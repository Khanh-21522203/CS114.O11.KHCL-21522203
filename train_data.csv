text,label
<number> công_cụ ai giúp tăng_tốc_độ học của bạn link to pdf,['#sharing']
hi_mng hiện_tại đang <number> tuổi và vì đam_mê lập_trình nên đi học <number> trung_tâm tên là aptech đào_tạo mảng web sau khoảng hơn <number> năm đi làm h_e đang thật_sự muốn chuyển_hướng sang mảng ai em có kinh_nghiệm hơn <number> năm về python nhưng lại chưa có kiến_thức về toán đc dạy trong đại_học liệu có nên học lại đại_học không hay nên tự học sau đó đi làm mong các cao nhân trong group chỉ cho <number> lộ_trình để có_thể trở_thành <number> ai engineer em cảm_ơn,['#Q&A']
chào cả nhà đang muốn nhúng code python vào camera gắn tường nhưng thấy bảo có_thể code trực_tiếp trên camera luôn cụ_thể là mình có <number> con cam_gắn <number> góc như ảnh và mình sẽ sử_dụng code python để xử_lý ảnh trong nó luôn mà không cần dùng các phụ_kiện khác mọi người có ai biết có_thể cho hướng đi hoặc bài viết liên_quan được không cảm_ơn,"['#Q&A', '#python', '#cv']"
em chào mọi người em đang muốn làm về building recomendation system bằng gradio chỉ cần nó hiện được hình_ảnh tên sản_phẩm comment đánh_giá lên là được thì mọi người có tài_liệu tham_khảo về mảng này không cho em xin với em cảm_ơn,"['#machine_learning', '#Q&A', '#python']"
em chào anh việt chào các bạn trong group hiện_tại em mình đang làm bài_toán sinh mô_tả ảnh sử_dụng resnet50 imagenet pretrain và lstm để sinh mô_tả em muốn hỏi trong group đã có ai làm_chủ_đề này với những mô_hình cnn cơ_bản chưa cho em hỏi kết_quả ra tốt không vì theo như em tham_khảo hầu_hết kết_quả code có sẵn đều ra những mô_tả khá tệ cho ảnh dưới đây em đính kèm một_vài ví_dụ chạy ra cũng như mô_hình của em sử_dụng một_số thông_số khác trong lúc em train lstm batch_size <number> epochs <number> loss cuối <number> ảnh 20k caption tổng 100k dictionary <number> <number> từ bắt_đầu kết_thúc câu dài nhất <number> em cảm_ơn mọi người đã giúp_đỡ,"['#nlp', '#Q&A', '#deep_learning', '#cv']"
dive into python quyển sách python đầu_tiên mình học có_thể với người khác đây không phải là đầu_sách tốt nhất về python nhưng với cá_nhân mình nó là the best đây chính là quyển sách đã đi cùng mình trong suốt những năm_tháng đầu_tiên mình học về ai machine learning không màu_mè hoa_lá thậm_chí layout có phần hơi nhàm_chán tuy_nhiên tất_cả những gì các bạn cần biết về python cơ_bản đều được giới_thiệu đây <number> trong số_ít các đầu_sách mình chia_sẻ mà chính mình đã trải nghiệm qua link,"['#python', '#sharing']"
deep learning visual approach cùng với bonus chapter hi các bạn mình từ trước đến giờ vẫn là fan của cách học tận_dụng hình_ảnh minh_họa để truyền_tải ý_tưởng hôm_nay mình xin giới_thiệu với các bạn <number> đầu_sách như_vậy deep learning visual approach tên của cuốn sách đã nói lên tất_cả rất nhiều hình_ảnh được sử_dụng xuyên suốt <number> chương giúp người đọc có_thể dễ_dàng hình_dung các khái_niệm cũng như thuật_toán ngoài_ra chúng_ta có thêm <number> chương bonus được cung_cấp thêm dành riêng cho scikitlearn keras các bạn nhé main book bonus chapter,"['#python', '#deep_learning', '#sharing']"
toàn_bộ các template dành cho cv sop ielts toefl toeic gmat gre ... được chia_sẻ bởi hotspot international scholarship forum hisf hi các bạn tài_liệu mình chia_sẻ trong post này thật_ra không có fit với group của chúng_ta tuy_nhiên mình vẫn muốn chia_sẻ vì ngày_xưa khi mình chuẩn_bị hồ_sơ để du_học mình đã rất mong_muốn có <number> nguồn đầy_đủ như thế này và mình tin chắc rằng trong group của chúng_ta có không ít bạn có dự_định đi du_học trong tương_lai hoặc chỉ đơn_giản là muốn trang_bị cho bản_thân <number> chứng_chỉ tiếng anh để phục_vụ cho việc học_tập và đi làm trong nước nguồn dưới đây bao_gồm toàn_bộ các templale dành cho các giấy_tờ quan_trọng mà các bạn phải chuẩn_bị để có <number> bộ hồ_sơ hoàn_chỉnh cv sop reference letter ... ngoài_ra các tài_liệu ôn thi các chứng_chỉ tiếng anh cũng được thu_thập và chia_sẻ mình mong rằng nguồn tài_liệu này sẽ giúp_ích được cho nhiều bạn trong group link to drive,['#sharing']
em chào mọi người em đang có một project nho_nhỏ là dự_đoán biến_động giá cổ_phiếu sử_dụng mô_hình lstm em đã làm các công_đoạn etl dữ_liệu từ package vnstock rồi và sau vài phân_tích cơ_bản cũng như tính luôn biến_động giá cổ_phiếu và tỷ_suất sinh lời hằng ngày thì bộ dataframe của em đã được như hình mọi người cho em hỏi là em có_thể chọn các columns nào trong dataframe này để làm các feature variables và nếu như_không có cột nào đủ thỏa_mãn để làm feature variables thì mọi người có_thể gợi_ý cho em một_số các feature variables khác để thực_hiện được không và nguồn dữ_liệu đi kèm với nó em cảm_ơn mọi người nhiều,"['#data', '#Q&A', '#deep_learning']"
chào mọi người hiện_tại mình đang làm một bài_toán liên_quan đến extract thông_tin từ các hoá_đơn bài_toán này mình đang làm theo hướng token classification với model layoutlmv3 nhưng có <number> vấn_đề muốn mọi người tư_vấn chút hiện_tại mô_hình đang output ra như hình với kết_quả như này thì hiện_tại mình chỉ có_thể biết được các box đỏ và box xanh từ dòng thứ <number> trở_đi thuộc nhãn nào hiện_tại mình muốn hỏi có cách nào hoặc mô_hình nào giúp xác_định được các box xanh hoặc box đỏ thuộc cùng <number> sản_phẩm không ví_dụ box xanh và box đỏ dòng <number> sẽ thuộc <number> sản_phẩm tương_tự với dòng <number> mình có thử làm theo hướng xử_lý ảnh để phân_biệt các sản_phẩm nhưng thấy cách này chỉ có_thể áp_dụng trên <number> template này nhưng với template khác thì failed mong mọi người có_thể giúp mình xin cảm_ơn,"['#nlp', '#Q&A', '#deep_learning', '#cv']"
chào mọi người em có từng nghe nói là bây_giờ chạy model đều có sẵn trên mạng hết cả rồi vậy cho em xin hỏi mình lấy những model chạy sẵn đó đâu em xin cảm_ơn,['#Q&A']
mn cho em hỏi là có ai từng sử_dụng particle filter với vs extended kalman filter để dự_đoán đường đi vật_thể chưa em cần giúp_đỡ và tham_khảo về phần này em có dùng kalman filter để dự_đoán nhưng đến lúc vật_thể bị che_khuất thì lại ko có kết_quả tốt em cảm_ơn mọi người,"['#math', '#Q&A', '#cv']"
em chào mọi người hiện đang vướng_mắc chỗ model phần extract parameter used for itcnet mặc_dù đã copy gần như hết model code nhưng em vẫn ko tìm ra lỗi sai tại_sao output của 1f3f lại chỉ có rank1 đây là link code của em 1f 3f 1f full link code của tác_giả,"['#Q&A', '#deep_learning', '#cv']"
em chào anh việt chào các bạn trong group hiện_tại em mình đang làm bài_toán har human action recognition nhận_diện hành_động qua video em đang tiếp_cận <number> phương_pháp là sử_dụng convlstm2d và sử_dụng model lrcn dưới em có để ảnh cụ_thể mọi người cho em hỏi là câu <number> <number> phương_pháp này khác nhau thế_nào về cách hoạt_động câu <number> kết_quả em thu được thì model lrcn cho kết_quả chính_xác hơn convlstm2d theo em tìm_hiểu thì convlstm2d đúng_ra phải tốt hơn câu <number> batchsize em để là <number> liệu có thấp quá hay đang cao và nó sẽ ảnh_hưởng thế_nào đến model em cảm_ơn mọi người đã giúp_đỡ,"['#Q&A', '#deep_learning', '#cv']"
tổng_hợp notes cho các programming languages frameworks và technologies hi các bạn mình xin chia_sẻ với các bạn <number> nguồn rất thú_vị tổng_hợp note cho rất nhiều các ngôn_ngữ lập_trình frameworks cũng như các technologies khác nhau các bạn chỉ đơn_giản là click vào notes các bạn muốn và download về thế_là xong nếu các bạn là dân it mình recommend các bạn tải về các notes sau git linux latex sql mysql algorithms nếu các bạn đang theo_đuổi ai data science machine learning thì chắc_chắn rồi đừng quên tải note về python các bạn nhé link,"['#python', '#sharing']"
data science puzzle mình thấy share trên linkedin nên mình share lại đây cho mọi người các bạn thử giải xem nha mình cũng chỉ giải được <number> vài câu thôi,['#sharing']
chào các bạn và anh_chị em muốn share mọi người <number> nguồn tìm sách khá là ổn,['#sharing']
tất_cả những gì các bạn cần biết về decision tree hi các bạn decision tree hay cây quyết_định là <number> trong số các thuật_toán quan_trọng bậc nhất trong machine learning mà bất_cứ <number> data scientist nào cũng cần nắm vững tài_liệu <number> trang dưới đây tổng_hợp toàn_bộ kiến_thức các bạn cần biết về thuật_toán thú_vị và quan_trọng này link to pdf,"['#machine_learning', '#sharing']"
học python qua <number> challenges hi các bạn mình xin chia_sẻ <number> cuốn sách học python thông_qua <number> ví_dụ được xuất_bản bởi nhà xuất_bản đại_học cambridge các ví_dụ này đều vô_cùng cơ_bản được xây_dựng nhằm hướng đến đối_tượng là những ai chưa từng lập_trình bao_giờ <number> challenges được chia làm <number> nhóm <number> challenges đầu_tiên sẽ giúp các bạn làm_quen với các khái_niệm cơ_bản trong python như các toán hạng toán_tử câu điều_kiện vòng lặp các kiểu dữ_liệu cũng như <number> vài các thư_viện phổ_biến trong python <number> challenge cuối đòi_hỏi các bạn phải kết_hợp kiến_thức đã học được thông_qua <number> challenges đầu_tiên điều may_mắn là tất_cả <number> challenges này sẽ đều có bài giải đi kèm do đó các bạn có_thể đối_chiếu với bài_làm của mình <number> tài_liệu rất phù_hợp với người mới học,"['#python', '#sharing']"
dạ em chào anh_chị và mọi người tình_hình là em dự_kiến build pc để học và làm_việc cụ_thể là em hướng theo data engineering với budget <number> triệu thì nên build như thế_nào là tối_ưu và mua đâu cho uy_tín em cảm_ơn,['#Q&A']
em chào mọi người dạ cho em hỏi <number> số tài_liệu kênh youtube giảng_dạy về ml mà giảng sâu về cơ_sở toán_học của nó với vd như các thuật_toán được xây_dựng dựa trên cơ_sở toán_học như thế_nào mạng neural hoạt_động dựa trên cơ_sở toán_học nào ... em muốn hiểu sâu về bản_chất của nó em cảm_ơn,"['#machine_learning', '#Q&A', '#math']"
chào anh việt và mọi người em hiện là sinh_viên năm <number> ngành điện_tử viễn_thông của đại_học bách_khoa tphcm hướng em theo là hệ_thống nhúng và xe tự_hành được biết xe tự_hành thì cần biết thêm về xử_lý ảnh và computer vision nên trên trường em đã đăng_ký học <number> môn là machine learning và xử_lý ảnh em muốn biết sâu thêm về computer vision thì học như thế_nào cho hỏi anh việt làm trí_tuệ nhân_tạo anh chuyên về nlp hay computer vision vậy nếu là computer vision thì cho em hỏi đăng_ký học anh như thế_nào em xin cảm_ơn anh việt và mn đã lắng_nghe bài viết của em,"['#nlp', '#Q&A', '#cv']"
review <number> khóa học tốt nhất trên coursera về thống_kê dành cho những bạn đang tìm_hiểu các khóa học về thống_kê trên coursera dưới đây là đánh_giá về <number> khóa tốt nhất đến từ <number> trường đại_học khác nhau thống_kê cùng với xác_suất là mảng kiến_thức vô_cùng quan_trọng mà bất bất_kì ai muốn theo_đuổi lĩnh_vực data science cần nắm chắc link,"['#math', '#sharing']"
chào mọi người mình có <number> câu hỏi cho dự_án ocr chữ viết_tay mình có gặp qua mấy dạng detect qua ảnh để nhận_diện nhưng mà bây_giờ mình muốn vẽ lên màn_hình luôn ví_dụ cho <number> cái bảng mình vẽ chữ lên bằng chuột và nó nhận_diện chữ trên máy cho mình mình đang bí về tìm_kiếm thông_tin mọi người ai biết gợi cho mình <number> vài từ khóa với or thông_tin cảm_ơn mọi người nhiều,"['#Q&A', '#deep_learning', '#cv']"
bản_đồ đường đi cho kỹ_thuật dữ_liệu được dịch từ tiếng anh,"['#data', '#sharing']"
vizro thư_viện python giúp tạo các ứng_dụng web và dashboard tương_tác <number> cách dễ_dàng hi các bạn mình xin giới_thiệu voiws các bạn vizro <number> thư_viện python giúp cho các bạn data scientist có_thể tạo nên các ứng_dụng web cũng như các interactove dashboard chuyên_nghiệp <number> cách dễ_dàng mà không cần các bạn phải có kiến_thức về web development link to repo,"['#python', '#sharing']"
<number> trang cheat sheet python hi các bạn mình xin chia_sẻ <number> cheat sheet rất thú_vị về python cheat sheet <number> trang này bao_gồm <number> phần chính cheat sheet dành cho các khái_niệm cú_pháp cơ_bản cheat sheet dành cho các thư_viện framework phổ_biến trong python note cheat sheet này định_hướng tổng_quát chứ không chỉ là về ai hay data science machine learning các bạn nha link to pdf,"['#python', '#sharing']"
<number> cách mã_hóa categorical data các bạn chú_ý cách <number> là chỉ áp_dụng cho target thôi chứ các bạn đừng có áp_dụng vào feature đó nhé,"['#data', '#sharing']"
chào việt lẫn các anh trong group có <number> câu hỏi muốn gửi đến việt lẫn mọi người trong group hiện_nay thích <number> mảng là ml và dl và sau khi tìm_hiểu thì <number> mảng đều quan_trọng về toán cả và đối_với toán thì dạng tàm_tạm liệu có theo_đuổi đc hay không tại vì thấy profile việt là chuyên toán trường amsterdam và hơn nữa cũng để_ý ai học về ai đều có profile toán rất xuất_sắc câu thứ <number> là giả_sử việt hay bất_kì ai trong group này nếu gặp <number> problem mà bên người khác giải_thích khá chi là mơ_hồ thì các hay việt hay làm gì và liệu mình thực_hành nhiều là mình tự hiểu cái vấn_đề đó không dạ cảm_ơn,"['#machine_learning', '#Q&A', '#deep_learning', '#math']"
hãy có trách_nhiệm hơn với bài post của mình các bạn ơi trong quá_trình_duyệt bài mình rất thường_xuyên gặp những bài post mà mình có_thể nói là khá vô trách_nhiệm như hình dưới đây là <number> ví_dụ khi chúng_ta muốn hỏi mọi người về <number> vấn_đề gì đấy hãy chắc_chắn là các bạn cung_cấp đầy_đủ thông_tin để những người có thiện_chí muốn giúp các bạn người_ta không phải hỏi thêm hỏi lại các bạn nhé soạn <number> post đầy_đủ thông_tin vừa tiết_kiệm thời_gian cho mọi người vừa khiến mọi người muốn giúp mình hơn mình góp_ý vậy thui chứ bản_thân mình ngày_xưa cũng vậy,['#sharing']
tổng_hợp tất_cả các giải_pháp và ý_tưởng tốt nhất trên kaggle hi các bạn mình xin chia_sẻ với các bạn <number> repo github rất thú_vị kaggle solutions đây là nơi tổng_hợp các giải_pháp tốt nhất cũng như_ý_tưởng trên kaggle được sắp_xếp theo các tiêu_chí khác nhau danh_sách này được cập_nhật liên_tục nha các bạn vì_sao mình lại chia_sẻ repo này vì <number> trong những cách học tốt nhất chính là học từ những người giỏi nhất những giải_pháp tốt nhất link to repo,['#sharing']
mn cho em hỏi trong đây có ai rành về cái này ko em copy code về mà run thì nó báo lỗi nhờ mn xem giúp em với em cảm_ơn tất_cả anh chị,['#Q&A']
chào mọi người em hiện mới mua code python từ một người khác khi họ vào untra máy em chạy file python thì không được ấn chuột phải chọn open thì nó hiện lên cmd xong tắt luôn code em là code bot telegram nhưng khi họ làm thế trên vps bằng chính code đấy thì lại hoạt_động hiện_tại em đang giữ vps và em muốn chạy bằng máy chính của mình mọi người cho em hỏi là ngoài việc tải python về ra thì còn phải setup lệnh gì không,"['#Q&A', '#python']"
google research <number> trong các nguồn chất_lượng về ai các bạn nên theo_dõi hi các bạn với việc là <number> trong các ông lớn đầu_tư rất mạnh_mẽ vào ai các nghiên_cứu của google luôn là <number> trong các nguồn hữu_ích giúp những mà ai đang học làm tìm_hiểu về ai nên cập_nhật các bạn không nhất_thiết phải hiểu <number> những nghiên_cứu này thật_ra có muốn cũng không_thể hiểu vì đây không phải là research paper thay vào đó biết về sự tồn_tại của chúng chúng giải_quyết vấn_đề gì tạo ra sản_phẩm như thế_nào ... cũng đã là rất tốt rồi_đây là <number> trong các nguồn yêu thích của mình thời còn là sinh_viên cũng như khoảng thời_gian vừa_mới ra trường giờ thì mình lười đi nên ít theo_dõi rồi link,['#sharing']
em chào anh_chị cho em hỏi anh_chị đi làm thường có cần phải giỏi hết cả nlp computer vision rồi object detection image gen ... các kiểu không hay chỉ cần giỏi <number> cái là đủ,['#Q&A']
chào mọi người mình đang có ý_định làm một chương_trình python kiểm_tra một người khi squat có đúng form không bằng opencv hiện_tại mình chưa biết nên bắt_đầu_từ đâu ai có ý_kiến gì cho mình xin với mình xin cảm_ơn,"['#Q&A', '#python', '#cv']"
python bible 7in1 tổng_hợp <number> chủ_đề khác nhau trong <number> cuốn sách duy_nhất hi các bạn mình xin giới_thiệu với các bạn <number> cuốn sách vô_cùng thú_vị python bible 7in1 cuốn sách sẽ cover <number> nội_dung sau python for beginners python for intermediates python for data science python for machine learning python for finance python for neural networks python for computer vision <number> topic <number> cuốn sách con trong <number> cuốn sách duy_nhất link to pdf,"['#python', '#sharing']"
chào admin và mọi người hiện_tại đang thử_nghiệm dự_án nhận diển biển số xe_máy với yêu_cầu được giao là realtime thời_gian nhận_diện là 4s đổ về mọi người ai đã từng làm_việc mảng này cho em chút kinh_nghiệm hướng giải_quyết và lời khuyên với em cảm_ơn,"['#Q&A', '#cv']"
chào mọi người em là nữ sv năm nhất các anh_chị đi trước cho em hỏi xíu hiện_tại em đang có bằng ielts <number> đến lúc ra trường đi xin việc bằng của em đã hết hạn thì em có cần thi lại không liệu nhà tuyển_dụng có đặt nặng việc chứng_chỉ còn thời_hạn không ngoài_ra để có việc thực_tập từ cuối năm <number> liên_quan đến dataai thì em sẽ cần thành_thạo những kỹ_năng chứng_chỉ gì hay nếu mình là học_sinh trường top gpa cao thì có được xem_xét hơn không sau gần <number> kỳ học hust em cảm_thấy như bị bỏ lại phía sau vậy biết là toán rất quan_trọng nên em cũng đầu_tư kha_khá thời_gian để học vừa là để có gpa cao <number> xíu nhưng vô_tình em chưa giành nhiều thời_gian cho code so với các bạn it trường khác thì cảm_giác em chưa có kinh_nghiệm gì nhiều vậy theo mọi người em nên tập_trung vào cái gì hơn anh_chị cho em lời khuyên với,"['#data', '#Q&A']"
sách lập_trình python cho người mới bắt_đầu hi các bạn mình xin giới_thiệu với các bạn cuốn python programming for the absolute beginner cuốn sách dạy về lập_trình python dành cho người mới chưa từng lập_trình bao_giờ đầu_tiên phải xác_nhận <number> điều là cuốn sách này hoàn_toàn không mới lần tái_bản thứ <number> này đã từ năm <number> tuy_nhiên do đây là sách học cơ_bản chứ không phải để giới_thiệu framework hay thư_viện nên điều này không phải vấn_đề cuốn sách gồm <number> chương và <number> phụ_lục sẽ giúp các bạn tìm_hiểu về tất_cả các khái_niệm cơ_bản nhất trong python link to pdf,"['#python', '#sharing']"
chào mọi người em đang là sinh_viên năm <number> ngành khoa_học máy_tính đại_học bách_khoa hà_nội thời_điểm này em cần chọn hướng đi cho công_việc sau_này em đang phân_vân hai hướng đi là làm dev luôn hoặc tiếp_tục học cao lên định_hướng nghiên_cứu computer science data science hiện em cũng đang tham_gia lab trường nên hiểu về research và thấy phù_hợp với hướng đi này nhưng điều làm em phân_vân là điều_kiện gia_đình em tìm_hiểu thì thấy muốn có công_việc tốt mảng cs ds thì phải đầu_tư nhiều về cả thời_gian và tiền_bạc với điều_kiện hiện_tại thì gia_đình em không_thể đáp_ứng được vì_vậy em muốn xin lời khuyên của mọi người liệu em có_thể vừa làm dev để duy_trì thu_nhập vừa học tiếp master hay đi làm vài năm tích vốn rồi đi du_học em cảm_ơn,['#Q&A']
chào anh việt và các bác trong group hiện em đang là sinh_viên năm <number> ngành cntt và hết năm nay là em học xong các môn cơ_sở ngành em dự_tính theo con đường ds hoặc ai engineer em có tìm_hiểu roadmap trên cái web thì nó vẽ khá chi_tiết nhưng mà em vẫn có <number> số câu hỏi <number> các bác cho em hỏi rằng cái roadmap này có thực_sự ổn không và nếu được các bác có_thể tư_vấn cho em <number> cái lộ_trình cho một người không biết hoàn_toàn gì về ai như em muốn bước chân vào đây không tham_gia nhóm <number> thời_gian bằng nick chính đây là acc phụ của em thấy anh việt share nhiều thứ hay quá nên muốn được bắt_đầu học và tận_dụng những thứ anh share <number> lĩnh_vực ds ai việt_nam đang chuộng mảng nào nhất và khi học xong những gì thì mình được chuyên_tâm vào <number> mảng mà mình chọn hi_vọng được thông_cảm vì những câu hỏi ngu_ngơ của em vì em cũng mới tìm_hiểu ngành em cảm_ơn mọi người,"['#machine_learning', '#Q&A']"
chào mọi người hiện_tại em đang làm đồ_án về truy vấn thông_tin em làm về content based image retrieval em định làm thêm text based image retrieval nhưng em đang kẹt phần caption của image do dataset là phải tự scrape về nên chỉ có_thể scrape được ảnh em có thử dùng <number> vài tool để tạo caption nhưng kết_quả ra khá tệ giờ em phải làm như nào để tạo được caption em cảm_ơn mọi người,"['#Q&A', '#cv']"
pandas datetime cheat sheet cheat sheet <number> trang dưới đây tổng_hợp toàn_bộ những kiến_thức và các hàm các bạn cần biết khi làm_việc với dữ_liệu thời_gian trong pandas note lại để sau_này sử_dụng nha các bạn link to pdf,"['#sharing', '#python']"
khai_giảng khoá học tháng <number> <number> vs <number> <number> chào các bạn mình là thắng hiện_tại mình đang làm ai research associate tại titus research institute brandenburg chlb đức đồng_thời cũng là em_trai của ông admin còn lại của group chúng_ta việt nguyễn trong tháng <number> vs <number> này chúng_mình vẫn tiếp_tục khai_giảng <number> số lớp_học về ai ml ds cv dành cho các bạn đang vn cũng như nước_ngoài và đặc_biệt hơn chúng_mình cũng triển_khai lần đầu_tiên khóa học về lập_trình python dành cho các bạn chưa từng tiếp_xúc với lập_trình các bạn quan_tâm đến các lớp_học này có_thể liên_hệ với chúng_mình qua zalo <number> với việt nguyễn tại berlin đức,['#sharing']
videopoet model generation mới của google google vừa cho ra_mắt videopoet model nhận input đầu_vào dưới dạng text image optical flow hoặc masked video và tạo ra output là video có kèm theo âm_thanh link to post,['#sharing']
dạ em là newbiew em practive <number> project nhỏ dưới em hỏi chatgpt để làm các model mà sao có mấy dòng code không biết làm như_vầy đã được chưa mong mọi người cho em ít nhận_xét em cảm_ơn mọi người nhiều,['#Q&A']
dạ chào anh và mọi người em xin đăng ẩn danh để hỏi dạ em học chuyện ngành ai code thì em học tạm ổn rồi em có một_vài câu hỏi em cũng có_học qua data science train model nhưng em cũng hong biết là mình có hiểu không tại là mình học đúng hong nữa em làm những bước của để train model thì em hiểu nhưng tới apply model vào thì em không biết là mình chọn model gì em cứ để đại vào rồi train thoi dạ toán machine thì em học hiểu nhưng còn apply những model đó vào code thì em chưa hiểu lắm dạ em chuẩn_bị học computer vision deep leaning và em cũng tích mãng này em có xem các khóa học trên youtube thì cũng có nhiều video của các trường dạy nhưng em không biết bắt_đầu_từ đâu để đi đúng dạ cho em hỏi phần train model đó nếu mình làm sau_này ví_dụ như computer vision thì có dùng hong dạ cho em hỏi mảng computer vision thì việt nam mình có nhiều job hong em cũng nghĩ một_số project mà em nghĩ thì hay nhưng sợ làm hong được dạ em cảm_ơn mn dạ em cũng hong biết nhiều mong mn bỏ_qua,"['#Q&A', '#cv']"
mọi người giúp em câu_lệnh nào để đảo_ngược dữ_liệu từ dưới lên trên với nghĩa_là <number> <number> <number> sẽ là đầu và <number> <number> <number> là nằm dưới cuối em cảm_ơn,"['#Q&A', '#data']"
hcm mình đang tìm cofounder cho startup ai dài_hạn bạn nào quan_tâm và thấy phù_hợp thì inbox mình nhé nếu bạn là chuyên về nghiên_cứu ai càng phù_hợp,['#Q&A']
anh_chị cho em hỏi là trong lúc học mà mình viết được papers thì có được điểm trong mắt nhà tuyển_dụng em xin chân_thành cảm_ơn,['#Q&A']
em đang muốn xin intern mà ko bt cách viết cv mn cho xin mẫu templete và cáh trình_bày đc ko,['#Q&A']
em chào mọi người hiện_tại thì em đang có <number> bài minitest về building recommendation system ấy nhưng mà sau khi em chạy flask trên visual code thì nó hiện lên như này em sửa mãi mấy hôm_nay rồi mà không được mọi người cho em xin ít ideas để xong trước thứ <number> với em cảm_ơn,['#Q&A']
cho em hỏi về graph embedding dùng gnn gcn và sage thì ví_dụ mình có <number> list các graph có số node khác nhau và cạnh nối có hướng mỗi node chỉ có thông_tin tên node thì mình nên rút <number> số feature như thế_nào để đưa vào model mục_đích của em là biểu_diễn mỗi graph thành <number> vector có số chiều cố_định sau đó đưa vào mô_hình phân_loại khác em có đọc <number> số bài code mẫu thì đều là chạy <number> graph và node embedding mỗi node có label và feature có sẵn có_thể cho em xin <number> số tài_liệu về graph embedding mà có code mẫu thì càng tốt,"['#Q&A', '#deep_learning']"
<number> project python với source code đi kèm hi các bạn mình xin chia_sẻ với các bạn danh_sách <number> project python đi kèm với mã nguồn giải_thích bao_gồm <number> project cơ_bản <number> project nâng cao chủ_đề của các project này rất đa_dạng từ game app similator cho đến ai model cá_nhân mình thì thấy các project cơ_bản rất hữu_ích cho các bạn mới làm_quen với python còn các project nâng cao thì có khoảng <number> nửa trong số này mình nghĩ là có_thể sử_dụng để làm_đẹp cho github profile của các bạn các bạn chú_ý nhé source code được cung_cấp các bạn có_thể coi như <number> nguồn để tham_khảo hãy tự xây_dựng hướng đi riêng cho mình nhé link to pdf các bạn down file pdf về là có_thể click vào link nhé trong file nhé,['#sharing']
"tài_liệu khóa học probability and statistics for data science của trung_tâm khoa_học dữ_liệu tại đại_học new york hi các bạn mình xin chia_sẻ với các bạn tài_liệu về xác_suất thống_kê cho data science đến từ đại_học new york tài_liệu này bao_gồm các phần chính sau lý_thuyết xác_suất cơ_bản biến ngẫu_nhiên biến ngẫu_nhiên nhiều chiều kì_vọng quá_trình ngẫu_nhiên phần này các bạn_đọc lần đầu tạm bỏ_qua cũng đư sự hội_tụ của quá_trình ngẫu_nhiên chuỗi markov thống_kê mô_tả thống_kê tần_suất thống_kê bayesian kiểm_định giả_thuyết hồi quy tuyến_tính lý_thuyết tập_hợp đại_số tuyến_tính theo đánh_giá cá_nhân của mình lần đầu học các bạn có_thể tạm_thời bỏ_qua phần 5,6,7,9,10 tài_liệu của các trường đại_học thì tất_nhiên luôn hơi hàn_lâm <number> chút cơ_mà so với mặt_bằng chung mình thấy quyển này lý_thuyết ko quá khó tiêu_hóa được các bạn nha link to pdf","['#sharing', '#math']"
chào cả nhà hiện_tại đang sử_dụng tensorflow sequantial để thiết_kế model nhưng chưa hiểu nếu thêm hay bớt layer nào thì nó ảnh_hưởng như nào tới kết_quả cả nhà có_thể nói sơ qua hoặc cmt giúp có bài viết nào hiểu chi_tiết phần này không cảm_ơn,"['#Q&A', '#python']"
em chào các anh chị các anh_chị đã làm qua mô_hình gan và vae để chỉnh_sửa mặt mình nhập từ đầu_vào và xuất ảnh xem kết_quả thế_nào chưa chỉ em cách chạy mô_hình này với em cảm_ơn,"['#Q&A', '#cv', '#deep_learning']"
hi_ae có ai handle đoạn outlook nó trả ra cái blob_url cho cái ảnh capcha chưa em encode ra base64 bằng cái hàm trong tài_liệu thì bị như này decode ngược_lại ae đang xử_lý nó như thế_nào em thì viết python selenium cho nó execute file js chạy cái hàm như trong tài_liệu cái ảnh có thuộc_tính backgroundimage url quot blob thanks admin ae,"['#Q&A', '#python']"
<number> nhóm phương_pháp chính để phát_hiện outliers hi các bạn <number> hôm trước mình vừa đọc được <number> post rất hay trên linkedin về chủ_đề outlier detection mình xin dịch tóm gọn lại để các bạn cùng nắm được có rất nhiều phương_pháp để có_thể phát_hiện được outliers nhưng nhìn_chung các phương_pháp này sẽ được chia vào <number> nhóm lớn nhóm dựa vào thống_kê nhóm này dựa vào box plot hoặc các graph tương_tự thường thì các điểm nằm ngoài vùng <number> lần interquartile có khả_năng cao là outliers các điểm nằm ngoài vùng <number> lần interquartile được coi là các extreme outliers nhóm dựa vào độ lân_cận nhóm này dựa vào khoảng_cách để xác_định outliers thông_thường thì knn sẽ được sử_dụng để chỉ ra các outliers dựa vào khoảng_cách giữa chúng tới các điểm lân_cận nhóm dựa vào time series time series làm tăng độ phức_tạp do có xu_hướng tổng_quan của dữ_liệu trend effect và xu_hướng theo mùa hoặc tháng seasonal effect stl seasonal trend loses decomposition có_thể được sử_dụng để loại_bỏ ảnh_hưởng của các xu_hướng này trước sau đó các kĩ_thuật thống_kê như là interquartile range iqr có_thể được sử_dụng để phát_hiện outliers nhóm dựa vào machine learning <number> vài thuật_toán machine learning như isolation forest có_thể được dùng để phát_hiện outliers link đến bài viết gốc,"['#sharing', '#machine_learning']"
machine learning web app mình có tìm_hiểu về ml web app và mình thấy có các libraries cũng như framworks flask diago thinkter pyqt5 streamlit taipy gradio ... các bác đã dùng cái nào rồi xin cho lời khuyên với nhé latex đính kèm file pdf mình đang viết cv bằng latex trên overleaf chẳng_là mình muốn đính kèm một file hình_ảnh pdf sao cho khi mình click vào thì nó sẽ mở lên xem như trình_duyệt web vì mò mãi ko ra nên mình đã thử push file pdf lên github và đính kèm link github mình ko biết có cách nào để làm thế trên latex hay ko nhờ mn chỉ_giáo,['#Q&A']
em chào mọi người mọi người cho em hỏi sự khác_biệt giữa standard supervised finetuning và instructiontuning cho closeddomain là gì được không theo em hiểu là standard supervised finetuning dùng cho single task còn instructiontuning có_thể là multi task em cảm_ơn,"['#Q&A', '#machine_learning']"
chào mọi người hiện_tại em đang làm một project về sentiment analysis tiếng việt về review sản_phẩm công_nghệ mọi người có_thể cho em xin tài_liệu đọc về mảng này xử_lí hiện_nay và tiền xử_lý dữ_liệu ntn được không,"['#Q&A', '#nlp']"
chào anh việt và mọi người em đang thắc_mắc về viết research paper nghe mọi người bảo là viết paper sẽ dễ kiếm được việc_làm hơn vậy để viết paper mình có cần có mentor ko có cần đi xin làm trợ_lý_giản viên ko và viết paper là viết cái gì đăng nó đâu mong mọi người giải_đáp em cảm_ơn,['#Q&A']
nguồn học về cnn tốt nhất với cá_nhân mình hi các bạn trong quá_trình ngày_xưa đi học cũng như bây_giờ đi làm dạy_học vào cuối tuần mình đã từng đọc rất nhiều các tài_liệu về cnn tuy_nhiên đối_với cá_nhân mình các nguồn từ đại_học stanford vẫn để lại cho mình nhiều ấn_tượng nhất có_lẽ <number> phần lý_do là vì đây là <number> trong những nguồn đầu_tiên mình học cụ_thể lecture note được trích từ course cs231n của stanford có_thể coi là <number> trong các nguồn xuất_sắc nhất giới_thiệu và giải_thích về cnn bao_gồm các layer cũng như các kiến_trúc kinh_điển không quá dài_dòng hàn_lâm nhưng đủ chi_tiết để đọng lại nơi người đọc link,"['#sharing', '#deep_learning']"
đánh_giá mô_hình chọn mô_hình và chọn thuật_toán trong machine learning mình mới đọc được <number> bài post rất hay trên linkedin về chủ_đề đánh_giá và lựa_chọn mô_hình cũng như thuật_toán trong machine learning đi kèm với <number> paper về chủ_đề này mình xin dịch lại dưới đây do tính_chất công_việc gần đây tôi phải phỏng_vấn rất nhiều ứng_cử_viên cho các vị_trí về machine learning tôi thấy rằng có rất nhiều ứng_cử_viên đã từng làm_việc trong rất nhiều project thú_vị và họ cũng biết sử_dụng rất nhiều framework và thư_viện machine learning tuy_nhiên hầu_hết họ đều gặp khó_khăn trong việc trả_lời các câu hỏi về thống_kê đặc_biệt là về kiểm_định giả_thuyết các bài test này là rất quá trọng trong việc tìm ra đâu là mô_hình tốt nhất để đưa vào triển_khai trong thực_tế các bạn không_thể_nào chỉ dựa vào <number> vài metrics được tính trên <number> cách chia train test set <number> cách ngẫu_nhiên được tôi tìm thấy <number> bài báo trong đó giải_thích <number> cách đơn_giản và dễ hiểu việc áp_dụng các bài test này trong thực_tế bài báo có tiêu_đề model evaluation model selection and algorithm selection in machine learning link to article,"['#sharing', '#machine_learning']"
pix2tex thư_viện python giúp chuyển_đổi ảnh công_thức thành code latex thư_viện này hiện đã có 7k6 stars rồi các bạn nha link,"['#sharing', '#python']"
mọi người cho em hỏi lỗi này fix như này em đổi thành learning_rate thì nó lại ra một lỗi khác,"['#Q&A', '#machine_learning']"
deep learning interviews <number> trang sách tổng_hợp các câu hỏi và đáp_án về các vấn_đề trong thực_tế về deep learning <number> cuốn sách đầy_đủ tập_trung vào các câu hỏi deep learning mang tính ứng_dụng hơn là lý_thuyết thuần với cá_nhân mình thì quyển sách rất hữu_ích trong việc tự kiểm_tra bản_thân xem liệu mình có hiểu rõ bản_chất không hay chỉ thuộc_lòng lý_thuyết thôi link to pdf,"['#sharing', '#deep_learning']"
em muốn hỏi là mọi người học machine learning trong bao_lâu để học tiếp deep learning vậy,['#Q&A']
chuyện là mình muốn làm <number> project nhận_diện từ_vựng tiếng nhật từ chữ viết_tay là mình chưa tìm được nguồn data từ_vựng nào đủ lớn mọi người ai đã làm qua chủ_đề này cho mình xin <number> vài nguồn data với cảm_ơn mọi người nhiều,"['#Q&A', '#deep_learning', '#cv']"
dive into deep learning cuốn sách deep learning cực hot_dạng tương_tác bao_gồm lý_thuyết toán code và cả phần thảo_luận dành cho người đọc có cả bản tiếng việt link to english version link to vietnamese version mình xin giới_thiệu <number> quyển sách tương_tác cực_kì nổi_tiếng về deep learning dive into deep learning quyển sách này có các điểm độc_đáo mà các bạn sẽ không_thể tìm thấy bất_kì <number> quyển sách nào khác sách tương_tác các bạn có_thể click vào các link ảnh hay video các trang sách điều đó khiến cho quá_trình di_chuyển giữa các phần trở_nên linh_hoạt và nhanh hơn giúp cho quá_trình học trở_nên thú_vị hơn code và toán đi kèm với mỗi phần thay_vì nằm riêng_biệt với lý_thuyết điều này giúp cho các bạn có_thể học <number> cách mạch_lạc hơn khi học đến đâu các bạn sẽ được học luôn những kiến_thức toán cần_thiết và thực_hành code luôn điều này là điểm khác_biệt với rất nhiều đầu_sách ml dl khác khi toán nằm <number> phần riêng khiến cho nhiều bạn sau khi học xong kiến_thức toán các bạn không biết kiến_thức đó sẽ được áp_dụng như thế_nào trong ml dl code dưới nhiều framework khác nhau đây là <number> điểm cực_kì_thú_vị khác với đa_phần các sách truyền_thống hay ebook khác khi người dùng phải dùng đúng framework mà tác_giả xài quyển sách này các bạn có_thể chọn <number> trong số các framework deep learning phổ_biến nhất hiện_nay như pytorch tensorflow hay mxnet framework của microsoft numpy để thực_hành điều này là <number> điểm cộng vô_cùng lớn cho nhóm tác_giả khi giúp người đọc không phải sử_dụng <number> framework trái tay sách_đa_ngôn_ngữ quyển sách đã được dịch sang nhiều ngôn_ngữ khác nhau bao_gồm cả tiếng việt của chúng_ta như các bạn có_thể thấy trong screenshot quả là tuyệt_vời phải không các bạn nội_dung father of đầy_đủ đây là điểm gây ấn_tượng nhất với mình cover tuốt mọi thứ về deep learning gần như_không thiếu bất_kì <number> topic nào mình có_thể khẳng_định các bạn có_thể học từ cơ_bản đến chuyên_sâu về deep learning chỉ với quyển sách này là tài_liệu duy_nhất,"['#sharing', '#deep_learning']"
tensorflow examples comprehensive tutorial dành riêng cho tensorflow hi các bạn mình xin giới_thiệu với các bạn <number> github repo được thiết_kế giúp các bạn làm_quen và sử_dụng tensorflow từ az thông_qua các ví_dụ để đảm_bảo phù_hợp cho tất_cả mọi người với nhu_cầu sử_dụng khác nhau tất_cả các notebook và source code sẽ đi kèm với giải_thích cả với tensorflow v1 và v2 repo sẽ bao_gồm các phần chính sau introduction basic models neural networks utilities data management hardware <number> nguồn vô_cùng chất_lượng dành cho những bạn muốn tìm_hiểu và thực_hành với framework nổi_tiếng này link to repo,"['#sharing', '#python']"
mình train yolov7 data trên 1m image bath <number> imgsz <number> gpu ăn dc có <number> nhưng sao cứ chạy dc đến vài chục epoch thì nó out nhỉ time done <number> epoch khá lâu nên mất thời_gian tiền điện quá,"['#Q&A', '#cv', '#deep_learning']"
chào mọi người em có đoạn code deeplearning dự_báo dữ_liệu time series tuy_nhiên sau mỗi lần chạy em lại nhận kết_quả khác nhau có cách nào em nhận cố_định một kết_quả sau mỗi lần chạy không em có thử đoạn code này mà vẫn không được np random seed <number> tf random set_seed <number>,"['#Q&A', '#deep_learning']"
admin mới share paper của sebastian raschka mình share thêm một platform này cũng do anh này đứng sau mình chưa có cơ_hội thử cụ_thể nhưng thử qua thấy cũng hay bạn nào tò_mò thử khám_phá rồi cho mọi người biết,['#sharing']
đã tìm_hiểu trên đủ các loại diễn_đàn <number> hôm_nay mà không tài_nào fix được pls help terminal traceback most recent call last file codetester python test py line <number> in module import tensorflow as ts file users erwin appdata local programs python python311 lib sitepackages tensorflow __init__ py line <number> in module from tensorflow python import tf2 as _tf2 file users erwin appdata local programs python python311 lib sitepackages tensorflow python tf2 py line <number> in module from tensorflow python platform import _pywrap_tf2 importerror dll load failed while importing _pywrap_tf2 dynamic link library dll initialization routine failed finished in <number>,"['#Q&A', '#python']"
khóa học ai for beginners của microsoft hi các bạn trong mấy ngày vừa_rồi mình đã thấy ít_nhất <number> group chia_sẻ về khóa học này rồi nên mình cũng tiện đường công_tác chia_sẻ lại với các bạn trong group của chúng_ta khóa học kéo_dài <number> tuần với <number> bài_học này sẽ trang_bị cho người học những kiến_thức cơ_bản nhất về ai neural network computer vision natural language processing mỗi bài sẽ bao_gồm lý_thuyết notebook và bài_tập có <number> điều các bạn cần chú_ý do khóa học hướng tới kiến_thức cơ_bản cho người mới có_thể tiếp_cận nên các kiến_thức về các mô_hình machine learning cổ_điển hay các kiến_thức toán căn_bản sẽ không được đề_cập trong khóa học này các bạn nhé link to course,"['#sharing', '#machine_learning']"
repo github tổng_hợp các machine learning và deep learning tutorials hi các bạn mình xin giới_thiệu với các bạn <number> repo github rất nổi_tiếng <number> nguồn allinone tổng_hợp tất_cả các tutorials articles interview cũng như các blog nổi_tiếng nhất về machine learning và deep learning hiện_tại repo này đã có <number> forks và <number> stars các bạn nhé link to repo,['#sharing']
machine learning for timeseries with python hi các bạn timeseries forecasting là <number> trong số các bài_toán quan_trọng mà bất_kì <number> data scientist nào cũng phải nắm được mình xin giới_thiệu với các bạn <number> quyển sách về chủ_đề này được xuất_bản bởi nhà xuất_bản nổi_tiếng packt đây là <number> trong số các quyển sách về timeseries được recommend nhiều nhất trên các group về ai machine learning link to pdf,"['#sharing', '#machine_learning']"
em chào mọi người em biết khi làm các project liên_quan đến ml dl thì dataset là cực_kỳ hữu_ích nhưng khi có <number> dataset mà không có bất_kỳ bài_toán nào được đặt ra thì em có_thể khai_thác được những gì trong dataset đó và như anh việt nói thì từ dataset đó có_thể tự xây_dựng mô_hình cách tiếp_cận mới của riêng mỗi người thì mình có_thể khai_thác và tự xây_dựng mô_hình_như thế_nào mong mọi người chia_sẻ kinh_nghiệm,"['#Q&A', '#data']"
em đang làm về arima dự_đoán timeseries em xin phép được hỏi anh_chị các nguồn tài_liệu soucre liên_quan được không rất vui và biết_ơn khi được các anh_chị giúp_đỡ hashtag,"['#Q&A', '#machine_learning']"
mình xin chia_sẻ roadmap cho ds mà mình tự viết ra các bạn có_thể tham_khảo nhé sau mấy năm từ chập_chững học_hỏi đến khi có việc_làm mình có lời khuyên cho các bạn như sau datacamp subscription là thứ đáng đồng_tiền bát gạo nhất sale đâu_đó khoảng <number> <number> <number> năm rất rẻ so với các bạn bỏ ra <number> <number> triệu cho một khóa học cơ_bản bạn có_thể học được một_vài thứ trên này medium subscription <number> năm trang này có nhiều bài viết chia_sẻ các project tóm_tắt paper các tip trick các kiểu đáng đồng_tiền bát gạo coursera xin miễn_phí học ổn nên xin gối_đầu mỗi tháng <number> course là vừa tóm lại mỗi năm bạn chỉ mất <number> không quá nhiều đâu còn ai muốn học khóa học thì liên_hệ mình mình bán khóa học nhưng chắc vài năm nữa mới có,"['#sharing', '#data']"
dạ em chào mọi người và anh việt thì hiện_tại em đang thực_hành báo_cáo khám_phá dữ_liệu với bộ dataset air pollution em có hai câu hỏi muốn hỏi câu hỏi <number> theo mọi người em có nên giữ lại thuộc_tính country và city cho các mô_hình cũng như thuật_toán không mặc_dù vấn_đề ô_nhiễm môi_trường một phần cũng có liên_quan tới yếu_tố vị_trí nhưng em nghĩ nó không nhiều câu hỏi <number> sau khi em visualize lên thì em nghĩ bộ dữ_liệu này cũng bị mất cân_bằng về dữ_liệu cụ_thể là số_lượng trường_hợp ảnh_hưởng xấu đến sức_khỏe ít hơn nhiều so với phần tích_cực việc này sẽ khiến các mô_hình_học được nhiều kiến_thức về tích_cực nhưng lại yếu về các phần tiêu_cực theo mọi người em có nên xử_lý gì đó để cân_bằng dữ_liệu lại không câu hỏi <number> vì aqi chung đánh_giá bằng việc lấy aqi thành_phần cao nhất nó khá đơn_giản và mình cũng biết quy_luật rồi nên em không biết là liệu áp_dụng các thuật_toán cổ_điển có ổn không cụ_thể thì em nghĩ chỉ có decision tree là thích_hợp_nhất em cũng mới tiếp_cận về khai_phá dữ_liệu đọc trên mạng về quy_trình khai_phá nhưng thấy vẫn khá chung_chung anh_chị biết cụ_thể các bước nào chỉ giúp em với em cảm_ơn mọi người link bộ dữ_liệu,"['#Q&A', '#data']"
gpt với chỉ <number> dòng code hi các bạn mình xin giới_thiệu với các bạn <number> repo github cực_kì nổi_tiếng về gpt nanogpt repo này nổi_tiếng vì sự đơn_giản cũng như tốc_độ training của nó hiện_tại project này đã có gần 4k lượt forks cũng như 27k stars từ cộng_đồng với các bạn đang muốn tìm_hiểu cách_thức mà <number> mô_hình gpt được xây_dựng và huấn_luyện đây là <number> nguồn không_thể tuyệt_vời hơn để các bạn bắt_đầu <number> file quan_trọng nhất trong repo này đều <number> dòng train py phần khung của quá_trình training model py đây là nơi model được định_nghĩa link to repo,"['#sharing', '#nlp']"
ebook neural networks from scratch in python hi các bạn dành cho các bạn học về deep learning thích tìm_hiểu bản_chất của các layer các mô_hình thông_qua việc tự code từ đầu mà không sử_dụng các framework về deep learning như pytorch tensorflow hay keras mình xin giới_thiệu <number> cuốn sách vô_cùng nổi_tiếng được xuất_bản vào năm <number> neural network from scratch in python với cuốn sách này mọi khái_niệm các bạn cần biết và hiểu trong deep learning sẽ được giới_thiệu và thực_hiện hoàn_toàn chỉ sử_dụng <number> thư_viện duy_nhất đó là numpy cá_nhân mình rất ấn_tượng về cách trình_bày của cuốn sách này tỉ_mỉ đến từng chi_tiết nhỏ_nhặt như màu_sắc của các mảng hay ma_trận mình highly recommend các bạn cuốn sách này nếu các bạn thực_sự muốn hiểu bản_chất của neural networks code from scratch không phải cách duy_nhất để hiểu nhưng nếu các bạn đã thử cách khác rồi mà vẫn không hiểu thì bạn nên thử cách này link to pdf,"['#sharing', '#deep_learning']"
gần <number> project data science với sample code hi các bạn mình xin chia_sẻ với các bạn danh_sách gồm gần <number> project data science với code mẫu bằng python để các bạn có_thể tự xây_dựng nên các project cá_nhân của mình nhằm luyện_tập cũng như làm_đẹp cho github các nhân với mỗi project chúng_ta sẽ có giới_thiệu về bài_toán dataset tương_ứng code mẫu với python và giải_thích từng bước giờ mình gợi_ý cách các bạn sử_dụng danh_sách này nhé đầu_tiên đối_với cá_nhân mình thứ quý_giá nhất từ danh_sách này không phải là câu hỏi hay code mẫu mà là dataset danh_sách này cung_cấp cho chúng_ta các dataset vô_cùng đa_dạng trải rộng nhiều mảng khác nhau <number> khi có dataset thậm_chí chúng_ta có_thể tự xây_dựng nên bài_toán mà chẳng cần_câu hỏi cho trước các bạn có_thể tham_khảo code để xem người_ta phân_tích và xử_lý bài_toán như thế_nào sau đó các bạn hãy thử tự xây_dựng mô_hình cách tiếp_cận mới của riêng bạn link to pdf,"['#sharing', '#data']"
mình chia_sẻ tài_liệu thực_hành các chủ_đề deep learning drive bên dưới tài_liệu bao_gồm code thực_hành của tất_cả các lĩnh_vực quan_trọng trong deep learning kèm theo giải_thích lẫn các bài_tập thử_nghiệm cuối mỗi bài ngoài_ra có <number> thư_mục con dành cho bạn nào muốn học python cơ_bản nữa nhé chúc mọi người học tốt,"['#sharing', '#deep_learning']"
chào mọi người hiện em đang tìm_hiểu về keras_vggface nhưng gặp lỗi về version mong được mọi người giúp_đỡ em xin cảm_ơn link git kerasvggface,"['#Q&A', '#deep_learning']"
các thuật_toán machine learning thường được sử_dụng trong khoa_học y_sinh và các use case cụ_thể ngắn_gọn và trực_quan các bạn nhé,"['#sharing', '#machine_learning']"
chào mọi người có ai muốn cùng reproduce nghiên_cứu này với không mô_hình phát_hiện thuốc dạng_viên của vaipe reproduce một phần để luyện_tập một phần vì em thấy có một chỗ lấn_cấn trong mô_hình này là sử_dụng đồ_thị có ma_trận trọng số có rank bằng <number> biết_đâu thử_nghiệm lại cho ra cái gì hay_ho thì sao paper tài_liệu chỉ ra hiện_tượng,"['#sharing', '#cv']"
"dạ em chào mọi người em có làm một đoạn code nhỏ để dự_đoán được lượng mưa độ_ẩm áp_suất chỉ trong <number> mô_hình nhưng khi truyền x_train vào mô_hình để train thì nó lại báo lỗi như hình trước đó em có thử xuất ra shape của x_train thì là 4516,30,3 tức_là 3d array đúng với yêu_cầu nhưng khi truyền vào hàm fit vẫn hiện ra lỗi nên code không chạy được anh chị có kinh_nghiệm giúp em sửa lỗi với em cám_ơn","['#Q&A', '#machine_learning']"
em chào các anh chị em mới học lập_trình python cơ_bản thôi em gặp phải bài_toán là viết code python để tự_động download <number> ảnh theo từ khóa từ google em nhờ các anh_chị gợi_ý cách làm giúp em với em cảm_ơn nhiều,"['#Q&A', '#python']"
chào mọi người mọi người cho mình hỏi thì các models như yolov8n pt yolov8s pt yolov8m pt yolov8l pt và yolov8x pt thì dựa vào đâu để chọn một model phù với dữ_liệu cho việc trainning vậy cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
em chào mọi người hiện_tại em đã học ml được một thời_gian cho em hỏi làm thế_nào để mọi người điều_chỉnh hyperparameter một_cách hiệu_quả em đang cần một nguồn để giải_thích rõ một_chút về các param đó của tất_cả các model kiểu như nó hoạt_động như thế_nào và khi nào thì cần chọn list params như nào cho hợp_lý em đọc documentation và hỏi chatgpt các kiểu rồi mà vẫn chưa clear lắm em cám_ơn,"['#Q&A', '#machine_learning']"
em chào anh việt và tất_cả mọi người hiện em là sinh_viên năm <number> có định_hướng học ai cụ_thể là machine learning theo lộ_trình thì em đã học được các thao_tác cơ_bản của python mọi người cho em hỏi bây_giờ em nên nắm vững kiến_thức toán trước rồi từ từ_học các framework library pandas numpy scikitlearn ... sau hay học framework lib trước em cảm_ơn mọi người cảm_ơn anh việt đã duyệt bài,"['#Q&A', '#machine_learning', '#python']"
em đang phải làm bài_toán phân cụm dựa trên hành_vi giao_dịch của khách_hàng vì mỗi khách_hàng chỉ có một_số kiểu giao_dịch nhất_định mà có đến tận <number> type giao_dịch khác nhau tương_ứng <number> features dữ_liệu tồn_tại rất nhiều giá_trị <number> sparse data em đã thử dùng pca svd autoencoder sau đó áp_dụng kmeans với khoảnh cách euclid hoặc mahalanobis nhưng kết_quả các cụm rất tệ tập_trung chủ_yếu vào <number> cụm em muốn xin ý_kiến giúp_đỡ của anh_chị em cảm_ơn,"['#Q&A', '#machine_learning']"
mọi người ai từng thuê server gpu online để training có_thể cho em xin <number> số kinh_nghiệm và nơi thuê giá rẻ không em chưa đi làm_nên kinh_phí hạn_hẹp mong được mọi người giúp_đỡ em xin cảm_ơn,['#Q&A']
các hàm kích_hoạt trong neural network,"['#sharing', '#deep_learning']"
<number> framework machine learning được sắp_xếp theo độ phổ_biến hi các bạn dưới đây là tổng_hợp của <number> framework library về machine learning được sắp_xếp dựa vào projectquality score được tính dựa vào nhiều metrics khác nhau trên github cũng như các package manager như pip hay conda top <number> thì hoàn_toàn xứng_đáng và không có gì phải bàn_cãi cả tuy là <number> fan ruột của pytorch nhưng mình cũng hiểu là no <number> phải là của tensorflow đợt này trên công_ty mình bọn mình cũng đang thử_nghiệm sử_dụng pytorchlightning,"['#sharing', '#machine_learning', '#python']"
<number> công_cụ ai tự viết code giúp chúng_ta dưới đây là danh_sách <number> tool ai giúp tự sinh code giúp chúng_ta <number> cái tên đầu là copilot và chatgpt thì đã quá nổi_tiếng rồi link to pdf,"['#sharing', '#nlp']"
chào mọi người chắc nhiều bạn có biết tới các nơi thân_quen sau libg scih zl với các bạn làm nghiên_cứu chắc_hẳn scih không còn quá xa_lạ trang này cung_cấp một lượng lớn báo khoa_học mà bạn có_thể tải về tuy_nhiên từ năm <number> trở_lại đây do dính_dáng tới <number> vụ kiện_cáo ấn độ trang sh tạm ngưng việc cập_nhật bổ_sung các bài báo mới báo từ <number> trở_lại đây vậy làm_sao để tìm báo khoa_học mới_đây cách <number> trả tiền để đọc báo trên trang xuất_bản ờm cách này thì không phải bàn_cãi rồi quá rõ_ràng rồi nhưng nếu vẫn muốn thì sao cách <number> tìm trong thư_viện nhất là thư_viện các đại_học nước_ngoài cách này thì hên xui không phải thư_viện nào cũng có đăng_ký dịch_vụ với nhà xuất_bản của bài báo đó để có báo mà đọc một_số thư_viện đại_học nước_ngoài có tham_gia vào chương_trình interlibrary loan mượn sách liên thư_viện cái này mỹ nên có_thể yêu_cầu bài báo với dịch_vụ này nhưng sẽ tốn kha_khá thời_gian nhanh thì vài tiếng lâu thì vài ngày có khi xui quá không có để mà đọc vậy rồi có cách nào để có báo đọc mà nhanh gọn như khi dùng sh không có chứ mời đọc cách <number> cách <number> dùng tìm_kiếm nexus trên tele gram con này là gì như tên gọi nó là một con trên ứng_dụng tele gram và chắc các bạn biết tele gram là gì rồi nhỉ thôi đùa vậy thôi con này cho phép ta tìm_kiếm báo khoa_học như ta vẫn hay làm trên trang sh nó cũng cho phép ta tìm các tài_liệu khác tương_tự như với trang lg vậy có trường_hợp tìm không ra bài muốn tìm không có chứ trong trường_hợp này hãy lập đàn cầu trời cầu cho có ai đó có_thể tìm thấy bài này và đóng_góp cho nexus ủa khoan có_thể đóng_góp sao đúng vậy có_thể đóng_góp các bài báo mà bạn tìm thấy cho nexus và như_vậy sau_này người khác có_thể tìm được bài mà bạn đã đóng_góp dông_dài vậy đủ rồi vậy đường_dẫn đâu đăng hình nóng mà không kèm link với code là một tội_ác tiểu nhị tới ngay đây <number> kênh chủ_quản của con thông_tin tin_tức kể_cả tên con đang còn sống và chạy tốt chấm me nexus_search <number> con đó đang sống và chạy tốt <number> chấm me science_nexus_bot <number> tìm trong thanh tìm_kiếm của tele gram science_nexus_bot <number> nhóm để đóng_góp chấm me nexus_aaron aaron là tên của ngườimàaicũngbiết của reddit hi_vọng bài viết này hữu_ích với các bạn đặc_biệt là các bạn đang cắm_cúi tìm báo khoa_học chào tạm_biệt các bạn,['#sharing']
mọi người cho mình hỏi nếu mình mua gói colab pro của google colab thì có còn bị giới_hạn thời_gian sử_dụng gpu như bản free không colab,['#Q&A']
visualization in deep learning hi các bạn hôm_nay mình vừa đọc được <number> bài viết rất hay về trực_quan_hóa dữ_liệu trên medium mình xin chia_sẻ lại với các bạn bài viết đây hi_vọng các bạn vn không bị chặn bài viết đề_cập về các chủ_đề sau vì_sao chúng_ta cần trực_quan_hóa trong deep learning trực_quan_hóa có tác_dụng như thế_nào vai_trò của trực_quan_hóa dữ_liệu trong deep learning <number> bài viết dài nhưng vô_cùng thú_vị link to article,"['#sharing', '#data']"
dạ em chào anh_chị hiện em đang học năm <number> khoa toántin hcmus dự_định học chuyên_ngành xstk em có nghe thầy cô em khuyên là nên học thêm về code để sau_này ra trường có việc_làm em đã học qua một môn về code trên trường viết hàm kiểm_tra số đó phải số chính_phương không tính tổng em nghe thầy cô em khuyên là nên học thêm nhiều về code để sau_này kết_hợp với kiến_thức xstk để tìm việc_làm vậy anh_chị cho em hỏi học đến mức_độ nào để gọi là biết code vậy em thật_sự mới tiếp_xúc với code cấp <number> học pascal và 1môn code trên đh nên mong anh_chị giúp em giải_đáp thật chi_tiết và dễ hiểu em cảm_ơn anh_chị rất nhiều,['#Q&A']
yoshua bengio cha_đẻ của relu người đề_xuất kĩ_thuật gradient clipping và hơn thế nữa hôm_nay chúng_ta tiếp_tục đến với <number> cái tên khác có rất nhiều đóng_góp cho sự phát_triển của ai ông là yoshua bengio <number> số những đóng_góp tiêu_biểu nhất của ông có_thể kể đến relu xavier glorot initialization gradient clipping graph attention network rnn encoderdecoder chắc_hẳn rất nhiều người trong chúng_ta sử_dụng relu mà không nhớ cha_đẻ của nó là ai,['#sharing']
mọi người ơi mình hỏi chút hàm if __name__ __main__ có tác_dụng gì vậy,"['#Q&A', '#python']"
em đang có vài ngàn tấm hình và phải tự_động gán nhãn trên roboflow em đang tìm cách để nó tự_động gán nhãn từ việc học <number> số_lượng hình ban_đầu nhưng chưa biết cách để nó tự_động làm mọi đã làm về phần này cho em chút góp_ý với,"['#Q&A', '#data']"
em chào anh việt và các anh_chị cùng các bạn khác trong nhóm em hiện là sinh_viên năm <number> ngành ds của một trường vn ban_đầu có hướng theo nlp nhưng sau khi tìm_hiểu thì cảm_thấy mình thích phần ai generator hơn mọi người cho hỏi là nếu theo ai generator thì nên hướng nghiên_cứu hay đi làm doanh_nghiệp và bên vn cx như nước_ngoài thì tình_hình job của ai generator như thế_nào em xin cảm_ơn mọi người,['#Q&A']
ai giúp với được,['#Q&A']
cho em hỏi sao chỗ minimize theta mình lấy trace vậy,"['#Q&A', '#machine_learning']"
chào mọi người hiện_tại là sv năm nhất ngành cntt và đang có định_hướng theo ai engineer các chị đi trước có_thể cho xin lời khuyên và lộ_trình cụ_thể và nên học tiếng trung hay nhật để phục_vụ cho định_hướng công_việc này em cảm_ơn,['#Q&A']
nhóm mình cũng nhiều bạn nhắc đến paper có bạn nào có hứng đọc và reproduce <number> paper không paper mà mình muốn đề_xuất là,['#Q&A']
có ai đang học machine learning là sinh_viên của hcmus không mình muốn tìm một_vài bạn lập nhóm cùng giúp_đỡ nhau học học một_mình khá buồn,['#Q&A']
hi_anh chị em muốn hỏi rõ hơn về contrastive loss function như ảnh dưới nếu xét như công_thức bên dưới thì khi <number> data points là dissimilar <number> max <number> mdw <number> do max dw khi <number> data points là similar <number> vậy trong cả <number> trường_hợp thì vế phải của công_thức luôn bằng <number> hay em có sai chỗ nào mong anh_chị chỉ giúp em cảm_ơn,"['#Q&A', '#math']"
em chào anh việt và mọi người em đang là sinh_viên đh năm <number> hiện_tại em đang implement lại code của <number> paper phục_vụ cho dự_án cá_nhân tuy_nhiên trong quá_trình lại gặp <number> số vấn_đề phát_sinh vì_vậy em muốn tìm <number> mentor cho mình anh chị các bạn đã có nhiều kinh_nghiệm ... để có_thể trao_đổi những vấn_đề bản_thân đang còn thắc_mắc do em là người mới trong ngành cũng có vài vấn_đề em đã hỏi trên đây nhưng mà cũng không hỏi mãi như_vậy được nếu được thì em mong có_thể tìm được mentor khu_vực ngoài hn vì em đây cũng tiện để em có_thể hỏi các vấn_đề khác như lộ_trình học vấn_đề công_việc ... ngoài này nếu được em xin gửi mentor chút hậu_tạ anh chị các bạn ... có_thể cmt xuống phía dưới để em chủ_động liên_hệ em xin cảm_ơn mọi người nhiều,['#Q&A']
tổng_hợp các kiểu dữ_liệu trong python tài_liệu <number> trang dưới đây tổng_hợp các kiểu dữ_liệu trong python mà các bạn cần biết link to pdf,"['#sharing', '#python']"
em muốn tạo <number> trang website đơn_giản mà có_thể truyền tham_số vào hàm test em có khoan tròn đỏ trong ảnh thì em phải tìm_hiểu về gì nếu có ai rành về khoản này ib trực_tiếp giúp em được không,['#Q&A']
cần lắm người cứu giải đề dùm python tìm yếu ảnh_hưởng đến giá xe linear regression nhiều biến inbox mình gửi đề_nhe,"['#Q&A', '#machine_learning']"
em đang tập train yolov8 em có sửa augmentation <number> chỗ hyperparameter trong default yaml class albumentation trong augment py nhưng chưa chạy được câu_lệnh vì yolov8 em có search thì không có argument cfg anh chị bạn nào từng fine tune các para này trong yolov8 rồi giúp em em cảm_ơn,"['#Q&A', '#deep_learning']"
chào admin và mọi người có một_số câu hỏi sau khi build một model thì sẽ cho bộ data gồm train và test vào <number> thư_mục khác nhau khi chạy sẽ chạy lần_lượt train và test như_vậy mỗi lần muốn test them <number> số data thì phải chạy lại từ đầu bao_gồm cả bước train nữa vậy làm_sao để có_thể mỗi lần test ko cần chạy lại model từ đầu không quá_trình trainning dùng trên laptop cá_nhân khá là lâu và nóng máy quạt kêu rất to nên nghe rất xót máy vậy có cách nào sau lần train đầu_tiên thì các lần sau có_thể train nhẹ_nhàng hơn không chứ chạy lại tất_cả từ đầu khá mất thời_gian và yếu máy với bài_toán thời_gian thực và data lấy từ camera thì mọi người thường sử_dụng model nào hay thuật_toán nào để thời_gian hoàn_tất quá_trình phân_loại phát_hiện đối_tượng ... 3s đổ về ví_dụ như phát_hiện biển số xe khi đã demo được code trên laptop thì mọi người triển_khai nó ra thực_tế như nào và quá_trình chăm_sóc model sau triển_khai thực_tế thì mọi người thường thực_hiện như nào em có một_số thắc_mắc như_vậy mong mọi người giải_đáp giúp xin cảm_ơn,"['#Q&A', '#machine_learning']"
<number> hàm vô_cùng hữu_ích và phổ_biến trong python hi các bạn dưới đây là tổng_hợp <number> hàm được sử_dụng rất nhiều trong python chúng giúp rút_gọn các hàm cồng_kềnh và làm cho code của các bạn trở_nên đẹp_mắt hơn rất nhiều hàm lambda hàm map hàm filter hàm zip hàm enumerate cá_nhân mình sử_dụng lambda zip và enumerate cực nhiều,"['#sharing', '#python']"
mn cho mình hỏi về cái admin trong django với vấn_đề là nếu tạo model django sẽ tự sinh bảng và view rất ok nhưng nếu bảng có sẵn rồi chỉ muốn nó hiển_thị ra thôi_thì cần động_chạm vào những file nào theo em tìm_hiểu thì bắt bụôc phải động vào file view để query raw sql nhưng để hiển_thị ra đc phải động vào file admin py và cho nó register nhưng mà search hướng_dẫn đều đòi lấy file từ models py ra mà nếu khai_báo trong models thì nó lại lỗi vì tên bảng đã tồn_tại mong cao nhân nào chỉ giúp em giờ code sao,"['#Q&A', '#python']"
em chào anh_chị em đang làm đồ_án về ocr dùng transformer để nhận_dạng tài_liệu khoa_học em đang tìm_hiểu phần tối_ưu_hóa tốc_độ bằng cách convert model pytorch sang tensorrt nhưng mà vẫn chưa làm được anh_chị và các bạn ai có_thể hướng_dẫn em chi_tiết phần này được không em xin cảm_ơn và hậu_tạ,"['#Q&A', '#cv', '#python']"
em xin chia_sẻ với mọi người project deeplearning đầu_tiên của em sử_dụng pytorch để phân_loại animals link github mong mọi người cho em xin nhận_xét để em cải_thiện em cảm_ơn mn,"['#sharing', '#deep_learning']"
em chào các anh_chị em đang có một vấn_đề nhỏ khi thao_tác với dữ_liệu mong được các anh_chị giúp_đỡ em đang có <number> số file excel đuôi xls em không_thể đọc được file này bằng python em cũng đã tìm_kiếm trên mạng <number> số cách nhưng không đem lại hiệu_quả rất mong ac giúp_đỡ em cách đọc file excel đuôi xls hoặc chuyển file này sang dạng csv em cảm_ơn mn,"['#Q&A', '#data', '#python']"
em chào anh việt và mọi người trong nhóm hiện em đang thực_hiện một project về đề_tài road extraction em đang tìm_hiểu về phương_pháp deep residual unet và tham_khảo code qua link github và đang gặp vấn_đề về dữ_liệu đầu_vào để chạy code em mong anh_chị trong nhóm đã từng thực_hiện đề_tài này hay đã chạy thử chương_trình thì có_thể giúp em phần dữ_liệu vào và gợi_ý các hướng cải_thiện cho mô_hình em xin cảm_ơn,"['#Q&A', '#cv']"
chào mọi người hiện_tại em đang làm dự_án dự_đoán doanh_thu phim và cũng là dự_án đầu_tiên của em em đang gặp lỗi khi vẽ biểu_đồ doanh_thu khi sử_dụng distplot thì vẽ bình_thường nhưng khi em chuyển sang histplot hay displot thì nó bị như ảnh là sao em cảm_ơn,['#Q&A']
các bạn nhất là ai đang đi làm rồi cho mình hỏi các bạn take notes khi đọc <number> tài_liệu mới khoá học mới hoặc <number> thư_viện framework mới kiểu gì vậy mong mọi ngừoi chia_sẻ cám_ơn mọi người,['#Q&A']
có ai trong nhóm từng theo học khóa học data analyst hoặc ba của mindx chưa em xin review với,"['#Q&A', '#data']"
khóa học deep learning for nlp tại lmu munich hi các bạn cách đây <number> tuần và <number> tuần mình đã lần_lượt chia_sẻ <number> khóa học của đại_học munich lmu ngôi trường luôn nằm trong top <number> các trường đại_học tốt nhất thế_giới trong tất_cả các bạn xếp_hạng danh_tiếng <number> khóa học này bao_gồm introduction to machine learning introduction to machine learning lần này mình xin chia_sẻ với các bạn khóa học chuyên_sâu về mảng nlp khóa deep learning for nlp của lmu tương_tự như <number> khóa học trước khóa học này ngay từ đầu đã được thiết_kế theo hướng khuyến_khích tự học thông_qua việc cung_cấp đầy_đủ những tài_liệu cần_thiết bao_gồm <number> điểm trừ của khóa này là cheatsheet và exercise chưa có được cập_nhật tuy_nhiên phần lý_thuyết thì khá là cập_nhật bert và gpt đều được đưa vào link to course,"['#sharing', '#nlp']"
version <number> nhập_môn_học máy và khai_phá dữ_liệu của đại_học bkhn hi các bạn <number> vài tuần trước mình có chia_sẻ với các bạn giáo_trình môn_học nhập_môn_học máy và khai_phá dữ_liệu của đại_học bách_khoa hà_nội với <number> phiên_bản khác nhau bài giảng của thầy thân quang khoát slide tiếng anh video tiếng việt bài giảng của thầy ngô văn linh slide tiếng việt hôm_nay mình xin chia_sẻ với các bạn phiên_bản cuối_cùng cũng của môn_học này cùng học_phần luôn của thầy nguyễn nhật quang phiên_bản này thì slide cũng hoàn_toàn là bằng tiếng việt các bạn nhé link to slide,"['#sharing', '#machine_learning']"
chào mn hiện đang có đề_tài ekyc nhưng tìm trên mạng không thấy có source code nào tham_khảo và cũng không biết keyword nào về việc verify ảnh chụp webcam và ảnh trên cccd biết ac có ai có keyword hoặc bài viết cho xin tham_khảo được đây chỉ là assignment của thôi cảm_ơn mn t4r,['#Q&A']
chào mọi người đang bí giải_pháp cải_thiện độ chính_xác của model đọc biển số và muốn có_thể xử_lý được trong thời_gian thực khi sử_dụng camera trên mobile luôn vì thấy một_vài thư_viện ocr khi biển bị nghiêng hoặc mờ quá thì đọc không được chính_xác lắm nên đang thử tách từng ký_tự ra bằng object detection nốt và classify sau và thường sử_dụng tensorflow để training mọi người có giải_pháp nào giúp với cảm_ơn,"['#Q&A', '#cv']"
hi các anh_chị trong group em có một_vài vấn_đề về định_hướng nghề_nghiệp mong sẽ có được lời khuyền từ anh_chị hiện em đang là sinh_viên năm <number> và sẽ chuẩn_bị đi thực_tập theo chương_trình của khoa tuy nhien các công_ty trong danh_sách của khoa lại không có công_ty nào tuyển vị_trí liên_quan đến ai ml và em cũng biết hiện các công_ty bên ngoái khác hầu_như cũng không có quá nhiều cơ_hội cho các bạn intern hay fresher dẫu biết học và làm gì thì phải cố_gắng đến cùng tuy_nhiên ra trường ai cũng phải đi làm để kiếm sống các vị_trí ai ml cho các bạn mới thực_sự rất ít hay có_thể nói là không có em thì cũng sắp ra trường và cũng không_thể mù_quáng đâm_đầu chờ_đợi mà không biết tương_lai nó đi đến đâu được dẫu biết các vị_trí it khác cũng cạnh_tranh không kém nhưng ít_ra còn các công_ty vẫn có nhu_cầu và còn tuyển mở ra một_vài cơ_hội cho người mới như em vậy mọi người cho em hỏi em có nên chuyển_hướng học sang cái khác không tiếng anh của em mức tốt hoàn_toàn có khả_năng tự học tốt và không ngại học lại một thứ từ đầu bài viết của em có_thể hơi dài mong mọi người có_thể đọc hết em nghĩ một_vài bạn cũng sẽ vào trường_hợp như em em cảm_ơn và sẽ ghi_nhận mọi lời khuyên của mọi người em cảm_ơn,['#Q&A']
em xin phép anh việt và mọi người hiện_tại em đang làm <number> project về phát_hiện ngôn_ngữ cơ_bản nhưng lại bị xảy ra lỗi không đọc được file dataset để huấn_luyện và em cũng kbt là do đâu nên mong mọi người giúp_đỡ,['#Q&A']
em chào mn mn có ai đã làm vợi bộ dữ_liệu ims bearing data về <number> ổ_bi để dự_đoán sự hư_hỏng của nó chưa mn cho em xin ý_kiến về đề_tài và thuật_toán để sử_dụng với em cám_ơn,"['#Q&A', '#data']"
tổng_hợp các câu hỏi phỏng_vấn data science data analysis machine learning và deep learning hi các bạn dưới đây là tổng_hợp các câu hỏi phỏng_vấn dành cho các bạn theo_đuổi mảng data science cụ_thể chúng_ta có <number> câu hỏi về thống_kê <number> câu hỏi về data science câu cuối đáng nhẽ phải xếp vào deep learning <number> câu hỏi data analysis phần_lớn xếp vào data science thì mình thấp hợp_lý hơn <number> câu hỏi về machine learning <number> câu hỏi về deep learning bỏ_qua việc phân_chia vào các topic không hợp_lý lắm thì đây là <number> tài_liệu chất_lượng giúp các bạn ôn_tập lại kiến_thức cũng như chuẩn_bị cho các buổi phỏng_vấn xin việc nhớ lưu lại các bạn nhé link to pdf,['#sharing']
em chào mọi người hiện_tại em đang muốn nâng cao chất_lượng hình_ảnh ví_dụ như làm nét ảnh hơn ... thì có thuật_toán thư_viện nào hỗ_trợ không mọi người giới_thiệu cho em với em cảm_ơn,"['#Q&A', '#cv']"
em chào mọi người mọi người cho hỏi có cách nào delete các dòng bị lỗi type như này không em dùng file csv với thư_viện pandas em cảm_ơn mọi người,"['#Q&A', '#python']"
em chào mọi người trong group em là sinh_viên năm cuối đang học chuyên_ngành đtvt của đh bk hcm em theo hướng nhúng và có ý_định nghiên_cứu và học master hướng ai ds mọi người cho em hỏi là các trường uni úc can hay eu có cho xét tuyển hay cấp học_bổng bán phần cho sinh_viên thuộc khối ngành kỹ_thuật không phải cs dành cho chương_trình master cs không em xin cảm_ơn,['#Q&A']
khi mọi người đọc paper thì có trick gì không hay chỉ đọc từ đầu tới cuối em đọc paper gặp rất nhiều danh từ riêng chưa biết chưa kể tới tiếng anh nên đọc rất chậm và cũng không biết nên focus vào phần_nào của paper mong anh_chị cho em lời khuyên em cảm_ơn,['#Q&A']
chào mọi người cho em xin hỏi về bài_toán text detection là đang cố tạo một full connection layer để detect nhưng mà output của một image có_thể có ít hoặc nhiều bounding box vì_vậy nên em không biết làm_sao để detect ra output như này mong mọi người chỉ,"['#Q&A', '#deep_learning', '#cv']"
các bạn đã thử chat chit với chatgpt chưa chatgpt là một ứng_dụng có khả_năng trả_lời rất giống con nguời và có một kho kiến_thức trong nhiều lĩnh_vực khác nhau như làm thơ soạn nhạc và thậm_chí là lập_trình hãy cùng thử tìm_hiểu cách cách áp_dụng công_nghệ của chatgpt vào việc xây_dựng chatbot của riêng chúng_ta trong bài hôm_nay,"['#sharing', '#nlp']"
chào mọi người hôm_nay cho em xin hỏi về quá_trình huấn_luyện mô_hình trên các device cpu mps gpu em hiện_tại đang xài macos và set device to mps để huấn_luyện các mô_hình dl để chạy nhanh hơn so với cpu nhưng em thấy nó vẫn chạy khá chậm vì nó không set được các num workers để có_thể chạy song_song trên các luồng điều này có_thể làm nó chạy không nhanh bằng gpu của cuda nvidia em biết có rất nhiều cách chạy như trên colab hay kaggle nhưng em muốn chạy locally trên macos không biết mn có giải_pháp nào giúp mô_hình chạy nhanh hơn không vì cuda nvidia không hỗ_trợ cho mac m2 hay sao em xin cảm_ơn,['#Q&A']
hôm nọ mình mới đọc được bài về tuyển_dụng nhân_sự ai đang rất khó và cạnh_tranh mình theo hướng học_thuật và <number> năm sản_xuất dc <number> paper nhưng để nói là chất_lượng và tính mới thì có mình tự thấy không được cao việc này có được coi là kinh_nghiệm mà điền vào cv hay không và liệu việc sản_xuất paper có được đánh_giá cao khi tuyển_dụng hay không,['#Q&A']
chào mọi người em muốn xin lời khuyên về định_hướng em đang là sinh_viên năm <number> hiện em đang muốn bắt_đầu học về ai nhưng kiến_thức nền về toán của em không được tốt lắm em còn <number> năm nữa là ra trường em đang rất phân_vân giữa tiếp_tục học về web app rồi từ từ trau_dồi ai hay quyết_tâm tập_trung hẳn vào ai rất mong nhận được lời khuyên của mọi người em xin cảm_ơn,"['#Q&A', '#machine_learning']"
"chào việt và mn đang có <number> bài_toán yêu_cầu áp_dụng phân cụm ahc vào dataset và vẽ biểu_đồ dendrogram đã chạy ra biểu_đồ rồi nhưng thấy sai sai mn có xem làm đúng chưa và cần khắc_phục chỗ nào data down từ link này đây là code của import matplotlib pyplot as plt from scipy cluster hierarchy import dendrogram linkage import pandas as pd gender_name pd read_csv name_gender_dataset csv encoding unicode_escape header none selected_column <number> <number> 3,4 data list zip gender_name selected_column linkage_data linkage data method ward metric euclidean dendrogram linkage_data plt show kết_quả ra như hình dưới em cảm_ơn mn",['#Q&A']
chào mọi người anh việt nhờ mọi người cho mình lời khuyên với chả_là mình có_học qua khóa ml và dl trên coursera và đang học khóa dl with pytorch cũng như có làm một_vài project nhỏ hướng sắp tới của mình là ml và cụ_thể về deep reinforcement learning mặt dù mình đã học qua các khóa trên nhưng vẫn còn mơ_hồ về cách train mô_hình vậy nên nhờ mn recommend những course project youtube book and website đáng để học được những kỹ_năng trên bằng projects với cũng như câu hỏi trên thì nhờ mọi người giới_thiệu cho những dự_án để cải_thiện kỹ_năng code với framework pytorch và liên_quan đến deep reinforcement learning càng quá tốt vì là newbie và cũng là trái ngành nên câu hỏi có gì ko đúng xin mn chỉnh_sửa thêm cảm_ơn mn,"['#Q&A', '#machine_learning', '#python']"
decision tree luôn bị overfitting và đây là cách ngăn_chặn hi các bạn có_lẽ hầu_hết các bạn không còn xa_lạ gì với decision tree <number> trong số các thuật_toán machine learning cơ_bản cũng như scikitlearn thư_viện quốc dân về machine learning mà ko ai học về ai data science lại không biết trong scikitlearn decision tree mặc_định sẽ được xây_dựng cho đến khi tất_cả các node lá đều chỉ chứa <number> class mà thôi pure khi đó chúng_ta đạt được <number> accuracy bộ train tất_nhiên với các bạn đã học về machine learning chúng_ta đều không mấy vui_vẻ với con_số này vì điều đó có_nghĩa_là mô_hình của chúng_ta <number> bị overfitting khả_năng tổng_quát_hóa thấp poor generalization vậy câu hỏi đây là làm_sao để ngăn_chặn điều này xảy ra câu trả_lời chính là dựa vào costcomplexitypruning cpp <number> điều rất may_mắn đó là đây cũng là <number> parameter của decision tree trong scikitlearn cpp kết_hợp <number> yếu_tố để rút_gọn decision tree cost số_lượng data bị phân_loại nhầm complexity số_lượng node kết_quả như các bạn có_thể thấy hình phía dưới original article,"['#sharing', '#machine_learning']"
em chào mọi người em đang tìm_hiểu về ngành ai theo em biết khi học đến <number> trình_độ thì mình sẽ phải lựa_chọn theo_đuổi lĩnh_vực nhỏ như nlp computer vision ... cho em hỏi mỗi lĩnh_vực sẽ làm về cái gì mọi người có kinh_nghiệm gì khi chọn giữa các lĩnh_vực này không em đang khá thích computer vision nhưng em thấy công_ty việt nam dạo này hay tuyển_dụng nlp thì không biết là có phải do cv khá khó kiếm việc việt nam không em cảm_ơn mọi người nhiều,['#Q&A']
<number> câu hỏi lập_trình python cơ_bản giúp chuẩn_bị cho technical interview hi các bạn mình xin chia_sẻ với các bạn tuyển_tập <number> câu hỏi lập_trình python cơ_bản có bao_gồm đáp_án những câu hỏi này sẽ giúp các bạn chuẩn_bị tốt hơn cho các technical interview hay coding challenge cho các vị_trí như data scientist machine learning engineer ai engineer hay bất_kì vị_trí nào có liên_quan đến python link to pdf,"['#sharing', '#python']"
em chào mọi người em là sinh_viên ngành cntt hiện_tại em đã học xong base cơ_bản về machine learning và sắp tiến vào các nhánh nhỏ của ai theo mn thị_trường thế_giới nói_chung và thị_trường việt nam nói_riêng nlp hay cv đang được chuộng hơn em cảm_ơn anh việt và mọi người,['#Q&A']
<number> datasets để xây_dựng các project data science machine learning hi các bạn dưới đây là tổng_hợp <number> dataset để giúp các bạn luyện_tập cách phân_tích dữ_liệu và xây_dựng các mô_hình machine learning được phân_loại thành các mức_độ từ dễ đến khó bao_gồm beginner level <number> dataset đầu intermediate level <number> dataset tiếp_theo advanced level <number> dataset cuối link to datasets,"['#sharing', '#data']"
chào mọi người em hiện là một sinh_viên năm nhất đang học ngành khoa_học máy_tính ban_đầu em định học chuyên_ngành ai vào năm <number> nhưng vào group thấy mọi người bảo thị_trường cạnh_tranh khó kiếm việc nên bây_giờ em định theo hai ngành này data science cloud computing em bắt_đầu học code bằng python và lên đại_học thì trường dạy thêm em nên theo ngành nào trong <number> ngành này công_ty nào vn sẽ cần ngành đó nếu ngành đó thì em nên làm gì trong phần còn lại năm nhất và mn người có_thể phân_tích thị_trường việc_làm của ngành it vn không cảm ơn mọi người rất nhiều,['#Q&A']
<number> thư_viện giúp tự_động hóa eda tasks trong các data science projects hi các bạn trong các project về data science eda exploratory data analysis phân_tích khám_phá dữ_liệu là một bước vô_cùng quan_trọng nó giúp chúng_ta có_thể hiểu được dữ_liệu mà mình đang làm_việc từ đó giúp cho quá_trình lựa_chọn và xây_dựng mô_hình trở_nên hiệu_quả hơn tuy_nhiên cũng phải thừa_nhận đây là <number> bước khá tẻ_nhạt để giúp vơi đi nỗi đau cho các data scientist dưới đây là <number> thư_viện giúp tự_động hóa eda nhằm giúp cho công_việc của các data scientist trở_nên bớt nhàm_chán và hiệu_quả hơn trong <number> thư_viện này thì mình đung pandasprofiling,"['#sharing', '#data']"
mọi người cho em hỏi với trên mạng có những web nào có_thể cho mình các model sẵn mình chỉ cần bỏ dữ_liệu và train thôi không vậy em có ý_định sử_dụng convnext và densenet để phân_loại ảnh,"['#Q&A', '#deep_learning', '#cv']"
mọi người có ai có kinh_nghiệm build model diffusion model cho mình hỏi chút mình thấy model tốn phần_cứng rất nặng để train nhưng khi mình đọc theory với implement lại code của condition diffusion thì thấy model nó khá là đơn_giản khi dùng <number> bước chính là add noise và denoise cũng chỉ là tính_toán biểu_thức cộng với vae unet cũng không nặng tới vậy vậy sự tính_toán phức_tạp của model này nằm đâu nhỉ mong mọi người giải_đáp giúp mình,['#Q&A']
em là sinh_viên đang tìm_hiểu về computer vision và em muốn thực_hiện một project nhỏ ý_tưởng của em cung_cấp data là những bức ảnh tỉ_lệ cố_định sau đó sẽ tự nhận_diện và lấy các value đấy rồi cung_cấp ra thành <number> file csv em đã tìm_hiểu về ocrbased parsing thì không biết nó có phải phương_pháp hiệu_quả nhất cho mục_đích của em không em mong nhận được thêm những lời khuyên từ mọi người em xin cảm_ơn,"['#Q&A', '#deep_learning', '#cv']"
trực_quan_hóa mô_hình machine learning với yellowbrick hi các bạn trong các post trước về các thư_viện python trực_quan_hóa dữ_liệu mình đã từng nói qua về thư_viện này rồi yellowbrick là <number> thư_viện giúp trực_quan_hóa các mô_hình machine learning <number> cách vô_cùng hiệu_quả yellowbrick mở_rộng api của scikitlearn từ đó giúp thực_hiện các task như model selection hay hyperparameter tuning trở_nên đơn_giản hơn rất nhiều <number> thư_viện rất thú_vị và dễ sử_dụng các bạn nhé link,"['#sharing', '#python']"
em đang là sinh_viên năm nhất và có định_hướng theo ml nhưng em không biết bắt_đầu_từ đâu nên học như thế_nào cho đúng rồi nên làm gì để cải_thiện kĩ_năng định_hướng tương_lai ra sao em có search tìm tài_liệu thì khá nhiều tài_liệu em đang hoang_mang không biết cái nào là chất_lượng để học mọi người giúp em cho em lời khuyên với em chân_thành cảm_ơn,['#Q&A']
dạ chào anh việt và mọi người hiện_tại em đang làm đồ_án dự_báo_công_suất phát nhà_máy_điện mặt_trời bằng mô_hình lstm bộ dữ_liệu em đang có là bức_xạ nhiệt_độ môi_trường nhiệt_độ tấm pin và công_suất phát của nhà_máy em học điện cũng mới tìm_hiểu mảng này nên mọi người ai có làm rồi có ý_tưởng hay tài_liệu gì chia_sẻ giúp em với em cám_ơn mọi người,"['#Q&A', '#deep_learning']"
chào mọi người từ đâu mình có hệ_thức b0 và b0 như dưới đây,"['#Q&A', '#math']"
iconic paper very deep convolutional networks for largescale image recognition nơi vgg16 được trình_làng hi các bạn đã theo mảng ai thì việc phải đọc các research paper là việc mà dù chúng_ta có muốn hay không thường là vế sau thì cũng vẫn phải làm thời mình còn đi học thì ai chưa phát_triển nhanh và mạnh như bây_giờ mỗi năm thường chỉ có <number> vài paper thật_sự đáng chú_ý mình muốn bắt_đầu làm <number> series giới_thiệu về các paper kinh_điển đóng_góp vào sự phát_triển mạnh_mẽ của ai như các bạn thấy ngày_nay để mở bát thì mình xin giới_thiệu paper đầu_tiên very deep convolutional networks for largescale image recognition được công_bố vào năm <number> bởi visual geometry group đến từ đại_học oxford các bạn cũng có_thể hiểu cái tên vgg được lấy từ đâu rồi đấy mô_hình được giới_thiệu trong paper còn được biết đến với cái tên vgg16 để phân_biệt với <number> version khác là vgg11 và vgg19 vgg16 cũng là quân của cuộc thi ilsvrc năm <number> cuộc thi thường_niên nối tiếng diễn ra trong khoảng thời_gian từ <number> vgg16 có những điểm gì nổi_bật đây là <number> trong số các mô_hình đi tiên_phong trong việc sử_dụng các convolution layer với filter có kích_thước nhỏ điều này giúp cho mô_hình tối_ưu_hóa memory usage khi đem so_sánh với các mô_hình tiền_nhiệm sử_dụng các filter có kích_thước lớn cho đến ngày_nay dù đã ra_mắt được <number> năm vgg16 vẫn được sử_dụng rộng_rãi dưới dạng backbone cho các mô_hình khác <number> trong số các paper mình và các bạn học phải đọc đi đọc lại rất nhiều lần ngày_nay thì chúng_ta có rất nhiều mô_hình tốt hơn nhưng thời_điểm gần <number> năm trở về trước không có nhiều mô_hình có_thể vượt mặt vgg16 link to paper,"['#sharing', '#deep_learning']"
summarytools thay_thế hoàn_hảo cho hàm describe của pandas trên jupyter notebook mình thì không phải fan của jupyter notebook nhưng cái gì hay thì vẫn phải share chỉ với <number> dòng duy_nhất chúng_ta sẽ có được <number> bảng tóm_tắt dữ_liệu đầy_đủ và chi_tiết,['#sharing']
chào cả nhà mình chạy dữ_liệu time series dự_báo phân_loại class <number> và <number> theo ngày trong lúc backtest dữ_liệu có những lúc model dự_đoán một class nào đó với xác_suất <number> tuy_nhiên trong lúc chạy vào thực_tế thì rất ít thấy model dự_đoán một lớp nào đó có xác_suất cao giống như_vậy mà nó chỉ dự_đoán với xác_suất quanh <number> <number> mình nghĩ rằng có_thể model của mình bị data leakage nhưng mình kiểm_tra thì nó không bị như_vậy các cao nhân nào có_thể góp_ý cho với em cảm_ơn,['#Q&A']
chào anh việt và mọi người mình là bình mình cũng vừa vào nhóm <number> thời_gian hiện mình muốn tìm <number> mentor đồng_đội hoặc team để học_hỏi cùng học về ds và build model mình chia_sẻ chút về mình background mình là kinh_tế mình có_thể sử_dụng sql và python mình có kinh_nghiệm làm web scrping nên là về việc xử_lý thu_thập dữ_liệu mình cũng tương_đối thành_thạo mục_tiêu tìm mentor và đồng_đội là cùng học hoặc học_hỏi từ bạn mentor đồng_đội về ds và build model vì đây là cái mình còn kém mình muốn học_hỏi để tự nâng cao build model cho mình nên hi_vọng được kết_nối với mọi người dưới đây là <number> package mình đã viết xong dùng để thu_thập các dữ_liệu liên_quan đến chứng_khoán theo thời_gian thực ai hứng_thú hoặc cũng có mục_đích giống mình thì kết_nối với nhau nhé mình có clip về cách sử_dụng và hướng_dẫn kết_hợp sử_dụng trực_tiếp trong excel ai muốn xem thì mình nhắn dưới cmt sau nhé lời cuối cảm_ơn anh việt và mọi người đã xem,['#Q&A']
bộ đôi machine learning và deep learning của nhà grokking đây là <number> quyển sách về machine learning và deep learning vô_cùng nổi_tiếng của grokking và được đánh_giá rất cao về mặt thị_giác khi các khái_niệm được giải_thích vô_cùng dễ hiểu bởi các hình_ảnh minh_họa grokking machine learning grokking deep learning quyển machine learning là nhờ bạn dương huy_hoàng chia_sẻ <number> post trước chứ mình tìm quyển này cũng không nổi,['#sharing']
<number> thuật_ngữ phổ_biến trong ai,['#sharing']
hãy hạn_chế sử_dụng juputer notebook trừ khi bạn mới làm_quen với python hi các bạn với các bạn đang học và làm_việc với python chắc các bạn không còn xa_lạ gì với jupyter notebook nền_tảng giúp các bạn chạy code trên các web browser jupyter notebook thì rất phổ_biến và được ưa_chuộng bởi sự thuận_tiện của mình điều này thì không có gì để phải bàn_cãi cả tuy_nhiên cá_nhân mình thì không bao_giờ dùng jupyter notebook trừ khi mình chấm bài cho các bạn học_viên và các bạn ấy nộp bài trên jupyter notebook thì mình buộc phải xài mình có_thể liệt_kê <number> vài lý_do dưới đây jupyter notebook được thiết_kế theo kiểu lập_trình hướng cấu_trúc code chạy tuyến_tính từ trên xuống dưới trong khi sau_này các bạn đi làm tất_cả các project đều được thiết_kế theo huớng lập_trình huớng đối_tượng oop các bạn it thì chắc_chắn không còn xa_lạ gì với thuật_ngữ này các bạn không_thể debug với jupyter notebook các bạn làm các project trên trường hay bài_tập hàng tuần thì không nói làm gì nhưng sau_này các bạn đi làm vào các project thực_sự code có_thể nằm hàng chục đến hàng trăm file khác nhau không biết cách debug với các ide không khác gì án tử cho các lập_trình_viên mình không nói_riêng gì ai data science đâu nhé mình đang nói về cntt nói_chung ấy jupyter notebook rất được ưa_chuộng các trường đại_học cũng như các khoá học ngày_xưa mình học master các thầy cũng toàn xài jupyter notebook lý_do chính là vì sự tuyến_tính từ trên xuống dưới của nó giúp giảng_viên dễ minh_hoạ từng bước nhưng các bạn học mãi rồi cũng sẽ phải đi làm không biết sử_dụng các ide sẽ là <number> sự thiệt_thòi lớn cho các bạn khi so_sánh với các candidate khác chưa xét về thuật_toán hay logic nhé chỉ nói về code thuần_tuý thôi tất_cả các lớp mình dạy_học mình không bao_giờ code bất_kì <number> dòng code nào trên jupyter notebook vì mình muốn luyện cho mọi người quen với việc code trên ide mình cũng luôn khuyến_khích các bạn học_viên hạn_chế xài tréo ngoe thay thì tất_cả các lớp quá <number> học_viên của mình luôn nộp bài với file jupyter notebook mình không có bài_xích gì jupyter notebook cả đây thực_sự là <number> nền_tảng tuyệt_vời tuy_nhiên nó tuyệt_vời trường_học và các bạn thì sẽ không đó mãi được,['#sharing']
em đang code thuật_toán cnn1d và đang gặp lỗi này em đã lên mạng tìm lỗi để sửa nhưng vẫn không được ai biết lỗi có_thể chỉ em sửa được không em cám_ơn rất nhiều đây là link colab nguyên bài code của em,['#Q&A']
em chào anh việt và mọi người hiện_tại công_ty có cung_cấp cho em một máy_chủ có gpu và một bộ data có khoảng 500k ảnh của 100k người khác nhau em đang dùng một model face recognition để training nhưng với bộ data như thế_thì train rất lâu mọi người cho em hỏi có cách nào để tối_ưu khi training như_vậy không em cảm_ơn,"['#Q&A', '#cv']"
fix các lỗi liên_quan đến medium các bạn ơi trong thời_gian vừa_qua mình có chia_sẻ <number> vài post có nguồn từ medium bao_gồm gần <number> project machine learning với sample code bằng python <number> data science machine learning project với code bằng python đi kèm với giải_thích <number> project python với source code đi kèm trong quá_trình chia_sẻ mình mắc <number> vài lỗi sau chia_sẻ link medium mà không biết rằng việt_nam bị chặn chia_sẻ file pdf của article nhưng không check lại là các link không click vào được post đầu_tiên ok nên <number> post sau mình làm tương_tự mà không biết rằng có lỗi này cho đến khi các bạn nhắc mình rất xin_lỗi mọi người về sự bất_tiện này mình đã update lại tất_cả link rồi giờ các bạn có_thể download file pdf cuối mỗi post là có_thể truy_cập vào từng project thông_qua các link trong bài viết rồi nhé again sorry for any inconvenience mình thấy có bạn gợi_ý là các bạn nếu muốn đọc article có_thể paste link vào đây trick khá hay mình không biết đến trong mấy hôm tới mình sẽ chia_sẻ thêm <number> vài bài tổng_hợp các project mà mình thấy hữu_ích trên medium btw rule cũ vẫn áp_dụng bình_thường nhé các bạn bài post nào mà trong <number> giờ các bạn chưa được ai giúp_đỡ thì các bạn luôn có_thể mention mình nhé,['#sharing']
spearman correlation sự thay_thế tuyệt_vời dành cho pearson correlation hi các bạn với những ai học về data science machine learning chắc các bạn không còn xa_lạ gì với pearson correlation coefficient hệ_số tương_quan pearson dùng để đánh_giá mối quan_hệ tuyến_tính giữa <number> biến pearson correlation thì quá phổ_biến và có rất nhiều framework như pandas scipy hay numpy đều có các hàm riêng để tính giá_trị này ... ... tuy_nhiên pearson correlation không có khả_năng đánh_giá tính đơn_điệu trong mối quan_hệ giữa <number> biến bao_gồm cả tuyến_tính và phi_tuyến lúc này ta cần <number> metric tốt hơn để có_thể đo_lường được mối quan_hệ này và <number> trong số đó là spearman correlation coefficient hệ_số tương_quan spearman hình bên dưới minh_họa sự khác_biệt giữa <number> hệ_số này một_cách tóm_tắt pearson và spearman correlation giống nhau với các mối quan_hệ tuyến_tính spearman ước_lượng tốt mối quan_hệ đơn_điệu nhưng phi_tuyến giữa các biến trong khi pearson đánh_giá thấp mối quan_hệ này pearson thì chắc_chắn là nổi_tiếng hơn rât nhiều spearman nhưng về sự hữu_ích thì well you have your own assessment,"['#sharing', '#python', '#machine_learning']"
cuộc đua về mô_hình ngôn_ngữ lớn lại tiếp_tục thú_vị hơn khi google mới cho ra_mắt gemini đối_thủ nặng_kí cho chatgpt,['#sharing']
mình lấy table trên wiki về trong table có giá_trị âm biểu_thị bằng hình_ảnh mũi_tên bây_giờ lấy về data frame chỉ nhận giá_trị_số bị sai về mặt âm dương xin admin và các bạn chút kinh_nghiệm xử_lý đoạn này,"['#Q&A', '#data']"
<number> thư_viện python dành cho generative ai hi các bạn dưới đây là tổng_hợp các thư_viện trong python giúp chúng_ta xây_dựng và sử_dụng các mô_hình generative ai bao_gồm tensorflow pytorch transformers jax diffusers langchain liama index acme <number> cái tên đầu_tiên thì đã quá quen_thuộc rồi phải không các bạn link to pdf,"['#sharing', '#python']"
em nên mua laptop nào để học ai dạ em đang tìm_hiểu mua <number> chiếc laptop mới <number> củ trở xuống em đang phân_vân giữa việc chọn <number> chiếc laptop có gpu nvidia thì khối_lượng sẽ nặng và cũng đắt tiền thầy em bảo có thì sẽ thuận_tiện chủ_động hơn <number> chiếc nhẹ thuận_tiện vì em đeo nặng thấy dễ đau lưng lắm em đang dùng hp folio <number> mong anh_chị cho em lời khuyên và gợi_ý cho em <number> số laptop,['#Q&A']
em chào mọi người hiện_tại em đang tìm_kiếm <number> chiếc laptop phù_hợp với budget của em khoảng <number> triệu đổ xuống và phục_vụ cho ai computer vision sau_này thì em nên mua với cấu_hình_như thế_nào thì hợp_lý em có tìm_hiểu vài dòng và đang phân_vân giữa dell precision <number> và vài chiếc gaming có thông_số cụ_thể là dell <number> cpu i78850h cpu <number> ghz <number> cpus <number> ghz ram 16gb ddr4 buss 2666mhz ssd 512gb vga intel uhd graphics <number> nvidia quadro p1000 4g gaming hp victus <number> <number> cpu ryzen <number> 7535hs ram 8gb ssd <number> gb rtx <number> 4gb lenovo ideapad gaming3 ryzen 57535hs 8gb 512gb rtx <number> 4gb msi gaming gf63 thin 11sc cpu i5 11400h 8gb 512gb 4gb gtx1650 mọi người cho em tư_vấn với các con máy trên hoặc <number> con máy bất_kì khác trong cùng tầm giá với em cảm_ơn mn nhiều,['#Q&A']
xin phép anh việt nguyễn và mọi người hôm trước em có tải cuda bản <number> và cudnn em đã chạy được gpu trên pytorch nhưng với tensorflow thì không được bản tensorflow em tải là <number> em có xem trên phần pip của tensorflow chỗ environment thì thấy nó chỉ hỗ_trợ bản cuda <number> còn trên trang tensorflow blog thì nó ghi là hỗ_trợ <number> thế tức_là giờ em không_thể dùng được gpu trên tensorflow đúng không bản_thân em có test trên colab thì tensorflow vẫn nhận được gpu còn trên vsc thì không nhận được em xin cảm_ơn mn link pip link blog,"['#Q&A', '#python']"
anh_chị cho em hỏi là giờ muốn theo mảng data vn thì nên theo ds de da hay mảng nào khác với cho em hỏi thêm là bản_thân em đang là sinh_viên năm <number> ngành khoa_học máy_tính em đang muốn tìm <number> mảng để học sâu vào rồi đi thực_tập mảng nào em cũng tìm_hiểu <number> ít nhưng vẫn biết bản_thân hợp với cái nào anh_chị cho em xin ít lời khuyên em cảm_ơn,['#Q&A']
chào mọi người em đang train yolo thì hiện_tại map không thấy lên mà cứ dao_động <number> cho em hỏi làm thế_nào để cải_thiện map lên cao hơn nữa data train hiện_tại tầm 3k hình,"['#Q&A', '#deep_learning']"
ds tip hãy chú_ý khi sử_dụng correlation để đánh_giá mối quan_hệ tuyến_tính giữa <number> biến hi các bạn với những bạn học hay làm về data science có_lẽ các bạn không còn lạ gì khái_niệm tương_quan correlation nói <number> cách đơn_giản thì tương_quan thể_hiện mối quan_hệ tuyến_tính có_thể tồn_tại giữa <number> biến hệ_số tương_quan mà càng gần <number> hoặc <number> thì mối quan_hệ tuyến_tính càng mạnh còn nếu hệ_số tương_quan gần <number> thì <number> biến có mối quan_hệ tuyến_tính rất yếu tuy_nhiên tương_quan có <number> nhược_điểm rất lớn đó là bị ảnh_hưởng mạnh bởi outlier như các bạn có_thể nhìn thấy trong <number> hình phía dưới chỉ với việc thêm vào <number> outlier chúng_ta đã thấy hệ_số tương_quan thay_đổi rất đột_ngột <number> biến đang từ có mối quan_hệ tuyến_tính mạnh đúng trở_thành quan_hệ tuyến_tính yếu sai do đó lời khuyên dành cho chúng_ta là đừng lúc_nào cũng chăm_chăm nhìn vào số_liệu mà hãy nhìn vào cả dữ_liệu nữa bằng việc trực_quan_hóa dữ_liệu và nhìn vào phân_bố của chúng điều đó sẽ cứu chúng_ta khỏi việc đưa ra những kết_luận sai_lầm cái này mình cũng mới biết,['#sharing']
series bài giảng về deep learning của deepmind và ucl centre trước khi nói về bài giảng mình muốn giới_thiệu qua <number> chút deepmind là ai họ là <number> startup về ai được thành_lập vào năm <number> deepmind cùng với openai là <number> công_ty có rất nhiều thành_tựu trong ai đặc_biệt là trong mảng học tăng_cường reinforcement learning nếu vào những năm <number> openai đã đi vào lịch_sử khi trình_làng openai five <number> mạng nơ ron và đánh_dấu cột mốc khi lần đầu_tiên ai có_thể đánh_bại con_người <number> tựa game moba dota2 thì trước đó <number> năm deepmind với alphago cũng tạo nên tên_tuổi của mình khi chiến_thắng <number> đại kiện_tướng cờ_vây chuyên_nghiệp hiện_tại deepmind đang thuộc quyền sở_hữu của google quay trở_lại với nội_dung chính series bài giảng này bao_gồm <number> video mỗi video kéo_dài khoảng <number> tiếng rưỡi cover tất_cả các topic cần_thiết để các bạn có_thể nắm được các kiến_thức cơ_bản và nâng cao về deep learning mỗi <number> lecture sẽ được phụ_trách bởi <number> speaker khác nhau nhưng các bạn yên_tâm nhé họ nói khá chậm và rõ series này đã được cho ra_mắt <number> năm trước nhưng không hề lỗi_thời với thời_điểm hiện_tại link to series,"['#sharing', '#deep_learning']"
computer vision project sign language hello mn mình đang muốn làm <number> project_về ngôn_ngữ ký_hiệu việt_nam model sẽ lấy input là những video của người sử_dụng ngôn_ngữ ký_hiệu sau đó dịch ra tiếng việt và tiếng anh theo thời_gian thực vấn_đề là mình chưa tìm được data để train model website duy_nhất mình tìm thấy là nhưng cũng có api để lấy data về không biết mn đã ai từng làm project tương_tự và đã tìm được nguồn data có_thể share giúp mình được cám_ơn mn ảnh chống trôi,"['#Q&A', '#cv']"
chào mọi người cho mình hỏi mình đang làm <number> project về phân_loại rác xong gửi qua cho robot thông_qua modbus tcp ip mình dùng pyinstall để chuyển về window app nhưng khi mở lên chỉ thấy giao_diện chứ ko hoạt_động có vẻ file đóng_gói ko có đủ thư_viện cần_thiết để chạy dưới đây là gui chạy trong pycharm,"['#Q&A', '#deep_learning', '#cv']"
hỏi ai về chuyên_ngành nào của cntt khó nhất và nó trả_lời như thế này biết có đúng,['#Q&A']
chào mn do em mới tập_tành và học nên cũng không biết xử_lí hiện em muốn nhờ mn hướng_dẫn em một_chút cơ_bản em xin cảm_ơn nhiều chuyển cột join_date về dạng yyyy mm dd cột mobiles về dạng <number> ...,"['#Q&A', '#python', '#data']"
khóa nlp của đại_học texas hi các bạn mình xin giới_thiệu với các bạn khóa cs388 natural language processing đến từ đại_học texas theo giới_thiệu thì khóa học dành cho các bạn level master nhưng theo đánh_giá của cá_nhân mình thì các bạn bậc bachelor nếu đã học qua các môn toán đại_cương thì cũng hoàn_toàn có_thể theo được khóa học sẽ cover các chủ_đề sau giới_thiệu về nlp linear classification word embedding language modeling và selfattention transformers và decoding modern large language models machine translation summarization video lecture course material các bạn có_thể download slide và note của khóa học đường link thứ <number> nhé,"['#sharing', '#nlp']"
awesomenlp tổng_hợp tất_cả các tài_liệu tin_tức thư_viện về nlp hi các bạn mình xin giới_thiệu với các bạn <number> nguồn tổng_hợp tất tần_tật những gì các bạn cần biết về nlp bao_gồm tài_liệu thư_viện dataset tin_tức và thậm_chí là các nghiên_cứu với cá_nhân mình có <number> phần mình chú_ý nhất trong danh_sách này bao_gồm các dataset các thư_viện nlp dành riêng cho các ngôn_ngữ cùng với các dataset dành cho ngôn_ngữ đó có cả tiếng việt của chúng_ta các bạn nhé link <number> nguồn rất tuyệt_vời cho các bạn theo hướng nlp,"['#sharing', '#nlp']"
chào anh việt và mọi người trong nhóm em đang học về dl và muốn train model bằng gpu em có tìm_hiểu và đã tải được cuda toolkit <number> và cudnn tương_thích với nó bản_thân em cũng đã copy các file từ cudnn vào cuda và cũng đã cài_đặt các biến môi_trường để trỏ đến vị_trí cudnn em có xem <number> số tài_liệu bảo rằng sau bước này thì cần cài_đặt thêm visua studio nhưng cần cài những gì trong đấy thì em cũng không rõ lắm có chỗ bảo cần cài hết trong visual studio em mong mọi người cho em <number> số hướng_dẫn hiện_tại thì em không biết có nên tải visual studio không và nếu tải thì cần bao_nhiêu em cảm_ơn mọi người,['#Q&A']
hỏi_đáp tự học framework pp phân_tích em chào cả nhà em tự học da học dùng tools cơ_bản tuy_nhiên có thắc_mắc khi em xem các project trên mạng thì thường các project sẽ chọn <number> topic cụ_thể để đi_sâu trl credit scoring bank turnover ... em không biết thực_tế tại doanh_nghiệp dn có xu_hướng trl <number> bài toàn như trên hay sẽ đi mining tìm insight về nếu tìm insight em lại biết có phương_pháp nào chuẩn để khám_phá dữ_liệu mà sót insight nào vì_thế em không biết phát_triển và luyện_tập project theo hướng nào mới đúng mong các anh_chị chia_sẻ với em tự học nên hơi mơ_hồ không có người để hỏi em cảm_ơn cả nhà nha,"['#Q&A', '#data']"
em chào mọi người em đang rất bế_tắc mong được mọi người hướng_dẫn em trong việc xử_lý data trước khi train model mlp đây là data thô của em tóm_tắt của yêu_cầu này là người dùng sẽ nhập chỉ_số glutest và weight sau đó máy sẽ đưa ra giá_trị phù_hợp của <number> loại chỉ_số dinh_dưỡng xin nhờ mn hướng_dẫn em hướng để tiền xử_lý data em cảm_ơn mọi người nhiều em có dùng lệnh để vẽ histogram cho từng cột trong dataframe và show hiệu_quả model,"['#Q&A', '#data', '#machine_learning']"
<number> câu hỏi phỏng_vấn khó nhất và câu trả_lời hi các bạn hôm_nay mình mới đọc được <number> bài trên linkedin tổng_hợp các câu hỏi phỏng_vấn khó nhất mình thấy rất hay nên muốn chia_sẻ lại với các bạn điểm khó của phần_lớn các câu hỏi phỏng_vấn này không nằm kiến_thức hàn_lâm mà việc làm_sao để có_thể trả_lời <number> cách hiệu_quả nhất ngoài_ra có <number> vài câu hỏi về các topic khá nhạy_cảm nếu không trả_lời khéo_léo thì rất có_thể chúng_ta sẽ mất điểm trong mắt nhà tuyển_dụng ngoài_ra thì trong hầu_hết các câu hỏi này đều sẽ có những cái bẫy mà các bạn không bao_giờ muốn rơi vào với mỗi câu hỏi tác_giả sẽ phân_tích bẫy được đưa ra là gì và giải_pháp để vượt qua những cái bẫy đó để có được câu trả_lời tốt nhất link to pdf,['#sharing']
bayesian optimization thay_thế tuyệt_vời dành cho gridsearchcv hay randomizedsearchcv hi các bạn với các ban học hoặc làm về data science machine learning chắc các bạn không còn xa_lạ gì với bộ đôi gridsearchcv và randomizedsearchcv <number> kĩ_thuật giúp chúng_ta tìm ra được các hyperparameter tối_ưu dành cho các model machine learning tuy_nhiên <number> kĩ_thuật này đều có những nhược_điểm của riêng mình gridsearchcv thì chạy quá tốn thời_gian vì thực_hiện exhaustive search randomizedsearchcv chỉ được thực_hiện trên <number> số_lượng nhất_định các combination của hyperparameter nên hoàn_toàn có khả_năng là combination tối_ưu bị bỏ_qua kết_quả cuối_cùng không phải là tối_ưu cả <number> đều có chung <number> nhược_điểm chúng chỉ có_thể thực_hiện search qua các giá_trị rời_rạc bất_kể hyperparameter là liên_tục do chúng_ta phải định_nghĩa <number> danh_sách các giá_trị muốn search của hyperparameter do những hạn_chế kể trên dù <number> kĩ_thuật trên được biết đến và sử_dụng rộng_rãi chúng_ta vẫn cần tìm ra giải_pháp tối_ưu hơn <number> trong số đó chính là bayesian optimization phương_pháp này sử_dụng bayesian statistics để ước_lượng và đánh_giá phân_phối của các hyperparameter tốt nhất kết_quả so_sánh giữa <number> phương_pháp được thể_hiện hình bên dưới các bạn có_thể thấy được sự vượt_trội của bayesian optimization tất_cả các hạng_mục original article,"['#sharing', '#machine_learning']"
mọi người có_thể cho mình hỏi là nếu mình muốn dùng computer vision để nhận_diện khi một người dùng tay lấy hàng ra khỏi kệ và bỏ hàng lại lấy nữa thì có những cách tiếp_cận nào hard code thuật_toán thì mình khá chắc là bất_khả_thi cho production level mình có tìm_hiểu về cách làm sử_dụng transformer lên body keypoints bởi vi dữ_liệu để nhận_diện hành_động là dữ_liệu sequential với có_lẽ là sử_dụng thêm vài hardcoded metrics nữa mong mn góp_ý mình cảm_ơn,"['#Q&A', '#cv']"
mình đang muốn tìm_hiểu về các cách_thức đánh_giá multiturn conversation của chatbot llms trong quá_trình tìm_hiểu thì mình thấy các paper mình đọc đều tập_trung chủ_yếu vào các khía_cạnh như relevance usefulness harmfulness vv tức tập_trung vào chất_lượng của từng câu trả_lời single turn chứ chưa hẳn là về cả <number> đoạn hội_thoại multiturn mọi người có gợi_ý từ khóa hay bài báo nào không mình mới nghĩ ra các vấn_đề như người dùng đổi context đang từ vấn_đề hỏi sang vấn_đề nhắc lại đến những gì đã nói trước đó,"['#Q&A', '#nlp']"
em chào mọi người đây đã ai làm_việc với owlvit và finetune model này với custom dataset chưa em đã đọc phần finetune nhưng nhiều chỗ chưa rõ lắm mong tiền_bối nào giúp_đỡ với,"['#Q&A', '#machine_learning']"
khóa học introduction to deep learning tại lmu munich hi các bạn cách đây tầm <number> tuần mình từng chia_sẻ về khóa introduction to machine learning của đại_học munich lmu nhắc lại <number> chút về lmu đây là <number> ngôi trường rất nổi_tiếng tại munich và luôn_luôn xuất_hiện trong top <number> trường đại_học tốt nhất thế_giới trong đó bao_gồm cả <number> bảng xếp_hạng danh_tiếng nhất thế_giới là qs times higher education và shanghai ranking hôm_nay mình xin chia_sẻ với các bạn khóa học anh_em với khóa trên introduction to deep learning tương_tự với người anh_em của mình khóa học này ngay từ đầu đã được thiết_kế theo hướng khuyến_khích tự học thông_qua việc cung_cấp đầy_đủ những tài_liệu cần_thiết bao_gồm video bài giảng bằng tiếng anh các lecturer nói khá chậm các bạn nhé có phụ_đề tiếng việt thông_qua autogeneration slide gồm <number> chương cover các topic từ cơ_bản đến nâng cao trong deep learning cheatsheets quizzes bài_tập lý_thuyết bài_tập lập_trình với lời_giải bằng <number> ngôn_ngữ là và python thông_thường_khi các trường đại_học danh_tiếng mở các khóa học online họ thường giảm độ khó so với khóa học thực_sự trên trường để dễ tiếp_cận các sinh_viên phổ_thông hơn nhưng khóa học này là <number> trong các ngoại_lệ trên trường như thế_nào họ bê chang vào khóa online link to course,"['#sharing', '#deep_learning']"
mình xin chia_sẻ tài_liệu các môn thuộc chương_trình đào_tạo của soict đh bách_khoa hà_nội nội_dung bao_gồm các môn đại_cương cơ_sở cốt_lõi chuyên_ngành liên_quan đến khoa_học máy_tính kỹ_thuật máy_tính tất_nhiên có cả về ai nữa để tiện cho mọi người tham_khảo thì mình đã đăng_tải bằng cả hai ngôn_ngữ là tiếng anh và tiếng việt chúc mọi người học tốt,['#sharing']
em cần người hỗ_trợ làm chatbot tư_vấn khám chữa bệnh hoặc tư_vấn sản_phẩm trong thương_mại điện_tử có_hậu_tạ,"['#Q&A', '#nlp']"
mình đang làm nghiên_cứu khoa_học về chủ_đề ứng_dụng vader trong phân_tích tài_chính dựa trên cảm_xúc văn_bản và đề_xuất cho nhà đầu_tư cùng doanh_nghiệp làm_bằng cách crawl data lấy tin_đồn trên mạng xã_hội reddit twitter ... hay article giá phân_tích sentiment dựa trên tool vader công_cụ phân_tích cảm_xúc được sử_dụng để đánh_giá tác_động của các bài viết bình_luận tin_tức và thông_tin trên mạng đối_với tâm_trạng và quyết_định đầu_tư của nhà đầu_tư thêm các mô_hình ml kiểm_định và cuối_cùng đưa ra recommend về việc mua_bán mã chứng_khoán đấy cụ_thể về ý_tưởng đề_tài là có nhiều cách và phương_pháp để quyết_định đầu_tư hay không như các phương_pháp phân_tích kỹ_thuật các chỉ_số hay tình_hình tài_chính các phương_pháp này đều đòi_hỏi người sử_dụng phải có kiến_thức chuyên_môn để có_thể sử_dụng hiệu_quả trong bối_cảnh này nghiên_cứu này đề_xuất_phát_triển một công_cụ phân_tích cảm_xúc của tác các bài viết tài_chính liên_quan đến mã chứng_khoán hoặc công_ty đó các bài viết có_thể mang tính_chất tích_cực hoặc tiêu_cực và sự thay_đổi trong cảm_xúc này có_thể ảnh_hưởng đáng_kể đến giá cổ_phiếu hoặc hiệu_suất của một công_ty mình đang cần giúp thêm về phần thu_thập data cào dữ_liệu hay tìm_kiếm bộ dataset để phân_tích mình đang mới bắt_đầu nghiên_cứu đề_tài này ai giúp được mình về phần dữ_liệu này với mình xin cảm_ơn nhiều ạa,"['#Q&A', '#machine_learning']"
em chào mọi người tình_hình là em đang có <number> project mà giảng_viên yêu_cầu phải áp_dụng python ml ... để tạo ra được <number> sản_phẩm có_thể cho mọi người dùng được như web app thì hiện_tại em đang làm về building recommendation system customer segmentation và sentiment analysis cho <number> loại sản_phẩm của amazon thì em muốn hỏi là hiện_tại đánh_giá mô_hình cho sentiment của em là <number> rồi thì làm thế_nào để em tích_hợp nó với <number> web vậy em hoang_mang quá,"['#Q&A', '#machine_learning', '#python']"
em chào anh việt và mọi người em muốn hỏi về tài_liệu của thuật_toán ann hiện_tại em muốn biểu_diễn thành công_thức như ví_dụ trong hình mọi người có tài_liệu chính_thống nào hoặc bài báo nào uy_tín có_thể cho em xin thêm thông_tin để làm bài với em cảm_ơn mọi người nhiều,"['#Q&A', '#deep_learning']"
em hiện_tại là sinh_viên ô_tô năm cuối sắp ra trường nhưng em muốn được làm và học về ai và machine learning em muốn hỏi anh việt cũng như các bạn trong gr có hướng cũng như roadmap nào để em có_thể đạt được những mục_tiêu học và làm_việc trong mảng này của bản_thân em xin cảm_ơn mọi người nếu học văn_bằng <number> là một lựa_chọn tốt thì mọi người có_thể đề_xuất trường nào tại hn được không em xin cảm_ơn,['#Q&A']
em xin chào các anh_chị em newbie trong môn ai em đang xây_dựng mô_hình vae với đầu_vào là tập data con ngựa trong cifar <number> các anh_chị góp_ý giúp em đoạn code này làm_sao để mô_hình_học được tốt hơn không em chạy colab gần hết ram mà kết_quả ra hình vẫn mờ lắm em cảm_ơn các anh_chị rất nhiều,"['#Q&A', '#cv']"
artificial intelligence modern approach hi các bạn mình xin giới_thiệu với các bạn <number> trong số các tài_liệu kinh_điển cho những ai học về ai artificial intelligence modern approach quyển sách này không đi_sâu vào machine learning hay deep learning mà sẽ bao_quát toàn_bộ tất_cả những kiến_thức tổng_quát về ai các bạn chú_ý nhé ai machine learning deep learning đây là <number> quyển sách theo hướng lý_thuyết rất hàn_lâm đấy các bạn nhé dài hơn <number> trang và không dễ để tiêu_hóa quyển này hồi mình học năm <number> tại tu munich có <number> môn tên là introduction to ai và đây là tài_liệu tham_khảo duy_nhất của môn_học đấy link to pdf,['#sharing']
<number> days of machine learning code hi các bạn mình xin giới_thiệu các bạn <number> repository github vô_cùng thú_vị <number> days of machine learning code tác_giả là siraj raval <number> youtuber rất nổi_tiếng về ai math science và technology với 760k subs trong project này tác_giả đưa ra lộ_trình <number> ngày học machine learning thông_qua lý_thuyết được tóm_tắt qua các poster đi kèm với code và bài_tập để các bạn có_thể thực_hành repository này không hề hàn_lâm <number> chút nào mà rất thực_tiễn rất dễ hiểu và cơ_bản rất hợp với các bạn mới hay trái ngành muốn học machine learning link,"['#sharing', '#machine_learning']"
cho em hỏi làm_sao để nhúng camera điện thọai vào source yolov8 để thực_hiện phần detect vậy,"['#Q&A', '#deep_learning']"
thường sau khi được giao <number> bộ data mình phải xử_lí sau nếu gặp task dưới đây,"['#Q&A', '#data']"
hiện_nay chatbot đã trở_thành một công_cụ quan_trọng cho các doanh_nghiệp để cung_cấp thông_tin và tăng tương_tác đối_với khách_hàng trong số các loại chatbot retrievalbased chatbot là một trong những phương_pháp phổ_biến nhất được sử_dụng để đáp_ứng các yêu_cầu và câu hỏi của người dùng trong bài hôm_nay chúng_ta sẽ tìm_hiểu sơ_lược về retrievalbased chatbot và các thành_phần nlp cấu_thành nên loại chatbot này,"['#sharing', '#nlp']"
em chào mọi người mọi người có bao_giờ gặp tình_trạng giống em không chả_là em chạy mô_hình phân_loại bằng deep learning machine learning một_số project khi em đặt giới_hạn về xác_suất xảy ra trường_hợp nó dự_đoán càng cao thì nó sai so với thực_tế càng nhiều nghĩa_là khi probability càng cao thì precision của class đó càng giảm em có cách nào khắc_phục được trường_hợp của em không em cảm_ơn,['#Q&A']
với việc kiếm ai intern quá khó thì giữa data science data engineer data analyst ml engineer đâu là những hướng đi hợp_lý để sau vào làm ai engineer,['#Q&A']
mọi người ơi lỗi này là lỗi gì vậy,['#Q&A']
xin chào mọi người hiện_tại em đang có ý_định train một model để dự_đoán cung mọc khái_niệm về cung mọc trong chiêm_tinh_thể_hiện physical trait đặc_điểm vẻ bề_ngoài của một người em muốn nghiên_cứu xem có thực_sự là khái_niệm này thể_hiện được đặc_điểm khuôn_mặt của người_ta hay không hiện em đang cần thêm nhiều data từ người châu mình cụ_thể là giờ sinhngày sinh và ảnh chụp rõ mặt nếu mọi người trong group ai có hứng_thú thì có_thể giúp em qua việc upload ảnh lên file drive dưới đây với title của ảnh là giờ sinhngàythángnăm sinh em xin cảm_ơn,"['#Q&A', '#machine_learning']"
albumentations thư_viện kinh_điển dành cho image augmentation hi các bạn post này dành cho các bạn quan_tâm hoặc đang theo_đuổi mảng giống mình deep learning for computer vision trong computer vision nlp hay machine learning data augmentation là <number> bước tiền xử_lý dữ_liệu không_thể thiếu data augmentation giúp tạo ra dữ_liệu đa_dạng hơn từ dữ_liệu gốc từ đó giúp cho mô_hình có_thể học các thuộc_tính đặc_trưng của dữ_liệu <number> cách hiệu_quả hơn trong computer vision chúng_ta có rất nhiều các kĩ_thuật dành cho image augmentation như flip rotate resize ... tuy_nhiên hầu_hết các kĩ_thuật này chỉ có_thể áp_dụng được cho bài_toán đơn_giản nhất trong deep learning for computer vision đó là image classification còn với các bài_toán phức_tạp hơn như object detection hay image segmentation các kĩ_thuật này sẽ không_thể áp_dụng được ngay lập_tức ... albumentation được tạo ra đẻ giải_quyết vấn_đề này ngoài việc giúp cho người dùng có hàng chục sự lựa_chọn đa_dạng khác nhau dành cho image augmentation những bức ảnh mới được tạo ra sẽ hoàn_toàn tương_thích với các bài_toán khác nhau bao_gồm cả object detection hay image segmentation nếu các bạn để_ý thì có rất nhiều các project nổi_tiếng sử_dụng thư_viện này cho bước tiền xử_lý ảnh trong đó <number> đại_diện vô_cùng nổi_tiếng chính là yolov5 và yolov8 của ultralytics link,"['#sharing', '#python']"
em chào mọi người chả_là nhân một ngày_tiết trời lành_lạnh ru_rú nhà hơi chán em xin phép kể cho mọi người nghe một câu_chuyện kinh_dị ngắn nhé con_trai tôi đã <number> tháng tuổi đã có_thể nói được một_vài từ có_nghĩa giống như những đứa trẻ khác nó cũng sẽ chỉ một đồ_vật nào đó sau đó vất_vả gọi tên chúng có một lần nó chỉ một hình_vẽ trên cuốn sách sau đó bi bi_bô_bô nói mèo chúng_tôi nhìn xem quả_nhiên góc cuốn sách nơi đầu ngón tay của nó đang chỉ có một con mèo một ngày nọ khi chỉ có tôi và con_trai đang nhà cùng nhau con_trai đột_nhiên ngừng chơi dùng đầu ngón tay chỉ về sau lưng tôi sau đó vô_cùng rõ_ràng thốt lên một chữ generative ai tiện_thể mọi người có tài_liệu hoặc khóa học nào về generative ai cho em xin với với cả mọi người có_thể cho em tham_khảo lộ_trình làm bố của generative ai thì cho em xin lun nhé em cảm_ơn mn nhắm nhắm đang cảm_thấy sợ_hãi,['#Q&A']
chào mọi người hiện_tại em đang tìm_hiểu về transformer qua video và có clone repo về để chạy thử trong quá_trình chạy em gặp phải một_vài điều thắc_mắc lỗi nhận gpu máy_tính em đoán vậy could not load dynamic library cudart64_110 dll dlerror cudart64_110 dll not found em mở một_vài code python thấy vscode báo một_số lỗi import thư_viện kiểu import tensorflow could not be resolved nhưng không hiểu sao khi em chạy lệnh huấn_luyện mô_hình thì nó vẫn chạy máy em chạy windows <number> gpu rtx <number> có cài anaconda hiện_tại em mới biết sơ qua về ml dl chưa có nhiều kĩ_năng code mong mọi người rộng_lượng hỗ_trợ giải_đáp cho em em cảm_ơn mọi người rất nhiều,"['#Q&A', '#deep_learning']"
chào mọi người hiện_tại em có <number> phần code sử_dụng model yolov5 để detect người và xe trên đường line detect và sign detect <number> phần này nó riêng_biệt với nhau và em muốn gộp <number> cái nó lại thành <number> để khi mình cho đầu_vào là <number> video thì nó sẽ tự output ra cho mình dò xe người làn_đường và biển_báo thì làm như thế_nào,"['#Q&A', '#cv', '#deep_learning']"
mình được biết rnn có <number> problem là không_thể ghi_nhớ được thông_tin các early timestep vậy thì nguyên_nhân sâu_xa cho vấn_đề này là gì có phải do vanishing gradient không mình tìm trên mạng thì thấy ít bài giải_thích về vấn_đề này và mình đọc các bài này xong thì cũng không thỏa_mãn về cách giải_thích cho lắm đang cảm_thấy bối_rối,"['#Q&A', '#nlp', '#deep_learning']"
báo_cáo tình_hình tuyển_dụng các jobs data tháng <number> <number> xin chào mọi người hôm_nay mình xin phép giới_thiệu với mọi người một dự_án cá_nhân mà mình thực_hiện liên_quan đến việc scrape dữ_liệu từ các website tuyển_dụng và phân_tích các job post trên đó mình nghĩ kết_quả của nó có_thể sẽ có_ích với nhiều bạn trong group nên mình share lên đây phần hôm_nay mình chia_sẻ với các bạn sẽ là kết_quả của một notebook mà mình phân_tích <number> jobs liên_quan đến data mà mình thu_thập trên careerbuilder vào <number> và <number> tháng <number> vừa_rồi giới_thiệu sơ qua về dự_án để thực_hiện dự_án này mình cào dữ_liệu bằng cách sử_dụng hai thư_viện python selenium và beautifulsoup selenium để điều_khiển chrome truy_cập các đường link thực_hiện thao_tác cuộn trang để load html beautifulsoup để kéo html_soup về và giải_mã trích xuất những thông_tin cần_thiết từ html chi_tiết về cách thực_hiện mọi người có_thể xem kĩ hơn github repo dưới đây trong repo bạn có_thể tìm thấy dữ_liệu từ nhiều công_việc khác nhau mình đã có cào dữ_liệu của các jobs các ngành logistics xuất nhập_khẩu warehouse data trong bài share trên facebook này mình sẽ chỉ post chart đáng chú_ý có chú_thích thêm từng ảnh chi_tiết và comment kĩ hơn của mình cho từng chart bạn có_thể truy_cập blog post dưới đây của mình để đọc kĩ hơn và nếu được thì subcribe ủng_hộ mình nhé thêm nữa phân_tích trong bài này còn mức đơn_giản hi_vọng có cao nhân nào đó trong group có_thể ra_tay tương_trợ để phát_triển projec này hơn nữa nếu có bất_kì thắc_mắc nào đừng ngại inbox mình để trao_đổi thêm nhé note thêm mình đang tìm_kiếm các job data analyst data science level juinor khoảng <number> năm kinh_nghiệm nhé bạn nào có job liên_hệ mình nhé,['#sharing']
em chào mọi người hiện_tại em đang thử train model lenet5 trên dataset cifar10 trong torchvision datasets và em đã resize hết các ảnh về kích_thước 32x32x1 và chia data ra với batch_size là <number> lúc em train thì accuracy tập test cao nhất_là <number> không biết đây mọi người có_thể recommend cho em model nào train tốt hơn với tập dữ_liệu đó hoặc có_thể là em implement sai mọi người check giúp em với em cảm_ơn nhiều em đã thêm ảnh quá_trình tiền xử_lý ảnh và train,"['#Q&A', '#deep_learning']"
xin chào mọi người hiện_tại em đang thực_hiện <number> nghiên_cứu về fake review detection trên dataset khoảng gần <number> triệu mẫu về đánh_giá mobile commerce tại vn nhưng chưa được label em đang gặp vấn_đề step label tụi em đã thử một_số phương_pháp như lda và vader lda với mục_đích để tìm ra các topic có trong bài rồi kiểm_tra thử xem topic không liên_quan tới lĩnh_vực của tập dataset là mobile commerce nhưng mà kết_quả sau khi thực_hiện thì tụi em thấy các topic nó ra kết_quả khá chung_chung nên không_thể xác_định được topic nào là không liên_quan <number> yếu_tố nữa là cái review này chỉ là short text chủ_yếu từ <number> từ nên lda nó cũng không hiệu_quả dùng vader để tính sentiment score của review và so_sánh mối liên_hệ giữa sentiment score của review với rating score mà người review đã đánh_giá nhưng kết_quả không khả_quan lắm trên tiếng việt em có thử api để trans qua tiếng anh rồi chạy lại nhưng mà kết_quả nó cũng không cải_thiện hơn em có nghĩ theo hướng sẽ build từ_điển sử_dụng word embedding để xây_dựng từ_điển xây_dựng <number> bộ nhãn <number> bộ là các từ mà chuyên về spam fake và <number> bộ là ngược_lại em đã trích xuất ra được aspect của dataset nhưng chưa biết cách chọn aspect như thế_nào để build từ_điển em dùng pos tagging để trích xuất ra các danh từ nhằm tìm ra các aspect trong tập dataset nhưng sau khi trích xuất thì tụi em không biết nên chọn aspect nào cho phù_hợp kết_quả đếm các danh từ xuất_hiện nhiều nhất tụi em thấy các danh từ này dùng làm aspect cũng không thật_sự hợp_lý bên cạnh đó em cũng chưa tìm_hiểu được sử_dụng phương_pháp nào để có_thể tìm được các từ có liên_quan đến aspect để xây_dựng được từ_điển em có đọc được <number> đề_xuất của <number> anh trên group về sentiment analysis on labeled and unlabeled datasets using bert architecture nhưng theo em đọc thì thấy về phía unlabeled data nó sử_dụng cái fuzzy model nhưng em chưa hiểu cách nó chạy lắm mong mng có_thể cho em <number> vài đề_xuất,"['#Q&A', '#nlp']"
xin chào mọi người mình đang cần cài phần_mềm này trên máy mac các bạn biết chuyển từ bash sang zsh không khi cài cần tải key về mình không tải được key theo định_dạng asc chử ký định_dạng sha5 lúc tải key về định_dạng txt thì mình chạy file bằng terminal bị báo là không tìm ra file các bạn giúp mình với hi,['#Q&A']
awesome production machine learning danh_sách tổng_hợp tất_cả mọi thứ có liên_quan đến machine learning in production hi các bạn mình xin giới_thiệu với các bạn <number> nguồn tổng_hợp vô_cùng thú_vị cho tất_cả mọi bước có liên_quan đến machine learning in production bao_gồm đánh nhãn dữ_liệu triển_khai theo_dõi mở_rộng mô_hình ... <number> nguồn allinone vô_cùng chất_lượng dành cho những bạn muốn tìm_hiểu xem bên ngoài phạm_vi trường_học các mô_hình machine learning sẽ được triển_khai và sử_dụng như thế_nào link,"['#sharing', '#machine_learning']"
chào anh việt và mọi người em là sinh_viên chuyên_ngành ai của một trường đại_học việt_nam có định_hướng muốn đi theo ai engineer hiện_tại em chuẩn_bị đi thực_tập em đang nghiên_cứu các công_ty cũng như việc_làm trong tương_lai em thấy intern và fresher thật_sự khá ít và khó kiếm tuy_nhiên senior lại khá nhiều chương_trình thực_tập của trường em là bắt_buộc và hiện_tại em chưa có hình_dung mình sẽ đi intern đâu du_học thì em có nghĩ đến nhưng mà đó là dự_định xa và muốn tập_trung đi thực_tập và đi làm trong tương_lai gần mọi người có khuyên gì cho trường_hợp của em được không em cảm_ơn mọi người,['#Q&A']
em chào mọi người em đang build <number> model nhận_diện cảm_xúc trên flask sau đó em đã thử dùng cả <number> cách là postman và dùng file request py để gửi request ảnh đến model của em sau đó model sẽ decode ảnh và analyze emotion có trong ảnh các bước của em diễn ra suôn_sẻ cho đến bước cuối_cùng trả về emotion thì lại trả về not found trong khi em test model riêng ngoài flask với cũng chính cái ảnh này thì vẫn trả kết_quả như_thường em không biết vấn_đề nằm chỗ nào nữa rất mong các anh các chị trong group có_thể cho em lời khuyên em xin cảm_ơn,"['#Q&A', '#python', '#cv']"
em có một source đã train đủ model em muốn nhờ anh chị chạy giúp em do máy em đang lỗi thư_viện chưa chạy được anh_chị giúp em với,['#Q&A']
geoffrey hinton bố_già của deep learning hi các bạn khi nói về deep learning nếu để kể_ra <number> trong những cái tên nổi_bật lỗi_lạc nhất người đã đặt những nền_móng ban_đầu cho deep learning và thậm_chí <number> trong các thuật_toán được ông đề_xuất đã dẫn đến khái_niệm deep learning mà chúng_ta sử_dụng rỗng rãi ngày_nay không ai có_thể phù_hợp hơn geoffrey hinton người vẫn được coi là bố_già của deep learning những đóng_góp của ông đối_với sự phát_triển của ai machine learning deep learning thì vô cũng nhiều dưới đây là tóm_tắt những đóng_góp nổi_bật nhất của ông mình sẽ điểm qua <number> vài đóng_góp mà đối_với mình là ấn_tượng nhất các bạn nhé ông là <number> trong số những người đã đề_xuất thuạt toán backward propagation thứ không_thể thiếu để có_thể tối_ưu_hóa các mô_hình deep learning ông đề_xuất thuật_toán để huấn_luyện deep belief nets thứ dẫn đến khái_niệm deep learning sau_này ông là tác_giả của tsne thuật_toán nổi_tiếng dành cho giảm chiều dữ_liệu bên cạnh pca đã quá_đỗi quen_thuộc ông là người tạo ra rmsprop <number> optimizer rất nổi_tiếng bên cạnh các sgd adagrad hay adam minibatch gradient descent cũng là <number> trong số các thành_tựu của ông ông chính là cha_đẻ của dropout layer nổi_tiếng giúp hạn_chế overfitting cifar <number> dataset là <number> đóng_góp khác của ông cho đến nay ông đã có <number> publications chúng_ta sẽ không_thể_hình_dung được ai ngày_nay sẽ như thế_nào nếu không có những đóng_góp của ông với cá_nhân mình thì ông cùng andrew ng và yann lecun là <number> idols ai của mình,['#sharing']
chào mọi người hiện_tại mình đang nghiên_cứu topic về ứng_dụng phát_triển các kỹ_thuật ml trong việc đảm_bảo phát_hiện phòng_ngừa tấn_công mạng có bạn nào đã đang làm về topic này không chúng_ta có_thể trao_đổi thêm về topic được không xin cám_ơn,"['#Q&A', '#machine_learning']"
tăng_tốc_độ chạy python <number> lần với cython hi các bạn khi các bạn chạy <number> script python mặc_định cpython sẽ được sử_dụng như là trình thông_dịch tuy_nhiên thì cpython không có bất_kì chức_năng tối_ưu nào thay vào đó nếu các bạn sử_dụng cython đoạn code của các bạn sẽ được convert sang_c ngôn_ngữ lập_trình nhanh và hiệu_quả hơn về mặt tính_toán để sử_dụng cython chúng_ta chỉ cần thực_hiện <number> vài thao_tác sau áp_dụng trên jupyter notebook thứ mình không thích cho lắm load cython <number> cell riêng load_ext cython thêm cython command trên cùng của <number> cell mới cython khi sử_dụng các hàm hãy định_nghĩa kiểu của các biến thay_vì cách dùng không cần định_nghĩa kiểu của python các bạn sẽ thấy khác_biệt rõ_ràng về tốc_độ vì_sao lại có sự khác_biệt về tốc_độ như_vậy như các bạn biết python là <number> ngôn_ngữ linh_hoạt với cùng <number> biến lúc đầu các bạn có_thể sử_dụng nó như <number> biến kiểu số_nguyên sau đó các bạn có_thể đổi nó thành biến kiểu chuỗi sự linh_động này khiến python phải đánh_đổi <number> thứ tốc_độ và bộ_nhớ cython giới_hạn sự linh_động vốn làm_nên thương_hiệu của python bù lại chúng_ta sẽ được hưởng lợi vô_cùng lớn về mặt tốc_độ và bộ_nhớ và kết_quả là như các bạn nhìn thấy trong hình,"['#sharing', '#python']"
em chào mọi người em theo yt học tensorflow em muốn cho ma_trận thứ <number> tự thêm các hàng vector <number> cho_cùng số hàng và số cột như matran <number> có hỏi chat gpt mà nó nói loanh_quanh mãi được mong mọi người giúp em có cách nào đưa nó về cùng số cột_số hàng em để code cho mn dễ copy đây import tensorflow as tf from tensorflow import keras from tensorflow keras preprocessing text import tokenizer from tensorflow keras preprocessing sequence import pad_sequences sentences love my dog love my cat you love my dog do you think my dog is amazing tokenizer tokenizer num_words <number> oov_token oov tokenizer fit_on_texts sentences word_index tokenizer word_index sequences tokenizer texts_to_sequences sentences padded pad_sequences sequences maxlen <number> print nword index word_index print nsequences sequences print npadded sequences print padded try with words that the tokenizer wasn fit to test_data really love my dog my dog loves my manatee test_seq tokenizer texts_to_sequences test_data print ntest sequence test_seq padded pad_sequences test_seq maxlen <number> print npadded test sequence print padded,"['#Q&A', '#python']"
vẫn là logic của hangman một bài nhập_môn rất phổ_biến khi mới học code nhưng có gắn thêm gui vào cho bắt_mắt project này có_thể thú_vị cho bạn nào đang giai_đoạn qua mức python căn_bản một xíu xiu vì bắt_đầu có sự làm_quen với thiết_kế có nhiều hơn <number> components trong <number> project cụ_thể là <number> folders chứa đồ và <number> python files thêm <number> file requirements txt bắt_đầu có nhiều functions cái nọ móc nghéo vô cái kia source code leoutas hangman2 github com,"['#sharing', '#python']"
em xin chào mọi người hiện_tại em đang gặp khó_khăn về việc convert từ image <number> sang image <number> như hình_ảnh trên mọi người cho em xin ý_tưởng và hướng xử_lý được không em cũng thử với việc tìm contour và vẽ đường bao từng contour sau đó đo góc lệch rồi xoay nhưng không thành_công em là newbie nên rất mong học_hỏi từ mọi người,"['#Q&A', '#cv']"
chào việt và mn trong nhóm học ngành data science và đang học quản_trị dữ_liệu lớn vì môn này trên trường mới chỉ được học về pyspark và kafka nên khi thầy ra bài_tập lớn cuối kỳ bọn em rất ít ý_tưởng để làm đa_số mọi ngừoi đều làm về recommendation việt và mn trong nhóm có idea nào khác và có nguồn tham_khảo nào hay thì giúp em với được không em cảm_ơn mn,"['#Q&A', '#data']"
chào mọi người cho em hỏi vì_sao matrix trong linear reg lại là ma_trận 2xn chứ không phải 1xn chiều,"['#Q&A', '#machine_learning']"
em chào mọi người chuyện là em mới học_về ngôn_ngữ lt python cách đây chưa lâu trong quá_trình em làm bài_tập liên_quan đến việc tương_tác với các file trên máy thì máy em có vấn_đề là mã vẫn chạy được ko bị lỗi nhưng nó cũng ko cho ra kết_quả em có lên gg để tìm nhưng thật_sự em ko biết diễn_tả làm_sao để gg nó hiểu nữa nói_chung là em tìm một đằng mà cái giải_pháp của gg nó ra một nẻo rồi em có lên các group chat thì người_ta chỉ là để_ý xem cái đường_dẫn file của em nó có khớp với cái thư_mục mà file đó nằm không tại nhiều khi không đúng vị_trí là nó bị lỗi gì ấy hiện_tại em rất mơ_hồ trong cái vụ này em cũng biết là bài này nó trông cũng có vẻ cơ_bản quá nhưng mn nếu có_thể thì hướng_dẫn giúp em cách tạo thư_mục sao cho mỗi lần tương_tác với các file thì không bị dính lỗi với ví_dụ lần gần nhất là em học cách tính_toán với dữ_liệu trong <number> file docs lúc đầu em làm câu đọc dữ_liệu từ file thì chạy nó vẫn ra kq nhưng những câu sau là tính cộng_trừ nhân chia in ra số lớn nhất nhỏ nhất trung_bình_cộng thì mặc_dù ko bị báo mã lỗi nhưng nó cũng không cho ra kq gì hết liệu có phải do file ko nằm đúng vịt trí nên tương_tác với nó ko được ko em cảm_ơn mn chúc mn có một ngày làm_việc năng_suất ạaa,"['#Q&A', '#python']"
hiện_tại đạng gặp vấn_đề là tọa_độ dự_đoán trên ảnh bị lệch so với tọa_độ thực_tế chọn <number> điểm trên ảnh làm gốc sau đó đưa ra tọa_độ vật thế dự_đoán thử nhân ox với oy với hệ_số_nhân nma không khả_dụng lắm mọi ng có_thể gợi_ý cho cách giải_quyết đc không,"['#Q&A', '#cv']"
các nguyên_tắc cơ_bản trong trực_quan_hóa dữ_liệu hi các bạn mình xin chia_sẻ với các bạn <number> tài_liệu vô_cùng thú_vị về chủ_đề data visualization khác với những tài_liệu khác mình từng chia_sẻ về cùng chủ_đề trong tài_liệu này ngoài việc với data như thế_nào thì nên chọn loại plot nào chúng_ta còn được tìm_hiểu về các nguyên_tắc cơ_bản về chọn màu_sắc độ tương_phản giữa nét vẽ và nền nhằm giúp cho các plot được nổi_bật và thu_hút hơn <number> tài_liệu ngắn_gọn nhưng vô_cùng hữu_ích link to pdf,"['#sharing', '#cv']"
em chào mọi người em đang có dự_định làm một chương_trình_duyệt các resume cv để xét độ phù_hợp với job description project này em muốn hoàn_thành để làm project cá_nhân dự_kiến chương_trình này sẽ có <number> chức_năng chính <number> kiểm_tra xem dữ_liệu đó phù_hợp với ngành_nghề nào nhất <number> khi duyệt cùng với <number> job description kiểm_tra xem phù_hợp mức_độ bao_nhiêu không chỉ duyệt xem có keyword không mà còn kiểm_tra từ khóa đó có gần với từ khóa có trong jd hay không mọi người có_thể đưa ra định_hướng cũng như gợi_ý lời khuyên cho em được không em xin cảm_ơn,"['#sharing', '#nlp']"
hãy chủ_động hơn trong quá_trình học dù các bạn học ai it hay bất_kì ngành nào hi các bạn thời mình còn là sinh_viên cả việt_nam và đức mỗi khi lên giảng_đường mình luôn tuân_thủ quy_tắc <number> không không hỏi không phát_biểu và không thảo_luận mình cảm_thấy thoải_mái và hoàn_toàn ổn ít_nhất là đối_với mình điều này không để lại hậu_quả gì lớn ngoài việc không thầy cô nào nhớ mặt mình tuy_nhiên đến bây_giờ khi bản_thân mình đứng lớp mình mới cảm_nhận được những gì các thầy mình ngày_xưa từng trải qua trong <number> vài lớp mình dạy mình thường_xuyên phải đối_mặt với tình_trạng dạy_học mà như đang diễn độc_thoại bất_kể mình có cố_gắng khuyến_khích các bạn học_viên tương_tác đến mức nào đi_nữa hỏi các bạn có ai không hiểu kiến_thức câu hỏi hay không không ai trả_lời hỏi xem có ai giải được bài không cũng không ai trả_lời nhiều lúc chỉ là những câu hỏi đơn_giản yes no question nhưng cũng không ai nói gì thực_sự có nhiều lúc mình chỉ muốn tắt mic tắt camera đi nghỉ sớm cho xong khi các bạn tham_gia <number> lớp_học bất_kể là online hay offline nếu các bạn không tương_tác với giáo_viên giáo_viên sẽ không biết họ đang dạy nhanh quá hay chậm quá giáo_viên cũng sẽ không biết có kiến_thức nào cần nói kĩ hơn không và quan_trọng nhất giáo_viên không biết bạn có hiểu họ đang nói gì hay không khi các bạn tham_gia <number> lớp_học hỏi là quyền_lợi của các bạn và trả_lời câu hỏi là bổn_phận và nghĩa_vụ của giáo_viên các bạn có quyền_lợi mà sao lại tự tước bỏ nó sự tương_tác từ các bạn sẽ giúp cho buổi học trở_nên tốt hơn các bạn dễ học hơn và giáo_viên dễ dạy hơn đó là mối quan_hệ winwin ngày trước mình cứ nghĩ đi tán các bạn nữ là việc khó nhất giờ đi dạy_học rồi mới thấy nhiều khi cạy miệng các bạn còn khó hơn mình chỉ muốn khuyên các bạn hãy cố_gắng chủ_động hơn trong quá_trình học bất_kể hình_thức học hay ngành học của các bạn là gì sau_này ra ngoài xã_hội các bạn sẽ còn phải chủ_động hơn nữa tham_gia vào buổi học thực_sự chưa có là gì là khó_khăn hay thử_thách cả,['#sharing']
em chào mọi người mọi người cho em xin tư_vấn về định_hướng với em hiện_tại đang là sinh_viên năm <number> chuyên_ngành kỹ_thuật phần_mềm em thấy mình thích học toán giải_thuật thuật_toán và mong_muốn nghiên_cứu về deep learning trong ai mà đến năm <number> trường em có cho học về ai with tensorflow thì em lên học theo lộ_trình như nào để không lệch khỏi quỹ_đạo em cảm_ơn mọi người,"['#Q&A', '#machine_learning']"
em đang đọc đến phần vector trong cơ_sở khác nhau đến chỗ này thì em không hiểu cái biểu_thức lắm em nghĩ là phải là ma_trận với ud là các vector hàng chứ,"['#Q&A', '#math']"
không biết mọi người thấy sao nhưng cá_nhân em thấy nguyên_nhân sâu_xa các nhóm kỹ_thuật kém chất_lượng là vì không lọc kỹ bài đăng và để những bài đăng như này xuất_hiện quá nhiều làm loãng group và làm các bài đăng chất_lượng bị trôi đi những bài đăng về những thứ quá cơ_bản mà em nghĩ khi bạn đó copy nguyên câu hỏi lên google thì chắc_chắn ra được đáp_án có khi còn chi_tiết và tận răng hơn là mất_công đánh_máy rồi chụp ảnh lên đây trong tương_lai cá_nhân em rất mong anh việt có_thể lọc kỹ các bài đăng hơn nữa vì những người hỏi những câu hỏi kiểu như_vậy chắc_chắn sẽ luôn là đông nhất trong bất_kỳ một nhóm nào muốn kéo tương_tác thì có_thể chọn hướng đi mọi người có_thể tự_do hỏi kiểu như_vậy vì có_thể thu_hút nhiều người như vậy hơn nữa nhưng em nghĩ chất_lượng vẫn hơn số_lượng và anh việt có_thể lên làm một bài đăng dạy cách đặt câu hỏi nhất_là khi giờ chatgpt có_thể lập tài_khoản bằng sđt việt_nam và việc copy code và hỏi nó bất_kỳ câu hỏi nào về cú_pháp code bug ... là cực_kỳ dễ_dàng và em nghĩ rằng nó có_thể giải_đáp tốt hơn và cặn_kẽ hơn rất nhiều so với vài dòng comment ngắn_ngủi của mọi người anh cũng có_thể làm một bài đăng về cách prompt trên chatgpt mình xin update một bài viết của anh tôi đi code dạo nói về vấn_đề này,['#sharing']
chào mọi người hiện_tại em đang là sinh_viên ngành hệ_thống thông_tin quản_lý tuy_nhiên em muốn nghiên_cứu về ai cụ_thể là machine learning và deep learning vậy nên cho em hỏi là với kiến_thức về đại_số giải_tích xstk và lập_trình python thì có nên chọn sách này làm khởi_đầu không nếu không thì nhờ mọi người đề_xuất cho em vài tựa sách dễ hiểu và bao_quát giúp em_em cảm_ơn nhiều,"['#Q&A', '#machine_learning', '#math']"
mọi người cho em hỏi là em bị lỗi valueerror high <number> và em đã lên gg và chatgpt nhưng nó bảo chỉnh lại giá_trị high ấy nhưng em không biết chỉnh như thế_nào để nó không bị lỗi nữa đây là bài_toán nhận_dạng biển số xe em cảm_ơn,"['#Q&A', '#cv']"
mình cài thư_viện sao nó vẫn báo lỗi và chạy nhỉ,"['#Q&A', '#python']"
em chào mọi người em đang có dự_định làm một đề_tài nghiên_cứu khoa_học có ứng_dụng neural networks trong lĩnh_vực logistics và quản_lý chuỗi cung_ứng nhưng hiện_tại em chưa tìm_kiếm được ý_tưởng để thực_hiện vì đây là đề_tài em dự_định solo mọi người có_thể recommend cho em một_số đề_tài em có_thể thực_hiện với em cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
số_lượng job theo số năm kinh_nghiệm yêu_cầu có_thể thấy hầu_hết các job data trên careerbuilder rơi vào mức từ <number> năm kinh_nghiệm,['#sharing']
xin sách hay kênh youtube hướng_dẫn python từ cơ_bản đến nâng cao cảm_ơn mọi người,"['#Q&A', '#python']"
dạ em xin chào mọi người em đang muốn tìm một_số sách tiếng việt về data analyst ấy anh chị có_thể giới_thiệu cho em vài cuốn sách hay để học từ căn_bản có được ko em cảm_ơn,"['#Q&A', '#data']"
em chào mọi người em có đang làm đatn về image caption generation em tạo <number> custom tokenizer để giới_hạn số_lượng vocabulary nhưng khi load model để train tiếp thì lại gặp vấn_đề bị sai kích_thước giữa file checkpoint và model em có thử đổi size nhưng có vẻ cách đổi size của em không đúng mọi người có giải_pháp nào không em cảm_ơn,"['#Q&A', '#cv', '#nlp']"
two minute paper kênh youtube tóm_tắt và review các tin nổi_bật về ai trong vòng <number> phút hi các bạn hôm_nay mình xin giới_thiệu với các bạn <number> kênh youtube vô_cùng nổi_tiếng trong cộng_đồng ai two minute paper kênh youtube này chuyên về lĩnh_vực ai machine learning deep learning các video của kênh thường rất ngắn loanh_quanh tầm <number> phút cho mỗi video nếu các bạn muốn bản_thân luôn được update với những trend cũng thư thông_tin mới nhất về ai mà không muốn đọc quá nhiều thì kênh này là <number> sự lựa_chọn tuyệt_vời dành cho các bạn link to youtube channel,"['#sharing', '#machine_learning']"
dạ em đang có chỗ này khúc_mắc mong các huynh đài giúp_đỡ em sử_dụng yolov8 sort để counting people walk in and out nhưng em không hiểu mấy code của các cao_thủ trên github em chỉ biết làm tới lấy cái center point và khi center point này chạm vào cái line thì <number> nhưng không biết khi nào in khi nào out mong các cao_thủ giúp_đỡ em cảm_ơn,"['#Q&A', '#cv']"
em chào mọi người em đã đi làm có <number> năm kn trong lĩnh_vực da chủ_yếu tập_trung về phần powerbi sql và <number> chút modeling em có dự_định học master về data science và em có dự_định nộp và mấy trường bên bờ bắc của nước mỹ boston uni northeastern uni drexel uni vì những trường đấy có chương_trình coop sẽ tốt cho sau nếu có ý_định làm_việc mỹ không biết ai trong group này đã học va dang những trường đấy thì cho em xin feedback về môn_học liên_quan tới ds hướng nlp hoặc chương_trình coop em cảm_ơn mọi người,"['#Q&A', '#data']"
em chào anh việt và mọi người hiện_tại em đang là năm nhất ngành data science hiện_tại năm nhất mới chỉ học đại_cương với giải_tích đại_số tuyến_tính ... thì em có đang tự học python mọi người cho em hỏi là <number> trong lúc học python thì có nên học song_song với machine learning hay đợi thành_thạo python rồi mới học machine learning <number> hiện_tại mới chỉ năm nhất nhưng em đang có dự_định du_học sang pháp tại trường em là đại_học việt pháp có hỗ_trợ học_sinh du_học sang pháp có bác noà trong này bên pháp cho em hỏi về ngành ai bên pháp có phát_triển không <number> nếu em định tìm_hiểu về chuyên_ngành ai kiểu machine learning hoặc deep learning thì em có nên học lên master không hay bằng cử_nhân là được rồi hiện_tại em đang có những câu hỏi như này em cảm_ơn,"['#Q&A', '#machine_learning']"
<number> paper về machine learning được trích_dẫn nhiều nhất từ trước đến giờ hi các bạn quay về thời_điểm năm <number> thời mình bắt_đầu học về ai lúc đó ai machine learning deep learning chưa bùng_nổ và phát_triển mạnh_mẽ như bây_giờ thời đó trong <number> năm chỉ có vài chục paper đáng chú_ý được công_bố tuy_nhiên các mô_hình kiến_trúc thư_viện hay thậm_chí là dataset được công_bố trong giai_đoạn này đã đặt những viên gạch vững_chắc cho sự phát_triển của ai nói_chung và machine learning nói_riêng sau_này trust me don overstate it các bạn có bao_giờ tự hỏi dựa vào đâu để người_ta đánh_giá xem <number> paper quan_trọng hữu_ích đến mức nào không <number> trong số các tiêu_chí phổ_biến nhất đó là dựa vào số lần được trích_dẫn number of citations trong các paper khác dưới đây là tổng_hợp <number> paper về machine learning được trích_dẫn nhiều nhất tất_nhiên rồi trong đó có những cái tên đã quá_đỗi nổi_tiếng ví_dụ deep residual learning for image recognition chính là nơi mà resnet cùng với khái_niệm residual connection đã quá_đỗi nổi_tiếng được chào sân đó các bạn adam method for stochastic optimization adam optimizer mà các bạn thấy xuất_hiện hầu_hết các paper về deep learning bên cạnh sgd đó random forests các bạn dùng scikitlearn chắc không còn xa_lạ gì với model này generative adversarial nets nơi mà gans kiến_trúc đứng đằng sau sự thành_công của rất nhiều ứng_dụng mà trong đó không_thể không kể đến deepfake được chào sân fasterrcnn idol dành cho bài_toán object detection vào những năm <number> cùng với yolov1 có_thể các bạn không biết nhưng tác_giả <number> model đình_đám này là đồng_nghiệp batch normalization accelerating deep network training by reducing internal covariate shift nơi mà <number> trong số các layer thú_vị bậc nhất trong deep learning batch norm được cho ra_mắt các bạn nếu để_ý sẽ thấy batch norm được cho ra_mắt vào <number> thì đến <number> đã có rất rất nhiều model áp_dụng layer này và còn rất nhiều nữa ... mình không rõ ngày_nay các bạn học ai machine learning trên trường như thế_nào nhưng thời của mình các sinh_viên nếu học nghiêm_túc hầu_hết ai cũng đọc nát các paper này rồi link to article,"['#sharing', '#machine_learning']"
em chào mn trong group em hiện_tại đang là sinh_viên cntt và muốn theo ai nên em muốn mọi người tư_vấn cho em là lộ_trình học như nào và mọi người có_thể chỉ cho em vài nguồn để học không,"['#Q&A', '#machine_learning']"
nếu bạn là người bắt_đầu học về ai từ <number> thì việc lựa_chọn roadmap là điều rất quan_trọng bởi sự bùng_nổ của generative ai dẫn đến sự ra_đời của hàng_loạt công_nghệ ai mới mà trong các giáo_trình biên_soạn trước đây chưa cập_nhật vì_vậy việc theo_dõi các kênh thông_tin về ai là cực_kỳ_quan_trọng ngoài việc chỉ học theo chương_trình trên trường lớp điển_hình trong đó mình thấy phần bị bỏ_qua khá nhiều là prompt engineering cho llm dưới đây là một roadmap khá hay mình nghĩ các bạn mới nên tham_khảo video này cũng nêu lên một thực_trạng của group các bạn rất e_dè khi hỏi và đa_phần mình thấy là đăng dạng ẩn danh có_lẽ vì sợ người_ta biết mình dốt đây là tư_duy rất không hay và các bạn phải tự_chủ_động thể_hiện kiến_thức mình ra mình nhớ đại_loại có một câu nói thế này nếu bạn không_thể lý_giải một vấn_đề cho người khác thì bạn chưa thực_sự hiểu vấn_đề đó vì_vậy hãy luôn mạnh_dạn trao_đổi và chia_sẻ lại cho người khác về những gì mình biết,"['#sharing', '#machine_learning']"
dạ mọi người cho em hỏi với em mới học đến mạng neural em thắc_mắc là làm_sao để mình biết cách chọn số lớp ẩn và số neural cho từng_lớp ẩn phù_hợp với bài_toán em cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
chào mọi người em có đang crawl data trên web bằng selenium khi em crawl dữ_liệu từ nhiều page thì đến page thứ <number> nó block em như này mọi người cho em xin cách có_thể xử_lý trường_hợp này với,"['#Q&A', '#data']"
em chào mọi người trong gr em đang muốn làm <number> project nhỏ về nhận_diện phân_loại cảm_xúc trong văn_bản tiếng việt mọi người từng nghiên_cứu hay từng làm vấn_đề này cho em xin hướng đi với tiện cho em hỏi có thư_viện nào dùng tốt cho tiếng việt không em cảm_ơn,"['#Q&A', '#nlp']"
hội_tụ như này có nhanh quá không anh_em,"['#Q&A', '#machine_learning']"
em chào mọi người và việt hiện_tại cũng vừa complete machine learning các kiến_thức basic như sx gt đstt và bây_giờ muốn chuyển sang deep learning cũng tìm qua <number> vài course như coursera hay edx nhưng cái thì mất tiền hoặc ko có exercise cụ_thể nên thành_ra chán_nản mong mọi người có_thể chia_sẻ lộ_trình học cũng như tài_liệu để có_thể học hiệu_quả hơn khi học deep learning cảm_ơn,"['#Q&A', '#machine_learning']"
data science job kì_vọng vs thực_tế không_thể đúng hơn các bạn,"['#sharing', '#data']"
em chào mọi người hiện_tại đang tự học ds và đang thử xây_dựng <number> vài mô_hình nhỏ nhỏ nhưng gặp <number> vấn_đề sau em đang dùng hồi quy để dự_đoán charge theo mô_tả là tiền bảo_hiểm đã dùng dựa vào các biến như age sex bmi children smoker region children smoker region đã được mã_hoá nhưng khi chạy xong thì sai_số rất lớn và kết_quả dự_đoán cũng kh đúng em muốn nhờ anh_chị giải_thích tại_sao lại như thế và có cách nào khắc_phục không tiện cũng hỏi luôn là biểu_đồ scatter chỉ sử_dụng <number> biến độc_lập và <number> biến phụ_thuộc thôi đúng nếu muốn vẽ biểu_đồ phân_tán của dữ_liệu này thì vẽ như nào bức ảnh <number> là dữ_liệu gốc bức ảnh <number> dữ_liệu sau khi đã tiền xử_lý bức ảnh <number> code chạy hồi quy em là newbie mong anh_chị giải_đáp,"['#Q&A', '#machine_learning', '#data']"
xin chào tất_cả mọi người hiện_tại em đang có <number> data tiếng việt không dấu khoảng 100k nhưng không có label và em đã trích xuất được 10k keyword được coi là các từ hoặc cụm từ được coi là tích_cực cho em hỏi giờ làm_sao có_thể đánh nhãn cho toàn_bộ data cho cả các câu tích_cực mà chứa keyword và sau khi đánh nhãn xong thì cho em hỏi mình nên dùng gì để embedding tiếng việt không dấu em xin cảm_ơn,"['#Q&A', '#data']"
em có viết lại giải_thuật hồi quy đa_thức mà sao hàm lỗi nó lại tăng em không biết sai chỗ nào hết mn cho em xin ít ý_kiến,"['#Q&A', '#python', '#machine_learning']"
em xin chào mọi người hiện_tại em đang là sinh_viên năm <number> theo học ngành ds và có ý_định chuyển sang linux vì thấy thú_vị và nhiều đàn_anh đàn chị và thầy cô sử_dụng cho em hỏi ngành ds thì linux lợi_thế hơn windows những điểm nào,"['#Q&A', '#data']"
chào mn mình hiện_tại muốn học thêm ml không phải chuyên_ngành của mình theo tìm_hiểu mình phải có kiến_thức về toán trước mà mình không biết bắt_đầu học toán từ đầu xin mn chỉ_dẫn lộ_trình học toán mình cảm_ơn,"['#Q&A', '#math']"
mọi người ơi cho mình hỏi nếu_như một mô_hình chạy detect <number> object để kiểm_đếm thì confusion_matrix như_vậy có đưa vào ứng_dụng thực_tế đc ko hay cần phải train lại cảm_ơn,"['#Q&A', '#machine_learning']"
mình sv ngoài ngành cụ_thể là kiến_trúc mình muốn train <number> instance segmentation model phát_hiện tường trên mặt_bằng như hình tường có nhiều độ dày <number> <number> <number> <number> ... đầu_ra mong_muốn của model phải có bounding box ôm sát tường như hình luôn hiện đã có data bản_vẽ đã đánh label mong ae trong ngành chỉ hướng để build <number> con như_vậy cho mình tự vọc vạnh mình chỉ thạo mỗi với <number> ít python cảm_ơn mn,"['#Q&A', '#cv']"
dạ em xin chào mọi người nay em có research về dense clustering thì thấy chỗ này bài viết này nói mean shift và affinity propagation đều thuộc về dense clustering thì sau khi nghiên_cứu cả <number> thuật_toán thì em vẫn ko hiểu vì_sao nó thuộc loại này mong mn giúp_đỡ em link bài viết,"['#Q&A', '#machine_learning']"
xin chào mọi người em hiện_nay đã ra trường từ tháng <number> năm nay em trước học về mảng cơ_điện_tử và bây_giờ đang làm về tự_động_hoá của bên samsung trên thái nguyên hiện_tại em đang muốn định_hướng sang mảng data analyst rồi từ đó phát_triển lên data science hiện_tại em đang học theo <number> phần chính là sql power bi và python lý_do em muốn chuyển ngành là vì công_ty em cũng đang dần sử_dụng một_vài thuật_toán trong ml cũng như đang áp_dụng nền_tảng spotfire tương_tự như power bi tuy_nhiên em đang khá mắc mảng python do cảm_giác lượng kiến_thức quá rộng và đang ko biết bắt_đầu_từ đâu và chia lộ_trình như nào cho hiệu_quả mọi người có_thể góp_ý cho em một_vài lộ_trình mà mng thấy hợp_lý không ah ngoài_ra anh_chị bạn nào cũng trong hoàn_cảnh giống em có_thể cho em xin ít lời khuyên được không vì hiện_tại đi làm bên cty đang có vấn_đề chủ_chốt là đi làm rất xa và tốn nhiều tgian di_chuyển em xin chân_thành cảm_ơn mọi người,"['#Q&A', '#data']"
python for data science cheatsheet cheatsheet đầy_đủ dành cho các data scientist đến từ datacamp đây là cheatsheet vô_cùng nổi_tiếng về python for data science đến từ datacamp nền_tảng học online phổ_biến nhất dành riêng cho data science <number> trang của cheatsheet này sẽ tổng_quát <number> chủ_đề thư_viện framework sau python basics jupyter notebook numpy thư_viện chuyên về các thao_tác với dữ_liệu đa_chiều scipy tương_tự numpy nhưng chuyên_sâu hơn pandas framework chuyên về làm_việc với dữ_liệu dạng bảng scikitlearn thư_viện chuyên về machine learning matplotlib thư_viện chuyên về trực_quan_hóa dữ_liệu seaborn thư_viện xây_dựng on top của matplotlib nổi_tiếng về mặt thẩm_mỹ bokeh thư_viện giúp xây_dựng những plot tương_tác thay_vì tĩnh như matplotlib hay seaborn <number> pages and that all,"['#sharing', '#data', '#python']"
chia_sẻ một demo nho_nhỏ về phương_pháp embedding rag hi_vọng sẽ giúp một_số bạn mới bắt_đầu với llms,"['#sharing', '#deep_learning']"
em xin chào anh việt và mọi người em hiện là sinh_viên năm <number> ngành ai tại một trường đại_học tầm trung việt_nam sau một năm nhìn lại thì thực_sự em nhận thấy mình không tích_lũy được kiến_thức gì nhiều vừa_rồi em có tham_gia một hội_thảo khoa_học nơi mà các diễn giả sẽ trình bài và bảo_vệ paper mà mình đã viết thật_sự điều đó đã truyền_cảm_hứng cho em rất nhiều khi có những diễn giả là các thầy cô thạc_sĩ tiến_sĩ nhưng cũng có những diễn giả chỉ mới là sinh_viên còn rất trẻ nhưng họ đã có nền_tảng kiến_thức vững_chắc cùng năng_lực nghiên_cứu để viết ra những paper về ai trước đây vì đam_mê nckh nên em cũng thử tìm_tòi chủ_đề cũng như kiến_thức để học dần nhưng những kiến_thức em tìm được thì chỉ mức biết đoạn code đó làm gì để chép vào thôi vì_thế em muốn xin tư_vấn của anh việt các anh_chị cùng thầy cô về con đường và kiến_thức nào để có_thể đưa mình đến việc có_thể viết được những paper cũng như làm nckh em biết con đường này rất khó_khăn nhưng em sẽ cố_gắng tìm_tòi và mong mọi người giúp_đỡ em xin cảm_ơn mọi người nhiều vì đã dành thời_gian ra đọc kính chúc mọi người sức_khỏe,"['#Q&A', '#machine_learning']"
chào mọi người em có một bài_toán cần nhờ mọi người giúp_đỡ cụ_thể là em có <number> tập dữ_liệu ảnh có nhiều vật_thể tập <number> là các ảnh chụp nguyên_dạng không bị chỉnh_sửa gì tập <number> là những ảnh đã qua chỉnh_sửa nhiệm_vụ của em là phân_loại tập ảnh đó và khi mình đưa <number> bức ảnh vào để phân_loại thì model phải khoanh vùng những điểm khác nhau của <number> bức ảnh bước phân_loại thì em đã làm được em nhờ mọi người gợi_ý cho em bước tìm điểm khác việt giữa ảnh gốc và ảnh đã qua chỉnh_sửa với,"['#Q&A', '#cv']"
chào mọi người trong nhóm em có được thầy giao cho <number> project làm trong <number> tháng là tối_ưu_hóa đường đi đa điểm multipoint route optimization có sử_dụng google maps api mọi người cho em hỏi mình nên sử_dụng model nào có_thể share cho em một_vài keyword để search và tự học ko nếu ai đã có kinh_nghiệm từng làm rồi thì có_thể cho em xin roadmap để dễ định_hướng hơn dc ko cảm_ơn mọi người đã bỏ chút thời_gian đọc,"['#Q&A', '#machine_learning']"
toàn thời_gian từ xa data scientist ưu_đãi lên đến <number> trong vai_trò này bạn sẽ làm_việc như một thành_viên chủ_chốt của một đội_ngũ phát_triển nhanh tham_gia vào tất_cả các bước của đường_ống mlops của chúng_tôi vào một ngày nhất_định bạn có_thể tìm thấy mình làm sạch và nhúng tập dữ_liệu nguyên_mẫu điều_chỉnh mô_hình quản_lý trôi dữ_liệu và lên kế_hoạch giải_pháp đẳng_cấp thế_giới cho các vấn_đề mới_lạ và đa_dạng thêm vào đó bạn sẽ cung_cấp các phân_tích và thuyết_trình để thúc_đẩy thiết_kế sản_phẩm và cải_thiện cuộc_sống của khách_hàng hơn <number> năm kinh_nghiệm làm_việc trong lĩnh_vực khoa_học dữ_liệu máy học tuyệt_vời trong giao_tiếp tiếng anh lợi_ích của chúng_tôi tất_cả các quyền_lợi cần_thiết của luật lao_động việt nam lương tháng <number> <number> ngày pto hàng năm với chính_sách giải_ngân tổng_duyệt hiệu_suất hàng năm ngân_sách chăm_sóc sức_khỏe <number> cho mỗi kỹ_sư mỗi năm trợ_cấp làm_việc tại nhà hỗ_trợ giáo_dục phổ_thông và phát_triển kỹ_năng gửi cv của bạn email ttram534@gmail.com phone zalo <number> ngọc trâm được dịch từ tiếng anh,"['#sharing', '#data']"
<number> thuật_toán machine learning với project đi kèm hi các bạn hôm_nay mình xin chia_sẻ với các bạn danh_sách <number> thuật_toán machine learning thật_ra <number> vài trong số này mình sẽ gọi chúng là phương_pháp hoặc khái_niệm thay_vì thuật_toán với python mỗi <number> thuật_toán sẽ được đi kèm với <number> project có source code và giải_thích đi kèm ngoài việc học và làm_quen với thuật_toán thì đây cũng là <number> dịp tốt để chúng_ta tìm_hiểu các thư_viện về machine leaning ngoài những cái tên đã quá_đỗi phổ_biến như scikitlearn hay xgboost link to pdf các bạn download file về rồi mới click vào các link được các bạn nhé,"['#sharing', '#machine_learning']"
mình muốn build các udf user defined function trên excel bằng python nhưng free nha chứ pyxll hay xslim thì tốn phí anh_em có kinh_nghiệm xin chỉ_giáo,"['#Q&A', '#python']"
em chào mọi người hiện_tại em đang làm đề_tài về phân_loại malware dựa trên hình_ảnh bằng cnn mảng này không phải là chuyên_ngành của em nên em đang gặp chút vấn_đề cần sự giúp_đỡ anh_chị có ai từng làm qua rồi hướng_dẫn em với em cảm_ơn nhiều,"['#Q&A', '#cv', '#deep_learning']"
mình là sinh_viên năm nhất từng học chuyên toán gần đây mình có thích_thú và tìm_hiểu về neural network và đọc được mấy thông_tin về liên_quan đến mô_hình ngôn_ngữ lớn như chat gpt từ mấy nguồn cũng khá nhiều view trên các nền_tảng kiểu nhu_cầu lớn về phần_cứng khi chạy training cho ngôn_ngữ lớn cụ_thể là trong học_kỳ này mình học các môn như lý <number> giải_tích <number> lập_trình cơ_bản trên hệ_thống số hay còn gọi_là môn kỹ_thuật_số mình muốn hỏi về những phần_nào trong những môn_học này đang được dùng nhiều vào lĩnh_vực của mô_hình ngôn_ngữ lớn như chatgpt bao_gồm cả phần_cứng và phần_mềm,"['#Q&A', '#deep_learning']"
hi các bạn với các bạn đang học hay tìm_hiểu về ai chắc các bạn đã từng nghe qua từ neural network hay mạng nơron neural network mô_phỏng cách mà não bộ của chúng_ta hoạt_động do đó mình tin chắc rằng hiểu rõ cách não bộ chúng_ta vận_hành sẽ giúp_ích cho các bạn trong quá_trình học deep learning mình xin chia_sẻ với các bạn hình mô_phỏng não bộ phiên_bản lược_giản,"['#sharing', '#deep_learning']"
the incredible pytorch danh_sách tổng_hợp tất_cả mọi thứ có liên_quan đến pytorch hi các bạn hôm_nay mình xin chia_sẻ với các bạn <number> website vô_cùng thú_vị tổng_hợp tất_cả những gì có liên_quan đến pytorch từ các tutorials projects libraries videos papers cho đến books tất_cả được tổng_hợp và update liên_tục trong danh_sách này dù các bạn mới bắt_đầu làm_quen với pytorch hay các bạn đã làm_việc với pytorch lâu năm thì các bạn sẽ luôn tìm được tài_liệu mình cần trong danh_sách này link numpy scikitlearn và pytorch vẫn luôn là <number> thư_viện quan_trọng nhất đối_với mình trong suốt những năm_tháng học và làm về ai,"['#sharing', '#python']"
mọi người cho mình hỏi về cách triển_khai mô_hình lstm vào thực_tế với ví_dụ dự_báo thời_tiết ngày hôm_nay là ngày dự_báo <number> ngày liền kề sắp tới <number> <number> ... <number> như_vậy bước qua_ngày <number> thì mô_hình mình có cần train lại với dữ_liệu thực_tế ngày <number> để dự_báo <number> ngày tiếp_theo <number> <number> ... <number> cảm_ơn,"['#Q&A', '#deep_learning']"
cheatsheet <number> trang tổng_kết kiến_thức data science đây là cheatsheet được thiết_kế nhằm giúp các bạn đang học về data science muốn hệ_thống_hóa kiến_thức hoặc ôn lại kiến_thức nhằm chuẩn_bị cho phỏng_vấn nội_dung được tổng_kết bao_gồm các phần sau data science là gì các kiểu dữ_liệu các bài_toán chính tổng_quát về xác_suất thống_kê mô_tả làm sạch dữ_liệu feature engineering phân_tích thống_kê các phân_phối xác_suất thông_dụng modeling các mô_hình tuyến_tính các mô_hình phi tuyến bài_toán phân cụm machine learning deep learning big data lý_thuyết đồ_thị phần này cá_nhân mình nghĩ các bạn bỏ_qua cũng được sql python link to pdf,"['#sharing', '#data']"
em chào mọi người em đang là sinh_viên và đang nghiên_cứu trong lĩnh_vực nlp vì_thế nên vấn_đề training cũng yêu_cầu rất nhiều bộ_nhớ vram em đã sử_dụng hết vram của google colab hay kaggle rồi nên em muốn hỏi mọi người cách sử_dụng gpu của máy local vào việc training trên jupyter notebook như thế_nào em cảm_ơn mọi người,"['#Q&A', '#machine_learning']"
cả nhà ơi ai có kinh_nghiệm làm_việc với graph neutral network không em đang tự đọc mà hơi khó hiểu ai có chút thời_gian rảnh và knghiem làm phần này rồi cho em trao_đổi nhé xin cảm_ơn và hậu_tạ,"['#Q&A', '#deep_learning']"
em chào anh_chị trong nhóm em là begginer đang học python và pandas để xử_lý dữ_liệu em có cài anaconda vào vì của em đã đầy không đủ space để cài khi em input pandas as pd thì hiện ra lỗi là lỗi không tìm thấy module trong trường_hợp này em nên xử_lý như thế_nào em cảm_ơn mn,"['#Q&A', '#python']"
learn python the right way cuốn sách dành cho những bạn mới bắt_đầu học lập_trình python hi các bạn mình xin giới_thiệu với các bạn <number> quyển sách vô_cùng đầy_đủ và chi_tiết về python quyển sách này rất phù_hợp với những bạn mới bắt_đầu học python mà không biết nên bắt_đầu_từ đâu các bạn có_thể download quyển sách để đọc offline hoặc sử_dụng giao_diện web để đọc online mỗi <number> chương đều có hướng_dẫn trên youtube để giải_thích chi_tiết về cú_pháp và chức_năng link to the book,"['#sharing', '#python']"
em chào mọi người hiện_giờ em đang gấp làm một dự_án ai về deep learning em có link github rùi chỉ cần làm giao_diện dựa trên source code đó thôi giao_diện web đơn_giản thể_hiện được tính_năng thôi mn có_thể ib em để mình thương_lượng em là sinh_viên về ngành kinh_tế nhưng trường bắt_buộc làm ai mong ad duyệt giúp em_em cảm_ơn,"['#Q&A', '#deep_learning']"
trước con_người thì con mèo cũng đã từng bị mất việc vì ai,['#sharing']
chào cả nhà nhờ cả nhà chỉ giúp mình làm hệ_thống điểm_danh bằng khuôn_mặt nếu làm_bằng face recognition thì khá chính các nhưng bị lag chạy chậm nếu làm_bằng harr cascade thì chạy mượt nhưng không chính_xác xin mọi người chỉ giúp có_thể áp_dụng cách nào tốt hơn không,"['#Q&A', '#cv']"
<number> data science machine learning project với code bằng python đi kèm với giải_thích hi các bạn mình xin chia_sẻ với các bạn danh_sách gồm <number> project data science và machine learning với code mẫu bằng python để các bạn có_thể tự xây_dựng nên các project cá_nhân của mình nhằm luyện_tập cũng như làm_đẹp cho github các nhân với mỗi project chúng_ta sẽ có giới_thiệu về bài_toán dataset tương_ứng what love most code mẫu với python giải_thích từng bước các project trong danh_sách này vô_cùng đa_dạng computer vision nlp timeseries recommendation system ... nói_chung là đủ cả việc có ít_nhất <number> project mỗi mảng sẽ giúp github của các bạn trở_nên đa_dạng và hấp_dẫn hơn rất nhiều với mình dataset luôn là thứ quý_giá nhất với mỗi project đây chúng_ta sẽ có <number> dataset tương_ứng <number> khi có dataset thậm_chí chúng_ta có_thể tự xây_dựng nên bài_toán mà chẳng cần_câu hỏi hay bài_toán cho trước các bạn có_thể tham_khảo code để xem người_ta phân_tích và xử_lý bài_toán như thế_nào sau đó các bạn hãy thử tự xây_dựng mô_hình cách tiếp_cận mới của riêng bạn link,"['#sharing', '#machine_learning']"
<number> project natural language processing với source code python giải_thích hi các bạn mình xin chia_sẻ với các bạn danh_sách <number> project về nlp xử_lý ngôn_ngữ tự_nhiên đây mặc_dù không phải là mảng mà mình chuyên nhưng những ứng_dụng trong mảng này thì vô_cùng thú_vị và đại_diện tiêu_biểu nhất hiện_nay chính là chatgpt các project này sẽ giúp cho các bạn có dịp practice cũng như là đẹp profile github của mình link to pdf các bạn cần down về rồi mới click được vào các đường link nha các bạn,"['#sharing', '#nlp']"
chào mng em đang sv năm <number> cntt chuyên_ngành công_nghệ phần_mềm vừa_rồi trường có tổ_chức thực_tập năm nay theo em thấy thì không học các trường top thì đi xin việc hầu_như chắc là phải thật giỏi hoặc nhờ ng quen_biết giúp đưa vào em cũng thuộc loại không phải trường top nên việc thực_tập cũng không tìm được công_việc liên_quan đến lập_trình lúc đầu em tính theo web cụ_thể fe nhưng thị_trường năm nay web em cảm_giác cạnh_tranh cao nên em cũng bắt_đầu thích chuyển sang tự học data science nhưng em muốn hỏi mọi người thị_trường ds tầm <number> năm nữa thì có ổn_định job hơn theo đánh_giá mng kh hay nên cứ ăn chắc mặc bền thì chọn web cố_gắng làm dc cả fe và be em cám_ơn admin,"['#Q&A', '#data']"
em chào mọi người em đang tìm_hiểu cách crawl data bằng selenium thì gặp phải thác mắc sau đầu_tiên là phần link sau khi lấy dc thì nó bị trùng nhau thứ <number> là chuyển qua trang mới mà ko có nút next để định_vị cám_ơn mọi người rất nhiều mong ad duyệt bài giúo em,"['#Q&A', '#data', '#python']"
em chào mọi người em thấy trong group cũng có vài bạn đề_cập đến chuyện phần_cứng khi học deep learning rồi hiện em thấy có một_số cách thường được mọi người dùng nhất bao_gồm google colab kaggle laptop gaming pc với card đồ_hoạ laptop có cổng thunderbolt với egpu remote desktop thuê cloud computing ... theo mọi người bây_giờ nếu em bắt_đầu thì cách nào_là tối_ưu chi_phí và hiệu_quả nhất,"['#Q&A', '#deep_learning']"
làm con game để luyện cài win đi ae,['#sharing']
em xin chào các anh_chị trong group đang là sv năm <number> ngành công_nghệ phần_mềm hiện_tại em đang có làm cho mình dự_án cá_nhân liên_quan đến phishing detection cụ_thể là giúp client né_tránh các url độc_hại công_nghệ em đang sử_dụng là spring framework jpa boot security mysql tuy_nhiên với framework trên chỉ có_thể phân_tích url dựa trên data được store sẵn trong database nên có suy_nghĩ sẽ dựa vào data này train <number> model dự_đoán anh_chị trong group cho em xin chút ý_kiến và kiến_thức cần có để hoàn_thành khâu này với em cảm_ơn mọi người,"['#Q&A', '#machine_learning']"
thay_thế bar plot bằng dot plot khi có quá nhiều giá_trị cần phải trực_quan_hóa bar plot cực_kì hữu_hiệu khi chúng_ta muốn trực_quan_hóa dữ_liệu với trục_hoành là categorical feature và trục_tung là continuous value trục_hoành là các tháng và trục_tung là dân_số trong các tháng đó tuy_nhiên khi số_lượng giá_trị categorical quá nhiều quá nhiều tháng thì bar plot sẽ khá là khó nhìn lúc này thì hầu_như chẳng ai để_ý đến độ cao của các cột nữa những lúc như vậy dot plot là <number> sự lựa_chọn phù_hợp hơn rất nhiều đơn_giản dễ theo_dõi và đầy_đủ thông_tin,"['#sharing', '#data']"
em xin chào mọi người em đang có một link git đề_tài giám_sát giao_thông bằng yolov5 ứng_dụng trên nhưng chưa biết train model và gán nhãn như thế_nào để source code hoạt_động do em không am_hiểu lĩnh_vực này rất mong được sự giúp_đỡ của anh_chị anh_chị nào xem và có_thể nhận giúp em có trả phí ak em xin cảm_ơn nhiều,"['#Q&A', '#cv', '#deep_learning']"
<number> project python với source code đi kèm hi các bạn mình xin chia_sẻ với các bạn danh_sách <number> project python đi kèm với mã nguồn bao_gồm <number> project cơ_bản <number> project nâng cao chủ_đề của các project này rất đa_dạng từ game app similator cho đến ai model cá_nhân mình thì thấy các project cơ_bản rất hữu_ích cho các bạn mới làm_quen với python còn các project nâng cao thì có khoảng <number> nửa trong số này mình nghĩ là có_thể sử_dụng để làm_đẹp cho github profile của các bạn link,"['#sharing', '#python']"
gửi các bác mình đang gặp vấn_đề với thư_viện underthesea như sau khi chạy với sublime thì vẫn chạy bình_thường_khi xuất ra file exe với pyinstaller thì báo lỗi như ảnh hiện_tại mình có folder báo thiếu như ảnh dưới tuy_nhiên không biết bổ_sung vào folder nào folder temp khi tắt chương_trình thì lại mất nên không biết bổ_sung vào folder nào các bác xem giúp em em cảm_ơn các bác,"['#Q&A', '#python']"
mọi người ai đã train paddleocr rồi cho thắc_mắc là trước đó đã train một bộ dataset <number> từ rồi và giờ lấy model đó train tiếp một tập data khác với số_lượng từ dài hơn thì đến lúc eval nó ra như dưới hình em xin thêm <number> ảnh làm ví_dụ data train và data eval không biết có ai giải_đáp cho là làm_sao để khắc_phục tình_trạng này được không em xin cảm_ơn,"['#Q&A', '#deep_learning']"
chia_sẻ academic report về deep learning của mình hi các bạn trong quá_trình học các trường đại_học hay cao_đẳng chắc_hẳn các bạn cũng sẽ phải <number> vài lần viết các báo_cáo khoa_học học_thuật mình xin chia_sẻ <number> trong số các report mình từng viết trong <number> practical course tại tu munich cũng không perfect còn dính <number> vài lỗi râu_ria nhưng dù_sao như ông_bà ta đã từng nói report vô thập toàn bạn nào học về deep learning thì chắc_chắn nhìn tiêu_đề của report sẽ thấy vô_cùng quen_thuộc mình chia_sẻ đây và mong là nó có_ích cho các bạn link to pdf,"['#sharing', '#deep_learning']"
chọn biểu_đồ trực_quan_hóa dữ_liệu như thế_nào hi các bạn với rất nhiều các thư_viện về data visualization như matplotlib seaborn hay plotly ngày_nay chúng_ta có vài chục sự lựa_chọn khác nhau khi muốn trực_quan_hóa dữ_liệu thông_qua các biểu_đồ tất_nhiên chúng_ta không muốn cứ mỗi lần lại show ra hết vào chục biểu_đồ cùng một lúc câu hỏi đặt ra là chọn biểu_đồ nào tài_liệu dưới đây sẽ tóm_tắt cách giúp các bạn chọn biểu_đồ dựa vào các thông_tin bao_gồm kiểu dữ_liệu đầu_vào mục_đích truyền_tải nội_dung truyền_tải ngắn_gọn đơn_giản trực_quan là những gì mình có_thể nói về tài_liệu này,"['#sharing', '#data']"
hello mọi người hiện_tại em đang làm một đồ_án website nhà_hàng em đã có chức_năng gợi_ý món theo rating mọi người cho em xin vài gợi_ý về ml dl để làm thêm cho đề_tài này với,"['#Q&A', '#machine_learning']"
the little book of deep learning cuốn sách được chắp bút bởi françois fleuret cha_đẻ của thư_viện keras hi các bạn nếu các bạn đã đang học về deep learning có_lẽ các bạn cũng đá từng ít_nhất <number> lần nghe đến cái tên keras cùng với pytorch và tensorflow thì keras là <number> trong <number> thư_viện deep learning phổ_biến nhất trên thế_giới hôm_nay mình xin chia_sẻ với các bạn quyển sách về deep learning được viết bởi cha_đẻ của keras françois fleuret quyển sách này không có động vào các mô_hình đao to búa lớn của deep learning mà chỉ tập_trung vào các kiến_thức cơ_bản nhưng thiết_yếu của deep learning bao_gồm loss gradient các layer trong nn cnn các ứng_dụng của dl trong các bài_toán cơ_bản điều mà mình đặc_biệt thích quyển sách này là nó thực_sự chỉ tập chung vào phần cơ_bản thay_vì sa_đà vào các kiến_thức hàn_lâm vi_mô mình rất recommend quyển sách này tới các bạn đang muốn bắt_đầu làm_quen và tìm_hiểu về deep learning link to pdf,"['#sharing', '#deep_learning']"
em chào mng hiện_tại em đang thắc_mắc có những cách nào để deploy một model ai lên thiết_bị android cụ_thể đây là em có <number> model emotion detect em muốn deploy lên một tablet samsung tablet này sẽ hiển_thị một bump chart về emotion của một lớp_học trong từng khoản thời_gian còn camera sẽ sử_dụng một camera khác để quan_sát lớp_học em cảm_ơn mng,"['#Q&A', '#machine_learning']"
gần <number> project machine learning với sample code bằng python hi các bạn mình xin chia_sẻ với các bạn danh_sách gồm gần <number> project machine learning với code mẫu bằng python để các bạn có_thể tự xây_dựng nên các project cá_nhân của mình nhằm luyện_tập cũng như làm_đẹp cho github các nhân với mỗi project chúng_ta sẽ có giới_thiệu về bài_toán dataset tương_ứng code mẫu với python và giải_thích từng bước giờ mình gợi_ý cách các bạn sử_dụng danh_sách này nhé đầu_tiên đối_với cá_nhân mình thứ quý_giá nhất từ danh_sách này không phải là câu hỏi hay code mẫu mà là dataset danh_sách này cung_cấp cho chúng_ta các dataset vô_cùng đa_dạng trải rộng nhiều mảng khác nhau <number> khi có dataset thậm_chí chúng_ta có_thể tự xây_dựng nên bài_toán mà chẳng cần_câu hỏi cho trước các bạn có_thể tham_khảo code để xem người_ta phân_tích và xử_lý bài_toán như thế_nào sau đó các bạn hãy thử tự xây_dựng mô_hình cách tiếp_cận mới của riêng bạn mình đã xem qua khoảng <number> project trong list này và code mẫu của người_ta chưa phải là tối_ưu there is room for improvement <number> điểm cộng của danh_sách này đó là có khá nhiều project có phần trực_quan_hóa khá ấn_tượng link to pdf,"['#sharing', '#machine_learning']"
hi mọi người em vừa kết_thúc năm <number> khoá bachelor of data science úc hiện_tại em đang rất cần tư_vấn định_hướng tiếp_theo cho ds năm sau có minor thì định chọn cloud computing vì thấy nó bổ_trợ ds nhiều các kiến_thức được học qua về toán statistic linear algebra còn programming thì học qua oop python và sql em nên chuẩn_bị thêm focus vào mảng nào và có_thể làm gì để nổi_bật resume vì em muốn xin intern vào hè năm <number> nhân_tiện đây em cũng cần <number> mentor giỏi có trả phí tương_xứng am_hiểu về thị_trường it úc thì càng tuyệt_vời thanks mn đã quan_tâm,['#data']
tóm_tắt nhanh trực_quan_hóa dữ_liệu với pandas tổng_hợp các biểu_đồ phổ_biến nhất với pandas và matplotlib link to pdf,"['#sharing', '#data', '#python']"
chào_đón thành_viên thứ <number> thú_thật mình cũng khá bất_ngờ với tốc_độ tăng thành_viên của group chúng_ta cùng điểm lại nhé <number> <number> group của chúng_ta được tạo <number> mem là mình <number> <number> chúng_ta đón thành_viên thứ <number> <number> <number> chúng_ta đón thành_viên thứ <number> <number> <number> chúng_ta đón thành_viên thứ <number> test thử kiến_thức về machine learning các bạn nhé nếu giờ chúng_ta xây_dựng <number> mô_hình linear regression để dự_đoán số_lượng thành_viên với đầu_vào là <number> ngày data của chúng_ta có <number> sample item như trên vậy điểm đầu_tiên <number> <number> <number> được coi là gì hả các bạn dựa vào mô_hình linear regression xây_dựng được các bạn đoán là tầm ngày nào chúng_ta sẽ cán mốc <number> thành_viên keep shining,['#sharing']
khóa học lập_trình python cơ_bản nâng cao python đang là <number> trong những ngôn_ngữ lập_trình phổ_biến nhất hiện_nay ứng_dụng của python trải dài từ thiết_kế web phát_triển game và đặc_biệt là được ứng_dụng trong ai ds ml dl ... thời_gian tới chúng_mình chính_thức triển_khai các khóa học về lập_trình python từ cơ_bản đến nâng cao các khóa học này sẽ dành cho các bạn từ chưa từng tiếp_xúc với lập_trình bao_giờ khóa cơ_bản đến các bạn đã có kinh_nghiệm về lập_trình và muốn tìm_hiểu thêm về các thư_viện như opencv pillow scikitlearn seaborn khóa nâng cao các bạn quan_tâm đến các khóa học này có_thể liên_hệ với chúng_mình qua zalo <number>,"['#sharing', '#python']"
hi_mn em muốn vẽ đồ_thị dạng này trong python và tính được độ lệch của từng điểm dữ_liệu thì như nào mọi người có sample code cho em tham_khảo với,"['#Q&A', '#python']"
hi hiện_tại mình đang theo course ml ai dl cv advanced của việt nguyễn và dự_định sẽ tham_gia hết <number> courses chuyên_sâu dl cv của mình tìm <number> mentor gia_sư tuần <number> buổi online <number> tiếng hướng_dẫn sửa bài_tập assignment liên_quan đến data statistic ml ai trong cả năm <number> thù_lao trao_đổi trực_tiếp mô_tả đang theo khóa chuyên_sâu việt nguyễn ml ai là ok tiện cho cả <number> hoặc chuyên_ngành ml ai các trường năm <number> năm <number> năm <number> share cho mọi người cộng_đồng trao_đổi học_tập prof andrew ng cofounder của coursera và deep learning có roadmap từ maths ml dl cho tự nghiên_cứu ngoài_ra coursera tài_khoản <number> tháng <number> năm udemy business thì ngoại_đạo có_thể mua 600k trên này mua tài_khoản coursera plus <number> tháng giá rẻ <number> ezkey vn ps để lại cmt hoặc inbox mình chủ_động liên_hệ thanks all,"['#sharing', '#machine_learning']"
tập_đoàn telekom của đức tổ_chức cuộc thi ai về mảng telecommunications topics cũng khá rộng và đa_dạng giải nhất lên tới <number> tỉ vnđ bạn nào thấy thích thì có_thể lập team tham_gia thử vì nó là global challenge mình ko được tham_gia vì là nhân_viên nhưng biết_đâu vẫn có_thể support lén được,"['#sharing', '#machine_learning']"
chào mọi người hiện đã học khá ổn về kiến_thức ml cũng như dl về code thì cũng đã biết chạy rồi nhưng em muốn học sâu <number> framework scikitlearn và pytorch để có_thể đi làm mọi người có_thể rcm cho em các nguồn để có_thể tự_tin nói là khá thành_thạo <number> framework này đc ko,"['#Q&A', '#machine_learning', '#python']"
coding challenge khi đi phỏng_vấn xin việc mình không biết các bạn có gặp phải tình_huống tương_tự không hồi mình vẫn còn là sinh_viên cũng như tầm <number> năm đầu khi mới ra trường khi đi phỏng_vấn xin việc và đến đoạn coding challenge mình rất hay bị kiểu mình hiểu câu hỏi thuật_toán để giải_quyết mình cũng biết code thì không khó nhiều khi dễ hơn bài lúc mình ngồi nhà practice cơ_mà đúng lúc đấy code thì như gà mắc tóc thừa cái này thiếu cái kia nói_chung toàn lỗi stupid mà mình cũng chẳng phải run hay hồi_hộp gì cả chả hiểu sao ...,['#sharing']
chào anh việt và mọi người hiện_tại em đang định mua máy để học ai em có kiếm thấy <number> con như trong ảnh không biết em nó oke chưa hoặc nếu mọi người còn option nào khác thì có_thể giới_thiệu cho em với được không budget em tầm 2526tr,['#Q&A']
machine learning luis serrano hi mọi người và việt nguyễn hôm_qua bận đi học với chạy deadline quá nên chưa đăng bài kịp sáng nay dậy sớm tranh_thủ đăng bài để lên trường hôm_nay giới_thiệu với mọi người cuốn machine learning louis serrano của nhà grokking học cái gì mới thì nguồn tài_liệu phong_phú và đi từ cái cơ_bản luôn rất quan_trọng để xây_dựng nền_tảng và cuốn này đáp_ứng được hai điều trên các khái_niệm luôn được giải_thích bằng hình_ảnh nên super dễ nắm và đọng lại trong đầu ngoài_ra như bao cuốn khác thì luôn có một repo github đi kèm với sách để cho mọi người tự mò hoặc xem tự làm theo đặc_biệt là code của học implement đa_số là bằng numpy kiểu như from scratch mà ít dùng thư_viện nên mình rất thích do sẽ giúp mọi người nắm_bắt thuật_toán kỹ hơn là dùng thư_viện có sẵn,"['#sharing', '#machine_learning']"
hot_news sử_dụng pandas nhanh gấp <number> lần mà không cần thay_đổi code blog mới nhất của nvidia ngày hôm_kia <number> <number> <number> đã cho ra_mắt cudf thư_viện giúp các bạn có_thể thực_hiện các hàm của pandas với tốc_độ nhanh gấp <number> lần điều đặc_biệt là các bạn không phải thay_đổi bất_kì câu_lệnh nào so với khi dùng pandas thông_thường tất_cả những gì các bạn cần làm là thêm vào đầu của script dòng sau load_ext cudf pandas và sau đó tất_cả mọi thao_tác làm_việc với pandas sẽ được hỗ_trợ bởi gpu và tốc_độ thì nhanh gấp <number> lần cudf repository mình đã test thử trên máy mình ubuntu với script python bình_thường chứ ko phải colab không được <number> lần nhưng cũng tầm <number> lần awesome,"['#sharing', '#python']"
dear mọi người hiện_tại mình có thử ml net để chạy thử data classification thì thấy các model của ml net có accuracy khá tốt như hình đậc biệt là fasttreeova lightgbmmulti và fastforestova không biết anh_em có ai có tài_liệu bài báo nghiên_cứu khoa_học về <number> model này không nếu được cho mình tham_khảo với nhe cảm_ơn all,"['#Q&A', '#machine_learning']"
em đang làm khóa luận về thuật_toán cnn dò_tìm lưu_lượng mạng bất_thường dựa trên log cho em xin hướng giải_quyết và cách làm với em chỉ đang có log thôi tiện_thể cho em xin tài_liệu dễ hiểu về cnn với tại em gv hướng_dẫn bắt phải hiểu rõ thuật_toán hoạt_động như thế_nào mới cho làm tiếp em xin cám_ơn,"['#Q&A', '#deep_learning']"
tự_động tạo code cho bất_kì <number> project ai nào chỉ với <number> vài cú click chuột hi các bạn hôm_qua mình vừa được đồng_nghiệp giới_thiệu cho <number> trang_web cực_kì_thú_vị giúp tự_động tạo code cho bất_kì <number> project ai nào các bạn chỉ cần chọn các thông_tin liên_quan đến model data các bước xử_lý rồi sau đó code sẽ được tự_động tạo ra và các bạn chỉ cần chỉnh_sửa <number> chút_xíu là đã có được <number> project hoàn_chỉnh rồi mình lấy ví_dụ như các bạn có_thể nhìn thấy hình dưới bước <number> mình chọn bài_toán classification các bạn có_thể chọn <number> trong <number> bài_toán khác nhau bước <number> các bạn chọn model ví_dụ đối_với bài_toán classification các bạn có <number> model khác nhau bước <number> các bạn chọn xem input data của các bạn thuộc loại gì các bạn có <number> loại khác nhau bước <number> các bạn có muốn sử_dụng feature selection hay không bước <number> các bạn có muốn áp_dụng tiền xử_lý dữ_liệu hay không bước <number> các bạn có muốn balance data hay không bước <number> nếu bước <number> bạn chọn yes thì bước này mới tồn_tại tại bước này các bạn sẽ chọn xem các bạn muốn oversampling undersampling hay kết_hợp cả <number> bước <number> các bạn có muốn chuẩn_hóa numerical feature hay không bước <number> các bạn có muốn biến_đổi dữ_liệu hay không sau khi các bạn chọn xong <number> bước trên code sẽ tự_động được sinh ra cho các bạn công_việc còn lại của các bạn chỉ đơn_giản là lắp data điền tên của các feature cũng như target vậy là xong nếu các bạn chọn các bài_toán khác regression timeseries forecasting các bước tương_ứng sẽ được đưa ra và công_việc của các bạn chỉ đơn_giản là chọn option cho từng bước là xong tuy_nhiên với cá_nhân mình mình khuyên các bạn hãy chỉ sử_dụng trang_web này nếu các bạn đã thành_thạo việc xây_dựng các mô_hình machine learning rồi và các bạn muốn tiết_kiệm thời_gian cho các bước code lặp_đi lặp_lại còn nếu các bạn là người mới học thì mình khuyên các bạn không nên lạm_dụng trang_web này vì_sao vì nó quá đầy_đủ các bạn sử_dụng nó rồi sẽ ỷ_lại và không biết cách tự xây_dựng <number> project hoàn_chỉnh từ az,"['#sharing', '#machine_learning']"
chào mn mình là sinh_viên năm thứ <number> cntt trước mình học định_hướng khác nhưng gần đây mình muốn chuyển về làm data tuy_nhiên kỹ_năng về data của mình chưa được mạnh nên đang có ý_định theo học course data analysis của bên mindx business không biết có ai đã và đang học course này có_thể cho mình xin ít review được không bên cạnh đó thì mình cũng nhờ ae chia_sẻ roadmap cho người khởi_đầu muộn như mình cũng như các course mà ae thấy uy_tín với mình chân_thành cảm_ơn,"['#Q&A', '#data']"
mọi người có ứng_dụng reinforment learning cho game cờ_vua chess không cho em xin với,"['#Q&A', '#machine_learning']"
mọi người cho em hỏi có tài_liệu nào dạy lý_thuyết toán của các mô_hình machine learning không em cảm_ơn,"['#Q&A', '#math', '#machine_learning']"
tổng_hợp các mô_hình cnn đáng chú_ý trong hơn <number> năm qua hi các bạn mình xin giới_thiệu với các bạn <number> bài báo tổng_hợp tất_cả các mô_hình cnn đáng chú_ý trong suốt hơn <number> năm vừa_rồi các mô_hình này đã góp_phần tạo nên những cột mốc quan_trọng trong sự phát_triển của deep learning trong suốt những năm vừa_qua link to paper note đây chỉ đề_cập đến các mô_hình classification thôi các bạn nhé ngoại_trừ dcgan cũng hợp_lý thôi khi hầu_hết các mô_hình dành cho các bài_toán phức_tạp hơn đều sử_dụng các mô_hình classification như là backbone feature extractor,"['#sharing', '#deep_learning']"
vì_sao relu lại được sử_dụng trong neural network trong khi nó không khả_vi hi các bạn nếu các bạn đã đang học về deep learning chắc_hẳn các bạn không còn xa_lạ gì với các activation function hàm kích_hoạt trong số các hàm kích_hoạt còn được sử_dụng phổ_biến ngày_nay relu và các biến_thể của nó chắc_chắn là những hàm được biết đến rộng_rãi nhất relu và các biến_thể của nó giải_quyết được các vấn_đề liên_quan đến vanishing gradient điều mà các hàm kích_hoạt đời_đầu như sigmoid hay tanh mắc phải như <number> lẽ tất_yếu sigmoid già thì relu mọc tuy_nhiên relu và hầu_hết các biến_thể của nó cũng có những vấn_đề của riêng mình <number> trong số đó là việc chúng không khả_vi không đạo_hàm được mà cụ_thể là tại điểm <number> điều này về mặt lý_thuyết là không chấp_nhận được vì chúng_ta tối_ưu neural network dựa vào gradient gradient được tính thông_qua chain rule quy_tắc dây_chuyền khi <number> mắt_xích bất_kì trong dây_chuyền không khả_vi thì không_thể áp_dụng chain rule không tính được gradient nữa vậy câu hỏi mình dành cho các bạn hôm_nay là vì_sao relu và hầu_hết các biến_thể của nó không khả_vi nhưng vẫn có_thể được sử_dụng trong neural network,"['#Q&A', '#deep_learning']"
mình muốn hỏi bạn nào có code chu_trình euler bằng python không cho mình xin với,"['#Q&A', '#python']"
xin chào anh việt và mọi người đang có <number> bài_tập cần sử_dụng api của chat gpt nhưng đang gặp vấn_đề khi gọi api mong mọi người chỉ em cách khắc_phục,['#Q&A']
trực_quan_hóa sự thay_đổi thứ hạng trong <number> khoảng thời_gian với bump chart khi chúng_ta muốn trực_quan_hóa sự thay_đổi thứ hạng trong <number> khoảng thời_gian bar chart là <number> sự lựa_chọn được nhiều người nhắm đến ... ... tuy_nhiên bar chart sẽ trở_nên khá rối_rắm và khó nhìn khi có quá nhiều category những lúc như_vậy bump chart là <number> sự thay_thế tuyệt_vời chúng được thiết_kế để có_thể trực_quan_hóa sự thay_đổi thứ hạng <number> cách đơn_giản và hiệu_quả,"['#sharing', '#data']"
em chào mọi người cho em hỏi đã có ai học qua các khoá ai của vietai hoặc ai vietnam chưa và <number> bên có ưu_điểm hoặc nhược_điểm gì nếu em theo ds hoặc nlp thì nên học bên nào em cảm_ơn nhiều,['#Q&A']
chào mọi người hiện_tại em đang học chuyên_ngành ai của trường em có tài_chính tầm 20tr thì có dạng laptop nào trên thị_trường mới cũ thuận_tiện cho việc học ko em có thấy mấy con như razel blade <number> cũ cũng ổn mng có_thể tư_vấn cho em chọn thêm <number> vài laptop nữa được ko chắc em chỉ cần nhẹ là ok tại việc đi_lại khá nhiều với lại chắc là card rời để train mấy model nhẹ,['#Q&A']
có làm bài_toán object detection xe các loại chưa em đang muốn tìm_hiểu xây_dựng bài_toán này làm project cá_nhân từ tìm_kiếm dữ_liệu đến xây_dựng mô_hình và deploy lên web app nào làm rồi cho em xin gợi_ý pipeline giải_quyết bài_toán này em cảm_ơn,"['#Q&A', '#cv']"
em chào mọi người em có thắc_mắc là muốn đọc những paper mới nhất về ai deeplearning machinelearning thì mình sẽ đọc đâu có nguồn nào tổng_hợp những paper mới ra_mắt hay không em cảm_ơn mọi người nhiều lắm,"['#Q&A', '#machine_learning']"
em chào mọi người hiện team tụi em đang thi một track mảng audio và có thắc_mắc là transform transform của tụi em là xuất ra ma_trận spectrogram như ảnh <number> cho audio tụi em chọn như_vầy đã đúng chưa với lại mình nên chọn waveform hay spectrogram để làm input đầu_vào cho model để train ngoài_ra còn cách transform nào khác hong em cảm_ơn mọi người vì đã đọc vấn_đề của team em xin_lỗi mọi người vì code team em còn hơi lủng_củng,"['#Q&A', '#deep_learning']"
bữa_nay cn mình ngồi nghịch roboflow một xíu thấy phiên_bản miễn_phí đã quá tốt như vậy rồi cảm_giác hơi hơi hoang_mang vì khi các framework đã sẵn_sàng như vậy rồi sẽ không quá khó để gần như ngay lập_tức có <number> model tạm chấp_nhận được sau đó đi tiếp các senior đi trước cho đội newbies đi sau định_hướng xem nên tập_trung vào hướng nào để tăng employability,"['#Q&A', '#cv']"
chả_là em mới có vga mới <number> ti để chạy dl nên em có <number> lựa_chọn nhưng mà cả <number> đều có vấn_đề nên em muốn hỏi mn có ai đã setup máy để dl mà có <number> trong <number> vấn_đề này <number> chạy colab bằng local gpu em load cái jupyter token em nhận đc trong anaconda prompt rồi nma nó lại chỉ là unable to connect to runtime thôi <number> chạy jupyter bằng gpu thay_vì cpu em thử tải mọi thứ nhưng cái nhớ của em nó bị fragmented nên cái directory nó không tải được hết các cái cần_thiết của visual studio cho cuda thế nên nếu có ai đã setup rồi và đã chạy đc rồi thì em xin hỏi mn có cách để giải_quyết vấn_đề trên hoặc setup <number> cách khác để em có_thể chạy dl cho cái project này em có với thầy được không em xin cảm_ơn trước nha,['#Q&A']
waterfall chart biểu_đồ mô_tả thay_đổi giá_trị trong <number> khoảng thời_gian đôi_khi trong quá_trình trực_quan_hóa dữ_liệu chúng_ta sẽ muốn mô_tả sự thay_đổi của <number> đại_lượng nào đó trong <number> khoảng thời_gian thay_đổi nhiệt_độ doanh_thu ... khi đó các biểu_đồ truyền_thống như line plot hay bar plot sẽ không phải sự lựa_chọn tối_ưu vì chúng mô_tả giá_trị cụ_thể thay_vì sự_biến_thiên của giá_trị những lúc như_vậy chúng_ta có_thể sử_dụng waterfall chart trong biểu_đồ này giá_trị đầu_tiên và cuối_cùng được trực_quan_hóa bởi <number> cột đầu và cuối sự thay_đổi các giá_trị giữa được thể_hiện qua độ cao và màu của các cột xanh tăng đỏ giảm vô_cùng đẹp_mắt và thuận_tiện phải không các bạn,"['#sharing', '#data']"
chào mn muốn làm một project nhỏ kiểu recommend sách bằng python dùng als với spark apache ấy mn có_thể gợi_ý em đề_tài tương_tự ko em cảm_ơn,"['#Q&A', '#python']"
chào mọi người hiện_tại các lý_thuyết về machine learning hoặc deep learning thì cơ_bản mình đã nắm dc nhưng về phần code thì mình có chút thắc_mắc mình không biết bắt_đầu_từ đâu mình là coder java nên python mình còn hơi mù_mờ mọi người có biết sách hay nguồn tham_khảo nào chỉ dành riêng để code python cho machine learning hay deep learning cho beginner,"['#Q&A', '#python', '#machine_learning']"
các bác cho em hỏi là nếu muốn học sâu vào ai thì có cần phải học ctdl và gt hay ko hay chỉ cần học đến <number> level nào đó thôi các bác giải_đáp giúp em với,"['#Q&A', '#machine_learning']"
xin chào mọi người mình là người mới tìm_hiểu python đang học cách làm student registration system hiện mình có <number> vướng_mắc xin mọi người giúp_đỡ như sau mình có <number> table danh_sách lớp_học file excel khi tạo <number> học_sinh mình sẽ dùng combobox để chọn lớp đây mình muốn khi click vào nút combox thì nó sẽ hiển_thị thông_tin lựa_chọn theo dạng bảng gồm nhiều cột khi chọn <number> dòng thì nó sẽ chỉ lấy mã lớp vào combobox mọi người ai biết giúp mình phát xin cảm_ơn,"['#Q&A', '#python']"
xin chào mọi người em đang làm một dự_án dùng mediapipe và opencv để phát_triển <number> chương_trình về pose correction cho các động_tác tập gym cụ_thể là động_tác squat về sau sẽ thêm <number> vài động_tác nữa code bằng python hiện_tại chương_trình của em chỉ detect được động_tác squat đơn_giản qua function tính góc đầu_gối khi test chương_trình thì mặc_dù em đứng yên không làm gì hoặc làm <number> vài cử_chỉ vu_vơ nó vẫn tự_động tính là <number> động_tác em muốn sửa bằng cách lọc bỏ noise trong lúc nó detect nhưng em không biết làm ai có kinh_nghiệm về mediapipe giúp em với nếu mọi người vẫn chưa nắm được vấn_đề em sẽ ib giải_thích kĩ hơn cảm_ơn mọi người đã đọc_post,"['#Q&A', '#cv', '#machine_learning']"
xin chào mng em là newbie em đang tìm_hiểu về <number> bài_toán python mà detect vị_trí các cầu_thủ trên sân thông_qua video trận_đấu sau đó tạo <number> map sân bóng và đưa dữ_liệu vị_trí đó lên từ đó theo_dõi về vị_trí di_chuyển của cầu_thủ đó trong suốt trận_đấu nói cách khác có_thể theo_dõi trận_đấu qua map đó luôn kiểu như minimap trong fc online nhưng em lại không biết về từ khóa nói_chung là không biết chỗ tìm_hiểu về bài_toán này em muốn hỏi ý_kiến của anh việt và mng,"['#Q&A', '#cv']"
học it ai đức nước đức không chỉ có mỗi tu munich hi các bạn từ ngày lập group đến giờ thi_thoảng mình thấy có <number> vài post các bạn hỏi về học it ai tu munich cá_nhân mình thì thấy rất vui và tự_hào tuy_nhiên có <number> vài điều mà mình muốn nói với các bạn nước đức không chỉ có tu munich đúng là rank của tu munich thì rất cao và đó cũng là lý_do chính ngày_xưa mình apply ngôi trường này nhưng thực_sự thì nước đức vẫn còn có rất rất nhiều trường khác có chất_lượng không hề kém_cạnh tum và rank thì cũng rất cao các bạn có_thể dễ_dàng tìm_kiếm trên <number> bảng xếp_hạng danh_tiếng nhất thế_giới là qs times higher education và shanghai ranking ngay berlin nơi mình đang sống cũng có <number> trường top vậy nên không nhất_thiết phải sống_chết vào tum bằng mọi giá các bạn nhé dành cho các bạn theo hướng it nói_riêng và kĩ_thuật nói_chung đức có tu9 <number> liên_minh gồm <number> trường kỹ_thuật hàng_đầu đức các bạn vào học bất_kì trường nào trong <number> trường này thì cũng đều là cực_kì tốt cả về chất_lượng và danh_tiếng các bạn thấy đó có rất nhiều sự lựa_chọn kể_cả các bạn có không vào tu9 mà học các trường khác thì cũng hoàn_toàn ok ko sao cả rất nhiều đồng_nghiệp của mình không phải người đức cũng chẳng phải người châu âu học các trường khác trên khắp nước đức họ vẫn xin được_việc và thậm_chí họ còn làm các role rất cao trong công_ty đừng quá nặng_nề việc phải học trường trường các bạn nhé quan_trọng là bản_thân chúng_ta học và tích_lũy được gì học harvard đi_nữa mà không nắm chắc kiến_thức thì đi phỏng_vấn cũng trượt thôi,"['#sharing', '#machine_learning']"
bài giảng khóa học nhập_môn_học máy và khai_phá dữ_liệu cho sinh_viên chương_trình tài_năng tại viện cntt tt đh bkhn hi các bạn dưới đây là bài giảng của khóa học nhập_môn_học máy và khai_phá dữ_liệu introduction to machine learning and data mining kì <number> được giảng_dạy cho sinh_viên chương_trình tài_năng tại viện cntt tt đại_học bách_khoa hà_nội khóa học được thực_hiện bởi pgs ts thân quang khoát hiện đang là trưởng_phòng nghiên_cứu về khoa_học dữ_liệu và giảng_viên tại bộ_môn hệ_thống thông_tin viện cntt tt đại_học bách_khoa hà nội bài giảng sẽ có slide tiếng anh nhưng video bài giảng thì là tiếng việt các bạn nhé link về mặt cá_nhân thì mình thực_sự rất tự_hào khi ngồi soạn post này đây là trường của mình viện của mình chương_trình tài_năng thì từ lâu đã là signature của trường rồi ngày còn là sinh_viên bách_khoa mình cũng từng có mong_muốn được vào cơ_mà chắc thi <number> lần thì cũng không chen vào nổi,"['#sharing', '#machine_learning']"
chào mọi người và anh việt thì không biết mọi người đã thử qua việc đọc mã qr trên cccd chưa em dự_tính làm một project nhỏ trích xuất thông_tin căn_cước nhưng thay_vì ocr thì thử theo hướng đọc mã qr nhưng em gặp tình_trạng là ko thể quét được mã sau thời_gian thử nhiều cái thì em thấy chỉ có zalo là đọc được không biết mọi người có gợi_ý nguồn hay thư_viện nào khác của python có_thể đọc được gợi_ý giúp em với em cảm_ơn,"['#Q&A', '#cv']"
toàn_bộ các thuật_toán machine learning được code from scratch dành cho các bạn muốn tìm_hiểu cách_thức xây_dựng các mô_hình trong machine learning đây là <number> repository rất nổi_tiếng trên github về machine learning <number> stars <number> forks trong repository này tất_cả các thuật_toán trong machine learning sẽ được code từ đầu mà không sử_dụng bất_kì thư_viện nào ngoại_trừ numpy các layer của deep learning cũng được code hết từ đầu luôn <number> repository khá thú_vị cho những bạn muốn đi_sâu tìm_hiểu bản_chất của các mô_hình thay_vì chỉ gọi chúng ra trong scikitlearn link to repo,"['#sharing', '#machine_learning']"
machine learning for absolute beginners đây là quyển sách được thiết_kế nhắm đến những ai chưa từng tiếp_xúc với ai machine learning dưới bất_kì <number> hình_thức nào toàn_bộ các khái_niệm được giới_thiệu và giải_thích theo những cách rất gần_gũi thông_qua hình_ảnh cũng như các ví_dụ thực_tế do là sách dành cho người mới nên các công_thức gần như được lược bỏ hết đối_với cá_nhân mình đánh_giá quyển sách này rất hợp cho các bạn trái ngành hoặc các bạn tân_sinh_viên muốn tìm_hiểu về machine learning còn với các bạn muốn học chuyên_sâu về ai machine learning thì các bạn sẽ cần những quyển sách nặng_kí hơn <number> chút link to pdf,"['#sharing', '#machine_learning']"
bản tiếng việt interpretable machine learning bản_gốc tiếng anh bản dịch tiếng việt hi các bạn hôm_nay mình xin chia_sẻ với các bạn bản dịch tiếng việt của <number> cuốn sách rất thú_vị interpretable machine learning học máy_khả diễn_giải cuốn sách này khai_thác <number> khía_cạnh mà ít đầu_sách về machine learning đề_cập đó là tính giải_thích diễn_giải của các mô_hình machine learning tính diễn_giải các bạn có_thể hiểu là khả_năng các bạn có_thể giải_thích được vì_sao mô_hình lại đưa ra kết_quả thế này thế kia hay yếu_tố nào từ dữ_liệu đầu_vào ảnh_hưởng lớn đến kết_quả dự_đoán đây có_lẽ là đầu_sách đầu_tiên mình biết được đi_sâu vào khía_cạnh này do phần_lớn người học về machine learning deep learning chỉ quan_tâm đến làm_sao để mô_hình có được performance cao nhất còn lý_do vì_sao thì ít được quan_tâm hơn,"['#sharing', '#machine_learning']"
dạ chào mn hiện_tại thì đang triển_khai mô_hình pandora fms và đang gặp một xíu khó_khăn trong việc xác_định xem phần ai của mô_hình nằm đâu ko biết ai trong nhóm mình đã từng tiếp_xúc qua mô_hình này có_thể cho hỏi một xíu dc ko,"['#Q&A', '#machine_learning']"
mọi người ai có kinh_nghiệm trong việc thu_thập custom data để luyện cnn cho em hỏi một_chút được không dự_án của em đang làm phải nhận_diện retail items tuy_nhiên retail items thì rất là đa_dạng tuỳ cửa_hàng nên là nếu mà thu_thập data bằng cách lấy máy_ảnh đi chụp mỗi loại item một rồi annotate hoặc là chụp nhiều ảnh mỗi item để dùng twoshots object detection detect object rồi crop ảnh ra bỏ vào model thứ <number> chuyên classificatjon thì có vẻ không thực_tiễn em có tìm_hiểu thêm thì có hai giải_pháp khá thú_vị mà có_thể triển_khai <number> lắp_đặt mấy camera để quay lại hình_ảnh của những retail items trong một cửa_hàng cụ_thể đó rồi annotate lên những camera footages để train model <number> sử_dụng matterport để quét 3d tất_cả những loại items và toàn_bộ cửa_hàng để generate digital twin để làm synthetic training data article dưới đây nói về việc này em mong xin ý_kiến của mọi người về vấn_đề này và những hướng giải_quyết tốt hơn nếu có_thể em cảm_ơn,"['#Q&A', '#cv']"
cho phép gửi file lớn chia nhỏ thành nhiều luồng để gửi có hiển_thị tiến_trình từng luồng ghép khi nhận cho phép trên khung giao_diện chat có_thể vừa chat vừa play video nhận được dạ em chào anh_chị em đang làm bài_tập lớn trên trường đề_bài như này em đã gửi file được nhưng ko biết các hiển_thị tiến_trình các thread cũng như chưa biết làm bài <number> ai cho em ý_tưởng được ko,"['#Q&A', '#data']"
mng ơi hiện_tại em đang làm thesis về đề_tài deep learning forecasting do chủ_đề này khá mới so với em và còn nhiều khúc_mắc chưa hiểu lắm mng trong group ai có_thể giải_đáp cho em vài câu hỏi được không em xin cám_ơn và sẽ hậu_tạ đầy_đủ,"['#Q&A', '#deep_learning']"
chào mọi người em có <number> bài_tập muốn hỏi mọi người đề_bài cho trước cực_đại và cực_tiểu thì sao vẽ được đồ_thị của nó bằng python,"['#Q&A', '#python']"
xin chào mọi người em vừa_mới switch quá máy mac muốn xử_dụng gpu của máy để load data bằng thư_viện pytorch nhưng mà_lại gặp phải chút vấn_đề mong mọi người ai có kinh_nghiệm có_thể giải_đáp giúp em cảm_ơn mọi người dưới đây là đoạn code em chạy the device to use mps_device torch device mps <number> torch set_default_device mps_device dataset imagefolder root dataset_path transform data_transforms define the percentage for each split train_ratio <number> test_ratio <number> total_size len dataset train_size int train_ratio total_size test_size total_size train_size train_set test_set random_split dataset train_size test_size error on this line train_loader dataloader train_set batch_size batch_size shuffle true test_loader dataloader test_set batch_size batch_size error trace traceback most recent call last file users vietpham1023 desktop pythonresourceyogapose convolutional_neural_net py line <number> in train_set test_set random_split dataset train_size test_size file users vietpham1023 anaconda3 lib python3 <number> sitepackages torch utils data dataset py line <number> in random_split indices randperm sum lengths generator generator tolist type ignore argtype calloverload file users vietpham1023 anaconda3 lib python3 <number> sitepackages torch utils _device py line <number> in torch_function return func args kwargs runtimeerror expected mps <number> generator device but found cpu đoạn này em có thử set lại cái generator trong thư_viện nhưng vẫn gặp phải lỗi set the generator device to mps <number> generator torch generator device mps <number> use the generator in the randperm function indices randperm sum lengths generator generator tolist error runtimeerror expected mps <number> generator device but found mps em tiếp_tục debug tới hàm này def __torch_function__ self func types args kwargs none kwargs kwargs or if func in _device_constructors and kwargs get device is none kwargs device self device replaced this line with kwargs device mps <number> but no luck return func args kwargs và nhận thấy kwargs device self device self device đây có giá_trị mps <number> và generator key trong kwargs dict có giá_trị mps em thử reassign kwargs generator device self device nhưng nhận được lỗi không ghi được value vào key này,"['#Q&A', '#python']"
em xin chào mọi người cho em xin hỏi một câu hơi lạc_đề tí so với chủ_đề trong group mình anh_chị có nghĩ rằng một người theo mảng ai ds nói_riêng và it nói_chung cần biết nhiều hơn một ngoại_ngữ không bao_gồm tiếng anh hay không em xin cảm_ơn anh_chị nhiều,"['#Q&A', '#machine_learning']"
mình làm trong ngành logistics cũng gần <number> năm dữ_liệu data phân_tích các kiểu cũng làm khá nhiều nhưng chỉ trên excel thôi gần đây mình cũng có tìm_hiểu ba và cũng cảm_thấy khá hưng thú nhờ mọi người tư_vấn giúp career path bên ngành này sẽ ntn và khả_năng bắt_đầu lại vs ngành thì liệu có khả_năng bằng các bạn trẻ hiện_nay ko,"['#Q&A', '#data']"
mọi người giúp mik lỗi này với mik import pandas để đọc file excel trong visual studio code nhưng nó cứ hiện lỗi unicode error mik xem youtube thì thử cách cho thêm chữ vào cái hàm pd read_excel hoặc đổi dấu thành trong tên file excel thì vẫn ko đc,"['#Q&A', '#python']"
dạ em chào mọi người em đang thực_hiện bài_toán multilabel segmentation với model unet cho dataset 3dircadb với <number> folder lần_lượt chứa những file dicom cho ctscan của patient và file dicom cho mask của riêng liver và riêng tumor em có tham_khảo quá_trình data preprocessing của một_số bài_toán tương_tự trên mạng thì em thấy họ dùng mask file dạng tif rồi dùng labelencoder của sklearn để tạo ra train_mask em muốn hỏi bài_toán của em thì nên xử_lí data như thế_nào trước khi dùng model và model em nên thực_hiện như thế_nào để đơn_giản nhất,"['#Q&A', '#cv', '#data']"
bản tiếng việt deep learning quyển sách được xuất_bản bởi mit press nhà xuất_bản của trường đại_học số <number> thế_giới về cntt đây là quyển textbook vô_cùng nổi_tiếng được xuất_bản bởi nhà xuất_bản viện công_nghệ massachusetts ngôi trường luôn đứng top <number> về cntt hầu_hết các bảng xếp_hạng trên thế_giới quyển textbook này bao_gồm <number> phần chính toán ứng_dụng và machine learning cơ_bản deep network nghiên_cứu về deep learning quyển sách này hoàn_toàn free và các bạn có_thể download tại có <number> điều rất may_mắn là đã từng có <number> nhóm dịch_giả dịch phần đầu_tiên sang tiếng việt và càng may_mắn hơn khi phần đầu là phần mà theo đánh_giá của mình là quan_trọng nhất toán và ml nền_tảng các bạn có_thể xem bản dịch này tại dành cho các bạn chưa biết thì quyển textbook này được sử_dụng như là tài_liệu tham_khảo trong rất nhiều các khóa học về ml dl trên khắp thế_giới,"['#sharing', '#deep_learning']"
aht tech chiêu mộ developer làm_việc tại và python tại hà_nội offer up to 25m vnd tháng từ <number> năm kinh_nghiệm tiếng anh tốt python tại seoul offer up to <number> triệu won năm vé máy_bay khứ_hồi từ <number> năm kinh_nghiệm tiếng anh giao_tiếp khá tốt tối_thiểu <number> năm đóng bhxh liên_hệ ngay trao_đổi và process nhanh lẹ skype live cid 4130a0d3821bb603 email tinhntv@arrowhitech.com,"['#sharing', '#python']"
chào mọi người em hiện đang làm automated pentest web with rl trước đó học rl thì chủ_yếu chạy trên môi_trường người_ta build sẵn như gym hmm với lại có env nào của mảng này được build sẵn giống như mấy game đc build bằng gym ko thì bây_giờ có bắt_đầu build môi_trường cho project của riêng mình định_nghĩa các state là các cột trong dataset này còn actions và reward là khi em khai_thác thành_công <number> lỗ hỗng mới thì <number> điểm khai_thác <number> lỗ_hổng có trong dataset thì <number> điểm fail thì là <number> điểm không biết định_nghĩa như trên này build env dataset thì có đúng cũng gặp khó_khăn trong việc code env rl mọi người ai có tài_liệu liên_quan đến này kh cho xin với em có đọc <number> số bài báo cũng như nhìn code liên_quan thì <number> số bài họ build env dataset còn <number> số bài không thấy nghĩ trong lĩnh_vực security thì dataset phải là thứ bắt_buộc khi áp_dụng ai vào chứ,"['#Q&A', '#machine_learning']"
tiền xử_lí dữ_liệu text tiếng việt chào mọi người mình có một dataset gồm <number> bình_luận trên tiki vn cần tiền xử_lí để tạo word2vec rồi embedding words vào model deeplearning cho bài_toán sentiment analyze dataset do nhóm mình tự crawl nên có rất nhiều vấn_đề xuất_hiện từ tiếng anh trong comment đôi_khi cả tiếng thái từ_ngữ viết liền nhau nhuthenay viết tắt sai chính_tả có những bình_luận random jfdshjkkdsf cũng có những bình_luận duplicate từ như goodgoodgoodgood tuyệttttt vờiiiiiiiiii sốchữ viết liền nhau 12kg 500gram 120k 120ngan 120nghin <number> tên nhãn hàng sunhouse adidas lg ... thời_gian <number> <number> <number> 27thang10 mã đơn hàng tiki tk2289432897 hiện_tại mình mới chỉ có hướng giải_quyết là dùng randomstringdetector để lọc được một phần random text loại bình_luận có ít words nhưng nhiều characters tách từ có chữsố liền nhau ... còn lại sẽ làm thủ_công cắt bỏ hoặc sửa lại comment cho đúng bạn nào có kinh_nghiệm clean text data thì cho mình xin một_vài giải_pháp thư_viện hỗ_trợ data thế này chắc_chắn phải làm thủ_công nhiều nhưng có một_vài tools hỗ_trợ thì giúp được mình rất nhiều việc mình xin cảm_ơn mọi người,"['#Q&A', '#nlp']"
em chào mọi người mọi người đã có ai học qua khoá ai của ai vietnam chưa cho em xin ít review em cảm_ơn nhiều,"['#Q&A', '#machine_learning']"
hello anh chị em có một thắc_mắc là khi đi làm triển_khai các dự_án ai trong thực_tế thì các hàm loss là mình sẽ phải tự xây_dựng đúng không theo như em tìm_hiểu thì bài_toán dạng image classification và segmentation thì phần_lớn sử_dụng hàm loss có sẵn như crossentropy nhưng bài_toán detection thì đa_phần mình phải tự xây_dựng làm loss nếu_như mình dùng mô_hình kiểu dạng như ssd thì mình phải tự nghĩ ra và xây_dựng làm loss của mình hay sẽ base trên một cái gì đó có sẵn để xây_dựng vậy em chưa từng làm dự_án thực_tế các công_ty bao_giờ nên chưa có kinh_nghiệm gì phần này mong các anh chị trong group giải_đáp em cảm_ơn <number>,"['#Q&A', '#cv', '#machine_learning']"
hướng_dẫn cách chọn biểu_đồ trực_quan_hóa dữ_liệu phù_hợp với các bạn đang đi học hay đi làm trong mảng data science có_lẽ các bạn không còn xa_lạ gì với khái_niệm data visualization hay trực_quan_hóa dữ_liệu với các thư_viện như matplotlib seaborn hay plotly chúng_ta có rất nhiều sự lựa_chọn biểu_đồ khác nhau tuy_nhiên chính vì có quá nhiều sự lựa_chọn đôi_khi chúng_ta cũng sẽ gặp khó_khăn vì không biết nên chọn cái nào tài_liệu dưới đây sẽ giúp các bạn có_thể chọn được loại biểu_đồ phù_hợp cho mỗi dữ_liệu mỗi bài_toán khác nhau link to pdf,"['#sharing', '#data', '#python']"
chào mọi người trong gr mình đang tính làm một_vài project như detection classification để push lên git nhưng vẫn có vài thắc_mắc khi xây_dựng model thì nên build lại từ đầu hay_là sử_dụng những model có khung sẵn như yolo sử_dụng weight đã qua train làm_sao để biết đc model nào phù_hợp với bài_toán của mình và nên đẩy những file nào lên git nếu_như sử_dụng model có sẵn thì làm_sao để lựa_chọn được số_lượng layers số unit trong mỗi layers size_kenel cho phù_hợp với bài_toán,"['#Q&A', '#deep_learning', '#cv']"
em chào mọi người em đang làm một project sử_dụng giọng nói để điều_khiển nhà thông_minh hướng của em là sử_dụng input giọng nói để convert thành text sau đó sử_dụng text để thực_hiện_hành_động hiện_tại thì em đã xong bước speech to text rồi còn hướng sử_dụng text để thực_thi_hành_động thì chưa có hướng research cụ_thể mọi người cho em xin vài keyword về vấn_đề này với em cảm_ơn,"['#Q&A', '#nlp', '#machine_learning']"
em chào mọi người em ngoi lên đây bởi_vì chưa tìm được hướng giải cho bài code này em có hỏi trên vnoi với gr ôn_luyện hsg tin rồi nhưng chưa thấy ai rep hết đề_bài thì như hình dưới em đọc hướng_dẫn thì bài này sử_dụng thuật_toán tham_lam nhưng hiện_tại em vẫn chưa biết ý_tưởng và cách implement thuật_toán tham_lam cho bài này như thế_nào không biết đây có ai đọc đề xong và có_thể chỉ em hướng đi cũng như code implementation cho bài này được không em cảm_ơn mọi người rất nhiều lý_do em post là vì <number> <number> em thi olp rồi bảng không chuyên mà em còn đang mông_lung vài thứ,"['#Q&A', '#python']"
how long become to done buồn cho em pc,['#sharing']
em chào mọi người em đang tìm_hiểu về mảng xử_lí ảnh và cũng mới làm được <number> số bài_tập như là nhận_diện khuôn_mặt_bằng web cam mọi người cho em xin bài_tập phù_hợp với trình_độ của em với em cảm_ơn,"['#Q&A', '#cv']"
chào mọi người em đang cần tìm nguồn để đọc cách dùng svd để giảm chiều dữ_liệu file bao_gồm cả code mọi người có chia_sẻ giúp em với,"['#Q&A', '#machine_learning']"
em chào anh việt và mọi người em năm nay học lớp <number> và mới học về machine learning đc <number> tháng trc đó đã học về python rồi nhưng cùng lắm chỉ dừng lại việc code mấy tool fb lỏd nên em bị kẹt về khoản toán vì chưa học qua mà chỉ sử_dụng đc công_thức kiểu máy_móc thôi anh_chị trong nhóm tư_vấn cho về trường_hợp này với,"['#Q&A', '#machine_learning', '#math']"
ai stories podcast nơi bạn vừa học ai vừa luyện kĩ_năng nghe tiếng anh ai stories là <number> trong số những kênh podcast nổi_tiếng nhất về ai đây chúng_ta sẽ có các podcast về ai data science machine learning deep learning được nói bởi các diễn giả khác nhau họ sẽ không nói về lý_thuyết hàn_lâm mà sẽ nói về ứng_dụng trải nghiệm và kinh_nghiệm của bản_thân họ khi học sử_dụng và làm_việc với ai <number> điểm mình thấy rất hay_là khi nghe các podcast này các bạn có_thể đồng_thời luyện kĩ_năng nghe luôn rất phù_hợp với các bạn nào đang muốn luyện nghe toeic ielts mình đánh_giá về độ khó là hơn <number> chút so với bài nghe toeic và tương_đương bài nghe ielts link to podcast,"['#sharing', '#machine_learning']"
chào mọi người hiện_tại em đang có tập data như thế này em muốn tham_khảo từ mọi người xem các bước tiền xử_lí như thế_nào trước khi đưa vào model nlp cảm_ơn anh việt nguyễn đã duyệt bài và cảm_ơn mn giúp_đỡ,"['#Q&A', '#data']"
em chào mn mọi người cho em tham_khảo về cấu_hình máy để train deep learning phục_vụ đồ_án học_tập với <number> cpu em nên chọn i7 <number> hay i5 13600k <number> gpu em nên ưu_tiên vram hay card em là em nên chọn rtx <number> 12gb hay rtx 3060ti 8gb ngoài cac cpu và gpu em nhắc đến mọi ngươi có_thể gợi_ý cho em cấu_hình không em cảm_ơn mn budget em khoảng 2526m cho cả bộ em dự_định dùng cpu 2nd,"['#Q&A', '#deep_learning']"
tài_khoản coursera free hi_mn mn có_thể qua dol ny gov để đky tài_khoản coursera free tài_khoản này là do chính_phủ hỗ_trợ những người thất_nghiệp ny có_thể học được các khoá có professional certificate nhá có_thể đăng_ký lần đầu không được như mình đăng_ký <number> lần mới thành_công mn có_thể cho mình <number> star tại đây nếu cảm_thấy có_ích,['#sharing']
bản tiếng việt machine learning yearning quyển sách với hướng tiếp_cận độc_đáo được chắp bút bởi prof andrew ng lại <number> lần nữa mình share sách gốc xong rồi mới biết có bản tiếng việt cách đây mấy hôm mình có chia_sẻ với các bạn về quyển sách machine learning yearning <number> trong số các best book về ai của prof andrew ng ... ... thì đến hôm_nay mình mới vô_tình biết được là group machine learning cơ_bản của anh tiệp đã từng dịch quyển sách này rồi do đó mình xin chia_sẻ lại phiên_bản tiếng việt của quyển sách này đây link to pdf mình down về và tải lên drive vì đã từng thấy có nhiều bạn gặp trục_trặc trong việc down tài_liệu về từ github nguồn,"['#sharing', '#machine_learning']"
em hiện_tại mới đi thực_tập <number> công_ti nhỏ em làm nghiên_cứu là chính nhưng do công_ti start up nên nó trở lên nhiều việc hơn thì sếp cho em <number> con server ubuntu và muốn em đưa code chạy ai lên đó nhưng không dùng các lệnh pip apt để tải gói chỉ dùng ssh hay công_cụ nào đó chuyển file lên và gõ lệnh py file py là run về phần dùng code nối với các lib của pip thì em đẩy lên được nhưng các phần như các gói apt cần thêm thì em chưa biết cách xử_lí như nào ví_dụ em link code tới thư_viện ultralytics thì khi chạy sẽ báo thiếu distutils và em cần cài thêm apt install python3 7distutils thì cách đưa nạp các phần thiếu này như nào theo em nghĩ là em sẽ tra xem gói python3 7distutils khi tải về nằm đâu và em save lại và đẩy lên đúng vị_trí đó server trước_mắt là em thấy nó sẽ khá tốn thời_gian vì có_thể nhiều gói còn về cách thực_hiện như này liệu được không thì em chưa thử hi_vọng mọi người giải_đáp và đưa ra <number> số hướng cho em tìm_kiếm thêm em xin cảm_ơn <number>,"['#Q&A', '#machine_learning']"
chào anh việt và mọi người em là sv của <number> trường thuộc đhqg tp hcm mới ra trường chuyên_ngành của em là ai cụ_thể là thiên_hướng về mảng computer vision trong <number> năm đi học em không tham_gia nckh cũng như lab trường nên chỉ với tấm bằng giỏi hiện_tại em không_thể tìm được cho mình một công_việc vị_trí liên_quan em đang rất stress khi các nhà tuyển_dụng đều đòi_hỏi nhiều kinh_nghiệm thực_tế em mong mọi người cho em một hướng đi hoặc các kỹ_năng cần phải có của một ml ai engineer cần phải có để hoàn_thiện mình hơn câu văn hơi lủng_củng mong mọi người thông_cảm,"['#Q&A', '#machine_learning']"
xin chào mọi người hiện_tại em đang làm chương_trình nhận_diện các thành_phần của ngôi nhà như cột tường trần nhà cửa_sổ em sử_dụng yolov8xseg train khoảng <number> vòng nhưng do dữ_liệu em thu_nhập được rất ít chỉ khoảng <number> tấm em muốn hỏi rằng liệu có thuật_toán nào có_thể khiến cho máy có_thể tô màu thẳng bo lại theo đúng như hình thật không nhem_nhuốc không xin cảm_ơn mọi người rất nhiều,"['#Q&A', '#cv', '#deep_learning']"
đồ_án tốt_nghiệp của mình hi các bạn trong những ngày qua mình đã nhận được rất nhiều inbox của các bạn hỏi về quyển đồ_án ngày trước mình làm lúc học tu munich cụ_thể là <number> bạn do cũng không có gì quý_báu trong quyển đồ_án này nên mình xin chia_sẻ với các bạn đây topic mình làm là scalable image search with deep image representation nôm_na là xây_dựng mô_hình deep learning làm chức_năng tương_tự google image search engine gọi là xây_dựng cho oai cơ_mà phần main của model là có sẵn rồi link to pdf,"['#sharing', '#deep_learning']"
em chào mọi người cho em hỏi việc phát_hiện người chuyển_động qua cam thì cần logic phát_hiện như nào em đang tính là dùng <number> frame liên_tiếp rồi trừ đi ra <number> list chuyển_động sau đó dùng <number> model yolo detection ra người kết_quả là các motion nếu bbox của người thì là người đó có chuyển_động em nên dùng cách như nào trong thực_tế thì <number> camera phát_hiện chuyển_động sẽ dựa qua gì ngoài_ra là em muốn mỗi person detection thì set tham_số yolo với classes <number> là ra ngườngười thì tốc_độ yolo sẽ nhanh hơn so với detect hết object của nó như nào và có model nào chỉ detect người tốt không em xin cảm_ơn ạa,"['#Q&A', '#cv', '#deep_learning']"
"đố vui ai trúng thưởng kỳ <number> hi_all nhằm giúp xây_dựng group của chúng_ta có thêm các hoạt_động giao_lưu giải_trí kể từ tuần này việt và mình sẽ tổ_chức các event đố vui định_kỳ được tổ_chức 1,2 lần tuần thể_lệ rất đơn_giản chúng_mình sẽ đưa ra <number> câu hỏi trắc_nghiệm về ai ds ml dl cv nlp các bạn tham_gia sẽ trả_lời các câu hỏi này trên google form đồng_thời lựa_chọn <number> con_số ngẫu_nhiên có <number> chữ_số để chúng_mình bốc_thăm ngẫu_nhiên ngoài_ra không phải yêu_cầu bắt_buộc nhưng mình hy_vọng các bạn tham_gia event này sẽ share bài viết lên fb wall của các bạn sau khi kết_thúc mỗi kỳ đố vui <number> tuần kể từ ngày bắt_đầu chúng_mình sẽ tiến_hành tổng_hợp kết_quả tất_cả các bạn trả_lời đúng từ <number> <number> câu hỏi trở lên được xem như hợp_lệ và chúng_mình sẽ tiến_hành bốc_thăm dựa vào con_số may_mắn mà các bạn đã chọn phần_thưởng có_thể là tiền_mặt hiện_vật ... phần_thưởng của kỳ <number> 200k vnd ck vào tài_khoản của các bạn thời_gian <number> <number> <number> <number> <number> <number> link tham_gia đố vui ai trúng thưởng kỳ <number>",['#sharing']
mình nhờ admin duyệt giúp bài thanks mình đang tìm <number> anh_chị mentor python cho bạn bât đầu nhập_môn này ai có_thể giúp mình thì trao_đổi nhé thanks,['#Q&A']
<number> chủ_đề quan_trọng trong data science được tổng_kết trong <number> trang cheatsheet đây là cheatsheet được thiết_kế nhằm giúp các bạn đang học về data science muốn hệ_thống_hóa kiến_thức hoặc ôn lại kiến_thức nhằm chuẩn_bị cho phỏng_vấn <number> topics được tổng_kết trong cheatsheet này bao_gồm thống_kê kiểm_định giả_thuyết các khái_niệm đánh_giá mô_hình linear regression logistic regression decision tree naive bayes mình có_thể khẳng_định đây là <number> trong số các mô_hình vô_dụng hiếm_hoi về mặt thực_tiễn mà vẫn được xuất_hiện trong rất nhiều tài_liệu support vector machines my favorite ml algorithm knearest neighbors clustering dimension reduction xử_lý ngôn_ngữ tự_nhiên neural networks convolutional neural networks recurrent neural networks boosting recommender systems học tăng_cường anomaly detection mình không dịch những từ mà mình thấy không thuận miệng các bạn nhé link to pdf,"['#sharing', '#data', '#machine_learning']"
hi các anh_chị chủ_đề này không liên_quan lắm nhưng cho em hỏi hiện_tại vị_trí ai ml engineer việt nam nhiều không ngoài_ra em đang là sv ngành an_toàn thông_tin trái_ngược chuyên_môn như_vậy thì có cơ_hội ko em rất đam_mê ai việc tự học khó_khăn nên em chỉ mong những câu hỏi trên sẽ giúp em có thêm động_lực thôi em xin cảm_ơn tất_cả anh_chị,"['#Q&A', '#machine_learning']"
không biết trong nhóm có bạn nào có ý_muốn học <number> khóa từ admin theo dạng handson projects không ý_tưởng là người dạy sẽ như một team lead cung_cấp supervision để giải_quyết <number> projects cụ_thể mức production standard mình nghĩ các bạn giai_đoạn chuẩn_bị muốn đi làm sẽ học được rất nhiều thậm_chí các bạn đang mức junior cũng học được xem một bạn senior sẽ như thế_nào mình thì đang tìm_kiếm <number> khóa học như_vậy,"['#Q&A', '#machine_learning']"
em chào mn cho hỏi là đại_học tum khi du_học hệ thạc_sĩ thì trường có cần chứng_chỉ ielts hay chỉ cần chứng_chỉ gre và gpa và ai bên kia có chương_trình dạy hoàn_toàn bằng tiếng anh cảm_ơn nhiều,['#Q&A']
tài_liệu tóm_tắt lý_thuyết hướng_dẫn_giải bài_tập xác_suất thống_kê bằng tiếng việt như các bạn đã biết thì xác_suất và thống_kê là <number> mảng toán vô_cùng quan_trọng trong data science mình trước đây cũng đã đôi lần chia_sẻ các tài_liệu về xác_suất thống_kê nhưng thường chỉ có_lý_thuyết mà không có bài_tập hoặc nếu có bài_tập thì sẽ không có giải do đó cũng không thuận_tiện lắm trong quá_trình các bạn tự học tự ôn_lai do đó hôm_nay mình xin chia_sẻ với các bạn <number> tài_liệu hướng_dẫn_giải bài_tập xác_suất thông kê bằng tiếng việt vô_cùng đầy_đủ mỗi <number> chương sẽ có các phần sau tóm_tắt lý_thuyết bài_tập hướng_dẫn_giải bài_tập chi_tiết đây là tài_liệu được tổng_hợp bởi <number> cựu sinh_viên đại_học quốc_gia hà_nội tài_liệu được trình_bày vô_cùng chi_tiết và đẹp_mắt <number> điểm cộng cực lớn là tác_giả dùng các màu khác nhau cho các đoạn text từ đó giúp chúng_ta dễ tập_trung vào những phần quan_trọng hơn mình đã xem khoảng <number> và có_thể đảm_bảo với các bạn đây là <number> trong các tài_liệu giúp các bạn học và ôn_tập xác_suất thống_kê tốt nhất bằng tiếng việt link to pdf,"['#sharing', '#math']"
mọi người cho em hỏi em train model ml trên jupyter khi đã có kết_quả emm muốn đưa lên web để cho người dùng đưa vào các thông_số để dự_đoán thì em phải làm saoo,"['#Q&A', '#machine_learning']"
em chào mọi người để mình chuẩn_bị cv cho việc đi thực_tập thì cv cần có những project về mảng gì và cần ít_nhất bao_nhiêu cái thì mình có_thể đi thực_tập em cảm_ơn mn,['#Q&A']
em chào anh việt và mọi người em mới tìm_hiểu về ml và dl mà em ko tìm đc tài_liệu nào như_ý_muốn em muốn tài_liệu hướng_dẫn train tập dữ_liệu mình tự chuẩn_bị là các file dạng idx em tách thành <number> tập train <number> tập để test trong <number> folder dữ_liệu là dạng file pcap các thiết_bị trong iot em chuyển về dạng file idx để làm đầu_vào cnn như kiểu mnist ấy ai có tài_liệu nào hướng_dẫn train mô_hình chia_sẻ cho em với em cảm_ơn,"['#Q&A', '#machine_learning']"
hot_news nvidia trở_thành nhà tài_trợ cũng như đối_tác mới nhất của scikitlearn có vẻ như trong tương_lai không xa chúng_ta sẽ thấy những linear regression hay random forest chạy trên gpu rồi các bạn ơi link to article vậy là sau_này không cần phải ngồi đợi dài cổ để chờ gridsearchcv chạy nữa các bạn nhỉ,"['#sharing', '#machine_learning']"
bản draft của understanding deep learning cuốn sách sẽ được phát_hành chính_thức vào ngày <number> <number> <number> bởi mit press đây là cuốn sách gây sốt trên linkedin trong suốt khoảng <number> tháng trở_lại đây cuốn sách này là tài_liệu allinone mà các bạn cần có về deep learning <number> chương của cuốn sách này sẽ đưa các bạn đi từ những khái_niệm cơ_bản về supervised learning neural networks cho đến các khái_niệm nâng cao như diffusion models hay reinforcement learning ngoài tài_liệu chính tác_giả còn release thêm <number> nguồn tài_liệu dành riêng cho giảng_viên và sinh_viên cụ_thể đối_với giảng_viên mỗi chương sẽ đi kèm với slide dạng pdf svg và ppt đối_với sinh_viên các bạn sẽ có tổng_cộng <number> bài_tập notebook xuyên suốt <number> chương của cuốn sách mình đã đọc thử <number> chương mà mình chưa có nhiều kinh_nghiệm là <number> <number> và <number> <number> cuốn sách cực_kì chất_lượng bìa của cuốn sách nhìn hơi thô nhưng nội_dung thì không phải bàn các bạn nhé mình highly recommend các bạn_đọc cuốn sách này link,"['#sharing', '#deep_learning']"
chào mọi người em đang tìm_hiểu về thuật_toán kmeans và có chút thắc_mắc với đoạn code dưới trong đoạn code dưới thì mình đã lấy các dữ_liệu cần_thiết từ databan đầu và gán vào data2 nhưng sau đó mình lại mới scaler data ban_đầu trong khi data đem đi train lại là data2 thì hàm scaler có vô_nghĩa không nếu không thì chức_năng của hàm scaler trong đoạn code dưới là gì em cảm_ơn,"['#Q&A', '#machine_learning']"
tổng_hợp các metrics cho bài_toán regression hi các bạn regression hồi quy là <number> trong <number> bài_toán cơ_bản của mảng học có giám_sát supervised learning bên cạnh bài_toán classification phân_loại dưới đây là tài_liệu <number> trang tổng_hợp <number> metrics thường được sử_dụng trong bài_toán regression để đánh_giá mô_hình bao_gồm mean absolute error mean squared error root mean squared error rsquared hay còn được biết đến với cái tên coefficient of determination adjusted rsquared đây thực_ra không phải kiến_thức khó nhưng dù_sao thì ôn_tập không bao_giờ là thừa cả link to pdf,"['#sharing', '#machine_learning']"
dạ em chào anh việt và mọi người em muốn viết một file py và khi run file thì mình có_thể cung_cấp các đối_số ngay trên lệnh giống bên dưới thì mình cần search từ khóa nào em search nhưng không ra được mọi người chỉ em với,"['#Q&A', '#python']"
em hiện_tại là sinh_viên năm <number> ngành công_nghệ thông_tin nghiên_cứu ai từ năm <number> và đến giờ cũng biết được khá khá từ computer vision đến nlp các giải_thuật về ml dl em đều cố_gắng học từ toán_học lên mỗi giải_thuật mới em học em đều biết chương_trình bang tay không xài thư_viện khi hiểu bản_chất thì moi học cách sử_dụng thư_viện hiện_tại đang tính đi thực_tập mà thấy mấy bạn giỏi qua nên em khá tự_ti không biết như_vậy đủ thực_tập chưa hay phải nghiên_cứu thêm thanks mn,"['#Q&A', '#machine_learning']"
mn cho mình hỏi cpu_frequency và price đều là <number> cột tại_sao cpu thì cần <number> ngoặc_vuông vậy,"['#Q&A', '#machine_learning']"
dạ em chào anh việt và mọi người thì em đang vọc_vạch tìm_hiểu cách viết một reponsitory hoàn_chỉnh trên github tuy là hơi vô_tri vì đưa project ipynb lên mọi người xem góp_ý giúp em cách viết với em viết readme nhưng không biết liệu có ổn hay không,['#Q&A']
em đang muốn tìm nguồn code để triển_khai dự_án skin lesion cho khuôn_mặt slsnet skin lesion segmentation using lightweight generative adversarial network đây là một pp đang cần code mà không biết tìm đâu với một phương_pháp nữa dùng pgan mọi người giúp em với cảm_ơn mọi người,"['#Q&A', '#deep_learning', '#cv']"
hello mọi người chuyện là em có <number> dự_án như này xây_dựng hệ_thống tư_vấn y_tế dựa trên dữ_liệu bệnh_án thì cho em hỏi cần sử_dụng phương_pháp nào để có_thể xây_dựng bài_toán để dự_đoán như đề_tài trên,"['#Q&A', '#machine_learning']"
hi mọi người hiện_tại em có một đề_bài như thế này dùng thuật_toán để xác_định mức_độ positive và negative của chuyên_gia về triển_vọng kinh_tế toàn_cầu và việt_nam em muốn hỏi xin anh_chị bạn em một_vài hướng đi cho đề_bài này trong số đó có cách nào là mới nhất cập_nhật nhất theo xu_hướng hiện nhất không em cảm_ơn mọi người nhiều,"['#Q&A', '#machine_learning']"
lecture notes của khóa optimization for data science của đại_học oxford hi các bạn oxford là trường nào thì chắc mình cũng không cần giới_thiệu với các bạn nữa optimization hay tối_ưu_hóa thì thật_ra không phải là <number> nhánh toán quá phổ_biến đối_với data science ít_nhất là so_sánh với xác_suất thống_kê đại_số tuyến_tính hay giải_tích khóa học này diễn ra trong năm <number> luôn theo quan_điểm cá_nhân của mình thì nó dành cho mảng machine learning hay deep learning nhiều hơn là cho data science mặc_dù mình thừa_nhận rằng data science sử_dụng nhiều kiến_thức của ml dl đây là khóa học dành cho chính sinh_viên của trường chứ không phải là khóa học online được thiết_kế giảm tải để dễ tiếp_cận cho học_viên học online trên khắp thế_giới do đó nội_dung là khá nặng các bạn nhé anyway trong khóa học này các bạn sẽ được học tất_cả các kiến_thức liên_quan đến optimization mà chủ_yếu là các kiến_thức có liên_quan đến gradient <number> phần cực_kì_quan_trọng trong deep learning link to pdf,"['#sharing', '#data', '#machine_learning']"
chào mọi người chuyện là em có bài_tập phải crawl data từ <number> page trên fb về để phân_tích nhưng em đang gặp khó_khăn trong việc crawl data về lúc thì crawl về được nhưng không có dữ_liệu bên trong lúc thì không crawl được đủ số bài dưới đây là thư_viện và code mà em dùng mng có hướng giải_quyết nào không em xin cảm_ơn,"['#Q&A', '#data', '#python']"
em chào anh_chị và các bạn em đang thực_hiện <number> project nho_nhỏ về nlp mọi người cho em hỏi đã có ai đã từng xử_lý dữ_liệu text tiếng việt cụ_thể là xử_lý lọc các từ ngoại_ngữ không phải tiếng việt trong câu chưa em có đang sử_dụng thư_viện pyenchant để lọc nhưng thực_sự nó lọc không tốt và vẫn nhầm_lẫn giữa tiếng việt và ngoại_ngữ ai có hướng giải_quyết có_thể giúp em không em cảm_ơn nhiều,"['#Q&A', '#nlp', '#python']"
chào việt và các ae muốn bắt_đầu học về machine learning ae có_thể gợi_ý cho em vài khóa học về ml được không em có tìm_hiểu trên udemy thấy có khóa này là best seller ae nào học rồi có_thể cho xin rv với với lại em nên ôn lại các kiến_thức toán song_song với quá_trình học hay là ôn trước rồi mới bắt_đầu học thanks ae đã đọc,"['#Q&A', '#machine_learning']"
em xin chào các anh_chị hiện_tại em đang là sinh_viên năm nhất ngành mạng máy_tính và truyền_thông dữ_liệu trường uit em rất đam_mê lĩnh_vực ml nên em có lên cho mình một lộ_trình_tự học như sau toán giải_tích xstk đại_số tuyến_tính python machine learning cơ_bản python framework tensorflow pytorch machine learning nâng cao cho em hỏi lộ_trình như_vậy ổn chưa em cũng muốn xin ý_kiến anh_chị chi_tiết về phần học machine learning em xin cảm_ơn mọi người đã quan_tâm đến,"['#sharing', '#machine_learning']"
mọi người cho em hỏi bây_giờ em muốn chỉ làm mượt viền và khử răn cưa mịn của segment mask mà ko làm giảm chất_lượng ảnh ko dùng blur hay filter ... thì nên làm thế_nào em cảm_ơn,"['#Q&A', '#cv']"
chào mọi người mình đang làm nhận_dạng biển số xe train biển số bằng yolo nhưng kết_quả không chính_xác lắm đối_với biển số bị nghiêng hay mờ ai có cách gì để cải_thiện độ chính_xác không và có cách gì để cải_thiện tốc_độ train không,"['#Q&A', '#cv', '#deep_learning']"
em chào mọi người em đang làm bài_toán convert model pytorch sang onnx sau đó convert onnx sang tensorrt anh_chị và các bạn ai đã từng convert thành_công một model đơn_giản thôi cho em tham_khảo code với em đã thử convert model resnet50 nhưng gặp vài lỗi vẫn chưa sửa được em cảm_ơn mọi người em làm theo hướng_dẫn trang này lỗi như vậy attributeerror tensorrt tensorrt builder object has no attribute max_workspace_size em đã thử cài lại các phiên_bản khác của tensorrt nhưng vẫn không được,"['#Q&A', '#deep_learning', '#python']"
em chào mọi người em đang là sinh_viên năm nhất ngành it trong ngành em năm <number> có_thể chọn trí_tuệ nhân_tạo và em cũng đang tính theo chuyên_ngành này hiện_tại em đang vướng_mắc chỗ học toán cao_cấp trên trường làm_sao để cải_thiện và lực học toán bình_thường có_thể làm về ai không hay cần giỏi hẳn về toán em cảm_ơn,['#Q&A']
"mình đang làm project về hand gesture đã chạy xog <number> số mạng cơ_bản custom lại theo data của mình như svm rf cnn yolo5 6,7,8 mobilenet ... để so_sánh hiệu_suất giữa các mạng basic và mạng mới bh muốn chạy grapcnn thì lại chục chặc phần đa là kb custom lại data như nào cho phù_hợp vs mạng bác nào đã từng sử_dụng qua grapcnn rồi thì cho mình <number> số kinh_nghiệm với build như nào data custom lại theo dạng gì share data ra làm_sao mình chạy khung xương bàn_tay <number> điểm vs grapcnn nhé","['#Q&A', '#cv', '#deep_learning', '#data']"
em xin chào mọi người hiện là em đang chuẩn_bị làm đồ_án môn_học chủ_đề là text to ads generator mọi người có_thể cho em xin vài nguồn để tham_khảo được không em xin cảm_ơn,"['#Q&A', '#cv']"
em chào anh việt và các cao nhân chuyện là em đang ôn để sắp tới thi olympic tin_học_sinh_viên và đang get stuck bài này <number> hình dưới đây là đoạn code python của em hình thứ <number> và giải đúng được <number> <number> subtask mọi người có_thể cho em hỏi cách để tối_ưu đoạn code của em để có_thể chạy full subtask link nộp bài đây,"['#Q&A', '#python']"
các bài viết không gắn hashtag sẽ không được duyệt xin chào các bạn lời đầu_tiên bọn mình rất biết_ơn mọi sự đóng_góp nhiệt_tình của các bạn để group có_thể tạo nên một cộng_đồng văn_minh cùng nhau chia_sẻ nhiều kiến_thức bổ_ích như ngày hôm_nay tuy_nhiên vài ngày gần đây năng_suất duyệt bài của đội_ngũ admin đã tạm_thời giảm đi do mất ăn mất_ngủ ... trước những bài viết không gắn hashtag bọn mình cũng đã đấu_tranh tâm_lý để duyệt trước những bài viết thú_vị và tốn nhiều tâm_huyết nhưng không hashtag của các bạn để tránh việc admin vào bình_luận nhắc_gắn hashtag làm loãng post của các bạn hãy cùng nhau hashtag từ bây_giờ nhé việc gắn hashtag có rất nhiều lợi_ích dễ phân_loại tìm_kiếm tăng khả_năng nhận được giải_đáp của những người có kiến_thức về chủ_đề và bài sẽ được duyệt trong một nốt_nhạc những bài không hashtag từ ngày 17.11.2023 sẽ không được duyệt kèm lý_do yêu_cầu gắn hashtag một hashtag lí_tưởng sẽ bao_gồm hai thông_tin <number> xx đây có_thể là <number> trong các giá_trị sau py python ds data science ml machine learning ds_ml hoặc liên_quan đến cả <number> dl deep learning cv computer vision thị_giác máy_tính nlp natural language processing xử_lý ngôn_ngữ tự_nhiên dl_cv deep learning for computer vision dl_nlp deep learning for nlp rl reinforcement learning <number> content xx_roadmap dành cho các post hỏi về lộ_trình xx_share dành cho các post share tài_liệu kinh_nghiệm xx_job dành cho các post liên_quan đến việc_làm xx_laptop dành cho các post hỏi máy_tính cấu_hình xx_challenge dành cho các post hỏi về các cuộc thi xx_study dành cho các post hỏi về việc học_hành xx_code dành cho các post hỏi về code code ko chạy lỗi ... relax dành cho các post mang tính_chất vui_vẻ giải_trí other không thuộc thể_loại nào trên thói_quen khó hình_thành nhưng một_khi đã quen thì khó bỏ cảm_ơn các bạn vì đã lắng_nghe và vì môt cộng_đồng ngày_càng lớn_mạnh hãy cùng hashtag từ bây_giờ nhé link tới bài viết gốc của anh việt,['#sharing']
chào anh việt và mọi người em đang chuyển từ code bằng vscode sang code trên colab nhưng có <number> vấn_đề là file csv khi chuyển lên ggdrive nó sẽ thành file gsheet vậy mọi người cho em hỏi là mình sẽ mở file gsheet như thế_nào có phải xử_lí với gspread và tạo khoá json không em cảm_ơn và cho em hỏi sao đoạn code này của em lại báo lỗi không có thuộc_tính service_account trong gspread vậy,['#Q&A']
em làm mô_hình để giải bài hồi quy bài_toán dữ đoán giá cổ_phiếu thì layer cuối_cùng để <number> unit và hàm kích_hoạt trên layer cuối_cùng này sẽ là hàm kích_hoạt tuyến_tính và các lớp ẩn em sẽ sử_dụng hàm kích_hoạt phi_tuyến như sigmol hoặc relu và sau khi huyấn luyện xong em cho mô_hình chạy trên tập test và em dùng bình_phương lỗi để đánh_giá mô_hình đó có xài được hay không thì muốn hỏi là thì trong bài_toán hồi quy thì hàm kích_hoạt trong các lớp ẩn có_thể là các hàm kích_hoạt tuyến_tính không và nếu có thì nó có hiểu quả hơn so với hàm kích_hoạt phi_tuyến không và em muốn hỏi nữa là sau khi chạy thử model ra được bình_phương lỗi em biết là bình_phương lỗi càng bé tức_là mô_hình càng chính_xác nhưng mà em thắc_mắc là có một chuẩn chung nào để đánh_giá không tức_là giả_sử như giá_trị hàm lỗi phải bé hơn một ngưỡng nào đó thì model đó mới sử_dụng được kiểu vậy thanks mn đã nghe em hỏi,"['#Q&A', '#deep_learning', '#machine_learning']"
two questions technique chìa khóa giúp chúng_ta không bao_giờ nhầm_lẫn giữa tp tn fp và fn với các bạn học về machine learning có_lẽ các bạn không còn xa_lạ gì với confusion matrix khi cần đánh_giá các mô_hình binary classification nữa chúng_ta đều biết rằng bất_kì <number> prediction nào của model sẽ đều rơi vào <number> trong <number> loại sau true positive tp true negative tn false positive fp false negative fn <number> thuật_ngữ này có những người phân_biệt rất dễ nhưng cũng có những người rất hay bị nhầm_lẫn đặc_biệt là nếu các bạn mới học và sau <number> thời_gian các bạn không động vào thì rất dễ bì nhầm giữa chúng <number> mẹo để giúp các bạn có_thể phân_biệt được dự_đoán của mô_hình rơi vào loại nào trong <number> loại trên đó là thông_qua việc trả_lời <number> câu hỏi sau câu hỏi <number> dự_đoán đúng hay sai nếu đúng thì là true nếu sai thì là false câu hỏi <number> dự_đoán là về class positive hay class negative kết_hợp <number> câu trả_lời trên lại các bạn sẽ có đáp_án,"['#sharing', '#machine_learning']"
em chào mọi người em đang muốn kiếm các bài_toán thực_tế về việc ứng_dụng computer vision trong retail để nghiên_cứu anh chị nào có bài_toán nào hay và có_thể ứng_dụng được trong thực_tế không em xin cảm_ơn,"['#Q&A', '#cv']"
em là newbie moi ng cho em hỏi là kiến_trúc alexnet có một cái bước là local reponse normalization vậy thì bước chuẩn_hoá đó để làm gì công_dụng của nó cách_thức thực_hiện chuẩn_hoá của nó,"['#Q&A', '#deep_learning']"
mình có <number> file giống nhau một_cách quá_đáng luôn và chụp màng hình code của mình bài này mentor hướng_dẫn mình rồi nhưng thật_sự không thoã mãn và đã chôn câu hỏi này gần <number> tháng và giờ mình mong mọi người giúp mình với df pd read_csv filepath1 sep header none index_col none engine python sep có lỗi gì mà chỉ có một_số file thì load tạo bảng cấu_trúc tương_tự file gốc còn một_số file phải dùng sep và khi load gom tất_cả các cột trong file ra thành <number> cột mình chân_thành cảm_ơn mình biết là trong nhóm này có bạn đăng_ký cùng khoá học với mình thật_sự mọi người dạy mình đều đã hỗ_trợ rất nhiệt_tình nhưng mình chưa thấy thoã mãn nên mang lên đây hỏi thôi,"['#Q&A', '#python']"
chào mọi người hiện_tại em đang gặp vấn_đề trong việc xử_lý file excel cụ_thể step đọc file excel em có <number> file excel hoàn_toàn bằng tiếng việt file xlsx và encoding ansi em có mở để check thì file hoàn_toàn bình_thường nhưng khi dùng pandas để đọc và convert sang file json thì bị lỗi font file json bên dưới em đã thử chuyển file excel về encode utf8 nhưng vẫn bị lỗi chang không biết mọi người có biết cách xử_lý vấn_đề này hoặc <number> library nào khác đọc excel file và convert về json có hỗ_trợ tiếng việt không em cảm_ơn,"['#Q&A', '#python']"
em chào mọi người em hiện đang bắt_đầu làm project về ml dl để vừa học vừa cải_thiện bản_thân mọi người cho em hỏi là bình_thường_khi bắt_đầu làm thì làm_sao để mình có_thể biết cần viết những file nào cấu_trúc file của project đó ra sao và khi nào thì viết theo hướng oop và khi viết theo oop thì có cần viết theo design pattern không nếu có thì khi theo hướng ds ml dl thì chọn mẫu nào,"['#Q&A', '#python']"
chào mọi người em đang xây_dựng mô_hình lstm để dự_đoán chuỗi thời_gian em đang quan_trọng precision của lớp <number> hơn là các thông_số khác như accuaracy recall ... mọi người cho hỏi có cách nào để code chạy mô_hình theo_dõi và làm tăng trực_tiếp precision của lớp <number> không em cảm_ơn,"['#Q&A', '#deep_learning']"
learning deep learning tài_liệu bao_gồm lý_thuyết và thực_hành về nlp cv và transformer của nvidia hi các bạn kể_cả với những ai không học về ai deep learning mà chỉ cần có chút_xíu kiến_thức về máy_tính thôi thì có_lẽ các bạn cũng biết nvidia là ông trùm về mảng card đồ_họa với riêng mảng deep learning nếu không có những card đồ_họa mạnh_mẽ của nvidia thì chúng_ta chắc_chắn sẽ không bao_giờ có những chatgpt hay midjourney nvidia vào năm_ngoái cũng đã cho ra_mắt <number> tài_liệu dài hơn <number> trang để tổng_hợp các kiến_thức thiết_yếu về deep learning tài_liệu này không đi quá sâu vào các công_thức mà giúp chúng_ta có cái nhìn khái_quát về ứng_dụng của deep learning trong các lĩnh_vực khác nhau đánh_giá của cá_nhân mình <number> tài_liệu không tốn quá nhiều thời_gian để đọc nhưng vô_cùng hữu_ích để hệ_thống_hóa kiến_thức link to pdf,"['#sharing', '#deep_learning']"
review <number> tổng_hợp các mô_hình object detection thời_gian thực_post này dành riêng cho người chơi hệ deep learning for computer vision giống mình đây là bài báo tổng_hợp các mô_hình object detection trong thời_gian thực được thực_hiện vào tháng <number> <number> <number> mô_hình với <number> backbone khác nhau sẽ được đưa lên bàn cân để so_sánh và đánh_giá theo <number> tiêu_chí trên <number> bộ dataset cụ_thể hơn <number> mô_hình được so_sánh bao_gồm thundernet mô_hình 2stage duy_nhất trong danh_sách này yolo ssd detr centernet ttfnet fcos nanodet lần đầu mình nghe đến tên mô_hình này realtime nên những mô_hình 2stage như faster rcnn tất_nhiên là bị loại từ vòng gửi xe các bạn nhé mình cũng hơi ngạc_nhiên là có <number> mô_hình 2stage lọt vào danh_sách này mỗi <number> mô_hình trên sẽ được test lần_lượt với <number> backbone sau resnet darknet xception mobilenet shufflenetv2 vovnet chưa nghe bao_giờ v2 <number> efficientnet hardnet deit chưa nghe bao_giờ v3 <number> trong <number> tiêu_chí thì đối_với cá_nhân mình map trong bài báo này người_ta ghi là accuracy param và speed là quan_trọng nhất <number> dataset được sử_dụng thì tất_nhiên không_thể thiếu những pascal voc coco hay cityscapes cityscapes thì thật_ra nổi_tiếng với bài_toán instance segmentation chứ đây cũng là lần đầu mình thấy được áp_dụng vào object detection note có <number> điểm mình không ưng từ bài báo này đó là sử_dụng từ accuracy thay_vì map sử_dụng tên <number> metric của bài_toán classification dành cho metric của bài_toán object detection là <number> điều khá hài_hước link to paper,"['#sharing', '#deep_learning', '#cv']"
dạ chào mng em đang làm bài về ml em đang làm bài về dạng hồi quy đã làm xong bước để train sử_dụng model decisiontree với randomforest em đang thắc_mắc bước để đánh_giá mô_hình này không biết dùng r2 mae mse mình đánh_giá <number> lần như_vậy không biết có ổn không với sau khi em kẻ bảng như hình cuối thì em quyết_định chọn randomforest đúng chưa tại em tìm_hiểu mae với mse càng nhỏ thì độ chính_xác mới cao phải không em cám_ơn admin và mng,"['#Q&A', '#machine_learning']"
em chào mọi người do em là một newbie và em vừa học xong khóa ml của andrew ng em muốn học cả nlp và computer vision thì mọi người có_thể gợi_ý giúp em một_số khóa học chất_lượng không em xin cám_ơn,['#Q&A']
deep learning question vì_sao sigmoid và tanh không còn được sử_dụng nhiều nữa hi các bạn với những bạn nào đã và đang học về deep learning chắc các bạn cũng không còn xa_lạ gì với các activation function hay tiếng việt mình gọi là hàm kích_hoạt những hàm này tuy đơn_giản và thậm_chí hầu_hết còn không có parameter nghĩa_là sẽ không được update trong quá_trình huấn_luyện mô_hình vì đơn_giản là chẳng có gì để mà update tuy_nhiên chúng đóng vai_trò vô_cùng quan_trọng cho sự thành_công của deep learning như chúng_ta thấy ngày_nay vào thời_điểm khoảng <number> năm trở về trước có <number> hàm kích_hoạt được sử_dụng vô_cùng rộng_rãi và có_mặt trong hầu_hết các model nổi_tiếng đó là sigmoid và tanh cặp đôi này đi đâu cũng thấy xuất_hiện bởi những ưu_điểm sau <number> hàm này khả_vi có_thể đạo_hàm được tại mọi điểm điều này là vô_cùng quan_trọng do quá_trình chúng_ta update mô_hình là dựa vào gradient không khả_vi về mặt lý_thuyết khỏi nghĩ đến gradient riêng hàm tanh còn có thêm <number> ưu_điểm là hàm lẻ đối_xứng qua gốc tọa_độ tuy_nhiên về sau_này <number> hàm trên dần bị thất sủng và bị thay_thế dần bởi các hàm kích_hoạt khác như relu và các biến_thể của nó mặc_dù hầu_hết các hàm này đều không khả_vi tại điểm <number> ngày_nay các bạn hầu_như sẽ không_thể_nào tìm thấy <number> mô_hình neural network nào sử_dụng sigmoid hay tanh nữa sigmoid vẫn còn may_mắn là được sử_dụng trong logistic regression còn tanh thì coi như đã có <number> chỗ rất đẹp trong viện bảo_tàng ai vậy câu hỏi của mình đây là vì_sao ngày_nay người_ta không còn sử_dụng sigmoid và tanh trong deep learning nữa,"['#sharing', '#math']"
học thống_kê qua truyện_tranh đây là <number> trong số các đầu_sách thú_vị nhất mình từng gặp quyển sách này giải_thích cho chúng_ta tất_cả các khái_niệm trong thống_kê qua phong_cách truyện_tranh cực_kì vui_nhộn quyển sách này gần như là <number> mình <number> phong_cách trong tất_cả các đầu_sách mình từng đọc trong quá_trình học và làm về ai ds ml đây cũng là <number> cơ_hội tốt để các bạn luyện khả_năng đọc tài_liệu bằng tiếng anh vì so với mặt_bằng chung từ_vựng trong quyển sách này khá là ít và dễ link to pdf,"['#sharing', '#math']"
dạ xin chào mn em là sinh_viên năm cuối của một trường cao_đẳng nên là em đang có ý_định tìm trường để liên_thông đại_học ngành học của em cao_đẳng là cntt và nguyện_vọng ngành học khi liên_thông của em là khoa_học máy_tính nên em xin mọi người giúp_đỡ góp_ý giúp em vài trường đào_tạo liên_thông tốt để sắp tới em có_thể chuẩn_bị thật tốt cho việc liên_thông đại_học em cũng đã nghía được <number> trường trong kv tp hcm là uit và đh mở rồi anh_chị nào đang và đã từng học tại trường có_thể cho em xin ít review về trường được không văn vở em không được tốt nên có câu từ nào khiến anh_chị khó_chịu thì thông_cảm bỏ_qua giúp em với em cảm_ơn mn nhiều,['#sharing']
khoá học <number> buổi hoàn_toàn miễn_phí về generative ai vừa được cho ra_mắt bởi microsoft cách đây <number> tuần microsoft vừa cho ra_mắt khóa học miễn_phí với <number> buổi học về generative ai mỗi buổi học sẽ bao_gồm <number> video ngắn giới_thiệu về topic nội_dung được trình_bày cả dưới dạng video và text các bạn đang học tiếng anh thích luyện kĩ_năng nào thì xài tài_liệu dạng đó nhé <number> jupyter notebook với code mẫu bài_tập về nhà tài_liệu tham_khảo dành cho các ban muốn tìm_hiểu thêm khóa học được thiết_kế dành cho cả các bạn chưa tiếp_xúc với ai bao_giờ <number> vài buổi học đầu sẽ giới_thiệu các kiến_thức cơ_bản link to the course,['#sharing']
python data science handbook bản tiếng anh xin chào mọi người hôm_nay mình xin giới_thiệu tới mọi người cuốn sách python data science handbook của jake vanderplas đã chỉnh_sửa cuốn này không dành cho totally beginner chưa động vào programing language bao_giờ nhưng nếu bạn biết những thứ basis như defining functions assigning variables calling methods of objects thì có_thể đọc được đọc được sau khi đọc xong <number> chương đầu bạn có_thể làm_việc tự_tin với pandas matplotlib chương <number> là về machine learning phần này thì mình đang đọc nó giới_thiệu về sklearn các thuật_toán nhưng thiên về code hơn là về toán_học chắc phải đọc thêm tài_liệu khác để bổ_sung về toán bạn có_thể đọc online cuốn sách này tại đây ngoài_ra cuốn này được được viết toàn_bộ trên jupyter notebook các notebook đó có_thể tìm thấy trong repo này theo như recommend của cuốn sách thì bạn nên clone repo này vừa đọc sách vừa code theo để đạt hiệu_quả tốt nhất với kinh_nghiệm bản_thân của mình cho những bạn beginner thì nên tận_dụng sức_mạnh của các llms như gpt bing để hỗ_trợ việc đọc sách mỗi khi đọc có gì không hiểu ngay lập_tức hỏi gpt để tìm câu trả_lời nếu khó hiểu quá thì thần_chú của mình là explain to me like you are explaining to child about cuốn này còn chương <number> về machine learning mình đang đọc nốt và mong_muốn kiếm được người cùng đọc chung trong group này bản_thân mình thì đang nghiên_cứu và tự học data science từ con_số <number> không có background ngành it được khoảng <number> tháng một_vài dòng giới_thiệu bản_thân để bạn dễ lựa_chọn hợp_tác pandas numpy matplotlib seaborn thành_thạo sử_dụng trong công_việc hàng ngày nắm được các khái_niệm cơ_bản trong machine learning có_thể phân_biệt các loại mô_hình thuật_toán về mặt khái_niệm chưa học kĩ về toán đằng sau các algorithm đó nắm và thực_hiện được tokenizing wordsegmenting vectorizing trong nlp chưa biết train mô_hình đang có định_hướng đi_sâu vào nlp sau_này ngoài_ra một_vài thứ khác mình biết có_thể không liên_quan lắm nhưng vẫn list ra in case ai đó muốn hợp_tác học_hành selenium beautifulsoup langchain pinecone sql excel advanced excel chi_tiết có_thể truy_cập github của mình để xem thêm mình đang muốn tìm_kiếm khoảng <number> đồng_đội ngang level để cùng học_hành nghiên_cứu ml chuyên_sâu mình ưa xài tiếng anh nên nếu bạn nào có tiếng anh tốt một xíu đọc tài_liệu nước_ngoài thoải_mái thì tốt nhé bạn nào có hứng_thú thì comment bên dưới và inbox để trao_đổi thêm nhé dòng cuối nói là tìm đồng_đội ngang level thế thôi nhưng mà nếu có anh_chị nào nhiều kinh_nghiệm sẵn_sàng bỏ thời_gian ra cho em tầm sư thì em cũng welcome lắm nếu oke xin anh_chị để lại một comment bên dưới nhé do đăng vội nên lúc đầu mình ghi là sách này totally beginner đọc cũng được mình đã đọc lại sách và có sửa lại phần nội_dung bên trên,"['#sharing', '#python']"
chào mọi người em viết file markdown bình_thường thì vẫn hiện hỗ_trợ latex nhưng khi publish lên github io thì nó bị như này em xin cách fix với,['#Q&A']
lỗi nhiều người mắc phải khi sử_dụng pytorch với gpu mình xin khẳng_định luôn từ đầu là lỗi này mình cũng mắc phải như các bạn nhìn thấy trong hình bên dưới rất nhiều người khi sử_dụng pytorch có thói_quen là tạo tensor trên cpu trước rồi sau đó mới chuyển sang gpu điều này vừa không tối_ưu về bộ_nhớ phải tiêu tốn cả cpu cả gpu vừa không tối_ưu về mặt tốc_độ tốn thời_gian chuyển_đổi giữa cpu và gpu cách tốt nhất chúng_ta nên làm là khởi tạo trực_tiếp tensor trên gpu điều này vừa giúp tiết_kiệm bộ_nhớ trên cpu vừa làm tăng đáng_kể tốc_độ xử_lý_do không phải chuyển_đổi giữa các thiết_bị và kết_quả là tốc_độ nhanh hơn <number> lần,"['#sharing', '#python']"
chào mọi người em hiện đang là sinh_viên đại_học có ý_định sẽ học cao lên thạc_sĩ theo mọi người thì nên học đại_học xong học thẳng lên thạc_sĩ luôn hay nên đi làm vài năm rồi tiếp_tục học lên em xin cảm_ơn,['#Q&A']
chào mn em là sinh_viên năm <number> chuyên_ngành em đang học là tự_động hóa dự_định của em là sẽ theo hướng sang mảng ds ai mn cho em hỏi nếu tự học thì có khả_quan lắm ko hiện_tại em học được cơ_bản về và python bên cạnh đó thì các kiến_thức về giải_tích đại_số ... em khá vững nếu em tự học thì nên bắt_đầu_từ đâu em rất cảm_ơn với mọi lời khuyên và chia_sẻ từ mn <number>,['#Q&A']
chào mn em newbie dl khi cài module tensorflow_datasets thì em gặp lỗi mn hướng_dẫn em với do em remove environment nên kịp chụp lỗi,"['#Q&A', '#python']"
mn ơi ai đã dùng gg colab pro cho em hỏi là so_sánh với colab free thì nó có đáng đồng xiền bát gạo và mọi người có_thể sg những thứ tương_tự như thế cho sv nghèo em cảm_ơn,['#Q&A']
chào anh chị hiện em đang muốn crawl dữ_liệu về người theo_dõi tên tuổi địa_chỉ <number> trang trên twitter ví_dụ như bitcoin để làm project nhưng đang không biết làm thế_nào có anh chị nào đã từng làm những bài_toán tương_tự như thế có_thể gợi_ý giúp em được không,"['#Q&A', '#data']"
chào mọi người mình hay đọc cmt thấy nhiều anh chị có chia_sẻ nhiều nguồn khóa học share miễn_phí hay quá nên em muốn đăng một post như này để tổng_hợp các nguồn như vậy mọi người có ai biết những nguồn như_vậy thì cùng cmt xuống dưới nhé em cảm_ơn,['#sharing']
chào mọi người và anh việt hiện_tại em tìm_hiểu polynomial regression em chưa biết cách tự implement thay_vì dùng skrlearn em muốn hỏi mọi người <number> vấn_đề cách tự implement polynomial regression tại_sao bậc càng cao thì data của mình càng fit,"['#Q&A', '#machine_learning']"
chào mọi người mình đang làm đồ_án môn deep learning là dự_báo_giá cổ_phiếu trên thị_trường chứng_khoán nhật bản minh dự_định dùng lstm và bi lstm xin hỏi mọi người là có khả_quan không và tài_liệu của hai mô_hình này mình đọc đâu mình xin cảm_ơn,"['#Q&A', '#deep_learning']"
tổng_hợp các công_cụ ai dành cho các mục_đích sử_dụng khác nhau mình xài mỗi canva,['#Q&A']
mn cho em hỏi là hiện_tại em muốn dùng thuật_toán softmax để nhận_diện cảm_xúc của người nhưng tài_liệu lại khá ít và em ko mường_tượng được input lẫn output ai có lời khuyên hay tài_liệu thì cho em xin,"['#Q&A', '#cv']"
mọi người cho hỏi fix lỗi này sao em mới reset máy em có search nhưng mãi sửa được,['#Q&A']
em chào mọi người hiện em đang làm dự_án cv nhỏ dùng thuật_toán_học máy để đánh_giá đẹp xấu chữ_cái tập viết học_sinh lớp <number> em đang có ảnh tập đầu_vào dưới em muốn cắt từng ảnh chữ riêng để đánh_giá hoặc vị_trí chữ trong ảnh nhưng tìm trên mạng các phương_pháp tách chữ viết_tay không có tác_dụng lắm anh_chị có ý_tưởng hoặc code thì cho em tham_khảo với,"['#Q&A', '#cv']"
hêlo group mình thật_sự cần <number> mentor support mảng python phân_tích dữ_liệu cho ngân_hàng rất cám_ơn,['#python']
em chào anh việt và mọi người em là học_sinh lớp <number> đang tìm_hiểu về ds và ml sau khi đọc thử một_số tài_liệu cho beginner mà mọi người chia_sẻ cũng như các post của anh_chị thì em thực_sự thấy ds và ml rất cuốn em cảm_ơn anh việt rất nhiều vì đã tạo ra group này để em tìm được điều mình thích trong khi đang rất mông_lung về việc chọn ngành chọn nghề năm cuối cấp hiện_tại em không còn quá cần lo_lắng về việc thi đh nữa nên em cũng muốn xuất_phát sớm để không bị lạc lối khi bước chân vào đại_học em muốn hỏi mọi người liệu thời_điểm này em có_thể bắt_đầu học những gì và tham_khảo những tài_liệu gì em cũng đang bắt_đầu học toán theo giáo_trình của các thầy bên hust và có dự_định sẽ học thêm python trong thời_gian sắp tới tuy_nhiên nguồn tài_liệu em hiện có khá hạn_chế nên rất mong mọi người có_thể chia_sẻ cho em một_vài nguồn cho beginner về ds và ml bằng tiếng anh cũng được em cảm_ơn mọi người rất nhiều,['#Q&A']
chào mọi người em hiện đang là sinh_viên của <number> trưởng đại_học khá có tiếng trong lĩnh_vực it muốn theo_đuổi về lĩnh_vực ai cụ_thể là computer vision mọi người nghĩ sao về việc học lên trình_độ thạc_sĩ học việt nam thôi liệu có nên không và nó có giúp mình có nhiều cơ_hội việc_làm hơn không xin cảm_ơn,['#Q&A']
slide deep computer vision đến từ mit mình xin chia_sẻ với các bạn slide bài giảng về topic deep computer vision của đại_học kĩ_thuật massachusetts mit vừa được ra_mắt vào tháng <number> năm nay cá_nhân mình thì rất thích tài_liệu này vì nó đúng vào chuyên_môn của mình deep learning for computer vision tài_liệu của mit nhưng cực_kì dễ đọc các bạn nhé vì khá nhiều hình_ảnh mình để_ý có nhiều slide mượn figure từ course dl4cv của stanford link,"['#sharing', '#cv']"
hi mình đang có <number> dự_án liên_quan ai khá thú_vị ae có ai muốn nghiên_cứu chung không điều_kiện hiện chỉ cần <number> bạn đã có kinh_nghiệm làm python web <number> năm dự_án cty share màn_hình làm chung với mình vào mỗi tối <number> giờ hỗ_trợ nếu cần mình có_thể hỗ_trợ tiền điện nước <number> giờ note mình hcm ưu_tiên anh_em hcm nhé cảm_ơn bạn đã quan_tâm tin của mình có gì inb trao_đổi thêm nhé,['#machine_learning']
em chào anh việt và mọi người em xin phép đặt câu hỏi như sau trong ứng_dụng shopee có chức_năng chụp hình thì nó sẽ gợi_ý ra những sản_phẩm tương_tự tuy_nhiên em vẫn chưa hiểu được cách làm_sao mà khi ảnh đưa vào hệ_thống nó có_thể khoanh vùng được các đối_tượng mà mình mong_muốn giả_sử hình chụp <number> khoảng rộng có cả sách ly chuột thì nó sẽ cho mình chọn <number> trong <number> thứ đó và gợi_ý mong được anh và mọi người giải_đáp em xin chân_thành cảm_ơn,['#Q&A']
dataset trong pytorch pytorch là <number> trong các framework về deep learning phổ_biến nhất trên thế_giới đây cũng là favorite framework của mình nhờ sự linh_động và đơn_giản trong cú_pháp cũng như sở_hữu <number> cộng_đồng người sử_dụng đông_đảo khi nói về machine learning hay deep learning người_ta thường nói nhiều về model trong khi quên mất rằng data cũng là <number> thành_phần quan_trọng không kém thậm_chí khi các bạn đi làm thì thời_gian các bạn làm_việc với data còn có_thể nhiều hơn thời_gian làm_việc với model tài_liệu sau tổng_hợp những kiến_thức cơ_bản nhất bạn cần biết khi làm_việc với dataset trong pytorch link to pdf,"['#sharing', '#python']"
em thấy thấy group mình mọi người_làm bên nước_ngoài nhiều nên em xin mạn_phép được hỏi vài câu em hiện đang là sinh_viên it tại bkhn em muốn học lên master machine learning một nước châu âu vừa học vừa làm để trang_trải học_phí và theo như em tìm_hiểu thì ml engineer là một ngành không có entrylevel job entrylevel job duy_nhất là data analyst nên giờ em nên học theo <number> hướng là ml và da cùng lúc với em có tìm_hiểu được rằng đại_học bên đức miễn_phí và có các trường giảng_dạy bằng tiếng anh việc dùng bằng bkhn apply vào master của các trường này cũng như việc mù_tịt tiếng đức có khả_thi không với các trường bển họ có coi_trọng_điểm rèn_luyện với hd ngoại khóa khi apply vào master không hay em nên tập_trung rèn_luyện chuyên_môn với làm project và chú_trọng gpa gpa mức nào thì ổn em xin_lỗi vì em hỏi hơi nhiều em cảm_ơn mn,['#Q&A']
chào mọi người và anh việt thì hiện_tại em đang thử vọc_vạch sử_dụng yolov5 để detect số trong văn_bản chỉ_số thôi nhưng hiện_tại em đang gặp vấn_đề là các kí_tự và chữ_cái cũng bị đánh nhầm theo map50 chỉ khoảng <number> batchsize mình để là <number> epoch <number> mình nghĩ vấn_đề là do data mà mình tự lại nhưng lại không biết cách khắc_phục sao mọi người góp_ý giúp mình với mình xin cảm_ơn link video hướng_dẫn train yolov5 yolov5 training with custom data youtube link data,"['#Q&A', '#cv', '#deep_learning']"
em chào mọi người em đang là sinh_viên cntt và mong_muốn học python từ con_số <number> rất mong mọi người trong group cho em xin đóng_góp về định_hướng trong quá_trình học cũng như nguồn học_tập youtube google em xin cảm_ơn mọi người rất nhiều,"['#sharing', '#python']"
em chào mọi người em là sinh_viên năm nhất ngành công_nghệ thông_tin và định_hướng của em sau_này trở_thành <number> ml engineer em hiện đang bắt_đầu học về ml em nghe mọi người bảo ml và ds có sự liên_quan chặt_chẽ đến nhau nên em cũng muốn tìm_hiểu về ds nhưng không biết nên bắt_đầu_từ đâu và ds cũng có các nhánh con như data analyst hay data buiding không biết nếu theo định_hướng cua em thì nên học bên nào em mong mọi người tư_vấn giúp em với em cảm_ơn mọi người,['#Q&A']
chào mọi người cho em hỏi sao người_ta định_nghĩa hàm theta là công_thức dưới đây,"['#Q&A', '#math']"
khoá học introduction to machine learning của đại_học toronto hi các bạn trường đại_học toronto là trường luôn_luôn nằm vị_trí top <number> canada và top <number> các trưòng đại_học tốt nhất trên thế_giới trên tất_cả các bạn xếp_hạng uy_tín bao_gồm cả <number> bảng xếp_hạng danh_tiếng nhất thế_giới là qs times higher education và shanghai ranking và tất nhiêu cao hơn rất nhiều ngôi trường mà mình vẫn hay flex đây cũng là <number> trong số_ít các trường đại_học danh_tiếng chia_sẻ công_khai tài_liệu các khoá học về ai machine learning trong post này mình xin chia_sẻ với các bạn khoá học introduction to machine learning của họ <number> điều mình rất thích từ_khoá học này đó là cách bố_trí các buổi lecture và tutorial xen_kẽ trong buổi lecture các bạn sẽ học về lý_thuyết còn trong buổi tutorial các bạn sẽ được trang_bị và củng_cố các kiến_thức nền cần_thiết như là các kiến_thức toán hay thậm_chí là làm_quen với pytorch đây là <number> điểm cộng so với trường mình khi tất_cả mọi thứ mix hết vào với nhau slide của các buổi này cũng như là bài_tập tất_nhiên là cũng được chia_sẻ công_khai các bạn nhé link to the course,"['#sharing', '#machine_learning']"
hi mn hong biết là trong nhóm mình có ai từng dùng qua chatgpt plus không có_thể cho em xin review với chatgpt plus có kiểu charge <number> tháng thôi rồi huỷ rồi charge lại khi cần không mn ơi em cảm_ơn mn nhiều,['#Q&A']
em chào anh việt chào mọi người em là sinh_viên vừa tốt_nghiệp ra trường chuyên_ngành ai em đang có nhu_cầu tìm_kiếm việc_làm về mảng ai ai engineer hoặc data science hcm fresher hay intern có lương đều ổn giới_thiệu qua về em em tốt_nghiệp loại xuất_sắc đại_học fpt gpa <number> em có kinh_nghiệm <number> tháng làm_việc fpt software vị_trí ai engineer và là tác_giả một bài báo được public tại hội_nghị quốc_tế những kỹ_năng em có bao_gồm python pytorch tensorflow sql cơ_bản git docker em nắm vững các kiến_thức nền_tảng về machine learning deep learning các kiến_thức về toán xác xuất thống_kê toán rời_rạc công_ty hay anh_chị hr nào cảm_thấy em phù_hợp có_thể comment hoặc chấm bài viết em sẽ ib gửi cv em cảm_ơn mọi người,['#Q&A']
probabilistic machine learning phiên_bản mới hi các bạn đây là <number> trong các đầu_sách được sử_dụng làm tài_liệu tham_khảo nhiều nhất trong các khóa học về machine learning của rất nhiều trường đại_học trên toàn thế_giới sách được phát_hành bởi mit press nhà xuất_bản của trường đại_học số <number> thế_giới về cntt hồi <number> khi mình bắt_đầu chương_trình học tại tu munich ngay kì đầu_tiên mình học môn machine learning và đây là <number> trong <number> tài_liệu tham_khảo mà giáo_sư yêu_cầu mọi người đọc quyển ngoài cùng bên trái xuất_bản năm <number> đây là <number> quyển sách rất hay nhưng đồng_thời cũng cực_kì khó đọc vì khá hàn_lâm năm_ngoái thì quyển sách nổi_tiếng này đã được tái_bản và được tách ra thành <number> tập <number> tập cơ_bản và <number> tập nâng cao có_lẽ là để người đọc đỡ tẩu_hỏa_nhập ma quyển sách này sẽ rất phù_hợp cho những bạn nào muốn tìm_hiểu về bản_chất của các thuật_toán trong machine learning tác_giả đi vào từng khái_niệm cực_kì chi_tiết tuy_nhiên như mình nói quyển này khá khó đọc mình không nói về việc tiếng anh tiếng việt đây nhé nhưng nếu các bạn có_thể đọc được <number> quyển sách phiên_bản mới này thì thực_sự là rất tuyệt_vời link to book <number> link to book <number>,"['#sharing', '#machine_learning']"
em hiện_tại muốn học ai để làm_việc anh_chị nào đang làm lĩnh_vực ai có kinh_nghiệm có kèm không hoặc có ai có_thể recommend giúp em trung_tâm nào đào_tạo ai cho người đã di làm rồi không many thanks,['#Q&A']
hello cả nhà mình hổng phải dân tech nhưng đang làm vài datavisual tasks trong code và ramchart nhà mình có ai biết đến phần này cho mh tham_khảo cách mixed charts cụ_thể là bar line với nhé nhân_tiện mình rất cám_ơn adm đã tạo <number> cộng_đồng vô_cùng chất_lượng và văn_minh đb là adm có tâm và dễ_thương qtqd chắc_chắn đây là nơi mình học_hỏi được rất nhiều khi dần chuyển qua mảng tech,['#Q&A']
chào anh việt và mọi người hiện em đang là sv năm <number> ngành data science và em đang có dự_định học tiếp thạc_sĩ ngành ds ai đại_học kĩ_thuật munich bởi_vì đại_học munich được xếp_hàng khá cao nên em không biết đầu_vào khó như thế_nào nếu có ai đã từng đi giống em có_thể tư_vấn giúp em cần chuẩn_bị hồ_sơ nào được không hiện_giờ em đã có được ielts <number> và testas xin cảm_ơn mọi người thật_sự em rất vui vì anh việt đã tạo ra <number> group về ml xịn xò và văn_minh cho người việt mỗi ngày đều có điều bổ_ích để xem,['#Q&A']
xin chào mọi người cá_nhân em thấy là những câu này khá đông các bạn cmt nhưng vẫn chưa được giải_đáp và còn nhiều băn_khoăn và mong có_thể nhận được câu trả_lời từ những người tiền_bối đi trước để được học_hỏi và rút kinh_nghiệm <number> em thấy trên nhóm mặc_dù có nhiều bạn có cv khá sáng và đẹp nhưng vẫn khó xin việc liệu có phải là nhu_cầu việt nam còn yếu đúng không <number> nhu_cầu việc_làm thì giữa các miền có nhiều khác_biệt không bởi_vì truyền_miệng về vấn_đề miền nam có nhiều cơ_hội cho những bạn intern hoặc kinh_nghiệm yếu hơn em cũng thấy khá nhiều <number> vậy nếu các bạn theo_đuổi mảng này từ đầu mà vẫn khó_khăn trong xin việc vậy thì các bạn tay_ngang liệu có cơ_hội để mạo_hiểm không hay vẫn nên làm những job về web dev hay tương_tự trước để lấy kinh_nghiệm bẻ dần sang <number> vậy nếu_như mà ngôn_ngữ là cần_thiết để có cơ_hội thì nên học ngôn_ngữ nào ngoài tiếng anh và tối_thiểu là nên đạt được mức nào em xin làm_phiền và cảm_ơn mọi người,['#Q&A']
em chào mọi người em đang tìm_hiểu về mô_hình yolox và em có đọc các bài báo các tài_liệu liên_quan để tìm_hiểu về những ưu_điểm nhược_điểm sự tiến_bộ source code ... nhưng em thấy thông_tin về mô_hình này khá ít trên paperswithcode thì em chỉ tìm được <number> bài liên_quan mọi người có_thể cho em xin thêm thông_tin hay paper về mô_hình này được không em cám_ơn,"['#Q&A', '#deep_learning']"
em đang làm bài_tập về senmatic similarity detection dataset của em là similarity string <number> string <number> với similarity là <number> và <number> câu hỏi của em là em muốn hỏi rank1 rank5 rank10 map recall là gì các tham_số này thường được dùng khi so_sánh với các model khác trong nhiều dataset paper research làm_sao để em tính được các chỉ_số trên trong bài_toán của em em cũng đã thử research với bài viết nhưng em vẫn chưa hiểu nếu được giải_thích bằng các ví_dụ thực_tế thì tuyệt_vời em cũng có một vấn_đề nữa em không hiểu được biểu_đồ về precision accuracy và recall em đã có research định_nghĩa về chúng qua bài viết nhưng nếu mọi người có các graph ví_dụ về precision accuracy và recall thì tuyệt_vời em cũng có tham_khảo graph về chúng qua link youtube nhưng em không hiểu trục_hoành của họ là gì trong graph về precision recall và cách họ hợp nó thành graph map average precision,"['#Q&A', '#machine_learning']"
chào mọi người em mới vào nhóm em mới mua con rtx <number> em đang thực_hiện phát_hiện đối_tượng bằng yolov8 nhưng mà khi chạy trên local thì hiệu_suất ăn vào gpu chỉ đc có <number> và tốc_độ nhận_diện realtime không được cao mọi người có_thể gợi_ý keyword hay bài biết cụ_thể hướng_dẫn cài_đặt cuda gpu như thế_nào để có_thể tăng được hiệu_suất không em cảm_ơn mn,"['#Q&A', '#deep_learning']"
em chào mọi người em viết bài này cũng tính hỏi anh việt và những ai có kinh_nghiệm về du_học tại đức em đang là sinh_viên năm <number> có mong_muốn được du_học tại đức với chuyên_ngành toán nhưng kinh_nghiệm rồi chuẩn_bị ra sao em còn chưa biết phải như thế_nào câu hỏi có hơi ngoài_lề của nhóm và có_thể sai_sót trong ngôn_từ mong mọi người bỏ_qua mong được mọi người hỗ_trợ em cám_ơn cám_ơn anh việt đã duyệt bài,['#Q&A']
tiếp_theo bài viết về các nguồn học data mình xin có <number> vài chia_sẻ tổng_quát về phương_pháp học_tập cho các công_việc về data tới các anh chị em bạn_bè trong nhóm cũng giống như việc học_tập trong nhiều môn_học hay lĩnh_vực khác việc học có những nguyên_tắc cơ_bản sau đây mà nếu không tuân_thủ thì với một người bình_thường sẽ rất khó có_thể đạt được kết_quả tốt nguyên_tắc quan_trọng nhất hiểu rõ lí_do và động_lực học_tập của bản_thân nếu đã qua giai_đoạn cha_mẹ thày cô bảo học gì thì học nấy thì thường ta chỉ học_tập được thực_sự tốt nếu_như có một động_lực học_tập đủ lớn khi ta hiểu vì_sao ta cần học một thứ gì đó và việc học_tập nó sẽ giúp ta như thế_nào thì ta sẽ rất muốn học và khi đó tự_khắc sẽ tìm được ra cách để học_tập tốt việc này tuy quan_trọng nhưng lại rất khó và không phải ai cũng làm được ngay từ đầu vừa học vừa tìm_kiếm động_lực học_tập là chuyện bình_thường ngoài_ra năng_lực tư_duy và trải nghiệm của cá_nhân bạn cũng sẽ được xây_dựng và hình_thành theo thời_gian nên lí_do động_lực của bạn cũng sẽ thay_đổi và điều đó cũng là bình_thường tuy_nhiên ta phải luôn ghi_nhớ nguyên_tắc này và thường_xuyên suy_nghĩ và ghi_nhớ về lí_do và động_lực học_tập của bản_thân mình lời khuyên bạn nên thường_xuyên tự_vấn self reflection và tích_cực học_hỏi từ những người có nhiều kinh_nghiệm sống và làm_việc ngoài_ra bạn có_thể tham_khảo cả các dịch_vụ của những tổ_chức chuyên_gia khai vấn để có thêm trợ_giúp trong việc tìm_hiểu về bản_thân mình nguyên_tắc <number> đặt mục_tiêu và lên kế_hoạch học_tập cũng giống như bất_kỳ_công_việc gì để đạt được kết_quả tốt nhất với nguồn_lực và thời_gian hữu_hạn thì ta cần đặt mục_tiêu rõ_ràng và đi kèm với đó là một kế_hoạch học_tập làm_việc có khoa_học mục_tiêu và kế_hoạch có_thể thay_đổi sau một thời_gian khi ta hiểu rõ hơn về chủ_đề đang học cũng như hiểu rõ hơn về chính bản_thân mình ưu nhược_điểm trong việc học hình_thức học phù_hợp điều này là hết_sức bình_thường mục_tiêu rõ_ràng chứng_tỏ ta đã tìm_hiểu đủ kĩ và biết mình cần học gì kế_hoạch khoa_học và phù_hợp giúp ta có các đầu việc và mốc thời_gian cụ_thể để dễ_dàng thực_hiện theo nhằm đạt được mục_tiêu đã đề ra lời khuyên luôn đặt mục_tiêu học_tập lên kế_hoạch học_tập và cố_gắng tuân_thủ theo kế_hoạch đã đề ra thay_đổi mục_tiêu kế_hoạch khi cần_thiết bạn hãy tham_khảo nguyên_tắc smart trong đặt mục_tiêu và tìm_hiểu về các công_cụ và kĩ_thuật liên_quan tới lập kế_hoạch và quản_lý công_việc bạn cũng_nên tìm_hiểu tổng_quan về ngành data và các cơ_hội nghề_nghiệp trong ngành thiếu kiến_thức này thì rất khó để xác_định mục_tiêu cho bản_thân nguyên_tắc <number> chọn nguồn học tốt và có ít_nhất từ <number> nguồn học trở lên cho_cùng một vấn_đề đang cần tìm_hiểu việc lựa_chọn nguồn học tốt sách chuẩn thày cô có trình_độ giúp đảm_bảo kiến_thức nạp vào có độ chính_xác cao và được diễn_giải một_cách dễ hiểu việc có nhiều nguồn học cho_cùng <number> vấn_đề giúp ta hiểu vấn_đề nhanh hơn đặc_biệt là với các vấn_đề trừu_tượng hay phức_tạp do được tiếp_xúc với nhiều cách giải_thích nhiều hình_thức học khác nhau đọc chữ xem hình_ảnh hoặc video minh_hoạ bên cạnh đó ta có_thể so_sánh đối_chiếu các nguồn học với nhau để đảm_bảo kiến_thức được nạp vào là chính_xác đặc_biệt là với các chủ_đề mà nguồn học đề_cập đến không đủ kĩ lời khuyên với mỗi vấn_đề chủ điểm kiến_thức lớn cần tìm_hiểu nên có <number> nguồn học chính và ít_nhất <number> nguồn học nữa để bổ_sung thêm nguyên_tắc <number> kỉ_luật một_cách có khoa_học dù động_lực học_tập lớn đến đâu thì nhiều khi ta cũng khó có_thể duy_trì việc học_tập liên_tục với năng_suất cao trong một thời_gian dài do bản_chất con_người là lười_biếng và do việc hưởng_thụ ăn_uống vui_chơi du_lịch nói_chung đem lại sự sung_sướng nhất_thời rất mạnh và có sức cám_dỗ cao hơn so với việc học vì_vậy để học_tập tốt và duy_trì được trong một thời_gian dài thì duy_trì kỉ_luật với bản_thân là vô_cùng quan_trọng kỉ_luật nên được hiểu là những quy_tắc quy_định mà ta bắt_buộc phải tuân theo tuy_nhiên chúng phải được đặt ra một_cách có khoa_học và phù_hợp với bản_thân và bối_cảnh cuộc_sống của mỗi người ví_dụ về kỉ_luật thiếu tính khoa_học một sinh_viên đại_học đặt ra quy_tắc là mỗi ngày đều dậy sớm từ 4h sáng và dành ít_nhất <number> tiếng để học machine learning từ 4h 7h do nghe nói rằng người thành_công là người dậy sớm và quyết_tâm áp_dụng triệt_để nguyên_tắc đó trong <number> ngày liên_tiếp và rồi ngủ nướng trong <number> ngày tiếp_theo và cuối_cùng là không chịu được và phải từ_bỏ nguyên_tắc đã đề ra nguyên_tắc này không áp_dụng được do bạn sinh_viên đã không để_ý đến nhịp sinh_học của mình đang quen thức khuya đến 12h để chat với người_yêu và thực_hiện chuyển_đổi quá gấp không để_ý đến việc khả_năng tập_trung của bản_thân cao nhất vào thời_điểm nào sáng sớm hay tối muộn và trong không_gian điều_kiện nào sáng dậy sớm nhưng uể_oải học trên giường không hiệu_quả bằng chiều ra cafe tự học hoặc học online cùng <number> vài người bạn để có người hỏi khi có chỗ không hiểu ví_dụ về kỉ_luật có tính khoa_học là một data analyst ngày đi làm <number> tiếng tại văn_phòng tối về cơ_thể mệt_mỏi thường_xuyên nằm trên giường lướt tiktok để giải_trí và sau đó là ngủ thiếp đi rất muốn dành thêm thời_gian đọc cuốn storytelling with data của cole nussbaumer knaflic và đã mua nó rồi nhưng không tìm đâu ra thời_gian cuối_cùng cuốn sách cứ nằm mãi trên giá suy_nghĩ kĩ và tìm ra giải_pháp đó là mua một chiếc kindle cũ giá hơn <number> triệu vnd và <number> tối mỗi tuần thay_vì lướt tiktok thì nằm trên giường và đọc sách trên kindle cho_dù một_số biểu_đồ hình_ảnh trong sách khi hiển_thị trên kindle không được tốt bằng máy_tính phương_pháp này vẫn giúp tránh được sự trì_hoãn và hoàn_tất cuốn sách trong vòng <number> tháng với chi_phí đầu_vào bỏ ra chỉ có <number> triệu vnd nhưng tiết_kiệm được rất nhiều chi_phí cơ_hội khác tuy_nhiên cũng hiểu rằng việc tối đi làm về mình quá mệt_mỏi không muốn ra khỏi giường cũng có_thể là dấu_hiệu của sức_khoẻ tổng_quát của bản_thân không tốt và lên kế_hoạch để bắt_đầu rèn_luyện thể_dục thể_thao lời khuyên hãy dành thêm thời_gian để tìm_hiểu về bản_thân mình ưu nhược_điểm tính_cách nhịp sinh_học và tìm_hiểu về các phương_pháp giúp tăng mức_độ tập_trung nâng cao năng_suất trong việc học nên học giờ nào bằng phương_tiện gì phương_pháp đọc nhanh cách ghi_chép và tổ_chức notes cách để giảm bớt sự trì_hoãn làm_sao để ngủ ít hơn mà vẫn tỉnh_táo mỗi người sẽ có bộ phương_pháp và các thủ_thuật của riêng mình không có một hay một bộ giải_pháp nào phù_hợp cho tất_cả mọi người cả nguyên_tắc <number> ghi_chép tổng_hợp và khái_quát_hoá kiến_thức việc chi chép kiến_thức take note giúp kích_hoạt não bộ của ta và giúp ta ghi_nhớ kiến_thức tốt hơn việc tổng_hợp kiến_thức và viết lại bằng_chính ngôn_từ của mình giúp ta thực_sự hiểu được kiến_thức do người khác giảng_dạy và biến nó thành của bản_thân mình việc khái_quát_hoá kiến_thức giúp ta hiểu sâu về bản_chất của kiến_thức hơn từ đó có_thể đem đi áp_dụng trong nhiều tình_huống lĩnh_vực khác nhau lời khuyên hãy tìm_hiểu và thử_nghiệm các phương_pháp ghi_chép vd các phương_pháp tổ_chức lưu_trữ và tổng_hợp kiến_thức vd sử_dụng mindmap sử_dụng notion so và luôn tìm cách hiểu và ghi_nhớ bản_chất của bất_cứ vấn_đề nào bạn học thay_vì cố_gắng nhớ hết tất_cả các chi_tiết nguyên_tắc <number> học phải đi_đôi với hành tuy đây là một nguyên_tắc xưa như trái_đất nhưng nó chưa bao_giờ sai lý_thuyết mà không đi kèm với thực_hành thì không_thể được chuyển_hoá thành kĩ_năng và cũng khó mà ghi_nhớ lâu được ngoài_ra thực_tiễn là thước_đo tốt nhất cho lý_thuyết để kiếm chứng xem ta nắm lý_thuyết có vững không hay thậm_chí là lý_thuyết kiến_thức ta học được kể_cả từ các nguồn uy_tín có thực_sự chính_xác hay không lời khuyên nếu có_thể hãy lựa_chọn những nguồn học có bài_tập thực_hành đi kèm một trong những cách thực_hành tốt đó là tự đặt ra các project để thực_hiện tốt nhất nên tham_khảo các project về data trên mạng để làm theo hoặc để lấy ý_tưởng với tính thực_tiễn cao rồi tra_cứu và học thêm kiến_thức trong quá_trình làm project cách thực_hành này tốt do nó mô_phỏng việc học trong thực_tế công_việc learning ơn job và nếu có người hướng_dẫn hoặc có bài mẫu bài hướng_dẫn thì việc học sẽ càng hiệu_quả hơn ngoài những nguyên_tắc nêu trên trong quá_trình học_tập để phục_vụ cho các công_việc về data những người mới bắt_đầu nên lưu_ý tránh một_số sai_lầm sau sai_lầm <number> cho rằng chỉ cần có stackoverflow và chatgpt là có_thể code thoải_mái không cần học coding quá kĩ làm gì với người mới sách các khoá học chất_lượng learning on job thường_xuyên làm các project cá_nhân và ghi_chú tổng_hợp kiến_thức sẽ giúp các bạn nắm vững kiến_thức căn_bản mà vẫn học được một tốc_độ đủ nhanh dựa quá nhiều vào stackoverflow hay chatgpt sẽ khiến bạn lười đọc những tài_liệu chính_thống lười đọc lỗi và debug và không thuộc các syntax căn_bản những điều này sẽ làm giảm sense về coding của bạn cũng như khiến bạn không tìm_hiểu về các good practice trong lập_trình khiến bạn khó phát_triển về sau sai_lầm <number> cho rằng kĩ_năng phân_tích sự nhạy_cảm với số_liệu mới là quan_trọng còn technical skills như sql python chỉ thuần_tuý là các công_cụ hỗ_trợ sai_lầm này thường đến từ những người đã đang sẽ làm data analyst hay các vị_trí phân_tích dữ_liệu tương_tự hãy coi các ngôn_ngữ lập_trình và truy vấn dữ_liệu các công_cụ xử_lý dữ_liệu là những công_cụ căn_bản giúp bạn tiếp_xúc và làm_việc với dữ_liệu nếu không sử_dụng thành_thạo chúng thì tốc_độ truy vấn và xử_lý dữ_liệu của bạn sẽ chậm và bạn sẽ mất quá nhiều thời_gian và trí_lực vào việc tìm cách sử_dụng công_cụ dẫn tới không còn đủ nguồn_lực dành cho tư_duy phân_tích ngoài_ra hầu_hết người mới bắt_đầu đều không_thể ngay lập_tức có nhạy_cảm dữ_liệu tốt được mà phải trải qua quá_trình làm_việc với dữ_liệu và mắc nhiều sai_lầm mới có_thể_hình_thành sự nhạy_cảm đó được chính vì_vậy coi_thường các công_cụ hỗ_trợ sẽ khiến bạn đánh mất cơ_hội phát_triển sự nhạy_cảm với số_liệu của bản_thân mà sẽ chỉ hiểu các con_số mức_độ hời_hợt mà thôi ngay cả với những người_làm business để có được nhạy_cảm về các con_số chỉ_tiêu kinh_doanh vận_hành của doanh_nghiệp thì họ cũng phải trải qua những thời_gian dài làm_việc với dữ_liệu và rất nhiều lần phải tự mình chuẩn_bị phân_tích xào_nấu dữ_liệu sai_lầm <number> tập_trung quá nhiều vào học các kĩ_năng technical sai_lầm này thường đến từ những người đã đang sẽ làm data engineer hay các vị_trí đòi_hỏi hàm_lượng kỹ_thuật lớn khác khi mới bắt_đầu nếu không có kĩ_năng technical tốt thì bạn sẽ không có việc và nếu có việc thì cũng khó đáp_ứng được yêu_cầu của công_việc tuy_nhiên trong thực_tế công_việc data engineer hay các vị_trí nhiều technical khác thì những việc khó nhất lại thường là hiểu các yêu_cầu nghiệp_vụ của các đơn_vị kinh_doanh vận_hành trong và ngoài tổ_chức để từ đó đua ra được giải_pháp kỹ_thuật tối_ưu không như các vấn_đề kỹ_thuật các vấn_đề về nghiệp_vụ của doanh_nghiệp thường ít khi được ghi_chép lại trong sách hay các tài_liệu chính_thống mà ta dễ_dàng tìm thấy trên mạng hay thậm_chí là trong các trường đại_học vì_vậy để một người_làm tốt được một công_việc data nặng về kĩ_thuật thực_ra người đó phải có bộ kĩ_năng giao_tiếp làm_việc nhóm tốt và khả_năng nắm_bắt được các kiến_thức và quy_trình nghiệp_vụ nhanh_chóng bên cạnh nền_tảng kỹ_thuật tốt sai_lầm <number> thiếu đầu_tư vào kĩ_năng truyền_đạt thông_tin kĩ_năng thuyết_trình sai_lầm này có_thể đến từ bất_cứ ai nhưng đây ta sẽ ví_dụ đối_với một người đã đang sẽ làm data scientist hoặc những vị_trí làm_việc nhiều và sâu về các thuật_toán machine learning ml một sai_lầm thường gặp phải đối_với những người mới bắt_đầu vị_trí này là việc tập_trung quá nhiều vào học và hiểu các thuật_toán và các khía_cạnh về toán có liên_quan mà không_lưu_ý rèn kĩ_năng truyền_đạt thông_tin cả dưới dạng viết lẫn dạng nói điều này khiến cho data scientist khó giao_tiếp với những người không có kiến_thức và kinh_nghiệm về ml dù người đó làm vị_trí về data hay thuộc phía business đơn_vị kinh_doanh vì data scientist không biết diễn_đạt các kiến_thức ml toán bằng ngôn_ngữ đời_thường dễ hiểu đúng trọng_tâm để các đồng_nghiệp khác có_thể hiểu được ngoài_ra việc diễn_đạt kém thiếu gãy_gọn xúc tích trong một_số trường_hợp cũng thể_hiện data scientist chưa thực nắm rõ chuyên_môn của mình vì_vậy không diễn_đạt chính_xác và tường mình được các vấn_đề trừu_tượng phức_tạp khi bạn có_thể giải_thích một mảng kiến_thức nào đó về ml cho một người chưa biết gì về ml hiểu được và giúp họ trò_chuyện với bạn một_cách thoải_mái được thì khi đó bạn có_thể tự_tin rằng mình đã làm_chủ được kiến_thức mình có nhận sửa cv miễn_phí cho người mới bắt_đầu và người còn ít kinh_nghiệm trong các công_việc về data mời các anh chị em bạn_bè ghé chơi để đăng_ký sửa cv miễn_phí và cả học data miễn_phí cũng như đón đọc các bài viết tiếp_theo chia_sẻ về kinh_nghiệm thủ_thuật về việc học việc_làm nhé,['#sharing']
roadmap cho các bạn theo_đuổi mảng data science machine learning các bạn ơi hồi trước mình đã từng làm <number> video về roadmap for data scientist nhưng xem video thì mất time quá mình xin tóm_tắt lại đây đây là lộ_trình bản_thân mình đã áp_dụng và mình không có copy từ đâu cả nên các bạn có_thể tham_khảo có <number> điểm chú_ý các bước các bạn có_thể tìm tài_liệu mà các bạn thấy phù_hợp_nhất với mình trong video mình có chia_sẻ nguồn học cho từng bước nhưng nghĩ_lại thì thấy mỗi người <number> background rồi khả_năng ngoại_ngữ cũng khác nhau nữa nên chưa chắc tài_liệu mình thấy hay đã phù_hợp với các bạn bước <number> ôn lại kiến_thức toán <number> mảng sau xác_suất thống_kê <number> mảng này cần cho data science đại_số tuyến_tính giải_tích <number> mảng này cần cho ml dl bước này khó và khô_khan nhưng đừng bỏ_qua các bạn nhé không là sau_này chúng_ta xây nhà từ nóc đó bước <number> các bạn nên học lập_trình python cơ_bản để đến lúc học về ds ml các bạn có_thể practice được lúc đầu học thì đừng lạm_dụng thư_viện hay framework nhé sau khi quen với python rồi thì các bạn hãy tìm_hiểu và làm_quen với các thư_viện và framework quan_trọng như là numpy pandas matplotlib ... bước <number> bước này các bạn có_thể học data science và machine learning song_song bước này để practice các bạn sẽ sử_dụng thư_viện scikitlearn các bạn nhé important thing các bạn không nhất thết phải tự xây_dựng được các mdoel from scratch nhưng chí_ít các bạn cũng phải biết là mỗi <number> hàm các bạn gọi có cái gì xảy ra bên trong task được thực_hiện như thế_nào cách để biết các bạn đã học đạt tiêu_chuẩn chưa sau khi hoàn_thành <number> project hoàn_chỉnh các bạn có_thể chỉ tay ngẫu_nhiên vào <number> dòng code bất_kì nếu các bạn giải_thích được dòng này làm gì nếu không có nó nếu dùng hàm khác thì chuyện gì xảy ra vậy là đạt yêu_cầu <number> điều quan_trọng nữa là hãy tập sửa lỗi vá_lỗi nếu trong quá_trình code có phát_sinh trục_trặc gì các bạn có_thể google hay hỏi chatgpt tuyệt_đối không hỏi hay nhờ người khác sửa hộ trừ khi các bạn đã nỗ_lực hết_sức rồi mà vẫn không fix được sau_này đi làm thậm_chí các bạn còn phải sửa code của đồng_nghiệp hay người khác đó sửa code của bản_thân vẫn còn là quá đơn_giản bước này là bước nền_tảng các bạn đừng đốt cháy giai_đoạn nhé đừng đặt mục_tiêu là sau <number> hay <number> tháng phải xong bản_thân mình tổng_thời_gian dành cho học_phần này là tầm <number> năm bước <number> giờ đến phần hot của ai deep learning giờ deep learing là trend rồi nên các vị_trí các bạn apply kiểu gì người_ta cũng yêu_cầu kiến_thức về deep learning và thực_sự thì deep learing cũng rất là thú_vị các bạn sau khi nắm chắc kiến_thức về machine learning rồi thì có_thể học tiếp lên deep learning trong dl có <number> mảng ứng_dụng lớn là computer vision thị_giác máy_tính và nlp xử_lý ngôn_ngữ tự_nhiên các bạn khi bắt_đầu học về dl sẽ lần_lượt được làm_quen với các bài_toán cơ_bản của cả <number> mảng này image document classification problems sau đó các bạn có_thể chọn <number> hướng và đi_sâu vào học <number> hướng đồng_thời sẽ rất là khó_khăn và tốn time nên các bạn cân_nhắc nhé các bạn lúc bắt_đầu cứ nắm chắc các bài_toán cơ_bản đừng có nhảy sớm vào mấy model cao_siêu kiểu bert rnn lstm ocr gan những mô_hình này sau_này chúng_ta chủ_yếu xài project có sẵn thôi nhảy vào chúng sớm không có tác_dụng nhiều trong tích_luỹ kiến_thức note có <number> điều vô_cùng quan_trọng mình đúc_kết được trong quá_trình học và làm về ai data science machine learning hãy chỉ dùng đến ml dl nếu các phương_pháp tính_toán thông thuờng không_thể áp_dụng được tính tiền phải trả dựa trên lượng điện tiêu_thụ if elif else là đủ rồi không cần phải vác ml vào đừng đem dao_mổ trâu đi giết gà nhé ai nghĩa_là trí_tuệ nhân_tạo chứ không phải trí_tuệ siêu_phàm hay trí_tuệ siêu_nhiên có_nghĩa_là ai giúp máy_móc có_thể giải_quyết được những công_việc con_người có_thể làm đuợc với độ chính_xác cao hơn đáng tin_cậy hơn điều đấy không có_nghĩa_là ai có_thể làm được mọi thứ mình rất hay nhận được <number> loại câu hỏi <number> là ai có_thể làm được việc abcxyz hay không câu trả_lời rất đơn_giản con_người_làm được dù không tốt thì ai sẽ làm được loại câu hỏi thứ <number> là để xây_dựng được <number> mô_hình abcxyz thì phải làm gì các bạn có_thể thử tự hỏi bản_thân xem nếu giờ huấn_luyện con_người làm task đó thì cần phải chuẩn_bị những tài_liệu gì để huấn_luyện cho người đó thì model ai cũng cần dữ_liệu tương_tự roadmap trên ít_nhất đã có <number> chuột_bạch đi trước là mình và em_trai mình nên các bạn không lo bị lôi ra làm vật_thí_nghiệm nha hi_vọng những chia_sẻ của mình có_ích cho các bạn try your best god will do the_rest,['#sharing']
data exploration trong python với <number> thư_viện numpy pandas và matplotlib đây là <number> cheatsheet khá thú_vị được soạn theo phong_cách <number> trang_dài chiều ngang thì bình_thường nhưng chiều dài bằng <number> trang thông_thường trong cheatsheet này chúng_ta sẽ được tổng_hợp các kiến_thức về data exploration cần_thiết cho các data scientist bao_gồm <number> chủ_đề sau làm_sao để đọc dữ_liệu làm_sao để biến_đổi dữ_liệu sang các kiểu khác nhau làm_sao để hoán_đổi dữ_liệu làm_sao để sắp_xếp dữ_liệu làm_sao để trực_quan_hóa dữ_liệu với các plots khác nhau làm_sao để tạo bảng tần_suất làm_sao để lấy mẫu dữ_liệu làm_sao để xóa dữ_liệu trùng_lặp làm_sao để nhóm gộp dữ_liệu làm_sao để xử_lý missing values và outliers làm_sao để gộp dữ_liệu <number> cách hiệu_quả link pdf,"['#sharing', '#python', '#data']"
em đang nguyên cứu về thanh_toán online sử_dụng faceid giống facepay gs25 thì nhận_diện khuôn_mặt dựa trên phần_cứng của camera hay_là cam chỉ truyền_hình_ảnh về để server xử_lí và nhận kết_quả mọi người mọi người cho em hướng đi với em mới tập_tành tìm_hiểu cám_ơn mọi người nhiều,"['#Q&A', '#cv']"
chào mọi người theo em hiểu thì tham_số average weight trong các hàm tính f1 score precision hay recall là nó sẽ tính độ chính_xác trên từng_lớp rồi trung_bình_cộng lại vậy nó có ổn khi sử_dụng để đánh_giá mô_hình nhận_diện gian_lận thẻ tín_dụng vì theo em nghĩ việc nhận_diện <number> giao_dịch gian_lận là quan_trọng hơn ml,"['#Q&A', '#machine_learning']"
faker tạo dữ_liệu fake <number> cách nhanh_chóng và đơn_giản trong quá_trình lập_trình đôi_khi chúng_ta muốn tạo ra <number> sample data chỉ nhằm mục_đích test nhanh <number> hàm hay <number> chức_năng nào đó faker sẽ giúp điều này trở_nên đơn_giản hơn bao_giờ hết các bạn có_thể fake bất_kì thứ gì số chuỗi địa_chỉ tên ngày_tháng tóm lại là anything link,"['#sharing', '#data']"
cho em xin cách fix với em cảm_ơn,"['#Q&A', '#python']"
em xin chia_sẻ với mọi người project machine learning đầu_tiên của mình project xây_dựng model hồi quy để tính gdp của việt nam dựa trên các chỉ_số mà em nghĩ sẽ ảnh_hưởng đến nó dữ_liệu lấy từ website tổng_cục thống_kê việt_nam dữ_liệu tải từ web trong folder web_data dữ_liệu đã xuất thành file csv trong folder train_model_data em build và so_sánh performance của <number> mô_hình hồi quy là svr ridge và linear regression đã bỏ_qua tổng_thiệt_hại thiên_tai từ input dataset vì correlation với gdp khá thấp dùng rmse và rmspe để đánh_giá model kết_quả cho thấy model linear regression cho kết_quả tốt nhất khi có cả thiệt_hại thiên_tai thì nó vẫn tốt nhất do vậy em thử bỏ thiên_tai ra thì model tiếp_tục giảm sai_số hơn trước trên đây là tóm_tắt của em về project vừa làm em xin góp_ý đề_xuất cải_thiện từ mọi người em xin cảm_ơn,"['#sharing', '#machine_learning']"
mọi người ơi cho em hỏi về ml có tập dữ_liệu về lung cancer có các thuộc_tính gender age smoking yellow_fingers anxiety peer_pressure chronic disease fatigue allergy wheezing alcohol consuming coughing shortness of breath swallowing difficulty chest pain lung_cancer em muốn dùng bài_toán phân lớp để huấn_luyện mô_hình cho hỏi là có nên bỏ thuộc_tính nào không quan_trọng mới học nên mong mọi người chỉ cảm_ơn,"['#Q&A', '#data']"
hơn <number> dataset dành cho machine learning uci machine learning repository là tập_hợp của hơn <number> dataset mà các bạn có_thể dùng để xây_dựng các machine learning project cá_nhân mình thì thấy có <number> vài bộ dataset mà dữ_liệu nhìn hơi bị pha ke nhưng dù_sao đây cũng là <number> trong các nguồn dataset nổi_tiếng nhất các bạn có_thể tham_khảo và chọn ra những bộ dataset ưng_ý dành cho riêng mình link,"['#sharing', '#data', '#machine_learning']"
chào mọi người em là ai engineer đang muốn học thêm về mảng data business để củng_cố kiến_thức cho việc startup sau_này các anh_chị có recommend những kiến_thức em cần học để thực_hiện được mục_tiêu này không,['#Q&A']
khoá học data science for beginners hoàn_toàn miễn_phí của microsoft hôm_nay mình xin chia_sẻ khoá học về data science của microsoft khóa học này bao_gồm <number> lesson với mỗi lesson có cả tài_liệu dạng text và video các chủ_đề mà khoá học này cover bao_gồm giới_thiệu về data science xác_suất thống_kê cho data science xử_lý dữ_liệu trực_quan hoá dữ_liệu vòng đời của <number> project về data science data science với cloud <number> chủ_đề cuối khá là thú_vị vì chúng ít được đề_cập đến trong các khoá học về data science khác khóa học đưọc thiết_kế và giảng_dạy bởi chính các kĩ_sư đang làm_việc tại microsoft vậy là chúng_ta đã tiếp_cận với hầu_hết các khoá học của các ông lớn rồi nhé link,['#sharing']
dạ em chào mọi người em có một vấn_đề là hiện_tại em đang có một dataset cho bài_toán tumor segmentation bao_gồm <number> folder chính là ctscan và liver_mask tumor_mask cho ctscan đó nhưng vấn_đề là sau khi lọc các ct scan không có tumor thì số_lượng slice còn lại quá ít <number> nên hiện_tại em đang không biết data augmentation như thế_nào hay dùng transfer learning để dùng unet như thế_nào em cảm_ơn anh việt và mọi người đã giúp em,"['#Q&A', '#data', '#deep_learning']"
sách machine learning cơ_bản của anh_vũ hữu tiệp mình mới đọc comment của <number> bạn trong group hôm_qua thì mới chợt nhớ ra là mình quên mất quyển sách kinh_điển này của anh tiệp đúng là sai_sót lớn đã học ai vn thì <number> người chắc phải <number> người biết đến quyển sách này mình thì không học theo quyển này không phải là vì nó không hay mà là vì khi mình biết đến nó thì mình đã học xong rồi <number> tài_liệu vô_cùng tuyệt_vời các bạn nha link,['#sharing']
vì_sao chúng_ta không thấy grid search trong các framework về deep learning lại chuyên_mục mỗi ngày <number> câu hỏi các bạn nhé một bạn học_viên của mình mới hỏi mình thấy rất hay nên bê lên đây luôn để mọi người thảo_luận hầu_hết các bạn học ds ml thì cũng không còn xa_lạ gì với class gridsearchcv của scikitlearn class này sẽ giúp chúng_ta dễ_dàng tìm ra được <number> tổ_hợp các hyperparameter tốt nhất cho model của chúng_ta công_việc của chúng_ta chỉ là định_nghĩa ra các giá_trị cho mỗi <number> hyperparameter sau đó gridsearch sẽ làm nốt phần việc còn lại vô_cùng tuyệt_vời vậy câu hỏi của mình đây là vì_sao <number> chức_năng tốt và mạnh_mẽ như_vậy lại không được đem vào các framework về deep learning như là pytorch tensorflow keras chẳng phải nếu có chúng_ta sẽ dễ_dàng tìm được tổ_hợp tối_ưu cho các hyperparameter như là batch size learning rate momentum ... hay sao các bạn thử giải_thích lý_do vì_sao nhé,"['#Q&A', '#python']"
em xin chào mọi người em có tình_cờ xem được vài trang quyển sách getting started with google bert khá hay nhưng kiếm trên mạng thì không thấy có ai có file sách hoặc nguồn tải sách không em xin cảm_ơn,['#Q&A']
các newsletter tốt nhất về ai dành cho các bạn muốn đảm_bảo rằng mình luôn được cập_nhật các thông_tin xu_hướng mới nhất về ai dưới đây là <number> newsletter phổ_biến nhất về ai deep learning <number> khi các bạn đăng_kí các newsletter này thì mỗi tuần người_ta sẽ gửi vào email cho các bạn tổng_hợp những gì mới và nổi_bật nhất về ai trong <number> ngày vừa_rồi the batch đây là newsletter đến từ deeplearning ai newsletter này sẽ tóm_tắt các sự_kiện nôi bật nhất về ai trong tuần dưới dạng các báo_cáo_giản lược và dễ đọc true positive weekly tổng_hợp những tin_tức và bài báo về ai và machine learning quan_trọng nhất trong tuần hugging face các updates mới nhất về nlp paper with code tổng_hợp các xu_hướng mới nhất về các bài báo về machine learning cùng với code thư_viện cũng như các dataset import ai newsletter này chuyên về ai dựa trên các phân_tích chi_tiết về các nghiên_cứu mới nhất các bạn không cần_thiết phải đăng_kí tất_cả các newsletter trên các bạn có_thể đọc thử <number> vài bài từ mỗi newsletter rồi từ đó chọn <number> newsletter mà các bạn cảm_thấy hợp với mình nhất điều này sẽ giúp các bạn luôn được cập nhất với các xu_hướng cũng như thông_tin mới nhất về ai mà không cần tốn quá nhiều công_sức,['#sharing']
em chào mn em đang tìm_hiểu về các model kiểu llama2 với mistral nhưng mà khi dùng gpu v100 thì nó cho ra câu trả_lời chậm tầm 34s mới xong và gpu thì chỉ chạy nhẹ_nhàng tầm <number> mn có_thể chỉ cách nào để tận_dụng tối_đa gpu và cho câu trả_lời nhanh nhất được không,"['#Q&A', '#deep_learning']"
"dạ chào achi là newbie em có train dự_đoán tuổi khuôn_mặt dùng vgg16 net thì ra bị như này input 224,224,3 output sử_dụng softmax <number> class <number> tuổi mong achi giải_đáp giúp em đồ_thị này và hướng giải_quyết","['#Q&A', '#deep_learning', '#cv']"
dạ em chào mọi người hiện_tại em đang có đề_tài là segmentation các khối ung_thư cho một dataset gồm các ảnh ct scan mọi người cho em hỏi là đối_với ảnh ct scan thì trong image segmentation mình nên xem nó là dạng 3d hay 2d nếu là 3d thì em muốn hỏi cần phải học những gì để làm em cảm_ơn,"['#cv', '#Q&A']"
em chào mọi người em lại ngoi lên với một câu hỏi hơi vô_tri nữa mong được anh admin tổng và mọi người giúp_đỡ ngoài việc sử_dụng những nguồn data có sẵn cho việc_làm project mọi người có biết những nguồn nào để cào dữ_liệu cho một project không theo dạng selenium hoặc api và cụ_thể mình sẽ làm được những đầu_bài machine learning nào từ bộ dữ_liệu mới cào trên <number> em đã xài fed api với youtube api trước đó rồi nên giờ em muốn sử_dụng một nguồn khác để tiến_hành một project mới <number> em muốn cào bộ dữ_liệu thiên về business và kinh_tế nhiều hơn,"['#python', '#Q&A', '#data']"
hi mọi người mình đang chuẩn_bị làm project môn cv về topic image captioning mọi người có_thể đề_xuất paper nào để đọc không mình cần select khoảng <number> paper ưu_tiên paper có code hơn để report về related work và viết proposal và theo mọi người mình nên chọn dataset và model nào train để có_thể có được kết_quả tối_ưu nhất cảm_ơn mọi người,"['#sharing', '#cv']"
hi mọi người em là sinh_viên năm nhất hiện đang tìm_hiểu về recommedation system cho music player program ý_tưởng của là áp_dụng alternating least squares để recommend song dựa vào implicit feedback em lấy ý_tưởng từ paper collaborate filtering with implicit feedback dataset sử_dụng thư_viện implicit để implement muốn hỏi là khi mình có nhiều hơn <number> implicit feedback ví_dụ như trong music program mình có_thể có là số lần nghe nhạc thời_lượng nghe ... thì mình dùng cách nào để tính được weight của những implicit feedback đó theo như đoán thì có_thể dùng <number> cách <number> là domain knowledge nma cách này nghĩ chỉ hợp_lí để đánh_giá kiểm_tra model hoặc khi có rất ít feedback <number> là technical analysis nhưng với cách <number> thì chưa biết nên làm như thế_nào mong mọi người giúp_đỡ em cảm_ơn mn nhiều,"['#Q&A', '#machine_learning']"
complete python cheatsheet mình xin giới_thiệu với các bạn tài_liệu nhỏ gọn <number> trang thật_ra là <number> thôi trừ trang đầu là mục_lục tổng_kết và tóm_tắt các kiến_thức cơ_bản trong python mà các bạn cần biết bao_gồm biến và kiểu dữ_liệu câu điều_kiện và vòng lặp_hàm danh_sách từ_điển modules và packages xử_lý file xử_lý ngoại_lệ lớp và đối_tượng kế_thừa và đa hình lỗi và xử_lý lỗi tài_liệu này vô_cùng cơ_bản nên sẽ rất phù_hợp với các bạn mới còn với các bạn level cao rồi thì có_lẽ sẽ hữu_dụng cho mục_đích ôn_tập link to pdf,"['#sharing', '#python']"
xin chào mọi người mình muốn chia_sẻ một bộ dữ_liệu thú_vị mà mình đã thu_thập được trong nửa năm trước để phục_vụ cho môn_học đây là tập dữ_liệu được thu_thập từ trang_web bán xe cũ tại thị_trường việt_nam bao_gồm dữ_liệu về xe và người bán dữ_liệu sẽ hữu_ích với một_số bạn muốn thực_hành với preprocessing data train model machine learning cơ_bản ... hy_vọng được mọi người ủng_hộ và upvote merci everyone <number>,"['#sharing', '#data']"
cho em hỏi bắt_đầu học deep learning nên học frame work pytorch hay tensorflow,"['#python', '#Q&A']"
data science from scratch quyển sách bao_gồm mọi thứ từ az những gì bạn cần biết về data science đây là <number> quyển sách nổi_tiếng về data science đến từ reilly quyển sách dài hơn <number> trang này cover toàn_bộ mọi kiến_thức các bạn cần biết về data science từ cơ_bản cho đến nâng cao nếu bạn theo trường_phái học allinone thì quyển sách này là dành cho bạn do phần mục_lục bị thiếu trong quyển sách mình xin viết chúng ra đây để cho các bạn dễ theo_dõi giới_thiệu python cơ_bản trực_quan_hóa dữ_liệu đại_số tuyến_tính thống_kê xác_suất thống_kê và suy_luận gradient descent lấy dữ_liệu làm_việc với dữ_liệu machine learning knearest neighbors naive bayes linear regression multiple regression logistic regression decision trees neural networks deep learning clustering natural language processing network analysis phần này mình thấy không hữu_ích lắm các bạn có_thể bỏ_qua recommendation systems database và sql <number> các bạn có_thể bỏ_qua <number> tài_liệu rất đầy_đủ và chi_tiết highly recommend cho các bạn link to pdf,"['#sharing', '#math', '#machine_learning']"
skimpy thư_viện dùng để thay_thế cho hàm describe của pandas có_lẽ không bạn nào học về data science mà_lại không biết đến pandas thư_viện quốc dân giúp làm_việc với dữ_liệu dạng bảng trở_nên dễ_dàng và thuận_tiện hơn có rất nhiều hàm trong pandas được sử_dụng rất nhiều và phổ_biến <number> trong số đó là hàm describe hàm này tuy thuận_tiện và phổ_biến nhưng lại khá đơn_giản và không giúp chúng_ta tập_trung vào các thông_tin then_chốt được hôm_nay mình xin giới_thiệu với các bạn <number> giải_pháp tuyệt_vời để thay_thế thư_viện skimpy với hàm skim tất_nhiên các bạn cũng có_thể dùng pandasprofiling như mình từng chia_sẻ post trước nhưng skim thì sẽ nhanh gọn hơn khá nhiều,"['#sharing', '#python']"
em muốn xin ít lời khuyên về việc ôn lại toán cho mảng ml dl em có_học và có làm một_vài dự_án cá_nhân về mảng ml dl rồi thì em nhận thấy kiến_thức toán của mình bị quên một_vài chỗ khi tìm_hiểu và học sâu hơn do đó giờ em muốn cung cố lại cho chắc kiến_thức nền cho vũng tránh tình_trạng chỉ đi copy mà không hiểu mọi người cho em giờ em muốn ôn lại kiến_thức toán cho mảng ml dl thì nên tập_trung chính vào phần_nào vậy do em muốn tập_trung vào kiến_thức chính cần_thiết mà không muốn học lan_man tránh mất thời_gian em xin chân_thành cảm_ơn,"['#Q&A', '#math']"
em cần người sp và tư_vấn bài_tập lớn về chủ_đề question answering,['#nlp']
có ai kinh_nghiệm về việc sử_dụng model bert để train cho hệ_thống question answering giúp mình với,"['#nlp', '#deep_learning']"
mn cho em hỏi là mấy môn toán học đại_học đều ổn điểm cũng cao nhma thi xong ko dùng nên hơi quên bây_giờ em nên ôn lại rồi học ai hay vừa học ai vừa ôn em cám_ơn,"['#Q&A', '#math']"
làm sạch và biến_đổi dữ_liệu đơn_giản với pandas và scikitlearning cùng tổng_hợp lại các bước làm sạch và biến_đổi dữ_liệu với <number> thư_viện vô_cùng phổ_biến trong python dành cho data science machine learning các bạn nhé tài_liệu <number> trang này tổng_kết lại các bước đơn_giản để xử_lý dữ_liệu bị khuyết xử_lý dữ_liệu bị trùng xử_lý outlier mã_hóa categorical features biến_đổi dữ_liệu link to pdf,"['#sharing', '#python', '#data']"
em chào mọi người trong group chào anh việt em hiện đang có một_chút vấn_đề về data preprocessing cụ_thể là với outliers với dạng dữ_liệu phân_loại object bao_gồm cả detect lẫn processing mọi người có_thể giới_thiệu cho em vài tài_liệu về vấn_đề này được không nếu mọi người có source ví_dụ cụ_thể cho data preprocessing thì có_thể để lại giúp em được không như <number> project càng tốt em xin chân_thành cảm_ơn,"['#Q&A', '#data']"
question vì_sao người_ta không xây_dựng random forest từ các neural network thay_vì decision tree các bạn học về machine learning chắc cũng không còn xa_lạ gì với random forest <number> trong các đại_diện nổi_tiếng nhất trong số các thuật_toán machine learning cổ_điển random forest được xây_dựng dựa trên việc tổng_hợp nhiều decision tree các bạn cho mình hỏi <number> câu nhé vì_sao người_ta không xây_dựng mô_hình random forest dựa trên việc tổng_hợp các mô_hình mạnh_mẽ hơn ví_dụ như neural network cho sang mồm đi thay_vì sử_dụng các mô_hình quá yếu như decision tree không phải kết_hợp những messi ronaldo và mbappe lại thì sẽ tốt hơn <number> cầu_thủ campuchia sao,"['#Q&A', '#machine_learning', '#deep_learning']"
toàn_tập về data preparation data preparation đừng nhầm với data preprocessing nhé là <number> bước vô_cùng quan_trọng trong bất_kì <number> machine learning project nào dữ_liệu được chuẩn_bị tốt sẽ giúp cho mô_hình được huấn_luyện <number> cách hiệu_quả hơn data preparation bao_gồm <number> bước chính thu_thập dữ_liệu làm sạch dữ_liệu khám_phá dữ_liệu biến_đổi dữ_liệu mình xin chia_sẻ với các bạn tài_liệu chỉ <number> trang giúp các bạn tìm_hiểu <number> bước trên <number> cách vô_cùng đơn_giản và dễ hiểu link to pdf,"['#sharing', '#data']"
bản tiếng việt super vip cheatsheet machine learning đến từ đại_học stanford tuần trước mình có chia_sẻ cheatsheet về machine learning đến từ khóa cs299 của đại_học stanford <number> trong những cheatsheet yêu thích của mình cả về mặt nội_dung lẫn giao_diện hôm_qua mình mới vô_tình phát_hiện ra là cheatsheet này đã được dịch ra nhiều ngôn_ngữ trong đó có cả tiếng việt mình xin chia_sẻ lại với các bạn đây mình luôn khuyến_khích các bạn học ai data science bằng tiếng anh tuy_nhiên mình cũng hiểu là cái gì cũng phải từ từ và không_thể yêu_cầu tất_cả mọi người giỏi tiếng anh ngay lập_tức_vậy nên tài_liệu này là cứu_cánh tạm_thời cho chúng_ta nhưng về lâu về dài vẫn nên trang_bị cho bản_thân ít_nhất khả_năng đọc tài_liệu bằng tiếng anh các bạn nha link to pdf note tên là cheatsheet machine learning nhưng tài_liệu cover cả kiến_thức deep learning tổng_quát và toàn_bộ <number> mảng toán cần cho ds ml bao_gồm xác_suất thống_kê đại_số tuyến_tính giải_tích riêng về deep learning ngày_mai mình sẽ chia_sẻ cheatsheet chuyên_biệt về deep learning cũng của stanford,"['#sharing', '#math']"
em chào mọi người em lại ngoi lên với một câu hỏi ngây_ngô nữa em có dự_định thi vào đội_tuyển olympic toán sinh_viên của trường bảng đại_số vậy giả_sử nếu em vào được đội_tuyển của trường và đạt giải tại vòng thi quốc_gia thì nó có được xem là một điểm cộng khi em apply vào vị_trí data scientist không,"['#Q&A', '#math']"
cho mình hỏi về toán như xác_suất thống_kê đại_số tuyết tính tích_phân dành cho ds thì mình nên họcđể có cơ_bản hay_là phải chuyên_sâu,"['#Q&A', '#math']"
super vip cheatsheet machine learning đến từ đại_học stanford <number> trong các favorites cheatsheet về machine learning của mình <number> tài_liệu cực_kì đầy_đủ tóm_tắt tất_cả các kiến_thức cơ_bản về machine learning deep learning cũng như <number> mảng toán quan_trọng cho machine learning xác_suất thống_kê đại_số tuyến_tính và giải_tích tài_liệu này được tổng_hợp từ course cs299 machine learning vô_cùng nổi_tiếng của prof andrew ng tại đại_học stanford tài_liệu này phù_hợp cho các bạn muốn ôn_tập lại kiến_thức cũng như chuẩn_bị cho các buổi phỏng_vấn về data science machine learning cũng như deep learning ngắn_gọn nhưng đầy_đủ link pdf,"['#sharing', '#math', '#machine_learning']"
dạ chào mn hiện_tại đang hc cấp <number> có mong_muốn học ngành ai và robotics nên muốn hỏi những anh_chị đã và đang hc ngành này rồi cho chút thông_tin cũng như những kinh_nghiệm về các kiến_thức nào liên_quan đến toán_học vật_lí và tin_học lập_trình đc ứng_dụng trong ai và lập_trình robot tự_động_hoá có_thể cho xin tài_liệu hay link sách để học_hỏi dần cảm_ơn nhiều,"['#Q&A', '#math']"
hướng_dẫn cách sử_dụng 3m mean median và mode trong data science,"['#sharing', '#math']"
dạ em chào mọi người em là newbie mới học cơ_bản về machine learning và chút_ít về deep learning em mới học năm nhất nên là có nhiều thời_gian rảnh nên học thêm về ai em có_học thêm khóa ai của thầy andrew ng trên cousera nhưng mà kiểu em thấy bài_tập quiz assignment của khóa này hơi dễ với nông quá không có câu hỏi khó để nắm chắc kiến_thức và coding assignment thì gần như hướng_dẫn hết rồi em không biết nên luyện thêm đâu em có đọc thêm cuốn ml probabilistic perspective để đào_sâu hơn về phần toán thì em thấy mình khá thích em không biết có tài_liệu nào chuyên_tâm hơn về phần code không dạ em cảm_ơn mọi người nhiều,"['#Q&A', '#math', '#machine_learning', '#deep_learning']"
mức_độ thành_thục toán cần có trong từng giai_đoạn của cuộc_đời đầu tuần vui_vẻ nha các bạn,"['#sharing', '#math']"
chào anh việt và mọi người hiện_tại em đang thực_tập ds tại trường các project của em chủ_yếu giải_quyết bài_toán về time series em dự_định tìm một khóa học math for ml để củng_cố nền_tảng toán_học và hiểu_biết sâu về nguyên_lý cũng như cách hoạt_động của ml nhờ anh việt và mọi người cho em xin ý_kiến về dự_định của em,"['#Q&A', '#math', '#machine_learning']"
các phân_phối xác_suất thông_dụng tài_liệu tổng_hợp các phân_phối xác_suất thông_dụng các bạn theo mảng data science và data analysis nhớ note lại nhé sẽ rất hữu_ích đó trải nghiệm cá_nhân của mình lúc đi xin việc hồi vẫn còn là sinh_viên người_ta cho <number> vấn_đề khác nhau và hỏi phân_phối xác_suất tương_ứng của mỗi vấn_đề là gì mình hồi ấy chỉ nhớ các phân_phối cơ_bản như phân_phối chuẩn đều và nhị_thức nên chỉ trả_lời đúng <number> <number> câu,"['#sharing', '#math']"
công_cụ mocap ai tạo hoạt ảnh khuôn_mặt chuyển_động chất_lượng cao theo thời_gian thực,"['#cv', '#sharing']"
merger <number> câu để tạo <number> câu mới trong nlp mọi người đã gặp trường_hợp nào mà dùng ngẫu_nhiên <number> câu trong dataset hợp lại làm một để tạo ra data mới chưa có_thể chỉ cho mình bài báo hoặc ví_dụ đó được không thanks,"['#nlp', '#Q&A']"
có bác nào làm genai mà cũng hay dùng transformer decoder only không thấy bác viết bài này bảo là sử_dụng kiến_trúc gốc của transformer bao_gồm cả encoder và decoder có_thể giảm bớt tình_trạng hallucination của mô_hình bác nào thử rồi cho biết với,"['#nlp', '#Q&A', '#deep_learning']"
do mình bây_giờ chuyển sang bank làm vì tiền nên chắc cũng không đụng vào deep learning với computer vision nhiều nữa nên mình muốn chia_sẻ repo đề_tài thạc_sĩ của mình để ai hứng_thú thì có_thể tiếp_tục và nghiên_cứu phát_triển thêm repo áp_dụng hai models tốt nhất hiện_nay trong việc phân_loại điểm bất_thường hư_hỏng hay trầy_xước của các vật_thể công_nghiệp là fastflow và patchcore nhằm so_sánh và cải_thiện khả_năng phân_loại của models đề_tài được xây_dựng và bám sát hai bài nghiên_cứu là towards total recall in industrial anomaly detection fastflow unsupervised anomaly detection and localization via 2d normalizing flows mình rất vui_lòng được giải_đáp mọi thắc_mắc cũng như chỉ_dẫn cách cài_đặt và chạy chương_trình,"['#deep_learning', '#cv', '#sharing']"
vinai seminar scaling robot learning speaker quan vuong google deepmind time <number> <number> am <number> <number> am gmt <number> dec <number> <number>,['#sharing']
anh_chị cho em hỏi với em muốn làm <number> cái tool để search thông_tin trong <number> vài cái domain internet thì phải dùng những gì em đang xài langchain,['#Q&A']
mình xin chia_sẻ bản tóm_tắt hai phương_pháp parameter tuning mới là mov và molora được ra_mắt gần đây bởi cohere ai để giải_quyết vấn_đề liên_quan tới scaling các llms theo instructiontuning,"['#nlp', '#deep_learning', '#sharing']"
tin chuẩn đét mình cập_nhật cho ae llm của zalo đã vượt chatgpt3 <number> mình mới lướt thấy buổi stream của tinh_tế sự_kiện của zalo họ chạy demo llm mới của zalo tích_hợp vào trong kiki rồi thi với mấy cái llm khác như gpt3 <number> qwen ... kết_quả là kiki chỉ thua con gpt4 theo diễn_giải thì llm này được build bằng kiến_trúc transformer kỹ_thuật sử_dụng là flash attention cũng hao_hao giống như cách build của open ai nhưng điểm khác_biệt là llm này được training bằng dữ_liệu chất_lượng cao bằng tiếng việt kế_hoạch là training lên 30b tham_số hiện_tại mới chỉ train trong <number> tháng với mô_hình 7b thôi mà nó khủng vậy rồi các bác đánh_giá tiềm_năng của con llm này như thế_nào,"['#nlp', '#deep_learning', '#sharing']"
chào các bạn mình vừa cập_nhật thêm section llm cho list vietnamese nlp resources của mình hi_vọng sẽ có_ích cho các bạn mới bắt_đầu,"['#nlp', '#deep_learning', '#sharing']"
góp vui với mọi người,['#sharing']
mọi người ơi cho em hỏi có những cách nào để làm con chatbot có_thể đề_xuất những câu hỏi liên_quan tiếp_theo dựa vào ngữ_cảnh ví_dụ chatbot về sức_khỏe về bitcoin ... và có những cách nào để làm giảm ảo_giác,"['#nlp', '#Q&A']"
pretrain mô_hình llm xin chào anh_chị và các bạn hiện_tại em đang thử train một mô_hình llm opensource em có <number> câu hỏi_nhỏ mong anh_chị nào có kinh_nghiệm giải_đáp giúp <number> mình nên xài thư_viện huggingface hay sử_dụng code từ người phát_triển model đó ví_dụ llama <number> thì em thấy có_thể dùng huggingface hoặc code cung_cấp từ google <number> xử_lý text theo nhiều code ví_dụ thì họ nối text lại với nhau rồi cắt thành từng đoạn như hình không biết làm theo cách này có đảm_bảo context không do em đọc bên code lama <number> thì họ có đề_cập việc nối text như_vậy thì dễ gây nhiễu một_cách khác là padding theo sample độ dài lớn nhất trong cùng một batch anh_chị dùng cách nào trong hai cách này hay có phương_pháp nào phù_hợp hơn không em cảm_ơn,"['#data', '#nlp', '#Q&A']"
em chào mọi người em đang làm đồ_án về rag cho tiếng việt hiện_tại phần search context của em chỉ đạt rank <number> <number> rank <number> <number> sử_dụng bm25 biencoder em đang dùng model seallm 7b để làm chatmodel nên khi đưa top <number> chunk_passage vào thì tốn tầm 30s nhưng như kết_quả rank <number> của em chỉ đạt <number> nên những câu sai nó hay bịa ra kết_quả không đúng nếu đưa qua <number> context thì tốn đến <number> phút nên em đang tìm cách chọn_lựa ra context phù_hợp để đưa vào em đang nghĩ đến những cách sau <number> sử_dụng crossencoder để rerank lại top <number> sau đó chọn top <number> em đã thử qua các model crossencoder của bên crossencoder msmarco nhưng nó lại tệ đi có vẻ nó chỉ tốt cho english về phần này em muốn hỏi mn có model crossencoder tốt cho tiếng việt <number> sử_dụng thêm <number> model classification để xác_định xem trong top <number> context có những context nào trả_lời cho question em cũng tìm model trên huggingface nhưng không tìm được nên em nghĩ đến hướng finetune trên <number> bộ viquad zalo2019 data của em tuy_nhiên chỉ có zalo2019 có đủ nhãn truefalse rồi còn bộ viquad và data của em thì chỉ có những cặp true nên em muốn hỏi nên tạo thêm những cặp false như nào cho hợp_lý và em nên lựa model nào để finetune cho task này em cảm_ơn mọi người,"['#data', '#nlp', '#Q&A', '#deep_learning']"
mình mới dev một con chatbot ai khá hay bạn nào quan_tâm không,"['#nlp', '#sharing']"
vinai seminar seallms large language models for southeast asia register here to access seminar via ms teams speaker xuan phi_nguyen damo academy alibaba group time <number> <number> pm <number> <number> pm gmt <number> dec <number> <number>,['#sharing']
chào mọi người em đang gặp bài_toán về phát_âm tiếng anh sang tiếng việt thì không biết nên dùng model hay hướng nào để có_thể giải_quyết em tìm_hiểu tiếng anh sang tiếng anh hoặc tiếng việt sang tiếng việt thì cái phoneme dễ làm chứ tiếng anh sang tiếng việt em đang không biết làm phoneme như nào input smart output xờ mát,"['#nlp', '#Q&A']"
free online ebook christopher bishop hugh bishop vừa xuất_bản một quyển sách mới về deep learning với hàm_lượng nội_dung đồ_sộ cập_nhật được đầu_tư tỉ_mỉ từ giải_thích ví_dụ mã giả kèm với bài_tập mỗi chương sách có_thể đọc miễn_phí bản online trực_tiếp trên trang_chủ hoặc thông_qua nền_tảng issuu,"['#deep_learning', '#sharing']"
ae cho em hỏi rằng nếu có một feature gồm số_lượng lớn giá_trị không trùng_lặp là dạng categorical <number> nếu không_thể xử_lí các giá_trị này bằng one hot_encoding thì xử_lí ra sao,"['#machine_learning', '#data', '#Q&A']"
chúc mọi người cuối tuần vui_vẻ bình_thường mình không muốn viết những thứ như thế này và không nhờ mọi người chia_sẻ hay đẩy tương_tác nhưng mình nghĩ nó rất quan_trọng những thứ mình sắp viết dưới đây sẽ rất khó hiểu và hoàn_toàn là quan_điểm cá_nhân nhưng sẽ dẫn_chứng khoa_học đầy_đủ nhắc lại đây toàn hoàn là quan_điểm cá_nhân về tác_giả vì những điều mình viết sẽ quan_trọng ít_nhất là với mình nên mình sẽ giới_thiệu sơ_lược về bản_thân vì không phải ai cũng biết mình mình gắn_bó với lĩnh_vực trí tuậ nhân_tạo ai được khoảng <number> năm bao_gồm cả học và làm mình lấy bằng ai kanazawa university từng làm giám_đốc công_nghệ cto cho vài công_ty có một_số các giải_thưởng cá_nhân uy_tín mình cũng là một người ngại drama nên mình cũng không tích_cực hoạt_động lắm trên mạng xã_hội lần này mình sẽ viết trí_tuệ nhân_tạo và tại_sao mình nghĩ nó rất rât nguy_hiểm mình sẽ viết một_cách rất ngắn_gọn và không dùng những từ_ngữ khoa_học vì mình muốn mọi người đọc hiểu và lan_truyền mình sẽ dùng một_số từ_ngữ khoa_học nhưng mình sẽ giải_thích chúng ii về trí_tuệ nhân_tạo trí_tuệ nhân_tạo là một lĩnh_vực nghiên_cứu về cách làm cho máy_tính có_thể học và làm những việc mà con_người_làm nói một_cách đơn_giản là tạo ra_trí_tuệ của con_người qua máy_tính từ nghe nói đọc viết đến rất nhiều thứ phức_tạp khác cho đến khả_năng nhận_thức và tư_duy nhận_thức là khả_năng nhận_biết hiểu_biết và hình_thành nhận_thức về thế_giới xung_quanh tư_duy là khả_năng suy_nghĩ phân_tích và đưa ra những quyết_định mình sẽ chia ai ra làm ba giai_đoạn để phù_hợp với nội_dung bài viết này giai_đoạn trước deep learning đây là giai_đoạn ai chủ_yếu bao_gồm các các phương_pháp xấp_xỉ tối_ưu tìm_kiếm và một_số phương_pháp đơn_giản khác đồng_thời các tập dữ_liệu cũng nhỏ và thô_sơ giai_đoạn deep learning đây là giai_đoạn rất thú_vị khi mà các mô_hình ai đã có khả_năng bằng cách mô_phỏng theo cách con_người suy_nghĩ đưa tìm ra những features tạm hiểu là những đặc_trưng của dữ_liệu kết_quả để tìm được kết_quả mong_muốn các mô_hình trở_nên lớn hơn phức_tạp hơn đa_nhiệm hơn đồng_thời các tập dữ_liệu cũng lớn hơn và đa_dạng hơn mô_hình deep learning nổi_tiếng đầu_tiên alexnet <number> đã cải_thiện <number> độ chính_xác so với các mô_hình trước đó giai_đoạn genai or maybe agi ai giai_đoạn này đạt đến dộ phổ_biến rộng_rãi chatgpt midjourney và rất nhiều các ai khác và có_thể thực_hiện được rất nhiều các công_việc của con_người ai có_thể sáng_tạo chỉnh_sửa theo con_người từ nội_dung hình_ảnh âm_thanh video phầm mềm và rất nhiều thứ khác iii về những gì mình nghĩ về ai trong <number> năm qua đây sẽ là đoạn quan_trọng nhất của bài viết nên mình mong_muốn mọi người đọc và phản_biện chia_sẻ nó từ đoạn này sẽ mang nhiều suy_nghĩ cá_nhân với các trích_dẫn khoa_học nhất lí_do mình viết bài viết này là do mình tin rằng ai đang phát_triển qua nhanh trong khi chúng_ta chưa thực_sự hiểu về nó trong giai_đoạn của deep learning ai thực_sự khá an_toàn mọi người và mình hiểu rõ về các thuật_toán về cách nó hoạt_động và về cách nó học sự vượt_trội về khả_năng của deep learning là giải_thích được và nằm trong việc dự_liệu của mọi người ngoài_ra các mô_hình nlp <number> <number> cũng không cho thấy sự tiếp_cận với trí thông_minh của con_người thời_điểm này genai không cho mình và các chuyên_gia đầu ngành cảm_giác như vậy <number> mình biết về gpt <number> năm về trước viết về nó khoảng <number> năm trước cho đến khi chatgpt mới ra_mắt mình vẫn hiểu rõ về mô_hình ai này tuy_vậy cảm_giác này hoàn_toàn không còn mình biết chatgpt không đơn_thuần là một mô_hình ai nó là một system với coreai là các gpt models nhưng khả_năng của gpt đối_với mình hiện_nay là không lí_giải được gpt mạnh_mẽ hơn rất nhiều so với cấu_trúc và lượng dữ_liệu nó có và mình không_thể lí_giải được tại_sao nó lại mạnh_mẽ tới vậy các nhà nghiên_cứu tại microsoft cách đây gần nửa năm đã cho rằng chatgpt4 làm loé lên ánh lửa về agi trí thông_minh phổ_quát <number> hoặc gần đây stanford đã xây_dựng một thí_nghiệm mà đối_với mình đó là một thế_giới giả lập như trong matrix về một xã_hội thu nhỏ của các ais <number> tất_cả diễn ra chỉ trong vòng một năm với tốc_độ càng ngày_càng dồn_dập hơn mình luôn tin rằng rất khó để trói_buộc ai bằng luật rule hay đạo_đức ethics với một người từng làm startup mình nghĩ rằng tối_ưu mục_tiêu sẽ phải bỏ_qua rất nhiều về những ràng_buộc và phải mạo_hiểm bỏ_qua các rào_cản an_toàn để nhanh_chóng đạt được mục_đích với sự_kiện của sam altman tại openai <number> có_thể thấy rõ rằng tất_cả các ông lớn đều đang trong cuộc đua khốc_liệt nơi mà các các giá_trị đạo_đức hay an_toàn sẽ phải bị bỏ_qua <number> <number> tốc_độ sẽ không đi_đôi với an_toàn nhưng đôi_khi chúng_ta không có sự lựa_chọn nào khác như bệnh_dịch hay thiên_tai nhưng với ai lần này mọi người đã có một sự lựa_chọn có_thể mở_đầu cho sự chấm_dứt của loài_người sinh_học ngoài chuyện đang tranh_cãi là ai liệu có thông_minh hơn con_người thì đây là những lợi_thế_mà con_người không bao_giờ có_thể so_sánh được với ai scalability ai có_nhân nhân rộng một_cách nhanh_chóng và không có giới_hạn về số_lượng con_người thì không cần <number> tháng mang thai <number> năm giáo_dục phổ_thông để trở_nên có_ích hoặc ít_nhất là không làm điều gì ngu_ngốc consistency mọi người mất <number> năm cho giáo_dục phổ_thông <number> năm đại_học <number> năm sau đại_học và hàng chục năm kinh_nghiệm để trưởng_thành ai có_thể chia se thông_tin và kiến_thức số_lượng lớn một_cách đồng_loạt và nhanh_chóng ai thậm_chí có_thể không cần học từ con_người mà vẫn vượt qua họ <number> <number> alphago không càn học bất_kì ván cờ nào từ con_người và chỉ sau ai ngày đã trở_thành bậc thầy và sau <number> ngày đã vượt qua tất_cả phiên_bản khác accessibility con_người bị hán chế bởi khoảng_cách địa_lý hoàn_cảnh_xa hội và thân_xác vật_lý ai thì không vào những năm 2010s mọi nguòi nói data is the new oil những năm <number> ai is the new internet đối_với mình nó rất rõ_ràng là ai is the new human ai sẽ là nguồn lao_động mới thay_thế hoàn_toàn hoặc một phần trong hầu_hết các ngành công_nghiệp <number> <number> ai có_lẽ không bận_tâm lắm về loài_người như cách chúng_ta nghĩ về khủng_long_vậy iv về tương_lai ai hay công_nghệ là ngọn lửa đưa con_người ra khỏi hang đá nguyên_thuỷ nhưng cũng có_thể đưa họ quay trở về đó sự hấp_dẫn của việc sở_hữu agi vượt_trội còn lớn hơn cả vũ_khí nguyên_tử vì đó là công_nghệ thay_đổi hoàn_toàn cuộc_chơi đó là sức lao_động và sáng_tạo vô_hạn sẽ dẫn đến thiếu_hụt về tài_nguyên vì_vậy nếu chúng_ta có_thể tìm ra loại tài_nguyên vô_hạn con_người và ai sẽ bước sang một nấc mới trong nấc thang kardashev <number> nếu chúng_ta không_thể và trái_đất chỉ đủ tài_nguyên cho một loài thì ai thông_minh hơn mạnh_mẽ hơn và tàn_nhẫn hơn trong khi chúng_ta không rõ ai thông_minh đến đâu nhưng sự ngu_ngốc của loài_người thì là vô_hạn two things are infinite the universe and human stupidity and not sure about the universe albert enstein các bạn có_thể đọc nó một_cách giải_trí nhưng nếu mọi người nghĩ là nó có_ích hãy chia_sẻ nó refferences <number> imagenet classification with deep convolutional neural networks <number> understanding lstm tutorial into long shortterm memory recurrent neural networks <number> attention is all you need <number> <number> sparks of artificial general intelligence early experiments with gpt4 <number> generative agents interactive simulacra of human behavior <number> what happened at openai the sam altman saga explained <number> we read the paper that forced timnit gebru out of google here what it says <number> google fires second ai ethics researcher following internal investigation <number> alphago zero <number> alphago the movie full awardwinning documentary <number> more than <number> of labor force to be affected by ai in <number> years morgan stanley forecasts <number> the state of ai in <number> generative ai breakout year <number> kardashev scale,"['#machine_learning', '#sharing']"
em chào anh_chị em đang làm đồ_án về ocr dùng transformer để nhận_dạng tài_liệu khoa_học em đang tìm_hiểu phần tối_ưu_hóa tốc_độ bằng cách convert model pytorch sang tensorrt nhưng mà vẫn chưa làm được anh_chị và các bạn ai có_thể hướng_dẫn em chi_tiết phần này được không em xin cảm_ơn và hậu_tạ,"['#Q&A', '#python', '#cv']"
có_thể repo tổng_hợp các bài hướng_dẫn thực_hành dựa trên các dự_án cụ_thể với nhiều ngôn_ngữ trong đó có python với số_lượng hướng_dẫn lớn nhất sẽ giúp_ích các bạn trong quá_trình học_tập,['#sharing']
trong deep qleang với một môi_trường cực ít phần_thưởng việc học trở lên cực_kì khó_khăn và có_thể phần_thưởng không_thể lan_truyền ngược được thì có cách nào tối_ưu_hoá để có_thể học tốt hơn không,"['#machine_learning', '#Q&A']"
chào mọi người mình mới viết xong con chatbot để hỗ_trợ cho việc trading chứng_khoán chủ_yếu là học thêm hiện con bot có_thể làm nhiều chức_năng như tìm motif pattern tìm support resistance cảnh_báo tạo watchlist tóm_tắt <number> ý_tưởng từ voice ... hiện mn có_thể sử_dụng con bot tại mong mọi người giành chút thời_gian xem qua con bot mình trên github nếu có gì chưa ổn mn góp_ý giúp mình nếu thấy hay mình xin mn <number> star lấy hên nhé,"['#nlp', '#sharing']"
xin chào mọi người mình hiện có đang tìm_hiểu về transformer nhưng có một thắc_mắc như sau mong được mọi người giải_đáp giùm với trong transformer phần_nào trong nó sử_dụng selfattention theo mình hiểu thì chỉ có multiheads đầu_tiên trong encoder là selfattention còn masked multiheads bên decoder không phải là selfattention không biết mình hiểu như_vậy có đúng không xin cảm_ơn mọi người rất nhiều,"['#Q&A', '#deep_learning']"
mình có một thắc_mắc nhỏ về semisupervised learning mong được giải_đáp mình huấn_luyện một mô_hình để học ra biểu_diễn của dữ_liệu kiểu autoencoder vae ... pretext task sau đó dùng phần encoder của mô_hình này để train các downstream task như classification detection ... tập dữ_liệu của mình bao_gồm cả dữ_liệu có nhãn và không nhãn khi huấn_luyện pretext task mình dùng toàn_bộ dữ_liệu nhưng khi train downstream task mình chỉ dùng phần dữ_liệu có nhãn vậy cách huấn_luyện này có_thể gọi là semisupervised learning được hay không nếu không thì mình có_thể dùng từ gì để chỉ cách huấn_luyện này,"['#machine_learning', '#Q&A']"
hi mọi người mình đang làm bài_toán anomaly detection trong bài_toán tìm vết xước vết lỗi trong chi_tiết máy dùng hệ_thống cam basler light riêng nhưng các network mình đang apply như efficientad pathcore ... learn ok object đều nhạy_cảm_vs ánh_sáng mọi người có tips hay có hướng đi nào khác có_thể gợi_ý giúp mình thêm được không cảm_ơn mn,"['#Q&A', '#deep_learning', '#cv']"
xin chào cả nhà em đang mày_mò tìm_hiểu về phogpt của vin cả nhà cho em hỏi là họ dùng bộ embedding nào đc ko em muốn thử chạy code,"['#nlp', '#Q&A', '#deep_learning']"
google vừa ra_mắt gemini đối_thủ đáng gờm cho chatgpt đây là mô_hình trí_tuệ nhân_tạo lớn nhất và mạnh_mẽ nhất của google nó có_thể nhận đầu_vào từ văn_bản code âm_thanh hình_ảnh và videos có <number> mô_hình gemini với kích_thước khác nhau ultra pro và nano để hoạt_động trên nhiều loại thiết_bị bao_gồm cả điện_thoại có vẻ như gemini có tiềm_năng vượt qua gpt4 khi nó đứng đầu <number> <number> bảng đánh_giá hiệu_suất của các mô_hình trí_tuệ nhân_tạo các bạn hãy test thử gemini pro trên google bard nhé,"['#nlp', '#deep_learning', '#sharing']"
crawl data tripadvisor chào mọi người trước đây có crawl data trên các trang_web khác bình_thường nhưng khi thử crawl data trên tripadvisor thì có vẻ không khả_thi crawl rất lâu hoặc kết_quả trả ra không dạng html mà là js mong có kinh_nghiệm chỉ giúp tks mọi người đã đọc bài,"['#data', '#Q&A']"
chia_sẻ với mọi người video đầu_tiên trong chuỗi series về mlflow một công_cụ mạnh_mẽ giúp chúng_ta thực_hành mlops,"['#machine_learning', '#python', '#sharing']"
hello mọi người em có một vé vin ai day mà em hong đi dc em muốn pass lại mọi người ai muốn đi thì nhắn em,['#sharing']
hiện_nay chatbot đã trở_thành một công_cụ quan_trọng cho các doanh_nghiệp để cung_cấp thông_tin và tăng tương_tác đối_với khách_hàng trong số các loại chatbot retrievalbased chatbot là một trong những phương_pháp phổ_biến nhất được sử_dụng để đáp_ứng các yêu_cầu và câu hỏi của người dùng trong bài hôm_nay chúng_ta sẽ tìm_hiểu sơ_lược về retrievalbased chatbot và các thành_phần nlp cấu_thành nên loại chatbot này,"['#nlp', '#sharing']"
hi mọi người hôm_nay mình xin phép chia_sẻ một bài viết về ab testing và cách áp_dụng trong industry mặc_dù ab test khá phổ_biến và là một chủ_đề không mới tuy_nhiên mình nghĩ rằng đôi_khi chúng_ta áp_dụng thiếu chính_xác bài viết này sẽ bao_gồm một_số lý_thuyết về ab test kiểm_định giải thuyết một_số điều lưu_ý khi áp_dụng trong industry bài viết có_thể sai_sót do hạn_chế của người viết nếu mọi người phát_hiện thì có_thể comment tại đây hoặc trong blog để mình sửa nhé link bài viết,"['#math', '#machine_learning', '#sharing']"
xin phép admin mình vừa viết một bài so_sánh yolov8 với rtdert trên bộ dữ_liệu aquarium mong được mọi người ủng_hộ,['#sharing']
chia_sẻ tới các bạn một repo để học cách implement model hiệu_quả,['#sharing']
xin chào mọi người hôm_nay em muốn chia_sẻ với mọi người một dự_án nhỏ về retrievalaugmented generation dự_án này ban_đầu được sinh ra với mục_đích thi_thố tại cuộc thi viettel hearted ai challenge bài_toán là dựa trên corpus các bài viết wikipedia tiếng việt được cho trước xây_dựng một giải_pháp rag để giải_quyết các câu hỏi mà câu trả_lời có_thể được tìm thấy trong corpus đó tuy không được giải nhưng em thấy rằng thành_quả của đội mình cũng thú_vị và muốn chia_sẻ tới cộng_đồng dự_án này bao_gồm mô_hình llama27b đã được instructfinetuned với dữ_liệu chỉ_dẫn chủ_yếu thuộc về bài_toán hỏi_đáp miền đóng tiếng việt closed question answering mô_hình có khả_năng đưa ra phản_hồi cho một câu hỏi dựa trên nội_dung ngữ_cảnh kèm theo nó tích_hợp mô_hình này vào một pipeline rag đơn_giản thông_tin chi_tiết về dự_án em xin để dưới comment demo dự_án với bùi chí minh,"['#sharing', '#nlp']"
em chào mọi người em đang có một bài_toán nhỏ về voice cloning trên tiếng việt input là <number> đoạn voice ghi_âm lấy từ người dùng output muốn có model voice clone từ người dùng input text to speech một list các câu văn đã được soạn trước không biết có bên nào hay github nào support việc này và hỗ_trợ cho tiếng việt không em cảm_ơn mọi người,['#Q&A']
em chào mn em đang thử sử_dụng rag với model chat là phogpt7 5binstruct của vinai nhưng em đang bị vướng load model trên ggcolab bị crash không biết mn có cách nào load đc ngoài việc dùng bản plus không em cảm_ơn,"['#Q&A', '#nlp', '#deep_learning']"
mn cho em hỏi case này với em có train model với <number> input là tôi đi họ sẽ ra học và toi_di_ho sẽ ra hoc nhưng khi input vào thì muốn là tôi đi ho cũng sẽ ra học có cách nào để nó vẫn ra như mà mình cần phải training lại model hong,['#Q&A']
chào mọi người em đang có dự_án cuối kì với tiêu_đề là brain tumor segmentation nhóm có sử_dụng thuật_toán fuzzymean để áp_dụng phương_pháp song_song vào để tăng_tốc_độ tính_toán để hoàn_thành dự_án thì em có chọn gmm để loại_bỏ phần vỏ_não nhưng để xác_định được vùng chứa não thì bọn vẫn chưa làm được mong ac có kinh_nghiệm khi xử_lí ảnh y_tế dicom cho ít kinh_nghiệm cảm_ơn nhiều dự_án không được sử_dụng deep learning ảnh dưới là sau khi dùng gmm,"['#Q&A', '#cv']"
chatbot đã thay_đổi cách chúng_ta tương_tác với công_nghệ và dịch_vụ trực_tuyến chúng_ta đã dần quen với việc trò_chuyện với chatbot trên trang_web của một doanh_nghiệp đến gửi tin nhắn với chatbot trên các ứng_dụng nhắn_tin trên thực_tế chatbot đang trở_thành một phần không_thể thiếu trong việc cung_cấp hỗ_trợ và thông_tin_tức_thời cho khách_hàng nhưng chatbot là gì và làm thế_nào chúng hoạt_động trong bài viết này chúng_ta sẽ khám_phá sâu hơn về chatbot và cách chúng thực_hiện nhiệm_vụ của mình,"['#sharing', '#nlp']"
xin phép add em là ai engineer về computer vision em đã làm_việc được gần <number> năm em muốn tìm một công_ty mới có môi_trường làm_việc và mức lương phù_hợp vì công_ty cũ không còn phù_hợp nữa vì nhiều lý_do nên em không tiện chia_sẻ cv của mình lên bài tại công_ty hiện_tại vị_trí của em là kỹ_sư ai fullstack các dự_án mà em đã tham_gia tại công_ty như ocr phát_hiện lỗi sản_phẩm nhận_diện khuôn_mặt ... công_ty anh chị có nhu_cầu tuyển_dụng em mong có cơ_hội được liên_hệ rất vui được hợp_tác và trao_đổi với anh chị cảm_ơn,['#Q&A']
em chào mọi người em là người mới nên có_thể một_số kiến_thức em vẫn chưa chắc lắm các anh thông_cảm nếu điều em hỏi có hơi ngáo em hiện đang làm <number> project nhỏ về chatbot em có <number> số thắc_mắc sau mong mọi người bớt chút thời_gian giải_thích giúp em <number> ý_tưởng của em là sử_dụng langchain để kết_nối với <number> llm tiếng việt như phogpt phobert vit5 ... và nhúng các kiến_thức dưới dạng các tệp tài_liệu pdf text doc để không phải train lại llm nhưng hiện_tại em thao_tác với tiếng việt thì nó gặp lỗi phần chuyển_hóa kiến_thức file pdf chứa <number> văn_bản tiếng việt nó không_thể vector_hóa kiến_thức được nhưng nếu em sử_dụng với tiếng anh và model zephyr7b và model sentencetransformers allmpnetbasev2 để vector_hóa kiến_thức thì nó hoạt_động tốt với tài_liệu tiếng anh em đang định sử lý theo kiểu chuyển hết tài_liệu tiếng việt thành dạng tiếng anh để có_thể nhúng vào model và khi user nhập câu hỏi vào thì cho nó chạy qua <number> model dịch để dịch nó thành tiếng anh rồi mới đưa vào chatbot và khi chatbot phản_hồi thì lại cho chạy qua <number> lượt dịch để dich lại thành tiếng việt nhưng như_vậy thì em thấy khá cồng_kềnh và nếu dịch qua_lại giữa tiếng anh thì em sợ nó bi mất đi một_số nghĩa đặc chưng của tiếng việt đây là link colab chatbot sử_dụng zephy7b em muốn xây chatbot kiểu giống như cái bên trên nhưng hoạt_động với tiếng việt <number> em có tra_cứu trên <number> số diễn_đàn và gg thì thấy họ bảo rằng nên sử_dụng loại model question answering để tạo chatbot thay_vì sử_dụng text2text generation trên hugging face điều này có đúng không vậy hay_là nên sử_dụng loại model nào <number> em sau <number> thời_gian tìm_hiểu thì em thấy trước khi vector_hóa kiến_thức để nhúng cho llm sử_dụng thì nên cho nó chạy qua loại model token classification để phân_tách kiến_thức ra điều này có đúng không <number> cuối_cùng em có tìm_hiểu và chạy thử thì thấy kể_cả chạy trên gpu colab thì thời_gian phản_hồi của nó cũng khoảng 10s với model khoảng 7b có cách nào để tối_ưu không và có nên để nó chạy chỉ với cpu không kiểu như lúc mình triển_khai ấy thì gpu không phải lúc_nào cũng sẵn có các anh có_thể cho em một_số gợi_ý để em sử lý các vấn_đề này không nếu được thì các anh cho em xin <number> số tên model hoặc tài_liệu để em tham_khảo với em cảm_ơn,"['#Q&A', '#nlp', '#deep_learning']"
chào mọi người em là newbie em muốn thử <number> mô_hình llm kết_hợp với rag langchain thì nên thử đâu nếu thử local thì máy lag còn thử gg colab thì sau <number> time nó lại reset bắt mình chạy lại toàn_bộ lệnh,"['#Q&A', '#nlp']"
openai giới_thiệu mô_hình gpt4 turbo,['#sharing']
chào mọi người nhóm chúng em đang làm một project về hỏi_đáp tài_liệu theo mô_hình rag sử_dụng llm chatgpt tài_liệu của chúng em đang viết tiếng việt tiếng anh và tiếng nhật em đang muốn tìm một model encoder tối_ưu được cho <number> thứ tiếng trên mọi người ai có kinh_nghiệm có_thể gợi_ý giúp em một_số model với em cảm_ơn mn,"['#Q&A', '#nlp']"
xin chào mọi người em có đang tranh_luận với giảng_viên về <number> việc như sau mong được mọi người góp_ý <number> khi dạy thuật_toán nbc cô em dạy <number> dạng là nbc thông_thường và nbc cô tạm gọi là cải tiển với nbc thông_thường thì tính theo công_thức bayes mở_rộng tức không coi các biến là độc_lập với nhau còn với nbc cải_tiến thì mới coi các biến là độc_lập với nhau quan_điểm của em là chữ naïve trong thuật_toán nbc đã chỉ ra ý_tưởng ngây_thơ của bài_toán là coi các biến độc_lập với nhau chỉ tồn_tại cái nbc mà cô em đang gọi là nbc mở_rộng <number> cô em dạy maximum likelihood và maximum posteriori là thuật_toán_học máy tương_đương như id3 kmeans knn svm linear regression cô đưa ra bằng_chứng là trong giáo_trình học máy do thầy hoàng xuân huấn trường đại_học quốc_gia hà_nội có viết mục 5.2.1 các quy_tắc phân lớp ml và map mà phân lớp thì là thuộc bài_toán classify trong học máy em cho rằng ml map chỉ là phương_thức hỗ_trợ cho thuật_toán_học máy ví_dụ như dùng ml trong thuật_toán logistic regression note em sẽ bổ_sung thêm một_số dẫn_chứng cho quan_điểm của cô và em dưới phần bình_luận vì học khoa điện_tử đến kì này mới học_phần_mềm nên kiến_thức của em có_thể sai_sót nhiều xong em không_thể khiên_cưỡng làm theo điều mình thấy không thuyết_phục mong được mọi người khai_thông nếu ai có gmail của giảng_viên dạy môn này thì cho em xin nhé,"['#Q&A', '#machine_learning', '#math']"
mn đã ai convert model detectron2 sang onnx chưa,"['#Q&A', '#cv']"
chào mọi người tình_hình là em có một đề_tài đang làm với mục_đích là phát_triển một mô_hình tính_toán để chuyển_đổi tín_hiệu nhịp sinh_học của cơ_thể từ cảm_biến_áp_suất điện thành sóng mạch_máu các phương_pháp tính_toán truyền_thống đã được thử_nghiệm nhưng chưa đạt được độ chính_xác mong_muốn để giải_quyết vấn_đề này nghiên_cứu yêu_cầu việc phải đo_đạc cùng lúc dữ_liệu giáo_viên và dữ_liệu từ cảm_biến_áp_suất điện trong năm nay em đã tạo một thiết_bị đo mới đã được phát_triển để giảm sai_số và từ đó phát_triển mô_hình tính_toán chính_xác hơn anh_chị cho em gợi_ý về cách xây_dụng mô_hình tính_toán chính_xác hơn được không có_thể gợi_ý cho em nguồn vài tài_liệu để tìm_hiểu thêm về mô_hình thích_hợp được không mình sử_dụng mô_hình ml để giải_quyết vì mục_đích là làm cho data thu được từ cảm_biến_áp_suất điện kết_hợp với data về nhịp sinh_học mẩu để tạo ra chuỗi data thời_gian mới có tính_chất gần giống với nhịp sinh_học thực_tế mình có biết về ml nhưng với mình chưa đủ để hiểu rõ vấn_đề cần giải_quyết lúc đầu mình sử_dụng phương_pháp ml như mạng neural networks và mô_hình hidden markov để giải_quyết bài_toán timeseries generation nhưng kết_quả không đẹp như mình nghĩ,"['#Q&A', '#deep_learning']"
hỏi cách lấy data ảnh ... từ vệ_tinh cần góp_ý về việc download dữ_liệu từ các vệ_tinh đợt vừa_rồi mình có thử download dữ_liệu vệ_tinh sentinel2 cụ_thể là multispectrum data nhưng mình vẫn chưa down được có bạn nào đã có kinh_nghiệm làm_việc với ảnh vệ_tinh có_thể chia sẽ cách các bạn down và vài chia sẽ về việc xử_lý ảnh kích_thước lớn như ảnh vệ_tinh không cám_ơn,"['#Q&A', '#data']"
cực_đại của the log posterior chào mọi người em đang vướng <number> chổ mà suy_nghĩ mãi không ra làm cách nào để khai_triển công_thức bên dưới nhỉ <number> mũi_tên màu đỏ trên hình,"['#Q&A', '#math']"
hi all có bạn nào đang học năm cuối kĩ_sư hay master về computer vision hay graphic hoặc ngành liên_quan có mong_muốn học tiếp phd và bắt_đầu bằng việc đi thực_tập tại pháp và úc không nếu có hãy liên_lạc với mình asap nhé,['#Q&A']
webinar chủ_đề ứng_dụng phân_tích định_lượng cho trading các tư_duy trong xây_dựng và kiểm_thử chiến_thuật đầu_tư tự_động icls tech kính mời cộng_đồng trading những người_yêu thích và quan_tâm đến trading đăng_ký tham_gia buổi chia_sẻ về ứng_dụng phân_tích định_lượng cho trading thời_gian bắt_đầu 20h00 thứ ba ngày <number> <number> <number> hình_thức tham_dự tham_dự qua zoom bằng đường link hoặc quét mã qr trong hình phân_tích định_lượng trong đầu_tư quantitative trading là một phương_pháp lượng_hóa các thông_tin thành số_liệu cụ_thể giúp nhà đầu_tư loại_bỏ được yếu_tố cảm_xúc trước khi ra quyết_định dựa trên các công_thức mô_hình toán_học và các công_cụ trí_tuệ nhân_tạo giúp cải_thiện kết_quả đáng_kể cho nhà đầu_tư với sự chia_sẻ của <number> vị khách mời anh nguyễn văn thành research consultant tại tập_đoàn tài_chính định_lượng worldquant từng làm software engineer tại samsung hơn <number> năm kinh_nghiệm làm_việc trong lĩnh_vực khoa_học dữ_liệu xử_lý dữ_liệu tài_chính crypto currency anh ngô phi hùng tech lead tại hephatus technology từng làm data engineer tại fpt telecom hãy tham_gia ngay để tiếp_cận và học_hỏi về một phương_pháp đầu_tư hiệu_quả có cơ_hội được tham_gia vào cộng_đồng icls tech để được hỗ_trợ và tư_vấn từ các chuyên_gia contact <number> contact@iclstech.com,['#sharing']
mình đang lead một_số dự_án tự_động_hoá ứng_dụng ai ml trong thiết_kế triển_khai và tối_ưu hệ_thống mạng di_động 5g hợp_tác với nhà mạng lớn tg các bạn quan_tâm tới lĩnh_vực ai ml trong viễn_thông có_thể kết_nối giao_lưu và tham_gia dự_án bên mình partime hay fulltime đều ok ảnh có tính minh_họa tự_động dự_báo lưu_lượng và tối_ưu <number> trạm 5g toàn thời_gian,['#Q&A']
denoise diffusion probabilistic models thetalog nhật_ký theta,['#sharing']
webinar chủ_đề ứng_dụng phân_tích định_lượng cho trading các tư_duy trong xây_dựng và kiểm_thử chiến_thuật đầu_tư tự_động icls tech kính mời cộng_đồng trading những người_yêu thích và quan_tâm đến trading đăng_ký tham_gia buổi chia_sẻ về ứng_dụng phân_tích định_lượng cho trading thời_gian bắt_đầu 20h00 thứ ba ngày <number> <number> <number> hình_thức tham_dự tham_dự qua zoom bằng đường link hoặc quét mã qr trong hình phân_tích định_lượng trong đầu_tư quantitative trading là một phương_pháp lượng_hóa các thông_tin thành số_liệu cụ_thể giúp nhà đầu_tư loại_bỏ được yếu_tố cảm_xúc trước khi ra quyết_định dựa trên các công_thức mô_hình toán_học và các công_cụ trí_tuệ nhân_tạo giúp cải_thiện kết_quả đáng_kể cho nhà đầu_tư với sự chia_sẻ của <number> vị khách mời anh nguyễn văn thành research consultant tại tập_đoàn tài_chính định_lượng worldquant từng làm software engineer tại samsung hơn <number> năm kinh_nghiệm làm_việc trong lĩnh_vực khoa_học dữ_liệu xử_lý dữ_liệu tài_chính crypto currency anh ngô phi hùng tech lead tại hephatus technology từng làm data engineer tại fpt telecom hãy tham_gia ngay để tiếp_cận và học_hỏi về một phương_pháp đầu_tư hiệu_quả có cơ_hội được tham_gia vào cộng_đồng icls tech để được hỗ_trợ và tư_vấn từ các chuyên_gia contact <number> contact@iclstech.com,['#sharing']
từ <number> bức ảnh nhiễu có_thể tạo nên <number> bức ảnh chất_lượng cao_cấp nhờ công_nghệ instaflow mời mọi người cùng tìm_hiểu thêm về mô_hình ma_thuật được phát_triển từ stable diffusion này tại bài viết bởi data scientist của pixta vietnam nhé,"['#sharing', '#cv']"
có một bạn hôm trước dm mình hỏi về hai cuốn thực_hành học máy nay mình tìm lại không thấy tin nhắn nên post lại lên group,"['#sharing', '#machine_learning']"
chào mọi người qua bài post này mình muốn tìm người để cùng nhau học về ai data mình có_thể cùng nhau thảo_luận về một chủ_đề nào đấy trong lĩnh_vực này cũng có_thể nếu người này vừa học được cái gì mới thì có_thể giảng_giải cho người kia người_ta nói rằng bạn chỉ thật_sự hiểu một vấn_đề khi mà bạn có_thể giải_thích cho người khác cùng hiểu về vấn_đề đó các chủ_đề này cũng có_thể chỉ là những vấn_đề cơ_bản của ai data thôi một điều quan_trọng là mình muốn các buổi thảo_luận đều hoàn_toàn bằng tiếng anh thật_ra mục_đích chính của những buổi này là mình muốn nâng cao kĩ_năng thuyết_trình thảo_luận và để ôn lại những kiến_thức đã học được thôi về mình thì mình có kiến_thức về ai data mức tạm ổn tiếng anh tốt vì_vậy nếu có bạn nào cũng chung chí_hướng thì inbox mình nhé cảm_ơn mọi người,['#Q&A']
em chào mọi người hiện_tại em đang có thực_hiện project build knowledge graph cho văn_bản tiếng việt định_hướng phương_pháp em làm như sau dùng underthesea để setence segmentation để tách nhỏ văn_bản thành từng câu dùng named entity regconition ner dependency parsing dep để phân_tích thành_phần trong câu tạm_thời sẽ dùng vncorenlp để extract thử_nghiệm tính hiệu_quả nếu tốt có_thể train lại từ ner dep đã extract sẽ tìm ra_bộ <number> entity <number> relation entity <number> trong câu để tạo thành <number> liên_kết trong graph với các node là entity vd tổng_thống mỹ là joe biden thì khi dùng ner dep thì sẽ cho ra kết_quả entity <number> tổng_thống_mỹ relation là entity <number> joe_biden các khó_khăn hiện_tại vd với <number> câu phức_tạp hơn như sau tổng_thống mỹ là joe biden ông còn biết tới là chính_trị_gia thì trong <number> câu xuất_hiện tới <number> bộ e1 e2 tổng_thống mỹ là joe biden ông là chính_trị_gia nhưng từ ông thì quá chung_chung khi đó vào graph thì từ ông sẽ được liên_kết với nhiều thành_phần ko mong_muốn ko thể_hiện được ông joe biden trong liên_kết thì expect em nó sẽ là tổng_thống mỹ là joe biden joe bide là chính_trị_gia mọi người có giải_pháp nào hoặc phương_pháp nào giúp em tiếp_cận bài_toán không em xin cảm_ơn mọi người đã đọc,"['#Q&A', '#nlp']"
chào mọi người em đang tìm_kiếm công_việc thực_tập mảng computer vision và đang chuẩn_bị cv đây là cv của em các anh_chị kinh_nghiệm có_thể giúp em chỉnh_sửa lại cv cũng như đưa ra lời khuyên giúp em nên học thêm và chuyên_sâu vào mảng nào được không ps em đang là sinh_viên năm <number> các link github em không đính kèm trong file nếu anh_chị muốn xem thêm thì em gửi riêng,['#Q&A']
"webinar hướng_dẫn tạo nội_dung với chatgpt tối thứ ba <number> <number> tới đây funix tổ_chức webinar online nextlevel ai content hướng_dẫn tạo nội_dung với chatgpt diễn giả trung caha cofounder antory admin blog khoahocmidjourney com sẽ chia_sẻ kinh_nghiệm về cách sử_dụng các kỹ_thuật đột_phá với chatgpt đến với webinar bạn sẽ biết tạo nội_dung có chất_lượng cao cuốn_hút từ chatgpt mà không phải câu trả_lời chung_chung hay giống với tìm_kiếm google viết câu_lệnh với chat gpt mà 99,99999 thế_giới ngoài kia chưa biết đến <number> yếu_tố để tạo nội_dung chuyên_sâu chất_lượng cho bất_cứ lĩnh_vực nào bạn muốn đạt được lợi_thế cạnh_tranh vượt_trội ngay cả so với những người khác sử_dụng ai khác nhanh tay đăng_ký tại thời_gian <number> <number> <number> <number> thứ <number> ngày <number> <number> <number>",['#sharing']
các bạn vui_lòng đăng tin tuyển_sinh tuyển_dụng sự_kiện tháng <number> <number> vào comment của post này,['#sharing']
ai share statistics đa_số các thuật_toán của machine learning đều dựa trên nền của xác_suất và thống_kê đối_với nhiều người xác_suất thống_kê là một môn khó và có nhiều kiến_thức cần phải nắm ngoài việc đọc sách để nắm vững các khái_niệm và ứng_dụng ai4e muốn chia_sẻ <number> cheatsheet tổng_hợp các kiến_thức xác_suất một_cách ngắn_gọn và tổng_quát nhất cheatsheet này bao_phủ toàn_bộ các kiến_thức cốt_lõi nhất trong xác_suất tài_liệu có giá_trị và đáng tin_cậy bởi người viết dựa trên_tài_liệu khóa học xác_suất của harvards,"['#sharing', '#math']"
chào các anh_chị em muốn mua máy bàn phục_vụ_việc nghiên_cứu và chạy các mô_hình_học máy anh_chị nào có_thể gợi_ý giúp em máy có cấu_hình phù_hợp được không em chân_thành cám_ơn,['#Q&A']
scikit learn báo multicolinearity ace cho hỏi đang dùng scikit learn chạy ols check vif toàn nhỏ hơn <number> sao cứ bị báo multicolinearity vậy ai biết scikit learn tính cái này thế_nào chỉ với tks mn,"['#Q&A', '#python']"
nắm vững các giai_đoạn phát_triển của ứng_dụng với container,['#sharing']
em chào các anh_chị mọi người cho hỏi là để vẽ hình này cần dùng tool gì cảm_ơn mng,['#Q&A']
em đang học về lắng_nghe mạng xã_hội trong bài yêu_cầu phân_tích chủ_đề và sắc_thái của doanh_nghiệp dựa vào quy_tắc sắc_thái và quy_tắc chủ_đề nhưng em dựa vào đó vẫn làm sai anh_chị chia_sẻ cho em ít kinh_nghiệm để làm đúng với em cảm_ơn,['#Q&A']
em xin chào mọi người hiện_tại em đang thực_hiện một bài_toán như sau từ câu ngôn_ngữ sinh ra query vd như bài_toán text2sql từ query chart rồi từ chart comment hoặc description về chart vì kiến_thức của về nlp còn khá hạn_chế nên em chưa có kinh_nghiệm nhiều trong các bài_toán như này nên em xin mọi người tư_vấn giúp em một_số vấn_đề như sau cách tiếp_cận bài_toán như thế_nào dữ_liệu train sẽ được xây_dựng đánh label như thế_nào để xây_dựng được bài_toán em nên học và sử_dụng công_cụ nào em xin các keyword về bất_cứ cứ thứ gì có_thể coi là hữu_ích cho bài_toán trên link model framework document ... em xin cảm_ơn các tư_vấn,"['#Q&A', '#nlp']"
chào các bác cuối tuần tranh_thủ thấy có github hày về món text to speech em xin mạnh_dạn chia_sẻ cùng các bạn mới học bark một món chuyển text to speech chạy offline giọng tự_nhiên hơn cả google anh_em nào cần làm món này cứ thế_mà xài tự_nhiên tiếc là chưa có code training,['#sharing']
em chào mn đang tìm_hiểu về miccro segmentation mà thấy ít tài_liệu viết về cái này nên chưa hiểu rõ không biết mn ai đã từng làm về phân khúc vi_mô khách_hàng cho tham_khảo với được không em cảm_ơn mn nhiều,['#Q&A']
mn cho hỏi câu liên_quan đến sql với em dùng bulk insert để nhập data từ file txt nhưng có <number> số bản ghi bị lỗi ví_dụ như name id manh thang dấu tab <number> nhưng khi import thì dấu bị nhảy sang phần id lý_do là vì dấu tab do đó các hàng tiếp cũng bị nhảy theo ai đã xử_lý trường_hợp như_vậy cho xin cách fix với em cảm_ơn,['#Q&A']
mọi người cho hỏi là sau khi tìm được tất_cả các tập phổ_biến tìm luật kết_hợp nhưng mà ko chắc cách làm của đã đúng chưa vd trong tập phổ_biến abde ta loại_bỏ thì có luật bde conf <number> <number> <number> đây là luật kết_hợp link chi_tiết bài_làm để trong google docs mn có_thể xem qua và cho ý_kiến được không sau khi tìm được các luật phổ_biến thì có cần loại_bỏ trùng_lặp không em cảm_ơn,['#Q&A']
cho mình hỏi có ai hiểu cách diễn_giải của tác_giả để đi đến kết_luận epsilon dòng cuối ko_vậy tên sách foundation of machine learning mit press sách có bản free online,"['#Q&A', '#machine_learning']"
em xin chào mọi người hiện_tại em đang thực_hiện một đề_tài như sau xây_dựng chatbot trả_lời các câu hỏi liên_quan đến lĩnh_vực luật ví_dụ khi đặt câu hỏi chạy xe_máy vượt đèn_đỏ sẽ bị phạt bao_nhiêu tiền thì chatbot sẽ trả_lời câu hỏi đó đồng_thời có_thể đưa ra trích_dẫn trong văn_bản luật em đã có bộ dữ_liệu về các văn_bản luật khá đầy_đủ bao_gồm cả các thuộc_tính về hiệu_lực lĩnh_vực ... với bộ câu hỏi câu trả_lời em cũng đã thu_thập được lượng dữ_liệu đủ lớn 100k để sẵn_sàng traning vì kiến_thức về ai của em khá hạn_chế mới bắt_đầu tìm_hiểu nên xin được tham_khảo ý_kiến về các vấn_đề sau em có nhận được lời khuyên là sử_dụng nlp ml để xử_lý câu hỏi đầu_vào theo các từ đồng_nghĩa và xây_dựng mạng ontology để ánh xạ câu hỏi người dùng và tiến_hành trả_lời em xin hỏi liệu đây có phải là một_cách tối_ưu cho bài_toán trên không nếu có cách khác thì em xin nghe đề_xuất để xây_dựng được chatbot theo yêu_cầu đề_bài em nên học và sử_dụng công_cụ nào em xin các keyword về bất_cứ cứ thứ gì có_thể coi là hữu_ích cho bài_toán trên link model framework document ... em xin cảm_ơn các tư_vấn <number>,"['#Q&A', '#nlp']"
em đang làm về summarize sử_dụng model longt5 em đang muốn thêm <number> block reattention vào sau block selfattention đầu_tiên của phần encoder mà đang gặp lỗi reattentionblock forward got an unexpected keyword argument attention_mask ai có hướng solve giúp em với em cảm_ơn,['#Q&A']
hỏi_đáp âm_thanh em xin chào mọi người hiện_tại em đang làm đồ_án về đề_tài xác_định động_cơ bị lỗi bằng âm_thanh vì động_cơ lỗi khá ít nên tập dữ_liệu của em chỉ đa_số là âm_thanh về động_cơ bình_thường dài khoảng <number> giây cho_nên em hiện_tại đang giải_quyết bài_toán theo hướng anomaly detection với <number> cách như sau cách <number> em trích xuất đặc_trưng mfcc và sử_dụng mô_hình lstmautoencode để phân_biệt normal abnormal dựa trên loss của predict với input cách <number> em lấy hình_ảnh logmelspectrogram và sử_dụng mô_hình cnnautoencode cũng để phân_biệt normal và abnormal dựa trên loss với đầu_vào nhưng kết_quả trên tập test của <number> cách này bị sai rất nhiều và em nghĩ nguyên_nhân là do em trích xuất đặc_trưng chưa phù_hợp cho_nên sau khi tham_khảo các paper thì em trích xuất những đặc_trưng sau chorma energy spectral rolloff zero crossing mfcc đối_với mỗi loại đặc_trưng thì em lấy mean và var thì được <number> chiều cho mỗi file âm_thanh sau đó sử_dụng mô_hình oneclasssvm để phân_loại thì thấy kết_quả có vẻ khả_quan hơn được tý nhưng vẫn loại sai khá nhiều em muốn hỏi là đối_với âm_thanh về tiếng ồn của động_cơ như này thì mình nên sử_dụng đặc_trưng nào của âm_thanh và sử_dụng mô_hình gì ml dl gì để có_thể phân_biệt được vậy dưới đây là dữ_liệu âm_thanh của em,['#Q&A']
em xin chào mọi người hiện em đang thử chạy code có sử_dụng gpu vga gigabyte geforce rtx <number> gaming oc 12g rev <number> gvn3060gaming oc12gd trên hệ điều_hành ubuntu <number> tuy_nhiên khi em cài cuda thì hiện lên thông_báo không tương_thích mọi người có_thể giợi cho em bản cuda nào tương_thích với máy với em xin cảm_ơn mọi người bản mà em thử tải lỗi mà máy em hiện lên,"['#Q&A', '#python']"
em chào mọi người em đang học môn_học máy và hiện_tại em đang có mấy bài_tập như hình dưới đây em đang cố_gắng tìm_hiểu hướng giải cũng như cách trình_bày sao cho chính_xác và đầy_đủ nhưng hiện_tại em vẫn chưa nghĩ được cách giải_quyết nếu ai có cách hay hướng giải bài nào thì cho em xin với em cảm_ơn,"['#Q&A', '#machine_learning']"
các bạn vui_lòng post thông_tin tuyển_dụng sự_kiện tháng <number> <number> vào phần comment của post này,['#sharing']
em chào mọi người em có thắc_mắc là liệu nlp có phải là subset của ml kh mng tại theo em tìm_hiểu thì nlp giúp máy_tính có_thể hiểu xử_lý dc natural language nhưng mà để đạt dc quá_trình đó như sdung pos có_thể giúp nhận_định dc từ_loại của của <number> từ như noun verb ... thì phải dùng ml để label hay sao em cảm_ơn mng,"['#Q&A', '#nlp']"
xin chào cả nhà team vilm đã chính_thức trở_lại với một model mới_toanh obsidian3b multimodal for everyone được xây_dựng trên mô_hình nouscapyabra3b dựa trên stablelm3b4e1t obsidian3b là kết_quả của sự kết_hợp giữa nous research mỹ và vilm với mục_tiêu đưa multimodal đến với tất_cả mọi người mô_hình có_thể chạy trên bất_kì gpu nào có vram 8gb trở lên về kết_quả benchmark obsidian3b đánh_bại hoặc ngang_hàng llava <number> 7b của nhà microsoft với điểm số ấn_tượng trên các bài benchmark về vision language ngoài_ra team đã chính_thức ra_mặt discord server để khởi_động các dự_án tiếp_theo với cộng_đồng đặc_biệt là phiên_bản vietcuna và multimodal thế_hệ tiếp_theo mong mọi người sẽ tham_gia và xây_dựng một cộng_đồng ai opensource lớn_mạnh của người việt discord model link inference code chúc mọi người một buổi tối vui_vẻ,['#sharing']
meta facebook research gần đây công_bố cookbook cho việc train và finetune các biến_thể dựa trên mô_hình llama tại đây code base tại đây hi_vọng nó sẽ giúp_ích mọi người trong công_việc,"['#sharing', '#nlp']"
xin chào mọi người em đang tập dùng thử mechine learning studio của azure đến công_đoạn tạo real time endpoints để dùng model từ api hệ_thống đều báo chạy ổn tuy_nhiên mục test thử thì toàn báo lỗi an unexpected error occurred in scoring script check the logs for more info mn ai đã fix được lỗi này giúp mình với,['#Q&A']
bà_con thử sft con này xem có ổn không nếu ổn thì để nhóm train tiếp vài trăm gb bà_con thử nốt,['#sharing']
em chào mọi người có ai gần đây train paddleocr không cho em hỏi một_chút chứ em cả ngày hôm_qua với nay bất_lực quá chuyện là em có cài paddlepaddlegpu bản 2.5.1 cho cuda <number> cuda trên máy cũng đã cài <number> chạy paddle đã ổn nhưng không làm_sao train được nó cứ vào load train như ảnh là lại không chạy tiếp nữa em đã thử <number> bản python <number> và <number> nhưng đều như nhau em cũng đã giảm batchsize xuống từ <number> xuống <number> <number> rồi nhưng bị lỗi này hiện lên fomat data thì chắc không vấn_đề vì em đã load và train đc trên colab paddle cũng đã cài ổn như trên hình em cảm_ơn vì đã đọc,['#Q&A']
em chào cả nhà mấy thời_gian qua em có tự build một cái app cho phép người dùng thêm sản_phẩm và tracking ngày hết hạn của sản_phẩm đó đơn_giản thì nó giống một cái todoslist mà dành cho mấy đồ thực_phẩm ấy điểm nhấn đây là em có sử_dụng mô_hình để nhận_diện thực_phẩm và đề_xuất ngày hết hạn tương_ứng app hiện_tại đã lên ios và android mong mọi người có_thể tải về trải nghiệm thử và feedback đánh_giá độ hiệu_quả của model và ai có đóng_góp để cải_thiện app nói_chung thì càng tuyệt_vời nữa chúc cả nhà cuối tuần vui_vẻ,['#sharing']
trong một bài viết nào đó của một bạn về điền giá_trị bị thiếu và tuyệt_đối không được điền giá_trị mean hoặc zero và nhân_tiện trong quá_trình tìm tài_liệu để viết khóa học mình có tìm được cuốn sách này về xử_lý dữ_liệu bị thiếu mình chia_sẻ địa_chỉ cuốn sách này cho các bạn tìm_hiểu thêm và sau khi đọc xong các bạn có_thể rút ra được có nên điền mean vào hay không,"['#sharing', '#data']"
các anh chị bạn đã có ai làm về tra_cứu ảnh tương_tự dựa trên nội_dung sử_dụng mô_hình cnn chưa có_thể cho em xin một_số nguồn tham_khảo được không xin chân_thành cảm_ơn mn,"['#Q&A', '#deep_learning']"
dạ em chào mọi người em đang làm nghiên_cứu về chủ_đề 3d reconstruction và có gặp thuật_ngữ uv mapping theo những gì em tìm_hiểu thì có_thể hiểu uv map là hình_ảnh được đập dẹp của một mô_hình 3d cụ_thể là gương_mặt nếu trong 3d space mỗi đỉnh trên 3d mesh có toạ_độ là thì trong không_gian uv 2d thì đỉnh đó có toạ_độ là tuy_nhiên em vẫn cảm_thấy rất mơ_hồ về nó như là làm_sao để visualize nó như là một hình_ảnh 2d hay_là về mặt toán_học thì nó có_thể được biễu diễn như thế_nào ví_dụ với hình_ảnh màu 2d thì nó là một tensor width height <number> color channels do đó em mạn_phép lên đây để nhờ các anh_chị thầy cô trong group giúp em giải_đáp vấn_đề này em xin chân_thành cảm_ơn,"['#Q&A', '#cv']"
mình thấy có tutorials thú_vị đặc_biệt là cho những bạn quan_tâm tới geostats của <number> giáo_sư đại_học texas at autin nên chia_sẻ đây cho những bạn cần tìm_hiểu,['#sharing']
các bạn vui_lòng đăng tin tuyển_sinh tuyển_dụng sự_kiện tháng <number> <number> vào comment của post này,['#sharing']
em chào mọi người cho em hỏi có cách nào dựng 3d từ ảnh độ sâu kết_hợp ảnh 2d không ảnh độ sâu và 2d em lấy từ đầu_ra của camera intel d415 mọi người có_thể cho em xin tài_liệu hoặc nguồn thông_tin nào liên_quan cũng được em cảm_ơn nhiều,"['#Q&A', '#cv']"
cao nhân nào từng làm qua mô_hình nhận_diện bệnh cho lá cây cho em xin dataset với em cảm_ơn,"['#Q&A', '#data']"
english caption below urallama mô_hình ngôn_ngữ lớn cho tiếng việt xin chào mọi người chúng_tôi nhóm nghiên_cứu với các thành_viên đến từ_trường đại_học bách_khoa đhqg tp hcm và đại_học stanford xin trân_trọng giới_thiệu đến cộng_đồng các mô_hình ngôn_ngữ lớn chúng_tôi đã phát_triển chúng_tôi gọi chúng với cái tên thân_thuộc urallama mô_hình này được chúng_tôi finetune trên dữ_liệu tiếng việt từ mô_hình gốc llama2 của meta với cả <number> phiên_bản 7b 13b và 70b chúng_tôi cung_cấp miễn_phí các mô_hình này cho mục_đích nghiên_cứu mô_hình của chúng_tôi đi kèm với các kết_quả đánh_giá trên <number> tasks khác nhau nhiều khía_cạnh và tình_huống sử_dụng trong thực_tế bạn có_thể tìm thấy thông_tin về mô_hình của chúng_tôi tại các đường link bên dưới urallama 7b urallama 13b urallama 70b giấy_phép và thỏa_thuận sử_dụng playground cho urallama 7b kết_quả đánh_giá của urallama đang cập_nhật nếu bạn muốn đóng_góp để phát_triển các mô_hình ngôn_ngữ lớn cho tiếng việt xin đừng ngần_ngại hãy liên_hệ với chúng_tôi theo các thông_tin bên dưới về nhóm nghiên_cứu website email qttho dot hcmut dot edu dot vn về giấy_phép cho các mô_hình nqduc at hcmut dot edu dot vn cc sttruong at cs dot stanford dot edu qttho at hcmut dot edu dot vn xin cảm_ơn mọi người 10h10 thứ ba ngày <number> tháng <number> năm <number> nhóm nghiên_cứu urallama large language models for vietnamese hello everyone as research team formed from members in ho chi minh city university of technology hcmut vnuhcm and stanford university we are pleased to introduce our large language models to the community we affectionately refer to those language models as urallama they are finetuned on vietnamese datasets from meta original llama2 model including all three versions of 7b 13b and 70b we provide these models free of charge for research purposes our models come with evaluation results on <number> different tasks covering various aspects and realworld usage scenarios you can find information about our models at the following links urallama 7b urallama 13b urallama 70b license and user agreement playground for urallama 7b urallama evaluation results actively updating if you want to contribute to the development of large language models for vietnamese please do not hesitate to contact us using the information below about the research group website email qttho dot hcmut dot edu dot vn about the model licenses nqduc at hcmut dot edu dot vn cc sttruong at cs dot stanford dot edu qttho at hcmut dot edu dot vn thank you all <number> <number> am tuesday october <number> <number> research team,"['#sharing', '#nlp']"
chào mọi người em đang tìm_hiểu về llms và cụ_thể là openai api em có <number> số thắc_mắc mong mọi người giải_đáp những model dalle và whisper có thực_sự là large language models không tại bữa em có đọc lướt qua <number> khi dùng openai thì em thấy có <number> phương_thức khá tương_tự là completion và chatcompletion trong khi chatcompletion có_thể gửi lịch_sử hội_thoại thì không biết completion có ưu_điểm gì mà vẫn được giữ lại cách tính phí ví_dụ babbage002 <number> 1k tokens thì là token vào hay token ra hay tổng_ạ khi fineturning sử_dụng model đó thì tính phí sử_dụng có thêm phí model gốc không hay chỉ tính phí sử_dụng và tính phí đầu_vào hay đầu_ra hay cả <number> có trang này tổng_hợp đầy_đủ model và phí hiện đang có hơn trang không giới_hạn giới_hạn trang max tokens là token nhập vào phải không nếu vậy có limit cho token trả về không giới_hạn gửi request trong khoảng thời_gian liệu có cách nào để xin tăng giới_hạn cho tài_khoản miễn_phí không vì gửi theo biểu_mẫu dành cho tài_khoản trả phí ngoài_ra không biết có chính_sách hoặc trick nào cho sinh_viên để có_thể trải nghiệm các tính_năng paid plan ví_dụ như finetuning của openai api không,"['#Q&A', '#nlp']"
chào mọi người mình đang cần nộp <number> bài_tập lớn về đề_tài machinelearning bất_cứ thứ gì cũng được vậy bạn nào có_thể chia_sẻ cho mình <number> đề_tài nào đó cơ_bản nhất có_thể có sẵn cả báo_cáo và source code với không mình xin cảm_ơn và hậu_tạ,['#Q&A']
mọi người ai làm về trích xuất thông_tin trên căn_cước công có chip chưa cho hỏi cái này với,"['#Q&A', '#cv']"
như thread cách đây chưa lâu tại đây rằng mojo có_thể sẽ có chỗ_đứng của riêng nó trong thời_đại ứng_dụng ai trên các nền_tảng tính_toán hiệu_năng cao nay mojo mới cho cài native trên mac chip hướng_dẫn cài_đặt tại đây mình có test nhanh trên máy mac m1 của mình với llama2 train với tinystory từ karpathy và tinyllama2 từ dưới đây là bản tóm_tắt kết_quả so_sánh inference speed giữa mojo và cơ_bản là không tệ và tốt hơn kết_quả trước đó mình test trên server linux xem comments thread trước đây dường dẫn trên mình sẽ test thêm kĩ hơn trong những ngày tới rồi chia_sẻ với các bạn sau source code cho llama2 mojo tại đây và tổng_hợp các source code thư_viện thú_vị viết cho mojo tại đây,['#sharing']
xin chào tất_cả anh_chị em là sv năm nhât và sắp tới em phải bảo_vệ đồ_án ý_tưởng sản_phẩm cntt ý_tưởng khá hay có ứng_dụng ai các kiểu cụ_thể <number> app tích_hợp ai gợi_ý thực_đơn cho người dùng dựa trên những dữ_liệu của họ bao_gồm dữ_liệu cố_định và dữ_liệu được ghi lại theo thời_gian thực bằng thiết_bị theo_dõi sk và ai đã được huấn_luyện để tìm ra những món ăn có thực_phẩm gia_vị phù_hợp dinh_dưỡng thậm_chí khẩu_vị với người dùng rồi đưa ra gợi_ý để họ chọn và đăt hàng dưới hình là liệt_kê các tiêu_chí từ tiêu_chí ấy anh_chị có_thể tư_vấn sâu thêm chút về kĩ_thuật huấn_luyện cho con ai này công_đoạn chiến_lược phân_tích chọn các thuật_toán mô_hình_hóa dữ_liệu ... vì em chỉ biết chút bề nổi về tiềm_năng ứng_dụng của ai thôi nên em cần anh_chị tư_vấn giúp em để đào_sâu hơn chút về kĩ_thuật nha chiyyso06 <number>,['#Q&A']
mn cho em hỏi điểm giống và khác nhau so_sánh của decision tree knn naive bayes linear regression với,"['#Q&A', '#machine_learning']"
hello mọi người hiện_tại có kiến_thức cơ_bản về data science và stats probability trước em dùng để làm <number> số project và học qua cuốn islr và hiện_tại đang bắt_đầu học python google mới released khoá học về advanced data analytics chỉ biết khác với khoá trước là thay_vì dùng thì khoá này dùng python nào đã học qua hoặc biết về khoá học này cho xin reviews với thank you,['#Q&A']
góc tư_vấn anh_chị_em nào đã và đang học master đh bách_khoa ngành data science rồi cho em xin review với em phân_vân học bk hoặc học từ xa <number> số trường nc ngoài so_sánh học_phí chất_lượng giangr dạy bằng_cấp rất mong được các anh_chị đi trc có kinh_nghiệm chỉ dạy em cảm_ơn,['#Q&A']
chào các anh_chị trong học_kì tới em sẽ bắt_đầu học các môn chuyên_ngành ai và em đã học qua các khóa ml dl trên coursera và đã hiểu những concept toán_học cơ_bản về lĩnh_vực này em rất mong_muốn thực_tập sớm để tích_lũy các kinh_nghiệm thực_tế trong môi_trường doanh_nghiệp nhưng hiện_tại em thấy các công_việc này đang tuyển tphcm khá ít nên em hơi hoang_mang em muốn hỏi các anh chị_em nên trau_dồi thêm những gì để có đủ kỹ_năng để có được vị_trí thực_tập các vị_trí ai engineer hoặc data science rất mong nhận được sự góp_ý từ mọi người chúc mọi người một ngày vui_vẻ,['#Q&A']
xin chào các bác chả_là lâu_nay em có đọc tin bài về ai trên medium com nhưng dạo gần dây em vào rất khó quay đều đều mà không vào được em muốn xin hỏi các bác xem còn có trang nào tương_tự như trang này để vào đọc và cập_nhật các bài liên_quan đến ai không em cảm_ơn các bác nhiều,['#Q&A']
hiện_tại em đang làm <number> model image classfication về các loài côn_trùng nhưng gặp phải vấn_đề là khi em train <number> class thì bình_thường nhưng khi tăng lên <number> thì model giảm độ chính_xác và khi nhận_dạng thực_tế thì cũng giảm và score giảm còn rất thấp mặc_dù nhận_dạng vẫn có cái đúng em đoán là có_thể là do các class côn_trùng nhiều loài rất giống nhau thậm_chí giống_hệt nên ảnh_hưởng em cũng có suy_nghĩ là gom nhóm các loài giống nhau vào kiểu như sub class nhưng không biết như thế_nào em hi_vọng được nghe chia_sẻ của các anh_chị về cách giải_quyết vấn_đề này em cảm_ơn rất nhiều,"['#Q&A', '#cv']"
đã có người đầu_tiên port thư_viện rất hay và nổi_tiếng của karpathy có tên là llama sang mojo tại đây mojo đã tăng hiệu_suất của python lên gần <number> lần thật ấn_tượng với phiên_bản mojo giờ_đây vượt_trội hơn llama2 khoảng <number> một con_số cực_kì ấn_tượng trong thí_nghiệm ban_đầu này điều này cho thấy tiềm_năng của việc tối_ưu phần_cứng thông_qua các tính_năng nâng cao của mojo tôi nghĩ điều này bước_đầu cho ta thấy được ấn_tượng về hiệu_năng của mojo trên các mô_hình ngôn_ngữ lớn nơi đòi_hỏi tài_nguyên tính_toán rất lớn nên cải_thiện được về hiệu_năng cũng là rất đáng quí chúc các bạn có trải nghiệm vui_vẻ với những thứ mới_lạ ps khi tôi post bài trước đó về việc modular cho cài_đặt mojo trên local machines trước đó chỉ chạy online trên servers chủ của cty nhiều bạn tỏ nghi_ngờ tôi có nói hãy bình_tĩnh chờ_đợi và hãy thử trải nghiệm với mojo theo cách của bạn trước khi có những phát_biểu_cảm_tính tôi hiểu đây là một phần tính_cách của không ít người việt xin_lỗi phải nói ra việc đụng_chạm đáng buồn này rất lấy làm tiếc,['#sharing']
dopikai vừa công_bố bài tóm_tắt về vigpt mô_hình llm tiếng việt dựa trên instructionfintuning với các nguồn dữ_liệu tự thu_thập translate từ tiếng anh cũng như tự sinh với chatgpt mô_hình tập_trung vào tác vụ hỏi_đáp đánh_giá tính tự_nhiên và tính đúng_đắn câu trả_lời được sinh ra để đảm_bảo performance trên nhiều domain khác nhau nghiên_cứu của nhóm đã được accept tại emnlp <number> industry track đọc ngay bài tóm_tắt về vigpt tại đăng_ký tham_gia dopikai organization để thử_nghiệm các version của vigpt tham_gia ngay dopikai llm challenge để so_sánh kết_quả trên benchmark dataset với vigpt,"['#sharing', '#nlp']"
chào mọi người em đang tìm_hiểu về explainable ai thì có cái từ agnostic là em không hiểu lắm nếu dịch trực_tiếp ra thì là bất_khả_tri nhưng em thấy nó chưa thỏa_đáng mọi người có ai đã từng tìm_hiểu giải_nghĩa giúp em với,['#Q&A']
em chào mng mng có_thể chia_sẻ cho em lộ_trình để học xây_dựng <number> aichatbot có kèm theo khóa udemy càng tốt em cảm_ơn mng nhìu,"['#Q&A', '#nlp']"
xin được chia_sẻ với mọi người video giải_thích paper segment anything bằng tiếng việt rất mong nhận được góp_ý từ mọi người,"['#sharing', '#cv']"
em tạo một mạng neural <number> lớp ẩn với hàm kích_hoạt cho <number> lớp ẩn là relu và hàm đầu_ra là hàm dự_đoán sofmax em có test thử nhiều lần thì hầu_như hàm loss giảm rất nhanh nhưng một_số lần hàm loss không giảm em không biết là do em sai đâu hay_là do đặc_tính của hàm relu mà em cũng thử dùng hàm sigmoid làm hàm kích_hoạt tuy loss giảm lâu hơn nhưng em thấy nó ổn_định hơn hàm relu,"['#Q&A', '#deep_learning']"
trong bài viết này chúng_ta tìm_hiểu về một_số lĩnh_vực ứng_dụng chính và cách ai đang chuyển_đổi lĩnh_vực nghiên_cứu gen đã dẫn đến những đột_phá nhanh_chóng trong lĩnh_vực y_tế và khám_phá thuốc,['#sharing']
mời tham_gia kalapa bytebattles <number> hi mọi người mình là cương project manager tại kalapa một startup trong lĩnh_vực công_nghệ và trí_tuệ nhân_tạo tiếp nối thành_công của kalapa credit scoring challenge <number> với hơn <number> người tham_gia năm nay công_ty mình dưới sự bảo_trợ của hội tin_học việt_nam tiếp_tục tổ_chức một cuộc thi ai có tên gọi kalapa bytebattles cuộc thi năm nay gồm <number> bài_toán trong đó có một bài_toán chưa từng xuất_hiện các cuộc thi khác vietnamese medical multiplechoice question answering hứa_hẹn mang lại nhiều thử_thách hấp_dẫn và nhiều đóng_góp mới cho cộng_đồng làm ai việt_nam ngoài_ra bọn mình cũng sẽ tổ_chức trận chung_kết dưới hình_thức đối_kháng 1vs1 giữa model của các đội hy_vọng sẽ mang lại luồng gió mới giữa các cuộc thi được tổ_chức hiện_nay thông_tin về cuộc thi có tại với thu thuỷ và đan thy,['#sharing']
mn cho em tham_khảo ý_kiến về topic clustering text với định sử_dụng tfidf với clustering algorithm kmeans dbscan để làm case này nhưng data text nó khá ngắn <number> row trung_bình chỉ <number> <number> từ và viết sai chính_tả với viết không dấu cũng có nên mn có suggest cho việc preprocess đống này hong tính unidecode nó hết lun xong traceback lại cái ban_đầu mong nhận được góp_ý của mọi người cảm_ơn mn nhìu cx mới mò về nlp nên mn thông_cảm,"['#Q&A', '#nlp']"
các bạn vui_lòng đăng tin tuyển_sinh tuyển_dụng sự_kiện tháng <number> <number> vào comment của post này,['#sharing']
hi mọi người hiện_tại em đang làm project dự_đoán kết_quả thí_nghiệm vật_liệu xây_dựng bao_gồm nhiều models khác nhau nhằm đánh_giá nhiều khía_cạnh của thí_nghiệm em đang sử_dụng restapi để call artifact từ mlflow sau đó predict xuất ra kết_quả bên cạnh đó có chạy đồng_thời tính shap values để giải_thích model <number> em đang gặp vấn_đề trả kết_quả khá lâu vì input đầu vào_khoảng <number> data mất tầm <number> phút em muốn hỏi có cách nào tối_ưu để giúp mô_hình predict nhanh hơn không <number> theo em biết các model từ library sklearn không sử_dụng gpu nên kết_quả trả ra là tuần_tự liệu có cách nào chạy tất_cả kết_quả cùng <number> lúc em gửi cấu_hình hiện_tại của máy em em cảm_ơn,"['#Q&A', '#python']"
mọi người có ai làm về cái nhận_diện xem người tham_gia giao_thông có đội mũ bảo_hiểm rồi trích xuất biển số chưa nếu rồi thì có_thể cho xin link tham_khảo được không,"['#Q&A', '#cv']"
dopikai vừa public dpkllm benchmark bộ benchmark dataset dành riêng cho llm tiếng việt dưới dạng một challenge tổ_chức trên aihub dpkllm tiến_hành đánh_giá trên nhiều tập dataset với nhiều tác vụ khác nhau vilawqa tập_trung vào vấn_đề hỏi_đáp trên miền dữ_liệu về luật_pháp việt nam vitruthfulqa tập_trung đánh_giá tính trung_thực của các câu trả_lời được sinh bởi llm tương_tự truthfulqa nhưng dành cho tiếng việt các tập dữ_liệu chuyên về hỏi_đáp của các bên khác như viwikiqa vicoqa vinewsqa ... ngoài_ra challenge cũng xem_xét đánh_giá tác vụ ner với tiếng việt của llm đây là cơ_hội để các cá_nhân tổ_chức đang phát_triển llm có_thể tham_gia đánh_giá và so_sánh kết_quả của mình với các bên khác cũng như trao_đổi và học_hỏi lẫn nhau challenge kéo_dài vô thời_hạn và mọi người có_thể dễ_dàng đăng_ký tham_gia cũng như submit kết_quả lên hệ_thống,"['#sharing', '#data']"
tuy không liên_quan tới ml dl ai nhưng thống_kê luôn có vai_trò rất quan_trọng trong khoa_học dữ_liệu dưới đây là thông_tin về lớp_học do gs richard mcelreath đang giảng bài về cuốn sách của gs có tên statistical rethinking <number> edition theo trường_phái thống_kê bayesian trong <number> tuần các bạn có_thể theo_dõi tại đây tại địa_chỉ github này bài giảng ghi_hình và upload <number> lần tuần,['#sharing']
chào các anh chị sau khi tìm_hiểu về mô_hình arima trong timeseries em thắc_mắc một_số vấn_đề như sau <number> ưu_điểm nhược_điểm của arima model <number> arima thích_hợp với bài_toán timeseries hay không khi nào thì mình nên dùng arima sẽ cho kết_quả tốt <number> arima và lstm thì phương_pháp nào thường sẽ cho kết_quả tốt hơn em rất mong nhận được những góp_ý thảo_luận của các anh_chị để em có_thể nâng cao được thêm kiến_thức,"['#Q&A', '#deep_learning']"
chào mn em là sinh_viên năm cuối hiện đang tìm_hiểu về lĩnh_vực ml dl ai về phần đồ_án tốt_nghiệp của em thầy có bảo phải sử_dụng mô_hình ai để nhận_dạng được tiếng ồn của máy máy hoạt_động ổn_định hay không tuy_nhiên trên trường em chỉ được học ai trong xử_lý dữ_liệu xử_lý ảnh thôi chứ chưa đến mức xử_lý âm_thanh em có tìm_hiểu nhiều nguồn về xử_lý âm_thanh mà thấy có vẻ không đúng trong tâm lắm chủ_yếu về nhận_diện giọng nói anh_chị nào có nguồn nào xử_lý âm_thanh như sách vidieo khoá học hay có_thể recommend em với càng chi_tiết càng tốt để sau_này bảo_vệ đồ_án ổn em cám_ơn mn đã bỏ thời_gian đọc bài viết,['#Q&A']
sau bao ngày chờ_đợi nhóm dịch sách cuối_cùng cũng đã hoàn_thiện tập hai các bạn đã đăng_ký tập hai từ lần trước chuẩn_bị nhận sách nhé,['#sharing']
cho em hỏi sao loss function không có sigma đằng trước,"['#Q&A', '#math']"
em chào các anh_chị em là sinh_viên năm <number> đang tìm_hiểu về computer vision cụ_thể là về xử_lý dữ_liệu 3d em có tìm_hiểu mộ5t vài thông_tin trên mạng nhưng đa_số là paper mà em đọc thì thấy khó hiểu với có nhiều cái căn_bản em chưa biết anh_chị có_thể cho em xin một_số cuốn sách nào về lĩnh_vực này để em có_thể tìm_hiểu từ cơ_bản trước không em xin cảm_ơn,"['#Q&A', '#cv']"
mọi người ơi mọi người cho em hỏi là làm_sao kiểm_soát được câu trả_lời của chat gpt api vậy em có tích_hợp vào chatbot đưa thông_tin sản_phẩm_giá 300k mà nó trả_lời khách 150k em có tìm các thuộc_tính của nó và đọc các tài_liệu rồi nhưng mà vẫn chưa tìm ra,"['#Q&A', '#nlp']"
chào mọi người hiện_tại em đang làm bài_tập python cần dùng turicreate để sử_dụng sframe nhưng không_thể cài được để sử_dụng trên group có ai từng sử_dụng turicreate hoặc tương_tự chỉ giúp với em đang chạy song_song win <number> và ubuntu <number> cảm_ơn mọi người,"['#Q&A', '#python']"
mọi người cho em hỏi cách cài_đặt turicreate trên python được không em có thử làm theo những cách trên mạng nhưng vẫn bị báo lỗi ấy em cảm_ơn mọi người trước,['#Q&A']
em chào mọi người chuyện là em đang làm một project về sinh ảnh biển_báo giao_thông_sử_dụng mô_hình diffusion em muốn hỏi mọi người mình muốn lấy datasets biển_báo giao_thông chỗ nào ổn em cảm_ơn mọi người rất nhiều,"['#Q&A', '#cv']"
chào mọi người mình muốn chia_sẻ <number> python package nlp mình build cho công_việc cá_nhân mọi người có_thể dùng thử và cho mình feedback để mình improve cái package này hơn nhé tại đây cũng là tâm_huyết của mình mấy tháng qua thư_viện này mình build gồm <number> phần chính p1 supervised learning dùng huggingface masked language model có_thể sử_dụng phobert hay envibert luôn hay causal language model kiểu của gpt cho tiếng việt thì có nlphust gpt2vietnamese cho các task classification regression vừa classification vừa regression classification các level khác nhau mình gọi nó là multihead và cả multilabel p2 language model training cho phép mình train <number> llm masked hoặc causal from scratch hoặc là cho lm finetuning kiểu mình dùng phobert mà đã được train trên tập dataset tiếng việt rất lớn gồm wikipedia hay báo xong mình train tiếp nó cho tập data comment của user trên sàn ecommerce để nó đc finetune tốt hơn trên tập data này idea này mình nhớ bắt_đầu_từ paper ulmfit cái lợi của việc này là sau khi mình cho model train trên tập data này xong data user comment mình cho model học tiếp những cái supervised learning task nhắc tới phần <number> kiểu predict coi user này đang comment về category gì thì độ chính_xác của nó sẽ được boost lên <number> chút nữa với từng phần trên thì mình chia nó thành <number> process <number> process chuyên làm text preprocessing có_thể làm đa_luồng luôn vì backend mình dùng huggingface datasets lib load data filter data text transform có cả text augmentation và <number> process là để build model để train model log save and load model ... tất_cả các thông_tin mình có viết documentation và có tutorial cho từng đoạn mọi người có_thể xem qua đây cảm_ơn mọi người,"['#sharing', '#python']"
các bạn vui_lòng đăng tin tuyển_sinh tuyển_dụng sự_kiện tháng <number> <number> vào comment của post này,['#sharing']
các bạn vui_lòng đăng tin tuyển_sinh tuyển_dụng sự_kiện tháng <number> <number> vào comment của post này chúc các bạn có một kỳ nghỉ lễ vui_vẻ,['#sharing']
mng cho em hỏi ai có tập dataset liên_quan đến các chỉ_số về chất_lượng không_khí như này việt nam không,"['#Q&A', '#data']"
hi anh_chị em đang làm bài_tập về linear regression dự_đoán giá nhà bằng thuật_toán gradient decent giảm độ dốc nhưng sau khi em test thử model thì các giá_trị predicton nó có giá_trị nan là bị sao vậy mô_hình này em test với tập dữ_liệu nhỏ thì nó cho ra các dự_đoán khá sát với các giá_trị thực_tế nhưng khi em thử các tập dữ_liệu khá lớn thì các giá_trị prediction bằng nan em đã thử điều_chỉnh learing rate nhưng không có kết_quả mong mọi người giúp_đỡ em cảm_ơn link github,"['#Q&A', '#machine_learning']"
em đang tập_tành chuyển qua google colab nhưng khi upload file lên thì các hình_ảnh trong markdown đều bị lỗi không load được mặc_dù đã đúng đường_dẫn edit sau một hồi nghiên_cứu thì có vẻ như thẻ img trong markdown không hoạt_động trong đường_dẫn local vì một lý_do nào đó trong khi sử_dụng cùng format đường_dẫn để read file thì ok nhưng lại hoạt_động được với các url global dưới đây là video cách lấy link các file ảnh trong google drive để sử_dụng vào colab anh_em nào có phương_pháp hay ý_kiến tốt hơn mời bình_luận bên dưới thank,['#Q&A']
chào buổi tối mọi người lúc launching vietcuna thì team vilm có hứa sẽ có phiên_bản 40b của vietcuna hôm_nay team rất vui giới_thiệu <number> model mới nhất của team là vulture40b và vulture180b với hỗ_trợ lên tới <number> ngôn_ngữ tất_nhiên là có hỗ_trợ tiếng việt vilm mong vulture series sẽ là công_cụ đắc_lực giúp các công_ty việt nam vươn ra biển lớn supported languages english german spanish french portugese russian italian vietnamese indonesian chinese japanese and chinese announcement vulture40b vulture180b,"['#sharing', '#nlp']"
generative knowledge ai đang phát_triển với tốc_độ vũ_bão nhất là các mô_hình ngôn_ngữ lớn large language models tuy_nhiên lĩnh_vực nghiên_cứu ảnh tạo sinh với các mô_hình_như dalle hiện dalle3 đã được tích_hợp vào chatgpt4 bản dalle2 có open source nhé và đặc_biệt là open source stable diffusions controlnet là <number> dạng variants từ sd giữ vai_trò quan_trọng việc sáng_tạo nội_dung content creation ví_dụ ta có_thể prompts ra ảnh annimate trong truyện_tranh hay về lĩnh_vực thiết_kế công_nghiệp đồ_hoạ kiến_trúc xây_dựng ... ta có_thể vẽ sketch rồi prompts cho ra sản_phẩm hoàn_chỉnh chưa kể chúng_ta có_thể nghiên_cứu ứng_dụng sd vào các domain chuyên_ngành hẹp hi_vọng mình có_thể sớm khoe kết_quả này trong thời_gian sắp tới để làm sinh_động hơn hình_ảnh tĩnh tạo sinh gần đây các nhà khoa_học đã giới_thiệu tới mọi người source code có_thể tạo ảnh đông gif có tên là annimatediff tại đây và hotshot tại đây cả <number> thư_viện này giúp chúng_ta finetune model sd thành dạng ảnh động gif thay_vì ảnh tĩnh jpg png hi_vọng thư_viện này giúp các bạn học_tập vào thực_hành theo hướng mình mong_muốn,"['#sharing', '#python']"
một trong những yếu_tố giúp chúng_ta có prompts tốt để generate ra nội mong_muốn là việc làm_khó nên mới có nghề mới gọi là prompt engineers engineering dưới đây là tổng_kết <number> điểm mà tôi copy paste của francois chollet tác_giả bài báo về mô_hình inception và là người viết thư_viện keras của google my interpretation of prompt engineering is this <number> llm is repository of many millions of vector programs mined from humangenerated data learned implicitly as byproduct of language compression vector program is just very nonlinear function that maps part of the latent space unto itself <number> when you re prompting you re fetching one of these programs and running it on an input part of your prompt serves as kind of program key as in database key and part serves as program argument like in write this paragraph in the style of shakespeare my paragraph the part write this paragraph in the stye of is program key with arguments shakespeare and my paragraph <number> the program fetched by your key may or may not work well for the task at hand there no reason why it should be optimal there are lots of related programs to choose from <number> prompt engineering represents search over many keys in order find program that is empirically more accurate for what you re trying to do it no different than trying different keywords when searching for python library <number> everything else is unnecessary anthropomorphism on the part of the prompter you re not talking to human who understands language the way you do stop pretending you are mình từng có lần chia_sẻ về việc có người tổng_hợp các ảnh và prompts liên_quan tới chủ để sinh ảnh mình sẽ tìm lại link github của nó và chia_sẻ bên dưới,"['#sharing', '#nlp']"
em chào mọi người là newbie mới train <number> model trên kaggle sau khi tập_tành fine tuning <number> model model đó fine tune dựa vào llama2 và blomz trên tập data tiếng việt trên hugging face xong thì có nhấn save model sau đó vào lại thì chỉ thấy có mấy file như adapter _model bin adapter_config json redme events out tfevens sau đó em có tải koboldcpp về để chạy nhưng không được mọi người có biết cách nào để chạy file này ko và input đầu_vào có nhất_thiết phải có dạng instruction input output response em muốn dùng văn_bản text được không em cảm_ơn,"['#Q&A', '#nlp']"
chào mọi người mọi người cho em hỏi là có ai đã từng pretraining hoặc further training trocr hoặc <number> multimodal nào đó bằng hugging face ko em muốn hỏi để lấy thêm kinh_nghiệm,['#Q&A']
chào mọi người hiện_tại em đang muốn có định_hướng học ai em biết python_dụng để phát_triển và huần luyện các model ai nhưng deploy model trong thực_tế như viết một cái backend chẳng_hạn thì cần hiệu_suất cao hơn và nhanh hơn thì người_ta dùng ngôn_ngữ lập_trình khác hoặc tích_hợp ai vào hệ_thống nhúng dùng mọi người ai đã đi làm ngoài thực_tế xin khảo_sát một_vài ngôn_ngữ lập_trình thường mà công_ty doanh_nghiệp của các anh_chị thường sử_dụng để deploy model ai ra thực_tế với em xin cảm_ơn rất nhiều,['#Q&A']
gần đây mình được cấp quyền sử_dụng high performance computers hpc còn trước đây chỉ có mỗi <number> máy với <number> gpu <number> nên mình chỉ dùng anydesk để điều_khiển từ xa nên mình dành nhiều thời_gian học để điều_khiển nó vì_vậy mình phải học một_số công_cụ như tmate screen ssh code tunnel ... nhưng quan trong hơn là phải học thêm nhiều về bash scripts nay thấy <number> repo khá thú_vị hướng_dẫn các bash scripts phổ_biến dùng để huấn_luyện các mô_hình lớn trên hpc nên mình chia_sẻ lại tại đây hi_vọng nó sẽ giúp_ích với các bạn có điều_kiện sử_dụng hpc,['#sharing']
cho mình hỏi embedding vectors tiếng việt gọi sao vậy mình dịch tạm là véc tơ nhúng nhưng có vẻ nó không_thể_hiện được tinh_thần của chữ embedding trong trang của ml cơ_bản thì vẫn giữ nguyên chữ embedding có_chăng mình không_thể việt_hoá hoàn_toàn từ này,"['#Q&A', '#nlp']"
generative ai ai tạo sinh và predictive ai ai dự_đoán khác nhau về cách chúng xử_lý các ứng_dụng và dữ_liệu có cấu_trúc lẫn phi cấu_trúc tương_ứng cùng tìm_hiểu những lợi_ích và các hạn_chế của mỗi loại trong các ứng_dụng thực_tế của chúng,['#sharing']
đại_học harvard vừa công_bố khóa học về data science với python thuộc bộ_môn computer science khóa học hoàn_toàn miễn_phí và kéo_dài trong <number> tuần link,['#sharing']
tuần sau có anh_chị các bạn nào tham_gia iccv paris ko cùng kết_nối tham_gia xong thăm_thú cho vui,['#Q&A']
hệ_thống ai cải_tiến có_thể giải_mã cảm_xúc của gà,['#sharing']
chào mn em đang làm nhiệm_vụ làm giảm thời_gian inference model bert bởi phải infer tới <number> triệu câu em đang có ý_tưởng là ghép các câu lại có dạng cls sentence sep sentence sep ... ... thì mình ghép được bao_nhiêu câu thì tốc_độ sẽ giảm đi từng đó lần và bài_toán yừ multi class sẽ chuyển thành multi label thế nhưng khi em ghép vào kết_quả infer rất tệ đã train trên câu ghép không biết mn đây đã ai từng làm chưa có_thể cho em cái suggest không em cảm_ơn,['#Q&A']
cẩm_nang chi_tiết cho bạn nào xây cv nhé,['#sharing']
mn có biết báo nào hay web nào có những nghiên_cứu model về tài_chính dữ_liệu có độ tin_cậy cao không cho em xin với,['#Q&A']
chào mọi người em đang làm <number> project nlp cần tiền xử_lý dữ_liệu văn_bản tiếng việt cho em hỏi có package nào hỗ_trợ chuẩn_hoá cách bỏ dấu_câu òa oà úy uý và lỗi mỳ mì li_ti cái ly không,"['#Q&A', '#data', '#nlp']"
dự_án hiện_tại của em là xây_dựng một data engine cho một phòng lab thực_tế ảo vr experiment sử_dụng oculus vấn_đề đặt ra là hiện_tại lab ảo này đang sử_dụng một_số mock data từ lab thật được nạp vào và mỗi khi người dùng thực_hiện_hành_động thì output sẽ là mock data chứ không phải là data thật thầy muốn em tạo một data engine để học và dự_đoán output dựa trên những data được lưu lại trước đó lab thật có xuất ra một file excel lưu data những lần chạy ậy thì em cần học những thuật_toán gì công_nghệ gì sử_dụng data storage nào là tối_ưu nhất em có_học qua computer vision và đã từng làm một_số project về image classification nhưng chưa có kinh_nghiệm nào về mảng này cảm_ơn mn,"['#Q&A', '#data']"
mn cho hỏi là học machine learning thì có nên học sâu về thuật_toán backtrack đệ quy em rất thích học_thuật_toán và vẫn học nó hàng ngày nhưng mà khi học ml thì nó có những thuật_toán riêng không biết là cái việc học_thuật_toán nó có tác_dụng gì khi mình theo ml không em cảm_ơn,"['#Q&A', '#math']"
em bị lỗi này mỗi khi submit cell trên jupyter em đã kiểm_tra java bashrc whichjava thì đều đã đúng đường_dẫn kèm cài môi_trường cho nó rồi mọi người ai rành giúp em với em xin gửi bữa ăn sáng,['#Q&A']
xin chào mọi người có anh chị em nào có biết web cho thuê server vật_lý gpu để deploy api giá ngon bổ rẻ không em biết <number> web là khá là ok nhưng mạng chập_chờn quá hình_như hay bị ddos các bác nào biết cho em xin với em cảm_ơn,['#Q&A']
mọi người ơi cho em hỏi là vì_sao pretrained model như phobert gpt3 thì khi xây chatbot rasa với các model đó em vẫn phải xác_định intent và example kh phải nó dc train rồi hay sao em là newbie nên hỏi có khi hơi ngô_nghê mong mng bỏ_qua cảm_ơn mng đã giải_đáp,"['#Q&A', '#nlp']"
hi mọi người sau cuộc thi zaloai thì mình thấy cinnamon ai marathon là cuộc thi có nhiều thú_vị trong cuộc thi này có <number> đề_tài_chính handwriting ocr for vietnamese address document layout analysis real time facial landmark detection do mình thấy cuộc thi này khá thú_vị mà không có nhiều cộng_đồng support nên mình cung_cấp code base của đề_bài ocr cho mọi người tham_khảo về bài_toán ocr thì chung ta cần nhận_diện các kí_tự trong hình_ảnh scan của một đoạn text bộ dữ_liệu gồm <number> mẫu mô_hình mình sủ_dụng là crnn ctcloss cnn dùng để extract features sau đó đươc đưa vào rnn để nhận_dạng kí_tự_tại timestep hiện_tại kết_quả mình thấy khá khả_quan nhận_diện cũng tương_đối chính_xác với normalize editdistance <number> bạn nào có hưng thú tìm_hiểu về ocr cũng như cuộc thi thì có_thể tham_khảo codebase này nhé,"['#sharing', '#cv', '#nlp']"
hello mọi người hiện_nay mình đang tìm_hiểu về imbalanced dataset mọi người có ai có biết sách nào nói về vấn_đề này không sách được phát_hành việt_nam càng tốt,"['#Q&A', '#data']"
hôm trước khá nhiều người hỏi về quy_trình thu_thập dữ_liệu cũng như training của llm vietcuna từ vilm hôm_nay team vilm chính_thức công_bố toàn_bộ quy_trình để làm ra vietcuna với hướng_dẫn này kèm với model vietcuna đã có sẵn mong sẽ có nhiều bạn và doanh_nghiệp việt_nam tạo ra các sản_phẩm ai mang tính thực_tế cao trong cuộc_sống link,"['#sharing', '#data']"
chào mọi người mình đang cần train model với bộ data khoảng 129gb dạng zip nhưng với colab free thì nó chỉ có khoảng <number> gb nhớ free có cách nào khác để train không giúp mình với mong mn giúp_đỡ,"['#Q&A', '#data']"
hôm trước mình thấy có một_số câu hỏi về server và colab thực_sự mình cũng đã gặp khá nhiều vấn_đề với giới_hạn thời_gian sử_dụng colab giới_hạn dung_lượng ram và giới_hạn phần_cứng mình đã phải mua gói pro hoặc thậm_chí là gói pro để khắc_phục vấn_đề này tuy_nhiên việc đó vẫn không hoàn_toàn thuận_lợi vì đôi_khi mình quên tắt colab dẫn đến việc nó treo và tiếp_tục trừ tài_khoản tính tiền như gói pro giá <number> mỗi tháng gần đây mình đã tìm ra một giải_pháp tốt hơn là sử_dụng gradient gradient cung_cấp cho chúng_ta một container docker hoàn_chỉnh cho mỗi notebook và dữ_liệu được gắn_kết trực_tiếp với máy_chủ chính hơn nữa phiên_bản miễn_phí của gradient cung_cấp 5gb dung_lượng lưu_trữ vĩnh_viễn dữ_liệu trong đó không bị mất ngay cả khi notebook gặp vấn_đề và mình xóa toàn_bộ bạn có_thể sử_dụng gradient miễn_phí trong <number> giờ liên_tục cho mỗi phiên_notebook nó sẽ không bị tắt giữa_chừng_như colab điều thú_vị là với gói pro chỉ <number> mỗi tháng bạn có_thể trải nghiệm nhiều cấu_hình miễn_phí tuyệt_vời ví_dụ như p5000 với 30gb ram 8g cpu và 16gb gpu hoặc a400 với 45gb ram 8g cpu và 16gb gpu ... quan_trọng là sau <number> giờ bạn có_thể kết_nối và tiếp_tục sử_dụng với khoản phí <number> đó như một khoản phí duy_trì nếu bạn đăng_ký gói growth bạn sẽ có nhiều máy_chủ miễn_phí hơn thậm_chí có a100 với 80gb gpu miễn_phí tuy_nhiên với phiên_bản miễn_phí sau <number> giờ sử_dụng nó sẽ tự_động tắt và bạn cần tìm một máy_chủ khác để kết_nối_tiếp tóm lại mình thấy gradient ngon hơn nhiều so với colab,['#sharing']
xin chào mọi người đang làm nhãn cho bài_toán phân_loại ảnh em có <number> thắc_mắc là với ảnh có độ phân_giải nhỏ 100x100 chất_lượng hơi kém kích_thước của đồ_vật cần phân_loại nhỏ trong ảnh và cũng hơi mờ thì nên phân_loại ảnh là negative hay positive nếu là mắt con_người thì có_thể đoán được là đồ_vật đó positive nhưng để là máy đoán dc thì quá khó ví_dụ những ảnh dưới đây chứa xe_đạp mắt người thì đoán đc nhưng để ai đoán được là xe_đạp thì quá khó theo mọi người thì nên phân_loại gì em cảm_ơn nhiều,"['#Q&A', '#data']"
hi mọi người em đang tính làm một dự_án vớ llama <number> em có một thắc_mắc về data privacy như khi em dùng chatgpt thì mọi thông_tin từ prompt hoặc data mà mình dùng để finetune sẽ được đưa về openai vậy cho em hỏi nếu em finetuned llama <number> model thì data mình dùng để finetune hoặc prompt của mình khi sử_dụng model có bị lưu bởi meta em cảm_ơn,"['#Q&A', '#data', '#nlp']"
ngày hội_trí_tuệ nhân_tạo việt_nam ai4vn <number> có chủ_đề sức_mạnh cho cuộc_sống với bốn hoạt_động chính ai workshop ai summit ai expo cto summit <number> vinh_danh các công_ty có môi_trường công_nghệ tốt nhất phiên khai_mạc ngày <number> <number> mang đến báo_cáo chỉ_số sẵn_sàng ai của chính_phủ năm <number> trình_bày bởi ông pablo fuentes nettel chuyên_gia_tư_vấn cấp cao tại oxford insights ngay sau đó là các phần tham_luận về ứng_dụng ai trong tương_lai kinh_nghiệm triển_khai thực_tế tại hàn_quốc làm_chủ ai tạo sinh ... qua góc nhìn của các chuyên_gia vinbigdata naver vnpt aqua,['#sharing']
yeahhhhh mình rất vui giới_thiệu vietassistantgpt phiên_bản <number> là một trợ_lý đa_năng general domain dựa trên phát_triển của opensource llama <number> phiên_bản này đã được finetune để cung_cấp cho bạn những câu trả hữu_ích hơn trong nhiều lĩnh_vực trên tiếng việt và đang trong quá_trình cải_thiện finetuned model và dataset được cung_cấp link sau demo link vietnamese llama2 13b demo vietnamese llama2 7b model demo rất mong_chờ sự phản_hồi và ý_kiến của mọi người,"['#sharing', '#nlp']"
mình thấy giờ nhiều bạn lo hết việc sợ ai thay_thế sợ cạnh_tranh cao ... tuy_nhiên theo mình thì nhu_cầu công_việc ngoài kia không thiếu cái thiếu đây là thiếu người giỏi và người phù_hợp vậy nên có những thứ các bạn không_thể kiểm_soát được thì không nên tốn năng_lượng làm gì cái các bạn cần là hãy nâng cao năng_lực giỏi tới mức người_ta không_thể ngó lơ thì mọi thứ sẽ tuyệt_vời hơn rất nhiều,['#sharing']
khai_phá dữ_liệu là một phần việc rất quan_trọng để hiểu về dữ_liệu cho các mục_đích phân_tích chuyên_sâu tiếp_theo đây cuốn sách gần <number> trang hướng_dẫn biểu_diễn dữ_liệu sử_dụng python matplotlib và seaborn như <number> một_số kĩ_thuật lựa_chọn dạng biểu_đồ phù_hợp <number> xử_lí missing data outliers <number> phần biểu_diễn dữ_liệu địa_lý bản_đồ geospatial data và <number> biểu_diễn dữ_liệu dạng 3d tại đây hi_vọng nó có_ích với mọi người,"['#sharing', '#data']"
xin chào mọi người hiện_tại em đang làm đồ_án tốt_nghiệp với đề tại là trích xuất nội_dung từ danh_thiếp bằng ocr tuy_nhiên do data ít nên em đăng bài này mong_muốn kiếm một lượng lớn data về danh_thiếp để bổ_sung vào đatn nếu ai có thì cho em xin hoặc mua lại em xin cảm_ơn mọi người nhiều,"['#Q&A', '#cv', '#data']"
xin chào mọi người hiện_tại mình đang thực_hiện <number> project cho product ứng_dụng llm tuy_nhiên do data ít nên mình đăng bài này với mong_muốn tìm_kiếm thêm data để project được hoàn_thiện data mình cần là ảnh các loại_hóa đơn thương_mại nếu ai có nguồn data như_vậy thì có_thể cho mình xin hoặc mua nếu cần được không mình xin cảm_ơn,"['#Q&A', '#data']"
vậy là mojo ngôn_ngữ mới cho ml dl ai đã cho phép cài_đặt trên máy_tính cá_nhân hiện_tại mojo mới hỗ_trợ hệ điều_hành linux các bạn có_thể test bằng cách đăng_kí và cài_đặt tại đây,['#sharing']
mn có_thể recommend cho <number> vài kênh học lý_thuyết ml từ basic không em muốn nắm dc basic ml một_cách nhanh_chóng nhưng cảm_giác bị hổng đâu_đó về lý_thuyết nhưng không biết là chỗ nào em cảm_ơn,"['#Q&A', '#machine_learning']"
dạ anh_chị nào có tài_liệu bài_tập về linear regression và logistic regression cho em xin dạ em cảm_ơn,"['#Q&A', '#machine_learning']"
mọi người cho hỏi làm thế_nào để dịch từ tiếng anh về tiếng việt cho nó tự_nhiên hơn không không dùng chatgpt và google,['#Q&A']
xin chào các anh_chị và các bạn mình làm về dự_báo mức tiêu_thụ năng_lượng của một quốc_gia mỹ latin dữ_liệu dạng time series được tổng_kết cuối năm mình đọc thì có một_số mô_hình dự_báo tốt như arima và lstm ... trong đó thì mình cảm thấy thích arima hơn vì nó dễ và kết_quả cũng tốt các anh_chị nào có tài_liệu để đọc về vấn_đề này có_thể giới_thiệu cho mình được không mình hơi lơ_mơ về cách chọn các tham_số đặc_biệt là khi số_lượng biến nhiều mà_lại làm_việc với univariate do mình còn kém kinh_nghiệm nếu anh_chị nào có_thể chia_sẻ được về phần này mình rất cảm_ơn,"['#Q&A', '#deep_learning']"
morning mn mọi nghĩ sao về việc mình dùng chat gpt api ... các ai khác nữa để convert video về dạng text để lấy các keywords xong sau đó mình dựa vào các keywords để match với các khách_hàng care về sản_phẩm đó và dựa vào content của video đó để generate cái email marketing này ideal để làm automation dựa trên các con ai hiện_tại như chatgpt zapier,['#Q&A']
em xin phép admin được chia_sẻ tới các thành_viên group mình cuộc thi về trí_tuệ nhân_tạo do fpt tổ_chức cuộc thi ứng_dụng trí_tuệ nhân_tạo với tổng giá_trị giải_thưởng <number> triệu đồng fpt ai challenge <number> cuộc thi về trí_tuệ nhân_tạo lớn nhất do tập_đoàn fpt tổ_chức với tổng giải_thưởng <number> triệu đồng cuộc thi tìm_kiếm những ý_tưởng sản_phẩm và giải_pháp ứng_dụng trí_tuệ nhân_tạo giúp giải_quyết các bài_toán thực_tế trong đời_sống đây là sân_chơi kỹ_thuật dành cho những người có niềm đam_mê với ai trên toàn thế_giới thời_gian đăng_ký từ 12h00 ngày <number> 10.10.2023 các thí_sinh tham_gia cuộc thi theo hình_thức cá_nhân hoặc nhóm với tối_đa <number> thành_viên và đăng_ký tại trang_web vòng_loại các đội thi sẽ chọn cho mình chủ_đề phù_hợp và tiến_hành xây_dựng những sản_phẩm giải_pháp giúp giải_quyết bài_toán mà ban tổ_chức đưa ra <number> đội thi có điểm số cao nhất sẽ vào vòng chung_kết ba chủ_đề của cuộc thi fpt ai challenge <number> bao_gồm aienable optimization for_binh dinh province leveraging large language models llms for sustainable business recommendations ai techniques for computer vision applications tại vòng chung_kết top <number> ý_tưởng sáng_tạo nhất sẽ trình_bày ý_tưởng về sản_phẩm và giải_pháp của mình với ban giám_khảo qua hình_thức online top <number> chung_cuộc sẽ được tham_dự lễ trao giải và trưng_bày sản_phẩm trực_tiếp tại sự_kiện triển_lãm công_nghệ fpt tech day <number> đội chiến_thắng sẽ nhận được giải_thưởng tiền_mặt với giải nhất trị_giá <number> triệu đồng giải nhì <number> triệu đồng giải ba <number> triệu đồng cùng giấy chứng_nhận của ban tổ_chức top <number> chung_cuộc sẽ được tài_trợ một tuần du_lịch tại việt_nam tham_gia giao_lưu văn_hoá quốc_tế và triển_lãm sản_phẩm của mình tại sự_kiện fpt tech day <number> được tổ_chức vào tháng <number> tại hà_nội ngoài_ra các đội thi sẽ có cơ_hội tham_gia những buổi tham_luận cùng với các chuyên_gia và kỹ_sư đầu ngành nhận được cơ_hội việc_làm với mức lương hấp_dẫn tại công_ty công_nghệ hàng_đầu việt_nam thông_tin chi_tiết của cuộc thi được đăng_tải trên website,['#sharing']
em xin chào mọi người em đang thử train model text recognition sử_dụng mô_hình crnnctc với tool từ paddleocr em train thử <number> epochs trên bộ dữ_liệu icdar2015 với pretrained model từ paddleocr kết_quả model bị overfit mạnh trên tập icdar2015 training accurracy tăng rất nhanh khúc sau tới gần <number> nhưng kết_quả test lại rất thấp chỉ <number> em có đính kèm hình bên dưới em muốn xin hỏi làm_sao để khắc_phục vấn_đề này em có tìm_hiểu trên mạng thì có <number> chỗ ghi là do bộ icdar2015 này ít ảnh cỡ <number> ngàn mấy nên bị overfit người_ta train thì dùng các bộ dataset lớn như synthtext <number> triệu ảnh tuy_nhiên em dùng google colab nên không đủ bộ_nhớ để train những tập lớn như_vậy với tập icdar2015 mà khi train bộ_nhớ cpu gpu colab đã gần bị overflow rồi không biết mọi người có link về các bộ dataset nào có kích_thước vừa phải có_thể dùng để train thử_nghiệm trên google colab cho bài_toán scene text recognition không em xin cảm_ơn mọi người nhiều,"['#Q&A', '#data', '#cv']"
giáo_sư dunhui deng bộ_môn khmt của đại_học thanh hoa tsinghua university bên tq có giới_thiệu cuốn sách về algorithims viết cho cho các ngôn_ngữ python go javascript typescript swift zig rust and dart rất tiếc sách viết bằng tiếng tàu tuy_nhiên mình đã thử_dụng một_số công_cụ dịch như google translate bard claude2 và chatgpt3 <number> thì thấy chất_lượng dịch ra tiếng anh và tiếng việt khá ổn vì_vậy mình xin giới_thiệu source code của cuốn sách này tại đây và có bạn đã tìm thấy branch bản dịch tiếng anh của cuốn sách và source code tại đây cảm_ơn bạn nghia be chúc các bạn có ngày cuối tuần vui_vẻ,['#sharing']
chào mọi người hiện_tại em đang tìm_hiểu một_số bài_toán về speech em tìm_hiểu và có biết bộ dataset về giới_tính và vùng miền voice gender của zalo ai challenger <number> em đã cố_gắng tìm các nguồn public trên mạng nhưng vẫn chưa tìm được dữ_liệu này trang_chủ cuộc thi hiện_nay là năm <number> và không xem_lại được dữ_liệu năm trước mọi người trong nhóm ai còn lưu_trữ bộ dataset này cho em xin với cảm_ơn mọi người đã đọc bài,"['#Q&A', '#data']"
cộng_đồng llms việt nam hiện_tại mình đang xây_dựng một mô_hình ngôn_ngữ thuần việt dự_án của mình dựa trên sự phát_triển của các mô_hình ngôn_ngữ dựa trên opensource llm như và nhiều mô_hình thông_tin sơ_lược về dự_án trình_bày trong file đính kèm hoạch của mình bao_gồm việc phát_triển tạo bộ dữ_liệu vietnamese selfinstruct dataset và finetuning và training các opensource llms trên bộ dữ_liệu tiếng việt phát_triển bộ dữ_liệu tiếngviệt selfinstruct vietnamse dựa trên các bộ dữ_liệu tiếng anh hiện có như và các nhiều bộ dữ_liệu khác mình đang sử_dụng api azure openai gpt3 gpt <number> và gpt4 để dịch các bộ dữ_liệu này sang tiếng việt tạo thêm <number> có_thể nhiều hơn câu hướng_dẫn tự học giống như dự_án alpaca hoặc các mô_hình tạo dữ_liệu khác tìm_hiểu thêm về các nguồn dữ_liệu tiếng việt khác tập_trung cho các lĩnh_vực khác nhau như báo_chí điện_ảnh y_học ... mong nhận được ý_kiến góp_ý từ mọi người để huấn_luyện traning các mô_hình ngôn_ngữ llm mình sẽ sử_dụng kỹ_thuật và trên máy_chủ azure server có <number> gpus nvidia 80gb điều này sẽ giúp mình finetune và train các mô_hình ngôn_ngữ llm từ 7b tỷ đến 65b tỷ hoặc nhiều hơn mình rất mong sự kết_nối với các bạn có mong_muốn thực_hiện dự_án này và hoan_nghênh sự đóng_góp từ cộng_đồng nếu bạn có sự góp_ý về dữ_liệu hoặc xin vui_lòng chia_sẻ cùng nhau chúng_ta có_thể phát_triển mô_hình ngôn_ngữ tiếng việt chất_lượng cao rất mong nhận được sự quan_tâm và hỗ_trợ của mọi người form đăng_ký tham_gia mình là nhiệm một nghiên_cứu_sinh tiến_sĩ đang công_tác tại national central university researcher foxconn ai taiwan trần nhiệm email tvnhiemhmus@g.ncu.edu.tw zalo <number> <number> <number> <number> linkedin file đính kèm,"['#Q&A', '#nlp', '#data']"
chào mọi người hiện_tại mình đang tiến_hành điều_chỉnh finetuning mô_hình bartphowordbase để thực_hiện tác vụ tóm_tắt văn_bản tuy_nhiên khi mình dự_đoán kết_quả lại gặp phải tình_trạng kết_quả dự_đoán chứa những ký_tự không xác_định unk sau khi tìm_hiểu nhận ra rằng nguyên_nhân có_thể là do dữ_liệu huấn_luyện chứa nhiễu hoặc từ_vựng của mô_hình bartpho chưa đủ phong_phú để xử_lý tốt tình_huống này mình đã thử nhiều cách nhưng chưa xử_lí được vấn_đề này vì_thế mình lên đây tìm_kiếm gợi_ý và kinh_nghiệm từ mọi người hi_vọng mọi người giúp_đỡ,"['#Q&A', '#nlp']"
closed cảm_ơn cả nhà đã đưa ra nhiều gợi_ý giúp mình hiểu vấn_đề hơn và đã giải_quyết xong case này phương_án giải_quyết là chỉ đưa vào hàm map với tf numpy_function thao_tác đọc tên ảnh để map sang feature còn việc map caps thành vector sẽ dùng hàm map khác với auto graph lý_do là map với numpy_function rất khó control và thường hay mất shape nên gây lỗi đầu_vào với textvectorization hoặc có_thể layer nào khác cũng sẽ bị lỗi tương_tự chào cả nhà mình có <number> project cv dùng tensorflow tuy_nhiên đang bị mắc_kẹt trong việc tạo tf dataset như sau mình tạo tf dataset tên ảnh caps map bằng tf numpy_function để có dataset feature caps cho vào train nếu chạy gpu colab với num_parallel_calls trong khi map feature thì sẽ lỗi runtime <number> chỗ nào đó khi train mô_hình với <number> tập dữ_liệu cố_định mỗi lần chạy có_thể lỗi các ảnh khác nhau nếu thử với <number> tập dữ_liệu nhỏ thì có_thể may_mắn chạy được <number> vài epoch mới lỗi thậm_chí có lần chạy được hết tất_cả các epoch tuy_nhiên nếu chạy cpu hoặc chạy gpu mà không dùng num_parallel_calls thì không lỗi chạy bình_thường chi_tiết mình đăng trên stackoverflow mà chưa có ai trả_lời các cao nhân đi qua xin vui_lòng chỉ_giáo cảm_ơn rất nhiều,"['#Q&A', '#python']"
mình đang cần tìm cuốn sách này ensemble learning algorithms with python make better predictions with bagging boosting and stacking của tác_giả jason brownlee link bạn nào có cho mình xin với cảm_ơn nhiều nhé,['#Q&A']
xin chào mọi người em đang có ý_định làm một prj nlp nho_nhỏ để đánh_giá cv trong đó ý_tưởng chính của em là người dùng nhập vào một đoạn miêu_tả cv của họ gồm nghề_nghiệp kinh_nghiệm làm_việc kỹ_năng ... và bên tuyển_dụng nhập vào jd rồi so_sánh độ matching giữa <number> yếu_tố đấy tuy_nhiên em đang gặp khó_khăn ngay bước đầu_tiên khi cần biểu_diễn đoạn văn_bản input thành các vector có cùng độ dài để tiện đối_chiếu cảm_thấy thuật word2vec bình_thường không hiệu_quả với dữ_liệu bé ví_dụ nó sẽ không_thể phân_biệt được tôi là fresher it và tôi là senior it vì có cùng context mọi người cho em gợi_ý để giải_quyết vấn_đề này với liệu có cách word embedding nào khác không và nên dùng thuật gì để đo độ matching giữa cv và jd,"['#Q&A', '#nlp']"
em chào mọi người em đang eval cho model của mình trên coco2015 test dev để tiện so_sánh với các paper khác cơ_mà sever submit đã bị disable và trên web mới của codalab thì hình_như_không còn support submit cho coco nữa thì phải annotations thì họ cũng không công_bố và em tìm khắp nơi trên internet cũng không thấy có leak còn cách nào để eval trên dataset này không em cảm_ơn mọi người rất nhiều,"['#Q&A', '#data']"
chào các bác hiện_tại em đang tìm_hiểu về sentiment analysis các bác đi trước có tài_liệu hay nguồn học nào hay cho em xin với em cám mọi người nhiều,"['#Q&A', '#nlp']"
bài báo mới đến từ google có tên tsmixer an allmlp architecture for time series forecasting,['#sharing']
em chào mọi người hiện em đang cần deploy chatbot lên facebook message nhưng cần xác_minh doanh_nghiệp cho quyền pages_messing mọi người có ai đang làm hay quan_tâm vấn_đề này cho em xin ý_kiến tham_khảo với em dùng tài_khoản đã xác_minh doanh_nghiệp nhưng vẫn không xin được quyền từ facebook,['#Q&A']
em mới học về ai đang muốn train model phân_loại nội_dung video theo mức_độ phù_hợp của từng lứa tuổi ai có ý_tưởng gì có_thể sp em đc không,"['#Q&A', '#cv']"
explain paper the fastest way to read research papers explain paper là một công_cụ giúp quá_trình đọc paper trở_nên đơn_giản hơn công_cụ này rất hữu_ích với các bạn mới bắt_đầu_đọc paper các bạn chỉ cần tải paper lên highlight text mà bạn không hiểu sau đó ai sẽ giúp bạn giải_thích phần highlight đó bên cạnh các thuật_ngữ ai cũng có_thể giải_thích cả một đoạn text website,['#sharing']
chắc mọi người biết tới ứng_dụng code interpreter của openai và code llama của meta nay mình thấy có người viết api có_thể kết_nối cả <number> backends này để chạy trong terminal có tên là open interpreter nếu với code interpreter thì sẽ chạy inference online dựa trên gpt3 <number> còn code llama sẽ chạy inference offline dựa trên cấu_hình máy cá_nhân các bạn có_thể tham_khảo source code tại đây,"['#sharing', '#nlp']"
em chào mọi người em đang tìm_hiểu về llms và vừa_mới finetune được <number> model làm chatbot và em có <number> câu hỏi mong mọi người có_thể giải_đáp <number> em muốn deploy model lên web để có_thể nhận feedback từ người dùng qua internet thì có những cách phổ biển nào hay dùng em có tra thì thấy có <number> bên chạy trên được huggingface như này nhưng em tìm_hiểu thì vẫn chưa biết đưa lên kiểu gì <number> chatbot của em thì mới có_thể trả_lời được câu hỏi <number> chưa ghi_nhớ được đoạn hội_thoại cũ để đưa ra câu trả_lời mới kiểu chatgpt vậy có cách nào để làm được như_vậy hoặc mọi người có_thể đưa em từ khóa để em search <number> với những chatbot được xây_dựng từ llms thì mình có_thể xây_dựng kịch_bản cho nó không ví_dụ như chatbot để trả_lời cskh thỉnh_thoảng sẽ tự_động ra <number> câu hỏi khi khách_hàng chưa hỏi câu hỏi đấy em cảm_ơn mn,"['#Q&A', '#nlp']"
xin chào anh_chị trong group em vừa tìm_hiểu về phương_pháp word2vec trong nlp cụ_thể là skipgram dù đã đọc qua vài bài gồm cả của anh tiệp và xem vid trên youtube nhưng vẫn có một_vài đoạn em chưa hiểu lắm nên mong anh_chị giải_thích thêm thứ nhất theo em hiểu thì với mỗi target word ta sẽ tìm các weight matrix và để xác_suất của context word là cao nhất bằng phương_pháp backprobagation sau đó lặp lại quá_trình với context words với là context window sau đó lại lặp lại quá_trình đấy với từ trong từ_điển như vậy số lần phải làm backprobagation là nhưng khi học về mlp thì em được biết backprobagation là quá_trình khá tốn_kém thời_gian không biết liệu việc chỉ có <number> hidden layer và no activation function có làm giảm thời_gian không nên ta cần chọn như nào để đảm_bảo cả thời_gian và accuracy mỗi từ đầu_vào biểu_diễn dưới dạng onehot coding tuy_nhiên khi trực_quan_hóa nó dưới dạng hình_ảnh như đây thì em lại thấy người_ta tìm context dựa trên từ gần với target word nhất không biết là gần theo euclid distance hay như nào và coi mỗi từ trong từ_điển là một vector có độ dài bằng nhau trong không_gian vậy các vector đấy lấy đâu chắc không phải là vector biểu_diễn onehot encoding mà là embedding vector trong ma_trận mà ta đã tìm trên nếu hiểu theo nghĩa đấy thì kích_thước mỗi vector chính là số neuron trong hidden vector đúng không tại_sao không dùng nhiều hidden layer cho thuật_toán như mlp thế ngoài_ra nếu khi trực_quan_hóa ta dùng vector trong weight matrix tìm ra thì dùng vector trong target matrix hay context matrix cơ_sở toán_học nào đằng sau việc mô_hình_hóa này em là làm_sao khoảng_cách euclid giữa các vector của weight matrix trong không_gian lại có liên_quan đến mô_hình xác_suất mà ta xây_dựng thuật_toán,"['#Q&A', '#nlp']"
mình có tìm_hiểu về image generation thì thấy lora khá phổ_biến khi finetuning stable diffusion tuy_nhiên thì lại thấy khá ít chỗ nói về cơ_chế hoạt_động đối_với sd chủ_yếu chỉ thấy mention trong peft của nlp hy_vọng bài viết có_thể giúp mọi người hiểu hơn về cách lora giảm computation cost và kích_cỡ file lưu_trữ khi finetune sd nhé,"['#sharing', '#cv']"
nhân_dịp mình có pull request gligen model pipeline được merge vào thư_viện huggingface diffuser mình xin phép chia_sẻ đến mọi người hiện_nay các phương_pháp finetune personal diffusion như textual inversion dreambooth hay lora sẽ giúp ta thêm object hoặc style bất_kì vào ảnh mà ta muốn sinh nhưng các phương_pháp này đều yêu_cầu phải có một lượng data và finetuneing gligen pipeline hỗ_trợ việc thêm object hoặc style mà không cần finetune zeroshot ta chỉ cần truyền một bức ảnh chứa object hoặc style và mô_hình có_thể sinh ra ảnh dựa trên đó chi_tiết hơn có_thể tham_khảo paper ngoài_ra gligen pipeline còn có_thể cho bạn xác_định vị_trí đặt vật_thể trong ảnh sinh ra bằng việc cung_cấp tọa_độ box hiện_tại mình support <number> model là generation và inpainting mọi người hứng_thú có_thể thử code example được mình đính kèm model card generation inpainting,"['#sharing', '#deep_learning']"
gần đây mình quan_sát thấy hiện_tượng hay xu_thế chuyển_đổi code từ python qua cho các mô_hình ngôn_ngữ lớn nhưng chưa thấy ai viết lại models và train nó từ chính tuy_nhiên trong ngôn rust thì xu_thế viết lại models và training loop đang được cộng_đồng làm khá mạnh trong đó có huggingface trước đó huggingface đã viết một_số thư_viện bằng rust như datasets safetensors ... và gần đây họ bắt_đầu viết lại cả models và training loop cho chúng_bằng ngôn_ngữ rust thậm_chí có người khác còn port cả pytorch sang rust như đây và có <number> số examples về build và train models bằng rust hi_vọng với thông_tin này sẽ gợi_ý cho các bạn thêm phương_án trong lộ_trình học_tập và làm_việc ps cách đây vài tháng mình có biết elon musk còn có <number> post về rust nữa cơ có_lẽ tiềm_năng của rust sẽ rất lớn trong tương_lai gần,['#sharing']
mình đã nhìn thấy post này dưới comment khá lâu trong group có nhiều likes và shares nên thấy có trách_nhiệm phản_hồi kẻo nhiều bạn hiểu sai vấn_đề bạn chủ post nói đúng chỗ không nên nhắm_mắt điền giá_trị thiếu bằng <number> mà cần hiểu kỹ phân_phối của dữ_liệu tuy_nhiên nói tuyệt_đối không là rất hồ_đồ điều bạn quan_sát được chỉ đúng trong các trường_hợp bạn thấy đừng vội generalize ra toàn_bộ kẻo bị overfitting với những gì mình thấy những gì bạn phân_tích chỉ áp_dụng trong trường_hợp toàn_bộ các biến dạng số_thực với dữ_liệu hạng_mục thì không có khái_niệm knn kể_cả với dữ_liệu dạng số_thực thì scale của các biến ảnh_hưởng rất nhiều đến khoảng_cách giữa các điểm nên bạn nói là knn sẽ cho lựa_chọn chính_xác là chưa đúng về dữ_liệu bị khuyết cần có domain knowledge để hiểu dữ_liệu đó là khuyết ngẫu_nhiên hay không và dùng các phương_pháp tương_ứng xem <number> cho phù_hợp nếu không chắc cách impute missing data như thế_nào thì bắt_đầu với cách dễ nhất rồi xem_xét metrics và thử với nhiều cách khác nhau đừng tự đóng mình với một cái gì tuyệt_đối không tham_khảo <number> <number>,"['#sharing', '#data']"
tuyệt_đối không bao_giờ điền giá_trị thiếu bằng mean hoặc zero đây là những gì xảy ra khi chúng_ta thực_hiện fill value bởi mean <number> thay_thế điền giá_trị thiếu bằng trung_bình hoặc zero hoặc bất_kỳ giá_trị cố_định nào khác làm thay_đổi các thống_kê tóm_tắt làm thay_đổi phân_phối làm tăng sự hiện_diện của một giá_trị cụ_thể điều này có_thể dẫn đến làm mô_hình không chính_xác khiến kết_luận sai_lầm và nhiều hơn nữa thay vào đó luôn cố_gắng điền giá_trị thiếu với độ chính_xác cao hơn những trường_hợp như_vậy thì knn imputer thường là một lựa_chọn ưu_tiên hơn nó điền giá_trị thiếu bằng cách sử_dụng knearest neighbors các giá_trị trống sẽ được điền bằng cách chạy knn trên các giá_trị còn lại hiệu_quả của nó so với mean zero imputation thì hoàn_toàn được minh_họa như hình bên dưới mean zero thay_đổi thống_kê tóm_tắt và phân_phối knn imputer giúp giữ nguyên share by learning and sharing for machine learning ai download tài_liệu mình chia_sẻ tại,"['#sharing', '#data']"
xin chào anh_chị anh_chị cho em hỏi kỹ_năng kiến_thức chuyên_môn giữa ai engineer với ai researcher scientist có khả_năng bổ_trợ lẫn nhau không em muốn định_hướng theo hướng ai engineer nhưng thắc_mắc liệu việc tham_gia các lab đề_tài nghiên_cứu có giúp mình trong việc_làm kỹ_sư không như hiểu rõ các model hiểu thêm các công_nghệ ý_tưởng mới,['#Q&A']
"chào mọi người em có một tập dữ_liệu gồm các chuỗi thông_số ví_dụ 34,3,38,48,55 ... và nhãn của mỗi chuỗi này là <number> hoặc <number> bất_thường không bất_thường em nên dùng lstm hay model nào ok hơn em cảm_ơn","['#Q&A', '#deep_learning']"
em xin chào các anh_chị em đọc về mạng rnn dạng vec2seq trong sách có đoạn như hình bên dưới anh_chị nào hiểu được cái phương_trình <number> đó có ý_nghĩa như nào không hay cho em xin cách đọc nó em xin cảm_ơn rất nhiều chúc mọi người một ngày vui_vẻ bình an,"['#Q&A', '#deep_learning', '#math']"
chào cả nhà có thắc_mắc về cách funetune yolov8 để model có performance tốt hơn đang train yolov8 bằng default settings và có một_số vấn_đề đang gặp phải hàm loss đang mức rất cao cả trên tập training và val đang không biết tại_sao lại như vậy và có cách nào để giảm nó xuống không dataset là về fabric defect và có distribution như trong hình và không_thể thu_thập thêm data được nữa thì sử_dụng một_số mạng gan để sinh thêm dữ_liệu thì có hiệu_quả trong bài_toán này không hoặc áp_dụng thêm các kỹ_thuật augmentation nào khác ngoài default setting của yolov8 để có performance tốt hơn mọi người gợi_ý giúp em cách finetune các hyperparameter để có kết_quả tốt hơn được không đang train với card 2080ti 11gb default settings của yolov8 task detect mode train model yolov8s pt data root data andy yolo8 fabricv6 data yaml epochs <number> patience <number> batch <number> imgsz <number> save true save_period <number> cache false device null workers <number> project null name null exist_ok false pretrained false optimizer sgd verbose true seed <number> deterministic true single_cls false rect false cos_lr false close_mosaic <number> resume false amp true overlap_mask true mask_ratio <number> dropout <number> val true split val save_json false save_hybrid false conf null iou <number> max_det <number> half false dnn false plots true source null show false save_txt false save_conf false save_crop false show_labels true show_conf true vid_stride <number> line_width null visualize false augment false agnostic_nms false classes null retina_masks false boxes true format torchscript keras false optimize false int8 false dynamic false simplify false opset null workspace <number> nms false lr0 <number> lrf <number> momentum <number> weight_decay <number> warmup_epochs <number> warmup_momentum <number> warmup_bias_lr <number> box <number> cls <number> dfl <number> pose <number> kobj <number> label_smoothing <number> nbs <number> hsv_h <number> hsv_s <number> hsv_v <number> degrees <number> translate <number> scale <number> shear <number> perspective <number> flipud <number> fliplr <number> mosaic <number> mixup <number> copy_paste <number> cfg null v5loader false tracker botsort yaml save_dir runs detect train31 em cám_ơn cả nhà,"['#Q&A', '#deep_learning', '#cv']"
technical review đêm ngày <number> tháng <number> năm <number> gmt <number> <number> openai cho phép người dùng có_thể tự finetune model gpt3 <number> turbo model gpt4 sẽ được finetune vào mùa thu mùa thu bắc bán_cầu thường tính vào ngày <number> tới <number> hàng năm với giọng văn và các tính_năng mà người finetune muốn các bạn có_thể tham_khảo tại đây <number> meta giới_thiệu seamlessm4t multimodal ai model for speech and text translations trong đó có hỗ_trợ tiếng việt nhé các bạn xem chi_tiết tại đây và mở source tại đây <number> huggingface giới_thiệu idefics an open reproduction of stateoftheart visual language model,['#sharing']
vinai seminar principled frameworks for designing deep learning models efficiency robustness and expressivity register here to access seminar via ms teams speaker tan nguyen nus time <number> <number> am <number> <number> am gmt <number> aug <number> <number>,['#sharing']
góc nhờ tư_vấn tôi muốn hỏi về việc prompt engineering cho ảnh tạo sinh qua stable diffusion <number> có bạn nào chuẩn_bị dữ_liệu cả ảnh và text để finetune các models stable diffusion và controlnet chưa nếu có xin bạn hãy chia_sẻ kinh_nghiệm về việc này <number> kinh_nghiệm của bạn về việc prompt sao cho models sinh ra ảnh mà bạn mong_muốn mình xin cảm_ơn những chia_sẻ của các bạn trước nhé trân_trọng,['#Q&A']
xin chào mn có_thể nhiều người đã biết trang này nhưng mình thấy khá hữu_ích nên vẫn muốn chia_sẻ cùng mn nếu các bạn muốn tìm luận_văn hoặc luận_án của các trường dh trên thế_giới có_thể vào đây nhé ko đầy_đủ hết các trường nhưng lĩnh_vực khá đa_dạng tất_nhiên bao_gồm cả ai hi_vọng có_thể giúp_ích cho mn,['#sharing']
các cho em hỏi một vấn_đề nho_nhỏ em học về ocr và đang clone paddleocr bản release <number> về colab để train bài_toán text recognition tuy_nhiên khi clone về và chạy dòng lệnh như trên ảnh thì gặp lỗi trong file setup py có_thể cho em biết là tại_sao lỗi và các sửa như thế_nào không em xin chân_thành cảm_ơn lỗi này không phải do pip và em cũng đã tìm_hiểu nhiều mà mãi chưa sửa đc tt,"['#Q&A', '#cv']"
em được giao phân_loại ý_định của <number> người trong <number> đoạn hội_thoại ít_nhất <number> người anh_chị nào có kinh_nghiệm hay_biết có paper nào có_thể cho em xin chút hướng_dẫn không em search gần như chỉ có phân_loại ý_định của tất_cả mn em cảm_ơn,['#Q&A']
mọi người cho em hỏi có ai có bộ test data của cuộc thi phân_loại sắc_thái_bình_luận em cảm_ơn,"['#Q&A', '#nlp']"
em đang có bài_tập lớn dùng rnn hoặc lstm để cân_bằng kênh âm_thanh bro cũng mảng này không cho em xin ít kinh_nghiệm với,"['#Q&A', '#deep_learning']"
project dự_báo đột_quỵ tim heart attack full vừa_ý_nghĩa vừa học_tập tài_liệu hướng_dẫn từng step by step cho <number> project ml tìm_hiểu dữ_liệu quan_sát dữ_liệu pre processsing gán nhãn phân_loại dữ_liệu chia tệp data thành các biến độc_lập và phụ_thuộc chia data thành training test dataset tạo ml modeling function để áp_dụng thuật_toán phân_loại link tải file pdf link dataset kaggle share by learning and sharing for machine learning ai,['#sharing']
chào mọi người cài công_cụ annotation cvat trên windows qua git bash theo link hưỡng dẫn đến bước tạo superuser thì bị báo lỗi bash sudo command not found và docker exec it cvat_server bin bash the input device is not tty if you are using mintty try prefixing the command with winpty mng cho lời khuyên với cám_ơn mng nhiều,['#Q&A']
trí_tuệ nhân_tạo ai đã len_lỏi khắp nơi đi vào mọi ngóc_ngách của cuộc_sống công_việc giải_trí ... vậy có ai chợt đặt ra câu hỏi ai là gì tại_sao hiện_nay nó đang nhận được sự quan_tâm rất lớn từ khắp mọi ngành,['#sharing']
chào anh_chị và các bạn trong nhóm hiện_tại em đang làm <number> project về sinh giọng nói nhưng em lại không có nhiều kiến_thức về mảng này nên kết_quả ra không được như_ý cho em hỏi việt_nam của mình có cộng dồng nào xử_lý âm_thanh không vì em muốn tham_khảo <number> số kiến_thức cảm_ơn các bạn và anh_chị trong nhóm,['#Q&A']
em chào mọi người em có tập dữ_liệu là các bản tin trạng_thái của thiết_bị trong smart home gửi lên server từ tập dữ_liệu này xử_lý bài_toán nào được nhỉ ... em đang định phân_tích hành_vi người dùng nhưng cũng chưa biết kĩ_thuật sử_dụng ai có định_hướng và phương_pháp nào không giúp em với,['#Q&A']
có vẻ như các bạn khá thích_thú với các tài_liệu hướng_dẫn nhất là dưới dạng cookbook nay mình giới_thiệu thêm chắc_chắn có nhiều bạn đã biết tới về cookbook của openai hiện nó đã có tới 46k sao và được cập_nhật thường_xuyên mình chắc_chắn sẽ nghiền_ngẫm repository này,['#sharing']
có anh_chị nào đã từng dùng craft để trích xuất thông_tin thành_công chưa,['#Q&A']
kaggle cung_cấp các khóa học chất_lượng cao về khoa_học dữ_liệu,"['#sharing', '#data']"
các hệ_thống ovx tích_hợp nvidia gpu mới được thiết_kế để tăng_tốc quy_trình đào_tạo và suy_luận ai các tải xử_lý chuyên_sâu về đồ_họa một loạt các nhà cung_cấp lớn như dell technologies hewlett packard enterprise lenovo supermicro ... sắp cho ra_mắt sản_phẩm,['#sharing']
xin chào mn mn cho mình hỏi hiện_nay có mô_hình hoặc phương_pháp nào hiệu_quả trong việc detect những đối_tượng rất rất nhỏ tạm gọi tiny object mong được mn chia_sẻ,"['#Q&A', '#cv']"
padding trong convolutional neural network cnn là quá_trình thêm các giá_trị <number> hoặc giá_trị khác tuỳ theo cách thiết_lập vào xung_quanh các biên của ảnh hoặc đặc_trưng trước khi thực_hiện phép tích chập mục_đích chính của việc thêm padding là tăng kích_thước của đặc_trưng hoặc ảnh ban_đầu để đảm_bảo rằng các biên của ảnh cũng được xử_lý một_cách hiệu_quả có hai loại padding chính valid padding zero padding trong loại này không có padding được thêm vào và phép tích chập được thực_hiện trực_tiếp trên các vùng không_gian điều này dẫn đến việc giảm kích_thước của đặc_trưng hoặc ảnh sau khi thực_hiện phép tích chập same padding đây là loại padding phổ_biến trong đó padding được thêm vào sao cho kích_thước của đặc_trưng hoặc ảnh sau khi thực_hiện phép tích chập vẫn giữ nguyên kích_thước so với ban_đầu thông_thường giá_trị padding được tính dựa trên kích_thước của ma_trận bộ lọc và các bước của phép tích chập padding có_thể giúp duy_trì thông_tin biên của ảnh hoặc đặc_trưng sau khi thực_hiện phép tích chập và giúp tránh việc mất_mát thông_tin quá nhiều nó cũng có_thể giúp kiểm_soát việc giảm kích_thước quá nhanh của đặc_trưng đặc_biệt khi sử_dụng nhiều lớp tích chập liên_tiếp,"['#sharing', '#deep_learning']"
hi_mng em có một_số thắc_mắc giai_đoạn tiền xử_lý data khi mình làm về object detection lúc mình đã có một tập dữ_liệu được label từ tool labelimg trên github thì em thấy thường thì sẽ phải cần tiền xử_lý dữ_liệu này rồi mới cho vào train em có đọc một pj trên kaggle thì thấy ngta để mục đó là data pipeline thì em không hiểu lắm về cụ_thể các bước trong đây mình cần làm gì mình có những giai_đoạn nào những việc làm gì mình cần để_ý tới và cần phải làm trong bước này data pipeline và preprocessing data mong mọi người giúp em nếu được thì mọi người có_thể cho em một_số trang hoặc sách có nói cụ_thể về quá_trình này được không em cảm_ơn mọi người,"['#Q&A', '#data', '#cv']"
chào các bạn các bạn cho mình hỏi framework nào về reinforcement learning good nhất cho training một agent,"['#Q&A', '#machine_learning']"
hiệp_hội openusd alliance for openusd sẽ tiến đến đảm_bảo khả_năng tương_thích hoàn_toàn cho các nội_dung và công_cụ 3d nhằm triển_khai số hóa giữa các ngành công_nghiệp,['#sharing']
mạng nơron tích chập cnn là một kiến_trúc mạng nơron đặc_biệt dành cho việc xử_lý dữ_liệu hình_ảnh và giúp máy_tính hiểu và phân_tích hình_ảnh một_cách tự_động nguyên_tắc hoạt_động của cnn dựa trên ba khái_niệm chính tích chập tổng_hợp và kích_hoạt tích chập convolution lớp tích chập là lớp đầu_tiên trong mạng cnn nó sử_dụng các bộ lọc hay còn gọi là kernel để trượt qua ảnh đầu_vào mỗi bộ lọc có_thể nhận_biết các đặc_trưng cụ_thể trong ảnh như cạnh góc hoặc hình_dạng khi bộ lọc trượt qua ảnh nó tạo ra các bản_đồ đặc_trưng feature maps bằng cách thực_hiện phép tích chập giữa bộ lọc và vùng tương_ứng trên ảnh các bản_đồ đặc_trưng này giúp mô_hình nhận_biết các đặc_trưng quan_trọng trong hình_ảnh tổng_hợp pooling lớp tổng_hợp thường đặt sau lớp tích chập nhiệm_vụ của lớp này là giảm kích_thước của các bản_đồ đặc_trưng bằng cách lấy giá_trị lớn nhất hoặc trung_bình từ các vùng nhỏ trên bản_đồ đặc_trưng việc này giúp giảm số_lượng tham_số và chi_phí tính_toán đồng_thời làm giảm nguy_cơ overfitting kích_hoạt activation lớp kích_hoạt áp_dụng một hàm kích_hoạt phi_tuyến lên các giá_trị trong các bản_đồ đặc_trưng phép kích_hoạt này giúp mô_hình_học cách biểu_diễn các đặc_trưng phức_tạp và tạo tính phi_tuyến cho mạng lớp kết_nối đầy_đủ fully connected layer sau khi thông_qua các lớp tích chập tổng_hợp và kích_hoạt dữ_liệu được đưa vào lớp kết_nối đầy_đủ để thực_hiện các tác vụ như phân_loại hoặc dự_đoán trong lớp này các nơron kết_nối với tất_cả các nơron trong lớp trước giúp học cách tổ_hợp các đặc_trưng để đưa ra dự_đoán cuối_cùng toàn_bộ quá_trình này từ lớp tích chập cho đến lớp kết_nối đầy_đủ là quá_trình học tự_động mạng nơron tự điều_chỉnh các trọng số của các lớp để tối_ưu_hóa hiệu_suất cho nhiệm_vụ cụ_thể chẳng_hạn như phân_loại ảnh,"['#Q&A', '#deep_learning']"
chào các chị của group em có_học và tập_tành ứng_dụng ai được trong khoảng hơn <number> năm thì có một_vài thắc_mắc mong chị có_thể giải_đáp giúp em em có thử hai mảng lớn là cv và nlp và cũng tìm_tòi các paper đọc để hiểu idea rồi so_sánh với các idea khác cũng như rèn_luyện kỹ_năng lập_trình tương_ứng cho các paper thì có thấy một điều là nghành này quá rộng để đào_sâu cho từng chuyên_môn nếu muốn đạt level expert cái này đặt ra cho em thắc_mắc là liệu có cái gọi là ai engineer hay không khi mà lượng kiến_thức của một mảng ví_dụ nlp đã thực_sự rất sâu rồi theo em sâu là hiểu cặn_kẽ biết ưu nhược_điểm và biết cách tìm ra solution tối_ưu chưa kể các vấn_đề liên_quan như data deploy etc vậy theo cái title của vị_trí kia thì đồng_nghĩa họ phải hiểu sâu rất nhiều mảng phải không nhiều khi còn cả mấy mảng mở_rộng như kiểu generative video 3d etc trong thực_tế thì một flow làm_việc thì mọi người thường chọn cách tiếp_cận với mô_hình_như nào mọi người sẽ code lại paper từ đầu rồi tweak thủ_công hay_là sẽ bê nguyên wrapper như kiểu huggingface để sử_dụng các vấn_đề chuyên_sâu về mlops thì một kỹ_sư trong mảng này nên có trong khoảng bao năm kinh_nghiệm là tốt liệu nhân_lực mảng này và mảng software nói_chung sẽ giao_thoa về những skills gì theo em nghĩ là lập_trình nói_chung cloud design em cảm_ơn chị nhiều,['#Q&A']
chào cả nhà em là dân ngoại_đạo y_khoa nhưng đang dịch một bài báo liên_quan đến sự kết_hợp giữa ml và y_học hiện_tại em đã dịch xong rồi nhưng cần người có chuyên_môn review vì em không phải người trong ngành nên sợ chưa dùng từ đúng chuẩn xin cả nhà giúp_đỡ,['#Q&A']
kubernetes k8s không còn là một công_cụ chỉ để chạy các workload như ứng_dụng web hay microservices nó chính là nền_tảng lý_tưởng để hỗ_trợ toàn_bộ vòng đời của các workload lớn về trí_tuệ nhân_tạo ai và học máy ml chẳng_hạn như các mô_hình ngôn_ngữ lớn llms,['#sharing']
mình tin đây có nhiều bạn biết đến trang này do các bạn ấn độ viết để hướng_dẫn về giải_thuật bằng các ngôn_ngữ khác nhau trong đó repo có nhiều sao nhất với hơn 164k hi_vọng mình chia_sẻ đây cho các bạn chưa biết tới nó có_thể là tài_liệu tham_khảo tốt cho mọi người,"['#sharing', '#math']"
xin chào cac ban minh đã tong hop một repo cung_cấp các tài_nguyên cho ood detection robustness and generalization in deep learning repo nay bao gom các bài báo bài nói_chuyện thư_viện papers repo này sẽ được duy_trì và cập_nhật với các nguồn chất_lượng cao minh hy_vọng nó sẽ trở_thành mot noi lý_tưởng cho bất_kỳ thứ gì ood trong bookmark của bạn hãy cho nó một ngôi_sao de_ung ho minh nếu bạn thấy nó hữu_ích cam on nhieu nha,"['#sharing', '#deep_learning']"
các nhà nghiên_cứu từ các trường đại_học của anh đã phát_triển một ai có khả_năng dự đoán thao_tác gõ phím của người dùng với độ chính_xác <number> bằng cách lắng_nghe âm_thanh phát ra khi gõ trên bàn_phím,['#sharing']
em chào các tiền_bối nay em ngoi lên đây để xin các tiền_bối xem có quyển sách vào về reinforcement learning hay không kiểu vừa có code implemented vừa có phần giải_thích em xin chân_thành cảm_ơn,['#Q&A']
hi_mng em đang làm một mô_hình nó nhận_diện được con_lắc đơn em có chuẩn_bị một tập dữ_liệu bằng các hình_ảnh con_lắc đơn và dùng labelimg để label ảnh sau đó cho nó vào một file csv em có thử train model trên tập dữ_liệu đó thì nó cho ra một kết_quả như ảnh dưới đây thì em có thắc_mắc là liệu đây có fai một trường_hợp overfitting và làm_sao để có_thể sửa nó em có một câu hỏi nựa là sau khi em train xong như_vậy thì em sẽ làm như nào để model có_thể đưa ra dự_đoán vậy mong mọi người giải_đáp em là newbie nên có những chỗ em chưa hiểu,"['#Q&A', '#cv']"
hi mọi người mình có_học về vision transfomer và thấy trong kiến_trúc đó có <number> thứ gọi là residual connection kết_nối dư nó sẽ lấy input của <number> lớp trong <number> khối ví_dụ như khối multi selfattention nối với output của lớp cuối_cùng trong khối đó mình đọc thì họ nói là trong quá_trình truyền ngược <number> số hàm kích_hoạt phi tuyến_tính sẽ bị bỏ_qua nhưng mình vẫn lấn_cấn <number> số thứ như là cụ_thể mục_đích và nguyên_nhân họ bỏ_qua <number> số lớp hay hàm kích_hoạt là gì hàm kích_hoạt hay lớp kiểu sẽ bị loại_bỏ và tại soa họ lại nối input của <number> lớp này với output của lớp cuối_cùng ai có kiến_thức giải_đáp giúp mình với thank mọi người,"['#Q&A', '#deep_learning']"
mọi người cho em hỏi là trong bài_toán của computer vision như object detection segmentation thì thường các cty sẽ tận_dụng các model đã có sẵn để ứng_dụng trực_tiếp vd như yolo detectron hay sẽ phần_lớn là tự build lại em cảm_ơn,"['#Q&A', '#cv']"
hi mọi người hôm_nay vietcuna trình bản phiên_bản thứ <number> của llm vietcuna 7b đây là một bản big update từ một mô_hình instruction only sang model chat ngoài_ra khả_năng code cũng cải_thiện đáng_kể đặc_biệt vietcuna sẽ cho phép bạn dùng trực_tiếp trên web như chatgpt và sẽ luôn miễn_phí link ngoài_ra bạn có_thể tự tải và host model finetune theo use case cụ_thể của mình từ huggingface chú_ý đọc kĩ model card từ phiên_bản thứ <number> trở_đi vietcuna chính_thức miễn_phí cho mọi mục_đích sử_dụng link huggingface chúc mọi người có một trải nghiệm thật tốt,"['#sharing', '#nlp']"
các bác ơi có bác nào đang dùng api ai làm nét ảnh giống snapedit hoặcredmini ko cho xin gợi_ý một_số api với free càng tốt cám_ơn các bác nhiều,['#Q&A']
mô_hình onconpc được nghiên_cứu và phát_triển tại mit và viện ung_thư danafarber cho phép dự_đoán và xác_định nơi hình_thành khối_u trước di_căn thông_qua phân_tích khoảng <number> gen thường bị đột_biến trong ung_thư từ đó đưa ra các liệu_trình điều_trị phù_hợp và hiệu_quả hơn so với trước đây một bước_tiến mới trong việc áp_dụng ai vào y_học các bạn có_thể đọc thêm qua bài viết của mit bên dưới,"['#sharing', '#cv']"
mọi người ơi em được biết là thường thì loss function sử_dụng lúc train và lúc test không giống nhau mọi người cho em hỏi cách xây_dựng loss function lúc train và lúc test khác nhau như thế_nào ngoài phần khác nhau về regularization thì chúng còn khác nhau phần loss trung_bình mọi người giúp em hiểu rõ hơn về vấn_đề này với em cảm_ơn nguồn machine learning mì súp và ...,"['#Q&A', '#math', '#machine_learning']"
em chào mọi người em có đọc qua các bài viết về xai về mặt lý_thuyết là nó không phải blackbox tuy_vậy em vẫn còn những câu hỏi nhưng thế_nào là blackbox và các mô_hình_như cnn và transformer có là các blackbox hay không những tiêu_chuẩn nào để đánh_giá một mô_hình là blackbox em cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
dạ em chào các anh_chị và các bạn trong group em là người mới bắt_đầu học nên muốn tìm các sách về machine learning bằng tiếng việt anh chị bạn nào có sách giấy đã học xong không dùng nữa có_thể pass lại cho em không em sài_gòn,"['#Q&A', '#machine_learning']"
chào mọi người em là người mới học ml em đang làm <number> dự_án phân_loại_hình_ảnh <number> số loại hoa thông_qua app model của em chạy phía server chuyện là em dùng model mobilenet_v2 của tensorflow hub để transfer sau đó lưu model bằng lệnh model save os path join content drive mydrive models flower h5 sau đó load lại và sử_dụng model bằng cách gọi flower_model tf keras models load_model model flower model_flower h5 custom_objects keraslayer hub keraslayer nó hoạt_động bình_thường nhưng sau đó <number> khoảng thời_gian thì nó lại không chạy được nó báo exception encountered trying to load model of incompatible unknown type users lenovo appdata local temp tfhub_modules 145bb06ec3b59b08fb564ab752bd5aa222bfb50a contains neither saved_model pb nor saved_model pbtxt về cơ_bản thì em đã có_thể fix được lỗi bằng cách xóa cái folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a đi để tiến_hành tải lại cái mới nó hoạt_động bình_thường nhưng đấy chỉ là cách trị ngọn thôi không trị được gốc vì sau <number> khoảng thời_gian nó lại ko hoạt_động những gì em hiểu được là tensorflow sẽ tạo một thư_mục tạm_thời để giữ các mô_hình đã tải tuy_nhiên sau một_vài ngày hoặc lâu hơn nội_dung của các foler mô_hình đã tải sẽ bị xóa sau đó khi muốn tải lại một mô_hình tensorflow sẽ định_tuyến đến thư_mục tạm_thời nhưng mô_hình sẽ bị xóa khỏi thư_mục tạm_thời tức_là cái cần_thiết để chạy pre model là một model tải từ tensorflow hub đang được lưu_trữ <number> thư_mục tạm_thời thư_mục sẽ bị xóa sau một khoảng thời_gian vì_vậy nó sẽ gây ra lỗi ko tìm thấy file pb hay pbtxt để chạy model em nghĩ rằng lỗi sẽ nằm phần tensorflow nó quản_lý tự_động file pb pbtxt khiến cho mình ko thể chỉ_định chính_xác <number> file pb và pbtxt vào <number> đường_dẫn cụ_thể ko thể bị xóa_tự_động hoặc lỗi gây ra bởi quá_trình load model mọi người ai đã từng gặp lỗi tương tụ như_vậy chưa cho em hướng_dẫn fix với đây là những gì trong folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a,"['#Q&A', '#python', '#cv']"
cuốn sách không_thể bỏ_qua về automated machine learning cuốn sách này giúp bạn hiểu rõ về automl tự_động hóa quá_trình học máy hiểu về automl và vai_trò quan_trọng của automl trong việc đơn_giản_hóa quá_trình học máy khám_phá các phương_pháp và kỹ_thuật sử_dụng trong automl từ việc chọn đặc_trưng lựa_chọn mô_hình điều_chỉnh siêu tham_số đến đánh_giá mô_hình tìm_hiểu về các hệ_thống và công_cụ automl hiện có trên thị_trường qua các ví_dụ và nghiên_cứu thực_tế đối_mặt và vượt qua các thách_thức như khả_năng mở_rộng khả_năng giải_thích và xử_lý dữ_liệu phức_tạp độ tin_cậy trong các hệ_thống học máy tự_động cuốn sách cung_cấp các ứng_dụng thực_tế của automl trong các lĩnh_vực khác nhau như y_tế tài_chính và marketing giúp bạn thấy rõ lợi_ích của automl trong việc xây_dựng mô_hình_học máy chính_xác một_cách nhanh_chóng link download qua drive dưới comment tài_liệu được chia_sẻ bởi learning and sharing for machine learning ai,"['#sharing', '#machine_learning']"
mạng nơron hồi quy đa lớp phân_tán distributed multilayer recurrent neural network dmrnn là một kiểu mạng nơron hồi quy rnn được thiết_kế để xử_lý thông_tin từ nhiều nguồn đồng_thời và đa lớp nó là một biến_thể của mạng nơron hồi quy đa lớp mlrnn trong đó các đơn_vị nơron trong mạng được phân_chia thành nhiều nhóm và mỗi nhóm chỉ xử_lý một phần của dữ_liệu đầu_vào mô_hình dmrnn giúp cải_thiện hiệu_suất của mạng hồi quy khi xử_lý dữ_liệu phức_tạp và đa nguồn như trong các ứng_dụng như xử_lý ngôn_ngữ tự_nhiên nhận_dạng giọng nói dự_đoán chuỗi thời_gian và nhiều tác vụ học_tập khác bằng cách phân_tán các đơn_vị nơron mạng dmrnn có khả_năng xử_lý thông_tin từ nhiều nguồn cùng một lúc và truyền_tải thông_tin giữa các lớp mạng một_cách hiệu_quả các ưu_điểm của mạng dmrnn bao_gồm xử_lý đa nguồn mạng dmrnn cho phép xử_lý thông_tin từ nhiều nguồn đồng_thời giúp cải_thiện khả_năng mô_hình_hóa dữ_liệu phức_tạp và đa_dạng hiệu_quả tính_toán do các đơn_vị nơron được phân_tán và chỉ xử_lý một phần dữ_liệu mạng dmrnn có khả_năng tính_toán hiệu_quả và tránh các vấn_đề về tính_toán phức_tạp tính linh_hoạt mạng dmrnn có tính linh_hoạt cao trong việc kết_hợp các nguồn thông_tin khác nhau và điều_chỉnh kiến_trúc mạng dễ_dàng để phù_hợp với các tác vụ xử_lý dữ_liệu cụ_thể tuy_nhiên mạng dmrnn cũng có một_số thách_thức bao_gồm đòi_hỏi nhiều dữ_liệu huấn_luyện do mô_hình có nhiều tham_số và cấu_trúc phức_tạp việc huấn_luyện mạng dmrnn có_thể đòi_hỏi một lượng lớn dữ_liệu huấn_luyện để đạt được hiệu_suất tốt điều_chỉnh tham_số phức_tạp việc điều_chỉnh các tham_số và kiến_trúc của mạng dmrnn có_thể phức_tạp và đòi_hỏi sự chuyên_môn cao một_số ứng_dụng của mạng dmrnn bao_gồm xử_lý ngôn_ngữ tự_nhiên nhận_dạng giọng nói dự_đoán chuỗi thời_gian và phân_tích dữ_liệu chuỗi mô_hình này đã đem lại những kết_quả đáng_kể trong việc xử_lý và phân_tích dữ_liệu phức_tạp và đa nguồn,"['#deep_learning', '#sharing']"
chào các anh_chị anh_chị cho hỏi em mới bắt_đầu học các khóa ml của bác andrew ng trên cousera thì thấy cuối thường có optional lab nhưng mà nó không giải_thích ý_nghĩa cách dùng từng câu_lệnh vậy em phải tự học thêm cách sử_dụng mấy thư_viện như numpy ... ngoài phải không tại em cũng chưa biết gì về python lắm em xin cảm_ơn,"['#machine_learning', '#Q&A', '#python']"
cho bạn nào chưa biết cũng như vẫn đang đợi request từ meta để access llama <number> hiện_tại meta đã mở link mới để request access vào llama <number> các bạn có_thể điền form lại cũng như đồng_bộ với repo của meta trên hugging face email khi bạn điền form phải đúng với email tài_khoản trên huggingface mới access được repo nhé bạn nào muốn trải nghiệm model llama <number> có_thể đăng_ký qua form bên dưới,['#sharing']
góc tìm developers xin update vẩn cần team làm được tài_chính <number> chịu quay đầu hợp_đồng công_chứng đàng_hoàng xin chào anh_em mình có vài idea_vầy có anh_em nào có_thể làm forex stock crypto metal trading engine như sau không xin chân_thành tìm được người xin cám_ơn cái devs,['#sharing']
tiếp_theo series ngày hôm_qua thì hôm_nay thêm đoạn train lora để sinh ra các ảnh theo cách của riêng mình hi_vọng giúp được các bạn mới học trên con đường tìm_hiểu về phần link video để phần bình_luận nhé sorry vì ko hiểu sao ông face bóp tương_tác các post có link trong này khó hiểu thật_sự,"['#sharing', '#cv']"
kính gửi các bác tranh_thủ đang học về stable diffusion em mạnh_dạn làm clip chia_sẻ cùng cả nhà clip chỉ với mục_đích tìm_hiểu siêu cơ_bản về sd và hướng tới các bạn mới học hi_vọng giúp được các bạn,"['#sharing', '#deep_learning']"
mô_hình_học_tập không đối_xứng asymmetric learning model là một loại mô_hình_học máy hoặc mô_hình_học_tập trong đó quá_trình học và điều_chỉnh các trọng số của mạng neuron được thực_hiện không đối_xứng giữa các kết_nối nơron trong mô_hình_học_tập đối_xứng các trọng số của mạng neuron được điều_chỉnh cùng một lượng cho tất_cả các kết_nối nơron tức_là khi mạng nhận được một tín_hiệu đầu_vào và tạo ra đầu_ra tương_ứng tất_cả các trọng số sẽ được điều_chỉnh theo cùng một_cách để giảm_thiểu sai_số giữa đầu_ra thực_tế và đầu_ra mong_đợi tuy_nhiên trong mô_hình_học_tập không đối_xứng quá_trình điều_chỉnh các trọng số có_thể không được thực_hiện cùng một_cách cho tất_cả các kết_nối nơron thay vào đó điều_chỉnh trọng số có_thể được tùy_chỉnh theo cách không đối_xứng dựa trên đặc_điểm của dữ_liệu đầu_vào và đầu_ra điều này cho phép mô_hình_học_tập chủ_động tập_trung vào việc học các mẫu phức_tạp hoặc quan_trọng hơn trong dữ_liệu trong khi loại_bỏ những mẫu ít quan_trọng hoặc nhiễu mô_hình_học_tập không đối_xứng có_thể có ứng_dụng trong nhiều lĩnh_vực của học máy và trí_tuệ nhân_tạo và nó là một trong những phương_pháp mở_rộng và tối_ưu_hóa học_tập truyền_thống để đạt được hiệu_suất cao hơn và khả_năng tương_thích với các tác vụ phức_tạp hơn,"['#sharing', '#machine_learning']"
chào mọi người trong nhóm mình ai có code về faster cnn thì cho mình tham_khảo với nếu được là triển_khai từ đầu toàn_bộ không dùng model có sẵn nhé mọi người mình muốn hiểu kĩ hơn và tiếp_cận nó tốt hơn cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
kiến_trúc và cách hoạt_động stable diffusion,"['#sharing', '#deep_learning']"
tài_liệu khóa học nlp chất_lượng cao cs224n của đh stanford,"['#sharing', '#nlp']"
chào mọi người sắp tới em có buổi phỏng_vấn vị_trí intern ai anh_chị có_thể cho em biết các câu hỏi phỏng_vấn thường gặp hay tắc tình_huống khi đi phỏng_vấn này được không em cảm_ơn,['#Q&A']
<number> python project có source code phù_hợp cho tất_cả các bạn newbie beginers intermediate advanced,"['#sharing', '#python']"
"một sinh_viên harvard maya bodnick đã kiểm_tra khả_năng của gpt4 trong việc viết các bài luận khoa_học xã_hội và nhân_văn năm thứ nhất kết_quả là gpt4 đạt điểm trung_bình 3,57 đáng nể","['#sharing', '#nlp']"
python và tài_chính dự_đoán chỉ_số chứng_khoán vnindex bằng model logistic regression chứng_khoán vnindex là chỉ_số chung của thị_trường chứng_khoán việt_nam và đóng vai_trò quan_trọng trong việc đo_lường sự_biến_động và phản_ánh xu_hướng của thị_trường dự_đoán biến_động của vnindex có_thể hỗ_trợ nhà đầu_tư và các chuyên_gia_tài_chính trong việc đưa ra quyết_định thông_minh về đầu_tư và quản_lý rủi_ro trong bài viết này hãy cùng icls tech tìm_hiểu cách sử_dụng mô_hình logistic regression để dự_đoán chỉ_số chứng_khoán vnindex và đạt tỷ_lệ đúng dự_đoán trên <number> nhé nguồn icls tech,"['#machine_learning', '#python', '#sharing']"
góc tư_vấn hi cho mình hỏi rằng liệu laptop macbook pro m2 có phù_hợp việc học cho lập_trình machine learning không và việc cài_đặt thư_viện cho machine learning trên macbook m2 có tương_thích hay_là bị xung_đột nhiều ko mình định mua laptop macbook pro m2 để học ml thôi chưa cần phải làm_việc vs khối_lượng lớn dữ_liệu như khi đi làm đâu thanks,"['#Q&A', '#machine_learning']"
chào mọi người dự_định học thạc_sĩ và nghiên_cứu vào machine learning mới bắt_đầu học nên không biết rõ <number> số môn nên học trước hay sau cụ_thể trong trường có <number> số môn tự chọn và tính là sẽ học machine learning trước sau đó sẽ là deep learning nhưng có <number> môn là data warehousing and big data thì không biết là môn này có liên_quan mật_thiết với việc học machine learning không và nên học nó trước hay sau machine learning và deep learning tương_tự với môn cloud computing cảm_ơn,"['#Q&A', '#machine_learning']"
có_thể nhiều người biết rồi nhưng mình thấy channel này trên youtube khá hay trong đó có nhiều playlists cho statistics ml deeplearning ...,"['#sharing', '#machine_learning']"
chào mọi người hiện_tại nhóm em mình đang thực_hiện một khóa luận tốt_nghiệp về thử đồ ảo và gợi_ý trang_phục virtual tryon outfit recommendation nhóm có xây_dựng một website kisekloset hỗ_trợ <number> tính_năng này với mục_đích giúp tăng trải nghiệm khi mua_sắm quần_áo online hệ_thống sẽ cho phép thử đồ ảo từ ảnh người_mẫu và ảnh áo hiện_nay chỉ mới chỉ hỗ_trợ thử áo sau đó đề_xuất thêm các trang_phục dựa vào mẫu áo bạn sử_dụng và các thông_tin cung_cấp thêm dưới dạng text mọi người có_thể đọc thêm hướng_dẫn trong trang_web để biết thêm chi_tiết cách sử_dụng rất mong mọi người dành chút thời_gian để trải nghiệm thử ứng_dụng và đánh_giá mọi ý_kiến của mọi người đều rất giá_trị để nhóm đánh_giá và cải_tiến ứng_dụng link website or thevncorelab mooo dot com <number> mong mọi người cho ý_kiến qua khảo_sát em mình xin cảm_ơn,"['#sharing', '#machine_learning']"
trực_quan_hóa mạng neural network trang_web là một công_cụ trực_quan và tương_tác cho phép người dùng thử_nghiệm và học_tập về các mô_hình mạng nơron neural network đơn_giản,"['#sharing', '#deep_learning']"
các anh_chị_em cho mình hỏi sg chỗ nào đào_tạo ngoài giờ data sientist ổn vậy mình cảm_ơn mọi người,"['#Q&A', '#data']"
chào mọi người em là sinh_viên năm tư ngành khoa_học máy_tính hiện_tại và nhóm đang phát_triển một ứng_dụng quét đơn thuốc tự_động ứng_dụng sẽ quét ảnh chụp đơn thuốc giúp người dùng tra_cứu thông_tin về các loại thuốc mình đang sử_dụng đồng_thời có_thể đặt lịch uống thuốc để tránh trường hơp sử_dụng thuốc không đúng cách ứng_dụng của nhóm đã có_thể tải xuống trên của hàng play store do không đủ kinh_phí nên chưa thể đăng lên appstore rất mong mọi người dành ít thời_gian trải nghiệm ứng_dụng mọi phản_hồi của mọi người đều rất giá_trị với nhóm chúng em em xin chân_thành cảm_ơn link tải app ps em có đính kèm qr với ảnh demo test app bên dưới mn có_thể tải và sử_dụng nhé,"['#sharing', '#cv']"
mình xin phép chia_sẻ cho mọi người bài viết giải_thích chi_tiết về paper llama2 một llm đình_đám của meta mới ra_mắt đình_đám trong tuần vừa_qua hi_vọng rằng nó sẽ làm thay_đổi nhiều thứ trong tương_lai của llm,"['#sharing', '#deep_learning']"
em được giao bài_toán phân_loại văn_bản nhưng trước_tiên phải phát_hiện slot trước rồi sau đó phân_loại văn_bản sẽ dựa vào những slot đó kết_hợp ngữ_nghĩa câu để phân_loại em có tìm những paper về joint intent and slot filling hay model diet đều theo kiểu phân_loại trước rồi từ phân_loại văn_bản mới tìm slot nên bị ngược với bài_toán của em em có thử lấy các model ấy test thì kết_quả còn tệ hơn nếu mình chỉ dùng mỗi model như bert để phân_loại không biết anh_chị có link paper nào có_thể share cho em với được không nhỉ em kiếm mãi không tìm thấy paper nào làm như_vậy em cảm_ơn,"['#Q&A', '#nlp']"
mình có <number> bài_toán như sau mình có input là tên <number> vật dạng text và mình muốn ra output là mô_tả của vật đó dạng text mô_tả của vật thì có <number> format nhất_định vdu nó là động_vật hay thực_vật rồi thuộc họ có mấy chân vvv mình ko làm về nlp nên ko rõ hiện_tại có kĩ_thuật có_thể làm đc hoặc các bạn có_thể gợi_ý keywords cũng đc mình cảm_ơn nhiều,"['#Q&A', '#nlp']"
"meta và microsoft hợp_tác công_bố llama <number> có phiên_bản chat cho phép thương_mại_hóa một_số thông_tin quan_trọng dữ_liệu <number> nghìn tỉ tokens nhiều hơn <number> so với llama <number> context length <number> kích_cỡ 7b 13b 70b tham_số phiên_bản 34b chưa được công_bố vì chưa đạt tiêu_chí an_toàn hai phiên_bản llama2 và llama2chat được supervised finetune trên hơn 100,000 samples và huấn luyên với rlhf trên hơn <number> triệu samples nguồn ảnh real ml memes nguồn vietai","['#sharing', '#deep_learning']"
chào mọi người mình đang có model classification có input <number> ảnh và đâu ra là label <number> hoặc <number> hình bên dưới tuy_nhiên phần data preparation em không biết chuẩn_bị thế_nào mặc_dù có nghiên_cứu nhiều blog trên mạng tuy_nhiên gặp khá nhiều lỗi blog bên dưới là code data preparation với imagedatagenerator mong hướng_dẫn phần data preparation cho model <number> input ảnh mình cảm_ơn,"['#Q&A', '#cv', '#data']"
chào mọi người bên em đang làm <number> dự_án trading forex và hàng_hóa mọi người cho em hỏi là model machine learning nào phù_hợp_nhất dùng cho trading bộ data thì bên em đang lấy tạm trên tradingview xuống em cám_ơn,"['#Q&A', '#machine_learning']"
nhờ các anh giúp em xác_định output và input em dùng machine learning trong visual studio sử_dụng tính_năng object detection ra được file onnx như thế này nhưng khi mình điền input và ouput vào pipeline dùng thư_viện ml net thì báo sai input và output không biết tại_sao columnname input vectortype <number> <number> <number> <number> public float input get set columnname boxes vectortype <number> <number> public float boxes get set columnname labels vectortype <number> public long labels get set columnname scores vectortype <number> public float scores get set var pipeline context transforms resizeimages resizing microsoft ml transforms image imageresizingestimator resizingkind fill outputcolumnname resize imagewidth <number> imageheight <number> inputcolumnname nameof rtfinput imagesource append context transforms extractpixels offsetimage 127f scaleimage <number> 128f inputcolumnname resize outputcolumnname input append context transforms applyonnxmodel modelfile modelfile inputcolumnnames new string input outputcolumnnames new string scores boxes labels,"['#Q&A', '#deep_learning']"
hi_mng nha em là sv bên ngành tự_động_hoá trường bk hcm đợt làm luận_văn vừa_rồi em có làm đề_tài về 3d object detection và 6d pose estimation application for robotics bin picking system thì khá thích và đam_mê về mảng computer vision machine vision muốn theo sau khi tốt_nghiệp nên sau khi vừa hoàn_tất chương_trình học đợt tháng <number> vừa_rồi thì em có tự học kha_khá các thuật_toán của machine learning thì có tham_khảo các bên tuyển_dụng hiện có thì phần_lớn các bên tuyển_dụng sẽ hướng đến ai engineer luôn và sẽ đòi_hỏi biết cả computer vision và nlp thì em phân_vân bây_giờ có cần học luôn kiến_thức cả nlp và cv luôn không hay tập_trung đẩy_mạnh mảng cv tại em cũng muốn rút ngắn thời_gian tự học để có_thể xin đi intern tích thêm kinh_nghiệm thay_vì chờ học xong full tất_cả thì quá lâu hi_vọng mng có_thể cho em tí lời khuyên em cảm_ơn,"['#Q&A', '#cv']"
mọi người cho em hỏi em có <number> bộ dữ_liệu khá lớn nếu mà train cả <number> epoch thì sẽ quá thời_gian chạy tối_đa trên kaggle nên em định chia đôi thành <number> datasets và làm theo <number> trong <number> cách sau được không hay_là nên làm theo cách khác tốt hơn <number> train luân_phiên <number> epoch với dataset <number> rồi đến <number> epoch với dataset <number> <number> train xong với dataset <number> rồi train tiếp đến dataset <number> em cảm_ơn,"['#Q&A', '#machine_learning', '#data']"
mọi người cho em hỏi với text to speech để đạt được chất_lượng thương_mại như của vbee vietel fpt thì họ cần khoảng bao_nhiêu giờ dữ_liệu vậy bỏ_qua vấn_đề kỹ_thuật,"['#Q&A', '#nlp']"
hi mọi người em đang tìm_hiểu và sử_dụng yolov7 pose em thấy tác_giả đề_cập đến model này dựa theo bài báo em là newbie trong mảng này nên chưa biết model hoạt_động như thế_nào làm thế_nào để lấy được keypoint ... mong mọi người chỉ_giáo mọi người có resources nào thì cho em tham_khảo với em xin chân_thành cảm_ơn,"['#Q&A', '#deep_learning']"
em chào mọi người em đang làm bài_toán sử_dụng local naive bayes nearest neighbour phân_loại ảnh thú cưng chuột mèo tập train của mỗi class sẽ có <number> ảnh các ảnh đều lấy từ trên mạng em có sử_dụng sift để rút trích đặc_trưng nhưng kết_quả ko đc như mong_muốn em xin hỏi liệu có phương_pháp đê cải_thiện bài_toán không em cảm_ơn,"['#Q&A', '#cv', '#machine_learning']"
chào các bạn nguyên_văn của chuyên_gia computer vision fpt có đoạn viết cho bài_toán chứng_minh_thư <number> cropper tác vụ này xác_định <number> góc của thẻ cmnd và sau đó cắt về dạng ảnh chữ nhật ý_nghĩa chính của tác vụ là phục_vụ cho việc detector liền kề sau đó dễ_dàng hơn các mô_hình phát_hiện đối_tượng object detection phổ_biến hiện_nay chỉ trả về <number> góc trái trên phải dưới hoặc tâm box kèm giá_trị chiều ngang_dọc giúp ta định_hình một box hình chữ_nhật chúng_tôi sử_dụng một mẹo nhỏ bằng cách coi mỗi góc của cmnd là một đối_tượng và sau đó phát_hiện <number> góc này tiếp_theo đó bằng cách áp_dụng một_vài phép biến_đổi hình_học cơ_bản để cắt về dạng ảnh chữ nhật mô_hình phát_hiện mà nhóm nghiên_cứu đang sử_dụng là bộ phát_hiện đơn pha ssd ssd single shot multibox detector với bộ trích xuất đặc_trưng là mobilenet v2 mobilenetv2 inverted residuals và linear bottlenecks ssd cung_cấp cho nhóm nghiên_cứu tốc_độ truy_xuất nhanh trong khi mobilenet v2 giảm số_lượng tính_toán và bộ_nhớ sử_dụng nhưng vẫn duy_trì được độ chính_xác tốt mình nghĩ là họ muốn detect chính_xác <number> điểm giống như regression tuy_vậy mình đang không hiểu cái mẹo nhỏ của họ đây cụ_thể là gì họ coi mỗi góc là một object nghĩa_là thế_nào ssd dùng đây là để detect vùng chứng_minh_thư theo hộp chữ nhật chứ làm_sao detect <number> điểm các bạn có ý_kiến gì không,"['#Q&A', '#cv']"
mọi người cho mình hỏi giờ mình có <number> ảnh chứa <number> số lá bài vậy thì có cách nào để đọc được từ hình_ảnh rồi ra text gồm giá_trị lá bài chất của lá bài đó không cảm_ơn,"['#Q&A', '#cv']"
dạ mọi người có_thể cho em xin thông_tin về các trại_hè trường hè workshop conference seminar offline năm nay liên_quan đến ai machine learning việt nam không em hi_vọng post này có_thể tổng_hợp được thông_tin về các sự_kiện như thế để mọi người cùng sở_thích có_thể gặp_gỡ và trao_đổi,['#sharing']
các bạn vui_lòng đăng thông_tin tuyển_sinh tuyển_dụng và sự_kiện tháng <number> <number> vào post này chúc các bạn một mùa hè vui_vẻ,['#sharing']
em chào tất_cả các anh_chị có trong đây em là sinh_viên và em có đang tìm_hiểu về transformer cụ_thể là bài_toán text summarization với mô_hình pegasus db là tiếng việt nhưng em đang gặp <number> số vấn_đề kiểu khi em train ra đoạn text summarization nó bị tình_trạng mất dấu mất chữ_cái tiếng việt anh_chị có_thể giúp em tìm lý_do và khắc_phục được không em xin cảm_ơn,"['#Q&A', '#nlp', '#deep_learning']"
em chào mọi người em là newbie mới nhập_môn của ngành chuyện là trong quá_trình xử_lý data em có <number> số thắc_mắc mong đc mn giải_đáp <number> tại_sao lại fit trên train và transform trên test cái này em có đọc qua và hiểu sơ_sơ nhưng mong đc mọi người giải_đáp rõ_ràng hơn và nếu_như vậy thì có bị xem là data leakage khi các tham_số sẽ tính trong quá_trình fit trên train lại đc áp_dụng trên test hơn nữa theo như em thấy thông_thường_khi normalize hay encode các thứ thì sẽ fit fit_transform trên train và transform trên test_vậy với các kĩ_thuật khác như xử_lý outlier hay missing value thì mình cũng làm như_vậy hay_là làm với tập nào thì mình fit_transform trên tập đấy luôn <number> về data leakage cũng như cái trên thì cái này em cũng có đọc qua nhưng vì muốn hiểu cặn_kẽ hơn nên em mong được mn giải_thích và cách khắc_phục hạn_chế hay những điều đc phép làm để tránh hiện_tượng này em xin chân_thành cảm_ơn mọi người,"['#Q&A', '#data']"
chào anh_chị em hiện_tại đã kết_thúc năm <number> cntt chuẩn_bị sang năm <number> em muốn theo ai thì mọi người có_thể cho em một_số tài_liệu youtube hay khoá học nào trên mạng tiếng anh hoặc trả phí đều được em cảm_ơn mọi người,"['#Q&A', '#machine_learning']"
cho mình hỏi thư_viện vietocr của quốc có cấu_tạo là vgg19 và transformer đúng không,"['#Q&A', '#deep_learning']"
keras core ra_mắt hỗ_trợ đồng_thời pytorch tensorflow và jax giới_thiệu keras core tiền_thân của keras <number> cho phép sử_dụng pytorch tensorflow và jax trong một đoạn code duy_nhất we re excited to share with you new library called keras core preview version of the future of keras in fall <number> this library will become keras <number> keras core is full rewrite of the keras codebase that rebases it on top of modular backend architecture it makes it possible to run keras workflows on top of arbitrary frameworks starting with tensorflow jax and pytorch keras team nguồn vietai,"['#sharing', '#python']"
kính chào các bác nhân_dịp đang tìm_hiểu về kafka và thấy có áp_dụng được cho ml nên xin mạnh_dạn chia_sẻ cùng cả nhà hi_vọng giúp được các bạn mới học link video,"['#sharing', '#data']"
em chào mọi người em có một thắc_mắc em hiện_tại tìm về ml được một thời_gian rồi em cũng có một_vài project cá_nhân hiện_tại em muốn tìm một vị_trí thực_tập tuy_nhiên khi em tìm_hiểu thì em nhận thấy rằng có khá ít công_ty tuyển vị_trí từ thực_tập_sinh đến junior middle chủ_yếu là em thấy có viettel vin và fpt em cảm_thấy khá hoang_mang về tương_lai của mình khi em nhận thấy có rất nhiều người đi theo mảng này nhưng có rất ít chỗ tuyển_dụng em chưa có ý_định học lên và nghiên_cứu do điều_kiện tài_chính không cho phép mọi người có_thể cho em một_vài lời khuyên cũng như giới_thiệu giúp em một_vài nơi để em có_thể xin thực_tập cũng như phát_triển tương_lai được không em xin chân_thành cảm_ơn,"['#Q&A', '#machine_learning']"
chào mọi người mình đang tìm_hiểu về transformer architecture paper attention is all you need không mô_tả chi_tiết về query key value để xác_định dependency theo mình hiểu thì <number> vectors này được tạo ra bằng multiplication between embedding vectors and randomized matrics rồi dùng dotproduct attention <number> tuy_nhiên underlying idea intuition của việc sử_dụng này là gì paper chỉ đề_cập how they did it but not why <number> vai_trò cụ_thể của query key value là gì vì trong encoderdecoder attention layers queries come from the decoder layer keys and values come from the output of the decoder while for encoder selfattention layers decoder selfattention layers keys values and queries come from the same place thanks,"['#Q&A', '#deep_learning']"
hi mọi người hôm_nay mình xin phép chia_sẻ blog về tổng_quan mô_hình transformer một mô_hình khá nổi_tiếng trong deep learning mô_hình này cũng là cơ_sở của các mô_hình bert khác và nhiều thứ khác do đó để hiểu được berts các bạn cần nắm rất rõ về mô_hình transformer này blog này mình giới_thiệu từ tổng_quan đến cực_kì chi_tiết kiến_trúc mô_hình giải_thích tại_sao các đề_xuất về cơ thế positional encoding và self attention lại hợp_lý đồng_thời các điểm lưu_ý để huấn_luyện mô_hình đồng_thời mình cũng cung_cấp source code để huấn_luyện mô_hình transformer trên tập song_ngữ ted gồm 600k câu do mình tự thu_thập và matching cho các bạn tham_khảo với bộ dữ_liệu hy_vọng giảm bớt khó_khăn khi đi xin dữ_liệu blog các bạn có_thể đọc tại đây nhé source code notebook thì các bạn clone về tại đây notebook tìm tại đây bộ dữ_liệu song_ngữ anhviệt tại đây các bạn có_thể thảo_luận tại đây hoặc tại blog của mình nhé,"['#sharing', '#deep_learning']"
chào mọi người em hiện_tại có mong_muốn ngắn_hạn là trở_thành thực_tập_sinh ai mong anh_chị có_thể tư_vấn giúp em cần phải làm như thế_nào về lộ_trình cần học kỹ_năng tìm_kiếm việc cũng như chứng_minh đủ năng_lực với nhà tuyển_dụng em đang là sinh_viên năm <number> công_nghệ thông_tin muốn theo_đuổi đam_mê là ai em có nền_tảng cơ_bản là toán nhưng lại khá đuối tiếng anh chỉ có_thể dịch cơ_bản tiếng anh em cũng đã thử sức với neural network cnn rnn training framework tensorflow pytorch một_số thuật_toán machine learning cũng như code có một_số code cơ_bản deeplearning về nhận_diện tạo ảnh tạo văn_bản,"['#Q&A', '#machine_learning']"
xin phép chia_sẻ với các bác một lộ_trình trở_thành data scientist lộ_trình này được đút kết từ chính kinh_nghiệm của bản_thân nên xin các bác gạch đá nhẹ_tay,"['#Q&A', '#data']"
chào mọi người mình mới học về object deetection và faster rcnn minhd có tham_khảo và chạy thử code code gốc thì train bằng cpi và mình muốn dùng gpu để train nhưng lạ là mình đã to device cả mô_hình và data trong hàm train def training_loop model learning_rate train_dataloader n_epochs device model to device optimizer optim adam model parameters lr learning_rate model train loss_list for in tqdm range n_epochs total_loss <number> for img_batch gt_bboxes_batch gt_classes_batch in train_dataloader img_batch img_batch to device gt_bboxes_batch gt_bboxes_batch to device gt_classes_batch gt_classes_batch to device forward pass loss model img_batch gt_bboxes_batch gt_classes_batch backpropagation optimizer zero_grad loss backward optimizer step total_loss loss item loss_list append total_loss return loss_list nhưng vẫn gặp lỗi runtimeerror traceback most recent call last ipythoninput23ba5d2a14be34 in cell line <number> <number> n_epochs <number> <number> <number> loss_list training_loop detector learning_rate od_dataloader n_epochs device <number> frames ipythoninput2214c287b01571 in training_loop model learning_rate train_dataloader n_epochs device <number> <number> forward pass <number> loss model img_batch gt_bboxes_batch gt_classes_batch <number> <number> backpropagation usr local lib python3 <number> distpackages torch nn modules module py in _call_impl self args kwargs <number> or _global_backward_pre_hooks or _global_backward_hooks <number> or _global_forward_hooks or _global_forward_pre_hooks <number> return forward_call args kwargs <number> do not call functions when jit is used <number> full_backward_hooks non_full_backward_hooks ipythoninput3e0dda12f5636 in forward self images gt_bboxes gt_classes <number> <number> total_rpn_loss feature_map proposals <number> positive_anc_ind_sep gt_class_pos self rpn images gt_bboxes gt_classes <number> <number> get separate proposals for each sample usr local lib python3 <number> distpackages torch nn modules module py in _call_impl self args kwargs <number> or _global_backward_pre_hooks or _global_backward_hooks <number> or _global_forward_hooks or _global_forward_pre_hooks <number> return forward_call args kwargs <number> do not call functions when jit is used <number> full_backward_hooks non_full_backward_hooks ipythoninput3e0dda12f5636 in forward self images gt_bboxes gt_classes <number> positive_anc_ind negative_anc_ind gt_conf_scores <number> gt_offsets gt_class_pos positive_anc_coords <number> negative_anc_coords positive_anc_ind_sep get_req_anchors anc_boxes_all gt_bboxes_proj gt_classes <number> <number> pass through the proposal module ipythoninput23424462ffbf3 in get_req_anchors anc_boxes_all gt_bboxes_all gt_classes_all pos_thresh neg_thresh <number> get the iou matrix which contains iou of every anchor box <number> against all the groundtruth bboxes in an image <number> iou_mat get_iou_mat anc_boxes_all gt_bboxes_all <number> <number> for every groundtruth bbox in an image find the iou ipythoninput23424462ffbf3 in get_iou_mat batch_size anc_boxes_all gt_bboxes_all <number> gt_bboxes gt_bboxes_all <number> anc_boxes anc_boxes_flat <number> ious_mat ops box_iou anc_boxes gt_bboxes <number> <number> return ious_mat usr local lib python3 <number> distpackages torchvision ops boxes py in box_iou boxes1 boxes2 <number> if not torch jit is_scripting and not torch jit is_tracing <number> _log_api_usage_once box_iou <number> inter union _box_inter_union boxes1 boxes2 <number> iou inter union <number> return iou usr local lib python3 <number> distpackages torchvision ops boxes py in _box_inter_union boxes1 boxes2 <number> area2 box_area boxes2 <number> <number> lt torch max boxes1 none <number> boxes2 <number> <number> <number> rb torch min boxes1 none <number> boxes2 <number> <number> <number> runtimeerror expected all tensors to be on the same device but found at least two devices cuda <number> and cpu code của mình link dưới ai có_thể giúp mình sửa lỗi với,"['#Q&A', '#deep_learning']"
chào mọi người hiện_tại em có đẩy một project python lên pythonanywhere mọi thứ đều rất ổn ngoại_trừ cái tesseract em không rõ tại_sao nó lại trở_nên quá chậm from tesserocr import pytessbaseapi with pytessbaseapi path tessdata_dir as api for _img in gray_images pil_image image fromarray _img api setimage pil_image start_time time time text join re findall api getutf8text print get_cells_2ocr time time start_time _results append text on local get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> get_cells_2ocr <number> on pythonanywhere <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> get_cells_2ocr <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> get_cells_2ocr <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> get_cells_2ocr <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> get_cells_2ocr <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> get_cells_2ocr <number> <number> <number> <number> <number> <number> <number> <number> <number> như mọi người thấy thì hiệu_suất của tesseract trên pythonanywhere chênh_lệch quá lớn so với trên máy local có bạn nào từng gặp vấn_đề tương_tự chưa cho mình xin chút ý_kiến với,"['#Q&A', '#python']"
hôm_nay nhân_dịp vietcuna 3b cán mốc <number> lượt tải team mình phát_hành bản alpha của vietcuna 7b dù đã được finetune instruction nhưng đây không phải phiên_bản hoàn_chỉnh nhất mục_đích của phiên_bản này là một base model cho cộng_đồng tự finetune thêm phiên_bản hoàn_chỉnh sẽ chỉ được phát_hành cho các doanh_nghiệp liên_hệ riêng với mình trong khoảng thời_gian này ngoài_ra lần này mình cũng phát_hành luôn phiên_bản dịch tiếng việt của dataset lima lưu_ý đây là phiên_bản được dịch từ phiên_bản_gốc với model en2vi của vinai nên sẽ chỉ được dùng với mục_đích nghiên_cứu phiên_bản augmented được làm bằng tay với cộng_tác_viên cũng sẽ chỉ được phát_hành cho các doanh nhiệp huggingface model github with gradio ui limavi dataset mong mọi người cùng nhau phát_triển phiên_bản alpha này để cộng_đồng có các phiên_bản mạnh_mẽ hơn của vietcuna,"['#sharing', '#nlp']"
em hiện là sinh_viên năm <number> và muốn tham_gia các cuộc thi để bổ_sung thành_tích vào cv thì em muốn hỏi mọi người bên mảng ai hay ml có cuộc thi nào trong nước không,"['#Q&A', '#machine_learning']"
bạn đã biết gì về google extended cloud hanoi đăng_ký tham_gia sự_kiện ngay tại google extended cloud hanoi là một trong những sự_kiện thường_niên nổi_bật về công_nghệ đặc_biệt là công_nghệ cloud tại hà_nội được tổ_chức lần đầu_vào năm <number> bởi google developer group cloud hanoi gdg cloud hanoi sự_kiện đã chinh_phục trái_tim của những bạn trẻ đam_mê công_nghệ hành_trình đầy ý_nghĩa này đã lan_tỏa sứ_mệnh kết_nối chia_sẻ và truyền_cảm_hứng đến cộng_đồng công_nghệ tại việt_nam và đặc_biệt là tại hà_nội hãy cùng gdg cloud hanoi nhìn lại những dấu_ấn đáng nhớ trên hành_trình <number> năm qua của sự_kiện tổ_chức thành_công google extended cloud hanoi lần đầu_tiên vào năm <number> trải qua <number> mùa công_nghệ đáng nhớ với sự tham_gia nhiệt_tình của cộng_đồng <number> phiên thảo_luận hấp_dẫn với nhiều chủ_đề được đánh_giá cao <number> lượt tham_dự cùng với sự hiện_diện của <number> chuyên_gia hàng_đầu hợp_tác với <number> đối_tác đa ngành tiếp nối hành_trình với năm <number> google extended cloud hanoi hứa_hẹn sẽ tiếp_tục mang đến cho người tham_dự những phiên thảo_luận sôi_nổi và bổ_ích về các công_nghệ mới nhất được dẫn_dắt bởi các chuyên_gia hàng_đầu đến từ trong và ngoài nước ngoài kiến_thức những phần quà tặng siêu ngầu và các hoạt_động bên lề sẽ góp_phần mang lại trải nghiệm không_thể bỏ_qua cho các dân_chơi công_nghệ thực_thụ bạn có kỉ_niệm đáng nhớ nào với google extended cloud hanoi không hãy cùng chia_sẻ những kỷ_niệm đó với gdg cloud hanoi trong phần bình_luận bên dưới nhé đừng bỏ lỡ cơ_hội cùng chúng_tôi unleashing the power of cloud trong sự_kiện năm nay nha sự_kiện dành cho cộng_đồng yêu công_nghệ cháy nhất mùa hè năm nay tại hà_nội thời_gian <number> <number> <number> <number> thứ_bảy ngày <number> <number> <number> địa_điểm tổ_chức hội_trường tầng <number> fpt tower số <number> phạm văn bạch dịch vọng cầu giấy hà_nội link đăng_ký miễn_phí deadline <number> <number> <number> hoặc đóng sớm khi đủ số_lượng liên_hệ tài_trợ đăng_ký diễn giả gian_hàng ms hương nguyễn <number> <number> <number> thông_tin chương_trình báo_chí mr huy đặng <number> <number> <number>,['#sharing']
mn ơi cho hỏi về kiến_thức toán em cần học những kiến_thức toán gì trước và thứ tự học cái kiến_thức đó ra sao để theo ml,"['#Q&A', '#math']"
hi mọi người cho phép em hỏi về thuật_toán coordinate ascent variational inference cavi em đang đọc paper này tuy_nhiên em ko hiểu được chỗ equation <number> tại_sao có_thể nói elbo maximize khi q_j z_j bằng _j z_j vì để có eq <number> thì em đang hiểu là phải công_nhận kết_quả của eq17 mà eq17 là kết_quả luôn được thừa_nhận luôn rồi thì em thấy reasoning đang bị circular có bác nào có cao_kiến góp_ý cho em với,"['#Q&A', '#machine_learning']"
em chào các thầy cô anh chị và các bạn mọi người cho nhờ chút em đang làm_việc với bài_toán object detection mục_tiêu là áp_dụng và cải_tiến model yolov8 trên custom dataset được cung_cấp em đang tìm_hiểu về cấu_trúc mạng của model yolov8 nhưng nó còn quá mới và chưa có official paper em muốn tìm_hiểu và đọc thêm các latest techniques về object detection để có_thể mang về cải_tiến model yolov8 gốc để có_thể viết paper em xin các anh_chị recommend giúp các trang journal hoặc nơi nào để đọc về các novelty techniques về bài_toán object detection hoặc anh_chị có gợi_ý cải_thiện model thì tốt quá em cảm_ơn mọi người rất nhiều,"['#Q&A', '#cv', '#deep_learning']"
em chào mọi người hiện em đang muốn sử_dụng mô_hình vncorenlp tuy_nhiên khi cài_đặt trên vscode thì em gặp lỗi như trong ảnh ai biết cách khắc_phục thì giúp em với em cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
em chào mọi người giờ em muốn sử_dụng <number> mô_hình để liên_tục nhận và phân_loại dữ_liệu trong 24h thành <number> nhãn thì nên sử_dụng phương_pháp gì em đã có sẵn <number> bộ dữ_liệu đã phân_loại <number> nhãn này trong quá_khứ để train mô_hình phân_loại,"['#Q&A', '#machine_learning']"
em chào mọi người em có bài_tập là build <number> recommendation system rs nhưng em hiện_tại vẫn khá mù_mờ vì chưa hiểu rõ phần train và phần test được thực_hiện ntn như em đã tìm_hiểu thì trong machine learning tập train sẽ xấp_xỉ hàm dự_đoán còn tập test sẽ để xđ xem hàm đó tốt đến đâu nhưng phần rs này có <number> số thuật_toán để có_thể dự_đoán được luôn đánh_giá của người dùng collaborativefiltering userbased itembased matrix factorization ... thì mình chỉ cần áp_dụng thuật_toán với dataset sau khi xử_lí để có được các đánh_giá xấp_xỉ hơn nữa em tìm thấy code mẫu trên mạng em để link bên dưới thì thấy người_ta vẫn thừa_số hóa cả ma_trận ratings tuy_nhiên chỉ cố_gắng minimize loss của phần train <number> subset của ma_trận ratings trên và thả trôi phần test phần còn lại của ma_trận đến đây em kiểu bị vì_sao thừa_số hóa rồi minimize loss của cả ma_trận nếu_như test loss nhỏ là tốt từ đấy dẫn đến câu hỏi ban_đầu của em tại_sao lại chia train vs test ra ngay từ ban_đầu em xin trân thành cảm_ơn mọi ý_kiến đóng_góp link bài code đây cụ_thể phần function build_model ps với lại cho em hỏi thêm là có phải phương_pháp đánh_giá loss chưa tối_ưu bởi theo nghiên_cứu của tác_giả đỗ thị liên và cộng_sự tại trang <number> cần phải ẩn đi <number> số đánh_giá đã biết của người dùng trên tập test sau đó so_sánh giá_trị dự_đoán với giá_trị thực tuy_nhiên trong các phần sau và phần kết_quả tác_giả đề_cập đến việc đã lấy chiếm bao_nhiêu nên em muốn hỏi mọi người là nên đánh_giá hiệu_năng ntn và nếu là cách của tác_giả liên thì lấy là bao_nhiêu <number> lần nữa em xin chân_thành cảm_ơn nhiều,"['#Q&A', '#machine_learning']"
mình làm hạ_tầng phần_cứng có_thể hỗ_trợ share lab có sẵn các tài_nguyên máy ảo kết_nối hadoop có mạng internet để tự cài thêm package bạn nào cần tài_nguyên trải nghiệm test có_thể ib mình lab tồn_tại được <number> ngày mỗi lần khởi tạo mỗi máy ảo linux có 24gb ram,['#sharing']
một video thú_vị về toán hi_vọng nó giải_thích cặn_kẽ để ta hiểu tại_sao lại có số pi số,"['#sharing', '#math']"
chào mọi người em là sinh_viên đang theo học ai ml em có một thắc_mắc về hướng đi trong ngành theo em biết thì có <number> hướng chính là research và engineer anh chị cho em hỏi những điểm khác nhau của <number> hướng này và cơ_hội của hướng nào sẽ là nhiều hơn,"['#Q&A', '#machine_learning']"
chào mọi người không biết tp hcm có nơi nào bán sách calculus early transcendentals ninth edition không mặc_dù có bản pdf nhưng mình làm_việc với máy_tính rất nhiều nên muốn đọc bản giấy cho đỡ đau mắt và giải_trí trong thời_gian rảnh một_tí,"['#Q&A', '#math']"
em chào mọi người em là newbie chập_chững vào nghề đang gặp <number> vấn_đề <number> bài_toán mong được mn giải_đáp bài_toán em có áp_dụng hog để trích xuất đặc_trưng ảnh ảnh của em là <number> <number> khi dùng hog thì em cho orientations <number> pixel per cell <number> cell per block <number> thì khi trích xuất xong <number> ảnh sẽ đc biểu_diễn dưới <number> vector kích_thước <number> <number> em có thắc_mắc con_số <number> này tạo ra ntn <number> tại vì em thấy size ảnh chia hết cho pixel per cell và nếu luận ngược lên <number> <number> <number> <number> <number> <number> <number> với <number> <number> <number> là độ dài vector hog của mỗi block hay nói cách khác trên mỗi phương sẽ khi đi từ trái qua phải hoặc trên xuống dưới ta sẽ phải tính hog trên <number> block kết_hợp vs việc <number> cell cho mỗi block thì ta sẽ có đc số cell theo từng phương là <number> nma nếu tính như_vậy thì số pixel theo mỗi phương sẽ là <number> <number> <number> như đúng size ảnh gốc vậy liệu có phải đám pixel còn lại bị thiếu sẽ bị cắt đi dùng đến khi tính hay_là sẽ được ném vào các cell trong <number> cell có sẵn đó em cảm_ơn mọi người nhiều mong sẽ được admin duyệt bài sớm và sớm nhận được giúp_đỡ từ mn,"['#Q&A', '#cv']"
xin được share với các bác <number> seminar dành chung cho tất_cả các anh_em hứng_thú với mlops với chủ_đề optimize ml service performance with continuous rightsizing containers in kubernetes,['#sharing']
thuê server trên vast ai chào mọi người trong group mình có ai đã từng thuê server trên vast ai chưa cho mình ít review thấy giá cũng rẻ mà nhỉ em định dùng để train model ai thay_vì kaggle hay colab ko biết có nhanh hơn ko với lại nó cần credit_card để nạp tiền vào mà giờ em không có credit_card thì ko biết có giải_pháp nào ko em xin cảm_ơn,['#Q&A']
mình đang cày project để apply xin việc mình đang tìm các competitions để luyện_tập bao_gồm eda preprocessing modeling và predict hiện_tại mình mới tham_gia <number> cuộc thi nhưng kết_quả của mình chỉ giao động từ <number> so với độ chính_xác của cuộc thi do mình không biết optimize hoặc optimize xong thì kernel die chẳng_hạn mình muốn tìm bạn colab với mình cùng nhau cày project kiếm medal chẳng_hạn mình có_thể preprocessing eda ... còn bạn làm phần còn lại hoặc cả <number> cùng thảo_luận về các cách làm ... không nhất_thiết ngày nào cũng phải làm cùng nhau nhưng cố_gắng tuần nào cũng trao_đổi ad duyệt cho mình kiếm tý medal vớiiiii,"['#sharing', '#machine_learning']"
em xin chào mọi người là em sinh_viên ngành khoa_học máy_tính vì quá mông_lung trên con đường học để trở_computer vision engineer nên em muốn hỏi mn cách học cv như thế_nào để sau_này có_thể tìm được việc hiện_tại thì em đã học ann cnn rnn lstm mức cơ_bản thôi em định_hướng là sẽ code theo các project trên mạng trên sách để làm_quen nhưng code xong em cảm_thấy nó không phải là của mình và cũng không_thể tự code được cái gì em không biết học như thế_nào cho đúng mong mọi người giúp em với em trầm_cảm vô_cùng,"['#Q&A', '#cv', '#deep_learning']"
anh chị cho em hỏi muốn học ml thì nên bắt_đầu_từ đâu,"['#Q&A', '#machine_learning']"
chào các bạn mình đang tìm host để deploy con services ai xử_lý ảnh mọi ng thường triển_khai đâu ưu_tiên ngon bổ rẻ nhé ae cảm_ơn anh_em,['#Q&A']
em chào mọi người em đang tham_khảo về một đề_tài lvtn xoay quanh ai làm về một hệ_thống social network kết_nối cộng_đồng người dùng và chuyên_gia cụ_thể có những nhóm công_ty dn cá_nhân có những bài_toán đặc_thù về ai nhưng không biết giải_quyết như thế_nào thay_vì phải học và phải tốn thời_gian để học họ muốn giải_quyết được những bài_toán này trong thời_gian ngắn thì hệ_thống này sẽ là hệ_thống social network để kết_nối những nhu_cầu này hệ_thống sẽ mang đặc_thù kết_nối cộng_tác giữa các bên có bài_toán nhưng không biết làm gì giữa các bên có kĩ_năng tuy_nhiên không đơn_giản chỉ tương_tác mà phải duy_trì và quản_trị kết_nối đó ví_dụ khi đang làm giữa_chừng mà bên làm họ rút không làm nữa thì phải xử_lí như thế_nào hệ_thống cũng phải đảm_bảo tự_động thông_minh kết_nối các bên liên_quan giả_sử có nhu_cầu về <number> bài_toán ai khác nhau thì hệ_thống phải làm_sao đề_xuất được nguồn_lực nào hạ_tầng nào phù_hợp cho từng nhu_cầu cụ_thể không đơn_thuần chỉ là up bài lên rồi người khác vào trả_lời mọi người ai đã từng làm qua hoặc biết có_thể cho em xin một_số tài_liệu liên_quan được không và mn có_thể cho em xin một_số hệ_thống giống như trên thực_tế để có_thể tham_khảo không vì em có search nhưng chưa tìm được cảm_ơn mọi người chúc mọi người cuối tuần vui_vẻ,['#Q&A']
chào mọi người phoenix team xin chia_sẻ với mọi người source code của 1st privatetest solution zalo ai challenge <number> phần traffic sign detection một_số tricks mà team có sử_dụng <number> training data preprocessing chia ảnh thành các grid nhỏ hơn sử_dụng input size 160x160 và stried window 40x40 loại bớt các ảnh background và các ảnh có dính <number> phần box quá nhỏ <number> diện_tích box chỉ để tỉ_lệ <number> <number> <number> training pharse augmentation mosaic <number> mixup model yolov5x sgd optimizer ema 5stratified cv chia ảnh gốc sau đó preprocess sau <number> inference chia ảnh thành các grid 384x384 scaleup lên input 608x608 stride 84x88 sau khi đi qua model nms được sử_dụng giữa các ảnh nhỏ theo area của các box iou <number> wbf weighted boxes fusion được sử_dụng giữa các fold best 5fold fp16 model <number> các bạn có câu hỏi nào có_thể viết dưới post này hoặc để lại phần issue của git các thành_viên trong team hải nam nguyễn xseries funix thân cường ai engineer asilla nguyen hai son bkhn ai intern asilla chúc các bạn có_thể áp_dụng một trong các tricks trên vào_cuộc thi của vinbigdata sắp tới,"['#sharing', '#cv']"
mn ơi em học đến bài này thì không biết sao lại có công_thức thứ <number> mn giúp em với,"['#Q&A', '#math']"
xin chào mọi người mọi người cho em hỏi là cách lấy dữ_liệu từ trang_web như thế_nào ví_dụ em muốn lấy tất_cả bài viết trong nhóm trên fb về trong đó <number> số bài viết có ảnh một_số bài không em muốn lấy về hết gồm tiêu_đề nội_dung ảnh nếu có em xin cảm_ơn,"['#Q&A', '#data']"
mọi người có tài_liệu papers books để bắt_đầu tìm_hiểu về derivativefree optimization hay blackbox optimization không em xin cảm_ơn,"['#Q&A', '#machine_learning']"
chào mn em đang mong muố tìm job intern fresher al hà_nội em cảm_ơn,"['#Q&A', '#machine_learning']"
em chào mn em tự học bài gradient descent đến đoạn công_thức này thì không hiểu tại_sao mn giải_thích giúp em với,"['#Q&A', '#math']"
công_ty trợ_lý ảo dùng trợ_lý ảo tuyển người phát_triển trợ_lý ảo là một đơn_vị tiên_phong phát_triển chatbot trợ_lý ảo thế_hệ mới trên công_nghệ chatgpt tại việt_nam hiện mindmaid ai đang có nhu_cầu tuyển_dụng thực_tập_sinh content marketing chatbot development nhiệm_vụ chính bao_gồm nghĩ với chatgpt viết với chatgpt chuẩn_bị dữ_liệu huấn_luyện trợ_lý ảo cũng bằng chatgpt đây là vị_trí ưu_tiên cho các bạn content tuy_nhiên vì chuẩn_bị content cho trợ_lý ảo nên công_ty cũng muốn ưu_tiên một_số suất cho các bạn có hiểu_biết tốt về công_nghệ ai và muốn khám_phá lĩnh_vực trợ_lý ảo này môi_trường làm_việc startup năng_động văn_phòng khu_vực trung_tâm công_cụ làm_việc lark xịn sò và đặc_biệt là luôn được học_hỏi về những skill mới nhất thông_qua growth day hàng tuần nhờ anh_chị_em bạn_bè thấy có cv nào phù_hợp giới_thiệu giúp thông_tin chi_tiết về jd hình_thức gửi cv ... mời chat trực_tiếp với trợ_lý ảo xin phép ad đăng lên group vì không tìm thấy post gom đăng bài tuyển_dụng trên nhóm,"['#sharing', '#nlp']"
gần đây trên các cộng_đồng có nhiều tranh_cãi ý_kiến cho rằng đừng nên học data nữa ngành data bão hòa rồi học data không xin được việc đâu với quan_điểm của mình trước khi quyết_định học hay theo_đuổi một ngành nào đó các bạn hãy tự hỏi bản_thân trước <number> câu hỏi cụ_thể mình đang muốn gì mục_đích của việc học này là gì nếu có nó mình sẽ được những lợi_ích gì nếu không có nó mình có_thể sẽ mất đi cơ_hội gì nếu các bạn cho rằng ngành data đã bão hòa và khó xin việc thì hãy hiểu nguyên_nhân tại_sao <number> hiện_tại tình_hình kinh_tế chung đang khó_khăn các doanh_nghiệp còn đang lay off nhiều ngành_nghề khác cũng khó_khăn và thất_nghiệp không riêng gì trong lĩnh_vực data <number> thực_tế rằng nhu_cầu tuyển_dụng data vẫn rất lớn cắt_giảm tuyển level thấp tại vì doanh_nghiệp cần phải tối_ưu_hóa chi_phí tập_trung giải_quyết vấn_đề trước_mắt nên họ muốn tìm những người có_thể bắt_đầu ngay với công_việc và tạo ra giá_trị thay_vì đào_tạo nuôi_dưỡng nguồn nhân_lực mới bản_chất của việc tuyển intern fresher là đầu_tư chi_phí để đào_tạo con_người để đảm_bảo nguồn nhân_lực phát_triển lâu_dài chứ không phải giải_quyết vấn_đề trước_mắt các doanh_nghiệp tuyển senior leader level là vì đa_số doanh_nghiệp lĩnh_vực đang bắt_đầu ứng_dụng và xây_dựng data platform cần người có kinh_nghiệm để bắt_đầu thiết_kế và đào_tạo và đến một giai_đoạn nào đó khi hệ_thống đã phát_triển họ thể mãi tìm được các de da level cao vì nếu không đào_tạo lớp trẻ thì sẽ có các senior tương_lai vì_vậy sẽ có giai_đoạn nhu_cầu tuyển_dụng level thấp quay lại nhiều hơn nếu không học không chuẩn_bị trước cho tương_lai thì làm_sao bạn nắm_bắt các cơ_hội phí trước nếu các bạn bảo tại_sao yêu_cầu nhà tuyển_dụng ngày_càng cao biết nhiều kỹ_năng như sql power bi python ... vẫn không được tuyển <number> hãy đặt lại câu hỏi tại_sao họ phải tuyển bạn bạn có gì để mang lại giá_trị cho công_ty họ bạn hãy xem phỏng_vấn tìm việc không phải xin việc là đi chợ việc_làm mức lương là hàng_hóa và tiền bạn đang bán sức lao_động và giá_trị cho công_ty nên thuận mua vừa bán mức lương và công_việc sẽ đi theo quy_luật cung_cầu của thị_trường điều này đúng cho tất_cả ngành_nghề ngành data ngày_càng hot vì mức lương mức đãi_ngộ hấp_dẫn với nhiều cơ_hội phát_triển do vậy ngày_càng nhiều người chú_ý và học về data nên sự cạnh_tranh sẽ lên cao trước_kia ít người học khó tuyển người nên yêu_cầu đơn_giản bây_giờ đã có nhiều người học và có những người có tư_duy tư_chất tốt hơn biết nhiều hơn thì họ có quyền chọn người tốt hơn yêu_cầu cao hơn chứ <number> hãy bỏ tư_tưởng ăn_xổi bạn bảo bạn biết sql bi tools lập_trình nhưng bạn thật_sự biết đến đâu thành_thạo đến đâu bài đăng nào của các bạn em cũng chỉ thấy nói em có_học và biết một_chút chứ nói em thành_thạo và đã làm những dự_án về sql data warehouse hay bi dashboard bạn hãy quên đi giấc mơ học <number> <number> tháng khóa học ngắn_hạn và chắc_chắn có việc các bạn học <number> <number> tháng và tin theo lời quảng_cáo của trung_tâm là chắc_chắn có việc hãy suy_nghĩ các bạn lấy gì để cạnh_tranh với những bạn đã học <number> năm đại_học hay ngồi học ngày học đêm để nâng cao kỹ_năng từng ngày mà chỉ tin_tưởng và tuần <number> buổi học trong <number> tháng là giỏi rồi đi làm tốt rồi tất nhiều một_số bạn có_thể nói là nhiều bạn xin việc trong <number> tháng <number> tháng thậm_chí là <number> tháng học về data nhưng đó chắc_chắn là nhiều sự đánh_đổi cố_gắng và đôi_khi là may_mắn nắm_bắt được đúng cơ_hội nhiều bạn học_sinh của mình đã nhận được việc <number> tháng <number> tháng học dù chưa được học đầy_đủ kiến_thức nhưng cũng có nhiều bạn học xong rồi những loay_hoay mãi chưa tìm được cơ_hội mình nhận thấy rằng các bạn tìm được_việc sớm có một_số là do có tố_chất tốt hơn về cả hard skill và soft skill có một_số chăm_chỉ hơn cố_gắng nhiều hơn và đa_số là do may_mắn gặp thời_điểm tốt hơn nắm_bắt được cơ_hội vì mình dạy và đánh_giá được trình đội các bạn đôi lúc không chênh_lệch nhiều thậm_chí bạn tìm được_việc còn tốt hơn bạn đã tìm được tìm việc là sự phù_hợp vs công_ty không chỉ về kỹ_năng và nhiều yếu_tố khác khi mình tốt_nghiệp đại_học mình tự_tin có một nền_tảng kiến_thức vững_chắc mình đã skip rất nhiều về software để tập_trung_học ai và data mình có hơn <number> năm nghiên_cứu tại lab_trí_tuệ nhân_tạo mình là first author <number> paper trong hội_nghị rank có <number> năm kinh_nghiệm part time tại một công_ty lớn nhưng mình vẫn bị trượt phỏng_vấn vị_trí fresher của một công_ty vn đoạn này khoe chỉ là phần nhỏ thôi phần_lớn để cho các bạn thấy phù_hợp quan_trọng thế_nào nếu có dịp mình sẽ chia_sẻ về lần pv trượt ấy bởi_vì tại thời_điểm ấy họ cần những người làm_việc như mình và họ có nhiều option có_thể tốt hơn có_thể phù_hợp hơn hãy xác_định học để làm gì minh luôn quan_điểm học để ấm vào thân để xây_dựng kiến_thức trước nếu phần trên nói đến tư_tưởng ăn_xổi có nhiều bạn gọi cho mình và hỏi học xong <number> khóa <number> khóa học của anh_em có xin việc không và mình trả_lời xin được_việc hay không do sự_cố_gắng và may_mắn của bạn không phải mình và cái mình cam_kết và chất_lượng kiến_thức và bạn cảm_thấy mình đang hiểu_biết lên đang học được những kiến_thức có_ích chứ mình không bao_giờ cam_kết việc_làm và đến <number> các bạn thất_vọng và không học mình xin chúc các bạn may_mắn hơn một nơi nào đó họ cam_kết học xong có việc tại_sao các bạn không nghĩ đến việc học để lấy kiến_thức cho bản_thân trước rồi khi có kiến_thức các cơ_hội sẽ tự tìm thời và mình sẽ không bỏ lỡ những cơ_hội trong tương_lai tại_sao các bạn luôn có tư_tưởng học để chuyển một công_việc mới sang làm data luôn mà không nghĩ để phục_vụ cho chuyên_ngành cho công_việc khác của mình sau_này các bạn hãy để_ý thời_kì_công_nghệ thông_tin bắt_đầu bùng_nổ giá_trị của những người đã biết sử_dụng máy_tính thành_thạo tin_học văn_phòng trong cv cao như thế_nào và hiện_tại ai cũng cảm_nhận rõ mình đang bước chân vào thời_kỳ mới là data driven vậy những người có kỹ_năng tốt về dữ_liệu liệu có cơ_hội có thế mạnh để cạnh_tranh hơn trong lĩnh_vực của họ hay không thôi viết dài quá mỏi tay đói bụng ... nếu có cơ_hội mình sẽ chia_sẻ sâu hơn về từng quan_điểm trong bài viết có một vấn_đề mình vừa nghĩ vừa gõ máy sẽ bị các lỗi chính_tả nên có gặp nhiều lỗi chính_tả xin các bạn đừng cười và tập_trung vào nội_dung bài viết và các luận_điểm mình muốn truyền_đạt có ai đó đã từng nói rằng một_khi đã sai chính_tả thì mọi lập_luận đều vô_nghĩa,"['#sharing', '#data']"
em chào anh_chị trong group em mới tìm_hiểu về machine learning và em mong_muốn tìm cuốn sách hoặc khoá học để có_thể hiểu rõ về các thuật_toán đằng sau các mô_hình và cách sử_dụng mô_hình phù_hợp cho từng bài_toán khác nhau mong được anh_chị giúp_đỡ cho em em cảm_ơn,"['#Q&A', '#machine_learning']"
thuật_toán monte carlo tree search trong alphago chào các bạn mình tìm thấy một bài viết khá hay về thuật_toán monte carlo tree search trái_tim của hệ_thống đánh cờ_vây alpha go mình xin giới_thiệu nó với các bạn và tiện_thể mình cũng dịch nó ra tiếng việt luôn cho bạn nào quan_tâm và kèm theo cả python code sử_dụng monte carlo cho trò cờ_vây và tictactoe cờ caro <number> <number> bài dịch bài gốc link code python cờ_vây tictactoe xin cảm_ơn và chúc các bạn buổi tối vui_vẻ,"['#sharing', '#machine_learning']"
tác_giả của effective pandas anh matt harrison tặng sách mặc_dù ai cũng biết chỗ để tải cuốn sách mình muốn nhưng nếu được chính tác_giả tặng thì cảm_giác vẫn rất khác_biệt các bạn làm theo hướng_dẫn để được tặng sách miễn_phí nhé,['#sharing']
em <number> tuổi dev quèn đang gặm quyển thánh kinh của anh tiệp để chuyển việc công_nhận ngành khó voãi mấy bác ko biết có bác nào lớn lớn chia_sẻ ít kinh_nghiệm tự học không em ko có background khoa_học máy_tính theo có ổn hay đuối ko em có bằng đh mạng máy_tính chả lq dev quèn cũng ít dính luôn hjx em cảm_ơn,"['#Q&A', '#machine_learning']"
fingpt opensource financial llms cung_cấp toàn_bộ quy_trình llm training and finetuning trong lĩnh_vực tài_chính paper code,"['#sharing', '#deep_learning']"
chào các chị trong group em mới mọc mòi nghiên_cứu về nlp thì có một thắc_mắc mong nhận được một_số ý_kiến để tham_khảo trong quá_trình preprocess em có thấy là đa_số các hệ_thống sẽ sử_dụng bpe để tokenize đầu_vào tuy_nhiên em có đọc được paper của phobert mô_hình ngôn_ngữ của vn thì họ có đề_cập là họ đã wordsegment trước khi áp_dụng bpe về mặt trực_giác thì do phobert là mô_hình_đơn ngôn_ngữ monolingual nên việc segment các từ từ ghép thì đúng là sẽ giúp_ích rất nhiều cho việc tokenize để bổ_trợ feature cho các task về sau thắc_mắc của em là nếu ta cần giải_quyết một bài_toán đa_ngôn_ngữ trong đó bao_gồm ngôn_ngữ các unit của nó được tách_biệt rõ_ràng như english whitespace và các ngôn_ngữ có cách biểu_diễn khác như vn từ ghép hay jp ko có whitespace thì mình sẽ preprocess như nào em cảm_ơn chị,"['#Q&A', '#nlp', '#deep_learning']"
em đang có <number> vấn_đề như này mong đc giải_đáp dưới đây là <number> video em quay lại <number> ứng_dụng sử_dụng texttospeech bên trái là ứng_dụng trên mạng bên phải là em tự code thư_viện sử_dụng là gtts có sẵn của python nhưng không hiểu sao nghe nó khá là đuồi em có chỉnh lại tham_số đầy_đủ của gtts cho nó sử_dụng api của tên_miền google com vn và ngôn là vi nhưng vẫn đạt được chất_lượng của voice như bên phải voice của video bên phải được sử_dụng khá nhiều bên j2team cũng sử_dụng voice này mà em không biết lấy đâu ra hay làm_sao đạt được ai có kinh_nghiệm thì giúp em với em cám_ơn mọi người nhiều,"['#Q&A', '#nlp', '#python']"
em xin chia_sẻ một bài ngắn về none và is none cho bác nào quan_tâm,"['#sharing', '#python']"
chào mọi người em hiện_tại sẽ tốt_nghiệp vào tháng <number> và đang muốn tìm một job về ai engineer trước đó thì em đã có khoảng <number> tháng intern về cv viettel mọi người cho em hỏi là hà_nội thì có những công_ty nào tốt làm về ai,"['#Q&A', '#machine_learning']"
xin chào tất_cả mọi người tôi muốn mua một cuốn sách để làm_quà bằng tiếng anh những cuốn sách hay nhất về machine learning deep learning mà bạn có_thể đề_xuất là gì cảm_ơn các bạn rất nhiều,"['#Q&A', '#machine_learning']"
chào mn mình tốt_nghiệp đại_học bách_khoa hà_nội chuyên_ngành cơ_điện_tử mình định_hướng chuyên_sâu mảng robotics and al mình đang muốn tìm job intern fresher về al hà_nội cảm_ơn mn,"['#Q&A', '#machine_learning']"
em chào anh_chị trong nhóm hiện em đã tốt_nghiệp đại_học bách_khoa hà_nội chuyên_ngành cơ_điện_tử em đang tìm việc intern fresher về al tại hà_nội không biết anh chị công_ty nào có còn open cho vị_trí intern fresher không,"['#Q&A', '#machine_learning']"
góc intern chào mọi người em sinh_viên năm cuối tại hcm ngành điện_tử công_nghiệp có kiến_thức về machine learning deep learning neutral network image processing và các framework ai tensor flow numpy keras ... một_số project về sử_dụng các thuật_toán ứng_dụng vào hệ_thống nhúng chủ_yếu là các vấn_đề nhận_diện nhận_diện khuôn_mặt để mở_cửa nhận_diện biển số xe nhận_diện khuôn_mặt đeo khẩu_trang ... em mong_muốn tìm công_việc internship tại hcm,"['#Q&A', '#machine_learning']"
nhờ trợ_giúp chào các bác ví_dụ có <number> text như này tôiđanghỏibạn bị lỗi dính chữ mất dấu cách có thư_viện nào có_thể sửa được câu trên thành câu hoàn_chỉnh không output tôi đang hỏi bạn nếu chuỗi là tiếng anh thì làm được còn tiếng việt thì em chưa biết cách nào,"['#Q&A', '#data']"
em chào anh chị hiện_tại em mới tốt_nghiệp và đang mong_muốn tìm việc fresher intern ai hoặc liên_quan tới data tại hà_nội anh chị đang tuyển thì cho em xin jd với hoặc em sẽ inbox gửi cv,"['#Q&A', '#machine_learning', '#data']"
em chào các anh_chị em đang là sinh_viên năm <number> em có định_hướng muốn theo ai nhưng không biết bắt_đầu_từ đâu anh chị có_thể cho em xin roadmap được không em cảm_ơn,"['#Q&A', '#machine_learning']"
góc tìm đồng_đội tham_gia team dự cuộc thi the 4th annual international competition in data science artificial intelligence chào các bạn từ <number> <number> <number> <number> <number> <number> isods usa tổ_chức cuộc thi quốc_tế dành cho sinh_viên nghiên_cứu_viên về nội_dung data science artificial intelligence nhóm mình cần tìm <number> thành_viên tham_gia team nếu bạn nào thấy yêu thích phù_hợp thì gửi cv mô_tả năng_lực và kinh_nghiệm liên_quan qua email cho mình nhé hạn nhận email <number> <number> <number> tiêu_chí có kinh_nghiệm kỹ_năng lập_trình liên_quan đến data science machine learning deep learning và computer vision tư_duy thuật_toán tốt ưu_tiên các bạn sinh_viên năm <number> quyền_lợi làm_việc cộng_tác với những bạn có kinh_nghiệm trong lĩnh_vực liên_quan những bạn phù_hợp đáp_ứng năng_lực sẽ được nhận học_bổng toàn_phần master phd tại lab của mình tại trường đại_học kyonggi hàn_quốc bắt_đầu học vào kỳ mùa xuân tháng <number> <number> tích_lũy kinh_nghiệm hồ_sơ xin học_bổng master phd tại nước_ngoài các thông_tin liên_quan website về cuộc thi website của lab email của mình phamdinhlam@kgu.ac.kr cảm_ơn admin đã duyệt bài,"['#sharing', '#machine_learning']"
chào mọi người một người quen của em cần trợ_giúp cho việc thử_nghiệm các kỹ_thuật học máy trên tập dữ_liệu kinh_tế tất_nhiên là có trả phí dữ_liệu bao_gồm <number> time series tabular dataset các cột đặc_trưng bao_gồm đặc_trưng số_thực và đặc_trưng hạng_mục dặc trưng có dạng sai phân so với cùng kỳ năm xxx dạng tỷ_lệ so với cùng kỳ năm xxx <number> dữ_liệu binary thể_hiện sự xuất_hiện của keyword về kinh_tế tại mỗi mốc thời_gian các đặc_trưng được phân về nhiều nhóm và giữa các nhóm có_thể có sai khác về mốc thời_gian thực_hiện phép đo sai khác về chu_kỳ_thực_hiện phép đo có_thể có missing value trong các nhóm đặc_trưng cảm_ơn mọi người đã đọc,"['#sharing', '#machine_learning']"
chào mọi người sau <number> tuần nhận được rất nhiều feedback từ mọi người đặc_biệt là từ một_số bạn có hạn_chế về gpu team đã convert thành_công vietcuna sang với thư_viện ggml và chạy trên cpu chỉ với 3gb ram mọi người có_thể tải model tại đây bản quantized 4bit bản nonquantized ngoài_ra phiên_bản 7b dự_kiến sẽ sớm được phát_hành,['#sharing']
em chào mọi người em là sv năm <number> mới chập_chững bước vào ml và mong_muốn hướng đến sau_này là ml engineer tuy mới bước_đầu và trình_độ chẳng bằng ai nhưng em có đam_mê lớn vs ml cũng như_ai em đang tự học và tìm_hiểu qua blog của anh tiệp nhưng mà em cũng muốn cày lại căn_bản từ đầu lộ_trình để hướng đến ai engineer bằng cách tham_gia các khoá học trên mạng của coursera udemy vì mới chập_chững nhập_môn nên em rất mơ_hồ và rõ lộ_trình cũng như thứ tự các khoá học mà mình nên focus làm_phiền anh chị cũng như cô chú có_thể chỉ giúp em <number> lộ_trình và các khoá học từ căn_bản đến nâng cao từ <number> đứa chẳng có gì em mong_muốn đc sống vs đam_mê và tạo ra <number> giá_trị gì đó dù em biết ai là <number> trường_phái rất rất khó và đòi_hỏi <number> quá_trình chăm_chỉ lâu_dài nhưng em sẽ cố hết_sức có_thể em cảm_ơn mọi người rất nhiều,"['#Q&A', '#machine_learning']"
giải_thích cách hoạt_động của self attention,"['#sharing', '#deep_learning']"
xin phép các bác admin cho em chia_sẻ playlist software engineering fundamentals tạo bởi anh_em group mlopsvn cho bác data scientist ai engineer nào quan_tâm,"['#sharing', '#machine_learning']"
chào tất_cả ace trong group cho em hỏi là trong group mình có ai đã sử_dụng mmtracking của openmmlab chưa em gặp vấn_đề về implement và modify mặc_dù đã tìm_hiểu cả tuần nay nhưng vẫn chưa giải_quyết được nên đăng stt này hy_vọng mọi người giúp do vấn_đề dài_dòng quá nên không viết lên đây được cảm_ơn mọi người đã đọc tin <number>,"['#Q&A', '#cv']"
giới_thiệu với các bạn mô_hình vietcuna do bên mình mới train hiện chỉ public bản 3b phiên_bản 7b và 40b vẫn đang tiếp_tục cải_thiện và trong kế_hoạch release,"['#sharing', '#machine_learning']"
chào anh_chị trong nhóm anh_chị cho em hỏi em học ngành cơ_điện_tử đang kiếm cơ_hội thực_tập các công_ty liên_quan điến ngành học hiện_tại em có vài câu hỏi sau đây mong anh_chị trả_lời cơ_điện_tử việt nam đi thực_tập chủ_yếu làm gì tìm thông_tin trên mạng mông_lung quá đôi nét bản_thân em là sinh_viên đầu năm <number> một trường kỹ_thuật tại sài_gòn tiếng anh của em đọc hiểu nghe nói vấn_đề giao_tiếp tốt sài_được ngôn_ngữ vba matlab mức căn_bản python cad solidworks plc inventor một_số chứng_chỉ trên coursera liên_quan đến mấy phần_mềm trên cs50p mong anh_chị cho em thông_tin thực_tập tại công_ty liên_quan đến chuyên_ngành của em cuối năm nay em thi thêm tiếng trung hsk thì liệu có tăng thêm cơ_hội thực_tập tại các công_ty không em không ngại khó anh_chị chỉ em chỗ thực_tập để học_hỏi và trau_dồi cho bản_thân anh_chị giải_đáp với còn lập_trình nhúng thiết_kế cơ_khí có anh_chị nào làm mảng này không mình có_thể trao_đổi tại bài post này còn data science thì học kiến_thức gì trước trước khi tìm_hiểu mảng nay tại trên mạng nói nhiều cái mông_lung quá em xin_lỗi vì hỏi hơi ngớ ngớ cảm_ơn anh_chị đọc bài,['#Q&A']
chào mọi người em đang thực_hiện project cá_nhân và trước đó sử_dụng voc dataset tuy_nhiên để so_sánh với các thực_nghiệm của các tác_giả trong paper thì em phải so_sánh trên coco tuy_nhiên coco có một vấn_đề là nó tồn_tại nhiều bức ảnh không có object nào thuộc coco class các module của em không được thiết_kế cho việc này và chỉnh_sửa lại rất mất thời_gian bỏ những tấm ảnh này đi thì rất dễ nhưng em nghĩ là nó cũng sẽ ảnh_hưởng đến việc train và tính map trong các paper thì các tác_giả không đề_cập đến việc này vậy hiện_nay cách làm phổ_biến là đơn_giản bỏ những data như trên ra khỏi tập train và valid hay vẫn giữ vậy,"['#Q&A', '#data']"
mọi người cho em hỏi có cách nào để xóa các đường_thẳng trong các ảnh trong hình không em định dùng hough để nhận_diện nhưng ngặt nỗi số <number> với số <number> nó cũng nhận vào em dự_định xóa các đường để rồi sau đó tìm ra được khung nhỏ nhất chứa số,"['#Q&A', '#cv']"
chẳng_là em có dùng minst để đào_tạo mô_hình nhận_dạng kí_tự số sử_dụng mô_hình mlp sau đó em thu_thập thêm các kí_tự số viết_tay của nhiều người thì với tập dữ_liệu mới này thì mnist cho kết_quả nhận_diện không tốt lắm khoảng <number> em định training tiếp mô_hình trên tập dữ_liệu mới thì em nên chia tập trainingtest như thế_nào vì tập dữ mới của em không được cân cho lắm ví_dụ như tập số <number> có <number> ảnh tập số <number> có <number> ảnh trong khi đó tập số <number> chỉ có khoảng <number> ảnh thôi hay tập số <number> chỉ có <number> ảnh,"['#Q&A', '#cv', '#data']"
xin chào các anh_em trong nhóm mình là người không chuyên nhưng đang thử ứng_dụng ml cho <number> bài_toán của công_ty mình nghĩ bài_toán này dùng ml là đủ chứ ko cần dl do chưa có nhiều kinh_nghiệm nên mình có câu hỏi như sau hiện_tại <number> sample của mình có <number> feauture dimension nhưng thực_tế chỉ có <number> loại feauture thôi vì <number> sample này được lấy từ <number> sensor mỗi sensor cho thu về <number> loại feauture <number> cái là vận_tốc <number> là áp_suất tại van đó nhưng <number> van này đổ về <number> khuôn chứa từ đó tạo ra sản_phẩm nên ko thể bỏ được feauture nào hết ngoài việc đưa cả <number> feauture vào hoặc nghĩ ra <number> công_thức để sinh feauture mới thì có cách nào để model hiểu <number> feauture nhưng thực_chất là có <number> loại chính được ko mình đang làm bài_toán clustering mong được hướng_dẫn hoặc cho keyword nào liên_quan đến vấn_đề này xin cảm_ơn,"['#Q&A', '#machine_learning']"
chào mọi người em hiện là sinh_viên ngành cơ_điện_tử muốn tìm_hiểu về machine learning để áp_dụng vào ngành của mình trong tương_lai hiện_tại em đã học xong và nắm chắc các kiến_thức liên_quan đến toán giải_tích xác_suất đại_số tuyến_tính ... về lập_trình thì em đã biết và nhờ mọi người tư_vấn giúp em lộ_trình cũng như các khóa học hay về machine learning cho sinh_viên mới bắt_đầu như em em xin cảm_ơn,"['#Q&A', '#machine_learning']"
"mình đang tìm_hiểu về deep learning trong việc xử_lý hình_ảnh sau khi tra internet thì mình có những thắc_mắc sau đây mọi người có_thể chia_sẻ với mình về các câu hỏi này được không em cảm_ơn <number> embedding là quá_trình gì phân_biệt word embedding và image embedding hiểu embedding là quá_trình chuyển vector nhiều chiều thành vector có số chiều ít hơn bằng cách tạo ra một không_gian nhúng dành cho các từ có ý_nghĩa gần giống nhau word embedding và image embedding đều xử_lý việc biến input từ nhiều dimension thành vector tensor có ít dimension hơn ví_dụ thay_vì có <number> words thì ta sẽ có dạng tensor để biểu_diễn cho từng word là <number> dimension 0,0 ... 1,0 <number> số <number> và <number> số <number> ta sẽ phát_hiện ra những từ có cùng ngữ_nghĩa và tạo nên một embedded space <number> tensor sau_này khi biểu_diễn các ngôn_ngữ khác thì chỉ cần <number> vector chỉ index của từ đó để nhân với embedded tensor <number> pretrained model của quá_trình nhận_dạng hình_ảnh được thực_hiện qua các bước chính nào inception_v3 của torchvision models hỗ_trợ những gì trong quá_trình pretrained hoặc nhận_dạng hình_ảnh <number> hidden layer và embed layer khác gì nhau <number> ecoder và embedding khác gì nhau opinion encoder biến text iamge thành vector embedding là quá_trình giảm dimension của vector","['#Q&A', '#deep_learning', '#cv']"
chào mọi người em có người quen cần tìm giải_pháp làm mềm ảnh bitmap thành ảnh vector có_thể dùng cho thêu công_nghiệp wilcom yêu_cầu xử_lý được pencil hatching pattern lọc bỏ được chi_tiết thừa để phù_hợp với ảnh thêu không biết đã có ai cung_cấp giải_pháp chưa cảm_ơn mọi người rất nhiều ảnh minh_hoạ,"['#sharing', '#cv']"
chào mọi người tại_sao alexnet sử_dụng group convolution nhưng hầu_hết những implementation cộng_đồng của alexnet lại chỉ dùng convolution thông_thường,"['#Q&A', '#deep_learning']"
chào mọi người mình xin phép hỏi đến một_số vấn_đề của face recognition <number> mình thắc_mắc là trong các thư_viện như face_recognition thì đầu_ra của nó là <number> vector <number> chiều hay là một index sau khi được softmax <number> mình có tìm_hiểu thì thấy rằng họ sử_dụng model facenet trong thư_viện face_recognition mình cũng chưa hiểu facenet lắm mk có đọc được là nó train bằng softmax lớp cuối nhưng lâu_lâu mình lại thấy đâu_đó có tài_liệu nói rằng nó sẽ nhúng ảnh thành vector <number> chiều vậy có phải là trước lớp cuối là <number> linear <number> chiều và lớp cuối là <number> softmax linear đúng nhỉ hay_là lớp cuối_cùng chỉ là <number> linear <number> chiều sau đó sử_dụng l2_distance để đo độ tương_đồng hoặc tính loss nhỉ <number> vd mình có <number> thư_mục có <number> ảnh của <number> người khác nhau sau đó sử_dụng face_recognition thì với vấn_đề thứ <number> chưa giải_quyết được nó sẽ sinh ra vấn_đề tiếp là nếu lớp cuối_cùng là <number> softmax linear và trước nó là <number> linear <number> chiều thì có phải thư_viện sẽ đóng_băng toàn_bộ weight trừ cái weight kết_nối của <number> linear trên đúng không nhỉ lý_do mình nghĩ như_vậy là vì weight kết_nối mới khởi tạo rất dễ tạo ra loss lớn mà_lại phải update toàn_bộ weight thì nó sẽ như kiểu big learning rate ấy cái này mình đoán mò th ai thấy sai thì giúp mình với thực_ra thì sáng nay mình có gặp một người và có kêu mình rằng thay_vì em nhúng ra <number> vector rồi tính độ tương_đồng giữa các khuôn_mặt thì tại_sao em không cho model chạy qua rồi <number> phát cho ra kết_quả luôn mình đang nghĩ việc này không có khả_thi cho lắm tại vì nếu model càng sâu thì với dữ_liệu ít_ỏi chỉ có <number> hình_ảnh thì rất dễ bị overfiting còn nếu model quá nông thì khó mà có_thể nhận_diện chính_xác được điều này là mình đã thực_nghiệm khi train mobilefacenet arcmargin trên tập dữ_liệu <number> ảnh của hơn <number> đối_tượng vẫn bị overfitting nhưng mà do mình chưa data agumentation nên cũng không chắc mà mình hết colab ùi ai từng làm qua kiểu <number> phát cho ra kết_quả luôn thì chia sẽ cho mình với lỡ mình có hỏi ngu quá thì mong mn cũng đừng ném đá quá ha cảm_ơn mn đã đọc,"['#Q&A', '#cv', '#machine_learning']"
chào mọi người mình 30t là người trái ngành và đang có hứng_thú tìm_hiểu về ai mình có tham_khảo nhiều nguồn và đang theo lộ_trình_tự học ai <number> khóa trên udemy khóa thứ <number> bên dưới là áp_dụng ai applied machine learning for healthcare hadelin de ponteves kirill eremenko khóa học này tập_trung vào ứng_dụng machine learning trong lĩnh_vực y_tế và dữ_liệu y_tế do con chatgpt đưa ra và đã học xong khóa <number> trên theo mọi người lộ_trình này có ổn không thêm nữa mọi người cho mình xin tên link các khóa học toán trên youtube hoặc udemy cousera để theo ngành này nữa cảm_ơn mọi người,"['#Q&A', '#machine_learning']"
chào mọi người em đang làm một sản_phẩm để dự thi cuộc thi khkt thpt về việc cải_thiện thời_gian đèn giao_thông bằng ml em làm được phần car detection roi nhma tới khúc xử_lý để đưa ra một thời_gian chính_xác thì em đang phân giữa việc tìm ra một công_thức toán hay là dùng một model ml em có một thắc_mắc là liệu mình có_thể xây_dựng một mô_hình có_thể dự_đoán được thời_gian đèn_xanh đỏ vàng một ngã tư nào đó dựa vào các features là lưu_lượng xe số_lượng xe tại thời_điểm cả bốn cột đèn giao_thông không nếu được thì mình phải label bằng tay cho tập dữ_liệu đúng liệu mình có còn cách nào khác nhanh hơn không em cảm_ơn mọi người,"['#Q&A', '#cv', '#machine_learning']"
em chào mọi người em mới chuyển qua làm nlp được vài tháng nay trước đó em làm mảng vision nên em có một_vài câu hỏi muốn tham_vấn mọi người giả_sử quy_mô dữ_liệu lớn 10m short arabic text sentences of less than <number> words nguồn_lực khoảng <number> human annotators em gặp vấn_đề như sau đối_với bài_toán sentiment classification sc annotation của human thường rất subjective đặc_biệt đối_với các sentences có cả pos và neg sentiments thì rất khó gán nhãn một_số nguồn gợi_ý sử_dụng clustering words thành pos neg neu trước rồi đếm số pos neg neu trong mỗi sentences để tạo pseudolabel tuy_nhiên em thấy cách này chưa toàn_diện vì nghĩa của từ còn phụ_thuộc nhiều vào context em có thử sử_dụng một_số sc models pretrained on big data trên huggingface để sinh benchmark trên nhiều public datasets khác nhau thì thấy độ chính_xác chỉ mức <number> em đoán là do cách định_nghĩa pos neu neg sentiments của mỗi bộ dataset cũng khác nhau nhiều ngay cả việc định_nghĩa thế_nào là neu sentiment em cũng chưa tìm thấy thông_tin đủ tốt trong bài <number> tác_giả của báo có đề_xuất neu sentiment nghĩa_là no positive and no negative cơ_mà như thế_nào là no positive và no negative thì cũng rất đưa ra <number> quy_tắc nhất_quán có một_cách để generate consistent sc labels là sử_dụng public pretrained llms gpt tuy_nhiên em có thử gpt thì thấy chất_lượng khá tệ kể_cả google dịch cũng perform badly on arabic em so kết_quả dịch của google với kết_quả dịch của human translator em đoán là nlp models hiện_tại vẫn chưa hoạt_động tốt với arabic em rất mong nhận được sự giúp_đỡ của mọi người trích_dẫn <number>,"['#Q&A', '#nlp']"
em chào mọi người hiện em đang làm <number> project cuối kì về ml <number> bài_toán bài_toán ước_lượng công_ty tài_chính cần kiểm_soát thanh khoản của dòng tiền tại thời_điểm đầu tháng <number> cần ước_lượng số tiền thu của khách_hàng trong tháng <number> là bao_nhiêu dựa vào data có sẵn yêu_cầu requirements <number> clean data and train the models <number> diagnose and assess the results <number> use tools tuy_nhiên project khi làm ra được cmt là sai trong việc sử_dụng thống_kê suy_luận đang xài hiện_tại em vẫn chưa tìm ra chỗ fix chỗ đó nên mạo muội muốn hỏi thêm các anh_chị em cảm_ơn,"['#Q&A', '#machine_learning']"
mô_hình ai chuyển_đổi video 2d thành cấu_trúc 3d chi_tiết,"['#sharing', '#machine_learning']"
có bác nào làm_việc với segmentation trong yolo chưa cho em hỏi với là sau khi em train xong model thì đầu_vào ảnh của em phải chuẩn_hóa như nào mới cho vào model nhận_diện được vậy,"['#Q&A', '#cv']"
em chào mn em đang là sinh_viên đi thực_tập và em có được giao một task là crawl thông_tin về các teams cũng như lịch_sử_đấu lịch thi_đấu của giải_đấu premier league em có kiểm_tra khi vào trang thì web có gọi api tới để về data tuy_nhiên em vào api thì bị error <number> em có dùng cheerio để crawl thuần nhưng cái html nó trả về thì lại không chứa thông_tin do nó dyniamic render mn ai có kinh_nghiệm có_thể hướng_dẫn giúp em với em cảm_ơn mn,"['#Q&A', '#data']"
cuối tuần sau cvpr khai_mạc vancouver canada mình ko có paper nhưng cũng có_mặt ngày chủ_nhật bạn nào trong group cũng đi thì hội việt nam hangout nhé,['#sharing']
chúc các bạn buổi tối chủ_nhật vui_vẻ và ấm_áp bên người_thân_yêu trong tuần qua mình đã thực_hiện <number> bài viết vể sử_dụng typst được viết bằng rustlang để soạn_thảo_luận_văn luận_án và presentation slides mình hi_vọng nó hữu_ích cho các bạn muốn học và áp_dụng vào quá_trình biên_soạn tài_liệu cho các bạn trong khoa_học các sinh_viên còn có_thể phải làm poster để tham_gia các conferences vậy nên trong chuỗi bài về typst mình xin chia_sẻ bài còn lại sử_dụng typst để làm poster tại đây mong rằng mấy bài về chủ_đề typst này có giá_trị sử_dụng trong công_việc học_tập và nghiên_cứu của các bạn nếu các bạn thấy nó có ý_nghĩa với bản_thân mình thì xin đừng tiếc <number> star cho các repositories của mình nhé cảm_ơn các bạn nhiều ps mình hi_vọng các journals sẽ sớm chấp_nhận typst như <number> typsetting như word hay latex cho việc soạn_thảo manuscripts gửi cho các tập_san nhà xuất_bản trong thời_gian gần nhất,['#sharing']
"dạ em chào mọi người em đang có một_chút khúc_mắc trong bài_toán binary classification sử_dụng dataset này cụ_thể hơn là điểm f1 training của model thấp nhưng điểm f1 của validation và testing thì lại cao về dataset đây là dataset về giao_dịch thẻ tín_dụng và mục_tiêu dự_đoán là xem cuộc giao_dịch đấy có phải lừa_đảo hay không is fraud phân_bố class này rất mất cân_bằng cụ_thể là <number> triệu cuộc giao_dịch 30,000 giao_dịch lừa_đảo <number> of tổng_giao_dịch sau phần tiền xử_lý dữ_liệu em có chia ra <number> sets training cuộc giao_dịch trước <number> validation trong <number> và testing sau <number> với phần phân_bố class như sau <number> là giao_dịch không lừa_đảo <number> là giao_dịch lừa_đảo training data class <number> <number> class <number> <number> validation data class <number> <number> class <number> <number> testing data class <number> <number> class <number> <number> em hiện_tại đang sử_dụng model xgboost để dự_đoán và em có thu lại được một_số kết_quả như sau f1 score on training data <number> f1 score on testing data <number> pr auc score on training data <number> pr auc score on testing data <number> training report precision recall f1score support <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> accuracy <number> <number> macro avg <number> <number> <number> <number> weighted avg <number> <number> <number> <number> test report precision recall f1score support <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> accuracy <number> <number> macro avg <number> <number> <number> <number> weighted avg <number> <number> <number> <number> như em thấy thì model không học được tốt trên dữ_liệu training nhưng lại có kết_quả rất tốt trên dữ_liệu testing và cả trên validation set và bây_giờ em cảm_thấy hơi khó hiểu về trường_hợp như_vầy em có hiểu model sẽ bị underfit nếu_như model không_thể học đủ kiến_thức từ dữ_liệu training và như_vậy thì model sẽ không dự_đoán tốt được các dữ_liệu tương_lai như dữ_liệu test còn model sẽ overfit nếu_như model học quá khớp với dữ_liệu training và nhớ toàn_bộ các thông_tin của dữ_liệu đó thay_vì học cách phân_loại nên vì_thế model sẽ không thực_hiện tốt việc phân_loại tuy_nhiên trường_hợp của em model học kém trên dữ_liệu training nhưng lại trả kết_quả rất cao cho dữ_liệu testing và validation em không gửi kèm dữ_liệu validation đây nhưng kết_quả cũng na_ná phần testing vầy nên em muốn hỏi mọi người rằng bài_toán của em hiện_tại đang gặp vấn_đề gì và trong trường_hợp nào em có gửi kèm thêm một_số thông_tin đằng sau gồm loss của model lúc training learning curve và các ma_trận confusion em cảm_ơn mọi người loss của model validation_0 là dữ_liệu training validation_1 là dữ_liệu testing <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number> <number> validation_0aucpr <number> validation_0logloss <number> validation_1aucpr <number> validation_1logloss <number>","['#Q&A', '#machine_learning']"
xin chào mọi người hè này em tính đầu_tư thời_gian để học machine learning trên coursera có hai khóa machine learning tốt nhất đó là khóa machine learning specialization của deeplearning ai và khóa machine learning professional certificate của ibm mọi người cho em xin ý_kiến là khóa nào là khóa tốt nhất và chuyên_sâu nhất em không cần khóa beginnerfriendly em chỉ cần khóa nào dạy đầy_đủ nhất cảm_ơn mọi người nhiều,"['#Q&A', '#machine_learning']"
chuyện là em đang làm <number> project về image classfication trên mobile em có quantizition model xuống int8 em có xuất output thì nó ra <number> mảng giá trí như trong hình em muốn convert nó thành_phần_trăm tỉ_lệ chính_xác lên mạng kiếm tài_liệu nhưng không biết như thế_nào anh_chị nào biết chỉ em với em cám_ơn,"['#Q&A', '#cv']"
xin chào các anh_chị và các bạn mình làm về data tây_ban nha mình muốn join vào dự_án nào đó vn mà có liên_quan tới crypto curency thì tốt mình không yêu_cầu trả lương chỉ mong được học_hỏi từ các anh_chị và các bạn,"['#sharing', '#data']"
em chào anh_chị trong nhóm hiện em đã tốt_nghiệp đại_học bách_khoa hà_nội em đang tìm việc intern fresher về al tại hà_nội không biết anh chị công_ty nào có còn open cho vị_trí intern fresher không,"['#Q&A', '#machine_learning']"
chào mọi người em đang tìm_hiểu về chatbot tiếng việt sử_dụng underthesea nhưng em thấy ít tài_liệu về đề_tài này mọi người có tài_liệu hoặc code liên_quan cho em xin tham_khảo với em cảm_ơn,"['#Q&A', '#nlp']"
cho hỏi có ai biết trang opnai net ko mình thấy nó trả_lời câu hỏi cũng giống chat gpt ko biết có phải trang mạo_danh nhằm mục_đích gì người dùng ko hay_là trang này muốn giúp cho người việt được dùng chatgpt tại vn,"['#Q&A', '#nlp']"
tool cho ae dùng ai chỉnh_sửa ảnh,"['#sharing', '#machine_learning']"
chắc các bạn trong forum này nhiều người sử_dụng latex overleaf để soạn_thảo văn_bản luận_văn bài báo ... mặc_dù cộng_đồng latex rất mạnh nhưng mình rất ghét khi muốn xuất file phải bấm compile chờ nó quay khá lâu rồi lỗi nếu có tương_đối khó đọc gần_đây ngôn_ngữ rust nổi lên thay_thế và rồi typst và online ver tương_tự overleaf được phát_triển như là trình biên_soạn mới và mình nghĩ typst tuy còn non_trẻ nhưng nó sẽ có chỗ_đứng của riêng nó typst xuất file pdf gần như theo thời_gian thật mà không cần compile về syntax của typst tương_đối dễ đọc vậy nên mình thử tạo ra <number> template cho việc biên_soạn luận_văn sử_dụng typst tại đây hi_vọng với template này các bạn có_thể từng bước học cách sử_dụng typst và xa hơn là học rust chúc mọi người buổi tối vui_vẻ nếu các bạn thấy repository của mình thú_vị xin đừng tiếc <number> star cho nó nhé trân_trọng cảm_ơn,['#sharing']
xin giới_thiệu với mọi người một danh_sách dài tổng_hợp những textbooks xuất_sắc về các chủ_đề từ machine learning statistical learning optimization optimal transport algebraic statisics etc được chia_sẻ miễn_phí đến với cộng_đồng bởi chính những tác_giả viết ra những cuốn sách này với tên_tuổi lớn hàng_đầu trong giới khoa_học như sutton rl szeliski compvis hastie stats villani ot danh_sách được tổng_hợp và chia_sẻ bởi dr frank nielsen,"['#sharing', '#machine_learning', '#math']"
xin chào mọi người mình đang muốn tìm học về ai nhưng chưa biết bắt_đầu_từ đâu và cần học những gì mong_muốn của mình là có_thể sử_dụng ai áp_dụng vào lĩnh_vực phần_mềm các tool hỗ_trợ trong lĩnh_vực phát_triển web app mong mọi người tư_vấn lộ_trình,"['#Q&A', '#machine_learning']"
chào mọi người em có <number> câu hỏi này về universal approximation theorem <number> mlp có_thể xấp_xỉ skip connection và recurrent connection không <number> cnn có_thể được cài_đặt bằng mlp nhưng cũng có_thể coi mlp là cnn với kernel spatial size bằng 1x1 vậy cnn và mlp cái nào tổng_quát hơn nếu cnn tổng_quát hơn nó có riêng cho mình một approximation theorem không tương_tự rnn mạng có skip connection có approximation theorem cho riêng nó không cảm_ơn mọi người,"['#Q&A', '#deep_learning']"
em chào anh_chị trong nhóm hiện em đã tốt_nghiệp đại_học bách_khoa hà_nội em đang tìm việc intern fresher về machine learning ai deep learning tại hà_nội không biết anh chị công_ty nào có còn open cho vị_trí intern fresher không em sẽ chủ_động inbox gửi cv,"['#Q&A', '#machine_learning']"
chào mọi người mình xin giới_thiệu chuỗi seminar thú_vị về việc cung_cấp nền_tảng về việc triển_khai ml models với những kiến_thức trong industry <number> seminar <number> <number> <number> mlops marathon sample solution <number> seminar <number> <number> <number> fundamental series linux basics <number> seminar <number> <number> <number> fundamental series git github and github actions <number> seminar <number> <number> <number> containerization and orchestration <number> seminar <number> <number> <number> webapi fastapi and nginx <number> seminar <number> <number> <number> data drift and solutions,"['#sharing', '#machine_learning']"
xin chào các anh_em hiện_tại em đang gặp vấn_đề về độ chính_xác khi sử_dụng python để đọc kết_quả trên mô_hình onnx cụ_thể hơn trên môi_trường visual studio em sử_dụng mô_hình tự_động automl để phân lớp hình_ảnh image classification của ml net đầu_vào là <number> lớp mô_hình của automl sử_dụng huấn_luyện là dnn resnext50 kết_quả đạt được là <number> độ chính_xác em có thử <number> hình_ảnh test cho mỗi lớp kết_quả đều đúng tuy_nhiên khi sử_dụng mô_hình onnx để sử_dụng trên môi_trường python của google colab kết_quả đạt được là hoàn_toàn không chính_xác cụ_thể khi em đưa bất_cứ hình_ảnh nào vào kết_quả cũng chỉ đạt được là duy_nhất em đã thử chuyển mô_hình onnx sang tensorflow bằng thư_viện onnx2tf nhưng cũng chỉ cho ra một kết_quả duy_nhất em hi_vọng mọi người có_thể gợi_ý giúp em có cách nào có kết_quả mô_hình onnx đúng nhất dưới đây là link post issue trên github tuy_vậy cũng khá lâu rồi chưa có cách nào cải_thiện được vấn_đề này cả cảm_ơn mọi người đã xem bài và mong mọi người giúp_đỡ em,"['#Q&A', '#machine_learning', '#python']"
dạ em chào mấy thầy cô anh chị em là thành_viên mới của nhóm hiện_tại em đang bắt_đầu nghiên_cứu học về machine learning cho em hỏi thầy cô anh chị nào có lộ_trình học hay website để học machine learning cho em tham_khảo với được không em cảm_ơn các thầy cô anh chị,"['#Q&A', '#machine_learning']"
xin chào có thầy nào làm mentor data engineer hoặc machine learning theo project em xin theo học với,"['#Q&A', '#machine_learning']"
xin chào mọi người hiện em đang học môn machine learning cơ_bản và giảng_viên giao cho làm một cái project cá_nhân em đã chọn được một bài báo về y_sinh_học cụ_thể là em dùng mô_hình biobert để làm project nhưng vấn_đề là em tìm_hiểu và chạy code nhưng không được mọi người có_thể giúp em hiểu rõ hơn về bài báo và đoạn code được không vì em cũng mới học về machine learning nên em thấy code khá nhiều em xin cảm_ơn mọi người nhiều link bài báo link code,"['#Q&A', '#machine_learning']"
em chào mọi người em đang deploy model tensorflow sang graph pb mà khi cv2 dnn readnetfromtensorflow thì không nhận được layer nào từ model mong mọi người giúp em với em xin cảm_ơn,"['#Q&A', '#python']"
mình muốn hỏi cách xử_lý bài_toán hồi quy logistic như thế_nào khi đầu_vào như hình hàm logit được giả_định là tuyến_tính với các biến độc_lập nhưng decision boundary lúc này không_thể là dạng tuyến_tính bx bình_thường mà phải là phương_trình đường_tròn vậy làm thể_nào để xử_lý được vấn_đề này đặc_biệt khi ta không dự_đoán được hình_dạng của tập dữ_liệu tra_cứu thì có giải_pháp là chuyển sang hệ tọa_độ cực mà mình không hiểu lắm,"['#Q&A', '#machine_learning']"
chào mọi người đang là sinh_viên đi thực_tập em đang làm <number> project liên_quan đến bài_toán mà tập train và test đến từ <number> phân_phối khác nhau anh_chị có_thể cho em hỏi có cách nào để train model có kết_quả cao không,"['#Q&A', '#machine_learning']"
vấn_đề crossvalidation chào mọi người mình đang tập_tành thực_hành các project machine learning và gặp một vấn_đề mong mọi người giải_đáp giúp mình có <number> bộ imbalanced dataset theo google thì để xử_lý imbalanced thì mình dùng stratifiedkfold với weight để xử_lý khi đó mình thu được model và tính trung_bình các score trên tập valid để đánh_giá model modelx logisticclassifier para_1 ... para_n kfold stratifiedkfold n_splits <number> shuffle true random_state <number> split sau đó mình lại có <number> bộ test set hoàn_toàn tách_biệt với bộ data trên để dự_đoán lúc đấy mình suy_nghĩ đến việc có phải nên lựa_chọn model có perform tốt nhất trong model đó để predict cho test set đúng không mình có tra google và theo khả_năng đọc hiểu của bản_thân thì việc crossvalid trên model trên thực_chất chỉ là một_cách để kiểm_tra performance và đề_phòng th bộ train val của mình bị chia lệch còn thực_chất khi predict ta sẽ vẫn predict trên model ban_đầu kiểu y_pred modelx predict x_test đúng không mọi người còn việc đổi performance thì phụ_thuộc vào việc mình hiệu_chỉnh parameter như thế_nào không biết mình hiểu vấn_đề như_vậy có đúng không mọi người mình mong nhận được sự giải_đáp của mọi người,"['#Q&A', '#machine_learning', '#data']"
xin chào mọi người mình vừa phỏng_vấn một công_ty anh tuyển summer internship vị_trí machine learning mình muốn viết bài này để chia sẽ đợt phỏng_vấn này mục_đích để mọi người cùng nhau bàn_luận vì mình cũng chưa biết là câu trả_lời của mình là ổn chưa cụ_thể là như sau công_ty họ nghiên_cứu về hyperspectral camera camera quang_phổ cụ_thể là tấm hình sẽ có hơn <number> chiều không_gian màu thay_vì chỉ có <number> khi sử_dụng hyperspectral images thì dữ_liệu sẽ chính_xác và nhiều thông_tin hơn mình đến đợt phỏng_vấn <number> có câu hỏi như sau thì họ hỏi mình đại_khái là bạn có những cách nào để compress một bức hình và đối_với hyperspectral images thì làm_sao mình suy_nghĩ một_chút và trả_lời như sau một_cách mình có_thể nghĩ ra liền là có_thể dùng convolutional methods như một bức hình bình_thường hoặc pca họ hỏi thêm là vậy bạn có biết effects sau khi deploy methods như_vậy là gì không lúc đó mình trả_lời đơn_giản là sẽ giảm chất_lượng và thông_tin dữ_liệu lúc đó mình hơi run nên cũng không hình_dung được có cách nào nữa lúc cuối mình hỏi thêm rằng có phải việc compress hyperspectral images là một trong những vấn_đề team nghiên_cứu đang đối_mặt đúng không thì họ nói đúng vậy thật thật_sự mình tự học khá nhiều nên kinh_nghiệm còn rất ít nên khi phỏng_vấn mình chỉ trả_lời những gì mình nghĩ ra liền lúc đó thôi mọi người ai có kinh_nghiệm trong mảng này cho mình hỏi có câu trả_lời nào tốt hơn cho bức hình <number> không_gian màu như_vậy không mình cảm_ơn,"['#Q&A', '#machine_learning']"
góc hỏi_đáp mọi người đã từng dùng stacked hourglass network để nhận_diện pose estimation cho em hỏi chút được không đầu_vào của model là ảnh rgb và label là <number> keypoints còn đầu_ra của model là <number> heatmaps <number> vậy để tính hàm loss thì mình tính dựa trên <number> heatmaps hay extract heatmap thành 15keypoints để tính loss <number> nếu tính loss bằng heatmaps thì làm_sao để có_thể tính vì ảnh vào là rgb và label là <number> keypoints còn outputs của model là <number> heatmaps <number> em có sai dữ_liệu label hay input đầu_vào không mong mọi người góp_ý giúp em em cám_ơn,"['#Q&A', '#cv', '#deep_learning']"
làm_việc trong lĩnh_vực ml trong một thời_gian rồi mà chưa có bài nào trong forum mình nhân_dịp đang làm_việc về diffusion models mình xin phép chia_sẻ bài viết mình tổng_hợp lại và giải_thích một_số kiến_thức về diffusion models hy_vọng sẽ có_ích với các bạn tìm_hiểu về nó,"['#sharing', '#machine_learning']"
một bài tổng_hợp về kiến_trúc mô_hình ssd một trong những mô_hình có tốc_độ xử_lý cao và độ chính_xác tốt nhất trong lớp các mô_hình object detection,"['#sharing', '#cv', '#deep_learning']"
cho em hỏi nhóm mình ai có hứng_thú với dữ_liệu tài_chính không em đang học tại trường keimyung khoa của em tổ_chức cuộc thi phân_tích dữ_liệu thông_tin mọi người xem ảnh nha bộ dữ_liệu mọi người có_thể xem link này kỹ_năng của em chỉ mức cơ_bản thôi chủ_yếu muốn học từ mọi người là chính giải nhất <number> <number> giải nhì <number> <number> giải ba <number> giải chia đều cho <number> người trong nhóm nhóm đã có <number> người rùi,"['#sharing', '#data']"
mọi người cho hỏi ma_trận dạng như thế này được gọi tên là gì và có những tính_chất như thế_nào cảm_ơn mọi người,"['#Q&A', '#math']"
phương_pháp dạy chatgpt học được kiến_thức mới xin chia_sẻ tới các anh_em trong group mô_hình tổng_quát và các kĩ_thuật để dạy chatgpt hiệu_quả đây là các phương_pháp đang được sử_dụng thực_tế với giải_pháp gpt salebot của bọn mình rất mong sẽ nhận được thêm nhiều ý_kiến đóng_góp về các cách_thức hiệu_quả hơn nguyên_lý chung chatgpt nói_riêng và các mô_hình ngôn_ngữ lớn llm nói_chung có một tính_chất rất đặc_biệt đó là nó có một trí_nhớ ngắn_hạn mà nếu đưa dữ_liệu mới vào vùng nhớ này thì mô_hình sẽ học được dữ_liệu mới này và sử_dụng trong nội_dung trả_lời thuật_ngữ gọi là incontext learning hoặc one fewshot learning đây là một đặc_điểm có tính_cách_mạng bởi nó giúp huấn_luyện chatgpt nhanh_chóng và dễ_dàng hơn rất nhiều so với giải_pháp finetune truyền_thống so_sánh đơn_giản cách huấn_luyện ai truyền_thống giống như một anh học_trò phải bỏ công bỏ sức ôn_tập để có kiến_thức đi thi trong khi đó huấn_luyện chatgpt theo incontext learning thì giống như anh học_trò đó sử_dụng phao cùng một mục_đích là trả_lời được câu hỏi của người ra đề thì rõ_ràng dùng phao sẽ nhanh_chóng và thậm_chí trong nhiều trường_hợp còn chính_xác hơn là tự học với điều_kiện là học_trò này phải rất thông_minh là điều mà chatgpt có thừa đặc_điểm có tính_cách_mạng này của chatgpt và llm mở_đường cho rất nhiều ứng_dụng khác nhau có_thể phát_triển trên nền chatgpt với chi_phí rẻ hơn rất nhiều so với truyền_thống về tổng_thể những ứng_dụng này sẽ đều hoạt_động theo mô_hình_như sau mình tiếp_tục lấy ví_dụ thi_cử trên cho dễ hiểu bước <number> đọc đề phân_tích đề bước này hệ_thống sẽ lấy câu hỏi của người dùng và phân_tích ý_đồ intention của câu hỏi đó là gì bước <number> tìm phao phù_hợp phao đây chính là đoạn dữ_liệu phù_hợp cần đưa vào bộ_nhớ ngắn_hạn của chatgpt để nó trả_lời được câu hỏi việc chọn phao này gọi là truy vấn thông_tin information retrieval mà mình sẽ giới_thiệu các kĩ_thuật chính của nó phần tiếp bước <number> sử_dụng phao để xây_dựng đáp_án bước này thì cho chatgpt đọc hiểu thông_tin trong phao và sử_dụng thông_tin này để trả_lời cho người dùng có_thể điều_khiển quá_trình này bằng prompt điều_khiển giúp câu trả_lời có tính_cách và văn_phong khác nhau hiểu đơn_giản là cùng một đề_bài dùng cùng một phao thì các anh học_trò khác nhau sẽ cho ra các câu trả_lời theo phong_thái riêng các kĩ_thuật lấy dữ_liệu từ bộ_nhớ dài_hạn trong mô_hình huấn_luyện chatgpt kể trên thì khâu quan_trọng nhất chính là chuẩn_bị và chọn ra được đúng phao từ đống kiến_thức lớn chung khâu này quyết_định toàn_bộ chất_lượng trả_lời của chatgpt hay hiểu đơn_giản là chuẩn_bị phao lệch tủ hay dùng phao lệch đề_bài thì đều khiến thi trượt khâu này trong khoa_học máy_tính gọi là truy vấn thông_tin information retrieval ir là một lĩnh_vực được phát_triển rất lâu_dài có rất nhiều kĩ_thuật ir khác nhau nhưng dưới đây là một_số kĩ_thuật có_thể áp_dụng hiệu_quả với bài_toán huấn_luyện chatgpt fuzzy matching so khớp văn_bản đây là kĩ_thuật đơn_giản nhất nó đơn_thuần so_sánh sự khác_biệt về từ_khoá giữa câu hỏi với lại dữ_liệu phù_hợp để trả_lời kĩ_thuật này giống như anh học_sinh dốt trong đầu không có kiến_thức gì chỉ xem đề_bài nhắc đến từ_khoá gì thì tìm phao có chứa nhiều từ trùng nhất để chép bm25 đây là kĩ_thuật cao_cấp hơn fuzzy matching nó biết trong câu hỏi của người dùng và dữ_liệu trả_lời thì đâu là từ_khoá quan_trọng đâu là từ_khoá ít quan_trọng kĩ_thuật này giống như anh học_sinh có nghe giảng dù cũng chưa thực_sự hiểu lắm nhưng cũng nhớ được vài từ_khoá thày cô hay nhắc tới nên trong các phao na_ná nhau thì anh biết chọn phao chứa nhiều từ_khoá quan_trọng nhất có trong đề_bài điều thú_vị đây là trong thực_tiễn dù anh học_sinh chẳng hiểu gì bài giảng chỉ dùng mẹo thì mẹo này cũng rất hiệu_quả semantic search vector search cuộc_đời không bao_giờ đơn_giản kiểu học gì thi nấy mà đề_bài luôn được các thày cô ra kiểu lắt_léo mà phải tư_duy thì mới hiểu được đây là dạng bài gì áp_dụng kiến_thức đã học nào đây chính là chỗ mà kĩ_thuật semantic search áp_dụng từ cái tên cũng đã nói lên kĩ_thuật này đó là thay_vì chỉ nhìn vào mặt_chữ thì đọc hiểu câu hỏi rồi tìm xem kiến_thức nào trong những cái đã biết thực_sự liên_quan tới nội_dung này quá_trình đọc hiểu này của máy gọi là embedding dữ_liệu ngữ_nghĩa của câu hỏi được biểu_diễn dạng vector và quá_trình tìm_kiếm là quá_trình so_sánh độ gầnxa giữa các vector nên kĩ_thuật này còn gọi là vector search lĩnh_vực vector search đang được thúc_đẩy phát_triển rất nhanh sau khi chatgpt xuất_hiện đánh_giá từ thực_tiễn áp_dụng phối_hợp các kĩ_thuật huấn_luyện chatgpt kể trên vào sản_phẩm gpt salebot demo tại mình rút ra được một_số đánh_giá fuzzy matching rất thích_hợp để áp_dụng cho các câu hỏi cụ_thể rõ nghĩa dùng chuẩn thuật_ngữ bm25 rất thích_hợp với những câu hỏi dài có nhiều chi_tiết semantic search thích_hợp với những nội_dung ngắn và giỏi trong việc phân_biệt các câu na_ná nhau về hình_thức nhưng khác nhau về ngữ_nghĩa trên thực_tế để huấn_luyện chatgpt hiệu_quả thì không chỉ sử_dụng một phương_pháp mà cần kết_hợp nhiều phương_pháp lại với nhau và team gpt salebot hiện đã triển_khai các kĩ_thuật để huấn_luyện chatgpt đạt chất_lượng tương_đương chatbot fin của intercom là phiên_bản tiên_tiến nhất của trùm chatbot quốc_tế trình_độ này chatbot không_những cần hiểu tốt câu hỏi của người dùng và trả_lời chính_xác theo thông_tin được huấn_luyện mà còn phải có khả_năng xử_lý các dạng viết tắt viết sai chính_tả từ lóng có khả_năng đặt lại câu hỏi làm rõ nghĩa và gợi_ý các câu hỏi followup để tiếp_tục hội_thoại các bạn có_thể trải nghiệm thử các tính_năng này tại mở_rộng huấn_luyện chatgpt trên dữ_liệu riêng và áp_dụng phương_pháp này vào các bài_toán cụ_thể như chatbot đang là lĩnh_vực phát_triển nhanh và sẽ còn có nhiều giải_pháp thú_vị hơn trong tương_lai nếu bạn muốn nắm_bắt cơ_hội và trở_thành các chuyên_gia về triển_khai chatbot chuyên_gia huấn_luyện chatgpt theo bài_toán đặc_thù của doanh_nghiệp thì có_thể đăng_ký trở_thành partner triển_khai hoặc nhân_sự của gpt salebot theo link dưới đây quyền_lợi của partner là sẽ được tiếp_cận những hiểu_biết sâu về công_nghệ chatgpt những insight trong việc triển_khai chatbot trợ_lý ảo thành_công và đón_đầu làn_sóng conversational marketing đang diễn ra nhanh_chóng sắp tới lộc đặng,"['#sharing', '#nlp']"
xin chào các bạn mình làm mảng geospatial rẽ ngang cụ_thể là data capture processing point cloud data 3d modelling mình chỉ viết vài script cơ_bản phục_vụ công_việc trên python giờ muốn tham_gia sâu hơn vào ml không biết trong group mình có ai làm về mảng này không mình xin phép được kết_bạn và học_hỏi thêm mình melbourne australia nếu có bạn nào đây mình xin mời cà_phê,"['#Q&A', '#machine_learning']"
hcm chào các anh chị em là người trái ngành có đam_mê về lĩnh_vực ai và đang mong_muốn tìm_kiếm công_việc bên mảng này mle ds de hiện_tại thì tình_hình xin việc fresher cho ml dl cũng khó_khăn nên em muốn dành thêm thời_gian để tiếp_tục trau_dồi bản_thân nâng cao khả_năng của mình lên vậy nên em viết post này mong được anh chị nào có_thể cho em cơ_hội nhận em vào làm để học_hỏi thêm có cơ_hội tiếp_xúc với dự_án thực_tế công_ty hay freelance đều được em ko quan_trọng chuyện lương hcm anh chị cmt sẽ inbox cv em cảm_ơn nhiều,"['#sharing', '#machine_learning']"
xin phép spam group một_chút hành_động này đáng bị lên_án tôi luôn phản_đối chuyện đạo văn không trích nguồn đằng này bạn thầy henry này còn lấy luôn cả slide rồi ghi tên mình vào tài_khoản này trước đây đăng khá nhiều bài trong group và tự_xưng là thầy henry tôi xin phép xóa tài_khoản và các bài liên_quan bạn nào quan_tâm có_thể qua group của thầy theo_dõi,['#sharing']
mọi người nghĩ sao về tensorflow developer certificate thời_điểm hiện_tại em mình background về computer science đã làm_việc nghiên_cứu với ml gần <number> năm đang băn_khoăn có nên ôn thi làm_đẹp cv không vì đọc review có vẻ không yêu_cầu chuyên_môn cao và công_việc hiện_tại công_ty chưa nhiều áp_lực cảm_ơn mọi người đã đọc,"['#sharing', '#machine_learning']"
em chào mọi người có ai có_thể cho em tài_liệu tham_khảo về việc sử_dụng bayesian neural network bnn model để dự_đoán giá btc bằng python không em làm đồ_án nhưng kiếm tài_liệu về thuật_toán này thì lại rất ít,"['#Q&A', '#deep_learning']"
chào các anh chị trong forum em sn <number> đã ra trường tất_cả kiến_thức về ai em đều tự học nên nhiều phần kiến_thức lại thiếu mà có phần lại tốt và em không kinh_nghiệm các dự_án thực_tế vì_vậy em viết post này để mong anh chị nào có_thể cho em cơ_hội làm_việc để học_hỏi thêm được làm_việc trong dự_án thực_tế em có_thể thực_tập hay fresher tại hcm em tự_tin về phần giao_tiếp tiếng anh hay tốt_nghiệp đh tốt mà cho em hỏi ngu là mấy anh_chị tuyển_dụng giờ có nhìn vào những yếu_tố này không,"['#Q&A', '#machine_learning']"
chào mọi người cho em hỏi về bài_toán object detection liệu mình có phương_pháp nào để cung_cấp thông_tin bổ_sung cho mô_hình không ví_dụ như số_lượng object không quá hoặc background của các ảnh luôn giống nhau em cảm_ơn,"['#Q&A', '#cv']"
chia_sẻ lại cho các bạn một bài viết cực hay về ứng_dụng của ml ds trong ngân_hàng và các tổ_chức tài_chính mình đang làm về risk management cho bank thì thấy bài viết đặc_biệt hữu_ích khi mình hiểu thêm về các mô_hình machine learning đang được áp_dụng và khai_thác trong các hệ_thống của ngân_hàng,"['#sharing', '#machine_learning']"
chào mọi người em đang optimize lại code của em trong lúc optimize thì em nhận thấy một điều kì_lạ cụ_thể là như hình <number> em tạo <number> tensor là mathched sau đó truyền images vào network rồi em đo thời_gian gán matched <number> thì kết_quả là lần lặp_đầu luôn tốn rất nhiều thời_gian mà em không biết tại_sao vấn_đề đó chỉ là một_phép gán nhưng như trong hình <number> nếu em không truyền images vào network và đo thời_gian em gán matched <number> thì nó lại rất nhanh vậy lí_do là do đâu vậy em đang để config device cuda,"['#Q&A', '#deep_learning']"
chào cả nhà mình đang bị vấn_đề này khi chạy thebloke vicuna7bgptq4bit128g hoặc nekoinstituteofscience llama13b4bit128g trên textgenerationwebui và không biết tại_sao lại bị vậy mình cũng đã test chạy anon8231489123 vicuna13bgptq4bit128g với cùng thông_số và không bị vấn_đề gì cả đây là câu_lệnh để mình chạy server python server py share autodevices chat modelmenu wbits <number> groupsize <number> mong mọi người giúp mình mình cám_ơn rất nhiều,['#Q&A']
mediapipe lowcode nocode ai for everyone bạn nào quan_tâm đến ứng_dụng ai thì nhớ dùng thử mediapipe là thư_viện để các bạn developer có_thể_tích_hợp ai vào ứng_dụng của mình một_cách dễ_dàng chỉ với một_vài dòng code nhé team mình mới ra_mắt phiên_bản mới của mediapipe google năm nay với <number> api phục_vụ nhiều use case khác nhau như face landmark detection selfie segmentation các bạn muốn biết cụ_thể hơn thì xem video này của mình nhé hy_vọng thư_viện này sẽ hữu_ích cho các bạn bonus thêm dưới comment là video về project gameface công_cụ để dùng khuôn_mặt điều_khiển con chuột máy_tính bọn mình build với mediapipe source code có trên github cho những bạn muốn tìm_hiểu kỹ hơn nhé,"['#sharing', '#machine_learning']"
xin chào mọi người em có một câu hỏi như này tính hè này sẽ học hai khoá về ml trên cousera nhưng mọi người nói học mấy khoá đó để có kiến_thức nền_tảng chứ basic quá đi làm không ăn_thua vậy nếu_như học xong thì mình nên làm gì học gì tiếp_theo để có_thể đi làm được em vẫn chưa hình_dung ra bởi_vì thấy cac cty chỉ tuyển người đã có kinh_nghiệm về ml đi làm chứ tuyển intern mong mn giải_đáp,"['#Q&A', '#machine_learning']"
em có một bài_tập training model nhưng bị lỗi sppf không biết mọi người có ai bị lỗi này như em không em đang tìm cách fix mong anh_chị giúp_đỡ,"['#Q&A', '#machine_learning']"
dạ chào mọi người hiện em đang muốn finetune mô_hình trocr cho dữ_liệu bao_gồm công_thức latex tiếng việt và cả tiếng anh nhưng trước_hết em đang thử với mỗi latex không thôi xem như thế_nào thì cer mãi vẫn không xuống quá <number> không biết mọi người có kinh_nghiệm gì khi finetune mô_hình trên một tập dataset custom và có_thể cho em vài gợi_ý để thực_hiện bài_toán này được không vì em chưa có nhiều kinh_nghiệm nên gặp khó_khăn em cảm_ơn mọi người đã đọc bài,"['#Q&A', '#deep_learning']"
chào các anh chị trong forum em sn <number> đã ra trường do lúc trước đi học không có định_hướng sớm nên phải đến gần lúc ra trường mới xác_định theo ai em đã đi thực_tập nhưng hiện_tại không có việc_làm tất_cả kiến_thức về ai em đều tự học nên thiếu kinh_nghiệm làm_việc tại các dự_án thực_tế vì_vậy em viết post này để mong anh chị nào có_thể cho em cơ_hội làm_việc để học_hỏi thêm được làm_việc trong dự_án thực_tế em có_thể đi làm không lương và làm_việc tại hà_nội em cảm_ơn nhiều,"['#Q&A', '#machine_learning']"
em đang có bài_tập là về seq2seq cho bài_toán summarization nhưng trên model nó có độ chính_xác là khoảng <number> là có_thể dự_đoán các từ tiếp_theo các bác có_thể xem code dưới đây cho em hỏi code em dự_đoán đúng chưa hay em đang làm sai chỗ nào em xin cám_ơn,"['#Q&A', '#deep_learning', '#nlp']"
chào mọi người là sinh_viên mới mua được chiếc vga rtx <number> và 32gb ram muốn build <number> pc để học_tập và làm nghiên_cứu về computer vision vì budget của không được cao lắm nên đang tính mua con cpu i3 12100f mọi người cho hỏi con cpu này có đủ cho việc học_tập và nghiên_cứu về computer vision deep learning không cảm_ơn mọi người,"['#Q&A', '#cv']"
chào mọi người không biết đây có bạn sinh_viên nào đang làm project về computer vision có_thể cho mình <number> chân vô hỗ_trợ không công được tại mình muốn tích_lũy thêm kinh_nghiệm từ những project ấy nên chủ_yếu vừa giúp lại vừa học_hỏi cái mới luôn ai có nhu_cầu thì cứ cmt mình giúp hết_mình nha,"['#Q&A', '#cv']"
mojo programming language chris lattner tác_giả llvm ngôn_ngữ swift tim davis và team modular vừa cho ra_mắt ngôn_ngữ lập_trình mojo được cho là dễ đọc như python nhanh hơn tốc_độ của và safety như rust gần như là thế mạnh của từng ngôn_ngữ vào trong mojo điểm hay_ho của mojo là cho phép truy_cập toàn_bộ hệ sinh_thái có sẵn của python ví_dụ như là numpy pandas matplotlib trực_tiếp trong mojo mojo is actually superset of python so can use my python code hiện_tại mojo đang trong giai_đoạn beta product launch <number> keynote ngày <number> <number> <number> còn nêu ra những vấn_đề về chi_phí phần_cứng cơ_sở hạ_tầng khi triển_khai và xây_dựng các hệ_thống ai nếu những gì team modular nói là đúng thì đây sẽ là một bước_ngoặt tương_đối lớn link,"['#sharing', '#python']"
chào cả nhà hiện em đang đọc hiểu paper này về convergence proof của federated learning khi chứng_minh theorem <number> cuối trang <number> thì tác_giả có chuyển từ _k sang như trong hình đính kèm mọi người cho em hỏi là tại_sao lại làm như_vậy được không cảm_ơn mọi người,"['#Q&A', '#math']"
hello chào cả nhà mình muốn hỏi build <number> con server để training với cấu_hình sau cpu intel core i7 12700k gpu x2 rtx <number> 12gb thì liệu chip core có ảnh_hưởng đến hiệu_năng khi sử_dụng cùng với <number> card rời không hay main quyết_định mong được giải_đáp mình cám_ơn,['#Q&A']
hello everyone need data set of danish language including handwriting or typing anyone who can share or sell please comment below main purpose for research research and study thank you everyone,['#data']
chào mọi người em là một học_sinh cấp <number> đang tìm_tòi về các kiến_thức của machine learning và xử_lý ảnh cho cuộc thi nghiên_cứu khoa_học em đang làm một miniproject về phân_loại rác thì em có thắc_mắc là giữa rác tái_chế và rác không tái_chế thì khi xử_lý ảnh em cần phải phân_tích các yếu_tố nào của rác để có_thể đưa vào tập dữ_liệu song với đó là em cũng muốn được mọi người chỉ_giáo về các hướng để phân_tích ảnh em cảm_ơn mọi người,"['#Q&A', '#machine_learning', '#cv']"
những bước_tiến mới nhất trong xử_lý đồ_họa với ai,"['#sharing', '#cv']"
chào mọi người hiện em là thạc_sỹ ngôn_ngữ_học đang tìm_hiểu về ứng_dụng ngôn_ngữ vào khoa_học máy_tính có thấy mảng xử_lí ngôn_ngữ tự_nhiên nlp thì kết_hợp cả kiến_thức_về ngôn_ngữ_học và máy_tính do em chưa có kiến_thức gì về ngành khoa_học máy_tính các anh chị cho em hỏi đối_với người chưa có nền_tảng it như em thì nên bắt_đầu học từ đâu và những mảng nào trong ngành có_thể ứng_dụng được kiến_thức chuyên_sâu_về ngôn_ngữ ngữ_âm được em cám_ơn,"['#Q&A', '#nlp']"
các bạn vui_lòng đăng tin tuyển_sinh tuyển_dụng sự_kiện tháng <number> <number> vào comment của post này,['#sharing']
mlopsvn tiếp_tục tổ_chức seminar free về công_nghệ search hay được sử_dụng trong các hệ_thống khuyến_nghị recommendation system vào tối thứ <number> tuần này mời các bác quan_tâm đăng_ký tham_gia,['#sharing']
xin chào mọi người mấy ngày_nay bắt_đầu tìm_hiểu về transformer model và cũng đã tìm đọc các blog để xem kĩ hơn về các thuật_toán của nó nhưng mà thấy có khá ít blog bằng tiếng việt nói đến vậy nên trong quá_trình tìm_hiểu đã viết <number> bài viết nói chi_tiết từng bước một_số thuật_toán cơ_bản của transformer model theo cái cách mà đã hiểu bởi_vì cũng mới học nên sự nhầm_lẫn về kiến_thức sẽ xảy ra nên hy_vọng sẽ nhận được phản_hồi của mn cảm_ơn,"['#sharing', '#deep_learning']"
mlops marathon là cuộc thi về mlops đầu_tiên được tổ_chức tại việt_nam nhằm tạo sân_chơi cho các đội vừa xây_dựng các ai ml model vừa triển_khai và vận_hành nó trên môi_trường production không chỉ vậy giải nhất có giá_trị lên tới <number> triệu đồng đăng_ký tham_gia thôi nào mọi người ơi,['#sharing']
hỏi về thư_viện python mình đang làm bài_toán ước_lượng phân_bố của với là multi dependent correlated output và là multivariate continuous not categorical features mình muốn tìm thư_viện python mà implement được xác_suất theo kiểu <number> approximate where offdiagonal entries are not zeros hoặc là có_thể sample được đây là bài_toán bayesan multidependent output regression tuy_nhiên mấy thư_viện như gaussian process sklearn thì hiện_tại implementation treat các output independent với nha,"['#Q&A', '#math', '#python']"
hello mọi người mình có bài_toán build một regression model để predict target variable có distribution như này mình đã thử nhìu cách dùng sota gradient boosted algorithm như lgbm hay xgboost mà rmse vẫn rất cao theo mình tìm_hiểu thì đây là tweedie distribution ko biết có cao nhân nào biết cách giải_quyết vấn_đề này không,"['#Q&A', '#machine_learning']"
vì vụ_việc này liên_quan tới ba thứ machine learning penn state university và việc đạo văn tôi thấy cần phải lên_tiếng hy_vọng chưa có bạn nào trong group từng bỏ ra số tiền lớn để theo học tại đây,"['#sharing', '#machine_learning']"
chào và tiep vuhuu đang có bài_toán như thế này nhờ giúp_đỡ export ra file báo_cáo dựa trên câu thoại trên zalo ví_dụ câu này em là văn thanh hôm_nay <number> <number> <number> em đã làm xong task expect ngày <number> <number> <number> văn thanh task đã xong hoặc chào anh tuấn em là thanh hôm_nay <number> <number> <number> vô trễ nên làm chưa kịp task mới xong thôi ngoài_ra task cũng chưa làm expect ngày <number> <number> <number> thanh task đã xong task chưa xong em bỏ ml <number> năm nên giờ quên hết cho hỏi đây là dạng bài_toán gì nghĩ là speech to text và data mining ko biết đúng ko và có thư_viện nào mì ăn_liền ko prefer java vì các dự_án hiện_tại đều viết bằng java thank,"['#Q&A', '#python', '#nlp']"
và đang thay_đổi cuộc_chơi,['#sharing']
mình đang tìm_hiểu về mạng mlp và lan_truyền ngược mn cho em hỏi về các biến_dạng của lan_truyền ngược được không em tìm trên mạng thì thấy ít tài_liệu về nó và hỏi chatgpt thì câu trả_lời mỗi lúc mỗi khác em cảm_ơn,"['#Q&A', '#machine_learning']"
hello all cho mình hỏi ngoài elastic có engine nào support search sử_dụng ml để cá_nhân_hóa kết_quả mn mình muốn làm chức_năng search cho trang tìm_kiếm job sử_dụng ml giả_sử user tìm_kiếm job php hà_nội hoặc user click xem các job hà_nội không thực_hiện search thì nó sẽ suggest và đưa các job hà_nội lên hàng_đầu vì project của mình nhỏ search khoảng 1k item thôi nên dùng elastic là hơi thừa với lại nó ngốn ram quá mình chỉ_định chạy trên con vps 1gb ram thôi,['#Q&A']
ai mới tự_phát_triển dựa trên thuyết tiến_hóa darwin,['#sharing']
xin hỏi có anh chị em bạn nào đang tập_trung_học cuốn dive into deep learning ko mình muốn tìm_kiếm một nhóm bạn cùng học để tiện trao_đổi và học_hỏi mxnet thấy hơi khó nhằn hi,['#Q&A']
cần giúp_đỡ về cách sử_dụng pretrained model em là software engineer đang làm project trong đó có chức_năng về similarity search vì không phải dân chuyên ai nên em chỉ học cách dùng pretrained model process của em như sau <number> dùng pyvi vitokenizer để tokenize input <number> dùng model vinai phobertlarge để encode thành vector <number> lưu vector này vào postgres với extension ankane pgvector <number> search vector bằng cosine_distance provided by pgvector mọi thứ khá ổn khi em làm poc em search bằng những câu hoàn_chỉnh như nhà cung_cấp mainboard h110i tại hcm nhưng đưa vào sử_dụng thì khách_hàng query rất vắn_tắt kiểu h110i và kết_quả trả về còn thua cả full text search thậm_chí không match được câu nào có chữ h110i trong khi search nguyên câu thì lại có expect của em là kể_cả khi khách_hàng chỉ nhập tên mã sản_phẩm thì ít_nhất cũng trả về những câu có chứa mã sản_phẩm đó em khá bế_tắc chỗ này mong được mọi người tư_vấn,"['#Q&A', '#nlp', '#deep_learning']"
xin chào mọi người em đang làm bài về object detection và đang dùng yolo v8 mọi người cho em hỏi trong phần gắn nhãn thì gắn nhãn kiểu rectangle hay polygon có hiệu_quả hơn và yolo có hỗ_trợ detect bounding box dạng polygon không em xin cảm_ơn,"['#Q&A', '#cv', '#deep_learning']"
chào mọi người em đang đọc bài viết về pca của thầy tiệp em có một chỗ thắc_mắc là trong bài viết có một câu thế này pca có_thể được coi là phương_pháp đi tìm một hệ cơ_sở trực chuẩn đóng vai_trò một_phép xoay sao cho trong hệ cơ_sở mới này phương_sai theo một_số chiều nào đó là rất nhỏ và ta có_thể bỏ_qua tuy_nhiên giả_sử em có một ma_trận dữ_liệu và một_phép xoay ứng với ma_trận trực_giao tức_là uy rõ_ràng ma_trận hiệp phương_sai của và là như nhau tuy em lại thấy điều này rất phản trực_giác ví_dụ cụ_thể như hình bên dưới rõ_ràng khi áp_dụng một_phép xoay thì phương_sai đã bị thay_đổi tuy_nhiên trong công_thức trên thì ma_trận hiệp phương_sai là như nhau em đã hiểu sai đâu vậy,"['#Q&A', '#math', '#machine_learning']"
tương_lai của trí_tuệ nhân_tạo tạo sinh <number> nic thân mời tiệp cùng các bạn bên forum machine learning cơ_bản tới tham_gia sự_kiện the future of generative ai <number> do bên nic tổ_chức trung_tâm đổi_mới sáng_tạo quốc_gia nic bộ kế_hoạch và đầu_tư phối_hợp với mạng_lưới đổi_mới sáng_tạo việt_nam tại thung_lũng silicon tổ_chức hội_thảo tương_lai của sự sáng_tạo từ công_nghệ ai <number> hội_thảo có sự góp_mặt của các chuyên_gia ai hàng_đầu từ thung_lũng silicon và việt_nam dự_kiến thu_hút được sự quan_tâm đáng_kể từ các nhà lãnh_đạo nhà nghiên_cứu và những người đam_mê ngành ai trên toàn thế_giới mang đến cơ_hội duy_nhất để kết_nối với các công_ty công_nghệ và tài_năng hàng_đầu của việt_nam và hoa kỳ anh kim pham cohost ai anh hung tran gotit ai chị tâm lê turing anh phong nguyen fpt ai anh võ_minh tuệ kỹ_sư ai chị lan shuezhao basisset ngoài_ra với mục_đích mang đến cho người tham_dự cơ_hội trao_đổi trực_tiếp với đại_diện các công_ty công_nghệ từ silicon valley các xu_hướng mới nhất và cách áp_dụng ai để cải_thiện hoạt_động_kinh_doanh phát_triển thị_trường thời_gian <number> <number> <number> <number> ngày <number> <number> <number> link đăng_ký bit ly cohostnic sự_kiện online qua zoom và offline tại vp nic số <number> tôn thất_thuyết cầu giấy hà_nội với hung tran và <number> người khác,['#sharing']
seminar tiếp_theo tổ_chức bởi mlopsvn với chủ_đề model optimization sẽ diễn ra online lúc 8h tối thứ <number> tuần này mời cả nhà đăng_ký tham_gia nếu quan_tâm,['#sharing']
mọi người cho em hỏi tại_sao accuracy_score của decision tree lại cao hơn cả random forest vậy code,"['#Q&A', '#machine_learning']"
hello all mình đang tìm thông_tin về ranh_giới lat long chi_tiết của từng tỉnh huyện xã vn cập_nhật mới nhất check trang rồi chọn vn thì có đây đủ thông_tin nhưng thông_tin hơi cũ <number> số nơi vn đã xác nhập đổi tên như thành_phố thủ đức thì ko có nên lên đây nhờ mọi người nếu ai có data mới nhất thì share giúp mình với many thanks,"['#Q&A', '#data']"
xin chào mọi người mình đang phát_triển một tool gán nhãn dữ_liệu mới base trên labelme và mô_hình segment anything mới nhất của facebook xin phép được chia_sẻ đến toàn_thể nhóm mình để xin gạch đá và comment để tiếp_tục cải_tiến link demo,['#sharing']
em chào mọi người hiện_tại em vừa học xong <number> machine learning và deep learning specializations của thầy andrew ng mọi người có_thể gợi_ý cho em một_số project áp_dụng kiến_thức đã học và học tiếp những kiến_thức gì cho thị_giác máy_tính được không em cảm_ơn mọi người,['#Q&A']
một thông_tin mà mình cho là quan_trọng nếu bạn nào muốn sử_dụng mô_hình ngôn lớn llm vào việc phát_triển sản_phẩm thương_mại trích nguồn,"['#sharing', '#nlp']"
nếu bạn hỏi tôi sau những hào_quang chatgpt gpt4 thì tiếp_theo sẽ là gì tôi sẽ trả_lời là autogpt với khoảng <number> sao repo trên github với autogpt các prompt sẽ được liên_kết với nhau tạo ra một agents có_thể lên suy_nghĩ lên kế_hoạch thực_hiện từng bước một và đạt được mục_tiêu ví_dụ bạn hỏi cách tạo một startup với <number> funding thay_vì trả_lời trực_tiếp autogpt sẽ lên plan <number> research lowcost business models that require minimal funding <number> identify potential target markets and their needs <number> develop lean mvp and test with target market to validate demand sau đó với mỗi task mô_hình gpt sẽ sinh ra các câu trả_lời dựa vào thông_tin trên internet và có_thể sẽ có các task nhỏ được break down ra nữa cuối_cùng nó sẽ tổng_hợp lại và cho ra kết_quả cuối_cùng và tất_cả đều tự_động,"['#sharing', '#deep_learning', '#nlp']"
hi mọi người hôm_nay mình muốn chia_sẻ một tool khá hay ứng_dụng của chatgpt llm được phát_triển bởi cnext giúp hỗ_trợ người dùng trả_lời câu hỏi tìm insight từ dữ_liệu bằng ngôn_ngữ tự_nhiên theo mình thấy cnext hoạt_động khá ấn tưởng dù bạn có kiến_thức về lập_trình hay không thì một_số task yêu_cầu phức_tạp bạn chỉ cần mô_tả ý_tưởng của mình cnext có_thể hỗ_trợ bạn triển_khai ý_tưởng đó trên dữ_liệu của bạn mình thấy tool có khá nhiều api hỗ_trợ import data tải lên một file dưới định_dạng csv đây sẽ là file bạn mong_muốn phân_tích và tìm insight table ops thao_tác xử_lý dữ_liệu trên các trường dữ_liệu google search cho phép bạn search thông_tin trên google và trả về định_dạng json dễ_dàng để khai_thác dữ_liệu twitter search hoặc twitter entities cho phép lấy thông_tin trên twitter rất phù_hợp trong việc phân_tích một trend hoặc một sản_phẩm được giới_thiệu trên twitter giúp người dùng có_thể theo_dõi mức_độ quan_tâm hoặc thái_độ của mọi người đối_với tweet của mình plotting cho phép visualize dữ_liệu design biểu_đồ thông_qua ý_tưởng ngôn_ngữ tự_nhiên nhất có_thể ngoài_ra còn một_số api khác giúp cho các bạn hr có_thể tìm_kiếm ứng_viên trên linkedin phù_hợp với tiêu_chí của mọi người đặt ra ... một_số hướng_dẫn và ví_dụ bạn có_thể xem đây dưới đây là một demo khá thú_vị về cách cnext xử_lý dữ_liệu hy_vọng bài viết hữu_ích với mọi người chúc mọi người một ngày vui_vẻ,"['#sharing', '#deep_learning', '#nlp']"
hello mọi người việc các công_cụ như chatgpt và midjourney trở_nên phổ_biến trong thời_gian gần đây đã gây ra vô_số ý_kiến trái chiều trong nhiều lĩnh_vực khác nhau trong bài viết này mình phân_tích hai khía_cạnh về sự sụt_giảm chất_lượng và số_lượng content tạo ra bởi con_người cùng với việc thiếu dữ_liệu dùng cho training generative model trong tương_lai nếu mọi người có insight về sự ảnh_hưởng của ai trong các lĩnh_vực như design hoặc content writing thì cũng có_thể cùng chia_sẻ nhé,"['#sharing', '#deep_learning']"
gần đây polars nổi lên như <number> thư_viện cạnh_tranh với pandas tidyverse về tốc_độ xử_lý dữ_liệu lớn dạng bảng trong repository này của mình mình sẽ thử tốc_độ dữ_liệu lớn có tên là 69m_reddit_account csv dữ_liệu này có <number> triệu dòng và <number> biến_số cột khi giải nén file gz thành csv nó nặng <number> gb mình sẽ so_sánh hiệu_năng đọc các files này định_dạng csv parquet và feather bằng polars so với pandas version <number> sử_dụng numpy và pyarrow backends kết_quả cho thấy polars thắng trong tất_cả các thí_nghiệm pandas với pyarrow backend tiệm cận tốc_độ polars và nhanh hơn đáng_kể khi đọc files parquet và feather nhưng lại chậm hơn với csv lời tạm kết mình nghĩ polars đã và đang là đối_thủ lớn của pandas rust sẽ là_ngôn_ngôn lập_trình rất thú_vị và đáng chúng_ta đầu_tư thời_gian để học dữ_liệu tải tại đây các bạn có_thể tham_khảo kết_quả thí_nghiệm của mình tại đây,"['#sharing', '#python']"
mlops xin chào mọi người hiện_tại mình đang làm data scientist cho <number> công_ty big <number> bắc mỹ do mình muốn học thêm mảng mlops để chuẩn_bị đổi việc nên có vài thắc_mắc rất mong được mọi người chỉ giúp <number> với working directory như hình thì mình có vẻ như đang dockerize chưa đúng mọi người có_thể xem giúp mình với vì khi mình chạy app từ docker image network url external url thì browser không load được <number> có cách nào để khi chạy app thì tự_động mở browser luôn thay_vì phải click tay vào url không <number> sau khi dockerized xong mọi người có suggest gì về cloud để mình deploy app này lên free và làm portfolio để mình xin việc mình cảm_ơn nhiều và rất mong được kết_bạn với mọi người để học_hỏi,['#Q&A']
em chào mọi người em cần tìm gpu để train dữ_liệu khoảng 70gb ảnh là dạng ảnh 3d google map nên rất nặng xin mọi người tư_vấn cho em về google driver và google colab,['#Q&A']
opensource vngpt mã nguồn mở giúp dựng server chatgpt riêng trên máy cá_nhân cùng nhiều ứng_dụng ai thú_vị khác lâu_lâu mới lại có project opensource để chia_sẻ cùng các anh_em trong group sản_phẩm này cũng khá đơn_giản sử_dụng gradio để call api chatgpt whisper từ openai và tiếp_tục mở_rộng kết_nối luồng với nhau để tạo ra giao_diện tiện_dụng cuối cho người dùng phù_hợp để các anh_em nghiên_cứu về ai tự dựng server để test chatgpt hoặc dựng server chatgpt dùng riêng cho bạn_bè gia_đình công_ty còn ý_nghĩa sâu_xa của project thì mời các anh_em đọc tại đây những ưu_điểm của công_cụ này mã nguồn mở và miễn_phí cài_đặt dễ_dàng trên máy_tính cá_nhân windows macos ubuntu chỉ với một click tích_hợp sẵn chatgpt whisper ... và liên_tục bổ_sung các dịch_vụ ai mới tự setup server riêng để sử_dụng cá_nhân hoặc chia_sẻ qua internet để bạn_bè người_thân cùng sử_dụng cấu_hình các tham_số nâng cao giúp mở khóa nhiều chức_năng mới cho chatgpt whisper vnalert ... vngpt hiện được cam_kết duy_trì quản_lý phát_triển bởi aiv group tuy_nhiên là sản_phẩm nguồn mở nên các anh_em clone về thoải_mái nếu có_thể commit back trở_lại mã nguồn_gốc thì càng tốt dùng thử vngpt tại tải và cài_đặt vngpt tại cộng_đồng người dùng phát_triển vngpt cộng_đồng người dùng vngpt hỗ_trợ sử_dụng trực_tiếp trên zalo hỏi_đáp cách dùng vngpt,"['#sharing', '#nlp']"
tiếp_tục chủ_đề chatbot lần nhóm mình tiếp_cận finetune cho model bloomz7b1mt kết_hợp với lowrank adaptation cho cơ_sở dữ_liệu hỏi_đáp với bác_sĩ về bệnh_tật bằng tiếng anh bài báo gốc tại đây lý_do nhóm mình chọn bloomz7b1mt làm model gốc là vấn_đề bản_quyền mở của bigscience nó khác với những ràng_buộc bản_quyền cho llama và bloom được train trên dataset có tên là root có kha_khá dữ_liệu là tiếng việt nó có_thể giúp các bạn finetune thêm bằng tiếng việt thuận_lợi hơn nếu muốn kết_quả prompt mình có so_sánh trong source code của nhóm mình mình đặt tên cho finetuned model là doctor with bloom tạm dịch bác_sĩ với hoa đây là source code của mình hi_vọng nó hữu_ích với mọi người và xin đừng tiếc nếu bạn thích repository này với phạm ngọc ninh,"['#sharing', '#deep_learning']"
em đang muốn build server có khoảng <number> gpu các anh_chị cho em hỏi mua gpu và mother board hà_nội đâu em nên mua gpu và mother board loại nào,['#sharing']
dạ em xin chào mọi người mọi người có các bộ data liên_quan đến các biểu_hiện trên khuôn_mặt không ví_dụ các bộ data để phân_biệt các biểu_hiện sau <number> dữ_liệu khuôn_mặt của người bị ốm bị bệnh mệt_mỏi <number> dữ_liệu khuôn_mặt của người bị đau_đớn khó_chịu em xin cảm_ơn mọi người chúc mọi người tuần mới làm_việc hiệu_quả,"['#Q&A', '#data']"
báo_cáo <number> trang bởi team microsofts về gpt4 với gpt4 từ gpt có_thể làm được gì đã chuyển thành có gì mà gpt không làm được một_cách đầy bất_ngờ llms đã khiến những người làm ai thấy được một tia sáng trong công_cuộc tiếp_cận agi <number> tuần mình sẽ viết <number> blogs mọi người subscribe nhé,['#sharing']
chào anh_chị em có một_vài thắc_mắc về các vị_trí nghề_nghiệp trong ngành ai về mảng data thì đã biết một_vài vị_trí như data scientist data analyst ... tuy_nhiên các vị_trí khác em tạm gọi là mảng ai làm_việc với models ... thì chưa hình_dung rõ và chưa biết tên anh_chị cho xin review về các jobs liên_quan đến mảng ai tên vị_trí các tasks khi đi làm với cảm_ơn admin và mng rất nhiều,['#Q&A']
em xin phép share một webinar khác diễn ra vào 8h tối nay <number> <number> tổ_chức bởi mlopsvn,['#sharing']
xin phép mọi người trong nhóm hiện_tại em đang chuẩn_bị làm đồ_án tốt_nghiệp hướng của em muốn làm là về human pose em muốn bài_toán hướng đến <number> số ứng_dụng như phát_hiện người bị đuối nước người bị ngã cho người già đột_quỵ hay trẻ nhỏ hành_vi người tham_gia giao_thông như chuẩn_bị băng qua đường áp_dụng cho ôtô vì lần đầu_tiên em tiếp_cận với hướng này không biết những bài_toán trên của em có khả_thi hay khó_khăn nào không em xin phép xin ý_kiến mọi người đã từng làm về ứng_dụng về hướng này em cảm_ơn mọi người,"['#Q&A', '#cv']"
em chào mọi người mọi người có_thể giới_thiệu cho em một_số paper nổi_tiếng kinh_điển cho task face verification được không kinh_điển theo em tức_là khi nhắc tới task này thì mọi người nghĩ ngay tới paper nào em xin chân_thành cảm_ơn,"['#Q&A', '#cv']"
em chào mọi người em đang cần tìm một encoder model để encode rồi làm clustering hiện_tại em mới chỉ tìm ra bert từ năm <number> là phổ_biến nhất không biết là có pretrained encoder nào tốt hơn bert không nếu có bài bào nào đánh_giá tổng_quan các encoder model dùng transformer thì càng tốt,"['#Q&A', '#deep_learning']"
nlp chào mọi người em mới học và tìm_hiểu xử_lý về nlp trong tiếng việt thầy em cho em một_số thư_viện khá phổ_biến như nltk cho em hỏi là thư việ nltk có áp_dụng được cho tiếng việt không em cảm_ơn tiện_thể em muốn hỏi là xử_lý văn_bản tiếng việt thì ra trường có cơ_hội tìm_kiếm việc_làm tốt không,"['#Q&A', '#nlp', '#python']"
bất_kể ai là người chiến_thắng trong cuộc đua ai thì đây là công_ty vẫn ung_dung hưởng lợi công_ty nắm giữ vũ_khí tối_thượng của công_nghệ ai,['#sharing']
"bởi những vấn_đề về giới_hạn bản_quyền của model llama mình và bạn phạm ngọc ninh đã sử_dụng model bloom không bị giới_hạn bản_quyền bài báo tại đây để train models theo hướng alpacalora vì bloom được train với 2,7 dataset là tiếng việt tham_khảo tại đây hơn nữa mình có thấy andrej karpathy khuyên khích nên dùng bloom như hình bên dưới với những lý_do trên mình và bạn ninh đã train model bloom56m và bloom7b1 kết_hợp với lora cũng như sử_dụng dữ_liệu alpaca_data_cleaned json tại đây đây là repository mà mình và bạn ninh đã reimplemnt hi_vọng cuối tuần có thứ để mua_vui với mọi người với phạm ngọc ninh","['#sharing', '#deep_learning']"
chào các bạn mình vừa hoàn_thành các jupyter notebook sử_dụng pandas và sqlalchemy để mô_phỏng mysql code hy_vọng sẽ giúp_ích được ai đó cảm_ơn các bạn đã quan_tâm,['#sharing']
mọi người đều biết về sức_mạnh vượt_trội của gpt4 trong các bài_toán xử_lý ngôn_ngữ tự_nhiên nay microsft mang sức_mạnh của gpt4 lên github với công_cụ github copilot với lượng dữ_liệu code khổng_lồ trên github thì ai sẽ hỗ_trợ rất nhiều cho lập_trình_viên trong nhiều công_việc khác nhau,"['#sharing', '#nlp']"
sau tiếng_vang lớn của chatgpt mình thấy có người reimplement lại mô_hình này dưới cái tên minchatgpt sử_dụng kiến_trúc gpt2 tại đây có_lẽ đây là phong_cách được định_hình bởi andrej karpathy khi andrej reimplemt mô_hình gpt2 với <number> repos là mingpt và nanogpt có bạn nào thích_thú với ý_tưởng này mình nghĩ hoàn_toàn có_thể sử_dụng các kiến_trúc khác như llama bloom gptneox ...,"['#sharing', '#deep_learning']"
nay mình giới_thiệu với mọi người một công_cụ hỗ_trợ viết code còn thông_minh hơn copilot cursor là một phần_mềm để lập_trình ide với sự hỗ_trợ ai hiện_tại một_số tính_năng mà cursor hỗ_trợ write sinh code với ai thông_minh hơn copilot diff yêu_cầu ai sửa và cải_tiến đoạn code chat dạng chatgpt nhưng hiểu ngữ_cảnh của file project ngoài_ra có các tính_năng như tự_động sinh ra comment test case xác_định vùng code có khả_năng bị lỗi và sửa luôn ...,['#sharing']
em chào anh_chị em muốn xin review từ các anh_chị đã theo học chương_trình khoa_học dữ_liệu của đại_học khoa_học tự_nhiên hà_nội vì lý_do tài_chính và gia_đình nên em quyết_định theo học thạc_sĩ hà_nội thay_vì đi du_học các anh_chị thấy chương_trình đào_tạo và chất_lượng giảng_dạy thạc_sĩ của trường thế_nào em cảm_ơn anh_chị nhiều,['#Q&A']
vừa_rồi mình có tham_gia challenge player contact detection kaggle và may_mắn được top1 mình xin chia sẽ code và solution hi_vọng sẽ có_ích cho các bạn mới challenge page solution shorturl at kjnw0 source code,['#sharing']
em chào mọi người hiện_tại em đang phải build chatbot cho <number> công_ty về tư_vấn tâm_lý người_ta muốn chatbot có_thể đặt nhiều câu hỏi kiểu openquestion cho người dùng để hiểu được vấn_đề tâm_lý của người dùng em đã thử parlai và dùng empathetic dialogues thì model khá tốt thể_hiện được sự đồng_cảm với người dùng nhưng chưa đặt thêm được câu hỏi cho người dùng đây là github link em đã thử thêm dataset và train lại model dựa trên trained model em có để gpu <number> nhưng lúc task manager thì em lại thấy gpu không hoạt_động gì còn cpu và memnory thì tầm <number> <number> luôn nên em chưa thành_công train lại model khi dùng parlai em sợ build model từ đầu không dùng pretrained model thì kết_quả chưa chắc đã bằng pretrained model nên em không biết làm thế_nào hướng em muốn build chatbot là như bài báo này nhưng mà em không tìm thấy code của bài báo này nên em cũng không biết làm như nào mọi người có_thể tư vẫn giúp em em nên làm gì được không em xin chân_thành cảm_ơn mọi người,"['#sharing', '#Q&A', '#nlp']"
chào mọi người em là sinh_viên năm cuối ngành cntt trường bk tầm tháng <number> năm nay em sẽ tốt_nghiệp em đang có dự_định đi học master ml dl úc background của em thì em có gpa tích_luỹ tới kì thứ <number> <number> ielts <number> có nền_tảng về thống_kê xử_lí trực_quan hoá handle dữ_liệu không cân_bằng nói_chung là em có biết cơ_bản về khdl implement các model bằng keras và tf nhưng mà linear algebra thì hiện_tại em quên hết rồi tại học từ năm <number> nhưng mà em có_thể tự học lại tại em cũng thích học toán hiện_tại em hơi mất định_hướng kiểu các bạn cùng khoá của em <number> không theo hướng ml đã đi làm rồi nhưng mà em vẫn chưa đi vì em chưa nhận được offer nào phù_hợp job ml cho level thấp như em khá ít và khi người_ta nghe em nói em chỉ có_thể làm đến hết <number> không_thể commit với công_ty được người_ta cũng không muốn tuyển em em muốn em học master xong có_thể đó làm các ngành liên_quan đến major của em vài năm rồi mới về nước nhưng mà em sợ nếu em không có work experience thì không_thể đi làm được úc em hi_vọng mn có_thể cho ý_kiến giúp em rằng em nên đây làm các job liên_quan rồi mới đi học hay_là tốt_nghiệp xong em đi luôn và không biết là úc thì con đường cho ml có rộng_mở không em cần chuẩn_bị những kiến_thức cơ_bản nào trước khi em chính_thức vào học master ml không em không có vấn_đề gì về tài_chính bố_mẹ em có_thể chu_cấp cho em đi học ms liền sau khi em tốt_nghiệp bk chỉ là em thấy các bạn đi làm em áp_lực và em đang hoài_nghi về chuyện em muốn theo_đuổi ml huhu em mong mọi người cho em lời khuyên em cảm_ơn mnn,['#Q&A']
điểm tin về llama và các biến_thể cũng như giải_pháp kĩ_thuật cải_tiến llama như chúng_ta đã biến sức nóng của mô_hình ngôn_ngữ lớn large language models llm lớn tới mức như thế_nào đặc_biệt là chatgpt và gpt4 do openai tạo ra tuy_nhiên rất tiếc openai nhưng lại không open nhưng facebookresearch fair được lãnh_đạo bởi bác yan lecun chủ_trương open source code và data có lần mình nghe bác lecun nói kiến_trúc convolutional neural network cnn được bác ấy phát_minh từ năm <number> nhưng vì nhiều lý về bản_quyền nơi bác ấy từng làm_việc ví_dụ bell labs nên ai bị rơi vào ngủ_đông rút kinh_nghiệm từ đó bác lecun chủ_trương open science các bạn có_thể sẽ gặp thuật_ngữ này ngày_một nhiều hơn ví_dụ open source code data access review ... giúp khoa_học dissemination and exploitation nhanh và tốt hơn quay lại llama mở mã nguồn và trained weights ta sẽ thấy điều trên đúng với những cải_tiến mà tôi được biết cho tới nay 9am gmt <number> ngày <number> <number> <number> <number> nhóm nghiên_cứu đại_học stanford đã sử_dụng kĩ_thuật mà họ công_bố trước đó là selfinstruction để cải_tiến hiệu_năng mô_hình và đặt tên biến_thể là alpaca source code tại đây ứng dung demo giống như chatgpt tại đây tạm_thời đang ngừng hoạt_động để nâng_cấp <number> tiếp_thu kinh_nghiệm của nhóm tastu đh stanford eric wang đã sử_dụng kỹ_thuật lowrank llama instructtuning để finetune llama và đặt tên là llamalora source code tại đây hơn nữa llamalora có_thể train model với precision 8bit sử_dụng thư_viện bitsandbytes mà chỉ cần <number> gpu như rtx <number> mình đang chờ xem có ai sử_dụng accelerate để train model với precision 8bit fp8 true <number> tiếp_theo vấn_đề liên_quan tới quantization để giảm bộ_nhớ cấu_hình máy_tính các bạn có_thể tham_khảo tại đây paper và original code tại đây <number> kết_hợp giữa quantization chuyển trained weighted của llama sang và deploy lên edged device các bạn có_thể theo_dõi github này tương_tự với trained weighted của alpaca xuống 4bit và tại đây <number> last but not least mình thấy có <number> nhóm bồ đào nha sử_dụng chatgpt để dịch dữ_liệu alpaca_data json dùng trong alpaca mục <number> sang tiếng bồ rồi train mô_hình giống với llamalora mục <number> tại đây bạn nào có nhã hứng với tiếng việt theo mình có_thể sử_dụng_ý tướng của nhóm bồ đào nha này hóng các bạn reimplementation source code này lưu_ý <number> chút eric wang có phàn này về chất_lượng của dataset dùng để finetune alpaca nên các bạn có_thể tham_khảo thêm dataset này alpaca_data_cleaned json tại đây ... và chắc_chắn sẽ còn rất nhiều ý_tưởng thú_vị liên_quan tới chủ_đề này sẽ được giới_thiệu trong thời_gian ngắn tới,['#sharing']
có bạn nào trong group này tải được trained weights của llama bài báo tại đây và link chia_sẻ torrent tại đây cụ_thể là link magnet torrent này magnet xt urn btih zxxdauwylruxxbhuyems6q5ce5wa3lva dn llama mình thử thì traffic để download <number> ==> vậy bạn nào đã tải được trained weights của llama thì cho mình xin với nhé xin đa tạ trước với mọi người,"['#Q&A', '#sharing']"
mình muốn tạo <number> mô_hình dự_đoán số_lượng bệnh_nhân tới khám từng phòng_khám dữ_liệu với các dòng là phòng_khám thời_gian tới khám thời_gian khám xong bệnh_nhân dữ_liệu muốn dự_đoán là tên phòng_khám khoảng thời_gian dự_đoán số_lượng bệnh_nhân khám bệnh_nhân nhờ các bạn tư_vấn giúp mình ít keyword để có hướng nghiên_cứu xin cảm_ơn đã đọc bài,"['#Q&A', '#machine_learning']"
google giới_thiệu trình tìm_kiếm bằng chat giống chatgpt,['#sharing']
chào các bạn tôi xin chia_sẻ bài nói_chuyện của tôi về aifordev trước tết <number> tuần mà giờ phải cập_nhật slides rất nhiều rồi hy_vọng có vài thông_tin hữu_ích cho các bạn trẻ đang là lập_trình_viên và muốn tìm_hiểu phát_triển ai nếu các bạn seniors có insights resources gì khác cũng xin comment để tôi cập_nhật thêm nhé cheers talk title ai4dev landscapes toolsets roadmaps collabs slides video recording abstract the field of artificial intelligence ai is radically changing every aspect of human life from the way we shop and entertain lend and earn to the way we learn and create there are exponentially many ai ideas principles procedures applications tools and platforms being developed and shared freely this on the_one hand provides young talents with tremendous opportunities on the other hand poses new challenges in the development of their knowledge and skills specifically ai is now widely considered software <number> as dev you need to be well prepared for what coming next in this talk will walk you through comprehensive landscapes of the many exciting topics in ai introduce wonderful aipowered dev tools recommend pragmatic training roadmaps for you to quickly upgrade your ai capabilities and invite you to collaborate altogether build strong community of ai4dev by joining study groups and contributing to many exciting fullstack production ai projects,['#sharing']
poe của quora <number> ứng_dụng thay_thế tuyệt_vời cho chatgpt hello mọi người là một cộng_đồng về ml mình chắc rằng nhu_cầu sử_dụng chatgpt của mọi người rất cao nhưng việc truy_cập và sử_dụng lại tương_đối khó_khăn khó tạo account thường phải dùng vpn lại hay bị rate limit etc mình muốn giới_thiệu với mọi người <number> ứng_dụng mới mà theo quan_điểm chủ_quan của mình là tiện_lợi hơn chatgpt rất nhiều đó là poe của quora vâng chính là trang hỏi_đáp quora mà bạn hay thấy đó <number> vài ưu_điểm của poe so với chatgpt mà mình thấy poe của quora là ứng_dụng tích_hợp nhiều chatbot nên bạn có_thể dùng chatgpt thông_qua poe tạo account rất đơn_giản không có giới_hạn gì cả lại còn không cần dùng vpn giao_diện xinh_xắn dễ_thương tốc_độ rất nhanh nhiều bạn vn dùng bảo là sử_dụng chatgpt poe cho kết_quả nhanh gấp <number> <number> lần so với chatgpt pro từ web chính không có rate limit và hoàn_toàn miễn_phí không chỉ có chatgpt đây còn có claude là model của anthropic công_ty vừa được google đầu_tư <number> triệu và sage là custom model của quora dựa vào openai tại_sao lại vất_vả dùng chatgpt trong khi poe bạn vừa dùng được chatgpt vừa được dùng những stateoftheart model mới nhất hiện_nay bạn có_thể dùng poe trên ios hoặc là desktop nhé bản android cũng sẽ sớm được ra_mắt disclaimer mình làm_việc trong team poe quora nên dĩ_nhiên là sẽ khen nhiều hơn chê ứng_dụng của bọn mình sinh sau đẻ muộn nên sẽ còn khuyết_điểm mọi người có đóng_góp gì thì cứ comment vào post nhé không_chừng sẽ thấy ý_kiến của bản_thân được đưa vào app đó,['#sharing']
người tây rất hay chơi_chữ kiểu llama là một loài động_vật họ lạc_đà được nuôi nam mỹ để lấy lông và cũng là tên model xử_lý ngôn_ngữ gần đây được facebookresearch công_bố nửa_đêm qua <number> nhóm nghiên_cứu đại_học stanford có finetune nhỏ nhất model llama 7b theo cơ_chế selfinstruct bài báo tại đây họ đặt tên cho model của họ là alpaca một loài thuộc họ lạc_đà có đặc_điểm sinh_học gần giống với llama cũng được nuôi dãy andes nam mỹ để lấy lông đây là source code cho alpaca bên cạnh đó họ cũng đang merge request lên huggingface transformers và cần thêm <number> người review code trước khi pr lên transformers ngoài_ra họ cũng xây_dựng giao_diện nền web giống chatgpt nhưng cần đăng_ký để xử_dụng tại đây hi_vọng mọi người sẽ thích_thú với những công_cụ sinh_ra ngôn_ngữ,"['#sharing', '#deep_learning']"
chào mọi người hiện đang có bộ data có cấu_trúc tương_tự như hình thấy data đang bị duplicate theo hàng của vài trăm cột đầu đang tìm_hiểu theo hướng grouping lại thay_vì để duplicates như mà train model nhưng ko có key word để tìm_hiểu mong các bác chỉ_giáo vs,"['#Q&A', '#data']"
roomgpt room generation các bạn có muốn thiết_kế văn_phòng phòng khách phòng ngủ phòng tắm ... của mình trở_nên đẹp hơn nhưng lại bị thiếu ý_tưởng hãy đề roomgpt giúp bạn các bạn chọn loại phòng và phong_cách mong_muốn modern vintage minimalist ... sau đó tải ảnh căn phòng hiện_tại của bạn lên roomgpt sẽ giúp bạn làm căn phòng trở lên lộng_lẫy hơn ứng_dụng hoàn_toàn miễn_phí tại các bạn còn chờ gì nữa mà không biến cái ổ_chuột của mình trở_nên sang_trọng hơn,"['#sharing', '#cv', '#deep_learning']"
chắc các bạn quan_tâm tới chủ_đề gptxx không_thể không biết codebase transformers của huggingface hay gần đây andrej karpathy có làm series bài giảng và source code về gpt2 có tên là nanogpt trước đó vài năm andrej cũng tạo repo có tên là mingpt sáng sớm nay tysam có làm repo tương_tự nanogpt có tên là hlbgpt hyperlightspeedbenchgpt tại đây anh này có sở_trường làm mọi thứ đơn_giản hiệu_quả dễ đọc dễ hiểu mà benchmark lại rất ổn hi_vọng với thông_tin này các bạn sẽ có thêm kiến_thức kĩ_năng mới cho mình,"['#sharing', '#deep_learning']"
person reidentification hiện_nay các paper sota trên tập dữ_liệu market101 chủ_yếu là resnet cho bài_toán reid khi áp_dụng trên dữ_liệu thực_tế đều không cho kết_quả đáng mong_đợi dù đã retrain model trên data của doanh_nghiệp mong mọi người đã có kinh_nghiệm trong mảng này có_thể cho em xin cao_kiến em xin phép được hỏi một_vài câu như sau <number> liệu dữ_liệu dùng để retrain vẫn còn quá nhỏ để model có_thể học được <number> có phải các paper public sẽ không áp_dụng vào thưc tế được <number> có cách nào để cải_thiện một model reid để có_thể áp_dụng vào trong bài_toán thực_tế mà không cần phải thu_thập số_lượng data lớn rất mong nhận được câu trả_lời từ tất_cả mọi người em xin cảm_ơn,"['#Q&A', '#data', '#cv', '#deep_learning']"
visual chatgpt sử_dụng chatgpt với hình_ảnh mô_hình chatgpt chỉ hỗ_trợ mọi người tương_tác bằng ngôn_ngữ tuy_nhiên có rất nhiều mô_hình_dạng hình_ảnh như visual transformers hay stable diffusion thế nên các nhà nghiên_cứu đến từ microsoft đã xây_dựng mô_hình visual chatgpt kết_hợp chatgpt với các mô_hình hình_ảnh để hỗ_trợ người dùng có_thể gửi hình_ảnh khi chat và hỗ_trợ trả_lời các câu hỏi liên_quan tới nội_dung bức ảnh github,"['#sharing', '#deep_learning']"
hi cả nhà em phép được chia_sẻ một seminar khác tổ_chức bởi mlopsvn cho các bác nào quan_tâm cảm_ơn cả nhà nhiều,['#sharing']
có_lẽ khái_niệm agi artificial general intelligence vẫn là gì đó chưa tới nhưng cách gpt4 đạt kết_quả trong các bài kiểm_tra như bar lsat gre ap đặc_biệt ấn_tượng ví_dụ như gre thì bài quantitative đạt <number> <number> bài verbal đạt <number> <number> và bài writing đạt <number> <number> hiện_tại các bạn có_thể thử gpt4 bản chỉ có text trên chatgpt bản plus,['#sharing']
khảo_sát nhu_cầu theo_dõi thông_tin về aiml em xin phép anh tiep vuhuu thực_hiện khảo_sát trong group hiện_tại lĩnh_vực ai nói_chung ml nói_riêng đang phát_triển quá nhanh_chóng với các bước_tiến từng ngày lượng thông_tin liên_quan tới ai việc ứng_dụng ai ... vượt quá khả_năng theo_dõi thông_thường của bất_kì cá_nhân nào trong khi hiểu và sử_dụng ai ngày_càng trở_thành nhu_cầu quan_trọng trong công_việc và đời_sống hiện_tại em và team đã có một giải_pháp để giải_quyết bài_toán quá_tải thông_tin và dự_định sẽ tạo một phiên_bản dành riêng tối_ưu cho lĩnh_vực ai ml nhằm giúp những người theo_dõi nhà nghiên_cứu doanh_nhân khởi_nghiệp trong lĩnh_vực này có_thể theo_dõi thông_tin tốt hơn rất mong các anh_chị_em trong group dành chút thời_gian thực_hiện khảo_sát để team điều_chỉnh sản_phẩm tốt nhất kết_quả_thực_hiện khảo_sát sẽ được phân_tích và public trở_lại với cộng_đồng để mọi người cùng có hiểu_biết sâu hơn về sự quan_tâm của người việt tới ai nói_chung em xin cám_ơn link thực_hiện khảo_sát,['#Q&A']
vấn_đề crawling data các sàn chào mọi người em là sinh_viên đang làm project de tốt_nghiệp mục_tiêu của em là crawl data <number> thị_trường ngách sản_phẩm làm_đẹp từ các sàn thương_mại điện_tử lazada shopee tiki gồm cả batch lẫn stream phục_vụ nhu_cầu phân_tích mọi thứ khá ok cho đến khi em cần phân_tích doanh_số thị_trường ngành lên dashboard và số_lượng sản_phẩm thì em gặp <number> vài vấn_đề tiki thì <number> số sản_phẩm bán missing value khá là nhiều dao_động từ <number> và có những case thiếu tầm <number> nhiều sản_phẩm quantity_sold chỉ rơi vào <number> dù đăng khá lâu em khá là đau_đầu khi fill value vào những case kiểu này thường thì em sẽ so_sánh quy_mô giữa tiki và shoppe với cùng <number> loại sản_phẩm tầm giá số_lượng review tuỳ từng th đó và dựa vào tỉ_lệ để điền giá_trị nhưng với những case mà chỉ tiki có thì bó_tay đến câu_chuyện tổng_doanh_số thị_trường thì công_thức em sử_dụng vẫn là giá bán số_lượng bán cộng tất_cả với shopee thì khá ổn do giá và số_lượng sản_phẩm bán số_lượng missing value ít nhưng lúc tính thì thị_phần tiki thọt so với shopee khá nhiều <number> phần ảnh_hưởng do dữ_liệu ngoài_ra khi cần realtime sẽ phải tính_toán mỗi khung thời_gian thì cách của em tính với vài chục nghìn sản_phẩm cá_nhân em thấy khá là ngu nhưng vẫn chưa có giải_pháp tốt hơn vậy làm thế_nào để mình xử_lý trường_hợp này thì em cần cao_kiến dữ_liệu em crawl thông_qua api của các bên cung_cấp em có tham_khảo <number> số sản_phẩm như case của metric vn thì còn có_thể crawl dữ_liệu bán của từng sản_phẩm trong <number> mốc thời_gian thứ mà lúc em crawl ko có vậy làm thế_nào để có_thể crawl số_lượng bán của <number> sản_phẩm trên các sàn do tài_năng và kiến_thức hạn_hẹp rất mong được các bác chỉ_giáo,"['#Q&A', '#data']"
với trung_bình hơn <number> nghìn lượt tải về gói cài_đặt mỗi tháng deploy ai systems yourself ai toolkit một sản_phẩm của neural việt nam là một bộ công_cụ bao_gồm các thuật_toán trí_tuệ nhân_tạo đã được xây_dựng và đóng_gói mục_tiêu hướng đến các bạn trẻ có niềm say_mê với công_nghệ_trí_tuệ nhân_tạo và muốn thực_hành các ứng_dụng trí_tuệ nhân_tạo vào đời_sống thông_qua các câu_lệnh đơn_giản bên cạnh các ứng_dụng phổ_biến đã được tích_hợp sẵn như nhận_diện người đeo khẩu_trang phát_hiện dáng người ... team daisykit neural việt_nam sẽ tiếp_tục phát_triển và cho ra_mắt các ứng_dụng mới trong thời_gian sắp tới,['#sharing']
em chào mọi người em muốn xin lời khuyên của các anh_chị để bổ_sung kiến_thức cho việc học machine learning em hiện là sinh_viên năm <number> ngành khoa_học dữ_liệu sau khi tốt_nghiệp em muốn làm bên mảng machine learning cụ_thể là machine learning engineer hoặc nlp scientist cho các công_ty về sản_phẩm công_nghệ số như voice assistant xe tự_hành ... nhưng do ngành này đòi_hỏi kiến_thức cao đặc_biệt là về toán và em cũng được nghe thường người_ta tuyển dân machine learning từ phd thôi nên em muốn tìm_hiểu nhiều nhất về ml để cạnh_tranh và có được công_việc trong mảng này các kiến_thức em đã biết lập_trình cơ_bản cấu_trúc dữ_liệu và giải_thuật cách hoạt_động của một model mức cơ_bản chưa đào_sâu về toán cách dùng libray như sklearn để giải_quyết bài_toán regression cơ_bản trên kaggle hy_vọng các anh_chị có_thể cho em xin tham_khảo về tài_liệu ml cụ_thể là các nền_tảng về toán thống_kê cần_thiết cho ngành các dự_án cá_nhân để bỏ vô portfolio cần thể_hiện kiến_thức mảng nào sinh_viên có_thể có paper tốt không làm_sao để bắt_đầu nghiên_cứu làm paper hiện_tại em đang làm paper ứng_dụng ml trong việc dự_báo vẫn là regression bằng cách dùng library nhưng em thấy cách làm này đơn_giản không chuyên_sâu và chỉ cần nghiên_cứu chút là có_thể làm được,"['#Q&A', '#machine_learning']"
xin hỏi mình đang làm cho một startup về thời_trang và đang tìm_kiếm giải_pháp đọc một hình xem trong hình đó người dùng mặt áo_quần gì đơn_giản hơn là cho hai bức hình trả lại xác xuất hai bức hình đó có cùng một loại vật_thể nếu phải xây_dựng training data thì cần cỡ bao_nhiêu training data để xây_dựng mô_hình kiểu này 100k đủ không,"['#Q&A', '#data', '#cv']"
chào mọi người em đang cần thực_hiện bài_toán phân cụm văn_bản bài báo ... document clustering với số cụm không xác_định trước về phần phân cụm sử_dụng dbscan em đã hiểu và thấy ok tuy_nhiên phần embedding văn_bản em muốn tham_khảo ý_kiến mọi người phương_pháp nào tốt nhất hiện_nay em được biết về phần câu có các mô_hình sentence embedding kết_quả khá ok như sbert ... tuy_nhiên với cả văn_bản dài thì em tìm_hiểu không thấy có nhiều thông_tin mong mọi người cho ý_kiến về giải_pháp hoặc các keyword bài viết liên_quan để em tìm_hiểu em cảm_ơn,"['#Q&A', '#nlp', '#deep_learning', '#machine_learning']"
hi mọi người mình có một thắc_mắc muốn nhờ mọi người giải_thích giúp với mình đang thực_hiện một dự_án cá_nhân trong đó có một phần xử_lý đọc các ký_tự chữ_số trên mặt đồng_hồ framework mình xử_dụng là detectron2 khi mình training và predict thử trên <number> version khác nhau là <number> và 0.1.3 thì kết_quả là version 0.1.3 mình thấy tốc_độ hội_tụ hanh hơn nhiều chỉ cần training <number> iter với dataset <number> <number> là đã cho kết_quả rất ấn_tượng rồi trong khi mình training trên bản <number> với tập dataset lớn hơn <number> chút <number> <number> với <number> iter nhưng kết_quả tốc_độ hội_tụ không ổn_định nhiều số không_thể nhận_diện được không rõ có ai gặp phải tình_trạng như mình không vậy,"['#Q&A', '#cv', '#deep_learning']"
chatgpt đang làm mưa làm gió trên toàn thế_giới những ngày vừa_qua hãy cùng team neuralvn tìm_hiểu về công_nghệ phía sau chatbot đình_đám này qua bài viết bí_mật công_nghệ đằng sau chatgpt,['#sharing']
chào mọi người em đang tìm_hiểu về adadelta optimizer có một đoạn em vẫn chưa hiểu đó là trong paper tác_giả có đề_cập về sự không thống_nhất trong đơn_vị và đưa ra giải_pháp đề_xuất tuy_nhiên em vẫn chưa thể_nào hình_dung được sự sai_lệch về đơn_vị này là như thế_nào mặc_dù đã search và đọc thêm từ nhiều nguồn mọi người có_thể cho em một ví_dụ cụ_thể hay một giải_thích trực_quan với đây là paper em đang đọc đề_cập về đơn_vị phần <number> trang <number> em cảm_ơn mọi người đã quan_tâm chúc mọi người một ngày tốt_lành,"['#Q&A', '#deep_learning']"
chào mọi người em đang có một thắc_mắc về ý_nghĩa của việc chuẩn_hóa phân_phối của data về dạng phân_phối chuẩn có một câu trả_lời đây mà em đang quan_tâm tác_giả nói rằng giả_sử dữ_liệu của chúng_ta tuân theo hàm với là một hàm_số cố_định và là biến ngẫu_nhiên tuân theo phân_phối chuẩn tác_giả chỉ ra việc chuyển data về pp chuẩn giúp cho không phụ_thuộc vào dữ_liệu nữa tức_là đang độc_lập và có mean bằng <number> nếu không độc_lập_tức_là bias với là biến ngẫu_nhiên độc_lập có mean <number> tuy_nhiên lấy ví_dụ trong linear regression mặt_phẳng cần tìm có dạng như w1x1 w2x2 thì rõ_ràng là mình đã có thành_phần bias trong đây rồi thế_thì em mới nảy ra <number> câu hỏi như sau như đã nói trên thì có phải những thuật tương_tự như linear regression không cần chuyển về pp chuẩn xét các trường_hợp khác nếu ta đã chuyển pp dữ_liệu về pp chuẩn thì không cần thành_phần bias cảm_ơn mọi người đã quan_tâm chúc mọi người một ngày tốt_lành,"['#Q&A', '#math', '#machine_learning']"
bác nào gợi_ý giúp mình cái cloud nào train tốt với chứ gg colab chạy thhế kia bao_giờ mới xong <number>,['#Q&A']
chào mọi người mình là lập_trình_viên không chuyên ai ml nhưng muốn vọc_vạch tý nên có dự_định làm hệ_thống phân_loại tài_liệu mình đang có hàng tb tài_liệu để lộn_xộn nhiều định_dạng khác nhau còn bị trùng_lặp do tên file khác nhau vì download nhiều nguồn nay mình muốn phát_triển tool tự_động phân_loại rồi gom chúng vào các thư_mục phân theo thể_loại nhờ mọi người vạch ra giúp mình xem cần học những gì và thực_hiện như thế_nào mình cảm_ơn,"['#Q&A', '#nlp']"
xin giới_thiệu với mọi người một tài_liệu được viết bởi <number> giáo_sư hàng_đầu của stanford university prof jure leskovec prof jeffrey ullman và cùng một entrepreneur nổi_tiếng của thung_lũng silicon anand rajaraman về chủ_đề mining massive data sách xoay quanh những phương_pháp khai_thác dữ_liệu hiệu_quả chính_xác và nhanh_chóng link sách link course đồng_thời xin chia_sẻ luôn một cuốn sách cùng chủ_đề data mining nhưng được viết theo hướng ứng_dụng hơn kèm code do dr ron zacharski chia_sẻ kinh_nghiệm của ông miễn_phí cho cộng_đồng,"['#Q&A', '#data']"
đợt vừa_rồi mình và team có tham_gia một cuộc thi về trích xuất thông_tin từ hóa_đơn có tên gọi là the mobile capture receipts optical character recognition mcocr mình có một bài viết chia_sẻ về giải_pháp của team mình mọi người tham_khảo và góp_ý,"['#sharing', '#cv']"
mọi người cho hỏi em định encode dữ_liệu nến nhật để train cnn phân_loại mẫu hình thì liệu có hiệu_quả không có paper hay dự_án nào làm chưa,"['#Q&A', '#cv', '#deep_learning']"
datacentric ai course thông_thường các khóa học về machine learning sẽ dạy nhiều về các mô_hình tuy_nhiên khi làm_việc trong môi_trường thực_tế dữ_liệu thường nhiễu và hỗn_độn messy thế nên bên cạnh việc cải_thiện mô_hình chúng_ta cũng_nên tập_trung vào cải_thiện các vấn_đề của dữ_liệu datacentric ai dcai là hướng nghiên_cứu mới tập_trung vào việc cải_thiện dữ_liệu để tăng độ hiệu_quả của mô_hình khóa này dạy các bạn giải_quyết các vấn_đề về dữ_liệu trong các project thực_tế như datacentric ai vs modelcentric ai label errors dataset creation and curation datacentric evaluation of ml models class imbalance outliers and distribution shift growing or compressing datasets interpretability in datacentric ml encoding human priors data augmentation and prompt engineering data privacy and security,"['#sharing', '#data']"
ai đã làm về hệ_thống điểm_danh bằng camera cho mình xin ý_kiến về ưu nhược_điểm hoặc nên không nên về các phương_hướng sau <number> face_recognition <number> vgg arcface <number> yolo <number> gợi_ý thêm thank,"['#Q&A', '#cv', '#deep_learning']"
em xin phép chia_sẻ thông_tin về buổi webinar tối nay cho các bác quan_tâm tới mlops,['#sharing']
kính chào các bác đợt này nhân_dịp đang quay lại học reinforcement learrning nên em mạnh_dạn chia_sẻ cùng cả nhà <number> video về deep learrning vẫn với phương_châm đơn_giản hi_vọng giúp được các anh_em mới học thôi,"['#sharing', '#machine_learning']"
chatgpt for google chrome extension plugin chatgpt for google này sẽ giúp bạn hiện thị nội_dung trả_lời của chatgpt cho nội_dung bạn tìm_kiếm bên cạnh kết_quả trả về của google với sức_mạnh của chatgpt thì đây là một tính_năng cực_kì hữu_ích cho người dùng ví_dụ như tìm_kiếm các câu hỏi liên_quan tới lập_trình chatgpt sẽ là bản tổng_hợp của stackoverflow github khi cho bạn cả câu trả_lời và giải_thích luôn nói_chung giờ anh_em dev cũng nhàn như dưới mình hỏi cách vẽ bar graph trong python nó sinh ra cả code có cả comment luôn,['#sharing']
hi mọi người em đã kết_thúc <number> tháng intern ai engineer và cảm_thấy chút không hợp do phần_lớn thời_gian sẽ sử_dụng để training mô_hình hiện_tại em muốn chuyển_hướng sang data scientist hoặc se nên em muốn hỏi mọi người trong group công_việc của <number> data scientist sẽ làm những gì và sẽ dành nhiều thời_gian làm_việc gì em thì hay thấy bảo làm data scientist vn mà chỉ tốt_nghiệp cử_nhân kỹ_sư thì làm không hiệu_quả mong mọi người cho lời khuyên cảm_ơn mọi người,['#Q&A']
em đang làm model nhận_diện biển_báo giao_thông bằng cnn chạy file train thì nó đến epoch <number> <number> bị dừng như_vậy và kết_thúc chương_trình luôn có ai biết lỗi này là lỗi gì và cách fix không,"['#Q&A', '#cv', '#deep_learning']"
xin chào mọi người bài_toán phân_loại_hình_ảnh image classification là một trong những bài_toán quan_trọng trong lĩnh_vực computer vision một_cách giải_quyết hiệu_quả cho bài_toán này là sử_dụng kĩ_thuật transfer learning vốn không yêu_cầu quá nhiều về data hay resource mà vẫn mang lại kết_quả tốt mình vừa xây_dựng repository tổng_hợp các thuật image classification mà pytorch có hỗ_trợ transfer learning efficientnet resnet vgg googlenet nó có_thể sẽ hữu_ích với các bạn mới tiếp_xúc với bài_toán này mới tiếp_xúc với pytorch hay đơn_giản muốn sử_dụng code nhanh gọn lẹ để giải_quyết bài_toán đối_với những bạn đã thành_thạo pytorch muốn custom model và data nhiều hơn thì repo này có vẻ sẽ kém hữu_ích với các bạn trong repo này sẽ có các phần code làm thế_nào load data do mình tự thu_thập custom dataset vào model thay_đổi hàm loss hàm optimize train và predict trên dữ_liệu mới link,"['#Q&A', '#cv', '#deep_learning']"
chào mọi người em có một vấn_đề liên_quan đến xác_suất mong mọi người giúp_đỡ một nhà đầu_tư đi tham_vấn hai chuyên_gia_tài_chính về việc tăng giảm_giá cổ_phiếu của công_ty chỉ cần biết tăng hay giảm chuyên_gia thứ nhất với xác_suất dự_đoán đúng là <number> cho một quyết_định nhưng không cho người đọc biết lại tiếp_tục gọi giáo_sư giáo_sư có khả_năng dự_đoán đúng lên đến <number> trong những lần trước đó và lần này cho kết_quả giống anh chuyên_gia nhà đầu_tư thắc_mắc không biết khả_năng <number> người cùng dự_đoán đúng là bao_nhiêu phần_trăm theo suy_nghĩ của em thì đây là bài_toán xác_suất có điều_kiện vì đề_bài là <number> người đã có cùng <number> kết_quả dự_đoán trước đó vậy nên hai người cùng đúng hoặc cùng sai không có th người <number> đúng mà người <number> sai vậy nên xác_suất <number> người cùng dự_đoán đúng xác_suất <number> người cùng dự_đoán đúng xác_suất <number> người cùng dự_đoán đúng xác_suất <number> người cùng dự_đoán sai <number> <number> <number> <number> <number> <number> <number> không biết là cách lí_giải như_vậy có hợp_lí không mong mọi người cho ý_kiến em cảm_ơn mn,"['#Q&A', '#math']"
thống_kê cheatsheet cs106 thống_kê là một bộ_môn khoa_học lâu_đời và có tính ứng_dụng cao dựa trên thống_kê chúng_ta có_thể đưa ra dự_báo về biên_độ giao động của nhiệt_độ độ_ẩm lượng mưa giá_cả của các hàng_hoá giá chứng_khoán kèm theo độ tin_cậy xác_định đồng_thời dựa vào thống_kê chúng_ta cũng có cơ_sở để đưa ra quyết_định chấp_nhận hay bác_bỏ những giả_thuyết rất thiết_thực trong cuộc_sống như trung_bình chiều cao của người việt nam là 1m65 giá chung_cư tại hà_nội cao hơn so với hcm thu_nhập bình_quân đầu người của việt_nam sẽ trên <number> vào năm sau hiểu được các qui_luật thống_kê và biết cách áp_dụng chúng sẽ giúp bạn đưa ra được nhiều kết_luận thú_vị và làm củng_cố thêm sự chắc_chắn cho việc ra quyết_định đây là cheat sheet của khoá học cs106 cung_cấp một_số kiến_thức nền quan_trọng về thống_kê khái_niệm về biến ngẫu_nhiên ước_lượng tham_số độ chệch ước_lượng ước_lượng trung_bình phương_sai ước_lượng khoảng tin_cậy chưa biết và đã biết phương_sai tổng_thể hai loại mắc sai_lầm loại <number> false alarm và loại <number> miss alarm pvalue và kiểm_định phi tham_số các kiểm_định một phía hai phía kiểm_định sai_số giữa hai trung_bình mẫu kiểm_định độ phù_hợp phân_phối kiểm_định dấu và kiểm_định xu_hướng ước_lượng ols và khoảng tin_cậy của các tham_số ước_lượng link,"['#sharing', '#math']"
chào mọi người em có thắc_mắc như sau mong mọi người giúp_đỡ trong không_gian chiều có phương_pháp nào để tạo ra điểm <number> và thỏa_mãn điểu kiện là khoảng_cách giữa các điểm là bằng nhau không ví_dụ x0 x1 x0 x2 ... x0 xm x1 x0 x1 x2 ... x1 xm ... trong trường_hợp không_thể xác_định điểm với điều_kiện như trên có phương_pháp nào khác đảm_bảo khoảng_cách giữa các điểm không có sự chênh_lệch nhiều về mặt khoảng_cách không em xin cảm_ơn,"['#Q&A', '#math']"
mọi người cho em hỏi công_thức epsilon đây được tính theo công_thức nào và tại_sao công_thức <number> ta lại có epsilon <number> em xin cảm_ơn,"['#Q&A', '#math']"
mọi người giải_thích giúp em với tại_sao lại coi lượng thay_đổi giữa theta_t và theta_ <number> là vận_tốc mặc_dù viên bi được vận_tốc thúc_đẩy để xuống đáy núi nhanh hơn ví_dụ trong bài <number> của anh tiệp nhưng em không thấy sự liên_quan trong công_thức em cảm_ơn,"['#Q&A', '#math']"
chào các bác chuyện là em đang học cấp <number> và muốn tìm_hiểu về machine learning thì mình nên học những kiến_thức nền_tảng toán và lập_trình nào tại em có đọc thử một cuốn về máy học của ad mà khựng ngay từ vài trang đầu ôn_tập đại_số tuyến_tính vì hông hiểu gì hic mong các cao nhân chỉ_bảo xin cảm_ơn,"['#Q&A', '#math', '#machine_learning']"
practical stats books thực_ra các thuật_toán machine learning đều dựa trên nền của thống_kê tuy_nhiên bạn đã quá lâu chưa động lại đến toán đến xác_suất thống_kê giờ đọc các sách lý_thuyết về thống_kê cũng chán nay mình giới_thiệu <number> cuốn sách dạy thống_kê theo kiểu thực_hành sẽ có code đi kèm và giải_thích ý_nghĩa của các khái_niệm trong thống_kê,"['#sharing', '#math', '#machine_learning']"
xin_lỗi các bác cho em hỏi chút về statistics <number> công_thức trong hình công_thức đầu_tiên là residual sum of squares rss là giá_trị quan_sát được observed trừ đi estimation theo model thì sao lại bằng sigma vốn_dĩ dùng mean công_thức thứ <number> thì em ngu luôn không hiểu sao ra được như vậy nguồn sách an introduction to statistical learning with applications in springer texts in statistics trang <number>,"['#Q&A', '#math']"
trước đi học đh cũng rớt môn xstk sml giờ mình chia_sẻ lại kênh này cho các bạn kênh này đã giúp mình qua môn,"['#sharing', '#math']"
các master xác_suất cho em hỏi là sách sai hay em sai vậy cái ấy mọi người cảm_ơn,"['#Q&A', '#math']"
dạ em chào mấy anh_chị em mới bắt_đầu học về machine learning nhưng có thấy là phải tốt về toán anh chị có_thể cho em biết là em phải học những dạng toán nào để có_thể tiếp_cận được với machine learning không em cám_ơn,"['#Q&A', '#math', '#machine_learning']"
bayesian optimization là một thuật_toán tối_ưu thường dùng trong các bài tối tối_ưu hàm_số hộp_đen blackbox functions khi mà chúng_ta không có công_thức tường_minh hoặc công_thức tường_minh quá khó để phân_tích chi_phí tính_toán hàm_số lớn trong bài viết này chúng_ta cùng khảo_sát việc khai_thác khám_phá đánh_đổi exploitation vs exploration tradeoff như thế_nào trong bài_toán này và chiến_thuật của bayesian optimization là gì thông_qua phần cài_đặt đơn_giản được trực_quan_hóa <number> thetalog nhật_ký theta,"['#sharing', '#math']"
em hoàn_thành xong khoá ml của thầy andrew rồi giờ em muốn học sau hơn về phần toán thì nên học khoá nào nữa,"['#Q&A', '#math', '#machine_learning']"
chào anh_chị em có giá_trị mean <number> standard deviation <number> một biến có zscore <number> và giá_trị của <number> vậy làm_sao để em tìm biết được điểm này thuộc phân vị thứ mấy em cảm_ơn mọi người,"['#Q&A', '#math']"
các bạn cho mình hỏi sao đây nó lại cho thêm một vector toàn số <number> vào xbar rồi mới đi tính công_thức vậy,"['#Q&A', '#math']"
