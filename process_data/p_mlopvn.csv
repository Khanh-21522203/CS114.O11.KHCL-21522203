Contents,p_content,old_hastag,Hashtag
"MLOps platform @ Coupang
Trong năm vừa rồi, MLOps platform ở Coupang (một công ty thương mại điện tử của Hàn Quốc) vận hành tới 100k+ workflow runs trên tổng số 600+ ML projects, đồng thời giúp giảm thiểu thời gian deploy models từ nhiều tuần xuống vài ngày.
Coupang cũng sử dụng Seldon Core để serving model trên k8s kết hợp với các pre-packaged servers như TFServing, Triton và custom servers cho các models như sklearn và XGBoost. Điều lạ là mấy sếp này lại không thấy dùng mlserver của Seldon Core 🤣.
Ở phần data preparation, Coupang có sử dụng một format khá lạ (với em) là feather, đầu tiên cứ tưởng ý họ là feathr (một feature store framework) nhưng hoá ra không phải. Format này có thể giúp export nhanh gấp 20 lần, và import nhanh gấp 6 lần so với csv, thường để lưu trữ dữ liệu short term cho các experiments (khác với parquet format export và import chậm hơn, nhưng khả năng nén tốt hơn nên hay dùng để lưu trữ long-term). Ae có thể đọc thêm một số benchmark so với parquet và csv ở đây: https://stackoverflow.com/a/72406099

Link: https://medium.com/coupang-engineering/meet-coupangs-machine-learning-platform-cd00e9ccc172

#platform #k8s","MLOps platform @ Coupang Trong năm vừa rồi, MLOps platform ở Coupang (một công ty thương mại điện tử của Hàn Quốc) vận hành tới 100k+ workflow runs trên tổng số 600+ ML projects, đồng thời giúp giảm thiểu thời gian deploy models từ nhiều tuần xuống vài ngày. Coupang cũng sử dụng Seldon Core để serving model trên k8s kết hợp với các pre-packaged servers như TFServing, Triton và custom servers cho các models như sklearn và XGBoost. Điều lạ là mấy sếp này lại không thấy dùng mlserver của Seldon Core . Ở phần data preparation, Coupang có sử dụng một format khá lạ (với em) là feather, đầu tiên cứ tưởng ý họ là feathr (một feature store framework) nhưng hoá ra không phải. Format này có thể giúp export nhanh gấp 20 lần, và import nhanh gấp 6 lần so với csv, thường để lưu trữ dữ liệu short term cho các experiments (khác với parquet format export và import chậm hơn, nhưng khả năng nén tốt hơn nên hay dùng để lưu trữ long-term). Ae có thể đọc thêm một số benchmark so với parquet và csv ở đây: https://stackoverflow.com/a/72406099 Link: https://medium.com/coupang-engineering/meet-coupangs-machine-learning-platform-cd00e9ccc172",#platform	#k8s,
"🎉🎉🎉SEMINAR #13: GPT Prompt Engineering 🎉🎉🎉
Chào mừng các bạn đến với sự kiện seminar về ""GPT Prompt Engineering: Designing Communication with LLM"". Đây là cơ hội tuyệt vời để tìm hiểu sâu hơn về cách Prompt Engineering với chat GPT và các LLM khác.
Thông tin của seminar các bạn xem ở Fanpage MLOpsVn nhé :)","SEMINAR GPT Prompt Engineering Chào mừng các bạn đến với sự kiện seminar về ""GPT Prompt Engineering: Designing Communication with LLM"". Đây là cơ hội tuyệt vời để tìm hiểu sâu hơn về cách Prompt Engineering với chat GPT và các LLM khác. Thông tin của seminar các bạn xem ở Fanpage MLOpsVn nhé :)",#13:,
"SEMINAR #13: GPT PROMPT ENGINEERING 

Chủ đề rất hot về ứng dụng LLM, cách để giảm hallucination và tối ưu các LLM, nhanh tay đăng ký để giao lưu cùng diễn giả MoMo vào 8h tối mai nào ae ⏰.

#momo #llm #hieungo #optimization","SEMINAR GPT PROMPT ENGINEERING Chủ đề rất hot về ứng dụng LLM, cách để giảm hallucination và tối ưu các LLM, nhanh tay đăng ký để giao lưu cùng diễn giả MoMo vào 8h tối mai nào ae ⏰.",#13:	#momo	#llm	#hieungo	#optimization,
"The architecture of an ML Platform with Resource Sharing on Kubernetes
Một video khá hay để cả nhà đọc chơi mùa giáng sinh. 

Tóm tắt là mấy ông trong video sử dụng 1 tool tên là Kueue (https://kueue.sigs.k8s.io/docs/overview/) để các team trong công ty có thể chia nhau dùng chung các node pool trong cluster (được định nghĩa bởi ResourceFlavor object, có thể là cụm node pool NVIDIA L4 hoặc A100, reserved, on-demand hoặc spot). Hai (hoặc nhiều) team muốn chia sẻ node pool được gọi là thuộc cùng 1 cohort (kiểu như 2 team chơi thân với nhau thì mới đồng ý chia sẻ tài nguyên). Mỗi team trong cohort này có thể định nghĩa muốn dùng những node pool nào, cụ thể bao nhiêu CPU và RAM, thứ tự ưu tiên các node pool (ví dụ reserved trước xong tới spot), mượn tối đa bao nhiêu CPU và RAM từ team chung cohort, thì sẽ định nghĩa thông qua ClusterQueue object. 

Kueue cũng cho phép định nghĩa Job nào sẽ được ưu tiên hơn trong cluster có tài nguyên hữu hạn giúp cho việc Job Management dễ dàng hơn rất nhiều.

Còn rất nhiều thứ hay ho khác, mọi người có thể xem ở video dưới đây hoặc ở trang Documentation của Kueue 👀. À mà Kueue có thể tích hợp với Kubeflow Training Job (ví dụ TFJob), và RayJob nhé ae.

https://www.youtube.com/watch?v=HA9yt_-RQe8

#kueue #optimization #kubeflow #ray","The architecture of an ML Platform with Resource Sharing on Kubernetes Một video khá hay để cả nhà đọc chơi mùa giáng sinh. Tóm tắt là mấy ông trong video sử dụng 1 tool tên là Kueue (https://kueue.sigs.k8s.io/docs/overview/) để các team trong công ty có thể chia nhau dùng chung các node pool trong cluster (được định nghĩa bởi ResourceFlavor object, có thể là cụm node pool NVIDIA L4 hoặc A100, reserved, on-demand hoặc spot). Hai (hoặc nhiều) team muốn chia sẻ node pool được gọi là thuộc cùng 1 cohort (kiểu như 2 team chơi thân với nhau thì mới đồng ý chia sẻ tài nguyên). Mỗi team trong cohort này có thể định nghĩa muốn dùng những node pool nào, cụ thể bao nhiêu CPU và RAM, thứ tự ưu tiên các node pool (ví dụ reserved trước xong tới spot), mượn tối đa bao nhiêu CPU và RAM từ team chung cohort, thì sẽ định nghĩa thông qua ClusterQueue object. Kueue cũng cho phép định nghĩa Job nào sẽ được ưu tiên hơn trong cluster có tài nguyên hữu hạn giúp cho việc Job Management dễ dàng hơn rất nhiều. Còn rất nhiều thứ hay ho khác, mọi người có thể xem ở video dưới đây hoặc ở trang Documentation của Kueue . À mà Kueue có thể tích hợp với Kubeflow Training Job (ví dụ TFJob), và RayJob nhé ae. https://www.youtube.com/watch?v=HA9yt_-RQe8",#kueue	#optimization	#kubeflow	#ray,
Em có ý định tham gia khoá học này. Mng cho em hỏi có ai cũng có nhu cầu đăng kí học và ghép nhóm với em để dc discount ko ạ 🥹,Em có ý định tham gia khoá học này. Mng cho em hỏi có ai cũng có nhu cầu đăng kí học và ghép nhóm với em để dc discount ko ạ,,
"Xin chào mọi người. Em đang thấy có khoá mlops free vừa mới ra lại nên đang cần tìm người học cùng, trao đổi cho đỡ bỡ ngỡ ạ. Có ai đang có ý định học cùng thì chấm xuống dưới để em lập nhóm nha. Cảm ơn mọi người.","Xin chào mọi người. Em đang thấy có khoá mlops free vừa mới ra lại nên đang cần tìm người học cùng, trao đổi cho đỡ bỡ ngỡ ạ. Có ai đang có ý định học cùng thì chấm xuống dưới để em lập nhóm nha. Cảm ơn mọi người.",,
"Hi cả nhà mình!
Vậy là đã tròn 1 năm trôi qua kể từ khi khóa học MLOps Crash Course ra mắt cộng đồng từ 12/12/2022, với gần 2000 bạn đăng ký, team MLOpsVN cảm thấy thực sự tự hào vì đã giúp đỡ ít nhiều được các bạn và đóng góp vào sự phát triển chung của AI/ML tại Việt Nam, đặc biệt là khi chứng kiến các đội áp dụng MLOps vào cuộc thi MLOps Marathon 2023 diễn ra từ tháng 4 tới tháng 9 vừa qua.
Để tiếp tục thúc đẩy sự học trong lĩnh vực này, ngoài các hoạt động seminars tới từ các diễn giả khách mời vippro, team MLOpsVN quyết định host khóa học MLOps Crash Course online tại https://courses.mlops.vn/mlops-crash-course/index.html. Các bạn từ giờ có thể đọc online mọi lúc mọi nơi và gửi link cho các vippro khác trong ngành.
Như đã biết, trong quá trình học MLOps Crash Course, các bạn sẽ được thực hành để xây dựng 1 on-premise MLOps Platform trên máy của các bạn. Thêm nữa, với Github Repo MLOps Infrastructure được cấu trúc gọn gàng và hoàn chỉnh để triển khai MLOps platform, các bạn có thể tham khảo để sử dụng trong việc triển khai MLOps platform tại tổ chức nơi các bạn làm việc, ví dụ trên Kubernetes.
Links:
MLOps Crash Course: https://courses.mlops.vn/mlops-crash-course/index.html
Application repo: https://github.com/MLOpsVN/mlops-crash-course-code
Infrastructure repo: https://github.com/MLOpsVN/mlops-crash-course-platform
Cảm ơn cả nhà và chúc mọi người may mắn 🍀 ","Hi cả nhà mình! Vậy là đã tròn 1 năm trôi qua kể từ khi khóa học MLOps Crash Course ra mắt cộng đồng từ 12/12/2022, với gần 2000 bạn đăng ký, team MLOpsVN cảm thấy thực sự tự hào vì đã giúp đỡ ít nhiều được các bạn và đóng góp vào sự phát triển chung của AI/ML tại Việt Nam, đặc biệt là khi chứng kiến các đội áp dụng MLOps vào cuộc thi MLOps Marathon 2023 diễn ra từ tháng 4 tới tháng 9 vừa qua. Để tiếp tục thúc đẩy sự học trong lĩnh vực này, ngoài các hoạt động seminars tới từ các diễn giả khách mời vippro, team MLOpsVN quyết định host khóa học MLOps Crash Course online tại https://courses.mlops.vn/mlops-crash-course/index.html. Các bạn từ giờ có thể đọc online mọi lúc mọi nơi và gửi link cho các vippro khác trong ngành. Như đã biết, trong quá trình học MLOps Crash Course, các bạn sẽ được thực hành để xây dựng 1 on-premise MLOps Platform trên máy của các bạn. Thêm nữa, với Github Repo MLOps Infrastructure được cấu trúc gọn gàng và hoàn chỉnh để triển khai MLOps platform, các bạn có thể tham khảo để sử dụng trong việc triển khai MLOps platform tại tổ chức nơi các bạn làm việc, ví dụ trên Kubernetes. Links: MLOps Crash Course: https://courses.mlops.vn/mlops-crash-course/index.html Application repo: https://github.com/MLOpsVN/mlops-crash-course-code Infrastructure repo: https://github.com/MLOpsVN/mlops-crash-course-platform Cảm ơn cả nhà và chúc mọi người may mắn",,
"Xin chào mọi người. Hiện nay em đang cần deploy một con AI lên môi trường production tuy nhiên hiện tại với kiến thức của em chỉ có thể deploy 1 microservice docker container: sử dụng Fast API + torchserve; riêng ở phần torchserve em đã scale bằng cách tạo nhiều worker cho model tuy nhiên số lượng request handle trong 1s không đủ để đáp ứng production. Sau quá trình tìm hiểu em có biết được 1 số cách sau để có thể scale server AI.

Tạo ra nhiều container == nhiều server khác nhau, sau đó sử dụng nginx để load balance các request vào các server để handle được nhiều request hơn.
Sử dụng kubernetes để tạo nhiều pod == container cho server và giúp handle nhiều request hơn (tuy nhiên chỗ này em không biết load balance ntn).

Không biết các cách tiếp cận trên thì em hiểu có đúng k ạ và còn cách nào khác không ạ, và nên chọn cách nào để có thể scale tốt hơn. Em có thấy một câu trả lời về cách scale dùng nginx là khả thi tuy nhiên không productive thì em vẫn không hiểu lắm câu này. Em xin cảm ơn mọi người đã xem câu hỏi ạ.","Xin chào mọi người. Hiện nay em đang cần deploy một con AI lên môi trường production tuy nhiên hiện tại với kiến thức của em chỉ có thể deploy 1 microservice docker container: sử dụng Fast API + torchserve; riêng ở phần torchserve em đã scale bằng cách tạo nhiều worker cho model tuy nhiên số lượng request handle trong 1s không đủ để đáp ứng production. Sau quá trình tìm hiểu em có biết được 1 số cách sau để có thể scale server AI. Tạo ra nhiều container == nhiều server khác nhau, sau đó sử dụng nginx để load balance các request vào các server để handle được nhiều request hơn. Sử dụng kubernetes để tạo nhiều pod == container cho server và giúp handle nhiều request hơn (tuy nhiên chỗ này em không biết load balance ntn). Không biết các cách tiếp cận trên thì em hiểu có đúng k ạ và còn cách nào khác không ạ, và nên chọn cách nào để có thể scale tốt hơn. Em có thấy một câu trả lời về cách scale dùng nginx là khả thi tuy nhiên không productive thì em vẫn không hiểu lắm câu này. Em xin cảm ơn mọi người đã xem câu hỏi ạ.",,
"Cloudflare sẽ migrate ML platform qua Kubeflow 😁, dự là có thêm contributor từ Cloudflare cho Kubeflow rồi các sếp.
#mlops #kubeflow","Cloudflare sẽ migrate ML platform qua Kubeflow , dự là có thêm contributor từ Cloudflare cho Kubeflow rồi các sếp.",#mlops	#kubeflow,
"Hi mọi người,
Em đang làm newbie trong mảng MLOps, DE nên em muốn làm 1 project từ giai đoạn build database, CI/CD từ Github, xây hệ thống ML để deploy luôn thì không biết có nguồn nào từ scratch luôn không ạ?
Hiện thì em cũng có google được một số project có thể áp dụng cơ mà em cũng muốn tham khảo thêm từ những người có kinh nghiệm góp ý.
Em cảm ơn mọi người nhiều ạ.","Hi mọi người, Em đang làm newbie trong mảng MLOps, DE nên em muốn làm 1 project từ giai đoạn build database, CI/CD từ Github, xây hệ thống ML để deploy luôn thì không biết có nguồn nào từ scratch luôn không ạ? Hiện thì em cũng có google được một số project có thể áp dụng cơ mà em cũng muốn tham khảo thêm từ những người có kinh nghiệm góp ý. Em cảm ơn mọi người nhiều ạ.",,
"🎉🎉🎉SEMINAR #12: Triton Server and TensorRT-LLM 🎉🎉🎉
Chào mừng các bạn đến với sự kiện seminar về ""Triton Server and TensorRT-LLM"". Đây là cơ hội tuyệt vời để tìm hiểu sâu hơn về quá trình deployment các model ML đặc biệt là LLM trên server cũng như là Edge device.
🎤 Diễn giả: Mr. Lê Tân Pha
👨‍💻Công việc hiện tại:
Senior AI Engineer tại MoMo
Founder của NVIAI.
📘 Nội dung chính:
+ Best practices in LLM deployment.
+ LLM deployment with TensorRT-LLM and Triton Server.
+ Deploy LLM model on Edge Device: Jetson Platform
+ Live demo
📅 Hãy đánh dấu lịch và đừng bỏ lỡ cơ hội này để cập nhật kiến thức và kỹ năng mới nhất về Triton và TensorRT. Lê Tân Pha sẽ mang đến cho chúng ta những kinh nghiệm thực tế và bí quyết giúp quá trình deployment trở nên dễ dàng.
Hãy đăng ký tham gia ngay hôm nay để không bỏ lỡ bất kỳ thông tin quý giá nào!
📌 Thời gian: Thứ năm, ngày 23/11/2023, 20:00 - 21:00 GMT+7🎉
📌 Hình thức: Online qua Zoom (https://umu.zoom.us/j/65608200901)
📌 Link đăng ký tham gia: https://forms.gle/xG9vVb2xkWPd4ABA8
🎯CÁC BẠN LƯU Ý LINK ZOOM SẼ XUẤT HIỆN KHI CÁC BẠN SUBMIT FORM, NÊN HÃY LƯU LẠI TRƯỚC NHÉ.
CẢM ƠN CÁC BẠN ĐÃ ĐĂNG KÝ THAM GIA
———————————
Tham gia Facebook Group tại: https://www.facebook.com/groups/mlopsvn/
Tham gia Discord Channel tại: https://discord.gg/JNbQpba9Ae
Theo dõi Linkedin tại:
https://www.linkedin.com/company/mlopsvn/
#mlopsvn #seminar
#TritonServer #LeTanPha #MoMo #LLM #TensorRT","SEMINAR Triton Server and TensorRT-LLM Chào mừng các bạn đến với sự kiện seminar về ""Triton Server and TensorRT-LLM"". Đây là cơ hội tuyệt vời để tìm hiểu sâu hơn về quá trình deployment các model ML đặc biệt là LLM trên server cũng như là Edge device. Diễn giả: Mr. Lê Tân Pha Công việc hiện tại: Senior AI Engineer tại MoMo Founder của NVIAI. Nội dung chính: + Best practices in LLM deployment. + LLM deployment with TensorRT-LLM and Triton Server. + Deploy LLM model on Edge Device: Jetson Platform + Live demo Hãy đánh dấu lịch và đừng bỏ lỡ cơ hội này để cập nhật kiến thức và kỹ năng mới nhất về Triton và TensorRT. Lê Tân Pha sẽ mang đến cho chúng ta những kinh nghiệm thực tế và bí quyết giúp quá trình deployment trở nên dễ dàng. Hãy đăng ký tham gia ngay hôm nay để không bỏ lỡ bất kỳ thông tin quý giá nào! Thời gian: Thứ năm, ngày 23/11/2023, 20:00 - 21:00 GMT+7 Hình thức: Online qua Zoom (https://umu.zoom.us/j/65608200901) Link đăng ký tham gia: https://forms.gle/xG9vVb2xkWPd4ABA8 CÁC BẠN LƯU Ý LINK ZOOM SẼ XUẤT HIỆN KHI CÁC BẠN SUBMIT FORM, NÊN HÃY LƯU LẠI TRƯỚC NHÉ. CẢM ƠN CÁC BẠN ĐÃ ĐĂNG KÝ THAM GIA ——————————— Tham gia Facebook Group tại: https://www.facebook.com/groups/mlopsvn/ Tham gia Discord Channel tại: https://discord.gg/JNbQpba9Ae Theo dõi Linkedin tại: https://www.linkedin.com/company/mlopsvn/",#12:	#mlopsvn	#seminar	#TritonServer	#LeTanPha	#MoMo	#LLM	#TensorRT,
"Kubeflow Summit 2023

Đầu tháng 10 vừa qua mới diễn ra Kubeflow Summit 2023 với chủ đề chính là Kubeflow Pipelines version 2 và Kubeflow use-cases ở một số công ty lớn.
Một số điểm cải thiện nổi bật ở version 2: 
Cải thiện KFP SDK giúp cho việc code các pipeline component dễ dàng hơn và đỡ bị rối mắt. 
Kubeflow pipeline có thể chạy trên các backend khác, không bị phụ thuộc vào Argo nữa.
Cải thiện các visualization trong pipelines.
Cải thiện ML metadata giúp dễ dàng hơn trong việc lineage tracking cho artifacts.
Cải thiện security cho Argo, Minio, .v.v.
Một số tool thú vị được sử dụng bởi các công ty:
Buildpacks (https://buildpacks.io/): được sử dụng bởi Roche cho phép tự động detect và build image từ code
Kyverno (https://kyverno.io/): sử dụng bởi Roblox để validate và mutate các rule và policy trong k8s

Các recordings của Kubeflow Summit:
https://vimeo.com/871171608 
https://vimeo.com/871926867","Kubeflow Summit 2023 Đầu tháng 10 vừa qua mới diễn ra Kubeflow Summit 2023 với chủ đề chính là Kubeflow Pipelines version 2 và Kubeflow use-cases ở một số công ty lớn. Một số điểm cải thiện nổi bật ở version 2: Cải thiện KFP SDK giúp cho việc code các pipeline component dễ dàng hơn và đỡ bị rối mắt. Kubeflow pipeline có thể chạy trên các backend khác, không bị phụ thuộc vào Argo nữa. Cải thiện các visualization trong pipelines. Cải thiện ML metadata giúp dễ dàng hơn trong việc lineage tracking cho artifacts. Cải thiện security cho Argo, Minio, .v.v. Một số tool thú vị được sử dụng bởi các công ty: Buildpacks (https://buildpacks.io/): được sử dụng bởi Roche cho phép tự động detect và build image từ code Kyverno (https://kyverno.io/): sử dụng bởi Roblox để validate và mutate các rule và policy trong k8s Các recordings của Kubeflow Summit: https://vimeo.com/871171608 https://vimeo.com/871926867",,
Tham gia ngay bây giờ thôi mọi người ơi 🎉🎉🎉,Tham gia ngay bây giờ thôi mọi người ơi,,
Mọi người nhanh tay đăng ký tham dự nào 💥💥💥,Mọi người nhanh tay đăng ký tham dự nào,,
"Từ k8s 1.27 là HPA có thể scale dựa trên metrics của từng container rồi nhé các sếp 🫡. Tính năng này cho phép users có thể dễ dàng scale pod dựa trên một container nhất định trong một multi-container pod. Ae nào thử tính năng này chưa nhỉ?
Nguồn: https://www.linkedin.com/feed/update/urn:li:activity:7120265745434853376/
#k8s",Từ k8s 1.27 là HPA có thể scale dựa trên metrics của từng container rồi nhé các sếp . Tính năng này cho phép users có thể dễ dàng scale pod dựa trên một container nhất định trong một multi-container pod. Ae nào thử tính năng này chưa nhỉ? Nguồn: https://www.linkedin.com/feed/update/urn:li:activity:7120265745434853376/,#k8s,
"Analyze the Trade-Offs of Vector Databases
Bài phân tích các giải pháp Vector DB trên nhiều khía cạnh này chắc sẽ hữu ích cho mấy bác đang triển khai các hệ thống LLM.
https://thedataquarry.com/posts/vector-db-4/
#llm #vectordb",Analyze the Trade-Offs of Vector Databases Bài phân tích các giải pháp Vector DB trên nhiều khía cạnh này chắc sẽ hữu ích cho mấy bác đang triển khai các hệ thống LLM. https://thedataquarry.com/posts/vector-db-4/,#llm	#vectordb,
"DopikAI vừa public DPKLLM Benchmark - Bộ benchmark dataset dành riêng cho LLM tiếng Việt, dưới dạng một challenge tổ chức trên aihub. DPKLLM tiến hành đánh giá trên nhiều tập dataset với nhiều tác vụ khác nhau
ViLaw-QA: Tập trung vào vấn đề hỏi đáp trên miền dữ liệu về luật pháp Việt Nam
VitruthfulQA: Tập trung đánh giá tính trung thực của các câu trả lời được sinh bởi LLM (tương tự TruthfulQA nhưng dành cho tiếng Việt)
Các tập dữ liệu chuyên về hỏi đáp của các bên khác như ViWikiQA, ViCoQA, ViNewsQA, ...
Ngoài ra, challenge cũng xem xét đánh giá tác vụ NER với tiếng Việt của LLM
Đây là cơ hội để các cá nhân, tổ chức đang phát triển LLM có thể tham gia đánh giá và so sánh kết quả của mình với các bên khác cũng như trao đổi và học hỏi lẫn nhau. Challenge kéo dài vô thời hạn, và mọi người có thể dễ dàng đăng ký tham gia cũng như submit kết quả lên hệ thống.","DopikAI vừa public DPKLLM Benchmark - Bộ benchmark dataset dành riêng cho LLM tiếng Việt, dưới dạng một challenge tổ chức trên aihub. DPKLLM tiến hành đánh giá trên nhiều tập dataset với nhiều tác vụ khác nhau ViLaw-QA: Tập trung vào vấn đề hỏi đáp trên miền dữ liệu về luật pháp Việt Nam VitruthfulQA: Tập trung đánh giá tính trung thực của các câu trả lời được sinh bởi LLM (tương tự TruthfulQA nhưng dành cho tiếng Việt) Các tập dữ liệu chuyên về hỏi đáp của các bên khác như ViWikiQA, ViCoQA, ViNewsQA, ... Ngoài ra, challenge cũng xem xét đánh giá tác vụ NER với tiếng Việt của LLM Đây là cơ hội để các cá nhân, tổ chức đang phát triển LLM có thể tham gia đánh giá và so sánh kết quả của mình với các bên khác cũng như trao đổi và học hỏi lẫn nhau. Challenge kéo dài vô thời hạn, và mọi người có thể dễ dàng đăng ký tham gia cũng như submit kết quả lên hệ thống.",,
"Xin phép các bác flex tí về đồ án Text Image Retrieval của một học sinh khóa MLE em đang training. Model được deploy trên GKE và expose sử dụng Nginx Ingress. Jenkins để build CI/CD pipeline được deploy trên GCE sử dụng Ansible. Bên cạnh đó, bạn cũng dùng GKE để deploy các monitoring tools để observe hệ thống. README được viết rất chi tiết, nên em hy vọng sẽ là một nguồn tài liệu hữu ích khác bên cạnh MLOps Crash Course :D.
https://github.com/duongngyn0510/continuous-deployment-to-gke-cluster
Mọi người đừng quên động viên bạn ý một Github star nếu thấy có ích nhé ạ ;).
Chúc các bác buổi tối tốt lành!
#mle #mlops","Xin phép các bác flex tí về đồ án Text Image Retrieval của một học sinh khóa MLE em đang training. Model được deploy trên GKE và expose sử dụng Nginx Ingress. Jenkins để build CI/CD pipeline được deploy trên GCE sử dụng Ansible. Bên cạnh đó, bạn cũng dùng GKE để deploy các monitoring tools để observe hệ thống. README được viết rất chi tiết, nên em hy vọng sẽ là một nguồn tài liệu hữu ích khác bên cạnh MLOps Crash Course :D. https://github.com/duongngyn0510/continuous-deployment-to-gke-cluster Mọi người đừng quên động viên bạn ý một Github star nếu thấy có ích nhé ạ ;). Chúc các bác buổi tối tốt lành!",#mle	#mlops,
"RAY SUMMIT 2023 (Sep 18-20)
HEAR FROM THE TEAMS AND LEADERS DEVELOPING THE NEXT GENERATION OF AI APPLICATIONS. LEARN HOW TO DEVELOP AND DEPLOY LLM AND GENERATIVE AI APPLICATIONS WITH OUR HANDS-ON TRAINING AND TUTORIALS.
Hội nghị về LLM và Generative AI tổ chức bởi Ray với speakers đến từ các công ty lớn cho các bác nào quan tâm. Hôm nay là buổi thứ 2 của summit rồi :D
https://raysummit.anyscale.com/
#llm #generativeai #ray",RAY SUMMIT 2023 (Sep 18-20) HEAR FROM THE TEAMS AND LEADERS DEVELOPING THE NEXT GENERATION OF AI APPLICATIONS. LEARN HOW TO DEVELOP AND DEPLOY LLM AND GENERATIVE AI APPLICATIONS WITH OUR HANDS-ON TRAINING AND TUTORIALS. Hội nghị về LLM và Generative AI tổ chức bởi Ray với speakers đến từ các công ty lớn cho các bác nào quan tâm. Hôm nay là buổi thứ 2 của summit rồi :D https://raysummit.anyscale.com/,#llm	#generativeai	#ray,
Chung kết MLOps Marathon 2023 đang live nhé mọi người :v rất nhiều kiến thức hay ho,Chung kết MLOps Marathon 2023 đang live nhé mọi người :v rất nhiều kiến thức hay ho,,
"Cách tính và tối ưu cost của các dịch vụ trên Cloud
Đọc để hiểu xem các dịch vụ tính tiền như thế nào và tối ưu cost ra sao nhé các sếp 😱
https://handbook.vantage.sh/
#costoptimization #aws #cloud",Cách tính và tối ưu cost của các dịch vụ trên Cloud Đọc để hiểu xem các dịch vụ tính tiền như thế nào và tối ưu cost ra sao nhé các sếp https://handbook.vantage.sh/,#costoptimization	#aws	#cloud,
Nhanh tay đăng ký nào các bạn ơi 🎉,Nhanh tay đăng ký nào các bạn ơi,,
"Hello anh chị em trong nhóm 😄,
Bữa giờ chắc mọi người cũng thấy phần online technical seminars dành chung cho các anh em trong group đã tạm pending để nhường chỗ cho chuỗi technical seminars dành riêng cho các bạn tham dự MLOps Marathon. 😞
Tuy nhiên, hôm nay, mình xin phép thay mặt anh em trong đội ngũ admin, trân trọng giới thiệu buổi online seminar về MLOps dành chung cho tất cả anh chị em trong nhóm sẽ quay trở lại vào 8h tối thứ 5 tới đây, với chủ đề về “Optimize ML service’s performance with continuous right-sizing containers in Kubernetes “. 👏👏👏
Hy vọng anh chị em sẽ thấy hứng thú, và nhớ dành thời gian thứ 5 tới đây để lắng nghe những chia sẻ của bác Tạ Tô Minh Chí , là Senior Devops Engineer, đã có kinh nghiệm chinh chiến ở những công ty lớn như MoMo, MISA. Mọi người có thể đặt câu hỏi và thảo luận về những băn khoăn của mình về các chủ đề liên quan một cách thoải mái trong buổi sắp tới nhé! 👉👈
Đừng quên đăng ký theo link bên dưới để tụi mình gửi link Zoom cho các bạn. Thank you! 🙏","Hello anh chị em trong nhóm , Bữa giờ chắc mọi người cũng thấy phần online technical seminars dành chung cho các anh em trong group đã tạm pending để nhường chỗ cho chuỗi technical seminars dành riêng cho các bạn tham dự MLOps Marathon. Tuy nhiên, hôm nay, mình xin phép thay mặt anh em trong đội ngũ admin, trân trọng giới thiệu buổi online seminar về MLOps dành chung cho tất cả anh chị em trong nhóm sẽ quay trở lại vào 8h tối thứ 5 tới đây, với chủ đề về “Optimize ML service’s performance with continuous right-sizing containers in Kubernetes “. Hy vọng anh chị em sẽ thấy hứng thú, và nhớ dành thời gian thứ 5 tới đây để lắng nghe những chia sẻ của bác Tạ Tô Minh Chí , là Senior Devops Engineer, đã có kinh nghiệm chinh chiến ở những công ty lớn như MoMo, MISA. Mọi người có thể đặt câu hỏi và thảo luận về những băn khoăn của mình về các chủ đề liên quan một cách thoải mái trong buổi sắp tới nhé! Đừng quên đăng ký theo link bên dưới để tụi mình gửi link Zoom cho các bạn. Thank you!",,
,nan,,
,nan,,
,nan,,
"Em chào các bác. Sắp ra trường nên em cảm thấy hơi mông lung về sự nghiệp xin được chỉ giáo nhẹ từ những đàn anh đi trước ạ.
Do công việc về MLOps đang không có tuyển fresher nhiều (theo quan sát cá nhân em ạ) nên em đang cân nhắc có nên đi học việc DevOps 1 thời gian tầm 1-3 năm để học thêm về xây dựng điều hành hệ thống không, sau đó mới chuyển sang làm hệ thống ML đặc thù. Tuy nhiên thì do kinh nghiệm SE ít, em cũng không biết liệu thời gian này đi làm SE chuyên code ML model, data pipeline (để nâng tay nghề) có khôn ngoan hơn không ạ.
Em đang phân vân giữa 2 định hướng này, bác nào đi qua có lời khuyên thì em xin được nhận. Cảm ơn các bác đã dành thời gian đọc đến đây ạ. Bài viết trong vội vã nên ngắn và hơi lủng củng có gì mong các bác thứ lỗi.","Em chào các bác. Sắp ra trường nên em cảm thấy hơi mông lung về sự nghiệp xin được chỉ giáo nhẹ từ những đàn anh đi trước ạ. Do công việc về MLOps đang không có tuyển fresher nhiều (theo quan sát cá nhân em ạ) nên em đang cân nhắc có nên đi học việc DevOps 1 thời gian tầm 1-3 năm để học thêm về xây dựng điều hành hệ thống không, sau đó mới chuyển sang làm hệ thống ML đặc thù. Tuy nhiên thì do kinh nghiệm SE ít, em cũng không biết liệu thời gian này đi làm SE chuyên code ML model, data pipeline (để nâng tay nghề) có khôn ngoan hơn không ạ. Em đang phân vân giữa 2 định hướng này, bác nào đi qua có lời khuyên thì em xin được nhận. Cảm ơn các bác đã dành thời gian đọc đến đây ạ. Bài viết trong vội vã nên ngắn và hơi lủng củng có gì mong các bác thứ lỗi.",,
,nan,,
"Bytedance sử dụng Ray Data để xử lý 200TB dữ liệu từ nhiều nguồn concurrently (sorry các bác em không biết dịch sao :v) trên cả CPU và GPU, đồng thời sử dụng model sharding để chia layer (hoặc weight của mỗi layer) của model ra xử lý trên nhiều GPU.
https://www.anyscale.com/blog/how-bytedance-scales-offline-inference-with-multi-modal-llms-to-200TB-data
Bác nào thay Spark bằng Ray Data chưa ạ? =))
#llm #modelsharding #ray","Bytedance sử dụng Ray Data để xử lý 200TB dữ liệu từ nhiều nguồn concurrently (sorry các bác em không biết dịch sao :v) trên cả CPU và GPU, đồng thời sử dụng model sharding để chia layer (hoặc weight của mỗi layer) của model ra xử lý trên nhiều GPU. https://www.anyscale.com/blog/how-bytedance-scales-offline-inference-with-multi-modal-llms-to-200TB-data Bác nào thay Spark bằng Ray Data chưa ạ? =))",#llm	#modelsharding	#ray,
"What type of worker nodes should I use, and how many of them?
Một bài phân tích hay cho bác nào đang phân vân không biết nên chọn bao nhiêu node, node to hay node bé cho k8s cluster của mình.
https://learnk8s.io/kubernetes-node-size","What type of worker nodes should I use, and how many of them? Một bài phân tích hay cho bác nào đang phân vân không biết nên chọn bao nhiêu node, node to hay node bé cho k8s cluster của mình. https://learnk8s.io/kubernetes-node-size",,
Nhanh tay đăng ký cho seminar ngày mai thôi các bạn ơi 💪💪💪,Nhanh tay đăng ký cho seminar ngày mai thôi các bạn ơi,,
Nhanh tay đăng ký để tham gia seminar ngay lúc này nha các bạn,Nhanh tay đăng ký để tham gia seminar ngay lúc này nha các bạn,,
"[Góc giải cứu]


Các anh chị cho em hỏi, em là sinh viên năm 2 mới biết đến khoá học trên https://mlops.vn/#registration qua youtube.  Em thử nhập mã code  trên youtube là  MLOPSVN-REL thì wed báo lỗi mã không hợp lệ. Anh chị hướng dẫn em với ạ. Em thực sự muốn học khoá học này ạ.","[Góc giải cứu] Các anh chị cho em hỏi, em là sinh viên năm 2 mới biết đến khoá học trên https://mlops.vn/#registration qua youtube. Em thử nhập mã code trên youtube là MLOPSVN-REL thì wed báo lỗi mã không hợp lệ. Anh chị hướng dẫn em với ạ. Em thực sự muốn học khoá học này ạ.",,
Xin phép admin Quan Dang để chia sẻ thông tin về tọa đàm AI vào chiều thứ 6 sắp tới. Mọi người quan tâm có thể đăng ký tham gia tại đây nhé https://bit.ly/ToaDam28-07,Xin phép admin Quan Dang để chia sẻ thông tin về tọa đàm AI vào chiều thứ 6 sắp tới. Mọi người quan tâm có thể đăng ký tham gia tại đây nhé https://bit.ly/ToaDam28-07,,
"[Góc xin tư vấn]
Chào mọi người,
Em đi làm hơn 3 năm rồi, ban đầu code backend, xong làm Project Manager, rồi làm Data Engineer nữa, nhưng em là dân nhảy ngành ạ. Ban đầu thấy làm dev không khó lắm, cũng bởi junior thì khó khăn gì cũng đc các anh chị giúp đỡ nên nghĩ mình học nhanh sáng dạ. Nhưng rồi khi tự bơi thì càng ngày em càng thấy knowledge gap của mình nhiều quá, làm những task khó đều thấy mất quá nhiều thời gian, cảm thấy mình là ""worker"" làm theo task được giao chứ ko phải là ""engineer"" nữa, dần dần mất sự joyful nên có của việc development. Em vẫn mày mò tự học, lấy cert này cert kia, đọc sách này sách nọ, rồi càng đọc sâu em càng thấy mình thiếu cơ bản, đơn cử nhất là khi em biết rằng query database ko phải chỉ là ""Select * from table"" mà là Linear Algebra 🥹 Vì vậy em đang có ý định học MCs về Computer Science ạ, cho em có tấm bằng để apply vô các giants, mà quan trọng hơn là em buildup kiến thức ạ 🥹
Em tìm được khóa này, của University of Colorado Boulder: https://www.coursera.org/degrees/ms-computer-science-boulder
Trong hình là các courses nó dạy và các expected knowledges để có thể học ạ. Em thấy nó phù hợp vì cảm thấy nó dạy và yêu cầu kiến thức rất nền tảng, ko phải ăn xổi kiểu on-job-training để chạy dự án, làm nhiều quen tay.
Anh chị có thể cho em xin tư vấn có nên theo học không với, cụ thể khóa này luôn thì tốt ạ. Bởi dù sao đó cũng là 1 trade-off khá lớn, cả về thời gian và tiền bạc ($15k ~ 350Mil VND). Hoặc nếu không thì ai chỉ cho em trường ở Sài Gòn với, em prefer học bằng tiếng anh ạ.
Em cảm ơn mọi người đã đọc ạ.","[Góc xin tư vấn] Chào mọi người, Em đi làm hơn 3 năm rồi, ban đầu code backend, xong làm Project Manager, rồi làm Data Engineer nữa, nhưng em là dân nhảy ngành ạ. Ban đầu thấy làm dev không khó lắm, cũng bởi junior thì khó khăn gì cũng đc các anh chị giúp đỡ nên nghĩ mình học nhanh sáng dạ. Nhưng rồi khi tự bơi thì càng ngày em càng thấy knowledge gap của mình nhiều quá, làm những task khó đều thấy mất quá nhiều thời gian, cảm thấy mình là ""worker"" làm theo task được giao chứ ko phải là ""engineer"" nữa, dần dần mất sự joyful nên có của việc development. Em vẫn mày mò tự học, lấy cert này cert kia, đọc sách này sách nọ, rồi càng đọc sâu em càng thấy mình thiếu cơ bản, đơn cử nhất là khi em biết rằng query database ko phải chỉ là ""Select * from table"" mà là Linear Algebra Vì vậy em đang có ý định học MCs về Computer Science ạ, cho em có tấm bằng để apply vô các giants, mà quan trọng hơn là em buildup kiến thức ạ Em tìm được khóa này, của University of Colorado Boulder: https://www.coursera.org/degrees/ms-computer-science-boulder Trong hình là các courses nó dạy và các expected knowledges để có thể học ạ. Em thấy nó phù hợp vì cảm thấy nó dạy và yêu cầu kiến thức rất nền tảng, ko phải ăn xổi kiểu on-job-training để chạy dự án, làm nhiều quen tay. Anh chị có thể cho em xin tư vấn có nên theo học không với, cụ thể khóa này luôn thì tốt ạ. Bởi dù sao đó cũng là 1 trade-off khá lớn, cả về thời gian và tiền bạc ($15k ~ 350Mil VND). Hoặc nếu không thì ai chỉ cho em trường ở Sài Gòn với, em prefer học bằng tiếng anh ạ. Em cảm ơn mọi người đã đọc ạ.",,
"Cho mình hỏi có bạn nào đăng kí nhóm khóa học ML engineer của a Quân không, mình đk nhóm để đc discount ạ. Nếu có thì comment mình nhắn tin ạ.","Cho mình hỏi có bạn nào đăng kí nhóm khóa học ML engineer của a Quân không, mình đk nhóm để đc discount ạ. Nếu có thì comment mình nhắn tin ạ.",,
"Pydantic 2.0 vừa release đẩy một phần core qua xử lý bằng Rust giúp tối ưu tốc độ lên tới 5 lần, bác nào dùng FastAPI chú ý nhé ạ 🧐","Pydantic 2.0 vừa release đẩy một phần core qua xử lý bằng Rust giúp tối ưu tốc độ lên tới 5 lần, bác nào dùng FastAPI chú ý nhé ạ",,
,nan,,
"Chia sẻ cho các bác nào quan tâm tới mấy công nghệ computer vision đang trong top trending 🤣
#computervision",Chia sẻ cho các bác nào quan tâm tới mấy công nghệ computer vision đang trong top trending,#computervision,
"Khóa học khác về OpenAI nhé cả nhà, miễn phí nhưng giới hạn số người đăng ký nên mọi người nhanh tay đăng ký không hết cơ hội ạ 🤣
#llm #openai","Khóa học khác về OpenAI nhé cả nhà, miễn phí nhưng giới hạn số người đăng ký nên mọi người nhanh tay đăng ký không hết cơ hội ạ",#llm	#openai,
"[Research article] dành cho các bạn cần một cái nhìn tổng quan về MLOps.
Machine Learning Operations (MLOps): Overview, Definition, and Architecture
DOMINIK KREUZBERGER , NIKLAS KÜHL, AND SEBASTIAN HIRSCHL
Link trên IEEE Access: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10081336
Link trên arxiv: https://arxiv.org/abs/2205.02302
#review #survey #research #paper","[Research article] dành cho các bạn cần một cái nhìn tổng quan về MLOps. Machine Learning Operations (MLOps): Overview, Definition, and Architecture DOMINIK KREUZBERGER , NIKLAS KÜHL, AND SEBASTIAN HIRSCHL Link trên IEEE Access: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10081336 Link trên arxiv: https://arxiv.org/abs/2205.02302",#review	#survey	#research	#paper,
Ý tưởng hay về tối ưu memory cho các LLM models từ các sếp UC Berkeley cho ae tham khảo 😁,Ý tưởng hay về tối ưu memory cho các LLM models từ các sếp UC Berkeley cho ae tham khảo,,
"Các bác có bao giờ thắc mắc nên dùng ""== None"" hay ""is None"" chưa ạ? 😅
#tips","Các bác có bao giờ thắc mắc nên dùng ""== None"" hay ""is None"" chưa ạ?",#tips,
"Khoá học miễn phí LangChain & Vector Databases in Production
Em xin phép chia sẻ với các bác một khoá học LLM khác rất practical vì có siêu nhiều hands-on projects và có luôn cả chứng chỉ để mọi người mang đi khoe 🤣.
Nhân tiện đây là page mới của em chia sẻ thêm về nhiều thứ khác xung quanh Data Science (không chỉ MLOps), bác nào quan tâm thì like ủng hộ em với nhé ạ :v.
Cảm ơn cả nhà và chúc cả nhà một buổi tối tốt lành 🥰
#llm #langchain #fullstackds","Khoá học miễn phí LangChain & Vector Databases in Production Em xin phép chia sẻ với các bác một khoá học LLM khác rất practical vì có siêu nhiều hands-on projects và có luôn cả chứng chỉ để mọi người mang đi khoe . Nhân tiện đây là page mới của em chia sẻ thêm về nhiều thứ khác xung quanh Data Science (không chỉ MLOps), bác nào quan tâm thì like ủng hộ em với nhé ạ :v. Cảm ơn cả nhà và chúc cả nhà một buổi tối tốt lành",#llm	#langchain	#fullstackds,
"MLOps Marathon 2023 Training Seminars Recordings
Dạo gần đây em nhận được rất nhiều tin nhắn của các bác muốn tham gia marathon, nhưng lại sợ chưa có đủ kiến thức để tham gia, nên em xin được gửi lại link playlist của chuỗi training seminars vừa rồi cho mọi người tại đây: https://www.youtube.com/playlist?list=PLvmLXlo5OR87Gifw5IT-YWllj67YHhaEw. Mục đích của chuỗi seminars này nhằm trang bị cho mọi người các kỹ năng software engineering cơ bản nhưng cũng không kém phần quan trọng, đồng thời cung cấp cả kiến thức về data drift và sample solution giúp mọi người có một quick start cho marathon.
Bên cạnh chuỗi seminars này thì mọi người đừng quên chúng ta còn khoá học MLOps Crash Course miễn phí (nhưng cũng tốn nhiều công sức của em và bác Tung Nar để hoàn thiện và publish) bằng cách đăng ký tại đây https://mlops.vn/#registration với mã code: MLOPS-MARA.
Tài liệu đã có, mọi người nếu muốn cải thiện kỹ năng xây dựng hệ thống ML hoặc MLOps thì hãy bớt chút thời gian tham gia MLOps Marathon tại đây https://aihub.ml/competitions/376 để có cơ hội thực hành nhé ạ. 100 triệu phần thưởng là lớn, nhưng kinh nghiệm thu được thông qua thực hành còn quý hơn nhiều, mọi người còn chần chừ gì mà không đăng ký thôi nào ;).
Nhân đây em cũng xin trân trọng cảm ơn đội ngũ engineers xuất sắc đã cùng em tạo nên chuỗi training seminars này bao gồm các bác: Tung Nar Lê Ngọc Thạch Nguyễn Thái Sơn Nguyễn Vĩnh Phúc Thịnh Nguyễn

À mọi người đừng quên like và subscribe Youtube channel MLOpsVN để động viên team nhé ạ :v 

#mlopsmarathon2023 #software #training","MLOps Marathon 2023 Training Seminars Recordings Dạo gần đây em nhận được rất nhiều tin nhắn của các bác muốn tham gia marathon, nhưng lại sợ chưa có đủ kiến thức để tham gia, nên em xin được gửi lại link playlist của chuỗi training seminars vừa rồi cho mọi người tại đây: https://www.youtube.com/playlist?list=PLvmLXlo5OR87Gifw5IT-YWllj67YHhaEw. Mục đích của chuỗi seminars này nhằm trang bị cho mọi người các kỹ năng software engineering cơ bản nhưng cũng không kém phần quan trọng, đồng thời cung cấp cả kiến thức về data drift và sample solution giúp mọi người có một quick start cho marathon. Bên cạnh chuỗi seminars này thì mọi người đừng quên chúng ta còn khoá học MLOps Crash Course miễn phí (nhưng cũng tốn nhiều công sức của em và bác Tung Nar để hoàn thiện và publish) bằng cách đăng ký tại đây https://mlops.vn/#registration với mã code: MLOPS-MARA. Tài liệu đã có, mọi người nếu muốn cải thiện kỹ năng xây dựng hệ thống ML hoặc MLOps thì hãy bớt chút thời gian tham gia MLOps Marathon tại đây https://aihub.ml/competitions/376 để có cơ hội thực hành nhé ạ. 100 triệu phần thưởng là lớn, nhưng kinh nghiệm thu được thông qua thực hành còn quý hơn nhiều, mọi người còn chần chừ gì mà không đăng ký thôi nào ;). Nhân đây em cũng xin trân trọng cảm ơn đội ngũ engineers xuất sắc đã cùng em tạo nên chuỗi training seminars này bao gồm các bác: Tung Nar Lê Ngọc Thạch Nguyễn Thái Sơn Nguyễn Vĩnh Phúc Thịnh Nguyễn À mọi người đừng quên like và subscribe Youtube channel MLOpsVN để động viên team nhé ạ :v",#mlopsmarathon2023	#software	#training,
"Chào mn, có cách nào chạy cụm hdfs từ 1 máy ko nhỉ? Hiện tại mình muốn run cụm là phải chạy lệnh ""start namenode"" ở máy NAMENODE, sau đó chạy lệnh ""start datanode"" ở các máy DATANODE, rất mất thời gian.
Đã thử chạy bằng cách sau:
ssh user@DATANODE_IP start datanode
nhưng ko được, lỗi trả về là:
ERROR: JAVA_HOME is not set and could not be found,
trong khi mình check tại máy DATANODE, JAVA_HOME đã đc set rồi.
Ai biết nguyên nhân của lỗi này là gì ko ạ, chỉ giúp mình với. Hoặc chỉ cho mình 1 cách chạy khác cũng được, mình cảm ơn.","Chào mn, có cách nào chạy cụm hdfs từ 1 máy ko nhỉ? Hiện tại mình muốn run cụm là phải chạy lệnh ""start namenode"" ở máy NAMENODE, sau đó chạy lệnh ""start datanode"" ở các máy DATANODE, rất mất thời gian. Đã thử chạy bằng cách sau: ssh user@DATANODE_IP start datanode nhưng ko được, lỗi trả về là: ERROR: JAVA_HOME is not set and could not be found, trong khi mình check tại máy DATANODE, JAVA_HOME đã đc set rồi. Ai biết nguyên nhân của lỗi này là gì ko ạ, chỉ giúp mình với. Hoặc chỉ cho mình 1 cách chạy khác cũng được, mình cảm ơn.",,
"MLOps Marathon 2023 chỉ vừa mới bắt đầu, các bác nhanh tay đăng ký tham gia tại đây https://aihub.ml/competitions/376 để có cơ hội nhận 100 triệu và tham gia chuỗi training seminars miễn phí từ BTC nhé ạ ;).
Tuần này sẽ có 2 seminars hay ho là WebAPI và Data Drift, còn những seminars tuần vừa rồi thì như ảnh đính kèm bên dưới (link playlist sẽ được gửi lại cho các bác đăng ký mới).

#mlopsmarathon2023","MLOps Marathon 2023 chỉ vừa mới bắt đầu, các bác nhanh tay đăng ký tham gia tại đây https://aihub.ml/competitions/376 để có cơ hội nhận 100 triệu và tham gia chuỗi training seminars miễn phí từ BTC nhé ạ ;). Tuần này sẽ có 2 seminars hay ho là WebAPI và Data Drift, còn những seminars tuần vừa rồi thì như ảnh đính kèm bên dưới (link playlist sẽ được gửi lại cho các bác đăng ký mới).",#mlopsmarathon2023,
"Giới thiệu với các bác một nguồn để hỏi khác bên cạnh kênh Discord của MLOpsVN (https://discord.gg/XmKVtgyQfg). Ví dụ ở đây một bạn Quân Đặng giấu tên hỏi và đã được các bác, cụ thể là bác Dương Hằng bên AWS trả lời rất nhiệt tình 🥹:
https://repost.aws/questions/QUeCithZ5JTcaf9LyhhCF5BA/deploy-ml-timeseries-models-effectively
#aws #mlopsmarathon2023 #qna","Giới thiệu với các bác một nguồn để hỏi khác bên cạnh kênh Discord của MLOpsVN (https://discord.gg/XmKVtgyQfg). Ví dụ ở đây một bạn Quân Đặng giấu tên hỏi và đã được các bác, cụ thể là bác Dương Hằng bên AWS trả lời rất nhiệt tình : https://repost.aws/questions/QUeCithZ5JTcaf9LyhhCF5BA/deploy-ml-timeseries-models-effectively",#aws	#mlopsmarathon2023	#qna,
"MLOps Marathon 2023 Training Seminars - Module I
Hé lộ chuỗi seminars đầu tiên giúp trang bị kiến thức để cả nhà vững tâm thi đấu hơn ;), link tham dự sẽ chỉ được gửi cho thí sinh nên mọi người nhanh tay đăng ký tham gia thi đấu tại đây https://aihub.ml/competitions/376 thôi nào 🫡.
#mlopsmarathon2023 #seminar","MLOps Marathon 2023 Training Seminars - Module I Hé lộ chuỗi seminars đầu tiên giúp trang bị kiến thức để cả nhà vững tâm thi đấu hơn ;), link tham dự sẽ chỉ được gửi cho thí sinh nên mọi người nhanh tay đăng ký tham gia thi đấu tại đây https://aihub.ml/competitions/376 thôi nào .",#mlopsmarathon2023	#seminar,
"Webinar MLOps Marathon 2023 sắp diễn ra nha cả nhà ơi, mọi người nhanh tay đăng ký để giải đáp các thắc mắc và giao lưu với BTC thôi nào ạ ;). Đặc biệt sẽ có một vài bí mật được tiết lộ trong buổi này 😆.
Thời gian: 20h00, ngày 1/06/2023
Hình thức: Online qua Zoom
Link đăng ký tham gia: https://s.net.vn/V8zj 
#mlopsvn #seminar","Webinar MLOps Marathon 2023 sắp diễn ra nha cả nhà ơi, mọi người nhanh tay đăng ký để giải đáp các thắc mắc và giao lưu với BTC thôi nào ạ ;). Đặc biệt sẽ có một vài bí mật được tiết lộ trong buổi này . Thời gian: 20h00, ngày 1/06/2023 Hình thức: Online qua Zoom Link đăng ký tham gia: https://s.net.vn/V8zj",#mlopsvn	#seminar,
"Xin chào, có thầy nào làm mentor data engineer hoặc machine learning theo project. Em xin theo học với.","Xin chào, có thầy nào làm mentor data engineer hoặc machine learning theo project. Em xin theo học với.",,
"Webinar MLOps Marathon 2023 QnA vào 8h tối thứ 5 tuần này nhằm mục đích giải đáp các thắc mắc liên đến cuộc thi cho các bác nào quan tâm. Bên cạnh đó, các bác nào không tham gia được marathon cũng có thể tham dự để giao lưu cùng các speakers và các bác khác. 😇
#mlopsmarathon2023 #seminar #webinar","Webinar MLOps Marathon 2023 QnA vào 8h tối thứ 5 tuần này nhằm mục đích giải đáp các thắc mắc liên đến cuộc thi cho các bác nào quan tâm. Bên cạnh đó, các bác nào không tham gia được marathon cũng có thể tham dự để giao lưu cùng các speakers và các bác khác.",#mlopsmarathon2023	#seminar	#webinar,
"Kỹ thuật isolate pod đang chạy trên production để debug với hình minh hoạ cute hạt me 🤣
https://medium.com/@danielepolencic/isolating-kubernetes-pods-for-debugging-5fe41e630e9
#k8s #debug",Kỹ thuật isolate pod đang chạy trên production để debug với hình minh hoạ cute hạt me https://medium.com/@danielepolencic/isolating-kubernetes-pods-for-debugging-5fe41e630e9,#k8s	#debug,
"Góc trả recording cho Seminar MLOps on AWS
Em xin gửi lại slides và recording cho buổi Seminar: MLOps on AWS diễn ra tối thứ 5 vừa rồi cho các bác nào không tham dự được. Thay mặt cộng đồng MLOpsVN, em xin cảm ơn bác Dương Hằng rất nhiều vì đã cung cấp rất nhiều kiến thức bổ ích, các best practices và cả demo nữa 🫶.
Tiếp tới các bác muốn tìm hiểu thêm về chủ đề nào thì comment bên dưới nhé ạ? 🧐
Cảm ơn cả nhà và chúc mọi người cuối tuần vui vẻ.
#seminar #webinar #mlopsmarathon2023 #aws","Góc trả recording cho Seminar MLOps on AWS Em xin gửi lại slides và recording cho buổi Seminar: MLOps on AWS diễn ra tối thứ 5 vừa rồi cho các bác nào không tham dự được. Thay mặt cộng đồng MLOpsVN, em xin cảm ơn bác Dương Hằng rất nhiều vì đã cung cấp rất nhiều kiến thức bổ ích, các best practices và cả demo nữa . Tiếp tới các bác muốn tìm hiểu thêm về chủ đề nào thì comment bên dưới nhé ạ? Cảm ơn cả nhà và chúc mọi người cuối tuần vui vẻ.",#seminar	#webinar	#mlopsmarathon2023	#aws,
"Tóm tắt sự kiện AI Infra @ Scale 
1. AI Research SuperComputer (RSC):
- Sứ mệnh: Xử lý với khối lượng lớn dữ liệu (data volume), độ đa dạng của dữ liệu (data variety) với nhiều thể loại từ audio, image, tới text, video, logs và model checkpoints, ...,đảm bảo được tính bảo mật dữ liệu (data privacy), tăng tốc quá trình nghiên cứu sáng tạo, đồng thời đối ứng được với độ phức tạp ngày càng tăng của các model (ví dụ model MT-NLG với 530 tỉ tham số) và Metaverse.
- AI RSC có gì mới với các data center có sẵn ở Meta: Hệ thống tản nhiệt nước (liquid cooling) thay cho tản nhiệt gió (air flow cooling) để phục vụ quá trinh AI training, hệ thống cung cấp điện mới đáp ưng cho sự xuất hiện của các rack chứa GPU, và hệ thống mạng flat giảm thiểu độ trễ và tối đa băng thông. Hệ thống mạng flat này được hiểu nôm na là ông Data Scientist sẽ không phải đau đầu trong việc chọn lựa các node ở gần nhau để training nữa. Bên cạnh việc được cung cấp thêm các rack chứa GPU và hệ thống tản nhiệt nước thì RSC vẫn có những server bình thường như các data center khác.
- Năng lực tính toán: 2000 DGX A100 GPUS thế hệ mới nhất tại thời điểm mua, với 8 GPUs cho mỗi node (80GB memory cho mỗi GPU).
- Custom Storage System: Để đẩy nhanh quá trình lấy dữ liệu training, các dữ liệu training được tiền xử lý và phân phối tới vài nghìn Flash Arrays và cache lại ở các cache nodes (số lượng lên tới hàng trăm) giúp cho việc láy dữ liệu training nhanh hơn. Hệ thống này được gọi là AIRStore. Bên cạnh đó, NFS cũng được sử dụng cho việc lưu trữ checkpoints và code.
- Job Orchestration: Ông researcher sẽ submit 1 job tới cluster, job này được đặt vào queue, và Slurm (https://slurm.schedmd.com/documentation.html) sẽ chịu trách nhiệm tìm node phù hợp để chạy job.
- Thách thức trong vận hành RSC: GPU có thể lỗi cả phần cứng và phần mềm nên cần nhiều chiến lược xử lý khác nhau. Lỗi các thành phần mạng như NIC, cable và switch, hoặc các thành phần trong node (CPU, memory) cũng đáng quan tâm.
- Meta cam kết bảo vệ môi trường thông qua việc giảm thiểu thời gian sử dụng, hợp tác với các nhà cung cấp để đưa ra các giải pháp hợp lý, và sử dụng các vật liệu low-carbon.
- Góc khoe khoang: Model LLaMA đã giảm thiểu thời gian training rất nhiều do có lượng lớn GPU, đồng thời có khả năng training liên tục do sự ổn định hạ tầng. Model này có độ chính xác cao tương đương với các model với số lượng tham số nhiều hơn rất nhiều.
2. Pytorch 2.0
- Ngày càng nhiều paper được implement bằng PyTorch (đồ thị họ show nhìn đúng kiểu fit linear regression phát một là được :v)
- Torch Dynamo với Torch Inductor backend: giúp cho code PyTorch chạy nhanh hơn chỉ với 1 dòng code torch.compile(m, backend=""inductor""). Bản chất của đoạn code này là đi sửa Python bytecode để tối ưu trước khi execute
- PyTorch roadmap: về ngăn hạn tiếp tục cải thiện performance và khả năng tương thích với các core features khác, về dài hạn sẽ có thêm 2 tính năng là distributed compiler giúp tối ưu compute và communication giữa các node, và tính năng export giúp cho việc ông research có thể tạo ra 1 production model dễ dàng hơn (và thừa hưởng được các tính năng hay ho của PyTorch 2.0).
3. Chip MTIA dành riêng cho Deep Learning Recommendation Models (DLRM)
- Specification: Thiết kế mới sử dụng công nghệ TSNM 7nm, 800MHz frequency, TDP tối ưu ở 25W, với memory bandwith 800GB/s on-chip SRAM và 176GB/s off-chip DRAM
- Thiết kế chip: Chứa grid 8x8 processing units (PE), mỗi unit chứa 2 RISC-V cores, trong đó một core có thêm vector extension cung cấp khả năng tính toán vector. Mỗi PE sẽ được trang bị thêm các fixed-function unit giúp đẩy nhanh việc tính toán ma trận, các hàm non linear hay việc di chuyển dữ liệu trong PE, giữa các PE hoặc với một bộ nhớ ngoài.
- Thiết kế board: Sử dụng dual M.2, với TDP 35W, kết nối với host sử dụng 8 links PCle Gen4 giúp host bandwidth đạt 12.8GB/s.
- Thiết kế host: 12 boards, với TDP 780W.
- Chip mới này giúp cải thiện hiệu năng hơn NNPI (cái này em không biết là gì, chắc ý tác giả là NNAPI (https://www.tensorflow.org/lite/android/delegates/nnapi)?) và GPU cho các model vừa và nhỏ (low and medium complexity), và thua GPU cho các model lớn (high complexity)
4. Meta's Scalable Video Processor (MSVP):
- Quá trình xử lý video: Sau khi video được upload từ một thiết bị nào đó, trước tiên nó sẽ được lưu trữ ở data center, sau đó sẽ được transcode sang các format và độ phân giải (resolution) khác nhau, để phân phối tới các thiết bị và mạng (ví dụ mạng di động hay mạng WiFi) phù hợp.
- Quá trình transcode video: sau khi video được upload lên data center, nó sẽ được nén sử dụng AVC/H.264. Video này sau đó sẽ được decode thành các frame, rồi resize xuống độ phân giải thấp hơn (tại bước này thực chất sẽ resize ra nhiều độ phân giải khác nhau ví dụ 540p, 720p, và 1080p), và encode sử dụng một codec ví dụ như AV1, và cuối cùng là tính toán chất lượng so sánh với video nén ban đầu.
- Trade-offs trong hệ thống Video Encoding: 3 yếu tố cần tradeoff là compute cost, video quality và egress bandwith cost (bitrate). Ví dụ muốn đảm bảo chất lượng, mà giảm thiểu compute thì phải tăng bitrate (số lượng bit truyền đi trong một khoảng thời gian).
Link recording: https://www.youtube.com/watch?v=44t2-88GV3E
-------------------------------------------------------------------------------
🥰 Link đăng ký tham gia MLOps Marathon: https://aihub.ml/competitions/376
🥰 Link đăng ký khoá học MLOps Crash Course miễn phí: https://mlops.vn/#registration (sử dụng code MLOPS-MARA)
-------------------------------------------------------------------------------
#infra #mlops #mlopsmarathon2023","Tóm tắt sự kiện AI Infra @ Scale 1. AI Research SuperComputer (RSC): - Sứ mệnh: Xử lý với khối lượng lớn dữ liệu (data volume), độ đa dạng của dữ liệu (data variety) với nhiều thể loại từ audio, image, tới text, video, logs và model checkpoints, ...,đảm bảo được tính bảo mật dữ liệu (data privacy), tăng tốc quá trình nghiên cứu sáng tạo, đồng thời đối ứng được với độ phức tạp ngày càng tăng của các model (ví dụ model MT-NLG với 530 tỉ tham số) và Metaverse. - AI RSC có gì mới với các data center có sẵn ở Meta: Hệ thống tản nhiệt nước (liquid cooling) thay cho tản nhiệt gió (air flow cooling) để phục vụ quá trinh AI training, hệ thống cung cấp điện mới đáp ưng cho sự xuất hiện của các rack chứa GPU, và hệ thống mạng flat giảm thiểu độ trễ và tối đa băng thông. Hệ thống mạng flat này được hiểu nôm na là ông Data Scientist sẽ không phải đau đầu trong việc chọn lựa các node ở gần nhau để training nữa. Bên cạnh việc được cung cấp thêm các rack chứa GPU và hệ thống tản nhiệt nước thì RSC vẫn có những server bình thường như các data center khác. - Năng lực tính toán: 2000 DGX A100 GPUS thế hệ mới nhất tại thời điểm mua, với 8 GPUs cho mỗi node (80GB memory cho mỗi GPU). - Custom Storage System: Để đẩy nhanh quá trình lấy dữ liệu training, các dữ liệu training được tiền xử lý và phân phối tới vài nghìn Flash Arrays và cache lại ở các cache nodes (số lượng lên tới hàng trăm) giúp cho việc láy dữ liệu training nhanh hơn. Hệ thống này được gọi là AIRStore. Bên cạnh đó, NFS cũng được sử dụng cho việc lưu trữ checkpoints và code. - Job Orchestration: Ông researcher sẽ submit 1 job tới cluster, job này được đặt vào queue, và Slurm (https://slurm.schedmd.com/documentation.html) sẽ chịu trách nhiệm tìm node phù hợp để chạy job. - Thách thức trong vận hành RSC: GPU có thể lỗi cả phần cứng và phần mềm nên cần nhiều chiến lược xử lý khác nhau. Lỗi các thành phần mạng như NIC, cable và switch, hoặc các thành phần trong node (CPU, memory) cũng đáng quan tâm. - Meta cam kết bảo vệ môi trường thông qua việc giảm thiểu thời gian sử dụng, hợp tác với các nhà cung cấp để đưa ra các giải pháp hợp lý, và sử dụng các vật liệu low-carbon. - Góc khoe khoang: Model LLaMA đã giảm thiểu thời gian training rất nhiều do có lượng lớn GPU, đồng thời có khả năng training liên tục do sự ổn định hạ tầng. Model này có độ chính xác cao tương đương với các model với số lượng tham số nhiều hơn rất nhiều. 2. Pytorch 2.0 - Ngày càng nhiều paper được implement bằng PyTorch (đồ thị họ show nhìn đúng kiểu fit linear regression phát một là được :v) - Torch Dynamo với Torch Inductor backend: giúp cho code PyTorch chạy nhanh hơn chỉ với 1 dòng code torch.compile(m, backend=""inductor""). Bản chất của đoạn code này là đi sửa Python bytecode để tối ưu trước khi execute - PyTorch roadmap: về ngăn hạn tiếp tục cải thiện performance và khả năng tương thích với các core features khác, về dài hạn sẽ có thêm 2 tính năng là distributed compiler giúp tối ưu compute và communication giữa các node, và tính năng export giúp cho việc ông research có thể tạo ra 1 production model dễ dàng hơn (và thừa hưởng được các tính năng hay ho của PyTorch 2.0). 3. Chip MTIA dành riêng cho Deep Learning Recommendation Models (DLRM) - Specification: Thiết kế mới sử dụng công nghệ TSNM 7nm, 800MHz frequency, TDP tối ưu ở 25W, với memory bandwith 800GB/s on-chip SRAM và 176GB/s off-chip DRAM - Thiết kế chip: Chứa grid 8x8 processing units (PE), mỗi unit chứa 2 RISC-V cores, trong đó một core có thêm vector extension cung cấp khả năng tính toán vector. Mỗi PE sẽ được trang bị thêm các fixed-function unit giúp đẩy nhanh việc tính toán ma trận, các hàm non linear hay việc di chuyển dữ liệu trong PE, giữa các PE hoặc với một bộ nhớ ngoài. - Thiết kế board: Sử dụng dual M.2, với TDP 35W, kết nối với host sử dụng 8 links PCle Gen4 giúp host bandwidth đạt 12.8GB/s. - Thiết kế host: 12 boards, với TDP 780W. - Chip mới này giúp cải thiện hiệu năng hơn NNPI (cái này em không biết là gì, chắc ý tác giả là NNAPI (https://www.tensorflow.org/lite/android/delegates/nnapi)?) và GPU cho các model vừa và nhỏ (low and medium complexity), và thua GPU cho các model lớn (high complexity) 4. Meta's Scalable Video Processor (MSVP): - Quá trình xử lý video: Sau khi video được upload từ một thiết bị nào đó, trước tiên nó sẽ được lưu trữ ở data center, sau đó sẽ được transcode sang các format và độ phân giải (resolution) khác nhau, để phân phối tới các thiết bị và mạng (ví dụ mạng di động hay mạng WiFi) phù hợp. - Quá trình transcode video: sau khi video được upload lên data center, nó sẽ được nén sử dụng AVC/H.264. Video này sau đó sẽ được decode thành các frame, rồi resize xuống độ phân giải thấp hơn (tại bước này thực chất sẽ resize ra nhiều độ phân giải khác nhau ví dụ 540p, 720p, và 1080p), và encode sử dụng một codec ví dụ như AV1, và cuối cùng là tính toán chất lượng so sánh với video nén ban đầu. - Trade-offs trong hệ thống Video Encoding: 3 yếu tố cần tradeoff là compute cost, video quality và egress bandwith cost (bitrate). Ví dụ muốn đảm bảo chất lượng, mà giảm thiểu compute thì phải tăng bitrate (số lượng bit truyền đi trong một khoảng thời gian). Link recording: https://www.youtube.com/watch?v=44t2-88GV3E ------------------------------------------------------------------------------- Link đăng ký tham gia MLOps Marathon: https://aihub.ml/competitions/376 Link đăng ký khoá học MLOps Crash Course miễn phí: https://mlops.vn/#registration (sử dụng code MLOPS-MARA) -------------------------------------------------------------------------------",#infra	#mlops	#mlopsmarathon2023,
"AI INFRA @SCALE
Sau seminar MLOps on AWS tối nay lúc 8h (đăng ký tại https://bom.so/vysc5a) thì có thêm sự kiện AI Infra @Scale tổ chức lúc 23h bởi Meta với rất nhiều thông tin hữu ích, đặc biệt là The Future of AI Infra cho bác nào quan tâm.
https://atscaleconference.com/events/meta-ai-infra-scale/#global__section-event-agenda-77898
#seminar #infra #aws","AI INFRA @SCALE Sau seminar MLOps on AWS tối nay lúc 8h (đăng ký tại https://bom.so/vysc5a) thì có thêm sự kiện AI Infra @Scale tổ chức lúc 23h bởi Meta với rất nhiều thông tin hữu ích, đặc biệt là The Future of AI Infra cho bác nào quan tâm. https://atscaleconference.com/events/meta-ai-infra-scale/#global__section-event-agenda-77898",#seminar	#infra	#aws,
"MLOps Marathon Seminar: MLOps on AWS 
Thứ 5 tuần này chúng ta lại có online seminar hay ho khác về MLOps trên AWS và SageMaker do bác Dương Hằng bên AWS chia sẻ, mọi người nhanh tay đăng ký và đặt câu hỏi cho speaker tại đây https://bom.so/vysc5a nào.
🥰 Link đăng ký tham gia MLOps Marathon: https://aihub.ml/competitions/376
🥰 Link đăng ký khoá học MLOps Crash Course miễn phí: https://mlops.vn/#registration (sử dụng code MLOPS-MARA)
#aws #sagemaker #cloud #mlopsmarathon2023 #seminar #webinar","MLOps Marathon Seminar: MLOps on AWS Thứ 5 tuần này chúng ta lại có online seminar hay ho khác về MLOps trên AWS và SageMaker do bác Dương Hằng bên AWS chia sẻ, mọi người nhanh tay đăng ký và đặt câu hỏi cho speaker tại đây https://bom.so/vysc5a nào. Link đăng ký tham gia MLOps Marathon: https://aihub.ml/competitions/376 Link đăng ký khoá học MLOps Crash Course miễn phí: https://mlops.vn/#registration (sử dụng code MLOPS-MARA)",#aws	#sagemaker	#cloud	#mlopsmarathon2023	#seminar	#webinar,
"LLM Bootcamp - Spring 2023
Tiếp tục một nguồn tài liệu hay ho khác về LLM cho mọi người, đi từ Quick Start tới Foundations và Ops.
https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/
Mà bác dạy LLM Foundations đang cần tuyển designer thì phải :v
#llm #llmops","LLM Bootcamp - Spring 2023 Tiếp tục một nguồn tài liệu hay ho khác về LLM cho mọi người, đi từ Quick Start tới Foundations và Ops. https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/ Mà bác dạy LLM Foundations đang cần tuyển designer thì phải :v",#llm	#llmops,
"🔊🔊🔊 MLOPS MARATHON 2023 LAUNCH!!!
😍😍😍Mọi người ơi, hiện tại sự kiện MLOps Marathon 2023 Launch  đang được livestream trực tiếp trên fanpage, mọi người hãy cùng theo dõi nhé 😍😍😍
___________________________________________________
👉 Thông tin chi tiết tại: https://mlops.vn/marathon
📌 Cập nhật sự kiện tại:
🌐 MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/
🌐 MLOps VN Group | https://www.facebook.com/groups/mlopsvn
🌐 MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
🌐 MLOps VN Discord |  https://discord.gg/JNbQpba9Ae
🌐 MLOps VN Youtube | https://www.youtube.com/@mlopsvn","MLOPS MARATHON 2023 LAUNCH!!! Mọi người ơi, hiện tại sự kiện MLOps Marathon 2023 Launch đang được livestream trực tiếp trên fanpage, mọi người hãy cùng theo dõi nhé ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"📢 CHỈ CÒN 24 GIỜ NỮA, SỰ KIỆN KHỞI ĐỘNG CUỘC THI MLOPS MARATHON SẼ DIỄN RA!
👉 Đăng ký tham gia sự kiện tại: https://g2.by/Cq4J
📆 Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023
📍 Địa điểm: Phòng Anh Sáu, F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội và sẽ phát live trên Fanpage Facebook của MLOpsVN
🏆MLOps Marathon là cuộc thi đầu tiên tại Việt Nam về MLOps, được tổ chức trong Quý 2, 3 năm 2023, hứa hẹn mang đến nhiều thách thức cho các kĩ sư AI cùng nhiều giải thưởng hấp dẫn và giải nhất trị giá 100 TRIỆU ĐỒNG! Cuộc thi được xây dựng từ những kinh nghiệm thực tiễn, bám sát theo các vấn đề hay gặp của doanh nghiệp khi triển khai một dự án AI ra thị trường.
🌟 Bạn đã sẵn sàng để:
✔️ Trở thành một trong những người đầu tiên tham gia cuộc thi MLOps độc đáo này tại Việt Nam.
✔️ Gặp gỡ và trao đổi với các chuyên gia hàng đầu trong lĩnh vực Công nghệ thông tin thông qua các bài chia sẻ chuyên sâu.
✔️ Đối mặt với những thử thách hấp dẫn và thú vị để kiểm tra kỹ năng của bạn.
✔️ Giao lưu và tạo mối quan hệ trong cộng đồng Công nghệ sôi động.
✔️ Nhận hàng trăm phần quà hấp dẫn và quyền lợi độc quyền chỉ dành cho người tham dự sự kiện.
🎉 Hãy sẵn sàng cho cuộc thi MLOps Marathon, nơi bạn sẽ tìm thấy những cơ hội tuyệt vời, khám phá, và phát triển bản thân. Đừng bỏ lỡ cơ hội này để trở thành nhà vô địch MLOps đầu tiên của Việt Nam!
___________________________________________________
👉 Thông tin chi tiết tại: https://mlops.vn/marathon
📌 Cập nhật sự kiện tại:
🌐 MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/
🌐 MLOps VN Group | https://www.facebook.com/groups/mlopsvn
🌐 MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
🌐 MLOps VN Discord |  https://discord.gg/JNbQpba9Ae
🌐 MLOps VN Youtube | https://www.youtube.com/@mlopsvn","CHỈ CÒN 24 GIỜ NỮA, SỰ KIỆN KHỞI ĐỘNG CUỘC THI MLOPS MARATHON SẼ DIỄN RA! Đăng ký tham gia sự kiện tại: https://g2.by/Cq4J Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023 Địa điểm: Phòng Anh Sáu, F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội và sẽ phát live trên Fanpage Facebook của MLOpsVN MLOps Marathon là cuộc thi đầu tiên tại Việt Nam về MLOps, được tổ chức trong Quý 2, 3 năm 2023, hứa hẹn mang đến nhiều thách thức cho các kĩ sư AI cùng nhiều giải thưởng hấp dẫn và giải nhất trị giá 100 TRIỆU ĐỒNG! Cuộc thi được xây dựng từ những kinh nghiệm thực tiễn, bám sát theo các vấn đề hay gặp của doanh nghiệp khi triển khai một dự án AI ra thị trường. Bạn đã sẵn sàng để: Trở thành một trong những người đầu tiên tham gia cuộc thi MLOps độc đáo này tại Việt Nam. Gặp gỡ và trao đổi với các chuyên gia hàng đầu trong lĩnh vực Công nghệ thông tin thông qua các bài chia sẻ chuyên sâu. Đối mặt với những thử thách hấp dẫn và thú vị để kiểm tra kỹ năng của bạn. Giao lưu và tạo mối quan hệ trong cộng đồng Công nghệ sôi động. Nhận hàng trăm phần quà hấp dẫn và quyền lợi độc quyền chỉ dành cho người tham dự sự kiện. Hãy sẵn sàng cho cuộc thi MLOps Marathon, nơi bạn sẽ tìm thấy những cơ hội tuyệt vời, khám phá, và phát triển bản thân. Đừng bỏ lỡ cơ hội này để trở thành nhà vô địch MLOps đầu tiên của Việt Nam! ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"🎉 GIỚI THIỆU DÀN DIỄN GIẢ CHẤT PHÁT NGẤT CỦA MLOPS MARATHON TẠI LAUNCHING EVENT 12/05 🎉
𝑯𝒂𝒓𝒓𝒚 𝑵𝒈𝒖𝒚𝒆𝒏: Giảng viên tại trường Đại học Quốc gia Ireland ở Cork, chuyên về lĩnh vực Trí tuệ Nhân tạo (AI) và MLOps. Các nghiên cứu của anh đã được đăng tải trong nhiều hội nghị và tạp chí nổi tiếng, bao gồm AAAI Conference on Artificial Intelligence (AAAI), ACM Multimedia (ACM MM), và Health and Quality of Life Outcomes. Ngoài ra, anh Harry cũng là chủ tịch của nhiều cuộc thi và sự kiện AI/ML, chẳng hạn như cuộc thi reliable intelligence on social media, AI for COVID-19 detection và MLOps challenges.
𝑽𝒖̃ 𝑿𝒖𝒂̂𝒏 𝑺𝒐̛𝒏: nghiên cứu viên cao cấp của chương trình WASP Media & Language tại Đại học Umeå (Thụy Điển), trưởng nhóm phát triển AI/ML tại công ty Devr INC. Anh tập trung vào các công nghệ bảo vệ quyền riêng tư trong học máy và có nhiều công bố khoa học được đánh giá xuất sắc tại các hội nghị AI quốc tế. Anh là đồng sáng lập của một số dự án cộng đồng như AIcovidVN, AIHUB.ML, MLOpsVN.
𝑵𝒈𝒖𝒚𝒆̂̃𝒏 𝑻𝒓𝒐̣𝒏𝒈 𝑫𝒖̃𝒏𝒈: AI Lab Manager, AI Center, FPT Software. Sau khi tốt nghiệp Đại học Bách khoa Hà Nội, anh Trọng Dũng tiếp tục học và nghiên cứu ở bậc Tiến sĩ tại Đại học John Hopkins, Mỹ với chuyên ngành Kỹ thuật Điện và Máy tính. Trở lại Việt Nam, anh đã làm việc tại rất nhiều công ty uy tín như Vantix/VinGroup, Axon Enterprise, Fossil Group hay Misfit Wearables.
Đ𝒂̣̆𝒏𝒈 𝑽𝒂̆𝒏 𝑸𝒖𝒂̂𝒏: Kỹ sư về học máy, có kinh nghiệm về phát triển các hệ thống MLOps trong doanh nghiệp lớn như Heligate, One Mount, Yokogawa Singapore và MSB. Năm 2021, anh đồng sáng lập cộng đồng MLOpsVN, một diễn đàn để chia sẻ, thảo luận và đào tạo về cách thức xây dựng các hệ thống học máy cho 6.000 thành viên.
𝑯𝒂̆̀𝒏𝒈 𝑫𝒖̛𝒐̛𝒏𝒈: Solutions Architect tại Amazon Web Services Vietnam. Chị chuyên sâu trong lĩnh vực trí tuệ nhân tạo và học máy. Chị cũng là cựu Management Associate tại Techcombank và tốt nghiệp xuất sắc khoa Khoa học máy tính tại Đại học Công nghệ với nhiều thành tích và giải thưởng.
𝑵𝒈𝒖𝒚𝒆̂̃𝒏 𝑲𝒉𝒂́𝒏𝒉 𝑳𝒊𝒏𝒉: Head of Machine Learning Platform & MLOps của Techcombank. Chị tốt nghiệp NUS (học bổng chính phủ) và từng làm việc với nhiều tập đoàn công nghệ hàng đầu như IBM, A*STAR, Shopee Singapore, Mediacorp, Continental... Với 2 bằng sáng chế và 3 bài báo khoa học về NLP, Data và sức khoẻ tâm lí, chị Linh sáng lập tổ chức phi lợi nhuận về sức khoẻ tâm lí Beautiful Mind Vietnam.
✨ MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội. Khi tham dự các bạn sẽ có cơ hội nhận được nhiều phần quà hấp dẫn đến từ FPT, và còn cả free food cho chúng ta nữa. Nếu các bạn không thể tham gia offline, chúng ta có thể giam gia online thông qua fanpage chính của MLOps nhé.
📆 Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023
📍 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội và sẽ phát live trên Fanpage Facebook của MLOpsVN
👉 Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J
___________________________________________________
👉 Thông tin chi tiết tại: https://mlops.vn/marathon
📌 Cập nhật sự kiện tại:
🌐 MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/
🌐 MLOps VN Group | https://www.facebook.com/groups/mlopsvn
🌐 MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
🌐 MLOps VN Discord |  https://discord.gg/JNbQpba9Ae
🌐 MLOps VN Youtube | https://www.youtube.com/@mlopsvn","GIỚI THIỆU DÀN DIỄN GIẢ CHẤT PHÁT NGẤT CỦA MLOPS MARATHON TẠI LAUNCHING EVENT 12/05 : Giảng viên tại trường Đại học Quốc gia Ireland ở Cork, chuyên về lĩnh vực Trí tuệ Nhân tạo (AI) và MLOps. Các nghiên cứu của anh đã được đăng tải trong nhiều hội nghị và tạp chí nổi tiếng, bao gồm AAAI Conference on Artificial Intelligence (AAAI), ACM Multimedia (ACM MM), và Health and Quality of Life Outcomes. Ngoài ra, anh Harry cũng là chủ tịch của nhiều cuộc thi và sự kiện AI/ML, chẳng hạn như cuộc thi reliable intelligence on social media, AI for COVID-19 detection và MLOps challenges. ̃ ̂ ̛: nghiên cứu viên cao cấp của chương trình WASP Media & Language tại Đại học Umeå (Thụy Điển), trưởng nhóm phát triển AI/ML tại công ty Devr INC. Anh tập trung vào các công nghệ bảo vệ quyền riêng tư trong học máy và có nhiều công bố khoa học được đánh giá xuất sắc tại các hội nghị AI quốc tế. Anh là đồng sáng lập của một số dự án cộng đồng như AIcovidVN, AIHUB.ML, MLOpsVN. ̂̃ ̣ ̃: AI Lab Manager, AI Center, FPT Software. Sau khi tốt nghiệp Đại học Bách khoa Hà Nội, anh Trọng Dũng tiếp tục học và nghiên cứu ở bậc Tiến sĩ tại Đại học John Hopkins, Mỹ với chuyên ngành Kỹ thuật Điện và Máy tính. Trở lại Việt Nam, anh đã làm việc tại rất nhiều công ty uy tín như Vantix/VinGroup, Axon Enterprise, Fossil Group hay Misfit Wearables. Đ̣̆ ̆ ̂: Kỹ sư về học máy, có kinh nghiệm về phát triển các hệ thống MLOps trong doanh nghiệp lớn như Heligate, One Mount, Yokogawa Singapore và MSB. Năm 2021, anh đồng sáng lập cộng đồng MLOpsVN, một diễn đàn để chia sẻ, thảo luận và đào tạo về cách thức xây dựng các hệ thống học máy cho 6.000 thành viên. ̆̀ ̛̛: Solutions Architect tại Amazon Web Services Vietnam. Chị chuyên sâu trong lĩnh vực trí tuệ nhân tạo và học máy. Chị cũng là cựu Management Associate tại Techcombank và tốt nghiệp xuất sắc khoa Khoa học máy tính tại Đại học Công nghệ với nhiều thành tích và giải thưởng. ̂̃ ́ : Head of Machine Learning Platform & MLOps của Techcombank. Chị tốt nghiệp NUS (học bổng chính phủ) và từng làm việc với nhiều tập đoàn công nghệ hàng đầu như IBM, A*STAR, Shopee Singapore, Mediacorp, Continental... Với 2 bằng sáng chế và 3 bài báo khoa học về NLP, Data và sức khoẻ tâm lí, chị Linh sáng lập tổ chức phi lợi nhuận về sức khoẻ tâm lí Beautiful Mind Vietnam. MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội. Khi tham dự các bạn sẽ có cơ hội nhận được nhiều phần quà hấp dẫn đến từ FPT, và còn cả free food cho chúng ta nữa. Nếu các bạn không thể tham gia offline, chúng ta có thể giam gia online thông qua fanpage chính của MLOps nhé. Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội và sẽ phát live trên Fanpage Facebook của MLOpsVN Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"Giảm 90% chi phí hạ tầng cho audio/video monitoring service tại Prime Video
Team Video Quality Analysis (VQA) tại Prime Video vừa quyết định gom đống AWS Lambda (orchestrate thông qua AWS StepFunction) lại do chi phí của việc chuyển state và dữ liệu giữa các step quá cao thành một service duy nhất (mà theo Prime Video Tech gọi là kiến trúc monolith), và dùng ECS (EC2 launch type) để scale ngang. 
Cách mới này cũng giúp team tận dụng được EC2 saving plans tiết kiệm thêm ít tiền để trang trải cuộc sống.
Có điều bài blog này cũng gây tranh cãi về kiến trúc mới này có thực sự là monolith hay là macroservice, khi mà các ứng dụng của VQA chỉ là một phần nhỏ trong rất nhiều service của Prime Video? 🧐
Nhân tiện nhắc tới EC2, mọi người đăng ký MLOps Marathon để được dùng EC2 miễn phí nha 💻 https://g2.by/Cq4J 
https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90
#infra #costoptimization","Giảm 90% chi phí hạ tầng cho audio/video monitoring service tại Prime Video Team Video Quality Analysis (VQA) tại Prime Video vừa quyết định gom đống AWS Lambda (orchestrate thông qua AWS StepFunction) lại do chi phí của việc chuyển state và dữ liệu giữa các step quá cao thành một service duy nhất (mà theo Prime Video Tech gọi là kiến trúc monolith), và dùng ECS (EC2 launch type) để scale ngang. Cách mới này cũng giúp team tận dụng được EC2 saving plans tiết kiệm thêm ít tiền để trang trải cuộc sống. Có điều bài blog này cũng gây tranh cãi về kiến trúc mới này có thực sự là monolith hay là macroservice, khi mà các ứng dụng của VQA chỉ là một phần nhỏ trong rất nhiều service của Prime Video? Nhân tiện nhắc tới EC2, mọi người đăng ký MLOps Marathon để được dùng EC2 miễn phí nha https://g2.by/Cq4J https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90",#infra	#costoptimization,
"MLOPS MARATHON Q&A
Hi cả nhà, thời gian vừa qua em nhận được rất nhiều câu hỏi về MLOps Marathon, nên xin phép được tóm tắt lại mấy ý như sau, (chi tiết sẽ được tiết lộ khi cuộc thi bắt đầu): 
Nội dung cuộc thi: tối ưu model metrics và API performance (ví dụ: latency và RPS) trên môi trường production (trên máy ảo BTC cung cấp). Mọi người sẽ vẫn được cung cấp tập data để tự chia train-val-test, tuy nhiên score cho model metrics sẽ được tính trên dữ liệu thực tế (private test set chỉ BTC biết). Dữ liệu thực tế này có dạng bảng, và có thể bị drift. 
Đối tượng cuộc thi: không giới hạn, chỉ cần có kinh nghiệm lập trình. 
Đội chơi: từ 1 đến 5 người 1 đội, bạn nào muốn ghép thêm với bạn software engineer hoặc data scientist thì BTC có thể sắp xếp giúp sau. 
Thời gian thi: diễn ra từ 5/6 đến hết 28/8, với 3 phase với tỉ lệ điểm là 5% - 25% - 70%. Phase 1 nhằm mục đích giúp các đội làm quen môi trường và luật thi là chủ yếu, và thời gian này các đội thi có thể tham gia các buổi training từ phía BTC. 
Link đăng ký tham gia: https://g2.by/Cq4J
Kênh hỗ trợ giải đáp thắc mắc thể lệ cuộc thi: https://discord.gg/gfUU5HQRaX

#marathon #qna ","MLOPS MARATHON Q&A Hi cả nhà, thời gian vừa qua em nhận được rất nhiều câu hỏi về MLOps Marathon, nên xin phép được tóm tắt lại mấy ý như sau, (chi tiết sẽ được tiết lộ khi cuộc thi bắt đầu): Nội dung cuộc thi: tối ưu model metrics và API performance (ví dụ: latency và RPS) trên môi trường production (trên máy ảo BTC cung cấp). Mọi người sẽ vẫn được cung cấp tập data để tự chia train-val-test, tuy nhiên score cho model metrics sẽ được tính trên dữ liệu thực tế (private test set chỉ BTC biết). Dữ liệu thực tế này có dạng bảng, và có thể bị drift. Đối tượng cuộc thi: không giới hạn, chỉ cần có kinh nghiệm lập trình. Đội chơi: từ 1 đến 5 người 1 đội, bạn nào muốn ghép thêm với bạn software engineer hoặc data scientist thì BTC có thể sắp xếp giúp sau. Thời gian thi: diễn ra từ 5/6 đến hết 28/8, với 3 phase với tỉ lệ điểm là 5% - 25% - 70%. Phase 1 nhằm mục đích giúp các đội làm quen môi trường và luật thi là chủ yếu, và thời gian này các đội thi có thể tham gia các buổi training từ phía BTC. Link đăng ký tham gia: https://g2.by/Cq4J Kênh hỗ trợ giải đáp thắc mắc thể lệ cuộc thi: https://discord.gg/gfUU5HQRaX",#marathon	#qna,
"🎉ĐÓN CHỜ SỰ XUẤT HIỆN CỦA DR. HARRY NGUYEN - CHUYÊN GIA HÀNG ĐẦU VỀ TRÍ TUỆ NHÂN TẠO VÀ MLOPS TẠI MLOPS MARATHON LAUNCHING EVENT🎉
👉 Đăng ký tham gia sự kiện tại: https://g2.by/Cq4J
Dr. Harry Nguyen đang là giảng viên tại trường Đại học Quốc gia Ireland ở Cork, chuyên về lĩnh vực Trí tuệ Nhân tạo (AI) và MLOps. Với nhiều năm kinh nghiệm và thành tích nghiên cứu, Dr. Nguyen đã tham gia nhiều dự án lớn để phát triển trí tuệ nhân tạo đáng tin cậy cho các mục tiêu phát triển bền vững. Các nghiên cứu của anh đã được đăng tải trong nhiều hội nghị và tạp chí nổi tiếng, bao gồm AAAI Conference on Artificial Intelligence (AAAI), ACM Multimedia (ACM MM), và Health and Quality of Life Outcomes.
Ngoài ra, anh Harry cũng là chủ tịch của nhiều cuộc thi và sự kiện AI/ML, chẳng hạn như cuộc thi reliable intelligence on social media, AI for COVID-19 detection và MLOps challenges. Những đóng góp của anh đã được ghi nhận và trao nhiều giải thưởng danh giá, bao gồm Herbert A. Simon's design research award, IMDA Open Innovation và NUS Innovation & Entrepreneurship Practicum.
Hãy đăng ký tham gia sự kiện MLOps Marathon Launching Event để cùng anh Harry và các diễn giả khác chia sẻ kiến thức và kinh nghiệm, cập nhật những xu hướng mới nhất của lĩnh vực AI và MLOps.
✨ MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội vào tháng 5 này
📆 Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023
📍 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội và sẽ phát live trên Fanpage Facebook của MLOpsVN
👉 Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J
___________________________________________________
👉 Thông tin chi tiết tại: https://mlops.vn/marathon
📌 Cập nhật sự kiện tại:
🌐 MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/
🌐 MLOps VN Group | https://www.facebook.com/groups/mlopsvn
🌐 MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
🌐 MLOps VN Discord |  https://discord.gg/JNbQpba9Ae
🌐 MLOps VN Youtube | https://www.youtube.com/@mlopsvn","ĐÓN CHỜ SỰ XUẤT HIỆN CỦA DR. HARRY NGUYEN - CHUYÊN GIA HÀNG ĐẦU VỀ TRÍ TUỆ NHÂN TẠO VÀ MLOPS TẠI MLOPS MARATHON LAUNCHING EVENT Đăng ký tham gia sự kiện tại: https://g2.by/Cq4J Dr. Harry Nguyen đang là giảng viên tại trường Đại học Quốc gia Ireland ở Cork, chuyên về lĩnh vực Trí tuệ Nhân tạo (AI) và MLOps. Với nhiều năm kinh nghiệm và thành tích nghiên cứu, Dr. Nguyen đã tham gia nhiều dự án lớn để phát triển trí tuệ nhân tạo đáng tin cậy cho các mục tiêu phát triển bền vững. Các nghiên cứu của anh đã được đăng tải trong nhiều hội nghị và tạp chí nổi tiếng, bao gồm AAAI Conference on Artificial Intelligence (AAAI), ACM Multimedia (ACM MM), và Health and Quality of Life Outcomes. Ngoài ra, anh Harry cũng là chủ tịch của nhiều cuộc thi và sự kiện AI/ML, chẳng hạn như cuộc thi reliable intelligence on social media, AI for COVID-19 detection và MLOps challenges. Những đóng góp của anh đã được ghi nhận và trao nhiều giải thưởng danh giá, bao gồm Herbert A. Simon's design research award, IMDA Open Innovation và NUS Innovation & Entrepreneurship Practicum. Hãy đăng ký tham gia sự kiện MLOps Marathon Launching Event để cùng anh Harry và các diễn giả khác chia sẻ kiến thức và kinh nghiệm, cập nhật những xu hướng mới nhất của lĩnh vực AI và MLOps. MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội vào tháng 5 này Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội và sẽ phát live trên Fanpage Facebook của MLOpsVN Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"Giới thiệu cho các bác dùng VSCode draw.io extension giúp sửa file draw.io offline, đồng thời cho phép collaboratively edit (khó dịch từ này quá 😅) luôn.
https://marketplace.visualstudio.com/items?itemName=hediet.vscode-drawio
#vscode #tips","Giới thiệu cho các bác dùng VSCode draw.io extension giúp sửa file draw.io offline, đồng thời cho phép collaboratively edit (khó dịch từ này quá ) luôn. https://marketplace.visualstudio.com/items?itemName=hediet.vscode-drawio",#vscode	#tips,
"🥇MLOps MARATHON 2023 - SÂN CHƠI MLOPS ĐẦU TIÊN TẠI VN VỚI GIÁ TRỊ GIẢI THƯỞNG LÊN ĐẾN 9-CHỮ-SỐ 🥇
💯Tham gia Challenge, các thí sinh có cơ hội trình diễn kỹ năng lập trình của mình, xử lý tình huống bám sát theo các vấn đề hay gặp của doanh nghiệp khi triển khai một dự án AI ra thị trường. Làm việc cùng đồng đội trong những bài thi chắc chắn sẽ đem lại cho bạn những khoảnh khắc hồi hộp nhưng không kém phần hào hứng! Các thí sinh, đây chính là lúc để nhiệt huyết của bạn trỗi dậy!
💰Không chỉ vậy, đang chờ bạn ở vạch đích Challenge là những phần quà vô cùng hấp dẫn với giải nhất trị giá 100 TRIỆU ĐỒNG!
🤟Chúc tất cả các thí sinh dự thi có thể bình tĩnh, tự tin, chiến thắng  Đặt lịch hẹn, chuẩn bị một tâm hồn thật đẹp, tham gia đúng giờ và đi đến cuối cùng để rinh về cho mình những phần quà tuyệt vời nhất!
✨ MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội vào tháng 5 này
📆 Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023
📍 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội
👉 Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J
___________________________________________________
Thông tin chi tiết tại: https://mlops.vn/marathon
Cập nhật sự kiện tại:
🌐MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/
🌐MLOps VN Group | https://www.facebook.com/groups/mlopsvn
🌐MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
🌐MLOps VN Discord |  https://discord.gg/JNbQpba9Ae
🌐MLOps VN Youtube | https://www.youtube.com/@mlopsvn","MLOps MARATHON 2023 - SÂN CHƠI MLOPS ĐẦU TIÊN TẠI VN VỚI GIÁ TRỊ GIẢI THƯỞNG LÊN ĐẾN 9-CHỮ-SỐ Tham gia Challenge, các thí sinh có cơ hội trình diễn kỹ năng lập trình của mình, xử lý tình huống bám sát theo các vấn đề hay gặp của doanh nghiệp khi triển khai một dự án AI ra thị trường. Làm việc cùng đồng đội trong những bài thi chắc chắn sẽ đem lại cho bạn những khoảnh khắc hồi hộp nhưng không kém phần hào hứng! Các thí sinh, đây chính là lúc để nhiệt huyết của bạn trỗi dậy! Không chỉ vậy, đang chờ bạn ở vạch đích Challenge là những phần quà vô cùng hấp dẫn với giải nhất trị giá 100 TRIỆU ĐỒNG! Chúc tất cả các thí sinh dự thi có thể bình tĩnh, tự tin, chiến thắng Đặt lịch hẹn, chuẩn bị một tâm hồn thật đẹp, tham gia đúng giờ và đi đến cuối cùng để rinh về cho mình những phần quà tuyệt vời nhất! MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội vào tháng 5 này Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"📢""HOT NEWS"": SỰ KIỆN MLOPS MARATHON LAUNCHING HÉ LỘ THÔNG TIN VỀ DIỄN GIẢ VÔ CÙNG ẤN TƯỢNG!🤖
👉 Tham gia MLOps Marathon launching event tại: https://g2.by/Cq4J
Chuỗi sự kiện MLOPS MARATHON LAUNCHING sắp diễn ra và chúng tôi vô cùng phấn khích khi được giới thiệu với mọi người về một trong những diễn giả đặc biệt của sự kiện - anh Nguyễn Trọng Dũng, AI Lab Manager, AI Center, FPT Software
Sau khi tốt nghiệp Đại học Bách khoa Hà Nội, anh Trọng Dũng tiếp tục học và nghiên cứu ở bậc Tiến sĩ tại Đại học John Hopkins, Mỹ với chuyên ngành Kỹ thuật Điện và Máy tính. Trở lại Việt Nam, anh đã làm việc tại rất nhiều công ty uy tín như Vantix/VinGroup, Axon Enterprise, Fossil Group hay Misfit Wearables.
Với hiểu biết sâu rộng về AI và Machine Learning, anh Dũng sẽ giúp các bạn khai thác tiềm năng AI của bản thân với một tầm nhìn mới!
Đừng quên đăng ký tham dự sự kiện để không bỏ lỡ cơ hội gặp gỡ và trò chuyện với anh Dũng và những diễn giả tuyệt vời khác nhé! 🎉
✨ MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội vào tháng 5 này
📆 Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023
📍 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội
👉 Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J
___________________________________________________
👉 Thông tin chi tiết tại: https://mlops.vn/marathon
📌 Cập nhật sự kiện tại:
🌐 MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/
🌐 MLOps VN Group | https://www.facebook.com/groups/mlopsvn
🌐 MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
🌐 MLOps VN Discord |  https://discord.gg/JNbQpba9Ae
🌐 MLOps VN Youtube | https://www.youtube.com/@mlopsvn","""HOT NEWS"": SỰ KIỆN MLOPS MARATHON LAUNCHING HÉ LỘ THÔNG TIN VỀ DIỄN GIẢ VÔ CÙNG ẤN TƯỢNG! Tham gia MLOps Marathon launching event tại: https://g2.by/Cq4J Chuỗi sự kiện MLOPS MARATHON LAUNCHING sắp diễn ra và chúng tôi vô cùng phấn khích khi được giới thiệu với mọi người về một trong những diễn giả đặc biệt của sự kiện - anh Nguyễn Trọng Dũng, AI Lab Manager, AI Center, FPT Software Sau khi tốt nghiệp Đại học Bách khoa Hà Nội, anh Trọng Dũng tiếp tục học và nghiên cứu ở bậc Tiến sĩ tại Đại học John Hopkins, Mỹ với chuyên ngành Kỹ thuật Điện và Máy tính. Trở lại Việt Nam, anh đã làm việc tại rất nhiều công ty uy tín như Vantix/VinGroup, Axon Enterprise, Fossil Group hay Misfit Wearables. Với hiểu biết sâu rộng về AI và Machine Learning, anh Dũng sẽ giúp các bạn khai thác tiềm năng AI của bản thân với một tầm nhìn mới! Đừng quên đăng ký tham dự sự kiện để không bỏ lỡ cơ hội gặp gỡ và trò chuyện với anh Dũng và những diễn giả tuyệt vời khác nhé! MLOps Marathon sẽ tổ chức sự kiện offline tại Hà Nội vào tháng 5 này Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau: https://g2.by/Cq4J ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"Tọa đàm khác tổ chức bởi tạp chí Tia Sáng vào chủ nhật tới (7/5) với diễn giả là GS. Nguyễn Tiến Dũng (ĐH Toulouse), đồng sáng lập Torus AI cho anh em nào quan tâm 😁.
Nội dung chính:
AI sẽ tạo ra các thay đổi như thế nào đến kinh tế xã hội?
Việt Nam có thể đầu tư cho AI như thế nào với nguồn lực hiện nay?
Nguy cơ tụt hậu nếu không đầu tư cho hệ sinh thái AI?
Các công ty SME có thể ưu tiên xu hướng nào trong nghiên cứu và phát triển AI trong bối cảnh các big tech có quá nhiều lợi thế?
Ngoài ra, GS. Dũng cũng sẽ trả lời các câu hỏi liên quan khác về việc phát triển các ứng dụng AI xử lý tự động các thông tin, tín hiệu và hình ảnh trong nhiều lĩnh vực.
#seminar #offline","Tọa đàm khác tổ chức bởi tạp chí Tia Sáng vào chủ nhật tới (7/5) với diễn giả là GS. Nguyễn Tiến Dũng (ĐH Toulouse), đồng sáng lập Torus AI cho anh em nào quan tâm . Nội dung chính: AI sẽ tạo ra các thay đổi như thế nào đến kinh tế xã hội? Việt Nam có thể đầu tư cho AI như thế nào với nguồn lực hiện nay? Nguy cơ tụt hậu nếu không đầu tư cho hệ sinh thái AI? Các công ty SME có thể ưu tiên xu hướng nào trong nghiên cứu và phát triển AI trong bối cảnh các big tech có quá nhiều lợi thế? Ngoài ra, GS. Dũng cũng sẽ trả lời các câu hỏi liên quan khác về việc phát triển các ứng dụng AI xử lý tự động các thông tin, tín hiệu và hình ảnh trong nhiều lĩnh vực.",#seminar	#offline,
"MOJO ra mắt Inference Engine giúp giảm latency và giảm cost cho các model có sẵn chỉ với một vài câu lệnh (https://docs.modular.com/engine/python/python-demo.html), và MOJO language với syntax tương tự Python nhưng performance lại giống C++ và Rust (https://docs.modular.com/mojo/programming-manual.html), cơ mà hiện tại chưa cài được ở local mà mới chỉ có thể Request for Early Program để dùng trên cloud :v chắc phải gọi vốn xong cái đã mới release bản cài local cho chắc. Ae nào dùng thử chưa nhỉ?
#mojo #rust","MOJO ra mắt Inference Engine giúp giảm latency và giảm cost cho các model có sẵn chỉ với một vài câu lệnh (https://docs.modular.com/engine/python/python-demo.html), và MOJO language với syntax tương tự Python nhưng performance lại giống C++ và Rust (https://docs.modular.com/mojo/programming-manual.html), cơ mà hiện tại chưa cài được ở local mà mới chỉ có thể Request for Early Program để dùng trên cloud :v chắc phải gọi vốn xong cái đã mới release bản cài local cho chắc. Ae nào dùng thử chưa nhỉ?",#mojo	#rust,
"Scalable Distributed Systems - Final

Hôm nay mình đi ăn trưa với sếp, sếp kể chuyện đang phỏng vấn vài bạn muốn nhảy từ vị trí làm ML models vào team ML Platform của sếp, nhưng các kĩ năng của các bạn ấy chưa phù hợp lắm. Sếp nhấn mạnh ngoài các backend coding skills như software architecture, concurrency, thì vị trí này trong team mình đòi hỏi phải hiểu sâu về Kubernetes (k8s).

Các phần trong series Scalable Distributed Systems mình viết không nói về Kubernetes, nhưng khá đầy đủ các kiến thức nền tảng về scaling distributed systems, giúp các bạn dễ tiếp cận hơn với lý do đằng sau các design của k8s, từ đó các bạn có thể hiểu rất sâu về nó, ví dụ:
- 1 k8s deployment có thể quản lý rất nhiều replicas, hay chính là 1 trong 2 nguyên tắc scaling cơ bản nhất
- 1 k8s service đóng vai trò là 1 Load balancer đơn giản, giúp cho việc chia traffic tới các replicas rất tiện lợi

Trong team hiện tại, mình làm việc với MySQL, Redis và etcd là chủ yếu. Hiếm khi nào mình cần phải nghĩ tới việc shard data để scale systems, nhưng việc dùng read replicas là rất phổ biến, mặc định khi team data tạo database là tạo luôn 2 read replicas và 1 write replica. Phần cuối này trong series sẽ giúp các bạn hiểu về cách scaling relational databases bằng read replicas và partitioning data, cũng như scaling non-relational databases.

Trong việc coding hàng ngày, mình sử dụng distributed transactions thường xuyên, cho cả relational và non-relational databases, nhưng không cần implement nó, vì các databases đã cung cấp sẵn functions rồi. Trong phần cuối này, mình cũng sẽ nói về distributed transactions, 2 loại consistency quan trọng nhất trong database là eventual consistency, strong consistency, cách tune consistency để cân bằng các trade-offs, và cách xử lý conflicts của các concurrent writes.

Ngoài ra, trong quá trình code, concurrency programming skills được dùng rất nhiều. Deadlock giờ các lib hỗ trợ việc phát hiện hết rồi nên là không cần nghĩ nhiều lắm, nhưng trong các test cases ở các projects mình làm vẫn phải có deadlock tests, do đó cần phải hiểu nó và hiểu hệ thống thì mới design được các test cases đó. Series này mình không nói về concurrency nhiều, vì các bạn có thể dễ dàng tìm thấy trên internet. Tuy nhiên, trong bài cuối cùng của series, mình có chia sẻ các câu hỏi interview trong thực tế mà mình gặp, liên quan tới concurrency và databases để các bạn luyện tập các kiến thức học được từ series.

Cuối cùng, cảm ơn cả nhà đã ủng hộ series Scalable Distributed Systems. Hy vọng các kiến thức trong series có thể hỗ trợ được một chút cho công việc của các bạn, và có thể là cho cuộc thi MLOps Marathon sắp tới của team MLOpsVN. MLOps Marathon một cuộc thi đòi hỏi cả kĩ năng phát triển ML models và các kĩ năng trong distributed systems, thích hợp với các bạn dù mới hay đã có kinh nghiệm vài năm trong cái ngành AI/ML này.

* Link phần cuối: https://aiengineer.net/ml-skills/scalable-distributed-systems/scalable-databases
* Ảnh minh họa: Hủ tiếu khô ở Cao Lãnh, Đồng Tháp","Scalable Distributed Systems - Final Hôm nay mình đi ăn trưa với sếp, sếp kể chuyện đang phỏng vấn vài bạn muốn nhảy từ vị trí làm ML models vào team ML Platform của sếp, nhưng các kĩ năng của các bạn ấy chưa phù hợp lắm. Sếp nhấn mạnh ngoài các backend coding skills như software architecture, concurrency, thì vị trí này trong team mình đòi hỏi phải hiểu sâu về Kubernetes (k8s). Các phần trong series Scalable Distributed Systems mình viết không nói về Kubernetes, nhưng khá đầy đủ các kiến thức nền tảng về scaling distributed systems, giúp các bạn dễ tiếp cận hơn với lý do đằng sau các design của k8s, từ đó các bạn có thể hiểu rất sâu về nó, ví dụ: - 1 k8s deployment có thể quản lý rất nhiều replicas, hay chính là 1 trong 2 nguyên tắc scaling cơ bản nhất - 1 k8s service đóng vai trò là 1 Load balancer đơn giản, giúp cho việc chia traffic tới các replicas rất tiện lợi Trong team hiện tại, mình làm việc với MySQL, Redis và etcd là chủ yếu. Hiếm khi nào mình cần phải nghĩ tới việc shard data để scale systems, nhưng việc dùng read replicas là rất phổ biến, mặc định khi team data tạo database là tạo luôn 2 read replicas và 1 write replica. Phần cuối này trong series sẽ giúp các bạn hiểu về cách scaling relational databases bằng read replicas và partitioning data, cũng như scaling non-relational databases. Trong việc coding hàng ngày, mình sử dụng distributed transactions thường xuyên, cho cả relational và non-relational databases, nhưng không cần implement nó, vì các databases đã cung cấp sẵn functions rồi. Trong phần cuối này, mình cũng sẽ nói về distributed transactions, 2 loại consistency quan trọng nhất trong database là eventual consistency, strong consistency, cách tune consistency để cân bằng các trade-offs, và cách xử lý conflicts của các concurrent writes. Ngoài ra, trong quá trình code, concurrency programming skills được dùng rất nhiều. Deadlock giờ các lib hỗ trợ việc phát hiện hết rồi nên là không cần nghĩ nhiều lắm, nhưng trong các test cases ở các projects mình làm vẫn phải có deadlock tests, do đó cần phải hiểu nó và hiểu hệ thống thì mới design được các test cases đó. Series này mình không nói về concurrency nhiều, vì các bạn có thể dễ dàng tìm thấy trên internet. Tuy nhiên, trong bài cuối cùng của series, mình có chia sẻ các câu hỏi interview trong thực tế mà mình gặp, liên quan tới concurrency và databases để các bạn luyện tập các kiến thức học được từ series. Cuối cùng, cảm ơn cả nhà đã ủng hộ series Scalable Distributed Systems. Hy vọng các kiến thức trong series có thể hỗ trợ được một chút cho công việc của các bạn, và có thể là cho cuộc thi MLOps Marathon sắp tới của team MLOpsVN. MLOps Marathon một cuộc thi đòi hỏi cả kĩ năng phát triển ML models và các kĩ năng trong distributed systems, thích hợp với các bạn dù mới hay đã có kinh nghiệm vài năm trong cái ngành AI/ML này. * Link phần cuối: https://aiengineer.net/ml-skills/scalable-distributed-systems/scalable-databases * Ảnh minh họa: Hủ tiếu khô ở Cao Lãnh, Đồng Tháp",,
"Tutorial xây dựng voice bot với 3 services chính là speech-to-text, text-to-response (sử dụng OpenAI API) và text-to-speech cho ae nào muốn ghi LLM project vào CV 🤣.
Công nghệ sử dụng: BentoML, LangChain, FastAPI và GradioUI 
https://towardsdatascience.com/deploy-a-voice-based-chatbot-with-bentoml-langchain-and-gradio-7f25af3e45df
LLM hay thật, nhưng Search cũng hay không kém, mọi người nhanh tay đăng ký seminar Search và cách sử dụng ElasticSearch vào ngày mai tại đây nha 🥹 https://bom.so/vysc5a
#llm #llmops #bentoml #search","Tutorial xây dựng voice bot với 3 services chính là speech-to-text, text-to-response (sử dụng OpenAI API) và text-to-speech cho ae nào muốn ghi LLM project vào CV . Công nghệ sử dụng: BentoML, LangChain, FastAPI và GradioUI https://towardsdatascience.com/deploy-a-voice-based-chatbot-with-bentoml-langchain-and-gradio-7f25af3e45df LLM hay thật, nhưng Search cũng hay không kém, mọi người nhanh tay đăng ký seminar Search và cách sử dụng ElasticSearch vào ngày mai tại đây nha https://bom.so/vysc5a",#llm	#llmops	#bentoml	#search,
"Tiếp nối seminar ""Behind a Spotify's Search"" của anh Cuong Dao, tối thứ 5 tuần này chúng ta sẽ tìm hiểu sâu thêm về công nghệ search và Elastic Search cùng với speaker Đinh Văn Quý đến từ Chope Singapore.
Mọi người nhanh tay đăng ký và gửi các câu hỏi về cho diễn giả thôi nào :D. Vẫn như lần trước sẽ có record, nhưng mà thỉnh thoảng có sự cố nên không record được hoặc chỉ record được một phần, nên mọi người cố gắng join nhé ạ.
Chúc cả nhà buổi tối tốt lành!
#seminar #webinar #search #elasticsearch","Tiếp nối seminar ""Behind a Spotify's Search"" của anh Cuong Dao, tối thứ 5 tuần này chúng ta sẽ tìm hiểu sâu thêm về công nghệ search và Elastic Search cùng với speaker Đinh Văn Quý đến từ Chope Singapore. Mọi người nhanh tay đăng ký và gửi các câu hỏi về cho diễn giả thôi nào :D. Vẫn như lần trước sẽ có record, nhưng mà thỉnh thoảng có sự cố nên không record được hoặc chỉ record được một phần, nên mọi người cố gắng join nhé ạ. Chúc cả nhà buổi tối tốt lành!",#seminar	#webinar	#search	#elasticsearch,
"Tranh thủ ngày lễ cập nhật công nghệ thôi cả nhà
https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/
#chatgpt #llm #llmops",Tranh thủ ngày lễ cập nhật công nghệ thôi cả nhà https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/,#chatgpt	#llm	#llmops,
"Sử dụng Gitlab làm backend cho MLFlow client 
Tin vui cho ae nào đang dùng Gitlab là đã có thể lưu thông tin các experiment vào Gitlab thông qua MLFlow client, cách này cũng làm ae bớt suy nghĩ làm sao để thực hiện authentication cho MLFlow luôn http://docs.gitlab.com/ee/user/project/ml/experiment_tracking/
tuy nhiên, hiện tại đang có một hạn chế là chưa hỗ trợ tính năng model registry của MLFlow như đề cập ở đây
https://docs.gitlab.com/ee/user/project/integrations/mlflow_client.html
#mlflow #gitlab #integrations","Sử dụng Gitlab làm backend cho MLFlow client Tin vui cho ae nào đang dùng Gitlab là đã có thể lưu thông tin các experiment vào Gitlab thông qua MLFlow client, cách này cũng làm ae bớt suy nghĩ làm sao để thực hiện authentication cho MLFlow luôn http://docs.gitlab.com/ee/user/project/ml/experiment_tracking/ tuy nhiên, hiện tại đang có một hạn chế là chưa hỗ trợ tính năng model registry của MLFlow như đề cập ở đây https://docs.gitlab.com/ee/user/project/integrations/mlflow_client.html",#mlflow	#gitlab	#integrations,
"Giảm thiểu thời gian xử lý từ 65s xuống 0.04s cho phép chia 2 cột trong 1 pandas.DataFrame 10 triệu dòng (element-wise)
#quicktips #optimization #tips",Giảm thiểu thời gian xử lý từ 65s xuống 0.04s cho phép chia 2 cột trong 1 pandas.DataFrame 10 triệu dòng (element-wise),#quicktips	#optimization	#tips,
"🎉🎉🎉SỰ KIỆN RA MẮT CUỘC THI MLOps MARATHON SẼ ĐƯỢC TỔ CHỨC TẠI FPT SOFTWARE HOÀ LẠC🎉🎉🎉

💌 Ngày hội cộng nghệ sôi động đầu năm MLOps MARATHON 2023 đã chính thức chọn Trụ sở FPT Software, tại Khu công nghệ cao Hoà Lạc làm nơi diễn ra sự kiện ra mắt offline và sẽ được phát trực tiếp đến mọi miền tổ quốc!

🤖 MLOps MARATHON 2023 là một sự kiện công nghệ đột phá lần đầu tiên có mặt tại Việt Nam của cộng đồng Machine Learning với chủ đề chính là MLOps - một phương pháp mới trong việc triển khai và quản lý các hệ thống Machine Learning, với tổng giá trị giải thưởng đẫ lên đến TRĂM TRIỆU ĐỒNG!

💡 Sự kiện này sẽ mang đến cho bạn những trải nghiệm thú vị về MLOps, bao gồm các buổi diễn thuyết, workshop và các hoạt động giải trí khác với sự có mặt của các chuyên gia đầu ngành. Đây là cơ hội để bạn học hỏi và chia sẻ kinh nghiệm với những chuyên gia hàng đầu trong lĩnh vực này, cũng như tạo ra các mối quan hệ mới với những người có cùng đam mê.

💡 Các bạn tham gia còn được gặp mặt các nhà tuyển dụng đến từ các công ty hàng đầu trong lĩnh vực ML/ AI

📆 Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023
📍 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội

🎁 Đặc biệt, các bạn sẽ nhận được những phần quà thú vị khi đăng ký tham gia sớm nhất

👉 Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau https://docs.google.com/.../1FAIpQLSetvRJjGAWUw9.../viewform
___________________________________________________
Thông tin chi tiết tại: https://mlops.vn/marathon
Cập nhật sự kiện tại:
MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn
MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/
MLOps VN Discord | https://discord.gg/JNbQpba9Ae
MLOps VN Youtube | https://www.youtube.com/@mlopsvn","SỰ KIỆN RA MẮT CUỘC THI MLOps MARATHON SẼ ĐƯỢC TỔ CHỨC TẠI FPT SOFTWARE HOÀ LẠC Ngày hội cộng nghệ sôi động đầu năm MLOps MARATHON 2023 đã chính thức chọn Trụ sở FPT Software, tại Khu công nghệ cao Hoà Lạc làm nơi diễn ra sự kiện ra mắt offline và sẽ được phát trực tiếp đến mọi miền tổ quốc! MLOps MARATHON 2023 là một sự kiện công nghệ đột phá lần đầu tiên có mặt tại Việt Nam của cộng đồng Machine Learning với chủ đề chính là MLOps - một phương pháp mới trong việc triển khai và quản lý các hệ thống Machine Learning, với tổng giá trị giải thưởng đẫ lên đến TRĂM TRIỆU ĐỒNG! Sự kiện này sẽ mang đến cho bạn những trải nghiệm thú vị về MLOps, bao gồm các buổi diễn thuyết, workshop và các hoạt động giải trí khác với sự có mặt của các chuyên gia đầu ngành. Đây là cơ hội để bạn học hỏi và chia sẻ kinh nghiệm với những chuyên gia hàng đầu trong lĩnh vực này, cũng như tạo ra các mối quan hệ mới với những người có cùng đam mê. Các bạn tham gia còn được gặp mặt các nhà tuyển dụng đến từ các công ty hàng đầu trong lĩnh vực ML/ AI Thời gian: Từ 9h30 đến 12h, ngày 12/05/2023 Địa điểm: F-Ville 2, FPT Software, Khu Công nghệ cao Hòa Lạc, Km29 Đại lộ Thăng Long, Hà Nội Đặc biệt, các bạn sẽ nhận được những phần quà thú vị khi đăng ký tham gia sớm nhất Đừng bỏ lỡ cơ hội tuyệt vời này để tìm hiểu về MLOps và kết nối với cộng đồng công nghệ đầy nhiệt huyết. Đăng ký tham gia ngay tại đường link sau https://docs.google.com/.../1FAIpQLSetvRJjGAWUw9.../viewform ___________________________________________________ Thông tin chi tiết tại: https://mlops.vn/marathon Cập nhật sự kiện tại: MLOps VN Fanpage | https://www.facebook.com/MLOpsVN/ MLOps VN Group | https://www.facebook.com/groups/mlopsvn MLOps VN Linkedin | https://www.linkedin.com/company/mlopsvn/ MLOps VN Discord | https://discord.gg/JNbQpba9Ae MLOps VN Youtube | https://www.youtube.com/@mlopsvn",,
"4 patterns for deploying models at the edge
Chắc mọi người hay dùng cái pattern 1 nhỉ? 🤔
#edge #designpatterns
https://www.youtube.com/watch?app=desktop&v=6PHHLjiSkdg",4 patterns for deploying models at the edge Chắc mọi người hay dùng cái pattern 1 nhỉ? https://www.youtube.com/watch?app=desktop&v=6PHHLjiSkdg,#edge	#designpatterns,
"Xin cảm ơn bác Giang Hoang rất rất nhiều vì đã bỏ công sức chuẩn bị slide và chia sẻ siêu nhiệt tình về model optimization. Em xin gửi lại record cho mọi người không có điều kiện tham gia hoặc muốn xem lại.
Mọi người đừng quên thả tim hoặc comment để cảm ơn speaker nha 😊
#seminar #webinar #ModelOptimization",Xin cảm ơn bác Giang Hoang rất rất nhiều vì đã bỏ công sức chuẩn bị slide và chia sẻ siêu nhiệt tình về model optimization. Em xin gửi lại record cho mọi người không có điều kiện tham gia hoặc muốn xem lại. Mọi người đừng quên thả tim hoặc comment để cảm ơn speaker nha,#seminar	#webinar	#ModelOptimization,
,nan,,
"Join seminar Model Optimization thôi nào cả nhà 🏘
#seminar #webinar #modeloptimization",Join seminar Model Optimization thôi nào cả nhà,#seminar	#webinar	#modeloptimization,
"Seminar tiếp theo về Model Optimization, một chủ đề hay ho và là một phần rất quan trọng trong quá trình triển khai một hệ thống ML lên production. Mọi người nhanh tay đăng ký thôi nào 😁. Cả nhà cố gắng tham gia để speaker vui và BTC có thêm động lực mời các speaker khác nha ạ.
#seminar #webinar","Seminar tiếp theo về Model Optimization, một chủ đề hay ho và là một phần rất quan trọng trong quá trình triển khai một hệ thống ML lên production. Mọi người nhanh tay đăng ký thôi nào . Cả nhà cố gắng tham gia để speaker vui và BTC có thêm động lực mời các speaker khác nha ạ.",#seminar	#webinar,
"MLFlow bị dính lỗ hổng bảo mật nguy hiểm, ace đang dùng cập nhật lên bản mới nhất để vá nhé 🫣","MLFlow bị dính lỗ hổng bảo mật nguy hiểm, ace đang dùng cập nhật lên bản mới nhất để vá nhé",,
"Fork và Spawn trong Python Multiprocessing
import multiprocessing

with multiprocessing.Pool() as pool:
pool.map(plot_function, args)
Chăc hẳn mọi người không còn lạ lẫm gì với code snippet này để chạy nhiều process tính toán song song. Tuy nhiên, mọi người cần để ý một chút là khi chạy đoạn code này trong Windows và Linux sẽ khác nhau, do ở Windows và MacOS thì default start method là spawn, còn Linux là fork. 
Fork sẽ tạo bản sao các biến và các hàm trong main process để chạy, trong khi spawn thì bắt đầu process với một vùng nhớ hoàn toàn mới. Bên cạnh đó, spawn cũng không thể sử dụng global variable như fork do đó mọi người sẽ gặp lỗi nếu dùng global variable trong fork. Fork có vẻ như chiếm ưu thế hơn so với spawn do tận dụng được vùng nhớ đã được khợi tạo bởi main process, tuy nhiên lại dễ gây deadlock do không copy threads từ main process (https://pythonspeed.com/articles/python-multiprocessing/).
Mọi người đọc thêm về chủ đề hay ho này tại:
https://britishgeologicalsurvey.github.io/science/python-forking-vs-spawn/
https://stackoverflow.com/a/66113051
https://superfastpython.com/multiprocessing-inherit-global-variables-in-python/
#multiprocess","Fork và Spawn trong Python Multiprocessing import multiprocessing with multiprocessing.Pool() as pool: pool.map(plot_function, args) Chăc hẳn mọi người không còn lạ lẫm gì với code snippet này để chạy nhiều process tính toán song song. Tuy nhiên, mọi người cần để ý một chút là khi chạy đoạn code này trong Windows và Linux sẽ khác nhau, do ở Windows và MacOS thì default start method là spawn, còn Linux là fork. Fork sẽ tạo bản sao các biến và các hàm trong main process để chạy, trong khi spawn thì bắt đầu process với một vùng nhớ hoàn toàn mới. Bên cạnh đó, spawn cũng không thể sử dụng global variable như fork do đó mọi người sẽ gặp lỗi nếu dùng global variable trong fork. Fork có vẻ như chiếm ưu thế hơn so với spawn do tận dụng được vùng nhớ đã được khợi tạo bởi main process, tuy nhiên lại dễ gây deadlock do không copy threads từ main process (https://pythonspeed.com/articles/python-multiprocessing/). Mọi người đọc thêm về chủ đề hay ho này tại: https://britishgeologicalsurvey.github.io/science/python-forking-vs-spawn/ https://stackoverflow.com/a/66113051 https://superfastpython.com/multiprocessing-inherit-global-variables-in-python/",#multiprocess,
"Spotify chia sẻ cách họ generate preview của audio podcasts trên nền tảng của họ at-scale với GCP Dataflow, Apache Beam và một số framework DL khác.","Spotify chia sẻ cách họ generate preview của audio podcasts trên nền tảng của họ at-scale với GCP Dataflow, Apache Beam và một số framework DL khác.",,
"Góc Discord
Hallo cả nhà, hồi chiều em thấy bác nào đó đăng bài hỏi gì đó mà chưa kịp approve thì bài đã biến mất, nên em xin phép được nhắc lại một chút là group mình có một kênh trao đổi khác là Discord tại đây https://discord.gg/uPWvMg9FXd. Trên này mọi người trả lời rất nhiệt tình, và cũng có một số chuyên mục hay ho khác như #job dành cho tuyển dụng.
Còn bác nào chưa vào thì vào ngay thôi ạ :D","Góc Discord Hallo cả nhà, hồi chiều em thấy bác nào đó đăng bài hỏi gì đó mà chưa kịp approve thì bài đã biến mất, nên em xin phép được nhắc lại một chút là group mình có một kênh trao đổi khác là Discord tại đây https://discord.gg/uPWvMg9FXd. Trên này mọi người trả lời rất nhiệt tình, và cũng có một số chuyên mục hay ho khác như dành cho tuyển dụng. Còn bác nào chưa vào thì vào ngay thôi ạ :D",#job,
"Hi các bạn, sáng thứ 7 tuần này Grokking và KMS Healthcare có phối hợp tổ chức techtalk về chủ đề DevOps và MLOps, mời các bạn tham gia nhé
- Talk1: Accelerate Continuous Delivery with JenkinsX - Trung Nguyen - Principal Software Engineer @ KMS Healthcare
- Talk2: Feature Platform in the landscape of MLOps - Lead Machine Learning Engineer @ MoMo
Thông tin chi tiết mọi người có thể tham khảo ở đây nhen: https://www.facebook.com/events/173641025512747
Cảm ơn các bạn!","Hi các bạn, sáng thứ 7 tuần này Grokking và KMS Healthcare có phối hợp tổ chức techtalk về chủ đề DevOps và MLOps, mời các bạn tham gia nhé - Talk1: Accelerate Continuous Delivery with JenkinsX - Trung Nguyen - Principal Software Engineer @ KMS Healthcare - Talk2: Feature Platform in the landscape of MLOps - Lead Machine Learning Engineer @ MoMo Thông tin chi tiết mọi người có thể tham khảo ở đây nhen: https://www.facebook.com/events/173641025512747 Cảm ơn các bạn!",,
"Accelerate Data Science in Python with RAPIDS
RAPIDS (https://rapids.ai/) là một tập hợp các thư viện giúp cho việc chạy các dự án Data Science trên GPU một cách dễ dàng. Dưới đây là một số ví dụ về ứng dụng RAPIDS giúp cải thiện về thời gian và chi phí mà em note lại từ sự kiện NVIDIA GTC 2023 vừa qua, hy vọng hữu ích với mọi người.
Còn nhiều cái hay ho khác em để em nghiên cứu rồi sẽ post lên sau 😁
#gtc2023 #gpu","Accelerate Data Science in Python with RAPIDS RAPIDS (https://rapids.ai/) là một tập hợp các thư viện giúp cho việc chạy các dự án Data Science trên GPU một cách dễ dàng. Dưới đây là một số ví dụ về ứng dụng RAPIDS giúp cải thiện về thời gian và chi phí mà em note lại từ sự kiện NVIDIA GTC 2023 vừa qua, hy vọng hữu ích với mọi người. Còn nhiều cái hay ho khác em để em nghiên cứu rồi sẽ post lên sau",#gtc2023	#gpu,
"Scalable Distributed Systems - Part 2

Hi cả nhà, hôm nay mình lại biến hình lên đây để share với mọi người part 2 của series Scalable Distributed Systems mà mình đang thực hiện. Đáng ra part 2 đã được released từ tuần trước nhưng tuần trước mình lại phải biến hình đi chỗ khác nên lỡ hẹn.

Trong part 2 này, mình viết về:
- Scaling trong Application services: Service design, scaling trong application servers, horizontal scaling và load balancing
- Distributed caching: các caching design pattern phổ biến và best practices
- Hệ thống async messaging và các architecture thường gặp
- Microservices: 7 principles khi design microservices trong distributed systems và vấn đề về Resilience trong microservices

Series này sẽ còn part 3 là part cuối. Hy vọng tiếp tục nhận được sự ủng hộ của mọi người.
Cảm ơn cả nhà.

* Link part 2: https://aiengineer.net/ml-skills/scalable-distributed-systems/application-services","Scalable Distributed Systems - Part 2 Hi cả nhà, hôm nay mình lại biến hình lên đây để share với mọi người part 2 của series Scalable Distributed Systems mà mình đang thực hiện. Đáng ra part 2 đã được released từ tuần trước nhưng tuần trước mình lại phải biến hình đi chỗ khác nên lỡ hẹn. Trong part 2 này, mình viết về: - Scaling trong Application services: Service design, scaling trong application servers, horizontal scaling và load balancing - Distributed caching: các caching design pattern phổ biến và best practices - Hệ thống async messaging và các architecture thường gặp - Microservices: 7 principles khi design microservices trong distributed systems và vấn đề về Resilience trong microservices Series này sẽ còn part 3 là part cuối. Hy vọng tiếp tục nhận được sự ủng hộ của mọi người. Cảm ơn cả nhà. * Link part 2: https://aiengineer.net/ml-skills/scalable-distributed-systems/application-services",,
"Khoá học về MultiModal Machine Learning từ CMU cho bác nào quan tâm
https://cmu-multicomp-lab.github.io/mmml-course/fall2022/schedule/
#course #mmml",Khoá học về MultiModal Machine Learning từ CMU cho bác nào quan tâm https://cmu-multicomp-lab.github.io/mmml-course/fall2022/schedule/,#course	#mmml,
💎 Còn nhiều điều thú vị hơn đang ở phía trước! Cùng MLOps Marathon 2023 chờ đón bạn nha!,Còn nhiều điều thú vị hơn đang ở phía trước! Cùng MLOps Marathon 2023 chờ đón bạn nha!,,
"Xin chào các bạn,
OpenFactor Foundation đang trong giai đoạn chuẩn bị cuối cùng cho sự kiện Marathon đầu tiên về MLOps tại Việt Nam. Để đảm bảo sự thành công của cuộc thi và đáp ứng được đúng nhu cầu của người tham dự, chúng mình muốn tiến hành một cuộc khảo sát về sự kiện kick-off sắp tới. 
MLOps Marathon 2023 sẽ chính thức bắt đầu trong một tháng nữa, với tổng giá trị giải thưởng lên tới hơn 150 triệu, dự kiến sẽ tổ chức kick-off event tại Hòa Lạc, Hà Nội vào sáng thứ 6, ngày 12/05/2023. Sự kiện lần này sẽ có live talk và Q&A của các diễn giả là những chuyên gia nhiều năm kinh nghiệm trong lĩnh vực AI/ML.
Rất mong các bạn dành ít phút điền form khảo sát dưới đây nhé. Những thông tin thu thập được từ khảo sát này sẽ giúp chúng mình cải thiện tốt hơn cho kế hoạch tổ chức trong thời gian diễn ra sự kiện. Chúng mình xin chân thành cảm ơn! 🥰

https://bit.ly/mlops-marathon-kickoff-survey
 — với Quan Dang và Tung Nar.","Xin chào các bạn, OpenFactor Foundation đang trong giai đoạn chuẩn bị cuối cùng cho sự kiện Marathon đầu tiên về MLOps tại Việt Nam. Để đảm bảo sự thành công của cuộc thi và đáp ứng được đúng nhu cầu của người tham dự, chúng mình muốn tiến hành một cuộc khảo sát về sự kiện kick-off sắp tới. MLOps Marathon 2023 sẽ chính thức bắt đầu trong một tháng nữa, với tổng giá trị giải thưởng lên tới hơn 150 triệu, dự kiến sẽ tổ chức kick-off event tại Hòa Lạc, Hà Nội vào sáng thứ 6, ngày 12/05/2023. Sự kiện lần này sẽ có live talk và Q&A của các diễn giả là những chuyên gia nhiều năm kinh nghiệm trong lĩnh vực AI/ML. Rất mong các bạn dành ít phút điền form khảo sát dưới đây nhé. Những thông tin thu thập được từ khảo sát này sẽ giúp chúng mình cải thiện tốt hơn cho kế hoạch tổ chức trong thời gian diễn ra sự kiện. Chúng mình xin chân thành cảm ơn! https://bit.ly/mlops-marathon-kickoff-survey — với Quan Dang và Tung Nar.",,
Twitter vừa open-source recommendation algorithm của họ.,Twitter vừa open-source recommendation algorithm của họ.,,
"Nhân sự kiện Twitter open source recommender system, thì bác Che Viet Hai cũng đã open source hệ thống Sentiment Analysis tại đây: https://github.com/haicheviet/fullstack-machine-learning-inference.
Cảm ơn bác Hải nhiều vì đã cất công chuẩn bị slide và demo cho anh em 😄. Mọi người có thể đọc thêm nhiều bài viết hay ho khác từ bác Hải tại đây nhé ạ https://haicheviet.com/
Ai muốn em quảng cáo nữa thì đăng ký làm speaker thôi :v
#seminar #webinar","Nhân sự kiện Twitter open source recommender system, thì bác Che Viet Hai cũng đã open source hệ thống Sentiment Analysis tại đây: https://github.com/haicheviet/fullstack-machine-learning-inference. Cảm ơn bác Hải nhiều vì đã cất công chuẩn bị slide và demo cho anh em . Mọi người có thể đọc thêm nhiều bài viết hay ho khác từ bác Hải tại đây nhé ạ https://haicheviet.com/ Ai muốn em quảng cáo nữa thì đăng ký làm speaker thôi :v",#seminar	#webinar,
"Chia sẻ: 𝐈𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐢𝐧𝐠 𝐋𝐋𝐌𝐎𝐩𝐬: 𝐓𝐡𝐞 𝐅𝐮𝐭𝐮𝐫𝐞 𝐨𝐟 𝐌𝐋𝐎𝐩𝐬 𝐟𝐨𝐫 𝐆𝐞𝐧𝐞𝐫𝐚𝐭𝐢𝐯𝐞 𝐀𝐈!
🤔 𝐖𝐡𝐚𝐭 𝐢𝐬 𝐋𝐋𝐌𝐎𝐩𝐬?
LLMops is a subfield of MLOps that focuses on the operationalization of Large Language Models (LLMs). It involves developing tools and workflows to train, deploy, and manage LLMs efficiently.
- 𝐋ink https://www.linkedin.com/posts/munjal-patel_mlops-llmops-mlengineer-activity-7047185045303738368-tsA0?utm_source=share&utm_medium=member_desktop
- 𝐀𝐰𝐞𝐬𝐨𝐦𝐞 𝐋𝐋𝐌𝐎𝐩𝐬 𝐑𝐞𝐩𝐨: https://lnkd.in/diywgkk9","Chia sẻ: : ! ? LLMops is a subfield of MLOps that focuses on the operationalization of Large Language Models (LLMs). It involves developing tools and workflows to train, deploy, and manage LLMs efficiently. - ink https://www.linkedin.com/posts/munjal-patel_mlops-llmops-mlengineer-activity-7047185045303738368-tsA0?utm_source=share&utm_medium=member_desktop - : https://lnkd.in/diywgkk9",,
"Seminar sẽ diễn ra trong ít phút nữa, các bạn đừng quên tham gia nhé 😘","Seminar sẽ diễn ra trong ít phút nữa, các bạn đừng quên tham gia nhé",,
"Mọi người còn chờ đợi gì nữa, đăng ký tham gia ngay webinar 8h tối nay thôi nào ạ 🤔","Mọi người còn chờ đợi gì nữa, đăng ký tham gia ngay webinar 8h tối nay thôi nào ạ",,
"ML Infrastructure Interview
Hi cả nhà, hôm nay mình viết bài này là để tìm kiếm sự ủng hộ và quan tâm của mọi người cho loạt bài về chủ đề ML Infrastructure Interview mà mình đang lên kế hoạch chia sẻ.
Giới thiệu một chút, mình là Tùng, hiện tại đang là full-stack ML Engineer cho một công ty ở Singapore. Full-stack ở đây có nghĩa là mình có trách nhiệm trong tất cả các phần của ML lifecycle như là problem definition, data engineering, model development, model deployment, monitoring, và maintenance, cho các dự án có liên quan tới ML trong công ty. Đồng thời mình cũng đang là MLOps Lead cho dự án AICOVIDVN, nhờ có bác Quan Dang post một bài tuyển dụng cho dự án này trong group mình hồi tháng 10 năm ngoái.

Trong khoảng hơn 1 tháng vừa rồi, mình có thực hiện 35 buổi phỏng vấn ở 6 công ty khác nhau cho vị trí Senior ML Infrastructure/MLOps Engineer, trong đó có 20 buổi technical interview, còn lại là các buổi thương lượng offer. Với mỗi buổi phỏng vấn, mình đều ghi chép lại tất cả các câu hỏi bao gồm các câu hỏi technical và các câu hỏi non-technical.
Các câu hỏi technical về các chủ đề:
Computer science
Coding test
System design
Machine learning
MLOps
Các câu hỏi non-technical thì không nhiều, nhưng có đề cập tới văn hóa làm việc, cách ứng xử trong một vài tình huống, kĩ năng mềm, etc.
Trong loạt bài về chủ đề ML Infrastructure Interview, mình có dự định chia sẻ về:
Kinh nghiệm học ML System, ML Infrastructure, MLOps và roadmap cơ bản từ Junior lên Senior.
Quy trình phỏng vấn, ví dụ: có bao nhiêu vòng, thời lượng mỗi vòng, lượng câu hỏi computer science, coding, MLOps ở mỗi vòng chiếm bao nhiêu, phần nói về các projects mình đã làm chiếm bao nhiêu, etc.
Các tip trick trước, trong, và sau khi phỏng vấn. Ví dụ như các câu hỏi mà bạn nên hỏi để người phỏng vấn đánh giá cao.
Các nguồn tài liệu mình dùng để ôn tập trước khi phỏng vấn và các tài liệu khác mình đã học trong nhiều năm góp phần tích lũy kinh nghiệm khi phỏng vấn.
Và quan trọng nhất, các bộ câu hỏi technical và non-technical mà mình đã thu thập.

Các công ty mình đã phỏng vấn có quy mô khác nhau, lần lượt là: ~50 nhân viên, ~500 nhân viên, ~7k nhân viên, ~20k nhân viên, ~40k nhân viên, và ~110k nhân viên. Có vài công ty có quy mô rất lớn, product liên quan tới AI/ML của họ cũng có quy mô rất lớn, hệ thống ML infrastructure và đội ngũ các kĩ sư ở đó thì khỏi bàn, quy trình phỏng vấn của họ được chuẩn hóa, cho nên các bạn có thể yên tâm về chất lượng của các bộ câu hỏi mà mình sẽ chia sẻ.
Nhóm bạn đọc mình hướng đến bao gồm 2 nhóm. Nhóm 1 là nhóm các bạn/anh/chị quan tâm tới ML System/ML Infrastructure/MLOps và có thể đang tìm kiếm các cơ hội việc làm liên quan. Nhóm 2 là nhóm các bạn/anh/chị đã có kinh nghiệm làm ML System/ML Infrastructure/MLOps lâu năm, các Project Owners, Project Managers, có trách nhiệm thực hiện các buổi phỏng vấn tuyển dụng các kĩ sư vào team.
Mục đích của loạt bài viết này, không phải để quảng cáo cho một công ty môi giới việc làm, huấn luyện phỏng vấn, hay cung cấp các dịch vụ phỏng vấn liên quan, mà phần lớn là muốn đóng góp cho cộng đồng AI/ML ở Việt Nam nói chung và group MLOps VN của chúng ta nói riêng, một chút “nước tăng lực”. Phần nhỏ còn lại là mình muốn kết bạn, bàn luận, trao đổi với các bạn thích làm ML System/ML Infrastructure/MLOps và các chuyên gia trong lĩnh vực này. Mọi người có thể kết nối với mình qua:
LinkedIn: https://www.linkedin.com/in/tungdao17/
Hoặc Facebook Messenger
Hy vọng nhận được sự ủng hộ từ mọi người cho loạt bài chia sẻ sắp tới. Cảm ơn mọi người.
P/s: bạn nào đang trong quá trình phỏng vấn liên quan tới vị trí ML System/ML Infrastructure/MLOps, hoặc đang ở giai đoạn tìm hiểu, cần tư vấn gấp mà mình lại chưa viết xong kịp các bài chia sẻ, thì cứ nhắn cho mình qua Facebook Messenger nhé. Mình sẽ tư vấn trực tiếp và không mưu cầu gì ;)
Link post 1: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/introduction/","ML Infrastructure Interview Hi cả nhà, hôm nay mình viết bài này là để tìm kiếm sự ủng hộ và quan tâm của mọi người cho loạt bài về chủ đề ML Infrastructure Interview mà mình đang lên kế hoạch chia sẻ. Giới thiệu một chút, mình là Tùng, hiện tại đang là full-stack ML Engineer cho một công ty ở Singapore. Full-stack ở đây có nghĩa là mình có trách nhiệm trong tất cả các phần của ML lifecycle như là problem definition, data engineering, model development, model deployment, monitoring, và maintenance, cho các dự án có liên quan tới ML trong công ty. Đồng thời mình cũng đang là MLOps Lead cho dự án AICOVIDVN, nhờ có bác Quan Dang post một bài tuyển dụng cho dự án này trong group mình hồi tháng 10 năm ngoái. Trong khoảng hơn 1 tháng vừa rồi, mình có thực hiện 35 buổi phỏng vấn ở 6 công ty khác nhau cho vị trí Senior ML Infrastructure/MLOps Engineer, trong đó có 20 buổi technical interview, còn lại là các buổi thương lượng offer. Với mỗi buổi phỏng vấn, mình đều ghi chép lại tất cả các câu hỏi bao gồm các câu hỏi technical và các câu hỏi non-technical. Các câu hỏi technical về các chủ đề: Computer science Coding test System design Machine learning MLOps Các câu hỏi non-technical thì không nhiều, nhưng có đề cập tới văn hóa làm việc, cách ứng xử trong một vài tình huống, kĩ năng mềm, etc. Trong loạt bài về chủ đề ML Infrastructure Interview, mình có dự định chia sẻ về: Kinh nghiệm học ML System, ML Infrastructure, MLOps và roadmap cơ bản từ Junior lên Senior. Quy trình phỏng vấn, ví dụ: có bao nhiêu vòng, thời lượng mỗi vòng, lượng câu hỏi computer science, coding, MLOps ở mỗi vòng chiếm bao nhiêu, phần nói về các projects mình đã làm chiếm bao nhiêu, etc. Các tip trick trước, trong, và sau khi phỏng vấn. Ví dụ như các câu hỏi mà bạn nên hỏi để người phỏng vấn đánh giá cao. Các nguồn tài liệu mình dùng để ôn tập trước khi phỏng vấn và các tài liệu khác mình đã học trong nhiều năm góp phần tích lũy kinh nghiệm khi phỏng vấn. Và quan trọng nhất, các bộ câu hỏi technical và non-technical mà mình đã thu thập. Các công ty mình đã phỏng vấn có quy mô khác nhau, lần lượt là: ~50 nhân viên, ~500 nhân viên, ~7k nhân viên, ~20k nhân viên, ~40k nhân viên, và ~110k nhân viên. Có vài công ty có quy mô rất lớn, product liên quan tới AI/ML của họ cũng có quy mô rất lớn, hệ thống ML infrastructure và đội ngũ các kĩ sư ở đó thì khỏi bàn, quy trình phỏng vấn của họ được chuẩn hóa, cho nên các bạn có thể yên tâm về chất lượng của các bộ câu hỏi mà mình sẽ chia sẻ. Nhóm bạn đọc mình hướng đến bao gồm 2 nhóm. Nhóm 1 là nhóm các bạn/anh/chị quan tâm tới ML System/ML Infrastructure/MLOps và có thể đang tìm kiếm các cơ hội việc làm liên quan. Nhóm 2 là nhóm các bạn/anh/chị đã có kinh nghiệm làm ML System/ML Infrastructure/MLOps lâu năm, các Project Owners, Project Managers, có trách nhiệm thực hiện các buổi phỏng vấn tuyển dụng các kĩ sư vào team. Mục đích của loạt bài viết này, không phải để quảng cáo cho một công ty môi giới việc làm, huấn luyện phỏng vấn, hay cung cấp các dịch vụ phỏng vấn liên quan, mà phần lớn là muốn đóng góp cho cộng đồng AI/ML ở Việt Nam nói chung và group MLOps VN của chúng ta nói riêng, một chút “nước tăng lực”. Phần nhỏ còn lại là mình muốn kết bạn, bàn luận, trao đổi với các bạn thích làm ML System/ML Infrastructure/MLOps và các chuyên gia trong lĩnh vực này. Mọi người có thể kết nối với mình qua: LinkedIn: https://www.linkedin.com/in/tungdao17/ Hoặc Facebook Messenger Hy vọng nhận được sự ủng hộ từ mọi người cho loạt bài chia sẻ sắp tới. Cảm ơn mọi người. P/s: bạn nào đang trong quá trình phỏng vấn liên quan tới vị trí ML System/ML Infrastructure/MLOps, hoặc đang ở giai đoạn tìm hiểu, cần tư vấn gấp mà mình lại chưa viết xong kịp các bài chia sẻ, thì cứ nhắn cho mình qua Facebook Messenger nhé. Mình sẽ tư vấn trực tiếp và không mưu cầu gì ;) Link post 1: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/introduction/",,
"Seminar #6: Design a sentiment analysis system on industry-standard
Một chủ đề hay ho khác với rất nhiều công nghệ thú vị đằng sau nhé mọi người, cả nhà nhanh tay đăng ký thôi nào 👻. Mail thông tin về seminar sẽ được gửi ngay sau khi mọi người hoàn thành form (nếu không thấy thì mọi người check spam) nhé ạ :D.
Cảm ơn bác Che Viet Hai đã nhận lời mời chia sẻ tới cộng đồng MLOpsVN ạ 🥰
#seminar #webinar","Seminar Design a sentiment analysis system on industry-standard Một chủ đề hay ho khác với rất nhiều công nghệ thú vị đằng sau nhé mọi người, cả nhà nhanh tay đăng ký thôi nào . Mail thông tin về seminar sẽ được gửi ngay sau khi mọi người hoàn thành form (nếu không thấy thì mọi người check spam) nhé ạ :D. Cảm ơn bác Che Viet Hai đã nhận lời mời chia sẻ tới cộng đồng MLOpsVN ạ",#6:	#seminar	#webinar,
"Scalable Distributed Systems - Part 1

Hi cả nhà, mới đó mà đã gần 1 năm từ lần mình share với mọi người series về ML Infrastructure Interview. Hôm nay, mình muốn share với mọi người 1 series mới, đó là về Scalable Distributed Systems.

7 năm trước, mình bắt đầu tìm hiểu về Machine Learning và làm trong các vị trí liên quan tới việc train ML models như Researcher, Data Scientist, ML Engineer. Tháng 6 năm ngoái, mình bắt đầu một vị trí mới, đó là ML Platform Engineer. Title này là mình tự đặt ra thôi, còn trong công ty, mọi người trong team đều gọi nhau là Backend Engineer. Một cách ngắn gọn, ML Platform Engineer là Backend Engineer xây dựng các ""backend"" systems cho ML Platforms.

Team của mình có khoảng 20 người, chia thành nhiều subteams. Mỗi subteam phụ trách một phần trong 1 ML Platform, ví dụ: Feature Platform, Training Platform, Model Deployment, Inference Platform, etc. Trong khoảng 20 người, thì có khoảng 18 người thuần tuý là Backend Engineer, vài người tự học ML qua youtube, vài người chưa train model bao giờ. Họ hiếm khi dùng keyword ""distributed"", nhiều người chưa nghe tới ""MLOps"", và vài bác trong team Inference ko biết về KServe. Tuy nhiên, kinh nghiệm của họ về distributed systems thì xuất sắc.

Kiến thức mình có được từ Machine Learning đúng là giúp ích được rất nhiều, và mình có ưu thế nhất định so với các bạn khác trong team, nhưng hầu hết những vấn đề team gặp phải đều liên quan tới distributed systems. Nhận thấy vấn đề này, sau một thời gian tìm hiểu và học hỏi từ sách vở và đồng nghiệp, mình quyết định viết một series về Scalable Distributed Systems cho bản thân mình, cho cộng đồng ML, đặc biệt là những bạn đang làm ML Engineer và MLOps Engineer.

Trong series này, mình sẽ đề cập tới:
- Nguyên tắc Scaling: Replication và Optimization
- Tổng quan architecture, các vấn dề trong distributed systems
- Cách scale application services
- Cách scale distributed cache, asynchronous messaging
- Cách scale distributed database, các lưu ý về eventual consistency và strong consistency
- Đảo qua về event-driven processing và stream processing

Mình viết series này với tham vọng cung cấp một cái nhìn tổng quan về distributed systems và các nguyên lý cơ bản để scale chúng to the moon.  Hy vọng nhận được sự ủng hộ và có thể giúp được mọi người ít nhiều.
Cảm ơn cả nhà.

* Link Scalable Distributed Systems series: https://aiengineer.net/ml-skills/scalable-distributed-systems/introduction
* Link ML Infrastructure Interview series: https://www.facebook.com/groups/mlopsvn/posts/513997553787788/","Scalable Distributed Systems - Part 1 Hi cả nhà, mới đó mà đã gần 1 năm từ lần mình share với mọi người series về ML Infrastructure Interview. Hôm nay, mình muốn share với mọi người 1 series mới, đó là về Scalable Distributed Systems. 7 năm trước, mình bắt đầu tìm hiểu về Machine Learning và làm trong các vị trí liên quan tới việc train ML models như Researcher, Data Scientist, ML Engineer. Tháng 6 năm ngoái, mình bắt đầu một vị trí mới, đó là ML Platform Engineer. Title này là mình tự đặt ra thôi, còn trong công ty, mọi người trong team đều gọi nhau là Backend Engineer. Một cách ngắn gọn, ML Platform Engineer là Backend Engineer xây dựng các ""backend"" systems cho ML Platforms. Team của mình có khoảng 20 người, chia thành nhiều subteams. Mỗi subteam phụ trách một phần trong 1 ML Platform, ví dụ: Feature Platform, Training Platform, Model Deployment, Inference Platform, etc. Trong khoảng 20 người, thì có khoảng 18 người thuần tuý là Backend Engineer, vài người tự học ML qua youtube, vài người chưa train model bao giờ. Họ hiếm khi dùng keyword ""distributed"", nhiều người chưa nghe tới ""MLOps"", và vài bác trong team Inference ko biết về KServe. Tuy nhiên, kinh nghiệm của họ về distributed systems thì xuất sắc. Kiến thức mình có được từ Machine Learning đúng là giúp ích được rất nhiều, và mình có ưu thế nhất định so với các bạn khác trong team, nhưng hầu hết những vấn đề team gặp phải đều liên quan tới distributed systems. Nhận thấy vấn đề này, sau một thời gian tìm hiểu và học hỏi từ sách vở và đồng nghiệp, mình quyết định viết một series về Scalable Distributed Systems cho bản thân mình, cho cộng đồng ML, đặc biệt là những bạn đang làm ML Engineer và MLOps Engineer. Trong series này, mình sẽ đề cập tới: - Nguyên tắc Scaling: Replication và Optimization - Tổng quan architecture, các vấn dề trong distributed systems - Cách scale application services - Cách scale distributed cache, asynchronous messaging - Cách scale distributed database, các lưu ý về eventual consistency và strong consistency - Đảo qua về event-driven processing và stream processing Mình viết series này với tham vọng cung cấp một cái nhìn tổng quan về distributed systems và các nguyên lý cơ bản để scale chúng to the moon. Hy vọng nhận được sự ủng hộ và có thể giúp được mọi người ít nhiều. Cảm ơn cả nhà. * Link Scalable Distributed Systems series: https://aiengineer.net/ml-skills/scalable-distributed-systems/introduction * Link ML Infrastructure Interview series: https://www.facebook.com/groups/mlopsvn/posts/513997553787788/",,
,nan,,
"Góc trả recording và tìm thêm speaker 
Recording cho seminar #5 về Spotify Search đã về nhé mọi người, em vẫn khuyến khích các bác tham gia seminar trực tiếp để đặt câu hỏi cho speaker và tránh sự cố kỹ thuật dẫn tới không record được như seminar #3. Thật sự cảm ơn anh Cuong Dao rất nhiều vì rất nhiều kiến thức hay ho cho mọi người.
Bên cạnh đó, em vẫn đang tìm kiếm thêm speaker cho các buổi seminar sắp tới. Đây sẽ là một cơ hội tốt cho các bác muốn đóng góp gì đó cho community bất kể nhỏ hay to và PR một chút cho bản thân (và cũng để dễ dàng deal lương hơn nữa chả hạn), thế nên hãy inbox em luôn đi ạ 🤣.
Chúc cả nhà buổi tối vui vẻ 😄
#seminar #webinar","Góc trả recording và tìm thêm speaker Recording cho seminar về Spotify Search đã về nhé mọi người, em vẫn khuyến khích các bác tham gia seminar trực tiếp để đặt câu hỏi cho speaker và tránh sự cố kỹ thuật dẫn tới không record được như seminar Thật sự cảm ơn anh Cuong Dao rất nhiều vì rất nhiều kiến thức hay ho cho mọi người. Bên cạnh đó, em vẫn đang tìm kiếm thêm speaker cho các buổi seminar sắp tới. Đây sẽ là một cơ hội tốt cho các bác muốn đóng góp gì đó cho community bất kể nhỏ hay to và PR một chút cho bản thân (và cũng để dễ dàng deal lương hơn nữa chả hạn), thế nên hãy inbox em luôn đi ạ . Chúc cả nhà buổi tối vui vẻ",#5	#3.	#seminar	#webinar,
"Một use-case sử dụng feature store để lưu trữ embedding cho các video frame đến từ Netflix cho ae tham khảo
https://netflixtechblog.com/scaling-media-machine-learning-at-netflix-f19b400243
#featurestore",Một use-case sử dụng feature store để lưu trữ embedding cho các video frame đến từ Netflix cho ae tham khảo https://netflixtechblog.com/scaling-media-machine-learning-at-netflix-f19b400243,#featurestore,
"Mọi người đừng quên seminar tối nay lúc 8h nhé ạ 😁
#seminar",Mọi người đừng quên seminar tối nay lúc 8h nhé ạ,#seminar,
"Hi mọi người, mình được anh Quan Dang giới thiệu để chia sẻ figure này với mọi người. Mong nó sẽ có ích với những bạn, anh chị đang hứng thú với quy trình bảo trì AI 😊
https://www.linkedin.com/feed/update/urn:li:activity:7037341231789576192/","Hi mọi người, mình được anh Quan Dang giới thiệu để chia sẻ figure này với mọi người. Mong nó sẽ có ích với những bạn, anh chị đang hứng thú với quy trình bảo trì AI https://www.linkedin.com/feed/update/urn:li:activity:7037341231789576192/",,
"Hello tất cả mọi người,🔥
🎉 MlOps team muốn chia sẻ với mọi người về sự kiện seminar #4 với chủ đề ""Tản mạn về MLOps thực tế ở doanh nghiệp"" vào thời gian 20h ngày 23/02/2023, hình thức online qua zoom. Sự kiện bao gồm các buổi thuyết trình và thảo luận của speaker Lê Minh Tân là senior Machine Learning Engineer, giúp mọi người hiểu rõ hơn về MLOps và cách áp dụng kiến thức đó vào công việc. Nếu quan tâm, bạn có thể đăng ký tham gia tại https://tinyurl.com/2q3op45b hoặc liên hệ trực tiếp với chúng tôi.
🔥Cảm ơn mọi người đã đọc tin này và mong sớm gặp lại tất cả trong sự kiện sắp tới!🔥","Hello tất cả mọi người, MlOps team muốn chia sẻ với mọi người về sự kiện seminar với chủ đề ""Tản mạn về MLOps thực tế ở doanh nghiệp"" vào thời gian 20h ngày 23/02/2023, hình thức online qua zoom. Sự kiện bao gồm các buổi thuyết trình và thảo luận của speaker Lê Minh Tân là senior Machine Learning Engineer, giúp mọi người hiểu rõ hơn về MLOps và cách áp dụng kiến thức đó vào công việc. Nếu quan tâm, bạn có thể đăng ký tham gia tại https://tinyurl.com/2q3op45b hoặc liên hệ trực tiếp với chúng tôi. Cảm ơn mọi người đã đọc tin này và mong sớm gặp lại tất cả trong sự kiện sắp tới!",#4,
"Mới 3 hôm trước Meta release model LLaMA ít tỷ parameters hơn nhưng lại powerful hơn GPT-3, thì lại lại mới hôm qua có nguyên cái github mời mọi người customize LLaMA và train lại để build mấy cái assistant còn kinh hơn cả chatgpt. Tôi định hỏi mọi người một câu nhưng mà thôi mọi ng hãy tự hỏi chính mình đi ;)
https://www.linkedin.com/posts/yann-lecun_github-facebookresearchllama-inference-activity-7034956639526952960-B1-d
https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama","Mới 3 hôm trước Meta release model LLaMA ít tỷ parameters hơn nhưng lại powerful hơn GPT-3, thì lại lại mới hôm qua có nguyên cái github mời mọi người customize LLaMA và train lại để build mấy cái assistant còn kinh hơn cả chatgpt. Tôi định hỏi mọi người một câu nhưng mà thôi mọi ng hãy tự hỏi chính mình đi ;) https://www.linkedin.com/posts/yann-lecun_github-facebookresearchllama-inference-activity-7034956639526952960-B1-d https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama",,
"Mời mọi người bàn bạc về chủ đề: Batch size có phải càng to càng tốt, hoặc có nhất thiết phải là 2 mũ x? 🧐
Nguồn: https://www.linkedin.com/posts/sebastianraschka_deeplearning-machinelearning-activity-7023311055984488448-5MpX","Mời mọi người bàn bạc về chủ đề: Batch size có phải càng to càng tốt, hoặc có nhất thiết phải là 2 mũ x? Nguồn: https://www.linkedin.com/posts/sebastianraschka_deeplearning-machinelearning-activity-7023311055984488448-5MpX",,
"🔥 Chỉ còn chưa đầy 30p nữa thì SEMINAR #4 sẽ diễn ra, mọi người đã chuẩn bị chưa nào 🔥
Mọi người có thể tham gia qua đường link sau nhé:
📌 Link zoom: https://bit.ly/mlopsvn-seminar","Chỉ còn chưa đầy 30p nữa thì SEMINAR sẽ diễn ra, mọi người đã chuẩn bị chưa nào Mọi người có thể tham gia qua đường link sau nhé: Link zoom: https://bit.ly/mlopsvn-seminar",#4,
"Một số pattern giúp giải quyết vấn đề timeout ở đầu API Gateway
Vấn đề timeout ở đầu API Gateway (ví dụ 29s ở AWS API Gateway) gây ra khó khăn trong việc serve một model mất nhiều thời gian inference. Để giải quyết vấn đề này, mọi người (client) có thể gọi model serving service theo kiểu async (không cần trả về kết quả luôn) như sau: service sau khi được gọi sẽ bắt đầu lọ mọ đi xử lý request và ghi kết quả dự đoán vào một database (DB) và mọi người sẽ lấy kết quả từ đây. Nhưng làm thế nào để biết khi nào có kết quả trong database mà lấy? Có 3 cách như sau:
Polling: Định kỳ gọi vào DB để xem đã có kết quả chưa. Dùng cách này cần chú ý không nên gọi quá nhiều dẫn tới tăng tải DB, mà cũng không nên gọi quá ít dẫn tới tăng thời gian nhận về kết quả.
Webhook: Mọi người sẽ tạo thêm một cái webhook để khi model serving service xử lý thành công thì sẽ gửi một thông báo ""Đã hoàn thành"" tới webhook này. Sau khi nhận được tín hiệu này, mọi người mới lọ mọ vào DB lấy kết quả. Cách này thì giảm thiểu được thời gian gọi tới DB, tuy nhiên phải xây dựng thêm webhook phía client.
Websocket: Cách này phức tạp nhất và hay dùng cho các client là browser. Khi mở kết nối Websocket, phía client sẽ nhận được kết quả ngay khi model serving service xử lý xong giúp cho thời gian client nhận được kết quả ngắn nhất trong 3 phương pháp.
Để tìm hiểu thêm về các pattern này, mọi người tham khảo thêm tại: https://aws.amazon.com/blogs/architecture/managing-asynchronous-workflows-with-a-rest-api/
#modelserving #designpattern","Một số pattern giúp giải quyết vấn đề timeout ở đầu API Gateway Vấn đề timeout ở đầu API Gateway (ví dụ 29s ở AWS API Gateway) gây ra khó khăn trong việc serve một model mất nhiều thời gian inference. Để giải quyết vấn đề này, mọi người (client) có thể gọi model serving service theo kiểu async (không cần trả về kết quả luôn) như sau: service sau khi được gọi sẽ bắt đầu lọ mọ đi xử lý request và ghi kết quả dự đoán vào một database (DB) và mọi người sẽ lấy kết quả từ đây. Nhưng làm thế nào để biết khi nào có kết quả trong database mà lấy? Có 3 cách như sau: Polling: Định kỳ gọi vào DB để xem đã có kết quả chưa. Dùng cách này cần chú ý không nên gọi quá nhiều dẫn tới tăng tải DB, mà cũng không nên gọi quá ít dẫn tới tăng thời gian nhận về kết quả. Webhook: Mọi người sẽ tạo thêm một cái webhook để khi model serving service xử lý thành công thì sẽ gửi một thông báo ""Đã hoàn thành"" tới webhook này. Sau khi nhận được tín hiệu này, mọi người mới lọ mọ vào DB lấy kết quả. Cách này thì giảm thiểu được thời gian gọi tới DB, tuy nhiên phải xây dựng thêm webhook phía client. Websocket: Cách này phức tạp nhất và hay dùng cho các client là browser. Khi mở kết nối Websocket, phía client sẽ nhận được kết quả ngay khi model serving service xử lý xong giúp cho thời gian client nhận được kết quả ngắn nhất trong 3 phương pháp. Để tìm hiểu thêm về các pattern này, mọi người tham khảo thêm tại: https://aws.amazon.com/blogs/architecture/managing-asynchronous-workflows-with-a-rest-api/",#modelserving	#designpattern,
"️🎊 MLOps VN xin chân thành cảm ơn tất cả các bạn đã theo dõi và tham gia buổi seminar của chúng tôi. Hy vọng qua buổi seminar này có thể giúp các bạn có cái nhìn tổng quan hơn về Model Serving.
✍️ P/S: Nhờ mọi người dành chút ít thời gian để điền form khảo sát của chúng tôi. Những ý kiến đóng góp của bạn giúp chúng tôi sẽ hoàn thiện hơn trong tương lai.
Link khảo sát: https://tinyurl.com/2y4v2phz",MLOps VN xin chân thành cảm ơn tất cả các bạn đã theo dõi và tham gia buổi seminar của chúng tôi. Hy vọng qua buổi seminar này có thể giúp các bạn có cái nhìn tổng quan hơn về Model Serving. P/S: Nhờ mọi người dành chút ít thời gian để điền form khảo sát của chúng tôi. Những ý kiến đóng góp của bạn giúp chúng tôi sẽ hoàn thiện hơn trong tương lai. Link khảo sát: https://tinyurl.com/2y4v2phz,,
"Nhà mình ơi em có chút việc muốn nhờ ạ:
- Bên cty em từ trước đang chạy luồng ml spark trên yarn cluster bây giờ phòng em đang muốn chuyển sang chạy trên k8s
- Thì đã demo chạy được spark trên k8s với luồng cơ bản là sinh feature, rồi tạo model, rồi predict. Kết quả được đẩy lên HDFS bên ngoài
- Nhưng sếp vẫn chưa muốn đổi sang dùng k8s, các bác nào mà đã triển khai trên k8s rồi thì cho em biết k8s dùng sẽ hơn yarn ở những điểm nào để em thuyết phục sếp em đc ko ạ?","Nhà mình ơi em có chút việc muốn nhờ ạ: - Bên cty em từ trước đang chạy luồng ml spark trên yarn cluster bây giờ phòng em đang muốn chuyển sang chạy trên k8s - Thì đã demo chạy được spark trên k8s với luồng cơ bản là sinh feature, rồi tạo model, rồi predict. Kết quả được đẩy lên HDFS bên ngoài - Nhưng sếp vẫn chưa muốn đổi sang dùng k8s, các bác nào mà đã triển khai trên k8s rồi thì cho em biết k8s dùng sẽ hơn yarn ở những điểm nào để em thuyết phục sếp em đc ko ạ?",,
"Hi members của nhóm,
Không biết trong nhóm mình đã có ai sử dụng Delta Lake (https://delta.io/) và Delta Table cho data version control cho dữ liệu ảnh chưa. Mình muốn hỏi về pros and cons của hướng tiếp cận này, cũng như best practices.","Hi members của nhóm, Không biết trong nhóm mình đã có ai sử dụng Delta Lake (https://delta.io/) và Delta Table cho data version control cho dữ liệu ảnh chưa. Mình muốn hỏi về pros and cons của hướng tiếp cận này, cũng như best practices.",,
"🔥 Hi cả nhà, giờ lành đã điểm. Buổi seminar của chúng ta đã bắt đầu, mọi người nhanh chân join vào zoom để không bỏ lỡ những điều thú vị nha. 🔥","Hi cả nhà, giờ lành đã điểm. Buổi seminar của chúng ta đã bắt đầu, mọi người nhanh chân join vào zoom để không bỏ lỡ những điều thú vị nha.",,
"🎉THÔNG BÁO BUỔI SEMINAR #3: HIGH PERFORMANCE MODEL SERVING WITH BENTOML AND JENKINS🎉
👉 Đây là buổi seminar thứ 3 trong chuỗi 3 seminars liên quan đến các nội dung từ khóa học MLOps Crash Course của MLOpsVN team.
MLOps Crash Course là khóa học dành cho các cá nhân và tổ chức muốn tìm hiểu, thử nghiệm và triển khai MLOps cho các dự án AI của mình. Thông tin đăng ký và tải về có trong nội dung ở cuối bài(hoàn toàn miễn phí với access code).
🧑‍💻 Speaker ở lần thứ 3 này là Quan Dang, một trong những authors của khóa học MLOps Crash Course. Quân hiện đang là Expert Machine Learning Engineer tại Ngân hàng TMCP Hàng Hải, với nhiều năm kinh nghiệm về AI và hệ thống MLOps trong những doanh nghiệp lớn.
📝 Nội dung của buổi seminar lần này là High Performance Model Serving with BentoML and Jenkins với 3 nội dung chính sau:
- Model Serving Design Patterns
- Implement Model Serving using BentoML
- Release Faster and More Reliable with Jenkins
Mọi người nhớ dành thời gian đăng ký tham gia nhé!
——————
📌 Thời gian: Thứ sáu, ngày 10/02/2023, 20:00 - 21:00 GMT+7
📌 Hình thức: Online qua Zoom ở địa chỉ https://bit.ly/mlopsvn-seminar
📌 Link đăng ký tham gia: https://tinyurl.com/22fvvklu
——————
Cách tham gia khóa học:
✅ Truy cập địa chỉ: https://mlops.vn/#registration
✅ Điền vào form thông tin về tên, email và access code ""MLOPS-MARA""
✅ Một email chứa link tải về của khóa học sẽ được gửi đến địa chỉ đã đăng ký
—--
Tham gia Facebook Group tại: https://www.facebook.com/groups/mlopsvn/
Tham gia Discord Channel tại: https://discord.gg/JNbQpba9Ae
#mlopsvn #mlopscrashcourse","THÔNG BÁO BUỔI SEMINAR HIGH PERFORMANCE MODEL SERVING WITH BENTOML AND JENKINS Đây là buổi seminar thứ 3 trong chuỗi 3 seminars liên quan đến các nội dung từ khóa học MLOps Crash Course của MLOpsVN team. MLOps Crash Course là khóa học dành cho các cá nhân và tổ chức muốn tìm hiểu, thử nghiệm và triển khai MLOps cho các dự án AI của mình. Thông tin đăng ký và tải về có trong nội dung ở cuối bài(hoàn toàn miễn phí với access code). Speaker ở lần thứ 3 này là Quan Dang, một trong những authors của khóa học MLOps Crash Course. Quân hiện đang là Expert Machine Learning Engineer tại Ngân hàng TMCP Hàng Hải, với nhiều năm kinh nghiệm về AI và hệ thống MLOps trong những doanh nghiệp lớn. Nội dung của buổi seminar lần này là High Performance Model Serving with BentoML and Jenkins với 3 nội dung chính sau: - Model Serving Design Patterns - Implement Model Serving using BentoML - Release Faster and More Reliable with Jenkins Mọi người nhớ dành thời gian đăng ký tham gia nhé! —————— Thời gian: Thứ sáu, ngày 10/02/2023, 20:00 - 21:00 GMT+7 Hình thức: Online qua Zoom ở địa chỉ https://bit.ly/mlopsvn-seminar Link đăng ký tham gia: https://tinyurl.com/22fvvklu —————— Cách tham gia khóa học: Truy cập địa chỉ: https://mlops.vn/#registration Điền vào form thông tin về tên, email và access code ""MLOPS-MARA"" Một email chứa link tải về của khóa học sẽ được gửi đến địa chỉ đã đăng ký —-- Tham gia Facebook Group tại: https://www.facebook.com/groups/mlopsvn/ Tham gia Discord Channel tại: https://discord.gg/JNbQpba9Ae",#3:	#mlopsvn	#mlopscrashcourse,
"Hi admin và mọi người. Mình đang thực hành theo mlops crash course. Tuy nhiên, mình đang vướng chỗ set Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR ở phần xây dựng pipeline của datapipline. Mình thử set theo hướng dẫn thì không được. DAG chạy báo lỗi File or directory not found. Mình cũng thử hardcode nhưng vẫn không thể mount source cho image. Không biết có phải do mình đang sang WSL2 trên docker desktop hay không. Mình test thử docker run với source path thì chỉ nó chỉ tạo folder trên image chứ không binding. Nhờ mọi người hỗ trợ giúp mình với.","Hi admin và mọi người. Mình đang thực hành theo mlops crash course. Tuy nhiên, mình đang vướng chỗ set Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR ở phần xây dựng pipeline của datapipline. Mình thử set theo hướng dẫn thì không được. DAG chạy báo lỗi File or directory not found. Mình cũng thử hardcode nhưng vẫn không thể mount source cho image. Không biết có phải do mình đang sang WSL2 trên docker desktop hay không. Mình test thử docker run với source path thì chỉ nó chỉ tạo folder trên image chứ không binding. Nhờ mọi người hỗ trợ giúp mình với.",,
"Góc MLFlow với một chiếc UI đẹp hơn 🤣
https://medium.com/aimstack/exploring-mlflow-experiments-with-a-powerful-ui-238fa2acf89e
#mlflow #experimentracking",Góc MLFlow với một chiếc UI đẹp hơn https://medium.com/aimstack/exploring-mlflow-experiments-with-a-powerful-ui-238fa2acf89e,#mlflow	#experimentracking,
"FEATURE STORE SUMMIT 2022
Feature Store ngày càng được ứng dụng ở nhiều công ty data-driven giúp dễ dàng hơn trong việc tái sử dụng, chia sẻ và theo dõi chất lượng feature, đồng thời cũng giảm training-serving skew (xảy ra khi feature dùng để training và serving được xử lý khác nhau).
Dưới đây là ứng dụng Feature Store ở một số công ty lớn, mọi người chắc chắn sẽ học hỏi được nhiều thứ hay ho 😁.
Chúc mừng năm mới cả nhà, và cảm ơn mọi người đã đồng hành cùng em và MLOpsVN team trong suốt cả năm qua. 🫶
https://www.featurestore.org/feature-store-summit-2022
#featurestore","FEATURE STORE SUMMIT 2022 Feature Store ngày càng được ứng dụng ở nhiều công ty data-driven giúp dễ dàng hơn trong việc tái sử dụng, chia sẻ và theo dõi chất lượng feature, đồng thời cũng giảm training-serving skew (xảy ra khi feature dùng để training và serving được xử lý khác nhau). Dưới đây là ứng dụng Feature Store ở một số công ty lớn, mọi người chắc chắn sẽ học hỏi được nhiều thứ hay ho . Chúc mừng năm mới cả nhà, và cảm ơn mọi người đã đồng hành cùng em và MLOpsVN team trong suốt cả năm qua. https://www.featurestore.org/feature-store-summit-2022",#featurestore,
"MLOPSVN CHÚC TẾT 2023 QUÝ MÃO
HAPPY NEW YEAR 2023 QUÝ MÃO 🐱🐱🐱
🚀 Năm cũ đã qua, năm mới lại đến. MLOpsVN chúc tất cả thành viên trong cộng đồng có một năm mới 2023 thật nhiều năng lượng và có nhiều bứt phá hơn trong công việc.
🎉 MLOpsVN rất vui khi được đồng hành, chia sẻ kiến thức về MLOps và Machine Learning in Production cùng tất cả các thành viên trong group. Hy vọng bước sang năm 2023 này, cộng đồng của chúng ta sẽ phát triển mạnh mẽ hơn nữa.","MLOPSVN CHÚC TẾT 2023 QUÝ MÃO HAPPY NEW YEAR 2023 QUÝ MÃO Năm cũ đã qua, năm mới lại đến. MLOpsVN chúc tất cả thành viên trong cộng đồng có một năm mới 2023 thật nhiều năng lượng và có nhiều bứt phá hơn trong công việc. MLOpsVN rất vui khi được đồng hành, chia sẻ kiến thức về MLOps và Machine Learning in Production cùng tất cả các thành viên trong group. Hy vọng bước sang năm 2023 này, cộng đồng của chúng ta sẽ phát triển mạnh mẽ hơn nữa.",,
"Một số chia sẻ nhỏ cuối năm về Flask, FastAPI và BentoML
Flask là một framework phổ biến mà rất nhiều bác sử dụng để serve model hiện nay. Tuy nhiên, do Flask sử dụng WSGI server nên sẽ xử lý request theo kiểu đồng bộ: worker hoàn thành tất cả task trong request A (có thể đồng bộ hoặc bất đồng bộ) mới bắt đầu xử lý request B. FastAPI sử dụng ASGI server giúp cho các request được xử lý bất đồng bộ: trong khi xử lý request A có thể tạm thời chuyển qua xử lý request B và trở lại xử lý tiếp request A sau.
Tuy nhiên hầu hết các task trong ML đều là CPU/memory bound dẫn tới multithreading không hiệu quả (bởi vì GIL của CPython interpreter), đồng thời việc fork các prediction process để xử lý multiprocessing cũng khiến nhiều bản sao của model bị load lên RAM. Để giải quyết vấn đề này, BentoML đã implement tính năng micro-batching giúp nâng cao through put của hệ thống thông qua việc gom nhiều request để xử lý một lúc, đồng thời framework này cũng đơn giản hóa việc viết API và đóng gói model dẫn tới việc serve dễ dàng hơn rất nhiều.
Mọi người có thể học thêm về cách serve model hiệu quả sử dụng BentoML ở khóa học free MLOps Crash Course (Em xin gửi lại link cho các bác chưa đăng ký https://mlops.vn/#registration, ACCESS CODE là MLOPSVN-REL).
Cảm ơn cả nhà nhiều!
#bentoml #modelserving","Một số chia sẻ nhỏ cuối năm về Flask, FastAPI và BentoML Flask là một framework phổ biến mà rất nhiều bác sử dụng để serve model hiện nay. Tuy nhiên, do Flask sử dụng WSGI server nên sẽ xử lý request theo kiểu đồng bộ: worker hoàn thành tất cả task trong request A (có thể đồng bộ hoặc bất đồng bộ) mới bắt đầu xử lý request B. FastAPI sử dụng ASGI server giúp cho các request được xử lý bất đồng bộ: trong khi xử lý request A có thể tạm thời chuyển qua xử lý request B và trở lại xử lý tiếp request A sau. Tuy nhiên hầu hết các task trong ML đều là CPU/memory bound dẫn tới multithreading không hiệu quả (bởi vì GIL của CPython interpreter), đồng thời việc fork các prediction process để xử lý multiprocessing cũng khiến nhiều bản sao của model bị load lên RAM. Để giải quyết vấn đề này, BentoML đã implement tính năng micro-batching giúp nâng cao through put của hệ thống thông qua việc gom nhiều request để xử lý một lúc, đồng thời framework này cũng đơn giản hóa việc viết API và đóng gói model dẫn tới việc serve dễ dàng hơn rất nhiều. Mọi người có thể học thêm về cách serve model hiệu quả sử dụng BentoML ở khóa học free MLOps Crash Course (Em xin gửi lại link cho các bác chưa đăng ký https://mlops.vn/#registration, ACCESS CODE là MLOPSVN-REL). Cảm ơn cả nhà nhiều!",#bentoml	#modelserving,
,nan,,
"Seminar #2 - Feature Store - What, Why, How
Hi cả nhà, như đã giới thiệu hôm bữa về chuỗi 3 buổi Seminars cho khoá học MLOps Crash Course, dưới đây là nội dung của buổi seminar thứ 2 với chủ đề FEATURE STORE - WHAT, WHY, HOW:
Tổng quan và kiến trúc của Feature Store
Tháp nhu cầu của Feature Store
So sánh các sản phẩm Feature Store
Ứng dụng Feature Store trong MLOps Crash Course
——————
📌 Thời gian: Thứ Tư, ngày 04/01/2023, 20:00 - 21:00 GMT+7
📌 Hình thức: Online qua Zoom ở địa chỉ https://bit.ly/mlopsvn-seminar
Hẹn gặp mọi người vào buổi seminar tới!","Seminar - Feature Store - What, Why, How Hi cả nhà, như đã giới thiệu hôm bữa về chuỗi 3 buổi Seminars cho khoá học MLOps Crash Course, dưới đây là nội dung của buổi seminar thứ 2 với chủ đề FEATURE STORE - WHAT, WHY, HOW: Tổng quan và kiến trúc của Feature Store Tháp nhu cầu của Feature Store So sánh các sản phẩm Feature Store Ứng dụng Feature Store trong MLOps Crash Course —————— Thời gian: Thứ Tư, ngày 04/01/2023, 20:00 - 21:00 GMT+7 Hình thức: Online qua Zoom ở địa chỉ https://bit.ly/mlopsvn-seminar Hẹn gặp mọi người vào buổi seminar tới!",#2,
"Free AWS Solutions Architect Training cho cả nhà
https://lnkd.in/eAVCYkuM
#aws #cloud",Free AWS Solutions Architect Training cho cả nhà https://lnkd.in/eAVCYkuM,#aws	#cloud,
"MLOps Guide
This site is intended to be a MLOps Guide to help projects and companies to build more reliable MLOps environment. This guide should contemplate the theory behind MLOps and an implementation that should fit for most use cases. Made by Arthur Olga, Gabriel Monteiro, Guilherme Leite and Vinicius Lima","MLOps Guide This site is intended to be a MLOps Guide to help projects and companies to build more reliable MLOps environment. This guide should contemplate the theory behind MLOps and an implementation that should fit for most use cases. Made by Arthur Olga, Gabriel Monteiro, Guilherme Leite and Vinicius Lima",,
"MLOps Marathon Tìm GRAPHIC DESIGNER / VIDEO EDITOR
Hi cả nhà, hôm nay mình viết bài này để nhờ mọi người giới thiệu giúp các bạn có nguyện vọng volunteer cho MLOps Marathon ở vị trí Graphic Designer / Video Editor.

Hôm bữa mình có post bài tìm tình nguyện viên cho MLOps Marathon ở các vị trí ML Engineer, Backend Engineer, Graphic Designer / Video Editor thì rất vui khi nhận được rất nhiều hồ sơ của mọi người, nhưng lại chưa tìm được Graphic Designer / Video Editor phù hợp. Rất rất mong mọi người có thể giới thiệu bạn bè hay những ứng viên phù hợp giúp MLOpsVN team.
Cảm ơn cà nhà nhiều!

--------
MLOps Marathon là cuộc thi đầu tiên tại Việt Nam về MLOps, được tổ chức trong Quý 1 2023. Cuộc thi sẽ thách thức các kĩ sư trong cộng đồng AI với các vấn đề hay gặp của các sản phẩm AI khi triển khai ra thị trường, đòi hỏi các kĩ sư cần hiểu về những khó khăn khi triển khai một hệ thống ML, và trang bị một bộ các kĩ năng về MLOps nhất định.
💼 Vị trí cần tuyển: Graphic Designer / Video Editor
📝 Mô tả công việc: https://bit.ly/mlops-marathon-volunteers-JD
✍️ Cách đăng ký: Gửi CV về email mlopsvn@openfactor.org với tiêu đề: MLOps Marathon Volunteer - Role name
📌 Deadline: 2023-01-21
🌱 Quyền lợi:
Giấy chứng nhận tình nguyện viên cho cuộc thi đầu tiên về MLOps tại Việt Nam
Nhận sự giúp đỡ về chuyên môn và kĩ năng tương ứng vị trí công việc
Kết nối với các tổ chức lớn và mở rộng các cơ hội việc làm
Trải nghiệm môi trường làm việc đa quốc gia, đa văn hóa","MLOps Marathon Tìm GRAPHIC DESIGNER / VIDEO EDITOR Hi cả nhà, hôm nay mình viết bài này để nhờ mọi người giới thiệu giúp các bạn có nguyện vọng volunteer cho MLOps Marathon ở vị trí Graphic Designer / Video Editor. Hôm bữa mình có post bài tìm tình nguyện viên cho MLOps Marathon ở các vị trí ML Engineer, Backend Engineer, Graphic Designer / Video Editor thì rất vui khi nhận được rất nhiều hồ sơ của mọi người, nhưng lại chưa tìm được Graphic Designer / Video Editor phù hợp. Rất rất mong mọi người có thể giới thiệu bạn bè hay những ứng viên phù hợp giúp MLOpsVN team. Cảm ơn cà nhà nhiều! -------- MLOps Marathon là cuộc thi đầu tiên tại Việt Nam về MLOps, được tổ chức trong Quý 1 2023. Cuộc thi sẽ thách thức các kĩ sư trong cộng đồng AI với các vấn đề hay gặp của các sản phẩm AI khi triển khai ra thị trường, đòi hỏi các kĩ sư cần hiểu về những khó khăn khi triển khai một hệ thống ML, và trang bị một bộ các kĩ năng về MLOps nhất định. Vị trí cần tuyển: Graphic Designer / Video Editor Mô tả công việc: https://bit.ly/mlops-marathon-volunteers-JD Cách đăng ký: Gửi CV về email mlopsvn@openfactor.org với tiêu đề: MLOps Marathon Volunteer - Role name Deadline: 2023-01-21 Quyền lợi: Giấy chứng nhận tình nguyện viên cho cuộc thi đầu tiên về MLOps tại Việt Nam Nhận sự giúp đỡ về chuyên môn và kĩ năng tương ứng vị trí công việc Kết nối với các tổ chức lớn và mở rộng các cơ hội việc làm Trải nghiệm môi trường làm việc đa quốc gia, đa văn hóa",,
Mình thấy các pipeline MLOPS hiện nay có vẻ như đều dành cho bài toán unsupervised nhỉ. Mình có thắc mắc với bài toán supervised thì Data Annotator sẽ nằm ở đâu trong pipeline? Nếu sử dụng deep learning thì feature store sẽ không cần thiết đúng không nhỉ? Như trong các bài toán với dữ liệu dạng ảnh chẳng hạn…,Mình thấy các pipeline MLOPS hiện nay có vẻ như đều dành cho bài toán unsupervised nhỉ. Mình có thắc mắc với bài toán supervised thì Data Annotator sẽ nằm ở đâu trong pipeline? Nếu sử dụng deep learning thì feature store sẽ không cần thiết đúng không nhỉ? Như trong các bài toán với dữ liệu dạng ảnh chẳng hạn…,,
"Mọi người join link Zoom để có thể tham dự buổi seminar #2 về Feature Store do anh Tung Nar, là một trong những authors của MLOps Crash Course trình bày nha! 😄","Mọi người join link Zoom để có thể tham dự buổi seminar về Feature Store do anh Tung Nar, là một trong những authors của MLOps Crash Course trình bày nha!",#2,
"Hello mn, mình xin share cuốn sách khá hay về ML Solution Architect. Cụ thể:
Áp dụng các phương pháp ML để giải quyết các vấn đề business
Design enterprise ML platform architecture
Triển khai MLOps cho ML workflow automation
Xây dựng end-to-end data management architecture bằng AWS
Train large-scale ML models và optimize model inference latency
Tạo business application bằng AI service và custom model.
Sử dụng các AWS services để detect data, model bias và explain models.

Link book: https://www.amazon.com/Machine-Learning-Solutions-Architect-Handbook/dp/1801072167
Link code: https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-Handbook
#mlops #aws #book #ml #mlsa #mlsah ","Hello mn, mình xin share cuốn sách khá hay về ML Solution Architect. Cụ thể: Áp dụng các phương pháp ML để giải quyết các vấn đề business Design enterprise ML platform architecture Triển khai MLOps cho ML workflow automation Xây dựng end-to-end data management architecture bằng AWS Train large-scale ML models và optimize model inference latency Tạo business application bằng AI service và custom model. Sử dụng các AWS services để detect data, model bias và explain models. Link book: https://www.amazon.com/Machine-Learning-Solutions-Architect-Handbook/dp/1801072167 Link code: https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-Handbook",#mlops	#aws	#book	#ml	#mlsa	#mlsah,
"MLOps Marathon Tìm Tình Nguyện Viên
MLOps Marathon là cuộc thi đầu tiên tại Việt Nam về MLOps, được tổ chức trong Quý 1 2023. Cuộc thi sẽ thách thức các kĩ sư trong cộng đồng AI với các vấn đề hay gặp của các sản phẩm AI khi triển khai ra thị trường, đòi hỏi các kĩ sư cần hiểu về những khó khăn khi triển khai một hệ thống ML, và trang bị một bộ các kĩ năng về MLOps nhất định.
💼 Vị trí cần tuyển: ML Engineer, Backend Engineer, Graphic Designer
📝 Mô tả công việc: https://bit.ly/mlops-marathon-volunteers-JD
✍️ Cách đăng ký: Gửi CV về email mlopsvn@openfactor.org với tiêu đề: MLOps Marathon Volunteer - Role name
📌 Deadline: 2023-01-21
🌱 Quyền lợi:
Giấy chứng nhận tình nguyện viên cho cuộc thi đầu tiên về MLOps tại Việt Nam
Nhận sự giúp đỡ về chuyên môn và kĩ năng tương ứng vị trí công việc
Kết nối, học hỏi từ các chuyên gia về AI/ML đặc biệt là MLOps
Trải nghiệm môi trường làm việc đa quốc gia, đa văn hóa","MLOps Marathon Tìm Tình Nguyện Viên MLOps Marathon là cuộc thi đầu tiên tại Việt Nam về MLOps, được tổ chức trong Quý 1 2023. Cuộc thi sẽ thách thức các kĩ sư trong cộng đồng AI với các vấn đề hay gặp của các sản phẩm AI khi triển khai ra thị trường, đòi hỏi các kĩ sư cần hiểu về những khó khăn khi triển khai một hệ thống ML, và trang bị một bộ các kĩ năng về MLOps nhất định. Vị trí cần tuyển: ML Engineer, Backend Engineer, Graphic Designer Mô tả công việc: https://bit.ly/mlops-marathon-volunteers-JD Cách đăng ký: Gửi CV về email mlopsvn@openfactor.org với tiêu đề: MLOps Marathon Volunteer - Role name Deadline: 2023-01-21 Quyền lợi: Giấy chứng nhận tình nguyện viên cho cuộc thi đầu tiên về MLOps tại Việt Nam Nhận sự giúp đỡ về chuyên môn và kĩ năng tương ứng vị trí công việc Kết nối, học hỏi từ các chuyên gia về AI/ML đặc biệt là MLOps Trải nghiệm môi trường làm việc đa quốc gia, đa văn hóa",,
,nan,,
"MLOps Platform: Seminar 1 - Updates
Hi cả nhà, hôm này mình có 2 updates cực hot.
Update 1, như đã giới thiệu hôm bữa, dưới đây là thông tin buổi Seminar cho MLOps Crash Course:
Thời gian: thứ Năm ngày 22/12/2022, 20:00 - 21:00 GMT+7
Hình thức: Online qua Zoom tại https://bit.ly/mlopsvn-seminar
Update 2, dạo này mình biết mọi người đang tích cực tìm kiếm remote job lương cao, nên xin được share với mọi người:
Danh sách hơn 700 remote-friendly tech companies: https://github.com/remoteintech/remote-jobs
Blog series cách phỏng vấn vị trí liên quan tới backend của ML Systems: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/
Xin hết updates, hẹn gặp mọi người vào buổi seminar thứ 5 tới lúc 20:00 !
 — với Quan Dang.","MLOps Platform: Seminar 1 - Updates Hi cả nhà, hôm này mình có 2 updates cực hot. Update 1, như đã giới thiệu hôm bữa, dưới đây là thông tin buổi Seminar cho MLOps Crash Course: Thời gian: thứ Năm ngày 22/12/2022, 20:00 - 21:00 GMT+7 Hình thức: Online qua Zoom tại https://bit.ly/mlopsvn-seminar Update 2, dạo này mình biết mọi người đang tích cực tìm kiếm remote job lương cao, nên xin được share với mọi người: Danh sách hơn 700 remote-friendly tech companies: https://github.com/remoteintech/remote-jobs Blog series cách phỏng vấn vị trí liên quan tới backend của ML Systems: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/ Xin hết updates, hẹn gặp mọi người vào buổi seminar thứ 5 tới lúc 20:00 ! — với Quan Dang.",,
"MLOps Platform: Seminar 1
Hi cả nhà, hôm nay mình ngoi lên với 2 mục đích.

Thứ nhất là để cảm ơn group mình hôm trước đã đi offline và nhậu. Trò chuyện chia sẻ gặp gỡ mọi người real-time cảm giác khác với trên mạng rất nhiều, rất là con người.

Thứ hai là vẫn là để cảm ơn group mình đã support nhiệt tình cho MLOps Crash Course vừa mới released hôm trước, đặc biệt là các bạn Reviewers đã giành nhiều tâm huyết và thời gian để kiểm tra từng lỗi nhỏ, từ câu từ cho tới các bugs trong course. MLOpsVN Team có gửi lời cảm ơn chân thành và để tên các bạn trong trang đầu tiên của ebook khoá học.

Hiện tại khoá học đã có tới hơn 500 lượt tải ebook. Nhận thấy sự quan tâm của cộng đồng, MLOpsVN Team sẽ tổ chức khoảng 3 buổi chia sẻ để giúp các bạn hiểu hơn về khoá học, cách học và tiếp cận các bài trong khoá học, về MLOps, tầm quan trọng của MLOps, xu hướng của MLOps trong tương lai ở Việt Nam, và trao đổi với mọi người về các topics Designing ML Systems, và đặc biệt là Building MLOps Platform.

Để đăng ký cho các buổi chia sẻ và để MLOpsVN team chuẩn bị cho trọn vẹn, mọi người giúp mình đăng ký tại link mình để dưới đây nha. Lịch về các buổi chia sẻ sẽ được thông báo trong vài ngày tới.

Hy vọng những gì MLOpsVN Team đang và sẽ làm có thể đóng góp ít nhiều cho cộng đồng.
Cảm ơn cả nhà.

* Link đăng ký buổi chia sẻ: https://forms.gle/nyc5VncFbLQ1tUd18
* Cách đăng ký khoá học: https://www.facebook.com/MLOpsVN/posts/pfbid0NzrrngFk2zA11EeWDov7cQkx533gojFzG6cCUhmbhCH92NQ9K4UDQbRZT7BWL2qgl","MLOps Platform: Seminar 1 Hi cả nhà, hôm nay mình ngoi lên với 2 mục đích. Thứ nhất là để cảm ơn group mình hôm trước đã đi offline và nhậu. Trò chuyện chia sẻ gặp gỡ mọi người real-time cảm giác khác với trên mạng rất nhiều, rất là con người. Thứ hai là vẫn là để cảm ơn group mình đã support nhiệt tình cho MLOps Crash Course vừa mới released hôm trước, đặc biệt là các bạn Reviewers đã giành nhiều tâm huyết và thời gian để kiểm tra từng lỗi nhỏ, từ câu từ cho tới các bugs trong course. MLOpsVN Team có gửi lời cảm ơn chân thành và để tên các bạn trong trang đầu tiên của ebook khoá học. Hiện tại khoá học đã có tới hơn 500 lượt tải ebook. Nhận thấy sự quan tâm của cộng đồng, MLOpsVN Team sẽ tổ chức khoảng 3 buổi chia sẻ để giúp các bạn hiểu hơn về khoá học, cách học và tiếp cận các bài trong khoá học, về MLOps, tầm quan trọng của MLOps, xu hướng của MLOps trong tương lai ở Việt Nam, và trao đổi với mọi người về các topics Designing ML Systems, và đặc biệt là Building MLOps Platform. Để đăng ký cho các buổi chia sẻ và để MLOpsVN team chuẩn bị cho trọn vẹn, mọi người giúp mình đăng ký tại link mình để dưới đây nha. Lịch về các buổi chia sẻ sẽ được thông báo trong vài ngày tới. Hy vọng những gì MLOpsVN Team đang và sẽ làm có thể đóng góp ít nhiều cho cộng đồng. Cảm ơn cả nhà. * Link đăng ký buổi chia sẻ: https://forms.gle/nyc5VncFbLQ1tUd18 * Cách đăng ký khoá học: https://www.facebook.com/MLOpsVN/posts/pfbid0NzrrngFk2zA11EeWDov7cQkx533gojFzG6cCUhmbhCH92NQ9K4UDQbRZT7BWL2qgl",,
"🔥 Open Factor Launches MLOps Crash Course for AI Professionals & Enthusiasts 🔥

🚀🟢 HANOI, 12 Dec 2022 -- Open Factor today at 20:00 on 12 Dec 2022 launches its first ever free-of-charge MLOps Crash Course for Vietnamese AI professionals, professionals-to-be, and enthusiasts‼️

🎯 MLOps Crash Course provides those who are interested in the course and register to a part of it with comprehensive concepts and applications in MLOps. The participants will get access to available content for download, e-books, an online community for Q&A, and seminars by the instructors.

🌟 All the content is composed and designed following an easy-to-understand flow and gathered the latest AI industry best practices for use cases and examples. The course is practical with a project-based learning approach that included many hands-on tutorials designed and reviewed by MLOps experts from AI-leading companies. The MLOps platform created by the course can be customized and applied to multiple ML systems with different scales.

🧑‍🤝‍🧑 The course suits ML Engineers, DevOps Engineers, and Data Scientists who want to bring AI models into production and application phases. IT students and AI and/or MLOps enthusiasts who want to get a hold of ML systems can join to have a better understanding and or prepare themselves for future jobs.

✅ Participants with the access code (below) go to the Registration section at https://mlops.vn/#registration

✅ Fill out the form with your email, name and code and submit.

✅ An email containing the download link will be sent to that email.

📱The course is in HTML format and compressed as a zip file. Learners need to unzip and open it using their preferred browser. After that, they can go step by step through each chapter. In the coming month, 2-3 technical seminars will be hosted by the instructors to summarise the key concepts, and some lab demos and answer questions related to the course's content.

💥 Open Factor is looking forward to having many AI professionals and enthusiast join us in this very debut course. Open Factor is a social enterprise aiming at building capacity for a successful digital transformation of Vietnamese sectors and systems by training and nurturing the best AI and data analytic professionals.

💠 Since AI is one of the most transformative technologies supporting the digital transformation of businesses around the world, becoming an essential part of enterprise nowadays. And MLOps is a set of practices that aims to deploy and maintain ML models in production reliably and efficiently. YOU don’t want to miss this opportunity to learn all of this with us and the community through the MLOps Crash Course.

ACCESS CODE: MLOPSVN-REL
https://www.facebook.com/110954241693058/posts/pfbid02SQrXjUrNhUDsM3tXB6hwpe9BcUacshtzv7egtuPsM7q3yqG11M4MvSeSUgP8b3W5l/?mibextid=Nif5oz","Open Factor Launches MLOps Crash Course for AI Professionals & Enthusiasts HANOI, 12 Dec 2022 -- Open Factor today at 20:00 on 12 Dec 2022 launches its first ever free-of-charge MLOps Crash Course for Vietnamese AI professionals, professionals-to-be, and enthusiasts‼ MLOps Crash Course provides those who are interested in the course and register to a part of it with comprehensive concepts and applications in MLOps. The participants will get access to available content for download, e-books, an online community for Q&A, and seminars by the instructors. All the content is composed and designed following an easy-to-understand flow and gathered the latest AI industry best practices for use cases and examples. The course is practical with a project-based learning approach that included many hands-on tutorials designed and reviewed by MLOps experts from AI-leading companies. The MLOps platform created by the course can be customized and applied to multiple ML systems with different scales. The course suits ML Engineers, DevOps Engineers, and Data Scientists who want to bring AI models into production and application phases. IT students and AI and/or MLOps enthusiasts who want to get a hold of ML systems can join to have a better understanding and or prepare themselves for future jobs. Participants with the access code (below) go to the Registration section at https://mlops.vn/#registration Fill out the form with your email, name and code and submit. An email containing the download link will be sent to that email. The course is in HTML format and compressed as a zip file. Learners need to unzip and open it using their preferred browser. After that, they can go step by step through each chapter. In the coming month, 2-3 technical seminars will be hosted by the instructors to summarise the key concepts, and some lab demos and answer questions related to the course's content. Open Factor is looking forward to having many AI professionals and enthusiast join us in this very debut course. Open Factor is a social enterprise aiming at building capacity for a successful digital transformation of Vietnamese sectors and systems by training and nurturing the best AI and data analytic professionals. Since AI is one of the most transformative technologies supporting the digital transformation of businesses around the world, becoming an essential part of enterprise nowadays. And MLOps is a set of practices that aims to deploy and maintain ML models in production reliably and efficiently. YOU don’t want to miss this opportunity to learn all of this with us and the community through the MLOps Crash Course. ACCESS CODE: MLOPSVN-REL https://www.facebook.com/110954241693058/posts/pfbid02SQrXjUrNhUDsM3tXB6hwpe9BcUacshtzv7egtuPsM7q3yqG11M4MvSeSUgP8b3W5l/?mibextid=Nif5oz",,
,nan,,
,nan,,
"Gửi cả nhà tài liệu tổng hợp các Key Services, features, thông tin mới nhất tại AWS re:Invent 2023 (downloaded link below). Nhà mình cần thêm info hay cần support từ AWS thì ib My nha. Chúc cả nhà đầu tuần thật tốt.
Great material to summarize the key launches at AWS re:Invent this year that includes all re:Invent 2022 service launches and top new feature, instance, and region expansion","Gửi cả nhà tài liệu tổng hợp các Key Services, features, thông tin mới nhất tại AWS re:Invent 2023 (downloaded link below). Nhà mình cần thêm info hay cần support từ AWS thì ib My nha. Chúc cả nhà đầu tuần thật tốt. Great material to summarize the key launches at AWS re:Invent this year that includes all re:Invent 2022 service launches and top new feature, instance, and region expansion",,
"Chào anh em, nay mình có tham gia sự kiện 𝗩𝗶𝗲𝘁𝗻𝗮𝗺 𝗪𝗲𝗯 𝗦𝘂𝗺𝗺𝗶𝘁 𝟮𝟬𝟮𝟮. Qua bài talk của anh Nhân, speaker mà mình may mắn kết nối được tới cộng đồng MLOPs. Mình chia sẻ lại slide của bài talk cho anh em nào quan tâm. 
https://drive.google.com/file/d/14luwtVjN2jlZV4Kqi2Vmoci1fKWXTyzb/view?usp=sharing","Chào anh em, nay mình có tham gia sự kiện . Qua bài talk của anh Nhân, speaker mà mình may mắn kết nối được tới cộng đồng MLOPs. Mình chia sẻ lại slide của bài talk cho anh em nào quan tâm. https://drive.google.com/file/d/14luwtVjN2jlZV4Kqi2Vmoci1fKWXTyzb/view?usp=sharing",,
"Một bài khác từ Binance giải thích kỹ hơn về Feature Store bao gồm: lý do, cách ứng dụng và các best practices khi sử dụng.
https://www.binance.com/en/blog/all/a-closer-look-at-our-machine-learning-feature-store-3411614684128221181
#featurestore","Một bài khác từ Binance giải thích kỹ hơn về Feature Store bao gồm: lý do, cách ứng dụng và các best practices khi sử dụng. https://www.binance.com/en/blog/all/a-closer-look-at-our-machine-learning-feature-store-3411614684128221181",#featurestore,
"Dạ chào các bác, em đang tìm hiểu về sử dụng Docker và có một thắc mắc là mình có cách nào có thể tạo 1 container có thể quản lý được các container khác không ạ? Quản lý các tác vụ như create/start/stop/rm và kiểm tra trạng thái của container khác.
Em có xem thì thấy có portainer nhưng nó giống như giao diện, em đang muốn như là kiểu api gọi đến để tạo luật cho kiểm tra và chạy tự động.
Em mới tìm hiểu nên còn chưa hiểu mong các bác giúp, cảm ơn ạ","Dạ chào các bác, em đang tìm hiểu về sử dụng Docker và có một thắc mắc là mình có cách nào có thể tạo 1 container có thể quản lý được các container khác không ạ? Quản lý các tác vụ như create/start/stop/rm và kiểm tra trạng thái của container khác. Em có xem thì thấy có portainer nhưng nó giống như giao diện, em đang muốn như là kiểu api gọi đến để tạo luật cho kiểm tra và chạy tự động. Em mới tìm hiểu nên còn chưa hiểu mong các bác giúp, cảm ơn ạ",,
"Hello cả nhà, để tăng cường tính gắn kết của mọi người, em tạo ra 1 channel Telegram để anh em có thể dễ dàng giao lưu chém gió, chia sẻ tâm tư tình cảm nhé ạ. Những vấn đề liên quan đến hỏi đáp hoặc chia sẻ kiến thức em vẫn khuyến khích mọi người đăng lên group này để bài viết đỡ bị trôi nhé ạ :D
Chúc cả nhà tuần mới tốt lành.
https://t.me/mlopsvn","Hello cả nhà, để tăng cường tính gắn kết của mọi người, em tạo ra 1 channel Telegram để anh em có thể dễ dàng giao lưu chém gió, chia sẻ tâm tư tình cảm nhé ạ. Những vấn đề liên quan đến hỏi đáp hoặc chia sẻ kiến thức em vẫn khuyến khích mọi người đăng lên group này để bài viết đỡ bị trôi nhé ạ :D Chúc cả nhà tuần mới tốt lành. https://t.me/mlopsvn",,
"GÓC OFFLINE LẦN 1
Hi cả nhà, do số lượng người đăng ký offline không nhiều nên bọn em quyết định chuyển qua hình thức tham gia không cần đăng ký trước. 
Thông tin sự kiện:
Thời gian: 15h00-18h00 thứ 7 ngày 03/12/2022
Địa điểm: Cộng cafe (Biệt thự B30, 70 P. Nguyễn Thị Định, Trung Hoà, Cầu Giấy, Hà Nội)
Chi phí tham dự: Mọi người uống gì trả nấy 🤣
Link nhóm để mọi người làm quen trước với nhau và để update thông tin buổi offline: https://discord.gg/9hqZXRxc
Nội dung sự kiện: Giao lưu, chia sẻ kiến thức và kinh nghiệm về MLOps
Mọi người sẽ ngồi kết nối với nhau theo kiểu quây tròn thay vì kiểu hội thảo với máy chiếu nên em tin chắc đây sẽ là cơ hội tốt để mọi người gắn kết được với nhau. Số lượng chỗ em đặt trước chỉ có 20 slots thôi nên các bác chịu khó đến sớm chút không thì lại không có chỗ ngồi. Cảm ơn mọi người nhiều, và hy vọng sớm được gặp mặt mọi người.
#offline","GÓC OFFLINE LẦN 1 Hi cả nhà, do số lượng người đăng ký offline không nhiều nên bọn em quyết định chuyển qua hình thức tham gia không cần đăng ký trước. Thông tin sự kiện: Thời gian: 15h00-18h00 thứ 7 ngày 03/12/2022 Địa điểm: Cộng cafe (Biệt thự B30, 70 P. Nguyễn Thị Định, Trung Hoà, Cầu Giấy, Hà Nội) Chi phí tham dự: Mọi người uống gì trả nấy Link nhóm để mọi người làm quen trước với nhau và để update thông tin buổi offline: https://discord.gg/9hqZXRxc Nội dung sự kiện: Giao lưu, chia sẻ kiến thức và kinh nghiệm về MLOps Mọi người sẽ ngồi kết nối với nhau theo kiểu quây tròn thay vì kiểu hội thảo với máy chiếu nên em tin chắc đây sẽ là cơ hội tốt để mọi người gắn kết được với nhau. Số lượng chỗ em đặt trước chỉ có 20 slots thôi nên các bác chịu khó đến sớm chút không thì lại không có chỗ ngồi. Cảm ơn mọi người nhiều, và hy vọng sớm được gặp mặt mọi người.",#offline,
"Breaking Down Binance's Real-time End-to-end ML Pipeline
https://www.binance.com/en/blog/all/using-mlops-to-build-a-realtime-endtoend-machine-learning-pipeline-3820048062346322706",Breaking Down Binance's Real-time End-to-end ML Pipeline https://www.binance.com/en/blog/all/using-mlops-to-build-a-realtime-endtoend-machine-learning-pipeline-3820048062346322706,,
"[KUBERNETES] Em đang tìm hiểu về kubernetes gặp một vấn đề khi cài đặt sử dụng HAProxy Ingress. Em tải file yaml bản file yaml bản v0.14.0-beta.2 tại https://github.com/jcmoraisjr/haproxy-ingress/releases và cài đặt, sau đó thêm lệnh kubectl label node [..] role=ingress-controller cho master và 2 worker.
Sau đó em tạo 1 service và deployment để tạo pod chạy tại cổng 80 và 1 ingress để chuyển các http request qua service tương ứng. Tuy nhiên khi em truy cập địa chỉ host tự tạo là haproxy.test (ánh xạ qua IP của máy worker 2 trong /etc/hosts file) nhưng lại không hiển thị thông báo của nginx. Mọi người có ai gặp TH này giải thích giúp em với ạ. ","[KUBERNETES] Em đang tìm hiểu về kubernetes gặp một vấn đề khi cài đặt sử dụng HAProxy Ingress. Em tải file yaml bản file yaml bản v0.14.0-beta.2 tại https://github.com/jcmoraisjr/haproxy-ingress/releases và cài đặt, sau đó thêm lệnh kubectl label node [..] role=ingress-controller cho master và 2 worker. Sau đó em tạo 1 service và deployment để tạo pod chạy tại cổng 80 và 1 ingress để chuyển các http request qua service tương ứng. Tuy nhiên khi em truy cập địa chỉ host tự tạo là haproxy.test (ánh xạ qua IP của máy worker 2 trong /etc/hosts file) nhưng lại không hiển thị thông báo của nginx. Mọi người có ai gặp TH này giải thích giúp em với ạ.",,
"[KUBERNETES] Em đang tìm hiểu về kubernetes gặp một vấn đề khi cài đặt metrics-server. Đầu tiên cài đặt file yaml như hướng dẫn: https://github.com/kubernetes-sigs/metrics-server/releases. Thì em gặp lỗi: Readiness probe failed: HTTP probe failed with statuscode: 500. Sau khi search thì em thêm - --kubelet-insecure-tls vào args thì fix được, nhưng vẫn gặp lỗi timeout (hình dưới). Tình cờ em seach được bài này trên github: https://github.com/kubernetes-sigs/metrics-server/issues/141 và thêm hostNetwork: true thì metrics-server chạy được. Có anh/chị nào hiểu rõ khúc này giải thích giúp em chỗ hostNetwork này có liên quan gì với ạ. Em cảm ơn.","[KUBERNETES] Em đang tìm hiểu về kubernetes gặp một vấn đề khi cài đặt metrics-server. Đầu tiên cài đặt file yaml như hướng dẫn: https://github.com/kubernetes-sigs/metrics-server/releases. Thì em gặp lỗi: Readiness probe failed: HTTP probe failed with statuscode: 500. Sau khi search thì em thêm - --kubelet-insecure-tls vào args thì fix được, nhưng vẫn gặp lỗi timeout (hình dưới). Tình cờ em seach được bài này trên github: https://github.com/kubernetes-sigs/metrics-server/issues/141 và thêm hostNetwork: true thì metrics-server chạy được. Có anh/chị nào hiểu rõ khúc này giải thích giúp em chỗ hostNetwork này có liên quan gì với ạ. Em cảm ơn.",,
"[KUBERNETES] Em đang tìm hiểu về kubernetes và có tạo 1 cluster gồm 3 máy ảo (Centos 7), 1 máy master và 2 worker. IP lần lượt : 192.168.10.100, 192.168.10.101, 192.168.10.102. Khi em làm theo hướng dẫn để cài đặt kuber dashboard https://kubernetes.io/.../access.../web-ui-dashboard/ . Em có thử tự tạo certs theo hướng dẫn thì kuber dashboard thì pod chạy running 1 lúc thì gặp lỗi CrashLoopBackOff. Mọi người có ai đã từng gặp lỗi này cho em hỏi cách sửa với ạ.","[KUBERNETES] Em đang tìm hiểu về kubernetes và có tạo 1 cluster gồm 3 máy ảo (Centos 7), 1 máy master và 2 worker. IP lần lượt : 192.168.10.100, 192.168.10.101, 192.168.10.102. Khi em làm theo hướng dẫn để cài đặt kuber dashboard https://kubernetes.io/.../access.../web-ui-dashboard/ . Em có thử tự tạo certs theo hướng dẫn thì kuber dashboard thì pod chạy running 1 lúc thì gặp lỗi CrashLoopBackOff. Mọi người có ai đã từng gặp lỗi này cho em hỏi cách sửa với ạ.",,
"Twitter architecture được vẽ vời bởi bác Elon Musk ngày hôm qua. Ae có thể thấy bóng dáng của Feature Store và Prediction Service phía tay phải 🤣

Nguồn: https://twitter.com/elonmusk/status/1593899029531803649/photo/1",Twitter architecture được vẽ vời bởi bác Elon Musk ngày hôm qua. Ae có thể thấy bóng dáng của Feature Store và Prediction Service phía tay phải Nguồn: https://twitter.com/elonmusk/status/1593899029531803649/photo/1,,
"Giới thiệu với mọi người một giải pháp serving khá hay ho, đúng kiểu kết hợp PPAP (Pen-Pineapple-Apple-Pen) giữa kiến trúc server (ví dụ EC2) và serverless (ví dụ Lambda) 🤣, đó là modelmesh (https://github.com/kserve/modelmesh).
Framework này được tạo nên bởi IBM, sau đó kết hợp với kserve để tạo thành một dự án open-source. Idea của modelmesh là giữ cho số lượng pod nhất định running, và có một con controller sẽ làm nhiệm vụ load model phù hợp vào pod dựa trên tần suất gọi model và tài nguyên tính toán tương ứng với model đó (CPU, memory, ...).
Ưu điểm của modelmesh là tối ưu cost so với kiến trúc server truyền thống, đồng thời giảm thời gian so với việc spin up một instance mới trong kiến trúc serverless. Nhược điểm là phải chọn ra bao nhiêu pod running là phù hợp (có thể giải quyết bằng cách viết thêm 1 k8s controller để tự scale).
Để hiểu rõ hơn về kiến trúc này, em đã đơn giản hóa và vẽ lại như hình đính kèm bên dưới. Chúc các bác ngày mới tốt lành :D","Giới thiệu với mọi người một giải pháp serving khá hay ho, đúng kiểu kết hợp PPAP (Pen-Pineapple-Apple-Pen) giữa kiến trúc server (ví dụ EC2) và serverless (ví dụ Lambda) , đó là modelmesh (https://github.com/kserve/modelmesh). Framework này được tạo nên bởi IBM, sau đó kết hợp với kserve để tạo thành một dự án open-source. Idea của modelmesh là giữ cho số lượng pod nhất định running, và có một con controller sẽ làm nhiệm vụ load model phù hợp vào pod dựa trên tần suất gọi model và tài nguyên tính toán tương ứng với model đó (CPU, memory, ...). Ưu điểm của modelmesh là tối ưu cost so với kiến trúc server truyền thống, đồng thời giảm thời gian so với việc spin up một instance mới trong kiến trúc serverless. Nhược điểm là phải chọn ra bao nhiêu pod running là phù hợp (có thể giải quyết bằng cách viết thêm 1 k8s controller để tự scale). Để hiểu rõ hơn về kiến trúc này, em đã đơn giản hóa và vẽ lại như hình đính kèm bên dưới. Chúc các bác ngày mới tốt lành :D",,
"Tiếp tục chuỗi kubeflow example từ tuần trước. Em có tập hợp lại các example cơ bản để interact giữa Kubeflow pipeline và k8s như thêm volume, resource, secret,... thành một pipeline chi tiết hơn. Hy vọng sẽ có ích cho cả nhà 😁","Tiếp tục chuỗi kubeflow example từ tuần trước. Em có tập hợp lại các example cơ bản để interact giữa Kubeflow pipeline và k8s như thêm volume, resource, secret,... thành một pipeline chi tiết hơn. Hy vọng sẽ có ích cho cả nhà",,
"Sally xin chào các anh/chị em MLop Việt Nam, 
Lần trước Sally đã giới thiệu với anh chị về www.K1st.world ( Hội nghị K1st World), nay Sally xin gửi Agenda của hội nghị để mọi người được nắm ạ.
Agenda này là dự kiến, có thể thay đổi nội dung hoặc speaker cho đến khi sự kiện được chính thức diễn ra vào ngày 16 và 17/11 tại Stanford - CA - US.
Agenda here: https://www.k1st.world/agenda
Ở K1st các anh/chị sẽ được giao lưu trực tiếp với diễn giả và được kết nối với cộng đồng AI từ khắp nơi trên thế giới để chia sẻ về với :
Tri thức, kinh nghiệm của con người khi xây dựng mô hình AI ở trong công nghiệp, dịch vụ, phòng nghiên cứu….ở những “case studies"" thực tế đã, đang và sẽ triển khai.
AI model và những cơ hội thách thức trong tương lai ở Việt Nam và thế giới.
Cơ hội nghề nghiệp nào cho các bạn trẻ trong ngành AI
👍 Để nhận vé tham dự In person trị giá $899 với code 0đ tại đây: https://bit.ly/attend-k1st-Sally
👍 Các anh/chị không thể tham dự in person thì có thể tham gia online live trực tiếp tại: https://bit.ly/k1stticket","Sally xin chào các anh/chị em MLop Việt Nam, Lần trước Sally đã giới thiệu với anh chị về www.K1st.world ( Hội nghị K1st World), nay Sally xin gửi Agenda của hội nghị để mọi người được nắm ạ. Agenda này là dự kiến, có thể thay đổi nội dung hoặc speaker cho đến khi sự kiện được chính thức diễn ra vào ngày 16 và 17/11 tại Stanford - CA - US. Agenda here: https://www.k1st.world/agenda Ở K1st các anh/chị sẽ được giao lưu trực tiếp với diễn giả và được kết nối với cộng đồng AI từ khắp nơi trên thế giới để chia sẻ về với : Tri thức, kinh nghiệm của con người khi xây dựng mô hình AI ở trong công nghiệp, dịch vụ, phòng nghiên cứu….ở những “case studies"" thực tế đã, đang và sẽ triển khai. AI model và những cơ hội thách thức trong tương lai ở Việt Nam và thế giới. Cơ hội nghề nghiệp nào cho các bạn trẻ trong ngành AI Để nhận vé tham dự In person trị giá $899 với code 0đ tại đây: https://bit.ly/attend-k1st-Sally Các anh/chị không thể tham dự in person thì có thể tham gia online live trực tiếp tại: https://bit.ly/k1stticket",,
"Em chào mọi người,
em đang thử dùng vagrant để tạo máy ảo trên virtualbox, Vagrantfile chạy bình thường và tạo các máy ảo thành công, kết nối được thông qua ssh. Nhưng sau khi em cài đặt docker desktop và kích hoạt docker-desktop và kubenetes thì khi em tạo lại máy ảo bằng Vagrantfile thì bị ngưng tại chỗ ssh và xảy ra lỗi timeout. Mọi người cho em hỏi lúc bật docker-desktop thì nó có kích hoạt cái gì làm cho ssh vào các virtual machine bị chặn không ạ ( Ubuntu 22.04 ạ). Em cảm ơn.","Em chào mọi người, em đang thử dùng vagrant để tạo máy ảo trên virtualbox, Vagrantfile chạy bình thường và tạo các máy ảo thành công, kết nối được thông qua ssh. Nhưng sau khi em cài đặt docker desktop và kích hoạt docker-desktop và kubenetes thì khi em tạo lại máy ảo bằng Vagrantfile thì bị ngưng tại chỗ ssh và xảy ra lỗi timeout. Mọi người cho em hỏi lúc bật docker-desktop thì nó có kích hoạt cái gì làm cho ssh vào các virtual machine bị chặn không ạ ( Ubuntu 22.04 ạ). Em cảm ơn.",,
"Tiktok cuối cùng đã publish Real-time Recommendation System của họ.
Một paper cực kì practical dành cho các bác nào đam mê ML system design.
https://arxiv.org/pdf/2209.07663.pdf",Tiktok cuối cùng đã publish Real-time Recommendation System của họ. Một paper cực kì practical dành cho các bác nào đam mê ML system design. https://arxiv.org/pdf/2209.07663.pdf,,
"Hi ace,
Giới thiệu m.n bài viết về mô hình Word2Vec cho bài toán Recommender System. Thanks","Hi ace, Giới thiệu m.n bài viết về mô hình Word2Vec cho bài toán Recommender System. Thanks",,
"#mlflow #trackingserver
Chào mọi người, team mình đang triển khai MLFlow trên AWS và gặp 1 số vấn đề hy vọng mọi người chỉ giáo ạ. Mình không có nhiều kinh nghiệm nên rất mong mọi người góp ý 😁
Problem: team mình muốn triển khai cho mỗi team data science là 1 MLFlow tracking server (chạy trên EC2 hoặc Fargate). Bên mình dự định sẽ dùng path-based routing rules trên Application Load Balancer(ALB) theo tên của mỗi team tương ứng
Ví dụ: kết nối đến mlflow tracking server qua url như sau
- Team sale: domain.com/sale/
- Team payment: domain.com/payment/
Bên mình đã làm đến bước này thành công (nhớ add thêm --static-prefix vào mlflow server mới được nha), và cũng đã access được UI qua các URLs trên.
Vấn đề hiện nay mình gặp phải là khi data scientist trong team họ viết code ở local và set_tracking_uri('domain.com/sale/') và chay experiment thì lại bị lỗi URL not found. Theo bên mình tìm hiểu thì dù đã set static-prefix rồi nhưng mlflow.client vẫn chưa xử lý phần prefix này ở _call_endpoint() dẫn đến url request bị sai.
Cho mình hỏi là các bạn đã gặp tình huống trên và xử lý như thế nào cho gọn gàng ạ. Mình xin cám ơn :)","Chào mọi người, team mình đang triển khai MLFlow trên AWS và gặp 1 số vấn đề hy vọng mọi người chỉ giáo ạ. Mình không có nhiều kinh nghiệm nên rất mong mọi người góp ý Problem: team mình muốn triển khai cho mỗi team data science là 1 MLFlow tracking server (chạy trên EC2 hoặc Fargate). Bên mình dự định sẽ dùng path-based routing rules trên Application Load Balancer(ALB) theo tên của mỗi team tương ứng Ví dụ: kết nối đến mlflow tracking server qua url như sau - Team sale: domain.com/sale/ - Team payment: domain.com/payment/ Bên mình đã làm đến bước này thành công (nhớ add thêm --static-prefix vào mlflow server mới được nha), và cũng đã access được UI qua các URLs trên. Vấn đề hiện nay mình gặp phải là khi data scientist trong team họ viết code ở local và set_tracking_uri('domain.com/sale/') và chay experiment thì lại bị lỗi URL not found. Theo bên mình tìm hiểu thì dù đã set static-prefix rồi nhưng mlflow.client vẫn chưa xử lý phần prefix này ở _call_endpoint() dẫn đến url request bị sai. Cho mình hỏi là các bạn đã gặp tình huống trên và xử lý như thế nào cho gọn gàng ạ. Mình xin cám ơn :)",#mlflow	#trackingserver,
"Giới thiệu với cả nhà một kho cheatsheet hay là https://devhints.io/, bản thân em thấy tác giả trình bày rất rõ ràng và dễ hiểu, ví dụ Bash cheatsheet: https://devhints.io/bash
#QuickTip","Giới thiệu với cả nhà một kho cheatsheet hay là https://devhints.io/, bản thân em thấy tác giả trình bày rất rõ ràng và dễ hiểu, ví dụ Bash cheatsheet: https://devhints.io/bash",#QuickTip,
"[Đã FULL] Tìm Reviewers cho khoá học MLOps
Hi cả nhà, admin Quan Dang và mình đang tìm kiếm:
Một nhóm nhỏ khoảng 10 bạn
Ở đủ mọi cấp độ kinh nghiệm trong MLOps
Để tình nguyện review một khoá học MLOps trước khi nó được released
Về việc review, công việc sẽ bao gồm:
Học thử cả khoá học
Report lỗi cho các bài học. Các lỗi xảy ra có thể là: sai chính tả, trình bày xấu, giải thích chưa rõ ràng, thiết kế quá phức tạp, code không chạy, etc.
Việc review sẽ kéo dài khoảng 1-2 tuần. Mình sẽ bàn bạc chi tiết hơn sau khi đã chốt danh sách. Mọi người có thể comment để xí chỗ, hoặc inbox trực tiếp Quan Dang và mình.
Cảm ơn mọi người!
UPDATE: Số lượng các bạn đăng ký đã đủ! Cảm ơn mọi người nhiều!","[Đã FULL] Tìm Reviewers cho khoá học MLOps Hi cả nhà, admin Quan Dang và mình đang tìm kiếm: Một nhóm nhỏ khoảng 10 bạn Ở đủ mọi cấp độ kinh nghiệm trong MLOps Để tình nguyện review một khoá học MLOps trước khi nó được released Về việc review, công việc sẽ bao gồm: Học thử cả khoá học Report lỗi cho các bài học. Các lỗi xảy ra có thể là: sai chính tả, trình bày xấu, giải thích chưa rõ ràng, thiết kế quá phức tạp, code không chạy, etc. Việc review sẽ kéo dài khoảng 1-2 tuần. Mình sẽ bàn bạc chi tiết hơn sau khi đã chốt danh sách. Mọi người có thể comment để xí chỗ, hoặc inbox trực tiếp Quan Dang và mình. Cảm ơn mọi người! UPDATE: Số lượng các bạn đăng ký đã đủ! Cảm ơn mọi người nhiều!",,
"Tuần qua em vừa nghiên cứu Kubeflow và có doc lại cách một cách tạo pipeline rất đơn giản, chỉ như viết một file docker-compose. Mong sẽ giúp được cho các bác/em mới bắt đầu sử dụng Kubeflow. Tutorial này sử dụng docker image và data public nên các bác có thể bê nguyên về chạy không phải sửa gì thêm. Chúc cả nhà cuối tuần vui vẻ 😁","Tuần qua em vừa nghiên cứu Kubeflow và có doc lại cách một cách tạo pipeline rất đơn giản, chỉ như viết một file docker-compose. Mong sẽ giúp được cho các bác/em mới bắt đầu sử dụng Kubeflow. Tutorial này sử dụng docker image và data public nên các bác có thể bê nguyên về chạy không phải sửa gì thêm. Chúc cả nhà cuối tuần vui vẻ",,
"Chắc hẳn ae ít nhất đã từng nghe tới các khái niệm như A/B testing, Blue/Green, Canary, Shadow Deployment... Đây là tên của một số chiến lược deployment.
Vậy cụ thể chúng là gì và cách thực hiện trên Kubernetes như thế nào? Trên mạng đầy rẫy các giải thích nhưng tài liệu dưới đây của CNCF mình thấy trực quan và dễ hiểu nhất, mời ae thẩm nhé.
https://www.cncf.io/wp-content/uploads/2020/08/CNCF-Presentation-Template-K8s-Deployment.pdf","Chắc hẳn ae ít nhất đã từng nghe tới các khái niệm như A/B testing, Blue/Green, Canary, Shadow Deployment... Đây là tên của một số chiến lược deployment. Vậy cụ thể chúng là gì và cách thực hiện trên Kubernetes như thế nào? Trên mạng đầy rẫy các giải thích nhưng tài liệu dưới đây của CNCF mình thấy trực quan và dễ hiểu nhất, mời ae thẩm nhé. https://www.cncf.io/wp-content/uploads/2020/08/CNCF-Presentation-Template-K8s-Deployment.pdf",,
"Xin mời MLOps Vietnam team tham dự chương trình ""Harness the Potential of Data"" cùng với AWS và đối tác, tại Pullman Hà Nội, ngày 18/10:","Xin mời MLOps Vietnam team tham dự chương trình ""Harness the Potential of Data"" cùng với AWS và đối tác, tại Pullman Hà Nội, ngày 18/10:",,
"Xin chào các bạn của MLOP,
Mình là Sally, hiện tại mình đang tham gia tổ chức 1 sự kiện có tên gọi là: K1st World là hội nghị chuyên đề về Human Knowledge trong AI duy nhất, quy tụ các chuyên gia hàng đầu trên thế giới về Học máy (ML) trên thế giới.
Mình muốn chia sẻ hội nghị “hay ho"" này đến với những bạn đang loay hoay tìm cho mình hướng đi trong AI, với nhiều câu hỏi băn khoăn như:
Liệu mình có thể tham gia vào lĩnh vực AI khi hiện là sinh viên Y khoa, Vật lý, hóa học, tài chính…hay không? Và mình phải chuẩn bị những gì khi muốn tham gia vào lĩnh vực AI? Ai có thể giúp được mình?
Các công ty CNTT thì có chức vị trí gì, chức danh gì cho nhân sự ở trong lĩnh vực AI? Yêu cầu cơ bản khi tuyển dụng của các công ty đó là gì cho sinh viên khi mới ra trường? Và các yêu cầu đó có khác nhau ở các quốc gia trên toàn thế giới?
Làm sao để biết mình phù hợp với nghiên cứu hay sản xuất các sản phẩm về AI? Yêu cầu giữa nghiên cứu và sản xuất khác nhau như thế nào?
Hãy tham gia hội nghị www.K1st.world, để  lắng nghe các chuyên gia đầu ngành đến từ các công ty và tổ chức nghiên cứu “siêu khủng” như: NASA, Google Cloud AI, VinAI, Wesco, Hitachi, Panasonic, và các giáo sư với profile “siêu khủng” từ: MIT, Stanford, USC, CMU….giải đáp nhé.
Các bạn có thể đăng kí vé tham dự tại đây nhé, vé này dành cho các thành viên Việt Referral với số lượng là 40 vé ạ: https://bit.ly/3cVJvVn","Xin chào các bạn của MLOP, Mình là Sally, hiện tại mình đang tham gia tổ chức 1 sự kiện có tên gọi là: K1st World là hội nghị chuyên đề về Human Knowledge trong AI duy nhất, quy tụ các chuyên gia hàng đầu trên thế giới về Học máy (ML) trên thế giới. Mình muốn chia sẻ hội nghị “hay ho"" này đến với những bạn đang loay hoay tìm cho mình hướng đi trong AI, với nhiều câu hỏi băn khoăn như: Liệu mình có thể tham gia vào lĩnh vực AI khi hiện là sinh viên Y khoa, Vật lý, hóa học, tài chính…hay không? Và mình phải chuẩn bị những gì khi muốn tham gia vào lĩnh vực AI? Ai có thể giúp được mình? Các công ty CNTT thì có chức vị trí gì, chức danh gì cho nhân sự ở trong lĩnh vực AI? Yêu cầu cơ bản khi tuyển dụng của các công ty đó là gì cho sinh viên khi mới ra trường? Và các yêu cầu đó có khác nhau ở các quốc gia trên toàn thế giới? Làm sao để biết mình phù hợp với nghiên cứu hay sản xuất các sản phẩm về AI? Yêu cầu giữa nghiên cứu và sản xuất khác nhau như thế nào? Hãy tham gia hội nghị www.K1st.world, để lắng nghe các chuyên gia đầu ngành đến từ các công ty và tổ chức nghiên cứu “siêu khủng” như: NASA, Google Cloud AI, VinAI, Wesco, Hitachi, Panasonic, và các giáo sư với profile “siêu khủng” từ: MIT, Stanford, USC, CMU….giải đáp nhé. Các bạn có thể đăng kí vé tham dự tại đây nhé, vé này dành cho các thành viên Việt Referral với số lượng là 40 vé ạ: https://bit.ly/3cVJvVn",,
"Em chào mọi người ạ! Mọi người cho em hỏi, trong quá trình triển khai từ model lên production với điều kiện chỉ sử dụng CPU cho quá trình tính toán thì có cách nào cải thiện tốc độ predict, chấp nhận độ chính xác giảm xuống không ạ! Em có sử dụng một số kỹ thuật compression như pruned hay quantization mà không thấy có hiệu quả cao lắm! Mô hình giảm đáng kể dung lượng lưu trữ nhưng thời gian predict giảm không đáng kể cũng như độ chính xác giảm khá nhiều! (Model em train trên GPU ạ)
Ngoài ra, mọi người cho em hỏi thêm và em thấy việc Rust hiện đang có tốc độ phát triển khá nhanh và thực sự có nhiều ưu điểm khi triển khai mô hình lên production! Mọi người nghĩ sao về Rust cũng như việc ứng dụng của nó trong AI ạ!
Em cảm ơn nhiều ạ! ♥♥","Em chào mọi người ạ! Mọi người cho em hỏi, trong quá trình triển khai từ model lên production với điều kiện chỉ sử dụng CPU cho quá trình tính toán thì có cách nào cải thiện tốc độ predict, chấp nhận độ chính xác giảm xuống không ạ! Em có sử dụng một số kỹ thuật compression như pruned hay quantization mà không thấy có hiệu quả cao lắm! Mô hình giảm đáng kể dung lượng lưu trữ nhưng thời gian predict giảm không đáng kể cũng như độ chính xác giảm khá nhiều! (Model em train trên GPU ạ) Ngoài ra, mọi người cho em hỏi thêm và em thấy việc Rust hiện đang có tốc độ phát triển khá nhanh và thực sự có nhiều ưu điểm khi triển khai mô hình lên production! Mọi người nghĩ sao về Rust cũng như việc ứng dụng của nó trong AI ạ! Em cảm ơn nhiều ạ!",,
30 ngày đọc sách miễn phí trên nền tảng O'Reilly với rất nhiều đầu sách hay cho mọi người :D,30 ngày đọc sách miễn phí trên nền tảng O'Reilly với rất nhiều đầu sách hay cho mọi người :D,,
"AWS SageMaker Training vừa cho ra mắt Warm Pools, giúp giảm thiểu thời gian start up các instances để training qua thông việc giữ các instances `warm` trong một thời gian sau nhất định sau khi job đã hoàn thành. 
https://aws.amazon.com/about-aws/whats-new/2022/09/reduce-ml-model-training-job-startup-time-8x-sagemaker-training-managed-warm-pools/
#quicktip","AWS SageMaker Training vừa cho ra mắt Warm Pools, giúp giảm thiểu thời gian start up các instances để training qua thông việc giữ các instances `warm` trong một thời gian sau nhất định sau khi job đã hoàn thành. https://aws.amazon.com/about-aws/whats-new/2022/09/reduce-ml-model-training-job-startup-time-8x-sagemaker-training-managed-warm-pools/",#quicktip,
"Clean Code event sẽ diễn ra vào sáng mai, bổ ích cho ae coder mọi lứa tuổi và trình độ. Chỉ hôm nay thôi sẽ hết đăng ký. Mời ae nhanh chân ạ 🫡","Clean Code event sẽ diễn ra vào sáng mai, bổ ích cho ae coder mọi lứa tuổi và trình độ. Chỉ hôm nay thôi sẽ hết đăng ký. Mời ae nhanh chân ạ",,
"Trong bài toán personalization của Linkedin, dữ liệu về hành vi apply job của user bị delay một giờ khiến model giảm performance 3.51%. Vì thế, các engineer đã thay đổi thiết kế feature pipeline từ batch job sang kết hợp sử dụng cả batch và near real-time feature dẫn tới các business metrics cũng cải thiện đáng kể.
Mọi người xem chi tiết hơn tại đây: https://engineering.linkedin.com/blog/2022/near-real-time-features-for-near-real-time-personalization","Trong bài toán personalization của Linkedin, dữ liệu về hành vi apply job của user bị delay một giờ khiến model giảm performance 3.51%. Vì thế, các engineer đã thay đổi thiết kế feature pipeline từ batch job sang kết hợp sử dụng cả batch và near real-time feature dẫn tới các business metrics cũng cải thiện đáng kể. Mọi người xem chi tiết hơn tại đây: https://engineering.linkedin.com/blog/2022/near-real-time-features-for-near-real-time-personalization",,
"Em chào cả nhà.
Không biết có anh chị nào đã gộp thành công 2x 3090 24gb -> 1x 48gb thông qua NVLink trên ubuntu chưa ạ (memory pooling).
Em mong được anh/chị hướng dẫn ạ",Em chào cả nhà. Không biết có anh chị nào đã gộp thành công 2x 3090 24gb -> 1x 48gb thông qua NVLink trên ubuntu chưa ạ (memory pooling). Em mong được anh/chị hướng dẫn ạ,,
"[#MoMo #Hanoi Tuyển dụng MLOps Engineer & Machine Learning Engineer (Mid/ Senior)] 
👉 JD em gửi mọi người ngay dưới comment ạ.
👉 Như tiêu đề của post, với xu hướng AI First, MoMo đang chiêu mộ các anh chị em MLOps & MLE về chung team ạ. Về với MoMo, mình sẽ có cơ hội:
Làm việc với các bài toán sở hữu lượng data lớn (hiện MoMo đang có khoảng 35 triệu users.
Không chấm công giờ làm, làm từ thứ 2-6. Hôm nào muốn làm việc ở nhà thì alo xin sếp, miễn đảm bảo chất lượng và kết quả công việc là được ạ;
Đồng nghiệp, sếp vui, xịn ạ :d 
Em mong nhận được sự quan tâm của mọi người. Em cũng cảm ơn admin đã duyệt bài ạ.","[#MoMo Tuyển dụng MLOps Engineer & Machine Learning Engineer (Mid/ Senior)] JD em gửi mọi người ngay dưới comment ạ. Như tiêu đề của post, với xu hướng AI First, MoMo đang chiêu mộ các anh chị em MLOps & MLE về chung team ạ. Về với MoMo, mình sẽ có cơ hội: Làm việc với các bài toán sở hữu lượng data lớn (hiện MoMo đang có khoảng 35 triệu users. Không chấm công giờ làm, làm từ thứ 2-6. Hôm nào muốn làm việc ở nhà thì alo xin sếp, miễn đảm bảo chất lượng và kết quả công việc là được ạ; Đồng nghiệp, sếp vui, xịn ạ :d Em mong nhận được sự quan tâm của mọi người. Em cũng cảm ơn admin đã duyệt bài ạ.",#Hanoi,
"POST TUYỂN DỤNG THÁNG 09/2022

Mọi người đăng thông tin tuyển dụng và các cơ hội việc làm cho tháng này tại đây nhé ạ, chúc mọi người một tuần làm việc hiệu quả 😂
#tuyendung","POST TUYỂN DỤNG THÁNG 09/2022 Mọi người đăng thông tin tuyển dụng và các cơ hội việc làm cho tháng này tại đây nhé ạ, chúc mọi người một tuần làm việc hiệu quả",#tuyendung,
Mình dùng MLflow thì các metrics và graphs chỉ update sau khi epoch đầu tiên hoàn thành. Có cách nào để lấy được metrics theo từng step trong cả epoch đầu tiên không nhỉ?,Mình dùng MLflow thì các metrics và graphs chỉ update sau khi epoch đầu tiên hoàn thành. Có cách nào để lấy được metrics theo từng step trong cả epoch đầu tiên không nhỉ?,,
"Chào cả nhà, mình hiện tại đang tìm hiểu về kubernetes và đang dùng Docker desktop cho kubernetes trên MacOS, không biết có ai từng dùng vậy chưa cho mình xin ý kiến là có nên triển khai kubernetes thông qua Docker Desktop vậy không, hay có phương án nào thay thế trên MacOS nếu không dùng Docker Desktop không ạ?","Chào cả nhà, mình hiện tại đang tìm hiểu về kubernetes và đang dùng Docker desktop cho kubernetes trên MacOS, không biết có ai từng dùng vậy chưa cho mình xin ý kiến là có nên triển khai kubernetes thông qua Docker Desktop vậy không, hay có phương án nào thay thế trên MacOS nếu không dùng Docker Desktop không ạ?",,
"Có bác nào đã code 1 pipeline hoàn chỉnh vs pytorch có thể cho em xin đoạn code nhỏ tham khảo hoặc cho em xin nguồn tiếp cận dễ hiểu dc ko ạ, em đã tiếp cận pipeline vs TF nhưng qua pytorch tìm về content này thì đang gặp khó quá ạ. Em là beginner hy vọng được các Bác giúp đỡ, em xin cảm ơn ạ.","Có bác nào đã code 1 pipeline hoàn chỉnh vs pytorch có thể cho em xin đoạn code nhỏ tham khảo hoặc cho em xin nguồn tiếp cận dễ hiểu dc ko ạ, em đã tiếp cận pipeline vs TF nhưng qua pytorch tìm về content này thì đang gặp khó quá ạ. Em là beginner hy vọng được các Bác giúp đỡ, em xin cảm ơn ạ.",,
"Hello mn, em muốn hỏi mn 1 chút về cách mn đọc, viết và lưu trữ metadata của artifacts (models, datasets,...) trong quá trình đưa ứng dụng ML vào sản phẩm ạ (e.g: lưu trữ model nào được train bởi phiên bản data nào, trên GPU nào, metrics ra sao,...).
Em nghe nói MLFlow là 1 giải pháp không tồi vì cộng đồng lớn và dễ sử dụng, bên cạnh đó thì trong hệ sinh thái của TF có ml-metadata cũng là 1 thư viện tốt. Không biết mn có kinh nghiệm gì về những giải pháp này có thể chia sẽ không ạ.","Hello mn, em muốn hỏi mn 1 chút về cách mn đọc, viết và lưu trữ metadata của artifacts (models, datasets,...) trong quá trình đưa ứng dụng ML vào sản phẩm ạ (e.g: lưu trữ model nào được train bởi phiên bản data nào, trên GPU nào, metrics ra sao,...). Em nghe nói MLFlow là 1 giải pháp không tồi vì cộng đồng lớn và dễ sử dụng, bên cạnh đó thì trong hệ sinh thái của TF có ml-metadata cũng là 1 thư viện tốt. Không biết mn có kinh nghiệm gì về những giải pháp này có thể chia sẽ không ạ.",,
"FYI: Cơ hội học và thực hành các dịch vụ liên quan tới tới App Modernization và Data Analytics trên nền tảng Google Cloud với một tháng truy cập miễn phí Google Cloud Skills Boost (Qwiklabs) (từ 08/09 ~ 09/10). Ngoài ra còn có quà từ Google Cloud cho anh em chăm chỉ làm bài tập nha 😁
https://events.withgoogle.com/quanquangcp-challenge-1",FYI: Cơ hội học và thực hành các dịch vụ liên quan tới tới App Modernization và Data Analytics trên nền tảng Google Cloud với một tháng truy cập miễn phí Google Cloud Skills Boost (Qwiklabs) (từ 08/09 ~ 09/10). Ngoài ra còn có quà từ Google Cloud cho anh em chăm chỉ làm bài tập nha https://events.withgoogle.com/quanquangcp-challenge-1,,
"Chào mọi người, em đang làm đồ án ra trường, hiện tại em đang xây dựng mô hình để giải quyết bài toán phát hiện bất thường trong time series, cụ thể em đang xử lý với bộ data liên quan đến sensor trong nhà máy, và hiện h định hướng em muốn xây dựng 1 sản phẩm demo đúng theo quy trình mlops. Em định triển khai 2 model: thứ nhất là model phát hiện attack, thứ 2 là model phát hiện bất thường nhưng sẽ với đầu vào khác( tức theo hướng phát triển của em sẽ triển khai nhiều mô hình trên các máy trong nhà máy) và đầu vào của em là streaming và batch, quá trình sẽ có update, monitoring, logging cũng như em xây dựng pipeline để tự động các quá trình và có retrain model sau một thời gian nếu phát hiện model drift, data drift, concept drift.
Serving thì em vừa muốn sử dụng api và batch ạ.
nhưng em định sẽ triển khai trên local hiện tại em có 1 máy tính cá nhân( ram 24gb, i7-8750H, 1060 maxQ) hoặc triển khai trên cloud( triển khai vs chi phí rẻ vì chỉ mang tính demo). Em là beginner vs mlops, mới học qua quy trình cũng như các tools trong mỗi giai đoạn của mlops: kubernetes, kubeflow, seldon... . Mong các bác chỉ em hướng triển khai vs ạ. Rất cảm ơn các bác ạ 😀!","Chào mọi người, em đang làm đồ án ra trường, hiện tại em đang xây dựng mô hình để giải quyết bài toán phát hiện bất thường trong time series, cụ thể em đang xử lý với bộ data liên quan đến sensor trong nhà máy, và hiện h định hướng em muốn xây dựng 1 sản phẩm demo đúng theo quy trình mlops. Em định triển khai 2 model: thứ nhất là model phát hiện attack, thứ 2 là model phát hiện bất thường nhưng sẽ với đầu vào khác( tức theo hướng phát triển của em sẽ triển khai nhiều mô hình trên các máy trong nhà máy) và đầu vào của em là streaming và batch, quá trình sẽ có update, monitoring, logging cũng như em xây dựng pipeline để tự động các quá trình và có retrain model sau một thời gian nếu phát hiện model drift, data drift, concept drift. Serving thì em vừa muốn sử dụng api và batch ạ. nhưng em định sẽ triển khai trên local hiện tại em có 1 máy tính cá nhân( ram 24gb, i7-8750H, 1060 maxQ) hoặc triển khai trên cloud( triển khai vs chi phí rẻ vì chỉ mang tính demo). Em là beginner vs mlops, mới học qua quy trình cũng như các tools trong mỗi giai đoạn của mlops: kubernetes, kubeflow, seldon... . Mong các bác chỉ em hướng triển khai vs ạ. Rất cảm ơn các bác ạ !",,
"Xin chào mọi người.
Không biết ở trong nhóm đã có anh em nào áp dụng và sử dụng thành công nền tảng Kubeflow, đặc biệt là Kubeflow Pipelines trong thực tế chưa ạ.
Em đang thí nghiệm sử dụng nó và thấy khá loằng ngoằng trong việc viết pipelines, không biết có phải do mình sử dụng nó sai mục đích hay bản thân KFP là một nền tảng chưa hoàn thiện để cho production.","Xin chào mọi người. Không biết ở trong nhóm đã có anh em nào áp dụng và sử dụng thành công nền tảng Kubeflow, đặc biệt là Kubeflow Pipelines trong thực tế chưa ạ. Em đang thí nghiệm sử dụng nó và thấy khá loằng ngoằng trong việc viết pipelines, không biết có phải do mình sử dụng nó sai mục đích hay bản thân KFP là một nền tảng chưa hoàn thiện để cho production.",,
"[POST TUYỂN DỤNG]

Để tránh mọi người đăng bài tuyển dụng nhiều bị loãng group, mình sẽ tạo post riêng hàng tháng để mọi người comment vào post nha. 

Đây là post tuyển dụng tháng 8 luôn :D
#tuyendung","[POST TUYỂN DỤNG] Để tránh mọi người đăng bài tuyển dụng nhiều bị loãng group, mình sẽ tạo post riêng hàng tháng để mọi người comment vào post nha. Đây là post tuyển dụng tháng 8 luôn :D",#tuyendung,
"Một số Design Patterns hữu ích cho MLE
🤓 Pipeline/Workflow: xử lý một chuỗi các hàm theo thứ tự (hay được dùng trong data processing hoặc các inference framework)
🤓 Iterator: loop qua từng batch trong dataset với __iter__() và __next__()
🤓 Job Queues: từng model sẽ được lấy ra từ queue để xử lý input (hay dùng trong multi-model inference framework)
🤓 Callbacks: ví dụ theo dõi sự thay đổi của loss để cập nhật learning rate (tf.keras.callbacks.LearningRateScheduler)
🤓 Learner: bắt đầu cho model học chỉ với 1 dòng code model.fit(data)
🤓 Batch Processing: stack các input và đưa qua model để dự đoán một lần thay vì loop qua từng input
🤓 Decorator: ví dụ thêm @profile decorator để profile một hàm bất kỳ (thời gian chạy và memory sử dụng, .v.v.)
🤓 Strategy: sử dụng tính kế thừa trong OOP để implement một optimizer khác dựa trên base optimizer, điều này sẽ giúp developer không cần quan tâm nhiều tới các phần code khác
Nguồn: https://github.com/msaroufim/ml-design-patterns","Một số Design Patterns hữu ích cho MLE Pipeline/Workflow: xử lý một chuỗi các hàm theo thứ tự (hay được dùng trong data processing hoặc các inference framework) Iterator: loop qua từng batch trong dataset với __iter__() và __next__() Job Queues: từng model sẽ được lấy ra từ queue để xử lý input (hay dùng trong multi-model inference framework) Callbacks: ví dụ theo dõi sự thay đổi của loss để cập nhật learning rate (tf.keras.callbacks.LearningRateScheduler) Learner: bắt đầu cho model học chỉ với 1 dòng code model.fit(data) Batch Processing: stack các input và đưa qua model để dự đoán một lần thay vì loop qua từng input Decorator: ví dụ thêm @profile decorator để profile một hàm bất kỳ (thời gian chạy và memory sử dụng, .v.v.) Strategy: sử dụng tính kế thừa trong OOP để implement một optimizer khác dựa trên base optimizer, điều này sẽ giúp developer không cần quan tâm nhiều tới các phần code khác Nguồn: https://github.com/msaroufim/ml-design-patterns",,
"Hi mọi người, em mới deploy kubeflow theo doc của aws: https://awslabs.github.io/kubeflow-manifests/docs/deployment/Đã deploy xong, tuy nhiên bước cuối port fowarding từ kubectl thì vẫn chưa run được ở localhost, không biết đã ai ở đây bị lỗi đó và fix được chưa ạ?
kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
vào từ browser thì gặp lỗi 403 You don't have authorization to view this page.","Hi mọi người, em mới deploy kubeflow theo doc của aws: https://awslabs.github.io/kubeflow-manifests/docs/deployment/Đã deploy xong, tuy nhiên bước cuối port fowarding từ kubectl thì vẫn chưa run được ở localhost, không biết đã ai ở đây bị lỗi đó và fix được chưa ạ? kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80 vào từ browser thì gặp lỗi 403 You don't have authorization to view this page.",,
"Quá trình phát triển các sản phẩm AI luôn tồn tại những thách thức. Mời các bạn theo dõi sự kiện để lắng nghe chia sẻ từ chuyên gia hàng đầu về AI/Machine Learning/Data Scientist trong talkshow AI production challenge được tài trợ bởi công ty Neurond và tổ chức bởi DataScienceWorld.Kan.
Thời gian từ 10:45 AM-12:00 PM ngày 21-August-2022, GMT +7 VietNam time
- live stream youtube:
https://youtu.be/02FCIk8anVo
- link đặt câu hỏi:
https://forms.gle/igM4mncYFcjDhV1W6","Quá trình phát triển các sản phẩm AI luôn tồn tại những thách thức. Mời các bạn theo dõi sự kiện để lắng nghe chia sẻ từ chuyên gia hàng đầu về AI/Machine Learning/Data Scientist trong talkshow AI production challenge được tài trợ bởi công ty Neurond và tổ chức bởi DataScienceWorld.Kan. Thời gian từ 10:45 AM-12:00 PM ngày 21-August-2022, GMT +7 VietNam time - live stream youtube: https://youtu.be/02FCIk8anVo - link đặt câu hỏi: https://forms.gle/igM4mncYFcjDhV1W6",,
"Hôm nay có thời gian ngồi đọc cuốn ""Fundamentals of Data Engineering: Plan and Build Robust Data Systems, tác giả có nói
How do you keep your skills sharp in a rapidly changing field like data engineering? Should you focus on the latest tools or deep dive into fundamentals? Here’s our advice: focus on the fundamentals to understand what’s not going to change; pay attention to ongoing developments to know where the field is going
và theo em thì MLOps cũng thế. Nhiều bác hỏi em là ""Nên chọn tool nào và framework nào để xây dựng MLOps platform"", thì em cũng đều khuyên rằng: hãy tập trung vào những kiến thức nền tảng trước để biết rằng mình thực sự cần gì trong giai đoạn hiện tại. Ví dụ nếu các bác đang ở giai đoạn experimentation thì hãy quan tâm tới experimentation platform cần đảm bảo những yếu tố nào trước, sau đó mới đi lựa chọn tool phù hợp với yêu cầu đó. Các bác không nhất thiết phải dùng luôn một tool siêu nhiều chức năng, mà mất quá nhiều thời gian để học và ứng dụng nó, trong khi nhu cầu hiện tại đang gấp rút thì lại không đáp ứng được luôn 😂
Ý kiến cá nhân của em như thế, không biết các bác nghĩ sao 😂
#QnA ","Hôm nay có thời gian ngồi đọc cuốn ""Fundamentals of Data Engineering: Plan and Build Robust Data Systems, tác giả có nói How do you keep your skills sharp in a rapidly changing field like data engineering? Should you focus on the latest tools or deep dive into fundamentals? Here’s our advice: focus on the fundamentals to understand what’s not going to change; pay attention to ongoing developments to know where the field is going và theo em thì MLOps cũng thế. Nhiều bác hỏi em là ""Nên chọn tool nào và framework nào để xây dựng MLOps platform"", thì em cũng đều khuyên rằng: hãy tập trung vào những kiến thức nền tảng trước để biết rằng mình thực sự cần gì trong giai đoạn hiện tại. Ví dụ nếu các bác đang ở giai đoạn experimentation thì hãy quan tâm tới experimentation platform cần đảm bảo những yếu tố nào trước, sau đó mới đi lựa chọn tool phù hợp với yêu cầu đó. Các bác không nhất thiết phải dùng luôn một tool siêu nhiều chức năng, mà mất quá nhiều thời gian để học và ứng dụng nó, trong khi nhu cầu hiện tại đang gấp rút thì lại không đáp ứng được luôn Ý kiến cá nhân của em như thế, không biết các bác nghĩ sao",#QnA,
"Một bài hay về phân tích requirements và thiết kế MLOps platform của iFunny (ở đây nhiều memes vui phết các bác ạ :v). Các engineers của iFunny không áp dụng Kubeflow hay Feast, mà thay vào đó chọn Airflow cho pipelines và 2 DB Clickhouse và Mongo cho feature stores. Bên cạnh đó họ cũng lưu cả dữ liệu raw thay vì chỉ features vào feature store với mục đích dễ dàng update DB hơn. Các bác có thể xem chi tiết hơn về tư duy thiết kế khá mở của họ tại đây: 
https://medium.com/@FunCorp/practical-guide-to-create-a-two-layered-recommendation-system-5486b42f9f63
#systemdesign","Một bài hay về phân tích requirements và thiết kế MLOps platform của iFunny (ở đây nhiều memes vui phết các bác ạ :v). Các engineers của iFunny không áp dụng Kubeflow hay Feast, mà thay vào đó chọn Airflow cho pipelines và 2 DB Clickhouse và Mongo cho feature stores. Bên cạnh đó họ cũng lưu cả dữ liệu raw thay vì chỉ features vào feature store với mục đích dễ dàng update DB hơn. Các bác có thể xem chi tiết hơn về tư duy thiết kế khá mở của họ tại đây: https://medium.com/@FunCorp/practical-guide-to-create-a-two-layered-recommendation-system-5486b42f9f63",#systemdesign,
"Có ai đã sử dụng docker + ray + fastapi/flask để deploy API service mà chưa ạ, mình chạy bị lỗi load model xong rồi chạy để deploy API (FastAPI) thì các model bị terminate còn không chạy docker ( chỉ chạy ray + fastapi) thì vẫn chạy bình thường","Có ai đã sử dụng docker + ray + fastapi/flask để deploy API service mà chưa ạ, mình chạy bị lỗi load model xong rồi chạy để deploy API (FastAPI) thì các model bị terminate còn không chạy docker ( chỉ chạy ray + fastapi) thì vẫn chạy bình thường",,
"The Machine Learning Engineer Newsletter là một bản tin rất hay cho các bác quan tâm tới các sự kiện và các bài viết nổi bật trong tuần về chủ đề ML Engineering và MLOps
https://www.linkedin.com/newsletters/6882216044568571904/",The Machine Learning Engineer Newsletter là một bản tin rất hay cho các bác quan tâm tới các sự kiện và các bài viết nổi bật trong tuần về chủ đề ML Engineering và MLOps https://www.linkedin.com/newsletters/6882216044568571904/,,
"Cuối tuần trước em có buổi talk nhỏ ""How to operate a ML system productively"" chia sẻ một số kiến thức và kinh nghiệm cá nhân trong việc vận hành các hệ thống ML. Em xin gửi lại record và slide cho bác nào quan tâm nha :D
Video: https://www.youtube.com/watch?v=tBY5DZ5v0jQ
Slide: https://docs.google.com/presentation/d/1WEESpXdcL8qQDG4aAbdrmSYC-1BDNJGf0G9T0SkXFi4/edit?usp=sharing","Cuối tuần trước em có buổi talk nhỏ ""How to operate a ML system productively"" chia sẻ một số kiến thức và kinh nghiệm cá nhân trong việc vận hành các hệ thống ML. Em xin gửi lại record và slide cho bác nào quan tâm nha :D Video: https://www.youtube.com/watch?v=tBY5DZ5v0jQ Slide: https://docs.google.com/presentation/d/1WEESpXdcL8qQDG4aAbdrmSYC-1BDNJGf0G9T0SkXFi4/edit?usp=sharing",,
"https://us06web.zoom.us/j/89490912342?pwd=ZEVtMzF5TnRHMXd1U05nTGlWQml2QT09
Mọi người ai có time vào giao lưu cùng mình cho vui nhé ạ :D chủ đề là ""MLOps - How to operate a ML system effectively?"". Meeting đang bắt đầu. Chúc mọi người ngày cuối tuần vui vẻ.","https://us06web.zoom.us/j/89490912342?pwd=ZEVtMzF5TnRHMXd1U05nTGlWQml2QT09 Mọi người ai có time vào giao lưu cùng mình cho vui nhé ạ :D chủ đề là ""MLOps - How to operate a ML system effectively?"". Meeting đang bắt đầu. Chúc mọi người ngày cuối tuần vui vẻ.",,
"https://drive.google.com/drive/folders/1mpJAfkctfg3EspziU2faT5_sZXyUuAgQ?usp=sharing
Recordings của hội nghị MLOps: Machine Learning in Production Bay Area July '22 (https://mlopsworld.com/) cho các bác không tham gia nha
#conferences #summit",https://drive.google.com/drive/folders/1mpJAfkctfg3EspziU2faT5_sZXyUuAgQ?usp=sharing Recordings của hội nghị MLOps: Machine Learning in Production Bay Area July '22 (https://mlopsworld.com/) cho các bác không tham gia nha,#conferences	#summit,
"Bài tutorial đầu tiên của hội thảo SOICT 2022 đã được lên chương trình đến từ bạn Tung Nar.
https://soict.org/tutorial/
 — đang cảm thấy tuyệt.",Bài tutorial đầu tiên của hội thảo SOICT 2022 đã được lên chương trình đến từ bạn Tung Nar. https://soict.org/tutorial/ — đang cảm thấy tuyệt.,,
"Hi mọi người. Mình đang làm full stack data scientist. Mình đang muốn nâng cao kiến thức và chuyên môn để trở thành MLOps engineer. Programming và skills chính mình đang làm là xây dựng thuạt toán bằng python. Vậy mình cần học thêm kĩ năng gì, thuật toán gì để trở thành MLOps engineer? Nếu mọi người có career path guide, thì chỉ cho mình với. Cảm ơn mọi người.","Hi mọi người. Mình đang làm full stack data scientist. Mình đang muốn nâng cao kiến thức và chuyên môn để trở thành MLOps engineer. Programming và skills chính mình đang làm là xây dựng thuạt toán bằng python. Vậy mình cần học thêm kĩ năng gì, thuật toán gì để trở thành MLOps engineer? Nếu mọi người có career path guide, thì chỉ cho mình với. Cảm ơn mọi người.",,
"Chào các bạn, mình là tutorial chair của hội thảo SOICT 2022 diễn ra vào 4-6/12 tới tại Hà Nội và Hạ Long. Mình và BTC thấy rằng chủ đề MLOps rất hấp dẫn và nhận được nhiều sự quan tâm từ cộng đồng. Do đó, mình trân trọng có lời mời đại diện MLOps VN hoặc các cá nhân có kiến thức và kinh nghiệm trong mảng này tham gia hội thảo khoa học với tư cách diễn giả khách mời làm tutorial về chủ đề MLOps. Mình tin rằng đây là cơ hội tốt để giao lưu và chia sẻ kiến thức cho các bạn sinh viên và cộng đồng nghiên cứu AL/ML tại Việt Nam và khu vực.
Thông tin chi tiết mình sẽ chia sẻ riêng cho diễn giả. Mọi người biết ai giới thiệu giúp nhé. Xin trân trọng cảm ơn.","Chào các bạn, mình là tutorial chair của hội thảo SOICT 2022 diễn ra vào 4-6/12 tới tại Hà Nội và Hạ Long. Mình và BTC thấy rằng chủ đề MLOps rất hấp dẫn và nhận được nhiều sự quan tâm từ cộng đồng. Do đó, mình trân trọng có lời mời đại diện MLOps VN hoặc các cá nhân có kiến thức và kinh nghiệm trong mảng này tham gia hội thảo khoa học với tư cách diễn giả khách mời làm tutorial về chủ đề MLOps. Mình tin rằng đây là cơ hội tốt để giao lưu và chia sẻ kiến thức cho các bạn sinh viên và cộng đồng nghiên cứu AL/ML tại Việt Nam và khu vực. Thông tin chi tiết mình sẽ chia sẻ riêng cho diễn giả. Mọi người biết ai giới thiệu giúp nhé. Xin trân trọng cảm ơn.",,
"Bảng so sánh các model serving frameworks hiện tại (framework agnostic) để mọi người dễ dàng hơn trong việc quyết định nên dùng giải pháp nào :D. Sẽ có nhiều nội dung hay ho khác trong buổi tech talk cuối tuần này, mọi người nhớ join nha 🤣","Bảng so sánh các model serving frameworks hiện tại (framework agnostic) để mọi người dễ dàng hơn trong việc quyết định nên dùng giải pháp nào :D. Sẽ có nhiều nội dung hay ho khác trong buổi tech talk cuối tuần này, mọi người nhớ join nha",,
"Chào mọi người, hiện tại em đang support một công ty trong lĩnh vực  E-commerce tìm Machine Learning Engineer/Data Scientist để xây dựng các bài toán trong domain này, đặc biệt là bài toán recommendation. Yêu cầu là:
3 năm kinh nghiệm trong Machine Learning
Tiếng Anh: đọc hiểu được research và giao tiếp cơ bản

Mọi người quan tâm inbox em nhé. Em sẽ trao đổi chi tiết hơn về công ty cũng như vị trí ạ. Cảm ơn mọi người ^^","Chào mọi người, hiện tại em đang support một công ty trong lĩnh vực E-commerce tìm Machine Learning Engineer/Data Scientist để xây dựng các bài toán trong domain này, đặc biệt là bài toán recommendation. Yêu cầu là: 3 năm kinh nghiệm trong Machine Learning Tiếng Anh: đọc hiểu được research và giao tiếp cơ bản Mọi người quan tâm inbox em nhé. Em sẽ trao đổi chi tiết hơn về công ty cũng như vị trí ạ. Cảm ơn mọi người ^^",,
"Hello cả nhà, cuối tuần sau em sẽ có buổi nói chuyện nho nhỏ về MLOps, nội dung chủ yếu là chia sẻ kinh nghiệm của bản thân khi xây dựng và vận hành các hệ thống ML, tech stack sử dụng, tài liệu học tập, và trả lời một số câu hỏi liên quan tới lĩnh vực này. Mọi người ai quan tâm (ví dụ các bác ""Group member"" ẩn danh :v) thì join nhé ạ 😄. Chúc mọi người buổi tối tốt lành!
Link đăng ký:","Hello cả nhà, cuối tuần sau em sẽ có buổi nói chuyện nho nhỏ về MLOps, nội dung chủ yếu là chia sẻ kinh nghiệm của bản thân khi xây dựng và vận hành các hệ thống ML, tech stack sử dụng, tài liệu học tập, và trả lời một số câu hỏi liên quan tới lĩnh vực này. Mọi người ai quan tâm (ví dụ các bác ""Group member"" ẩn danh :v) thì join nhé ạ . Chúc mọi người buổi tối tốt lành! Link đăng ký:",,
"MLOps is a mess, but that is to be expected
Sáng ra đọc được bài blog insight về MLOps mà thấy sầu quá nên em xin phép được chia sẻ với cộng đồng để chúng ta thảo luận.blog insight về MLOps mà thấy sầu quá nên em xin phép được chia sẻ với cộng đồng để chúng ta thảo luận.
Bài viết nói về trạng thái hiện tại của MLOps (technical tools) vào thời điểm tháng 3 năm 2022, so sánh với DevOps và chia sẻ thêm những resources để các kỹ sư có thể dùng để navigate trong biển MLOps tools.
Em rất vui nếu mọi người có thể đọc cùng em và chia sẻ tech stack  của mình cũng như tại sao mình lại dùng những tech đó.
https://www.mihaileric.com/posts/mlops-is-a-mess/","MLOps is a mess, but that is to be expected Sáng ra đọc được bài blog insight về MLOps mà thấy sầu quá nên em xin phép được chia sẻ với cộng đồng để chúng ta thảo luận.blog insight về MLOps mà thấy sầu quá nên em xin phép được chia sẻ với cộng đồng để chúng ta thảo luận. Bài viết nói về trạng thái hiện tại của MLOps (technical tools) vào thời điểm tháng 3 năm 2022, so sánh với DevOps và chia sẻ thêm những resources để các kỹ sư có thể dùng để navigate trong biển MLOps tools. Em rất vui nếu mọi người có thể đọc cùng em và chia sẻ tech stack của mình cũng như tại sao mình lại dùng những tech đó. https://www.mihaileric.com/posts/mlops-is-a-mess/",,
"https://www.eventbrite.ca/e/mlops-machine-learning-in-production-bay-area-virtual-summit-tickets-368609509967
Một hội nghị khác về MLOps cho cả nhà, hội nghị này có phí, tuy nhiên mọi người có thể dùng promotion code ""mlopsfriends"" để có free entry (limited)
Nguồn: https://www.linkedin.com/posts/davidscharbach_bay-area-mlops-world-activity-6955923012713943040-9icB","https://www.eventbrite.ca/e/mlops-machine-learning-in-production-bay-area-virtual-summit-tickets-368609509967 Một hội nghị khác về MLOps cho cả nhà, hội nghị này có phí, tuy nhiên mọi người có thể dùng promotion code ""mlopsfriends"" để có free entry (limited) Nguồn: https://www.linkedin.com/posts/davidscharbach_bay-area-mlops-world-activity-6955923012713943040-9icB",,
"Hi mn, em muốn đăng 1 post để hỏi về giải pháp cho ML models deployment của cộng đồng ạ. Không biết mn đang tool dùng gì để deploy model lên K8s, Azure, AWS và GCP. Cá nhân em đang nghiên cứu dùng KServe nhưng nó chưa release v1.0.0 (hiện tại đang dev ở 0.9.0 và release 0.8.0).
Em không biết sử dụng KServe có ưu điểm gì so với dùng Pods/Deployment tự viết API (TFServing/Triton/TorchServe + FastAPI), so với Seldon Core và các giải pháp khác.
Những tổ chức em đã làm chủ yếu dùng API tự viết và quản lý model bởi các DevOps, em muốn so sánh phương pháp này và defend/promote việc nên dùng các giải pháp ML deployment thì không biết có các key metrics gì để highlight và so sánh ưu/nhược điểm của các giải pháp này không ạ. Vì không có background về DevOps, Microservices nên em mù tịt về khoản này ạ :<","Hi mn, em muốn đăng 1 post để hỏi về giải pháp cho ML models deployment của cộng đồng ạ. Không biết mn đang tool dùng gì để deploy model lên K8s, Azure, AWS và GCP. Cá nhân em đang nghiên cứu dùng KServe nhưng nó chưa release v1.0.0 (hiện tại đang dev ở 0.9.0 và release 0.8.0). Em không biết sử dụng KServe có ưu điểm gì so với dùng Pods/Deployment tự viết API (TFServing/Triton/TorchServe + FastAPI), so với Seldon Core và các giải pháp khác. Những tổ chức em đã làm chủ yếu dùng API tự viết và quản lý model bởi các DevOps, em muốn so sánh phương pháp này và defend/promote việc nên dùng các giải pháp ML deployment thì không biết có các key metrics gì để highlight và so sánh ưu/nhược điểm của các giải pháp này không ạ. Vì không có background về DevOps, Microservices nên em mù tịt về khoản này ạ :<",,
"Let's Architect là một series các usecases sử dụng các dịch vụ AWS, các bác có thể tham khảo các usecases này để lấy ý tưởng giải quyết các bài toán của mình. Link dưới đây là Let's Architect cho Machine Learning, ngoài ra có cả cho DevOps, Security, .v.v., mọi người có thể tự tìm đọc thêm 😂.
Chúc cả nhà buổi tối cuối tuần vui vẻ!","Let's Architect là một series các usecases sử dụng các dịch vụ AWS, các bác có thể tham khảo các usecases này để lấy ý tưởng giải quyết các bài toán của mình. Link dưới đây là Let's Architect cho Machine Learning, ngoài ra có cả cho DevOps, Security, .v.v., mọi người có thể tự tìm đọc thêm . Chúc cả nhà buổi tối cuối tuần vui vẻ!",,
Dành cho các bác đang phân vân nên chọn loại GPU nào trên AWS,Dành cho các bác đang phân vân nên chọn loại GPU nào trên AWS,,
"Một virtual event miễn phí về AI sắp tới cho bác nào quan tâm
https://register.snorkel.ai/events/04054741-5952-406b-8d37-82c8c1217083",Một virtual event miễn phí về AI sắp tới cho bác nào quan tâm https://register.snorkel.ai/events/04054741-5952-406b-8d37-82c8c1217083,,
"chào mọi người, em mới tìm hiểu về kubeflow, có 1 số thắc mắc mong mọi người giải đáp:
1 - kubeflow có cách nào cài trên local server không ?
Em có cài thử theo bản manifest nhưng khá nhiều lỗi.
Em có thử qua về minikf, nhưng bản này chạy trên máy ảo nên k dùng GPU được.
2 - Nếu mình dùng các phiên bản trên các nền tảng cloud thì có cách nào training model trên local GPU của công ty được k?","chào mọi người, em mới tìm hiểu về kubeflow, có 1 số thắc mắc mong mọi người giải đáp: 1 - kubeflow có cách nào cài trên local server không ? Em có cài thử theo bản manifest nhưng khá nhiều lỗi. Em có thử qua về minikf, nhưng bản này chạy trên máy ảo nên k dùng GPU được. 2 - Nếu mình dùng các phiên bản trên các nền tảng cloud thì có cách nào training model trên local GPU của công ty được k?",,
"Share với mọi ng một paper rất thực tế, giải thích tổng quan về MLOps, các challenges ở trong mỗi giai đoạn của một ML System, và nhiều thứ khó hiểu khác 😎
Member của một group MLOps thì ko thể bỏ qua bài này đc ;)
Link paper: https://arxiv.org/abs/2205.02302","Share với mọi ng một paper rất thực tế, giải thích tổng quan về MLOps, các challenges ở trong mỗi giai đoạn của một ML System, và nhiều thứ khó hiểu khác Member của một group MLOps thì ko thể bỏ qua bài này đc ;) Link paper: https://arxiv.org/abs/2205.02302",,
"Mình hiện đang là Data Scientist và muốn update skills để bắt nhịp kịp với thị trường cviec.
Có bootcamp online nào dạy MLOps hoặc Data Engineer chất lượng, thực hành nhiều ko các bạn?","Mình hiện đang là Data Scientist và muốn update skills để bắt nhịp kịp với thị trường cviec. Có bootcamp online nào dạy MLOps hoặc Data Engineer chất lượng, thực hành nhiều ko các bạn?",,
"Chào mọi người, em muốn hỏi là hiện e có tập data hình ảnh lưu trên cloud storage và e muốn sử dụng yolov5 để detect object trên tập data đó trực tiếp từ gg cloud mà không cần tải từ cloud xuống local ạ. Mọi người ai có kinh nghiệm cho e xin ý kiến với ạ. E thấy source có nhận từ glob mà e không biết dùng sao ạ. Cám ơn mn ạ.","Chào mọi người, em muốn hỏi là hiện e có tập data hình ảnh lưu trên cloud storage và e muốn sử dụng yolov5 để detect object trên tập data đó trực tiếp từ gg cloud mà không cần tải từ cloud xuống local ạ. Mọi người ai có kinh nghiệm cho e xin ý kiến với ạ. E thấy source có nhận từ glob mà e không biết dùng sao ạ. Cám ơn mn ạ.",,
"Cho em hỏi nhóm mình có ai dùng colab pro + chưa ạ? Cho em một số review, tiện thể nếu ai có nhu cầu share thì inbox em luôn với.","Cho em hỏi nhóm mình có ai dùng colab pro + chưa ạ? Cho em một số review, tiện thể nếu ai có nhu cầu share thì inbox em luôn với.",,
"Quick tip: Đổi domain từ github.com sang githubtocolab.com là có thể mở được notebook trên github bằng colab luôn nha mọi người 😁
Ví dụ:  https://githubtocolab.com/quan-dang/kubeflow-tutorials/blob/master/1-operators/condition.ipynb",Quick tip: Đổi domain từ github.com sang githubtocolab.com là có thể mở được notebook trên github bằng colab luôn nha mọi người Ví dụ: https://githubtocolab.com/quan-dang/kubeflow-tutorials/blob/master/1-operators/condition.ipynb,,
"🎯 [CG-HN] Tuyển dụng
✅ AI/ML ENGINEER
✅ AI/MLOps
✅ NLP ENGINEER
- Fresher - Senior
- Lương từ 14-45tr
- Đóng BH full lương. Cùng nhiều chế độ VIP
- Công ty logistics top 1 VN. Với rất nhiều dự án khủng cần giải quyết.
- Môi trường, không gian làm việc siêu cấp ...
Inbox mình nha 😃 Many thanks !","[CG-HN] Tuyển dụng AI/ML ENGINEER AI/MLOps NLP ENGINEER - Fresher - Senior - Lương từ 14-45tr - Đóng BH full lương. Cùng nhiều chế độ VIP - Công ty logistics top 1 VN. Với rất nhiều dự án khủng cần giải quyết. - Môi trường, không gian làm việc siêu cấp ... Inbox mình nha Many thanks !",,
"[Cài đặt Kubeflow lên máy tính cá nhân]
Chào mọi người,
Em đang tìm hiểu và cài đặt KubeFlow trên máy local cá nhân. Hiện tại em thấy có nhiều cách triển khai K8s lên máy cá nhân như MicroK8s, minikube. Hiện tại trên máy em đã có microk8s và minikube rồi.
Nhưng em không biết nếu cài đặt KubeFlow lên minikube trong máy tính cá nhân thì mình cài đặt như thế nào. Em có thấy một số tutorial hướng dẫn cách này nhưng từ version v0.x rồi, mà trên trang chính thức của Kubeflow bản hiện tại thì không còn hướng dẫn cài đặt KF trên minikube nữa.
Em muốn hỏi mọi thường thường cài KF lên máy cá nhân thì sẽ cài như thế nào ạ ? Em cảm ơn mọi người.
-----------------
Update: Cảm ơn bác Quan Dang
Em làm theo cách này thì cài MiniKF dễ dàng hơn:
https://v1-0-branch.kubeflow.org/docs/started/workstation/getting-started-minikf/
#MLOps #Kubeflow #caidat #hoidap","[Cài đặt Kubeflow lên máy tính cá nhân] Chào mọi người, Em đang tìm hiểu và cài đặt KubeFlow trên máy local cá nhân. Hiện tại em thấy có nhiều cách triển khai K8s lên máy cá nhân như MicroK8s, minikube. Hiện tại trên máy em đã có microk8s và minikube rồi. Nhưng em không biết nếu cài đặt KubeFlow lên minikube trong máy tính cá nhân thì mình cài đặt như thế nào. Em có thấy một số tutorial hướng dẫn cách này nhưng từ version v0.x rồi, mà trên trang chính thức của Kubeflow bản hiện tại thì không còn hướng dẫn cài đặt KF trên minikube nữa. Em muốn hỏi mọi thường thường cài KF lên máy cá nhân thì sẽ cài như thế nào ạ ? Em cảm ơn mọi người. ----------------- Update: Cảm ơn bác Quan Dang Em làm theo cách này thì cài MiniKF dễ dàng hơn: https://v1-0-branch.kubeflow.org/docs/started/workstation/getting-started-minikf/",#MLOps	#Kubeflow	#caidat	#hoidap,
"💡 How to grow as an AI Engineer? 💡
by Nguyễn Văn Tâm, AI Engineer @ Instill AI
https://www.facebook.com/instilltech/posts/565849418605636","How to grow as an AI Engineer? by Nguyễn Văn Tâm, AI Engineer @ Instill AI https://www.facebook.com/instilltech/posts/565849418605636",,
"Mọi người ơi cho em hỏi về kinh nghiệm thiết kế với ạ.
Trường hợp em có khoảng 100 models cần online, language model, tương đối lớn. Vậy thì nên:
1. Sử dụng serverless, ví dụ như aws thì nhiều lambda function
Hay là
2. Sử dụng container orchestration như k8s, như vậy cost sẽ nhiều hơn.
Em cảm ơn","Mọi người ơi cho em hỏi về kinh nghiệm thiết kế với ạ. Trường hợp em có khoảng 100 models cần online, language model, tương đối lớn. Vậy thì nên: 1. Sử dụng serverless, ví dụ như aws thì nhiều lambda function Hay là 2. Sử dụng container orchestration như k8s, như vậy cost sẽ nhiều hơn. Em cảm ơn",,
"[MLOps & ML-Engineers positions] Aimino: Creating Intelligence with Synthetic data
Gartner predicts that 60% of data being used will be synthetically generated by 2024.  By 2030, “fake data” might entirely replace real data. Synthetic data are essential when historical data become obsolete, or when real-world data collection is dangerous or difficult.
Aimino is the provider to bring Machine Learning into real applications easily with synthetic data.
Join us on this exciting journey! Feel free to reach out to our university team at hieu.cao@aimino.de or to me at tam.nguyen@aimino.de
More at: https://aimino.de/career/","[MLOps & ML-Engineers positions] Aimino: Creating Intelligence with Synthetic data Gartner predicts that 60% of data being used will be synthetically generated by 2024. By 2030, “fake data” might entirely replace real data. Synthetic data are essential when historical data become obsolete, or when real-world data collection is dangerous or difficult. Aimino is the provider to bring Machine Learning into real applications easily with synthetic data. Join us on this exciting journey! Feel free to reach out to our university team at hieu.cao@aimino.de or to me at tam.nguyen@aimino.de More at: https://aimino.de/career/",,
"Continuous training with XGboost, LightGBM and CatBoost","Continuous training with XGboost, LightGBM and CatBoost",,
"Serverless Optimization Workshop (Performance and Cost)
During this workshop you will learn some best practice technique to optimize your serverless workloads to reduce costs and improve performance. The workshop focuses on AWS Lambda however other services are used throughout including: Amazon SQS, Amazon API Gateway, Amazon DynamoDB, AWS Step Functions, AWS AppConfig
https://catalog.us-east-1.prod.workshops.aws/workshops/2d960419-7d15-44e7-b540-fd3ebeb7ce2e/en-US","Serverless Optimization Workshop (Performance and Cost) During this workshop you will learn some best practice technique to optimize your serverless workloads to reduce costs and improve performance. The workshop focuses on AWS Lambda however other services are used throughout including: Amazon SQS, Amazon API Gateway, Amazon DynamoDB, AWS Step Functions, AWS AppConfig https://catalog.us-east-1.prod.workshops.aws/workshops/2d960419-7d15-44e7-b540-fd3ebeb7ce2e/en-US",,
Một phương pháp để estimate AUC-ROC khi chưa có ground truth,Một phương pháp để estimate AUC-ROC khi chưa có ground truth,,
"Các bước để ship model lên production bởi team DoorDash Anti-Fraud DSML

Bước 0: Pre-production iterations
Train, evaluate và tune model ở môi trường development
Bước 1: Production: shadow traffic, 1% volume
Đưa model lên production với 1% shadow traffic (traffic được copy từ live traffic). Bước này nhằm sẽ đảm bảo hệ thống chạy trơn tru từ đầu đến cuối ở production.
Bước 2: Production: shadow traffic, 100% volume
Tăng traffic vào model mới lên 100% để phân tích sự ảnh hưởng của model tới business, đồng thời đảm bảo các system metrics (CPU, memory, latency, ...) không có vấn đề gì quá nghiêm trọng.
Bước 3: Experiment that compares the performance of the incumbent and new models
So sánh 2 models với nhau để xem model mới có thực sự tốt hơn ở môi trường production không, nếu có thì sẽ promote model mới này lên thay thế model incumbent.
https://doordash.engineering/2022/03/08/ship-to-production-darkly-moving-fast-staying-safe-with-ml-deployments/","Các bước để ship model lên production bởi team DoorDash Anti-Fraud DSML Bước 0: Pre-production iterations Train, evaluate và tune model ở môi trường development Bước 1: Production: shadow traffic, 1% volume Đưa model lên production với 1% shadow traffic (traffic được copy từ live traffic). Bước này nhằm sẽ đảm bảo hệ thống chạy trơn tru từ đầu đến cuối ở production. Bước 2: Production: shadow traffic, 100% volume Tăng traffic vào model mới lên 100% để phân tích sự ảnh hưởng của model tới business, đồng thời đảm bảo các system metrics (CPU, memory, latency, ...) không có vấn đề gì quá nghiêm trọng. Bước 3: Experiment that compares the performance of the incumbent and new models So sánh 2 models với nhau để xem model mới có thực sự tốt hơn ở môi trường production không, nếu có thì sẽ promote model mới này lên thay thế model incumbent. https://doordash.engineering/2022/03/08/ship-to-production-darkly-moving-fast-staying-safe-with-ml-deployments/",,
"Hello cả nhà 👨‍👩‍👦‍👦, theo yêu cầu của một số bác thì hôm nay em xin liều mạng đóng góp thêm một bài viết nho nhỏ về cách serve model sử dụng FastAPI và Kubernetes (k8s).
Chúc cả nhà một buổi tối vui vẻ 🥰","Hello cả nhà , theo yêu cầu của một số bác thì hôm nay em xin liều mạng đóng góp thêm một bài viết nho nhỏ về cách serve model sử dụng FastAPI và Kubernetes (k8s). Chúc cả nhà một buổi tối vui vẻ",,
mình tìm đồng đội ở HCMC 🥹,mình tìm đồng đội ở HCMC,,
"ML Infrastructure Interview - Part 3
Hi cả nhà, mình lại quay trở lại với series Machine Learning Infrastructure Interview đây.
Hôm nay mình viết bài này với 1 mục đích thôi. Đó là để thông báo với mọi người rằng mình vừa viết xong 2 bài mới, và cũng là 2 bài cuối cùng trong series Machine Learning Infrastructure Interview. 2 bài này nói về:
Machine Learning Infrastructure Learning Resources: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/learning-resources
Machine Learning Infrastructure Interview Questions: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/interview-questions
Okay vậy thôi, mong mọi người enjoy bộ câu hỏi interview có 1 0 2 này. Hẹn gặp mọi người trong các series khác. Tạm biệt và gud nike!","ML Infrastructure Interview - Part 3 Hi cả nhà, mình lại quay trở lại với series Machine Learning Infrastructure Interview đây. Hôm nay mình viết bài này với 1 mục đích thôi. Đó là để thông báo với mọi người rằng mình vừa viết xong 2 bài mới, và cũng là 2 bài cuối cùng trong series Machine Learning Infrastructure Interview. 2 bài này nói về: Machine Learning Infrastructure Learning Resources: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/learning-resources Machine Learning Infrastructure Interview Questions: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/interview-questions Okay vậy thôi, mong mọi người enjoy bộ câu hỏi interview có 1 0 2 này. Hẹn gặp mọi người trong các series khác. Tạm biệt và gud nike!",,
"Hi cả nhà,
Em/mình xin phép dùng clone vì trong group có người quen 🙂
Em/mình đã có 02 năm kinh nghiệm ở vị trí data scientist/analyst, giờ muốn dịch chuyển dần sang MLE thì cần chuẩn bị những gì ạ? và có cty nào ở HN (hoặc HCM, em sẵn sàng relocate) đang tìm fresher/junior MLE ko ạ? vì hình như role này ko tuyển đại trà, em chỉ thấy các cty tuyển senior MLE là chủ yếu.
Cảm ơn cả nhà nhiều. Nhờ admin duyệt giúp ạ 😀","Hi cả nhà, Em/mình xin phép dùng clone vì trong group có người quen Em/mình đã có 02 năm kinh nghiệm ở vị trí data scientist/analyst, giờ muốn dịch chuyển dần sang MLE thì cần chuẩn bị những gì ạ? và có cty nào ở HN (hoặc HCM, em sẵn sàng relocate) đang tìm fresher/junior MLE ko ạ? vì hình như role này ko tuyển đại trà, em chỉ thấy các cty tuyển senior MLE là chủ yếu. Cảm ơn cả nhà nhiều. Nhờ admin duyệt giúp ạ",,
"ML Infrastructure Interview - Part 2
Hi cả nhà, hôm nay mình viết bài này với 2 mục đích.
Mục đích thứ nhất là để cảm ơn mọi người. Sau bài đăng trong group mình tuần trước, mình đã nhận được nhiều sự quan tâm và ủng hộ từ mọi người, các tin nhắn từ các bạn có nhu cầu trao đổi trực tiếp và các chuyên gia trong ngành cần bàn luận về các vấn đề trong Machine Learning System. Cảm ơn mọi người lần nữa vì đã giúp mình có cơ hội được nói chuyện và chia sẻ.
Mục đích thứ hai là để thông báo với mọi người rằng mình vừa viết xong 2 bài tiếp theo trong loạt bài về Machine Learning Infrastructure Interview. 2 bài mới này nói về:
Machine Learning Infrastructure Roadmap: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/the-roadmap
Machine Learning Infrastructure Interview Process: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/interview-process
Hy vọng tiếp tục nhận được sự ủng hộ và nhiều tin nhắn nữa từ mọi người.
LinkedIn: https://www.linkedin.com/in/tungdao17/","ML Infrastructure Interview - Part 2 Hi cả nhà, hôm nay mình viết bài này với 2 mục đích. Mục đích thứ nhất là để cảm ơn mọi người. Sau bài đăng trong group mình tuần trước, mình đã nhận được nhiều sự quan tâm và ủng hộ từ mọi người, các tin nhắn từ các bạn có nhu cầu trao đổi trực tiếp và các chuyên gia trong ngành cần bàn luận về các vấn đề trong Machine Learning System. Cảm ơn mọi người lần nữa vì đã giúp mình có cơ hội được nói chuyện và chia sẻ. Mục đích thứ hai là để thông báo với mọi người rằng mình vừa viết xong 2 bài tiếp theo trong loạt bài về Machine Learning Infrastructure Interview. 2 bài mới này nói về: Machine Learning Infrastructure Roadmap: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/the-roadmap Machine Learning Infrastructure Interview Process: https://aiengineer.net/ml-skills/machine-learning-infrastructure-interview/interview-process Hy vọng tiếp tục nhận được sự ủng hộ và nhiều tin nhắn nữa từ mọi người. LinkedIn: https://www.linkedin.com/in/tungdao17/",,
"https://github.com/DataTalksClub/mlops-zoomcamp
Một khóa học MLOps khá hay và chi tiết đến từ DataTalksClub, mỗi tội tác giả mới update 2 module đầu 🤣","https://github.com/DataTalksClub/mlops-zoomcamp Một khóa học MLOps khá hay và chi tiết đến từ DataTalksClub, mỗi tội tác giả mới update 2 module đầu",,
Đôi khi 1 quyển sách đủ để làm thay đổi cuộc đời bạn. Đằng này những 6 cuốn. :D,Đôi khi 1 quyển sách đủ để làm thay đổi cuộc đời bạn. Đằng này những 6 cuốn. :D,,
FYI,FYI,,
Xin giới thiệu các bạn quan tâm đến việc phỏng vấn về Machine Learning ở các công ty FAANG. https://rebrand.ly/mldesignbook Bạn có thể đọc sample ở đây: https://rebrand.ly/MachineLearningDesignShort,Xin giới thiệu các bạn quan tâm đến việc phỏng vấn về Machine Learning ở các công ty FAANG. https://rebrand.ly/mldesignbook Bạn có thể đọc sample ở đây: https://rebrand.ly/MachineLearningDesignShort,,
"Chào mọi người ạ, em mới tìm hiểu về kubeflow. Hiện em đã cài đặt kubeflow thông qua microk8s và juju trên 1 máy cá nhân ko có GPU. Hiện em đang muốn add thêm 1 node từ 1 máy khác có GPU vào cluster chứa Kubeflow để dùng GPU train model cho nhanh hơn. Mọi người đã có ai làm trường hợp tương tự chưa ạ, có thể gợi ý cho em cần những gì ko ạ","Chào mọi người ạ, em mới tìm hiểu về kubeflow. Hiện em đã cài đặt kubeflow thông qua microk8s và juju trên 1 máy cá nhân ko có GPU. Hiện em đang muốn add thêm 1 node từ 1 máy khác có GPU vào cluster chứa Kubeflow để dùng GPU train model cho nhanh hơn. Mọi người đã có ai làm trường hợp tương tự chưa ạ, có thể gợi ý cho em cần những gì ko ạ",,
FYI!,FYI!,,
"#MoMo #Hanoi #HoChiMinh
✌️Em chào các anh chị, công ty M nhà em (cụ thể là M_service) rất tha thiết tuyển các vị trí: MLOPs, Machine Learning Engineer, Data Engineer, AI Software Engineer. Các vị trí open với các bạn từ 2 năm kinh nghiệm trở lên ạ.
✌️Sơ qua thông tin về môi trường:
+ Môi trường thoải mái tự do: nhân viên mặc gì thì mặc đừng mặc kệ job; không chấm công giờ làm việc, làm từ thứ 2-6. Hôm nào muốn làm việc ở nhà thì alo xin sếp, miễn đảm bảo chất lượng và kết quả công việc là được ạ;
+ Sếp, đồng nghiệp nice, team thực sự rất vui ạ. Nhân sự là key member từ Pique, background sáng, công ty startup đã sát nhập vào MoMo;
+ Văn phòng ở 444 Hoàng Hoa Thám, nếu mình có duyên thì chỗ ngồi view Hồ Tây ạ =)) chiều chiều đi làm xong lượn 1 vòng Hồ Tây về cũng khá là chill ạ;
+ Phỏng vấn online/ offline như nào cũng được, miễn là tiện cho các anh chị em, 2 vòng;
-> JD em để dưới comment ạ. Em mong nhận được sự quan tâm của mọi người.
Em cũng cảm ơn admin đã duyệt bài ạ.","Em chào các anh chị, công ty M nhà em (cụ thể là M_service) rất tha thiết tuyển các vị trí: MLOPs, Machine Learning Engineer, Data Engineer, AI Software Engineer. Các vị trí open với các bạn từ 2 năm kinh nghiệm trở lên ạ. Sơ qua thông tin về môi trường: + Môi trường thoải mái tự do: nhân viên mặc gì thì mặc đừng mặc kệ job; không chấm công giờ làm việc, làm từ thứ 2-6. Hôm nào muốn làm việc ở nhà thì alo xin sếp, miễn đảm bảo chất lượng và kết quả công việc là được ạ; + Sếp, đồng nghiệp nice, team thực sự rất vui ạ. Nhân sự là key member từ Pique, background sáng, công ty startup đã sát nhập vào MoMo; + Văn phòng ở 444 Hoàng Hoa Thám, nếu mình có duyên thì chỗ ngồi view Hồ Tây ạ =)) chiều chiều đi làm xong lượn 1 vòng Hồ Tây về cũng khá là chill ạ; + Phỏng vấn online/ offline như nào cũng được, miễn là tiện cho các anh chị em, 2 vòng; -> JD em để dưới comment ạ. Em mong nhận được sự quan tâm của mọi người. Em cũng cảm ơn admin đã duyệt bài ạ.",#MoMo	#Hanoi	#HoChiMinh,
"High-level architecture của một hệ thống Recommendation trong thực tế
Part 1: https://blog.fennel.ai/p/real-world-recommendation-system?s=w
Part 2: https://blog.fennel.ai/p/real-world-recommendation-systems?s=r",High-level architecture của một hệ thống Recommendation trong thực tế Part 1: https://blog.fennel.ai/p/real-world-recommendation-system?s=w Part 2: https://blog.fennel.ai/p/real-world-recommendation-systems?s=r,,
"Helm (https://helm.sh/) là một công cụ giúp quản lý các ứng dụng (ví dụ: install, upgrade, rollback, và uninstall, ...) trên nền tảng k8s. Mình xin chia sẻ một số kiến thức và kinh nghiệm khi làm việc với tool này, với ví dụ cụ thể là deploy MLFlow lên Kubeflow platform. Chúc cả nhà cuối tuần vui vẻ :D.","Helm (https://helm.sh/) là một công cụ giúp quản lý các ứng dụng (ví dụ: install, upgrade, rollback, và uninstall, ...) trên nền tảng k8s. Mình xin chia sẻ một số kiến thức và kinh nghiệm khi làm việc với tool này, với ví dụ cụ thể là deploy MLFlow lên Kubeflow platform. Chúc cả nhà cuối tuần vui vẻ :D.",,
"Chào m.n, Em đang gặp một số vấn đề cần sự giúp đỡ khi triển khai ứng dụng deep cho đồ án tốt nghiệp, sử dụng cloud AWS.
Mô tả: khi sử dụng Flask với phương thức get ( hình 1) cần qua 2 model GAN (65MB, 320MB) để có được output , em đã triển khai ở máy local sử dụng ngrok làm server và time client post image tới khi server trả output ~ 7s.
Tuy nhiên khi triển khai do sử dụng ec2 intance type t2.micro free nên chỉ có 1vCPU ,   khi nhận request thì server bị out CPU (quá tải) ( hình 2) và time lên đến 30s - 40s / 1 request. 
Em có thử AutoScalling , loadBlancers , do lần đầu sử dụng không biết đã khởi tạo đúng chưa.
Câu hỏi 1: do mô hình nặng nên cần phải sử dụng instance type có tính phí ( vd: t2.xlarge 4vCPU, .. )  không
2.  AutoScaling,loadBlancers tới main instance chạy port 8000 như thế nào mới chính xác ? 
Em cảm ơn.","Chào m.n, Em đang gặp một số vấn đề cần sự giúp đỡ khi triển khai ứng dụng deep cho đồ án tốt nghiệp, sử dụng cloud AWS. Mô tả: khi sử dụng Flask với phương thức get ( hình 1) cần qua 2 model GAN (65MB, 320MB) để có được output , em đã triển khai ở máy local sử dụng ngrok làm server và time client post image tới khi server trả output ~ 7s. Tuy nhiên khi triển khai do sử dụng ec2 intance type t2.micro free nên chỉ có 1vCPU , khi nhận request thì server bị out CPU (quá tải) ( hình 2) và time lên đến 30s - 40s / 1 request. Em có thử AutoScalling , loadBlancers , do lần đầu sử dụng không biết đã khởi tạo đúng chưa. Câu hỏi 1: do mô hình nặng nên cần phải sử dụng instance type có tính phí ( vd: t2.xlarge 4vCPU, .. ) không 2. AutoScaling,loadBlancers tới main instance chạy port 8000 như thế nào mới chính xác ? Em cảm ơn.",,
"Skillset của Site Reliability Engineers (SREs) đóng một vai trò quan trọng trong quá trình thiết kế và triển khai các hệ thống ML, hy vọng tài liệu của LinkedIn sẽ có ích với mọi người.
https://linkedin.github.io/school-of-sre/","Skillset của Site Reliability Engineers (SREs) đóng một vai trò quan trọng trong quá trình thiết kế và triển khai các hệ thống ML, hy vọng tài liệu của LinkedIn sẽ có ích với mọi người. https://linkedin.github.io/school-of-sre/",,
"Sau rất nhiều ngày tháng chầy bửa, em xin được ra mắt phần 2 cho series Seldon Core, nói về autoscale, metrics, và health checks, các bác cứ ném đá mạnh tay nha =))) Chúc cả nhà cuối tuần vui vẻ 🥳","Sau rất nhiều ngày tháng chầy bửa, em xin được ra mắt phần 2 cho series Seldon Core, nói về autoscale, metrics, và health checks, các bác cứ ném đá mạnh tay nha =))) Chúc cả nhà cuối tuần vui vẻ",,
,nan,,
"Mọi người cho em hỏi kinh nghiệm tích hợp MNN trên android ạ!
Hiện tại em có 1 model yolov5 đã được convert sang MNN, và hiện code C++ để predict với model yolov5.mnn đã hoạt động trên môi trường Ubuntu, nhưng khi build MNN và tích hợp vô android, em có thay đổi CMakeLists.txt của repo MNN để build MNN cho ẢRMv8, và link đường dẫn include và đường dẫn libMNN.so đầy đủ trong CMakeLists của android project. Sau khi thực hiện build project của em, em bị lỗi
error: undefined reference to 'MNN::Tensor::create(std::__ndk1::vector<int, std::__ndk1::allocator<int> > const&, halide_type_t, void*, MNN::Tensor::DimensionType)'
trong khi trong file Tensor.hpp chỉ định nghĩa:
static Tensor* create(const std::vector<int>& shape, void* data = NULL, DimensionType dimType = TENSORFLOW)
chỉ có hàm đầu vào kiểu std::vector không có đầu vào kiểu std::__ndk1::vector.
Mọi người cho em hỏi em có quên bước config gì đó trong android project để android studio biết chuyển từ std::__ndk1::vector sang std::vector không.","Mọi người cho em hỏi kinh nghiệm tích hợp MNN trên android ạ! Hiện tại em có 1 model yolov5 đã được convert sang MNN, và hiện code C++ để predict với model yolov5.mnn đã hoạt động trên môi trường Ubuntu, nhưng khi build MNN và tích hợp vô android, em có thay đổi CMakeLists.txt của repo MNN để build MNN cho ẢRMv8, và link đường dẫn include và đường dẫn libMNN.so đầy đủ trong CMakeLists của android project. Sau khi thực hiện build project của em, em bị lỗi error: undefined reference to 'MNN::Tensor::create(std::__ndk1::vector<int, std::__ndk1::allocator<int> > const&, halide_type_t, void*, MNN::Tensor::DimensionType)' trong khi trong file Tensor.hpp chỉ định nghĩa: static Tensor* create(const std::vector<int>& shape, void* data = NULL, DimensionType dimType = TENSORFLOW) chỉ có hàm đầu vào kiểu std::vector không có đầu vào kiểu std::__ndk1::vector. Mọi người cho em hỏi em có quên bước config gì đó trong android project để android studio biết chuyển từ std::__ndk1::vector sang std::vector không.",,
"In this book we present a balance of fundamentals as well as practical know-how to fully equip you to go ahead and optimize your model training and deployment workflows such that your models perform as well or better than earlier, with a fraction of resources. We also will present deep dives into popular models, infrastructure, and hardware, along with challenging projects to test your skills.
FYI: https://efficientdlbook.com/","In this book we present a balance of fundamentals as well as practical know-how to fully equip you to go ahead and optimize your model training and deployment workflows such that your models perform as well or better than earlier, with a fraction of resources. We also will present deep dives into popular models, infrastructure, and hardware, along with challenging projects to test your skills. FYI: https://efficientdlbook.com/",,
"Hi cả nhà, bạn mình làm bên VNM nhờ chia sẻ link tuyển dung DS
https://www.linkedin.com/jobs/view/3032779073
Thanks Mod đã approve post","Hi cả nhà, bạn mình làm bên VNM nhờ chia sẻ link tuyển dung DS https://www.linkedin.com/jobs/view/3032779073 Thanks Mod đã approve post",,
"Machine Learning Cheatsheet cho các bác nào bỗng nhiên một ngày không còn nhớ thuật toán do ngồi nghịch infra quá lâu :v
Nguồn: https://www.linkedin.com/posts/imarpit_machine-learning-cheatsheet-activity-6918744155485536256-v_SS?utm_source=linkedin_share&utm_medium=member_desktop_web",Machine Learning Cheatsheet cho các bác nào bỗng nhiên một ngày không còn nhớ thuật toán do ngồi nghịch infra quá lâu :v Nguồn: https://www.linkedin.com/posts/imarpit_machine-learning-cheatsheet-activity-6918744155485536256-v_SS?utm_source=linkedin_share&utm_medium=member_desktop_web,,
"DESIGN ML SYSTEM ĐỂ SERVE ~100 MODELS
Hi mọi người, hôm bữa bạn Khanh Pham có post 1 câu hỏi về ML system design khá hay. Mình định comment trả lời mà thấy quá dài nên mình viết 1 post riêng, mọi ng thông cảm ;)
CÂU HỎI
Serve ~100 language models online, thì:
1. Dùng serverless, như AWS Lambda
Hay
2. Dùng container orchestration tools, như k8s

TRẢ LỜI NGẮN
Nên dùng container orchestration như k8s (EKS, GKE, AKS), hoặc ECS, etc., vì:
1. Auto horizontal-scale dựa trên CPU, memory, hoặc custom metrics.
2. Auto manage cả tá containers, full quyền quản lý metrics và logs
3. Mấy ông bác Google, Spotify, Grab, Airbnb, etc. toàn dùng container orchestration

Ko dùng serverless vì:
1. Ko đảm bảo uptime/high availability vì nếu không có request thì container sẽ bị cho ngủ hoặc die.
2. Bị phụ thuộc vào 1 nhà cung cấp: AWS, GCP, etc.
3. Debug khó vì nhà cung cấp hạn chế log của backend.

TRẢ LỜI DÀI
Khi nói đến ML serving platform ở production, mình thường nghĩ đến những yếu tố sau:
- Deployment pattern
- Deployment strategy (rolling, canary, blue/green)
- High availability
- Scalability
- Model compression/optimization
- Monitoring & maintenance
- CI/CD/CT automation
- Khác: data provider constraints, customer privacy, data/model security/encryption, access control, etc.

Để trả lời câu hỏi trên, mình sẽ phân tích 3 thứ: Deployment pattern, High availability, và Scalability.

1. Deployment pattern
Khi serve vài trăm, vài ngàn models, thì chúng ta dùng microservices architecture (pros và cons mình ko bàn đến). Các layers trong 1 ML serving system thường được abstract như sau:
- Layer 1: Inference Services
- Layer 2: Model Inference Services
- Layer 3: Model Repository
Giải thích: Khi có request tới, request ko được đưa thẳng tới Model Inference Services (MIS) mà được đưa qua Inference Services (IS) trước. IS tập trung vào các tác vụ I/O để deliver request/response tới nơi cần tới, còn MIS tập trung vào các tác vụ nặng tính toán như model inference. MIS sẽ download model từ Model Repository.
Cả serverless và container orchestration tools đều support microservices rất tốt. Tuy nhiên nếu dùng serverless như AWS Lambda, khả năng sẽ không support GPU. Nếu dùng container orchestration như AWS EKS hay AWS ECS thì có support GPU. Debug và viết integration test cho AWS Lambda (inter-communication giữa các services) cũng khá là ""nhục"".

2. High availability
Như ở câu trả lời ngắn trên, serverless ko đảm bảo uptime. Còn container orchestration sẽ ko kill container nào kể cả khi ko có request nào.

3. Scalability
- Horizontal-scaling: AWS Lambda có khả năng scale tự động số instances lên tới 3000 instances/region khi request tăng lên. Container orchestration thì khỏi phải bàn, tự động tạo replicas theo đúng những gì bạn bảo nó làm. Metrics dùng để scale serverless instances nếu muốn custom thì thường phải tích hợp với các service khác của nhà cung cấp (AWS SNS, CloudWatch events). Metrics dùng để scale trong container orchestration được quản lý bởi 1 server (vd. metrics server trong k8s).
- Multi-model serving per container: nếu mỗi model chạy trên 1 container thì sẽ ổn với số lượng vài trăm models. Nhưng nếu scale lên vài trăm nghìn models, thì sẽ có một vài trở ngại. 1) có model thì chạy, có model lại ko chạy, resource thì bị chiếm 1 phần mà ko dùng. 2) Số lượng container bị giới hạn kể cả với AWS Lambda hay container orchestration (dù là k8s hay ECS). Serve vài model trong 1 container sẽ giải quyết được 2 vấn đề này.
- Caching: Dùng AWS Lambda thì sẽ được hỗ trợ phần cache nhiệt tình, nhưng technology sẽ bị phụ thuộc vào AWS. Dùng container orchestration sẽ customize được technology (vd: Redis), nhưng sẽ thêm đau đầu khi design cache system.

4. Chi phí
Phần này mình bổ sung thêm vì bạn Khanh Pham có nhắc tới. Dù là serverless hay container orchestration, bạn chỉ trả tiền cho resources bạn dùng, phụ thuộc vào mức độ high availability yêu cầu. Ví dụ nếu bạn cần high availability lên tới 99.9..9 % (11 số 9) thì đương nhiên cần dùng container orchestration. Càng nhiều số 9 thì chi phí sẽ càng đắt, vì resources cứ alive 24/24. Ngoài ra AWS EKS có thu thêm phụ phí trông trẻ để theo dõi k8s cluster $0.1/h.

TÓM LẠI
Đọc phần trả lời ngắn ở trên để được tóm lại.
Câu trả lời đã quá dài không tránh khỏi sai sót về logic và tình hình technology hiện tại. Bạn đọc cân nhắc :)))

REFERENCES
- https://bejamas.io/blog/serverless-architectures/
- https://towardsdatascience.com/serve-hundreds-to-thousands-of-ml-models-architectures-from-industry-bf3d9474d427
- https://docs.aws.amazon.com/whitepapers/latest/microservices-on-aws/microservices-on-aws.html
- https://aws.amazon.com/blogs/compute/operating-lambda-application-design-scaling-and-concurrency-part-2/
- https://aws.amazon.com/blogs/architecture/data-caching-across-microservices-in-a-serverless-architecture/
- https://netflixtechblog.com/announcing-evcache-distributed-in-memory-datastore-for-cloud-c26a698c27f7","DESIGN ML SYSTEM ĐỂ SERVE ~100 MODELS Hi mọi người, hôm bữa bạn Khanh Pham có post 1 câu hỏi về ML system design khá hay. Mình định comment trả lời mà thấy quá dài nên mình viết 1 post riêng, mọi ng thông cảm ;) CÂU HỎI Serve ~100 language models online, thì: 1. Dùng serverless, như AWS Lambda Hay 2. Dùng container orchestration tools, như k8s TRẢ LỜI NGẮN Nên dùng container orchestration như k8s (EKS, GKE, AKS), hoặc ECS, etc., vì: 1. Auto horizontal-scale dựa trên CPU, memory, hoặc custom metrics. 2. Auto manage cả tá containers, full quyền quản lý metrics và logs 3. Mấy ông bác Google, Spotify, Grab, Airbnb, etc. toàn dùng container orchestration Ko dùng serverless vì: 1. Ko đảm bảo uptime/high availability vì nếu không có request thì container sẽ bị cho ngủ hoặc die. 2. Bị phụ thuộc vào 1 nhà cung cấp: AWS, GCP, etc. 3. Debug khó vì nhà cung cấp hạn chế log của backend. TRẢ LỜI DÀI Khi nói đến ML serving platform ở production, mình thường nghĩ đến những yếu tố sau: - Deployment pattern - Deployment strategy (rolling, canary, blue/green) - High availability - Scalability - Model compression/optimization - Monitoring & maintenance - CI/CD/CT automation - Khác: data provider constraints, customer privacy, data/model security/encryption, access control, etc. Để trả lời câu hỏi trên, mình sẽ phân tích 3 thứ: Deployment pattern, High availability, và Scalability. 1. Deployment pattern Khi serve vài trăm, vài ngàn models, thì chúng ta dùng microservices architecture (pros và cons mình ko bàn đến). Các layers trong 1 ML serving system thường được abstract như sau: - Layer 1: Inference Services - Layer 2: Model Inference Services - Layer 3: Model Repository Giải thích: Khi có request tới, request ko được đưa thẳng tới Model Inference Services (MIS) mà được đưa qua Inference Services (IS) trước. IS tập trung vào các tác vụ I/O để deliver request/response tới nơi cần tới, còn MIS tập trung vào các tác vụ nặng tính toán như model inference. MIS sẽ download model từ Model Repository. Cả serverless và container orchestration tools đều support microservices rất tốt. Tuy nhiên nếu dùng serverless như AWS Lambda, khả năng sẽ không support GPU. Nếu dùng container orchestration như AWS EKS hay AWS ECS thì có support GPU. Debug và viết integration test cho AWS Lambda (inter-communication giữa các services) cũng khá là ""nhục"". 2. High availability Như ở câu trả lời ngắn trên, serverless ko đảm bảo uptime. Còn container orchestration sẽ ko kill container nào kể cả khi ko có request nào. 3. Scalability - Horizontal-scaling: AWS Lambda có khả năng scale tự động số instances lên tới 3000 instances/region khi request tăng lên. Container orchestration thì khỏi phải bàn, tự động tạo replicas theo đúng những gì bạn bảo nó làm. Metrics dùng để scale serverless instances nếu muốn custom thì thường phải tích hợp với các service khác của nhà cung cấp (AWS SNS, CloudWatch events). Metrics dùng để scale trong container orchestration được quản lý bởi 1 server (vd. metrics server trong k8s). - Multi-model serving per container: nếu mỗi model chạy trên 1 container thì sẽ ổn với số lượng vài trăm models. Nhưng nếu scale lên vài trăm nghìn models, thì sẽ có một vài trở ngại. 1) có model thì chạy, có model lại ko chạy, resource thì bị chiếm 1 phần mà ko dùng. 2) Số lượng container bị giới hạn kể cả với AWS Lambda hay container orchestration (dù là k8s hay ECS). Serve vài model trong 1 container sẽ giải quyết được 2 vấn đề này. - Caching: Dùng AWS Lambda thì sẽ được hỗ trợ phần cache nhiệt tình, nhưng technology sẽ bị phụ thuộc vào AWS. Dùng container orchestration sẽ customize được technology (vd: Redis), nhưng sẽ thêm đau đầu khi design cache system. 4. Chi phí Phần này mình bổ sung thêm vì bạn Khanh Pham có nhắc tới. Dù là serverless hay container orchestration, bạn chỉ trả tiền cho resources bạn dùng, phụ thuộc vào mức độ high availability yêu cầu. Ví dụ nếu bạn cần high availability lên tới 99.9..9 % (11 số 9) thì đương nhiên cần dùng container orchestration. Càng nhiều số 9 thì chi phí sẽ càng đắt, vì resources cứ alive 24/24. Ngoài ra AWS EKS có thu thêm phụ phí trông trẻ để theo dõi k8s cluster $0.1/h. TÓM LẠI Đọc phần trả lời ngắn ở trên để được tóm lại. Câu trả lời đã quá dài không tránh khỏi sai sót về logic và tình hình technology hiện tại. Bạn đọc cân nhắc :))) REFERENCES - https://bejamas.io/blog/serverless-architectures/ - https://towardsdatascience.com/serve-hundreds-to-thousands-of-ml-models-architectures-from-industry-bf3d9474d427 - https://docs.aws.amazon.com/whitepapers/latest/microservices-on-aws/microservices-on-aws.html - https://aws.amazon.com/blogs/compute/operating-lambda-application-design-scaling-and-concurrency-part-2/ - https://aws.amazon.com/blogs/architecture/data-caching-across-microservices-in-a-serverless-architecture/ - https://netflixtechblog.com/announcing-evcache-distributed-in-memory-datastore-for-cloud-c26a698c27f7",,
"Thân chào các Admin và anh chị em trong group!
Xin phép admin cho mình chia sẻ với các anh chị em về một Online Seminar về Industrial AI Engineering công ty mình sắp tổ chức: http://bit.ly/industrial-ai-eng
Công ty mình mong mang tới cộng đồng các anh chị em có backgrounds về Vật lý, Kỹ thuật, MLOps, … những thông tin có ích qua hội thảo này. Bọn mình sẽ chia sẻ về một số nội dung chính như sau về việc áp dụng AI trong các ngành công nghiệp nặng:
Các cơ hội và thử thách lớn trong Industrial AI
Các ứng dụng AI trong công nghiệp điển hình trong Hàng hải và Chuỗi cung ứng
Phương pháp áp dụng Domain Expertise vào AI trong công nghiệp (“Knowledge-First AI"")
Nghiệp vụ AI Engineering để xây dựng các hệ thống AI phức hợp
Các công việc hàng ngày của AI Engineers làm Industrial AI

Hẹn gặp mọi người ở Online Seminar! Mình xin cảm ơn.","Thân chào các Admin và anh chị em trong group! Xin phép admin cho mình chia sẻ với các anh chị em về một Online Seminar về Industrial AI Engineering công ty mình sắp tổ chức: http://bit.ly/industrial-ai-eng Công ty mình mong mang tới cộng đồng các anh chị em có backgrounds về Vật lý, Kỹ thuật, MLOps, … những thông tin có ích qua hội thảo này. Bọn mình sẽ chia sẻ về một số nội dung chính như sau về việc áp dụng AI trong các ngành công nghiệp nặng: Các cơ hội và thử thách lớn trong Industrial AI Các ứng dụng AI trong công nghiệp điển hình trong Hàng hải và Chuỗi cung ứng Phương pháp áp dụng Domain Expertise vào AI trong công nghiệp (“Knowledge-First AI"") Nghiệp vụ AI Engineering để xây dựng các hệ thống AI phức hợp Các công việc hàng ngày của AI Engineers làm Industrial AI Hẹn gặp mọi người ở Online Seminar! Mình xin cảm ơn.",,
"Mình xin giới thiệu 1 số NLP project từ cơ bản đến nâng cao có source code và dataset để ae tham khảo.
thanks all.",Mình xin giới thiệu 1 số NLP project từ cơ bản đến nâng cao có source code và dataset để ae tham khảo. thanks all.,,
"Chào các Admin và mọi người, hiện tại công ty em là Aimesoft đang tìm kiếm các Optimization/AIgorithm Engineer và NLP Engineer. Em có đọc kỹ Quy tắc nhóm nhưng không thấy nói về vấn đề tuyển dụng nên xin phép đăng bài. Nếu không phù hợp thì nhờ mọi người nhắc em, em sẽ sửa hoặc xóa ạ.
1. Về công ty: Aimesoft là công ty chuyên về các sản phẩm và giải pháp trí tuệ nhân tạo (đặc biệt là Multimodal AI) tại Hà Nội.

2. Về vị trí tuyển dụng:
2.1. Optimization/AIgorithm Engineer: https://bom.so/nVsDj6
- Giải quyết các bài toán liên quan đến tối ưu hoá tổ hợp.
- Giải quyết các bài toán lập lịch, matching, luồng,...
- Giải quyết các bài toán liên quan đến đồ thị.
- Đảm nhiệm quá trình từ mô hình hoá (thiết kế thuật toán) đến lập trình, đánh giá, tích hợp hệ thống.

2.2. NLP Engineer: https://bom.so/lme0YIG
-Nghiên cứu và ứng dụng các mô hình NLP vào hệ thống lớn của khách hàng.
-Tham gia xây dựng sản phẩm chiến lược của Aimesoft như trợ lý ảo AimeReception, AimeTalk, AimeMasking,...
-Trực tiếp nghiên cứu, phát triển các thuật toán NLP mang tính ứng dụng cao, đồng thời triển khai hệ thống phần mềm giải quyết các bài toán nổi cộm hiện nay như Medical, Question & Answering System, ChatBot,...

3. Về phương thức liên hệ: Mọi người quan tâm có thể inbox trực tiếp hoặc gửi CV đến huechi@aimesoft.com để em support mọi người nhé. Em cảm ơn ạ!","Chào các Admin và mọi người, hiện tại công ty em là Aimesoft đang tìm kiếm các Optimization/AIgorithm Engineer và NLP Engineer. Em có đọc kỹ Quy tắc nhóm nhưng không thấy nói về vấn đề tuyển dụng nên xin phép đăng bài. Nếu không phù hợp thì nhờ mọi người nhắc em, em sẽ sửa hoặc xóa ạ. 1. Về công ty: Aimesoft là công ty chuyên về các sản phẩm và giải pháp trí tuệ nhân tạo (đặc biệt là Multimodal AI) tại Hà Nội. 2. Về vị trí tuyển dụng: 2.1. Optimization/AIgorithm Engineer: https://bom.so/nVsDj6 - Giải quyết các bài toán liên quan đến tối ưu hoá tổ hợp. - Giải quyết các bài toán lập lịch, matching, luồng,... - Giải quyết các bài toán liên quan đến đồ thị. - Đảm nhiệm quá trình từ mô hình hoá (thiết kế thuật toán) đến lập trình, đánh giá, tích hợp hệ thống. 2.2. NLP Engineer: https://bom.so/lme0YIG -Nghiên cứu và ứng dụng các mô hình NLP vào hệ thống lớn của khách hàng. -Tham gia xây dựng sản phẩm chiến lược của Aimesoft như trợ lý ảo AimeReception, AimeTalk, AimeMasking,... -Trực tiếp nghiên cứu, phát triển các thuật toán NLP mang tính ứng dụng cao, đồng thời triển khai hệ thống phần mềm giải quyết các bài toán nổi cộm hiện nay như Medical, Question & Answering System, ChatBot,... 3. Về phương thức liên hệ: Mọi người quan tâm có thể inbox trực tiếp hoặc gửi CV đến huechi@aimesoft.com để em support mọi người nhé. Em cảm ơn ạ!",,
"Kubeflow là một công cụ hữu ích để build pipelines, tuy nhiên document hơi khó hiểu và khó theo dõi (ít nhất là với em :v). Do đó em đã tổng hợp và viết thêm một vài tutorials nhỏ về kubeflow pipelines, hy vọng có ích cho mọi người.","Kubeflow là một công cụ hữu ích để build pipelines, tuy nhiên document hơi khó hiểu và khó theo dõi (ít nhất là với em :v). Do đó em đã tổng hợp và viết thêm một vài tutorials nhỏ về kubeflow pipelines, hy vọng có ích cho mọi người.",,
"Boxkite là một tool cho phép track và expose model và data drift. Prometheus sẽ scrape các metrics này và hiển thị trên Grafana dashboard như hình bên dưới. Không biết bác nào dùng tool này chưa nhỉ 😂
https://boxkite.ml/en/latest/using/",Boxkite là một tool cho phép track và expose model và data drift. Prometheus sẽ scrape các metrics này và hiển thị trên Grafana dashboard như hình bên dưới. Không biết bác nào dùng tool này chưa nhỉ https://boxkite.ml/en/latest/using/,,
"Kinh nghiệm để tăng độ chính xác cho bài toán phân loại từ 70% lên 99% bởi kỹ sư Amazon 🤣 
https://www.linkedin.com/posts/rohankamath_i-was-a-part-of-the-fraud-detection-team-activity-6907684110697943040-0isE/",Kinh nghiệm để tăng độ chính xác cho bài toán phân loại từ 70% lên 99% bởi kỹ sư Amazon https://www.linkedin.com/posts/rohankamath_i-was-a-part-of-the-fraud-detection-team-activity-6907684110697943040-0isE/,,
"Em chào mọi người.
Hiện tại em đang là sinh viên năm 2 đang muốn tìm vị trí thực tập MLE ở TP HCM.
Em đã nắm rõ các kiến thức của ML, NLP, CV. Mong mọi người giới thiệu cho em vài công ty với ạ.","Em chào mọi người. Hiện tại em đang là sinh viên năm 2 đang muốn tìm vị trí thực tập MLE ở TP HCM. Em đã nắm rõ các kiến thức của ML, NLP, CV. Mong mọi người giới thiệu cho em vài công ty với ạ.",,
"Hi mọi người, như anh Phuoc Trinh đã đề cập ở post trước, thì 20h tối nay mình có buổi chia sẻ nhỏ về Kubeflow, mọi người quan tâm thì join cùng cho vui nha :D. Chúc cả nhà buổi tối vui vẻ 🥳
Thời gian: 20h 
Link Zoom: [https://zoom.us/j/94136472952?pwd=MzhUd0JKS3Y2MDVtV0VHUEFiOXdXdz09](https://zoom.us/j/94136472952?pwd=MzhUd0JKS3Y2MDVtV0VHUEFiOXdXdz09)   
Meeting ID: 941 3647 2952  
Passcode: 509418","Hi mọi người, như anh Phuoc Trinh đã đề cập ở post trước, thì 20h tối nay mình có buổi chia sẻ nhỏ về Kubeflow, mọi người quan tâm thì join cùng cho vui nha :D. Chúc cả nhà buổi tối vui vẻ Thời gian: 20h Link Zoom: [https://zoom.us/j/94136472952?pwd=MzhUd0JKS3Y2MDVtV0VHUEFiOXdXdz09](https://zoom.us/j/94136472952?pwd=MzhUd0JKS3Y2MDVtV0VHUEFiOXdXdz09) Meeting ID: 941 3647 2952 Passcode: 509418",,
Bác nào còn thức thì xem cho vui 😆,Bác nào còn thức thì xem cho vui,,
"Mời 500 anh em tham gia, thảo luận và kết nối nhé. Thanks :)","Mời 500 anh em tham gia, thảo luận và kết nối nhé. Thanks :)",,
Một số hướng để debug K8S deployments,Một số hướng để debug K8S deployments,,
"Scalability in Machine Learning: Grow your model to serve millions of users
Quá trình scale hệ thống của 1 startup AI từ 1 tới 1 triệu user
https://theaisummer.com/scalability",Scalability in Machine Learning: Grow your model to serve millions of users Quá trình scale hệ thống của 1 startup AI từ 1 tới 1 triệu user https://theaisummer.com/scalability,,
Bài giảng của chị Huyền Chip về monitor và update model trong môi trường production.,Bài giảng của chị Huyền Chip về monitor và update model trong môi trường production.,,
"Nhân dịp tết đến xuân về, thay mặt ban quản trị MLOps VN (cụ thể là em và một ông nữa mới thêm là Nguyễn Việt Anh :v) xin chúc các bác một năm mới an khang thịnh vượng, deploy model không bao giờ bị gãy trên production.
Em xin gửi tới các bác bài blog chia sẻ kinh nghiệm serving model trên Kubernetes sử dụng Seldon Core này như là một món quà nho nhỏ, thay lời cảm ơn các bác đã đồng hành cùng em trong suốt một năm qua. Năm mới em hứa sẽ chăm đăng bài hơn, tuyển thêm các admin khác, và sẽ tổ chức buổi giao lưu sớm để tăng tinh thần đồng đội hơn :v.
HAPPY NEW YEAR! 💋🤩🥳💪","Nhân dịp tết đến xuân về, thay mặt ban quản trị MLOps VN (cụ thể là em và một ông nữa mới thêm là Nguyễn Việt Anh :v) xin chúc các bác một năm mới an khang thịnh vượng, deploy model không bao giờ bị gãy trên production. Em xin gửi tới các bác bài blog chia sẻ kinh nghiệm serving model trên Kubernetes sử dụng Seldon Core này như là một món quà nho nhỏ, thay lời cảm ơn các bác đã đồng hành cùng em trong suốt một năm qua. Năm mới em hứa sẽ chăm đăng bài hơn, tuyển thêm các admin khác, và sẽ tổ chức buổi giao lưu sớm để tăng tinh thần đồng đội hơn :v. HAPPY NEW YEAR!",,
"Xin phép admin và mọi người cho mình được đăng tin tuyển dụng trong group này.
[HN] TPBank tuyển dụng Chuyên gia Vận hành Mô hình **
Trung tâm Quản trị dữ liệu - Khối CNTT đang cần tuyển 3 vị trí Chuyên gia/ Chuyên viên cao cấp/ Chuyên viên chính Vận hành mô hình.
☑️ Nếu bạn là người có kinh nghiệm MLOps từ 1-2 năm
Hoặc
☑️ Nếu bạn là người có kinh nghiệm Data engineer/ DevOps/ Software Engineer từ 2-4 năm và có hứng thú với MLOps
Welcome các bạn tham gia vào team PTDL - Trung Tâm Quản trị dữ liệu của TPBank!
Mô tả công việc:
1. Phụ trách việc đưa các mô hình ML lên môi trường production dựa trên BRD: chuyển đổi code phát triển thành code vận hành, phát triển API hoặc deploy mô hình trên các platform chuyên dụng như IBM Watson Machine Learning/ OpenScale hoặc phối hợp với team DevOps để tích hợp trực tiếp lên trên hệ thống vận hành/ứng dụng tại NH
2. Phối hợp với team DS để lên kế hoạch hiệu chỉnh, bảo dưỡng mô hình ML trong trường hợp hiệu năng mô hình thấp hơn ngưỡng cho phép
3. Nghiên cứu, thử nghiệm để từng bước áp dụng quy trình CI/CD và thực hành DataOps trong vòng đời phát triển/ vận hành của các mô hình ML (Continuous Delivery for Machine Learning)
******
Chúng tôi không đòi hỏi bạn:
❌ Xây dựng mô hình ML
❌ Xây dựng và phát triển data pipeline cho các mô hình
❌ Phát triển phần mềm ứng dụng
Chúng tôi cần bạn:
☑️ Đọc hiểu được code phát triển của team DS để chuyển đổi thành code vận hành
☑️ Đặt đầu bài cho các team DevOps/ DE để thiết kế data pipeline cũng như tích hợp mô hình vào trong hệ thống vận hành/ ứng dụng trên môi trường production
Mức đãi ngộ:
+ Mức lương đối với vị trí chuyên gia 60-100m/ tháng
++ Tổng thu nhập gồm lương thưởng 16-18 tháng lương/ năm
+++ Incentive theo hiệu quả công việc hằng quý
++++ Sử dụng nền tảng commercial IBM cloud pak for Data - được đánh giá là leader trong nhóm nền tảng về Data Science & Machine Learning năm 2021 theo Gartner (https://www.ibm.com/blogs/journey-to-ai/2021/03/ibm-is-named-a-leader-2021-magic-quadrant-for-data-science-and-machine-learning-platforms/)
+++++ Tài khoản coursera phục vụ mục tiêu tự đào tạo/ phát triển năng lực bản thân
=======
Các bạn quan tâm vui lòng liên hệ trực tiếp hoặc gửi CV về email lynm@tpb.com.vn.
Cảm ơn các bạn!","Xin phép admin và mọi người cho mình được đăng tin tuyển dụng trong group này. [HN] TPBank tuyển dụng Chuyên gia Vận hành Mô hình ** Trung tâm Quản trị dữ liệu - Khối CNTT đang cần tuyển 3 vị trí Chuyên gia/ Chuyên viên cao cấp/ Chuyên viên chính Vận hành mô hình. Nếu bạn là người có kinh nghiệm MLOps từ 1-2 năm Hoặc Nếu bạn là người có kinh nghiệm Data engineer/ DevOps/ Software Engineer từ 2-4 năm và có hứng thú với MLOps Welcome các bạn tham gia vào team PTDL - Trung Tâm Quản trị dữ liệu của TPBank! Mô tả công việc: 1. Phụ trách việc đưa các mô hình ML lên môi trường production dựa trên BRD: chuyển đổi code phát triển thành code vận hành, phát triển API hoặc deploy mô hình trên các platform chuyên dụng như IBM Watson Machine Learning/ OpenScale hoặc phối hợp với team DevOps để tích hợp trực tiếp lên trên hệ thống vận hành/ứng dụng tại NH 2. Phối hợp với team DS để lên kế hoạch hiệu chỉnh, bảo dưỡng mô hình ML trong trường hợp hiệu năng mô hình thấp hơn ngưỡng cho phép 3. Nghiên cứu, thử nghiệm để từng bước áp dụng quy trình CI/CD và thực hành DataOps trong vòng đời phát triển/ vận hành của các mô hình ML (Continuous Delivery for Machine Learning) ****** Chúng tôi không đòi hỏi bạn: Xây dựng mô hình ML Xây dựng và phát triển data pipeline cho các mô hình Phát triển phần mềm ứng dụng Chúng tôi cần bạn: Đọc hiểu được code phát triển của team DS để chuyển đổi thành code vận hành Đặt đầu bài cho các team DevOps/ DE để thiết kế data pipeline cũng như tích hợp mô hình vào trong hệ thống vận hành/ ứng dụng trên môi trường production Mức đãi ngộ: + Mức lương đối với vị trí chuyên gia 60-100m/ tháng ++ Tổng thu nhập gồm lương thưởng 16-18 tháng lương/ năm +++ Incentive theo hiệu quả công việc hằng quý ++++ Sử dụng nền tảng commercial IBM cloud pak for Data - được đánh giá là leader trong nhóm nền tảng về Data Science & Machine Learning năm 2021 theo Gartner (https://www.ibm.com/blogs/journey-to-ai/2021/03/ibm-is-named-a-leader-2021-magic-quadrant-for-data-science-and-machine-learning-platforms/) +++++ Tài khoản coursera phục vụ mục tiêu tự đào tạo/ phát triển năng lực bản thân ======= Các bạn quan tâm vui lòng liên hệ trực tiếp hoặc gửi CV về email lynm@tpb.com.vn. Cảm ơn các bạn!",,
"BentoML là một framework đơn giản, dễ sử dụng, có khả năng serve nhiều ML frameworks khác nhau, và quan trọng hơn là giúp bridge the gap giữa Data Science và DevOps.
Mình xin chia sẻ một số kinh nghiệm trong quá trình làm việc với BentoML, hy vọng sẽ có ích cho mọi người 🤔
https://quan-dang.github.io/2021/10/30/model-serving-using-bentoml/
#serving","BentoML là một framework đơn giản, dễ sử dụng, có khả năng serve nhiều ML frameworks khác nhau, và quan trọng hơn là giúp bridge the gap giữa Data Science và DevOps. Mình xin chia sẻ một số kinh nghiệm trong quá trình làm việc với BentoML, hy vọng sẽ có ích cho mọi người https://quan-dang.github.io/2021/10/30/model-serving-using-bentoml/",#serving,
,nan,,
Xin phép chia sẻ đến anh em.,Xin phép chia sẻ đến anh em.,,
"Deep Learning Interviews book: Hundreds of fully solved job interview questions from a wide range of key topics in AI.
https://github.com/BoltzmannEntropy/interviews.ai",Deep Learning Interviews book: Hundreds of fully solved job interview questions from a wide range of key topics in AI. https://github.com/BoltzmannEntropy/interviews.ai,,
"Làm thế nào để tạo file requirements.txt chỉ bao gồm các thư viện được import, thay vì sử dụng pip freeze và nó lưu một đống? 
Các bác chỉ cần vào project hiện tại và gõ pipreqsnb . là có file requirements.txt luôn nha :D
https://pypi.org/project/pipreqsnb/
#quicktip","Làm thế nào để tạo file requirements.txt chỉ bao gồm các thư viện được import, thay vì sử dụng pip freeze và nó lưu một đống? Các bác chỉ cần vào project hiện tại và gõ pipreqsnb . là có file requirements.txt luôn nha :D https://pypi.org/project/pipreqsnb/",#quicktip,
"ML and Streaming at the Edge with Data Reply
Join us for this webinar with the ML engineering team at Data Reply. They'll share their experiences building ML systems in the real world, talk about their MLOps strategy, and explain how they've built an architecture that allows them to run high-performing inference at the edge. You'll learn how their ML systems are run in production, what tools they use and have the chance to ask questions of your own.
Bác nào quan tâm đến chủ đề Edge MLOps có thể join webinar này (free) của Data Reply nha
https://www.linkedin.com/events/mlandstreamingattheedgewithdata6876219094991953921","ML and Streaming at the Edge with Data Reply Join us for this webinar with the ML engineering team at Data Reply. They'll share their experiences building ML systems in the real world, talk about their MLOps strategy, and explain how they've built an architecture that allows them to run high-performing inference at the edge. You'll learn how their ML systems are run in production, what tools they use and have the chance to ask questions of your own. Bác nào quan tâm đến chủ đề Edge MLOps có thể join webinar này (free) của Data Reply nha https://www.linkedin.com/events/mlandstreamingattheedgewithdata6876219094991953921",,
"Các yếu tố chính để đánh giá chất lượng của 1 hệ thống ML tại Booking.com
Xem chi tiết tại: https://bookingcom.github.io/ml-quality-model/",Các yếu tố chính để đánh giá chất lượng của 1 hệ thống ML tại Booking.com Xem chi tiết tại: https://bookingcom.github.io/ml-quality-model/,,
"Xin chào cả cộng đồng MLOps. Mình xin phép được post tìm chuyên gia về MLOps - Nếu vi phạm quy định của group, thì mình xin hạ post.
QAI( Quy Nhon AI hoặc Quantum AI) có gần 500 thành viên chuyên làm AI, Data gồm phát triển các sản phẩm AI (Work safety trong nhà máy, Inteligent Inspection, Phát hiện và sàng lọc ung thư sớm ...) và cung cấp dịch vụ về phát triển AI/AA cho khách hàng chủ yếu là Mỹ, Nhật, Canada, Đức và một phần cho khách hàng Việt Nam.
Hiện mình đang cần tuyển 7-10 người có kinh nghiệm về MLOps
Tham gia phát triển platform MLOps 
Tham gia các dự án về MLOps và có cơ hội đi onsite ngắn hạn hoặc thậm chí dài hạn và định cư tại Canada, Mỹ và Nhật.
Về thu nhập mình nghĩ là ổn và cùng trao đổi và cơ hội hiện thật sự đang rất tốt để anh em có thể phát triển tốt.
ANh em nào quan tâm có thể inbox trực tiếp mình nhá.
Rất hy vọng sẽ nhận dc sự quan tâm của anh em trong nhóm. ","Xin chào cả cộng đồng MLOps. Mình xin phép được post tìm chuyên gia về MLOps - Nếu vi phạm quy định của group, thì mình xin hạ post. QAI( Quy Nhon AI hoặc Quantum AI) có gần 500 thành viên chuyên làm AI, Data gồm phát triển các sản phẩm AI (Work safety trong nhà máy, Inteligent Inspection, Phát hiện và sàng lọc ung thư sớm ...) và cung cấp dịch vụ về phát triển AI/AA cho khách hàng chủ yếu là Mỹ, Nhật, Canada, Đức và một phần cho khách hàng Việt Nam. Hiện mình đang cần tuyển 7-10 người có kinh nghiệm về MLOps Tham gia phát triển platform MLOps Tham gia các dự án về MLOps và có cơ hội đi onsite ngắn hạn hoặc thậm chí dài hạn và định cư tại Canada, Mỹ và Nhật. Về thu nhập mình nghĩ là ổn và cùng trao đổi và cơ hội hiện thật sự đang rất tốt để anh em có thể phát triển tốt. ANh em nào quan tâm có thể inbox trực tiếp mình nhá. Rất hy vọng sẽ nhận dc sự quan tâm của anh em trong nhóm.",,
"Designing Twitter's Trending Hashtags Solution
https://mlops-discord.github.io/blog/designing-twitters-trending-hashtags-solution/#attempt-3-beyond-mvp
Cách tác giả tiếp cận với bài toán tìm kiếm trending hashtags
1. Motivations: động lực để tìm kiếm một giải pháp tìm trending hashtags tự động thay vì làm thủ công
2. Objectives: xác định mục tiêu cụ thể trên cả khía cạnh business và ML
3. Problem Definition: phân tích kỹ hơn về bài toán (ví dụ thế nào thì gọi là trending, và hiển thị bao nhiêu trending hashtags là đủ?)
4. Solution Development: thiết kế giải pháp (data & thuật toán) cho MVP và những hướng mở rộng/cải thiện trong tương lai","Designing Twitter's Trending Hashtags Solution https://mlops-discord.github.io/blog/designing-twitters-trending-hashtags-solution/#attempt-3-beyond-mvp Cách tác giả tiếp cận với bài toán tìm kiếm trending hashtags 1. Motivations: động lực để tìm kiếm một giải pháp tìm trending hashtags tự động thay vì làm thủ công 2. Objectives: xác định mục tiêu cụ thể trên cả khía cạnh business và ML 3. Problem Definition: phân tích kỹ hơn về bài toán (ví dụ thế nào thì gọi là trending, và hiển thị bao nhiêu trending hashtags là đủ?) 4. Solution Development: thiết kế giải pháp (data & thuật toán) cho MVP và những hướng mở rộng/cải thiện trong tương lai",,
"Design and Build Intelligent Systems
This course is going to explore how to design and build an intelligent system from a software engineering perspective, from requirement gathering and analysis to deployment and maintenance.
https://github.com/jin-guo/COMP599_Fall2021","Design and Build Intelligent Systems This course is going to explore how to design and build an intelligent system from a software engineering perspective, from requirement gathering and analysis to deployment and maintenance. https://github.com/jin-guo/COMP599_Fall2021",,
"Chào mọi người ạ. Lúc tạo budget em tưởng nó báo theo thời gian thực, Đặt giới hạn 50%, 80% của 10$, mà sài tới 35 mỹ kim nó mới báo. Em mắc cái lỗi down template cloudformation của metaflow về dùng mà ko đọc kỹ tài liệu gì cả, tắt instance nó tự đẻ thêm rồi tự chạy (chắc là do autoscaling) 😂
Mọi người có thể chia sẻ kinh nghiệm từng trải hồi còn non nớt không ạ :D
Với lại em đang tập config lại mấy repo của paper kiểu này
https://github.com/jacopotagliabue/you-dont-need-a-bigger-boat
Làm thế nào học hỏi nhiều nhất từ những paper về MLOps ạ ☘️","Chào mọi người ạ. Lúc tạo budget em tưởng nó báo theo thời gian thực, Đặt giới hạn 50%, 80% của 10$, mà sài tới 35 mỹ kim nó mới báo. Em mắc cái lỗi down template cloudformation của metaflow về dùng mà ko đọc kỹ tài liệu gì cả, tắt instance nó tự đẻ thêm rồi tự chạy (chắc là do autoscaling) Mọi người có thể chia sẻ kinh nghiệm từng trải hồi còn non nớt không ạ :D Với lại em đang tập config lại mấy repo của paper kiểu này https://github.com/jacopotagliabue/you-dont-need-a-bigger-boat Làm thế nào học hỏi nhiều nhất từ những paper về MLOps ạ",,
"Vì điều này quan trọng cho các bạn trẻ 🇻🇳 nên tôi phải tách thành 1 status: giới thiệu ngắn về #DataOps
https://www.facebook.com/curiousAI/posts/2576684449142475
Cheers! 🍀",Vì điều này quan trọng cho các bạn trẻ nên tôi phải tách thành 1 status: giới thiệu ngắn về https://www.facebook.com/curiousAI/posts/2576684449142475 Cheers!,#DataOps,
"Yo, sao dạo này vắng lặng quá ta? 🤪
Các bạn làm #industrialAI #productionAI #fullstackAI như #CoTAI: dành tgian dự #DataOps Summit nhé. Cheers! 👇","Yo, sao dạo này vắng lặng quá ta? Các bạn làm như dành tgian dự Summit nhé. Cheers!",#industrialAI	#productionAI	#fullstackAI	#CoTAI:	#DataOps,
"Mẹo nhỏ để tăng tốc Pandas's apply cho anh em 😂
Source: https://khuyentran1401.github.io/Efficient_Python_tricks_and_tools_for_data_scientists/Chapter5/speed_up_code.html#swifter-add-one-word-to-make-your-pandas-apply-23-times-faster",Mẹo nhỏ để tăng tốc Pandas's apply cho anh em Source: https://khuyentran1401.github.io/Efficient_Python_tricks_and_tools_for_data_scientists/Chapter5/speed_up_code.html#swifter-add-one-word-to-make-your-pandas-apply-23-times-faster,,
"Query Optimization Techniques - Tips For Writing Efficient And Faster SQL Queries
https://media-exp1.licdn.com/dms/document/C561FAQGt1Z838CUleQ/feedshare-document-pdf-analyzed/0/1637084319968?e=1637244000&v=beta&t=0l-hPYBtQKA45HmWKxCsJCHTzi-n1Quoko3N41Yro8E&fbclid=IwAR2c74qZtIxW-5yDqtvb0SXKSLXlsXhakZ1Vi-rXe7zcV-nT7z-Qz1nOnEc
Top 1: Use Column Names Instead of * in a SELECT Statement 😂
Source: https://www.linkedin.com/posts/greg-coquillo_sql-query-optimization-techniques-activity-6866431616772919296-ZnME",Query Optimization Techniques - Tips For Writing Efficient And Faster SQL Queries https://media-exp1.licdn.com/dms/document/C561FAQGt1Z838CUleQ/feedshare-document-pdf-analyzed/0/1637084319968?e=1637244000&v=beta&t=0l-hPYBtQKA45HmWKxCsJCHTzi-n1Quoko3N41Yro8E&fbclid=IwAR2c74qZtIxW-5yDqtvb0SXKSLXlsXhakZ1Vi-rXe7zcV-nT7z-Qz1nOnEc Top 1: Use Column Names Instead of * in a SELECT Statement Source: https://www.linkedin.com/posts/greg-coquillo_sql-query-optimization-techniques-activity-6866431616772919296-ZnME,,
"Xin chào mọi người,
Em mới bắt đầu cài đặt và sử dụng Kubeflow trên AWS và gặp một vấn đề nhờ mọi người giải đáp giúp
Hiện tại k8s của em setup 2 spot:
- cpu-spot: để run các step của pipeline dùng cpu
- gpu-spot: để run các task training, serving, được tạo theo command sau:
eksctl create nodegroup --cluster kubeflow- --neksame nodegpu --node-type p2.xlarge --node-labels=""gpu=yes"" --nodes 0 --nodes-min 0 --nodes-max 4
Vấn đề em gặp phải là khi tạo một step bằng python dsl.ContainerOp( .... ).set_gpu_limit(1) thì gpu-spot không tự động scale khởi tạo node.
Em đã thử với ""--nodes 1"" khi tạo nodegroup và tạo nhiều step đồng thời dsl.ContainerOp( .... ).set_gpu_limit(1) thì các step này sẽ lần lượt chạy trên node-gpu được khởi tạo (1 node) mà không scale thêm gpu node
Cho em hỏi là có cần phải cài đặt gì đặc biệt thêm trên EKS không để có thể auto-scale trên gpu-spot.
Em xin cảm ơn và hậu tạ chầu bia sau dịch cho bác nào giúp e giải quyết issue này với ạ :D","Xin chào mọi người, Em mới bắt đầu cài đặt và sử dụng Kubeflow trên AWS và gặp một vấn đề nhờ mọi người giải đáp giúp Hiện tại k8s của em setup 2 spot: - cpu-spot: để run các step của pipeline dùng cpu - gpu-spot: để run các task training, serving, được tạo theo command sau: eksctl create nodegroup --cluster kubeflow- --neksame nodegpu --node-type p2.xlarge --node-labels=""gpu=yes"" --nodes 0 --nodes-min 0 --nodes-max 4 Vấn đề em gặp phải là khi tạo một step bằng python dsl.ContainerOp( .... ).set_gpu_limit(1) thì gpu-spot không tự động scale khởi tạo node. Em đã thử với ""--nodes 1"" khi tạo nodegroup và tạo nhiều step đồng thời dsl.ContainerOp( .... ).set_gpu_limit(1) thì các step này sẽ lần lượt chạy trên node-gpu được khởi tạo (1 node) mà không scale thêm gpu node Cho em hỏi là có cần phải cài đặt gì đặc biệt thêm trên EKS không để có thể auto-scale trên gpu-spot. Em xin cảm ơn và hậu tạ chầu bia sau dịch cho bác nào giúp e giải quyết issue này với ạ :D",,
"Near-real-time similar image detection at scale at Pinterest.
https://www.youtube.com/watch?v=Vfgr8V-EOEA",Near-real-time similar image detection at scale at Pinterest. https://www.youtube.com/watch?v=Vfgr8V-EOEA,,
"Reliable, effective user-centered AI systems should be designed following general best practices for software systems, together with practices that address considerations unique to machine learning. Our top recommendations are outlined below, with additional resources for further reading.
Một số best practices của Google để xây dựng một hệ thống AI mang lại trải nghiệm tốt cho người dùng
https://ai.google/responsibilities/responsible-ai-practices/","Reliable, effective user-centered AI systems should be designed following general best practices for software systems, together with practices that address considerations unique to machine learning. Our top recommendations are outlined below, with additional resources for further reading. Một số best practices của Google để xây dựng một hệ thống AI mang lại trải nghiệm tốt cho người dùng https://ai.google/responsibilities/responsible-ai-practices/",,
"Probabilistic Machine Learning: An Introduction (2022)
Anh em làm ML chắc không còn xa lạ gì với quyền sách huyền thoại Probabilistic Machine Learning: An Introduction (2012). Tác giả Murphy đã không làm anh em thất vọng khi cho ra lò tiếp bản 2022 nhiều từ khoá hot trend như Recommender Systems và Graph Embeddings 😂
Mời anh em đón đọc tại: https://probml.github.io/pml-book/book1.html",Probabilistic Machine Learning: An Introduction (2022) Anh em làm ML chắc không còn xa lạ gì với quyền sách huyền thoại Probabilistic Machine Learning: An Introduction (2012). Tác giả Murphy đã không làm anh em thất vọng khi cho ra lò tiếp bản 2022 nhiều từ khoá hot trend như Recommender Systems và Graph Embeddings Mời anh em đón đọc tại: https://probml.github.io/pml-book/book1.html,,
"Hi ae, trend bh tiến tới end-to-end ML pipeline rồi k biết ae lưu training data như nào thế?
Trường hợp của mình là object detection, data update thường xuyên và dung lượng lớn. Hiện tại thì lưu trên VM luôn nhưng cảm thấy 1 là ko an toàn 2 là nhiều lúc label ở máy local xong lại update lên VM rất mất thời gian.
Vậy ae hiện đang dùng gì để lưu trữ thì để lại chút kinh nghiệm nhé.","Hi ae, trend bh tiến tới end-to-end ML pipeline rồi k biết ae lưu training data như nào thế? Trường hợp của mình là object detection, data update thường xuyên và dung lượng lớn. Hiện tại thì lưu trên VM luôn nhưng cảm thấy 1 là ko an toàn 2 là nhiều lúc label ở máy local xong lại update lên VM rất mất thời gian. Vậy ae hiện đang dùng gì để lưu trữ thì để lại chút kinh nghiệm nhé.",,
"Engineering best practices for Machine Learning
https://se-ml.github.io/practices/",Engineering best practices for Machine Learning https://se-ml.github.io/practices/,,
"RecSysOps: Best Practices for Operating a Large-Scale Recommender System
Một số bài học rút ra từ team Netflix trong quá trình vận hành hệ thống RecSys:
Issue Detection: làm sao để phát hiện vấn đề nhanh chóng và chính xác
Issue Prediction: làm sao để dự đoán vấn đề trước khi nó xảy ra
Issue Diagnosis: làm sao để chẩn đoán nguyên nhân gây ra vấn đề
Issue Resolution: cách giải quyết vấn đề như thế nào

Paper: https://dl.acm.org/doi/pdf/10.1145/3460231.3474620 
Youtube: https://www.youtube.com/watch?v=VTLwSapTjVs",RecSysOps: Best Practices for Operating a Large-Scale Recommender System Một số bài học rút ra từ team Netflix trong quá trình vận hành hệ thống RecSys: Issue Detection: làm sao để phát hiện vấn đề nhanh chóng và chính xác Issue Prediction: làm sao để dự đoán vấn đề trước khi nó xảy ra Issue Diagnosis: làm sao để chẩn đoán nguyên nhân gây ra vấn đề Issue Resolution: cách giải quyết vấn đề như thế nào Paper: https://dl.acm.org/doi/pdf/10.1145/3460231.3474620 Youtube: https://www.youtube.com/watch?v=VTLwSapTjVs,,
"Kubernetes (K8S) là một hệ thống mã nguồn mở giúp tự động hoá quá trình quản lý, deploy và scale các ứng dụng triển khai theo kiến trúc microservice.
Mình thấy tutorial này giải thích khá chi tiết và dễ hiểu các khái niệm liên quan đến K8S, hy vọng có ích với mọi người 🥳
Chúc cả nhà buổi tối cuối tuần vui vẻ! 🥰","Kubernetes (K8S) là một hệ thống mã nguồn mở giúp tự động hoá quá trình quản lý, deploy và scale các ứng dụng triển khai theo kiến trúc microservice. Mình thấy tutorial này giải thích khá chi tiết và dễ hiểu các khái niệm liên quan đến K8S, hy vọng có ích với mọi người Chúc cả nhà buổi tối cuối tuần vui vẻ!",,
"Hello mọi người,
Lần trước em chia sẻ dưới dạng link dẫn về blog cá nhân nên bị facebook gắn cờ spam và bài đăng của em đã bị gỡ 😢
Có khá nhiều bạn liên hệ em vì thế em xin phép được chia sẻ lại.
Hiện tại em đang bắt đầu triển khai viết blog để làm cẩm nang cá nhân cũng như để chia sẻ kiến thức và có thể nhận được đóng góp và góp ý từ tất cả mọi người về lĩnh vực MLOps. Em đang và sẽ đề cập đến các công nghệ thông dụng liên quan, cụ thể là công nghệ DAG (task-driven) với series đầu tiên là về nền tảng Kubeflow được phát triển bởi Google.
Mong mọi người đón đọc và góp ý để em có thể hoàn thiện hơn. Episode 2 cũng đang được hoàn thành và sẽ được chia sẻ đến mọi người sớm nhất có thể 🥳🥳🥳
Cảm phiền mọi người truy cập bằng cách copy link này ạ
👉 vule24.github.io
Bon week-end!!!
#mlops #dag #kubeflow","Hello mọi người, Lần trước em chia sẻ dưới dạng link dẫn về blog cá nhân nên bị facebook gắn cờ spam và bài đăng của em đã bị gỡ Có khá nhiều bạn liên hệ em vì thế em xin phép được chia sẻ lại. Hiện tại em đang bắt đầu triển khai viết blog để làm cẩm nang cá nhân cũng như để chia sẻ kiến thức và có thể nhận được đóng góp và góp ý từ tất cả mọi người về lĩnh vực MLOps. Em đang và sẽ đề cập đến các công nghệ thông dụng liên quan, cụ thể là công nghệ DAG (task-driven) với series đầu tiên là về nền tảng Kubeflow được phát triển bởi Google. Mong mọi người đón đọc và góp ý để em có thể hoàn thiện hơn. Episode 2 cũng đang được hoàn thành và sẽ được chia sẻ đến mọi người sớm nhất có thể Cảm phiền mọi người truy cập bằng cách copy link này ạ vule24.github.io Bon week-end!!!",#mlops	#dag	#kubeflow,
"Data Science Interview Q&A
https://media-exp1.licdn.com/dms/document/C561FAQH2B8pdMAoggQ/feedshare-document-pdf-analyzed/0/1628841498962?e=1628956800&v=beta&t=FDx2vECqHZFv-x93LsJ3SRHZ07JgxL9rHEex5G2xW_g
Nguồn: https://www.linkedin.com/posts/lightsondata_data-science-interview-questions-ugcPost-6831857375868280832-ld28
#interview",Data Science Interview Q&A https://media-exp1.licdn.com/dms/document/C561FAQH2B8pdMAoggQ/feedshare-document-pdf-analyzed/0/1628841498962?e=1628956800&v=beta&t=FDx2vECqHZFv-x93LsJ3SRHZ07JgxL9rHEex5G2xW_g Nguồn: https://www.linkedin.com/posts/lightsondata_data-science-interview-questions-ugcPost-6831857375868280832-ld28,#interview,
"Xin chào các bác, nhân một ngày không có gì đặc biệt cả, em xin phép viết thêm bài blog nho nhỏ về chủ để ""Kiểm thử hệ thống ML"", các bác xem và đóng góp ý kiến giúp em với ạ. 🥳🥳🥳
https://quan-dang.github.io/2021/08/22/test-in-ml/
Chúc cả nhà buổi tối cuối tuần vui vẻ!
#testing #monitoring #mlops","Xin chào các bác, nhân một ngày không có gì đặc biệt cả, em xin phép viết thêm bài blog nho nhỏ về chủ để ""Kiểm thử hệ thống ML"", các bác xem và đóng góp ý kiến giúp em với ạ. https://quan-dang.github.io/2021/08/22/test-in-ml/ Chúc cả nhà buổi tối cuối tuần vui vẻ!",#testing	#monitoring	#mlops,
"MLOps Basic
The goal of the series is to understand the basics of MLOps (model building, monitoring, configurations, testing, packaging, deployment, cicd).
Một nguồn tài liệu hay về MLOps cho mọi người học tập và tham khảo
https://www.ravirajag.dev/blog","MLOps Basic The goal of the series is to understand the basics of MLOps (model building, monitoring, configurations, testing, packaging, deployment, cicd). Một nguồn tài liệu hay về MLOps cho mọi người học tập và tham khảo https://www.ravirajag.dev/blog",,
"Dự án AICOVIDVN (dự đoán Covid qua tiếng ho) đang cần tuyển thành viên có kinh nghiệm về MLOps, chi phí infra được tài trợ bởi AWS tha hồ cho anh em quẩy 🥳
Ai có hứng thú thì liên lạc anh Hung Le nha 🥳","Dự án AICOVIDVN (dự đoán Covid qua tiếng ho) đang cần tuyển thành viên có kinh nghiệm về MLOps, chi phí infra được tài trợ bởi AWS tha hồ cho anh em quẩy Ai có hứng thú thì liên lạc anh Hung Le nha",,
"Điểm sáng hiếm hoi của mùa Covid là hội nghị lớn nhất thế giới về AI do Nvidia tổ chức lại tiếp tục tổ chức online và là cơ hội để các nhà nghiên cứu, phát triển được tham gia FREE. Đây là cơ hội để AI Developers, Data Scientists tiếp xúc với những framework, pre-train model,… sản phẩm trong nhiều lĩnh vực : ....Robotic, Automatic Driver, Banking,BigData, 5G….
Link đăng ký miễn phí :
www.nvidia.com/gtc/?ncid=GTC-NVVCUONG
Trân trọng kính mời anh em đăng ký để hoà nhập và phát triển cùng AI Thế giới","Điểm sáng hiếm hoi của mùa Covid là hội nghị lớn nhất thế giới về AI do Nvidia tổ chức lại tiếp tục tổ chức online và là cơ hội để các nhà nghiên cứu, phát triển được tham gia FREE. Đây là cơ hội để AI Developers, Data Scientists tiếp xúc với những framework, pre-train model,… sản phẩm trong nhiều lĩnh vực : ....Robotic, Automatic Driver, Banking,BigData, 5G…. Link đăng ký miễn phí : www.nvidia.com/gtc/?ncid=GTC-NVVCUONG Trân trọng kính mời anh em đăng ký để hoà nhập và phát triển cùng AI Thế giới",,
"Hi ae,

Mình đợt rồi có tìm hiểu 1 chút về việc deploy machine learning/deep learning model in production. Lục tung cái google thì mình có tổng hợp đc 1 số tutorial và rút gọn lại ở link github này:
https://github.com/tuvovan/ml_in_production
về cơ bản thì mình tổng hợp 1 số phương pháp:
bắt đầu từ restapi + flask + redis
restapi + nginx + uwsgi (bản nâng cấp để handle multiple requests)
fastapi + redis
tensorflow serving
restapi + kuberflow
bài viết tổng hợp từ nhiều nguồn, có thể sẽ có thiếu sót, hi vọng mọi người đọc và cho ý kiến đóng góp để hoàn thiện hơn.

Many thanks!","Hi ae, Mình đợt rồi có tìm hiểu 1 chút về việc deploy machine learning/deep learning model in production. Lục tung cái google thì mình có tổng hợp đc 1 số tutorial và rút gọn lại ở link github này: https://github.com/tuvovan/ml_in_production về cơ bản thì mình tổng hợp 1 số phương pháp: bắt đầu từ restapi + flask + redis restapi + nginx + uwsgi (bản nâng cấp để handle multiple requests) fastapi + redis tensorflow serving restapi + kuberflow bài viết tổng hợp từ nhiều nguồn, có thể sẽ có thiếu sót, hi vọng mọi người đọc và cho ý kiến đóng góp để hoàn thiện hơn. Many thanks!",,
"Video chia sẻ về MLOps cũng như nói về cách tối ưu bài toán Machine Learning của giáo sư Andrew Ng
---------
Notes/Pointers of Video.
- AI = Code + Data
- Instead of emphasising more on tunning model, clean the data as much as possible. Opt for data centric approaches which means Data Augmentation, Data tagging etc.
- We can have more and more data to increase model performance, but better approach would be to increase only quality data, because with little increase in quality data the model will have direct and high effect rather than huge data (big data) of compromised quality.
-MLOps people should help ML Engineer to prepare stratergies for Quality Data creation across all the phases of ML project Life cycle.
- Deploying a ML model is just 50% work done, now gathering more quality data and retrain the model periodically will make the work 100% done.
- Try to work from Model Centric to Data Centric process.
- Important Forntier: MLOps tools to make data centric AI an efficient and systematic process.","Video chia sẻ về MLOps cũng như nói về cách tối ưu bài toán Machine Learning của giáo sư Andrew Ng --------- Notes/Pointers of Video. - AI = Code + Data - Instead of emphasising more on tunning model, clean the data as much as possible. Opt for data centric approaches which means Data Augmentation, Data tagging etc. - We can have more and more data to increase model performance, but better approach would be to increase only quality data, because with little increase in quality data the model will have direct and high effect rather than huge data (big data) of compromised quality. -MLOps people should help ML Engineer to prepare stratergies for Quality Data creation across all the phases of ML project Life cycle. - Deploying a ML model is just 50% work done, now gathering more quality data and retrain the model periodically will make the work 100% done. - Try to work from Model Centric to Data Centric process. - Important Forntier: MLOps tools to make data centric AI an efficient and systematic process.",,
"Comparing Dask, Ray, Modin, Vaex, and RAPIDS
Còn thiếu giải pháp nào để scale Pandas không các bác? 🤔
https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray","Comparing Dask, Ray, Modin, Vaex, and RAPIDS Còn thiếu giải pháp nào để scale Pandas không các bác? https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray",,
"https://alexioannides.com/2019/01/10/deploying-python-ml-models-with-flask-docker-and-kubernetes/
mình thấy bác này viết rất dễ hiểu và đầy đủ. anh em tham khảo nhé. :D nhân tiện có anh em nào đang làm TFX (tensorflow extend) và có document nào hay vs dễ hiểu thì chia sẻ nhé.
Code gốc của tác giả ko có ML hay DL model nào, nên m có chỉnh sửa 1 chút code để deploy Resnet50.
https://github.com/tuvovan/deeplearning-deployment-docker-kubernetes","https://alexioannides.com/2019/01/10/deploying-python-ml-models-with-flask-docker-and-kubernetes/ mình thấy bác này viết rất dễ hiểu và đầy đủ. anh em tham khảo nhé. :D nhân tiện có anh em nào đang làm TFX (tensorflow extend) và có document nào hay vs dễ hiểu thì chia sẻ nhé. Code gốc của tác giả ko có ML hay DL model nào, nên m có chỉnh sửa 1 chút code để deploy Resnet50. https://github.com/tuvovan/deeplearning-deployment-docker-kubernetes",,
"Architecture of ML Systems SS2021
This course covers the architecture and essential concepts of modern ML systems for both local and large-scale machine learning (ML).
Khoá học hay về ML Systems cho cả nhà cùng ngâm cứu :D 
https://mboehm7.github.io/teaching/ss21_amls/index.htm",Architecture of ML Systems SS2021 This course covers the architecture and essential concepts of modern ML systems for both local and large-scale machine learning (ML). Khoá học hay về ML Systems cho cả nhà cùng ngâm cứu :D https://mboehm7.github.io/teaching/ss21_amls/index.htm,,
"Methods for inferring concept drift
Ở bài blog trước mình đã nói qua về concept drift, tuy nhiên việc thiếu label gây ra trở ngại lớn để xác định loại drift này. 
Các kỹ sư của CLOUDERA đã giới thiệu 4 phương pháp sau để giúp suy luận ra concept dift:
1. Statistical test for change in feature space: kiểm tra thay đổi trong phân phối của các feature
2. Statistical test for change in response variable: kiểm tra thay đổi trong phân phối của dự đoán
3. Statistical test for change in margin density of response variable: kiểm tra thay đổi trong phân phối ""in-margin"" 
4. Detect change in margin density of response distribution using a learned threshold: kiểm tra thay đổi trong phân phối ""in-margin"" kết hợp kỹ thuật k-fold
Chi tiết xem tại: https://concept-drift.fastforwardlabs.com/","Methods for inferring concept drift Ở bài blog trước mình đã nói qua về concept drift, tuy nhiên việc thiếu label gây ra trở ngại lớn để xác định loại drift này. Các kỹ sư của CLOUDERA đã giới thiệu 4 phương pháp sau để giúp suy luận ra concept dift: 1. Statistical test for change in feature space: kiểm tra thay đổi trong phân phối của các feature 2. Statistical test for change in response variable: kiểm tra thay đổi trong phân phối của dự đoán 3. Statistical test for change in margin density of response variable: kiểm tra thay đổi trong phân phối ""in-margin"" 4. Detect change in margin density of response distribution using a learned threshold: kiểm tra thay đổi trong phân phối ""in-margin"" kết hợp kỹ thuật k-fold Chi tiết xem tại: https://concept-drift.fastforwardlabs.com/",,
"Em chào mọi người. Em là Hương Bùi, Recruiter chuyên mảng Data Science tại Headhunting Agency One Arrow Consulting. Được sự cho phép của Admin Quan Dang, em xin update job list về Data hiện tại em đang phụ trách như sau:
#HN
1. Senior Data Manaagement Manager I Hospitality - $3500 - $6000 (Open for expat)
2. Data analytics Senior Manager - Consulting Service - $4000
3. Data engineer - Digital Banking - $3000 - $5000
4. Data scientist - Digital Banking - $3000 - $5000
#HCM
5. Data analytics Senior Manager - Consulting Service - $3000 - $4000
6. Data Managment and Reporting Manager - Insurance - $2500 - $3500
7. Data Engineer Team Leader - Insurance - $2500 - $3500
8. Senior Data Engineer - Insurance - $2000 - $2500
9. Data Scientist - Insurance - $2000 - $2500 (Big Data/Data Modeling)
Mọi người quan tâm job nào có thể inbox em để được hỗ trợ nhé ạ!💁‍♀️ Hi vọng có cơ hội được hợp tác với mọi người ^^ Chúc mọi người có 1 tuần mới làm việc hiệu quả!
#OAC #DataScience #tuyendung","Em chào mọi người. Em là Hương Bùi, Recruiter chuyên mảng Data Science tại Headhunting Agency One Arrow Consulting. Được sự cho phép của Admin Quan Dang, em xin update job list về Data hiện tại em đang phụ trách như sau: 1. Senior Data Manaagement Manager I Hospitality - $3500 - $6000 (Open for expat) 2. Data analytics Senior Manager - Consulting Service - $4000 3. Data engineer - Digital Banking - $3000 - $5000 4. Data scientist - Digital Banking - $3000 - $5000 5. Data analytics Senior Manager - Consulting Service - $3000 - $4000 6. Data Managment and Reporting Manager - Insurance - $2500 - $3500 7. Data Engineer Team Leader - Insurance - $2500 - $3500 8. Senior Data Engineer - Insurance - $2000 - $2500 9. Data Scientist - Insurance - $2000 - $2500 (Big Data/Data Modeling) Mọi người quan tâm job nào có thể inbox em để được hỗ trợ nhé ạ! Hi vọng có cơ hội được hợp tác với mọi người ^^ Chúc mọi người có 1 tuần mới làm việc hiệu quả!",#HN	#HCM	#OAC	#DataScience	#tuyendung,
"MLOps - Market Review
https://airtable.com/shr4rfiuOIVjMhvhL/tblP1hFSp3Uez50bn/viwq8eCvLCHNph2wt?blocks=hide&backgroundColor=blue",MLOps - Market Review https://airtable.com/shr4rfiuOIVjMhvhL/tblP1hFSp3Uez50bn/viwq8eCvLCHNph2wt?blocks=hide&backgroundColor=blue,,
"ML Lifecycle & Deployment
----------------------------
Xin chào các anh chị, em là Dũng đến từ AIlab của UET. Trong tuần vừa rồi em có báo cáo một vài vấn đề lên quan đến MLOps muốn chia sẻ lên đây để mọi người cùng góp ý và nhận xét ạ.
----------------------------
Trong phần trình bày cover các khái niệm sau:
Review về vòng đời phát triển một dự án ML
Khái niệm Data drift và Concept drift
Quá trình monitoring
----------------------------
Tài liệu liên quan:
Slide: https://nmd2000-my.sharepoint.com/:p:/g/personal/18020370_nmd2000_onmicrosoft_com/EaGskFIijxNGt_9zM3ir8HAB0FvZkgTu0MOdJqA9xrWbtQ?e=fGUUWg
Note ML lifecycle: https://www.notion.so/nmd2000/Machine-Learning-Project-Lifecycle-54e2fcb8615640aea198e4748735c76e
Note Deployment: https://www.notion.so/nmd2000/Deployment-a-ML-Project-e326a73335284e6a88f6db515d63fe6d
----------------------------
Vui lòng liên hệ với em nếu có nhu cầu re-up lại phần thuyết trình này. Em xin cảm ơn.","ML Lifecycle & Deployment ---------------------------- Xin chào các anh chị, em là Dũng đến từ AIlab của UET. Trong tuần vừa rồi em có báo cáo một vài vấn đề lên quan đến MLOps muốn chia sẻ lên đây để mọi người cùng góp ý và nhận xét ạ. ---------------------------- Trong phần trình bày cover các khái niệm sau: Review về vòng đời phát triển một dự án ML Khái niệm Data drift và Concept drift Quá trình monitoring ---------------------------- Tài liệu liên quan: Slide: https://nmd2000-my.sharepoint.com/:p:/g/personal/18020370_nmd2000_onmicrosoft_com/EaGskFIijxNGt_9zM3ir8HAB0FvZkgTu0MOdJqA9xrWbtQ?e=fGUUWg Note ML lifecycle: https://www.notion.so/nmd2000/Machine-Learning-Project-Lifecycle-54e2fcb8615640aea198e4748735c76e Note Deployment: https://www.notion.so/nmd2000/Deployment-a-ML-Project-e326a73335284e6a88f6db515d63fe6d ---------------------------- Vui lòng liên hệ với em nếu có nhu cầu re-up lại phần thuyết trình này. Em xin cảm ơn.",,
"Hi mọi người, em vừa viết một bài blog nhỏ chia sẻ kinh nghiệm cá nhân khi xây dựng một hệ thống ML. Các bác xem và đóng góp ý kiến giúp em với ạ :D.
Chúc cả nhà buổi tối cuối tuần vui vẻ 🥳","Hi mọi người, em vừa viết một bài blog nhỏ chia sẻ kinh nghiệm cá nhân khi xây dựng một hệ thống ML. Các bác xem và đóng góp ý kiến giúp em với ạ :D. Chúc cả nhà buổi tối cuối tuần vui vẻ",,
"Build Interactive reports for analyzing machine learning models with Evidently
https://github.com/evidentlyai/evidently
#monitoring",Build Interactive reports for analyzing machine learning models with Evidently https://github.com/evidentlyai/evidently,#monitoring,
"Deep Learning Recommender Systems Summit
https://www.facebook.com/events/532119901468724",Deep Learning Recommender Systems Summit https://www.facebook.com/events/532119901468724,,
"lakeFS (https://docs.lakefs.io/) là một open-source platform cung cấp giải pháp tương tự git branch và commit cho dữ liệu lưu trên GCS, S3 và Azure Blob.
lakeFS có Python Client API nên có thể dễ dàng tích hợp vào làm một component trên Kubeflow pipeline để xây dựng một pipeline có tính reproducible.
https://lakefs.io/build-reproducible-experiments-with-lakefs-and-kubeflow/","lakeFS (https://docs.lakefs.io/) là một open-source platform cung cấp giải pháp tương tự git branch và commit cho dữ liệu lưu trên GCS, S3 và Azure Blob. lakeFS có Python Client API nên có thể dễ dàng tích hợp vào làm một component trên Kubeflow pipeline để xây dựng một pipeline có tính reproducible. https://lakefs.io/build-reproducible-experiments-with-lakefs-and-kubeflow/",,
"Nửa đêm T4, rạng sáng T5 này (có lẽ sẽ ko có video recording)","Nửa đêm T4, rạng sáng T5 này (có lẽ sẽ ko có video recording)",,
Join livestream MLOps của DeepLearning.AI thôi mn :D,Join livestream MLOps của DeepLearning.AI thôi mn :D,,
MLOps Tooling Landscape v2 by Huyền Chip,MLOps Tooling Landscape v2 by Huyền Chip,,
https://mlops.toys,https://mlops.toys,,
"Practice coding for ML interviews
https://mlpro.io/",Practice coding for ML interviews https://mlpro.io/,,
"Còn khá lâu mới tới nhưng cứ register luôn kẻo quên nhé anh em ;)
Chỉ có điều 4AM giờ VN :( Hy vọng có video recording
Conversational AI & NLP Product Management by Facebook PM.
Btw, anh em ai đã & đang làm về ConvAI production (đặc biệt cho tiếng Việt) thì tym ❤️ cho mọi người biết nhé!","Còn khá lâu mới tới nhưng cứ register luôn kẻo quên nhé anh em ;) Chỉ có điều 4AM giờ VN :( Hy vọng có video recording Conversational AI & NLP Product Management by Facebook PM. Btw, anh em ai đã & đang làm về ConvAI production (đặc biệt cho tiếng Việt) thì tym cho mọi người biết nhé!",,
"MLOps Event by DeepLearning.AI
https://www.facebook.com/events/2979209212315532/?ref=newsfeed",MLOps Event by DeepLearning.AI https://www.facebook.com/events/2979209212315532/?ref=newsfeed,,
"Hi ae,
Mình có 1 cái pipeline như này. hiện tại cluster mình đang dùng chưa có gpu
giả sử mình dùng cluster khác, có gpu nhưng chỉ muốn dùng gpu cho 2 components là train-model + test-model thì phải config như nào?
và có cách nào để schedule để tiết kiệm resource ko? cụ thể là ko bị charge khi ko chạy pipeline.
rất mong được chia sẻ ạ :D","Hi ae, Mình có 1 cái pipeline như này. hiện tại cluster mình đang dùng chưa có gpu giả sử mình dùng cluster khác, có gpu nhưng chỉ muốn dùng gpu cho 2 components là train-model + test-model thì phải config như nào? và có cách nào để schedule để tiết kiệm resource ko? cụ thể là ko bị charge khi ko chạy pipeline. rất mong được chia sẻ ạ :D",,
Khóa học ML mới nhất từ deeplearning.ai . Mk vừa nhận được gmail,Khóa học ML mới nhất từ deeplearning.ai . Mk vừa nhận được gmail,,
"Great resources on ML System Design from Tech Giants
https://becominghuman.ai/machine-learning-system-design-f2f4018f2f8",Great resources on ML System Design from Tech Giants https://becominghuman.ai/machine-learning-system-design-f2f4018f2f8,,
"[Góc tìm người]- #MLOps- #HCMC
Hello cả nhà, mình đang tìm 1 bạn #DevOps có làm về #MLOps cho 1 cty Product lớn ở quận 1 với offer 50-60Mil gross, yêu cầu hiểu và làm tốt về MLOps. Mọi người quan tâm vị trí này gửi CV vào thao.nguyen@hr1vietnam.com hoặc số đt em 0976664853 để trao đổi vị trí này nhé!
Thanks anh Quan Dang duyệt cho em ạ!","[Góc tìm người]- Hello cả nhà, mình đang tìm 1 bạn có làm về cho 1 cty Product lớn ở quận 1 với offer 50-60Mil gross, yêu cầu hiểu và làm tốt về MLOps. Mọi người quan tâm vị trí này gửi CV vào thao.nguyen@hr1vietnam.com hoặc số đt em 0976664853 để trao đổi vị trí này nhé! Thanks anh Quan Dang duyệt cho em ạ!",#MLOps-	#HCMC	#DevOps	#MLOps,
"Hi mọi người, hôm bữa bác Quan Dang có share link tới khóa học ML Systems Design của chị Huyền Chip hay quá. Mình ngồi đọc rồi note lại vô whimsical.
Lúc đầu mình tách nó ra thành 12 files, nhưng sau mình gộp chung lại thành 1 file cho dễ search. Rồi thấy nhìn cũng hay ho nên share cho mọi người cũng dễ search theo :)
Mời các bác tự do clone và edit theo ý muốn.
Whimsical link: https://whimsical.com/cs-329s-machine-learning-systems-design-note-E7oPi8C6VUU89j8yPJdgzK@2Ux7TurymLtJ5UFVoDpm
cs329s course: https://stanford-cs329s.github.io/index.html","Hi mọi người, hôm bữa bác Quan Dang có share link tới khóa học ML Systems Design của chị Huyền Chip hay quá. Mình ngồi đọc rồi note lại vô whimsical. Lúc đầu mình tách nó ra thành 12 files, nhưng sau mình gộp chung lại thành 1 file cho dễ search. Rồi thấy nhìn cũng hay ho nên share cho mọi người cũng dễ search theo :) Mời các bác tự do clone và edit theo ý muốn. Whimsical link: https://whimsical.com/cs-329s-machine-learning-systems-design-note-E7oPi8C6VUU89j8yPJdgzK@2Ux7TurymLtJ5UFVoDpm cs329s course: https://stanford-cs329s.github.io/index.html",,
"4 Types of ML Drift in MLOps Monitoring
https://towardsdatascience.com/how-to-detect-model-drift-in-mlops-monitoring-7a039c22eaf9",4 Types of ML Drift in MLOps Monitoring https://towardsdatascience.com/how-to-detect-model-drift-in-mlops-monitoring-7a039c22eaf9,,
"AWS Machine Learning Engineer Scholarship
https://www.udacity.com/scholarships/aws-machine-learning-scholarship-program",AWS Machine Learning Engineer Scholarship https://www.udacity.com/scholarships/aws-machine-learning-scholarship-program,,
"Better model evaluation with What-If Tool
Một số tính năng hay ho:
Thay đổi feature value để quan sát sự thay đổi kết trong quả dự đoán
Tìm datapoint tương tự với datapoint hiện tại mà cho kết quả dự đoán khác
Đánh giá tính ""fairness"" của model dựa trên kết quả dự đoán trên các group khác nhau
https://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html","Better model evaluation with What-If Tool Một số tính năng hay ho: Thay đổi feature value để quan sát sự thay đổi kết trong quả dự đoán Tìm datapoint tương tự với datapoint hiện tại mà cho kết quả dự đoán khác Đánh giá tính ""fairness"" của model dựa trên kết quả dự đoán trên các group khác nhau https://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html",,
"A quick recap on GCP Services in MLOps
https://medium.com/google-developer-experts/mlops-big-picture-in-gcp-a637566d6ae8",A quick recap on GCP Services in MLOps https://medium.com/google-developer-experts/mlops-big-picture-in-gcp-a637566d6ae8,,
"Hi all. Mọi người đã ai từng train custom language model của AWS Transcribe chưa ạ? Cho em hỏi:
1. Theo official guide https://docs.aws.amazon.com/transcribe/latest/dg/create-custom-language-model.html
Làm sao model có thể học được khi chỉ cung cấp text mà không cung cấp audio tương ứng?
2. Mẫu file text Training data và Tuning data các bác đã dùng? Model sau train có thực sự tốt hơn đối với bộ data (domain-specific) của mình?
Em cảm ơn mọi người nhiều.",Hi all. Mọi người đã ai từng train custom language model của AWS Transcribe chưa ạ? Cho em hỏi: 1. Theo official guide https://docs.aws.amazon.com/transcribe/latest/dg/create-custom-language-model.html Làm sao model có thể học được khi chỉ cung cấp text mà không cung cấp audio tương ứng? 2. Mẫu file text Training data và Tuning data các bác đã dùng? Model sau train có thực sự tốt hơn đối với bộ data (domain-specific) của mình? Em cảm ơn mọi người nhiều.,,
https://www.youtube.com/playlist?list=PLH-rpi_agJT1FZoxD70YOVJKn13LcQKbd,https://www.youtube.com/playlist?list=PLH-rpi_agJT1FZoxD70YOVJKn13LcQKbd,,
"Hello các bạn.
Mình đang tìm hiểu về Kubeflow và đang muốn tìm thêm tutorial ( ngoại trừ 2 tutorial có sẵn trong Kubeflow docs) để học hỏi. Các bạn có biết nguồn tutorial Kubeflow nào đa dạng + code để tìm học hỏi được không?
Mình cảm ơn!",Hello các bạn. Mình đang tìm hiểu về Kubeflow và đang muốn tìm thêm tutorial ( ngoại trừ 2 tutorial có sẵn trong Kubeflow docs) để học hỏi. Các bạn có biết nguồn tutorial Kubeflow nào đa dạng + code để tìm học hỏi được không? Mình cảm ơn!,,
"Some notes from apply() conference by James
https://jameskle.com/writes/tecton-apply2021",Some notes from apply() conference by James https://jameskle.com/writes/tecton-apply2021,,
"Databricks Data+AI Summit 2021
Free General Admission to learn on topics like:
Best practices and use cases for Apache Spark™, Delta Lake, MLflow
Data engineering, including streaming architectures
SQL analytics and BI using data warehouses and data lakes
Data science, including the Python ecosystem
Machine learning and deep learning applications
https://databricks.com/dataaisummit/north-america-2021","Databricks Data+AI Summit 2021 Free General Admission to learn on topics like: Best practices and use cases for Apache Spark™, Delta Lake, MLflow Data engineering, including streaming architectures SQL analytics and BI using data warehouses and data lakes Data science, including the Python ecosystem Machine learning and deep learning applications https://databricks.com/dataaisummit/north-america-2021",,
Cho mình tham khảo chút là đã có bạn nào thử sử dụng Kubeflow-v1.3 chưa ạ. Mình đang định chuyển hệ thống từ v1.1 -> v1.3 nhưng sợ là mới release nên nhiều lỗi.,Cho mình tham khảo chút là đã có bạn nào thử sử dụng Kubeflow-v1.3 chưa ạ. Mình đang định chuyển hệ thống từ v1.1 -> v1.3 nhưng sợ là mới release nên nhiều lỗi.,,
"Khoá học Machine Learning Systems Design của Stanford đã được update slides và notes rồi nha cả nhà :D
https://stanford-cs329s.github.io/syllabus.html",Khoá học Machine Learning Systems Design của Stanford đã được update slides và notes rồi nha cả nhà :D https://stanford-cs329s.github.io/syllabus.html,,
"Spam:
Katib giúp chúng ta optimize model bằng cách cho chạy nhiều trials với các set of hyperparams khác nhau.
Mỗi trial là 1 run nên sẽ rất tốn tài nguyên.
Vậy mọi người nghĩ sao nếu chúng ta hard-coding hyperparams?
Nghĩa là tạo 1 list các possible params và loop cho nó chạy 😀
Rất mong đc mọi người giải đáp.",Spam: Katib giúp chúng ta optimize model bằng cách cho chạy nhiều trials với các set of hyperparams khác nhau. Mỗi trial là 1 run nên sẽ rất tốn tài nguyên. Vậy mọi người nghĩ sao nếu chúng ta hard-coding hyperparams? Nghĩa là tạo 1 list các possible params và loop cho nó chạy Rất mong đc mọi người giải đáp.,,
"MLOps Security: An Overview of the Threats
🍻 Data Extraction 
🍻 Model Stealing
🍻 Model Tricking
🍻 Model Corruption
https://www.youtube.com/watch?v=hregcFryuC4",MLOps Security: An Overview of the Threats Data Extraction Model Stealing Model Tricking Model Corruption https://www.youtube.com/watch?v=hregcFryuC4,,
"One-line magical code to perform EDA!
Các bác biết tool nào khác tương tự thì comment để anh em cùng tham khảo với ạ 😄
https://pub.towardsai.net/one-line-magical-code-to-perform-eda-f83a731fbc35",One-line magical code to perform EDA! Các bác biết tool nào khác tương tự thì comment để anh em cùng tham khảo với ạ https://pub.towardsai.net/one-line-magical-code-to-perform-eda-f83a731fbc35,,
"Kubeflow Pipeline là để tạo 1 end-to-end machine learning pipeline.
Katib là để tuning hyper-params.
Ae nào đã integrate katib vào pipeline chưa?
Rất mong được chỉ giáo :D",Kubeflow Pipeline là để tạo 1 end-to-end machine learning pipeline. Katib là để tuning hyper-params. Ae nào đã integrate katib vào pipeline chưa? Rất mong được chỉ giáo :D,,
"Great Expectations component for Kubeflow has been released 🥳🍻🎂. This guide shows you how to integrate it into your pipeline!
https://medium.com/analytics-vidhya/data-quality-assurance-with-great-expectations-and-kubeflow-pipelines-d83449fbaa81",Great Expectations component for Kubeflow has been released . This guide shows you how to integrate it into your pipeline! https://medium.com/analytics-vidhya/data-quality-assurance-with-great-expectations-and-kubeflow-pipelines-d83449fbaa81,,
"Gentle reminder: Production ML conf live TODAY
https://www.facebook.com/curiousAI/posts/2387205408090381",Gentle reminder: Production ML conf live TODAY https://www.facebook.com/curiousAI/posts/2387205408090381,,
,nan,,
"A short article comparing MLOps vs DevOps
https://towardsdatascience.com/mlops-vs-devops-5c9a4d5a60ba",A short article comparing MLOps vs DevOps https://towardsdatascience.com/mlops-vs-devops-5c9a4d5a60ba,,
"How to improve software engineering skills as a researcher
Have a great week ahead! :D
https://ljvmiranda921.github.io/notebook/2020/11/15/data-science-swe/",How to improve software engineering skills as a researcher Have a great week ahead! :D https://ljvmiranda921.github.io/notebook/2020/11/15/data-science-swe/,,
"A logical, reasonably standardized, but flexible project structure for doing and sharing data science work.","A logical, reasonably standardized, but flexible project structure for doing and sharing data science work.",,
"How GPUs work?
https://rishtech.substack.com/p/gpus-101",How GPUs work? https://rishtech.substack.com/p/gpus-101,,
Thời tới cản không nổi :D chúc mừng C++,Thời tới cản không nổi :D chúc mừng C++,,
"https://www.fast.ai/2020/01/07/data-questionnaire/
Some considerations before starting a data project",https://www.fast.ai/2020/01/07/data-questionnaire/ Some considerations before starting a data project,,
"“What I’m finding is that for a lot of problems, it’d be useful to shift our mindset toward not just improving the code but in a more systematic way of improving the data,” said Andrew Ng","“What I’m finding is that for a lot of problems, it’d be useful to shift our mindset toward not just improving the code but in a more systematic way of improving the data,” said Andrew Ng",,
"Hello mọi người.
Có bác nào đang dùng Kubernetes + azure có thể cho m hỏi xíu với đc ko? M đang follow cái tutorial của kubeflow.org mà đang mắc chưa có hướng giải quyết. Rất mong được hỗ trợ!
Cám ơn mọi người.",Hello mọi người. Có bác nào đang dùng Kubernetes + azure có thể cho m hỏi xíu với đc ko? M đang follow cái tutorial của kubeflow.org mà đang mắc chưa có hướng giải quyết. Rất mong được hỗ trợ! Cám ơn mọi người.,,
"News Feed ranking algorithm at FB
https://engineering.fb.com/2021/01/26/ml-applications/news-feed-ranking/",News Feed ranking algorithm at FB https://engineering.fb.com/2021/01/26/ml-applications/news-feed-ranking/,,
"As you may already know, you can build ML models using BigQuery and SQL
https://towardsdatascience.com/how-to-build-ml-model-using-bigquery-eced0107e4fd","As you may already know, you can build ML models using BigQuery and SQL https://towardsdatascience.com/how-to-build-ml-model-using-bigquery-eced0107e4fd",,
A collection of resources on how to facilitate Machine Learning Ops with GitHub.,A collection of resources on how to facilitate Machine Learning Ops with GitHub.,,
Một bài viết hay về real-time trong Machine Learning,Một bài viết hay về real-time trong Machine Learning,,
ML Feature Serving Infrastructure at Lyft,ML Feature Serving Infrastructure at Lyft,,
"Great Expectations helps data teams eliminate pipeline debt, through data testing, documentation, and profiling.
https://greatexpectations.io/","Great Expectations helps data teams eliminate pipeline debt, through data testing, documentation, and profiling. https://greatexpectations.io/",,
"Feature Stores: The Data Side of ML Pipelines
😎 What are feature stores?
😎 Feature Stores Today: Challenges & Limitations
😎 The Future of Feature Stores",Feature Stores: The Data Side of ML Pipelines What are feature stores? Feature Stores Today: Challenges & Limitations The Future of Feature Stores,,
Jupyter kernel for scala and spark,Jupyter kernel for scala and spark,,
"Hi all, mình có 1 docker image >12Gb để deliver DL app lấy base từ rapids-ai. Nhằm giảm size mình đã thử multi-stage build từ 2 base là python-alpine, nvidia-cuda nhưng ko thành công. Các guide trên google chỉ dừng lại ở mức cơ bản (copy thư mục source code+venv từ stage0 sang) chứ ko đụng đến ENV như CUDA. Có ai biết cách làm đúng, có Dockerfile ví dụ hoặc có phương án bổ sung ko ạ? Mong mn giúp đỡ.
Note: kỳ vọng kết quả chỉ ~3Gb
Cảm ơn mọi người đã đọc.","Hi all, mình có 1 docker image >12Gb để deliver DL app lấy base từ rapids-ai. Nhằm giảm size mình đã thử multi-stage build từ 2 base là python-alpine, nvidia-cuda nhưng ko thành công. Các guide trên google chỉ dừng lại ở mức cơ bản (copy thư mục source code+venv từ stage0 sang) chứ ko đụng đến ENV như CUDA. Có ai biết cách làm đúng, có Dockerfile ví dụ hoặc có phương án bổ sung ko ạ? Mong mn giúp đỡ. Note: kỳ vọng kết quả chỉ ~3Gb Cảm ơn mọi người đã đọc.",,
"Ray Summit 2021
Topic included: ML in production, MLOps, deep & reinforcement learning, cloud computing, serverless, Ray libraries (RLlib, Tune, Serve, RaySGD, spaCy, Hugging Face & more)
https://www.anyscale.com/ray-summit-2021?fbclid=IwAR1-nIeBGOH4Fk5qUlFWLzlhc7Z5tfr9iU6BldJ23mZY6x75jvG3dONUBGc","Ray Summit 2021 Topic included: ML in production, MLOps, deep & reinforcement learning, cloud computing, serverless, Ray libraries (RLlib, Tune, Serve, RaySGD, spaCy, Hugging Face & more) https://www.anyscale.com/ray-summit-2021?fbclid=IwAR1-nIeBGOH4Fk5qUlFWLzlhc7Z5tfr9iU6BldJ23mZY6x75jvG3dONUBGc",,
Building Recommender Systems with PyTorch,Building Recommender Systems with PyTorch,,
Một số design pattern khi thiết kế các hệ thống ML,Một số design pattern khi thiết kế các hệ thống ML,,
Giới thiệu với mọi người buổi nói chuyện ngắn mới đây của Andrew Ng về chủ đề MLOps.,Giới thiệu với mọi người buổi nói chuyện ngắn mới đây của Andrew Ng về chủ đề MLOps.,,
"tecton.ai là một trong những công ty tiên phong xây dựng giải pháp Feature Store cho các hệ thống ML. Sắp tới tecton có tổ chức một hội nghị trực tuyến miễn phí về các best practices để xây dựng các ứng dụng ML, các bác nào rảnh thì join nghe ạ.
https://www.applyconf.com/?utm_source=Superb_AI&utm_medium=Referral&utm_campaign=apply_registration&utm_content=&fbclid=IwAR1ul7EQeeEDxpLzlZG8pTQJ_U-8l_xRKCPijJLVMn9p0ra2YADkCxoXaQU#","tecton.ai là một trong những công ty tiên phong xây dựng giải pháp Feature Store cho các hệ thống ML. Sắp tới tecton có tổ chức một hội nghị trực tuyến miễn phí về các best practices để xây dựng các ứng dụng ML, các bác nào rảnh thì join nghe ạ. https://www.applyconf.com/?utm_source=Superb_AI&utm_medium=Referral&utm_campaign=apply_registration&utm_content=&fbclid=IwAR1ul7EQeeEDxpLzlZG8pTQJ_U-8l_xRKCPijJLVMn9p0ra2YADkCxoXaQU#",,
"ML Platform của các công ty lớn trên thế giới như thế nào?
https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/?fbclid=IwAR3rvEsOfHJjHxLBPiGFvYArS5TMFg7iOwJ2LfuAjmtoUj9iZzZVmV5QGvw",ML Platform của các công ty lớn trên thế giới như thế nào? https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/?fbclid=IwAR3rvEsOfHJjHxLBPiGFvYArS5TMFg7iOwJ2LfuAjmtoUj9iZzZVmV5QGvw,,
"Khái niệm MLOps khá hot trong thời gian trở lại đây. Bài blog dưới đây giúp trả lời 3 câu hỏi chính:
😗 MLOps là gì?
😗 MLOps giải quyết vấn đề gì?
😗 MLOps yêu cầu những skills gì?
https://www.freecodecamp.org/news/what-is-mlops-machine-learning-operations-explained/?fbclid=IwAR0w39kZYOKW5uzB0fljkxftUF5bWZyzoQMJ6CmVfeZXgKkSkN3Csgml5sg",Khái niệm MLOps khá hot trong thời gian trở lại đây. Bài blog dưới đây giúp trả lời 3 câu hỏi chính: MLOps là gì? MLOps giải quyết vấn đề gì? MLOps yêu cầu những skills gì? https://www.freecodecamp.org/news/what-is-mlops-machine-learning-operations-explained/?fbclid=IwAR0w39kZYOKW5uzB0fljkxftUF5bWZyzoQMJ6CmVfeZXgKkSkN3Csgml5sg,,
,nan,,
Chia sẻ kiến thức về MLOps và Machine Learning in Production,Chia sẻ kiến thức về MLOps và Machine Learning in Production,,
,nan,,
