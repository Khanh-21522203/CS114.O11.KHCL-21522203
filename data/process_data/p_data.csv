Unnamed: 0,Contents,Hashtags,p_content
0,"Chào mọi người. Hiện tại em đang làm đồ án về truy vấn thông tin. Em làm về content based image retrieval. Em định làm thêm text based image retrieval nhưng em đang kẹt ở phần caption của image. Do dataset là phải tự scrape về nên chỉ có thể scrape được ảnh. Em có thử dùng 1 vài tool để tạo caption nhưng kết quả ra khá tệ. Giờ em phải làm như nào để tạo được caption ạ. Em cảm ơn mọi người.
#study #cv","['#Q&A', '#cv']","['chào', 'đồ án', 'truy vấn', 'thông content', 'based', 'image', 'retrieval định', 'text', 'based', 'image', 'retrieval', 'kẹt', 'caption', 'image', 'dataset', 'scrape thể', 'scrape', 'ảnh', 'thử', '1', 'tool', 'caption', 'kết tệ', 'caption']"
1,"Pandas datetime Cheat sheet 🔥🔥🔥
Cheat sheet 9 trang dưới đây tổng hợp toàn bộ những kiến thức và các hàm các bạn cần biết khi làm việc với dữ liệu thời gian trong Pandas 😍
Note lại để sau này sử dụng nha các bạn 😎
Link to pdf: https://drive.google.com/file/d/1psgt5ztGjszwCTmayIXERhfyFFP9tZ6B/view?usp=sharing
#ds_share #pandas #datetime","['#sharing', '#python']","['pandas', 'datetime', 'cheat', 'sheet', 'cheat', 'sheet', '9', 'trang', 'tổng hợp', 'toàn', 'kiến thức', 'hàm liệu', 'pandas', 'note nha', 'link', 'to', 'pdf']"
2,"Giải thích nhanh 8 thuật toán Machine Learning cơ bản nhất 🔥🔥🔥
Hi các bạn,
Dưới đây là bài viết tổng hợp 8 thuật toán cơ bản nhất trong Machine Learning đi kèm với tóm tắt ngắn gọn cho mỗi thuật toán. 1 tài liệu rất hữu ích cho những bạn đang muốn ôn tập để chuẩn bị cho các buổi phỏng vấn 😎
Link: https://datasciencedojo.com/blog/machine-learning-algorithms-explanation/
P/s: Mình không khuyến khích các bạn mới lần đầu học Machine learning đọc tài liệu này nha. Mới học thì các bạn nên đọc phiên bản đầy đủ thì sẽ tốt hơn là phiên bản tóm tắt 😁
#ml_share","['#sharing', '#machine_learning']","['giải', '8', 'thuật toán', 'machine', 'learning', 'hi viết', 'tổng hợp', '8', 'thuật toán', 'machine', 'learning', 'đi', 'kèm', 'tóm tắt', 'ngắn gọn', 'thuật toán', '1', 'tài liệu', 'hữu ích', 'ôn tập', 'chuẩn vấn', 'link', 'https', 'datasciencedojo', 'com', 'blog', 'machinelearningalgorithmsexplanation', 'p', 's', 'khuyến khích', 'đầu', 'học', 'machine learning', 'đọc', 'tài liệu', 'nha học', 'đọc', 'phiên', 'phiên', 'tóm tắt']"
3,"Khai giảng khoá học tháng 12/23 vs 01/24 💻💻💻
Chào các bạn,
Mình là Thắng. Hiện tại mình đang làm AI Research Associate tại TITUS Research institute, Brandenburg, CHLB Đức, đồng thời cũng là em trai của ông admin còn lại của group chúng ta, Việt Nguyễn 😅. Trong tháng 12 vs 01 này, chúng mình vẫn tiếp tục khai giảng 1 số lớp học về AI/ML/DS/CV dành cho các bạn đang ở VN cũng như nước ngoài, và đặc biệt hơn, chúng mình cũng triển khai lần đầu tiên khóa học về lập trình Python, dành cho các bạn chưa từng tiếp xúc với lập trình. 

Các bạn quan tâm đến các lớp học này, có thể liên hệ với chúng mình qua Zalo: 0349942449 

#py_course
 — với Việt Nguyễn tại Berlin, Đức.",['#sharing'],"['khai giảng', 'khóa', 'học', '12', '23', 'vs', '01', '24', 'chào thắng', 'research', 'associate', 'titus', 'research', 'institute', 'brandenburg', 'chlb', 'đức', 'trai', 'admin', 'group', 'ta', 'việt', 'nguyễn', '12', 'vs', '01', 'khai giảng', '1', 'lớp học', 'ml', 'ds', 'cv', 'vn', 'triển khai', 'khóa học', 'lập trình', 'python', 'tiếp xúc', 'lập trình', 'lớp học thể', 'liên hệ', 'zalo', '0349942449', 'việt', 'nguyễn berlin đức']"
4,"Playlist về Computer Vision của Joseph Redmon - cha đẻ của mô hình YOLO 🔥🔥🔥
Hi các bạn,
Post này dành riêng cho các bạn (muốn) theo mảng Computer Vision giống như mình. Đây là playlist có tên The Ancient Secrets of Computer Vision của Joseph Redmon. Nếu các bạn thấy cái tên này quen quen thì đúng vậy, ông chính là cha đẻ của mô hình You only look once (YOLO) huyền thoại mà bất kì ai học hay làm về Deep Learning for Computer Vision đều không thể không biết đến 😎
Playlist gồm 19 video này sẽ cover toàn bộ tất cả các kiến thức về Computer Vision, từ cơ bản cho đến nâng cao. 1 nguồn vô cùng chất lượng cho những bạn muốn học và làm về Computer Vision 🥰
Link to playlist: https://youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p&si=V1PeC9T-rdQuJPEk
#cv_share","['#sharing', '#cv']","['playlist', 'computer', 'vision', 'joseph redmon', 'đẻ', 'mô hình', 'yolo', 'hi post', 'mảng', 'computer', 'vision', 'playlist', 'the', 'ancient', 'secrets', 'of computer', 'vision', 'joseph', 'redmon', 'quen quen', 'đẻ', 'mô hình', 'you', 'only', 'look', 'once', 'yolo', 'huyền thoại', 'học', 'deep', 'learning', 'for', 'computer', 'vision thể', 'playlist', '19', 'video', 'cover', 'toàn', 'tất kiến thức', 'computer', 'vision', 'nâng', '1', 'vô chất', 'học', 'computer', 'vision', 'link', 'to', 'playlist']"
5,"VideoPoet: Model generation mới của Google 🔥🔥🔥
Google vừa cho ra mắt VideoPoet - model nhận input đầu vào dưới dạng text, image, optical flow hoặc masked video và tạo ra output là video có kèm theo âm thanh 😎
Link to post: https://blog.research.google/2023/12/videopoet-large-language-model-for-zero.html
#dl_share #llm",['#sharing'],"['videopoet', 'model', 'generation', 'google', 'google', 'mắt', 'videopoet', 'model', 'input', 'đầu', 'dạng', 'text', 'image', 'optical', 'flow', 'masked', 'video', 'output', 'video', 'kèm', 'âm link', 'to', 'post']"
6,"Dạ em là newbiew, em practive 1 project nhỏ ở dưới, em hỏi chatgpt để làm các model mà sao có mấy dòng code à, không biết làm như vầy đã được chưa, mong mọi người cho em ít nhận xét ạ, em cảm ơn mọi người nhiều
https://github.com/luongtien872003/Bank_Personal_Loan
#python, #ML, #Study",['#Q&A'],"['newbiew', 'practive', '1', 'project', 'chatgpt', 'model', 'mấy', 'dòng', 'code', 'vầy', 'mong', 'xét']"
7,"Dạ chào anh và mọi người, em xin đăng ẩn danh để hỏi ạ.
Dạ em học chuyện ngành AI code thì em học tạm ổn rồi ạ, em có một vài câu hỏi ạ:

Em cũng có học qua Data Science train model nhưng em cũng hong biết là mình có hiểu không tại là mình học đúng hong nữa em làm những bước của để train model thì em hiểu nhưng tới apply model vào thì em không biết là mình chọn model gì em cứ để đại vào rồi train thoi. Dạ toán Machine thì em học hiểu ạ nhưng còn apply những model đó vào code thì em chưa hiểu lắm ạ.
Dạ em chuẩn bị học computer vision, deep leaning và em cũng tích mãng này em có xem các khóa học trên youtube thì cũng có nhiều video của các trường dạy ạ nhưng em không biết bắt đầu từ đâu để đi đúng ạ. Dạ cho em hỏi phần train model đó nếu mình làm sau này ví dụ như computer vision thì có dùng hong ạ. 
Dạ cho em hỏi mảng computer vision thì ở Việt Nam mình có nhiều job hong ạ, em cũng nghĩ một số project mà em nghĩ thì hay nhưng sợ làm hong được.
Dạ em cảm ơn mn ạ. Dạ em cũng hong biết nhiều mong mn bỏ qua ạ.
#xx_study, #cv, #dl_cv, #ml","['#Q&A', '#cv']","['chào', 'đăng ẩn', 'danh học', 'ngành', 'code học', 'tạm', 'ổn', 'học', 'data', 'science', 'train', 'model', 'hong', 'học', 'hong', 'train', 'model', 'apply', 'model', 'model', 'đại train', 'thoi toán', 'machine', 'học', 'apply', 'model', 'code', 'lắm', 'chuẩn', 'học', 'computer', 'vision', 'deep', 'leaning tích', 'mãng', 'khóa', 'học', 'youtube', 'video', 'trường', 'dạy', 'đi', 'train', 'model', 'ví dụ', 'computer', 'vision', 'hong', 'mảng', 'computer', 'vision', 'việt nam', 'job', 'hong', 'project', 'sợ', 'hong', 'mn', 'hong', 'mong', 'mn']"
8,"Mọi người giúp em câu lệnh nào để e đảo ngược dữ liệu từ dưới lên trên với ạ, nghĩa là 12/12/2013 sẽ là đầu và 12/12/2023 là nằm dưới cuối.
Em cảm ơn
#ds_Study","['#Q&A', '#data']","['giúp', 'câu', 'lệnh', 'e đảo', 'ngược liệu', 'nghĩa', '12', '12', '2013', 'đầu', '12', '12', '2023', 'nằm']"
9,"[HCM] Mình đang tìm co-founder cho startup AI dài hạn, bạn nào quan tâm và thấy phù hợp thì inbox mình nhé, nếu bạn là chuyên về nghiên cứu AI càng phù hợp.
#AI_Startup",['#Q&A'],"['hcm', 'cofounder', 'startup', 'hạn', 'inbox', 'chuyên', 'nghiên cứu']"
10,Anh chị cho em hỏi là trong lúc học mà mình viết được papers thì có được điểm + trong mắt nhà tuyển dụng k ạ ! Em xin chân thành cảm ơn #ds_job #ds_Study,['#Q&A'],"['học', 'viết', 'papers mắt', 'tuyển dụng', 'k', 'chân thành']"
11,"Em đang muốn xin intern mà ko bt cách viết cv
Mn cho e xin mẫu templete và cáh trình bày đc ko ạ
#xx_study #dl #datascience",['#Q&A'],"['intern', 'ko', 'bt', 'viết', 'cv', 'mn', 'e mẫu', 'templete', 'cáh', 'trình bày', 'đc', 'ko']"
12,"Chào mọi người, chuyện là em đang muốn dùng selenium crawl data từ sàn hose mà em gặp lỗi là cùng 1 code nhưng lúc thì chạy ra dữ liệu, cái 1 lúc sau, củng là code đó em chạy lại mà không ra data.
Mọi người giúp em với ạ.
#xx_study","['#Q&A', '#data']","['chào', 'selenium', 'crawl', 'data', 'sàn', 'hose', 'lỗi', '1', 'code', 'chạy liệu', '1', 'củng code', 'chạy', 'data', 'giúp']"
13,"Em chào mọi người ạ, hiện tại thì em đang có 1 bài minitest về building recommendation system ấy ạ, nhưng mà sau khi em chạy flask trên visual code thì nó hiện lên như này ạ, em sửa mãi mấy hôm nay rồi mà không được, mọi người cho em xin ít ideas để xong trước thứ 6 với , em cảm ơn ạ.
#ds #ml #python #flask",['#Q&A'],"['chào', '1', 'minitest', 'building', 'recommendation system', 'chạy', 'flask', 'visual', 'code', 'hiện', 'sửa', 'mãi', 'mấy', 'hôm', 'ideas', 'xong', '6']"
14,"Cho em hỏi về graph embedding dùng gnn ( gcn và sage), thì ví dụ mình có 1 list các graph có số node khác nhau và cạnh nối có hướng, mỗi node chỉ có thông tin tên node.
Thì mình nên rút 1 số feature như thế nào để đưa vào model.
Mục đích của em là biểu diễn mỗi graph thành 1 vector có số chiều cố định sau đó đưa vào mô hình phân loại khác ạ.
Em có đọc 1 số bài code mẫu thì đều là chạy 1 graph và node embedding, mỗi node có label và feature có sẵn. Có thể cho em xin 1 số tài liệu về graph embedding mà có code mẫu thì càng tốt ạ.
#dl_code
#dl_graph","['#Q&A', '#deep_learning']","['graph', 'embedding', 'gnn', 'gcn', 'sage', 'ví dụ', '1', 'list', 'graph', 'node', 'cạnh', 'nối', 'hướng', 'node', 'thông', 'node', 'rút', '1', 'feature', 'model', 'mục đích', 'biểu diễn', 'graph', 'thành', '1', 'vector', 'chiều', 'cố định', 'mô hình', 'phân đọc', '1', 'code', 'mẫu', 'chạy', '1', 'graph', 'node', 'embedding', 'node', 'label', 'feature', 'sẵn thể', '1', 'tài liệu', 'graph', 'embedding', 'code', 'mẫu']"
15,"190 project Python với source code đi kèm 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn danh sách 190 project Python đi kèm với mã nguồn + giải thích, bao gồm:
96 project cơ bản
97 project nâng cao
Chủ đề của các project này rất đa dạng, từ game, app, similator cho đến AI model 😎
Cá nhân mình thì thấy các project cơ bản rất hữu ích cho các bạn mới làm quen với Python. Còn các project nâng cao thì có khoảng 1 nửa trong số này mình nghĩ là có thể sử dụng để làm đẹp cho Github profile của các bạn 🥰
Các bạn chú ý nhé, source code được cung cấp các bạn có thể coi như 1 nguồn để tham khảo. Hãy tự xây dựng hướng đi riêng cho mình nhé 😎
Link to pdf: https://drive.google.com/file/d/1xOP3vW2BNDJCvF8E8Lk_4_3AXLVMqbRT/view?usp=sharing
#py_share #project_share 
P/s: Các bạn down file pdf về là có thể click vào link nhé trong file nhé ☺️",['#sharing'],"['190', 'project', 'python', 'source', 'code', 'đi', 'kèm', 'hi danh sách', '190', 'project', 'python', 'đi', 'kèm mã', 'giải', 'bao', '96', 'project', '97', 'project', 'nâng', 'chủ đề', 'project', 'đa dạng', 'game', 'app', 'similator', 'model', 'project', 'hữu ích', 'quen', 'python', 'project', 'nâng', '1', 'nửa thể', 'đẹp', 'github', 'profile', 'source', 'code', 'cung thể', 'coi', '1', 'tham khảo', 'xây dựng', 'hướng', 'đi', 'link', 'to', 'pdf', 'p', 's', 'down', 'file', 'pdf thể', 'click', 'link', 'file']"
16,"Tài liệu khóa học Probability and Statistics for Data Science của Trung tâm khoa học dữ liệu tại đại học New York 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn tài liệu về xác suất thống kê cho Data Science đến từ đại học New York. Tài liệu này bao gồm các phần chính sau:
Lý thuyết xác suất cơ bản
Biến ngẫu nhiên
Biến ngẫu nhiên nhiều chiều
Kì vọng
Quá trình ngẫu nhiên (Phần này các bạn đọc lần đầu tạm bỏ qua cũng đư)
Sự hội tụ của quá trình ngẫu nhiên
Chuỗi Markov
Thống kê mô tả
Thống kê tần suất
Thống kê Bayesian 
Kiểm định giả thuyết 
Hồi quy tuyến tính
Lý thuyết tập hợp
Đại số tuyến tính
Theo đánh giá cá nhân của mình, lần đầu học các bạn có thể tạm thời bỏ qua phần 5,6,7,9,10 😁
Tài liệu của các trường đại học thì tất nhiên luôn hơi hàn lâm 1 chút. Cơ mà so với mặt bằng chung mình thấy quyển này lý thuyết ko quá khó. Tiêu hóa được các bạn nha 😎
Link to pdf: https://drive.google.com/file/d/1hClE8dN7jZhC3DdreyO8aVM2Sy79Df7e/view?usp=sharing
#ds_share","['#sharing', '#math']","['tài liệu', 'khóa học', 'probability and', 'statistics', 'for', 'data', 'science', 'trung tâm', 'khoa học liệu', 'đại học', 'new york', 'hi tài liệu', 'xác suất', 'thống kê', 'data', 'science', 'đại học', 'new', 'york', 'tài liệu', 'bao lý thuyết', 'xác suất', 'biến', 'ngẫu nhiên', 'biến', 'ngẫu nhiên', 'chiều kì', 'vọng trình', 'ngẫu nhiên', 'đọc', 'đầu', 'tạm', 'đư hội', 'tụ trình', 'ngẫu nhiên', 'chuỗi', 'markov', 'thống kê', 'mô tả', 'thống kê', 'tần suất', 'thống kê', 'bayesian', 'kiểm định', 'giả thuyết', 'hồi', 'quy tuyến', 'lý thuyết', 'tập hợp', 'đại tuyến', 'đầu', 'học thể', 'tạm thời', '5', '6', '7', '9', '10', 'tài liệu', 'trường', 'đại học', 'tất nhiên', 'hơi', 'hàn lâm', '1', 'chút', 'mặt', 'quyển', 'lý thuyết', 'ko tiêu', 'hóa', 'nha', 'link', 'to', 'pdf']"
17,"E chào cả nhà ạ, hiện tại e đang sử dụng tensorflow sequantial để thiết kế model nhưng e chưa hiểu nếu thêm hay bớt layer nào thì nó ảnh hưởng như nào tới kết quả. Cả nhà có thể nói sơ qua hoặc cmt giúp e có bài viết nào hiểu chi tiết phần này không ạ. E cảm ơn ạ!
#dl #tensorflow #tf","['#Q&A', '#python']","['e', 'chào e', 'tensorflow', 'sequantial', 'thiết kế', 'model', 'e', 'bớt', 'layer', 'ảnh hưởng', 'kết thể', 'sơ cmt', 'giúp', 'e', 'viết', 'chi tiết', 'e']"
18,"Em chào các anh/chị, các anh chị đã làm qua mô hình GAN và VAE để chỉnh sửa mặt mình nhập từ đầu vào và xuất ảnh xem kết quả thế nào chưa ạ, chỉ em cách chạy mô hình này với, em cảm ơn ạ!
#dl #ml","['#Q&A', '#cv', '#deep_learning']","['chào', 'mô hình', 'gan', 'vae', 'chỉnh sửa', 'mặt', 'nhập', 'đầu', 'xuất ảnh', 'kết', 'chạy', 'mô hình']"
19,"hi ae, có ai handle đoạn outlook nó trả ra cái blob_url cho cái ảnh capcha chưa ? em encode ra base64 bằng cái hàm trong tài liệu thì bị như này (decode ngược lại) ae đang xử lý nó như thế nào ? em thì viết python selenium, cho nó execute file js, chạy cái hàm như trong tài liệu. Cái ảnh có thuộc tính : background-image: url(&quot;blob:https://client-api.arkoselabs.com/7192fa35-d50f-481a-98ba...;);""
thanks admin, ae.
#selenium #outlook #funCaptchaV2 #blob","['#Q&A', '#python']","['hi ae', 'handle', 'đoạn', 'outlook', 'blob_url', 'ảnh', 'capcha', 'encode', 'base64 hàm', 'tài liệu', 'decode', 'ngược', 'ae', 'viết', 'python', 'selenium', 'execute', 'file', 'js', 'chạy', 'hàm tài liệu', 'ảnh', 'backgroundimage', 'url', 'quot', 'blob', 'https', 'clientapi', 'arkoselabs', 'com', '7192', 'fa35d50f481a98ba', 'thanks', 'admin', 'ae']"
20,"4 nhóm phương pháp chính để phát hiện Outliers 🔥🔥🔥
Hi các bạn,
2 hôm trước mình vừa đọc được 1 post rất hay trên linkedin về chủ đề outlier detection. Mình xin dịch + tóm gọn lại để các bạn cùng nắm được ☺️
Có rất nhiều phương pháp để có thể phát hiện được outliers, nhưng nhìn chung các phương pháp này sẽ được chia vào 4 nhóm lớn:
Nhóm dựa vào thống kê: Nhóm này dựa vào box plot hoặc các graph tương tự. Thường thì các điểm nằm ngoài vùng 1.5 lần interquartile có khả năng cao là outliers. Các điểm nằm ngoài vùng 3 lần interquartile được coi là các extreme outliers.
Nhóm dựa vào độ lân cận: Nhóm này dựa vào khoảng cách để xác định outliers. Thông thường thì KNN sẽ được sử dụng để chỉ ra các outliers dựa vào khoảng cách giữa chúng tới các điểm lân cận.
Nhóm dựa vào Time Series: Time Series làm tăng độ phức tạp do có xu hướng tổng quan của dữ liệu (trend effect) và xu hướng theo mùa hoặc tháng (seasonal effect). STL (Seasonal Trend Loses) Decomposition có thể được sử dụng để loại bỏ ảnh hưởng của các xu hướng này trước. Sau đó các kĩ thuật thống kê như là interquartile range (IQR) có thể được sử dụng để phát hiện outliers.
Nhóm dựa vào Machine Learning: 1 vài thuật toán Machine Learning như Isolation Forest có thể được dùng để phát hiện outliers. 
Link đến bài viết gốc: https://www.linkedin.com/posts/mattdancho_outliers-have-led-me-to-100s-of-business-activity-7142179371833782272-TeVN?utm_source=share&utm_medium=member_desktop
#ml_share","['#sharing', '#machine_learning']","['4', 'phương pháp', 'phát hiện', 'outliers', 'hi', '2', 'hôm', 'đọc', '1', 'post', 'linkedin', 'chủ đề', 'outlier', 'detection', 'dịch', 'tóm', 'gọn', 'nắm', 'phương pháp thể', 'phát hiện', 'outliers', 'phương pháp', 'chia', '4', 'dựa', 'thống kê', 'dựa', 'box', 'plot', 'graph', 'tương nằm', '1', '5', 'interquartile', 'khả năng', 'outliers', 'nằm', '3', 'interquartile', 'coi', 'extreme', 'outliers', 'dựa độ', 'lân cận', 'dựa', 'xác định', 'outliers', 'thông knn', 'outliers', 'dựa', 'lân cận', 'dựa', 'time', 'series', 'time', 'series độ', 'phức tạp', 'xu hướng', 'tổng quan liệu', 'trend', 'effect', 'xu hướng', 'mùa', 'seasonal', 'effect', 'stl', 'seasonal', 'trend', 'loses', 'decomposition thể', 'ảnh hưởng', 'xu hướng', 'kĩ thuật', 'thống kê', 'interquartile', 'range', 'iqr thể', 'phát hiện', 'outliers', 'dựa', 'machine', 'learning', '1', 'thuật toán', 'machine', 'learning', 'isolation', 'forest thể', 'phát hiện', 'outliers', 'link', 'viết', 'gốc']"
21,"Buổi học miễn phí lập trình Python cơ bản

Python đã và đang trở thành 1 trong những ngôn ngữ lập trình phổ biến nhất hiện nay. Python được sử dụng trong rất nhiều lĩnh vực, từ thiết kế web, game..... cho đến lĩnh vực đang hot nhất hiện nay, AI.
Thứ 4, 27/12/2023, 19:00-20:00 (theo múi giờ VN GMT+7), Việt vs mình sẽ tổ chức 1 buổi dạy lập trình Python cơ bản hoàn toàn free, dành cho các bạn chưa từng lập trình bao giờ. Nếu các bạn quan tâm, các bạn có thể điền thông tin theo đường link bên dưới nhé, chúng mình sẽ gửi link tham gia buổi học vào email mà các bạn đăng ký  
https://youtu.be/9gQV_-qdleI?si=QiO1rrKUz0Pxzh50

#py_course","['#webinar', '#python']","['học', 'miễn phí', 'lập trình', 'python', 'python', '1', 'ngôn ngữ', 'lập trình', 'phổ biến', 'python', 'lĩnh vực', 'thiết kế', 'web', 'game', 'lĩnh vực', 'hot', '4', '27', '12', '2023', '19', '0020', '00', 'múi', 'vn', 'gmt', '7', 'việt', 'vs', 'tổ chức', '1', 'dạy', 'lập trình', 'python free', 'lập trình thể', 'điền thông', 'đường', 'link', 'gửi', 'link', 'tham gia', 'học', 'email', 'đăng ký']"
22,"[ Machine Learning Web app]
Mình có tìm hiểu về ML web app, và mình thấy có các libraries cũng như framworks: Flask, Diago, Thinkter, PyQt5, Streamlit, Taipy, Gradio...Các bác đã dùng cái nào rồi xin cho lời khuyên với nhé.
[LaTex đính kèm file pdf]
Mình đang viết cv bằng LaTex trên overleaf, chẳng là mình muốn đính kèm một file hình ảnh pdf sao cho khi mình click vào thì nó sẽ mở lên xem như trình duyệt web. Vì mò mãi ko ra nên mình đã thử push file pdf lên github và đính kèm link github. Mình ko biết có cách nào để làm thế trên LaTex hay ko, nhờ mn chỉ giáo.
#hoidap #discuss #LaTex #mlwebapp",['#Q&A'],"['machine', 'learning', 'web', 'app', 'ml', 'web', 'app', 'libraries', 'framworks', 'flask', 'diago', 'thinkter', 'pyqt5', 'streamlit', 'taipy', 'gradio', 'khuyên', 'latex', 'đính', 'kèm', 'file', 'pdf', 'viết', 'cv', 'latex', 'overleaf', 'chẳng', 'đính', 'kèm', 'file', 'hình ảnh', 'pdf', 'click', 'trình duyệt', 'web mò', 'mãi', 'ko', 'thử', 'push', 'file', 'pdf', 'github', 'đính', 'kèm', 'link', 'github', 'ko', 'latex', 'ko', 'mn giáo']"
23,"Em chào mọi người
Mọi người cho em hỏi sự khác biệt giữa standard supervised fine-tuning và instruction-tuning cho closed-domain là gì được không ạ?
Theo em hiểu là : standard supervised fine-tuning dùng cho single task còn instruction-tuning có thể là multi task ạ
em cảm ơn
#qa #nlp","['#Q&A', '#machine_learning']","['chào biệt', 'standard', 'supervised', 'finetuning', 'instructiontuning', 'closeddomain', 'standard', 'supervised', 'finetuning', 'single', 'task', 'instructiontuning thể', 'multi', 'task']"
24,"#dl_nlp
Chào mọi người hiện tại em đang làm một project về sentiment analysis tiếng việt về review sản phẩm công nghệ. Mọi người có thể cho em xin tài liệu đọc về mảng này xử lí hiện nay và tiền xử lý dữ liệu ntn được không ạ","['#Q&A', '#nlp']","['chào', 'project', 'sentiment', 'analysis', 'tiếng', 'việt', 'review', 'sản phẩm', 'công nghệ thể', 'tài liệu', 'đọc', 'mảng', 'xử lí', 'tiền liệu', 'ntn']"
25,"Tổng hợp và xếp hạng các thư viện về Data Visualization trong Python 🔥🔥🔥
Hi các bạn,
Dưới đây là tổng hợp các thư viện về Data Visualization, được xếp hạng dựa trên sự kết hợp giữa nhiều metrics khác nhau, như độ phổ biến và số lượt cài đặt.
Cái tên đứng đầu thì có lẽ không có ai học về Data Science/Machine Learning mà lại không biết 😎
Link: https://github.com/ml-tooling/best-of-ml-python?tab=readme-ov-file#data-visualization
#ml_share #ds_share","['#sharing', '#python']","['tổng hợp', 'xếp hạng', 'thư viện', 'data', 'visualization', 'python', 'hi tổng hợp', 'thư viện', 'data', 'visualization', 'xếp hạng', 'dựa', 'kết hợp', 'metrics độ', 'phổ biến', 'lượt', 'cài', 'đứng', 'đầu lẽ', 'học', 'data', 'science', 'machine', 'learning', 'link']"
26,"#hoidap
Chào anh Việt và mọi người.
Em đang thắc mắc về viết research paper.
Nghe mọi người bảo là viết paper sẽ dễ kiếm được việc làm hơn ạ.
Vậy để viết paper mình có cần có mentor ko ạ? Có cần đi xin làm trợ lý giản viên ko ạ?
Và viết paper là viết cái gì ạ? Đăng nó ở đâu ạ?
Mong mọi người giải đáp em cảm ơn.",['#Q&A'],"['chào', 'việt', 'thắc mắc', 'viết', 'research', 'paper', 'bảo', 'viết', 'paper', 'kiếm', 'viết', 'paper', 'mentor', 'ko', 'đi', 'trợ lý', 'giản viên', 'ko', 'viết', 'paper', 'viết', 'đăng mong', 'giải đáp']"
27,"Muốn thành công thì nên chăm chỉ học tập mọi lúc mọi nơi các bạn nhé 😎
#relax ",['#sharing'],"['thành công', 'chăm', 'học tập']"
28,"Nguồn học về CNN tốt nhất với cá nhân mình 🔥🔥🔥
Hi các bạn,
Trong quá trình ngày xưa đi học cũng như bây giờ đi làm + dạy học vào cuối tuần, mình đã từng đọc rất nhiều các tài liệu về CNN. Tuy nhiên đối với cá nhân mình, các nguồn từ đại học Stanford vẫn để lại cho mình nhiều ấn tượng nhất (có lẽ 1 phần lý do là vì đây là 1 trong những nguồn đầu tiên mình học)
Cụ thể lecture note được trích từ course CS231n của Stanford có thể coi là 1 trong các nguồn xuất sắc nhất, giới thiệu và giải thích về CNN, bao gồm các layer cũng như các kiến trúc kinh điển. Không quá dài dòng hàn lâm nhưng đủ chi tiết để đọng lại nơi người đọc 😎
Link: https://cs231n.github.io/convolutional-networks/","['#sharing', '#deep_learning']","['học', 'cnn', 'hi trình', 'xưa', 'đi', 'học', 'đi', 'dạy học', 'tuần', 'đọc', 'tài liệu', 'cnn nhiên', 'đối đại học', 'stanford', 'ấn tượng', 'lẽ', '1', 'lý', '1', 'học', 'lecture', 'note', 'trích', 'course', 'cs231n', 'stanford thể', 'coi', '1', 'xuất sắc', 'giới thiệu', 'giải', 'cnn', 'bao layer', 'kiến trúc', 'kinh điển', 'dòng', 'hàn lâm', 'chi tiết đọng', 'đọc', 'link', 'https', 'cs231n', 'github', 'io', 'convolutionalnetworks']"
29,"Đánh giá mô hình, chọn mô hình và chọn thuật toán trong Machine Learning 🔥🔥🔥
Mình mới đọc được 1 bài post rất hay trên Linkedin về chủ đề đánh giá và lựa chọn mô hình cũng như thuật toán trong Machine Learning, đi kèm với 1 paper về chủ đề này. Mình xin dịch lại ở dưới đây:
Do tính chất công việc, gần đây tôi phải phỏng vấn rất nhiều ứng cử viên cho các vị trí về Machine Learning. Tôi thấy rằng có rất nhiều ứng cử viên đã từng làm việc trong rất nhiều project thú vị, và họ cũng biết sử dụng rất nhiều framework và thư viện Machine Learning. 
Tuy nhiên hầu hết họ đều gặp khó khăn trong việc trả lời các câu hỏi về thống kê, đặc biệt là về kiểm định giả thuyết. Các bài test này là rất quá trọng trong việc tìm ra đâu là mô hình tốt nhất để đưa vào triển khai trong thực tế. Các bạn không thể nào chỉ dựa vào 1 vài metrics được tính trên 1 cách chia train/test set 1 cách ngẫu nhiên được.
Tôi tìm thấy 1 bài báo, trong đó giải thích 1 cách đơn giản và dễ hiểu việc áp dụng các bài test này trong thực tế.
Bài báo có tiêu đề: Model evaluation, Model Selection, and Algorithm Selection in Machine Learning 
Link to article: https://arxiv.org/pdf/1811.12808.pdf
#ml_share","['#sharing', '#machine_learning']","['mô hình', 'mô hình', 'thuật toán', 'machine', 'learning', 'đọc', '1', 'post', 'linkedin', 'chủ đề', 'lựa', 'mô hình', 'thuật toán', 'machine', 'learning', 'đi', 'kèm', '1', 'paper', 'chủ đề', 'dịch', 'chất', 'công vấn', 'ứng cử viên', 'machine', 'learning', 'ứng cử viên', 'project', 'thú vị', 'framework', 'thư viện', 'machine', 'learning nhiên', 'khăn', 'thống kê', 'kiểm định', 'giả thuyết', 'test trọng', 'mô hình', 'triển khai thể', 'dựa', '1', 'metrics', '1', 'chia', 'train', 'test', 'set', '1', 'ngẫu nhiên', '1', 'báo', 'giải', '1', 'đơn giản', 'áp dụng', 'test', 'báo', 'tiêu đề', 'model', 'evaluation', 'model selection', 'and algorithm', 'selection', 'in', 'machine', 'learning', 'link', 'to', 'article']"
30,"Pix2TeX - Thư viện Python giúp chuyển đổi ảnh công thức thành code LaTeX 😎😎😎
Thư viện này hiện đã có 7k6 stars rồi các bạn nha 🥳
Link: https://github.com/lukas-blecher/LaTeX-OCR
#dl_share","['#sharing', '#python']","['pix2tex', 'thư viện', 'python', 'giúp', 'đổi', 'ảnh', 'công thức', 'thành', 'code', 'latex', 'thư viện', 'hiện', '7', 'k6', 'stars', 'nha', 'link']"
31,"Em chào mọi người, em đang làm về một đề tài  dùng AI để lọc content trên mạng xã hội. nó quét câu từ vi phạm các tiêu chuẩn cộng đồng phổ biến, học luôn các từ viết tắt và chơi chữ vi phạm tiêu chuẩn cộng đồng.
Ai trong nhóm đã từng làm về vấn đề này hay có bộ dataset nào phù hợp có thể cho em xin với được không ạ.
Em cám ơn anh chị nhiều ạ.
#dl_ask","['#Q&A', '#nlp']","['chào', 'đề tài', 'lọc', 'content mạng', 'xã hội', 'quét', 'câu', 'vi phạm', 'tiêu chuẩn', 'cộng đồng', 'phổ biến', 'học', 'viết', 'tắt', 'chữ', 'vi phạm', 'tiêu chuẩn', 'cộng đồng', 'dataset thể', 'cám ơn']"
32,"Mọi người cho em hỏi lỗi này fix như này ạ? Em đổi thành learning_rate thì nó lại ra một lỗi khác
#dl_ask","['#Q&A', '#machine_learning']","['lỗi', 'fix', 'đổi', 'thành', 'learning_rate', 'lỗi']"
33,"Deep Learning Interviews - 400 trang sách tổng hợp các câu hỏi và đáp án về các vấn đề trong thực tế về Deep Learning 🔥🔥🔥
1 cuốn sách đầy đủ tập trung vào các câu hỏi Deep Learning mang tính ứng dụng hơn là lý thuyết thuần 😎 
Với cá nhân mình thì quyển sách rất hữu ích trong việc tự kiểm tra bản thân xem liệu mình có hiểu rõ bản chất không hay chỉ thuộc lòng lý thuyết thôi 😁
Link to pdf: https://arxiv.org/ftp/arxiv/papers/2201/2201.00650.pdf
#dl_share","['#sharing', '#deep_learning']","['deep', 'learning', 'interviews', '400', 'trang sách', 'tổng hợp', 'đáp án', 'deep', 'learning', '1', 'sách', 'deep learning', 'ứng dụng', 'lý thuyết', 'quyển', 'sách', 'hữu ích', 'kiểm tra', 'thân liệu', 'chất', 'lý thuyết', 'link', 'to', 'pdf']"
34,"Em muốn hỏi là mọi người học machine learning trong bao lâu để học tiếp deep learning vậy ạ.
#machinelearning",['#Q&A'],"['học', 'machine', 'learning', 'học', 'tiếp', 'deep', 'learning']"
35,"Chuyện là mình muốn làm 1 project nhận diện từ vựng (tiếng Nhật) từ chữ viết tay là mình chưa tìm được nguồn data từ vựng nào đủ lớn. Mọi người ai đã làm qua chủ đề này cho mình xin 1 vài nguồn data với ạ. Cảm ơn mọi người nhiều
#deep_learning","['#Q&A', '#deep_learning', '#cv']","['1', 'project diện', 'vựng', 'tiếng', 'nhật', 'chữ viết', 'data', 'vựng', 'chủ đề', '1', 'data']"
36,"Dive into Deep Learning - cuốn sách Deep Learning cực hot dạng tương tác, bao gồm lý thuyết, Toán, code và cả phần thảo luận dành cho người đọc. Có cả bản tiếng Việt 🇻🇳🇻🇳🇻🇳
Link to English version: https://d2l.ai/
Link to Vietnamese version: https://d2l.aivivn.com/

Mình xin giới thiệu 1 quyển sách tương tác CỰC KÌ nổi tiếng về Deep learning: Dive into Deep Learning. Quyển sách này có các điểm độc đáo mà các bạn sẽ không thể tìm thấy ở bất kì 1 quyển sách nào khác:
Sách tương tác: Các bạn có thể click vào các link, ảnh hay video ở các trang sách. Điều đó khiến cho quá trình di chuyển giữa các phần trở nên linh hoạt và nhanh hơn, giúp cho quá trình học trở nên thú vị hơn 🥳
Code và Toán đi kèm với mỗi phần thay vì nằm riêng biệt với lý thuyết: Điều này giúp cho các bạn có thể học 1 cách mạch lạc hơn, khi học đến đâu các bạn sẽ được học luôn những kiến thức Toán cần thiết và thực hành code luôn. Điều này là điểm khác biệt với rất nhiều đầu sách ML/DL khác, khi Toán nằm ở 1 phần riêng, khiến cho nhiều bạn sau khi học xong kiến thức Toán các bạn không biết kiến thức đó sẽ được áp dụng như thế nào trong ML/DL 🥹
Code dưới nhiều framework khác nhau: Đây là 1 điểm cực kì thú vị. Khác với đa phần các sách truyền thống hay ebook khác, khi người dùng phải dùng đúng framework mà tác giả xài. Ở quyển sách này, các bạn có thể chọn 1 trong số các framework Deep Learning phổ biến nhất hiện nay như Pytorch, Tensorflow hay MXNet (framework của Microsoft) + Numpy để thực hành. Điều này là 1 điểm cộng vô cùng lớn cho nhóm tác giả khi giúp người đọc không phải sử dụng 1 framework trái tay 😍
Sách đa ngôn ngữ: Quyển sách đã được dịch sang nhiều ngôn ngữ khác nhau, bao gồm cả tiếng Việt của chúng ta (Như các bạn có thể thấy trong screenshot). Quả là tuyệt vời phải không các bạn 🥰
Nội dung FATHER OF đầy đủ: Đây là điểm gây ấn tượng nhất với mình. Cover tuốt mọi thứ về Deep Learning, gần như không thiếu bất kì 1 topic nào. Mình có thể khẳng định các bạn có thể học từ cơ bản đến chuyên sâu về Deep Learning chỉ với quyển sách này là tài liệu duy nhất 🤩","['#sharing', '#deep_learning']","['dive', 'into', 'deep', 'learning', 'sách', 'deep', 'learning', 'cực', 'hot dạng', 'tương tác', 'bao lý', 'thuyết toán', 'code', 'thảo luận', 'đọc', 'tiếng', 'việt', 'link', 'to', 'english', 'version', 'https', 'd2l', 'link', 'to', 'vietnamese', 'version', 'https', 'd2l', 'aivivn', 'com', 'giới thiệu', '1', 'quyển', 'sách', 'tương tác', 'cực kì', 'nổi tiếng', 'deep', 'learning', 'dive', 'into', 'deep', 'learning', 'quyển', 'sách', 'độc đáo thể', '1', 'quyển', 'sách', 'sách', 'tương tác thể', 'click', 'link', 'ảnh', 'video trang', 'sách trình', 'di trở', 'linh hoạt', 'giúp', 'trình học', 'trở', 'thú vị', 'code toán', 'đi', 'kèm', 'thay', 'nằm', 'biệt lý thuyết', 'giúp thể', 'học', '1', 'mạch lạc', 'học học', 'kiến thức', 'toán thiết thực hành', 'code biệt', 'đầu sách', 'ml', 'dl toán', 'nằm', '1', 'học', 'xong', 'kiến thức toán', 'kiến thức', 'áp dụng', 'ml', 'dl', 'code', 'framework', '1', 'cực kì', 'thú vị', 'đa sách', 'truyền thống', 'ebook', 'framework tác giả', 'xài', 'quyển', 'sách thể', '1', 'framework', 'deep', 'learning', 'phổ biến', 'pytorch', 'tensorflow', 'mxnet', 'framework', 'microsoft', 'numpy', 'thực hành', '1', 'cộng', 'vô tác giả', 'giúp', 'đọc', '1', 'framework', 'trái', 'sách', 'đa ngôn ngữ', 'quyển', 'sách dịch', 'ngôn ngữ', 'bao', 'tiếng', 'việt', 'ta thể', 'screenshot', 'tuyệt vời', 'nội dung', 'father of', 'ấn tượng', 'cover', 'tuốt', 'deep', 'learning', '1', 'topic thể thể', 'học', 'chuyên sâu', 'deep', 'learning', 'quyển', 'sách', 'tài liệu']"
37,"71 Python project với mã nguồn và tài liệu tham khảo 🔥🔥🔥
Hầu hết các project đều ở mức độ dễ và vừa các bạn nha. Có 1 vài project cuối là về Machine Learning 😁
Link to pdf: https://drive.google.com/file/d/1mUiEYSAijI4Jtihf0zdechAcAkG_j4o5/view?usp=sharing","['#sharing', '#python']","['71', 'python', 'project mã', 'tài liệu', 'tham khảo', 'project độ', 'nha', '1', 'project', 'machine', 'learning', 'link', 'to', 'pdf']"
38,"Tensorflow Examples: Comprehensive tutorial dành riêng cho Tensorflow 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 Github repo được thiết kế giúp các bạn làm quen và sử dụng Tensorflow từ A-Z, thông qua các ví dụ. 
Để đảm bảo phù hợp cho tất cả mọi người với nhu cầu sử dụng khác nhau, tất cả các notebook và source code sẽ đi kèm với giải thích cả với Tensorflow v1 và v2 😎. Repo sẽ bao gồm các phần chính sau:
Introduction 
Basic models:
Neural Networks
Utilities
Data management
Hardware
1 nguồn vô cùng chất lượng dành cho những bạn muốn tìm hiểu và thực hành với framework nổi tiếng này 😎
Link to repo: https://github.com/aymericdamien/TensorFlow-Examples
#ml_share #dl_share","['#sharing', '#python']","['tensorflow', 'examples', 'comprehensive', 'tutorial', 'tensorflow', 'hi', 'giới thiệu', '1', 'github', 'repo', 'thiết kế', 'giúp', 'quen', 'tensorflow', 'az', 'thông', 'ví dụ', 'tất', 'nhu cầu', 'tất notebook', 'source', 'code', 'đi', 'kèm', 'giải', 'tensorflow', 'v1', 'v2', 'repo', 'bao', 'introduction', 'basic', 'models', 'neural', 'networks', 'utilities', 'data', 'management', 'hardware', '1', 'vô chất', 'thực hành', 'framework', 'nổi tiếng', 'link', 'to', 'repo']"
39,"Bộ sưu tập các Cheat sheet về Data Science 🔥🔥🔥 
Hi các bạn,
Nguồn dưới đây tổng hợp các cheat sheet về các topic khác nhau mà 1 Data Scientist nên nắm vững, bao gồm:
SQL 
Web Scraping 
Toán, xác suất và thống kê
Data Analytics 
Business Intelligence 
Big Data 
Cấu trúc dữ liệu và giải thuật 
Machine Learning 
Deep Learning
NLP 
Data Engineering 
Web Frameworks
Link to pdf: https://drive.google.com/file/d/1jyAcbrXw_fnlML98MMD-oGhLGUhx4yqZ/view?usp=sharing
P/s: Có 1 vài link trong danh sách này bị die các bạn nha 😢
#ds_share","['#sharing', '#data']","['sưu tập', 'cheat', 'sheet', 'data', 'science', 'hi tổng hợp', 'cheat', 'sheet', 'topic', '1', 'data', 'scientist', 'nắm', 'vững', 'bao', 'sql web', 'scraping toán', 'xác suất', 'thống kê', 'data analytics', 'business', 'intelligence', 'big data', 'cấu trúc liệu', 'giải thuật', 'machine', 'learning', 'deep', 'learning', 'nlp', 'data', 'engineering', 'web', 'frameworks', 'link', 'to', 'pdf', 'p', 's', '1', 'link', 'danh sách', 'die nha']"
40,"Mình train yolov7, data trên 1m image, bath = 32 , imgsz=512. GPU ăn dc có 4.5G. Nhưng sao cứ chạy dc đến vài chục epoch thì nó out nhỉ?
Time done 1 epoch khá lâu nên mất thời gian + tiền điện quá 🥲
#yolo #computervision","['#Q&A', '#cv', '#deep_learning']","['train', 'yolov7', 'data', '1', 'm', 'image', 'bath', '32', 'imgsz', '512', 'gpu', 'dc', '4', '5', 'g', 'chạy', 'dc', 'chục', 'epoch', 'out', 'time', 'done', '1', 'epoch', 'tiền', 'điện']"
41,"Chào mọi người, 
em có đoạn code deeplearning dự báo dữ liệu time series. Tuy nhiên, sau mỗi lần chạy em lại nhận kết quả khác nhau. Có cách nào em nhận cố định một kết quả sau mỗi lần chạy không ạ?
Em có thử đoạn code này mà vẫn không được ạ:

np.random.seed(0)
tf.random.set_seed(0)

 #DL","['#Q&A', '#deep_learning']","['chào', 'đoạn', 'code', 'deeplearning', 'dự báo', 'liệu', 'time', 'series nhiên', 'chạy kết', 'cố định kết', 'chạy', 'thử', 'đoạn', 'code', 'np', 'random', 'seed', '0', 'tf', 'random', 'set_seed', '0']"
42,"Admin mới share paper của Sebastian Raschka, mình share thêm một platform này, cũng do anh này đứng sau, mình chưa có cơ hội thử cụ thể nhưng thử qua thấy cũng hay, bạn nào tò mò thử khám phá rồi cho mọi người biết.
#dl_share",['#sharing'],"['admin', 'share', 'paper', 'sebastian', 'raschka', 'share', 'platform', 'đứng', 'hội', 'thử', 'thử', 'tò mò', 'thử', 'khám phá']"
43,"mọi người cho em hỏi, em có train model densenet121 cho bài toán multilabel classification với đầu vào là poster phim và label là các thể loại phim, em có train lần đầu thì tỉ lệ max chỉ có 70% nhưng với tập test chỉ có loanh quanh 30% thì nguyên nhân từ đâu vậy ạ
#ml
#dl","['#Q&A', '#deep_learning', '#cv']","['train', 'model', 'densenet121 toán', 'multilabel', 'classification', 'đầu', 'poster', 'phim', 'label thể', 'phim', 'train', 'đầu', 'tỉ lệ', 'max', '70', 'tập', 'test', 'loanh quanh', '30', 'nguyên nhân']"
44,"#Other
E đã tìm hiểu trên đủ các loại diễn đàn 2 hôm nay mà không tài nào fix được:(( Pls help!!!
Terminal: Traceback (most recent call last):
File ""C:\CodeTester\Python\Test.py"", line 1, in <module>
import tensorflow as ts
File ""C:\Users\erwin\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\__init__.py"", line 45, in <module>
from tensorflow.python import tf2 as _tf2
File ""C:\Users\erwin\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\tf2.py"", line 21, in <module>
from tensorflow.python.platform import _pywrap_tf2
ImportError: DLL load failed while importing _pywrap_tf2: A dynamic link library (DLL) initialization routine failed.
[Finished in 1.6s]","['#Q&A', '#python']","['e', 'diễn đàn', '2', 'hôm', 'tài fix', 'pls', 'help', 'terminal', 'traceback', 'most', 'recent', 'call', 'last', 'file', 'c', 'codetester', 'python', 'line', '1', 'in', 'module', 'import', 'tensorflow', 'as', 'ts', 'file', 'c', 'users', 'erwin', 'appdata', 'local', 'programs', 'python', 'python311', 'lib', 'sitepackages', 'tensorflow', '__init__', 'py', 'line', '45', 'in', 'module', 'from', 'tensorflow', 'python', 'import', 'tf2', 'as', '_tf2', 'file', 'c', 'users', 'erwin', 'appdata', 'local', 'programs', 'python', 'python311', 'lib', 'sitepackages', 'tensorflow', 'python', 'line', '21', 'in', 'module', 'from', 'tensorflow', 'python', 'platform', 'import', '_pywrap_tf2', 'importerror', 'dll', 'load', 'failed', 'while', 'importing', '_pywrap_tf2 a', 'dynamic', 'link', 'library', 'dll', 'initialization', 'routine', 'failed', 'finished', 'in', '1', '6', 's']"
45,"Khóa học AI for Beginners của Microsoft 🔥🔥🔥 
Hi các bạn,
Trong mấy ngày vừa rồi mình đã thấy ít nhất 3 group chia sẻ về khóa học này rồi, nên mình cũng tiện đường công tác chia sẻ lại với các bạn trong group của chúng ta. Khóa học kéo dài 12 tuần với 24 bài học này sẽ trang bị cho người học những kiến thức cơ bản nhất về:
AI
Neural Network
Computer Vision
Natural Language Processing
Mỗi bài sẽ bao gồm lý thuyết, notebook và bài tập. Có 1 điều các bạn cần chú ý: Do khóa học hướng tới kiến thức cơ bản cho người mới có thể tiếp cận nên các kiến thức về các mô hình Machine Learning cổ điển hay các kiến thức Toán căn bản sẽ không được đề cập trong khóa học này các bạn nhé 😎
Link to course: https://github.com/microsoft/AI-For-Beginners
#ai_share","['#sharing', '#machine_learning']","['khóa', 'học', 'for', 'beginners', 'microsoft', 'hi mấy', '3', 'group', 'khóa', 'học tiện', 'đường', 'công tác', 'group', 'ta', 'khóa học', 'kéo', '12', 'tuần', '24', 'học', 'trang học', 'kiến thức', 'neural', 'network', 'computer', 'vision', 'natural', 'language', 'processing', 'bao', 'lý thuyết', 'notebook tập', '1', 'khóa', 'học', 'hướng', 'kiến thức thể', 'tiếp cận', 'kiến thức', 'mô hình', 'machine learning', 'cổ điển', 'kiến thức toán', 'đề cập', 'khóa', 'học', 'link', 'to', 'course']"
46,"Repo Github tổng hợp các Machine Learning và Deep Learning tutorials 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 repo Github rất nổi tiếng - 1 nguồn All-in-one tổng hợp tất cả các tutorials, articles, interview cũng như các blog nổi tiếng nhất về Machine Learning và Deep Learning. Hiện tại repo này đã có 3.7k forks và 14.3k stars các bạn nhé 😎
Link to repo: https://github.com/ujjwalkarn/Machine-Learning-Tutorials
#ml_share #dl_share",['#sharing'],"['repo', 'github', 'tổng hợp', 'machine', 'learning', 'deep', 'learning', 'tutorials', 'hi', 'giới thiệu', '1', 'repo', 'github', 'nổi tiếng', '1', 'allinone', 'tổng hợp', 'tất tutorials', 'articles', 'interview', 'blog', 'nổi tiếng', 'machine', 'learning', 'deep', 'learning', 'repo', '3', '7', 'k', 'forks', '14', '3', 'k', 'stars', 'link', 'to', 'repo']"
47,"Machine Learning for Time-series with Python 🔥🔥🔥
Hi các bạn,
Time-series forecasting là 1 trong số các bài toán quan trọng mà bất kì 1 Data Scientist nào cũng phải nắm được. Mình xin giới thiệu với các bạn 1 quyển sách về chủ đề này được xuất bản bởi nhà xuất bản nổi tiếng Packt 😎
Đây là 1 trong số các quyển sách về Time-series được recommend nhiều nhất trên các group về AI/Machine Learning ☺️
Link to pdf: https://drive.google.com/file/d/1ooKq0FcObwgfaMXySitBCKc5swkAYK4m/view?usp=sharing
#ml_share","['#sharing', '#machine_learning']","['machine', 'learning', 'for', 'timeseries', 'with', 'python', 'hi timeseries', 'forecasting', '1', 'toán', '1', 'data', 'scientist', 'nắm', 'giới thiệu', '1', 'quyển', 'sách', 'chủ đề xuất', 'xuất', 'nổi tiếng', 'packt', '1', 'quyển', 'sách', 'timeseries', 'recommend', 'group', 'machine', 'learning', 'link', 'to', 'pdf']"
48,"Em chào mọi người. Em biết khi làm các project liên quan đến ML/DL thì dataset là cực kỳ hữu ích. Nhưng khi có 1 dataset mà không có bất kỳ bài toán nào được đặt ra thì em có thể khai thác được những gì trong dataset đó. Và như anh Việt nói thì từ dataset đó có thể tự xây dựng mô hình/cách tiếp cận mới của riêng mỗi người thì mình có thể khai thác và tự xây dựng mô hình như thế nào ạ. Mong mọi người chia sẻ kinh nghiệm.
#ml_study","['#Q&A', '#data']","['chào', 'project', 'ml', 'dl', 'dataset', 'cực kỳ', 'hữu ích', '1', 'dataset', 'toán thể', 'khai thác', 'dataset', 'việt', 'dataset thể', 'xây dựng', 'mô hình', 'tiếp cận thể', 'khai thác', 'xây dựng', 'mô hình', 'mong', 'kinh nghiệm']"
49,"Em đang làm về ARIMA dự đoán timeseries ! Em xin phép được hỏi anh chị các nguồn tài liệu, soucre liên quan được không ạ !! Rất vui và biết ơn khi được các anh chị giúp đỡ ạ
hashtag : #ds_ml , #xx_code","['#Q&A', '#machine_learning']","['arima', 'dự đoán', 'timeseries phép', 'tài liệu', 'soucre', 'vui ơn', 'giúp đỡ', 'hashtag']"
50,"Em đang tìm hiểu về PCA nhưng thấy nó cứ rối rối nên muốn xin nguồn tìm hiểu , do em thấy mỗi nguồn thì cứ biểu đạt theo cách khác nhau. Em cảm ơn
#machinelearning","['#Q&A', '#machine_learning']","['pca', 'rối rối biểu']"
51,"Mình xin chia sẻ Roadmap cho DS mà mình tự viết ra, các bạn có thể tham khảo nhé.
https://docs.google.com/spreadsheets/d/1Bss92xVD3YQyibm1NmPW28BJiOdcNt8s/edit?usp=sharing&ouid=116047729382306725452&rtpof=true&sd=true
Sau mấy năm từ chập chững học hỏi đến khi có việc làm, mình có lời khuyên cho các bạn như sau.
- Datacamp Subscription là thứ đáng đồng tiền bát gạo nhất, Sale đâu đó khoảng 59$~80$ / 1 năm. Rất rẻ so với các bạn bỏ ra 3~4 triệu cho một khóa học cơ bản. Bạn có thể học được một vài thứ ở trên này.
- Medium Subscription: 50$/năm. Trang này có nhiều bài viết chia sẻ các project, tóm tắt paper, các tip trick các kiểu, đáng đồng tiền bát gạo.
- Coursera: Xin miễn phí. Học ổn, nên xin gối đầu mỗi tháng 2 course là vừa.
Tóm lại mỗi năm bạn chỉ mất 130$ không quá nhiều đâu.
Còn ai muốn học khóa học thì liên hệ mình, mình bán khóa học, nhưng chắc vài năm nữa mới có 🫠🫠
#roadmap","['#sharing', '#data']","['roadmap', 'ds', 'viết thể', 'tham khảo', 'mấy', 'chập chững', 'học', 'khuyên', 'datacamp', 'subscription', 'đồng tiền', 'bát', 'gạo', 'sale', '59', '80', '1', 'rẻ', '3', '4', 'triệu', 'khóa', 'học thể', 'học', 'medium', 'subscription', '50', 'trang', 'viết', 'project tóm', 'tắt', 'paper', 'tip', 'trick', 'kiểu', 'đồng tiền', 'bát', 'gạo', 'coursera', 'miễn phí', 'học', 'ổn', 'gối đầu', '2', 'course tóm', '130', 'học', 'khóa học', 'liên hệ', 'khóa', 'học']"
52,"#ds_study
Dạ em chào mọi người và anh Việt ạ, thì hiện tại em đang thực hành báo cáo khám phá dữ liệu với bộ dataset Air pollution, em có hai câu hỏi muốn hỏi ạ:
Câu hỏi 1: Theo mọi người em có nên giữ lại thuộc tính Country và City cho các mô hình cũng như thuật toán không ạ, mặc dù vấn đề ô nhiễm môi trường một phần cũng có liên quan tới yếu tố vị trí nhưng em nghĩ nó không nhiều ạ.
Câu hỏi 2: Sau khi em visualize lên thì em nghĩ bộ dữ liệu này cũng bị mất cân bằng về dữ liệu, cụ thể là số lượng trường hợp ảnh hưởng xấu đến sức khỏe ít hơn nhiều so với phần tích cực, việc này sẽ khiến các mô hình học được nhiều kiến thức về tích cực nhưng lại yếu về các phần tiêu cực, theo mọi người em có nên xử lý gì đó để cân bằng dữ liệu lại không ạ.
Câu hỏi 3: Vì AQI chung đánh giá bằng việc lấy AQI thành phần cao nhất, nó khá đơn giản và mình cũng biết quy luật rồi nên em không biết là liệu áp dụng các thuật toán cổ điển có ổn không, cụ thể thì em nghĩ chỉ có decision tree là thích hợp nhất.
Em cũng mới tiếp cận về khai phá dữ liệu, đọc trên mạng về quy trình khai phá nhưng thấy vẫn khá chung chung, anh chị biết cụ thể các bước nào chỉ giúp em với ạ. Em cảm ơn mọi người.
Link bộ dữ liệu:","['#Q&A', '#data']","['chào việt', 'thực hành', 'báo cáo', 'khám phá liệu', 'dataset', 'air', 'pollution', 'hai', '1', 'country', 'city', 'mô hình', 'thuật toán', 'mặc', 'ô nhiễm', 'môi trường', 'yếu tố', '2', 'visualize liệu', 'cân liệu', 'trường hợp', 'ảnh hưởng', 'xấu', 'sức', 'khỏe', 'tích cực', 'mô hình', 'học', 'kiến thức', 'tích cực', 'yếu', 'tiêu cực', 'cân liệu', '3', 'aqi', 'aqi', 'thành', 'đơn giản', 'quy luật liệu', 'áp dụng', 'thuật toán', 'cổ điển', 'ổn', 'decision', 'tree hợp', 'tiếp cận', 'khai', 'phá liệu', 'đọc', 'mạng', 'quy trình', 'khai phá', 'giúp', 'link liệu']"
53,"GPT với chỉ 330 dòng code 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 repo Github cực kì nổi tiếng về GPT - nanoGPT. Repo này nổi tiếng vì sự đơn giản cũng như tốc độ training của nó. Hiện tại project này đã có gần 4k lượt forks cũng như 27k stars từ cộng đồng 😎
Với các bạn đang muốn tìm hiểu cách thức mà 1 mô hình GPT được xây dựng và huấn luyện, đây là 1 nguồn không thể tuyệt vời hơn để các bạn bắt đầu. 2 file quan trọng nhất trong repo này đều ~330 dòng:
train.py: Phần khung của quá trình training
model.py: Đây là nơi model được định nghĩa
Link to repo: https://github.com/karpathy/nanoGPT","['#sharing', '#nlp']","['gpt', '330', 'dòng', 'code', 'hi', 'giới thiệu', '1', 'repo', 'github', 'cực kì', 'nổi tiếng', 'gpt', 'nanogpt', 'repo', 'nổi tiếng', 'đơn giản', 'tốc độ', 'training', 'project', '4', 'k', 'lượt', 'forks', '27', 'k', 'stars', 'cộng đồng thức', '1', 'mô hình', 'gpt', 'xây dựng', 'huấn luyện', '1', 'thể', 'tuyệt vời', '2', 'file', 'repo', '330', 'dòng', 'khung', 'trình', 'training', 'model định nghĩa', 'link', 'to', 'repo']"
54,"Ebook Neural networks from Scratch in Python 🔥🔥🔥
Hi các bạn,
Dành cho các bạn học về Deep Learning thích tìm hiểu bản chất của các layer, các mô hình thông qua việc tự code từ đầu mà không sử dụng các framework về Deep Learning như Pytorch, Tensorflow hay Keras, mình xin giới thiệu 1 cuốn sách vô cùng nổi tiếng được xuất bản vào năm 2020: Neural network from Scratch in Python.
Với cuốn sách này, mọi khái niệm các bạn cần biết và hiểu trong Deep Learning sẽ được giới thiệu và thực hiện hoàn toàn chỉ sử dụng 1 thư viện duy nhất, đó là Numpy. Cá nhân mình rất ấn tượng về cách trình bày của cuốn sách này (tỉ mỉ đến từng chi tiết nhỏ nhặt như màu sắc của các mảng hay ma trận 🥰)
Mình highly recommend các bạn cuốn sách này, nếu các bạn thực sự muốn hiểu bản chất của Neural Networks. Code from scratch không phải cách duy nhất để hiểu, nhưng nếu các bạn đã thử cách khác rồi mà vẫn không hiểu thì bạn nên thử cách này 😎
Link to pdf: https://drive.google.com/file/d/1C1AOUqwmfDbQ9rDVVoTpP-ofA-gSLCkZ/view?usp=sharing
#dl_share","['#sharing', '#deep_learning']","['ebook', 'neural', 'networks', 'from', 'scratch', 'in', 'python', 'hi học', 'deep', 'learning', 'chất', 'layer', 'mô hình', 'thông code', 'đầu', 'framework', 'deep', 'learning', 'pytorch', 'tensorflow', 'keras', 'giới thiệu', '1', 'sách', 'vô', 'nổi tiếng', 'xuất', '2020', 'neural', 'network', 'from', 'scratch', 'in', 'python', 'sách', 'khái niệm', 'deep', 'learning', 'giới thiệu', '1', 'thư viện', 'numpy', 'ấn tượng', 'trình bày', 'sách', 'tỉ mỉ', 'chi tiết', 'nhặt', 'màu sắc', 'mảng', 'ma trận', 'highly', 'recommend', 'sách', 'thực chất', 'neural', 'networks', 'code', 'from', 'scratch', 'thử', 'thử', 'link', 'to', 'pdf']"
55,"Generate Question
Chào mọi người ạ, hiện tại em đang làm đồ án môn học trên trường với dataset là Quora Question Pairs (https://paperswithcode.com/dataset/quora-question-pairs)
Các trường của dữ liệu:
⦁    id: ID của cặp câu hỏi
⦁    qid1, qid2: chứa ID cho mỗi câu hỏi trong cặp
⦁    question1, question2: nội dung của các câu hỏi trong cặ
⦁ is_duplicate: một giá trị nhị phân chỉ ra xem dòng đó có chứa một cặp câu hỏi trùng lặp hay không

Trong đồ án em có 1 task là sinh thêm các cặp câu hỏi tương đồng ở các topic ít câu hỏi (vì dataset khá mất cân bằng)
Với Task trên em đã chia thành 2 task nhỏ hơn là 
- Phân loại dataset thành các topic: Em đã dùng LDA Model để phân loại và chọn được các topic ít câu hỏi, với output như hình dưới.
- Sinh thêm các cặp câu hỏi tương đồng ở các chủ đề ít (để làm cân bằng dataset thì số lượng cặp câu hỏi cần sinh ~ 10k)
Ở task thứ 2: Sinh thêm các cặp câu hỏi thì em chưa nghĩ ra hướng giải quyết nào (trừ việc viết prompt cho các công cụ AI hiện nay)
Mong a/c và mọi người giúp đỡ ạ.
Em cảm ơn. 
#ml_study #generate_models","['#Q&A', '#nlp']","['generate', 'question', 'chào', 'đồ án', 'môn học', 'trường', 'dataset', 'quora', 'question', 'pairs', 'trường liệu', 'id', 'id', 'cặp', 'qid1', 'qid2', 'chứa', 'id', 'cặp', 'question1', 'question2', 'nội dung', 'cặ', 'is_duplicate', 'nhị', 'phân', 'dòng', 'chứa', 'cặp', 'trùng lặp', 'đồ án', '1', 'task', 'sinh', 'cặp', 'tương đồng', 'topic', 'dataset', 'cân', 'task', 'chia', 'thành', '2', 'task', 'phân dataset', 'thành', 'topic', 'lda', 'model', 'phân topic', 'output', 'hình sinh', 'cặp', 'tương đồng', 'chủ đề', 'cân', 'dataset', 'cặp', 'sinh', '10', 'k', 'task', '2', 'sinh', 'cặp', 'hướng', 'giải quyết', 'trừ', 'viết', 'prompt', 'công cụ', 'mong', 'a c', 'giúp đỡ']"
56,"Gần 200 project Data Science với sample code 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn danh sách gồm gần 200 project Data Science với code mẫu bằng Python để các bạn có thể tự xây dựng nên các project cá nhân của mình, nhằm luyện tập cũng như làm đẹp cho Github các nhân. Với mỗi project chúng ta sẽ có:
Giới thiệu về bài toán
Dataset tương ứng
Code mẫu với Python và giải thích từng bước
Giờ mình gợi ý cách các bạn sử dụng danh sách này nhé. Đầu tiên, đối với cá nhân mình, thứ quý giá nhất từ danh sách này không phải là câu hỏi hay code mẫu, mà là dataset. Danh sách này cung cấp cho chúng ta các dataset vô cùng đa dạng, trải rộng ở nhiều mảng khác nhau. 1 khi có dataset, thậm chí chúng ta có thể tự xây dựng nên bài toán mà chẳng cần câu hỏi cho trước.
Các bạn có thể tham khảo code để xem người ta phân tích và xử lý bài toán như thế nào, sau đó các bạn hãy thử tự xây dựng mô hình/cách tiếp cận mới của riêng bạn 😎
Link to pdf: https://drive.google.com/file/d/18wAOsRE2bYRNFHcmUC6tqIQva_RACyYc/view?usp=sharing
#ds_share #ml_share #py_share","['#sharing', '#data']","['200', 'project', 'data', 'science', 'sample', 'code', 'hi danh sách', '200', 'project', 'data', 'science', 'code', 'mẫu', 'python thể', 'xây dựng', 'project', 'luyện tập', 'đẹp', 'github nhân', 'project', 'ta', 'giới thiệu', 'toán', 'dataset', 'tương ứng', 'code', 'mẫu', 'python', 'giải gợi', 'danh sách', 'đối quý', 'giá', 'danh sách', 'code mẫu', 'dataset', 'danh sách', 'cung', 'ta', 'dataset', 'vô', 'đa dạng', 'trải', 'rộng', 'mảng', '1', 'dataset chí', 'ta thể', 'xây dựng', 'toán', 'chẳng thể', 'tham khảo', 'code', 'ta', 'phân tích', 'toán', 'thử', 'xây dựng', 'mô hình', 'tiếp cận', 'link', 'to', 'pdf']"
57,"Mình chia sẻ tài liệu thực hành các chủ đề Deep Learning ở Drive bên dưới. Tài liệu bao gồm code thực hành của tất cả các lĩnh vực quan trọng trong Deep Learning kèm theo giải thích lẫn các bài tập thử nghiệm ở cuối mỗi bài. Ngoài ra có 1 thư mục con dành cho bạn nào muốn học Python cơ bản nữa nhé. Chúc mọi người học tốt.
https://drive.google.com/drive/folders/1X4yZxH9LrMF_dDqBKZFL31dFq0Mwb9YB?usp=drive_link
#ms_share","['#sharing', '#deep_learning']","['tài liệu', 'thực hành', 'chủ đề', 'deep', 'learning', 'drive', 'tài liệu', 'bao code', 'thực hành', 'tất', 'lĩnh vực', 'deep', 'learning', 'kèm', 'giải', 'lẫn', 'tập', 'thử nghiệm', '1', 'thư', 'mục học', 'python', 'chúc', 'học']"
58,"Chào mọi người hiện em đang tìm hiểu về keras_vggface nhưng gặp lỗi về version. Mong được mọi người giúp đỡ, em xin cảm ơn:
Link git keras-vggface : https://github.com/rcmalli/keras-vggface
#Kera_","['#Q&A', '#deep_learning']","['chào', 'hiện', 'keras_vggface', 'lỗi', 'version', 'mong', 'giúp đỡ', 'link', 'git', 'kerasvggface']"
59,"Tổng hợp các thư viện Machine Learning quan trọng nhất trong Python 🔥🔥🔥 
Nói 1 cách chính xác hơn, đây là các thư viện quan trọng nhất khi các bạn học về Machine Learning 😎
#ml_share","['#sharing', '#machine_learning']","['tổng hợp', 'thư viện', 'machine', 'learning', 'python', '1', 'xác', 'thư viện', 'học', 'machine', 'learning']"
60,"Các thuật toán Machine Learning thường được sử dụng trong khoa học y sinh và các use case cụ thể 🔥🔥🔥
Ngắn gọn và trực quan các bạn nhé ☺️
#ml_share","['#sharing', '#machine_learning']","['thuật', 'toán', 'machine learning', 'khoa học', 'y sinh', 'use', 'case', 'ngắn gọn', 'trực quan']"
61,"#cv_study
Chào mọi người, có ai muốn cùng reproduce nghiên cứu này với e không ạ? Mô hình phát hiện thuốc dạng viên của VAIPE
Reproduce một phần để luyện tập, một phần vì em thấy có một chỗ lấn cấn trong mô hình này là sử dụng đồ thị có ma trận trọng số có rank bằng 1 (*), biết đâu thử nghiệm lại cho ra cái gì hay ho thì sao 😁
Paper: https://doi.org/10.1371/journal.pone.0291865
Tài liệu chỉ ra hiện tượng(*): https://docs.google.com/document/d/1YIulq6iwg3d8-Q4c8MqNcGYuqkNPjD-sQNIyLSk0sxo/edit?usp=sharing","['#sharing', '#cv']","['chào reproduce', 'nghiên cứu', 'e', 'mô hình', 'phát hiện', 'thuốc', 'dạng', 'viên', 'vaipe', 'reproduce', 'luyện tập', 'chỗ', 'lấn cấn', 'mô hình', 'đồ thị', 'ma trận', 'trọng rank', '1', 'thử nghiệm', 'ho paper', 'tài liệu', 'hiện tượng']"
62,"Dạ em chào mọi người, em có làm một đoạn code nhỏ để dự đoán được lượng mưa, độ ẩm, áp suất chỉ trong 1 mô hình, nhưng khi truyền x_train vào mô hình để train thì nó lại báo lỗi như hình. Trước đó, em có thử xuất ra shape của x_train thì là (4516,30,3) - tức là 3D array, đúng với yêu cầu, nhưng khi truyền vào hàm fit vẫn hiện ra lỗi, nên code không chạy được
Anh/chị có kinh nghiệm giúp em sửa lỗi với ạ, em cám ơn #py_code","['#Q&A', '#machine_learning']","['chào', 'đoạn', 'code', 'dự đoán', 'mưa', 'độ ẩm', 'áp suất', '1', 'mô hình', 'truyền', 'x_train', 'mô hình', 'train', 'báo', 'lỗi hình', 'thử', 'xuất', 'shape', 'x_train', '4516', '30', '3', 'tức', '3', 'd', 'array', 'truyền', 'hàm fit', 'hiện', 'lỗi', 'code', 'chạy', 'kinh nghiệm', 'giúp', 'sửa', 'lỗi', 'cám ơn']"
63,"Em chào các anh, chị! Em mới học lập trình python cơ bản thôi, em gặp phải bài toán là viết code python để tự động download 300 ảnh theo từ khóa từ Google. Em nhờ các anh chị gợi ý cách làm giúp em với, Em cảm ơn nhiều ạ!
#py","['#Q&A', '#python']","['chào học', 'lập trình', 'python toán', 'viết', 'code', 'python động', 'download', '300', 'ảnh', 'khóa', 'google', 'gợi', 'giúp']"
64,"Chào mọi người, mọi người cho mình hỏi thì các models như yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt và yolov8x.pt. Thì dựa vào đâu để chọn một model phù với dữ liệu cho việc trainning vậy ạ. Cảm ơn mọi người.
#hoidap","['#Q&A', '#deep_learning']","['chào models', 'dựa', 'model', 'phù liệu', 'trainning']"
65,"#ml_tunning_hyperparams
Em chào mọi người ạ, hiện tại em đã học ML được một thời gian. Cho em hỏi làm thế nào để mọi người điều chỉnh hyperparameter một cách hiệu quả ạ? Em đang cần một nguồn để giải thích rõ một chút về các param đó của tất cả các model, kiểu như nó hoạt động như thế nào, và khi nào thì cần chọn list params như nào cho hợp lý. Em đọc documentation và hỏi chatGPT các kiểu rồi mà vẫn chưa clear lắm ạ :(((. Em cám ơn ạ.","['#Q&A', '#machine_learning']","['chào học', 'ml chỉnh', 'hyperparameter hiệu', 'giải', 'chút', 'param', 'tất model', 'kiểu', 'hoạt động', 'list', 'params', 'hợp lý', 'đọc', 'documentation', 'chatgpt', 'kiểu', 'clear', 'lắm', 'cám ơn']"
66,"Em chào anh Việt và tất cả mọi người ạ.
Hiện em là sinh viên năm 2, có định hướng học AI cụ thể là Machine Learning. Theo lộ trình thì em đã học được các thao tác cơ bản của Python, mọi người cho em hỏi bây giờ em nên nắm vững kiến thức Toán trước rồi từ từ học các framework/library ( pandas, numpy, scikit-learn ...) sau hay học framework/lib trước ạ. Em cảm ơn mọi người, cảm ơn anh Việt đã duyệt bài ạ.
#hoidap #other","['#Q&A', '#machine_learning', '#python']","['chào', 'việt', 'tất hiện', 'sinh viên', '2', 'định hướng', 'học', 'machine', 'learning', 'lộ trình', 'học', 'thao tác', 'python', 'nắm', 'vững', 'kiến thức', 'toán học', 'framework', 'library', 'pandas', 'numpy', 'scikitlearn', 'học', 'framework', 'lib', 'việt', 'duyệt']"
67,"#ml_clustering
Em đang phải làm bài toán phân cụm dựa trên hành vi giao dịch của khách hàng. Vì mỗi khách hàng chỉ có một số kiểu giao dịch nhất định, mà có đến tận 30 type giao dịch khác nhau (tương ứng 30 features) => dữ liệu tồn tại rất nhiều giá trị 0 => Sparse data. Em đã thử dùng PCA, SVD, auto-encoder sau đó áp dụng Kmeans với khoảnh cách Euclid hoặc Mahalanobis nhưng kết quả các cụm rất tệ (tập trung chủ yếu vào 1 cụm). Em muốn xin ý kiến giúp đỡ của anh chị ạ. Em cảm ơn.","['#Q&A', '#machine_learning']","['toán', 'phân cụm', 'dựa', 'hành vi', 'giao dịch', 'hàng', 'hàng', 'kiểu', 'giao dịch', 'định', 'tận', '30', 'type', 'giao dịch', 'tương ứng', '30', 'features liệu', 'tồn', '0', 'sparse', 'data', 'thử', 'pca', 'svd', 'autoencoder', 'áp dụng', 'kmeans', 'khoảnh', 'euclid', 'mahalanobis', 'kết cụm', 'tệ', 'chủ yếu', '1', 'cụm', 'kiến', 'giúp đỡ']"
68,"Mọi người ai từng thuê server GPU online để training có thể cho em xin 1 số kinh nghiệm và nơi thuê giá rẻ không ạ. Em chưa đi làm nên kinh phí hạn hẹp mong được mọi người giúp đỡ ạ. Em xin cảm ơn ạ
#serverGPU",['#Q&A'],"['thuê', 'server', 'gpu', 'online', 'training thể', '1', 'kinh nghiệm', 'thuê', 'giá', 'rẻ', 'đi', 'kinh phí', 'hạn hẹp', 'mong', 'giúp đỡ']"
69,"Các hàm kích hoạt trong Neural Network 🔥🔥🔥
#dl_share","['#sharing', '#deep_learning']","['hàm kích', 'hoạt neural', 'network']"
70,"61 framework Machine Learning được sắp xếp theo độ phổ biến 🔥🔥🔥
Hi các bạn,
Dưới đây là tổng hợp của 61 framework/library về Machine Learning, được sắp xếp dựa vào project-quality score - được tính dựa vào nhiều metrics khác nhau trên Github cũng như các package manager như pip hay conda ⭐️⭐️⭐️
Top 4 thì hoàn toàn xứng đáng và không có gì phải bàn cãi cả. Tuy là 1 fan ruột của Pytorch nhưng mình cũng hiểu là No.1 phải là của Tensorflow 😅 Đợt này trên công ty mình, bọn mình cũng đang thử nghiệm sử dụng pytorch-lightning 😎
#ml_share","['#sharing', '#machine_learning', '#python']","['61', 'framework', 'machine', 'learning', 'xếp độ', 'phổ biến', 'hi tổng hợp', '61', 'framework', 'library', 'machine', 'learning xếp', 'dựa', 'projectquality', 'score', 'dựa', 'metrics', 'github', 'package', 'manager', 'pip', 'conda', 'top', '4', 'xứng', 'bàn cãi', '1', 'fan', 'ruột', 'pytorch', 'no', '1', 'tensorflow', 'đợt', 'công ty', 'bọn', 'thử nghiệm', 'pytorchlightning']"
71,"8 công cụ AI tự viết code giúp chúng ta 🔥🔥🔥
Dưới đây là danh sách 8 tool AI giúp tự sinh code giúp chúng ta. 2 cái tên đầu là Copilot và ChatGPT thì đã quá nổi tiếng rồi 😎
Link to pdf: https://drive.google.com/file/d/1HfJC9tR3ZLX8cVNjIosfBShS3VS4J_G4/view?usp=sharing
#ai_share","['#sharing', '#nlp']","['8', 'công cụ', 'viết', 'code', 'giúp', 'ta', 'danh sách', '8', 'tool', 'giúp', 'sinh code', 'giúp', 'ta', '2', 'đầu', 'copilot', 'chatgpt', 'nổi tiếng', 'link', 'to', 'pdf']"
72,"Chào mọi người!!
Chắc nhiều bạn có biết tới các nơi thân quen sau: LibG*n, SciH*b, ZL*b.
Với các bạn làm nghiên cứu, chắc hẳn SciH*b không còn quá xa lạ. Trang này cung cấp một lượng lớn báo khoa học mà bạn có thể tải về m.i.ễ.n p.h.í. Tuy nhiên, từ năm 2020 trở lại đây, do dính dáng tới 1 vụ kiện cáo ở Ấn Độ, trang SH tạm ngưng việc cập nhật/bổ sung các bài báo mới (báo từ 2020 trở lại đây). Vậy làm sao để tìm báo khoa học mới đây?
Cách 1: Trả tiền để đọc báo trên trang xuất bản.
Ờm, cách này thì không phải bàn cãi rồi, quá rõ ràng rồi. Nhưng nếu vẫn muốn m.i.ễ.n p.h.í thì sao?
Cách 2: Tìm trong thư viện (nhất là thư viện ở các đại học nước ngoài).
Cách này thì hên xui. Không phải thư viện nào cũng có đăng ký dịch vụ với nhà xuất bản của bài báo đó để có báo mà đọc. Một số thư viện đại học ở nước ngoài có tham gia vào chương trình Interlibrary Loan (Mượn sách liên thư viện) (cái này ở Mỹ), nên có thể yêu cầu bài báo với dịch vụ này, nhưng sẽ tốn kha khá thời gian (nhanh thì vài tiếng, lâu thì vài ngày, có khi xui quá, không có để mà đọc).
Vậy rồi có cách nào để có báo đọc mà nhanh, gọn, m.i.ễ.n p.h.í như khi dùng SH không? Có chứ. Mời đọc Cách 3.
Cách 3: Dùng b.o.t tìm kiếm Nexus trên Tele.gram.
Con b.o.t này là gì? Như tên gọi, nó là một con b.o.t trên ứng dụng Tele.gram, và chắc các bạn biết Tele.gram là gì rồi nhỉ :V Thôi đùa vậy thôi.
Con b.o.t này cho phép ta tìm kiếm báo khoa học như ta vẫn hay làm trên trang SH. Nó cũng cho phép ta tìm các tài liệu khác (tương tự như với trang LG).
Vậy có trường hợp tìm không ra bài muốn tìm không? Có chứ. Trong trường hợp này, hãy lập đàn cầu trời, cầu cho có ai đó có thể tìm thấy bài này và đóng góp cho Nexus.
Ủa khoan, có thể đóng góp sao? Đúng vậy, có thể đóng góp các bài báo mà bạn tìm thấy cho Nexus và như vậy, sau này, người khác có thể tìm được bài mà bạn đã đóng góp.
Dông dài vậy đủ rồi. Vậy đường dẫn đâu? (""Đăng hình nóng mà không kèm link với code là một tội ác"" :V )
Tiểu nhị tới ngay đây.
1) Kênh chủ quản của con b.o.t (thông tin, tin tức, kể cả tên con b.o.t đang còn sống và chạy tốt):
-> t chấm me /nexus_search
2) Con b.o.t đó (đang sống và chạy tốt):
2.1: t chấm me /science_nexus_bot
2.2: (Tìm trong thanh tìm kiếm của Tele.gram) @science_nexus_bot
3) Nhóm để đóng góp:
-> t chấm me /nexus_aaron
(Aaron là tên của người-mà-ai-cũng-biết của Reddit)
---------------
Hi vọng bài viết này hữu ích với các bạn, đặc biệt là các bạn đang cắm cúi tìm báo khoa học.
Chào tạm biệt các bạn!!!
#other",['#sharing'],"['chào', 'thân quen', 'libg', 'n', 'scih', 'b', 'zl', 'b', 'nghiên cứu', 'hẳn', 'scih', 'b', 'lạ trang', 'cung báo', 'khoa học thể', 'tải', 'm', 'i', 'ễ', 'n', 'p', 'h', 'í nhiên', '2020', 'trở', 'dính dáng', '1', 'vụ', 'kiện cáo', 'ấn độ', 'trang', 'sh', 'tạm', 'ngưng', 'cập nhật', 'bổ sung', 'báo', 'báo', '2020', 'trở báo', 'khoa học', '1', 'tiền', 'đọc', 'báo', 'trang', 'xuất ờm', 'bàn cãi', 'ràng', 'm', 'i', 'ễ', 'n', 'p', 'h', 'í', '2', 'thư viện', 'thư viện', 'đại học', 'hên', 'xui', 'thư viện', 'đăng ký', 'dịch vụ', 'xuất báo', 'báo', 'đọc', 'thư viện', 'đại học', 'tham gia', 'chương trình', 'interlibrary', 'loan', 'mượn', 'sách', 'liên thư viện', 'mỹ thể', 'báo', 'dịch vụ', 'tốn', 'kha tiếng', 'xui', 'đọc', 'báo', 'đọc', 'gọn', 'm', 'i', 'ễ', 'n', 'p', 'h', 'í', 'sh', 'mời', 'đọc', '3', '3', 'b', 'o', 't', 'kiếm', 'nexus', 'tele', 'gram', 'b', 'o t', 'gọi', 'b', 'o', 't', 'ứng dụng', 'tele', 'gram', 'tele', 'gram', 'v', 'đùa', 'b', 'o', 't phép', 'ta', 'kiếm', 'báo', 'khoa học', 'ta', 'trang', 'sh phép', 'ta', 'tài liệu', 'tương trang', 'lg', 'trường hợp', 'trường hợp', 'lập', 'đàn', 'cầu', 'trời', 'cầu thể', 'đóng góp', 'nexus', 'khoan thể', 'đóng góp thể', 'đóng góp', 'báo', 'nexus thể', 'đóng góp', 'dông', 'đường', 'đăng hình', 'nóng', 'kèm', 'link', 'code', 'tội ác', 'v', 'tiểu nhị', '1', 'kênh', 'chủ quản', 'b', 'o', 't', 'thông tức', 'b', 'o', 't', 'sống', 'chạy', 't', 'chấm', 'me', 'nexus_search', '2', 'b', 'o', 't', 'sống', 'chạy', '2', '1', 't', 'chấm', 'me', 'science_nexus_bot', '2', '2', 'kiếm', 'tele', 'gram', 'science_nexus_bot', '3', 'đóng góp', 't', 'chấm', 'me', 'nexus_aaron', 'aaron', 'ngườimàaicũngbiết', 'reddit', 'hi vọng', 'viết', 'hữu ích', 'cắm cúi', 'báo', 'khoa học', 'chào', 'tạm biệt']"
73,"Mọi người cho mình hỏi nếu mình mua gói Colab Pro của google Colab thì có còn bị giới hạn thời gian sử dụng GPU như bản free không ạ.
#Google Colab",['#Q&A'],"['mua', 'gói', 'colab', 'pro', 'google', 'colab', 'giới hạn', 'gpu', 'free', 'colab']"
74,"Visualization in Deep Learning 🔥🔥🔥
Hi các bạn,
Hôm nay mình vừa đọc được 1 bài viết rất hay về trực quan hóa dữ liệu trên medium. Mình xin chia sẻ lại với các bạn bài viết ở đây (Hi vọng các bạn ở VN không bị chặn)
Bài viết đề cập về các chủ đề sau:
Vì sao chúng ta cần trực quan hóa trong Deep Learning? 
Trực quan hóa có tác dụng như thế nào?
Vai trò của trực quan hóa dữ liệu trong Deep Learning 
1 bài viết dài nhưng vô cùng thú vị 😎
Link to article: https://medium.com/multiple-views-visualization-research-explained/visualization-in-deep-learning-b29f0ec4f136
#dl_share","['#sharing', '#data']","['visualization', 'in', 'deep', 'learning', 'hi hôm', 'đọc', '1', 'viết', 'trực quan', 'hóa liệu', 'medium', 'viết', 'hi vọng', 'vn', 'chặn', 'viết', 'đề cập', 'chủ đề', 'ta', 'trực quan', 'hóa', 'deep learning', 'trực quan', 'hóa', 'tác dụng', 'vai trò', 'trực quan', 'hóa liệu', 'deep', 'learning', '1', 'viết', 'vô', 'thú vị', 'link', 'to', 'article']"
75,"Dạ em chào anh chị, hiện em đang học năm 1 khoa Toán-Tin HCMUS, dự định học chuyên ngành xstk, em có nghe thầy cô em khuyên là nên học thêm về code để sau này ra trường có việc làm. Em đã học qua một môn về code C trên trường (viết hàm, kiểm tra số đó phải số chính phương không, tính tổng,…). Em nghe thầy cô em khuyên là nên học thêm nhiều về code để sau này kết hợp với kiến thức xstk để tìm việc làm. Vậy anh chị cho em hỏi học đến mức độ nào để gọi là “BIẾT CODE” vậy ạ. Em thật sự mới tiếp xúc với code ở cấp 2 học pascal và 1môn code trên ĐH nên mong anh chị giúp em giải đáp thật chi tiết và dễ hiểu ạ, em cảm ơn anh chị rất nhiều
#Other",['#Q&A'],"['chào', 'hiện học', '1', 'khoa', 'toántin hcmus', 'dự định', 'học', 'chuyên ngành', 'xstk', 'thầy', 'khuyên', 'học', 'code', 'trường học', 'môn', 'code', 'c', 'trường', 'viết', 'hàm', 'kiểm tra', 'phương', 'tổng thầy', 'khuyên', 'học', 'code', 'kết hợp', 'kiến thức', 'xstk', 'học độ', 'gọi', 'code', 'tiếp xúc', 'code', '2', 'học', 'pascal', '1', 'môn', 'code', 'đh', 'mong', 'giúp', 'giải đáp', 'chi tiết']"
76,"Yoshua Bengio - Cha đẻ của ReLU. Người đề xuất kĩ thuật gradient clipping và hơn thế nữa 🔥🔥🔥
Hôm nay chúng ta tiếp tục đến với 1 cái tên khác có rất nhiều đóng góp cho sự phát triển của AI. Ông là Yoshua Bengio. 1 số những đóng góp tiêu biểu nhất của ông có thể kể đến:
ReLU
Xavier/Glorot initialization
Gradient Clipping
Graph attention network
RNN encoder-decoder
Chắc hẳn rất nhiều người trong chúng ta sử dụng ReLU mà không nhớ cha đẻ của nó là ai 😁
#ai_share",['#sharing'],"['yoshua', 'bengio', 'đẻ', 'relu', 'đề xuất', 'kĩ thuật', 'gradient', 'clipping', 'hôm', 'ta', '1', 'đóng góp', 'phát triển', 'yoshua', 'bengio', '1', 'đóng góp', 'tiêu biểu thể', 'relu', 'xavier', 'glorot', 'initialization', 'gradient', 'clipping', 'graph', 'attention', 'network', 'rnn', 'encoderdecoder', 'hẳn', 'ta', 'relu', 'đẻ']"
77,"Mọi người ơi mình hỏi chút. Hàm if __name__ == '__main__' có tác dụng gì vậy ạ
#hoidap","['#Q&A', '#python']","['chút', 'hàm if', '__name__', '__main__ tác dụng']"
78,"Em đang có vài ngàn tấm hình. Và phải tự động gán nhãn trên roboflow. Em đang tìm cách để nó tự động gán nhãn từ việc học 1 số lượng hình ban đầu nhưng chưa biết cách để nó tự động làm. Mọi đã làm về phần này cho em chút góp ý với ạ
#hoidap","['#Q&A', '#data']","['ngàn', 'hình động', 'gán', 'nhãn', 'roboflow động', 'gán', 'nhãn học', '1', 'hình', 'ban đầu động', 'chút', 'góp']"
79,"#question #other
Em chào anh Việt và các anh chị cùng các bạn khác trong nhóm. Em hiện là sinh viên năm 3 ngành DS của một trường ở VN. Ban đầu e có hướng theo NLP nhưng sau khi tìm hiểu thì e cảm thấy mình thích phần AI generator hơn. Mọi người cho e hỏi là nếu theo ai generator thì nên hướng nghiên cứu hay đi làm doanh nghiệp? Và bên VN cx như nước ngoài thì tình hình job của AI generator như thế nào ạ?
Em xin cảm ơn mọi người.",['#Q&A'],"['chào việt', 'hiện', 'sinh viên', '3', 'ngành', 'ds trường', 'vn', 'ban đầu', 'e', 'hướng', 'nlp', 'e generator', 'e', 'generator', 'hướng', 'nghiên cứu', 'đi', 'doanh nghiệp', 'vn', 'cx', 'tình hình', 'job', 'generator']"
80,"Ai giúp e với được k 😭
#py_laptop #py_code",['#Q&A'],"['giúp', 'e k']"
81,"Cho em hỏi sao chỗ minimize J(theta) mình lấy trace vậy ạ
#ML","['#Q&A', '#machine_learning']","['chỗ', 'minimize', 'j', 'theta', 'trace']"
82,"Chào mọi người ạ. Hiện tại e là sv năm nhất ngành CNTT và đang có định hướng theo AI engineer, các a chị đi trước có thể cho e xin lời khuyên và lộ trình cụ thể k ạ và e nên học tiếng Trung hay Nhật để phục vụ cho định hướng công việc này ạ. Em cảm ơn ạ.
#Other",['#Q&A'],"['chào', 'e', 'sv', 'ngành', 'cntt', 'định hướng', 'engineer a', 'đi thể', 'e khuyên', 'lộ trình', 'k', 'e học', 'tiếng', 'trung nhật', 'phục vụ', 'định hướng', 'công']"
83,"Nhóm mình cũng nhiều bạn nhắc đến paper, có bạn nào có hứng đọc và reproduce 1 paper không? Paper mà mình muốn đề xuất là
https://arxiv.org/abs/2109.09165
#cv_study",['#Q&A'],"['nhắc', 'paper hứng', 'đọc', 'reproduce', '1', 'paper', 'paper', 'đề xuất']"
84,"Có ai đang học Machine Learning là sinh viên của HCMUS không ạ, mình muốn tìm một vài bạn lập nhóm cùng giúp đỡ nhau học ạ, học một mình khá buồn 😅
#other",['#Q&A'],"['học', 'machine', 'learning', 'sinh viên', 'hcmus', 'lập', 'giúp đỡ', 'học', 'học', 'buồn']"
85,"#ml #dl
Hi anh/chị,
Em muốn hỏi rõ hơn về Contrastive Loss function (như ảnh dưới). Nếu xét như công thức bên dưới thì:
Khi 2 data points là dissimilar: Y=1; max(0, m-Dw)=0 (do max(Dw) <= m)
Khi 2 data points là similar: Y=0
Vậy trong cả 2 trường hợp thì vế phải của công thức luôn bằng 0 ạ? Hay em có sai chỗ nào mong anh chị chỉ giúp.
Em cảm ơn ạ","['#Q&A', '#math']","['hi contrastive', 'loss', 'function', 'ảnh', 'xét', 'công thức', '2', 'data', 'points', 'dissimilar y', '1', 'max', '0', 'mdw', '0', 'max', 'dw', 'm', '2', 'data', 'points', 'similar y', '0', '2', 'trường hợp', 'vế', 'công thức', '0', 'sai', 'chỗ', 'mong', 'giúp']"
86,"Tổng hợp những gì các bạn cần học/biết về Python 🔥🔥🔥
Mình thấy khá chi tiết và đầy đủ các bạn nhé 🥰
#python_share","['#sharing', '#python']","['tổng hợp', 'học', 'python', 'chi tiết']"
87,"Em chào anh Việt và mọi người ạ.
Em đang là sinh viên ĐH năm 3. Hiện tại em đang implement lại code của 1 paper phục vụ cho dự án cá nhân. Tuy nhiên trong quá trình lại gặp 1 số vấn đề phát sinh, vì vậy em muốn tìm 1 mentor cho mình (anh, chị, các bạn đã có nhiều kinh nghiệm...) để có thể trao đổi những vấn đề bản thân đang còn thắc mắc (do em là người mới trong ngành, cũng có vài vấn đề em đã hỏi trên đây nhưng mà cũng không hỏi mãi như vậy được ạ)
Nếu được thì em mong có thể tìm được mentor khu vực ngoài HN ạ (vì em ở đây, cũng tiện để em có thể hỏi các vấn đề khác như lộ trình học, vấn đề công việc... ngoài này ạ), nếu được em xin gửi mentor chút hậu tạ ạ. Anh, chị, các bạn... có thể cmt xuống phía dưới để em chủ động liên hệ ạ. Em xin cảm ơn mọi người nhiều.
#other",['#Q&A'],"['chào', 'việt', 'sinh viên', 'đh', '3', 'implement', 'code', '1', 'paper', 'phục vụ', 'dự án', 'nhiên trình', '1', 'phát sinh', '1', 'mentor', 'kinh nghiệm thể', 'trao đổi', 'thân', 'thắc mắc', 'ngành', 'mãi', 'mong thể', 'mentor', 'khu vực', 'hn', 'tiện thể', 'lộ trình', 'học', 'công', 'gửi', 'mentor', 'chút', 'hậu', 'tạ thể', 'cmt', 'chủ động', 'liên hệ']"
88,"Tổng hợp các kiểu dữ liệu trong Python 🔥🔥🔥
Tài liệu 6 trang dưới đây tổng hợp các kiểu dữ liệu trong Python mà các bạn cần biết 😁
Link to pdf: https://drive.google.com/file/d/1E63fhd_VxGBOVCx-tlXpRtLGBbsRor9g/view?usp=sharing
#py_share","['#sharing', '#python']","['tổng hợp', 'kiểu liệu', 'python', 'tài liệu', '6', 'trang', 'tổng hợp', 'kiểu liệu', 'python', 'link', 'to', 'pdf']"
89,"Em muốn tạo 1 trang website đơn giản mà có thể truyền tham số vào hàm test em có khoan tròn đỏ trong ảnh, thì em phải tìm hiểu về gì ạ?
Nếu có ai rành về khoản này, ib trực tiếp giúp em được không ạ?
#question",['#Q&A'],"['1', 'trang', 'website', 'đơn giản thể', 'truyền', 'tham hàm', 'test', 'khoan', 'tròn', 'đỏ ảnh', 'rành khoản', 'ib', 'giúp']"
90,"Cần lắm người cứu giải đề dùm Python tìm yếu ảnh hưởng đến giá xe Linear Regression nhiều biến.
Inbox mình gửi đề nhe 😭","['#Q&A', '#machine_learning']","['lắm', 'cứu', 'giải', 'đề dùm', 'python', 'yếu', 'ảnh hưởng', 'giá', 'xe', 'linear', 'regression', 'biến inbox', 'gửi', 'đề nhe']"
91,"Em đang tập train yolov8, em có sửa augmentation ở 2 chỗ
- hyperparameter trong default.yaml
- class Albumentation trong augment.py
nhưng chưa chạy được câu lệnh vì yolov8 em có search thì không có argument: —cfg
Anh/chị/bạn nào từng fine tune các para này trong yolov8 rồi giúp em ạ.
Em cảm ơn.
#df_study","['#Q&A', '#deep_learning']","['tập', 'train', 'yolov8', 'sửa', 'augmentation', '2', 'chỗ', 'hyperparameter', 'default', 'yaml', 'class', 'albumentation', 'chạy', 'câu', 'lệnh', 'yolov8', 'search', 'argument', 'cfg', 'fine', 'tune', 'para', 'yolov8', 'giúp']"
92,"#DL
#Question
Chào admin và mọi người, e có một số câu hỏi sau:
Khi build một model thì e sẽ cho bộ data gồm train và test vào 2 thư mục khác nhau, khi chạy sẽ chạy lần lượt train và test, như vậy mỗi lần e muốn test them 1 số data thì phải chạy lại từ đầu bao gồm cả bước train nữa. Vậy làm sao để có thể mỗi lần test ko cần chạy lại model từ đầu không ạ
Quá trình trainning e dùng trên laptop cá nhân khá là lâu và nóng máy, quạt kêu rất to nên nghe rất xót máy, vậy có cách nào sau lần train đầu tiên thì các lần sau có thể train nhẹ nhàng hơn không ạ, chứ chạy lại tất cả từ đầu khá mất thời gian và yếu máy
Với bài toán thời gian thực và data lấy từ camera thì mọi người thường sử dụng model nào hay thuật toán nào để thời gian hoàn tất quá trình phân loại, phát hiện đối tượng, ... 3s đổ về ạ, ví dụ như phát hiện biển số xe ạ
Khi đã demo được code ở trên laptop thì mọi người triển khai nó ra thực tế như nào ạ, và quá trình chăm sóc model sau triển khai thực tế thì mọi người thường thực hiện như nào ạ.
Em có một số thắc mắc như vậy, mong mọi người giải đáp giúp e, e xin cảm ơn ","['#Q&A', '#machine_learning']","['chào', 'admin', 'e build', 'model', 'e data', 'train', 'test', '2', 'thư mục', 'chạy', 'chạy', 'lượt', 'train', 'test', 'e test', 'them', '1', 'data', 'chạy', 'đầu', 'bao', 'train thể', 'test ko', 'chạy', 'model', 'đầu', 'trình', 'trainning', 'e laptop', 'nóng', 'máy quạt', 'kêu', 'to xót', 'máy', 'train thể', 'train', 'nhẹ nhàng', 'chạy', 'tất đầu', 'yếu', 'máy toán', 'thực data', 'camera', 'model thuật toán', 'hoàn tất', 'trình', 'phân', 'phát hiện', 'đối tượng', '3', 's', 'đổ', 'ví dụ', 'phát hiện', 'biển', 'xe', 'demo', 'code', 'laptop', 'triển khai', 'trình', 'chăm sóc', 'model', 'triển khai', 'thắc mắc', 'mong', 'giải đáp', 'giúp', 'e e']"
93,"Em đang làm về NLP với topic là : Tạo các ghi chú từ bài giảng hay là text book ( Automatic Lecture Note Generation from Textbooks and Slides) !
Em xin phép được hỏi anh chị các nguồn tài liệu, soucre liên quan được không ạ !!
Rất làm vui và cảm ơn các anh chị giúp đỡ ạ
Em cảm ơn rất nhiều ạ
#question","['#Q&A', '#nlp']","['nlp', 'topic', 'ghi', 'giảng', 'text', 'book', 'automatic', 'lecture', 'note', 'generation', 'from', 'textbooks and', 'slides phép', 'tài liệu', 'soucre', 'vui', 'giúp đỡ']"
94,"5 hàm vô cùng hữu ích và phổ biến trong Python 🔥🔥🔥 
Hi các bạn, dưới đây là tổng hợp 5 hàm được sử dụng rất nhiều trong Python. Chúng giúp rút gọn các hàm cồng kềnh, và làm cho code của các bạn trở nên đẹp mắt hơn rất nhiều 😎
Hàm lambda
Hàm map
Hàm filter
Hàm zip
Hàm enumerate
Cá nhân mình sử dụng lambda, zip và enumerate cực nhiều 🥰
#py_share","['#sharing', '#python']","['5', 'hàm vô', 'hữu ích', 'phổ biến', 'python', 'hi tổng hợp', '5', 'hàm python', 'giúp', 'rút', 'gọn hàm', 'cồng kềnh', 'code', 'trở đẹp', 'mắt', 'hàm lambda', 'hàm', 'map', 'hàm', 'filter', 'hàm', 'zip', 'hàm enumerate', 'lambda', 'zip', 'enumerate', 'cực']"
95,"#django #python #db
Mn cho mình hỏi về cái admin trong django với ạ:
Vấn đề là nếu tạo model, django sẽ tự sinh bảng và view rất ok
Nhưng nếu bảng có sẵn rồi, chỉ muốn nó hiển thị ra thôi thì cần động chạm vào những file nào ạ?
Theo em tìm hiểu thì bắt bụôc phải động vào file view để query raw sql nhưng để hiển thị ra đc phải động vào file admin.py và cho nó register nhưng mà search hướng dẫn đều đòi lấy file từ models.py ra mà nếu khai báo trong models thì nó lại lỗi vì tên bảng đã tồn tại.
Mong cao nhân nào chỉ giúp em giờ code sao ạ?","['#Q&A', '#python']","['mn', 'admin', 'django', 'model', 'django sinh', 'bảng', 'view', 'ok', 'bảng', 'sẵn', 'hiển thị động', 'chạm', 'file', 'bắt buộc', 'động', 'file', 'view', 'query', 'raw', 'sql', 'hiển thị', 'đc động', 'file', 'register', 'search', 'hướng', 'đòi', 'file', 'khai báo', 'models', 'lỗi', 'bảng', 'tồn', 'mong nhân', 'giúp', 'code']"
96,"#question
Chào các anh chị, em là sv năm 3, không học chuyên về AI nhưng trong chương trình học có. Em có một bài tập về cây quyết định, giải thuật trên giấy, sau khi loay hoay xem lại slide, xem lại bài giảng trên lớp, xem youtube và các bài viết thì em vẫn chưa giải quyết được vấn đề của mình nên em lên đây hỏi ạ. Mong anh chị giúp đỡ.
Em có thắc mắc là:
Vấn đề 1: Em đang làm bài tập về xây dựng cây quyết định, làm giải thuật trên giấy, đến bước cuối cùng thì em gặp phải nhánh cùng mang 2 nhãn: 1 no và 1 yes (tức là đầu vào thì giống nhau nhưng kết quả là 1 no và 1 yes), vậy làm thế nào để em chọn lá cuối cùng là no hay yes? (ở 2 dòng em gạch đỏ)
vấn đề thứ 2: khi tạo cây quyết định và tìm node gốc: em giải information gain của các thuộc tính thì có 2 thuộc tính có giá trị gain lớn bằng nhau, vậy để chọn làm node thì em nên chọn thuộc tính nào?
Em cảm ơn mọi người","['#Q&A', '#machine_learning']","['chào', 'sv', '3', 'học', 'chuyên', 'chương trình', 'học tập', 'quyết định', 'giải thuật', 'giấy', 'loay hoay', 'slide giảng', 'lớp', 'youtube', 'viết', 'giải quyết', 'mong', 'giúp đỡ', 'thắc mắc', '1', 'tập', 'xây dựng', 'quyết định', 'giải thuật', 'giấy', 'nhánh', '2', 'nhãn', '1', 'no', '1', 'yes', 'tức', 'đầu kết', '1', 'no', '1', 'yes', 'lá', 'no', 'yes', '2', 'dòng', 'gạch', 'đỏ', '2', 'quyết định', 'node', 'gốc', 'giải', 'information', 'gain', '2', 'gain', 'node']"
97,"Em chào anh chị, em đang làm đồ án về OCR dùng transformer để nhận dạng tài liệu khoa học: https://github.com/facebookresearch/nougat
Em đang tìm hiểu phần tối ưu hóa tốc độ bằng cách convert model Pytorch sang TensorRT nhưng mà vẫn chưa làm được. Anh chị và các bạn ai có thể hướng dẫn em chi tiết phần này được không ạ, em xin cảm ơn và hậu tạ ạ.
#CV_study
#hoidap","['#Q&A', '#cv', '#python']","['chào', 'đồ án', 'ocr', 'transformer', 'dạng', 'tài liệu', 'khoa học', 'tối ưu hóa', 'tốc độ', 'convert', 'model', 'pytorch', 'tensorrt thể', 'hướng', 'chi tiết', 'hậu tạ']"
98,"Em xin chia sẻ với mọi người project deeplearning đầu tiên của em sử dụng pytorch để phân loại animals. Link github: https://github.com/vuniem131104/90-Animals-CLassification-With-Pytorch
Mong mọi người cho em xin nhận xét để em cải thiện ạ. Em cảm ơn mn. #dl_share","['#sharing', '#deep_learning']","['project', 'deeplearning', 'pytorch', 'phân animals', 'link', 'github', 'mong xét', 'cải thiện', 'mn']"
99,"Em chào các anh chị ạ. Em đang có một vấn đề nhỏ khi thao tác với dữ liệu mong được các anh chị giúp đỡ ạ. Em đang có 1 số file excel đuôi .xls. Em không thể đọc được file này bằng python. Em cũng đã tìm kiếm trên mạng 1 số cách nhưng không đem lại hiệu quả. Rất mong ac giúp đỡ em cách đọc file excel đuôi .xls hoặc chuyển file này sang dạng csv ạ. Em cảm ơn mn ạ.
#hoidap","['#Q&A', '#data', '#python']","['chào', 'thao tác liệu', 'mong', 'giúp đỡ', '1', 'file', 'excel', 'đuôi', 'xls thể', 'đọc', 'file', 'python', 'kiếm', 'mạng', '1', 'đem', 'hiệu', 'mong', 'ac', 'giúp đỡ', 'đọc', 'file', 'excel', 'đuôi', 'xls', 'file', 'dạng', 'csv', 'mn']"
100,"#deeplearning #cv #code
Em chào anh Việt và mọi người trong nhóm. Hiện em đang thực hiện một project về đề tài Road Extraction. Em đang tìm hiểu về phương pháp Deep Residual U-Net và tham khảo code qua link github https://github.com/rishikksh20/ResUnet . Và đang gặp vấn đề về dữ liệu đầu vào để chạy code . 
Em mong anh chị trong nhóm đã từng thực hiện đề tài này hay đã chạy thử chương trình thì có thể giúp em phần dữ liệu vào và gợi ý các hướng cải thiện cho mô hình. 
Em xin cảm ơn.","['#Q&A', '#cv']","['chào', 'việt', 'hiện', 'project', 'đề tài', 'road', 'extraction', 'phương pháp', 'deep', 'residual', 'unet', 'tham khảo', 'code', 'link', 'github liệu', 'đầu', 'chạy', 'code mong', 'đề tài', 'chạy', 'thử', 'chương trình thể', 'giúp liệu', 'gợi hướng', 'cải thiện', 'mô hình']"
101,"Chào mọi người ạ. Hiện tại em đang làm dự án dự đoán doanh thu phim và cũng là dự án đầu tiên của em, em đang gặp lỗi khi vẽ biểu đồ doanh thu, khi sử dụng distplot thì vẽ bình thường nhưng khi em chuyển sang histplot hay displot thì nó bị như ảnh là sao ạ. Em cảm ơn.
#hoidap",['#Q&A'],"['chào', 'dự án', 'dự đoán', 'doanh thu', 'phim', 'dự án', 'lỗi', 'vẽ', 'biểu đồ', 'doanh thu', 'distplot', 'vẽ', 'bình histplot', 'displot', 'ảnh']"
102,"Với tình hình đồ hàng được lên kệ nhiều như vậy, hoa mắt quá, nguyên năm nay có một mớ amazing CV papers ra đời, gần nghỉ cuối năm lại xuất hiện đồ hàng xịn như vầy,
#nl_study
https://huggingface.co/blog/mixtral?fbclid=IwAR0eamdqshV-haFErgxnl_3Kx8R1MdN4qV66d220rMEnwpS_HeCSefvBy54",['#sharing'],"['tình hình', 'đồ', 'hàng', 'kệ', 'hoa', 'mắt', 'nguyên mớ', 'amazing', 'cv', 'papers', 'đời', 'nghỉ', 'đồ', 'hàng', 'xịn', 'vầy']"
103,"Các bạn (nhất là ai đang đi làm rồi) cho mình hỏi, các bạn take notes khi đọc 1 tài liệu mới/khoá học mới hoặc 1 thư viện/framework mới kiểu gì vậy? Mong mọi ngừoi chia sẻ. Cám ơn mọi người.
#ds_study",['#Q&A'],"['đi', 'take', 'notes', 'đọc', '1', 'tài liệu', 'khóa học', '1', 'thư viện', 'framework', 'kiểu', 'mong ngừoi', 'cám ơn']"
104,"Có ai trong nhóm từng theo học khóa học Data Analyst hoặc BA của MindX chưa ạ. Em xin review với ạ 😘
#da_ba_study","['#Q&A', '#data']","['học', 'khóa', 'học', 'data', 'analyst', 'mindx', 'review']"
105,"Khóa học Deep Learning for NLP tại LMU Munich 🔥🔥🔥
Hi các bạn,
Cách đây 6 tuần và 3 tuần mình đã lần lượt chia sẻ 2 khóa học của Đại học Munich (LMU) - ngôi trường luôn nằm trong Top 100 các trường đại học tốt nhất thế giới trong tất cả các bạn xếp hạng danh tiếng. 2 khóa học này bao gồm:
Introduction to Machine Learning (https://www.facebook.com/groups/dsmlvietnam/permalink/314807134632748/)
Introduction to Machine Learning (https://www.facebook.com/groups/dsmlvietnam/permalink/324412683672193/)
Lần này, mình xin chia sẻ với các bạn khóa học chuyên sâu về mảng NLP - khóa Deep learning for NLP của LMU
Tương tự như 2 khóa học trước, khóa học này ngay từ đầu đã được thiết kế theo hướng khuyến khích tự học, thông qua việc cung cấp đầy đủ những tài liệu cần thiết bao gồm:
1 điểm trừ của khóa này là Cheatsheet và Exercise chưa có được cập nhật 😢 Tuy nhiên phần lý thuyết thì khá là cập nhật (BERT và GPT đều được đưa vào) 😎
Link to course: https://slds-lmu.github.io/dl4nlp/
#dl_share #nlp_share","['#sharing', '#nlp']","['khóa', 'học', 'deep', 'learning', 'for', 'nlp', 'lmu', 'munich', 'hi', '6', 'tuần', '3', 'tuần', 'lượt', '2', 'khóa', 'học', 'đại học', 'munich', 'lmu trường', 'nằm', 'top', '100', 'trường', 'đại học', 'giới', 'tất xếp hạng', 'danh tiếng', '2', 'khóa', 'học', 'bao', 'introduction', 'to', 'machine', 'learning', 'https', 'www', 'facebook', 'com', 'groups', 'dsmlvietnam', 'permalink', '314807134632748', 'introduction', 'to', 'machine', 'learning', 'https', 'www', 'facebook', 'com', 'groups', 'dsmlvietnam', 'permalink', '324412683672193 khóa', 'học', 'chuyên sâu', 'mảng', 'nlp', 'khóa', 'deep', 'learning', 'for', 'nlp', 'lmu', 'tương', '2', 'khóa', 'học', 'khóa học', 'đầu', 'thiết kế', 'hướng', 'khuyến khích', 'học', 'thông cung', 'tài liệu', 'thiết bao', '1', 'trừ', 'khóa', 'cheatsheet', 'exercise cập', 'nhật nhiên', 'lý thuyết', 'cập nhật', 'bert', 'gpt', 'link', 'to', 'course', 'https', 'sldslmu', 'github', 'io', 'dl4nlp']"
106,"[Version 3] Nhập môn học máy và khai phá dữ liệu của đại học BKHN 🔥🔥🔥
Hi các bạn,
1 vài tuần trước mình có chia sẻ với các bạn giáo trình môn học: Nhập môn học máy và khai phá dữ liệu của đại học Bách Khoa Hà Nội với 2 phiên bản khác nhau:
Bài giảng của thầy Thân Quang Khoát (https://www.facebook.com/groups/dsmlvietnam/permalink/323317617115033/?mibextid=oMANbw): Slide tiếng Anh + video tiếng Việt 
Bài giảng của thầy Ngô Văn Linh (https://www.facebook.com/groups/dsmlvietnam/permalink/330231563090305/?mibextid=oMANbw): Slide tiếng Việt
Hôm nay mình xin chia sẻ với các bạn phiên bản cuối cùng cũng của môn học này (cùng học phần luôn) của thầy Nguyễn Nhật Quang. Phiên bản này thì slide cũng hoàn toàn là bằng tiếng Việt các bạn nhé 😁
Link to slide: https://drive.google.com/drive/folders/1hekfS2RdjEiFTiYbtG64GZ7ppPGQDb7x?usp=drive_link
#ml_share","['#sharing', '#machine_learning']","['version', '3', 'nhập môn', 'học', 'máy', 'khai phá liệu', 'đại học', 'bkhn', 'hi', '1', 'tuần giáo trình', 'môn học', 'nhập môn', 'học', 'máy', 'khai phá liệu', 'đại học', 'bách khoa', 'hà nội', '2', 'phiên', 'giảng', 'thầy', 'thân quang', 'khoát', 'slide', 'tiếng', 'video', 'tiếng', 'việt', 'giảng', 'thầy', 'ngô', 'văn linh slide', 'tiếng', 'việt', 'hôm', 'phiên', 'môn học', 'học', 'thầy', 'nguyễn nhật quang', 'phiên', 'slide', 'tiếng', 'việt', 'link', 'to', 'slide']"
107,"#DL #question
Chào mn, hiện e đang có đề tài eKYC nhưng tìm trên mạng không thấy có source code nào tham khảo, và cũng không biết keyword nào về việc verify ảnh chụp webcam và ảnh trên cccd. K biết ac có ai có keyword hoặc bài viết cho e xin tham khảo được k ạ? (Đây chỉ là assignment của e thôi ạ)
E cảm ơn mn ạ. T4r!",['#Q&A'],"['chào mn', 'hiện e', 'đề tài', 'ekyc', 'mạng', 'source code', 'tham khảo', 'keyword', 'verify', 'ảnh', 'chụp', 'webcam', 'ảnh', 'cccd', 'k', 'ac', 'keyword', 'viết', 'e', 'tham khảo', 'k', 'assignment', 'e', 'e mn', 't4r']"
108,"Chào mọi người, e đang bí giải pháp cải thiện độ chính xác của model đọc biển số, và e muốn có thể xử lý được trong thời gian thực khi sử dụng camera trên mobile luôn. Vì e thấy một vài thư viện OCR khi biển bị nghiêng hoặc mờ quá thì đọc không được chính xác lắm, nên e đang thử tách từng ký tự ra bằng object detection nốt và classify sau. Và e thường sử dụng tensorflow để training. Mọi người có giải pháp nào giúp e với, e cảm ơn ạ
#other","['#Q&A', '#cv']","['chào', 'e bí', 'giải pháp', 'cải thiện', 'độ', 'xác model', 'đọc', 'biển', 'e thể', 'thực camera', 'mobile', 'e', 'thư viện', 'ocr', 'biển', 'nghiêng mờ', 'đọc', 'xác', 'lắm', 'e', 'thử', 'tách', 'ký', 'object', 'detection', 'nốt', 'classify', 'e tensorflow', 'training', 'giải pháp', 'giúp', 'e e']"
109,"Tổng hợp các thuật toán Machine Learning quan trọng nhất cùng với ưu và nhược điểm  🔥🔥🔥
Hi các bạn,
Đây là bản tổng hợp 49 trang được tóm lược từ khóa học Introduction to Machine Learning của đại học Munich (LMU). Trong tài liệu này thì các thuật toán quan trọng nhất trong Machine Learning sẽ được tóm tắt, kèm với ưu nhược điểm và Code tương ứng trên 2 ngôn ngữ là R và Python 😎
Link to pdf: https://drive.google.com/file/d/1troqxtUjj4p8gpmF6zLoGA1_gAkdprQ5/view?usp=sharing
#ml_share","['#sharing', '#machine_learning']","['tổng hợp', 'thuật toán', 'machine', 'learning', 'ưu nhược hi', 'tổng hợp', '49', 'trang', 'tóm lược', 'khóa', 'học', 'introduction', 'to', 'machine', 'learning', 'đại học', 'munich', 'lmu', 'tài liệu', 'thuật toán', 'machine', 'learning', 'tóm tắt', 'kèm', 'ưu nhược code', 'tương ứng', '2', 'ngôn ngữ', 'r', 'python', 'link', 'to', 'pdf']"
110,"Hi các anh chị trong group, em có một vài vấn đề về định hướng nghề nghiệp mong sẽ có được lời khuyền từ anh chị.
Hiện em đang là sinh viên năm 4 và sẽ chuẩn bị đi thực tập theo chương trình của khoa. Tuy nhien các công ty trong danh sách của khoa lại không có công ty nào tuyển vị trí liên quan đến AI/ML. Và em cũng biết hiện các công ty bên ngoái khác hầu như cũng không có quá nhiều cơ hội cho các bạn intern hay fresher.
Dẫu biết học và làm gì thì phải cố gắng đến cùng, tuy nhiên ra trường ai cũng phải đi làm để kiếm sống, các vị trí AI/ML cho các bạn mới thực sự rất ít hay có thể nói là không có. Em thì cũng sắp ra trường và cũng không thể mù quáng đâm đầu, chờ đợi mà không biết tương lai nó đi đến đâu được.
Dẫu biết các vị trí ở IT khác cũng cạnh tranh không kém nhưng ít ra còn các công ty vẫn có nhu cầu và còn tuyển mở ra một vài cơ hội cho người mới như em. Vậy mọi người cho em hỏi em có nên chuyển hướng học sang cái khác không ạ?
Tiếng anh của em ở mức tốt, hoàn toàn có khả năng tự học tốt và không ngại học lại một thứ từ đầu. Bài viết của em có thể hơi dài, mong mọi người có thể đọc hết ạ, em nghĩ một vài bạn cũng sẽ vào trường hợp như em. Em cảm ơn và sẽ ghi nhận mọi lời khuyên của mọi người ạ. Em cảm ơn ạ
#career
#hoidap",['#Q&A'],"['hi group', 'định hướng', 'nghề nghiệp', 'mong khuyền', 'hiện', 'sinh viên', '4', 'chuẩn', 'đi', 'thực tập', 'chương trình', 'khoa', 'nhien', 'công ty', 'danh sách', 'khoa', 'công ty', 'tuyển ml', 'hiện', 'công ty', 'ngoái', 'hầu hội', 'intern', 'fresher học', 'cố gắng nhiên', 'trường', 'đi', 'kiếm', 'sống', 'ml', 'thực thể', 'trường thể', 'mù quáng', 'đâm đầu', 'chờ đợi', 'tương lai', 'đi', 'it', 'cạnh tranh', 'kém', 'công ty', 'nhu cầu', 'tuyển hội', 'hướng', 'học', 'tiếng', 'khả năng', 'học ngại', 'học', 'đầu', 'viết thể', 'hơi', 'mong thể', 'đọc', 'trường hợp', 'ghi', 'khuyên']"
111,"Em xin phép anh Việt và mọi người ạ !
Hiện tại em đang làm 1 project về phát hiện ngôn ngữ cơ bản nhưng lại bị xảy ra lỗi không đọc được file dataset để huấn luyện ạ :( và em cũng kbt là do đâu nên mong mọi người giúp đỡ ạ !
#ML",['#Q&A'],"['phép', 'việt', '1', 'project', 'phát hiện', 'ngôn ngữ', 'xảy', 'lỗi', 'đọc', 'file', 'dataset', 'huấn luyện', 'kbt', 'mong', 'giúp đỡ']"
112,"CNN explainer: tương tác với CNN trên web browser 🔥🔥🔥
Mình xin giới thiệu với các bạn 1 trang web rất thú vị, giúp các bạn mới học về CNN có thể hiểu rõ hơn cách thức mà CNN hoạt động: CNN explainer 🥰
Thông qua các thao tác đơn giản, các bạn có thể tương tác với các layer khác nhau trong CNN và trực quan hóa cách mà CNN áp dụng các phép tính khác nhau.
Bản thân mình cũng đã có đôi lần play với trang web này, khá thú vị và độc đáo 😎
Link: https://poloclub.github.io/cnn-explainer/
#dl_share","['#sharing', '#deep_learning']","['cnn', 'explainer', 'tương tác', 'cnn web', 'browser', 'giới thiệu', '1', 'trang web', 'thú vị', 'giúp', 'học', 'cnn thể', 'thức cnn', 'hoạt động', 'cnn', 'explainer', 'thông', 'thao tác', 'đơn giản thể', 'tương tác', 'layer cnn', 'trực quan', 'hóa cnn', 'áp dụng', 'phép', 'thân', 'đôi', 'play', 'trang web', 'thú vị', 'độc đáo', 'link', 'https', 'poloclub', 'github', 'io', 'cnnexplainer']"
113,"Em chào mn ạ, mn có ai đã làm vợi bộ dữ liệu IMS Bearing Data về 4 ổ bi để dự đoán sự hư hỏng của nó chưa ạ. Mn cho em xin ý kiến về đề tài và thuật toán để sử dụng với ạ. Em cám ơn.
#DSP #ML","['#Q&A', '#data']","['chào', 'mn', 'mn', 'vợi liệu', 'ims', 'bearing', 'data', '4', 'ổ bi', 'dự đoán', 'hư hỏng', 'mn kiến', 'đề tài thuật', 'toán', 'cám ơn']"
114,"Tổng hợp các câu hỏi phỏng vấn Data Science, Data Analysis, Machine Learning và Deep Learning 🔥🔥🔥
Hi các bạn,
Dưới đây là tổng hợp các câu hỏi phỏng vấn dành cho các bạn theo đuổi mảng Data Science. Cụ thể chúng ta có:
8 câu hỏi về thống kê
27 câu hỏi về Data Science (Câu cuối đáng nhẽ phải xếp vào Deep Learning)
12 câu hỏi Data Analysis (Phần lớn xếp vào Data Science thì mình thấp hợp lý hơn) 
31 câu hỏi về Machine Learning 
31 câu hỏi về Deep Learning 
Bỏ qua việc phân chia vào các topic không hợp lý lắm thì đây là 1 tài liệu chất lượng, giúp các bạn ôn tập lại kiến thức cũng như chuẩn bị cho các buổi phỏng vấn xin việc. Nhớ lưu lại các bạn nhé ☺️
Link to pdf: https://drive.google.com/file/d/1JGEp_SPNOqeKf4WahIgWZimklnt-TKav/view?usp=sharing
#ds_share #ml_share #dl_share",['#sharing'],"['tổng hợp vấn', 'data', 'science', 'data', 'analysis', 'machine', 'learning', 'deep', 'learning', 'hi tổng hợp vấn', 'đuổi', 'mảng', 'data', 'science', 'ta', '8', 'thống kê', '27', 'data', 'science', 'câu', 'nhẽ', 'xếp', 'deep', 'learning', '12', 'data', 'analysis', 'xếp', 'data', 'science', 'hợp lý', '31', 'machine', 'learning', '31', 'deep', 'learning', 'phân chia', 'topic', 'hợp lý', 'lắm', '1', 'tài liệu', 'chất', 'giúp', 'ôn tập', 'kiến thức', 'chuẩn vấn', 'lưu link', 'to', 'pdf']"
115,"Em chào mọi người ạ.
Hiện tại em đang muốn nâng cao chất lượng hình ảnh (ví dụ như làm nét ảnh hơn,...) thì có thuật toán, thư viện nào hỗ trợ không ạ. Mọi người giới thiệu cho em với.
Em cảm ơn ạ
#cv_study","['#Q&A', '#cv']","['chào', 'nâng', 'chất', 'hình ảnh', 'ví dụ', 'nét', 'ảnh', 'thuật toán', 'thư viện', 'giới thiệu']"
116,"Em chào mọi người ạ. Mọi người cho e hỏi có cách nào delete các dòng bị lỗi type như này không ạ. Em dùng file csv với thư viện pandas ạ. Em cảm ơn mọi người ạ.
#py_orther
#hoidap","['#Q&A', '#python']","['chào', 'e delete', 'dòng', 'lỗi', 'type', 'file', 'csv', 'thư viện', 'pandas']"
117,"Python Cheat sheet cho các thư viện phổ biến dành cho Data Science 🔥🔥🔥
Hi các bạn,
Dưới đây là Cheat sheet dành cho các thư viện phổ biến nhất trong Python dành cho mảng Data Science, bao gồm:
Pandas
Numpy
Scikit-Learn 
Matplotlib & Seaborn
Beautiful Soup
Selenium
Với cá nhân minh, ngoài 2 thư viện cuối cũng khá lâu rồi mình không sử dụng thì các thư viện còn lại mình vẫn dùng rất thường xuyên
Link to pdf: https://drive.google.com/file/d/1n_hgAFKfVTa43UGTkREX9I29fCiMyx2x/view?usp=sharing
#cheatsheet_share #ds_share","['#sharing', '#python', '#data']","['python', 'cheat', 'sheet', 'thư viện', 'phổ biến', 'data', 'science', 'hi cheat', 'sheet', 'thư viện', 'phổ biến', 'python', 'mảng', 'data', 'science', 'bao', 'pandas', 'numpy', 'scikitlearn', 'matplotlib', 'seaborn', 'beautiful', 'soup', 'selenium minh', '2', 'thư viện', 'thư viện', 'xuyên', 'link', 'to', 'pdf']"
118,"Chào mọi người, em mới học về NLP, hiện em xây dựng được model và lưu dưới dạng .pt mọi người cho em hỏi cách deloy model lên web đơn giản để demo với ạ
#NLP #deploy","['#Q&A', '#nlp']","['chào học', 'nlp', 'hiện', 'xây dựng', 'model', 'lưu dạng', 'pt', 'deloy', 'model web', 'đơn giản', 'demo']"
119,"#scholarship_ask ?
Em chào mọi người trong group. Em là sinh viên năm cuối đang học chuyên ngành ĐTVT của đh BK HCM. Em theo hướng nhúng và có ý định nghiên cứu và học Master hướng AI/DS. Mọi người cho em hỏi là các trường Uni ở Úc, can hay EU có cho xét tuyển hay cấp học bổng bán phần cho sinh viên thuộc khối ngành kỹ thuật không phải CS dành cho chương trình master CS không ạ. Em xin cảm ơn",['#Q&A'],"['chào', 'group', 'sinh viên', 'học', 'chuyên ngành', 'đtvt', 'đh', 'bk', 'hcm', 'hướng', 'nhúng định', 'nghiên cứu', 'học', 'master', 'hướng', 'ds', 'trường', 'uni', 'úc', 'can', 'eu', 'xét', 'tuyển', 'học bổng', 'sinh viên', 'khối', 'ngành', 'kỹ thuật', 'cs', 'chương trình', 'master', 'cs']"
120,"Khi mọi người đọc paper thì có trick gì không ạ hay chỉ đọc từ đầu tới cuối? Em đọc paper gặp rất nhiều danh từ riêng chưa biết, chưa kể tới tiếng Anh, nên đọc rất chậm, và cũng không biết nên focus vào phần nào của paper. Mong anh chị cho em lời khuyên ạ. Em cảm ơn.
#skill",['#Q&A'],"['đọc', 'paper trick', 'đọc', 'đầu', 'đọc', 'paper danh tiếng', 'đọc', 'chậm', 'focus', 'paper', 'mong', 'khuyên']"
121,"Chào mọi người , cho em xin hỏi về bài toán Text Detection là e đang cố tạo một full connection layer để detect ,nhưng mà output của một image có thể có ít hoặc nhiều bounding box vì vậy nên em không biết làm sao để detect ra output như này,mong mọi người chỉ ạ
#other
#hoidap","['#Q&A', '#deep_learning', '#cv']","['chào toán', 'text', 'detection', 'e cố', 'full', 'connection', 'layer', 'detect', 'output', 'image thể', 'bounding', 'box', 'detect', 'output', 'mong']"
122,"Các bạn đã thử chat chit với ChatGPT chưa?
ChatGPT là một ứng dụng có khả năng trả lời rất giống con nguời và có một kho kiến thức trong nhiều lĩnh vực khác nhau như làm thơ, soạn nhạc và thậm chí là lập trình.
Hãy cùng thử tìm hiểu cách cách áp dụng công nghệ của ChatGPT vào việc xây dựng chatbot của riêng chúng ta trong bài hôm nay.
#nlp_share","['#sharing', '#nlp']","['thử', 'chat', 'chit', 'chatgpt', 'chatgpt', 'ứng dụng', 'khả năng', 'nguời kho', 'kiến thức', 'lĩnh vực', 'thơ soạn', 'nhạc chí', 'lập trình', 'thử', 'áp dụng', 'công nghệ', 'chatgpt', 'xây dựng', 'chatbot', 'ta', 'hôm']"
123,"Yann LeCun - Người đóng góp nhiều nhất vào sự phát triển của CNN 🔥🔥🔥
Hi các bạn,
Tiếp tục với series giới thiệu về các huyền thoại trong lĩnh vực AI, hôm nay chúng ta sẽ nói về Yann LeCun - người mà nếu đóng góp của ông cho Convolutional Neural Networks là số 2 thì không ai là số 1. Dưới đây là tóm tắt 1 vài đóng góp nổi bật nhất của ông:
Ông là cha đẻ của Siamese Neural Network 
Ông và các cộng sự là những người tạo ra LeNet - 1 trong các viên gạch đầu tiên của CNN 
Ông là người tạo ra dataset nổi tiếng MNIST 
Ông chính là tác giả của Character-level CNN dành cho bài toán document classification (Các bạn ngày nay có thể ít biết đến mô hình này. Nhưng hồi 2015 mình bắt đầu học về AI thì mô hình này father of nổi tiếng 😎)
Ông là người đầu tiên áp dụng CNN vào rất nhiều bài toán khác nhau
Tất nhiên vẫn có 1 vài tranh cãi nhỏ về sự đóng góp của ông so với 2 cây đại thụ khác là Andrew Ng và Geoffrey Hinton. Nhưng những gì mà bộ 3 này đóng góp cho AI thì là không phải bàn cãi 😎
#ai_share ",['#sharing'],"['yann', 'lecun', 'đóng góp', 'phát triển', 'cnn', 'hi series', 'giới thiệu', 'huyền thoại', 'lĩnh vực', 'hôm', 'ta', 'yann lecun', 'đóng góp', 'convolutional', 'neural', 'networks', '2', '1', 'tóm tắt', '1', 'đóng góp', 'nổi bật', 'đẻ', 'siamese', 'neural', 'network', 'cộng', 'lenet', '1', 'viên', 'gạch', 'cnn', 'dataset', 'nổi tiếng', 'mnist tác giả', 'characterlevel', 'cnn toán', 'document', 'classification thể', 'mô hình', 'hồi', '2015', 'học', 'mô hình', 'father of', 'nổi tiếng', 'áp dụng', 'cnn toán', 'tất nhiên', '1', 'tranh cãi', 'đóng góp', '2', 'đại thụ', 'andrew', 'ng', 'geoffrey', 'hinton', '3', 'đóng góp', 'bàn cãi']"
124,"Chào mọi người, hôm nay cho em xin hỏi về quá trình huấn luyện mô hình trên các device : cpu, mps, gpu. Em hiện tại đang xài macOS và set device to mps để huấn luyện các mô hình DL để chạy nhanh hơn so với cpu. Nhưng em thấy nó vẫn chạy khá chậm vì nó không set được các num workers để có thể chạy song song trên các luồng, điều này có thể làm nó chạy không nhanh bằng gpu của cuda nvidia. Em biết có rất nhiều cách chạy như trên colab hay kaggle, nhưng em muốn chạy locally trên macOS. Không biết mn có giải pháp nào giúp mô hình chạy nhanh hơn không ạ, vì cuda nvidia không hỗ trợ cho mac m2 hay sao ạ. Em xin cảm ơn
#gpu",['#Q&A'],"['chào', 'hôm', 'trình', 'huấn luyện', 'mô hình', 'device', 'cpu', 'mps', 'gpu', 'xài', 'macos', 'set', 'device', 'to', 'mps', 'huấn luyện', 'mô hình', 'dl', 'chạy', 'cpu', 'chạy', 'chậm', 'set', 'num', 'workers thể', 'chạy', 'song song', 'luồng thể', 'chạy', 'gpu', 'cuda', 'nvidia', 'chạy', 'colab kaggle', 'chạy', 'locally', 'macos', 'mn', 'giải pháp', 'giúp', 'mô hình', 'chạy', 'cuda', 'nvidia', 'mac', 'm2']"
125,"Hôm nọ mình mới đọc được bài về tuyển dụng nhân sự AI đang rất khó và cạnh tranh.
Mình theo hướng học thuật và 1 năm sản xuất dc 3 paper nhưng để nói là chất lượng và tính mới thì có mình tự thấy không được cao.
Việc này có được coi là kinh nghiệm mà điền vào cv hay không? Và liệu việc sản xuất paper có được đánh giá cao khi tuyển dụng hay không?
#hoidap #computervision #DL",['#Q&A'],"['hôm', 'đọc', 'tuyển dụng', 'nhân', 'cạnh tranh', 'hướng', 'học thuật', '1', 'sản xuất', 'dc', '3', 'paper', 'chất', 'coi', 'kinh nghiệm', 'điền', 'cv liệu', 'sản xuất', 'paper', 'tuyển dụng']"
126,"Chào mọi người, em muốn xin lời khuyên về định hướng ạ.
Em đang là sinh viên năm 3. Hiện em đang muốn bắt đầu học về AI, nhưng kiến thức nền về toán của em không được tốt lắm.
Em còn 1.5 năm nữa là ra trường, em đang rất phân vân giữa tiếp tục học về Web, app, rồi từ từ trau dồi AI hay quyết tâm tập trung hẳn vào AI.
Rất mong nhận được lời khuyên của mọi người, em xin cảm ơn ạ.
#ml_study","['#Q&A', '#machine_learning']","['chào', 'khuyên', 'định hướng', 'sinh viên', '3', 'hiện học', 'kiến thức', 'toán', 'lắm', '1', '5', 'trường', 'phân vân', 'học', 'web', 'app', 'trau dồi', 'quyết tâm', 'hẳn', 'mong', 'khuyên']"
127,"e chào a việt và mn ạ, e đang có 1 bài toán yêu cầu áp dụng phân cụm AHC vào dataset và vẽ biểu đồ dendrogram. E đã chạy ra biểu đồ rồi nhưng e thấy sai sai. Mn có xem e làm đúng chưa và cần khắc phục chỗ nào ạ ? data e down từ link này ạ: https://archive.ics.uci.edu/dataset/591/gender+by+namecòn 
đây là code của e
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage
import pandas as pd
gender_name = pd.read_csv(""name_gender_dataset.csv"", encoding='unicode_escape', header=None)
selected_column= [ 1, 2, 3,4]
data = list(zip(gender_name[selected_column]))
linkage_data = linkage(data, method='ward',metric='euclidean')
dendrogram(linkage_data)
plt.show()
kết quả e ra như hình dưới ạ. em cảm ơn mn ạ
 #ds_ml_study",['#Q&A'],"['e', 'chào a', 'việt', 'mn', 'e', '1', 'toán', 'áp dụng', 'phân cụm', 'ahc', 'dataset', 'vẽ', 'biểu đồ', 'dendrogram e', 'chạy', 'biểu đồ', 'e', 'sai', 'sai', 'mn e', 'khắc phục', 'chỗ', 'data', 'e', 'down', 'link', 'code', 'e', 'import', 'matplotlib', 'pyplot', 'as', 'plt', 'from', 'scipy', 'cluster', 'hierarchy', 'import', 'dendrogram', 'linkage', 'import', 'pandas', 'as', 'pd', 'gender_name', 'pd', 'read_csv', 'name_gender_dataset', 'csv', 'encoding', 'unicode_escape', 'header', 'none', 'selected_column', '1', '2', '3', '4', 'data', 'list', 'zip', 'gender_name', 'selected_column', 'linkage_data', 'linkage', 'data', 'method', 'ward', 'metric', 'euclidean', 'dendrogram', 'linkage_data', 'plt', 'show kết', 'e hình', 'mn']"
128,"Chào mọi người, anh Việt.

Nhờ mọi người cho mình lời khuyên với ạ.
Chả là mình có học qua khóa ML, và DL trên coursera và đang học khóa DL with Pytorch, cũng như có làm một vài project nhỏ. Hướng sắp tới của mình là ML, và cụ thể về Deep Reinforcement Learning.
Mặt dù mình đã học qua các khóa ở trên nhưng vẫn còn mơ hồ về cách train mô hình vậy nên nhờ mn recommend những course, project, youtube, book and website đáng để học được những kỹ năng trên bằng projects với ạ.
Cũng như câu hỏi trên thì nhờ mọi người giới thiệu cho những dự án để cải thiện kỹ năng code với framework Pytorch, và liên quan đến Deep Reinforcement Learning càng quá tốt ạ!

Vì là newbie và cũng là trái ngành nên câu hỏi có gì ko đúng xin  mn chỉnh sửa thêm.

Cảm ơn mn!

#help, #hoidap #ml #DeepreinforcementLearning #Pytorch","['#Q&A', '#machine_learning', '#python']","['chào', 'việt', 'khuyên', 'chả', 'học', 'khóa', 'ml', 'dl', 'coursera', 'học', 'khóa', 'dl', 'with', 'pytorch', 'project', 'hướng', 'ml', 'deep', 'reinforcement', 'learning', 'mặt', 'học', 'khóa', 'mơ hồ', 'train', 'mô hình', 'mn', 'recommend', 'course', 'project', 'youtube', 'book and', 'website học', 'kỹ năng', 'projects', 'giới thiệu', 'dự án', 'cải thiện', 'kỹ năng', 'code', 'framework', 'pytorch', 'deep', 'reinforcement', 'learning', 'newbie', 'trái', 'ngành', 'ko', 'mn', 'chỉnh sửa', 'mn']"
129,"Decision Tree LUÔN bị overfitting. Và đây là cách ngăn chặn 🔥🔥🔥
Hi các bạn,
Có lẽ hầu hết các bạn không còn xa lạ gì với Decision Tree - 1 trong số các thuật toán Machine Learning cơ bản, cũng như Scikit-learn - thư viện quốc dân về Machine Learning mà ko ai học về AI/Data Science lại không biết. 
Trong Scikit-learn, Decision Tree mặc định sẽ được xây dựng cho đến khi tất cả các node lá đều chỉ chứa 1 class mà thôi (pure). Khi đó, chúng ta đạt được 100% accuracy ở bộ train. Tất nhiên với các bạn đã học về Machine Learning, chúng ta đều không mấy vui vẻ với con số này vì điều đó có nghĩa là mô hình của chúng ta:
100% bị overfitting
Khả năng tổng quát hóa thấp (poor generalization)
Vậy câu hỏi ở đây là, làm sao để ngăn chặn điều này xảy ra. Câu trả lời chính là dựa vào Cost-complexity-pruning (CPP). 1 điều rất may mắn đó là đây cũng là 1 parameter của Decision Tree trong Scikit-learn 🥰
CPP kết hợp 2 yếu tố để rút gọn Decision Tree:
Cost: Số lượng data bị phân loại nhầm
Complexity: Số lượng node
Kết quả như các bạn có thể thấy ở hình phía dưới 😎
#ml_share
Original article: https://www.blog.dailydoseofds.com/p/decision-trees-always-overfit-heres","['#sharing', '#machine_learning']","['decision', 'tree', 'overfitting', 'ngăn chặn', 'hi lẽ', 'lạ', 'decision tree', '1', 'thuật toán', 'machine', 'learning', 'scikitlearn', 'thư viện', 'quốc dân', 'machine', 'learning', 'ko', 'học', 'data', 'science', 'scikitlearn', 'decision', 'tree', 'mặc định', 'xây dựng', 'tất node', 'lá', 'chứa', '1', 'class', 'pure', 'ta', '100', 'accuracy', 'train', 'tất nhiên', 'học', 'machine', 'learning', 'ta', 'mấy', 'vui vẻ', 'nghĩa mô hình', 'ta', '100', 'overfitting', 'khả năng', 'tổng quát', 'hóa', 'poor', 'generalization', 'ngăn chặn', 'xảy', 'câu', 'dựa', 'costcomplexitypruning', 'cpp', '1', 'may mắn', '1', 'parameter', 'decision', 'tree', 'scikitlearn', 'cpp', 'kết hợp', '2', 'yếu tố', 'rút', 'gọn', 'decision', 'tree', 'cost', 'data', 'phân nhầm', 'complexity', 'node', 'kết thể', 'hình original', 'article']"
130,"Em chào anh Việt và mọi người. 
Em đang làm bài toán Training Custom Object Detector và sau đó dùng snpe để chạy model ( giống như ví dụ này )  có 1 số câu hỏi 
Câu 1 : Khi em thực hiện việc dự đoán ảnh , tức là sau khi chạy lệnh spne-net-run như trong tutorial thì được các file raw . Ở đây em đang thử  2 hướng 
Hướng 1 : Chạy theo tutorial trong link trên với model là inception_v3_quantized.dlc
Hướng 2 : pretrain với model ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03 . customize với file label_map.pbtxt như trong ảnh em để bên dưới
Sau khi đọc kết quả từ các file raw thì : với inception được 1 mảng (1000,) với các giá trị là các xác suất thì quá rõ ràng , nhưng với mobilenet thì được mảng (100,) với giá trị là các số 1,2,3 . Tại sao không phải là xác suất và 1,2,3 này có liên quan gì đến id trong label_map không ? 
Câu hỏi 2 : Nếu mảng có các giá trị 1,2,3 thì làm sao để biết ảnh đưa vào được chia vào class nào ( nếu như là xác suất thì kết quả sẽ trả về là class có xác suất lớn nhất nhưng 1,2,3 thì có nhiều số 3 lặp lại ) 
Câu hỏi 3 : Em đang label bằng tay thì có cách nào khác nhanh hơn không ạ ? 
Em cảm ơn mọi người nhiều ạ #dl #hoidap","['#Q&A', '#cv']","['chào', 'việt toán', 'training', 'custom', 'object', 'detector', 'snpe', 'chạy', 'model', 'ví dụ', '1', 'câu', '1', 'dự đoán', 'ảnh', 'tức', 'chạy', 'lệnh', 'spnenetrun', 'tutorial', 'file', 'raw', 'thử', '2', 'hướng', 'hướng', '1', 'chạy', 'tutorial', 'link', 'model', 'inception_v3_quantized', 'dlc', 'hướng', '2', 'pretrain', 'model', 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03', 'customize', 'file', 'label_map', 'pbtxt ảnh', 'đọc', 'kết file', 'raw', 'inception', '1', 'mảng', '1000', 'xác suất', 'ràng', 'mobilenet', 'mảng', '100', '1', '2', '3', 'xác suất', '1', '2', '3', 'id', 'label_map', '2', 'mảng', '1', '2', '3', 'ảnh', 'chia', 'class', 'xác suất', 'kết class', 'xác suất', '1', '2', '3', '3', 'lặp', '3', 'label']"
131,"Em chào mọi người ạ. Em đang tìm hiểu về ngành AI. Theo em biết, khi học đến 1 trình độ thì mình sẽ phải lựa chọn theo đuổi lĩnh vực nhỏ như NLP, Computer Vision, .... 
Cho em hỏi mỗi lĩnh vực sẽ làm về cái gì ạ?
Mọi người có kinh nghiệm gì khi chọn giữa các lĩnh vực này không ạ?
Em đang khá thích Computer Vision nhưng em thấy công ty Việt Nam dạo này hay tuyển dụng NLP í ạ thì không biết là có phải do CV khá khó kiếm việc ở Việt Nam không ạ?
Em cảm ơn mọi người nhiều ạ
#other",['#Q&A'],"['chào', 'ngành', 'học', '1', 'trình độ', 'lựa đuổi', 'lĩnh vực', 'nlp', 'computer', 'vision', 'lĩnh vực', 'kinh nghiệm', 'lĩnh vực', 'computer vision', 'công ty', 'việt nam', 'dạo', 'tuyển dụng', 'nlp', 'í', 'cv', 'kiếm', 'việt nam']"
132,"140 câu hỏi lập trình Python cơ bản giúp chuẩn bị cho technical interview 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn tuyển tập 140 câu hỏi lập trình Python cơ bản (có bao gồm đáp án). Những câu hỏi này sẽ giúp các bạn chuẩn bị tốt hơn cho các technical interview hay coding challenge cho các vị trí như Data Scientist, Machine Learning engineer, Ai engineer hay bất kì vị trí nào có liên quan đến Python 😎
Link to pdf: https://drive.google.com/file/d/1Lf76ElJmwZU3cF7DMrDBun9wTSVtrbfF/view?usp=sharing
#py_share #interview","['#sharing', '#python']","['140', 'lập trình', 'python', 'giúp', 'chuẩn', 'technical', 'interview', 'hi tuyển', 'tập', '140', 'lập trình', 'python', 'bao', 'đáp án', 'giúp', 'chuẩn', 'technical', 'interview', 'coding', 'challenge', 'data', 'scientist', 'machine', 'learning', 'engineer', 'engineer', 'python', 'link', 'to', 'pdf']"
133,"Chào mọi người và admin. Em có một thắc mắc mong được mọi người giải thích, em được biết DL là một phương pháp rất mạnh và nhưng rất khó để diễn giải tại sao hiệu quả. Vậy:
- Nhận định này có đúng không?
- Nếu nhận định đấy đúng, thì làm sao các nhà khoa học phát hiện ra các kiến trúc như CNN, Transformer (trong khi không biết được nó hoạt động có tốt không)
- Các kiến trúc nổi tiếng có liên quan gì đến việc hoạt động của não bộ hay không?
Tóm lại thắc mắc của em xoay quanh vấn đề là làm thế nào để tạo ra các kiến trúc DL hiệu quả.
Cảm ơn mọi người.
#dl #hoidap","['#Q&A', '#deep_learning']","['chào', 'admin', 'thắc mắc', 'mong', 'giải dl', 'phương pháp', 'diễn', 'giải hiệu', 'định định', 'đấy', 'khoa học', 'phát hiện', 'kiến trúc', 'cnn transformer', 'hoạt động', 'kiến trúc', 'nổi tiếng', 'hoạt động', 'não tóm', 'thắc mắc', 'xoay', 'quanh', 'kiến trúc', 'dl hiệu']"
134,"Nhập môn học máy và khai phá dữ liệu của đại học BKHN 🔥🔥🔥
Hi các bạn,
1 vài tuần trước mình có chia sẻ với các bạn giáo trình môn học: Nhập môn học máy và khai phá dữ liệu của đại học Bách Khoa Hà Nội (slide tiếng Anh còn video bài giảng tiếng Việt).
Hôm nay mình xin chia sẻ với các bạn slide bài giảng cũng của môn học này (cùng học phần luôn), nhưng của một thầy khác - thầy Ngô Văn Linh. Phiên bản này thì slide hoàn toàn là bằng tiếng Việt các bạn nhé 😁
Link to slide: https://drive.google.com/drive/folders/1wjiUmi5EjnzQ-umVUZJDhibCtSonI-5a?usp=drive_link
#ml_share","['#sharing', '#machine_learning']","['nhập', 'môn học', 'máy', 'khai phá liệu', 'đại học', 'bkhn', 'hi', '1', 'tuần giáo trình', 'môn học', 'nhập môn', 'học', 'máy', 'khai phá liệu', 'đại học', 'bách khoa', 'hà nội', 'slide', 'tiếng', 'video giảng', 'tiếng', 'việt', 'hôm', 'slide', 'giảng', 'môn học', 'học', 'thầy', 'thầy', 'ngô', 'văn linh', 'phiên', 'slide', 'tiếng', 'việt', 'link', 'to', 'slide']"
135,"Bác nào từng chạy yolov8 vs data khoảng trên 1m image chưa? Sao e chạy bath có 32 gpu ăn có 6Gb
Mà sao nó cứ báo lỗi tràn GPU nhỉ.
#computervision #DL","['#Q&A', '#deep_learning']","['chạy', 'yolov8', 'vs', 'data', '1', 'm', 'image', 'e', 'chạy', 'bath', '32', 'gpu', '6', 'gb', 'báo', 'lỗi', 'tràn', 'gpu']"
136,"Em chào mọi người em là sinh viên ngành cntt. Hiện tại em đã học xong base cơ bản về machine learning và sắp tiến vào các nhánh nhỏ của AI . Theo mn thị trường thế giới nói chung và thị trường Việt Nam nói riêng NLP hay CV đang được chuộng hơn ạ . Em cảm ơn anh Việt và mọi người ạ
#hoidap
#conputervision
#nlp",['#Q&A'],"['chào', 'sinh viên', 'ngành', 'cntt học', 'xong', 'base', 'machine', 'learning', 'tiến nhánh', 'mn', 'thị trường giới', 'thị trường', 'việt nam', 'nlp', 'cv chuộng', 'việt']"
137,"32 datasets để xây dựng các project Data Science/Machine Learning 🔥🔥🔥
Hi các bạn,
Dưới đây là tổng hợp 32 dataset để giúp các bạn luyện tập cách phân tích dữ liệu và xây dựng các mô hình Machine Learning, được phân loại thành các mức độ từ dễ đến khó, bao gồm:
Beginner level: 7 dataset đầu
Intermediate level: 19 dataset tiếp theo
Advanced level: 6 dataset cuối
#dataset_share
Link to datasets: https://datasciencedojo.com/blog/datasets-data-science-skills/?utm_campaign=DSD%20blogs%202023&utm_content=273978707&utm_medium=social&utm_source=linkedin&hss_channel=lcp-3740012","['#sharing', '#data']","['32', 'datasets', 'xây dựng', 'project', 'data', 'science', 'machine', 'learning', 'hi tổng hợp', '32', 'dataset', 'giúp', 'luyện tập', 'phân tích liệu', 'xây dựng', 'mô hình', 'machine', 'learning', 'phân', 'thành', 'độ', 'bao', 'beginner', 'level', '7', 'dataset', 'đầu', 'intermediate', 'level', '19', 'dataset', 'tiếp', 'advanced', 'level', '6', 'dataset', 'link', 'to', 'datasets']"
138,"Chào mọi người ạ, em hiện là một sinh viên năm nhất đang học ngành Khoa Học Máy Tính ạ. Ban đầu em định học chuyên ngành AI vào năm 2 nhưng vào group thấy mọi người bảo thị trường cạnh tranh khó kiếm việc nên bây giờ em định theo hai ngành này ạ:
- Data Science.
- Cloud Computing.
Em bắt đầu học code bằng python và lên đại học thì trường dạy thêm C++ ạ.
Em nên theo ngành nào trong 2 ngành này. Công ty nào ở VN sẽ cần ngành ""đó"".
Nếu ngành ""đó"" thì em nên làm gì trong phần còn lại năm nhất.
Và mn người có thể phân tích thị trường việc làm của ngành IT ở VN không ạ?
Cảm.ơn mọi người rất nhiều ạ.
#hoidap
#py_jobs
#py_roadmap",['#Q&A'],"['chào', 'hiện', 'sinh viên', 'học', 'ngành', 'khoa học', 'máy', 'ban đầu', 'định học', 'chuyên ngành', '2', 'group', 'bảo', 'thị trường', 'cạnh tranh', 'kiếm định', 'hai', 'ngành', 'data', 'science', 'cloud', 'computing', 'học', 'code', 'python', 'đại học', 'trường', 'dạy', 'c', 'ngành', '2', 'ngành', 'công ty', 'vn', 'ngành', 'ngành', 'mn thể', 'phân tích', 'thị trường', 'ngành', 'it', 'vn']"
139,"8 thư viện giúp tự động hóa EDA tasks trong các Data Science projects 🔥🔥🔥
Hi các bạn,
Trong các project về Data Science, EDA (Exploratory Data Analysis – Phân tích khám phá dữ liệu) là một bước vô cùng quan trọng. Nó giúp chúng ta có thể hiểu được dữ liệu mà mình đang làm việc, từ đó giúp cho quá trình lựa chọn và xây dựng mô hình trở nên hiệu quả hơn. Tuy nhiên, cũng phải thừa nhận đây là 1 bước khá tẻ nhạt 😅
Để giúp vơi đi nỗi đau cho các Data Scientist, dưới đây là 8 thư viện giúp tự động hóa EDA, nhằm giúp cho công việc của các Data Scientist trở nên bớt nhàm chán và hiệu quả hơn.
#ds_share
P/s: Trong 8 thư viện này thì mình đung Pandas-Profiling 😁","['#sharing', '#data']","['8', 'thư viện', 'giúp động', 'hóa', 'eda', 'tasks', 'data', 'science', 'projects', 'hi project', 'data', 'science', 'eda', 'exploratory', 'data', 'analysis', 'phân tích', 'khám phá liệu', 'vô', 'giúp', 'ta', 'thể liệu', 'giúp', 'trình lựa', 'xây dựng', 'mô hình', 'trở hiệu nhiên', 'thừa', '1', 'tẻ', 'nhạt', 'giúp', 'vơi', 'đi', 'nỗi', 'đau', 'data', 'scientist', '8', 'thư viện', 'giúp động', 'hóa', 'eda', 'giúp', 'công data', 'scientist', 'trở', 'bớt', 'nhàm', 'chán hiệu', 'p', 's', '8', 'thư viện', 'đung pandasprofiling']"
140,"mọi người cho em hỏi với ạ, trên mạng có những web nào có thể cho mình các model sẵn, mình chỉ cần bỏ dữ liệu và train thôi không vậy ạ, em có ý định sử dụng convnext và densenet để phân loại ảnh ạ
#ml
#dl
#cv","['#Q&A', '#deep_learning', '#cv']","['mạng', 'web thể', 'model', 'sẵn liệu', 'train định', 'convnext', 'densenet', 'phân ảnh']"
141,"MissForest - phương pháp thay thế tuyệt vời dành cho mean hay median imputation khi có dữ liệu bị khuyết 🔥🔥🔥
Không hiểu sao trong lúc viết mình cứ nhầm MissForest thành MissFortune 🙄
Hi các bạn,
Khi làm việc với dữ liệu, 1 trong các bước cơ bản chúng ta phải xử lý đó là missing value imputation - Điền vào các ô dữ liệu bị khuyết.  1 vài cách cơ bản bao gồm.
Điền vào các ô bị khuyết giá trị mean hoặc median hoặc 0 cho các numerical features
Điền vào các ô bị khuyết giá trị mode cho các categorical features
Drop luôn hàng đó (cách này thì thôi không tính tiền, tạm thời bỏ qua trong post này các bạn nhé 😅)
Tuy nhiên với 2 cách đầu tiên, chúng đều gây ra 1 hệ quả lớn, đó là làm cho số lượng phần tử của 1 giá trị cụ thể (mean, median, mode, 0, ...) tăng lên bất thường (như các bạn có thể nhìn thấy ở hình số 1 phía dưới). Điều này sẽ càng rõ ràng khi số lượng missing value quá nhiều 🥲 Như kết quả tất yếu, chúng ta sẽ có 1 phân bố khá dị, và không phản ánh được phân bố thực tế
Vậy làm sao để khắc phụ được tình trạng này. Câu trả lời là sử dụng MissForest - kĩ thuật dựa trên Random Forest được thiết kế nhằm xử lý các giá trị bị khuyết 1 cách hiệu quả.
Ý tưởng của MissForest rất đơn giản, chúng ta sẽ thực hiện 5 bước sau (Các bạn có thể nhìn vào hình số 2 phía dưới):
Bước 1: Điền vào các giá trị bị khuyết 1 giá trị ngẫu nhiên nào đó: Mean, median hay cái gì cũng được
Bước 2: Huấn luyện mô hình Random Forest với target (y) là feature mà chúng ta đang muốn điền giá trị bị khuyết
Bước 3: Dựa vào mô hình Random Forest vừa được huấn luyện ở bước 2 để dự đoán các giá trị bị khuyết, và sử dụng luôn giá trị dự đoán này để điền vào các giá trị bị khuyết đó
Bước 4: Lặp lại bước 3 cho đến khi nào hết iteration định nghĩa từ đầu (e.g. 10 iter) hoặc mô hình hội tụ (chạy thêm thì cũng không có gì thay đổi)
Nếu có nhiều hơn 1 feature có dữ liệu bị khuyết thì ý tưởng cũng tương tự (Hình số 3 phía dưới). Sau khi hoàn thành quá trình và trực quan hóa dữ liệu, các bạn sẽ thấy dữ liệu được điền dựa trên MissForest nhìn tự nhiên và sát với phân phối thực tế hơn rất nhiều các phương pháp truyền thống chúng ta vẫn hay làm 😎
Link to MissForest: https://github.com/epsilon-machine/missingpy (thư viện hoàn toàn tương thích với Scikit-learn các bạn nhé 😎)
#ds_tip ","['#sharing', '#data']","['missforest', 'phương pháp', 'thay', 'tuyệt vời', 'mean', 'median', 'imputation liệu', 'khuyết viết', 'nhầm', 'missforest', 'thành', 'missfortune', 'hi liệu', '1', 'ta', 'missing', 'value', 'imputation điền', 'ô liệu', 'khuyết', '1', 'bao', 'điền ô', 'khuyết mean', 'median', '0', 'numerical', 'features', 'điền ô', 'khuyết mode', 'categorical', 'features', 'drop', 'hàng', 'tiền', 'tạm thời', 'post nhiên', '2', '1', 'hệ tử', '1', 'mean', 'median', 'mode', '0', 'bất thể', 'hình', '1', 'ràng', 'missing', 'value kết', 'tất yếu', 'ta', '1', 'phân bố', 'dị phản ánh', 'phân bố', 'khắc', 'phụ', 'câu', 'missforest', 'kĩ thuật', 'dựa', 'random', 'forest', 'thiết kế', 'khuyết', '1', 'hiệu', 'tưởng', 'missforest', 'đơn giản', 'ta', '5', 'thể hình', '2', '1', 'điền khuyết', '1', 'ngẫu nhiên', 'mean', 'median', '2', 'huấn luyện', 'mô hình', 'random', 'forest', 'target', 'y feature', 'ta', 'điền khuyết', '3', 'dựa', 'mô hình', 'random', 'forest', 'huấn luyện', '2', 'dự đoán', 'khuyết', 'dự đoán', 'điền khuyết', '4', 'lặp', '3', 'iteration định nghĩa', 'đầu', 'e g', '10', 'iter', 'mô hình', 'hội tụ', 'chạy', '1', 'feature liệu', 'khuyết tưởng', 'tương hình', '3', 'hoàn thành', 'trình', 'trực quan', 'hóa liệu', 'liệu điền', 'dựa', 'missforest nhiên', 'sát', 'phân phối', 'phương pháp', 'truyền thống', 'ta', 'link', 'to', 'missforest', 'thư viện', 'tương scikitlearn']"
142,"Mọi người có ai có kinh nghiệm build model diffusion model cho mình hỏi chút.
Mình thấy model tốn phần cứng rất nặng để train. Nhưng khi mình đọc theory với implement lại code của Condition Diffusion thì thấy model nó khá là đơn giản khi dùng 2 bước chính là add noise và denoise cũng chỉ là tính toán biểu thức, cộng với VAE + U-NET cũng không nặng tới vậy. Vậy sự tính toán phức tạp của model này nằm ở đâu nhỉ. Mong mọi người giải đáp giúp mình :_)
#hoidap #diffusion",['#Q&A'],"['kinh nghiệm', 'build', 'model', 'diffusion', 'model', 'chút', 'model', 'tốn', 'cứng train', 'đọc', 'theory', 'implement', 'code', 'condition', 'diffusion', 'model', 'đơn giản', '2', 'add', 'noise', 'denoise toán', 'biểu thức', 'cộng', 'vae', 'unet toán', 'phức tạp model', 'nằm', 'mong', 'giải đáp', 'giúp', '_']"
143,"Em là sinh viên đang tìm hiểu về Computer Vision và em muốn thực hiện một project nhỏ.
Ý tưởng của em : cung cấp data là những bức ảnh tỉ lệ cố định, sau đó sẽ tự nhận diện và lấy các value đấy rồi cung cấp ra thành 1 file CSV.
Em đã tìm hiểu về OCR-based parsing thì không biết nó có phải phương pháp hiệu quả nhất cho mục đích của em không, em mong nhận được thêm những lời khuyên từ mọi người ạ.
Em xin cảm ơn.
#cv_study","['#Q&A', '#deep_learning', '#cv']","['sinh viên', 'computer', 'vision', 'project', 'tưởng', 'cung data', 'ảnh', 'tỉ lệ', 'cố định diện', 'value', 'đấy', 'cung', 'thành', '1', 'file', 'csv', 'ocrbased', 'parsing', 'phương pháp', 'hiệu', 'mục đích', 'mong', 'khuyên']"
144,"Trực quan hóa mô hình Machine Learning với Yellowbrick 🔥🔥🔥
Hi các bạn,
Trong các post trước về các thư viện Python trực quan hóa dữ liệu, mình đã từng nói qua về thư viện này rồi. Yellowbrick là 1 thư viện giúp trực quan hóa các mô hình Machine Learning 1 cách vô cùng hiệu quả. Yellowbrick mở rộng API của Scikit-learn, từ đó giúp thực hiện các task như model selection hay hyperparameter tuning trở nên đơn giản hơn rất nhiều. 1 thư viện rất thú vị và dễ sử dụng các bạn nhé 😁
Link: https://www.scikit-yb.org/en/latest/#
#ml_share","['#sharing', '#python']","['trực quan', 'hóa', 'mô hình', 'machine', 'learning', 'yellowbrick', 'hi post', 'thư viện', 'python', 'trực quan', 'hóa liệu', 'thư viện', 'yellowbrick', '1', 'thư viện', 'giúp', 'trực quan', 'hóa', 'mô hình', 'machine', 'learning', '1', 'vô hiệu', 'yellowbrick', 'rộng', 'api', 'scikitlearn', 'giúp', 'task', 'model', 'selection', 'hyperparameter', 'tuning', 'trở', 'đơn giản', '1', 'thư viện', 'thú vị', 'link', 'https', 'www', 'scikityb', 'org', 'en', 'latest']"
145,"Em đang là sinh viên năm nhất, và có định hướng theo ML nhưng em không biết bắt đầu từ đâu, nên học như thế nào cho đúng, rồi nên làm gì để cải thiện kĩ năng, định hướng tương lai ra sao! Em có search tìm tài liệu thì khá nhiều tài liệu em đang hoang mang không biết cái nào là chất lượng để học ạ! Mọi người giúp em cho em lời khuyên với ạ! Em chân thành cảm ơn!
#hoidap",['#Q&A'],"['sinh viên', 'định hướng', 'ml học', 'cải thiện', 'kĩ năng', 'định hướng', 'tương lai', 'search', 'tài liệu', 'tài liệu', 'hoang chất', 'học', 'giúp', 'khuyên', 'chân thành']"
146,"dạ chào anh Việt và mọi người, hiện tại em đang làm đồ án dự báo công suất phát nhà máy điện mặt trời bằng mô hình LSTM.
Bộ dữ liệu em đang có là bức xạ, nhiệt độ môi trường, nhiệt độ tấm pin, và công suất phát của nhà máy.
Em học điện, cũng mới tìm hiểu mảng này, nên mọi người ai có làm rồi có ý tưởng hay tài liệu gì chia sẻ giúp em với ạ.
em cám ơn mọi người.
#dl #lstm","['#Q&A', '#deep_learning']","['chào', 'việt', 'đồ án', 'dự báo', 'công suất', 'phát', 'máy', 'điện', 'mặt trời', 'mô hình', 'lstm liệu', 'xạ', 'nhiệt độ', 'môi trường', 'nhiệt độ', 'pin', 'công suất', 'phát', 'máy', 'học', 'điện', 'mảng', 'tưởng', 'tài liệu', 'giúp', 'cám ơn']"
147,"Feature scaling không phải lúc nào cũng cần thiết 🔥🔥🔥
Hi các bạn,
Trong quá trình xây dựng các mô hình Machine Learning, chúng ta đều biết là 1 trong các bước không thể thiếu đó là data preprocessing, hay tiền xử lý dữ liệu. Tùy thuộc vào kiểu dữ liệu, mỗi feature sẽ có cách tiền xử lý khác nhau. 1 trong số các loại feature phổ biến nhất là numerical features. Với kiểu dữ liệu này, hầu hết chúng ta sẽ thực hiện feature scaling - đưa các feature có scale khác nhau về cùng mức scale tương đương. Điều này nhằm ngăn chặn mô hình của chúng ta thiên vị hơn cho các feature có scale lớn 😅
Lấy ví dụ như trong hình số 2 ở bên dưới, nếu không thực hiện feature scaling thì feature income sẽ luôn ảnh hướng tới target hơn là feature experience, mặc dụ trong thực tế thì chưa chắc tầm ảnh hưởng của income đã quan trọng hơn của experience 🙄
Tuy nhiên điều này không phải lúc nào cũng cần thiết. Không phải mô hình Machine Learning nào cũng bị ảnh hưởng bởi scale của feature. Thật vậy, có nhiều mô hình mà việc feature có scale lớn hay nhỏ hoàn toàn không ảnh hưởng tới việc mô hình ra quyết định cuối cùng. 1 ví dụ điển hình chính là Decision Tree. Cây quyết định của chúng ta phân chia dữ liệu dựa vào các ngưỡng, do đó scale lớn hay nhỏ hoàn toàn không ảnh hưởng gì đến việc cây quyết định được xây dựng (ví dụ như ở hình số 3 ở bên dưới)
Tổng kết các mô hình cần sử dụng feature scaling trong quá trình tiền xử lý và những mô hình không cần bước này được thể hiện trong hình số 1 😎
Original article: https://www.blog.dailydoseofds.com/p/feature-scaling-is-not-always-necessary
#ml_tip","['#sharing', '#data', '#machine_learning']","['feature', 'scaling thiết', 'hi trình', 'xây dựng', 'mô hình', 'machine', 'learning', 'ta', '1', 'thể', 'data', 'preprocessing', 'tiền liệu', 'tùy', 'kiểu liệu', 'feature', 'tiền', '1', 'feature', 'phổ biến', 'numerical', 'features', 'kiểu liệu', 'ta', 'feature', 'scaling', 'feature', 'scale', 'scale', 'tương đương', 'ngăn chặn', 'mô hình', 'ta', 'thiên vị', 'feature', 'scale', 'ví dụ', 'hình', '2', 'feature', 'scaling', 'feature', 'income', 'ảnh', 'hướng', 'target', 'feature', 'experience', 'mặc', 'dụ', 'tầm', 'ảnh hưởng', 'income', 'experience nhiên thiết', 'mô hình', 'machine', 'learning', 'ảnh hưởng', 'scale', 'feature', 'mô hình', 'feature', 'scale', 'ảnh hưởng', 'mô hình', 'quyết định', '1', 'ví dụ', 'điển hình', 'decision', 'tree', 'quyết định', 'ta', 'phân chia liệu', 'dựa ngưỡng', 'scale', 'ảnh hưởng', 'quyết định', 'xây dựng', 'ví dụ', 'hình', '3', 'tổng kết', 'mô hình', 'feature', 'scaling trình', 'tiền', 'mô hình', 'thể hiện', 'hình', '1', 'original', 'article']"
148,"Chào mọi người, từ đâu mình có hệ thức B0* và b0* như dưới đây ạ
#ml","['#Q&A', '#math']","['chào', 'hệ thức', 'b0', 'b0']"
149,"[Iconic paper] Very Deep Convolutional Networks for Large-Scale Image Recognition - nơi VGG16 được trình làng 🔥🔥🔥
Hi các bạn,
Đã theo mảng AI thì việc phải đọc các research paper là việc mà dù chúng ta có muốn hay không (thường là vế sau 🥲) thì cũng vẫn phải làm. Thời mình còn đi học thì AI chưa phát triển nhanh và mạnh như bây giờ. Mỗi năm thường chỉ có 1 vài paper thật sự đáng chú ý. Mình muốn bắt đầu làm 1 series giới thiệu về các paper kinh điển, đóng góp vào sự phát triển mạnh mẽ của AI như các bạn thấy  ngày nay.
Để mở bát thì mình xin giới thiệu paper đầu tiên: Very Deep Convolutional Networks for Large-Scale Image Recognition. Được công bố vào năm 2014 bởi Visual Geometry Group đến từ đại học Oxford (Các bạn cũng có thể hiểu cái tên VGG được lấy từ đâu rồi đấy 😎). Mô hình được giới thiệu trong paper, còn được biết đến với cái tên VGG16, để phân biệt với 2 version khác là VGG11 và VGG19. VGG16 cũng là á quân của cuộc thi ILSVRC năm 2014 - cuộc thi thường niên nối tiếng diễn ra trong khoảng thời gian từ 2010-2017
VGG16 có những điểm gì nổi bật?
Đây là 1 trong số các mô hình đi tiên phong trong việc sử dụng các Convolution layer với filter có kích thước nhỏ. Điều này giúp cho mô hình tối ưu hóa memory usage, khi đem so sánh với các mô hình tiền nhiệm sử dụng các filter có kích thước lớn
Cho đến ngày nay, dù đã ra mắt được 9 năm, VGG16 vẫn được sử dụng rộng rãi dưới dạng backbone cho các mô hình khác
1 trong số các paper mình và các bạn học phải đọc đi đọc lại rất nhiều lần. Ngày nay thì chúng ta có rất nhiều mô hình tốt hơn, nhưng thời điểm gần 10 năm trở về trước, không có nhiều mô hình có thể vượt mặt VGG16 😎
Link to paper: https://arxiv.org/pdf/1409.1556.pdf
#dl_share","['#sharing', '#deep_learning']","['iconic', 'paper', 'very', 'deep', 'convolutional', 'networks', 'for', 'largescale', 'image', 'recognition', 'vgg16', 'trình làng', 'hi mảng', 'đọc', 'research', 'paper', 'ta', 'vế', 'thời', 'đi', 'học', 'phát triển', '1', 'paper', '1', 'series', 'giới thiệu', 'paper', 'kinh điển', 'đóng góp', 'phát triển', 'mẽ bát', 'giới thiệu', 'paper', 'very', 'deep', 'convolutional', 'networks', 'for', 'largescale', 'image', 'recognition', 'công bố', '2014', 'visual', 'geometry', 'group', 'đại học', 'oxford thể', 'vgg', 'đấy', 'mô hình', 'giới thiệu', 'paper', 'vgg16', 'phân biệt', '2', 'version', 'vgg11', 'vgg19', 'vgg16', 'quân', 'thi', 'ilsvrc', '2014', 'thi niên', 'nối', 'tiếng', 'diễn', '20102017', 'vgg16', 'nổi bật', '1', 'mô hình', 'đi', 'tiên phong', 'convolution', 'layer', 'filter kích thước', 'giúp', 'mô hình', 'tối ưu hóa', 'memory', 'usage', 'đem', 'sánh', 'mô hình', 'tiền nhiệm', 'filter kích thước', 'mắt', '9', 'vgg16', 'rộng rãi', 'dạng', 'backbone', 'mô hình', '1', 'paper học', 'đọc', 'đi đọc', 'ta', 'mô hình', '10', 'trở', 'mô hình thể', 'mặt', 'vgg16', 'link', 'to', 'paper']"
150,"SummaryTools - thay thế hoàn hảo cho hàm describe() của Pandas trên Jupyter Notebook 🔥🔥🔥
Mình thì không phải fan của Jupyter Notebook nhưng cái gì hay thì vẫn phải share 🥲. Chỉ với 1 dòng duy nhất chúng ta sẽ có được 1 bảng tóm tắt dữ liệu đầy đủ và chi tiết 😎
#ds_share",['#sharing'],"['summarytools', 'thay', 'hoàn hảo', 'hàm describe', 'pandas', 'jupyter', 'notebook', 'fan', 'jupyter', 'notebook', 'share', '1', 'dòng', 'ta', '1', 'bảng tóm', 'tắt liệu', 'chi tiết']"
151,"Cho em hỏi bài toán giờ có dataset nhỏ mỗi class chỉ có 5 tấm.
Em có tham khảo phương pháp few-shot dùng protonet ở link: https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch
Nhưng nếu cho unlabelled image mới vào để check class nào thì e k bt dùng nnao. Ai biết cài này cho em hỏi với ạ .-.
#ml #cv","['#Q&A', '#cv', '#deep_learning']","['toán', 'dataset', 'class', '5', 'tham khảo', 'phương pháp', 'fewshot', 'protonet', 'link', 'unlabelled', 'image', 'check', 'class', 'e k', 'bt', 'nnao', 'cài']"
152,"13 Use cases của Large Language Models 🔥🔥🔥
Hi các bạn,
Sau sự bùng nổ của ChatGPT và các mô hình tương tự thì thuật ngữ Large Language Model (LLM) ngày càng trở nên phổ biến. Dưới đây là tổng hợp 13 use case ứng dụng của LLM. Mình tin chắc rằng nó sẽ hữu dụng với các bạn đang học và tìm hiểu về AI, đặc biệt là những bạn theo mảng NLP 😎
Link to pdf: https://drive.google.com/file/d/14CGOi6KY3w6rZiB7Dd-cXNHLkYw3MuVi/view?usp=sharing
#nlp_share #ai_share","['#sharing', '#nlp']","['13', 'use', 'cases', 'large', 'language', 'models', 'hi bùng nổ', 'chatgpt', 'mô hình', 'tương thuật', 'ngữ', 'large', 'language', 'model', 'llm', 'trở', 'phổ biến', 'tổng hợp', '13', 'use', 'case', 'ứng dụng', 'llm', 'hữu dụng', 'học', 'mảng', 'nlp', 'link', 'to', 'pdf']"
153,"Chào cả nhà,
Mình chạy dữ liệu time series dự báo phân loại class 0 và 1 theo ngày. Trong lúc backtest dữ liệu, có những lúc model dự đoán một class nào đó với xác suất 99%. Tuy nhiên, trong lúc chạy vào thực tế thì rất ít thấy model dự đoán một lớp nào đó có xác suất cao giống như vậy, mà nó chỉ dự đoán với xác suất quanh 60%-70%.
Mình nghĩ rằng có thể model của mình bị data leakage nhưng mình kiểm tra thì nó không bị như vậy.
Các cao nhân nào có thể góp ý cho e với ạ. Em cảm ơn!
#ML #DL",['#Q&A'],"['chào', 'chạy liệu', 'time series', 'dự báo', 'phân class', '0', '1', 'backtest liệu', 'model', 'dự đoán', 'class', 'xác suất', '99', 'nhiên', 'chạy', 'model', 'dự đoán', 'lớp', 'xác suất', 'dự đoán', 'xác suất', 'quanh', '60', '70', 'thể', 'model', 'data', 'leakage', 'kiểm tra', 'nhân thể', 'góp', 'e']"
154,"Chào anh Việt và mọi người, mình là Bình. Mình cũng vừa vào nhóm 1 thời gian, hiện mình muốn tìm 1 mentor, đồng đội, hoặc team để học hỏi, cùng học về DS và build model.
Mình chia sẻ chút về mình, background mình là kinh tế, mình có thể sử dụng sql và python. Mình có kinh nghiệm làm web scrping, nên là về việc xử lý thu thập dữ liệu mình cũng tương đối thành thạo.
Mục tiêu tìm mentor và đồng đội là: Cùng học hoặc học hỏi từ bạn (mentor/đồng đội) về DS và build model vì đây là cái mình còn kém, mình muốn học hỏi để tự nâng cao build model cho mình.
Nên hi vọng được kết nối với mọi người.
À dưới đây là 1 package mình đã viết xong dùng để thu thập các dữ liệu liên quan đến chứng khoán theo thời gian thực, ai hứng thú hoặc cũng có mục đích giống mình thì kết nối với nhau nhé. Mình có clip về cách sử dụng và hướng dẫn kết hợp sử dụng trực tiếp trong excel ai muốn xem thì mình nhắn dưới cmt sau nhé.
Lời cuối cảm ơn anh Việt và mọi người đã xem.
#DL_ML_STUDY",['#Q&A'],"['chào', 'việt bình', '1', 'hiện', '1', 'mentor', 'đồng đội', 'team', 'học', 'học', 'ds', 'build', 'model', 'chút', 'background', 'kinh tế thể', 'sql python', 'kinh nghiệm', 'web', 'scrping', 'thu thập liệu', 'tương đối', 'thành thạo', 'mục tiêu', 'mentor', 'đồng đội', 'học', 'học', 'mentor', 'đồng đội', 'ds', 'build', 'model', 'kém', 'học', 'nâng', 'build', 'model', 'hi vọng', 'kết nối', '1', 'package', 'viết', 'xong', 'thu thập liệu', 'chứng khoán', 'thực hứng', 'thú', 'mục đích', 'kết nối', 'clip', 'hướng', 'kết hợp', 'excel', 'nhắn', 'cmt', 'việt']"
155,"Bộ đôi Machine Learning và Deep Learning của nhà grokking🔥🔥🔥
Đây là 2 quyển sách về Machine Learning và Deep Learning vô cùng nổi tiếng của grokking và được đánh giá rất cao về mặt thị giác khi các khái niệm được giải thích vô cùng dễ hiểu bởi các hình ảnh minh họa.
Grokking Machine Learning: https://drive.google.com/file/d/1OAcDZQ-YUyseZAbkgiqIqMSqe0ihB78o/view?usp=sharing
Grokking Deep Learning: https://drive.google.com/file/d/1zxfXMORxzDmtF8zltJC97VRHg-nMG6Kp/view?usp=sharing
Quyển Machine Learning là nhờ bạn Dương Huy Hoàng chia sẻ ở 1 post trước, chứ mình tìm quyển này cũng không nổi 🙏
#ml_share #dl_share",['#sharing'],"['đôi', 'machine', 'learning', 'deep', 'learning', 'grokking', '2', 'quyển', 'sách', 'machine', 'learning', 'deep', 'learning', 'vô', 'nổi tiếng', 'grokking mặt', 'thị giác', 'khái niệm', 'giải', 'vô', 'hình ảnh', 'minh họa', 'grokking', 'machine', 'learning', 'grokking', 'deep', 'learning', 'quyển', 'machine', 'learning dương', 'huy hoàng', '1', 'post', 'quyển', 'nổi']"
156,"20 thuật ngữ phổ biến trong AI 🔥🔥🔥
#ai_share",['#sharing'],"['20', 'thuật ngữ', 'phổ biến']"
157,"Hãy hạn chế sử dụng Juputer Notebook, trừ khi bạn mới làm quen với Python 🙄🙄🙄
Hi các bạn,
Với các bạn đang học và làm việc với Python, chắc các bạn không còn xa lạ gì với Jupyter Notebook - nền tảng giúp các bạn chạy code trên các web browser. Jupyter Notebook thì rất phổ biến và được ưa chuộng bởi sự thuận tiện của mình. Điều này thì không có gì để phải bàn cãi cả 😁
Tuy nhiên, cá nhân mình thì KHÔNG BAO GIỜ dùng Jupyter Notebook (trừ khi mình chấm bài cho các bạn học viên, và các bạn ấy nộp bài trên Jupyter Notebook thì mình buộc phải xài). Mình có thể liệt kê 1 vài lý do ở dưới đây:
Jupyter Notebook được thiết kế theo kiểu Lập trình hướng cấu trúc (Code chạy tuyến tính từ trên xuống dưới), trong khi sau này các bạn đi làm, tất cả các project đều được thiết kế theo huớng Lập trình huớng đối tượng (OOP - các bạn IT thì chắc chắn không còn xa lạ gì với thuật ngữ này)
Các bạn không thể debug với Jupyter Notebook. Các bạn làm các project trên trường hay bài tập hàng tuần thì không nói làm gì. Nhưng sau này các bạn đi làm, vào các project thực sự, code có thể nằm ở hàng chục đến hàng trăm file khác nhau. Không biết cách debug với các IDE không khác gì án tử cho các lập trình viên (Mình không nói riêng gì AI/Data Science đâu nhé, mình đang nói về CNTT nói chung ấy)
Jupyter Notebook rất được ưa chuộng ở các trường đại học cũng như các khoá học (Ngày xưa mình học master các thầy cũng toàn xài Jupyter Notebook). Lý do chính là vì sự tuyến tính từ trên xuống dưới của nó giúp giảng viên dễ minh hoạ từng bước. NHƯNG, các bạn học mãi rồi cũng sẽ phải đi làm. Không biết sử dụng các IDE sẽ là 1 sự thiệt thòi lớn cho các bạn khi so sánh với các candidate khác (Chưa xét về thuật toán hay logic nhé, chỉ nói về code thuần tuý thôi)
Ở tất cả các lớp mình dạy học, mình không bao giờ code bất kì 1 dòng code nào trên Jupyter Notebook, vì mình muốn luyện cho mọi người quen với việc code trên IDE. Mình cũng luôn khuyến khích các bạn học viên hạn chế xài. Tréo ngoe thay thì ở tất cả các lớp, quá 50% học viên của mình luôn nộp bài với file Jupyter Notebook 😢
Mình không có bài xích gì Jupyter Notebook cả. Đây thực sự là 1 nền tảng tuyệt vời. Tuy nhiên nó tuyệt vời ở trường học, và các bạn thì sẽ không ở đó mãi được 😎
#py_advice",['#sharing'],"['hạn chế', 'juputer', 'notebook trừ', 'quen', 'python', 'hi học', 'python', 'lạ', 'jupyter', 'notebook tảng', 'giúp', 'chạy', 'code web', 'browser', 'jupyter', 'notebook', 'phổ biến', 'ưa chuộng', 'thuận tiện', 'bàn', 'cãi nhiên', 'jupyter', 'notebook trừ', 'chấm', 'học viên', 'nộp', 'jupyter', 'notebook', 'buộc', 'xài thể', 'liệt kê', '1', 'lý', 'jupyter', 'notebook', 'thiết kế', 'kiểu', 'lập trình', 'hướng', 'cấu trúc', 'code', 'chạy', 'tuyến', 'đi', 'tất project', 'thiết kế', 'hướng', 'lập trình', 'hướng', 'đối tượng', 'oop', 'it chắn', 'lạ thuật', 'ngữ thể', 'debug', 'jupyter', 'notebook', 'project', 'trường', 'tập', 'hàng', 'tuần', 'đi', 'project thực', 'code thể', 'nằm', 'hàng', 'chục', 'hàng', 'trăm', 'file', 'debug', 'ide', 'án tử', 'lập trình viên', 'data', 'science', 'cntt', 'jupyter', 'notebook', 'ưa chuộng', 'trường', 'đại học', 'khóa học', 'xưa', 'học', 'master', 'thầy', 'toàn', 'xài', 'jupyter', 'notebook lý', 'tuyến', 'giúp', 'giảng viên', 'minh', 'họa học', 'mãi', 'đi', 'ide', '1', 'thiệt thòi', 'sánh', 'candidate', 'xét thuật', 'toán', 'logic', 'code', 'túy', 'tất lớp', 'dạy học', 'code', '1', 'dòng', 'code', 'jupyter', 'notebook luyện', 'quen', 'code', 'ide', 'khuyến khích', 'học viên', 'hạn chế', 'xài', 'tréo ngoe', 'thay', 'tất lớp', '50', 'học viên', 'nộp', 'file', 'jupyter', 'notebook', 'xích', 'jupyter', 'notebook', 'thực', '1', 'tảng', 'tuyệt vời nhiên', 'tuyệt vời', 'trường học', 'mãi']"
158,"em đang code thuật toán cnn1d và đang gặp lỗi này, em đã lên mạng tìm lỗi để sửa nhưng vẫn không được, ai biết lỗi có thể chỉ em sửa được không, em cám ơn rất nhiều ạ. đây là link colab nguyên bài code của em https://colab.research.google.com/drive/1akRLuK9qQy28hs-_zf4w4_nRoAn_BXmC?usp=drive_link
#dl
#cnn1d
#hoidap",['#Q&A'],"['code', 'thuật toán', 'cnn1d', 'lỗi', 'mạng', 'lỗi', 'sửa', 'lỗi thể', 'sửa', 'cám ơn', 'link', 'colab', 'nguyên', 'code']"
159,"Em đang định làm về Face Detection, thay vì theo hướng Feature-based thì em muốn thử về Image-based, với YOLO. Và em search thấy có quá nhiều biến thể của YOLO. Có nên cứ bản mới mà đóng vào không ạ?
#py #yolo","['#Q&A', '#cv', '#deep_learning']","['định', 'face', 'detection', 'thay', 'hướng', 'featurebased', 'thử', 'imagebased', 'yolo', 'search', 'biến thể', 'yolo', 'đóng']"
160,"Giáo trình và hướng dẫn giải bài tập Xác suất thống kê của Bách Khoa Hà Nội 🔥🔥🔥
Mình xin chia sẻ với các bạn 2 quyển sách mình từng học ở học kì thứ 3 tại đại học Bách Khoa Hà Nội. Nhờ 2 quyển sách này mà sau này khi học về Data Science và Machine Learning, mình gần như không phải ôn lại kiến thức Toán ☺️
Link to pdf: https://drive.google.com/drive/folders/1apDeebDLjsWtdrjqD7O1d3isYeel3Uv5?usp=sharing
#math_share","['#sharing', '#math']","['giáo trình', 'hướng', 'giải tập', 'xác suất', 'thống kê', 'bách khoa', 'hà nội', '2', 'quyển', 'sách học', 'học kì', '3', 'đại học', 'bách khoa', 'hà nội', '2', 'quyển', 'sách', 'học', 'data', 'science', 'machine', 'learning ôn', 'kiến thức', 'toán', 'link', 'to', 'pdf']"
161,"Em chào anh Việt và mọi người. Hiện tại công ty có cung cấp cho em một máy chủ có GPU và một bộ data có khoảng 500k ảnh của 100k người khác nhau. Em đang dùng một model face recognition để training. Nhưng với bộ data như thế thì train rất lâu. Mọi người cho em hỏi có cách nào để tối ưu khi training như vậy không ạ. Em cảm ơn.
#ml
#dl
#cv","['#Q&A', '#cv']","['chào việt', 'công ty', 'cung máy', 'chủ', 'gpu', 'data', '500', 'k', 'ảnh', '100', 'k', 'model', 'face', 'recognition', 'training', 'data', 'train', 'tối ưu', 'training']"
162,"Fix các lỗi liên quan đến Medium 🔥🔥🔥
Các bạn ơi,
Trong thời gian vừa qua mình có chia sẻ 1 vài post có nguồn từ Medium, bao gồm:
Gần 300 project Machine Learning với sample code bằng Python (https://www.facebook.com/groups/dsmlvietnam/permalink/317877850992343/?mibextid=oMANbw)
180 Data Science + Machine Learning project với code bằng Python đi kèm với giải thích (https://www.facebook.com/groups/dsmlvietnam/permalink/325498813563580/?mibextid=oMANbw)
60 project Python với source code đi kèm (https://www.facebook.com/groups/dsmlvietnam/permalink/325506116896183/?mibextid=oMANbw)
Trong quá trình chia sẻ, mình mắc 1 vài lỗi sau:
Chia sẻ link Medium mà không biết rằng ở Việt Nam bị chặn
Chia sẻ file pdf của article nhưng không check lại là các link không click vào được (post đầu tiên ok nên 2 post sau mình làm tương tự mà không biết rằng có lỗi này, cho đến khi các bạn nhắc)
Mình rất xin lỗi mọi người về sự bất tiện này. Mình đã update lại tất cả link rồi. Giờ các bạn có thể download file pdf ở cuối mỗi post là có thể truy cập vào từng project thông qua các link trong bài viết rồi nhé. Again, sorry for any inconvenience 🙏🙏🙏
Mình thấy có bạn gợi ý là các bạn nếu muốn đọc article có thể paste link vào đây: https://freedium.cfd/ Trick khá hay mình không biết đến 😁
Trong mấy hôm tới mình sẽ chia sẻ thêm 1 vài bài tổng hợp các project mà mình thấy hữu ích trên Medium ☺️
Btw, Rule cũ vẫn áp dụng bình thường nhé các bạn. Bài post nào mà trong 12 giờ các bạn chưa được ai giúp đỡ thì các bạn luôn có thể mention mình nhé 😎
#fix_error",['#sharing'],"['fix', 'lỗi', 'medium', '1', 'post', 'medium', 'bao', '300', 'project', 'machine', 'learning', 'sample', 'code', 'python', '180', 'data', 'science', 'machine', 'learning', 'project', 'code', 'python', 'đi', 'kèm', 'giải', '60', 'project', 'python', 'source', 'code', 'đi', 'kèm', 'trình', 'mắc', '1', 'lỗi', 'link', 'medium', 'việt nam', 'chặn', 'file', 'pdf', 'article', 'check', 'link', 'click', 'post', 'ok', '2', 'post', 'tương lỗi', 'nhắc', 'lỗi', 'bất tiện', 'update', 'tất', 'link thể', 'download', 'file', 'pdf', 'post thể', 'truy cập', 'project', 'thông link', 'viết', 'again', 'sorry', 'for', 'any', 'inconvenience gợi', 'đọc', 'article thể', 'paste', 'link', 'https', 'freedium', 'cfd', 'trick', 'mấy', 'hôm', '1', 'tổng hợp', 'project', 'hữu ích', 'medium', 'btw', 'rule', 'cũ', 'áp dụng', 'bình', 'post', '12', 'giúp đỡ thể', 'mention']"
163,"Spearman correlation - Sự thay thế tuyệt vời dành cho Pearson correlation 😎😎😎
Hi các bạn,
Với những ai học về Data Science/Machine Learning, chắc các bạn không còn xa lạ gì với Pearson correlation coefficient - hệ số tương quan Pearson - dùng để đánh giá mối quan hệ tuyến tính giữa 2 biến.
Pearson correlation thì quá phổ biến và có rất nhiều framework như Pandas, scipy hay numpy đều có các hàm riêng để tính giá trị này ...
... TUY NHIÊN, Pearson correlation KHÔNG có khả năng đánh giá tính đơn điệu trong mối quan hệ giữa 2 biến (bao gồm cả tuyến tính và phi tuyến)
Lúc này, ta cần 1 metric tốt hơn để có thể đo lường được mối quan hệ này. Và 1 trong số đó là Spearman correlation coefficient - hệ số tương quan Spearman. Hình bên dưới minh họa sự khác biệt giữa 2 hệ số này. Một cách tóm tắt:
Pearson và Spearman correlation giống nhau với các mối quan hệ tuyến tính.
Spearman ước lượng tốt mối quan hệ đơn điệu (nhưng phi tuyến) giữa các biến, trong khi Pearson đánh giá thấp mối quan hệ này
Pearson thì chắc chắn là nổi tiếng hơn rât nhiều Spearman. Nhưng về sự hữu ích thì, well, you have your own assessment 😎
#ds_tip","['#sharing', '#python', '#machine_learning']","['spearman', 'correlation', 'thay', 'tuyệt vời', 'pearson', 'correlation', 'hi học', 'data', 'science', 'machine', 'learning', 'lạ', 'pearson', 'correlation', 'coefficient hệ', 'tương quan', 'pearson', 'quan hệ', 'tuyến', '2', 'biến', 'pearson', 'correlation', 'phổ biến', 'framework', 'pandas', 'scipy', 'numpy', 'hàm nhiên', 'pearson correlation', 'khả năng', 'đơn điệu', 'quan hệ', '2', 'biến', 'bao', 'tuyến', 'phi', 'tuyến', 'ta', '1', 'metric thể', 'đo lường', 'quan hệ', '1', 'spearman', 'correlation', 'coefficient hệ', 'tương quan', 'spearman', 'hình minh', 'họa biệt', '2', 'hệ', 'tóm tắt', 'pearson', 'spearman', 'correlation', 'quan hệ', 'tuyến', 'spearman ước', 'quan hệ', 'đơn điệu', 'phi', 'tuyến', 'biến pearson', 'quan hệ', 'pearson chắn', 'nổi tiếng', 'rât spearman', 'hữu ích', 'well', 'you', 'have', 'your', 'own', 'assessment']"
164,"Cuộc đua về mô hình ngôn ngữ lớn lại tiếp tục thú vị hơn khi Google mới cho ra mắt Gemini, đối thủ nặng kí cho ChatGPT.
#nlp_share",['#sharing'],"['đua', 'mô hình', 'ngôn ngữ', 'thú vị', 'google', 'mắt', 'gemini', 'đối thủ kí', 'chatgpt']"
165,"Mình lấy table trên wiki về, trong table có giá trị âm, biểu thị bằng hình ảnh mũi tên. Bây giờ lấy về data frame chỉ nhận giá trị số, bị sai về mặt âm dương, xin admin và các bạn chút kinh nghiệm xử lý đoạn này.
#data, #python","['#Q&A', '#data']","['table', 'wiki', 'table', 'âm biểu thị', 'hình ảnh', 'mũi', 'data', 'frame', 'sai mặt', 'âm dương', 'admin chút', 'kinh nghiệm', 'đoạn']"
166,"9 thư viện Python dành cho Generative AI 🔥🔥🔥
Hi các bạn,
Dưới đây là tổng hợp các thư viện trong Python giúp chúng ta xây dựng và sử dụng các mô hình Generative AI, bao gồm:
Tensorflow 
Pytorch 
Transformers 
JAX 
Diffusers 
LangChain 
LIama Index 
W&B 
Acme 
3 cái tên đầu tiên thì đã quá quen thuộc rồi phải không các bạn 😎 
#dl_share
Link to pdf: https://drive.google.com/file/d/1zS118ENDHQOOPzO2O1UOnWyUJ1uInlaR/view?usp=sharing","['#sharing', '#python']","['9', 'thư viện', 'python', 'generative', 'hi tổng hợp', 'thư viện', 'python', 'giúp', 'ta', 'xây dựng', 'mô hình', 'generative', 'bao', 'tensorflow', 'pytorch', 'transformers', 'jax', 'diffusers', 'langchain', 'liama', 'index', 'w', 'b', 'acme', '3', 'quen', 'link', 'to', 'pdf']"
167,"Hi mọi người. E dag code bài toán fashion classification vs model VGG19. Mà tới chỗ này e bị lỗi mà fix ko dc. Mong mn giải thích vs chỉ giúp em vs ạ. Em cảm ơn nhiều
#CVs","['#Q&A', '#cv', '#deep_learning']","['hi e', 'dag', 'code toán', 'fashion', 'classification', 'vs', 'model', 'vgg19', 'chỗ', 'e', 'lỗi', 'fix', 'ko', 'dc', 'mong', 'mn', 'giải', 'vs', 'giúp', 'vs']"
168,"[EM NÊN MUA LAPTOP NÀO ĐỂ HỌC AI ạ?]
Dạ em đang tìm hiểu mua 1 chiếc laptop mới 20 củ trở xuống ạ. Em đang phân vân giữa việc chọn :
- 1 chiếc laptop có GPU NVidia thì khối lượng sẽ nặng, và cũng đắt tiền (thầy em bảo có thì sẽ thuận tiện, chủ động hơn)
- 1 chiếc nhẹ, thuận tiện (vì em đeo nặng thấy dễ đau lưng lắm ạ) (em đang dùng hp folio 9480 )
Mong anh chị cho em lời khuyên và gợi ý cho em 1 số laptop ạ
#laptop
#AI_study",['#Q&A'],"['mua', 'laptop', 'học', 'mua', '1', 'laptop', '20', 'củ', 'trở', 'phân vân', '1', 'laptop', 'gpu', 'nvidia', 'khối', 'đắt', 'tiền', 'thầy', 'bảo', 'thuận tiện', 'chủ động', '1', 'nhẹ', 'thuận tiện', 'đeo', 'đau', 'lưng', 'lắm', 'hp', 'folio', '9480', 'mong', 'khuyên', 'gợi', '1', 'laptop']"
169,"#DL_CV_Laptop
Em chào mọi người ạ, 
Hiện tại em đang tìm kiếm 1 chiếc laptop phù hợp với budget của em khoảng 15 triệu đổ xuống và phục vụ cho AI (computer vision sau này) thì em nên mua với cấu hình như thế nào thì hợp lý ạ?
Em có tìm hiểu vài dòng và đang phân vân giữa dell precision 5530 và vài chiếc gaming có thông số cụ thể là :
Dell 5530: CPU: i7-8850H CPU @ 2.60GHz (12 CPUs), ~2.6GHz, RAM: 16GB DDR4 Buss 2666MHz, SSD: 512GB, VGA: Intel UHD Graphics 630 + NVIDIA Quadro P1000- 4G
Gaming HP victus 15 2023: CPU Ryzen 5 – 7535HS, Ram 8GB, SSD 512 GB, RTX 2050 (4GB)
Lenovo ideapad gaming3: Ryzen 5-7535HS, 8GB, 512GB, RTX 2050 4GB
MSI Gaming GF63 Thin 11SC: CPU i5- 11400H/8GB/512GB/4GB GTX1650
Mọi người cho em tư vấn với các con máy trên hoặc 1 con máy bất kì khác trong cùng tầm giá với ạ
Em cảm ơn mn nhiều.",['#Q&A'],"['chào', 'kiếm', '1', 'laptop', 'budget', '15', 'triệu', 'đổ', 'phục vụ', 'computer', 'vision', 'mua', 'cấu hình', 'hợp lý', 'dòng', 'phân vân', 'dell', 'precision', '5530', 'gaming', 'thông dell', '5530', 'cpu', 'i78850h', 'cpu', '2', '60', 'ghz', '12', 'cpus', '2', '6', 'ghz', 'ram', '16', 'gb', 'ddr4', 'buss', '2666', 'mhz', 'ssd', '512', 'gb', 'vga', 'intel', 'uhd', 'graphics', '630', 'nvidia', 'quadro', 'p1000', '4', 'g', 'gaming', 'hp', 'victus', '15', '2023', 'cpu', 'ryzen', '5', '7535', 'hs', 'ram', '8', 'gb', 'ssd', '512', 'gb', 'rtx', '2050', '4', 'gb', 'lenovo', 'ideapad', 'gaming3', 'ryzen', '57535', 'hs', '8', 'gb', '512', 'gb', 'rtx', '2050', '4', 'gb', 'msi', 'gaming', 'gf63', 'thin', '11', 'sc', 'cpu', 'i5', '11400', 'h', '8', 'gb', '512', 'gb', '4', 'gb', 'gtx1650', 'tư vấn', 'máy', '1', 'máy', 'tầm', 'giá', 'mn']"
170,"Chào mọi người,
Em sắp làm luận văn về điểm danh sinh viên, mọi người cho em hỏi em có thể sử dụng YOLO8 để nhận dạng và điểm danh sinh viên được không ạ ? Với mình có thể sử dụng tập dữ liệu nào để train mô hình này trước khi train với dữ liệu thực tế
Em xin chân thành cám ơn ạ !
#ml #face_recognition #YOLO","['#Q&A', '#deep_learning', '#cv']","['chào luận', 'văn danh', 'sinh viên', 'thể', 'yolo8', 'dạng', 'danh', 'sinh viên thể', 'tập liệu', 'train', 'mô hình', 'train liệu', 'chân thành', 'cám ơn']"
171,"Chào mọi người. Mình mới viết xong con chatbot để hỗ trợ cho việc trading chứng khoán (Chủ yếu là học thêm). Hiện con bot có thể làm nhiều chức năng như tìm motif pattern, tìm support resistance, cảnh báo, tạo watchlist, tóm tắt 1 ý tưởng từ voice...
Hiện mn có thể sử dụng con bot tại https://t.me/mrzaizai2k_bot
Mong mọi người giành chút thời gian xem qua con bot mình trên github. Nếu có gì chưa ổn, mn góp ý giúp mình. Nếu thấy hay, mình xin mn 1 star lấy hên nhé!
https://github.com/mrzaizai2k/stock_price_4_fun
#hoidap #chatbot #sideproject #","['#sharing', '#nlp']","['chào', 'viết', 'xong', 'chatbot', 'trading chứng khoán', 'chủ yếu', 'học', 'hiện', 'bot thể', 'chức năng', 'motif', 'pattern', 'support', 'resistance', 'cảnh báo', 'watchlist', 'tóm tắt', '1', 'tưởng', 'voice', 'hiện', 'mn thể', 'bot mong', 'giành', 'chút', 'bot', 'github ổn', 'mn', 'góp', 'giúp', 'mn', '1', 'star', 'hên']"
172,"Tip ít người biết đến khi trực quan hoá dữ liệu 🔥🔥🔥
Hi các bạn,
Khi các bạn trực quan hoá dữ liệu, phần lớn sẽ sử dụng Matplotlib hay các thư viện có liên quan. Đôi khi sẽ có những khu vực trong biểu đồ mà chúng ta muốn người xem chú ý. Vậy lúc đó chúng ta sẽ phải làm như thế nào?
Câu trả lời là hàm indicate_inset_zoom(). Các bạn có thể thấy tác dụng như hình dưới đây 😎
#ds_share
P/s: Mình cũng không biết đến tip này 😅","['#sharing', '#data']","['tip', 'trực quan', 'hóa liệu', 'hi trực quan', 'hóa liệu', 'matplotlib', 'thư viện', 'đôi', 'khu vực', 'biểu đồ', 'ta', 'ta', 'câu', 'hàm', 'indicate_inset_zoom thể', 'tác dụng', 'hình p', 's', 'tip']"
173,"Hi anh Việt và mọi người. Em đang gặp khó khăn ở chỗ đọc file .lvm mong mọi người giúp đỡ. Chuyện là em tạo 1 environment bằng conda và cài các thư viện vào đó, những thư viện như numpy, pandas, matplotlib thì đều bình thường nhưng đến cài lvm-read thì khi em gõ pip install lvm-read ở terminal vẫn tải được, nhưng ở trên code thì nó hiện như vầy.
Anh/ chị nào có kinh nghiệm đọc file .lvm có thể chỉ em trường hợp này không ạ ?
Em xin cảm ơn rất nhiều ạ.
P/s: Ảnh 1 là lỗi, ảnh 2 là terminal báo thư viện lvm-read đã được tải
#py_code #ds_code","['#Q&A', '#python']","['hi việt', 'khăn', 'chỗ', 'đọc', 'file', 'lvm', 'mong', 'giúp đỡ', '1', 'environment conda', 'cài', 'thư viện', 'thư viện', 'numpy', 'pandas', 'matplotlib bình', 'cài', 'lvmread', 'gõ', 'pip', 'install', 'lvmread', 'terminal tải', 'code', 'hiện vầy', 'kinh nghiệm', 'đọc', 'file', 'lvm thể', 'trường hợp', 'p', 's', 'ảnh', '1', 'lỗi', 'ảnh', '2', 'terminal', 'báo', 'thư viện', 'lvmread tải']"
174,"Xin phép anh Việt Nguyễn và mọi người
Hôm trước em có tải CUDA bản 12.3 và CuDNN. Em đã chạy được GPU trên pytorch nhưng với tensorflow thì không được. 
Bản tensorflow em tải là 2.15. Em có xem trên phần pip của tensorflow chỗ environment thì thấy nó chỉ hỗ trợ bản CUDA 11.8 còn trên trang tensorflow blog thì nó ghi là hỗ trợ 12.2
Thế tức là giờ em không thể dùng được GPU trên tensorflow đúng không ạ. Bản thân em có test trên colab thì tensorflow vẫn nhận được GPU còn trên VSC thì không nhận được.
Em xin cảm ơn mn ạ.

Link pip: https://pypi.org/project/tensorflow/
Link blog: https://blog.tensorflow.org/2023/11/whats-new-in-tensorflow-2-15.html?hl=vi

#cuda #cudnn","['#Q&A', '#python']","['phép', 'việt', 'nguyễn', 'hôm tải', 'cuda', '12', '3', 'cudnn', 'chạy', 'gpu', 'pytorch', 'tensorflow', 'tensorflow tải', '2', '15', 'pip', 'tensorflow', 'chỗ', 'environment', 'cuda', '11', '8', 'trang', 'tensorflow', 'blog', 'ghi', '12', '2', 'tức thể', 'gpu', 'tensorflow thân', 'test', 'colab', 'tensorflow', 'gpu', 'vsc', 'mn', 'link', 'pip', 'https', 'pypi', 'org', 'project', 'tensorflow', 'link', 'blog']"
175,"Anh chị cho em hỏi là giờ muốn theo mảng data ở VN thì nên theo DS, DE, DA,.. Hay mảng nào khác ạ? Với cho em hỏi thêm là bản thân em đang là sinh viên năm 2 ngành Khoa học máy tính, em đang muốn tìm 1 mảng để học sâu vào rồi đi thực tập, mảng nào em cũng tìm hiểu 1 ít, nhưng vẫn k biết bản thân hợp với cái nào, anh chị cho em xin ít lời khuyên ạ. Em cảm ơn ạ!
#career",['#Q&A'],"['mảng', 'data', 'vn', 'ds', 'de', 'da', 'mảng', 'thân', 'sinh viên', '2', 'ngành', 'khoa học', 'máy', '1', 'mảng', 'học', 'sâu', 'đi', 'thực tập', 'mảng', '1', 'k', 'thân hợp', 'khuyên']"
176,"#dl_cv
Chào mọi người em đang train yolo, thì hiện tại mAP không thấy lên mà cứ dao động 0.86, cho em hỏi làm thế nào để cải thiện mAP lên cao hơn nữa ạ. Data train hiện tại tầm 3k hình ạ","['#Q&A', '#deep_learning']","['chào', 'train', 'yolo', 'map', 'dao động', '0', '86', 'cải thiện', 'map', 'data', 'train', 'tầm', '3', 'k', 'hình']"
177,"[DS Tip] Hãy chú ý khi sử dụng Correlation để đánh giá mối quan hệ tuyến tính giữa 2 biến 🔥🔥🔥
Hi các bạn,
Với những bạn học hay làm về Data Science, có lẽ các bạn không còn lạ gì khái niệm tương quan (correlation). Nói 1 cách đơn giản thì tương quan thể hiện mối quan hệ tuyến tính có thể tồn tại giữa 2 biến. Hệ số tương quan mà càng gần 1 hoặc -1 thì mối quan hệ tuyến tính càng mạnh, còn nếu hệ số tương quan gần 0 thì 2 biến có mối quan hệ tuyến tính rất yếu
TUY NHIÊN, tương quan có 1 nhược điểm rất lớn, đó là bị ảnh hưởng mạnh bởi outlier. Như các bạn có thể nhìn thấy ở trong 2 hình phía dưới, chỉ với việc thêm vào 2 outlier, chúng ta đã thấy hệ số tương quan thay đổi rất đột ngột, 2 biến đang từ có mối quan hệ tuyến tính mạnh (đúng) trở thành quan hệ tuyến tính yếu (sai)
Do đó lời khuyên dành cho chúng ta là, đừng lúc nào cũng chăm chăm nhìn vào số liệu, mà hãy nhìn vào cả dữ liệu nữa. Bằng việc trực quan hóa dữ liệu và nhìn vào phân bố của chúng, điều đó sẽ cứu chúng ta khỏi việc đưa ra những kết luận sai lầm 🥰
#ds_tip
P/s: Cái này mình cũng mới biết 😅",['#sharing'],"['ds', 'tip', 'correlation', 'quan hệ', 'tuyến', '2', 'biến', 'hi học', 'data', 'science lẽ', 'lạ', 'khái niệm', 'tương quan', 'correlation', '1', 'đơn giản', 'tương quan', 'thể hiện', 'quan hệ', 'tuyến thể', 'tồn', '2', 'biến hệ', 'tương quan', '1', '1', 'quan hệ', 'tuyến', 'hệ', 'tương quan', '0', '2', 'biến', 'quan hệ', 'tuyến', 'yếu nhiên', 'tương quan', '1', 'nhược', 'ảnh hưởng', 'outlier thể', '2', 'hình', '2', 'outlier', 'ta', 'hệ', 'tương quan', 'đột ngột', '2', 'biến', 'quan hệ', 'tuyến', 'quan hệ', 'tuyến', 'yếu', 'sai', 'khuyên', 'ta', 'đừng', 'chăm', 'chăm liệu liệu', 'trực quan', 'hóa liệu', 'phân bố', 'cứu', 'ta', 'kết luận', 'sai lầm', 'p', 's']"
178,"Series bài giảng về Deep Learning của DeepMind và UCL centre 🔥🔥🔥
Trước khi nói về bài giảng, mình muốn giới thiệu qua 1 chút: DeepMind là ai?
Họ là 1 startup về AI được thành lập vào năm 2010. DeepMind cùng với OpenAI là 2 công ty có rất nhiều thành tựu trong AI, đặc biệt là trong mảng học tăng cường (Reinforcement Learning). Nếu vào những năm 2018, OpenAI đã đi vào lịch sử khi trình làng OpenAI Five - 5 mạng nơ ron và đánh dấu cột mốc khi lần đầu tiên AI có thể đánh bại con người ở 1 tựa game MOBA (DOTA2), thì trước đó 2 năm, DeepMind với AlphaGo cũng tạo nên tên tuổi của mình khi chiến thắng 1 đại kiện tướng cờ vây chuyên nghiệp. Hiện tại DeepMind đang thuộc quyền sở hữu của Google 😎
Quay trở lại với nội dung chính. Series bài giảng này bao gồm 12 video, mỗi video kéo dài khoảng 1 tiếng rưỡi cover tất cả các topic cần thiết để các bạn có thể nắm được các kiến thức cơ bản và nâng cao về Deep Learning. Mỗi 1 lecture sẽ được phụ trách bởi 1 speaker khác nhau, nhưng các bạn yên tâm nhé, họ nói khá chậm và rõ. Series này đã được cho ra mắt 3 năm trước, nhưng không hề lỗi thời với thời điểm hiện tại 😁
Link to series: https://youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&si=dwiixBgcCQHQESwM
#dl_share","['#sharing', '#deep_learning']","['series', 'giảng', 'deep', 'learning', 'deepmind', 'ucl', 'centre', 'giảng', 'giới thiệu', '1', 'chút', 'deepmind', '1', 'startup', 'thành lập', '2010', 'deepmind', 'openai', '2', 'công ty', 'thành tựu', 'mảng', 'học cường', 'reinforcement', 'learning', '2018', 'openai', 'đi', 'lịch sử', 'trình', 'làng', 'openai', 'five', '5', 'mạng', 'nơ ron', 'đánh dấu', 'cột', 'mốc thể', 'đánh bại', '1', 'tựa', 'game', 'moba', 'dota2', '2', 'deepmind', 'alphago', 'chiến thắng', '1', 'đại kiện', 'tướng', 'cờ vây', 'chuyên nghiệp', 'deepmind', 'quyền sở hữu google', 'trở', 'nội dung', 'series', 'giảng', 'bao', '12', 'video', 'video', 'kéo', '1', 'tiếng', 'rưỡi', 'cover', 'tất topic', 'thiết thể', 'nắm', 'kiến thức', 'nâng', 'deep', 'learning', '1', 'lecture', 'phụ trách', '1', 'speaker', 'yên tâm', 'chậm', 'series', 'mắt', '3', 'hề', 'lỗi thời', 'link', 'to', 'series']"
179,"[Computer Vision project - Sign language]
Hello mn, mình đang muốn làm 1 project về ngôn ngữ ký hiệu Việt Nam. Model sẽ lấy input là những video của người sử dụng ngôn ngữ ký hiệu, sau đó dịch ra tiếng việt và tiếng anh theo thời gian thực.
Vấn đề là mình chưa tìm được data để train model. Website duy nhất mình tìm thấy là https://m.tudienngonngukyhieu.com/, nhưng cũng k có API để lấy data về.
Không biết mn đã ai từng làm project tương tự và đã tìm được nguồn data, có thể share giúp mình được k? Cám ơn mn.
(Ảnh chống trôi)
#cv","['#Q&A', '#cv']","['computer', 'vision', 'project', 'sign', 'language', 'hello', 'mn', '1', 'project', 'ngôn ngữ', 'ký hiệu', 'việt nam', 'model', 'input video', 'ngôn ngữ', 'ký hiệu', 'dịch', 'tiếng', 'việt', 'tiếng', 'thực data', 'train', 'model', 'website', 'https', 'm', 'tudienngonngukyhieu', 'com', 'k', 'api', 'data', 'mn', 'project', 'tương data', 'thể', 'share', 'giúp', 'k', 'cám ơn', 'mn ảnh', 'chống', 'trôi']"
180,"Chào mọi người, cho mình hỏi
Mình đang làm 1 project về phân loại rác xong gửi qua cho Robot thông qua Modbus TCP/IP, mình dùng pyinstall để chuyển về window app nhưng khi mở lên chỉ thấy giao diện chứ ko hoạt động. Có vẻ file đóng gói ko có đủ thư viện cần thiết để chạy. Dưới đây là GUI chạy trong Pycharm
#yolov5s
#pyinstaller","['#Q&A', '#deep_learning', '#cv']","['chào', '1', 'project', 'phân', 'rác', 'xong', 'gửi', 'robot', 'thông modbus', 'tcp', 'ip', 'pyinstall', 'window', 'app', 'giao diện', 'ko', 'hoạt động', 'vẻ', 'file', 'đóng gói', 'ko', 'thư viện', 'thiết', 'chạy', 'gui', 'chạy', 'pycharm']"
181,"e hỏi AI về chuyên ngành nào của CNTT khó nhất và nó trả lời như thế này, K biết có đúng k ạ
#code",['#Q&A'],"['e', 'chuyên ngành', 'cntt', 'k', 'k']"
182,"Chào mn, do em mới tập tành và học nên cũng không biết xử lí, hiện em muốn nhờ mn hướng dẫn em một chút cơ bản. Em xin cảm ơn nhiều ạ
chuyển cột join_date về dạng yyyy/mm/dd 
cột mobiles về dạng 84.....
#py_study
#py_code","['#Q&A', '#python', '#data']","['chào', 'mn', 'tập tành', 'học', 'xử lí', 'hiện', 'mn', 'hướng', 'chút', 'cột', 'join_date', 'dạng', 'yyyy', 'mm', 'dd', 'cột', 'mobiles', 'dạng', '84']"
183,"Khóa NLP của đại học Texas 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn khóa CS388: Natural Language Processing đến từ đại học Texas. Theo giới thiệu thì khóa học dành cho các bạn ở level Master, nhưng theo đánh giá của cá nhân mình thì các bạn ở bậc Bachelor nếu đã học qua các môn Toán đại cương thì cũng hoàn toàn có thể theo được 😁 Khóa học sẽ cover các chủ đề sau:
Giới thiệu về NLP 
Linear Classification
Word Embedding
Language Modeling và Self-Attention
Transformers và Decoding
Modern Large Language Models 
Machine Translation
Summarization 
Video lecture: https://www.youtube.com/playlist?list=PLofp2YXfp7TZZ5c7HEChs0_wfEfewLDs7
Course material: https://www.cs.utexas.edu/~gdurrett/courses/online-course/materials.html
(Các bạn có thể download slide và note của khóa học ở đường link thứ 2 nhé 😎)
#nlp_share","['#sharing', '#nlp']","['khóa', 'nlp', 'đại học', 'texas', 'hi giới thiệu', 'khóa', 'cs388', 'natural', 'language', 'processing', 'đại học', 'texas', 'giới thiệu', 'khóa', 'học', 'level master', 'bậc', 'bachelor học', 'môn toán', 'đại cương thể', 'khóa học', 'cover', 'chủ đề', 'giới thiệu', 'nlp', 'linear', 'classification', 'word', 'embedding', 'language', 'modeling', 'selfattention', 'transformers', 'decoding', 'modern', 'large', 'language', 'models', 'machine', 'translation', 'summarization', 'video', 'lecture', 'course', 'material thể', 'download', 'slide', 'note', 'khóa', 'học đường', 'link', '2']"
184,"Awesome-NLP: Tổng hợp tất cả các tài liệu, tin tức, thư viện về NLP 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 nguồn tổng hợp tất tần tật những gì các bạn cần biết về NLP, bao gồm tài liệu, thư viện, dataset, tin tức và thậm chí là các nghiên cứu. Với cá nhân mình, có 2 phần mình chú ý nhất trong danh sách này, bao gồm:
Các dataset
Các thư viện NLP dành riêng cho các ngôn ngữ cùng với các dataset dành cho ngôn ngữ đó (có cả tiếng Việt của chúng ta các bạn nhé 😎)
Link: https://github.com/keon/awesome-nlp
1 nguồn rất tuyệt vời cho các bạn theo hướng NLP 🥰
#nlp_share","['#sharing', '#nlp']","['awesomenlp', 'tổng hợp', 'tất tài liệu', 'tức', 'thư viện', 'nlp', 'hi', 'giới thiệu', '1', 'tổng hợp', 'nlp', 'bao', 'tài liệu', 'thư viện', 'dataset', 'tức chí', 'nghiên cứu', '2', 'danh sách', 'bao dataset', 'thư viện', 'nlp', 'ngôn ngữ', 'dataset ngôn ngữ', 'tiếng', 'việt', 'ta', 'link', '1', 'tuyệt vời', 'hướng', 'nlp']"
185,"Chào anh Việt và mọi người trong nhóm
Em đang học về DL và muốn train model bằng GPU. Em có tìm hiểu và đã tải được Cuda Toolkit 12.3 và CuDNN tương thích với nó. Bản thân em cũng đã copy các file từ CuDNN vào Cuda và cũng đã cài đặt các biến môi trường để trỏ đến vị trí cuDNN.
Em có xem 1 số tài liệu bảo rằng sau bước này thì cần cài đặt thêm Visua Studio. Nhưng cần cài những gì trong đấy thì em cũng không rõ lắm (có chỗ bảo cần cài hết trong Visual Studio)
Em mong mọi người cho em 1 số hướng dẫn . Hiện tại thì em không biết có nên tải Visual Studio không và nếu tải thì cần bao nhiêu.
Em cảm ơn mọi người.
#cuda #cudnn",['#Q&A'],"['chào', 'việt', 'học', 'dl', 'train', 'model', 'gpu tải', 'cuda', 'toolkit', '12', '3', 'cudnn', 'tương thân', 'copy', 'file', 'cudnn cuda', 'cài biến', 'môi trường', 'trỏ', 'cudnn', '1', 'tài liệu', 'bảo cài', 'visua studio', 'cài', 'đấy', 'lắm', 'chỗ', 'bảo', 'cài', 'visual', 'studio', 'mong', '1', 'hướng', 'tải', 'visual', 'studio tải']"
186,"[Hỏi đáp - Tự học - Framework & pp phân tích]
Em chào cả nhà ạ,
Em tự học DA, học dùng tools cơ bản, tuy nhiên e có thắc mắc Khi em xem các project trên mạng, thì thường các project sẽ chọn 1 topic cụ thể để đi sâu trl: credit scoring, bank turnover,...
em không biết thực tế tại doanh nghiệp, DN có xu hướng trl 1 bài toàn như trên hay sẽ đi mining, tìm insight? về nếu tìm insight,  em lại k biết có phương pháp nào chuẩn để khám phá dữ liệu mà k sót insight nào. Vì thế em không biết phát triển và luyện tập project theo hướng nào mới đúng ạ.
Mong các anh chị chia sẻ với em, e tự học nên hơi mơ hồ không có người để hỏi ạ. Em cảm ơn cả nhà nha
#da_selfstudy","['#Q&A', '#data']","['đáp', 'học', 'framework pp', 'phân tích', 'chào học', 'da học', 'tools nhiên', 'e', 'thắc mắc', 'project', 'mạng', 'project', '1', 'topic', 'đi sâu', 'trl', 'credit', 'scoring bank', 'turnover', 'doanh nghiệp', 'dn', 'xu hướng', 'trl', '1', 'toàn', 'đi', 'mining', 'insight', 'insight', 'k', 'phương pháp', 'chuẩn', 'khám phá liệu', 'k sót', 'insight', 'phát triển', 'luyện tập', 'project', 'hướng', 'mong', 'e học', 'hơi', 'mơ hồ', 'nha']"
187,"Em chào mọi người ạ. Em đang rất bế tắc, mong được mọi người hướng dẫn em trong việc xử lý data trước khi train model MLP.
Đây là data thô của em: https://docs.google.com/spreadsheets/d/1t5MKnBi__W8qSDahVvA6k0JoZtH3rB4_/edit#gid=1714034122 
Tóm tắt của yêu cầu này là: người dùng sẽ nhập chỉ số Glutest và Weight, sau đó máy sẽ đưa ra giá trị phù hợp của 4 loại chỉ số dinh dưỡng.
Xin nhờ mn hướng dẫn em hướng để tiền xử lý data ạ. Em cảm ơn mọi người nhiều.
Em có dùng lệnh để vẽ histogram cho từng cột trong DataFrame và show hiệu quả model.
#dl_code","['#Q&A', '#data', '#machine_learning']","['chào', 'bế tắc', 'mong', 'hướng', 'data', 'train', 'model', 'mlp', 'data', 'thô tóm', 'tắt', 'nhập', 'glutest', 'weight', 'máy', '4', 'dinh dưỡng', 'mn', 'hướng', 'hướng', 'tiền', 'data lệnh', 'vẽ', 'histogram', 'cột', 'dataframe', 'show hiệu', 'model']"
188,"56 câu hỏi phỏng vấn khó nhất và câu trả lời 🔥🔥🔥
Hi các bạn,
Hôm nay mình mới đọc được 1 bài trên Linkedin, tổng hợp các câu hỏi phỏng vấn khó nhất. Mình thấy rất hay nên muốn chia sẻ lại với các bạn.
Điểm khó của phần lớn các câu hỏi phỏng vấn này không nằm ở kiến thức hàn lâm, mà ở việc làm sao để có thể trả lời 1 cách hiệu quả nhất. Ngoài ra, có 1 vài câu hỏi về các topic khá nhạy cảm, nếu không trả lời khéo léo thì rất có thể chúng ta sẽ mất điểm trong mắt nhà tuyển dụng. Ngoài ra thì trong hầu hết các câu hỏi này đều sẽ có những cái bẫy mà các bạn không bao giờ muốn rơi vào 😅
Với mỗi câu hỏi, tác giả sẽ phân tích bẫy được đưa ra là gì, và giải pháp để vượt qua những cái bẫy đó để có được câu trả lời tốt nhất 😎
Link to pdf: https://drive.google.com/file/d/10TjdlPJHEmjz5SXI5U8D0FiXPtT8a7Qn/view?usp=sharing
#interview_tip",['#sharing'],"['56', 'vấn', 'câu', 'hi hôm', 'đọc', '1', 'linkedin', 'tổng hợp', 'vấn vấn', 'nằm', 'kiến thức', 'hàn lâm thể', '1', 'hiệu', '1', 'topic', 'nhạy cảm', 'khéo léo thể', 'ta', 'mắt', 'tuyển dụng', 'bẫy', 'rơi tác giả', 'phân tích', 'bẫy', 'giải pháp', 'bẫy', 'câu', 'link', 'to', 'pdf']"
189,"Bayesian Optimization - thay thế tuyệt vời dành cho GridSearchCV hay RandomizedSearchCV 🔥🔥🔥
Hi các bạn,
Với các ban học hoặc làm về Data Science/Machine Learning, chắc các bạn không còn xa lạ gì với bộ đôi GridSearchCV và RandomizedSearchCV - 2 kĩ thuật giúp chúng ta tìm ra được các hyperparameter tối ưu dành cho các model Machine Learning. Tuy nhiên 2 kĩ thuật này đều có những nhược điểm của riêng mình:
GridSearchCV thì chạy quá tốn thời gian vì thực hiện exhaustive search
RandomizedSearchCV chỉ được thực hiện trên 1 số lượng nhất định các combination của hyperparameter nên hoàn toàn có khả năng là combination tối ưu bị bỏ qua => kết quả cuối cùng không phải là tối ưu
Cả 2 đều có chung 1 nhược điểm: Chúng chỉ có thể thực hiện search qua các giá trị rời rạc, bất kể hyperparameter là liên tục (Do chúng ta phải định nghĩa 1 danh sách các giá trị muốn search của hyperparameter)
Do những hạn chế kể trên, dù 2 kĩ thuật trên được biết đến và sử dụng rộng rãi, chúng ta vẫn cần tìm ra giải pháp tối ưu hơn. 1 trong số đó chính là Bayesian Optimization. Phương pháp này sử dụng Bayesian statistics để ước lượng và đánh giá phân phối của các hyperparameter tốt nhất. Kết quả so sánh giữa 3 phương pháp được thể hiện ở hình bên dưới. Các bạn có thể thấy được sự vượt trội của Bayesian Optimization ở tất cả các hạng mục 😎
#ml_tip
Original article: https://www.blog.dailydoseofds.com/p/the-overlooked-limitations-of-grid","['#sharing', '#machine_learning']","['bayesian', 'optimization', 'thay', 'tuyệt vời', 'gridsearchcv', 'randomizedsearchcv', 'hi ban', 'học', 'data', 'science', 'machine', 'learning', 'lạ', 'đôi', 'gridsearchcv', 'randomizedsearchcv', '2', 'kĩ thuật', 'giúp', 'ta', 'hyperparameter', 'tối ưu model', 'machine', 'learning nhiên', '2', 'kĩ thuật', 'nhược gridsearchcv', 'chạy', 'tốn', 'exhaustive', 'search', 'randomizedsearchcv', '1', 'định', 'combination', 'hyperparameter', 'khả năng', 'combination', 'tối ưu kết', 'tối ưu', '2', '1', 'nhược thể', 'search', 'rời rạc', 'hyperparameter', 'liên tục', 'ta', 'định nghĩa', '1', 'danh sách', 'search hyperparameter', 'hạn chế', '2', 'kĩ thuật', 'rộng rãi', 'ta', 'giải pháp', 'tối ưu', '1', 'bayesian', 'optimization', 'phương pháp', 'bayesian', 'statistics ước', 'phân phối', 'hyperparameter', 'kết sánh', '3', 'phương pháp', 'thể hiện', 'hình thể trội', 'bayesian', 'optimization', 'tất', 'hạng mục', 'original', 'article']"
190,"Mọi người có thể cho mình hỏi là nếu mình muốn dùng computer vision để nhận diện khi một người dùng tay lấy hàng ra khỏi kệ và bỏ hàng lại k lấy nữa thì có những cách tiếp cận nào ạ ? Hard code thuật toán thì mình khá chắc là bất khả thi cho production level..
mình có tìm hiểu về cách làm sử dụng transformer lên body keypoints bởi vi dữ liệu để nhận diện “ hành động “ là dữ liệu sequential với có lẽ là sử dụng thêm vài hard-coded metrics nữa.. mong mn góp ý , mình cảm ơn
#computervision #poseestimation","['#Q&A', '#cv']","['thể', 'computer', 'vision diện', 'hàng', 'kệ', 'hàng', 'k', 'tiếp cận', 'hard', 'code thuật toán', 'bất khả thi', 'production', 'level', 'transformer', 'body', 'keypoints', 'vi liệu diện', 'hành động liệu', 'sequential lẽ', 'hardcoded', 'metrics', 'mong', 'mn', 'góp']"
191,"Mình đang muốn tìm hiểu về các cách thức đánh giá Multi-turn Conversation của chatbot, LLMs.
Trong quá trình tìm hiểu thì mình thấy các paper mình đọc đều tập trung chủ yếu vào các khía cạnh như relevance, usefulness, harmfulness, vv, tức tập trung vào chất lượng của từng câu trả lời (single turn) chứ chưa hẳn là về cả 1 đoạn hội thoại (multiturn).
Mọi người có gợi ý từ khóa hay bài báo nào không ạ?
Mình mới nghĩ ra các vấn đề như:
- người dùng đổi context (đang từ vấn đề A hỏi sang vấn đề B)
- nhắc lại đến những gì đã nói ở trước đó.
#NLP #dl_nlp #hoidap","['#Q&A', '#nlp']","['thức', 'multiturn', 'conversation', 'chatbot', 'llms trình', 'paper', 'đọc', 'chủ yếu', 'khía cạnh', 'relevance', 'usefulness', 'harmfulness', 'vv', 'tức', 'chất', 'câu', 'single', 'turn', 'hẳn', '1', 'đoạn', 'hội thoại', 'multiturn', 'gợi', 'khóa', 'báo', 'đổi', 'context a', 'b', 'nhắc']"
192,"Em chào mọi người,
Ở đây đã ai làm việc với owl-vit và finetune model này với custom dataset chưa ạ?
https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit
Em đã đọc phần finetune nhưng nhiều chỗ chưa rõ lắm. Mong tiền bối nào giúp đỡ với ạ.
#dl_ml_study","['#Q&A', '#machine_learning']","['chào', 'owlvit', 'finetune', 'model', 'custom', 'dataset', 'đọc', 'finetune', 'chỗ', 'lắm', 'mong', 'tiền bối', 'giúp đỡ']"
193,"Khóa học Introduction to Deep Learning tại LMU Munich 🔥🔥🔥
Hi các bạn,
Cách đây tầm 3 tuần, mình từng chia sẻ về khóa Introduction to Machine Learning của Đại học Munich (LMU) 
Nhắc lại 1 chút về LMU. Đây là 1 ngôi trường rất nổi tiếng tại Munich và luôn luôn xuất hiện trong Top 100 trường đại học tốt nhất thế giới, trong đó bao gồm cả 3 bảng xếp hạng danh tiếng nhất thế giới là QS, Times Higher Education và Shanghai Ranking
Hôm nay mình xin chia sẻ với các bạn khóa học anh em với khóa trên: Introduction to Deep Learning 😎
Tương tự với người anh em của mình, khóa học này ngay từ đầu đã được thiết kế theo hướng khuyến khích tự học, thông qua việc cung cấp đầy đủ những tài liệu cần thiết bao gồm:
Video bài giảng bằng tiếng Anh (các lecturer nói khá chậm các bạn nhé. Có phụ đề tiếng Việt thông qua auto-generation)
Slide gồm 10 chương, cover các topic từ cơ bản đến nâng cao trong Deep Learning 😎
Cheatsheets
Quizzes
Bài tập lý thuyết
Bài tập lập trình với lời giải bằng 2 ngôn ngữ là R và Python
Thông thường khi các trường đại học danh tiếng mở các khóa học online, họ thường giảm độ khó so với khóa học thực sự trên trường, để dễ tiếp cận các sinh viên phổ thông hơn. Nhưng khóa học này là 1 trong các ngoại lệ: Trên trường như thế nào họ bê y chang vào khóa online 😅
Link to course:https://slds-lmu.github.io/i2dl/
#dl_share","['#sharing', '#deep_learning']","['khóa', 'học', 'introduction', 'to', 'deep', 'learning', 'lmu', 'munich', 'hi tầm', '3', 'tuần', 'khóa', 'introduction', 'to', 'machine', 'learning', 'đại học', 'munich', 'lmu', 'nhắc', '1', 'chút', 'lmu', '1', 'trường', 'nổi tiếng', 'munich', 'top', '100', 'trường', 'đại học', 'giới', 'bao', '3', 'bảng', 'xếp hạng', 'danh tiếng', 'giới', 'qs', 'times', 'higher', 'education', 'shanghai', 'ranking', 'hôm', 'khóa', 'học', 'khóa', 'introduction', 'to', 'deep', 'learning', 'tương khóa', 'học', 'đầu', 'thiết kế', 'hướng', 'khuyến khích', 'học', 'thông cung', 'tài liệu', 'thiết bao', 'video', 'giảng tiếng', 'lecturer', 'chậm', 'phụ đề', 'tiếng', 'việt', 'thông', 'autogeneration', 'slide', '10', 'chương', 'cover', 'topic', 'nâng', 'deep', 'learning', 'cheatsheets', 'quizzes', 'tập lý', 'thuyết tập', 'lập trình', 'giải', '2', 'ngôn ngữ', 'r', 'python', 'thông trường', 'đại học', 'danh tiếng', 'khóa', 'học', 'online độ', 'khóa học', 'thực trường', 'tiếp cận', 'sinh viên', 'phổ thông', 'khóa học', '1', 'ngoại lệ', 'trường', 'bê y chang', 'khóa', 'online', 'link', 'to', 'course', 'https', 'sldslmu', 'github', 'io', 'i2dl']"
194,"Mình xin chia sẻ tài liệu các môn thuộc chương trình đào tạo của SoICT - ĐH Bách Khoa Hà Nội. Nội dung bao gồm các môn đại cương, cơ sở cốt lõi, chuyên ngành liên quan đến khoa học máy tính, kỹ thuật máy tính, tất nhiên có cả về AI nữa. Để tiện cho mọi người tham khảo thì mình đã đăng tải bằng cả hai ngôn ngữ là Tiếng Anh và Tiếng Việt. Chúc mọi người học tốt.
https://drive.google.com/drive/folders/1QmB2H9rF2wKxCuti7pXW2Q_7-9EKQUid?usp=drive_link
#ms_share",['#sharing'],"['tài liệu', 'môn', 'chương trình', 'đào', 'soict', 'đh', 'bách khoa', 'hà nội', 'nội dung', 'bao môn', 'đại cương', 'sở', 'cốt lõi', 'chuyên ngành', 'khoa học', 'máy', 'kỹ thuật', 'máy', 'tất nhiên', 'tiện', 'tham khảo', 'đăng tải', 'hai', 'ngôn ngữ', 'tiếng', 'tiếng', 'việt', 'chúc', 'học']"
195,"Recommender Systems' Architectures: Tổng hợp tất cả các mô hình Neural network được sử dụng cho recommender systems 🔥🔥🔥
Chúng ta đều biết Neural Network hay mạng nơron chính là trái tim của Deep Learning. Neural Network đã và đang được ứng dụng rộng rãi trong rất nhiều mảng khác nhau như Computer Vision cũng như NLP. Tất nhiên Recommender system cũng không nằm ngoài cuộc chơi 😁 Nguồn dưới đây tổng hợp tất cả các mô hình Neural Network phổ biến nhất từng được áp dụng cho Recommender systems, bao gồm:
Wide and Deep (2016)
Deep Factorization Machine / DeepFM (2017)
Neural Collaborative Filtering / NCF (2017)
Deep and Cross Networks / DCN (2017)
AutoInt (2019)
DLRM (2019)
DCN V2 (2020)
DHEN (2022)
GDCN (2023)
Link to article: https://aman.ai/recsys/architectures/
#ml_share #RecommendationSystems","['#sharing', '#deep_learning']","['recommender', 'systems architectures', 'tổng hợp', 'tất', 'mô hình', 'neural', 'network', 'recommender', 'systems', 'ta', 'neural', 'network mạng', 'nơron', 'trái tim', 'deep', 'learning', 'neural', 'network', 'ứng dụng', 'rộng rãi', 'mảng', 'computer', 'vision', 'nlp', 'tất nhiên', 'recommender system', 'nằm', 'tổng hợp', 'tất', 'mô hình', 'neural network', 'phổ biến', 'áp dụng', 'recommender', 'systems', 'bao wide', 'and deep', '2016', 'deep', 'factorization', 'machine', 'deepfm', '2017', 'neural', 'collaborative', 'filtering', 'ncf', '2017', 'deep and', 'cross', 'networks', 'dcn', '2017', 'autoint', '2019', 'dlrm', '2019', 'dcn', 'v2', '2020', 'dhen', '2022', 'gdcn', '2023', 'link', 'to', 'article', 'https', 'aman', 'recsys', 'architectures']"
196,"Em cần người hỗ trợ làm chatbot tư vấn khám chữa bệnh hoặc tư vấn sản phẩm trong thương mại điện tử
Có hậu tạ ạ
#nlp_code","['#Q&A', '#nlp']","['chatbot', 'tư vấn', 'khám chữa', 'bệnh', 'tư vấn', 'sản phẩm', 'thương mại điện tử', 'hậu tạ']"
197,"hi mn, em làm bên mảng app mobile game, em muốn dùng predict life time value của user(y), y này sẽ bị ảnh hưởng bởi số impression mà user xem quảng cáo (x). Giá trả cho 1000 impression của mỗi mạng quảng cáo là khác nhau. Trường hợp này mình nên dùng Linear regression đúng không ạ ? mn cho em hỏi là:
Mình tìm cái equation của data này như nào ạ, nếu là 2 biến thì mình dùng linear regression là xong, vậy nếu có yếu tố như là thời gian dùng app, số lần xem quảng cáo của user hoặc user pass qua một số level trong game thì mình tạo equation như nào v ạ
đây là cuốn sách mà một bạn trong group giới thiệu mà em đọc qua đã cho em hướng đi tiếp
Luis Serrano - Grokking Machine Learning-Manning Publications (2021)
bác nào có case study nào tương tự cho em xin link để em tham khảo ạ,
cảm ơn mn đã đọc, chúc mn có tuần làm việc hiệu quả
#question","['#Q&A', '#machine_learning']","['hi mn', 'mảng', 'app', 'mobile', 'game', 'predict', 'life', 'time', 'value', 'user', 'y y', 'ảnh hưởng', 'impression', 'user', 'quảng cáo', 'x', 'giá', '1000', 'impression mạng', 'quảng cáo', 'trường hợp', 'linear', 'regression', 'mn', 'equation', 'data', '2', 'biến', 'linear', 'regression', 'xong', 'yếu tố', 'app', 'quảng cáo', 'user', 'user', 'pass', 'level', 'game', 'equation', 'v', 'sách', 'group', 'giới thiệu', 'đọc', 'hướng', 'đi', 'tiếp', 'luis', 'serrano', 'grokking', 'machine', 'learningmanning', 'publications', '2021', 'case', 'study', 'tương link', 'tham khảo', 'mn', 'đọc', 'chúc', 'mn', 'tuần hiệu']"
198,"Mình đang làm nghiên cứu khoa học về chủ đề “Ứng dụng VADER trong phân tích tài chính dựa trên cảm xúc văn bản và đề xuất cho nhà đầu tư cùng doanh nghiệp” (làm bằng cách crawl data lấy tin đồn trên mạng xã hội (reddit, twitter...) hay article + giá , phân tích sentiment dựa trên tool VADER (công cụ phân tích cảm xúc được sử dụng để đánh giá tác động của các bài viết, bình luận, tin tức và thông tin trên mạng đối với tâm trạng và quyết định đầu tư của nhà đầu tư), ( thêm các mô hình ML kiểm định,…), và cuối cùng đưa ra recommend về việc mua - bán mã chứng khoán đấy.
Cụ thể về ý tưởng đề tài là có nhiều cách và phương pháp để quyết định đầu tư hay không, như các phương pháp phân tích kỹ thuật các chỉ số hay tình hình tài chính, các phương pháp này đều đòi hỏi người sử dụng phải có kiến thức chuyên môn để có thể sử dụng hiệu quả. Trong bối cảnh này, nghiên cứu này đề xuất phát triển một công cụ phân tích cảm xúc của tác các bài viết tài chính liên quan đến mã chứng khoán hoặc công ty đó. Các bài viết có thể mang tính chất tích cực hoặc tiêu cực, và sự thay đổi trong cảm xúc này có thể ảnh hưởng đáng kể đến giá cổ phiếu hoặc hiệu suất của một công ty.
Mình đang cần giúp thêm về phần thu thập data, cào dữ liệu, hay tìm kiếm bộ dataset để phân tích. Mình đang mới bắt đầu nghiên cứu đề tài này, ai giúp được mình về phần dữ liệu này với mình xin cảm ơn nhiều ạa.","['#Q&A', '#machine_learning']","['nghiên cứu', 'khoa học', 'chủ đề', 'ứng dụng', 'vader', 'phân tích', 'tài', 'dựa', 'cảm xúc văn', 'đề xuất', 'đầu tư', 'doanh nghiệp', 'crawl', 'data', 'đồn mạng', 'xã hội', 'reddit', 'twitter', 'article', 'giá', 'phân tích', 'sentiment', 'dựa', 'tool', 'vader', 'công cụ', 'phân tích', 'cảm xúc', 'tác động', 'viết', 'bình luận', 'tức', 'thông mạng', 'đối tâm trạng', 'quyết định', 'đầu tư', 'đầu tư', 'mô hình', 'ml', 'kiểm định', 'recommend', 'mua', 'mã chứng khoán', 'đấy', 'tưởng', 'đề tài', 'phương pháp', 'quyết định', 'đầu tư', 'phương pháp', 'phân tích', 'kỹ thuật', 'tình hình', 'tài phương pháp', 'đòi', 'kiến thức', 'chuyên môn', 'thể hiệu', 'bối cảnh', 'nghiên cứu', 'đề xuất', 'phát triển', 'công cụ', 'phân tích', 'cảm xúc tác', 'viết', 'tài mã', 'chứng khoán', 'công ty', 'viết', 'thể chất', 'tích cực', 'tiêu cực', 'cảm xúc thể', 'ảnh hưởng', 'giá', 'cổ phiếu', 'hiệu suất', 'công ty', 'giúp', 'thu thập', 'data', 'cào liệu', 'kiếm', 'dataset', 'phân tích', 'nghiên cứu', 'đề tài', 'giúp', 'liệu', 'ạa']"
199,"Em chào mọi người ạ, tình hình là em đang có 1 project mà giảng viên yêu cầu phải áp dụng python/ML,... Để tạo ra được 1 sản phẩm có thể cho mọi người dùng được như web/app
Thì hiện tại em đang làm về Building Recommendation System, Customer Segmentation và Sentiment Analysis cho 1 loại sản phẩm của Amazon, thì em muốn hỏi là hiện tại đánh giá mô hình cho sentiment của em là 90% rồi thì làm thế nào để em tích hợp nó với 1 web vậy ạ? Em hoang mang quá :<
#ml #python #web","['#Q&A', '#machine_learning', '#python']","['chào', 'tình hình', '1', 'project', 'giảng viên', 'áp dụng', 'python', 'ml', '1', 'sản phẩm thể', 'web', 'app', 'building', 'recommendation', 'system', 'customer', 'segmentation', 'sentiment', 'analysis', '1', 'sản phẩm', 'amazon', 'mô hình', 'sentiment', '90', 'tích hợp', '1', 'web', 'hoang']"
200,"Em chào anh Việt và mọi người, em muốn hỏi về tài liệu của thuật toán ANN ạ, hiện tại em muốn biểu diễn thành công thức như ví dụ trong hình. Mọi người có tài liệu chính thống nào hoặc bài báo nào uy tín có thể cho em xin thêm thông tin để làm bài với ạ.
Em cảm ơn mọi người nhiều
#ml_learn #question","['#Q&A', '#deep_learning']","['chào', 'việt', 'tài liệu', 'thuật toán', 'ann', 'biểu diễn', 'thành công thức', 'ví dụ', 'hình', 'tài liệu', 'thống báo', 'uy tín thể', 'thông']"
201,"Em hiện tại là sinh viên ô tô năm cuối sắp ra trường nhưng em muốn được làm và học về AI và Machine Learning. Em muốn hỏi anh Việt cũng như các bạn trong gr có hướng cũng như roadmap nào để em có thể đạt được những mục tiêu học và làm việc trong mảng này của bản thân ạ. Em xin cảm ơn mọi người (nếu học văn bằng 2 là một lựa chọn tốt thì mọi người có thể đề xuất trường nào tại HN được không ạ, em xin cảm ơn)
#roadmap",['#Q&A'],"['sinh viên', 'ô tô', 'trường học', 'machine', 'learning', 'việt', 'gr', 'hướng', 'roadmap thể', 'mục tiêu', 'học', 'mảng', 'thân học', 'văn', '2', 'lựa thể', 'đề xuất', 'trường', 'hn']"
202,"Em xin chào các anh chị, em newbie trong môn AI ạ, em đang xây dựng mô hình VAE với đầu vào là tập data con ngựa trong cifar 10, các anh chị góp ý giúp em đoạn code này làm sao để mô hình học được tốt hơn không ạ, em chạy colab gần hết RAM mà kết quả ra hình vẫn mờ lắm ạ, em cảm ơn các anh chị rất nhiều ạ!😃
#DL","['#Q&A', '#cv']","['chào', 'newbie môn', 'xây dựng', 'mô hình', 'vae', 'đầu', 'tập', 'data', 'ngựa', 'cifar', '10', 'góp', 'giúp', 'đoạn', 'code', 'mô hình', 'học', 'chạy', 'colab ram', 'kết hình', 'mờ', 'lắm']"
203,"Artificial Intelligence - A modern approach 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 trong số các tài liệu kinh điển cho những ai học về AI: Artificial Intelligence - A modern approach. 
Quyển sách này không đi sâu vào Machine Learning hay Deep Learning, mà sẽ bao quát toàn bộ tất cả những kiến thức tổng quát về AI (Các bạn chú ý nhé, AI > Machine Learning > Deep Learning)
Đây là 1 quyển sách theo hướng lý thuyết (rất hàn lâm đấy các bạn nhé), dài hơn 1100 trang, và không dễ để tiêu hóa. Quyển này hồi mình học năm 1 tại TU Munich, có 1 môn tên là Introduction to AI, và đây là tài liệu tham khảo duy nhất của môn học đấy ☺️
Link to pdf: https://drive.google.com/file/d/1sxct_-EjwvzOYyEdBpP1Kyc26dzx6FBP/view?usp=sharing
#ai_share",['#sharing'],"['artificial', 'intelligence', 'a', 'modern', 'approach', 'hi', 'giới thiệu', '1', 'tài liệu', 'kinh điển', 'học', 'artificial', 'intelligence', 'a modern', 'approach', 'quyển', 'sách', 'đi sâu', 'machine', 'learning', 'deep', 'learning', 'bao quát', 'toàn', 'tất kiến thức', 'tổng quát', 'machine', 'learning', 'deep', 'learning', '1', 'quyển', 'sách', 'hướng', 'lý thuyết', 'hàn lâm', 'đấy', '1100', 'trang tiêu', 'hóa', 'quyển', 'hồi', 'học', '1', 'tu munich', '1', 'môn', 'introduction', 'to', 'tài liệu', 'tham khảo', 'môn học', 'đấy', 'link', 'to', 'pdf']"
204,"100 days of Machine Learning code 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu các bạn 1 repository Github vô cùng thú vị: 100 days of Machine Learning code. Tác giả là Siraj Raval - 1 Youtuber rất nổi tiếng về AI, Math, Science và Technology với 760k subs.
Trong project này, tác giả đưa ra lộ trình 100 ngày học Machine Learning, thông qua lý thuyết được tóm tắt qua các poster đi kèm với code và bài tập để các bạn có thể thực hành 🥰
Repository này không hề hàn lâm 1 chút nào mà rất thực tiễn. Rất dễ hiểu và cơ bản. Rất hợp với các bạn mới hay trái ngành muốn học Machine Learning 😎
Link: https://github.com/Avik-Jain/100-Days-Of-ML-Code
#ml_share","['#sharing', '#machine_learning']","['100', 'days', 'of machine', 'learning', 'code', 'hi', 'giới thiệu', '1', 'repository github', 'vô', 'thú vị', '100', 'days', 'of machine', 'learning', 'code', 'tác giả', 'siraj', 'raval', '1', 'youtuber', 'nổi tiếng', 'math', 'science', 'technology', '760', 'k', 'subs', 'project', 'tác giả', 'lộ trình', '100', 'học', 'machine', 'learning', 'thông lý', 'thuyết tóm', 'tắt', 'poster', 'đi', 'kèm', 'code', 'tập thể', 'thực hành', 'repository', 'hề', 'hàn lâm', '1', 'chút', 'thực tiễn', 'hợp', 'trái', 'ngành', 'học', 'machine', 'learning', 'link']"
205,"Cho em hỏi làm sao để nhúng camera điện thọai vào source yolov8 để thực hiện phần detect vậy ạ?
#vscode","['#Q&A', '#deep_learning']","['nhúng', 'camera', 'điện thoại', 'source', 'yolov8', 'detect']"
206,"Thường sau khi được giao 1 bộ data , mình phải xử lí sau nếu gặp task dưới đây ạ
#data","['#Q&A', '#data']","['giao', '1', 'data', 'xử lí', 'task']"
207,"Hiện nay, chatbot đã trở thành một công cụ quan trọng cho các doanh nghiệp để cung cấp thông tin và tăng tương tác đối với khách hàng. Trong số các loại chatbot, retrieval-based chatbot là một trong những phương pháp phổ biến nhất được sử dụng để đáp ứng các yêu cầu và câu hỏi của người dùng.
Trong bài hôm nay, chúng ta sẽ tìm hiểu sơ lược về retrieval-based chatbot và các thành phần NLP cấu thành nên loại chatbot này.
#nlp_share","['#sharing', '#nlp']","['chatbot', 'công cụ', 'doanh nghiệp', 'cung thông', 'tương tác', 'đối hàng', 'chatbot', 'retrievalbased', 'chatbot', 'phương pháp', 'phổ biến', 'đáp ứng', 'hôm', 'ta', 'sơ lược', 'retrievalbased', 'chatbot', 'thành', 'nlp', 'cấu thành', 'chatbot']"
208,"Em chào mọi người ạ,
Mọi người có bao giờ gặp tình trạng giống em không ạ. Chả là em chạy mô hình phân loại bằng deep learning, machine learning. Một số project khi em đặt giới hạn về xác suất xảy ra trường hợp nó dự đoán càng cao thì nó sai so với thực tế càng nhiều. Nghĩa là khi probability càng cao thì precision của class đó càng giảm.
Em có cách nào khắc phục được trường hợp của em không ạ. Em cảm ơn.
#ML #python #DL",['#Q&A'],"['chào chả', 'chạy', 'mô hình', 'phân deep', 'learning', 'machine', 'learning', 'project', 'giới hạn', 'xác suất', 'xảy', 'trường hợp', 'dự đoán', 'sai nghĩa', 'probability precision', 'class', 'khắc phục', 'trường hợp']"
209,"Với việc kiếm AI intern quá khó, thì giữa Data Science, Data Engineer, Data Analyst, ML Engineer, đâu là những hướng đi hợp lý để sau vào làm AI Engineer ạ?
#career",['#Q&A'],"['kiếm', 'intern', 'data', 'science', 'data', 'engineer', 'data', 'analyst', 'ml', 'engineer', 'hướng', 'đi', 'hợp lý', 'engineer']"
210,"Chào anh/chị trong nhóm e có 1 task forecast revenue của danh sách khách hàng trong năm 2024 khi revenue các năm cũ = revenue của từng category cộng lại nhưng revenue 2024 biết category A sẽ giảm so với năm cũ thì em sẽ sử dụng thuật toán nào để forecast cho phù hợp ạ
Em cảm ơn ạ
#question",['#Q&A'],"['chào', 'e', '1', 'task', 'forecast', 'revenue', 'danh sách', 'hàng', '2024', 'revenue', 'cũ', 'revenue', 'category', 'cộng', 'revenue', '2024', 'category a', 'cũ thuật', 'toán', 'forecast']"
211,"mọi người ơi, lỗi này là lỗi gì vậy ạ??
#ML",['#Q&A'],"['lỗi', 'lỗi']"
212,"Xin chào mọi người,
Hiện tại em đang có ý định train một model để dự đoán cung mọc. Khái niệm về cung mọc trong chiêm tinh thể hiện physical trait (đặc điểm, vẻ bề ngoài) của một người. Em muốn nghiên cứu xem có thực sự là khái niệm này thể hiện được đặc điểm khuôn mặt của người ta hay không!
Hiện em đang cần thêm nhiều data từ người châu Á mình, cụ thể là giờ sinh-ngày sinh và ảnh chụp rõ mặt!
Nếu mọi người trong group ai có hứng thú thì có thể giúp em qua việc upload ảnh lên file drive dưới đây, với title của ảnh là “giờ sinh-ngày-tháng-năm sinh” ạ
Em xin cảm ơn!
https://drive.google.com/drive/folders/1-IeiXWvqKorlfZn2nKDF_q6-nq8Z3Vw4
#dl_challenge","['#Q&A', '#machine_learning']","['chào định', 'train', 'model', 'dự đoán', 'cung', 'mọc', 'khái niệm', 'cung', 'mọc', 'chiêm tinh', 'thể hiện', 'physical', 'trait', 'đặc vẻ', 'bề nghiên cứu', 'thực', 'khái niệm', 'thể hiện', 'đặc khuôn mặt', 'ta', 'hiện', 'data', 'châu sinhngày', 'sinh ảnh', 'chụp', 'mặt', 'group hứng', 'thú thể', 'giúp', 'upload', 'ảnh', 'file', 'drive', 'title', 'ảnh', 'sinhngàythángnăm sinh']"
213,"Tổng hợp tất cả các Cheatsheet về AI của MIT và đại học Stanford 🔥🔥🔥
Hi các bạn,
Dưới đây là tổng hợp tất cả các cheatsheet quan trọng về AI đến từ Học viện Massachusetts và Đại học Stanford. Các cheat sheet này bao gồm những phần sau:
Xác suất
Thống kê
Trí tuệ nhân tạo
Machine Learning 
Deep Learning 
Link: https://drive.google.com/file/d/1eTJC9OY9zhgXMB_NdJ3_85n7YLo_Ajzx/view?usp=sharing
P/s: Trước đây mình đã share các cheat sheet của đại học Stanford (cả bản tiếng Anh và tiếng Việt) rồi. Tài liệu này thêm vào cheat sheet của MIT nữa các bạn nhé 😎
#ml_share #dl_share #math_share",['#sharing'],"['tổng hợp', 'tất cheatsheet', 'mit', 'đại học', 'stanford', 'hi tổng hợp', 'tất cheatsheet', 'học viện', 'massachusetts', 'đại học', 'stanford', 'cheat', 'sheet', 'bao', 'xác suất', 'thống kê', 'trí tuệ', 'nhân machine', 'learning', 'deep', 'learning', 'link', 'p', 's', 'share', 'cheat', 'sheet', 'đại học', 'stanford', 'tiếng', 'tiếng', 'việt', 'tài liệu', 'cheat', 'sheet', 'mit']"
214,"Anh chị cùng các bạn có định hướng theo Data tư vấn giúp em với ạ. Em hiện đang là sinh viên năm 4 ngành CNTT và khoảng 6 tháng nữa thì ra trường. Em có ý định ra trường sẽ theo mảng data và trở thành DS, nhưng hiện tại hướng này thì hơi khó tìm nơi thực tập nên em đang thực tập tại một cty phần mềm. Em biết nếu thực tập tại cty hiện tại thì sau ra trường xin việc thì sẽ không được đánh giá cao nếu muốn xin vào mảng data. Anh chị cho em hỏi nếu không thực tập đúng ở hướng mình theo thì sau này xin việc có ảnh hưởng gì nhiều lắm không ạ. Em dự định là thực tập ở mảng phần mềm này những vẫn sẽ tự học thêm về DS :(((
#career",['#Q&A'],"['định hướng', 'data', 'tư vấn', 'giúp', 'hiện', 'sinh viên', '4', 'ngành', 'cntt', '6', 'trường', 'định trường', 'mảng', 'data', 'ds', 'hướng', 'hơi', 'thực tập', 'thực tập', 'cty', 'mềm thực tập', 'cty', 'trường', 'mảng', 'data', 'thực tập', 'hướng', 'ảnh hưởng', 'lắm', 'dự định', 'thực tập', 'mảng', 'mềm học', 'ds']"
215,"dạ em chào mọi người ạ, hiện em đang thực hiện đề tài về NLP cụ thể là về mảng Summarize Text. Mọi người có thể suggest những paper và các mảng để tiếp cận với đề tài này cũng như là nguồn học và hướng đi về application cho em với được không ạ. Em cám ơn mọi người nhiều ạ
#NLP #MLStudy #DLStudy","['#Q&A', '#nlp']","['chào', 'hiện', 'đề tài', 'nlp', 'mảng', 'summarize', 'text thể', 'suggest', 'paper', 'mảng', 'tiếp cận', 'đề tài', 'học', 'hướng', 'đi', 'application', 'cám ơn']"
216,"Albumentations - thư viện kinh điển dành cho image augmentation 🔥🔥🔥
Hi các bạn,
Post này dành cho các bạn quan tâm hoặc đang theo đuổi mảng giống mình: Deep Learning for Computer Vision 😎
Trong Computer Vision, NLP hay Machine Learning, data augmentation là 1 bước tiền xử lý dữ liệu không thể thiếu. Data augmentation giúp tạo ra dữ liệu đa dạng hơn từ dữ liệu gốc, từ đó giúp cho mô hình có thể học các thuộc tính/đặc trưng của dữ liệu 1 cách hiệu quả hơn ☺️
Trong Computer Vision, chúng ta có rất nhiều các kĩ thuật dành cho image augmentation, như flip, rotate, resize, ... Tuy nhiên hầu hết các kĩ thuật này chỉ có thể áp dụng được cho bài toán đơn giản nhất trong Deep Learning for Computer Vision, đó là Image Classification. Còn với các bài toán phức tạp hơn như Object Detection hay Image Segmentation, các kĩ thuật này sẽ không thể áp dụng được ngay lập tức ...
Albumentation được tạo ra đẻ giải quyết vấn đề này. Ngoài việc giúp cho người dùng có hàng chục sự lựa chọn đa dạng khác nhau dành cho image augmentation, những bức ảnh mới được tạo ra sẽ hoàn toàn tương thích với các bài toán khác nhau, bao gồm cả Object Detection hay Image Segmentation
Nếu các bạn để ý thì có rất nhiều các project nổi tiếng sử dụng thư viện này cho bước tiền xử lý ảnh, trong đó 2 đại diện vô cùng nổi tiếng chính là Yolov5 và Yolov8 của Ultralytics
Link: https://albumentations.ai/
#dl_share","['#sharing', '#python']","['albumentations', 'thư viện', 'kinh điển', 'image augmentation', 'hi post', 'đuổi', 'mảng', 'deep', 'learning', 'for', 'computer', 'vision', 'computer', 'vision', 'nlp', 'machine', 'learning', 'data', 'augmentation', '1', 'tiền', 'liệu thể', 'data', 'augmentation', 'giúp liệu', 'đa dạng liệu', 'gốc', 'giúp', 'mô hình thể', 'học', 'đặc trưng liệu', '1', 'hiệu', 'computer', 'vision', 'ta', 'kĩ thuật', 'image', 'augmentation', 'flip', 'rotate', 'resize nhiên', 'kĩ thuật thể', 'áp dụng', 'toán', 'đơn giản', 'deep', 'learning', 'for', 'computer', 'vision', 'image', 'classification toán', 'phức tạp', 'object', 'detection', 'image segmentation', 'kĩ thuật thể', 'áp dụng', 'lập tức', 'albumentation đẻ', 'giải quyết', 'giúp', 'hàng', 'chục', 'lựa', 'đa dạng', 'image', 'augmentation', 'ảnh', 'tương toán', 'bao', 'object', 'detection', 'image', 'segmentation', 'project', 'nổi tiếng', 'thư viện', 'tiền', 'ảnh', '2', 'đại diện', 'vô', 'nổi tiếng', 'yolov5', 'yolov8', 'ultralytics', 'link', 'https', 'albumentations']"
217,"Em chào mọi người ạ. Chả là nhân một ngày tiết trời lành lạnh ru rú ở nhà hơi chán, em xin phép kể cho mọi người nghe một câu chuyện kinh dị ngắn nhé.

""Con trai tôi đã 11 tháng tuổi, đã có thể nói được một vài từ có nghĩa. Giống như những đứa trẻ khác, nó cũng sẽ chỉ một đồ vật nào đó, sau đó vất vả gọi tên chúng. Có một lần, nó chỉ một hình vẽ trên cuốn sách sau đó bi bi bô bô nói: “mèo”. Chúng tôi nhìn xem, quả nhiên, ở góc cuốn sách nơi đầu ngón tay của nó đang chỉ có một con mèo.
Một ngày nọ khi chỉ có tôi và con trai đang ở nhà cùng nhau, con trai đột nhiên ngừng chơi, dùng đầu ngón tay chỉ về sau lưng tôi, sau đó vô cùng rõ ràng thốt lên một chữ: “Generative AI”.  ""
Tiện thể mọi người có tài liệu hoặc khóa học nào về Generative AI cho em xin với ạ, với cả mọi người có thể cho em tham khảo lộ trình làm bố của Generative AI thì cho em xin lun nhé ạ.
Em cảm ơn mn nhắm nhắm. 😍😍
#dl_study #dl_roadmap
 — đang cảm thấy sợ hãi.",['#Q&A'],"['chào', 'chả', 'nhân tiết', 'trời', 'lành lạnh', 'ru', 'rú hơi', 'chán phép', 'câu', 'kinh dị', 'ngắn', 'trai', '11', 'thể nghĩa', 'đứa', 'trẻ', 'đồ vật', 'vất vả', 'gọi', 'hình', 'vẽ', 'sách', 'bi bi bô', 'bô', 'mèo nhiên', 'góc', 'sách', 'đầu ngón', 'mèo', 'trai', 'trai', 'đột nhiên', 'ngừng', 'đầu ngón', 'lưng', 'vô ràng', 'chữ', 'generative', 'tài liệu', 'khóa học', 'generative thể', 'tham khảo', 'lộ trình', 'bố', 'generative', 'lun', 'mn', 'nhắm', 'nhắm', 'sợ hãi']"
218,"Python programming - 3 books in 1: Quyển sách All-in-One về lập trình Python từ cơ bản đến nâng cao theo định hướng Data Science/Data Analysis 🔥🔥🔥
Hi các bạn,
Với các bạn đang tìm hiểu về lập trình Python theo định hướng DS/DA, mình xin giới thiệu với các bạn 1 quyển sách về Python đầy đủ từ cơ bản đến nâng cao. Quyển sách này bao gồm 3 phần:
Python cho người mới bắt đầu
Python cho Data Analysis 
Python cho Data Science 
Mình đã đọc qua nội dung từng phần của quyển sách này. cả 3 phần đều khá ổn. Có 1 điều mình mong tác giả sẽ làm tốt hơn, đó là phần code formatting (để như hiện tại nhìn không chuyên nghiệp lắm 😅). Anyway, vẫn là 1 đầu sách vô cùng tốt cho các bạn muốn bắt đầu học lập trình với Python 🥰
Link to pdf: https://drive.google.com/file/d/1ogb0uT0RkdTL1ut2nwpYhjcOmHgpJveD/view?usp=sharing
#py_share","['#sharing', '#python']","['python', 'programming', '3', 'books', 'in', '1', 'quyển', 'sách', 'allinone', 'lập trình', 'python', 'nâng', 'định hướng', 'data', 'science', 'data', 'analysis', 'hi lập trình', 'python', 'định hướng', 'ds', 'da', 'giới thiệu', '1', 'quyển', 'sách', 'python', 'nâng', 'quyển', 'sách', 'bao', '3', 'python', 'python', 'data', 'analysis', 'python', 'data', 'science', 'đọc', 'nội dung', 'quyển', 'sách', '3', 'ổn', '1', 'mong', 'tác giả', 'code formatting', 'chuyên nghiệp', 'lắm', 'anyway', '1', 'đầu sách', 'vô học', 'lập trình', 'python', 'link', 'to', 'pdf']"
219,"Chào mọi người, hiện tại em đang tìm hiểu về Transformer qua video https://www.youtube.com/watch?v=_Zt23FA31co&list=PLMm4sOMuA2QLOXMoonhz1uuBhi3IXaeNY
 và có clone repo https://github.com/bangoc123/transformer/ về để chạy thử. Trong quá trình chạy em gặp phải một vài điều thắc mắc:
Lỗi nhận GPU máy tính (em đoán vậy): Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found.
Em mở một vài code python thấy vscode báo một số lỗi import thư viện kiểu: Import \""tensorflow\"" could not be resolved . Nhưng không hiểu sao khi em chạy lệnh huấn luyện mô hình thì nó vẫn chạy.
Máy em chạy Windows 11, GPU RTX 3050, có cài anaconda.
Hiện tại em mới biết sơ qua về ML, DL chưa có nhiều kĩ năng code, mong mọi người rộng lượng hỗ trợ giải đáp cho em. Em cảm ơn mọi người rất nhiều. 
#dsml_study #nlp_study","['#Q&A', '#deep_learning']","['chào', 'transformer', 'video', 'clone', 'repo', 'https', 'github', 'com', 'bangoc123', 'transformer', 'chạy', 'thử trình', 'chạy', 'thắc mắc', 'lỗi', 'gpu', 'máy đoán', 'could', 'not', 'load', 'dynamic', 'library', 'cudart64_110', 'dll', 'dlerror', 'cudart64_110', 'dll', 'not', 'found', 'code', 'python', 'vscode', 'báo', 'lỗi', 'import', 'thư viện', 'kiểu', 'import', 'tensorflow', 'could', 'not', 'be resolved', 'chạy', 'lệnh', 'huấn luyện', 'mô hình', 'chạy', 'máy', 'chạy', 'windows', '11', 'gpu', 'rtx', '3050', 'cài', 'anaconda', 'sơ ml', 'dl', 'kĩ năng', 'code mong', 'rộng', 'giải đáp']"
220,"Chào mọi người, hiện tại em có 3 phần code: sử dụng model yolov5 để detect người và xe trên đường, line detect, và sign detect. 3 phần này nó riêng biệt với nhau và em muốn gộp 3 cái nó lại thành 1 để khi mình cho đầu vào là 1 video thì nó sẽ tự output ra cho mình dò xe, người, làn đường và biển báo thì làm như thế nào ạ
#cv_code","['#Q&A', '#cv', '#deep_learning']","['chào', '3', 'code', 'model', 'yolov5', 'detect', 'xe', 'đường', 'line', 'detect', 'sign', 'detect', '3', 'biệt gộp', '3', 'thành', '1', 'đầu', '1', 'video', 'output', 'dò', 'xe', 'làn đường', 'biển báo']"
221,"#dl_nlp
Mình được biết RNN có 1 problem là không thể ghi nhớ được thông tin ở các early timestep. Vậy thì nguyên nhân sâu xa cho vấn đề này là gì ạ ? Có phải do Vanishing Gradient không ạ ? Mình tìm trên mạng thì thấy ít bài giải thích về vấn đề này, và mình đọc các bài này xong thì cũng không thỏa mãn về cách giải thích cho lắm.
 — đang cảm thấy bối rối.","['#Q&A', '#nlp', '#deep_learning']","['rnn', '1', 'problem thể', 'ghi', 'thông early', 'timestep', 'nguyên nhân', 'sâu', 'vanishing', 'gradient mạng', 'giải', 'đọc', 'xong', 'thỏa', 'mãn giải', 'lắm', 'bối rối']"
222,"Báo cáo tình hình tuyển dụng các Jobs Data tháng 11/2023

Xin chào mọi người, hôm nay mình xin phép giới thiệu với mọi người một dự án cá nhân mà mình thực hiện liên quan đến việc scrape dữ liệu từ các website tuyển dụng và phân tích các job post trên đó. Mình nghĩ kết quả của nó có thể sẽ có ích với nhiều bạn trong group nên mình share lên đây. 

Phần hôm nay mình chia sẻ với các bạn sẽ là kết quả của một notebook mà mình phân tích 370 jobs liên quan đến data mà mình thu thập trên CareerBuilder vào 19 và 20 tháng 11 vừa rồi.

Giới thiệu sơ qua về dự án:

Để thực hiện dự án này, mình cào dữ liệu bằng cách sử dụng hai thư viện Python: Selenium và BeautifulSoup:
Selenium để điều khiển Chrome, truy cập các đường link, thực hiện thao tác cuộn trang để load html
BeautifulSoup để kéo html_soup về và giải mã, trích xuất những thông tin cần thiết từ html
Chi tiết về cách thực hiện mọi người có thể xem kĩ hơn ở Github repo dưới đây:
https://github.com/DataSpi/scraping-jobs
Trong repo, bạn có thể tìm thấy dữ liệu từ nhiều công việc khác nhau. Mình đã có cào dữ liệu của các jobs ở các ngành logistics xuất nhập khẩu, warehouse, data. Trong bài share trên facebook này, mình sẽ chỉ post chart đáng chú ý (có chú thích thêm ở từng ảnh), chi tiết và comment kĩ hơn của mình cho từng chart, bạn có thể truy cập blog post dưới đây của mình để đọc kĩ hơn, và nếu được thì subcribe ủng hộ mình nhé. 
https://spyno.substack.com/p/thi-truong-tuyen-dung-cac-jobs-ve
Thêm nữa, phân tích trong bài này còn ở mức đơn giản, hi vọng có cao nhân nào đó trong group có thể ra tay tương trợ để phát triển projec này hơn nữa. Nếu có bất kì thắc mắc nào, đừng ngại inbox mình để trao đổi thêm nhé. 

-

Note thêm, mình đang tìm kiếm các job data analyst & data science level juinor khoảng 1 năm kinh nghiệm nhé. Bạn nào có job liên hệ mình nhé 😉. 

#ds_share",['#sharing'],"['báo cáo', 'tình hình', 'tuyển dụng', 'jobs', 'data', '11', '2023', 'chào', 'hôm', 'phép', 'giới thiệu', 'dự án', 'scrape liệu', 'website', 'tuyển dụng', 'phân tích', 'job', 'post', 'kết thể ích', 'group share', 'hôm', 'kết notebook', 'phân tích', '370', 'jobs', 'data', 'thu thập', 'careerbuilder', '19', '20', '11', 'giới thiệu', 'sơ', 'dự án', 'dự án', 'cào liệu', 'hai', 'thư viện', 'python', 'selenium', 'beautifulsoup', 'selenium khiển', 'chrome', 'truy cập', 'đường', 'link', 'thao tác', 'cuộn trang', 'load', 'html', 'beautifulsoup', 'kéo', 'html_soup', 'giải mã', 'trích xuất', 'thông thiết', 'html', 'chi tiết thể', 'kĩ github', 'repo', 'repo thể liệu', 'công cào liệu', 'jobs', 'ngành', 'logistics', 'xuất nhập khẩu', 'warehouse', 'data', 'share', 'facebook', 'post', 'chart', 'ảnh', 'chi tiết', 'comment', 'kĩ', 'chart thể', 'truy cập', 'blog', 'post', 'đọc', 'kĩ subcribe', 'ủng hộ', 'phân tích', 'đơn giản', 'hi vọng', 'nhân', 'group thể', 'tương trợ', 'phát triển', 'projec', 'thắc mắc', 'đừng', 'ngại', 'inbox', 'trao đổi', 'note', 'kiếm', 'job', 'data', 'analyst', 'data', 'science', 'level', 'juinor', '1', 'kinh nghiệm', 'job', 'liên hệ']"
223,"Em chào mọi người à. Hiện tại em đang thử train model lenet5 trên dataset CIFAR10 ở trong torchvision.datasets và em đã resize hết các ảnh về kích thước 32x32x1 và chia data ra với batch_size là 32. Lúc em train thì accuracy ở tập test cao nhất là 50%. Không biết ở đây mọi người có thể recommend cho em model nào train tốt hơn với tập dữ liệu đó hoặc có thể là em implement sai, mọi người check giúp em với ạ. Em cảm ơn nhiều. (Em đã thêm ảnh quá trình tiền xử lý ảnh và train ạ)
#dl","['#Q&A', '#deep_learning']","['chào', 'thử', 'train', 'model', 'lenet5', 'dataset', 'cifar10', 'torchvision', 'datasets', 'resize', 'ảnh', 'kích thước', '32x32', 'x1', 'chia', 'data', 'batch_size', '32', 'train', 'accuracy', 'tập', 'test', '50', 'thể', 'recommend', 'model', 'train', 'tập liệu thể', 'implement', 'sai', 'check', 'giúp', 'ảnh', 'trình', 'tiền', 'ảnh', 'train']"
224,"#dl_nlp
Xin chào mọi người ạ.
Hiện tại em đang thực hiện 1 nghiên cứu về Fake review detection trên dataset khoảng gần 1 triệu mẫu về đánh giá mobile commerce tại VN nhưng chưa được label. Em đang gặp vấn đề ở step label. Tụi em đã thử một số phương pháp như LDA và Vader. LDA với mục đích để tìm ra các topic có trong bài rồi kiểm tra thử xem topic không liên quan tới lĩnh vực của tập dataset là mobile commerce nhưng mà kết quả sau khi thực hiện thì tụi em thấy các topic nó ra kết quả khá chung chung nên không thể xác định được topic nào là không liên quan ạ). 1 yếu tố nữa là cái review này chỉ là short text chủ yếu từ 10-15 từ nên LDA nó cũng không hiệu quả .Dùng VADER để tính Sentiment Score của Review và so sánh mối liên hệ giữa Sentiment Score của Review với Rating Score mà người Review đã đánh giá nhưng kết quả không khả quan lắm trên tiếng việt. Em có thử api để trans qua tiếng anh rồi chạy lại nhưng mà kết quả nó cũng không cải thiện hơn.
Em có nghĩ theo hướng sẽ build từ điển. Sử dụng word embedding để xây dựng từ điển. Xây dựng 2 bộ nhãn, 1 bộ là các từ mà chuyên về spam/ fake và 1 bộ là ngược lại. Em đã trích xuất ra được aspect của dataset nhưng chưa biết cách chọn aspect như thế nào để build từ điển. Em dùng pos tagging để trích xuất ra các danh từ nhằm tìm ra các aspect trong tập dataset nhưng sau khi trích xuất thì tụi em không biết nên chọn aspect nào cho phù hợp (kết quả đếm các danh từ xuất hiện nhiều nhất tụi em thấy các danh từ này dùng làm aspect cũng không thật sự hợp lý). Bên cạnh đó em cũng chưa tìm hiểu được sử dụng phương pháp nào để có thể tìm được các từ có liên quan đến aspect để xây dựng được từ điển.
Em có đọc được 1 đề xuất của 1 anh trên group về Sentiment analysis on labeled and unlabeled datasets using BERT architecture nhưng theo em đọc thì thấy về phía unlabeled data nó sử dụng cái Fuzzy model nhưng em chưa hiểu cách nó chạy lắm.
Mong mng có thể cho em 1 vài đề xuất ạ.","['#Q&A', '#nlp']","['chào', '1', 'nghiên cứu', 'fake', 'review', 'detection', 'dataset', '1', 'triệu', 'mẫu', 'mobile', 'commerce', 'vn', 'label', 'step', 'label', 'tụi', 'thử', 'phương pháp', 'lda', 'vader', 'lda', 'mục đích', 'topic', 'kiểm tra', 'thử', 'topic', 'lĩnh vực', 'tập', 'dataset', 'mobile', 'commerce', 'kết', 'tụi', 'topic', 'kết thể', 'xác định', 'topic', '1', 'yếu tố', 'review', 'short text', 'chủ yếu', '1015', 'lda hiệu', 'vader', 'sentiment', 'score', 'review', 'sánh', 'liên hệ', 'sentiment', 'score', 'review', 'rating', 'score', 'review kết', 'khả quan', 'lắm', 'tiếng', 'việt', 'thử', 'api', 'trans', 'tiếng', 'chạy kết', 'cải thiện', 'hướng', 'build điển', 'word embedding', 'xây dựng', 'điển', 'xây dựng', '2', 'nhãn', '1', 'chuyên', 'spam', 'fake', '1', 'ngược', 'trích', 'xuất', 'aspect', 'dataset', 'aspect', 'build điển', 'pos', 'tagging', 'trích', 'xuất danh', 'aspect', 'tập', 'dataset', 'trích', 'xuất', 'tụi', 'aspect kết', 'đếm danh', 'tụi', 'danh aspect', 'hợp lý', 'cạnh', 'phương pháp thể', 'aspect', 'xây dựng', 'điển', 'đọc', '1', 'đề xuất', '1', 'group', 'sentiment', 'analysis', 'on labeled', 'and unlabeled', 'datasets', 'using', 'bert', 'architecture', 'đọc', 'unlabeled', 'data', 'fuzzy', 'model', 'chạy', 'lắm', 'mong', 'mng thể', '1', 'đề xuất']"
225,"Xin chào mọi người, mình đang cần cài phần mềm này trên máy Mac.
Các bạn biết chuyển từ bash sang zsh không?
khi cài cần tải key về, mình không tải được key theo định dạng .asc, chử ký định dạng .sha5
lúc tải key về định dạng .txt thì mình chạy file bằng terminal, bị báo là không tìm ra file.
Các bạn giúp mình với hi.
#py_code",['#Q&A'],"['chào', 'cài', 'mềm', 'máy', 'mac', 'bash zsh', 'cài tải', 'key tải', 'key định', 'dạng', 'asc', 'chử', 'ký định', 'dạng', 'sha5 tải', 'key định', 'dạng', 'txt', 'chạy', 'file', 'terminal', 'báo', 'file', 'giúp', 'hi']"
226,"Awesome Production Machine Learning - danh sách tổng hợp tất cả mọi thứ có liên quan đến Machine Learning in production 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 nguồn tổng hợp vô cùng thú vị cho tất cả mọi bước có liên quan đến Machine Learning in Production, bao gồm: 
Đánh nhãn dữ liệu 
Triển khai
Theo dõi
Mở rộng mô hình
...
1 nguồn All-in-one vô cùng chất lượng dành cho những bạn muốn tìm hiểu xem bên ngoài phạm vi trường học, các mô hình Machine Learning sẽ được triển khai và sử dụng như thế nào 😎
Link: https://github.com/EthicalML/awesome-production-machine-learning
#ml_share","['#sharing', '#machine_learning']","['awesome', 'production', 'machine', 'learning', 'danh sách', 'tổng hợp', 'tất machine', 'learning', 'in', 'production', 'hi', 'giới thiệu', '1', 'tổng hợp', 'vô thú vị', 'tất machine', 'learning', 'in', 'production', 'bao', 'đánh', 'nhãn liệu', 'triển khai', 'dõi', 'rộng', 'mô hình', '1', 'allinone', 'vô chất', 'phạm vi', 'trường học', 'mô hình', 'machine', 'learning', 'triển khai', 'link']"
227,"Dạ xin chào anh chị, em mới học DL và xử lý ảnh.
Em đã viết được 1 model train classcification Mnist ( em thấy đầu ra là xác suất của ảnh với 10 label). Em cũng thử làm detection với yolov5 ( chỉ xử lý đầu vào cho khớp đầu ra, và chạy lệnh detect).
Giờ em muốn học kĩ hơn, là làm sao để detect 1 vật ( ra đó là vật j và có bbox) nhưng em thấy có rất nhiều hướng:
1 là tự viết 1 model
2 là em có nghe về transfer learning ( ví dụ như resnet50) . Và nếu dùng hướng này thì em dùng torch. Resnet50 luôn hay tự code từng lớp theo model ạ?
3 là em thắc mắc về việc làm sao ra bbx, vì ví dụ em thấy đầy ra mạng resnet50 là (1,1000)
Mong anh chị giải đáp thắc mắc của em, và gợi ý em thư viện j nên dùng và tourial ạ
(Em có biết pytorch cơ bản , đọc ảnh với openCV)
Em xin cảm ơn rất nhiều
#dl_cv
#Detection","['#Q&A', '#deep_learning', '#cv']","['chào học', 'dl', 'ảnh', 'viết', '1', 'model', 'train', 'classcification', 'mnist', 'đầu', 'xác suất', 'ảnh', '10', 'label', 'thử', 'detection', 'yolov5', 'đầu', 'khớp', 'đầu', 'chạy', 'lệnh', 'detect học', 'kĩ detect', '1', 'vật vật', 'j', 'bbox', 'hướng', '1', 'viết', '1', 'model', '2', 'transfer', 'learning', 'ví dụ', 'resnet50', 'hướng', 'torch', 'resnet50', 'code', 'lớp', 'model', '3', 'thắc mắc', 'bbx', 'ví dụ', 'mạng', 'resnet50', '1', '1000', 'mong', 'giải đáp', 'thắc mắc', 'gợi', 'thư viện', 'j', 'tourial', 'pytorch', 'đọc', 'ảnh', 'opencv']"
228,"Chào anh Việt và mọi người, em là sinh viên chuyên ngành AI của một trường đại học ở Việt Nam.
E có định hướng muốn đi theo AI Engineer. Hiện tại em chuẩn bị đi thực tập, em đang nghiên cứu các công ty cũng như việc làm trong tương lai, em thấy Intern và Fresher thật sự khá ít và khó kiếm, tuy nhiên Senior lại khá nhiều. Chương trình thực tập của trường em là bắt buộc và hiện tại em chưa có hình dung mình sẽ đi intern ở đâu ạ.
Du học thì em có nghĩ đến nhưng mà đó là dự định xa và e muốn tập trung đi thực tập và đi làm trong tương lai gần. Mọi người có khuyên gì cho trường hợp của em được không ạ?
Em cảm ơn mọi người ạ.
#career",['#Q&A'],"['chào', 'việt', 'sinh viên', 'chuyên ngành', 'trường', 'đại học', 'việt nam', 'e định hướng', 'đi', 'engineer chuẩn', 'đi', 'thực tập', 'nghiên cứu', 'công ty', 'tương lai', 'intern', 'fresher', 'kiếm nhiên', 'senior', 'chương trình', 'thực tập', 'trường', 'bắt buộc', 'hình dung', 'đi', 'intern', 'du học', 'dự định', 'e', 'đi', 'thực tập', 'đi', 'tương lai', 'khuyên', 'trường hợp']"
229,"Em chào mọi người, em đang build 1 model nhận diện cảm xúc trên flask. Sau đó em đã thử dùng cả 2 cách là postman và dùng file request.py để gửi request ảnh đến model của em. Sau đó model sẽ decode ảnh và analyze emotion có trong ảnh. Các bước của em diễn ra suôn sẻ, cho đến bước cuối cùng trả về emotion thì lại trả về not found, trong khi em test model riêng ngoài flask với cũng chính cái ảnh này thì vẫn trả kết quả như thường. Em không biết vấn đề nằm ở chỗ nào nữa ạ! Rất mong các anh các chị trong group có thể cho em lời khuyên! Em xin cảm ơn.
#ml","['#Q&A', '#python', '#cv']","['chào', 'build', '1', 'model diện', 'cảm xúc', 'flask', 'thử', '2', 'postman', 'file', 'gửi', 'request', 'ảnh', 'model', 'model', 'decode', 'ảnh', 'analyze', 'emotion', 'ảnh', 'diễn', 'suôn sẻ', 'emotion', 'not', 'found', 'test', 'model', 'flask', 'ảnh', 'kết', 'nằm', 'chỗ', 'mong', 'group thể', 'khuyên']"
230,"Em có một source đã train đủ model em muốn nhờ anh/ chị chạy giúp em, do máy em đang lỗi thư viện chưa chạy được. Anh chị giúp em với ạ :(( #python #cv",['#Q&A'],"['source', 'train', 'model', 'chạy', 'giúp', 'máy', 'lỗi', 'thư viện', 'chạy', 'giúp']"
231,"Geoffrey Hinton - Bố già của Deep Learning 🔥🔥🔥
Hi các bạn,
Khi nói về Deep Learning, nếu để kể ra 1 trong những cái tên nổi bật, lỗi lạc nhất, người đã đặt những nền móng ban đầu cho Deep Learning, và thậm chí 1 trong các thuật toán được ông đề xuất đã dẫn đến khái niệm Deep Learning mà chúng ta sử dụng rỗng rãi ngày nay, không ai có thể phù hợp hơn Geoffrey Hinton - người vẫn được coi là Bố già của Deep Learning. 
Những đóng góp của ông đối với sự phát triển của AI/Machine Learning/Deep Learning thì vô cũng nhiều. Dưới đây là tóm tắt những đóng góp nổi bật nhất của ông. Mình sẽ điểm qua 1 vài đóng góp mà đối với mình là ấn tượng nhất các bạn nhé:
Ông là 1 trong số những người đã đề xuất thuạt toán Backward propagation - thứ không thể thiếu để có thể tối ưu hóa các mô hình Deep Learning 
Ông đề xuất thuật toán để huấn luyện Deep Belief Nets - thứ dẫn đến khái niệm Deep Learning sau này
Ông là tác giả của t-SNE, thuật toán nổi tiếng dành cho giảm chiều dữ liệu, bên cạnh PCA đã quá đỗi quen thuộc
Ông là người tạo ra RMSprop - 1 optimizer rất nổi tiếng, bên cạnh các SGD, AdaGrad hay Adam 
Mini-batch Gradient Descent cũng là 1 trong số các thành tựu của ông 
Ông chính là cha đẻ của Dropout - layer nổi tiếng giúp hạn chế overfitting 
CIFAR 10 dataset là 1 đóng góp khác của ông
Cho đến nay ông đã có 327 publications. Chúng ta sẽ không thể hình dung được AI ngày nay sẽ như thế nào nếu không có những đóng góp của ông 😎
#ai_share
P/s: Với cá nhân mình thì ông cùng Andrew Ng và Yann LeCun là 3 idols AI của mình 😁",['#sharing'],"['geoffrey', 'hinton', 'bố', 'già', 'deep', 'learning', 'hi deep', 'learning', '1', 'nổi bật', 'lỗi lạc', 'móng', 'ban đầu', 'deep', 'learning chí', '1', 'thuật toán', 'đề xuất', 'khái niệm', 'deep', 'learning', 'ta', 'rỗng rãi thể', 'geoffrey', 'hinton', 'coi', 'bố', 'già', 'deep learning', 'đóng góp', 'đối phát triển', 'machine', 'learning', 'deep', 'learning', 'vô tóm tắt', 'đóng góp', 'nổi bật', '1', 'đóng góp', 'đối ấn tượng', '1', 'đề xuất', 'thuạt toán', 'backward', 'propagation thể thể', 'tối ưu hóa', 'mô hình', 'deep', 'learning', 'đề xuất', 'thuật toán', 'huấn luyện', 'deep', 'belief', 'nets', 'khái niệm', 'deep', 'learning', 'tác giả', 'tsne thuật toán', 'nổi tiếng', 'chiều liệu', 'cạnh', 'pca đỗi', 'quen', 'rmsprop', '1', 'optimizer', 'nổi tiếng', 'cạnh', 'sgd', 'adagrad', 'adam', 'minibatch', 'gradient', 'descent', '1', 'thành tựu', 'đẻ', 'dropout', 'layer', 'nổi tiếng', 'giúp', 'hạn chế', 'overfitting', 'cifar', '10', 'dataset', '1', 'đóng góp', '327', 'publications', 'ta thể', 'hình dung', 'đóng góp', 'p', 's', 'andrew', 'ng', 'yann', 'lecun', '3', 'idols']"
232,"Chào mọi người, hiện tại mình đang nghiên cứu Topic về ""Ứng dụng/phát triển các kỹ thuật ML trong việc đảm bảo/phát hiện/phòng ngừa tấn công mạng"". Có bạn nào đã/đang làm về topic này không, chúng ta có thể trao đổi thêm về topic được không ạ, xin cám ơn!
#ds_ml
#py #dl","['#Q&A', '#machine_learning']","['chào', 'nghiên cứu', 'topic', 'ứng dụng', 'phát triển', 'kỹ thuật', 'ml', 'phát hiện', 'phòng ngừa', 'công mạng', 'topic', 'ta thể', 'trao đổi', 'topic', 'cám ơn']"
233,"Tăng tốc độ chạy Python 100 lần với Cython 🔥🔥🔥
Hi các bạn,
Khi các bạn chạy 1 script Python, mặc định CPython sẽ được sử dụng như là trình thông dịch. Tuy nhiên thì CPython không có bất kì chức năng tối ưu nào
Thay vào đó, nếu các bạn sử dụng Cython, đoạn code của các bạn sẽ được convert sang C - ngôn ngữ lập trình nhanh và hiệu quả hơn về mặt tính toán. Để sử dụng Cython, chúng ta chỉ cần thực hiện 1 vài thao tác sau (Áp dụng trên Jupyter Notebook - thứ mình không thích cho lắm 😅):
Load Cython ở 1 cell riêng: %load_ext Cython
Thêm Cython command ở trên cùng của 1 cell mới: %%cython -a
Khi sử dụng các hàm, hãy định nghĩa kiểu của các biến thay vì cách dùng không cần định nghĩa kiểu của Python 
Các bạn sẽ thấy khác biệt rõ ràng về tốc độ.
Vì sao lại có sự khác biệt về tốc độ như vậy? Như các bạn biết, Python là 1 ngôn ngữ linh hoạt. Với cùng 1 biến, lúc đầu các bạn có thể sử dụng nó như 1 biến kiểu số nguyên, sau đó các bạn có thể đổi nó thành biến kiểu chuỗi. Sự linh động này khiến Python phải đánh đổi 2 thứ: Tốc độ và bộ nhớ.
Cython giới hạn sự linh động vốn làm nên thương hiệu của Python. Bù lại chúng ta sẽ được hưởng lợi vô cùng lớn về mặt tốc độ và bộ nhớ, và kết quả là như các bạn nhìn thấy trong hình 😎
#py_tip","['#sharing', '#python']","['tốc độ', 'chạy', 'python', '100', 'cython', 'hi chạy', '1', 'script', 'python', 'mặc định', 'cpython trình', 'thông', 'dịch nhiên', 'cpython', 'chức năng', 'tối ưu', 'thay', 'cython', 'đoạn', 'code', 'convert c', 'ngôn ngữ', 'lập trình', 'hiệu', 'mặt toán', 'cython', 'ta', '1', 'thao tác', 'áp dụng', 'jupyter', 'notebook', 'lắm', 'load', 'cython', '1', 'cell', 'load_ext', 'cython', 'cython', 'command', '1', 'cell', 'cython', 'a', 'hàm định nghĩa', 'kiểu biến', 'thay', 'định nghĩa', 'kiểu', 'python biệt', 'ràng', 'tốc độ', 'biệt tốc độ', 'python', '1', 'ngôn ngữ', 'linh hoạt', '1', 'biến', 'đầu thể', '1', 'biến', 'kiểu', 'nguyên thể', 'đổi', 'thành', 'biến', 'kiểu', 'chuỗi', 'linh động', 'python', 'đánh đổi', '2', 'tốc độ', 'cython', 'giới hạn', 'linh động', 'vốn', 'thương hiệu', 'python', 'bù', 'ta', 'hưởng', 'lợi', 'vô mặt', 'tốc độ', 'kết hình']"
234,"Em chào mọi người. Em theo yt học tensorflow. Em muốn cho ma trận thứ 2 tự thêm các hàng vector 0 cho cùng số hàng và số cột như matran 1. E có hỏi chat gpt mà nó nói loanh quanh mãi k được. Mong mọi người giúp em có cách nào đưa nó về cùng số cột số hàng k. Em để code cho mn dễ copy đây ạ.
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
sentences = [
'I love my dog',
'I love my cat',
'You love my dog!',
'Do you think my dog is amazing?'
]
tokenizer = Tokenizer(num_words = 100, oov_token=""<OOV>"")
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index
sequences = tokenizer.texts_to_sequences(sentences)
padded = pad_sequences(sequences, maxlen=5)
print(""\nWord Index = "" , word_index)
print(""\nSequences = "" , sequences)
print(""\nPadded Sequences:"")
print(padded)
# Try with words that the tokenizer wasn't fit to
test_data = [
'i really love my dog',
'my dog loves my manatee'
]
test_seq = tokenizer.texts_to_sequences(test_data)
print(""\nTest Sequence = "", test_seq)
padded = pad_sequences(test_seq, maxlen=10)
print(""\nPadded Test Sequence: "")
print(padded)
#nlp_study #ml_study","['#Q&A', '#python']","['chào', 'yt', 'học', 'tensorflow', 'ma trận', '2', 'hàng', 'vector', '0', 'hàng', 'cột', 'matran', '1', 'e', 'chat', 'gpt', 'loanh quanh', 'mãi', 'k', 'mong', 'giúp', 'cột', 'hàng', 'k', 'code', 'mn', 'copy', 'import', 'tensorflow', 'as', 'tf', 'from', 'tensorflow', 'import', 'keras', 'from', 'tensorflow', 'keras', 'preprocessing', 'text', 'import', 'tokenizer', 'from', 'tensorflow', 'keras', 'preprocessing', 'sequence', 'import', 'pad_sequences', 'sentences', 'i', 'love', 'my', 'dog', 'i', 'love', 'my', 'cat', 'you', 'love', 'my', 'dog', 'you', 'think', 'my', 'dog', 'is', 'amazing', 'tokenizer', 'tokenizer', 'num_words', '100', 'oov_token', 'oov', 'tokenizer', 'fit_on_texts', 'sentences', 'word_index', 'tokenizer', 'word_index', 'sequences', 'tokenizer', 'texts_to_sequences', 'sentences', 'padded', 'pad_sequences', 'sequences', 'maxlen', '5', 'print', 'nword', 'index', 'word_index', 'print', 'nsequences', 'sequences', 'print', 'npadded', 'sequences', 'print', 'padded', 'try', 'with', 'words', 'that', 'the', 'tokenizer', 'wasn', 't', 'fit', 'to', 'test_data', 'i', 'really', 'love', 'my', 'dog', 'my', 'dog', 'loves', 'my', 'manatee', 'test_seq', 'tokenizer', 'texts_to_sequences', 'test_data', 'print', 'ntest', 'sequence', 'test_seq', 'padded', 'pad_sequences', 'test_seq', 'maxlen', '10', 'print', 'npadded', 'test', 'sequence', 'print', 'padded']"
235,"Vẫn là logic của hangman, một bài nhập môn rất phổ biến khi mới học code, nhưng có gắn thêm GUI vào cho bắt mắt. Project này có thể thú vị cho bạn nào đang ở giai đoạn qua mức python căn bản một xíu xiu vì:
- bắt đầu có sự làm quen với thiết kế có nhiều hơn 1 components trong 1 project (cụ thể là 2 folders chứa đồ và 3 python files, thêm 1 file requirements.txt);
- bắt đầu có nhiều functions cái nọ móc nghéo vô cái kia.

Source code: LeoUtas/hangman2 (github.com)

#py_share #py_code","['#sharing', '#python']","['logic', 'hangman', 'nhập môn', 'phổ biến', 'học', 'code', 'gắn', 'gui', 'bắt mắt', 'project thể', 'thú vị', 'giai đoạn', 'python xíu', 'xiu', 'quen', 'thiết kế', '1', 'components', '1', 'project', '2', 'folders', 'chứa', 'đồ', '3', 'python', 'files', '1', 'file', 'requirements', 'txt', 'functions', 'móc', 'nghéo', 'vô', 'kia', 'source', 'code', 'leoutas', 'hangman2']"
236,"Em xin chào mọi người,
Hiện tại, em đang gặp khó khăn về việc convert từ Image 1 sang Image 2 như hình ảnh trên. Mọi người cho em xin ý tưởng và hướng xử lý được không ạ. Em cũng thử với việc tìm contour và vẽ đường bao từng contour sau đó đo góc lệch rồi xoay nhưng không thành công.
Em là newbie nên rất mong học hỏi từ mọi người ạ!
#cv_study #py","['#Q&A', '#cv']","['chào', 'khăn', 'convert', 'image', '1', 'image', '2', 'hình ảnh', 'tưởng', 'hướng', 'thử', 'contour', 'vẽ', 'đường', 'bao contour', 'đo', 'góc', 'lệch', 'xoay', 'thành công', 'newbie', 'mong', 'học']"
237,"Hi anh chị, hiện tại em đang được giao bài tập về web (viết bằng JSP-SERVLET với JAVA) có tính toán lớn như xử lý dữ liệu lớn, mô hình học máy...Dự định của em là xây dựng một trang web phân loại chó và mèo, input là một image (chó hoặc mèo), output là kết quả từ model trả về cho mình là một đoạn text (Chó hoặc mèo).Model thì em đã build rồi ạ( em dùng Tensorflow và Keras...). Em muốn nhờ anh chị cho em một số hướng để làm bài toán này ạ, theo em tìm hiểu thì bây giờ chúng ta phải DEPLOY model lên web bằng Flask(hoặc bằng công nghệ khác)  sau đó dùng RestFull API để connect với ứng dụng Web(JSP-Servlet) đúng không ạ, em chưa từng deploy model lên web nên chưa biết về cái này. Mong anh chị giúp đỡ và đề xuất một vài nguồn tham khảo để em có thể tìm hiểu ạ. Em cảm ơn anh chị đã giúp đỡ 🥰🥰
#ds_ml_study #dl_study #cv_study #deploy_study ","['#Q&A', '#cv']","['hi', 'giao tập', 'web', 'viết', 'jspservlet', 'java', 'toán liệu', 'mô hình', 'học', 'máy', 'dự định', 'xây dựng', 'trang web', 'phân', 'chó', 'mèo', 'input', 'image', 'chó', 'mèo', 'output', 'kết', 'model', 'đoạn', 'text', 'chó', 'mèo', 'model', 'build', 'tensorflow', 'keras', 'hướng', 'toán', 'ta', 'deploy', 'model web', 'flask', 'công nghệ', 'restfull', 'api', 'connect', 'ứng dụng', 'web', 'jspservlet', 'deploy', 'model web', 'mong', 'giúp đỡ', 'đề xuất', 'tham khảo thể', 'giúp đỡ']"
238,"Chào a Việt và mn trong nhóm. E học ngành Data Science và đang học quản trị dữ liệu lớn .
Vì môn này trên trường e mới chỉ được học về pyspark và kafka . Nên khi thầy ra bài tập lớn cuối kỳ bọn em rất ít ý tưởng để làm . Đa số mọi ngừoi đều làm về recommendation . A Việt và mn trong nhóm có idea nào khác và có nguồn tham khảo nào hay thì giúp em với được không ạ!
Em cảm ơn mn!
#data_science #project_idea","['#Q&A', '#data']","['chào', 'a việt', 'mn', 'e học', 'ngành', 'data', 'science học', 'quản trị liệu', 'môn', 'trường', 'e học', 'pyspark', 'kafka', 'thầy', 'tập', 'kỳ', 'bọn', 'tưởng', 'đa ngừoi', 'recommendation', 'a việt', 'mn', 'idea', 'tham khảo', 'giúp', 'mn']"
239,"Chào mọi người cho em hỏi vì sao matrix X trong linear reg lại là ma trận 2xn chứ không phải 1xn chiều ạ
#ML","['#Q&A', '#machine_learning']","['chào', 'matrix', 'x', 'linear', 'reg', 'ma trận', '2', 'xn', '1', 'xn', 'chiều']"
240,"Em chào mọi người ạ
Chuyện là em mới học về ngôn ngữ LT Python cách đây chưa lâu, trong quá trình em làm bài tập liên quan đến việc tương tác với các file trên máy thì máy em có vấn đề là mã vẫn chạy được, ko bị lỗi nhưng nó cũng ko cho ra kết quả. Em có lên gg để tìm nhưng thật sự em ko biết diễn tả làm sao để gg nó hiểu nữa, nói chung là em tìm một đằng mà cái giải pháp của gg nó ra một nẻo 🥲, rồi em có lên các group chat thì người ta chỉ là để ý xem cái đường dẫn file của em nó có khớp với cái thư mục mà file đó nằm không, tại nhiều khi không đúng vị trí là nó bị lỗi gì ấy. Hiện tại em rất mơ hồ trong cái vụ này, em cũng biết là bài này nó trông cũng có vẻ cơ bản quá, nhưng mn nếu có thể thì hướng dẫn giúp em cách tạo thư mục sao cho mỗi lần tương tác với các file thì không bị dính lỗi với ạ!
Ví dụ lần gần nhất là em học cách tính toán với dữ liệu trong 1 file docs, lúc đầu em làm câu đọc dữ liệu từ file thì chạy nó vẫn ra KQ nhưng những câu sau là tính cộng trừ nhân chia, in ra số lớn nhất, nhỏ nhất, trung bình cộng thì mặc dù ko bị báo mã lỗi nhưng nó cũng không cho ra KQ gì hết ạ. Liệu có phải do file ko nằm đúng vịt trí nên tương tác với nó ko được ko ạ 🥹
Em cảm ơn mn, chúc mn có một ngày làm việc năng suất ạaa
#py_study","['#Q&A', '#python']","['chào học', 'ngôn ngữ', 'lt', 'python', 'trình tập', 'tương tác', 'file', 'máy', 'máy mã', 'chạy', 'ko', 'lỗi', 'ko', 'kết', 'gg', 'ko', 'diễn tả', 'gg', 'đằng', 'giải pháp', 'gg', 'nẻo', 'group', 'chat', 'ta', 'đường', 'file', 'khớp', 'thư mục', 'file', 'nằm', 'lỗi', 'mơ hồ', 'vụ', 'trông vẻ', 'mn thể', 'hướng', 'giúp', 'thư mục', 'tương tác', 'file', 'dính', 'lỗi', 'ví dụ', 'học', 'toán liệu', '1', 'file', 'docs', 'đầu', 'câu', 'đọc liệu', 'file', 'chạy', 'kq', 'câu', 'cộng trừ', 'nhân', 'chia', 'in', 'trung bình', 'cộng', 'mặc', 'ko', 'báo mã', 'lỗi', 'kq liệu', 'file ko', 'nằm', 'vịt trí', 'tương tác', 'ko ko', 'mn', 'chúc', 'mn', 'năng suất', 'ạaa']"
241,"Hiện tại e đạng gặp vấn đề là tọa độ dự đoán trên ảnh bị lệch so với tọa độ thực tế (chọn 1 điểm trên ảnh làm gốc sau đó đưa ra tọa độ vật thế dự đoán). E thử nhân Ox với Oy với hệ số nhân nma không khả dụng lắm. Mọi ng có thể gợi ý cho e cách giải quyết đc không ạ?
#cv_study","['#Q&A', '#cv']","['e', 'đạng', 'tọa độ', 'dự đoán', 'ảnh', 'lệch', 'tọa độ', '1', 'ảnh', 'gốc', 'tọa độ', 'vật', 'dự đoán', 'e', 'thử', 'nhân', 'ox', 'oy', 'hệ', 'nhân nma', 'khả dụng', 'lắm', 'ng thể', 'gợi e', 'giải quyết', 'đc']"
242,"Các nguyên tắc cơ bản trong trực quan hóa dữ liệu 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn 1 tài liệu vô cùng thú vị về chủ đề data visualization. Khác với những tài liệu khác mình từng chia sẻ về cùng chủ đề, ở trong tài liệu này, ngoài việc với data như thế nào thì nên chọn loại plot nào, chúng ta còn được tìm hiểu về các nguyên tắc cơ bản về chọn màu sắc, độ tương phản giữa nét vẽ và nền, nhằm giúp cho các plot được nổi bật và thu hút hơn 🥰
1 tài liệu ngắn gọn nhưng vô cùng hữu ích 😎
Link to pdf: https://drive.google.com/file/d/1UIj8O5oW6RiT8Ebcse3HXDtrczh0akcK/view?usp=sharing
#ds_share","['#sharing', '#cv']","['nguyên tắc', 'trực quan', 'hóa liệu', 'hi', '1', 'tài liệu', 'vô thú vị', 'chủ đề', 'data', 'visualization', 'tài liệu', 'chủ đề', 'tài liệu', 'data', 'plot', 'ta', 'nguyên tắc', 'màu sắc độ', 'tương phản', 'nét', 'vẽ', 'giúp', 'plot', 'nổi bật', 'thu hút', '1', 'tài liệu', 'ngắn gọn', 'vô hữu ích', 'link', 'to', 'pdf']"
243,"Em chào mọi người ạ,
Em đang có dự định làm một chương trình duyệt các resume, cv để xét độ phù hợp với job description. Project này em muốn hoàn thành để làm project cá nhân ạ.
Dự kiến chương trình này sẽ có 2 chức năng chính:
1. Kiểm tra xem dữ liệu đó phù hợp với ngành nghề nào nhất
2. Khi duyệt cùng với 1 job description, kiểm tra xem phù hợp mức độ bao nhiêu (Không chỉ duyệt xem có keyword không, mà còn kiểm tra từ khóa đó có gần với từ khóa có trong jd hay không?)
Mọi người có thể đưa ra định hướng cũng như gợi ý, lời khuyên cho em được không ạ. Em xin cảm ơn ạ!
#nlp_study","['#sharing', '#nlp']","['chào', 'dự định', 'chương trình', 'duyệt', 'resume', 'cv', 'xét độ', 'job', 'description project', 'hoàn thành', 'project', 'dự kiến', 'chương trình', '2', 'chức năng', '1', 'kiểm tra liệu', 'ngành nghề', '2', 'duyệt', '1', 'job', 'description', 'kiểm tra', 'độ', 'duyệt', 'keyword', 'kiểm tra', 'khóa', 'khóa', 'jd thể', 'định hướng', 'gợi', 'khuyên']"
244,"Phân biệt 4 phương thức huấn luyện phổ biến trong các mô hình Machine Learning trong thực tế 🔥🔥🔥
Hi các bạn,
Trong các ứng dụng Machine Learning/Deep Learning thực tế, chúng ta sẽ gần như không bao giờ huấn luyện 1 mô hình hoàn toàn từ A-Z. Thay vào đó chúng ta sẽ tái sử dụng/tận dụng các model đã được huấn luyện từ trước nhằm tận dụng khả năng của các model này. Dưới đây là 4 phương thức huấn luyện phổ biến mà các bạn sẽ gặp trong các ứng dụng ML/DL thực tế:
Transfer learning: Đây là phương thức vô cùng phổ biến và hữu ích nếu các bạn có ít data. Cách áp dụng rất đơn giản. Các bạn sử dụng model đã được huấn luyện trên 1 dataset rất lớn và có nét tương đồng với dataset của các bạn (ImageNet, COCO, ...). Sau đó các bạn thay thế 1 vài layer cuối của model đó bằng các layer mới, và sau đó tiếp tục huấn luyện mô hình mới này với dataset của các bạn. Trong quá trình này thì chỉ có các layer mới được gắn thêm vào mới được update thông qua backpropagation
Fine-tuning: Gần tương tự như Transfer learning, nhưng số lượng các layer được update sẽ linh động hơn. Có thể 1 vài hoặc thậm chí toàn bộ các layer sẽ được update. Ngoài ra những layer cuối cùng có thể sẽ không bị thay đổi bởi các layer mới
Multi-task learning: Model được huấn luyện để thực hiện nhiêu task cùng 1 lúc. Ở công ty trước của mình, bọn mình cũng huấn luyện 1 model theo cách này. Mô hình classification của bọn mình vừa classify số áo, vừa classify màu của áo jersey cùng 1 lúc
Federated learning: Đây là cách tiếp cận phi tập trung hóa, trong đó thì training data sẽ nằm ở thiết bị người dùng (e.g. điện thoại di động, ...). Sau đó, thay vì dữ liệu được gửi tới server thì model sẽ được gửi tới thiết bị người dùng và được huấn luyện tại đó. Cuối cùng, chỉ có các update là sẽ được thu thập và gửi ngược về cho server
#ml_share #dl_share","['#sharing', '#machine_learning']","['phân biệt', '4', 'phương thức', 'huấn luyện', 'phổ biến', 'mô hình', 'machine learning', 'hi ứng dụng', 'machine', 'learning', 'deep', 'learning', 'ta', 'huấn luyện', '1', 'mô hình', 'az', 'thay', 'ta', 'tái', 'tận dụng', 'model', 'huấn luyện', 'tận dụng', 'khả năng', 'model', '4', 'phương thức', 'huấn luyện', 'phổ biến', 'ứng dụng', 'ml', 'dl', 'transfer', 'learning', 'phương thức', 'vô', 'phổ biến', 'hữu ích', 'data', 'áp dụng', 'đơn giản', 'model', 'huấn luyện', '1', 'dataset', 'nét', 'tương đồng', 'dataset', 'imagenet', 'coco', 'thay', '1', 'layer', 'model', 'layer', 'huấn luyện', 'mô hình', 'dataset trình', 'layer', 'gắn', 'update', 'thông', 'backpropagation', 'finetuning', 'tương transfer', 'learning', 'layer', 'update', 'linh động thể', '1', 'chí', 'toàn', 'layer', 'update', 'layer thể', 'layer', 'multitask', 'learning', 'model', 'huấn luyện', 'nhiêu', 'task', '1', 'công ty', 'bọn', 'huấn luyện', '1', 'model', 'mô hình', 'classification', 'bọn', 'classify', 'áo', 'classify', 'màu', 'áo', 'jersey', '1', 'federated', 'learning', 'tiếp cận', 'phi', 'hóa', 'training', 'data', 'nằm', 'thiết e', 'g', 'điện thoại di động', 'thay liệu', 'gửi', 'server', 'model', 'gửi', 'thiết huấn luyện', 'update', 'thu thập', 'gửi', 'ngược', 'server']"
245,"Hãy chủ động hơn trong quá trình học, dù các bạn học AI, IT hay bất kì ngành nào 🙏🙏🙏
Hi các bạn,
Thời mình còn là sinh viên (cả ở Việt Nam và Đức), mỗi khi lên giảng đường, mình luôn tuân thủ quy tắc 3 không: Không hỏi, không phát biểu và không thảo luận. Mình cảm thấy thoải mái và hoàn toàn ổn. Ít nhất là đối với mình, điều này không để lại hậu quả gì lớn (ngoài việc không thầy cô nào nhớ mặt mình 😅)
Tuy nhiên đến bây giờ, khi bản thân mình đứng lớp, mình mới cảm nhận được những gì các thầy mình ngày xưa từng trải qua. Trong 1 vài lớp mình dạy, mình thường xuyên phải đối mặt với tình trạng dạy học mà như đang diễn độc thoại, bất kể mình có cố gắng khuyến khích các bạn học viên tương tác đến mức nào đi nữa. Hỏi các bạn có ai không hiểu kiến thức/câu hỏi hay không, không ai trả lời. Hỏi xem có ai giải được bài không, cũng không ai trả lời. Nhiều lúc chỉ là những câu hỏi đơn giản, yes/no question, nhưng cũng không ai nói gì. Thực sự có nhiều lúc mình chỉ muốn tắt mic tắt camera đi nghỉ sớm cho xong 😢
Khi các bạn tham gia 1 lớp học, bất kể là online hay offline, nếu các bạn không tương tác với giáo viên:
Giáo viên sẽ không biết họ đang dạy nhanh quá hay chậm quá
Giáo viên cũng sẽ không biết có kiến thức nào cần nói kĩ hơn không
Và quan trọng nhất, giáo viên không biết bạn có hiểu họ đang nói gì hay không
Khi các bạn tham gia 1 lớp học, hỏi là quyền lợi của các bạn và trả lời câu hỏi là bổn phận và nghĩa vụ của giáo viên. Các bạn có quyền lợi mà, sao lại tự tước bỏ nó? Sự tương tác từ các bạn sẽ giúp cho buổi học trở nên tốt hơn, các bạn dễ học hơn và giáo viên dễ dạy hơn. Đó là mối quan hệ win-win 😎
Ngày trước mình cứ nghĩ đi tán các bạn nữ là việc khó nhất, giờ đi dạy học rồi mới thấy nhiều khi cạy miệng các bạn còn khó hơn 😅
Mình chỉ muốn khuyên các bạn, hãy cố gắng chủ động hơn trong quá trình học, bất kể hình thức học hay ngành học của các bạn là gì. Sau này ra ngoài xã hội các bạn sẽ còn phải chủ động hơn nữa, tham gia vào buổi học thực sự chưa có là gì là khó khăn hay thử thách cả 😎
#study_advice",['#sharing'],"['chủ động', 'trình', 'học', 'học', 'it', 'ngành', 'hi thời', 'sinh viên', 'việt nam', 'đức', 'giảng đường', 'tuân thủ', 'quy tắc', '3', 'phát biểu', 'thảo luận', 'thoải mái', 'ổn', 'đối hậu', 'thầy', 'mặt nhiên', 'thân', 'đứng lớp', 'cảm thầy', 'xưa', 'trải', '1', 'lớp', 'dạy', 'xuyên', 'đối mặt', 'dạy học', 'diễn', 'độc thoại', 'cố gắng', 'khuyến khích', 'học viên', 'tương tác', 'đi', 'kiến thức', 'giải', 'đơn giản', 'yes', 'no', 'question', 'thực tắt', 'mic', 'tắt', 'camera', 'đi', 'nghỉ', 'xong', 'tham gia', '1', 'lớp học', 'online offline', 'tương tác', 'giáo viên', 'giáo viên', 'dạy', 'chậm', 'giáo viên', 'kiến thức', 'kĩ giáo viên', 'tham gia', '1', 'lớp học', 'quyền lợi', 'bổn phận', 'nghĩa vụ', 'giáo viên', 'quyền lợi', 'tước', 'tương tác', 'giúp', 'học', 'trở học', 'giáo viên', 'dạy', 'quan hệ', 'winwin', 'đi', 'tán', 'nữ', 'đi', 'dạy học', 'cạy', 'miệng', 'khuyên', 'cố gắng', 'chủ động', 'trình học', 'hình thức', 'học', 'ngành', 'học xã hội', 'chủ động', 'tham gia', 'học', 'thực khăn', 'thử thách']"
246,"Em chào mọi người ạ. Mọi người cho em xin tư vấn về định hướng với ạ. Em hiện tại đang là sinh viên năm 2 chuyên ngành kỹ thuật phần mềm. Em thấy mình thích học toán, giải thuật, thuật toán và mong muốn nghiên cứu về deep learning trong AI mà đến năm 3 trường em có cho học về AI with tensorflow thì em lên học theo lộ trình như nào để không lệch khỏi quỹ đạo ạ. Em cảm ơn mọi người ạ.
#deepLearning_study
#tensorflow
#advice","['#Q&A', '#machine_learning']","['chào', 'tư vấn', 'định hướng', 'sinh viên', '2', 'chuyên ngành', 'kỹ thuật', 'mềm', 'học toán', 'giải thuật', 'thuật toán', 'mong', 'nghiên cứu', 'deep', 'learning', '3', 'trường học', 'with', 'tensorflow học', 'lộ trình', 'lệch', 'quỹ đạo']"
247,"Em đang đọc đến phần vector trong cơ sở khác nhau. Đến chỗ này thì em không hiểu cái biểu thức lắm em nghĩ là U phải là ma trận với ud là các vector hàng chứ ạ
#math","['#Q&A', '#math']","['đọc', 'vector', 'sở', 'chỗ', 'biểu thức', 'lắm u', 'ma trận', 'ud', 'vector', 'hàng']"
248,"Mình có Camera HikVision và mình dùng cap = cv2.Videocapture để lấy frame từ camera. Nếu mình dùng cap.read() thì chỉ đọc dc frame trước đó và chỉ mất 2ms, còn nếu đọc 2 lần liên tiếp cap.read() thì sẽ lấy dc frame hiện tại nhưng thời gian đọc lên đến 100ms. Mình cũng test với webcam và bị tương tự. Ai giúp mình với
#Camera HikVision
#Python","['#Q&A', '#cv']","['camera', 'hikvision', 'cap', 'cv2', 'videocapture', 'frame', 'camera', 'cap', 'read', 'đọc', 'dc', 'frame', '2', 'ms', 'đọc', '2', 'liên tiếp', 'cap', 'read', 'dc', 'frame', 'đọc', '100', 'ms', 'test', 'webcam', 'tương giúp', 'hikvision']"
249,"#other
Không biết mọi người thấy sao nhưng cá nhân em thấy nguyên nhân sâu xa các nhóm kỹ thuật kém chất lượng là vì không lọc kỹ bài đăng và để những bài đăng như này xuất hiện quá nhiều làm loãng group và làm các bài đăng chất lượng bị trôi đi (những bài đăng về những thứ quá cơ bản mà em nghĩ khi bạn đó copy nguyên câu hỏi lên google thì chắc chắn ra được đáp án có khi còn chi tiết và ""tận răng"" hơn là mất công đánh máy rồi chụp ảnh lên đây!
Trong tương lai, cá nhân em rất mong anh Việt có thể lọc kỹ các bài đăng hơn nữa, vì những người hỏi những câu hỏi kiểu như vậy chắc chắn sẽ luôn là đông nhất trong bất kỳ một nhóm nào, muốn kéo tương tác thì có thể chọn hướng đi mọi người có thể tự do hỏi kiểu như vậy vì có thể thu hút nhiều người như vậy hơn nữa, nhưng em nghĩ chất lượng vẫn hơn số lượng, và anh Việt có thể lên làm một bài đăng dạy cách đặt câu hỏi ạ! Nhất là khi giờ ChatGPT có thể lập tài khoản bằng SĐT Việt Nam và việc copy code và hỏi nó bất kỳ câu hỏi nào về cú pháp code, bug,... là cực kỳ dễ dàng và em nghĩ rằng nó có thể giải đáp tốt hơn và cặn kẽ hơn rất nhiều so với vài dòng comment ngắn ngủi của mọi người (Anh cũng có thể làm một bài đăng về cách prompt trên ChatGPT ạ:>) Mình xin update một bài viết của anh Tôi đi code dạo nói về vấn đề này ạ: https://toidicodedao.com/2019/11/05/cach-dat-cau-hoi-lap-trinh/",['#sharing'],"['nguyên nhân', 'sâu', 'kỹ thuật', 'kém', 'chất', 'lọc', 'kỹ', 'đăng', 'đăng', 'loãng', 'group', 'đăng chất', 'trôi', 'đi', 'đăng copy', 'nguyên', 'google', 'chắn', 'đáp án', 'chi tiết', 'tận công', 'đánh máy', 'chụp', 'ảnh', 'tương lai', 'mong', 'việt thể', 'lọc', 'kỹ', 'đăng', 'kiểu', 'chắn', 'đông', 'kéo', 'tương tác thể', 'hướng', 'đi thể', 'kiểu thể', 'thu hút', 'chất', 'việt thể', 'đăng dạy', 'chatgpt thể', 'lập', 'tài khoản', 'sđt', 'việt nam', 'copy', 'code', 'cú', 'pháp', 'code', 'bug', 'cực kỳ dàng thể', 'giải đáp', 'cặn kẽ', 'dòng', 'comment', 'ngắn ngủi thể', 'đăng prompt', 'chatgpt', 'update', 'viết', 'đi', 'code', 'dạo', 'https', 'toidicodedao', 'com', '2019', '11', '05', 'cachdatcauhoilaptrinh']"
250,"Chào mọi người
Hiện tại em đang là sinh viên ngành Hệ thống thông tin quản lý. Tuy nhiên, em muốn nghiên cứu về AI cụ thể là Machine learning và Deep learning. Vậy nên cho em hỏi là với kiến thức về đại số, giải tích, xstk và lập trình Python thì có nên chọn sách này làm khởi đầu không? Nếu không thì nhờ mọi người đề xuất cho em vài tựa sách dễ hiểu và bao quát giúp em
Em cảm ơn nhiều ạ.
#ml_study","['#Q&A', '#machine_learning']","['chào', 'sinh viên', 'ngành', 'hệ thống', 'thông', 'quản lý nhiên', 'nghiên cứu', 'machine', 'learning', 'deep learning', 'kiến thức', 'đại giải tích', 'xstk', 'lập trình', 'python', 'sách', 'khởi đầu', 'đề xuất', 'tựa', 'sách', 'bao quát', 'giúp']"
251,"Paper đã thay đổi mọi thứ về AI 1 lần và mãi mãi: Attention is all you need 🔥🔥🔥
Vào tháng 6 năm 2017, các nhà nghiên cứu tại Google đã công bố paper này. Đây là paper đã đặt nền móng cho sự phát triển mạnh mẽ của AI về sau này, bằng việc giới thiệu 1 loạt các khái niệm, thuật toán mới, bao gồm:
Giới thiệu Transformers: Paper này lần đầu cho ra mắt các mô hình Transformer - 1 sự cải tiến vượt bậc so với các mô hình CNN và RNN truyền thống trong NLP 
Cơ chế Self-Attention: Transformers sử dụng self-attention để xử lý 1 cách hiệu quả các phần khác nhau của dữ liệu đầu vào
Cải thiện song song hóa: Transformers cho phép huấn luyện mô hình 1 cách hiệu quả hơn thông qua việc song song hóa tốt hơn so với RNN 
Cải thiện performance của các mô hình NLP: Transformers cải thiện đáng kể performance khi so sánh với các mô hình truyền thống trong các task như là machine translation hay text summerization
Làm nền tảng cho các mô hình nâng cao: Kiến trúc của Transformers đã tạo tiền đề cho các mô hình như BERT hay GPT sau này
1 paper đã ra mắt cách đây 6 năm nhưng ảnh hưởng của nó thì vẫn còn cho đến bây giờ 😎
#dl_share
P/s: Đây là mình dịch lại 1 post khá thú vị trên Linkedin mà mình mới đọc được các bạn nhé. Paper này vào cuối 2017 mình cũng đã từng có dịp đọc. Tuy nhiên hướng đi chính của mình là Computer Vision nên mình sau đó cũng không quá chú ý đến nó, mặc dù tầm quan trọng của paper này là không cần bàn cãi 😎
Link to paper: https://arxiv.org/pdf/1706.03762.pdf
#dl_share","['#sharing', '#deep_learning']","['paper', '1', 'mãi mãi', 'attention', 'is', 'all', 'you', 'need', '6', '2017', 'nghiên cứu', 'google', 'công bố', 'paper', 'paper móng', 'phát triển', 'mẽ', 'giới thiệu', '1', 'loạt', 'khái niệm', 'thuật toán', 'bao', 'giới thiệu', 'transformers', 'paper', 'đầu', 'mắt', 'mô hình', 'transformer', '1', 'cải tiến', 'bậc', 'mô hình', 'cnn rnn', 'truyền thống', 'nlp chế', 'selfattention', 'transformers', 'selfattention', '1', 'hiệu liệu', 'đầu', 'cải thiện', 'song song', 'hóa', 'transformers phép', 'huấn luyện', 'mô hình', '1', 'hiệu', 'thông', 'song song', 'hóa', 'rnn', 'cải thiện', 'performance', 'mô hình', 'nlp', 'transformers', 'cải thiện', 'performance', 'sánh', 'mô hình', 'truyền thống', 'task', 'machine', 'translation', 'text', 'summerization tảng', 'mô hình', 'nâng', 'kiến trúc', 'transformers', 'tiền đề', 'mô hình', 'bert', 'gpt', '1', 'paper', 'mắt', '6', 'ảnh hưởng', 'p', 's', 'dịch', '1', 'post', 'thú vị', 'linkedin', 'đọc', 'paper', '2017', 'dịp', 'đọc nhiên', 'hướng', 'đi', 'computer', 'vision', 'mặc', 'tầm', 'paper', 'bàn cãi', 'link', 'to', 'paper']"
252,"Mọi người cho em hỏi là em bị lỗi ValueError: high <= 0 và em đã lên gg và chatgpt nhưng nó bảo chỉnh lại giá trị high ấy nhưng em không biết chỉnh như thế nào để nó không bị lỗi nữa ạ, đây là bài toán nhận dạng biển số xe ạ, em cảm ơn ạ.
#py_code #ds_ml_project #cv_code","['#Q&A', '#cv']","['lỗi', 'valueerror', 'high', '0', 'gg', 'chatgpt', 'bảo chỉnh', 'high chỉnh', 'lỗi toán', 'dạng', 'biển', 'xe']"
253,"mọi người cho em xin ý tưởng bài toán với ạ, em có bài tập về xử lý ảnh là xác định tọa độ của vật trên thực tế trong một hệ quy chiếu xác định thì nên làm như nào cho hợp lý ạ,
#cv
#py","['#Q&A', '#cv']","['tưởng', 'toán tập', 'ảnh', 'xác định', 'tọa độ', 'vật hệ', 'quy chiếu', 'xác định', 'hợp lý']"
254,"mình cài thư viện r sao nó vẫn báo lỗi và k chạy nhỉ
#py_code","['#Q&A', '#python']","['cài', 'thư viện', 'r', 'báo', 'lỗi k', 'chạy']"
255,"Em chào mọi người ạ. Em đang có dự định làm một đề tài nghiên cứu khoa học có ứng dụng Neural Networks trong lĩnh vực Logistics và quản lý chuỗi cung ứng ạ. Nhưng hiện tại em chưa tìm kiếm được ý tưởng để thực hiện ạ, vì đây là đề tài em dự định solo ạ. Mọi người có thể recommend cho em một số đề tài em có thể thực hiện với ạ? Em cảm ơn mọi người ạ
#ds_ml_project","['#Q&A', '#deep_learning']","['chào', 'dự định', 'đề tài', 'nghiên cứu', 'khoa học', 'ứng dụng', 'neural', 'networks', 'lĩnh vực', 'logistics', 'quản lý', 'chuỗi', 'cung ứng', 'kiếm tưởng', 'đề tài', 'dự định', 'solo thể', 'recommend', 'đề tài thể']"
256,"Số lượng job theo số năm kinh nghiệm yêu cầu.
-
Có thể thấy, hầu hết các job data trên CareerBuilder rơi vào mức từ 1-3 năm kinh nghiệm.",['#sharing'],"['job', 'kinh nghiệm thể', 'job', 'data', 'careerbuilder', 'rơi', '13', 'kinh nghiệm']"
257,"Em chào mọi người ạ, em đang tìm hiểu xây dựng 1 retrival-based chatbot đơn giản, mọi người cho em xin 1 vài link tham khảo code trong đó có sử dụng ranking answer để trả về dựa trên tập input là các bộ câu hỏi và câu trả lời ạ.
#nlp_study","['#Q&A', '#nlp']","['chào', 'xây dựng', '1', 'retrivalbased', 'chatbot', 'đơn giản', '1', 'link', 'tham khảo', 'code', 'ranking', 'answer', 'dựa', 'tập', 'input', 'câu']"
258,"Xin sách hay kênh Youtube hướng dẫn Python từ cơ bản đến nâng cao.
Cảm ơn mọi người.
#py_share","['#Q&A', '#python']","['sách', 'kênh', 'youtube', 'hướng', 'python', 'nâng']"
259,"dạ em xin chào mọi người , em đang muốn tìm một số sách tiếng việt về data analyst ấy ạ . Anh / Chị có thể giới thiệu cho em vài cuốn sách hay để học từ căn bản có được ko ạ . Em cảm ơn
#xx_share
#da_book","['#Q&A', '#data']","['chào sách', 'tiếng', 'việt', 'data', 'analyst thể', 'giới thiệu', 'sách', 'học', 'ko']"
260,"Em chào mọi người.
Em có đang làm ĐATN về Image Caption Generation. Em tạo 1 Custom Tokenizer để giới hạn số lượng vocabulary nhưng khi load model để train tiếp thì lại gặp vấn đề bị sai kích thước giữa file checkpoint và model. Em có thử đổi size nhưng có vẻ cách đổi size của em không đúng.
Mọi người có giải pháp nào không ạ? Em cảm ơn.
#nlp_code","['#Q&A', '#cv', '#nlp']","['chào', 'đatn', 'image', 'caption', 'generation', '1', 'custom', 'tokenizer', 'giới hạn', 'vocabulary', 'load', 'model', 'train', 'tiếp', 'sai kích thước', 'file', 'checkpoint', 'model', 'thử', 'đổi', 'size vẻ', 'đổi', 'size', 'giải pháp']"
261,"Two Minute Paper - kênh youtube tóm tắt và review các tin nổi bật về AI trong vòng 5 phút 🔥🔥🔥
Hi các bạn,
Hôm nay mình xin giới thiệu với các bạn 1 kênh Youtube vô cùng nổi tiếng trong cộng đồng AI: Two Minute Paper. 
Kênh Youtube này chuyên về lĩnh vực AI/Machine Learning/Deep Learning. Các video của kênh thường rất ngắn (loanh quanh tầm 5 phút cho mỗi video). Nếu các bạn muốn bản thân luôn được update với những trend cũng thư thông tin mới nhất về AI, mà không muốn đọc quá nhiều, thì kênh này là 1 sự lựa chọn tuyệt vời dành cho các bạn 🥰
Link to Youtube channel: https://www.youtube.com/@TwoMinutePapers
#ai_share #dl_share","['#sharing', '#machine_learning']","['two', 'minute', 'paper', 'kênh', 'youtube tóm', 'tắt', 'review', 'nổi bật', 'vòng', '5', 'phút', 'hi hôm', 'giới thiệu', '1', 'kênh', 'youtube', 'vô', 'nổi tiếng', 'cộng đồng', 'two', 'minute', 'paper', 'kênh', 'youtube', 'chuyên', 'lĩnh vực', 'machine', 'learning', 'deep', 'learning', 'video', 'kênh', 'ngắn', 'loanh quanh', 'tầm', '5', 'phút', 'video thân', 'update', 'trend', 'thư thông', 'đọc', 'kênh', '1', 'lựa', 'tuyệt vời', 'link', 'to', 'youtube', 'channel']"
262,"Dạ em đang có chỗ này khúc mắc mong các huynh đài giúp đỡ, em sử dụng yolov8 + sort để counting people walk in and out, nhưng em không hiểu mấy code của các cao thủ trên github, em chỉ biết làm tới lấy cái center point và khi center point này chạm vào cái line thì + 1, nhưng không biết khi nào in khi nào out, mong các cao thủ giúp đỡ ạ, em cảm ơn !
#cv_code","['#Q&A', '#cv']","['chỗ', 'khúc', 'mắc', 'mong huynh', 'đài', 'giúp đỡ', 'yolov8', 'sort', 'counting', 'people', 'walk', 'in', 'and out', 'mấy', 'code', 'thủ github', 'center', 'point', 'center', 'point', 'chạm', 'line', '1', 'in', 'out', 'mong thủ', 'giúp đỡ']"
263,"Em chào mọi người. Em đã đi làm có 2 năm kn trong lĩnh vực da ( chủ yếu tập trung về phần PowerBi, Sql và 1 chút modeling ). Em có dự định học master về data science và em có dự định nộp và mấy trường bên bờ bắc của nước Mỹ : Boston Uni, Northeastern Uni, Drexel Uni vì những trường đấy có chương trình co-op sẽ tốt cho sau nếu có ý định làm việc ở Mỹ. Không biết ai trong group này đã học va dang ở những trường đấy thì cho em xin feedback về môn học liên quan tới ds hướng NLP hoặc chương trình co-op ạ . Em cảm ơn mọi người
#datascience
#nlp
#master","['#Q&A', '#data']","['chào', 'đi', '2', 'kn', 'lĩnh vực', 'da', 'chủ yếu', 'powerbi', 'sql', '1', 'chút', 'modeling', 'dự định', 'học', 'master', 'data', 'science', 'dự định', 'nộp', 'mấy', 'trường', 'bờ', 'bắc', 'mỹ boston', 'uni', 'northeastern', 'uni', 'drexel', 'uni', 'trường', 'đấy', 'chương trình', 'coop định', 'mỹ group', 'học', 'va dang', 'trường', 'đấy', 'feedback', 'môn học', 'ds', 'hướng', 'nlp', 'chương trình', 'coop']"
264,"Em chào anh Việt và mọi người.
Hiện tại em đang là năm nhất, ngành Data Science. Hiện tại năm nhất mới chỉ học đại cương với giải tích, đại số tuyến tính, ... Thì em có đang tự học Python. Mọi người cho em hỏi là :
1 Trong lúc học Python thì có nên học song song với machine learning hay đợi thành thạo python rồi mới học machine learning ạ
2 Hiện tại mới chỉ năm nhất nhưng em đang có dự định du học sang Pháp ( tại trường em là đại học VIệt Pháp có hỗ trợ học sinh du học sang Pháp) , có bác noà trong này ở bên pháp cho em hỏi về ngành AI bên Pháp có phát triển không ạ .
3 Nếu em định tìm hiểu về chuyên ngành AI kiểu machine learning hoặc deep learning thì em có nên học lên master không ạ hay bằng cử nhân là được rồi ạ
Hiện tại em đang có những câu hỏi như này ạ . Em cảm ơn
#ds_ml #py #dl","['#Q&A', '#machine_learning']","['chào', 'việt', 'ngành', 'data', 'science', 'học', 'đại cương', 'giải tích', 'đại tuyến', 'học', 'python', '1', 'học', 'python học', 'song song', 'machine', 'learning', 'đợi', 'thành thạo', 'python', 'học', 'machine', 'learning', '2', 'dự định', 'du học', 'pháp trường', 'đại học', 'việt pháp', 'học sinh', 'du học', 'pháp', 'noà pháp', 'ngành pháp', 'phát triển', '3', 'định', 'chuyên ngành', 'kiểu', 'machine', 'learning', 'deep', 'learning', 'học', 'master', 'cử nhân']"
265,"Mình mới bắt đầu học python, mọi người cho mình hỏi là học python cho việc phân tích dữ liệu nên chọn IDEs nào là tốt nhất ạ ? #py","['#Q&A', '#python']","['học', 'python học', 'python', 'phân tích liệu', 'ides']"
266,"21 paper về Machine Learning được trích dẫn nhiều nhất từ trước đến giờ 🔥🔥🔥
Hi các bạn,
Quay về thời điểm năm 2015 - thời mình bắt đầu học về AI. Lúc đó AI/Machine Learning/Deep Learning chưa bùng nổ và phát triển mạnh mẽ như bây giờ. Thời đó trong 1 năm chỉ có vài chục paper đáng chú ý được công bố. Tuy nhiên, các mô hình, kiến trúc, thư viện hay thậm chí là dataset được công bố trong giai đoạn này đã đặt những viên gạch vững chắc cho sự phát triển của AI nói chung và Machine Learning nói riêng sau này (Trust me. I don't overstate it 😎)
Các bạn có bao giờ tự hỏi dựa vào đâu để người ta đánh giá xem 1 paper quan trọng/hữu ích đến mức nào không? 1 trong số các tiêu chí phổ biến nhất đó là dựa vào số lần được trích dẫn (number of citations) trong các paper khác.
Dưới đây là tổng hợp 21 paper về Machine Learning được trích dẫn nhiều nhất. Tất nhiên rồi, trong đó có những cái tên đã quá đỗi nổi tiếng, ví dụ:
Deep Residual Learning for Image Recognition: Chính là nơi mà Resnet cùng với khái niệm residual connection đã quá đỗi nổi tiếng được chào sân đó các bạn 😎
Adam: A Method for Stochastic Optimization: Adam optimizer mà các bạn thấy xuất hiện ở hầu hết các paper về Deep Learning, bên cạnh SGD đó 😎
Random Forests: Các bạn dùng scikit-learn chắc không còn xa lạ gì với model này 😁
Generative Adversarial Nets: Nơi mà GANs - kiến trúc đứng đằng sau sự thành công của rất nhiều ứng dụng mà trong đó không thể không kể đến DeepFake được chào sân
Faster-RCNN: Idol dành cho bài toán object detection vào những năm 2015, cùng với Yolov1 (Có thể các bạn không biết nhưng tác giả 2 model đình đám này là đồng nghiệp 😁)
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift: Nơi mà 1 trong số các layer thú vị bậc nhất trong Deep Learning - Batch Norm được cho ra mắt. Các bạn nếu để ý sẽ thấy Batch Norm được cho ra mắt vào 2015 thì đến 2016 đã có rất rất nhiều model áp dụng layer này 😊
và còn rất nhiều nữa ...
Mình không rõ ngày nay các bạn học AI/Machine learning trên trường như thế nào, nhưng thời của mình các sinh viên (nếu học nghiêm túc) hầu hết ai cũng đọc nát các paper này rồi 😅
Link to article: https://www.doradolist.com/papers/most-cited-papers-in-machine-learning.html
#ml_share","['#sharing', '#machine_learning']","['21', 'paper', 'machine', 'learning', 'trích', 'hi', '2015', 'thời', 'học', 'machine', 'learning', 'deep', 'learning', 'bùng nổ', 'phát triển', 'mẽ', 'thời', '1', 'chục', 'paper', 'công bố nhiên', 'mô hình', 'kiến trúc', 'thư viện', 'chí dataset', 'công bố', 'giai đoạn', 'viên', 'gạch vững', 'phát triển', 'machine', 'learning', 'trust', 'me', 'i', 'don', 't', 'overstate', 'it', 'dựa', 'ta', '1', 'paper', 'hữu ích', '1', 'tiêu chí', 'phổ biến', 'dựa', 'trích', 'number', 'of citations', 'paper', 'tổng hợp', '21', 'paper', 'machine', 'learning', 'trích', 'tất nhiên đỗi', 'nổi tiếng', 'ví dụ', 'deep', 'residual', 'learning', 'for', 'image', 'recognition', 'resnet', 'khái niệm', 'residual', 'connection đỗi', 'nổi tiếng', 'chào sân', 'adam', 'a', 'method', 'for', 'stochastic', 'optimization', 'adam', 'optimizer', 'paper', 'deep', 'learning', 'cạnh', 'sgd', 'random', 'forests', 'scikitlearn', 'lạ', 'model', 'generative', 'adversarial', 'nets gans', 'kiến trúc', 'đứng', 'đằng', 'thành công', 'ứng dụng thể', 'deepfake', 'chào', 'sân', 'fasterrcnn', 'idol toán', 'object', 'detection', '2015', 'yolov1 thể', 'tác giả', '2', 'model', 'đình đám', 'đồng nghiệp', 'batch', 'normalization', 'accelerating', 'deep', 'network', 'training', 'by', 'reducing', 'internal', 'covariate', 'shift', '1', 'layer', 'thú vị', 'bậc', 'deep', 'learning', 'batch', 'norm', 'mắt', 'batch', 'norm', 'mắt', '2015', '2016', 'model', 'áp dụng', 'layer', 'học', 'machine', 'learning', 'trường', 'thời', 'sinh viên', 'học', 'nghiêm túc', 'đọc', 'nát', 'paper', 'link', 'to', 'article']"
267,"Em chào mn trong group ạ.
Em hiện tại đang là sinh viên CNTT và muốn theo AI ạ.
Nên em muốn mọi người tư vấn cho em là lộ trình học như nào và mọi người có thể chỉ cho em vài nguồn để học không ạ
#py#ml","['#Q&A', '#machine_learning']","['chào', 'mn', 'group', 'sinh viên', 'cntt', 'tư vấn', 'lộ trình', 'học thể', 'học']"
268,"Chào mọi người ạ, hiện tại em là sinh viên ngành DS tại một trường đại học, em có một bài tập trong môn học ML, sinh viên được cho một tập dữ liệu,yêu cầu phân tích và đưa ra mô hình học máy phù hợp. Bản thân em đã tự mày mò nhưng vẫn không có hướng giải quyết, em cần một người hướng dẫn cho bài tập trên, phí thương lượng, em xin cảm ơn ạ!
#ml_study","['#Q&A', '#machine_learning']","['chào', 'sinh viên', 'ngành', 'ds', 'trường', 'đại học tập', 'môn học', 'ml', 'sinh viên', 'tập liệu', 'phân tích', 'mô hình', 'học', 'máy thân', 'mày mò', 'hướng', 'giải quyết', 'hướng', 'tập', 'phí', 'thương']"
269,"Nếu bạn là người bắt đầu học về AI từ 2023 thì việc lựa chọn roadmap là điều rất quan trọng, bởi sự bùng nổ của generative AI dẫn đến sự ra đời của hàng loạt công nghệ AI mới mà trong các giáo trình biên soạn trước đây chưa cập nhật. Vì vậy việc theo dõi các kênh thông tin về AI là cực kỳ quan trọng ngoài việc chỉ học theo chương trình trên trường lớp.
Điển hình trong đó mình thấy phần bị bỏ qua khá nhiều là prompt engineering cho LLM
Dưới đây là một roadmap khá hay mình nghĩ các bạn mới nên tham khảo
Video này cũng nêu lên một thực trạng của group: các bạn rất e dè khi hỏi, và đa phần mình thấy là đăng dạng ẩn danh (có lẽ vì sợ người ta biết mình dốt?). Đây là tư duy rất không hay, và các bạn phải tự chủ động thể hiện kiến thức mình ra
Mình nhớ đại loại có một câu nói thế này: Nếu bạn không thể lý giải một vấn đề cho người khác, thì bạn chưa thực sự hiểu vấn đề đó. Vì vậy, hãy luôn mạnh dạn trao đổi và chia sẻ lại cho người khác về những gì mình biết

https://www.youtube.com/watch?v=TR7AGmey1C8
#ai_roadmap","['#sharing', '#machine_learning']","['học', '2023', 'lựa', 'roadmap', 'bùng nổ', 'generative đời', 'hàng loạt', 'công nghệ giáo trình', 'biên soạn', 'cập nhật dõi', 'kênh', 'thông', 'cực kỳ', 'học', 'chương trình', 'trường lớp', 'điển hình', 'prompt', 'engineering', 'llm', 'roadmap', 'tham khảo', 'video', 'nêu', 'thực trạng', 'group', 'e dè', 'đa', 'đăng dạng', 'ẩn danh lẽ', 'sợ', 'ta', 'dốt tư', 'chủ động', 'thể hiện', 'kiến thức', 'đại', 'câu thể', 'lý giải', 'thực dạn', 'trao đổi']"
270,"Em chào mọi người, em đang cần tìm người crawl website sàn tmđt bằng python. Mn cmt r em sẽ ib cho mọi người.
#dsml_study","['#sharing', '#data']","['chào', 'crawl', 'website', 'sàn', 'tmđt', 'python', 'mn', 'cmt', 'r', 'ib']"
271,"Dạ mọi người cho em hỏi với ạ. Em mới học đến mạng neural. Em thắc mắc là làm sao để mình biết cách chọn số lớp ẩn và số neural cho từng lớp ẩn phù hợp với bài toán ạ. Em cảm ơn mọi người.
#ml_study","['#Q&A', '#deep_learning']","['học', 'mạng', 'neural', 'thắc mắc', 'lớp', 'ẩn neural', 'lớp', 'ẩn toán']"
272,"E chào mọi người ạ. Em có đang crawl data trên web bằng selenium. Khi em crawl dữ liệu từ nhiều page thì đến page thứ 2 nó block em như này ạ: (
Mọi người cho em xin cách có thể xử lý trường hợp này với :<
#xx_code","['#Q&A', '#data']","['e', 'chào crawl', 'data', 'web', 'selenium', 'crawl liệu', 'page', 'page', '2', 'block thể', 'trường hợp']"
273,"Em chào mọi người trong gr ạ. Em đang muốn làm 1 project nhỏ về nhận diện, phân loại cảm xúc trong văn bản tiếng Việt. Mọi người từng nghiên cứu hay từng làm vấn đề này cho em xin hướng đi với ạ. Tiện cho em hỏi có thư viện nào dùng tốt cho tiếng Việt không ạ. Em cảm ơn!
#nlp_study #nlp_share","['#Q&A', '#nlp']","['chào', 'gr', '1', 'project diện', 'phân cảm', 'xúc văn', 'tiếng', 'việt', 'nghiên cứu', 'hướng', 'đi', 'tiện', 'thư viện', 'tiếng', 'việt']"
274,"Hội tụ như này có nhanh quá không anh em?
#Ml #Dl #python","['#Q&A', '#machine_learning']",['hội tụ']
275,"em chào mọi người và a Việt, hiện tại e cũng vừa complete machine learning, các kiến thức basic như , sx, gt, đstt và bây giờ e muốn chuyển sang deep learning. E cũng tìm qua 1 vài course như coursera hay edx nhưng cái thì mất tiền , hoặc ko có exercise cụ thể nên thành ra chán nản.
mong mọi người có thể chia sẻ lộ trình học , cũng như tài liệu để e có thể học hiệu quả hơn khi học deep learning ạ. E cảm ơn!!!
#ds_ml,#dl,#py","['#Q&A', '#machine_learning']","['chào', 'a việt', 'e complete', 'machine learning', 'kiến thức', 'basic', 'sx', 'gt', 'đstt', 'e deep', 'learning', 'e', '1', 'course', 'coursera', 'edx', 'tiền', 'ko', 'exercise', 'thành', 'chán nản', 'mong thể', 'lộ trình', 'học', 'tài liệu', 'e thể', 'học hiệu', 'học', 'deep', 'learning', 'e']"
276,"Data Science job: Kì vọng vs thực tế 😎
Không thể đúng hơn các bạn ạ 😅
#ds_share","['#sharing', '#data']","['data', 'science', 'job kì vọng', 'vs thể']"
277,"Em chào mọi người ạ. Hiện tại e đang tự học DS và đang thử xây dựng 1 vài mô hình nhỏ nhỏ nhưng gặp 1 vấn đề sau:
Em đang dùng hồi quy để dự đoán charge (Theo mô tả là tiền bảo hiểm đã dùng) dựa vào các biến như age, sex, bmi, children, smoker, region (Children, smoker, region đã được e mã hoá)
Nhưng khi chạy xong thì sai số rất lớn và kết quả dự đoán cũng kh đúng. Em muốn nhờ anh chị giải thích tại sao lại như thế và có cách nào khắc phục không ạ?
Tiện e cũng hỏi luôn là biểu đồ Scatter chỉ sử dụng ở 1 biến độc lập và 1 biến phụ thuộc thôi đúng k ạ? Nếu e muốn vẽ biểu đồ phân tán của dữ liệu này thì vẽ như nào ạ?
Bức ảnh 1: là dữ liệu gốc
Bức ảnh 2: Dữ liệu sau khi đã tiền xử lý
Bức ảnh 3: Code chạy hồi quy
Em là newbie mong anh chị giải đáp ạ!
#ds_ml_study","['#Q&A', '#machine_learning', '#data']","['chào', 'e học', 'ds', 'thử', 'xây dựng', '1', 'mô hình', '1', 'hồi', 'quy dự đoán', 'charge', 'mô tả', 'tiền', 'bảo hiểm', 'dựa', 'biến', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'children', 'smoker', 'region', 'e mã', 'hóa', 'chạy', 'xong', 'sai kết', 'dự đoán', 'kh giải', 'khắc phục', 'tiện', 'e biểu đồ', 'scatter', '1', 'biến', 'độc lập', '1', 'biến', 'phụ k', 'e vẽ', 'biểu đồ', 'phân tán liệu', 'vẽ', 'ảnh', '1', 'liệu', 'gốc', 'ảnh', '2', 'liệu', 'tiền', 'ảnh', '3', 'code', 'chạy', 'hồi', 'quy newbie', 'mong', 'giải đáp']"
278,"Dạ em chào các anh chị ạ. Hiện tại em đang học về ResNet nhưng em tìm hiểu mãi vẫn chưa hiểu thật sự resnet là gì ạ. Theo em tìm hiểu được thì resnet giúp giải quyết các vấn đề vanishing gradient. Trong resnet có 2 khái niệm mà em vẫn chưa thể hiểu được là Residual Blocks và Skip Connections (điển hình là cái hình ở dưới). Các anh chị có thể giúp em hiểu bằng cách minh họa một ví dụ cụ thể được không ạ? Em xin cảm ơn rất nhiềuuu 🥰
#dl_study","['#Q&A', '#deep_learning']","['chào học', 'resnet', 'mãi', 'resnet', 'resnet', 'giúp', 'giải quyết', 'vanishing', 'gradient', 'resnet', '2', 'khái niệm thể', 'residual', 'blocks', 'skip', 'connections', 'điển hình', 'hình thể', 'giúp', 'minh họa', 'ví dụ', 'nhiềuuu']"
279,"Xin chào tất cả mọi người ạ
Hiện tại em đang có 1 data tiếng việt không dấu khoảng 100k nhưng không có label. và em đã trích xuất được 10k keyword được coi là các từ hoặc cụm từ được coi là tích cực.
Cho em hỏi giờ làm sao có thể đánh nhãn cho toàn bộ data (cho cả các câu tích cực mà k chứa keyword)
và sau khi đánh nhãn xong thì cho em hỏi mình nên dùng gì để embedding tiếng việt không dấu ạ
Em xin cảm ơn !
#hoidap #tiengvietkhongdau #keyword","['#Q&A', '#data']","['chào', 'tất', '1', 'data', 'tiếng', 'việt', 'dấu', '100', 'k', 'label', 'trích', 'xuất', '10', 'k', 'keyword', 'coi', 'cụm', 'coi', 'tích cực thể', 'đánh', 'nhãn', 'toàn', 'data', 'câu', 'tích cực', 'k', 'chứa', 'keyword', 'đánh', 'nhãn', 'xong', 'embedding', 'tiếng', 'việt', 'dấu']"
280,"Em chào mọi người,
Hiện giờ em đang gấp làm một dự án AI về deep learning ạ.
Em có link github rồi nhưng em đọc source không thể hiểu được được. Em muốn tìm cao nhân chỉ dạy lại và giúp hoàn thiện bài báo cáo theo đúng trình tự ạ :(
Mn có thể ib em để mình thương lượng ạ
Em là sinh viên về ngành khác nhưng trường bắt buộc làm AI 🙁
Mong ad duyệt giúp em
Em cảm ơn ạ
[#ds_help]","['#Q&A', '#deep_learning']","['chào', 'hiện', 'gấp', 'dự án', 'deep', 'learning', 'link', 'github', 'đọc', 'source thể', 'nhân dạy', 'giúp', 'hoàn thiện', 'báo cáo', 'trình', 'mn thể', 'ib thương', 'sinh viên', 'ngành', 'trường', 'bắt buộc', 'mong', 'ad', 'duyệt', 'giúp', 'ds_help']"
281,"Chào mọi người, em năm nay mới học năm nhất nhưng e đã có 1 số kiến thức về DSA vì em cũng dành khá nhiều thời gian để tự nghiên cứu python. Em có định hướng là học về AI thì cho e hỏi là bây giờ e có nên tiếp tục luyện DSA hay là vừa học DSA cũng như học thêm về Machine Learning. Nếu như học thì mng có thể chỉ cho em phương hướng để tự học không ạ vì e cảm thấy nhiều quá mà không biết cái nào cần thiết ạ
#ml_study","['#Q&A', '#machine_learning']","['chào', 'học', 'e', '1', 'kiến thức', 'dsa', 'nghiên cứu', 'python', 'định hướng', 'học', 'e', 'e luyện', 'dsa', 'học', 'dsa', 'học', 'machine', 'learning', 'học', 'mng thể', 'phương hướng', 'học', 'e thiết']"
282,"em có viết lại giải thuật hồi quy đa thức mà sao hàm lỗi nó lại tăng . Em không biết sai chỗ nào hết. MN cho em xin ít ý kiến . 
#py_code","['#Q&A', '#python', '#machine_learning']","['viết', 'giải thuật', 'hồi', 'quy đa', 'thức', 'hàm lỗi', 'sai', 'chỗ', 'mn kiến']"
283,"Em xin chào mọi người, hiện tại em đang là sinh viên năm 2 theo học ngành DS và có ý định chuyển sang Linux vì thấy thú vị và nhiều đàn anh đàn chị và thầy cô sử dụng. Cho em hỏi ngành DS thì Linux lợi thế hơn Windows ở những điểm nào ạ
#ds_study #hoi_dap","['#Q&A', '#data']","['chào', 'sinh viên', '2', 'học', 'ngành', 'ds định', 'linux', 'thú vị', 'đàn', 'đàn', 'thầy', 'ngành', 'ds', 'linux lợi', 'windows']"
284,"Chào mn, mình hiện tại muốn học thêm ML, không phải chuyên ngành của mình. Theo tìm hiểu, mình phải có kiến thức về Toán trước. Mà mình không biết bắt đầu học Toán từ đầu. Xin mn chỉ dẫn lộ trình học Toán ạ. Mình cảm ơn!!
#math_roadmap #ml_roadmap","['#Q&A', '#math']","['chào', 'mn', 'học', 'ml', 'chuyên ngành', 'kiến thức toán', 'học toán', 'đầu mn', 'lộ trình', 'học toán']"
285,"Mọi người ơi
Cho mình hỏi nếu như một mô hình chạy detect 1 object để kiểm đếm thì confusion_matrix như vậy có đưa vào ứng dụng thực tế đc ko ạ
Hay cần phải train lại ạ
Cảm ơn!
#ds_share","['#Q&A', '#machine_learning']","['mô hình', 'chạy', 'detect', '1', 'object', 'kiểm đếm', 'confusion_matrix', 'ứng dụng', 'đc', 'ko', 'train']"
286,"Mình sv ngoài ngành, cụ thể là kiến trúc, mình muốn train 1 instance segmentation model phát hiện tường trên mặt bằng như hình (tường có nhiều độ dày 100, 150, 200, 400,...) đầu ra mong muốn của model phải có bounding box ôm sát tường như hình luôn. Hiện đã có data bản vẽ đã đánh label. Mong ae trong ngành chỉ hướng để build 1 con như vậy cho mình tự vọc vạnh. Mình chỉ thạo mỗi c# với 1 ít python, cảm ơn mn.
.
.
.
#dl_cv_study #hoi_dap #computer_vision #image_processing #deep_learning #instance_segmentation","['#Q&A', '#cv']","['sv', 'ngành', 'kiến trúc', 'train', '1', 'instance', 'segmentation', 'model', 'phát hiện', 'tường', 'mặt', 'hình', 'tường', 'độ', 'dày', '100', '150', '200', '400', 'đầu', 'mong', 'model', 'bounding', 'box', 'ôm', 'sát', 'tường hình', 'hiện', 'data', 'vẽ', 'đánh', 'label', 'mong', 'ae', 'ngành', 'hướng', 'build', '1', 'vọc', 'vạnh', 'thạo', 'c', '1', 'python', 'mn']"
287,"Dạ em xin chào mọi người
Nay em có research về dense clustering thì thấy chỗ này bài viết này nói Mean Shift và Affinity Propagation đều thuộc về dense clustering thì sau khi nghiên cứu cả 2 thuật toán thì em vẫn ko hiểu vì sao nó thuộc loại này. Mong mn giúp đỡ em :))
#ml_study
Link bài viết https://www.analyticsvidhya.com/blog/2023/11/types-of-clustering-algorithms-in-machine-learning/#h-1-dbscan-density-based-spatial-clustering-of-applications-with-noise","['#Q&A', '#machine_learning']","['chào', 'research', 'dense', 'clustering', 'chỗ', 'viết', 'mean', 'shift', 'affinity', 'propagation', 'dense', 'clustering', 'nghiên cứu', '2', 'thuật toán', 'ko', 'mong', 'mn', 'giúp đỡ', 'link', 'viết']"
288,"Xin chào mọi người, em hiện nay đã ra trường từ tháng 6 năm nay ạ. Em trước học về mảng cơ điện tử và bây giờ đang làm về tự động hoá của bên Samsung trên thái nguyên.
Hiện tại em đang muốn định hướng sang mảng Data Analyst rồi từ đó phát triển lên Data Science. Hiện tại em đang học theo 3 phần chính là SQL, Power BI và Python ạ.Lý do em muốn chuyển ngành là vì công ty em cũng đang dần sử dụng một vài thuật toán trong ML, cũng như đang áp dụng nền tảng spotfire - tương tự như Power BI ạ.
Tuy nhiên em đang khá mắc ở mảng Python do cảm giác lượng kiến thức quá rộng và đang ko biết bắt đầu từ đâu và chia lộ trình như nào cho hiệu quả.
Mọi người có thể góp ý cho em một vài lộ trình mà mng thấy hợp lý không ah. Ngoài ra anh chị/bạn nào cũng trong hoàn cảnh giống em có thể cho em xin ít lời khuyên được không ạ. Vì hiện tại đi làm ở bên cty đang có vấn đề chủ chốt là đi làm rất xa và tốn nhiều tgian di chuyển ạ
Em xin chân thành cảm ơn mọi người ạ
#py_study","['#Q&A', '#data']","['chào trường', '6', 'học', 'mảng', 'điện tử động', 'hóa', 'samsung thái', 'nguyên định hướng', 'mảng', 'data analyst', 'phát triển', 'data', 'science', 'học', '3', 'sql', 'power bi', 'python lý', 'ngành', 'công ty', 'dần thuật', 'toán', 'ml', 'áp dụng', 'tảng', 'spotfire', 'tương power', 'bi nhiên', 'mắc', 'mảng', 'python', 'cảm giác', 'kiến thức', 'rộng', 'ko', 'chia', 'lộ trình', 'hiệu thể', 'góp', 'lộ trình', 'mng', 'hợp lý', 'ah', 'hoàn cảnh', 'thể', 'khuyên', 'đi', 'cty', 'chủ chốt', 'đi', 'tốn', 'tgian', 'di chân thành']"
289,"[Python for Data Science Cheatsheet]: Cheatsheet đầy đủ dành cho các Data Scientist đến từ DataCamp 🔥🔥🔥
Đây là Cheatsheet vô cùng nổi tiếng về Python for Data Science đến từ DataCamp - nền tảng học online phổ biến nhất dành riêng cho Data Science. 9 trang của cheatsheet này sẽ tổng quát 9 chủ đề/thư viện/framework sau:
Python basics
Jupyter Notebook
Numpy: Thư viện chuyên về các thao tác với dữ liệu đa chiều
Scipy: Tương tự Numpy nhưng chuyên sâu hơn
Pandas: Framework chuyên về làm việc với dữ liệu dạng bảng
Scikit-Learn: Thư viện chuyên về Machine Learning
Matplotlib: Thư viện chuyên về trực quan hóa dữ liệu
Seaborn: Thư viện xây dựng on top của Matplotlib, nổi tiếng về mặt thẩm mỹ
Bokeh: Thư viện giúp xây dựng những plot tương tác thay vì tĩnh như Matplotlib hay Seaborn
9 pages and that's all 🥰","['#sharing', '#data', '#python']","['python', 'for', 'data', 'science', 'cheatsheet', 'cheatsheet', 'data', 'scientist', 'datacamp', 'cheatsheet', 'vô', 'nổi tiếng', 'python', 'for', 'data', 'science', 'datacamp tảng', 'học', 'online', 'phổ biến', 'data', 'science', '9', 'trang cheatsheet', 'tổng quát', '9', 'chủ đề', 'thư viện', 'framework', 'python', 'basics', 'jupyter', 'notebook', 'numpy', 'thư viện', 'chuyên', 'thao tác liệu', 'đa chiều', 'scipy', 'tương numpy', 'chuyên sâu', 'pandas', 'framework', 'chuyên liệu', 'dạng', 'bảng', 'scikitlearn', 'thư viện', 'chuyên machine', 'learning', 'matplotlib', 'thư viện', 'chuyên', 'trực quan', 'hóa liệu', 'seaborn', 'thư viện', 'xây dựng', 'on', 'top', 'matplotlib', 'nổi tiếng', 'mặt', 'thẩm mỹ', 'bokeh', 'thư viện', 'giúp', 'xây dựng', 'plot', 'tương tác', 'thay', 'tĩnh matplotlib', 'seaborn', '9', 'pages and', 'that', 's', 'all']"
290,"Chia sẻ một demo nho nhỏ về phương pháp embedding+RAG. Hi vọng sẽ giúp một số bạn mới bắt đầu với LLMs 🧑‍💻
#Chatbot #LLMs #NLP","['#sharing', '#deep_learning']","['demo', 'nho', 'phương pháp', 'embedding rag', 'hi vọng', 'giúp', 'llms']"
291,"Em chào mọi người ạ.
Em muốn xử lí đa luồng camera dùng chung 1 model yolo thì nên xử lí như nào ? (giả sử ở đây là 2 cam, em dùng luồng cam rtsp nên độ delay sẽ rõ hơn:>)
Dưới đây là cách em nghnghĩ:
Đầu tiên cách 1 là việc xử lí tuần tự là từng cam đọc ảnh và dùng yolo xử lí luôn thì dùng 2 cam sẽ delay tầm 8s so với hành động thực tế bên ngoài
Cách 2 em làm là tạo 2 luồng camera để đọc riêng, và luồng chính là duyệt từng camera lấy frame mới nhất của luồng đó và áp dụng yolo cho từng frame đó. Cách này thì nó sẽ delay tầm 2s, nhưng mà em cảm thấy nó không hiệu quả tối ưu về sử dụng hết đa luồng:>
Cách 3 thì nó có lỗi gì đó. Em sử dụng là như cách cho mỗi luồng đọc thì xử lí luôn ảnh, thì nó lag gì đó, không cv2 imshow ra được ouput để xem, log thì có hiển thị:>
Cách 4 là dùng mỗi model cho 1 luồng xử lí nhưng em cũng gặp lỗi :>, không biết có phải do em code sai xử lí đa luồng không. Cách code thì như ảnh dưới ở main thì khởi tạo 2 luồng rồi mỗi luồng tạo model, và xử lí ảnh tương ứng.
Còn theo mong muốn output của em là kiểu sử dụng hết các luồng xử lí liên tục, do 2 luồng khác dùng luồng cam khác nhau nên chắc không cần cho luồng nghỉ. Có thể khởi tạo mỗi model cho mỗi luồng tránh xung đột:> nhưng chung 1 model thì càng tốt ạ.
Cho em xin 1 số lời khuyên hay docs nào về các vấn đề liên quan ạ::.Em xin cảm ơnn
#cv_code
#py_code","['#Q&A', '#deep_learning', '#cv']","['chào', 'xử lí', 'đa luồng', 'camera', '1', 'model', 'yolo', 'xử lí', 'giả sử', '2', 'cam luồng', 'cam', 'rtsp', 'độ', 'delay', 'nghnghĩ', '1', 'xử lí', 'cam', 'đọc', 'ảnh', 'yolo', 'xử lí', '2', 'cam delay', 'tầm', '8', 's', 'hành động', '2', '2', 'luồng', 'camera', 'đọc', 'luồng', 'duyệt', 'camera', 'frame luồng', 'áp dụng', 'yolo', 'frame', 'delay', 'tầm', '2', 's hiệu', 'tối ưu', 'đa luồng', '3', 'lỗi', 'luồng', 'đọc', 'xử lí', 'ảnh', 'lag', 'cv2', 'imshow', 'ouput', 'log', 'hiển thị', '4', 'model', '1', 'luồng', 'xử lí', 'lỗi', 'code', 'sai', 'xử lí', 'đa luồng', 'code', 'ảnh', 'main khởi', '2', 'luồng', 'luồng', 'model', 'xử lí', 'ảnh', 'tương ứng', 'mong output', 'kiểu', 'luồng', 'xử lí', 'liên tục', '2', 'luồng', 'luồng', 'cam luồng', 'nghỉ thể', 'khởi model', 'luồng', 'xung đột', '1', 'model', '1', 'khuyên', 'docs cảm', 'ơnn']"
292,"Em xin chào anh Việt và mọi người ạ !
Em hiện là sinh viên năm 2 ngành AI tại một trường đại học tầm trung ở Việt Nam, sau một năm nhìn lại thì thực sự em nhận thấy mình không tích lũy được kiến thức gì nhiều.
Vừa rồi em có tham gia một hội thảo khoa học, nơi mà các diễn giả sẽ trình bài và bảo vệ paper mà mình đã viết. Thật sự điều đó đã truyền cảm hứng cho em rất nhiều, khi có những diễn giả là các thầy cô thạc sĩ, tiến sĩ, nhưng cũng có những diễn giả chỉ mới là sinh viên còn rất trẻ nhưng họ đã có nền tảng kiến thức vững chắc cùng năng lực nghiên cứu để viết ra những paper về AI. Trước đây, vì đam mê NCKH nên em cũng thử tìm tòi chủ đề cũng như kiến thức để học dần, nhưng những kiến thức em tìm được thì chỉ ở mức biết đoạn code đó làm gì để chép vào thôi ạ.
Vì thế, em muốn xin tư vấn của anh Việt, các anh chị cùng thầy cô về con đường và kiến thức nào để có thể đưa mình đến việc có thể viết được những paper cũng như làm NCKH ạ. Em biết con đường này rất khó khăn, nhưng em sẽ cố gắng tìm tòi và mong mọi người giúp đỡ ạ.
Em xin cảm ơn mọi người nhiều vì đã dành thời gian ra đọc ạ. Kính chúc mọi người sức khỏe ạ.
#dl_study #dl_roadmap","['#Q&A', '#machine_learning']","['chào việt', 'hiện', 'sinh viên', '2', 'ngành', 'trường', 'đại học', 'tầm', 'trung việt nam', 'thực tích', 'lũy', 'kiến thức', 'tham gia', 'hội thảo', 'khoa học', 'diễn', 'giả trình', 'bảo vệ', 'paper', 'viết', 'truyền', 'cảm hứng', 'diễn', 'giả', 'thầy', 'thạc sĩ', 'tiến sĩ', 'diễn giả', 'sinh viên', 'trẻ tảng', 'kiến thức', 'vững năng lực', 'nghiên cứu', 'viết', 'paper', 'đam mê', 'nckh', 'thử tòi', 'chủ đề', 'kiến thức', 'học', 'dần', 'kiến thức', 'đoạn', 'code chép', 'tư vấn', 'việt', 'thầy', 'đường', 'kiến thức', 'thể thể', 'viết', 'paper', 'nckh', 'đường', 'khăn', 'cố gắng', 'tòi', 'mong', 'giúp đỡ', 'đọc', 'kính chúc', 'sức', 'khỏe']"
293,"Em chào mọi người trong gr ạ. Em bên mobile và muốn lấn qua một chút python NLP một số như làm check đạo văn, hay tóm tắt văn bản ấy ạ. Em có em video trên yt rồi làm theo nhưng không hiểu và video em xem thấy áp dụng cho văn bản tiếng anh còn tiếng việt thì khó tìm. Mọi người có nguồn nào về vấn đề đó đi từ cơ bản đến nâng cao không ạ cho em xin link tài liệu với ạ. Nếu có tài liệu tiếng việt càng tốt ạ. Em rất mong được mọi người mách bảo lộ trình.
Em cảm ơn ạ.
#nlp_study","['#Q&A', '#nlp']","['chào', 'gr', 'mobile', 'lấn', 'chút', 'python', 'nlp', 'check đạo', 'văn tóm', 'tắt', 'văn video', 'yt video', 'áp dụng', 'văn tiếng', 'tiếng', 'việt', 'đi', 'nâng', 'link', 'tài liệu', 'tài liệu', 'tiếng', 'việt', 'mong', 'mách bảo', 'lộ trình']"
294,"chào mọi người, em có một bài toán cần nhờ mọi người giúp đỡ ạ:
Cụ thể là em có 2 tập dữ liệu ảnh có nhiều vật thể, tập 1 là các ảnh chụp nguyên dạng, không bị chỉnh sửa gì, tập 2 là những ảnh đã qua chỉnh sửa, nhiệm vụ của em là phân loại tập ảnh đó và khi mình đưa 1 bức ảnh vào để phân loại thì model phải khoanh vùng những điểm khác nhau của 2 bức ảnh. Bước phân loại thì em đã làm được, em nhờ mọi người gợi ý cho em bước tìm điểm khác việt giữa ảnh gốc và ảnh đã qua chỉnh sửa với ạ
#DL_study","['#Q&A', '#cv']","['chào toán', 'giúp đỡ', '2', 'tập liệu', 'ảnh', 'vật thể', 'tập', '1', 'ảnh', 'chụp', 'nguyên', 'dạng', 'chỉnh sửa', 'tập', '2', 'ảnh', 'chỉnh sửa', 'nhiệm vụ', 'phân tập', 'ảnh', '1', 'ảnh', 'phân model', 'khoanh', '2', 'ảnh', 'phân gợi', 'việt', 'ảnh', 'gốc', 'ảnh', 'chỉnh sửa']"
295,"Chào mọi người trong nhóm, em có được thầy giao cho 1 project làm trong 4 tháng là: ""Tối Ưu Hóa Đường Đi Đa Điểm"" (Multi-Point Route Optimization) có sử dụng google maps API. 
- Mọi người cho em hỏi mình nên sử dụng model nào 
- Có thể share cho em một vài keyword để search và tự học ko ạ. 
- Nếu ai đã có kinh nghiệm từng làm rồi thì có thể cho em xin roadmap để dễ định hướng hơn dc ko ạ.
Cảm ơn mọi người đã bỏ chút thời gian đọc ạ.

#ml_study  #ml_roadmap","['#Q&A', '#machine_learning']","['chào', 'thầy', 'giao', '1', 'project', '4', 'tối ưu hóa', 'đường', 'đi', 'đa multipoint', 'route', 'optimization', 'google', 'maps', 'api', 'model thể', 'share', 'keyword', 'search', 'học', 'ko', 'kinh nghiệm thể', 'roadmap', 'định hướng', 'dc', 'ko', 'chút', 'đọc']"
296,"Toàn thời gian từ xa | Data Scientist 👨 💻
💰 Ưu đãi lên đến 3000$
Trong vai trò này, bạn sẽ làm việc như một thành viên chủ chốt của một đội ngũ phát triển nhanh, tham gia vào tất cả các bước của đường ống MLOps của chúng tôi. Vào một ngày nhất định, bạn có thể tìm thấy mình làm sạch và nhúng tập dữ liệu, nguyên mẫu, điều chỉnh mô hình, quản lý trôi dữ liệu, và lên kế hoạch giải pháp đẳng cấp thế giới cho các vấn đề mới lạ và đa dạng. Thêm vào đó, bạn sẽ cung cấp các phân tích và thuyết trình để thúc đẩy thiết kế sản phẩm và cải thiện cuộc sống của khách hàng.
Hơn 5 năm kinh nghiệm làm việc trong lĩnh vực khoa học dữ liệu, máy học
Tuyệt vời trong giao tiếp tiếng Anh
LỢI ÍCH CỦA CHÚNG TÔI
Tất cả các quyền lợi cần thiết của Luật Lao Động Việt Nam
Lương tháng 13
12+ ngày PTO hàng năm với chính sách giải ngân
Tổng duyệt hiệu suất hàng năm
Ngân sách chăm sóc sức khỏe $3.000 cho mỗi kỹ sư mỗi năm
Trợ cấp làm việc tại nhà
Hỗ trợ giáo dục phổ thông và phát triển kỹ năng
GỬI CV CỦA BẠN:
Email: ttram534@gmail.com
Phone/ Zalo: 0934440301 (Ngọc Trâm)
#DS #Hiring
Được dịch từ Tiếng Anh","['#sharing', '#data']","['toàn', 'data', 'scientist', 'ưu đãi', '3000', 'vai trò', 'thành viên', 'chủ chốt', 'đội ngũ', 'phát triển', 'tham gia', 'tất', 'đường ống', 'mlops', 'định thể', 'sạch', 'nhúng', 'tập liệu', 'nguyên mẫu', 'chỉnh', 'mô hình', 'quản lý', 'trôi liệu', 'kế hoạch', 'giải pháp', 'đẳng giới', 'lạ', 'đa dạng cung', 'phân tích', 'thuyết trình', 'thúc đẩy', 'thiết kế', 'sản phẩm', 'cải thiện', 'sống', 'hàng', '5', 'kinh nghiệm', 'lĩnh vực', 'khoa học liệu', 'máy học', 'tuyệt vời', 'giao tiếp', 'tiếng', 'lợi ích', 'tất quyền lợi', 'thiết luật', 'lao động', 'việt nam', 'lương', '13', '12', 'pto', 'hàng', 'sách', 'giải ngân', 'tổng duyệt', 'hiệu suất', 'hàng', 'ngân sách', 'chăm sóc', 'sức', 'khỏe', '3', '000', 'kỹ sư', 'trợ giáo dục phổ thông', 'phát triển', 'kỹ năng', 'gửi', 'cv', 'email', 'ttram534', 'gmail', 'com', 'phone', 'zalo', '0934440301', 'ngọc trâm', 'dịch', 'tiếng']"
297,"50 thuật toán Machine Learning với project đi kèm 🔥🔥🔥
Hi các bạn,
Hôm nay mình xin chia sẻ với các bạn danh sách 50 thuật toán Machine Learning (thật ra 1 vài trong số này mình sẽ gọi chúng là phương pháp hoặc khái niệm thay vì thuật toán) với Python. Mỗi 1 thuật toán sẽ được đi kèm với 1 project, có source code và giải thích đi kèm 🥰
Ngoài việc học và làm quen với thuật toán thì đây cũng là 1 dịp tốt để chúng ta tìm hiểu các thư viện về Machine Leaning, ngoài những cái tên đã quá đỗi phổ biến như Scikit-learn hay XGBoost 😍
Link to pdf: https://drive.google.com/file/d/1vVsAy1_e046P1dND88dViZmmSZKHoC9r/view?usp=sharing
P/s: Các bạn download file về rồi mới click vào các link được các bạn nhé 😁
#ml_share","['#sharing', '#machine_learning']","['50', 'thuật toán', 'machine', 'learning', 'project', 'đi', 'kèm', 'hi hôm', 'danh sách', '50', 'thuật toán', 'machine', 'learning', '1', 'gọi', 'phương pháp', 'khái niệm', 'thay thuật', 'toán', 'python', '1', 'thuật toán', 'đi', 'kèm', '1', 'project', 'source', 'code', 'giải', 'đi', 'kèm học', 'quen thuật', 'toán', '1', 'dịp', 'ta', 'thư viện', 'machine', 'leaning đỗi', 'phổ biến', 'scikitlearn', 'xgboost', 'link', 'to', 'pdf', 'p', 's', 'download', 'file', 'click', 'link']"
298,"Mình muốn build các UDF (user defined function) trên Excel bằng python nhưng free nha, chứ pyXLL hay xslim thì tốn phí. Anh em có kinh nghiệm xin chỉ giáo.
#pythondeveloper","['#Q&A', '#python']","['build', 'udf', 'user', 'defined', 'function', 'excel', 'python', 'free', 'nha', 'pyxll', 'xslim', 'tốn phí', 'kinh nghiệm', 'giáo']"
299,"Em chào mọi người ạ, hiện tại em đang làm đề tài về Phân loại malware dựa trên hình ảnh bằng CNN, mảng này không phải là chuyên ngành của em nên em đang gặp chút vấn đề cần sự giúp đỡ, anh chị có ai từng làm qua rồi hướng dẫn em với ạ. Em cảm ơn nhiều ạ!
#dl_help","['#Q&A', '#cv', '#deep_learning']","['chào', 'đề tài', 'phân malware', 'dựa', 'hình ảnh', 'cnn', 'mảng', 'chuyên ngành', 'chút', 'giúp đỡ', 'hướng']"
300,"Mình là sinh viên năm nhất, từng học chuyên toán. Gần đây mình có thích thú và tìm hiểu về neural network và đọc được mấy thông tin về liên quan đến mô hình ngôn ngữ lớn như chat gpt từ mấy nguồn cũng khá nhiều view trên các nền tảng kiểu nhu cầu lớn về phần cứng khi chạy training cho ngôn ngữ lớn. Cụ thể là trong học kỳ này mình học các môn như Lý 1, giải tích 1, lập trình cơ bản trên C++, hệ thống số (hay còn gọi là môn kỹ thuật số). Mình muốn hỏi về những phần nào trong những môn học này đang được dùng nhiều vào lĩnh vực của mô hình ngôn ngữ lớn như ChatGPT, bao gồm cả phần cứng và phần mềm.
#other","['#Q&A', '#deep_learning']","['sinh viên', 'học', 'chuyên toán', 'thú', 'neural', 'network', 'đọc', 'mấy', 'thông', 'mô hình', 'ngôn ngữ', 'chat', 'gpt', 'mấy', 'view tảng', 'kiểu', 'nhu cầu', 'cứng', 'chạy', 'training ngôn ngữ', 'học kỳ học', 'môn lý', '1', 'giải tích', '1', 'lập trình', 'c', 'hệ thống', 'gọi', 'môn', 'kỹ thuật', 'môn học', 'lĩnh vực', 'mô hình', 'ngôn ngữ', 'chatgpt bao', 'cứng', 'mềm']"
301,"Em cần tìm 1 người chỉnh code từ source dể đếm người đi ra vào ạ. Làm qua teamviewer hoặc ultra ạ
📷
Sử dụng yolov với point để tạo vùng ra vào ạ
#python #yolov_job","['#Q&A', '#deep_learning']","['1', 'chỉnh', 'code', 'source dể', 'đếm', 'đi', 'teamviewer', 'ultra', 'yolov', 'point']"
302,"Chào mọi người, có cách nào để split một con LLM 7B lên nhiều con gpu trên kaggle không ạ? 
Em đã xem một số hướng dẫn như:
Dùng tensor-parallel thì mặc dù load được lên cả hai GPU thi khi cho model vào Trainer nó vẫn như cũ bị load lại về 1 GPU
Dùng device_map của transformer thì nó chỉ load lên cpu và gpu1, gpu2 bị bỏ qua còn.
Dùng lệnh ""CUDA_VISIBLE_DEVICES=0,1 python3 -m torch.distributed.launch --nproc_per_node=2 trainpy"" thì nó sẽ bị tràn ram em cũng chưa biết được là nó sẽ load lên GPU như thế nào
#Al #question","['#Q&A', '#deep_learning']","['chào', 'split', 'llm', '7', 'b', 'gpu', 'kaggle', 'hướng', 'tensorparallel', 'mặc', 'load', 'hai', 'gpu', 'thi', 'model', 'trainer', 'cũ', 'load', '1', 'gpu', 'device_map', 'transformer', 'load', 'cpu', 'gpu1', 'gpu2', 'lệnh', 'cuda_visible_devices', '0', '1', 'python3', 'm', 'torch', 'distributed', 'launch', 'nproc_per_node', '2', 'trainpy', 'tràn', 'ram', 'load', 'gpu']"
303,"𝐀 𝐬𝐢𝐦𝐩𝐥𝐢𝐟𝐢𝐞𝐝 𝐯𝐢𝐞𝐰 𝐨𝐟 𝐛𝐫𝐚𝐢𝐧 𝐟𝐮𝐧𝐜𝐭𝐢𝐨𝐧 🧠🧠🧠
Hi các bạn,
Với các bạn đang học hay tìm hiểu về AI, chắc các bạn đã từng nghe qua từ Neural Network, hay mạng nơron. Neural Network mô phỏng cách mà não bộ của chúng ta hoạt động. 
Do đó mình tin chắc rằng hiểu rõ cách não bộ chúng ta vận hành sẽ giúp ích cho các bạn trong quá trình học Deep Learning. Mình xin chia sẻ với các bạn hình mô phỏng não bộ phiên bản lược giản 😁
#ai_relax","['#sharing', '#deep_learning']","['hi học', 'neural', 'network mạng', 'nơron', 'neural', 'network', 'mô não', 'ta', 'hoạt động', 'não', 'ta', 'vận hành', 'giúp ích', 'trình', 'học', 'deep', 'learning hình', 'mô não', 'phiên', 'lược giản']"
304,"The incredible Pytorch - danh sách tổng hợp tất cả mọi thứ có liên quan đến Pytorch 🔥🔥🔥
Hi các bạn,
Hôm nay mình xin chia sẻ với các bạn 1 website vô cùng thú vị, tổng hợp tất cả những gì có liên quan đến Pytorch. Từ các tutorials, projects, libraries, videos, papers cho đến books. Tất cả được tổng hợp và update liên tục trong danh sách này. Dù các bạn mới bắt đầu làm quen với Pytorch hay các bạn đã làm việc với Pytorch lâu năm thì các bạn sẽ luôn tìm được tài liệu mình cần trong danh sách này 😎
Link: https://www.ritchieng.com/the-incredible-pytorch/
P/s: Numpy, Scikit-learn và Pytorch vẫn luôn là 3 thư viện quan trọng nhất đối với mình trong suốt những năm tháng học và làm về AI ☺️
#dl_share","['#sharing', '#python']","['the', 'incredible', 'pytorch', 'danh sách', 'tổng hợp', 'tất pytorch', 'hi hôm', '1', 'website', 'vô', 'thú vị', 'tổng hợp', 'tất pytorch', 'tutorials', 'projects', 'libraries', 'videos', 'papers', 'books tất', 'tổng hợp', 'update', 'liên tục', 'danh sách', 'quen', 'pytorch', 'pytorch', 'tài liệu', 'danh sách', 'link', 'https', 'www', 'ritchieng', 'com', 'theincrediblepytorch', 'p', 's', 'numpy', 'scikitlearn', 'pytorch', '3', 'thư viện', 'đối suốt', 'học']"
305,"Data Science and Machine Learning - Mathematical and Statistical Methods : Quyển sách tập trung vào các phương pháp Toán phía sau các mô hình Machine Learning 🔥🔥🔥
Data Science and Machine Learning - Mathematical and Statistical Methods là 1 quyển sách đã được share đi share lại trên rất nhiều các group về Data Science/Machine Learning. Quyển sách này tập trung vào các kiến thức Toán đứng sau các mô hình Machine Learning. Ngoài ra phần xác suất thống kê ở cuối sách là vô cùng cần thiết cho các Data Scientist tương lai
1 điểm thú vị là quyển sách về Toán nhưng code được chèn vào tại tất cả các phần, giúp cho các bạn có thể hình dung được output trông như thế nào
Mình đã đọc qua 1 vài chương của quyển này. Theo đánh giá cá nhân của mình thì kiến thức Toán được trình bày không quá hàn lâm vĩ mô, vẫn nằm trong phạm vi con người có thể hiểu được 😍 
1 trong các đầu sách thầu cả Toán, Data Science và Machine Learning. Rất xứng đáng để các bạn bỏ thời gian ra đọc 🥰
Link to pdf: https://drive.google.com/file/d/1tKCFrLJ3uXo_ybxphErzt0Q9246e3VPX/view?usp=sharing
#ds_ml_share
P/s: Phần Deep Learning có được đá qua 1 chút, nhưng không quá nhiều. Dù sao Deep learning cũng không phải trọng tâm của quyển sách này 😁","['#sharing', '#machine_learning', '#math']","['data', 'science and', 'machine', 'learning mathematical', 'and statistical', 'methods', 'quyển', 'sách', 'phương pháp toán', 'mô hình', 'machine', 'learning', 'data science', 'and machine', 'learning mathematical', 'and', 'statistical', 'methods', '1', 'quyển', 'sách', 'share', 'đi', 'share', 'group', 'data', 'science', 'machine', 'learning', 'quyển', 'sách', 'kiến thức toán', 'đứng', 'mô hình', 'machine', 'learning', 'xác suất', 'thống kê', 'sách', 'vô thiết', 'data', 'scientist', 'tương lai', '1', 'thú vị', 'quyển', 'sách toán', 'code', 'chèn', 'tất', 'giúp thể', 'hình dung', 'output', 'trông', 'đọc', '1', 'chương quyển', 'kiến thức toán', 'trình bày', 'hàn lâm', 'vĩ mô', 'nằm', 'phạm vi thể', '1', 'đầu sách', 'thầu toán', 'data', 'science', 'machine', 'learning xứng', 'đọc', 'link', 'to', 'pdf', 'p', 's', 'deep', 'learning', 'đá', '1', 'chút', 'deep', 'learning trọng tâm', 'quyển', 'sách']"
306,"Mọi người cho mình hỏi về cách triển khai mô hình LSTM vào thực tế với ạ. Ví dụ dự báo thời tiết:
-Ngày hôm nay là ngày n
-Dự báo 7 ngày liền kề sắp tới n+1, n+2,..., n+7
-Như vậy bước qua ngày n+2 thì mô hình mình có cần train lại với dữ liệu thực tế ngày n+1 để dự báo 7 ngày tiếp theo: n+3, n+4,...,, n+9
Cảm ơn!
#ml_share","['#Q&A', '#deep_learning']","['triển khai', 'mô hình', 'lstm', 'ví dụ', 'dự báo', 'thời tiết', 'hôm', 'n', 'dự báo', '7', 'liền', 'kề', 'n', '1', 'n', '2', 'n', '7', 'n', '2', 'mô hình', 'train liệu', 'n', '1', 'dự báo', '7', 'tiếp', 'n', '3', 'n', '4', 'n', '9']"
307,"Cheatsheet 11 trang tổng kết kiến thức Data Science 🔥🔥🔥
Đây là Cheatsheet được thiết kế nhằm giúp các bạn đang học về Data Science muốn hệ thống hóa kiến thức hoặc ôn lại kiến thức nhằm chuẩn bị cho phỏng vấn. Nội dung được tổng kết bao gồm các phần sau:
Data Science là gì?
Các kiểu dữ liệu
Các bài toán chính
Tổng quát về xác suất
Thống kê mô tả
Làm sạch dữ liệu
Feature engineering
Phân tích thống kê
Các phân phối xác suất thông dụng
Modeling
Các mô hình tuyến tính 
Các mô hình phi tuyến
Bài toán phân cụm
Machine Learning 
Deep Learning 
Big Data 
Lý thuyết đồ thị (Phần này cá nhân mình nghĩ các bạn bỏ qua cũng được)
SQL 
Python 
Link to pdf: https://drive.google.com/file/d/1Ct9eWBNz8sTHBa48jPnEi_SiulpInCPa/view?usp=sharing
#ds_share","['#sharing', '#data']","['cheatsheet', '11', 'trang', 'tổng kết', 'kiến thức', 'data', 'science', 'cheatsheet', 'thiết kế', 'giúp', 'học', 'data science', 'hệ thống', 'hóa', 'kiến thức', 'ôn kiến thức', 'chuẩn vấn', 'nội dung', 'tổng kết', 'bao', 'data', 'science', 'kiểu', 'liệu toán', 'tổng quát', 'xác suất', 'thống kê', 'mô tả', 'sạch liệu', 'feature engineering', 'phân tích', 'thống kê', 'phân phối', 'xác suất', 'thông dụng', 'modeling', 'mô hình', 'tuyến', 'mô hình', 'phi', 'tuyến', 'toán', 'phân cụm', 'machine', 'learning', 'deep', 'learning', 'big', 'data', 'lý thuyết', 'đồ thị', 'sql', 'python', 'link', 'to', 'pdf']"
308,"Em chào mọi người ạ.
Em đang là sinh viên và đang nghiên cứu trong lĩnh vực NLP, vì thế nên vấn đề training cũng yêu cầu rất nhiều bộ nhớ Vram. Em đã sử dụng hết Vram của Google Colab hay Kaggle rồi nên em muốn hỏi mọi người cách sử dụng GPU của máy local vào việc training trên jupyter notebook như thế nào ạ?
Em cảm ơn mọi người.
#python #nlp","['#Q&A', '#machine_learning']","['chào', 'sinh viên', 'nghiên cứu', 'lĩnh vực', 'nlp', 'training', 'vram', 'vram', 'google', 'colab', 'kaggle', 'gpu', 'máy', 'local', 'training', 'jupyter', 'notebook']"
309,"Cả nhà ơi ai có kinh nghiệm làm việc với graph neutral network không ạ, em đang tự đọc mà hơi khó hiểu , ai có chút thời gian rảnh và knghiem làm phần này rồi cho em trao đổi nhé. xin cảm ơn và hậu tạ
#ai_question","['#Q&A', '#deep_learning']","['kinh nghiệm', 'graph', 'neutral', 'network', 'đọc', 'hơi', 'chút', 'rảnh', 'knghiem', 'trao đổi', 'hậu tạ']"
310,"Em chào anh chị trong nhóm, em là begginer đang học Python và Pandas để xử lý dữ liệu. Em có cài anaconda vào ổ D vì ổ C của em đã đầy, không đủ space để cài ạ. Khi em input 'pandas as pd' thì hiện ra lỗi là lỗi 'không tìm thấy module' ạ. Trong trường hợp này em nên xử lý như thế nào ạ? Em cảm ơn mn
#py_study","['#Q&A', '#python']","['chào', 'begginer', 'học', 'python', 'pandas liệu', 'cài', 'anaconda', 'ổ d', 'ổ', 'c space', 'cài', 'input', 'pandas', 'as', 'pd', 'hiện', 'lỗi', 'lỗi', 'module', 'trường hợp', 'mn']"
311,"Learn Python The Right Way: Cuốn sách dành cho những bạn mới bắt đầu học lập trình Python 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 quyển sách vô cùng đầy đủ và chi tiết về Python. Quyển sách này rất phù hợp với những bạn mới bắt đầu học Python mà không biết nên bắt đầu từ đâu.
Các bạn có thể download quyển sách để đọc offline hoặc sử dụng giao diện web để đọc online. Mỗi 1 chương đều có hướng dẫn trên Youtube để giải thích chi tiết về cú pháp và chức năng 🤤🤤🤤
Link to the book: https://learnpythontherightway.com/#read
#py_share","['#sharing', '#python']","['learn', 'python', 'the', 'right', 'way', 'sách học', 'lập trình', 'python', 'hi', 'giới thiệu', '1', 'quyển', 'sách', 'vô', 'chi tiết', 'python', 'quyển', 'sách', 'học', 'python thể', 'download', 'quyển', 'sách', 'đọc', 'offline', 'giao diện', 'web', 'đọc', 'online', '1', 'chương', 'hướng', 'youtube', 'giải', 'chi tiết', 'cú pháp', 'chức năng', 'link', 'to', 'the', 'book']"
312,"Dạ em chào mọi người, em hiện đang học về computer vision và có đồ án về thư viện point cloud (PCL). Em đã thử học theo trên mạng và cài nhiều lần nhưng vẫn bị lỗi. Em khẩn thiết mong mọi người ai có tài liệu hướng dẫn cho em xin với ạ :'( Em cảm ơn mọi người nhiều.","['#Q&A', '#cv']","['chào', 'hiện', 'học', 'computer', 'vision', 'đồ án', 'thư viện', 'point', 'cloud', 'pcl', 'thử', 'học mạng', 'cài', 'lỗi', 'khẩn thiết mong', 'tài liệu', 'hướng']"
313,"Two stages object detection
Chào mọi người, mình đang làm một dự án đòi hỏi object detection rất rất nhiều classes và intraclasses - cụ thể là retail items. Mình đã được anh Việt khuyên là nên đi theo hướng two stages , detect bounding box => crop ra feed vô classification model để cho nó chính xác hơn. Mình có tìm hiểu về two stages thì có hai hướng đi mình đang suy nghĩ..
Hướng đi 1: mình có tìm hiểu thấy Faster RCNN hoạt động y như những gì mình miêu tả phía trên, cụ thể là detectron2 . Vậy nên mình tính sử dụng transfer learning để nó learn được những cái classes mà mình mong muốn.
Hướng đi 2: Bởi vì mình biết là YOLO chạy cực nhanh so với faster rcnn, vậy nên mình nghĩ naively là mình sẽ train Yolov8 để detect đúng một class item duy nhất đó là retail item. Rồi dựa trên bounding boxes mà YOLO dự đoán mình sẽ trực tiếp crop hình ảnh ra, và bỏ vào model thứ hai để dự đoán item. Model thứ hai này là một image classification đựa fine tune để classify những items mà mình mong muốn.
Mình mong nhận được suy nghĩ của mọi người về hai hướng đi này và những góp ý..
#object_detection #computer_vision","['#Q&A', '#cv', '#deep_learning']","['two', 'stages', 'object', 'detection', 'chào', 'dự án', 'đòi', 'object', 'detection', 'classes', 'intraclasses', 'retail', 'items', 'việt', 'khuyên', 'đi', 'hướng', 'two', 'stages', 'detect', 'bounding', 'box', 'crop', 'feed', 'vô classification', 'model', 'xác', 'two', 'stages', 'hai', 'hướng', 'đi', 'suy hướng', 'đi', '1', 'faster', 'rcnn', 'hoạt động', 'y', 'miêu tả', 'detectron2', 'transfer', 'learning', 'learn', 'classes', 'mong', 'hướng', 'đi', '2', 'yolo', 'chạy', 'cực', 'faster', 'rcnn', 'naively', 'train', 'yolov8', 'detect', 'class', 'item', 'retail', 'item', 'dựa', 'bounding', 'boxes', 'yolo', 'dự đoán', 'crop', 'hình ảnh', 'model', 'hai', 'dự đoán', 'item', 'model', 'hai', 'image', 'classification', 'đựa', 'fine', 'tune', 'classify', 'items', 'mong', 'mong', 'suy', 'hai', 'hướng', 'đi', 'góp']"
314,"Em chào mọi người,
Hiện giờ em đang gấp làm một dự án AI về deep learning ạ.
Em có link github rùi chỉ cần làm giao diện dựa trên source code đó thôi ạ (giao diện web đơn giản thể hiện được tính năng thôi ạ).
Mn có thể ib em để mình thương lượng ạ
Em là sinh viên về ngành kinh tế nhưng trường bắt buộc làm AI :(
Mong ad duyệt giúp em
Em cảm ơn ạ
#ds_help","['#Q&A', '#deep_learning']","['chào', 'hiện', 'gấp', 'dự án', 'deep', 'learning', 'link', 'github', 'rùi', 'giao diện', 'dựa', 'source', 'code', 'giao diện', 'web', 'đơn giản', 'thể hiện năng', 'mn thể', 'ib thương', 'sinh viên', 'ngành', 'kinh tế', 'trường', 'bắt buộc', 'mong', 'ad', 'duyệt', 'giúp']"
315,"Interactive Machine Learning experiment - Github repository cho phép thực hiện các project Machine Learning tương tác 🔥🔥🔥
Hi các bạn,
Hôm nay mình xin giới thiệu với các bạn 1 Github repository bao gồm các project Machine Learning với phần demo rất đặc biệt, trong đó các bạn có thể tương tác trực tiếp với mô hình thông qua việc lựa chọn dữ liệu đầu vào từ ảnh, video hay thậm chí là từ webcam. Với mỗi 1 project chúng ta sẽ có 2 phần chính:
Jupyter/Colab notebook: Đây là nơi mà model được xây dựng và huấn luyện
Demo page: Đây là nơi mà các bạn có thể tương tác với model trên web browser
Các project ở đây bao gồm cả Neural Network, CNN, RNN và cả GAN nữa
Thật ra đối với cá nhân mình, giá trị lớn nhất của repo này là chúng ta có thể học cách để tạo ra các demo thú vị, nhằm giúp cho các project cá nhân của chúng ta trở nên hấp dẫn hơn thay vì là những dòng lệnh nhàm chán ☺️
Link to Github repo: https://github.com/trekhleb/machine-learning-experiments
#ml_share","['#sharing', '#machine_learning']","['interactive', 'machine', 'learning', 'experiment', 'github', 'repository phép', 'project', 'machine', 'learning', 'tương tác', 'hi hôm', 'giới thiệu', '1', 'github', 'repository', 'bao', 'project', 'machine', 'learning', 'demo thể', 'tương tác', 'mô hình', 'thông', 'lựa liệu', 'đầu ảnh', 'video chí', 'webcam', '1', 'project', 'ta', '2', 'jupyter', 'colab', 'notebook', 'model', 'xây dựng', 'huấn luyện', 'demo', 'page thể', 'tương tác', 'model web', 'browser', 'project', 'bao', 'neural', 'network', 'cnn', 'rnn', 'gan', 'đối repo', 'ta thể', 'học', 'demo', 'thú vị', 'giúp', 'project', 'ta', 'trở hấp', 'thay', 'dòng', 'lệnh', 'nhàm chán', 'link', 'to', 'github', 'repo']"
316,"Làm mới Heatmap truyền thống với hàm relplot() 🔥🔥🔥
Heatmap là 1 trong số các biểu dồ ưa thích của Data Scientist khi chúng ta cần trực quan hóa ma trận tương quan (Correlation matrix)
Nếu các bạn thấy nhàm chán khi dùng mãi Heatmap thông thường, hãy thử biến tấu 1 chút với hàm relplot() của Seaborn. Lúc này Heatmap của các bạn không những được biểu thị bởi màu sắc mà còn được làm nổi bật bởi độ lớn của các vòng tròn (vòng tròn càng lớn thì giá trị tuyệt đối càng cao). Điều này sẽ giúp Heatmap của các bạn trông độc đáo hơn 🥰
#ds_tip","['#sharing', '#data']","['heatmap', 'truyền thống', 'hàm relplot', 'heatmap', '1', 'biểu dồ', 'ưa', 'data', 'scientist', 'ta', 'trực quan', 'hóa', 'ma trận', 'tương quan', 'correlation', 'matrix', 'nhàm chán', 'mãi', 'heatmap', 'thông', 'thử', 'biến tấu', '1', 'chút', 'hàm relplot', 'seaborn', 'heatmap', 'biểu thị', 'màu sắc', 'nổi bật', 'độ', 'vòng tròn', 'vòng tròn', 'tuyệt đối', 'giúp', 'heatmap', 'trông', 'độc đáo']"
317,"Trước con người thì con mèo cũng đã từng bị mất việc vì AI 😅
#relax",['#sharing'],['mèo']
318,"Chào cả nhà,
Nhờ cả nhà chỉ giúp, mình làm hệ thống điểm danh bằng khuôn mặt, nếu làm bằng face recognition thì khá chính các nhưng bị lag, chạy chậm; nếu làm bằng harr cascade thì chạy mượt nhưng không chính xác. Xin mọi người chỉ giúp có thể áp dụng cách nào tốt hơn không ạ
#ml #face_recognition","['#Q&A', '#cv']","['chào', 'giúp', 'hệ thống', 'danh', 'khuôn mặt', 'face', 'recognition lag', 'chạy', 'chậm', 'harr', 'cascade', 'chạy', 'mượt xác', 'giúp thể', 'áp dụng']"
319,"180 Data Science + Machine Learning project với code bằng Python đi kèm với giải thích 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn danh sách gồm 180 project Data Science và Machine Learning với code mẫu bằng Python để các bạn có thể tự xây dựng nên các project cá nhân của mình, nhằm luyện tập cũng như làm đẹp cho Github các nhân. Với mỗi project chúng ta sẽ có:
Giới thiệu về bài toán
Dataset tương ứng (What I love most 🥰)
Code mẫu với Python 
Giải thích từng bước
Các project trong danh sách này vô cùng đa dạng: Computer Vision, NLP, Time-series, Recommendation System, ... nói chung là đủ cả. Việc có ít nhất 1 project ở mỗi mảng sẽ giúp Github của các bạn trở nên đa dạng và hấp dẫn hơn rất nhiều 🥰
Với mình, dataset luôn là thứ quý giá nhất. Với mỗi project ở đây chúng ta sẽ có 1 dataset tương ứng. 1 khi có dataset, thậm chí chúng ta có thể tự xây dựng nên bài toán mà chẳng cần câu hỏi hay bài toán cho trước 😎.
Các bạn có thể tham khảo code để xem người ta phân tích và xử lý bài toán như thế nào, sau đó các bạn hãy thử tự xây dựng mô hình/cách tiếp cận mới của riêng bạn 😁
Link: https://drive.google.com/file/d/1icisrMF9vDlaCuIR-uWDqU1BPJ6L3TVS/view?usp=sharing
#ds_ml_share","['#sharing', '#machine_learning']","['180', 'data', 'science', 'machine', 'learning', 'project', 'code', 'python', 'đi', 'kèm giải', 'hi danh sách', '180', 'project', 'data', 'science', 'machine', 'learning', 'code', 'mẫu', 'python thể', 'xây dựng', 'project', 'luyện tập', 'đẹp', 'github nhân', 'project', 'ta', 'giới thiệu', 'toán', 'dataset', 'tương ứng', 'what', 'i', 'love', 'most', 'code', 'mẫu', 'python', 'giải project', 'danh sách', 'vô', 'đa dạng', 'computer', 'vision', 'nlp', 'timeseries', 'recommendation system', '1', 'project', 'mảng', 'giúp', 'github', 'trở', 'đa dạng', 'hấp dataset', 'quý giá', 'project', 'ta', '1', 'dataset', 'tương ứng', '1', 'dataset chí', 'ta thể', 'xây dựng', 'toán', 'chẳng', 'toán thể', 'tham khảo', 'code', 'ta', 'phân tích', 'toán', 'thử', 'xây dựng', 'mô hình', 'tiếp cận', 'link']"
320,"20 project Natural Language Processing với source code Python + giải thích 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn danh sách 20 project về NLP (Xử lý ngôn ngữ tự nhiên). Đây mặc dù không phải là mảng mà mình chuyên, nhưng những ứng dụng trong mảng này thì vô cùng thú vị, và đại diện tiêu biểu nhất hiện nay chính là ChatGPT 😎
Các project này sẽ giúp cho các bạn có dịp practice cũng như là đẹp profile Github của mình 😁
Link to pdf: https://drive.google.com/file/d/1AMpoGY31brIxgMPfWUX6e4lt8VsW4HAt/view?usp=sharing
P/s: Các bạn cần down về rồi mới click được vào các đường link nha các bạn ☺️
#nlp_share","['#sharing', '#nlp']","['20', 'project', 'natural', 'language', 'processing', 'source', 'code', 'python', 'giải', 'hi danh sách', '20', 'project nlp', 'ngôn ngữ nhiên', 'mặc mảng', 'chuyên', 'ứng dụng', 'mảng', 'vô', 'thú vị', 'đại diện', 'tiêu biểu', 'chatgpt', 'project', 'giúp', 'dịp', 'practice', 'đẹp', 'profile', 'github', 'link', 'to', 'pdf', 'p', 's', 'down', 'click', 'đường', 'link nha']"
321,"Mình làm dự án vision phát hiện bánh bị lỗi ( bị bể hoặc biến dạng khi nướng). Mình đã test qua yolov8-segmentation để tính diện tích của bánh để xác định bánh bị bể, còn trường hợp bánh bị biến dạng nhưng có diện tích giống bánh chuẩn thì mình chưa biết xử lý. Mong mn giúp đỡ
#yolov8-segmentation","['#Q&A', '#cv', '#deep_learning']","['dự án', 'vision', 'phát hiện', 'bánh', 'lỗi', 'bể', 'biến dạng', 'nướng', 'test', 'yolov8segmentation', 'diện tích', 'bánh', 'xác định', 'bánh', 'bể', 'trường hợp', 'bánh', 'biến dạng', 'diện tích', 'bánh chuẩn', 'mong', 'mn', 'giúp đỡ']"
322,"Chào mng, em đang sv năm 4 CNTT chuyên ngành công nghệ phần mềm, vừa rồi trường có tổ chức thực tập, năm nay theo em thấy thì không học các trường top thì đi xin việc hầu như chắc là phải thật giỏi hoặc nhờ ng quen biết giúp đưa vào. Em cũng thuộc loại không phải trường top nên việc thực tập cũng không tìm được công việc liên quan đến lập trình. Lúc đầu em tính theo web ( cụ thể FE) nhưng thị trường năm nay web em cảm giác cạnh tranh cao nên em cũng bắt đầu thích chuyển sang tự học Data Science nhưng em muốn hỏi mọi người thị trường DS tầm 1 năm nữa thì có ổn định job hơn theo đánh giá mng kh ạ hay nên cứ ăn chắc mặc bền thì chọn web cố gắng làm dc cả FE và BE ạ
Em cám ơn admin
#question","['#Q&A', '#data']","['chào', 'mng', 'sv', '4', 'cntt', 'chuyên ngành', 'công nghệ', 'mềm trường', 'tổ chức', 'thực tập', 'học', 'trường', 'top', 'đi', 'hầu giỏi', 'ng', 'quen', 'giúp', 'trường', 'top', 'thực tập', 'công', 'lập trình', 'đầu', 'web fe', 'thị trường', 'web', 'cảm giác', 'cạnh tranh', 'học', 'data science', 'thị trường', 'ds', 'tầm', '1', 'ổn định', 'job', 'mng', 'kh', 'mặc', 'bền web', 'cố gắng', 'dc', 'fe', 'be', 'cám ơn', 'admin']"
323,"Em chào mọi người, em đang tìm hiểu cách crawl data  bằng selenium thì e gặp phải thác mắc sau:

Đầu tiên là phần link sau khi lấy dc thì nó bị trùng nhau
Thứ 2 là chuyển qua trang mới mà ko có nút next để định vị
Cám ơn mọi người rất nhiều

Mong ad duyệt bài giúo em ạ
#python #data #hoidap","['#Q&A', '#data', '#python']","['chào', 'crawl', 'data', 'selenium', 'e thác', 'mắc', 'link', 'dc trùng', '2', 'trang', 'ko', 'nút', 'next', 'định vị', 'cám ơn', 'mong', 'ad', 'duyệt', 'giúo']"
324,"Em chào mọi người ạ, hiện tại em đang phải clone code của project liên quan đến sign language recognition từ research paper và deploy thành web/app (em dự định dùng flask). Mọi người cho em hỏi cần học và làm những gì ạ vì em xem các vid trên youtube thì họ sử dụng file .h5 hay .pkl gì đó thì làm cách nào để tạo ra file đó từ code trên github ạ. Em cảm ơn ạ
#ml_study #ml #dl #cv","['#Q&A', '#python']","['chào', 'clone', 'code', 'project', 'sign', 'language', 'recognition', 'research', 'paper', 'deploy', 'thành', 'web', 'app', 'dự định', 'flask', 'học', 'vid', 'youtube', 'file', 'h5', 'pkl', 'file', 'code', 'github']"
325,"Chào anh Việt và mn,
Em có câu hỏi liên quan đến ""no such file or direction"" ạ. E có tải code ở trên github về và có tạo một virtual environment để chạy nhưng mặt dù đã cho file vào chung một folder và path trên VScode rồi nhưng nó vẫn bị lỗi ko thấy file ạ. Tại lần đầu tiên chạy với venv và dùng code của ngta nên e ko biết có bị miss gì ko? Nhờ mn giải đáp giúp ạ. Em có để link github code bên dưới, ae ai chạy đc thì cho e một ít niềm tin rằng vẫn chạy đc ạ 😂
https://github.com/simensov/ml4ca
#Al #question","['#Q&A', '#python']","['chào', 'việt', 'mn', 'no', 'such', 'file', 'or', 'direction', 'e tải', 'code', 'github', 'virtual', 'environment', 'chạy', 'mặt', 'file', 'folder', 'path', 'vscode', 'lỗi', 'ko', 'file', 'chạy', 'venv', 'code', 'ngta', 'e', 'ko', 'miss ko', 'mn', 'giải đáp', 'giúp', 'link', 'github', 'code', 'ae', 'chạy', 'đc', 'e niềm', 'chạy', 'đc']"
326,"Em chào mọi người! Em thấy trong group cũng có vài bạn đề cập đến chuyện phần cứng khi học deep learning rồi, hiện em thấy có một số cách thường được mọi người dùng nhất bao gồm:
- Google Colab, Kaggle
- Laptop Gaming
- PC với card đồ hoạ
- Laptop có cổng Thunderbolt với eGPU
- Remote desktop
- Thuê Cloud Computing...
Theo mọi người bây giờ nếu em bắt đầu thì cách nào là tối ưu chi phí và hiệu quả nhất ạ?
#dl_laptop #dl_share","['#Q&A', '#deep_learning']","['chào group', 'đề cập', 'cứng học', 'deep', 'learning', 'hiện', 'bao', 'google', 'colab', 'kaggle', 'laptop', 'gaming', 'pc', 'card', 'đồ', 'họa', 'laptop', 'cổng', 'thunderbolt', 'egpu', 'remote', 'desktop', 'thuê', 'cloud', 'computing', 'tối ưu', 'chi phí', 'hiệu']"
327,"Raincloud Plot - kết hợp 3 biểu đồ cùng 1 lúc 🔥🔥🔥
Để trực quan hóa dữ liệu, chúng ta có khá nhiều biều đồ khác nhau, trong đó bao gồm:
Box plot: Được sử dụng cho thống kê dữ liệu
Strip plot: Được sử dụng để cung cấp overview của dữ liệu
KDE plot: Được sử dụng để trực quan hóa phân bố của dữ liệu
Vậy nếu kết hợp cả 3 biểu đồ trên trong 1 biểu đồ duy nhất thì sao ☺️? Thì lúc đó chúng ta có Raincloud Plot. Biểu đồ này giúp chúng ta so sánh giữa các đối tượng 1 cách dễ dàng hơn, cũng như rút ngắn thời gian phân tích dữ liệu 😎
#ds_tip","['#sharing', '#data']","['raincloud', 'plot', 'kết hợp', '3', 'biểu đồ', '1', 'trực quan', 'hóa liệu', 'ta', 'biều đồ', 'bao', 'box', 'plot', 'thống kê liệu', 'strip', 'plot', 'cung', 'overview liệu', 'kde plot', 'trực quan', 'hóa', 'phân bố liệu', 'kết hợp', '3', 'biểu đồ', '1', 'biểu đồ', 'ta', 'raincloud', 'plot', 'biểu đồ', 'giúp', 'ta', 'sánh', 'đối tượng', '1', 'dàng', 'rút', 'ngắn', 'phân tích', 'liệu']"
328,"Làm con game để luyện cài win đi ae
#funny #python",['#sharing'],"['game luyện', 'cài', 'win', 'đi', 'ae']"
329,"150 câu hỏi phỏng vấn Data Science/Machine Learning và đáp án 🔥🔥🔥
Vừa là để chuẩn bị cho phỏng vấn, vừa là để ôn tập lại kiến thức các bạn nha 🥰
Link to pdf: https://drive.google.com/file/d/1ieNBkiW6FT0QsqUXPliDGZk2V7lCXpga/view?usp=sharing
#ds_ml_share","['#sharing', '#machine_learning', '#data']","['150', 'vấn', 'data', 'science', 'machine', 'learning', 'đáp án', 'chuẩn vấn', 'ôn tập', 'kiến thức', 'nha', 'link', 'to', 'pdf']"
330,"Em xin chào các anh chị trong group, e đang là sv năm 2 ngành công nghệ phần mềm. Hiện tại em đang có làm cho mình dự án cá nhân liên quan đến Phishing Detection, cụ thể là giúp client né tránh các URL độc hại. Công nghệ em đang sử dụng là Spring Framework ( JPA, Boot, Security), MySQL. Tuy nhiên với framework trên, e chỉ có thể phân tích URL dựa trên data được store sẵn trong database nên e có suy nghĩ sẽ dựa vào data này train 1 model dự đoán.
Anh chị trong group cho em xin chút ý kiến và kiến thức cần có để hoàn thành khâu này với ạ
Em cảm ơn mọi người
#AI #ask","['#Q&A', '#machine_learning']","['chào', 'group', 'e', 'sv', '2', 'ngành', 'công nghệ', 'mềm', 'dự án', 'phishing', 'detection', 'giúp', 'client', 'né', 'url', 'độc hại', 'công nghệ', 'spring', 'framework', 'jpa', 'boot', 'security', 'mysql nhiên', 'framework', 'e thể', 'phân tích', 'url', 'dựa', 'data', 'store', 'sẵn', 'database', 'e suy', 'dựa', 'data', 'train', '1', 'model', 'dự đoán', 'group', 'chút kiến', 'kiến thức', 'hoàn thành', 'khâu']"
331,"Thay thế Bar plot bằng Dot plot khi có quá nhiều giá trị cần phải trực quan hóa 🔥🔥🔥
Bar plot cực kì hữu hiệu khi chúng ta muốn trực quan hóa dữ liệu với trục hoành là categorical feature và trục tung là continuous value (e.g. trục hoành là các tháng và trục tung là dân số trong các tháng đó). 
Tuy nhiên khi số lượng giá trị categorical quá nhiều (e.g. quá nhiều tháng) thì bar plot sẽ khá là khó nhìn. Lúc này thì hầu như chẳng ai để ý đến độ cao của các cột nữa. Những lúc như vậy Dot plot là 1 sự lựa chọn phù hợp hơn rất nhiều. Đơn giản, dễ theo dõi và đầy đủ thông tin 😎
#ds_tip","['#sharing', '#data']","['thay', 'bar', 'plot', 'dot plot', 'trực quan', 'hóa', 'bar plot', 'cực kì', 'hữu hiệu', 'ta', 'trực quan', 'hóa liệu', 'trục', 'hoành categorical', 'feature', 'trục', 'tung', 'continuous', 'value', 'e g', 'trục', 'hoành trục', 'tung', 'dân nhiên', 'categorical', 'e g', 'bar', 'plot hầu', 'chẳng', 'độ', 'cột', 'dot', 'plot', '1', 'lựa', 'đơn giản dõi', 'thông']"
332,"Em xin chào mọi người. Em đang có một link git đề tài giám sát giao thông bằng yolov5 ứng dụng trên nhưng chưa biết train model và gán nhãn như thế nào để source code hoạt động do em không am hiểu lĩnh vực này . Rất mong được sự giúp đỡ của anh chị ạ , anh chị nào xem và có thể nhận giúp em có trả phí ak . Em xin cảm ơn nhiều !! #python #cv","['#Q&A', '#cv', '#deep_learning']","['chào', 'link', 'git', 'đề tài', 'giám sát', 'giao thông', 'yolov5', 'ứng dụng', 'train', 'model', 'gán', 'nhãn', 'source', 'code', 'hoạt động', 'am lĩnh vực', 'mong', 'giúp đỡ thể', 'giúp', 'phí', 'ak']"
333,"60 project Python với source code đi kèm 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn danh sách 60 project Python đi kèm với mã nguồn, bao gồm:
14 project cơ bản
46 project nâng cao
Chủ đề của các project này rất đa dạng, từ game, app, similator cho đến AI model 😎
Cá nhân mình thì thấy các project cơ bản rất hữu ích cho các bạn mới làm quen với Python. Còn các project nâng cao thì có khoảng 1 nửa trong số này mình nghĩ là có thể sử dụng để làm đẹp cho Github profile của các bạn 🥰
Link: https://drive.google.com/file/d/12qwi2NO09mAYjcoiik5LcHQUnKKQGQcC/view?usp=sharing
#py_share","['#sharing', '#python']","['60', 'project', 'python', 'source', 'code', 'đi', 'kèm', 'hi danh sách', '60', 'project', 'python', 'đi', 'kèm mã', 'bao', '14', 'project', '46', 'project', 'nâng', 'chủ đề', 'project', 'đa dạng', 'game', 'app', 'similator', 'model', 'project', 'hữu ích', 'quen', 'python', 'project', 'nâng', '1', 'nửa thể', 'đẹp', 'github', 'profile', 'link']"
334,"Gửi các bác, mình đang gặp vấn đề với thư viện underthesea như sau:
Khi chạy với Sublime thì vẫn chạy bình thường
Khi xuất ra file exe với Pyinstaller thì báo lỗi như ảnh, hiện tại mình có folder báo thiếu như ảnh dưới tuy nhiên không biết bổ sung vào folder nào, folder temp khi tắt chương trình thì lại mất nên không biết bổ sung vào folder nào.
Các bác xem giúp em, em cảm ơn các bác
#ml_questions","['#Q&A', '#python']","['gửi', 'thư viện', 'underthesea', 'chạy', 'sublime', 'chạy', 'bình xuất', 'file', 'exe', 'pyinstaller', 'báo', 'lỗi', 'ảnh', 'folder', 'báo', 'ảnh nhiên', 'bổ sung', 'folder', 'folder', 'temp', 'tắt', 'chương trình', 'bổ sung', 'folder', 'giúp']"
335,"#dl_code
Mọi người ai đã train PaddleOCR rồi cho e thắc mắc là trước đó e đã train một bộ dataset 2 từ rồi và giờ e lấy model đó train tiếp một tập data khác với số lượng từ dài hơn thì đến lúc eval nó ra như dưới hình ạ. Em xin thêm 2 ảnh làm ví dụ: data train và data eval. Không biết có ai giải đáp cho e là làm sao để khắc phục tình trạng này được không ạ. Em xin cảm ơn.","['#Q&A', '#deep_learning']","['train', 'paddleocr', 'e', 'thắc mắc', 'e', 'train', 'dataset', '2', 'e', 'model', 'train', 'tiếp tập', 'data', 'eval hình', '2', 'ảnh', 'ví dụ', 'data', 'train', 'data', 'eval', 'giải đáp', 'e', 'khắc phục']"
336,"Chia sẻ academic report về Deep Learning của mình 😁
Hi các bạn,
Trong quá trình học ở các trường đại học hay cao đẳng, chắc hẳn các bạn cũng sẽ phải 1 vài lần viết các báo cáo khoa học/học thuật. Mình xin chia sẻ 1 trong số các report mình từng viết trong 1 Practical course tại TU Munich. Cũng không perfect (còn dính 1 vài lỗi râu ria), nhưng dù sao như ông bà ta đã từng nói: Report vô thập toàn. Bạn nào học về Deep Learning thì chắc chắn nhìn tiêu đề của report sẽ thấy vô cùng quen thuộc 😎
Mình chia sẻ ở đây và mong là nó có ích cho các bạn ☺️
Link to pdf: https://drive.google.com/file/d/1A1tpfpuxGHNqhSVRl0W5pwtpcHBIvfgU/view?usp=sharing
#dl_share","['#sharing', '#deep_learning']","['academic', 'report', 'deep learning', 'hi trình', 'học', 'trường', 'đại học', 'đẳng', 'hẳn', '1', 'viết', 'báo cáo', 'khoa học', 'học thuật', '1', 'report', 'viết', '1', 'practical', 'course', 'tu', 'munich', 'perfect', 'dính', '1', 'lỗi', 'râu ria', 'ta', 'report', 'vô thập', 'toàn', 'học', 'deep', 'learning', 'chắn', 'tiêu đề', 'report', 'vô quen', 'mong ích', 'link', 'to', 'pdf']"
337,"Chọn biểu đồ trực quan hóa dữ liệu như thế nào ? 🔥🔥🔥
Hi các bạn,
Với rất nhiều các thư viện về Data Visualization như Matplotlib, Seaborn hay Plotly, ngày nay chúng ta có vài chục sự lựa chọn khác nhau khi muốn trực quan hóa dữ liệu thông qua các biểu đồ. 
Tất nhiên chúng ta không muốn cứ mỗi lần lại show ra hết vào chục biểu đồ cùng một lúc. Câu hỏi đặt ra là, chọn biểu đồ nào?
Tài liệu dưới đây sẽ tóm tắt cách giúp các bạn chọn biểu đồ, dựa vào các thông tin bao gồm:
Kiểu dữ liệu đầu vào
Mục đích truyền tải
Nội dung truyền tải
Ngắn gọn, đơn giản, trực quan là những gì mình có thể nói về tài liệu này 🥰
#ds_share","['#sharing', '#data']","['biểu đồ', 'trực quan', 'hóa liệu', 'hi thư viện', 'data', 'visualization', 'matplotlib', 'seaborn', 'plotly', 'ta', 'chục', 'lựa', 'trực quan', 'hóa liệu', 'thông biểu đồ', 'tất nhiên', 'ta', 'show', 'chục', 'biểu đồ', 'biểu đồ', 'tài liệu', 'tóm tắt', 'giúp', 'biểu đồ', 'dựa', 'thông bao', 'kiểu liệu', 'đầu', 'mục đích', 'truyền tải', 'nội dung', 'truyền tải', 'ngắn gọn', 'đơn giản', 'trực quan thể', 'tài liệu']"
338,"Hello mọi người, Hiện tại em đang làm một đồ án website nhà hàng. Em đã có chức năng gợi ý món theo rating . Mọi người cho em xin vài gợi ý về ML,DL để làm thêm cho đề tài này với ạ. #ml_questions","['#Q&A', '#machine_learning']","['hello', 'đồ án', 'website', 'hàng', 'chức năng', 'gợi', 'món', 'rating', 'gợi', 'ml', 'dl', 'đề tài']"
339,"The little book of Deep Learning - cuốn sách được chắp bút bởi François Fleuret - cha đẻ của thư viện Keras 🔥🔥🔥
Hi các bạn,
Nếu các bạn đã/đang học về Deep Learning, có lẽ các bạn cũng đá từng ít nhất 1 lần nghe đến cái tên Keras. Cùng với Pytorch và Tensorflow thì Keras là 1 trong 3 thư viện Deep Learning phổ biến nhất trên thế giới. Hôm nay mình xin chia sẻ với các bạn quyển sách về Deep Learning được viết bởi cha đẻ của Keras - François Fleuret 🥰
Quyển sách này không có động vào các mô hình đao to búa lớn của Deep Learning, mà chỉ tập trung vào các kiến thức cơ bản nhưng thiết yếu của Deep Learning, bao gồm:
Loss
Gradient
Các layer trong NN/CNN 
Các ứng dụng của DL trong các bài toán cơ bản
Điều mà mình đặc biệt thích ở quyển sách này là nó thực sự chỉ tập chung vào phần cơ bản, thay vì sa đà vào các kiến thức hàn lâm vi mô. Mình rất recommend quyển sách này tới các bạn đang muốn bắt đầu làm quen và tìm hiểu về Deep Learning 😎
Link to pdf: https://drive.google.com/file/d/1Fe65O4lbk4-qu1e7UObK6s_X0uDCf04R/view?usp=sharing
#dl_share","['#sharing', '#deep_learning']","['the', 'little', 'book', 'of deep', 'learning', 'sách', 'chắp bút', 'françois fleuret', 'đẻ', 'thư viện', 'keras', 'hi học', 'deep', 'learning lẽ', 'đá', '1', 'keras', 'pytorch', 'tensorflow', 'keras', '1', '3', 'thư viện', 'deep learning', 'phổ biến giới', 'hôm', 'quyển', 'sách', 'deep learning', 'viết', 'đẻ', 'keras', 'françois', 'fleuret', 'quyển', 'sách động', 'mô hình', 'đao', 'to', 'búa', 'deep learning', 'kiến thức', 'thiết yếu', 'deep', 'learning', 'bao', 'loss', 'gradient', 'layer', 'nn', 'cnn', 'ứng dụng', 'dl toán', 'quyển', 'sách', 'thực tập', 'thay', 'sa đà', 'kiến thức', 'hàn lâm vi', 'mô recommend', 'quyển', 'sách', 'quen', 'deep', 'learning', 'link', 'to', 'pdf']"
340,"Xin chào mọi người ạ,
Chuyện là hiện tại em đang có nghiên cứu và tìm hiểu cho đề tài về ""tìm hiểu các phương pháp nhận dạng và so sánh âm thanh"" thiên hướng về âm nhạc, không biết mọi người có ai có tài liệu, papers (có phần cài đặt code nếu được) hay gợi ý các nguồn hữu ích có thể cho em xin tham khảo và phát triển thêm được không ạ?
Em xin cảm ơn.
#ds_ml_study
 — đang tìm kiếm trợ giúp.","['#Q&A', '#machine_learning']","['chào', 'nghiên cứu', 'đề tài', 'phương pháp', 'dạng', 'sánh âm', 'thiên hướng', 'âm nhạc', 'tài liệu', 'papers', 'cài', 'code gợi', 'hữu ích thể', 'tham khảo', 'phát triển', 'kiếm', 'trợ giúp']"
341,"Em chào mng ạ.
Hiện tại em đang thắc mắc có những cách nào để deploy một Model AI lên thiết bị Android ạ.
Cụ thể ở đây là em có 1 model Emotion detect. Em muốn deploy lên một tablet Samsung. Tablet này sẽ hiển thị một Bump chart về emotion của một lớp học trong từng khoản thời gian. Còn camera sẽ sử dụng một camera khác để quan sát lớp học ạ
Em cảm ơn mng
#ai_question","['#Q&A', '#machine_learning']","['chào', 'mng', 'thắc mắc', 'deploy', 'model', 'thiết android', '1', 'model', 'emotion', 'detect', 'deploy', 'tablet', 'samsung', 'tablet', 'hiển thị', 'bump', 'chart', 'emotion', 'lớp học', 'khoản', 'camera', 'camera', 'quan sát', 'lớp học', 'mng']"
342,"Gần 300 project Machine Learning với sample code bằng Python 🔥🔥🔥
Hi các bạn,
Mình xin chia sẻ với các bạn danh sách gồm gần 300 project Machine Learning với code mẫu bằng Python để các bạn có thể tự xây dựng nên các project cá nhân của mình, nhằm luyện tập cũng như làm đẹp cho Github các nhân. Với mỗi project chúng ta sẽ có:
Giới thiệu về bài toán
Dataset tương ứng
Code mẫu với Python và giải thích từng bước
Giờ mình gợi ý cách các bạn sử dụng danh sách này nhé. Đầu tiên, đối với cá nhân mình, thứ quý giá nhất từ danh sách này không phải là câu hỏi hay code mẫu, mà là dataset. Danh sách này cung cấp cho chúng ta các dataset vô cùng đa dạng, trải rộng ở nhiều mảng khác nhau. 1 khi có dataset, thậm chí chúng ta có thể tự xây dựng nên bài toán mà chẳng cần câu hỏi cho trước. 
Các bạn có thể tham khảo code để xem người ta phân tích và xử lý bài toán như thế nào, sau đó các bạn hãy thử tự xây dựng mô hình/cách tiếp cận mới của riêng bạn. Mình đã xem qua khoảng 20 project trong list này, và code mẫu của người ta chưa phải là tối ưu => there is room for improvement. 
1 điểm cộng của danh sách này, đó là có khá nhiều project có phần trực quan hóa khá ấn tượng 😍
Link to pdf: https://drive.google.com/file/d/1DEzJ0JTwkYLf2GT9Fu4PWwSoEBkn5mD3/view?usp=sharing
#dsml_share","['#sharing', '#machine_learning']","['300', 'project', 'machine', 'learning', 'sample', 'code', 'python', 'hi danh sách', '300', 'project', 'machine', 'learning', 'code', 'mẫu', 'python thể', 'xây dựng', 'project', 'luyện tập', 'đẹp', 'github nhân', 'project', 'ta', 'giới thiệu', 'toán', 'dataset', 'tương ứng', 'code', 'mẫu', 'python', 'giải gợi', 'danh sách', 'đối quý', 'giá', 'danh sách', 'code mẫu', 'dataset', 'danh sách', 'cung', 'ta', 'dataset', 'vô', 'đa dạng', 'trải', 'rộng', 'mảng', '1', 'dataset chí', 'ta thể', 'xây dựng', 'toán', 'chẳng thể', 'tham khảo', 'code', 'ta', 'phân tích', 'toán', 'thử', 'xây dựng', 'mô hình', 'tiếp cận', '20', 'project', 'list', 'code', 'mẫu', 'ta', 'tối ưu there', 'is', 'room', 'for', 'improvement', '1', 'cộng', 'danh sách', 'project', 'trực quan', 'hóa', 'ấn tượng', 'link', 'to', 'pdf']"
343,"Hi mọi người, em vừa kết thúc năm 1 khoá Bachelor of Data Science ở Úc. Hiện tại em đang rất cần tư vấn định hướng tiếp theo cho DS. Năm sau có minor thì e định chọn Cloud Computing vì thấy nó bổ trợ DS nhiều. Các kiến thức e được học qua về toán: statistic, linear algebra. Còn programming thì học qua C++, C# OOP, python và sql.
Em nên chuẩn bị thêm/focus vào mảng nào và có thể làm gì để nổi bật resume ạ vì em muốn xin intern vào hè năm 2.
Nhân tiện đây em cũng cần 1 mentor giỏi, có trả phí tương xứng, am hiểu về thị trường IT úc thì càng tuyệt vời ạ.
Thanks mn đã quan tâm
#ds_study",['#data'],"['hi', 'kết thúc', '1', 'khóa', 'bachelor', 'of data', 'science', 'úc', 'tư vấn', 'định hướng', 'tiếp', 'ds', 'minor', 'e định', 'cloud', 'computing', 'bổ trợ ds', 'kiến thức', 'e', 'học toán', 'statistic', 'linear', 'algebra', 'programming', 'học', 'c', 'c', 'oop', 'python', 'sql', 'chuẩn', 'focus', 'mảng thể', 'nổi bật', 'resume', 'intern', 'hè', '2', '1', 'mentor', 'giỏi', 'phí', 'tương xứng', 'am thị trường', 'it úc', 'tuyệt vời', 'thanks', 'mn']"
344,"Hãy chắc chắn rằng các bạn chỉ học Deep Learning khi đã chắc kiến thức về Machine Learning 😎
Hi các bạn,
Đối với các bạn học về AI, bất kể các bạn tự học, đi học ở các trường đại học, cao đẳng hay học trung tâm ngoài, mặc định là các bạn sẽ luôn được dạy Machine Learning trước rồi đến Deep Learning 😁
Machine Learning thì nhàm chán hơn Deep Learning RẤT RẤT nhiều. Nếu chỉ so sánh riêng về các thuật toán, những Linear/Logistic Regression, SVM hay Random Forest không có 1 cái cửa nào để so sánh với những Neural Network, CNN, RNN hay GAN, cả về kiến trúc cũng như độ hiệu quả 😎
Trong quá trình mình dạy các lớp về Deep Learning, mình có để ý là có không ít bạn chỉ học sơ sơ về Machine Learning rồi nhảy lên học Deep Learning luôn, và hệ quả là kiến thức nền hổng toang hoác 🥹
Machine Learning không chỉ là về thuật toán, mà còn là về data (tiền xử lý dữ liệu, phân chia dữ liệu), đánh giá mô hình (các metrics), regularization, loss và rất rất nhiều thứ khác nữa. Không nắm chắc những kiến thức này mà nhảy vào Deep Learning luôn, các bạn học cũng khổ mà thầy dạy các bạn cũng khổ luôn 😢
Vậy nên hãy chắc chắn rằng mình nắm chắc các kiến thức (tẻ nhạt) của Machine Learning trước khi chuyển lên học về Deep Learning nha các bạn. Yên tâm không thiệt đâu 😊
Các bạn nhìn ở hình bên dưới là 1 ví dụ. Mình chuyên về Deep Learning nhưng thi thoảng vẫn cần làm 1 vài bước sử dụng các mô hình Machine Learning truyền thống ☺️
#ml_advice","['#sharing', '#machine_learning']","['chắn', 'học', 'deep learning', 'kiến thức', 'machine learning', 'hi đối học', 'học', 'đi học', 'trường', 'đại học', 'đẳng học', 'trung tâm', 'mặc định', 'dạy', 'machine', 'learning', 'deep', 'learning', 'machine', 'learning', 'nhàm', 'chán', 'deep', 'learning', 'sánh thuật', 'toán', 'linear', 'logistic', 'regression', 'svm', 'random', 'forest', '1', 'cửa', 'sánh', 'neural', 'network', 'cnn', 'rnn gan', 'kiến trúc', 'độ', 'hiệu', 'trình', 'dạy', 'lớp', 'deep', 'learning học', 'sơ sơ machine', 'learning', 'nhảy học', 'deep', 'learning hệ', 'kiến thức', 'hổng', 'toang hoác', 'machine', 'learning thuật', 'toán', 'data', 'tiền liệu', 'phân chia liệu', 'mô hình', 'metrics', 'regularization', 'loss', 'nắm', 'kiến thức', 'nhảy', 'deep', 'learning', 'học', 'khổ', 'thầy', 'dạy', 'khổ', 'chắn', 'nắm', 'kiến thức', 'tẻ', 'nhạt', 'machine', 'learning', 'học', 'deep', 'learning nha', 'yên tâm', 'thiệt hình', '1', 'ví dụ', 'chuyên', 'deep', 'learning', '1', 'mô hình', 'machine learning', 'truyền thống']"
345,"Tóm tắt nhanh trực quan hóa dữ liệu với Pandas 🔥🔥🔥
Tổng hợp các biểu đồ phổ biến nhất với Pandas và Matplotlib 🥰
Link to pdf: https://drive.google.com/file/d/1WE22XyroFy3TeVqoN79YdbIx-mzzkblg/view?usp=sharing
#ds_share","['#sharing', '#data', '#python']","['tóm tắt', 'trực quan', 'hóa liệu', 'pandas', 'tổng hợp', 'biểu đồ', 'phổ biến', 'pandas', 'matplotlib', 'link', 'to', 'pdf']"
346,"Confusion matrix 🐶🐶🐶🍞🍞🍞
Bài này mình share không phải do nội dung, vì mình đã từng có những post giải thích về Confusion Matrix rồi. Mình share vì thấy nó cute thôi 😁
#ml_share","['#sharing', '#machine_learning']","['confusion', 'matrix', 'share', 'nội dung', 'post', 'giải', 'confusion', 'matrix', 'share', 'cute']"
347,"Tổng hợp các thư viện, framework Machine Learning ở tất cả các ngôn ngữ lập trình 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 Github repository vô cùng thú vị: Awesome Machine Learning 😎
Tại đây, toàn bộ các thư viện và framework về Machine Learning được liên tục tổng hợp và sắp xếp theo ngôn ngữ lập trình. Trước đến giờ chúng ta chủ yếu xài Python khi cần xây dựng các mô hình Machine Learning (hoặc đôi khi là C++ nếu liên quan đến model deployment) ...
Tuy nhiên, cùng với sự phát triển mạnh mẽ của AI trong những năm vừa qua thì Machine Learning cũng đã được mang sang các ngôn ngữ lập trình khác, dù dưới dạng source code, wrapper hay API ☺️
Cấu trúc sẽ được phân tầng như sau các bạn nhé:
Level 1: Ngôn ngữ
Level 2: Mảng ứng dụng/Lĩnh vực
Level 3: Các thư viện, frameworks, tools
1 nguồn All-in-one vô cùng thú vị 🥰
Link to Github repository: https://github.com/josephmisiti/awesome-machine-learning
#ml_share","['#sharing', '#machine_learning']","['tổng hợp', 'thư viện', 'framework', 'machine', 'learning tất ngôn ngữ', 'lập trình', 'hi', 'giới thiệu', '1', 'github repository', 'vô', 'thú vị', 'awesome', 'machine', 'learning', 'toàn', 'thư viện', 'framework', 'machine', 'learning', 'liên tục', 'tổng hợp xếp', 'ngôn ngữ', 'lập trình', 'ta', 'chủ yếu', 'xài', 'python', 'xây dựng', 'mô hình', 'machine', 'learning', 'đôi', 'c', 'model', 'deployment nhiên', 'phát triển', 'mẽ', 'machine learning', 'ngôn ngữ', 'lập trình', 'dạng', 'source', 'code', 'wrapper api', 'cấu trúc', 'phân tầng', 'level', '1', 'ngôn ngữ', 'level', '2', 'mảng', 'ứng dụng', 'lĩnh vực', 'level', '3', 'thư viện', 'frameworks', 'tools', '1', 'allinone', 'vô', 'thú vị', 'link', 'to', 'github', 'repository']"
348,"Chào đón thành viên thứ 15000 🌞🌞🌞
Thú thật mình cũng khá bất ngờ với tốc độ tăng thành viên của group chúng ta. Cùng điểm lại nhé:
03/09: Group của chúng ta được tạo (1 mem là mình 🥲)
20/10: Chúng ta đón thành viên thứ 5000
30/10: Chúng ta đón thành viên thứ 10000
10/11: Chúng ta đón thành viên thứ 15000
Test thử kiến thức về Machine Learning các bạn nhé. Nếu giờ chúng ta xây dựng 1 mô hình Linear Regression để dự đoán số lượng thành viên, với đầu vào là 1 ngày. Data của chúng ta có 4 sample/item như trên. Vậy:
Điểm đầu tiên (x=03/09, y=1) được coi là gì hả các bạn ☺️?
Dựa vào mô hình Linear Regression xây dựng được, các bạn đoán là tầm ngày nào chúng ta sẽ cán mốc 20000 thành viên ?

KEEP SHINING 😎😎😎
#relax",['#sharing'],"['chào đón', 'thành viên', '15000', 'thú', 'tốc độ', 'thành viên', 'group', 'ta', '03', '09', 'group', 'ta', '1', 'mem', '20', '10', 'ta', 'đón', 'thành viên', '5000', '30', '10', 'ta', 'đón', 'thành viên', '10000', '10', '11', 'ta', 'đón', 'thành viên', '15000', 'test', 'thử', 'kiến thức', 'machine', 'learning', 'ta', 'xây dựng', '1', 'mô hình', 'linear', 'regression', 'dự đoán', 'thành viên', 'đầu', '1', 'data', 'ta', '4', 'sample', 'item', 'x', '03', '09', 'y', '1', 'coi', 'hả', 'dựa', 'mô hình', 'linear regression', 'xây dựng', 'đoán', 'tầm', 'ta', 'cán', 'mốc', '20000', 'thành viên', 'keep', 'shining']"
349,"Khóa học lập trình Python cơ bản & nâng cao

Python đang là 1 trong những ngôn ngữ lập trình phổ biến nhất hiện nay. Ứng dụng của Python trải dài từ thiết kế web, phát triển game, và đặc biệt là được ứng dụng trong AI/DS/ML/DL...
Thời gian tới, chúng mình chính thức triển khai các khóa học về lập trình Python, từ cơ bản đến nâng cao. Các khóa học này sẽ dành cho các bạn từ chưa từng tiếp xúc với lập trình bao giờ (khóa cơ bản), đến các bạn đã có kinh nghiệm về lập trình, và muốn tìm hiểu thêm về các thư viện như OpenCV, Pillow, Scikit-learn, Seaborn (khóa nâng cao).
Các bạn quan tâm đến các khóa học này, có thể liên hệ với chúng mình qua Zalo: 0349942449

#py_course","['#sharing', '#python']","['khóa', 'học', 'lập trình', 'python', 'nâng', 'python', '1', 'ngôn ngữ', 'lập trình', 'phổ biến', 'ứng dụng', 'python trải', 'thiết kế', 'web', 'phát triển', 'game', 'ứng dụng', 'ds', 'ml', 'dl thức', 'triển khai', 'khóa học', 'lập trình', 'python', 'nâng', 'khóa', 'học', 'tiếp xúc', 'lập trình', 'khóa', 'kinh nghiệm', 'lập trình', 'thư viện', 'opencv', 'pillow', 'scikitlearn', 'seaborn', 'khóa', 'nâng', 'khóa', 'học thể', 'liên hệ', 'zalo', '0349942449']"
350,"Hi mn, em muốn vẽ đồ thị dạng này trong python và tính được độ lệch của từng điểm dữ liệu thì như nào ạ, mọi người có sample code cho em tham khảo với
#ML","['#Q&A', '#python']","['hi mn', 'vẽ', 'đồ thị', 'dạng', 'python độ', 'lệch liệu', 'sample code', 'tham khảo']"
351,"Hi a e,
Hiện tại mình đang theo course ML/AI/DL/CV advanced của a Việt Nguyễn và dự định sẽ tham gia hết 2 courses chuyên sâu DL/CV của a, mình tìm 1 a e mentor, gia sư tuần 1-2 buổi online (2-3 tiếng) hướng dẫn, sửa bài tập, assignment liên quan đến data statistic, ml, ai trong cả năm 2024. Thù lao trao đổi trực tiếp.
Mô tả: a e đang theo khóa chuyên sâu a Việt Nguyễn ML/AI là ok, tiện cho cả 2 a e, hoặc chuyên ngành ML/ AI các trường năm 2, năm 3, năm 4.
Share cho mọi người cộng đồng trao đổi học tập Prof Andrew Ng, co-founder của coursera và deep learning: https://community.deeplearning.ai/
Có roadmap từ Maths -> ML -> DL cho a e tự nghiên cứu, ngoài ra coursera tài khoản 6 tháng, 1 năm, udemy business thì a e ngoại đạo có thể mua 600k trên này.
Mua Tài khoản Coursera Plus 6 Tháng giá rẻ 2023 (ezkey.vn)
PS: a e để lại cmt hoặc inbox, mình chủ động liên hệ. thanks all
#AI_share #AImentor_job","['#sharing', '#machine_learning']","['hi a', 'e', 'course', 'ml', 'dl', 'cv', 'advanced', 'a việt', 'nguyễn dự định', 'tham gia', '2', 'courses', 'chuyên sâu', 'dl', 'cv a', '1', 'a e', 'mentor', 'gia sư', 'tuần', '12', 'online', '23', 'tiếng', 'hướng', 'sửa', 'tập', 'assignment', 'data', 'statistic', 'ml', '2024', 'thù lao', 'trao đổi', 'mô tả', 'a', 'e khóa', 'chuyên sâu', 'a việt', 'nguyễn ml', 'ok tiện', '2', 'a e', 'chuyên ngành', 'ml', 'trường', '2', '3', '4', 'share', 'cộng đồng', 'trao đổi', 'học tập', 'prof', 'andrew', 'ng', 'cofounder', 'coursera', 'deep', 'learning', 'https', 'community', 'deeplearning', 'roadmap', 'maths', 'ml', 'dl', 'a e', 'nghiên cứu', 'coursera', 'tài khoản', '6', '1', 'udemy', 'business', 'a e', 'ngoại đạo thể', 'mua', '600', 'k', 'mua', 'tài khoản', 'coursera', 'plus', '6', 'giá', 'rẻ', '2023', 'ps', 'a e', 'cmt', 'inbox', 'chủ động', 'liên hệ', 'thanks', 'all']"
352,"Tập đoàn Telekom của Đức tổ chức cuộc thi AI về mảng telecommunications (topics cũng khá rộng và đa dạng), giải nhất lên tới 4 tỉ vnđ 😄 bạn nào thấy thích thì có thể lập team tham gia thử vì nó là global challenge 😁 mình ko được tham gia vì là nhân viên nhưng biết đâu vẫn có thể support lén được 😂
#AI_challenge","['#sharing', '#machine_learning']","['tập đoàn', 'telekom đức', 'tổ chức', 'thi', 'mảng', 'telecommunications', 'topics', 'rộng', 'đa dạng', 'giải', '4', 'tỉ', 'vnđ thể', 'lập', 'team', 'tham gia', 'thử', 'global', 'challenge', 'ko', 'tham gia', 'nhân viên', 'thể', 'support', 'lén']"
353,"Chào mọi người , hiện e đã học khá ổn về kiến thức ML cũng như DL về code thì cũng đã biết chạy rồi nhưng em muốn học sâu 2 framework scikit-learn và pytorch để có thể đi làm , mọi người có thể rcm cho em các nguồn để có thể tự tin nói là khá "" thành thạo"" 2 framework này đc ko ạ ?
#ml_study","['#Q&A', '#machine_learning', '#python']","['chào', 'hiện', 'e học', 'ổn', 'kiến thức', 'ml', 'dl', 'code', 'chạy', 'học', 'sâu', '2', 'framework', 'scikitlearn', 'pytorch thể', 'đi thể', 'rcm thể', 'thành thạo', '2', 'framework', 'đc', 'ko']"
354,"Coding challenge khi đi phỏng vấn xin việc 😎
Mình không biết các bạn có gặp phải tình huống tương tự không. Hồi mình vẫn còn là sinh viên cũng như tầm 1-2 năm đầu khi mới ra trường, khi đi phỏng vấn xin việc và đến đoạn coding challenge, mình rất hay bị kiểu, mình hiểu câu hỏi, thuật toán để giải quyết mình cũng biết. Code thì không khó, nhiều khi dễ hơn bài lúc mình ngồi nhà practice. Cơ mà đúng lúc đấy code thì như gà mắc tóc, thừa cái này, thiếu cái kia. Nói chung toàn lỗi stupid. Mà mình cũng chẳng phải run hay hồi hộp gì cả. Chả hiểu sao ... 😅
#it_relax",['#sharing'],"['coding', 'challenge', 'đi vấn', 'tình huống', 'tương hồi', 'sinh viên', 'tầm', '12', 'đầu', 'trường', 'đi vấn', 'đoạn', 'coding', 'challenge', 'kiểu', 'thuật toán', 'giải quyết', 'code', 'practice', 'đấy', 'code', 'gà', 'mắc', 'tóc', 'thừa', 'kia', 'toàn', 'lỗi', 'stupid', 'run', 'hồi hộp', 'chả']"
355,"Chào anh Việt và mọi người. Hiện tại em đang định mua máy để học AI. Em có kiếm thấy 1 con như trong ảnh. Không biết em nó oke chưa? Hoặc nếu mọi người còn option nào khác thì có thể giới thiệu cho em với được không ạ? Budget em tầm 25-26tr
#xx_laptop",['#Q&A'],"['chào', 'việt định', 'mua', 'máy', 'học', 'kiếm', '1', 'ảnh', 'oke', 'option thể', 'giới thiệu', 'budget', 'tầm', '2526', 'tr']"
356,"MACHINE LEARNING - LUIS G.SERRANO
Hi mọi người và a Việt Nguyễn, hôm qua bận đi học với chạy deadline quá nên chưa đăng bài kịp, sáng nay dậy sớm tranh thủ đăng bài để lên trường. Hôm nay giới thiệu với mọi người cuốn machine learning (Louis G.Serrano) của nhà grokking.

Học cái gì mới thì nguồn tài liệu phong phú và đi từ cái cơ bản luôn rất quan trọng để xây dựng nền tảng và cuốn này đáp ứng được hai điều trên. Các khái niệm luôn được giải thích bằng hình ảnh nên super dễ nắm và đọng lại trong đầu, ngoài ra như bao cuốn khác thì luôn có một repo github đi kèm với sách để cho mọi người tự mò hoặc xem r tự làm theo. Đặc biệt là code của học implement đa số là bằng numpy ( kiểu như from scratch mà ít dùng thư viện á nên mình rất thích do sẽ giúp mọi người nắm bắt thuật toán kỹ hơn là dùng thư viện có sẵn ).
https://drive.google.com/file/d/1JkFhkbyFd7KE66Jyon0LOjfYWrV8MJ16/view?usp=sharing
#dsml_share","['#sharing', '#machine_learning']","['machine', 'learning', 'luis', 'g', 'serrano', 'hi a', 'việt', 'nguyễn hôm', 'bận', 'đi', 'học', 'chạy', 'deadline', 'đăng', 'kịp', 'dậy', 'tranh thủ', 'đăng trường', 'hôm', 'giới thiệu', 'machine', 'learning', 'louis', 'g', 'serrano', 'grokking học', 'tài liệu', 'phong phú', 'đi', 'xây dựng', 'tảng', 'đáp ứng', 'hai', 'khái niệm', 'giải', 'hình ảnh', 'super', 'nắm', 'đọng', 'đầu', 'bao', 'repo', 'github', 'đi', 'kèm', 'sách', 'mò r', 'code', 'học', 'implement', 'đa numpy', 'kiểu', 'from', 'scratch', 'thư viện', 'giúp', 'nắm bắt', 'thuật toán', 'kỹ', 'thư viện', 'sẵn']"
357,"[Hot news] Sử dụng Pandas nhanh gấp 150 lần mà không cần thay đổi code 🔥🔥🔥
Blog mới nhất của NVIDIA ngày hôm kia, 08/11/2023 đã cho ra mắt cuDF- thư viện giúp các bạn có thể thực hiện các hàm của Pandas với tốc độ nhanh gấp 150 lần. Điều đặc biệt là các bạn không phải thay đổi bất kì câu lệnh nào so với khi dùng pandas thông thường. Tất cả những gì các bạn cần làm là thêm vào đầu của script dòng sau:
%load_ext cudf.pandas  
Và sau đó, tất cả mọi thao tác làm việc với Pandas sẽ được hỗ trợ bởi GPU, và tốc độ thì nhanh gấp 150 lần 🤤🤤🤤
cuDF repository: https://github.com/rapidsai/cudf
P/s: Mình đã test thử trên máy mình (Ubuntu, với script Python bình thường chứ ko phải colab). Không được 150 lần nhưng cũng tầm 70-80 lần. Awesome 😎
#dsml_share","['#sharing', '#python']","['hot', 'news', 'pandas', 'gấp', '150', 'code', 'blog', 'nvidia', 'hôm', 'kia', '08', '11', '2023', 'mắt', 'cudf', 'thư viện', 'giúp thể', 'hàm pandas', 'tốc độ', 'gấp', '150', 'câu', 'lệnh', 'pandas thông', 'tất đầu', 'script', 'dòng', 'load_ext', 'cudf', 'pandas', 'tất thao tác', 'pandas', 'gpu', 'tốc độ', 'gấp', '150', 'cudf', 'repository', 'p', 's', 'test', 'thử', 'máy', 'ubuntu', 'script', 'python', 'bình', 'ko', 'colab', '150', 'tầm', '7080', 'awesome']"
358,"Dear mọi người,
Hiện tại mình có thử ML .NET để chạy thử Data Classification thì thấy các Model của ML .NET có accuracy khá tốt như hình. Đậc biệt là FastTreeOva, LightGbmMulti và FastForestOva
Không biết anh em có ai có tài liệu/bài báo/nghiên cứu khoa học về 3 Model này không ạ.
Nếu được cho mình tham khảo với nhe
Cảm ơn all!
#ds_ml_share","['#Q&A', '#machine_learning']","['dear', 'thử', 'ml', 'net', 'chạy', 'thử', 'data', 'classification', 'model', 'ml', 'net', 'accuracy hình', 'đậc biệt', 'fasttreeova', 'lightgbmmulti', 'fastforestova', 'tài liệu', 'báo', 'nghiên cứu', 'khoa học', '3', 'model', 'tham khảo', 'nhe', 'all']"
359,"em đang làm khóa luận về thuật toán CNN dò tìm lưu lượng mạng bất thường dựa trên log. cho em xin hướng giải quyết và cách làm với ạ. em chỉ đang có log thôi. tiện thể cho em xin tài liệu dễ hiểu về CNN với ạ. tại em gv hướng dẫn bắt phải hiểu rõ thuật toán hoạt động như thế nào mới cho làm tiếp. em xin cám ơn ạ.
#dl_study","['#Q&A', '#deep_learning']","['khóa', 'luận thuật toán', 'cnn dò', 'lưu mạng', 'bất dựa', 'log', 'hướng', 'giải quyết', 'log', 'tài liệu', 'cnn', 'gv', 'hướng', 'bắt thuật toán', 'hoạt động', 'tiếp', 'cám ơn']"
360,"Tự động tạo code cho bất kì 1 project AI nào chỉ với 1 vài cú click chuột 🔥🔥🔥
Hi các bạn,
Hôm qua mình vừa được đồng nghiệp giới thiệu cho 1 trang web cực kì thú vị (https://blobcity.com/home) giúp tự động tạo code cho bất kì 1 project AI nào.
Các bạn chỉ cần chọn các thông tin liên quan đến model, data, các bước xử lý, rồi sau đó code sẽ được tự động tạo ra, và các bạn chỉ cần chỉnh sửa 1 chút xíu là đã có được 1 project hoàn chỉnh rồi 🌞
Mình lấy ví dụ, như các bạn có thể nhìn thấy ở hình dưới:
Bước 1: Mình chọn bài toán Classification (Các bạn có thể chọn 1 trong 9 bài toán khác nhau)
Bước 2: Các bạn chọn model (Ví dụ đối với bài toán Classification các bạn có 32 model khác nhau)
Bước 3: Các bạn chọn xem input data của các bạn thuộc loại gì (Các bạn có 4 loại khác nhau)
Bước 4: Các bạn có muốn sử dụng feature selection hay không?
Bước 5: Các bạn có muốn áp dụng tiền xử lý dữ liệu hay không?
Bước 6: Các bạn có muốn balance data hay không?
Bước 7: Nếu bước 6 bạn chọn Yes thì bước này mới tồn tại. Tại bước này các bạn sẽ chọn xem các bạn muốn oversampling, undersampling hay kết hợp cả 2
Bước 8: Các bạn có muốn chuẩn hóa numerical feature hay không?
Bước 9: Các bạn có muốn biến đổi dữ liệu hay không?
Sau khi các bạn chọn xong 9 bước trên, code sẽ tự động được sinh ra cho các bạn. Công việc còn lại của các bạn chỉ đơn giản là lắp data, điền tên của các feature cũng như target, vậy là xong 🥰
Nếu các bạn chọn các bài toán khác (Regression, time-series forecasting), các bước tương ứng sẽ được đưa ra và công việc của các bạn chỉ đơn giản là chọn option cho từng bước là xong 😎
Tuy nhiên, với cá nhân mình, mình khuyên các bạn hãy chỉ sử dụng trang web này nếu các bạn đã thành thạo việc xây dựng các mô hình Machine Learning rồi, và các bạn muốn tiết kiệm thời gian cho các bước code lặp đi lặp lại. Còn nếu các bạn là người mới học thì mình khuyên các bạn không nên lạm dụng trang web này. Vì sao? Vì nó quá đầy đủ. Các bạn sử dụng nó rồi sẽ ỷ lại, và không biết cách tự xây dựng 1 project hoàn chỉnh từ A-Z 😢
#ml_share","['#sharing', '#machine_learning']","['động', 'code', '1', 'project', '1', 'cú', 'click', 'chuột', 'hi hôm', 'đồng nghiệp', 'giới thiệu', '1', 'trang web', 'cực kì', 'thú vị', 'giúp', 'động', 'code', '1', 'project', 'thông model', 'data', 'code động', 'chỉnh sửa', '1', 'chút', 'xíu', '1', 'project', 'hoàn chỉnh', 'ví dụ', 'thể hình', '1', 'toán', 'classification thể', '1', '9', 'toán', '2', 'model', 'ví dụ', 'đối toán', 'classification', '32', 'model', '3', 'input', 'data', '4', '4', 'feature', 'selection', '5', 'áp dụng', 'tiền liệu', '6', 'balance', 'data', '7', '6', 'yes', 'tồn oversampling', 'undersampling', 'kết hợp', '2', '8', 'chuẩn', 'hóa', 'numerical', 'feature', '9', 'biến đổi liệu', 'xong', '9', 'code động', 'sinh công', 'đơn giản', 'lắp', 'data', 'điền feature', 'target', 'xong', 'toán', 'regression', 'timeseries', 'forecasting', 'tương ứng', 'công', 'đơn giản', 'option', 'xong nhiên', 'khuyên', 'trang web', 'thành thạo', 'xây dựng', 'mô hình', 'machine', 'learning', 'tiết kiệm', 'code', 'lặp đi lặp học', 'khuyên', 'lạm dụng', 'trang web', 'ỷ xây dựng', '1', 'project', 'hoàn chỉnh', 'az']"
361,"Chào mn. Mình là sinh viên năm thứ 4 CNTT. Trước mình học định hướng khác nhưng gần đây mình muốn chuyển về làm data. Tuy nhiên kỹ năng về data của mình chưa được mạnh nên đang có ý định theo học course Data Analysis của bên MindX Business. Không biết có ai đã và đang học course này có thể cho mình xin ít review được không ạ? Bên cạnh đó thì mình cũng nhờ ae chia sẻ roadmap cho người khởi đầu muộn như mình cũng như các course mà ae thấy uy tín với ạ. Mình chân thành cảm ơn.
#ds_roadmap #ds_study #ds_share","['#Q&A', '#data']","['chào mn', 'sinh viên', '4', 'cntt', 'học', 'định hướng', 'data nhiên', 'kỹ năng', 'data định', 'học', 'course', 'data', 'analysis mindx', 'business học', 'course thể', 'review', 'cạnh', 'ae', 'roadmap', 'khởi đầu', 'muộn', 'course', 'ae', 'uy tín', 'chân thành']"
362,"Xin chào mọi người !
Em 2k5 , sinh viên năm nhất đang theo học ngành Hệ thống thông tin quản lý ạ . Em đang xác định dần định hướng của mình sẽ phát triển về DA và tìm hiểu rằng làm data cần sử dụng các công cụ phổ biến : SQL, Power BI và PYthon để áp dụng công cụ đó vào việc sắp xếp , lưu trữ , xử lí số liệu ,....Nhưng theo em được biết trên trường sang năm 2 mới dạy Python mà năm nhất  lịch học của e khá rảnh và kiến thức đại cương vẫn nhẹ nhàng nên em muốn tranh thủ thời gian này xuất phát sớm .
Mong được các anh góp ý cho em nên đi theo lộ trình như thế nào , em dự tính học Python và có kênh nào dạy Python bằng tiếng Việt không ạ ?? 
Em cảm ơn mọi người nhiều ! 
#ds_help
#ds_roadmap","['#Q&A', '#data', '#python']","['chào', '2', 'k5', 'sinh viên', 'học', 'ngành', 'hệ thống', 'thông', 'quản lý', 'xác định', 'dần', 'định hướng', 'phát triển', 'da', 'data', 'công cụ', 'phổ biến', 'sql', 'power', 'bi python', 'áp dụng', 'công cụ', 'xếp', 'lưu trữ', 'xử lí liệu', 'trường', '2', 'dạy', 'python', 'lịch học', 'e rảnh', 'kiến thức', 'đại cương', 'nhẹ nhàng', 'tranh thủ', 'xuất phát', 'mong', 'góp', 'đi', 'lộ trình', 'dự học', 'python', 'kênh', 'dạy', 'python', 'tiếng', 'việt']"
363,"mọi người có ứng dụng reinforment learning cho game cờ vua (chess) không cho em xin với ạ :(((
#reinforment_learning","['#Q&A', '#machine_learning']","['ứng dụng', 'reinforment', 'learning', 'game', 'cờ', 'vua', 'chess']"
364,"Chào mọi người, hiện tại mình cần làm nghiên cứu liên quan đến generate ảnh từ 1 từ, 1 câu,... nhưng do trước đó mình k tìm hiểu về domain này nên muốn hỏi mọi người một số paper/research là khung sườn hay fundamentals và các improve của những research này ạ (có code càng tốt). Cám ơn mọi người nhiều ạ
#cv_study
#nlp_study","['#Q&A', '#cv', '#nlp']","['chào', 'nghiên cứu', 'generate', 'ảnh', '1', '1', 'câu', 'k', 'domain', 'paper', 'research', 'khung', 'sườn', 'fundamentals', 'improve', 'research', 'code', 'cám ơn']"
365,"Hiện tại em đang làm 1 prj về Python (Dự đoán lượt bán, giá cổ phiếu,..) và em bị stuck ở phần Crawl data từ website để tạo thành dataset dùng cho các step sau. Mọi người ai avail thì hỗ trợ bọn em với ạ. (có hậu tạ giá sinh viên ạ :<) Em xin cảm ơn mọi người.
#py_study","['#Q&A', '#data', '#python']","['1', 'prj', 'python', 'dự đoán', 'lượt', 'giá', 'cổ phiếu', 'stuck', 'crawl', 'data', 'website', 'thành', 'dataset', 'step', 'avail', 'bọn', 'hậu tạ', 'giá', 'sinh viên']"
366,"#nlp #bert #cnn
Anh Việt và mọi người cho em hỏi về NLP xíu ạ. Vấn đề là em muốn dùng PhoBert để pretrained data rồi sau đó đưa vào mạng CNN. Nhưng em làm mãi vẫn lỗi, anh (chị) giúp em với ạ:

# load PhoBert model
phobert_model_name = ""vinai/phobert-base""
tokenizer_phobert = AutoTokenizer.from_pretrained(phobert_model_name)
phobert_model = AutoModel.from_pretrained(phobert_model_name)
embed_size = phobert_model.config.hidden_size

# add CNN
input = Input(shape=(sequence_length,))
embeddings = phobert_model(input, return_dict=True)
conv_0 = Conv1D(num_filters, filter_sizes[0],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embeddings)
conv_1 = Conv1D(num_filters, filter_sizes[1],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embeddings)
conv_2 = Conv1D(num_filters, filter_sizes[2],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embeddings)
maxpool_0 = MaxPooling1D(sequence_length - filter_sizes[0] + 1, strides=1)(conv_0)
maxpool_1 = MaxPooling1D(sequence_length - filter_sizes[1] + 1, strides=1)(conv_1)
maxpool_2 = MaxPooling1D(sequence_length - filter_sizes[2] + 1, strides=1)(conv_2)
merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)
flatten = Flatten()(merged_tensor)
reshape = Reshape((3*num_filters,))(flatten)
dropout = Dropout(drop)(flatten)
output = Dense(units=3, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)","['#Q&A', '#nlp', '#deep_learning']","['việt', 'nlp xíu', 'phobert', 'pretrained', 'data mạng', 'cnn', 'mãi', 'lỗi', 'giúp', 'load', 'phobert', 'model', 'phobert_model_name', 'vinai', 'phobertbase', 'tokenizer_phobert', 'autotokenizer', 'from_pretrained', 'phobert_model_name', 'phobert_model', 'automodel', 'from_pretrained', 'phobert_model_name', 'embed_size', 'phobert_model', 'config', 'hidden_size', 'add', 'cnn', 'input', 'input', 'shape', 'sequence_length', 'embeddings', 'phobert_model', 'input', 'return_dict', 'true', 'conv_0', 'conv1d', 'num_filters', 'filter_sizes', '0', 'activation', 'relu', 'kernel_regularizer', 'regularizers', 'l2', '0', '01', 'embeddings', 'conv_1', 'conv1d', 'num_filters', 'filter_sizes', '1', 'activation', 'relu', 'kernel_regularizer', 'regularizers', 'l2', '0', '01', 'embeddings', 'conv_2', 'conv1d', 'num_filters', 'filter_sizes', '2', 'activation', 'relu', 'kernel_regularizer', 'regularizers', 'l2', '0', '01', 'embeddings', 'maxpool_0', 'maxpooling1d', 'sequence_length', 'filter_sizes', '0', '1', 'strides', '1', 'conv_0', 'maxpool_1', 'maxpooling1d', 'sequence_length', 'filter_sizes', '1', '1', 'strides', '1', 'conv_1', 'maxpool_2', 'maxpooling1d', 'sequence_length', 'filter_sizes', '2', '1', 'strides', '1', 'conv_2', 'merged_tensor', 'concatenate', 'maxpool_0', 'maxpool_1', 'maxpool_2', 'axis', '1', 'flatten', 'flatten', 'merged_tensor', 'reshape', 'reshape', '3', 'num_filters', 'flatten', 'dropout', 'dropout', 'drop', 'flatten', 'output', 'dense', 'units', '3', 'activation', 'softmax', 'kernel_regularizer', 'regularizers', 'l2', '0', '01', 'dropout']"
367,Mọi người cho em hỏi có tài liệu nào dạy lý thuyết toán của các mô hình machine learning không ạ. Em cảm ơn ạ. #ds_ml_study,"['#Q&A', '#math', '#machine_learning']","['tài liệu', 'dạy lý', 'thuyết toán', 'mô hình', 'machine', 'learning']"
368,"Bộ 3 sách về Machine Learning mà mình đã đọc trong quá trình học ở TU Munich 🔥🔥🔥

Đây là 1 trong số các post hiếm hoi mình chia sẻ về các ebook mà chính mình đã từng học trong quá trình mình học thạc sỹ ngày xưa. Đây là 3 cuốn sách rất nổi tiếng, đặt nền móng cho cơ sở lý thuyết của Machine Learning, mà mình và tất cả các bạn học đều phải đọc trong quá trình học (giáo sư yêu cầu từ buổi đầu chứ không phải sinh viên tự tìm ra mấy quyển này đâu nhé 😅, và không phải chỉ 1 môn mà 3-4 môn các giáo sự đều yêu cầu y chang 3 quyển này 😁)

3 quyển này thì khá là nặng, mình phải nói là như vậy. Bản thân mình thì phải đọc rất nhiều lần mới hiểu được chúng. Cơ mà chúng đi sâu vào ngõ ngách tất cả các khái niệm và bản chất của các thuật toán trong Machine learning, điều mà ít đầu sách khác làm được. Nếu các bạn có thể đọc được 3 cuốn sách này thì thực sự là rất tốt. Còn không thì cũng đừng buồn vì mình sẽ up thêm những đầu sách khác nhẹ nhàng hơn","['#sharing', '#machine_learning']","['3', 'sách', 'machine learning', 'đọc', 'trình', 'học', 'tu munich', '1', 'post', 'hiếm hoi', 'ebook', 'học', 'trình', 'học', 'thạc sỹ', 'xưa', '3', 'sách', 'nổi tiếng', 'móng', 'sở', 'lý thuyết', 'machine', 'learning', 'tất học', 'đọc', 'trình', 'học', 'giáo sư', 'đầu', 'sinh viên', 'mấy', 'quyển', '1', 'môn', '34', 'môn giáo', 'y chang', '3', 'quyển', '3', 'quyển', 'thân', 'đọc', 'đi sâu', 'ngõ ngách', 'tất', 'khái niệm', 'chất thuật', 'toán', 'machine', 'learning', 'đầu', 'sách thể', 'đọc', '3', 'sách', 'thực đừng', 'buồn', 'up', 'đầu sách', 'nhẹ nhàng']"
369,"Tổng hợp các mô hình CNN đáng chú ý trong hơn 30 năm qua 🔥🔥🔥
Hi các bạn,
Mình xin giới thiệu với các bạn 1 bài báo tổng hợp tất cả các mô hình CNN đáng chú ý trong suốt hơn 30 năm vừa rồi. Các mô hình này đã góp phần tạo nên những cột mốc quan trọng trong sự phát triển của Deep Learning trong suốt những năm vừa qua 😎
Link to paper: https://arxiv.org/ftp/arxiv/papers/2004/2004.02806.pdf
Note: Ở đây chỉ đề cập đến các mô hình classification thôi các bạn nhé (ngoại trừ DCGAN). Cũng hợp lý thôi khi hầu hết các mô hình dành cho các bài toán phức tạp hơn đều sử dụng các mô hình classification như là backbone/feature extractor 😎
#dl_share","['#sharing', '#deep_learning']","['tổng hợp', 'mô hình', 'cnn', '30', 'hi', 'giới thiệu', '1', 'báo', 'tổng hợp', 'tất', 'mô hình', 'cnn', 'suốt', '30', 'mô hình', 'góp', 'cột', 'mốc', 'phát triển', 'deep', 'learning', 'suốt', 'link', 'to', 'paper note', 'đề cập', 'mô hình', 'classification', 'ngoại trừ', 'dcgan', 'hợp lý', 'mô hình toán', 'phức tạp', 'mô hình', 'classification', 'backbone', 'feature', 'extractor']"
370,"Mọi người em là sinh viên năm 3 ngành kinh tế nhưng mà lại đả động tới 1 số kiến thức liên quan AI cho môn học mà team em thì không ai biết code thì em có tìm hiểu thì có tham khảo qua link github này https://github.com/cuiaiyu/dressing-in-order và muốn xây dựng 1 trang web demo ứng dụng CNN để dress code đơn giản với input 1 là chọn mẫu ảnh trong tập data có sẵn và input 2 là chọn ảnh áo và output thì sẽ được là 1 ảnh gồm mẫu input1 mặc áo input 2. Em đang chưa biết nên ứng dụng như thế nào và xây dựng web như thế nào mọi người có thể cho em ý tưởng được không ạ ❤️ em cám ơn
#hoibai","['#Q&A', '#deep_learning', '#cv']","['sinh viên', '3', 'ngành', 'kinh tế', 'đả động', '1', 'kiến thức', 'môn học', 'team', 'code', 'tham khảo', 'link github', 'xây dựng', '1', 'trang web', 'demo', 'ứng dụng', 'cnn', 'dress', 'code', 'đơn giản', 'input', '1', 'mẫu', 'ảnh', 'tập', 'data', 'sẵn', 'input', '2', 'ảnh', 'áo output', '1', 'ảnh', 'mẫu', 'input1', 'mặc', 'áo input', '2', 'ứng dụng', 'xây dựng', 'web thể', 'tưởng', 'cám ơn']"
371,"Vì sao ReLU lại được sử dụng trong Neural Network trong khi nó không khả vi ? 🤔🤔🤔
Hi các bạn,
Nếu các bạn đã/đang học về Deep Learning, chắc hẳn các bạn không còn xa lạ gì với các Activation function (hàm kích hoạt) 😁
Trong số các hàm kích hoạt còn được sử dụng phổ biến ngày nay, ReLU và các biến thể của nó chắc chắn là những hàm được biết đến rộng rãi nhất.
ReLU và các biến thể của nó giải quyết được các vấn đề liên quan đến vanishing gradient - điều mà các hàm kích hoạt đời đầu như Sigmoid hay Tanh mắc phải. Như 1 lẽ tất yếu, Sigmoid già thì ReLU mọc
Tuy nhiên, ReLU và hầu hết các biến thể của nó cũng có những vấn đề của riêng mình. 1 trong số đó là việc chúng KHÔNG khả vi (không đạo hàm được, mà cụ thể là tại điểm x = 0). Điều này về mặt lý thuyết là không chấp nhận được, vì: 
Chúng ta tối ưu Neural Network dựa vào Gradient
Gradient được tính thông qua Chain rule (Quy tắc dây chuyền)
Khi 1 mắt xích bất kì trong dây chuyền KHÔNG khả vi thì không thể áp dụng Chain rule => không tính được Gradient nữa 😢
Vậy câu hỏi mình dành cho các bạn hôm nay là: Vì sao ReLU và hầu hết các biến thể của nó không khả vi nhưng vẫn có thể được sử dụng trong Neural Network ? 😎
#dl_question","['#Q&A', '#deep_learning']","['relu', 'neural', 'network', 'khả vi', 'hi học', 'deep', 'learning', 'hẳn', 'lạ activation', 'function', 'hàm kích', 'hoạt hàm kích hoạt', 'phổ biến', 'relu', 'biến thể', 'chắn', 'hàm', 'rộng rãi', 'relu', 'biến thể', 'giải quyết', 'vanishing', 'gradient', 'hàm kích', 'hoạt đời', 'đầu', 'sigmoid', 'mắc', '1', 'lẽ', 'tất yếu', 'sigmoid', 'già', 'relu', 'mọc nhiên', 'relu', 'biến thể', '1', 'khả vi', 'đạo hàm', 'x', '0', 'mặt', 'lý thuyết chấp', 'ta', 'tối ưu neural', 'network', 'dựa', 'gradient', 'gradient', 'thông chain', 'rule', 'quy tắc', 'dây chuyền', '1', 'mắt xích', 'dây chuyền', 'khả vi thể', 'áp dụng', 'chain', 'rule', 'gradient', 'hôm', 'relu', 'biến thể', 'khả vi thể', 'neural', 'network']"
372,"Mình muốn hỏi bạn nào có code chu trình Euler bằng python không cho mình xin với???
#euler","['#Q&A', '#python']","['code', 'chu trình', 'euler', 'python']"
373,"xin chào anh Việt và mọi người, e đang có 1 bài tập cần sử dụng api của chat gpt nhưng e đang gặp vấn đề khi gọi api mong mọi người chỉ em cách khắc phục 
#ml_study",['#Q&A'],"['chào', 'việt', 'e', '1', 'tập', 'api', 'chat', 'gpt', 'e', 'gọi', 'api mong', 'khắc phục']"
374,"Trực quan hóa sự thay đổi thứ hạng trong 1 khoảng thời gian với Bump Chart 🔥🔥🔥
Khi chúng ta muốn trực quan hóa sự thay đổi thứ hạng trong 1 khoảng thời gian, bar chart là 1 sự lựa chọn được nhiều người nhắm đến...
... Tuy nhiên bar chart sẽ trở nên khá rối rắm và khó nhìn khi có quá nhiều category 🥹
Những lúc như vậy, Bump Chart là 1 sự thay thế tuyệt vời. Chúng được thiết kế để có thể trực quan hóa sự thay đổi thứ hạng 1 cách đơn giản và hiệu quả 😎
#ds_tip","['#sharing', '#data']","['trực quan', 'hóa', 'hạng', '1', 'bump', 'chart', 'ta', 'trực quan', 'hóa', 'hạng', '1', 'bar', 'chart', '1', 'lựa', 'nhắm nhiên', 'bar', 'chart', 'trở rối', 'rắm', 'category', 'bump', 'chart', '1', 'thay', 'tuyệt vời', 'thiết kế thể', 'trực quan', 'hóa', 'hạng', '1', 'đơn giản hiệu']"
375,"Em chào mọi người ạ
Cho em hỏi đã có ai học qua các khoá AI của VietAI hoặc AI VietNam chưa và 2 bên có ưu điểm hoặc nhược điểm gì ạ. Nếu em theo DS hoặc NLP thì nên học bên nào.
Em cảm ơn nhiều ạ.
#ds_share #nlp_share",['#Q&A'],"['chào học', 'khóa', 'vietai', 'vietnam', '2', 'ưu nhược', 'ds', 'nlp', 'học']"
376,"chào mọi người hiện tại em đang học chuyên ngành AI của trường, em có tài chính tầm 20tr thì có dạng laptop nào trên thị trường mới cũ thuận tiện cho việc học ko ạ, em có thấy mấy con như razel blade 15 cũ cũng ổn mng có thể tư vấn cho em chọn thêm 1 vài laptop nữa được ko ạ, chắc em chỉ cần nhẹ là ok tại việc đi lại khá nhiều với lại chắc là card rời để train mấy model nhẹ ạ #xxlaptop",['#Q&A'],"['chào học', 'chuyên ngành', 'trường', 'tài tầm', '20', 'tr', 'dạng', 'laptop', 'thị trường', 'cũ', 'thuận tiện', 'học', 'ko', 'mấy', 'razel', 'blade', '15', 'cũ', 'ổn', 'mng thể', 'tư vấn', '1', 'laptop', 'ko', 'nhẹ', 'ok', 'đi', 'card', 'rời', 'train', 'mấy', 'model', 'nhẹ']"
377,"Có a/c làm bài toán object detection xe các loại chưa ạ.
Em đang muốn tìm hiểu xây dựng bài toán này làm project cá nhân (từ tìm kiếm dữ liệu đến xây dựng mô hình và deploy lên web app), a/c nào làm rồi cho em xin gợi ý pipeline giải quyết bài toán này ạ.
Em cảm ơn ạ.
#dl_study","['#Q&A', '#cv']","['a', 'c toán', 'object', 'detection', 'xe', 'xây dựng', 'toán', 'project', 'kiếm liệu', 'xây dựng', 'mô hình', 'deploy web', 'app', 'a c', 'gợi pipeline', 'giải quyết', 'toán']"
378,"Em chào mọi người,
Em có thắc mắc là muốn đọc những paper mới nhất về AI, deeplearning, machinelearning thì mình sẽ đọc ở đâu ạ. Có nguồn nào tổng hợp những paper mới ra mắt hay không ạ.
Em cảm ơn mọi người nhiều lắm.

#dl #py #ml","['#Q&A', '#machine_learning']","['chào', 'thắc mắc', 'đọc', 'paper', 'deeplearning', 'machinelearning', 'đọc', 'tổng hợp', 'paper', 'mắt', 'lắm']"
379,"Em đang tự học Python và có ý định học AI dần. Hiện em đang học cấp 3 thì em có thử tham khảo và dự định học theo Udemy với các khoá sau mn có gợi ý gì giúp em cải thiện không ạ #python #AI
##python","['#Q&A', '#python', '#machine_learning']","['học', 'python định', 'học', 'dần', 'hiện', 'học', '3', 'thử', 'tham khảo', 'dự định', 'học', 'udemy', 'khóa', 'mn', 'gợi', 'giúp', 'cải thiện', 'python']"
380,"Chào mọi người ạ, em đang là sinh viên năm 3. Hiện nay em chỉ mới học ML chứ chưa học đến DL ạ. Vừa rồi thầy cho đề tài báo cáo về 1 model học máy, học sâu nên tụi em đã chọn đề tài Image Captioning. Hiện em có tham khảo qua paper ""An Empirical Study of Language CNN for Image Captioning"" nhưng phần lớn nội dung paper liên quan đến DL nên em không hiểu lắm. Hiện em cần phải học những phần kiến thức nào để hiểu được kiến trúc cũng như cách hoạt động của mô hình ạ? Em xin cảm ơn
#nlp_study","['#Q&A', '#deep_learning']","['chào', 'sinh viên', '3', 'học', 'ml học', 'dl', 'thầy', 'đề tài', 'báo cáo', '1', 'model', 'học', 'máy', 'học', 'sâu', 'tụi', 'đề tài', 'image', 'captioning', 'hiện', 'tham khảo', 'paper', 'an empirical', 'study', 'of language', 'cnn', 'for', 'image', 'captioning', 'nội dung', 'paper dl', 'lắm', 'hiện học', 'kiến thức', 'kiến trúc', 'hoạt động', 'mô hình']"
381,"#dl_code
Em chào mọi người ạ, hiện team tụi em đang thi một track mảng audio và có thắc mắc là transform(transform của tụi em là xuất ra ma trận spectrogram như ở ảnh 2) cho audio tụi em chọn như vầy đã đúng chưa với lại mình nên chọn waveform hay spectrogram để làm input đầu vào cho model để train , ngoài ra còn cách transform nào khác hong ạ. Em cảm ơn mọi người vì đã đọc vấn đề của team em.
Xin lỗi mọi người vì code team em còn hơi lủng củng :(","['#Q&A', '#deep_learning']","['chào', 'hiện', 'team', 'tụi', 'thi', 'track', 'mảng', 'audio', 'thắc mắc', 'transform', 'transform', 'tụi', 'xuất', 'ma trận', 'spectrogram', 'ảnh', '2', 'audio', 'tụi', 'vầy', 'waveform', 'spectrogram', 'input', 'đầu', 'model', 'train', 'transform hong', 'đọc', 'team', 'lỗi', 'code', 'team', 'hơi', 'lủng củng']"
382,"Bữa nay CN mình ngồi nghịch roboflow một xíu thấy phiên bản miễn phí đã quá tốt như vậy rồi, cảm giác hơi hơi hoang mang. Vì khi các framework đã sẵn sàng như vậy rồi sẽ không quá khó để gần như ngay lập tức có 1 model tạm chấp nhận được, sau đó đi tiếp. Các senior đi trước cho đội newbies đi sau định hướng xem nên tập trung vào hướng nào để tăng employability.
#cv_study","['#Q&A', '#cv']","['bữa', 'cn', 'nghịch', 'roboflow xíu', 'phiên', 'miễn phí', 'cảm giác', 'hơi', 'hơi', 'hoang framework', 'sẵn sàng', 'lập tức', '1', 'model', 'tạm', 'chấp', 'đi', 'tiếp', 'senior', 'đi', 'đội', 'newbies', 'đi', 'định hướng', 'hướng', 'employability']"
383,"Chả là em mới có ổ VGA mới (3080 ti) để chạy DL nên em có 2 lựa chọn nhưng mà cả 2 đều có vấn đề nên em muốn hỏi mn có ai đã setup máy để DL mà có 1 trong 2 vấn đề này:
1. Chạy Colab bằng local GPU (Em load cái Jupyter token em nhận đc trong Anaconda Prompt rồi nma nó lại chỉ là Unable to connect to runtime thôi)
2. Chạy Jupyter bằng GPU thay vì CPU (Em thử tải mọi thứ nhưng cái ổ nhớ của em nó bị fragmented nên cái directory nó không tải được hết các cái cần thiết của C++ Visual Studio cho CUDA)
Thế nên nếu có ai đã setup rồi và đã chạy đc rồi thì em xin hỏi mn có cách để giải quyết vấn đề trên hoặc setup 1 cách khác để em có thể chạy DL cho cái project này em có với thầy được không ạ. Em xin cảm ơn trước nha
#dl_study",['#Q&A'],"['chả', 'ổ', 'vga', '3080', 'ti', 'chạy dl', '2', 'lựa', '2', 'mn', 'setup', 'máy', 'dl', '1', '2', '1', 'chạy', 'colab', 'local', 'gpu', 'load', 'jupyter', 'token', 'đc', 'anaconda', 'prompt', 'nma', 'unable', 'to', 'connect', 'to', 'runtime', '2', 'chạy', 'jupyter gpu', 'thay', 'cpu', 'thử', 'tải', 'ổ fragmented', 'directory tải', 'thiết c', 'visual', 'studio', 'cuda', 'setup', 'chạy', 'đc mn', 'giải quyết', 'setup', '1', 'thể', 'chạy', 'dl', 'project', 'thầy', 'nha']"
384,"Waterfall chart - Biểu đồ mô tả thay đổi giá trị trong 1 khoảng thời gian 🔥🔥🔥
Đôi khi trong quá trình trực quan hóa dữ liệu, chúng ta sẽ muốn mô tả sự thay đổi của 1 đại lượng nào đó trong 1 khoảng thời gian (e.g. thay đổi nhiệt độ, doanh thu, ...) Khi đó các biểu đồ truyền thống như line plot hay bar plot sẽ không phải sự lựa chọn tối ưu, vì chúng mô tả giá trị cụ thể thay vì sự biến thiên của giá trị.
Những lúc như vậy, chúng ta có thể sử dụng Waterfall chart. Trong biểu đồ này, giá trị đầu tiên và cuối cùng được trực quan hóa bởi 2 cột đầu và cuối. Sự thay đổi các giá trị ở giữa được thể hiện qua độ cao và màu của các cột (xanh = tăng, đỏ = giảm). Vô cùng đẹp mắt và thuận tiện phải không các bạn ☺️
#ds_tip","['#sharing', '#data']","['waterfall', 'chart', 'biểu đồ', 'mô tả', '1', 'đôi', 'trình', 'trực quan', 'hóa liệu', 'ta', 'mô tả', '1', 'đại', '1', 'e g', 'nhiệt độ', 'doanh thu', 'biểu đồ', 'truyền thống', 'line', 'plot', 'bar', 'plot lựa', 'tối ưu', 'mô tả', 'thay', 'biến thiên', 'ta thể', 'waterfall', 'chart', 'biểu đồ', 'trực quan', 'hóa', '2', 'cột', 'đầu', 'thể hiện', 'độ', 'màu', 'cột', 'xanh đỏ', 'vô', 'đẹp mắt', 'thuận tiện']"
385,"StatQuest with Josh Starmer - kênh youtube hơn 1 triệu subs về Statistics, Machine Learning và Data Science 🔥🔥🔥
Hi các bạn,
Kênh youtube StatQuest with Josh Starmer là 1 trong số các kênh Youtube vô cùng nổi tiếng về AI/Data Science/Machine Learning. Các kiến thức và khái niệm về các mảng như Statistics, Machine Learning hay Deep Learning được trình bày vô cùng tỉ mỉ và chi tiết. Nội dung của kênh thì vô cùng phong phú, và mình highly recommend các bạn 4 danh sách phát sau (được khoanh trong ảnh):
Thống kê cơ bản
Machine Learning
Data (phần này nhiều video trùng với phần thống kê cơ bản)
Neural Network/Deep Learning 
1 kênh vô cùng chất lượng cho các bạn muốn học AI/Data Science/Machine Learning mà không ngại nghe tiếng Anh ☺️
Link to channel: https://www.youtube.com/@statquest/playlists
#ds_ml_share","['#sharing', '#machine_learning', '#math']","['statquest', 'with', 'josh', 'starmer', 'kênh', 'youtube', '1', 'triệu', 'subs', 'statistics', 'machine', 'learning', 'data', 'science', 'hi kênh', 'youtube', 'statquest', 'with', 'josh', 'starmer', '1', 'kênh', 'youtube', 'vô', 'nổi tiếng', 'data', 'science', 'machine learning', 'kiến thức', 'khái niệm', 'mảng', 'statistics', 'machine', 'learning', 'deep', 'learning', 'trình bày', 'vô', 'tỉ mỉ', 'chi tiết', 'nội dung', 'kênh', 'vô phong phú', 'highly', 'recommend', '4', 'danh sách', 'phát khoanh', 'ảnh', 'thống kê', 'machine', 'learning', 'data', 'video trùng', 'thống kê', 'neural', 'network', 'deep', 'learning', '1', 'kênh', 'vô chất', 'học', 'data', 'science', 'machine', 'learning ngại', 'tiếng', 'link', 'to', 'channel']"
386,"Chào mn, e muốn làm một project nhỏ kiểu recommend sách bằng python dùng als với spark apache ấy ạ, mn có thể gợi ý em đề tài tương tự ko ạ. Em cảm ơn ạ
#ds_help","['#Q&A', '#python']","['chào', 'mn', 'e project', 'kiểu', 'recommend', 'sách', 'python', 'als', 'spark', 'apache', 'mn thể', 'gợi', 'đề tài', 'tương ko']"
387,"Em chào mọi người ạ.
Hiện tại em đang chạy lại code của 1 paper down từ github trên GG Colab và bị get bug. Lỗi em gặp phải (theo như em hiểu khi đọc trên stackoverflow và google) là do không đồng nhất kiểu dữ liệu nên mới không call được cuda(). Tuy nhiên do mới tìm hiểu về Pytorch cũng như kiến thức DL cũng mới chỉ ở mức độ cơ bản trên lý thuyết nên em tìm mãi chưa được cách fix.
Em để link gg colab và ảnh phần gặp lỗi ở dưới đây (phần gặp lỗi ở hàm get_activations_from_layer). Ảnh cả hàm này em sẽ để dưới cmt ạ. Mong mọi người có thể giúp em với ạ. Em cảm ơn mọi người rất nhiều!
*Link code: https://colab.research.google.com/drive/1luVEbbPH8SjZTyXFP-f1ZvL8v4NRLvwB?usp=sharing
#dl_cv_code","['#Q&A', '#deep_learning']","['chào', 'chạy', 'code', '1', 'paper', 'down', 'github', 'gg', 'colab', 'get', 'bug', 'lỗi', 'đọc', 'stackoverflow', 'google', 'đồng', 'kiểu liệu', 'call', 'cuda nhiên', 'pytorch', 'kiến thức', 'dl độ', 'lý thuyết', 'mãi', 'fix', 'link', 'gg', 'colab', 'ảnh', 'lỗi', 'lỗi', 'hàm get_activations_from_layer', 'ảnh', 'hàm cmt', 'mong thể', 'giúp', 'link', 'code']"
388,"Chào mọi người, hiện tại các lý thuyết về machine learning hoặc deep learning thì cơ bản mình đã nắm dc. Nhưng về phần code thì mình có chút thắc mắc, mình không biết bắt đầu từ đâu. Mình là coder java nên ở python mình còn hơi mù mờ. Mọi người có biết sách hay nguồn tham khảo nào chỉ dành riêng để code python cho machine learning hay deep learning cho beginner k ạ?
#py_code","['#Q&A', '#python', '#machine_learning']","['chào', 'lý thuyết', 'machine', 'learning', 'deep', 'learning', 'nắm', 'dc', 'code', 'chút', 'thắc mắc', 'coder', 'java', 'python', 'hơi', 'mù mờ', 'sách', 'tham khảo', 'code', 'python', 'machine', 'learning', 'deep', 'learning', 'beginner', 'k']"
389,"Các bác cho em hỏi là nếu muốn học sâu vào AI thì có cần phải học ctdl và gt hay ko ạ, hay chỉ cần học đến 1 level nào đó thôi.Các bác giải đáp giúp em với
#py_study","['#Q&A', '#machine_learning']","['học', 'sâu học', 'ctdl', 'gt', 'ko', 'học', '1', 'level', 'giải đáp', 'giúp']"
390,"Xin chào mọi người, mình là người mới tìm hiểu python đang học cách làm ""Student Registration System"". Hiện mình có 1 vướng mắc xin mọi người giúp đỡ như sau:
Mình có 1 table danh sách lớp học (file excel).
khi tạo 1 học sinh mình sẽ dùng combobox để chọn lớp.
ở đây mình muốn khi click vào nút combox thì nó sẽ hiển thị thông tin lựa chọn theo dạng bảng gồm nhiều cột, khi chọn 1 dòng thì nó sẽ chỉ lấy mã lớp vào ô combobox. 
Mọi người ai biết giúp mình phát, xin cảm ơn.
#py_study","['#Q&A', '#python']","['chào', 'python', 'học', 'student registration', 'system', 'hiện', '1', 'vướng mắc', 'giúp đỡ', '1', 'table', 'danh sách', 'lớp học', 'file', 'excel', '1', 'học sinh', 'combobox', 'lớp', 'click', 'nút', 'combox', 'hiển thị', 'thông lựa', 'dạng', 'bảng', 'cột', '1', 'dòng mã', 'lớp', 'ô', 'combobox', 'giúp', 'phát']"
391,"Xin chào mọi người.
Em đang làm một dự án dùng Mediapipe và OpenCV để phát triển 1 chương trình về Pose correction cho các động tác tập gym ạ (cụ thể là động tác squat, về sau sẽ thêm 1 vài động tác nữa) code bằng Python. Hiện tại chương trình của em chỉ detect được động tác squat đơn giản qua function tính góc ở đầu gối. Khi test chương trình thì mặc dù em đứng yên không làm gì hoặc làm 1 vài cử chỉ vu vơ nó vẫn tự động tính là 1 động tác. Em muốn sửa bằng cách lọc bỏ noise trong lúc nó detect nhưng em không biết làm ạ.
Ai có kinh nghiệm về Mediapipe giúp em với ạ. Nếu mọi người vẫn chưa nắm được vấn đề em sẽ ib giải thích kĩ hơn ạ. Cảm ơn mọi người đã đọc post
#ml #py","['#Q&A', '#cv', '#machine_learning']","['chào', 'dự án', 'mediapipe opencv', 'phát triển', '1', 'chương trình', 'pose', 'correction', 'động tác', 'tập', 'gym', 'động tác', 'squat', '1', 'động tác', 'code', 'python', 'chương trình', 'detect', 'động tác', 'squat', 'đơn giản', 'function', 'góc', 'đầu gối', 'test', 'chương trình', 'mặc', 'đứng', 'yên', '1', 'cử vu', 'vơ động', '1', 'động tác', 'sửa', 'lọc', 'noise', 'detect', 'kinh nghiệm', 'mediapipe', 'giúp', 'nắm', 'ib', 'giải kĩ', 'đọc', 'post']"
392,"Xin chào mng, em là newbie. Em đang tìm hiểu về 1 bài toán python mà detect vị trí các cầu thủ trên sân thông qua video trận đấu, sau đó tạo 1 map sân bóng và đưa dữ liệu vị trí đó lên, từ đó theo dõi về vị trí di chuyển của cầu thủ đó trong suốt trận đấu, nói cách khác có thể theo dõi trận đấu qua map đó luôn ạ, kiểu như minimap trong FC online. Nhưng em lại không biết về từ khóa, nói chung là không biết chỗ tìm hiểu về bài toán này. Em muốn hỏi ý kiến của anh Việt và mng ạ?
#dl #py","['#Q&A', '#cv']","['chào', 'mng', 'newbie', '1', 'toán', 'python', 'detect', 'cầu thủ', 'sân', 'thông video', 'trận', 'đấu', '1', 'map', 'sân', 'bóng liệu', 'dõi', 'di cầu thủ', 'suốt', 'trận', 'đấu thể', 'dõi', 'trận', 'đấu', 'map', 'kiểu', 'minimap', 'fc', 'online khóa', 'chỗ', 'toán kiến', 'việt', 'mng']"
393,"Xin phép mọi người cho em hỏi là có cách nào để em lấy hàng đầu là tháng rồi lấy dữ liệu của từng năm không ạ? Hay là em phải chuyển về dạng dọc như bên dưới mới có thể lấy dữ liệu ạ
Em xin cảm ơn
#py_study","['#Q&A', '#python']","['phép', 'hàng đầu liệu', 'dạng', 'dọc', 'thể liệu']"
394,"Em chào mọi người ,em đang học môn xử xý tín hiệu số (DSP) hiện thầy có giao 1 đề tài viết luận là ứng dụng của GANs trong chuỗi TIme Series + 1 demo nhỏ. Anh chị có thể góp ý có em một số ứng dụng của nó liên quan đến đề tài này với ạ. Em cảm ơn.
#GANs #DSP","['#Q&A', '#deep_learning']","['chào học', 'môn', 'xử', 'xý', 'tín hiệu', 'dsp', 'hiện', 'thầy', 'giao', '1', 'đề tài', 'viết luận', 'ứng dụng', 'gans', 'chuỗi', 'time', 'series', '1', 'demo thể', 'góp', 'ứng dụng', 'đề tài']"
395,"Học IT/AI ở Đức: Nước Đức không chỉ có mỗi TU Munich 🔥🔥🔥
Hi các bạn,
Từ ngày lập group đến giờ, thi thoảng mình thấy có 1 vài post các bạn hỏi về học IT/AI ở TU Munich. Cá nhân mình thì thấy rất vui và tự hào. Tuy nhiên có 1 vài điều mà mình muốn nói với các bạn.
Nước Đức không chỉ có TU Munich: Đúng là rank của TU Munich thì rất cao, và đó cũng là lý do chính ngày xưa mình apply ngôi trường này. Nhưng thực sự thì nước Đức vẫn còn có RẤT RẤT nhiều trường khác có chất lượng không hề kém cạnh TUM và rank thì cũng rất cao (Các bạn có thể dễ dàng tìm kiếm trên 3 bảng xếp hạng danh tiếng nhất thế giới là QS, Times Higher Education và Shanghai Ranking). Ngay ở Berlin nơi mình đang sống cũng có 2-3 trường top. Vậy nên không nhất thiết phải sống chết vào TUM bằng mọi giá các bạn nhé 😎
Dành cho các bạn theo hướng IT nói riêng và kĩ thuật nói chung. Ở đức có TU9 - 1 liên minh gồm 9 trường kỹ thuật hàng đầu ở Đức. Các bạn vào học ở bất kì trường nào trong 9 trường này thì cũng đều là cực kì tốt (cả về chất lượng và danh tiếng) 🥰 Các bạn thấy đó, có rất nhiều sự lựa chọn 😎
Kể cả các bạn có không vào TU9 mà học ở các trường khác thì cũng hoàn toàn ok, ko sao cả. Rất nhiều đồng nghiệp của mình không phải người Đức, cũng chẳng phải người châu Âu, học ở các trường khác trên khắp nước Đức, họ vẫn xin được việc, và thậm chí họ còn làm ở các role rất cao trong công ty. Đừng quá nặng nề việc phải học trường A trường B các bạn nhé, quan trọng là bản thân chúng ta học và tích lũy được gì. Học Harvard đi nữa mà không nắm chắc kiến thức thì đi phỏng vấn cũng trượt thôi 😢
#it_study","['#sharing', '#machine_learning']","['học', 'it', 'đức đức', 'tu munich', 'hi lập', 'group', '1', 'post', 'học', 'it', 'tu munich', 'vui', 'hào nhiên', '1', 'đức tu', 'munich', 'rank tu', 'munich lý', 'xưa', 'apply trường', 'thực đức', 'trường', 'chất hề', 'kém', 'cạnh', 'tum', 'rank thể dàng', 'kiếm', '3', 'bảng', 'xếp hạng', 'danh tiếng', 'giới', 'qs', 'times', 'higher', 'education', 'shanghai', 'ranking', 'berlin', 'sống', '23', 'trường', 'top thiết', 'sống chết', 'tum', 'giá', 'hướng', 'it', 'kĩ thuật', 'đức tu9', '1', 'liên minh', '9', 'trường', 'kỹ thuật', 'hàng đầu', 'đức', 'học', 'trường', '9', 'trường', 'cực kì', 'chất', 'danh tiếng', 'lựa', 'tu9', 'học', 'trường', 'ok', 'ko', 'đồng nghiệp', 'đức', 'châu âu', 'học', 'trường', 'khắp', 'đức chí', 'role', 'công ty', 'đừng', 'nề', 'học', 'trường', 'a trường', 'b thân', 'ta', 'học tích', 'lũy', 'học', 'harvard', 'đi', 'nắm', 'kiến thức', 'đi vấn', 'trượt']"
396,"Bài giảng khóa học Nhập môn học máy và khai phá dữ liệu cho sinh viên Chương trình tài năng tại viện CNTT&TT, ĐH BKHN 🔥🔥🔥
Hi các bạn,
Dưới đây là bài giảng của khóa học Nhập môn học máy và khai phá dữ liệu (Introduction to Machine Learning and Data Mining) kì 2022-2 được giảng dạy cho sinh viên chương trình tài năng tại viện CNTT&TT, đại học Bách Khoa Hà Nội
Khóa học được thực hiện bởi PGS. TS. Thân Quang Khoát, hiện đang là Trưởng phòng Nghiên cứu về Khoa học dữ liệu, và Giảng viên tại bộ môn Hệ thống Thông tin, Viện CNTT&TT, Đại học Bách khoa Hà Nội
Bài giảng sẽ có slide tiếng Anh nhưng video bài giảng thì là tiếng Việt các bạn nhé 😎
Link: https://users.soict.hust.edu.vn/khoattq/ml-dm-course/
P/s: Về mặt cá nhân thì mình thực sự rất tự hào khi ngồi soạn post này. Đây là trường của mình, viện của mình 😎 Chương trình tài năng thì từ lâu đã là signature của trường rồi. Ngày còn là sinh viên Bách Khoa mình cũng từng có mong muốn được vào, cơ mà chắc thi 100 lần thì cũng không chen vào nổi 😅
#ml_share","['#sharing', '#machine_learning']","['giảng', 'khóa học', 'nhập môn', 'học', 'máy', 'khai phá liệu', 'sinh viên', 'chương trình', 'tài năng', 'viện', 'cntt', 'tt', 'đh', 'bkhn', 'hi giảng', 'khóa học', 'nhập môn', 'học', 'máy', 'khai phá liệu', 'introduction', 'to', 'machine learning', 'and data', 'mining kì', '20222', 'giảng dạy', 'sinh viên', 'chương trình', 'tài năng', 'viện', 'cntt', 'tt', 'đại học', 'bách khoa', 'hà nội', 'khóa', 'học', 'pgs', 'ts', 'thân quang', 'khoát', 'hiện', 'trưởng', 'phòng', 'nghiên cứu', 'khoa học liệu', 'giảng viên', 'môn', 'hệ thống', 'thông viện', 'cntt', 'tt', 'đại học', 'bách khoa', 'hà nội', 'giảng', 'slide', 'tiếng', 'video giảng', 'tiếng', 'việt', 'link', 'https', 'users', 'soict', 'hust', 'edu', 'vn', 'khoattq', 'mldmcourse', 'p', 's', 'mặt', 'thực hào', 'soạn', 'post', 'trường viện', 'chương trình', 'tài năng', 'signature trường', 'sinh viên', 'bách khoa', 'mong', 'thi', '100', 'chen', 'nổi']"
397,"Chào mọi người và anh Việt ạ, thì không biết mọi người đã thử qua việc đọc mã qr trên cccd chưa ạ, em dự tính làm một project nhỏ trích xuất thông tin căn cước nhưng thay vì ocr thì thử theo hướng đọc mã qr, nhưng em gặp tình trạng là ko thể quét được mã. Sau thời gian thử nhiều cái thì em thấy chỉ có zalo là đọc được. Không biết mọi người có gợi ý nguồn hay thư viện nào khác của python có thể đọc được gợi ý giúp em với. Em cảm ơn ạ
#py_code","['#Q&A', '#cv']","['chào', 'việt', 'thử', 'đọc', 'mã', 'qr', 'cccd', 'dự project', 'trích', 'xuất', 'thông cước', 'thay', 'ocr', 'thử', 'hướng', 'đọc', 'mã', 'qr', 'ko thể', 'quét mã', 'thử', 'zalo', 'đọc', 'gợi', 'thư viện', 'python thể', 'đọc', 'gợi', 'giúp']"
398,"Chào các bạn, mình đang muốn tìm chương trình học master DS của trường nước ngoài, học online. Background của mình là trái ngành, mình không học đại học về data hay IT, tuy nhiên mình hiện đang làm DA và định hướng theo DS. Nhờ các bạn giới thiệu giúp mình ạ, mình xin cảm ơn! #ds_study","['#Q&A', '#data']","['chào', 'chương trình', 'học', 'master', 'ds', 'trường học', 'online', 'background', 'trái', 'ngành', 'học', 'đại học', 'data', 'it nhiên', 'hiện', 'da', 'định hướng', 'ds', 'giới thiệu', 'giúp']"
399,"Chào mn ạ, em là sinh viên năm nhất ạ, cho em hỏi là với kiến thức toán như sau của em thì có học machine learning được chưa ạ, em mới hoàn thành xong khóa học giải tích 1, và 1 nửa khóa học đại số tuyến tính, chưa học XSTK vậy có học dc machine learning không ạ, em nghe nói học machine learning cần nhiều toán ạ.
#hoi_dap_machine_learning","['#Q&A', '#math', '#machine_learning']","['chào mn', 'sinh viên', 'kiến thức', 'toán học', 'machine learning', 'hoàn thành', 'xong', 'khóa', 'học', 'giải tích', '1', '1', 'nửa', 'khóa', 'học', 'đại tuyến', 'học', 'xstk', 'học', 'dc', 'machine', 'learning', 'học', 'machine', 'learning toán']"
400,"Toàn bộ các thuật toán Machine Learning được code from scratch 🔥🔥🔥
Dành cho các bạn muốn tìm hiểu cách thức xây dựng các mô hình trong Machine Learning. Đây là 1 repository rất nổi tiếng trên Github về Machine Learning (22.5k stars, 4.4k forks). 
Trong repository này, tất cả các thuật toán trong Machine Learning sẽ được code từ đầu mà không sử dụng bất kì thư viện nào (ngoại trừ numpy). Các layer của Deep Learning cũng được code hết từ đầu luôn 😁. 1 repository khá thú vị cho những bạn muốn đi sâu tìm hiểu bản chất của các mô hình thay vì chỉ gọi chúng ra trong scikit-learn 😅
Link to repo: https://github.com/eriklindernoren/ML-From-Scratch
#ml_share","['#sharing', '#machine_learning']","['toàn', 'thuật toán', 'machine', 'learning', 'code', 'from', 'scratch thức', 'xây dựng', 'mô hình', 'machine', 'learning', '1', 'repository', 'nổi tiếng', 'github', 'machine', 'learning', '22', '5', 'k', 'stars', '4', '4', 'k', 'forks', 'repository', 'tất thuật', 'toán', 'machine', 'learning', 'code', 'đầu', 'thư viện', 'ngoại trừ', 'numpy', 'layer', 'deep', 'learning', 'code', 'đầu', '1', 'repository', 'thú vị', 'đi sâu', 'chất', 'mô hình', 'thay', 'gọi', 'scikitlearn', 'link', 'to', 'repo']"
401,"Mọi người ơi, cho em xin được phép hỏi là ở đây có ai đã từng crawl data từ Shopee API chưa ạ? Nếu rồi thì xin phép chỉ giáo cho em với ạ, em đọc documentation mà chưa get it lắm ạ.
Em cảm ơn mọi người ạ.
#dsml_project","['#Q&A', '#data']","['phép', 'crawl', 'data', 'shopee', 'api', 'phép giáo', 'đọc', 'documentation', 'get', 'it', 'lắm']"
402,"Machine Learning for absolute Beginners 🔥🔥🔥
Đây là quyển sách được thiết kế nhắm đến những ai chưa từng tiếp xúc với AI/Machine Learning dưới bất kì 1 hình thức nào. Toàn bộ các khái niệm được giới thiệu và giải thích theo những cách rất gần gũi, thông qua hình ảnh cũng như các ví dụ thực tế. Do là sách dành cho người mới nên các công thức gần như được lược bỏ hết 😅
Đối với cá nhân mình đánh giá, quyển sách này rất hợp cho các bạn trái ngành hoặc các bạn tân sinh viên muốn tìm hiểu về Machine Learning 🥰 Còn với các bạn muốn học chuyên sâu về AI/Machine Learning thì các bạn sẽ cần những quyển sách nặng kí hơn 1 chút 😅
Link to pdf: https://drive.google.com/file/d/1XJ69RGSF9AanGHFDpHHMkxsGzJ_DL1Dd/view?usp=sharing
#ms_share","['#sharing', '#machine_learning']","['machine', 'learning', 'for', 'absolute', 'beginners', 'quyển', 'sách', 'thiết kế', 'nhắm', 'tiếp xúc', 'machine', 'learning', '1', 'hình thức', 'toàn', 'khái niệm', 'giới thiệu', 'giải gũi', 'thông', 'hình ảnh', 'ví dụ', 'sách', 'công thức', 'lược', 'đối quyển', 'sách', 'hợp', 'trái', 'ngành', 'tân', 'sinh viên', 'machine', 'learning', 'học', 'chuyên sâu', 'machine', 'learning', 'quyển', 'sách', 'kí', '1', 'chút', 'link', 'to', 'pdf']"
403,"[Bản tiếng Việt] Interpretable Machine Learning 🔥🔥🔥
Bản gốc tiếng Anh: https://christophm.github.io/interpretable-ml-book/
Bản dịch tiếng Việt: https://drive.google.com/file/d/1sBCp4hZr0tHWHVRtow_tKC49ZBHybljJ/view?usp=sharing
Hi các bạn,
Hôm nay mình xin chia sẻ với các bạn bản dịch tiếng Việt của 1 cuốn sách rất thú vị: Interpretable Machine Learning - học máy khả diễn giải
Cuốn sách này khai thác 1 khía cạnh mà ít đầu sách về Machine Learning đề cập, đó là tính giải thích/diễn giải của các mô hình Machine Learning. 
Tính diễn giải các bạn có thể hiểu là khả năng các bạn có thể giải thích được vì sao mô hình lại đưa ra kết quả thế này thế kia, hay yếu tố nào từ dữ liệu đầu vào ảnh hưởng lớn đến kết quả dự đoán.
Đây có lẽ là đầu sách đầu tiên mình biết được đi sâu vào khía cạnh này, do phần lớn người học về Machine Learning/Deep Learning chỉ quan tâm đến làm sao để mô hình có được performance cao nhất. Còn lý do vì sao thì ít được quan tâm hơn 😅
#ml_share","['#sharing', '#machine_learning']","['tiếng', 'việt', 'interpretable', 'machine', 'learning', 'gốc', 'tiếng', 'https', 'christophm', 'github', 'io', 'interpretablemlbook', 'dịch', 'tiếng', 'việt', 'hi hôm', 'dịch', 'tiếng', 'việt', '1', 'sách', 'thú vị', 'interpretable', 'machine', 'learning', 'học', 'máy', 'khả diễn', 'giải sách', 'khai thác', '1', 'khía cạnh', 'đầu sách', 'machine learning', 'đề cập', 'giải', 'diễn giải', 'mô hình', 'machine', 'learning', 'diễn', 'giải thể', 'khả năng thể', 'giải', 'mô hình', 'kết', 'kia', 'yếu tố', 'liệu', 'đầu', 'ảnh hưởng', 'kết', 'dự đoán', 'lẽ', 'đầu sách', 'đi sâu', 'khía cạnh', 'học', 'machine', 'learning', 'deep', 'learning', 'mô hình', 'performance lý']"
404,"Dạ e chào mn ạ, hiện tại thì e đang triển khai mô hình pandora fms và đang gặp một xíu khó khăn trong việc xác định xem phần AI của mô hình nằm ở đâu. Ko biết ai ở trong nhóm mình đã từng tiếp xúc qua mô hình này có thể cho e hỏi một xíu dc ko ạ. #ml_help","['#Q&A', '#machine_learning']","['e', 'chào mn', 'e', 'triển khai', 'mô hình', 'pandora', 'fms xíu', 'khăn', 'xác định', 'mô hình', 'nằm', 'ko', 'tiếp xúc', 'mô hình thể', 'e xíu', 'dc', 'ko']"
405,"Mọi người ai có kinh nghiệm trong việc thu thập custom data để luyện CNN cho em hỏi một chút được không ạ?
Dự án của em đang làm phải nhận diện retail items, tuy nhiên retail items thì rất là đa dạng tuỳ cửa hàng nên là nếu mà thu thập data bằng cách: lấy máy ảnh đi chụp mỗi loại item một rồi annotate hoặc là chụp nhiều ảnh mỗi item để dùng two-shots object detection ( detect object rồi crop ảnh ra bỏ vào model thứ 2 chuyên classificatjon ) thì có vẻ không thực tiễn. Em có tìm hiểu thêm thì có hai giải pháp khá thú vị mà có thể triển khai..
1. Lắp đặt mấy camera để quay lại hình ảnh của những retail items trong một cửa hàng cụ thể đó rồi annotate lên những camera footages để train model.
2. Sử dụng matterport để quét 3D tất cả những loại items và toàn bộ cửa hàng để generate digital twin để làm synthetic training data ( article dưới đây nói về việc này )
https://www.sciencedaily.com/releases/2022/09/220908100031.htm
Em mong xin ý kiến của mọi người về vấn đề này và những hướng giải quyết tốt hơn nếu có thể ạ. Em cảm ơn
#cv_help #imageclassification","['#Q&A', '#cv']","['kinh nghiệm thu thập', 'custom', 'data luyện', 'cnn', 'chút', 'dự án', 'diện', 'retail', 'items nhiên', 'retail', 'items', 'đa dạng', 'tùy', 'cửa hàng', 'thu thập', 'data', 'máy ảnh', 'đi', 'chụp', 'item', 'annotate', 'chụp', 'ảnh', 'item', 'twoshots', 'object', 'detection', 'detect', 'object', 'crop', 'ảnh', 'model', '2', 'chuyên', 'classificatjon vẻ', 'thực tiễn', 'hai', 'giải pháp', 'thú vị thể', 'triển khai', '1', 'lắp', 'mấy', 'camera', 'hình ảnh', 'retail', 'items', 'cửa hàng', 'annotate', 'camera', 'footages', 'train', 'model', '2', 'matterport', 'quét', '3', 'd', 'tất items', 'toàn', 'cửa hàng', 'generate', 'digital', 'twin', 'synthetic', 'training', 'data', 'article', 'mong kiến', 'hướng', 'giải quyết thể']"
406,"Cho phép gửi file lớn (chia nhỏ thành nhiều luồng để gửi) --> có hiển thị tiến trình từng luồng --> ghép khi nhận
Cho phép trên khung giao diện chat có thể vừa chat vừa play video (nhận được)
Dạ em chào anh chị, em đang làm bài tập lớn trên trường đề bài như này, em đã gửi file được nhưng ko biết các hiển thị tiến trình các thread cũng như chưa biết làm bài 2. Ai cho em ý tưởng được ko ạ
#ds_help","['#Q&A', '#data']","['phép', 'gửi', 'file', 'chia', 'thành', 'luồng', 'gửi', 'hiển thị', 'tiến trình', 'luồng', 'ghép', 'phép', 'khung', 'giao diện', 'chat thể', 'chat', 'play', 'video', 'chào tập', 'trường', 'đề', 'gửi', 'file', 'ko', 'hiển thị', 'tiến trình', 'thread', '2', 'tưởng', 'ko']"
407,"Mng ơi, hiện tại em đang làm Thesis về đề tài deep learning forecasting. Do chủ đề này khá mới so với em và còn nhiều khúc mắc chưa hiểu lắm ạ. Mng trong group ai có thể giải đáp cho em vài câu hỏi được không ạ. Em xin cám ơn và sẽ hậu tạ đầy đủ.
#dl_study #dl_code","['#Q&A', '#deep_learning']","['mng', 'thesis', 'đề tài', 'deep', 'learning', 'forecasting', 'chủ đề', 'khúc mắc', 'lắm', 'mng', 'group thể', 'giải đáp', 'cám ơn', 'hậu tạ']"
408,"Chào mọi người em có 1 bài tập muốn hỏi mọi người, đề bài cho trước cực đại và cực tiểu thì sao vẽ được đồ thị của nó bằng python ạ
#python","['#Q&A', '#python']","['chào', '1', 'tập', 'đề cực', 'đại cực', 'tiểu vẽ', 'đồ thị', 'python']"
409,"Xin chào mọi người, em vừa mới switch quá máy mac muốn xử dụng gpu của máy để load data bằng thư viện pytorch nhưng mà lại gặp phải chút vấn đề, mong mọi người ai có kinh nghiệm có thể giải đáp giúp em. Cảm ơn mọi người ạ :>
dưới đây là đoạn code em chạy:
#specify the device to use
mps_device = torch.device(""mps:0"")
torch.set_default_device(mps_device)

dataset = ImageFolder(root=dataset_path, transform=data_transforms)
# Define the percentage for each split
train_ratio = 0.8
test_ratio = 0.2

total_size = len(dataset)
train_size = int(train_ratio * total_size)
test_size = total_size - train_size

train_set, test_set = random_split(dataset, [train_size, test_size]) //error on this line

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_set, batch_size=batch_size)
Error trace:
```
Traceback (most recent call last):
File “/Users/vietpham1023/Desktop/python-resource-yoga-pose/convolutional_neural_net.py”, line 85, in
train_set, test_set = random_split(dataset, [train_size, test_size])
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File “/Users/vietpham1023/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py”, line 420, in random_split
indices = randperm(sum(lengths), generator=generator).tolist() # type: ignore[arg-type, call-overload]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File “/Users/vietpham1023/anaconda3/lib/python3.11/site-packages/torch/utils/_device.py”, line 77, in torch_function
return func(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected a ‘mps:0’ generator device but found ‘cpu’
```

Đoạn này em có thử set lại cái generator trong thư viện nhưng vẫn gặp phải lỗi.
# Set the generator device to 'mps:0'
generator = torch.Generator(device='mps:0')

# Use the generator in the randperm function
indices = randperm(sum(lengths), generator=generator).tolist()
Error:
RuntimeError: Expected a ‘mps:0’ generator device but found ‘mps’
Em tiếp tục debug tới hàm này:
def __torch_function__(self, func, types, args=(), kwargs=None):
kwargs = kwargs or {}
if func in _device_constructors() and kwargs.get('device') is None:
kwargs['device'] = self.device #I replaced this line with: kwargs['device'] = 'mps:0' but no luck
return func(*args, **kwargs)'
và nhận thấy kwargs[‘device’] = self.device, self.device ở đây có giá trị 'mps:0' và ‘generator’ key trong kwargs dict có giá trị ‘mps’, em thử re-assign kwargs[‘generator’].device = self.device nhưng nhận được lỗi không ghi được value vào key này ạ.

#pytorch, #data #random_slpit","['#Q&A', '#python']","['chào', 'switch', 'máy', 'mac', 'xử dụng', 'gpu', 'máy', 'load', 'data', 'thư viện', 'pytorch', 'chút', 'mong', 'kinh nghiệm thể', 'giải đáp', 'giúp', 'đoạn', 'code', 'chạy', 'the', 'device', 'to', 'use', 'mps_device', 'torch', 'device', 'mps', '0', 'torch', 'set_default_device', 'mps_device', 'dataset', 'imagefolder', 'root', 'dataset_path', 'transform', 'data_transforms', 'define', 'the', 'percentage', 'for', 'each', 'split', 'train_ratio', '0', '8', 'test_ratio', '0', '2', 'total_size', 'len dataset', 'train_size', 'int', 'train_ratio', 'total_size', 'test_size', 'total_size', 'train_size', 'train_set', 'test_set', 'random_split', 'dataset', 'train_size', 'test_size', 'error', 'on', 'this', 'line', 'train_loader', 'dataloader', 'train_set', 'batch_size', 'batch_size', 'shuffle', 'true', 'test_loader', 'dataloader', 'test_set', 'batch_size', 'batch_size', 'error', 'trace', 'traceback', 'most', 'recent', 'call', 'last', 'file', 'users', 'vietpham1023', 'desktop', 'pythonresourceyogapose', 'convolutional_neural_net', 'py', 'line', '85', 'in', 'train_set', 'test_set', 'random_split', 'dataset', 'train_size', 'test_size', 'file', 'users', 'vietpham1023', 'anaconda3', 'lib', 'python3', '11', 'sitepackages', 'torch', 'utils', 'data', 'dataset', 'py', 'line', '420', 'in', 'random_split', 'indices', 'randperm', 'sum lengths', 'generator', 'generator', 'tolist', 'type', 'ignore', 'argtype', 'calloverload', 'file', 'users', 'vietpham1023', 'anaconda3', 'lib', 'python3', '11', 'sitepackages', 'torch', 'utils', '_device', 'py', 'line', '77', 'in', 'torch_function', 'return', 'func', 'args', 'kwargs', 'runtimeerror', 'expected', 'a', 'mps', '0', 'generator', 'device', 'but', 'found', 'cpu', 'đoạn', 'thử', 'set', 'generator', 'thư viện', 'lỗi', 'set', 'the', 'generator', 'device', 'to', 'mps', '0', 'generator', 'torch', 'generator', 'device', 'mps', '0', 'use', 'the', 'generator', 'in', 'the', 'randperm', 'function', 'indices', 'randperm', 'sum lengths', 'generator', 'generator', 'tolist', 'error', 'runtimeerror', 'expected', 'a', 'mps', '0', 'generator', 'device', 'but', 'found', 'mps', 'debug', 'hàm def', '__torch_function__', 'self', 'func', 'types', 'args', 'kwargs', 'none', 'kwargs', 'kwargs', 'or', 'if', 'func', 'in', '_device_constructors and', 'kwargs', 'get', 'device', 'is', 'none', 'kwargs', 'device', 'self', 'device', 'replaced', 'this', 'line', 'with', 'kwargs', 'device', 'mps', '0', 'but', 'no', 'luck', 'return', 'func', 'args', 'kwargs', 'kwargs', 'device', 'self', 'device', 'self', 'device', 'mps', '0', 'generator', 'key', 'kwargs', 'dict', 'mps', 'thử', 'reassign', 'kwargs', 'generator', 'device', 'self', 'device', 'lỗi', 'ghi', 'value', 'key']"
410,"#other
Em xin chào mọi người. Cho em xin hỏi một câu hơi lạc đề tí so với chủ đề trong group mình.
Anh chị có nghĩ rằng một người theo mảng AI/DS nói riêng và IT nói chung cần biết nhiều hơn một ngoại ngữ (không bao gồm tiếng Anh) hay không?
Em xin cảm ơn anh chị nhiều.","['#Q&A', '#machine_learning']","['chào', 'câu', 'hơi', 'lạc đề tí', 'chủ đề', 'group', 'mảng', 'ds', 'it', 'ngoại ngữ', 'bao', 'tiếng']"
411,"Mình làm trong ngành logistics cũng gần 10 năm r. Dữ liệu data phân tích các kiểu cũng làm khá nhiều nhưng chỉ trên excel.thôi. Gần đây mình cũng có tìm hiểu BA và cũng cảm thấy khá hưng thú
Nhờ mọi người tư vấn giúp career path bên ngành này sẽ ntn, và khả năng bắt đầu lại vs ngành thì liệu có khả năng bằng các bạn trẻ hiện nay ko?
#Other","['#Q&A', '#data']","['ngành', 'logistics', '10', 'r liệu', 'data', 'phân tích', 'kiểu', 'excel hưng thú', 'tư vấn', 'giúp', 'career', 'path', 'ngành', 'ntn', 'khả năng', 'vs', 'ngành liệu', 'khả năng', 'trẻ', 'ko']"
412,"mọi người giúp mik lỗi này với ạ, mik import pandas để đọc file excel trong visual studio code nhưng nó cứ hiện lỗi unicode error.
mik xem youtube thì thử cách cho thêm chữ ""r"" vào cái hàm pd.read_excel hoặc đổi dấu \ thành \\ trong tên file excel thì vẫn ko đc ạ
#ds_help","['#Q&A', '#python']","['giúp', 'mik', 'lỗi', 'mik', 'import', 'pandas', 'đọc', 'file', 'excel', 'visual', 'studio', 'code', 'hiện', 'lỗi', 'unicode', 'error', 'mik', 'youtube', 'thử', 'chữ', 'r', 'hàm pd', 'read_excel', 'đổi', 'dấu', 'thành', 'file', 'excel', 'ko', 'đc']"
413,"Dạ em chào mọi người ạ!
Em đang thực hiện bài toán multilabel segmentation với model UNet cho dataset 3DIRCADB, với 3 folder lần lượt chứa những file .DICOM cho CTScan của patient, và file .DICOM cho mask của riêng liver và riêng tumor.
Em có tham khảo quá trình data preprocessing của một số bài toán tương tự trên mạng thì em thấy họ dùng mask file dạng .tif, rồi dùng labelencoder của sklearn để tạo ra train_mask.
Em muốn hỏi ở bài toán của em thì nên xử lí data như thế nào trước khi dùng model, và model em nên thực hiện như thế nào để đơn giản nhất ạ.
#cv_code","['#Q&A', '#cv', '#data']","['chào toán', 'multilabel', 'segmentation', 'model', 'unet', 'dataset', '3', 'dircadb', '3', 'folder', 'lượt', 'chứa', 'file', 'dicom', 'ctscan', 'patient', 'file', 'dicom', 'mask', 'liver', 'tumor', 'tham khảo', 'trình', 'data', 'preprocessing toán', 'tương mạng', 'mask', 'file', 'dạng', 'tif', 'labelencoder', 'sklearn', 'train_mask toán', 'xử lí', 'data', 'model', 'model', 'đơn giản']"
414,"[Bản tiếng Việt] Deep Learning - quyển sách được xuất bản bởi MIT Press - nhà xuất bản của trường đại học số 1 thế giới về CNTT 🔥🔥🔥
Đây là quyển textbook vô cùng nổi tiếng được xuất bản bởi nhà xuất bản viện công nghệ Massachusetts - ngôi trường luôn đứng top 1 về CNTT ở hầu hết các bảng xếp hạng trên thế giới. Quyển textbook này bao gồm 3 phần chính:
Toán ứng dụng và Machine Learning cơ bản
Deep network
Nghiên cứu về Deep Learning 
Quyển sách này hoàn toàn free, và các bạn có thể download tại https://www.deeplearningbook.org/
Có 1 điều rất may mắn là đã từng có 1 nhóm dịch giả dịch phần đầu tiên sang tiếng Việt (và càng may mắn hơn khi phần đầu là phần mà theo đánh giá của mình là quan trọng nhất - Toán và ML nền tảng). Các bạn có thể xem bản dịch này tại https://github.com/ttvn/deep-learning-ebook-vietnamese-translation
Dành cho các bạn chưa biết thì quyển textbook này được sử dụng như là tài liệu tham khảo trong rất nhiều các khóa học về ML/DL trên khắp thế giới ☺️
#dsml_share","['#sharing', '#deep_learning']","['tiếng', 'việt', 'deep', 'learning', 'quyển', 'sách', 'xuất mit', 'press', 'xuất trường', 'đại học', '1', 'giới', 'cntt', 'quyển', 'textbook', 'vô', 'nổi tiếng', 'xuất', 'xuất viện', 'công nghệ', 'massachusetts trường', 'đứng', 'top', '1', 'cntt', 'bảng', 'xếp hạng', 'giới', 'quyển', 'textbook', 'bao', '3', 'toán', 'ứng dụng', 'machine', 'learning', 'deep', 'network', 'nghiên cứu', 'deep', 'learning', 'quyển', 'sách', 'free thể', 'download', 'https', 'www', 'deeplearningbook', 'org', '1', 'may mắn', '1', 'dịch giả', 'dịch', 'tiếng', 'việt', 'may mắn', 'đầu toán', 'ml', 'tảng thể', 'dịch', 'quyển', 'textbook', 'tài liệu', 'tham khảo', 'khóa', 'học', 'ml dl', 'khắp', 'giới']"
415,"AHT TECH chiêu mộ #Python Developer làm việc tại #Hanoi và #Seoul
🇻🇳 Python tại Hà Nội - Offer up to 25M VND/tháng
Từ 2 năm kinh nghiệm
Tiếng Anh tốt
🇰🇷 Python tại Seoul - Offer up to 40 triệu won/năm + vé máy bay khứ hồi
Từ 3 năm kinh nghiệm
Tiếng Anh giao tiếp khá tốt
Tối thiểu 1 năm đóng BHXH
Liên hệ ngay, trao đổi và process nhanh lẹ ạ!!!
Skype: live:.cid.4130a0d3821bb603
Email: tinhntv@arrowhitech.com
#hiring #python #developer #hanoi #seoul","['#sharing', '#python']","['aht', 'tech', 'chiêu mộ', 'developer', 'python', 'hà nội', 'offer', 'up', 'to', '25', 'm', 'vnd', '2', 'kinh nghiệm', 'tiếng', 'python', 'seoul', 'offer', 'up', 'to', '40', 'triệu', 'won', 'vé', 'máy bay', 'khứ', 'hồi', '3', 'kinh nghiệm', 'tiếng', 'giao tiếp', 'tối thiểu', '1', 'đóng', 'bhxh', 'liên hệ', 'trao đổi', 'process', 'lẹ', 'skype', 'live', 'cid', '4130', 'a0d3821bb603', 'email', 'tinhntv', 'arrowhitech', 'com']"
416,"Chào mọi người ạ
Em hiện đang làm automated pentest web with RL, trước đó e học RL thì chủ yếu chạy trên môi trường người ta build sẵn như gym
hmm với lại có env nào của mảng này được build sẵn giống như mấy game đc build bằng gym ko ạ
Thì bây giờ e có bắt đầu build môi trường cho project của riêng mình, e định nghĩa các state là các cột trong dataset này,
còn actions và reward là:
khi em khai thác thành công 1 lỗ hỗng mới thì 10 điểm
khai thác 1 lỗ hổng có trong dataset thì 5 điểm
fail thì là -1 điểm
Không biết e định nghĩa như trên này + build env = dataset thì có đúng k ạ, e cũng gặp khó khăn trong việc code env RL, mọi người ai có tài liệu liên quan đến này kh ạ, cho e xin với.
Em có đọc 1 số bài báo cũng như nhìn code liên quan thì 1 số bài họ build env = dataset còn 1 số bài e không thấy, e nghĩ trong lĩnh vực security thì dataset phải là thứ bắt buộc khi áp dụng AI vào chứ ạ
#rl_study","['#Q&A', '#machine_learning']","['chào', 'hiện', 'automated', 'pentest', 'web', 'with', 'rl', 'e học', 'rl', 'chủ yếu', 'chạy', 'môi trường', 'ta', 'build', 'sẵn', 'gym', 'hmm', 'env', 'mảng', 'build', 'sẵn', 'mấy', 'game', 'đc', 'build', 'gym', 'ko', 'e build', 'môi trường', 'project', 'e định nghĩa', 'state cột', 'dataset', 'actions', 'reward', 'khai thác', 'thành công', '1', 'lỗ', 'hỗng', '10', 'khai thác', '1', 'lỗ', 'hổng', 'dataset', '5', 'fail', '1', 'e định nghĩa', 'build env', 'dataset', 'k', 'e khăn', 'code', 'env', 'rl', 'tài liệu', 'kh e', 'đọc', '1', 'báo', 'code', '1', 'build', 'env', 'dataset', '1', 'e e', 'lĩnh vực', 'security', 'dataset', 'bắt buộc', 'áp dụng']"
417,"#nlp_other
[TIỀN XỬ LÍ DỮ LIỆU TEXT TIẾNG VIỆT]
Chào mọi người.
Mình có một dataset gồm 60.000 bình luận trên Tiki.vn cần tiền xử lí để tạo Word2Vec, rồi embedding words vào model deep-learning, cho bài toán sentiment analyze
Dataset do nhóm mình tự crawl nên có rất nhiều vấn đề:
- Xuất hiện từ tiếng anh trong comment, đôi khi cả tiếng thái,
- Từ ngữ viết liền nhau nhuthenay, viết tắt, sai chính tả,
- Có những bình luận random jfdshjkkdsf, cũng có những bình luận duplicate từ như goodgoodgoodgood, tuyệttttt vờiiiiiiiiii,
- Số-chữ viết liền nhau 12kg, 500gram, 120k, 120ngan, 120nghin, 120.000,
- Tên nhãn hàng: sunhouse, adidas, LG,...,
- Thời gian 24/7, 22-10, 27thang10
- Mã đơn hàng tiki: TK2289432897,
Hiện tại mình mới chỉ có hướng giải quyết là dùng random-string-detector để lọc được một phần random text, loại bình luận có ít words nhưng nhiều characters, tách từ có chữ-số liền nhau... Còn lại sẽ làm thủ công, cắt bỏ hoặc sửa lại comment cho đúng.
Bạn nào có kinh nghiệm clean text data thì cho mình xin một vài giải pháp, thư viện hỗ trợ. Data thế này chắc chắn phải làm thủ công nhiều nhưng có một vài tools hỗ trợ thì giúp được mình rất nhiều việc.
Mình xin cảm ơn mọi người.","['#Q&A', '#nlp']","['tiền', 'xử lí liệu', 'text', 'tiếng', 'việt', 'chào dataset', '60', '000', 'bình luận', 'tiền', 'xử lí', 'word2vec', 'embedding', 'words', 'model', 'deeplearning toán', 'sentiment', 'analyze', 'dataset', 'crawl', 'tiếng', 'comment', 'đôi', 'tiếng', 'thái ngữ', 'viết', 'liền', 'nhuthenay', 'viết', 'tắt', 'sai tả', 'bình luận', 'random jfdshjkkdsf', 'bình luận', 'duplicate', 'goodgoodgoodgood', 'tuyệttttt', 'vờiiiiiiiiii', 'sốchữ', 'viết', 'liền', '12', 'kg', '500', 'gram', '120', 'k', '120', 'ngan', '120', 'nghin', '120', '000', 'nhãn', 'hàng', 'sunhouse', 'adidas', 'lg', '24', '7', '2210', '27', 'thang10 mã', 'đơn', 'hàng', 'tiki', 'tk2289432897', 'hướng', 'giải quyết', 'randomstringdetector', 'lọc', 'random text', 'bình luận', 'words', 'characters', 'tách', 'chữsố', 'liền', 'thủ công', 'cắt', 'sửa', 'comment', 'kinh nghiệm', 'clean', 'text', 'data', 'giải pháp', 'thư viện', 'data', 'chắn', 'thủ công', 'tools', 'giúp']"
418,"Chào mọi người,
Em đang là sinh viên năm 2. Sang kỳ sau em bắt đầu vào chuyên ngành. Em có tìm hiểu qua cv, nlp và ds nhưng chưa em xác định được hướng muốn đi. Nên em muốn biết cách nhìn của mọi người về cv, nlp và ds để tham khảo. Em cảm ơn mọi người nhiều🥰🥰🥰
#cv_share #nlp_share #ds_share","['#Q&A', '#cv', '#nlp']","['chào', 'sinh viên', '2', 'kỳ', 'chuyên ngành', 'cv', 'nlp', 'ds', 'xác định', 'hướng', 'đi', 'cv', 'nlp', 'ds', 'tham khảo']"
419,"Em chào mọi người.
Mọi người đã có ai học qua khoá AI của AI VietNam chưa ạ. Cho em xin ít review.
Em cảm ơn nhiều.
#Ai_share","['#Q&A', '#machine_learning']","['chào học', 'khóa', 'vietnam', 'review']"
420,"Hello anh/chị. Em có một thắc mắc là khi đi làm triển khai các dự án AI trong thực tế thì các hàm loss là mình sẽ phải tự xây dựng đúng không ạ? 
Theo như em tìm hiểu thì bài toán dạng image classification và segmentation thì phần lớn sử dụng hàm loss có sẵn như cross-entropy. Nhưng ở bài toán detection thì đa phần mình phải tự xây dựng làm loss. 
Nếu như mình dùng mô hình kiểu dạng như SSD thì mình phải tự nghĩ ra và xây dựng làm loss của mình hay sẽ base trên một cái gì đó có sẵn để xây dựng vậy ạ ? Em chưa từng làm dự án thực tế ở các công ty bao giờ nên chưa có kinh nghiệm gì phần này ạ. Mong các anh/chị trong group giải đáp ạ. Em cảm ơn ạ <3. 
#dl_study","['#Q&A', '#cv', '#machine_learning']","['hello', 'thắc mắc', 'đi', 'triển khai', 'dự án', 'hàm loss', 'xây dựng', 'toán', 'dạng', 'image', 'classification', 'segmentation', 'hàm loss', 'sẵn', 'crossentropy toán', 'detection đa', 'xây dựng', 'loss', 'mô hình', 'kiểu', 'dạng', 'ssd', 'xây dựng', 'loss', 'base', 'sẵn', 'xây dựng', 'dự án', 'công ty', 'kinh nghiệm', 'mong', 'group', 'giải đáp', '3']"
421,"Em xin chào tất cả các a/c trong group ạ.Các a/c cho e hỏi một vấn đề nho nhỏ ạ về bài toán OCR nhận dạng câu viết tay bằng tiếng việt ạ. Việc preprocess bộ data để lọc nhiễu, loại bỏ background trước khi đưa vào training có thực sự quan trọng không ạ? Em thì đã thử nghiệm trên vietocr cho bộ dataset raw và bộ data đã được preprocess sử dụng Kmeans như code dưới ảnh ạ thì em thấy em kết quả predict train bộ data gốc tốt hơn. Liệu em đang preprocess có vấn đề hay là việc process như của e là không cần ạ?
Em xin chân thành cảm ơn ạ.","['#Q&A', '#data', '#cv']","['chào', 'tất a', 'c', 'group', 'a c', 'e', 'nho toán', 'ocr', 'dạng', 'câu', 'viết', 'tiếng', 'việt', 'preprocess', 'data', 'lọc nhiễu', 'background', 'training thực', 'thử nghiệm', 'vietocr', 'dataset', 'raw', 'data', 'preprocess', 'kmeans', 'code', 'ảnh', 'kết predict', 'train', 'data', 'gốc liệu', 'preprocess', 'process', 'e', 'chân thành']"
422,"Hướng dẫn cách chọn biểu đồ trực quan hóa dữ liệu phù hợp 🔥🔥🔥
Với các bạn đang đi học hay đi làm trong mảng Data Science, có lẽ các bạn không còn xa lạ gì với khái niệm Data visualization, hay trực quan hóa dữ liệu. Với các thư viện như Matplotlib, Seaborn hay Plotly, chúng ta có rất nhiều sự lựa chọn biểu đồ khác nhau. Tuy nhiên chính vì có quá nhiều sự lựa chọn, đôi khi chúng ta cũng sẽ gặp khó khăn vì không biết nên chọn cái nào 🥹
Tài liệu dưới đây sẽ giúp các bạn có thể chọn được loại biểu đồ phù hợp cho mỗi dữ liệu, mỗi bài toán khác nhau 🥰
Link to pdf: https://drive.google.com/file/d/1sSSzJAPZcCOJITayfdNQm33cUky8lkZ8/view?usp=sharing
#ds_share","['#sharing', '#data', '#python']","['hướng', 'biểu đồ', 'trực quan', 'hóa liệu', 'đi', 'học', 'đi', 'mảng', 'data', 'science lẽ', 'lạ', 'khái niệm', 'data visualization', 'trực quan', 'hóa liệu', 'thư viện', 'matplotlib', 'seaborn', 'plotly', 'ta', 'lựa biểu', 'đồ nhiên', 'lựa', 'đôi', 'ta', 'khăn', 'tài liệu', 'giúp thể', 'biểu đồ', 'liệu toán', 'link', 'to', 'pdf']"
423,"Chào mọi người trong gr ạ, Mình đang tính làm một vài project như detection, classification để push lên git nhưng vẫn có vài thắc mắc. Khi xây dựng model thì nên build lại từ đầu hay là sử dụng những model có khung sẵn ( như yolo…), sử dụng weight đã qua train, làm sao để biết đc model nào phù hợp với bài toán của mình và nên đẩy những file nào lên git. Nếu như k sử dụng model có sẵn thì làm sao để lựa chọn được số lượng layers, số unit trong mỗi layers, size_kenel cho phù hợp với bài toán.
#dl_cv","['#Q&A', '#deep_learning', '#cv']","['chào', 'gr', 'project', 'detection', 'classification', 'push', 'git', 'thắc mắc', 'xây dựng', 'model', 'build', 'đầu', 'model', 'khung', 'sẵn', 'yolo', 'weight', 'train', 'đc', 'model toán', 'đẩy', 'file', 'git', 'k', 'model', 'sẵn', 'lựa', 'layers', 'unit', 'layers', 'size_kenel toán']"
424,"EM CHÀO MỌI NGƯỜI Ạ!
Em đang làm một project sử dụng giọng nói để điều khiển nhà thông minh. Hướng của em là sử dụng input giọng nói để convert thành text, sau đó sử dụng text để thực hiện hành động.

Hiện tại thì em đã xong bước speech to text rồi, còn hướng sử dụng text để thực thi hành động thì chưa có hướng research cụ thể. 
Mọi người cho em xin vài keyword về vấn đề này với ạ.
Em cảm ơn ạ.
#py_study #nlp_study","['#Q&A', '#nlp', '#machine_learning']","['chào', 'project', 'giọng', 'khiển', 'thông minh', 'hướng', 'input', 'giọng', 'convert', 'thành', 'text', 'text', 'hành động', 'xong', 'speech', 'to', 'text', 'hướng', 'text', 'thực thi hành', 'động', 'hướng', 'research', 'keyword']"
425,"Em chào mọi người ạ. Em ngoi lên đây bởi vì chưa tìm được hướng giải cho bài code này ạ (em có hỏi trên VNOI với gr Ôn luyện HSG Tin rồi nhưng chưa thấy ai rep hết ạ). Đề bài thì như hình ở dưới ạ.
Em đọc hướng dẫn thì bài này sử dụng thuật toán tham lam, nhưng hiện tại em vẫn chưa biết ý tưởng và cách implement thuật toán tham lam cho bài này như thế nào.
Không biết ở đây có ai đọc đề xong và có thể chỉ em hướng đi cũng như code implementation cho bài này được không ạ? Em cảm ơn mọi người rất nhiều ạ.
P/s: lý do em post là vì 6/12 em thi OLP rồi (bảng Không chuyên) mà em còn đang mông lung vài thứ ạ
#py_code #py_algorithm","['#Q&A', '#python']","['chào', 'ngoi', 'hướng', 'giải', 'code', 'vnoi', 'gr', 'ôn luyện', 'hsg', 'rep', 'đề hình', 'đọc', 'hướng', 'thuật toán', 'tham lam', 'tưởng', 'implement thuật toán', 'tham lam', 'đọc', 'đề', 'xong thể', 'hướng', 'đi', 'code', 'implementation', 'p', 's lý', 'post', '6', '12', 'thi', 'olp', 'bảng', 'chuyên mông', 'lung']"
426,"Các bác cho em hỏi làm cách nào để đống dữ liệu ở terminal xuống từng dòng và tách ra chỉ lấy địa chỉ email thôi vậy ạ? Em newbie đang làm bài tập mà mò tận 6 tiếng vẫn chưa biết cách @@
#Python","['#Q&A', '#python']","['đống', 'liệu', 'terminal', 'dòng', 'tách', 'địa email', 'newbie', 'tập mò', 'tận', '6', 'tiếng']"
427,"How long become to done?
Buồn cho em PC
#funny #python",['#sharing'],"['how', 'long', 'become', 'to', 'done', 'buồn', 'pc']"
428,"Em chào mọi người, em đang tìm hiểu về mảng xử lí ảnh và cũng mới làm được 1 số bài tập như là nhận diện khuôn mặt bằng web cam,mọi người cho em xin bài tập phù hợp với trình độ của em với ạ. Em cảm ơn!
#DL_study","['#Q&A', '#cv']","['chào mảng', 'xử lí', 'ảnh', '1', 'tập diện', 'khuôn mặt', 'web', 'cam tập', 'trình độ']"
429,"Tổng hợp Plotly - thư viện về Data Visualization trong Python 🔥🔥🔥
Hi các bạn,
Trong Python, có rất nhiều thư viện hỗ trợ chúng ta trong việc trực quan hóa dữ liệu. Bên cạnh 1 vài cái tên đã quá đỗi quen thuộc với chúng ta như Matplotlib hay Seaborn thì Plotly cũng là 1 cái tên vô cùng xuất sắc. Tài liệu dưới đây tổng hợp tất cả các plot phổ biến nhất của Plotly. Nó sẽ giúp các bạn làm quen với thư viện tuyệt vời này tốt hơn 😎
Link to pdf: https://drive.google.com/file/d/1aEez-MNK5INpu4Ki-rtD6fmbNrcvlMOh/view?usp=sharing
#ds_share","['#sharing', '#data', '#python']","['tổng hợp', 'plotly', 'thư viện', 'data', 'visualization', 'python', 'hi python', 'thư viện', 'ta', 'trực quan', 'hóa liệu', 'cạnh', '1', 'đỗi', 'quen', 'ta', 'matplotlib', 'seaborn', 'plotly', '1', 'vô', 'xuất sắc', 'tài liệu', 'tổng hợp', 'tất plot', 'phổ biến', 'plotly', 'giúp', 'quen', 'thư viện', 'tuyệt vời', 'link', 'to', 'pdf']"
430,"Cho mình hỏi có ai dùng dịch vụ của microsoft azure về ML chưa ạ. Cho mình xin đánh giá vs
#hỏiđáp","['#Q&A', '#machine_learning']","['dịch vụ', 'microsoft', 'azure', 'ml', 'vs']"
431,"Chào mọi người , em đang cần tìm nguồn để đọc cách dùng SVD để giảm chiều dữ liệu file bao gồm cả code, mọi người có chia sẻ giúp em với
#ML","['#Q&A', '#machine_learning']","['chào', 'đọc', 'svd', 'chiều liệu', 'file', 'bao', 'code', 'giúp']"
432,"Em chào anh Việt và mọi người ạ. Em năm nay học lớp 10 và mới học về machine learning đc 1 tháng(trc đó e đã học về python rồi nhưng cùng lắm chỉ dừng lại ở việc code mấy tool fb lỏd) nên em bị kẹt về khoản toán vì e chưa học qua mà chỉ sử dụng đc công thức kiểu máy móc thôi .Anh chị trong nhóm tư vấn cho e về trường hợp này với!
#ml_study","['#Q&A', '#machine_learning', '#math']","['chào', 'việt', 'học', 'lớp', '10', 'học', 'machine', 'learning', 'đc', '1', 'trc', 'e học', 'python', 'lắm', 'dừng', 'code', 'mấy', 'tool', 'fb', 'lỏd kẹt', 'khoản', 'toán', 'e học', 'đc', 'công thức', 'kiểu', 'máy móc', 'tư vấn', 'e', 'trường hợp']"
433,"AI Stories podcast - nơi bạn vừa học AI vừa luyện kĩ năng nghe tiếng Anh 🔥🔥🔥
AI Stories là 1 trong số những kênh podcast nổi tiếng nhất về AI. Ở đây chúng ta sẽ có các podcast về AI, Data Science, Machine Learning, Deep Learning được nói bởi các diễn giả khác nhau 😁
Họ sẽ không nói về lý thuyết hàn lâm mà sẽ nói về ứng dụng, trải nghiệm và kinh nghiệm của bản thân họ khi học, sử dụng và làm việc với AI 😊
1 điểm mình thấy rất hay là khi nghe các podcast này, các bạn có thể đồng thời luyện kĩ năng nghe luôn. Rất phù hợp với các bạn nào đang muốn luyện nghe TOEIC, IELTS. Mình đánh giá về độ khó là hơn 1 chút so với bài nghe TOEIC và tương đương bài nghe IELTS 😎
Link to podcast: https://aistories.buzzsprout.com/
#dsml_share","['#sharing', '#machine_learning']","['stories', 'podcast', 'học luyện', 'kĩ năng', 'tiếng', 'stories', '1', 'kênh', 'podcast', 'nổi tiếng', 'ta', 'podcast', 'data', 'science', 'machine', 'learning', 'deep', 'learning diễn', 'giả', 'lý thuyết', 'hàn lâm', 'ứng dụng', 'trải nghiệm', 'kinh nghiệm', 'thân học', '1', 'podcast thể luyện', 'kĩ năng', 'luyện', 'toeic', 'ielts độ', '1', 'chút', 'toeic', 'tương đương', 'ielts', 'link', 'to', 'podcast', 'https', 'aistories', 'buzzsprout', 'com']"
434,"Chào mọi người, hiện tại em đang có tập data như thế này, em muốn tham khảo từ mọi người xem các bước tiền xử lí như thế nào trước khi đưa vào model nlp.
Cảm ơn anh Việt Nguyễn đã duyệt bài và cảm ơn mn giúp đỡ ạ.
#nlp_code
#dl_nlp_code","['#Q&A', '#data']","['chào tập', 'data', 'tham khảo', 'tiền', 'xử lí', 'model', 'nlp', 'việt', 'nguyễn duyệt', 'mn', 'giúp đỡ']"
435,"#dl_PC
Em chào mn ạ,
Mọi người cho em tham khảo về cấu hình máy để train deep learning phục vụ đồ án/học tập với ạ.
1. CPU em nên chọn i7 12700 hay i5 13600k ạ
2. GPU em nên ưu tiên vram hay card ạ, ý em là em nên chọn RTX 3600 12Gb hay RTX 3060Ti 8Gb ạ
Ngoài cac CPU và GPU em nhắc đến mọi ngươi có thể gợi ý cho em cấu hình không ạ, em cảm ơn mn.
P/s: Budget em khoảng 25-26m cho cả bộ ạ. (Em dự định dùng cpu,..2nd)","['#Q&A', '#deep_learning']","['chào mn', 'tham khảo', 'cấu hình', 'máy', 'train', 'deep', 'learning', 'phục vụ', 'đồ án', 'học tập', '1', 'cpu', 'i7', '12700', 'i5', '13600', 'k', '2', 'gpu', 'ưu tiên', 'vram', 'card', 'rtx', '3600', '12', 'gb', 'rtx', '3060', 'ti', '8', 'gb', 'cac', 'cpu', 'gpu', 'nhắc thể', 'gợi cấu hình', 'mn', 'p', 's', 'budget', '2526', 'm', 'dự định', 'cpu', '2', 'nd']"
436,"TÀI KHOẢN COURSERA FREE
Hi mn,
mn có thể qua dol.ny.gov để đky tài khoản coursera free. Tài khoản này là do chính phủ hỗ trợ những người thất nghiệp ở NY. Có thể học được các khoá có professional certificate nhá. Có thể đăng ký lần đầu không được (Như mình đăng ký 2 lần mới thành công).
https://dol.ny.gov/online-learning-coursera
Mn có thể cho mình 1 star tại đây ạ nếu cảm thấy có ích ạ :D
https://github.com/albertnguyen97/coursera-free",['#sharing'],"['tài khoản', 'coursera', 'free', 'hi mn', 'mn thể', 'đky', 'tài khoản', 'coursera', 'free', 'tài khoản', 'phủ', 'thất nghiệp', 'ny thể', 'học', 'khóa', 'professional', 'certificate', 'nhá thể', 'đăng ký', 'đầu', 'đăng ký', '2', 'thành công', 'https', 'onlinelearningcoursera', 'mn thể', '1', 'star ích', 'd']"
437,"Toàn bộ các thuật toán được code từ đầu với Python, không sử dụng bất kì 1 thư viện nào 🔥🔥🔥
Nếu các bạn là người thích tìm hiểu, mày mò tìm hiểu cách xây dựng lại các thuật toán from scratch, thì repo này là dành cho các bạn. Tất cả các thuật toán trong nhiều mảng khác nhau, từ cấu trúc dữ liệu, đại số tuyến tính, machine learning đến thị giác máy tính, xử lý ngôn ngữ tự nhiên đều được code thuần bằng Python và không hề sử dụng bất kì 1 thư viện nào, ngoài các builtin function. Đây là 1 repo cực kì nổi tiếng về Python (đã có 172k star và 43k lượt fork). Nếu các bạn trong quá trình học Machine Learning/Deep Learning mà không hiểu các thuật toán, dù đã đọc đi đọc lại lý thuyết rất nhiều lần, thì repo này là cứu cánh tuyệt vời dành cho các bạn
Link github: https://github.com/TheAlgorithms/Python","['#sharing', '#python']","['toàn', 'thuật toán', 'code', 'đầu', 'python', '1', 'thư viện', 'mày mò', 'xây dựng', 'thuật toán', 'from', 'scratch', 'repo', 'tất thuật', 'toán mảng', 'cấu trúc liệu', 'đại tuyến', 'machine', 'learning', 'thị giác', 'máy ngôn ngữ nhiên', 'code', 'python', 'hề', '1', 'thư viện', 'builtin', 'function', '1', 'repo', 'cực kì', 'nổi tiếng', 'python', '172', 'k', 'star', '43', 'k', 'lượt', 'fork trình', 'học', 'machine', 'learning', 'deep', 'learning thuật toán', 'đọc', 'đi đọc', 'lý thuyết', 'repo', 'cứu cánh', 'tuyệt vời', 'link', 'github']"
438,"[Bản Tiếng Việt] Machine Learning Yearning - quyển sách với hướng tiếp cận độc đáo được chắp bút bởi Prof. Andrew Ng 🔥🔥🔥
Lại 1 lần nữa mình share sách gốc xong rồi mới biết có bản tiếng Việt 😅
Cách đây mấy hôm mình có chia sẻ với các bạn về quyển sách Machine Learning Yearning - 1 trong số các best book về AI của Prof. Andrew Ng...
... Thì đến hôm nay mình mới vô tình biết được là group Machine Learning cơ bản của anh Tiệp đã từng dịch quyển sách này rồi 🥰🥰🥰. Do đó mình xin chia sẻ lại phiên bản tiếng Việt của quyển sách này ở đây:
Link to pdf: https://drive.google.com/file/d/173glVxAhDcqWpCReSn30nZC6KLbDXhAH/view?usp=sharing (mình down về và tải lên drive vì đã từng thấy có nhiều bạn gặp trục trặc trong việc down tài liệu về từ Github 😢)
Nguồn: https://github.com/mlbvn/ml-yearning-vi
#ml_share","['#sharing', '#machine_learning']","['tiếng', 'việt', 'machine', 'learning', 'yearning', 'quyển', 'sách', 'hướng', 'tiếp cận', 'độc đáo', 'chắp bút', 'prof', 'andrew', 'ng', '1', 'share', 'sách', 'gốc', 'xong', 'tiếng', 'việt', 'mấy', 'hôm', 'quyển', 'sách', 'machine', 'learning', 'yearning', '1', 'best', 'book', 'prof', 'andrew', 'ng', 'hôm', 'vô tình', 'group', 'machine', 'learning', 'tiệp', 'dịch', 'quyển', 'sách', 'phiên', 'tiếng', 'việt', 'quyển', 'sách', 'link', 'to', 'pdf', 'down tải', 'drive', 'trục trặc', 'down', 'tài liệu', 'github']"
439,"Em hiện tại mới đi thực tập ở 1 công ti nhỏ. Em làm nghiên cứu là chính nhưng do công ti start up nên nó trở lên nhiều việc hơn@@. Thì sếp cho em 1 con server ubuntu, và muốn em đưa code chạy AI lên đó, nhưng không dùng các lệnh pip, apt để tải gói, chỉ dùng ssh hay công cụ nào đó chuyển file lên và gõ lệnh py file.py là run.
Về phần dùng code nối với các lib của pip thì em đẩy lên được, nhưng các phần như các gói apt cần thêm thì em chưa biết cách xử lí như nào?
Ví dụ em link code tới thư viện ultralytics thì khi chạy sẽ báo thiếu distutils và em cần cài thêm apt install python3.7-distutils,.. Thì cách đưa, nạp các phần thiếu này như nào ạ.
Theo em nghĩ là em sẽ tra xem gói python3.7-distutils khi tải về nằm ở đâu và em save lại và đẩy lên đúng vị trí đó ở server. Trước mắt là em thấy nó sẽ khá tốn thời gian vì có thể nhiều gói@@, còn về cách thực hiện như này liệu được không thì em chưa thử.
Hi vọng mọi người giải đáp và đưa ra 1 số hướng cho em tìm kiếm thêm ạ. Em xin cảm ơn:3
#other","['#Q&A', '#machine_learning']","['đi', 'thực tập', '1', 'công ti', 'nghiên cứu', 'công ti', 'start up', 'trở sếp', '1', 'server', 'ubuntu code', 'chạy', 'lệnh', 'pip', 'apt tải', 'gói', 'ssh', 'công cụ', 'file', 'gõ', 'lệnh', 'py', 'run code', 'nối', 'lib', 'pip', 'đẩy', 'gói', 'apt', 'xử lí', 'ví dụ', 'link', 'code', 'thư viện', 'ultralytics', 'chạy', 'báo distutils', 'cài', 'apt', 'install', 'python3', '7', 'distutils', 'nạp tra', 'gói', 'python3', '7', 'distutils tải', 'nằm', 'save', 'đẩy', 'server', 'mắt', 'tốn thể', 'gói liệu', 'thử', 'hi vọng', 'giải đáp', '1', 'hướng', 'kiếm', '3']"
440,"Chào anh Việt và mọi người. Em là sv của 1 trường thuộc ĐHQG Tp.HCM mới ra trường. Chuyên ngành của em là AI, cụ thể là thiên hướng về mảng Computer Vision. Trong 4 năm đi học, em không tham gia NCKH cũng như LAB ở trường, nên chỉ với tấm bằng giỏi, hiện tại em không thể tìm được cho mình một công việc ở vị trí liên quan. Em đang rất stress khi các nhà tuyển dụng đều đòi hỏi nhiều kinh nghiệm thực tế. Em mong mọi người cho em một hướng đi hoặc các kỹ năng cần phải có của một ML/AI Engineer cần phải có để hoàn thiện mình hơn.
Câu văn hơi lủng củng mong mọi người thông cảm.
#ml_job","['#Q&A', '#machine_learning']","['chào', 'việt', 'sv', '1', 'trường', 'đhqg', 'tp', 'hcm', 'trường', 'chuyên ngành', 'thiên hướng', 'mảng', 'computer', 'vision', '4', 'đi', 'học', 'tham gia', 'nckh', 'lab', 'trường', 'giỏi thể', 'công stress', 'tuyển dụng', 'đòi', 'kinh nghiệm', 'mong', 'hướng', 'đi', 'kỹ năng', 'ml engineer', 'hoàn thiện', 'câu', 'văn hơi', 'lủng', 'củng mong', 'thông cảm']"
441,"Xin chào mọi người
Hiện tại em đang làm chương trình nhận diện các thành phần của ngôi nhà như cột, tường, trần nhà, cửa sổ. Em sử dụng yolov8x-seg, train khoảng 300 vòng, nhưng do dữ liệu em thu nhập được rất ít, chỉ khoảng 100 tấm. Em muốn hỏi rằng liệu có thuật toán nào có thể khiến cho máy có thể tô màu thẳng, bo lại theo đúng như hình thật, không nhem nhuốc không ạ?
Xin cảm ơn mọi người rất nhiều!","['#Q&A', '#cv', '#deep_learning']","['chào', 'chương trình', 'diện', 'thành', 'cột', 'tường', 'trần', 'cửa sổ', 'yolov8xseg', 'train', '300', 'vòng liệu', 'thu nhập', '100', 'liệu thuật', 'toán thể', 'máy thể', 'tô', 'màu', 'thẳng', 'bo hình nhem', 'nhuốc']"
442,"Đồ án tốt nghiệp của mình 😎
Hi các bạn,
Trong những ngày qua mình đã nhận được rất nhiều inbox của các bạn hỏi về quyển đồ án ngày trước mình làm lúc học ở TU Munich (cụ thể là 2 bạn 😅). Do cũng không có gì quý báu trong quyển đồ án này, nên mình xin chia sẻ với các bạn ở đây 😄
Topic mình làm là Scalable Image Search with Deep Image Representation. Nôm na là xây dựng mô hình Deep Learning làm chức năng tương tự Google Image Search Engine. Gọi là xây dựng cho oai cơ mà phần main của model là có sẵn rồi 😅
Link to pdf: https://drive.google.com/file/d/1dheQbBVcLGlwEBsIclSlbSyUwnca_P5W/view?usp=sharing
#dl_master_thesis","['#sharing', '#deep_learning']","['đồ', 'án nghiệp', 'hi inbox', 'quyển', 'đồ án', 'học', 'tu munich', '2', 'quý báu', 'quyển', 'đồ án', 'topic', 'scalable', 'image', 'search', 'with', 'deep', 'image', 'representation', 'nôm na', 'xây dựng', 'mô hình', 'deep learning', 'chức năng', 'tương google', 'image', 'search', 'engine', 'gọi', 'xây dựng', 'oai main', 'model', 'sẵn', 'link', 'to', 'pdf']"
443,"Em chào mọi người. Cho em hỏi việc phát hiện người chuyển động qua cam thì cần logic phát hiện như nào ạ. Em đang tính là dùng 2 frame liên tiếp rồi trừ đi ra 1 list chuyển động, sau đó dùng 1 model Yolo detection ra người, kết quả là các motion nếu ở bbox của người thì là người đó có chuyển động ạ. 
Em nên dùng cách như nào ạ? Trong thực tế thì 1 camera phát hiện chuyển động sẽ dựa qua gì?
Ngoài ra là em muốn mỗi Person detection thì set tham số Yolo với 'classes=0' là ra ngườngười, thì tốc độ yolo sẽ nhanh hơn so với detect hết object của nó như nào. Và có model nào chỉ detect người tốt không ạ?
Em xin cảm ơn ạa.
#cv_study
#motion #detect ","['#Q&A', '#cv', '#deep_learning']","['chào', 'phát hiện', 'động', 'cam logic', 'phát hiện', '2', 'frame', 'liên tiếp', 'trừ', 'đi', '1', 'list động', '1', 'model', 'yolo', 'detection', 'kết motion', 'bbox động', '1', 'camera', 'phát hiện', 'động', 'dựa', 'person', 'detection', 'set', 'tham yolo', 'classes', '0', 'ngườngười', 'tốc độ', 'yolo', 'detect', 'object', 'model', 'detect', 'ạa']"
444,"42 thuật toán Machine Learning được sử dụng nhiều nhất đi kèm với sample code 🔥🔥🔥
Mình xin giới thiệu với các bạn 1 quyển sách vô cùng thú vị, tổng hợp 42 thuật toán được sử dụng nhiều nhất trong Machine Learning, vừa được cho ra mắt vào năm nay. Với mỗi thuật toán, ngoài phần diễn giải, chúng ta sẽ có cả sample code với nhiều framework khác nhau (scikit-learn, statmodels, keras, ...) 😍 
42 thuật toán là 42 đại diện đến từ các mảng khác nhau, bao gồm:
Machine Learning 
Deep Learning 
Reinforcement Learning 
Transformer
GPT và các biến thể
...
Link to pdf: https://drive.google.com/file/d/1loGTcKl-W09BcgemYMtYUKLT81cON0yC/view?usp=sharing
#ml_dl_share","['#sharing', '#machine_learning']","['42', 'thuật toán', 'machine', 'learning', 'đi', 'kèm', 'sample', 'code', 'giới thiệu', '1', 'quyển', 'sách', 'vô thú vị', 'tổng hợp', '42', 'thuật toán', 'machine', 'learning', 'mắt', 'thuật toán', 'diễn giải', 'ta', 'sample', 'code', 'framework', 'scikitlearn', 'statmodels', 'keras', '42', 'thuật toán', '42', 'đại diện', 'mảng', 'bao', 'machine', 'learning', 'deep', 'learning', 'reinforcement', 'learning', 'transformer', 'gpt', 'biến thể', 'link', 'to', 'pdf']"
445,"Đố vui AI trúng thưởng (Kỳ 1)

Hi all
Nhằm giúp xây dựng group của chúng ta có thêm các hoạt động giao lưu, giải trí, kể từ tuần này, Việt và mình sẽ tổ chức các event đố vui định kỳ, được tổ chức 1,2 lần/tuần. Thể lệ rất đơn giản, chúng mình sẽ đưa ra 5 câu hỏi trắc nghiệm về AI/DS/ML/DL/CV/NLP, các bạn tham gia sẽ trả lời các câu hỏi này trên google form, đồng thời lựa chọn 1 con số ngẫu nhiên có 3 chữ số (để chúng mình bốc thăm ngẫu nhiên). Ngoài ra, không phải yêu cầu bắt buộc nhưng mình hy vọng các bạn tham gia event này sẽ share bài viết lên fb wall của các bạn. Sau khi kết thúc mỗi kỳ đố vui (1 tuần kể từ ngày bắt đầu), chúng mình sẽ tiến hành tổng hợp kết quả, tất cả các bạn trả lời đúng từ 3/5 câu hỏi trở lên được xem như hợp lệ và chúng mình sẽ tiến hành bốc thăm dựa vào con số may mắn mà các bạn đã chọn. Phần thưởng có thể là tiền mặt, hiện vật....

Phần thưởng của kỳ 1: 200k VND (ck vào tài khoản của các bạn)
Thời gian: 29/10/2023 - 04/11/2023
Link tham gia Đố vui AI trúng thưởng kỳ 1: https://forms.gle/teAmmhdgoMtn8ZFf7",['#webinar'],"['đố', 'vui', 'trúng', 'thưởng kỳ', '1', 'hi all', 'giúp', 'xây dựng', 'group', 'ta', 'hoạt động', 'giao lưu', 'giải trí', 'tuần việt', 'tổ chức', 'event đố', 'vui định kỳ', 'tổ chức', '1', '2', 'tuần thể lệ', 'đơn giản', '5', 'trắc nghiệm', 'ds', 'ml', 'dl', 'cv', 'nlp', 'tham gia', 'google', 'form', 'lựa', '1', 'ngẫu nhiên', '3', 'chữ', 'bốc thăm', 'ngẫu nhiên', 'bắt buộc', 'hy vọng', 'tham gia', 'event', 'share', 'viết', 'fb', 'wall', 'kết thúc', 'kỳ đố', 'vui', '1', 'tuần', 'tiến hành', 'tổng hợp', 'kết tất', '3', '5', 'trở hợp lệ', 'tiến hành', 'bốc thăm', 'dựa', 'may mắn', 'thưởng thể', 'tiền mặt', 'hiện vật', 'thưởng kỳ', '1', '200', 'k', 'vnd', 'ck', 'tài khoản', '29', '10', '2023', '04', '11', '2023', 'link', 'tham gia', 'đố', 'vui', 'trúng', 'thưởng kỳ', '1']"
446,"mn ơi em có bức ảnh chữ cái a, em muốn remove background với khử nhiễu đi, em có thử GaussianBlur và threshold otsu nhưng kết quả vẫn không khử được hết đường kẻ ô ly (ảnh thứ 3) không biết mn có cách nào khác không, ảnh gốc em để dưỡi cmt
#ML_study","['#Q&A', '#machine_learning', '#cv']","['mn', 'ảnh', 'chữ', 'a', 'remove', 'background', 'khử nhiễu', 'đi', 'thử', 'gaussianblur', 'threshold', 'otsu', 'kết khử', 'đường', 'kẻ', 'ô ly', 'ảnh', '3', 'mn', 'ảnh', 'gốc', 'dưỡi', 'cmt']"
447,"Có cách nào để model của yolo chạy trên CPU mà fps của nó cao cao k nhỉ. Model e train trên GPU ok r. Nhưng nếu chạy k có GpU thì fps nó có 2-3fps 🥲
#ml_code","['#Q&A', '#deep_learning']","['model', 'yolo', 'chạy', 'cpu', 'fps', 'k', 'model', 'e train', 'gpu', 'ok r', 'chạy', 'k', 'gpu', 'fps', '23', 'fps']"
448,"Mình nhờ Admin duyệt giúp bài. Thanks
Mình đang tìm 1 anh chị mentor python cho bạn bât đầu nhập môn này. Ai có thể giúp mình thì trao đổi nhé. Thanks",['#Q&A'],"['admin', 'duyệt', 'giúp', 'thanks', '1', 'mentor', 'python', 'bât', 'đầu', 'nhập', 'môn thể', 'giúp', 'trao đổi', 'thanks']"
449,"Hiện tại mình đang học AI & Data ( năm 4 ) ở Đà Nẵng và mình thấy thị trường AI ở Đà Nẵng cực kì khan hiếm hầu như chỉ tuyển senior Mình đang có định hướng rẽ nhánh sang DA or BA, xin mọi người tư vấn ạ #tuvantamly","['#Q&A', '#machine_learning', '#data']","['học', 'data', '4', 'đà nẵng', 'thị trường', 'đà nẵng', 'cực kì', 'khan hiếm', 'hầu tuyển', 'senior', 'định hướng', 'rẽ', 'nhánh', 'da or', 'tư vấn']"
450,"em chào mọi người ạ, cho em xin lộ trình học về ds và machine learning với ạ
#ds_ml_roadmap","['#Q&A', '#machine_learning', '#data']","['chào', 'lộ trình', 'học', 'ds', 'machine', 'learning']"
451,"20 chủ đề quan trọng trong Data Science được tổng kết trong 4 trang Cheatsheet 🔥🔥🔥
Đây là Cheatsheet được thiết kế nhằm giúp các bạn đang học về Data Science muốn hệ thống hóa kiến thức hoặc ôn lại kiến thức nhằm chuẩn bị cho phỏng vấn. 20 topics được tổng kết trong Cheatsheet này bao gồm:
Thống kê
Kiểm định giả thuyết
Các khái niệm
Đánh giá mô hình
Linear Regression 
Logistic Regression 
Decision Tree
Naive Bayes (Mình có thể khẳng định đây là 1 trong số các mô hình vô dụng hiếm hoi về mặt thực tiễn mà vẫn được xuất hiện trong rất nhiều tài liệu 😢)
Support Vector Machines (My favorite ML algorithm 🥰)
k-Nearest Neighbors
Clustering
Dimension Reduction
Xử lý ngôn ngữ tự nhiên
Neural Networks
Convolutional Neural Networks
Recurrent Neural Networks
Boosting
Recommender Systems
Học tăng cường
Anomaly Detection
(Mình không dịch những từ mà mình thấy không thuận miệng các bạn nhé 😅)
Link to pdf: https://drive.google.com/file/d/1FGRe-TuvfO8y9bEz079mzvXW1SS_39KS/view?usp=sharing
#dsml_share","['#sharing', '#data', '#machine_learning']","['20', 'chủ đề', 'data', 'science', 'tổng kết', '4', 'trang', 'cheatsheet', 'cheatsheet', 'thiết kế', 'giúp', 'học', 'data science', 'hệ thống', 'hóa', 'kiến thức', 'ôn kiến thức', 'chuẩn vấn', '20', 'topics', 'tổng kết', 'cheatsheet', 'bao', 'thống kê', 'kiểm định', 'giả thuyết', 'khái niệm', 'mô hình', 'linear', 'regression', 'logistic', 'regression', 'decision', 'tree', 'naive', 'bayes thể', '1', 'mô hình', 'vô dụng', 'hiếm hoi', 'mặt', 'thực tiễn', 'tài liệu', 'support', 'vector', 'machines', 'my', 'favorite', 'ml', 'algorithm', 'knearest', 'neighbors', 'clustering', 'dimension reduction', 'ngôn ngữ nhiên', 'neural', 'networks', 'convolutional', 'neural', 'networks', 'recurrent', 'neural', 'networks', 'boosting', 'recommender', 'systems', 'học cường', 'anomaly', 'detection', 'dịch', 'thuận miệng', 'link', 'to', 'pdf']"
452,"Em chào mọi người ạ,em có một thắc mắc muốn hỏi ý ạ, trong phương pháp để phát hiện biên cạnh thì mình phải tính đạo hàm gradient của hàm số, tuy nhiên trong tập dữ liệu điểm ảnh thì nó không phải hàm liên tục nên không thể tính đạo hàm gradient bằng cách đạo hàm theo fx và fy được, chính vì thế nên chúng ta có phương pháp để xấp xỉ đạo hàm gradient của f(x,y) (theo mình biết thì nó được tính bằng cách tích chập một mặt nạ điểm 3x3 và một kernel) tuy nhiên trong thực tế thư viện cv2 với hàm sobel cho phép mình tính được đạo hàm gradient tuy nhiên thư viện này có hỗ trợ việc tạo ảnh gradient bằng các kernel với kích thước khác với 3x3, thì mình không biết các kernel khác với kích thước (5x5 hoặc 7x7) thì có thể được tính như nào ạ, tương tự với đạo hàm gradient bậc 2 (laplacian) thì mình có thể tính thông qua các kernel khác kernel basic đượcn không ạ
Em cảm ơn ạ
#imageprocessing","['#Q&A', '#cv']","['chào', 'thắc mắc', 'phương pháp', 'phát hiện', 'biên cạnh', 'đạo hàm', 'gradient', 'hàm nhiên', 'tập liệu', 'ảnh hàm', 'liên tục', 'thể', 'đạo hàm', 'gradient', 'đạo', 'hàm fx', 'fy', 'ta', 'phương pháp', 'xấp xỉ', 'đạo', 'hàm gradient', 'f', 'x', 'y tích', 'chập mặt nạ', '3x3', 'kernel nhiên', 'thư viện', 'cv2', 'hàm sobel', 'phép', 'đạo hàm', 'gradient nhiên', 'thư viện', 'ảnh', 'gradient', 'kernel kích thước', '3x3', 'kernel kích thước', '5x5', '7x7 thể', 'tương đạo', 'hàm gradient', 'bậc', '2', 'laplacian thể', 'thông kernel', 'kernel', 'basic', 'đượcn']"
453,"Hi các anh chị ạ, chủ đề này không liên quan lắm nhưng cho em hỏi hiện tại vị trí AI/ML engineer ở Việt Nam nhiều không ạ ? Ngoài ra em đang là sv ngành an toàn thông tin, trái ngược chuyên môn như vậy thì có cơ hội ko ạ ?
Em rất đam mê AI , việc tự học khó khăn nên em chỉ mong những câu hỏi trên sẽ giúp em có thêm động lực thôi ạ
Em xin cảm ơn tất cả anh chị ạ
#career","['#Q&A', '#machine_learning']","['hi chủ đề', 'lắm', 'ml', 'engineer', 'việt nam', 'sv', 'ngành', 'an toàn', 'thông', 'trái ngược', 'chuyên môn', 'hội ko', 'đam mê', 'học', 'khăn', 'mong', 'giúp', 'động lực', 'tất']"
454,"Không biết trong nhóm có bạn nào có ý muốn học 1 khóa từ admin theo dạng hands-on projects không :D? Ý tưởng là người dạy sẽ như một team lead cung cấp supervision để giải quyết 1-2 projects cụ thể ở mức production standard, mình nghĩ các bạn ở giai đoạn chuẩn bị muốn đi làm sẽ học được rất nhiều, thậm chí các bạn đang ở mức junior cũng học được xem một bạn senior sẽ như thế nào, mình thì đang tìm kiếm 1 khóa học như vậy.
#cv_study","['#Q&A', '#machine_learning']","['học', '1', 'khóa', 'admin', 'dạng', 'handson', 'projects', 'd', 'tưởng', 'dạy', 'team', 'lead', 'cung supervision', 'giải quyết', '12', 'projects', 'production', 'standard', 'giai đoạn', 'chuẩn', 'đi', 'học chí', 'junior học', 'senior', 'kiếm', '1', 'khóa', 'học']"
455,"Em chào mn ạ, cho e hỏi là Đại Học Tum khi du học hệ thạc sĩ thì Trường có cần chứng chỉ ielts k ạ hay chỉ cần chứng chỉ gre và gpa,… và AI bên kia có chương trình dạy hoàn toàn bằng tiếng anh k ạ, e cảm ơn nhiều ạ. #xx_study #ml",['#Q&A'],"['chào', 'mn', 'e', 'đại học', 'tum', 'du học', 'hệ', 'thạc sĩ', 'trường chứng', 'ielts', 'k chứng', 'gre', 'gpa', 'kia', 'chương trình', 'dạy', 'tiếng', 'k', 'e']"
456,"Tài liệu tóm tắt lý thuyết + hướng dẫn giải bài tập xác suất thống kê bằng tiếng Việt 🔥🔥🔥
Như các bạn đã biết thì xác suất và thống kê là 2 mảng toán vô cùng quan trọng trong Data Science. Mình trước đây cũng đã đôi lần chia sẻ các tài liệu về xác suất thống kê, nhưng thường chỉ có lý thuyết mà không có bài tập, hoặc nếu có bài tập thì sẽ không có giải. Do đó cũng không thuận tiện lắm trong quá trình các bạn tự học/tự ôn lai 😢
Do đó hôm nay mình xin chia sẻ với các bạn 1 tài liệu hướng dẫn giải bài tập xác suất thông kê bằng tiếng Việt vô cùng đầy đủ. Ở mỗi 1 chương sẽ có các phần sau:
Tóm tắt lý thuyết
Bài tập
Hướng dẫn giải bài tập chi tiết 🥰
Đây là tài liệu được tổng hợp bởi 1 cựu sinh viên Đại học quốc gia Hà Nội. Tài liệu được trình bày vô cùng chi tiết và đẹp mắt (1 điểm cộng cực lớn là tác giả dùng các màu khác nhau cho các đoạn text, từ đó giúp chúng ta dễ tập trung vào những phần quan trọng hơn 😍) Mình đã xem khoảng 70-80% và có thể đảm bảo với các bạn đây là 1 trong các tài liệu giúp các bạn học và ôn tập xác suất thống kê tốt nhất bằng tiếng Việt 😎
#dsml_share
Link to pdf: https://drive.google.com/file/d/1VqSuq7Eqct9bRpmKR_gvozMEiGJ0ihhX/view?usp=sharing","['#sharing', '#math']","['tài liệu', 'tóm tắt', 'lý thuyết', 'hướng', 'giải tập', 'xác suất', 'thống kê', 'tiếng', 'việt', 'xác suất', 'thống kê', '2', 'mảng toán', 'vô data', 'science', 'đôi', 'tài liệu', 'xác suất', 'thống kê', 'lý', 'thuyết tập', 'tập', 'giải', 'thuận tiện', 'lắm', 'trình học', 'ôn lai', 'hôm', '1', 'tài liệu', 'hướng', 'giải tập', 'xác suất', 'thông kê', 'tiếng', 'việt', 'vô', '1', 'chương tóm', 'tắt', 'lý thuyết', 'tập', 'hướng', 'giải tập', 'chi tiết', 'tài liệu', 'tổng hợp', '1', 'cựu', 'sinh viên', 'đại học', 'quốc gia', 'hà nội', 'tài liệu', 'trình bày', 'vô', 'chi tiết', 'đẹp mắt', '1', 'cộng', 'cực', 'tác giả', 'màu', 'đoạn', 'text', 'giúp', 'ta', '7080', 'thể', '1', 'tài liệu', 'giúp', 'học', 'ôn tập', 'xác suất', 'thống kê', 'tiếng', 'việt', 'link', 'to', 'pdf']"
457,"Mọi người cho em hỏi, em train model ML trên jupyter khi đã có kết quả, emm muốn đưa lên web để cho người dùng đưa vào các thông số để dự đoán thì em phải làm saoo ạ?
#ML_study","['#Q&A', '#machine_learning']","['train', 'model', 'ml', 'jupyter', 'kết emm', 'web', 'thông', 'dự đoán', 'saoo']"
458,Dạ e chào a Việt và mọi người. E là sv đang muốn theo NLP cần 1 pro có thể giúp e các bước làm chatbox tiếng việt dùng phoBert và mô hình seq2seq ạ. Dạ e cám ơn nhiều. E cũng có chút quà gửi tặng ạ. 1 lần nữa e cám ơn nhiều ạ #sup_NLP,"['#Q&A', '#nlp', '#deep_learning']","['e', 'chào a', 'việt', 'e', 'sv', 'nlp', '1', 'pro thể', 'giúp', 'e chatbox', 'tiếng', 'việt', 'phobert', 'mô hình', 'seq2seq e', 'cám ơn', 'e chút', 'quà', 'gửi', 'tặng', '1', 'e', 'cám ơn']"
459,"#cv_code
Xin chào mọi người ạ
Có bác nào có thể cho em ví dụ về việc xử lý đa luồng trong đó 1 luồng là request data từ url còn luồng còn lại là nhận data về để phát lên màn hình với thư viện urllib.request k ạ? em viết multithreading mà nó chạy k đc🥲
Em xin cảm ơn","['#Q&A', '#python']","['chào thể', 'ví dụ', 'đa luồng', '1', 'luồng', 'request', 'data', 'url', 'luồng', 'data phát', 'màn hình', 'thư viện', 'urllib', 'request', 'k', 'viết', 'multithreading', 'chạy', 'k', 'đc']"
460,"Em chào mọi người.
Để mình chuẩn bị cv cho việc đi thực tập thì cv cần có những project về mảng gì và cần ít nhất bao nhiêu cái thì mình có thể đi thực tập ạ.
Em cảm ơn mn.
#ds_study",['#Q&A'],"['chào', 'chuẩn', 'cv', 'đi', 'thực tập', 'cv', 'project', 'mảng thể', 'đi', 'thực tập', 'mn']"
461,"Em chào anh Việt và mọi người ạ ,em mới tìm hiểu về ML và DL mà em ko tìm đc tài liệu nào như ý muốn . Em muốn tài liệu hướng dẫn train tập dữ liệu mình tự chuẩn bị là các file dạng IDX em tách thành 1 tập train 1 tập để test trong 2 folder. Dữ liệu là dạng file Pcap các thiết bị trong IOT em chuyển về dạng file IDX để làm đầu vào CNN như kiểu MNIST ấy ạ. Ai có tài liệu nào hướng dẫn train mô hình chia sẻ cho em với ạ em cảm ơn ạ.
#ml_study #dl_study","['#Q&A', '#machine_learning']","['chào', 'việt', 'ml', 'dl', 'ko', 'đc', 'tài liệu', 'tài liệu', 'hướng', 'train', 'tập liệu', 'chuẩn', 'file', 'dạng', 'idx', 'tách', 'thành', '1', 'tập', 'train', '1', 'tập', 'test', '2', 'folder liệu', 'dạng', 'file', 'pcap thiết', 'iot', 'dạng', 'file', 'idx', 'đầu', 'cnn', 'kiểu', 'mnist', 'tài liệu', 'hướng', 'train', 'mô hình']"
462,"[Hot news] NVIDIA trở thành nhà tài trợ cũng như đối tác mới nhất của Scikit-learn 🔥🔥🔥
Có vẻ như trong tương lai không xa chúng ta sẽ thấy những Linear Regression hay Random Forest chạy trên GPU rồi các bạn ơi 🥰
Link to article: https://blog.scikit-learn.org/funding/nvidia-is-a-new-sponsor/
#dl_news
P/s: Vậy là sau này không cần phải ngồi đợi dài cổ để chờ GridSearchCV chạy nữa các bạn nhỉ 😎","['#sharing', '#machine_learning']","['hot', 'news nvidia', 'tài trợ', 'đối tác', 'scikitlearn vẻ', 'tương lai', 'ta', 'linear', 'regression', 'random', 'forest', 'chạy', 'gpu', 'link', 'to', 'article', 'https', 'blog', 'scikitlearn', 'org', 'funding', 'nvidiaisanewsponsor', 'p', 's', 'đợi', 'cổ', 'chờ', 'gridsearchcv', 'chạy']"
463,"Bản draft của Understanding Deep Learning - cuốn sách sẽ được phát hành chính thức vào ngày 05/12/2023 bởi MIT Press 🔥🔥🔥
Đây là cuốn sách gây sốt trên Linkedin trong suốt khoảng 3 tháng trở lại đây. Cuốn sách này là tài liệu All-in-one mà các bạn cần có về Deep Learning. 21 chương của cuốn sách này sẽ đưa các bạn đi từ những khái niệm cơ bản về Supervised Learning, Neural Networks cho đến các khái niệm nâng cao như Diffusion models hay Reinforcement Learning 😍
Ngoài tài liệu chính, tác giả còn release thêm 2 nguồn tài liệu, dành riêng cho giảng viên và sinh viên. Cụ thể:
Đối với giảng viên: Mỗi chương sẽ đi kèm với slide dạng pdf, svg và ppt
Đối với sinh viên: Các bạn sẽ có tổng cộng 68 bài tập notebook xuyên suốt 21 chương của cuốn sách
Mình đã đọc thử 3 chương mà mình chưa có nhiều kinh nghiệm là 12, 17 và 18. 1 cuốn sách cực kì chất lượng. Bìa của cuốn sách nhìn hơi thô, nhưng nội dung thì không phải bàn các bạn nhé. Mình highly recommend các bạn đọc cuốn sách này 😎
Link: https://udlbook.github.io/udlbook/
#dl_share","['#sharing', '#deep_learning']","['draft', 'understanding', 'deep', 'learning', 'sách', 'phát hành thức', '05', '12', '2023', 'mit', 'press', 'sách', 'sốt linkedin', 'suốt', '3', 'trở sách', 'tài liệu', 'allinone', 'deep', 'learning', '21', 'chương', 'sách', 'đi', 'khái niệm', 'supervised', 'learning', 'neural', 'networks', 'khái niệm', 'nâng', 'diffusion', 'models', 'reinforcement', 'learning', 'tài liệu', 'tác giả', 'release', '2', 'tài liệu', 'giảng viên', 'sinh viên', 'đối giảng viên', 'chương', 'đi', 'kèm', 'slide', 'dạng', 'pdf', 'svg', 'ppt', 'đối sinh viên', 'tổng cộng', '68', 'tập', 'notebook', 'xuyên', 'suốt', '21', 'chương', 'sách', 'đọc', 'thử', '3', 'chương', 'kinh nghiệm', '12', '17', '18', '1', 'sách', 'cực kì', 'chất', 'bìa', 'sách', 'hơi', 'thô', 'nội dung', 'bàn', 'highly recommend', 'đọc', 'sách', 'link', 'https', 'udlbook', 'github', 'io', 'udlbook']"
464,"chào mọi người ạ, em đang tìm hiểu về thuật toán Kmeans và có chút thắc mắc với đoạn code ở dưới ạ. Trong đoạn code dưới thì mình đã lấy các dữ liệu cần thiết từ databan đầu và gán vào data2, nhưng sau đó mình lại mới Scaler data ban đầu trong khi data đem đi train lại là data2 thì hàm Scaler có vô nghĩa không ạ, nếu không thì chức năng của hàm Scaler trong đoạn code dưới là gì ạ , em cảm ơn ạ
#ml_study","['#Q&A', '#machine_learning']","['chào thuật', 'toán', 'kmeans', 'chút', 'thắc mắc', 'đoạn', 'code', 'đoạn', 'code liệu', 'thiết databan', 'đầu', 'gán', 'data2', 'scaler', 'data', 'ban đầu', 'data', 'đem', 'đi', 'train', 'data2', 'hàm scaler', 'vô nghĩa', 'chức năng', 'hàm scaler', 'đoạn', 'code']"
465,"Tổng hợp các metrics cho bài toán Regression 🔥🔥🔥
Hi các bạn,
Regression (hồi quy) là 1 trong 2 bài toán cơ bản của mảng học có giám sát (Supervised Learning), bên cạnh bài toán Classification (phân loại). Dưới đây là tài liệu 26 trang tổng hợp 5 metrics thường được sử dụng trong bài toán Regression để đánh giá mô hình, bao gồm:
Mean Absolute Error
Mean Squared Error
Root Mean Squared Error
R-squared (Hay còn được biết đến với cái tên Coefficient of Determination)
Adjusted R-squared
Đây thực ra không phải kiến thức khó, nhưng dù sao thì ôn tập không bao giờ là thừa cả 😁
Link to pdf: https://drive.google.com/file/d/1vWC1yWFZF7zCeb0pmiyP6rfmavp-OvEe/view?usp=sharing
#ml_share","['#sharing', '#machine_learning']","['tổng hợp', 'metrics toán', 'regression', 'hi regression', 'hồi quy', '1', '2', 'toán', 'mảng', 'học', 'giám sát', 'supervised', 'learning', 'cạnh toán', 'classification', 'phân tài liệu', '26', 'trang', 'tổng hợp', '5', 'metrics toán', 'regression', 'mô hình', 'bao', 'mean', 'absolute', 'error', 'mean', 'squared', 'error', 'root', 'mean', 'squared', 'error', 'rsquared', 'coefficient', 'of determination', 'adjusted', 'rsquared thực kiến thức', 'ôn tập', 'thừa', 'link', 'to', 'pdf']"
466,"Dạ em chào anh Việt và mọi người ạ, em muốn viết một file .py và khi run file thì mình có thể cung cấp các đối số ngay trên lệnh giống bên dưới thì mình cần search từ khóa nào ạ. Em search nhưng không ra được, mọi người chỉ em với.
#py_code
#py_study","['#Q&A', '#python']","['chào', 'việt', 'viết', 'file', 'py', 'run', 'file thể', 'cung', 'đối lệnh', 'search', 'khóa', 'search']"
467,"#ds_ml_job
em hiện tại là sinh viên năm 4 ngành công nghệ thông tin ,e nghiên cứu AI từ năm 1 và đến giờ cũng biết được khá khá từ computer vision đến NLP các giải thuật về ML/DL em đều cố gắng học từ toán học lên mỗi giải thuật mới em học em đều biết chương trình bang tay không xài thư viện , khi hiểu bản chất thì moi học cách sử dụng thư viện .Hiện tại e đang tính đi thực tập mà thấy mấy bạn giỏi qua nên em khá tự ti không biết như vậy đủ thực tập chưa a hay phải nghiên cứu thêm ạ thanks mn","['#Q&A', '#machine_learning']","['sinh viên', '4', 'ngành', 'công nghệ thông e', 'nghiên cứu', '1', 'computer', 'vision', 'nlp', 'giải thuật', 'ml', 'dl', 'cố gắng', 'học toán học', 'giải thuật', 'học', 'chương trình', 'bang', 'xài', 'thư viện', 'chất', 'moi', 'học', 'thư viện', 'e', 'đi', 'thực tập', 'mấy', 'giỏi', 'ti thực tập', 'a', 'nghiên cứu', 'thanks', 'mn']"
468,mn cho mình hỏi CPU_frequency và Price đều là 2 cột tại sao CPU thì cần 2 ngoặc vuông [[ vậy ạ?,"['#Q&A', '#machine_learning']","['mn', 'cpu_frequency', 'price', '2', 'cột', 'cpu', '2', 'ngoặc', 'vuông']"
469,"Dạ em chào anh Việt và mọi người ạ. Thì em đang vọc vạch tìm hiểu cách viết một reponsitory hoàn chỉnh trên Github, tuy là hơi vô tri vì đưa project ipynb lên. Mọi người xem, góp ý giúp em cách viết với ạ. Em viết readme nhưng không biết liệu có ổn hay không.
#other",['#Q&A'],"['chào', 'việt', 'vọc', 'vạch', 'viết', 'reponsitory', 'hoàn chỉnh', 'github hơi', 'vô tri', 'project', 'ipynb', 'góp', 'giúp', 'viết', 'viết', 'readme liệu', 'ổn']"
470,"Em đang muốn tìm nguồn code để triển khai dự án skin lesion cho khuôn mặt:
SLSNet: Skin lesion segmentation using a lightweight generative adversarial network
đây là một pp e đang cần code mà không biết tìm đâu, với một phương pháp nữa dùng PGAN, mọi người giúp em với ạ, cảm ơn mọi người.
#DL_study","['#Q&A', '#deep_learning', '#cv']","['code', 'triển khai', 'dự án', 'skin', 'lesion', 'khuôn mặt', 'slsnet', 'skin', 'lesion', 'segmentation', 'using', 'a', 'lightweight', 'generative', 'adversarial', 'network', 'pp', 'e code', 'phương pháp', 'pgan', 'giúp']"
471,"Hello mọi người chuyện là em có 1 dự án như này : Xây dựng hệ thống tư vấn Y tế dựa trên dữ liệu Bệnh án. Thì cho em hỏi cần sử dụng phương pháp nào để có thể xây dựng bài toán để dự đoán như đề tài trên ạ
#ml_questions","['#Q&A', '#machine_learning']","['hello', '1', 'dự án', 'xây dựng', 'hệ thống', 'tư vấn', 'y tế', 'dựa liệu', 'bệnh án', 'phương pháp thể', 'xây dựng', 'toán', 'dự đoán', 'đề tài']"
472,"Tổng hợp tên của hơn 100 thuật toán Machine Learning 🔥🔥🔥 
Tài liệu này chỉ tổng hợp tên và giới thiệu rất ngắn gọn thôi các bạn nha ☺️
Link to pdf: https://drive.google.com/file/d/1oOlyfxxRPbaA4iISEPNOCVhnBUGavpKm/view?usp=sharing
P/s: Mình biết chưa đến 1/3 chỗ này 😅
#ml_share","['#sharing', '#machine_learning']","['tổng hợp', '100', 'thuật toán', 'machine', 'learning', 'tài liệu', 'tổng hợp', 'giới thiệu', 'ngắn gọn', 'nha', 'link', 'to', 'pdf', 'p', 's', '1', '3', 'chỗ']"
473,"Hi mọi người ạ,
Hiện tại em có một đề bài như thế này ạ: Dùng thuật toán để xác định mức độ positive và negative của chuyên gia về triển vọng kinh tế toàn cầu và Việt Nam.
Em muốn hỏi xin anh chị bạn em một vài hướng đi cho đề bài này, trong số đó có cách nào là mới nhất cập nhật nhất theo xu hướng hiện nhất không ạ ?
Em cảm ơn mọi người nhiều ạ./.
#py_challenge #ds_ml_challenge","['#Q&A', '#machine_learning']","['hi đề thuật toán', 'xác định', 'độ', 'positive', 'negative', 'chuyên gia', 'triển vọng', 'kinh tế', 'toàn cầu', 'việt nam', 'hướng', 'đi', 'đề cập nhật', 'xu hướng', 'hiện']"
474,"Lecture notes của khóa Optimization for Data Science của đại học Oxford 🔥🔥🔥
Hi các bạn,
Oxford là trường nào thì chắc mình cũng không cần giới thiệu với các bạn nữa 😅 Optimization hay tối ưu hóa thì thật ra không phải là 1 nhánh Toán quá phổ biến đối với Data Science (ít nhất là so sánh với xác suất thống kê, đại số tuyến tính hay giải tích) 🥲
Khóa học này (diễn ra trong năm 2023 luôn), theo quan điểm cá nhân của mình, thì nó dành cho mảng Machine Learning hay Deep Learning nhiều hơn là cho Data Science (mặc dù mình thừa nhận rằng Data Science sử dụng nhiều kiến thức của ML/DL) 😁
Đây là khóa học dành cho chính sinh viên của trường, chứ không phải là khóa học online được thiết kế giảm tải để dễ tiếp cận cho học viên học online trên khắp thế giới, do đó nội dung là khá nặng các bạn nhé 😅
Anyway, trong khóa học này các bạn sẽ được học tất cả các kiến thức liên quan đến optimization, mà chủ yếu là các kiến thức có liên quan đến gradient - 1 phần cực kì quan trọng trong Deep Learning.
Link to pdf: https://drive.google.com/file/d/1XPXDZTEa1HXoOP6LYtLtb2CAcmmLl993/view?usp=sharing
#ds_ml_share","['#sharing', '#data', '#machine_learning']","['lecture', 'notes', 'khóa', 'optimization', 'for', 'data', 'science', 'đại học', 'oxford', 'hi oxford', 'trường', 'giới thiệu', 'optimization', 'tối ưu hóa', '1', 'nhánh toán', 'phổ biến', 'đối data', 'science', 'sánh', 'xác suất', 'thống kê', 'đại tuyến', 'giải tích', 'khóa', 'học', 'diễn', '2023', 'quan mảng', 'machine', 'learning', 'deep', 'learning', 'data', 'science', 'mặc', 'thừa', 'data science', 'kiến thức', 'ml', 'dl', 'khóa', 'học sinh viên', 'trường', 'khóa học', 'online', 'thiết kế', 'tải', 'tiếp cận', 'học viên', 'học', 'online', 'khắp', 'giới', 'nội dung', 'anyway', 'khóa', 'học', 'học', 'tất kiến thức', 'optimization', 'chủ yếu', 'kiến thức', 'gradient', '1', 'cực kì', 'deep', 'learning', 'link', 'to', 'pdf']"
475,"Chào mọi người, chuyện là em có bài tập phải crawl data từ 1 page trên fb về để phân tích. Nhưng em đang gặp khó khăn trong việc crawl data về. Lúc thì crawl về được nhưng không có dữ liệu bên trong. Lúc thì không crawl được đủ số bài.Dưới đây là thư viện và code mà em dùng. Mng có hướng giải quyết nào không ạ. Em xin cảm ơn.
#py_code","['#Q&A', '#data', '#python']","['chào tập', 'crawl', 'data', '1', 'page', 'fb', 'phân tích', 'khăn', 'crawl', 'data', 'crawl liệu', 'crawl', 'thư viện', 'code', 'mng', 'hướng', 'giải quyết']"
476,"Em chào anh chị và các bạn ạ, em đang thực hiện 1 project nho nhỏ về NLP , mọi người cho em hỏi đã có ai đã từng xử lý dữ liệu text tiếng Việt cụ thể là xử lý lọc các từ ngoại ngữ (không phải tiếng Việt) trong câu chưa ạ, em có đang sử dụng thư viện pyenchant để lọc nhưng thực sự nó lọc không tốt và vẫn nhầm lẫn giữa tiếng Việt và ngoại ngữ. Ai có hướng giải quyết có thể giúp em không ạ? Em cảm ơn nhiều
#dl_study","['#Q&A', '#nlp', '#python']","['chào', '1', 'project', 'nho', 'nlp liệu', 'text', 'tiếng', 'việt', 'lọc', 'ngoại ngữ', 'tiếng', 'việt', 'câu', 'thư viện', 'pyenchant', 'lọc', 'thực lọc', 'nhầm lẫn', 'tiếng', 'việt', 'ngoại ngữ', 'hướng', 'giải quyết thể', 'giúp']"
477,"Chào a Việt và các ae e muốn bắt đầu học về machine learning ae có thể gợi ý cho em vài khóa học về ML được không ạ. Em có tìm hiểu trên Udemy thấy có khóa này là best seller ae nào học rồi có thể cho e xin rv với. Với lại em nên ôn lại các kiến thức toán song song với quá trình học hay là ôn trước rồi mới bắt đầu học. Thanks ae đã đọc
#Machinelearning #ML","['#Q&A', '#machine_learning']","['chào', 'a việt', 'ae', 'e học', 'machine', 'learning', 'ae thể', 'gợi khóa', 'học', 'ml', 'udemy', 'khóa', 'best', 'seller', 'ae', 'học thể', 'e rv', 'ôn kiến thức toán', 'song song', 'trình', 'học', 'ôn học', 'thanks ae', 'đọc']"
478,"Em xin chào các anh chị ạ ! Hiện tại em đang là sinh viên năm nhất ngành mạng máy tính và truyền thông dữ liệu trường UIT, em rất đam mê lĩnh vực ML nên em có lên cho mình một lộ trình tự học như sau ạ : Toán(giải tích, xstk, đại số tuyến tính) -> Python -> Machine Learning cơ bản -> Python Framework (Tensorflow, Pytorch) -> Machine Learning nâng cao.
Cho em hỏi lộ trình như vậy ổn chưa ạ ? Em cũng muốn xin ý kiến anh chị chi tiết về phần học Machine Learning ạ. Em xin cảm ơn mọi người đã quan tâm đến.
#roadmap #topics","['#sharing', '#machine_learning']","['chào', 'sinh viên', 'ngành', 'mạng', 'máy', 'truyền thông liệu', 'trường uit', 'đam mê', 'lĩnh vực', 'ml', 'lộ trình', 'học toán', 'giải tích', 'xstk', 'đại tuyến', 'python', 'machine', 'learning', 'python', 'framework', 'tensorflow', 'pytorch', 'machine', 'learning', 'nâng', 'lộ trình', 'ổn kiến', 'chi tiết', 'học', 'machine', 'learning']"
479,"#cv_code #py_code #ml_ask
Mọi người cho em hỏi, bây giờ em muốn chỉ làm mượt viền và khử răn cưa, mịn của segment mask mà ko làm giảm chất lượng ảnh ( ko dùng blur hay filter,...) thì nên làm thế nào ạ. Em cảm ơn ạ.","['#Q&A', '#cv']","['mượt', 'viền', 'khử', 'răn cưa', 'mịn', 'segment', 'mask', 'ko', 'chất', 'ảnh', 'ko', 'blur', 'filter']"
480,"Chào mọi người,
Mình đang làm nhận dạng biển số xe, train biển số bằng yolo nhưng kết quả không chính xác lắm đối với biển số bị nghiêng hay mờ, ai có cách gì để cải thiện độ chính xác không ạ, và có cách gì để cải thiện tốc độ train không ạ
#ml #yolo","['#Q&A', '#cv', '#deep_learning']","['chào', 'dạng', 'biển', 'xe', 'train', 'biển', 'yolo', 'kết xác', 'lắm', 'đối biển', 'nghiêng', 'mờ', 'cải thiện', 'độ', 'xác', 'cải thiện', 'tốc độ', 'train']"
481,"dạ em chào anh chị trong group. Em hiện đang là sv năm 2 ngành hệ thống thông tin và đang mơ hồ về tương lai, hướng phát triển sau này. Em đang mông lung giữa nhiều hướng phát triển khác nhau (như DA, DE, BA,...) nhưng không biết hướng nào sẽ sát với ngành em học nhất, về kiến thức thì em đã học C++, oop, dsa, đang học SQL
Mong được anh chị góp ý giờ em nên tìm hiểu phát triển theo hướng nào ạ và cần lộ trình như nào ạ🥲
//trình bày hơi khó hiểu có gì em sẽ giải thích thêm ạ😓
#ds_roadmap","['#Q&A', '#data']","['chào', 'group', 'hiện', 'sv', '2', 'ngành', 'hệ thống', 'thông', 'mơ hồ', 'tương lai', 'hướng', 'phát triển', 'mông', 'lung hướng', 'phát triển', 'da', 'de', 'hướng', 'sát', 'ngành', 'học', 'kiến thức', 'học', 'c', 'oop', 'dsa', 'học', 'sql', 'mong góp', 'phát triển', 'hướng', 'lộ trình', 'trình bày', 'hơi', 'giải']"
482,"Em chào mọi người ạ
Em đang làm bài toán convert model pytorch sang onnx, sau đó convert onnx sang tensorRT. Anh chị và các bạn ai đã từng convert thành công một model đơn giản thôi cho em tham khảo code với ạ. Em đã thử convert model resnet50 nhưng gặp vài lỗi vẫn chưa sửa được ạ. Em cảm ơn mọi người ạ.
Em làm theo hướng dẫn ở trang này https://learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/
lỗi như vậy ạ
AttributeError: 'tensorrt.tensorrt.Builder' object has no attribute 'max_workspace_size'
Em đã thử cài lại các phiên bản khác của tensorrt nhưng vẫn không được ạ
#dl_study","['#Q&A', '#deep_learning', '#python']","['chào toán', 'convert', 'model', 'pytorch', 'onnx', 'convert', 'onnx', 'tensorrt', 'convert', 'thành công', 'model', 'đơn giản', 'tham khảo', 'code', 'thử', 'convert', 'model', 'resnet50', 'lỗi', 'sửa', 'hướng', 'trang', 'https', 'learnopencv', 'com', 'howtoconvertamodelfrompytorchtotensorrtandspeedupinference', 'lỗi', 'attributeerror', 'tensorrt', 'tensorrt', 'builder', 'object', 'has', 'no', 'attribute', 'max_workspace_size', 'thử', 'cài', 'phiên', 'tensorrt']"
483,"Em chào mọi người ạ, em đang là sinh viên năm nhất ngành IT, trong ngành em năm 3 có thể chọn trí tuệ nhân tạo và em cũng đang tính theo chuyên ngành này. Hiện tại em đang vướng mắc ở chỗ học toán cao cấp trên trường làm sao để cải thiện ạ. Và lực học toán bình thường có thể làm về AI không ạ hay cần giỏi hẳn về toán ạ. Em cảm ơn ạ.
#AI_question",['#Q&A'],"['chào', 'sinh viên', 'ngành', 'it', 'ngành', '3', 'thể trí tuệ nhân', 'chuyên ngành', 'vướng mắc', 'chỗ', 'học toán', 'trường', 'cải thiện lực', 'học toán', 'bình thể', 'giỏi', 'hẳn toán']"
484,"Mình đang làm project về hand gesture.
Đã chạy xog 1 số mạng cơ bản custom lại theo data của mình như SVM, RF, cnn, yolo5,6,7,8, mobilenet, .... để so sánh hiệu suất giữa các mạng basic và mạng mới
Bh muốn chạy GrapCnn thì lại chục chặc. Phần đa là kb custom lại data như nào cho phù hợp vs mạng. Bác nào đã từng sử dụng qua grapcnn rồi thì cho mình 1 số kinh nghiệm với. Build như nào, data custom lại theo dạng gì, share data ra làm sao.
Mình chạy khung xương bàn tay 21 điểm vs grapcnn nhé
#dl_study","['#Q&A', '#cv', '#deep_learning', '#data']","['project', 'hand', 'gesture', 'chạy', 'xog', '1', 'mạng', 'custom', 'data', 'svm', 'rf', 'cnn', 'yolo5', '6', '7', '8', 'mobilenet', 'sánh', 'hiệu suất', 'mạng', 'basic mạng', 'bh', 'chạy', 'grapcnn chục', 'chặc', 'đa kb', 'custom', 'data', 'vs', 'mạng', 'grapcnn', '1', 'kinh nghiệm', 'build', 'data', 'custom', 'dạng', 'share', 'data', 'chạy', 'khung', 'xương', 'bàn', '21', 'vs', 'grapcnn']"
485,"Max pooling layer trong Neural Network 🔥🔥🔥
Hi các bạn,
Trong Deep Learning, bên cạnh những layer đã quá phổ biến như Fully-connected layer hay Convolutional layer thì Max pooling layer cũng là 1 layer vô cùng thú vị. Layer này sẽ giúp giảm kích thưóc của feature map nhanh chóng, từ đó giúp làm giảm số lượng parameter cho các Neural Network cũng như CNN. Mình có 2 câu hỏi dành cho các bạn về layer thú vị này:
Vì sao chúng ta chỉ có max pooling mà không có min pooling. Ngày xưa thì cũng đã từng có average pooling nhưng giờ thì cũng không ai dùng cả. Vì sao lại thế ?
Thuờng lúc các bạn học, max pooling sẽ có side và stride đều bằng 2. Điều này cũng làm cho tính toán kích thuớc của output dễ hàng hơn khi chiều cao và chiều ngang của feature map đều giảm đi còn 1 nửa. Tuy nhiên trong khoảng chục năm trở lại đây, có 1 trend đó là stride vẫn bằng 2 nhưng size lại bằng 3. Theo các bạn vì sao người ta lại làm vậy. Không phải là side = stride = 2 thì sẽ thuận mắt và dễ tính toán hơn sao ?
#dl_question","['#sharing', '#deep_learning']","['max', 'pooling', 'layer', 'neural', 'network', 'hi deep', 'learning', 'cạnh', 'layer', 'phổ biến', 'fullyconnected', 'layer', 'convolutional', 'layer', 'max', 'pooling', 'layer', '1', 'layer', 'vô', 'thú vị', 'layer', 'giúp', 'kích thưóc', 'feature', 'map chóng', 'giúp', 'parameter', 'neural', 'network', 'cnn', '2', 'layer', 'thú vị', 'ta', 'max', 'pooling', 'min', 'pooling', 'xưa', 'average', 'pooling', 'thường', 'học', 'max', 'pooling', 'side', 'stride', '2', 'toán kích thước', 'output', 'hàng', 'chiều chiều', 'ngang', 'feature', 'map', 'đi', '1', 'nửa nhiên', 'chục', 'trở', '1', 'trend', 'stride', '2', 'size', '3', 'ta', 'side', 'stride', '2', 'thuận', 'mắt toán']"
486,"Em xin chào mọi người ạ, hiện là em đang chuẩn bị làm đồ án môn học chủ đề là text to ads generator. Mọi người có thể cho em xin vài nguồn để tham khảo được không ạ
Em xin cảm ơn ạ
#dl_content","['#Q&A', '#cv']","['chào', 'hiện', 'chuẩn', 'đồ án', 'môn học', 'chủ đề', 'text', 'to', 'ads', 'generator thể', 'tham khảo']"
487,"Em chào anh Việt và các cao nhân ạ.
Chuyện là em đang ôn để sắp tới thi Olympic Tin học sinh viên và đang get stuck bài này (2 hình ở dưới ạ). Đây là đoạn code Python của em ạ (hình thứ 3) và giải đúng được 4/5 subtask ạ. Mọi người có thể cho em hỏi cách để tối ưu đoạn code của em để có thể chạy full subtask ạ.
Link nộp bài đây ạ:
https://oj.vnoi.info/problem/olp_kc19_tri
#py_code","['#Q&A', '#python']","['chào', 'việt nhân', 'ôn thi', 'olympic', 'học sinh viên', 'get', 'stuck', '2', 'hình', 'đoạn', 'code', 'python hình', '3', 'giải', '4', '5', 'subtask thể', 'tối ưu đoạn', 'code thể', 'chạy', 'full', 'subtask', 'link', 'nộp']"
488,"CÁC BÀI VIẾT KHÔNG GẮN HASHTAG SẼ KHÔNG ĐƯỢC DUYỆT

Xin chào các bạn,

lời đầu tiên bọn mình rất biết ơn mọi sự đóng góp nhiệt tình của các bạn để group có thể tạo nên một cộng đồng văn minh, cùng nhau chia sẻ nhiều kiến thức bổ ích như ngày hôm nay.
Tuy nhiên vài ngày gần đây, năng suất duyệt bài của đội ngũ admin đã tạm thời giảm đi do mất ăn mất ngủ... trước những bài viết không gắn hashtag. Bọn mình cũng đã đấu tranh tâm lý để duyệt trước những bài viết thú vị và tốn nhiều tâm huyết (nhưng không hashtag) của các bạn.
Để tránh việc admin vào bình luận nhắc gắn hashtag làm loãng post của các bạn, hãy cùng nhau hashtag từ bây giờ nhé! Việc gắn hashtag có rất nhiều lợi ích: dễ phân loại, tìm kiếm, tăng khả năng nhận được giải đáp của những người có kiến thức về chủ đề và bài sẽ được duyệt trong một nốt nhạc. Những bài không hashtag từ ngày 17.11.2023 sẽ không được duyệt kèm lý do yêu cầu gắn hashtag.
Một hashtag lí tưởng sẽ bao gồm hai thông tin #xx_content:

1. xx ở đây có thể là 1 trong các giá trị sau:
py: Python
ds: Data Science
ml: Machine Learning
ds_ml: Hoặc liên quan đến cả 2
dl: Deep Learning
cv: Computer Vision (Thị giác máy tính)
nlp: Natural Language Processing (Xử lý ngôn ngữ tự nhiên)
dl_cv: Deep Learning for Computer Vision
dl_nlp: Deep Learning for NLP
rl: Reinforcement Learning

2. Content:
xx_roadmap: Dành cho các post hỏi về lộ trình
xx_share: Dành cho các post share tài liệu, kinh nghiệm
xx_job: Dành cho các post liên quan đến việc làm
xx_laptop: Dành cho các post hỏi máy tính, cấu hình
xx_challenge: Dành cho các post hỏi về các cuộc thi
xx_study: Dành cho các post hỏi về việc học hành
xx_code: Dành cho các post hỏi về code (code ko chạy, lỗi, ...)
relax: Dành cho các post mang tính chất vui vẻ, giải trí
other: Không thuộc thể loại nào ở trên

Thói quen khó hình thành, nhưng một khi đã quen thì khó bỏ ;) Cảm ơn các bạn vì đã lắng nghe và vì môt cộng đồng ngày càng lớn mạnh, hãy cùng hashtag từ bây giờ nhé!

Link tới bài viết gốc của anh Việt: https://www.facebook.com/groups/dsmlvietnam/permalink/320074674105994",['#sharing'],"['viết', 'gắn', 'hashtag', 'duyệt', 'chào', 'bọn', 'ơn', 'đóng góp', 'nhiệt tình', 'group thể', 'cộng đồng', 'văn minh', 'kiến thức', 'bổ ích', 'hôm nhiên', 'năng suất', 'duyệt', 'đội ngũ', 'admin', 'tạm thời', 'đi', 'ngủ', 'viết', 'gắn', 'hashtag', 'bọn', 'đấu tranh', 'tâm lý', 'duyệt', 'viết', 'thú vị', 'tốn', 'tâm huyết', 'hashtag admin', 'bình luận', 'nhắc', 'gắn', 'hashtag', 'loãng', 'post', 'hashtag', 'gắn', 'hashtag', 'lợi ích', 'phân kiếm', 'khả năng', 'giải đáp', 'kiến thức', 'chủ đề', 'duyệt', 'nốt', 'nhạc', 'hashtag', '17', '11', '2023', 'duyệt', 'kèm lý', 'gắn', 'hashtag', 'hashtag lí tưởng', 'bao', 'hai', 'thông', '1', 'xx thể', '1', 'py', 'python', 'ds', 'data', 'science', 'ml', 'machine', 'learning', 'ds_ml', '2', 'dl', 'deep', 'learning', 'cv', 'computer', 'vision', 'thị giác', 'máy', 'nlp', 'natural', 'language processing', 'ngôn ngữ nhiên', 'dl_cv', 'deep', 'learning', 'for', 'computer', 'vision', 'dl_nlp', 'deep', 'learning', 'for', 'nlp', 'rl', 'reinforcement', 'learning', '2', 'content', 'xx_roadmap', 'post', 'lộ trình', 'xx_share', 'post', 'share', 'tài liệu', 'kinh nghiệm', 'xx_job', 'post', 'xx_laptop', 'post', 'máy', 'cấu hình', 'xx_challenge', 'post', 'thi', 'xx_study', 'post', 'học hành', 'xx_code', 'post', 'code', 'code', 'ko', 'chạy', 'lỗi', 'relax', 'post chất', 'vui vẻ', 'giải trí', 'other thể', 'thói quen', 'hình thành', 'quen', 'lắng', 'môt', 'cộng đồng', 'hashtag', 'link', 'viết', 'gốc', 'việt']"
489,"Chào anh Việt và mọi người. Em đang chuyển từ code bằng vscode sang code trên colab, nhưng có 1 vấn đề là file csv khi chuyển lên ggDrive nó sẽ thành file gsheet. Vậy mọi người cho em hỏi là mình sẽ mở file gsheet như thế nào ạ, có phải xử lí với gspread và tạo khoá json không ạ. Em cảm ơn.
và cho em hỏi sao đoạn code này của em lại báo lỗi không có thuộc tính service_account trong gspread vậy ạ
#xx_study",['#Q&A'],"['chào', 'việt', 'code', 'vscode', 'code', 'colab', '1', 'file', 'csv', 'ggdrive', 'thành', 'file', 'gsheet', 'file gsheet', 'xử lí', 'gspread', 'khóa', 'json', 'đoạn', 'code', 'báo', 'lỗi', 'service_account', 'gspread']"
490,"Em chào anh Việt, chào mọi người. Hiện em là sv năm 4 đang theo học Tự Động Hóa, em muốn tìm hiểu về AI thì cần phải học những gì ạ? Em đang định hướng sẽ học Toán( XSTK, ĐSTT), Phython và Machine Learning. Rất mong được mọi người giúp đỡ. Em cảm ơn ạ, chúc mọi người 1 ngày tốt lành <3
#ml_roadmap","['#Q&A', '#machine_learning']","['chào', 'việt', 'chào', 'hiện', 'sv', '4', 'học động', 'hóa', 'học', 'định hướng', 'học toán', 'xstk', 'đstt', 'phython', 'machine', 'learning', 'mong', 'giúp đỡ', 'chúc', '1', 'lành', '3']"
491,"#dl
em làm mô hình để giải bài hồi quy (bài toán dữ đoán giá cổ phiếu) thì layer cuối cùng e để 1 unit và hàm kích hoạt trên layer cuối cùng này sẽ là hàm kích hoạt tuyến tính , và các lớp ẩn em sẽ sử dụng hàm kích hoạt phi tuyến như sigmol hoặc relu . Và sau khi huyấn luyện xong em cho mô hình chạy trên tập test và em dùng bình phương lỗi để đánh giá mô hình đó có xài được hay không . Thì muốn hỏi là thì trong bài toán hồi quy thì hàm kích hoạt trong các lớp ẩn có thể là các hàm kích hoạt tuyến tính không và nếu có thì nó có hiểu quả hơn so với hàm kích hoạt phi tuyến không và em muốn hỏi nữa là sau khi chạy thử model ra được bình phương lỗi em biết là bình phương lỗi càng bé tức là mô hình càng chính xác nhưng mà em thắc mắc là có một chuẩn chung nào để đánh giá không tức là giả sử như giá trị hàm lỗi phải bé hơn một ngưỡng nào đó thì model đó mới sử dụng được á kiểu vậy ? Thanks mn đã nghe em hỏi","['#Q&A', '#deep_learning', '#machine_learning']","['mô hình', 'giải hồi', 'quy toán', 'đoán', 'giá', 'cổ phiếu', 'layer', 'e', '1', 'unit', 'hàm kích', 'hoạt layer', 'hàm kích', 'hoạt tuyến', 'lớp', 'ẩn hàm kích', 'hoạt phi', 'tuyến', 'sigmol', 'relu', 'huyấn luyện', 'xong', 'mô hình', 'chạy', 'tập test', 'bình phương', 'lỗi', 'mô hình', 'xài toán', 'hồi', 'quy hàm kích', 'hoạt lớp', 'ẩn thể', 'hàm kích', 'hoạt tuyến', 'hàm kích', 'hoạt phi', 'tuyến', 'chạy', 'thử', 'model', 'bình phương', 'lỗi', 'bình phương', 'lỗi', 'bé', 'tức', 'mô hình', 'xác', 'thắc mắc', 'chuẩn tức', 'giả', 'sử hàm', 'lỗi', 'bé', 'ngưỡng model', 'kiểu', 'thanks', 'mn']"
492,"Two Questions Technique - chìa khóa giúp chúng ta không bao giờ nhầm lẫn giữa TP, TN, FP và FN 🔥🔥🔥
Với các bạn học về Machine Learning, có lẽ các bạn không còn xa lạ gì với Confusion matrix khi cần đánh giá các mô hình binary classification nữa. Chúng ta đều biết rằng bất kì 1 prediction nào của model sẽ đều rơi vào 1 trong 4 loại sau:
True Positive (TP)
True Negative (TN)
False Positive (FP)
False Negative (FN)
4 thuật ngữ này, có những người phân biệt rất dễ, nhưng cũng có những người rất hay bị nhầm lẫn. Đặc biệt là nếu các bạn mới học, và sau 1 thời gian các bạn không động vào, thì rất dễ bì nhầm giữa chúng 🥹
1 mẹo để giúp các bạn có thể phân biệt được dự đoán của mô hình rơi vào loại nào trong 4 loại trên, đó là thông qua việc trả lời 2 câu hỏi sau:
Câu hỏi 1: Dự đoán đúng hay sai? Nếu đúng thì là True. Nếu sai thì là False
Câu hỏi 2: Dự đoán là về class positive hay class negative ?
Kết hợp 2 câu trả lời trên lại, các bạn sẽ có đáp án 😎
#ml_tips","['#sharing', '#machine_learning']","['two', 'questions', 'technique', 'chìa', 'khóa', 'giúp', 'ta', 'nhầm lẫn', 'tp', 'tn', 'fp', 'fn', 'học', 'machine', 'learning lẽ', 'lạ confusion', 'matrix', 'mô hình', 'binary', 'classification', 'ta', '1', 'prediction', 'model', 'rơi', '1', '4', 'true', 'positive', 'tp', 'true', 'negative', 'tn', 'false', 'positive', 'fp', 'false', 'negative', 'fn', '4', 'thuật ngữ', 'phân biệt', 'nhầm lẫn', 'học', '1', 'động', 'bì nhầm', '1', 'mẹo', 'giúp thể', 'phân biệt', 'dự đoán', 'mô hình', 'rơi', '4', 'thông', '2', '1', 'dự đoán', 'sai', 'true', 'sai', 'false', '2', 'dự đoán', 'class', 'positive', 'class', 'negative', 'kết hợp', '2', 'câu', 'đáp án']"
493,"Em chào mọi người ạ,
Em đang muốn kiếm các bài toán thực tế về việc ứng dụng Computer Vision trong Retail để nghiên cứu. Anh/chị nào có bài toán nào hay và có thể ứng dụng được trong thực tế không ạ? Em xin cảm ơn.
#cv_study","['#Q&A', '#cv']","['chào', 'kiếm toán', 'ứng dụng', 'computer', 'vision', 'retail', 'nghiên cứu', 'toán thể', 'ứng dụng']"
494,"#dl_cv_study
Em là newbie, moi ng cho em hỏi là:
Kiến trúc AlexNet có một cái bước là local reponse normalization. Vậy thì bước chuẩn hoá đó để làm gì, công dụng của nó, cách thức thực hiện chuẩn hoá của nó","['#Q&A', '#deep_learning']","['newbie', 'moi ng', 'kiến trúc', 'alexnet', 'local', 'reponse', 'normalization', 'chuẩn', 'hóa', 'công dụng', 'thức', 'chuẩn', 'hóa']"
495,"mình có 2 file giống nhau một cách quá đáng luôn, và chụp màng hình code của mình.
bài này mentor hướng dẫn mình rồi, nhưng thật sự không thoã mãn và đã chôn câu hỏi này gần 2 tháng và giờ mình mong mọi người giúp mình với.
df = pd.read_csv(filepath1, sep = ""[,]"" , header = None, index_col = None,engine = 'python')
sep = "","" có lỗi gì mà chỉ có một số file thì load tạo bảng cấu trúc tương tự file gốc còn một số file phải dùng sep = """" và khi load gom tất cả các cột trong file ra thành 1 cột.
Mình chân thành cảm ơn. mình biết là trong nhóm này có bạn đăng ký cùng khoá học với mình, thật sự mọi người dạy mình đều đã hỗ trợ rất nhiệt tình nhưng mình chưa thấy thoã mãn nên mang lên đây hỏi thôi à.
#xx_study","['#Q&A', '#python']","['2', 'file', 'chụp', 'màng hình', 'code', 'mentor', 'hướng', 'thõa', 'mãn', 'chôn', '2', 'mong', 'giúp', 'df', 'pd', 'read_csv', 'filepath1', 'sep', 'header', 'none', 'index_col', 'none', 'engine', 'python', 'sep', 'lỗi', 'file', 'load', 'bảng', 'cấu trúc', 'tương file', 'gốc', 'file', 'sep', 'load', 'gom', 'tất cột', 'file', 'thành', '1', 'cột', 'chân thành', 'đăng ký', 'khóa', 'học', 'dạy', 'nhiệt tình', 'thõa', 'mãn']"
496,"Chào mọi người,
Hiện tại em đang gặp vấn đề trong việc xử lý file excel cụ thể ở step đọc file excel. Em có 1 file Excel hoàn toàn bằng tiếng việt (file .xlsx và encoding ANSI) em có mở để check thì file hoàn toàn bình thường nhưng khi dùng pandas để đọc và convert sang file json thì bị lỗi font (file json bên dưới). Em đã thử chuyển file excel về encode utf-8 nhưng vẫn bị lỗi y chang.
Không biết mọi người có biết cách xử lý vấn đề này hoặc 1 library nào khác đọc excel file và convert về json có hỗ trợ tiếng việt không ạ?
Em cảm ơn.
#py_study #py_code","['#Q&A', '#python']","['chào', 'file', 'excel', 'step', 'đọc', 'file', 'excel', '1', 'file', 'excel', 'tiếng', 'việt', 'file', 'xlsx', 'encoding', 'ansi', 'check', 'file', 'bình pandas', 'đọc', 'convert', 'file', 'json', 'lỗi', 'font', 'file', 'json', 'thử', 'file', 'excel', 'encode', 'utf8', 'lỗi', 'y chang', '1', 'library', 'đọc', 'excel', 'file', 'convert', 'json', 'tiếng', 'việt']"
497,"Xin chào ad và mọi người, hiện mình đang muốn dịch các từ viết tay hoặc đánh máy trong ảnh sang tiếng việt thì mọi người có gợi ý nào không ạ
#other","['#Q&A', '#nlp']","['chào ad', 'hiện', 'dịch', 'viết', 'đánh máy ảnh', 'tiếng', 'việt', 'gợi']"
498,"Em chào mọi người. Em hiện đang bắt đầu làm project về ML/DL để vừa học vừa cải thiện bản thân. Mọi người cho em hỏi là bình thường khi bắt đầu làm, thì làm sao để mình có thể biết cần viết những file nào, cấu trúc file của project đó ra sao và khi nào thì viết theo hướng oop, và khi viết theo oop thì có cần viết theo design pattern không ạ, nếu có thì khi theo hướng DS/ML/DL thì chọn mẫu nào ạ?
#ml_study","['#Q&A', '#python']","['chào', 'hiện', 'project', 'ml', 'dl học', 'cải thiện', 'thân', 'bình thể', 'viết', 'file', 'cấu trúc', 'file', 'project', 'viết', 'hướng', 'oop', 'viết', 'oop', 'viết', 'design', 'pattern', 'hướng', 'ds', 'ml', 'dl', 'mẫu']"
499,"Chào mọi người, 
Em đang xây dựng mô hình LSTM để dự đoán chuỗi thời gian. Em đang quan trọng precision của lớp 1 hơn là các thông số khác như accuaracy, recall,...
Mọi người cho e hỏi có cách nào để code chạy mô hình theo dõi và làm tăng trực tiếp precision của lớp 1 không ạ. 
Em cảm ơn.
#pythonStudy","['#Q&A', '#deep_learning']","['chào', 'xây dựng', 'mô hình', 'lstm', 'dự đoán', 'chuỗi', 'precision', 'lớp', '1', 'thông', 'accuaracy', 'recall', 'e code', 'chạy', 'mô hình', 'dõi', 'precision', 'lớp', '1']"
500,"Learning Deep Learning - Tài liệu bao gồm lý thuyết và thực hành về NLP, CV và Transformer của NVIDIA 🔥🔥🔥
Hi các bạn,
Kể cả với những ai không học về AI/Deep Learning, mà chỉ cần có chút xíu kiến thức về máy tính thôi, thì có lẽ các bạn cũng biết NVIDIA là ông trùm về mảng card đồ họa. Với riêng mảng Deep Learning, nếu không có những card đồ họa mạnh mẽ của NVIDIA, thì chúng ta chắc chắn sẽ không bao giờ có những ChatGPT hay Midjourney. NVIDIA vào năm ngoái cũng đã cho ra mắt 1 tài liệu dài hơn 100 trang để tổng hợp các kiến thức thiết yếu về Deep Learning. Tài liệu này không đi quá sâu vào các công thức mà giúp chúng ta có cái nhìn khái quát về ứng dụng của Deep Learning trong các lĩnh vực khác nhau 😎
Đánh giá của cá nhân mình: 1 tài liệu không tốn quá nhiều thời gian để đọc nhưng vô cùng hữu ích để hệ thống hóa kiến thức 🥰
Link to pdf: https://drive.google.com/file/d/1QfgFDsir-lNj1EkQyFmcA-PZ7mFeSnCs/view?usp=sharing
#dl_share","['#sharing', '#deep_learning']","['learning', 'deep', 'learning', 'tài liệu', 'bao lý thuyết', 'thực hành', 'nlp', 'cv', 'transformer', 'nvidia', 'hi học', 'deep', 'learning', 'chút xíu', 'kiến thức', 'máy lẽ', 'nvidia', 'trùm', 'mảng', 'card', 'đồ', 'họa', 'mảng', 'deep', 'learning', 'card đồ', 'họa mẽ', 'nvidia', 'ta', 'chắn', 'chatgpt', 'midjourney', 'nvidia', 'ngoái', 'mắt', '1', 'tài liệu', '100', 'trang', 'tổng hợp', 'kiến thức', 'thiết yếu', 'deep', 'learning', 'tài liệu', 'đi sâu', 'công thức', 'giúp', 'ta', 'khái quát', 'ứng dụng', 'deep', 'learning', 'lĩnh vực', '1', 'tài liệu', 'tốn', 'đọc', 'vô hữu ích', 'hệ thống', 'hóa', 'kiến thức', 'link', 'to', 'pdf']"
501,"[Review 2023] Tổng hợp các mô hình object detection thời gian thực 🔥🔥🔥
Post này dành riêng cho người chơi hệ Deep Learning for Computer Vision giống mình ☺️
Đây là bài báo tổng hợp các mô hình object detection trong thời gian thực, được thực hiện vào tháng 2/2023. 
8 mô hình với 9 backbone khác nhau sẽ được đưa lên bàn cân để so sánh và đánh giá theo 8 tiêu chí trên 6 bộ dataset. Cụ thể hơn:
8 mô hình được so sánh bao gồm:
ThunderNet (Mô hình 2-stage duy nhất trong danh sách này)
YOLO 
SSD
DETR
CenterNet
TTFNet
FCOS
NanoDet (Lần đầu mình nghe đến tên mô hình này 😆)
Real-time nên những mô hình 2-stage như Faster RCNN tất nhiên là bị loại từ vòng gửi xe các bạn nhé. Mình cũng hơi ngạc nhiên là có 1 mô hình 2-stage lọt vào danh sách này 🤣
Mỗi 1 mô hình trên sẽ được test lần lượt với 9 backbone sau:
ResNet 
DarkNet
Xception
MobileNet
ShuffleNet-v2
VoVNet (Chưa nghe bao giờ v2.0)
EfficientNet
HarDNet 
DeiT (Chưa nghe bao giờ v3.0)
Trong 8 tiêu chí thì đối với cá nhân mình, mAP (trong bài báo này người ta ghi là accuracy), param và speed là quan trọng nhất
6 dataset được sử dụng thì tất nhiên không thể thiếu những Pascal VOC, COCO hay Cityscapes (Cityscapes thì thật ra nổi tiếng với bài toán instance segmentation chứ đây cũng là lần đầu mình thấy được áp dụng vào object detection 😅)
Note: Có 1 điểm mình không ưng từ bài báo này, đó là sử dụng từ accuracy thay vì mAP. Sử dụng tên 1 metric của bài toán classification dành cho metric của bài toán object detection là 1 điều khá hài hước 🥹
Link to paper: https://arxiv.org/pdf/2208.10895.pdf
#dl_paper","['#sharing', '#deep_learning', '#cv']","['review', '2023', 'tổng hợp', 'mô hình', 'object', 'detection', 'thực post', 'hệ', 'deep', 'learning', 'for', 'computer', 'vision', 'báo', 'tổng hợp', 'mô hình', 'object', 'detection thực', '2', '2023', '8', 'mô hình', '9', 'backbone', 'bàn', 'cân', 'sánh', '8', 'tiêu chí', '6', 'dataset', '8', 'mô hình', 'sánh', 'bao', 'thundernet', 'mô hình', '2', 'stage', 'danh sách', 'yolo', 'ssd', 'detr', 'centernet', 'ttfnet', 'fcos', 'nanodet', 'đầu', 'mô hình', 'realtime', 'mô hình', '2', 'stage', 'faster', 'rcnn', 'tất nhiên', 'vòng', 'gửi', 'xe hơi', 'ngạc nhiên', '1', 'mô hình', '2', 'stage', 'lọt', 'danh sách', '1', 'mô hình', 'test', 'lượt', '9', 'backbone', 'resnet', 'darknet', 'xception', 'mobilenet', 'shufflenetv2', 'vovnet', 'v2', '0', 'efficientnet', 'hardnet', 'deit', 'v3', '0', '8', 'tiêu chí', 'đối map', 'báo', 'ta', 'ghi', 'accuracy', 'param', 'speed', '6', 'dataset', 'tất nhiên thể', 'pascal', 'voc', 'coco', 'cityscapes', 'cityscapes', 'nổi tiếng', 'toán', 'instance', 'segmentation', 'đầu', 'áp dụng', 'object', 'detection', 'note', '1', 'ưng', 'báo', 'accuracy', 'thay', 'map', '1', 'metric toán', 'classification', 'metric toán', 'object', 'detection', '1', 'hài hước', 'link', 'to', 'paper']"
502,"Chào mọi người, em là sinh viên năm 3 đang học ngành Tài chính - Ngân Hàng định hướng fintech tại TPHCM, em đang muốn tìm đề tài tham khảo để thực hiện khóa luận tốt nghiệp vào năm 4. Mọi người đề xuất cho em 1 số nguồn tham khảo hay những đề tài liên quan đến TCNH và Machine Learning với ạ.
Em cảm ơn.
#AI_question","['#Q&A', '#machine_learning']","['chào', 'sinh viên', '3', 'học', 'ngành', 'tài', 'ngân hàng', 'định hướng', 'fintech', 'tphcm', 'đề tài', 'tham khảo', 'khóa luận nghiệp', '4', 'đề xuất', '1', 'tham khảo', 'đề tài', 'tcnh', 'machine', 'learning']"
503,"Dạ chào mng em đang làm bài về ML, em đang làm bài về dạng hồi quy đã làm xong bước để train sử dụng Model DecisionTree với RandomForest 
Em đang thắc mắc bước để đánh giá mô hình này, không biết dùng R2, MAE, MSE mình đánh giá 1 lần như vậy không biết có ổn không ạ, với sau khi em kẻ bảng như hình cuối thì em quyết định chọn RandomForest đúng chưa ạ tại em tìm hiểu MAE với MSE càng nhỏ thì độ chính xác mới cao phải không ạ.
Em cám ơn admin và mng
#dsml_question","['#Q&A', '#machine_learning']","['chào', 'mng', 'ml dạng', 'hồi quy', 'xong', 'train', 'model', 'decisiontree', 'randomforest', 'thắc mắc', 'mô hình', 'r2', 'mae', 'mse', '1', 'ổn', 'kẻ', 'bảng hình', 'quyết định', 'randomforest', 'mae', 'mse độ', 'xác', 'cám ơn', 'admin', 'mng']"
504,"em chào mọi người, do em là một newbie và em vừa học xong khóa ML của Andrew Ng. Em muốn học cả NLP và Computer Vision ạ thì mọi người có thể gợi ý giúp em một số khóa học chất lượng không ạ. Em xin cám ơn.
#ds_roadmap",['#Q&A'],"['chào', 'newbie', 'học', 'xong', 'khóa', 'ml', 'andrew', 'ng', 'học', 'nlp', 'computer', 'vision thể', 'gợi', 'giúp', 'khóa', 'học', 'chất', 'cám ơn']"
505,"[Deep Learning question] Vì sao Sigmoid và Tanh không còn được sử dụng nhiều nữa 🤔🤔🤔 ?
Hi các bạn,
Với những bạn nào đã và đang học về Deep Learning, chắc các bạn cũng không còn xa lạ gì với các activation function, hay tiếng Việt mình gọi là hàm kích hoạt. 
Những hàm này tuy đơn giản, và thậm chí hầu hết còn không có parameter (nghĩa là sẽ không được update trong quá trình huấn luyện mô hình, vì đơn giản là chẳng có gì để mà update), tuy nhiên chúng đóng vai trò vô cùng quan trọng cho sự thành công của Deep Learning như chúng ta thấy ngày nay.
Vào thời điểm khoảng 15 năm trở về trước, có 2 hàm kích hoạt được sử dụng vô cùng rộng rãi và có mặt trong hầu hết các model nổi tiếng, đó là Sigmoid và Tanh. Cặp đôi này đi đâu cũng thấy xuất hiện bởi những ưu điểm sau:
2 hàm này khả vi (có thể đạo hàm được) tại mọi điểm. Điều này là vô cùng quan trọng do quá trình chúng ta update mô hình là dựa vào gradient. Không khả vi => (về mặt lý thuyết) khỏi nghĩ đến gradient 😆
Riêng hàm Tanh còn có thêm 1 ưu điểm là hàm lẻ (đối xứng qua gốc tọa độ)
Tuy nhiên về sau này, 2 hàm trên dần bị thất sủng, và bị thay thế dần bởi các hàm kích hoạt khác như ReLU và các biến thể của nó (mặc dù hầu hết các hàm này đều không khả vi tại điểm 0). Ngày nay các bạn hầu như sẽ không thể nào tìm thấy 1 mô hình Neural Network nào sử dụng Sigmoid hay Tanh nữa. Sigmoid vẫn còn may mắn là được sử dụng trong Logistic Regression, còn Tanh thì coi như đã có 1 chỗ rất đẹp trong viện bảo tàng AI 🥹
Vậy câu hỏi của mình ở đây là, vì sao ngày nay người ta không còn sử dụng Sigmoid và Tanh trong Deep Learning nữa 🤓?
#dl_question","['#sharing', '#math']","['deep', 'learning', 'question', 'sigmoid', 'hi học', 'deep', 'learning', 'lạ', 'activation', 'function', 'tiếng', 'việt', 'gọi', 'hàm kích', 'hoạt hàm', 'đơn giản chí', 'parameter nghĩa', 'update trình', 'huấn luyện', 'mô hình', 'đơn giản', 'chẳng', 'update nhiên', 'đóng', 'vai trò', 'vô', 'thành công', 'deep', 'learning', 'ta', '15', 'trở', '2', 'hàm kích', 'hoạt vô', 'rộng rãi', 'mặt', 'model', 'nổi tiếng', 'sigmoid', 'cặp', 'đôi', 'đi', 'ưu', '2', 'hàm', 'khả vi thể', 'đạo hàm', 'vô trình', 'ta', 'update', 'mô hình', 'dựa', 'gradient', 'khả vi', 'mặt', 'lý thuyết', 'gradient hàm', '1', 'ưu hàm lẻ', 'đối xứng', 'gốc', 'tọa', 'độ nhiên', '2', 'hàm', 'dần', 'thất sủng', 'thay', 'dần', 'hàm kích', 'hoạt relu', 'biến thể', 'mặc hàm', 'khả vi', '0', 'hầu thể', '1', 'mô hình', 'neural', 'network', 'sigmoid', 'sigmoid', 'may mắn', 'logistic', 'regression', 'coi', '1', 'chỗ', 'đẹp', 'viện bảo tàng', 'ta', 'sigmoid', 'deep', 'learning']"
506,"Học thống kê qua truyện tranh 🔥🔥🔥
Đây là 1 trong số các đầu sách thú vị nhất mình từng gặp. Quyển sách này giải thích cho chúng ta tất cả các khái niệm trong thống kê qua phong cách truyện tranh cực kì vui nhộn 😁
Quyển sách này gần như là 1 mình 1 phong cách trong tất cả các đầu sách mình từng đọc trong quá trình học và làm về AI/DS/ML 😎 Đây cũng là 1 cơ hội tốt để các bạn luyện khả năng đọc tài liệu bằng tiếng Anh, vì so với mặt bằng chung, từ vựng trong quyển sách này khá là ít và dễ ☺️
Link to pdf: https://drive.google.com/file/d/1-t7AhyaXr1MFUwc0iZ3nKDP26VUtvUBe/view?usp=sharing
#dsml_share","['#sharing', '#math']","['học', 'thống kê', 'truyện', 'tranh', '1', 'đầu sách', 'thú vị', 'quyển', 'sách', 'giải', 'ta', 'tất', 'khái niệm', 'thống kê', 'phong truyện', 'tranh', 'cực kì', 'vui nhộn', 'quyển', 'sách', '1', '1', 'phong tất', 'đầu sách', 'đọc', 'trình', 'học', 'ds', 'ml', '1', 'hội luyện', 'khả năng', 'đọc', 'tài liệu', 'tiếng', 'mặt', 'vựng', 'quyển', 'sách', 'link', 'to', 'pdf']"
507,"2 câu hỏi về Machine Learning 🔥🔥🔥
Hôm nay mình sẽ hỏi các bạn 2 câu thay vì 1 câu như mọi ngày nhé 😊
Câu 1: Mình muốn xây dựng 1 mô hình phân loại nhằm phân loại con ngựa với con lừa. Mình có rất nhiều ngựa và lừa, nhưng mình sẽ không dùng hết để huấn luyện mô hình. Mình chỉ chọn ra 1 vài con ngựa trông giống lừa nhất, và 1 vài con lừa trông giống ngựa nhất, rồi sau đó huấn luyện mô hình với chỗ lừa + ngựa này. Mình đang nói về 1 thuật toán đặc biệt bậc nhất, phổ biến và vô cùng thú vị trong Machine Learning. Các bạn có biết mình đang nói về thuật toán nào không ?
Câu 2: Mình crush 1 bạn, và mình mời bạn ấy đi ăn tối. Bây giờ mình cần lên 1 danh sách những quán ăn ngon, để đến cuối cùng mình sẽ chọn ra 1 quán để mời bạn ấy đi ăn. Nếu mình coi quán ăn ngon là class positive, thì danh sách của mình sẽ cần tập trung vào precision hay recall hả các bạn ?
#ml_questions","['#Q&A', '#cv']","['2', 'machine', 'learning', 'hôm', '2', 'câu', 'thay', '1', 'câu', 'câu', '1', 'xây dựng', '1', 'mô hình', 'phân phân', 'ngựa', 'lừa', 'ngựa', 'lừa', 'huấn luyện', 'mô hình', '1', 'ngựa', 'trông', 'lừa', '1', 'lừa', 'trông', 'ngựa', 'huấn luyện', 'mô hình', 'chỗ', 'lừa', 'ngựa', '1', 'thuật toán', 'bậc', 'phổ biến', 'vô', 'thú vị', 'machine', 'learning thuật', 'toán', 'câu', '2', 'crush', '1', 'mời', 'đi', 'tối', '1', 'danh sách', 'quán', 'ngon', '1', 'quán', 'mời', 'đi', 'coi', 'quán', 'ngon', 'class', 'positive', 'danh sách', 'precision', 'recall', 'hả']"
508,"Dạ xin chào mn, em là sinh viên năm cuối của một trường cao đẳng, nên là em đang có ý định tìm trường để LIÊN THÔNG ĐẠI HỌC ạ.
Ngành học của em ở cao đẳng là CNTT, và nguyện vọng ngành học khi liên thông của em là Khoa học máy tính, nên em xin mọi người giúp đỡ góp ý giúp em vài trường đào tạo liên thông tốt để sắp tới em có thể chuẩn bị thật tốt cho việc LIÊN THÔNG ĐẠI HỌC ạ.
Em cũng đã nghía được 2 trường trong kv Tp.HCM là UIT và ĐH Mở rồi ạ, anh chị nào đang và đã từng học tại trường có thể cho em xin ít review về trường được không ạ.(Văn vở em không được tốt nên có câu từ nào khiến anh chị khó chịu thì thông cảm bỏ qua giúp em với ạ em cảm ơn mn nhiều.)",['#sharing'],"['chào mn', 'sinh viên', 'trường đẳng', 'định trường', 'liên thông', 'đại học', 'ngành', 'học đẳng', 'cntt', 'nguyện vọng', 'ngành', 'học', 'liên thông', 'khoa học', 'máy', 'giúp đỡ', 'góp', 'giúp', 'trường', 'đào', 'liên thông thể', 'chuẩn', 'liên thông', 'đại học', 'nghía', '2', 'trường', 'kv', 'tp', 'hcm', 'uit', 'đh', 'học', 'trường thể', 'review trường', 'văn câu', 'thông cảm', 'giúp', 'mn']"
509,"Khoá học 12 buổi hoàn toàn miễn phí về Generative AI vừa được cho ra mắt bởi Microsoft 🔥🔥🔥
Cách đây 2 tuần Microsoft vừa cho ra mắt khóa học miễn phí với 12 buổi học về generative AI. Mỗi buổi học sẽ bao gồm:
1 video ngắn giới thiệu về topic
Nội dung được trình bày cả dưới dạng video và text (các bạn đang học tiếng Anh thích luyện kĩ năng nào thì xài tài liệu dạng đó nhé 😎)
1 Jupyter Notebook với code mẫu
Bài tập về nhà
Tài liệu tham khảo dành cho các ban muốn tìm hiểu thêm
Khóa học được thiết kế dành cho cả các bạn chưa tiếp xúc với AI bao giờ (1 vài buổi học đầu sẽ giới thiệu các kiến thức cơ bản)
Link to the course: https://github.com/microsoft/generative-ai-for-beginners
#ai_share",['#sharing'],"['khóa', 'học', '12', 'miễn phí', 'generative', 'mắt', 'microsoft', '2', 'tuần', 'microsoft', 'mắt', 'khóa học', 'miễn phí', '12', 'học', 'generative', 'học', 'bao', '1', 'video', 'ngắn', 'giới thiệu', 'topic', 'nội dung', 'trình bày', 'dạng', 'video', 'text học', 'tiếng luyện', 'kĩ năng', 'xài', 'tài liệu', 'dạng', '1', 'jupyter', 'notebook', 'code', 'mẫu', 'tập', 'tài liệu', 'tham khảo', 'ban', 'khóa học', 'thiết kế', 'tiếp xúc', '1', 'học', 'đầu', 'giới thiệu', 'kiến thức', 'link', 'to', 'the', 'course']"
510,"Python Data Science Handbook [bản tiếng anh]

Xin chào mọi người, hôm nay mình xin giới thiệu tới mọi người cuốn sách Python Data Science Handbook của Jake VanderPlas.
[*đã chỉnh sửa*] Cuốn này không dành cho totally beginner (chưa động vào programing language bao giờ), nhưng nếu bạn biết những thứ basis như defining functions, assigning variables, calling methods of objects thì có thể đọc được đọc được. Sau khi đọc xong 4 chương đầu, bạn có thể làm việc tự tin với Pandas & Matplotlib. Chương 5 là về Machine Learning, phần này thì mình đang đọc. Nó giới thiệu về sklearn & các thuật toán nhưng thiên về code hơn là về toán học. Chắc phải đọc thêm tài liệu khác để bổ sung về toán.
Bạn có thể đọc online cuốn sách này tại đây: https://jakevdp.github.io/PythonDataScienceHandbook/
Ngoài ra, cuốn này được được viết toàn bộ trên Jupyter Notebook, các notebook đó có thể tìm thấy trong repo này: https://github.com/jakevdp/PythonDataScienceHandbook. Theo như recommend của cuốn sách thì bạn nên clone repo này, vừa đọc sách vừa code theo để đạt hiệu quả tốt nhất.
Với kinh nghiệm bản thân của mình cho những bạn beginner thì nên tận dụng sức mạnh của các LLMs như GPT, Bing để hỗ trợ việc đọc sách. Mỗi khi đọc, có gì không hiểu, ngay lập tức hỏi GPT để tìm câu trả lời. Nếu khó hiểu quá thì thần chú của mình là: “Explain to me like you are explaining to a child about: …” =))).
Cuốn này còn Chương 5 về Machine Learning mình đang đọc nốt và mong muốn kiếm được người cùng đọc chung trong group này.
Bản thân mình thì đang nghiên cứu và tự học Data Science từ con số 0, không có background ngành IT, được khoảng 5-6 tháng.
Một vài dòng giới thiệu bản thân để bạn dễ lựa chọn hợp tác:
Pandas, Numpy, Matplotlib, Seaborn thành thạo sử dụng trong công việc hàng ngày
Nắm được các khái niệm cơ bản trong Machine Learning, có thể phân biệt các loại mô hình, thuật toán về mặt khái niệm. Chưa học kĩ về toán đằng sau các algorithm đó.
Nắm và thực hiện được tokenizing, word-segmenting, vectorizing trong NLP. Chưa biết train mô hình. Đang có định hướng đi sâu vào NLP sau này.
Ngoài ra, một vài thứ khác mình biết, có thể không liên quan lắm, nhưng vẫn list ra, in case, ai đó muốn hợp tác học hành: Selenium, BeautifulSoup, Langchain, Pinecone, SQL, Excel (Advanced Excel),…
Chi tiết có thể truy cập github của mình để xem thêm: https://github.com/DataSpi
Mình đang muốn tìm kiếm khoảng 3-4 đồng đội ở ngang level để cùng học hành, nghiên cứu ML chuyên sâu. Mình ưa xài tiếng Anh, nên nếu bạn nào có tiếng Anh tốt một xíu, đọc tài liệu nước ngoài thoải mái thì tốt nhé. Bạn nào có hứng thú thì comment bên dưới và inbox để trao đổi thêm nhé.
📌 Dòng cuối, nói là tìm đồng đội ngang level thế thôi, nhưng mà nếu có anh chị nào nhiều kinh nghiệm, sẵn sàng bỏ thời gian ra cho em tầm sư thì em cũng welcome lắm ạ. Nếu oke, xin anh chị để lại một comment bên dưới nhé.

-

P/S: Do đăng vội nên lúc đầu mình ghi là sách này totally beginner đọc cũng được. Mình đã đọc lại sách và có sửa lại phần nội dung bên trên.
#ds_ml_share #ds_ml_study","['#sharing', '#python']","['python', 'data', 'science', 'handbook', 'tiếng', 'chào hôm', 'giới thiệu', 'sách', 'python', 'data', 'science', 'handbook', 'jake', 'vanderplas', 'chỉnh sửa', 'totally', 'beginner động', 'programing', 'language', 'basis', 'defining', 'functions', 'assigning', 'variables', 'calling', 'methods', 'of', 'objects thể', 'đọc', 'đọc', 'đọc', 'xong', '4', 'chương', 'đầu thể', 'pandas', 'matplotlib chương', '5', 'machine', 'learning', 'đọc', 'giới thiệu', 'sklearn thuật', 'toán', 'thiên code', 'toán học', 'đọc', 'tài liệu', 'bổ sung', 'toán thể', 'đọc', 'online', 'sách', 'https', 'jakevdp', 'github', 'io', 'pythondatasciencehandbook', 'viết', 'toàn', 'jupyter', 'notebook', 'notebook thể', 'repo', 'https', 'github', 'com', 'jakevdp', 'pythondatasciencehandbook', 'recommend', 'sách', 'clone repo', 'đọc', 'sách', 'code hiệu', 'kinh nghiệm', 'thân beginner', 'tận dụng', 'sức', 'llms', 'gpt bing', 'đọc', 'sách', 'đọc', 'lập tức', 'gpt', 'câu', 'thần', 'explain', 'to', 'me', 'like', 'you', 'are', 'explaining', 'to', 'a child', 'about chương', '5', 'machine learning', 'đọc', 'nốt', 'mong', 'kiếm', 'đọc', 'group thân', 'nghiên cứu', 'học', 'data', 'science', '0', 'background', 'ngành', 'it', '56', 'dòng', 'giới thiệu', 'thân lựa', 'hợp tác', 'pandas', 'numpy', 'matplotlib', 'seaborn', 'thành thạo', 'công hàng', 'nắm', 'khái niệm', 'machine', 'learning thể', 'phân biệt', 'mô hình', 'thuật toán', 'mặt', 'khái niệm', 'học', 'kĩ toán', 'đằng', 'algorithm', 'nắm', 'tokenizing', 'wordsegmenting', 'vectorizing', 'nlp', 'train', 'mô hình', 'định hướng', 'đi sâu', 'nlp thể', 'lắm', 'list', 'in', 'case', 'hợp tác', 'học hành', 'selenium', 'beautifulsoup', 'langchain', 'pinecone', 'sql', 'excel', 'advanced', 'excel', 'chi tiết thể', 'truy cập', 'github', 'kiếm', '34', 'đồng đội', 'ngang', 'level', 'học hành', 'nghiên cứu', 'ml', 'chuyên sâu', 'ưa', 'xài', 'tiếng', 'tiếng xíu', 'đọc', 'tài liệu', 'thoải mái', 'hứng', 'thú', 'comment', 'inbox', 'trao đổi', 'dòng', 'đồng đội', 'ngang', 'level', 'kinh nghiệm', 'sẵn sàng', 'tầm sư', 'welcome', 'lắm', 'oke', 'comment', 'p', 's', 'đăng', 'vội', 'đầu', 'ghi', 'sách', 'totally beginner', 'đọc', 'đọc', 'sách', 'sửa', 'nội dung']"
511,"Chào mọi người, em viết file Markdown bình thường thì vẫn hiện hỗ trợ LaTex, nhưng khi publish lên github io thì nó bị như này, em xin cách fix với ạ
#github",['#Q&A'],"['chào', 'viết', 'file', 'markdown', 'bình', 'hiện', 'latex', 'publish', 'github', 'io', 'fix']"
512,"Lỗi nhiều người mắc phải khi sử dụng Pytorch với GPU 🔥🔥🔥
Mình xin khẳng định luôn từ đầu là lỗi này mình cũng mắc phải 😅
Như các bạn nhìn thấy trong hình bên dưới, rất nhiều người khi sử dụng Pytorch có thói quen là tạo Tensor trên CPU trước, rồi sau đó mới chuyển sang GPU. Điều này vừa không tối ưu về bộ nhớ (phải tiêu tốn cả CPU cả GPU) vừa không tối ưu về mặt tốc độ (tốn thời gian chuyển đổi giữa CPU và GPU)
Cách tốt nhất chúng ta nên làm là khởi tạo trực tiếp Tensor trên GPU. Điều này vừa giúp tiết kiệm bộ nhớ trên CPU vừa làm tăng đáng kể tốc độ xử lý do không phải chuyển đổi giữa các thiết bị
Và kết quả là tốc độ nhanh hơn 170 lần 🥰
#dl_tips","['#sharing', '#python']","['lỗi', 'mắc', 'pytorch', 'gpu', 'đầu', 'lỗi', 'mắc hình', 'pytorch', 'thói quen', 'tensor', 'cpu', 'gpu', 'tối ưu tiêu', 'tốn', 'cpu', 'gpu', 'tối ưu mặt', 'tốc độ', 'tốn', 'đổi', 'cpu', 'gpu', 'ta', 'khởi tensor', 'gpu', 'giúp', 'tiết kiệm', 'cpu', 'tốc độ', 'đổi', 'thiết kết', 'tốc độ', '170']"
513,"Chào mọi người ạ, em hiện đang là sinh viên đại học có ý định sẽ học cao lên thạc sĩ. Theo mọi người thì nên học đại học xong học thẳng lên thạc sĩ luôn hay nên đi làm vài năm rồi tiếp tục học lên ạ?
Em xin cảm ơn ạ!!
#ds_roadmap",['#Q&A'],"['chào', 'hiện', 'sinh viên', 'đại học', 'định học', 'thạc sĩ', 'học', 'đại học', 'xong', 'học', 'thẳng', 'thạc sĩ', 'đi', 'học']"
514,"Chào mn, em là sinh viên năm 2. Chuyên ngành em đang học là Tự động hóa. Dự định của em là sẽ theo hướng sang mảng DS/AI. Mn cho em hỏi nếu tự học thì có khả quan lắm ko ạ? Hiện tại em học được cơ bản về C++ và python, bên cạnh đó thì các kiến thức về Giải tích, Đại số,... em khá vững. Nếu em tự học thì nên bắt đầu từ đâu ạ? Em rất cảm ơn với mọi lời khuyên và chia sẻ từ mn ạ <3
#ds_ml_roadmap",['#Q&A'],"['chào mn', 'sinh viên', '2', 'chuyên ngành', 'học động', 'hóa', 'dự định hướng', 'mảng', 'ds', 'mn học', 'khả quan', 'lắm', 'ko', 'học', 'c', 'python cạnh', 'kiến thức', 'giải tích', 'đại vững', 'học', 'khuyên', 'mn', '3']"
515,"Chào mn, em newbie DL, khi cài module tensorflow_datasets thì em gặp lỗi. Mn hướng dẫn em với ạ. Do em remove environment nên k kịp chụp lỗi.
#DL_ML","['#Q&A', '#python']","['chào', 'mn', 'newbie dl', 'cài', 'module', 'tensorflow_datasets', 'lỗi', 'mn', 'hướng', 'remove', 'environment', 'k', 'kịp', 'chụp', 'lỗi']"
516,"Chào mọi người,
Em là sinh viên đang làm bài tập lớn về xử lý phân loại lá theo kích thước, em muốn hỏi là mình nên dùng giải thuật nào là tối ưu và chính xác nhất, em thấy chỉ detect 1 đối tượng mà dùng segmentation như của yolo thì phải tốn công đoạn train nữa","['#Q&A', '#cv', '#deep_learning']","['chào', 'sinh viên', 'tập', 'phân lá', 'kích thước', 'giải thuật', 'tối ưu', 'xác', 'detect', '1', 'đối tượng', 'segmentation', 'yolo', 'tốn', 'công đoạn', 'train']"
517,Mn ơi ai đã dùng gg colab pro cho em hỏi là so sánh với colab free thì nó có đáng đồng xiền bát gạo k ạ. Và mọi người có thể sg những thứ tương tự như thế cho sv nghèo k ạ 🥺 Em cảm ơn ạ,['#Q&A'],"['mn', 'gg', 'colab', 'pro', 'sánh', 'colab', 'free', 'đồng', 'xiền', 'bát', 'gạo', 'k thể', 'sg', 'tương sv', 'nghèo', 'k']"
518,"Em chào mọi người,
Em đang tập thực hiện bài toán Classification trong ML thì dataset của em có 3 cột có giá trị NaN ở trong categorical columns.
Em có thực hiện chia dataset thành 3 phần train, val, test.
Khi thực hiện fillna em có suy nghĩ về việc sử dụng KNN và RandomForest để predict từng cột bị NaN một.
Em có thắc mắc là mình fillna trước khi chia dataset thành 3 phần hay sau khi chia, nếu fillna trước khi chia thì tập val và tập test chưa các dòng đã được fillna thì model liệu có còn predict đúng. Hay đơn giản là em nên dropna đi ở trong trường hợp này (NaN khoảng 10% ạ)
#ml_study","['#Q&A', '#machine_learning', '#data']","['chào', 'tập toán', 'classification', 'ml', 'dataset', '3', 'cột', 'nan', 'categorical', 'columns', 'chia', 'dataset', 'thành', '3', 'train', 'val', 'test', 'fillna', 'suy knn', 'randomforest', 'predict', 'cột', 'nan', 'thắc mắc', 'fillna', 'chia', 'dataset', 'thành', '3', 'chia', 'fillna', 'chia', 'tập', 'val', 'tập', 'test', 'dòng', 'fillna', 'model liệu', 'predict', 'đơn giản', 'dropna', 'đi', 'trường hợp', 'nan', '10']"
519,"Chào anh/chị hiện em đang muốn crawl dữ liệu về người theo dõi ( tên, tuổi, địa chỉ ) 1 trang trên twitter ( ví dụ như bitcoin ) để làm project nhưng đang không biết làm thế nào , có anh/chị nào đã từng làm những bài toán tương tự như thế có thể gợi ý giúp em được không ạ?
#data_study","['#Q&A', '#data']","['chào', 'hiện', 'crawl liệu', 'dõi địa', '1', 'trang', 'twitter', 'ví dụ', 'bitcoin', 'project toán', 'tương thể', 'gợi', 'giúp']"
520,"Chào mọi người. Mình hay đọc cmt thấy nhiều anh/chị có chia sẻ nhiều nguồn khóa học share miễn phí hay quá nên em muốn đăng một post như này để tổng hợp các nguồn như vậy ạ. Mọi người có ai biết những nguồn như vậy thì cùng cmt xuống dưới nhé ạ. Em cảm ơn!
#xx_share",['#sharing'],"['chào', 'đọc', 'cmt', 'khóa', 'học', 'share', 'miễn phí', 'đăng post', 'tổng hợp', 'cmt']"
521,"e chào các ac ạ
e là sv năm nhất trường cd FPT
e cũng mới tham gia group thôi nhưng thấy nhiều ac giỏi quá, e rất ngưỡng mộ và các ac cx là động lực để e trở thành người giỏi như các ac, nhưng thực thì e cx chưa bt gì về viết code, lập trình nên e có 3 câu hỏi mong được ac trong group giải đáp với ạ <333:
-theo các cj thì học cntt ở cd btec fpt liệu có ổn k ạ
-hiện tại e đang chỉ hc ta tại trường, năm sau mới hc vào chuyên ngành cntt nhưng bây giờ e muốn tự học viết code ạ nhưng mà e mù quán quá, k bt học từ đâu và học những j, e hoàn toàn k có 1 gốc j về viết code cả, ac định hướng phần này cho e đc k ạ
-e đam mê học kinh tế nhưng vì đã rớt nguyện vọng, hiện tại thì e đang học cntt thì liệu có ổn k ạ, lúc đầu e cx hướng đến hc DA, nhưng bây giờ muốn đổi chuyên ngành thì đóng 2 triệu cho trường, e k bt có nên đổi hay không vì gd e kt cx k qua dư dả
C.ơn ac đã đọc và giải đáp giúp e, chúc ac 1 ngày tốt lành ❤️❤️❤️
#py_study
 — đang cảm thấy đầy hy vọng.",['#Q&A'],"['e', 'chào ac', 'e', 'sv', 'trường', 'cd', 'fpt e', 'tham gia', 'group', 'ac', 'giỏi', 'e ngưỡng', 'mộ', 'ac', 'cx', 'động lực', 'e', 'giỏi', 'ac', 'thực e', 'cx', 'bt', 'viết', 'code', 'lập trình', 'e', '3', 'mong', 'ac', 'group', 'giải đáp', '333', 'cj', 'học', 'cntt', 'cd', 'btec', 'fpt liệu', 'ổn', 'k', 'e hc', 'ta', 'trường', 'hc', 'chuyên ngành', 'cntt', 'e học', 'viết', 'code', 'e mù', 'quán', 'k', 'bt', 'học', 'học', 'j', 'e k', '1', 'gốc', 'j', 'viết', 'code', 'ac', 'định hướng', 'e đc', 'k e', 'đam mê học', 'kinh tế', 'rớt nguyện vọng', 'e học', 'cntt liệu', 'ổn', 'k', 'đầu', 'e', 'cx', 'hướng', 'hc', 'da đổi', 'chuyên ngành', 'đóng', '2', 'triệu', 'trường', 'e k', 'bt', 'đổi', 'gd', 'e kt', 'cx', 'k dư', 'dả', 'c ơn', 'ac', 'đọc', 'giải đáp', 'giúp', 'e chúc', 'ac', '1', 'lành', 'hy vọng']"
522,"Em chào mọi người ạ, hiện tại em đang làm một project bên mảng NLP liên quan đến việc tóm tắt văn bản tiếng việt sử dụng BERT. Qua tìm hiểu nhiều nguồn tài liệu khác nhau thì e biết được là có các mô hình thông dụng như BERTSUM, Multilingual BERT, BERTAbs(Abstractive Bert),... Tuy nhiên, em vẫn còn gặp một số khó khăn ở phần định hướng cho project ví dụ như bước chọn dataset, tiền xử lý dữ liệu và chọn model nào cho thích hợp. Em rất mong nhận được sự giúp đỡ từ mọi người để có thể hoàn thành project của mình ạ. Em cảm ơn <3.
#nlp_study","['#Q&A', '#deep_learning', '#nlp', '#data']","['chào', 'project', 'mảng', 'nlp tóm', 'tắt văn', 'tiếng', 'việt', 'bert', 'tài liệu', 'e', 'mô hình', 'thông dụng', 'bertsum', 'multilingual', 'bert', 'bertabs', 'abstractive', 'bert nhiên', 'khăn', 'định hướng', 'project', 'ví dụ', 'dataset', 'tiền liệu', 'model hợp', 'mong', 'giúp đỡ thể', 'hoàn thành', 'project', '3']"
523,"Cheatsheet Data visualization trong Python 🔥🔥🔥
Dưới đây là cheatsheet dành cho data visualization trong Python, với 2 thư viện vô cùng phổ biến đối với các bạn học Data Science: Matplotlib và Seaborn. Các plot sẽ bao gồm:
Histogram 
Box plot
Violin Plot (Cái này cá nhân mình không xài nhiều)
Bar chart
Line chart
Stacked column chart
Scatter plot
Bubble plot
Pie chart
Heat map
Mình tin rằng cheatsheet này sẽ vô cùng hữu ích với các bạn theo mảng Data Science 🥳
Link: https://drive.google.com/file/d/11IZHGA8YOahXqdJTGbK2xNrQVZ5g97tg/view?usp=sharing","['#sharing', '#python']","['cheatsheet', 'data', 'visualization', 'python', 'cheatsheet', 'data', 'visualization', 'python', '2', 'thư viện', 'vô', 'phổ biến', 'đối học', 'data', 'science', 'matplotlib', 'seaborn', 'plot', 'bao', 'histogram', 'box', 'plot', 'violin', 'plot', 'xài', 'bar', 'chart', 'line', 'chart', 'stacked', 'column', 'chart', 'scatter', 'plot', 'bubble', 'plot', 'pie', 'chart', 'heat', 'map', 'cheatsheet', 'vô hữu ích', 'mảng', 'data', 'science', 'link']"
524,"Chào mọi người và anh Việt, hiện tại em tìm hiểu polynomial regression, em chưa biết cách tự implement thay vì dùng skrlearn
Em muốn hỏi mọi người 2 vấn đề:
Cách tự implement polynomial regression
Tại sao bậc càng cao thì data của mình càng fit
#ML_DL","['#Q&A', '#machine_learning']","['chào', 'việt', 'polynomial', 'regression', 'implement', 'thay', 'skrlearn', '2', 'implement', 'polynomial', 'regression', 'bậc', 'data', 'fit']"
525,"Chào mọi người. Mình đang làm đồ án môn Deep learning là dự báo giá cổ phiếu trên thị trường chứng khoán Nhật Bản. Minh dự định dùng LSTM và Bi LSTM. Xin hỏi mọi người là có khả quan không ạ. Và tài liệu của hai mô hình này mình đọc ở đâu. Mình xin cảm ơn.
#dl","['#Q&A', '#deep_learning']","['chào', 'đồ án', 'môn', 'deep', 'learning', 'dự báo giá', 'cổ phiếu', 'thị trường chứng khoán', 'nhật minh', 'dự định', 'lstm', 'bi lstm', 'khả quan tài liệu', 'hai', 'mô hình', 'đọc']"
526,"Tổng hợp các công cụ AI dành cho các mục đích sử dụng khác nhau 🔥🔥🔥
#ai_share 
P/s: Mình xài mỗi Canva 😅",['#Q&A'],"['tổng hợp', 'công cụ', 'mục đích', 'p', 's', 'xài', 'canva']"
527,"Mn cho em hỏi là hiện tại em muốn dùng thuật toán softmax để nhận diện cảm xúc của người nhưng tài liệu lại khá ít và em ko mường tượng được input lẫn output. Ai có lời khuyên hay tài liệu thì cho em xin ạ.
#ML_study","['#Q&A', '#cv']","['mn', 'thuật toán', 'softmax diện', 'cảm xúc', 'tài liệu', 'ko', 'mường tượng', 'input', 'lẫn', 'output', 'khuyên', 'tài liệu']"
528,"Mọi người cho e hỏi fix lỗi này sao ạ, em mới reset máy :((( em có search nhưng mãi k sửa được ạ",['#Q&A'],"['e', 'fix', 'lỗi', 'reset', 'máy', 'search', 'mãi', 'k', 'sửa']"
529,"Chào anh việt và mọi người,cho em xin một vài project ML triển khai trên AWS,em xin cảm ơn ạ #ML_study",['#sharing'],"['chào', 'việt', 'project', 'ml', 'triển khai', 'aws']"
530,"Em chào mọi người, hiện em đang làm dự án cv nhỏ dùng thuật toán học máy để đánh giá đẹp xấu chữ cái tập viết học sinh lớp 1, em đang có ảnh tập đầu vào ở dưới, em muốn cắt từng ảnh chữ riêng để đánh giá hoặc vị trí chữ trong ảnh, nhưng tìm trên mạng các phương pháp tách chữ viết tay không có tác dụng lắm, anh chị có ý tưởng hoặc code thì cho em tham khảo với ạ
#ML_study
#py_study","['#Q&A', '#cv']","['chào', 'hiện', 'dự án', 'cv thuật', 'toán học', 'máy', 'đẹp', 'xấu', 'chữ', 'tập', 'viết', 'học sinh', 'lớp', '1', 'ảnh', 'tập', 'đầu', 'cắt', 'ảnh', 'chữ', 'chữ', 'ảnh', 'mạng', 'phương pháp', 'tách', 'chữ viết', 'tác dụng', 'lắm', 'tưởng', 'code', 'tham khảo']"
531,"hêlo group. mình thật sự cần 1 mentor support mảng python phân tích dữ liệu cho ngân hàng.
rất cám ơn

#py_study",['#python'],"['hêlo', 'group', '1', 'mentor', 'support', 'mảng', 'python', 'phân tích liệu', 'ngân hàng', 'cám ơn']"
532,"Em chào anh Việt và mọi người ạ. Em là học sinh lớp 12 đang tìm hiểu về DS và ML. Sau khi đọc thử một số tài liệu cho beginner mà mọi người chia sẻ cũng như các post của anh chị thì em thực sự thấy DS và ML rất cuốn. Em cảm ơn anh Việt rất nhiều vì đã tạo ra group này để em tìm được điều mình thích trong khi đang rất mông lung về việc chọn ngành chọn nghề năm cuối cấp
Hiện tại em không còn quá cần lo lắng về việc thi đh nữa nên em cũng muốn xuất phát sớm để không bị lạc lối khi bước chân vào đại học. Em muốn hỏi mọi người liệu thời điểm này em có thể bắt đầu học những gì và tham khảo những tài liệu gì ạ ? Em cũng đang bắt đầu học toán theo giáo trình của các thầy bên HUST và có dự định sẽ học thêm python trong thời gian sắp tới. Tuy nhiên nguồn tài liệu em hiện có khá hạn chế nên rất mong mọi người có thể chia sẻ cho em một vài nguồn cho beginner về DS và ML ạ ( bằng tiếng Anh cũng được ạ )
Em cảm ơn mọi người rất nhiều ạ.
#ds_study
#ml_study
#py_study",['#Q&A'],"['chào', 'việt', 'học sinh', 'lớp', '12', 'ds', 'ml', 'đọc', 'thử', 'tài liệu', 'beginner', 'post', 'thực ds', 'ml', 'việt', 'group', 'mông lung', 'ngành nghề', 'lo lắng', 'thi', 'đh', 'xuất phát', 'lạc', 'lối', 'chân', 'đại học', 'liệu thể', 'học', 'tham khảo', 'tài liệu', 'học toán', 'giáo trình', 'thầy', 'hust', 'dự định', 'học', 'python nhiên', 'tài liệu', 'hiện', 'hạn chế', 'mong thể', 'beginner', 'ds', 'ml', 'tiếng']"
533,"Chào mọi người, em hiện đang là sinh viên của 1 trưởng đại học khá có tiếng trong lĩnh vực IT muốn theo đuổi về lĩnh vực AI, cụ thể là Computer Vision. Mọi người nghĩ sao về việc học lên trình độ Thạc sĩ ( học ở Việt Nam thôi ạ ), liệu có nên không và nó có giúp mình có nhiều cơ hội việc làm hơn không ạ?
E xin cảm ơn ạ!!!
#ai_study",['#Q&A'],"['chào', 'hiện', 'sinh viên', '1', 'trưởng', 'đại học', 'tiếng', 'lĩnh vực', 'it', 'đuổi', 'lĩnh vực', 'computer vision', 'học', 'trình độ', 'thạc sĩ', 'học', 'việt nam liệu', 'giúp', 'hội', 'e']"
534,"Slide Deep Computer Vision đến từ MIT 🔥🔥🔥
Mình xin chia sẻ với các bạn slide bài giảng về topic Deep Computer Vision của đại học kĩ thuật  Massachusetts (MIT), vừa được ra mắt vào tháng 1 năm nay. Cá nhân mình thì rất thích tài liệu này vì nó đúng vào chuyên môn của mình – Deep Learning for Computer Vision 😊
Tài liệu của MIT nhưng cực kì dễ đọc các bạn nhé, vì khá nhiều hình ảnh. Mình để ý có nhiều slide mượn figure từ course DL4CV của Stanford 😆
Link: https://drive.google.com/file/d/198wmT9m9kwB7DFXXpKh2r2vHs-vOylk_/view?usp=sharing
#dl_share","['#sharing', '#cv']","['slide', 'deep', 'computer', 'vision', 'mit', 'slide', 'giảng topic', 'deep', 'computer', 'vision', 'đại học kĩ thuật', 'massachusetts', 'mit', 'mắt', '1', 'tài liệu', 'chuyên môn', 'deep', 'learning', 'for', 'computer', 'vision', 'tài liệu', 'mit', 'cực kì', 'đọc', 'hình ảnh', 'slide', 'mượn', 'figure', 'course', 'dl4cv', 'stanford', 'link']"
535,"Hi!
Mình đang có 01 dự án liên quan AI khá thú vị, ae có ai muốn nghiên cứu chung không ạ?
Điều kiện:
- Hiện chỉ cần 1 bạn.
- Đã có kinh nghiệm làm python web 1-2 năm ở dự án cty.
- Share màn hình làm chung với mình vào mỗi tối 2-3 giờ.
Hỗ trợ:
- Nếu cần mình có thể hỗ trợ tiền điện nước 3-5$/giờ.
Note: mình ở HCM, ưu tiên anh em ở HCM nhé.
Cảm ơn bạn đã quan tâm tin của mình, có gì inb trao đổi thêm nhé.
#ai_job",['#machine_learning'],"['hi', '01', 'dự án', 'thú vị', 'ae', 'nghiên cứu', 'kiện', 'hiện', '1', 'kinh nghiệm', 'python web', '12', 'dự án', 'cty', 'share', 'màn hình', 'tối', '23', 'thể', 'tiền', 'điện', '35', 'note', 'hcm', 'ưu tiên', 'hcm', 'inb', 'trao đổi']"
536,"#dl_cv
Em chào anh Việt và mọi người.
Em xin phép đặt câu hỏi như sau. Trong ứng dụng shopee có chức năng chụp hình thì nó sẽ gợi ý ra những sản phẩm tương tự. Tuy nhiên em vẫn chưa hiểu được cách làm sao mà khi ảnh đưa vào hệ thống nó có thể khoanh vùng được các đối tượng mà mình mong muốn. Giả sử hình chụp 1 khoảng rộng có cả sách, ly, chuột thì nó sẽ cho mình chọn 1 trong 3 thứ đó và gợi ý. Mong được anh và mọi người giải đáp.
Em xin chân thành cảm ơn.",['#Q&A'],"['chào', 'việt phép', 'ứng dụng', 'shopee', 'chức năng', 'chụp', 'hình gợi', 'sản phẩm', 'tương nhiên', 'ảnh', 'hệ thống thể', 'khoanh', 'đối tượng', 'mong', 'giả', 'sử hình', 'chụp', '1', 'rộng', 'sách ly', 'chuột', '1', '3', 'gợi', 'mong', 'giải đáp', 'chân thành']"
537,"Dataset trong Pytorch 🔥🔥🔥
Pytorch là 1 trong các framework về Deep Learning phổ biến nhất trên thế giới (Đây cũng là favorite framework của mình 🥰), nhờ sự linh động và đơn giản trong cú pháp cũng như sở hữu 1 cộng đồng người sử dụng đông đảo. Khi nói về Machine Learning hay Deep Learning người ta thường nói nhiều về model trong khi quên mất rằng Data cũng là 1 thành phần quan trọng không kém (thậm chí khi các bạn đi làm thì thời gian các bạn làm việc với data còn có thể nhiều hơn thời gian làm việc với model). Tài liệu sau tổng hợp những kiến thức cơ bản nhất bạn cần biết khi làm việc với Dataset trong Pytorch 😎
Link to pdf: https://drive.google.com/file/d/1g-I-XB6MiRmiA0SsX0uGJdwF8LXzRbwT/view?usp=sharing
#dl_share","['#sharing', '#python']","['dataset', 'pytorch', 'pytorch', '1', 'framework', 'deep', 'learning', 'phổ biến', 'giới', 'favorite', 'framework', 'linh động', 'đơn giản', 'cú', 'pháp sở hữu', '1', 'cộng đồng', 'đông đảo', 'machine', 'learning', 'deep', 'learning', 'ta', 'model', 'quên', 'data', '1', 'thành', 'kém chí', 'đi', 'data thể', 'model', 'tài liệu', 'tổng hợp', 'kiến thức', 'dataset', 'pytorch', 'link', 'to', 'pdf']"
538,"Em thấy thấy group mình mọi người làm bên nước ngoài nhiều nên em xin mạn phép được hỏi vài câu :(
Em hiện đang là sinh viên IT tại BKHN. Em muốn học lên Master Machine Learning ở một nước Châu Âu vừa học vừa làm để trang trải học phí và theo như em tìm hiểu thì ML engineer là một ngành không có entry-level job, entry-level job duy nhất là Data Analyst, nên giờ em nên học theo 2 hướng là ML và DA cùng lúc ạ ?
Với em có tìm hiểu được rằng đại học bên đức miễn phí và có các trường giảng dạy bằng tiếng anh, việc e dùng bằng bkhn apply vào Master của các trường này cũng như việc mù tịt tiếng đức có khả thi không ạ ?
Với các trường bển họ có coi trọng điểm rèn luyện với hd ngoại khóa khi apply vào master không ạ ? Hay em nên tập trung rèn luyện chuyên môn với làm project và chú trọng gpa ạ ?(gpa mức nào thì ổn ạ ?)
Em xin lỗi vì em hỏi hơi nhiều, em cảm ơn mn :(",['#Q&A'],"['group', 'mạn phép', 'câu', 'hiện', 'sinh viên', 'it', 'bkhn', 'học', 'master', 'machine', 'learning', 'châu âu học', 'trang trải', 'học phí', 'ml', 'engineer', 'ngành', 'entrylevel', 'job', 'entrylevel', 'job', 'data', 'analyst', 'học', '2', 'hướng', 'ml', 'da', 'đại học', 'đức', 'miễn phí', 'trường', 'giảng dạy', 'tiếng', 'e bkhn', 'apply', 'master', 'trường', 'mù tịt', 'tiếng', 'đức', 'khả thi', 'trường', 'coi trọng', 'rèn luyện', 'hd', 'ngoại khóa', 'apply', 'master', 'rèn luyện', 'chuyên môn', 'project trọng', 'gpa', 'gpa', 'ổn', 'lỗi', 'hơi', 'mn']"
539,"Chào mọi người và anh Việt ạ, thì hiện tại em đang thử vọc vạch sử dụng yolov5 để detect số trong văn bản (chỉ số thôi ạ), nhưng hiện tại em đang gặp vấn đề là các kí tự và chữ cái cũng bị đánh nhầm theo, mAP50 chỉ ở khoảng 0.8, batchsize mình để là 8, epoch 100, mình nghĩ vấn đề là do data mà mình tự lại nhưng lại không biết cách khắc phục sao, mọi người góp ý giúp mình với mình xin cảm ơn ạ.
Link video hướng dẫn train yolov5: YOLOv5 training with custom data - YouTube
Link data: https://drive.google.com/file/d/1_PtFEGPeoe8Qr87XqFa9TZ3txnqSyHi2/view?usp=sharing
#cv_code
#ml_code","['#Q&A', '#cv', '#deep_learning']","['chào', 'việt', 'thử', 'vọc', 'vạch', 'yolov5', 'detect', 'văn kí', 'chữ', 'đánh', 'nhầm', 'map50', '0', '8', 'batchsize', '8', 'epoch', '100', 'data', 'khắc phục', 'góp', 'giúp', 'link', 'video', 'hướng', 'train', 'yolov5', 'yolov5', 'training', 'with', 'custom', 'data', 'youtube', 'link', 'data']"
540,"em chào mọi người ạ . Em đang là sinh viên CNTT và mong muốn học Python từ con số 0 , rất mong mọi người trong group cho em xin đóng góp về định hướng trong quá trình học , cũng như nguồn học tập ̣̣̣̣̣(youtube,google,..) . Em xin cảm ơn mọi người rất nhiều ạ
#pythonStudy","['#sharing', '#python']","['chào', 'sinh viên', 'cntt', 'mong', 'học', 'python', '0', 'mong group', 'đóng góp', 'định hướng', 'trình', 'học', 'học tập', 'youtube', 'google']"
541,"Em chào mọi người ạ. Em là sinh viên năm nhất ngành Công nghệ thông tin và định hướng của em sau này trở thành 1 ML Engineer. Em hiện đang bắt đầu học về ML. Em nghe mọi người bảo ML và DS có sự liên quan chặt chẽ đến nhau nên em cũng muốn tìm hiểu về DS nhưng không biết nên bắt đầu từ đâu và DS cũng có các nhánh con như data analyst hay data buiding. Không biết nếu theo định hướng cua em thì nên học bên nào ạ. Em mong mọi người tư vấn giúp em với ạ. Em cảm ơn mọi người ạ.
#DS_Study
#ML_study",['#Q&A'],"['chào', 'sinh viên', 'ngành', 'công nghệ thông', 'định hướng', '1', 'ml', 'engineer', 'hiện', 'học', 'ml', 'bảo', 'ml', 'ds', 'chặt chẽ', 'ds', 'ds', 'nhánh', 'data', 'analyst', 'data', 'buiding', 'định hướng', 'cua học', 'mong', 'tư vấn', 'giúp']"
542,"Chào mọi người, cho em hỏi sao người ta định nghĩa hàm J(theta) là công thức dưới đây ạ
#DL_ML","['#Q&A', '#math']","['chào', 'ta', 'định nghĩa', 'hàm j', 'theta', 'công thức']"
543,"Khoá học Introduction to Machine Learning của đại học Toronto 🔥🔥🔥
Hi các bạn,
Trường đại học Toronto là trường luôn luôn nằm ở vị trí Top 1 ở Canada và Top 30 các trưòng đại học tốt nhất trên thế giới trên tất cả các bạn xếp hạng uy tín, bao gồm cả 3 bảng xếp hạng danh tiếng nhất thế giới là QS, Times Higher Education và Shanghai Ranking (Và tất nhiêu cao hơn rất nhiều ngôi trường mà mình vẫn hay flex 😅)
Đây cũng là 1 trong số ít các trường đại học danh tiếng chia sẻ công khai tài liệu các khoá học về AI/Machine Learning. Trong post này mình xin chia sẻ với các bạn khoá học Introduction to Machine Learning của họ. 
1 điều mình rất thích từ khoá học này, đó là cách bố trí các buổi lecture và tutorial xen kẽ. Trong buổi lecture các bạn sẽ học về lý thuyết, còn trong buổi tutorial các bạn sẽ được trang bị và củng cố các kiến thức nền cần thiết, như là các kiến thức toán hay thậm chí là làm quen với Pytorch (Đây là 1 điểm cộng so với trường mình, khi tất cả mọi thứ mix hết vào với nhau 😢). Slide của các buổi này cũng như là bài tập tất nhiên là cũng được chia sẻ công khai các bạn nhé 😎
Link to the course: https://www.cs.toronto.edu/~rgrosse/courses/csc311_f21/","['#sharing', '#machine_learning']","['khóa', 'học', 'introduction', 'to', 'machine', 'learning', 'đại học', 'toronto', 'hi trường', 'đại học', 'toronto trường', 'nằm', 'top', '1', 'canada', 'top', '30', 'trưòng', 'đại học', 'giới', 'tất xếp hạng', 'uy tín', 'bao', '3', 'bảng', 'xếp hạng', 'danh tiếng', 'giới', 'qs', 'times', 'higher', 'education', 'shanghai', 'ranking', 'tất nhiêu', 'trường', 'flex', '1', 'trường', 'đại học', 'danh tiếng', 'công khai', 'tài liệu', 'khóa học', 'machine', 'learning', 'post', 'khóa', 'học', 'introduction', 'to', 'machine', 'learning', '1', 'khóa học', 'bố trí', 'lecture', 'tutorial', 'xen kẽ', 'lecture', 'học', 'lý thuyết', 'tutorial trang', 'củng cố', 'kiến thức', 'thiết kiến thức', 'toán chí', 'quen pytorch', '1', 'cộng', 'trường', 'tất mix', 'slide tập', 'tất nhiên', 'công khai', 'link', 'to', 'the', 'course', 'https', 'www', 'cs', 'toronto', 'edu', 'rgrosse', 'courses', 'csc311_f21']"
544,"Hi mn ạ, hong biết là trong nhóm mình có ai từng dùng qua chatgpt plus không ạ ?
Có thể cho em xin review với ạ
Chatgpt plus có kiểu charge 1 tháng thôi rồi huỷ rồi charge lại khi cần không mn ơi ?!?
Em cảm ơn mn nhiều ./.
#PY_SHARE #ds_share",['#Q&A'],"['hi mn', 'hong', 'chatgpt', 'plus thể', 'review', 'chatgpt', 'plus', 'kiểu', 'charge', '1', 'hủy', 'charge', 'mn', 'mn']"
545,"Em chào anh Việt, chào mọi người, em là sinh viên vừa tốt nghiệp ra trường chuyên ngành AI. Em đang có nhu cầu tìm kiếm việc làm về mảng AI, AI Engineer hoặc Data Science ở HCM, fresher hay intern (có lương) đều ổn ạ. Giới thiệu qua về em, em tốt nghiệp loại xuất sắc đại học FPT, GPA 9+. Em có kinh nghiệm 6 tháng làm việc ở FPT Software vị trí AI Engineer và là tác giả một bài báo được public tại hội nghị quốc tế. Những kỹ năng em có bao gồm Python, Pytorch, Tensorflow, SQL cơ bản, Git, Docker. Em nắm vững các kiến thức nền tảng về Machine Learning, Deep Learning, các kiến thức về toán xác xuất thống kê, toán rời rạc. Công ty hay anh chị HR nào cảm thấy em phù hợp có thể comment hoặc chấm bài viết em sẽ ib gửi CV ạ, em cảm ơn mọi người.
#dsml_job",['#Q&A'],"['chào', 'việt', 'chào', 'sinh viên', 'nghiệp trường', 'chuyên ngành', 'nhu cầu', 'kiếm', 'mảng', 'engineer', 'data', 'science', 'hcm', 'fresher', 'intern', 'lương ổn', 'giới thiệu nghiệp', 'xuất sắc', 'đại học', 'fpt', 'gpa', '9', 'kinh nghiệm', '6', 'fpt', 'software', 'engineer tác giả', 'báo', 'public', 'hội nghị', 'quốc tế', 'kỹ năng', 'bao', 'python', 'pytorch', 'tensorflow', 'sql', 'git', 'docker', 'nắm', 'vững', 'kiến thức', 'tảng', 'machine', 'learning', 'deep learning', 'kiến thức', 'toán', 'xác', 'xuất', 'thống kê', 'toán', 'rời rạc', 'công ty', 'hr thể', 'comment', 'chấm', 'viết', 'ib', 'gửi', 'cv']"
546,"Probabilistic Machine Learning phiên bản mới 🔥🔥🔥
Hi các bạn,
Đây là 1 trong các đầu sách được sử dụng làm tài liệu tham khảo nhiều nhất trong các khóa học về Machine Learning của rất nhiều trường đại học trên toàn thế giới. Sách được phát hành bởi MIT Press - nhà xuất bản của trường đại học số 1 thế giới về CNTT. 
Hồi 2015, khi mình bắt đầu chương trình học tại TU Munich, ngay kì đầu tiên mình học môn Machine Learning, và đây là 1 trong 3 tài liệu tham khảo mà giáo sư yêu cầu mọi người đọc (Quyển ngoài cùng bên trái, xuất bản năm 2012). Đây là 1 quyển sách rất hay, nhưng đồng thời cũng cực kì khó đọc vì khá hàn lâm 🥹
Năm ngoái thì quyển sách nổi tiếng này đã được tái bản, và được tách ra thành 2 tập: 1 tập cơ bản và 1 tập nâng cao (Có lẽ là để người đọc đỡ tẩu hỏa nhập ma 😂)
Quyển sách này sẽ rất phù hợp cho những bạn nào muốn tìm hiểu về bản chất của các thuật toán trong Machine Learning (tác giả đi vào từng khái niệm cực kì chi tiết). Tuy nhiên như mình nói, quyển này khá khó đọc (Mình không nói về việc Tiếng Anh Tiếng Việt ở đây nhé). Nhưng nếu các bạn có thể đọc được 2 quyển sách phiên bản mới này thì thực sự là rất tuyệt vời 🥰
Link to book 1: https://drive.google.com/file/d/130OwWa0LVgT3QqbhT97ztcXdwwY3_J-4/view?usp=sharing
Link to book 2: https://drive.google.com/file/d/1APnDlRpmmuNg6fnKNd5okZdin4D4ank9/view?usp=sharing","['#sharing', '#machine_learning']","['probabilistic', 'machine', 'learning', 'phiên', 'hi', '1', 'đầu sách', 'tài liệu', 'tham khảo', 'khóa', 'học', 'machine', 'learning', 'trường', 'đại học', 'toàn', 'giới', 'sách', 'phát hành', 'mit', 'press', 'xuất trường', 'đại học', '1', 'giới', 'cntt', 'hồi', '2015', 'chương trình', 'học tu', 'munich kì', 'học', 'môn', 'machine', 'learning', '1', '3', 'tài liệu', 'tham khảo', 'giáo sư', 'đọc', 'quyển', 'trái', 'xuất', '2012', '1', 'quyển', 'sách', 'cực kì', 'đọc', 'hàn lâm ngoái', 'quyển', 'sách', 'nổi tiếng', 'tái tách', 'thành', '2', 'tập', '1', 'tập', '1', 'tập', 'nâng lẽ', 'đọc', 'đỡ', 'tẩu hỏa', 'nhập', 'ma', 'quyển', 'sách', 'chất thuật', 'toán', 'machine', 'learning tác giả', 'đi', 'khái niệm', 'cực kì', 'chi tiết nhiên', 'quyển', 'đọc', 'tiếng', 'tiếng', 'việt thể', 'đọc', '2', 'quyển', 'sách', 'phiên thực', 'tuyệt vời', 'link', 'to', 'book', '1', 'link', 'to', 'book', '2']"
547,"Viết công thức Latex trên Python 🔥🔥🔥
Với thư viện latexify, chúng ta có thể dễ dàng tạo ra các công thức như thể chúng được tạo ra từ Latex 😎
#py_share","['#sharing', '#python']","['viết', 'công thức', 'latex', 'python', 'thư viện', 'latexify', 'ta', 'thể dàng', 'công thức thể', 'latex']"
548,"Em hiện tại muốn học AI để làm việc
Anh chị nào đang làm lĩnh vực AI có kinh nghiệm có kèm không ạ?
Hoặc có ai có thể recommend giúp em trung tâm nào đào tạo AI cho người đã di làm rồi không ạ
Many thanks
#ai_study",['#Q&A'],"['học', 'lĩnh vực', 'kinh nghiệm', 'kèm thể', 'recommend', 'giúp', 'trung tâm', 'đào', 'di many', 'thanks']"
549,"Hello cả nhà, mình hổng phải dân tech, nhưng đang làm vài datavisual tasks trong R code và rAmchart, nhà mình có ai biết đến phần này cho MH tham khảo cách mixed charts (cụ thể là bar + line) với nhé.
Nhân tiện mình rất cám ơn adm đã tạo 1 cộng đồng vô cùng chất lượng và văn minh, đb là adm có tâm và dễ thương qtqd 🥰. Chắc chắn đây là nơi mình học hỏi được rất nhiều khi dần chuyển qua mảng tech.
#ds #datavisualization",['#Q&A'],"['hello', 'hổng', 'dân', 'tech', 'datavisual', 'tasks', 'r', 'code', 'ramchart', 'mh', 'tham khảo', 'mixed', 'charts', 'bar', 'line', 'cám ơn', 'adm', '1', 'cộng đồng', 'vô chất', 'văn minh', 'đb', 'adm', 'tâm thương', 'qtqd', 'chắn', 'học', 'dần', 'mảng', 'tech']"
550,"Chào mọi người,
Em là sinh viên trái ngành có đam mê về khoa học dữ liệu.
Chuyện là em đã học các kiến thức về toán, python, sql, excel, machine learning. Em muốn làm 1 số projects và anh Việt Nguyễn có up trong group. Nhưng em muốn hỏi là quy trình như thế nào để làm projects cho chuẩn ạ?
#py_study #ml_study #ds_study #ds_ml",['#Q&A'],"['chào', 'sinh viên', 'trái', 'ngành', 'đam mê', 'khoa học liệu', 'học', 'kiến thức', 'toán', 'python', 'sql', 'excel', 'machine', 'learning', '1', 'projects', 'việt', 'nguyễn up group', 'quy trình', 'projects', 'chuẩn']"
551,"Chào anh Việt và mọi người, hiện em đang là sv năm 2 ngành Data Science và em đang có dự định học tiếp thạc sĩ ngành DS & AI ở đại học kĩ thuật Munich. Bởi vì đại học Munich được xếp hàng khá cao nên em không biết đầu vào khó như thế nào. Nếu có ai đã từng đi giống em có thể tư vấn giúp em cần chuẩn bị hồ sơ nào được không ?
Hiện giờ em đã có được IELTS 7.0 và testAS. Xin cảm ơn mọi người
P/S
Thật sự em rất vui vì anh Việt đã tạo ra 1 group về ML xịn xò và văn minh cho người Việt. Mỗi ngày đều có điều bổ ích để xem.
#ds_ml_study",['#Q&A'],"['chào', 'việt', 'hiện', 'sv', '2', 'ngành', 'data science', 'dự định', 'học', 'tiếp', 'thạc sĩ', 'ngành', 'ds', 'đại học kĩ thuật', 'munich', 'đại học', 'munich xếp', 'hàng đầu', 'đi thể', 'tư vấn', 'giúp', 'chuẩn', 'hồ sơ', 'hiện', 'ielts', '7', '0', 'testas', 'p', 's', 'vui việt', '1', 'group', 'ml', 'xịn', 'xò', 'văn minh', 'việt', 'bổ ích']"
552,"Xin chào mọi người!
Cá nhân em thấy là những câu này khá đông các bạn cmt nhưng vẫn chưa được giải đáp và còn nhiều băn khoăn. Và mong có thể nhận được câu trả lời từ những người tiền bối đi trước để được học hỏi và rút kinh nghiệm.
1. Em thấy trên nhóm mặc dù có nhiều bạn có CV khá sáng và đẹp nhưng vẫn khó xin việc, liệu có phải là nhu cầu ở Việt Nam còn yếu đúng không ạ?
2. Nhu cầu việc làm thì ở giữa các miền có nhiều khác biệt không ạ? Bởi vì truyền miệng về vấn đề miền Nam có nhiều cơ hội cho những bạn intern hoặc kinh nghiệm yếu hơn em cũng thấy khá nhiều.
3. Vậy nếu các bạn theo đuổi mảng này từ đầu mà vẫn khó khăn trong xin việc vậy thì các bạn tay ngang liệu có cơ hội để mạo hiểm không ạ. Hay vẫn nên làm những job về Web dev hay tương tự trước để lấy kinh nghiệm bẻ dần sang ạ?
4. Vậy nếu như mà ngôn ngữ là cần thiết để có cơ hội thì nên học ngôn ngữ nào ngoài Tiếng Anh và tối thiểu là nên đạt được mức nào ạ?
Em xin làm phiền và cảm ơn mọi người ạ!
#ds_ml_share #ds_ml_job #other",['#Q&A'],"['chào', 'câu', 'đông', 'cmt', 'giải đáp', 'băn khoăn', 'mong thể', 'câu', 'tiền bối', 'đi', 'học', 'rút', 'kinh nghiệm', '1', 'mặc', 'cv', 'đẹp liệu', 'nhu cầu', 'việt nam', 'yếu', '2', 'nhu cầu', 'miền', 'biệt', 'truyền miệng', 'miền', 'nam', 'hội intern', 'kinh nghiệm', 'yếu', '3', 'đuổi', 'mảng', 'đầu', 'khăn', 'ngang liệu', 'hội mạo hiểm', 'job', 'web', 'dev', 'tương kinh nghiệm', 'bẻ', 'dần', '4', 'ngôn ngữ', 'thiết hội học', 'ngôn ngữ', 'tiếng', 'tối thiểu', 'phiền']"
553,"Em chào mọi người, em đang tìm hiểu về mô hình YOLOX và em có đọc các bài báo, các tài liệu liên quan để tìm hiểu về những ưu điểm, nhược điểm, sự tiến bộ, source code, ... nhưng em thấy thông tin về mô hình này khá ít (trên paperswithcode thì em chỉ tìm được 2 bài liên quan), mọi người có thể cho em xin thêm thông tin hay paper về mô hình này được không ạ.
Em cám ơn!
#dl_cv_share","['#Q&A', '#deep_learning']","['chào', 'mô hình', 'yolox', 'đọc', 'báo', 'tài liệu', 'ưu nhược tiến', 'source', 'code', 'thông', 'mô hình', 'paperswithcode', '2', 'thể', 'thông paper', 'mô hình', 'cám ơn']"
554,"Em đang làm bài tập về senmatic similarity detection. dataset của em là similarity - string 1 - string 2, với similarity là 0 và 1 ạ.
Câu hỏi của em là:
+ em muốn hỏi rank1, rank5, rank10, mAP, recall là gì ạ (các tham số này thường được dùng khi so sánh với các model khác trong nhiều dataset ở paper research ạ)
+ làm sao để em tính được các chỉ số trên trong bài toán của em ạ
Em cũng đã thử research với bài viết: https://medium.com/@pavan.mksolution/deep-learning-literature-rank-1-rank-5-accuracies-22cb649be6b6
Nhưng em vẫn chưa hiểu ạ. Nếu được giải thích bằng các ví dụ thực tế thì tuyệt vời ạ.
Em cũng có một vấn đề nữa ạ:
- Em không hiểu được biểu đồ về precision, accuracy và recall. Em đã có research định nghĩa về chúng qua bài viết: https://www.evidentlyai.com/classification-metrics/accuracy-precision-recall
- Nhưng nếu mọi người có các graph ví dụ về precision, accuracy và recall thì tuyệt vời ạ. Em cũng có tham khảo graph về chúng qua link youtube:
https://www.youtube.com/watch?v=oqXDdxF_Wuw&t=334s&ab_channel=Roboflow
Nhưng em không hiểu trục hoành của họ là gì trong graph về precision, recall và cách họ hợp nó thành graph mAP ;-;
#Rank1
#Accuracy
#mean average precision
#precision
#Recall","['#Q&A', '#machine_learning']","['tập', 'senmatic', 'similarity', 'detection', 'dataset', 'similarity', 'string', '1', 'string', '2', 'similarity', '0', '1', 'rank1', 'rank5', 'rank10', 'map', 'recall', 'tham sánh', 'model', 'dataset', 'paper', 'research toán', 'thử', 'research', 'viết', 'giải', 'ví dụ', 'tuyệt vời', 'biểu đồ', 'precision', 'accuracy', 'recall', 'research định nghĩa', 'viết', 'graph', 'ví dụ', 'precision', 'accuracy recall', 'tuyệt vời', 'tham khảo', 'graph', 'link', 'youtube', 'trục', 'hoành graph', 'precision', 'recall', 'hợp thành', 'graph', 'map', 'average', 'precision']"
555,"Chào mọi người. em mới vào nhóm. Em mới mua con RTX 3060. Em đang thực hiện phát hiện đối tượng bằng YOLOv8, nhưng mà khi chạy trên local thì hiệu suất ăn vào GPU chỉ đc có 50-60%, và tốc độ nhận diện real-time không được cao, mọi người có thể gợi ý keyword hay bài biết cụ thể hướng dẫn cài đặt Cuda, GPU như thế nào để có thể tăng được hiệu suất không ạ. Em cảm ơn mn.
#gpu #py_study","['#Q&A', '#deep_learning']","['chào', 'mua', 'rtx', '3060', 'phát hiện', 'đối tượng', 'yolov8', 'chạy', 'local', 'hiệu suất', 'gpu', 'đc', '5060', 'tốc độ', 'diện', 'realtime thể', 'gợi', 'keyword hướng', 'cài', 'cuda', 'gpu thể', 'hiệu suất', 'mn']"
556,"Udacity đang offer 50k suất học bổng, anh em nào có hứng thú thì tham gia challenges để được chọn vào vòng trong nhé:
https://www.udacity.com/scholarships/bertelsmann-next-generation-tech-booster
#scholarship",['#sharing'],"['udacity', 'offer', '50', 'k suất', 'học bổng', 'hứng thú', 'tham gia', 'challenges', 'vòng']"
557,"#other
Em chào mọi người ạ. Em viết bài này cũng tính hỏi anh Việt và những ai có kinh nghiệm về du học tại Đức ạ.
Em đang là sinh viên năm 3, có mong muốn được du học tại Đức với chuyên ngành Toán ạ nhưng kinh nghiệm rồi chuẩn bị ra sao em còn chưa biết phải như thế nào.
Câu hỏi có hơi ngoài lề của nhóm và có thể sai sót trong ngôn từ mong mọi người bỏ qua, mong được mọi người hỗ trợ ạ. Em cám ơn ạ. Cám ơn anh Việt đã duyệt bài ạ.",['#Q&A'],"['chào', 'viết', 'việt', 'kinh nghiệm', 'du học', 'đức', 'sinh viên', '3', 'mong', 'du học', 'đức', 'chuyên ngành', 'toán', 'kinh nghiệm', 'chuẩn hơi', 'lề thể', 'sai sót ngôn mong', 'mong', 'cám ơn', 'cám ơn', 'việt', 'duyệt']"
558,"Tiếp theo bài viết về các nguồn học data (https://www.facebook.com/groups/dsmlvietnam/permalink/317146967732098/?mibextid=zDhOQc), mình xin có 1 vài chia sẻ tổng quát về phương pháp học tập cho các công việc về data tới các anh/chị/em/bạn bè trong nhóm.
Cũng giống như việc học tập trong nhiều môn học hay lĩnh vực khác, việc học có những nguyên tắc cơ bản sau đây mà nếu không tuân thủ thì với một người bình thường sẽ rất khó có thể đạt được kết quả tốt:
Nguyên tắc quan trọng nhất – Hiểu rõ lí do và động lực học tập của bản thân: Nếu đã qua giai đoạn cha mẹ, thày cô bảo học gì thì học nấy thì thường ta chỉ học tập được thực sự tốt nếu như có một động lực học tập đủ lớn. Khi ta hiểu vì sao ta cần học một thứ gì đó và việc học tập nó sẽ giúp ta như thế nào, thì ta sẽ rất muốn học, và khi đó tự khắc sẽ tìm được ra cách để học tập tốt. Việc này tuy quan trọng nhưng lại rất khó, và không phải ai cũng làm được ngay từ đầu. Vừa học vừa tìm kiếm động lực học tập là chuyện bình thường. Ngoài ra, năng lực tư duy và trải nghiệm của cá nhân bạn cũng sẽ được xây dựng và hình thành theo thời gian, nên lí do, động lực của bạn cũng sẽ thay đổi, và điều đó cũng là bình thường. Tuy nhiên ta phải luôn ghi nhớ nguyên tắc này và thường xuyên suy nghĩ và ghi nhớ về lí do và động lực học tập của bản thân mình.
—> Lời khuyên: Bạn nên thường xuyên tự vấn (self reflection) và tích cực học hỏi từ những người có nhiều kinh nghiệm sống và làm việc. Ngoài ra, bạn có thể tham khảo cả các dịch vụ của những tổ chức, chuyên gia khai vấn để có thêm trợ giúp trong việc tìm hiểu về bản thân mình.
Nguyên tắc 2 – Đặt mục tiêu và lên kế hoạch học tập: Cũng giống như bất kỳ công việc gì, để đạt được kết quả tốt nhất với nguồn lực và thời gian hữu hạn thì ta cần đặt mục tiêu rõ ràng và đi kèm với đó là một kế hoạch học tập, làm việc có khoa học. Mục tiêu và kế hoạch có thể thay đổi sau một thời gian khi ta hiểu rõ hơn về chủ đề đang học cũng như hiểu rõ hơn về chính bản thân mình (ưu, nhược điểm trong việc học, hình thức học phù hợp, …). Điều này là hết sức bình thường. Mục tiêu rõ ràng chứng tỏ ta đã tìm hiểu đủ kĩ và biết mình cần học gì. Kế hoạch khoa học và phù hợp giúp ta có các đầu việc và mốc thời gian cụ thể để dễ dàng thực hiện theo nhằm đạt được mục tiêu đã đề ra.
—> Lời khuyên: Luôn đặt mục tiêu học tập, lên kế hoạch học tập và cố gắng tuân thủ theo kế hoạch đã đề ra. Thay đổi mục tiêu, kế hoạch khi cần thiết. Bạn hãy tham khảo nguyên tắc SMART trong đặt mục tiêu (https://www.atlassian.com/blog/productivity/how-to-write-smart-goals) và tìm hiểu về các công cụ và kĩ thuật liên quan tới lập kế hoạch và quản lý công việc. Bạn cũng nên tìm hiểu tổng quan về ngành data và các cơ hội nghề nghiệp trong ngành. Thiếu kiến thức này thì rất khó để xác định mục tiêu cho bản thân.
Nguyên tắc 3 – Chọn nguồn học tốt và có ít nhất từ 2 nguồn học trở lên cho cùng một vấn đề đang cần tìm hiểu: Việc lựa chọn nguồn học tốt (sách chuẩn, thày cô có trình độ, …) giúp đảm bảo kiến thức nạp vào có độ chính xác cao và được diễn giải một cách dễ hiểu. Việc có nhiều nguồn học cho cùng 1 vấn đề giúp ta hiểu vấn đề nhanh hơn, đặc biệt là với các vấn đề trừu tượng hay phức tạp, do được tiếp xúc với nhiều cách giải thích, nhiều hình thức học khác nhau (đọc chữ, xem hình ảnh hoặc video minh hoạ, …). Bên cạnh đó, ta có thể so sánh, đối chiếu các nguồn học với nhau để đảm bảo kiến thức được nạp vào là chính xác, đặc biệt là với các chủ đề mà nguồn học đề cập đến không đủ kĩ.
—> Lời khuyên: Với mỗi vấn đề, chủ điểm kiến thức lớn cần tìm hiểu, nên có 1 nguồn học chính và ít nhất 1 nguồn học nữa để bổ sung thêm
Nguyên tắc 4 – Kỉ luật một cách có khoa học: Dù động lực học tập lớn đến đâu thì nhiều khi ta cũng khó có thể duy trì việc học tập liên tục với năng suất cao trong một thời gian dài do bản chất con người là lười biếng, và do việc hưởng thụ (ăn uống, vui chơi, du lịch, …) nói chung đem lại sự sung sướng nhất thời rất mạnh và có sức cám dỗ cao hơn so với việc học. Vì vậy, để học tập tốt và duy trì được trong một thời gian dài thì duy trì kỉ luật với bản thân là vô cùng quan trọng. Kỉ luật nên được hiểu là những quy tắc, quy định mà ta bắt buộc phải tuân theo, tuy nhiên chúng phải được đặt ra một cách có khoa học và phù hợp với bản thân và bối cảnh cuộc sống của mỗi người.
Ví dụ về kỉ luật thiếu tính khoa học: một sinh viên đại học đặt ra quy tắc là mỗi ngày đều dậy sớm từ 4h sáng và dành ít nhất 3 tiếng để học Machine Learning (từ 4h – 7h)  do nghe nói rằng người thành công là người dậy sớm, và quyết tâm áp dụng triệt để nguyên tắc đó trong 3 ngày liên tiếp và rồi ngủ nướng trong 2 ngày tiếp theo, và cuối cùng là không chịu được và phải từ bỏ nguyên tắc đã đề ra. Nguyên tắc này không áp dụng được do bạn sinh viên đã không để ý đến nhịp sinh học của mình (đang quen thức khuya đến 12h để chat với người yêu) và thực hiện chuyển đổi quá gấp, không để ý đến việc khả năng tập trung của bản thân cao nhất vào thời điểm nào (sáng sớm hay tối muộn) và trong không gian, điều kiện nào (sáng dậy sớm nhưng uể oải học trên giường không hiệu quả bằng chiều ra cafe tự học, hoặc học online cùng 1 vài người bạn để có người hỏi khi có chỗ không hiểu, ….
Ví dụ về kỉ luật có tính khoa học: A là một Data Analyst ngày đi làm 8 tiếng tại văn phòng, tối về cơ thể mệt mỏi, A thường xuyên nằm trên giường lướt tiktok để giải trí và sau đó là ngủ thiếp đi. A rất muốn dành thêm thời gian đọc cuốn Storytelling with Data của Cole Nussbaumer Knaflic và đã mua nó rồi nhưng không tìm đâu ra thời gian, cuối cùng cuốn sách cứ nằm mãi trên giá. A suy nghĩ kĩ và tìm ra giải pháp, đó là mua một chiếc Kindle cũ giá hơn 1 triệu VND và 3 tối mỗi tuần, thay vì lướt tiktok thì A nằm trên giường và đọc sách trên Kindle. Cho dù một số biểu đồ, hình ảnh trong sách khi hiển thị trên Kindle không được tốt bằng máy tính, phương pháp này vẫn giúp A tránh được sự trì hoãn và hoàn tất cuốn sách trong vòng 2 tháng với chi phí đầu vào bỏ ra chỉ có 1 triệu VND, nhưng tiết kiệm được rất nhiều chi phí cơ hội khác. Tuy nhiên A cũng hiểu rằng việc tối đi làm về mình quá mệt mỏi không muốn ra khỏi giường cũng có thể là dấu hiệu của sức khoẻ tổng quát của bản thân không tốt, và A lên kế hoạch để bắt đầu rèn luyện thể dục thể thao.
—> Lời khuyên: Hãy dành thêm thời gian để tìm hiểu về bản thân mình (ưu, nhược điểm, tính cách, nhịp sinh học, …) và tìm hiểu về các phương pháp giúp tăng mức độ tập trung, nâng cao năng suất trong việc học (nên học giờ nào, bằng phương tiện gì, phương pháp đọc nhanh, cách ghi chép và tổ chức notes, cách để giảm bớt sự trì hoãn, làm sao để ngủ ít hơn mà vẫn tỉnh táo, …). Mỗi người sẽ có bộ phương pháp và các thủ thuật của riêng mình, không có một hay một bộ giải pháp nào phù hợp cho tất cả mọi người cả.
Nguyên tắc 5 – Ghi chép, tổng hợp và khái quát hoá kiến thức: Việc chi chép kiến thức (take note) giúp kích hoạt não bộ của ta và giúp ta ghi nhớ kiến thức tốt hơn. Việc tổng hợp kiến thức và viết lại bằng chính ngôn từ của mình giúp ta thực sự hiểu được kiến thức do người khác giảng dạy và biến nó thành của bản thân mình. Việc khái quát hoá kiến thức giúp ta hiểu sâu về bản chất của kiến thức hơn, từ đó có thể đem đi áp dụng trong nhiều tình huống, lĩnh vực khác nhau.
—> Lời khuyên: hãy tìm hiểu và thử nghiệm các phương pháp ghi chép (vd: https://www.oxfordlearning.com/5-effective-note-taking-methods/), các phương pháp tổ chức, lưu trữ và tổng hợp kiến thức (vd: sử dụng mindmap, sử dụng Notion.so, …), và luôn tìm cách hiểu và ghi nhớ bản chất của bất cứ vấn đề nào bạn học, thay vì cố gắng nhớ hết tất cả các chi tiết.
Nguyên tắc 6 – Học phải đi đôi với hành: Tuy đây là một nguyên tắc xưa như trái đất nhưng nó chưa bao giờ sai! Lý thuyết mà không đi kèm với thực hành thì không thể được chuyển hoá thành kĩ năng, và cũng khó mà ghi nhớ lâu được. Ngoài ra, thực tiễn là thước đo tốt nhất cho lý thuyết, để kiếm chứng xem ta nắm lý thuyết có vững không, hay thậm chí là lý thuyết, kiến thức ta học được, kể cả từ các nguồn uy tín, có thực sự chính xác hay không.
—> Lời khuyên: Nếu có thể, hãy lựa chọn những nguồn học có bài tập thực hành đi kèm. Một trong những cách thực hành tốt đó là tự đặt ra các project để thực hiện (tốt nhất nên tham khảo các project về data trên mạng để làm theo hoặc để lấy ý tưởng) với tính thực tiễn cao rồi tra cứu và học thêm kiến thức trong quá trình làm project. Cách thực hành này tốt do nó mô phỏng việc học trong thực tế công việc (learning ơn job) và nếu có người hướng dẫn hoặc có bài mẫu, bài hướng dẫn thì việc học sẽ càng hiệu quả hơn.
Ngoài những nguyên tắc nêu trên, trong quá trình học tập để phục vụ cho các công việc về data, những người mới bắt đầu nên lưu ý tránh một số sai lầm sau:
Sai lầm 1: Cho rằng chỉ cần có stackoverflow và ChatGPT là có thể code thoải mái, không cần học coding quá kĩ làm gì. Với người mới, sách , các khoá học chất lượng, learning on job, thường xuyên làm các project cá nhân và ghi chú, tổng hợp kiến thức sẽ giúp các bạn nắm vững kiến thức căn bản mà vẫn học được ở một tốc độ đủ nhanh. Dựa quá nhiều vào stackoverflow hay ChatGPT sẽ khiến bạn lười đọc những tài liệu chính thống, lười đọc lỗi và debug, và không thuộc các syntax căn bản. Những điều này sẽ làm giảm sense về coding của bạn cũng như khiến bạn không tìm hiểu về các good practice trong lập trình, khiến bạn khó phát triển về sau.
Sai lầm 2: Cho rằng kĩ năng phân tích, sự nhạy cảm với số liệu mới là quan trọng, còn technical skills như SQL, Python, … chỉ thuần tuý là các công cụ hỗ trợ. Sai lầm này thường đến từ những người đã/đang/sẽ làm Data Analyst hay các vị trí phân tích dữ liệu tương tự. Hãy coi các ngôn ngữ lập trình và truy vấn dữ liệu, các công cụ xử lý dữ liệu là những công cụ căn bản giúp bạn tiếp xúc và làm việc với dữ liệu, nếu không sử dụng thành thạo chúng thì tốc độ truy vấn và xử lý dữ liệu của bạn sẽ chậm và bạn sẽ mất quá nhiều thời gian và trí lực vào việc tìm cách sử dụng công cụ, dẫn tới không còn đủ nguồn lực dành cho tư duy phân tích. Ngoài ra, hầu hết người mới bắt đầu đều không thể ngay lập tức có nhạy cảm dữ liệu tốt được, mà phải trải qua quá trình làm việc với dữ liệu và mắc nhiều sai lầm mới có thể hình thành sự nhạy cảm đó được. Chính vì vậy, coi thường các công cụ hỗ trợ sẽ khiến bạn đánh mất cơ hội phát triển sự nhạy cảm với số liệu của bản thân mà sẽ chỉ hiểu các con số ở mức độ hời hợt mà thôi. Ngay cả với những người làm business, để có được nhạy cảm về các con số, chỉ tiêu kinh doanh, vận hành của doanh nghiệp thì họ cũng phải trải qua những thời gian dài làm việc với dữ liệu, và rất nhiều lần phải tự mình chuẩn bị, phân tích, xào nấu dữ liệu.
Sai lầm 3: Tập trung quá nhiều vào học các kĩ năng technical. Sai lầm này thường đến từ những người đã/đang/sẽ làm Data Engineer hay các vị trí đòi hỏi hàm lượng kỹ thuật lớn khác. Khi mới bắt đầu, nếu không có kĩ năng technical tốt thì bạn sẽ không có việc, và nếu có việc thì cũng khó đáp ứng được yêu cầu của công việc. Tuy nhiên, trong thực tế công việc Data Engineer hay các vị trí nhiều technical khác thì những việc khó nhất lại thường là hiểu các yêu cầu nghiệp vụ của các đơn vị kinh doanh, vận hành trong và ngoài tổ chức để từ đó đua ra được giải pháp kỹ thuật tối ưu. Không như các vấn đề kỹ thuật, các vấn đề về nghiệp vụ của doanh nghiệp thường ít khi được ghi chép lại trong sách hay các tài liệu chính thống mà ta dễ dàng tìm thấy trên mạng hay thậm chí là trong các trường đại học. Vì vậy, để một người làm tốt được một công việc data nặng về kĩ thuật, thực ra người đó phải có bộ kĩ năng giao tiếp, làm việc nhóm tốt và khả năng nắm bắt được các kiến thức và quy trình nghiệp vụ nhanh chóng, bên cạnh nền tảng kỹ thuật tốt.
Sai lầm 4: Thiếu đầu tư vào kĩ năng truyền đạt thông tin, kĩ năng thuyết trình. Sai lầm này có thể đến từ bất cứ ai, nhưng ở đây ta sẽ ví dụ đối với một người đã/đang/sẽ làm Data Scientist hoặc những vị trí làm việc nhiều và sâu về các thuật toán Machine Learning (ML). Một sai lầm thường gặp phải đối với những người mới bắt đầu ở vị trí này là việc tập trung quá nhiều vào học và hiểu các thuật toán và các khía cạnh về toán có liên quan mà không lưu ý rèn kĩ năng truyền đạt thông tin, cả dưới dạng viết lẫn dạng nói. Điều này khiến cho Data Scientist khó giao tiếp với những người không có kiến thức và kinh nghiệm về ML, dù người đó làm vị trí về data hay thuộc phía business (đơn vị kinh doanh), vì Data Scientist không biết diễn đạt các kiến thức ML, toán bằng ngôn ngữ đời thường, dễ hiểu, đúng trọng tâm để các đồng nghiệp khác có thể hiểu được. Ngoài ra, việc diễn đạt kém, thiếu gãy gọn, xúc tích trong một số trường hợp cũng thể hiện Data Scientist chưa thực nắm rõ chuyên môn của mình, vì vậy không diễn đạt chính xác và tường mình được các vấn đề trừu tượng, phức tạp. Khi bạn có thể giải thích một mảng kiến thức nào đó về ML cho một người chưa biết gì về ML hiểu được và giúp họ trò chuyện với bạn một cách thoải mái được thì khi đó bạn có thể tự tin rằng mình đã làm chủ được kiến thức.
Mình có nhận sửa CV miễn phí cho người mới bắt đầu và người còn ít kinh nghiệm trong các công việc về data. Mời các anh/chị/em/bạn bè ghé chơi https://datatute.vn để đăng ký sửa CV miễn phí và cả học data miễn phí, cũng như đón đọc các bài viết tiếp theo chia sẻ về kinh nghiệm, thủ thuật về việc học, việc làm nhé.",['#sharing'],"['tiếp', 'viết', 'học', 'data', '1', 'tổng quát', 'phương pháp', 'học tập', 'công data', 'bè', 'học tập', 'môn học', 'lĩnh vực', 'học', 'nguyên tắc', 'tuân thủ', 'bình thể', 'kết nguyên tắc lí', 'động lực', 'học tập', 'thân', 'giai đoạn', 'mẹ', 'thày', 'bảo học', 'học', 'ta', 'học tập', 'thực động lực', 'học tập', 'ta', 'ta', 'học', 'học tập', 'giúp', 'ta', 'ta', 'học khắc', 'học tập', 'đầu', 'học', 'kiếm', 'động lực', 'học tập', 'bình năng lực', 'tư trải nghiệm', 'xây dựng', 'hình thành', 'lí động lực', 'bình nhiên', 'ta', 'ghi', 'nguyên tắc', 'xuyên', 'suy', 'ghi lí', 'động lực', 'học tập', 'thân khuyên', 'xuyên vấn', 'self', 'reflection', 'tích cực', 'học', 'kinh nghiệm', 'sống thể', 'tham khảo', 'dịch vụ', 'tổ chức', 'chuyên gia', 'khai vấn', 'trợ giúp', 'thân', 'nguyên tắc', '2', 'mục tiêu', 'kế hoạch', 'học tập', 'công', 'kết lực', 'hữu hạn', 'ta', 'mục tiêu', 'ràng', 'đi', 'kèm', 'kế hoạch', 'học tập', 'khoa học', 'mục tiêu', 'kế hoạch thể', 'ta', 'chủ đề', 'học thân', 'ưu nhược học', 'hình thức', 'học', 'sức', 'bình', 'mục tiêu', 'ràng', 'chứng tỏ', 'ta', 'kĩ học', 'kế hoạch', 'khoa học', 'giúp', 'ta', 'đầu', 'mốc dàng', 'mục tiêu đề', 'khuyên', 'mục tiêu', 'học tập', 'kế hoạch', 'học tập', 'cố gắng', 'tuân thủ', 'kế hoạch', 'đề', 'mục tiêu', 'kế hoạch thiết', 'tham khảo', 'nguyên tắc', 'smart', 'mục tiêu', 'công cụ', 'kĩ thuật', 'lập', 'kế hoạch', 'quản lý', 'công', 'tổng quan', 'ngành', 'data hội', 'nghề nghiệp', 'ngành', 'kiến thức', 'xác định', 'mục tiêu', 'thân', 'nguyên tắc', '3', 'học', '2', 'học', 'trở lựa', 'học', 'sách', 'chuẩn thày', 'trình độ', 'giúp', 'kiến thức', 'nạp độ', 'xác diễn', 'giải học', '1', 'giúp', 'ta', 'trừu tượng', 'phức tạp', 'tiếp xúc', 'giải', 'hình thức', 'học', 'đọc', 'chữ', 'hình ảnh', 'video minh', 'họa', 'cạnh', 'ta thể', 'sánh', 'đối chiếu', 'học', 'kiến thức', 'nạp', 'xác', 'chủ đề học', 'đề cập', 'kĩ khuyên', 'chủ', 'kiến thức', '1', 'học', '1', 'học', 'bổ sung', 'nguyên tắc', '4', 'kỉ luật', 'khoa học', 'động lực', 'học tập', 'ta', 'thể trì', 'học tập', 'liên tục', 'năng suất', 'chất', 'lười biếng', 'hưởng thụ', 'uống', 'vui', 'du lịch', 'đem', 'sung sướng', 'thời sức', 'cám dỗ', 'học', 'học tập', 'trì trì kỉ', 'luật thân', 'vô kỉ', 'luật', 'quy tắc', 'quy định', 'ta', 'bắt buộc', 'tuân nhiên', 'khoa học', 'thân bối cảnh', 'sống', 'ví dụ', 'kỉ luật', 'khoa học sinh viên', 'đại học', 'quy tắc', 'dậy', '4', 'h', '3', 'tiếng', 'học', 'machine', 'learning', '4', 'h', '7', 'h', 'thành công', 'dậy', 'quyết tâm', 'áp dụng', 'triệt nguyên tắc', '3', 'liên tiếp', 'ngủ', 'nướng', '2', 'tiếp', 'nguyên tắc', 'đề nguyên tắc', 'áp dụng', 'sinh viên', 'nhịp', 'sinh học', 'quen thức', 'khuya', '12', 'h', 'chat', 'yêu', 'đổi', 'gấp', 'khả năng', 'thân tối', 'muộn gian', 'kiện', 'dậy', 'uể', 'oải', 'học', 'giường hiệu', 'chiều', 'cafe', 'học', 'học', 'online', '1', 'chỗ', 'ví dụ', 'kỉ luật', 'khoa học', 'a data', 'analyst', 'đi', '8', 'tiếng', 'văn phòng', 'tối thể', 'mệt mỏi', 'a', 'xuyên', 'nằm', 'giường', 'lướt tiktok', 'giải trí', 'ngủ thiếp', 'đi', 'a', 'đọc', 'storytelling', 'with', 'data', 'cole', 'nussbaumer', 'knaflic', 'mua', 'sách', 'nằm', 'mãi', 'giá', 'a suy kĩ', 'giải pháp', 'mua', 'kindle', 'cũ', 'giá', '1', 'triệu', 'vnd', '3', 'tối', 'tuần', 'thay', 'lướt', 'tiktok a', 'nằm', 'giường', 'đọc', 'sách', 'kindle biểu đồ', 'hình ảnh', 'sách', 'hiển thị', 'kindle', 'máy', 'phương pháp', 'giúp', 'a trì hoãn', 'hoàn tất', 'sách', 'vòng', '2', 'chi phí', 'đầu', '1', 'triệu', 'vnd', 'tiết kiệm', 'chi phí', 'hội nhiên', 'a tối', 'đi', 'mệt mỏi', 'giường thể', 'dấu hiệu', 'sức', 'khỏe', 'tổng quát thân', 'a', 'kế hoạch', 'rèn luyện', 'thể dục', 'thể thao', 'khuyên thân', 'ưu nhược nhịp', 'sinh học', 'phương pháp', 'giúp', 'độ', 'nâng', 'năng suất', 'học', 'học', 'phương tiện', 'phương pháp', 'đọc', 'ghi chép', 'tổ chức', 'notes', 'bớt', 'trì hoãn', 'ngủ', 'tỉnh táo', 'phương pháp', 'thủ thuật', 'giải pháp', 'tất nguyên tắc', '5', 'ghi chép', 'tổng hợp', 'khái quát', 'hóa', 'kiến thức', 'chi chép', 'kiến thức', 'take', 'note', 'giúp', 'kích hoạt não', 'ta', 'giúp', 'ta', 'ghi', 'kiến thức', 'tổng hợp', 'kiến thức', 'viết ngôn', 'giúp', 'ta', 'thực kiến thức', 'giảng dạy', 'biến', 'thành', 'thân', 'khái quát', 'hóa', 'kiến thức', 'giúp', 'ta', 'sâu chất', 'kiến thức thể', 'đem', 'đi', 'áp dụng', 'tình huống', 'lĩnh vực', 'khuyên', 'thử nghiệm', 'phương pháp', 'ghi chép', 'vd', 'https', 'www', 'oxfordlearning', 'com', '5', 'effectivenotetakingmethods', 'phương pháp', 'tổ chức', 'lưu trữ', 'tổng hợp', 'kiến thức', 'vd', 'mindmap', 'ghi', 'chất học', 'thay', 'cố gắng', 'tất', 'chi tiết', 'nguyên tắc', '6', 'học', 'đi đôi', 'hành', 'nguyên tắc', 'xưa', 'trái đất', 'sai', 'lý thuyết', 'đi', 'kèm', 'thực hành thể', 'hóa thành', 'kĩ năng', 'ghi', 'thực tiễn', 'thước đo', 'lý thuyết', 'kiếm chứng', 'ta', 'nắm', 'lý thuyết', 'vững chí', 'lý thuyết', 'kiến thức', 'ta', 'học', 'uy tín', 'thực xác', 'khuyên thể', 'lựa', 'học tập', 'thực hành', 'đi', 'kèm', 'thực hành', 'project', 'tham khảo', 'project', 'data mạng', 'tưởng', 'thực tiễn tra', 'cứu học', 'kiến thức', 'trình', 'project', 'thực hành', 'mô', 'học', 'công', 'learning ơn', 'job', 'hướng', 'mẫu', 'hướng', 'học hiệu', 'nguyên tắc', 'nêu', 'trình', 'học tập', 'phục vụ', 'công data', 'lưu', 'sai lầm', 'sai lầm', '1', 'stackoverflow', 'chatgpt thể', 'code', 'thoải mái', 'học', 'coding', 'kĩ sách', 'khóa học', 'chất', 'learning', 'on', 'job', 'xuyên', 'project', 'ghi', 'tổng hợp', 'kiến thức', 'giúp', 'nắm', 'vững', 'kiến thức', 'học', 'tốc độ', 'dựa', 'stackoverflow', 'chatgpt lười', 'đọc', 'tài liệu', 'thống lười', 'đọc', 'lỗi', 'debug', 'syntax', 'sense', 'coding', 'good', 'practice', 'lập trình', 'phát triển', 'sai lầm', '2', 'kĩ năng', 'phân tích', 'nhạy cảm liệu', 'technical', 'skills', 'sql', 'python', 'túy', 'công cụ', 'sai lầm', 'data', 'analyst', 'phân tích liệu', 'tương coi', 'ngôn ngữ', 'lập trình', 'truy vấn liệu', 'công cụ', 'liệu', 'công cụ', 'giúp', 'tiếp xúc liệu', 'thành thạo', 'tốc độ', 'truy vấn liệu', 'chậm', 'trí lực', 'công cụ', 'lực tư', 'phân tích thể', 'lập tức', 'nhạy cảm liệu', 'trải', 'trình liệu', 'mắc', 'sai lầm thể', 'hình thành', 'nhạy cảm', 'coi', 'công cụ', 'đánh hội', 'phát triển', 'nhạy cảm liệu', 'thân độ', 'hời hợt', 'business', 'nhạy cảm tiêu', 'kinh doanh', 'vận hành', 'doanh nghiệp', 'trải liệu', 'chuẩn', 'phân tích', 'xào', 'nấu liệu', 'sai lầm', '3', 'học', 'kĩ năng', 'technical', 'sai lầm', 'data', 'engineer', 'đòi', 'hàm', 'kỹ thuật', 'kĩ năng', 'technical', 'đáp ứng', 'công nhiên', 'công data', 'engineer', 'technical', 'nghiệp vụ', 'kinh doanh', 'vận hành', 'tổ chức', 'đua', 'giải pháp', 'kỹ thuật', 'tối ưu', 'kỹ thuật', 'nghiệp vụ', 'doanh nghiệp', 'ghi chép', 'sách', 'tài liệu', 'thống', 'ta dàng', 'mạng', 'chí trường', 'đại học', 'công data', 'kĩ thuật', 'thực kĩ năng', 'giao tiếp', 'khả năng', 'nắm bắt', 'kiến thức', 'quy trình', 'nghiệp vụ', 'chóng', 'cạnh tảng', 'kỹ thuật', 'sai lầm', '4', 'đầu tư', 'kĩ năng', 'truyền thông', 'kĩ năng', 'thuyết trình', 'sai lầm thể', 'ta', 'ví dụ', 'đối data', 'scientist', 'sâu thuật', 'toán', 'machine', 'learning', 'ml', 'sai lầm', 'đối học', 'thuật toán', 'khía cạnh', 'toán', 'lưu rèn', 'kĩ năng', 'truyền thông', 'dạng', 'viết', 'lẫn', 'dạng', 'data', 'scientist', 'giao tiếp', 'kiến thức', 'kinh nghiệm', 'ml data', 'business', 'kinh doanh', 'data', 'scientist diễn', 'kiến thức', 'ml toán', 'ngôn ngữ', 'đời', 'trọng tâm', 'đồng nghiệp thể', 'diễn kém', 'gãy gọn', 'xúc tích', 'trường hợp', 'thể hiện', 'data', 'scientist', 'thực nắm', 'chuyên môn', 'diễn xác', 'tường', 'trừu tượng', 'phức tạp thể', 'giải mảng', 'kiến thức', 'ml', 'ml', 'giúp', 'trò', 'thoải mái thể', 'chủ', 'kiến thức', 'sửa', 'cv', 'miễn phí', 'kinh nghiệm', 'công data', 'mời', 'bè', 'ghé', 'đăng ký', 'sửa', 'cv', 'miễn phí', 'học', 'data', 'miễn phí', 'đón', 'đọc', 'viết', 'tiếp', 'kinh nghiệm', 'thủ thuật', 'học']"
559,"Roadmap cho các bạn theo đuổi mảng Data Science/Machine Learning 🔥🔥🔥
Các bạn ơi, hồi trước mình đã từng làm 1 video về Roadmap for Data Scientist (https://youtu.be/dXODkwN6ovo)  Nhưng xem video thì mất time quá. Mình xin tóm tắt lại ở đây. Đây là lộ  trình bản thân mình đã áp dụng, và mình không có copy từ đâu cả, nên  các bạn có thể tham khảo. Có 1 điểm chú ý, ở các bước các bạn có thể tìm  tài liệu mà các bạn thấy phù hợp nhất với mình. Trong video mình có  chia sẻ nguồn học cho từng bước, nhưng nghĩ lại thì thấy, mỗi người 1  background, rồi khả năng ngoại ngữ cũng khác nhau nữa, nên chưa chắc tài  liệu mình thấy hay đã phù hợp với các bạn 😅.
Bước 1: Ôn lại kiến thức Toán ở 4 mảng sau: Xác suất, thống kê (2 mảng này cần cho Data Science), đại số tuyến tính, giải tích (2 mảng này cần cho ML/DL). Bước này khó và khô khan nhưng đừng bỏ qua  các bạn nhé. Không là sau này chúng ta xây nhà từ nóc đó 🥹
Bước 2: Các bạn nên học lập trình Python cơ bản,  để đến lúc học về DS/ML, các bạn có thể practice được. Lúc đầu học thì  đừng lạm dụng thư viện hay framework nhé. Sau khi quen với Python rồi  thì các bạn hãy tìm hiểu và làm quen với các thư viện và framework quan  trọng, như là Numpy, Pandas, Matplotlib, ...
Bước  3: Ở bước này các bạn có thể học Data Science và Machine Learning song  song. Ở bước này để practice các bạn sẽ sử dụng thư viện Scikit-learn  các bạn nhé. IMPORTANT THING: Các bạn không nhất  thết phải tự xây dựng được các mdoel from scratch. Nhưng chí ít các bạn  cũng phải biết là mỗi 1 hàm các bạn gọi, có cái gì xảy ra bên trong/task  được thực hiện như thế nào. Cách để biết các bạn đã học đạt tiêu chuẩn  chưa: Sau khi hoàn thành 1 project hoàn chỉnh, các bạn có thể chỉ tay  ngẫu nhiên vào 1 dòng code bất kì, nếu các bạn giải thích được dòng này  làm gì, nếu không có nó/nếu dùng hàm khác thì chuyện gì xảy ra. Vậy là  đạt yêu cầu. 1 điều quan trọng nữa là, hãy tập sửa lỗi, vá lỗi nếu trong  quá trình code có phát sinh trục trặc gì (các bạn có thể Google hay hỏi  ChatGPT). Tuyệt đối không hỏi hay nhờ người khác sửa hộ, trừ khi các  bạn đã nỗ lực hết sức rồi mà vẫn không fix được (Sau này đi làm thậm chí  các bạn còn phải sửa code của đồng nghiệp hay người khác đó. Sửa code  của bản thân vẫn còn là quá đơn giản). Bước này là bước nền tảng,các bạn  đừng đốt cháy giai đoạn nhé. Đừng đặt mục tiêu là sau 3 hay 6 tháng  phải xong. Bản thân mình tổng thời gian dành cho học phần này là tầm 2  năm
Bước 4: Giờ đến phần hot của AI: Deep Learning.  Giờ Deep Learing là trend rồi nên các vị trí các bạn apply, kiểu gì  người ta cũng yêu cầu kiến thức về Deep Learning, và thực sự thì Deep  Learing cũng rất là thú vị. Các bạn sau khi nắm chắc kiến thức về  Machine Learning rồi thì có thể học tiếp lên Deep Learning. Trong DL có 2  mảng ứng dụng lớn là Computer Vision (thị giác máy tính) và NLP (Xử lý ngôn ngữ tự nhiên). Các bạn khi bắt đầu học về DL sẽ lần lượt  được làm quen với các bài toán cơ bản của cả 2 mảng này (Image/Document  classification problems) Sau đó các bạn có thể chọn 1 hướng và đi sâu  vào. Học 2 hướng đồng thời sẽ rất là khó khăn và tốn time, nên các bạn  cân nhắc nhé. Các bạn lúc bắt đầu cứ nắm chắc các bài toán cơ bản, đừng  có nhảy sớm vào mấy model cao siêu kiểu BERT, RNN, LSTM, OCR, GAN.  Những mô hình này sau này chúng ta chủ yếu xài project có sẵn thôi,  nhảy vào chúng sớm không có tác dụng nhiều trong tích luỹ kiến thức.
Note: Có 2 điều vô cùng quan trọng mình đúc kết được trong quá trình học và làm về AI/Data Science/Machine Learning:
Hãy  chỉ dùng đến ML/DL nếu các phương pháp tính toán thông thuờng không thể  áp dụng được (e.g. Tính tiền phải trả dựa trên lượng điện tiêu thụ: If  elif else là đủ rồi, không cần phải vác ML vào. Đừng đem dao mổ trâu đi  giết gà nhé)
AI  nghĩa là trí tuệ nhân tạo chứ không phải trí tuệ siêu phàm hay trí tuệ  siêu nhiên. Có nghĩa là AI giúp máy móc có thể giải quyết được những  công việc con người có thể làm đuợc với độ chính xác cao hơn, đáng tin  cậy hơn. Điều đấy không có nghĩa là AI có thể làm được mọi thứ. Mình rất  hay nhận được 2 loại câu hỏi, 1 là AI có thể làm được việc abcxyz hay  không. Câu trả lời rất đơn giản: Con người làm được (dù không tốt) thì  AI sẽ làm được. Loại câu hỏi thứ 2 là để xây dựng được 1 mô hình abcxyz  thì phải làm gì? Các bạn có thể thử tự hỏi bản thân xem, nếu giờ huấn  luyện con người làm task đó thì cần phải chuẩn bị những tài liệu gì để  huấn luyện cho người đó, thì model Ai cũng cần dữ liệu tương tự
Roadmap  trên ít nhất đã có 2 chuột bạch đi trước là mình và em trai mình, nên  các bạn không lo bị lôi ra làm vật thí nghiệm nha. Hi vọng những chia sẻ  của mình có ích cho các bạn. Try your best, God will do the rest 🥰🥰🥰",['#sharing'],"['roadmap', 'đuổi', 'mảng', 'data', 'science', 'machine', 'learning', 'hồi', '1', 'video', 'roadmap', 'for', 'data', 'scientist', 'video', 'time', 'tóm tắt', 'lộ trình', 'thân', 'áp dụng', 'copy thể', 'tham khảo', '1', 'thể', 'tài liệu', 'video học', '1', 'background', 'khả năng', 'ngoại ngữ', 'tài liệu', '1', 'ôn kiến thức', 'toán', '4', 'mảng', 'xác suất', 'thống kê', '2', 'mảng', 'data', 'science', 'đại tuyến', 'giải tích', '2', 'mảng', 'ml', 'dl', 'khô khan', 'đừng', 'ta', 'xây', '2', 'học', 'lập trình', 'python', 'học', 'ds', 'ml thể', 'practice', 'đầu', 'học', 'đừng', 'lạm dụng', 'thư viện', 'framework', 'quen', 'python', 'quen', 'thư viện', 'framework', 'numpy', 'pandas', 'matplotlib', '3', 'thể', 'học', 'data', 'science', 'machine', 'learning', 'song song', 'practice', 'thư viện', 'scikitlearn', 'important', 'thing thết', 'xây dựng', 'mdoel', 'from', 'scratch chí', '1', 'hàm', 'gọi', 'xảy', 'task', 'học', 'tiêu chuẩn', 'hoàn thành', '1', 'project', 'hoàn chỉnh thể', 'ngẫu nhiên', '1', 'dòng', 'code', 'giải', 'dòng', 'hàm xảy', '1', 'tập', 'sửa', 'lỗi', 'vá', 'lỗi trình', 'code', 'phát sinh', 'trục trặc thể', 'google chatgpt', 'tuyệt đối', 'sửa', 'hộ trừ', 'nỗ lực', 'sức fix', 'đi chí', 'sửa', 'code', 'đồng nghiệp', 'sửa', 'code thân', 'đơn giản tảng', 'đừng', 'đốt', 'cháy', 'giai đoạn', 'đừng', 'mục tiêu', '3', '6', 'xong', 'thân', 'tổng học', 'tầm', '2', '4', 'hot', 'deep', 'learning', 'deep', 'learing', 'trend', 'apply', 'kiểu', 'ta', 'kiến thức', 'deep', 'learning', 'thực deep', 'learing', 'thú vị', 'nắm', 'kiến thức', 'machine', 'learning thể', 'học', 'tiếp', 'deep', 'learning', 'dl', '2', 'mảng', 'ứng dụng', 'computer', 'vision', 'thị giác', 'máy nlp', 'ngôn ngữ nhiên', 'học', 'dl', 'lượt', 'quen toán', '2', 'mảng', 'image', 'document', 'classification', 'problems thể', '1', 'hướng', 'đi sâu', 'học', '2', 'hướng', 'khăn', 'tốn', 'time', 'cân nhắc', 'nắm toán', 'đừng', 'nhảy', 'mấy', 'model', 'siêu', 'kiểu', 'bert', 'rnn', 'lstm', 'ocr', 'gan', 'mô hình', 'ta', 'chủ yếu', 'xài', 'project', 'sẵn', 'nhảy', 'tác dụng', 'tích lũy', 'kiến thức', 'note', '2', 'vô đúc', 'kết trình', 'học', 'data', 'science', 'machine', 'learning', 'ml', 'dl', 'phương pháp toán', 'thông thường thể', 'áp dụng', 'e g', 'tiền', 'dựa', 'điện', 'tiêu thụ', 'if', 'elif', 'else vác', 'ml', 'đừng', 'đem', 'dao mổ', 'trâu', 'đi', 'giết', 'gà', 'nghĩa trí tuệ', 'nhân trí tuệ', 'siêu phàm', 'trí tuệ', 'siêu nhiên', 'nghĩa', 'giúp', 'máy móc thể', 'giải quyết', 'công thể', 'được', 'độ', 'xác cậy', 'đấy', 'nghĩa thể', '2', '1', 'thể', 'abcxyz', 'câu', 'đơn giản', '2', 'xây dựng', '1', 'mô hình', 'abcxyz thể', 'thử thân', 'huấn luyện', 'task', 'chuẩn', 'tài liệu', 'huấn luyện', 'model liệu', 'tương roadmap', '2', 'chuột bạch', 'đi', 'trai', 'lo', 'lôi vật', 'thí nghiệm', 'nha', 'hi vọng ích', 'try', 'your', 'best', 'god', 'will', 'the', 'rest']"
560,"Data exploration trong Python với 3 thư viện: Numpy, Pandas và Matplotlib 🔥🔥🔥
Đây là 1 cheatsheet khá thú vị, được soạn theo phong cách 1 trang dài (chiều ngang thì bình thường nhưng chiều dài bằng 10 trang thông thường). Trong Cheatsheet này chúng ta sẽ được tổng hợp các kiến thức về Data exploration cần thiết cho các Data Scientist, bao gồm 11 chủ đề sau:
Làm sao để đọc dữ liệu?
Làm sao để biến đổi dữ liệu sang các kiểu khác nhau?
Làm sao để hoán đổi dữ liệu?
Làm sao để sắp xếp dữ liệu?
Làm sao để trực quan hóa dữ liệu với các plots khác nhau?
Làm sao để tạo bảng tần suất?
Làm sao để lấy mẫu dữ liệu?
Làm sao để xóa dữ liệu trùng lặp?
Làm sao để nhóm/gộp dữ liệu?
Làm sao để xử lý missing values và outliers?
Làm sao để gộp dữ liệu 1 cách hiệu quả?
Link pdf: https://drive.google.com/file/d/1ZzZ3KPWBgqgMVlrPE-jRxWI2uprAqYe3/view?usp=sharing
#py_share","['#sharing', '#python', '#data']","['data', 'exploration', 'python', '3', 'thư viện', 'numpy', 'pandas', 'matplotlib', '1', 'cheatsheet', 'thú vị', 'soạn phong', '1', 'trang', 'chiều', 'ngang', 'bình', 'chiều', '10', 'trang', 'thông cheatsheet', 'ta', 'tổng hợp', 'kiến thức', 'data', 'exploration thiết', 'data', 'scientist', 'bao', '11', 'chủ đề', 'đọc liệu', 'biến đổi liệu', 'kiểu', 'hoán đổi liệu', 'xếp liệu', 'trực quan', 'hóa liệu', 'plots', 'bảng', 'tần suất', 'mẫu liệu', 'xóa liệu', 'trùng lặp', 'gộp liệu', 'missing', 'values', 'outliers', 'gộp liệu', '1', 'hiệu', 'link', 'pdf']"
561,"em đang nguyên cứu về thanh toán online sử dụng faceid giống facepay ở GS25. Thì nhận diện khuôn mặt dựa trên phần cứng của camera hay là cam chỉ truyền hình ảnh về để server xử lí và nhận kết quả mọi người. Mọi người cho em hướng đi với ạ. Em mới tập tành tìm hiểu. Cám ơn mọi người nhiều.
#hoidappython","['#Q&A', '#cv']","['nguyên', 'cứu toán', 'online', 'faceid', 'facepay', 'gs25 diện', 'khuôn mặt', 'dựa', 'cứng', 'camera', 'cam truyền', 'hình ảnh', 'server', 'xử lí', 'kết hướng', 'đi', 'tập tành', 'cám ơn']"
562,"Chào mọi người, theo em hiểu thì tham số average=""weight"" trong các hàm tính f1 score, precision, hay recall là nó sẽ tính độ chính xác trên từng lớp rồi trung bình cộng lại. Vậy nó có ổn khi sử dụng để đánh giá mô hình nhận diện gian lận thẻ tín dụng( Vì theo em nghĩ việc nhận diện 1 giao dịch gian lận là quan trọng hơn)
# ML","['#Q&A', '#machine_learning']","['chào', 'tham average', 'weight', 'hàm f1', 'score', 'precision', 'recall độ', 'xác', 'lớp', 'trung bình', 'cộng ổn', 'mô hình', 'diện', 'gian lận', 'thẻ tín dụng', 'diện', '1', 'giao dịch', 'gian lận', 'ml']"
563,"Faker - tạo dữ liệu fake 1 cách nhanh chóng và đơn giản 🔥🔥🔥
Trong quá trình lập trình, đôi khi chúng ta muốn tạo ra 1 sample data chỉ nhằm mục đích test nhanh 1 hàm hay 1 chức năng nào đó. Faker sẽ giúp điều này trở nên đơn giản hơn bao giờ hết 😎 Các bạn có thể fake bất kì thứ gì: Số, chuỗi, địa chỉ, tên, ngày tháng. Tóm lại là anything 💪
Link: https://github.com/joke2k/faker
#py_share","['#sharing', '#data']","['faker liệu', 'fake', '1', 'chóng', 'đơn giản trình', 'lập trình', 'đôi', 'ta', '1', 'sample', 'data', 'mục đích', 'test', '1', 'hàm', '1', 'chức năng', 'faker', 'giúp', 'trở', 'đơn giản thể', 'fake chuỗi', 'địa tóm', 'anything', 'link']"
564,"Cho em xin cách fix với ạ . Em cảm ơn ạ
#xx_code","['#Q&A', '#python']",['fix']
565,"chào mọi người. em mới vào nhóm. Chuyện là e mới sắm con RTX 3060. e cài conda + win10 để setup môi trường. nhưng e k tài nào setup được tensor cho quả GPU này. e đã cài cuda, cudnn,.. các gói liên quan.
tf báo là có thấy GPU nhưng nó lại không nhận vào. thành ra bh training nó ăn vào CPU. thấy tội nó quá.
mong các bác giúp ạ.",['#Q&A'],"['chào', 'e sắm', 'rtx', '3060', 'e cài', 'conda', 'win10 setup', 'môi trường', 'e k', 'tài setup', 'tensor', 'gpu e', 'cài', 'cuda', 'cudnn gói', 'tf', 'báo', 'gpu', 'thành', 'bh', 'training', 'cpu tội', 'mong', 'giúp']"
566,"Em xin chia sẻ với mọi người project machine learning đầu tiên của mình ạ.
Project xây dựng model hồi quy để tính GDP của Việt Nam dựa trên các chỉ số mà em nghĩ sẽ ảnh hưởng đến nó.
Dữ liệu lấy từ website tổng cục thống kê Việt Nam (Dữ liệu tải từ web trong folder WEB_DATA, dữ liệu đã xuất thành file CSV trong folder TRAIN_MODEL_DATA)
Em build và so sánh performance của 3 mô hình hồi quy là SVR, Ridge và Linear Regression. Đã bỏ qua tổng thiệt hại thiên tai từ input dataset vì correlation với GDP khá thấp. Dùng RMSE và RMSPE để đánh giá model.
Kết quả cho thấy model Linear Regression cho kết quả tốt nhất.(Khi X có cả thiệt hại thiên tai thì nó vẫn tốt nhất. Do vậy em thử bỏ thiên tai ra thì model tiếp tục giảm sai số hơn trước.)
Trên đây là tóm tắt của em về project vừa làm ạ.
Em xin góp ý, đề xuất cải thiện từ mọi người ạ. Em xin cảm ơn.
https://github.com/Buu2004/VIETNAM_GDP_MODEL/tree/main","['#sharing', '#machine_learning']","['project', 'machine', 'learning', 'project', 'xây dựng', 'model', 'hồi', 'quy gdp', 'việt nam', 'dựa', 'ảnh hưởng liệu', 'website', 'tổng cục', 'thống kê', 'việt nam', 'liệu tải', 'web', 'folder', 'web_data liệu', 'xuất', 'thành', 'file', 'csv', 'folder', 'train_model_data', 'build', 'sánh', 'performance', '3', 'mô hình', 'hồi', 'quy svr', 'ridge', 'linear', 'regression', 'tổng', 'thiệt hại', 'thiên tai', 'input', 'dataset', 'correlation', 'gdp', 'rmse', 'rmspe', 'model', 'kết', 'model', 'linear', 'regression kết', 'x', 'thiệt hại', 'thiên tai', 'thử', 'thiên tai', 'model', 'sai', 'tóm tắt', 'project góp', 'đề xuất', 'cải thiện']"
567,"Mọi người ơi cho em hỏi về ML , e có tập dữ liệu về lung cancer , có các thuộc tính 'GENDER', 'AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY','PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',
'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',
'SWALLOWING DIFFICULTY', 'CHEST PAIN', 'LUNG_CANCER'
Em muốn dùng bài toán phân lớp để huấn luyện mô hình, cho e hỏi là e có nên bỏ thuộc tính nào không quan trọng ạ, e mới học nên mong mọi người chỉ ạ, e cảm ơn.","['#Q&A', '#data']","['ml', 'e', 'tập liệu', 'lung cancer', 'gender', 'age', 'smoking', 'yellow_fingers', 'anxiety', 'peer_pressure', 'chronic', 'disease', 'fatigue', 'allergy', 'wheezing', 'alcohol', 'consuming', 'coughing', 'shortness', 'of breath', 'swallowing', 'difficulty', 'chest', 'pain', 'lung_cancer toán', 'phân lớp', 'huấn luyện', 'mô hình', 'e e', 'e học', 'mong', 'e']"
568,Dạ hiện tại em đang gặp trường hợp khi dùng pretrained weight cho MobileNetV2 với weight='imagenet' trên Google Colab thì gặp lỗi http 404. Em không biết nên khắc phục như thế nào ạ.,"['#Q&A', '#deep_learning']","['trường hợp', 'pretrained', 'weight', 'mobilenetv2', 'weight', 'imagenet', 'google', 'colab', 'lỗi', 'http', '404', 'khắc phục']"
569,"Hơn 650 dataset dành cho Machine Learning 🔥🔥🔥
UCI Machine Learning Repository là tập hợp của hơn 650 dataset mà các bạn có thể dùng để xây dựng các Machine Learning project. Cá nhân mình thì thấy có 1 vài bộ dataset mà dữ liệu nhìn hơi bị pha ke 😅 Nhưng dù sao đây cũng là 1 trong các nguồn dataset nổi tiếng nhất. Các bạn có thể tham khảo và chọn ra những bộ dataset ưng ý dành cho riêng mình 😁
Link: https://archive.ics.uci.edu/datasets
#ml_dataset","['#sharing', '#data', '#machine_learning']","['650', 'dataset', 'machine', 'learning', 'uci', 'machine', 'learning', 'repository', 'tập hợp', '650', 'dataset thể', 'xây dựng', 'machine', 'learning', 'project', '1', 'dataset liệu', 'hơi', 'pha', 'ke', '1', 'dataset', 'nổi tiếng thể', 'tham khảo', 'dataset', 'ưng', 'link']"
570,"Chào mọi người, em là AI Engineer đang muốn học thêm về mảng data/business để củng cố kiến thức cho việc start-up sau này. Các anh chị có recommend những kiến thức em cần học để thực hiện được mục tiêu này không ạ?",['#Q&A'],"['chào', 'engineer', 'học', 'mảng', 'data', 'business', 'củng cố', 'kiến thức', 'startup recommend', 'kiến thức', 'học', 'mục tiêu']"
571,"Khoá học Data Science for Beginners hoàn toàn miễn phí của Microsoft 🔥🔥🔥
Hôm nay mình xin chia sẻ Khoá học về Data Science của Microsoft. Khóa học này bao gồm 20 lesson, với mỗi lesson có cả tài liệu dạng text và video. Các chủ đề mà khoá học này cover bao gồm:
Giới thiệu về Data Science
Xác suất thống kê cho Data Science
Xử lý dữ liệu
Trực quan hoá dữ liệu
Vòng đời của 1 project về Data Science
Data Science với Cloud
2 chủ đề cuối khá là thú vị, vì chúng ít được đề cập đến trong các khoá học về Data Science khác ☺️. Khóa học đưọc thiết kế và giảng dạy bởi chính các kĩ sư đang làm việc tại Microsoft. Vậy là chúng ta đã tiếp cận với hầu hết các khoá học của các ông lớn rồi nhé 😎

Link: https://github.com/microsoft/Data-Science-For-Beginners",['#sharing'],"['khóa', 'học', 'data', 'science', 'for', 'beginners', 'miễn phí', 'microsoft', 'hôm', 'khóa', 'học', 'data', 'science', 'microsoft', 'khóa', 'học', 'bao', '20', 'lesson', 'lesson', 'tài liệu', 'dạng', 'text', 'video', 'chủ đề', 'khóa', 'học', 'cover', 'bao', 'giới thiệu', 'data', 'science', 'xác suất', 'thống kê', 'data', 'science liệu', 'trực quan', 'hóa liệu', 'vòng', 'đời', '1', 'project', 'data', 'science', 'data', 'science', 'cloud', '2', 'chủ đề', 'thú vị', 'đề cập', 'khóa', 'học', 'data', 'science', 'khóa học', 'được', 'thiết kế', 'giảng dạy', 'kĩ sư', 'microsoft', 'ta', 'tiếp cận', 'khóa', 'học', 'link']"
572,"Dạ em chào mọi người ạ,
Em có một vấn đề là hiện tại em đang có một dataset cho bài toán tumor segmentation bao gồm 3 folder chính là CTScan, và Liver_mask, Tumor_mask cho CTScan đó. Nhưng vấn đề là sau khi lọc các CT Scan không có tumor thì số lượng slice còn lại quá ít (>100) nên hiện tại em đang không biết data augmentation như thế nào hay dùng transfer learning để dùng UNet như thế nào ạ?
Em cảm ơn anh Việt và mọi người đã giúp em.
#cv_code","['#Q&A', '#data', '#deep_learning']","['chào', 'dataset toán', 'tumor', 'segmentation', 'bao', '3', 'folder', 'ctscan', 'liver_mask', 'tumor_mask', 'ctscan', 'lọc', 'ct', 'scan', 'tumor', 'slice', '100', 'data', 'augmentation', 'transfer', 'learning', 'unet', 'việt', 'giúp']"
573,"Sách Machine Learning cơ bản của anh Vũ Hữu Tiệp 🔥🔥🔥
Mình mới đọc comment của 1 bạn trong group hôm qua thì mới chợt nhớ ra là mình quên mất quyển sách kinh điển này của anh Tiệp. Đúng là sai sót lớn 🥲 Đã học AI ở VN thì 10 người chắc phải 9 người biết đến quyển sách này. Mình thì không học theo quyển này, không phải là vì nó không hay mà là vì khi mình biết đến nó thì mình đã học xong rồi. 1 tài liệu vô cùng tuyệt vời các bạn nha 🥰🥰🥰

Link: https://github.com/tiepvupsu/ebookMLCB",['#sharing'],"['sách', 'machine', 'learning vũ hữu tiệp', 'đọc', 'comment', '1', 'group', 'hôm', 'quên', 'quyển', 'sách', 'kinh điển', 'tiệp', 'sai sót', 'học', 'vn', '10', '9', 'quyển', 'sách', 'học', 'quyển', 'học', 'xong', '1', 'tài liệu', 'vô', 'tuyệt vời', 'nha', 'link']"
574,"Vì sao chúng ta không thấy Grid Search trong các framework về Deep Learning ? 🔥🔥🔥
Lại chuyên mục mỗi ngày 1 câu hỏi các bạn nhé 😎 Một bạn học viên của mình mới hỏi, mình thấy rất hay nên bê lên đây luôn để mọi người thảo luận 😁
Hầu hết các bạn học DS/ML thì cũng không còn xa lạ gì với class GridSearchCV của Scikit-learn. Class này sẽ giúp chúng ta dễ dàng tìm ra được 1 tổ hợp các hyperparameter tốt nhất cho model của chúng ta. Công việc của chúng ta chỉ là định nghĩa ra các giá trị cho mỗi 1 hyperparameter, sau đó GridSearch sẽ làm nốt phần việc còn lại. Vô cùng tuyệt vời 🥰
Vậy câu hỏi của mình ở đây là, vì sao 1 chức năng tốt và mạnh mẽ như vậy lại không được đem vào các framework về Deep Learning như là Pytorch, Tensorflow, Keras? Chẳng phải nếu có, chúng ta sẽ dễ dàng tìm được tổ hợp tối ưu cho các hyperparameter, như là batch size, learning rate, momentum, ... hay sao?
Các bạn thử giải thích lý do vì sao nhé 😉","['#Q&A', '#python']","['ta', 'grid', 'search', 'framework', 'deep', 'learning', 'chuyên mục', '1', 'học viên', 'bê', 'thảo luận', 'học', 'ds', 'ml', 'lạ', 'class', 'gridsearchcv', 'scikitlearn', 'class', 'giúp', 'ta dàng', '1', 'tổ hợp', 'hyperparameter', 'model', 'ta', 'công', 'ta', 'định nghĩa', '1', 'hyperparameter', 'gridsearch', 'nốt', 'vô', 'tuyệt vời', '1', 'chức năng mẽ', 'đem', 'framework', 'deep', 'learning', 'pytorch', 'tensorflow', 'keras', 'ta dàng', 'tổ hợp', 'tối ưu hyperparameter', 'batch', 'size', 'learning', 'rate', 'momentum', 'thử', 'giải lý']"
575,"Em xin chào mọi người, em có tình cờ xem được vài trang quyển sách Getting started with Google Bert khá hay nhưng kiếm trên mạng thì không thấy. Có ai có file sách hoặc nguồn tải sách không ạ? Em xin cảm ơn.",['#Q&A'],"['chào', 'tình cờ', 'trang', 'quyển', 'sách', 'getting', 'started', 'with', 'google', 'bert', 'kiếm', 'mạng', 'file', 'sách', 'tải', 'sách']"
576,"Các Newsletter tốt nhất về AI 🔥🔥🔥
Dành cho các bạn muốn đảm bảo rằng mình luôn được cập nhật các thông tin, xu hướng mới nhất về AI, dưới đây là 6 Newsletter phổ biến nhất về AI/Deep Learning (1 khi các bạn đăng kí ở các Newsletter này thì mỗi tuần người ta sẽ gửi vào email cho các bạn tổng hợp những gì mới và nổi bật nhất về AI trong 7 ngày vừa rồi):
The Batch (https://www.deeplearning.ai/the-batch/): Đây là Newsletter đến từ deeplearning.ai. Newsletter này sẽ tóm tắt các sự kiện nôi bật nhất về AI trong tuần, dưới dạng các báo cáo giản lược và dễ đọc
True Positive Weekly (https://aiweekly.substack.com/): Tổng hợp những tin tức và bài báo về AI và Machine Learning quan trọng nhất trong tuần
Hugging Face (https://huggingface.curated.co/): Các updates mới nhất về NLP 
Paper with code (https://paperswithcode.com/newsletter/): Tổng hợp các xu hướng mới nhất về các bài báo về Machine Learning, cùng với code, thư viện cũng như các dataset
Import AI (https://importai.substack.com/): Newsletter này chuyên về AI, dựa trên các phân tích chi tiết về các nghiên cứu mới nhất.
Các bạn không cần thiết phải đăng kí tất cả các Newsletter trên. Các bạn có thể đọc thử 1 vài bài từ mỗi Newsletter, rồi từ đó chọn 1-2 Newsletter mà các bạn cảm thấy hợp với mình nhất. Điều này sẽ giúp các bạn luôn được cập nhất với các xu hướng cũng như thông tin mới nhất về AI mà không cần tốn quá nhiều công sức 😎",['#sharing'],"['newsletter', 'cập nhật', 'thông', 'xu hướng', '6', 'newsletter', 'phổ biến', 'deep', 'learning', '1', 'đăng kí', 'newsletter', 'tuần', 'ta', 'gửi', 'email', 'tổng hợp', 'nổi bật', '7', 'the', 'batch', 'https', 'www', 'thebatch', 'newsletter', 'newsletter tóm', 'tắt', 'kiện', 'nôi', 'bật', 'tuần dạng', 'báo cáo', 'giản lược', 'đọc', 'true', 'positive', 'weekly', 'https', 'aiweekly', 'substack com', 'tổng hợp', 'tức', 'báo', 'machine', 'learning', 'tuần', 'hugging', 'face', 'https', 'huggingface', 'curated', 'co updates', 'nlp', 'paper', 'with', 'code', 'https', 'paperswithcode', 'com newsletter', 'tổng hợp', 'xu hướng', 'báo', 'machine', 'learning', 'code', 'thư viện', 'dataset', 'import', 'https', 'importai', 'substack', 'com', 'newsletter', 'chuyên', 'dựa', 'phân tích', 'chi tiết', 'nghiên cứu thiết', 'đăng kí', 'tất', 'newsletter thể', 'đọc', 'thử', '1', 'newsletter', '12', 'newsletter hợp', 'giúp', 'cập', 'xu hướng', 'thông tốn', 'công sức']"
577,"Em chào mn ạ, em đang tìm hiểu về các model kiểu llama2 với mistral nhưng mà khi e dùng gpu v100 thì nó cho ra câu trả lời chậm tầm 3-4s mới xong và gpu thì chỉ chạy nhẹ nhàng tầm 20-30%. Mn có thể chỉ e cách nào để tận dụng tối đa gpu và cho câu trả lời nhanh nhất được không ạ.
#ml_code","['#Q&A', '#deep_learning']","['chào', 'mn', 'model', 'kiểu', 'llama2', 'mistral', 'e gpu', 'v100', 'câu', 'chậm', 'tầm', '34', 's', 'xong', 'gpu', 'chạy', 'nhẹ nhàng', 'tầm', '2030', 'mn thể', 'e', 'tận dụng', 'tối đa', 'gpu', 'câu']"
578,"Dạ chào achi, e là newbie. Em có train dự đoán tuổi khuôn mặt dùng VGG-16 net thì ra bị như này ạ. Input (224,224,3); Output sử dụng softmax 100 class 1-100 tuổi. Mong achi giải đáp giúp em đồ thị này và hướng giải quyết ạ","['#Q&A', '#deep_learning', '#cv']","['chào', 'achi', 'e newbie', 'train', 'dự đoán', 'khuôn mặt', 'vgg16', 'net', 'input', '224', '224', '3', 'output', 'softmax', '100', 'class', '1100', 'mong', 'achi', 'giải đáp', 'giúp', 'đồ thị', 'hướng', 'giải quyết']"
579,"30 thư viện Python thú vị nhưng ít người biết đến giúp các Data Scientist làm việc hiệu quả hơn 🔥🔥🔥
Có lẽ với các bạn đang học/làm việc trong mảng Data Science, Machine Learning, thì các thư viện như Numpy, Pandas, Matplotlib hay Scikit-Learn không còn xa lạ gì với các bạn. Tuy nhiên có rất nhiều thư viện vô cùng thú vị, hỗ trợ hiệu quả các tasks khác nhau trong Data Science mà chúng ta không biết. Dưới đây là list 30 thư viện như vậy. Mình tóm tắt luôn cho các bạn chức năng của từng thư viện nha 🥰 (Mình đã cài đặt và dùng thử 28/30 thư viện này để viết tóm tắt chứ không phải chỉ ngồi dịch library/framework document từ tiếng Anh sang tiếng Việt đâu 🥹)
YellowBrick: Framework hỗ trợ visualization được xây dựng dựa trên Scikit-learn và matplotlib
PyCaret: Tự động hóa ML workflow, tập trung vào yếu tố tối thiểu hóa và tối giản hóa code
Imbalanced-learn: Thư viện cung cấp các phương pháp over-sampling và under-sampling nhằm xử lý dữ liệu mất cân bằng (Lớp DS/ML nâng cao mình phụ trách cũng sử dụng thư viện này 🥰)
Modin: Thư viện giúp tăng tốc độ xử lý các hàm của Pandas
SHAP: Giải thích kết quả của bất kì mô hình ML nào chỉ với 1 vài dòng code
Missingno: Trực quan hóa các missing values trong dataset của các bạn 1 cách dễ dàng
Prophet - Nhà tiên tri: Giúp xây dựng các mô hình dự đoán cho bài toán time-series forecasting 1 cách đơn giản và hiệu quả
Parallel-Pandas: Tối ưu hóa sử dụng phần cứng thông qua việc thực hiện các hàm Pandas song song, giúp tăng tốc độ xử lý cũng như xử dụng tài nguyên 1 cách hiệu quả
Featuretools: Framework tự động hóa feature engineering
LazyPredict: Thư viện giúp các bạn chạy vài chục mô hình ML chỉ trong tích tắc. Các bạn sẽ có 2 sự lựa chọn, 1 là các mô hình classification, 2 là bài toán regression. Đây cũng là 1 thư viện mình sử dụng trong lớp học DS/ML của mình
mlxtend: Thư viện giúp hỗ trợ xử lý, đánh giá và trực quan hóa các mô hình ML
Vatex: Thư viện tương tự như Pandas nhưng với tốc độ xử lý nhanh hơn rất nhiều
SweetViz: Thư viện tuyệt vời giúp chúng ta generate các EDA (Exploratory Data Analysis) report chỉ với 1 vài dòng code. Cực kì hữu ích cho các data scientist/data analyst
Skorch: Lá bài dung hợp giữa Pytorch và Sklearn: Kết hợp giữa sức mạnh của Pytorch và sự đơn giản của Scikit-learn. Mình đã từng giới thiệu về thư viện này rồi 🥰
Faiss; Cung cấp các thuật toán hiệu quả dành cho bài toán clustering và similarity search. Đây là thư viện được xây dựng bởi Facebook 🥰
Statsmodel: thư viện giúp các bạn thống kê và khám phá dữ liệu 1 cách vô cùng dễ dàng và hiệu quả
Pandas-profiling: Thư viện giúp tạo ra các report hoàn chỉnh để phân tích bất kì dataset nào. Again mình cũng xài thư viện này cho lớp học online của mình 🥰
Streamlit: Tạo website chỉ với 1 vài dòng code
Category-encoder: Hỗ trợ 15 kĩ thuật khác nhau để mã hóa categorical feature. Theo cá nhân mình thì sẽ rất tuyệt vời khi kết hợp với Scikit-learn. Các bạn có thể sử dụng như là biện pháp thay thế cho OneHotEncoder.
DuckDB: Giúp thực hiện các câu truy vấn SQL trên DataFrame (Thật ra Pandas cũng làm được)
PandasML: 1 lá bài dung hợp tiếp theo, khi kết hợp giữa xử lý dữ liệu của Pandas + thuật toán Ml của Scikit-learn + trực quan hóa dữ liệu của Matplotlib. 3 trong 1 easy 🥰
Pytest: Framework giúp test các script python của các bạn 1 cách nhanh chóng và đơn giản
Numexpr: Tối ưu hóa tốc độ các hàm của Numpy bằng việc song song hóa tính toán trên tất cả các core của CPU của bạn 🥰
CSV-kit: Framework giúp chúng ta truy vấn và phân tích các file CSV từ terminal.
PivotTableJS: Công cụ giúp các bạn làm việc với DataFrame bằng việc kéo thả thay vì phải ngồi code. Khá thú vị cho những bạn nào ghét code 🥰
Faker: Thư viện này không giúp các bạn chơi Liên minh huyền thoại nhưng sẽ giúp các bạn generate ra dữ liệu không có thật, nhưng hữu ích cho các task khác nhau
Icecream: Sự thay thế hoàn hảo cho những bạn hay debug bằng câu lệnh print() (Giống mình). Nhanh hơn và thuận tiện hơn rất nhiều so với print()
Pyforest: Thư viện giúp tự động import các thư viện cần thiết. Các bạn không cần phải viết vài chục dòng import ở đầu script nữa 🥰
PySnooper: Giúp các bạn debug và theo dõi các biến 1 cách dễ dàng hơn
Sidetable: Giúp các bạn tổng hợp thông tin về tần suất các giá trị trong dataset. Nhanh và hiệu quả hơn nhiều so với value_counts() của Pandas

Mong rằng bảng tóm tắt ở trên và hình minh họa ở dưới sẽ giúp ích cho các bạn trong quá trình học tập và trở thành 1 Data Scientist giỏi sau này ^_^
Link pdf: https://drive.google.com/file/d/1mVKM48sDxer19ojQBXrVhhcRFMndyB-x/view?usp=sharing","['#sharing', '#python']","['30', 'thư viện', 'python', 'thú vị', 'giúp', 'data', 'scientist', 'hiệu lẽ', 'học', 'mảng', 'data', 'science', 'machine', 'learning', 'thư viện', 'numpy', 'pandas', 'matplotlib', 'scikitlearn', 'lạ nhiên', 'thư viện', 'vô thú vị', 'hiệu', 'tasks', 'data', 'science', 'ta', 'list', '30', 'thư viện', 'tóm tắt', 'chức năng', 'thư viện', 'nha cài', 'thử', '28', '30', 'thư viện', 'viết', 'tóm tắt', 'dịch', 'library', 'framework', 'document', 'tiếng', 'tiếng', 'việt', 'yellowbrick', 'framework', 'visualization', 'xây dựng', 'dựa', 'scikitlearn', 'matplotlib', 'pycaret động', 'hóa', 'ml', 'workflow', 'yếu tố', 'tối thiểu', 'hóa', 'tối giản', 'hóa', 'code', 'imbalancedlearn', 'thư viện', 'cung', 'phương pháp', 'oversampling', 'undersampling liệu', 'cân', 'lớp', 'ds', 'ml', 'nâng', 'phụ trách', 'thư viện', 'modin', 'thư viện', 'giúp', 'tốc độ', 'hàm pandas', 'shap', 'giải kết', 'mô hình', 'ml', '1', 'dòng', 'code', 'missingno', 'trực quan', 'hóa', 'missing', 'values', 'dataset', '1 dàng', 'prophet', 'tiên tri', 'giúp', 'xây dựng', 'mô hình', 'dự đoán', 'toán', 'timeseries', 'forecasting', '1', 'đơn giản hiệu', 'parallelpandas', 'tối ưu hóa', 'cứng', 'thông', 'hàm pandas', 'song song', 'giúp', 'tốc độ', 'xử dụng', 'tài nguyên', '1', 'hiệu', 'featuretools', 'framework động', 'hóa', 'feature', 'engineering', 'lazypredict', 'thư viện', 'giúp', 'chạy', 'chục', 'mô hình', 'ml tích tắc', '2', 'lựa', '1', 'mô hình', 'classification', '2', 'toán', 'regression', '1', 'thư viện', 'lớp học', 'ds', 'ml', 'mlxtend', 'thư viện', 'giúp', 'trực quan', 'hóa', 'mô hình', 'ml', 'vatex', 'thư viện', 'tương pandas', 'tốc độ', 'sweetviz', 'thư viện', 'tuyệt vời', 'giúp', 'ta', 'generate', 'eda', 'exploratory', 'data', 'analysis', 'report', '1', 'dòng', 'code', 'cực kì', 'hữu ích', 'data', 'scientist', 'data', 'analyst', 'skorch', 'lá', 'dung hợp', 'pytorch', 'sklearn', 'kết hợp', 'sức', 'pytorch', 'đơn giản', 'scikitlearn', 'giới thiệu', 'thư viện', 'faiss', 'cung thuật', 'toán', 'hiệu toán', 'clustering', 'similarity', 'search', 'thư viện', 'xây dựng', 'facebook', 'statsmodel', 'thư viện', 'giúp', 'thống kê', 'khám', 'phá liệu', '1', 'vô dàng', 'hiệu', 'pandasprofiling', 'thư viện', 'giúp', 'report', 'hoàn chỉnh', 'phân tích', 'dataset', 'again', 'xài', 'thư viện', 'lớp học', 'online', 'streamlit', 'website', '1', 'dòng', 'code', 'categoryencoder', '15', 'kĩ thuật', 'mã', 'hóa', 'categorical feature', 'tuyệt vời', 'kết hợp', 'scikitlearn thể', 'biện pháp', 'thay', 'onehotencoder', 'duckdb', 'giúp', 'câu', 'truy vấn', 'sql', 'dataframe', 'pandas', 'pandasml', '1', 'lá', 'dung hợp', 'tiếp', 'kết hợp liệu', 'pandas thuật', 'toán', 'ml scikitlearn', 'trực quan', 'hóa liệu', 'matplotlib', '3', '1', 'easy', 'pytest', 'framework', 'giúp', 'test', 'script', 'python', '1', 'chóng', 'đơn giản', 'numexpr', 'tối ưu hóa', 'tốc độ', 'hàm numpy', 'song song', 'hóa toán', 'tất core', 'cpu', 'csvkit', 'framework', 'giúp', 'ta', 'truy vấn', 'phân tích', 'file', 'csv', 'terminal', 'pivottablejs', 'công cụ', 'giúp', 'dataframe', 'kéo', 'thả', 'thay', 'code', 'thú vị', 'ghét', 'code', 'faker', 'thư viện', 'giúp', 'liên minh', 'huyền thoại', 'giúp', 'generate liệu', 'hữu ích', 'task icecream', 'thay', 'hoàn hảo', 'debug', 'câu', 'lệnh', 'print', 'thuận tiện', 'print', 'pyforest', 'thư viện', 'giúp động', 'import', 'thư viện', 'thiết', 'viết', 'chục', 'dòng', 'import', 'đầu', 'script', 'pysnooper', 'giúp', 'debug', 'dõi', 'biến', '1', 'dàng', 'sidetable', 'giúp', 'tổng hợp', 'thông', 'tần suất', 'dataset hiệu', 'value_counts', 'pandas', 'mong', 'bảng tóm', 'tắt', 'hình minh họa', 'giúp ích', 'trình', 'học tập', '1', 'data', 'scientist', 'giỏi', '_', 'link', 'pdf']"
580,"Chào mọi người, em đang tìm kiếm công việc thực tập ở mảng Computer vision và đang chuẩn bị CV. Đây là CV của em, các anh chị kinh nghiệm có thể giúp em chỉnh sửa lại CV, cũng như đưa ra lời khuyên giúp em nên học thêm và chuyên sâu vào mảng nào được không ạ.
PS: em đang là sinh viên năm 3, các link github em không đính kèm trong file, nếu anh chị muốn xem thêm thì em gửi riêng ạ.",['#Q&A'],"['chào', 'kiếm', 'công thực tập', 'mảng', 'computer', 'vision', 'chuẩn', 'cv', 'cv', 'kinh nghiệm thể', 'giúp', 'chỉnh sửa', 'cv', 'khuyên', 'giúp', 'học', 'chuyên sâu', 'mảng', 'ps', 'sinh viên', '3', 'link', 'github', 'đính', 'kèm', 'file', 'gửi']"
581,"Dạ em chào mọi người ạ,
Hiện tại em đang có đề tài là segmentation các khối ung thư cho một dataset gồm các ảnh CT scan. Mọi người cho em hỏi là đối với ảnh CT scan thì trong image segmentation mình nên xem nó là dạng 3D hay 2D ạ, nếu là 3D thì em muốn hỏi cần phải học những gì để làm ạ. Em cảm ơn.","['#Q&A', '#cv']","['chào', 'đề tài', 'segmentation', 'khối', 'ung thư', 'dataset', 'ảnh', 'ct', 'scan', 'đối ảnh', 'ct', 'scan', 'image', 'segmentation', 'dạng', '3', 'd', '2', 'd', '3', 'd', 'học']"
582,"Xin phép admin ạ, mình vừa viết một bài so sánh Yolov8 với RT-DERT trên bộ dữ liệu Aquarium, mong được mọi người ủng hộ ạ.",['#sharing'],"['phép', 'admin', 'viết', 'sánh', 'yolov8', 'rtdert liệu', 'aquarium mong', 'ủng hộ']"
583,Chia sẻ tới các bạn một repo để học cách implement model hiệu quả:,['#sharing'],"['repo', 'học', 'implement', 'model hiệu']"
584,"Xin chào mọi người ạ,
Hôm nay em muốn chia sẻ với mọi người một dự án nhỏ về Retrieval-Augmented Generation. Dự án này ban đầu được sinh ra với mục đích thi thố tại cuộc thi Viettel Hearted AI Challenge. Bài toán là dựa trên corpus các bài viết Wikipedia tiếng Việt được cho trước, xây dựng một giải pháp RAG để giải quyết các câu hỏi mà câu trả lời có thể được tìm thấy trong corpus đó. Tuy không được giải nhưng em thấy rằng thành quả của đội mình cũng thú vị và muốn chia sẻ tới cộng đồng ạ.
Dự án này bao gồm:
Mô hình Llama-2-7b đã được instruct-finetuned với dữ liệu chỉ dẫn chủ yếu thuộc về bài toán hỏi đáp miền đóng tiếng Việt (closed question answering). Mô hình có khả năng đưa ra phản hồi cho một câu hỏi dựa trên nội dung ngữ cảnh kèm theo nó. 
Tích hợp mô hình này vào một pipeline RAG đơn giản.
Thông tin chi tiết về dự án em xin để dưới comment.
Demo dự án:
 — với Bùi Chí Minh.","['#sharing', '#nlp']","['chào', 'hôm', 'dự án', 'retrievalaugmented', 'generation', 'dự án', 'ban đầu', 'sinh', 'mục đích', 'thi', 'thố', 'thi', 'viettel', 'hearted', 'challenge toán', 'dựa', 'corpus', 'viết', 'wikipedia', 'tiếng', 'việt', 'xây dựng', 'giải pháp', 'rag', 'giải quyết', 'câu thể', 'corpus', 'giải', 'thành đội', 'thú vị', 'cộng đồng', 'dự án', 'bao', 'mô hình', 'llama27b', 'instructfinetuned liệu', 'chủ yếu', 'toán đáp', 'miền', 'đóng', 'tiếng', 'việt', 'closed', 'question', 'answering', 'mô hình', 'khả năng', 'phản hồi', 'dựa', 'nội dung', 'ngữ cảnh', 'kèm tích hợp', 'mô hình', 'pipeline', 'rag', 'đơn giản', 'thông', 'chi tiết', 'dự án', 'comment', 'demo', 'dự án', 'bùi chí minh']"
585,"Em chào mọi người ạ, em đang có một bài toán nhỏ về Voice cloning trên Tiếng Việt.
Input là 1 đoạn voice ghi âm lấy từ người dùng
Output muốn có model voice clone từ người dùng input, text to speech một list các câu văn đã được soạn trước.
Không biết có bên nào hay github nào support việc này và hỗ trợ cho Tiếng Việt không ạ. Em cảm ơn mọi người ạ",['#Q&A'],"['chào toán', 'voice', 'cloning', 'tiếng', 'việt', 'input', '1', 'đoạn', 'voice', 'ghi âm', 'output', 'model', 'voice', 'clone', 'input', 'text', 'to', 'speech list', 'câu', 'văn soạn', 'github', 'support', 'tiếng', 'việt']"
586,"em chào mọi người . mọi người đã ai từng sử dụng ""NlpHUST/vi-electra-small"" rồi có thể cho em xin cách load tokenize từ checkpoint này với được không ạ. em load như trong ảnh khi in ra thấy các token đều đang không có dấu. mà trên huggingface thì không có hướng dẫn . em cảm ơn ạ","['#Q&A', '#nlp', '#deep_learning']","['chào', 'nlphust', 'vielectrasmall thể', 'load', 'tokenize', 'checkpoint', 'load', 'ảnh', 'in', 'token', 'dấu', 'huggingface', 'hướng']"
587,"Em chào mn ạ, em đang thử sử dụng RAG với model chat là phogpt-7.5b-instruct của VinAI nhưng em đang bị vướng ở load model trên GGcolab bị crash:( Không biết mn có cách nào load đc ngoài việc dùng bản plus không ạ, em cảm ơn ạ.","['#Q&A', '#nlp', '#deep_learning']","['chào', 'mn', 'thử', 'rag', 'model', 'chat', 'phogpt7', '5', 'binstruct', 'vinai', 'vướng', 'load', 'model', 'ggcolab', 'crash', 'mn', 'load', 'đc', 'plus']"
588,"Mn cho em hỏi case này với, em có train model với 2 input là tôi đi họ sẽ ra học và toi di ho sẽ ra hoc. Nhưng h khi input vào thì e muốn là tôi đi ho cũng sẽ ra học. có cách nào để nó vẫn ra như v mà mình k cần phải training lại model hong ạ ?",['#Q&A'],"['mn', 'case', 'train', 'model', '2', 'input', 'đi', 'học', 'toi', 'di ho', 'hoc h', 'input', 'e', 'đi', 'ho học', 'v', 'k', 'training', 'model', 'hong']"
589,"Chào mọi người

Em đang có dự án cuối kì với tiêu đề là Brain Tumor Segmentation, nhóm có sử dụng thuật toán Fuzzy-Mean để áp dụng phương pháp song song vào để tăng tốc độ tính toán. Để hoàn thành dự án thì em có chọn GMM để loại bỏ phần vỏ não nhưng để xác định được vùng chứa u não thì bọn e vẫn chưa làm được ạ. Mong ac có kinh nghiệm khi xử lí ảnh y tế (dicom) cho e ít kinh nghiệm ạ. E cảm ơn nhiều ạ 😍☺😍☺😍 .
Dự án không được sử dụng Deep Learning ạ.

Ảnh dưới là sau khi dùng GMM ạ.","['#Q&A', '#cv']","['chào', 'dự án', 'kì', 'tiêu đề', 'brain', 'tumor', 'segmentation thuật', 'toán', 'fuzzymean', 'áp dụng', 'phương pháp', 'song song', 'tốc độ', 'toán', 'hoàn thành', 'dự án', 'gmm', 'vỏ', 'não', 'xác định', 'chứa', 'u', 'não', 'bọn', 'e mong', 'ac', 'kinh nghiệm', 'xử lí', 'ảnh', 'y tế', 'dicom e', 'kinh nghiệm', 'e', 'dự án', 'deep', 'learning', 'ảnh', 'gmm']"
590,"Em chào mọi người ạ , em hiện đang làm về task ""key information extraction"" , em có tìm hiểu một số thư viện  trên github và đang thử paddleocr, hiện tại em gặp một số vấn đề về cài đặt môi trường:
em có làm theo document trên github repository nhưng vẫn bị lỗi  ạ (phần 2. training ,lỗi ở link  issue ) 
 em có thử cài đặt trên docker nhưng vẫn không được ạ (lỗi ở hình bên dưới)
 có bác nào rành về paddle hay task kie không  ạ?
cuda:11.8 
ubuntu:22.04
repository:https://github.com/PaddlePaddle/PaddleOCR/tree/release/2.7
document:https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/kie_en.md
issue: https://github.com/PaddlePaddle/PaddleOCR/issues/11261
docker:https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/environment_en.md?fbclid=IwAR3TT4e98_wn87EyMR_9gvRwlmXYysN52vLbuBCqnw9h36MjHsRxBpLSKIA","['#Q&A', '#python']","['chào', 'hiện', 'task', 'key', 'information', 'extraction', 'thư viện', 'github', 'thử', 'paddleocr cài', 'môi trường', 'document', 'github', 'repository', 'lỗi', '2', 'training', 'lỗi', 'link', 'issue', 'thử', 'cài', 'docker', 'lỗi hình', 'rành paddle', 'task', 'kie', 'cuda', '11', '8', 'ubuntu', '22', '04', 'repository', 'document', 'issue', 'docker']"
591,"Chatbot đã thay đổi cách chúng ta tương tác với công nghệ và dịch vụ trực tuyến. Chúng ta đã dần quen với việc trò chuyện với chatbot trên trang web của một doanh nghiệp đến gửi tin nhắn với chatbot trên các ứng dụng nhắn tin. Trên thực tế, chatbot đang trở thành một phần không thể thiếu trong việc cung cấp hỗ trợ và thông tin tức thời cho khách hàng.
Nhưng chatbot là gì và làm thế nào chúng hoạt động? Trong bài viết này, chúng ta sẽ khám phá sâu hơn về chatbot và cách chúng thực hiện nhiệm vụ của mình.","['#sharing', '#nlp']","['chatbot', 'ta', 'tương tác', 'công nghệ', 'dịch vụ', 'trực tuyến', 'ta', 'dần', 'quen trò', 'chatbot', 'trang web', 'doanh nghiệp', 'gửi', 'nhắn chatbot', 'ứng dụng', 'nhắn', 'chatbot thể', 'cung thông', 'tức thời', 'hàng', 'chatbot', 'hoạt động', 'viết', 'ta', 'khám phá', 'sâu', 'chatbot', 'nhiệm vụ']"
592,"Xin phép add
Em là AI Engineer về Computer vision. Em đã làm việc được gần 1 năm.
Em muốn tìm một công ty mới có môi trường làm việc và mức lương phù hợp, vì công ty cũ không còn phù hợp nữa.
Vì nhiều lý do nên em không tiện chia sẻ cv của mình lên bài. Tại công ty hiện tại, vị trí của em là kỹ sư AI full-stack, các dự án mà em đã tham gia tại công ty như OCR, phát hiện lỗi sản phẩm, nhận diện khuôn mặt,...
Công ty anh/chị có nhu cầu tuyển dụng, em mong có cơ hội được liên hệ, rất vui được hợp tác và trao đổi với anh/chị
Cảm ơn!!
#ComputerVision, #AI, #job,",['#Q&A'],"['phép', 'add', 'engineer', 'computer', 'vision', '1', 'công ty', 'môi trường', 'lương', 'công ty', 'cũ lý', 'tiện cv', 'công ty', 'kỹ sư', 'fullstack', 'dự án', 'tham gia', 'công ty', 'ocr', 'phát hiện', 'lỗi', 'sản phẩm', 'diện', 'khuôn mặt', 'công ty', 'nhu cầu', 'tuyển dụng', 'mong hội', 'liên hệ', 'vui', 'hợp tác', 'trao đổi']"
593,"em chào mọi người !
em là người mới nên có thể một số kiến thức em vẫn chưa chắc lắm các anh thông cảm nếu điều em hỏi có hơi ngáo , em hiện đang làm 1 project nhỏ về chatbot . em có 1 số thắc mắc sau mong mọi người bớt chút thời gian giải thích giúp em ạ .
- 1 )ý tưởng của em là sử dụng langchain để kết nối với 1 llm tiếng việt ( như phogpt , phobert , vit5 ...) và nhúng các kiến thức dưới dạng các tệp tài liệu ( pdf , text , doc .. ) để không phải train lại llm .
nhưng hiện tại em thao tác với tiếng việt thì nó gặp lỗi ở phần chuyển hóa kiến thức file pdf ( chứa 1 văn bản tiếng việt ) nó không thể vector hóa kiến thức được . nhưng nếu em sử dụng với tiếng anh và model zephyr7b và model sentence-transformers/all-mpnet-base-v2 để vector hóa kiến thức thì nó hoạt động tốt với tài liệu tiếng anh .
em đang định sử lý theo kiểu chuyển hết tài liệu tiếng việt thành dạng tiếng anh để có thể nhúng vào model và khi user nhập câu hỏi vào thì cho nó chạy qua 1 model dịch để dịch nó thành tiếng anh rồi mới đưa vào chatbot và khi chatbot phản hồi thì lại cho chạy qua 1 lượt dịch để dich lại thành tiếng việt . nhưng như vậy thì em thấy khá cồng kềnh và nếu dịch qua lại giữa tiếng anh thì em sợ nó bi mất đi một số nghĩa đặc chưng của tiếng việt .
đây là link colab chatbot sử dụng zephy7b : https://drive.google.com/file/d/1c8_o0j0TMHY4S5daNFZwQVgW8MkBL9C-/view?usp=sharing
em muốn xây chatbot kiểu giống như cái bên trên nhưng hoạt động với tiếng việt .
- 2 ) em có tra cứu trên 1 số diễn đàn và gg thì thấy họ bảo rằng nên sử dụng loại model : Question Answering để tạo chatbot thay vì sử dụng Text2Text Generation trên hugging face , điều này có đúng không vậy ạ ? hay là nên sử dụng loại model nào ?
- 3 ) em sau 1 thời gian tìm hiểu thì em thấy trước khi vector hóa kiến thức để nhúng cho llm sử dụng thì nên cho nó chạy qua loại model Token Classification để phân tách kiến thức ra , điều này có đúng không ạ ?
- 4 ) cuối cùng em có tìm hiểu và chạy thử thì thấy kể cả chạy trên gpu ( colab ) thì thời gian phản hồi của nó cũng khoảng 10s với model khoảng 7b . có cách nào để tối ưu không ạ ? và có nên để nó chạy chỉ với cpu không ạ ? kiểu như lúc mình triển khai ấy thì gpu không phải lúc nào cũng sẵn có .
các anh có thể cho em một số gợi ý để em sử lý các vấn đề này không ? nếu được thì các anh cho em xin 1 số tên model hoặc tài liệu để em tham khảo với ạ . em cảm ơn .","['#Q&A', '#nlp', '#deep_learning']","['chào thể', 'kiến thức', 'lắm', 'thông cảm hơi', 'ngáo', 'hiện', '1', 'project', 'chatbot', '1', 'thắc mắc', 'mong', 'bớt', 'chút', 'giải', 'giúp', '1', 'tưởng', 'langchain', 'kết nối', '1', 'llm', 'tiếng', 'việt', 'phogpt', 'phobert', 'vit5 nhúng', 'kiến thức', 'dạng', 'tệp', 'tài liệu', 'pdf', 'text', 'doc', 'train', 'llm', 'thao tác', 'tiếng', 'việt', 'lỗi hóa', 'kiến thức', 'file', 'pdf', 'chứa', '1', 'văn', 'tiếng', 'việt thể', 'vector hóa', 'kiến thức', 'tiếng', 'model', 'zephyr7b', 'model', 'sentencetransformers', 'allmpnetbasev2', 'vector hóa', 'kiến thức', 'hoạt động', 'tài liệu', 'tiếng', 'định', 'sử lý', 'kiểu', 'tài liệu', 'tiếng', 'việt', 'thành', 'dạng', 'tiếng thể', 'nhúng', 'model', 'user', 'nhập', 'chạy', '1', 'model', 'dịch', 'dịch', 'thành', 'tiếng', 'chatbot chatbot', 'phản hồi', 'chạy', '1', 'lượt', 'dịch', 'dich', 'thành', 'tiếng', 'việt', 'cồng kềnh', 'dịch', 'tiếng', 'sợ', 'bi', 'đi nghĩa', 'đặc chưng', 'tiếng', 'việt', 'link', 'colab', 'chatbot', 'zephy7b', 'xây', 'chatbot', 'kiểu', 'hoạt động', 'tiếng', 'việt', '2', 'tra cứu', '1', 'diễn đàn', 'gg', 'bảo', 'model', 'question', 'answering', 'chatbot', 'thay', 'text2text', 'generation', 'hugging', 'face', 'model', '3', '1', 'vector hóa', 'kiến thức', 'nhúng', 'llm', 'chạy', 'model', 'token', 'classification', 'phân tách', 'kiến thức', '4', 'chạy', 'thử', 'chạy', 'gpu colab', 'phản hồi', '10', 's', 'model', '7', 'b', 'tối ưu', 'chạy', 'cpu', 'kiểu', 'triển khai', 'gpu', 'sẵn thể', 'gợi', 'sử lý', '1', 'model', 'tài liệu', 'tham khảo']"
594,"Chào mọi người em là newbie ạ
Em muốn thử 1 mô hình LLM kết hợp với RAG, Langchain thì nên thử ở đâu ạ. Nếu thử ở local thì máy lag, còn thử ở gg colab thì sau 1 time nó lại reset, bắt mình chạy lại toàn bộ lệnh","['#Q&A', '#nlp']","['chào', 'newbie', 'thử', '1', 'mô hình', 'llm', 'kết hợp', 'rag', 'langchain', 'thử', 'thử', 'local', 'máy', 'lag', 'thử', 'gg', 'colab', '1', 'time', 'reset', 'bắt', 'chạy', 'toàn', 'lệnh']"
595,"Gửi các bác, mình đang gặp vấn đề với thư viện underthesea như sau: 
Khi chạy với Sublime thì vẫn chạy bình thường
Khi xuất ra file exe với Pyinstaller thì báo lỗi như ảnh, hiện tại mình có folder báo thiếu như ảnh dưới tuy nhiên không biết bổ sung vào folder nào, folder temp khi tắt chương trình thì lại mất nên không biết bổ sung vào folder nào.
Các bác xem giúp em, em cảm ơn các bác","['#Q&A', '#python']","['gửi', 'thư viện', 'underthesea', 'chạy', 'sublime', 'chạy', 'bình xuất', 'file', 'exe', 'pyinstaller', 'báo', 'lỗi', 'ảnh', 'folder', 'báo', 'ảnh nhiên', 'bổ sung', 'folder', 'folder', 'temp', 'tắt', 'chương trình', 'bổ sung', 'folder', 'giúp']"
596,"Chào mọi người, em là newbie ạ
Cho em hỏi là muốn làm 1 con chatbot có thể trả lời theo dữ liệu realtime thì phải tìm hiểu những gì ạ, đặc biệt là LLAMA2
Em cảm ơn ạ","['#Q&A', '#nlp']","['chào', 'newbie', '1', 'chatbot thể liệu', 'realtime', 'llama2']"
597,"Em dân non-tech xin phép được đăng bài xin ý kiến anh chị ạ
Em thấy bộ VLMU được giới thiệu mới đây của Zalo AI là bảng leader board có thể nói là bảng đầu tiên ở nước mình, nhất là về mảng xử lý tiếng việt. Ở góc độ kinh tế, em có thể make-color cho sản phẩm của mình bằng rank này.
1. Tuy nhiên đối với anh chị, em rất muốn biết góc nhìn kỹ thuật thì đối với anh chị rank VLMU có làm highlight sản phẩm mình được không?
2. Nếu publish thì sẽ release nhiều thông tin, em muốn trước đó có 1 bộ đánh giá thử mà chỉ riêng nội bộ xem được, mình hiệu chỉnh và gửi publish sau thì có được hay không?
3. Những rule nào quy định về việc được publish, không được publish.
Mong ace hỗ trợ em ạ",['#Q&A'],"['dân', 'nontech phép', 'đăng kiến', 'vlmu', 'giới thiệu', 'zalo', 'bảng', 'leader', 'board thể', 'bảng mảng', 'tiếng', 'việt', 'góc độ', 'kinh tế thể', 'makecolor', 'sản phẩm', 'rank', '1', 'nhiên', 'đối góc', 'kỹ thuật', 'đối rank', 'vlmu', 'highlight', 'sản phẩm', '2', 'publish', 'release', 'thông', '1', 'thử', 'nội hiệu chỉnh', 'gửi', 'publish', '3', 'rule', 'quy định', 'publish', 'publish', 'mong', 'ace']"
598,🎯 OpenAi giới thiệu mô hình GPT-4 Turbo,['#sharing'],"['openai', 'giới thiệu', 'mô hình', 'gpt4', 'turbo']"
599,"Chào mọi người ạ.
Nhóm chúng em đang làm một project về Hỏi đáp tài liệu theo mô hình RAG sử dụng LLM ChatGPT.
Tài liệu của chúng em đang viết ở Tiếng Việt, Tiếng Anh và Tiếng Nhật. Em đang muốn tìm một model encoder tối ưu được cho 3 thứ tiếng trên ạ. Mọi người ai có kinh nghiệm có thể gợi ý giúp em một số model với ạ. Em cảm ơn mn","['#Q&A', '#nlp']","['chào', 'project', 'đáp', 'tài liệu', 'mô hình', 'rag', 'llm', 'chatgpt', 'tài liệu', 'viết', 'tiếng', 'việt', 'tiếng', 'tiếng', 'nhật model', 'encoder', 'tối ưu', '3', 'tiếng', 'kinh nghiệm thể', 'gợi', 'giúp', 'model', 'mn']"
600,"Xin chào mọi người, em có đang tranh luận với giảng viên về 2 việc như sau, mong được mọi người góp ý.
1. Khi dạy thuật toán NBC, cô em dạy 2 dạng là NBC thông thường và NBC (cô tạm gọi là) cải tiển.
- Với NBC thông thường thì tính theo công thức Bayes mở rộng, tức không coi các biến là độc lập với nhau
- Còn với NBC cải tiến thì mới coi các biến là độc lập với nhau
Quan điểm của em là: chữ Naïve trong thuật toán NBC đã chỉ ra ý tưởng ngây thơ của bài toán là coi các biến độc lập với nhau, chỉ tồn tại cái NBC mà cô em đang gọi là NBC mở rộng.
2. Cô em dạy Maximum Likelihood và Maximum A Posteriori là thuật toán học máy tương đương như ID3, Kmeans, kNN, SVM, Linear Regression. (Cô đưa ra bằng chứng là trong giáo trình học máy do thầy Hoàng Xuân Huấn trường Đại học Quốc gia Hà Nội có viết ở mục ‘5.2.1 Các quy tắc phân lớp ML và MAP’), mà phân lớp thì là thuộc bài toán classify trong học máy.
Em cho rằng ML, MAP chỉ là phương thức hỗ trợ cho thuật toán học máy, ví dụ như dùng ML trong thuật toán logistic regression.
Note: Em sẽ bổ sung thêm một số dẫn chứng cho quan điểm của cô và em dưới phần bình luận. Vì học khoa điện tử, đến kì này mới học phần mềm nên kiến thức của em có thể sai sót nhiều. Xong em không thể khiên cưỡng làm theo điều mình thấy không thuyết phục. Mong được mọi người khai thông, nếu ai có gmail của giảng viên dạy môn này thì cho em xin nhé ạ!","['#Q&A', '#machine_learning', '#math']","['chào', 'tranh luận', 'giảng viên', '2', 'mong', 'góp', '1', 'dạy', 'thuật toán', 'nbc', 'dạy', '2', 'dạng', 'nbc', 'thông nbc', 'tạm', 'gọi', 'cải tiển', 'nbc thông', 'công thức', 'bayes', 'rộng', 'tức', 'coi biến', 'độc lập', 'nbc', 'cải tiến', 'coi', 'biến', 'độc lập', 'quan chữ', 'naïve thuật toán', 'nbc tưởng', 'ngây', 'thơ toán', 'coi biến', 'độc lập', 'tồn nbc', 'gọi', 'nbc', 'rộng', '2', 'dạy', 'maximum', 'likelihood', 'maximum a', 'posteriori thuật', 'toán học', 'máy', 'tương đương', 'id3', 'kmeans', 'knn', 'svm', 'linear', 'regression chứng giáo trình', 'học', 'máy', 'thầy', 'hoàng', 'xuân', 'huấn', 'trường', 'đại học', 'quốc gia', 'hà nội', 'viết', 'mục', '5', '2', '1', 'quy tắc', 'phân lớp', 'ml', 'map', 'phân', 'lớp', 'toán', 'classify', 'học', 'máy', 'ml', 'map', 'phương thức', 'thuật toán', 'học', 'máy', 'ví dụ', 'ml thuật', 'toán', 'logistic', 'regression', 'note', 'bổ sung', 'chứng quan', 'bình luận', 'học khoa', 'điện tử kì', 'học mềm', 'kiến thức thể', 'sai sót', 'xong thể', 'khiên', 'cưỡng thuyết phục', 'mong', 'khai thông', 'gmail', 'giảng viên', 'dạy', 'môn']"
601,Mn đã ai convert model detectron2 sang onnx chưa ạ,"['#Q&A', '#cv']","['mn', 'convert', 'model', 'detectron2', 'onnx']"
602,"Chào mọi người . Tình hình là em có một đề tài đang làm với mục đích là phát triển một mô hình tính toán để chuyển đổi tín hiệu nhịp sinh học của cơ thể từ cảm biến áp suất điện thành sóng mạch máu. Các phương pháp tính toán truyền thống đã được thử nghiệm nhưng chưa đạt được độ chính xác mong muốn. Để giải quyết vấn đề này, nghiên cứu yêu cầu việc phải đo đạc cùng lúc dữ liệu giáo viên và dữ liệu từ cảm biến áp suất điện. Trong năm nay, em đã tạo một thiết bị đo mới đã được phát triển để giảm sai số và từ đó phát triển mô hình tính toán chính xác hơn.
- Anh chị cho em gợi ý về cách xây dụng mô hình tính toán chính xác hơn được không . có thể gợi ý cho em nguồn vài tài liệu để tìm hiểu thêm về mô hình thích hợp được không ạ .
- Mình sử dụng mô hình ML để giải quyết .
- Vì mục đích là làm cho data thu được từ cảm biến áp suất điện kết hợp với data về nhịp sinh học mẩu để tạo ra chuỗi data thời gian mới có tính chất gần giống với nhịp sinh học thực tế
- Mình có biết về ML , nhưng với mình chưa đủ để hiểu rõ vấn đề cần giải quyết .
- Lúc đầu mình sử dụng phương pháp ML như mạng neural networks và mô hình hidden markov để giải quyết bài toán time-series generation nhưng kết quả không đẹp như mình nghĩ .","['#Q&A', '#deep_learning']","['chào', 'tình hình', 'đề tài', 'mục đích', 'phát triển', 'mô hình', 'toán đổi', 'tín hiệu', 'nhịp', 'sinh học thể', 'cảm biến', 'áp suất', 'điện', 'thành', 'sóng', 'mạch máu', 'phương pháp toán', 'truyền thống', 'thử nghiệm', 'độ', 'xác mong', 'giải quyết', 'nghiên cứu', 'đo đạc liệu', 'giáo viên', 'liệu', 'cảm biến', 'áp suất', 'điện', 'thiết đo', 'phát triển', 'sai', 'phát triển', 'mô hình', 'toán', 'xác gợi', 'xây dụng', 'mô hình', 'toán', 'xác thể', 'gợi', 'tài liệu', 'mô hình', 'hợp', 'mô hình', 'ml', 'giải quyết', 'mục đích', 'data', 'thu', 'cảm biến', 'áp suất', 'điện', 'kết hợp', 'data nhịp', 'sinh học', 'mẩu', 'chuỗi', 'data', 'chất nhịp', 'sinh học', 'ml', 'giải quyết', 'đầu', 'phương pháp', 'ml mạng', 'neural', 'networks', 'mô hình', 'hidden', 'markov', 'giải quyết', 'toán', 'timeseries', 'generation kết', 'đẹp']"
603,"Hỏi cách lấy data (ảnh,...) từ vệ tinh. Cần góp ý về việc download dữ liệu từ các vệ tinh.
Đợt vừa rồi, mình có thử download dữ liệu vệ tinh Sentinel-2, cụ thể là multispectrum data. Nhưng mình vẫn chưa down được.
Có bạn nào đã có kinh nghiệm làm việc với ảnh vệ tinh có thể chia sẽ cách các bạn down và vài chia sẽ về việc xử lý ảnh kích thước lớn như ảnh vệ tinh không ạ?
Cám ơn.","['#Q&A', '#data']","['data', 'ảnh', 'vệ tinh góp', 'download liệu', 'vệ tinh', 'đợt', 'thử', 'download liệu', 'vệ tinh sentinel2', 'multispectrum', 'data', 'down', 'kinh nghiệm', 'ảnh vệ', 'tinh thể', 'chia', 'down', 'chia', 'ảnh', 'kích thước', 'ảnh', 'vệ tinh', 'cám ơn']"
604,"Cực đại của the log posterior
Chào mọi người, em đang vướng 1 chổ mà suy nghĩ mãi không ra. Làm cách nào để khai triển công thức bên dưới nhỉ (2 mũi tên màu đỏ trên hình).","['#Q&A', '#math']","['cực', 'đại the', 'log', 'posterior', 'chào vướng', '1', 'chổ', 'suy mãi', 'khai triển', 'công thức', '2', 'mũi', 'màu', 'đỏ hình']"
605,"Hi all ! 
Có bạn  nào đang học năm cuối kĩ sư hay master về computer vision hay graphic hoặc ngành liên quan. Có mong muốn học tiếp (PhD) và  bắt đầu bằng việc đi thực tập tại Pháp và Úc không ? Nếu có hãy liên lạc với mình ASAP nhé !
https://crossing.cnrs.fr/crossing-internships-2023-24/",['#Q&A'],"['hi all', 'học', 'kĩ sư', 'master', 'computer', 'vision', 'graphic', 'ngành', 'mong học', 'tiếp phd', 'đi', 'thực tập', 'pháp úc', 'liên lạc', 'asap', 'https', 'crossing', 'cnrs', 'fr', 'crossinginternships202324']"
606,"WEBINAR CHỦ ĐỀ  ""ỨNG DỤNG PHÂN TÍCH ĐỊNH LƯỢNG CHO TRADING"" CÁC TƯ DUY TRONG XÂY DỰNG VÀ KIỂM THỬ CHIẾN THUẬT ĐẦU TƯ TỰ ĐỘNG.
📌ICLS Tech kính mời cộng đồng Trading, những người yêu thích và quan tâm đến Trading đăng ký tham gia buổi chia sẻ về ""Ứng dụng phân tích định lượng cho Trading""
⏱Thời gian bắt đầu: 20h00, thứ Ba, ngày 21/11/2023
👉Hình thức tham dự: tham dự qua Zoom bằng đường link https://me-qr.com/w8ofedQx hoặc quét mã QR trong hình.
👨‍💼Phân tích định lượng trong đầu tư - Quantitative Trading là một phương pháp lượng hóa các thông tin thành số liệu cụ thể, giúp nhà đầu tư loại bỏ được yếu tố cảm xúc trước khi ra quyết định. Dựa trên các công thức, mô hình toán học và các công cụ trí tuệ nhân tạo. Giúp cải thiện kết quả đáng kể cho nhà đầu tư
---------------
👥Với sự chia sẻ của 2 vị khách mời:
🔹Anh Nguyễn Văn Thành:
- Research Consultant tại Tập đoàn Tài Chính định lượng WorldQuant
- Từng làm Software Engineer tại SamSung R&D
- Hơn 2 năm kinh nghiệm làm việc trong lĩnh vực khoa học dữ liệu, xử lý dữ liệu tài chính, crypto currency.
🔹Anh Ngô Phi Hùng:
- Tech Lead tại Hephatus Technology
- Từng làm Data Engineer tại FPT Telecom
---------------
Hãy tham gia ngay để tiếp cận và học hỏi về một phương pháp đầu tư hiệu quả. Có cơ hội được tham gia vào cộng đồng ICLS Tech để được hỗ trợ và tư vấn từ các chuyên gia🥰
Contact
☎️0962038175
✉️contact@icls-tech.com
#Quantitative #Trading #QuantitativeTrading #Webinar",['#webinar'],"['webinar', 'chủ đề', 'ứng dụng', 'phân tích', 'định', 'trading tư', 'xây dựng', 'kiểm thử', 'chiến thuật', 'đầu tư', 'động', 'icls', 'tech', 'kính', 'mời', 'cộng đồng', 'trading', 'yêu', 'trading', 'đăng ký', 'tham gia', 'ứng dụng', 'phân tích', 'định', 'trading', '20', 'h00', '21', '11', '2023', 'hình thức', 'tham dự', 'tham dự', 'zoom', 'đường', 'link', 'quét mã', 'qr hình', 'phân tích', 'định', 'đầu tư', 'quantitative', 'trading', 'phương pháp', 'hóa', 'thông', 'thành liệu', 'giúp', 'đầu tư', 'yếu tố', 'cảm xúc', 'quyết định', 'dựa', 'công thức', 'mô hình', 'toán học', 'công cụ', 'trí tuệ nhân', 'giúp', 'cải thiện', 'kết', 'đầu tư', '2', 'vị', 'mời', 'nguyễn văn thành', 'research', 'consultant', 'tập đoàn', 'tài định', 'worldquant', 'software', 'engineer', 'samsung', 'r', 'd', '2', 'kinh nghiệm', 'lĩnh vực', 'khoa học', 'liệu liệu', 'tài crypto', 'currency', 'ngô', 'phi hùng', 'tech', 'lead', 'hephatus', 'technology', 'data', 'engineer', 'fpt', 'telecom', 'tham gia', 'tiếp cận', 'học', 'phương pháp', 'đầu tư', 'hiệu hội', 'tham gia', 'cộng đồng', 'icls', 'tech', 'tư vấn', 'chuyên gia', 'contact', '0962038175', 'contact', 'iclstech', 'com']"
607,"Mình đang lead một số dự án tự động hoá ứng dụng AI/ML trong thiết kế, triển khai và tối ưu hệ thống mạng di động 5G (hợp tác với nhà mạng lớn tg).
Các bạn quan tâm tới lĩnh vực AI/ML trong viễn thông có thể kết nối, giao lưu và tham gia dự án bên mình (partime hay fulltime đều OK).
(Ảnh có tính minh họa tự động dự báo lưu lượng và tối ưu 1 trạm 5G toàn thời gian)",['#Q&A'],"['lead', 'dự án', 'động', 'hóa', 'ứng dụng', 'ml', 'thiết kế', 'triển khai', 'tối ưu', 'hệ thống', 'mạng', 'di động', '5', 'g', 'hợp tác', 'mạng', 'tg', 'lĩnh vực', 'ml', 'viễn thông thể', 'kết nối', 'giao lưu', 'tham gia', 'dự án', 'partime', 'fulltime', 'ok', 'ảnh minh', 'họa động', 'dự báo', 'lưu tối ưu', '1', 'trạm', '5', 'g', 'toàn']"
608,"Denoise diffusion probabilistic models
ThetaLog - Nhật ký Theta",['#sharing'],"['denoise', 'diffusion', 'probabilistic', 'models', 'thetalog', 'nhật ký', 'theta']"
609,"WEBINAR CHỦ ĐỀ  ""ỨNG DỤNG PHÂN TÍCH ĐỊNH LƯỢNG CHO TRADING"" CÁC TƯ DUY TRONG XÂY DỰNG VÀ KIỂM THỬ CHIẾN THUẬT ĐẦU TƯ TỰ ĐỘNG.
📌ICLS Tech kính mời cộng đồng Trading, những người yêu thích và quan tâm đến Trading đăng ký tham gia buổi chia sẻ về ""Ứng dụng phân tích định lượng cho Trading""
⏱Thời gian bắt đầu: 20h00, thứ Ba, ngày 21/11/2023
👉Hình thức tham dự: tham dự qua Zoom bằng đường link https://me-qr.com/w8ofedQx hoặc quét mã QR trong hình.
👨‍💼Phân tích định lượng trong đầu tư - Quantitative Trading là một phương pháp lượng hóa các thông tin thành số liệu cụ thể, giúp nhà đầu tư loại bỏ được yếu tố cảm xúc trước khi ra quyết định. Dựa trên các công thức, mô hình toán học và các công cụ trí tuệ nhân tạo. Giúp cải thiện kết quả đáng kể cho nhà đầu tư
---------------
👥Với sự chia sẻ của 2 vị khách mời:
🔹Anh Nguyễn Văn Thành:
- Research Consultant tại Tập đoàn Tài Chính định lượng WorldQuant
- Từng làm Software Engineer tại SamSung R&D
- Hơn 2 năm kinh nghiệm làm việc trong lĩnh vực khoa học dữ liệu, xử lý dữ liệu tài chính, crypto currency.
🔹Anh Ngô Phi Hùng:
- Tech Lead tại Hephatus Technology
- Từng làm Data Engineer tại FPT Telecom
---------------
Hãy tham gia ngay để tiếp cận và học hỏi về một phương pháp đầu tư hiệu quả. Có cơ hội được tham gia vào cộng đồng ICLS Tech để được hỗ trợ và tư vấn từ các chuyên gia🥰
Contact
☎️0962038175
✉️contact@icls-tech.com
#Quantitative #Trading #QuantitativeTrading #Webinar",['#webinar'],"['webinar', 'chủ đề', 'ứng dụng', 'phân tích', 'định', 'trading tư', 'xây dựng', 'kiểm thử', 'chiến thuật', 'đầu tư', 'động', 'icls', 'tech', 'kính', 'mời', 'cộng đồng', 'trading', 'yêu', 'trading', 'đăng ký', 'tham gia', 'ứng dụng', 'phân tích', 'định', 'trading', '20', 'h00', '21', '11', '2023', 'hình thức', 'tham dự', 'tham dự', 'zoom', 'đường', 'link', 'quét mã', 'qr hình', 'phân tích', 'định', 'đầu tư', 'quantitative', 'trading', 'phương pháp', 'hóa', 'thông', 'thành liệu', 'giúp', 'đầu tư', 'yếu tố', 'cảm xúc', 'quyết định', 'dựa', 'công thức', 'mô hình', 'toán học', 'công cụ', 'trí tuệ nhân', 'giúp', 'cải thiện', 'kết', 'đầu tư', '2', 'vị', 'mời', 'nguyễn văn thành', 'research', 'consultant', 'tập đoàn', 'tài định', 'worldquant', 'software', 'engineer', 'samsung', 'r', 'd', '2', 'kinh nghiệm', 'lĩnh vực', 'khoa học', 'liệu liệu', 'tài crypto', 'currency', 'ngô', 'phi hùng', 'tech', 'lead', 'hephatus', 'technology', 'data', 'engineer', 'fpt', 'telecom', 'tham gia', 'tiếp cận', 'học', 'phương pháp', 'đầu tư', 'hiệu hội', 'tham gia', 'cộng đồng', 'icls', 'tech', 'tư vấn', 'chuyên gia', 'contact', '0962038175', 'contact', 'iclstech', 'com']"
610,"Từ 1 bức ảnh nhiễu có thể tạo nên 1 bức ảnh chất lượng cao cấp nhờ công nghệ InstaFlow? 🫢 

Mời mọi người cùng tìm hiểu thêm về mô hình ""ma thuật"" được phát triển từ Stable Diffusion này tại bài viết bởi Data Scientist của PIXTA Vietnam nhé! 
#AI #MachineLearning #Instaflow","['#sharing', '#cv']","['1', 'ảnh', 'nhiễu thể', '1', 'ảnh', 'chất', 'công nghệ', 'instaflow', 'mời', 'mô hình', 'ma thuật', 'phát triển', 'stable', 'diffusion', 'viết', 'data', 'scientist', 'pixta', 'vietnam']"
611,"Có một bạn hôm trước DM mình hỏi về hai cuốn Thực hành Học máy, nay mình tìm lại không thấy tin nhắn nên post lại lên group:
http://handson-ml.mlbvn.org/?fbclid=IwAR1v-g8ihHP6LwYOGnWyvdOdcYbY91BZM9EW0Ig11HSMMKpBh4jjikWPZzc","['#sharing', '#machine_learning']","['hôm', 'dm', 'hai', 'thực hành', 'học', 'máy', 'nhắn', 'post', 'group']"
612,"Chào mọi người.
Qua bài post này mình muốn tìm người để cùng nhau học về AI/Data. Mình có thể cùng nhau thảo luận về một chủ đề nào đấy trong lĩnh vực này. Cũng có thể nếu người này vừa học được cái gì mới thì có thể giảng giải cho người kia. Người ta nói rằng: bạn chỉ thật sự hiểu một vấn đề, khi mà bạn có thể giải thích cho người khác cùng hiểu về vấn đề đó. Các chủ đề này cũng có thể chỉ là những vấn đề cơ bản của AI/Data thôi.
Một điều quan trọng là mình muốn các buổi thảo luận đều hoàn toàn bằng tiếng Anh.
Thật ra mục đích chính của những buổi này là mình muốn nâng cao kĩ năng thuyết trình, thảo luận và để ôn lại những kiến thức đã học được thôi.
Về mình thì mình có kiến thức về AI/Data ở mức tạm ổn, tiếng Anh tốt. Vì vậy nếu có bạn nào cũng chung chí hướng thì inbox mình nhé. Cảm ơn mọi người.",['#Q&A'],"['chào', 'post', 'học', 'data thể', 'thảo luận', 'chủ đề', 'đấy', 'lĩnh vực thể', 'học thể', 'giảng giải', 'kia', 'ta thể', 'giải', 'chủ đề thể', 'data', 'thảo luận', 'tiếng', 'mục đích', 'nâng', 'kĩ năng', 'thuyết trình', 'thảo luận', 'ôn kiến thức', 'học', 'kiến thức', 'data', 'tạm', 'ổn', 'tiếng', 'chí hướng', 'inbox']"
613,"Em chào mọi người,
Hiện tại em đang có thực hiện project build knowledge graph cho văn bản tiếng việt định hướng phương pháp em làm như sau :
- Dùng underthesea để setence segmentation để tách nhỏ văn bản thành từng câu
- Dùng Named Entity Regconition (NER)/Dependency Parsing (DEP) để phân tích thành phần trong câu ( Tạm thời sẽ dùng vncoreNLP để extract thử nghiệm tính hiệu quả nếu tốt có thể train lại )
- Từ NER/DEP đã extract sẽ tìm ra bộ 3 ( entity 1 - relation - entity 2 ) trong câu để tạo thành 1 liên kết trong graph với các node là entity
VD : ( Tổng thống mỹ là Joe Biden ) thì khi dùng NER/DEP thì sẽ cho ra kết quả ( entity 1:""Tổng_thống_mỹ"", relation:""là"",Entity 2 : ""Joe_Biden"")
---------------------------------------------------------------
Các khó khăn hiện tại vd với 1 câu phức tạp hơn như sau :
- Tổng thống mỹ là Joe Biden, ông còn biết tới là chính trị gia.
Thì trong 1 câu xuất hiện tới 2 bộ (e1,r,e2)
- Tổng thống mỹ là Joe Biden
- ông là chính trị gia
nhưng từ ông thì quá chung chung khi đó vào graph thì từ ông sẽ được liên kết với nhiều thành phần ko mong muốn ko thể hiện được ông = Joe Biden trong liên kết thì expect em nó sẽ là
- Tổng thống mỹ là Joe Biden
- Joe Bide là chính trị gia
Mọi người có giải pháp nào hoặc phương pháp nào giúp em tiếp cận bài toán không ạ em xin cảm ơn mọi người đã đọc","['#Q&A', '#nlp']","['chào', 'project', 'build', 'knowledge', 'graph văn', 'tiếng', 'việt', 'định hướng', 'phương pháp', 'underthesea', 'setence', 'segmentation', 'tách', 'văn thành', 'câu', 'named', 'entity', 'regconition', 'ner', 'dependency', 'parsing', 'dep', 'phân tích', 'thành', 'câu', 'tạm thời', 'vncorenlp', 'extract', 'thử nghiệm', 'hiệu thể', 'train', 'ner', 'dep', 'extract', '3', 'entity', '1', 'relation', 'entity', '2', 'câu', 'thành', '1', 'liên kết', 'graph', 'node', 'entity', 'vd', 'tổng thống', 'mỹ joe', 'biden', 'ner', 'dep', 'kết', 'entity', '1', 'tổng_thống_mỹ', 'relation', 'entity', '2', 'joe_biden', 'khăn', 'vd', '1', 'câu', 'phức tạp', 'tổng thống', 'mỹ joe', 'biden', 'trị gia', '1', 'câu', '2', 'e1', 'r', 'e2', 'tổng thống', 'mỹ joe', 'biden', 'trị gia graph', 'liên kết', 'thành', 'ko', 'mong', 'ko', 'thể hiện', 'joe', 'biden', 'liên kết', 'expect', 'tổng thống', 'mỹ joe', 'biden', 'joe', 'bide trị gia', 'giải pháp', 'phương pháp', 'giúp', 'tiếp cận toán', 'đọc']"
614,"Chào mọi người, em đang tìm kiếm công việc thực tập ở mảng Computer vision và đang chuẩn bị CV. Đây là CV của em, các anh chị kinh nghiệm có thể giúp em chỉnh sửa lại CV, cũng như đưa ra lời khuyên giúp em nên học thêm và chuyên sâu vào mảng nào được không ạ.
PS: em đang là sinh viên năm 3, các link github em không đính kèm trong file, nếu anh chị muốn xem thêm thì em gửi riêng ạ.",['#Q&A'],"['chào', 'kiếm', 'công thực tập', 'mảng', 'computer', 'vision', 'chuẩn', 'cv', 'cv', 'kinh nghiệm thể', 'giúp', 'chỉnh sửa', 'cv', 'khuyên', 'giúp', 'học', 'chuyên sâu', 'mảng', 'ps', 'sinh viên', '3', 'link', 'github', 'đính', 'kèm', 'file', 'gửi']"
615,"🎲🌈 WEBINAR: HƯỚNG DẪN TẠO NỘI DUNG VỚI CHATGPT
Tối thứ ba, 14/11 tới đây, FUNiX tổ chức webinar online ""Next-level AI Content - Hướng dẫn tạo nội dung với ChatGPT"". Diễn giả Trung Caha - Co-Founder Antory, Admin blog khoahocmidjourney.com, sẽ chia sẻ kinh nghiệm về cách sử dụng các kỹ thuật đột phá với ChatGPT.
Đến với webinar, bạn sẽ biết:
👉Tạo nội dung có chất lượng cao, cuốn hút từ ChatGPT mà không phải câu trả lời chung chung hay giống với tìm kiếm Google
👉Viết câu lệnh với Chat GPT mà  99,99999% thế giới ngoài kia chưa biết đến.
👉5 Yếu tố để tạo nội dung chuyên sâu, chất lượng cho bất cứ lĩnh vực nào bạn muốn.
👉Đạt được lợi thế cạnh tranh VƯỢT TRỘI  ngay cả so với những người khác sử dụng AI khác.
📌Nhanh tay đăng ký tại https://shorturl.at/atA28
⏰ Thời gian: 20:00 - 21:30, Thứ 3, ngày 14/11/2023",['#webinar'],"['webinar', 'hướng', 'nội dung', 'chatgpt', 'tối', '14', '11', 'funix', 'tổ chức', 'webinar', 'online', 'nextlevel', 'content', 'hướng', 'nội dung', 'chatgpt diễn', 'giả', 'trung caha', 'cofounder', 'antory', 'admin', 'blog', 'kinh nghiệm', 'kỹ thuật', 'đột phá', 'chatgpt', 'webinar', 'nội dung', 'chất', 'hút', 'chatgpt', 'câu', 'kiếm', 'google', 'viết', 'câu', 'lệnh', 'chat', 'gpt', '99', '99999', 'giới', 'kia', '5', 'yếu tố', 'nội dung', 'chuyên sâu', 'chất', 'lĩnh vực', 'lợi', 'cạnh tranh trội', 'đăng ký', 'tho', 'i gian', '20', '00', '21', '30', '3', 'nga', 'y', '14', '11', '2023']"
616,"Các bạn vui lòng đăng tin tuyển sinh, tuyển dụng, sự kiện tháng 11/2023 vào comment của post này.",['#sharing'],"['vui', 'đăng tuyển sinh', 'tuyển dụng', 'kiện', '11', '2023', 'comment', 'post']"
617,"[AI Share - Statistics]
Đa số các thuật toán của Machine Learning đều dựa trên nền của Xác suất và thống kê. Đối với nhiều người, xác suất thống kê là một môn khó và có nhiều kiến thức cần phải nắm. Ngoài việc đọc sách để nắm vững các khái niệm và ứng dụng, AI4E muốn chia sẻ 1 cheatsheet tổng hợp các kiến thức xác suất một cách ngắn gọn và tổng quát nhất. Cheatsheet này bao phủ toàn bộ các kiến thức cốt lõi nhất trong xác suất. Tài liệu có giá trị và đáng tin cậy bởi người viết dựa trên tài liệu khóa học Xác suất của Harvards.","['#sharing', '#math']","['share', 'statistics', 'đa thuật', 'toán', 'machine learning', 'dựa', 'xác suất', 'thống kê', 'đối', 'xác suất', 'thống kê', 'môn', 'kiến thức', 'nắm', 'đọc', 'sách', 'nắm', 'vững', 'khái niệm', 'ứng dụng', 'ai4e', '1', 'cheatsheet', 'tổng hợp', 'kiến thức', 'xác suất', 'ngắn gọn', 'tổng quát', 'cheatsheet', 'bao phủ', 'toàn', 'kiến thức', 'cốt lõi', 'xác suất', 'tài liệu', 'cậy', 'viết', 'dựa', 'tài liệu', 'khóa học', 'xác suất', 'harvards']"
618,"Chào các anh chị,
Em muốn mua máy bàn phục vụ việc nghiên cứu và chạy các mô hình học máy. Anh chị nào có thể gợi ý giúp em máy có cấu hình phù hợp được không ạ?

Em chân thành cám ơn.",['#Q&A'],"['chào', 'mua', 'máy', 'bàn', 'phục vụ', 'nghiên cứu', 'chạy', 'mô hình', 'học', 'máy thể', 'gợi', 'giúp', 'máy', 'cấu hình', 'chân thành', 'cám ơn']"
619,"[Scikit learn báo Multicolinearity]
ACE cho e hỏi e đang dùng Scikit Learn chạy OLS, check VIF toàn nhỏ hơn 2 sao cứ bị báo Multicolinearity vậy ạ. Ai biết Scikit Learn tính cái này thế nào k ạ chỉ e với. Tks mn!","['#Q&A', '#python']","['scikit', 'learn', 'báo', 'multicolinearity', 'ace', 'e e', 'scikit', 'learn', 'chạy', 'ols', 'check', 'vif', 'toàn', '2', 'báo', 'multicolinearity', 'scikit', 'learn', 'k', 'e tks', 'mn']"
620,"Chào mọi người ạ,
Em nhận thấy các LLM rất hay tự thêm thông tin vào context. Ví dụ em bảo nó viết câu hỏi cho một đoạn văn hoặc tóm tắt một bài báo thì nó hay tự động bổ sung các thông tin bên ngoài context / prompt vào kết quả.
Em cũng hiểu đây là chuyện dễ hiểu vì LLM là stocastic. Em cũng đã dùng các kiểu chain of thought để bắt LLM chỉ dùng thông tin được cung cấp để trả lời. Nếu không trả lời được dựa trên context thì cứ bảo là không biết, nhưng kết quả lúc được lúc không.
Không viết trong literature thì hiện tượng này gọi là gì ạ? Có phải là vấn đề các nhà khoa học đang giải quyết không ạ?
Cám ơn mọi người","['#Q&A', '#nlp']","['chào', 'llm', 'thông context', 'ví dụ', 'bảo', 'viết', 'đoạn', 'văn tóm', 'tắt', 'báo động', 'bổ sung', 'thông context', 'prompt', 'kết llm', 'stocastic', 'kiểu', 'chain', 'of thought', 'bắt', 'llm', 'thông cung', 'dựa', 'context', 'bảo kết', 'viết', 'literature', 'hiện tượng', 'gọi', 'khoa học', 'giải quyết', 'cám ơn']"
621,Nắm vững các giai đoạn phát triển của ứng dụng với Container,['#sharing'],"['nắm', 'vững', 'giai đoạn', 'phát triển', 'ứng dụng', 'container']"
622,"Chào buổi tối mọi người,
Hôm nay team VILM trình làng bộ dataset OpenOrca-Viet, bao gồm 120,000 cặp câu hỏi instructions chất lượng cao được distillate từ 3 LLMs hàng đầu trên thế giới: GPT-4, PaLM-2 và Claude.
OpenOrca-Viet được đồng phát triển dưới sự hợp tác của VILM và Alignment Lab AI, chủ nhân của bộ dataset OpenOrca gốc bằng tiếng Anh. Đây cũng chính là một trong các bộ dataset được sử dụng để train model Vietcuna-7B-v3.
Chúc mọi người có một buổi tối vui vẻ
Link to Dataset: https://huggingface.co/datasets/vilm/OpenOrca-Viet","['#sharing', '#data']","['chào', 'tối', 'hôm', 'team', 'vilm', 'trình', 'làng', 'dataset', 'openorcaviet', 'bao', '120', '000', 'cặp', 'instructions', 'chất', 'distillate', '3', 'llms', 'hàng đầu', 'giới', 'gpt4', 'palm2', 'claude', 'openorcaviet', 'đồng', 'phát triển', 'hợp tác', 'vilm', 'alignment', 'lab', 'chủ nhân', 'dataset', 'openorca', 'gốc', 'tiếng', 'dataset', 'train', 'model', 'vietcuna7bv3 chúc', 'tối', 'vui vẻ', 'link', 'to', 'dataset']"
623,"em chào các anh chị ạ, mọi người cho e hỏi là để vẽ hình này cần dùng tool gì ạ, e cảm ơn mng ạ!",['#Q&A'],"['chào e', 'vẽ', 'hình tool', 'e', 'mng']"
624,Em đang học về lắng nghe mạng xã hội. Trong bài yêu cầu phân tích chủ đề và sắc thái của doanh nghiệp dựa vào quy tắc sắc thái và quy tắc chủ đề. Nhưng em dựa vào đó vẫn làm sai. Anh chị chia sẻ cho em ít kinh nghiệm để làm đúng với ạ. Em cảm ơn.,['#Q&A'],"['học', 'lắng mạng', 'xã hội', 'phân tích', 'chủ đề', 'sắc thái', 'doanh nghiệp', 'dựa', 'quy tắc', 'sắc thái', 'quy tắc', 'chủ đề', 'dựa', 'sai', 'kinh nghiệm']"
625,"Em xin chào mọi người ạ. Hiện tại em đang thực hiện một bài toán như sau: Từ câu ngôn ngữ sinh ra query (vd như bài toán text2sql), từ query => chart, rồi từ chart => comment hoặc description về chart 📷
Vì kiến thức của e về nlp còn khá hạn chế, nên em chưa có kinh nghiệm nhiều trong các bài toán như này, nên em xin mọi người tư vấn giúp em một số vấn đề như sau ạ:
Cách tiếp cận bài toán như thế nào ạ? 
Dữ liệu train sẽ được xây dựng đánh label như thế nào ạ?
Để xây dựng được bài toán em nên học và sử dụng công cụ nào ạ? Em xin các keyword về bất cứ cứ thứ gì có thể coi là hữu ích cho bài toán trên: link, model, framework, document,...
Em xin cảm ơn các tư vấn ạ","['#Q&A', '#nlp']","['chào toán', 'câu', 'ngôn ngữ', 'sinh query', 'vd toán', 'text2sql', 'query', 'chart', 'chart', 'comment', 'description chart', 'kiến thức', 'e nlp', 'hạn chế', 'kinh nghiệm toán', 'tư vấn', 'giúp', 'tiếp cận', 'toán liệu', 'train', 'xây dựng', 'đánh label', 'xây dựng', 'toán học', 'công cụ', 'keyword thể', 'coi hữu ích', 'toán', 'link', 'model', 'framework', 'document', 'tư vấn']"
626,"Chào các bác. Cuối tuần tranh thủ thấy có github hày về món Text to Speech em xin mạnh dạn chia sẻ cùng các bạn mới học.
Bark - một món chuyển text to speech chạy offline, giọng tự nhiên hơn cả Google. Anh em nào cần làm món này cứ thế mà xài tự nhiên.
Tiếc là chưa có code training!",['#sharing'],"['chào', 'tuần', 'tranh thủ', 'github', 'hày', 'món', 'text', 'to', 'speech dạn', 'học', 'bark', 'món', 'text', 'to speech', 'chạy', 'offline', 'giọng nhiên', 'google', 'món', 'xài nhiên', 'tiếc', 'code', 'training']"
627,"Em chào mn ạ, e đang tìm hiểu về miccro segmentation mà thấy ít tài liệu viết về cái này nên e chưa hiểu rõ ạ. Không biết mn ai đã từng làm về phân khúc vi mô khách hàng cho e tham khảo với được không ạ? Em cảm ơn mn nhiều ạ.",['#Q&A'],"['chào', 'mn', 'e miccro', 'segmentation', 'tài liệu', 'viết', 'e mn', 'phân khúc', 'vi mô', 'hàng', 'e', 'tham khảo', 'mn']"
628,"Mn cho e hỏi câu liên quan đến SQL với ạ.
Em dùng bulk insert để nhập data từ file txt nhưng có 1 số bản ghi bị lỗi ví dụ như:
Name id
""Manh Thang (dấu tab)"" 1
Nhưng khi import thì dấu "" bị nhảy sang phần id( lý do là vì dấu tab) , do đó các hàng tiếp cũng bị nhảy theo.
Ai đã xử lý trường hợp như vậy cho e xin cách fix với ạ.
Em cảm ơn.",['#Q&A'],"['mn', 'e', 'câu', 'sql', 'bulk', 'insert', 'nhập', 'data', 'file', 'txt', '1', 'ghi', 'lỗi', 'ví dụ', 'name', 'id manh', 'thang', 'dấu', 'tab', '1', 'import', 'dấu', 'nhảy', 'id lý', 'dấu', 'tab', 'hàng', 'tiếp', 'nhảy', 'trường hợp', 'e', 'fix']"
629,"https://docs.google.com/document/d/1mlGA66qFAtNeTILDLZTSwxXZlI5R1T2Y2IbCiYTZRO8/edit?usp=sharing
Mọi người cho e hỏi là sau khi tìm được tất cả các tập phổ biến --> tìm luật kết hợp. Nhưng mà e ko chắc cách làm của e đã đúng chưa?
Vd trong tập phổ biến ABDE ta loại bỏ A thì có luật BDE->A conf = 2/2 = 1 --> đây là luật kết hợp
Link chi tiết bài làm e để trong google docs mn có thể xem qua và cho e ý kiến được không ạ ?
Sau khi tìm được các luật phổ biến thì có cần loại bỏ trùng lặp không ? Em cảm ơn!",['#Q&A'],"['e', 'tất tập', 'phổ biến', 'luật', 'kết hợp', 'e ko', 'e', 'vd tập', 'phổ biến', 'abde', 'ta', 'a luật', 'bde', 'a conf', '2', '2', '1', 'luật', 'kết hợp', 'link', 'chi tiết', 'e google', 'docs', 'mn thể', 'e kiến', 'luật', 'phổ biến', 'trùng lặp']"
630,"Cho mình hỏi có ai hiểu cách diễn giải của tác giả để đi đến kết luận P[R]>epsilon ở dòng cuối ko vậy?
Tên sách: Foundation of machine learning, MIT press. Sách có bản free online.","['#Q&A', '#machine_learning']","['diễn', 'giải tác giả', 'đi', 'kết luận', 'p', 'r', 'epsilon', 'dòng', 'ko', 'sách', 'foundation of', 'machine', 'learning', 'mit', 'press', 'sách', 'free', 'online']"
631,"Em xin chào mọi người ạ. Hiện tại em đang thực hiện một đề tài như sau: Xây dựng chatbot trả lời các câu hỏi liên quan đến lĩnh vực Luật. Ví dụ khi đặt câu hỏi ""Chạy xe máy vượt đèn đỏ sẽ bị phạt bao nhiêu tiền?"" thì chatbot sẽ trả lời câu hỏi đó đồng thời có thể đưa ra trích dẫn trong văn bản luật.
Em đã có bộ dữ liệu về các văn bản luật khá đầy đủ bao gồm cả các thuộc tính về hiệu lực, lĩnh vực,.... Với bộ câu hỏi - câu trả lời em cũng đã thu thập được lượng dữ liệu đủ lớn (100k) để sẵn sàng traning.
Vì kiến thức về AI của em khá hạn chế, mới bắt đầu tìm hiểu nên e xin được tham khảo ý kiến về các vấn đề sau ạ:
Em có nhận được lời khuyên là sử dụng NLP, ML để xử lý câu hỏi đầu vào theo các từ đồng nghĩa và xây dựng mạng Ontology để ánh xạ câu hỏi người dùng và tiến hành trả lời. Em xin hỏi liệu đây có phải là một cách tối ưu cho bài toán trên không ạ? Nếu có cách khác thì em xin nghe đề xuất ạ?
Để xây dựng được chatbot theo yêu cầu đề bài em nên học và sử dụng công cụ nào ạ? Em xin các keyword về bất cứ cứ thứ gì có thể coi là hữu ích cho bài toán trên: link, model, framework, document,...
Em xin cảm ơn các tư vấn ạ <3","['#Q&A', '#nlp']","['chào', 'đề tài', 'xây dựng', 'chatbot', 'lĩnh vực', 'luật', 'ví dụ', 'chạy', 'xe máy', 'đèn đỏ', 'phạt', 'tiền', 'chatbot thể', 'trích văn', 'luật liệu', 'văn luật', 'bao', 'hiệu lực', 'lĩnh vực', 'câu', 'thu thập liệu', '100', 'k', 'sẵn sàng', 'traning', 'kiến thức', 'hạn chế', 'e', 'tham khảo', 'kiến', 'khuyên', 'nlp', 'ml', 'đầu', 'đồng nghĩa', 'xây dựng', 'mạng', 'ontology', 'ánh xạ', 'tiến hành liệu', 'tối ưu toán', 'đề xuất', 'xây dựng', 'chatbot', 'đề học', 'công cụ', 'keyword thể', 'coi hữu ích', 'toán', 'link', 'model', 'framework', 'document', 'tư vấn', '3']"
632,Em đang làm về summarize sử dụng model LongT5. Em đang muốn thêm 1 block reattention vào sau block self-attention đầu tiên của phần encoder. Mà đang gặp lỗi ReAttentionBlock.forward() got an unexpected keyword argument 'attention_mask' ai có hướng solve giúp em với ạ. Em cảm ơn,['#Q&A'],"['summarize', 'model', 'longt5', '1', 'block', 'reattention', 'block', 'selfattention', 'encoder', 'lỗi', 'reattentionblock', 'forward', 'got', 'an unexpected', 'keyword', 'argument', 'attention_mask', 'hướng', 'solve', 'giúp']"
633,"[Hỏi đáp âm thanh]
Em xin chào mọi người.
Hiện tại em đang làm đồ án về đề tài xác định động cơ bị lỗi bằng âm thanh.
Vì động cơ lỗi khá ít nên tập dữ liệu của em chỉ đa số là âm thanh về động cơ bình thường dài khoảng 0.4 giây ạ.
Cho nên em hiện tại đang giải quyết bài toán theo hướng Anomaly Detection với 3 cách như sau:
Cách 1: Em trích xuất đặc trưng MFCC và sử dụng mô hình LSTM-Autoencode để phân biệt normal, abnormal dựa trên Loss của predict với input.
Cách 2: Em lấy hình ảnh Log-Mel-Spectrogram và sử dụng mô hình CNN-Autoencode cũng để phân biệt normal và abnormal dựa trên loss với đầu vào.
Nhưng kết quả trên tập test của 2 cách này bị sai rất nhiều ạ. Và em nghĩ nguyên nhân là do em trích xuất đặc trưng chưa phù hợp ạ.
Cho nên sau khi tham khảo các paper thì em trích xuất những đặc trưng sau: chorma, energy, spectral, rolloff, zero crossing, MFCC. Đối với mỗi loại đặc trưng thì em lấy mean và var thì được 69 chiều cho mỗi file âm thanh. Sau đó sử dụng mô hình One-Class-SVM để phân loại thì thấy kết quả có vẻ khả quan hơn được tý nhưng vẫn loại sai khá nhiều ạ.
Em muốn hỏi là đối với âm thanh về tiếng ồn của động cơ như này thì mình nên sử dụng đặc trưng nào của âm thanh và sử dụng mô hình gì ML/DL gì để có thể phân biệt được vậy ạ :(
Dưới đây là dữ liệu âm thanh của em ạ.
https://drive.google.com/drive/folders/171Y5_W7L6-v1dwDp9HB430fQYJeTwF9n?usp=sharing",['#Q&A'],"['đáp âm', 'chào', 'đồ án', 'đề tài', 'xác định', 'động', 'lỗi', 'âm động', 'lỗi', 'tập liệu', 'đa âm động', 'bình', '0', '4', 'giây', 'giải quyết', 'toán', 'hướng', 'anomaly', 'detection', '3', '1', 'trích xuất', 'đặc trưng', 'mfcc', 'mô hình', 'lstmautoencode', 'phân biệt', 'normal', 'abnormal', 'dựa', 'loss', 'predict', 'input', '2', 'hình ảnh', 'logmelspectrogram', 'mô hình', 'cnnautoencode', 'phân biệt', 'normal', 'abnormal', 'dựa', 'loss', 'đầu', 'kết tập', 'test', '2', 'sai', 'nguyên nhân', 'trích xuất', 'đặc trưng', 'tham khảo', 'paper', 'trích xuất', 'đặc trưng', 'chorma', 'energy', 'spectral', 'rolloff', 'zero', 'crossing', 'mfcc', 'đối đặc trưng', 'mean', 'var', '69', 'chiều', 'file âm', 'mô hình', 'oneclasssvm', 'phân kết', 'vẻ', 'khả quan', 'tý', 'sai', 'đối âm tiếng', 'ồn động', 'đặc trưng âm', 'mô hình', 'ml', 'dl thể', 'phân biệt liệu', 'âm']"
634,"Em xin chào mọi người ạ. Hiện em đang thử chạy code có sử dụng GPU VGA GIGABYTE GeForce RTX 3060 GAMING OC 12G (rev. 2.0) (GV-N3060GAMING OC-12GD) trên hệ điều hành Ubuntu 20.04. Tuy nhiên, khi em cài cuda thì hiện lên thông báo không tương thích. Mọi người có thể giợi ý cho em bản cuda nào tương thích với máy với ạ. Em xin cảm ơn mọi người.
Bản mà em thử tải ạ
https://linuxhint.com/install-cuda-ubuntu-2004/?fbclid=IwAR20YUODljBjdtVzyocI1wQeVpM-HaZID5RZ9VFcQl73DB3ueq4jPwmkYTQ
Lỗi mà máy em hiện lên ạ:","['#Q&A', '#python']","['chào', 'hiện', 'thử', 'chạy', 'code', 'gpu', 'vga', 'gigabyte', 'geforce', 'rtx', '3060', 'gaming', 'oc', '12', 'g', 'rev', '2', '0', 'gvn3060gaming', 'oc12gd', 'hệ hành', 'ubuntu', '20', '04', 'nhiên', 'cài', 'cuda', 'hiện', 'thông báo', 'tương thể', 'giợi', 'cuda', 'tương máy', 'thử', 'tải', 'lỗi', 'máy', 'hiện']"
635,"Em chào mọi người ạ, em đang học môn học máy, và hiện tại em đang có mấy bài tập như hình dưới đây ạ. Em đang cố gắng tìm hiểu hướng giải cũng như cách trình bày sao cho chính xác và đầy đủ nhưng hiện tại em vẫn chưa nghĩ được cách giải quyết ạ.
Nếu ai có cách hay hướng giải bài nào thì cho em xin với ạ. Em cảm ơn ạ.","['#Q&A', '#machine_learning']","['chào học', 'môn học', 'máy', 'mấy', 'tập hình', 'cố gắng', 'hướng', 'giải trình bày', 'xác', 'giải quyết', 'hướng', 'giải']"
636,"Các bạn vui lòng post thông tin tuyển dụng, sự kiện tháng 8/2023 vào phần comment của post này.",['#sharing'],"['vui', 'post thông', 'tuyển dụng', 'kiện', '8', '2023', 'comment', 'post']"
637,"Em chào mọi người ạ. Em có thắc mắc là liệu NLP có phải là subset của ML kh mng. Tại theo em tìm hiểu thì NLP giúp máy tính có thể hiểu, xử lý dc natural language nhưng mà để đạt dc quá trình đó như sdung POS có thể giúp nhận định dc từ loại của của 1 từ như noun, verb,... thì phải dùng ML để label hay sao ạ.
Em cảm ơn mng","['#Q&A', '#nlp']","['chào', 'thắc mắc liệu', 'nlp', 'subset', 'ml', 'kh', 'mng', 'nlp', 'giúp', 'máy thể', 'dc', 'natural', 'language', 'dc', 'trình', 'sdung', 'pos thể', 'giúp', 'định', 'dc', '1', 'noun', 'verb', 'ml', 'label', 'mng']"
638,"Xin chào cả nhà, team VILM đã chính thức trở lại với một model mới toanh :-P
🚀🚀🚀Obsidian-3B: Multimodal for Everyone. Được xây dựng trên mô hình NousCapyabra-3B dựa trên StableLM-3B-4e1t.
Obsidian-3B là kết quả của sự kết hợp giữa Nous Research (Mỹ) và VILM với mục tiêu đưa Multimodal đến với tất cả mọi người.
Mô hình có thể chạy trên bất kì GPU nào có VRAM 8GB trở lên.
Về kết quả benchmark: Obsidian-3B đánh bại hoặc ngang hàng LLaVA 1.5 7B của nhà Microsoft với điểm số ấn tượng trên các bài Benchmark về Vision Language
Ngoài ra team đã chính thức ra mặt Discord server để khởi động các dự án tiếp theo với cộng đồng, đặc biệt là phiên bản Vietcuna và multimodal thế hệ tiếp theo. Mong mọi người sẽ tham gia và xây dựng một cộng đồng AI Open-Source lớn mạnh của người Việt :)
Discord: https://discord.gg/uyhnuF9ncf
Model link: https://huggingface.co/NousResearch/Obsidian-3B-V0.5
Inference code: https://github.com/NousResearch/Obsidian

Chúc mọi người một buổi tối vui vẻ!",['#sharing'],"['chào', 'team', 'vilm thức', 'trở model', 'toanh', 'p', 'obsidian3b', 'multimodal', 'for', 'everyone', 'xây dựng', 'mô hình', 'nouscapyabra3b', 'dựa', 'stablelm3b4e1t', 'obsidian3b kết', 'kết hợp', 'nous', 'research', 'mỹ vilm', 'mục tiêu', 'multimodal', 'tất mô hình thể', 'chạy', 'gpu', 'vram', '8', 'gb', 'trở kết', 'benchmark', 'obsidian3b', 'đánh bại', 'ngang', 'hàng', 'llava', '1', '5', '7', 'b', 'microsoft', 'ấn tượng', 'benchmark', 'vision', 'language', 'team thức', 'mặt', 'discord server', 'khởi động', 'dự án', 'tiếp', 'cộng đồng', 'phiên', 'vietcuna', 'multimodal hệ', 'tiếp mong', 'tham gia', 'xây dựng', 'cộng đồng', 'opensource', 'việt', 'discord', 'model', 'link', 'inference', 'code chúc', 'tối', 'vui vẻ']"
639,"Meta/Facebook Research gần đây công bố Cookbook cho việc train và finetune các biến thể dựa trên mô hình LLaMA tại đây https://ai.meta.com/llama/get-started/; code base tại đây https://github.com/facebookresearch/llama-recipes.
Hi vọng nó sẽ giúp ích mọi người trong công việc","['#sharing', '#nlp']","['meta', 'facebook', 'research', 'công bố', 'cookbook', 'train', 'finetune', 'biến thể', 'dựa', 'mô hình', 'llama', 'https', 'meta', 'com', 'llama', 'getstarted', 'code', 'base', 'https', 'github', 'com', 'facebookresearch', 'llamarecipes', 'hi vọng', 'giúp ích', 'công']"
640,"Xin chào mọi người, em đang tập dùng thử ""Mechine learning Studio"" của Azure. Đến công đoạn tạo Real time Endpoints để dùng model từ API. Hệ thống đều báo chạy ổn, tuy nhiên, mục test thử thì toàn báo lỗi ""an unexpected error occurred in scoring script. check the logs for more info"". MN ai đã fix được lỗi này giúp mình với ạ",['#Q&A'],"['chào tập', 'thử', 'mechine', 'learning', 'studio', 'azure', 'công đoạn', 'real', 'time', 'endpoints', 'model', 'api', 'hệ thống', 'báo', 'chạy', 'ổn nhiên', 'mục test', 'thử', 'toàn', 'báo', 'lỗi', 'an unexpected', 'error', 'occurred', 'in', 'scoring', 'script', 'check', 'the', 'logs', 'for', 'more', 'info', 'mn', 'fix', 'lỗi', 'giúp']"
641,Bà con thử SFT con này xem có ổn không? Nếu ổn thì để nhóm train tiếp vài trăm GB bà con thử nốt.,['#sharing'],"['thử', 'sft', 'ổn', 'ổn', 'train', 'tiếp', 'trăm', 'gb', 'thử', 'nốt']"
642,"Em chào mọi người ạ, có ai gần đây train paddleocr không ạ ? cho em hỏi một chút :(( chứ em cả ngày hôm qua với nay bất lực quá. Chuyện là em có cài paddlepaddle-gpu bản 2.5.1 cho cuda 11.8, (cuda trên máy cũng đã cài 11.8 ) chạy paddle đã ổn nhưng không làm sao train được. Nó cứ vào load train như ảnh là lại không chạy tiếp nữa. em đã thử 2 bản python 3.7 và 3.10 nhưng đều như nhau. Em cũng đã giảm batchsize xuống từ 128 xuống 64, 32 rồi nhưng bị lỗi này hiện lên. Fomat data thì chắc không vấn đề, vì em đã load và train đc trên colab. Paddle cũng đã cài ổn như trên hình ạ. Em cảm ơn vì đã đọc.",['#Q&A'],"['chào', 'train', 'paddleocr', 'chút', 'hôm', 'bất lực', 'cài', 'paddlepaddlegpu', '2', '5', '1', 'cuda', '11', '8', 'cuda máy', 'cài', '11', '8', 'chạy', 'paddle', 'ổn', 'train', 'load', 'train ảnh', 'chạy', 'tiếp', 'thử', '2', 'python', '3', '7', '3', '10', 'batchsize', '128', '64', '32', 'lỗi', 'hiện', 'fomat', 'data', 'load', 'train', 'đc', 'colab paddle', 'cài', 'ổn hình', 'đọc']"
643,"Em chào cả nhà ạ. Mấy thời gian qua em có tự build một cái app cho phép người dùng thêm sản phẩm và tracking ngày hết hạn của sản phẩm đó. Đơn giản thì nó giống một cái todos-list mà dành cho mấy đồ thực phẩm ấy ạ. Điểm nhấn ở đây là em có sử dụng mô hình để nhận diện thực phẩm và đề xuất ngày hết hạn tương ứng. App hiện tại đã lên iOS và Android
https://apps.apple.com/vn/app/rappel-fresh-time-tracker/id6468539329
https://play.google.com/store/apps/details?id=com.tbsteam.rappel
Mong mọi người có thể tải về trải nghiệm thử và feedback đánh giá độ hiệu quả của model, và ai có đóng góp để cải thiện app nói chung thì càng tuyệt vời nữa ạ.
Chúc cả nhà cuối tuần vui vẻ ạ!! :)",['#sharing'],"['chào', 'mấy', 'build', 'app phép', 'sản phẩm', 'tracking hạn', 'sản phẩm', 'đơn giản', 'todoslist', 'mấy', 'đồ', 'thực phẩm', 'nhấn', 'mô hình', 'diện', 'thực phẩm', 'đề xuất', 'hạn', 'tương ứng', 'app', 'ios', 'android', 'mong thể', 'tải', 'trải nghiệm', 'thử', 'feedback', 'độ hiệu', 'model', 'đóng góp', 'cải thiện', 'app', 'tuyệt vời', 'chúc', 'tuần', 'vui vẻ']"
644,"Trong một bài viết nào đó của một bạn về điền giá trị bị thiếu và ""Tuyệt đối không được điền giá trị mean hoặc zero"" và nhân tiện trong quá trình tìm tài liệu để viết khóa học mình có tìm được cuốn sách này về xử lý dữ liệu bị thiếu.
Mình chia sẻ địa chỉ cuốn sách này cho các bạn tìm hiểu thêm, và sau khi đọc xong các bạn có thể rút ra được có nên điền mean vào hay không?","['#sharing', '#data']","['viết', 'điền', 'tuyệt đối', 'điền mean', 'zero trình', 'tài liệu', 'viết', 'khóa', 'học', 'sách liệu', 'địa sách', 'đọc', 'xong thể', 'rút', 'điền mean']"
645,"Các anh/chị/bạn đã có ai làm về tra cứu ảnh tương tự dựa trên nội dung sử dụng mô hình CNN chưa ạ.Có thể cho em xin một số nguồn tham khảo được không ạ.
Xin chân thành cảm ơn mn","['#Q&A', '#deep_learning']","['tra', 'cứu', 'ảnh', 'tương dựa', 'nội dung', 'mô hình', 'cnn thể', 'tham khảo', 'chân thành', 'mn']"
646,"Dạ em chào mọi người ạ. Em đang làm nghiên cứu về chủ đề 3D reconstruction và có gặp thuật ngữ UV mapping. Theo những gì em tìm hiểu thì có thể hiểu UV map là hình ảnh được ""đập dẹp"" của một mô hình 3D, cụ thể là gương mặt. Nếu trong 3D space, mỗi đỉnh trên 3D mesh có toạ độ là (x,y,z) thì trong không gian UV 2D thì đỉnh đó có toạ độ là (u,v). Tuy nhiên, em vẫn cảm thấy rất mơ hồ về nó, như là làm sao để visualize nó như là một hình ảnh 2D hay là về mặt toán học thì nó có thể được biễu diễn như thế nào? (ví dụ với hình ảnh màu 2D thì nó là một tensor width x height x 3 color channels). Do đó em mạn phép lên đây để nhờ các anh chị thầy cô trong group giúp em giải đáp vấn đề này ạ. Em xin chân thành cảm ơn!","['#Q&A', '#cv']","['chào', 'nghiên cứu', 'chủ đề', '3', 'd', 'reconstruction', 'thuật ngữ', 'uv', 'mapping thể', 'uv', 'map', 'hình ảnh', 'đập', 'dẹp', 'mô hình', '3', 'd', 'gương mặt', '3', 'd', 'space', 'đỉnh', '3', 'd', 'mesh', 'tọa độ', 'x', 'y z', 'gian', 'uv', '2', 'd', 'đỉnh', 'tọa', 'độ u', 'v nhiên', 'mơ hồ', 'visualize', 'hình ảnh', '2', 'd', 'mặt toán', 'học thể', 'biễu diễn', 'ví dụ', 'hình ảnh', 'màu', '2', 'd', 'tensor', 'width', 'x', 'height', 'x', '3', 'color', 'channels', 'mạn phép', 'thầy', 'group', 'giúp', 'giải đáp', 'chân thành']"
647,"Mình thấy có tutorials thú vị, đặc biệt là cho những bạn quan tâm tới Geostats của 1 giáo sư ở Đại học Texas at Autin nên chia sẻ ở đây cho những bạn cần tìm hiểu https://github.com/GeostatsGuy/PythonNumericalDemos",['#sharing'],"['tutorials', 'thú vị', 'geostats', '1', 'giáo sư', 'đại học', 'texas', 'at', 'autin']"
648,"Các bạn vui lòng đăng tin tuyển sinh, tuyển dụng, sự kiện tháng 10/2022 vào comment của post này.",['#sharing'],"['vui', 'đăng tuyển sinh', 'tuyển dụng', 'kiện', '10', '2022', 'comment', 'post']"
649,"Em chào mọi người, Cho em hỏi có cách nào dựng 3d từ ảnh độ sâu kết hợp ảnh 2d không ạ. Ảnh độ sâu và 2d em lấy từ đầu ra của camera intel d415. Mọi người có thể cho em xin tài liệu hoặc nguồn thông tin nào liên quan cũng được ạ. Em cảm ơn nhiều ạ 🥰","['#Q&A', '#cv']","['chào', 'dựng', '3', 'd', 'ảnh', 'độ', 'sâu', 'kết hợp', 'ảnh', '2', 'd', 'ảnh', 'độ', 'sâu', '2', 'd', 'đầu', 'camera', 'intel', 'd415 thể', 'tài liệu', 'thông']"
650,Cao nhân nào từng làm qua mô hình nhận diện bệnh cho lá cây cho em xin dataset với ạ. Em cảm ơn!,"['#Q&A', '#data']","['nhân', 'mô hình', 'diện', 'bệnh', 'lá', 'dataset']"
651,"Chào các anh chị và các bạn,
Hiện nay em đang làm đồ án môn học Xử lý âm thanh và tiếng nói. Bọn em chọn đề tài Nhận dạng tiếng nói tự động (ASR) sử dụng mô hình Conformer kết hợp với Noisy Student Training. Trong quá trình triển khai bọn em gặp một số vấn đề mong nhận được sự đóng góp và giúp đỡ đến từ mọi người:
VẤN ĐỀ VỀ VIỆC MÔ TẢ DỮ LIỆU: một trong những bộ dữ liệu bọn em sử dụng là 100h VLSP của VinAI công bố nhưng bọn em không tìm thấy mô tả bộ dữ liệu này.
VẤN ĐỀ VỀ TÀI NGUYÊN HUẤN LUYỆN: Hiện tại, với tài nguyên hạn chế và mô hình cũng khá lớn nên bọn em chỉ mới dừng lại ở mức character-level. Bọn em mong muốn huấn luyện ở mức Word-level nhưng lại gặp khó khăn trong việc thuê Colab Pro. Mọi người cho em hỏi ở nhóm mình có ai cho thuê Colab Pro thời gian ngắn không ạ ( khoảng dưới 1 tháng ).
Trên đây là những vấn đề bọn em gặp phải, mong nhận được sự giải đáp. Em xin cảm ơn ạ.",['#Q&A'],"['chào', 'đồ án', 'môn học', 'âm tiếng', 'bọn', 'đề tài', 'dạng', 'tiếng động', 'asr', 'mô hình', 'conformer', 'kết hợp', 'noisy', 'student', 'training trình', 'triển khai', 'bọn', 'mong', 'đóng góp', 'giúp đỡ', 'mô tả', 'liệu liệu', 'bọn', '100', 'h', 'vlsp', 'vinai', 'công bố', 'bọn', 'mô tả liệu', 'tài nguyên', 'huấn luyện', 'tài nguyên', 'hạn chế', 'mô hình', 'bọn', 'dừng', 'characterlevel', 'bọn', 'mong', 'huấn luyện', 'wordlevel', 'khăn', 'thuê', 'colab', 'pro', 'thuê', 'colab', 'pro', 'ngắn', '1', 'bọn', 'mong', 'giải đáp']"
652,"[English caption below]
URA-LLaMa: MÔ HÌNH NGÔN NGỮ LỚN CHO TIẾNG VIỆT
Xin chào mọi người,
Chúng tôi, nhóm nghiên cứu với các thành viên đến từ Trường Đại học Bách Khoa - ĐHQG TP.HCM và Đại học Stanford xin trân trọng giới thiệu đến cộng đồng các mô hình ngôn ngữ lớn chúng tôi đã phát triển. Chúng tôi gọi chúng với cái tên thân thuộc URA-LLaMa. Mô hình này được chúng tôi finetune trên dữ liệu tiếng Việt từ mô hình gốc LLaMa-2 của Meta với cả 3 phiên bản 7B, 13B và 70B.
Chúng tôi cung cấp miễn phí các mô hình này cho mục đích nghiên cứu. Mô hình của chúng tôi đi kèm với các kết quả đánh giá trên 10 tasks khác nhau ở nhiều khía cạnh và tình huống sử dụng trong thực tế. Bạn có thể tìm thấy thông tin về mô hình của chúng tôi tại các đường link bên dưới.
URA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b
URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b
URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b
Giấy phép và thỏa thuận sử dụng: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf
Playground cho URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground
Kết quả đánh giá của URA-LLaMa (Đang cập nhật): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation
Nếu bạn muốn đóng góp để phát triển các mô hình ngôn ngữ lớn cho Tiếng Việt, xin đừng ngần ngại hãy liên hệ với chúng tôi theo các thông tin bên dưới.
Về nhóm nghiên cứu:
Website: https://www.ura.hcmut.edu.vn
Email: qttho dot hcmut dot edu dot vn
Về giấy phép cho các mô hình: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn)
Xin cảm ơn mọi người.
10h10’, Thứ Ba, ngày 10 tháng 10 năm 2023.
Nhóm nghiên cứu
-----------------------------------------------
URA-LLaMa: LARGE LANGUAGE MODELS FOR VIETNAMESE
Hello everyone,
As a research team formed from members in Ho Chi Minh City University of Technology (HCMUT) - VNU-HCM and Stanford University, we are pleased to introduce our large language models to the community. We affectionately refer to those language models as URA-LLaMa. They are fine-tuned on Vietnamese datasets from Meta's original LLaMa-2 model, including all three versions of 7B, 13B, and 70B.
We provide these models free of charge for research purposes. Our models come with evaluation results on 10 different tasks, covering various aspects and real-world usage scenarios. You can find information about our models at the following links:
URA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b
URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b
URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b
License and User Agreement: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf
Playground for URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground
URA-LLaMa Evaluation Results (Actively updating): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation
If you want to contribute to the development of large language models for Vietnamese, please do not hesitate to contact us using the information below.
About the research group:
Website: https://www.ura.hcmut.edu.vn
Email: qttho dot hcmut dot edu dot vn
About the model licenses: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn)
Thank you all.
10:10 AM, Tuesday, October 10, 2023.
Research Team","['#sharing', '#nlp']","['english', 'caption', 'below', 'urallama', 'mô hình', 'ngôn ngữ', 'tiếng', 'việt', 'chào', 'nghiên cứu', 'thành viên', 'trường', 'đại học', 'bách khoa', 'đhqg', 'tp', 'hcm', 'đại học', 'stanford', 'trân trọng', 'giới thiệu', 'cộng đồng', 'mô hình', 'ngôn ngữ', 'phát triển', 'gọi', 'thân urallama', 'mô hình', 'finetune liệu', 'tiếng', 'việt', 'mô hình', 'gốc', 'llama2', 'meta', '3', 'phiên', '7', 'b', '13', 'b', '70', 'b', 'cung', 'miễn phí', 'mô hình', 'mục đích', 'nghiên cứu', 'mô hình', 'đi', 'kèm kết', '10', 'tasks', 'khía cạnh', 'tình huống thể', 'thông', 'mô hình', 'đường', 'link', 'urallama', '7', 'b', 'urallama', '13', 'b', 'urallama', '70', 'b', 'giấy phép', 'thỏa thuận', 'playground', 'urallama', '7', 'b', 'kết urallama', 'cập nhật', 'đóng góp', 'phát triển', 'mô hình', 'ngôn ngữ', 'tiếng', 'việt', 'đừng', 'ngần ngại', 'liên hệ', 'thông', 'nghiên cứu', 'website', 'email', 'qttho', 'dot', 'hcmut', 'dot', 'edu', 'dot', 'vn', 'giấy phép', 'mô hình', 'nqduc', 'at', 'hcmut', 'dot', 'edu', 'dot', 'vn', 'cc', 'sttruong', 'at', 'cs', 'dot', 'stanford', 'dot', 'edu', 'qttho', 'at', 'hcmut', 'dot', 'edu', 'dot', 'vn', '10', 'h10', '10', '10', '2023', 'nghiên cứu', 'urallama', 'large', 'language', 'models', 'for', 'vietnamese', 'hello', 'everyone', 'as', 'a', 'research', 'team', 'formed', 'from', 'members', 'in', 'ho', 'chi minh', 'city', 'university', 'of technology', 'hcmut vnuhcm', 'and stanford', 'university', 'we', 'are', 'pleased', 'to', 'introduce', 'our', 'large', 'language', 'models', 'to', 'the', 'community', 'we', 'affectionately', 'refer', 'to', 'those', 'language', 'models', 'as', 'urallama', 'they', 'are', 'finetuned', 'on', 'vietnamese', 'datasets', 'from', 'meta', 's', 'original', 'llama2', 'model', 'including', 'all', 'three', 'versions', 'of', '7', 'b', '13', 'b and', '70', 'b', 'we', 'provide', 'these', 'models', 'free', 'of charge', 'for', 'research', 'purposes', 'our', 'models', 'come', 'with', 'evaluation', 'results', 'on', '10', 'different', 'tasks', 'covering', 'various aspects', 'and realworld', 'usage', 'scenarios', 'you', 'can', 'find', 'information', 'about', 'our', 'models', 'at', 'the', 'following', 'links', 'urallama', '7', 'b', 'urallama', '13', 'b', 'urallama', '70', 'b', 'license and', 'user', 'agreement', 'playground', 'for', 'urallama', '7', 'b', 'urallama', 'evaluation', 'results', 'actively', 'updating', 'if', 'you', 'want', 'to', 'contribute', 'to', 'the', 'development', 'of large', 'language', 'models', 'for', 'vietnamese', 'please', 'not', 'hesitate', 'to', 'contact', 'us', 'using', 'the', 'information', 'below', 'about', 'the', 'research', 'group', 'website', 'email', 'qttho', 'dot', 'hcmut', 'dot', 'edu', 'dot', 'vn', 'about', 'the', 'model', 'licenses', 'nqduc', 'at', 'hcmut', 'dot', 'edu', 'dot', 'vn', 'cc', 'sttruong', 'at', 'cs', 'dot', 'stanford', 'dot', 'edu', 'qttho', 'at', 'hcmut', 'dot', 'edu', 'dot', 'vn', 'thank', 'you', 'all', '10', '10', 'am tuesday', 'october', '10', '2023', 'research', 'team']"
653,"Chào mọi người, em đang tìm hiểu về LLMs và cụ thể là OpenAI API. Em có 1 số thắc mắc mong mọi người giải đáp.
Những model DALL-E và Whisper có thực sự là Large Language Models không ạ, tại bữa em có đọc lướt qua 1 ?
Khi dùng openai thì em thấy có 2 phương thức khá tương tự là Completion và ChatCompletion. trong khi ChatCompletion có thể gửi lịch sử hội thoại thì không biết Completion có ưu điểm gì mà vẫn được giữ lại?
Cách tính phí
Ví dụ: babbage-002 $0.0004 / 1K tokens thì là token vào hay token ra hay tổng ạ.
Khi fine-turning, sử dụng model đó thì tính phí sử dụng có + thêm phí model gốc không hay chỉ tính phí sử dụng và tính phí đầu vào hay đầu ra hay cả 2
- có trang này tổng hợp đầy đủ model và phí hiện đang có hơn trang https://openai.com/pricing không ạ
Giới hạn
- Giới hạn ở trang https://platform.openai.com/docs/models MAX TOKENS là token nhập vào phải không ạ. Nếu vậy có limit cho token trả về không?
- Giới hạn gửi request trong khoảng thời gian: liệu có cách nào để xin tăng giới hạn (cho tài khoản miễn phí) không ạ? vì gửi theo biểu mẫu dành cho tài khoản trả phí.
Ngoài ra, không biết có chính sách (hoặc trick nào) cho sinh viên để có thể trải nghiệm các tính năng paid plan (ví dụ như fine-tuning) của OpenAI API không ạ?","['#Q&A', '#nlp']","['chào', 'llms', 'openai', 'api', '1', 'thắc mắc', 'mong', 'giải đáp', 'model', 'dalle', 'whisper', 'thực large', 'language', 'models', 'bữa', 'đọc', 'lướt', '1', 'openai', '2', 'phương thức', 'tương completion', 'chatcompletion', 'chatcompletion thể', 'gửi', 'lịch sử', 'hội thoại', 'completion', 'ưu phí', 'ví dụ', 'babbage002', '0', '0004', '1', 'k', 'tokens', 'token', 'token', 'tổng fineturning', 'model', 'phí', 'phí', 'model', 'gốc', 'phí', 'phí', 'đầu', 'đầu', '2', 'trang', 'tổng hợp', 'model phí', 'hiện trang', 'giới hạn', 'giới hạn', 'trang', 'max', 'tokens', 'token', 'nhập', 'limit', 'token', 'giới hạn', 'gửi', 'request liệu', 'giới hạn', 'tài khoản', 'miễn phí', 'gửi', 'biểu mẫu', 'tài khoản', 'phí', 'sách', 'trick', 'sinh viên thể', 'trải nghiệm năng', 'paid', 'plan', 'ví dụ', 'finetuning', 'openai', 'api']"
654,Chào mọi người. Mình đang cần nộp 1 bài tập lớn về đề tài MachineLearning bất cứ thứ gì cũng được. Vậy bạn nào có thể chia sẻ cho mình 1 đề tài nào đó cơ bản nhất có thể có sẵn cả báo cáo và source code với không ạ? Mình xin cảm ơn và hậu tạ ạ,['#Q&A'],"['chào', 'nộp', '1', 'tập', 'đề tài', 'machinelearning thể', '1', 'đề tài thể', 'sẵn', 'báo cáo', 'source', 'code hậu', 'tạ']"
655,Mọi người ai làm về trích xuất thông tin trên căn cước công có chip chưa cho e hỏi cái này với ạ?,"['#Q&A', '#cv']","['trích', 'xuất thông', 'cước', 'công chip', 'e']"
656,"Như thread cách đây chưa lâu (tại đây https://www.facebook.com/groups/machinelearningcoban/permalink/1778526872604712/) rằng Mojo có thể sẽ có chỗ đứng của riêng nó trong thời đại ứng dụng AI trên các nền tảng tính toán hiệu năng cao . Nay Mojo mới cho cài Native trên Mac chip M. Hướng dẫn cài đặt tại đây: https://developer.modular.com/download.
Mình có test nhanh trên máy Mac M1 của mình với LLaMA2 (train với TinyStory từ Karpathy) và TinyLLaMA2 từ (https://huggingface.co/kirp/TinyLlama-1.1B-Chat-v0.2-bin/resolve/main/tl-chat.bin). Dưới đây là bản tóm tắt kết quả so sánh inference speed giữa Mojo và C. Cơ bản là không tệ và tốt hơn kết quả trước đó mình test trên server Linux (xem comments ở thread trước đây, dường dẫn ở trên). Mình sẽ test thêm kĩ hơn trong những ngày tới rồi chia sẻ với các bạn sau!
source code cho LLaMA2.mojo tại đây https://github.com/tairov/llama2.mojo
và tổng hợp các source code/thư viện thú vị viết cho mojo tại đây https://github.com/mojicians/awesome-mojo",['#sharing'],"['thread', 'https', 'www', 'facebook', 'com', 'groups', 'machinelearningcoban', 'permalink', '1778526872604712', 'mojo thể', 'chỗ đứng', 'thời đại', 'ứng dụng', 'tảng toán', 'hiệu năng', 'mojo', 'cài', 'native', 'mac', 'chip', 'm', 'hướng', 'cài', 'https', 'developer', 'modular', 'com', 'download', 'test', 'máy', 'mac', 'm1', 'llama2', 'train', 'tinystory', 'karpathy', 'tinyllama2 tóm', 'tắt', 'kết sánh', 'inference', 'speed', 'mojo', 'c', 'tệ kết', 'test', 'server', 'linux', 'comments thread', 'dường test', 'kĩ source', 'code', 'llama2 mojo', 'tổng hợp', 'source', 'code', 'thư viện', 'thú vị', 'viết', 'mojo']"
657,"Xin chào tất cả anh chị. Em là sv năm nhât ạ và sắp tới em phải bảo vệ đồ án ý tưởng sản phẩm CNTT. ý tưởng khá hay có ứng dụng AI các kiểu. Cụ thể: 1 app tích hợp AI gợi ý thực đơn cho người dùng dựa trên những dữ liệu của họ( bao gồm dữ liệu cố định và dữ liệu được ghi lại theo thời gian thực bằng thiết bị theo dõi SK). Và AI đã được huấn luyện để tìm ra những món ăn có thực phẩm, gia vị phù hợp dinh dưỡng ( thậm chí khẩu vị ) với người dùng, rồi đưa ra gợi ý để họ chọn và đăt hàng.
Dưới hình là liệt kê các tiêu chí ạ, từ tiêu chí ấy anh chị có thể tư vấn sâu thêm chút về kĩ thuật huấn luyện cho con AI này ( công đoạn, chiến lược, phân tích, chọn các thuật toán, mô hình hóa dữ liệu,...)
Vì em chỉ biết chút bề nổi về tiềm năng ứng dụng của AI thôi ạ. Nên em cần anh chị tư vấn giúp em để đào sâu hơn chút về kĩ thuật nha !!!
Chiyyso06.5 ♠️",['#Q&A'],"['chào', 'tất sv', 'nhât', 'bảo vệ', 'đồ án', 'tưởng', 'sản phẩm', 'cntt tưởng', 'ứng dụng', 'kiểu', '1', 'app tích', 'hợp gợi', 'thực đơn', 'dựa liệu', 'bao liệu', 'cố định liệu', 'ghi', 'thực thiết dõi', 'sk', 'huấn luyện', 'món', 'thực phẩm', 'gia vị', 'dinh dưỡng chí', 'khẩu vị', 'gợi', 'đăt', 'hàng', 'hình liệt kê', 'tiêu chí', 'tiêu chí thể', 'tư vấn', 'sâu chút', 'kĩ thuật', 'huấn luyện', 'công đoạn', 'chiến lược', 'phân tích', 'thuật toán', 'mô hình', 'hóa liệu', 'chút bề', 'nổi', 'tiềm năng', 'ứng dụng', 'tư vấn', 'giúp', 'đào', 'sâu chút', 'kĩ thuật', 'nha', 'chiyyso06', '5']"
658,"Mn cho em hỏi điểm giống và khác nhau (so sánh) của decision tree, k-NN, naive bayes, linear regression với ạ","['#Q&A', '#machine_learning']","['mn', 'sánh', 'decision', 'tree', 'knn', 'naive', 'bayes', 'linear', 'regression']"
659,"Hello mọi người! Hiện tại e có kiến thức cơ bản về data science và stats/probability. Trước em dùng R để làm 1 số project và học qua cuốn ISLR và hiện tại đang bắt đầu học Python.
Google mới released khoá học về advanced data analytics, e chỉ biết khác với khoá trước là thay vì dùng R thì khoá này dùng Python. A/C nào đã học qua hoặc biết về khoá học này cho e xin reviews với ạ. Thank you",['#Q&A'],"['hello', 'e', 'kiến thức', 'data', 'science', 'stats', 'probability', 'r', '1', 'project', 'học', 'islr', 'học', 'python', 'google', 'released', 'khóa', 'học', 'advanced', 'data', 'analytics', 'e khóa', 'thay', 'r', 'khóa', 'python', 'a c', 'học', 'khóa', 'học', 'e reviews', 'thank', 'you']"
660,"[Góc tư vấn]
Anh chị em nào đã và đang học Master ở ĐH Bách Khoa ngành Data Science rồi cho em xin review với ạ.
Em phân vân học BK hoặc học từ xa 1 số trường nc ngoài (so sánh học phí, chất lượng giangr dạy, bằng cấp,…).
Rất mong được các anh chị đi trc có kinh nghiệm chỉ dạy ạ. Em cảm ơn ạ.",['#Q&A'],"['góc', 'tư vấn', 'học', 'master', 'đh', 'bách khoa', 'ngành', 'data', 'science', 'review', 'phân vân', 'học', 'bk học', '1', 'trường', 'nc sánh', 'học phí', 'chất', 'giangr', 'dạy', 'mong', 'đi', 'trc', 'kinh nghiệm', 'dạy']"
661,"Chào các anh chị!
Trong học kì tới em sẽ bắt đầu học các môn chuyên ngành AI và
Em đã học qua các khóa ML, DL trên Coursera và đã hiểu những concept, toán học cơ bản về lĩnh vực này.
Em rất mong muốn thực tập sớm để tích lũy các kinh nghiệm thực tế trong môi trường doanh nghiệp nhưng hiện tại em thấy các công việc này đang tuyển ở TPHCM khá ít nên em hơi hoang mang ạ.
Em muốn hỏi các anh/ chị em nên trau dồi thêm những gì để có đủ kỹ năng để có được vị trí thực tập ở các vị trí AI Engineer hoặc Data Science ạ.
Rất mong nhận được sự góp ý từ mọi người. Chúc mọi người một ngày vui vẻ ạ!",['#Q&A'],"['chào', 'học kì', 'học', 'môn', 'chuyên ngành', 'học', 'khóa', 'ml', 'dl', 'coursera', 'concept toán', 'học', 'lĩnh vực', 'mong', 'thực tập tích', 'lũy', 'kinh nghiệm', 'môi trường', 'doanh nghiệp', 'công tuyển', 'tphcm', 'hơi', 'hoang trau dồi', 'kỹ năng', 'thực tập', 'engineer', 'data', 'science mong', 'góp chúc', 'vui vẻ']"
662,"Xin chào các bác. Chả là lâu nay em có đọc tin bài về AI trên Medium. com nhưng dạo gần dây em vào rất khó, quay đều đều mà không vào được.
Em muốn xin hỏi các bác xem còn có trang nào tương tự như trang này để vào đọc và cập nhật các bài liên quan đến AI không ạ?
Em cảm ơn các bác nhiều!",['#Q&A'],"['chào chả', 'đọc', 'medium', 'com', 'dạo', 'dây trang', 'tương trang', 'đọc', 'cập nhật']"
663,"Hiện tại Em đang làm 1 model image classfication về các loài côn trùng. Nhưng gặp phải vấn đề là khi em train 200 class thì bình thường. Nhưng khi tăng lên 300 thì model giảm độ chính xác, và khi nhận dạng thực tế thì cũng giảm và score giảm còn rất thấp mặc dù nhận dạng vẫn có cái đúng. Em đoán là có thể là do các class côn trùng nhiều loài rất giống nhau thậm chí giống hệt. Nên ảnh hưởng. Em cũng có suy nghĩ là gom nhóm các loài giống nhau vào kiểu như sub class. Nhưng không biết như thế nào. Em hi vọng được nghe chia sẻ của các anh chị về cách giải quyết vấn đề này. Em cảm ơn rất nhiều.","['#Q&A', '#cv']","['1', 'model', 'image', 'classfication', 'loài', 'côn trùng', 'train', '200', 'class', 'bình', '300', 'model độ', 'xác', 'dạng', 'score', 'mặc', 'dạng', 'đoán thể', 'class', 'côn trùng', 'loài', 'chí hệt', 'ảnh hưởng', 'suy gom', 'loài', 'kiểu', 'sub class', 'hi vọng', 'giải quyết']"
664,"Đã có người đầu tiên port thư viện rất hay và nổi tiếng của Karpathy có tên là llama.c https://github.com/karpathy/llama2.c sang Mojo tại đây https://github.com/tairov/llama2.mojo
Mojo đã tăng hiệu suất của Python lên gần 250 lần. Thật ấn tượng với phiên bản Mojo giờ đây vượt trội hơn llama2.c khoảng 15-20%. Một con số cực kì ấn tượng trong thí nghiệm ban đầu này.
Điều này cho thấy tiềm năng của việc tối ưu phần cứng thông qua các tính năng nâng cao của Mojo. Tôi nghĩ điều này bước đầu cho ta thấy được ấn tượng về hiệu năng của Mojo trên các mô hình ngôn ngữ lớn, nơi đòi hỏi tài nguyên tính toán rất lớn. Nên cải thiện được x% về hiệu năng cũng là rất đáng quí.
Chúc các bạn có trải nghiệm vui vẻ với những thứ mới lạ!
Ps. Khi tôi post bài trước đó về việc Modular cho cài đặt Mojo trên local machines (trước đó chỉ chạy online trên servers chủ của cty), nhiều bạn tỏ ý nghi ngờ. Tôi có nói, hãy bình tĩnh chờ đợi và hãy thử trải nghiệm với Mojo theo cách của bạn, trước khi có những phát biểu cảm tính. Tôi hiểu đây là một phần tính cách của không ít người Việt. Xin lỗi phải nói ra việc đụng chạm đáng buồn này. Rất lấy làm tiếc
https://github.com/tairov/llama2.mojo/blob/master/assets/llama2.mojo-demo.gif",['#sharing'],"['port', 'thư viện', 'nổi tiếng', 'karpathy', 'llama', 'c', 'mojo', 'mojo', 'hiệu suất', 'python', '250', 'ấn tượng', 'phiên', 'mojo trội', 'llama2', 'c', '1520', 'cực kì', 'ấn tượng', 'thí nghiệm', 'ban đầu', 'tiềm năng', 'tối ưu cứng', 'thông năng', 'nâng', 'mojo', 'đầu', 'ta', 'ấn tượng', 'hiệu năng', 'mojo', 'mô hình', 'ngôn ngữ', 'đòi', 'tài nguyên toán', 'cải thiện', 'x', 'hiệu năng', 'quí chúc', 'trải nghiệm', 'vui vẻ', 'lạ ps', 'post modular', 'cài', 'mojo', 'local', 'machines', 'chạy', 'online servers', 'chủ', 'cty', 'tỏ', 'nghi ngờ', 'bình tĩnh', 'chờ đợi', 'thử', 'trải nghiệm', 'mojo', 'phát biểu cảm', 'việt', 'lỗi', 'đụng chạm', 'buồn', 'tiếc', 'blob', 'master', 'assets', 'llama2', 'mojodemo', 'gif']"
665,"DopikAI vừa công bố bài tóm tắt về ViGPT®, mô hình LLM tiếng Việt dựa trên instruction-fintuning với các nguồn dữ liệu tự thu thập, translate từ tiếng anh cũng như tự sinh với ChatGPT. 
Mô hình tập trung vào tác vụ hỏi đáp, đánh giá tính tự nhiên và tính đúng đắn câu trả lời được sinh ra để đảm bảo performance trên nhiều domain khác nhau. 
Nghiên cứu của nhóm đã được accept tại EMNLP 2023 (Industry Track).
Đọc ngay bài tóm tắt về ViGPT® tại: https://dopikai.com/files/Dopikai_ViGPT.pdf 
Đăng ký tham gia DopikAI's organization, để thử nghiệm các version của ViGPT®: https://huggingface.co/dopikai
Tham gia ngay DopikAI’s LLM Challenge để so sánh kết quả trên benchmark dataset với ViGPT®: https://aihub.vn/competitions/596 ","['#sharing', '#nlp']","['dopikai', 'công bố', 'tóm tắt', 'vigpt', 'mô hình', 'llm', 'tiếng', 'việt', 'dựa', 'instructionfintuning liệu', 'thu thập', 'translate', 'tiếng', 'sinh chatgpt', 'mô hình', 'tác vụ', 'đáp nhiên', 'đắn', 'câu', 'sinh', 'performance domain', 'nghiên cứu', 'accept', 'emnlp', '2023', 'industry track', 'đọc', 'tóm tắt', 'vigpt', 'đăng ký', 'tham gia', 'dopikai', 's', 'organization', 'thử nghiệm', 'version', 'vigpt', 'tham gia', 'dopikai', 's', 'llm', 'challenge', 'sánh', 'kết', 'benchmark', 'dataset', 'vigpt']"
666,"Chào mọi người, em đang tìm hiểu về Explainable AI thì có cái từ ""agnostic"" là em không hiểu lắm. Nếu dịch trực tiếp ra thì là ""bất khả tri"", nhưng em thấy nó chưa thỏa đáng. Mọi người có ai đã từng tìm hiểu giải nghĩa giúp em với ạ.",['#Q&A'],"['chào', 'explainable agnostic', 'lắm', 'dịch', 'bất khả tri', 'thỏa', 'giải nghĩa', 'giúp']"
667,"Em chào mng ạ.
Mng có thể chia sẻ cho em lộ trình để học xây dựng 1 AI-Chatbot (có kèm theo khóa Udemy càng tốt ạ).
Em cảm ơn mng nhìu","['#Q&A', '#nlp']","['chào', 'mng', 'mng thể', 'lộ trình', 'học', 'xây dựng', '1', 'aichatbot', 'kèm', 'khóa', 'udemy', 'mng', 'nhìu']"
668,Xin được chia sẻ với mọi người video giải thích paper Segment Anything bằng tiếng Việt ạ. Rất mong nhận được góp ý từ mọi người ạ,"['#sharing', '#cv']","['video', 'giải', 'paper', 'segment', 'anything', 'tiếng', 'việt', 'mong', 'góp']"
669,"Em tạo một mạng neural 2 lớp ẩn với hàm kích hoạt cho 2 lớp ẩn là ReLU và hàm đầu ra là hàm dự đoán sofmax. Em có test thử nhiều lần thì hầu như hàm loss giảm rất nhanh. Nhưng một số lần hàm loss không giảm. Em không biết là do em sai ở đâu. hay là do đặc tính của hàm ReLU.
Mà em cũng thử dùng hàm sigmoid làm hàm kích hoạt. Tuy loss giảm lâu hơn nhưng em thấy nó ổn định hơn hàm ReLU.","['#Q&A', '#deep_learning']","['mạng', 'neural', '2', 'lớp', 'ẩn hàm kích hoạt', '2', 'lớp', 'ẩn', 'relu', 'hàm', 'đầu', 'hàm', 'dự đoán', 'sofmax', 'test', 'thử', 'hầu hàm', 'loss', 'hàm loss', 'sai', 'đặc hàm', 'relu', 'thử', 'hàm', 'sigmoid', 'hàm kích', 'hoạt loss', 'ổn định', 'hàm relu']"
670,"Trong bài viết này, chúng ta tìm hiểu về một số lĩnh vực ứng dụng chính và cách AI đang chuyển đổi lĩnh vực nghiên cứu gen, đã dẫn đến những đột phá nhanh chóng trong lĩnh vực y tế và khám phá thuốc.
#AI #Healthcare #Genomics",['#sharing'],"['viết', 'ta', 'lĩnh vực', 'ứng dụng', 'đổi', 'lĩnh vực', 'nghiên cứu', 'gen', 'đột phá', 'chóng', 'lĩnh vực', 'y tế', 'khám phá', 'thuốc']"
671,"MỜI THAM GIA KALAPA BYTEBATTLES 2023
Hi mọi người. Mình là Cương, Project Manager tại KALAPA - một startup trong lĩnh vực công nghệ và Trí tuệ nhân tạo. Tiếp nối thành công của KALAPA Credit Scoring Challenge 2020 với hơn 800 người tham gia, năm nay công ty mình, dưới sự bảo trợ của Hội Tin học Việt Nam, tiếp tục tổ chức một cuộc thi AI có tên gọi KALAPA BYTEBATTLES. Cuộc thi năm nay gồm 2 bài toán, trong đó có một bài toán chưa từng xuất hiện ở các cuộc thi khác: Vietnamese Medical Multiple-choice Question Answering, hứa hẹn mang lại nhiều thử thách hấp dẫn và nhiều đóng góp mới cho cộng đồng làm AI ở Việt Nam.
Ngoài ra bọn mình cũng sẽ tổ chức trận chung kết dưới hình thức đối kháng 1vs1 giữa model của các đội, hy vọng sẽ mang lại luồng gió mới giữa các cuộc thi được tổ chức hiện nay.
Thông tin về cuộc thi có tại: https://challenge.kalapa.vn/
 — với Thu Thuỷ và Đan Thy.",['#sharing'],"['mời', 'tham gia', 'kalapa', 'bytebattles', '2023', 'hi cương', 'project', 'manager', 'kalapa', 'startup', 'lĩnh vực', 'công nghệ trí tuệ', 'nhân', 'tiếp nối', 'thành công', 'kalapa', 'credit', 'scoring', 'challenge', '2020', '800', 'tham gia', 'công ty', 'bảo trợ', 'hội học', 'việt nam', 'tổ chức', 'thi', 'gọi', 'kalapa', 'bytebattles', 'thi', '2', 'toán toán', 'thi', 'vietnamese', 'medical', 'multiplechoice', 'question', 'answering', 'hứa hẹn', 'thử thách hấp', 'đóng góp', 'cộng đồng', 'việt nam', 'bọn', 'tổ chức', 'trận', 'kết', 'hình thức', 'đối kháng', '1', 'vs1', 'model', 'đội', 'hy vọng', 'luồng', 'gió thi', 'tổ chức', 'thông thi', 'https', 'challenge', 'kalapa', 'vn', 'thu', 'thủy', 'đan', 'thy']"
672,"Mn cho em tham khảo ý kiến về topic clustering text với ạ.
E định sử dụng tf-idf với clustering algorithm (k-means, dbscan,..) để làm case này. Nhưng data text nó khá ngắn (1 row trung bình chỉ 6 7 từ), và viết sai chính tả với viết không dấu cũng có nên mn có suggest j cho việc preprocess đống này hong ạ (e tính unidecode nó hết lun xong traceback lại cái ban đầu).
Mong nhận được góp ý của mọi người ạ, cảm ơn mn nhìu, e cx mới mò về NLP nên mn thông cảm.","['#Q&A', '#nlp']","['mn', 'tham khảo', 'kiến', 'topic', 'clustering', 'text', 'e định', 'tfidf', 'clustering', 'algorithm', 'kmeans', 'dbscan', 'case', 'data', 'text', 'ngắn', '1', 'row', 'trung bình', '6', '7', 'viết', 'sai tả', 'viết', 'dấu', 'mn', 'suggest', 'j', 'preprocess', 'đống', 'hong', 'e unidecode', 'lun', 'xong', 'traceback', 'ban đầu', 'mong', 'góp', 'mn', 'nhìu', 'e cx', 'mò', 'nlp', 'mn', 'thông cảm']"
673,"Các bạn vui lòng đăng tin tuyển sinh, tuyển dụng, sự kiện tháng 12/2022 vào comment của post này.",['#sharing'],"['vui', 'đăng tuyển sinh', 'tuyển dụng', 'kiện', '12', '2022', 'comment', 'post']"
674,"Hi mọi người, hiện tại em đang làm project dự đoán kết quả thí nghiệm vật liệu xây dựng bao gồm nhiều models khác nhau nhằm đánh giá nhiều khía cạnh của thí nghiệm. Em đang sử dụng RestAPI để call artifact từ MLFlow sau đó predict xuất ra kết quả, bên cạnh đó có chạy đồng thời tính SHAP values để giải thích model.
1. Em đang gặp vấn đề trả kết quả khá lâu vì input đầu vào khoảng 1000 data ( mất tầm 3 phút), em muốn hỏi có cách nào tối ưu để giúp mô hình predict nhanh hơn không ạ ?
2. Theo em biết, các model từ library sklearn không sử dụng GPU, nên kết quả trả ra là tuần tự, liệu có cách nào chạy tất cả kết quả cùng 1 lúc ?
Em gửi cấu hình hiện tại của máy em ạ, em cảm ơn👩‍💻","['#Q&A', '#python']","['hi project', 'dự đoán', 'kết thí nghiệm', 'vật liệu', 'xây dựng', 'bao', 'models', 'khía cạnh', 'thí nghiệm', 'restapi', 'call', 'artifact', 'mlflow', 'predict', 'xuất kết', 'cạnh', 'chạy', 'shap', 'values', 'giải', 'model', '1', 'kết', 'input', 'đầu', '1000', 'data', 'tầm', '3', 'phút', 'tối ưu', 'giúp', 'mô hình', 'predict', '2', 'model', 'library', 'sklearn', 'gpu', 'kết liệu', 'chạy', 'tất kết', '1', 'gửi', 'cấu hình', 'máy']"
675,"Mọi người có ai làm về cái nhận diện xem người tham gia giao thông có đội mũ bảo hiểm rồi trích xuất biển số chưa, nếu rồi thì có thể cho e xin link tham khảo được không ạ?","['#Q&A', '#cv']","['diện', 'tham gia', 'giao thông', 'đội', 'mũ bảo hiểm', 'trích', 'xuất', 'biển thể', 'e link', 'tham khảo']"
676,"DopikAI vừa public DPKLLM Benchmark - Bộ benchmark dataset dành riêng cho LLM tiếng Việt, dưới dạng một challenge tổ chức trên aihub. DPKLLM tiến hành đánh giá trên nhiều tập dataset với nhiều tác vụ khác nhau

ViLaw-QA: Tập trung vào vấn đề hỏi đáp trên miền dữ liệu về luật pháp Việt Nam
VitruthfulQA: Tập trung đánh giá tính trung thực của các câu trả lời được sinh bởi LLM (tương tự TruthfulQA nhưng dành cho tiếng Việt)
Các tập dữ liệu chuyên về hỏi đáp của các bên khác như ViWikiQA, ViCoQA, ViNewsQA, ...
Ngoài ra, challenge cũng xem xét đánh giá tác vụ NER với tiếng Việt của LLM 

Đây là cơ hội để các cá nhân, tổ chức đang phát triển LLM có thể tham gia đánh giá và so sánh kết quả của mình với các bên khác cũng như trao đổi và học hỏi lẫn nhau. Challenge kéo dài vô thời hạn, và mọi người có thể dễ dàng đăng ký tham gia cũng như submit kết quả lên hệ thống. ","['#sharing', '#data']","['dopikai', 'public', 'dpkllm', 'benchmark', 'benchmark', 'dataset', 'llm', 'tiếng', 'việt', 'dạng', 'challenge', 'tổ chức', 'aihub', 'dpkllm', 'tiến hành', 'tập', 'dataset tác', 'vụ', 'vilawqa đáp', 'miền', 'liệu', 'luật pháp', 'việt nam', 'vitruthfulqa', 'trung thực', 'câu', 'sinh', 'llm', 'tương truthfulqa', 'tiếng', 'việt', 'tập liệu', 'chuyên đáp', 'viwikiqa', 'vicoqa', 'vinewsqa', 'challenge', 'xét tác', 'vụ', 'ner', 'tiếng', 'việt', 'llm hội', 'tổ chức', 'phát triển', 'llm thể', 'tham gia', 'sánh kết', 'trao đổi', 'học', 'lẫn', 'challenge', 'kéo', 'vô thời hạn thể dàng', 'đăng ký', 'tham gia', 'submit kết', 'hệ thống']"
677,"Tuy không liên quan tới ML/DL/AI, nhưng thống kê luôn có vai trò rất quan trọng trong Khoa học dữ liệu. Dưới đây là thông tin về lớp học do GS Richard McElreath đang giảng bài về cuốn sách của GS có tên""Statistical Rethinking (2023 Edition)"" theo trường phái thống kê Bayesian trong 10 tuần. Các bạn có thể theo dõi tại đây https://github.com/rmcelreath/stat_rethinking_2023. Tại địa chỉ GitHub này, bài giảng ghi hình và upload 2 lần/tuần.",['#sharing'],"['ml', 'dl', 'thống kê', 'vai trò', 'khoa học liệu', 'thông', 'lớp học', 'gs', 'richard', 'mcelreath', 'giảng', 'sách', 'gs', 'statistical', 'rethinking', '2023', 'edition', 'trường phái', 'thống kê', 'bayesian', '10', 'tuần thể', 'dõi', 'https', 'github', 'com', 'rmcelreath', 'stat_rethinking_2023', 'địa github', 'giảng', 'ghi hình', 'upload', '2', 'tuần']"
678,"Chào các Anh, Chị,
Sau khi tìm hiểu về mô hình ARIMA trong time-series em thắc mắc một số vấn đề như sau:
1) Ưu điểm, nhược điểm của Arima model.
2) Arima thích hợp với bài toán time-series hay không? khi nào thì mình nên dùng ARIMA sẽ cho kết quả tốt.?
3) Arima và LSTM thì phương pháp nào thường sẽ cho kết quả tốt hơn.
Em rất mong nhận được những góp ý, thảo luận của các Anh Chị, để em có thể nâng cao được thêm kiến thức ạ.","['#Q&A', '#deep_learning']","['chào', 'mô hình', 'arima', 'timeseries', 'thắc mắc', '1', 'ưu nhược', 'arima', 'model', '2', 'arima', 'hợp toán', 'timeseries', 'arima', 'kết', '3', 'arima', 'lstm', 'phương pháp', 'kết mong', 'góp', 'thảo luận thể', 'nâng', 'kiến thức']"
679,"Xin chào mn,
Hiện tại em đang làm một đồ án có liên quan tới một hệ thống kết nối cộng đồng AI. Đối tượng tham gia cộng đồng này sẽ là những người có kiến thức về AI, những người muốn tìm job về AI, những người có nhu cầu thuê người làm dự án AI,... Thì ở đây thầy em có yêu cầu sẽ dùng AI để hệ thống có thể đề xuất những người phù hợp nhất với dự án mà người chủ dự án đã đăng. Cụ thể, những người chủ án sẽ post dự án lên. Và những sẽ theo kèm đó là description của dự án. Dựa vào đó, hệ thống sẽ recommend những người có role phù hợp cho dự án đó. ( Đồ án này chỉ giới hạn pair matching giữa những dự án làm về AI với những người làm liên quan tới lĩnh vực AI thôi ạ). Mn có ai đã từng làm qua có thể cho em xin nguồn tham khảo được không ạ. Em có tham khảo qua recommandation system cũng như ứng dụng NLP nhưng vẫn chưa tìm được hướng đi rõ ràng ạ. Em cảm ơn mn ạ.",['#Q&A'],"['chào mn', 'đồ án', 'hệ thống', 'kết nối', 'cộng đồng', 'đối tượng', 'tham gia', 'cộng đồng', 'kiến thức', 'job', 'nhu cầu', 'thuê', 'dự án', 'thầy', 'hệ thống thể', 'đề xuất', 'dự án', 'chủ', 'dự án', 'đăng', 'chủ án', 'post', 'dự án', 'kèm', 'description', 'dự án', 'dựa', 'hệ thống', 'recommend', 'role', 'dự án', 'đồ án', 'giới hạn', 'pair', 'matching', 'dự án', 'lĩnh vực', 'mn thể', 'tham khảo', 'tham khảo', 'recommandation system', 'ứng dụng', 'nlp', 'hướng', 'đi', 'ràng', 'mn']"
680,"Chào mn, em là sinh viên năm cuối hiện đang tìm hiểu về lĩnh vực ML, DL, AI. Về phần đồ án tốt nghiệp của em thầy có bảo phải sử dụng mô hình AI để nhận dạng được tiếng ồn của máy (máy hoạt động ổn định hay không). Tuy nhiên trên trường em chỉ được học AI trong xử lý dữ liệu, xử lý ảnh thôi chứ chưa đến mức xử lý âm thanh. Em có tìm hiểu nhiều nguồn về xử lý âm thanh mà thấy có vẻ không đúng trong tâm lắm (chủ yếu về nhận diện giọng nói)? Anh chị nào có nguồn nào xử lý âm thanh (như sách, vidieo, khoá học hay) có thể recommend em với ạ, càng chi tiết càng tốt để sau này bảo vệ đồ án ổn ạ!
Em cám ơn mn đã bỏ thời gian đọc bài viết!",['#Q&A'],"['chào mn', 'sinh viên', 'hiện', 'lĩnh vực', 'ml', 'dl', 'đồ án nghiệp', 'thầy', 'bảo', 'mô hình', 'dạng', 'tiếng', 'ồn máy', 'máy', 'hoạt động', 'ổn định nhiên', 'trường học liệu', 'ảnh', 'âm âm', 'vẻ tâm', 'lắm', 'chủ yếu', 'diện', 'giọng', 'âm sách', 'vidieo khóa', 'học thể', 'recommend', 'chi tiết', 'bảo vệ', 'đồ án', 'ổn', 'cám ơn', 'mn', 'đọc', 'viết']"
681,"Sau bao ngày chờ đợi, nhóm dịch sách cuối cùng cũng đã hoàn thiện tập hai.
Các bạn đã đăng ký tập hai từ lần trước chuẩn bị nhận sách nhé!",['#sharing'],"['bao', 'chờ đợi', 'dịch', 'sách', 'hoàn thiện', 'tập', 'hai', 'đăng ký', 'tập', 'hai', 'chuẩn', 'sách']"
682,Cho em hỏi sao loss function không có sigma đằng trước ạ,"['#Q&A', '#math']","['loss', 'function', 'sigma', 'đằng']"
683,"Em chào các anh chị, em là sinh viên năm 3 đang tìm hiểu về Computer Vision, cụ thể là về xử lý dữ liệu 3D. Em có tìm hiểu mộ5t vài thông tin trên mạng nhưng đa số là paper mà em đọc thì thấy khó hiểu với có nhiều cái căn bản em chưa biết. Anh chị có thể cho em xin một số cuốn sách nào về lĩnh vực này để em có thể tìm hiểu từ cơ bản trước không ạ. Em xin cảm ơn ạ.","['#Q&A', '#cv']","['chào', 'sinh viên', '3', 'computer', 'vision liệu', '3', 'd', 'mộ5t', 'thông mạng', 'đa paper', 'đọc thể', 'sách', 'lĩnh vực', 'thể']"
684,"Mọi người ơi, mọi người cho em hỏi là làm sao kiểm soát được câu trả lời của chat gpt api vậy ạ? Em có tích hợp vào chatbot đưa thông tin sản phẩm giá 300k mà nó trả lời khách 150k. Em có tìm các thuộc tính của nó và đọc các tài liệu rồi nhưng mà vẫn chưa tìm ra ạ","['#Q&A', '#nlp']","['kiểm soát', 'câu', 'chat', 'gpt', 'api tích', 'hợp', 'chatbot thông', 'sản phẩm', 'giá', '300', 'k', '150', 'k', 'đọc', 'tài liệu']"
685,"Chào mọi người ạ. Hiện tại em đang làm bài tập python cần dùng turicreate để sử dụng sframe. Nhưng không thể cài được để sử dụng. Trên group có ai từng sử dụng turicreate hoặc tương tự chỉ giúp e với ạ. Em đang chạy song song Win 10 và Ubuntu 18.04 ạ.
Cảm ơn mọi người!!!","['#Q&A', '#python']","['chào tập', 'python', 'turicreate', 'sframe thể', 'cài', 'group', 'sử du ng', 'turicreate', 'tương giúp', 'e', 'chạy', 'song song', 'win', '10', 'ubuntu', '18', '04', 'ngươ', 'i']"
686,"Mọi người cho em hỏi cách cài đặt Turicreate trên Python được không ạ. Em có thử làm theo những cách ở trên mạng nhưng vẫn bị báo lỗi ấy ạ.
Em cảm ơn mọi người trước",['#Q&A'],"['cài', 'turicreate', 'python', 'thử', 'mạng', 'báo', 'lỗi']"
687,"Em chào mọi người ạ, chuyện là em đang làm một project về sinh ảnh biển báo giao thông sử dụng mô hình diffusion. Em muốn hỏi mọi người, mình muốn lấy datasets biển báo giao thông chỗ nào ổn ạ. Em cảm ơn mọi người rất nhiều ạ","['#Q&A', '#cv']","['chào', 'project sinh', 'ảnh', 'biển báo', 'giao thông', 'mô hình', 'diffusion', 'datasets', 'biển báo', 'giao thông', 'chỗ', 'ổn']"
688,"Chào mọi người, mình muốn chia sẻ 1 python package NLP mình build cho công việc + cá nhân, mọi người có thể dùng thử và cho mình feedback để mình improve cái package này hơn nhé, tại đây cũng là tâm huyết của mình mấy tháng qua 😅
Thư viện này mình build gồm 2 phần chính,
- P1: Supervised learning: dùng HuggingFace's masked language model (có thể sử dụng phobert hay envibert luôn) hay causal language model (kiểu của gpt, cho tiếng việt thì có NlpHUST/gpt2-vietnamese) cho các task: classification, regression; vừa classification vừa regression, classification các level khác nhau (mình gọi nó là multihead); và cả multilabel
- P2: Language model training: cho phép mình train 1 LLM (masked hoặc causal) from scratch, hoặc là cho LM fine-tuning (kiểu mình dùng phobert mà đã được train trên tập dataset tiếng việt rất lớn gồm wikipedia hay báo), xong mình train tiếp nó cho tập data comment của user trên sàn e-commerce, để nó đc finetune tốt hơn trên tập data này). Idea này mình nhớ bắt đầu từ paper ULMFiT. Cái lợi của việc này là sau khi mình cho model train trên tập data này xong (e.g. data user comment), mình cho model học tiếp những cái supervised learning task nhắc tới ở phần 1, kiểu predict coi user này đang comment về category gì, thì độ chính xác của nó sẽ được boost lên 1 chút nữa.
Với từng phần ở trên thì mình chia nó thành 2 process: 1 process chuyên làm text preprocessing (có thể làm đa luồng luôn, vì backend mình dùng HuggingFace Datasets lib), e.g. load data, filter data, text transform, có cả text augmentation), và 1 process là để build model (để train model, log, save and load model ...)
Tất cả các thông tin mình có viết documentation và có tutorial cho từng đoạn, mọi người có thể xem qua ở đây: https://anhquan0412.github.io/that-nlp-library/. Cảm ơn mọi người ạ :D","['#sharing', '#python']","['chào', '1', 'python', 'package', 'nlp', 'build', 'công thể', 'thử', 'feedback', 'improve', 'package', 'tâm huyết', 'mấy', 'thư viện', 'build', '2', 'p1', 'supervised', 'learning', 'huggingface', 's', 'masked', 'language', 'model thể', 'phobert', 'envibert', 'causal', 'language', 'model', 'kiểu', 'gpt', 'tiếng', 'việt', 'nlphust', 'gpt2vietnamese', 'task', 'classification', 'regression', 'classification', 'regression', 'classification', 'level', 'gọi', 'multihead', 'multilabel', 'p2', 'language', 'model', 'training', 'phép', 'train', '1', 'llm', 'masked', 'causal', 'from', 'scratch', 'lm', 'finetuning', 'kiểu', 'phobert', 'train', 'tập', 'dataset', 'tiếng', 'việt', 'wikipedia', 'báo', 'xong', 'train', 'tiếp tập', 'data', 'comment', 'user', 'sàn', 'ecommerce', 'đc', 'finetune', 'tập', 'data', 'idea', 'paper', 'ulmfit lợi', 'model', 'train', 'tập', 'data', 'xong', 'e', 'g', 'data', 'user', 'comment', 'model', 'học', 'tiếp', 'supervised', 'learning', 'task', 'nhắc', '1', 'kiểu', 'predict', 'coi', 'user', 'comment', 'category độ', 'xác', 'boost', '1', 'chút', 'chia', 'thành', '2', 'process', '1', 'process', 'chuyên text', 'preprocessing thể', 'đa luồng', 'backend', 'huggingface', 'datasets', 'lib', 'e g', 'load', 'data', 'filter', 'data', 'text', 'transform', 'text', 'augmentation', '1', 'process', 'build', 'model', 'train', 'model', 'log save', 'and load', 'model', 'tất thông', 'viết', 'documentation', 'tutorial', 'đoạn thể', 'https', 'anhquan0412', 'github', 'io', 'thatnlplibrary', 'd']"
689,"Các bạn vui lòng đăng tin tuyển sinh, tuyển dụng, sự kiện tháng 02/2023 vào comment của post này.",['#sharing'],"['vui', 'đăng tuyển sinh', 'tuyển dụng', 'kiện', '02', '2023', 'comment', 'post']"
690,"Các bạn vui lòng đăng tin tuyển sinh, tuyển dụng, sự kiện tháng 9/2023 vào comment của post này.
Chúc các bạn có một kỳ nghỉ lễ vui vẻ.",['#sharing'],"['vui', 'đăng tuyển sinh', 'tuyển dụng', 'kiện', '9', '2023', 'comment', 'post', 'chúc kỳ', 'nghỉ', 'lễ', 'vui vẻ']"
691,Mng cho em hỏi: ai có tập dataset liên quan đến các chỉ số về chất lượng không khí như này ở việt nam không ạ.,"['#Q&A', '#data']","['mng', 'tập', 'dataset', 'chất khí', 'việt nam']"
692,"Hi anh chị, em đang làm bài tập về Linear Regression dự đoán giá nhà bằng thuật toán Gradient Decent( Giảm độ dốc), nhưng sau khi em test thử model thì các giá trị predicton nó có giá trị ""nan"" là bị sao vậy ạ, mô hình này em test với tập dữ liệu nhỏ thì nó cho ra các dự đoán khá sát với các giá trị thực tế, nhưng khi em thử các tập dữ liệu khá lớn thì các giá trị prediction bằng ""nan"", em đã thử điều chỉnh learing rate nhưng không có kết quả ạ. Mong mọi người giúp đỡ, em cảm ơn ạ !
Link github: https://github.com/bigboss151102/Linear_Regression/blob/master/prediction_house_TUD.ipynb","['#Q&A', '#machine_learning']","['hi tập', 'linear', 'regression', 'dự đoán', 'giá', 'thuật toán', 'gradient', 'decent độ', 'dốc', 'test', 'thử', 'model', 'predicton nan', 'mô hình', 'test', 'tập liệu', 'dự đoán', 'sát', 'thử', 'tập liệu', 'prediction nan', 'thử', 'chỉnh', 'learing', 'rate', 'kết mong', 'giúp đỡ', 'link', 'github']"
693,"Xin chào mọi người, em có ý định sẽ tạo ra một con AI / ML có khả năng generate ra model 3d nhà theo phong cách kiến trúc Việt Nam, ngoài ra em cũng tò mò, muốn hiểu sâu về cơ chế hoạt động, hiểu rõ bản chất của các ứng dụng giả giọng nói ạ. Nhưng hiện tại kiến thức về ML hay AI của em gần như bằng 0, do đó e đã đặt ra mục tiêu dài hạn sẽ học về AI / ML để hoàn thành đc mục tiêu e đã đề cập ạ
Vì vậy có bác nào rành về lĩnh vực này có thể tư vấn giúp em lộ trình học hiệu quả theo hướng có thể giải quyết đc 2 nhu cầu trên của e ko ạ, em cám ơn.",['#Q&A'],"['chào định', 'ml', 'khả năng', 'generate', 'model', '3', 'd phong', 'kiến trúc', 'việt nam', 'tò mò', 'sâu chế', 'hoạt động', 'chất', 'ứng dụng', 'giả giọng', 'kiến thức', 'ml', '0', 'e', 'mục tiêu', 'hạn', 'học', 'ml', 'hoàn thành', 'đc', 'mục tiêu', 'e', 'đề cập', 'rành', 'lĩnh vực thể', 'tư vấn', 'giúp', 'lộ trình', 'học hiệu', 'hướng thể', 'giải quyết', 'đc', '2', 'nhu cầu', 'e ko', 'cám ơn']"
694,"Em đang tập tành chuyển qua google colab nhưng khi upload file lên thì các hình ảnh trong Markdown đều bị lỗi không load được mặc dù đã đúng đường dẫn ạ.
Edit:
Sau một hồi nghiên cứu thì có vẻ như thẻ <img> trong MarkDown không hoạt động trong đường dẫn local vì một lý do nào đó (trong khi sử dụng cùng format đường dẫn để read file thì ok) nhưng lại hoạt động được với các URL global. Dưới đây là video cách lấy link các file ảnh trong google drive để sử dụng vào colab.
Anh em nào có phương pháp hay ý kiến tốt hơn mời bình luận bên dưới ạ. Thank
https://www.youtube.com/watch?v=gCsmANNdmfo",['#Q&A'],"['tập', 'tành', 'google', 'colab', 'upload', 'file', 'hình ảnh', 'markdown', 'lỗi', 'load', 'mặc', 'đường', 'edit hồi', 'nghiên cứu', 'vẻ', 'thẻ img', 'markdown', 'hoạt động', 'đường', 'local lý', 'format', 'đường', 'read', 'file ok', 'hoạt động', 'url', 'global', 'video', 'link', 'file', 'ảnh', 'google', 'drive', 'colab', 'phương pháp kiến', 'mời', 'bình luận', 'thank']"
695,"Chào buổi tối mọi người,
Lúc launching Vietcuna thì team VILM có hứa sẽ có phiên bản 40B của Vietcuna. Hôm nay team rất vui giới thiệu 2 model mới nhất của team là Vulture-40B và Vulture-180B với hỗ trợ lên tới 12 ngôn ngữ, tất nhiên là có hỗ trợ tiếng Việt. VILM mong Vulture series sẽ là công cụ đắc lực giúp các công ty Việt Nam vươn ra biển lớn! 🙂
Supported Languages: English, German, Spanish, French, Portugese, Russian, Italian, Vietnamese, Indonesian, Chinese, Japanese and Chinese
Announcement: [https://www.vilm.org/research/meet-vulture-40b-and-180b-worlds-largest-multilingual-language-models]
Vulture-40B: [https://huggingface.co/vilm/vulture-40b]
Vulture-180B: [https://huggingface.co/vilm/vulture-180b]","['#sharing', '#nlp']","['chào', 'tối', 'launching', 'vietcuna', 'team', 'vilm', 'hứa', 'phiên', '40', 'b', 'vietcuna', 'hôm', 'team', 'vui', 'giới thiệu', '2', 'model', 'team', 'vulture40b', 'vulture180b', '12', 'ngôn ngữ', 'tất nhiên', 'tiếng', 'việt', 'vilm', 'mong', 'vulture', 'series', 'công cụ', 'đắc lực', 'giúp', 'công ty', 'việt nam', 'vươn', 'biển', 'supported', 'languages', 'english', 'german', 'spanish', 'french', 'portugese', 'russian', 'italian', 'vietnamese', 'indonesian', 'chinese japanese', 'and chinese', 'announcement', 'vulture40b', 'vulture180b']"
696,"Generative Knowledge AI đang phát triển với tốc độ vũ bão, nhất là các mô hình ngôn ngữ lớn (Large Language Models).
Tuy nhiên, lĩnh vực nghiên cứu ảnh tạo sinh với các mô hình như DALLE (hiện DALLE-3 đã được tích hợp vào ChatGPT-4(v), bản DALLE-2 có open source nhé) và đặc biệt là open source Stable Diffusions (ControlNet là 1 dạng variants từ SD) giữ vai trò quan trọng việc sáng tạo nội dung (content creation). Ví dụ ta có thể prompts ra ảnh annimate trong truyện tranh hay về lĩnh vực thiết kế công nghiệp/đồ hoạ/kiến trúc/xây dựng/..., ta có thể vẽ sketch rồi prompts cho ra sản phẩm “hoàn chỉnh”. Chưa kể chúng ta có thể nghiên cứu ứng dụng SD vào các domain chuyên ngành hẹp. Hi vọng mình có thể sớm ""khoe"" kết quả này trong thời gian sắp tới!!

Để làm sinh động hơn hình ảnh tĩnh tạo sinh, gần đây các nhà khoa học đã giới thiệu tới mọi người source code có thể tạo ảnh đông (*gif) có tên là Annimatediff (tại đây https://github.com/guoyww/AnimateDiff) và Hotshot (tại đây https://github.com/hotshotco/Hotshot-XL)
Cả 2 thư viện này giúp chúng ta finetune model SD thành dạng ảnh động (*gif) thay vì ảnh tĩnh (jpg/png).
Hi vọng thư viện này giúp các bạn học tập vào thực hành theo hướng mình mong muốn.","['#sharing', '#python']","['generative', 'knowledge', 'phát triển', 'tốc độ', 'vũ bão', 'mô hình', 'ngôn ngữ', 'large', 'language', 'models nhiên', 'lĩnh vực', 'nghiên cứu', 'ảnh sinh', 'mô hình', 'dalle', 'hiện', 'dalle3 tích', 'hợp', 'chatgpt4', 'v', 'dalle2', 'open', 'source', 'open', 'source', 'stable', 'diffusions', 'controlnet', '1', 'dạng', 'variants', 'sd', 'vai trò', 'nội dung', 'content', 'creation', 'ví dụ', 'ta thể', 'prompts', 'ảnh', 'annimate', 'truyện tranh', 'lĩnh vực', 'thiết kế', 'công nghiệp', 'đồ họa', 'kiến trúc', 'xây dựng', 'ta thể', 'vẽ', 'sketch prompts', 'sản phẩm', 'hoàn chỉnh', 'ta thể', 'nghiên cứu', 'ứng dụng', 'sd', 'domain', 'chuyên ngành', 'hẹp', 'hi vọng thể', 'khoe kết', 'sinh động', 'hình ảnh', 'tĩnh sinh', 'khoa học', 'giới thiệu', 'source', 'code thể', 'ảnh', 'đông', 'gif', 'annimatediff', 'https', 'github', 'com', 'guoyww', 'animatediff', 'hotshot', 'https', 'github', 'com', 'hotshotco', 'hotshotxl', '2', 'thư viện', 'giúp', 'ta', 'finetune', 'model', 'sd', 'thành', 'dạng', 'ảnh động', 'gif', 'thay', 'ảnh', 'tĩnh jpg', 'png', 'hi vọng', 'thư viện', 'giúp', 'học tập', 'thực hành', 'hướng', 'mong']"
697,"Một trong những yếu tố giúp chúng ta có prompts tốt để generate ra nội  mong muốn là việc làm khó. Nên mới có nghề mới gọi là prompt engineers/engineering. Dưới đây là tổng kết 6 điểm mà tôi copy&paste của Francois Chollet (tác giả bài báo về mô hình Inception và là người viết thư viện Keras của Google)
""My interpretation of prompt engineering is this:
1. A LLM is a repository of many (millions) of vector programs mined from human-generated data, learned implicitly as a by-product of language compression. A ""vector program"" is just a very non-linear function that maps part of the latent space unto itself.
2. When you're prompting, you're fetching one of these programs and running it on an input -- part of your prompt serves as a kind of ""program key"" (as in database key) and part serves as program argument(s). Like, in ""write this paragraph in the style of Shakespeare: {my paragraph}"", the part ""write this paragraph in the stye of X: Y"" is a program key, with arguments X=Shakespeare and Y={my paragraph}.
3. The program fetched by your key may or may not work well for the task at hand. There's no reason why it should be optimal. There are lots of related programs to choose from.
4. Prompt engineering represents a search over many keys in order a find a program that is empirically more accurate for what you're trying to do. It's no different than trying different keywords when searching for a Python library.
5. Everything else is unnecessary anthropomorphism on the part of the prompter. You're not talking to a human who understands language the way you do. Stop pretending you are.”
https://x.com/fchollet/status/1709242747293511939?s=46...
Mình từng có lần chia sẻ về việc có người tổng hợp các ảnh và prompts liên quan tới chủ để sinh ảnh. Mình sẽ tìm lại link GitHub của nó và chia sẻ bên dưới.","['#sharing', '#nlp']","['yếu tố', 'giúp', 'ta', 'prompts', 'generate', 'nội mong', 'nghề', 'gọi', 'prompt', 'engineers', 'engineering', 'tổng kết', '6', 'copy', 'paste', 'francois', 'chollet tác giả', 'báo', 'mô hình', 'inception', 'viết', 'thư viện', 'keras', 'google', 'my', 'interpretation', 'of prompt', 'engineering', 'is', 'this', '1', 'a llm', 'is', 'a', 'repository', 'of many', 'millions', 'of vector', 'programs', 'mined', 'from', 'humangenerated', 'data', 'learned', 'implicitly', 'as', 'a', 'byproduct', 'of language', 'compression', 'a vector', 'program', 'is', 'just', 'a', 'very', 'nonlinear', 'function', 'that', 'maps', 'part', 'of the', 'latent', 'space', 'unto', 'itself', '2', 'when', 'you', 're', 'prompting', 'you', 're', 'fetching', 'one', 'of', 'these programs', 'and running', 'it', 'on', 'an input', 'part', 'of your', 'prompt', 'serves', 'as', 'a', 'kind', 'of program', 'key', 'as', 'in', 'database key', 'and part', 'serves', 'as', 'program', 'argument', 's', 'like', 'in', 'write', 'this', 'paragraph', 'in', 'the', 'style', 'of shakespeare', 'my', 'paragraph', 'the', 'part', 'write', 'this', 'paragraph', 'in', 'the', 'stye of', 'x', 'y is', 'a', 'program', 'key', 'with', 'arguments', 'x', 'shakespeare', 'and y', 'my', 'paragraph', '3', 'the', 'program', 'fetched', 'by', 'your', 'key may', 'or', 'may', 'not', 'work', 'well', 'for', 'the', 'task', 'at', 'hand', 'there', 's', 'no', 'reason', 'why', 'it', 'should', 'be', 'optimal', 'there', 'are', 'lots', 'of related', 'programs', 'to', 'choose', 'from', '4', 'prompt', 'engineering', 'represents', 'a', 'search', 'over', 'many', 'keys', 'in', 'order', 'a find', 'a', 'program', 'that', 'is', 'empirically', 'more', 'accurate', 'for', 'what', 'you', 're', 'trying', 'to', 'it', 's', 'no', 'different', 'than', 'trying', 'different', 'keywords', 'when', 'searching', 'for', 'a', 'python', 'library', '5', 'everything', 'else', 'is', 'unnecessary', 'anthropomorphism', 'on', 'the', 'part', 'of the', 'prompter', 'you', 're', 'not', 'talking', 'to', 'a human', 'who', 'understands', 'language', 'the', 'way', 'you', 'stop', 'pretending', 'you', 'are', 'https', 'x', 'com', 'fchollet', 'status', '1709242747293511939', 's', '46', 'tổng hợp', 'ảnh', 'prompts', 'chủ sinh', 'ảnh', 'link', 'github']"
698,"Em chào mọi người , e là newbie , e mới train 1 model trên kaggle sau khi tập tành fine tuning 1 model (model đó fine tune dựa vào Llama2 và Blomz trên tập data tiếng việt ) trên hugging face xong thì e có nhấn save model , sau đó vào lại thì chỉ thấy có mấy file như adapter _model.bin , adapter_config.json , redme, events.out.tfevens , Sau đó em có tải koboldcpp về để chạy nhưng không được . Mọi người có biết cách nào để chạy file này ko ạ .Và input đầu vào có nhất thiết phải có dạng "" instruction , input ,output,response: , em muốn dùng văn bản text được không ạ ? em cảm ơn ạ!!!!","['#Q&A', '#nlp']","['chào', 'e newbie', 'e train', '1', 'model', 'kaggle', 'tập tành', 'fine', 'tuning', '1', 'model', 'model', 'fine', 'tune', 'dựa', 'llama2', 'blomz', 'tập', 'data', 'tiếng', 'việt', 'hugging', 'face', 'xong', 'e', 'nhấn', 'save', 'model', 'mấy', 'file', 'adapter', '_model bin', 'adapter_config', 'json', 'redme', 'events', 'out', 'tfevens tải', 'koboldcpp', 'chạy', 'chạy', 'file', 'ko', 'input', 'đầu', 'thiết dạng', 'instruction', 'input', 'output', 'response văn', 'text']"
699,"Xin phép chia sẻ với các bác về đồ án Text Image Retrieval của một học sinh khóa MLE em đang training. Model được deploy trên GKE và expose sử dụng Nginx Ingress. Jenkins để build CI/CD pipeline được deploy trên GCE sử dụng Ansible. Bên cạnh đó, bạn cũng dùng GKE để deploy các monitoring tools để observe hệ thống. README được viết rất chi tiết, nên em hy vọng sẽ là một nguồn tài liệu hữu ích khác bên cạnh MLOps Crash Course lần trước em chia sẻ 😃.
https://github.com/.../continuous-deployment-to-gke-cluster
Mọi người đừng quên động viên bạn Nguyen Tran Dang Duong một Github star nếu thấy có ích nhé ạ 😉.
Chúc các bác cuối tuần vui vẻ!","['#sharing', '#cv', '#nlp']","['phép', 'đồ án', 'text', 'image', 'retrieval', 'học sinh', 'khóa', 'mle', 'training', 'model', 'deploy', 'gke', 'expose', 'nginx', 'ingress', 'jenkins', 'build', 'ci', 'cd', 'pipeline', 'deploy', 'gce', 'ansible', 'cạnh', 'gke', 'deploy', 'monitoring', 'tools', 'observe', 'hệ thống', 'readme', 'viết', 'chi tiết', 'hy vọng', 'tài liệu', 'hữu ích', 'cạnh', 'mlops', 'crash', 'course', 'đừng', 'quên', 'động viên', 'nguyen', 'tran', 'dang', 'duong', 'github', 'star ích', 'chúc', 'tuần', 'vui vẻ']"
700,"Chào mọi người ạ!
Mọi người cho em hỏi là có ai đã từng pretraining (hoặc further training) TrOCR hoặc 1 multimodal nào đó bằng Hugging Face ko ạ? Em muốn hỏi để lấy thêm kinh nghiệm ạ!",['#Q&A'],"['chào', 'pretraining', 'further', 'training', 'trocr', '1', 'multimodal', 'hugging', 'face', 'ko', 'kinh nghiệm']"
701,"Chào mọi người ạ. Hiện tại em đang muốn có định hướng học AI. Em biết Python dụng để phát triển và huần luyện các model AI. Nhưng deploy model trong thực tế như viết một cái backend chẳng hạn thì cần hiệu suất cao hơn và nhanh hơn thì người ta dùng ngôn ngữ lập trình khác hoặc tích hợp AI vào hệ thống nhúng dùng C/C++. Mọi người ai đã đi làm ngoài thực tế xin khảo sát một vài ngôn ngữ lập trình thường mà công ty, doanh nghiệp của các anh chị thường sử dụng để deploy model AI ra thực tế với ạ. Em xin cảm ơn rất nhiều ạ.",['#Q&A'],"['chào', 'định hướng', 'học', 'python dụng', 'phát triển', 'huần luyện', 'model', 'deploy', 'model', 'viết', 'backend', 'chẳng hạn', 'hiệu suất', 'ta', 'ngôn ngữ', 'lập trình', 'tích hợp', 'hệ thống', 'nhúng', 'c', 'c', 'đi', 'khảo sát', 'ngôn ngữ', 'lập trình', 'công ty', 'doanh nghiệp', 'deploy', 'model']"
702,"Gần đây mình được cấp quyền sử dụng High Performance Computers (HPC), (còn trước đây chỉ có mỗi 1 máy với 1 GPU 3090, nên mình chỉ dùng AnyDesk để điều khiển từ xa), nên mình dành nhiều thời gian học để điều khiển nó. Vì vậy mình phải học một số công cụ như Tmate, Screen, SSH, Code Tunnel,... Nhưng quan trong hơn là phải học thêm nhiều về bash scripts. Nay thấy 1 repo khá thú vị hướng dẫn các bash scripts phổ biến dùng để huấn luyện các mô hình lớn trên HPC nên mình chia sẻ lại tại đây https://github.com/stas00/ml-engineering.
Hi vọng nó sẽ giúp ích với các bạn có điều kiện sử dụng HPC.",['#sharing'],"['quyền', 'high', 'performance', 'computers', 'hpc', '1', 'máy', '1', 'gpu', '3090', 'anydesk khiển', 'học khiển', 'học', 'công cụ', 'tmate', 'screen', 'ssh', 'code', 'tunnel', 'quan học', 'bash', 'scripts', '1', 'repo', 'thú vị', 'hướng', 'bash', 'scripts', 'phổ biến', 'huấn luyện', 'mô hình', 'hpc', 'https', 'github', 'com', 'stas00', 'mlengineering', 'hi vọng', 'giúp ích', 'kiện', 'hpc']"
703,"Cho mình hỏi embedding vectors tiếng Việt gọi sao vậy ạ? Mình dịch tạm là ""véc tơ nhúng"" nhưng có vẻ nó không thể hiện được tinh thần của chữ ""embedding""
Trong trang của ML cơ bản thì vẫn giữ nguyên chữ embedding: https://machinelearningcoban.com/tabml_book/ch_embedding/embedding.html
Có chăng mình không thể ""việt hoá"" hoàn toàn từ này?","['#Q&A', '#nlp']","['embedding', 'vectors', 'tiếng', 'việt', 'gọi', 'dịch', 'tạm', 'véc', 'tơ', 'nhúng vẻ', 'thể hiện', 'tinh thần', 'chữ', 'embedding trang', 'ml', 'nguyên', 'chữ', 'embedding thể', 'việt', 'hóa']"
704,"Generative AI (AI tạo sinh) và Predictive AI (AI dự đoán) khác nhau về cách chúng xử lý các ứng dụng và dữ liệu có cấu trúc lẫn phi cấu trúc tương ứng. Cùng tìm hiểu những lợi ích và các hạn chế của mỗi loại trong các ứng dụng thực tế của chúng.
#GenerativeAI #PredictiveAI #AI",['#sharing'],"['generative', 'sinh predictive', 'dự đoán', 'ứng dụng liệu', 'cấu trúc', 'lẫn', 'phi', 'cấu trúc', 'tương ứng', 'lợi ích', 'hạn chế', 'ứng dụng']"
705,"Chào các anh chị, các bạn, tiền bối trong ngành ạ. Mong anh chị cho em một chút nhận xét về CV này của em với ạ. Liệu đã đủ điều kiện để có thể xin đi thực tập chưa ạ. Nếu được mong anh chị cho em vài góp ý cần bổ sung và cải thiện thêm (cả hình thức và nội dung) ạ. Chúc mọi người một ngày tràn đầy năng lượng ạ.",['#sharing'],"['chào', 'tiền bối', 'ngành', 'mong', 'chút', 'xét', 'cv liệu', 'kiện thể', 'đi', 'thực tập', 'mong', 'góp', 'bổ sung', 'cải thiện', 'hình thức', 'nội dung', 'chúc', 'tràn năng']"
706,"Xin chào mọi người, anh chị trong nhóm ạ.Em xin phép hỏi là em đang nghiên cứu về mô hình học máy về data bên mảng xây dựng ạ, nên em muốn xin tài liệu tham khảo và code trên github cũng được ạ. Em xin cảm ơn rất nhiều.","['#Q&A', '#machine_learning']","['chào phép', 'nghiên cứu', 'mô hình', 'học', 'máy', 'data mảng', 'xây dựng', 'tài liệu', 'tham khảo', 'code', 'github']"
707,"Đại học Harvard vừa công bố khóa học về Data Science với Python thuộc bộ môn Computer Science.
Khóa học hoàn toàn miễn phí và kéo dài trong 8 tuần.
Link: https://pll.harvard.edu/.../introduction-data-science-python",['#sharing'],"['đại học', 'harvard', 'công bố', 'khóa', 'học', 'data', 'science', 'python', 'môn', 'computer', 'science', 'khóa học', 'miễn phí', 'kéo', '8', 'tuần', 'link']"
708,Tuần sau có anh chị các bạn nào tham gia ICCV ở Paris ko cùng kết nối tham gia xong thăm thú cho vui ạ 😄,['#Q&A'],"['tuần', 'tham gia', 'iccv', 'paris', 'ko', 'kết nối', 'tham gia', 'xong', 'thăm', 'thú vui']"
709,Hệ thống AI cải tiến có thể giải mã cảm xúc của gà.,['#sharing'],"['hệ thống', 'cải tiến thể', 'giải mã', 'cảm xúc', 'gà']"
710,"Chào mn. Em đang làm nhiệm vụ làm giảm thời gian inference model bert bởi phải infer tới 1 triệu câu . Em đang có ý tưởng là ghép các câu lại có dạng <cls> sentence A <sep> sentence b <sep> ...... . thì mình ghép được bao nhiêu câu thì tốc độ sẽ giảm đi từng đó lần , và bài toán yừ multi class sẽ chuyển thành multi label. Thế nhưng khi em ghép vào kết quả infer rất tệ (đã train trên câu ghép). Không biết mn ở đây đã ai từng làm chưa có thể cho em cái suggest không ạ. Em cảm ơn",['#Q&A'],"['chào mn', 'nhiệm vụ', 'inference', 'model', 'bert', 'infer', '1', 'triệu', 'câu', 'tưởng', 'ghép', 'câu', 'dạng', 'cls', 'sentence', 'a sep', 'sentence', 'b', 'sep', 'ghép', 'câu', 'tốc độ', 'đi toán', 'yừ', 'multi', 'class', 'thành', 'multi', 'label', 'ghép', 'kết', 'infer', 'tệ', 'train', 'câu', 'ghép', 'mn thể', 'suggest']"
711,Cẩm nang chi tiết cho bạn nào xây CV nhé,['#sharing'],"['cẩm nang', 'chi tiết', 'xây', 'cv']"
712,"Mn có biết báo nào hay web nào có những nghiên cứu model về tài chính, dữ liệu có độ tin cậy cao không ạ cho em xin với ạ",['#Q&A'],"['mn', 'báo web', 'nghiên cứu', 'model', 'tài liệu', 'độ', 'cậy']"
713,"Chào mọi người. Em đang làm 1 project nlp cần tiền xử lý dữ liệu văn bản tiếng Việt. Cho em hỏi có package nào hỗ trợ chuẩn hoá cách bỏ dấu câu (""òa"" - ""oà"", ""úy"" - uý) và lỗi y i (""mỳ"" - ""mì"", ""li ti"", ""cái ly"") không ạ.","['#Q&A', '#data', '#nlp']","['chào', '1', 'project', 'nlp', 'tiền liệu', 'văn tiếng', 'việt', 'package', 'chuẩn', 'hóa', 'dấu', 'câu', 'òa', 'òa', 'úy', 'úy', 'lỗi y', 'i', 'mỳ', 'mì', 'li ti', 'ly']"
714,"Dự án hiện tại của em là xây dựng một data engine cho một phòng lab thực tế ảo ( VR Experiment sử dụng Oculus). Vấn đề đặt ra là hiện tại lab ảo này đang sử dụng một số mock data từ lab thật được nạp vào và mỗi khi người dùng thực hiện hành động thì output sẽ là mock data chứ không phải là data thật.
Thầy muốn em tạo một data engine để học và dự đoán output dựa trên những data được lưu lại trước đó (lab thật có xuất ra một file excel lưu data những lần chạy) V
ậy thì, Em cần học những thuật toán gì? Công nghệ gì? Sử dụng data storage nào? Là tối ưu nhất ạ? Em có học qua computer vision và đã từng làm một số project về image classification nhưng chưa có kinh nghiệm nào về mảng này ạ.
Cảm ơn mn","['#Q&A', '#data']","['dự án', 'xây dựng', 'data', 'engine', 'phòng', 'lab', 'ảo', 'vr', 'experiment', 'oculus', 'lab', 'ảo', 'mock', 'data', 'lab nạp', 'hành động', 'output', 'mock', 'data', 'data', 'thầy', 'data', 'engine học', 'dự đoán', 'output', 'dựa', 'data', 'lưu lab', 'xuất file', 'excel', 'lưu data', 'chạy', 'v ậy', 'học thuật toán', 'công nghệ', 'data storage', 'tối ưu học', 'computer', 'vision', 'project', 'image', 'classification', 'kinh nghiệm', 'mảng', 'mn']"
715,"Xin chào mọi người, em thực hiện time series analysis với mô hình ARIMA dùng Python tuy nhiên nhận được giá trị dự đoán là gần giống như giá trị trung bình như hình ở dưới ạ. Data này đã lấy sai phân bậc 1 mà giá trị p,d,q thu được sau khi thử bằng auto_arima.
Xin mn chỉ giáo cách tiếp cận và sửa mô hình này ạ. Em cảm ơn nhiều.",['#Q&A'],"['chào', 'time', 'series', 'analysis', 'mô hình', 'arima', 'python nhiên', 'dự đoán', 'trung bình', 'hình', 'data', 'sai', 'phân bậc', '1', 'p', 'd', 'q', 'thu', 'thử', 'auto_arima', 'mn giáo', 'tiếp cận', 'sửa', 'mô hình']"
716,"#question
Mn cho e hỏi là học machine learning thì có nên học sâu về thuật toán (backtrack, đệ quy . . ) Em rất thích học thuật toán và vẫn học nó hàng ngày. Nhưng mà khi học ML thì nó có những thuật toán riêng không biết là cái việc học thuật toán nó có tác dụng gì khi mình theo ML không ạ ?
Em cảm ơn!","['#Q&A', '#math']","['mn', 'e học', 'machine', 'learning học', 'sâu thuật', 'toán', 'backtrack', 'đệ', 'quy học', 'thuật toán', 'học', 'hàng', 'học', 'ml thuật toán', 'học thuật toán', 'tác dụng', 'ml']"
717,"Em bị lỗi này mỗi khi submit cell trên jupyter, em đã kiểm tra java/bashrc/whichjava thì đều đã đúng đường dẫn kèm cài môi trường cho nó rồi.
Mọi người ai rành giúp em với em xin gửi bữa ăn sáng ạ :*",['#Q&A'],"['lỗi', 'submit', 'cell', 'jupyter', 'kiểm tra', 'java', 'bashrc', 'whichjava', 'đường', 'kèm cài', 'môi trường', 'rành giúp', 'gửi', 'bữa']"
718,"Xin chào mọi người, có anh/chị/em nào có biết web cho thuê server vật lý gpu để deploy api giá ngon / bổ/ rẻ không ạ ? , . Em biết 2 web là https://hostkey.com/ khá là ok nhưng mạng chập chờn quá ( hình như hay bị ddos ) . Các bác nào biết cho em xin với , em cảm ơn .",['#Q&A'],"['chào web', 'thuê', 'server', 'vật lý', 'gpu', 'deploy', 'api', 'giá', 'ngon bổ', 'rẻ', '2', 'web', 'https', 'hostkey', 'com', 'ok mạng', 'chập chờn', 'hình', 'ddos']"
719,"Mọi người ơi, cho em hỏi là vì sao pre-trained model như PhoBert, GPT-3 thì khi xây chatbot rasa với các model đó, em vẫn phải xác định intent và example ạ, kh phải nó dc train rồi hay sao ạ.
Em là newbie nên hỏi có khi hơi ngô nghê, mong mng bỏ qua.
Cảm ơn mng đã giải đáp","['#Q&A', '#nlp']","['pretrained', 'model', 'phobert', 'gpt3', 'xây', 'chatbot', 'rasa', 'model', 'xác định', 'intent', 'example', 'kh', 'dc', 'train', 'newbie', 'hơi', 'ngô', 'nghê', 'mong', 'mng', 'mng', 'giải đáp']"
720,"Hi mọi người, sau cuộc thi ZaloAi thì mình thấy Cinnamon AI marathon là cuộc thi có nhiều thú vị.
Trong cuộc thi này có 3 đề tài chính
- Handwriting OCR for Vietnamese Address
- Document Layout Analysis
- Real Time Facial LandMark Detection
Do mình thấy cuộc thi này khá thú vị mà không có nhiều cộng đồng support nên mình cung cấp code base của đề bài OCR cho mọi người tham khảo.
Về bài toán OCR thì chung ta cần nhận diện các kí tự trong hình ảnh scan của một đoạn text. Bộ dữ liệu gồm 2000 mẫu.
Mô hình mình sủ dụng là CRNN +CTCLoss. CNN dùng để extract features, sau đó đươc đưa vào RNN để nhận dạng kí tự tại timestep hiện tại.
Kết quả mình thấy khá khả quan, nhận diện cũng tương đối chính xác với normalize editdistance 0.28x.
Bạn nào có hưng thú tìm hiểu về OCR cũng như cuộc thi thì có thể tham khảo codebase này nhé.
----------------------------------------------
https://github.com/pbcquoc/vietnamese_ocr","['#sharing', '#cv', '#nlp']","['hi thi', 'zaloai', 'cinnamon', 'marathon', 'thi', 'thú vị', 'thi', '3', 'đề tài', 'handwriting', 'ocr', 'for', 'vietnamese', 'address', 'document', 'layout', 'analysis', 'real', 'time', 'facial', 'landmark', 'detection', 'thi', 'thú vị', 'cộng đồng', 'support', 'cung code', 'base', 'đề ocr', 'tham khảo', 'toán', 'ocr', 'ta', 'diện', 'kí', 'hình ảnh', 'scan', 'đoạn', 'text liệu', '2000', 'mẫu', 'mô hình', 'sủ dụng', 'crnn', 'ctcloss', 'cnn', 'extract', 'features', 'đươc', 'rnn', 'dạng', 'kí', 'timestep kết', 'khả quan diện', 'tương đối', 'xác', 'normalize', 'editdistance', '0', '28', 'x', 'hưng thú', 'ocr', 'thi thể', 'tham khảo', 'codebase']"
721,"Hello mọi người,
Hiện nay mình đang tìm hiểu về imbalanced dataset, mọi người có ai có biết sách nào nói về vấn đề này không, sách được phát hành ở việt nam càng tốt 😁","['#Q&A', '#data']","['hello', 'imbalanced', 'dataset', 'sách', 'sách', 'phát hành', 'việt nam']"
722,"Dường như các bạn có vẻ thích thú với chủ đề Machine Learning engineering mà mình post hôm qua tại đây (https://www.facebook.com/groups/machinelearningcoban/permalink/1784048968719169/).
Vậy nên, hôm nay mình chia sẻ tiếp một GitHub của Google có tới > 22k stars, có tên là Tuning_PlayBook về chủ đề làm sao ta có thể finetune pretrained models một cách hiệu quả cho downstream tasks như:
1/ Chọn kiến trúc models
2/ Chọn hàm tối ưu;
3/ Chọn Batch sizes;
4/ Huấn luyện model bao nhiêu epochs/steps;
5/ Đánh giá hiệu năng của models;
.... và nhiều thông tin thú vị khác nữa!!!
Các bạn có thể tham khảo repository này tại đây: https://github.com/google-research/tuning_playbook#deep-learning-tuning-playbook
Chúc các bạn thành công trong việc tối ưu dự án và quá trình học tập của mình!","['#sharing', '#machine_learning']","['dường', 'vẻ', 'thú', 'chủ đề', 'machine', 'learning', 'engineering', 'post', 'hôm', 'https', 'www', 'facebook', 'com', 'groups', 'machinelearningcoban', 'permalink', '1784048968719169', 'hôm', 'tiếp', 'github', 'google', '22', 'k', 'stars', 'tuning_playbook', 'chủ đề', 'ta thể', 'finetune', 'pretrained', 'models hiệu', 'downstream', 'tasks', '1', 'kiến trúc', 'models', '2', 'hàm', 'tối ưu', '3', 'batch', 'sizes', '4', 'huấn luyện', 'model', 'epochs', 'steps', '5', 'hiệu năng', 'models thông', 'thú vị thể', 'tham khảo', 'repository chúc', 'thành công', 'tối ưu', 'dự án', 'trình', 'học tập']"
723,"Hôm trước khá nhiều người hỏi về quy trình thu thập dữ liệu cũng như training của LLM Vietcuna từ VILM. Hôm nay team VILM chính thức công bố toàn bộ quy trình để làm ra Vietcuna.
Với hướng dẫn này kèm với model Vietcuna đã có sẵn, mong sẽ có nhiều bạn và doanh nghiệp Việt Nam tạo ra các sản phẩm AI mang tính thực tế cao trong cuộc sống :)
Link:","['#sharing', '#data']","['hôm', 'quy trình', 'thu thập liệu', 'training', 'llm', 'vietcuna', 'vilm', 'hôm', 'team', 'vilm thức', 'công bố', 'toàn', 'quy trình', 'vietcuna', 'hướng', 'kèm', 'model', 'vietcuna', 'sẵn mong', 'doanh nghiệp', 'việt nam', 'sản phẩm', 'sống', 'link']"
724,"Chào mọi người! Mình đang cần train model với bộ data khoảng 129GB dạng zip, nhưng với colab free thì nó chỉ có khoảng 70 gb ổ nhớ free. Có cách nào khác để train không giúp mình với ạ. Mong mn giúp đỡ ạ.","['#Q&A', '#data']","['chào', 'train', 'model', 'data', '129', 'gb', 'dạng', 'zip', 'colab', 'free', '70', 'gb', 'ổ', 'free', 'train', 'giúp', 'mong', 'mn', 'giúp đỡ']"
725,"Hôm trước mình thấy có một số câu hỏi về server và colab, thực sự, mình cũng đã gặp khá nhiều vấn đề với giới hạn thời gian sử dụng colab, giới hạn dung lượng RAM và giới hạn phần cứng. Mình đã phải mua gói pro hoặc thậm chí là gói pro+ để khắc phục vấn đề này. Tuy nhiên, việc đó vẫn không hoàn toàn thuận lợi vì đôi khi mình quên tắt colab, dẫn đến việc nó treo và tiếp tục trừ tài khoản tính tiền, như gói pro+ giá $49 mỗi tháng. Gần đây, mình đã tìm ra một giải pháp tốt hơn là sử dụng Gradient. Gradient cung cấp cho chúng ta một container Docker hoàn chỉnh cho mỗi notebook, và dữ liệu được gắn kết trực tiếp với máy chủ chính. Hơn nữa, phiên bản miễn phí của Gradient cung cấp 5GB dung lượng lưu trữ vĩnh viễn, dữ liệu trong đó không bị mất, ngay cả khi notebook gặp vấn đề và mình xóa toàn bộ. Bạn có thể sử dụng Gradient miễn phí trong 6 giờ liên tục cho mỗi phiên notebook, nó sẽ không bị tắt giữa chừng như colab. Điều thú vị là với gói pro chỉ $8 mỗi tháng, bạn có thể trải nghiệm nhiều cấu hình miễn phí tuyệt vời, ví dụ như P5000 với 30GB RAM, 8G CPU và 16GB GPU, hoặc A400 với 45GB RAM, 8G CPU và 16GB GPU... Quan trọng là sau 6 giờ, bạn có thể kết nối và tiếp tục sử dụng với khoản phí $8 đó, như một khoản phí duy trì. Nếu bạn đăng ký gói GROWTH, bạn sẽ có nhiều máy chủ miễn phí hơn, thậm chí có A100 với 80GB GPU miễn phí :)). Tuy nhiên, với phiên bản miễn phí, sau 6 giờ sử dụng, nó sẽ tự động tắt và bạn cần tìm một máy chủ khác để kết nối tiếp. Tóm lại, mình thấy Gradient ngon hơn nhiều so với colab 😂😂.",['#sharing'],"['hôm', 'server', 'colab', 'thực giới hạn', 'colab', 'giới hạn dung', 'ram', 'giới hạn', 'cứng', 'mua', 'gói', 'pro chí', 'gói pro', 'khắc phục nhiên', 'thuận lợi', 'đôi', 'quên', 'tắt', 'colab', 'treo', 'trừ', 'tài khoản', 'tiền', 'gói', 'pro', 'giá', '49', 'giải pháp', 'gradient', 'gradient', 'cung', 'ta', 'container', 'docker', 'hoàn chỉnh', 'notebook liệu', 'gắn kết', 'máy', 'chủ', 'phiên', 'miễn phí', 'gradient', 'cung', '5', 'gb dung', 'lưu trữ', 'vĩnh viễn liệu', 'notebook xóa', 'toàn thể', 'gradient', 'miễn phí', '6', 'liên tục', 'phiên', 'notebook', 'tắt chừng', 'colab', 'thú vị', 'gói', 'pro', '8', 'thể', 'trải nghiệm', 'cấu hình', 'miễn phí', 'tuyệt vời', 'ví dụ', 'p5000', '30', 'gb', 'ram', '8', 'g', 'cpu', '16', 'gb', 'gpu', 'a400', '45', 'gb', 'ram', '8', 'g', 'cpu', '16', 'gb', 'gpu', '6', 'thể', 'kết nối', 'khoản', 'phí', '8', 'khoản', 'phí trì', 'đăng ký', 'gói', 'growth', 'máy', 'chủ', 'miễn phí', 'chí', 'a100', '80', 'gb', 'gpu', 'miễn phí nhiên', 'phiên', 'miễn phí', '6', 'động', 'tắt', 'máy', 'chủ', 'kết nối', 'tiếp tóm', 'gradient', 'ngon', 'colab']"
726,"Xin chào mọi người, e đang làm nhãn cho bài toán phân loại ảnh . Em có 1 thắc mắc là : với ảnh có độ phân giải nhỏ ( 100x100 ), chất lượng hơi kém, kích thước của đồ vật cần phân loại nhỏ trong ảnh, và cũng hơi mờ thì nên phân loại ảnh là negative hay positive ạ. Nếu là mắt con người thì có thể đoán được là đồ vật đó ( positive ), nhưng để là máy đoán dc thì quá khó , Ví dụ những ảnh dưới đây chứa xe đạp ( mắt người thì đoán đc ),nhưng để AI đoán được là xe đạp thì quá khó. Theo mọi người thì nên phân loại gì ạ ?. Em cảm ơn nhiều ,","['#Q&A', '#data']","['chào e', 'nhãn toán', 'phân ảnh', '1', 'thắc mắc', 'ảnh độ', 'phân giải', '100x100', 'chất', 'hơi', 'kém', 'kích thước', 'đồ vật', 'phân ảnh', 'hơi', 'mờ', 'phân ảnh', 'negative', 'positive', 'mắt thể đoán', 'đồ vật', 'positive', 'máy đoán', 'dc', 'ví dụ', 'ảnh', 'chứa', 'xe đạp', 'mắt', 'đoán', 'đc đoán', 'xe đạp', 'phân']"
727,"Hi mọi người,
Em đang tính làm một dự án vớ Llama 2. Em có một thắc mắc về data privacy.Như khi em dùng chatGPT, thì mọi thông tin từ prompt, hoặc data mà mình dùng để fine-tune sẽ được đưa về OpenAI. Vậy cho em hỏi nếu em fine-tuned Llama 2 model, thì data mình dùng để fine-tune hoặc prompt của mình khi sử dụng model có bị lưu bởi Meta k ạ? Em cảm ơn!","['#Q&A', '#data', '#nlp']","['hi', 'dự án', 'vớ', 'llama', '2', 'thắc mắc', 'data', 'privacy', 'chatgpt', 'thông prompt', 'data', 'finetune', 'openai', 'finetuned', 'llama', '2', 'model', 'data', 'finetune', 'prompt', 'model', 'lưu meta', 'k']"
728,"Ngày hội Trí tuệ nhân tạo Việt Nam (AI4VN 2023) có chủ đề ""Sức mạnh cho cuộc sống"" với bốn hoạt động chính: AI workshop; AI Summit; AI Expo; CTO Summit 2023 - vinh danh các công ty có môi trường công nghệ tốt nhất.Phiên khai mạc ngày 21/9 mang đến báo cáo Chỉ số sẵn sàng AI của chính phủ năm 2022, trình bày bởi ông Pablo Fuentes Nettel - Chuyên gia tư vấn cấp cao tại Oxford Insights. Ngay sau đó là các phần tham luận về ứng dụng AI trong tương lai, kinh nghiệm triển khai thực tế tại Hàn Quốc, làm chủ AI tạo sinh... qua góc nhìn của các chuyên gia VinBigdata, Naver, VNPT, Aqua.
#AI4VN #VietAI #AI4VN2023",['#sharing'],"['hội trí tuệ nhân', 'việt nam', 'ai4vn', '2023', 'chủ đề', 'sức sống', 'bốn', 'hoạt động', 'workshop', 'summit', 'expo', 'cto', 'summit', '2023', 'vinh danh', 'công ty', 'môi trường', 'công nghệ', 'phiên', 'khai mạc', '21', '9', 'báo cáo', 'sẵn sàng', 'phủ', '2022', 'trình bày', 'pablo', 'fuentes', 'nettel', 'chuyên gia', 'tư vấn', 'oxford insights', 'tham luận', 'ứng dụng', 'tương lai', 'kinh nghiệm', 'triển khai', 'hàn quốc', 'chủ sinh', 'góc', 'chuyên gia', 'vinbigdata', 'naver', 'vnpt', 'aqua']"
729,"Yeahhhhh! 🌟
Mình rất vui giới thiệu VietAssistant-GPT phiên bản 1.0 🇻🇳. Là một trợ lý đa năng  (general domain)..
Dựa trên phát triển của open-source LLaMa 2, phiên bản này đã được finetune để cung cấp cho bạn những câu trả hữu ích hơn trong nhiều lĩnh vực trên Tiếng Việt. Và đang trong quá trình cải thiện📚
Finetuned model và dataset được cung cấp ở link sau:
https://github.com/VietnamAIHub/Vietnamese_LLMs
Demo Link:
Vietnamese llama2 13B  Demo https://c4242d50778850141a.gradio.live/
Vietnamese llama2 7B Model Demo https://31fee86ed135939f28.gradio.live
Rất mong chờ sự phản hồi và ý kiến của mọi người ! 🙌","['#sharing', '#nlp']","['yeahhhhh', 'vui', 'giới thiệu', 'vietassistantgpt', 'phiên', '1', '0', 'trợ lý', 'đa năng', 'general domain', 'dựa', 'phát triển', 'opensource', 'llama', '2', 'phiên', 'finetune', 'cung câu', 'hữu ích', 'lĩnh vực', 'tiếng', 'việt', 'trình', 'cải thiện', 'finetuned', 'model', 'dataset', 'cung', 'link', 'demo', 'link', 'vietnamese', 'llama2', '13', 'b', 'demo', 'https', 'c4242d50778850141a', 'gradio', 'live', 'vietnamese', 'llama2', '7', 'b', 'model', 'demo', 'mong chờ', 'phản hồi', 'kiến']"
730,"Không biết có ace bạn nào có biết qua bài này không ạ?
NASA: Neural Articulated Shape Approximation
Cho mình hỏi vài câu hỏi bên dưới (chắc sẽ còn hỏi thêm):
1/ Query ở đây là cái gì ??
- Phần tóm tắt contribution có câu sau: 
""The differentiable occupancy supports efficient constant time queries, avoiding the need to convert to separate representations, or the dynamic update of spatial acceleration data structures;"" 
- Phần related work có nói:
Object intersection queries: Registration, template matching, 3D tracking, collision detection, and other tasks require efficient inside/outside tests. A disadvantage of polygonal meshes is that they do not efficiently support these queries, as meshes often contain thousands of individual triangles that must be tested for each query. This has led to the development of a variety of spatial data structures to accelerate point-object queries
Kết hợp thêm cái hình Figure 1 này. chỗ O(x|θ) là cái gì ? nhìn khó hiểu.
Chỗ này em thực sự chẳng hiểu cái query ở đây là query cái gì?
Rốt cuộc input/output của paper này là gì ? (Thấy nó được train trên AMASS dataset? vậy input là pointcloud ?
Tại sao phần demo ứng dụng thì lại chọn tracking body?
(Em ko rành bên 3D CV này mà bị gán cho presentation trong môn học mà chỉ có vài ngày chuẩn bị nên hơi quá tải).
Hi vọng có ace nào biết chỉ giáo với ạ.
Em cảm ơn 😊","['#Q&A', '#cv', '#math']","['ace', 'nasa', 'neural', 'articulated', 'shape', 'approximation', '1', 'query', 'tóm tắt', 'contribution', 'câu', 'the', 'differentiable', 'occupancy', 'supports', 'efficient', 'constant', 'time', 'queries', 'avoid', 'ing', 'the', 'need', 'to', 'convert', 'to', 'separate', 'representations', 'or', 'the', 'dynamic', 'update', 'of spatial', 'acceleration', 'data', 'structures', 'related', 'work', 'object', 'intersection', 'queries', 'registration', 'template', 'matching', '3', 'd', 'tracking', 'collision detection', 'and other', 'tasks', 'require', 'efficient', 'inside', 'outside', 'tests', 'a', 'disad', 'vantage', 'of polygonal', 'meshes', 'is', 'that', 'they', 'not', 'efficiently', 'support', 'these', 'queries', 'as', 'meshes', 'often', 'contain', 'thousands', 'of individual', 'triangles', 'that', 'must', 'be', 'tested', 'for', 'each', 'query', 'this', 'has', 'led', 'to', 'the', 'development', 'of a', 'variety', 'of spatial', 'data', 'structures', 'to', 'accelerate', 'pointobject', 'queries', 'kết hợp', 'hình figure', '1', 'chỗ', 'o', 'x', 'θ', 'chỗ', 'thực chẳng', 'query', 'query', 'rốt input', 'output', 'paper', 'train', 'amass', 'dataset', 'input', 'pointcloud', 'demo', 'ứng dụng', 'tracking', 'body', 'ko', 'rành', '3', 'd', 'cv', 'gán', 'presentation', 'môn học', 'chuẩn', 'hơi tải', 'hi vọng', 'ace giáo']"
731,"Mình thấy giờ nhiều bạn lo hết việc, sợ AI thay thế, sợ cạnh tranh cao... Tuy nhiên theo mình thì nhu cầu công việc ngoài kia không thiếu, cái thiếu ở đây là thiếu người giỏi và người phù hợp. Vậy nên, có những thứ các bạn không thể kiểm soát được thì không nên tốn năng lượng làm gì, cái các bạn cần là hãy nâng cao năng lực, giỏi tới mức người ta không thể ngó lơ thì mọi thứ sẽ tuyệt vời hơn rất nhiều.",['#sharing'],"['lo sợ', 'thay', 'sợ', 'cạnh tranh nhiên', 'nhu cầu', 'công kia', 'giỏi thể', 'kiểm soát', 'tốn năng', 'nâng', 'năng lực', 'giỏi', 'ta thể', 'ngó', 'lơ tuyệt vời']"
732,"Khai phá dữ liệu là một phần việc rất quan trọng để hiểu về dữ liệu cho các mục đích phân tích chuyên sâu tiếp theo. Đây cuốn sách gần 400 trang hướng dẫn biểu diễn dữ liệu sử dụng Python (Matplotlib và Seaborn) như: (1) một số kĩ thuật lựa chọn dạng biểu đồ phù hợp; (2) xử lí missing data/outliers; (3) phần biểu diễn dữ liệu địa lý (bản đồ~geospatial data); và (4) biểu diễn dữ liệu dạng 3D tại đây https://theswissbay.ch/pdf/Gentoomen%20Library/Programming/Python/Beginning%20Python%20Visualization%20-%20Crafting%20Visual%20Transformation%20Scripts%20%282009%29.pdf; https://pyoflife.com/beginning-python-visualization-crafting-visual-transformation-scripts/
Hi vọng nó có ích với mọi người","['#sharing', '#data']","['khai phá', 'liệu liệu', 'mục đích', 'phân tích', 'chuyên sâu', 'tiếp', 'sách', '400', 'trang', 'hướng', 'biểu diễn liệu', 'python', 'matplotlib', 'seaborn', '1', 'kĩ thuật', 'lựa', 'dạng', 'biểu đồ', '2', 'xử lí', 'missing', 'data', 'outliers', '3', 'biểu diễn liệu', 'địa lý', 'đồ', 'geospatial', 'data', '4', 'biểu diễn liệu', 'dạng', '3', 'd', 'https', 'pyoflife', 'com', 'beginningpythonvisualizationcraftingvisualtransformationscripts', 'hi vọng ích']"
733,"Dạo này em đọc về RLHF (Reinforcement learning from human feedback) thấy khá thú vị + practical in production khá cao. Em đang tính làm 1 project để extract features từ description của sản phẩm, trong đó model nhận feedback từ người dùng để đánh giá xem output của model chính xác tới cỡ nào và model dùng đó để reward/penalty trong loss function.
Không biết các bác có kinh nghiệm gì về mảng này không ạ?","['#Q&A', '#deep_learning']","['dạo', 'đọc', 'rlhf', 'reinforcement', 'learning', 'from', 'human', 'feedback', 'thú vị', 'practical', 'in', 'production', '1', 'project', 'extract', 'features', 'description', 'sản phẩm', 'model', 'feedback', 'output', 'model', 'xác', 'cỡ', 'model', 'reward', 'penalty', 'loss', 'function', 'kinh nghiệm', 'mảng']"
734,"Xin chào mọi người, hiện tại em đang làm đồ án tốt nghiệp với đề tại là trích xuất nội dung từ danh thiếp bằng OCR , tuy nhiên do data ít nên em đăng bài này mong muốn kiếm một lượng lớn data về danh thiếp để bổ sung vào đatn ạ, nếu ai có thì cho em xin hoặc mua lại ạ, em xin cảm ơn mọi người nhiều ạ","['#Q&A', '#cv', '#data']","['chào', 'đồ án nghiệp', 'đề trích', 'xuất', 'nội dung', 'danh thiếp', 'ocr nhiên', 'data', 'đăng mong', 'kiếm', 'data', 'danh thiếp', 'bổ sung', 'đatn', 'mua']"
735,"Xin chào mọi người!
Hiện tại mình đang thực hiện 1 Project cho Product, ứng dụng LLM. Tuy nhiên do data ít nên mình đăng bài này với mong muốn tìm kiếm thêm data để Project được hoàn thiện.
Data mình cần là ảnh các loại hóa đơn thương mại. Nếu ai có nguồn data như vậy thì có thể cho mình xin (hoặc mua nếu cần) được không ạ?
Mình xin cảm ơn ạ!","['#Q&A', '#data']","['chào', '1', 'project', 'product', 'ứng dụng', 'llm nhiên', 'data', 'đăng mong', 'kiếm', 'data project', 'hoàn thiện', 'data', 'ảnh', 'hóa đơn', 'thương mại', 'data thể', 'mua']"
736,"Vậy là Mojo, ngôn ngữ mới cho ML/DL/AI, đã cho phép cài đặt trên máy tính cá nhân. Hiện tại, Mojo mới hỗ trợ hệ điều hành Linux. Các bạn có thể test bằng cách đăng kí và cài đặt tại đây",['#sharing'],"['mojo', 'ngôn ngữ', 'ml', 'dl phép', 'cài', 'máy', 'mojo', 'hệ hành', 'linux thể', 'test', 'đăng kí', 'cài']"
737,"#question
Mn có thể recommend cho e 1 vài kênh học lý thuyết ML từ basic không ạ. Em muốn nắm dc basic ML một cách nhanh chóng nhưng cảm giác bị hổng đâu đó về lý thuyết nhưng không biết là chỗ nào. Em cảm ơn","['#Q&A', '#machine_learning']","['mn thể', 'recommend', 'e', '1', 'kênh', 'học', 'lý thuyết', 'ml', 'basic', 'nắm', 'dc', 'basic', 'ml chóng', 'cảm giác', 'hổng', 'lý thuyết', 'chỗ']"
738,"Dạ anh chị nào có tài liệu bài tập về Linear Regression và  Logistic Regression , cho em xin ạ . Dạ em cảm  ơn  ","['#Q&A', '#machine_learning']","['tài liệu', 'tập', 'linear', 'regression', 'logistic', 'regression']"
739,Mọi người cho e hỏi làm thế nào để dịch từ tiếng anh về tiếng việt cho nó tự nhiên hơn không ạ (không dùng chatgpt và google)?,['#Q&A'],"['e', 'dịch', 'tiếng', 'tiếng', 'việt nhiên', 'chatgpt', 'google']"
740,"Xin chào các anh chị và các bạn,
Mình làm về dự báo mức tiêu thụ năng lượng của một quốc gia ở Mỹ Latin, dữ liệu dạng time series được tổng kết cuối năm.
Mình đọc thì có một số mô hình dự báo tốt như ARIMA và LSTM,... trong đó thì mình cảm thấy thích ARIMA hơn vì nó dễ và kết quả cũng tốt.
Các anh chị nào có tài liệu để đọc về vấn đề này có thể giới thiệu cho mình được không ạ? mình hơi lơ mơ về cách chọn các tham số p,d,q, đặc biệt là khi số lượng biến nhiều mà lại làm việc với univariate (do mình còn kém kinh nghiệm).
Nếu anh chị nào có thể chia sẻ được về phần này mình rất cảm ơn ạ.","['#Q&A', '#deep_learning']","['chào', 'dự báo', 'tiêu thụ năng', 'quốc gia', 'mỹ', 'latin liệu', 'dạng', 'time', 'series', 'tổng kết', 'đọc', 'mô hình', 'dự báo', 'arima', 'lstm', 'arima kết', 'tài liệu', 'đọc thể', 'giới thiệu', 'hơi', 'lơ mơ', 'tham p', 'd', 'q', 'biến univariate', 'kém', 'kinh nghiệm thể']"
741,"Mình có làm một game basic về ML và xử lí ảnh Computer Vision bằng python, project này chủ yếu là demo cho học sinh và các bạn sinh viên của mình. Bạn nào thích thì có thể tham khảo và tải về nhé 😀","['#sharing', '#cv']","['game', 'basic ml', 'xử lí', 'ảnh', 'computer', 'vision', 'python project', 'chủ yếu', 'demo', 'học sinh', 'sinh viên thể', 'tham khảo', 'tải']"
742,"Morning mn, mọi nghĩ sao về việc mình dùng chat gpt api,... các ai khác nữa để convert video về dạng text để lấy các keywords xong sau đó mình dựa vào các keywords để match với các khách hàng care về sản phẩm đó và dựa vào content của video đó để generate cái email marketing ạ. này ideal để làm automation dựa trên các con AI hiện tại như chat-gpt, zapier,..",['#Q&A'],"['morning', 'mn', 'chat', 'gpt', 'api', 'convert', 'video', 'dạng', 'text', 'keywords', 'xong', 'dựa', 'keywords', 'match', 'hàng', 'care', 'sản phẩm', 'dựa', 'content', 'video', 'generate', 'email', 'marketing', 'ideal', 'automation', 'dựa', 'chatgpt', 'zapier']"
743,"Em xin phép admin được chia sẻ tới các thành viên group mình cuộc thi về trí tuệ nhân tạo do FPT tổ chức.
CUỘC THI ỨNG DỤNG TRÍ TUỆ NHÂN TẠO VỚI TỔNG GIÁ TRỊ GIẢI THƯỞNG 370 TRIỆU ĐỒNG
FPT AI Challenge 2023 - cuộc thi về trí tuệ nhân tạo lớn nhất do Tập đoàn FPT tổ chức. Với tổng giải thưởng 370 triệu đồng, cuộc thi tìm kiếm những ý tưởng, sản phẩm và giải pháp ứng dụng trí tuệ nhân tạo giúp giải quyết các bài toán thực tế trong đời sống. Đây là sân chơi kỹ thuật dành cho những người có niềm đam mê với AI trên toàn thế giới.
Thời gian đăng ký: từ 12h00 ngày 09.09 - 10.10.2023
Các thí sinh tham gia cuộc thi theo hình thức cá nhân hoặc nhóm với tối đa 3 thành viên và đăng ký tại trang web https://hackathon.quynhon.ai/registration.
Ở Vòng loại, các đội thi sẽ chọn cho mình chủ đề phù hợp và tiến hành xây dựng những sản phẩm/giải pháp giúp giải quyết bài toán mà Ban Tổ chức đưa ra. 06 đội thi có điểm số cao nhất sẽ vào Vòng Chung kết.
Ba chủ đề của cuộc thi FPT AI Challenge 2023 bao gồm:
- AI-enable optimization for Binh Dinh province
- Leveraging large language models (LLMs) for sustainable business recommendations:
- AI techniques for computer vision applications
Tại Vòng Chung kết, top 06 ý tưởng sáng tạo nhất sẽ trình bày ý tưởng về sản phẩm và giải pháp của mình với Ban Giám khảo qua hình thức online. Top 03 chung cuộc sẽ được tham dự Lễ trao giải và trưng bày sản phẩm trực tiếp tại sự kiện triển lãm công nghệ FPT Tech Day 2023.
Đội chiến thắng sẽ nhận được giải thưởng tiền mặt với giải nhất trị giá 200 triệu đồng, giải nhì 100 triệu đồng, giải ba 70 triệu đồng, cùng giấy chứng nhận của Ban Tổ chức. Top 3 chung cuộc sẽ được tài trợ một tuần du lịch tại Việt Nam, tham gia giao lưu văn hoá quốc tế và triển lãm sản phẩm của mình tại sự kiện FPT Tech Day 2023 được tổ chức vào tháng 10.2023 tại Hà Nội. Ngoài ra, các đội thi sẽ có cơ hội tham gia những buổi tham luận cùng với các chuyên gia và kỹ sư đầu ngành; nhận được cơ hội việc làm với mức lương hấp dẫn tại công ty công nghệ hàng đầu Việt Nam.
Thông tin chi tiết của cuộc thi được đăng tải trên website: https://hackathon.quynhon.ai/",['#sharing'],"['phép', 'admin', 'thành viên', 'group', 'thi trí tuệ', 'nhân fpt', 'tổ chức', 'thi', 'ứng dụng', 'trí tuệ', 'nhân tổng', 'giải thưởng', '370', 'triệu', 'đồng', 'fpt', 'challenge', '2023', 'thi trí tuệ nhân', 'tập đoàn', 'fpt', 'tổ chức', 'tổng', 'giải thưởng', '370', 'triệu', 'đồng', 'thi', 'kiếm', 'tưởng', 'sản phẩm', 'giải pháp', 'ứng dụng', 'trí tuệ', 'nhân', 'giúp', 'giải quyết toán', 'đời sống', 'sân', 'kỹ thuật', 'niềm', 'đam mê', 'toàn giới', 'đăng ký', '12', 'h00', '09', '09', '10', '10', '2023', 'thí sinh', 'tham gia', 'thi', 'hình thức', 'tối đa', '3', 'thành viên', 'đăng ký', 'trang web', 'registration', 'vòng', 'đội', 'thi', 'chủ đề', 'tiến hành', 'xây dựng', 'sản phẩm', 'giải pháp', 'giúp', 'giải quyết', 'toán ban', 'tổ chức', '06', 'đội', 'thi', 'vòng kết', 'chủ đề', 'thi', 'fpt', 'challenge', '2023', 'bao', 'aienable', 'optimization', 'for binh', 'dinh', 'province', 'leveraging', 'large', 'language', 'models', 'llms', 'for sustainable', 'business', 'recommendations', 'techniques', 'for', 'computer', 'vision', 'applications', 'vòng', 'kết top', '06', 'tưởng', 'trình bày', 'tưởng', 'sản phẩm', 'giải pháp', 'ban', 'giám khảo', 'hình thức', 'online', 'top', '03', 'tham dự', 'lễ', 'trao', 'giải', 'trưng bày', 'sản phẩm', 'kiện', 'triển lãm', 'công nghệ', 'fpt', 'tech', 'day', '2023', 'đội', 'chiến thắng', 'giải thưởng', 'tiền mặt', 'giải', 'trị giá', '200', 'triệu', 'đồng', 'giải', 'nhì', '100', 'triệu', 'đồng', 'giải', '70', 'triệu', 'đồng', 'giấy', 'chứng ban', 'tổ chức', 'top', '3', 'tài trợ', 'tuần', 'du lịch', 'việt nam', 'tham gia', 'giao lưu', 'văn hóa', 'quốc tế', 'triển lãm', 'sản phẩm', 'kiện', 'fpt', 'tech', 'day', '2023', 'tổ chức', '10', '2023', 'hà nội', 'đội', 'thi hội', 'tham gia', 'tham luận', 'chuyên gia', 'kỹ sư', 'đầu', 'ngành', 'hội', 'lương hấp', 'công ty', 'công nghệ', 'hàng đầu', 'việt nam', 'thông', 'chi tiết', 'thi', 'đăng tải', 'website', 'https', 'hackathon', 'quynhon']"
744,"Em xin chào mọi người. Em đang thử train model text recognition sử dụng mô hình CRNN-CTC với tool từ PaddleOCR. Em train thử 100 epochs trên bộ dữ liệu ICDAR2015, với pretrained model từ PaddleOCR (https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar). Kết quả model bị overfit mạnh trên tập ICDAR2015 ạ, training accurracy tăng rất nhanh (khúc sau tới gần 100%), nhưng kết quả test lại rất thấp chỉ 51.4% (em có đính kèm hình bên dưới).
Em muốn xin hỏi làm sao để khắc phục vấn đề này ạ. Em có tìm hiểu trên mạng thì có 1 chỗ ghi là do bộ ICDAR2015 này ít ảnh (cỡ 4 ngàn mấy) nên bị overfit. Người ta train thì dùng các bộ dataset lớn như SynthText (9 triệu ảnh). Tuy nhiên em dùng Google Colab nên không đủ bộ nhớ để train những tập lớn như vậy (với tập ICDAR2015 mà khi train bộ nhớ CPU GPU colab đã gần bị overflow rồi). Không biết mọi người có link về các bộ dataset nào có kích thước vừa phải có thể dùng để train thử nghiệm trên Google Colab cho bài toán scene text recognition không ạ?
Em xin cảm ơn mọi người nhiều ạ.","['#Q&A', '#data', '#cv']","['chào', 'thử', 'train', 'model', 'text', 'recognition', 'mô hình', 'crnnctc', 'tool', 'paddleocr', 'train', 'thử', '100', 'epochs liệu', 'icdar2015', 'pretrained', 'model', 'paddleocr', 'kết', 'model', 'overfit', 'tập', 'icdar2015', 'training', 'accurracy khúc', '100', 'kết', 'test', '51', '4', 'đính', 'kèm hình', 'khắc phục', 'mạng', '1', 'chỗ', 'ghi', 'icdar2015', 'ảnh', 'cỡ', '4', 'ngàn', 'mấy', 'overfit', 'ta', 'train', 'dataset', 'synthtext', '9', 'triệu', 'ảnh nhiên', 'google', 'colab', 'train', 'tập', 'tập', 'icdar2015', 'train', 'cpu', 'gpu', 'colab', 'overflow', 'link', 'dataset kích', 'thước thể', 'train', 'thử nghiệm', 'google', 'colab toán', 'scene', 'text', 'recognition']"
745,"Giáo sư Dunhui Deng, Bộ môn KHMT của Đại học Thanh Hoa (Tsinghua University) bên TQ có giới thiệu cuốn sách về Algorithims viết cho cho các ngôn ngữ C+(+, Python, Go, JavaScript, TypeScript, C, C#, Swift, Zig, Rust, and Dart.
Rất tiếc sách viết bằng tiếng tàu, tuy nhiên, mình đã thử dụng một số công cụ dịch như Google Translate, Bard, Claude-2 và ChatGPT-3.5 thì thấy chất lượng dịch ra tiếng Anh và tiếng Việt khá ổn.
Vì vậy, mình xin giới thiệu source code của cuốn sách này tại đây https://github.com/krahets/hello-algo

Và có bạn đã tìm thấy branch bản dịch tiếng Anh của cuốn sách và source code tại đây https://github.com/yuelinxin/hello-algo-en?fbclid=IwAR310jM6QwOOYgEtgAdCVJQOdOWnKmpiEcFN0F00rhq_5dNIUN04VIP0nck
Cảm ơn bạn Nghia Be 

Chúc các bạn có ngày cuối tuần vui vẻ!",['#sharing'],"['giáo sư', 'dunhui', 'deng', 'môn', 'khmt', 'đại học', 'hoa', 'tsinghua university', 'tq', 'giới thiệu', 'sách', 'algorithims viết', 'ngôn ngữ', 'c', 'python', 'go', 'javascript', 'typescript', 'c', 'c', 'swift', 'zig rust', 'and dart', 'tiếc', 'sách', 'viết', 'tiếng', 'tàu nhiên', 'thử dụng', 'công cụ', 'dịch', 'google', 'translate', 'bard', 'claude2', 'chatgpt3', '5', 'chất', 'dịch', 'tiếng', 'tiếng', 'việt', 'ổn', 'giới thiệu', 'source', 'code', 'sách', 'branch dịch', 'tiếng', 'sách', 'source', 'code', 'nghia', 'be', 'chúc', 'tuần', 'vui vẻ']"
746,"Chào mọi người,
Hiện tại em đang tìm hiểu một số bài toán về speech. Em tìm hiểu và có biết bộ dataset về giới tính và vùng miền Voice Gender của Zalo AI Challenger 2018. Em đã cố gắng tìm các nguồn public trên mạng nhưng vẫn chưa tìm được dữ liệu này. Trang chủ cuộc thi hiện nay là năm 2022 và không xem lại được dữ liệu năm trước.
Mọi người trong nhóm ai còn lưu trữ bộ dataset này cho em xin với ạ. Cảm ơn mọi người đã đọc bài.","['#Q&A', '#data']","['chào toán', 'speech', 'dataset giới', 'miền', 'voice', 'gender', 'zalo', 'challenger', '2018', 'cố gắng', 'public', 'mạng liệu', 'trang', 'chủ', 'thi', '2022', 'liệu', 'lưu trữ', 'dataset', 'đọc']"
747,"🇻🇳 Cộng đồng LLMs Việt Nam!

Hiện tại, mình đang xây dựng một mô hình ngôn ngữ thuần Việt (#Vietnamese_LLM). Dự án của mình dựa trên sự phát triển của các mô hình ngôn ngữ  dựa trên Open-source LLM như #BLOOMZ, #Open_LlaMA, và nhiều mô hình #khác.
Thông tin sơ lược về dự án trình bày trong file đính kèm:
#Kế hoạch của mình bao gồm việc phát triển: #1. Tạo bộ dữ liệu Vietnamese (self-instruct dataset) và #2. Finetuning  và Training các Open-source LLMs trên bộ dữ liệu tiếng Việt.
#1. Phát triển bộ dữ liệu tiếngViệt (Self-Instruct Vietnamse):
+ Dựa trên các bộ dữ liệu tiếng Anh hiện có như #Alpaca, #Dolly, #OpenAssistant, #ShareGPT và các nhiều bộ dữ liệu khác. Mình đang sử dụng API Azure OpenAI: GPT3, GPT 3.5 và GPT-4 để dịch các bộ dữ liệu này sang tiếng Việt.
+ Tạo thêm 100.000 (có thể nhiều hơn) câu hướng dẫn tự học giống như dự án Alpaca hoặc các mô hình tạo dữ liệu khác.
+ Tìm hiểu thêm về các nguồn dữ liệu tiếng Việt khác tập trung cho các lĩnh vực khác nhau. như báo chí, điện ảnh, y học... (Mong nhận được ý kiến góp ý từ mọi người).
#2. Để huấn luyện (#Finetuning & Traning ) các mô hình ngôn ngữ LLM, mình sẽ sử dụng kỹ thuật #LoRA và #QLoRA trên máy chủ Azure server có 8 GPUs Nvidia #A100 80GB. Điều này sẽ giúp mình Finetune và Train các mô hình ngôn ngữ (LLM) từ 7B tỷ đến 65B tỷ hoặc nhiều hơn.
Mình rất mong sự kết nối với các bạn có mong muốn thực hiện dự án này và hoan nghênh sự đóng góp từ cộng đồng.
Nếu bạn có sự góp ý về dữ liệu hoặc , xin vui lòng chia sẻ.
Cùng nhau, chúng ta có thể phát triển mô hình ngôn ngữ tiếng Việt chất lượng cao. Rất mong nhận được sự quan tâm và hỗ trợ của mọi người!
Form đăng ký tham gia: https://docs.google.com/forms/d/e/1FAIpQLSfoc4tnV6R0RJvVPmsH4cyfgnkKdUkASgYFA-sTuL1hfDE9sA/viewform?usp=pp_url

Mình là Nhiệm, một nghiên cứu sinh tiến sĩ đang công tác tại National Central University, Researcher Foxconn AI, Taiwan.
Trần Nhiệm. Email. tvnhiemhmus@g.ncu.edu.tw
zalo: +886 934 311 751.
linkedIn: https://www.linkedin.com/in/tran-nhiem-ab1851125/
#VietnameseLLMs
File đính kèm:
https://drive.google.com/file/d/182T0ExiJFKfIUvK1Vm3WQqeju8kw9J6J/view?usp=sharing ","['#Q&A', '#nlp', '#data']","['cộng đồng', 'llms', 'việt nam', 'xây dựng', 'mô hình', 'ngôn ngữ', 'việt', 'vietnamese_llm', 'dự án', 'dựa', 'phát triển', 'mô hình', 'ngôn ngữ', 'dựa', 'opensource', 'llm', 'mô hình', 'thông', 'sơ lược', 'dự án', 'trình bày', 'file', 'đính', 'kèm hoạch', 'bao', 'phát triển', 'liệu', 'vietnamese', 'selfinstruct', 'dataset', 'finetuning', 'training', 'opensource', 'llms liệu', 'tiếng', 'việt', 'phát triển', 'liệu', 'tiếngviệt', 'selfinstruct', 'vietnamse', 'dựa liệu', 'tiếng', 'hiện liệu', 'api', 'azure', 'openai', 'gpt3', 'gpt', '3', '5', 'gpt4', 'dịch liệu', 'tiếng', 'việt', '100', '000', 'thể', 'câu', 'hướng', 'học', 'dự án', 'alpaca', 'mô hình', 'liệu liệu', 'tiếng', 'việt', 'lĩnh vực', 'báo chí', 'điện ảnh', 'y học', 'mong kiến', 'góp', 'huấn luyện', 'finetuning', 'traning', 'mô hình', 'ngôn ngữ', 'llm', 'kỹ thuật', 'máy', 'chủ', 'azure', 'server', '8', 'gpus', 'nvidia', '80', 'gb', 'giúp', 'finetune', 'train', 'mô hình', 'ngôn ngữ', 'llm', '7', 'b', 'tỷ', '65', 'b', 'tỷ mong', 'kết nối', 'mong', 'dự án', 'hoan nghênh', 'đóng góp', 'cộng đồng', 'góp liệu', 'vui', 'ta thể', 'phát triển', 'mô hình', 'ngôn ngữ', 'tiếng', 'việt', 'chất', 'mong', 'form', 'đăng ký', 'tham gia nhiệm', 'nghiên cứu sinh', 'tiến sĩ', 'công tác', 'national', 'central', 'university', 'researcher', 'foxconn', 'taiwan', 'trần nhiệm', 'email', 'tvnhiemhmus', 'g', 'ncu', 'edu', 'tw', 'zalo', '886', '934', '311', '751', 'linkedin', 'https', 'www', 'linkedin', 'com', 'in', 'trannhiemab1851125', 'file', 'đính', 'kèm']"
748,"Chào mọi người, Hiện tại, mình đang tiến hành điều chỉnh (fine-tuning) mô hình BartPho-word-base để thực hiện tác vụ tóm tắt văn bản. Tuy nhiên, khi mình dự đoán kết quả, lại gặp phải tình trạng kết quả dự đoán chứa những ký tự không xác định (<unk>). Sau khi tìm hiểu, nhận ra rằng nguyên nhân có thể là do dữ liệu huấn luyện chứa nhiễu hoặc từ vựng của mô hình BartPho chưa đủ phong phú để xử lý tốt tình huống này.
Mình đã thử nhiều cách nhưng chưa xử lí được vấn đề này, vì thế mình lên đây tìm kiếm gợi ý và kinh nghiệm từ mọi người. Hi vọng mọi người giúp đỡ.","['#Q&A', '#nlp']","['chào', 'tiến hành', 'chỉnh finetuning', 'mô hình', 'bartphowordbase tác', 'vụ', 'tóm tắt', 'văn nhiên', 'dự đoán', 'kết kết', 'dự đoán', 'chứa', 'ký', 'xác định', 'unk', 'nguyên nhân', 'thể liệu', 'huấn luyện', 'chứa nhiễu', 'vựng', 'mô hình', 'bartpho', 'phong phú', 'tình huống', 'thử', 'xử lí', 'kiếm', 'gợi', 'kinh nghiệm', 'hi vọng', 'giúp đỡ']"
749,"Closed.
Cảm ơn cả nhà đã đưa ra nhiều gợi ý giúp mình hiểu vấn đề hơn và đã giải quyết xong case này. 
Phương án giải quyết là chỉ đưa vào hàm map với tf.numpy_function thao tác đọc tên ảnh để map sang feature. Còn việc map caps thành vector sẽ dùng hàm map khác với auto graph. Lý do là map với numpy_function rất khó control và thường hay mất shape nên gây lỗi đầu vào với TextVectorization (hoặc có thể layer nào khác cũng sẽ bị lỗi tương tự).
-----------------------------------------------------
Chào cả nhà. Mình có 1 project CV dùng Tensorflow. Tuy nhiên đang bị mắc kẹt trong việc tạo TF dataset như sau:
Mình tạo tf dataset: tên ảnh, caps
map bằng tf.numpy_function để có dataset: feature, caps.
=> cho vào train.
Nếu chạy GPU Colab với num_parallel_calls trong khi map feature thì sẽ lỗi runtime ở 1 chỗ nào đó khi train mô hình. Với 1 tập dữ liệu cố định, mỗi lần chạy có thể lỗi ở các ảnh khác nhau. Nếu thử với 1 tập dữ liệu nhỏ thì có thể may mắn chạy được 1 vài epoch mới lỗi (thậm chí có lần chạy được hết tất cả các epoch).
Tuy nhiên nếu chạy CPU hoặc chạy GPU mà không dùng num_parallel_calls thì không lỗi, chạy bình thường.
Chi tiết mình đăng trên Stackoverflow mà chưa có ai trả lời.
https://stackoverflow.com/questions/77007077/runtime-error-when-use-dataset-map-with-tf-numpy-function-and-num-parallel-cal
Các cao nhân đi qua xin vui lòng chỉ giáo. 
Cảm ơn rất nhiều.","['#Q&A', '#python']","['closed', 'gợi', 'giúp', 'giải quyết', 'xong', 'case', 'phương án', 'giải quyết', 'hàm map', 'tf', 'numpy_function', 'thao tác', 'đọc', 'ảnh', 'map', 'feature', 'map', 'caps', 'thành', 'vector', 'hàm map', 'auto', 'graph lý', 'map', 'numpy_function', 'control', 'shape', 'lỗi', 'đầu', 'textvectorization thể', 'layer', 'lỗi', 'tương chào', '1', 'project', 'cv', 'tensorflow nhiên', 'mắc kẹt', 'tf', 'dataset', 'tf', 'dataset', 'ảnh', 'caps', 'map', 'tf', 'numpy_function', 'dataset', 'feature', 'caps', 'train', 'chạy', 'gpu', 'colab', 'num_parallel_calls', 'map', 'feature', 'lỗi', 'runtime', '1', 'chỗ', 'train', 'mô hình', '1', 'tập liệu', 'cố định', 'chạy thể', 'lỗi', 'ảnh', 'thử', '1', 'tập liệu thể', 'may mắn', 'chạy', '1', 'epoch', 'lỗi chí', 'chạy', 'tất', 'epoch nhiên', 'chạy', 'cpu', 'chạy', 'gpu', 'num_parallel_calls', 'lỗi', 'chạy', 'bình', 'chi tiết', 'đăng', 'stackoverflow nhân', 'đi', 'vui giáo']"
750,"Mình đang cần tìm cuốn sách này. Ensemble Learning Algorithms With Python: Make Better Predictions with Bagging, Boosting and Stacking của tác giả Jason Brownlee. Link https://machinelearningmastery.com/ensemble-learning.../ Bạn nào có cho mình xin với. Cảm ơn nhiều nhé",['#Q&A'],"['sách', 'ensemble', 'learning', 'algorithms', 'with', 'python', 'make', 'better', 'predictions', 'with', 'bagging', 'boosting and', 'stacking tác giả', 'jason', 'brownlee', 'link', 'https', 'machinelearningmastery', 'com', 'ensemblelearning']"
751,"Xin chào mọi người, em đang có ý định làm một prj NLP nho nhỏ để đánh giá CV, trong đó ý tưởng chính của em là người dùng nhập vào một đoạn miêu tả CV của họ (gồm nghề nghiệp, kinh nghiệm làm việc, kỹ năng,...) và bên tuyển dụng nhập vào JD rồi so sánh độ matching giữa 2 yếu tố đấy. Tuy nhiên em đang gặp khó khăn ở ngay bước đầu tiên khi cần biểu diễn đoạn văn bản input thành các vector có cùng độ dài để tiện đối chiếu. E cảm thấy thuật word2vec bình thường không hiệu quả với dữ liệu bé, ví dụ nó sẽ không thể phân biệt được ""Tôi là fresher IT"" và ""Tôi là senior IT"" vì có cùng context
Mọi người cho em gợi ý để giải quyết vấn đề này với ạ, liệu có cách word embedding nào khác không ạ? Và e nên dùng thuật gì để đo độ matching giữa CV và JD ạ?","['#Q&A', '#nlp']","['chào định', 'prj', 'nlp nho', 'cv tưởng', 'nhập đoạn', 'miêu tả', 'cv', 'nghề nghiệp', 'kinh nghiệm', 'kỹ năng', 'tuyển dụng', 'nhập', 'jd', 'sánh độ', 'matching', '2', 'yếu tố', 'đấy nhiên', 'khăn', 'biểu diễn', 'đoạn', 'văn input', 'thành', 'vector', 'độ tiện', 'đối chiếu', 'e thuật', 'word2vec', 'bình hiệu liệu', 'bé', 'ví dụ thể', 'phân biệt', 'fresher', 'it', 'senior', 'it', 'context', 'gợi', 'giải quyết', 'liệu', 'word embedding', 'e thuật', 'đo', 'độ', 'matching', 'cv', 'jd']"
752,"Em chào mọi người ạ, em đang eval cho model của mình trên coco2015 test dev để tiện so sánh với các paper khác, cơ mà sever submit đã bị disable và trên web mới của codalab thì hình như không còn support submit cho coco nữa thì phải, annotations thì họ cũng không công bố và em tìm khắp nơi trên internet cũng không thấy có leak. Còn cách nào để eval trên dataset này không ạ. Em cảm ơn mọi người rất nhiều ạ.","['#Q&A', '#data']","['chào', 'eval', 'model', 'coco2015', 'test', 'dev tiện', 'sánh', 'paper', 'sever', 'submit', 'disable web', 'codalab hình', 'support', 'submit', 'coco', 'annotations', 'công bố', 'khắp', 'internet', 'leak', 'eval', 'dataset']"
753,"Chào các bác, hiện tại em đang tìm hiểu về Sentiment Analysis. Các bác đi trước có tài liệu hay nguồn học nào hay cho em xin với ạ!
Em cám mọi người nhiều!","['#Q&A', '#nlp']","['chào', 'sentiment', 'analysis', 'đi', 'tài liệu', 'học', 'cám']"
754,Bài báo mới đến từ Google có tên: TSMixer: An all-MLP architecture for time series forecasting (https://arxiv.org/pdf/2303.06053),['#sharing'],"['báo', 'google', 'tsmixer', 'an allmlp', 'architecture', 'for', 'time', 'series', 'forecasting']"
755,"Em chào mọi người, hiện em đang cần deploy chatbot lên facebook message nhưng cần xác minh doanh nghiệp cho quyền pages_messing. Mọi người có ai đang làm hay quan tâm vấn đề này cho em xin ý kiến tham khảo với ạ. Em dùng tài khoản đã xác minh doanh nghiệp nhưng vẫn không xin được quyền từ facebook.",['#Q&A'],"['chào', 'hiện', 'deploy', 'chatbot', 'facebook', 'message', 'xác minh', 'doanh nghiệp', 'quyền', 'pages_messing kiến', 'tham khảo', 'tài khoản', 'xác minh', 'doanh nghiệp', 'quyền', 'facebook']"
756,"Em mới học về AI đang muốn train model phân loại nội dung video theo mức độ phù hợp của từng lứa tuổi, ai có ý tưởng gì có thể sp em đc không ạ :V","['#Q&A', '#cv']","['học', 'train', 'model', 'phân', 'nội dung', 'video độ', 'lứa', 'tưởng thể', 'sp', 'đc', 'v']"
757,"Explain Paper - The Fastest Way to Read Research Papers
Explain Paper là một công cụ giúp quá trình đọc paper trở nên đơn giản hơn. Công cụ này rất hữu ích với các bạn mới bắt đầu đọc paper.
Các bạn chỉ cần tải paper lên, highlight text mà bạn không hiểu. Sau đó, AI sẽ giúp bạn giải thích phần highlight đó. Bên cạnh các thuật ngữ, AI cũng có thể giải thích cả một đoạn text.
Website: https://www.explainpaper.com/",['#sharing'],"['explain', 'paper', 'the', 'fastest', 'way', 'to', 'read', 'research', 'papers', 'explain', 'paper', 'công cụ', 'giúp', 'trình', 'đọc', 'paper', 'trở', 'đơn giản', 'công cụ', 'hữu ích', 'đọc', 'paper tải', 'paper', 'highlight', 'text', 'giúp', 'giải highlight', 'cạnh', 'thuật ngữ thể', 'giải đoạn', 'text', 'website', 'https', 'www', 'explainpaper', 'com']"
758,"Chắc mọi người biết tới ứng dụng Code Interpreter của OpenAI và Code LLaMA của Meta, nay mình thấy có người viết API có thể kết nối cả 2 backends này để chạy trong terminal, có tên là Open Interpreter. Nếu với Code Interpreter thì sẽ chạy inference online dựa trên GPT-3.5, còn Code LLaMA sẽ chạy inference offline dựa trên cấu hình máy cá nhân. Các bạn có thể tham khảo source code tại đây","['#sharing', '#nlp']","['ứng dụng', 'code', 'interpreter', 'openai', 'code', 'llama', 'meta', 'viết', 'api thể', 'kết nối', '2', 'backends', 'chạy', 'terminal', 'open', 'interpreter', 'code', 'interpreter', 'chạy', 'inference online', 'dựa', 'gpt3', '5', 'code', 'llama', 'chạy', 'inference offline', 'dựa', 'cấu hình', 'máy thể', 'tham khảo', 'source', 'code']"
759,"Em chào mọi người ạ:v
Em đang tìm hiểu về LLMs và vừa mới fine-tune được 1 model làm chatbot và em có 3 câu hỏi mong mọi người có thể giải đáp:
1. Em muốn deploy model lên web để có thể nhận feedback từ người dùng qua Internet thì có những cách phổ biển nào hay dùng ạ?
Em có tra thì thấy có 1 bên chạy trên được huggingface
https://huggingface.co/spaces/project-baize/chat-with-baize như này. Nhưng em tìm hiểu thì vẫn chưa biết đưa lên kiểu gì:<
2. Chatbot của em thì mới có thể trả lời được câu hỏi 1-1. Chưa ghi nhớ được đoạn hội thoại cũ để đưa ra câu trả lời mới (kiểu chatgpt). Vậy có cách nào để làm được như vậy, hoặc mọi người có thể đưa em từ khóa để em search ạ.
3. Với những chatbot được xây dựng từ LLMs thì mình có thể xây dựng kịch bản cho nó không ạ? Ví dụ như chatbot để trả lời CSKH, thỉnh thoảng sẽ tự động ra 1 câu hỏi khi khách hàng chưa hỏi câu hỏi đấy.
Em cảm ơn mn ạ.","['#Q&A', '#nlp']","['chào', 'v', 'llms', 'finetune', '1', 'model', 'chatbot', '3', 'mong thể', 'giải đáp', '1', 'deploy', 'model', 'web thể', 'feedback', 'internet', 'phổ', 'biển', 'tra', '1', 'chạy', 'huggingface', 'kiểu', '2', 'chatbot thể', '11', 'ghi', 'đoạn', 'hội thoại', 'cũ', 'câu', 'kiểu', 'chatgpt thể', 'khóa', 'search', '3', 'chatbot', 'xây dựng', 'llms thể', 'xây dựng', 'kịch', 'ví dụ', 'chatbot', 'cskh động', '1', 'hàng', 'đấy', 'mn']"
760,"Xin chào anh chị trong group, em vừa tìm hiểu về phương pháp word2vec trong NLP (cụ thể là skip-gram). Dù đã đọc qua vài bài (gồm cả của anh Tiệp) và xem vid trên Youtube nhưng vẫn có một vài đoạn em chưa hiểu lắm nên mong anh chị giải thích thêm ạ:

Thứ nhất, theo em hiểu thì với mỗi target word ta sẽ tìm các weight matrix (U và V) để xác suất của context word là cao nhất, bằng phương pháp backprobagation; sau đó lặp lại quá trình với C context words (với C là context window); sau đó lại lặp lại quá trình đấy với N từ trong từ điển. Như vậy số lần phải làm backprobagation là C * N. Nhưng khi học về MLP thì em được biết backprobagation là quá trình khá tốn kém thời gian (không biết liệu việc chỉ có 1 hidden layer và no activation function có làm giảm thời gian không) nên ta cần chọn C, N như nào để đảm bảo cả thời gian và accuracy ạ? 
Mỗi từ đầu vào biểu diễn dưới dạng one-hot coding, tuy nhiên khi trực quan hóa nó dưới dạng hình ảnh (như ở đây: https://projector.tensorflow.org/) thì em lại thấy người ta tìm context dựa trên từ ""ở gần"" với target word nhất (không biết là gần theo Euclid distance hay như nào) và coi mỗi từ trong từ điển là một vector có độ dài bằng nhau trong không gian. Vậy các vector đấy lấy ở đâu ạ? Chắc không phải là vector biểu diễn one-hot encoding mà là embedding vector trong ma trận U, V mà ta đã tìm ở trên ạ? Nếu hiểu theo nghĩa đấy thì kích thước mỗi vector chính là số neuron trong hidden vector đúng không ạ? 
Tại sao không dùng nhiều hidden layer cho thuật toán như MLP thế ạ? 
Ngoài ra nếu khi trực quan hóa ta dùng vector trong weight matrix tìm ra thì dùng vector trong target matrix U hay context matrix V ạ?
Cơ sở toán học nào đằng sau việc mô hình hóa này ạ? Ý em là, làm sao khoảng cách euclid giữa các vector của weight matrix trong không gian lại có liên quan đến mô hình xác suất mà ta xây dựng ở thuật toán ạ? 


 ","['#Q&A', '#nlp']","['chào', 'group', 'phương pháp', 'word2vec', 'nlp', 'skipgram', 'đọc', 'tiệp', 'vid', 'youtube đoạn', 'lắm', 'mong', 'giải', 'target', 'word', 'ta', 'weight', 'matrix u', 'v', 'xác suất', 'context', 'word', 'phương pháp', 'backprobagation', 'lặp trình', 'c', 'context', 'words', 'c', 'context', 'window', 'lặp trình', 'đấy', 'n điển', 'backprobagation', 'c', 'n', 'học', 'mlp', 'backprobagation trình', 'tốn kém', 'liệu', '1', 'hidden', 'layer', 'no', 'activation', 'function', 'ta', 'c', 'n', 'accuracy', 'đầu', 'biểu diễn', 'dạng', 'onehot', 'coding nhiên', 'trực quan', 'hóa', 'dạng', 'hình ảnh', 'https', 'projector', 'tensorflow', 'org', 'ta', 'context', 'dựa', 'target', 'word', 'euclid', 'distance', 'coi điển', 'vector độ', 'gian vector', 'đấy', 'vector', 'biểu diễn', 'onehot', 'encoding', 'embedding', 'vector', 'ma trận', 'u', 'v', 'ta', 'nghĩa', 'đấy kích thước', 'vector', 'neuron', 'hidden', 'vector', 'hidden', 'layer thuật', 'toán mlp', 'trực quan', 'hóa', 'ta', 'vector', 'weight', 'matrix', 'vector', 'target', 'matrix u', 'context', 'matrix', 'v', 'sở toán', 'học', 'đằng', 'mô hình', 'hóa', 'euclid', 'vector', 'weight', 'matrix gian', 'mô hình', 'xác suất', 'ta', 'xây dựng', 'thuật toán']"
761,"Mình có tìm hiểu về Image generation thì thấy LoRA khá phổ biến khi finetuning Stable Diffusion. Tuy nhiên thì lại thấy khá ít chỗ nói về cơ chế hoạt động đối với SD, chủ yếu chỉ thấy mention trong PEFT của NLP. Hy vọng bài viết có thể giúp mọi người hiểu hơn về cách LoRA giảm computation cost và kích cỡ file lưu trữ khi finetune SD nhé!","['#sharing', '#cv']","['image', 'generation', 'lora', 'phổ biến', 'finetuning', 'stable', 'diffusion nhiên', 'chỗ chế', 'hoạt động', 'đối sd', 'chủ yếu', 'mention', 'peft', 'nlp', 'hy vọng', 'viết thể', 'giúp', 'lora', 'computation', 'cost kích cỡ', 'file', 'lưu trữ', 'finetune', 'sd']"
762,Có người đã tổng hợp tới 14 triệu ảnh kèm prompt sinh ra từ các mô hình diffusions tại đây,['#sharing'],"['tổng hợp', '14', 'triệu', 'ảnh', 'kèm', 'prompt sinh', 'mô hình', 'diffusions']"
763,"Nhân dịp mình có Pull Request (GLIGEN model Pipeline) được merge vào thư viện Huggingface/Diffuser mình xin phép chia sẻ đến mọi người. Hiện nay các phương pháp finetune personal diffusion như Textual Inversion, Dreambooth hay LoRA sẽ giúp ta thêm object hoặc style bất kì vào ảnh mà ta muốn sinh. Nhưng các phương pháp này đều yêu cầu phải có một lượng data và finetuneing. GLIGEN Pipeline hỗ trợ việc thêm object hoặc style mà không cần finetune (Zero-shot), ta chỉ cần truyền một bức ảnh chứa object hoặc style và mô hình có thể sinh ra ảnh dựa trên đó. Chi tiết hơn có thể tham khảo ở paper: https://arxiv.org/abs/2301.07093. Ngoài ra GLIGEN Pipeline còn có thể cho bạn xác định vị trí đặt vật thể trong ảnh sinh ra bằng việc cung cấp tọa độ box. Hiện tại mình support 2 model là Generation và Inpainting. Mọi người hứng thú có thể thử, code example được mình đính kèm ở model card.
Generation: https://huggingface.co/anhnct/Gligen_Text_Image
Inpainting: https://huggingface.co/anhnct/Gligen_Inpainting_Text_Image","['#sharing', '#deep_learning']","['pull', 'request', 'gligen', 'model', 'pipeline', 'merge', 'thư viện', 'huggingface', 'diffuser phép', 'phương pháp', 'finetune', 'personal', 'diffusion', 'textual', 'inversion', 'dreambooth', 'lora', 'giúp', 'ta', 'object', 'style', 'ảnh', 'ta', 'sinh', 'phương pháp', 'data', 'finetuneing', 'gligen', 'pipeline', 'object', 'style', 'finetune', 'zeroshot', 'ta', 'truyền', 'ảnh', 'chứa', 'object', 'style', 'mô hình thể', 'sinh ảnh', 'dựa', 'chi tiết thể', 'tham khảo', 'paper', 'https', 'arxiv', 'org', 'abs', '2301', '07093', 'gligen', 'pipeline thể', 'xác định', 'vật thể', 'ảnh', 'sinh cung', 'tọa độ', 'box', 'support', '2', 'model', 'generation', 'inpainting hứng', 'thú thể', 'thử', 'code', 'example', 'đính', 'kèm', 'model', 'card', 'generation', 'inpainting']"
764,"Gần đây mình quan sát thấy hiện tượng hay xu thế chuyển đổi code từ Python qua C/C++ cho các mô hình ngôn ngữ lớn. Nhưng chưa thấy ai viết lại models và train nó từ chính C/C++. Tuy nhiên, trong ngôn Rust thì xu thế viết lại models và training loop đang được cộng đồng làm khá mạnh, trong đó có Huggingface. Trước đó, Huggingface đã viết một số thư viện bằng Rust như datasets, safetensors,... và gần đây họ bắt đầu viết lại cả models và training loop cho chúng bằng ngôn ngữ Rust. https://github.com/huggingface/candle;
Thậm chí, có người khác còn port cả pytorch sang Rust như ở đây https://github.com/burn-rs/burn/tree/main và có 1 số examples về build và train models bằng Rust.
Hi vọng, với thông tin này sẽ gợi ý cho các bạn thêm phương án trong lộ trình học tập và làm việc.
Ps. Cách đây vài tháng mình có biết Elon Musk còn có 1 post về Rust nữa cơ. Có lẽ tiềm năng của Rust sẽ rất lớn trong tương lai gần.",['#sharing'],"['quan sát', 'hiện tượng', 'xu đổi', 'code', 'python', 'c', 'c', 'mô hình', 'ngôn ngữ', 'viết', 'models', 'train', 'c', 'c nhiên ngôn rust', 'xu', 'viết', 'models', 'training', 'loop', 'cộng đồng', 'huggingface', 'huggingface', 'viết', 'thư viện', 'rust', 'datasets', 'safetensors', 'viết', 'models', 'training loop', 'ngôn ngữ', 'rust chí', 'port', 'pytorch', 'rust', '1', 'examples', 'build', 'train', 'models', 'rust', 'hi vọng', 'thông gợi', 'phương án', 'lộ trình', 'học tập', 'ps', 'elon', 'musk', '1', 'post', 'rust lẽ', 'tiềm năng', 'rust', 'tương lai']"
765,"Mình đã nhìn thấy post này (dưới comment) khá lâu trong group, có nhiều likes và shares nên thấy có trách nhiệm phản hồi kẻo nhiều bạn hiểu sai vấn đề.
Bạn chủ post nói đúng ở chỗ không nên nhắm mắt điền giá trị thiếu bằng 0 mà cần hiểu kỹ phân phối của dữ liệu.
Tuy nhiên, nói “TUYỆT ĐỐI KHÔNG” là rất hồ đồ. Điều bạn quan sát được chỉ đúng trong các trường hợp bạn thấy, đừng vội generalize ra toàn bộ kẻo bị overfitting với những gì mình thấy.
Những gì bạn phân tích chỉ áp dụng trong trường hợp toàn bộ các biến ở dạng số thực. Với dữ liệu hạng mục thì không có khái niệm KNN!
Kể cả với dữ liệu dạng số thực thì scale của các biến ảnh hưởng rất nhiều đến khoảng cách giữa các điểm. Nên bạn nói là KNN sẽ cho lựa chọn chính xác là chưa đúng.
Về dữ liệu bị khuyết, cần có domain knowledge để hiểu dữ liệu đó là khuyết ngẫu nhiên hay không và dùng các phương pháp tương ứng (xem [1]) cho phù hợp.
Nếu không chắc cách impute missing data như thế nào thì bắt đầu với cách dễ nhất rồi xem xét metrics và thử với nhiều cách khác nhau. Đừng tự đóng mình với một cái gì “TUYỆT ĐỐI KHÔNG”.
Tham khảo:
[1]
https://www.ncbi.nlm.nih.gov/books/NBK493614/#:~:text=Missing%20at%20random%20(MAR).,but%20not%20the%20unobserved%20data.
[2]
https://en.wikipedia.org/wiki/Missing_data","['#sharing', '#data']","['post', 'comment', 'group', 'likes', 'shares', 'trách nhiệm', 'phản hồi', 'kẻo', 'sai', 'chủ', 'post', 'chỗ', 'nhắm mắt điền', '0', 'kỹ', 'phân phối', 'liệu nhiên', 'tuyệt đối', 'hồ', 'đồ', 'quan sát', 'trường hợp', 'đừng', 'vội', 'generalize', 'toàn', 'kẻo', 'overfitting', 'phân tích', 'áp dụng', 'trường hợp', 'toàn', 'biến dạng', 'thực liệu', 'hạng mục', 'khái niệm', 'knn liệu', 'dạng', 'thực scale', 'biến', 'ảnh hưởng', 'knn', 'lựa', 'xác liệu', 'khuyết domain', 'knowledge liệu', 'khuyết', 'ngẫu nhiên', 'phương pháp', 'tương ứng', '1', 'impute', 'missing', 'data', 'xét', 'metrics', 'thử', 'đừng', 'đóng', 'tuyệt đối', 'tham khảo', '1', 'https', 'www', 'ncbi', 'nlm', 'nih', 'gov', 'books', 'nbk493614', 'text', 'missing', '20', 'at', '20', 'random', '20', 'mar', 'but', '20', 'not', '20', 'the', '20', 'unobserved', '20', 'data', '2']"
766,"TUYỆT ĐỐI KHÔNG bao giờ điền giá trị thiếu bằng Mean (hoặc zero).
Đây là những gì xảy ra khi chúng ta thực hiện fill value bởi Mean/0:
.
.
Thay thế (điền) giá trị thiếu bằng trung bình hoặc zero hoặc bất kỳ giá trị cố định nào khác:
- Làm thay đổi các thống kê tóm tắt
- Làm thay đổi phân phối
- Làm tăng sự hiện diện của một giá trị cụ thể
Điều này có thể dẫn đến:
- Làm mô hình không chính xác
- Khiến kết luận sai lầm, và nhiều hơn nữa.
- Thay vào đó, luôn cố gắng điền giá trị thiếu với độ chính xác cao hơn.
Những trường hợp như vậy thì KNN imputer thường là một lựa chọn ưu tiên hơn
=> Nó điền giá trị thiếu bằng cách sử dụng k-Nearest Neighbors.
Các giá trị trống sẽ được điền bằng cách chạy kNN trên các giá trị còn lại.
Hiệu quả của nó so với Mean / Zero imputation thì hoàn toàn được minh họa như hình bên dưới:
- Mean / Zero thay đổi thống kê tóm tắt và phân phối
- KNN imputer giúp giữ nguyên
share by: learning and sharing for machine learning&ai
download tài liệu mình chia sẻ tại: https://bit.ly/drive-tailieu-ebook","['#sharing', '#data']","['tuyệt đối', 'điền mean', 'zero', 'xảy', 'ta', 'fill', 'value', 'mean', '0', 'thay điền', 'trung bình', 'zero', 'cố định', 'thống kê', 'tóm tắt', 'phân phối', 'hiện diện thể', 'mô hình', 'xác', 'kết luận', 'sai lầm', 'thay', 'cố gắng', 'điền độ', 'xác', 'trường hợp', 'knn', 'imputer lựa', 'ưu tiên', 'điền knearest', 'neighbors', 'trống điền', 'chạy', 'knn hiệu', 'mean', 'zero', 'imputation minh', 'họa hình', 'mean zero', 'thống kê', 'tóm tắt', 'phân phối', 'knn', 'imputer', 'giúp', 'nguyên', 'share', 'by learning', 'and sharing', 'for', 'machine', 'learning', 'download', 'tài liệu']"
767,"Mọi người cho em hỏi sự khác biệt giữa normalization và standardization là gì vậy ạ? Khi nào thì nên dùng cái nào ạ? Em đọc tài liệu mà thấy chỉ hướng dẫn cách tính toán nên hơi hoang mang không biết nên dùng cái nào (ví dụ KNN, Logistic Regression)
Em cảm ơn mọi người","['#Q&A', '#machine_learning']","['biệt', 'normalization', 'standardization', 'đọc', 'tài liệu', 'hướng toán', 'hơi', 'hoang', 'ví dụ', 'knn', 'logistic', 'regression']"
768,"Xin chào anh chị ạ, anh chị cho em hỏi kỹ năng/kiến thức chuyên môn giữa AI Engineer với AI Researcher/Scientist có khả năng bổ trợ lẫn nhau không ạ? Em muốn định hướng theo hướng AI Engineer nhưng thắc mắc liệu việc tham gia các Lab/đề tài nghiên cứu có giúp mình trong việc làm kỹ sư không ạ (như hiểu rõ các model/hiểu thêm các công nghệ/ý tưởng mới…)?",['#Q&A'],"['chào', 'kỹ năng', 'kiến thức', 'chuyên môn', 'engineer', 'researcher', 'scientist', 'khả năng', 'bổ trợ', 'lẫn', 'định hướng', 'hướng', 'engineer', 'thắc mắc liệu', 'tham gia', 'lab', 'đề tài', 'nghiên cứu giúp', 'kỹ sư', 'model', 'công nghệ', 'tưởng']"
769,"Chào mọi người, em có một tập dữ liệu gồm các chuỗi thông số ví dụ 34,3,38,48,55,... và nhãn của mỗi chuỗi này là 0 hoặc 1( bất thường/không bất thường ).
Em nên dùng LSTM hay model nào ok hơn ạ
Em cảm ơn","['#Q&A', '#deep_learning']","['chào', 'tập liệu', 'chuỗi', 'thông', 'ví dụ', '34', '3', '38', '48', '55', 'nhãn', 'chuỗi', '0', '1', 'bất bất lstm', 'model', 'ok']"
770,"Tuy Claude-2, cạnh tranh với ChatGPT và Bard, chưa được triển tại Việt Nam, nhưng mình đã dùng được 1 thời gian và có ấn tượng tốt với chat bot này. Ưu điểm của Claude-2 là có khả năng ""suy luận"" với long content/text. Vậy câu hỏi rằng làm sao có thể dùng được nó mà không có VNP, giải pháp đơn giản nhất là dùng Opera Browser (trước mình dùng Brave, nhưng Opera cũng có khả năng chặn quảng cáo rất tốt). Sau đây, Anthropic là công ti mẹ của Claude-2 giới thiệu Cook Book cách dùng với long context tại đây","['#sharing', '#nlp']","['claude2', 'cạnh tranh', 'chatgpt', 'bard', 'triển', 'việt nam', '1', 'ấn tượng', 'chat', 'bot', 'ưu claude2', 'khả năng', 'suy luận', 'long', 'content', 'text thể', 'vnp', 'giải pháp', 'đơn giản', 'opera', 'browser', 'brave opera', 'khả năng', 'chặn', 'quảng cáo', 'anthropic', 'công ti', 'mẹ', 'claude2', 'giới thiệu', 'cook', 'book', 'long', 'context']"
771,"Em xin chào các anh chị ạ. Em đọc về mạng RNN dạng Vec2seq, trong sách có đoạn như hình bên dưới ạ. Anh chị nào hiểu được cái phương trình 15.1 đó có ý nghĩa như nào không ạ hay cho em xin cách đọc nó ạ. Em xin cảm ơn rất nhiều ạ. Chúc mọi người một ngày vui vẻ bình an.","['#Q&A', '#deep_learning', '#math']","['chào', 'đọc', 'mạng', 'rnn dạng', 'vec2seq', 'sách', 'đoạn hình', 'phương trình', '15', '1', 'nghĩa', 'đọc', 'chúc', 'vui vẻ', 'bình an']"
772,"E chào cả nhà, e có thắc mắc về cách fune-tune YOLOV8 để model có performance tốt hơn ạ. E đang train yolov8 bằng default settings, và có một số vấn đề e đang gặp phải ạ:
- Hàm loss đang ở mức rất cao, cả trên tập training và val, e đang không biết tại sao lại như vậy ạ, và có cách nào để giảm nó xuống không ạ??
-Dataset là về fabric defect, và có distribution e như trong hình ạ, và e không thể thu thập thêm data được nữa, thì e sử dụng một số mạng GAN để sinh thêm dữ liệu thì có hiệu quả trong bài toán này không ạ?? Hoặc áp dụng thêm các kỹ thuật augmentation nào khác ngoài default setting của Yolov8 để có performance tốt hơn ạ?
- Mọi người gợi ý giúp em cách fine-tune các hyperparameter để có kết quả tốt hơn được không ạ!!
E đang train với card 2080ti 11gb, default settings của YOLOv8 ạ:
task: detect
mode: train
model: yolov8s.pt
data: /root/data/andy/yolo8/Fabricv6/data.yaml
epochs: 400
patience: 50
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: null
exist_ok: false
pretrained: false
optimizer: SGD
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 0
resume: false
amp: true
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
show: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
vid_stride: 1
line_width: null
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
boxes: true
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
cfg: null
v5loader: false
tracker: botsort.yaml
save_dir: runs/detect/train31
Em cám ơn cả nhà ạ!!","['#Q&A', '#deep_learning', '#cv']","['e', 'chào e', 'thắc mắc', 'funetune', 'yolov8', 'model', 'performance', 'e', 'train', 'yolov8', 'default', 'settings', 'e hàm', 'loss', 'tập', 'training', 'val', 'e', 'dataset', 'fabric', 'defect', 'distribution', 'e hình', 'e thể', 'thu thập', 'data', 'e mạng', 'gan', 'sinh liệu', 'hiệu toán', 'áp dụng', 'kỹ thuật', 'augmentation', 'default', 'setting', 'yolov8', 'performance', 'gợi', 'giúp', 'finetune', 'hyperparameter', 'kết e', 'train', 'card', '2080', 'ti', '11', 'gb', 'default', 'settings', 'yolov8', 'task', 'detect', 'mode', 'train', 'model', 'data', 'root', 'data', 'andy', 'yolo8', 'fabricv6', 'data', 'yaml', 'epochs', '400', 'patience', '50', 'batch', '16', 'imgsz', '640', 'save', 'true', 'save_period', '1', 'cache', 'false', 'device', 'null', 'workers', '8', 'project', 'null', 'name', 'null', 'exist_ok', 'false', 'pretrained', 'false', 'optimizer', 'sgd', 'verbose', 'true', 'seed', '0', 'deterministic', 'true', 'single_cls', 'false', 'rect', 'false', 'cos_lr', 'false', 'close_mosaic', '0', 'resume', 'false', 'amp', 'true', 'overlap_mask', 'true', 'mask_ratio', '4', 'dropout', '0', '0', 'val', 'true', 'split', 'val', 'save_json', 'false', 'save_hybrid', 'false', 'conf', 'null', 'iou', '0', '7', 'max_det', '300', 'half', 'false', 'dnn', 'false', 'plots', 'true', 'source', 'null', 'show', 'false', 'save_txt', 'false', 'save_conf', 'false', 'save_crop', 'false', 'show_labels', 'true', 'show_conf', 'true', 'vid_stride', '1', 'line_width', 'null', 'visualize', 'false', 'augment', 'false', 'agnostic_nms', 'false', 'classes', 'null', 'retina_masks', 'false', 'boxes', 'true', 'format', 'torchscript', 'keras', 'false', 'optimize', 'false', 'int8', 'false', 'dynamic', 'false', 'simplify', 'false', 'opset', 'null', 'workspace', '4', 'nms', 'false', 'lr0', '0', '01', 'lrf', '0', '01', 'momentum', '0', '937', 'weight_decay', '0', '0005', 'warmup_epochs', '3', '0', 'warmup_momentum', '0', '8', 'warmup_bias_lr', '0', '1', 'box', '7', '5', 'cls', '0', '5', 'dfl', '1', '5', 'pose', '12', '0', 'kobj', '1', '0', 'label_smoothing', '0', '0', 'nbs', '64', 'hsv_h', '0', '015', 'hsv_s', '0', '7', 'hsv_v', '0', '4', 'degrees', '0', '0', 'translate', '0', '1', 'scale', '0', '5', 'shear', '0', '0', 'perspective', '0', '0', 'flipud', '0', '0', 'fliplr', '0', '5', 'mosaic', '1', '0', 'mixup', '0', '0', 'copy_paste', '0', '0', 'cfg', 'null', 'v5loader', 'false', 'tracker', 'botsort', 'yaml', 'save_dir', 'runs', 'detect', 'train31', 'cám ơn']"
773,"Technical review (đêm ngày 22 tháng 8 năm 2023, GMT+7):
1/ OpenAi cho phép người dùng có thể tự finetune model GPT-3.5 turbo (model GPT-4 sẽ được finetune vào mùa thu, mùa thu ở Bắc bán cầu thường tính vào ngày 22-9 tới 21-12 hàng năm) với giọng văn và các tính năng mà người finetune muốn. Các bạn có thể tham khảo tại đây 

2/ Meta giới thiệu SeamlessM4T, a Multimodal AI Model for Speech and Text Translations trong đó có hỗ trợ tiếng Việt nhé các bạn (xem chi tiết tại đây https://about.fb.com/news/2023/08/seamlessm4t-ai-translation-model/), và mở source tại đây https://github.com/facebookresearch/seamless_communication
3/ HuggingFace giới thiệu IDEFICS: an open reproduction of State-of-the-Art Visual Language model https://huggingface.co/blog/idefics",['#sharing'],"['technical', 'review', 'đêm', '22', '8', '2023', 'gmt', '7', '1', 'openai', 'phép thể', 'finetune', 'model', 'gpt3', '5', 'turbo', 'model', 'gpt4', 'finetune', 'mùa', 'thu', 'mùa', 'thu', 'bắc cầu', '229', '2112', 'hàng', 'giọng', 'văn năng', 'finetune thể', 'tham khảo', '2', 'meta', 'giới thiệu', 'seamlessm4t', 'a', 'multimodal', 'model', 'for speech', 'and text', 'translations', 'tiếng', 'việt', 'chi tiết', 'https', 'about', 'fb', 'com', 'news', '2023', '08', 'seamlessm4taitranslationmodel', 'source', '3', 'huggingface', 'giới thiệu', 'idefics', 'an open', 'reproduction', 'of stateoftheart', 'visual', 'language', 'model']"
774,"VinAI Seminar - ""Principled Frameworks for Designing Deep Learning Models: Efficiency, Robustness, and Expressivity""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Tan Nguyen, NUS
Time: 10:00 am - 11:00 am (GMT+7), Aug 28, 2023",['#webinar'],"['vinai', 'seminar', 'principled', 'frameworks', 'for', 'designing', 'deep', 'learning', 'models', 'efficiency robustness', 'and expressivity', 'register', 'here', 'to', 'access', 'seminar', 'via', 'ms', 'teams', 'speaker', 'tan', 'nguyen', 'nus', 'time', '10', '00', 'am', '11', '00', 'am gmt', '7', 'aug', '28', '2023']"
775,"[GÓC NHỜ TƯ VẤN]: tôi muốn hỏi về việc prompt engineering cho ảnh tạo sinh qua Stable Diffusion.
1/ Có bạn nào chuẩn bị dữ liệu cả ảnh và text để finetune các models Stable Diffusion và ControlNet chưa? Nếu có, xin bạn hãy chia sẻ kinh nghiệm về việc này;
2/ Kinh nghiệm của bạn về việc prompt sao cho models sinh ra ảnh mà bạn mong muốn?
Mình xin cảm ơn những chia sẻ của các bạn trước nhé.
Trân trọng",['#Q&A'],"['góc', 'tư vấn', 'prompt', 'engineering', 'ảnh', 'sinh', 'stable', 'diffusion', '1', 'chuẩn liệu', 'ảnh', 'text', 'finetune', 'models', 'stable', 'diffusion', 'controlnet', 'kinh nghiệm', '2', 'kinh nghiệm', 'prompt', 'models sinh', 'ảnh', 'mong', 'trân trọng']"
776,"Xin chào mn. Có thể nhiều người đã biết trang này nhưng mình thấy khá hữu ích nên vẫn muốn chia sẻ cùng mn. Nếu các bạn muốn tìm luận văn hoặc luận án của các trường dh trên thế giới có thể vào đây nhé. Ko đầy đủ hết các trường nhưng lĩnh vực khá đa dạng, tất nhiên bao gồm cả AI.
https://oatd.org
Hi vọng có thể giúp ích cho mn!",['#sharing'],"['chào', 'mn thể', 'trang hữu ích', 'mn luận', 'văn luận án', 'trường', 'dh', 'giới thể', 'ko trường', 'lĩnh vực', 'đa dạng', 'tất nhiên', 'bao', 'hi vọng thể', 'giúp ích', 'mn']"
777,"Các a/c cho em hỏi một vấn đề nho nhỏ ạ? Em học về OCR và e đang clone paddleOCR bản release 2.6 về colab để train bài toán text recognition. Tuy nhiên khi clone về và chạy dòng lệnh như trên ảnh, thì gặp lỗi trong file setup.py. A/c có thể cho em biết là tại sao lỗi và các sửa như thế nào không ạ? Em xin chân thành cảm ơn ạ. (lỗi này không phải do pip và em cũng đã tìm hiểu nhiều mà mãi chưa sửa đc ạ TT)","['#Q&A', '#cv']","['a', 'c', 'nho học', 'ocr', 'e', 'clone', 'paddleocr', 'release', '2', '6', 'colab', 'train toán', 'text', 'recognition nhiên', 'clone', 'chạy', 'dòng', 'lệnh', 'ảnh', 'lỗi', 'file', 'a', 'c thể', 'lỗi', 'sửa', 'chân thành', 'lỗi', 'pip', 'mãi', 'sửa', 'đc', 'tt']"
778,Em được giao phân loại ý định của 1 người trong 1 đoạn hội thoại ít nhất 2 người. Anh chị nào có kinh nghiệm hay biết có paper nào có thể cho em xin chút hướng dẫn không ạ. Em search gần như chỉ có phân loại ý định của tất cả mn. Em cảm ơn ạ.,['#Q&A'],"['giao', 'phân định', '1', '1', 'đoạn', 'hội thoại', '2', 'kinh nghiệm', 'paper thể', 'chút', 'hướng', 'search', 'phân định', 'tất mn']"
779,Mọi người cho em hỏi có ai có bộ test data của cuộc thi Phân loại sắc thái bình luận https://www.aivivn.com/contests/1 . Em cảm ơn ạ.,"['#Q&A', '#nlp']","['test', 'data', 'thi', 'phân sắc thái bình luận']"
780,"Em đang có bài tập lớn dùng RNN hoặc LSTM để cân bằng kênh âm thanh, bro cũng mảng này không cho em xin ít kinh nghiệm với ạ","['#Q&A', '#deep_learning']","['tập', 'rnn', 'lstm', 'cân', 'kênh', 'âm bro', 'mảng', 'kinh nghiệm']"
781,"PROJECT DỰ BÁO ĐỘT QUỴ TIM (Heart Attack) Full
(vừa ý nghĩa vừa học tập)
---
Tài liệu hướng dẫn Từng step by step cho 1 Project ML:
- Tìm hiểu dữ liệu,
- Quan sát dữ liệu,
- Pre processsing : Gán nhãn, phân loại dữ liệu. Chia tệp Data thành các biến độc lập và phụ thuộc. Chia data thành Training & Test Dataset.
- Tạo ML Modeling function để áp dụng thuật toán phân loại
---
Link tải file pdf : https://drive.google.com/drive/u/0/folders/13s3qEAGXMaLELJSWe_MZyb9uITWK1ZU8
Link Dataset Kaggle: https://www.kaggle.com/.../heart-attack-analysis...
Share by: Learning and sharing for machine learning&Ai",['#sharing'],"['project', 'dự báo', 'đột quỵ', 'tim', 'heart', 'attack', 'full nghĩa', 'học tập', 'tài liệu', 'hướng', 'step', 'by', 'step', '1', 'project', 'ml liệu', 'quan sát liệu', 'pre', 'processsing', 'gán', 'nhãn', 'phân liệu', 'chia', 'tệp', 'data', 'thành', 'biến', 'độc lập', 'phụ', 'chia', 'data', 'thành', 'training', 'test', 'dataset', 'ml', 'modeling', 'function', 'áp dụng', 'thuật toán', 'phân', 'link', 'tải', 'file', 'pdf', 'link', 'dataset', 'kaggle', 'https', 'www', 'kaggle', 'com', 'heartattackanalysis', 'share', 'by learning', 'and sharing', 'for', 'machine', 'learning']"
782,"E chào mọi người ạ, e cài công cụ annotation CVAT trên windows qua git bash theo link hưỡng dẫn https://opencv.github.io/cvat/docs/administration/basics/installation/,
đến bước tạo superuser thì bị báo lỗi
: bash: sudo: command not found
và
$ docker exec -it cvat_server /bin/bash
the input device is not a TTY. If you are using mintty, try prefixing the command with 'winpty'
mng cho e lời khuyên với ạ e cám ơn mng nhiều!!!",['#Q&A'],"['e', 'chào e', 'cài', 'công cụ', 'annotation', 'cvat', 'windows', 'git', 'bash', 'link', 'hưỡng', 'https', 'opencv', 'github', 'io', 'cvat', 'docs', 'administration', 'basics', 'installation', 'superuser', 'báo', 'lỗi', 'bash', 'sudo', 'command', 'not', 'found', 'docker', 'exec', 'it', 'cvat_server', 'bin', 'bash', 'the', 'input', 'device', 'is', 'not', 'a', 'tty', 'if', 'you', 'are', 'using', 'mintty', 'try', 'prefixing', 'the', 'command', 'with', 'winpty', 'mng', 'e khuyên', 'e', 'cám ơn', 'mng']"
783,"Chào mọi người, em đang thử sửa cách trích xuất đặc trưng từ ảnh và muốn hỏi như sau. 
Em có một bức ảnh và các bounding box phát hiện ra người từ bức ảnh đó. Ở mô hình đề xuất của 1 paper em đang đọc, tác giả có dùng tọa độ của các bounding box (kích thước khác nhau) để cắt ra ảnh của từng người trong khung hình. Sau đó, mỗi bức ảnh được resize về kích thước (224, 224) và đưa qua ResNet-34 để trích xuất ra 1 véc-tơ đặc trưng 512 chiều. 
Bây giờ em muốn dùng 1 mạng CNN để trích xuất đặc trưng toàn ảnh thành 1 feature map, rồi biến đổi width và height của bounding box về tương ứng với width và height của feature map, và sau đó trích xuất đặc trưng từ feature map và biến đổi về thành 1 véc-tơ 512 chiều thì có khả thi không ạ?.
Em có thử và biết rằng việc trích xuất từ các bounding box có kích thước khác nhau sẽ cho ra các Tensor có kích thước khác nhau và không reshape về cùng 1 kích thước được. Mọi người cho em xin gợi ý với ạ. ","['#Q&A', '#cv', '#deep_learning']","['chào', 'thử', 'sửa', 'trích xuất', 'đặc trưng', 'ảnh', 'ảnh', 'bounding box', 'phát hiện', 'ảnh', 'mô hình', 'đề xuất', '1', 'paper', 'đọc', 'tác giả', 'tọa độ', 'bounding', 'box kích thước', 'cắt', 'ảnh', 'khung', 'hình ảnh', 'resize kích thước', '224', '224', 'resnet34', 'trích', 'xuất', '1', 'véctơ', 'đặc trưng', '512', 'chiều', '1', 'mạng', 'cnn', 'trích xuất', 'đặc trưng', 'toàn', 'ảnh', 'thành', '1', 'feature', 'map', 'biến đổi', 'width', 'height', 'bounding box', 'tương ứng', 'width', 'height', 'feature', 'map', 'trích xuất', 'đặc trưng', 'feature', 'map', 'biến đổi', 'thành', '1', 'véctơ', '512', 'chiều', 'khả thi', 'thử', 'trích', 'xuất', 'bounding', 'box kích thước', 'tensor kích thước', 'reshape', '1', 'kích thước', 'gợi']"
784,"Trí tuệ Nhân tạo (AI) đã len lỏi khắp nơi, đi vào mọi ngóc ngách của cuộc sống, công việc, giải trí,... Vậy có ai chợt đặt ra câu hỏi: AI là gì? Tại sao hiện nay nó đang nhận được sự quan tâm rất lớn từ khắp mọi ngành?
#AI #NVIDIA #NTC #TheGioiMayChu",['#sharing'],"['trí tuệ nhân', 'len lỏi', 'khắp', 'đi', 'ngóc ngách', 'sống công', 'giải trí', 'khắp', 'ngành']"
785,"Chào anh chị và các bạn trong nhóm ạ, hiện tại em đang làm 1 project về sinh giọng nói ạ, nhưng em lại không có nhiều kiến thức về mảng này nên kết quả ra không được như ý ạ.
Cho em hỏi ở Việt Nam của mình có cộng dồng nào xử lý âm thanh không ạ? Vì em muốn tham khảo 1 số kiến thức ạ.
Cảm ơn các bạn và anh chị trong nhóm.",['#Q&A'],"['chào', '1', 'project', 'sinh giọng', 'kiến thức', 'mảng', 'kết', 'việt nam', 'cộng', 'dồng âm', 'tham khảo', '1', 'kiến thức']"
786,"em chào mọi người ạ, em có tập dữ liệu là các bản tin trạng thái của thiết bị trong Smart Home gửi lên server.
Từ tập dữ liệu này, xử lý bài toán nào được nhỉ....
Em đang định phân tích hành vi người dùng, nhưng cũng chưa biết kĩ thuật sử dụng. Ai có định hướng và phương pháp nào không ạ giúp em với",['#Q&A'],"['chào', 'tập liệu', 'trạng thái', 'thiết smart', 'home', 'gửi', 'server', 'tập liệu', 'toán định', 'phân tích', 'hành vi', 'kĩ thuật', 'định hướng', 'phương pháp', 'giúp']"
787,"Có vẻ như các bạn khá thích thú với các tài liệu hướng dẫn, nhất là dưới dạng cookbook. Nay mình giới thiệu thêm (chắc chắn có nhiều bạn đã biết tới) về cookbook của OpenAI. Hiện nó đã có tới >46k sao, và được cập nhật thường xuyên. Mình chắc chắn sẽ nghiền ngẫm repository này",['#sharing'],"['vẻ', 'thú tài liệu', 'hướng', 'dạng', 'cookbook', 'giới thiệu', 'chắn', 'cookbook', 'openai', 'hiện', '46', 'k', 'cập nhật', 'xuyên', 'chắn', 'nghiền ngẫm', 'repository']"
788,Có anh chị nào đã từng dùng CRAFT để trích xuất thông tin thành công chưa ạ?,['#Q&A'],"['craft', 'trích', 'xuất thông', 'thành công']"
789,Kaggle cung cấp các khóa học chất lượng cao về Khoa học Dữ liệu.,"['#sharing', '#data']","['kaggle', 'cung khóa', 'học chất', 'khoa học liệu']"
790,"Các hệ thống OVX tích hợp NVIDIA GPU mới được thiết kế để tăng tốc quy trình đào tạo và suy luận AI, các tải xử lý chuyên sâu về đồ họa. Một loạt các nhà cung cấp lớn như Dell Technologies, Hewlett Packard Enterprise, Lenovo, Supermicro,v.v... sắp cho ra mắt sản phẩm.
#NVIDIA #OVX #OvxServer #Omniverse",['#sharing'],"['hệ thống', 'ovx tích', 'hợp', 'nvidia', 'gpu', 'thiết kế tốc', 'quy trình', 'đào', 'suy luận tải', 'chuyên sâu', 'đồ', 'họa', 'loạt', 'cung', 'dell', 'technologies', 'hewlett', 'packard', 'enterprise', 'lenovo', 'supermicro', 'v', 'v mắt', 'sản phẩm']"
791,Xin chào mn. Mn cho mình hỏi hiện nay có mô hình hoặc phương pháp nào hiệu quả trong việc detect những đối tượng rất rất nhỏ (tạm gọi tiny object). Mong được mn chia sẻ.,"['#Q&A', '#cv']","['chào', 'mn', 'mn', 'mô hình', 'phương pháp', 'hiệu', 'detect', 'đối tượng', 'tạm', 'gọi', 'tiny', 'object', 'mong', 'mn']"
792,"Padding trong Convolutional Neural Network (CNN) là quá trình thêm các giá trị 0 (hoặc giá trị khác tuỳ theo cách thiết lập) vào xung quanh các biên của ảnh hoặc đặc trưng trước khi thực hiện phép tích chập. Mục đích chính của việc thêm padding là tăng kích thước của đặc trưng hoặc ảnh ban đầu để đảm bảo rằng các biên của ảnh cũng được xử lý một cách hiệu quả.
Có hai loại padding chính:
Valid Padding (Zero Padding): Trong loại này, không có padding được thêm vào, và phép tích chập được thực hiện trực tiếp trên các vùng không gian. Điều này dẫn đến việc giảm kích thước của đặc trưng hoặc ảnh sau khi thực hiện phép tích chập.
Same Padding: Đây là loại padding phổ biến, trong đó padding được thêm vào sao cho kích thước của đặc trưng hoặc ảnh sau khi thực hiện phép tích chập vẫn giữ nguyên kích thước so với ban đầu. Thông thường, giá trị padding được tính dựa trên kích thước của ma trận bộ lọc và các bước của phép tích chập.
Padding có thể giúp duy trì thông tin ở biên của ảnh hoặc đặc trưng sau khi thực hiện phép tích chập và giúp tránh việc mất mát thông tin quá nhiều. Nó cũng có thể giúp kiểm soát việc giảm kích thước quá nhanh của đặc trưng, đặc biệt khi sử dụng nhiều lớp tích chập liên tiếp.","['#sharing', '#deep_learning']","['padding', 'convolutional', 'neural', 'network', 'cnn', 'trình', '0', 'tùy', 'thiết lập', 'xung quanh', 'biên ảnh', 'đặc trưng', 'phép tích', 'chập mục đích', 'padding kích thước', 'đặc trưng', 'ảnh', 'ban đầu', 'biên ảnh', 'hiệu', 'hai', 'padding', 'valid', 'padding', 'zero', 'padding', 'padding', 'phép tích', 'chập gian', 'kích thước', 'đặc trưng', 'ảnh', 'phép tích', 'chập same', 'padding', 'padding', 'phổ biến', 'padding kích thước', 'đặc trưng', 'ảnh', 'phép tích', 'chập nguyên kích thước', 'ban đầu', 'thông padding', 'dựa kích thước', 'ma trận', 'lọc', 'phép tích', 'chập', 'padding thể', 'giúp trì', 'thông biên ảnh', 'đặc trưng', 'phép tích', 'chập giúp', 'mát', 'thông thể', 'giúp', 'kiểm soát', 'kích thước', 'đặc trưng', 'lớp tích', 'chập liên tiếp']"
793,"E chào mng ạ, e đang xử lí dataset cho bài toán defect detection bằng YOLO, em băn khoăn là ngoài các ảnh thuộc các classes lỗi, thì e có nên cho vào ảnh không có lỗi (Just as background without object), nếu thêm vào thì có cải thiện hiệu năng của model không ạ?? E cám ơn mng ạ!!!","['#Q&A', '#data', '#cv']","['e', 'chào mng', 'e', 'xử lí', 'dataset toán', 'defect', 'detection', 'yolo', 'băn khoăn', 'ảnh', 'classes', 'lỗi', 'e', 'ảnh', 'lỗi', 'just', 'as', 'background', 'without', 'object', 'cải thiện', 'hiệu năng', 'model e', 'cám ơn', 'mng']"
794,"Hi mng em có một số thắc mắc ở giai đoạn tiền xử lý data khi mình làm về Object Detection ạ.
Lúc mình đã có một tập dữ liệu được label từ tool labelImg trên github thì em thấy thường thì sẽ phải cần tiền xử lý dữ liệu này rồi mới cho vào train. Em có đọc một pj trên Kaggle thì thấy ngta để mục đó là Data pipeline thì em không hiểu lắm về cụ thể các bước trong đây mình cần làm gì ạ? Mình có những giai đoạn nào những việc làm gì mình cần để ý tới và cần phải làm trong bước này (Data pipeline và pre-processing data).
Mong mọi người giúp em ạ. Nếu được thì mọi người có thể cho em một số trang hoặc sách có nói cụ thể về quá trình này được không ạ. Em cảm ơn mọi người.","['#Q&A', '#data', '#cv']","['hi mng', 'thắc mắc', 'giai đoạn', 'tiền', 'data', 'object', 'detection', 'tập liệu', 'label', 'tool', 'labelimg', 'github', 'tiền liệu', 'train', 'đọc', 'pj', 'kaggle', 'ngta', 'mục', 'data', 'pipeline', 'lắm', 'giai đoạn', 'data', 'pipeline', 'preprocessing', 'data', 'mong', 'giúp thể', 'trang', 'sách', 'trình']"
795,"Chào các bạn,
Các bạn cho mình hỏi framework nào về reinforcement learning good nhất cho training một Agent ạ?","['#Q&A', '#machine_learning']","['chào', 'framework', 'reinforcement', 'learning', 'good', 'training', 'agent']"
796,"Hiệp hội OpenUSD (Alliance for OpenUSD) sẽ tiến đến đảm bảo khả năng tương thích hoàn toàn cho các nội dung và công cụ 3D nhằm triển khai số hóa giữa các ngành công nghiệp.
#OpenUSD #AOUSD #UniversalSceneDescription #NVIDIA #3dworld",['#sharing'],"['hiệp hội', 'openusd', 'alliance', 'for', 'openusd tiến', 'khả năng', 'tương nội dung', 'công cụ', '3', 'd', 'triển khai', 'hóa', 'ngành', 'công nghiệp']"
797,"Mạng nơ-ron tích chập (CNN) là một kiến trúc mạng nơ-ron đặc biệt dành cho việc xử lý dữ liệu hình ảnh và giúp máy tính hiểu và phân tích hình ảnh một cách tự động. Nguyên tắc hoạt động của CNN dựa trên ba khái niệm chính: tích chập, tổng hợp và kích hoạt.
Tích chập (Convolution): Lớp tích chập là lớp đầu tiên trong mạng CNN. Nó sử dụng các bộ lọc (hay còn gọi là kernel) để trượt qua ảnh đầu vào. Mỗi bộ lọc có thể nhận biết các đặc trưng cụ thể trong ảnh như cạnh, góc, hoặc hình dạng. Khi bộ lọc trượt qua ảnh, nó tạo ra các bản đồ đặc trưng (feature maps) bằng cách thực hiện phép tích chập giữa bộ lọc và vùng tương ứng trên ảnh. Các bản đồ đặc trưng này giúp mô hình nhận biết các đặc trưng quan trọng trong hình ảnh.
Tổng hợp (Pooling): Lớp tổng hợp thường đặt sau lớp tích chập. Nhiệm vụ của lớp này là giảm kích thước của các bản đồ đặc trưng bằng cách lấy giá trị lớn nhất hoặc trung bình từ các vùng nhỏ trên bản đồ đặc trưng. Việc này giúp giảm số lượng tham số và chi phí tính toán, đồng thời làm giảm nguy cơ overfitting.
Kích hoạt (Activation): Lớp kích hoạt áp dụng một hàm kích hoạt phi tuyến lên các giá trị trong các bản đồ đặc trưng. Phép kích hoạt này giúp mô hình học cách biểu diễn các đặc trưng phức tạp và tạo tính phi tuyến cho mạng.
Lớp kết nối đầy đủ (Fully Connected Layer): Sau khi thông qua các lớp tích chập, tổng hợp và kích hoạt, dữ liệu được đưa vào lớp kết nối đầy đủ để thực hiện các tác vụ như phân loại hoặc dự đoán. Trong lớp này, các nơ-ron kết nối với tất cả các nơ-ron trong lớp trước, giúp học cách tổ hợp các đặc trưng để đưa ra dự đoán cuối cùng.
Toàn bộ quá trình này, từ lớp tích chập cho đến lớp kết nối đầy đủ, là quá trình học tự động. Mạng nơ-ron tự điều chỉnh các trọng số của các lớp để tối ưu hóa hiệu suất cho nhiệm vụ cụ thể, chẳng hạn như phân loại ảnh.","['#Q&A', '#deep_learning']","['mạng', 'nơron tích', 'chập cnn', 'kiến trúc', 'mạng', 'nơron liệu', 'hình ảnh', 'giúp', 'máy', 'phân tích', 'hình ảnh', 'động', 'nguyên tắc', 'hoạt động', 'cnn', 'dựa', 'khái niệm', 'tích chập', 'tổng hợp', 'kích hoạt tích', 'chập convolution', 'lớp tích', 'chập lớp', 'mạng', 'cnn lọc', 'gọi', 'kernel', 'trượt', 'ảnh', 'đầu', 'lọc thể', 'đặc trưng', 'ảnh', 'cạnh', 'góc', 'hình dạng', 'lọc', 'trượt', 'ảnh', 'đồ', 'đặc trưng', 'feature', 'maps', 'phép tích', 'chập lọc', 'tương ứng', 'ảnh đồ', 'đặc trưng', 'giúp', 'mô hình', 'đặc trưng', 'hình ảnh', 'tổng hợp', 'pooling', 'lớp', 'tổng hợp', 'lớp tích', 'chập', 'nhiệm vụ', 'lớp', 'kích thước đồ', 'đặc trưng', 'trung bình', 'đồ', 'đặc trưng', 'giúp', 'tham', 'chi phí', 'toán', 'nguy overfitting', 'kích hoạt activation', 'lớp', 'kích hoạt áp dụng', 'hàm kích', 'hoạt phi', 'tuyến', 'đồ', 'đặc trưng', 'phép', 'kích hoạt giúp', 'mô hình', 'học', 'biểu diễn', 'đặc trưng', 'phức tạp', 'phi', 'tuyến', 'mạng', 'lớp', 'kết nối', 'fully', 'connected', 'layer', 'thông', 'lớp tích', 'chập', 'tổng hợp kích', 'hoạt liệu', 'lớp', 'kết nối', 'tác vụ', 'phân', 'dự đoán', 'lớp', 'nơron', 'kết nối', 'tất nơron', 'lớp', 'giúp', 'học', 'tổ hợp', 'đặc trưng', 'dự đoán', 'toàn trình', 'lớp tích', 'chập lớp', 'kết nối', 'trình', 'học động', 'mạng', 'nơron', 'chỉnh trọng', 'lớp', 'tối ưu hóa', 'hiệu suất', 'nhiệm vụ', 'chẳng hạn', 'phân ảnh']"
798,"Chào các a/chị của group, em có học và tập tành ứng dụng AI được trong khoảng hơn 1 năm thì có một vài thắc mắc mong a/chị có thể giải đáp giúp em ạ:
Em có thử hai mảng lớn là CV và NLP và cũng tìm tòi các paper đọc để hiểu idea rồi so sánh với các idea khác cũng như rèn luyện kỹ năng lập trình tương ứng cho các paper thì có thấy một điều là nghành này quá rộng để đào sâu cho từng chuyên môn nếu muốn đạt level expert. Cái này đặt ra cho em thắc mắc là liệu có cái gọi là ""AI Engineer"" hay không khi mà lượng kiến thức của một mảng (ví dụ: NLP) đã thực sự rất sâu rồi (theo em sâu là hiểu cặn kẽ, biết ưu nhược điểm và biết cách tìm ra solution tối ưu, chưa kể các vấn đề liên quan như data, deploy, etc.). Vậy theo cái title của vị trí kia thì đồng nghĩa họ phải hiểu sâu rất nhiều mảng phải không ạ ? (Nhiều khi còn cả mấy mảng mở rộng như kiểu Generative, Video, 3D, etc.)
Trong thực tế thì một flow làm việc thì mọi người thường chọn cách tiếp cận với mô hình như nào ạ ? Mọi người sẽ code lại paper từ đầu rồi tweak thủ công hay là sẽ bê nguyên wrapper như kiểu HuggingFace để sử dụng ạ ?
Các vấn đề chuyên sâu về MLOps thì một kỹ sư trong mảng này nên có trong khoảng bao năm kinh nghiệm ạ là tốt ạ ? Liệu nhân lực mảng này và mảng Software nói chung sẽ giao thoa về những skills gì ạ ? Theo em nghĩ là lập trình nói chung, Cloud, Design.
Em cảm ơn a/chị nhiều ạ.",['#Q&A'],"['chào', 'a group', 'học tập tành', 'ứng dụng', '1', 'thắc mắc', 'mong', 'a thể', 'giải đáp', 'giúp', 'thử', 'hai', 'mảng', 'cv', 'nlp tòi', 'paper', 'đọc', 'idea', 'sánh', 'idea', 'rèn luyện', 'kỹ năng', 'lập trình', 'tương ứng', 'paper', 'ngành', 'rộng', 'đào', 'sâu', 'chuyên môn', 'level', 'expert', 'thắc mắc liệu', 'gọi', 'engineer', 'kiến thức', 'mảng', 'ví dụ', 'nlp', 'thực sâu', 'sâu', 'cặn kẽ', 'ưu nhược solution', 'tối ưu data', 'deploy', 'etc', 'title', 'kia', 'đồng nghĩa', 'sâu mảng', 'mấy', 'mảng', 'rộng', 'kiểu', 'generative', 'video', '3', 'd', 'etc', 'flow', 'tiếp cận', 'mô hình', 'code', 'paper', 'đầu', 'tweak', 'thủ công', 'bê nguyên', 'wrapper', 'kiểu', 'huggingface', 'chuyên sâu', 'mlops', 'kỹ sư', 'mảng', 'bao', 'kinh nghiệm liệu', 'nhân lực', 'mảng', 'mảng', 'software', 'giao thoa', 'skills', 'lập trình', 'cloud', 'design', 'a']"
799,"Chào cả nhà. Em là dân ngoại đạo (Y khoa) nhưng đang dịch một bài báo liên quan đến sự kết hợp giữa ML và Y học ạ.
Hiện tại em đã dịch xong rồi nhưng cần người có chuyên môn review vì em không phải người trong ngành nên sợ chưa dùng từ đúng chuẩn.
Xin cả nhà giúp đỡ ạ.",['#Q&A'],"['chào', 'dân', 'ngoại đạo', 'y khoa', 'dịch', 'báo', 'kết hợp', 'ml', 'y học', 'dịch', 'xong', 'chuyên môn', 'review', 'ngành', 'sợ', 'chuẩn', 'giúp đỡ']"
800,"Kubernetes (K8s) không còn là một công cụ chỉ để chạy các workload như ứng dụng web hay microservices, nó chính là nền tảng lý tưởng để hỗ trợ toàn bộ vòng đời của các workload lớn về Trí tuệ nhân tạo (AI) và Học máy (ML), chẳng hạn như các Mô hình ngôn ngữ lớn (LLMs).
#kubernetes #k8s #AI #LLM",['#sharing'],"['kubernetes', 'k8s', 'công cụ', 'chạy', 'workload', 'ứng dụng', 'web', 'microservices tảng', 'lý tưởng', 'toàn', 'vòng', 'đời', 'workload trí tuệ', 'nhân học', 'máy ml', 'chẳng hạn', 'mô hình', 'ngôn ngữ', 'llms']"
801,"Mình tin ở đây có nhiều bạn biết đến trang này https://github.com/TheAlgorithms/ do các bạn Ấn Độ viết để hướng dẫn về giải thuật bằng các ngôn ngữ khác nhau. Trong đó repo https://github.com/TheAlgorithms/Python có nhiều sao nhất, với hơn 164k. Hi vọng, mình chia sẻ ở đây, cho các bạn chưa biết tới nó, có thể là tài liệu tham khảo tốt cho mọi người","['#sharing', '#math']","['trang', 'https', 'github', 'com', 'thealgorithms', 'ấn độ', 'viết', 'hướng', 'giải thuật', 'ngôn ngữ', 'repo', 'python', '164', 'k', 'hi vọng thể', 'tài liệu', 'tham khảo']"
802,"E chào các anh chị a, e đang làm bài toán object detection, e có dataset và e muốn visualize cả bounding box lên cùng 1 ảnh để check bounding box và label đã chính xác hay chưa, E dùng công cụ online là roboflow nhưng nó chậm quá, anh chị có biết tool nào offline không ạ, em cám ơn ạ","['#Q&A', '#cv']","['e', 'chào a', 'e toán', 'object', 'detection', 'e dataset', 'e visualize', 'bounding', 'box', '1', 'ảnh', 'check', 'bounding', 'box', 'label', 'xác', 'e', 'công cụ', 'online', 'roboflow', 'chậm', 'tool', 'offline', 'cám ơn']"
803,"Xin chào cac ban,
Minh đã tong hop một repo cung cấp các tài nguyên cho OOD detection, robustness, and generalization in Deep Learning. Repo nay bao gom các bài báo, bài nói chuyện, thư viện, papers, v.v. Repo này sẽ được duy trì và cập nhật với các nguồn chất lượng cao! Minh hy vọng nó sẽ trở thành mot noi lý tưởng cho bất kỳ thứ gì OOD trong bookmark của bạn. Hãy cho nó một ngôi sao de ung ho minh nếu bạn thấy nó hữu ích;) Cam on nhieu nha!","['#sharing', '#deep_learning']","['chào', 'cac', 'ban minh tong', 'hop', 'repo', 'cung', 'tài nguyên', 'ood', 'detection robustness', 'and generalization', 'in', 'deep', 'learning', 'repo', 'bao', 'gom', 'báo', 'thư viện', 'papers', 'v', 'v', 'repo trì', 'cập nhật', 'chất minh', 'hy vọng', 'mot', 'noi', 'lý tưởng', 'ood', 'bookmark', 'de', 'ung ho', 'minh hữu ích', 'cam on', 'nhieu', 'nha']"
804,Các nhà nghiên cứu từ các trường đại học của Anh đã phát triển một AI có khả năng dự đoán thao tác gõ phím của người dùng với độ chính xác 95% bằng cách lắng nghe âm thanh phát ra khi gõ trên bàn phím.,['#sharing'],"['nghiên cứu', 'trường', 'đại học', 'phát triển', 'khả năng', 'dự đoán', 'thao tác', 'gõ', 'phím độ', 'xác', '95', 'lắng', 'âm phát', 'gõ', 'bàn phím']"
805,"Em chào các tiền bối
Nay em ngoi lên đây để xin các tiền bối xem có quyển sách vào về Reinforcement Learning hay không ạ, kiểu vừa có code implemented vừa có phần giải thích
Em xin chân thành cảm ơn ạ",['#Q&A'],"['chào', 'tiền', 'bối ngoi', 'tiền bối', 'quyển', 'sách', 'reinforcement learning', 'kiểu', 'code', 'implemented', 'giải', 'chân thành']"
806,"Hi mng, em đang làm một mô hình nó nhận diện được con lắc đơn. Em có chuẩn bị một tập dữ liệu bằng các hình ảnh con lắc đơn và dùng LabelIMG để label ảnh, sau đó cho nó vào một file csv.
Em có thử train model trên tập dữ liệu đó thì nó cho ra một kết quả như ảnh dưới đây. Thì em có thắc mắc là liệu đây có fai một trường hợp Overfitting và làm sao để có thể sửa nó ạ.
Em có một câu hỏi nựa là sau khi em train xong như vậy thì em sẽ làm như nào để model có thể đưa ra dự đoán vậy ạ?
Mong mọi người giải đáp ạ 🥹 Em là newbie nên có những chỗ em chưa hiểu ạ.","['#Q&A', '#cv']","['hi mng', 'mô hình', 'diện', 'lắc', 'đơn', 'chuẩn', 'tập liệu', 'hình ảnh', 'lắc', 'đơn', 'labelimg', 'label', 'ảnh', 'file', 'csv', 'thử', 'train', 'model', 'tập liệu', 'kết ảnh', 'thắc mắc liệu', 'fai', 'trường hợp', 'overfitting thể', 'sửa', 'nựa', 'train', 'xong', 'model thể', 'dự đoán', 'mong', 'giải đáp', 'newbie', 'chỗ']"
807,"E chào các ace ạ, e đang làm đề tài Fabric defect detection trên Yolov8 với dataset được cung cấp sẵn, e dùng default model YoloV8(s) để training nhưng kết quả kém quá ạ, Precision và recall và mAP chỉ tầm 0.5 và hàm loss rất cao, có phải dataset của em đang có vấn đề không ạ (em nghĩ là chất có thể chất lượng annontation không đảm bảo và imbalanced ạ), hoặc có thể do nguyên nhân nào khác mà output của em kém vậy ạ??, mng cho e lời khuyên để cải thiện được không ạ, em cảm ơn rất nhiều ạ!!","['#Q&A', '#cv']","['e', 'chào ace', 'e', 'đề tài', 'fabric', 'defect', 'detection', 'yolov8', 'dataset', 'cung', 'sẵn', 'e', 'default', 'model', 'yolov8', 's', 'training kết', 'kém', 'precision', 'recall', 'map', 'tầm', '0', '5', 'hàm loss', 'dataset', 'chất', 'thể chất', 'annontation', 'imbalanced thể', 'nguyên nhân', 'output', 'kém', 'mng', 'e khuyên', 'cải thiện']"
808,"Hi mọi người , mình có học về Vision Transfomer và thấy trong kiến trúc đó có 1 thứ gọi là residual connection(kết nối dư) , nó sẽ lấy input của 1 lớp trong 1 khối(ví dụ như khối multi self-attention) nối với output của lớp cuối cùng trong khối đó, mình đọc thì họ nói là trong quá trình truyền ngược, 1 số hàm kích hoạt phi tuyến tính sẽ bị bỏ qua. Nhưng mình vẫn lấn cấn 1 số thứ như là : cụ thể mục đích và nguyên nhân họ bỏ qua 1 số lớp hay hàm kích hoạt là gì, hàm kích hoạt hay lớp kiểu j sẽ bị loại bỏ và tại soa họ lại nối input của 1 lớp này với output của lớp cuối cùng. Ai có kiến thức giải đáp giúp mình với ạ. Thank mọi người!","['#Q&A', '#deep_learning']","['hi học', 'vision transfomer', 'kiến trúc', '1', 'gọi', 'residual', 'connection', 'kết nối', 'dư input', '1', 'lớp', '1', 'khối', 'ví dụ', 'khối', 'multi', 'selfattention', 'nối', 'output', 'lớp', 'khối', 'đọc', 'trình', 'truyền', 'ngược', '1', 'hàm kích', 'hoạt phi', 'tuyến', 'lấn cấn', '1', 'mục đích', 'nguyên nhân', '1', 'lớp', 'hàm kích', 'hoạt hàm kích', 'hoạt lớp', 'kiểu', 'j soa', 'nối', 'input', '1', 'lớp', 'output', 'lớp', 'kiến thức', 'giải đáp', 'giúp', 'thank']"
809,"Mọi người cho em hỏi là trong bài toán của computer vision như object detection, segmentation,.. thì thường các cty sẽ tận dụng các model đã có sẵn để ứng dụng trực tiếp vd như YOLO, Detectron,.. hay sẽ phần lớn là tự build lại ạ? Em cảm ơn!","['#Q&A', '#cv']","['toán', 'computer', 'vision', 'object', 'detection', 'segmentation', 'cty', 'tận dụng', 'model', 'sẵn', 'ứng dụng', 'vd', 'yolo', 'detectron', 'build']"
810,"Hi mọi người,
Hôm nay Vietcuna trình bản phiên bản thứ 3 của LLM Vietcuna 7B.
Đây là một bản big update từ một mô hình instruction only sang model chat. Ngoài ra khả năng code cũng cải thiện đáng kể.
Đặc biệt, Vietcuna sẽ cho phép bạn dùng trực tiếp trên web như ChatGPT, và sẽ luôn miễn phí.
Link: https://chat.vilm.org/
Ngoài ra, bạn có thể tự tải và host model, finetune theo use case cụ thể của mình từ HuggingFace (chú ý đọc kĩ Model Card). Từ phiên bản thứ 3 trở đi, Vietcuna chính thức miễn phí cho mọi mục đích sử dụng.
Link HuggingFace: https://huggingface.co/vilm/vietcuna-7b-v3
Chúc mọi người có một trải nghiệm thật tốt :)","['#sharing', '#nlp']","['hi hôm', 'vietcuna', 'trình', 'phiên', '3', 'llm', 'vietcuna', '7', 'b', 'big', 'update', 'mô hình', 'instruction', 'only', 'model', 'chat', 'khả năng', 'code', 'cải thiện', 'vietcuna phép', 'web', 'chatgpt', 'miễn phí', 'link', 'https', 'chat', 'vilm', 'org thể', 'tải', 'host', 'model', 'finetune', 'use', 'case', 'huggingface', 'đọc', 'kĩ model', 'card', 'phiên', '3', 'trở', 'đi', 'vietcuna thức', 'miễn phí', 'mục đích', 'link', 'huggingface chúc', 'trải nghiệm']"
811,"Các bác ơi có bác nào đang dùng api AI làm nét ảnh giống snapedit hoặcredmini ko ạ, cho e xin gợi ý một số api với ạ, free càng tốt. E cám ơn các bác nhiều",['#Q&A'],"['api', 'nét', 'ảnh', 'snapedit', 'hoặcredmini', 'ko', 'e gợi', 'api', 'free', 'e', 'cám ơn']"
812,Đừng để tiếng Anh mãi là rào cản với bạn!,['#sharing'],"['đừng', 'tiếng', 'mãi', 'rào cản']"
813,"Mô hình OncoNPC được nghiên cứu và phát triển tại MIT và Viện Ung thư Dana-Farber cho phép dự đoán và xác định nơi hình thành khối u trước di căn thông qua phân tích khoảng 400 gen thường bị đột biến trong ung thư , từ đó đưa ra các liệu trình điều trị phù hợp và hiệu quả hơn so với trước đây
Một bước tiến mới trong việc áp dụng AI vào Y học
Các bạn có thể đọc thêm qua bài viết của MIT bên dưới","['#sharing', '#cv']","['mô hình', 'onconpc', 'nghiên cứu', 'phát triển', 'mit viện', 'ung thư', 'danafarber phép', 'dự đoán', 'xác định', 'hình thành', 'khối u', 'di thông', 'phân tích', '400', 'gen', 'đột biến', 'ung thư', 'liệu trình', 'trị hiệu', 'tiến', 'áp dụng', 'y học thể', 'đọc', 'viết', 'mit']"
814,"Mọi người ơi, em được biết là thường thì Loss Function sử dụng lúc train và lúc test không giống nhau. Mọi người cho em hỏi cách xây dựng Loss Function ở lúc train và lúc test khác nhau như thế nào ạ, ngoài phần khác nhau về regularization thì chúng còn khác nhau ở phần Loss trung bình.
Mọi người giúp em hiểu rõ hơn về vấn đề này với .
Em cảm ơn !!!
Nguồn: Machine Learning: Mì, súp và....","['#Q&A', '#math', '#machine_learning']","['loss', 'function', 'train test', 'xây dựng', 'loss', 'function', 'train', 'test', 'regularization', 'loss', 'trung bình', 'giúp', 'machine', 'learning', 'mì', 'súp']"
815,"Em chào mọi người, em có đọc qua các bài viết về XAI. Về mặt lý thuyết là nó không phải blackbox. Tuy vậy, em vẫn còn những câu hỏi:
Nhưng thế nào là blackbox?
Và các mô hình như CNN và Transformer có là các blackbox hay không?
Những tiêu chuẩn nào để đánh giá một mô hình là blackbox?
Em cảm ơn mọi người ạ","['#Q&A', '#deep_learning']","['chào', 'đọc', 'viết', 'xai', 'mặt', 'lý thuyết', 'blackbox', 'blackbox', 'mô hình', 'cnn', 'transformer', 'blackbox', 'tiêu chuẩn', 'mô hình', 'blackbox']"
816,"Dạ em chào các anh chị và các bạn trong group. Em là người mới bắt đầu học nên muốn tìm các sách về Machine learning bằng tiếng Việt ạ. Anh, chị, bạn nào có sách giấy đã học xong không dùng nữa có thể pass lại cho em không ạ. Em ở Sài Gòn ạ.","['#Q&A', '#machine_learning']","['chào', 'group', 'học', 'sách', 'machine learning', 'tiếng', 'việt', 'sách', 'giấy', 'học', 'xong thể', 'pass', 'sài', 'gòn']"
817,"Chào mọi người , em là người mới học ML , em đang làm 1 dự án phân loại hình ảnh ( 1 số loại hoa ) thông qua app , model của em chạy ở phía server . Chuyện là em dùng model mobilenet_v2 của tensorflow hub để transfer , sau đó lưu model bằng lệnh : model.save(os.path.join('/content/drive/MyDrive/models','flower.h5')) .
sau đó load lại và sử dụng model bằng cách gọi :
flower_model = tf.keras.models.load_model(
(""model/flower/model_flower.h5""),
custom_objects={'KerasLayer':hub.KerasLayer}
)
nó hoạt động bình thường nhưng sau đó 1 khoảng thời gian thì nó lại không chạy được . nó báo : Exception encountered: Trying to load a model of incompatible/unknown type.
'C:\Users\Lenovo\AppData\Local\Temp\tfhub_modules\145bb06ec3b59b08fb564ab752bd5aa222bfb50a' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.
về cơ bản thì em đã có thể fix được lỗi bằng cách xóa cái folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a đi để tiến hành tải lại cái mới . nó hoạt động bình thường nhưng đấy chỉ là cách trị ngọn thôi không trị được gốc vì sau 1 khoảng thời gian nó lại ko hoạt động .
Những gì em hiểu được là : TensorFlow sẽ tạo một thư mục tạm thời để giữ các mô hình đã tải; tuy nhiên, sau một vài ngày hoặc lâu hơn, nội dung của các foler (mô hình đã tải) sẽ bị xóa. Sau đó, khi muốn tải lại một mô hình, TensorFlow sẽ định tuyến đến thư mục tạm thời, nhưng mô hình sẽ bị xóa khỏi thư mục tạm thời. Tức là cái cần thiết để chạy pre model là một model( tải từ tensorflow hub ) đang được lưu trữ ở 1 thư mục tạm thời ( thư mục sẽ bị xóa sau một khoảng thời gian ) vì vậy nó sẽ gây ra lỗi ko tìm thấy file .pb hay .pbtxt để chạy model .
Em nghĩ rằng lỗi sẽ nằm ở phần tensorflow nó quản lý tự động file pb ( pbtxt) khiến cho mình ko thể chỉ định chính xác 2 file pb và pbtxt vào 1 đường dẫn cụ thể ( ko thể bị xóa tự động ) . Hoặc lỗi gây ra bởi quá trình load model .
Mọi người ai đã từng gặp lỗi tương tụ như vậy chưa cho em hướng dẫn fix với .
Đây là những gì trong folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a","['#Q&A', '#python', '#cv']","['chào', 'học', 'ml', '1', 'dự án', 'phân', 'hình ảnh', '1', 'hoa', 'thông app', 'model', 'chạy', 'server', 'model', 'mobilenet_v2', 'tensorflow', 'hub', 'transfer', 'lưu model', 'lệnh', 'model', 'save', 'os', 'path', 'join', 'content', 'drive', 'mydrive', 'models', 'flower', 'h5', 'load', 'model', 'gọi', 'flower_model', 'tf', 'keras', 'models', 'load_model', 'model', 'flower', 'model_flower', 'h5', 'custom_objects', 'keraslayer', 'hub', 'keraslayer', 'hoạt động', 'bình', '1', 'chạy', 'báo', 'exception', 'encountered', 'trying', 'to', 'load a', 'model', 'of incompatible', 'unknown', 'type', 'c', 'users', 'lenovo', 'appdata', 'local', 'temp', 'tfhub_modules', '145', 'bb06ec3b59b08fb564ab752bd5aa222bfb50a', 'contains', 'neither', 'saved_model', 'pb', 'nor', 'saved_model', 'pbtxt thể', 'fix', 'lỗi', 'xóa', 'folder', '145', 'bb06ec3b59b08fb564ab752bd5aa222bfb50a', 'đi', 'tiến hành', 'tải', 'hoạt động', 'bình', 'đấy', 'trị trị', 'gốc', '1', 'ko', 'hoạt động', 'tensorflow', 'thư mục', 'tạm thời', 'mô hình', 'tải nhiên', 'nội dung', 'foler', 'mô hình', 'tải', 'xóa tải', 'mô hình', 'tensorflow định', 'tuyến', 'thư mục', 'tạm thời', 'mô hình', 'xóa', 'thư mục', 'tạm thời', 'tức thiết', 'chạy', 'pre', 'model', 'model tải', 'tensorflow', 'hub', 'lưu trữ', '1', 'thư mục', 'tạm thời', 'thư mục', 'xóa', 'lỗi', 'ko', 'file', 'pb', 'pbtxt', 'chạy', 'model', 'lỗi', 'nằm', 'tensorflow', 'quản lý', 'động', 'file', 'pb', 'pbtxt', 'ko thể', 'định xác', '2', 'file', 'pb', 'pbtxt', '1', 'đường', 'ko thể', 'xóa động', 'lỗi trình', 'load', 'model', 'lỗi', 'tương tụ', 'hướng', 'fix', 'folder', '145', 'bb06ec3b59b08fb564ab752bd5aa222bfb50a']"
818,"Full Project: Airline Passenger Booking Analyze and Forecast using ML
---
Tài liệu hướng dẫn Từng step by step cho 1 Project ML:
- Tìm hiểu dữ liệu,
- Quan sát dữ liệu,
- Pre processsing : Gán nhãn, phân loại dữ liệu. Chia tệp Data thành các biến độc lập và phụ thuộc. Chia data thành Training & Test Dataset.
- Tạo ML Modeling function để áp dụng thuật toán phân loại
- Link download: https://bit.ly/Drive-MachineLearning
----------------
Tài liệu được chia sẻ bởi: Learning&sharing for machine learning & Ai","['#sharing', '#machine_learning', '#data']","['full', 'project', 'airline', 'passenger', 'booking analyze', 'and forecast', 'using', 'ml', 'tài liệu', 'hướng', 'step', 'by', 'step', '1', 'project', 'ml liệu', 'quan sát liệu', 'pre', 'processsing', 'gán', 'nhãn', 'phân liệu', 'chia', 'tệp', 'data', 'thành', 'biến', 'độc lập', 'phụ', 'chia', 'data', 'thành', 'training', 'test', 'dataset', 'ml', 'modeling', 'function', 'áp dụng', 'thuật toán', 'phân link', 'download', 'tài liệu', 'learning', 'sharing', 'for', 'machine', 'learning']"
819,"CUỐN SÁCH KHÔNG THỂ BỎ QUA VỀ AUTOMATED MACHINE LEARNING
Cuốn sách này giúp bạn hiểu rõ về AutoML - tự động hóa quá trình học máy.
✅ Hiểu về AutoML và vai trò quan trọng của AutoML trong việc đơn giản hóa quá trình học máy.
✅ Khám phá các phương pháp và kỹ thuật sử dụng trong AutoML, từ việc chọn đặc trưng, lựa chọn mô hình, điều chỉnh siêu tham số đến đánh giá mô hình.
✅ Tìm hiểu về các hệ thống và công cụ AutoML hiện có trên thị trường, qua các ví dụ và nghiên cứu thực tế.
✅ Đối mặt và vượt qua các thách thức, như khả năng mở rộng, khả năng giải thích và xử lý dữ liệu phức tạp.
✅ Độ tin cậy trong các hệ thống học máy tự động.
📚 Cuốn sách cung cấp các ứng dụng thực tế của AutoML trong các lĩnh vực khác nhau như y tế, tài chính và marketing, giúp bạn thấy rõ lợi ích của AutoML trong việc xây dựng mô hình học máy chính xác một cách nhanh chóng.
Link download qua drive dưới comment.
---------------
Tài liệu được chia sẻ bởi: Learning and Sharing for Machine Learning & AI","['#sharing', '#machine_learning']","['sách thể', 'automated', 'machine', 'learning', 'sách', 'giúp', 'automl động', 'hóa trình', 'học', 'máy', 'automl', 'vai trò', 'automl', 'đơn giản', 'hóa trình', 'học', 'máy', 'khám phá', 'phương pháp', 'kỹ thuật', 'automl', 'đặc trưng', 'lựa', 'mô hình', 'chỉnh siêu', 'tham mô hình', 'hệ thống', 'công cụ', 'automl', 'hiện', 'thị trường', 'ví dụ', 'nghiên cứu', 'đối mặt', 'thách thức', 'khả năng', 'rộng', 'khả năng', 'giải liệu', 'phức tạp độ', 'cậy', 'hệ thống', 'học', 'máy động', 'sách', 'cung ứng dụng', 'automl', 'lĩnh vực', 'y tế', 'tài marketing', 'giúp', 'lợi ích', 'automl', 'xây dựng', 'mô hình', 'học', 'máy', 'xác chóng', 'link', 'download', 'drive', 'comment', 'tài liệu', 'learning and', 'sharing', 'for', 'machine', 'learning']"
820,"Mạng nơ-ron hồi quy đa lớp phân tán (Distributed Multilayer Recurrent Neural Network - DM-RNN) là một kiểu mạng nơ-ron hồi quy (RNN) được thiết kế để xử lý thông tin từ nhiều nguồn đồng thời và đa lớp. Nó là một biến thể của mạng nơ-ron hồi quy đa lớp (ML-RNN), trong đó các đơn vị nơ-ron trong mạng được phân chia thành nhiều nhóm, và mỗi nhóm chỉ xử lý một phần của dữ liệu đầu vào.
Mô hình DM-RNN giúp cải thiện hiệu suất của mạng hồi quy khi xử lý dữ liệu phức tạp và đa nguồn, như trong các ứng dụng như xử lý ngôn ngữ tự nhiên, nhận dạng giọng nói, dự đoán chuỗi thời gian và nhiều tác vụ học tập khác. Bằng cách phân tán các đơn vị nơ-ron, mạng DM-RNN có khả năng xử lý thông tin từ nhiều nguồn cùng một lúc và truyền tải thông tin giữa các lớp mạng một cách hiệu quả.
Các ưu điểm của mạng DM-RNN bao gồm:
Xử lý đa nguồn: Mạng DM-RNN cho phép xử lý thông tin từ nhiều nguồn đồng thời, giúp cải thiện khả năng mô hình hóa dữ liệu phức tạp và đa dạng.
Hiệu quả tính toán: Do các đơn vị nơ-ron được phân tán và chỉ xử lý một phần dữ liệu, mạng DM-RNN có khả năng tính toán hiệu quả và tránh các vấn đề về tính toán phức tạp.
Tính linh hoạt: Mạng DM-RNN có tính linh hoạt cao trong việc kết hợp các nguồn thông tin khác nhau và điều chỉnh kiến trúc mạng dễ dàng để phù hợp với các tác vụ xử lý dữ liệu cụ thể.
Tuy nhiên, mạng DM-RNN cũng có một số thách thức, bao gồm:
Đòi hỏi nhiều dữ liệu huấn luyện: Do mô hình có nhiều tham số và cấu trúc phức tạp, việc huấn luyện mạng DM-RNN có thể đòi hỏi một lượng lớn dữ liệu huấn luyện để đạt được hiệu suất tốt.
Điều chỉnh tham số phức tạp: Việc điều chỉnh các tham số và kiến trúc của mạng DM-RNN có thể phức tạp và đòi hỏi sự chuyên môn cao.
Một số ứng dụng của mạng DM-RNN bao gồm xử lý ngôn ngữ tự nhiên, nhận dạng giọng nói, dự đoán chuỗi thời gian và phân tích dữ liệu chuỗi. Mô hình này đã đem lại những kết quả đáng kể trong việc xử lý và phân tích dữ liệu phức tạp và đa nguồn.","['#deep_learning', '#sharing']","['mạng', 'nơron', 'hồi', 'quy đa', 'lớp', 'phân tán', 'distributed', 'multilayer', 'recurrent', 'neural', 'network', 'dmrnn', 'kiểu', 'mạng nơron', 'hồi', 'quy rnn', 'thiết kế', 'thông đa', 'lớp', 'biến thể', 'mạng nơron', 'hồi', 'quy đa', 'lớp', 'mlrnn', 'nơron mạng', 'phân chia', 'thành liệu', 'đầu', 'mô hình', 'dmrnn', 'giúp', 'cải thiện', 'hiệu suất', 'mạng', 'hồi', 'quy liệu', 'phức tạp đa', 'ứng dụng', 'ngôn ngữ nhiên', 'dạng', 'giọng', 'dự đoán', 'chuỗi tác', 'vụ', 'học tập', 'phân tán', 'nơron mạng', 'dmrnn', 'khả năng', 'thông', 'truyền tải', 'thông', 'lớp', 'mạng hiệu', 'ưu mạng', 'dmrnn', 'bao', 'đa mạng', 'dmrnn phép', 'thông', 'giúp', 'cải thiện', 'khả năng', 'mô hình', 'hóa liệu', 'phức tạp', 'đa dạng', 'hiệu toán', 'nơron', 'phân tán', 'liệu', 'mạng dmrnn', 'khả năng', 'toán', 'hiệu toán', 'phức tạp', 'linh hoạt mạng', 'dmrnn', 'linh hoạt', 'kết hợp', 'thông chỉnh', 'kiến trúc', 'mạng dàng', 'tác vụ', 'liệu nhiên', 'mạng', 'dmrnn', 'thách thức', 'bao', 'đòi liệu', 'huấn luyện', 'mô hình', 'tham cấu trúc', 'phức tạp', 'huấn luyện', 'mạng', 'dmrnn thể', 'đòi liệu', 'huấn luyện', 'hiệu suất', 'chỉnh', 'tham phức', 'tạp chỉnh', 'tham kiến trúc', 'mạng', 'dmrnn thể', 'phức tạp', 'đòi', 'chuyên môn', 'ứng dụng', 'mạng', 'dmrnn bao', 'ngôn ngữ nhiên', 'dạng', 'giọng', 'dự đoán', 'chuỗi', 'phân tích liệu', 'chuỗi', 'mô hình', 'đem', 'kết', 'phân tích liệu', 'phức tạp', 'đa']"
821,"Chào các anh chị, anh chị cho hỏi em mới bắt đầu học các khóa ML của bác Andrew Ng trên cousera thì thấy ở cuối thường có optional lab nhưng mà nó không giải thích ý nghĩa, cách dùng từng câu lệnh. Vậy em phải tự học thêm cách sử dụng mấy thư viện như numpy,... ở ngoài phải không ạ tại em cũng chưa biết gì về python lắm ạ. Em xin cảm ơn.","['#machine_learning', '#Q&A', '#python']","['chào học', 'khóa', 'ml', 'andrew', 'ng', 'cousera', 'optional', 'lab', 'giải nghĩa', 'câu lệnh', 'học', 'mấy', 'thư viện', 'numpy', 'python', 'lắm']"
822,"Cho bạn nào chưa biết , cũng như vẫn đang đợi request từ Meta để access LLaMA 2
Hiện tại , Meta đã mở link mới để request access vào LLaMA 2 , các bạn có thể điền form lại , cũng như đồng bộ với repo của Meta trên Hugging Face ( email khi bạn điền form phải đúng với email tài khoản trên huggingface mới access được repo nhé )
Bạn nào muốn trải nghiệm model LLaMA 2 có thể đăng ký qua form bên dưới
https://ai.meta.com/.../models-and.../llama-downloads/",['#sharing'],"['đợi', 'request', 'meta', 'access', 'llama', '2', 'meta', 'link', 'request', 'access', 'llama', '2', 'thể', 'điền form', 'đồng', 'repo', 'meta', 'hugging', 'face', 'email', 'điền form', 'email', 'tài khoản', 'huggingface', 'access', 'repo', 'trải nghiệm', 'model', 'llama', '2', 'thể', 'đăng ký', 'form', 'https', 'meta', 'com', 'modelsand', 'llamadownloads']"
823,"[Góc tìm developers]
Xin Update: vẩn cần team làm được
Tài chính 200 chịu quay đầu, hợp đồng công chứng đàng hoàng.
Xin chào anh em, mình có vài idea vầy có anh em nào có thể làm forex/stock/crypto/metal trading engine như sau không ạ? Xin chân thành tìm được người
Xin cám ơn cái devs",['#sharing'],"['góc', 'developers', 'update', 'vẩn', 'team tài', '200', 'đầu', 'hợp đồng', 'công chứng', 'đàng hoàng', 'chào idea', 'vầy thể', 'forex', 'stock', 'crypto', 'metal', 'trading', 'engine', 'chân thành', 'cám ơn', 'devs']"
824,"Tiếp theo series ngày hôm qua thì hôm nay thêm đoạn train LoRA để sinh ra các ảnh theo cách của riêng mình.
Hi vọng giúp được các bạn mới học trên con đường tìm hiểu về #stablediffusion. Phần link video để ở phần bình luận nhé (sorry vì ko hiểu sao ông Face bóp tương tác các post có link trong này, khó hiểu thật sự)
#miai","['#sharing', '#cv']","['tiếp', 'series', 'hôm', 'hôm', 'đoạn', 'train', 'lora', 'sinh ảnh', 'hi vọng', 'giúp', 'học đường', 'link video', 'bình luận', 'sorry', 'ko', 'face bóp', 'tương tác', 'post', 'link']"
825,"Mô hình học tập không đối xứng có nhiều ứng dụng hứa hẹn trong thực tế, đặc biệt là trong lĩnh vực trí tuệ nhân tạo và học máy. Dưới đây là một số ví dụ về các ứng dụng của mô hình học tập không đối xứng:

mô hình học tập không đối xứng có thể được sử dụng để nhận diện các đặc trưng quan trọng của các đối tượng trong hình ảnh một cách chính xác hơn.
Trong lĩnh vực xử lý ngôn ngữ tự nhiên, mô hình học tập không đối xứng có thể giúp tập trung vào việc học các mẫu ngôn ngữ phức tạp và quan trọng hơn trong dữ liệu văn bản.
Trong ứng dụng nhận dạng giọng nói, mô hình học tập không đối xứng có thể tập trung vào việc học các đặc điểm quan trọng của giọng nói, như cách luyến ái, nhịp điệu và ngữ điệu, giúp cải thiện độ chính xác của mô hình trong việc nhận dạng và phân tích giọng nói.
Trong lĩnh vực tự động lái xe, mô hình học tập không đối xứng có thể được sử dụng để tối ưu hóa các phản ứng và quyết định của hệ thống lái xe trên cơ sở các tình huống thực tế.

So với các mô hình phổ biến hiện nay như mạng nơ-ron tích chập (CNN) hoặc mạng nơ-ron hồi quy (RNN), mô hình học tập không đối xứng có đặc điểm và hiệu quả khác biệt trong việc tập trung vào việc học các mẫu quan trọng trong dữ liệu.Tuy nhiên, việc sử dụng mô hình học tập không đối xứng cũng có thể đòi hỏi nhiều dữ liệu huấn luyện và tính toán phức tạp hơn để điều chỉnh các trọng số của mạng.","['#sharing', '#machine_learning']","['mô hình', 'học tập', 'đối xứng', 'ứng dụng', 'hứa hẹn', 'lĩnh vực', 'trí tuệ', 'nhân học', 'máy', 'ví dụ', 'ứng dụng', 'mô hình', 'học tập', 'đối xứng', 'mô hình', 'học tập', 'đối xứng thể diện', 'đặc trưng', 'đối tượng', 'hình ảnh', 'xác', 'lĩnh vực', 'ngôn ngữ nhiên', 'mô hình', 'học tập', 'đối xứng thể', 'giúp', 'học mẫu', 'ngôn ngữ', 'phức tạp liệu', 'văn ứng dụng', 'dạng', 'giọng', 'mô hình', 'học tập', 'đối xứng thể', 'học', 'đặc giọng', 'luyến', 'nhịp', 'điệu ngữ điệu', 'giúp', 'cải thiện', 'độ', 'xác', 'mô hình', 'dạng', 'phân tích', 'giọng', 'lĩnh vực', 'động', 'lái xe', 'mô hình', 'học tập', 'đối xứng thể', 'tối ưu hóa', 'phản ứng', 'quyết định', 'hệ thống', 'lái xe', 'sở', 'tình huống', 'mô hình', 'phổ biến', 'mạng', 'nơron tích', 'chập cnn', 'mạng', 'nơron', 'hồi', 'quy rnn', 'mô hình', 'học tập', 'đối xứng', 'đặc hiệu', 'biệt học', 'mẫu', 'liệu nhiên', 'mô hình', 'học tập', 'đối xứng thể', 'đòi liệu', 'huấn luyện toán', 'phức tạp', 'chỉnh trọng', 'mạng']"
826,"Có bao giờ anh em thắc mắc làm sao mà mô hình như GPT4 có thể vừa xử lý ảnh lẫn prompt chưa? Dạo này mình tìm hiểu về Vision-Language models thì thấy thằng BLIP-2 có cách ứng dụng ViT + LLM mà không cần train lại 2 ông to đùng kia => Vừa tiết kiệm mà lại tận dụng được sức mạnh của pretrained ViT + LLM. Hi vọng bài viết sẽ giúp mọi người hiểu hơn về cách multimodal models hoạt động nhé! 
Link Viblo: https://viblo.asia/p/giai-quyet-bai-toan-vision-language-voi-blip-2-va-instructblip-W13VMeW7VY7","['#sharing', '#cv', '#deep_learning']","['thắc mắc', 'mô hình', 'gpt4 thể', 'ảnh', 'lẫn', 'prompt', 'dạo', 'visionlanguage', 'models', 'thằng', 'blip2', 'ứng dụng', 'vit', 'llm', 'train', '2', 'to đùng', 'kia', 'tiết kiệm', 'tận dụng', 'sức', 'pretrained', 'vit', 'llm', 'hi vọng', 'viết', 'giúp', 'multimodal models', 'hoạt động', 'link', 'viblo']"
827,"Kính gửi các bác. Tranh thủ đang học về Stable Diffusion em mạnh dạn làm clip chia sẻ cùng cả nhà. Clip chỉ với mục đích tìm hiểu siêu cơ bản về SD và hướng tới các bạn mới học.
Hi vọng giúp được các bạn!","['#sharing', '#deep_learning']","['kính', 'gửi', 'tranh thủ', 'học', 'stable', 'diffusion dạn', 'clip', 'clip', 'mục đích', 'siêu sd', 'hướng', 'học', 'hi vọng', 'giúp']"
828,"Mô hình học tập không đối xứng (Asymmetric Learning Model) là một loại mô hình học máy hoặc mô hình học tập trong đó quá trình học và điều chỉnh các trọng số của mạng neuron được thực hiện không đối xứng giữa các kết nối nơ-ron.
Trong mô hình học tập đối xứng, các trọng số của mạng neuron được điều chỉnh cùng một lượng cho tất cả các kết nối nơ-ron. Tức là, khi mạng nhận được một tín hiệu đầu vào và tạo ra đầu ra tương ứng, tất cả các trọng số sẽ được điều chỉnh theo cùng một cách để giảm thiểu sai số giữa đầu ra thực tế và đầu ra mong đợi.
Tuy nhiên, trong mô hình học tập không đối xứng, quá trình điều chỉnh các trọng số có thể không được thực hiện cùng một cách cho tất cả các kết nối nơ-ron. Thay vào đó, điều chỉnh trọng số có thể được tùy chỉnh theo cách không đối xứng dựa trên đặc điểm của dữ liệu đầu vào và đầu ra. Điều này cho phép mô hình học tập chủ động tập trung vào việc học các mẫu phức tạp hoặc quan trọng hơn trong dữ liệu, trong khi loại bỏ những mẫu ít quan trọng hoặc nhiễu.
Mô hình học tập không đối xứng có thể có ứng dụng trong nhiều lĩnh vực của học máy và trí tuệ nhân tạo, và nó là một trong những phương pháp mở rộng và tối ưu hóa học tập truyền thống để đạt được hiệu suất cao hơn và khả năng tương thích với các tác vụ phức tạp hơn.","['#sharing', '#machine_learning']","['mô hình', 'học tập', 'đối xứng', 'asymmetric', 'learning', 'model', 'mô hình', 'học', 'máy', 'mô hình', 'học tập', 'trình', 'học', 'chỉnh trọng mạng', 'neuron', 'đối xứng', 'kết nối', 'nơron', 'mô hình', 'học tập', 'đối xứng', 'trọng mạng', 'neuron chỉnh', 'tất kết nối', 'nơron', 'tức mạng', 'tín hiệu', 'đầu', 'đầu', 'tương ứng', 'tất trọng', 'chỉnh thiểu', 'sai', 'đầu', 'đầu', 'mong đợi nhiên', 'mô hình', 'học tập', 'đối xứng', 'trình', 'chỉnh trọng thể', 'tất kết nối', 'nơron', 'thay', 'chỉnh trọng thể', 'tùy chỉnh', 'đối xứng', 'dựa', 'đặc liệu', 'đầu', 'đầu phép', 'mô hình', 'học tập', 'chủ động', 'học mẫu', 'phức tạp liệu', 'mẫu nhiễu', 'mô hình', 'học tập', 'đối xứng thể', 'ứng dụng', 'lĩnh vực', 'học', 'máy trí tuệ', 'nhân phương pháp', 'rộng', 'tối ưu hóa', 'học tập', 'truyền thống', 'hiệu suất', 'khả năng', 'tương tác', 'vụ', 'phức tạp']"
829,"Chào mọi người, trong nhóm mình ai có code về faster r cnn thì cho mình tham khảo với ạ, nếu được là triển khai từ đầu toàn bộ không dùng model có sẵn nhé mọi người, mình muốn hiểu kĩ hơn và tiếp cận nó tốt hơn. Cảm ơn mọi người!","['#Q&A', '#deep_learning']","['chào', 'code', 'faster', 'r', 'cnn', 'tham khảo', 'triển khai', 'đầu', 'toàn', 'model', 'sẵn', 'kĩ', 'tiếp cận']"
830,"Chào mọi người, mình là Khôi Nguyễn. Một năm vừa qua, mình có thời gian đọc và thảo luận nội dung của cuốn sách ""Probabilistic Machine Learning"" của tác giả Kevin Murphy, đây là xuất bản mới của cuốn sách nổi tiếng ""Machine Learning: A Probabilistic Perspective"", xuất bản năm 2012. Đây là một trong những cuốn sách hay nhất về Machine Learning (ML), cung cấp những kiến thức nền tảng và mở rộng của lĩnh vực này. Sau 10 năm, nhận thấy kiến thức về ML tiếp tục thay đổi và cập nhật thì tác giả có cập nhật và mở rộng cuốn sách của mình, cũng như sắp xếp lại nội dung cho phù hợp hơn. Các kiến thức mới được cập nhật bao gồm cả về Machine Learning và Deep Learning, cover cả về Generative Model, Few-shot Learning, Continual Learning, Graph Neural Network, Transformer,... Cuốn sách mới được chia làm 2 cuốn con, đã và đang được xuất bản trong năm 2022 và 2023 này.
Nhận thấy nội dung cuốn sách rất hữu ích nên mình có ý định chia sẽ hướng dẫn đọc cuốn sách này. Lý do chính là nội dung khá là nhiều, xem như là Bible về Machine Learning, nếu có hướng dẫn thì việc đọc sẽ thuận lợi hơn phần nào. Hy vọng rằng, sau khi đọc cuốn sách này (và có thể nhiều lần đọc nữa) thì các bạn có thể tích luỹ được những kiến thức cần thiết phục vụ cho công việc của mình sau này, đặc biệt là các công việc nghiên cứu về ML/AI. Cảm ơn mọi người nhiều đã dành thời gian đọc.
Link của tài liệu hướng dẫn tại đây: https://tinyurl.com/ProbML","['#sharing', '#machine_learning']","['chào', 'khôi nguyễn đọc', 'thảo luận', 'nội dung', 'sách', 'probabilistic machine', 'learning', 'tác giả', 'kevin', 'murphy', 'xuất sách', 'nổi tiếng', 'machine', 'learning', 'a probabilistic', 'perspective', 'xuất', '2012', 'sách', 'machine', 'learning', 'ml cung', 'kiến thức', 'tảng', 'rộng', 'lĩnh vực', '10', 'kiến thức', 'ml cập', 'nhật tác giả', 'cập nhật', 'rộng', 'sách', 'xếp', 'nội dung', 'kiến thức', 'cập nhật', 'bao', 'machine', 'learning', 'deep', 'learning', 'cover', 'generative', 'model', 'fewshot', 'learning', 'continual', 'learning', 'graph', 'neural', 'network', 'transformer', 'sách', 'chia', '2', 'xuất', '2022', '2023', 'nội dung', 'sách', 'hữu ích', 'định', 'chia', 'hướng', 'đọc', 'sách lý', 'nội dung', 'bible', 'machine', 'learning', 'hướng', 'đọc', 'thuận lợi', 'hy vọng', 'đọc', 'sách thể', 'đọc', 'thể tích lũy', 'kiến thức thiết', 'phục vụ', 'công công', 'nghiên cứu', 'ml', 'đọc', 'link', 'tài liệu', 'hướng']"
831,"120 Python Project có Source Code phù hợp cho tất cả các bạn Newbie, Beginers, Intermediate, Advanced.
Link: https://s.net.vn/VFws","['#sharing', '#python']","['120', 'python', 'project', 'source', 'code', 'tất newbie', 'beginers', 'intermediate', 'advanced', 'link']"
832,Kiến trúc và cách hoạt động Stable Diffusion.,"['#sharing', '#deep_learning']","['kiến trúc', 'hoạt động', 'stable', 'diffusion']"
833,Tài liệu khóa học NLP chất lượng cao CS224n của ĐH Stanford 😘,"['#sharing', '#nlp']","['tài liệu', 'khóa học', 'nlp', 'chất', 'cs224n', 'đh', 'stanford']"
834,"Chào mọi người
Sắp tới em có buổi phỏng vấn vị trí Intern AI, anh chị có thể cho em biết các câu hỏi phỏng vấn thường gặp hay tắc tình huống khi đi phỏng vấn này được không ạ. Em cảm ơn ạ.",['#Q&A'],"['chào vấn', 'intern thể vấn tắc', 'tình huống', 'đi vấn']"
835,"120 Python Project có Source Code phù hợp cho tất cả các bạn Newbie, Beginers, Intermediate, Advanced.","['#sharing', '#python']","['120', 'python', 'project', 'source', 'code', 'tất newbie', 'beginers', 'intermediate', 'advanced']"
836,"Một sinh viên Harvard, Maya Bodnick, đã kiểm tra khả năng của GPT-4 trong việc viết các bài luận khoa học xã hội và nhân văn năm thứ nhất. Kết quả là GPT-4 đạt điểm trung bình 3,57 ""đáng nể""!","['#sharing', '#nlp']","['sinh viên', 'harvard', 'maya', 'bodnick', 'kiểm tra', 'khả năng', 'gpt4', 'viết luận', 'khoa học xã hội', 'nhân văn', 'kết gpt4', 'trung bình', '3', '57', 'nể']"
837,"PYTHON VÀ TÀI CHÍNH: DỰ ĐOÁN CHỈ SỐ CHỨNG KHOÁN VNINDEX BẰNG MODEL LOGISTIC REGRESSION
Chứng khoán VNINDEX là chỉ số chung của thị trường chứng khoán Việt Nam và đóng vai trò quan trọng trong việc đo lường sự biến động và phản ánh xu hướng của thị trường. Dự đoán biến động của VNINDEX có thể hỗ trợ nhà đầu tư và các chuyên gia tài chính trong việc đưa ra quyết định thông minh về đầu tư và quản lý rủi ro. Trong bài viết này, hãy cùng ICLS Tech tìm hiểu cách sử dụng mô hình Logistic Regression để dự đoán chỉ số chứng khoán VNINDEX và đạt tỷ lệ đúng dự đoán trên 50% nhé!
#ICLSTech #ThuvienPython #PythonLibraries #AlgoTrading #FinTech #QuantitativeFinance #DataScience
Nguồn: ICLS Tech","['#machine_learning', '#python', '#sharing']","['python', 'tài', 'dự đoán', 'chứng khoán', 'vnindex', 'model', 'logistic', 'regression', 'chứng khoán', 'vnindex', 'thị trường chứng khoán', 'việt nam', 'đóng', 'vai trò', 'đo lường', 'biến động', 'phản ánh', 'xu hướng', 'thị trường', 'dự đoán', 'biến động', 'vnindex thể', 'đầu tư', 'chuyên gia', 'tài', 'quyết định', 'thông minh', 'đầu tư', 'quản lý', 'rủi ro', 'viết', 'icls', 'tech', 'mô hình', 'logistic', 'regression', 'dự đoán', 'chứng khoán', 'vnindex', 'tỷ lệ', 'dự đoán', '50', 'icls', 'tech']"
838,"[Góc tư vấn]
Hi m.n, cho mình hỏi rằng liệu laptop Macbook pro M2 có phù hợp việc học cho lập trình machine learning không? Và việc cài đặt thư viện cho machine learning trên Macbook M2 có tương thích hay là bị xung đột nhiều ko ạ?
Mình định mua laptop Macbook pro M2 để học ML thôi? Chưa cần phải làm việc vs khối lượng lớn dữ liệu như khi đi làm đâu ạ?
Thanks m.n !!!","['#Q&A', '#machine_learning']","['góc', 'tư vấn', 'hi', 'm', 'n liệu', 'laptop', 'macbook', 'pro', 'm2', 'học', 'lập trình', 'machine learning', 'cài', 'thư viện', 'machine', 'learning', 'macbook', 'm2', 'tương xung', 'đột', 'ko định', 'mua', 'laptop', 'macbook', 'pro', 'm2', 'học', 'ml', 'vs', 'khối liệu', 'đi', 'thanks', 'm', 'n']"
839,"Chào mọi người, e dự định học thạc sĩ và nghiên cứu vào ""machine learning"". E mới bắt đầu học nên không biết rõ 1 số môn nên học trước hay sau.
Cụ thể trong trường e có 1 số môn tự chọn, và e tính là sẽ học ""machine learning"" trước sau đó sẽ là ""deep learning"". Nhưng có 1 môn là ""Data Warehousing and Big Data"" thì e không biết là môn này có liên quan mật thiết với việc học machine learning không và nên học nó trước hay sau ""machine learning và deep learning""? Tương tự với môn ""Cloud Computing"" ạ ?
e cảm ơn","['#Q&A', '#machine_learning']","['chào e', 'dự định', 'học', 'thạc sĩ', 'nghiên cứu', 'machine', 'learning', 'e học', '1', 'môn học', 'trường', 'e', '1', 'môn', 'e học', 'machine', 'learning', 'deep', 'learning', '1', 'môn', 'data warehousing', 'and big', 'data', 'e môn', 'mật thiết', 'học', 'machine', 'learning', 'học', 'machine', 'learning', 'deep', 'learning', 'tương môn', 'cloud', 'computing', 'e']"
840,"Xin chào mn ạ, mình là người ko có kiến thức sâu về AI, NLP, NLU,... muốn xây dựng một model theo các data có sẵn mình lụm được trên mạng như này, nhờ mng chỉ cách mình train để tạo thành model với ạ
https://github.com/lab914hust/SmartHomeNLU. git","['#Q&A', '#machine_learning']","['chào', 'mn ko', 'kiến thức', 'sâu', 'nlp nlu', 'xây dựng', 'model', 'data', 'sẵn', 'lụm mạng', 'mng', 'train', 'thành', 'model', 'https', 'github', 'com', 'lab914hust', 'smarthomenlu', 'git']"
841,"Có thể nhiều người biết rồi, nhưng mình thấy Channel này trên youtube khá hay:
https://www.youtube.com/@statquest
Trong đó có nhiều playlists cho Statistics, ML, DeepLearning, ...","['#sharing', '#machine_learning']","['thể', 'channel', 'youtube', 'playlists', 'statistics', 'ml', 'deeplearning']"
842,"Chào mọi người,
Hiện tại nhóm em/mình đang thực hiện một khóa luận tốt nghiệp về thử đồ ảo và gợi ý trang phục (virtual try-on & outfit recommendation). Nhóm có xây dựng một website - 👕KiseKloset hỗ trợ 2 tính năng này với mục đích giúp tăng trải nghiệm khi mua sắm quần áo online. Hệ thống sẽ cho phép thử đồ ảo từ ảnh người mẫu và ảnh áo (hiện nay chỉ mới chỉ hỗ trợ thử áo) sau đó đề xuất thêm các trang phục dựa vào mẫu áo bạn sử dụng và các thông tin cung cấp thêm dưới dạng text.
📎Mọi người có thể đọc thêm hướng dẫn trong trang web để biết thêm chi tiết cách sử dụng.
Rất mong mọi người dành chút thời gian để trải nghiệm thử ứng dụng và đánh giá. Mọi ý kiến của mọi người đều rất giá trị để nhóm đánh giá và cải tiến ứng dụng 🥰
📌Link website: http://selab.edu.vn:20440 or thevncore-lab.mooo(dot)com:20440
📌Mong mọi người cho ý kiến qua khảo sát: https://forms.gle/NNpqY7XiLkdiUh7D9
Em/mình xin cảm ơn.","['#sharing', '#machine_learning']","['chào', 'khóa luận nghiệp', 'thử', 'đồ', 'ảo', 'gợi', 'trang phục', 'virtual', 'tryon', 'outfit', 'recommendation', 'xây dựng', 'website', 'kisekloset', '2', 'năng', 'mục đích', 'giúp', 'trải nghiệm', 'mua sắm', 'quần áo', 'online', 'hệ thống', 'phép', 'thử', 'đồ', 'ảo', 'ảnh', 'mẫu', 'ảnh', 'áo', 'thử', 'áo', 'đề xuất', 'trang phục', 'dựa', 'mẫu', 'áo', 'thông', 'cung dạng', 'text thể', 'đọc', 'hướng', 'trang web', 'chi tiết', 'mong', 'chút', 'trải nghiệm', 'thử', 'ứng dụng kiến', 'cải tiến', 'ứng dụng', 'link', 'website', 'or', 'thevncorelab', 'mooo', 'dot', 'com', '20440', 'mong kiến', 'khảo sát']"
843,"TRỰC QUAN HÓA MẠNG NEURAL NETWORK.
Trang web http://playground.tensorflow.org/ là một công cụ trực quan và tương tác cho phép người dùng thử nghiệm và học tập về các mô hình mạng nơ-ron (neural network) đơn giản.","['#sharing', '#deep_learning']","['trực quan', 'hóa mạng', 'neural', 'network', 'trang web', 'http', 'playground', 'tensorflow', 'org', 'công cụ', 'trực quan', 'tương tác', 'phép', 'thử nghiệm', 'học tập', 'mô hình', 'mạng', 'nơron', 'neural', 'network', 'đơn giản']"
844,Các anh chị em cho mình hỏi ở sg chỗ nào đào tạo ngoài giờ data sientist ổn vậy ạ? Mình cảm ơn mọi người!!,"['#Q&A', '#data']","['sg', 'chỗ', 'đào', 'data', 'sientist', 'ổn']"
845,"Mọi người cho em xin chỗ hay tài liệu dạy về YOLO v7 và cách training nó với ạ, trên mạng ít tài liệu về nó thật sự.","['#Q&A', '#deep_learning']","['chỗ', 'tài liệu', 'dạy', 'yolo', 'v7', 'training mạng', 'tài liệu']"
846,"Chào mọi người, em là sinh viên năm tư ngành Khoa học máy tính. Hiện tại e và nhóm đang phát triển một ứng dụng quét đơn thuốc tự động. Ứng dụng sẽ quét ảnh chụp đơn thuốc giúp người dùng tra cứu thông tin về các loại thuốc mình đang sử dụng, đồng thời có thể đặt lịch uống thuốc để tránh trường hơp sử dụng thuốc không đúng cách. Ứng dụng của nhóm đã có thể tải xuống trên của hàng Play store (do không đủ kinh phí nên chưa thể đăng lên Appstore ạ). Rất mong mọi người dành ít thời gian trải nghiệm ứng dụng. Mọi phản hồi của mọi người đều rất giá trị với nhóm chúng em. Em xin chân thành cảm ơn.
Link tải App: https://bit.ly/3q3VGWz
Ps: Em có đính kèm QR với ảnh demo test app bên dưới, mn có thể tải và sử dụng nhé.","['#sharing', '#cv']","['chào', 'sinh viên', 'tư', 'ngành', 'khoa học', 'máy e', 'phát triển', 'ứng dụng', 'quét', 'đơn', 'thuốc động', 'ứng dụng', 'quét', 'ảnh', 'chụp', 'đơn', 'thuốc', 'giúp', 'tra cứu', 'thông', 'thuốc thể', 'lịch', 'uống', 'thuốc', 'trường', 'hơp', 'thuốc', 'ứng dụng', 'thể tải', 'hàng', 'play', 'store', 'kinh phí thể', 'đăng appstore', 'mong', 'trải nghiệm', 'ứng dụng', 'phản hồi', 'chân thành', 'link tải', 'app', 'ps', 'đính', 'kèm', 'qr', 'ảnh', 'demo', 'test', 'app', 'mn thể', 'tải']"
847,Mình xin phép chia sẻ cho mọi người bài viết giải thích chi tiết về paper LLaMa-2 - một LLM đình đám của Meta mới ra mắt đình đám trong tuần vừa qua. Hi vọng rằng nó sẽ làm thay đổi nhiều thứ trong tương lai của LLM,"['#sharing', '#deep_learning']","['phép', 'viết', 'giải', 'chi tiết', 'paper', 'llama2', 'llm đình', 'đám', 'meta', 'mắt', 'đình đám', 'tuần', 'hi vọng', 'tương lai', 'llm']"
848,Em được giao bài toán phân loại văn bản nhưng trước tiên phải phát hiện slot trước rồi sau đó phân loại văn bản sẽ dựa vào những slot đó kết hợp ngữ nghĩa câu để phân loại. Em có tìm những paper về joint intent and slot filling hay model diet đều theo kiểu phân loại trước rồi từ phân loại văn bản mới tìm slot nên bị ngược với bài toán của em. Em có thử lấy các model ấy test thì kết quả còn tệ hơn nếu mình chỉ dùng mỗi model như bert để phân loại. Không biết anh chị có link paper nào có thể share cho em với được không nhỉ. Em kiếm mãi không tìm thấy paper nào làm như vậy . em cảm ơn,"['#Q&A', '#nlp']","['giao toán', 'phân văn tiên', 'phát hiện', 'slot', 'phân văn', 'dựa', 'slot', 'kết hợp ngữ', 'nghĩa câu', 'phân paper', 'joint intent', 'and slot', 'filling', 'model', 'diet', 'kiểu', 'phân', 'phân văn', 'slot', 'ngược toán', 'thử', 'model', 'test', 'kết tệ', 'model', 'bert', 'phân link', 'paper thể', 'share', 'kiếm', 'mãi', 'paper']"
849,"Mình có 1 bài toán như sau. Mình có input là tên 1 vật (dạng text), và mình muốn ra output là mô tả của vật đó (dạng text). Mô tả của vật thì có 1 format nhất định, vdu nó là động vật hay thực vật, rồi thuộc họ j, có mấy chân, vvv. Mình ko làm về NLP nên ko rõ hiện tại có kĩ thuật j có thể làm đc? Hoặc các bạn có thể gợi ý keywords cũng đc. Mình cảm ơn nhiều.","['#Q&A', '#nlp']","['1', 'toán', 'input', '1', 'vật', 'dạng', 'text', 'output', 'mô tả', 'vật', 'dạng', 'text', 'mô tả', 'vật', '1', 'format định', 'vdu', 'động vật', 'thực vật', 'j', 'mấy', 'chân', 'vvv', 'ko', 'nlp ko', 'kĩ thuật', 'j thể', 'đc thể', 'gợi', 'keywords', 'đc']"
850,"🔥Meta và Microsoft hợp tác công bố Llama 2: Có phiên bản Chat, cho phép thương mại hóa💥
📌MỘT SỐ THÔNG TIN QUAN TRỌNG:
✅Dữ liệu: 2 nghìn tỉ tokens. Nhiều hơn 40% so với Llama 1.
✅Context length: 4096.
✅Kích cỡ: 7B, 13B, 70B tham số (phiên bản 34B chưa được công bố vì chưa đạt tiêu chí an toàn).
✅Hai phiên bản: Llama-2 và Llama-2-chat (được supervised fine-tune trên hơn 100,000 samples và huấn luyên với RLHF trên hơn 1 triệu samples).
Nguồn ảnh: real.ml.memes
-------------------------------
Nguồn: VietAI","['#sharing', '#deep_learning']","['meta', 'microsoft', 'hợp tác', 'công bố', 'llama', '2', 'phiên', 'chat phép', 'thương mại', 'hóa', 'thông liệu', '2', 'nghìn', 'tỉ', 'tokens', '40', 'llama', '1', 'context', 'length', '4096', 'kích cỡ', '7', 'b', '13', 'b', '70', 'b', 'tham phiên', '34', 'b', 'công bố', 'tiêu chí', 'an toàn', 'hai', 'phiên', 'llama2', 'llama2chat', 'supervised', 'finetune', '100', '000', 'samples', 'huấn', 'luyên', 'rlhf', '1', 'triệu', 'samples', 'ảnh', 'real', 'ml', 'memes', 'vietai']"
851,"Chào mọi người, mình đang có model classification có input 2 ảnh và đâu ra là label 0 hoặc 1 (Hình bên dưới). Tuy nhiên phần data preparation em không biết chuẩn bị thế nào. Mặc dù có nghiên cứu nhiều blog trên mạng tuy nhiên gặp khá nhiều lỗi (Blog: https://github.com/keras-team/keras/issues/8130). Bên dưới là code data preparation với ImageDataGenerator. Mong hướng dẫn phần data preparation cho model 2 input ảnh. Mình cảm ơn.","['#Q&A', '#cv', '#data']","['chào', 'model', 'classification', 'input', '2', 'ảnh', 'label', '0', '1', 'hình nhiên', 'data', 'preparation', 'chuẩn', 'mặc', 'nghiên cứu', 'blog', 'mạng nhiên', 'lỗi', 'blog', 'https', 'github', 'com', 'kerasteam', 'keras', 'issues', '8130', 'code', 'data', 'preparation', 'imagedatagenerator', 'mong', 'hướng', 'data', 'preparation', 'model', '2', 'input', 'ảnh']"
852,"Chào mọi người, bên em đang làm 1 dự án trading forex và hàng hóa. Mọi người cho em hỏi là model machine learning nào phù hợp nhất dùng cho trading ạ. Bộ data thì bên em đang lấy tạm trên tradingview xuống. Em cám ơn","['#Q&A', '#machine_learning']","['chào', '1', 'dự án', 'trading', 'forex', 'hàng', 'hóa', 'model', 'machine', 'learning', 'trading', 'data', 'tạm', 'tradingview', 'cám ơn']"
853,"Nhờ các anh giúp em xác định output và input !
Em dùng Machine Learning trong Visual studio Sử dụng tính năng object detection ra được file onnx như thế này
Nhưng khi mình điền input và ouput vào pipeline dùng thư viện ML.net thì báo sai input và output :( !
Không biết tại sao :(
[ColumnName(""input"")]
[VectorType(1, 3, 600, 800)]
public float[] Input { get; set; }
[ColumnName(""boxes"")]
[VectorType(1, 4)]
public float[] Boxes { get; set; }
[ColumnName(""labels"")]
[VectorType(1)]
public long[] Labels { get; set; }
[ColumnName(""scores"")]
[VectorType(1)]
public float[] Scores { get; set;
var pipeline =context.Transforms.ResizeImages(resizing: Microsoft.ML.Transforms.Image.ImageResizingEstimator.ResizingKind.Fill,
outputColumnName: ""resize"",
imageWidth: 800,
imageHeight: 600,
inputColumnName: nameof(RTFInput.ImageSource)
)
.Append(
context.Transforms.ExtractPixels(
offsetImage: 127f,
scaleImage: 1 / 128f,
inputColumnName: ""resize"",
outputColumnName: ""input"")
).Append(
context.Transforms.ApplyOnnxModel(
modelFile: modelFile,
inputColumnNames: new string[] { ""input"" },
outputColumnNames: new string[] { ""scores"", ""boxes"", ""labels"" }));","['#Q&A', '#deep_learning']","['giúp', 'xác định', 'output', 'input', 'machine', 'learning', 'visual', 'studio năng', 'object', 'detection', 'file', 'onnx', 'điền input', 'ouput', 'pipeline', 'thư viện', 'báo', 'sai', 'input', 'output', 'columnname', 'input', 'vectortype', '1', '3', '600', '800', 'public', 'float', 'input', 'get', 'set', 'columnname', 'boxes', 'vectortype', '1', '4', 'public', 'float', 'boxes', 'get', 'set', 'columnname', 'labels', 'vectortype', '1', 'public', 'long', 'labels', 'get', 'set', 'columnname', 'scores', 'vectortype', '1', 'public', 'float', 'scores', 'get', 'set', 'var', 'pipeline', 'context', 'transforms', 'resizeimages', 'resizing', 'microsoft', 'ml', 'transforms', 'image', 'imageresizingestimator', 'resizingkind', 'fill', 'outputcolumnname', 'resize', 'imagewidth', '800', 'imageheight', '600', 'inputcolumnname', 'nameof', 'rtfinput', 'imagesource', 'append', 'context', 'transforms', 'extractpixels', 'offsetimage', '127', 'f', 'scaleimage', '1', '128', 'f', 'inputcolumnname', 'resize', 'outputcolumnname', 'input', 'append', 'context', 'transforms', 'applyonnxmodel', 'modelfile', 'modelfile', 'inputcolumnnames', 'new', 'string', 'input', 'outputcolumnnames', 'new', 'string', 'scores', 'boxes', 'labels']"
854,"#hoidap
Mình mới cà được tầm 6000 comment trên trang tripnow .Mình định làm sentiment analysis. Mỗi comment có score nên mình lấy nó để đánh giá comment là tích cực hay tiêu cực.Nhưng trước khi đi vào model thì bước preprocessing mình có chút thắc mắc đó là trong tiếng việt khi ""Tokenizer"" thì mọi người hay làm thế nào. Dùng 1-gram hay Bigram.
p/s :Do lần đầu áp dụng trong tiếng việt mong mọi người giúp đỡ.","['#Q&A', '#nlp']","['cà', 'tầm', '6000', 'comment trang', 'tripnow định', 'sentiment', 'analysis', 'comment', 'score', 'comment', 'tích cực', 'tiêu cực', 'đi', 'model', 'preprocessing', 'chút', 'thắc mắc', 'tiếng', 'việt', 'tokenizer', '1', 'gram', 'bigram', 'p', 's', 'đầu', 'áp dụng', 'tiếng', 'việt', 'mong', 'giúp đỡ']"
855,"Hi mng nha, em là SV bên ngành tự động hoá trường BK HCM, đợt làm luận văn vừa rồi em có làm đề tài về “3D Object detection và 6D Pose estimation application for robotics bin picking system”, thì khá thích và đam mê về mảng Computer vision/Machine vision muốn theo sau khi tốt nghiệp, nên sau khi vừa hoàn tất chương trình học đợt tháng 6 vừa rồi thì em có tự học kha khá các thuật toán của machine learning, thì có tham khảo các bên tuyển dụng hiện có thì phần lớn các bên tuyển dụng sẽ hướng đến AI engineer luôn và sẽ đòi hỏi biết cả computer vision và NLP, thì em phân vân bây giờ có cần học luôn kiến thức cả NLP và CV luôn không hay tập trung đẩy mạnh mảng CV. Tại em cũng muốn rút ngắn thời gian tự học để có thể xin đi intern tích thêm kinh nghiệm thay vì chờ học xong full tất cả thì quá lâu. Hi vọng mng có thể cho em tí lời khuyên ạ. Em cảm ơn!","['#Q&A', '#cv']","['hi mng', 'nha', 'sv', 'ngành', 'động', 'hóa', 'trường', 'bk hcm', 'đợt', 'luận văn', 'đề tài', '3', 'd', 'object', 'detection', '6', 'd', 'pose', 'estimation', 'application', 'for', 'robotics', 'bin', 'picking system', 'đam mê', 'mảng', 'computer', 'vision', 'machine', 'vision nghiệp', 'hoàn tất', 'chương trình', 'học', 'đợt', '6', 'học', 'kha thuật', 'toán', 'machine', 'learning', 'tham khảo', 'tuyển dụng', 'hiện', 'tuyển dụng', 'hướng', 'engineer', 'đòi', 'computer', 'vision', 'nlp', 'phân vân', 'học', 'kiến thức', 'nlp', 'cv', 'đẩy', 'mảng', 'cv', 'rút', 'ngắn', 'học thể', 'đi', 'intern tích', 'kinh nghiệm', 'thay', 'chờ', 'học', 'xong', 'full tất', 'hi vọng', 'mng thể', 'tí', 'khuyên']"
856,"Mọi người cho em hỏi ạ: Em có 1 bộ dữ liệu khá lớn, nếu mà train cả 1 epoch thì sẽ quá thời gian chạy tối đa trên Kaggle. Nên em định chia đôi thành 2 datasets và làm theo 1 trong 2 cách sau được không hay là nên làm theo cách khác tốt hơn ạ:
1. Train luân phiên 1 epoch với dataset 1 rồi đến 1 epoch với dataset 2
2. Train xong với dataset 1 rồi train tiếp đến dataset 2
Em cảm ơn ạ","['#Q&A', '#machine_learning', '#data']","['1', 'liệu', 'train', '1', 'epoch', 'chạy', 'tối đa', 'kaggle định', 'chia', 'đôi', 'thành', '2', 'datasets', '1', '2', '1', 'train', 'luân phiên', '1', 'epoch', 'dataset', '1', '1', 'epoch', 'dataset', '2', '2', 'train', 'xong', 'dataset', '1', 'train', 'tiếp', 'dataset', '2']"
857,"Chào các anh chị trong group, em mới tìm hiểu về machine learning, đọc đếm đoạn này thì e có 2 câu hỏi:
+) −∇f0(x0) là gì? Vì trước h em hiểu đó là vector gradient nhưng trong bài viết lại ghi là vector pháp tuyến
+) mặt phẳng supporting hyperlane trông ntn trong kgian 3 chiều,
Mong các anh chị giải đáp giúp e ạ, em cảm ơn ạ","['#Q&A', '#math']","['chào', 'group', 'machine', 'learning', 'đọc', 'đếm', 'đoạn', 'e', '2', 'f0', 'x0', 'h', 'vector', 'gradient', 'viết', 'ghi', 'vector pháp', 'tuyến', 'mặt phẳng', 'supporting', 'hyperlane', 'trông', 'ntn', 'kgian', '3', 'chiều', 'mong', 'giải đáp', 'giúp', 'e']"
858,"Mọi người cho em hỏi: Với Text to speech, để đạt được chất lượng thương mại như của Vbee, Vietel, FPT thì họ cần khoảng bao nhiêu giờ dữ liệu vậy? (Bỏ qua vấn đề kỹ thuật)","['#Q&A', '#nlp']","['text', 'to', 'speech chất', 'thương mại', 'vbee', 'vietel', 'fpt liệu', 'kỹ thuật']"
859,"Hi mọi người , em đang tìm hiểu và sử dụng Yolov7 Pose : https://github.com/WongKinYiu/yolov7/tree/pose . Em thấy tác giả đề cập đến model này dựa theo bài báo : https://arxiv.org/ftp/arxiv/papers/2204/2204.06806.pdf . Em là newbie trong mảng này nên chưa biết model hoạt động như thế nào , làm thế nào để lấy được Keypoint ... Mong mọi người chỉ giáo ạ . Mọi người có resources nào thì cho em tham khảo với ạ . Em xin chân thành cảm ơn !!!","['#Q&A', '#deep_learning']","['hi yolov7', 'pose tác giả', 'đề cập', 'model', 'dựa', 'báo', 'newbie', 'mảng', 'model', 'hoạt động', 'keypoint', 'mong giáo resources', 'tham khảo', 'chân thành']"
860,"Em chào mọi người ạ,em đang làm bài toán sử dụng local Naive Bayes Nearest Neighbour phân loại ảnh thú cưng :chuột ,mèo (tập train của mỗi class sẽ có 20 ảnh ,các ảnh đều lấy từ trên mạng)Em có sử dụng SIFT để rút trích đặc trưng ,nhưng kết quả ko đc như mong muốn,em xin hỏi liệu có phương pháp đê cải thiện bài toán không ạ? Em cảm ơn ạ","['#Q&A', '#cv', '#machine_learning']","['chào toán', 'local', 'naive', 'bayes', 'nearest', 'neighbour', 'phân ảnh', 'thú cưng', 'chuột', 'mèo', 'tập', 'train', 'class', '20', 'ảnh', 'ảnh', 'mạng', 'sift', 'rút', 'trích', 'đặc trưng', 'kết ko', 'đc', 'mong liệu', 'phương pháp', 'đê', 'cải thiện toán']"
861,"Chào các bạn, nguyên văn của chuyên gia computer vision FPT có đoạn viết cho bài toán chứng minh thư: :D
""1. Cropper
Tác vụ này xác định 4 góc của thẻ CMND và sau đó cắt về dạng ảnh chữ nhật. Ý nghĩa chính của tác vụ là phục vụ cho việc Detector liền kề sau đó dễ dàng hơn.
Các mô hình phát hiện đối tượng (object detection) phổ biến hiện nay chỉ trả về 2 góc (trái trên phải dưới, hoặc tâm box kèm giá trị chiều ngang dọc) giúp ta định hình một box hình chữ nhật. Chúng tôi sử dụng một mẹo nhỏ bằng cách coi mỗi góc của CMND là một đối tượng và sau đó phát hiện 4 góc này. Tiếp theo đó bằng cách áp dụng một vài phép biến đổi hình học cơ bản để cắt về dạng ảnh chữ nhật.
Mô hình phát hiện mà nhóm nghiên cứu đang sử dụng là bộ phát hiện đơn pha: SSD (SSD: Single Shot MultiBox Detector), với bộ trích xuất đặc trưng là MobileNet v2 (MobileNetV2: Inverted Residuals và Linear Bottlenecks).
SSD cung cấp cho nhóm nghiên cứu tốc độ truy xuất nhanh, trong khi MobileNet v2 giảm số lượng tính toán và bộ nhớ sử dụng nhưng vẫn duy trì được độ chính xác tốt.""
Mình nghĩ là họ muốn detect chính xác 4 điểm giống như regression, tuy vậy mình đang không hiểu cái mẹo nhỏ của họ ở đây cụ thể là gì? Họ coi mỗi góc là một object??? Nghĩa là thế nào? SSD dùng ở đây là để detect vùng chứng minh thư theo hộp chữ nhật chứ làm sao detect 4 điểm?
Các bạn có ý kiến gì không?","['#Q&A', '#cv']","['chào', 'nguyên văn', 'chuyên gia', 'computer', 'vision', 'fpt', 'đoạn', 'viết', 'toán', 'chứng minh thư', 'd', '1', 'cropper', 'tác vụ', 'xác định', '4', 'góc', 'thẻ', 'cmnd', 'cắt', 'dạng', 'ảnh', 'chữ nhật nghĩa', 'tác vụ', 'phục vụ', 'detector', 'liền', 'kề dàng', 'mô hình', 'phát hiện', 'đối tượng', 'object detection', 'phổ biến', '2', 'góc', 'trái', 'tâm box', 'kèm', 'chiều', 'ngang dọc', 'giúp', 'ta', 'định hình', 'box', 'hình chữ nhật', 'mẹo', 'coi', 'góc', 'cmnd', 'đối tượng', 'phát hiện', '4', 'góc', 'tiếp', 'áp dụng', 'phép', 'biến đổi', 'hình học', 'cắt', 'dạng', 'ảnh', 'chữ nhật', 'mô hình', 'phát hiện', 'nghiên cứu', 'phát hiện', 'đơn', 'pha', 'ssd', 'ssd', 'single', 'shot', 'multibox', 'detector', 'trích xuất', 'đặc trưng', 'mobilenet', 'v2', 'mobilenetv2', 'inverted', 'residuals', 'linear', 'bottlenecks', 'ssd cung', 'nghiên cứu', 'tốc độ', 'truy xuất', 'mobilenet', 'v2 toán', 'trì độ', 'xác', 'detect', 'xác', '4', 'regression', 'mẹo', 'coi', 'góc', 'object nghĩa', 'ssd detect', 'chứng minh thư', 'hộp chữ nhật', 'detect', '4', 'kiến']"
862,"Mọi người cho mình hỏi , giờ mình có 1 ảnh chứa 1 số lá bài . Vậy thì có cách nào để đọc được từ hình ảnh rồi ra text gồm giá trị lá bài + Chất của lá bài đó không ! Cảm ơn","['#Q&A', '#cv']","['1', 'ảnh', 'chứa', '1', 'lá', 'đọc', 'hình ảnh', 'text', 'lá', 'chất', 'lá']"
863,"Dạ mọi người có thể cho em xin thông tin về các trại hè, trường hè, workshop, conference, Seminar (offline năm nay) liên quan đến AI/Machine Learning ở Việt Nam không ạ? Em hi vọng post này có thể tổng hợp được thông tin về các sự kiện như thế để mọi người cùng sở thích có thể gặp gỡ và trao đổi ạ ^^.",['#webinar'],"['thể', 'thông trại', 'hè', 'trường', 'hè', 'workshop', 'conference', 'seminar', 'offline', 'machine', 'learning', 'việt nam', 'hi vọng', 'post thể', 'tổng hợp', 'thông kiện', 'sở thể', 'gỡ', 'trao đổi']"
864,Bard của Google đã hỗ trợ thêm các ngôn ngữ mới trong đó có tiếng Việt. Cùng một số tính năng đáng chú ý. Chi tiết tại link sau:,"['#sharing', '#nlp']","['bard google', 'ngôn ngữ', 'tiếng', 'việt năng', 'chi tiết', 'link']"
865,"Cho mình hỏi,
Mình đang xử lý bài toán xếp thời khoá biểu, qua tìm hiểu thì dùng thuật toá Genetic Algorithm (GA) vẫn là phổ biến nhất.
Có ai đã dùng nhiều và chỉ giúp thư viện nào tốt nhất để ứng dụng GA này cho nền .Net không?
Cảm ơn!","['#Q&A', '#machine_learning']","['toán', 'xếp', 'thời khóa', 'biểu thuật', 'tóa', 'genetic', 'algorithm', 'ga', 'phổ biến', 'giúp', 'thư viện', 'ứng dụng', 'ga', 'net']"
866,"Các bạn vui lòng đăng thông tin tuyển sinh, tuyển dụng, và sự kiện tháng 7/2023 vào post này.
Chúc các bạn một mùa hè vui vẻ.",['#sharing'],"['vui', 'đăng thông', 'tuyển sinh', 'tuyển dụng', 'kiện', '7', '2023', 'post chúc', 'mùa', 'hè', 'vui vẻ']"
867,"Em chào tất cả các anh chị có trong đây ạ. Em là sinh viên và em có đang tìm hiểu về transformer. Cụ thể là bài toán text summarization với mô hình PEGASUS . Db là tiếng việt nhưng em đang gặp 1 số vấn đề kiểu khi em Train ra đoạn text summarization nó bị tình trạng mất dấu, mất chữ cái tiếng việt. Anh chị có thể giúp em tìm lý do và khắc phục được không ạ. Em xin cảm ơn","['#Q&A', '#nlp', '#deep_learning']","['chào tất', 'sinh viên', 'transformer toán', 'text', 'summarization', 'mô hình', 'pegasus', 'db', 'tiếng', 'việt', '1', 'kiểu', 'train', 'đoạn', 'text', 'summarization', 'dấu', 'chữ', 'tiếng', 'việt thể', 'giúp lý', 'khắc phục']"
868,"Em chào mọi người ạ.Em là newbie mới nhập môn của ngành.Chuyện là trong quá trình xử lý data em có 1 số thắc mắc mong đc mn giải đáp ạ:
1.Tại sao lại fit trên train và transform trên test? (Cái này em có đọc qua và hiểu sơ sơ nhưng mong đc mọi người giải đáp rõ ràng hơn ạ) Và nếu như vậy thì có bị xem là data leakage khi các tham số sẽ tính trong quá trình fit trên train lại đc áp dụng trên test ?
Hơn nữa theo như em thấy thông thường khi normalize hay encode các thứ thì sẽ fit(fit_transform) trên train và transform trên test vậy với các kĩ thuật khác như xử lý outlier hay missing value thì mình cũng làm như vậy hay là làm với tập nào thì mình fit_transform trên tập đấy luôn ạ?
2.Về data leakage ạ(cũng như cái trên thì cái này em cũng có đọc qua)nhưng vì muốn hiểu cặn kẽ hơn nên em mong được mn giải thích và cách khắc phục,hạn chế hay những điều k đc phép làm để tránh hiện tượng này ạ!
Em xin chân thành cảm ơn mọi người ạ !","['#Q&A', '#data']","['chào newbie', 'nhập môn', 'ngành', 'trình', 'data', '1', 'thắc mắc', 'mong', 'đc', 'mn', 'giải đáp', '1', 'fit', 'train', 'transform test', 'đọc', 'sơ sơ mong', 'đc', 'giải đáp', 'ràng', 'data', 'leakage', 'tham trình', 'fit', 'train', 'đc', 'áp dụng', 'test', 'thông normalize', 'encode', 'fit', 'fit_transform', 'train', 'transform test', 'kĩ thuật', 'outlier', 'missing', 'value', 'tập', 'fit_transform', 'tập', 'đấy', '2', 'data', 'leakage', 'đọc', 'cặn kẽ', 'mong', 'mn giải', 'khắc phục', 'hạn chế', 'k', 'đc phép', 'hiện tượng', 'chân thành']"
869,"Chào anh chị ạ , em hiện tại đã kết thúc năm 1 cntt ,chuẩn bị sang năm 2 em muốn theo AI thì mọi người có thể cho em một số tài liệu , YouTube, hay khoá học nào trên mạng ,tiếng anh hoặc trả phí đều được ạ em cảm ơn mọi người","['#Q&A', '#machine_learning']","['chào', 'kết thúc', '1', 'cntt', 'chuẩn', '2', 'thể', 'tài liệu', 'youtube khóa', 'học mạng', 'tiếng', 'phí']"
870,cho mình hỏi thư viện VietOCR của a Quốc có cấu tạo là vgg19 và transformer đúng không ạ,"['#Q&A', '#deep_learning']","['thư viện', 'vietocr', 'a quốc cấu', 'vgg19', 'transformer']"
871,"🔥KERAS CORE RA MẮT: HỖ TRỢ ĐỒNG THỜI PYTORCH, TENSORFLOW VÀ JAX🔥
✅Giới thiệu Keras Core, tiền thân của Keras 3.0, cho phép sử dụng PyTorch, TensorFlow và JAX trong một đoạn code duy nhất.
👨‍💻""We're excited to share with you a new library called Keras Core, a preview version of the future of Keras. In Fall 2023, this library will become Keras 3.0. Keras Core is a full rewrite of the Keras codebase that rebases it on top of a modular backend architecture. It makes it possible to run Keras workflows on top of arbitrary frameworks — starting with TensorFlow, JAX, and PyTorch."" - Keras Team.
Nguồn: VietAI","['#sharing', '#python']","['keras', 'core', 'mắt', 'pytorch', 'tensorflow', 'jax', 'giới thiệu', 'keras', 'core', 'tiền', 'thân', 'keras', '3', '0', 'phép', 'pytorch', 'tensorflow', 'jax', 'đoạn', 'code', 'we', 're', 'excited', 'to', 'share', 'with', 'you', 'a', 'new', 'library', 'called', 'keras', 'core', 'a', 'preview', 'version', 'of the', 'future', 'of keras', 'in', 'fall', '2023', 'this', 'library', 'will', 'become', 'keras', '3', '0', 'keras', 'core', 'is', 'a', 'full', 'rewrite', 'of the', 'keras', 'codebase', 'that', 'rebases', 'it', 'on', 'top', 'of a', 'modular', 'backend', 'architecture', 'it', 'makes', 'it', 'possible', 'to', 'run keras', 'workflows', 'on', 'top', 'of arbitrary', 'frameworks', 'starting', 'with', 'tensorflow jax', 'and pytorch', 'keras', 'team', 'vietai']"
872,"Kính chào các bác. Nhân dịp đang tìm hiểu về Kafka và thấy có áp dụng được cho ML nên xin mạnh dạn chia sẻ cùng cả nhà. Hi vọng giúp được các bạn mới học.
Link video: https://www.youtube.com/watch?v=JaBXLUdHEDU","['#sharing', '#data']","['kính', 'chào kafka', 'áp dụng', 'ml dạn', 'hi vọng', 'giúp', 'học', 'link', 'video']"
873,"Em chào mọi người. Em có một thắc mắc. Em hiện tại tìm về ML được một thời gian rồi, em cũng có một vài project cá nhân. Hiện tại em muốn tìm một vị trí thực tập. Tuy nhiên khi em tìm hiểu thì em nhận thấy rằng có khá ít công ty tuyển vị trí từ thực tập sinh đến Junior, Middle- (Chủ yếu là em thấy có ở Viettel, Vin và FPT). Em cảm thấy khá hoang mang về tương lai của mình khi em nhận thấy có rất nhiều người đi theo mảng này nhưng có rất ít chỗ tuyển dụng (Em chưa có ý định học lên và nghiên cứu do điều kiện tài chính không cho phép). Mọi người có thể cho em một vài lời khuyên cũng như giới thiệu giúp em một vài nơi để em có thể xin thực tập cũng như phát triển tương lai được không ạ. Em xin chân thành cảm ơn!","['#Q&A', '#machine_learning']","['chào', 'thắc mắc', 'ml', 'project thực', 'tập nhiên', 'công ty', 'tuyển thực tập', 'sinh', 'junior middle', 'chủ yếu', 'viettel', 'vin', 'fpt', 'hoang tương lai', 'đi', 'mảng', 'chỗ', 'tuyển dụng', 'định học', 'nghiên cứu', 'kiện', 'tài phép thể', 'khuyên', 'giới thiệu', 'giúp thể', 'thực tập', 'phát triển', 'tương lai', 'chân thành']"
874,"#ask #Transformer #attention
Chào mọi người, mình đang tìm hiểu về Transformer architecture. Paper ""Attention is all you need"" không mô tả chi tiết về query, key, value để xác định dependency. Theo mình hiểu thì 3 vectors này được tạo ra bằng multiplication between embedding vectors and randomized (?) Q/ K/ V matrics, rồi dùng dot-product attention.
1. Tuy nhiên underlying idea/ intuition của việc sử dụng Q, K, V này là gì? Paper chỉ đề cập how they did it, but not why.
2. Vai trò cụ thể của query, key, value là gì? Vì trong encoder-decoder attention layers, queries come from the decoder layer, keys and values come from the output of the decoder; while for encoder self-attention layers/ decoder self-attention layers, keys, values and queries come from the same place.
Thanks!","['#Q&A', '#deep_learning']","['chào', 'transformer', 'architecture', 'paper', 'attention', 'is', 'all', 'you', 'need', 'mô tả', 'chi tiết', 'query', 'key', 'value', 'xác định', 'dependency', '3', 'vectors', 'multiplication', 'between', 'embedding vectors', 'and randomized', 'q', 'k', 'v', 'matrics', 'dotproduct', 'attention', '1', 'nhiên', 'underlying', 'idea', 'intuition', 'q', 'k', 'v', 'paper', 'đề cập', 'how', 'they', 'did', 'it', 'but', 'not', 'why', '2', 'vai trò', 'query', 'key', 'value', 'encoderdecoder', 'attention', 'layers', 'queries', 'come', 'from', 'the', 'decoder', 'layer keys', 'and values', 'come', 'from', 'the', 'output', 'of the', 'decoder', 'while', 'for', 'encoder', 'selfattention', 'layers', 'decoder', 'selfattention', 'layers', 'keys values', 'and queries', 'come', 'from', 'the', 'same', 'place', 'thanks']"
875,"Hi mọi người,
Hôm nay mình xin phép chia sẻ blog về tổng quan mô hình Transformer, một mô hình khá nổi tiếng trong deep learning, mô hình này cũng là cơ sở của các mô hình BERT khác (và nhiều thứ khác). Do đó, để hiểu được BERTs các bạn cần nắm rất rõ về mô hình Transformer này. 

Ở blog này mình giới thiệu từ tổng quan đến cực kì chi tiết kiến trúc mô hình, giải thích tại sao các đề xuất về cơ thế positional encoding và self attention lại hợp lý. Đồng thời các điểm lưu ý để huấn luyện mô hình. 

Đồng thời mình cũng cung cấp source code để huấn luyện mô hình Transformer trên tập song ngữ TED gồm 600k câu do mình tự thu thập và matching cho các bạn tham khảo. Với bộ dữ liệu hy vọng giảm bớt khó khăn khi đi xin dữ liệu :)

Blog các bạn có thể đọc tại đây nhé.
https://pbcquoc.github.io/transformer/
Source code notebook thì các bạn clone về tại đây.
https://github.com/pbcquoc/transformer
Notebook tìm tại đây: 
https://github.com/pbcquoc/transformer/blob/master/transformer.ipynb
Bộ dữ liệu song ngữ anh-việt tại đây. 
https://drive.google.com/file/d/141kAeLKRHxHHkWCru6t1QZS6PRo8i_vE/view?usp=sharing
Các bạn có thể thảo luận tại đây hoặc tại blog của mình nhé. ","['#sharing', '#deep_learning']","['hi', 'hôm', 'phép', 'blog', 'tổng quan', 'mô hình', 'transformer', 'mô hình', 'nổi tiếng', 'deep', 'learning', 'mô hình', 'sở', 'mô hình', 'bert', 'berts', 'nắm', 'mô hình', 'transformer', 'blog', 'giới thiệu', 'tổng quan', 'cực kì', 'chi tiết', 'kiến trúc', 'mô hình', 'giải', 'đề xuất', 'positional', 'encoding', 'self', 'attention', 'hợp lý', 'lưu huấn luyện', 'mô hình', 'cung source', 'code', 'huấn luyện', 'mô hình', 'transformer tập', 'song ngữ', 'ted', '600', 'k', 'câu', 'thu thập', 'matching', 'tham khảo liệu', 'hy vọng', 'bớt', 'khăn', 'đi liệu', 'blog thể', 'đọc', 'https', 'pbcquoc', 'github', 'io', 'transformer', 'source', 'code', 'notebook', 'clone', 'notebook', 'blob', 'master', 'transformer', 'ipynb liệu', 'song ngữ', 'anhviệt thể', 'thảo luận', 'blog']"
876,"Chào mọi người !!.Em hiện tại có mong muốn ngắn hạn là trở thành thực tập sinh AI ,mong anh chị có thể tư vấn giúp em cần phải làm như thế nào ,về lộ trình cần học, kỹ năng tìm kiếm việc,cũng như chứng minh đủ năng lực với nhà tuyển dụng, ,Em đang là sinh viên năm 3 công nghệ thông tin muốn theo đuổi đam mê là AI , em có nền tảng cơ bản là toán nhưng lại khá đuối tiếng anh chỉ có thể dịch cơ bản tiếng anh,em cũng đã thử sức với neural network,CNN,rnn, training ,framework tensorflow, pytorch, một số thuật toán machine learning, cũng như code có một số code cơ bản deeplearning về nhận diện ,tạo ảnh ,tạo văn bản.","['#Q&A', '#machine_learning']","['chào mong', 'ngắn hạn', 'thực tập', 'sinh', 'mong thể', 'tư vấn', 'giúp', 'lộ trình', 'học', 'kỹ năng', 'kiếm', 'chứng minh', 'năng lực', 'tuyển dụng', 'sinh viên', '3', 'công nghệ thông đuổi', 'đam mê', 'tảng', 'toán đuối', 'tiếng thể', 'dịch', 'tiếng', 'thử', 'sức', 'neural', 'network', 'cnn', 'rnn', 'training', 'framework', 'tensorflow', 'pytorch thuật', 'toán', 'machine', 'learning', 'code', 'code', 'deeplearning diện', 'ảnh', 'văn']"
877,Xin phép chia sẻ với các bác một lộ trình trở thành Data Scientist ạ. Lộ trình này được đút kết từ chính kinh nghiệm của bản thân nên xin các bác gạch đá nhẹ tay ạ 🥲.,"['#Q&A', '#data']","['phép', 'lộ trình', 'data', 'scientist', 'lộ trình', 'đút kết', 'kinh nghiệm', 'thân', 'gạch đá', 'nhẹ']"
878,"Chào anh chị, em muốn hỏi về tiền xử lý dữ liệu ạ.
Trong dataset movie có một số categorical feature có nhiều giá trị cho một record. Ví dụ như credits là danh sách các diễn viên, đạo diễn của phim. Mỗi record chứa một list gồm trung bình 15-30 giá trị, có khoảng 140000 giá trị khác nhau cho toàn bộ dataset.
Em thắc mắc là mình nên dùng phương pháp gì để chuyển về vector số cho vào model ML (Catboost, XGBoost,...) ạ? Bởi vì one-hot encoding hoặc tokenizer em thấy đều không khả thi.
Em cảm ơn ạ.","['#Q&A', '#data']","['chào', 'tiền liệu', 'dataset', 'movie', 'categorical', 'feature', 'record', 'ví dụ', 'credits', 'danh sách', 'diễn viên', 'đạo diễn', 'phim', 'record', 'chứa', 'list', 'trung bình', '1530', '140000', 'toàn', 'dataset', 'thắc mắc', 'phương pháp', 'vector', 'model', 'ml', 'catboost', 'xgboost', 'onehot', 'encoding', 'tokenizer', 'khả thi']"
879,"Chào mọi người ạ , mình mới học về object deetection và Faster R-CNN, minhd có tham khảo và chạy thử code https://github.com/wingedrasengan927/pytorch-tutorials/blob/master/Object%20Detection/utils.py

code gốc thì train bằng cpi, và mình muốn dùng gpu để train , nhưng lạ là mình đã to(device) cả mô hình và data trong hàm train:

def training_loop(model, learning_rate, train_dataloader, n_epochs,device):
model.to(device)
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
model.train()
loss_list = []
for i in tqdm(range(n_epochs)):
total_loss = 0
for img_batch, gt_bboxes_batch, gt_classes_batch in train_dataloader:
img_batch = img_batch.to(device)
gt_bboxes_batch = gt_bboxes_batch.to(device)
gt_classes_batch = gt_classes_batch.to(device)
# forward pass
loss = model(img_batch, gt_bboxes_batch, gt_classes_batch)
# backpropagation
optimizer.zero_grad()
loss.backward()
optimizer.step()
total_loss += loss.item()
loss_list.append(total_loss)
return loss_list

nhưng vẫn gặp lỗi 
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-23-ba5d2a14be34> in <cell line: 4>()
      2 n_epochs = 1000
      3 
----> 4 loss_list = training_loop(detector, learning_rate, od_dataloader, n_epochs,device)
8 frames
<ipython-input-22-14c287b01571> in training_loop(model, learning_rate, train_dataloader, n_epochs, device)
     16 
     17             # forward pass
---> 18             loss = model(img_batch, gt_bboxes_batch, gt_classes_batch)
     19 
     20             # backpropagation
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
   1499                 or _global_backward_pre_hooks or _global_backward_hooks
   1500                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1501             return forward_call(*args, **kwargs)
   1502         # Do not call functions when jit is used
   1503         full_backward_hooks, non_full_backward_hooks = [], []
<ipython-input-3-e0dda12f5636> in forward(self, images, gt_bboxes, gt_classes)
    189 
    190         total_rpn_loss, feature_map, proposals, \
--> 191         positive_anc_ind_sep, GT_class_pos = self.rpn(images, gt_bboxes, gt_classes)
    192 
    193         # get separate proposals for each sample
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
   1499                 or _global_backward_pre_hooks or _global_backward_hooks
   1500                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1501             return forward_call(*args, **kwargs)
   1502         # Do not call functions when jit is used
   1503         full_backward_hooks, non_full_backward_hooks = [], []
<ipython-input-3-e0dda12f5636> in forward(self, images, gt_bboxes, gt_classes)
     88         positive_anc_ind, negative_anc_ind, GT_conf_scores, \
     89         GT_offsets, GT_class_pos, positive_anc_coords, \
---> 90         negative_anc_coords, positive_anc_ind_sep = get_req_anchors(anc_boxes_all, gt_bboxes_proj, gt_classes)
     91 
     92         # pass through the proposal module
<ipython-input-2-3424462ffbf3> in get_req_anchors(anc_boxes_all, gt_bboxes_all, gt_classes_all, pos_thresh, neg_thresh)
    190     # get the iou matrix which contains iou of every anchor box
    191     # against all the groundtruth bboxes in an image
--> 192     iou_mat = get_iou_mat(B, anc_boxes_all, gt_bboxes_all)
    193 
    194     # for every groundtruth bbox in an image, find the iou
<ipython-input-2-3424462ffbf3> in get_iou_mat(batch_size, anc_boxes_all, gt_bboxes_all)
    149         gt_bboxes = gt_bboxes_all[i]
    150         anc_boxes = anc_boxes_flat[i]
--> 151         ious_mat[i, :] = ops.box_iou(anc_boxes, gt_bboxes)
    152 
    153     return ious_mat
/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py in box_iou(boxes1, boxes2)
    269     if not torch.jit.is_scripting() and not torch.jit.is_tracing():
    270         _log_api_usage_once(box_iou)
--> 271     inter, union = _box_inter_union(boxes1, boxes2)
    272     iou = inter / union
    273     return iou
/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py in _box_inter_union(boxes1, boxes2)
    242     area2 = box_area(boxes2)
    243 
--> 244     lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]
    245     rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]
    246
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
code của mình ở link dưới, ai có thể giúp mình sửa lỗi với ạ
https://colab.research.google.com/drive/1WBX5GwKH5_pWajqJe60vVhzRDotf-LI8?usp=sharing","['#Q&A', '#deep_learning']","['chào', 'học', 'object', 'deetection', 'faster', 'rcnn', 'minhd', 'tham khảo', 'chạy', 'thử', 'code', 'code', 'gốc', 'train', 'cpi', 'gpu', 'train', 'lạ', 'to device', 'mô hình', 'data', 'hàm train', 'def', 'training_loop', 'model', 'learning_rate', 'train_dataloader', 'n_epochs', 'device', 'model', 'to', 'device', 'optimizer', 'optim', 'adam', 'model', 'parameters', 'lr', 'learning_rate', 'model', 'train', 'loss_list', 'for', 'i', 'in', 'tqdm', 'range', 'n_epochs', 'total_loss', '0', 'for', 'img_batch', 'gt_bboxes_batch', 'gt_classes_batch', 'in', 'train_dataloader', 'img_batch', 'img_batch', 'to', 'device', 'gt_bboxes_batch', 'gt_bboxes_batch', 'to', 'device', 'gt_classes_batch', 'gt_classes_batch', 'to', 'device', 'forward', 'pass', 'loss', 'model', 'img_batch', 'gt_bboxes_batch', 'gt_classes_batch', 'backpropagation', 'optimizer', 'zero_grad', 'loss', 'backward', 'optimizer', 'step', 'total_loss', 'loss', 'item', 'loss_list', 'append', 'total_loss', 'return', 'loss_list', 'lỗi', 'runtimeerror', 'traceback', 'most', 'recent', 'call', 'last', 'ipythoninput23ba5d2a14be34', 'in', 'cell', 'line', '4', '2', 'n_epochs', '1000', '3', '4', 'loss_list', 'training_loop', 'detector', 'learning_rate', 'od_dataloader', 'n_epochs', 'device', '8', 'frames', 'ipythoninput2214c287b01571', 'in', 'training_loop', 'model', 'learning_rate', 'train_dataloader', 'n_epochs', 'device', '16', '17', 'forward', 'pass', '18', 'loss', 'model', 'img_batch', 'gt_bboxes_batch', 'gt_classes_batch', '19', '20', 'backpropagation', 'usr', 'local', 'lib', 'python3', '10', 'distpackages', 'torch', 'nn', 'modules', 'module', 'py', 'in', '_call_impl', 'self', 'args', 'kwargs', '1499', 'or', '_global_backward_pre_hooks', 'or', '_global_backward_hooks', '1500', 'or', '_global_forward_hooks', 'or', '_global_forward_pre_hooks', '1501', 'return', 'forward_call', 'args', 'kwargs', '1502', 'not', 'call', 'functions', 'when', 'jit', 'is', 'used', '1503', 'full_backward_hooks', 'non_full_backward_hooks', 'ipythoninput3e0dda12f5636', 'in', 'forward', 'self', 'images', 'gt_bboxes', 'gt_classes', '189', '190', 'total_rpn_loss', 'feature_map', 'proposals', '191', 'positive_anc_ind_sep', 'gt_class_pos', 'self', 'rpn', 'images', 'gt_bboxes', 'gt_classes', '192', '193', 'get', 'separate', 'proposals', 'for', 'each', 'sample', 'usr', 'local', 'lib', 'python3', '10', 'distpackages', 'torch', 'nn', 'modules', 'module', 'py', 'in', '_call_impl', 'self', 'args', 'kwargs', '1499', 'or', '_global_backward_pre_hooks', 'or', '_global_backward_hooks', '1500', 'or', '_global_forward_hooks', 'or', '_global_forward_pre_hooks', '1501', 'return', 'forward_call', 'args', 'kwargs', '1502', 'not', 'call', 'functions', 'when', 'jit', 'is', 'used', '1503', 'full_backward_hooks', 'non_full_backward_hooks', 'ipythoninput3e0dda12f5636', 'in', 'forward', 'self', 'images', 'gt_bboxes', 'gt_classes', '88', 'positive_anc_ind', 'negative_anc_ind', 'gt_conf_scores', '89', 'gt_offsets', 'gt_class_pos', 'positive_anc_coords', '90', 'negative_anc_coords', 'positive_anc_ind_sep', 'get_req_anchors', 'anc_boxes_all', 'gt_bboxes_proj', 'gt_classes', '91', '92', 'pass', 'through', 'the', 'proposal', 'module', 'ipythoninput23424462ffbf3', 'in', 'get_req_anchors', 'anc_boxes_all', 'gt_bboxes_all', 'gt_classes_all', 'pos_thresh', 'neg_thresh', '190', 'get', 'the', 'iou', 'matrix', 'which', 'contains', 'iou', 'of every', 'anchor', 'box', '191', 'against', 'all', 'the', 'groundtruth', 'bboxes', 'in', 'an image', '192', 'iou_mat', 'get_iou_mat', 'b', 'anc_boxes_all', 'gt_bboxes_all', '193', '194', 'for', 'every', 'groundtruth', 'bbox', 'in', 'an image', 'find', 'the', 'iou', 'ipythoninput23424462ffbf3', 'in', 'get_iou_mat', 'batch_size', 'anc_boxes_all', 'gt_bboxes_all', '149', 'gt_bboxes', 'gt_bboxes_all', 'i', '150', 'anc_boxes', 'anc_boxes_flat', 'i', '151', 'ious_mat', 'i', 'ops', 'box_iou', 'anc_boxes', 'gt_bboxes', '152', '153', 'return', 'ious_mat', 'usr', 'local', 'lib', 'python3', '10', 'distpackages', 'torchvision', 'ops', 'boxes', 'py', 'in', 'box_iou', 'boxes1', 'boxes2', '269', 'if', 'not', 'torch', 'jit is_scripting', 'and not', 'torch', 'jit', 'is_tracing', '270', '_log_api_usage_once', 'box_iou', '271', 'inter', 'union', '_box_inter_union', 'boxes1', 'boxes2', '272', 'iou', 'inter', 'union', '273', 'return', 'iou', 'usr', 'local', 'lib', 'python3', '10', 'distpackages', 'torchvision', 'ops', 'boxes', 'py', 'in', '_box_inter_union', 'boxes1', 'boxes2', '242', 'area2', 'box_area', 'boxes2', '243', '244', 'lt', 'torch', 'max', 'boxes1', 'none', '2', 'boxes2', '2', 'n', 'm', '2', '245', 'rb', 'torch', 'min', 'boxes1', 'none', '2', 'boxes2', '2', 'n', 'm', '2', '246', 'runtimeerror', 'expected', 'all', 'tensors', 'to', 'be', 'on', 'the', 'same', 'device', 'but', 'found', 'at', 'least', 'two', 'devices', 'cuda', '0', 'and cpu', 'code', 'link thể', 'giúp', 'sửa', 'lỗi']"
880,"Chào mọi người, hiện tại em có đẩy một project python lên Pythonanywhere, mọi thứ đều rất ổn ngoại trừ cái Tesseract, em không rõ tại sao nó lại trở nên quá chậm
from tesserocr import PyTessBaseAPI
with PyTessBaseAPI(path=TESSDATA_DIR) as api:
for _img in gray_images:
pil_image = Image.fromarray(_img)
api.SetImage(pil_image)
start_time = time.time()
text = ''.join(re.findall(r'\d+', api.GetUTF8Text()))
print('get_cells_2-ocr: ', time.time() - start_time)
_results.append(text)

On local:
get_cells_2-ocr:  0.009741067886352539
get_cells_2-ocr:  0.007970333099365234
get_cells_2-ocr:  0.0022356510162353516
get_cells_2-ocr:  0.00189208984375
get_cells_2-ocr:  0.25850939750671387
get_cells_2-ocr:  0.16674566268920898
get_cells_2-ocr:  1.3970351219177246
get_cells_2-ocr:  0.06349921226501465
get_cells_2-ocr:  0.05964350700378418
get_cells_2-ocr:  0.05002236366271973
get_cells_2-ocr:  0.06497740745544434
get_cells_2-ocr:  0.018608570098876953
On Pythonanywhere:
2023-07-10 04:03:57 3.670355796813965
2023-07-10 04:03:57 
2023-07-10 04:04:01 get_cells_2-ocr: 
2023-07-10 04:04:01  
2023-07-10 04:04:01 3.228891134262085
2023-07-10 04:04:01 
2023-07-10 04:04:06 get_cells_2-ocr: 
2023-07-10 04:04:06  
2023-07-10 04:04:06 5.227738380432129
2023-07-10 04:04:06 
2023-07-10 04:04:13 get_cells_2-ocr: 
2023-07-10 04:04:13  
2023-07-10 04:04:13 7.223729372024536
2023-07-10 04:04:13 
2023-07-10 04:04:17 get_cells_2-ocr: 
2023-07-10 04:04:17  
2023-07-10 04:04:17 3.716923475265503
2023-07-10 04:04:17 
2023-07-10 04:04:22 get_cells_2-ocr: 
2023-07-10 04:04:22  
2023-07-10 04:04:22 4.74852442741394

Như mọi người thấy thì hiệu suất của tesseract trên pythonanywhere chênh lệch quá lớn so với trên máy local, có bạn nào từng gặp vấn đề tương tự chưa ạ, cho mình xin chút ý kiến với","['#Q&A', '#python']","['chào', 'đẩy', 'project', 'python', 'pythonanywhere', 'ổn', 'ngoại trừ', 'tesseract', 'trở', 'chậm', 'from', 'tesserocr', 'import', 'pytessbaseapi', 'with', 'pytessbaseapi', 'path', 'tessdata_dir', 'as', 'api', 'for', '_img', 'in', 'gray_images', 'pil_image', 'image', 'fromarray', '_img', 'api', 'setimage', 'pil_image', 'start_time', 'time', 'time', 'text', 'join', 're', 'findall', 'r', 'd', 'api', 'getutf8text', 'print', 'get_cells_2ocr', 'time', 'time', 'start_time', '_results', 'append', 'text', 'on', 'local', 'get_cells_2ocr', '0', '009741067886352539', 'get_cells_2ocr', '0', '007970333099365234', 'get_cells_2ocr', '0', '0022356510162353516', 'get_cells_2ocr', '0', '00189208984375', 'get_cells_2ocr', '0', '25850939750671387', 'get_cells_2ocr', '0', '16674566268920898', 'get_cells_2ocr', '1', '3970351219177246', 'get_cells_2ocr', '0', '06349921226501465', 'get_cells_2ocr', '0', '05964350700378418', 'get_cells_2ocr', '0', '05002236366271973', 'get_cells_2ocr', '0', '06497740745544434', 'get_cells_2ocr', '0', '018608570098876953', 'on', 'pythonanywhere', '20230710', '04', '03', '57', '3', '670355796813965', '20230710', '04', '03', '57', '20230710', '04', '04', '01', 'get_cells_2ocr', '20230710', '04', '04', '01', '20230710', '04', '04', '01', '3', '228891134262085', '20230710', '04', '04', '01', '20230710', '04', '04', '06', 'get_cells_2ocr', '20230710', '04', '04', '06', '20230710', '04', '04', '06', '5', '227738380432129', '20230710', '04', '04', '06', '20230710', '04', '04', '13', 'get_cells_2ocr', '20230710', '04', '04', '13', '20230710', '04', '04', '13', '7', '223729372024536', '20230710', '04', '04', '13', '20230710', '04', '04', '17', 'get_cells_2ocr', '20230710', '04', '04', '17', '20230710', '04', '04', '17', '3', '716923475265503', '20230710', '04', '04', '17', '20230710', '04', '04', '22', 'get_cells_2ocr', '20230710', '04', '04', '22', '20230710', '04', '04', '22', '4', '74852442741394', 'hiệu suất', 'tesseract', 'pythonanywhere', 'chênh lệch', 'máy', 'local', 'tương chút', 'kiến']"
881,"Hôm nay nhân dịp Vietcuna 3B cán mốc 1.6k lượt tải, team mình phát hành bản alpha của Vietcuna 7B.
Dù đã được finetune instruction nhưng đây không phải phiên bản hoàn chỉnh nhất. Mục đích của phiên bản này là một base model cho cộng đồng tự finetune thêm. Phiên bản hoàn chỉnh sẽ chỉ được phát hành cho các doanh nghiệp (liên hệ riêng với mình) trong khoảng thời gian này.
Ngoài ra lần này mình cũng phát hành luôn phiên bản dịch tiếng Việt của Dataset Lima. Lưu ý đây là phiên bản được dịch từ phiên bản gốc với model en2vi của VinAI nên sẽ chỉ được dùng với mục đích nghiên cứu. Phiên bản augmented được làm bằng tay với cộng tác viên cũng sẽ chỉ được phát hành cho các doanh nhiệp.
HuggingFace Model: https://huggingface.co/vilm/vietcuna-7b-alpha
GitHub with Gradio UI: https://github.com/vilm-ai/vietcuna
Lima-vi Dataset: https://huggingface.co/datasets/vilm/lima-vi
Mong mọi người cùng nhau phát triển phiên bản alpha này để cộng đồng có các phiên bản mạnh mẽ hơn của Vietcuna :D","['#sharing', '#nlp']","['hôm', 'vietcuna', '3', 'b', 'cán', 'mốc', '1', '6', 'k', 'lượt tải', 'team', 'phát hành', 'alpha', 'vietcuna', '7', 'b', 'finetune', 'instruction phiên', 'hoàn chỉnh', 'mục đích', 'phiên', 'base', 'model', 'cộng đồng', 'finetune phiên', 'hoàn chỉnh', 'phát hành', 'doanh nghiệp', 'liên hệ', 'phát hành', 'phiên dịch', 'tiếng', 'việt', 'dataset', 'lima lưu', 'phiên dịch', 'phiên', 'gốc', 'model', 'en2vi', 'vinai', 'mục đích', 'nghiên cứu', 'phiên', 'augmented', 'cộng tác viên', 'phát hành', 'doanh nhiệp', 'huggingface', 'model', 'github', 'with', 'gradio', 'ui', 'limavi', 'dataset mong', 'phát triển', 'phiên', 'alpha', 'cộng đồng', 'phiên mẽ', 'vietcuna', 'd']"
882,"Pydantic 2.0 vừa release đẩy một phần core qua xử lý bằng Rust giúp tối ưu tốc độ lên tới 5 lần, bác nào dùng FastAPI chú ý nhé ạ 🧐",['#sharing'],"['pydantic', '2', '0', 'release', 'đẩy', 'core', 'rust', 'giúp', 'tối ưu tốc độ', '5', 'fastapi']"
883,Em hiện là sinh viên năm 3 và muốn tham gia các cuộc thi để bổ sung thành tích vào CV thì em muốn hỏi mọi người bên mảng AI hay ML có cuộc thi nào trong nước không ạ?,"['#Q&A', '#machine_learning']","['hiện', 'sinh viên', '3', 'tham gia', 'thi', 'bổ sung', 'thành tích', 'cv', 'mảng', 'ml', 'thi']"
884,"❓BẠN ĐÃ BIẾT GÌ VỀ GOOGLE I/O EXTENDED CLOUD HANOI❓
📌 Đăng ký tham gia sự kiện ngay tại: https://bit.ly/3NdmYkJ
—-------------------
Google I/O Extended Cloud Hanoi là một trong những sự kiện thường niên nổi bật về công nghệ, đặc biệt là công nghệ Cloud tại Hà Nội. Được tổ chức lần đầu vào năm 2021 bởi Google Developer Group Cloud Hanoi(GDG Cloud Hanoi), sự kiện đã chinh phục trái tim của những bạn trẻ đam mê công nghệ.
✨ Hành trình đầy ý nghĩa này đã lan tỏa sứ mệnh kết nối, chia sẻ và truyền cảm hứng đến cộng đồng công nghệ tại Việt Nam và đặc biệt là tại Hà Nội.
Hãy cùng GDG Cloud Hanoi nhìn lại những dấu ấn đáng nhớ trên hành trình 3 năm qua của sự kiện:
🔻 Tổ chức thành công Google I/O Extended Cloud Hanoi lần đầu tiên vào năm 2021
🔻 Trải qua 2 mùa công nghệ đáng nhớ với sự tham gia nhiệt tình của cộng đồng
🔻 11 phiên thảo luận hấp dẫn với nhiều chủ đề được đánh giá cao
🔻 1000+ lượt tham dự cùng với sự hiện diện của 16 chuyên gia hàng đầu
🔻 Hợp tác với 10+ đối tác đa ngành
🎉 Tiếp nối hành trình với năm 2023, Google I/O Extended Cloud Hanoi hứa hẹn sẽ tiếp tục mang đến cho người tham dự những phiên thảo luận sôi nổi và bổ ích về các công nghệ mới nhất, được dẫn dắt bởi các chuyên gia hàng đầu đến từ trong và ngoài nước. Ngoài kiến thức, những phần quà tặng siêu ngầu và các hoạt động bên lề sẽ góp phần mang lại trải nghiệm không thể bỏ qua cho các dân chơi công nghệ thực thụ 😋.
😉 Bạn có kỉ niệm đáng nhớ nào với Google I/O Extended Cloud Hanoi không? Hãy cùng chia sẻ những kỷ niệm đó với GDG Cloud Hanoi trong phần bình luận bên dưới nhé.
💪 Đừng bỏ lỡ cơ hội cùng chúng tôi Unleashing the Power of Cloud trong sự kiện năm nay nha!!!
—-------------------
𝐆𝐎𝐎𝐆𝐋𝐄 𝐈/𝐎 𝐄𝐗𝐓𝐄𝐍𝐃𝐄𝐃 𝐂𝐋𝐎𝐔𝐃 𝐇𝐀𝐍𝐎𝐈 𝟐𝟎𝟐𝟑 - Sự kiện dành cho cộng đồng yêu công nghệ “cháy” nhất mùa hè năm nay tại Hà Nội
📌 Thời gian: 13:00 - 17:00 Thứ Bảy, ngày 29/7/2023
📌 Địa điểm tổ chức: Hội trường Tầng 8, FPT Tower, số 10 Phạm Văn Bạch, Dịch Vọng, Cầu Giấy, Hà Nội
📌 Link đăng ký (miễn phí): https://bit.ly/3NdmYkJ
Deadline: 25/07/2023, hoặc đóng sớm khi đủ số lượng
👉 Liên hệ tài trợ, đăng ký diễn giả, gian hàng: Ms. Hương Nguyễn - 0377 484 425
👉 Thông tin chương trình, báo chí: Mr. Huy Đặng - 0373 952 446
#GoogleIO #GDGCloudHanoi #GoogleIOExtendedCloudHanoi",['#webinar'],"['google', 'i', 'o', 'extended', 'cloud', 'hanoi', 'đăng ký', 'tham gia', 'kiện', 'google', 'i', 'o', 'extended', 'cloud', 'hanoi', 'kiện niên', 'nổi bật', 'công nghệ', 'công nghệ', 'cloud', 'hà nội', 'tổ chức', 'đầu', '2021', 'google', 'developer', 'group', 'cloud', 'hanoi', 'gdg', 'cloud', 'hanoi', 'kiện', 'chinh phục', 'trái tim', 'trẻ', 'đam mê', 'công nghệ', 'hành trình', 'nghĩa lan', 'tỏa', 'sứ mệnh kết nối', 'truyền', 'cảm hứng', 'cộng đồng', 'công nghệ', 'việt nam', 'hà nội', 'gdg', 'cloud', 'hanoi', 'dấu ấn', 'hành trình', '3', 'kiện', 'tổ chức', 'thành công', 'google', 'i', 'o', 'extended', 'cloud', 'hanoi', '2021', 'trải', '2', 'mùa', 'công nghệ', 'tham gia', 'nhiệt tình', 'cộng đồng', '11', 'phiên', 'thảo luận', 'hấp', 'chủ đề', '1000', 'lượt', 'tham dự', 'hiện diện', '16', 'chuyên gia', 'hàng đầu', 'hợp tác', '10', 'đối tác', 'đa', 'ngành', 'tiếp nối', 'hành trình', '2023', 'google', 'i', 'o', 'extended', 'cloud', 'hanoi', 'hứa hẹn', 'tham dự', 'phiên', 'thảo luận', 'sôi nổi', 'bổ ích', 'công nghệ', 'dắt', 'chuyên gia', 'hàng đầu', 'kiến thức', 'quà', 'tặng', 'siêu ngầu', 'hoạt động', 'lề góp', 'trải nghiệm thể', 'dân công nghệ', 'thực thụ', 'kỉ niệm', 'google', 'i', 'o', 'extended', 'cloud', 'hanoi', 'kỷ niệm', 'gdg', 'cloud hanoi', 'bình luận', 'đừng', 'lỡ', 'hội', 'unleashing', 'the', 'power', 'of cloud', 'kiện', 'nha kiện', 'cộng đồng', 'yêu', 'công nghệ', 'cháy', 'mùa', 'hè', 'hà nội', '13', '00', '17', '00', 'bảy', '29', '7', '2023', 'địa tổ chức', 'hội trường', 'tầng', '8', 'fpt', 'tower', '10', 'phạm văn bạch dịch', 'vọng', 'cầu', 'giấy', 'hà nội', 'link', 'đăng ký', 'miễn phí', 'deadline', '25', '07', '2023', 'đóng', 'liên hệ', 'tài trợ', 'đăng ký', 'diễn giả', 'gian hàng', 'ms', 'hương', 'nguyễn', '0377', '484', '425', 'thông chương trình', 'báo chí', 'mr', 'huy đặng', '0373', '952', '446']"
885,Mn ơi cho e hỏi về kiến thức toán. Em cần học những kiến thức toán gì trước ạ và thứ tự học cái kiến thức đó ra sao để theo ML ạ,"['#Q&A', '#math']","['mn', 'e kiến thức', 'toán học', 'kiến thức', 'toán học', 'kiến thức', 'ml']"
886,"em chào mọi người ạ, hiện tại em có đang làm trích xuất thực thể trong văn bản tiếng việt và PoS dựa theo toolkit phonlp (embedding là phoBERT) và dataset là VLSP2016 thì có một số là cho ra thẻ đúng còn một số thì em có gặp vấn đề về thừa thẻ trong tác vụ PoS ạ ở đây em có ví dụ cụ thể luôn ạ. Mọi người có thể giải đáp thắc mắc là tại sao lại bị thừa thẻ ko ạ. Hiện tại nhóm em đang giả thuyết là do embedding của phoBERT và dataset. Em xin cảm ơn
(note: trong ví dụ là em bị thừa 2 thẻ đầu là Ny)","['#Q&A', '#deep_learning', '#nlp']","['chào', 'trích xuất', 'thực thể', 'văn tiếng', 'việt', 'pos', 'dựa', 'toolkit', 'phonlp', 'embedding', 'phobert', 'dataset', 'vlsp2016', 'thẻ thừa', 'thẻ tác', 'vụ', 'pos', 'ví dụ thể', 'giải đáp', 'thắc mắc', 'thừa', 'thẻ', 'ko', 'giả thuyết', 'embedding', 'phobert', 'dataset', 'note', 'ví dụ', 'thừa', '2', 'thẻ', 'đầu', 'ny']"
887,"Hi mọi người cho phép em hỏi về thuật toán Coordinate ascent variational inference (CAVI) ạ. Em đang đọc paper này (https://arxiv.org/pdf/1601.00670.pdf). Tuy nhiên em ko hiểu được chỗ Equation 19 tại sao có thể nói ELBO(q) maximize khi q_j(z_j) bằng q*_j(z_j) ạ.
Vì để có eq 18 thì em đang hiểu là phải công nhận kết quả của eq17. Mà eq17 là kết quả luôn được thừa nhận luôn rồi thì em thấy reasoning đang bị circular.
Có bác nào có cao kiến góp ý cho em với ạ.","['#Q&A', '#machine_learning']","['hi phép', 'thuật toán', 'coordinate', 'ascent', 'variational', 'inference', 'cavi', 'đọc', 'paper nhiên', 'ko', 'chỗ', 'equation', '19', 'thể', 'elbo', 'q', 'maximize', 'q_j', 'z_j', 'q', '_j', 'z_j', 'eq', '18', 'công kết', 'eq17', 'eq17', 'kết thừa', 'reasoning', 'circular kiến', 'góp']"
888,"Machine Learning cho người ngoại đạo.
Chào mọi người, hiện mình đang là nghiên cứu về phân tích chuyển động của con người.
Phần nghiên cứu của mình có liên quan nhiều đến tính toán các thông số của chuyển động giống như bên ngành kỹ thuật tính toán chuyển động của cánh tay robot. Nên ML được ứng dụng rất nhiều để tính toán và đưa ra dự đoán.
Mình có một chút kiến thức về phân tích dữ liệu bằng R, tuy nhiên là do mình tự học nên nó không có hệ thống, cần phân tích cái gì thì lại dùng google tra cứu.
Cho nên hiện mình rất muốn học ML và Data Analysis một cách có hệ thống, nền tảng từ cơ bản đi lên.
Mọi người có tư vấn giúp mình một số thắc mắc?
- Kiến thức cơ bản về toán và tin cần những gì? (mình học y nên hồi đại học không học về toán- tin cao cấp).
- Kiến thức về cơ bản về ML cần học cái gì trước tiên?
Cảm ơn mọi người.","['#Q&A', '#machine_learning']","['machine', 'learning', 'ngoại đạo', 'chào hiện', 'nghiên cứu', 'phân tích động', 'nghiên cứu toán', 'thông động', 'ngành', 'kỹ thuật', 'toán động', 'cánh robot', 'ml', 'ứng dụng', 'toán', 'dự đoán', 'chút', 'kiến thức', 'phân tích liệu', 'r nhiên', 'học', 'hệ thống', 'phân tích', 'google tra', 'cứu', 'hiện', 'học', 'ml', 'data', 'analysis', 'hệ thống', 'tảng', 'đi', 'tư vấn', 'giúp', 'thắc mắc', 'kiến thức', 'toán học', 'y hồi', 'đại học', 'học toán', 'kiến thức', 'ml', 'học', 'tiên']"
889,"em chào các thầy/cô, anh/chị và các bạn ạ,
Mọi người cho e nhờ chút ạ,
Em đang làm việc với bài toán Object detection, mục tiêu là áp dụng và cải tiến model YOLOv8 trên custom dataset được cung cấp, em đang tìm hiểu về cấu trúc mạng của model yolov8, nhưng nó còn quá mới và chưa có official paper ạ, Em muốn tìm hiểu và đọc thêm các latest techniques về Object detection để có thể mang về cải tiến model Yolov8 gốc để có thể viết paper ạ, em xin các anh chị recommend giúp e các trang/ journal hoặc nơi nào để đọc về các novelty techniques về bài toán Object detection ạ, hoặc anh chị có gợi ý cải thiện model thì tốt quá ạ, em cảm ơn mọi người rất nhiều ạ.","['#Q&A', '#cv', '#deep_learning']","['chào', 'thầy', 'e', 'chút toán', 'object', 'detection', 'mục tiêu', 'áp dụng', 'cải tiến', 'model', 'yolov8', 'custom', 'dataset cung', 'cấu trúc', 'mạng', 'model', 'yolov8', 'official', 'paper', 'đọc', 'latest', 'techniques', 'object', 'detection thể', 'cải tiến', 'model', 'yolov8', 'gốc thể', 'viết', 'paper', 'recommend', 'giúp', 'e trang', 'journal', 'đọc', 'novelty', 'techniques toán', 'object', 'detection', 'gợi', 'cải thiện', 'model']"
890,"Em chào mọi người.
Hiện em đang muốn sử dụng mô hình VNCoreNLP, tuy nhiên, khi cài đặt trên vscode thì em gặp lỗi như trong ảnh. Ai biết cách khắc phục thì giúp em với.
Em cảm ơn mọi người.","['#Q&A', '#deep_learning']","['chào', 'hiện', 'mô hình', 'vncorenlp nhiên', 'cài', 'vscode', 'lỗi ảnh', 'khắc phục', 'giúp']"
891,"Em chào mọi người ạ . Giờ em muốn sử dụng 1 mô hình để liên tục nhận và phân loại dữ liệu trong 24h thành 2 nhãn thì nên sử dụng phương pháp gì .
( em đã có sẵn 1 bộ dữ liệu đã phân loại 2 nhãn này trong quá khứ để train mô hình phân loại )","['#Q&A', '#machine_learning']","['chào', '1', 'mô hình', 'liên tục', 'phân liệu', '24', 'h', 'thành', '2', 'nhãn', 'phương pháp', 'sẵn', '1', 'liệu', 'phân', '2', 'nhãn khứ', 'train', 'mô hình', 'phân']"
892,"Em chào mọi người ạ. Em có bài tập là build 1 Recommendation System (RS), nhưng em hiện tại vẫn khá mù mờ vì chưa hiểu rõ phần train và phần test được thực hiện ntn.
Như em đã tìm hiểu thì trong machine learning, tập train sẽ xấp xỉ hàm dự đoán còn tập test sẽ để xđ xem hàm đó tốt đến đâu. Nhưng ở phần RS này, có 1 số thuật toán để có thể dự đoán được luôn đánh giá của người dùng (Collaborative-filtering user-based/item-based, matrix factorization,...) thì mình chỉ cần áp dụng thuật toán với dataset sau khi xử lí để có được các đánh giá xấp xỉ. Hơn nữa, em tìm thấy code mẫu trên mạng ( em để link bên dưới) thì thấy người ta vẫn thừa số hóa cả ma trận ratings, tuy nhiên chỉ cố gắng minimize loss của phần train - 1 subset của ma trận ratings trên và thả trôi phần test - phần còn lại của ma trận. Đến đây em kiểu bị @@, vì sao k thừa số hóa rồi minimize loss của cả ma trận nếu như test loss nhỏ là tốt. Từ đấy dẫn đến câu hỏi ban đầu của em: Tại sao lại chia train vs test ra ngay từ ban đầu?
Em xin trân thành cảm ơn mọi ý kiến đóng góp ạ. Link bài code đây ạ (cụ thể ở phần function build_model): https://colab.research.google.com/github/google/eng-edu/blob/main/ml/recommendation-systems/recommendation-systems.ipynb?utm_source=ss-recommendation-systems&utm_campaign=colab-external&utm_medium=referral&utm_content=recommendation-systems#scrollTo=M9RxIX_Oo4tp
PS: Với lại cho em hỏi thêm là có phải phương pháp đánh giá loss chưa tối ưu, bởi theo nghiên cứu của tác giả Đỗ Thị Liên và cộng sự (https://portal.ptit.edu.vn/saudaihoc/wp-content/uploads/2020/02/LA_%C4%90%E1%BB%97-Th%E1%BB%8B-Li%C3%AAn.pdf?fbclid=IwAR1BU24ivQHfe6mg8dYbi0iwq5Plcmew3B2ODYf0SmZubAtOIscNChQQO_I#page23) tại trang 51, cần phải ẩn đi 1 số p đánh giá đã biết của người dùng trên tập test, sau đó so sánh giá trị dự đoán với p giá trị thực. Tuy nhiên trong các phần sau và phần kết quả, tác giả k đề cập đến việc đã lấy p chiếm bao nhiêu % nên em muốn hỏi mọi người là nên đánh giá hiệu năng ntn và nếu là cách của tác giả Liên thì lấy p là bao nhiêu % ạ.
1 lần nữa em xin chân thành cảm ơn nhiều ạ","['#Q&A', '#machine_learning']","['chào', 'tập', 'build', '1', 'recommendation', 'system', 'rs', 'mù mờ', 'train', 'test', 'ntn', 'machine', 'learning', 'tập', 'train', 'xấp xỉ', 'hàm', 'dự đoán', 'tập', 'test', 'xđ', 'hàm rs', '1', 'thuật', 'toán thể', 'dự đoán', 'collaborativefiltering', 'userbased', 'itembased', 'matrix', 'factorization', 'áp dụng', 'thuật toán', 'dataset', 'xử lí', 'xấp xỉ', 'code', 'mẫu', 'mạng', 'link', 'ta', 'thừa hóa', 'ma trận', 'ratings nhiên', 'cố gắng', 'minimize', 'loss', 'train', '1', 'subset', 'ma trận', 'ratings thả', 'trôi', 'test', 'ma trận', 'kiểu', 'k', 'thừa', 'hóa', 'minimize', 'loss', 'ma trận', 'test', 'loss', 'đấy', 'ban đầu', 'chia', 'train', 'vs', 'test', 'ban đầu', 'trân', 'thành kiến', 'đóng góp', 'link', 'code', 'function', 'build_model', 'ps', 'phương pháp', 'loss', 'tối ưu nghiên cứu', 'tác giả', 'đỗ thị', 'liên cộng', 'trang', '51', 'ẩn', 'đi', '1', 'p', 'tập', 'test', 'sánh', 'dự đoán', 'p', 'thực nhiên', 'kết tác giả', 'k', 'đề cập', 'p', 'chiếm', 'hiệu năng', 'ntn tác giả', 'liên p', '1', 'chân thành']"
893,"Mình làm hạ tầng phần cứng, có thể hỗ trợ share lab có sẵn các tài nguyên máy ảo, kết nối hadoop, có mạng Internet để tự cài thêm package. Bạn nào cần tài nguyên trải nghiệm, test có thể ib mình, lab tồn tại được 10 ngày mỗi lần khởi tạo. Mỗi máy ảo linux có 24GB RAM",['#sharing'],"['hạ tầng', 'cứng thể', 'share', 'lab', 'sẵn', 'tài nguyên', 'máy', 'ảo', 'kết nối', 'hadoop mạng', 'internet', 'cài', 'package', 'tài nguyên', 'trải nghiệm', 'test thể', 'ib', 'lab', 'tồn', '10', 'khởi máy', 'ảo', 'linux', '24', 'gb', 'ram']"
894,"Anh/chị/bạn trong group mình có thể cho em xin các nguồn thông tin mà mọi người cập nhật thông tin về các công nghệ machine learning, các thuật toán, các dòng code hay ở đâu không ạ? Tại vì em là newbie nên không rõ diễn đàn nào hay và có độ thảo luận cao. Các diễn đàn bằng tiếng anh càng tốt ạ <3.
Cảm ơn mọi người đã đọc post, chúc mọi người làm việc thật năng suất!","['#Q&A', '#machine_learning']","['group thể', 'thông cập', 'nhật thông', 'công nghệ', 'machine', 'learning thuật', 'toán', 'dòng', 'code', 'newbie', 'diễn đàn', 'độ', 'thảo luận', 'diễn đàn', 'tiếng', '3', 'đọc', 'post', 'chúc', 'năng suất']"
895,"Một video thú vị về toán. Hi vọng nó giải thích cặn kẽ để ta hiểu tại sao lại có số Pi, số e,…","['#sharing', '#math']","['video', 'thú vị', 'toán', 'hi vọng', 'giải', 'cặn kẽ', 'ta', 'pi', 'e']"
896,"Chào mọi người, em là sinh viên đang theo học AI/ML, em có một thắc mắc về hướng đi trong ngành. Theo em biết thì có 2 hướng chính là Research và Engineer, anh/chị cho em hỏi những điểm khác nhau của 2 hướng này, và cơ hội của hướng nào sẽ là nhiều hơn ạ.","['#Q&A', '#machine_learning']","['chào', 'sinh viên', 'học', 'ml', 'thắc mắc', 'hướng', 'đi', 'ngành', '2', 'hướng', 'research', 'engineer', '2', 'hướng', 'hội', 'hướng']"
897,"Chào mọi người, không biết ở tp.HCM có nơi nào bán sách  Calculus Early Transcendentals Ninth Edition không, mặc dù có bản pdf nhưng mình làm việc với máy tính rất nhiều nên muốn đọc bản giấy cho đỡ đau mắt và giải trí trong thời gian rảnh một tí.","['#Q&A', '#math']","['chào', 'tp', 'hcm', 'sách', 'calculus', 'early', 'transcendentals', 'ninth', 'edition', 'mặc', 'pdf', 'máy', 'đọc', 'giấy', 'đỡ', 'đau mắt', 'giải trí', 'rảnh', 'tí']"
898,"Em chào mọi người ạ,em là newbie chập chững vào nghề đang gặp 1 vấn đề ở 1 bài toán mong được mn giải đáp ạ!
Bài toán:Em có áp dụng HOG để trích xuất đặc trưng ảnh,ảnh của em là 150*150.khi dùng HOG thì em cho orientations = 8,pixel per cell =16,cell per block =4 thì khi trích xuất xong 1 ảnh sẽ đc biểu diễn dưới 1 vector kích thước (4608,)
1.Em có thắc mắc con số 4608 này tạo ra ntn ạ?
2.Tại vì em thấy size ảnh k chia hết cho pixel per cell và nếu luận ngược lên 4608 / 8*4*4= 36 =6*6(với 8*4*4 là độ dài Vector HOG của mỗi block) hay nói cách khác trên mỗi phương sẽ khi đi từ trái qua phải hoặc trên xuống dưới ta sẽ phải tính HOG trên 6 block kết hợp vs việc 4 cell cho mỗi block thì ta sẽ có đc số cell theo từng phương là 9
Nma nếu tính như vậy thì số pixel theo mỗi phương sẽ là 9*16 < 150 như đúng size ảnh gốc vậy liệu có phải đám pixel còn lại bị thiếu sẽ bị cắt đi k dùng đến khi tính hay là sẽ được ném vào các cell trong 9 cell có sẵn đó ạ ?
Em cảm ơn mọi người nhiều ạ,mong sẽ được admin duyệt bài sớm và sớm nhận được giúp đỡ từ mn ạ!!!","['#Q&A', '#cv']","['chào', 'newbie', 'chập chững', 'nghề', '1', '1', 'toán', 'mong', 'mn', 'giải đáp toán', 'áp dụng', 'hog', 'trích xuất', 'đặc trưng', 'ảnh', 'ảnh', '150', '150', 'hog', 'orientations', '8', 'pixel', 'per', 'cell', '16', 'cell', 'per', 'block', '4', 'trích', 'xuất', 'xong', '1', 'ảnh', 'đc', 'biểu diễn', '1', 'vector', 'kích thước', '4608', '1', 'thắc mắc', '4608', 'ntn', '2', 'size', 'ảnh', 'k', 'chia', 'pixel', 'per', 'cell luận', 'ngược', '4608', '8', '4', '4', '36', '6', '6', '8', '4', '4', 'độ', 'vector', 'hog', 'block phương', 'đi', 'trái', 'ta', 'hog', '6', 'block', 'kết hợp', 'vs', '4', 'cell', 'block', 'ta', 'đc', 'cell', 'phương', '9', 'nma', 'pixel', 'phương', '9', '16', '150', 'size', 'ảnh', 'gốc liệu', 'đám', 'pixel', 'cắt', 'đi', 'k', 'ném', 'cell', '9', 'cell', 'sẵn', 'mong', 'admin', 'duyệt', 'giúp đỡ', 'mn']"
899,"Xin được share với các bác 1 seminar dành chung cho tất cả các anh em hứng thú với MLOps với chủ đề:
“Optimize ML service’s performance with continuous right-sizing containers in Kubernetes”",['#webinar'],"['share', '1', 'seminar', 'tất hứng', 'thú mlops', 'chủ đề', 'optimize', 'ml', 'service', 's', 'performance', 'with', 'continuous', 'rightsizing', 'containers', 'in', 'kubernetes']"
900,"THUÊ SERVER TRÊN VAST.AI
Chào mọi người, trong group mình có ai đã từng thuê server trên vast.ai chưa ạ cho mình ít review. Thấy giá cũng rẻ mà nhỉ. Em định dùng để train model AI thay vì Kaggle hay Colab ko biết có nhanh hơn ko. Với lại nó cần credit card để nạp tiền vào mà giờ em không có credit card thì ko biết có giải pháp nào ko. Em xin cảm ơn.",['#Q&A'],"['thuê', 'server', 'chào group', 'thuê', 'server', 'review', 'giá', 'rẻ định', 'train', 'model', 'thay', 'kaggle', 'colab', 'ko', 'ko', 'credit', 'card nạp', 'tiền', 'credit', 'card', 'ko', 'giải pháp', 'ko']"
901,Khoa học dữ liệu (Data Science) là một lĩnh vực đang phát triển nhanh chóng với nhiều cơ hội nghề nghiệp. Hãy cùng khám phá một số vai trò chính trong lĩnh vực Khoa học dữ liệu.,"['#sharing', '#data']","['khoa học liệu', 'data', 'science', 'lĩnh vực', 'phát triển', 'chóng hội', 'nghề nghiệp', 'khám phá', 'vai trò', 'lĩnh vực', 'khoa học liệu']"
902,🔥 Vision Transformer (ViT) - Hiện tượng mới trong lĩnh vực thị giác máy tính! 🔥,"['#sharing', '#cv', '#deep_learning']","['vision', 'transformer', 'vit', 'hiện tượng', 'lĩnh vực', 'thị giác', 'máy']"
903,"Mình đang cày project để apply xin việc. Mình đang tìm các competitions để luyện tập. Bao gồm EDA, Pre-Processing, Modeling và Predict. Hiện tại mình mới tham gia 2 cuộc thi nhưng kết quả của mình chỉ giao động từ 40-55% so với độ chính xác của cuộc thi do mình không biết optimize (hoặc optimize xong thì kernel die chẳng hạn). Mình muốn tìm bạn colab với mình, cùng nhau cày project kiếm medal. Chẳng hạn mình có thể Pre-Processing, EDA,... còn bạn làm phần còn lại, hoặc cả 2 cùng thảo luận về các cách làm... Không nhất thiết ngày nào cũng phải làm cùng nhau nhưng cố gắng tuần nào cũng trao đổi 🥰🥰 ad duyệt cho mình kiếm tý medal vớiiiii","['#sharing', '#machine_learning']","['cày', 'project', 'apply', 'competitions', 'luyện tập', 'bao', 'eda', 'preprocessing', 'modeling', 'predict', 'tham gia', '2', 'thi kết', 'giao động', '4055', 'độ', 'xác', 'thi', 'optimize', 'optimize', 'xong', 'kernel', 'die', 'chẳng hạn', 'colab', 'cày', 'project', 'kiếm', 'medal', 'chẳng hạn thể', 'preprocessing eda', '2', 'thảo luận thiết', 'cố gắng', 'tuần', 'trao đổi', 'ad duyệt', 'kiếm', 'tý', 'medal', 'vớiiiii']"
904,"Anh chị có kinh nghiệm cho em hỏi chút với ạ. Em thấy trong các bài toán nhận dạng thực thể người ta hay kết hợp model transformer + CRF . thì cho em hỏi tại sao mình lại cho qua CRF mà ko phân loại luôn ạ. Bởi vì em thấy các từ lúc này đều có 1 ý nghĩa riêng rồi mà nhỉ, vì em có đọc tìm hiểu trên mạng nhưng thấy vẫn chưa được giải thích đúng lắm . Em cảm ơn những lời giải thích ạ","['#Q&A', '#cv', '#deep_learning']","['kinh nghiệm', 'chút toán', 'dạng', 'thực thể', 'ta', 'kết hợp', 'model', 'transformer', 'crf', 'crf', 'ko', 'phân', '1', 'nghĩa', 'đọc', 'mạng', 'giải', 'lắm', 'giải']"
905,"Em xin chào mọi người, là em sinh viên ngành Khoa học Máy tính.
Vì quá mông lung trên con đường học để trở Computer Vision Engineer, nên em muốn hỏi mn
""Cách học CV như thế nào để sau này có thể tìm được việc ạ"".
Hiện tại thì em đã học ANN, CNN, RNN, LSTM (ở mức cơ bản thôi ạ), em định hướng là sẽ code theo các project trên mạng, trên sách để làm quen. Nhưng code xong em cảm thấy nó không phải là của mình, và cũng không thể tự code được cái gì?
Em không biết học như thế nào cho đúng? Mong mọi người giúp em với ạ. Em trầm cảm vô cùng.","['#Q&A', '#cv', '#deep_learning']","['chào', 'sinh viên', 'ngành', 'khoa học', 'máy', 'mông', 'lung đường', 'học', 'trở computer', 'vision', 'engineer', 'mn', 'học', 'cv thể', 'học', 'ann', 'cnn', 'rnn', 'lstm', 'định hướng', 'code', 'project', 'mạng', 'sách', 'quen', 'code', 'xong thể', 'code', 'học', 'mong', 'giúp', 'trầm cảm', 'vô']"
906,Anh/chị cho em hỏi muốn học ML thì nên bắt đầu từ đâu ạ?,"['#Q&A', '#machine_learning']","['học', 'ml']"
907,"Chào các bạn
Mình đang tìm host để deploy con services AI xử lý ảnh. Mọi ng thường triển khai ở đâu? Ưu tiên ngon bổ rẻ nhé ae
Cảm ơn anh em",['#Q&A'],"['chào', 'host', 'deploy', 'services', 'ảnh', 'ng', 'triển khai', 'ưu tiên', 'ngon bổ', 'rẻ', 'ae']"
908,"Em chào mọi người ạ,
Em đang tham khảo về một đề tài LVTN xoay quanh AI làm về một hệ thống social network kết nối cộng đồng người dùng và chuyên gia.
Cụ thể, có những nhóm công ty DN, cá nhân, có những bài toán đặc thù về AI. Nhưng không biết giải quyết như thế nào, thay vì phải học và phải tốn thời gian để học, họ muốn giải quyết được những bài toán này trong thời gian ngắn. Thì hệ thống này sẽ là hệ thống social network để kết nối những nhu cầu này. Hệ thống sẽ mang đặc thù kết nối, cộng tác giữa các bên có bài toán nhưng không biết làm gì, giữa các bên có kĩ năng. Tuy nhiên, không đơn giản chỉ tương tác. Mà phải duy trì, và quản trị kết nối đó (Ví dụ khi đang làm giữa chừng, mà bên làm họ rút không làm nữa thì phải xử lí như thế nào). Hệ thống cũng phải đảm bảo tự động, thông minh, kết nối các bên liên quan. Giả sử có nhu cầu về 10 bài toán AI khác nhau, thì hệ thống phải làm sao đề xuất được nguồn lực nào, hạ tầng nào phù hợp cho từng nhu cầu cụ thể (Không đơn thuần chỉ là up bài lên rồi người khác vào trả lời).
Mọi người ai đã từng làm qua hoặc biết có thể cho em xin một số tài liệu liên quan được không ạ. Và mn có thể cho em xin một số hệ thống giống như trên ở thực tế để có thể tham khảo không ạ. Vì em có search nhưng chưa tìm được ạ.
Cảm ơn mọi người, chúc mọi người cuối tuần vui vẻ ^^",['#Q&A'],"['chào', 'tham khảo', 'đề tài', 'lvtn', 'xoay', 'quanh', 'hệ thống', 'social', 'network', 'kết nối', 'cộng đồng', 'chuyên gia', 'công ty', 'dn toán', 'đặc thù', 'giải quyết', 'thay', 'học', 'tốn học', 'giải quyết toán', 'ngắn', 'hệ thống', 'hệ thống', 'social', 'network', 'kết nối', 'nhu cầu', 'hệ thống', 'đặc thù', 'kết nối', 'cộng tác toán', 'kĩ năng nhiên', 'đơn giản', 'tương tác', 'trì quản trị', 'kết nối', 'ví dụ', 'chừng', 'rút', 'xử lí', 'hệ thống', 'động', 'thông minh', 'kết nối', 'giả sử', 'nhu cầu', '10', 'toán', 'hệ thống', 'đề xuất lực', 'hạ tầng', 'nhu cầu', 'đơn', 'up thể', 'tài liệu', 'mn thể', 'hệ thống thể', 'tham khảo', 'search', 'chúc', 'tuần', 'vui vẻ']"
909,"Chào mọi người,
Phoenix Team xin chia sẻ với mọi người source code của 1st private-test solution, Zalo AI Challenge 2020 phần traffic sign detection.
Một số tricks mà team có sử dụng:

1. Training data preprocessing
- Chia ảnh thành các grid nhỏ hơn, sử dụng input size 160x160 và stried window 40x40.
- Loại bớt các ảnh background và các ảnh có dính 1 phần box quá nhỏ (< 10% diện tích box), chỉ để tỉ lệ 1:3.

2. Training pharse
- Augmentation: Mosaic (9) + mixup.
- Model: Yolov5x, SGD Optimizer + Ema.
- 5-Stratified CV (chia ảnh gốc, sau đó preprocess sau).

3. Inference 
- Chia ảnh thành các grid 384x384, scale-up lên input 608x608, stride 84x88. 
-Sau khi đi qua model, NMS được sử dụng giữa các ảnh nhỏ theo area của các box, iou 0.1.
- WBF (Weighted boxes fusion) được sử dụng giữa các fold.
- Best 5-fold fp16 model: 60.5
Các bạn có câu hỏi nào có thể viết dưới post này hoặc để lại ở phần issue của git. 

Các thành viên trong team: Hải Nam Nguyễn (xSeries - FUNiX), Thân Cường (AI Engineer - Asilla), Nguyen Hai Son (BKHN - AI Intern, Asilla).
Chúc các bạn có thể áp dụng một trong các tricks ở trên vào cuộc thi của VinBigData Sắp tới :)
 ","['#sharing', '#cv']","['chào', 'phoenix', 'team', 'source', 'code', '1', 'st', 'privatetest', 'solution', 'zalo', 'challenge', '2020', 'traffic', 'sign', 'detection', 'tricks', 'team', '1', 'training', 'data', 'preprocessing', 'chia', 'ảnh', 'thành', 'grid', 'input', 'size', '160x160', 'stried', 'window', '40x40', 'bớt', 'ảnh', 'background', 'ảnh', 'dính', '1', 'box', '10', 'diện tích', 'box', 'tỉ lệ', '1', '3', '2', 'training', 'pharse', 'augmentation', 'mosaic', '9', 'mixup', 'model', 'yolov5x', 'sgd', 'optimizer', 'ema', '5', 'stratified', 'cv', 'chia', 'ảnh', 'gốc', 'preprocess', '3', 'inference', 'chia', 'ảnh', 'thành', 'grid', '384x384', 'scaleup', 'input', '608x608 stride', '84x88', 'đi', 'model', 'nms', 'ảnh', 'area', 'box', 'iou', '0', '1', 'wbf', 'weighted', 'boxes', 'fusion', 'fold', 'best', '5', 'fold', 'fp16', 'model', '60', '5', 'thể', 'viết', 'post', 'issue', 'git', 'thành viên', 'team', 'hải nam', 'nguyễn xseries', 'funix', 'thân cường', 'engineer', 'asilla', 'nguyen', 'hai', 'son bkhn', 'intern', 'asilla', 'chúc thể', 'áp dụng', 'tricks', 'thi', 'vinbigdata']"
910,"Mn ơi em học đến bài này thì không biết sao lại có công thức thứ 2 ạ. Mn giúp em với.
https://machinelearningcoban.com/2017/01/16/gradientdescent2/","['#Q&A', '#math']","['mn', 'học', 'công thức', '2', 'mn', 'giúp', 'https', 'machinelearningcoban', 'com', '2017', '01', '16', 'gradientdescent2']"
911,"xin chào mọi người
mọi người cho em hỏi là cách lấy dữ liệu từ trang web như thế nào ạ,
ví dụ: em muốn lấy tất cả bài viết trong nhóm trên fb về, trong đó 1 số bài viết có ảnh, một số bài không, em muốn lấy về hết gồm : tiêu đề, nội dung, ảnh (nếu có)
em xin cảm ơn ạ","['#Q&A', '#data']","['chào liệu', 'trang web', 'ví dụ', 'tất', 'viết', 'fb', '1', 'viết', 'ảnh', 'tiêu đề', 'nội dung', 'ảnh']"
912,Mn cho em hỏi xử lí các từ viết tắt tiếng như nào v ? E đang làm sentiment analysis mà đổi từng từ viết tắt sang hoàn chỉnh chắc chết mất.,"['#Q&A', '#nlp']","['mn', 'xử lí', 'viết', 'tắt', 'tiếng', 'v', 'e sentiment', 'analysis', 'đổi', 'viết', 'tắt', 'hoàn chỉnh', 'chết']"
913,"Mọi người có tài liệu, papers, books để bắt đầu tìm hiểu về derivative-free optimization hay blackbox optimization không ạ. Em xin cảm ơn","['#Q&A', '#machine_learning']","['tài liệu', 'papers', 'books', 'derivativefree', 'optimization', 'blackbox', 'optimization']"
914,Chào mn ạ. Em đang mong muố tìm job intern/fresher Al ở Hà Nội ạ. Em cảm ơn ạ,"['#Q&A', '#machine_learning']","['chào', 'mn', 'mong', 'muố', 'job', 'intern', 'fresher al', 'hà nội']"
915,"Em chào mn. em tự học bài Gradient Descent đến đoạn công thức này thì không hiểu tại sao. mn giải thích giúp em với.
https://machinelearningcoban.com/2017/01/16/gradientdescent2/","['#Q&A', '#math']","['chào', 'mn', 'học', 'gradient', 'descent', 'đoạn', 'công thức', 'mn', 'giải', 'giúp', 'https', 'machinelearningcoban', 'com', '2017', '01', '16', 'gradientdescent2']"
916,"Em chào cả nhà!
Em hiện làm việc cho một công ty về thiết kế xây dựng ở nước ngoài và có học thêm một Master về Data Science nhưng mọi thứ về DS đều khá mới với em, nên muốn hỏi các bậc cao nhân trong nhóm như sau ạ:
Mọi người cho em hỏi có ai xử dụng mô hình Neural Networks trong Deep learning để giải bài toán tối ưu trong kĩ thuật không ạ? Chẳng hạn, tìm nghiệm X=(x1,x2,...,xn) sao cho hàm f(X) đạt cực tiểu. Đây là bài toán tối ưu thuần Toán, tuy nhiên lại áp dụng nhiều trong kĩ thuật và thiết kế.
Em cảm ơn và mong mọi người cho em xin góp ý!","['#Q&A', '#math']","['chào', 'hiện', 'công ty', 'thiết kế', 'xây dựng', 'học', 'master', 'data', 'science ds', 'bậc', 'nhân', 'xử dụng', 'mô hình', 'neural', 'networks', 'deep', 'learning', 'giải toán', 'tối ưu kĩ thuật', 'chẳng hạn nghiệm', 'x', 'x1', 'x2', 'xn', 'hàm f', 'x', 'cực', 'tiểu toán', 'tối ưu toán nhiên', 'áp dụng', 'kĩ thuật', 'thiết kế', 'mong', 'góp']"
917,"Công ty trợ lý ảo, dùng trợ lý ảo, tuyển người phát triển trợ lý ảo🥳

Là một đơn vị tiên phong phát triển chatbot, trợ lý ảo thế hệ mới trên công nghệ ChatGPT tại Việt Nam, hiện mindmaid.ai đang có nhu cầu tuyển dụng Thực tập sinh Content Marketing & Chatbot Development. Nhiệm vụ chính bao gồm: nghĩ với ChatGPT, viết với ChatGPT, chuẩn bị dữ liệu huấn luyện trợ lý ảo cũng bằng ChatGPT. 

Đây là vị trí ưu tiên cho các bạn content, tuy nhiên vì chuẩn bị content cho trợ lý ảo, nên công ty cũng muốn ưu tiên một số suất cho các bạn có hiểu biết tốt về công nghệ, AI và muốn khám phá lĩnh vực trợ lý ảo này. 
Môi trường làm việc startup năng động, văn phòng khu vực trung tâm, công cụ làm việc Lark xịn sò, và đặc biệt là luôn được học hỏi về những skill mới nhất thông qua Growth Day hàng tuần.
Nhờ anh chị em bạn bè thấy có CV nào phù hợp giới thiệu giúp.
👉Thông tin chi tiết về JD, hình thức gửi CV...mời chat trực tiếp với trợ lý ảo ạ: https://aivtuyendung.mindmaid.ai

(p/s: xin phép ad đăng lên group vì không tìm thấy post gom đăng bài tuyển dụng trên nhóm)","['#sharing', '#nlp']","['công ty', 'trợ lý', 'ảo', 'trợ lý', 'ảo tuyển', 'phát triển', 'trợ lý', 'ảo', 'tiên phong', 'phát triển', 'chatbot', 'trợ lý', 'ảo hệ', 'công nghệ', 'chatgpt', 'việt nam', 'hiện', 'nhu cầu', 'tuyển dụng', 'thực tập', 'sinh', 'content', 'marketing', 'chatbot', 'development', 'nhiệm vụ', 'bao', 'chatgpt', 'viết', 'chatgpt', 'chuẩn liệu', 'huấn luyện', 'trợ lý', 'ảo chatgpt', 'ưu tiên', 'content nhiên', 'chuẩn', 'content', 'trợ lý', 'ảo', 'công ty', 'ưu tiên suất', 'công nghệ', 'khám phá', 'lĩnh vực', 'trợ lý', 'ảo', 'môi trường', 'startup năng động', 'văn phòng', 'khu vực', 'trung tâm', 'công cụ', 'lark', 'xịn', 'sò', 'học', 'skill', 'thông growth', 'day', 'hàng', 'tuần', 'bè', 'cv', 'giới thiệu', 'giúp', 'thông', 'chi tiết', 'jd', 'hình thức', 'gửi', 'cv', 'mời', 'chat', 'trợ lý', 'ảo', 'https', 'aivtuyendung', 'p', 's phép', 'ad', 'đăng group', 'post', 'gom', 'đăng', 'tuyển dụng']"
918,"Dạ em chào mọi người, em là newbie tự học về ML được vài tháng. Em thấy nhiều anh chị khuyên nên làm project trên kaggle, vậy cụ thể là mình làm như thế nào, các bước ra sao ạ? Do em thấy trên kaggle không có mục project mà chỉ có mục dataset và competition ạ. Mong mọi người giải đáp, em xin cảm ơn ạ","['#Q&A', '#machine_learning']","['chào', 'newbie', 'học', 'ml', 'khuyên', 'project', 'kaggle', 'kaggle', 'mục', 'project', 'mục', 'dataset', 'competition', 'mong', 'giải đáp']"
919,"🔥🔥🔥 𝙃𝒐̣𝙘 𝙙𝒂𝙩𝒂 𝒗𝙖̀ 𝙫𝒊𝙚̣̂𝒄 𝒍𝙖̀𝒎 𝑫𝙖𝒕𝙖. 🔥🔥🔥
Gần đây, trên các cộng đồng có nhiều tranh cãi ý kiến cho rằng “Đừng nên học data nữa, ngành data bão hòa rồi, học data không xin được việc đâu?”
Với quan điểm của mình, trước khi quyết định học hay theo đuổi một ngành nào đó các bạn hãy tự hỏi bản thân trước 3 câu hỏi:
- Cụ thể, mình đang muốn gì?
- Mục đích của việc học này là gì?
- Nếu có nó mình sẽ được những lợi ích gì? Nếu không có nó mình có thể sẽ mất đi cơ hội gì?
👉 Nếu các bạn cho rằng ngành data đã bão hòa và khó xin việc thì hãy hiểu nguyên nhân tại sao?
1. Hiện tại, tình hình kinh tế chung đang khó khăn, các doanh nghiệp còn đang lay off, nhiều ngành nghề khác cũng khó khăn và thất nghiệp không riêng gì trong lĩnh vực data.
2. Thực tế rằng nhu cầu tuyển dụng data vẫn rất lớn, cắt giảm tuyển level thấp tại vì doanh nghiệp cần phải tối ưu hóa chi phí, tập trung giải quyết vấn đề trước mắt nên họ muốn tìm những người có thể bắt đầu ngay với công việc và tạo ra giá trị thay vì đào tạo, nuôi dưỡng nguồn nhân lực mới.
- Bản chất của việc tuyển intern, fresher là đầu tư chi phí để đào tạo con người để đảm bảo nguồn nhân lực phát triển lâu dài chứ không phải giải quyết vấn đề trước mắt.
- Các doanh nghiệp tuyển Senior, Leader level là vì đa số doanh nghiệp, lĩnh vực đang bắt đầu ứng dụng và xây dựng data platform cần người có kinh nghiệm để bắt đầu, thiết kế, và đào tạo và đến một giai đoạn nào đó khi hệ thống đã phát triển họ k thể mãi tìm được các DE, DA level cao vì nếu không đào tạo lớp trẻ thì sẽ k có các senior tương lai. Vì vậy, sẽ có giai đoạn, nhu cầu tuyển dụng level thấp quay lại nhiều hơn… Nếu không học, không chuẩn bị trước cho tương lai thì làm sao bạn nắm bắt các cơ hội phí trước/
👉 Nếu các bạn bảo tại sao yêu cầu nhà tuyển dụng ngày càng cao, biết nhiều kỹ năng như: SQL, Power BI, Python,... vẫn không được tuyển?
1. Hãy đặt lại câu hỏi, tại sao họ phải tuyển bạn? Bạn có gì để mang lại giá trị cho công ty họ?
- Bạn hãy xem phỏng vấn, tìm việc (không phải xin việc =)) ) là đi chợ, việc làm, mức lương là hàng hóa và tiền. Bạn đang bán sức lao động và giá trị cho công ty nên “Thuận mua, vừa bán”. Mức lương và công việc sẽ đi theo quy luật cung cầu của thị trường (điều này đúng cho tất cả ngành nghề)
- Ngành data ngày càng hot vì mức lương, mức đãi ngộ hấp dẫn với nhiều cơ hội phát triển do vậy ngày càng nhiều người chú ý và học về Data nên sự cạnh tranh sẽ lên cao. Trước kia ít người học, khó tuyển người nên yêu cầu đơn giản, bây giờ đã có nhiều người học và có những người có tư duy, tư chất tốt hơn biết nhiều hơn thì họ có quyền chọn người tốt hơn, yêu cầu cao hơn chứ.
2. Hãy bỏ tư tưởng “ăn xổi”.
- Bạn bảo bạn biết SQL, BI tools, lập trình .. nhưng bạn thật sự biết đến đâu- thành thạo đến đâu? Bài đăng nào của các bạn em cũng chỉ thấy nói “em có học và biết một chút” chứ k nói em thành thạo và đã làm những dự án A, B, C về SQL, Data warehouse hay BI dashboard.
- Bạn hãy quên đi giấc mơ học 3, 6 tháng ở khóa học ngắn hạn và chắc chắn có việc. Các bạn học 3 -6 tháng và tin theo lời quảng cáo của trung tâm là chắc chắn có việc = )) . Hãy suy nghĩ các bạn lấy gì để cạnh tranh với những bạn đã học 4 năm đại học hay ngồi học ngày học đêm để nâng cao kỹ năng từng ngày mà chỉ tin tưởng và tuần 2 buổi học trong 3 tháng là giỏi rồi, đi làm tốt rồi ..
- Tất nhiều một số bạn, có thể nói là nhiều bạn xin việc trong 3 tháng , 6 tháng, thậm chí là 2 tháng học về data nhưng đó chắc chắn là nhiều sự đánh đổi cố gắng và đôi khi là may mắn nắm bắt được đúng cơ hội,..
Nhiều bạn học sinh của mình đã nhận được việc 2 tháng, 3 tháng học (dù chưa được học đầy đủ kiến thức nhưng cũng có nhiều bạn học xong rồi những loay hoay mãi chưa tìm được cơ hội, Mình nhận thấy rằng các bạn tìm được việc sớm có một số là do có tố chất tốt hơn về cả hard skill và soft skill, có một số chăm chỉ hơn, cố gắng nhiều hơn và đa số là do may mắn gặp thời điểm tốt hơn, nắm bắt được cơ hội =)) vì mình dạy và đánh giá được trình đội các bạn đôi lúc không chênh lệch nhiều thậm chí bạn k tìm được việc còn tốt hơn bạn đã tìm được =))
- Tìm việc là sự phù hợp vs công ty không chỉ về kỹ năng và nhiều yếu tố khác.
Khi mình tốt nghiệp đại học, mình tự tin có một nền tảng kiến thức vững chắc (mình đã skip rất nhiều về software để tập trung học AI và Data), mình có hơn 1 năm nghiên cứu tại Lab trí tuệ nhân tạo, Mình là first author 1 paper trong hội nghị RANK A, có 2 năm kinh nghiệm part time tại một công ty lớn nhưng mình vẫn “BỊ TRƯỢT PHỎNG VẤN VỊ TRÍ FRESHER CỦA MỘT CÔNG TY VN” (đoạn này khoe chỉ là phần nhỏ thôi, phần lớn để cho các bạn thấy phù hợp quan trọng thế nào. Nếu có dịp mình sẽ chia sẻ về lần PV trượt ấy) bởi vì tại thời điểm ấy họ k cần những người làm việc như mình, và họ có nhiều option có thể tốt hơn, có thể phù hợp hơn.
👉 Hãy xác định học để làm gì? Minh luôn quan điểm học để ấm vào thân, để xây dựng kiến thức trước.
- Nếu phần trên nói đến tư tưởng ăn xổi, có nhiều bạn gọi cho mình và hỏi học xong 1 khóa, 2 khóa học của anh em có xin việc không và mình trả lời “Xin được việc hay không do sự cố gắng và may mắn của bạn không phải ở mình và cái mình cam kết và chất lượng kiến thức và bạn cảm thấy mình đang hiểu biết lên, đang học được những kiến thức có ích chứ MÌNH KHÔNG BAO GIỜ CAM KẾT VIỆC LÀM” và đến 90 % các bạn thất vọng và không học. Mình xin chúc các bạn “may mắn hơn ở một nơi nào đó họ cam kết học xong có việc”
- Tại sao các bạn không nghĩ đến việc học để lấy kiến thức cho bản thân trước, rồi khi có kiến thức các cơ hội sẽ tự tìm thời và mình sẽ không bỏ lỡ những cơ hội trong tương lai?
- Tại sao các bạn luôn có tư tưởng học để chuyển một công việc mới sang làm Data luôn mà không nghĩ để phục vụ cho chuyên ngành, cho công việc khác của mình sau này. Các bạn hãy để ý thời kì công nghệ thông tin bắt đầu bùng nổ, giá trị của những người đã biết sử dụng máy tính, thành thạo tin học văn phòng trong CV cao như thế nào và hiện tại ai cũng cảm nhận rõ mình đang bước chân vào thời kỳ mới là “Data Driven” vậy những người có kỹ năng tốt về dữ liệu liệu có cơ hội, có thế mạnh để cạnh tranh hơn trong lĩnh vực của họ hay không?
Thôi viết dài quá, mỏi tay, đói bụng,... nếu có cơ hội mình sẽ chia sẻ sâu hơn về từng quan điểm trong bài viết. À có một vấn đề, mình vừa nghĩ vừa gõ máy sẽ bị các lỗi chính tả nên có gặp nhiều lỗi chính tả xin các bạn đừng cười, và tập trung vào nội dung bài viết và các luận điểm mình muốn truyền đạt, có ai đó đã từng nói rằng
“Một khi đã sai chính tả thì mọi lập luận đều vô nghĩa” =))","['#sharing', '#data']","['cộng đồng', 'tranh cãi kiến', 'đừng', 'học', 'data', 'ngành', 'data bão', 'hòa học', 'data quan', 'quyết định', 'học', 'đuổi', 'ngành', 'thân', '3', 'mục đích', 'học', 'lợi ích thể', 'đi', 'hội', 'ngành', 'data bão', 'hòa', 'nguyên nhân', '1', 'tình hình', 'kinh tế', 'khăn', 'doanh nghiệp', 'lay off', 'ngành nghề', 'khăn', 'thất nghiệp', 'lĩnh vực', 'data', '2', 'nhu cầu', 'tuyển dụng', 'data', 'cắt', 'tuyển', 'level', 'doanh nghiệp', 'tối ưu hóa', 'chi phí', 'giải quyết', 'mắt thể', 'công thay', 'đào', 'nuôi dưỡng', 'nhân lực', 'chất tuyển', 'intern', 'fresher', 'đầu tư', 'chi phí', 'đào', 'nhân lực', 'phát triển', 'giải quyết', 'mắt', 'doanh nghiệp', 'tuyển', 'senior', 'leader', 'level đa', 'doanh nghiệp', 'lĩnh vực', 'ứng dụng', 'xây dựng', 'data', 'platform', 'kinh nghiệm', 'thiết kế', 'đào', 'giai đoạn', 'hệ thống', 'phát triển', 'k thể', 'mãi', 'de', 'da', 'level', 'đào', 'lớp', 'trẻ', 'k', 'senior', 'tương lai', 'giai đoạn', 'nhu cầu', 'tuyển dụng', 'level', 'học', 'chuẩn', 'tương lai', 'nắm bắt', 'hội phí', 'bảo', 'tuyển dụng', 'kỹ năng', 'sql', 'power', 'bi python', 'tuyển', '1', 'tuyển', 'công ty vấn', 'đi', 'chợ', 'lương', 'hàng', 'hóa', 'tiền', 'sức lao động', 'công ty', 'thuận', 'mua', 'lương công', 'đi', 'quy luật', 'cung cầu', 'thị trường', 'tất', 'ngành nghề', 'ngành', 'data', 'hot', 'lương', 'đãi ngộ', 'hấp hội', 'phát triển', 'học', 'data', 'cạnh tranh', 'kia', 'học', 'tuyển', 'đơn giản học', 'tư tư', 'chất', 'quyền', '2', 'tư tưởng', 'xổi', 'bảo', 'sql', 'bi tools', 'lập trình', 'thành thạo', 'đăng học', 'chút', 'k', 'thành thạo', 'dự án', 'a b', 'c', 'sql', 'data', 'warehouse', 'bi dashboard', 'quên', 'đi', 'giấc', 'mơ', 'học', '3', '6', 'khóa học', 'ngắn hạn', 'chắn', 'học', '3', '6', 'quảng cáo', 'trung tâm', 'chắn', 'suy cạnh tranh', 'học', '4', 'đại học', 'học', 'học', 'đêm', 'nâng', 'kỹ năng', 'tưởng', 'tuần', '2', 'học', '3', 'giỏi', 'đi', 'tất thể', '3', '6', 'chí', '2', 'học', 'data chắn', 'đánh đổi', 'cố gắng', 'đôi', 'may mắn', 'nắm bắt', 'hội', 'học sinh', '2', '3', 'học học', 'kiến thức', 'học', 'xong', 'loay hoay', 'mãi', 'hội tố', 'chất', 'hard', 'skill', 'soft', 'skill', 'chăm', 'cố gắng', 'đa', 'may mắn', 'nắm bắt', 'hội', 'dạy', 'trình', 'đội', 'đôi', 'chênh lệch', 'chí', 'k vs', 'công ty', 'kỹ năng', 'yếu tố nghiệp', 'đại học tảng', 'kiến thức', 'vững skip', 'software', 'học', 'data', '1', 'nghiên cứu', 'lab trí tuệ', 'nhân', 'first', 'author', '1', 'paper', 'hội nghị', 'rank a', '2', 'kinh nghiệm', 'part time', 'công ty', 'trượt vấn', 'fresher', 'công ty', 'vn', 'đoạn', 'khoe', 'dịp', 'pv', 'trượt', 'k', 'option thể thể', 'xác định', 'học minh', 'quan học', 'ấm thân', 'xây dựng', 'kiến thức', 'tư tưởng', 'xổi', 'gọi', 'học', 'xong', '1', 'khóa', '2', 'khóa', 'học', 'cố gắng', 'may mắn', 'cam kết chất', 'kiến thức', 'học', 'kiến thức ích', 'cam kết', '90', 'thất vọng', 'học', 'chúc', 'may mắn', 'cam kết', 'học', 'xong học', 'kiến thức', 'thân', 'kiến thức', 'hội thời', 'lỡ hội', 'tương lai', 'tư tưởng', 'học', 'công data', 'phục vụ', 'chuyên ngành', 'công thời kì', 'công nghệ thông', 'bùng nổ', 'máy', 'thành thạo', 'học', 'văn phòng', 'cv cảm', 'chân', 'thời kỳ', 'data', 'driven', 'kỹ năng liệu liệu', 'hội', 'cạnh tranh', 'lĩnh vực', 'viết', 'mỏi', 'đói', 'bụng hội', 'sâu quan', 'viết', 'gõ', 'máy', 'lỗi tả', 'lỗi tả', 'đừng', 'cười', 'nội dung', 'viết luận', 'truyền', 'sai tả', 'lập luận', 'vô nghĩa']"
920,"Em chào anh chị trong group,
Em mới tìm hiểu về Machine Learning và em mong muốn tìm cuốn sách hoặc khoá học để có thể hiểu rõ về các thuật toán đằng sau các mô hình và cách sử dụng mô hình phù hợp cho từng bài toán khác nhau. Mong được anh chị giúp đỡ cho em ạ.
Em cảm ơn.","['#Q&A', '#machine_learning']","['chào', 'group', 'machine', 'learning', 'mong', 'sách', 'khóa', 'học thể', 'thuật toán', 'đằng', 'mô hình', 'mô hình', 'toán', 'mong', 'giúp đỡ']"
921,"Thuật toán Monte Carlo Tree Search trong AlphaGo.
Chào các bạn, mình tìm thấy một bài viết khá hay về thuật toán Monte Carlo Tree Search - trái tim của hệ thống đánh cờ vây Alpha Go. Mình xin giới thiệu nó với các bạn, và tiện thể mình cũng dịch nó ra tiếng Việt luôn cho bạn nào quan tâm.
Và kèm theo cả python code sử dụng Monte Carlo cho trò cờ vây và tic-tac-toe (cờ caro 3*3).
Bài dịch: https://ngdmau.github.io/Monte-Carlo-Tree-Search/
Bài gốc: https://int8.io/monte-carlo-tree-search-beginners-guide/
Link code python:
Cờ vây: https://github.com/int8/gomcts
Tic-tac-toe: https://github.com/int8/monte-carlo-tree-search
Xin cảm ơn và chúc các bạn buổi tối vui vẻ ^^.
#python #montecarlo #mcts #alphago #gametheory","['#sharing', '#machine_learning']","['thuật', 'toán', 'monte', 'carlo', 'tree', 'search', 'alphago', 'chào', 'viết', 'thuật toán', 'monte', 'carlo', 'tree', 'search', 'trái tim', 'hệ thống', 'đánh', 'cờ', 'vây alpha', 'go', 'giới thiệu', 'dịch', 'tiếng', 'việt', 'kèm', 'python', 'code', 'monte', 'carlo', 'trò', 'cờ vây', 'tictactoe', 'cờ', 'caro', '3', '3', 'dịch', 'https', 'ngdmau', 'github', 'io', 'montecarlotreesearch', 'gốc', 'https', 'int8', 'io', 'montecarlotreesearchbeginnersguide', 'link', 'code', 'python', 'cờ vây', 'tictactoe chúc', 'tối', 'vui vẻ']"
922,"Tác giả của ""Effective Pandas"" - anh Matt Harrison - tặng sách.
Mặc dù ai cũng biết chỗ để tải cuốn sách mình muốn, nhưng nếu được chính tác giả tặng thì cảm giác vẫn rất khác biệt.
Các bạn làm theo hướng dẫn để được tặng sách miễn phí nhé.",['#sharing'],"['tác giả', 'effective', 'pandas', 'matt', 'harrison', 'tặng', 'sách', 'mặc', 'chỗ', 'tải', 'sách tác giả', 'tặng', 'cảm giác', 'biệt hướng', 'tặng', 'sách', 'miễn phí']"
923,"Em 27 tuổi dev quèn đang gặm quyển thánh kinh của anh Tiệp để chuyển việc.
Công nhận ngành khó voãi mấy bác ạ, ko biết có bác nào lớn lớn chia sẻ ít kinh nghiệm tự học không, em ko có background khoa học máy tính theo có ổn hay đuối ko ợ.
(em có bằng đh mạng máy tính, chả LQ, dev quèn cũng ít dính luôn, hjx)
Em cảm ơn.","['#Q&A', '#machine_learning']","['27', 'dev', 'quèn gặm', 'quyển', 'thánh kinh', 'tiệp', 'công', 'ngành', 'voãi', 'mấy', 'ko', 'kinh nghiệm', 'học', 'ko background', 'khoa học', 'máy', 'ổn đuối', 'ko', 'ợ', 'đh', 'mạng', 'máy', 'chả', 'lq', 'dev', 'quèn', 'dính', 'hjx']"
924,Xin chia sẻ với mọi người một thư viện hay ho giúp tối ưu bộ nhớ khi triển khai các mô hình LLM lên môi trường production ạ 😁,"['#Q&A', '#deep_learning']","['thư viện', 'ho', 'giúp', 'tối ưu', 'triển khai', 'mô hình', 'llm', 'môi trường', 'production']"
925,"FinGPT: Open-Source Financial LLMs
Cung cấp toàn bộ quy trình LLM training and finetuning trong lĩnh vực tài chính.
paper: https://arxiv.org/abs/2306.06031
Code: https://github.com/AI4Finance-Foundation/FinGPT","['#sharing', '#deep_learning']","['fingpt', 'opensource', 'financial', 'llms', 'cung toàn', 'quy trình', 'llm training', 'and finetuning', 'lĩnh vực', 'tài paper', 'code']"
926,"Chào các a/chị trong group ạ.
Em mới mọc mòi nghiên cứu về NLP thì có một thắc mắc mong nhận được một số ý kiến để tham khảo ạ:
Ở trong quá trình preprocess, em có thấy là đa số các hệ thống sẽ sử dụng BPE để tokenize đầu vào. Tuy nhiên em có đọc được paper của PhoBERT (Mô hình ngôn ngữ của VN) thì họ có đề cập là họ đã WordSegment trước khi áp dụng BPE.
Về mặt trực giác thì do PhoBERT là mô hình đơn ngôn ngữ (monolingual) nên việc segment các từ, từ ghép thì đúng là sẽ giúp ích rất nhiều cho việc tokenize để bổ trợ feature cho các task về sau.
Thắc mắc của em là nếu ta cần giải quyết một bài toán đa ngôn ngữ trong đó bao gồm ngôn ngữ các unit của nó được tách biệt rõ ràng như English (Whitespace) và các ngôn ngữ có cách biểu diễn khác như VN (từ ghép) hay JP (ko có whitespace) thì mình sẽ preprocess như nào ạ ?
Em cảm ơn a.chị.","['#Q&A', '#nlp', '#deep_learning']","['chào', 'a group', 'mọc mòi', 'nghiên cứu', 'nlp', 'thắc mắc', 'mong kiến', 'tham khảo', 'trình', 'preprocess đa', 'hệ thống', 'bpe', 'tokenize', 'đầu nhiên', 'đọc', 'paper', 'phobert', 'mô hình', 'ngôn ngữ', 'vn', 'đề cập', 'wordsegment', 'áp dụng', 'bpe mặt', 'trực giác', 'phobert', 'mô hình', 'đơn ngôn ngữ', 'monolingual', 'segment', 'ghép', 'giúp ích', 'tokenize', 'bổ trợ', 'feature', 'task', 'thắc mắc', 'ta', 'giải quyết', 'toán đa', 'ngôn ngữ', 'bao ngôn ngữ', 'unit', 'tách biệt', 'ràng', 'english whitespace', 'ngôn ngữ', 'biểu diễn', 'vn', 'ghép', 'jp', 'ko', 'whitespace', 'preprocess', 'a']"
927,"Em đang có 1 vấn đề như này ạ, mong đc giải đáp
Dưới đây là 2 video em quay lại 2 ứng dụng sử dụng text-to-speech, bên trái là ứng dụng trên mạng, bên phải là em tự code. Thư viện e sử dụng là gTTS có sẵn của Python, nhưng không hiểu sao nghe nó khá là đuồi :(
Em có chỉnh lại tham số đầy đủ của gTTS cho nó sử dụng api của tên miền google.com.vn và ngôn là vi nhưng vẫn k đạt được chất lượng của voice như bên phải. Voice của video bên phải được sử dụng khá nhiều, bên J2Team cũng sử dụng voice này mà em không biết lấy đâu ra hay làm sao đạt được, ai có kinh nghiệm thì giúp em với, em cám ơn mọi người nhiều ạ","['#Q&A', '#nlp', '#python']","['1', 'mong', 'đc', 'giải đáp', '2', 'video', '2', 'ứng dụng', 'texttospeech', 'trái', 'ứng dụng', 'mạng', 'code', 'thư viện', 'e gtts', 'sẵn', 'python', 'đuồi chỉnh', 'tham gtts', 'api', 'miền', 'ngôn vi k', 'chất', 'voice', 'voice', 'video', 'j2team', 'voice', 'kinh nghiệm', 'giúp', 'cám ơn']"
928,Em xin chia sẻ một bài ngắn về a == None và a is None cho bác nào quan tâm ạ 😁,"['#sharing', '#python']","['ngắn', 'a none', 'a', 'is', 'none']"
929,"Chào mọi người, em hiện tại sẽ tốt nghiệp vào tháng 8 và đang muốn tìm một job về AI Engineer. Trước đó thì em đã có khoảng 9 tháng intern về CV ở Viettel. Mọi người cho em hỏi là ở Hà Nội thì có những công ty nào tốt làm về AI ạ?","['#Q&A', '#machine_learning']","['chào nghiệp', '8', 'job', 'engineer', '9', 'intern', 'cv', 'viettel', 'hà nội', 'công ty']"
930,"Giống như công cụ Warp của Photoshop, nhưng mạnh mẽ hơn nhiều.
Mô hình AI mới này giúp chỉnh sửa hình ảnh bằng thao tác bấm và kéo thả đơn giản. Xoay đối tượng của ảnh như thể đó là một mô hình 3D.
Xem thêm:","['#sharing', '#cv', '#machine_learning']","['công cụ', 'warp', 'photoshop mẽ', 'mô hình', 'giúp', 'chỉnh sửa', 'hình ảnh', 'thao tác', 'bấm', 'kéo', 'thả', 'đơn giản', 'xoay', 'đối tượng', 'ảnh thể', 'mô hình', '3', 'd']"
931,"Xin chào tất cả mọi người,
Tôi muốn mua một cuốn sách để làm quà bằng tiếng Anh. Những cuốn sách hay nhất về Machine Learning, Deep Learning mà bạn có thể đề xuất là gì.
Cảm ơn các bạn rất nhiều.","['#Q&A', '#machine_learning']","['chào tất', 'mua', 'sách', 'quà', 'tiếng', 'sách', 'machine', 'learning', 'deep', 'learning thể', 'đề xuất']"
932,Chào mn ạ. Mình tốt nghiệp đại học Bách khoa Hà nội chuyên ngành Cơ điện tử. Mình định hướng chuyên sâu mảng robotics and Al. Mình đang muốn tìm job intern/fresher về Al ở Hà nội. Cảm ơn mn ạ,"['#Q&A', '#machine_learning']","['chào', 'mn nghiệp', 'đại học', 'bách khoa', 'hà nội', 'chuyên ngành', 'điện tử', 'định hướng', 'chuyên sâu', 'mảng', 'robotics', 'and al', 'job', 'intern', 'fresher al', 'hà nội', 'mn']"
933,"Em chào anh chị trong nhóm ạ. Hiện em đã tốt nghiệp Đại học Bách Khoa Hà Nội chuyên ngành CƠ điện tử, em đang tìm việc Intern/fresher về Al tại Hà Nội. Không biết anh/chị ở công ty nào có còn open cho vị trí Intern/fresher không ạ?","['#Q&A', '#machine_learning']","['chào', 'hiện nghiệp', 'đại học', 'bách khoa', 'hà nội', 'chuyên ngành', 'điện tử', 'intern', 'fresher al', 'hà nội', 'công ty', 'open', 'intern', 'fresher']"
934,"[ Góc INTERN ]
Chào mọi người
Em sinh viên năm cuối tại HCM ngành điện tử công nghiệp
Có kiến thức về Machine learning,Deep learning, Neutral Network.
Image Processing và các framework AI tensor flow, Numpy, keras.....
Một số project về sử dụng các thuật toán ứng dụng vào hệ thống nhúng chủ yếu là các vấn đề nhận diện ( nhận diện khuôn mặt để mở cửa, nhận diện biển số xe, nhận diện khuôn mặt đeo khẩu trang...)
Em mong muốn tìm công việc internship tại HCM ạ","['#Q&A', '#machine_learning']","['góc', 'intern', 'chào', 'sinh viên', 'hcm', 'ngành', 'điện tử', 'công nghiệp', 'kiến thức', 'machine', 'learning', 'deep', 'learning', 'neutral', 'network', 'image', 'processing', 'framework', 'tensor', 'flow', 'numpy', 'keras', 'project thuật toán', 'ứng dụng', 'hệ thống', 'nhúng', 'chủ yếu', 'diện diện', 'khuôn mặt', 'cửa diện', 'biển', 'xe', 'diện', 'khuôn mặt', 'đeo', 'khẩu trang', 'mong', 'công internship', 'hcm']"
935,"[Nhờ trợ giúp]
Chào các bác, ví dụ có 1 text như này ""tôiđanghỏibạn"", bị lỗi dính chữ, mất dấu cách. Có thư viện nào có thể sửa được câu trên thành câu hoàn chỉnh không ạ? # output: ""tôi đang hỏi bạn"".
Nếu chuỗi là tiếng Anh thì làm được, còn tiếng Việt thì em chưa biết cách nào.🥲","['#Q&A', '#data']","['trợ giúp', 'chào', 'ví dụ', '1', 'text', 'tôiđanghỏibạn', 'lỗi', 'dính', 'chữ', 'dấu', 'thư viện thể', 'sửa', 'câu', 'thành', 'câu', 'hoàn chỉnh', 'output', 'chuỗi', 'tiếng', 'tiếng', 'việt']"
936,"Em chào anh/chị ạ. Hiện tại em mới tốt nghiệp và đang mong muốn tìm việc Fresher/Intern AI hoặc liên quan tới Data tại Hà Nội ạ.
Anh/chị đang tuyển thì cho em xin JD với ạ hoặc em sẽ inbox gửi CV ạ.","['#Q&A', '#machine_learning', '#data']","['chào nghiệp', 'mong', 'fresher', 'intern', 'data', 'hà nội', 'tuyển', 'jd', 'inbox', 'gửi', 'cv']"
937,"Em chào các anh chị ạ
Em đang là sinh viên năm 2 em có định hướng muốn theo AI nhưng không biết bắt đầu từ đâu, anh/chị có thể cho em xin roadmap được không ạ?Em cảm ơn ạ","['#Q&A', '#machine_learning']","['chào', 'sinh viên', '2', 'định hướng thể', 'roadmap']"
938,"Góc tìm đồng đội tham gia Team dự cuộc thi ""The 4th Annual International Competition in Data Science & Artificial Intelligence""
Chào các bạn, từ 01/7/2023 ~ 31/8/2023 ISODS, USA tổ chức cuộc thi quốc tế dành cho sinh viên, nghiên cứu viên về nội dung Data Science & Artificial Intelligence.
Nhóm mình cần tìm 05 thành viên tham gia Team, nếu bạn nào thấy yêu thích, phù hợp thì gửi CV mô tả năng lực và kinh nghiệm liên quan qua email cho mình nhé.
Hạn nhận Email: 25/06/2023.
Tiêu chí:
- Có kinh nghiệm, kỹ năng lập trình liên quan đến Data science, Machine learning, Deep learning và Computer vision.
- Tư duy thuật toán tốt.
- Ưu tiên các bạn sinh viên năm 4.
Quyền lợi:
- Làm việc, cộng tác với những bạn có kinh nghiệm trong lĩnh vực liên quan.
- Những bạn phù hợp, đáp ứng năng lực sẽ được nhận học bổng toàn phần Master/PhD tại Lab của mình tại trường Đại học Kyonggi, Hàn Quốc. Bắt đầu học vào kỳ mùa Xuân, tháng 3/2024.
- Tích lũy kinh nghiệm, hồ sơ xin học bổng Master/PhD tại nước ngoài.
Các thông tin liên quan:
Website về cuộc thi: http://isods.org/
Website của Lab: http://ctrl.kyonggi.ac.kr/
Email của mình: phamdinhlam@kgu.ac.kr
Cảm ơn Admin đã duyệt bài!","['#sharing', '#machine_learning']","['góc', 'đồng đội', 'tham gia', 'team', 'dự', 'thi', 'the', '4', 'th', 'annual', 'international', 'competition', 'in', 'data', 'science', 'artificial', 'intelligence', 'chào', '01', '7', '2023', '31', '8', '2023', 'isods usa', 'tổ chức', 'thi', 'quốc tế', 'sinh viên', 'nghiên cứu viên', 'nội dung', 'data', 'science', 'artificial', 'intelligence', '05', 'thành viên', 'tham gia', 'team', 'yêu', 'gửi', 'cv', 'mô tả', 'năng lực', 'kinh nghiệm', 'email', 'hạn', 'email', '25', '06', '2023', 'tiêu chí', 'kinh nghiệm', 'kỹ năng', 'lập trình', 'data', 'science', 'machine', 'learning', 'deep', 'learning', 'computer', 'vision', 'tư thuật toán', 'ưu tiên', 'sinh viên', '4', 'quyền lợi', 'cộng tác', 'kinh nghiệm', 'lĩnh vực', 'đáp ứng', 'năng lực', 'học bổng', 'toàn', 'master', 'phd', 'lab', 'trường', 'đại học', 'kyonggi', 'hàn quốc', 'học kỳ', 'mùa', 'xuân', '3', '2024', 'tích lũy', 'kinh nghiệm', 'hồ sơ', 'học bổng', 'master', 'phd', 'thông', 'website', 'thi', 'http', 'isods', 'org', 'website', 'lab', 'http', 'ctrl', 'kyonggi', 'ac', 'kr', 'email', 'phamdinhlam', 'kgu', 'ac', 'kr', 'admin', 'duyệt']"
939,"Chào mọi người, một người quen của em cần trợ giúp cho việc thử nghiệm các kỹ thuật học máy trên tập dữ liệu kinh tế, tất nhiên là có trả phí ạ.
Dữ liệu bao gồm: (1) time series tabular dataset, các cột đặc trưng bao gồm đặc trưng số thực và đặc trưng hạng mục, dặc trưng có dạng sai phân so với ""cùng kỳ năm xxx"", dạng tỷ lệ so với ""cùng kỳ năm xxx""; (2) dữ liệu binary thể hiện sự xuất hiện của keyword về kinh tế tại mỗi mốc thời gian. Các đặc trưng được phân về nhiều nhóm và giữa các nhóm có thể có sai khác về mốc thời gian thực hiện phép đo, sai khác về chu kỳ thực hiện phép đo; có thể có missing value trong các nhóm đặc trưng.
Cảm ơn mọi người đã đọc ạ.","['#sharing', '#machine_learning']","['chào', 'quen', 'trợ giúp', 'thử nghiệm', 'kỹ thuật', 'học', 'máy', 'tập liệu', 'kinh tế', 'tất nhiên', 'phí liệu', 'bao', '1', 'time', 'series', 'tabular', 'dataset', 'cột', 'đặc trưng', 'bao', 'đặc trưng', 'thực đặc trưng', 'hạng mục dặc', 'trưng dạng', 'sai', 'phân kỳ', 'xxx dạng', 'tỷ lệ', 'kỳ xxx', '2', 'liệu', 'binary', 'thể hiện', 'keyword', 'kinh tế', 'mốc', 'đặc trưng', 'phân thể', 'sai', 'mốc phép', 'đo', 'sai', 'chu kỳ', 'phép', 'đo thể', 'missing value', 'đặc trưng', 'đọc']"
940,"Các bác giúp em với ạ!
Em đang dùng thử VNCORENLP cho bài toán ner ạ , vấn đề là văn bản phải được chuẩn hóa(viết hoa tên người, địa điểm,...) thì mới phát huy được ạ còn để tất còn để ở chữ thường thì gần như là không phát hiện được gì ạ :(
Các bác có model nào để chuẩn hóa tiếng việt không ạ ,giới thiệu em với ạ !
Em cảm ơn","['#Q&A', '#nlp', '#data']","['giúp', 'thử', 'vncorenlp toán', 'ner', 'văn chuẩn', 'hóa', 'viết', 'hoa', 'địa phát huy', 'tất chữ', 'phát hiện', 'model', 'chuẩn', 'hóa', 'tiếng', 'việt', 'giới thiệu']"
941,"Giống như cây bút cần phải đọc rất nhiều truyện để trở thành một “tài năng kể chuyện”, các mô hình ngôn ngữ cần phải được huấn luyện trên một lượng lớn văn bản để đạt được sự thành thục. Càng đọc và học nhiều, chúng càng hiểu và sinh ra ngôn ngữ tốt hơn.","['#sharing', '#nlp']","['bút', 'đọc', 'truyện', 'tài năng', 'mô hình', 'ngôn ngữ', 'huấn luyện', 'văn', 'thành thục', 'đọc', 'học sinh', 'ngôn ngữ']"
942,"Chào mọi người!
Sau 1 tuần nhận được rất nhiều feedback từ mọi người, đặc biệt là từ một số bạn có hạn chế về GPU, team đã convert thành công Vietcuna sang C++ với thư viện GGML và chạy trên CPU chỉ với 3GB RAM.
Mọi người có thể tải model C++ tại đây
Bản quantized (4bit): https://huggingface.co/vilm/vietcuna-3b-ggml-fp16-q4_0
Bản non-quantized: https://huggingface.co/vilm/vietcuna-3b-ggml-fp16
Ngoài ra phiên bản 7B dự kiến sẽ sớm được phát hành.
https://github.com/vilm-ai/vietcuna.cpp",['#sharing'],"['chào', '1', 'tuần', 'feedback', 'hạn chế', 'gpu', 'team', 'convert', 'thành công', 'vietcuna', 'c', 'thư viện', 'ggml', 'chạy', 'cpu', '3', 'gb', 'ram thể', 'tải', 'model', 'c', 'quantized', '4', 'bit', 'nonquantized', 'phiên', '7', 'b', 'dự kiến', 'phát hành']"
943,"Em chào mọi người ạ.Em là sv năm 2 mới chập chững bước vào ML và mong muốn hướng đến sau này là ML engineer.Tuy mới bước đầu và trình độ chẳng bằng ai nhưng em có đam mê lớn vs ML cũng như AI ạ.Em đang tự học và tìm hiểu qua blog của anh Tiệp,nhưng mà em cũng muốn cày lại căn bản từ đầu lộ trình để hướng đến AI engineer bằng cách tham gia các khoá học trên mạng của coursera,udemy …
Vì mới chập chững nhập môn nên em rất mơ hồ và k rõ lộ trình cũng như thứ tự các khoá học mà mình nên focus 😞 Làm phiền anh/chị,cũng như cô/chú có thể chỉ giúp em 1 lộ trình và các khoá học từ căn bản đến nâng cao k ạ.
Từ 1 đứa chẳng có gì,em mong muốn đc sống vs đam mê và tạo ra 1 giá trị gì đó dù em biết AI là 1 trường phái rất rất khó và đòi hỏi 1 quá trình chăm chỉ lâu dài,nhưng em sẽ cố hết sức có thể ạ!
Em cảm ơn mọi người rất nhiều!!","['#Q&A', '#machine_learning']","['chào', 'sv', '2', 'chập chững', 'ml', 'mong', 'hướng', 'ml', 'engineer', 'đầu', 'trình độ', 'chẳng', 'đam mê', 'vs', 'ml', 'học', 'blog', 'tiệp', 'cày đầu', 'lộ trình', 'hướng', 'engineer', 'tham gia', 'khóa', 'học', 'mạng', 'coursera', 'udemy', 'chập chững', 'nhập môn', 'mơ hồ', 'k', 'lộ trình', 'khóa', 'học', 'focus', 'phiền thể', 'giúp', '1', 'lộ trình', 'khóa', 'học', 'nâng', 'k', '1', 'đứa', 'chẳng', 'mong', 'đc', 'sống', 'vs', 'đam mê', '1', '1', 'trường phái', 'đòi', '1', 'trình', 'chăm cố', 'sức thể']"
944,GIẢI THÍCH CÁCH HOẠT ĐỘNG CỦA SELF- ATTENTION.,"['#sharing', '#deep_learning']","['giải', 'hoạt động', 'self', 'attention']"
945,"Xin phép các bác admin cho em chia sẻ playlist Software Engineering Fundamentals tạo bởi anh em group MLOpsVN cho bác Data Scientist/AI Engineer nào quan tâm ạ.
https://www.youtube.com/playlist?list=PLvmLXlo5OR87Gifw5IT-YWllj67YHhaEw","['#sharing', '#machine_learning']","['phép', 'admin', 'playlist', 'software', 'engineering', 'fundamentals', 'group', 'mlopsvn', 'data', 'scientist', 'engineer']"
946,"Chào tất cả ACE trong group.
Cho em hỏi là trong group mình có ai đã sử dụng MMtracking của openmmlab chưa ạ? Em gặp vấn đề về implement và modify; mặc dù đã tìm hiểu cả tuần nay nhưng vẫn chưa giải quyết được nên e đăng stt này hy vọng mọi người giúp e ạ. Do vấn đề dài dòng quá nên không viết lên đây được ạ.
Cảm ơn mọi người đã đọc tin <3","['#Q&A', '#cv']","['chào', 'tất ace', 'group', 'group', 'mmtracking', 'openmmlab', 'implement', 'modify', 'mặc', 'tuần', 'giải quyết', 'e', 'đăng stt', 'hy vọng', 'giúp', 'e', 'dòng', 'viết', 'đọc', '3']"
947,"Giới thiệu với các bạn mô hình Vietcuna do bên mình mới train. Hiện chỉ public bản 3B, phiên bản 7B và 40B vẫn đang tiếp tục cải thiện và trong kế hoạch release","['#sharing', '#machine_learning']","['giới thiệu', 'mô hình', 'vietcuna', 'train', 'hiện', 'public', '3', 'b', 'phiên', '7', 'b', '40', 'b', 'cải thiện', 'kế hoạch', 'release']"
948,"Chào anh chị trong nhóm
Anh chị cho em hỏi em học ngành cơ điện tử đang kiếm cơ hội thực tập các công ty liên quan điến ngành học hiện tại
Em có vài câu hỏi sau đây:
Mong anh chị trả lời
Cơ điện tử ở việt nam đi thực tập chủ yếu làm gì?
Tìm thông tin trên mạng mông lung quá
Đôi nét bản thân: em là sinh viên đầu năm 3 một trường kỹ thuật tại sài gòn
tiếng anh của em đọc hiểu nghe nói k vấn đề giao tiếp tốt, sài được ngôn ngữ c, vba, matlab ở mức căn bản, python, cad, solidworks, plc, inventor
Một số chứng chỉ trên coursera liên quan đến mấy phần mềm ở trên ,cs50p
Mong anh chị cho em thông tin thực tập tại công ty liên quan đến chuyên ngành của em
Cuối năm nay em thi thêm tiếng trung hsk thì liệu có tăng thêm cơ hội thực tập tại các công ty không
Em không ngại khó anh chị chỉ em chỗ thực tập để học hỏi và trau dồi cho bản thân.
Anh chị giải đáp với.
Còn lập trình nhúng , thiết kế cơ khí có anh chị nào làm mảng này không, mình có thể trao đổi tại bài post này.
Còn data science thì học kiến thức gì trước trước khi tìm hiểu mảng nay tại trên mạng nói nhiều cái mông lung quá
Em xin lỗi vì hỏi hơi ngớ ngớ.
Cảm ơn anh chị đọc bài!",['#Q&A'],"['chào học', 'ngành', 'điện tử', 'kiếm', 'hội', 'thực tập', 'công ty', 'điến', 'ngành', 'học', 'mong điện tử', 'việt nam', 'đi', 'thực tập', 'chủ yếu', 'thông mạng', 'mông', 'lung đôi', 'nét', 'thân', 'sinh viên', 'đầu', '3', 'trường', 'kỹ thuật', 'sài gòn', 'tiếng', 'đọc', 'k', 'giao tiếp sài', 'ngôn ngữ', 'c', 'vba', 'matlab', 'python', 'cad', 'solidworks', 'plc', 'inventor', 'chứng coursera', 'mấy', 'mềm', 'cs50p mong', 'thông thực tập', 'công ty', 'chuyên ngành', 'thi tiếng', 'trung hsk liệu', 'hội thực tập', 'công ty', 'ngại', 'chỗ', 'thực tập', 'học', 'trau dồi', 'thân', 'giải đáp', 'lập trình', 'nhúng', 'thiết kế', 'khí', 'mảng thể', 'trao đổi', 'post', 'data', 'science học', 'kiến thức', 'mảng', 'mạng', 'mông', 'lung lỗi', 'hơi', 'ngớ ngớ', 'đọc']"
949,"Chào mọi người ạ, em đang thực hiện project cá nhân và trước đó sử dụng VOC dataset. Tuy nhiên để so sánh với các thực nghiệm của các tác giả trong paper thì em phải so sánh trên COCO. Tuy nhiên COCO có một vấn đề là nó tồn tại nhiều bức ảnh không có object nào thuộc COCO class, các module của em không được thiết kế cho việc này và chỉnh sửa lại rất mất thời gian. Bỏ những tấm ảnh này đi thì rất dễ nhưng em nghĩ là nó cũng sẽ ảnh hưởng đến việc train và tính mAP. Trong các paper thì các tác giả không đề cập đến việc này. Vậy hiện nay cách làm phổ biến là đơn giản bỏ những data như trên ra khỏi tập train và valid hay vẫn giữ vậy ạ.","['#Q&A', '#data']","['chào', 'project', 'voc', 'dataset nhiên', 'sánh thực nghiệm', 'tác giả', 'paper', 'sánh', 'coco nhiên', 'coco', 'tồn ảnh', 'object', 'coco', 'class', 'module', 'thiết kế', 'chỉnh sửa', 'ảnh', 'đi', 'ảnh hưởng', 'train', 'map', 'paper tác giả', 'đề cập', 'phổ biến', 'đơn giản', 'data', 'tập', 'train', 'valid']"
950,Mọi người cho em hỏi có cách nào để xóa các đường thẳng trong các ảnh trong hình không ạ? Em định dùng Hough để nhận diện nhưng ngặt nỗi số 7 với số 1 nó cũng nhận vào. Em dự định xóa các đường để rồi sau đó tìm ra được khung nhỏ nhất chứa số,"['#Q&A', '#cv']","['xóa', 'đường thẳng', 'ảnh', 'hình định', 'hough diện', 'ngặt', 'nỗi', '7', '1', 'dự định', 'xóa', 'đường', 'khung', 'chứa']"
951,"Chẳng là em có dùng MINST để đào tạo mô hình nhận dạng kí tự số, sử dụng mô hình MLP. Sau đó em thu thập thêm các kí tự số viết tay của nhiều người. Thì với tập dữ liệu mới này thì MNIST cho kết quả nhận diện không tốt lắm (khoảng 65%). Em định training tiếp mô hình trên tập dữ liệu mới, thì em nên chia tập training-test như thế nào ạ? Vì tập dữ mới của em không được cân cho lắm, ví dụ như tập số 0 có 100 ảnh, tập số 8 có 70 ảnh, trong khi đó tập số 1 chỉ có khoảng 15 ảnh thôi, hay tập số 4 chỉ có 20 ảnh","['#Q&A', '#cv', '#data']","['chẳng', 'minst', 'đào', 'mô hình', 'dạng', 'kí', 'mô hình', 'mlp', 'thu thập', 'kí', 'viết', 'tập liệu', 'mnist', 'kết diện', 'lắm', '65', 'định', 'training', 'tiếp', 'mô hình', 'tập liệu', 'chia', 'tập', 'trainingtest', 'tập', 'cân', 'lắm', 'ví dụ', 'tập', '0', '100', 'ảnh', 'tập', '8', '70', 'ảnh', 'tập', '1', '15', 'ảnh', 'tập', '4', '20', 'ảnh']"
952,"Xin chào các anh em trong nhóm,
Mình là người không chuyên, nhưng đang thử ứng dụng ML cho 1 bài toán của công ty. Mình nghĩ bài toán này dùng ML là đủ chứ ko cần DL.
Do chưa có nhiều kinh nghiệm nên mình có câu hỏi như sau. Hiện tại 1 sample của mình có 8 feauture (dimension ), nhưng thực tế chỉ có 2 LOẠI feauture thôi, vì 1 sample này được lấy từ 4 sensor, mỗi sensor cho thu về 2 loại feauture. 1 cái là Vận tốc, 1 là áp suất tại van đó. Nhưng 4 van này đổ về 1 khuôn chứa, từ đó tạo ra sản phẩm, nên ko thể bỏ được feauture nào hết.
Ngoài việc đưa cả 8 feauture vào, hoặc nghĩ ra 1 công thức để sinh feauture mới, thì có cách nào để Model hiểu 8 feauture, nhưng thực chất là có 2 loại chính được ko ạ?
Mình đang làm bài toán Clustering.
Mong được hướng dẫn hoặc cho keyword nào liên quan đến vấn đề này. Xin cảm ơn!","['#Q&A', '#machine_learning']","['chào', 'chuyên', 'thử', 'ứng dụng', 'ml', '1', 'toán', 'công ty', 'toán', 'ml', 'ko', 'dl', 'kinh nghiệm', '1', 'sample', '8', 'feauture', 'dimension', '2', 'feauture', '1', 'sample', '4', 'sensor', 'sensor', 'thu', '2', 'feauture', '1', 'vận tốc', '1', 'áp suất', 'van', '4', 'van', 'đổ', '1', 'khuôn', 'chứa', 'sản phẩm', 'ko thể', 'feauture', '8', 'feauture', '1', 'công thức', 'sinh feauture', 'model', '8', 'feauture', 'thực chất', '2', 'ko toán', 'clustering', 'mong', 'hướng', 'keyword']"
953,"Chào mọi người,
Em hiện là sinh viên ngành Cơ Điện Tử muốn tìm hiểu về Machine Learning để áp dụng vào ngành của mình trong tương lai.
Hiện tại em đã học xong và nắm chắc các kiến thức liên quan đến Toán (Giải Tích, Xác suất, Đại Số Tuyến Tính,...). Về lập trình thì em đã biết C và R.
Nhờ mọi người tư vấn giúp em lộ trình cũng như các khóa học hay về Machine Learning cho sinh viên mới bắt đầu như em ạ.
Em xin cảm ơn.","['#Q&A', '#machine_learning']","['chào', 'hiện', 'sinh viên', 'ngành', 'điện tử', 'machine', 'learning', 'áp dụng', 'ngành', 'tương lai', 'học', 'xong', 'nắm', 'kiến thức', 'toán', 'giải tích', 'xác suất', 'đại tuyến', 'lập trình', 'c r', 'tư vấn', 'giúp', 'lộ trình', 'khóa', 'học', 'machine', 'learning', 'sinh viên']"
954,"Chào mọi người trong nhóm ạ
Em là sinh viên mới ra trường, trước đây thì e có theo hướng lập trình web, app bây giờ em muốn tìm hiểu sang cả học máy nữa nhưng chưa biết bắt đầu từ đâu. Mọi người có thể cho em xin một cái roadmap dành cho người mới bắt đầu như em không ạ? Em xin cảm ơn mn nhiều","['#Q&A', '#machine_learning']","['chào', 'sinh viên', 'trường', 'e hướng', 'lập trình', 'web', 'app', 'học', 'máy thể', 'roadmap', 'mn']"
955,"Mình đang tìm hiểu về deep learning trong việc xử lý hình ảnh, sau khi tra internet thì mình có những thắc mắc sau đây, mọi người có thể chia sẻ với mình về các câu hỏi này được không ạ? Em cảm ơn.
1. Embedding là quá trình gì? Phân biệt word embedding và image embedding?
→ Hiểu: embedding là quá trình chuyển vector nhiều chiều thành vector có số chiều ít hơn bằng cách tạo ra một không gian nhúng dành cho các từ có ý nghĩa gần giống nhau. Word embedding và image embedding đều xử lý việc biến input từ nhiều dimension thành vector/tensor có ít dimension hơn (ví dụ, thay vì có 10 words, thì ta sẽ có dạng tensor để biểu diễn cho từng word là 10 dimension - (0,0,...,1,0) - 9 số 0 và 1 số 1. → ta sẽ phát hiện ra những từ có cùng ngữ nghĩa và tạo nên một embedded space (1 tensor). Sau này khi biểu diễn các ngôn ngữ khác thì chỉ cần 1 vector chỉ index của từ đó để nhân với embedded tensor.
2. Pre-trained model của quá trình nhận dạng hình ảnh được thực hiện qua các bước chính nào? inception_v3 của torchvision.models hỗ trợ những gì trong quá trình pre-trained hoặc nhận dạng hình ảnh?
3. Hidden layer và embed layer khác gì nhau?
4. Ecoder và embedding khác gì nhau?
Opinion: encoder biến text/iamge thành vector, embedding là quá trình giảm dimension của vector","['#Q&A', '#deep_learning', '#cv']","['deep', 'learning', 'hình ảnh', 'tra', 'internet', 'thắc mắc thể', '1', 'embedding trình', 'phân biệt', 'word', 'embedding', 'image', 'embedding', 'embedding trình', 'vector', 'chiều', 'thành', 'vector', 'chiều', 'gian', 'nhúng nghĩa', 'word', 'embedding', 'image', 'embedding', 'biến input', 'dimension', 'thành', 'vector', 'tensor', 'dimension', 'ví dụ', 'thay', '10', 'words', 'ta', 'dạng', 'tensor', 'biểu diễn', 'word', '10', 'dimension', '0', '0', '1', '0', '9', '0', '1', '1', 'ta', 'phát hiện', 'ngữ nghĩa', 'embedded space', '1', 'tensor', 'biểu diễn', 'ngôn ngữ', '1', 'vector', 'index nhân', 'embedded', 'tensor', '2', 'pretrained', 'model trình', 'dạng', 'hình ảnh', 'inception_v3', 'torchvision', 'models', 'trình', 'pretrained', 'dạng', 'hình ảnh', '3', 'hidden', 'layer', 'embed', 'layer', '4', 'ecoder', 'embedding', 'opinion', 'encoder', 'biến', 'text', 'iamge', 'thành', 'vector', 'embedding trình', 'dimension', 'vector']"
956,"Xin chào mọi người ạ. Hiện em đang bắt đầu học python để dùng cho ML, mọi người có thể giới thiệu cho em học các khóa học online nào thì phù hợp ạ.
P/S: Em có kiến thức về lập trình căn bản rồi nên em nghĩ em học sẽ khá nhanh
Cảm ơn mọi người ạ <3","['#Q&A', '#machine_learning', '#python']","['chào', 'hiện', 'học', 'python', 'ml thể', 'giới thiệu', 'học', 'khóa học', 'online', 'p s', 'kiến thức', 'lập trình', 'học', '3']"
957,"Chào mọi người, em có người quen cần tìm giải pháp làm mềm ảnh bitmap thành ảnh vector có thể dùng cho thêu công nghiệp wilcom. Yêu cầu xử lý được pencil hatching pattern, lọc bỏ được chi tiết thừa để phù hợp với ảnh thêu. Không biết đã có ai cung cấp giải pháp chưa ạ? Cảm ơn mọi người rất nhiều.
Ảnh minh hoạ","['#sharing', '#cv']","['chào', 'quen', 'giải pháp', 'mềm ảnh', 'bitmap', 'thành', 'ảnh', 'vector thể', 'thêu', 'công nghiệp', 'wilcom', 'pencil', 'hatching', 'pattern', 'lọc', 'chi tiết', 'thừa', 'ảnh', 'thêu cung', 'giải pháp', 'ảnh minh', 'họa']"
958,"Chào mọi người, tại sao AlexNet sử dụng Group Convolution nhưng hầu hết những implementation cộng đồng của AlexNet lại chỉ dùng Convolution thông thường ạ?","['#Q&A', '#deep_learning']","['chào', 'alexnet', 'group', 'convolution', 'implementation', 'cộng đồng', 'alexnet', 'convolution', 'thông']"
959,"Xin chào mọi người, em có 1 vài vấn đề cần mọi người trong nhóm tư vấn và hỗ trợ ạ.
Em đang có 1 đề tài về ứng dụng AI trong giám sát mạng. Dự định của em sẽ sử dụng Zabbix cho phần giám sát mạng, nhưng em tìm hiểu thì zabbix nó hỗ trợ rất ít AI hoặc không có ứng dụng AI rõ ràng trong đó. Nên em định chuyển tiếp các thông tin log thu thập được từ zabbix về 1 công cụ AI của bên khác để phân tích rõ hơn.
Vì thế em muốn hỏi mọi người trong nhóm tư vấn cho em các tool về 1 vài công cụ AI đó ( chủ yếu sử dụng qua webui chứ không phải lập trình vì em không chuyên về lập trình ạ) hoặc ứng dụng có tích hợp AI trong giám mạng có thể thay thế được Zabbix ạ.
Em cảm ơn ạ.","['#Q&A', '#machine_learning']","['chào', '1', 'tư vấn', '1', 'đề tài', 'ứng dụng', 'giám sát', 'mạng', 'dự định', 'zabbix', 'giám sát', 'mạng', 'zabbix', 'ứng dụng', 'ràng định', 'tiếp', 'thông log', 'thu thập', 'zabbix', '1', 'công cụ', 'phân tích', 'tư vấn', 'tool', '1', 'công cụ', 'chủ yếu', 'webui', 'lập trình', 'chuyên', 'lập trình', 'ứng dụng', 'tích hợp', 'giám mạng thể', 'thay', 'zabbix']"
960,"chào mọi người, mình xin phép hỏi đến một số vấn đề của face recognition.
1.Mình thắc mắc là trong các thư viện như face_recognition thì đầu ra của nó là 1 vector 128 chiều , hay là một index sau khi được softmax.
2. Mình có tìm hiểu thì thấy rằng họ sử dụng model facenet trong thư viện face_recognition. Mình cũng chưa hiểu facenet lắm, mk có đọc được là nó train bằng softmax ở lớp cuối, nhưng lâu lâu mình lại thấy đâu đó có tài liệu nói rằng nó sẽ nhúng ảnh thành vector 128 chiều. Vậy có phải là trước lớp cuối là 1 linear 128 chiều và lớp cuối là 1 softmax linear đúng k nhỉ, hay là lớp cuối cùng chỉ là 1 linear 128 chiều sau đó sử dụng l2_distance để đo độ tương đồng hoặc tính loss nhỉ ?
3. VD mình có 1 thư mục có 30 ảnh của 30 người khác nhau. Sau đó sử dụng face_recognition thì với vấn đề thứ 2 chưa giải quyết được nó sẽ sinh ra vấn đề tiếp là: nếu lớp cuối cùng là 1 softmax linear và trước nó là 1 linear 128 chiều thì có phải thư viện sẽ đóng băng toàn bộ weight trừ cái weight kết nối của 2 linear trên đúng không nhỉ? ( lý do mình nghĩ như vậy là vì weight kết nối mới khởi tạo rất dễ tạo ra loss lớn, mà lại phải update toàn bộ weight thì nó sẽ như kiểu big learning rate ấy). Cái này mình đoán mò th, ai thấy sai thì giúp mình với ạ.
Thực ra thì sáng nay mình có gặp một người và có kêu mình rằng thay vì em nhúng ra 128 vector rồi tính độ tương đồng giữa các khuôn mặt thì tại sao em không cho model chạy qua rồi 1 phát cho ra kết quả luôn. Mình đang nghĩ việc này không có khả thi cho lắm Tại vì nếu model càng sâu thì với dữ liệu ít ỏi chỉ có 30 hình ảnh thì rất dễ bị overfiting còn nếu model quá nông thì khó mà có thể nhận diện chính xác được. Điều này là mình đã thực nghiệm khi train mobilefacenet +arcMargin trên tập dữ liệu 5000 ảnh của hơn 1000 đối tượng vẫn bị overfitting. Nhưng mà do mình chưa data Agumentation nên cũng không chắc, mà mình hết colab ùi, ai từng làm qua kiểu 1 phát cho ra kết quả luôn thì chia sẽ cho mình với ạ.
Lỡ mình có hỏi ngu quá thì mong mn cũng đừng ném đá quá ha!!! cảm ơn mn đã đọc ạ.","['#Q&A', '#cv', '#machine_learning']","['o', 'mo', 'i', 'ngươ', 'i', 'mi', 'nh', 'phe p', 'ho', 'i', 'đê', 'n', 'mô', 't', 'sô', 'vâ', 'n', 'đê', 'cu', 'a', 'face', 'recognition', '1', 'mi', 'nh', 'thă', 'c', 'mă', 'c', 'la ca', 'c', 'thư', 'viê', 'n', 'face_recognition', 'thi', 'đâ u', 'cu a', 'no la', '1', 'vector', '128', 'chiê', 'u la', 'mô', 't', 'index', 'đươ', 'c', 'softmax', '2', 'mi', 'nh', 'co', 'ti', 'm', 'hiê u', 'thi', 'thâ', 'y ră', 'ng', 'ho sư', 'du ng', 'model', 'facenet', 'thư', 'viê', 'n', 'face_recognition', 'mi', 'nh', 'cu', 'ng', 'hiê u', 'facenet', 'lă', 'm', 'mk', 'co đo', 'c', 'đươ', 'c la', 'no', 'train', 'bă', 'ng', 'softmax', 'lơ p', 'cuô', 'i', 'mi', 'nh', 'la', 'i', 'thâ', 'y đo', 'co', 'ta', 'i', 'liê u', 'no', 'i', 'ră', 'ng', 'no', 'se', 'nhu ng', 'a', 'nh', 'tha nh', 'vector', '128', 'chiê u', 'vâ y co', 'pha', 'i la', 'trươ', 'c', 'lơ p', 'cuô', 'i la', '1', 'linear', '128', 'chiê u', 'va', 'lơ p', 'cuô', 'i la', '1', 'softmax', 'linear', 'đu ng', 'k', 'nhi la', 'lơ p', 'cuô', 'i', 'cu', 'ng', 'chi la', '1', 'linear', '128', 'chiê u', 'đo sư', 'du ng', 'l2_distance', 'đê', 'đo', 'đô', 'tương đô', 'ng', 'hoă', 'c ti', 'nh', 'loss nhi', '3', 'vd', 'mi', 'nh', 'co', '1', 'thư', 'mu c', 'co', '30', 'a nh', 'cu', 'a', '30', 'ngươ', 'i', 'kha c', 'đo sư', 'du ng', 'face_recognition', 'thi vơ', 'i', 'vâ', 'n', 'đê thư', '2', 'gia i', 'quyê', 't', 'đươ', 'c', 'no', 'se sinh', 'vâ', 'n', 'đê', 'tiê', 'p la', 'nê u', 'lơ p', 'cuô', 'i', 'cu', 'ng', 'la', '1', 'softmax', 'linear', 'va trươ', 'c', 'no la', '1', 'linear', '128', 'chiê u', 'thi co', 'pha', 'i', 'thư viê', 'n', 'se', 'đo', 'ng', 'băng', 'toa', 'n', 'bô', 'weight', 'trư', 'ca', 'i', 'weight', 'kê', 't', 'nô', 'i', 'cu', 'a', '2', 'linear', 'đu ng', 'nhi', 'ly mi', 'nh', 'nghi vâ', 'y la', 'vi weight', 'kê', 't', 'nô', 'i', 'mơ', 'i', 'khơ', 'i', 'ta', 'o', 'râ', 't', 'dê', 'ta', 'o', 'loss', 'lơ n', 'ma la', 'i', 'pha', 'i', 'update', 'toa', 'n', 'bô', 'weight', 'thi', 'no', 'se', 'kiê u', 'big', 'learning', 'rate', 'â', 'y ca', 'i', 'na y mi', 'nh', 'đoa', 'n mo', 'th', 'thâ y', 'sai', 'thi giu', 'p', 'mi', 'nh', 'vơ', 'i', 'a thư', 'c', 'thi', 'sa ng', 'mi', 'nh', 'co gă', 'p', 'mô', 't', 'ngươ', 'i', 'va co', 'kêu', 'mi', 'nh', 'ră', 'ng', 'thay vi', 'nhu ng', '128', 'vector', 'rô', 'i ti', 'nh đô', 'tương đô', 'ng', 'giư', 'a ca', 'c', 'khuôn', 'mă', 't', 'thi', 'ta', 'i', 'model', 'y rô', 'i', '1', 'pha', 't', 'kê', 't', 'mi', 'nh', 'nghi viê', 'c', 'na y co', 'kha', 'thi', 'lă', 'm', 'ta', 'i vi', 'nê u', 'model', 'ca', 'ng', 'sâu', 'thi vơ', 'i dư', 'liê u', 'i', 't', 'o', 'i', 'chi co', '30', 'hi nh', 'a', 'nh', 'thi', 'râ', 't', 'dê', 'bi overfiting', 'co n', 'nê u', 'model', 'nông thi', 'kho', 'ma co', 'thê nhâ', 'n', 'diê', 'n', 'chi', 'nh', 'c', 'đươ', 'c', 'điê u', 'na y la', 'mi', 'nh', 'đa thư', 'c', 'nghiê', 'm', 'train', 'mobilefacenet', 'arcmargin', 'tâ', 'p dư', 'liê u', '5000', 'a nh', 'cu', 'a', '1000', 'đô', 'i', 'tươ', 'ng', 'vâ', 'n', 'bi overfitting', 'ma', 'mi', 'nh', 'data', 'agumentation', 'cu', 'ng', 'chă', 'c', 'ma mi', 'nh', 'hê', 't', 'colab u', 'i tư', 'ng', 'la', 'm', 'kiê u', '1', 'pha', 't', 'kê', 't', 'thi', 'chia', 'se', 'mi', 'nh', 'vơ', 'i', 'a', 'lơ mi nh', 'co ho', 'i ngu', 'thi mong', 'mn', 'cu', 'ng', 'đư', 'ng', 'ne', 'm', 'đa', 'ha', 'ca', 'm', 'ơn', 'mn', 'đa đo', 'c', 'a']"
961," Chào mọi người, mình 30t là người trái ngành và đang có hứng thú tìm hiểu về AI. Mình có tham khảo nhiều nguồn và đang theo lộ trình tự học AI 6 khóa trên udemy (khóa thứ 6 ở bên dưới là: Áp dụng AI:
Applied Machine Learning for Healthcare (Hadelin de Ponteves, Kirill Eremenko)Khóa học này tập trung vào ứng dụng Machine Learning trong lĩnh vực y tế và dữ liệu y tế.
) do con chatGPT đưa ra và đã học xong khóa 1 trên. Theo mọi người lộ trình này có ổn không. Thêm nữa mọi người cho mình xin tên/link các khóa học toán trên Youtube hoặc Udemy/Cousera để theo ngành này nữa ạ. Cảm ơn mọi người!","['#Q&A', '#machine_learning']","['chào', '30', 't', 'trái', 'ngành', 'hứng thú', 'tham khảo', 'lộ trình', 'học', '6', 'khóa', 'udemy', 'khóa', '6', 'áp dụng', 'applied', 'machine', 'learning', 'for', 'healthcare', 'hadelin', 'de', 'ponteves', 'kirill', 'eremenko', 'khóa học', 'ứng dụng', 'machine', 'learning', 'lĩnh vực', 'y tế liệu', 'y tế', 'chatgpt học', 'xong', 'khóa', '1', 'lộ trình', 'ổn', 'link', 'khóa', 'học toán', 'youtube', 'udemy', 'cousera', 'ngành']"
962,"Chào mọi người,
Em đang làm một sản phẩm để dự thi cuộc thi KHKT THPT về việc cải thiện thời gian đèn giao thông bằng ML. Em làm được phần Car Detection roi nhma tới khúc xử lý để đưa ra một thời gian chính xác thì em đang phân giữa việc tìm ra một công thức toán hay là dùng một model ML.
Em có một thắc mắc là liệu mình có thể xây dựng một mô hình có thể dự đoán được thời gian đèn xanh/đỏ/vàng ở một ngã tư nào đó dựa vào các features là : lưu lượng xe , số lượng xe tại thời điểm t ở cả bốn cột đèn giao thông không ạ.
Nếu được thì mình phải label bằng tay cho tập dữ liệu đúng k ạ? Liệu mình có còn cách nào khác nhanh hơn không ạ.
Em cảm ơn mọi người ạ.","['#Q&A', '#cv', '#machine_learning']","['chào', 'sản phẩm', 'dự', 'thi', 'thi', 'khkt', 'thpt', 'cải thiện', 'đèn', 'giao thông', 'ml', 'car', 'detection', 'roi', 'nhma khúc', 'xác', 'phân công', 'thức toán', 'model', 'ml', 'thắc mắc', 'liệu thể', 'xây dựng', 'mô hình thể', 'dự đoán', 'đèn xanh', 'đỏ', 'vàng', 'ngã', 'tư', 'dựa', 'features', 'lưu', 'xe', 'xe', 't', 'bốn', 'cột', 'đèn', 'giao thông', 'label', 'tập liệu', 'k liệu']"
963,"Em chào mọi người ạ,
Em mới chuyển qua làm NLP được vài tháng nay, trước đó em làm mảng vision, nên em có một vài câu hỏi muốn tham vấn mọi người ạ. Giả sử quy mô dữ liệu lớn (>= 10M short Arabic text sentences of less than 100 words), nguồn lực khoảng 50 human annotators, em gặp vấn đề như sau:
Đối với bài toán sentiment classification (SC), annotation của human thường rất subjective, đặc biệt đối với các sentences có cả POS và NEG sentiments thì rất khó gán nhãn
Một số nguồn gợi ý sử dụng clustering words thành POS/NEG/NEU trước, rồi đếm số POS/NEG/NEU trong mỗi sentences để tạo pseudo-label. Tuy nhiên em thấy cách này chưa toàn diện, vì nghĩa của từ còn phụ thuộc nhiều vào context
Em có thử sử dụng một số SC models (pre-trained on big data) trên huggingface để sinh benchmark trên nhiều public datasets khác nhau thì thấy độ chính xác chỉ ở mức 70% => Em đoán là do cách định nghĩa POS/NEU/NEG sentiments của mỗi bộ dataset cũng khác nhau nhiều
Ngay cả việc định nghĩa thế nào là NEU sentiment em cũng chưa tìm thấy thông tin đủ tốt ạ. Trong bài [1], tác giả của báo có đề xuất NEU sentiment nghĩa là ""no positive and no negative"". Cơ mà như thế nào là ""no positive"" và ""no negative"" thì cũng rất đưa ra 1 quy tắc nhất quán
Có một cách để generate consistent SC labels là sử dụng public pre-trained LLMs (e.g. GPT), tuy nhiên em có thử GPT thì thấy chất lượng khá tệ. Kể cả Google Dịch cũng perform badly on Arabic (em so kết quả dịch của Google với kết quả dịch của human translator) => Em đoán là NLP models hiện tại vẫn chưa hoạt động tốt với Arabic
Em rất mong nhận được sự giúp đỡ của mọi người ạ!
Trích dẫn:
[1] https://www.reddit.com/r/MachineLearning/comments/1my83q/the_importance_of_neutral_class_in_sentiment/","['#Q&A', '#nlp']","['chào', 'nlp', 'mảng', 'vision', 'tham vấn', 'giả sử', 'quy mô liệu', '10', 'm', 'short', 'arabic', 'text', 'sentences', 'of less', 'than', '100', 'words lực', '50', 'human', 'annotators', 'đối toán', 'sentiment', 'classification', 'sc', 'annotation', 'human', 'subjective', 'đối sentences', 'pos', 'neg', 'sentiments', 'gán', 'nhãn', 'gợi', 'clustering', 'words', 'thành', 'pos', 'neg neu', 'đếm', 'pos', 'neg', 'neu', 'sentences', 'pseudolabel nhiên', 'toàn diện', 'nghĩa', 'phụ context', 'thử', 'sc', 'models', 'pretrained', 'on', 'big', 'data', 'huggingface sinh', 'benchmark', 'public', 'datasets độ', 'xác', '70', 'đoán định nghĩa', 'pos', 'neu', 'neg', 'sentiments', 'dataset định nghĩa', 'neu', 'sentiment thông', '1', 'tác giả', 'báo', 'đề xuất', 'neu', 'sentiment nghĩa', 'no positive', 'and no', 'negative', 'no', 'positive', 'no', 'negative', '1', 'quy tắc', 'quán', 'generate', 'consistent', 'sc', 'labels', 'public', 'pretrained', 'llms', 'e g', 'gpt nhiên', 'thử', 'gpt', 'chất tệ', 'google', 'dịch', 'perform', 'badly', 'on', 'arabic', 'kết', 'dịch', 'google kết', 'dịch', 'human', 'translator đoán', 'nlp models', 'hoạt động', 'arabic', 'mong', 'giúp đỡ', 'trích', '1', 'https', 'www', 'reddit', 'com', 'r', 'machinelearning', 'comments', '1', 'my83q', 'the_importance_of_neutral_class_in_sentiment']"
964,"Em chào mọi người ạ
Hiện em đang làm 1 project cuối kì về ML
1.1.Bài toán: Bài toán ước lượng
Công ty tài chính A cần kiểm soát thanh khoản của dòng tiền. Tại thời điểm đầu tháng 04.2023 cần ước lượng số tiền thu của khách hàng trong tháng 4.2023 là bao nhiêu.
Dựa vào data có sẵn
Yêu cầu
Requirements:
1.Clean data and train the models
2.Diagnose and assess the results
3.Use tools
Tuy nhiên project khi làm ra được cmt là sai trong việc sử dụng thống kê suy luận, đang xài R. Hiện tại em vẫn chưa tìm ra chỗ fix chỗ đó nên mạo muội muốn hỏi thêm các anh chị a, em cảm ơn","['#Q&A', '#machine_learning']","['chào', 'hiện', '1', 'project kì', 'ml', '1', '1', 'toán', 'toán ước', 'công ty', 'tài a', 'kiểm soát', 'khoản', 'dòng', 'tiền', 'đầu', '04', '2023', 'ước', 'tiền', 'thu', 'hàng', '4', '2023', 'dựa', 'data', 'sẵn', 'requirements', '1', 'clean', 'data', 'and train', 'the', 'models', '2', 'diagnose', 'and assess', 'the', 'results', '3', 'use', 'tools nhiên', 'project', 'cmt', 'sai', 'thống kê', 'suy luận', 'xài', 'r', 'chỗ', 'fix', 'chỗ mạo', 'muội', 'a']"
965,Mô hình AI chuyển đổi video 2D thành cấu trúc 3D chi tiết!,"['#sharing', '#machine_learning']","['mô hình', 'đổi', 'video', '2', 'd', 'thành', 'cấu trúc', '3', 'd', 'chi tiết']"
966,"Có bác nào làm việc với segmentation trong YOLO chưa ạ, cho em hỏi với là sau khi em train xong model thì đầu vào ảnh của em phải chuẩn hóa như nào mới cho vào model nhận diện được vậy ạ","['#Q&A', '#cv']","['segmentation', 'yolo', 'train', 'xong', 'model', 'đầu', 'ảnh', 'chuẩn', 'hóa', 'model diện']"
967,"Em chào mn ạ,
Em đang là sinh viên đi thực tập và em có được giao một task là crawl thông tin về các teams cũng như lịch sử đấu, lịch thi đấu của giải đấu Premier League. Em có kiểm tra khi vào trang thì web có gọi API tới để về data. Tuy nhiên em vào API thì bị error 403. Em có dùng cheerio để crawl thuần nhưng cái HTML nó trả về thì lại không chứa thông tin do nó dyniamic render. Mn ai có kinh nghiệm có thể hướng dẫn giúp em với ạ.
Em cảm ơn mn.
https://www.premierleague.com/","['#Q&A', '#data']","['chào mn', 'sinh viên', 'đi', 'thực tập', 'giao', 'task', 'crawl', 'thông teams', 'lịch sử', 'đấu', 'lịch', 'thi đấu', 'giải', 'đấu', 'premier', 'league', 'kiểm tra', 'trang web', 'gọi', 'api', 'data nhiên', 'api', 'error', '403', 'cheerio', 'crawl', 'html', 'chứa', 'thông dyniamic', 'render mn', 'kinh nghiệm thể', 'hướng', 'giúp', 'mn', 'https', 'www', 'premierleague', 'com']"
968,"Cuối tuần sau CVPR khai mạc ở Vancouver, Canada. Mình ko có paper nhưng cũng có mặt ngày chủ nhật, bạn nào trong group cũng đi thì hội Việt Nam hangout nhé.",['#sharing'],"['tuần', 'cvpr', 'khai mạc', 'vancouver', 'canada', 'ko', 'paper', 'mặt', 'chủ nhật', 'group', 'đi', 'hội', 'việt nam', 'hangout']"
969,"Chúc các bạn buổi tối chủ nhật vui vẻ và ấm áp bên người thân yêu. Trong tuần qua mình đã thực hiện 2 bài viết vể sử dụng Typst (được viết bằng Rust-lang) để soạn thảo luận văn/luận án và presentation slides. Mình hi vọng nó hữu ích cho các bạn muốn học và áp dụng vào quá trình biên soạn tài liệu cho các bạn.
Trong khoa học, các sinh viên còn có thể phải làm Poster để tham gia các Conferences. Vậy nên, trong chuỗi bài về Typst, mình xin chia sẻ bài còn lại sử dụng Typst để làm Poster tại đây: https://github.com/linhduongtuan/VNUHCM-typst-poster.
Mong rằng mấy bài về chủ đề Typst này có giá trị sử dụng trong công việc học tập và nghiên cứu của các bạn. Nếu các bạn thấy nó có ý nghĩa với bản thân mình thì xin đừng tiếc 1 Star cho các repositories của mình nhé. Cảm ơn các bạn nhiều.
Ps. Mình hi vọng, các Journals sẽ sớm chấp nhận Typst như 1 typsetting (như Word hay LaTeX) cho việc soạn thảo manuscripts gửi cho các tập san/nhà xuất bản trong thời gian gần nhất.",['#sharing'],"['chúc', 'tối', 'chủ nhật', 'vui vẻ', 'ấm áp', 'thân yêu', 'tuần', '2', 'viết', 'vể', 'typst', 'viết', 'rustlang', 'soạn thảo luận', 'văn luận án', 'presentation slides', 'hi vọng', 'hữu ích', 'học', 'áp dụng', 'trình', 'biên soạn', 'tài liệu', 'khoa học sinh', 'viên thể', 'poster', 'tham gia', 'conferences', 'chuỗi', 'typst', 'typst', 'poster', 'https', 'github', 'com', 'linhduongtuan', 'vnuhcmtypstposter', 'mong', 'mấy', 'chủ đề', 'typst công', 'học tập', 'nghiên cứu', 'nghĩa thân', 'đừng', 'tiếc', '1', 'star', 'repositories', 'ps', 'hi vọng', 'journals', 'chấp typst', '1', 'typsetting', 'word', 'latex', 'soạn thảo', 'manuscripts', 'gửi', 'tập san', 'xuất']"
970,"Dạ em chào mọi người, em đang có một chút khúc mắc trong bài toán binary classification sử dụng dataset này https://github.com/IBM/TabFormer/tree/main/data/credit_card, cụ thể hơn là điểm F1 training của model thấp, nhưng điểm F1 của validation và testing thì lại cao.  Về dataset, đây là dataset về giao dịch thẻ tín dụng, và mục tiêu dự đoán là xem cuộc giao dịch đấy có phải lừa đảo hay không (""Is Fraud?""). Phân bố class này rất mất cân bằng, cụ thể là:
24 triệu cuộc giao dịch
30,000 giao dịch lừa đảo (0.1% of tổng giao dịch)
Sau phần tiền xử lý dữ liệu, em có chia ra 3 sets Training (Cuộc giao dịch trước 2018), Validation (trong 2018) và Testing (sau 2018), với phần phân bố class như sau (0 là giao dịch không lừa đảo, 1 là giao dịch lừa đảo)
Training Data: 
Class 0:  20579668 
Class 1: 25179 
Validation Data: 
Class 0: 1719124 
Class 1: 2491 
Testing Data: 
Class 0: 2058351 
Class 1: 2087
Em hiện tại đang sử dụng model XGBoost để dự đoán, và em có thu lại được một số kết quả như sau:
F1 Score on Training Data : 0.57417479049085 
F1 Score on Testing Data : 0.8719438392641008 
PR AUC score on Training Data : 0.9918559271777408 
PR AUC score on Testing Data : 0.9077624174590952
Training report
precision recall f1-score support

0 1.00 1.00 1.00 20579668
1 0.47 1.00 0.64 25179

accuracy 1.00 20604847
macro avg 0.73 1.00 0.82 20604847
weighted avg 1.00 1.00 1.00 20604847

Test report
precision recall f1-score support

0 1.00 1.00 1.00 2058351
1 0.83 0.93 0.87 2087

accuracy 1.00 2060438
macro avg 0.91 0.96 0.94 2060438
weighted avg 1.00 1.00 1.00 2060438
Như em thấy, thì model không học được tốt trên dữ liệu training nhưng lại có kết quả rất tốt ở trên dữ liệu testing (Và cả ở trên validation set), và bây giờ em cảm thấy hơi khó hiểu về trường hợp như vầy. Em có hiểu model sẽ bị underfit nếu như model không thể học đủ kiến thức từ dữ liệu training, và như vậy thì model sẽ không dự đoán tốt được các dữ liệu tương lai, như dữ liệu test. Còn model sẽ overfit nếu như model học quá khớp với dữ liệu training, và nhớ toàn bộ các thông tin của dữ liệu đó thay vì học cách phân loại, nên vì thế model sẽ không thực hiện tốt việc phân loại. Tuy nhiên ở trường hợp của em, model học kém ở trên dữ liệu training, nhưng lại trả kết quả rất cao cho dữ liệu testing và validation (Em không gửi kèm dữ liệu validation ở đây, nhưng kết quả cũng na ná phần testing).   Vầy nên em muốn hỏi mọi người rằng bài toán của em hiện tại đang gặp vấn đề gì, và ở trong trường hợp nào ạ? Em có gửi kèm thêm một số thông tin đằng sau, gồm loss của model lúc training, learning curve và các ma trận confusion. Em cảm ơn mọi người ạ!
Loss của model (validation_0 là dữ liệu training, validation_1 là dữ liệu testing)
[0] validation_0-aucpr:0.75831 validation_0-logloss:0.67418 validation_1-aucpr:0.17989 validation_1-logloss:0.67417
[10] validation_0-aucpr:0.78157 validation_0-logloss:0.52305 validation_1-aucpr:0.42574 validation_1-logloss:0.51965
[20] validation_0-aucpr:0.83228 validation_0-logloss:0.41181 validation_1-aucpr:0.79299 validation_1-logloss:0.40593
[30] validation_0-aucpr:0.84335 validation_0-logloss:0.32956 validation_1-aucpr:0.82845 validation_1-logloss:0.32171
[40] validation_0-aucpr:0.86026 validation_0-logloss:0.26683 validation_1-aucpr:0.86401 validation_1-logloss:0.25788
[50] validation_0-aucpr:0.87519 validation_0-logloss:0.21770 validation_1-aucpr:0.86298 validation_1-logloss:0.20919
[60] validation_0-aucpr:0.88714 validation_0-logloss:0.17906 validation_1-aucpr:0.86130 validation_1-logloss:0.17034
[70] validation_0-aucpr:0.89531 validation_0-logloss:0.14839 validation_1-aucpr:0.86285 validation_1-logloss:0.14016
[80] validation_0-aucpr:0.89770 validation_0-logloss:0.12463 validation_1-aucpr:0.86329 validation_1-logloss:0.11545
[90] validation_0-aucpr:0.90004 validation_0-logloss:0.10519 validation_1-aucpr:0.86052 validation_1-logloss:0.09647
[100] validation_0-aucpr:0.90534 validation_0-logloss:0.08897 validation_1-aucpr:0.87044 validation_1-logloss:0.07986
[110] validation_0-aucpr:0.91044 validation_0-logloss:0.07617 validation_1-aucpr:0.86994 validation_1-logloss:0.06662
[120] validation_0-aucpr:0.91458 validation_0-logloss:0.06538 validation_1-aucpr:0.86962 validation_1-logloss:0.05589
[130] validation_0-aucpr:0.91902 validation_0-logloss:0.05645 validation_1-aucpr:0.87092 validation_1-logloss:0.04684
[140] validation_0-aucpr:0.92276 validation_0-logloss:0.04895 validation_1-aucpr:0.87258 validation_1-logloss:0.03967
[150] validation_0-aucpr:0.92713 validation_0-logloss:0.04308 validation_1-aucpr:0.87285 validation_1-logloss:0.03377
[160] validation_0-aucpr:0.93179 validation_0-logloss:0.03788 validation_1-aucpr:0.87703 validation_1-logloss:0.02851
[170] validation_0-aucpr:0.93487 validation_0-logloss:0.03361 validation_1-aucpr:0.87967 validation_1-logloss:0.02426
[180] validation_0-aucpr:0.93875 validation_0-logloss:0.03013 validation_1-aucpr:0.88027 validation_1-logloss:0.02093
[190] validation_0-aucpr:0.94333 validation_0-logloss:0.02688 validation_1-aucpr:0.88284 validation_1-logloss:0.01781
[200] validation_0-aucpr:0.94592 validation_0-logloss:0.02454 validation_1-aucpr:0.88497 validation_1-logloss:0.01577
[210] validation_0-aucpr:0.95043 validation_0-logloss:0.02236 validation_1-aucpr:0.89025 validation_1-logloss:0.01363
[220] validation_0-aucpr:0.95464 validation_0-logloss:0.02033 validation_1-aucpr:0.89146 validation_1-logloss:0.01172
[230] validation_0-aucpr:0.95761 validation_0-logloss:0.01880 validation_1-aucpr:0.89327 validation_1-logloss:0.01044
[240] validation_0-aucpr:0.96080 validation_0-logloss:0.01747 validation_1-aucpr:0.89531 validation_1-logloss:0.00912
[250] validation_0-aucpr:0.96417 validation_0-logloss:0.01625 validation_1-aucpr:0.89891 validation_1-logloss:0.00802
[260] validation_0-aucpr:0.96675 validation_0-logloss:0.01519 validation_1-aucpr:0.90279 validation_1-logloss:0.00712
[270] validation_0-aucpr:0.96898 validation_0-logloss:0.01434 validation_1-aucpr:0.90530 validation_1-logloss:0.00645
[280] validation_0-aucpr:0.97143 validation_0-logloss:0.01353 validation_1-aucpr:0.90629 validation_1-logloss:0.00573
[290] validation_0-aucpr:0.97334 validation_0-logloss:0.01284 validation_1-aucpr:0.90836 validation_1-logloss:0.00520
[300] validation_0-aucpr:0.97506 validation_0-logloss:0.01216 validation_1-aucpr:0.90954 validation_1-logloss:0.00468
[310] validation_0-aucpr:0.97660 validation_0-logloss:0.01161 validation_1-aucpr:0.91150 validation_1-logloss:0.00427
[320] validation_0-aucpr:0.97800 validation_0-logloss:0.01108 validation_1-aucpr:0.91411 validation_1-logloss:0.00386
[330] validation_0-aucpr:0.97927 validation_0-logloss:0.01068 validation_1-aucpr:0.91551 validation_1-logloss:0.00361
[340] validation_0-aucpr:0.98054 validation_0-logloss:0.01019 validation_1-aucpr:0.91600 validation_1-logloss:0.00323
[350] validation_0-aucpr:0.98177 validation_0-logloss:0.00977 validation_1-aucpr:0.91776 validation_1-logloss:0.00299
[360] validation_0-aucpr:0.98272 validation_0-logloss:0.00938 validation_1-aucpr:0.92028 validation_1-logloss:0.00275
[370] validation_0-aucpr:0.98370 validation_0-logloss:0.00903 validation_1-aucpr:0.92015 validation_1-logloss:0.00256
[380] validation_0-aucpr:0.98444 validation_0-logloss:0.00877 validation_1-aucpr:0.92196 validation_1-logloss:0.00242
[390] validation_0-aucpr:0.98514 validation_0-logloss:0.00851 validation_1-aucpr:0.92389 validation_1-logloss:0.00229
[400] validation_0-aucpr:0.98580 validation_0-logloss:0.00828 validation_1-aucpr:0.92348 validation_1-logloss:0.00219
[410] validation_0-aucpr:0.98643 validation_0-logloss:0.00801 validation_1-aucpr:0.92514 validation_1-logloss:0.00203
[420] validation_0-aucpr:0.98711 validation_0-logloss:0.00774 validation_1-aucpr:0.92575 validation_1-logloss:0.00189
[430] validation_0-aucpr:0.98774 validation_0-logloss:0.00750 validation_1-aucpr:0.92427 validation_1-logloss:0.00177
[440] validation_0-aucpr:0.98832 validation_0-logloss:0.00725 validation_1-aucpr:0.92531 validation_1-logloss:0.00164
[450] validation_0-aucpr:0.98887 validation_0-logloss:0.00708 validation_1-aucpr:0.92623 validation_1-logloss:0.00160
[460] validation_0-aucpr:0.98931 validation_0-logloss:0.00690 validation_1-aucpr:0.92806 validation_1-logloss:0.00151
[470] validation_0-aucpr:0.98963 validation_0-logloss:0.00674 validation_1-aucpr:0.92860 validation_1-logloss:0.00146
[480] validation_0-aucpr:0.99005 validation_0-logloss:0.00656 validation_1-aucpr:0.92980 validation_1-logloss:0.00140
[490] validation_0-aucpr:0.99038 validation_0-logloss:0.00642 validation_1-aucpr:0.93051 validation_1-logloss:0.00135
[500] validation_0-aucpr:0.99077 validation_0-logloss:0.00628 validation_1-aucpr:0.93089 validation_1-logloss:0.00131
[510] validation_0-aucpr:0.99108 validation_0-logloss:0.00613 validation_1-aucpr:0.93270 validation_1-logloss:0.00126
[520] validation_0-aucpr:0.99138 validation_0-logloss:0.00601 validation_1-aucpr:0.93254 validation_1-logloss:0.00122
[530] validation_0-aucpr:0.99166 validation_0-logloss:0.00590 validation_1-aucpr:0.93199 validation_1-logloss:0.00119
[540] validation_0-aucpr:0.99197 validation_0-logloss:0.00577 validation_1-aucpr:0.93318 validation_1-logloss:0.00116
[550] validation_0-aucpr:0.99224 validation_0-logloss:0.00566 validation_1-aucpr:0.93408 validation_1-logloss:0.00112
[560] validation_0-aucpr:0.99250 validation_0-logloss:0.00554 validation_1-aucpr:0.93327 validation_1-logloss:0.00109
[570] validation_0-aucpr:0.99278 validation_0-logloss:0.00542 validation_1-aucpr:0.93397 validation_1-logloss:0.00106
[580] validation_0-aucpr:0.99300 validation_0-logloss:0.00530 validation_1-aucpr:0.93339 validation_1-logloss:0.00102
[590] validation_0-aucpr:0.99324 validation_0-logloss:0.00521 validation_1-aucpr:0.93372 validation_1-logloss:0.00100
[599] validation_0-aucpr:0.99338 validation_0-logloss:0.00513 validation_1-aucpr:0.93378 validation_1-logloss:0.00099","['#Q&A', '#machine_learning']","['chào', 'chút', 'khúc', 'mắc toán', 'binary', 'classification', 'dataset', 'https', 'github', 'com', 'ibm', 'tabformer', 'tree', 'main', 'data', 'credit_card', 'f1', 'training', 'model', 'f1', 'validation', 'testing', 'dataset', 'dataset', 'giao dịch', 'thẻ tín dụng', 'mục tiêu', 'dự đoán', 'giao dịch', 'đấy', 'lừa đảo', 'is fraud', 'phân bố', 'class', 'cân', '24', 'triệu', 'giao dịch', '30', '000', 'giao dịch', 'lừa đảo', '0', '1', 'of tổng', 'giao dịch', 'tiền liệu', 'chia', '3', 'sets', 'training', 'giao dịch', '2018', 'validation', '2018', 'testing', '2018', 'phân bố', 'class', '0', 'giao dịch', 'lừa đảo', '1', 'giao dịch', 'lừa đảo', 'training', 'data', 'class', '0', '20579668', 'class', '1', '25179', 'validation', 'data', 'class', '0', '1719124', 'class', '1', '2491', 'testing', 'data', 'class', '0', '2058351', 'class', '1', '2087', 'model', 'xgboost', 'dự đoán', 'thu', 'kết', 'f1', 'score', 'on', 'training', 'data', '0', '57417479049085', 'f1', 'score', 'on', 'testing', 'data', '0', '8719438392641008', 'pr', 'auc', 'score', 'on', 'training', 'data', '0', '9918559271777408', 'pr', 'auc', 'score', 'on', 'testing', 'data', '0', '9077624174590952', 'training', 'report', 'precision', 'recall', 'f1score', 'support', '0', '1', '00', '1', '00', '1', '00', '20579668', '1', '0', '47', '1', '00', '0', '64', '25179', 'accuracy', '1', '00', '20604847', 'macro', 'avg', '0', '73', '1', '00', '0', '82', '20604847', 'weighted', 'avg', '1', '00', '1', '00', '1', '00', '20604847', 'test', 'report', 'precision', 'recall', 'f1score', 'support', '0', '1', '00', '1', '00', '1', '00', '2058351', '1', '0', '83', '0', '93', '0', '87', '2087', 'accuracy', '1', '00', '2060438', 'macro', 'avg', '0', '91', '0', '96', '0', '94', '2060438', 'weighted', 'avg', '1', '00', '1', '00', '1', '00', '2060438', 'model', 'học liệu', 'training', 'kết liệu', 'testing', 'validation', 'set', 'hơi', 'trường hợp', 'vầy', 'model', 'underfit', 'model thể', 'học', 'kiến thức liệu', 'training', 'model', 'dự đoán', 'liệu', 'tương lai', 'liệu', 'test', 'model', 'overfit', 'model', 'học', 'khớp liệu', 'training', 'toàn', 'thông liệu', 'thay', 'học', 'phân model', 'phân nhiên', 'trường hợp', 'model học', 'kém liệu', 'training', 'kết liệu', 'testing', 'validation', 'gửi', 'kèm liệu', 'validation kết', 'na ná', 'testing', 'vầy toán', 'trường hợp', 'gửi', 'kèm', 'thông đằng', 'loss', 'model', 'training', 'learning', 'curve', 'ma trận', 'confusion', 'loss', 'model', 'validation_0 liệu', 'training', 'validation_1 liệu', 'testing', '0', 'validation_0aucpr', '0', '75831', 'validation_0logloss', '0', '67418', 'validation_1aucpr', '0', '17989', 'validation_1logloss', '0', '67417', '10', 'validation_0aucpr', '0', '78157', 'validation_0logloss', '0', '52305', 'validation_1aucpr', '0', '42574', 'validation_1logloss', '0', '51965', '20', 'validation_0aucpr', '0', '83228', 'validation_0logloss', '0', '41181', 'validation_1aucpr', '0', '79299', 'validation_1logloss', '0', '40593', '30', 'validation_0aucpr', '0', '84335', 'validation_0logloss', '0', '32956', 'validation_1aucpr', '0', '82845', 'validation_1logloss', '0', '32171', '40', 'validation_0aucpr', '0', '86026', 'validation_0logloss', '0', '26683', 'validation_1aucpr', '0', '86401', 'validation_1logloss', '0', '25788', '50', 'validation_0aucpr', '0', '87519', 'validation_0logloss', '0', '21770', 'validation_1aucpr', '0', '86298', 'validation_1logloss', '0', '20919', '60', 'validation_0aucpr', '0', '88714', 'validation_0logloss', '0', '17906', 'validation_1aucpr', '0', '86130', 'validation_1logloss', '0', '17034', '70', 'validation_0aucpr', '0', '89531', 'validation_0logloss', '0', '14839', 'validation_1aucpr', '0', '86285', 'validation_1logloss', '0', '14016', '80', 'validation_0aucpr', '0', '89770', 'validation_0logloss', '0', '12463', 'validation_1aucpr', '0', '86329', 'validation_1logloss', '0', '11545', '90', 'validation_0aucpr', '0', '90004', 'validation_0logloss', '0', '10519', 'validation_1aucpr', '0', '86052', 'validation_1logloss', '0', '09647', '100', 'validation_0aucpr', '0', '90534', 'validation_0logloss', '0', '08897', 'validation_1aucpr', '0', '87044', 'validation_1logloss', '0', '07986', '110', 'validation_0aucpr', '0', '91044', 'validation_0logloss', '0', '07617', 'validation_1aucpr', '0', '86994', 'validation_1logloss', '0', '06662', '120', 'validation_0aucpr', '0', '91458', 'validation_0logloss', '0', '06538', 'validation_1aucpr', '0', '86962', 'validation_1logloss', '0', '05589', '130', 'validation_0aucpr', '0', '91902', 'validation_0logloss', '0', '05645', 'validation_1aucpr', '0', '87092', 'validation_1logloss', '0', '04684', '140', 'validation_0aucpr', '0', '92276', 'validation_0logloss', '0', '04895', 'validation_1aucpr', '0', '87258', 'validation_1logloss', '0', '03967', '150', 'validation_0aucpr', '0', '92713', 'validation_0logloss', '0', '04308', 'validation_1aucpr', '0', '87285', 'validation_1logloss', '0', '03377', '160', 'validation_0aucpr', '0', '93179', 'validation_0logloss', '0', '03788', 'validation_1aucpr', '0', '87703', 'validation_1logloss', '0', '02851', '170', 'validation_0aucpr', '0', '93487', 'validation_0logloss', '0', '03361', 'validation_1aucpr', '0', '87967', 'validation_1logloss', '0', '02426', '180', 'validation_0aucpr', '0', '93875', 'validation_0logloss', '0', '03013', 'validation_1aucpr', '0', '88027', 'validation_1logloss', '0', '02093', '190', 'validation_0aucpr', '0', '94333', 'validation_0logloss', '0', '02688', 'validation_1aucpr', '0', '88284', 'validation_1logloss', '0', '01781', '200', 'validation_0aucpr', '0', '94592', 'validation_0logloss', '0', '02454', 'validation_1aucpr', '0', '88497', 'validation_1logloss', '0', '01577', '210', 'validation_0aucpr', '0', '95043', 'validation_0logloss', '0', '02236', 'validation_1aucpr', '0', '89025', 'validation_1logloss', '0', '01363', '220', 'validation_0aucpr', '0', '95464', 'validation_0logloss', '0', '02033', 'validation_1aucpr', '0', '89146', 'validation_1logloss', '0', '01172', '230', 'validation_0aucpr', '0', '95761', 'validation_0logloss', '0', '01880', 'validation_1aucpr', '0', '89327', 'validation_1logloss', '0', '01044', '240', 'validation_0aucpr', '0', '96080', 'validation_0logloss', '0', '01747', 'validation_1aucpr', '0', '89531', 'validation_1logloss', '0', '00912', '250', 'validation_0aucpr', '0', '96417', 'validation_0logloss', '0', '01625', 'validation_1aucpr', '0', '89891', 'validation_1logloss', '0', '00802', '260', 'validation_0aucpr', '0', '96675', 'validation_0logloss', '0', '01519', 'validation_1aucpr', '0', '90279', 'validation_1logloss', '0', '00712', '270', 'validation_0aucpr', '0', '96898', 'validation_0logloss', '0', '01434', 'validation_1aucpr', '0', '90530', 'validation_1logloss', '0', '00645', '280', 'validation_0aucpr', '0', '97143', 'validation_0logloss', '0', '01353', 'validation_1aucpr', '0', '90629', 'validation_1logloss', '0', '00573', '290', 'validation_0aucpr', '0', '97334', 'validation_0logloss', '0', '01284', 'validation_1aucpr', '0', '90836', 'validation_1logloss', '0', '00520', '300', 'validation_0aucpr', '0', '97506', 'validation_0logloss', '0', '01216', 'validation_1aucpr', '0', '90954', 'validation_1logloss', '0', '00468', '310', 'validation_0aucpr', '0', '97660', 'validation_0logloss', '0', '01161', 'validation_1aucpr', '0', '91150', 'validation_1logloss', '0', '00427', '320', 'validation_0aucpr', '0', '97800', 'validation_0logloss', '0', '01108', 'validation_1aucpr', '0', '91411', 'validation_1logloss', '0', '00386', '330', 'validation_0aucpr', '0', '97927', 'validation_0logloss', '0', '01068', 'validation_1aucpr', '0', '91551', 'validation_1logloss', '0', '00361', '340', 'validation_0aucpr', '0', '98054', 'validation_0logloss', '0', '01019', 'validation_1aucpr', '0', '91600', 'validation_1logloss', '0', '00323', '350', 'validation_0aucpr', '0', '98177', 'validation_0logloss', '0', '00977', 'validation_1aucpr', '0', '91776', 'validation_1logloss', '0', '00299', '360', 'validation_0aucpr', '0', '98272', 'validation_0logloss', '0', '00938', 'validation_1aucpr', '0', '92028', 'validation_1logloss', '0', '00275', '370', 'validation_0aucpr', '0', '98370', 'validation_0logloss', '0', '00903', 'validation_1aucpr', '0', '92015', 'validation_1logloss', '0', '00256', '380', 'validation_0aucpr', '0', '98444', 'validation_0logloss', '0', '00877', 'validation_1aucpr', '0', '92196', 'validation_1logloss', '0', '00242', '390', 'validation_0aucpr', '0', '98514', 'validation_0logloss', '0', '00851', 'validation_1aucpr', '0', '92389', 'validation_1logloss', '0', '00229', '400', 'validation_0aucpr', '0', '98580', 'validation_0logloss', '0', '00828', 'validation_1aucpr', '0', '92348', 'validation_1logloss', '0', '00219', '410', 'validation_0aucpr', '0', '98643', 'validation_0logloss', '0', '00801', 'validation_1aucpr', '0', '92514', 'validation_1logloss', '0', '00203', '420', 'validation_0aucpr', '0', '98711', 'validation_0logloss', '0', '00774', 'validation_1aucpr', '0', '92575', 'validation_1logloss', '0', '00189', '430', 'validation_0aucpr', '0', '98774', 'validation_0logloss', '0', '00750', 'validation_1aucpr', '0', '92427', 'validation_1logloss', '0', '00177', '440', 'validation_0aucpr', '0', '98832', 'validation_0logloss', '0', '00725', 'validation_1aucpr', '0', '92531', 'validation_1logloss', '0', '00164', '450', 'validation_0aucpr', '0', '98887', 'validation_0logloss', '0', '00708', 'validation_1aucpr', '0', '92623', 'validation_1logloss', '0', '00160', '460', 'validation_0aucpr', '0', '98931', 'validation_0logloss', '0', '00690', 'validation_1aucpr', '0', '92806', 'validation_1logloss', '0', '00151', '470', 'validation_0aucpr', '0', '98963', 'validation_0logloss', '0', '00674', 'validation_1aucpr', '0', '92860', 'validation_1logloss', '0', '00146', '480', 'validation_0aucpr', '0', '99005', 'validation_0logloss', '0', '00656', 'validation_1aucpr', '0', '92980', 'validation_1logloss', '0', '00140', '490', 'validation_0aucpr', '0', '99038', 'validation_0logloss', '0', '00642', 'validation_1aucpr', '0', '93051', 'validation_1logloss', '0', '00135', '500', 'validation_0aucpr', '0', '99077', 'validation_0logloss', '0', '00628', 'validation_1aucpr', '0', '93089', 'validation_1logloss', '0', '00131', '510', 'validation_0aucpr', '0', '99108', 'validation_0logloss', '0', '00613', 'validation_1aucpr', '0', '93270', 'validation_1logloss', '0', '00126', '520', 'validation_0aucpr', '0', '99138', 'validation_0logloss', '0', '00601', 'validation_1aucpr', '0', '93254', 'validation_1logloss', '0', '00122', '530', 'validation_0aucpr', '0', '99166', 'validation_0logloss', '0', '00590', 'validation_1aucpr', '0', '93199', 'validation_1logloss', '0', '00119', '540', 'validation_0aucpr', '0', '99197', 'validation_0logloss', '0', '00577', 'validation_1aucpr', '0', '93318', 'validation_1logloss', '0', '00116', '550', 'validation_0aucpr', '0', '99224', 'validation_0logloss', '0', '00566', 'validation_1aucpr', '0', '93408', 'validation_1logloss', '0', '00112', '560', 'validation_0aucpr', '0', '99250', 'validation_0logloss', '0', '00554', 'validation_1aucpr', '0', '93327', 'validation_1logloss', '0', '00109', '570', 'validation_0aucpr', '0', '99278', 'validation_0logloss', '0', '00542', 'validation_1aucpr', '0', '93397', 'validation_1logloss', '0', '00106', '580', 'validation_0aucpr', '0', '99300', 'validation_0logloss', '0', '00530', 'validation_1aucpr', '0', '93339', 'validation_1logloss', '0', '00102', '590', 'validation_0aucpr', '0', '99324', 'validation_0logloss', '0', '00521', 'validation_1aucpr', '0', '93372', 'validation_1logloss', '0', '00100', '599', 'validation_0aucpr', '0', '99338', 'validation_0logloss', '0', '00513', 'validation_1aucpr', '0', '93378', 'validation_1logloss', '0', '00099']"
971,"Chào mọi người, sau nhiều tháng chậm trễ, em cũng đã hoàn thành đề tài OCR cho chữ Hán-Nôm mà đã được mọi người góp ý qua trước đây.  
Link bài post cũ: https://www.facebook.com/groups/machinelearningcoban/posts/1423658951424841 
Hiện tại, nhóm em đã xây dựng thành công 1 bộ dữ liệu OCR dành cho các tài liệu lịch sử cũ được viết tay bằng chữ Hán-Nôm với 2953 Page và 38318 Patch, phục vụ cho cả 2 bài toán Text Detection và Text Recognition. Bộ dữ liệu dựa trên 3 tác phẩm lớn gồm: 
- Trọn bộ 24 quyển của Đại Việt Sử Ký Toàn Thư. 
- Truyện Kiều các bản năm 1866, 1871, và 1872. 
- Lục Vân Tiên.  
Ngoài ra, em cũng đã cài đặt và thử nghiệm các mô hình theo sequence level thay vì character level như các công trình trước, trong đó:
- Text Detection: sử dụng 2 mô hình đại diện cho 2 hướng tiếp cận Regression-based và Segmentation-based, được tham khảo từ cuộc thi về Scene Text Detection trên bộ dữ liệu ICDAR 2015.
- Text Recognition: giải quyết theo 4 hướng tiếp cận khác nhau cùng với 2 phương pháp huấn luyện gồm Fine-tuning trên 1 bộ dữ liệu Synthetic với hơn 100k Patch và Retraining từ đầu trên dữ liệu thật để so sánh kết quả với khi Fine-tuning.
GitHub: https://github.com/ds4v/NomNaOCR
Dataset: https://www.kaggle.com/datasets/quandang/nomnaocr 
Rất mong nhận được các góp ý từ mọi người để em có thể học hỏi cũng như để cải thiện thêm cho project trong tương lai.
 — với Nguyễn Đức Duy Anh.","['#sharing', '#cv', '#deep_learning']","['chào', 'chậm trễ', 'hoàn thành', 'đề tài', 'ocr', 'chữ', 'hánnôm', 'góp', 'link', 'post', 'cũ', 'xây dựng', 'thành công', '1', 'liệu', 'ocr', 'tài liệu', 'lịch sử', 'cũ', 'viết', 'chữ', 'hánnôm', '2953', 'page', '38318', 'patch', 'phục vụ', '2', 'toán', 'text', 'detection', 'text', 'recognition liệu', 'dựa', '3', 'tác phẩm', 'trọn', '24', 'quyển', 'đại việt', 'sử ký', 'toàn', 'thư', 'truyện kiều', '1866', '1871', '1872', 'lục vân', 'tiên cài', 'thử nghiệm', 'mô hình', 'sequence', 'level', 'thay', 'character', 'level', 'công trình', 'text', 'detection', '2', 'mô hình', 'đại diện', '2', 'hướng', 'tiếp cận', 'regressionbased', 'segmentationbased', 'tham khảo', 'thi', 'scene', 'text', 'detection liệu', 'icdar', '2015', 'text', 'recognition', 'giải quyết', '4', 'hướng', 'tiếp cận', '2', 'phương pháp', 'huấn luyện', 'finetuning', '1', 'liệu', 'synthetic', '100', 'k', 'patch', 'retraining', 'đầu liệu', 'sánh kết', 'finetuning', 'github', 'dataset', 'mong', 'góp thể', 'học', 'cải thiện', 'project', 'tương lai', 'nguyễn đức']"
972,Nghề của tương lai: #PromptEngineering,['#sharing'],"['nghề', 'tương lai']"
973,"Chào các anh,chị trong forum.
Em hiện đang học về GIS (hệ thống thông tin địa lý). Các anh chị cho em hỏi liệu Machine Learning có áp dụng được vào GIS không ạ và áp dụng như thế nào vậy ạ.
Em cảm ơn mọi người ạ🥰🥰","['#Q&A', '#machine_learning']","['chào', 'forum', 'hiện', 'học', 'gis', 'hệ thống', 'thông', 'địa lý liệu', 'machine learning', 'áp dụng', 'gis', 'áp dụng']"
974,"Xin chào mọi người,
Hè này em tính đầu tư thời gian để học Machine Learning. Trên Coursera có hai khóa Machine Learning tốt nhất đó là khóa Machine Learning Specialization của DeepLearning.ai và khóa Machine Learning Professional Certificate của IBM.
Mọi người cho em xin ý kiến là khóa nào là khóa tốt nhất và chuyên sâu nhất.
Em không cần khóa beginner-friendly, em chỉ cần khóa nào dạy đầy đủ nhất.
Cảm ơn mọi người nhiều.","['#Q&A', '#machine_learning']","['chào hè', 'đầu tư', 'học', 'machine', 'learning', 'coursera', 'hai', 'khóa', 'machine', 'learning', 'khóa', 'machine', 'learning', 'specialization', 'khóa', 'machine', 'learning', 'professional', 'certificate', 'ibm kiến', 'khóa', 'khóa', 'chuyên sâu', 'khóa', 'beginnerfriendly', 'khóa', 'dạy']"
975,Chuyện là em đang làm 1 project về image classfication trên mobile. Em có quantizition model xuống int8. Em có xuất output thì nó ra 1 mảng giá trí như trong hình. Em muốn convert nó thành phần trăm tỉ lệ chính xác. Lên mạng kiếm tài liệu nhưng không biết như thế nào. Anh chị nào biết chỉ em với ạ. Em cám ơn.,"['#Q&A', '#cv']","['1', 'project', 'image', 'classfication', 'mobile', 'quantizition', 'model', 'int8', 'xuất output', '1', 'mảng', 'giá trí', 'hình convert', 'thành', 'trăm', 'tỉ lệ', 'xác mạng', 'kiếm', 'tài liệu', 'cám ơn']"
976,"Chào các bạn,
Tuần trước mình nhận được một email rất dài nhờ tư vấn cho một dự án tiên đoán mức độ ung thư vú trong tương lai cho phụ nữ Việt Nam. Mình đã nói chuyện với team và thấy rằng đây là một dự án ý nghĩa, mình đã nhận lời kết nối dự án với cộng đồng.
Hiện nhóm đã có khá nhiều dữ liệu, cả về ảnh lẫn dữ liệu bảng, có chuyên gia về mặt y tế và có các bạn lập trình viên hỗ trợ. Tuy nhiên vẫn còn nhiều điểm có thể cải thiện bằng cả computer vision và data science. Theo mình đây cũng là một cơ hội tốt cho các bạn nghiên cứu về ML cho Y Sinh được tiếp cận nguồn dữ liệu tốt và làm với một dự án thực tế.
Vậy nên mình viết post này giúp kết nối các bạn có kinh nghiệm trong lĩnh vực này với dự án. Thông tin chi tiết về dự án và cách liên hệ hợp tác được cho trong comment.
Cảm ơn các bạn.","['#sharing', '#machine_learning']","['chào', 'tuần', 'email', 'tư vấn', 'dự án', 'tiên đoán', 'độ', 'ung thư', 'vú', 'tương lai', 'phụ nữ', 'việt nam', 'team', 'dự án', 'nghĩa kết nối', 'dự án', 'cộng đồng', 'hiện liệu', 'ảnh', 'lẫn liệu', 'bảng', 'chuyên gia', 'mặt', 'y tế', 'lập trình', 'viên nhiên thể', 'cải thiện', 'computer', 'vision', 'data', 'science hội', 'nghiên cứu', 'ml', 'y sinh', 'tiếp cận liệu', 'dự án', 'viết', 'post', 'giúp', 'kết nối', 'kinh nghiệm', 'lĩnh vực', 'dự án', 'thông', 'chi tiết', 'dự án', 'liên hệ', 'hợp tác', 'comment']"
977,"Mấy ngày trước mình có tạo ra template để viết luận văn/luận án sử dụng Typst tại đây https://github.com/linhduongtuan/BKHN-Thesis_template_typst.
Hôm nay, mình xin gửi đến các bạn 1 template khác với mục đích viết Slides để báo cáo. Xin tham khảo tại đây: https://github.com/linhduongtuan/DTU-typst-presentation
Hi vọng với combo thư viện này sẽ giúp chúng ta có thêm công cụ để soạn thảo văn bản và bài thuyết trình một cách hiệu quả.
Chúc các bạn cuối tuần vui vẻ.
Ps. Nếu các bạn thấy repositories của mình có ích, xin đừng tiếc một Star cho mỗi thư viện nói trên.
Trân trọng",['#sharing'],"['mấy', 'template', 'viết luận', 'văn luận án', 'typst', 'https', 'github', 'com', 'linhduongtuan', 'bkhnthesis_template_typst', 'hôm', 'gửi', '1', 'template', 'mục đích', 'viết', 'slides', 'báo cáo', 'tham khảo', 'hi vọng', 'combo', 'thư viện', 'giúp', 'ta', 'công cụ', 'soạn thảo', 'văn thuyết', 'trình hiệu', 'chúc', 'tuần', 'vui vẻ', 'ps', 'repositories ích', 'đừng', 'tiếc', 'star', 'thư viện', 'trân trọng']"
978,Xin chào các anh chị và các bạn. Mình làm về data ở Tây Ban Nha. Mình muốn join vào dự án nào đó ở VN mà có liên quan tới Crypto Curency thì tốt. Mình không yêu cầu trả lương chỉ mong được học hỏi từ các anh chị và các bạn.,"['#sharing', '#data']","['chào', 'data tây', 'ban nha', 'join', 'dự án', 'vn', 'crypto', 'curency', 'lương', 'mong', 'học']"
979,"Em chào anh chị trong nhóm ạ. Hiện em đã tốt nghiệp Đại học Bách Khoa Hà Nội, em đang tìm việc Intern/fresher về Al tại Hà Nội. Không biết anh/chị ở công ty nào có còn open cho vị trí Intern/fresher không ạ?","['#Q&A', '#machine_learning']","['chào', 'hiện nghiệp', 'đại học', 'bách khoa', 'hà nội', 'intern', 'fresher al', 'hà nội', 'công ty', 'open', 'intern', 'fresher']"
980,"Chào mọi người em đang tìm hiểu về chatbot tiếng việt sử dụng Underthesea. Nhưng em thấy ít tài liệu về đề tài này, mọi người có tài liệu hoặc code liên quan cho em xin tham khảo với ạ. Em cảm ơn","['#Q&A', '#nlp']","['chào chatbot', 'tiếng', 'việt', 'underthesea', 'tài liệu', 'đề tài', 'tài liệu', 'code', 'tham khảo']"
981,Một bài báo của DeepMind sử dụng AlphaDev tìm ra được thuật toán sắp xếp hiệu quả hơn. Chi tiết bài báo:,"['#sharing', '#machine_learning']","['báo', 'deepmind', 'alphadev thuật', 'toán', 'xếp hiệu', 'chi tiết', 'báo']"
982,"*** Câu hỏi phỏng vấn ***
Em là AI engineer, kinh nghiệm 2.5 năm, em sắp đi phỏng vấn mà tại đó giờ em làm 1 công ty, chủ yếu làm computer vision nên hơi tự ti 1 tí.
Mỗi người đi qua thấy post của em có thể cho em 1 vài câu hỏi phỏng vấn liên quan hoặc 1 bài toán gì mọi người được hỏi để giải quyết nhanh trong cuộc phỏng vấn được ko ạ?
*** Những kĩ năng của em
+ Pytorch, Tensoflow
+ Mô hình Yolov7, mask rcnn, efficientnet, efficientdet,...
+ Project thì chủ yếu liên quan đến defect detection, classification, segmentation, theo dõi đối tượng bằng deepsort.","['#Q&A', '#cv', '#machine_learning']","['vấn', 'engineer', 'kinh nghiệm', '2', '5', 'đi vấn', '1', 'công ty', 'chủ yếu', 'computer', 'vision', 'hơi ti', '1', 'tí', 'đi', 'post thể', '1', 'vấn', '1', 'toán', 'giải quyết', 'vấn ko', 'kĩ năng', 'pytorch tensoflow', 'mô hình', 'yolov7', 'mask', 'rcnn', 'efficientnet', 'efficientdet project', 'chủ yếu', 'defect', 'detection', 'classification', 'segmentation dõi', 'đối tượng', 'deepsort']"
983,"Cho hỏi có ai biết trang opnai.net ko? Mình thấy nó trả lời câu hỏi cũng giống chat gpt, ko biết có phải trang mạo danh nhằm mục đích gì ở người dùng ko hay là trang này muốn giúp cho người việt được dùng chatgpt tại vn?","['#Q&A', '#nlp']","['trang', 'ko', 'chat', 'gpt', 'ko', 'trang mạo', 'danh mục đích', 'ko trang', 'giúp', 'việt', 'chatgpt', 'vn']"
984,Tool cho ae dùng AI chỉnh sửa ảnh.,"['#sharing', '#machine_learning']","['tool', 'ae', 'chỉnh sửa', 'ảnh']"
985,"Chắc các bạn trong forum này nhiều người sử dụng LaTeX/Overleaf để soạn thảo văn bản, luận văn, bài báo,... Mặc dù cộng đồng LaTex rất mạnh, nhưng mình rất ghét khi muốn xuất file phải bấm `compile`, chờ nó quay khá lâu, rồi lỗi (nếu có) tương đối khó đọc. Gần đây ngôn ngữ Rust nổi lên thay thế C/C++, và rồi Typst (https://github.com/typst/typst) và (online ver. tương tự Overleaf https://typst.app/) được phát triển như là trình biên soạn mới, và mình nghĩ Typst tuy còn non trẻ nhưng nó sẽ có chỗ đứng của riêng nó. Typst xuất file pdf gần như theo thời gian thật mà không cần compile. Về syntax của Typst tương đối dễ đọc. Vậy nên mình thử tạo ra 1 template cho việc biên soạn luận văn sử dụng Typst tại đây https://github.com/linhduongtuan/BKHN-Thesis_template_typst. Hi vọng, với template này các bạn có thể từng bước học cách sử dụng Typst và xa hơn là học Rust.
Chúc mọi người buổi tối vui vẻ!
Nếu các bạn thấy repository của mình thú vị, xin đừng tiếc 1 Star cho nó nhé. Trân trọng cảm ơn.",['#sharing'],"['forum', 'latex', 'overleaf', 'soạn thảo', 'văn luận', 'văn báo', 'mặc', 'cộng đồng', 'latex', 'ghét', 'xuất file', 'bấm', 'compile', 'chờ', 'lỗi', 'tương đối', 'đọc', 'ngôn ngữ', 'rust', 'nổi', 'thay', 'c', 'c', 'typst', 'online', 'ver', 'tương overleaf', 'https', 'typst app', 'phát triển', 'trình', 'biên soạn', 'typst', 'non trẻ', 'chỗ đứng', 'typst', 'xuất', 'file', 'pdf', 'compile', 'syntax', 'typst', 'tương đối', 'đọc', 'thử', '1', 'template biên', 'soạn luận', 'văn typst', 'https', 'github', 'com', 'linhduongtuan', 'bkhnthesis_template_typst', 'hi vọng', 'template thể', 'học', 'typst học', 'rust chúc', 'tối', 'vui vẻ', 'repository', 'thú vị', 'đừng', 'tiếc', '1', 'star', 'trân trọng']"
986,"Xin giới thiệu với mọi người một danh sách dài tổng hợp những textbooks xuất sắc về các chủ đề từ Machine Learning, Statistical Learning, Optimization, Optimal Transport, Algebraic Statisics, etc được chia sẻ miễn phí đến với cộng đồng bởi chính những tác giả viết ra những cuốn sách này, với tên tuổi lớn hàng đầu trong giới khoa học như Sutton (RL), Szeliski (CompVis), Hastie (Stats), Villani (OT)
Danh sách được tổng hợp và chia sẻ bởi Dr. Frank Nielsen: https://franknielsen.github.io/Books/CuratedBookLists.html","['#sharing', '#machine_learning', '#math']","['giới thiệu', 'danh sách', 'tổng hợp', 'textbooks', 'xuất sắc', 'chủ đề', 'machine', 'learning', 'statistical', 'learning', 'optimization', 'optimal', 'transport', 'algebraic', 'statisics', 'etc', 'miễn phí', 'cộng đồng', 'tác giả', 'viết', 'sách', 'hàng đầu giới', 'khoa học', 'sutton', 'rl', 'szeliski', 'compvis', 'hastie', 'stats', 'villani', 'ot', 'danh sách', 'tổng hợp', 'dr', 'frank', 'nielsen']"
987,"Chào mọi người, mình đang scan khả năng sử dụng YoLo vào những ứng dụng trong nghiên cứu của mình tại Nauy. Cụ thể là kiểu như hình và link phía dưới trong nhưng là monitor các hạt rắn trong lò phản ứng của mình thông qua camera.
Trong nhóm này có ACE nào đã làm với YoLo không cho mình xin chút ít kinh nghiệm/Input, comment hoặc ib mình sẽ liên lạc trao đổi thêm nhé.
Cảm ơn mọi
https://www.youtube.com/watch?v=dm3FcR_WrvQ","['#Q&A', '#cv', '#deep_learning']","['chào scan', 'khả năng', 'yolo', 'ứng dụng', 'nghiên cứu', 'nauy', 'kiểu', 'hình link', 'monitor', 'hạt', 'rắn', 'lò', 'phản ứng', 'thông camera', 'ace', 'yolo', 'chút', 'kinh nghiệm', 'input', 'comment', 'ib', 'liên lạc', 'trao đổi']"
988,"Xin chào mọi người
Mình đang muốn tìm học về AI nhưng chưa biết bắt đầu từ đâu và cần học những gì
Mong muốn của mình là có thể sử dụng AI áp dụng vào lĩnh vực phần mềm,các tool hỗ trợ trong lĩnh vực phát triển web , app
Mong mọi người tư vấn lộ trình ạ","['#Q&A', '#machine_learning']","['chào học', 'học', 'mong thể', 'áp dụng', 'lĩnh vực', 'mềm tool', 'lĩnh vực', 'phát triển', 'web', 'app mong', 'tư vấn', 'lộ trình']"
989,"Chào mọi người em có 2 câu hỏi này về universal approximation theorem:
1/ MLP có thể xấp xỉ skip connection và recurrent connection không?
2/ CNN có thể được cài đặt bằng MLP, nhưng cũng có thể coi MLP là CNN với kernel spatial size bằng 1x1. Vậy CNN và MLP cái nào ""tổng quát"" hơn? Nếu CNN ""tổng quát"" hơn, nó có riêng cho mình một approximation theorem không? Tương tự, RNN, mạng có skip connection, v.v. có approximation theorem cho riêng nó không?
Cảm ơn mọi người.","['#Q&A', '#deep_learning']","['chào', '2', 'universal', 'approximation', 'theorem', '1', 'mlp thể', 'xấp xỉ', 'skip', 'connection', 'recurrent', 'connection', '2', 'cnn thể', 'cài', 'mlp thể', 'coi', 'mlp', 'cnn', 'kernel', 'spatial', 'size', '1x1', 'cnn', 'mlp', 'tổng quát', 'cnn', 'tổng quát', 'approximation', 'theorem', 'tương rnn', 'mạng', 'skip', 'connection', 'v', 'v', 'approximation', 'theorem']"
990,"Em chào anh chị trong nhóm ạ. Hiện em đã tốt nghiệp Đại học Bách Khoa Hà Nội, em đang tìm việc Intern/fresher về Machine Learning/AI/Deep Learning tại Hà Nội. Không biết anh/chị ở công ty nào có còn open cho vị trí Intern/fresher không ạ? Em sẽ chủ động inbox gửi CV ạ.","['#Q&A', '#machine_learning']","['chào', 'hiện nghiệp', 'đại học', 'bách khoa', 'hà nội', 'intern', 'fresher', 'machine', 'learning', 'deep', 'learning', 'hà nội', 'công ty', 'open', 'intern', 'fresher', 'chủ động', 'inbox', 'gửi', 'cv']"
991,"Chào mọi người, mình xin giới thiệu chuỗi seminar thú vị về việc cung cấp nền tảng về việc triển khai ML models với những kiến thức trong industry.
1. Seminar 1 (5/6): MLOps Marathon Sample Solution
2. Seminar 2 (6/6): Fundamental Series: Linux basics
3. Seminar 3 (7/6): Fundamental Series: Git, Github and Github actions
4. Seminar 4 (8/6): Containerization and Orchestration
5. Seminar 5 (13/6): WebAPI, FastAPI and NGINX
6. Seminar 6 (14/6): Data Drift and Solutions","['#sharing', '#machine_learning']","['chào', 'giới thiệu', 'chuỗi', 'seminar', 'thú vị', 'cung tảng', 'triển khai', 'ml models', 'kiến thức', 'industry', '1', 'seminar', '1', '5', '6', 'mlops', 'marathon', 'sample', 'solution', '2', 'seminar', '2', '6', '6', 'fundamental', 'series', 'linux', 'basics', '3', 'seminar', '3', '7', '6', 'fundamental', 'series', 'git github', 'and github', 'actions', '4', 'seminar', '4', '8', '6', 'containerization', 'and orchestration', '5', 'seminar', '5', '13', '6', 'webapi fastapi', 'and nginx', '6', 'seminar', '6', '14', '6', 'data', 'drift and', 'solutions']"
992,"Xin chào các anh em, hiện tại em đang gặp vấn đề về độ chính xác khi sử dụng Python để đọc kết quả trên mô hình ONNX. Cụ thể hơn, trên môi trường Visual Studio, em sử dụng mô hình tự động (AutoML) để phân lớp hình ảnh (Image Classification) của ML.NET, đầu vào là 7 lớp. Mô hình của AutoML sử dụng huấn luyện là DNN + ResNeXt-50. Kết quả đạt được là 100% độ chính xác, em có thử 10 hình ảnh test cho mỗi lớp, kết quả đều đúng. Tuy nhiên khi sử dụng mô hình ONNX để sử dụng trên môi trường Python của Google Colab. Kết quả đạt được là hoàn toàn không chính xác. Cụ thể, khi em đưa bất cứ hình ảnh nào vào, kết quả cũng chỉ đạt được là duy nhất. Em đã thử chuyển mô hình onnx sang Tensorflow bằng thư viện onnx2tf nhưng cũng chỉ cho ra một kết quả duy nhất. Em hi vọng mọi người có thể gợi ý giúp em có cách nào có kết quả mô hình ONNX đúng nhất. Dưới đây là link post issue trên Github, tuy vậy cũng khá lâu rồi chưa có cách nào cải thiện được vấn đề này cả.
https://github.com/microsoft/onnxruntime/issues/16001#issuecomment-1554819072
Cảm ơn mọi người đã xem bài và mong mọi người giúp đỡ em.","['#Q&A', '#machine_learning', '#python']","['chào độ', 'xác python', 'đọc', 'kết', 'mô hình', 'onnx', 'môi trường', 'visual studio', 'mô hình', 'động', 'automl', 'phân lớp', 'hình ảnh', 'image', 'classification', 'đầu', '7', 'lớp', 'mô hình', 'automl', 'huấn luyện', 'dnn', 'resnext50 kết', '100', 'độ', 'xác', 'thử', '10', 'hình ảnh', 'test', 'lớp', 'kết nhiên', 'mô hình', 'onnx', 'môi trường', 'python', 'google', 'colab kết', 'xác', 'hình ảnh', 'kết thử', 'mô hình', 'onnx', 'tensorflow', 'thư viện', 'onnx2tf kết', 'hi vọng thể', 'gợi', 'giúp', 'kết', 'mô hình', 'onnx', 'link', 'post', 'issue', 'github', 'cải thiện', 'mong', 'giúp đỡ']"
993,"Dạ em chào mấy Thầy, Cô, Anh, Chị.
Em là thành viên mới của nhóm, hiện tại em đang bắt đầu nghiên cứu học về Machine Learning. Cho em hỏi Thầy, Cô, Anh, Chị nào có Lộ Trình Học hay Website để học Machine Learning cho em tham khảo với được không ạ.
Em cảm ơn các Thầy, Cô, Anh, Chị ạ 🥰","['#Q&A', '#machine_learning']","['chào', 'mấy', 'thầy', 'thành viên', 'nghiên cứu', 'học', 'machine', 'learning', 'thầy', 'lộ trình', 'học', 'website', 'học', 'machine', 'learning', 'tham khảo', 'thầy']"
994,"Xin chào, có thầy nào làm mentor data engineer hoặc machine learning theo project. Em xin theo học với.","['#Q&A', '#machine_learning']","['chào', 'thầy', 'mentor', 'data', 'engineer', 'machine', 'learning', 'project', 'học']"
995,"Em chào mọi người ạ. Em đang gặp khó về việc cài tensorflow GPU. Em đã cài đầy đủ package và path như trên mạng hướng dẫn.
- tensorflow 2.12
cuda 12.1
cudnn 8.1.0.77
python 3.10.11
Nhưng khi kiểm tra thì vẫn không có GPU . Mong mọi người giúp em với ạ. Em xin cảm ơn ạ.","['#Q&A', '#python']","['chào', 'cài', 'tensorflow gpu', 'cài', 'package', 'path', 'mạng', 'hướng', 'tensorflow', '2', '12', 'cuda', '12', '1', 'cudnn', 'python', '3', '10', '11', 'kiểm tra', 'gpu', 'mong', 'giúp']"
996,"Xin chào mọi người, hiện em đang học môn machine learning cơ bản và giảng viên giao cho làm một cái project cá nhân. 
Em đã chọn được một bài báo về y sinh học, cụ thể là em dùng mô hình Bio-Bert để làm project, nhưng vấn đề là em tìm hiểu và chạy code nhưng không được
Mọi người có thể giúp em hiểu rõ hơn về bài báo và đoạn code được không ạ, vì em cũng mới học về machine learning nên em thấy code khá nhiều
Em xin cảm ơn mọi người nhiều
Link bài báo: https://paperswithcode.com/paper/biobert-a-pre-trained-biomedical-language
Link code : https://github.com/dmis-lab/biobert/blob/master/README.md","['#Q&A', '#machine_learning']","['chào', 'hiện', 'học', 'môn', 'machine', 'learning', 'giảng viên', 'giao', 'project', 'báo', 'y sinh học', 'mô hình', 'biobert', 'project', 'chạy', 'code thể', 'giúp', 'báo', 'đoạn', 'code', 'học', 'machine', 'learning', 'code', 'link', 'báo', 'link', 'code']"
997,"Em chào mọi người, em đang deploy model tensorflow sang graph(.pb) mà khi cv2.dnn.readNetFromTensorflow thì không nhận được layer nào từ model
https://colab.research.google.com/drive/1m-kOQRKsyrfxKVzGrZAx2WT8Fs9IQ_wY?usp=sharing
Mong mọi người giúp em với ạ. Em xin cảm ơn","['#Q&A', '#python']","['chào', 'deploy', 'model', 'tensorflow', 'graph', 'pb', 'cv2', 'dnn', 'readnetfromtensorflow', 'layer', 'model', 'mong', 'giúp']"
998,"Mình muốn hỏi cách xử lý bài toán hồi quy logistic như thế nào khi đầu vào như hình. Hàm logit được giả định là tuyến tính với các biến độc lập x nhưng Decision boundary lúc này không thể là dạng tuyến tính a+bX bình thường mà phải là phương trình đường tròn. Vậy làm thể nào để xử lý được vấn đề này, đặc biệt khi ta không dự đoán được hình dạng của tập dữ liệu. Tra cứu thì có giải pháp là chuyển sang hệ tọa độ cực mà mình không hiểu lắm.","['#Q&A', '#machine_learning']","['toán', 'hồi', 'quy logistic', 'đầu', 'hình', 'hàm logit', 'giả định', 'tuyến', 'biến', 'độc lập', 'x', 'decision', 'boundary thể', 'dạng', 'tuyến', 'a bx', 'bình', 'phương trình', 'đường', 'tròn thể', 'ta', 'dự đoán', 'hình dạng', 'tập liệu', 'tra cứu', 'giải pháp', 'hệ', 'tọa độ', 'cực', 'lắm']"
999,"Chào mọi người, e đang là sinh viên đi thực tập, em đang làm 1 project liên quan đến bài toán mà tập train và test đến từ 2 phân phối khác nhau , anh chị có thể cho em hỏi có cách nào để train model có kết quả cao không ạ","['#Q&A', '#machine_learning']","['chào e', 'sinh viên', 'đi', 'thực tập', '1', 'project toán', 'tập', 'train', 'test', '2', 'phân phối thể', 'train', 'model', 'kết']"
1000,"Vấn đề cross-validation.
Chào mọi người.Mình đang tập tành thực hành các project machine learning và gặp một vấn đề mong mọi người giải đáp giúp ạ.
Mình có 1 bộ imbalanced dataset. Theo google thì để xử lý imbalanced thì mình dùng StratifiedKFold với weight để xử lý. Khi đó, mình thu được K model và tính trung bình các score trên tập valid để đánh giá model.
modelX = LogisticClassifier(para_1=a, ....., para_n = t)
kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=12).split(X,y)
Sau đó, mình lại có 1 bộ test set hoàn toàn tách biệt với bộ data trên để dự đoán. Lúc đấy mình suy nghĩ đến việc có phải nên lựa chọn model có perform tốt nhất trong K model đó để predict cho test set đúng không? Mình có tra google và theo khả năng đọc hiểu của bản thân thì, việc cross-valid trên K model trên thực chất chỉ là một cách để kiểm tra performance và đề phòng TH bộ train -val của mình bị chia lệch. Còn thực chất khi predict ta sẽ vẫn predict trên model ban đầu (kiểu y_pred=modelX.predict(X_test)) đúng không mọi người.Còn việc đổi performance thì phụ thuộc vào việc mình hiệu chỉnh parameter như thế nào.
Không biết mình hiểu vấn đề như vậy có đúng không mọi người? Mình mong nhận được sự giải đáp của mọi người ạ.","['#Q&A', '#machine_learning', '#data']","['crossvalidation', 'chào tập tành', 'thực hành', 'project', 'machine', 'learning', 'mong', 'giải đáp', 'giúp', '1', 'imbalanced', 'dataset', 'google', 'imbalanced', 'stratifiedkfold', 'weight', 'thu', 'k', 'model', 'trung bình', 'score', 'tập', 'valid', 'model', 'modelx', 'logisticclassifier', 'para_1', 'a para_n', 't', 'kfold', 'stratifiedkfold', 'n_splits', '5', 'shuffle', 'true', 'random_state', '12', 'split', 'x', 'y', '1', 'test', 'set', 'tách biệt', 'data', 'dự đoán', 'đấy', 'suy lựa', 'model', 'perform', 'k', 'model', 'predict', 'test', 'set tra', 'google', 'khả năng', 'đọc', 'thân', 'crossvalid', 'k', 'model', 'thực chất', 'kiểm tra', 'performance', 'đề phòng', 'th', 'train', 'val', 'chia', 'lệch', 'thực chất', 'predict', 'ta', 'predict', 'model', 'ban đầu', 'kiểu', 'y_pred', 'modelx', 'predict', 'x_test', 'đổi', 'performance', 'phụ hiệu', 'chỉnh parameter', 'mong', 'giải đáp']"
1001,"Chào mọi người,
Mình hiện tại đang làm việc trong lĩnh vực Web scraping về quảng cáo bất động sản/xe hơi và MLOps. Mình muốn đóng góp/hỗ trợ các dự án công đồng để trao dồi thêm kinh nghiệm về MLOps.
Nếu mn có dự án công đồng nào cần thu thập public data hoặc xây dựng ML pipelines thì ping mình nhé.","['#Q&A', '#machine_learning', '#data']","['chào', 'lĩnh vực', 'web', 'scraping', 'quảng cáo', 'bất động sản', 'xe hơi', 'mlops', 'đóng góp', 'dự án', 'công đồng', 'trao dồi', 'kinh nghiệm', 'mlops mn', 'dự án', 'công đồng', 'thu thập', 'public', 'data', 'xây dựng', 'ml', 'pipelines', 'ping']"
1002,"Xin chào mọi người, mình vừa phỏng vấn ở một công ty ở Anh tuyển summer internship ở vị trí Machine Learning, mình muốn viết bài này để chia sẽ đợt phỏng vấn này mục đích để mọi người cùng nhau bàn luận vì mình cũng chưa biết là câu trả lời của mình là ổn chưa, cụ thể là như sau:
Công ty họ nghiên cứu về Hyperspectral Camera(Camera quang phổ) cụ thể là tấm hình sẽ có hơn 50 chiều không gian màu thay vì chỉ có 3. Khi sử dụng hyperspectral images thì dữ liệu sẽ chính xác và nhiều thông tin hơn. Mình đến đợt phỏng vấn 2 có câu hỏi như sau:
Thì họ hỏi mình đại khái là: Bạn có những cách nào để compress một bức hình và đối với hyperspectral images thì làm sao?
Mình suy nghĩ một chút và trả lời như sau: một cách mình có thể nghĩ ra liền là có thể dùng convolutional methods như một bức hình bình thường hoặc PCA
Họ hỏi thêm là: Vậy bạn có biết effects sau khi deploy methods như vậy là gì không?
Lúc đó mình trả lời đơn giản là sẽ giảm chất lượng và thông tin dữ liệu
Lúc đó mình hơi run nên cũng không hình dung được có cách nào nữa.
Lúc cuối mình hỏi thêm rằng có phải việc compress hyperspectral images là một trong những vấn đề team nghiên cứu đang đối mặt đúng không? Thì họ nói đúng vậy thật.
Thật sự mình tự học khá nhiều nên kinh nghiệm còn rất ít nên khi phỏng vấn mình chỉ trả lời những gì mình nghĩ ra liền lúc đó thôi.
Mọi người ai có kinh nghiệm trong mảng này, cho mình hỏi có câu trả lời nào tốt hơn cho bức hình 50+ không gian màu như vậy không? Mình cảm ơn","['#Q&A', '#machine_learning']","['chào vấn', 'công ty', 'tuyển', 'summer', 'internship', 'machine', 'learning', 'viết', 'chia', 'đợt vấn', 'mục đích', 'bàn luận', 'câu', 'ổn', 'công ty', 'nghiên cứu', 'hyperspectral', 'camera', 'camera quang', 'phổ hình', '50', 'chiều', 'gian', 'màu', 'thay', '3', 'hyperspectral', 'images liệu', 'xác thông', 'đợt vấn', '2', 'đại khái', 'compress hình', 'đối hyperspectral', 'images', 'suy chút thể', 'liền thể', 'convolutional', 'methods hình', 'bình pca', 'effects', 'deploy', 'methods', 'đơn giản', 'chất', 'thông liệu', 'hơi', 'run hình dung', 'compress', 'hyperspectral', 'images', 'team', 'nghiên cứu', 'đối mặt', 'học', 'kinh nghiệm vấn', 'liền', 'kinh nghiệm', 'mảng', 'câu', 'hình', '50', 'gian', 'màu']"
1003,"Hôm nay check github của sách chợt nhận ra đã được gần 1k stars :)
Các bạn có thể tải sách miễn phí tại https://github.com/tiepvupsu/ebookMLCB. Đừng quên để lại một star nếu bạn thấy hữu ích.",['#sharing'],"['hôm', 'check', 'github', 'sách', '1', 'k', 'stars thể', 'tải', 'sách', 'miễn phí', 'https', 'github', 'com', 'tiepvupsu', 'ebookmlcb', 'đừng', 'quên', 'star', 'hữu ích']"
1004,"[Góc hỏi đáp]
Mọi người đã từng dùng Stacked Hourglass Network để nhận diện Pose Estimation cho em hỏi chút được không ạ?
Đầu vào của model là ảnh RGB và label là 15 keypoints(x, y). Còn đầu ra của model là 15 heatmaps.
1. Vậy để tính hàm loss thì mình tính dựa trên 15 heatmaps hay extract heatmap thành 15keypoints để tính loss ạ?
2. Nếu tính loss bằng heatmaps thì làm sao để có thể tính ạ? Vì ảnh vào là RGB và label là 15 keypoints còn outputs của model là 15 heatmaps?
3. Em có sai ở dữ liệu label hay input đầu vào không ạ? Mong mọi người góp ý giúp em ạ..
Em cám ơn..","['#Q&A', '#cv', '#deep_learning']","['góc', 'đáp', 'stacked', 'hourglass', 'network diện', 'pose', 'estimation', 'chút', 'đầu', 'model', 'ảnh', 'rgb', 'label', '15', 'keypoints', 'x', 'y đầu', 'model', '15', 'heatmaps', '1', 'hàm loss', 'dựa', '15', 'heatmaps', 'extract', 'heatmap', 'thành', '15', 'keypoints', 'loss', '2', 'loss', 'heatmaps thể', 'ảnh', 'rgb', 'label', '15', 'keypoints', 'outputs', 'model', '15', 'heatmaps', '3', 'sai liệu', 'label input', 'đầu', 'mong', 'góp', 'giúp', 'cám ơn']"
1005,"Làm việc trong lĩnh vực ML trong một thời gian rồi mà chưa có bài nào trong forum mình. Nhân dịp đang làm việc về Diffusion Models, mình xin phép chia sẻ bài viết mình tổng hợp lại và giải thích một số kiến thức về Diffusion Models. Hy vọng sẽ có ích với các bạn tìm hiểu về nó.
https://viblo.asia/p/diffusion-models-co-ban-phan-1-E1XVOx884Mz","['#sharing', '#machine_learning']","['lĩnh vực', 'ml', 'forum', 'diffusion', 'models phép', 'viết', 'tổng hợp', 'giải', 'kiến thức', 'diffusion', 'models', 'hy vọng ích']"
1006,"Em chào mọi người!
Em đang tìm hiểu về zero-shot learning cho bài toán multi-label nhưng em đã đọc một số bài báo nhưng em vẫn chưa hiểu cách zero-shot learning có thể predict được những label không có trong tập train. Không biết mọi người có 1 bài viết nào đó về vấn đề này, có thể suggest cho em được không ạ, em cảm ơn !","['#Q&A', '#machine_learning']","['chào', 'zeroshot', 'learning toán', 'multilabel', 'đọc', 'báo', 'zeroshot', 'learning thể', 'predict', 'label', 'tập', 'train', '1', 'viết thể', 'suggest']"
1007,"Một bài tổng hợp về kiến trúc mô hình SSD, một trong những mô hình có tốc độ xử lý cao và độ chính xác tốt nhất trong lớp các mô hình object detection.","['#sharing', '#cv', '#deep_learning']","['tổng hợp', 'kiến trúc', 'mô hình', 'ssd', 'mô hình', 'tốc độ', 'độ', 'xác', 'lớp', 'mô hình', 'object', 'detection']"
1008,"[Transformer model pytorch]
Mọi người cho em hỏi một chút về Transformer trên Pytorch ạ.
Em đang gặp một vấn đề là khi set d_model = d_FFN = 512 thì model hội tụ bình thường - bất biến với số block encoder và decoder .
Còn khi set d_model = 512 , d_FFN = d_model x (2^n) ,
thì loss chỉ giảm một chút rồi sau đó nó gần như không đổi.
Em mong mọi người góp ý, em xin cảm ơn ạ.","['#Q&A', '#deep_learning']","['transformer', 'model', 'pytorch', 'chút', 'transformer', 'pytorch', 'set', 'd_model', 'd_ffn', '512', 'model hội', 'tụ bình', 'bất biến', 'block', 'encoder', 'decoder', 'set', 'd_model', '512', 'd_ffn', 'd_model', 'x', '2', 'n', 'loss', 'chút', 'đổi', 'mong', 'góp']"
1009,"Cho em hỏi nhóm mình ai có hứng thú với dữ liệu tài chính không ạ?
Em đang học tại trường Keimyung,khoa của em tổ chức cuộc thi phân tích dữ liệu , thông tin mọi người xem ảnh nha.
Bộ dữ liệu mọi người có thể xem ở link này : https://drive.google.com/drive/folders/1Pxy1uRX3Zx4OvIsEloyH6tCKO_KCJQYO?usp=share_link
Kỹ năng của em chỉ ở mức cơ bản thôi , chủ yếu muốn học từ mọi người là chính ạ.
Giải nhất 570$
2 Giải nhì 400$
5 Giải ba 230$
Giải chia đều cho 3 người trong nhóm ạ, nhóm đã có 2 người rùi !","['#sharing', '#data']","['hứng', 'thú liệu', 'tài học', 'trường', 'keimyung khoa', 'tổ chức', 'thi', 'phân tích liệu', 'thông ảnh', 'nha liệu thể', 'link', 'kỹ năng', 'chủ yếu', 'học', 'giải', '570', '2', 'giải', 'nhì', '400', '5', 'giải', '230', 'giải', 'chia', '3', '2', 'rùi']"
1010,"Mọi người cho e hỏi, ma trận dạng như thế này được gọi tên là gì và có những tính chất như thế nào? Cảm ơn mọi người ạ.","['#Q&A', '#math']","['e', 'ma trận', 'dạng', 'gọi', 'chất']"
1011,"Sau hơn 1 tháng phát triển, AnyLabeling - công cụ gán nhãn dữ liệu ảnh với AI models đã hoàn thiện hơn: 
🔥 Tích hợp Segment Anything, YOLOv5, YOLOv8. Hỗ trợ nạp Custom Models để có thể tạo thành vòng lặp Gán nhãn - Huấn luyện, phát triển model dần dần. 
🔥 Hỗ trợ gán nhãn OCR, KIE với trường text và tính năng grouping. 
🔥 Hỗ trợ đa ngôn ngữ: Tiếng Anh, Tiếng Việt, Tiếng Trung. 
🔥 Cài đặt dễ dàng với Pip, hoặc các tệp thực thi. 
🔥 Tài liệu đầy đủ tại https://anylabeling.com/docs.  
Công cụ này sẽ giúp tăng tốc việc gán nhãn cho nhiều bài toán khác nhau. Xin được giới thiệu đến tất cả mọi người!
- Mã nguồn: https://github.com/vietanhdev/anylabeling
- Blog: https://aicurious.io/.../2023-04-22-create-a-segment...
#anylabeling #segmentanything #yolo #yolov5 #yolov8","['#sharing', '#cv', '#deep_learning']","['1', 'phát triển', 'anylabeling', 'công cụ', 'gán', 'nhãn liệu', 'ảnh', 'models', 'hoàn thiện', 'tích hợp', 'segment', 'anything', 'yolov5', 'yolov8 nạp', 'custom', 'models thể', 'thành', 'vòng', 'lặp gán', 'nhãn', 'huấn luyện', 'phát triển', 'model', 'gán', 'nhãn', 'ocr', 'kie', 'trường', 'text năng', 'grouping đa', 'ngôn ngữ', 'tiếng', 'tiếng', 'việt', 'tiếng', 'trung cài dàng', 'pip', 'tệp', 'thực thi', 'tài liệu', 'https', 'anylabeling', 'com', 'docs', 'công cụ', 'giúp tốc', 'gán', 'nhãn toán', 'giới thiệu', 'tất mã', 'blog', 'https', 'aicurious', 'io', '20230422', 'createasegment']"
1012,"PHƯƠNG PHÁP DẠY CHATGPT HỌC ĐƯỢC KIẾN THỨC MỚI
Xin chia sẻ tới các anh em trong group mô hình tổng quát và các kĩ thuật để dạy ChatGPT hiệu quả. Đây là các phương pháp đang được sử dụng thực tế với giải pháp GPT SaleBot của bọn mình. Rất mong sẽ nhận được thêm nhiều ý kiến đóng góp về các cách thức hiệu quả hơn.
A. NGUYÊN LÝ CHUNG
ChatGPT nói riêng và các mô hình ngôn ngữ lớn (LLM) nói chung có một tính chất rất đặc biệt. Đó là nó có một ""trí nhớ ngắn hạn"" mà nếu đưa dữ liệu mới vào vùng nhớ này, thì mô hình sẽ học được dữ liệu mới này và sử dụng trong nội dung trả lời. Thuật ngữ gọi là in-context learning, hoặc one/few-shot learning. Đây là một đặc điểm có tính cách mạng, bởi nó giúp huấn luyện ChatGPT nhanh chóng và dễ dàng hơn rất nhiều so với giải pháp ""fine-tune"" truyền thống.
So sánh đơn giản, cách huấn luyện AI truyền thống giống như một anh học trò phải bỏ công bỏ sức ôn tập để có kiến thức đi thi. Trong khi đó huấn luyện ChatGPT theo in-context learning thì giống như anh học trò đó sử dụng phao. Cùng một mục đích là trả lời được câu hỏi của người ra đề, thì rõ ràng dùng phao sẽ nhanh chóng và thậm chí trong nhiều trường hợp còn chính xác hơn là tự học, với điều kiện là học trò này phải rất thông minh, là điều mà ChatGPT có thừa.
Đặc điểm có tính cách mạng này của ChatGPT và LLM mở đường cho rất nhiều ứng dụng khác nhau có thể phát triển trên nền ChatGPT, với chi phí rẻ hơn rất nhiều so với truyền thống.
Về tổng thể những ứng dụng này sẽ đều hoạt động theo mô hình như sau. Mình tiếp tục lấy ví dụ thi cử ở trên cho dễ hiểu
Bước 1: Đọc đề, phân tích đề
Ở bước này, hệ thống sẽ lấy câu hỏi của người dùng, và phân tích ý đồ (intention) của câu hỏi đó là gì?
Bước 2: Tìm ""phao"" phù hợp
Phao ở đây chính là đoạn dữ liệu phù hợp cần đưa vào bộ nhớ ngắn hạn của ChatGPT để nó trả lời được câu hỏi. Việc chọn phao này gọi là truy vấn thông tin (information retrieval) mà mình sẽ giới thiệu các kĩ thuật chính của nó ở phần tiếp
Bước 3: Sử dụng ""phao"" để xây dựng đáp án
Ở bước này thì cho ChatGPT đọc hiểu thông tin trong ""phao"" và sử dụng thông tin này để trả lời cho người dùng. Có thể điều khiển quá trình này bằng ""prompt điều khiển"", giúp câu trả lời có tính cách và văn phong khác nhau. Hiểu đơn giản là cùng một đề bài, dùng cùng một phao, thì các anh học trò khác nhau sẽ cho ra các câu trả lời theo phong thái riêng.
B. CÁC KĨ THUẬT LẤY DỮ LIỆU TỪ BỘ NHỚ DÀI HẠN
Trong mô hình huấn luyện ChatGPT kể trên, thì khâu quan trọng nhất chính là chuẩn bị và chọn ra được đúng ""phao"" từ đống kiến thức lớn chung. Khâu này quyết định toàn bộ chất lượng trả lời của ChatGPT, hay hiểu đơn giản là chuẩn bị ""phao"" lệch tủ, hay dùng ""phao"" lệch đề bài thì đều khiến thi trượt.
Khâu này trong khoa học máy tính gọi là truy vấn thông tin (information retrieval - IR), là một lĩnh vực được phát triển rất lâu dài. Có rất nhiều kĩ thuật IR khác nhau, nhưng dưới đây là một số kĩ thuật có thể áp dụng hiệu quả với bài toán huấn luyện ChatGPT:
Fuzzy matching (so khớp văn bản)
Đây là kĩ thuật đơn giản nhất, nó đơn thuần so sánh sự khác biệt về từ khoá giữa câu hỏi với lại dữ liệu phù hợp để trả lời. Kĩ thuật này giống như anh học sinh dốt trong đầu không có kiến thức gì, chỉ xem đề bài nhắc đến từ khoá gì thì tìm phao có chứa nhiều từ trùng nhất để chép
BM25 
Đây là kĩ thuật cao cấp hơn Fuzzy matching, nó biết trong câu hỏi của người dùng và dữ liệu trả lời, thì đâu là từ khoá quan trọng, đâu là từ khoá ít quan trọng. Kĩ thuật này giống như anh học sinh có nghe giảng, dù cũng chưa thực sự hiểu lắm nhưng cũng nhớ được vài từ khoá thày cô hay nhắc tới, nên trong các phao na ná nhau, thì anh biết chọn phao chứa nhiều từ khoá quan trọng nhất có trong đề bài. Điều thú vị ở đây là trong thực tiễn, dù anh học sinh chẳng hiểu gì bài giảng, chỉ dùng ""mẹo"" thì mẹo này cũng rất hiệu quả.
Semantic search (vector search)
Cuộc đời không bao giờ đơn giản kiểu học gì thi nấy, mà đề bài luôn được các thày cô ra kiểu lắt léo mà phải tư duy thì mới hiểu được đây là dạng bài gì, áp dụng kiến thức đã học nào. Đây chính là chỗ mà kĩ thuật semantic search áp dụng. Từ cái tên cũng đã nói lên kĩ thuật này, đó là thay vì chỉ nhìn vào mặt chữ, thì ""đọc hiểu"" câu hỏi, rồi tìm xem kiến thức nào trong những cái đã biết thực sự liên quan tới nội dung này. Quá trình ""đọc hiểu"" này của máy gọi là embedding, dữ liệu ngữ nghĩa của câu hỏi được biểu diễn ở dạng vector, và quá trình tìm kiếm là quá trình so sánh độ gần-xa giữa các vector nên kĩ thuật này còn gọi là vector search. Lĩnh vực vector search đang được thúc đẩy phát triển rất nhanh sau khi ChatGPT xuất hiện.
C. ĐÁNH GIÁ
Từ thực tiễn áp dụng, phối hợp các kĩ thuật huấn luyện ChatGPT kể trên vào sản phẩm GPT SaleBot (demo tại: https://support.gptsalebot.com), mình rút ra được một số đánh giá:
Fuzzy matching rất thích hợp để áp dụng cho các câu hỏi cụ thể, rõ nghĩa, dùng chuẩn thuật ngữ
BM25 rất thích hợp với những câu hỏi dài, có nhiều chi tiết
Semantic search thích hợp với những nội dung ngắn, và giỏi trong việc phân biệt các câu na ná nhau về hình thức nhưng khác nhau về ngữ nghĩa
Trên thực tế, để huấn luyện ChatGPT hiệu quả, thì không chỉ sử dụng một phương pháp, mà cần kết hợp nhiều phương pháp lại với nhau. Và team GPT SaleBot hiện đã triển khai các kĩ thuật để huấn luyện ChatGPT đạt chất lượng tương đương chatbot Fin của Intercom, là phiên bản tiên tiến nhất của trùm chatbot quốc tế (https://www.intercom.com/fin). Ở trình độ này, chatbot không những cần hiểu tốt câu hỏi của người dùng, và trả lời chính xác theo thông tin được huấn luyện, mà còn phải có khả năng xử lý các dạng viết tắt, viết sai chính tả, từ lóng, có khả năng đặt lại câu hỏi làm rõ nghĩa và gợi ý các câu hỏi follow-up để tiếp tục hội thoại.
Các bạn có thể trải nghiệm thử các tính năng này tại: https://support.gptsalebot.com
D. MỞ RỘNG
Huấn luyện ChatGPT trên dữ liệu riêng, và áp dụng phương pháp này vào các bài toán cụ thể như chatbot đang là lĩnh vực phát triển nhanh và sẽ còn có nhiều giải pháp thú vị hơn trong tương lai. Nếu bạn muốn nắm bắt cơ hội và trở thành các chuyên gia về triển khai chatbot, chuyên gia huấn luyện ChatGPT theo bài toán đặc thù của doanh nghiệp thì có thể đăng ký trở thành partner triển khai hoặc nhân sự của GPT SaleBot theo link dưới đây: https://aivgroupworking.sg.larksuite.com/.../shrlgvtifZ8t...
Quyền lợi của partner là sẽ được tiếp cận những hiểu biết sâu về công nghệ ChatGPT, những insight trong việc triển khai chatbot, trợ lý ảo thành công và đón đầu làn sóng conversational marketing đang diễn ra nhanh chóng sắp tới.
Lộc Đặng","['#sharing', '#nlp']","['phương pháp', 'dạy', 'chatgpt học', 'kiến thức', 'group', 'mô hình', 'tổng quát', 'kĩ thuật', 'dạy', 'chatgpt hiệu', 'phương pháp', 'giải pháp', 'gpt', 'salebot', 'bọn', 'mong kiến', 'đóng góp', 'thức hiệu', 'a', 'nguyên lý', 'chatgpt', 'mô hình', 'ngôn ngữ', 'llm', 'chất trí', 'ngắn hạn liệu', 'mô hình', 'học liệu', 'nội dung', 'thuật ngữ', 'gọi', 'incontext', 'learning', 'one', 'fewshot', 'learning', 'đặc mạng', 'giúp', 'huấn luyện', 'chatgpt', 'chóng dàng', 'giải pháp', 'finetune', 'truyền thống', 'sánh', 'đơn giản', 'huấn luyện', 'truyền thống', 'học trò', 'công sức', 'ôn tập', 'kiến thức', 'đi', 'thi', 'huấn luyện', 'chatgpt', 'incontext', 'learning', 'học trò', 'phao', 'mục đích', 'đề ràng', 'phao', 'chóng chí', 'trường hợp', 'xác', 'học', 'kiện', 'học trò', 'thông minh', 'chatgpt', 'thừa', 'đặc mạng', 'chatgpt', 'llm', 'đường', 'ứng dụng thể', 'phát triển', 'chatgpt', 'chi phí', 'rẻ', 'truyền thống', 'tổng thể', 'ứng dụng', 'hoạt động', 'mô hình', 'ví dụ', 'thi cử', '1', 'đọc', 'đề', 'phân tích', 'đề', 'hệ thống', 'phân tích', 'đồ', 'intention', '2', 'phao', 'phao', 'đoạn liệu', 'ngắn hạn', 'chatgpt', 'phao', 'gọi', 'truy vấn', 'thông information', 'retrieval', 'giới thiệu', 'kĩ thuật', 'tiếp', '3', 'phao', 'xây dựng', 'đáp án', 'chatgpt', 'đọc', 'thông phao', 'thông thể', 'khiển trình', 'prompt khiển', 'giúp', 'câu', 'văn phong', 'đơn giản', 'đề phao', 'học trò', 'câu', 'phong thái b', 'kĩ thuật', 'liệu', 'hạn', 'mô hình', 'huấn luyện', 'chatgpt', 'khâu', 'chuẩn phao', 'đống', 'kiến thức', 'khâu', 'quyết định', 'toàn', 'chất', 'chatgpt', 'đơn giản', 'chuẩn phao', 'lệch', 'tủ phao', 'lệch', 'đề thi', 'trượt', 'khâu', 'khoa học', 'máy', 'gọi', 'truy vấn', 'thông information', 'retrieval', 'ir', 'lĩnh vực', 'phát triển', 'kĩ thuật', 'ir', 'kĩ thuật thể', 'áp dụng', 'hiệu toán', 'huấn luyện', 'chatgpt', 'fuzzy', 'matching', 'khớp văn kĩ thuật', 'đơn giản đơn', 'sánh biệt', 'khóa liệu', 'kĩ thuật', 'học sinh', 'dốt đầu', 'kiến thức', 'đề nhắc', 'khóa', 'phao', 'chứa trùng', 'chép bm25', 'kĩ thuật', 'fuzzy', 'matching liệu', 'khóa khóa', 'kĩ thuật', 'học sinh', 'giảng thực', 'lắm', 'khóa', 'thày', 'nhắc', 'phao', 'na ná', 'phao', 'chứa', 'khóa', 'đề thú vị', 'thực tiễn', 'học sinh', 'chẳng', 'giảng mẹo', 'mẹo hiệu', 'semantic', 'search', 'vector', 'search', 'đời', 'đơn giản', 'kiểu', 'học', 'thi', 'đề thày', 'kiểu', 'lắt léo', 'tư dạng', 'áp dụng', 'kiến thức', 'học chỗ', 'kĩ thuật', 'semantic', 'search', 'áp dụng', 'kĩ thuật', 'thay mặt', 'chữ', 'đọc', 'kiến thức', 'thực nội dung', 'trình', 'đọc', 'máy', 'gọi', 'embedding', 'liệu ngữ nghĩa', 'biểu diễn', 'dạng', 'vector trình', 'kiếm', 'trình', 'sánh độ', 'gầnxa vector', 'kĩ thuật', 'gọi', 'vector', 'search', 'lĩnh vực', 'vector', 'search', 'thúc đẩy', 'phát triển', 'chatgpt', 'c', 'thực tiễn', 'áp dụng', 'phối hợp', 'kĩ thuật', 'huấn luyện', 'chatgpt', 'sản phẩm', 'gpt', 'salebot', 'demo', 'rút', 'fuzzy', 'matching hợp', 'áp dụng', 'nghĩa', 'chuẩn thuật ngữ', 'bm25 hợp', 'chi tiết', 'semantic', 'search hợp', 'nội dung', 'ngắn', 'giỏi', 'phân biệt', 'câu', 'na ná', 'hình thức', 'ngữ nghĩa', 'huấn luyện', 'chatgpt hiệu', 'phương pháp', 'kết hợp', 'phương pháp', 'team', 'gpt', 'salebot', 'hiện', 'triển khai', 'kĩ thuật', 'huấn luyện', 'chatgpt', 'chất', 'tương đương', 'chatbot', 'fin', 'intercom', 'phiên', 'tiên tiến', 'trùm', 'chatbot', 'quốc tế', 'trình độ', 'chatbot', 'xác', 'thông', 'huấn luyện', 'khả năng', 'dạng', 'viết', 'tắt', 'viết', 'sai tả', 'lóng', 'khả năng', 'nghĩa gợi', 'followup', 'hội thoại thể', 'trải nghiệm', 'thử năng', 'd', 'rộng', 'huấn luyện', 'chatgpt liệu', 'áp dụng', 'phương pháp', 'toán', 'chatbot', 'lĩnh vực', 'phát triển', 'giải pháp', 'thú vị', 'tương lai', 'nắm bắt', 'hội', 'chuyên gia', 'triển khai', 'chatbot', 'chuyên gia', 'huấn luyện', 'chatgpt toán', 'đặc thù', 'doanh nghiệp thể', 'đăng ký', 'partner', 'triển khai', 'nhân gpt', 'salebot', 'link', 'https', 'aivgroupworking', 'sg', 'larksuite', 'com shrlgvtifz8t', 'quyền lợi', 'partner', 'tiếp cận', 'sâu', 'công nghệ', 'chatgpt', 'insight', 'triển khai', 'chatbot', 'trợ lý', 'ảo', 'thành công', 'đón đầu', 'làn sóng', 'conversational', 'marketing', 'diễn chóng', 'lộc', 'đặng']"
1013,"Xin chào các bạn, mình làm mảng geospatial rẽ ngang, cụ thể là data capture & processing point cloud data & 3D modelling. Mình chỉ viết vài script cơ bản phục vụ công việc trên python. Giờ muốn tham gia sâu hơn vào ML.
Không biết trong group mình có ai làm về mảng này không ạ? Mình xin phép được kết bạn và học hỏi thêm.
Mình ở Melbourne, Australia. Nếu có bạn nào ở đây mình xin mời cà phê ạ 🙂","['#Q&A', '#machine_learning']","['chào', 'mảng', 'geospatial', 'rẽ', 'ngang', 'data', 'capture', 'processing', 'point', 'cloud', 'data', '3', 'd', 'modelling', 'viết', 'script', 'phục vụ', 'công python', 'tham gia', 'sâu', 'ml', 'group', 'mảng', 'phép', 'kết học', 'melbourne australia', 'mời', 'cà phê']"
1014,"[HCM]
Chào các anh/chị.
Em là người trái ngành, có đam mê về lĩnh vực AI và đang mong muốn tìm kiếm công việc bên mảng này (MLE, DS, DE)
Hiện tại thì tình hình xin việc fresher cho ML/DL cũng khó khăn, nên em muốn dành thêm thời gian để tiếp tục trau dồi bản thân, nâng cao khả năng của mình lên.
Vậy nên, em viết post này mong được anh/chị nào có thể cho em cơ hội, nhận em vào làm để học hỏi thêm, có cơ hội tiếp xúc với dự án thực tế. (công ty hay freelance đều được ạ).
Em ko quan trọng chuyện lương.
E ở HCM.
Anh/chị cmt e sẽ inbox CV ạ.
Em cảm ơn nhiều.","['#sharing', '#machine_learning']","['hcm', 'chào', 'trái', 'ngành', 'đam mê', 'lĩnh vực', 'mong', 'kiếm', 'công mảng', 'mle', 'ds de', 'tình hình', 'fresher', 'ml', 'dl', 'khăn', 'trau dồi', 'thân', 'nâng', 'khả năng', 'viết', 'post', 'mong thể', 'hội học', 'hội', 'tiếp xúc', 'dự án', 'công ty', 'freelance', 'ko', 'lương', 'e hcm', 'cmt', 'e inbox', 'cv']"
1015,"Xin phép spam group một chút. Hành động này đáng bị lên án.
Tôi luôn phản đối chuyện đạo văn không trích nguồn. Đằng này bạn 'thầy Henry' này còn lấy luôn cả slide rồi ghi tên mình vào.
Tài khoản này trước đây đăng khá nhiều bài trong group và tự xưng là 'thầy Henry', tôi xin phép xóa tài khoản và các bài liên quan. Bạn nào quan tâm có thể qua group của 'thầy' theo dõi.",['#sharing'],"['phép', 'spam', 'group', 'chút', 'hành động án', 'phản đối đạo', 'văn trích', 'đằng', 'thầy', 'henry', 'slide', 'ghi', 'tài khoản', 'đăng group', 'xưng', 'thầy', 'henry', 'phép', 'xóa', 'tài khoản', 'thể', 'group', 'thầy', 'dõi']"
1016,"Mọi người nghĩ sao về Tensorflow Developer Certificate ở thời điểm hiện tại ? 
Em/mình background về computer science + đã làm việc/nghiên cứu với ML gần 2 năm, đang băn khoăn có nên ôn thi làm đẹp CV không vì đọc review có vẻ không yêu cầu chuyên môn cao và công việc hiện tại ở công ty chưa nhiều áp lực.
Cảm ơn mọi người đã đọc.","['#sharing', '#machine_learning']","['tensorflow', 'developer', 'certificate', 'background', 'computer', 'science', 'nghiên cứu', 'ml', '2', 'băn khoăn', 'ôn thi', 'đẹp', 'cv', 'đọc', 'review vẻ', 'chuyên môn', 'công', 'công ty', 'áp lực', 'đọc']"
1017,"Em chào mọi người ạ
Có ai có thể cho em tài liệu tham khảo về việc sử dụng Bayesian Neural Network ( BNN Model) để dự đoán giá BTC bằng python không ạ. Em làm đồ án nhưng kiếm tài liệu về thuật toán này thì lại rất ít ạ","['#Q&A', '#deep_learning']","['chào thể', 'tài liệu', 'tham khảo', 'bayesian', 'neural', 'network', 'bnn', 'model', 'dự đoán', 'giá', 'btc', 'python', 'đồ án', 'kiếm', 'tài liệu', 'thuật toán']"
1018,"Chào các anh,chị trong forum.
Em sn 2000 đã ra trường. Tất cả kiến thức về AI em đều tự học nên nhiều phần kiến thức lại thiếu mà có phần lại tốt, và em không kinh nghiệm các dự án thực tế, vì vậy em viết post này để mong anh/chị nào có thể cho em cơ hội làm việc để học hỏi thêm, được làm việc trong dự án thực tế. Em có thể thực tập hay fresher tại HCM.
Em tự tin về phần giao tiếp tiếng Anh hay tốt nghiệp ở đh tốt, mà cho em hỏi ngu là mấy anh chị tuyển dụng giờ có nhìn vào những yếu tố này không ạ?","['#Q&A', '#machine_learning']","['chào', 'forum', 'sn', '2000', 'trường', 'tất kiến thức', 'học', 'kiến thức', 'kinh nghiệm', 'dự án', 'viết', 'post', 'mong thể', 'hội học', 'dự án', 'thể', 'thực tập', 'fresher', 'hcm', 'giao tiếp', 'tiếng nghiệp', 'đh', 'ngu', 'mấy', 'tuyển dụng', 'yếu tố']"
1019,"Em chào anh chị trong group ạ, hiện tại em đang dùng yolov5 để detect object nhưng gặp tình trạng box của vật thể bị chia thành 2 box nhỏ thì có cách nào giải quyết không ạ ?
Em cảm ơn nhiều.","['#Q&A', '#deep_learning', '#cv']","['chào', 'group', 'yolov5', 'detect', 'object box', 'vật thể', 'chia', 'thành', '2', 'box', 'giải quyết']"
1020,"Chào mọi người,
Cho em hỏi về bài toán Object Detection, liệu mình có phương pháp nào để cung cấp thông tin bổ sung cho mô hình không ạ.
Ví dụ như số lượng object không quá n, hoặc background của các ảnh luôn giống nhau.
Em cảm ơn ạ.","['#Q&A', '#cv']","['chào toán', 'object', 'detection liệu', 'phương pháp', 'cung thông', 'bổ sung', 'mô hình', 'ví dụ', 'object', 'n', 'background', 'ảnh']"
1021,"CHia sẻ lại cho các bạn một bài viết cực hay về ứng dụng của ML DS trong ngân hàng và các tổ chức tài chính.
Mình đang làm về risk management cho bank thì thấy bài viết đặc biệt hữu ích khi mình hiểu thêm về các mô hình machine learning đang được áp dụng và khai thác trong các hệ thống của ngân hàng.
https://www.facebook.com/groups/1083842528922368/posts/1259824431324176","['#sharing', '#machine_learning']","['viết', 'cực', 'ứng dụng', 'ml', 'ds', 'ngân hàng', 'tổ chức', 'tài risk', 'management bank', 'viết', 'hữu ích', 'mô hình', 'machine learning', 'áp dụng', 'khai thác', 'hệ thống', 'ngân hàng']"
1022,"Chào mọi người ạ, em đang optimize lại code của em, trong lúc optimize thì em nhận thấy một điều kì lạ.
Cụ thể là như hình 1, em tạo 1 tensor là mathched, sau đó truyền images vào network, rồi em đo thời gian gán matched[0] thì kết quả là lần lặp đầu luôn tốn rất nhiều thời gian mà em không biết tại sao. Vấn đề đó chỉ là một phép gán.
Nhưng như trong hình 2, nếu em không truyền images vào network và đo thời gian em gán matched[0] thì nó lại rất nhanh. Vậy lí do là do đâu vậy ạ.
// em đang để config.device = ""cuda""","['#Q&A', '#deep_learning']","['chào', 'optimize code', 'optimize kì', 'lạ hình', '1', '1', 'tensor', 'mathched', 'truyền', 'images', 'network', 'đo', 'gán', 'matched', '0', 'kết lặp', 'đầu', 'tốn phép', 'gán hình', '2', 'truyền', 'images', 'network', 'đo', 'gán matched', '0', 'lí config', 'device', 'cuda']"
1023,"Chào cả nhà. Mình đang bị vấn đề này khi chạy TheBloke/vicuna-7B-GPTQ-4bit-128g hoặc Neko-Institute-of-Science/LLaMA-13B-4bit-128g trên text-generation-webui và không biết tại sao lại bị vậy. 
Mình cũng đã test chạy anon8231489123/vicuna-13b-GPTQ-4bit-128g với cùng thông số và không bị vấn đề gì cả.

- Đây là câu lệnh để mình chạy server:
 python server.py --share --auto-devices --chat --model-menu --wbits 4 --groupsize 128
Mong mọi người giúp mình. Mình cám ơn rất nhiều!",['#Q&A'],"['chào', 'chạy', 'thebloke', 'vicuna7bgptq4bit128g', 'nekoinstituteofscience', 'llama13b4bit128g', 'textgenerationwebui', 'test', 'chạy', 'anon8231489123', 'vicuna13bgptq4bit128g', 'thông', 'câu', 'lệnh', 'chạy', 'server', 'python', 'share', 'autodevices', 'chat', 'modelmenu', 'wbits', '4', 'groupsize', '128', 'mong', 'giúp', 'cám ơn']"
1024,"MEDIAPIPE: LOW-CODE NO-CODE AI FOR EVERYONE
Bạn nào quan tâm đến ứng dụng AI thì nhớ dùng thử MediaPipe là thư viện để các bạn developer có thể tích hợp AI vào ứng dụng của mình một cách dễ dàng chỉ với một vài dòng code nhé. Team mình mới ra mắt phiên bản mới của MediaPipe ở Google I/O năm nay với 14 API phục vụ nhiều use case khác nhau như face landmark detection, selfie segmentation v.v. Các bạn muốn biết cụ thể hơn thì xem video I/O này của mình nhé. Hy vọng thư viện này sẽ hữu ích cho các bạn! https://youtu.be/yOP_FY2KTm8P/S: Bonus thêm dưới comment là video về Project Gameface, công cụ để dùng khuôn mặt điều khiển con chuột máy tính bọn mình build với MediaPipe. Source code có trên GitHub cho những bạn muốn tìm hiểu kỹ hơn nhé.","['#sharing', '#machine_learning']","['mediapipe', 'lowcode', 'nocode', 'for', 'everyone', 'ứng dụng', 'thử', 'mediapipe', 'thư viện', 'developer', 'thể tích hợp', 'ứng dụng dàng', 'dòng', 'code', 'team', 'mắt', 'phiên', 'mediapipe', 'google', 'i', 'o', '14', 'api', 'phục vụ', 'use', 'case', 'face', 'landmark', 'detection', 'selfie', 'segmentation', 'v', 'v', 'video', 'i', 'o', 'hy vọng', 'thư viện', 'hữu ích', 'https', 'youtu', 'be', 'yop_fy2ktm8p', 's', 'bonus', 'comment', 'video', 'project', 'gameface', 'công cụ', 'khuôn mặt', 'khiển', 'chuột', 'máy', 'bọn', 'build', 'mediapipe', 'source', 'code', 'github', 'kỹ']"
1025,"Hi mọi người,

Mình muốn hỏi chút về cách freeze 1 custom model.

Mình có 1 model gồm 2 blocks,
Mình muốn train từng block theo cách như sau:
Freeze block 2, train block 1 và lưu weight
Load weight đã lưu, freeze block 1 và train block 2.
Mình muốn hỏi là làm cách nào để freeze các layer ở mỗi block dùng pytorch?
Mình đã thử:

for param in block1.parameters():
    param.requires_grad = True (False)

Nhưng khi làm như này thì tất cả param đều bị set requires_grad = False hết. Nếu k dùng đoạn code trên (nghĩa là k set gì cả) thì requires_grad của các param trong 2 blocks vẫn là True.

Ae ai gặp phải vấn đề như vậy cho mình ý kiến vs nhé. Thank you!","['#Q&A', '#machine_learning']","['hi chút', 'freeze', '1', 'custom', 'model', '1', 'model', '2', 'blocks', 'train', 'block', 'freeze', 'block', '2', 'train', 'block', '1', 'lưu weight', 'load', 'weight', 'lưu freeze', 'block', '1', 'train', 'block', '2', 'freeze', 'layer', 'block', 'pytorch', 'thử', 'for', 'param', 'in', 'block1', 'parameters', 'param', 'requires_grad', 'true', 'false', 'tất param', 'set', 'requires_grad', 'false', 'k', 'đoạn', 'code nghĩa', 'k', 'set', 'requires_grad', 'param', '2', 'blocks', 'true', 'ae kiến', 'vs', 'thank', 'you']"
1026,"Xin chào mọi người, em có một câu hỏi như này ạ, e tính hè này sẽ học hai khoá về ML trên cousera nhưng mọi người nói học mấy khoá đó để có kiến thức nền tảng chứ basic quá, đi làm không ăn thua.
Vậy nếu như học xong thì mình nên làm gì, học gì tiếp theo để có thể đi làm được ạ. Em vẫn chưa hình dung ra. Bởi vì e thấy cac cty chỉ tuyển người đã có kinh nghiệm về ML đi làm chứ k tuyển intern.
Mong mn giải đáp ạ.","['#Q&A', '#machine_learning']","['chào', 'e hè', 'học', 'hai', 'khóa', 'ml', 'cousera', 'học', 'mấy', 'khóa', 'kiến thức', 'tảng', 'basic', 'đi', 'thua học', 'xong', 'học', 'tiếp thể', 'đi', 'hình dung', 'e cac', 'cty', 'tuyển', 'kinh nghiệm', 'ml', 'đi', 'k tuyển', 'intern', 'mong', 'mn', 'giải đáp']"
1027,em có một bài tập training model nhưng bị lỗi SPPF không biết mọi người có ai bị lỗi này như em không ạ. Em đang tìm cách fix mong anh chị giúp đỡ,"['#Q&A', '#machine_learning']","['tập', 'training', 'model', 'lỗi', 'sppf', 'lỗi', 'fix', 'mong', 'giúp đỡ']"
1028,"Dạ chào mọi người, hiện em đang muốn fine-tune mô hình TrOCR cho dữ liệu bao gồm công thức Latex, tiếng Việt và cả tiếng Anh nhưng trước hết em đang thử với mỗi Latex không thôi xem như thế nào thì CER mãi vẫn không xuống quá 0.27, không biết mọi người có kinh nghiệm gì khi fine-tune mô hình trên một tập dataset custom và có thể cho em vài gợi ý để thực hiện bài toán này được không ạ? Vì em chưa có nhiều kinh nghiệm nên gặp khó khăn, em cảm ơn mọi người đã đọc bài.","['#Q&A', '#deep_learning']","['chào', 'hiện', 'finetune', 'mô hình', 'trocr liệu', 'bao', 'công thức', 'latex', 'tiếng', 'việt', 'tiếng', 'thử', 'latex', 'cer', 'mãi', '0', '27', 'kinh nghiệm', 'finetune', 'mô hình', 'tập', 'dataset', 'custom thể', 'gợi toán', 'kinh nghiệm', 'khăn', 'đọc']"
1029,"Chào các anh,chị trong forum.
Em sn 2000 đã ra trường. Do lúc trước đi học không có định hướng sớm nên phải đến gần lúc ra trường mới xác định theo AI. Em đã đi thực tập nhưng hiện tại không có việc làm.
Tất cả kiến thức về AI em đều tự học nên thiếu kinh nghiệm làm việc tại các dự án thực tế, vì vậy em viết post này để mong anh/chị nào có thể cho em cơ hội làm việc để học hỏi thêm, được làm việc trong dự án thực tế. Em có thể đi làm không lương và làm việc tại Hà Nội.
Em cảm ơn nhiều.","['#Q&A', '#machine_learning']","['chào', 'forum', 'sn', '2000', 'trường', 'đi', 'học', 'định hướng', 'trường', 'xác định', 'đi', 'thực tập', 'tất kiến thức', 'học', 'kinh nghiệm', 'dự án', 'viết', 'post', 'mong thể', 'hội học', 'dự án thể', 'đi', 'lương', 'hà nội']"
1030,Em đang có bài tập là về seq2seq cho bài toán summarization nhưng trên model nó có độ chính xác là khoảng 0.4% là có thể dự đoán các từ tiếp theo. Các bác có thể xem code dưới đây cho em hỏi code em dự đoán đúng chưa hay em đang làm sai chỗ nào. Em xin cám ơn.,"['#Q&A', '#deep_learning', '#nlp']","['tập', 'seq2seq toán', 'summarization', 'model độ', 'xác', '0', '4', 'thể', 'dự đoán', 'tiếp thể', 'code', 'code', 'dự đoán', 'sai', 'chỗ', 'cám ơn']"
1031,"Chào mọi người ạ! E là sinh viên, e mới mua được chiếc vga rtx 3060 và 32GB RAM, e muốn build 1 PC để học tập và làm nghiên cứu về computer vision, vì budget của e không được cao lắm nên e đang tính mua con CPU i3 12100F. Mọi người cho e hỏi con CPU này có đủ cho việc học tập và nghiên cứu về Computer Vision, deep learning không ạ? E cảm ơn mọi người","['#Q&A', '#cv']","['chào e', 'sinh viên', 'e', 'mua', 'vga', 'rtx', '3060', '32', 'gb', 'ram', 'e build', '1', 'pc', 'học tập', 'nghiên cứu', 'computer', 'vision', 'budget', 'e', 'lắm', 'e', 'mua', 'cpu', 'i3', '12100', 'f', 'e cpu', 'học tập', 'nghiên cứu', 'computer', 'vision', 'deep', 'learning', 'e']"
1032,"Chào mọi người, không biết ở đây có bạn sinh viên nào đang làm project về computer vision k ạ, có thể cho mình 1 chân vô hỗ trợ không công được k tại mình muốn tích lũy thêm kinh nghiệm từ những project ấy nên chủ yếu vừa giúp lại vừa học hỏi cái mới luôn ạ. Ai có nhu cầu thì cứ cmt mình giúp hết mình nha !!!!","['#Q&A', '#cv']","['chào', 'sinh viên', 'project', 'computer', 'vision', 'k thể', '1', 'chân', 'vô công', 'k tích', 'lũy', 'kinh nghiệm', 'project', 'chủ yếu', 'giúp', 'học', 'nhu cầu', 'cmt', 'giúp', 'nha']"
1033,"Mojo Programming Language

Chris Lattner (tác giả LLVM, ngôn ngữ Swift), Tim Davis và team Modular vừa cho ra mắt ngôn ngữ lập trình Mojo. Được cho là dễ đọc như Python, nhanh hơn tốc độ của C++ và safety như Rust - gần như là thế mạnh của từng ngôn ngữ - vào trong Mojo. Điểm hay ho của Mojo là cho phép truy cập toàn bộ hệ sinh thái có sẵn của Python, ví dụ như là NumPy, Pandas, Matplotlib trực tiếp trong Mojo (Mojo is actually a superset of Python, so I can use my Python code).

Hiện tại Mojo đang ở trong giai đoạn beta.

Product Launch 2023 Keynote ngày 03/05/2023 còn nêu ra những vấn đề về chi phí, phần cứng, cơ sở hạ tầng khi triển khai và xây dựng các hệ thống AI.

Nếu những gì team Modular nói là đúng, thì đây sẽ là một bước ngoặt tương đối lớn 👀

Link: https://www.youtube.com/watch?v=-3Kf2ZZU-dg","['#sharing', '#python']","['mojo', 'programming', 'language', 'chris', 'lattner', 'tác giả', 'llvm', 'ngôn ngữ', 'swift', 'tim', 'davis', 'team', 'modular mắt', 'ngôn ngữ', 'lập trình', 'mojo', 'đọc', 'python', 'tốc độ', 'c', 'safety rust', 'ngôn ngữ', 'mojo ho', 'mojo phép', 'truy cập', 'toàn', 'hệ sinh thái', 'sẵn', 'python', 'ví dụ', 'numpy', 'pandas', 'matplotlib', 'mojo', 'mojo', 'is', 'actually', 'a', 'superset', 'of python', 'i', 'can', 'use', 'my', 'python', 'code', 'mojo', 'giai đoạn', 'beta', 'product', 'launch', '2023', 'keynote', '03', '05', '2023', 'nêu', 'chi phí', 'cứng', 'sở hạ tầng', 'triển khai', 'xây dựng', 'hệ thống', 'team', 'modular', 'ngoặt', 'tương đối', 'link']"
1034,"Chào cả nhà,
Hiện em đang đọc hiểu paper này (https://arxiv.org/abs/1907.02189) về convergence proof của federated learning. Khi chứng minh Theorem 1 ở cuối trang 14 thì tác giả có chuyển từ F^*_k sang F^* như trong hình đính kèm. Mọi người cho em hỏi là tại sao lại làm như vậy được không ạ?
Cảm ơn mọi người!","['#Q&A', '#math']","['chào', 'hiện', 'đọc', 'paper', 'convergence', 'proof', 'federated', 'learning', 'chứng minh', 'theorem', '1', 'trang', '14', 'tác giả', 'f', '_k', 'f hình', 'đính', 'kèm']"
1035,"Hello chào cả nhà! Mình muốn hỏi build 1 con server để training với cấu hình sau:
- cpu: intel core i7 12700K
- gpu: x2 RTX 3060 12GB
Thì liệu chip core có ảnh hưởng đến hiệu năng khi sử dụng cùng với 2 card rời không hay main quyết định ạ.
Mong được giải đáp.
Mình cám ơn.",['#Q&A'],"['hello', 'chào build', '1', 'server', 'training', 'cấu hình', 'cpu', 'intel', 'core', 'i7', '12700', 'k', 'gpu', 'x2', 'rtx', '3060', '12', 'gb liệu', 'chip', 'core', 'ảnh hưởng', 'hiệu năng', '2', 'card', 'rời', 'main', 'quyết định', 'mong', 'giải đáp', 'cám ơn']"
1036,"Hello everyone, I need a data set of Danish language including handwriting or typing. Anyone who can share or sell, please comment below. Main purpose for research research and study.Thank you everyone",['#data'],"['hello', 'everyone', 'i', 'need', 'a', 'data', 'set', 'of danish', 'language', 'including', 'handwriting', 'or', 'typing', 'anyone', 'who', 'can', 'share', 'or', 'sell', 'please', 'comment', 'below', 'main', 'purpose', 'for', 'research research', 'and study', 'thank', 'you', 'everyone']"
1037,"Chào mọi người , em là một học sinh cấp 3 đang tìm tòi về các kiến thức của Machine learning và xử lý ảnh cho cuộc thi nghiên cứu khoa học . Em đang làm một mini-project về phân loại rác thì em có thắc mắc là giữa rác tái chế và rác không tái chế thì khi xử lý ảnh em cần phải phân tích các yếu tố nào của rác để có thể đưa vào tập dữ liệu . Song với đó là em cũng muốn được mọi người chỉ giáo về các hướng để phân tích ảnh ạ.
Em cảm ơn mọi người.","['#Q&A', '#machine_learning', '#cv']","['chào', 'học sinh', '3', 'tòi', 'kiến thức', 'machine', 'learning', 'ảnh', 'thi', 'nghiên cứu', 'khoa học', 'miniproject', 'phân', 'rác', 'thắc mắc', 'rác', 'tái chế', 'rác', 'tái chế', 'ảnh', 'phân tích', 'yếu tố', 'rác thể', 'tập liệu', 'song giáo', 'hướng', 'phân tích', 'ảnh']"
1038,"🔥 #Neuron #Rendering, những bước tiến mới nhất trong xử lý đồ họa với AI","['#sharing', '#cv']","['tiến', 'đồ', 'họa']"
1039,"Hello cả nhà cho mình xin phép chia sẻ một tập podcast episode mà bên Forward Vietnam Podcast bọn mình vừa thu với anh Phong Nguyen - Chief AI Officer tại FPT Software. Nếu mọi người trong group muốn tìm hiểu thêm về Al, ChatGPT, và FPT thì có thể check it out ở đây ạ:
Youtube: https://youtu.be/UhP417Xn-L0
Spotify: https://open.spotify.com/episode/5tiEqSwcZALcJ6Z6OP4T18?si=KJcNKw7sTi2zCaDjh7HzVw
Apple Podcast: https://podcasts.apple.com/us/podcast/forward-vietnam-podcast/id1653799053?i=1000611506073
Forward Vietnam Podcast là nơi chúng mình bàn luận và chia sẻ tới cộng đồng những cuộc thảo luận về công việc, tài chính, kinh doanh, công nghệ và cuộc sống của các bạn trẻ từ Việt Nam. Các bạn có thể tìm hiểu thêm về podcast của bọn mình tại đường link dưới đây nha. Chúng mình rất mong nhận được sự phản hồi từ mọi người nhé!
https://linktr.ee/forwardvietnampodcast","['#sharing', '#machine_learning']","['hello', 'phép', 'tập', 'podcast', 'episode', 'forward', 'vietnam', 'podcast', 'bọn', 'thu phong', 'nguyen', 'chief', 'officer', 'fpt', 'software', 'group al', 'chatgpt', 'fpt thể', 'check', 'it', 'out', 'youtube', 'spotify', 'apple', 'podcast', 'forward', 'vietnam podcast', 'bàn luận', 'cộng đồng', 'thảo luận', 'công tài', 'kinh doanh', 'công nghệ', 'sống', 'trẻ', 'việt nam thể', 'podcast', 'bọn', 'đường', 'link nha', 'mong', 'phản hồi']"
1040,"Chào mọi người, hiện em là thạc sỹ ngôn ngữ học, e đang tìm hiểu về ứng dụng ngôn ngữ vào khoa học máy tính, e có thấy mảng xử lí ngôn ngữ tự nhiên (NLP) thì kết hợp cả kiến thức về ngôn ngữ học và máy tính. Do em chưa có kiến thức gì về ngành khoa học máy tính, các anh/ chị cho em hỏi đối với người chưa có nền tảng IT như em thì nên bắt đầu học từ đâu và những mảng nào trong ngành có thể ứng dụng được kiến thức chuyên sâu về ngôn ngữ, ngữ âm được ạ. Em cám ơn ạ","['#Q&A', '#nlp']","['chào', 'hiện', 'thạc sỹ', 'ngôn ngữ', 'học', 'e ứng dụng', 'ngôn ngữ', 'khoa học', 'máy', 'e mảng', 'xử lí', 'ngôn ngữ nhiên', 'nlp', 'kết hợp', 'kiến thức', 'ngôn ngữ', 'học máy', 'kiến thức', 'ngành', 'khoa học', 'máy', 'đối tảng', 'it', 'học', 'mảng', 'ngành thể', 'ứng dụng', 'kiến thức', 'chuyên sâu', 'ngôn ngữ ngữ âm', 'cám', 'ơn']"
1041,"Các bạn vui lòng đăng tin tuyển sinh, tuyển dụng, sự kiện tháng 04/2023 vào comment của post này.",['#sharing'],"['vui', 'đăng tuyển sinh', 'tuyển dụng', 'kiện', '04', '2023', 'comment', 'post']"
1042,"Có thể câu hỏi đã cũ nhưng mà các bác cho em hỏi với là chi tiết cách xác định Anchor box trong YOLO với ạ ! không thì bác nào có tài liệu hay cho em xin đọc với, chứ em đọc miết mà những câu trả lời chưa làm em thấy thỏa mãn hic !
P/S: Em cảm ơn và ghi nhận tất cả các ý kiến đóng góp từ mọi người ạ","['#Q&A', '#deep_learning']","['thể', 'cũ', 'chi tiết', 'xác định', 'anchor', 'box', 'yolo', 'tài liệu', 'đọc', 'đọc', 'miết', 'câu', 'thỏa', 'mãn', 'hic', 'p', 's', 'ghi', 'tất kiến', 'đóng góp']"
1043,"MLOpsVN tiếp tục tổ chức seminar FREE về công nghệ search hay được sử dụng trong các hệ thống khuyến nghị (recommendation system) vào tối thứ 5 tuần này, mời các bác quan tâm đăng ký tham gia ạ 😁",['#webinar'],"['mlopsvn', 'tổ chức', 'seminar free', 'công nghệ', 'search', 'hệ thống', 'khuyến nghị', 'recommendation system', 'tối', '5', 'tuần', 'mời', 'đăng ký', 'tham gia']"
1044,"Xin chào mọi người, mấy ngày nay e bắt đầu tìm hiểu về Transformer model và e cũng đã tìm đọc các blog để xem kĩ hơn về các thuật toán của nó nhưng mà e thấy có khá ít blog bằng Tiếng Việt nói đến . Vậy nên trong quá trình tìm hiểu, e đã viết 1 bài viết nói chi tiết từng bước một số thuật toán cơ bản của Transformer model theo cái cách mà e đã hiểu . Bởi vì e cũng mới học nên sự nhầm lẫn về kiến thức sẽ xảy ra nên e hy vọng sẽ nhận được phản hồi của mn ạ @@ e cảm ơn ạ !","['#sharing', '#deep_learning']","['chào', 'mấy', 'e', 'transformer', 'model e', 'đọc', 'blog kĩ thuật', 'toán', 'e blog', 'tiếng', 'việt', 'trình', 'e', 'viết', '1', 'viết', 'chi tiết', 'thuật toán', 'transformer', 'model', 'e', 'e học', 'nhầm lẫn', 'kiến thức', 'xảy', 'e', 'hy vọng', 'phản hồi', 'mn', 'e']"
1045,"MLOps Marathon là cuộc thi về MLOps đầu tiên được tổ chức tại Việt Nam nhằm tạo sân chơi cho các đội vừa xây dựng các AI/ML model vừa triển khai và vận hành nó trên môi trường production.
Không chỉ vậy, giải nhất có giá trị lên tới 100 triệu đồng, đăng ký tham gia thôi nào mọi người ơi 🥳",['#sharing'],"['mlops', 'marathon', 'thi mlops', 'tổ chức', 'việt nam', 'sân', 'đội', 'xây dựng', 'ml', 'model', 'triển khai', 'vận hành', 'môi trường', 'production', 'giải', '100', 'triệu', 'đồng', 'đăng ký', 'tham gia']"
1046,"[ Hỏi về thư viện Python] Mình đang làm bài toán ước lượng phân bố của P(Y |X), với Y là multi dependent/correlated output, và X là multivariate continuous (not categorical) features. Mình muốn tìm thư viện Python mà implement được xác suất theo kiểu :(1) approximate P(Y|X) ~ N(m, S), where off-diagonal entries are not zeros hoặc là có thể sample được Y~ P(Y|X).
Đây là bài toán Bayesan multi-dependent output regression. Tuy nhiên mấy thư viện như Gaussian process ở sklearn thì hiện tại implementation, treat các output independent với nha","['#Q&A', '#math', '#python']","['thư viện', 'python toán ước', 'phân bố', 'p y', 'x', 'y multi', 'dependent', 'correlated', 'output', 'x', 'multivariate', 'continuous', 'not', 'categorical', 'features', 'thư viện', 'python', 'implement', 'xác suất', 'kiểu', '1', 'approximate', 'p y', 'x', 'n', 'm', 's', 'where', 'offdiagonal', 'entries', 'are', 'not', 'zeros thể', 'sample y', 'p y', 'x', 'toán', 'bayesan', 'multidependent', 'output', 'regression nhiên', 'mấy', 'thư viện', 'gaussian', 'process', 'sklearn', 'implementation', 'treat', 'output', 'independent', 'nha']"
1047,"Hello mọi người!
Mình có bài toán build một regression model để predict target variable có distribution như này. Mình đã thử nhìu cách, dùng SOTA gradient boosted algorithm như LGBM hay XGBoost mà RMSE vẫn rất cao. Theo mình tìm hiểu thì đây là Tweedie Distribution, ko biết có cao nhân nào biết cách giải quyết vấn đề này không ạ?","['#Q&A', '#machine_learning']","['hello toán', 'build', 'regression', 'model', 'predict', 'target', 'variable', 'distribution', 'thử', 'nhìu', 'sota', 'gradient', 'boosted', 'algorithm', 'lgbm', 'xgboost', 'rmse', 'tweedie', 'distribution', 'ko nhân', 'giải quyết']"
1048,"Vì vụ việc này liên quan tới ba thứ: machine learning, Penn State University, và việc đạo văn, tôi thấy cần phải lên tiếng. Hy vọng chưa có bạn nào trong group từng bỏ ra số tiền lớn để theo học tại đây:

https://forum.machinelearningcoban.com/t/mot-vai-nghi-van-ve-vien-ung-dung-toan-hoc-big-data-data-analytics-data-mining/5420","['#sharing', '#machine_learning']","['vụ', 'machine', 'learning', 'penn', 'state', 'university đạo', 'văn tiếng', 'hy vọng', 'group', 'tiền', 'học']"
1049,"#PyTorch Multi-GPUs training trong PyTorch
Chào mọi người. Xin phép hỏi các anh chị có kinh nghiệm về training model bằng PyTorch trên nhiều GPUs. Hiện tại em đang gặp vấn đề khi chạy code trên 1 GPU thì ko sảy ra vấn đề gì, nhưng khi đẩy lên nhiều GPUs thì bị lỗi khi thực hiện backward cho loss. Em xin mô tả code ở ví dụ đơn giản như ảnh bên dưới đây.
Vấn đề này em có tìm kiếm thì biết rằng cho training trên nhiều GPUs thì tương đương có chừng ấy outputs được trả về cùng lúc. Do vậy việc backprop thông qua `loss.backward()` sẽ sảy ra lỗi, do `loss` lúc này là 1 Tensor nhiều chiều (PyTorch chỉ cho phép backward với scalar). Một cách khắc phục em tìm được là sử dụng `loss.sum().backward()` hoặc `loss.mean().backward()`.
Câu hỏi em đặt ra là việc lấy `sum` hoặc lấy `mean` của các losses trên sau đó backward thì có thay đổi bản chất hoặc kết quả của quá trình backpropagation hay không ? Ngoài ra có cách nào khác đơn giản hơn để không phải dùng sum hoặc mean của loss trước khi backward hay không ? Em xin cảm ơn mọi người.","['#Q&A', '#python']","['multigpus', 'training', 'pytorch', 'chào phép', 'kinh nghiệm', 'training', 'model', 'pytorch', 'gpus', 'chạy', 'code', '1', 'gpu', 'ko', 'sảy', 'đẩy', 'gpus', 'lỗi', 'backward', 'loss', 'mô tả', 'code', 'ví dụ', 'đơn giản', 'ảnh', 'kiếm', 'training', 'gpus', 'tương đương', 'chừng', 'outputs', 'backprop', 'thông loss', 'backward', 'sảy', 'lỗi', 'loss', '1', 'tensor', 'chiều', 'pytorch', 'phép', 'backward scalar', 'khắc phục', 'loss', 'sum backward', 'loss', 'mean', 'backward', 'sum mean', 'losses', 'backward chất', 'kết trình', 'backpropagation', 'đơn giản', 'sum mean', 'loss', 'backward']"
1050,5 CÔNG NGHỆ MỚI TRONG DATA ENGINEERING.,['#sharing'],"['5', 'công nghệ', 'data', 'engineering']"
1051,"Chào m.n và a Tiep VuHuu, e đang có bài toán như thế này nhờ m.n giúp đỡ:
Export ra file báo cáo dựa trên câu thoại trên zalo
Ví dụ câu này: ""Em là Văn Thanh, hôm nay 01/01/2023 em đã làm xong task a, b ,c""
Expect: Ngày 01/01/2023, Văn Thanh, task a, b, c: đã xong
Hoặc: ""Chào anh Tuấn, em là Thanh, hôm nay 31/01/2023 e vô trễ nên làm chưa kịp task a, mới xong b, c thôi. Ngoài ra task d e cũng chưa làm""
Expect: Ngày 31/01/2023, Thanh, task b, c: đã xong; task a, d chưa xong
Em bỏ ML 6 năm r nên giờ quên hết, m.n cho e hỏi đây là dạng bài toán gì (e nghĩ là speech to text và data mining, ko biết đúng ko); và có thư viện nào mì ăn liền ko ạ (e prefer Java vì các dự án hiện tại đều viết bằng Java)
Thank m.n","['#Q&A', '#python', '#nlp']","['chào', 'm', 'n', 'a tiep', 'vuhuu', 'e', 'toán', 'm', 'n', 'giúp đỡ', 'export', 'file', 'báo cáo', 'dựa', 'câu thoại', 'zalo', 'ví dụ', 'câu văn', 'hôm', '01', '01', '2023', 'xong', 'task', 'a b', 'c', 'expect', '01', '01', '2023', 'văn task', 'a b', 'c', 'xong', 'chào tuấn', 'hôm', '31', '01', '2023', 'e', 'vô trễ', 'kịp', 'task', 'a', 'xong', 'b', 'c', 'task', 'd', 'e', 'expect', '31', '01', '2023', 'task', 'b', 'c', 'xong', 'task', 'a d', 'xong', 'ml', '6', 'r', 'quên', 'm', 'n', 'e dạng', 'toán', 'e speech', 'to', 'text', 'data', 'mining', 'ko', 'ko', 'thư viện', 'mì', 'liền', 'ko', 'e prefer', 'java', 'dự án', 'viết', 'java', 'thank', 'm', 'n']"
1052,"Chào mn ạ, theo kết quả của giải tích 2 thì nếu tồn tại đạo hàm có hướng tại điểm theta và vector gradient tại theta khác 0 thì kể từ điểm theta hàm y sẽ giảm nhiều nhất theo hướng của vector gradient. Vậy thường hàm lỗi trong học sâu có thoả mãn điều kiện tồn tại đạo hàm có hướng tại mọi điểm không ạ? Nếu không thì với những tính chất nào của mô hình và hàm lỗi thì hàm lỗi sẽ có đạo hàm có hướng tại mọi điểm ạ? Em cảm ơn mọi người","['#Q&A', '#math', '#machine_learning']","['chào', 'mn kết', 'giải tích', '2', 'tồn đạo', 'hàm hướng', 'theta', 'vector', 'gradient', 'theta', '0', 'theta', 'hàm y', 'hướng', 'vector', 'gradient', 'hàm', 'lỗi', 'học', 'sâu thỏa', 'mãn', 'kiện', 'tồn đạo', 'hàm hướng', 'chất', 'mô hình', 'hàm', 'lỗi', 'hàm', 'lỗi', 'đạo', 'hàm', 'hướng']"
1053,#AR và #AI đang thay đổi cuộc chơi!,['#sharing'],[]
1054,"Mình đang tìm hiểu về Mạng MLP và lan truyền ngược
mn cho em hỏi về các biến dạng của lan truyền ngược được không ạ! em tìm trên mạng thì thấy ít tài liệu về nó và hỏi chatgpt thì câu trả lời mỗi lúc mỗi khác ạ! em cảm ơn","['#Q&A', '#machine_learning']","['mạng', 'mlp', 'lan truyền', 'ngược', 'mn', 'biến dạng', 'lan truyền', 'ngược mạng', 'tài liệu', 'chatgpt', 'câu']"
1055,"hello all, cho mình hỏi
ngoài Elastic có engine nào support Search sử dụng ML để cá nhân hóa kết quả k mn?
mình muốn làm chức năng search cho trang tìm kiếm Job sử dụng ML, giả sử user tìm kiếm job PHP ở hà nội, hoặc user click xem các job ở hà nội (không thực hiện search) , thì nó sẽ suggest và đưa các job ở hà nội lên hàng đầu
vì project của mình nhỏ ( search khoảng 1k item thôi ) nên dùng Elastic là hơi thừa, với lại nó ngốn Ram quá, mình chỉ định chạy trên con Vps 1gb RAM thôi",['#Q&A'],"['hello', 'all', 'elastic', 'engine', 'support', 'search', 'ml', 'hóa', 'kết k', 'mn', 'chức năng', 'search trang', 'kiếm', 'job', 'ml', 'giả sử', 'user', 'kiếm', 'job', 'php', 'hà nội', 'user', 'click', 'job', 'hà nội', 'search', 'suggest', 'job', 'hà nội', 'hàng đầu', 'project', 'search', '1', 'k', 'item', 'elastic', 'hơi', 'thừa ngốn', 'ram định', 'chạy', 'vps', '1', 'gb', 'ram']"
1056,AI mới tự phát triển dựa trên Thuyết tiến hóa Darwin.,['#sharing'],"['phát triển', 'dựa thuyết', 'tiến', 'hóa', 'darwin']"
1057,"Xin hỏi có anh/chị/em/bạn nào đang tập trung học cuốn ""Dive into Deep Learning"" ko ạ? Mình muốn tìm kiếm một nhóm bạn cùng học để tiện trao đổi và học hỏi. MXNet thấy hơi khó nhằn. Hi",['#Q&A'],"['học', 'dive', 'into', 'deep', 'learning', 'ko', 'kiếm', 'học tiện', 'trao đổi', 'học', 'mxnet', 'hơi nhằn', 'hi']"
1058,"Cần giúp đỡ về cách sử dụng pretrained model.
Em là software engineer đang làm project trong đó có chức năng về similarity search. Vì không phải dân chuyên AI nên em chỉ học cách dùng pretrained model. Process của em như sau:
1. Dùng pyvi.ViTokenizer để tokenize input
2. Dùng model vinai/phobert-large để encode thành vector:
3. Lưu vector này vào Postgres với extension ankane/pgvector
4. Search vector bằng cosine_distance, provided by pgvector
Mọi thứ khá ổn khi em làm POC, em search bằng những câu hoàn chỉnh như: ""nhà cung cấp mainboard H110i tại HCM"". Nhưng đưa vào sử dụng thì khách hàng query rất vắn tắt kiểu: ""H110i"" và kết quả trả về còn thua cả full text search, thậm chí không match được câu nào có chữ ""H110i"", trong khi search nguyên câu thì lại có.
Expect của em là kể cả khi khách hàng chỉ nhập tên mã sản phẩm thì ít nhất cũng trả về những câu có chứa mã sản phẩm đó.
Em khá bế tắc ở chỗ này, mong được mọi người tư vấn.","['#Q&A', '#nlp', '#deep_learning']","['giúp đỡ', 'pretrained', 'model', 'software', 'engineer', 'project', 'chức năng', 'similarity', 'search', 'dân', 'chuyên học', 'pretrained', 'model', 'process', '1', 'pyvi', 'vitokenizer', 'tokenize', 'input', '2', 'model', 'vinai', 'phobertlarge', 'encode', 'thành', 'vector', '3', 'lưu vector', 'postgres', 'extension', 'ankane', 'pgvector', '4', 'search', 'vector', 'cosine_distance', 'provided', 'by', 'pgvector', 'ổn', 'poc', 'search', 'câu', 'hoàn chỉnh', 'cung mainboard', 'h110i', 'hcm', 'hàng', 'query', 'vắn tắt', 'kiểu', 'h110i', 'kết thua', 'full', 'text', 'search chí', 'match', 'câu', 'chữ', 'h110i', 'search', 'nguyên', 'câu', 'expect', 'hàng', 'nhập mã', 'sản phẩm', 'câu', 'chứa mã', 'sản phẩm', 'bế tắc', 'chỗ', 'mong', 'tư vấn']"
1059,"Xin chào mọi người, em đang làm bài về object detection và đang dùng yolo v8. Mọi người cho em hỏi ở trong phần gắn nhãn thì gắn nhãn kiểu rectangle hay polygon có hiệu quả hơn ạ, và yolo có hỗ trợ detect bounding box dạng polygon không ạ, em xin cảm ơn","['#Q&A', '#cv', '#deep_learning']","['chào', 'object', 'detection', 'yolo', 'v8', 'gắn', 'nhãn', 'gắn', 'nhãn', 'kiểu', 'rectangle', 'polygon hiệu', 'yolo', 'detect', 'bounding', 'box', 'dạng', 'polygon']"
1060,"Chào mọi người ạ, em đang đọc bài viết về PCA của thầy Tiệp. Em có một chỗ thắc mắc là : trong bài viết có một câu thế này ""PCA có thể được coi là phương pháp đi tìm một hệ cơ sở trực chuẩn đóng vai trò một phép xoay, sao cho trong hệ cơ sở mới này, phương sai theo một số chiều nào đó là rất nhỏ, và ta có thể bỏ qua"". Tuy nhiên giả sử em có một ma trận dữ liệu X và một phép xoay ứng với ma trận trực giao U, tức là X = UY. Rõ ràng ma trận hiệp phương sai của X và Y là như nhau, tuy em lại thấy điều này rất phản trực giác. Ví dụ cụ thể như hình bên dưới, rõ ràng khi áp dụng một phép xoay thì phương sai đã bị thay đổi, tuy nhiên trong công thức trên thì ma trận hiệp phương sai là như nhau. Em đã hiểu sai ở đâu vậy ạ.","['#Q&A', '#math', '#machine_learning']","['chào', 'đọc', 'viết', 'pca', 'thầy', 'tiệp', 'chỗ', 'thắc mắc', 'viết', 'câu', 'pca thể', 'coi', 'phương pháp', 'đi', 'hệ sở', 'trực chuẩn', 'đóng', 'vai trò', 'phép', 'xoay hệ', 'sở phương', 'sai', 'chiều', 'ta', 'thể nhiên', 'giả sử', 'ma', 'trận liệu', 'x', 'phép', 'xoay ứng', 'ma trận', 'trực', 'giao u', 'tức', 'x', 'uy ràng', 'ma trận', 'hiệp phương', 'sai', 'x', 'y phản', 'trực giác', 'ví dụ', 'hình ràng', 'áp dụng', 'phép', 'xoay phương', 'sai nhiên', 'công thức', 'ma trận', 'hiệp phương', 'sai', 'sai']"
1061,"TƯƠNG LAI CỦA TRÍ TUỆ NHÂN TẠO TẠO SINH 2023 - NIC
Thân mời a Tiệp cùng các bạn bên Forum machine learning cơ bản tới tham gia sự kiện: "" The future of Generative AI 2023"" do bên NIC tổ chức.
Trung tâm Đổi mới sáng tạo Quốc gia (NIC), Bộ Kế hoạch và Đầu tư phối hợp với Mạng lưới Đổi mới sáng tạo Việt Nam tại Thung lũng Silicon tổ chức hội thảo “Tương lai của sự sáng tạo từ công nghệ AI 2023”.
Hội thảo có sự góp mặt của các chuyên gia AI hàng đầu từ Thung lũng Silicon và Việt Nam, dự kiến thu hút được sự quan tâm đáng kể từ các nhà lãnh đạo, nhà nghiên cứu và những người đam mê ngành AI trên toàn thế giới, mang đến cơ hội duy nhất để kết nối với các công ty công nghệ và tài năng hàng đầu của Việt Nam và Hoa Kỳ.
Anh Kim Pham - Cohost AI
Anh Hung Tran - GotIt AI
Chị Tâm Lê - Turing
Anh Phong Nguyen FPT AI
Anh Võ Minh Tuệ - Kỹ sư AI
Chị Lan Shuezhao - BasisSet
Ngoài ra, với mục đích mang đến cho người tham dự cơ hội trao đổi trực tiếp với đại diện các công ty công nghệ từ Silicon Valley, các xu hướng mới nhất và cách áp dụng AI để cải thiện hoạt động kinh doanh, phát triển thị trường.
Thời gian: 8:30 - 12:00 ngày 20/04/2023
Link đăng ký: bit.ly/cohost-nic
Sự kiện Online qua Zoom và Offline tại VP NIC số 7 Tôn Thất Thuyết, Cầu Giấy, Hà Nội.
 — với Hung Tran và 4 người khác.","['#sharing', '#webinar']","['tương lai', 'trí tuệ', 'nhân sinh', '2023', 'nic thân', 'mời', 'a tiệp', 'forum', 'machine', 'learning', 'tham gia', 'kiện', 'the', 'future', 'of generative', '2023', 'nic', 'tổ chức', 'trung tâm', 'đổi', 'quốc gia', 'nic', 'kế hoạch', 'đầu tư', 'phối hợp', 'mạng lưới', 'đổi', 'việt nam', 'thung lũng', 'silicon', 'tổ chức', 'hội thảo', 'tương lai', 'công nghệ', '2023', 'hội thảo', 'góp', 'mặt', 'chuyên gia', 'hàng đầu', 'thung lũng', 'silicon', 'việt nam', 'dự kiến', 'thu hút', 'lãnh đạo', 'nghiên cứu', 'đam mê', 'ngành', 'toàn giới', 'hội', 'kết nối', 'công ty', 'công nghệ', 'tài năng', 'hàng đầu', 'việt nam', 'hoa', 'kỳ kim', 'pham', 'cohost', 'hung tran', 'gotit tâm', 'lê turing', 'phong nguyen', 'fpt', 'võ minh tuệ', 'kỹ sư', 'lan', 'shuezhao', 'basisset', 'mục đích', 'tham dự', 'hội', 'trao đổi', 'đại diện', 'công ty', 'công nghệ', 'silicon', 'valley', 'xu hướng', 'áp dụng', 'cải thiện', 'hoạt động', 'kinh doanh', 'phát triển', 'thị trường', '8', '30', '12', '00', '20', '04', '2023', 'link', 'đăng ký', 'kiện', 'online', 'zoom', 'offline', 'vp', 'nic', '7', 'tôn', 'thất thuyết', 'cầu', 'giấy', 'hà nội', 'hung', 'tran', '4']"
1062,"Seminar tiếp theo tổ chức bởi MLOpsVN với chủ đề Model Optimization sẽ diễn ra online lúc 8h tối thứ 5 tuần này, mời cả nhà đăng ký tham gia nếu quan tâm ạ 😁","['#sharing', '#webinar']","['seminar', 'tiếp', 'tổ chức', 'mlopsvn', 'chủ đề', 'model', 'optimization', 'diễn', 'online', '8', 'h', 'tối', '5', 'tuần', 'mời', 'đăng ký', 'tham gia']"
1063,"Mọi người cho em hỏi tại sao accuracy_score của decision tree lại cao hơn cả Random Forest vậy ạ?
code: https://github.com/akirayorunoe/MLLearning/blob/main/SONAR%20Rock%20vs%20Mine%20Prediction/rock_vs_mine_score.py","['#Q&A', '#machine_learning']","['accuracy_score', 'decision', 'tree', 'random', 'forest', 'code']"
1064,"Hello all, mình đang tìm thông tin về ranh giới lat/long chi tiết của từng tỉnh/huyện/xã ở VN cập nhật mới nhất. Check trang https://gadm.org/download_country.html rồi chọn VN thì có đây đủ thông tin, nhưng thông tin hơi cũ, 1 số nơi ở VN đã xác nhập, đổi tên như Thành Phố Thủ Đức thì ko có. Nên lên đây nhờ mọi người, nếu ai có data mới nhất thì share giúp mình với. Many thanks.","['#Q&A', '#data']","['hello', 'all', 'thông', 'ranh giới', 'lat', 'long', 'chi tiết', 'tỉnh', 'huyện', 'xã', 'vn', 'cập nhật', 'check', 'trang', 'vn', 'thông', 'thông', 'hơi', 'cũ', '1', 'vn', 'xác', 'nhập', 'đổi', 'thành phố', 'thủ đức', 'ko', 'data', 'share', 'giúp', 'many', 'thanks']"
1065,"Xin chào mọi người!
Mình đang phát triển một tool gán nhãn dữ liệu mới base trên LabelMe và mô hình Segment Anything mới nhất của Facebook.
Xin phép được chia sẻ đến toàn thể nhóm mình để xin gạch đá và comment để tiếp tục cải tiến.
- Link: https://github.com/vietanhdev/anylabeling
- Demo: https://www.youtube.com/watch?v=5iQSGL7ebXE",['#sharing'],"['chào', 'phát triển', 'tool', 'gán', 'nhãn liệu', 'base labelme', 'mô hình', 'segment', 'anything', 'facebook phép', 'toàn thể', 'gạch đá', 'comment', 'cải tiến', 'link', 'demo']"
1066,"Em chào mọi người, Hiện tại, em vừa học xong 2 machine learning và deep learning specializations của thầy Andrew Ng. Mọi người có thể gợi ý cho em một số project áp dụng kiến thức đã học và học tiếp những kiến thức gì cho thị giác máy tính được không ạ. Em cảm ơn mọi người",['#Q&A'],"['chào', 'học', 'xong', '2', 'machine', 'learning', 'deep', 'learning', 'specializations', 'thầy', 'andrew', 'ng thể', 'gợi project', 'áp dụng', 'kiến thức', 'học học', 'tiếp', 'kiến thức', 'thị giác', 'máy']"
1067,"Một thông tin mà mình cho là quan trọng nếu bạn nào muốn sử dụng mô hình ngôn lớn (LLM) vào việc phát triển sản phẩm thương mại.
Trích nguồn:","['#sharing', '#nlp']","['thông', 'mô hình', 'ngôn llm', 'phát triển', 'sản phẩm', 'thương mại', 'trích']"
1068,"Nếu bạn hỏi tôi sau những hào quang ChatGPT, GPT-4 thì tiếp theo sẽ là gì, tôi sẽ trả lời là AutoGPT, với khoảng 30.000 sao ở repo trên Github.
Với AutoGPT các prompt sẽ được liên kết với nhau tạo ra một agents, có thể lên suy nghĩ, lên kế hoạch, thực hiện từng bước một và đạt được mục tiêu. Ví dụ, bạn hỏi cách tạo một startup với 100$ funding, thay vì trả lời trực tiếp, AutoGPT sẽ lên plan:
1. Research low-cost business models that require minimal funding.
2. Identify potential target markets and their needs.
3. Develop a lean MVP and test with target market to validate demand.
Sau đó, với mỗi task mô hình GPT sẽ sinh ra các câu trả lời dựa vào thông tin trên internet, và có thể sẽ có các task nhỏ được break down ra nữa. Cuối cùng nó sẽ tổng hợp lại và cho ra kết quả cuối cùng. Và tất cả đều tự động ^^","['#sharing', '#deep_learning', '#nlp']","['hào quang', 'chatgpt', 'gpt4', 'tiếp', 'autogpt', '30', '000', 'repo', 'github', 'autogpt', 'prompt', 'liên kết', 'agents thể', 'suy kế hoạch', 'mục tiêu', 'ví dụ', 'startup', '100', 'funding', 'thay', 'autogpt', 'plan', '1', 'research lowcost', 'business', 'models', 'that', 'require', 'minimal', 'funding', '2', 'identify', 'potential', 'target markets', 'and', 'their', 'needs', '3', 'develop', 'a', 'lean mvp', 'and test', 'with', 'target', 'market', 'to', 'validate', 'demand', 'task', 'mô hình', 'gpt sinh', 'câu', 'dựa', 'thông', 'internet thể', 'task', 'break down', 'tổng hợp', 'kết', 'tất động']"
1069,"Hi mọi người, hôm nay mình muốn chia sẻ một tool khá hay ứng dụng của chatgpt/LLM được phát triển bởi CNext, giúp hỗ trợ người dùng trả lời câu hỏi, tìm insight từ dữ liệu bằng ngôn ngữ tự nhiên.
Theo mình thấy CNext hoạt động khá ấn tưởng, dù bạn có kiến thức về lập trình hay không thì một số task yêu cầu phức tạp bạn chỉ cần mô tả ý tưởng của mình CNext có thể hỗ trợ bạn triển khai ý tưởng đó trên dữ liệu của bạn.
Mình thấy tool có khá nhiều api hỗ trợ:
Import data: Tải lên một file dưới định dạng .csv (đây sẽ là file bạn mong muốn phân tích và tìm insight)
Table ops: Thao tác xử lý dữ liệu trên các trường dữ liệu
Google search: cho phép bạn search thông tin trên google và trả về định dạng json dễ dàng để khai thác dữ liệu
Twitter search hoặc Twitter Entities: Cho phép lấy thông tin trên twitter (rất phù hợp trong việc phân tích một trend hoặc một sản phẩm được giới thiệu trên twitter, giúp người dùng có thể theo dõi mức độ quan tâm hoặc thái độ của mọi người đối với tweet của mình
Plotting: Cho phép visualize dữ liệu, design biểu đồ thông qua ý tưởng ngôn ngữ tự nhiên nhất có thể
Ngoài ra còn một số api khác giúp cho các bạn HR có thể tìm kiếm ứng viên trên linkedin phù hợp với tiêu chí của mọi người đặt ra,...
Một số hướng dẫn và ví dụ bạn có thể xem ở đây: https://docs.cnext.io/sample-playbooks
https://twitter.com/cnextdotio
Dưới đây là một demo khá thú vị về cách CNext xử lý dữ liệu. Hy vọng bài viết hữu ích với mọi người. Chúc mọi người một ngày vui vẻ 🤗","['#sharing', '#deep_learning', '#nlp']","['hi hôm', 'tool', 'ứng dụng', 'chatgpt llm', 'phát triển', 'cnext', 'giúp', 'insight liệu', 'ngôn ngữ nhiên', 'cnext', 'hoạt động', 'ấn tưởng', 'kiến thức', 'lập trình', 'task', 'phức tạp', 'mô tả', 'tưởng', 'cnext thể', 'triển khai', 'tưởng liệu', 'tool', 'api', 'import', 'data tải', 'file định', 'dạng', 'csv', 'file mong', 'phân tích', 'insight', 'table', 'ops', 'thao tác liệu', 'trường liệu', 'google', 'search phép', 'search', 'thông', 'google định', 'dạng', 'json dàng', 'khai thác', 'liệu', 'twitter', 'search', 'twitter', 'entities phép', 'thông twitter', 'phân tích', 'trend', 'sản phẩm', 'giới thiệu', 'twitter', 'giúp thể', 'dõi độ', 'thái độ', 'đối tweet', 'plotting phép', 'visualize liệu', 'design biểu đồ', 'thông tưởng', 'ngôn ngữ nhiên thể', 'api', 'giúp', 'hr thể', 'kiếm', 'ứng viên', 'linkedin', 'tiêu chí', 'hướng', 'ví dụ thể', 'demo', 'thú vị', 'cnext liệu', 'hy vọng', 'viết', 'hữu ích', 'chúc', 'vui vẻ']"
1070,"Hello mọi người, việc các công cụ như ChatGPT và Midjourney trở nên phổ biến trong thời gian gần đây đã gây ra vô số ý kiến trái chiều trong nhiều lĩnh vực khác nhau. Trong bài viết này mình phân tích hai khía cạnh về sự sụt giảm chất lượng và số lượng content tạo ra bởi con người cùng với việc thiếu dữ liệu dùng cho training generative model trong tương lai. Nếu mọi người có insight về sự ảnh hưởng của AI trong các lĩnh vực như design hoặc content writing thì cũng có thể cùng chia sẻ nhé.","['#sharing', '#deep_learning']","['hello', 'công cụ', 'chatgpt', 'midjourney', 'trở', 'phổ biến', 'vô kiến', 'trái', 'chiều', 'lĩnh vực', 'viết', 'phân tích', 'hai', 'khía cạnh', 'sụt', 'chất', 'content liệu', 'training', 'generative', 'model', 'tương lai', 'insight', 'ảnh hưởng', 'lĩnh vực', 'design', 'content', 'writing thể']"
1071,"Gần đây (r-)Polars nổi lên như 1 thư viện cạnh tranh với Pandas/Tidyverse về tốc độ xử lý dữ liệu lớn dạng bảng. Trong repository (https://github.com/linhduongtuan/Polars_vs_Pandas) này của mình, mình sẽ thử tốc độ dữ liệu lớn có tên là 69M_reddit_account.csv. Dữ liệu này có 69 triệu dòng và 7 biến số (cột). Khi giải nén file *gz thành *csv nó nặng ~3.3Gb. Mình sẽ so sánh hiệu năng đọc các files này (định dạng CSV, Parquet, và Feather) bằng Polars so với Pandas (version 2) sử dụng NumPy  và PyArrow backends.

Kết quả cho thấy:
Polars thắng trong tất cả các thí nghiệm;
Pandas với PyArrow backend tiệm cận tốc độ Polars, và nhanh hơn đáng kể khi đọc files *parquet và *feather (nhưng lại chậm hơn với *csv).
Lời tạm kết:
Mình nghĩ Polars đã và đang là đối thủ lớn của Pandas;
Rust sẽ là ngôn ngôn lập trình rất thú vị và đáng chúng ta đầu tư thời gian để học.
Dữ liệu tải tại đây (https://files.pushshift.io/reddit/69M_reddit_accounts.csv.gz)
Các bạn có thể tham khảo kết quả thí nghiệm của mình tại đây (https://github.com/linhduongtuan/Polars_vs_Pandas) ","['#sharing', '#python']","['r', 'polars', 'nổi', '1', 'thư viện', 'cạnh tranh', 'pandas', 'tidyverse', 'tốc độ', 'liệu', 'dạng', 'bảng', 'repository', 'thử', 'tốc độ', 'liệu', '69', 'm_reddit_account', 'csv liệu', '69', 'triệu', 'dòng', '7', 'biến', 'cột', 'giải', 'nén', 'file', 'gz', 'thành', 'csv', '3', '3', 'gb', 'sánh', 'hiệu năng', 'đọc', 'files định', 'dạng', 'csv', 'parquet', 'feather', 'polars', 'pandas', 'version', '2', 'numpy', 'pyarrow', 'backends', 'kết polars', 'thắng', 'tất thí nghiệm', 'pandas', 'pyarrow', 'backend', 'tiệm', 'cận', 'tốc độ', 'polars', 'đọc', 'files', 'parquet', 'feather', 'chậm', 'csv', 'tạm', 'kết polars', 'đối thủ', 'pandas', 'rust ngôn ngôn', 'lập trình', 'thú vị', 'ta', 'đầu tư', 'học liệu', 'tải thể', 'tham khảo', 'kết', 'thí nghiệm']"
1072,"[MLOps] 
Xin chào mọi người, hiện tại mình đang làm Data Scientist cho 1 công ty Big 4 ở Bắc Mỹ. Do mình muốn học thêm mảng MLOps để chuẩn bị đổi việc, nên có vài thắc mắc, rất mong được mọi người chỉ giúp ạ.
1. Với working directory như hình, thì mình có vẻ như đang dockerize chưa đúng, mọi người có thể xem giúp mình với ạ. Vì khi mình chạy app từ docker image (  Network URL: http://172.17.0.4:8501,   External URL: http://76.64.53.12:8501) thì browser không load được.
2. Có cách nào để khi chạy app thì tự động mở browser luôn thay vì phải click tay vào URL không ạ?
3. Sau khi Dockerized xong, mọi người có suggest gì về Cloud để mình deploy app này lên free và làm portfolio để mình xin việc.
Mình cảm ơn nhiều ạ. Và rất mong được kết bạn với mọi người để học hỏi.",['#Q&A'],"['mlops', 'chào data', 'scientist', '1', 'công ty', 'big', '4', 'bắc', 'mỹ học', 'mảng', 'mlops', 'chuẩn đổi', 'thắc mắc', 'mong', 'giúp', '1', 'working', 'directory', 'hình vẻ', 'dockerize thể', 'giúp', 'chạy', 'app', 'docker', 'image', 'network', 'url', 'http', '172', '17', '0', '4', '8501', 'external', 'url', 'http', '76', '64', '53', '12', '8501', 'browser', 'load', '2', 'chạy', 'app động', 'browser', 'thay', 'click', 'url', '3', 'dockerized', 'xong', 'suggest', 'cloud', 'deploy', 'app', 'free', 'portfolio', 'mong kết', 'học']"
1073,"Em chào mọi người, em cần tìm gpu để train dữ liệu khoảng 70gb, ảnh là dạng ảnh 3d google map nên rất nặng ạ. Xin mọi người tư vấn cho em về google driver và google colab ạ",['#Q&A'],"['chào', 'gpu', 'train liệu', '70', 'gb', 'ảnh', 'dạng', 'ảnh', '3', 'd', 'google', 'map', 'tư vấn', 'google', 'driver', 'google', 'colab']"
1074,"[OpenSource] VnGPT - Mã nguồn mở giúp dựng server ChatGPT riêng trên máy cá nhân cùng nhiều ứng dụng AI thú vị khác

Lâu lâu mới lại có project opensource để chia sẻ cùng các anh em trong group. Sản phẩm này cũng khá đơn giản, sử dụng Gradio để call API ChatGPT, Whisper từ OpenAI và tiếp tục mở rộng, kết nối luồng với nhau để tạo ra giao diện tiện dụng cuối cho người dùng. Phù hợp để các anh em nghiên cứu về AI tự dựng server để test ChatGPT, hoặc dựng server ChatGPT dùng riêng cho bạn bè, gia đình, công ty. 

Còn ý nghĩa sâu xa của project thì mời các anh em đọc tại đây:
https://www.facebook.com/photo/?fbid=159818203592346&set=a.116382481269252

Những ưu điểm của công cụ này:
Mã nguồn mở và miễn phí
Cài đặt dễ dàng trên máy tính cá nhân (Windows, MacOS, Ubuntu) chỉ với một click
Tích hợp sẵn: ChatGPT, Whisper...và liên tục bổ sung các dịch vụ AI mới
Tự setup server riêng để sử dụng cá nhân, hoặc chia sẻ qua Internet để bạn bè, người thân cùng sử dụng
Cấu hình các tham số nâng cao, giúp mở khóa nhiều chức năng mới cho ChatGPT, Whisper, VnAlert...

VnGPT hiện được cam kết duy trì quản lý, phát triển bởi AIV Group. Tuy nhiên là sản phẩm nguồn mở nên các anh em clone về thoải mái. Nếu có thể commit back trở lại mã nguồn gốc thì càng tốt. 
-------------------------
👉 Dùng thử VnGPT tại: https://vngpt.aivgroup.vn
👉 Tải và cài đặt VnGPT tại: https://github.com/AIV-Group/VnGPT-CE
👉 Cộng đồng người dùng & phát triển VnGPT: Cộng đồng người dùng VnGPT
👉 Hỗ trợ sử dụng trực tiếp trên Zalo: Hỏi đáp cách dùng VnGPT","['#sharing', '#nlp']","['opensource', 'vngpt mã', 'giúp', 'dựng', 'server', 'chatgpt', 'máy', 'ứng dụng', 'thú vị', 'project', 'opensource', 'group', 'sản phẩm', 'đơn giản', 'gradio', 'call', 'api', 'chatgpt', 'whisper', 'openai', 'rộng', 'kết nối', 'luồng', 'giao diện', 'tiện dụng', 'nghiên cứu', 'dựng', 'server', 'test', 'chatgpt', 'dựng', 'server', 'chatgpt bè', 'gia đình', 'công ty', 'nghĩa', 'sâu project', 'mời', 'đọc', 'ưu công cụ', 'mã', 'miễn phí', 'cài dàng', 'máy', 'windows', 'macos', 'ubuntu', 'click tích', 'hợp', 'sẵn', 'chatgpt', 'whisper', 'liên tục', 'bổ sung', 'dịch vụ', 'setup', 'server', 'internet', 'bè', 'thân cấu hình', 'tham nâng', 'giúp', 'khóa', 'chức năng', 'chatgpt', 'whisper', 'vnalert', 'vngpt', 'hiện', 'cam kết trì', 'quản lý', 'phát triển', 'aiv', 'group nhiên', 'sản phẩm', 'clone', 'thoải mái thể', 'commit', 'back', 'trở mã', 'gốc', 'thử', 'vngpt tải', 'cài', 'vngpt', 'cộng đồng', 'phát triển', 'vngpt', 'cộng đồng', 'vngpt', 'zalo', 'đáp', 'vngpt']"
1075,"Tiếp tục chủ đề chatbot. Lần nhóm mình tiếp cận finetune cho model Bloomz-7b1-mt, kết hợp với Low-rank adaptation cho cơ sở dữ liệu hỏi đáp với bác sĩ về bệnh tật (bằng tiếng Anh). Bài báo gốc tại đây https://arxiv.org/pdf/2303.14070.pdf.
Lý do nhóm mình chọn Bloomz-7b1-mt làm model gốc là vấn đề bản quyền mở của BigScience. Nó khác với những ràng buộc bản quyền cho LLaMA. Và Bloom được train trên dataset có tên là ROOT có kha khá dữ liệu là tiếng Việt. Nó có thể giúp các bạn finetune thêm bằng tiếng Việt thuận lợi hơn nếu muốn.
Kết quả prompt mình có so sánh trong source code của nhóm mình. Mình đặt tên cho finetuned model là Doctor with Bloom (tạm dịch bác sĩ với hoa). Đây là source code của mình.  https://github.com/linhduongtuan/doctorwithbloom
Hi vọng nó hữu ích với mọi người. Và xin đừng tiếc **** nếu bạn thích repository này.
 — với Phạm Ngọc Ninh.","['#sharing', '#deep_learning']","['chủ đề', 'chatbot', 'tiếp cận', 'finetune', 'model', 'bloomz7b1mt', 'kết hợp', 'lowrank', 'adaptation', 'sở liệu', 'đáp sĩ', 'bệnh tật', 'tiếng', 'báo', 'gốc', 'https', 'arxiv', 'org', 'pdf', '2303', '14070', 'pdf lý', 'bloomz7b1mt', 'model', 'gốc', 'quyền', 'bigscience', 'ràng buộc', 'quyền', 'llama', 'bloom', 'train', 'dataset', 'root', 'kha liệu', 'tiếng', 'việt thể', 'giúp', 'finetune', 'tiếng', 'việt', 'thuận lợi', 'kết', 'prompt', 'sánh', 'source', 'code', 'finetuned', 'model', 'doctor', 'with', 'bloom', 'tạm', 'dịch sĩ', 'hoa', 'source code', 'hi vọng', 'hữu ích', 'đừng', 'tiếc', 'repository phạm', 'ngọc ninh']"
1076,Em đang muốn build server có khoảng 10 GPU. Các anh chị cho em hỏi mua GPU và mother board ở Hà Nội ở đâu ạ? Em nên mua GPU và mother board loại nào ạ.,['#sharing'],"['build', 'server', '10', 'gpu', 'mua', 'gpu', 'mother', 'board', 'hà nội', 'mua', 'gpu', 'mother', 'board']"
1077,"Dạ em xin chào mọi người!
Mọi người có các bộ data liên quan đến các biểu hiện trên khuôn mặt không ạ? Ví dụ các bộ data để phân biệt các biểu hiện sau:
1- Dữ liệu khuôn mặt của người bị ốm (bị bệnh/ mệt mỏi)
2- Dữ liệu khuôn mặt của người bị đau đớn (khó chịu)
Em xin cảm ơn mọi người ạ. Chúc mọi người tuần mới làm việc hiệu quả .","['#Q&A', '#data']","['chào', 'data', 'biểu hiện', 'khuôn mặt', 'ví dụ', 'data', 'phân biệt', 'biểu hiện', '1', 'liệu', 'khuôn mặt', 'ốm bệnh', 'mệt mỏi', '2', 'liệu', 'khuôn mặt', 'đau đớn', 'chúc', 'tuần hiệu']"
1078,"[Nhờ giúp đỡ về dự báo thời tiết Timeseries]
Chào mọi người, hiện tại em đang làm project dự báo thời tiết và em đang có bảng dữ liệu như hình (có thể làm thêm các feild khác nếu cần để training model).
Cụ thể là:
-Mỗi 1h, hệ thống sẽ thu dữ liệu Nhiệt độ, độ ẩm, áp suất từ cảm biến và đưa lên database MySQL sau đó đưa lên web như hình. Sau đó toàn bộ dữ liệu của hệ thống sẽ được sử dụng để train model và đưa ra dự báo.
Em muốn dự báo thời tiết trong 7 ngày tới (time series) nhưng chưa biết tìm hiểu từ đâu, hay dùng model gì (em mới tìm hiểu về AI ML). Em xin cảm ơn ạ 🥹🥹🥹","['#Q&A', '#data', '#machine_learning']","['giúp đỡ', 'dự báo', 'thời tiết', 'timeseries', 'chào project', 'dự báo', 'thời tiết', 'bảng liệu', 'hình thể', 'feild', 'training', 'model', '1', 'h', 'hệ thống', 'thu liệu', 'nhiệt độ', 'độ ẩm', 'áp suất', 'cảm biến', 'database', 'mysql', 'web hình', 'toàn liệu', 'hệ thống', 'train', 'model', 'dự báo', 'dự báo', 'thời tiết', '7', 'time', 'series', 'model', 'ml']"
1079,"Báo cáo 150 trang bởi team Microsofts về GPT-4.
Với GPT-4, từ ""GPT có thể làm được gì"" đã chuyển thành ""Có gì mà GPT không làm được"".
Một cách đầy bất ngờ, LLMs đã khiến những người làm AI thấy được một tia sáng trong công cuộc tiếp cận AGI.
https://vuanhtran.substack.com/p/2-sparks-of-artificial-general-intelligence?sd=pf
1 tuần mình sẽ viết 1-2 blogs, mọi người subscribe nhé",['#sharing'],"['báo cáo', '150', 'trang', 'team', 'microsofts', 'gpt4', 'gpt4', 'gpt thể', 'thành', 'gpt', 'llms', 'tia công', 'tiếp cận', 'agi', '1', 'tuần', 'viết', '12', 'blogs', 'subscribe']"
1080,"Chào anh chị ạ, em có một vài thắc mắc về các vị trí nghề nghiệp trong ngành AI.
Về mảng data thì e đã biết một vài vị trí như Data Scientist, Data Analyst, ... Tuy nhiên các vị trí khác - em tạm gọi là mảng AI (làm việc với models, ...) thì e chưa hình dung rõ và chưa biết tên ạ.
Anh chị cho e xin review về các jobs liên quan đến mảng AI (tên vị trí, các tasks khi đi làm) với ạ.
Cảm ơn admin và mng rất nhiều",['#Q&A'],"['chào', 'thắc mắc', 'nghề nghiệp', 'ngành', 'mảng', 'data', 'e', 'data', 'scientist', 'data', 'analyst nhiên', 'tạm', 'gọi', 'mảng', 'models', 'e hình dung', 'e review', 'jobs', 'mảng', 'tasks', 'đi', 'admin', 'mng']"
1081,Em xin phép share một webinar khác diễn ra vào 8h tối nay (30/3) tổ chức bởi MLOpsVN,['#webinar'],"['phép', 'share', 'webinar', 'diễn', '8', 'h', 'tối', '30', '3', 'tổ chức', 'mlopsvn']"
1082,"Xin phép mọi người trong nhóm. Hiện tại em đang chuẩn bị làm đồ án tốt nghiệp hướng của em muốn làm là về human pose, em muốn bài toán hướng đến 1 số ứng dụng như phát hiện người bị đuối nước, người bị ngã cho người già đột quỵ hay trẻ nhỏ, hành vi người tham gia giao thông như chuẩn bị băng qua đường áp dụng cho ôtô. Vì lần đầu tiên em tiếp cận với hướng này không biết những bài toán trên của em có khả thi hay khó khăn nào không em xin phép xin ý kiến mọi người đã từng làm về ứng dụng về hướng này ạ. Em cảm ơn mọi người.","['#Q&A', '#cv']","['phép', 'chuẩn', 'đồ án nghiệp', 'hướng', 'human', 'pose toán', 'hướng', '1', 'ứng dụng', 'phát hiện', 'đuối', 'ngã', 'già', 'đột quỵ', 'trẻ', 'hành vi', 'tham gia', 'giao thông', 'chuẩn', 'băng', 'đường', 'áp dụng', 'ôtô', 'tiếp cận', 'hướng', 'toán', 'khả thi', 'khăn', 'phép kiến', 'ứng dụng', 'hướng']"
1083,"Em chào mọi người ạ,
Mọi người có thể giới thiệu cho em một số paper nổi tiếng, kinh điển cho task Face Verification được không ạ. Kinh điển theo ý em tức là khi nhắc tới task này thì mọi người nghĩ ngay tới paper nào ý ạ.
Em xin chân thành cảm ơn ạ.","['#Q&A', '#cv']","['chào thể', 'giới thiệu', 'paper', 'nổi tiếng', 'kinh điển', 'task', 'face', 'verification', 'kinh điển', 'tức', 'nhắc', 'task', 'paper', 'chân thành']"
1084,"Em chào mọi người,
Em đang cần tìm một encoder model để encode rồi làm clustering. Hiện tại em mới chỉ tìm ra BERT từ năm 2018 là phổ biến nhất. Không biết là có pretrained encoder nào tốt hơn BERT không ạ. Nếu có bài bào nào đánh giá tổng quan các encoder model dùng transformer thì càng tốt ạ","['#Q&A', '#deep_learning']","['chào', 'encoder', 'model', 'encode', 'clustering', 'bert', '2018', 'phổ biến', 'pretrained', 'encoder', 'bert bào', 'tổng quan', 'encoder', 'model', 'transformer']"
1085,"NLP. Chào mọi người ạ. Em mới học và tìm hiểu xử lý về NLP trong tiếng việt. Thầy em cho em một số thư viện khá phổ biến như NLTK. Cho em hỏi là thư việ NLTK có áp dụng được cho tiếng việt không ạ? Em cảm ơn.
Tiện thể em muốn hỏi là xử lý văn bản tiếng việt thì ra trường có cơ hội tìm kiếm việc làm tốt không ạ?","['#Q&A', '#nlp', '#python']","['nlp', 'chào học', 'nlp', 'tiếng', 'việt', 'thầy', 'thư viện', 'phổ biến', 'nltk', 'thư', 'việ nltk', 'áp dụng', 'tiếng', 'việt văn', 'tiếng', 'việt', 'trường', 'hội', 'kiếm']"
1086,"Bất kể ai là người chiến thắng trong cuộc đua AI, thì đây là công ty vẫn ung dung hưởng lợi! Công ty nắm giữ vũ khí tối thượng của công nghệ AI.
#A100 #SmartTechnology #FutureTech",['#sharing'],"['chiến thắng', 'đua', 'công ty', 'ung dung', 'hưởng', 'lợi', 'công ty', 'nắm', 'vũ khí', 'tối thượng', 'công nghệ']"
1087,"Bởi những vấn đề về giới hạn bản quyền của model LLaMA, mình và bạn Phạm Ngọc Ninh đã sử dụng model BLOOM không bị giới hạn bản quyền (bài báo tại đâyhttps://arxiv.org/abs/2211.05100) để train models theo hướng Alpaca-LoRA. Vì BLOOM được train với 2,7% dataset là tiếng Việt (tham khảo tại đây https://huggingface.co/bigscience/bloom). Hơn nữa, mình có thấy Andrej Karpathy khuyên khích nên dùng BLOOM như hình bên dưới. Với những lý do trên, mình và bạn Ninh đã train model BLOOM-56M và BLOOM-7b1 kết hợp với LoRA, cũng như sử dụng dữ liệu Alpaca_data_cleaned.json tại đây (https://github.com/gururise/AlpacaDataCleaned).
Đây là repository mà mình và bạn Ninh đã reimplemnt https://github.com/linhduongtuan/BLOOM-LORA.
Hi vọng cuối tuần có thứ để mua vui với mọi người.
 — với Phạm Ngọc Ninh.","['#sharing', '#deep_learning']","['giới hạn', 'quyền', 'model', 'llama phạm', 'ngọc ninh', 'model', 'bloom', 'giới hạn', 'quyền', 'báo', 'đâyhttps', 'arxiv', 'org', 'abs', '2211', '05100', 'train', 'models', 'hướng', 'alpacalora', 'bloom', 'train', '2', '7', 'dataset', 'tiếng', 'việt', 'tham khảo', 'https', 'huggingface', 'co bigscience', 'bloom', 'andrej', 'karpathy', 'khuyên khích', 'bloom', 'hình lý ninh', 'train', 'model', 'bloom56m', 'bloom7b1', 'kết hợp', 'lora liệu', 'alpaca_data_cleaned', 'json', 'repository ninh', 'reimplemnt', 'https', 'github', 'com', 'linhduongtuan', 'bloomlora', 'hi vọng', 'tuần', 'mua', 'vui phạm', 'ngọc ninh']"
1088,"Chào các bạn.
Mình vừa hoàn thành các jupyter notebook sử dụng pandas và sqlalchemy để mô phỏng MySQL code, hy vọng sẽ giúp ích được ai đó.
Cảm ơn các bạn đã quan tâm ạ.",['#sharing'],"['chào', 'hoàn thành', 'jupyter', 'notebook', 'pandas', 'sqlalchemy', 'mô', 'mysql', 'code', 'hy vọng', 'giúp ích']"
1089,"Xin chào anh em, nhân dịp đang tìm hiểu về Data Visualize nên chia sẻ cùng anh em một công cụ nhỏ. Hi vọng giúp được anh em mới học!","['#sharing', '#data']","['chào', 'data', 'visualize', 'công cụ', 'hi vọng', 'giúp', 'học']"
1090,Mọi người đều biết về sức mạnh vượt trội của GPT-4 trong các bài toán xử lý ngôn ngữ tự nhiên. Nay Microsft mang sức mạnh của GPT-4 lên Github với công cụ GitHub Copilot X. Với lượng dữ liệu (code) khổng lồ trên Github thì AI sẽ hỗ trợ rất nhiều cho lập trình viên trong nhiều công việc khác nhau.,"['#sharing', '#nlp']","['sức trội', 'gpt4 toán', 'ngôn ngữ nhiên', 'microsft', 'sức', 'gpt4', 'github', 'công cụ', 'github', 'copilot', 'x liệu', 'code', 'khổng lồ', 'github', 'lập trình viên', 'công']"
1091,"Sau tiếng vang lớn của ChatGPT, mình thấy có người reimplement lại mô hình này dưới cái tên minChatGPT (sử dụng kiến trúc GPT-2) tại đây https://github.com/ethanyanjiali/minChatGPT. Có lẽ đây là phong cách được định hình bởi Andrej Karpathy, khi Andrej reimplemt mô hình GPT-2 với 2 repos là minGPT và nanoGPT.
Có bạn nào thích thú với ý tưởng này, mình nghĩ hoàn toàn có thể sử dụng các kiến trúc khác như LLaMA, BLOOM, GPT-NEOX,...","['#sharing', '#deep_learning']","['tiếng', 'vang', 'chatgpt', 'reimplement', 'mô hình', 'minchatgpt', 'kiến trúc', 'gpt2', 'https', 'github', 'com', 'ethanyanjiali', 'minchatgpt lẽ', 'phong định hình', 'andrej', 'karpathy', 'andrej', 'reimplemt', 'mô hình', 'gpt2', '2', 'repos', 'mingpt', 'nanogpt thú', 'tưởng thể', 'kiến trúc', 'llama', 'bloom', 'gptneox']"
1092,"Nay mình giới thiệu với mọi người một công cụ hỗ trợ viết code còn thông minh hơn Copilot.
Cursor là một phần mềm để lập trình (IDE) với sự hỗ trợ AI. Hiện tại một số tính năng mà Cursor hỗ trợ: - Write: Sinh code với AI, thông minh hơn Copilot - Diff: Yêu cầu AI sửa và cải tiến đoạn code - Chat: Dạng ChatGPT nhưng hiểu ngữ cảnh của file, project Ngoài ra có các tính năng như: tự động sinh ra comment, test case, xác định vùng code có khả năng bị lỗi, và sửa luôn...",['#sharing'],"['giới thiệu', 'công cụ', 'viết', 'code', 'thông minh', 'copilot', 'cursor mềm', 'lập trình', 'ide năng', 'cursor', 'write sinh', 'code', 'thông minh', 'copilot', 'diff', 'sửa', 'cải tiến', 'đoạn', 'code', 'chat', 'dạng', 'chatgpt ngữ', 'cảnh', 'file', 'project', 'năng động', 'sinh comment', 'test', 'case', 'xác định', 'code', 'khả năng', 'lỗi', 'sửa']"
1093,"Em chào anh chị ạ, em muốn xin review từ các anh chị đã theo học chương trình Khoa học dữ liệu của đại học khoa học tự nhiên hà nội. Vì lý do tài chính và gia đình nên em quyết định theo học thạc sĩ ở Hà Nội thay vì đi du học. Các anh chị thấy chương trình đào tạo và chất lượng giảng dạy thạc sĩ của trường thế nào ạ?
Em cảm ơn anh chị nhiều ạ",['#Q&A'],"['chào', 'review học', 'chương trình', 'khoa học liệu', 'đại học', 'khoa học nhiên', 'hà nội lý', 'tài', 'gia đình', 'quyết định', 'học', 'thạc sĩ', 'hà nội', 'thay', 'đi', 'du học', 'chương trình', 'đào', 'chất', 'giảng dạy', 'thạc sĩ', 'trường']"
1094,"Vừa rồi mình có tham gia challenge Player Contact Detection ở kaggle và may mắn được top1. Mình xin chia sẽ code và solution hi vọng sẽ có ích cho các bạn mới.
Challenge page: https://www.kaggle.com/competitions/nfl-player-contact-detection/leaderboard
Solution: shorturl.at/kJNW0
Source code: https://github.com/nvnnghia/nfl3_1st",['#sharing'],"['tham gia', 'challenge', 'player', 'contact', 'detection', 'kaggle', 'may mắn', 'top1', 'chia', 'code', 'solution', 'hi vọng ích', 'challenge', 'page', 'solution', 'source', 'code']"
1095,"#chatbot
Em chào mọi người ạ,
Hiện tại em đang phải build chatbot cho 1 công ty về tư vấn tâm lý, người ta muốn chatbot có thể đặt nhiều câu hỏi kiểu open-question cho người dùng để hiểu được vấn đề tâm lý của người dùng.
Em đã thử ParlAI và dùng Empathetic Dialogues, thì model khá tốt, thể hiện được sự đồng cảm với người dùng nhưng chưa đặt thêm được câu hỏi cho người dùng. Đây là github link ạ https://github.com/facebookresearch/ParlAI
Em đã thử thêm dataset và train lại model dựa trên trained model, em có để --gpu 1 nhưng lúc ở task manager thì em lại thấy GPU không hoạt động gì, còn CPU và memnory thì tầm 90% - 100% luôn. Nên em chưa thành công train lại model khi dùng ParlAI ạ.
Em sợ build model từ đầu, không dùng pretrained model thì kết quả chưa chắc đã bằng pretrained model. Nên em không biết làm thế nào.
https://dl.acm.org/doi/abs/10.1145/3313831.3376131
Hướng em muốn build chatbot là như bài báo này ạ. Nhưng mà em không tìm thấy code của bài báo này, nên em cũng không biết làm như nào.
Mọi người có thể tư vẫn giúp em, em nên làm gì được không ạ. Em xin chân thành cảm ơn mọi người ạ. 😄🙏","['#sharing', '#Q&A', '#nlp']","['chào', 'build', 'chatbot', '1', 'công ty', 'tư vấn', 'tâm lý', 'ta', 'chatbot thể', 'kiểu', 'openquestion tâm lý', 'thử', 'parlai', 'empathetic', 'dialogues', 'model', 'thể hiện', 'đồng cảm', 'github', 'link', 'thử', 'dataset', 'train', 'model', 'dựa', 'trained', 'model', 'gpu', '1', 'task', 'manager', 'gpu', 'hoạt động', 'cpu', 'memnory', 'tầm', '90', '100', 'thành công', 'train', 'model', 'parlai', 'sợ', 'build', 'model', 'đầu', 'pretrained', 'model', 'kết pretrained', 'model', 'hướng', 'build', 'chatbot', 'báo', 'code', 'báo thể', 'tư giúp', 'chân thành']"
1096,"Chào mọi người ạ, hiện em đang có một project nho nhỏ, em đang imple model SSD để test với dataset là VOC sau đó nếu được kết quả tốt thì chỉnh sửa lại kiến trúc một tí và thử trên một dataset của riêng em. Tuy nhiên em không có chỗ train, máy em không đủ vram, còn colab pro em có nghe nói là chỉ nới rộng thời gian train thôi chứ random ra gpu cũng không ngon lắm. Mà bản pro plus thì em đang là sv nên không đủ điều kiện mua. Vậy nếu em muốn train SSD thì có giải pháp nào cho em không ạ, em cảm ơn mọi người rất nhiều.","['#Q&A', '#deep_learning']","['chào', 'hiện', 'project', 'nho imple', 'model', 'ssd', 'test', 'dataset', 'voc', 'kết chỉnh sửa', 'kiến trúc', 'tí', 'thử', 'dataset nhiên', 'chỗ', 'train', 'máy', 'vram', 'colab', 'pro', 'nới', 'rộng', 'train', 'random', 'gpu', 'ngon', 'lắm', 'pro', 'plus', 'sv', 'kiện', 'mua', 'train', 'ssd', 'giải pháp']"
1097,"Chào mọi người, em là sinh viên năm cuối ngành CNTT trường BK. Tầm tháng 8 năm nay em sẽ tốt nghiệp. Em đang có dự định đi học Master ML/DL ở Úc.
Background của em thì em có GPA tích luỹ tới kì thứ 7 ~ 3.8, ielts 7.0, có nền tảng về thống kê, xử lí, trực quan hoá, handle dữ liệu không cân bằng, nói chung là em có biết cơ bản về khdl, implement các model bằng keras và tf, nhưng mà linear algebra thì hiện tại em quên hết rồi ạ tại học từ năm 1 😞 nhưng mà em có thể tự học lại tại em cũng thích học toán.
Hiện tại em hơi mất định hướng, kiểu các bạn cùng khoá của em (90% không theo hướng ML) đã đi làm rồi ạ, nhưng mà em vẫn chưa đi vì em chưa nhận được offer nào phù hợp. Job ML cho level thấp như em khá ít và khi người ta nghe em nói em chỉ có thể làm đến hết 2023 không thể commit với công ty được người ta cũng không muốn tuyển em í 😞. Em muốn em học Master xong có thể ở đó làm các ngành liên quan đến major của em vài năm rồi mới về nước ạ. Nhưng mà em sợ nếu em không có work experience thì không thể đi làm được ở Úc. Em hi vọng mn có thể cho ý kiến giúp em rằng em nên ở đây làm các job liên quan rồi mới đi học, hay là tốt nghiệp xong em đi luôn ạ? Và không biết là ở Úc thì con đường cho ML có rộng mở không ạ? Em cần chuẩn bị những kiến thức cơ bản nào trước khi em chính thức vào học Master ML không ạ? Em không có vấn đề gì về tài chính, bố mẹ em có thể chu cấp cho em đi học ms liền sau khi em tốt nghiệp bk ạ, chỉ là em thấy các bạn đi làm em áp lực và em đang hoài nghi về chuyện em muốn theo đuổi ML huhu 😞 Em mong mọi người cho em lời khuyên, em cảm ơn mnn",['#Q&A'],"['chào', 'sinh viên', 'ngành', 'cntt trường', 'bk', 'tầm', '8', 'nghiệp', 'dự định', 'đi', 'học', 'master', 'ml', 'dl', 'úc', 'background', 'gpa tích', 'lũy kì', '7', '3', '8', 'ielts', '7', '0', 'tảng', 'thống kê', 'xử lí', 'trực quan', 'hóa', 'handle liệu', 'cân', 'khdl', 'implement', 'model', 'keras', 'tf', 'linear', 'algebra', 'quên', 'học', '1', 'thể', 'học', 'học toán', 'hơi', 'định hướng', 'kiểu', 'khóa', '90', 'hướng', 'ml', 'đi đi', 'offer', 'job', 'ml', 'level', 'ta thể', '2023', 'thể commit', 'công ty', 'ta', 'tuyển', 'í', 'học', 'master', 'xong thể', 'ngành', 'major', 'sợ', 'work', 'experience thể', 'đi', 'úc', 'hi vọng', 'mn thể', 'kiến', 'giúp', 'job', 'đi', 'học nghiệp', 'xong', 'đi', 'úc', 'đường', 'ml', 'rộng', 'chuẩn', 'kiến thức', 'thức', 'học', 'master', 'ml tài', 'bố mẹ thể', 'chu đi', 'học', 'ms', 'liền nghiệp', 'bk', 'đi', 'áp lực', 'hoài nghi', 'đuổi', 'ml', 'huhu', 'mong', 'khuyên', 'mnn']"
1098,"#imageclassification
Hi mọi người, hiện giờ e đang muốn build một image classifcation model có thể phân loại flowers and leaf. Về phần training, e đang train trên dataset tầm 10GB ảnh, 124 training classes. Giờ vấn đề e gặp phải là nếu mà trong test images mà có images mà ko thuộc training class nào, thì làm thế nào model của e có thể detect được là cái images đấy ko thuộc training class nào. E định dùng neural network với output layer có sigmoid activation function. Nếu mà sigmoid score cho từng class < 0.5, thì e sẽ classify tấm images đấy ko thuộc training class nào. Liệu rằng approach của e có khả dĩ ko hay mọi ng có approach nào khác?","['#Q&A', '#cv', '#deep_learning']","['hi hiện', 'e build', 'image', 'classifcation', 'model thể', 'phân flowers', 'and leaf', 'training', 'e train', 'dataset', 'tầm', '10', 'gb', 'ảnh', '124', 'training', 'classes', 'e test', 'images', 'images', 'ko', 'training', 'class', 'model', 'e thể', 'detect', 'images', 'đấy', 'ko', 'training', 'class', 'e định', 'neural', 'network', 'output', 'layer', 'sigmoid', 'activation', 'function', 'sigmoid', 'score', 'class', '0', '5', 'e classify', 'images', 'đấy', 'ko', 'training', 'class liệu', 'approach', 'e', 'khả dĩ', 'ko', 'ng', 'approach']"
1099,"***** Điểm tin về LLaMA (https://arxiv.org/abs/2302.13971; https://github.com/facebookresearch/llama) và các biến thể cũng như giải pháp kĩ thuật cải tiến LLaMA *****
Như chúng ta đã biến sức nóng của mô hình ngôn ngữ lớn (Large Language Models ~ LLM) lớn tới mức như thế nào, đặc biệt là ChatGPT và GPT-4 do OpenAI tạo ra. Tuy nhiên, rất tiếc OpenAI nhưng lại không Open, nhưng FacebookResearch (FAIR) được lãnh đạo bởi bác Yan LeCun chủ trương Open (source code và data). Có lần mình nghe bác LeCun nói, kiến trúc Convolutional Neural Network (CNN) được bác ấy phát minh từ năm 1988-89, nhưng vì nhiều lý về bản quyền (nơi bác ấy từng làm việc, ví dụ Bell Labs) nên AI bị rơi vào ""ngủ đông"". Rút kinh nghiệm từ đó, bác LeCun chủ trương Open Science (các bạn có thể sẽ gặp thuật ngữ này ngày một nhiều hơn, ví dụ OPEN: source code, data, access, review,...) giúp khoa học dissemination and exploitation nhanh và tốt hơn.
Quay lại LLaMA mở mã nguồn và trained weights ta sẽ thấy điều trên đúng với những cải tiến mà tôi được biết cho tới nay (9AM GMT+7, ngày 18/3/2023):
1/ Nhóm nghiên cứu ở Đại Học Stanford đã sử dụng kĩ thuật mà họ công bố trước đó là Self-Instruction (https://arxiv.org/abs/2212.10560) để cải tiến hiệu năng mô hình và đặt tên biến thể là Alpaca. Source code tại đây: https://github.com/tatsu-lab/stanford_alpaca; ứng dung Demo giống như ChatGPT tại đây: https://alpaca-ai-custom4.ngrok.io/ (tạm thời đang ngừng hoạt động để nâng cấp)
2/ Tiếp thu kinh nghiệm của nhóm Tastu ở ĐH Stanford, Eric J. Wang đã sử dụng kỹ thuật Low-Rank LLaMA Instruct-Tuning (https://arxiv.org/pdf/2106.09685.pdf) để finetune LLaMA và đặt tên là LLaMA-lora (source code tại đây: https://github.com/tloen/alpaca-lora). Hơn nữa, LLaMA-lora có thể train model với precision=8-bit sử dụng thư viện bitsandbytes mà chỉ cần 1 GPU như RTX 4090. Mình đang chờ xem có ai sử dụng accelerate để train model với precision=8-bit (fp8=True)???
3/ Tiếp theo vấn đề liên quan tới quantization để giảm bộ nhớ, cấu hình máy tính, các bạn có thể tham khảo tại đây https://github.com/qwopqwop200/GPTQ-for-LLaMa (paper: https://arxiv.org/abs/2302.13971 và original code tại đây: https://github.com/IST-DASLab/gptq)
4/ Kết hợp giữa quantization, chuyển trained weighted của LLaMA sang C/C++ và deploy lên edged device các bạn có thể theo dõi GitHub này: https://github.com/ggerganov/llama.cpp. Tương tự, với trained weighted của Alpaca xuống 4-bit và C/C++ tại đây https://github.com/antimatter15/alpaca.cpp
5/ Last but not least, mình thấy có 1 nhóm ở Bồ Đào Nha, sử dụng ChatGPT để dịch dữ liệu alpaca_data.json dùng trong Alpaca (mục 1/) sang tiếng Bồ rồi train mô hình giống với LLaMA-lora (mục 2/) tại đây: https://github.com/22-hours/cabrita. Bạn nào có nhã hứng với tiếng Việt, theo mình có thể sử dụng ý tướng của nhóm Bồ Đào Nha này. Hóng các bạn reimplementation source code này. Lưu ý 1 chút, Eric J. Wang có phàn này về chất lượng của dataset dùng để finetune Alpaca, nên các bạn có thể tham khảo thêm dataset này alpaca_data_cleaned.json tại đây (https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_cleaned.json).
...
n/ và chắc chắn sẽ còn rất nhiều ý tưởng thú vị liên quan tới chủ đề này sẽ được giới thiệu trong thời gian ngắn tới",['#sharing'],"['llama', 'https', 'github', 'com', 'facebookresearch', 'llama', 'biến thể', 'giải pháp', 'kĩ thuật', 'cải tiến', 'llama', 'ta', 'biến sức', 'nóng', 'mô hình', 'ngôn ngữ', 'large', 'language', 'models', 'llm', 'chatgpt', 'gpt4', 'openai nhiên', 'tiếc', 'openai', 'open', 'facebookresearch', 'fair', 'lãnh đạo', 'yan lecun', 'chủ trương', 'open', 'source', 'code', 'data lecun', 'kiến trúc', 'convolutional', 'neural', 'network', 'cnn', 'phát minh', '198889', 'lý quyền', 'ví dụ', 'bell', 'labs', 'rơi', 'ngủ', 'đông', 'rút', 'kinh nghiệm', 'lecun', 'chủ trương', 'open', 'science thể', 'thuật ngữ', 'ví dụ', 'open', 'source', 'code', 'data', 'access', 'review', 'giúp', 'khoa học', 'dissemination and', 'exploitation', 'llama mã', 'trained', 'weights', 'ta', 'cải tiến', '9', 'am gmt', '7', '18', '3', '2023', '1', 'nghiên cứu', 'đại học', 'stanford', 'kĩ thuật', 'công bố', 'selfinstruction', 'cải tiến', 'hiệu năng', 'mô hình', 'biến thể', 'alpaca', 'source', 'code', 'ứng dung', 'demo', 'chatgpt', 'https', 'alpacaaicustom4', 'ngrok', 'io', 'tạm thời', 'ngừng', 'hoạt động', 'nâng', '2', 'tiếp thu', 'kinh nghiệm', 'tastu', 'đh', 'stanford', 'eric', 'j', 'wang', 'kỹ thuật', 'lowrank', 'llama', 'instructtuning', 'finetune', 'llama', 'llamalora', 'source', 'code', 'https', 'github', 'com', 'tloen', 'alpacalora', 'llamalora thể', 'train', 'model', 'precision', '8', 'bit', 'thư viện', 'bitsandbytes', '1', 'gpu', 'rtx', '4090', 'chờ', 'accelerate', 'train', 'model', 'precision', '8', 'bit', 'fp8', 'true', '3', 'tiếp', 'quantization', 'cấu hình', 'máy thể', 'tham khảo', 'paper', 'original', 'code', 'https', 'github', 'com', 'istdaslab', 'gptq', '4', 'kết hợp', 'quantization', 'trained', 'weighted', 'llama', 'c', 'c', 'deploy', 'edged', 'device thể', 'dõi', 'github', 'https', 'github', 'com', 'ggerganov', 'llama', 'cpp', 'tương trained', 'weighted', 'alpaca', '4', 'bit', 'c', 'c', '5', 'last', 'but', 'not', 'least', '1', 'bồ', 'đào nha', 'chatgpt', 'dịch liệu', 'alpaca_data', 'json', 'alpaca', 'mục', '1', 'tiếng', 'bồ train', 'mô hình', 'llamalora mục', '2', 'https', 'github', 'com', '22', 'hours', 'cabrita', 'nhã hứng', 'tiếng', 'việt thể', 'tướng', 'bồ', 'đào nha', 'hóng', 'reimplementation', 'source', 'code lưu', '1', 'chút', 'eric', 'j', 'wang', 'phàn', 'chất', 'dataset', 'finetune', 'alpaca thể', 'tham khảo', 'dataset', 'alpaca_data_cleaned', 'json', 'n', 'chắn', 'tưởng', 'thú vị', 'chủ đề', 'giới thiệu', 'ngắn']"
1100,"Có bạn nào trong group này tải được trained weights của LLaMA (bài báo tại đây https://arxiv.org/abs/2302.13971v1) và link chia sẻ torrent tại đây https://github.com/facebookresearch/llama/pull/73/files, cụ thể là link magnet torrent này magnet:?xt=urn:btih:ZXXDAUWYLRUXXBHUYEMS6Q5CE5WA3LVA&dn=LLaMA; Mình thử thì traffic để download == 0%.
==> Vậy bạn nào đã tải được trained weights của LLaMA thì cho mình xin với nhé.
Xin đa tạ trước với mọi người.","['#Q&A', '#sharing']","['group', 'tải', 'trained', 'weights', 'llama', 'báo', 'https', 'arxiv', 'org', 'abs', '2302', '13971', 'v1', 'link', 'torrent', 'https', 'github', 'com', 'facebookresearch', 'llama', 'pull', '73', 'files', 'link', 'magnet', 'torrent', 'magnet', 'xt', 'urn', 'btih', 'zxxdauwylruxxbhuyems6q5ce5wa3lva', 'dn', 'llama', 'thử', 'traffic', 'download', '0', 'tải', 'trained', 'weights', 'llama', 'đa tạ']"
1101,"Mình muốn tạo 1 mô hình dự đoán số lượng bệnh nhân tới khám từng phòng khám. Dữ liệu với các dòng là: phòng khám, thời gian tới khám, thời gian khám xong, bệnh nhân.
Dữ liệu muốn dự đoán là. Tên phòng khám + khoảng thời gian —> dự đoán số lượng bệnh nhân khám, bệnh nhân
Nhờ các bạn tư vấn giúp mình ít keyword để có hướng nghiên cứu. Xin cảm ơn đã đọc bài.","['#Q&A', '#machine_learning']","['1', 'mô hình', 'dự đoán', 'bệnh nhân', 'khám', 'phòng khám liệu', 'dòng', 'phòng khám', 'khám', 'khám', 'xong', 'bệnh nhân liệu', 'dự đoán', 'phòng khám', 'dự đoán', 'bệnh nhân', 'khám', 'bệnh nhân', 'tư vấn', 'giúp', 'keyword', 'hướng', 'nghiên cứu', 'đọc']"
1102,🎯 Google giới thiệu trình tìm kiếm bằng chat giống ChatGPT,['#sharing'],"['google', 'giới thiệu', 'trình', 'kiếm', 'chat', 'chatgpt']"
1103,"Chào các bạn. Tôi xin chia sẻ bài nói chuyện của tôi về AI-for-dev (trước Tết 1 tuần mà giờ phải cập nhật slides rất nhiều rồi) hy vọng có vài thông tin hữu ích cho các bạn trẻ đang là lập trình viên và muốn tìm hiểu phát triển AI. 

Nếu các bạn seniors có insights & resources gì khác cũng xin comment để tôi cập nhật thêm nhé. Cheers!

Talk Title: AI4Dev: Landscapes, Toolsets, Roadmaps, Collabs
Slides & video recording: https://gem.cot.ai/p/-9_Wl26kz#/
Abstract:
The field of Artificial Intelligence (AI) is radically changing every aspect of human life, from the way we shop and entertain, lend and earn, to the way we learn and create. There are exponentially many AI ideas, principles, procedures, applications, tools and platforms being developed and shared freely. This on the one hand provides young talents with tremendous opportunities, on the other hand poses new challenges in the development of their knowledge and skills.
Specifically, AI is now widely considered software 2.0. As a dev, you need to be well prepared for what’s coming next. In this talk I will walk you through comprehensive landscapes of the many exciting topics in AI, introduce wonderful AI-powered dev tools, recommend pragmatic training roadmaps for you to quickly upgrade your AI capabilities, and invite you to collaborate & altogether build a strong community of AI4Dev by joining study groups and contributing to many exciting fullstack production AI projects.

#AI4Dev #AI4VN #Startup",['#sharing'],"['chào', 'aifordev', 'tết', '1', 'tuần', 'cập nhật', 'slides', 'hy vọng', 'thông hữu ích', 'trẻ', 'lập trình viên', 'phát triển', 'seniors', 'insights', 'resources', 'comment', 'cập nhật', 'cheers', 'talk', 'title', 'ai4dev', 'landscapes', 'toolsets', 'roadmaps', 'collabs', 'slides', 'video', 'recording', 'https', 'gem', 'cot', 'p', '9', '_wl26kz', 'abstract', 'the', 'field', 'of artificial', 'intelligence', 'is', 'radically', 'changing', 'every', 'aspect', 'of human', 'life', 'from', 'the', 'way', 'we shop', 'and entertain', 'lend and', 'earn', 'to', 'the', 'way', 'we learn', 'and create', 'there', 'are', 'exponentially', 'many', 'ideas', 'principles', 'procedures', 'applications tools', 'and platforms', 'being developed', 'and shared', 'freely', 'this', 'on', 'the', 'one', 'hand', 'provides', 'young', 'talents', 'with', 'tremendous', 'opportunities', 'on', 'the', 'other', 'hand', 'poses', 'new', 'challenges', 'in', 'the', 'development', 'of', 'their knowledge', 'and skills', 'specifically', 'is', 'now', 'widely', 'considered', 'software', '2', '0', 'as', 'a', 'dev', 'you', 'need', 'to', 'be', 'well', 'prepared', 'for', 'what', 's', 'coming', 'next', 'in', 'this', 'talk', 'i', 'will', 'walk', 'you', 'through', 'comprehensive', 'landscapes', 'of the', 'many', 'exciting', 'topics', 'in', 'introduce', 'wonderful', 'aipowered', 'dev', 'tools', 'recommend', 'pragmatic', 'training', 'roadmaps', 'for', 'you', 'to', 'quickly', 'upgrade', 'your capabilities', 'and invite', 'you', 'to', 'collaborate', 'altogether', 'build', 'a', 'strong', 'community', 'of ai4dev', 'by', 'joining', 'study groups', 'and contributing', 'to', 'many', 'exciting', 'fullstack', 'production', 'projects']"
1104,"[Poe của Quora - 1 ứng dụng thay thế tuyệt vời cho ChatGPT]

Hello mọi người,
Là một cộng đồng về ML, mình chắc rằng nhu cầu sử dụng ChatGPT của mọi người rất cao nhưng việc truy cập và sử dụng lại tương đối khó khăn (khó tạo account, thường phải dùng VPN, lại hay bị rate limit, etc. ). Mình muốn giới thiệu với mọi người 1 ứng dụng mới, mà theo quan điểm chủ quan của mình là tiện lợi hơn ChatGPT rất nhiều, đó là Poe của Quora. Vâng, chính là trang hỏi đáp Quora mà bạn hay thấy đó.

1 vài ưu điểm của Poe so với ChatGPT mà mình thấy:
📚Poe của Quora là ứng dụng tích hợp nhiều chatbot, nên bạn có thể dùng ChatGPT thông qua Poe.
📧 Tạo account rất đơn giản, không có giới hạn gì cả. Lại còn không cần dùng VPN.
💻 Giao diện xinh xắn dễ thương.
🏃Tốc độ rất nhanh, nhiều bạn ở VN dùng bảo là sử dụng ChatGPT ở Poe cho kết quả nhanh gấp 3, 4 lần so với ChatGPT Pro từ web chính.
💰Không có rate limit và hoàn toàn miễn phí .
🧐 Không chỉ có ChatGPT, ở đây còn có Claude là model của Anthropic, công ty vừa được Google đầu tư $300 triệu và Sage là custom model của Quora dựa vào OpenAI. Tại sao lại vất vả dùng ChatGPT trong khi ở Poe, bạn vừa dùng được ChatGPT, vừa được dùng những state-of-the-art model mới nhất?

Hiện nay bạn có thể dùng Poe trên iOS hoặc là desktop nhé. Bản Android cũng sẽ sớm được ra mắt.

[Disclaimer]: mình làm việc trong team Poe ở Quora nên dĩ nhiên là sẽ khen nhiều hơn chê. Ứng dụng của bọn mình sinh sau đẻ muộn nên sẽ còn khuyết điểm, mọi người có đóng góp gì thì cứ comment vào post nhé, không chừng sẽ thấy ý kiến của bản thân được đưa vào app đó 😜",['#sharing'],"['poe', 'quora', '1', 'ứng dụng', 'thay', 'tuyệt vời', 'chatgpt', 'hello', 'cộng đồng', 'ml', 'nhu cầu', 'chatgpt', 'truy cập', 'tương đối', 'khăn', 'account', 'vpn', 'rate', 'limit', 'etc', 'giới thiệu', '1', 'ứng dụng', 'quan', 'chủ quan', 'tiện lợi', 'chatgpt', 'poe', 'quora trang', 'đáp quora', '1', 'ưu poe', 'chatgpt', 'poe', 'quora', 'ứng dụng', 'tích hợp', 'chatbot thể', 'chatgpt', 'thông poe', 'account', 'đơn giản', 'giới hạn', 'vpn', 'giao diện', 'xinh xắn', 'thương', 'tốc độ', 'vn', 'bảo', 'chatgpt', 'poe', 'kết', 'gấp', '3', '4', 'chatgpt', 'pro', 'web', 'rate', 'limit', 'miễn phí', 'chatgpt', 'claude', 'model', 'anthropic', 'công ty', 'google', 'đầu tư', '300', 'triệu', 'sage', 'custom', 'model', 'quora', 'dựa', 'openai', 'vất vả', 'chatgpt', 'poe', 'chatgpt', 'stateoftheart', 'model thể', 'poe', 'ios', 'desktop', 'android', 'mắt', 'disclaimer', 'team', 'poe', 'quora dĩ nhiên', 'khen chê', 'ứng dụng', 'bọn', 'sinh đẻ', 'muộn khuyết', 'đóng góp', 'comment', 'post', 'chừng', 'kiến thân', 'app']"
1105,"Người tây rất hay chơi chữ kiểu LLaMA (là một loài động vật họ lạc đà được nuôi ở Nam Mỹ để lấy lông) và cũng là tên model xử lý ngôn ngữ gần đây được FacebookResearch công bố. Nửa đêm qua, 1 nhóm nghiên cứu ở Đại học Stanford có finetune nhỏ nhất model LLaMA 7B theo cơ chế Self-Instruct (bài báo tại đây https://arxiv.org/abs/2212.10560). Họ đặt tên cho model của họ là Alpaca (một loài thuộc họ lạc đà, có đặc điểm sinh học gần giống với Llama, cũng được nuôi ở dãy Andes, Nam Mỹ để lấy lông). Đây là source code cho Alpaca (https://github.com/tatsu-lab/stanford_alpaca). Bên cạnh đó, họ cũng đang merge request lên HuggingFace/transformers, và cần thêm 1 người review code trước khi PR lên transformers. Ngoài ra, họ cũng xây dựng giao diện nền web giống ChatGPT (nhưng k cần đăng ký để xử dụng) tại đây https://alpaca-ai-custom1.ngrok.io/
***** Hi vọng mọi người sẽ thích thú với những công cụ sinh ra ngôn ngữ *****","['#sharing', '#deep_learning']","['tây', 'chữ', 'kiểu', 'llama', 'loài', 'động vật', 'lạc đà', 'nuôi', 'nam mỹ', 'lông model', 'ngôn ngữ', 'facebookresearch', 'công bố', 'nửa đêm', '1', 'nghiên cứu', 'đại học', 'stanford', 'finetune', 'model', 'llama', '7', 'b chế', 'selfinstruct', 'báo', 'https', 'arxiv', 'org', 'abs', '2212', '10560', 'model', 'alpaca', 'loài', 'lạc đà', 'đặc sinh học', 'llama', 'nuôi', 'dãy', 'andes', 'nam', 'mỹ lông', 'source', 'code', 'alpaca', 'cạnh', 'merge', 'request', 'huggingface', 'transformers', '1', 'review', 'code', 'pr', 'transformers', 'xây dựng', 'giao diện', 'web', 'chatgpt', 'k', 'đăng ký', 'xử dụng', 'https', 'alpacaaicustom1', 'ngrok', 'io', 'hi vọng', 'thú', 'công cụ', 'sinh ngôn ngữ']"
1106,Hi mn. Hiện tại e đang làm project cá nhân Crawl data shopee. Đa số các fields đều lấy đúng nhưng chỉ có Price và Stock là bị sai số. Mn chỉ e chỗ này với ạ. E xin cảm ơn,"['#Q&A', '#data']","['hi mn', 'e project', 'crawl', 'data', 'shopee', 'đa fields', 'price', 'stock', 'sai', 'mn', 'e', 'chỗ', 'e']"
1107,Chào mọi người. Hiện e đang có bộ data có cấu trúc tương tự như hình. E thấy data đang bị duplicate theo hàng của vài trăm cột đầu. E đang tìm hiểu theo hướng grouping lại thay vì để duplicates như v mà train model nhưng ko có key word để tìm hiểu. Mong các bác chỉ giáo vs ạ.,"['#Q&A', '#data']","['chào', 'hiện', 'e data', 'cấu trúc', 'tương hình', 'e data', 'duplicate', 'hàng', 'trăm', 'cột', 'đầu', 'e', 'hướng', 'grouping', 'thay', 'duplicates', 'v', 'train', 'model', 'ko', 'key', 'word', 'mong giáo', 'vs']"
1108,"[RoomGPT - Room Generation]

Các bạn có muốn thiết kế văn phòng, phòng khách, phòng ngủ, phòng tắm,... của mình trở nên đẹp hơn, nhưng lại bị thiếu ý tưởng. Hãy đề RoomGPT giúp bạn. Các bạn chọn loại phòng và phong cách mong muốn (modern, vintage, minimalist,...), sau đó tải ảnh căn phòng hiện tại của bạn lên, RoomGPT sẽ giúp bạn làm căn phòng trở lên lộng lẫy hơn.

Ứng dụng hoàn toàn miễn phí tại: https://www.roomgpt.io/

Các bạn còn chờ gì nữa mà không biến cái ổ chuột của mình trở nên sang trọng hơn ^^","['#sharing', '#cv', '#deep_learning']","['roomgpt', 'room', 'generation', 'thiết kế', 'văn phòng', 'phòng', 'phòng', 'ngủ', 'phòng', 'tắm', 'trở', 'đẹp', 'tưởng', 'đề roomgpt', 'giúp', 'phòng', 'phong mong', 'modern', 'vintage', 'minimalist tải', 'ảnh', 'phòng', 'roomgpt', 'giúp', 'phòng', 'trở', 'lộng lẫy', 'ứng dụng', 'miễn phí', 'https', 'www', 'roomgpt io', 'chờ', 'biến', 'ổ chuột', 'trở trọng']"
1109,"Chắc các bạn quan tâm tới chủ đề GPT-xx không thể không biết codebase transformers của HuggingFace. Hay gần đây, Andrej Karpathy có làm series bài giảng và source code về GPT-2 có tên là nanoGPT (https://github.com/karpathy/nanoGPT/tree/master). Trước đó vài năm Andrej cũng tạo repo có tên là minGPT (https://github.com/karpathy/minGPT/tree/master). Sáng sớm nay, TySam có làm repo tương tự nanoGPT có tên là hlb-GPT ~hyperlightspeedbench-gpt tại đây (https://github.com/tysam-code/hlb-gpt/tree/main), anh này có sở trường làm mọi thứ đơn giản, hiệu quả, dễ đọc, dễ hiểu, mà benchmark lại rất ổn! Hi vọng với thông tin này, các bạn sẽ có thêm kiến thức, kĩ năng mới cho mình.","['#sharing', '#deep_learning']","['chủ đề', 'gptxx thể', 'codebase', 'transformers', 'huggingface', 'andrej', 'karpathy', 'series', 'giảng', 'source', 'code', 'gpt2', 'nanogpt', 'andrej', 'repo', 'mingpt', 'tysam', 'repo', 'tương nanogpt', 'hlbgpt', 'hyperlightspeedbenchgpt', 'sở trường', 'đơn giản hiệu', 'đọc', 'benchmark ổn', 'hi vọng', 'thông', 'kiến thức', 'kĩ năng']"
1110,"[Person Re-Identification]
Hiện nay các paper sota trên tập dữ liệu Market-101 (chủ yếu là resnet) cho bài toán ReID khi áp dụng trên dữ liệu thực tế đều không cho kết quả đáng mong đợi (dù đã retrain model trên data của doanh nghiệp). Mong mọi người đã có kinh nghiệm trong mảng này có thể cho em xin cao kiến. Em xin phép được hỏi một vài câu như sau:
1. Liệu dữ liệu dùng để retrain vẫn còn quá nhỏ để model có thể học được?
2. Có phải các paper public sẽ không áp dụng vào thưc tế được?
3. Có cách nào để cải thiện một model ReID để có thể áp dụng vào trong bài toán thực tế mà không cần phải thu thập số lượng data lớn?
Rất mong nhận được câu trả lời từ tất cả mọi người, em xin cảm ơn.","['#Q&A', '#data', '#cv', '#deep_learning']","['person', 'reidentification', 'paper', 'sota', 'tập liệu', 'market101', 'chủ yếu', 'resnet toán', 'reid', 'áp dụng', 'liệu kết', 'mong đợi', 'retrain', 'model', 'data', 'doanh nghiệp', 'mong', 'kinh nghiệm', 'mảng thể', 'kiến phép', 'câu', '1', 'liệu liệu', 'retrain', 'model thể', 'học', '2', 'paper', 'public', 'áp dụng', 'thưc tế', '3', 'cải thiện', 'model', 'reid thể', 'áp dụng', 'toán', 'thu thập', 'data', 'mong', 'câu', 'tất']"
1111,"Hello mọi người,
Hôm nay mình có một discussion với đồng nghiệp của mình về một cái khá là basic trong ML nhưng cũng khá hay để thảo luận. Mình muốn đưa ra đây để mọi người cùng thảo luận:
Vấn đề của mình là một bài toán về time series based và deployment in production.
Mình có một ML model, được train mỗi ngày với dữ liệu mới được cập nhật (feedback của model hôm trước) và deploy mỗi ngày vì data freshness rất rất quan trọng khi có quá nhiều data drift. đặc biệt là data của ngày N-1 là quan trọng nhất vì nó chứa nhiều thông tin hữu ích nhất.
Cách làm nào là tốt nhất và có thể là best practice trong các trường hợp dưới đây:
Suppose là ngày N là ngày deployment, mình chỉ có dữ liệu đến ngày N-1, mục tiêu là probability predictions tại ngày N là tốt nhất và được calibrated tốt nhất.
Train model trên data đến N-3, sau đó optimize (hyperparams search) trên data N-2 rồi calibration trên N-1
Train model trên data đến N-2, sau đó optimize (hyperparams search) trên data N- 1. rồi calibration trên N - 1
Hyperparams search với time-series cross validation (5 folds) trên toàn bộ data để obtain best params, sau đó train trên toàn bộ data đến N với best params đó. 
Mời mọi người cùng thảo luận xem cách nào theoretically là hiệu quả nhất.","['#Q&A', '#machine_learning']","['hello', 'hôm', 'discussion', 'đồng nghiệp', 'basic ml', 'thảo luận', 'thảo luận toán', 'time', 'series', 'based', 'deployment', 'in', 'production', 'ml', 'model', 'train liệu', 'cập nhật', 'feedback', 'model', 'hôm', 'deploy', 'data', 'freshness', 'data', 'drift', 'data', 'n1', 'chứa', 'thông hữu ích thể', 'best', 'practice', 'trường hợp', 'suppose', 'n', 'deployment liệu', 'n1', 'mục tiêu', 'probability', 'predictions', 'n', 'calibrated', 'train', 'model', 'data', 'n3', 'optimize', 'hyperparams', 'search', 'data', 'n2', 'calibration', 'n1', 'train', 'model', 'data', 'n2', 'optimize', 'hyperparams', 'search', 'data', 'n', '1', 'calibration', 'n', '1', 'hyperparams', 'search', 'timeseries', 'cross', 'validation', '5', 'folds', 'toàn', 'data', 'obtain', 'best', 'params', 'train', 'toàn', 'data', 'n', 'best', 'params', 'mời', 'thảo luận', 'theoretically hiệu']"
1112,"[Visual ChatGPT: Sử dụng ChatGPT với hình ảnh]

Mô hình ChatGPT chỉ hỗ trợ mọi người tương tác bằng ngôn ngữ. Tuy nhiên có rất nhiều mô hình dạng hình ảnh như Visual Transformers hay Stable Diffusion.  Thế nên các nhà nghiên cứu đến từ Microsoft đã xây dựng mô hình Visual ChatGPT kết hợp ChatGPT với các mô hình hình ảnh để hỗ trợ người dùng có thể gửi hình ảnh khi chat và hỗ trợ trả lời các câu hỏi liên quan tới nội dung bức ảnh.

Github: https://github.com/microsoft/visual-chatgpt","['#sharing', '#deep_learning']","['visual', 'chatgpt', 'chatgpt', 'hình ảnh', 'mô hình', 'chatgpt', 'tương tác', 'ngôn ngữ nhiên', 'mô hình', 'dạng', 'hình ảnh', 'visual', 'transformers', 'stable', 'diffusion', 'nghiên cứu', 'microsoft', 'xây dựng', 'mô hình', 'visual', 'chatgpt', 'kết hợp', 'chatgpt', 'mô hình', 'hình ảnh thể', 'gửi', 'hình ảnh', 'chat', 'nội dung', 'ảnh', 'github']"
1113,"Hi cả nhà, em phép được chia sẻ một seminar khác tổ chức bởi MLOpsVN cho các bác nào quan tâm :D. Cảm ơn cả nhà nhiều.",['#webinar'],"['hi phép', 'seminar', 'tổ chức', 'mlopsvn', 'd']"
1114,"Có lẽ khái niệm AGI (Artificial General Intelligence) vẫn là gì đó chưa tới, nhưng cách GPT-4 đạt kết quả trong các bài kiểm tra như BAR, LSAT, GRE, AP, đặc biệt ấn tượng. Ví dụ như GRE, thì bài Quantitative đạt 163/170, bài Verbal đạt 169/170 và bài Writing đạt 4/6.
Hiện tại các bạn có thể thử GPT-4 bản chỉ có text trên ChatGPT bản plus.",['#sharing'],"['lẽ', 'khái niệm', 'agi', 'artificial', 'general', 'intelligence', 'gpt4 kết', 'kiểm tra', 'bar', 'lsat', 'gre', 'ap', 'ấn tượng', 'ví dụ', 'gre', 'quantitative', '163', '170', 'verbal', '169', '170', 'writing', '4', '6', 'thể', 'thử', 'gpt4', 'text', 'chatgpt', 'plus']"
1115,"KHẢO SÁT NHU CẦU THEO DÕI THÔNG TIN VỀ AI-ML 

Em xin phép anh Tiep VuHuu thực hiện khảo sát trong group. 

Hiện tại lĩnh vực AI nói chung, ML nói riêng đang phát triển quá nhanh chóng, với các bước tiến từng ngày. Lượng thông tin liên quan tới AI, việc ứng dụng AI...vượt quá khả năng theo dõi thông thường của bất kì cá nhân nào, trong khi hiểu và sử dụng AI ngày càng trở thành nhu cầu quan trọng trong công việc và đời sống. 

Hiện tại em và team đã có một giải pháp để giải quyết bài toán quá tải thông tin, và dự định sẽ tạo một phiên bản dành riêng tối ưu cho lĩnh vực AI/ML nhằm giúp những người theo dõi, nhà nghiên cứu, doanh nhân khởi nghiệp trong lĩnh vực này có thể theo dõi thông tin tốt hơn. 

Rất mong các anh chị em trong Group dành chút thời gian thực hiện khảo sát để team điều chỉnh sản phẩm tốt nhất. 

Kết quả thực hiện khảo sát sẽ được phân tích và public trở lại với cộng đồng để mọi người cùng có hiểu biết sâu hơn về sự quan tâm của người Việt tới AI nói chung. 

Em xin cám ơn!

👉Link thực hiện khảo sát: http://bit.ly/3Za2mPd",['#Q&A'],"['khảo sát', 'nhu cầu', 'dõi', 'thông', 'aiml phép', 'tiep', 'vuhuu', 'khảo sát', 'group', 'lĩnh vực', 'ml', 'phát triển', 'chóng', 'tiến thông', 'ứng dụng', 'khả năng', 'dõi', 'thông', 'nhu cầu', 'công', 'đời sống', 'team', 'giải pháp', 'giải quyết', 'toán tải', 'thông', 'dự định', 'phiên', 'tối ưu', 'lĩnh vực', 'ml', 'giúp', 'dõi', 'nghiên cứu', 'doanh nhân', 'khởi nghiệp', 'lĩnh vực', 'thể dõi', 'thông mong', 'group', 'chút', 'khảo sát', 'team chỉnh', 'sản phẩm', 'kết', 'khảo sát', 'phân tích', 'public', 'trở', 'cộng đồng', 'sâu', 'việt', 'cám ơn', 'link', 'khảo sát']"
1116,"#Ask Vấn đề Crawling Data ở các sàn
Chào mọi người em là sinh viên đang làm project De tốt nghiệp. Mục tiêu của em là crawl Data ở 1 thị trường ngách sản phẩm làm đẹp từ các sàn thương mại điện tử Lazada, Shopee,Tiki gồm cả Batch lẫn Stream phục vụ nhu cầu phân tích, mọi thứ khá ok cho đến khi em cần phân tích doanh số thị trường ngành lên Dashboard và số lượng sản phẩm thì em gặp 1 vài vấn đề :
Tiki thì 1 số sản phẩm bán missing value khá là nhiều( dao động từ 10-20% ) và có những case thiếu tầm 50% , nhiều sản phẩm quantity_sold chỉ rơi vào 1 dù đăng khá lâu , em khá là đau đầu khi fill value vào những case kiểu này, thường thì em sẽ so sánh quy mô giữa Tiki và Shoppe với cùng 1 loại sản phẩm/tầm giá/số lượng review tuỳ từng th đó và dựa vào tỉ lệ để điền giá trị, nhưng với những case mà chỉ Tiki có thì bó tay.
Đến câu chuyện tổng doanh số thị trường , thì công thức em sử dụng vẫn là giá bán x số lượng bán cộng tất cả. Với Shopee thì khá ổn do giá và số lượng sản phẩm bán số lượng missing value ít, Nhưng lúc tính thì thị phần Tiki thọt so với Shopee khá nhiều, 1 phần ảnh hưởng do dữ liệu . Ngoài ra khi cần real-time sẽ phải tính toán mỗi khung thời gian thì cách của em tính với vài chục nghìn sản phẩm cá nhân em thấy khá là ngu nhưng vẫn chưa có giải pháp tốt hơn. Vậy làm thế nào để mình xử lý trường hợp này thì em cần cao kiến
Dữ liệu em crawl thông qua API của các bên cung cấp, em có tham khảo 1 số sản phẩm như case của Metric.vn thì còn có thể crawl dữ liệu bán của từng sản phẩm trong 1 mốc thời gian thứ mà lúc em crawl ko có, vậy làm thế nào để có thể crawl số lượng bán của 1 sản phẩm trên các sàn ạ?
Do tài năng và kiến thức hạn hẹp,rất mong được các bác chỉ giáo 🙁","['#Q&A', '#data']","['crawling', 'data', 'sàn', 'chào', 'sinh viên', 'project', 'de nghiệp', 'mục tiêu', 'crawl', 'data', '1', 'thị trường', 'ngách', 'sản phẩm', 'đẹp sàn', 'thương mại điện tử', 'lazada', 'shopee', 'tiki', 'batch', 'lẫn', 'stream', 'phục vụ', 'nhu cầu', 'phân tích', 'ok', 'phân tích', 'doanh thị trường', 'ngành', 'dashboard', 'sản phẩm', '1', 'tiki', '1', 'sản phẩm', 'missing value', 'dao động', '1020', 'case', 'tầm', '50', 'sản phẩm', 'quantity_sold', 'rơi', '1', 'đăng', 'đau đầu', 'fill', 'value', 'case', 'kiểu', 'sánh', 'quy mô', 'tiki', 'shoppe', '1', 'sản phẩm', 'tầm', 'giá', 'review', 'tùy', 'th', 'dựa', 'tỉ lệ', 'điền case', 'tiki bó', 'câu', 'tổng doanh thị trường', 'công thức', 'giá', 'x', 'cộng', 'tất shopee', 'ổn', 'giá', 'sản phẩm', 'missing', 'value thị', 'tiki', 'thọt', 'shopee', '1', 'ảnh hưởng liệu', 'realtime toán', 'khung', 'chục', 'nghìn', 'sản phẩm', 'ngu', 'giải pháp', 'trường hợp', 'kiến liệu', 'crawl', 'thông api', 'cung', 'tham khảo', '1', 'sản phẩm', 'case thể', 'crawl liệu', 'sản phẩm', '1', 'mốc', 'crawl', 'ko thể', 'crawl', '1', 'sản phẩm', 'sàn', 'tài năng', 'kiến thức', 'hạn hẹp', 'mong giáo']"
1117,"👉🏻Với trung bình hơn 3 nghìn lượt tải về gói cài đặt mỗi tháng, Deploy AI Systems Yourself (D.AI.S.Y) toolkit - một sản phẩm của Neural Việt Nam là một bộ công cụ bao gồm các thuật toán trí tuệ nhân tạo đã được xây dựng và đóng gói. Mục tiêu hướng đến các bạn trẻ có niềm say mê với công nghệ trí tuệ nhân tạo và muốn thực hành các ứng dụng trí tuệ nhân tạo vào đời sống thông qua các câu lệnh đơn giản.
🙋🏻‍♂️🙋🏻‍♂️Bên cạnh các ứng dụng phổ biến đã được tích hợp sẵn như: nhận diện người đeo khẩu trang, phát hiện dáng người,... Team Daisykit - Neural Việt Nam sẽ tiếp tục phát triển và cho ra mắt các ứng dụng mới trong thời gian sắp tới.",['#sharing'],"['trung bình', '3', 'nghìn', 'lượt', 'tải gói', 'cài', 'deploy', 'systems', 'yourself', 'd', 's', 'y toolkit', 'sản phẩm', 'neural', 'việt nam', 'công cụ', 'bao thuật', 'toán trí tuệ nhân', 'xây dựng', 'đóng gói', 'mục tiêu', 'hướng', 'trẻ', 'niềm', 'say mê', 'công nghệ trí tuệ', 'nhân thực hành', 'ứng dụng', 'trí tuệ', 'nhân', 'đời sống', 'thông câu', 'lệnh', 'đơn giản', 'cạnh', 'ứng dụng', 'phổ biến tích', 'hợp', 'sẵn diện', 'đeo', 'khẩu trang', 'phát hiện', 'dáng', 'team', 'daisykit', 'neural', 'việt nam', 'phát triển', 'mắt', 'ứng dụng']"
1118,"Em chào mọi người ạ. Em muốn xin lời khuyên của các anh chị để bổ sung kiến thức cho việc học Machine Learning.
Em hiện là sinh viên năm 2 ngành Khoa học dữ liệu. Sau khi tốt nghiệp em muốn làm bên mảng Machine Learning, cụ thể là Machine Learning Engineer hoặc NLP Scientist cho các công ty về sản phẩm công nghệ số như voice assistant, xe tự hành, ...
Nhưng do ngành này đòi hỏi kiến thức cao (đặc biệt là về Toán), và em cũng được nghe thường người ta tuyển dân Machine Learning từ PhD thôi nên em muốn tìm hiểu nhiều nhất về ML để cạnh tranh và có được công việc trong mảng này.
Các kiến thức em đã biết:
Lập trình cơ bản
Cấu trúc dữ liệu và giải thuật
Cách hoạt động của một model (ở mức cơ bản, chưa đào sâu về Toán)
Cách dùng libray như sklearn để giải quyết bài toán regression cơ bản trên Kaggle
Hy vọng các anh chị có thể cho em xin tham khảo về:
Tài liệu ML, cụ thể là các nền tảng về Toán, Thống Kê cần thiết cho ngành
Các dự án cá nhân để bỏ vô portfolio cần thể hiện kiến thức ở mảng nào
Sinh viên có thể có paper tốt không? Làm sao để bắt đầu nghiên cứu làm paper? Hiện tại em đang làm paper ứng dụng ML trong việc dự báo, vẫn là Regression bằng cách dùng library, nhưng em thấy cách làm này đơn giản, không chuyên sâu và chỉ cần nghiên cứu chút là có thể làm được. ","['#Q&A', '#machine_learning']","['chào', 'khuyên', 'bổ sung', 'kiến thức', 'học', 'machine learning', 'hiện', 'sinh viên', '2', 'ngành', 'khoa học liệu nghiệp', 'mảng', 'machine', 'learning', 'machine', 'learning', 'engineer', 'nlp', 'scientist', 'công ty', 'sản phẩm', 'công nghệ', 'voice', 'assistant', 'xe hành', 'ngành', 'đòi', 'kiến thức', 'toán', 'ta', 'tuyển', 'dân', 'machine', 'learning', 'phd', 'ml', 'cạnh tranh', 'công mảng', 'kiến thức', 'lập trình', 'cấu trúc liệu', 'giải thuật', 'hoạt động', 'model', 'đào', 'sâu toán', 'libray', 'sklearn', 'giải quyết', 'toán', 'regression', 'kaggle', 'hy vọng thể', 'tham khảo', 'tài liệu', 'ml', 'tảng toán', 'thống kê', 'thiết', 'ngành', 'dự án', 'vô portfolio', 'thể hiện', 'kiến thức', 'mảng', 'sinh viên thể', 'paper', 'nghiên cứu', 'paper', 'paper', 'ứng dụng', 'ml', 'dự báo', 'regression', 'library', 'đơn giản', 'chuyên sâu', 'nghiên cứu', 'chút thể']"
1119,"Xin hỏi:
Mình đang làm cho một startup về thời trang, và đang tìm kiếm giải pháp đọc một hình, xem trong hình đó người dùng mặt áo quần gì.
Đơn giản hơn là cho hai bức hình, trả lại xác xuất hai bức hình đó có cùng một loại vật thể .
Nếu phải xây dựng training data thì cần cỡ bao nhiêu training data để xây dựng mô hình kiểu này. 100k đủ không ?","['#Q&A', '#data', '#cv']","['startup', 'thời trang', 'kiếm', 'giải pháp', 'đọc', 'hình hình', 'mặt', 'áo quần', 'đơn giản', 'hai', 'hình', 'xác xuất', 'hai', 'hình vật thể', 'xây dựng', 'training', 'data', 'cỡ', 'training data', 'xây dựng', 'mô hình', 'kiểu', '100', 'k']"
1120,"#nlp #question #documentclustering
Chào mọi người, Em đang cần thực hiện bài toán phân cụm văn bản, bài báo,... ( document clustering) với số cụm không xác định trước. Về phần phân cụm sử dụng DBSCAN em đã hiểu và thấy ok. Tuy nhiên phần embedding văn bản, em muốn tham khảo ý kiến mọi người phương pháp nào tốt nhất hiện nay. Em được biết về phần câu có các mô hình sentence embedding kết quả khá ok như sbert,... Tuy nhiên với cả văn bản dài thì em tìm hiểu không thấy có nhiều thông tin. Mong mọi người cho ý kiến về giải pháp hoặc các keyword, bài viết liên quan để em tìm hiểu ạ.  Em cảm ơn","['#Q&A', '#nlp', '#deep_learning', '#machine_learning']","['chào toán', 'phân cụm', 'văn báo', 'document', 'clustering', 'cụm', 'xác định', 'phân cụm', 'dbscan', 'ok nhiên', 'embedding văn', 'tham khảo', 'kiến', 'phương pháp', 'câu', 'mô hình', 'sentence', 'embedding', 'kết ok', 'sbert nhiên', 'văn thông', 'mong kiến', 'giải pháp', 'keyword', 'viết']"
1121,"Hi mọi người, mình có một thắc mắc muốn nhờ mọi người giải thích giúp với.
Mình đang thực hiện một dự án cá nhân, trong đó có một phần xử lý đọc các ký tự chữ số trên mặt đồng hồ. Framework mình xử dụng là detectron2.
Khi mình training và predict thử trên 2 version khác nhau là 0.6 và 0.1.3 thì kết quả là version 0.1.3 mình thấy tốc độ hội tụ hanh hơn nhiều, chỉ cần training 2000 iter với dataset 1300/150 là đã cho kết quả rất ấn tượng rồi. Trong khi mình training trên bản 0.6 với tập dataset lớn hơn 1 chút 1600/250 với 80000 iter nhưng kết quả tốc độ hội tụ không ổn định, nhiều số không thể nhận diện được. Không rõ có ai gặp phải tình trạng như mình không vậy?","['#Q&A', '#cv', '#deep_learning']","['hi', 'thắc mắc', 'giải', 'giúp', 'dự án', 'đọc', 'ký', 'chữ', 'mặt', 'đồng hồ', 'framework', 'xử dụng', 'detectron2', 'training', 'predict', 'thử', '2', 'version', '0', '6', '0', '1', '3', 'kết', 'version', '0', '1', '3', 'tốc độ', 'hội tụ', 'hanh', 'training', '2000', 'iter', 'dataset', '1300', '150', 'kết', 'ấn tượng', 'training', '0', '6', 'tập', 'dataset', '1', 'chút', '1600', '250', '80000', 'iter kết', 'tốc độ', 'hội tụ', 'ổn định thể', 'diện']"
1122,"🤖🤖🤖 ChatGPT đang làm mưa làm gió trên toàn thế giới những ngày vừa qua. Hãy cùng team NeuralVN tìm hiểu về công nghệ phía sau chatbot đình đám này qua bài viết ""Bí mật công nghệ đằng sau ChatGPT"".",['#sharing'],"['chatgpt', 'mưa gió', 'toàn', 'giới', 'team neuralvn', 'công nghệ', 'chatbot đình', 'đám', 'viết', 'bí mật', 'công nghệ', 'đằng', 'chatgpt']"
1123,"Chào mọi người ạ, em đang tìm hiểu về AdaDelta optimizer, có một đoạn em vẫn chưa hiểu đó là trong paper, tác giả có đề cập về sự không thống nhất trong đơn vị và đưa ra giải pháp đề xuất. Tuy nhiên em vẫn chưa thể nào hình dung được sự sai lệch về đơn vị này là như thế nào mặc dù đã search và đọc thêm từ nhiều nguồn. Mọi người có thể cho em một ví dụ cụ thể hay một giải thích trực quan với ạ.
Đây là paper em đang đọc, đề cập về đơn vị ở phần 3.2 (trang 3) : https://arxiv.org/pdf/1212.5701.pdf
Em cảm ơn mọi người đã quan tâm, chúc mọi người một ngày tốt lành.","['#Q&A', '#deep_learning']","['chào', 'adadelta', 'optimizer', 'đoạn', 'paper tác giả', 'đề cập thống', 'giải pháp', 'đề xuất nhiên thể', 'hình dung', 'sai lệch', 'mặc', 'search', 'đọc thể', 'ví dụ', 'giải', 'trực quan', 'paper', 'đọc', 'đề cập', '3', '2', 'trang', '3', 'chúc', 'lành']"
1124,"Chào mọi người ạ, em đang có một thắc mắc về ý nghĩa của việc chuẩn hóa phân phối của data về dạng phân phối chuẩn. 
Có một câu trả lời ở đây mà em đang quan tâm : https://www.quora.com/Why-in-machine-learning-do-lots-of-people-want-to-convert-skewed-data-into-normal-distribution
Tác giả nói rằng, giả sử dữ liệu của chúng ta tuân theo hàm y = f(x) + e với f(x) là một hàm số cố định và e là biến ngẫu nhiên tuân theo phân phối chuẩn, tác giả chỉ ra việc chuyển data về pp chuẩn giúp cho e không phụ thuộc vào dữ liệu nữa, tức là e đang độc lập và có mean bằng 0, nếu e không độc lập tức là e = bias + t với t là biến ngẫu nhiên độc lập có mean = 0. Tuy nhiên lấy ví dụ trong linear regression, mặt phẳng cần tìm có dạng như w1x1 + w2x2 + b, thì rõ ràng là mình đã có thành phần bias trong đây rồi, thế thì em mới nảy ra 2 câu hỏi như sau :
Như đã nói ở trên thì có phải những thuật tương tự như linear regression không cần chuyển về pp chuẩn ?
Xét các trường hợp khác, nếu ta đã chuyển pp dữ liệu về pp chuẩn thì không cần thành phần bias ?
Cảm ơn mọi người đã quan tâm, chúc mọi người một ngày tốt lành","['#Q&A', '#math', '#machine_learning']","['chào', 'thắc mắc', 'nghĩa', 'chuẩn hóa', 'phân phối', 'data dạng', 'phân phối', 'chuẩn', 'câu', 'tác giả', 'giả sử liệu', 'ta', 'tuân hàm', 'y f', 'x', 'e f', 'x', 'hàm', 'cố định', 'e biến', 'ngẫu nhiên', 'tuân', 'phân phối', 'chuẩn tác giả', 'data', 'pp', 'chuẩn', 'giúp', 'e', 'phụ liệu', 'tức e', 'độc lập', 'mean', '0', 'e', 'độc lập tức', 'e bias', 't', 't biến', 'ngẫu nhiên', 'độc lập', 'mean', '0', 'nhiên', 'ví dụ', 'linear', 'regression', 'mặt phẳng', 'dạng', 'w1x1', 'w2x2', 'b', 'ràng', 'thành', 'bias nảy', '2', 'thuật', 'tương linear', 'regression', 'pp', 'chuẩn', 'xét', 'trường hợp', 'ta', 'pp liệu', 'pp', 'chuẩn', 'thành', 'bias', 'chúc', 'lành']"
1125,Bác nào gợi ý giúp mình cái cloud nào train tốt với chứ gg colab chạy thhế kia bao giờ mới xong :3,['#Q&A'],"['gợi', 'giúp', 'cloud', 'train', 'gg', 'colab', 'chạy', 'thhế', 'kia', 'xong', '3']"
1126,"Chào mọi người,
Mình là lập trình viên không chuyên AI, ML nhưng muốn vọc vạch tý nên có dự định làm hệ thống phân loại tài liệu.
Mình đang có hàng TB tài liệu để lộn xộn, nhiều định dạng khác nhau, còn bị trùng lặp do tên file khác nhau vì download ở nhiều nguồn.
Nay mình muốn phát triển tool tự động phân loại rồi gom chúng vào các thư mục phân theo thể loại.
Nhờ mọi người vạch ra giúp mình xem cần học những gì và thực hiện như thế nào?
Mình cảm ơn.","['#Q&A', '#nlp']","['chào', 'lập trình viên', 'chuyên ml', 'vọc', 'vạch tý', 'dự định', 'hệ thống', 'phân tài liệu', 'hàng', 'tb', 'tài liệu', 'lộn xộn', 'định dạng', 'trùng lặp', 'file download', 'phát triển', 'tool động', 'phân gom', 'thư mục', 'phân thể', 'vạch', 'giúp', 'học']"
1127,"Anh em đang học hoặc đã làm thì cùng mình trao đổi 1 số câu hỏi về CV nhé:
Tại sao Yolov8 pretrained task object detection bằng tập COCO, trong khi task classification lại dùng tập ImageNet. Câu hỏi vận dụng là nếu mình có 1 bài toán đầu vào ảnh grayscale cho task object detection thì việc dùng pretrain trên tập COCO có hiệu quả bằng việc dùng bộ dataset grayscale khác ( như mnist) hay không ?
Việc chọn backbone khi xây dựng model thì nên dựa vào yếu tố nào ?
Làm thế nào để đánh giá việc data  agumentation thủ công có hiệu quả hơn so với dùng có sẵn của yolo ?","['#Q&A', '#data', '#deep_learning', '#cv']","['học', 'trao đổi', '1', 'cv', 'yolov8', 'pretrained', 'task', 'object', 'detection', 'tập', 'coco', 'task', 'classification', 'tập', 'imagenet', 'vận dụng', '1', 'toán', 'đầu', 'ảnh', 'grayscale', 'task', 'object', 'detection', 'pretrain', 'tập', 'coco hiệu', 'dataset', 'grayscale', 'mnist', 'backbone', 'xây dựng', 'model', 'dựa', 'yếu tố', 'data', 'agumentation', 'thủ công hiệu', 'sẵn', 'yolo']"
1128,"Xin giới thiệu với mọi người một tài liệu được viết bởi 2 giáo sư hàng đầu của Stanford University, Prof. Jure Leskovec & Prof. Jeffrey D. Ullman, và cùng một entrepreneur nổi tiếng của Thung Lũng Silicon Anand Rajaraman, về chủ đề ""Mining Massive Data"". Sách xoay quanh những phương pháp khai thác dữ liệu hiệu quả, chính xác, và nhanh chóng. Link sách: http://www.mmds.org/, Link course: https://online.stanford.edu/courses/soe-ycs0007-mining-massive-data-sets
Đồng thời, xin chia sẻ luôn một cuốn sách cùng chủ đề Data Mining nhưng được viết theo hướng ứng dụng hơn kèm code do Dr. Ron Zacharski chia sẻ kinh nghiệm của ông miễn phí cho cộng đồng: http://guidetodatamining.com/","['#Q&A', '#data']","['giới thiệu', 'tài liệu', 'viết', '2', 'giáo sư', 'hàng đầu', 'stanford', 'university', 'prof', 'jure', 'leskovec', 'prof', 'jeffrey', 'd', 'ullman', 'entrepreneur', 'nổi tiếng', 'thung lũng', 'silicon', 'anand', 'rajaraman', 'chủ đề', 'mining', 'massive', 'data', 'sách', 'xoay', 'quanh', 'phương pháp', 'khai thác', 'liệu hiệu', 'xác chóng', 'link', 'sách', 'http', 'www', 'mmds', 'org', 'link', 'course', 'sách', 'chủ đề', 'data', 'mining', 'viết', 'hướng', 'ứng dụng', 'kèm', 'code', 'dr', 'ron', 'zacharski', 'kinh nghiệm', 'miễn phí', 'cộng đồng', 'http', 'guidetodatamining', 'com']"
1129,"Đợt vừa rồi mình và team có tham gia một cuộc thi về trích xuất thông tin từ hóa đơn có tên gọi là The Mobile capture receipts Optical Character Recognition (MC-OCR).
Mình có một bài viết chia sẻ về giải pháp của team mình, mọi người tham khảo và góp ý ạ.","['#sharing', '#cv']","['đợt', 'team', 'tham gia', 'thi trích', 'xuất', 'thông hóa', 'đơn', 'gọi', 'the', 'mobile', 'capture', 'receipts', 'optical', 'character', 'recognition', 'mcocr', 'viết', 'giải pháp', 'team', 'tham khảo', 'góp']"
1130,Mọi người cho e hỏi. Em định encode dữ liệu nến nhật để train CNN phân loại mẫu hình thì liệu có hiệu quả không ạ. Có paper hay dự án nào làm r chưa ạ?,"['#Q&A', '#cv', '#deep_learning']","['e định', 'encode liệu', 'nến nhật', 'train', 'cnn', 'phân mẫu', 'hình liệu', 'hiệu', 'paper', 'dự án', 'r']"
1131,"[Data-Centric AI Course]
Thông thường các khóa học về Machine Learning sẽ dạy nhiều về các mô hình. Tuy nhiên khi làm việc trong môi trường thực tế, dữ liệu thường nhiễu và hỗn độn (messy), thế nên bên cạnh việc cải thiện mô hình, chúng ta cũng nên tập trung vào cải thiện các vấn đề của dữ liệu. Data-Centric AI (DCAI) là hướng nghiên cứu mới, tập trung vào việc cải thiện dữ liệu để tăng độ hiệu quả của mô hình.
Khóa này dạy các bạn giải quyết các vấn đề về dữ liệu trong các project thực tế như:
- Data-Centric AI vs. Model-Centric AI
- Label Errors
- Dataset Creation and Curation
- Data-centric Evaluation of ML Models
- Class Imbalance, Outliers, and Distribution Shift
- Growing or Compressing Datasets
- Interpretability in Data-Centric ML
- Encoding Human Priors: Data Augmentation and Prompt Engineering
- Data Privacy and Security","['#sharing', '#data']","['datacentric', 'course', 'thông khóa', 'học', 'machine', 'learning', 'dạy', 'mô hình nhiên', 'môi trường', 'liệu nhiễu', 'hỗn độn', 'messy', 'cạnh', 'cải thiện', 'mô hình', 'ta', 'cải thiện liệu', 'datacentric', 'dcai', 'hướng', 'nghiên cứu', 'cải thiện liệu', 'độ hiệu', 'mô hình', 'khóa', 'dạy', 'giải quyết', 'liệu', 'project', 'datacentric', 'vs', 'modelcentric', 'label', 'errors', 'dataset creation', 'and curation', 'datacentric', 'evaluation', 'of ml', 'models', 'class', 'imbalance outliers', 'and distribution', 'shift', 'growing', 'or', 'compressing', 'datasets', 'interpretability', 'in', 'datacentric', 'ml', 'encoding', 'human', 'priors', 'data augmentation', 'and prompt', 'engineering', 'data', 'privacy and', 'security']"
1132,"Ai đã làm về hệ thống điểm danh bằng camera cho mình xin ý kiến về ưu/nhược điểm (hoặc nên/không nên) về các phương hướng sau:
1- Face_recognition
2- VGG + ArcFace
3- YOLO
4- gợi ý thêm 😅
Thank.","['#Q&A', '#cv', '#deep_learning']","['hệ thống', 'danh', 'camera kiến', 'ưu nhược', 'phương hướng', '1', 'face_recognition', '2', 'vgg', 'arcface', '3', 'yolo', '4', 'gợi', 'thank']"
1133,Em xin phép chia sẻ thông tin về buổi webinar tối nay cho các bác quan tâm tới MLOps 😁,['#webinar'],"['phép', 'thông webinar', 'tối', 'mlops']"
1134,"Kính chào các bác. Đợt này nhân dịp đang quay lại học Reinforcement Learrning nên em mạnh dạn chia sẻ cùng cả nhà 1 video về ""Deep Q Learrning"".
Vẫn với phương châm đơn giản, hi vọng giúp được các anh em mới học thôi!","['#sharing', '#machine_learning']","['kính', 'chào', 'đợt', 'học', 'reinforcement', 'learrning dạn', '1', 'video', 'deep', 'q', 'learrning', 'phương châm', 'đơn giản', 'hi vọng', 'giúp', 'học']"
1135,"[ChatGPT for Google - Chrome Extension]
Plugin ChatGPT for Google này sẽ giúp bạn hiện thị nội dung trả lời của ChatGPT cho nội dung bạn tìm kiếm bên cạnh kết quả trả về của Google.
Với sức mạnh của ChatGPT thì đây là một tính năng cực kì hữu ích cho người dùng. Ví dụ như tìm kiếm các câu hỏi liên quan tới lập trình, ChatGPT sẽ là bản tổng hợp của Stackoverflow, Github,.., khi cho bạn cả câu trả lời và giải thích luôn. Nói chung giờ anh em dev cũng nhàn :)))
Như ở dưới mình hỏi cách vẽ Bar Graph trong Python, nó sinh ra cả code có cả comment luôn.",['#sharing'],"['chatgpt', 'for', 'google', 'chrome', 'extension', 'plugin', 'chatgpt', 'for', 'google', 'giúp', 'hiện thị', 'nội dung', 'chatgpt', 'nội dung', 'kiếm', 'cạnh', 'kết', 'google', 'sức', 'chatgpt năng', 'cực kì', 'hữu ích', 'ví dụ', 'kiếm', 'lập trình', 'chatgpt', 'tổng hợp', 'stackoverflow', 'github', 'câu', 'giải', 'dev', 'nhàn', 'vẽ', 'bar', 'graph', 'python sinh', 'code', 'comment']"
1136,"Hi mọi người, em đã kết thúc 6 tháng intern AI Engineer và cảm thấy chút không hợp do phần lớn thời gian sẽ sử dụng để training mô hình. Hiện tại em muốn chuyển hướng sang Data Scientist hoặc SE nên em muốn hỏi mọi người trong Group, công việc của 1 Data Scientist sẽ làm những gì và sẽ dành nhiều thời gian làm việc gì? Em thì hay thấy bảo làm Data Scientist ở VN mà chỉ tốt nghiệp Cử nhân/ Kỹ sư thì làm không hiệu quả, mong mọi người cho lời khuyên.
Cảm ơn mọi người.",['#Q&A'],"['hi kết thúc', '6', 'intern', 'engineer', 'chút', 'hợp training', 'mô hình', 'hướng', 'data', 'scientist', 'se', 'group', 'công', '1', 'data', 'scientist', 'bảo', 'data', 'scientist', 'vn nghiệp', 'cử nhân', 'kỹ sư', 'hiệu', 'mong', 'khuyên']"
1137,Em đang làm model nhận diện biển báo giao thông bằng CNN. Chạy file train thì nó đến epoch 446/2000 bị dừng như vậy và kết thúc chương trình luôn. Có ai biết lỗi này là lỗi gì và cách fix không ạ.,"['#Q&A', '#cv', '#deep_learning']","['model diện', 'biển báo', 'giao thông', 'cnn', 'chạy', 'file', 'train', 'epoch', '446', '2000', 'dừng', 'kết thúc', 'chương trình', 'lỗi', 'lỗi', 'fix']"
1138,"Xin chào mọi người.
Bài toán phân loại hình ảnh (image classification) là một trong những bài toán quan trọng trong lĩnh vực Computer Vision. Một cách giải quyết hiệu quả cho bài toán này là sử dụng kĩ thuật transfer learning vốn không yêu cầu quá nhiều về data hay resource mà vẫn mang lại kết quả tốt. Mình vừa xây dựng repository tổng hợp các thuật image classification mà pytorch có hỗ trợ transfer learning: Efficientnet, resnet, vgg, googlenet. Nó có thể sẽ hữu ích với các bạn mới tiếp xúc với bài toán này, mới tiếp xúc với pytorch hay đơn giản muốn sử dụng code nhanh gọn lẹ để giải quyết bài toán. Đối với những bạn đã thành thạo pytorch, muốn custom model và data nhiều hơn thì repo này có vẻ sẽ kém hữu ích với các bạn.
Trong repo này sẽ có các phần code:
- Làm thế nào load data do mình tự thu thập (custom dataset) vào model.
- Thay đổi hàm loss, hàm optimize
- Train và predict trên dữ liệu mới.
link:","['#Q&A', '#cv', '#deep_learning']","['chào toán', 'phân', 'hình ảnh', 'image', 'classification toán', 'lĩnh vực', 'computer', 'vision', 'giải quyết', 'hiệu toán', 'kĩ thuật', 'transfer', 'learning', 'vốn', 'data', 'resource kết', 'xây dựng', 'repository', 'tổng hợp thuật', 'image', 'classification', 'pytorch', 'transfer', 'learning', 'efficientnet', 'resnet', 'vgg', 'googlenet thể', 'hữu ích', 'tiếp xúc toán', 'tiếp xúc', 'pytorch', 'đơn giản', 'code', 'gọn lẹ', 'giải quyết toán', 'đối thành', 'thạo', 'pytorch', 'custom', 'model', 'data', 'repo vẻ', 'kém', 'hữu ích', 'repo', 'code', 'load', 'data', 'thu thập', 'custom', 'dataset', 'model', 'hàm', 'loss', 'hàm optimize', 'train', 'predict liệu', 'link']"
