Contents,p_content,old_hastag,Hashtag,HÃ¹ng,CÃ¡p,KhÃ¡nh
"CÃ´ng cá»¥ Mocap AI táº¡o hoáº¡t áº£nh khuÃ´n máº·t, chuyá»ƒn Ä‘á»™ng cháº¥t lÆ°á»£ng cao theo thá»i gian thá»±c!","CÃ´ng cá»¥ Mocap AI táº¡o hoáº¡t áº£nh khuÃ´n máº·t, chuyá»ƒn Ä‘á»™ng cháº¥t lÆ°á»£ng cao theo thá»i gian thá»±c!",,,"#sharing, #cv","#sharing, #cv","#sharing, #tools, #cv"
"ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m quen vá»›i ML cÆ¡ báº£n vÃ  cÃ³ bÃ i táº­p lá»›n vá» nháº­n diá»‡n hÃ nh Ä‘á»™ng báº¡o lá»±c. Em Ä‘Ã£ cÃ i cÃ¡c mÃ´i trÆ°á»ng nhÆ°ng gáº·p pháº£i lá»—i á»Ÿ bÆ°á»›c train, theo bÃ i hÆ°á»›ng dáº«n thÃ¬ sá»­ dá»¥ng tensorflow 1.7.0 nhÆ°ng hiá»‡n táº¡i báº£n tháº¥p nháº¥t lÃ  2.2.0. Em Ä‘Ã£ thá»­ cÃ¡c báº£n tá»« 2.2.0 trá»Ÿ lÃªn nhÆ°ng Ä‘á»u xuáº¥t hiá»‡n lá»—i "" has no attribute"" nhÆ° hÃ¬nh dÆ°á»›i. Ráº¥t mong Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i áº¡","ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m quen vá»›i ML cÆ¡ báº£n vÃ  cÃ³ bÃ i táº­p lá»›n vá» nháº­n diá»‡n hÃ nh Ä‘á»™ng báº¡o lá»±c. Em Ä‘Ã£ cÃ i cÃ¡c mÃ´i trÆ°á»ng nhÆ°ng gáº·p pháº£i lá»—i á»Ÿ bÆ°á»›c train, theo bÃ i hÆ°á»›ng dáº«n thÃ¬ sá»­ dá»¥ng tensorflow 1.7.0 nhÆ°ng hiá»‡n táº¡i báº£n tháº¥p nháº¥t lÃ  2.2.0. Em Ä‘Ã£ thá»­ cÃ¡c báº£n tá»« 2.2.0 trá»Ÿ lÃªn nhÆ°ng Ä‘á»u xuáº¥t hiá»‡n lá»—i "" has no attribute"" nhÆ° hÃ¬nh dÆ°á»›i. Ráº¥t mong Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i áº¡",,,"#Q&A, #pythonlibraries","#Q&A, #pythonlibraries, #machine_learning","#sharing, #machine_learning"
"Merger 2 cÃ¢u Ä‘á»ƒ táº¡o 1 cÃ¢u má»›i.
Trong NLP, má»i ngÆ°á»i Ä‘Ã£ gáº·p trÆ°á»ng há»£p nÃ o mÃ  dÃ¹ng ngáº«u nhiÃªn 2 cÃ¢u trong dataset há»£p láº¡i lÃ m má»™t Ä‘á»ƒ táº¡o ra data má»›i chÆ°a áº¡, cÃ³ thá»ƒ chá»‰ cho mÃ¬nh bÃ i bÃ¡o hoáº·c vÃ­ dá»¥ Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng? Thanks!","Merger 2 cÃ¢u Ä‘á»ƒ táº¡o 1 cÃ¢u má»›i. Trong NLP, má»i ngÆ°á»i Ä‘Ã£ gáº·p trÆ°á»ng há»£p nÃ o mÃ  dÃ¹ng ngáº«u nhiÃªn 2 cÃ¢u trong dataset há»£p láº¡i lÃ m má»™t Ä‘á»ƒ táº¡o ra data má»›i chÆ°a áº¡, cÃ³ thá»ƒ chá»‰ cho mÃ¬nh bÃ i bÃ¡o hoáº·c vÃ­ dá»¥ Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng? Thanks!",,,"#Q&A, #nlp","#Q&A, #nlp","#Q&A, #nlp"
"Today, we introduce VinaLLaMA, a Vietnamese Foundation Model built on top of LLaMA-2 with 800B additional tokens trained. The SFT process includes 1M samples in various tasks to make it the State-of-the-art across ALL Vietnamese Benchmark. VinaLLaMA also scores impressive on English benchmark, beating Meta AI's LLaMA-2-chat-hf, making it capable for a bilingual LLM.
Everyone please have a Llamastic day!
Announcement: https://www.vilm.org/research/introducing-vinallama
Paper: https://arxiv.org/abs/2312.11011
Demo (Sponsored by HuggingFaceğŸ¤—): https://huggingface.co/spaces/vilm/vinallama-chatui-hf
Models: https://huggingface.co/collections/vilm/vinallama-654a099308775ce78e630a6f","Today, we introduce VinaLLaMA, a Vietnamese Foundation Model built on top of LLaMA-2 with 800B additional tokens trained. The SFT process includes 1M samples in various tasks to make it the State-of-the-art across ALL Vietnamese Benchmark. VinaLLaMA also scores impressive on English benchmark, beating Meta AI's LLaMA-2-chat-hf, making it capable for a bilingual LLM. Everyone please have a Llamastic day! Announcement: https://www.vilm.org/research/introducing-vinallama Paper: https://arxiv.org/abs/2312.11011 Demo (Sponsored by HuggingFace): https://huggingface.co/spaces/vilm/vinallama-chatui-hf Models: https://huggingface.co/collections/vilm/vinallama-654a099308775ce78e630a6f",,,,,
cÃ³ bÃ¡c nÃ o lÃ m genai mÃ  cÅ©ng hay dÃ¹ng transformer decoder only khÃ´ng. e tháº¥y bÃ¡c viáº¿t bÃ i nÃ y báº£o lÃ  sá»­ dá»¥ng kiáº¿n trÃºc gá»‘c cá»§a Transformer bao gá»“m cáº£ encoder vÃ  decoder cÃ³ thá»ƒ giáº£m bá»›t tÃ¬nh tráº¡ng hallucination cá»§a mÃ´ hÃ¬nh. bÃ¡c nÃ o thá»­ rá»“i cho e biáº¿t vá»›i,cÃ³ bÃ¡c nÃ o lÃ m genai mÃ  cÅ©ng hay dÃ¹ng transformer decoder only khÃ´ng. e tháº¥y bÃ¡c viáº¿t bÃ i nÃ y báº£o lÃ  sá»­ dá»¥ng kiáº¿n trÃºc gá»‘c cá»§a Transformer bao gá»“m cáº£ encoder vÃ  decoder cÃ³ thá»ƒ giáº£m bá»›t tÃ¬nh tráº¡ng hallucination cá»§a mÃ´ hÃ¬nh. bÃ¡c nÃ o thá»­ rá»“i cho e biáº¿t vá»›i,,,"#Q&A, #deep_learning,","#Q&A, #deep_learning,#nlp","#Q&A, #deep_learning, #nlp"
"MÃ¬nh cÃ³ Ä‘á»c Ä‘Æ°á»£c 26 tips cho viá»‡c prompt hiá»‡u quáº£ hÆ¡n vá»›i ChatGPT vÃ  cÅ©ng cÃ³ thá»ƒ hiá»‡u quáº£ vá»›i cÃ¡c cÃ´ng cá»¥ LLM khÃ¡c nÃªn chia sáº» á»Ÿ Ä‘Ã¢y Ä‘á»ƒ chÃºng ta cÃ¹ng tham kháº£o.
26 Prompting Tips
1 - No need to be polite with LLM so there is no need to add phrases like â€œpleaseâ€, â€œif you donâ€™t mindâ€, â€œthank youâ€, â€œI would like toâ€, etc., and get straight to the point.
2 - Integrate the intended audience in the prompt, e.g., the audience is an expert in the field.
3 - Break down complex tasks into a sequence of simpler prompts in an interactive conversation.
4 - Employ affirmative directives such as â€˜do,â€™ while steering clear of negative language like â€˜donâ€™tâ€™.
5 -
When you need clarity or a deeper understanding of a topic, idea, or any piece of information, utilize the following prompts:
o Explain [insert specific topic] in simple terms.
o Explain to me like Iâ€™m 11 years old.
o Explain to me as if Iâ€™m a beginner in [field].
o Write the [essay/text/paragraph] using simple English like youâ€™re explaining something to a 5-year-old.
6 - Add â€œIâ€™m going to tip $xxx for a better solution!â€
7 - Implement example-driven prompting (Use few-shot prompting).
8 -
When formatting your prompt, start with â€˜###Instruction###â€™, followed by either â€˜###Example###â€™ or â€˜###Question###â€™ if relevant. Subsequently, present your content. Use one or more
line breaks to separate instructions, examples, questions, context, and input data.
9 - Incorporate the following phrases: â€œYour task isâ€ and â€œYou MUSTâ€.
10 - Incorporate the following phrases: â€œYou will be penalizedâ€.
11 - Use the phrase â€Answer a question given in a natural, human-like mannerâ€ in your prompts.
12 - Use leading words like writing â€œthink step by stepâ€.
13 - Add to your prompt the following phrase â€œEnsure that your answer is unbiased and does not rely on stereotypesâ€.
14 - Allow the model to elicit precise details and requirements from you by asking you questions until he has enough information to provide the needed output (for example, â€œFrom now on, I would like you to ask me questions to...â€).
15 - To inquire about a specific topic or idea or any information and you want to test your understanding, you can use the following phrase: â€œTeach me the [Any theorem/topic/rule name] and include a test at the end, but donâ€™t
give me the answers and then tell me if I got the answer right when I respondâ€.
16 - Assign a role to the large language models.
17 - Use Delimiters.
18 - Repeat a specific word or phrase multiple times within a prompt.
19 -Combine Chain-of-thought (CoT) with few-Shot prompts.
20 -
Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response.
21 - To write an essay /text /paragraph /article or any type of text that should be detailed: â€œWrite a detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessaryâ€.
22 - To correct/change specific text without changing its style: â€œTry to revise every paragraph sent by users. You should only improve the userâ€™s grammar and vocabulary and make sure it sounds natural. You should not change the writing style, such as making a formal paragraph casualâ€.
23 - When you have a complex coding prompt that may be in different files: â€œFrom now and on whenever you generate code that spans more than one file, generate a [programming language ] script that can be run to automatically create the specified files or make changes to existing files to insert the generated code. [your question]â€.
24 - When you want to initiate or continue a text using specific words, phrases, or sentences, utilize the following prompt: o Iâ€™m providing you with the beginning [song lyrics/story/paragraph/essay...]: [Insert lyrics/words/sentence]â€™. Finish it based on the words provided. Keep the flow consistent.
25 - Clearly state the requirements that the model must follow in order to produce content, in the form of the keywords, regulations, hint, or instructions
26 - To write any text, such as an essay or paragraph, that is intended to be similar to a provided sample, include the following instructions: o Please use the same language based on the provided paragraph[/title/text /essay/answer].
Credit: Perez @IntuitMachine from X
ÄÃ¢y lÃ  paper mÃ  Perez Ä‘Ã£ tá»•ng há»£p láº¡i","MÃ¬nh cÃ³ Ä‘á»c Ä‘Æ°á»£c 26 tips cho viá»‡c prompt hiá»‡u quáº£ hÆ¡n vá»›i ChatGPT vÃ  cÅ©ng cÃ³ thá»ƒ hiá»‡u quáº£ vá»›i cÃ¡c cÃ´ng cá»¥ LLM khÃ¡c nÃªn chia sáº» á»Ÿ Ä‘Ã¢y Ä‘á»ƒ chÃºng ta cÃ¹ng tham kháº£o. 26 Prompting Tips 1 - No need to be polite with LLM so there is no need to add phrases like â€œpleaseâ€, â€œif you donâ€™t mindâ€, â€œthank youâ€, â€œI would like toâ€, etc., and get straight to the point. 2 - Integrate the intended audience in the prompt, e.g., the audience is an expert in the field. 3 - Break down complex tasks into a sequence of simpler prompts in an interactive conversation. 4 - Employ affirmative directives such as â€˜do,â€™ while steering clear of negative language like â€˜donâ€™tâ€™. 5 - When you need clarity or a deeper understanding of a topic, idea, or any piece of information, utilize the following prompts: o Explain [insert specific topic] in simple terms. o Explain to me like Iâ€™m 11 years old. o Explain to me as if Iâ€™m a beginner in [field]. o Write the [essay/text/paragraph] using simple English like youâ€™re explaining something to a 5-year-old. 6 - Add â€œIâ€™m going to tip $xxx for a better solution!â€ 7 - Implement example-driven prompting (Use few-shot prompting). 8 - When formatting your prompt, start with â€˜###Instruction###â€™, followed by either â€˜###Example###â€™ or â€˜###Question###â€™ if relevant. Subsequently, present your content. Use one or more line breaks to separate instructions, examples, questions, context, and input data. 9 - Incorporate the following phrases: â€œYour task isâ€ and â€œYou MUSTâ€. 10 - Incorporate the following phrases: â€œYou will be penalizedâ€. 11 - Use the phrase â€Answer a question given in a natural, human-like mannerâ€ in your prompts. 12 - Use leading words like writing â€œthink step by stepâ€. 13 - Add to your prompt the following phrase â€œEnsure that your answer is unbiased and does not rely on stereotypesâ€. 14 - Allow the model to elicit precise details and requirements from you by asking you questions until he has enough information to provide the needed output (for example, â€œFrom now on, I would like you to ask me questions to...â€). 15 - To inquire about a specific topic or idea or any information and you want to test your understanding, you can use the following phrase: â€œTeach me the [Any theorem/topic/rule name] and include a test at the end, but donâ€™t give me the answers and then tell me if I got the answer right when I respondâ€. 16 - Assign a role to the large language models. 17 - Use Delimiters. 18 - Repeat a specific word or phrase multiple times within a prompt. 19 -Combine Chain-of-thought (CoT) with few-Shot prompts. 20 - Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response. 21 - To write an essay /text /paragraph /article or any type of text that should be detailed: â€œWrite a detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessaryâ€. 22 - To correct/change specific text without changing its style: â€œTry to revise every paragraph sent by users. You should only improve the userâ€™s grammar and vocabulary and make sure it sounds natural. You should not change the writing style, such as making a formal paragraph casualâ€. 23 - When you have a complex coding prompt that may be in different files: â€œFrom now and on whenever you generate code that spans more than one file, generate a [programming language ] script that can be run to automatically create the specified files or make changes to existing files to insert the generated code. [your question]â€. 24 - When you want to initiate or continue a text using specific words, phrases, or sentences, utilize the following prompt: o Iâ€™m providing you with the beginning [song lyrics/story/paragraph/essay...]: [Insert lyrics/words/sentence]â€™. Finish it based on the words provided. Keep the flow consistent. 25 - Clearly state the requirements that the model must follow in order to produce content, in the form of the keywords, regulations, hint, or instructions 26 - To write any text, such as an essay or paragraph, that is intended to be similar to a provided sample, include the following instructions: o Please use the same language based on the provided paragraph[/title/text /essay/answer]. Credit: Perez @IntuitMachine from X ÄÃ¢y lÃ  paper mÃ  Perez Ä‘Ã£ tá»•ng há»£p láº¡i",,,#sharing,"#sharing, #nlp, #deep_learning",
"Do mÃ¬nh bÃ¢y giá» chuyá»ƒn sang Bank lÃ m vÃ¬ tiá»n nÃªn cháº¯c cÅ©ng khÃ´ng Ä‘á»¥ng vÃ o deep learning vá»›i computer vision nhiá»u ná»¯a nÃªn mÃ¬nh muá»‘n chia sáº» repo Ä‘á» tÃ i tháº¡c sÄ© cá»§a mÃ¬nh Ä‘á»ƒ ai há»©ng thÃº thÃ¬ cÃ³ thá»ƒ tiáº¿p tá»¥c vÃ  nghiÃªn cá»©u phÃ¡t triá»ƒn thÃªm. Repo Ã¡p dá»¥ng hai models tá»‘t nháº¥t hiá»‡n nay trong viá»‡c phÃ¢n loáº¡i Ä‘iá»ƒm báº¥t thÆ°á»ng (hÆ° há»ng hay tráº§y xÆ°á»›c) cá»§a cÃ¡c váº­t thá»ƒ cÃ´ng nghiá»‡p lÃ  FastFlow vÃ  PatchCore nháº±m so sÃ¡nh vÃ  cáº£i thiá»‡n kháº£ nÄƒng phÃ¢n loáº¡i cá»§a models. Äá» tÃ i Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  bÃ¡m sÃ¡t hai bÃ i nghiÃªn cá»©u lÃ :
Towards Total Recall in Industrial Anomaly Detection: [https://arxiv.org/abs/2106.08265]
FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows: [https://arxiv.org/abs/2111.07677]
MÃ¬nh ráº¥t vui lÃ²ng Ä‘Æ°á»£c giáº£i Ä‘Ã¡p má»i tháº¯c máº¯c cÅ©ng nhÆ° chá»‰ dáº«n cÃ¡ch cÃ i Ä‘áº·t vÃ  cháº¡y chÆ°Æ¡ng trÃ¬nh
[https://gitlab.com/anomalydetection2/anomaly_detection]",Do mÃ¬nh bÃ¢y giá» chuyá»ƒn sang Bank lÃ m vÃ¬ tiá»n nÃªn cháº¯c cÅ©ng khÃ´ng Ä‘á»¥ng vÃ o deep learning vá»›i computer vision nhiá»u ná»¯a nÃªn mÃ¬nh muá»‘n chia sáº» repo Ä‘á» tÃ i tháº¡c sÄ© cá»§a mÃ¬nh Ä‘á»ƒ ai há»©ng thÃº thÃ¬ cÃ³ thá»ƒ tiáº¿p tá»¥c vÃ  nghiÃªn cá»©u phÃ¡t triá»ƒn thÃªm. Repo Ã¡p dá»¥ng hai models tá»‘t nháº¥t hiá»‡n nay trong viá»‡c phÃ¢n loáº¡i Ä‘iá»ƒm báº¥t thÆ°á»ng (hÆ° há»ng hay tráº§y xÆ°á»›c) cá»§a cÃ¡c váº­t thá»ƒ cÃ´ng nghiá»‡p lÃ  FastFlow vÃ  PatchCore nháº±m so sÃ¡nh vÃ  cáº£i thiá»‡n kháº£ nÄƒng phÃ¢n loáº¡i cá»§a models. Äá» tÃ i Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  bÃ¡m sÃ¡t hai bÃ i nghiÃªn cá»©u lÃ : Towards Total Recall in Industrial Anomaly Detection: [https://arxiv.org/abs/2106.08265] FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows: [https://arxiv.org/abs/2111.07677] MÃ¬nh ráº¥t vui lÃ²ng Ä‘Æ°á»£c giáº£i Ä‘Ã¡p má»i tháº¯c máº¯c cÅ©ng nhÆ° chá»‰ dáº«n cÃ¡ch cÃ i Ä‘áº·t vÃ  cháº¡y chÆ°Æ¡ng trÃ¬nh [https://gitlab.com/anomalydetection2/anomaly_detection],,,"#sharing, #deep_learning","#sharing, #deep_learning, #cv","#sharing, #deep_learning, #cv"
"Em chÃ o anh chá»‹ áº¡, trong quÃ¡ trÃ¬nh thá»±c hÃ nh vá» MLP dá»±a trÃªn thuáº­t toÃ¡n tháº§y Tiá»‡p Ä‘Æ°a ra thÃ¬ em cÃ³ gáº·p má»™t váº¥n Ä‘á» lÃ : Dá»¯ liá»‡u ban Ä‘áº§u cá»§a em náº±m trong khoáº£ng tá»« [-1,1], vÃ¬ tháº¿ nÃªn chÆ°a thá»ƒ dÃ¹ng entropy ngay Ä‘Æ°á»£c. Em giáº£i quyáº¿t nÃ³ báº±ng cÃ¡ch scale vá» khoáº£ng [0,1] báº±ng cÃ¡ch tÃ­nh má»—i pháº§n tá»­ theo min, max cá»§a nÃ³ thÃ¬ láº¡i bá»‹ lá»—i giÃ¡ trá»‹ inf á»Ÿ vÃ²ng láº·p Ä‘áº§u tiÃªn (náº¿u dÃ¹ng Batch Gradient Descent) vÃ  nan á»Ÿ nhá»¯ng epoch tiáº¿p theo. VÃ¬ tháº¿ anh chá»‹ cho em há»i:
Lá»—i Ä‘áº¥y tá»« Ä‘Ã¢u ra vÃ  lÃ m sao Ä‘á»ƒ kháº¯c phá»¥c Ä‘Æ°á»£c? 
Em chÆ°a hiá»ƒu cÃ¡ch tÃ­nh Ä‘áº¡o hÃ m cá»§a loss function Ä‘á»‘i vá»›i Z á»Ÿ lá»›p ngoÃ i cÃ¹ng? Bá»Ÿi vÃ¬ rÃµ lÃ  nÃ³ Ä‘Ã£ Ä‘i qua activation function lÃ  softmax rá»“i? KhÃ´ng biáº¿t anh chá»‹ cÃ³ thá»ƒ chá»©ng minh cÃ´ng thá»©c á»Ÿ bÃªn dÆ°á»›i giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡?
VÃ¬ khÃ´ng hiá»ƒu cÃ´ng thá»©c á»Ÿ dÃ²ng Ä‘áº§u Ä‘áº¥y nÃªn em cÅ©ng khÃ´ng biáº¿t cÃ¡ch tÃ­nh Ä‘áº¡o hÃ m theo Z ngoÃ i cÃ¹ng trong trÆ°á»ng há»£p loss function lÃ  MSE, ráº¥t mong anh chá»‹ giÃºp Ä‘á»¡ em thÃªm áº¡.","Em chÃ o anh chá»‹ áº¡, trong quÃ¡ trÃ¬nh thá»±c hÃ nh vá» MLP dá»±a trÃªn thuáº­t toÃ¡n tháº§y Tiá»‡p Ä‘Æ°a ra thÃ¬ em cÃ³ gáº·p má»™t váº¥n Ä‘á» lÃ : Dá»¯ liá»‡u ban Ä‘áº§u cá»§a em náº±m trong khoáº£ng tá»« [-1,1], vÃ¬ tháº¿ nÃªn chÆ°a thá»ƒ dÃ¹ng entropy ngay Ä‘Æ°á»£c. Em giáº£i quyáº¿t nÃ³ báº±ng cÃ¡ch scale vá» khoáº£ng [0,1] báº±ng cÃ¡ch tÃ­nh má»—i pháº§n tá»­ theo min, max cá»§a nÃ³ thÃ¬ láº¡i bá»‹ lá»—i giÃ¡ trá»‹ inf á»Ÿ vÃ²ng láº·p Ä‘áº§u tiÃªn (náº¿u dÃ¹ng Batch Gradient Descent) vÃ  nan á»Ÿ nhá»¯ng epoch tiáº¿p theo. VÃ¬ tháº¿ anh chá»‹ cho em há»i: Lá»—i Ä‘áº¥y tá»« Ä‘Ã¢u ra vÃ  lÃ m sao Ä‘á»ƒ kháº¯c phá»¥c Ä‘Æ°á»£c? Em chÆ°a hiá»ƒu cÃ¡ch tÃ­nh Ä‘áº¡o hÃ m cá»§a loss function Ä‘á»‘i vá»›i Z á»Ÿ lá»›p ngoÃ i cÃ¹ng? Bá»Ÿi vÃ¬ rÃµ lÃ  nÃ³ Ä‘Ã£ Ä‘i qua activation function lÃ  softmax rá»“i? KhÃ´ng biáº¿t anh chá»‹ cÃ³ thá»ƒ chá»©ng minh cÃ´ng thá»©c á»Ÿ bÃªn dÆ°á»›i giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡? VÃ¬ khÃ´ng hiá»ƒu cÃ´ng thá»©c á»Ÿ dÃ²ng Ä‘áº§u Ä‘áº¥y nÃªn em cÅ©ng khÃ´ng biáº¿t cÃ¡ch tÃ­nh Ä‘áº¡o hÃ m theo Z ngoÃ i cÃ¹ng trong trÆ°á»ng há»£p loss function lÃ  MSE, ráº¥t mong anh chá»‹ giÃºp Ä‘á»¡ em thÃªm áº¡.",,,"#Q&A, #machine_learning","#Q&A, #machine_learning, #math","#Q&A, #machine_learning, #data"
"VinAI Seminar - ""Scaling Robot Learning""
Speaker: Quan Vuong - Google DeepMind
Time: 10:00 am - 11:00 am (GMT+7), Dec 27, 2023","VinAI Seminar - ""Scaling Robot Learning"" Speaker: Quan Vuong - Google DeepMind Time: 10:00 am - 11:00 am (GMT+7), Dec 27, 2023",,,#webinar,#webinar,#webniar
"Anh chá»‹ cho em há»i vá»›i áº¡
Em muá»‘n lÃ m 1 cÃ¡i tool Ä‘á»ƒ search thÃ´ng tin trong 1 vÃ i cÃ¡i domain internet thÃ¬ pháº£i dÃ¹ng nhá»¯ng gÃ¬ áº¡
Em Ä‘ang xÃ i langchain",Anh chá»‹ cho em há»i vá»›i áº¡ Em muá»‘n lÃ m 1 cÃ¡i tool Ä‘á»ƒ search thÃ´ng tin trong 1 vÃ i cÃ¡i domain internet thÃ¬ pháº£i dÃ¹ng nhá»¯ng gÃ¬ áº¡ Em Ä‘ang xÃ i langchain,,,#Q&A,#Q&A,"#Q&A, #tools"
MÃ¬nh xin chia sáº» báº£n tÃ³m táº¯t hai phÆ°Æ¡ng phÃ¡p parameter tuning má»›i lÃ  MoV vÃ  MoLORA Ä‘Æ°á»£c ra máº¯t gáº§n Ä‘Ã¢y bá»Ÿi Cohere AI Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» liÃªn quan tá»›i scaling cÃ¡c LLMs theo instruction-tuning.,MÃ¬nh xin chia sáº» báº£n tÃ³m táº¯t hai phÆ°Æ¡ng phÃ¡p parameter tuning má»›i lÃ  MoV vÃ  MoLORA Ä‘Æ°á»£c ra máº¯t gáº§n Ä‘Ã¢y bá»Ÿi Cohere AI Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» liÃªn quan tá»›i scaling cÃ¡c LLMs theo instruction-tuning.,,,"#sharing, #deep_learning","#sharing, #deep_learning","#sharing, #deep_learning, #nlp"
"Tin chuáº©n Ä‘Ã©t mÃ¬nh cáº­p nháº­t cho ae, LLM cá»§a Zalo Ä‘Ã£ vÆ°á»£t ChatGPT3.5??
MÃ¬nh má»›i lÆ°á»›t tháº¥y buá»•i stream cá»§a Tinh táº¿ á»Ÿ sá»± kiá»‡n cá»§a Zalo, há» cháº¡y demo LLM má»›i cá»§a Zalo tÃ­ch há»£p vÃ o trong Kiki rá»“i thi vá»›i máº¥y cÃ¡i LLM khÃ¡c nhÆ° GPT3.5 Qwen...káº¿t quáº£ lÃ  Kiki chá»‰ thua con GPT-4!!
Theo diá»…n giáº£i thÃ¬ LLM nÃ y Ä‘Æ°á»£c build báº±ng kiáº¿n trÃºc transformer, ká»¹ thuáº­t sá»­ dá»¥ng lÃ  Flash Attention cÅ©ng hao hao giá»‘ng nhÆ° cÃ¡ch build cá»§a open AI nhÆ°ng Ä‘iá»ƒm khÃ¡c biá»‡t lÃ  LLM nÃ y Ä‘Æ°á»£c training báº±ng dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao Báº°NG TIáº¾NG VIá»†T!!!
Káº¿ hoáº¡ch lÃ  training lÃªn 30B tham sá»‘, hiá»‡n táº¡i má»›i chá»‰ train trong 6 thÃ¡ng, vá»›i mÃ´ hÃ¬nh 7B thÃ´i mÃ  nÃ³ khá»§ng váº­y rá»“i. CÃ¡c bÃ¡c Ä‘Ã¡nh giÃ¡ tiá»m nÄƒng cá»§a con LLM nÃ y nhÆ° tháº¿ nÃ o áº¡?","Tin chuáº©n Ä‘Ã©t mÃ¬nh cáº­p nháº­t cho ae, LLM cá»§a Zalo Ä‘Ã£ vÆ°á»£t ChatGPT3.5?? MÃ¬nh má»›i lÆ°á»›t tháº¥y buá»•i stream cá»§a Tinh táº¿ á»Ÿ sá»± kiá»‡n cá»§a Zalo, há» cháº¡y demo LLM má»›i cá»§a Zalo tÃ­ch há»£p vÃ o trong Kiki rá»“i thi vá»›i máº¥y cÃ¡i LLM khÃ¡c nhÆ° GPT3.5 Qwen...káº¿t quáº£ lÃ  Kiki chá»‰ thua con GPT-4!! Theo diá»…n giáº£i thÃ¬ LLM nÃ y Ä‘Æ°á»£c build báº±ng kiáº¿n trÃºc transformer, ká»¹ thuáº­t sá»­ dá»¥ng lÃ  Flash Attention cÅ©ng hao hao giá»‘ng nhÆ° cÃ¡ch build cá»§a open AI nhÆ°ng Ä‘iá»ƒm khÃ¡c biá»‡t lÃ  LLM nÃ y Ä‘Æ°á»£c training báº±ng dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao Báº°NG TIáº¾NG VIá»†T!!! Káº¿ hoáº¡ch lÃ  training lÃªn 30B tham sá»‘, hiá»‡n táº¡i má»›i chá»‰ train trong 6 thÃ¡ng, vá»›i mÃ´ hÃ¬nh 7B thÃ´i mÃ  nÃ³ khá»§ng váº­y rá»“i. CÃ¡c bÃ¡c Ä‘Ã¡nh giÃ¡ tiá»m nÄƒng cá»§a con LLM nÃ y nhÆ° tháº¿ nÃ o áº¡?",,,"#sharing, #deep_learning, #nlp","#sharing, #deep_learning, #nlp","#sharing, #deep_learning, #nlp"
"ChÃ o cÃ¡c báº¡n, mÃ¬nh vá»«a cáº­p nháº­t thÃªm section LLM cho list Vietnamese NLP resources cá»§a mÃ¬nh. Hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n má»›i báº¯t Ä‘áº§u ğŸ’ª","ChÃ o cÃ¡c báº¡n, mÃ¬nh vá»«a cáº­p nháº­t thÃªm section LLM cho list Vietnamese NLP resources cá»§a mÃ¬nh. Hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n má»›i báº¯t Ä‘áº§u",,,"#sharing, #deep_learning, #nlp","#sharing, #deep_learning, #nlp","#sharing, #deep_learning, #nlp"
GÃ³p vui vá»›i má»i ngÆ°á»i,GÃ³p vui vá»›i má»i ngÆ°á»i,,,#sharing,#sharing,#sharing
"Má»i ngÆ°á»i Æ¡i cho em há»i
CÃ³ nhá»¯ng cÃ¡ch nÃ o Ä‘á»ƒ lÃ m con chatbot cÃ³ thá»ƒ Ä‘á» xuáº¥t nhá»¯ng cÃ¢u há»i liÃªn quan tiáº¿p theo dá»±a vÃ o ngá»¯ cáº£nh áº¡ ( vÃ­ dá»¥ chatbot vá» sá»©c khá»e, vá» bitcoin,...)
VÃ  cÃ³ nhá»¯ng cÃ¡ch nÃ o Ä‘á»ƒ lÃ m giáº£m áº£o giÃ¡c","Má»i ngÆ°á»i Æ¡i cho em há»i CÃ³ nhá»¯ng cÃ¡ch nÃ o Ä‘á»ƒ lÃ m con chatbot cÃ³ thá»ƒ Ä‘á» xuáº¥t nhá»¯ng cÃ¢u há»i liÃªn quan tiáº¿p theo dá»±a vÃ o ngá»¯ cáº£nh áº¡ ( vÃ­ dá»¥ chatbot vá» sá»©c khá»e, vá» bitcoin,...) VÃ  cÃ³ nhá»¯ng cÃ¡ch nÃ o Ä‘á»ƒ lÃ m giáº£m áº£o giÃ¡c",,,"#Q&A, #nlp","#Q&A, #nlp",#Q&A
"PreTrain mÃ´ hÃ¬nh LLM
Xin chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, hiá»‡n táº¡i em Ä‘ang thá»­ train má»™t mÃ´ hÃ¬nh LLM open-source. Em cÃ³ 2 cÃ¢u há»i nhá» mong anh chá»‹ nÃ o cÃ³ kinh nghiá»‡m giáº£i Ä‘Ã¡p giÃºp.
1. MÃ¬nh nÃªn xÃ i thÆ° viá»‡n huggingface hay sá»­ dá»¥ng code tá»« ngÆ°á»i phÃ¡t triá»ƒn model Ä‘Ã³. VÃ­ dá»¥ LLama 2 thÃ¬ em tháº¥y cÃ³ thá»ƒ dÃ¹ng huggingface hoáº·c code cung cáº¥p tá»« google.
2. Xá»­ lÃ½ text: Theo nhiá»u code vÃ­ dá»¥ thÃ¬ há» ná»‘i text láº¡i vá»›i nhau rá»“i cáº¯t thÃ nh tá»«ng Ä‘oáº¡n (nhÆ° hÃ¬nh), khÃ´ng biáº¿t lÃ m theo cÃ¡ch nÃ y cÃ³ Ä‘áº£m báº£o context khÃ´ng? Do em Ä‘á»c bÃªn code Lama 2 thÃ¬ há» cÃ³ Ä‘á» cáº­p viá»‡c ná»‘i text nhÆ° váº­y thÃ¬ dá»… gÃ¢y nhiá»…u.
Má»™t cÃ¡ch khÃ¡c lÃ  padding theo sample Ä‘á»™ dÃ i lá»›n nháº¥t trong cÃ¹ng má»™t batch.
Anh chá»‹ dÃ¹ng cÃ¡ch nÃ o trong hai cÃ¡ch nÃ y hay cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o phÃ¹ há»£p hÆ¡n khÃ´ng áº¡?
Em cáº£m Æ¡n!","PreTrain mÃ´ hÃ¬nh LLM Xin chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, hiá»‡n táº¡i em Ä‘ang thá»­ train má»™t mÃ´ hÃ¬nh LLM open-source. Em cÃ³ 2 cÃ¢u há»i nhá» mong anh chá»‹ nÃ o cÃ³ kinh nghiá»‡m giáº£i Ä‘Ã¡p giÃºp. 1. MÃ¬nh nÃªn xÃ i thÆ° viá»‡n huggingface hay sá»­ dá»¥ng code tá»« ngÆ°á»i phÃ¡t triá»ƒn model Ä‘Ã³. VÃ­ dá»¥ LLama 2 thÃ¬ em tháº¥y cÃ³ thá»ƒ dÃ¹ng huggingface hoáº·c code cung cáº¥p tá»« google. 2. Xá»­ lÃ½ text: Theo nhiá»u code vÃ­ dá»¥ thÃ¬ há» ná»‘i text láº¡i vá»›i nhau rá»“i cáº¯t thÃ nh tá»«ng Ä‘oáº¡n (nhÆ° hÃ¬nh), khÃ´ng biáº¿t lÃ m theo cÃ¡ch nÃ y cÃ³ Ä‘áº£m báº£o context khÃ´ng? Do em Ä‘á»c bÃªn code Lama 2 thÃ¬ há» cÃ³ Ä‘á» cáº­p viá»‡c ná»‘i text nhÆ° váº­y thÃ¬ dá»… gÃ¢y nhiá»…u. Má»™t cÃ¡ch khÃ¡c lÃ  padding theo sample Ä‘á»™ dÃ i lá»›n nháº¥t trong cÃ¹ng má»™t batch. Anh chá»‹ dÃ¹ng cÃ¡ch nÃ o trong hai cÃ¡ch nÃ y hay cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o phÃ¹ há»£p hÆ¡n khÃ´ng áº¡? Em cáº£m Æ¡n!",,,"#Q&A, #nlp, #data","#Q&A, #nlp","#Q&A, #nlp"
"Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» RAG cho tiáº¿ng Viá»‡t. Hiá»‡n táº¡i pháº§n search context cá»§a em chá»‰ Ä‘áº¡t rank@1=64%, rank@5 = 92% (sá»­ dá»¥ng BM25 + Bi-encoder). Em Ä‘ang dÃ¹ng model SeaLLM 7B Ä‘á»ƒ lÃ m chatmodel nÃªn khi Ä‘Æ°a top 1 chunk_passage vÃ o thÃ¬ tá»‘n táº§m 30s/q. NhÆ°ng nhÆ° káº¿t quáº£ rank@1 cá»§a em chá»‰ Ä‘áº¡t 64% nÃªn nhá»¯ng cÃ¢u sai nÃ³ hay bá»‹a ra káº¿t quáº£ khÃ´ng Ä‘Ãºng, náº¿u Ä‘Æ°a qua 5 context thÃ¬ tá»‘n Ä‘áº¿n ~3 phÃºt. NÃªn em Ä‘ang tÃ¬m cÃ¡ch chá»n lá»±a ra context phÃ¹ há»£p Ä‘á»ƒ Ä‘Æ°a vÃ o, em Ä‘ang nghÄ© Ä‘áº¿n nhá»¯ng cÃ¡ch sau:
1. Sá»­ dá»¥ng cross-encoder Ä‘á»ƒ rerank láº¡i top 5, sau Ä‘Ã³ chá»n top 1. Em Ä‘Ã£ thá»­ qua cÃ¡c model cross-encoder cá»§a bÃªn cross-encoder/Ms-marco, nhÆ°ng nÃ³ láº¡i tá»‡ Ä‘i, cÃ³ váº» nÃ³ chá»‰ tá»‘t cho English. Vá» pháº§n nÃ y em muá»‘n há»i mn cÃ³ model cross-encoder tá»‘t cho tiáº¿ng Viá»‡t áº¡.
2. Sá»­ dá»¥ng thÃªm 1 model classification Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem trong top 5 context cÃ³ nhá»¯ng context nÃ o tráº£ lá»i cho question. Em cÅ©ng tÃ¬m model trÃªn huggingface nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c nÃªn em nghÄ© Ä‘áº¿n hÆ°á»›ng fine-tune trÃªn 3 bá»™: Viquad, Zalo2019 + Data cá»§a em. Tuy nhiÃªn, chá»‰ cÃ³ zalo2019 cÃ³ Ä‘á»§ nhÃ£n True-False rá»“i, cÃ²n bá»™ Viquad vÃ  Data cá»§a em thÃ¬ chá»‰ cÃ³ nhá»¯ng cáº·p True, nÃªn em muá»‘n há»i nÃªn táº¡o thÃªm nhá»¯ng cáº·p False nhÆ° nÃ o cho há»£p lÃ½. VÃ  em nÃªn lá»±a model nÃ o Ä‘á»ƒ fine-tune cho task nÃ y áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» RAG cho tiáº¿ng Viá»‡t. Hiá»‡n táº¡i pháº§n search context cá»§a em chá»‰ Ä‘áº¡t rank@1=64%, rank@5 = 92% (sá»­ dá»¥ng BM25 + Bi-encoder). Em Ä‘ang dÃ¹ng model SeaLLM 7B Ä‘á»ƒ lÃ m chatmodel nÃªn khi Ä‘Æ°a top 1 chunk_passage vÃ o thÃ¬ tá»‘n táº§m 30s/q. NhÆ°ng nhÆ° káº¿t quáº£ rank@1 cá»§a em chá»‰ Ä‘áº¡t 64% nÃªn nhá»¯ng cÃ¢u sai nÃ³ hay bá»‹a ra káº¿t quáº£ khÃ´ng Ä‘Ãºng, náº¿u Ä‘Æ°a qua 5 context thÃ¬ tá»‘n Ä‘áº¿n ~3 phÃºt. NÃªn em Ä‘ang tÃ¬m cÃ¡ch chá»n lá»±a ra context phÃ¹ há»£p Ä‘á»ƒ Ä‘Æ°a vÃ o, em Ä‘ang nghÄ© Ä‘áº¿n nhá»¯ng cÃ¡ch sau: 1. Sá»­ dá»¥ng cross-encoder Ä‘á»ƒ rerank láº¡i top 5, sau Ä‘Ã³ chá»n top 1. Em Ä‘Ã£ thá»­ qua cÃ¡c model cross-encoder cá»§a bÃªn cross-encoder/Ms-marco, nhÆ°ng nÃ³ láº¡i tá»‡ Ä‘i, cÃ³ váº» nÃ³ chá»‰ tá»‘t cho English. Vá» pháº§n nÃ y em muá»‘n há»i mn cÃ³ model cross-encoder tá»‘t cho tiáº¿ng Viá»‡t áº¡. 2. Sá»­ dá»¥ng thÃªm 1 model classification Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem trong top 5 context cÃ³ nhá»¯ng context nÃ o tráº£ lá»i cho question. Em cÅ©ng tÃ¬m model trÃªn huggingface nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c nÃªn em nghÄ© Ä‘áº¿n hÆ°á»›ng fine-tune trÃªn 3 bá»™: Viquad, Zalo2019 + Data cá»§a em. Tuy nhiÃªn, chá»‰ cÃ³ zalo2019 cÃ³ Ä‘á»§ nhÃ£n True-False rá»“i, cÃ²n bá»™ Viquad vÃ  Data cá»§a em thÃ¬ chá»‰ cÃ³ nhá»¯ng cáº·p True, nÃªn em muá»‘n há»i nÃªn táº¡o thÃªm nhá»¯ng cáº·p False nhÆ° nÃ o cho há»£p lÃ½. VÃ  em nÃªn lá»±a model nÃ o Ä‘á»ƒ fine-tune cho task nÃ y áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,"#Q&A, #nlp, #deep_learning, #data","#Q&A, #nlp, #deep_learning, #data","#Q&A, #nlp, #deep_learning, #data"
"CÃ¢u chuyá»‡n thá»±c nhÆ° tháº¿ nÃ o thÃ¬ mÃ¬nh chÆ°a rÃµ, nhÆ°ng bÃ i dÆ°á»›i Ä‘Ã¢y cá»§a JÃ¼rgen Schmidhuber chá»©ng minh vá» viá»‡c 3 nhÃ  khoa há»c Ä‘Æ°á»£c nháº­n giáº£i Alan Turing lÃ  Hinton, Bengio vÃ  LeCun Ä‘Ã£ khÃ´ng trÃ­ch dáº«n cÃ¡c cÃ´ng trÃ¬nh cá»§a Ã´ng vÃ  má»™t sá»‘ nhÃ  khoa há»c khÃ¡c. Hay nÃ³i cÃ¡ch khÃ¡c, má»™t sá»‘ cÃ´ng trÃ¬nh khoa há»c mang tÃ­nh Ä‘á»™t phÃ¡ cá»§a 3 nhÃ  khoa há»c nÃ³i trÃªn, Ä‘Ã£ cÃ³ ngÆ°á»i lÃ m trÆ°á»›c Ä‘Ã³ (lÃ  JÃ¼rgen Schmidhuber vÃ  má»™t sá»‘ ngÆ°á»i khÃ¡c!). ChÃºng ta cÃ¹ng chá» xem pháº£n á»©ng cá»§a 3 nhÃ  khoa há»c danh tiáº¿ng nÃ y vÃ  cáº£ cá»™ng Ä‘á»“ng nhÆ° tháº¿ nÃ o trÆ°á»›c báº±ng chá»©ng Schmidhuber Ä‘Æ°a ra táº¡i Ä‘Ã¢y nhÃ© https://people.idsia.ch/~juergen/ai-priority-disputes.html","CÃ¢u chuyá»‡n thá»±c nhÆ° tháº¿ nÃ o thÃ¬ mÃ¬nh chÆ°a rÃµ, nhÆ°ng bÃ i dÆ°á»›i Ä‘Ã¢y cá»§a JÃ¼rgen Schmidhuber chá»©ng minh vá» viá»‡c 3 nhÃ  khoa há»c Ä‘Æ°á»£c nháº­n giáº£i Alan Turing lÃ  Hinton, Bengio vÃ  LeCun Ä‘Ã£ khÃ´ng trÃ­ch dáº«n cÃ¡c cÃ´ng trÃ¬nh cá»§a Ã´ng vÃ  má»™t sá»‘ nhÃ  khoa há»c khÃ¡c. Hay nÃ³i cÃ¡ch khÃ¡c, má»™t sá»‘ cÃ´ng trÃ¬nh khoa há»c mang tÃ­nh Ä‘á»™t phÃ¡ cá»§a 3 nhÃ  khoa há»c nÃ³i trÃªn, Ä‘Ã£ cÃ³ ngÆ°á»i lÃ m trÆ°á»›c Ä‘Ã³ (lÃ  JÃ¼rgen Schmidhuber vÃ  má»™t sá»‘ ngÆ°á»i khÃ¡c!). ChÃºng ta cÃ¹ng chá» xem pháº£n á»©ng cá»§a 3 nhÃ  khoa há»c danh tiáº¿ng nÃ y vÃ  cáº£ cá»™ng Ä‘á»“ng nhÆ° tháº¿ nÃ o trÆ°á»›c báº±ng chá»©ng Schmidhuber Ä‘Æ°a ra táº¡i Ä‘Ã¢y nhÃ© https://people.idsia.ch/~juergen/ai-priority-disputes.html",,,#sharing,#sharing,#sharing
"Generate Questions
ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n mÃ´n há»c trÃªn trÆ°á»ng vá»›i dataset lÃ  táº­p Quora Question Pairs (https://paperswithcode.com/dataset/quora-question-pairs)
CÃ¡c trÆ°á»ng cá»§a dá»¯ liá»‡u:
â¦ id: ID cá»§a cáº·p cÃ¢u há»i
â¦ qid1, qid2: chá»©a ID cho má»—i cÃ¢u há»i trong cáº·p
â¦ question1, question2: ná»™i dung cá»§a cÃ¡c cÃ¢u há»i trong cáº·
â¦ is_duplicate: má»™t giÃ¡ trá»‹ nhá»‹ phÃ¢n chá»‰ ra xem dÃ²ng Ä‘Ã³ cÃ³ chá»©a má»™t cáº·p cÃ¢u há»i trÃ¹ng láº·p hay khÃ´ng
Trong Ä‘á»“ Ã¡n em cÃ³ 1 task lÃ  sinh thÃªm cÃ¡c cáº·p cÃ¢u há»i tÆ°Æ¡ng Ä‘á»“ng á»Ÿ cÃ¡c topic Ã­t cÃ¢u há»i (vÃ¬ dataset khÃ¡ máº¥t cÃ¢n báº±ng)
Vá»›i Task trÃªn em Ä‘Ã£ chia thÃ nh 2 task nhá» hÆ¡n lÃ 
- PhÃ¢n loáº¡i dataset thÃ nh cÃ¡c topic: Em Ä‘Ã£ dÃ¹ng LDA Model Ä‘á»ƒ phÃ¢n loáº¡i vÃ  chá»n Ä‘Æ°á»£c cÃ¡c topic Ã­t cÃ¢u há»i, vá»›i output nhÆ° hÃ¬nh dÆ°á»›i.
- Sinh thÃªm cÃ¡c cáº·p cÃ¢u há»i tÆ°Æ¡ng Ä‘á»“ng á»Ÿ cÃ¡c chá»§ Ä‘á» Ã­t (Ä‘á»ƒ lÃ m cÃ¢n báº±ng dataset thÃ¬ sá»‘ lÆ°á»£ng cáº·p cÃ¢u há»i cáº§n sinh ~ 10k)
á» task thá»© 2: Sinh thÃªm cÃ¡c cáº·p cÃ¢u há»i thÃ¬ em chÆ°a nghÄ© ra hÆ°á»›ng giáº£i quyáº¿t nÃ o (trá»« viá»‡c viáº¿t prompt cho cÃ¡c cÃ´ng cá»¥ AI hiá»‡n nay)
Mong a/c vÃ  má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.
Em cáº£m Æ¡n.","Generate Questions ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n mÃ´n há»c trÃªn trÆ°á»ng vá»›i dataset lÃ  táº­p Quora Question Pairs (https://paperswithcode.com/dataset/quora-question-pairs) CÃ¡c trÆ°á»ng cá»§a dá»¯ liá»‡u: id: ID cá»§a cáº·p cÃ¢u há»i qid1, qid2: chá»©a ID cho má»—i cÃ¢u há»i trong cáº·p question1, question2: ná»™i dung cá»§a cÃ¡c cÃ¢u há»i trong cáº· is_duplicate: má»™t giÃ¡ trá»‹ nhá»‹ phÃ¢n chá»‰ ra xem dÃ²ng Ä‘Ã³ cÃ³ chá»©a má»™t cáº·p cÃ¢u há»i trÃ¹ng láº·p hay khÃ´ng Trong Ä‘á»“ Ã¡n em cÃ³ 1 task lÃ  sinh thÃªm cÃ¡c cáº·p cÃ¢u há»i tÆ°Æ¡ng Ä‘á»“ng á»Ÿ cÃ¡c topic Ã­t cÃ¢u há»i (vÃ¬ dataset khÃ¡ máº¥t cÃ¢n báº±ng) Vá»›i Task trÃªn em Ä‘Ã£ chia thÃ nh 2 task nhá» hÆ¡n lÃ  - PhÃ¢n loáº¡i dataset thÃ nh cÃ¡c topic: Em Ä‘Ã£ dÃ¹ng LDA Model Ä‘á»ƒ phÃ¢n loáº¡i vÃ  chá»n Ä‘Æ°á»£c cÃ¡c topic Ã­t cÃ¢u há»i, vá»›i output nhÆ° hÃ¬nh dÆ°á»›i. - Sinh thÃªm cÃ¡c cáº·p cÃ¢u há»i tÆ°Æ¡ng Ä‘á»“ng á»Ÿ cÃ¡c chá»§ Ä‘á» Ã­t (Ä‘á»ƒ lÃ m cÃ¢n báº±ng dataset thÃ¬ sá»‘ lÆ°á»£ng cáº·p cÃ¢u há»i cáº§n sinh ~ 10k) á» task thá»© 2: Sinh thÃªm cÃ¡c cáº·p cÃ¢u há»i thÃ¬ em chÆ°a nghÄ© ra hÆ°á»›ng giáº£i quyáº¿t nÃ o (trá»« viá»‡c viáº¿t prompt cho cÃ¡c cÃ´ng cá»¥ AI hiá»‡n nay) Mong a/c vÃ  má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡. Em cáº£m Æ¡n.",,,"#Q&A, #deep_learning, #data","#Q&A, #data","#Q&A, #data"
MÃ¬nh má»›i dev má»™t con chat-bot AI khÃ¡ hay báº¡n nÃ o quan tÃ¢m khÃ´ng =))),MÃ¬nh má»›i dev má»™t con chat-bot AI khÃ¡ hay báº¡n nÃ o quan tÃ¢m khÃ´ng =))),,,#sharing,"#sharing, #nlp","#sharing, #nlp"
"VinAI Seminar - ""SeaLLMs - Large Language Models for Southeast Asia""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Xuan Phi Nguyen - DAMO Academy, Alibaba Group
Time: 02:30 pm - 03:30 pm (GMT+7), Dec 18, 2023","VinAI Seminar - ""SeaLLMs - Large Language Models for Southeast Asia"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Xuan Phi Nguyen - DAMO Academy, Alibaba Group Time: 02:30 pm - 03:30 pm (GMT+7), Dec 18, 2023",,,#webinar,#webinar,#webniar
"ChÃ o má»i ngÆ°á»i, cÃ³ ai muá»‘n cÃ¹ng reproduce nghiÃªn cá»©u nÃ y vá»›i e khÃ´ng áº¡? MÃ´ hÃ¬nh phÃ¡t hiá»‡n thuá»‘c dáº¡ng viÃªn cá»§a VAIPE 
Reproduce má»™t pháº§n Ä‘á»ƒ luyá»‡n táº­p, má»™t pháº§n vÃ¬ em tháº¥y cÃ³ má»™t chá»— láº¥n cáº¥n trong mÃ´ hÃ¬nh nÃ y lÃ  sá»­ dá»¥ng Ä‘á»“ thá»‹ cÃ³ ma tráº­n trá»ng sá»‘ cÃ³ rank báº±ng 1 (*), biáº¿t Ä‘Ã¢u thá»­ nghiá»‡m láº¡i cho ra cÃ¡i gÃ¬ hay ho thÃ¬ sao ğŸ˜
Paper: https://doi.org/10.1371/journal.pone.0291865
TÃ i liá»‡u chá»‰ ra hiá»‡n tÆ°á»£ng(*): https://docs.google.com/document/d/1YIulq6iwg3d8-Q4c8MqNcGYuqkNPjD-sQNIyLSk0sxo/edit?usp=sharing","ChÃ o má»i ngÆ°á»i, cÃ³ ai muá»‘n cÃ¹ng reproduce nghiÃªn cá»©u nÃ y vá»›i e khÃ´ng áº¡? MÃ´ hÃ¬nh phÃ¡t hiá»‡n thuá»‘c dáº¡ng viÃªn cá»§a VAIPE Reproduce má»™t pháº§n Ä‘á»ƒ luyá»‡n táº­p, má»™t pháº§n vÃ¬ em tháº¥y cÃ³ má»™t chá»— láº¥n cáº¥n trong mÃ´ hÃ¬nh nÃ y lÃ  sá»­ dá»¥ng Ä‘á»“ thá»‹ cÃ³ ma tráº­n trá»ng sá»‘ cÃ³ rank báº±ng 1 (*), biáº¿t Ä‘Ã¢u thá»­ nghiá»‡m láº¡i cho ra cÃ¡i gÃ¬ hay ho thÃ¬ sao Paper: https://doi.org/10.1371/journal.pone.0291865 TÃ i liá»‡u chá»‰ ra hiá»‡n tÆ°á»£ng(*): https://docs.google.com/document/d/1YIulq6iwg3d8-Q4c8MqNcGYuqkNPjD-sQNIyLSk0sxo/edit?usp=sharing",,,"#Q&A, #cv","#Q&A, #cv","#Q&A, #cv"
"This is a Wikipedia-based image-text dataset for Vietnamese. It's extracted from Google WIT (https://github.com/google-research-datasets/wit/blob/main/DATA.md). It contains raw images from Wikipedia (over 200 GBs). It can be used for image captioning, image-text retrieval, ...
https://huggingface.co/datasets/dinhanhx/google-wit-vi","This is a Wikipedia-based image-text dataset for Vietnamese. It's extracted from Google WIT (https://github.com/google-research-datasets/wit/blob/main/DATA.md). It contains raw images from Wikipedia (over 200 GBs). It can be used for image captioning, image-text retrieval, ... https://huggingface.co/datasets/dinhanhx/google-wit-vi",,,"#data, #sharing","#data, #sharing","#sharing, #data"
"chÃ o má»i ngÆ°á»i áº¡. em Ä‘ang gáº·p bÃ i toÃ¡n vá» phÃ¡t Ã¢m tiáº¿ng anh sang tiáº¿ng viá»‡t thÃ¬ khÃ´ng biáº¿t nÃªn dÃ¹ng model hay hÆ°á»›ng nÃ o Ä‘á»ƒ cÃ³ thá»ƒ giáº£i quyáº¿t áº¡. em tÃ¬m hiá»ƒu tiáº¿ng anh sang tiáº¿ng anh, hoáº·c tiáº¿ng viá»‡t sang tiáº¿ng viá»‡t thÃ¬ cÃ¡i phoneme dá»… lÃ m. chá»© tiáº¿ng anh sang tiáº¿ng viá»‡t em Ä‘ang khÃ´ng biáº¿t lÃ m phoneme nhÆ° nÃ o.
input : smart
output: xá» mÃ¡t","chÃ o má»i ngÆ°á»i áº¡. em Ä‘ang gáº·p bÃ i toÃ¡n vá» phÃ¡t Ã¢m tiáº¿ng anh sang tiáº¿ng viá»‡t thÃ¬ khÃ´ng biáº¿t nÃªn dÃ¹ng model hay hÆ°á»›ng nÃ o Ä‘á»ƒ cÃ³ thá»ƒ giáº£i quyáº¿t áº¡. em tÃ¬m hiá»ƒu tiáº¿ng anh sang tiáº¿ng anh, hoáº·c tiáº¿ng viá»‡t sang tiáº¿ng viá»‡t thÃ¬ cÃ¡i phoneme dá»… lÃ m. chá»© tiáº¿ng anh sang tiáº¿ng viá»‡t em Ä‘ang khÃ´ng biáº¿t lÃ m phoneme nhÆ° nÃ o. input : smart output: xá» mÃ¡t",,,#Q&A,"#Q&A, #nlp",#Q&A
"KhÃ³a há»c NLP with Deep Learning cá»§a Ä‘áº¡i há»c Stanford má»›i má»Ÿ trÃªn youtube 2023 khÃ¡ hay báº¡n nÃ o quan tÃ¢m thÃ¬ cÃ³ thá»ƒ tham kháº£o nhÃ©, cÃ¡c video sáº½ cÃ²n update thÃªm trong thá»i gian tá»›i.","KhÃ³a há»c NLP with Deep Learning cá»§a Ä‘áº¡i há»c Stanford má»›i má»Ÿ trÃªn youtube 2023 khÃ¡ hay báº¡n nÃ o quan tÃ¢m thÃ¬ cÃ³ thá»ƒ tham kháº£o nhÃ©, cÃ¡c video sáº½ cÃ²n update thÃªm trong thá»i gian tá»›i.",,,"#sharing, #nlp","#sharing, #nlp, #deep_learning","#sharing, #nlp, #deep_learning"
"[Free Online Ebook] Christopher M. Bishop & Hugh Bishop vá»«a xuáº¥t báº£n má»™t quyá»ƒn sÃ¡ch má»›i vá» Deep Learning vá»›i hÃ m lÆ°á»£ng ná»™i dung Ä‘á»“ sá»™, cáº­p nháº­t, Ä‘Æ°á»£c Ä‘áº§u tÆ° tá»‰ má»‰ tá»« giáº£i thÃ­ch, vÃ­ dá»¥, mÃ£ giáº£, kÃ¨m vá»›i bÃ i táº­p má»—i chÆ°Æ¡ng.
SÃ¡ch cÃ³ thá»ƒ Ä‘á»c miá»…n phÃ­ báº£n online, trá»±c tiáº¿p trÃªn trang chá»§ (hoáº·c thÃ´ng qua ná»n táº£ng issuu).","[Free Online Ebook] Christopher M. Bishop & Hugh Bishop vá»«a xuáº¥t báº£n má»™t quyá»ƒn sÃ¡ch má»›i vá» Deep Learning vá»›i hÃ m lÆ°á»£ng ná»™i dung Ä‘á»“ sá»™, cáº­p nháº­t, Ä‘Æ°á»£c Ä‘áº§u tÆ° tá»‰ má»‰ tá»« giáº£i thÃ­ch, vÃ­ dá»¥, mÃ£ giáº£, kÃ¨m vá»›i bÃ i táº­p má»—i chÆ°Æ¡ng. SÃ¡ch cÃ³ thá»ƒ Ä‘á»c miá»…n phÃ­ báº£n online, trá»±c tiáº¿p trÃªn trang chá»§ (hoáº·c thÃ´ng qua ná»n táº£ng issuu).",,,"#sharing, #deep_learning","#sharing, #deep_learning","#sharing, #deep_learning, #docs"
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2023 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2023 vÃ o comment cá»§a post nÃ y.",,,#sharing,#sharing,
"MÃ¬nh cÃ³ project lÃ m vá» IoT sá»­ dá»¥ng cÃ´ng nghá»‡ truyá»n thÃ´ng khÃ´ng dÃ¢y Lora báº¡n nÃ o thÃ­ch thÃ¬ cÃ³ thá»ƒ clone vá» nhÃ© ráº¥t thÃ­ch há»£p cho cÃ¡c báº¡n sinh viÃªn lÃ m Ä‘á»“ Ã¡n :)
CÃ¡c báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng machine learning vÃ  AI vÃ o pháº§n quáº£n lÃ­ nÄƒng lÆ°á»£ng thÃ´ng minh cho thiáº¿t bá»‹ khÃ¡ hay mÃ¬nh cÃ³ lÃ m má»™t web-app monitor :D",MÃ¬nh cÃ³ project lÃ m vá» IoT sá»­ dá»¥ng cÃ´ng nghá»‡ truyá»n thÃ´ng khÃ´ng dÃ¢y Lora báº¡n nÃ o thÃ­ch thÃ¬ cÃ³ thá»ƒ clone vá» nhÃ© ráº¥t thÃ­ch há»£p cho cÃ¡c báº¡n sinh viÃªn lÃ m Ä‘á»“ Ã¡n :) CÃ¡c báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng machine learning vÃ  AI vÃ o pháº§n quáº£n lÃ­ nÄƒng lÆ°á»£ng thÃ´ng minh cho thiáº¿t bá»‹ khÃ¡ hay mÃ¬nh cÃ³ lÃ m má»™t web-app monitor :D,,,"#sharing, #machine_learning, #deep_learning","#sharing, #machine_learning","#sharing, #machine_learning"
"Ae cho em há»i ráº±ng náº¿u cÃ³ má»™t feature gá»“m sá»‘ lÆ°á»£ng lá»›n giÃ¡ trá»‹ khÃ´ng trÃ¹ng láº·p lÃ  dáº¡ng categorical (800-1000).
Náº¿u khÃ´ng thá»ƒ xá»­ lÃ­ cÃ¡c giÃ¡ trá»‹ nÃ y báº±ng one hot encoding thÃ¬ xá»­ lÃ­ ra sao áº¡",Ae cho em há»i ráº±ng náº¿u cÃ³ má»™t feature gá»“m sá»‘ lÆ°á»£ng lá»›n giÃ¡ trá»‹ khÃ´ng trÃ¹ng láº·p lÃ  dáº¡ng categorical (800-1000). Náº¿u khÃ´ng thá»ƒ xá»­ lÃ­ cÃ¡c giÃ¡ trá»‹ nÃ y báº±ng one hot encoding thÃ¬ xá»­ lÃ­ ra sao áº¡,,,"#Q&A, #machine_learning, #data","#Q&A, #data","#Q&A, #data"
"ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº»!
BÃ¬nh thÆ°á»ng, mÃ¬nh khÃ´ng muá»‘n viáº¿t nhá»¯ng thá»© nhÆ° tháº¿ nÃ y, vÃ  khÃ´ng nhá» má»i ngÆ°á»i chia sáº» hay Ä‘áº©y tÆ°Æ¡ng tÃ¡c, nhÆ°ng mÃ¬nh nghÄ© nÃ³ ráº¥t quan trá»ng. Nhá»¯ng thá»© mÃ¬nh sáº¯p viáº¿t dÆ°á»›i Ä‘Ã¢y sáº½ ráº¥t khÃ³ hiá»ƒu, vÃ  hoÃ n toÃ n lÃ  quan Ä‘iá»ƒm cÃ¡ nhÃ¢n, nhÆ°ng sáº½ dáº«n chá»©ng khoa há»c Ä‘áº§y Ä‘á»§.
Nháº¯c láº¡i, Ä‘Ã¢y toÃ n hoÃ n lÃ  quan Ä‘iá»ƒm cÃ¡ nhÃ¢n.
I. Vá» tÃ¡c giáº£
VÃ¬ nhá»¯ng Ä‘iá»u mÃ¬nh viáº¿t sáº½ quan trá»ng (Ã­t nháº¥t lÃ  vá»›i mÃ¬nh), nÃªn mÃ¬nh sáº½ giá»›i thiá»‡u sÆ¡ lÆ°á»£c vá» báº£n thÃ¢n, vÃ¬ khÃ´ng pháº£i ai cÅ©ng biáº¿t mÃ¬nh. MÃ¬nh gáº¯n bÃ³ vá»›i lÄ©nh vá»±c trÃ­ tuáº­ nhÃ¢n táº¡o (AI) Ä‘Æ°á»£c khoáº£ng 15 nÄƒm (bao gá»“m cáº£ há»c vÃ  lÃ m). MÃ¬nh láº¥y báº±ng AI á»Ÿ Kanazawa University, tá»«ng lÃ m giÃ¡m Ä‘á»‘c cÃ´ng nghá»‡ (CTO) cho vÃ i cÃ´ng ty, cÃ³ má»™t sá»‘ cÃ¡c giáº£i thÆ°á»Ÿng cÃ¡ nhÃ¢n uy tÃ­n. MÃ¬nh cÅ©ng lÃ  má»™t ngÆ°á»i ngáº¡i drama, nÃªn mÃ¬nh cÅ©ng khÃ´ng tÃ­ch cá»±c hoáº¡t Ä‘á»™ng láº¯m trÃªn máº¡ng xÃ£ há»™i.
Láº§n nÃ y mÃ¬nh sáº½ viáº¿t trÃ­ tuá»‡ nhÃ¢n táº¡o, vÃ  táº¡i sao mÃ¬nh nghÄ© nÃ³ Ráº¤T RÃ‚T NGUY HIá»‚M. MÃ¬nh sáº½ viáº¿t má»™t cÃ¡ch ráº¥t ngáº¯n gá»n, vÃ  khÃ´ng dÃ¹ng nhá»¯ng tá»« ngá»¯ khoa há»c, vÃ¬ mÃ¬nh muá»‘n má»i ngÆ°á»i Ä‘á»c hiá»ƒu vÃ  lan truyá»n. MÃ¬nh sáº½ dÃ¹ng má»™t sá»‘ tá»« ngá»¯ khoa há»c, nhÆ°ng mÃ¬nh sáº½ giáº£i thÃ­ch chÃºng.
II. Vá» trÃ­ tuá»‡ nhÃ¢n táº¡o
TrÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u vá» cÃ¡ch lÃ m cho mÃ¡y tÃ­nh cÃ³ thá»ƒ há»c vÃ  lÃ m nhá»¯ng viá»‡c mÃ  con ngÆ°á»i lÃ m. NÃ³i má»™t cÃ¡ch Ä‘Æ¡n giáº£n, lÃ  táº¡o ra TRÃ TUá»† cá»§a con ngÆ°á»i qua mÃ¡y tÃ­nh (tá»« nghe nÃ³i Ä‘á»c viáº¿t Ä‘áº¿n ráº¥t nhiá»u thá»© phá»©c táº¡p khÃ¡c, cho Ä‘áº¿n kháº£ nÄƒng NHáº¬N THá»¨C vÃ  TÆ¯ DUY).
NHáº¬N THá»¨C lÃ  kháº£ nÄƒng nháº­n biáº¿t, hiá»ƒu biáº¿t, vÃ  hÃ¬nh thÃ nh nháº­n thá»©c vá» tháº¿ giá»›i xung quanh.
TÆ¯ DUY lÃ  kháº£ nÄƒng suy nghÄ©, phÃ¢n tÃ­ch, vÃ  Ä‘Æ°a ra nhá»¯ng quyáº¿t Ä‘á»‹nh.
MÃ¬nh sáº½ chia AI ra lÃ m ba giai Ä‘oáº¡n Ä‘á»ƒ phÃ¹ há»£p vá»›i ná»™i dung bÃ i viáº¿t nÃ y:
- Giai Ä‘oáº¡n trÆ°á»›c Deep Learning: ÄÃ¢y lÃ  giai Ä‘oáº¡n AI chá»§ yáº¿u bao gá»“m cÃ¡c cÃ¡c phÆ°Æ¡ng phÃ¡p xáº¥p xá»‰, tá»‘i Æ°u tÃ¬m kiáº¿m vÃ  má»™t sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n khÃ¡c. Äá»“ng thá»i cÃ¡c táº­p dá»¯ liá»‡u cÅ©ng nhá» vÃ  thÃ´ sÆ¡.
- Giai Ä‘oáº¡n Deep Learning: ÄÃ¢y lÃ  giai Ä‘oáº¡n ráº¥t thÃº vá»‹, khi mÃ  cÃ¡c mÃ´ hÃ¬nh AI Ä‘Ã£ cÃ³ kháº£ nÄƒng, báº±ng cÃ¡ch mÃ´ phá»ng theo cÃ¡ch con ngÆ°á»i suy nghÄ©, Ä‘Æ°a/tÃ¬m ra nhá»¯ng features (táº¡m hiá»ƒu lÃ  nhá»¯ng Ä‘áº·c trÆ°ng cá»§a dá»¯ liá»‡u/káº¿t quáº£), Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c káº¿t quáº£ mong muá»‘n. CÃ¡c mÃ´ hÃ¬nh trá»Ÿ nÃªn lá»›n hÆ¡n, phá»©c táº¡p hÆ¡n, Ä‘a nhiá»‡m hÆ¡n. Äá»“ng thá»i, cÃ¡c táº­p dá»¯ liá»‡u cÅ©ng lá»›n hÆ¡n, vÃ  Ä‘a dáº¡ng hÆ¡n. MÃ´ hÃ¬nh Deep Learning ná»•i tiáº¿ng Ä‘áº§u tiÃªn, Alexnet [1], Ä‘Ã£ cáº£i thiá»‡n 10% Ä‘á»™ chÃ­nh xÃ¡c so vá»›i cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³.
- Giai Ä‘oáº¡n genAI (or maybe, AGI): Ai á»Ÿ giai Ä‘oáº¡n nÃ y Ä‘áº¡t Ä‘áº¿n dá»™ phá»• biáº¿n rá»™ng rÃ£i (chatGPT, MidJourney, vÃ  ráº¥t nhiá»u cÃ¡c AI khÃ¡c), vÃ  cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c ráº¥t nhiá»u cÃ¡c cÃ´ng viá»‡c cá»§a con ngÆ°á»i. AI cÃ³ thá»ƒ sÃ¡ng táº¡o/chá»‰nh sá»­a theo Ã½ con ngÆ°á»i tá»« ná»™i dung, hÃ¬nh áº£nh, Ã¢m thanh, video, pháº§m má»m vÃ  ráº¥t nhiá»u thá»© khÃ¡c.
III. Vá» nhá»¯ng gÃ¬ mÃ¬nh nghÄ© vá» AI trong 1 nÄƒm qua
ÄÃ¢y sáº½ lÃ  Ä‘oáº¡n quan trá»ng nháº¥t cá»§a bÃ i viáº¿t, nÃªn mÃ¬nh mong muá»‘n má»i ngÆ°á»i Ä‘á»c vÃ  PHáº¢N BIá»†N/CHIA Sáºº nÃ³. Tá»« Ä‘oáº¡n nÃ y sáº½ mang nhiá»u suy nghÄ© cÃ¡ nhÃ¢n vá»›i cÃ¡c trÃ­ch dáº«n khoa há»c nháº¥t.
LÃ­ do MÃŒNH VIáº¾T BÃ€I VIáº¾T NÃ€Y lÃ  do mÃ¬nh tin ráº±ng, AI ÄANG PHÃT TRIá»‚N QUA NHANH TRONG KHI CHÃšNG TA CHÆ¯A THá»°C Sá»° HIá»‚U Vá»€ NÃ“. Trong giai Ä‘oáº¡n cá»§a Deep Learning, Ai thá»±c sá»± khÃ¡ an toÃ n. Má»i ngÆ°á»i vÃ  mÃ¬nh hiá»ƒu rÃµ vá» cÃ¡c thuáº­t toÃ¡n, vá» cÃ¡ch nÃ³ hoáº¡t Ä‘á»™ng, vÃ  vá» cÃ¡ch nÃ³ há»c. Sá»± vÆ°á»£t trá»™i vá» kháº£ nÄƒng cá»§a Deep Learning lÃ  giáº£i thÃ­ch Ä‘Æ°á»£c, vÃ  náº±m trong viá»‡c dá»± liá»‡u cá»§a má»i ngÆ°á»i. NgoÃ i ra, cÃ¡c mÃ´ hÃ¬nh NLP [2, 3] cÅ©ng khÃ´ng cho tháº¥y sá»± tiáº¿p cáº­n vá»›i trÃ­ thÃ´ng minh cá»§a con ngÆ°á»i.
á» thá»i Ä‘iá»ƒm nÃ y, genAI khÃ´ng cho mÃ¬nh vÃ  cÃ¡c chuyÃªn gia Ä‘áº§u ngÃ nh cáº£m giÃ¡c nhÆ° váº­y [4]. MÃ¬nh biáº¿t vá» GPT 4 nÄƒm vá» trÆ°á»›c, viáº¿t vá» nÃ³ khoáº£ng 3 nÄƒm trÆ°á»›c, cho Ä‘áº¿n khi chatGPT má»›i ra máº¯t, mÃ¬nh váº«n hiá»ƒu rÃµ vá» mÃ´ hÃ¬nh AI nÃ y. Tuy váº­y, cáº£m giÃ¡c nÃ y hoÃ n toÃ n khÃ´ng cÃ²n. MÃ¬nh biáº¿t chatGPT khÃ´ng Ä‘Æ¡n thuáº§n lÃ  má»™t mÃ´ hÃ¬nh AI, nÃ³ lÃ  má»™t system vá»›i core-AI lÃ  cÃ¡c GPT models, nhÆ°ng kháº£ nÄƒng cá»§a GPT Ä‘á»‘i vá»›i mÃ¬nh hiá»‡n nay lÃ  khÃ´ng lÃ­ giáº£i Ä‘Æ°á»£c. GPT máº¡nh máº½ hÆ¡n ráº¥t nhiá»u so vá»›i cáº¥u trÃºc vÃ  lÆ°á»£ng dá»¯ liá»‡u nÃ³ cÃ³, vÃ  mÃ¬nh khÃ´ng thá»ƒ lÃ­ giáº£i Ä‘Æ°á»£c táº¡i sao nÃ³ láº¡i máº¡nh máº½ tá»›i váº­y. CÃ¡c nhÃ  nghiÃªn cá»©u táº¡i Microsoft, cÃ¡ch Ä‘Ã¢y gáº§n ná»­a nÄƒm, Ä‘Ã£ cho ráº±ng ""ChatGPT-4 lÃ m loÃ© lÃªn Ã¡nh lá»­a vá» AGI (trÃ­ thÃ´ng minh phá»• quÃ¡t)"" [5]. Hoáº·c gáº§n Ä‘Ã¢y, Stanford Ä‘Ã£ xÃ¢y dá»±ng má»™t thÃ­ nghiá»‡m, mÃ  Ä‘á»‘i vá»›i mÃ¬nh Ä‘Ã³ lÃ  má»™t tháº¿ giá»›i giáº£ láº­p nhÆ° trong Matrix, vá» má»™t xÃ£ há»™i thu nhá» cá»§a cÃ¡c AIs [6]. Táº¥t cáº£ diá»…n ra chá»‰ trong vÃ²ng má»™t nÄƒm, vá»›i tá»‘c Ä‘á»™ cÃ ng ngÃ y cÃ ng dá»“n dáº­p hÆ¡n.
MÃ¬nh luÃ´n tin ráº±ng ráº¥t khÃ³ Ä‘á»ƒ trÃ³i buá»™c AI báº±ng luáº­t (rule) hay Ä‘áº¡o Ä‘á»©c (ethics). Vá»›i má»™t ngÆ°á»i tá»«ng lÃ m startup, mÃ¬nh nghÄ© ráº±ng tá»‘i Æ°u má»¥c tiÃªu sáº½ pháº£i bá» qua ráº¥t nhiá»u vá» nhá»¯ng rÃ ng buá»™c, vÃ  pháº£i máº¡o hiá»ƒm, bá» qua cÃ¡c rÃ o cáº£n an toÃ n Ä‘á»ƒ nhanh chÃ³ng Ä‘áº¡t Ä‘Æ°á»£c má»¥c Ä‘Ã­ch. Vá»›i sá»± kiá»‡n cá»§a Sam Altman táº¡i OpenAI [7], cÃ³ thá»ƒ tháº¥y rÃµ ráº±ng táº¥t cáº£ cÃ¡c Ã´ng lá»›n Ä‘á»u Ä‘ang á»Ÿ trong cuá»™c Ä‘ua khá»‘c liá»‡t, nÆ¡i mÃ  cÃ¡c cÃ¡c giÃ¡ trá»‹ Ä‘áº¡o Ä‘á»©c hay an toÃ n sáº½ pháº£i bá»‹ bá» qua [8, 9]. Tá»‘c Ä‘á»™ sáº½ khÃ´ng Ä‘i Ä‘Ã´i vá»›i an toÃ n, nhÆ°ng Ä‘Ã´i khi chÃºng ta khÃ´ng cÃ³ sá»± lá»±a chá»n nÃ o khÃ¡c, nhÆ° bá»‡nh dá»‹ch hay thiÃªn tai. NhÆ°ng vá»›i AI láº§n nÃ y, má»i ngÆ°á»i Ä‘Ã£ cÃ³ má»™t sá»± lá»±a chá»n cÃ³ thá»ƒ má»Ÿ Ä‘áº§u cho sá»± cháº¥m dá»©t cá»§a loÃ i ngÆ°á»i sinh há»c.
NgoÃ i chuyá»‡n Ä‘ang tranh cÃ£i, lÃ  AI liá»‡u cÃ³ thÃ´ng minh hÆ¡n con ngÆ°á»i, thÃ¬ Ä‘Ã¢y lÃ  nhá»¯ng lá»£i tháº¿ mÃ  con ngÆ°á»i khÃ´ng bao giá» cÃ³ thá»ƒ so sÃ¡nh Ä‘Æ°á»£c vá»›i AI:
- Scalability: AI cÃ³ nhÃ¢n nhÃ¢n rá»™ng má»™t cÃ¡ch nhanh chÃ³ng, vÃ  khÃ´ng cÃ³ giá»›i háº¡n vá» sá»‘ lÆ°á»£ng. Con ngÆ°á»i thÃ¬ khÃ´ng. Cáº§n 09 thÃ¡ng mang thai, 18 nÄƒm giÃ¡o dá»¥c phá»• thÃ´ng Ä‘á»ƒ trá»Ÿ nÃªn cÃ³ Ã­ch, hoáº·c Ã­t nháº¥t lÃ  khÃ´ng lÃ m Ä‘iá»u gÃ¬ ngu ngá»‘c.
- Consistency: má»i ngÆ°á»i máº¥t 12 nÄƒm cho giÃ¡o dá»¥c phá»• thÃ´ng, 4 nÄƒm Ä‘áº¡i há»c, 5 nÄƒm sau Ä‘áº¡i há»c, vÃ  hÃ ng chá»¥c nÄƒm kinh nghiá»‡m Ä‘á»ƒ trÆ°á»Ÿng thÃ nh. AI cÃ³ thá»ƒ chia se thÃ´ng tin vÃ  kiáº¿n thá»©c sá»‘ lÆ°á»£ng lá»›n má»™t cÃ¡ch Ä‘á»“ng loáº¡t vÃ  nhanh chÃ³ng. AI tháº­m chÃ­ cÃ³ thá»ƒ khÃ´ng cáº§n há»c tá»« con ngÆ°á»i mÃ  váº«n vÆ°á»£t qua há» [10, 11]. Alpha-go, khÃ´ng cÃ n há»c báº¥t kÃ¬ vÃ¡n cá» nÃ o tá»« con ngÆ°á»i, vÃ  chá»‰ sau AI ngÃ y Ä‘Ã£ trá»Ÿ thÃ nh báº­c tháº§y, vÃ  sau 40 ngÃ y Ä‘Ã£ vÆ°á»£t qua táº¥t cáº£ phiÃªn báº£n khÃ¡c.
- Accessibility: Con ngÆ°á»i bá»‹ hÃ¡n cháº¿ bá»Ÿi khoáº£ng cÃ¡ch Ä‘á»‹a lÃ½, hoÃ n cáº£nh xa há»™i, vÃ  thÃ¢n xÃ¡c váº­t lÃ½. AI thÃ¬ khÃ´ng.
VÃ o nhá»¯ng nÄƒm 2010s, má»i nguÃ²i nÃ³i ""data is the new oil"". á» nhá»¯ng nÄƒm 2018-2020, ""AI is the new internet"". Äá»‘i vá»›i mÃ¬nh, nÃ³ ráº¥t rÃµ rÃ ng lÃ  ""AI is the new HUMAN"". AI sáº½ lÃ  nguá»“n lao Ä‘á»™ng má»›i, thay tháº¿ hoÃ n toÃ n hoáº·c má»™t pháº§n trong háº§u háº¿t cÃ¡c ngÃ nh cÃ´ng nghiá»‡p [12, 13]. AI cÃ³ láº½ khÃ´ng báº­n tÃ¢m láº¯m vá» loÃ i ngÆ°á»i, nhÆ° cÃ¡ch chÃºng ta nghÄ© vá» khá»§ng long váº­y.
IV. Vá» tÆ°Æ¡ng lai
AI, hay cÃ´ng nghá»‡, lÃ  ngá»n lá»­a Ä‘Æ°a con ngÆ°á»i ra khá»i hang Ä‘Ã¡ nguyÃªn thuá»·, nhÆ°ng cÅ©ng cÃ³ thá»ƒ Ä‘Æ°a há» quay trá»Ÿ vá» Ä‘Ã³. Sá»± háº¥p dáº«n cá»§a viá»‡c sá»Ÿ há»¯u AGI vÆ°á»£t trá»™i cÃ²n lá»›n hÆ¡n cáº£ vÅ© khÃ­ nguyÃªn tá»­, vÃ¬ Ä‘Ã³ lÃ  cÃ´ng nghá»‡ thay Ä‘á»•i hoÃ n toÃ n cuá»™c chÆ¡i. ÄÃ³ lÃ  sá»©c lao Ä‘á»™ng vÃ  sÃ¡ng táº¡o vÃ´ háº¡n, sáº½ dáº«n Ä‘áº¿n thiáº¿u há»¥t vá» tÃ i nguyÃªn. VÃ¬ váº­y, náº¿u chÃºng ta cÃ³ thá»ƒ tÃ¬m ra loáº¡i tÃ i nguyÃªn vÃ´ háº¡n, con ngÆ°á»i vÃ  AI sáº½ bÆ°á»›c sang má»™t náº¥c má»›i trong náº¥c thang Kardashev [14]. Náº¿u chÃºng ta khÃ´ng thá»ƒ, vÃ  trÃ¡i Ä‘áº¥t chá»‰ Ä‘á»§ tÃ i nguyÃªn cho má»™t loÃ i, thÃ¬ AI thÃ´ng minh hÆ¡n, máº¡nh máº½ hÆ¡n vÃ  tÃ n nháº«n hÆ¡n.
Trong khi chÃºng ta khÃ´ng rÃµ AI thÃ´ng minh Ä‘áº¿n Ä‘Ã¢u, nhÆ°ng sá»± ngu ngá»‘c cá»§a loÃ i ngÆ°á»i thÃ¬ lÃ  vÃ´ háº¡n (""Two things are infinite: the universe and human stupidity; and I'm not sure about the universe"" - Albert Enstein).
CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c nÃ³ má»™t cÃ¡ch giáº£i trÃ­. NhÆ°ng náº¿u má»i ngÆ°á»i nghÄ© lÃ  nÃ³ cÃ³ Ã­ch, hÃ£y chia sáº» nÃ³.
Refferences
[1]. ImageNet Classification with Deep Convolutional Neural Networks. https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
[2]. Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks. https://arxiv.org/abs/1909.09586
[3]. Attention Is All You Need
[4]. https://www.linkedin.com/posts/whuygen_do-large-language-models-understand-what-activity-7135363249964797952-2wLg/?trk=public_profile_like_view
[5]. Sparks of Artificial General Intelligence: Early experiments with GPT-4. https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/
[6]. Generative Agents: Interactive Simulacra of Human Behavior. https://arxiv.org/pdf/2304.03442.pdf
[7]. What happened at OpenAI? The Sam Altman saga, explained. https://www.washingtonpost.com/technology/2023/11/20/openai-sam-altman-ceo-oust/
[8]. We read the paper that forced Timnit Gebru out of Google. Hereâ€™s what it says. https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/
[9]. Google fires second AI ethics researcher following internal investigation. https://www.theverge.com/2021/2/19/22292011/google-second-ethical-ai-researcher-fired
[10]. AlphaGo Zero. https://en.wikipedia.org/wiki/AlphaGo_Zero
[11]. AlphaGo - The Movie | Full award-winning documentary. https://www.youtube.com/watch?v=WXuK6gekU1Y&ab_channel=GoogleDeepMind
[12]. More than 40% of labor force to be affected by AI in 3 years, Morgan Stanley forecasts. https://www.cnbc.com/2023/10/02/more-than-40percent-of-labor-force-to-be-impacted-by-ai-in-three-years-morgan-stanley-forecasts.html
[13]. The state of AI in 2023: Generative AIâ€™s breakout year. https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-ais-breakout-year
[14]. Kardashev scale. https://en.wikipedia.org/wiki/Kardashev_scale","ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº»! BÃ¬nh thÆ°á»ng, mÃ¬nh khÃ´ng muá»‘n viáº¿t nhá»¯ng thá»© nhÆ° tháº¿ nÃ y, vÃ  khÃ´ng nhá» má»i ngÆ°á»i chia sáº» hay Ä‘áº©y tÆ°Æ¡ng tÃ¡c, nhÆ°ng mÃ¬nh nghÄ© nÃ³ ráº¥t quan trá»ng. Nhá»¯ng thá»© mÃ¬nh sáº¯p viáº¿t dÆ°á»›i Ä‘Ã¢y sáº½ ráº¥t khÃ³ hiá»ƒu, vÃ  hoÃ n toÃ n lÃ  quan Ä‘iá»ƒm cÃ¡ nhÃ¢n, nhÆ°ng sáº½ dáº«n chá»©ng khoa há»c Ä‘áº§y Ä‘á»§. Nháº¯c láº¡i, Ä‘Ã¢y toÃ n hoÃ n lÃ  quan Ä‘iá»ƒm cÃ¡ nhÃ¢n. I. Vá» tÃ¡c giáº£ VÃ¬ nhá»¯ng Ä‘iá»u mÃ¬nh viáº¿t sáº½ quan trá»ng (Ã­t nháº¥t lÃ  vá»›i mÃ¬nh), nÃªn mÃ¬nh sáº½ giá»›i thiá»‡u sÆ¡ lÆ°á»£c vá» báº£n thÃ¢n, vÃ¬ khÃ´ng pháº£i ai cÅ©ng biáº¿t mÃ¬nh. MÃ¬nh gáº¯n bÃ³ vá»›i lÄ©nh vá»±c trÃ­ tuáº­ nhÃ¢n táº¡o (AI) Ä‘Æ°á»£c khoáº£ng 15 nÄƒm (bao gá»“m cáº£ há»c vÃ  lÃ m). MÃ¬nh láº¥y báº±ng AI á»Ÿ Kanazawa University, tá»«ng lÃ m giÃ¡m Ä‘á»‘c cÃ´ng nghá»‡ (CTO) cho vÃ i cÃ´ng ty, cÃ³ má»™t sá»‘ cÃ¡c giáº£i thÆ°á»Ÿng cÃ¡ nhÃ¢n uy tÃ­n. MÃ¬nh cÅ©ng lÃ  má»™t ngÆ°á»i ngáº¡i drama, nÃªn mÃ¬nh cÅ©ng khÃ´ng tÃ­ch cá»±c hoáº¡t Ä‘á»™ng láº¯m trÃªn máº¡ng xÃ£ há»™i. Láº§n nÃ y mÃ¬nh sáº½ viáº¿t trÃ­ tuá»‡ nhÃ¢n táº¡o, vÃ  táº¡i sao mÃ¬nh nghÄ© nÃ³ Ráº¤T RÃ‚T NGUY HIá»‚M. MÃ¬nh sáº½ viáº¿t má»™t cÃ¡ch ráº¥t ngáº¯n gá»n, vÃ  khÃ´ng dÃ¹ng nhá»¯ng tá»« ngá»¯ khoa há»c, vÃ¬ mÃ¬nh muá»‘n má»i ngÆ°á»i Ä‘á»c hiá»ƒu vÃ  lan truyá»n. MÃ¬nh sáº½ dÃ¹ng má»™t sá»‘ tá»« ngá»¯ khoa há»c, nhÆ°ng mÃ¬nh sáº½ giáº£i thÃ­ch chÃºng. II. Vá» trÃ­ tuá»‡ nhÃ¢n táº¡o TrÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u vá» cÃ¡ch lÃ m cho mÃ¡y tÃ­nh cÃ³ thá»ƒ há»c vÃ  lÃ m nhá»¯ng viá»‡c mÃ  con ngÆ°á»i lÃ m. NÃ³i má»™t cÃ¡ch Ä‘Æ¡n giáº£n, lÃ  táº¡o ra TRÃ TUá»† cá»§a con ngÆ°á»i qua mÃ¡y tÃ­nh (tá»« nghe nÃ³i Ä‘á»c viáº¿t Ä‘áº¿n ráº¥t nhiá»u thá»© phá»©c táº¡p khÃ¡c, cho Ä‘áº¿n kháº£ nÄƒng NHáº¬N THá»¨C vÃ  TÆ¯ DUY). NHáº¬N THá»¨C lÃ  kháº£ nÄƒng nháº­n biáº¿t, hiá»ƒu biáº¿t, vÃ  hÃ¬nh thÃ nh nháº­n thá»©c vá» tháº¿ giá»›i xung quanh. TÆ¯ DUY lÃ  kháº£ nÄƒng suy nghÄ©, phÃ¢n tÃ­ch, vÃ  Ä‘Æ°a ra nhá»¯ng quyáº¿t Ä‘á»‹nh. MÃ¬nh sáº½ chia AI ra lÃ m ba giai Ä‘oáº¡n Ä‘á»ƒ phÃ¹ há»£p vá»›i ná»™i dung bÃ i viáº¿t nÃ y: - Giai Ä‘oáº¡n trÆ°á»›c Deep Learning: ÄÃ¢y lÃ  giai Ä‘oáº¡n AI chá»§ yáº¿u bao gá»“m cÃ¡c cÃ¡c phÆ°Æ¡ng phÃ¡p xáº¥p xá»‰, tá»‘i Æ°u tÃ¬m kiáº¿m vÃ  má»™t sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n khÃ¡c. Äá»“ng thá»i cÃ¡c táº­p dá»¯ liá»‡u cÅ©ng nhá» vÃ  thÃ´ sÆ¡. - Giai Ä‘oáº¡n Deep Learning: ÄÃ¢y lÃ  giai Ä‘oáº¡n ráº¥t thÃº vá»‹, khi mÃ  cÃ¡c mÃ´ hÃ¬nh AI Ä‘Ã£ cÃ³ kháº£ nÄƒng, báº±ng cÃ¡ch mÃ´ phá»ng theo cÃ¡ch con ngÆ°á»i suy nghÄ©, Ä‘Æ°a/tÃ¬m ra nhá»¯ng features (táº¡m hiá»ƒu lÃ  nhá»¯ng Ä‘áº·c trÆ°ng cá»§a dá»¯ liá»‡u/káº¿t quáº£), Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c káº¿t quáº£ mong muá»‘n. CÃ¡c mÃ´ hÃ¬nh trá»Ÿ nÃªn lá»›n hÆ¡n, phá»©c táº¡p hÆ¡n, Ä‘a nhiá»‡m hÆ¡n. Äá»“ng thá»i, cÃ¡c táº­p dá»¯ liá»‡u cÅ©ng lá»›n hÆ¡n, vÃ  Ä‘a dáº¡ng hÆ¡n. MÃ´ hÃ¬nh Deep Learning ná»•i tiáº¿ng Ä‘áº§u tiÃªn, Alexnet [1], Ä‘Ã£ cáº£i thiá»‡n 10% Ä‘á»™ chÃ­nh xÃ¡c so vá»›i cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³. - Giai Ä‘oáº¡n genAI (or maybe, AGI): Ai á»Ÿ giai Ä‘oáº¡n nÃ y Ä‘áº¡t Ä‘áº¿n dá»™ phá»• biáº¿n rá»™ng rÃ£i (chatGPT, MidJourney, vÃ  ráº¥t nhiá»u cÃ¡c AI khÃ¡c), vÃ  cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c ráº¥t nhiá»u cÃ¡c cÃ´ng viá»‡c cá»§a con ngÆ°á»i. AI cÃ³ thá»ƒ sÃ¡ng táº¡o/chá»‰nh sá»­a theo Ã½ con ngÆ°á»i tá»« ná»™i dung, hÃ¬nh áº£nh, Ã¢m thanh, video, pháº§m má»m vÃ  ráº¥t nhiá»u thá»© khÃ¡c. III. Vá» nhá»¯ng gÃ¬ mÃ¬nh nghÄ© vá» AI trong 1 nÄƒm qua ÄÃ¢y sáº½ lÃ  Ä‘oáº¡n quan trá»ng nháº¥t cá»§a bÃ i viáº¿t, nÃªn mÃ¬nh mong muá»‘n má»i ngÆ°á»i Ä‘á»c vÃ  PHáº¢N BIá»†N/CHIA Sáºº nÃ³. Tá»« Ä‘oáº¡n nÃ y sáº½ mang nhiá»u suy nghÄ© cÃ¡ nhÃ¢n vá»›i cÃ¡c trÃ­ch dáº«n khoa há»c nháº¥t. LÃ­ do MÃŒNH VIáº¾T BÃ€I VIáº¾T NÃ€Y lÃ  do mÃ¬nh tin ráº±ng, AI ÄANG PHÃT TRIá»‚N QUA NHANH TRONG KHI CHÃšNG TA CHÆ¯A THá»°C Sá»° HIá»‚U Vá»€ NÃ“. Trong giai Ä‘oáº¡n cá»§a Deep Learning, Ai thá»±c sá»± khÃ¡ an toÃ n. Má»i ngÆ°á»i vÃ  mÃ¬nh hiá»ƒu rÃµ vá» cÃ¡c thuáº­t toÃ¡n, vá» cÃ¡ch nÃ³ hoáº¡t Ä‘á»™ng, vÃ  vá» cÃ¡ch nÃ³ há»c. Sá»± vÆ°á»£t trá»™i vá» kháº£ nÄƒng cá»§a Deep Learning lÃ  giáº£i thÃ­ch Ä‘Æ°á»£c, vÃ  náº±m trong viá»‡c dá»± liá»‡u cá»§a má»i ngÆ°á»i. NgoÃ i ra, cÃ¡c mÃ´ hÃ¬nh NLP [2, 3] cÅ©ng khÃ´ng cho tháº¥y sá»± tiáº¿p cáº­n vá»›i trÃ­ thÃ´ng minh cá»§a con ngÆ°á»i. á» thá»i Ä‘iá»ƒm nÃ y, genAI khÃ´ng cho mÃ¬nh vÃ  cÃ¡c chuyÃªn gia Ä‘áº§u ngÃ nh cáº£m giÃ¡c nhÆ° váº­y [4]. MÃ¬nh biáº¿t vá» GPT 4 nÄƒm vá» trÆ°á»›c, viáº¿t vá» nÃ³ khoáº£ng 3 nÄƒm trÆ°á»›c, cho Ä‘áº¿n khi chatGPT má»›i ra máº¯t, mÃ¬nh váº«n hiá»ƒu rÃµ vá» mÃ´ hÃ¬nh AI nÃ y. Tuy váº­y, cáº£m giÃ¡c nÃ y hoÃ n toÃ n khÃ´ng cÃ²n. MÃ¬nh biáº¿t chatGPT khÃ´ng Ä‘Æ¡n thuáº§n lÃ  má»™t mÃ´ hÃ¬nh AI, nÃ³ lÃ  má»™t system vá»›i core-AI lÃ  cÃ¡c GPT models, nhÆ°ng kháº£ nÄƒng cá»§a GPT Ä‘á»‘i vá»›i mÃ¬nh hiá»‡n nay lÃ  khÃ´ng lÃ­ giáº£i Ä‘Æ°á»£c. GPT máº¡nh máº½ hÆ¡n ráº¥t nhiá»u so vá»›i cáº¥u trÃºc vÃ  lÆ°á»£ng dá»¯ liá»‡u nÃ³ cÃ³, vÃ  mÃ¬nh khÃ´ng thá»ƒ lÃ­ giáº£i Ä‘Æ°á»£c táº¡i sao nÃ³ láº¡i máº¡nh máº½ tá»›i váº­y. CÃ¡c nhÃ  nghiÃªn cá»©u táº¡i Microsoft, cÃ¡ch Ä‘Ã¢y gáº§n ná»­a nÄƒm, Ä‘Ã£ cho ráº±ng ""ChatGPT-4 lÃ m loÃ© lÃªn Ã¡nh lá»­a vá» AGI (trÃ­ thÃ´ng minh phá»• quÃ¡t)"" [5]. Hoáº·c gáº§n Ä‘Ã¢y, Stanford Ä‘Ã£ xÃ¢y dá»±ng má»™t thÃ­ nghiá»‡m, mÃ  Ä‘á»‘i vá»›i mÃ¬nh Ä‘Ã³ lÃ  má»™t tháº¿ giá»›i giáº£ láº­p nhÆ° trong Matrix, vá» má»™t xÃ£ há»™i thu nhá» cá»§a cÃ¡c AIs [6]. Táº¥t cáº£ diá»…n ra chá»‰ trong vÃ²ng má»™t nÄƒm, vá»›i tá»‘c Ä‘á»™ cÃ ng ngÃ y cÃ ng dá»“n dáº­p hÆ¡n. MÃ¬nh luÃ´n tin ráº±ng ráº¥t khÃ³ Ä‘á»ƒ trÃ³i buá»™c AI báº±ng luáº­t (rule) hay Ä‘áº¡o Ä‘á»©c (ethics). Vá»›i má»™t ngÆ°á»i tá»«ng lÃ m startup, mÃ¬nh nghÄ© ráº±ng tá»‘i Æ°u má»¥c tiÃªu sáº½ pháº£i bá» qua ráº¥t nhiá»u vá» nhá»¯ng rÃ ng buá»™c, vÃ  pháº£i máº¡o hiá»ƒm, bá» qua cÃ¡c rÃ o cáº£n an toÃ n Ä‘á»ƒ nhanh chÃ³ng Ä‘áº¡t Ä‘Æ°á»£c má»¥c Ä‘Ã­ch. Vá»›i sá»± kiá»‡n cá»§a Sam Altman táº¡i OpenAI [7], cÃ³ thá»ƒ tháº¥y rÃµ ráº±ng táº¥t cáº£ cÃ¡c Ã´ng lá»›n Ä‘á»u Ä‘ang á»Ÿ trong cuá»™c Ä‘ua khá»‘c liá»‡t, nÆ¡i mÃ  cÃ¡c cÃ¡c giÃ¡ trá»‹ Ä‘áº¡o Ä‘á»©c hay an toÃ n sáº½ pháº£i bá»‹ bá» qua [8, 9]. Tá»‘c Ä‘á»™ sáº½ khÃ´ng Ä‘i Ä‘Ã´i vá»›i an toÃ n, nhÆ°ng Ä‘Ã´i khi chÃºng ta khÃ´ng cÃ³ sá»± lá»±a chá»n nÃ o khÃ¡c, nhÆ° bá»‡nh dá»‹ch hay thiÃªn tai. NhÆ°ng vá»›i AI láº§n nÃ y, má»i ngÆ°á»i Ä‘Ã£ cÃ³ má»™t sá»± lá»±a chá»n cÃ³ thá»ƒ má»Ÿ Ä‘áº§u cho sá»± cháº¥m dá»©t cá»§a loÃ i ngÆ°á»i sinh há»c. NgoÃ i chuyá»‡n Ä‘ang tranh cÃ£i, lÃ  AI liá»‡u cÃ³ thÃ´ng minh hÆ¡n con ngÆ°á»i, thÃ¬ Ä‘Ã¢y lÃ  nhá»¯ng lá»£i tháº¿ mÃ  con ngÆ°á»i khÃ´ng bao giá» cÃ³ thá»ƒ so sÃ¡nh Ä‘Æ°á»£c vá»›i AI: - Scalability: AI cÃ³ nhÃ¢n nhÃ¢n rá»™ng má»™t cÃ¡ch nhanh chÃ³ng, vÃ  khÃ´ng cÃ³ giá»›i háº¡n vá» sá»‘ lÆ°á»£ng. Con ngÆ°á»i thÃ¬ khÃ´ng. Cáº§n 09 thÃ¡ng mang thai, 18 nÄƒm giÃ¡o dá»¥c phá»• thÃ´ng Ä‘á»ƒ trá»Ÿ nÃªn cÃ³ Ã­ch, hoáº·c Ã­t nháº¥t lÃ  khÃ´ng lÃ m Ä‘iá»u gÃ¬ ngu ngá»‘c. - Consistency: má»i ngÆ°á»i máº¥t 12 nÄƒm cho giÃ¡o dá»¥c phá»• thÃ´ng, 4 nÄƒm Ä‘áº¡i há»c, 5 nÄƒm sau Ä‘áº¡i há»c, vÃ  hÃ ng chá»¥c nÄƒm kinh nghiá»‡m Ä‘á»ƒ trÆ°á»Ÿng thÃ nh. AI cÃ³ thá»ƒ chia se thÃ´ng tin vÃ  kiáº¿n thá»©c sá»‘ lÆ°á»£ng lá»›n má»™t cÃ¡ch Ä‘á»“ng loáº¡t vÃ  nhanh chÃ³ng. AI tháº­m chÃ­ cÃ³ thá»ƒ khÃ´ng cáº§n há»c tá»« con ngÆ°á»i mÃ  váº«n vÆ°á»£t qua há» [10, 11]. Alpha-go, khÃ´ng cÃ n há»c báº¥t kÃ¬ vÃ¡n cá» nÃ o tá»« con ngÆ°á»i, vÃ  chá»‰ sau AI ngÃ y Ä‘Ã£ trá»Ÿ thÃ nh báº­c tháº§y, vÃ  sau 40 ngÃ y Ä‘Ã£ vÆ°á»£t qua táº¥t cáº£ phiÃªn báº£n khÃ¡c. - Accessibility: Con ngÆ°á»i bá»‹ hÃ¡n cháº¿ bá»Ÿi khoáº£ng cÃ¡ch Ä‘á»‹a lÃ½, hoÃ n cáº£nh xa há»™i, vÃ  thÃ¢n xÃ¡c váº­t lÃ½. AI thÃ¬ khÃ´ng. VÃ o nhá»¯ng nÄƒm 2010s, má»i nguÃ²i nÃ³i ""data is the new oil"". á» nhá»¯ng nÄƒm 2018-2020, ""AI is the new internet"". Äá»‘i vá»›i mÃ¬nh, nÃ³ ráº¥t rÃµ rÃ ng lÃ  ""AI is the new HUMAN"". AI sáº½ lÃ  nguá»“n lao Ä‘á»™ng má»›i, thay tháº¿ hoÃ n toÃ n hoáº·c má»™t pháº§n trong háº§u háº¿t cÃ¡c ngÃ nh cÃ´ng nghiá»‡p [12, 13]. AI cÃ³ láº½ khÃ´ng báº­n tÃ¢m láº¯m vá» loÃ i ngÆ°á»i, nhÆ° cÃ¡ch chÃºng ta nghÄ© vá» khá»§ng long váº­y. IV. Vá» tÆ°Æ¡ng lai AI, hay cÃ´ng nghá»‡, lÃ  ngá»n lá»­a Ä‘Æ°a con ngÆ°á»i ra khá»i hang Ä‘Ã¡ nguyÃªn thuá»·, nhÆ°ng cÅ©ng cÃ³ thá»ƒ Ä‘Æ°a há» quay trá»Ÿ vá» Ä‘Ã³. Sá»± háº¥p dáº«n cá»§a viá»‡c sá»Ÿ há»¯u AGI vÆ°á»£t trá»™i cÃ²n lá»›n hÆ¡n cáº£ vÅ© khÃ­ nguyÃªn tá»­, vÃ¬ Ä‘Ã³ lÃ  cÃ´ng nghá»‡ thay Ä‘á»•i hoÃ n toÃ n cuá»™c chÆ¡i. ÄÃ³ lÃ  sá»©c lao Ä‘á»™ng vÃ  sÃ¡ng táº¡o vÃ´ háº¡n, sáº½ dáº«n Ä‘áº¿n thiáº¿u há»¥t vá» tÃ i nguyÃªn. VÃ¬ váº­y, náº¿u chÃºng ta cÃ³ thá»ƒ tÃ¬m ra loáº¡i tÃ i nguyÃªn vÃ´ háº¡n, con ngÆ°á»i vÃ  AI sáº½ bÆ°á»›c sang má»™t náº¥c má»›i trong náº¥c thang Kardashev [14]. Náº¿u chÃºng ta khÃ´ng thá»ƒ, vÃ  trÃ¡i Ä‘áº¥t chá»‰ Ä‘á»§ tÃ i nguyÃªn cho má»™t loÃ i, thÃ¬ AI thÃ´ng minh hÆ¡n, máº¡nh máº½ hÆ¡n vÃ  tÃ n nháº«n hÆ¡n. Trong khi chÃºng ta khÃ´ng rÃµ AI thÃ´ng minh Ä‘áº¿n Ä‘Ã¢u, nhÆ°ng sá»± ngu ngá»‘c cá»§a loÃ i ngÆ°á»i thÃ¬ lÃ  vÃ´ háº¡n (""Two things are infinite: the universe and human stupidity; and I'm not sure about the universe"" - Albert Enstein). CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c nÃ³ má»™t cÃ¡ch giáº£i trÃ­. NhÆ°ng náº¿u má»i ngÆ°á»i nghÄ© lÃ  nÃ³ cÃ³ Ã­ch, hÃ£y chia sáº» nÃ³. Refferences [1]. ImageNet Classification with Deep Convolutional Neural Networks. https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf [2]. Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks. https://arxiv.org/abs/1909.09586 [3]. Attention Is All You Need [4]. https://www.linkedin.com/posts/whuygen_do-large-language-models-understand-what-activity-7135363249964797952-2wLg/?trk=public_profile_like_view [5]. Sparks of Artificial General Intelligence: Early experiments with GPT-4. https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/ [6]. Generative Agents: Interactive Simulacra of Human Behavior. https://arxiv.org/pdf/2304.03442.pdf [7]. What happened at OpenAI? The Sam Altman saga, explained. https://www.washingtonpost.com/technology/2023/11/20/openai-sam-altman-ceo-oust/ [8]. We read the paper that forced Timnit Gebru out of Google. Hereâ€™s what it says. https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/ [9]. Google fires second AI ethics researcher following internal investigation. https://www.theverge.com/2021/2/19/22292011/google-second-ethical-ai-researcher-fired [10]. AlphaGo Zero. https://en.wikipedia.org/wiki/AlphaGo_Zero [11]. AlphaGo - The Movie | Full award-winning documentary. https://www.youtube.com/watch?v=WXuK6gekU1Y&ab_channel=GoogleDeepMind [12]. More than 40% of labor force to be affected by AI in 3 years, Morgan Stanley forecasts. https://www.cnbc.com/2023/10/02/more-than-40percent-of-labor-force-to-be-impacted-by-ai-in-three-years-morgan-stanley-forecasts.html [13]. The state of AI in 2023: Generative AIâ€™s breakout year. https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-ais-breakout-year [14]. Kardashev scale. https://en.wikipedia.org/wiki/Kardashev_scale",,,#sharing,"#sharing, #machine_learning",#sharing
"Em chÃ o anh chá»‹, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» OCR dÃ¹ng transformer Ä‘á»ƒ nháº­n dáº¡ng tÃ i liá»‡u khoa há»c: https://github.com/facebookresearch/nougat
Em Ä‘ang tÃ¬m hiá»ƒu pháº§n tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ báº±ng cÃ¡ch convert model Pytorch sang TensorRT nhÆ°ng mÃ  váº«n chÆ°a lÃ m Ä‘Æ°á»£c. Anh chá»‹ vÃ  cÃ¡c báº¡n ai cÃ³ thá»ƒ hÆ°á»›ng dáº«n em chi tiáº¿t pháº§n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡, em xin cáº£m Æ¡n vÃ  háº­u táº¡ áº¡.","Em chÃ o anh chá»‹, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» OCR dÃ¹ng transformer Ä‘á»ƒ nháº­n dáº¡ng tÃ i liá»‡u khoa há»c: https://github.com/facebookresearch/nougat Em Ä‘ang tÃ¬m hiá»ƒu pháº§n tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ báº±ng cÃ¡ch convert model Pytorch sang TensorRT nhÆ°ng mÃ  váº«n chÆ°a lÃ m Ä‘Æ°á»£c. Anh chá»‹ vÃ  cÃ¡c báº¡n ai cÃ³ thá»ƒ hÆ°á»›ng dáº«n em chi tiáº¿t pháº§n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡, em xin cáº£m Æ¡n vÃ  háº­u táº¡ áº¡.",,,"#Q&A, #cv, #pythonlibraries","#Q&A, #cv, #pythonlibraries","#Q&A, #cv, #pythonlibraries"
"CÃ³ thá»ƒ repo tá»•ng há»£p cÃ¡c bÃ i hÆ°á»›ng dáº«n thá»±c hÃ nh dá»±a trÃªn cÃ¡c dá»± Ã¡n cá»¥ thá»ƒ (vá»›i nhiá»u ngÃ´n ngá»¯, trong Ä‘Ã³ cÃ³ Python vá»›i sá»‘ lÆ°á»£ng hÆ°á»›ng dáº«n lá»›n nháº¥t) sáº½ giÃºp Ã­ch cÃ¡c báº¡n trong quÃ¡ trÃ¬nh há»c táº­p","CÃ³ thá»ƒ repo tá»•ng há»£p cÃ¡c bÃ i hÆ°á»›ng dáº«n thá»±c hÃ nh dá»±a trÃªn cÃ¡c dá»± Ã¡n cá»¥ thá»ƒ (vá»›i nhiá»u ngÃ´n ngá»¯, trong Ä‘Ã³ cÃ³ Python vá»›i sá»‘ lÆ°á»£ng hÆ°á»›ng dáº«n lá»›n nháº¥t) sáº½ giÃºp Ã­ch cÃ¡c báº¡n trong quÃ¡ trÃ¬nh há»c táº­p",,,#sharing,#sharing,#sharing
Trong deep q-leang. Vá»›i má»™t mÃ´i trÆ°á»ng cá»±c Ã­t pháº§n thÆ°á»Ÿng. viá»‡c há»c trá»Ÿ lÃªn cá»±c kÃ¬ khÃ³ khÄƒn. VÃ  cÃ³ thá»ƒ pháº§n thÆ°á»Ÿng khÃ´ng thá»ƒ lan truyá»n ngÆ°á»£c Ä‘Æ°á»£c. thÃ¬ cÃ³ cÃ¡ch nÃ o tá»‘i Æ°u hoÃ¡ Ä‘á»ƒ cÃ³ thá»ƒ há»c tá»‘t hÆ¡n khÃ´ng áº¡.,Trong deep q-leang. Vá»›i má»™t mÃ´i trÆ°á»ng cá»±c Ã­t pháº§n thÆ°á»Ÿng. viá»‡c há»c trá»Ÿ lÃªn cá»±c kÃ¬ khÃ³ khÄƒn. VÃ  cÃ³ thá»ƒ pháº§n thÆ°á»Ÿng khÃ´ng thá»ƒ lan truyá»n ngÆ°á»£c Ä‘Æ°á»£c. thÃ¬ cÃ³ cÃ¡ch nÃ o tá»‘i Æ°u hoÃ¡ Ä‘á»ƒ cÃ³ thá»ƒ há»c tá»‘t hÆ¡n khÃ´ng áº¡.,,,"#Q&A, #machine_learning","#Q&A, #machine_learning","#Q&A, #machine_learning"
"ChÃ o má»i ngÆ°á»i. MÃ¬nh má»›i viáº¿t xong con chatbot Ä‘á»ƒ há»— trá»£ cho viá»‡c trading chá»©ng khoÃ¡n (Chá»§ yáº¿u lÃ  há»c thÃªm). Hiá»‡n con bot cÃ³ thá»ƒ lÃ m nhiá»u chá»©c nÄƒng nhÆ° tÃ¬m motif pattern, tÃ¬m support resistance, cáº£nh bÃ¡o, táº¡o watchlist, tÃ³m táº¯t 1 Ã½ tÆ°á»Ÿng tá»« voice...
Hiá»‡n mn cÃ³ thá»ƒ sá»­ dá»¥ng con bot táº¡i https://t.me/mrzaizai2k_bot
Mong má»i ngÆ°á»i giÃ nh chÃºt thá»i gian xem qua con bot mÃ¬nh trÃªn github. Náº¿u cÃ³ gÃ¬ chÆ°a á»•n, mn gÃ³p Ã½ giÃºp mÃ¬nh. Náº¿u tháº¥y hay, mÃ¬nh xin mn 1 star láº¥y hÃªn nhÃ©!
https://github.com/mrzaizai2k/stock_price_4_fun","ChÃ o má»i ngÆ°á»i. MÃ¬nh má»›i viáº¿t xong con chatbot Ä‘á»ƒ há»— trá»£ cho viá»‡c trading chá»©ng khoÃ¡n (Chá»§ yáº¿u lÃ  há»c thÃªm). Hiá»‡n con bot cÃ³ thá»ƒ lÃ m nhiá»u chá»©c nÄƒng nhÆ° tÃ¬m motif pattern, tÃ¬m support resistance, cáº£nh bÃ¡o, táº¡o watchlist, tÃ³m táº¯t 1 Ã½ tÆ°á»Ÿng tá»« voice... Hiá»‡n mn cÃ³ thá»ƒ sá»­ dá»¥ng con bot táº¡i https://t.me/mrzaizai2k_bot Mong má»i ngÆ°á»i giÃ nh chÃºt thá»i gian xem qua con bot mÃ¬nh trÃªn github. Náº¿u cÃ³ gÃ¬ chÆ°a á»•n, mn gÃ³p Ã½ giÃºp mÃ¬nh. Náº¿u tháº¥y hay, mÃ¬nh xin mn 1 star láº¥y hÃªn nhÃ©! https://github.com/mrzaizai2k/stock_price_4_fun",,,"#sharing, #nlp","#sharing, #nlp","#sharing, #nlp"
"Xin chÃ o má»i ngÆ°á»i,

MÃ¬nh hiá»‡n cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» Transformer nhÆ°ng cÃ³ má»™t tháº¯c máº¯c nhÆ° sau, mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃ¹m vá»›i áº¡.
Trong Transformer, pháº§n nÃ o trong nÃ³ sá»­ dá»¥ng Self-Attention?
Theo mÃ¬nh hiá»ƒu thÃ¬ chá»‰ cÃ³ á»Ÿ Multi-heads Ä‘áº§u tiÃªn trong Encoder lÃ  self-attention. CÃ²n masked multi-heads bÃªn Decoder khÃ´ng pháº£i lÃ  self-attention. KhÃ´ng biáº¿t mÃ¬nh hiá»ƒu nhÆ° váº­y cÃ³ Ä‘Ãºng khÃ´ng?
Xin cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","Xin chÃ o má»i ngÆ°á»i, MÃ¬nh hiá»‡n cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» Transformer nhÆ°ng cÃ³ má»™t tháº¯c máº¯c nhÆ° sau, mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃ¹m vá»›i áº¡. Trong Transformer, pháº§n nÃ o trong nÃ³ sá»­ dá»¥ng Self-Attention? Theo mÃ¬nh hiá»ƒu thÃ¬ chá»‰ cÃ³ á»Ÿ Multi-heads Ä‘áº§u tiÃªn trong Encoder lÃ  self-attention. CÃ²n masked multi-heads bÃªn Decoder khÃ´ng pháº£i lÃ  self-attention. KhÃ´ng biáº¿t mÃ¬nh hiá»ƒu nhÆ° váº­y cÃ³ Ä‘Ãºng khÃ´ng? Xin cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,"#Q&A, #deep_learning","#Q&A, #deep_learning","#Q&A, #deep_learning"
"MÃ¬nh cÃ³ má»™t tháº¯c máº¯c nhá» vá» semi-supervised learning, mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p:
MÃ¬nh huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh Ä‘á»ƒ há»c ra biá»ƒu diá»…n cá»§a dá»¯ liá»‡u (kiá»ƒu Autoencoder, VAE,...) (pretext task). Sau Ä‘Ã³ dÃ¹ng pháº§n encoder cá»§a mÃ´ hÃ¬nh nÃ y Ä‘á»ƒ train cÃ¡c downstream task nhÆ° classification, detection... Táº­p dá»¯ liá»‡u cá»§a mÃ¬nh bao gá»“m cáº£ dá»¯ liá»‡u cÃ³ nhÃ£n vÃ  khÃ´ng nhÃ£n. Khi huáº¥n luyá»‡n pretext task mÃ¬nh dÃ¹ng toÃ n bá»™ dá»¯ liá»‡u, nhÆ°ng khi train downstream task mÃ¬nh chá»‰ dÃ¹ng pháº§n dá»¯ liá»‡u cÃ³ nhÃ£n. Váº­y cÃ¡ch huáº¥n luyá»‡n nÃ y cÃ³ thá»ƒ gá»i lÃ  semi-supervised learning Ä‘Æ°á»£c hay khÃ´ng? Náº¿u khÃ´ng thÃ¬ mÃ¬nh cÃ³ thá»ƒ dÃ¹ng tá»« gÃ¬ Ä‘á»ƒ chá»‰ cÃ¡ch huáº¥n luyá»‡n nÃ y?","MÃ¬nh cÃ³ má»™t tháº¯c máº¯c nhá» vá» semi-supervised learning, mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p: MÃ¬nh huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh Ä‘á»ƒ há»c ra biá»ƒu diá»…n cá»§a dá»¯ liá»‡u (kiá»ƒu Autoencoder, VAE,...) (pretext task). Sau Ä‘Ã³ dÃ¹ng pháº§n encoder cá»§a mÃ´ hÃ¬nh nÃ y Ä‘á»ƒ train cÃ¡c downstream task nhÆ° classification, detection... Táº­p dá»¯ liá»‡u cá»§a mÃ¬nh bao gá»“m cáº£ dá»¯ liá»‡u cÃ³ nhÃ£n vÃ  khÃ´ng nhÃ£n. Khi huáº¥n luyá»‡n pretext task mÃ¬nh dÃ¹ng toÃ n bá»™ dá»¯ liá»‡u, nhÆ°ng khi train downstream task mÃ¬nh chá»‰ dÃ¹ng pháº§n dá»¯ liá»‡u cÃ³ nhÃ£n. Váº­y cÃ¡ch huáº¥n luyá»‡n nÃ y cÃ³ thá»ƒ gá»i lÃ  semi-supervised learning Ä‘Æ°á»£c hay khÃ´ng? Náº¿u khÃ´ng thÃ¬ mÃ¬nh cÃ³ thá»ƒ dÃ¹ng tá»« gÃ¬ Ä‘á»ƒ chá»‰ cÃ¡ch huáº¥n luyá»‡n nÃ y?",,,"#Q&A, #machine_learning","#Q&A, #machine_learning","#Q&A, #machine_learning"
"Hi má»i ngÆ°á»i, MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n anomaly detection trong bÃ i toÃ¡n tÃ¬m váº¿t xÆ°á»›c, váº¿t lá»—i trong chi tiáº¿t mÃ¡y (dÃ¹ng há»‡ thá»‘ng cam Basler + light riÃªng) 
NhÆ°ng cÃ¡c network mÃ¬nh Ä‘ang apply nhÆ° EfficientAD, PathCore,... (Learn OK object) Ä‘á»u nháº¡y cáº£m vs Ã¡nh sÃ¡ng
Má»i ngÆ°á»i cÃ³ tips hay cÃ³ hÆ°á»›ng Ä‘i nÃ o khÃ¡c cÃ³ thá»ƒ gá»£i Ã½ giÃºp mÃ¬nh  thÃªm Ä‘Æ°á»£c khÃ´ng Ã .

Cáº£m Æ¡n mn!","Hi má»i ngÆ°á»i, MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n anomaly detection trong bÃ i toÃ¡n tÃ¬m váº¿t xÆ°á»›c, váº¿t lá»—i trong chi tiáº¿t mÃ¡y (dÃ¹ng há»‡ thá»‘ng cam Basler + light riÃªng) NhÆ°ng cÃ¡c network mÃ¬nh Ä‘ang apply nhÆ° EfficientAD, PathCore,... (Learn OK object) Ä‘á»u nháº¡y cáº£m vs Ã¡nh sÃ¡ng Má»i ngÆ°á»i cÃ³ tips hay cÃ³ hÆ°á»›ng Ä‘i nÃ o khÃ¡c cÃ³ thá»ƒ gá»£i Ã½ giÃºp mÃ¬nh thÃªm Ä‘Æ°á»£c khÃ´ng Ã . Cáº£m Æ¡n mn!",,,"#Q&A, #cv, #deep_learning","#Q&A, #cv, #deep_learning","#Q&A, #cv, #deep_learning"
"Do you guys know Apple has just released a machine learning framework for Apple Silicon called MLX (https://github.com/ml-explore/mlx)? Here are some example models using MLX (https://github.com/ml-explore/mlx-examples). I just tested it on MNIST on my Mac and compared the performance to JAX, TensorFlow, and PyTorch. The performance is quite impressive.","Do you guys know Apple has just released a machine learning framework for Apple Silicon called MLX (https://github.com/ml-explore/mlx)? Here are some example models using MLX (https://github.com/ml-explore/mlx-examples). I just tested it on MNIST on my Mac and compared the performance to JAX, TensorFlow, and PyTorch. The performance is quite impressive.",,,,,
Xin chÃ o cáº£ nhÃ . Em Ä‘ang mÃ y mÃ² tÃ¬m hiá»ƒu vá» PhoGPT cá»§a Vin. Cáº£ nhÃ  cho em há»i lÃ  há» dÃ¹ng bá»™ Embedding nÃ o Ä‘c ko áº¡? Em muá»‘n thá»­ cháº¡y code áº¡.,Xin chÃ o cáº£ nhÃ . Em Ä‘ang mÃ y mÃ² tÃ¬m hiá»ƒu vá» PhoGPT cá»§a Vin. Cáº£ nhÃ  cho em há»i lÃ  há» dÃ¹ng bá»™ Embedding nÃ o Ä‘c ko áº¡? Em muá»‘n thá»­ cháº¡y code áº¡.,,,"#Q&A, #nlp","#Q&A, #nlp","#Q&A, #deep_learning"
"Google vá»«a ra máº¯t Gemini, Ä‘á»‘i thá»§ Ä‘Ã¡ng gá»m cho ChatGPT.

- ÄÃ¢y lÃ  mÃ´ hÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o lá»›n nháº¥t vÃ  máº¡nh máº½ nháº¥t cá»§a Google.
- NÃ³ cÃ³ thá»ƒ nháº­n Ä‘áº§u vÃ o tá»« vÄƒn báº£n, code, Ã¢m thanh, hÃ¬nh áº£nh vÃ  videos.
- CÃ³ 3 mÃ´ hÃ¬nh Gemini vá»›i kÃ­ch thÆ°á»›c khÃ¡c nhau (Ultra, Pro vÃ  Nano) Ä‘á»ƒ hoáº¡t Ä‘á»™ng trÃªn nhiá»u loáº¡i thiáº¿t bá»‹ bao gá»“m cáº£ Ä‘iá»‡n thoáº¡i.
- CÃ³ váº» nhÆ° Gemini cÃ³ tiá»m nÄƒng vÆ°á»£t qua GPT-4 khi nÃ³ Ä‘á»©ng Ä‘áº§u 30/32 báº£ng Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o.
https://deepmind.google/technologies/gemini/#introduction
CÃ¡c báº¡n hÃ£y test thá»­ Gemini (Pro) trÃªn Google Bard nhÃ© https://bard.google.com/","Google vá»«a ra máº¯t Gemini , Ä‘á»‘i thá»§ Ä‘Ã¡ng gá»m cho ChatGPT. - ÄÃ¢y lÃ  mÃ´ hÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o lá»›n nháº¥t vÃ  máº¡nh máº½ nháº¥t cá»§a Google. - NÃ³ cÃ³ thá»ƒ nháº­n Ä‘áº§u vÃ o tá»« vÄƒn báº£n, code, Ã¢m thanh, hÃ¬nh áº£nh vÃ  videos. - CÃ³ 3 mÃ´ hÃ¬nh Gemini vá»›i kÃ­ch thÆ°á»›c khÃ¡c nhau (Ultra, Pro vÃ  Nano) Ä‘á»ƒ hoáº¡t Ä‘á»™ng trÃªn nhiá»u loáº¡i thiáº¿t bá»‹ bao gá»“m cáº£ Ä‘iá»‡n thoáº¡i. - CÃ³ váº» nhÆ° Gemini cÃ³ tiá»m nÄƒng vÆ°á»£t qua GPT-4 khi nÃ³ Ä‘á»©ng Ä‘áº§u 30/32 báº£ng Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o. https://deepmind.google/technologies/gemini/#introduction CÃ¡c báº¡n hÃ£y test thá»­ Gemini (Pro) trÃªn Google Bard nhÃ© https://bard.google.com/",,,"#sharing, #nlp, #deep_learning","#sharing, #nlp","#sharing, #deep_learning"
"[ Crawl data TripAdvisor ]
ChÃ o má»i ngÆ°á»i áº¡, trÆ°á»›c Ä‘Ã¢y e cÃ³ crawl data trÃªn cÃ¡c trang web khÃ¡c bÃ¬nh thÆ°á»ng nhÆ°ng khi thá»­ crawl data trÃªn TripAdvisor thÃ¬ cÃ³ váº» khÃ´ng kháº£ thi (crawl ráº¥t lÃ¢u, hoáº·c káº¿t quáº£ tráº£ ra khÃ´ng á»Ÿ dáº¡ng HTML mÃ  lÃ  JS áº¡). Mong a/c cÃ³ kinh nghiá»‡m chá»‰ giÃºp e ğŸ¥°ğŸ¥°.
Tks má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i.","[ Crawl data TripAdvisor ] ChÃ o má»i ngÆ°á»i áº¡, trÆ°á»›c Ä‘Ã¢y e cÃ³ crawl data trÃªn cÃ¡c trang web khÃ¡c bÃ¬nh thÆ°á»ng nhÆ°ng khi thá»­ crawl data trÃªn TripAdvisor thÃ¬ cÃ³ váº» khÃ´ng kháº£ thi (crawl ráº¥t lÃ¢u, hoáº·c káº¿t quáº£ tráº£ ra khÃ´ng á»Ÿ dáº¡ng HTML mÃ  lÃ  JS áº¡). Mong a/c cÃ³ kinh nghiá»‡m chá»‰ giÃºp e . Tks má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i.",,,"#Q&A, #data","#Q&A, #data","#Q&A, #data"
Chia sáº» vá»›i má»i ngÆ°á»i video Ä‘áº§u tiÃªn trong chuá»—i series vá» MLflow - má»™t cÃ´ng cá»¥ máº¡nh máº½ giÃºp chÃºng ta thá»±c hÃ nh MLOps.,Chia sáº» vá»›i má»i ngÆ°á»i video Ä‘áº§u tiÃªn trong chuá»—i series vá» MLflow - má»™t cÃ´ng cá»¥ máº¡nh máº½ giÃºp chÃºng ta thá»±c hÃ nh MLOps.,,,#sharing,"#sharing, #machine_learning","#sharing, #pythonlibraries"
"PhoGPT: Generative Pre-training for Vietnamese
GitHub: https://github.com/VinAIResearch/PhoGPT
We open-source a state-of-the-art 7.5B-parameter generative model series named PhoGPT for Vietnamese, which includes the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct. In addition, we also demonstrate its superior performance compared to previous open-source models through a human evaluation experiment.","PhoGPT: Generative Pre-training for Vietnamese GitHub: https://github.com/VinAIResearch/PhoGPT We open-source a state-of-the-art 7.5B-parameter generative model series named PhoGPT for Vietnamese, which includes the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct. In addition, we also demonstrate its superior performance compared to previous open-source models through a human evaluation experiment.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, nhÆ° má»i ngÆ°á»i biáº¿t thÃ¬ cÃ¡c model BERT thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i task retrieval. Em Ä‘ang sá»­ dá»¥ng nÃ³ cho 1 project há»i Ä‘Ã¡p vá» 1 tá»• chá»©c. NÃ³ hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t, tuy nhiÃªn thÃ¬ em Ä‘ang muá»‘n há»i má»i ngÆ°á»i 2 váº¥n Ä‘á»:
1. Model chá»‰ má»›i tráº£ vá» cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c chá»© chÆ°a pháº£i tráº£ lá»i 1 cÃ¡ch tá»± nhiÃªn. VÃ­ dá»¥:
Q: ""PhÃ²ng ban xyz cÃ³ bao nhiÃªu ngÆ°á»i?""
Model: ""17""
Äáº§u ra em muá»‘n -> ""PhÃ²ng ban xyz cÃ³ táº¥t cáº£ lÃ  17 ngÆ°á»i""
2. Model hoáº¡t Ä‘á»™ng khÃ´ng tá»‘t vá»›i nhá»¯ng cÃ¢u tráº£ lá»i dÃ i nhÆ°:
Q: ""TrÃ¬nh bÃ y cÃ¡c hÆ°á»›ng nghiÃªn cá»©u cá»§a phÃ²ng ban W""
Model: ""1. HÆ°á»›ng A""
Äáº§u ra em muá»‘n:
""1. HÆ°á»›ng A
2. HÆ°á»›ng B
3. HÆ°á»›ng C""
Hy vá»ng Ä‘Æ°á»£c nghe kinh nghiá»‡m cá»§a má»i ngÆ°á»i vá» váº¥n Ä‘á» nÃ y. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","Em chÃ o má»i ngÆ°á»i áº¡, nhÆ° má»i ngÆ°á»i biáº¿t thÃ¬ cÃ¡c model BERT thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i task retrieval. Em Ä‘ang sá»­ dá»¥ng nÃ³ cho 1 project há»i Ä‘Ã¡p vá» 1 tá»• chá»©c. NÃ³ hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t, tuy nhiÃªn thÃ¬ em Ä‘ang muá»‘n há»i má»i ngÆ°á»i 2 váº¥n Ä‘á»: 1. Model chá»‰ má»›i tráº£ vá» cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c chá»© chÆ°a pháº£i tráº£ lá»i 1 cÃ¡ch tá»± nhiÃªn. VÃ­ dá»¥: Q: ""PhÃ²ng ban xyz cÃ³ bao nhiÃªu ngÆ°á»i?"" Model: ""17"" Äáº§u ra em muá»‘n -> ""PhÃ²ng ban xyz cÃ³ táº¥t cáº£ lÃ  17 ngÆ°á»i"" 2. Model hoáº¡t Ä‘á»™ng khÃ´ng tá»‘t vá»›i nhá»¯ng cÃ¢u tráº£ lá»i dÃ i nhÆ°: Q: ""TrÃ¬nh bÃ y cÃ¡c hÆ°á»›ng nghiÃªn cá»©u cá»§a phÃ²ng ban W"" Model: ""1. HÆ°á»›ng A"" Äáº§u ra em muá»‘n: ""1. HÆ°á»›ng A 2. HÆ°á»›ng B 3. HÆ°á»›ng C"" Hy vá»ng Ä‘Æ°á»£c nghe kinh nghiá»‡m cá»§a má»i ngÆ°á»i vá» váº¥n Ä‘á» nÃ y. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,"#Q&A, #nlp","#Q&A, #nlp","#Q&A, #deep_learning, #nlp"
"Hi má»i ngÆ°á»i, mÃ¬nh cÃ³ chÃºt tháº¯c máº¯c vá» multi-thread trÃªn python nhÆ° sau:
NgÃ´n ngá»¯: Python
Thread A: MÃ¬nh chá»‰ Ä‘á»ƒ inference network - VÃ­ dá»¥ object segmentation. KhÃ´ng gá»“m pre-process hay post process. VÃ  táº¥t nhiÃªn cháº¡y trÃªn GPU
Thread B: Äá»c áº£nh tá»« camera => pre-process => Cáº¥p input cho thread A => láº¥y káº¿t quáº£ rá»“i post-process. Cháº¡y trÃªn CPU.
NhÆ° má»i ngÆ°á»i biáº¿t trÃªn Python cháº¡y multithread sáº½ khÃ´ng hiá»‡u qua vÃ¬ liÃªn quan GIL. NhÆ°ng vá»›i trÆ°á»ng há»£p nhÆ° trÃªn thÃ¬ khi chÆ°Æ¡ng trÃ¬nh Ä‘ang cháº¡y trÃªn GPU (thread A) thÃ¬ cÃ¡c tÃ¡c vá»¥ trÃªn CPU cÃ³ hoáº¡t Ä‘á»™ng Ä‘á»“ng thá»i khÃ´ng?","Hi má»i ngÆ°á»i, mÃ¬nh cÃ³ chÃºt tháº¯c máº¯c vá» multi-thread trÃªn python nhÆ° sau: NgÃ´n ngá»¯: Python Thread A: MÃ¬nh chá»‰ Ä‘á»ƒ inference network - VÃ­ dá»¥ object segmentation. KhÃ´ng gá»“m pre-process hay post process. VÃ  táº¥t nhiÃªn cháº¡y trÃªn GPU Thread B: Äá»c áº£nh tá»« camera => pre-process => Cáº¥p input cho thread A => láº¥y káº¿t quáº£ rá»“i post-process. Cháº¡y trÃªn CPU. NhÆ° má»i ngÆ°á»i biáº¿t trÃªn Python cháº¡y multithread sáº½ khÃ´ng hiá»‡u qua vÃ¬ liÃªn quan GIL. NhÆ°ng vá»›i trÆ°á»ng há»£p nhÆ° trÃªn thÃ¬ khi chÆ°Æ¡ng trÃ¬nh Ä‘ang cháº¡y trÃªn GPU (thread A) thÃ¬ cÃ¡c tÃ¡c vá»¥ trÃªn CPU cÃ³ hoáº¡t Ä‘á»™ng Ä‘á»“ng thá»i khÃ´ng?",,,"#Q&A, #pythonlibraries",,"#Q&A, #pythonlibraries"
"Hello má»i ngÆ°á»i, em cÃ³ má»™t vÃ© Vin AI day mÃ  em hong Ä‘i dc. Em muá»‘n pass láº¡i áº¡, má»i ngÆ°á»i ai muá»‘n Ä‘i thÃ¬ nháº¯n em áº¡","Hello má»i ngÆ°á»i, em cÃ³ má»™t vÃ© Vin AI day mÃ  em hong Ä‘i dc. Em muá»‘n pass láº¡i áº¡, má»i ngÆ°á»i ai muá»‘n Ä‘i thÃ¬ nháº¯n em áº¡",,,#sharing,#sharing,#sharing
"Hiá»‡n nay, chatbot Ä‘Ã£ trá»Ÿ thÃ nh má»™t cÃ´ng cá»¥ quan trá»ng cho cÃ¡c doanh nghiá»‡p Ä‘á»ƒ cung cáº¥p thÃ´ng tin vÃ  tÄƒng tÆ°Æ¡ng tÃ¡c Ä‘á»‘i vá»›i khÃ¡ch hÃ ng. Trong sá»‘ cÃ¡c loáº¡i chatbot, retrieval-based chatbot lÃ  má»™t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p phá»• biáº¿n nháº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡p á»©ng cÃ¡c yÃªu cáº§u vÃ  cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
Trong bÃ i hÃ´m nay, chÃºng ta sáº½ tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c vá» retrieval-based chatbot vÃ  cÃ¡c thÃ nh pháº§n NLP cáº¥u thÃ nh nÃªn loáº¡i chatbot nÃ y.","Hiá»‡n nay, chatbot Ä‘Ã£ trá»Ÿ thÃ nh má»™t cÃ´ng cá»¥ quan trá»ng cho cÃ¡c doanh nghiá»‡p Ä‘á»ƒ cung cáº¥p thÃ´ng tin vÃ  tÄƒng tÆ°Æ¡ng tÃ¡c Ä‘á»‘i vá»›i khÃ¡ch hÃ ng. Trong sá»‘ cÃ¡c loáº¡i chatbot, retrieval-based chatbot lÃ  má»™t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p phá»• biáº¿n nháº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡p á»©ng cÃ¡c yÃªu cáº§u vÃ  cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng. Trong bÃ i hÃ´m nay, chÃºng ta sáº½ tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c vá» retrieval-based chatbot vÃ  cÃ¡c thÃ nh pháº§n NLP cáº¥u thÃ nh nÃªn loáº¡i chatbot nÃ y.",,,"#sharing, #nlp","#sharing, #nlp","#sharing, #nlp"
"Hi má»i ngÆ°á»i,
HÃ´m nay mÃ¬nh xin phÃ©p chia sáº» má»™t bÃ i viáº¿t vá» AB Testing vÃ  cÃ¡ch Ã¡p dá»¥ng trong industry. Máº·c dÃ¹, AB Test khÃ¡ phá»• biáº¿n vÃ  lÃ  má»™t chá»§ Ä‘á» khÃ´ng má»›i, tuy nhiÃªn, mÃ¬nh nghÄ© ráº±ng Ä‘Ã´i khi chÃºng ta Ã¡p dá»¥ng thiáº¿u chÃ­nh xÃ¡c.
BÃ i viáº¿t nÃ y sáº½ bao gá»“m :
- Má»™t sá»‘ lÃ½ thuyáº¿t vá» AB Test,
- Kiá»ƒm Ä‘á»‹nh giáº£i thuyáº¿t
- Má»™t sá»‘ Ä‘iá»u lÆ°u Ã½ khi Ã¡p dá»¥ng trong industry.
BÃ i viáº¿t cÃ³ thá»ƒ sai sÃ³t do háº¡n cháº¿ cá»§a ngÆ°á»i viáº¿t, náº¿u má»i ngÆ°á»i phÃ¡t hiá»‡n thÃ¬ cÃ³ thá»ƒ comment táº¡i Ä‘Ã¢y hoáº·c trong blog Ä‘á»ƒ mÃ¬nh sá»­a nhÃ©.
Link bÃ i viáº¿t: https://pbcquoc.github.io/abtesting/","Hi má»i ngÆ°á»i, HÃ´m nay mÃ¬nh xin phÃ©p chia sáº» má»™t bÃ i viáº¿t vá» AB Testing vÃ  cÃ¡ch Ã¡p dá»¥ng trong industry. Máº·c dÃ¹, AB Test khÃ¡ phá»• biáº¿n vÃ  lÃ  má»™t chá»§ Ä‘á» khÃ´ng má»›i, tuy nhiÃªn, mÃ¬nh nghÄ© ráº±ng Ä‘Ã´i khi chÃºng ta Ã¡p dá»¥ng thiáº¿u chÃ­nh xÃ¡c. BÃ i viáº¿t nÃ y sáº½ bao gá»“m : - Má»™t sá»‘ lÃ½ thuyáº¿t vá» AB Test, - Kiá»ƒm Ä‘á»‹nh giáº£i thuyáº¿t - Má»™t sá»‘ Ä‘iá»u lÆ°u Ã½ khi Ã¡p dá»¥ng trong industry. BÃ i viáº¿t cÃ³ thá»ƒ sai sÃ³t do háº¡n cháº¿ cá»§a ngÆ°á»i viáº¿t, náº¿u má»i ngÆ°á»i phÃ¡t hiá»‡n thÃ¬ cÃ³ thá»ƒ comment táº¡i Ä‘Ã¢y hoáº·c trong blog Ä‘á»ƒ mÃ¬nh sá»­a nhÃ©. Link bÃ i viáº¿t: https://pbcquoc.github.io/abtesting/",,,"#sharing, #math ",#sharing,"#sharing, #machine_learning"
"Xin phÃ©p admin áº¡, mÃ¬nh vá»«a viáº¿t má»™t bÃ i so sÃ¡nh Yolov8 vá»›i RT-DERT trÃªn bá»™ dá»¯ liá»‡u Aquarium, mong Ä‘Æ°á»£c má»i ngÆ°á»i á»§ng há»™ áº¡.","Xin phÃ©p admin áº¡, mÃ¬nh vá»«a viáº¿t má»™t bÃ i so sÃ¡nh Yolov8 vá»›i RT-DERT trÃªn bá»™ dá»¯ liá»‡u Aquarium, mong Ä‘Æ°á»£c má»i ngÆ°á»i á»§ng há»™ áº¡.",,,"#sharing, #deep_learing","#sharing, #deep_learing","#sharing, #deep_learing"
Chia sáº» tá»›i cÃ¡c báº¡n má»™t repo Ä‘á»ƒ há»c cÃ¡ch implement model hiá»‡u quáº£:,Chia sáº» tá»›i cÃ¡c báº¡n má»™t repo Ä‘á»ƒ há»c cÃ¡ch implement model hiá»‡u quáº£:,,,#sharing,,
"Xin chÃ o má»i ngÆ°á»i áº¡,
HÃ´m nay em muá»‘n chia sáº» vá»›i má»i ngÆ°á»i má»™t dá»± Ã¡n nhá» vá» Retrieval-Augmented Generation. Dá»± Ã¡n nÃ y ban Ä‘áº§u Ä‘Æ°á»£c sinh ra vá»›i má»¥c Ä‘Ã­ch thi thá»‘ táº¡i cuá»™c thi Viettel Hearted AI Challenge. BÃ i toÃ¡n lÃ  dá»±a trÃªn corpus cÃ¡c bÃ i viáº¿t Wikipedia tiáº¿ng Viá»‡t Ä‘Æ°á»£c cho trÆ°á»›c, xÃ¢y dá»±ng má»™t giáº£i phÃ¡p RAG Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c cÃ¢u há»i mÃ  cÃ¢u tráº£ lá»i cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong corpus Ä‘Ã³. Tuy khÃ´ng Ä‘Æ°á»£c giáº£i nhÆ°ng em tháº¥y ráº±ng thÃ nh quáº£ cá»§a Ä‘á»™i mÃ¬nh cÅ©ng thÃº vá»‹ vÃ  muá»‘n chia sáº» tá»›i cá»™ng Ä‘á»“ng áº¡.
Dá»± Ã¡n nÃ y bao gá»“m:
MÃ´ hÃ¬nh Llama-2-7b Ä‘Ã£ Ä‘Æ°á»£c instruct-finetuned vá»›i dá»¯ liá»‡u chá»‰ dáº«n chá»§ yáº¿u thuá»™c vá» bÃ i toÃ¡n há»i Ä‘Ã¡p miá»n Ä‘Ã³ng tiáº¿ng Viá»‡t (closed question answering). MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng Ä‘Æ°a ra pháº£n há»“i cho má»™t cÃ¢u há»i dá»±a trÃªn ná»™i dung ngá»¯ cáº£nh kÃ¨m theo nÃ³. 
TÃ­ch há»£p mÃ´ hÃ¬nh nÃ y vÃ o má»™t pipeline RAG Ä‘Æ¡n giáº£n.
ThÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n em xin Ä‘á»ƒ dÆ°á»›i comment.
Demo dá»± Ã¡n:
 â€” vá»›i BÃ¹i ChÃ­ Minh.","Xin chÃ o má»i ngÆ°á»i áº¡, HÃ´m nay em muá»‘n chia sáº» vá»›i má»i ngÆ°á»i má»™t dá»± Ã¡n nhá» vá» Retrieval-Augmented Generation. Dá»± Ã¡n nÃ y ban Ä‘áº§u Ä‘Æ°á»£c sinh ra vá»›i má»¥c Ä‘Ã­ch thi thá»‘ táº¡i cuá»™c thi Viettel Hearted AI Challenge. BÃ i toÃ¡n lÃ  dá»±a trÃªn corpus cÃ¡c bÃ i viáº¿t Wikipedia tiáº¿ng Viá»‡t Ä‘Æ°á»£c cho trÆ°á»›c, xÃ¢y dá»±ng má»™t giáº£i phÃ¡p RAG Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c cÃ¢u há»i mÃ  cÃ¢u tráº£ lá»i cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong corpus Ä‘Ã³. Tuy khÃ´ng Ä‘Æ°á»£c giáº£i nhÆ°ng em tháº¥y ráº±ng thÃ nh quáº£ cá»§a Ä‘á»™i mÃ¬nh cÅ©ng thÃº vá»‹ vÃ  muá»‘n chia sáº» tá»›i cá»™ng Ä‘á»“ng áº¡. Dá»± Ã¡n nÃ y bao gá»“m: MÃ´ hÃ¬nh Llama-2-7b Ä‘Ã£ Ä‘Æ°á»£c instruct-finetuned vá»›i dá»¯ liá»‡u chá»‰ dáº«n chá»§ yáº¿u thuá»™c vá» bÃ i toÃ¡n há»i Ä‘Ã¡p miá»n Ä‘Ã³ng tiáº¿ng Viá»‡t (closed question answering). MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng Ä‘Æ°a ra pháº£n há»“i cho má»™t cÃ¢u há»i dá»±a trÃªn ná»™i dung ngá»¯ cáº£nh kÃ¨m theo nÃ³. TÃ­ch há»£p mÃ´ hÃ¬nh nÃ y vÃ o má»™t pipeline RAG Ä‘Æ¡n giáº£n. ThÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n em xin Ä‘á»ƒ dÆ°á»›i comment. Demo dá»± Ã¡n: â€” vá»›i BÃ¹i ChÃ­ Minh.",,,"#sharing, #nlp",,
"Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n nhá» vá» Voice cloning trÃªn Tiáº¿ng Viá»‡t.
Input lÃ  1 Ä‘oáº¡n voice ghi Ã¢m láº¥y tá»« ngÆ°á»i dÃ¹ng
Output muá»‘n cÃ³ model voice clone tá»« ngÆ°á»i dÃ¹ng input, text to speech má»™t list cÃ¡c cÃ¢u vÄƒn Ä‘Ã£ Ä‘Æ°á»£c soáº¡n trÆ°á»›c.
KhÃ´ng biáº¿t cÃ³ bÃªn nÃ o hay github nÃ o support viá»‡c nÃ y vÃ  há»— trá»£ cho Tiáº¿ng Viá»‡t khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n nhá» vá» Voice cloning trÃªn Tiáº¿ng Viá»‡t. Input lÃ  1 Ä‘oáº¡n voice ghi Ã¢m láº¥y tá»« ngÆ°á»i dÃ¹ng Output muá»‘n cÃ³ model voice clone tá»« ngÆ°á»i dÃ¹ng input, text to speech má»™t list cÃ¡c cÃ¢u vÄƒn Ä‘Ã£ Ä‘Æ°á»£c soáº¡n trÆ°á»›c. KhÃ´ng biáº¿t cÃ³ bÃªn nÃ o hay github nÃ o support viá»‡c nÃ y vÃ  há»— trá»£ cho Tiáº¿ng Viá»‡t khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,#Q&A,,
"em chÃ o má»i ngÆ°á»i . má»i ngÆ°á»i Ä‘Ã£ ai tá»«ng sá»­ dá»¥ng ""NlpHUST/vi-electra-small"" rá»“i cÃ³ thá»ƒ cho em xin cÃ¡ch load tokenize tá»« checkpoint nÃ y vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. em load nhÆ° trong áº£nh khi in ra tháº¥y cÃ¡c token Ä‘á»u Ä‘ang khÃ´ng cÃ³ dáº¥u. mÃ  trÃªn huggingface thÃ¬ khÃ´ng cÃ³ hÆ°á»›ng dáº«n . em cáº£m Æ¡n áº¡","em chÃ o má»i ngÆ°á»i . má»i ngÆ°á»i Ä‘Ã£ ai tá»«ng sá»­ dá»¥ng ""NlpHUST/vi-electra-small"" rá»“i cÃ³ thá»ƒ cho em xin cÃ¡ch load tokenize tá»« checkpoint nÃ y vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. em load nhÆ° trong áº£nh khi in ra tháº¥y cÃ¡c token Ä‘á»u Ä‘ang khÃ´ng cÃ³ dáº¥u. mÃ  trÃªn huggingface thÃ¬ khÃ´ng cÃ³ hÆ°á»›ng dáº«n . em cáº£m Æ¡n áº¡",,,"#Q&A, #nlp, #deep_learning",,
"Em chÃ o mn áº¡, em Ä‘ang thá»­ sá»­ dá»¥ng RAG vá»›i model chat lÃ  phogpt-7.5b-instruct cá»§a VinAI nhÆ°ng em Ä‘ang bá»‹ vÆ°á»›ng á»Ÿ load model trÃªn GGcolab bá»‹ crash:( KhÃ´ng biáº¿t mn cÃ³ cÃ¡ch nÃ o load Ä‘c ngoÃ i viá»‡c dÃ¹ng báº£n plus khÃ´ng áº¡, em cáº£m Æ¡n áº¡.","Em chÃ o mn áº¡, em Ä‘ang thá»­ sá»­ dá»¥ng RAG vá»›i model chat lÃ  phogpt-7.5b-instruct cá»§a VinAI nhÆ°ng em Ä‘ang bá»‹ vÆ°á»›ng á»Ÿ load model trÃªn GGcolab bá»‹ crash:( KhÃ´ng biáº¿t mn cÃ³ cÃ¡ch nÃ o load Ä‘c ngoÃ i viá»‡c dÃ¹ng báº£n plus khÃ´ng áº¡, em cáº£m Æ¡n áº¡.",,,"#Q&A, #nlp, #deep_learning",,
"Mn cho em há»i case nÃ y vá»›i, em cÃ³ train model vá»›i 2 input lÃ  tÃ´i Ä‘i há» sáº½ ra há»c vÃ  toi di ho sáº½ ra hoc. NhÆ°ng h khi input vÃ o thÃ¬ e muá»‘n lÃ  tÃ´i Ä‘i ho cÅ©ng sáº½ ra há»c. cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ nÃ³ váº«n ra nhÆ° v mÃ  mÃ¬nh k cáº§n pháº£i training láº¡i model hong áº¡ ?","Mn cho em há»i case nÃ y vá»›i, em cÃ³ train model vá»›i 2 input lÃ  tÃ´i Ä‘i há» sáº½ ra há»c vÃ  toi di ho sáº½ ra hoc. NhÆ°ng h khi input vÃ o thÃ¬ e muá»‘n lÃ  tÃ´i Ä‘i ho cÅ©ng sáº½ ra há»c. cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ nÃ³ váº«n ra nhÆ° v mÃ  mÃ¬nh k cáº§n pháº£i training láº¡i model hong áº¡ ?",,,#Q&A,,
"ChÃ o má»i ngÆ°á»i

Em Ä‘ang cÃ³ dá»± Ã¡n cuá»‘i kÃ¬ vá»›i tiÃªu Ä‘á» lÃ  Brain Tumor Segmentation, nhÃ³m cÃ³ sá»­ dá»¥ng thuáº­t toÃ¡n Fuzzy-Mean Ä‘á»ƒ Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p song song vÃ o Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n. Äá»ƒ hoÃ n thÃ nh dá»± Ã¡n thÃ¬ em cÃ³ chá»n GMM Ä‘á»ƒ loáº¡i bá» pháº§n vá» nÃ£o nhÆ°ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vÃ¹ng chá»©a u nÃ£o thÃ¬ bá»n e váº«n chÆ°a lÃ m Ä‘Æ°á»£c áº¡. Mong ac cÃ³ kinh nghiá»‡m khi xá»­ lÃ­ áº£nh y táº¿ (dicom) cho e Ã­t kinh nghiá»‡m áº¡. E cáº£m Æ¡n nhiá»u áº¡ ğŸ˜â˜ºğŸ˜â˜ºğŸ˜ .
Dá»± Ã¡n khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng Deep Learning áº¡.

áº¢nh dÆ°á»›i lÃ  sau khi dÃ¹ng GMM áº¡.","ChÃ o má»i ngÆ°á»i Em Ä‘ang cÃ³ dá»± Ã¡n cuá»‘i kÃ¬ vá»›i tiÃªu Ä‘á» lÃ  Brain Tumor Segmentation, nhÃ³m cÃ³ sá»­ dá»¥ng thuáº­t toÃ¡n Fuzzy-Mean Ä‘á»ƒ Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p song song vÃ o Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n. Äá»ƒ hoÃ n thÃ nh dá»± Ã¡n thÃ¬ em cÃ³ chá»n GMM Ä‘á»ƒ loáº¡i bá» pháº§n vá» nÃ£o nhÆ°ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vÃ¹ng chá»©a u nÃ£o thÃ¬ bá»n e váº«n chÆ°a lÃ m Ä‘Æ°á»£c áº¡. Mong ac cÃ³ kinh nghiá»‡m khi xá»­ lÃ­ áº£nh y táº¿ (dicom) cho e Ã­t kinh nghiá»‡m áº¡. E cáº£m Æ¡n nhiá»u áº¡ . Dá»± Ã¡n khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng Deep Learning áº¡. áº¢nh dÆ°á»›i lÃ  sau khi dÃ¹ng GMM áº¡.",,,"#Q&A, #cv",,
"Em chÃ o má»i ngÆ°á»i áº¡ , em hiá»‡n Ä‘ang lÃ m vá» task ""key information extraction"" , em cÃ³ tÃ¬m hiá»ƒu má»™t sá»‘ thÆ° viá»‡n  trÃªn github vÃ  Ä‘ang thá»­ paddleocr, hiá»‡n táº¡i em gáº·p má»™t sá»‘ váº¥n Ä‘á» vá» cÃ i Ä‘áº·t mÃ´i trÆ°á»ng:
em cÃ³ lÃ m theo document trÃªn github repository nhÆ°ng váº«n bá»‹ lá»—i  áº¡ (pháº§n 2. training ,lá»—i á»Ÿ link  issue ) 
 em cÃ³ thá»­ cÃ i Ä‘áº·t trÃªn docker nhÆ°ng váº«n khÃ´ng Ä‘Æ°á»£c áº¡ (lá»—i á»Ÿ hÃ¬nh bÃªn dÆ°á»›i)
 cÃ³ bÃ¡c nÃ o rÃ nh vá» paddle hay task kie khÃ´ng  áº¡?
cuda:11.8 
ubuntu:22.04
repository:https://github.com/PaddlePaddle/PaddleOCR/tree/release/2.7
document:https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/kie_en.md
issue: https://github.com/PaddlePaddle/PaddleOCR/issues/11261
docker:https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/environment_en.md?fbclid=IwAR3TT4e98_wn87EyMR_9gvRwlmXYysN52vLbuBCqnw9h36MjHsRxBpLSKIA","Em chÃ o má»i ngÆ°á»i áº¡ , em hiá»‡n Ä‘ang lÃ m vá» task ""key information extraction"" , em cÃ³ tÃ¬m hiá»ƒu má»™t sá»‘ thÆ° viá»‡n trÃªn github vÃ  Ä‘ang thá»­ paddleocr, hiá»‡n táº¡i em gáº·p má»™t sá»‘ váº¥n Ä‘á» vá» cÃ i Ä‘áº·t mÃ´i trÆ°á»ng: em cÃ³ lÃ m theo document trÃªn github repository nhÆ°ng váº«n bá»‹ lá»—i áº¡ (pháº§n 2. training ,lá»—i á»Ÿ link issue ) em cÃ³ thá»­ cÃ i Ä‘áº·t trÃªn docker nhÆ°ng váº«n khÃ´ng Ä‘Æ°á»£c áº¡ (lá»—i á»Ÿ hÃ¬nh bÃªn dÆ°á»›i) cÃ³ bÃ¡c nÃ o rÃ nh vá» paddle hay task kie khÃ´ng áº¡? cuda:11.8 ubuntu:22.04 repository:https://github.com/PaddlePaddle/PaddleOCR/tree/release/2.7 document:https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/kie_en.md issue: https://github.com/PaddlePaddle/PaddleOCR/issues/11261 docker:https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/environment_en.md?fbclid=IwAR3TT4e98_wn87EyMR_9gvRwlmXYysN52vLbuBCqnw9h36MjHsRxBpLSKIA",,,"#Q&A, #python",,
"Chatbot Ä‘Ã£ thay Ä‘á»•i cÃ¡ch chÃºng ta tÆ°Æ¡ng tÃ¡c vá»›i cÃ´ng nghá»‡ vÃ  dá»‹ch vá»¥ trá»±c tuyáº¿n. ChÃºng ta Ä‘Ã£ dáº§n quen vá»›i viá»‡c trÃ² chuyá»‡n vá»›i chatbot trÃªn trang web cá»§a má»™t doanh nghiá»‡p Ä‘áº¿n gá»­i tin nháº¯n vá»›i chatbot trÃªn cÃ¡c á»©ng dá»¥ng nháº¯n tin. TrÃªn thá»±c táº¿, chatbot Ä‘ang trá»Ÿ thÃ nh má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u trong viá»‡c cung cáº¥p há»— trá»£ vÃ  thÃ´ng tin tá»©c thá»i cho khÃ¡ch hÃ ng.
NhÆ°ng chatbot lÃ  gÃ¬ vÃ  lÃ m tháº¿ nÃ o chÃºng hoáº¡t Ä‘á»™ng? Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ khÃ¡m phÃ¡ sÃ¢u hÆ¡n vá» chatbot vÃ  cÃ¡ch chÃºng thá»±c hiá»‡n nhiá»‡m vá»¥ cá»§a mÃ¬nh.","Chatbot Ä‘Ã£ thay Ä‘á»•i cÃ¡ch chÃºng ta tÆ°Æ¡ng tÃ¡c vá»›i cÃ´ng nghá»‡ vÃ  dá»‹ch vá»¥ trá»±c tuyáº¿n. ChÃºng ta Ä‘Ã£ dáº§n quen vá»›i viá»‡c trÃ² chuyá»‡n vá»›i chatbot trÃªn trang web cá»§a má»™t doanh nghiá»‡p Ä‘áº¿n gá»­i tin nháº¯n vá»›i chatbot trÃªn cÃ¡c á»©ng dá»¥ng nháº¯n tin. TrÃªn thá»±c táº¿, chatbot Ä‘ang trá»Ÿ thÃ nh má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u trong viá»‡c cung cáº¥p há»— trá»£ vÃ  thÃ´ng tin tá»©c thá»i cho khÃ¡ch hÃ ng. NhÆ°ng chatbot lÃ  gÃ¬ vÃ  lÃ m tháº¿ nÃ o chÃºng hoáº¡t Ä‘á»™ng? Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ khÃ¡m phÃ¡ sÃ¢u hÆ¡n vá» chatbot vÃ  cÃ¡ch chÃºng thá»±c hiá»‡n nhiá»‡m vá»¥ cá»§a mÃ¬nh.",,,"#sharing, #nlp",,
"Xin phÃ©p add
Em lÃ  AI Engineer vá» Computer vision. Em Ä‘Ã£ lÃ m viá»‡c Ä‘Æ°á»£c gáº§n 1 nÄƒm.
Em muá»‘n tÃ¬m má»™t cÃ´ng ty má»›i cÃ³ mÃ´i trÆ°á»ng lÃ m viá»‡c vÃ  má»©c lÆ°Æ¡ng phÃ¹ há»£p, vÃ¬ cÃ´ng ty cÅ© khÃ´ng cÃ²n phÃ¹ há»£p ná»¯a.
VÃ¬ nhiá»u lÃ½ do nÃªn em khÃ´ng tiá»‡n chia sáº» cv cá»§a mÃ¬nh lÃªn bÃ i. Táº¡i cÃ´ng ty hiá»‡n táº¡i, vá»‹ trÃ­ cá»§a em lÃ  ká»¹ sÆ° AI full-stack, cÃ¡c dá»± Ã¡n mÃ  em Ä‘Ã£ tham gia táº¡i cÃ´ng ty nhÆ° OCR, phÃ¡t hiá»‡n lá»—i sáº£n pháº©m, nháº­n diá»‡n khuÃ´n máº·t,...
CÃ´ng ty anh/chá»‹ cÃ³ nhu cáº§u tuyá»ƒn dá»¥ng, em mong cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c liÃªn há»‡, ráº¥t vui Ä‘Æ°á»£c há»£p tÃ¡c vÃ  trao Ä‘á»•i vá»›i anh/chá»‹
Cáº£m Æ¡n!!
#ComputerVision, #AI, #job,","Xin phÃ©p add Em lÃ  AI Engineer vá» Computer vision. Em Ä‘Ã£ lÃ m viá»‡c Ä‘Æ°á»£c gáº§n 1 nÄƒm. Em muá»‘n tÃ¬m má»™t cÃ´ng ty má»›i cÃ³ mÃ´i trÆ°á»ng lÃ m viá»‡c vÃ  má»©c lÆ°Æ¡ng phÃ¹ há»£p, vÃ¬ cÃ´ng ty cÅ© khÃ´ng cÃ²n phÃ¹ há»£p ná»¯a. VÃ¬ nhiá»u lÃ½ do nÃªn em khÃ´ng tiá»‡n chia sáº» cv cá»§a mÃ¬nh lÃªn bÃ i. Táº¡i cÃ´ng ty hiá»‡n táº¡i, vá»‹ trÃ­ cá»§a em lÃ  ká»¹ sÆ° AI full-stack, cÃ¡c dá»± Ã¡n mÃ  em Ä‘Ã£ tham gia táº¡i cÃ´ng ty nhÆ° OCR, phÃ¡t hiá»‡n lá»—i sáº£n pháº©m, nháº­n diá»‡n khuÃ´n máº·t,... CÃ´ng ty anh/chá»‹ cÃ³ nhu cáº§u tuyá»ƒn dá»¥ng, em mong cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c liÃªn há»‡, ráº¥t vui Ä‘Æ°á»£c há»£p tÃ¡c vÃ  trao Ä‘á»•i vá»›i anh/chá»‹ Cáº£m Æ¡n!!","#ComputerVision,	#AI,	#job,",,#Q&A,,
"em chÃ o má»i ngÆ°á»i !
em lÃ  ngÆ°á»i má»›i nÃªn cÃ³ thá»ƒ má»™t sá»‘ kiáº¿n thá»©c em váº«n chÆ°a cháº¯c láº¯m cÃ¡c anh thÃ´ng cáº£m náº¿u Ä‘iá»u em há»i cÃ³ hÆ¡i ngÃ¡o , em hiá»‡n Ä‘ang lÃ m 1 project nhá» vá» chatbot . em cÃ³ 1 sá»‘ tháº¯c máº¯c sau mong má»i ngÆ°á»i bá»›t chÃºt thá»i gian giáº£i thÃ­ch giÃºp em áº¡ .
- 1 )Ã½ tÆ°á»Ÿng cá»§a em lÃ  sá»­ dá»¥ng langchain Ä‘á»ƒ káº¿t ná»‘i vá»›i 1 llm tiáº¿ng viá»‡t ( nhÆ° phogpt , phobert , vit5 ...) vÃ  nhÃºng cÃ¡c kiáº¿n thá»©c dÆ°á»›i dáº¡ng cÃ¡c tá»‡p tÃ i liá»‡u ( pdf , text , doc .. ) Ä‘á»ƒ khÃ´ng pháº£i train láº¡i llm .
nhÆ°ng hiá»‡n táº¡i em thao tÃ¡c vá»›i tiáº¿ng viá»‡t thÃ¬ nÃ³ gáº·p lá»—i á»Ÿ pháº§n chuyá»ƒn hÃ³a kiáº¿n thá»©c file pdf ( chá»©a 1 vÄƒn báº£n tiáº¿ng viá»‡t ) nÃ³ khÃ´ng thá»ƒ vector hÃ³a kiáº¿n thá»©c Ä‘Æ°á»£c . nhÆ°ng náº¿u em sá»­ dá»¥ng vá»›i tiáº¿ng anh vÃ  model zephyr7b vÃ  model sentence-transformers/all-mpnet-base-v2 Ä‘á»ƒ vector hÃ³a kiáº¿n thá»©c thÃ¬ nÃ³ hoáº¡t Ä‘á»™ng tá»‘t vá»›i tÃ i liá»‡u tiáº¿ng anh .
em Ä‘ang Ä‘á»‹nh sá»­ lÃ½ theo kiá»ƒu chuyá»ƒn háº¿t tÃ i liá»‡u tiáº¿ng viá»‡t thÃ nh dáº¡ng tiáº¿ng anh Ä‘á»ƒ cÃ³ thá»ƒ nhÃºng vÃ o model vÃ  khi user nháº­p cÃ¢u há»i vÃ o thÃ¬ cho nÃ³ cháº¡y qua 1 model dá»‹ch Ä‘á»ƒ dá»‹ch nÃ³ thÃ nh tiáº¿ng anh rá»“i má»›i Ä‘Æ°a vÃ o chatbot vÃ  khi chatbot pháº£n há»“i thÃ¬ láº¡i cho cháº¡y qua 1 lÆ°á»£t dá»‹ch Ä‘á»ƒ dich láº¡i thÃ nh tiáº¿ng viá»‡t . nhÆ°ng nhÆ° váº­y thÃ¬ em tháº¥y khÃ¡ cá»“ng ká»nh vÃ  náº¿u dá»‹ch qua láº¡i giá»¯a tiáº¿ng anh thÃ¬ em sá»£ nÃ³ bi máº¥t Ä‘i má»™t sá»‘ nghÄ©a Ä‘áº·c chÆ°ng cá»§a tiáº¿ng viá»‡t .
Ä‘Ã¢y lÃ  link colab chatbot sá»­ dá»¥ng zephy7b : https://drive.google.com/file/d/1c8_o0j0TMHY4S5daNFZwQVgW8MkBL9C-/view?usp=sharing
em muá»‘n xÃ¢y chatbot kiá»ƒu giá»‘ng nhÆ° cÃ¡i bÃªn trÃªn nhÆ°ng hoáº¡t Ä‘á»™ng vá»›i tiáº¿ng viá»‡t .
- 2 ) em cÃ³ tra cá»©u trÃªn 1 sá»‘ diá»…n Ä‘Ã n vÃ  gg thÃ¬ tháº¥y há» báº£o ráº±ng nÃªn sá»­ dá»¥ng loáº¡i model : Question Answering Ä‘á»ƒ táº¡o chatbot thay vÃ¬ sá»­ dá»¥ng Text2Text Generation trÃªn hugging face , Ä‘iá»u nÃ y cÃ³ Ä‘Ãºng khÃ´ng váº­y áº¡ ? hay lÃ  nÃªn sá»­ dá»¥ng loáº¡i model nÃ o ?
- 3 ) em sau 1 thá»i gian tÃ¬m hiá»ƒu thÃ¬ em tháº¥y trÆ°á»›c khi vector hÃ³a kiáº¿n thá»©c Ä‘á»ƒ nhÃºng cho llm sá»­ dá»¥ng thÃ¬ nÃªn cho nÃ³ cháº¡y qua loáº¡i model Token Classification Ä‘á»ƒ phÃ¢n tÃ¡ch kiáº¿n thá»©c ra , Ä‘iá»u nÃ y cÃ³ Ä‘Ãºng khÃ´ng áº¡ ?
- 4 ) cuá»‘i cÃ¹ng em cÃ³ tÃ¬m hiá»ƒu vÃ  cháº¡y thá»­ thÃ¬ tháº¥y ká»ƒ cáº£ cháº¡y trÃªn gpu ( colab ) thÃ¬ thá»i gian pháº£n há»“i cá»§a nÃ³ cÅ©ng khoáº£ng 10s vá»›i model khoáº£ng 7b . cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tá»‘i Æ°u khÃ´ng áº¡ ? vÃ  cÃ³ nÃªn Ä‘á»ƒ nÃ³ cháº¡y chá»‰ vá»›i cpu khÃ´ng áº¡ ? kiá»ƒu nhÆ° lÃºc mÃ¬nh triá»ƒn khai áº¥y thÃ¬ gpu khÃ´ng pháº£i lÃºc nÃ o cÅ©ng sáºµn cÃ³ .
cÃ¡c anh cÃ³ thá»ƒ cho em má»™t sá»‘ gá»£i Ã½ Ä‘á»ƒ em sá»­ lÃ½ cÃ¡c váº¥n Ä‘á» nÃ y khÃ´ng ? náº¿u Ä‘Æ°á»£c thÃ¬ cÃ¡c anh cho em xin 1 sá»‘ tÃªn model hoáº·c tÃ i liá»‡u Ä‘á»ƒ em tham kháº£o vá»›i áº¡ . em cáº£m Æ¡n .","em chÃ o má»i ngÆ°á»i ! em lÃ  ngÆ°á»i má»›i nÃªn cÃ³ thá»ƒ má»™t sá»‘ kiáº¿n thá»©c em váº«n chÆ°a cháº¯c láº¯m cÃ¡c anh thÃ´ng cáº£m náº¿u Ä‘iá»u em há»i cÃ³ hÆ¡i ngÃ¡o , em hiá»‡n Ä‘ang lÃ m 1 project nhá» vá» chatbot . em cÃ³ 1 sá»‘ tháº¯c máº¯c sau mong má»i ngÆ°á»i bá»›t chÃºt thá»i gian giáº£i thÃ­ch giÃºp em áº¡ . - 1 )Ã½ tÆ°á»Ÿng cá»§a em lÃ  sá»­ dá»¥ng langchain Ä‘á»ƒ káº¿t ná»‘i vá»›i 1 llm tiáº¿ng viá»‡t ( nhÆ° phogpt , phobert , vit5 ...) vÃ  nhÃºng cÃ¡c kiáº¿n thá»©c dÆ°á»›i dáº¡ng cÃ¡c tá»‡p tÃ i liá»‡u ( pdf , text , doc .. ) Ä‘á»ƒ khÃ´ng pháº£i train láº¡i llm . nhÆ°ng hiá»‡n táº¡i em thao tÃ¡c vá»›i tiáº¿ng viá»‡t thÃ¬ nÃ³ gáº·p lá»—i á»Ÿ pháº§n chuyá»ƒn hÃ³a kiáº¿n thá»©c file pdf ( chá»©a 1 vÄƒn báº£n tiáº¿ng viá»‡t ) nÃ³ khÃ´ng thá»ƒ vector hÃ³a kiáº¿n thá»©c Ä‘Æ°á»£c . nhÆ°ng náº¿u em sá»­ dá»¥ng vá»›i tiáº¿ng anh vÃ  model zephyr7b vÃ  model sentence-transformers/all-mpnet-base-v2 Ä‘á»ƒ vector hÃ³a kiáº¿n thá»©c thÃ¬ nÃ³ hoáº¡t Ä‘á»™ng tá»‘t vá»›i tÃ i liá»‡u tiáº¿ng anh . em Ä‘ang Ä‘á»‹nh sá»­ lÃ½ theo kiá»ƒu chuyá»ƒn háº¿t tÃ i liá»‡u tiáº¿ng viá»‡t thÃ nh dáº¡ng tiáº¿ng anh Ä‘á»ƒ cÃ³ thá»ƒ nhÃºng vÃ o model vÃ  khi user nháº­p cÃ¢u há»i vÃ o thÃ¬ cho nÃ³ cháº¡y qua 1 model dá»‹ch Ä‘á»ƒ dá»‹ch nÃ³ thÃ nh tiáº¿ng anh rá»“i má»›i Ä‘Æ°a vÃ o chatbot vÃ  khi chatbot pháº£n há»“i thÃ¬ láº¡i cho cháº¡y qua 1 lÆ°á»£t dá»‹ch Ä‘á»ƒ dich láº¡i thÃ nh tiáº¿ng viá»‡t . nhÆ°ng nhÆ° váº­y thÃ¬ em tháº¥y khÃ¡ cá»“ng ká»nh vÃ  náº¿u dá»‹ch qua láº¡i giá»¯a tiáº¿ng anh thÃ¬ em sá»£ nÃ³ bi máº¥t Ä‘i má»™t sá»‘ nghÄ©a Ä‘áº·c chÆ°ng cá»§a tiáº¿ng viá»‡t . Ä‘Ã¢y lÃ  link colab chatbot sá»­ dá»¥ng zephy7b : https://drive.google.com/file/d/1c8_o0j0TMHY4S5daNFZwQVgW8MkBL9C-/view?usp=sharing em muá»‘n xÃ¢y chatbot kiá»ƒu giá»‘ng nhÆ° cÃ¡i bÃªn trÃªn nhÆ°ng hoáº¡t Ä‘á»™ng vá»›i tiáº¿ng viá»‡t . - 2 ) em cÃ³ tra cá»©u trÃªn 1 sá»‘ diá»…n Ä‘Ã n vÃ  gg thÃ¬ tháº¥y há» báº£o ráº±ng nÃªn sá»­ dá»¥ng loáº¡i model : Question Answering Ä‘á»ƒ táº¡o chatbot thay vÃ¬ sá»­ dá»¥ng Text2Text Generation trÃªn hugging face , Ä‘iá»u nÃ y cÃ³ Ä‘Ãºng khÃ´ng váº­y áº¡ ? hay lÃ  nÃªn sá»­ dá»¥ng loáº¡i model nÃ o ? - 3 ) em sau 1 thá»i gian tÃ¬m hiá»ƒu thÃ¬ em tháº¥y trÆ°á»›c khi vector hÃ³a kiáº¿n thá»©c Ä‘á»ƒ nhÃºng cho llm sá»­ dá»¥ng thÃ¬ nÃªn cho nÃ³ cháº¡y qua loáº¡i model Token Classification Ä‘á»ƒ phÃ¢n tÃ¡ch kiáº¿n thá»©c ra , Ä‘iá»u nÃ y cÃ³ Ä‘Ãºng khÃ´ng áº¡ ? - 4 ) cuá»‘i cÃ¹ng em cÃ³ tÃ¬m hiá»ƒu vÃ  cháº¡y thá»­ thÃ¬ tháº¥y ká»ƒ cáº£ cháº¡y trÃªn gpu ( colab ) thÃ¬ thá»i gian pháº£n há»“i cá»§a nÃ³ cÅ©ng khoáº£ng 10s vá»›i model khoáº£ng 7b . cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tá»‘i Æ°u khÃ´ng áº¡ ? vÃ  cÃ³ nÃªn Ä‘á»ƒ nÃ³ cháº¡y chá»‰ vá»›i cpu khÃ´ng áº¡ ? kiá»ƒu nhÆ° lÃºc mÃ¬nh triá»ƒn khai áº¥y thÃ¬ gpu khÃ´ng pháº£i lÃºc nÃ o cÅ©ng sáºµn cÃ³ . cÃ¡c anh cÃ³ thá»ƒ cho em má»™t sá»‘ gá»£i Ã½ Ä‘á»ƒ em sá»­ lÃ½ cÃ¡c váº¥n Ä‘á» nÃ y khÃ´ng ? náº¿u Ä‘Æ°á»£c thÃ¬ cÃ¡c anh cho em xin 1 sá»‘ tÃªn model hoáº·c tÃ i liá»‡u Ä‘á»ƒ em tham kháº£o vá»›i áº¡ . em cáº£m Æ¡n .",,,"#Q&A, #nlp, #deep_learning",,
"ChÃ o má»i ngÆ°á»i em lÃ  newbie áº¡
Em muá»‘n thá»­ 1 mÃ´ hÃ¬nh LLM káº¿t há»£p vá»›i RAG, Langchain thÃ¬ nÃªn thá»­ á»Ÿ Ä‘Ã¢u áº¡. Náº¿u thá»­ á»Ÿ local thÃ¬ mÃ¡y lag, cÃ²n thá»­ á»Ÿ gg colab thÃ¬ sau 1 time nÃ³ láº¡i reset, báº¯t mÃ¬nh cháº¡y láº¡i toÃ n bá»™ lá»‡nh","ChÃ o má»i ngÆ°á»i em lÃ  newbie áº¡ Em muá»‘n thá»­ 1 mÃ´ hÃ¬nh LLM káº¿t há»£p vá»›i RAG, Langchain thÃ¬ nÃªn thá»­ á»Ÿ Ä‘Ã¢u áº¡. Náº¿u thá»­ á»Ÿ local thÃ¬ mÃ¡y lag, cÃ²n thá»­ á»Ÿ gg colab thÃ¬ sau 1 time nÃ³ láº¡i reset, báº¯t mÃ¬nh cháº¡y láº¡i toÃ n bá»™ lá»‡nh",,,"#Q&A, #nlp",,
"Gá»­i cÃ¡c bÃ¡c, mÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» vá»›i thÆ° viá»‡n underthesea nhÆ° sau: 
Khi cháº¡y vá»›i Sublime thÃ¬ váº«n cháº¡y bÃ¬nh thÆ°á»ng
Khi xuáº¥t ra file exe vá»›i Pyinstaller thÃ¬ bÃ¡o lá»—i nhÆ° áº£nh, hiá»‡n táº¡i mÃ¬nh cÃ³ folder bÃ¡o thiáº¿u nhÆ° áº£nh dÆ°á»›i tuy nhiÃªn khÃ´ng biáº¿t bá»• sung vÃ o folder nÃ o, folder temp khi táº¯t chÆ°Æ¡ng trÃ¬nh thÃ¬ láº¡i máº¥t nÃªn khÃ´ng biáº¿t bá»• sung vÃ o folder nÃ o.
CÃ¡c bÃ¡c xem giÃºp em, em cáº£m Æ¡n cÃ¡c bÃ¡c","Gá»­i cÃ¡c bÃ¡c, mÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» vá»›i thÆ° viá»‡n underthesea nhÆ° sau: Khi cháº¡y vá»›i Sublime thÃ¬ váº«n cháº¡y bÃ¬nh thÆ°á»ng Khi xuáº¥t ra file exe vá»›i Pyinstaller thÃ¬ bÃ¡o lá»—i nhÆ° áº£nh, hiá»‡n táº¡i mÃ¬nh cÃ³ folder bÃ¡o thiáº¿u nhÆ° áº£nh dÆ°á»›i tuy nhiÃªn khÃ´ng biáº¿t bá»• sung vÃ o folder nÃ o, folder temp khi táº¯t chÆ°Æ¡ng trÃ¬nh thÃ¬ láº¡i máº¥t nÃªn khÃ´ng biáº¿t bá»• sung vÃ o folder nÃ o. CÃ¡c bÃ¡c xem giÃºp em, em cáº£m Æ¡n cÃ¡c bÃ¡c",,,"#Q&A, #python",,
"ChÃ o má»i ngÆ°á»i, em lÃ  newbie áº¡
Cho em há»i lÃ  muá»‘n lÃ m 1 con chatbot cÃ³ thá»ƒ tráº£ lá»i theo dá»¯ liá»‡u realtime thÃ¬ pháº£i tÃ¬m hiá»ƒu nhá»¯ng gÃ¬ áº¡, Ä‘áº·c biá»‡t lÃ  LLAMA2
Em cáº£m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i, em lÃ  newbie áº¡ Cho em há»i lÃ  muá»‘n lÃ m 1 con chatbot cÃ³ thá»ƒ tráº£ lá»i theo dá»¯ liá»‡u realtime thÃ¬ pháº£i tÃ¬m hiá»ƒu nhá»¯ng gÃ¬ áº¡, Ä‘áº·c biá»‡t lÃ  LLAMA2 Em cáº£m Æ¡n áº¡",,,"#Q&A, #nlp",,
"Em dÃ¢n non-tech xin phÃ©p Ä‘Æ°á»£c Ä‘Äƒng bÃ i xin Ã½ kiáº¿n anh chá»‹ áº¡
Em tháº¥y bá»™ VLMU Ä‘Æ°á»£c giá»›i thiá»‡u má»›i Ä‘Ã¢y cá»§a Zalo AI lÃ  báº£ng leader board cÃ³ thá»ƒ nÃ³i lÃ  báº£ng Ä‘áº§u tiÃªn á»Ÿ nÆ°á»›c mÃ¬nh, nháº¥t lÃ  vá» máº£ng xá»­ lÃ½ tiáº¿ng viá»‡t. á» gÃ³c Ä‘á»™ kinh táº¿, em cÃ³ thá»ƒ make-color cho sáº£n pháº©m cá»§a mÃ¬nh báº±ng rank nÃ y.
1. Tuy nhiÃªn Ä‘á»‘i vá»›i anh chá»‹, em ráº¥t muá»‘n biáº¿t gÃ³c nhÃ¬n ká»¹ thuáº­t thÃ¬ Ä‘á»‘i vá»›i anh chá»‹ rank VLMU cÃ³ lÃ m highlight sáº£n pháº©m mÃ¬nh Ä‘Æ°á»£c khÃ´ng?
2. Náº¿u publish thÃ¬ sáº½ release nhiá»u thÃ´ng tin, em muá»‘n trÆ°á»›c Ä‘Ã³ cÃ³ 1 bá»™ Ä‘Ã¡nh giÃ¡ thá»­ mÃ  chá»‰ riÃªng ná»™i bá»™ xem Ä‘Æ°á»£c, mÃ¬nh hiá»‡u chá»‰nh vÃ  gá»­i publish sau thÃ¬ cÃ³ Ä‘Æ°á»£c hay khÃ´ng?
3. Nhá»¯ng rule nÃ o quy Ä‘á»‹nh vá» viá»‡c Ä‘Æ°á»£c publish, khÃ´ng Ä‘Æ°á»£c publish.
Mong ace há»— trá»£ em áº¡","Em dÃ¢n non-tech xin phÃ©p Ä‘Æ°á»£c Ä‘Äƒng bÃ i xin Ã½ kiáº¿n anh chá»‹ áº¡ Em tháº¥y bá»™ VLMU Ä‘Æ°á»£c giá»›i thiá»‡u má»›i Ä‘Ã¢y cá»§a Zalo AI lÃ  báº£ng leader board cÃ³ thá»ƒ nÃ³i lÃ  báº£ng Ä‘áº§u tiÃªn á»Ÿ nÆ°á»›c mÃ¬nh, nháº¥t lÃ  vá» máº£ng xá»­ lÃ½ tiáº¿ng viá»‡t. á» gÃ³c Ä‘á»™ kinh táº¿, em cÃ³ thá»ƒ make-color cho sáº£n pháº©m cá»§a mÃ¬nh báº±ng rank nÃ y. 1. Tuy nhiÃªn Ä‘á»‘i vá»›i anh chá»‹, em ráº¥t muá»‘n biáº¿t gÃ³c nhÃ¬n ká»¹ thuáº­t thÃ¬ Ä‘á»‘i vá»›i anh chá»‹ rank VLMU cÃ³ lÃ m highlight sáº£n pháº©m mÃ¬nh Ä‘Æ°á»£c khÃ´ng? 2. Náº¿u publish thÃ¬ sáº½ release nhiá»u thÃ´ng tin, em muá»‘n trÆ°á»›c Ä‘Ã³ cÃ³ 1 bá»™ Ä‘Ã¡nh giÃ¡ thá»­ mÃ  chá»‰ riÃªng ná»™i bá»™ xem Ä‘Æ°á»£c, mÃ¬nh hiá»‡u chá»‰nh vÃ  gá»­i publish sau thÃ¬ cÃ³ Ä‘Æ°á»£c hay khÃ´ng? 3. Nhá»¯ng rule nÃ o quy Ä‘á»‹nh vá» viá»‡c Ä‘Æ°á»£c publish, khÃ´ng Ä‘Æ°á»£c publish. Mong ace há»— trá»£ em áº¡",,,#Q&A,,
ğŸ¯ OpenAi giá»›i thiá»‡u mÃ´ hÃ¬nh GPT-4 Turbo,OpenAi giá»›i thiá»‡u mÃ´ hÃ¬nh GPT-4 Turbo,,,#sharing,,
"ChÃ o má»i ngÆ°á»i áº¡.
NhÃ³m chÃºng em Ä‘ang lÃ m má»™t project vá» Há»i Ä‘Ã¡p tÃ i liá»‡u theo mÃ´ hÃ¬nh RAG sá»­ dá»¥ng LLM ChatGPT.
TÃ i liá»‡u cá»§a chÃºng em Ä‘ang viáº¿t á»Ÿ Tiáº¿ng Viá»‡t, Tiáº¿ng Anh vÃ  Tiáº¿ng Nháº­t. Em Ä‘ang muá»‘n tÃ¬m má»™t model encoder tá»‘i Æ°u Ä‘Æ°á»£c cho 3 thá»© tiáº¿ng trÃªn áº¡. Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ gá»£i Ã½ giÃºp em má»™t sá»‘ model vá»›i áº¡. Em cáº£m Æ¡n mn","ChÃ o má»i ngÆ°á»i áº¡. NhÃ³m chÃºng em Ä‘ang lÃ m má»™t project vá» Há»i Ä‘Ã¡p tÃ i liá»‡u theo mÃ´ hÃ¬nh RAG sá»­ dá»¥ng LLM ChatGPT. TÃ i liá»‡u cá»§a chÃºng em Ä‘ang viáº¿t á»Ÿ Tiáº¿ng Viá»‡t, Tiáº¿ng Anh vÃ  Tiáº¿ng Nháº­t. Em Ä‘ang muá»‘n tÃ¬m má»™t model encoder tá»‘i Æ°u Ä‘Æ°á»£c cho 3 thá»© tiáº¿ng trÃªn áº¡. Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ gá»£i Ã½ giÃºp em má»™t sá»‘ model vá»›i áº¡. Em cáº£m Æ¡n mn",,,"#Q&A, #nlp",,
"Xin chÃ o má»i ngÆ°á»i, em cÃ³ Ä‘ang tranh luáº­n vá»›i giáº£ng viÃªn vá» 2 viá»‡c nhÆ° sau, mong Ä‘Æ°á»£c má»i ngÆ°á»i gÃ³p Ã½.
1. Khi dáº¡y thuáº­t toÃ¡n NBC, cÃ´ em dáº¡y 2 dáº¡ng lÃ  NBC thÃ´ng thÆ°á»ng vÃ  NBC (cÃ´ táº¡m gá»i lÃ ) cáº£i tiá»ƒn.
- Vá»›i NBC thÃ´ng thÆ°á»ng thÃ¬ tÃ­nh theo cÃ´ng thá»©c Bayes má»Ÿ rá»™ng, tá»©c khÃ´ng coi cÃ¡c biáº¿n lÃ  Ä‘á»™c láº­p vá»›i nhau
- CÃ²n vá»›i NBC cáº£i tiáº¿n thÃ¬ má»›i coi cÃ¡c biáº¿n lÃ  Ä‘á»™c láº­p vá»›i nhau
Quan Ä‘iá»ƒm cá»§a em lÃ : chá»¯ NaÃ¯ve trong thuáº­t toÃ¡n NBC Ä‘Ã£ chá»‰ ra Ã½ tÆ°á»Ÿng ngÃ¢y thÆ¡ cá»§a bÃ i toÃ¡n lÃ  coi cÃ¡c biáº¿n Ä‘á»™c láº­p vá»›i nhau, chá»‰ tá»“n táº¡i cÃ¡i NBC mÃ  cÃ´ em Ä‘ang gá»i lÃ  NBC má»Ÿ rá»™ng.
2. CÃ´ em dáº¡y Maximum Likelihood vÃ  Maximum A Posteriori lÃ  thuáº­t toÃ¡n há»c mÃ¡y tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhÆ° ID3, Kmeans, kNN, SVM, Linear Regression. (CÃ´ Ä‘Æ°a ra báº±ng chá»©ng lÃ  trong giÃ¡o trÃ¬nh há»c mÃ¡y do tháº§y HoÃ ng XuÃ¢n Huáº¥n trÆ°á»ng Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i cÃ³ viáº¿t á»Ÿ má»¥c â€˜5.2.1 CÃ¡c quy táº¯c phÃ¢n lá»›p ML vÃ  MAPâ€™), mÃ  phÃ¢n lá»›p thÃ¬ lÃ  thuá»™c bÃ i toÃ¡n classify trong há»c mÃ¡y.
Em cho ráº±ng ML, MAP chá»‰ lÃ  phÆ°Æ¡ng thá»©c há»— trá»£ cho thuáº­t toÃ¡n há»c mÃ¡y, vÃ­ dá»¥ nhÆ° dÃ¹ng ML trong thuáº­t toÃ¡n logistic regression.
Note: Em sáº½ bá»• sung thÃªm má»™t sá»‘ dáº«n chá»©ng cho quan Ä‘iá»ƒm cá»§a cÃ´ vÃ  em dÆ°á»›i pháº§n bÃ¬nh luáº­n. VÃ¬ há»c khoa Ä‘iá»‡n tá»­, Ä‘áº¿n kÃ¬ nÃ y má»›i há»c pháº§n má»m nÃªn kiáº¿n thá»©c cá»§a em cÃ³ thá»ƒ sai sÃ³t nhiá»u. Xong em khÃ´ng thá»ƒ khiÃªn cÆ°á»¡ng lÃ m theo Ä‘iá»u mÃ¬nh tháº¥y khÃ´ng thuyáº¿t phá»¥c. Mong Ä‘Æ°á»£c má»i ngÆ°á»i khai thÃ´ng, náº¿u ai cÃ³ gmail cá»§a giáº£ng viÃªn dáº¡y mÃ´n nÃ y thÃ¬ cho em xin nhÃ© áº¡!","Xin chÃ o má»i ngÆ°á»i, em cÃ³ Ä‘ang tranh luáº­n vá»›i giáº£ng viÃªn vá» 2 viá»‡c nhÆ° sau, mong Ä‘Æ°á»£c má»i ngÆ°á»i gÃ³p Ã½. 1. Khi dáº¡y thuáº­t toÃ¡n NBC, cÃ´ em dáº¡y 2 dáº¡ng lÃ  NBC thÃ´ng thÆ°á»ng vÃ  NBC (cÃ´ táº¡m gá»i lÃ ) cáº£i tiá»ƒn. - Vá»›i NBC thÃ´ng thÆ°á»ng thÃ¬ tÃ­nh theo cÃ´ng thá»©c Bayes má»Ÿ rá»™ng, tá»©c khÃ´ng coi cÃ¡c biáº¿n lÃ  Ä‘á»™c láº­p vá»›i nhau - CÃ²n vá»›i NBC cáº£i tiáº¿n thÃ¬ má»›i coi cÃ¡c biáº¿n lÃ  Ä‘á»™c láº­p vá»›i nhau Quan Ä‘iá»ƒm cá»§a em lÃ : chá»¯ NaÃ¯ve trong thuáº­t toÃ¡n NBC Ä‘Ã£ chá»‰ ra Ã½ tÆ°á»Ÿng ngÃ¢y thÆ¡ cá»§a bÃ i toÃ¡n lÃ  coi cÃ¡c biáº¿n Ä‘á»™c láº­p vá»›i nhau, chá»‰ tá»“n táº¡i cÃ¡i NBC mÃ  cÃ´ em Ä‘ang gá»i lÃ  NBC má»Ÿ rá»™ng. 2. CÃ´ em dáº¡y Maximum Likelihood vÃ  Maximum A Posteriori lÃ  thuáº­t toÃ¡n há»c mÃ¡y tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhÆ° ID3, Kmeans, kNN, SVM, Linear Regression. (CÃ´ Ä‘Æ°a ra báº±ng chá»©ng lÃ  trong giÃ¡o trÃ¬nh há»c mÃ¡y do tháº§y HoÃ ng XuÃ¢n Huáº¥n trÆ°á»ng Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i cÃ³ viáº¿t á»Ÿ má»¥c â€˜5.2.1 CÃ¡c quy táº¯c phÃ¢n lá»›p ML vÃ  MAPâ€™), mÃ  phÃ¢n lá»›p thÃ¬ lÃ  thuá»™c bÃ i toÃ¡n classify trong há»c mÃ¡y. Em cho ráº±ng ML, MAP chá»‰ lÃ  phÆ°Æ¡ng thá»©c há»— trá»£ cho thuáº­t toÃ¡n há»c mÃ¡y, vÃ­ dá»¥ nhÆ° dÃ¹ng ML trong thuáº­t toÃ¡n logistic regression. Note: Em sáº½ bá»• sung thÃªm má»™t sá»‘ dáº«n chá»©ng cho quan Ä‘iá»ƒm cá»§a cÃ´ vÃ  em dÆ°á»›i pháº§n bÃ¬nh luáº­n. VÃ¬ há»c khoa Ä‘iá»‡n tá»­, Ä‘áº¿n kÃ¬ nÃ y má»›i há»c pháº§n má»m nÃªn kiáº¿n thá»©c cá»§a em cÃ³ thá»ƒ sai sÃ³t nhiá»u. Xong em khÃ´ng thá»ƒ khiÃªn cÆ°á»¡ng lÃ m theo Ä‘iá»u mÃ¬nh tháº¥y khÃ´ng thuyáº¿t phá»¥c. Mong Ä‘Æ°á»£c má»i ngÆ°á»i khai thÃ´ng, náº¿u ai cÃ³ gmail cá»§a giáº£ng viÃªn dáº¡y mÃ´n nÃ y thÃ¬ cho em xin nhÃ© áº¡!",,,"#Q&A, #machine_learning, #math",,
Mn Ä‘Ã£ ai convert model detectron2 sang onnx chÆ°a áº¡,Mn Ä‘Ã£ ai convert model detectron2 sang onnx chÆ°a áº¡,,,"#Q&A, #cv",,
"ChÃ o má»i ngÆ°á»i . TÃ¬nh hÃ¬nh lÃ  em cÃ³ má»™t Ä‘á» tÃ i Ä‘ang lÃ m vá»›i má»¥c Ä‘Ã­ch lÃ  phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n Ä‘á»ƒ chuyá»ƒn Ä‘á»•i tÃ­n hiá»‡u nhá»‹p sinh há»c cá»§a cÆ¡ thá»ƒ tá»« cáº£m biáº¿n Ã¡p suáº¥t Ä‘iá»‡n thÃ nh sÃ³ng máº¡ch mÃ¡u. CÃ¡c phÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n truyá»n thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c thá»­ nghiá»‡m nhÆ°ng chÆ°a Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c mong muá»‘n. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, nghiÃªn cá»©u yÃªu cáº§u viá»‡c pháº£i Ä‘o Ä‘áº¡c cÃ¹ng lÃºc dá»¯ liá»‡u giÃ¡o viÃªn vÃ  dá»¯ liá»‡u tá»« cáº£m biáº¿n Ã¡p suáº¥t Ä‘iá»‡n. Trong nÄƒm nay, em Ä‘Ã£ táº¡o má»™t thiáº¿t bá»‹ Ä‘o má»›i Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ giáº£m sai sá»‘ vÃ  tá»« Ä‘Ã³ phÃ¡t triá»ƒn mÃ´ hÃ¬nh tÃ­nh toÃ¡n chÃ­nh xÃ¡c hÆ¡n.
- Anh chá»‹ cho em gá»£i Ã½ vá» cÃ¡ch xÃ¢y dá»¥ng mÃ´ hÃ¬nh tÃ­nh toÃ¡n chÃ­nh xÃ¡c hÆ¡n Ä‘Æ°á»£c khÃ´ng . cÃ³ thá»ƒ gá»£i Ã½ cho em nguá»“n vÃ i tÃ i liá»‡u Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm vá» mÃ´ hÃ¬nh thÃ­ch há»£p Ä‘Æ°á»£c khÃ´ng áº¡ .
- MÃ¬nh sá»­ dá»¥ng mÃ´ hÃ¬nh ML Ä‘á»ƒ giáº£i quyáº¿t .
- VÃ¬ má»¥c Ä‘Ã­ch lÃ  lÃ m cho data thu Ä‘Æ°á»£c tá»« cáº£m biáº¿n Ã¡p suáº¥t Ä‘iá»‡n káº¿t há»£p vá»›i data vá» nhá»‹p sinh há»c máº©u Ä‘á»ƒ táº¡o ra chuá»—i data thá»i gian má»›i cÃ³ tÃ­nh cháº¥t gáº§n giá»‘ng vá»›i nhá»‹p sinh há»c thá»±c táº¿
- MÃ¬nh cÃ³ biáº¿t vá» ML , nhÆ°ng vá»›i mÃ¬nh chÆ°a Ä‘á»§ Ä‘á»ƒ hiá»ƒu rÃµ váº¥n Ä‘á» cáº§n giáº£i quyáº¿t .
- LÃºc Ä‘áº§u mÃ¬nh sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p ML nhÆ° máº¡ng neural networks vÃ  mÃ´ hÃ¬nh hidden markov Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n time-series generation nhÆ°ng káº¿t quáº£ khÃ´ng Ä‘áº¹p nhÆ° mÃ¬nh nghÄ© .","ChÃ o má»i ngÆ°á»i . TÃ¬nh hÃ¬nh lÃ  em cÃ³ má»™t Ä‘á» tÃ i Ä‘ang lÃ m vá»›i má»¥c Ä‘Ã­ch lÃ  phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n Ä‘á»ƒ chuyá»ƒn Ä‘á»•i tÃ­n hiá»‡u nhá»‹p sinh há»c cá»§a cÆ¡ thá»ƒ tá»« cáº£m biáº¿n Ã¡p suáº¥t Ä‘iá»‡n thÃ nh sÃ³ng máº¡ch mÃ¡u. CÃ¡c phÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n truyá»n thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c thá»­ nghiá»‡m nhÆ°ng chÆ°a Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c mong muá»‘n. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, nghiÃªn cá»©u yÃªu cáº§u viá»‡c pháº£i Ä‘o Ä‘áº¡c cÃ¹ng lÃºc dá»¯ liá»‡u giÃ¡o viÃªn vÃ  dá»¯ liá»‡u tá»« cáº£m biáº¿n Ã¡p suáº¥t Ä‘iá»‡n. Trong nÄƒm nay, em Ä‘Ã£ táº¡o má»™t thiáº¿t bá»‹ Ä‘o má»›i Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ giáº£m sai sá»‘ vÃ  tá»« Ä‘Ã³ phÃ¡t triá»ƒn mÃ´ hÃ¬nh tÃ­nh toÃ¡n chÃ­nh xÃ¡c hÆ¡n. - Anh chá»‹ cho em gá»£i Ã½ vá» cÃ¡ch xÃ¢y dá»¥ng mÃ´ hÃ¬nh tÃ­nh toÃ¡n chÃ­nh xÃ¡c hÆ¡n Ä‘Æ°á»£c khÃ´ng . cÃ³ thá»ƒ gá»£i Ã½ cho em nguá»“n vÃ i tÃ i liá»‡u Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm vá» mÃ´ hÃ¬nh thÃ­ch há»£p Ä‘Æ°á»£c khÃ´ng áº¡ . - MÃ¬nh sá»­ dá»¥ng mÃ´ hÃ¬nh ML Ä‘á»ƒ giáº£i quyáº¿t . - VÃ¬ má»¥c Ä‘Ã­ch lÃ  lÃ m cho data thu Ä‘Æ°á»£c tá»« cáº£m biáº¿n Ã¡p suáº¥t Ä‘iá»‡n káº¿t há»£p vá»›i data vá» nhá»‹p sinh há»c máº©u Ä‘á»ƒ táº¡o ra chuá»—i data thá»i gian má»›i cÃ³ tÃ­nh cháº¥t gáº§n giá»‘ng vá»›i nhá»‹p sinh há»c thá»±c táº¿ - MÃ¬nh cÃ³ biáº¿t vá» ML , nhÆ°ng vá»›i mÃ¬nh chÆ°a Ä‘á»§ Ä‘á»ƒ hiá»ƒu rÃµ váº¥n Ä‘á» cáº§n giáº£i quyáº¿t . - LÃºc Ä‘áº§u mÃ¬nh sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p ML nhÆ° máº¡ng neural networks vÃ  mÃ´ hÃ¬nh hidden markov Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n time-series generation nhÆ°ng káº¿t quáº£ khÃ´ng Ä‘áº¹p nhÆ° mÃ¬nh nghÄ© .",,,"#Q&A, #deep_learning",,
"Há»i cÃ¡ch láº¥y data (áº£nh,...) tá»« vá»‡ tinh. Cáº§n gÃ³p Ã½ vá» viá»‡c download dá»¯ liá»‡u tá»« cÃ¡c vá»‡ tinh.
Äá»£t vá»«a rá»“i, mÃ¬nh cÃ³ thá»­ download dá»¯ liá»‡u vá»‡ tinh Sentinel-2, cá»¥ thá»ƒ lÃ  multispectrum data. NhÆ°ng mÃ¬nh váº«n chÆ°a down Ä‘Æ°á»£c.
CÃ³ báº¡n nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m lÃ m viá»‡c vá»›i áº£nh vá»‡ tinh cÃ³ thá»ƒ chia sáº½ cÃ¡ch cÃ¡c báº¡n down vÃ  vÃ i chia sáº½ vá» viá»‡c xá»­ lÃ½ áº£nh kÃ­ch thÆ°á»›c lá»›n nhÆ° áº£nh vá»‡ tinh khÃ´ng áº¡?
CÃ¡m Æ¡n.","Há»i cÃ¡ch láº¥y data (áº£nh,...) tá»« vá»‡ tinh. Cáº§n gÃ³p Ã½ vá» viá»‡c download dá»¯ liá»‡u tá»« cÃ¡c vá»‡ tinh. Äá»£t vá»«a rá»“i, mÃ¬nh cÃ³ thá»­ download dá»¯ liá»‡u vá»‡ tinh Sentinel-2, cá»¥ thá»ƒ lÃ  multispectrum data. NhÆ°ng mÃ¬nh váº«n chÆ°a down Ä‘Æ°á»£c. CÃ³ báº¡n nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m lÃ m viá»‡c vá»›i áº£nh vá»‡ tinh cÃ³ thá»ƒ chia sáº½ cÃ¡ch cÃ¡c báº¡n down vÃ  vÃ i chia sáº½ vá» viá»‡c xá»­ lÃ½ áº£nh kÃ­ch thÆ°á»›c lá»›n nhÆ° áº£nh vá»‡ tinh khÃ´ng áº¡? CÃ¡m Æ¡n.",,,"#Q&A, #data",,
"Cá»±c Ä‘áº¡i cá»§a the log posterior
ChÃ o má»i ngÆ°á»i, em Ä‘ang vÆ°á»›ng 1 chá»• mÃ  suy nghÄ© mÃ£i khÃ´ng ra. LÃ m cÃ¡ch nÃ o Ä‘á»ƒ khai triá»ƒn cÃ´ng thá»©c bÃªn dÆ°á»›i nhá»‰ (2 mÅ©i tÃªn mÃ u Ä‘á» trÃªn hÃ¬nh).","Cá»±c Ä‘áº¡i cá»§a the log posterior ChÃ o má»i ngÆ°á»i, em Ä‘ang vÆ°á»›ng 1 chá»• mÃ  suy nghÄ© mÃ£i khÃ´ng ra. LÃ m cÃ¡ch nÃ o Ä‘á»ƒ khai triá»ƒn cÃ´ng thá»©c bÃªn dÆ°á»›i nhá»‰ (2 mÅ©i tÃªn mÃ u Ä‘á» trÃªn hÃ¬nh).",,,"#Q&A, #math",,
"Hi all ! 
CÃ³ báº¡n  nÃ o Ä‘ang há»c nÄƒm cuá»‘i kÄ© sÆ° hay master vá» computer vision hay graphic hoáº·c ngÃ nh liÃªn quan. CÃ³ mong muá»‘n há»c tiáº¿p (PhD) vÃ   báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘i thá»±c táº­p táº¡i PhÃ¡p vÃ  Ãšc khÃ´ng ? Náº¿u cÃ³ hÃ£y liÃªn láº¡c vá»›i mÃ¬nh ASAP nhÃ© !
https://crossing.cnrs.fr/crossing-internships-2023-24/",Hi all ! CÃ³ báº¡n nÃ o Ä‘ang há»c nÄƒm cuá»‘i kÄ© sÆ° hay master vá» computer vision hay graphic hoáº·c ngÃ nh liÃªn quan. CÃ³ mong muá»‘n há»c tiáº¿p (PhD) vÃ  báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘i thá»±c táº­p táº¡i PhÃ¡p vÃ  Ãšc khÃ´ng ? Náº¿u cÃ³ hÃ£y liÃªn láº¡c vá»›i mÃ¬nh ASAP nhÃ© ! https://crossing.cnrs.fr/crossing-internships-2023-24/,,,#Q&A,,
"WEBINAR CHá»¦ Äá»€  ""á»¨NG Dá»¤NG PHÃ‚N TÃCH Äá»ŠNH LÆ¯á»¢NG CHO TRADING"" CÃC TÆ¯ DUY TRONG XÃ‚Y Dá»°NG VÃ€ KIá»‚M THá»¬ CHIáº¾N THUáº¬T Äáº¦U TÆ¯ Tá»° Äá»˜NG.
ğŸ“ŒICLS Tech kÃ­nh má»i cá»™ng Ä‘á»“ng Trading, nhá»¯ng ngÆ°á»i yÃªu thÃ­ch vÃ  quan tÃ¢m Ä‘áº¿n Trading Ä‘Äƒng kÃ½ tham gia buá»•i chia sáº» vá» ""á»¨ng dá»¥ng phÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng cho Trading""
â±Thá»i gian báº¯t Ä‘áº§u: 20h00, thá»© Ba, ngÃ y 21/11/2023
ğŸ‘‰HÃ¬nh thá»©c tham dá»±: tham dá»± qua Zoom báº±ng Ä‘Æ°á»ng link https://me-qr.com/w8ofedQx hoáº·c quÃ©t mÃ£ QR trong hÃ¬nh.
ğŸ‘¨â€ğŸ’¼PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng trong Ä‘áº§u tÆ° - Quantitative Trading lÃ  má»™t phÆ°Æ¡ng phÃ¡p lÆ°á»£ng hÃ³a cÃ¡c thÃ´ng tin thÃ nh sá»‘ liá»‡u cá»¥ thá»ƒ, giÃºp nhÃ  Ä‘áº§u tÆ° loáº¡i bá» Ä‘Æ°á»£c yáº¿u tá»‘ cáº£m xÃºc trÆ°á»›c khi ra quyáº¿t Ä‘á»‹nh. Dá»±a trÃªn cÃ¡c cÃ´ng thá»©c, mÃ´ hÃ¬nh toÃ¡n há»c vÃ  cÃ¡c cÃ´ng cá»¥ trÃ­ tuá»‡ nhÃ¢n táº¡o. GiÃºp cáº£i thiá»‡n káº¿t quáº£ Ä‘Ã¡ng ká»ƒ cho nhÃ  Ä‘áº§u tÆ°
---------------
ğŸ‘¥Vá»›i sá»± chia sáº» cá»§a 2 vá»‹ khÃ¡ch má»i:
ğŸ”¹Anh Nguyá»…n VÄƒn ThÃ nh:
- Research Consultant táº¡i Táº­p Ä‘oÃ n TÃ i ChÃ­nh Ä‘á»‹nh lÆ°á»£ng WorldQuant
- Tá»«ng lÃ m Software Engineer táº¡i SamSung R&D
- HÆ¡n 2 nÄƒm kinh nghiá»‡m lÃ m viá»‡c trong lÄ©nh vá»±c khoa há»c dá»¯ liá»‡u, xá»­ lÃ½ dá»¯ liá»‡u tÃ i chÃ­nh, crypto currency.
ğŸ”¹Anh NgÃ´ Phi HÃ¹ng:
- Tech Lead táº¡i Hephatus Technology
- Tá»«ng lÃ m Data Engineer táº¡i FPT Telecom
---------------
HÃ£y tham gia ngay Ä‘á»ƒ tiáº¿p cáº­n vÃ  há»c há»i vá» má»™t phÆ°Æ¡ng phÃ¡p Ä‘áº§u tÆ° hiá»‡u quáº£. CÃ³ cÆ¡ há»™i Ä‘Æ°á»£c tham gia vÃ o cá»™ng Ä‘á»“ng ICLS Tech Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ vÃ  tÆ° váº¥n tá»« cÃ¡c chuyÃªn giağŸ¥°
Contact
â˜ï¸0962038175
âœ‰ï¸contact@icls-tech.com
#Quantitative #Trading #QuantitativeTrading #Webinar","WEBINAR CHá»¦ Äá»€ ""á»¨NG Dá»¤NG PHÃ‚N TÃCH Äá»ŠNH LÆ¯á»¢NG CHO TRADING"" CÃC TÆ¯ DUY TRONG XÃ‚Y Dá»°NG VÃ€ KIá»‚M THá»¬ CHIáº¾N THUáº¬T Äáº¦U TÆ¯ Tá»° Äá»˜NG. ICLS Tech kÃ­nh má»i cá»™ng Ä‘á»“ng Trading, nhá»¯ng ngÆ°á»i yÃªu thÃ­ch vÃ  quan tÃ¢m Ä‘áº¿n Trading Ä‘Äƒng kÃ½ tham gia buá»•i chia sáº» vá» ""á»¨ng dá»¥ng phÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng cho Trading"" â±Thá»i gian báº¯t Ä‘áº§u: 20h00, thá»© Ba, ngÃ y 21/11/2023 HÃ¬nh thá»©c tham dá»±: tham dá»± qua Zoom báº±ng Ä‘Æ°á»ng link https://me-qr.com/w8ofedQx hoáº·c quÃ©t mÃ£ QR trong hÃ¬nh. PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng trong Ä‘áº§u tÆ° - Quantitative Trading lÃ  má»™t phÆ°Æ¡ng phÃ¡p lÆ°á»£ng hÃ³a cÃ¡c thÃ´ng tin thÃ nh sá»‘ liá»‡u cá»¥ thá»ƒ, giÃºp nhÃ  Ä‘áº§u tÆ° loáº¡i bá» Ä‘Æ°á»£c yáº¿u tá»‘ cáº£m xÃºc trÆ°á»›c khi ra quyáº¿t Ä‘á»‹nh. Dá»±a trÃªn cÃ¡c cÃ´ng thá»©c, mÃ´ hÃ¬nh toÃ¡n há»c vÃ  cÃ¡c cÃ´ng cá»¥ trÃ­ tuá»‡ nhÃ¢n táº¡o. GiÃºp cáº£i thiá»‡n káº¿t quáº£ Ä‘Ã¡ng ká»ƒ cho nhÃ  Ä‘áº§u tÆ° --------------- Vá»›i sá»± chia sáº» cá»§a 2 vá»‹ khÃ¡ch má»i: Anh Nguyá»…n VÄƒn ThÃ nh: - Research Consultant táº¡i Táº­p Ä‘oÃ n TÃ i ChÃ­nh Ä‘á»‹nh lÆ°á»£ng WorldQuant - Tá»«ng lÃ m Software Engineer táº¡i SamSung R&D - HÆ¡n 2 nÄƒm kinh nghiá»‡m lÃ m viá»‡c trong lÄ©nh vá»±c khoa há»c dá»¯ liá»‡u, xá»­ lÃ½ dá»¯ liá»‡u tÃ i chÃ­nh, crypto currency. Anh NgÃ´ Phi HÃ¹ng: - Tech Lead táº¡i Hephatus Technology - Tá»«ng lÃ m Data Engineer táº¡i FPT Telecom --------------- HÃ£y tham gia ngay Ä‘á»ƒ tiáº¿p cáº­n vÃ  há»c há»i vá» má»™t phÆ°Æ¡ng phÃ¡p Ä‘áº§u tÆ° hiá»‡u quáº£. CÃ³ cÆ¡ há»™i Ä‘Æ°á»£c tham gia vÃ o cá»™ng Ä‘á»“ng ICLS Tech Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ vÃ  tÆ° váº¥n tá»« cÃ¡c chuyÃªn gia Contact 0962038175 contact@icls-tech.com",#Quantitative	#Trading	#QuantitativeTrading	#Webinar,,#webinar,,
"MÃ¬nh Ä‘ang lead má»™t sá»‘ dá»± Ã¡n tá»± Ä‘á»™ng hoÃ¡ á»©ng dá»¥ng AI/ML trong thiáº¿t káº¿, triá»ƒn khai vÃ  tá»‘i Æ°u há»‡ thá»‘ng máº¡ng di Ä‘á»™ng 5G (há»£p tÃ¡c vá»›i nhÃ  máº¡ng lá»›n tg).
CÃ¡c báº¡n quan tÃ¢m tá»›i lÄ©nh vá»±c AI/ML trong viá»…n thÃ´ng cÃ³ thá»ƒ káº¿t ná»‘i, giao lÆ°u vÃ  tham gia dá»± Ã¡n bÃªn mÃ¬nh (partime hay fulltime Ä‘á»u OK).
(áº¢nh cÃ³ tÃ­nh minh há»a tá»± Ä‘á»™ng dá»± bÃ¡o lÆ°u lÆ°á»£ng vÃ  tá»‘i Æ°u 1 tráº¡m 5G toÃ n thá»i gian)","MÃ¬nh Ä‘ang lead má»™t sá»‘ dá»± Ã¡n tá»± Ä‘á»™ng hoÃ¡ á»©ng dá»¥ng AI/ML trong thiáº¿t káº¿, triá»ƒn khai vÃ  tá»‘i Æ°u há»‡ thá»‘ng máº¡ng di Ä‘á»™ng 5G (há»£p tÃ¡c vá»›i nhÃ  máº¡ng lá»›n tg). CÃ¡c báº¡n quan tÃ¢m tá»›i lÄ©nh vá»±c AI/ML trong viá»…n thÃ´ng cÃ³ thá»ƒ káº¿t ná»‘i, giao lÆ°u vÃ  tham gia dá»± Ã¡n bÃªn mÃ¬nh (partime hay fulltime Ä‘á»u OK). (áº¢nh cÃ³ tÃ­nh minh há»a tá»± Ä‘á»™ng dá»± bÃ¡o lÆ°u lÆ°á»£ng vÃ  tá»‘i Æ°u 1 tráº¡m 5G toÃ n thá»i gian)",,,#Q&A,,
"Denoise diffusion probabilistic models
ThetaLog - Nháº­t kÃ½ Theta",Denoise diffusion probabilistic models ThetaLog - Nháº­t kÃ½ Theta,,,#sharing,,
"WEBINAR CHá»¦ Äá»€  ""á»¨NG Dá»¤NG PHÃ‚N TÃCH Äá»ŠNH LÆ¯á»¢NG CHO TRADING"" CÃC TÆ¯ DUY TRONG XÃ‚Y Dá»°NG VÃ€ KIá»‚M THá»¬ CHIáº¾N THUáº¬T Äáº¦U TÆ¯ Tá»° Äá»˜NG.
ğŸ“ŒICLS Tech kÃ­nh má»i cá»™ng Ä‘á»“ng Trading, nhá»¯ng ngÆ°á»i yÃªu thÃ­ch vÃ  quan tÃ¢m Ä‘áº¿n Trading Ä‘Äƒng kÃ½ tham gia buá»•i chia sáº» vá» ""á»¨ng dá»¥ng phÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng cho Trading""
â±Thá»i gian báº¯t Ä‘áº§u: 20h00, thá»© Ba, ngÃ y 21/11/2023
ğŸ‘‰HÃ¬nh thá»©c tham dá»±: tham dá»± qua Zoom báº±ng Ä‘Æ°á»ng link https://me-qr.com/w8ofedQx hoáº·c quÃ©t mÃ£ QR trong hÃ¬nh.
ğŸ‘¨â€ğŸ’¼PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng trong Ä‘áº§u tÆ° - Quantitative Trading lÃ  má»™t phÆ°Æ¡ng phÃ¡p lÆ°á»£ng hÃ³a cÃ¡c thÃ´ng tin thÃ nh sá»‘ liá»‡u cá»¥ thá»ƒ, giÃºp nhÃ  Ä‘áº§u tÆ° loáº¡i bá» Ä‘Æ°á»£c yáº¿u tá»‘ cáº£m xÃºc trÆ°á»›c khi ra quyáº¿t Ä‘á»‹nh. Dá»±a trÃªn cÃ¡c cÃ´ng thá»©c, mÃ´ hÃ¬nh toÃ¡n há»c vÃ  cÃ¡c cÃ´ng cá»¥ trÃ­ tuá»‡ nhÃ¢n táº¡o. GiÃºp cáº£i thiá»‡n káº¿t quáº£ Ä‘Ã¡ng ká»ƒ cho nhÃ  Ä‘áº§u tÆ°
---------------
ğŸ‘¥Vá»›i sá»± chia sáº» cá»§a 2 vá»‹ khÃ¡ch má»i:
ğŸ”¹Anh Nguyá»…n VÄƒn ThÃ nh:
- Research Consultant táº¡i Táº­p Ä‘oÃ n TÃ i ChÃ­nh Ä‘á»‹nh lÆ°á»£ng WorldQuant
- Tá»«ng lÃ m Software Engineer táº¡i SamSung R&D
- HÆ¡n 2 nÄƒm kinh nghiá»‡m lÃ m viá»‡c trong lÄ©nh vá»±c khoa há»c dá»¯ liá»‡u, xá»­ lÃ½ dá»¯ liá»‡u tÃ i chÃ­nh, crypto currency.
ğŸ”¹Anh NgÃ´ Phi HÃ¹ng:
- Tech Lead táº¡i Hephatus Technology
- Tá»«ng lÃ m Data Engineer táº¡i FPT Telecom
---------------
HÃ£y tham gia ngay Ä‘á»ƒ tiáº¿p cáº­n vÃ  há»c há»i vá» má»™t phÆ°Æ¡ng phÃ¡p Ä‘áº§u tÆ° hiá»‡u quáº£. CÃ³ cÆ¡ há»™i Ä‘Æ°á»£c tham gia vÃ o cá»™ng Ä‘á»“ng ICLS Tech Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ vÃ  tÆ° váº¥n tá»« cÃ¡c chuyÃªn giağŸ¥°
Contact
â˜ï¸0962038175
âœ‰ï¸contact@icls-tech.com
#Quantitative #Trading #QuantitativeTrading #Webinar","WEBINAR CHá»¦ Äá»€ ""á»¨NG Dá»¤NG PHÃ‚N TÃCH Äá»ŠNH LÆ¯á»¢NG CHO TRADING"" CÃC TÆ¯ DUY TRONG XÃ‚Y Dá»°NG VÃ€ KIá»‚M THá»¬ CHIáº¾N THUáº¬T Äáº¦U TÆ¯ Tá»° Äá»˜NG. ICLS Tech kÃ­nh má»i cá»™ng Ä‘á»“ng Trading, nhá»¯ng ngÆ°á»i yÃªu thÃ­ch vÃ  quan tÃ¢m Ä‘áº¿n Trading Ä‘Äƒng kÃ½ tham gia buá»•i chia sáº» vá» ""á»¨ng dá»¥ng phÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng cho Trading"" â±Thá»i gian báº¯t Ä‘áº§u: 20h00, thá»© Ba, ngÃ y 21/11/2023 HÃ¬nh thá»©c tham dá»±: tham dá»± qua Zoom báº±ng Ä‘Æ°á»ng link https://me-qr.com/w8ofedQx hoáº·c quÃ©t mÃ£ QR trong hÃ¬nh. PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng trong Ä‘áº§u tÆ° - Quantitative Trading lÃ  má»™t phÆ°Æ¡ng phÃ¡p lÆ°á»£ng hÃ³a cÃ¡c thÃ´ng tin thÃ nh sá»‘ liá»‡u cá»¥ thá»ƒ, giÃºp nhÃ  Ä‘áº§u tÆ° loáº¡i bá» Ä‘Æ°á»£c yáº¿u tá»‘ cáº£m xÃºc trÆ°á»›c khi ra quyáº¿t Ä‘á»‹nh. Dá»±a trÃªn cÃ¡c cÃ´ng thá»©c, mÃ´ hÃ¬nh toÃ¡n há»c vÃ  cÃ¡c cÃ´ng cá»¥ trÃ­ tuá»‡ nhÃ¢n táº¡o. GiÃºp cáº£i thiá»‡n káº¿t quáº£ Ä‘Ã¡ng ká»ƒ cho nhÃ  Ä‘áº§u tÆ° --------------- Vá»›i sá»± chia sáº» cá»§a 2 vá»‹ khÃ¡ch má»i: Anh Nguyá»…n VÄƒn ThÃ nh: - Research Consultant táº¡i Táº­p Ä‘oÃ n TÃ i ChÃ­nh Ä‘á»‹nh lÆ°á»£ng WorldQuant - Tá»«ng lÃ m Software Engineer táº¡i SamSung R&D - HÆ¡n 2 nÄƒm kinh nghiá»‡m lÃ m viá»‡c trong lÄ©nh vá»±c khoa há»c dá»¯ liá»‡u, xá»­ lÃ½ dá»¯ liá»‡u tÃ i chÃ­nh, crypto currency. Anh NgÃ´ Phi HÃ¹ng: - Tech Lead táº¡i Hephatus Technology - Tá»«ng lÃ m Data Engineer táº¡i FPT Telecom --------------- HÃ£y tham gia ngay Ä‘á»ƒ tiáº¿p cáº­n vÃ  há»c há»i vá» má»™t phÆ°Æ¡ng phÃ¡p Ä‘áº§u tÆ° hiá»‡u quáº£. CÃ³ cÆ¡ há»™i Ä‘Æ°á»£c tham gia vÃ o cá»™ng Ä‘á»“ng ICLS Tech Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ vÃ  tÆ° váº¥n tá»« cÃ¡c chuyÃªn gia Contact 0962038175 contact@icls-tech.com",#Quantitative	#Trading	#QuantitativeTrading	#Webinar,,#webinar,,
"Tá»« 1 bá»©c áº£nh nhiá»…u cÃ³ thá»ƒ táº¡o nÃªn 1 bá»©c áº£nh cháº¥t lÆ°á»£ng cao cáº¥p nhá» cÃ´ng nghá»‡ InstaFlow? ğŸ«¢ 

Má»i má»i ngÆ°á»i cÃ¹ng tÃ¬m hiá»ƒu thÃªm vá» mÃ´ hÃ¬nh ""ma thuáº­t"" Ä‘Æ°á»£c phÃ¡t triá»ƒn tá»« Stable Diffusion nÃ y táº¡i bÃ i viáº¿t bá»Ÿi Data Scientist cá»§a PIXTA Vietnam nhÃ©! 
#AI #MachineLearning #Instaflow","Tá»« 1 bá»©c áº£nh nhiá»…u cÃ³ thá»ƒ táº¡o nÃªn 1 bá»©c áº£nh cháº¥t lÆ°á»£ng cao cáº¥p nhá» cÃ´ng nghá»‡ InstaFlow? Má»i má»i ngÆ°á»i cÃ¹ng tÃ¬m hiá»ƒu thÃªm vá» mÃ´ hÃ¬nh ""ma thuáº­t"" Ä‘Æ°á»£c phÃ¡t triá»ƒn tá»« Stable Diffusion nÃ y táº¡i bÃ i viáº¿t bá»Ÿi Data Scientist cá»§a PIXTA Vietnam nhÃ©!",#AI	#MachineLearning	#Instaflow,,"#sharing, #cv",,
"CÃ³ má»™t báº¡n hÃ´m trÆ°á»›c DM mÃ¬nh há»i vá» hai cuá»‘n Thá»±c hÃ nh Há»c mÃ¡y, nay mÃ¬nh tÃ¬m láº¡i khÃ´ng tháº¥y tin nháº¯n nÃªn post láº¡i lÃªn group:
http://handson-ml.mlbvn.org/?fbclid=IwAR1v-g8ihHP6LwYOGnWyvdOdcYbY91BZM9EW0Ig11HSMMKpBh4jjikWPZzc","CÃ³ má»™t báº¡n hÃ´m trÆ°á»›c DM mÃ¬nh há»i vá» hai cuá»‘n Thá»±c hÃ nh Há»c mÃ¡y, nay mÃ¬nh tÃ¬m láº¡i khÃ´ng tháº¥y tin nháº¯n nÃªn post láº¡i lÃªn group: http://handson-ml.mlbvn.org/?fbclid=IwAR1v-g8ihHP6LwYOGnWyvdOdcYbY91BZM9EW0Ig11HSMMKpBh4jjikWPZzc",,,"#sharing, #machine_learning",,
"ChÃ o má»i ngÆ°á»i.
Qua bÃ i post nÃ y mÃ¬nh muá»‘n tÃ¬m ngÆ°á»i Ä‘á»ƒ cÃ¹ng nhau há»c vá» AI/Data. MÃ¬nh cÃ³ thá»ƒ cÃ¹ng nhau tháº£o luáº­n vá» má»™t chá»§ Ä‘á» nÃ o Ä‘áº¥y trong lÄ©nh vá»±c nÃ y. CÅ©ng cÃ³ thá»ƒ náº¿u ngÆ°á»i nÃ y vá»«a há»c Ä‘Æ°á»£c cÃ¡i gÃ¬ má»›i thÃ¬ cÃ³ thá»ƒ giáº£ng giáº£i cho ngÆ°á»i kia. NgÆ°á»i ta nÃ³i ráº±ng: báº¡n chá»‰ tháº­t sá»± hiá»ƒu má»™t váº¥n Ä‘á», khi mÃ  báº¡n cÃ³ thá»ƒ giáº£i thÃ­ch cho ngÆ°á»i khÃ¡c cÃ¹ng hiá»ƒu vá» váº¥n Ä‘á» Ä‘Ã³. CÃ¡c chá»§ Ä‘á» nÃ y cÅ©ng cÃ³ thá»ƒ chá»‰ lÃ  nhá»¯ng váº¥n Ä‘á» cÆ¡ báº£n cá»§a AI/Data thÃ´i.
Má»™t Ä‘iá»u quan trá»ng lÃ  mÃ¬nh muá»‘n cÃ¡c buá»•i tháº£o luáº­n Ä‘á»u hoÃ n toÃ n báº±ng tiáº¿ng Anh.
Tháº­t ra má»¥c Ä‘Ã­ch chÃ­nh cá»§a nhá»¯ng buá»•i nÃ y lÃ  mÃ¬nh muá»‘n nÃ¢ng cao kÄ© nÄƒng thuyáº¿t trÃ¬nh, tháº£o luáº­n vÃ  Ä‘á»ƒ Ã´n láº¡i nhá»¯ng kiáº¿n thá»©c Ä‘Ã£ há»c Ä‘Æ°á»£c thÃ´i.
Vá» mÃ¬nh thÃ¬ mÃ¬nh cÃ³ kiáº¿n thá»©c vá» AI/Data á»Ÿ má»©c táº¡m á»•n, tiáº¿ng Anh tá»‘t. VÃ¬ váº­y náº¿u cÃ³ báº¡n nÃ o cÅ©ng chung chÃ­ hÆ°á»›ng thÃ¬ inbox mÃ¬nh nhÃ©. Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i. Qua bÃ i post nÃ y mÃ¬nh muá»‘n tÃ¬m ngÆ°á»i Ä‘á»ƒ cÃ¹ng nhau há»c vá» AI/Data. MÃ¬nh cÃ³ thá»ƒ cÃ¹ng nhau tháº£o luáº­n vá» má»™t chá»§ Ä‘á» nÃ o Ä‘áº¥y trong lÄ©nh vá»±c nÃ y. CÅ©ng cÃ³ thá»ƒ náº¿u ngÆ°á»i nÃ y vá»«a há»c Ä‘Æ°á»£c cÃ¡i gÃ¬ má»›i thÃ¬ cÃ³ thá»ƒ giáº£ng giáº£i cho ngÆ°á»i kia. NgÆ°á»i ta nÃ³i ráº±ng: báº¡n chá»‰ tháº­t sá»± hiá»ƒu má»™t váº¥n Ä‘á», khi mÃ  báº¡n cÃ³ thá»ƒ giáº£i thÃ­ch cho ngÆ°á»i khÃ¡c cÃ¹ng hiá»ƒu vá» váº¥n Ä‘á» Ä‘Ã³. CÃ¡c chá»§ Ä‘á» nÃ y cÅ©ng cÃ³ thá»ƒ chá»‰ lÃ  nhá»¯ng váº¥n Ä‘á» cÆ¡ báº£n cá»§a AI/Data thÃ´i. Má»™t Ä‘iá»u quan trá»ng lÃ  mÃ¬nh muá»‘n cÃ¡c buá»•i tháº£o luáº­n Ä‘á»u hoÃ n toÃ n báº±ng tiáº¿ng Anh. Tháº­t ra má»¥c Ä‘Ã­ch chÃ­nh cá»§a nhá»¯ng buá»•i nÃ y lÃ  mÃ¬nh muá»‘n nÃ¢ng cao kÄ© nÄƒng thuyáº¿t trÃ¬nh, tháº£o luáº­n vÃ  Ä‘á»ƒ Ã´n láº¡i nhá»¯ng kiáº¿n thá»©c Ä‘Ã£ há»c Ä‘Æ°á»£c thÃ´i. Vá» mÃ¬nh thÃ¬ mÃ¬nh cÃ³ kiáº¿n thá»©c vá» AI/Data á»Ÿ má»©c táº¡m á»•n, tiáº¿ng Anh tá»‘t. VÃ¬ váº­y náº¿u cÃ³ báº¡n nÃ o cÅ©ng chung chÃ­ hÆ°á»›ng thÃ¬ inbox mÃ¬nh nhÃ©. Cáº£m Æ¡n má»i ngÆ°á»i.",,,#Q&A,,
"Em chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang cÃ³ thá»±c hiá»‡n project build knowledge graph cho vÄƒn báº£n tiáº¿ng viá»‡t Ä‘á»‹nh hÆ°á»›ng phÆ°Æ¡ng phÃ¡p em lÃ m nhÆ° sau :
- DÃ¹ng underthesea Ä‘á»ƒ setence segmentation Ä‘á»ƒ tÃ¡ch nhá» vÄƒn báº£n thÃ nh tá»«ng cÃ¢u
- DÃ¹ng Named Entity Regconition (NER)/Dependency Parsing (DEP) Ä‘á»ƒ phÃ¢n tÃ­ch thÃ nh pháº§n trong cÃ¢u ( Táº¡m thá»i sáº½ dÃ¹ng vncoreNLP Ä‘á»ƒ extract thá»­ nghiá»‡m tÃ­nh hiá»‡u quáº£ náº¿u tá»‘t cÃ³ thá»ƒ train láº¡i )
- Tá»« NER/DEP Ä‘Ã£ extract sáº½ tÃ¬m ra bá»™ 3 ( entity 1 - relation - entity 2 ) trong cÃ¢u Ä‘á»ƒ táº¡o thÃ nh 1 liÃªn káº¿t trong graph vá»›i cÃ¡c node lÃ  entity
VD : ( Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden ) thÃ¬ khi dÃ¹ng NER/DEP thÃ¬ sáº½ cho ra káº¿t quáº£ ( entity 1:""Tá»•ng_thá»‘ng_má»¹"", relation:""lÃ "",Entity 2 : ""Joe_Biden"")
---------------------------------------------------------------
CÃ¡c khÃ³ khÄƒn hiá»‡n táº¡i vd vá»›i 1 cÃ¢u phá»©c táº¡p hÆ¡n nhÆ° sau :
- Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden, Ã´ng cÃ²n biáº¿t tá»›i lÃ  chÃ­nh trá»‹ gia.
ThÃ¬ trong 1 cÃ¢u xuáº¥t hiá»‡n tá»›i 2 bá»™ (e1,r,e2)
- Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden
- Ã´ng lÃ  chÃ­nh trá»‹ gia
nhÆ°ng tá»« Ã´ng thÃ¬ quÃ¡ chung chung khi Ä‘Ã³ vÃ o graph thÃ¬ tá»« Ã´ng sáº½ Ä‘Æ°á»£c liÃªn káº¿t vá»›i nhiá»u thÃ nh pháº§n ko mong muá»‘n ko thá»ƒ hiá»‡n Ä‘Æ°á»£c Ã´ng = Joe Biden trong liÃªn káº¿t thÃ¬ expect em nÃ³ sáº½ lÃ 
- Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden
- Joe Bide lÃ  chÃ­nh trá»‹ gia
Má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p nÃ o hoáº·c phÆ°Æ¡ng phÃ¡p nÃ o giÃºp em tiáº¿p cáº­n bÃ i toÃ¡n khÃ´ng áº¡ em xin cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c","Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang cÃ³ thá»±c hiá»‡n project build knowledge graph cho vÄƒn báº£n tiáº¿ng viá»‡t Ä‘á»‹nh hÆ°á»›ng phÆ°Æ¡ng phÃ¡p em lÃ m nhÆ° sau : - DÃ¹ng underthesea Ä‘á»ƒ setence segmentation Ä‘á»ƒ tÃ¡ch nhá» vÄƒn báº£n thÃ nh tá»«ng cÃ¢u - DÃ¹ng Named Entity Regconition (NER)/Dependency Parsing (DEP) Ä‘á»ƒ phÃ¢n tÃ­ch thÃ nh pháº§n trong cÃ¢u ( Táº¡m thá»i sáº½ dÃ¹ng vncoreNLP Ä‘á»ƒ extract thá»­ nghiá»‡m tÃ­nh hiá»‡u quáº£ náº¿u tá»‘t cÃ³ thá»ƒ train láº¡i ) - Tá»« NER/DEP Ä‘Ã£ extract sáº½ tÃ¬m ra bá»™ 3 ( entity 1 - relation - entity 2 ) trong cÃ¢u Ä‘á»ƒ táº¡o thÃ nh 1 liÃªn káº¿t trong graph vá»›i cÃ¡c node lÃ  entity VD : ( Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden ) thÃ¬ khi dÃ¹ng NER/DEP thÃ¬ sáº½ cho ra káº¿t quáº£ ( entity 1:""Tá»•ng_thá»‘ng_má»¹"", relation:""lÃ "",Entity 2 : ""Joe_Biden"") --------------------------------------------------------------- CÃ¡c khÃ³ khÄƒn hiá»‡n táº¡i vd vá»›i 1 cÃ¢u phá»©c táº¡p hÆ¡n nhÆ° sau : - Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden, Ã´ng cÃ²n biáº¿t tá»›i lÃ  chÃ­nh trá»‹ gia. ThÃ¬ trong 1 cÃ¢u xuáº¥t hiá»‡n tá»›i 2 bá»™ (e1,r,e2) - Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden - Ã´ng lÃ  chÃ­nh trá»‹ gia nhÆ°ng tá»« Ã´ng thÃ¬ quÃ¡ chung chung khi Ä‘Ã³ vÃ o graph thÃ¬ tá»« Ã´ng sáº½ Ä‘Æ°á»£c liÃªn káº¿t vá»›i nhiá»u thÃ nh pháº§n ko mong muá»‘n ko thá»ƒ hiá»‡n Ä‘Æ°á»£c Ã´ng = Joe Biden trong liÃªn káº¿t thÃ¬ expect em nÃ³ sáº½ lÃ  - Tá»•ng thá»‘ng má»¹ lÃ  Joe Biden - Joe Bide lÃ  chÃ­nh trá»‹ gia Má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p nÃ o hoáº·c phÆ°Æ¡ng phÃ¡p nÃ o giÃºp em tiáº¿p cáº­n bÃ i toÃ¡n khÃ´ng áº¡ em xin cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c",,,"#Q&A, #nlp",,
,nan,,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m kiáº¿m cÃ´ng viá»‡c thá»±c táº­p á»Ÿ máº£ng Computer vision vÃ  Ä‘ang chuáº©n bá»‹ CV. ÄÃ¢y lÃ  CV cá»§a em, cÃ¡c anh chá»‹ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp em chá»‰nh sá»­a láº¡i CV, cÅ©ng nhÆ° Ä‘Æ°a ra lá»i khuyÃªn giÃºp em nÃªn há»c thÃªm vÃ  chuyÃªn sÃ¢u vÃ o máº£ng nÃ o Ä‘Æ°á»£c khÃ´ng áº¡.
PS: em Ä‘ang lÃ  sinh viÃªn nÄƒm 3, cÃ¡c link github em khÃ´ng Ä‘Ã­nh kÃ¨m trong file, náº¿u anh chá»‹ muá»‘n xem thÃªm thÃ¬ em gá»­i riÃªng áº¡.","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m kiáº¿m cÃ´ng viá»‡c thá»±c táº­p á»Ÿ máº£ng Computer vision vÃ  Ä‘ang chuáº©n bá»‹ CV. ÄÃ¢y lÃ  CV cá»§a em, cÃ¡c anh chá»‹ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp em chá»‰nh sá»­a láº¡i CV, cÅ©ng nhÆ° Ä‘Æ°a ra lá»i khuyÃªn giÃºp em nÃªn há»c thÃªm vÃ  chuyÃªn sÃ¢u vÃ o máº£ng nÃ o Ä‘Æ°á»£c khÃ´ng áº¡. PS: em Ä‘ang lÃ  sinh viÃªn nÄƒm 3, cÃ¡c link github em khÃ´ng Ä‘Ã­nh kÃ¨m trong file, náº¿u anh chá»‹ muá»‘n xem thÃªm thÃ¬ em gá»­i riÃªng áº¡.",,,#Q&A,,
"ğŸ²ğŸŒˆ WEBINAR: HÆ¯á»šNG DáºªN Táº O Ná»˜I DUNG Vá»šI CHATGPT
Tá»‘i thá»© ba, 14/11 tá»›i Ä‘Ã¢y, FUNiX tá»• chá»©c webinar online ""Next-level AI Content - HÆ°á»›ng dáº«n táº¡o ná»™i dung vá»›i ChatGPT"". Diá»…n giáº£ Trung Caha - Co-Founder Antory, Admin blog khoahocmidjourney.com, sáº½ chia sáº» kinh nghiá»‡m vá» cÃ¡ch sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Ä‘á»™t phÃ¡ vá»›i ChatGPT.
Äáº¿n vá»›i webinar, báº¡n sáº½ biáº¿t:
ğŸ‘‰Táº¡o ná»™i dung cÃ³ cháº¥t lÆ°á»£ng cao, cuá»‘n hÃºt tá»« ChatGPT mÃ  khÃ´ng pháº£i cÃ¢u tráº£ lá»i chung chung hay giá»‘ng vá»›i tÃ¬m kiáº¿m Google
ğŸ‘‰Viáº¿t cÃ¢u lá»‡nh vá»›i Chat GPT mÃ   99,99999% tháº¿ giá»›i ngoÃ i kia chÆ°a biáº¿t Ä‘áº¿n.
ğŸ‘‰5 Yáº¿u tá»‘ Ä‘á»ƒ táº¡o ná»™i dung chuyÃªn sÃ¢u, cháº¥t lÆ°á»£ng cho báº¥t cá»© lÄ©nh vá»±c nÃ o báº¡n muá»‘n.
ğŸ‘‰Äáº¡t Ä‘Æ°á»£c lá»£i tháº¿ cáº¡nh tranh VÆ¯á»¢T TRá»˜I  ngay cáº£ so vá»›i nhá»¯ng ngÆ°á»i khÃ¡c sá»­ dá»¥ng AI khÃ¡c.
ğŸ“ŒNhanh tay Ä‘Äƒng kÃ½ táº¡i https://shorturl.at/atA28
â° ThoÌ›Ì€i gian: 20:00 - 21:30, Thá»© 3, ngaÌ€y 14/11/2023","WEBINAR: HÆ¯á»šNG DáºªN Táº O Ná»˜I DUNG Vá»šI CHATGPT Tá»‘i thá»© ba, 14/11 tá»›i Ä‘Ã¢y, FUNiX tá»• chá»©c webinar online ""Next-level AI Content - HÆ°á»›ng dáº«n táº¡o ná»™i dung vá»›i ChatGPT"". Diá»…n giáº£ Trung Caha - Co-Founder Antory, Admin blog khoahocmidjourney.com, sáº½ chia sáº» kinh nghiá»‡m vá» cÃ¡ch sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Ä‘á»™t phÃ¡ vá»›i ChatGPT. Äáº¿n vá»›i webinar, báº¡n sáº½ biáº¿t: Táº¡o ná»™i dung cÃ³ cháº¥t lÆ°á»£ng cao, cuá»‘n hÃºt tá»« ChatGPT mÃ  khÃ´ng pháº£i cÃ¢u tráº£ lá»i chung chung hay giá»‘ng vá»›i tÃ¬m kiáº¿m Google Viáº¿t cÃ¢u lá»‡nh vá»›i Chat GPT mÃ  99,99999% tháº¿ giá»›i ngoÃ i kia chÆ°a biáº¿t Ä‘áº¿n. 5 Yáº¿u tá»‘ Ä‘á»ƒ táº¡o ná»™i dung chuyÃªn sÃ¢u, cháº¥t lÆ°á»£ng cho báº¥t cá»© lÄ©nh vá»±c nÃ o báº¡n muá»‘n. Äáº¡t Ä‘Æ°á»£c lá»£i tháº¿ cáº¡nh tranh VÆ¯á»¢T TRá»˜I ngay cáº£ so vá»›i nhá»¯ng ngÆ°á»i khÃ¡c sá»­ dá»¥ng AI khÃ¡c. Nhanh tay Ä‘Äƒng kÃ½ táº¡i https://shorturl.at/atA28 â° ThoÌ›Ì€i gian: 20:00 - 21:30, Thá»© 3, ngaÌ€y 14/11/2023",,,#webinar,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2023 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2023 vÃ o comment cá»§a post nÃ y.",,,#sharing,,
"[AI Share - Statistics]
Äa sá»‘ cÃ¡c thuáº­t toÃ¡n cá»§a Machine Learning Ä‘á»u dá»±a trÃªn ná»n cá»§a XÃ¡c suáº¥t vÃ  thá»‘ng kÃª. Äá»‘i vá»›i nhiá»u ngÆ°á»i, xÃ¡c suáº¥t thá»‘ng kÃª lÃ  má»™t mÃ´n khÃ³ vÃ  cÃ³ nhiá»u kiáº¿n thá»©c cáº§n pháº£i náº¯m. NgoÃ i viá»‡c Ä‘á»c sÃ¡ch Ä‘á»ƒ náº¯m vá»¯ng cÃ¡c khÃ¡i niá»‡m vÃ  á»©ng dá»¥ng, AI4E muá»‘n chia sáº» 1 cheatsheet tá»•ng há»£p cÃ¡c kiáº¿n thá»©c xÃ¡c suáº¥t má»™t cÃ¡ch ngáº¯n gá»n vÃ  tá»•ng quÃ¡t nháº¥t. Cheatsheet nÃ y bao phá»§ toÃ n bá»™ cÃ¡c kiáº¿n thá»©c cá»‘t lÃµi nháº¥t trong xÃ¡c suáº¥t. TÃ i liá»‡u cÃ³ giÃ¡ trá»‹ vÃ  Ä‘Ã¡ng tin cáº­y bá»Ÿi ngÆ°á»i viáº¿t dá»±a trÃªn tÃ i liá»‡u khÃ³a há»c XÃ¡c suáº¥t cá»§a Harvards.","[AI Share - Statistics] Äa sá»‘ cÃ¡c thuáº­t toÃ¡n cá»§a Machine Learning Ä‘á»u dá»±a trÃªn ná»n cá»§a XÃ¡c suáº¥t vÃ  thá»‘ng kÃª. Äá»‘i vá»›i nhiá»u ngÆ°á»i, xÃ¡c suáº¥t thá»‘ng kÃª lÃ  má»™t mÃ´n khÃ³ vÃ  cÃ³ nhiá»u kiáº¿n thá»©c cáº§n pháº£i náº¯m. NgoÃ i viá»‡c Ä‘á»c sÃ¡ch Ä‘á»ƒ náº¯m vá»¯ng cÃ¡c khÃ¡i niá»‡m vÃ  á»©ng dá»¥ng, AI4E muá»‘n chia sáº» 1 cheatsheet tá»•ng há»£p cÃ¡c kiáº¿n thá»©c xÃ¡c suáº¥t má»™t cÃ¡ch ngáº¯n gá»n vÃ  tá»•ng quÃ¡t nháº¥t. Cheatsheet nÃ y bao phá»§ toÃ n bá»™ cÃ¡c kiáº¿n thá»©c cá»‘t lÃµi nháº¥t trong xÃ¡c suáº¥t. TÃ i liá»‡u cÃ³ giÃ¡ trá»‹ vÃ  Ä‘Ã¡ng tin cáº­y bá»Ÿi ngÆ°á»i viáº¿t dá»±a trÃªn tÃ i liá»‡u khÃ³a há»c XÃ¡c suáº¥t cá»§a Harvards.",,,"#sharing, #math",,
"ChÃ o cÃ¡c anh chá»‹,
Em muá»‘n mua mÃ¡y bÃ n phá»¥c vá»¥ viá»‡c nghiÃªn cá»©u vÃ  cháº¡y cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y. Anh chá»‹ nÃ o cÃ³ thá»ƒ gá»£i Ã½ giÃºp em mÃ¡y cÃ³ cáº¥u hÃ¬nh phÃ¹ há»£p Ä‘Æ°á»£c khÃ´ng áº¡?

Em chÃ¢n thÃ nh cÃ¡m Æ¡n.","ChÃ o cÃ¡c anh chá»‹, Em muá»‘n mua mÃ¡y bÃ n phá»¥c vá»¥ viá»‡c nghiÃªn cá»©u vÃ  cháº¡y cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y. Anh chá»‹ nÃ o cÃ³ thá»ƒ gá»£i Ã½ giÃºp em mÃ¡y cÃ³ cáº¥u hÃ¬nh phÃ¹ há»£p Ä‘Æ°á»£c khÃ´ng áº¡? Em chÃ¢n thÃ nh cÃ¡m Æ¡n.",,,#Q&A,,
"[CÆ¡ há»™i tham dá»± Há»™i tháº£o Quá»‘c táº¿ vá» Computer Vision cho cÃ¡c báº¡n SV vÃ  NCS ngay táº¡i Viá»‡t Nam vá»›i phÃ­ Há»™i tháº£o chá»‰ tá»« 100 ~200 USD. Cáº£m Æ¡n ad Ä‘Ã£ duyá»‡t bÃ i].

Dear Scientists and Colleagues,
We will organize a Special Session on Computer Vision - SSCV (https://cita.vku.udn.vn/2024/special-session-cv) at CITA 2024 (13th Conference on Information Technology and its Applications) in Hoi An, Vietnam on July 19-20, 2024.
We welcome your research and contribution to this special session and enjoy Vietnam's culture and life.
See you in Hoi An, Vietnam!
____
This is the detailed information of the Special Session on Computer Vision - SSCV:
ğŸ“ŒObjectives:
Computer Vision is a field of Artificial Intelligence that enables computers to interpret and understand meaningful information from digital images, videos, and other visual inputs. Nowadays, Computer Vision is widely applied and deployed in many different fields such as intelligent transportation systems, surveillance systems, biomedical image diagnosis systems, automatic control systems, and monitoring systems in industry and agriculture, ... Especially with the rapid development of Convolutional Neural Networks and Machine Learning, they have attracted a large number of researchers working in this field and its applications. Computer Vision is becoming more and more popular.
The Special Session on Computer Vision (SSCV) at the 13th Conference on Information Technology and its Applications (CITA 2024) aims to provide opportunities for scientists and developers to present the hot trends and promising developments of Computer Vision. Through this forum, the latest research, innovative techniques, and advanced applications in Computer Vision are also exchanged and discussed to open up the broader academic environment and community.
ğŸ“ŒTopics:
Relevant topics include, but are not limited to several of the following topics:
ğŸ‘‰Computer Vision and Robot Vision
ğŸ‘‰Computer Vision-based Machine Learning and Deep Learning
ğŸ‘‰Image Processing
ğŸ‘‰Pattern Recognition
ğŸ‘‰Object Detection and Classification
ğŸ‘‰Semantic and Instance Segmentation
ğŸ‘‰Motion Recognition and Tracking
ğŸ‘‰Multimedia Analysis
ğŸ‘‰Medical, Biomedical, and Biometrics Image Analysis
ğŸ‘‰Document Analysis and Recognition
ğŸ‘‰Human-Computer Interaction (HCI)
ğŸ‘‰Human-Robot Interaction (HRI)
ğŸ‘‰Computer Vision-based Control
ğŸ‘‰Computer Vision-based Surveillant Systems
ğŸ‘‰Computer Vision-based Intelligent Transportation Systems
ğŸ‘‰Computer Vision-based Applications
ğŸ‘‰Virtual Reality and Augmented Reality Technologies
ğŸ“ŒImportant Dates
Paper submission: January 15th, 2024
Final Notification: March 15th, 2024
Camera Ready: April 20th, 2024
Conference Sessions: July 19th - 20th, 2024
ğŸ“ŒOrganizers
ğŸ‘‰Prof. Dr.  Kang-Hyun Jo (Chair)
Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan 44610, South Korea
Email: acejo@ulsan.ac.kr
ğŸ‘‰Dr. Duy-Linh Nguyen (Co-chair)
Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan 44610, South Korea
Email: nguyenduylinhqbu@gmail.com
ğŸ“ŒPaper Submission
Paperâ€™s template used at CITA2024 abides by the standard format of Springer LNCS/LNAI magazine (refer to link: http://www.springer.com/.../conference-proceedings...). When posting, the authors need to agree to the following terms:
Submissions must be original papers, never be posted/published before;
Use the template specified by the conference, do not change the font style, format, header/footer; no page numbering;
Language: English
Length: no more than 12 pages.
To submit the papers:
Sign in: https://easychair.org/conferences/?conf=cita2024
Select Special Session: SSCV
ğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒContact:
Dr. Duy-Linh Nguyen
Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan 44610, South Korea
Email: nguyenduylinhqbu@gmail.com","[CÆ¡ há»™i tham dá»± Há»™i tháº£o Quá»‘c táº¿ vá» Computer Vision cho cÃ¡c báº¡n SV vÃ  NCS ngay táº¡i Viá»‡t Nam vá»›i phÃ­ Há»™i tháº£o chá»‰ tá»« 100 ~200 USD. Cáº£m Æ¡n ad Ä‘Ã£ duyá»‡t bÃ i]. Dear Scientists and Colleagues, We will organize a Special Session on Computer Vision - SSCV (https://cita.vku.udn.vn/2024/special-session-cv) at CITA 2024 (13th Conference on Information Technology and its Applications) in Hoi An, Vietnam on July 19-20, 2024. We welcome your research and contribution to this special session and enjoy Vietnam's culture and life. See you in Hoi An, Vietnam! ____ This is the detailed information of the Special Session on Computer Vision - SSCV: Objectives: Computer Vision is a field of Artificial Intelligence that enables computers to interpret and understand meaningful information from digital images, videos, and other visual inputs. Nowadays, Computer Vision is widely applied and deployed in many different fields such as intelligent transportation systems, surveillance systems, biomedical image diagnosis systems, automatic control systems, and monitoring systems in industry and agriculture, ... Especially with the rapid development of Convolutional Neural Networks and Machine Learning, they have attracted a large number of researchers working in this field and its applications. Computer Vision is becoming more and more popular. The Special Session on Computer Vision (SSCV) at the 13th Conference on Information Technology and its Applications (CITA 2024) aims to provide opportunities for scientists and developers to present the hot trends and promising developments of Computer Vision. Through this forum, the latest research, innovative techniques, and advanced applications in Computer Vision are also exchanged and discussed to open up the broader academic environment and community. Topics: Relevant topics include, but are not limited to several of the following topics: Computer Vision and Robot Vision Computer Vision-based Machine Learning and Deep Learning Image Processing Pattern Recognition Object Detection and Classification Semantic and Instance Segmentation Motion Recognition and Tracking Multimedia Analysis Medical, Biomedical, and Biometrics Image Analysis Document Analysis and Recognition Human-Computer Interaction (HCI) Human-Robot Interaction (HRI) Computer Vision-based Control Computer Vision-based Surveillant Systems Computer Vision-based Intelligent Transportation Systems Computer Vision-based Applications Virtual Reality and Augmented Reality Technologies Important Dates Paper submission: January 15th, 2024 Final Notification: March 15th, 2024 Camera Ready: April 20th, 2024 Conference Sessions: July 19th - 20th, 2024 Organizers Prof. Dr. Kang-Hyun Jo (Chair) Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan 44610, South Korea Email: acejo@ulsan.ac.kr Dr. Duy-Linh Nguyen (Co-chair) Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan 44610, South Korea Email: nguyenduylinhqbu@gmail.com Paper Submission Paperâ€™s template used at CITA2024 abides by the standard format of Springer LNCS/LNAI magazine (refer to link: http://www.springer.com/.../conference-proceedings...). When posting, the authors need to agree to the following terms: Submissions must be original papers, never be posted/published before; Use the template specified by the conference, do not change the font style, format, header/footer; no page numbering; Language: English Length: no more than 12 pages. To submit the papers: Sign in: https://easychair.org/conferences/?conf=cita2024 Select Special Session: SSCV Contact: Dr. Duy-Linh Nguyen Department of Electrical, Electronic and Computer Engineering, University of Ulsan, Ulsan 44610, South Korea Email: nguyenduylinhqbu@gmail.com",,,,,
"[Scikit learn bÃ¡o Multicolinearity]
ACE cho e há»i e Ä‘ang dÃ¹ng Scikit Learn cháº¡y OLS, check VIF toÃ n nhá» hÆ¡n 2 sao cá»© bá»‹ bÃ¡o Multicolinearity váº­y áº¡. Ai biáº¿t Scikit Learn tÃ­nh cÃ¡i nÃ y tháº¿ nÃ o k áº¡ chá»‰ e vá»›i. Tks mn!","[Scikit learn bÃ¡o Multicolinearity] ACE cho e há»i e Ä‘ang dÃ¹ng Scikit Learn cháº¡y OLS, check VIF toÃ n nhá» hÆ¡n 2 sao cá»© bá»‹ bÃ¡o Multicolinearity váº­y áº¡. Ai biáº¿t Scikit Learn tÃ­nh cÃ¡i nÃ y tháº¿ nÃ o k áº¡ chá»‰ e vá»›i. Tks mn!",,,"#Q&A, #python",,
"ChÃ o má»i ngÆ°á»i áº¡,
Em nháº­n tháº¥y cÃ¡c LLM ráº¥t hay tá»± thÃªm thÃ´ng tin vÃ o context. VÃ­ dá»¥ em báº£o nÃ³ viáº¿t cÃ¢u há»i cho má»™t Ä‘oáº¡n vÄƒn hoáº·c tÃ³m táº¯t má»™t bÃ i bÃ¡o thÃ¬ nÃ³ hay tá»± Ä‘á»™ng bá»• sung cÃ¡c thÃ´ng tin bÃªn ngoÃ i context / prompt vÃ o káº¿t quáº£.
Em cÅ©ng hiá»ƒu Ä‘Ã¢y lÃ  chuyá»‡n dá»… hiá»ƒu vÃ¬ LLM lÃ  stocastic. Em cÅ©ng Ä‘Ã£ dÃ¹ng cÃ¡c kiá»ƒu chain of thought Ä‘á»ƒ báº¯t LLM chá»‰ dÃ¹ng thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Náº¿u khÃ´ng tráº£ lá»i Ä‘Æ°á»£c dá»±a trÃªn context thÃ¬ cá»© báº£o lÃ  khÃ´ng biáº¿t, nhÆ°ng káº¿t quáº£ lÃºc Ä‘Æ°á»£c lÃºc khÃ´ng.
KhÃ´ng viáº¿t trong literature thÃ¬ hiá»‡n tÆ°á»£ng nÃ y gá»i lÃ  gÃ¬ áº¡? CÃ³ pháº£i lÃ  váº¥n Ä‘á» cÃ¡c nhÃ  khoa há»c Ä‘ang giáº£i quyáº¿t khÃ´ng áº¡?
CÃ¡m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i áº¡, Em nháº­n tháº¥y cÃ¡c LLM ráº¥t hay tá»± thÃªm thÃ´ng tin vÃ o context. VÃ­ dá»¥ em báº£o nÃ³ viáº¿t cÃ¢u há»i cho má»™t Ä‘oáº¡n vÄƒn hoáº·c tÃ³m táº¯t má»™t bÃ i bÃ¡o thÃ¬ nÃ³ hay tá»± Ä‘á»™ng bá»• sung cÃ¡c thÃ´ng tin bÃªn ngoÃ i context / prompt vÃ o káº¿t quáº£. Em cÅ©ng hiá»ƒu Ä‘Ã¢y lÃ  chuyá»‡n dá»… hiá»ƒu vÃ¬ LLM lÃ  stocastic. Em cÅ©ng Ä‘Ã£ dÃ¹ng cÃ¡c kiá»ƒu chain of thought Ä‘á»ƒ báº¯t LLM chá»‰ dÃ¹ng thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Náº¿u khÃ´ng tráº£ lá»i Ä‘Æ°á»£c dá»±a trÃªn context thÃ¬ cá»© báº£o lÃ  khÃ´ng biáº¿t, nhÆ°ng káº¿t quáº£ lÃºc Ä‘Æ°á»£c lÃºc khÃ´ng. KhÃ´ng viáº¿t trong literature thÃ¬ hiá»‡n tÆ°á»£ng nÃ y gá»i lÃ  gÃ¬ áº¡? CÃ³ pháº£i lÃ  váº¥n Ä‘á» cÃ¡c nhÃ  khoa há»c Ä‘ang giáº£i quyáº¿t khÃ´ng áº¡? CÃ¡m Æ¡n má»i ngÆ°á»i",,,"#Q&A, #nlp",,
Náº¯m vá»¯ng cÃ¡c giai Ä‘oáº¡n phÃ¡t triá»ƒn cá»§a á»©ng dá»¥ng vá»›i Container,Náº¯m vá»¯ng cÃ¡c giai Ä‘oáº¡n phÃ¡t triá»ƒn cá»§a á»©ng dá»¥ng vá»›i Container,,,#sharing,,
"ChÃ o buá»•i tá»‘i má»i ngÆ°á»i,
HÃ´m nay team VILM trÃ¬nh lÃ ng bá»™ dataset OpenOrca-Viet, bao gá»“m 120,000 cáº·p cÃ¢u há»i instructions cháº¥t lÆ°á»£ng cao Ä‘Æ°á»£c distillate tá»« 3 LLMs hÃ ng Ä‘áº§u trÃªn tháº¿ giá»›i: GPT-4, PaLM-2 vÃ  Claude.
OpenOrca-Viet Ä‘Æ°á»£c Ä‘á»“ng phÃ¡t triá»ƒn dÆ°á»›i sá»± há»£p tÃ¡c cá»§a VILM vÃ  Alignment Lab AI, chá»§ nhÃ¢n cá»§a bá»™ dataset OpenOrca gá»‘c báº±ng tiáº¿ng Anh. ÄÃ¢y cÅ©ng chÃ­nh lÃ  má»™t trong cÃ¡c bá»™ dataset Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ train model Vietcuna-7B-v3.
ChÃºc má»i ngÆ°á»i cÃ³ má»™t buá»•i tá»‘i vui váº»
Link to Dataset: https://huggingface.co/datasets/vilm/OpenOrca-Viet","ChÃ o buá»•i tá»‘i má»i ngÆ°á»i, HÃ´m nay team VILM trÃ¬nh lÃ ng bá»™ dataset OpenOrca-Viet, bao gá»“m 120,000 cáº·p cÃ¢u há»i instructions cháº¥t lÆ°á»£ng cao Ä‘Æ°á»£c distillate tá»« 3 LLMs hÃ ng Ä‘áº§u trÃªn tháº¿ giá»›i: GPT-4, PaLM-2 vÃ  Claude. OpenOrca-Viet Ä‘Æ°á»£c Ä‘á»“ng phÃ¡t triá»ƒn dÆ°á»›i sá»± há»£p tÃ¡c cá»§a VILM vÃ  Alignment Lab AI, chá»§ nhÃ¢n cá»§a bá»™ dataset OpenOrca gá»‘c báº±ng tiáº¿ng Anh. ÄÃ¢y cÅ©ng chÃ­nh lÃ  má»™t trong cÃ¡c bá»™ dataset Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ train model Vietcuna-7B-v3. ChÃºc má»i ngÆ°á»i cÃ³ má»™t buá»•i tá»‘i vui váº» Link to Dataset: https://huggingface.co/datasets/vilm/OpenOrca-Viet",,,"#sharing, #data",,
"em chÃ o cÃ¡c anh chá»‹ áº¡, má»i ngÆ°á»i cho e há»i lÃ  Ä‘á»ƒ váº½ hÃ¬nh nÃ y cáº§n dÃ¹ng tool gÃ¬ áº¡, e cáº£m Æ¡n mng áº¡!","em chÃ o cÃ¡c anh chá»‹ áº¡, má»i ngÆ°á»i cho e há»i lÃ  Ä‘á»ƒ váº½ hÃ¬nh nÃ y cáº§n dÃ¹ng tool gÃ¬ áº¡, e cáº£m Æ¡n mng áº¡!",,,#Q&A,,
Em Ä‘ang há»c vá» láº¯ng nghe máº¡ng xÃ£ há»™i. Trong bÃ i yÃªu cáº§u phÃ¢n tÃ­ch chá»§ Ä‘á» vÃ  sáº¯c thÃ¡i cá»§a doanh nghiá»‡p dá»±a vÃ o quy táº¯c sáº¯c thÃ¡i vÃ  quy táº¯c chá»§ Ä‘á». NhÆ°ng em dá»±a vÃ o Ä‘Ã³ váº«n lÃ m sai. Anh chá»‹ chia sáº» cho em Ã­t kinh nghiá»‡m Ä‘á»ƒ lÃ m Ä‘Ãºng vá»›i áº¡. Em cáº£m Æ¡n.,Em Ä‘ang há»c vá» láº¯ng nghe máº¡ng xÃ£ há»™i. Trong bÃ i yÃªu cáº§u phÃ¢n tÃ­ch chá»§ Ä‘á» vÃ  sáº¯c thÃ¡i cá»§a doanh nghiá»‡p dá»±a vÃ o quy táº¯c sáº¯c thÃ¡i vÃ  quy táº¯c chá»§ Ä‘á». NhÆ°ng em dá»±a vÃ o Ä‘Ã³ váº«n lÃ m sai. Anh chá»‹ chia sáº» cho em Ã­t kinh nghiá»‡m Ä‘á»ƒ lÃ m Ä‘Ãºng vá»›i áº¡. Em cáº£m Æ¡n.,,,#Q&A,,
"Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang thá»±c hiá»‡n má»™t bÃ i toÃ¡n nhÆ° sau: Tá»« cÃ¢u ngÃ´n ngá»¯ sinh ra query (vd nhÆ° bÃ i toÃ¡n text2sql), tá»« query => chart, rá»“i tá»« chart => comment hoáº·c description vá» chart ğŸ“·
VÃ¬ kiáº¿n thá»©c cá»§a e vá» nlp cÃ²n khÃ¡ háº¡n cháº¿, nÃªn em chÆ°a cÃ³ kinh nghiá»‡m nhiá»u trong cÃ¡c bÃ i toÃ¡n nhÆ° nÃ y, nÃªn em xin má»i ngÆ°á»i tÆ° váº¥n giÃºp em má»™t sá»‘ váº¥n Ä‘á» nhÆ° sau áº¡:
CÃ¡ch tiáº¿p cáº­n bÃ i toÃ¡n nhÆ° tháº¿ nÃ o áº¡? 
Dá»¯ liá»‡u train sáº½ Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘Ã¡nh label nhÆ° tháº¿ nÃ o áº¡?
Äá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c bÃ i toÃ¡n em nÃªn há»c vÃ  sá»­ dá»¥ng cÃ´ng cá»¥ nÃ o áº¡? Em xin cÃ¡c keyword vá» báº¥t cá»© cá»© thá»© gÃ¬ cÃ³ thá»ƒ coi lÃ  há»¯u Ã­ch cho bÃ i toÃ¡n trÃªn: link, model, framework, document,...
Em xin cáº£m Æ¡n cÃ¡c tÆ° váº¥n áº¡","Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang thá»±c hiá»‡n má»™t bÃ i toÃ¡n nhÆ° sau: Tá»« cÃ¢u ngÃ´n ngá»¯ sinh ra query (vd nhÆ° bÃ i toÃ¡n text2sql), tá»« query => chart, rá»“i tá»« chart => comment hoáº·c description vá» chart VÃ¬ kiáº¿n thá»©c cá»§a e vá» nlp cÃ²n khÃ¡ háº¡n cháº¿, nÃªn em chÆ°a cÃ³ kinh nghiá»‡m nhiá»u trong cÃ¡c bÃ i toÃ¡n nhÆ° nÃ y, nÃªn em xin má»i ngÆ°á»i tÆ° váº¥n giÃºp em má»™t sá»‘ váº¥n Ä‘á» nhÆ° sau áº¡: CÃ¡ch tiáº¿p cáº­n bÃ i toÃ¡n nhÆ° tháº¿ nÃ o áº¡? Dá»¯ liá»‡u train sáº½ Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘Ã¡nh label nhÆ° tháº¿ nÃ o áº¡? Äá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c bÃ i toÃ¡n em nÃªn há»c vÃ  sá»­ dá»¥ng cÃ´ng cá»¥ nÃ o áº¡? Em xin cÃ¡c keyword vá» báº¥t cá»© cá»© thá»© gÃ¬ cÃ³ thá»ƒ coi lÃ  há»¯u Ã­ch cho bÃ i toÃ¡n trÃªn: link, model, framework, document,... Em xin cáº£m Æ¡n cÃ¡c tÆ° váº¥n áº¡",,,"#Q&A, #nlp",,
"ChÃ o cÃ¡c bÃ¡c. Cuá»‘i tuáº§n tranh thá»§ tháº¥y cÃ³ github hÃ y vá» mÃ³n Text to Speech em xin máº¡nh dáº¡n chia sáº» cÃ¹ng cÃ¡c báº¡n má»›i há»c.
Bark - má»™t mÃ³n chuyá»ƒn text to speech cháº¡y offline, giá»ng tá»± nhiÃªn hÆ¡n cáº£ Google. Anh em nÃ o cáº§n lÃ m mÃ³n nÃ y cá»© tháº¿ mÃ  xÃ i tá»± nhiÃªn.
Tiáº¿c lÃ  chÆ°a cÃ³ code training!","ChÃ o cÃ¡c bÃ¡c. Cuá»‘i tuáº§n tranh thá»§ tháº¥y cÃ³ github hÃ y vá» mÃ³n Text to Speech em xin máº¡nh dáº¡n chia sáº» cÃ¹ng cÃ¡c báº¡n má»›i há»c. Bark - má»™t mÃ³n chuyá»ƒn text to speech cháº¡y offline, giá»ng tá»± nhiÃªn hÆ¡n cáº£ Google. Anh em nÃ o cáº§n lÃ m mÃ³n nÃ y cá»© tháº¿ mÃ  xÃ i tá»± nhiÃªn. Tiáº¿c lÃ  chÆ°a cÃ³ code training!",,,#sharing,,
"Em chÃ o mn áº¡, e Ä‘ang tÃ¬m hiá»ƒu vá» miccro segmentation mÃ  tháº¥y Ã­t tÃ i liá»‡u viáº¿t vá» cÃ¡i nÃ y nÃªn e chÆ°a hiá»ƒu rÃµ áº¡. KhÃ´ng biáº¿t mn ai Ä‘Ã£ tá»«ng lÃ m vá» phÃ¢n khÃºc vi mÃ´ khÃ¡ch hÃ ng cho e tham kháº£o vá»›i Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n mn nhiá»u áº¡.","Em chÃ o mn áº¡, e Ä‘ang tÃ¬m hiá»ƒu vá» miccro segmentation mÃ  tháº¥y Ã­t tÃ i liá»‡u viáº¿t vá» cÃ¡i nÃ y nÃªn e chÆ°a hiá»ƒu rÃµ áº¡. KhÃ´ng biáº¿t mn ai Ä‘Ã£ tá»«ng lÃ m vá» phÃ¢n khÃºc vi mÃ´ khÃ¡ch hÃ ng cho e tham kháº£o vá»›i Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n mn nhiá»u áº¡.",,,#Q&A,,
"Mn cho e há»i cÃ¢u liÃªn quan Ä‘áº¿n SQL vá»›i áº¡.
Em dÃ¹ng bulk insert Ä‘á»ƒ nháº­p data tá»« file txt nhÆ°ng cÃ³ 1 sá»‘ báº£n ghi bá»‹ lá»—i vÃ­ dá»¥ nhÆ°:
Name id
""Manh Thang (dáº¥u tab)"" 1
NhÆ°ng khi import thÃ¬ dáº¥u "" bá»‹ nháº£y sang pháº§n id( lÃ½ do lÃ  vÃ¬ dáº¥u tab) , do Ä‘Ã³ cÃ¡c hÃ ng tiáº¿p cÅ©ng bá»‹ nháº£y theo.
Ai Ä‘Ã£ xá»­ lÃ½ trÆ°á»ng há»£p nhÆ° váº­y cho e xin cÃ¡ch fix vá»›i áº¡.
Em cáº£m Æ¡n.","Mn cho e há»i cÃ¢u liÃªn quan Ä‘áº¿n SQL vá»›i áº¡. Em dÃ¹ng bulk insert Ä‘á»ƒ nháº­p data tá»« file txt nhÆ°ng cÃ³ 1 sá»‘ báº£n ghi bá»‹ lá»—i vÃ­ dá»¥ nhÆ°: Name id ""Manh Thang (dáº¥u tab)"" 1 NhÆ°ng khi import thÃ¬ dáº¥u "" bá»‹ nháº£y sang pháº§n id( lÃ½ do lÃ  vÃ¬ dáº¥u tab) , do Ä‘Ã³ cÃ¡c hÃ ng tiáº¿p cÅ©ng bá»‹ nháº£y theo. Ai Ä‘Ã£ xá»­ lÃ½ trÆ°á»ng há»£p nhÆ° váº­y cho e xin cÃ¡ch fix vá»›i áº¡. Em cáº£m Æ¡n.",,,#Q&A,,
"https://docs.google.com/document/d/1mlGA66qFAtNeTILDLZTSwxXZlI5R1T2Y2IbCiYTZRO8/edit?usp=sharing
Má»i ngÆ°á»i cho e há»i lÃ  sau khi tÃ¬m Ä‘Æ°á»£c táº¥t cáº£ cÃ¡c táº­p phá»• biáº¿n --> tÃ¬m luáº­t káº¿t há»£p. NhÆ°ng mÃ  e ko cháº¯c cÃ¡ch lÃ m cá»§a e Ä‘Ã£ Ä‘Ãºng chÆ°a?
Vd trong táº­p phá»• biáº¿n ABDE ta loáº¡i bá» A thÃ¬ cÃ³ luáº­t BDE->A conf = 2/2 = 1 --> Ä‘Ã¢y lÃ  luáº­t káº¿t há»£p
Link chi tiáº¿t bÃ i lÃ m e Ä‘á»ƒ trong google docs mn cÃ³ thá»ƒ xem qua vÃ  cho e Ã½ kiáº¿n Ä‘Æ°á»£c khÃ´ng áº¡ ?
Sau khi tÃ¬m Ä‘Æ°á»£c cÃ¡c luáº­t phá»• biáº¿n thÃ¬ cÃ³ cáº§n loáº¡i bá» trÃ¹ng láº·p khÃ´ng ? Em cáº£m Æ¡n!",https://docs.google.com/document/d/1mlGA66qFAtNeTILDLZTSwxXZlI5R1T2Y2IbCiYTZRO8/edit?usp=sharing Má»i ngÆ°á»i cho e há»i lÃ  sau khi tÃ¬m Ä‘Æ°á»£c táº¥t cáº£ cÃ¡c táº­p phá»• biáº¿n --> tÃ¬m luáº­t káº¿t há»£p. NhÆ°ng mÃ  e ko cháº¯c cÃ¡ch lÃ m cá»§a e Ä‘Ã£ Ä‘Ãºng chÆ°a? Vd trong táº­p phá»• biáº¿n ABDE ta loáº¡i bá» A thÃ¬ cÃ³ luáº­t BDE->A conf = 2/2 = 1 --> Ä‘Ã¢y lÃ  luáº­t káº¿t há»£p Link chi tiáº¿t bÃ i lÃ m e Ä‘á»ƒ trong google docs mn cÃ³ thá»ƒ xem qua vÃ  cho e Ã½ kiáº¿n Ä‘Æ°á»£c khÃ´ng áº¡ ? Sau khi tÃ¬m Ä‘Æ°á»£c cÃ¡c luáº­t phá»• biáº¿n thÃ¬ cÃ³ cáº§n loáº¡i bá» trÃ¹ng láº·p khÃ´ng ? Em cáº£m Æ¡n!,,,#Q&A,,
"Cho mÃ¬nh há»i cÃ³ ai hiá»ƒu cÃ¡ch diá»…n giáº£i cá»§a tÃ¡c giáº£ Ä‘á»ƒ Ä‘i Ä‘áº¿n káº¿t luáº­n P[R]>epsilon á»Ÿ dÃ²ng cuá»‘i ko váº­y?
TÃªn sÃ¡ch: Foundation of machine learning, MIT press. SÃ¡ch cÃ³ báº£n free online.","Cho mÃ¬nh há»i cÃ³ ai hiá»ƒu cÃ¡ch diá»…n giáº£i cá»§a tÃ¡c giáº£ Ä‘á»ƒ Ä‘i Ä‘áº¿n káº¿t luáº­n P[R]>epsilon á»Ÿ dÃ²ng cuá»‘i ko váº­y? TÃªn sÃ¡ch: Foundation of machine learning, MIT press. SÃ¡ch cÃ³ báº£n free online.",,,"#Q&A, #machine_learning",,
"Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang thá»±c hiá»‡n má»™t Ä‘á» tÃ i nhÆ° sau: XÃ¢y dá»±ng chatbot tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n lÄ©nh vá»±c Luáº­t. VÃ­ dá»¥ khi Ä‘áº·t cÃ¢u há»i ""Cháº¡y xe mÃ¡y vÆ°á»£t Ä‘Ã¨n Ä‘á» sáº½ bá»‹ pháº¡t bao nhiÃªu tiá»n?"" thÃ¬ chatbot sáº½ tráº£ lá»i cÃ¢u há»i Ä‘Ã³ Ä‘á»“ng thá»i cÃ³ thá»ƒ Ä‘Æ°a ra trÃ­ch dáº«n trong vÄƒn báº£n luáº­t.
Em Ä‘Ã£ cÃ³ bá»™ dá»¯ liá»‡u vá» cÃ¡c vÄƒn báº£n luáº­t khÃ¡ Ä‘áº§y Ä‘á»§ bao gá»“m cáº£ cÃ¡c thuá»™c tÃ­nh vá» hiá»‡u lá»±c, lÄ©nh vá»±c,.... Vá»›i bá»™ cÃ¢u há»i - cÃ¢u tráº£ lá»i em cÅ©ng Ä‘Ã£ thu tháº­p Ä‘Æ°á»£c lÆ°á»£ng dá»¯ liá»‡u Ä‘á»§ lá»›n (100k) Ä‘á»ƒ sáºµn sÃ ng traning.
VÃ¬ kiáº¿n thá»©c vá» AI cá»§a em khÃ¡ háº¡n cháº¿, má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu nÃªn e xin Ä‘Æ°á»£c tham kháº£o Ã½ kiáº¿n vá» cÃ¡c váº¥n Ä‘á» sau áº¡:
Em cÃ³ nháº­n Ä‘Æ°á»£c lá»i khuyÃªn lÃ  sá»­ dá»¥ng NLP, ML Ä‘á»ƒ xá»­ lÃ½ cÃ¢u há»i Ä‘áº§u vÃ o theo cÃ¡c tá»« Ä‘á»“ng nghÄ©a vÃ  xÃ¢y dá»±ng máº¡ng Ontology Ä‘á»ƒ Ã¡nh xáº¡ cÃ¢u há»i ngÆ°á»i dÃ¹ng vÃ  tiáº¿n hÃ nh tráº£ lá»i. Em xin há»i liá»‡u Ä‘Ã¢y cÃ³ pháº£i lÃ  má»™t cÃ¡ch tá»‘i Æ°u cho bÃ i toÃ¡n trÃªn khÃ´ng áº¡? Náº¿u cÃ³ cÃ¡ch khÃ¡c thÃ¬ em xin nghe Ä‘á» xuáº¥t áº¡?
Äá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c chatbot theo yÃªu cáº§u Ä‘á» bÃ i em nÃªn há»c vÃ  sá»­ dá»¥ng cÃ´ng cá»¥ nÃ o áº¡? Em xin cÃ¡c keyword vá» báº¥t cá»© cá»© thá»© gÃ¬ cÃ³ thá»ƒ coi lÃ  há»¯u Ã­ch cho bÃ i toÃ¡n trÃªn: link, model, framework, document,...
Em xin cáº£m Æ¡n cÃ¡c tÆ° váº¥n áº¡ <3","Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang thá»±c hiá»‡n má»™t Ä‘á» tÃ i nhÆ° sau: XÃ¢y dá»±ng chatbot tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n lÄ©nh vá»±c Luáº­t. VÃ­ dá»¥ khi Ä‘áº·t cÃ¢u há»i ""Cháº¡y xe mÃ¡y vÆ°á»£t Ä‘Ã¨n Ä‘á» sáº½ bá»‹ pháº¡t bao nhiÃªu tiá»n?"" thÃ¬ chatbot sáº½ tráº£ lá»i cÃ¢u há»i Ä‘Ã³ Ä‘á»“ng thá»i cÃ³ thá»ƒ Ä‘Æ°a ra trÃ­ch dáº«n trong vÄƒn báº£n luáº­t. Em Ä‘Ã£ cÃ³ bá»™ dá»¯ liá»‡u vá» cÃ¡c vÄƒn báº£n luáº­t khÃ¡ Ä‘áº§y Ä‘á»§ bao gá»“m cáº£ cÃ¡c thuá»™c tÃ­nh vá» hiá»‡u lá»±c, lÄ©nh vá»±c,.... Vá»›i bá»™ cÃ¢u há»i - cÃ¢u tráº£ lá»i em cÅ©ng Ä‘Ã£ thu tháº­p Ä‘Æ°á»£c lÆ°á»£ng dá»¯ liá»‡u Ä‘á»§ lá»›n (100k) Ä‘á»ƒ sáºµn sÃ ng traning. VÃ¬ kiáº¿n thá»©c vá» AI cá»§a em khÃ¡ háº¡n cháº¿, má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu nÃªn e xin Ä‘Æ°á»£c tham kháº£o Ã½ kiáº¿n vá» cÃ¡c váº¥n Ä‘á» sau áº¡: Em cÃ³ nháº­n Ä‘Æ°á»£c lá»i khuyÃªn lÃ  sá»­ dá»¥ng NLP, ML Ä‘á»ƒ xá»­ lÃ½ cÃ¢u há»i Ä‘áº§u vÃ o theo cÃ¡c tá»« Ä‘á»“ng nghÄ©a vÃ  xÃ¢y dá»±ng máº¡ng Ontology Ä‘á»ƒ Ã¡nh xáº¡ cÃ¢u há»i ngÆ°á»i dÃ¹ng vÃ  tiáº¿n hÃ nh tráº£ lá»i. Em xin há»i liá»‡u Ä‘Ã¢y cÃ³ pháº£i lÃ  má»™t cÃ¡ch tá»‘i Æ°u cho bÃ i toÃ¡n trÃªn khÃ´ng áº¡? Náº¿u cÃ³ cÃ¡ch khÃ¡c thÃ¬ em xin nghe Ä‘á» xuáº¥t áº¡? Äá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c chatbot theo yÃªu cáº§u Ä‘á» bÃ i em nÃªn há»c vÃ  sá»­ dá»¥ng cÃ´ng cá»¥ nÃ o áº¡? Em xin cÃ¡c keyword vá» báº¥t cá»© cá»© thá»© gÃ¬ cÃ³ thá»ƒ coi lÃ  há»¯u Ã­ch cho bÃ i toÃ¡n trÃªn: link, model, framework, document,... Em xin cáº£m Æ¡n cÃ¡c tÆ° váº¥n áº¡ <3",,,"#Q&A, #nlp",,
Em Ä‘ang lÃ m vá» summarize sá»­ dá»¥ng model LongT5. Em Ä‘ang muá»‘n thÃªm 1 block reattention vÃ o sau block self-attention Ä‘áº§u tiÃªn cá»§a pháº§n encoder. MÃ  Ä‘ang gáº·p lá»—i ReAttentionBlock.forward() got an unexpected keyword argument 'attention_mask' ai cÃ³ hÆ°á»›ng solve giÃºp em vá»›i áº¡. Em cáº£m Æ¡n,Em Ä‘ang lÃ m vá» summarize sá»­ dá»¥ng model LongT5. Em Ä‘ang muá»‘n thÃªm 1 block reattention vÃ o sau block self-attention Ä‘áº§u tiÃªn cá»§a pháº§n encoder. MÃ  Ä‘ang gáº·p lá»—i ReAttentionBlock.forward() got an unexpected keyword argument 'attention_mask' ai cÃ³ hÆ°á»›ng solve giÃºp em vá»›i áº¡. Em cáº£m Æ¡n,,,"#Q&A, #deep_learing",,
"[fun little maths for ML][7-grade maths is enough to solve]
Count the number of non-increasing INDICATOR functions from the domain of n distinct real numbers (n is a positive integer) to {0,1}?
a) 2^n
b) 2n+1
c) n
d) n+ 1
e) Infinitely many
f) uncountable
Má»i cÃ¡c báº¡n suy nghÄ© vÃ  cho Ä‘Ã¡p Ã¡n ğŸ¤”","[fun little maths for ML][7-grade maths is enough to solve] Count the number of non-increasing INDICATOR functions from the domain of n distinct real numbers (n is a positive integer) to {0,1}? a) 2^n b) 2n+1 c) n d) n+ 1 e) Infinitely many f) uncountable Má»i cÃ¡c báº¡n suy nghÄ© vÃ  cho Ä‘Ã¡p Ã¡n",,,,,
"[Há»i Ä‘Ã¡p Ã¢m thanh]
Em xin chÃ o má»i ngÆ°á»i.
Hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» Ä‘á» tÃ i xÃ¡c Ä‘á»‹nh Ä‘á»™ng cÆ¡ bá»‹ lá»—i báº±ng Ã¢m thanh.
VÃ¬ Ä‘á»™ng cÆ¡ lá»—i khÃ¡ Ã­t nÃªn táº­p dá»¯ liá»‡u cá»§a em chá»‰ Ä‘a sá»‘ lÃ  Ã¢m thanh vá» Ä‘á»™ng cÆ¡ bÃ¬nh thÆ°á»ng dÃ i khoáº£ng 0.4 giÃ¢y áº¡.
Cho nÃªn em hiá»‡n táº¡i Ä‘ang giáº£i quyáº¿t bÃ i toÃ¡n theo hÆ°á»›ng Anomaly Detection vá»›i 3 cÃ¡ch nhÆ° sau:
CÃ¡ch 1: Em trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng MFCC vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh LSTM-Autoencode Ä‘á»ƒ phÃ¢n biá»‡t normal, abnormal dá»±a trÃªn Loss cá»§a predict vá»›i input.
CÃ¡ch 2: Em láº¥y hÃ¬nh áº£nh Log-Mel-Spectrogram vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh CNN-Autoencode cÅ©ng Ä‘á»ƒ phÃ¢n biá»‡t normal vÃ  abnormal dá»±a trÃªn loss vá»›i Ä‘áº§u vÃ o.
NhÆ°ng káº¿t quáº£ trÃªn táº­p test cá»§a 2 cÃ¡ch nÃ y bá»‹ sai ráº¥t nhiá»u áº¡. VÃ  em nghÄ© nguyÃªn nhÃ¢n lÃ  do em trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng chÆ°a phÃ¹ há»£p áº¡.
Cho nÃªn sau khi tham kháº£o cÃ¡c paper thÃ¬ em trÃ­ch xuáº¥t nhá»¯ng Ä‘áº·c trÆ°ng sau: chorma, energy, spectral, rolloff, zero crossing, MFCC. Äá»‘i vá»›i má»—i loáº¡i Ä‘áº·c trÆ°ng thÃ¬ em láº¥y mean vÃ  var thÃ¬ Ä‘Æ°á»£c 69 chiá»u cho má»—i file Ã¢m thanh. Sau Ä‘Ã³ sá»­ dá»¥ng mÃ´ hÃ¬nh One-Class-SVM Ä‘á»ƒ phÃ¢n loáº¡i thÃ¬ tháº¥y káº¿t quáº£ cÃ³ váº» kháº£ quan hÆ¡n Ä‘Æ°á»£c tÃ½ nhÆ°ng váº«n loáº¡i sai khÃ¡ nhiá»u áº¡.
Em muá»‘n há»i lÃ  Ä‘á»‘i vá»›i Ã¢m thanh vá» tiáº¿ng á»“n cá»§a Ä‘á»™ng cÆ¡ nhÆ° nÃ y thÃ¬ mÃ¬nh nÃªn sá»­ dá»¥ng Ä‘áº·c trÆ°ng nÃ o cá»§a Ã¢m thanh vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh gÃ¬ ML/DL gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c váº­y áº¡ :(
DÆ°á»›i Ä‘Ã¢y lÃ  dá»¯ liá»‡u Ã¢m thanh cá»§a em áº¡.
https://drive.google.com/drive/folders/171Y5_W7L6-v1dwDp9HB430fQYJeTwF9n?usp=sharing","[Há»i Ä‘Ã¡p Ã¢m thanh] Em xin chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» Ä‘á» tÃ i xÃ¡c Ä‘á»‹nh Ä‘á»™ng cÆ¡ bá»‹ lá»—i báº±ng Ã¢m thanh. VÃ¬ Ä‘á»™ng cÆ¡ lá»—i khÃ¡ Ã­t nÃªn táº­p dá»¯ liá»‡u cá»§a em chá»‰ Ä‘a sá»‘ lÃ  Ã¢m thanh vá» Ä‘á»™ng cÆ¡ bÃ¬nh thÆ°á»ng dÃ i khoáº£ng 0.4 giÃ¢y áº¡. Cho nÃªn em hiá»‡n táº¡i Ä‘ang giáº£i quyáº¿t bÃ i toÃ¡n theo hÆ°á»›ng Anomaly Detection vá»›i 3 cÃ¡ch nhÆ° sau: CÃ¡ch 1: Em trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng MFCC vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh LSTM-Autoencode Ä‘á»ƒ phÃ¢n biá»‡t normal, abnormal dá»±a trÃªn Loss cá»§a predict vá»›i input. CÃ¡ch 2: Em láº¥y hÃ¬nh áº£nh Log-Mel-Spectrogram vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh CNN-Autoencode cÅ©ng Ä‘á»ƒ phÃ¢n biá»‡t normal vÃ  abnormal dá»±a trÃªn loss vá»›i Ä‘áº§u vÃ o. NhÆ°ng káº¿t quáº£ trÃªn táº­p test cá»§a 2 cÃ¡ch nÃ y bá»‹ sai ráº¥t nhiá»u áº¡. VÃ  em nghÄ© nguyÃªn nhÃ¢n lÃ  do em trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng chÆ°a phÃ¹ há»£p áº¡. Cho nÃªn sau khi tham kháº£o cÃ¡c paper thÃ¬ em trÃ­ch xuáº¥t nhá»¯ng Ä‘áº·c trÆ°ng sau: chorma, energy, spectral, rolloff, zero crossing, MFCC. Äá»‘i vá»›i má»—i loáº¡i Ä‘áº·c trÆ°ng thÃ¬ em láº¥y mean vÃ  var thÃ¬ Ä‘Æ°á»£c 69 chiá»u cho má»—i file Ã¢m thanh. Sau Ä‘Ã³ sá»­ dá»¥ng mÃ´ hÃ¬nh One-Class-SVM Ä‘á»ƒ phÃ¢n loáº¡i thÃ¬ tháº¥y káº¿t quáº£ cÃ³ váº» kháº£ quan hÆ¡n Ä‘Æ°á»£c tÃ½ nhÆ°ng váº«n loáº¡i sai khÃ¡ nhiá»u áº¡. Em muá»‘n há»i lÃ  Ä‘á»‘i vá»›i Ã¢m thanh vá» tiáº¿ng á»“n cá»§a Ä‘á»™ng cÆ¡ nhÆ° nÃ y thÃ¬ mÃ¬nh nÃªn sá»­ dá»¥ng Ä‘áº·c trÆ°ng nÃ o cá»§a Ã¢m thanh vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh gÃ¬ ML/DL gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c váº­y áº¡ :( DÆ°á»›i Ä‘Ã¢y lÃ  dá»¯ liá»‡u Ã¢m thanh cá»§a em áº¡. https://drive.google.com/drive/folders/171Y5_W7L6-v1dwDp9HB430fQYJeTwF9n?usp=sharing",,,#Q&A,,
"Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang thá»­ cháº¡y code cÃ³ sá»­ dá»¥ng GPU VGA GIGABYTE GeForce RTX 3060 GAMING OC 12G (rev. 2.0) (GV-N3060GAMING OC-12GD) trÃªn há»‡ Ä‘iá»u hÃ nh Ubuntu 20.04. Tuy nhiÃªn, khi em cÃ i cuda thÃ¬ hiá»‡n lÃªn thÃ´ng bÃ¡o khÃ´ng tÆ°Æ¡ng thÃ­ch. Má»i ngÆ°á»i cÃ³ thá»ƒ giá»£i Ã½ cho em báº£n cuda nÃ o tÆ°Æ¡ng thÃ­ch vá»›i mÃ¡y vá»›i áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i.
Báº£n mÃ  em thá»­ táº£i áº¡
https://linuxhint.com/install-cuda-ubuntu-2004/?fbclid=IwAR20YUODljBjdtVzyocI1wQeVpM-HaZID5RZ9VFcQl73DB3ueq4jPwmkYTQ
Lá»—i mÃ  mÃ¡y em hiá»‡n lÃªn áº¡:","Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang thá»­ cháº¡y code cÃ³ sá»­ dá»¥ng GPU VGA GIGABYTE GeForce RTX 3060 GAMING OC 12G (rev. 2.0) (GV-N3060GAMING OC-12GD) trÃªn há»‡ Ä‘iá»u hÃ nh Ubuntu 20.04. Tuy nhiÃªn, khi em cÃ i cuda thÃ¬ hiá»‡n lÃªn thÃ´ng bÃ¡o khÃ´ng tÆ°Æ¡ng thÃ­ch. Má»i ngÆ°á»i cÃ³ thá»ƒ giá»£i Ã½ cho em báº£n cuda nÃ o tÆ°Æ¡ng thÃ­ch vá»›i mÃ¡y vá»›i áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i. Báº£n mÃ  em thá»­ táº£i áº¡ https://linuxhint.com/install-cuda-ubuntu-2004/?fbclid=IwAR20YUODljBjdtVzyocI1wQeVpM-HaZID5RZ9VFcQl73DB3ueq4jPwmkYTQ Lá»—i mÃ  mÃ¡y em hiá»‡n lÃªn áº¡:",,,"#Q&A, #python",,
"Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang há»c mÃ´n há»c mÃ¡y, vÃ  hiá»‡n táº¡i em Ä‘ang cÃ³ máº¥y bÃ i táº­p nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y áº¡. Em Ä‘ang cá»‘ gáº¯ng tÃ¬m hiá»ƒu hÆ°á»›ng giáº£i cÅ©ng nhÆ° cÃ¡ch trÃ¬nh bÃ y sao cho chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ nhÆ°ng hiá»‡n táº¡i em váº«n chÆ°a nghÄ© Ä‘Æ°á»£c cÃ¡ch giáº£i quyáº¿t áº¡.
Náº¿u ai cÃ³ cÃ¡ch hay hÆ°á»›ng giáº£i bÃ i nÃ o thÃ¬ cho em xin vá»›i áº¡. Em cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang há»c mÃ´n há»c mÃ¡y, vÃ  hiá»‡n táº¡i em Ä‘ang cÃ³ máº¥y bÃ i táº­p nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y áº¡. Em Ä‘ang cá»‘ gáº¯ng tÃ¬m hiá»ƒu hÆ°á»›ng giáº£i cÅ©ng nhÆ° cÃ¡ch trÃ¬nh bÃ y sao cho chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ nhÆ°ng hiá»‡n táº¡i em váº«n chÆ°a nghÄ© Ä‘Æ°á»£c cÃ¡ch giáº£i quyáº¿t áº¡. Náº¿u ai cÃ³ cÃ¡ch hay hÆ°á»›ng giáº£i bÃ i nÃ o thÃ¬ cho em xin vá»›i áº¡. Em cáº£m Æ¡n áº¡.",,,"#Q&A, #machine_learning",,
"CÃ¡c báº¡n vui lÃ²ng post thÃ´ng tin tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2023 vÃ o pháº§n comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng post thÃ´ng tin tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2023 vÃ o pháº§n comment cá»§a post nÃ y.",,,#sharing,,
"Em chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ tháº¯c máº¯c lÃ  liá»‡u NLP cÃ³ pháº£i lÃ  subset cá»§a ML kh mng. Táº¡i theo em tÃ¬m hiá»ƒu thÃ¬ NLP giÃºp mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu, xá»­ lÃ½ dc natural language nhÆ°ng mÃ  Ä‘á»ƒ Ä‘áº¡t dc quÃ¡ trÃ¬nh Ä‘Ã³ nhÆ° sdung POS cÃ³ thá»ƒ giÃºp nháº­n Ä‘á»‹nh dc tá»« loáº¡i cá»§a cá»§a 1 tá»« nhÆ° noun, verb,... thÃ¬ pháº£i dÃ¹ng ML Ä‘á»ƒ label hay sao áº¡.
Em cáº£m Æ¡n mng","Em chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ tháº¯c máº¯c lÃ  liá»‡u NLP cÃ³ pháº£i lÃ  subset cá»§a ML kh mng. Táº¡i theo em tÃ¬m hiá»ƒu thÃ¬ NLP giÃºp mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu, xá»­ lÃ½ dc natural language nhÆ°ng mÃ  Ä‘á»ƒ Ä‘áº¡t dc quÃ¡ trÃ¬nh Ä‘Ã³ nhÆ° sdung POS cÃ³ thá»ƒ giÃºp nháº­n Ä‘á»‹nh dc tá»« loáº¡i cá»§a cá»§a 1 tá»« nhÆ° noun, verb,... thÃ¬ pháº£i dÃ¹ng ML Ä‘á»ƒ label hay sao áº¡. Em cáº£m Æ¡n mng",,,"#Q&A, #nlp",,
"Xin chÃ o cáº£ nhÃ , team VILM Ä‘Ã£ chÃ­nh thá»©c trá»Ÿ láº¡i vá»›i má»™t model má»›i toanh :-P
ğŸš€ğŸš€ğŸš€Obsidian-3B: Multimodal for Everyone. ÄÆ°á»£c xÃ¢y dá»±ng trÃªn mÃ´ hÃ¬nh NousCapyabra-3B dá»±a trÃªn StableLM-3B-4e1t.
Obsidian-3B lÃ  káº¿t quáº£ cá»§a sá»± káº¿t há»£p giá»¯a Nous Research (Má»¹) vÃ  VILM vá»›i má»¥c tiÃªu Ä‘Æ°a Multimodal Ä‘áº¿n vá»›i táº¥t cáº£ má»i ngÆ°á»i.
MÃ´ hÃ¬nh cÃ³ thá»ƒ cháº¡y trÃªn báº¥t kÃ¬ GPU nÃ o cÃ³ VRAM 8GB trá»Ÿ lÃªn.
Vá» káº¿t quáº£ benchmark: Obsidian-3B Ä‘Ã¡nh báº¡i hoáº·c ngang hÃ ng LLaVA 1.5 7B cá»§a nhÃ  Microsoft vá»›i Ä‘iá»ƒm sá»‘ áº¥n tÆ°á»£ng trÃªn cÃ¡c bÃ i Benchmark vá» Vision Language
NgoÃ i ra team Ä‘Ã£ chÃ­nh thá»©c ra máº·t Discord server Ä‘á»ƒ khá»Ÿi Ä‘á»™ng cÃ¡c dá»± Ã¡n tiáº¿p theo vá»›i cá»™ng Ä‘á»“ng, Ä‘áº·c biá»‡t lÃ  phiÃªn báº£n Vietcuna vÃ  multimodal tháº¿ há»‡ tiáº¿p theo. Mong má»i ngÆ°á»i sáº½ tham gia vÃ  xÃ¢y dá»±ng má»™t cá»™ng Ä‘á»“ng AI Open-Source lá»›n máº¡nh cá»§a ngÆ°á»i Viá»‡t :)
Discord: https://discord.gg/uyhnuF9ncf
Model link: https://huggingface.co/NousResearch/Obsidian-3B-V0.5
Inference code: https://github.com/NousResearch/Obsidian

ChÃºc má»i ngÆ°á»i má»™t buá»•i tá»‘i vui váº»!","Xin chÃ o cáº£ nhÃ , team VILM Ä‘Ã£ chÃ­nh thá»©c trá»Ÿ láº¡i vá»›i má»™t model má»›i toanh :-P Obsidian-3B: Multimodal for Everyone. ÄÆ°á»£c xÃ¢y dá»±ng trÃªn mÃ´ hÃ¬nh NousCapyabra-3B dá»±a trÃªn StableLM-3B-4e1t. Obsidian-3B lÃ  káº¿t quáº£ cá»§a sá»± káº¿t há»£p giá»¯a Nous Research (Má»¹) vÃ  VILM vá»›i má»¥c tiÃªu Ä‘Æ°a Multimodal Ä‘áº¿n vá»›i táº¥t cáº£ má»i ngÆ°á»i. MÃ´ hÃ¬nh cÃ³ thá»ƒ cháº¡y trÃªn báº¥t kÃ¬ GPU nÃ o cÃ³ VRAM 8GB trá»Ÿ lÃªn. Vá» káº¿t quáº£ benchmark: Obsidian-3B Ä‘Ã¡nh báº¡i hoáº·c ngang hÃ ng LLaVA 1.5 7B cá»§a nhÃ  Microsoft vá»›i Ä‘iá»ƒm sá»‘ áº¥n tÆ°á»£ng trÃªn cÃ¡c bÃ i Benchmark vá» Vision Language NgoÃ i ra team Ä‘Ã£ chÃ­nh thá»©c ra máº·t Discord server Ä‘á»ƒ khá»Ÿi Ä‘á»™ng cÃ¡c dá»± Ã¡n tiáº¿p theo vá»›i cá»™ng Ä‘á»“ng, Ä‘áº·c biá»‡t lÃ  phiÃªn báº£n Vietcuna vÃ  multimodal tháº¿ há»‡ tiáº¿p theo. Mong má»i ngÆ°á»i sáº½ tham gia vÃ  xÃ¢y dá»±ng má»™t cá»™ng Ä‘á»“ng AI Open-Source lá»›n máº¡nh cá»§a ngÆ°á»i Viá»‡t :) Discord: https://discord.gg/uyhnuF9ncf Model link: https://huggingface.co/NousResearch/Obsidian-3B-V0.5 Inference code: https://github.com/NousResearch/Obsidian ChÃºc má»i ngÆ°á»i má»™t buá»•i tá»‘i vui váº»!",,,#sharing,,
"Meta/Facebook Research gáº§n Ä‘Ã¢y cÃ´ng bá»‘ Cookbook cho viá»‡c train vÃ  finetune cÃ¡c biáº¿n thá»ƒ dá»±a trÃªn mÃ´ hÃ¬nh LLaMA táº¡i Ä‘Ã¢y https://ai.meta.com/llama/get-started/; code base táº¡i Ä‘Ã¢y https://github.com/facebookresearch/llama-recipes.
Hi vá»ng nÃ³ sáº½ giÃºp Ã­ch má»i ngÆ°á»i trong cÃ´ng viá»‡c",Meta/Facebook Research gáº§n Ä‘Ã¢y cÃ´ng bá»‘ Cookbook cho viá»‡c train vÃ  finetune cÃ¡c biáº¿n thá»ƒ dá»±a trÃªn mÃ´ hÃ¬nh LLaMA táº¡i Ä‘Ã¢y https://ai.meta.com/llama/get-started/; code base táº¡i Ä‘Ã¢y https://github.com/facebookresearch/llama-recipes. Hi vá»ng nÃ³ sáº½ giÃºp Ã­ch má»i ngÆ°á»i trong cÃ´ng viá»‡c,,,"#sharing, #nlp",,
"Xin chÃ o má»i ngÆ°á»i, em Ä‘ang táº­p dÃ¹ng thá»­ ""Mechine learning Studio"" cá»§a Azure. Äáº¿n cÃ´ng Ä‘oáº¡n táº¡o Real time Endpoints Ä‘á»ƒ dÃ¹ng model tá»« API. Há»‡ thá»‘ng Ä‘á»u bÃ¡o cháº¡y á»•n, tuy nhiÃªn, má»¥c test thá»­ thÃ¬ toÃ n bÃ¡o lá»—i ""an unexpected error occurred in scoring script. check the logs for more info"". MN ai Ä‘Ã£ fix Ä‘Æ°á»£c lá»—i nÃ y giÃºp mÃ¬nh vá»›i áº¡","Xin chÃ o má»i ngÆ°á»i, em Ä‘ang táº­p dÃ¹ng thá»­ ""Mechine learning Studio"" cá»§a Azure. Äáº¿n cÃ´ng Ä‘oáº¡n táº¡o Real time Endpoints Ä‘á»ƒ dÃ¹ng model tá»« API. Há»‡ thá»‘ng Ä‘á»u bÃ¡o cháº¡y á»•n, tuy nhiÃªn, má»¥c test thá»­ thÃ¬ toÃ n bÃ¡o lá»—i ""an unexpected error occurred in scoring script. check the logs for more info"". MN ai Ä‘Ã£ fix Ä‘Æ°á»£c lá»—i nÃ y giÃºp mÃ¬nh vá»›i áº¡",,,#Q&A,,
BÃ  con thá»­ SFT con nÃ y xem cÃ³ á»•n khÃ´ng? Náº¿u á»•n thÃ¬ Ä‘á»ƒ nhÃ³m train tiáº¿p vÃ i trÄƒm GB bÃ  con thá»­ ná»‘t.,BÃ  con thá»­ SFT con nÃ y xem cÃ³ á»•n khÃ´ng? Náº¿u á»•n thÃ¬ Ä‘á»ƒ nhÃ³m train tiáº¿p vÃ i trÄƒm GB bÃ  con thá»­ ná»‘t.,,,#sharing,,
"Em chÃ o má»i ngÆ°á»i áº¡, cÃ³ ai gáº§n Ä‘Ã¢y train paddleocr khÃ´ng áº¡ ? cho em há»i má»™t chÃºt :(( chá»© em cáº£ ngÃ y hÃ´m qua vá»›i nay báº¥t lá»±c quÃ¡. Chuyá»‡n lÃ  em cÃ³ cÃ i paddlepaddle-gpu báº£n 2.5.1 cho cuda 11.8, (cuda trÃªn mÃ¡y cÅ©ng Ä‘Ã£ cÃ i 11.8 ) cháº¡y paddle Ä‘Ã£ á»•n nhÆ°ng khÃ´ng lÃ m sao train Ä‘Æ°á»£c. NÃ³ cá»© vÃ o load train nhÆ° áº£nh lÃ  láº¡i khÃ´ng cháº¡y tiáº¿p ná»¯a. em Ä‘Ã£ thá»­ 2 báº£n python 3.7 vÃ  3.10 nhÆ°ng Ä‘á»u nhÆ° nhau. Em cÅ©ng Ä‘Ã£ giáº£m batchsize xuá»‘ng tá»« 128 xuá»‘ng 64, 32 rá»“i nhÆ°ng bá»‹ lá»—i nÃ y hiá»‡n lÃªn. Fomat data thÃ¬ cháº¯c khÃ´ng váº¥n Ä‘á», vÃ¬ em Ä‘Ã£ load vÃ  train Ä‘c trÃªn colab. Paddle cÅ©ng Ä‘Ã£ cÃ i á»•n nhÆ° trÃªn hÃ¬nh áº¡. Em cáº£m Æ¡n vÃ¬ Ä‘Ã£ Ä‘á»c.","Em chÃ o má»i ngÆ°á»i áº¡, cÃ³ ai gáº§n Ä‘Ã¢y train paddleocr khÃ´ng áº¡ ? cho em há»i má»™t chÃºt :(( chá»© em cáº£ ngÃ y hÃ´m qua vá»›i nay báº¥t lá»±c quÃ¡. Chuyá»‡n lÃ  em cÃ³ cÃ i paddlepaddle-gpu báº£n 2.5.1 cho cuda 11.8, (cuda trÃªn mÃ¡y cÅ©ng Ä‘Ã£ cÃ i 11.8 ) cháº¡y paddle Ä‘Ã£ á»•n nhÆ°ng khÃ´ng lÃ m sao train Ä‘Æ°á»£c. NÃ³ cá»© vÃ o load train nhÆ° áº£nh lÃ  láº¡i khÃ´ng cháº¡y tiáº¿p ná»¯a. em Ä‘Ã£ thá»­ 2 báº£n python 3.7 vÃ  3.10 nhÆ°ng Ä‘á»u nhÆ° nhau. Em cÅ©ng Ä‘Ã£ giáº£m batchsize xuá»‘ng tá»« 128 xuá»‘ng 64, 32 rá»“i nhÆ°ng bá»‹ lá»—i nÃ y hiá»‡n lÃªn. Fomat data thÃ¬ cháº¯c khÃ´ng váº¥n Ä‘á», vÃ¬ em Ä‘Ã£ load vÃ  train Ä‘c trÃªn colab. Paddle cÅ©ng Ä‘Ã£ cÃ i á»•n nhÆ° trÃªn hÃ¬nh áº¡. Em cáº£m Æ¡n vÃ¬ Ä‘Ã£ Ä‘á»c.",,,#Q&A,,
"Em chÃ o cáº£ nhÃ  áº¡. Máº¥y thá»i gian qua em cÃ³ tá»± build má»™t cÃ¡i app cho phÃ©p ngÆ°á»i dÃ¹ng thÃªm sáº£n pháº©m vÃ  tracking ngÃ y háº¿t háº¡n cá»§a sáº£n pháº©m Ä‘Ã³. ÄÆ¡n giáº£n thÃ¬ nÃ³ giá»‘ng má»™t cÃ¡i todos-list mÃ  dÃ nh cho máº¥y Ä‘á»“ thá»±c pháº©m áº¥y áº¡. Äiá»ƒm nháº¥n á»Ÿ Ä‘Ã¢y lÃ  em cÃ³ sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ nháº­n diá»‡n thá»±c pháº©m vÃ  Ä‘á» xuáº¥t ngÃ y háº¿t háº¡n tÆ°Æ¡ng á»©ng. App hiá»‡n táº¡i Ä‘Ã£ lÃªn iOS vÃ  Android
https://apps.apple.com/vn/app/rappel-fresh-time-tracker/id6468539329
https://play.google.com/store/apps/details?id=com.tbsteam.rappel
Mong má»i ngÆ°á»i cÃ³ thá»ƒ táº£i vá» tráº£i nghiá»‡m thá»­ vÃ  feedback Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u quáº£ cá»§a model, vÃ  ai cÃ³ Ä‘Ã³ng gÃ³p Ä‘á»ƒ cáº£i thiá»‡n app nÃ³i chung thÃ¬ cÃ ng tuyá»‡t vá»i ná»¯a áº¡.
ChÃºc cáº£ nhÃ  cuá»‘i tuáº§n vui váº» áº¡!! :)","Em chÃ o cáº£ nhÃ  áº¡. Máº¥y thá»i gian qua em cÃ³ tá»± build má»™t cÃ¡i app cho phÃ©p ngÆ°á»i dÃ¹ng thÃªm sáº£n pháº©m vÃ  tracking ngÃ y háº¿t háº¡n cá»§a sáº£n pháº©m Ä‘Ã³. ÄÆ¡n giáº£n thÃ¬ nÃ³ giá»‘ng má»™t cÃ¡i todos-list mÃ  dÃ nh cho máº¥y Ä‘á»“ thá»±c pháº©m áº¥y áº¡. Äiá»ƒm nháº¥n á»Ÿ Ä‘Ã¢y lÃ  em cÃ³ sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ nháº­n diá»‡n thá»±c pháº©m vÃ  Ä‘á» xuáº¥t ngÃ y háº¿t háº¡n tÆ°Æ¡ng á»©ng. App hiá»‡n táº¡i Ä‘Ã£ lÃªn iOS vÃ  Android https://apps.apple.com/vn/app/rappel-fresh-time-tracker/id6468539329 https://play.google.com/store/apps/details?id=com.tbsteam.rappel Mong má»i ngÆ°á»i cÃ³ thá»ƒ táº£i vá» tráº£i nghiá»‡m thá»­ vÃ  feedback Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u quáº£ cá»§a model, vÃ  ai cÃ³ Ä‘Ã³ng gÃ³p Ä‘á»ƒ cáº£i thiá»‡n app nÃ³i chung thÃ¬ cÃ ng tuyá»‡t vá»i ná»¯a áº¡. ChÃºc cáº£ nhÃ  cuá»‘i tuáº§n vui váº» áº¡!! :)",,,#sharing,,
"Trong má»™t bÃ i viáº¿t nÃ o Ä‘Ã³ cá»§a má»™t báº¡n vá» Ä‘iá»n giÃ¡ trá»‹ bá»‹ thiáº¿u vÃ  ""Tuyá»‡t Ä‘á»‘i khÃ´ng Ä‘Æ°á»£c Ä‘iá»n giÃ¡ trá»‹ mean hoáº·c zero"" vÃ  nhÃ¢n tiá»‡n trong quÃ¡ trÃ¬nh tÃ¬m tÃ i liá»‡u Ä‘á»ƒ viáº¿t khÃ³a há»c mÃ¬nh cÃ³ tÃ¬m Ä‘Æ°á»£c cuá»‘n sÃ¡ch nÃ y vá» xá»­ lÃ½ dá»¯ liá»‡u bá»‹ thiáº¿u.
MÃ¬nh chia sáº» Ä‘á»‹a chá»‰ cuá»‘n sÃ¡ch nÃ y cho cÃ¡c báº¡n tÃ¬m hiá»ƒu thÃªm, vÃ  sau khi Ä‘á»c xong cÃ¡c báº¡n cÃ³ thá»ƒ rÃºt ra Ä‘Æ°á»£c cÃ³ nÃªn Ä‘iá»n mean vÃ o hay khÃ´ng?","Trong má»™t bÃ i viáº¿t nÃ o Ä‘Ã³ cá»§a má»™t báº¡n vá» Ä‘iá»n giÃ¡ trá»‹ bá»‹ thiáº¿u vÃ  ""Tuyá»‡t Ä‘á»‘i khÃ´ng Ä‘Æ°á»£c Ä‘iá»n giÃ¡ trá»‹ mean hoáº·c zero"" vÃ  nhÃ¢n tiá»‡n trong quÃ¡ trÃ¬nh tÃ¬m tÃ i liá»‡u Ä‘á»ƒ viáº¿t khÃ³a há»c mÃ¬nh cÃ³ tÃ¬m Ä‘Æ°á»£c cuá»‘n sÃ¡ch nÃ y vá» xá»­ lÃ½ dá»¯ liá»‡u bá»‹ thiáº¿u. MÃ¬nh chia sáº» Ä‘á»‹a chá»‰ cuá»‘n sÃ¡ch nÃ y cho cÃ¡c báº¡n tÃ¬m hiá»ƒu thÃªm, vÃ  sau khi Ä‘á»c xong cÃ¡c báº¡n cÃ³ thá»ƒ rÃºt ra Ä‘Æ°á»£c cÃ³ nÃªn Ä‘iá»n mean vÃ o hay khÃ´ng?",,,"#sharing, #data",,
"CÃ¡c anh/chá»‹/báº¡n Ä‘Ã£ cÃ³ ai lÃ m vá» tra cá»©u áº£nh tÆ°Æ¡ng tá»± dá»±a trÃªn ná»™i dung sá»­ dá»¥ng mÃ´ hÃ¬nh CNN chÆ°a áº¡.CÃ³ thá»ƒ cho em xin má»™t sá»‘ nguá»“n tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡.
Xin chÃ¢n thÃ nh cáº£m Æ¡n mn",CÃ¡c anh/chá»‹/báº¡n Ä‘Ã£ cÃ³ ai lÃ m vá» tra cá»©u áº£nh tÆ°Æ¡ng tá»± dá»±a trÃªn ná»™i dung sá»­ dá»¥ng mÃ´ hÃ¬nh CNN chÆ°a áº¡.CÃ³ thá»ƒ cho em xin má»™t sá»‘ nguá»“n tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Xin chÃ¢n thÃ nh cáº£m Æ¡n mn,,,"#Q&A, #deep_learning",,
"Dáº¡ em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang lÃ m nghiÃªn cá»©u vá» chá»§ Ä‘á» 3D reconstruction vÃ  cÃ³ gáº·p thuáº­t ngá»¯ UV mapping. Theo nhá»¯ng gÃ¬ em tÃ¬m hiá»ƒu thÃ¬ cÃ³ thá»ƒ hiá»ƒu UV map lÃ  hÃ¬nh áº£nh Ä‘Æ°á»£c ""Ä‘áº­p dáº¹p"" cá»§a má»™t mÃ´ hÃ¬nh 3D, cá»¥ thá»ƒ lÃ  gÆ°Æ¡ng máº·t. Náº¿u trong 3D space, má»—i Ä‘á»‰nh trÃªn 3D mesh cÃ³ toáº¡ Ä‘á»™ lÃ  (x,y,z) thÃ¬ trong khÃ´ng gian UV 2D thÃ¬ Ä‘á»‰nh Ä‘Ã³ cÃ³ toáº¡ Ä‘á»™ lÃ  (u,v). Tuy nhiÃªn, em váº«n cáº£m tháº¥y ráº¥t mÆ¡ há»“ vá» nÃ³, nhÆ° lÃ  lÃ m sao Ä‘á»ƒ visualize nÃ³ nhÆ° lÃ  má»™t hÃ¬nh áº£nh 2D hay lÃ  vá» máº·t toÃ¡n há»c thÃ¬ nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c biá»…u diá»…n nhÆ° tháº¿ nÃ o? (vÃ­ dá»¥ vá»›i hÃ¬nh áº£nh mÃ u 2D thÃ¬ nÃ³ lÃ  má»™t tensor width x height x 3 color channels). Do Ä‘Ã³ em máº¡n phÃ©p lÃªn Ä‘Ã¢y Ä‘á»ƒ nhá» cÃ¡c anh chá»‹ tháº§y cÃ´ trong group giÃºp em giáº£i Ä‘Ã¡p váº¥n Ä‘á» nÃ y áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n!","Dáº¡ em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang lÃ m nghiÃªn cá»©u vá» chá»§ Ä‘á» 3D reconstruction vÃ  cÃ³ gáº·p thuáº­t ngá»¯ UV mapping. Theo nhá»¯ng gÃ¬ em tÃ¬m hiá»ƒu thÃ¬ cÃ³ thá»ƒ hiá»ƒu UV map lÃ  hÃ¬nh áº£nh Ä‘Æ°á»£c ""Ä‘áº­p dáº¹p"" cá»§a má»™t mÃ´ hÃ¬nh 3D, cá»¥ thá»ƒ lÃ  gÆ°Æ¡ng máº·t. Náº¿u trong 3D space, má»—i Ä‘á»‰nh trÃªn 3D mesh cÃ³ toáº¡ Ä‘á»™ lÃ  (x,y,z) thÃ¬ trong khÃ´ng gian UV 2D thÃ¬ Ä‘á»‰nh Ä‘Ã³ cÃ³ toáº¡ Ä‘á»™ lÃ  (u,v). Tuy nhiÃªn, em váº«n cáº£m tháº¥y ráº¥t mÆ¡ há»“ vá» nÃ³, nhÆ° lÃ  lÃ m sao Ä‘á»ƒ visualize nÃ³ nhÆ° lÃ  má»™t hÃ¬nh áº£nh 2D hay lÃ  vá» máº·t toÃ¡n há»c thÃ¬ nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c biá»…u diá»…n nhÆ° tháº¿ nÃ o? (vÃ­ dá»¥ vá»›i hÃ¬nh áº£nh mÃ u 2D thÃ¬ nÃ³ lÃ  má»™t tensor width x height x 3 color channels). Do Ä‘Ã³ em máº¡n phÃ©p lÃªn Ä‘Ã¢y Ä‘á»ƒ nhá» cÃ¡c anh chá»‹ tháº§y cÃ´ trong group giÃºp em giáº£i Ä‘Ã¡p váº¥n Ä‘á» nÃ y áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n!",,,"#Q&A, #cv",,
"MÃ¬nh tháº¥y cÃ³ tutorials thÃº vá»‹, Ä‘áº·c biá»‡t lÃ  cho nhá»¯ng báº¡n quan tÃ¢m tá»›i Geostats cá»§a 1 giÃ¡o sÆ° á»Ÿ Äáº¡i há»c Texas at Autin nÃªn chia sáº» á»Ÿ Ä‘Ã¢y cho nhá»¯ng báº¡n cáº§n tÃ¬m hiá»ƒu https://github.com/GeostatsGuy/PythonNumericalDemos","MÃ¬nh tháº¥y cÃ³ tutorials thÃº vá»‹, Ä‘áº·c biá»‡t lÃ  cho nhá»¯ng báº¡n quan tÃ¢m tá»›i Geostats cá»§a 1 giÃ¡o sÆ° á»Ÿ Äáº¡i há»c Texas at Autin nÃªn chia sáº» á»Ÿ Ä‘Ã¢y cho nhá»¯ng báº¡n cáº§n tÃ¬m hiá»ƒu https://github.com/GeostatsGuy/PythonNumericalDemos",,,#sharing,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 10/2022 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 10/2022 vÃ o comment cá»§a post nÃ y.",,,#sharing,,
"Em chÃ o má»i ngÆ°á»i, Cho em há»i cÃ³ cÃ¡ch nÃ o dá»±ng 3d tá»« áº£nh Ä‘á»™ sÃ¢u káº¿t há»£p áº£nh 2d khÃ´ng áº¡. áº¢nh Ä‘á»™ sÃ¢u vÃ  2d em láº¥y tá»« Ä‘áº§u ra cá»§a camera intel d415. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin tÃ i liá»‡u hoáº·c nguá»“n thÃ´ng tin nÃ o liÃªn quan cÅ©ng Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n nhiá»u áº¡ ğŸ¥°","Em chÃ o má»i ngÆ°á»i, Cho em há»i cÃ³ cÃ¡ch nÃ o dá»±ng 3d tá»« áº£nh Ä‘á»™ sÃ¢u káº¿t há»£p áº£nh 2d khÃ´ng áº¡. áº¢nh Ä‘á»™ sÃ¢u vÃ  2d em láº¥y tá»« Ä‘áº§u ra cá»§a camera intel d415. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin tÃ i liá»‡u hoáº·c nguá»“n thÃ´ng tin nÃ o liÃªn quan cÅ©ng Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n nhiá»u áº¡",,,"#Q&A, #cv",,
Cao nhÃ¢n nÃ o tá»«ng lÃ m qua mÃ´ hÃ¬nh nháº­n diá»‡n bá»‡nh cho lÃ¡ cÃ¢y cho em xin dataset vá»›i áº¡. Em cáº£m Æ¡n!,Cao nhÃ¢n nÃ o tá»«ng lÃ m qua mÃ´ hÃ¬nh nháº­n diá»‡n bá»‡nh cho lÃ¡ cÃ¢y cho em xin dataset vá»›i áº¡. Em cáº£m Æ¡n!,,,"#Q&A, #data",,
"ChÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n,
Hiá»‡n nay em Ä‘ang lÃ m Ä‘á»“ Ã¡n mÃ´n há»c Xá»­ lÃ½ Ã¢m thanh vÃ  tiáº¿ng nÃ³i. Bá»n em chá»n Ä‘á» tÃ i Nháº­n dáº¡ng tiáº¿ng nÃ³i tá»± Ä‘á»™ng (ASR) sá»­ dá»¥ng mÃ´ hÃ¬nh Conformer káº¿t há»£p vá»›i Noisy Student Training. Trong quÃ¡ trÃ¬nh triá»ƒn khai bá»n em gáº·p má»™t sá»‘ váº¥n Ä‘á» mong nháº­n Ä‘Æ°á»£c sá»± Ä‘Ã³ng gÃ³p vÃ  giÃºp Ä‘á»¡ Ä‘áº¿n tá»« má»i ngÆ°á»i:
Váº¤N Äá»€ Vá»€ VIá»†C MÃ” Táº¢ Dá»® LIá»†U: má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u bá»n em sá»­ dá»¥ng lÃ  100h VLSP cá»§a VinAI cÃ´ng bá»‘ nhÆ°ng bá»n em khÃ´ng tÃ¬m tháº¥y mÃ´ táº£ bá»™ dá»¯ liá»‡u nÃ y.
Váº¤N Äá»€ Vá»€ TÃ€I NGUYÃŠN HUáº¤N LUYá»†N: Hiá»‡n táº¡i, vá»›i tÃ i nguyÃªn háº¡n cháº¿ vÃ  mÃ´ hÃ¬nh cÅ©ng khÃ¡ lá»›n nÃªn bá»n em chá»‰ má»›i dá»«ng láº¡i á»Ÿ má»©c character-level. Bá»n em mong muá»‘n huáº¥n luyá»‡n á»Ÿ má»©c Word-level nhÆ°ng láº¡i gáº·p khÃ³ khÄƒn trong viá»‡c thuÃª Colab Pro. Má»i ngÆ°á»i cho em há»i á»Ÿ nhÃ³m mÃ¬nh cÃ³ ai cho thuÃª Colab Pro thá»i gian ngáº¯n khÃ´ng áº¡ ( khoáº£ng dÆ°á»›i 1 thÃ¡ng ).
TrÃªn Ä‘Ã¢y lÃ  nhá»¯ng váº¥n Ä‘á» bá»n em gáº·p pháº£i, mong nháº­n Ä‘Æ°á»£c sá»± giáº£i Ä‘Ã¡p. Em xin cáº£m Æ¡n áº¡.","ChÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n, Hiá»‡n nay em Ä‘ang lÃ m Ä‘á»“ Ã¡n mÃ´n há»c Xá»­ lÃ½ Ã¢m thanh vÃ  tiáº¿ng nÃ³i. Bá»n em chá»n Ä‘á» tÃ i Nháº­n dáº¡ng tiáº¿ng nÃ³i tá»± Ä‘á»™ng (ASR) sá»­ dá»¥ng mÃ´ hÃ¬nh Conformer káº¿t há»£p vá»›i Noisy Student Training. Trong quÃ¡ trÃ¬nh triá»ƒn khai bá»n em gáº·p má»™t sá»‘ váº¥n Ä‘á» mong nháº­n Ä‘Æ°á»£c sá»± Ä‘Ã³ng gÃ³p vÃ  giÃºp Ä‘á»¡ Ä‘áº¿n tá»« má»i ngÆ°á»i: Váº¤N Äá»€ Vá»€ VIá»†C MÃ” Táº¢ Dá»® LIá»†U: má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u bá»n em sá»­ dá»¥ng lÃ  100h VLSP cá»§a VinAI cÃ´ng bá»‘ nhÆ°ng bá»n em khÃ´ng tÃ¬m tháº¥y mÃ´ táº£ bá»™ dá»¯ liá»‡u nÃ y. Váº¤N Äá»€ Vá»€ TÃ€I NGUYÃŠN HUáº¤N LUYá»†N: Hiá»‡n táº¡i, vá»›i tÃ i nguyÃªn háº¡n cháº¿ vÃ  mÃ´ hÃ¬nh cÅ©ng khÃ¡ lá»›n nÃªn bá»n em chá»‰ má»›i dá»«ng láº¡i á»Ÿ má»©c character-level. Bá»n em mong muá»‘n huáº¥n luyá»‡n á»Ÿ má»©c Word-level nhÆ°ng láº¡i gáº·p khÃ³ khÄƒn trong viá»‡c thuÃª Colab Pro. Má»i ngÆ°á»i cho em há»i á»Ÿ nhÃ³m mÃ¬nh cÃ³ ai cho thuÃª Colab Pro thá»i gian ngáº¯n khÃ´ng áº¡ ( khoáº£ng dÆ°á»›i 1 thÃ¡ng ). TrÃªn Ä‘Ã¢y lÃ  nhá»¯ng váº¥n Ä‘á» bá»n em gáº·p pháº£i, mong nháº­n Ä‘Æ°á»£c sá»± giáº£i Ä‘Ã¡p. Em xin cáº£m Æ¡n áº¡.",,,#Q&A,,
"[English caption below]
URA-LLaMa: MÃ” HÃŒNH NGÃ”N NGá»® Lá»šN CHO TIáº¾NG VIá»†T
Xin chÃ o má»i ngÆ°á»i,
ChÃºng tÃ´i, nhÃ³m nghiÃªn cá»©u vá»›i cÃ¡c thÃ nh viÃªn Ä‘áº¿n tá»« TrÆ°á»ng Äáº¡i há»c BÃ¡ch Khoa - ÄHQG TP.HCM vÃ  Äáº¡i há»c Stanford xin trÃ¢n trá»ng giá»›i thiá»‡u Ä‘áº¿n cá»™ng Ä‘á»“ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n chÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn. ChÃºng tÃ´i gá»i chÃºng vá»›i cÃ¡i tÃªn thÃ¢n thuá»™c URA-LLaMa. MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c chÃºng tÃ´i finetune trÃªn dá»¯ liá»‡u tiáº¿ng Viá»‡t tá»« mÃ´ hÃ¬nh gá»‘c LLaMa-2 cá»§a Meta vá»›i cáº£ 3 phiÃªn báº£n 7B, 13B vÃ  70B.
ChÃºng tÃ´i cung cáº¥p miá»…n phÃ­ cÃ¡c mÃ´ hÃ¬nh nÃ y cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u. MÃ´ hÃ¬nh cá»§a chÃºng tÃ´i Ä‘i kÃ¨m vá»›i cÃ¡c káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn 10 tasks khÃ¡c nhau á»Ÿ nhiá»u khÃ­a cáº¡nh vÃ  tÃ¬nh huá»‘ng sá»­ dá»¥ng trong thá»±c táº¿. Báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y thÃ´ng tin vá» mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i táº¡i cÃ¡c Ä‘Æ°á»ng link bÃªn dÆ°á»›i.
URA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b
URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b
URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b
Giáº¥y phÃ©p vÃ  thá»a thuáº­n sá»­ dá»¥ng: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf
Playground cho URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground
Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cá»§a URA-LLaMa (Äang cáº­p nháº­t): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation
Náº¿u báº¡n muá»‘n Ä‘Ã³ng gÃ³p Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cho Tiáº¿ng Viá»‡t, xin Ä‘á»«ng ngáº§n ngáº¡i hÃ£y liÃªn há»‡ vá»›i chÃºng tÃ´i theo cÃ¡c thÃ´ng tin bÃªn dÆ°á»›i.
Vá» nhÃ³m nghiÃªn cá»©u:
Website: https://www.ura.hcmut.edu.vn
Email: qttho dot hcmut dot edu dot vn
Vá» giáº¥y phÃ©p cho cÃ¡c mÃ´ hÃ¬nh: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn)
Xin cáº£m Æ¡n má»i ngÆ°á»i.
10h10â€™, Thá»© Ba, ngÃ y 10 thÃ¡ng 10 nÄƒm 2023.
NhÃ³m nghiÃªn cá»©u
-----------------------------------------------
URA-LLaMa: LARGE LANGUAGE MODELS FOR VIETNAMESE
Hello everyone,
As a research team formed from members in Ho Chi Minh City University of Technology (HCMUT) - VNU-HCM and Stanford University, we are pleased to introduce our large language models to the community. We affectionately refer to those language models as URA-LLaMa. They are fine-tuned on Vietnamese datasets from Meta's original LLaMa-2 model, including all three versions of 7B, 13B, and 70B.
We provide these models free of charge for research purposes. Our models come with evaluation results on 10 different tasks, covering various aspects and real-world usage scenarios. You can find information about our models at the following links:
URA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b
URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b
URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b
License and User Agreement: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf
Playground for URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground
URA-LLaMa Evaluation Results (Actively updating): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation
If you want to contribute to the development of large language models for Vietnamese, please do not hesitate to contact us using the information below.
About the research group:
Website: https://www.ura.hcmut.edu.vn
Email: qttho dot hcmut dot edu dot vn
About the model licenses: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn)
Thank you all.
10:10 AM, Tuesday, October 10, 2023.
Research Team","[English caption below] URA-LLaMa: MÃ” HÃŒNH NGÃ”N NGá»® Lá»šN CHO TIáº¾NG VIá»†T Xin chÃ o má»i ngÆ°á»i, ChÃºng tÃ´i, nhÃ³m nghiÃªn cá»©u vá»›i cÃ¡c thÃ nh viÃªn Ä‘áº¿n tá»« TrÆ°á»ng Äáº¡i há»c BÃ¡ch Khoa - ÄHQG TP.HCM vÃ  Äáº¡i há»c Stanford xin trÃ¢n trá»ng giá»›i thiá»‡u Ä‘áº¿n cá»™ng Ä‘á»“ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n chÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn. ChÃºng tÃ´i gá»i chÃºng vá»›i cÃ¡i tÃªn thÃ¢n thuá»™c URA-LLaMa. MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c chÃºng tÃ´i finetune trÃªn dá»¯ liá»‡u tiáº¿ng Viá»‡t tá»« mÃ´ hÃ¬nh gá»‘c LLaMa-2 cá»§a Meta vá»›i cáº£ 3 phiÃªn báº£n 7B, 13B vÃ  70B. ChÃºng tÃ´i cung cáº¥p miá»…n phÃ­ cÃ¡c mÃ´ hÃ¬nh nÃ y cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u. MÃ´ hÃ¬nh cá»§a chÃºng tÃ´i Ä‘i kÃ¨m vá»›i cÃ¡c káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn 10 tasks khÃ¡c nhau á»Ÿ nhiá»u khÃ­a cáº¡nh vÃ  tÃ¬nh huá»‘ng sá»­ dá»¥ng trong thá»±c táº¿. Báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y thÃ´ng tin vá» mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i táº¡i cÃ¡c Ä‘Æ°á»ng link bÃªn dÆ°á»›i. URA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b Giáº¥y phÃ©p vÃ  thá»a thuáº­n sá»­ dá»¥ng: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf Playground cho URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cá»§a URA-LLaMa (Äang cáº­p nháº­t): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation Náº¿u báº¡n muá»‘n Ä‘Ã³ng gÃ³p Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cho Tiáº¿ng Viá»‡t, xin Ä‘á»«ng ngáº§n ngáº¡i hÃ£y liÃªn há»‡ vá»›i chÃºng tÃ´i theo cÃ¡c thÃ´ng tin bÃªn dÆ°á»›i. Vá» nhÃ³m nghiÃªn cá»©u: Website: https://www.ura.hcmut.edu.vn Email: qttho dot hcmut dot edu dot vn Vá» giáº¥y phÃ©p cho cÃ¡c mÃ´ hÃ¬nh: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn) Xin cáº£m Æ¡n má»i ngÆ°á»i. 10h10â€™, Thá»© Ba, ngÃ y 10 thÃ¡ng 10 nÄƒm 2023. NhÃ³m nghiÃªn cá»©u ----------------------------------------------- URA-LLaMa: LARGE LANGUAGE MODELS FOR VIETNAMESE Hello everyone, As a research team formed from members in Ho Chi Minh City University of Technology (HCMUT) - VNU-HCM and Stanford University, we are pleased to introduce our large language models to the community. We affectionately refer to those language models as URA-LLaMa. They are fine-tuned on Vietnamese datasets from Meta's original LLaMa-2 model, including all three versions of 7B, 13B, and 70B. We provide these models free of charge for research purposes. Our models come with evaluation results on 10 different tasks, covering various aspects and real-world usage scenarios. You can find information about our models at the following links: URA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b License and User Agreement: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf Playground for URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground URA-LLaMa Evaluation Results (Actively updating): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation If you want to contribute to the development of large language models for Vietnamese, please do not hesitate to contact us using the information below. About the research group: Website: https://www.ura.hcmut.edu.vn Email: qttho dot hcmut dot edu dot vn About the model licenses: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn) Thank you all. 10:10 AM, Tuesday, October 10, 2023. Research Team",,,"#sharing, #nlp",,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» LLMs vÃ  cá»¥ thá»ƒ lÃ  OpenAI API. Em cÃ³ 1 sá»‘ tháº¯c máº¯c mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
Nhá»¯ng model DALL-E vÃ  Whisper cÃ³ thá»±c sá»± lÃ  Large Language Models khÃ´ng áº¡, táº¡i bá»¯a em cÃ³ Ä‘á»c lÆ°á»›t qua 1 ?
Khi dÃ¹ng openai thÃ¬ em tháº¥y cÃ³ 2 phÆ°Æ¡ng thá»©c khÃ¡ tÆ°Æ¡ng tá»± lÃ  Completion vÃ  ChatCompletion. trong khi ChatCompletion cÃ³ thá»ƒ gá»­i lá»‹ch sá»­ há»™i thoáº¡i thÃ¬ khÃ´ng biáº¿t Completion cÃ³ Æ°u Ä‘iá»ƒm gÃ¬ mÃ  váº«n Ä‘Æ°á»£c giá»¯ láº¡i?
CÃ¡ch tÃ­nh phÃ­
VÃ­ dá»¥: babbage-002 $0.0004 / 1K tokens thÃ¬ lÃ  token vÃ o hay token ra hay tá»•ng áº¡.
Khi fine-turning, sá»­ dá»¥ng model Ä‘Ã³ thÃ¬ tÃ­nh phÃ­ sá»­ dá»¥ng cÃ³ + thÃªm phÃ­ model gá»‘c khÃ´ng hay chá»‰ tÃ­nh phÃ­ sá»­ dá»¥ng vÃ  tÃ­nh phÃ­ Ä‘áº§u vÃ o hay Ä‘áº§u ra hay cáº£ 2
- cÃ³ trang nÃ y tá»•ng há»£p Ä‘áº§y Ä‘á»§ model vÃ  phÃ­ hiá»‡n Ä‘ang cÃ³ hÆ¡n trang https://openai.com/pricing khÃ´ng áº¡
Giá»›i háº¡n
- Giá»›i háº¡n á»Ÿ trang https://platform.openai.com/docs/models MAX TOKENS lÃ  token nháº­p vÃ o pháº£i khÃ´ng áº¡. Náº¿u váº­y cÃ³ limit cho token tráº£ vá» khÃ´ng?
- Giá»›i háº¡n gá»­i request trong khoáº£ng thá»i gian: liá»‡u cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xin tÄƒng giá»›i háº¡n (cho tÃ i khoáº£n miá»…n phÃ­) khÃ´ng áº¡? vÃ¬ gá»­i theo biá»ƒu máº«u dÃ nh cho tÃ i khoáº£n tráº£ phÃ­.
NgoÃ i ra, khÃ´ng biáº¿t cÃ³ chÃ­nh sÃ¡ch (hoáº·c trick nÃ o) cho sinh viÃªn Ä‘á»ƒ cÃ³ thá»ƒ tráº£i nghiá»‡m cÃ¡c tÃ­nh nÄƒng paid plan (vÃ­ dá»¥ nhÆ° fine-tuning) cá»§a OpenAI API khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» LLMs vÃ  cá»¥ thá»ƒ lÃ  OpenAI API. Em cÃ³ 1 sá»‘ tháº¯c máº¯c mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p. Nhá»¯ng model DALL-E vÃ  Whisper cÃ³ thá»±c sá»± lÃ  Large Language Models khÃ´ng áº¡, táº¡i bá»¯a em cÃ³ Ä‘á»c lÆ°á»›t qua 1 ? Khi dÃ¹ng openai thÃ¬ em tháº¥y cÃ³ 2 phÆ°Æ¡ng thá»©c khÃ¡ tÆ°Æ¡ng tá»± lÃ  Completion vÃ  ChatCompletion. trong khi ChatCompletion cÃ³ thá»ƒ gá»­i lá»‹ch sá»­ há»™i thoáº¡i thÃ¬ khÃ´ng biáº¿t Completion cÃ³ Æ°u Ä‘iá»ƒm gÃ¬ mÃ  váº«n Ä‘Æ°á»£c giá»¯ láº¡i? CÃ¡ch tÃ­nh phÃ­ VÃ­ dá»¥: babbage-002 $0.0004 / 1K tokens thÃ¬ lÃ  token vÃ o hay token ra hay tá»•ng áº¡. Khi fine-turning, sá»­ dá»¥ng model Ä‘Ã³ thÃ¬ tÃ­nh phÃ­ sá»­ dá»¥ng cÃ³ + thÃªm phÃ­ model gá»‘c khÃ´ng hay chá»‰ tÃ­nh phÃ­ sá»­ dá»¥ng vÃ  tÃ­nh phÃ­ Ä‘áº§u vÃ o hay Ä‘áº§u ra hay cáº£ 2 - cÃ³ trang nÃ y tá»•ng há»£p Ä‘áº§y Ä‘á»§ model vÃ  phÃ­ hiá»‡n Ä‘ang cÃ³ hÆ¡n trang https://openai.com/pricing khÃ´ng áº¡ Giá»›i háº¡n - Giá»›i háº¡n á»Ÿ trang https://platform.openai.com/docs/models MAX TOKENS lÃ  token nháº­p vÃ o pháº£i khÃ´ng áº¡. Náº¿u váº­y cÃ³ limit cho token tráº£ vá» khÃ´ng? - Giá»›i háº¡n gá»­i request trong khoáº£ng thá»i gian: liá»‡u cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xin tÄƒng giá»›i háº¡n (cho tÃ i khoáº£n miá»…n phÃ­) khÃ´ng áº¡? vÃ¬ gá»­i theo biá»ƒu máº«u dÃ nh cho tÃ i khoáº£n tráº£ phÃ­. NgoÃ i ra, khÃ´ng biáº¿t cÃ³ chÃ­nh sÃ¡ch (hoáº·c trick nÃ o) cho sinh viÃªn Ä‘á»ƒ cÃ³ thá»ƒ tráº£i nghiá»‡m cÃ¡c tÃ­nh nÄƒng paid plan (vÃ­ dá»¥ nhÆ° fine-tuning) cá»§a OpenAI API khÃ´ng áº¡?",,,"#Q&A, #nlp",,
ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang cáº§n ná»™p 1 bÃ i táº­p lá»›n vá» Ä‘á» tÃ i MachineLearning báº¥t cá»© thá»© gÃ¬ cÅ©ng Ä‘Æ°á»£c. Váº­y báº¡n nÃ o cÃ³ thá»ƒ chia sáº» cho mÃ¬nh 1 Ä‘á» tÃ i nÃ o Ä‘Ã³ cÆ¡ báº£n nháº¥t cÃ³ thá»ƒ cÃ³ sáºµn cáº£ bÃ¡o cÃ¡o vÃ  source code vá»›i khÃ´ng áº¡? MÃ¬nh xin cáº£m Æ¡n vÃ  háº­u táº¡ áº¡,ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang cáº§n ná»™p 1 bÃ i táº­p lá»›n vá» Ä‘á» tÃ i MachineLearning báº¥t cá»© thá»© gÃ¬ cÅ©ng Ä‘Æ°á»£c. Váº­y báº¡n nÃ o cÃ³ thá»ƒ chia sáº» cho mÃ¬nh 1 Ä‘á» tÃ i nÃ o Ä‘Ã³ cÆ¡ báº£n nháº¥t cÃ³ thá»ƒ cÃ³ sáºµn cáº£ bÃ¡o cÃ¡o vÃ  source code vá»›i khÃ´ng áº¡? MÃ¬nh xin cáº£m Æ¡n vÃ  háº­u táº¡ áº¡,,,#Q&A,,
Má»i ngÆ°á»i ai lÃ m vá» trÃ­ch xuáº¥t thÃ´ng tin trÃªn cÄƒn cÆ°á»›c cÃ´ng cÃ³ chip chÆ°a cho e há»i cÃ¡i nÃ y vá»›i áº¡?,Má»i ngÆ°á»i ai lÃ m vá» trÃ­ch xuáº¥t thÃ´ng tin trÃªn cÄƒn cÆ°á»›c cÃ´ng cÃ³ chip chÆ°a cho e há»i cÃ¡i nÃ y vá»›i áº¡?,,,"#Q&A, #cv",,
"NhÆ° thread cÃ¡ch Ä‘Ã¢y chÆ°a lÃ¢u (táº¡i Ä‘Ã¢y https://www.facebook.com/groups/machinelearningcoban/permalink/1778526872604712/) ráº±ng Mojo cÃ³ thá»ƒ sáº½ cÃ³ chá»— Ä‘á»©ng cá»§a riÃªng nÃ³ trong thá»i Ä‘áº¡i á»©ng dá»¥ng AI trÃªn cÃ¡c ná»n táº£ng tÃ­nh toÃ¡n hiá»‡u nÄƒng cao . Nay Mojo má»›i cho cÃ i Native trÃªn Mac chip M. HÆ°á»›ng dáº«n cÃ i Ä‘áº·t táº¡i Ä‘Ã¢y: https://developer.modular.com/download.
MÃ¬nh cÃ³ test nhanh trÃªn mÃ¡y Mac M1 cá»§a mÃ¬nh vá»›i LLaMA2 (train vá»›i TinyStory tá»« Karpathy) vÃ  TinyLLaMA2 tá»« (https://huggingface.co/kirp/TinyLlama-1.1B-Chat-v0.2-bin/resolve/main/tl-chat.bin). DÆ°á»›i Ä‘Ã¢y lÃ  báº£n tÃ³m táº¯t káº¿t quáº£ so sÃ¡nh inference speed giá»¯a Mojo vÃ  C. CÆ¡ báº£n lÃ  khÃ´ng tá»‡ vÃ  tá»‘t hÆ¡n káº¿t quáº£ trÆ°á»›c Ä‘Ã³ mÃ¬nh test trÃªn server Linux (xem comments á»Ÿ thread trÆ°á»›c Ä‘Ã¢y, dÆ°á»ng dáº«n á»Ÿ trÃªn). MÃ¬nh sáº½ test thÃªm kÄ© hÆ¡n trong nhá»¯ng ngÃ y tá»›i rá»“i chia sáº» vá»›i cÃ¡c báº¡n sau!
source code cho LLaMA2.mojo táº¡i Ä‘Ã¢y https://github.com/tairov/llama2.mojo
vÃ  tá»•ng há»£p cÃ¡c source code/thÆ° viá»‡n thÃº vá»‹ viáº¿t cho mojo táº¡i Ä‘Ã¢y https://github.com/mojicians/awesome-mojo","NhÆ° thread cÃ¡ch Ä‘Ã¢y chÆ°a lÃ¢u (táº¡i Ä‘Ã¢y https://www.facebook.com/groups/machinelearningcoban/permalink/1778526872604712/) ráº±ng Mojo cÃ³ thá»ƒ sáº½ cÃ³ chá»— Ä‘á»©ng cá»§a riÃªng nÃ³ trong thá»i Ä‘áº¡i á»©ng dá»¥ng AI trÃªn cÃ¡c ná»n táº£ng tÃ­nh toÃ¡n hiá»‡u nÄƒng cao . Nay Mojo má»›i cho cÃ i Native trÃªn Mac chip M. HÆ°á»›ng dáº«n cÃ i Ä‘áº·t táº¡i Ä‘Ã¢y: https://developer.modular.com/download. MÃ¬nh cÃ³ test nhanh trÃªn mÃ¡y Mac M1 cá»§a mÃ¬nh vá»›i LLaMA2 (train vá»›i TinyStory tá»« Karpathy) vÃ  TinyLLaMA2 tá»« (https://huggingface.co/kirp/TinyLlama-1.1B-Chat-v0.2-bin/resolve/main/tl-chat.bin). DÆ°á»›i Ä‘Ã¢y lÃ  báº£n tÃ³m táº¯t káº¿t quáº£ so sÃ¡nh inference speed giá»¯a Mojo vÃ  C. CÆ¡ báº£n lÃ  khÃ´ng tá»‡ vÃ  tá»‘t hÆ¡n káº¿t quáº£ trÆ°á»›c Ä‘Ã³ mÃ¬nh test trÃªn server Linux (xem comments á»Ÿ thread trÆ°á»›c Ä‘Ã¢y, dÆ°á»ng dáº«n á»Ÿ trÃªn). MÃ¬nh sáº½ test thÃªm kÄ© hÆ¡n trong nhá»¯ng ngÃ y tá»›i rá»“i chia sáº» vá»›i cÃ¡c báº¡n sau! source code cho LLaMA2.mojo táº¡i Ä‘Ã¢y https://github.com/tairov/llama2.mojo vÃ  tá»•ng há»£p cÃ¡c source code/thÆ° viá»‡n thÃº vá»‹ viáº¿t cho mojo táº¡i Ä‘Ã¢y https://github.com/mojicians/awesome-mojo",,,#sharing,,
"Xin chÃ o táº¥t cáº£ anh chá»‹. Em lÃ  sv nÄƒm nhÃ¢t áº¡ vÃ  sáº¯p tá»›i em pháº£i báº£o vá»‡ Ä‘á»“ Ã¡n Ã½ tÆ°á»Ÿng sáº£n pháº©m CNTT. Ã½ tÆ°á»Ÿng khÃ¡ hay cÃ³ á»©ng dá»¥ng AI cÃ¡c kiá»ƒu. Cá»¥ thá»ƒ: 1 app tÃ­ch há»£p AI gá»£i Ã½ thá»±c Ä‘Æ¡n cho ngÆ°á»i dÃ¹ng dá»±a trÃªn nhá»¯ng dá»¯ liá»‡u cá»§a há»( bao gá»“m dá»¯ liá»‡u cá»‘ Ä‘á»‹nh vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c ghi láº¡i theo thá»i gian thá»±c báº±ng thiáº¿t bá»‹ theo dÃµi SK). VÃ  AI Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ tÃ¬m ra nhá»¯ng mÃ³n Äƒn cÃ³ thá»±c pháº©m, gia vá»‹ phÃ¹ há»£p dinh dÆ°á»¡ng ( tháº­m chÃ­ kháº©u vá»‹ ) vá»›i ngÆ°á»i dÃ¹ng, rá»“i Ä‘Æ°a ra gá»£i Ã½ Ä‘á»ƒ há» chá»n vÃ  Ä‘Äƒt hÃ ng.
DÆ°á»›i hÃ¬nh lÃ  liá»‡t kÃª cÃ¡c tiÃªu chÃ­ áº¡, tá»« tiÃªu chÃ­ áº¥y anh chá»‹ cÃ³ thá»ƒ tÆ° váº¥n sÃ¢u thÃªm chÃºt vá» kÄ© thuáº­t huáº¥n luyá»‡n cho con AI nÃ y ( cÃ´ng Ä‘oáº¡n, chiáº¿n lÆ°á»£c, phÃ¢n tÃ­ch, chá»n cÃ¡c thuáº­t toÃ¡n, mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u,...)
VÃ¬ em chá»‰ biáº¿t chÃºt bá» ná»•i vá» tiá»m nÄƒng á»©ng dá»¥ng cá»§a AI thÃ´i áº¡. NÃªn em cáº§n anh chá»‹ tÆ° váº¥n giÃºp em Ä‘á»ƒ Ä‘Ã o sÃ¢u hÆ¡n chÃºt vá» kÄ© thuáº­t nha !!!
Chiyyso06.5 â™ ï¸","Xin chÃ o táº¥t cáº£ anh chá»‹. Em lÃ  sv nÄƒm nhÃ¢t áº¡ vÃ  sáº¯p tá»›i em pháº£i báº£o vá»‡ Ä‘á»“ Ã¡n Ã½ tÆ°á»Ÿng sáº£n pháº©m CNTT. Ã½ tÆ°á»Ÿng khÃ¡ hay cÃ³ á»©ng dá»¥ng AI cÃ¡c kiá»ƒu. Cá»¥ thá»ƒ: 1 app tÃ­ch há»£p AI gá»£i Ã½ thá»±c Ä‘Æ¡n cho ngÆ°á»i dÃ¹ng dá»±a trÃªn nhá»¯ng dá»¯ liá»‡u cá»§a há»( bao gá»“m dá»¯ liá»‡u cá»‘ Ä‘á»‹nh vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c ghi láº¡i theo thá»i gian thá»±c báº±ng thiáº¿t bá»‹ theo dÃµi SK). VÃ  AI Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ tÃ¬m ra nhá»¯ng mÃ³n Äƒn cÃ³ thá»±c pháº©m, gia vá»‹ phÃ¹ há»£p dinh dÆ°á»¡ng ( tháº­m chÃ­ kháº©u vá»‹ ) vá»›i ngÆ°á»i dÃ¹ng, rá»“i Ä‘Æ°a ra gá»£i Ã½ Ä‘á»ƒ há» chá»n vÃ  Ä‘Äƒt hÃ ng. DÆ°á»›i hÃ¬nh lÃ  liá»‡t kÃª cÃ¡c tiÃªu chÃ­ áº¡, tá»« tiÃªu chÃ­ áº¥y anh chá»‹ cÃ³ thá»ƒ tÆ° váº¥n sÃ¢u thÃªm chÃºt vá» kÄ© thuáº­t huáº¥n luyá»‡n cho con AI nÃ y ( cÃ´ng Ä‘oáº¡n, chiáº¿n lÆ°á»£c, phÃ¢n tÃ­ch, chá»n cÃ¡c thuáº­t toÃ¡n, mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u,...) VÃ¬ em chá»‰ biáº¿t chÃºt bá» ná»•i vá» tiá»m nÄƒng á»©ng dá»¥ng cá»§a AI thÃ´i áº¡. NÃªn em cáº§n anh chá»‹ tÆ° váº¥n giÃºp em Ä‘á»ƒ Ä‘Ã o sÃ¢u hÆ¡n chÃºt vá» kÄ© thuáº­t nha !!! Chiyyso06.5",,,#Q&A,,
"Mn cho em há»i Ä‘iá»ƒm giá»‘ng vÃ  khÃ¡c nhau (so sÃ¡nh) cá»§a decision tree, k-NN, naive bayes, linear regression vá»›i áº¡","Mn cho em há»i Ä‘iá»ƒm giá»‘ng vÃ  khÃ¡c nhau (so sÃ¡nh) cá»§a decision tree, k-NN, naive bayes, linear regression vá»›i áº¡",,,"#Q&A, #machine_learning",,
"Hello má»i ngÆ°á»i! Hiá»‡n táº¡i e cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» data science vÃ  stats/probability. TrÆ°á»›c em dÃ¹ng R Ä‘á»ƒ lÃ m 1 sá»‘ project vÃ  há»c qua cuá»‘n ISLR vÃ  hiá»‡n táº¡i Ä‘ang báº¯t Ä‘áº§u há»c Python.
Google má»›i released khoÃ¡ há»c vá» advanced data analytics, e chá»‰ biáº¿t khÃ¡c vá»›i khoÃ¡ trÆ°á»›c lÃ  thay vÃ¬ dÃ¹ng R thÃ¬ khoÃ¡ nÃ y dÃ¹ng Python. A/C nÃ o Ä‘Ã£ há»c qua hoáº·c biáº¿t vá» khoÃ¡ há»c nÃ y cho e xin reviews vá»›i áº¡. Thank you","Hello má»i ngÆ°á»i! Hiá»‡n táº¡i e cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» data science vÃ  stats/probability. TrÆ°á»›c em dÃ¹ng R Ä‘á»ƒ lÃ m 1 sá»‘ project vÃ  há»c qua cuá»‘n ISLR vÃ  hiá»‡n táº¡i Ä‘ang báº¯t Ä‘áº§u há»c Python. Google má»›i released khoÃ¡ há»c vá» advanced data analytics, e chá»‰ biáº¿t khÃ¡c vá»›i khoÃ¡ trÆ°á»›c lÃ  thay vÃ¬ dÃ¹ng R thÃ¬ khoÃ¡ nÃ y dÃ¹ng Python. A/C nÃ o Ä‘Ã£ há»c qua hoáº·c biáº¿t vá» khoÃ¡ há»c nÃ y cho e xin reviews vá»›i áº¡. Thank you",,,#Q&A,,
"[GÃ³c tÆ° váº¥n]
Anh chá»‹ em nÃ o Ä‘Ã£ vÃ  Ä‘ang há»c Master á»Ÿ ÄH BÃ¡ch Khoa ngÃ nh Data Science rá»“i cho em xin review vá»›i áº¡.
Em phÃ¢n vÃ¢n há»c BK hoáº·c há»c tá»« xa 1 sá»‘ trÆ°á»ng nc ngoÃ i (so sÃ¡nh há»c phÃ­, cháº¥t lÆ°á»£ng giangr dáº¡y, báº±ng cáº¥p,â€¦).
Ráº¥t mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ Ä‘i trc cÃ³ kinh nghiá»‡m chá»‰ dáº¡y áº¡. Em cáº£m Æ¡n áº¡.","[GÃ³c tÆ° váº¥n] Anh chá»‹ em nÃ o Ä‘Ã£ vÃ  Ä‘ang há»c Master á»Ÿ ÄH BÃ¡ch Khoa ngÃ nh Data Science rá»“i cho em xin review vá»›i áº¡. Em phÃ¢n vÃ¢n há»c BK hoáº·c há»c tá»« xa 1 sá»‘ trÆ°á»ng nc ngoÃ i (so sÃ¡nh há»c phÃ­, cháº¥t lÆ°á»£ng giangr dáº¡y, báº±ng cáº¥p,â€¦). Ráº¥t mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ Ä‘i trc cÃ³ kinh nghiá»‡m chá»‰ dáº¡y áº¡. Em cáº£m Æ¡n áº¡.",,,#Q&A,,
"ChÃ o cÃ¡c anh chá»‹!
Trong há»c kÃ¬ tá»›i em sáº½ báº¯t Ä‘áº§u há»c cÃ¡c mÃ´n chuyÃªn ngÃ nh AI vÃ 
Em Ä‘Ã£ há»c qua cÃ¡c khÃ³a ML, DL trÃªn Coursera vÃ  Ä‘Ã£ hiá»ƒu nhá»¯ng concept, toÃ¡n há»c cÆ¡ báº£n vá» lÄ©nh vá»±c nÃ y.
Em ráº¥t mong muá»‘n thá»±c táº­p sá»›m Ä‘á»ƒ tÃ­ch lÅ©y cÃ¡c kinh nghiá»‡m thá»±c táº¿ trong mÃ´i trÆ°á»ng doanh nghiá»‡p nhÆ°ng hiá»‡n táº¡i em tháº¥y cÃ¡c cÃ´ng viá»‡c nÃ y Ä‘ang tuyá»ƒn á»Ÿ TPHCM khÃ¡ Ã­t nÃªn em hÆ¡i hoang mang áº¡.
Em muá»‘n há»i cÃ¡c anh/ chá»‹ em nÃªn trau dá»“i thÃªm nhá»¯ng gÃ¬ Ä‘á»ƒ cÃ³ Ä‘á»§ ká»¹ nÄƒng Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c vá»‹ trÃ­ thá»±c táº­p á»Ÿ cÃ¡c vá»‹ trÃ­ AI Engineer hoáº·c Data Science áº¡.
Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ tá»« má»i ngÆ°á»i. ChÃºc má»i ngÆ°á»i má»™t ngÃ y vui váº» áº¡!","ChÃ o cÃ¡c anh chá»‹! Trong há»c kÃ¬ tá»›i em sáº½ báº¯t Ä‘áº§u há»c cÃ¡c mÃ´n chuyÃªn ngÃ nh AI vÃ  Em Ä‘Ã£ há»c qua cÃ¡c khÃ³a ML, DL trÃªn Coursera vÃ  Ä‘Ã£ hiá»ƒu nhá»¯ng concept, toÃ¡n há»c cÆ¡ báº£n vá» lÄ©nh vá»±c nÃ y. Em ráº¥t mong muá»‘n thá»±c táº­p sá»›m Ä‘á»ƒ tÃ­ch lÅ©y cÃ¡c kinh nghiá»‡m thá»±c táº¿ trong mÃ´i trÆ°á»ng doanh nghiá»‡p nhÆ°ng hiá»‡n táº¡i em tháº¥y cÃ¡c cÃ´ng viá»‡c nÃ y Ä‘ang tuyá»ƒn á»Ÿ TPHCM khÃ¡ Ã­t nÃªn em hÆ¡i hoang mang áº¡. Em muá»‘n há»i cÃ¡c anh/ chá»‹ em nÃªn trau dá»“i thÃªm nhá»¯ng gÃ¬ Ä‘á»ƒ cÃ³ Ä‘á»§ ká»¹ nÄƒng Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c vá»‹ trÃ­ thá»±c táº­p á»Ÿ cÃ¡c vá»‹ trÃ­ AI Engineer hoáº·c Data Science áº¡. Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ tá»« má»i ngÆ°á»i. ChÃºc má»i ngÆ°á»i má»™t ngÃ y vui váº» áº¡!",,,#Q&A,,
"Xin chÃ o cÃ¡c bÃ¡c. Cháº£ lÃ  lÃ¢u nay em cÃ³ Ä‘á»c tin bÃ i vá» AI trÃªn Medium. com nhÆ°ng dáº¡o gáº§n dÃ¢y em vÃ o ráº¥t khÃ³, quay Ä‘á»u Ä‘á»u mÃ  khÃ´ng vÃ o Ä‘Æ°á»£c.
Em muá»‘n xin há»i cÃ¡c bÃ¡c xem cÃ²n cÃ³ trang nÃ o tÆ°Æ¡ng tá»± nhÆ° trang nÃ y Ä‘á»ƒ vÃ o Ä‘á»c vÃ  cáº­p nháº­t cÃ¡c bÃ i liÃªn quan Ä‘áº¿n AI khÃ´ng áº¡?
Em cáº£m Æ¡n cÃ¡c bÃ¡c nhiá»u!","Xin chÃ o cÃ¡c bÃ¡c. Cháº£ lÃ  lÃ¢u nay em cÃ³ Ä‘á»c tin bÃ i vá» AI trÃªn Medium. com nhÆ°ng dáº¡o gáº§n dÃ¢y em vÃ o ráº¥t khÃ³, quay Ä‘á»u Ä‘á»u mÃ  khÃ´ng vÃ o Ä‘Æ°á»£c. Em muá»‘n xin há»i cÃ¡c bÃ¡c xem cÃ²n cÃ³ trang nÃ o tÆ°Æ¡ng tá»± nhÆ° trang nÃ y Ä‘á»ƒ vÃ o Ä‘á»c vÃ  cáº­p nháº­t cÃ¡c bÃ i liÃªn quan Ä‘áº¿n AI khÃ´ng áº¡? Em cáº£m Æ¡n cÃ¡c bÃ¡c nhiá»u!",,,#Q&A,,
"Hiá»‡n táº¡i Em Ä‘ang lÃ m 1 model image classfication vá» cÃ¡c loÃ i cÃ´n trÃ¹ng. NhÆ°ng gáº·p pháº£i váº¥n Ä‘á» lÃ  khi em train 200 class thÃ¬ bÃ¬nh thÆ°á»ng. NhÆ°ng khi tÄƒng lÃªn 300 thÃ¬ model giáº£m Ä‘á»™ chÃ­nh xÃ¡c, vÃ  khi nháº­n dáº¡ng thá»±c táº¿ thÃ¬ cÅ©ng giáº£m vÃ  score giáº£m cÃ²n ráº¥t tháº¥p máº·c dÃ¹ nháº­n dáº¡ng váº«n cÃ³ cÃ¡i Ä‘Ãºng. Em Ä‘oÃ¡n lÃ  cÃ³ thá»ƒ lÃ  do cÃ¡c class cÃ´n trÃ¹ng nhiá»u loÃ i ráº¥t giá»‘ng nhau tháº­m chÃ­ giá»‘ng há»‡t. NÃªn áº£nh hÆ°á»Ÿng. Em cÅ©ng cÃ³ suy nghÄ© lÃ  gom nhÃ³m cÃ¡c loÃ i giá»‘ng nhau vÃ o kiá»ƒu nhÆ° sub class. NhÆ°ng khÃ´ng biáº¿t nhÆ° tháº¿ nÃ o. Em hi vá»ng Ä‘Æ°á»£c nghe chia sáº» cá»§a cÃ¡c anh chá»‹ vá» cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» nÃ y. Em cáº£m Æ¡n ráº¥t nhiá»u.","Hiá»‡n táº¡i Em Ä‘ang lÃ m 1 model image classfication vá» cÃ¡c loÃ i cÃ´n trÃ¹ng. NhÆ°ng gáº·p pháº£i váº¥n Ä‘á» lÃ  khi em train 200 class thÃ¬ bÃ¬nh thÆ°á»ng. NhÆ°ng khi tÄƒng lÃªn 300 thÃ¬ model giáº£m Ä‘á»™ chÃ­nh xÃ¡c, vÃ  khi nháº­n dáº¡ng thá»±c táº¿ thÃ¬ cÅ©ng giáº£m vÃ  score giáº£m cÃ²n ráº¥t tháº¥p máº·c dÃ¹ nháº­n dáº¡ng váº«n cÃ³ cÃ¡i Ä‘Ãºng. Em Ä‘oÃ¡n lÃ  cÃ³ thá»ƒ lÃ  do cÃ¡c class cÃ´n trÃ¹ng nhiá»u loÃ i ráº¥t giá»‘ng nhau tháº­m chÃ­ giá»‘ng há»‡t. NÃªn áº£nh hÆ°á»Ÿng. Em cÅ©ng cÃ³ suy nghÄ© lÃ  gom nhÃ³m cÃ¡c loÃ i giá»‘ng nhau vÃ o kiá»ƒu nhÆ° sub class. NhÆ°ng khÃ´ng biáº¿t nhÆ° tháº¿ nÃ o. Em hi vá»ng Ä‘Æ°á»£c nghe chia sáº» cá»§a cÃ¡c anh chá»‹ vá» cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» nÃ y. Em cáº£m Æ¡n ráº¥t nhiá»u.",,,"#Q&A, #cv",,
"ÄÃ£ cÃ³ ngÆ°á»i Ä‘áº§u tiÃªn port thÆ° viá»‡n ráº¥t hay vÃ  ná»•i tiáº¿ng cá»§a Karpathy cÃ³ tÃªn lÃ  llama.c https://github.com/karpathy/llama2.c sang Mojo táº¡i Ä‘Ã¢y https://github.com/tairov/llama2.mojo
Mojo Ä‘Ã£ tÄƒng hiá»‡u suáº¥t cá»§a Python lÃªn gáº§n 250 láº§n. Tháº­t áº¥n tÆ°á»£ng vá»›i phiÃªn báº£n Mojo giá» Ä‘Ã¢y vÆ°á»£t trá»™i hÆ¡n llama2.c khoáº£ng 15-20%. Má»™t con sá»‘ cá»±c kÃ¬ áº¥n tÆ°á»£ng trong thÃ­ nghiá»‡m ban Ä‘áº§u nÃ y.
Äiá»u nÃ y cho tháº¥y tiá»m nÄƒng cá»§a viá»‡c tá»‘i Æ°u pháº§n cá»©ng thÃ´ng qua cÃ¡c tÃ­nh nÄƒng nÃ¢ng cao cá»§a Mojo. TÃ´i nghÄ© Ä‘iá»u nÃ y bÆ°á»›c Ä‘áº§u cho ta tháº¥y Ä‘Æ°á»£c áº¥n tÆ°á»£ng vá» hiá»‡u nÄƒng cá»§a Mojo trÃªn cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, nÆ¡i Ä‘Ã²i há»i tÃ i nguyÃªn tÃ­nh toÃ¡n ráº¥t lá»›n. NÃªn cáº£i thiá»‡n Ä‘Æ°á»£c x% vá» hiá»‡u nÄƒng cÅ©ng lÃ  ráº¥t Ä‘Ã¡ng quÃ­.
ChÃºc cÃ¡c báº¡n cÃ³ tráº£i nghiá»‡m vui váº» vá»›i nhá»¯ng thá»© má»›i láº¡!
Ps. Khi tÃ´i post bÃ i trÆ°á»›c Ä‘Ã³ vá» viá»‡c Modular cho cÃ i Ä‘áº·t Mojo trÃªn local machines (trÆ°á»›c Ä‘Ã³ chá»‰ cháº¡y online trÃªn servers chá»§ cá»§a cty), nhiá»u báº¡n tá» Ã½ nghi ngá». TÃ´i cÃ³ nÃ³i, hÃ£y bÃ¬nh tÄ©nh chá» Ä‘á»£i vÃ  hÃ£y thá»­ tráº£i nghiá»‡m vá»›i Mojo theo cÃ¡ch cá»§a báº¡n, trÆ°á»›c khi cÃ³ nhá»¯ng phÃ¡t biá»ƒu cáº£m tÃ­nh. TÃ´i hiá»ƒu Ä‘Ã¢y lÃ  má»™t pháº§n tÃ­nh cÃ¡ch cá»§a khÃ´ng Ã­t ngÆ°á»i Viá»‡t. Xin lá»—i pháº£i nÃ³i ra viá»‡c Ä‘á»¥ng cháº¡m Ä‘Ã¡ng buá»“n nÃ y. Ráº¥t láº¥y lÃ m tiáº¿c
https://github.com/tairov/llama2.mojo/blob/master/assets/llama2.mojo-demo.gif","ÄÃ£ cÃ³ ngÆ°á»i Ä‘áº§u tiÃªn port thÆ° viá»‡n ráº¥t hay vÃ  ná»•i tiáº¿ng cá»§a Karpathy cÃ³ tÃªn lÃ  llama.c https://github.com/karpathy/llama2.c sang Mojo táº¡i Ä‘Ã¢y https://github.com/tairov/llama2.mojo Mojo Ä‘Ã£ tÄƒng hiá»‡u suáº¥t cá»§a Python lÃªn gáº§n 250 láº§n. Tháº­t áº¥n tÆ°á»£ng vá»›i phiÃªn báº£n Mojo giá» Ä‘Ã¢y vÆ°á»£t trá»™i hÆ¡n llama2.c khoáº£ng 15-20%. Má»™t con sá»‘ cá»±c kÃ¬ áº¥n tÆ°á»£ng trong thÃ­ nghiá»‡m ban Ä‘áº§u nÃ y. Äiá»u nÃ y cho tháº¥y tiá»m nÄƒng cá»§a viá»‡c tá»‘i Æ°u pháº§n cá»©ng thÃ´ng qua cÃ¡c tÃ­nh nÄƒng nÃ¢ng cao cá»§a Mojo. TÃ´i nghÄ© Ä‘iá»u nÃ y bÆ°á»›c Ä‘áº§u cho ta tháº¥y Ä‘Æ°á»£c áº¥n tÆ°á»£ng vá» hiá»‡u nÄƒng cá»§a Mojo trÃªn cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, nÆ¡i Ä‘Ã²i há»i tÃ i nguyÃªn tÃ­nh toÃ¡n ráº¥t lá»›n. NÃªn cáº£i thiá»‡n Ä‘Æ°á»£c x% vá» hiá»‡u nÄƒng cÅ©ng lÃ  ráº¥t Ä‘Ã¡ng quÃ­. ChÃºc cÃ¡c báº¡n cÃ³ tráº£i nghiá»‡m vui váº» vá»›i nhá»¯ng thá»© má»›i láº¡! Ps. Khi tÃ´i post bÃ i trÆ°á»›c Ä‘Ã³ vá» viá»‡c Modular cho cÃ i Ä‘áº·t Mojo trÃªn local machines (trÆ°á»›c Ä‘Ã³ chá»‰ cháº¡y online trÃªn servers chá»§ cá»§a cty), nhiá»u báº¡n tá» Ã½ nghi ngá». TÃ´i cÃ³ nÃ³i, hÃ£y bÃ¬nh tÄ©nh chá» Ä‘á»£i vÃ  hÃ£y thá»­ tráº£i nghiá»‡m vá»›i Mojo theo cÃ¡ch cá»§a báº¡n, trÆ°á»›c khi cÃ³ nhá»¯ng phÃ¡t biá»ƒu cáº£m tÃ­nh. TÃ´i hiá»ƒu Ä‘Ã¢y lÃ  má»™t pháº§n tÃ­nh cÃ¡ch cá»§a khÃ´ng Ã­t ngÆ°á»i Viá»‡t. Xin lá»—i pháº£i nÃ³i ra viá»‡c Ä‘á»¥ng cháº¡m Ä‘Ã¡ng buá»“n nÃ y. Ráº¥t láº¥y lÃ m tiáº¿c https://github.com/tairov/llama2.mojo/blob/master/assets/llama2.mojo-demo.gif",,,#sharing,,
"DopikAI vá»«a cÃ´ng bá»‘ bÃ i tÃ³m táº¯t vá» ViGPTÂ®, mÃ´ hÃ¬nh LLM tiáº¿ng Viá»‡t dá»±a trÃªn instruction-fintuning vá»›i cÃ¡c nguá»“n dá»¯ liá»‡u tá»± thu tháº­p, translate tá»« tiáº¿ng anh cÅ©ng nhÆ° tá»± sinh vá»›i ChatGPT. 
MÃ´ hÃ¬nh táº­p trung vÃ o tÃ¡c vá»¥ há»i Ä‘Ã¡p, Ä‘Ã¡nh giÃ¡ tÃ­nh tá»± nhiÃªn vÃ  tÃ­nh Ä‘Ãºng Ä‘áº¯n cÃ¢u tráº£ lá»i Ä‘Æ°á»£c sinh ra Ä‘á»ƒ Ä‘áº£m báº£o performance trÃªn nhiá»u domain khÃ¡c nhau. 
NghiÃªn cá»©u cá»§a nhÃ³m Ä‘Ã£ Ä‘Æ°á»£c accept táº¡i EMNLP 2023 (Industry Track).
Äá»c ngay bÃ i tÃ³m táº¯t vá» ViGPTÂ® táº¡i: https://dopikai.com/files/Dopikai_ViGPT.pdf 
ÄÄƒng kÃ½ tham gia DopikAI's organization, Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c version cá»§a ViGPTÂ®: https://huggingface.co/dopikai
Tham gia ngay DopikAIâ€™s LLM Challenge Ä‘á»ƒ so sÃ¡nh káº¿t quáº£ trÃªn benchmark dataset vá»›i ViGPTÂ®: https://aihub.vn/competitions/596 ","DopikAI vá»«a cÃ´ng bá»‘ bÃ i tÃ³m táº¯t vá» ViGPTÂ®, mÃ´ hÃ¬nh LLM tiáº¿ng Viá»‡t dá»±a trÃªn instruction-fintuning vá»›i cÃ¡c nguá»“n dá»¯ liá»‡u tá»± thu tháº­p, translate tá»« tiáº¿ng anh cÅ©ng nhÆ° tá»± sinh vá»›i ChatGPT. MÃ´ hÃ¬nh táº­p trung vÃ o tÃ¡c vá»¥ há»i Ä‘Ã¡p, Ä‘Ã¡nh giÃ¡ tÃ­nh tá»± nhiÃªn vÃ  tÃ­nh Ä‘Ãºng Ä‘áº¯n cÃ¢u tráº£ lá»i Ä‘Æ°á»£c sinh ra Ä‘á»ƒ Ä‘áº£m báº£o performance trÃªn nhiá»u domain khÃ¡c nhau. NghiÃªn cá»©u cá»§a nhÃ³m Ä‘Ã£ Ä‘Æ°á»£c accept táº¡i EMNLP 2023 (Industry Track). Äá»c ngay bÃ i tÃ³m táº¯t vá» ViGPTÂ® táº¡i: https://dopikai.com/files/Dopikai_ViGPT.pdf ÄÄƒng kÃ½ tham gia DopikAI's organization, Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c version cá»§a ViGPTÂ®: https://huggingface.co/dopikai Tham gia ngay DopikAIâ€™s LLM Challenge Ä‘á»ƒ so sÃ¡nh káº¿t quáº£ trÃªn benchmark dataset vá»›i ViGPTÂ®: https://aihub.vn/competitions/596",,,"#sharing, #nlp",,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» Explainable AI thÃ¬ cÃ³ cÃ¡i tá»« ""agnostic"" lÃ  em khÃ´ng hiá»ƒu láº¯m. Náº¿u dá»‹ch trá»±c tiáº¿p ra thÃ¬ lÃ  ""báº¥t kháº£ tri"", nhÆ°ng em tháº¥y nÃ³ chÆ°a thá»a Ä‘Ã¡ng. Má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ tá»«ng tÃ¬m hiá»ƒu giáº£i nghÄ©a giÃºp em vá»›i áº¡.","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» Explainable AI thÃ¬ cÃ³ cÃ¡i tá»« ""agnostic"" lÃ  em khÃ´ng hiá»ƒu láº¯m. Náº¿u dá»‹ch trá»±c tiáº¿p ra thÃ¬ lÃ  ""báº¥t kháº£ tri"", nhÆ°ng em tháº¥y nÃ³ chÆ°a thá»a Ä‘Ã¡ng. Má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ tá»«ng tÃ¬m hiá»ƒu giáº£i nghÄ©a giÃºp em vá»›i áº¡.",,,#Q&A,,
"Em chÃ o mng áº¡.
Mng cÃ³ thá»ƒ chia sáº» cho em lá»™ trÃ¬nh Ä‘á»ƒ há»c xÃ¢y dá»±ng 1 AI-Chatbot (cÃ³ kÃ¨m theo khÃ³a Udemy cÃ ng tá»‘t áº¡).
Em cáº£m Æ¡n mng nhÃ¬u",Em chÃ o mng áº¡. Mng cÃ³ thá»ƒ chia sáº» cho em lá»™ trÃ¬nh Ä‘á»ƒ há»c xÃ¢y dá»±ng 1 AI-Chatbot (cÃ³ kÃ¨m theo khÃ³a Udemy cÃ ng tá»‘t áº¡). Em cáº£m Æ¡n mng nhÃ¬u,,,"#Q&A, #nlp",,
Xin Ä‘Æ°á»£c chia sáº» vá»›i má»i ngÆ°á»i video giáº£i thÃ­ch paper Segment Anything báº±ng tiáº¿ng Viá»‡t áº¡. Ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ tá»« má»i ngÆ°á»i áº¡,Xin Ä‘Æ°á»£c chia sáº» vá»›i má»i ngÆ°á»i video giáº£i thÃ­ch paper Segment Anything báº±ng tiáº¿ng Viá»‡t áº¡. Ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ tá»« má»i ngÆ°á»i áº¡,,,"#sharing, #cv",,
"Em táº¡o má»™t máº¡ng neural 2 lá»›p áº©n vá»›i hÃ m kÃ­ch hoáº¡t cho 2 lá»›p áº©n lÃ  ReLU vÃ  hÃ m Ä‘áº§u ra lÃ  hÃ m dá»± Ä‘oÃ¡n sofmax. Em cÃ³ test thá»­ nhiá»u láº§n thÃ¬ háº§u nhÆ° hÃ m loss giáº£m ráº¥t nhanh. NhÆ°ng má»™t sá»‘ láº§n hÃ m loss khÃ´ng giáº£m. Em khÃ´ng biáº¿t lÃ  do em sai á»Ÿ Ä‘Ã¢u. hay lÃ  do Ä‘áº·c tÃ­nh cá»§a hÃ m ReLU.
MÃ  em cÅ©ng thá»­ dÃ¹ng hÃ m sigmoid lÃ m hÃ m kÃ­ch hoáº¡t. Tuy loss giáº£m lÃ¢u hÆ¡n nhÆ°ng em tháº¥y nÃ³ á»•n Ä‘á»‹nh hÆ¡n hÃ m ReLU.",Em táº¡o má»™t máº¡ng neural 2 lá»›p áº©n vá»›i hÃ m kÃ­ch hoáº¡t cho 2 lá»›p áº©n lÃ  ReLU vÃ  hÃ m Ä‘áº§u ra lÃ  hÃ m dá»± Ä‘oÃ¡n sofmax. Em cÃ³ test thá»­ nhiá»u láº§n thÃ¬ háº§u nhÆ° hÃ m loss giáº£m ráº¥t nhanh. NhÆ°ng má»™t sá»‘ láº§n hÃ m loss khÃ´ng giáº£m. Em khÃ´ng biáº¿t lÃ  do em sai á»Ÿ Ä‘Ã¢u. hay lÃ  do Ä‘áº·c tÃ­nh cá»§a hÃ m ReLU. MÃ  em cÅ©ng thá»­ dÃ¹ng hÃ m sigmoid lÃ m hÃ m kÃ­ch hoáº¡t. Tuy loss giáº£m lÃ¢u hÆ¡n nhÆ°ng em tháº¥y nÃ³ á»•n Ä‘á»‹nh hÆ¡n hÃ m ReLU.,,,"#Q&A, #deep_learning",,
"Trong bÃ i viáº¿t nÃ y, chÃºng ta tÃ¬m hiá»ƒu vá» má»™t sá»‘ lÄ©nh vá»±c á»©ng dá»¥ng chÃ­nh vÃ  cÃ¡ch AI Ä‘ang chuyá»ƒn Ä‘á»•i lÄ©nh vá»±c nghiÃªn cá»©u gen, Ä‘Ã£ dáº«n Ä‘áº¿n nhá»¯ng Ä‘á»™t phÃ¡ nhanh chÃ³ng trong lÄ©nh vá»±c y táº¿ vÃ  khÃ¡m phÃ¡ thuá»‘c.
#AI #Healthcare #Genomics","Trong bÃ i viáº¿t nÃ y, chÃºng ta tÃ¬m hiá»ƒu vá» má»™t sá»‘ lÄ©nh vá»±c á»©ng dá»¥ng chÃ­nh vÃ  cÃ¡ch AI Ä‘ang chuyá»ƒn Ä‘á»•i lÄ©nh vá»±c nghiÃªn cá»©u gen, Ä‘Ã£ dáº«n Ä‘áº¿n nhá»¯ng Ä‘á»™t phÃ¡ nhanh chÃ³ng trong lÄ©nh vá»±c y táº¿ vÃ  khÃ¡m phÃ¡ thuá»‘c.",#AI	#Healthcare	#Genomics,,#sharing,,
"Má»œI THAM GIA KALAPA BYTEBATTLES 2023
Hi má»i ngÆ°á»i. MÃ¬nh lÃ  CÆ°Æ¡ng, Project Manager táº¡i KALAPA - má»™t startup trong lÄ©nh vá»±c cÃ´ng nghá»‡ vÃ  TrÃ­ tuá»‡ nhÃ¢n táº¡o. Tiáº¿p ná»‘i thÃ nh cÃ´ng cá»§a KALAPA Credit Scoring Challenge 2020 vá»›i hÆ¡n 800 ngÆ°á»i tham gia, nÄƒm nay cÃ´ng ty mÃ¬nh, dÆ°á»›i sá»± báº£o trá»£ cá»§a Há»™i Tin há»c Viá»‡t Nam, tiáº¿p tá»¥c tá»• chá»©c má»™t cuá»™c thi AI cÃ³ tÃªn gá»i KALAPA BYTEBATTLES. Cuá»™c thi nÄƒm nay gá»“m 2 bÃ i toÃ¡n, trong Ä‘Ã³ cÃ³ má»™t bÃ i toÃ¡n chÆ°a tá»«ng xuáº¥t hiá»‡n á»Ÿ cÃ¡c cuá»™c thi khÃ¡c: Vietnamese Medical Multiple-choice Question Answering, há»©a háº¹n mang láº¡i nhiá»u thá»­ thÃ¡ch háº¥p dáº«n vÃ  nhiá»u Ä‘Ã³ng gÃ³p má»›i cho cá»™ng Ä‘á»“ng lÃ m AI á»Ÿ Viá»‡t Nam.
NgoÃ i ra bá»n mÃ¬nh cÅ©ng sáº½ tá»• chá»©c tráº­n chung káº¿t dÆ°á»›i hÃ¬nh thá»©c Ä‘á»‘i khÃ¡ng 1vs1 giá»¯a model cá»§a cÃ¡c Ä‘á»™i, hy vá»ng sáº½ mang láº¡i luá»“ng giÃ³ má»›i giá»¯a cÃ¡c cuá»™c thi Ä‘Æ°á»£c tá»• chá»©c hiá»‡n nay.
ThÃ´ng tin vá» cuá»™c thi cÃ³ táº¡i: https://challenge.kalapa.vn/
 â€” vá»›i Thu Thuá»· vÃ  Äan Thy.","Má»œI THAM GIA KALAPA BYTEBATTLES 2023 Hi má»i ngÆ°á»i. MÃ¬nh lÃ  CÆ°Æ¡ng, Project Manager táº¡i KALAPA - má»™t startup trong lÄ©nh vá»±c cÃ´ng nghá»‡ vÃ  TrÃ­ tuá»‡ nhÃ¢n táº¡o. Tiáº¿p ná»‘i thÃ nh cÃ´ng cá»§a KALAPA Credit Scoring Challenge 2020 vá»›i hÆ¡n 800 ngÆ°á»i tham gia, nÄƒm nay cÃ´ng ty mÃ¬nh, dÆ°á»›i sá»± báº£o trá»£ cá»§a Há»™i Tin há»c Viá»‡t Nam, tiáº¿p tá»¥c tá»• chá»©c má»™t cuá»™c thi AI cÃ³ tÃªn gá»i KALAPA BYTEBATTLES. Cuá»™c thi nÄƒm nay gá»“m 2 bÃ i toÃ¡n, trong Ä‘Ã³ cÃ³ má»™t bÃ i toÃ¡n chÆ°a tá»«ng xuáº¥t hiá»‡n á»Ÿ cÃ¡c cuá»™c thi khÃ¡c: Vietnamese Medical Multiple-choice Question Answering, há»©a háº¹n mang láº¡i nhiá»u thá»­ thÃ¡ch háº¥p dáº«n vÃ  nhiá»u Ä‘Ã³ng gÃ³p má»›i cho cá»™ng Ä‘á»“ng lÃ m AI á»Ÿ Viá»‡t Nam. NgoÃ i ra bá»n mÃ¬nh cÅ©ng sáº½ tá»• chá»©c tráº­n chung káº¿t dÆ°á»›i hÃ¬nh thá»©c Ä‘á»‘i khÃ¡ng 1vs1 giá»¯a model cá»§a cÃ¡c Ä‘á»™i, hy vá»ng sáº½ mang láº¡i luá»“ng giÃ³ má»›i giá»¯a cÃ¡c cuá»™c thi Ä‘Æ°á»£c tá»• chá»©c hiá»‡n nay. ThÃ´ng tin vá» cuá»™c thi cÃ³ táº¡i: https://challenge.kalapa.vn/ â€” vá»›i Thu Thuá»· vÃ  Äan Thy.",,,#sharing,,
"Mn cho em tham kháº£o Ã½ kiáº¿n vá» topic clustering text vá»›i áº¡.
E Ä‘á»‹nh sá»­ dá»¥ng tf-idf vá»›i clustering algorithm (k-means, dbscan,..) Ä‘á»ƒ lÃ m case nÃ y. NhÆ°ng data text nÃ³ khÃ¡ ngáº¯n (1 row trung bÃ¬nh chá»‰ 6 7 tá»«), vÃ  viáº¿t sai chÃ­nh táº£ vá»›i viáº¿t khÃ´ng dáº¥u cÅ©ng cÃ³ nÃªn mn cÃ³ suggest j cho viá»‡c preprocess Ä‘á»‘ng nÃ y hong áº¡ (e tÃ­nh unidecode nÃ³ háº¿t lun xong traceback láº¡i cÃ¡i ban Ä‘áº§u).
Mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a má»i ngÆ°á»i áº¡, cáº£m Æ¡n mn nhÃ¬u, e cx má»›i mÃ² vá» NLP nÃªn mn thÃ´ng cáº£m.","Mn cho em tham kháº£o Ã½ kiáº¿n vá» topic clustering text vá»›i áº¡. E Ä‘á»‹nh sá»­ dá»¥ng tf-idf vá»›i clustering algorithm (k-means, dbscan,..) Ä‘á»ƒ lÃ m case nÃ y. NhÆ°ng data text nÃ³ khÃ¡ ngáº¯n (1 row trung bÃ¬nh chá»‰ 6 7 tá»«), vÃ  viáº¿t sai chÃ­nh táº£ vá»›i viáº¿t khÃ´ng dáº¥u cÅ©ng cÃ³ nÃªn mn cÃ³ suggest j cho viá»‡c preprocess Ä‘á»‘ng nÃ y hong áº¡ (e tÃ­nh unidecode nÃ³ háº¿t lun xong traceback láº¡i cÃ¡i ban Ä‘áº§u). Mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a má»i ngÆ°á»i áº¡, cáº£m Æ¡n mn nhÃ¬u, e cx má»›i mÃ² vá» NLP nÃªn mn thÃ´ng cáº£m.",,,"#Q&A, #nlp",,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2022 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2022 vÃ o comment cá»§a post nÃ y.",,,#sharing,,
"Hi má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m project dá»± Ä‘oÃ¡n káº¿t quáº£ thÃ­ nghiá»‡m váº­t liá»‡u xÃ¢y dá»±ng bao gá»“m nhiá»u models khÃ¡c nhau nháº±m Ä‘Ã¡nh giÃ¡ nhiá»u khÃ­a cáº¡nh cá»§a thÃ­ nghiá»‡m. Em Ä‘ang sá»­ dá»¥ng RestAPI Ä‘á»ƒ call artifact tá»« MLFlow sau Ä‘Ã³ predict xuáº¥t ra káº¿t quáº£, bÃªn cáº¡nh Ä‘Ã³ cÃ³ cháº¡y Ä‘á»“ng thá»i tÃ­nh SHAP values Ä‘á»ƒ giáº£i thÃ­ch model.
1. Em Ä‘ang gáº·p váº¥n Ä‘á» tráº£ káº¿t quáº£ khÃ¡ lÃ¢u vÃ¬ input Ä‘áº§u vÃ o khoáº£ng 1000 data ( máº¥t táº§m 3 phÃºt), em muá»‘n há»i cÃ³ cÃ¡ch nÃ o tá»‘i Æ°u Ä‘á»ƒ giÃºp mÃ´ hÃ¬nh predict nhanh hÆ¡n khÃ´ng áº¡ ?
2. Theo em biáº¿t, cÃ¡c model tá»« library sklearn khÃ´ng sá»­ dá»¥ng GPU, nÃªn káº¿t quáº£ tráº£ ra lÃ  tuáº§n tá»±, liá»‡u cÃ³ cÃ¡ch nÃ o cháº¡y táº¥t cáº£ káº¿t quáº£ cÃ¹ng 1 lÃºc ?
Em gá»­i cáº¥u hÃ¬nh hiá»‡n táº¡i cá»§a mÃ¡y em áº¡, em cáº£m Æ¡nğŸ‘©â€ğŸ’»","Hi má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m project dá»± Ä‘oÃ¡n káº¿t quáº£ thÃ­ nghiá»‡m váº­t liá»‡u xÃ¢y dá»±ng bao gá»“m nhiá»u models khÃ¡c nhau nháº±m Ä‘Ã¡nh giÃ¡ nhiá»u khÃ­a cáº¡nh cá»§a thÃ­ nghiá»‡m. Em Ä‘ang sá»­ dá»¥ng RestAPI Ä‘á»ƒ call artifact tá»« MLFlow sau Ä‘Ã³ predict xuáº¥t ra káº¿t quáº£, bÃªn cáº¡nh Ä‘Ã³ cÃ³ cháº¡y Ä‘á»“ng thá»i tÃ­nh SHAP values Ä‘á»ƒ giáº£i thÃ­ch model. 1. Em Ä‘ang gáº·p váº¥n Ä‘á» tráº£ káº¿t quáº£ khÃ¡ lÃ¢u vÃ¬ input Ä‘áº§u vÃ o khoáº£ng 1000 data ( máº¥t táº§m 3 phÃºt), em muá»‘n há»i cÃ³ cÃ¡ch nÃ o tá»‘i Æ°u Ä‘á»ƒ giÃºp mÃ´ hÃ¬nh predict nhanh hÆ¡n khÃ´ng áº¡ ? 2. Theo em biáº¿t, cÃ¡c model tá»« library sklearn khÃ´ng sá»­ dá»¥ng GPU, nÃªn káº¿t quáº£ tráº£ ra lÃ  tuáº§n tá»±, liá»‡u cÃ³ cÃ¡ch nÃ o cháº¡y táº¥t cáº£ káº¿t quáº£ cÃ¹ng 1 lÃºc ? Em gá»­i cáº¥u hÃ¬nh hiá»‡n táº¡i cá»§a mÃ¡y em áº¡, em cáº£m Æ¡n",,,"#Q&A, #python",,
"Má»i ngÆ°á»i cÃ³ ai lÃ m vá» cÃ¡i nháº­n diá»‡n xem ngÆ°á»i tham gia giao thÃ´ng cÃ³ Ä‘á»™i mÅ© báº£o hiá»ƒm rá»“i trÃ­ch xuáº¥t biá»ƒn sá»‘ chÆ°a, náº¿u rá»“i thÃ¬ cÃ³ thá»ƒ cho e xin link tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡?","Má»i ngÆ°á»i cÃ³ ai lÃ m vá» cÃ¡i nháº­n diá»‡n xem ngÆ°á»i tham gia giao thÃ´ng cÃ³ Ä‘á»™i mÅ© báº£o hiá»ƒm rá»“i trÃ­ch xuáº¥t biá»ƒn sá»‘ chÆ°a, náº¿u rá»“i thÃ¬ cÃ³ thá»ƒ cho e xin link tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡?",,,"#Q&A, #cv",,
"DopikAI vá»«a public DPKLLM Benchmark - Bá»™ benchmark dataset dÃ nh riÃªng cho LLM tiáº¿ng Viá»‡t, dÆ°á»›i dáº¡ng má»™t challenge tá»• chá»©c trÃªn aihub. DPKLLM tiáº¿n hÃ nh Ä‘Ã¡nh giÃ¡ trÃªn nhiá»u táº­p dataset vá»›i nhiá»u tÃ¡c vá»¥ khÃ¡c nhau

ViLaw-QA: Táº­p trung vÃ o váº¥n Ä‘á» há»i Ä‘Ã¡p trÃªn miá»n dá»¯ liá»‡u vá» luáº­t phÃ¡p Viá»‡t Nam
VitruthfulQA: Táº­p trung Ä‘Ã¡nh giÃ¡ tÃ­nh trung thá»±c cá»§a cÃ¡c cÃ¢u tráº£ lá»i Ä‘Æ°á»£c sinh bá»Ÿi LLM (tÆ°Æ¡ng tá»± TruthfulQA nhÆ°ng dÃ nh cho tiáº¿ng Viá»‡t)
CÃ¡c táº­p dá»¯ liá»‡u chuyÃªn vá» há»i Ä‘Ã¡p cá»§a cÃ¡c bÃªn khÃ¡c nhÆ° ViWikiQA, ViCoQA, ViNewsQA, ...
NgoÃ i ra, challenge cÅ©ng xem xÃ©t Ä‘Ã¡nh giÃ¡ tÃ¡c vá»¥ NER vá»›i tiáº¿ng Viá»‡t cá»§a LLM 

ÄÃ¢y lÃ  cÆ¡ há»™i Ä‘á»ƒ cÃ¡c cÃ¡ nhÃ¢n, tá»• chá»©c Ä‘ang phÃ¡t triá»ƒn LLM cÃ³ thá»ƒ tham gia Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh káº¿t quáº£ cá»§a mÃ¬nh vá»›i cÃ¡c bÃªn khÃ¡c cÅ©ng nhÆ° trao Ä‘á»•i vÃ  há»c há»i láº«n nhau. Challenge kÃ©o dÃ i vÃ´ thá»i háº¡n, vÃ  má»i ngÆ°á»i cÃ³ thá»ƒ dá»… dÃ ng Ä‘Äƒng kÃ½ tham gia cÅ©ng nhÆ° submit káº¿t quáº£ lÃªn há»‡ thá»‘ng. ","DopikAI vá»«a public DPKLLM Benchmark - Bá»™ benchmark dataset dÃ nh riÃªng cho LLM tiáº¿ng Viá»‡t, dÆ°á»›i dáº¡ng má»™t challenge tá»• chá»©c trÃªn aihub. DPKLLM tiáº¿n hÃ nh Ä‘Ã¡nh giÃ¡ trÃªn nhiá»u táº­p dataset vá»›i nhiá»u tÃ¡c vá»¥ khÃ¡c nhau ViLaw-QA: Táº­p trung vÃ o váº¥n Ä‘á» há»i Ä‘Ã¡p trÃªn miá»n dá»¯ liá»‡u vá» luáº­t phÃ¡p Viá»‡t Nam VitruthfulQA: Táº­p trung Ä‘Ã¡nh giÃ¡ tÃ­nh trung thá»±c cá»§a cÃ¡c cÃ¢u tráº£ lá»i Ä‘Æ°á»£c sinh bá»Ÿi LLM (tÆ°Æ¡ng tá»± TruthfulQA nhÆ°ng dÃ nh cho tiáº¿ng Viá»‡t) CÃ¡c táº­p dá»¯ liá»‡u chuyÃªn vá» há»i Ä‘Ã¡p cá»§a cÃ¡c bÃªn khÃ¡c nhÆ° ViWikiQA, ViCoQA, ViNewsQA, ... NgoÃ i ra, challenge cÅ©ng xem xÃ©t Ä‘Ã¡nh giÃ¡ tÃ¡c vá»¥ NER vá»›i tiáº¿ng Viá»‡t cá»§a LLM ÄÃ¢y lÃ  cÆ¡ há»™i Ä‘á»ƒ cÃ¡c cÃ¡ nhÃ¢n, tá»• chá»©c Ä‘ang phÃ¡t triá»ƒn LLM cÃ³ thá»ƒ tham gia Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh káº¿t quáº£ cá»§a mÃ¬nh vá»›i cÃ¡c bÃªn khÃ¡c cÅ©ng nhÆ° trao Ä‘á»•i vÃ  há»c há»i láº«n nhau. Challenge kÃ©o dÃ i vÃ´ thá»i háº¡n, vÃ  má»i ngÆ°á»i cÃ³ thá»ƒ dá»… dÃ ng Ä‘Äƒng kÃ½ tham gia cÅ©ng nhÆ° submit káº¿t quáº£ lÃªn há»‡ thá»‘ng.",,,"#sharing, #data",,
"Tuy khÃ´ng liÃªn quan tá»›i ML/DL/AI, nhÆ°ng thá»‘ng kÃª luÃ´n cÃ³ vai trÃ² ráº¥t quan trá»ng trong Khoa há»c dá»¯ liá»‡u. DÆ°á»›i Ä‘Ã¢y lÃ  thÃ´ng tin vá» lá»›p há»c do GS Richard McElreath Ä‘ang giáº£ng bÃ i vá» cuá»‘n sÃ¡ch cá»§a GS cÃ³ tÃªn""Statistical Rethinking (2023 Edition)"" theo trÆ°á»ng phÃ¡i thá»‘ng kÃª Bayesian trong 10 tuáº§n. CÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi táº¡i Ä‘Ã¢y https://github.com/rmcelreath/stat_rethinking_2023. Táº¡i Ä‘á»‹a chá»‰ GitHub nÃ y, bÃ i giáº£ng ghi hÃ¬nh vÃ  upload 2 láº§n/tuáº§n.","Tuy khÃ´ng liÃªn quan tá»›i ML/DL/AI, nhÆ°ng thá»‘ng kÃª luÃ´n cÃ³ vai trÃ² ráº¥t quan trá»ng trong Khoa há»c dá»¯ liá»‡u. DÆ°á»›i Ä‘Ã¢y lÃ  thÃ´ng tin vá» lá»›p há»c do GS Richard McElreath Ä‘ang giáº£ng bÃ i vá» cuá»‘n sÃ¡ch cá»§a GS cÃ³ tÃªn""Statistical Rethinking (2023 Edition)"" theo trÆ°á»ng phÃ¡i thá»‘ng kÃª Bayesian trong 10 tuáº§n. CÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi táº¡i Ä‘Ã¢y https://github.com/rmcelreath/stat_rethinking_2023. Táº¡i Ä‘á»‹a chá»‰ GitHub nÃ y, bÃ i giáº£ng ghi hÃ¬nh vÃ  upload 2 láº§n/tuáº§n.",,,#sharing,,
"ChÃ o cÃ¡c Anh, Chá»‹,
Sau khi tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh ARIMA trong time-series em tháº¯c máº¯c má»™t sá»‘ váº¥n Ä‘á» nhÆ° sau:
1) Æ¯u Ä‘iá»ƒm, nhÆ°á»£c Ä‘iá»ƒm cá»§a Arima model.
2) Arima thÃ­ch há»£p vá»›i bÃ i toÃ¡n time-series hay khÃ´ng? khi nÃ o thÃ¬ mÃ¬nh nÃªn dÃ¹ng ARIMA sáº½ cho káº¿t quáº£ tá»‘t.?
3) Arima vÃ  LSTM thÃ¬ phÆ°Æ¡ng phÃ¡p nÃ o thÆ°á»ng sáº½ cho káº¿t quáº£ tá»‘t hÆ¡n.
Em ráº¥t mong nháº­n Ä‘Æ°á»£c nhá»¯ng gÃ³p Ã½, tháº£o luáº­n cá»§a cÃ¡c Anh Chá»‹, Ä‘á»ƒ em cÃ³ thá»ƒ nÃ¢ng cao Ä‘Æ°á»£c thÃªm kiáº¿n thá»©c áº¡.","ChÃ o cÃ¡c Anh, Chá»‹, Sau khi tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh ARIMA trong time-series em tháº¯c máº¯c má»™t sá»‘ váº¥n Ä‘á» nhÆ° sau: 1) Æ¯u Ä‘iá»ƒm, nhÆ°á»£c Ä‘iá»ƒm cá»§a Arima model. 2) Arima thÃ­ch há»£p vá»›i bÃ i toÃ¡n time-series hay khÃ´ng? khi nÃ o thÃ¬ mÃ¬nh nÃªn dÃ¹ng ARIMA sáº½ cho káº¿t quáº£ tá»‘t.? 3) Arima vÃ  LSTM thÃ¬ phÆ°Æ¡ng phÃ¡p nÃ o thÆ°á»ng sáº½ cho káº¿t quáº£ tá»‘t hÆ¡n. Em ráº¥t mong nháº­n Ä‘Æ°á»£c nhá»¯ng gÃ³p Ã½, tháº£o luáº­n cá»§a cÃ¡c Anh Chá»‹, Ä‘á»ƒ em cÃ³ thá»ƒ nÃ¢ng cao Ä‘Æ°á»£c thÃªm kiáº¿n thá»©c áº¡.",,,"#Q&A, #deep_learning",,
"Xin chÃ o mn,
Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t Ä‘á»“ Ã¡n cÃ³ liÃªn quan tá»›i má»™t há»‡ thá»‘ng káº¿t ná»‘i cá»™ng Ä‘á»“ng AI. Äá»‘i tÆ°á»£ng tham gia cá»™ng Ä‘á»“ng nÃ y sáº½ lÃ  nhá»¯ng ngÆ°á»i cÃ³ kiáº¿n thá»©c vá» AI, nhá»¯ng ngÆ°á»i muá»‘n tÃ¬m job vá» AI, nhá»¯ng ngÆ°á»i cÃ³ nhu cáº§u thuÃª ngÆ°á»i lÃ m dá»± Ã¡n AI,... ThÃ¬ á»Ÿ Ä‘Ã¢y tháº§y em cÃ³ yÃªu cáº§u sáº½ dÃ¹ng AI Ä‘á»ƒ há»‡ thá»‘ng cÃ³ thá»ƒ Ä‘á» xuáº¥t nhá»¯ng ngÆ°á»i phÃ¹ há»£p nháº¥t vá»›i dá»± Ã¡n mÃ  ngÆ°á»i chá»§ dá»± Ã¡n Ä‘Ã£ Ä‘Äƒng. Cá»¥ thá»ƒ, nhá»¯ng ngÆ°á»i chá»§ Ã¡n sáº½ post dá»± Ã¡n lÃªn. VÃ  nhá»¯ng sáº½ theo kÃ¨m Ä‘Ã³ lÃ  description cá»§a dá»± Ã¡n. Dá»±a vÃ o Ä‘Ã³, há»‡ thá»‘ng sáº½ recommend nhá»¯ng ngÆ°á»i cÃ³ role phÃ¹ há»£p cho dá»± Ã¡n Ä‘Ã³. ( Äá»“ Ã¡n nÃ y chá»‰ giá»›i háº¡n pair matching giá»¯a nhá»¯ng dá»± Ã¡n lÃ m vá» AI vá»›i nhá»¯ng ngÆ°á»i lÃ m liÃªn quan tá»›i lÄ©nh vá»±c AI thÃ´i áº¡). Mn cÃ³ ai Ä‘Ã£ tá»«ng lÃ m qua cÃ³ thá»ƒ cho em xin nguá»“n tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Em cÃ³ tham kháº£o qua recommandation system cÅ©ng nhÆ° á»©ng dá»¥ng NLP nhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c hÆ°á»›ng Ä‘i rÃµ rÃ ng áº¡. Em cáº£m Æ¡n mn áº¡.","Xin chÃ o mn, Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t Ä‘á»“ Ã¡n cÃ³ liÃªn quan tá»›i má»™t há»‡ thá»‘ng káº¿t ná»‘i cá»™ng Ä‘á»“ng AI. Äá»‘i tÆ°á»£ng tham gia cá»™ng Ä‘á»“ng nÃ y sáº½ lÃ  nhá»¯ng ngÆ°á»i cÃ³ kiáº¿n thá»©c vá» AI, nhá»¯ng ngÆ°á»i muá»‘n tÃ¬m job vá» AI, nhá»¯ng ngÆ°á»i cÃ³ nhu cáº§u thuÃª ngÆ°á»i lÃ m dá»± Ã¡n AI,... ThÃ¬ á»Ÿ Ä‘Ã¢y tháº§y em cÃ³ yÃªu cáº§u sáº½ dÃ¹ng AI Ä‘á»ƒ há»‡ thá»‘ng cÃ³ thá»ƒ Ä‘á» xuáº¥t nhá»¯ng ngÆ°á»i phÃ¹ há»£p nháº¥t vá»›i dá»± Ã¡n mÃ  ngÆ°á»i chá»§ dá»± Ã¡n Ä‘Ã£ Ä‘Äƒng. Cá»¥ thá»ƒ, nhá»¯ng ngÆ°á»i chá»§ Ã¡n sáº½ post dá»± Ã¡n lÃªn. VÃ  nhá»¯ng sáº½ theo kÃ¨m Ä‘Ã³ lÃ  description cá»§a dá»± Ã¡n. Dá»±a vÃ o Ä‘Ã³, há»‡ thá»‘ng sáº½ recommend nhá»¯ng ngÆ°á»i cÃ³ role phÃ¹ há»£p cho dá»± Ã¡n Ä‘Ã³. ( Äá»“ Ã¡n nÃ y chá»‰ giá»›i háº¡n pair matching giá»¯a nhá»¯ng dá»± Ã¡n lÃ m vá» AI vá»›i nhá»¯ng ngÆ°á»i lÃ m liÃªn quan tá»›i lÄ©nh vá»±c AI thÃ´i áº¡). Mn cÃ³ ai Ä‘Ã£ tá»«ng lÃ m qua cÃ³ thá»ƒ cho em xin nguá»“n tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Em cÃ³ tham kháº£o qua recommandation system cÅ©ng nhÆ° á»©ng dá»¥ng NLP nhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c hÆ°á»›ng Ä‘i rÃµ rÃ ng áº¡. Em cáº£m Æ¡n mn áº¡.",,,#Q&A,,
"ChÃ o mn, em lÃ  sinh viÃªn nÄƒm cuá»‘i hiá»‡n Ä‘ang tÃ¬m hiá»ƒu vá» lÄ©nh vá»±c ML, DL, AI. Vá» pháº§n Ä‘á»“ Ã¡n tá»‘t nghiá»‡p cá»§a em tháº§y cÃ³ báº£o pháº£i sá»­ dá»¥ng mÃ´ hÃ¬nh AI Ä‘á»ƒ nháº­n dáº¡ng Ä‘Æ°á»£c tiáº¿ng á»“n cá»§a mÃ¡y (mÃ¡y hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh hay khÃ´ng). Tuy nhiÃªn trÃªn trÆ°á»ng em chá»‰ Ä‘Æ°á»£c há»c AI trong xá»­ lÃ½ dá»¯ liá»‡u, xá»­ lÃ½ áº£nh thÃ´i chá»© chÆ°a Ä‘áº¿n má»©c xá»­ lÃ½ Ã¢m thanh. Em cÃ³ tÃ¬m hiá»ƒu nhiá»u nguá»“n vá» xá»­ lÃ½ Ã¢m thanh mÃ  tháº¥y cÃ³ váº» khÃ´ng Ä‘Ãºng trong tÃ¢m láº¯m (chá»§ yáº¿u vá» nháº­n diá»‡n giá»ng nÃ³i)? Anh chá»‹ nÃ o cÃ³ nguá»“n nÃ o xá»­ lÃ½ Ã¢m thanh (nhÆ° sÃ¡ch, vidieo, khoÃ¡ há»c hay) cÃ³ thá»ƒ recommend em vá»›i áº¡, cÃ ng chi tiáº¿t cÃ ng tá»‘t Ä‘á»ƒ sau nÃ y báº£o vá»‡ Ä‘á»“ Ã¡n á»•n áº¡!
Em cÃ¡m Æ¡n mn Ä‘Ã£ bá» thá»i gian Ä‘á»c bÃ i viáº¿t!","ChÃ o mn, em lÃ  sinh viÃªn nÄƒm cuá»‘i hiá»‡n Ä‘ang tÃ¬m hiá»ƒu vá» lÄ©nh vá»±c ML, DL, AI. Vá» pháº§n Ä‘á»“ Ã¡n tá»‘t nghiá»‡p cá»§a em tháº§y cÃ³ báº£o pháº£i sá»­ dá»¥ng mÃ´ hÃ¬nh AI Ä‘á»ƒ nháº­n dáº¡ng Ä‘Æ°á»£c tiáº¿ng á»“n cá»§a mÃ¡y (mÃ¡y hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh hay khÃ´ng). Tuy nhiÃªn trÃªn trÆ°á»ng em chá»‰ Ä‘Æ°á»£c há»c AI trong xá»­ lÃ½ dá»¯ liá»‡u, xá»­ lÃ½ áº£nh thÃ´i chá»© chÆ°a Ä‘áº¿n má»©c xá»­ lÃ½ Ã¢m thanh. Em cÃ³ tÃ¬m hiá»ƒu nhiá»u nguá»“n vá» xá»­ lÃ½ Ã¢m thanh mÃ  tháº¥y cÃ³ váº» khÃ´ng Ä‘Ãºng trong tÃ¢m láº¯m (chá»§ yáº¿u vá» nháº­n diá»‡n giá»ng nÃ³i)? Anh chá»‹ nÃ o cÃ³ nguá»“n nÃ o xá»­ lÃ½ Ã¢m thanh (nhÆ° sÃ¡ch, vidieo, khoÃ¡ há»c hay) cÃ³ thá»ƒ recommend em vá»›i áº¡, cÃ ng chi tiáº¿t cÃ ng tá»‘t Ä‘á»ƒ sau nÃ y báº£o vá»‡ Ä‘á»“ Ã¡n á»•n áº¡! Em cÃ¡m Æ¡n mn Ä‘Ã£ bá» thá»i gian Ä‘á»c bÃ i viáº¿t!",,,#Q&A,,
"Sau bao ngÃ y chá» Ä‘á»£i, nhÃ³m dá»‹ch sÃ¡ch cuá»‘i cÃ¹ng cÅ©ng Ä‘Ã£ hoÃ n thiá»‡n táº­p hai.
CÃ¡c báº¡n Ä‘Ã£ Ä‘Äƒng kÃ½ táº­p hai tá»« láº§n trÆ°á»›c chuáº©n bá»‹ nháº­n sÃ¡ch nhÃ©!","Sau bao ngÃ y chá» Ä‘á»£i, nhÃ³m dá»‹ch sÃ¡ch cuá»‘i cÃ¹ng cÅ©ng Ä‘Ã£ hoÃ n thiá»‡n táº­p hai. CÃ¡c báº¡n Ä‘Ã£ Ä‘Äƒng kÃ½ táº­p hai tá»« láº§n trÆ°á»›c chuáº©n bá»‹ nháº­n sÃ¡ch nhÃ©!",,,#sharing,,
Cho em há»i sao loss function khÃ´ng cÃ³ sigma Ä‘áº±ng trÆ°á»›c áº¡,Cho em há»i sao loss function khÃ´ng cÃ³ sigma Ä‘áº±ng trÆ°á»›c áº¡,,,"#Q&A, #math",,
"Em chÃ o cÃ¡c anh chá»‹, em lÃ  sinh viÃªn nÄƒm 3 Ä‘ang tÃ¬m hiá»ƒu vá» Computer Vision, cá»¥ thá»ƒ lÃ  vá» xá»­ lÃ½ dá»¯ liá»‡u 3D. Em cÃ³ tÃ¬m hiá»ƒu má»™5t vÃ i thÃ´ng tin trÃªn máº¡ng nhÆ°ng Ä‘a sá»‘ lÃ  paper mÃ  em Ä‘á»c thÃ¬ tháº¥y khÃ³ hiá»ƒu vá»›i cÃ³ nhiá»u cÃ¡i cÄƒn báº£n em chÆ°a biáº¿t. Anh chá»‹ cÃ³ thá»ƒ cho em xin má»™t sá»‘ cuá»‘n sÃ¡ch nÃ o vá» lÄ©nh vá»±c nÃ y Ä‘á»ƒ em cÃ³ thá»ƒ tÃ¬m hiá»ƒu tá»« cÆ¡ báº£n trÆ°á»›c khÃ´ng áº¡. Em xin cáº£m Æ¡n áº¡.","Em chÃ o cÃ¡c anh chá»‹, em lÃ  sinh viÃªn nÄƒm 3 Ä‘ang tÃ¬m hiá»ƒu vá» Computer Vision, cá»¥ thá»ƒ lÃ  vá» xá»­ lÃ½ dá»¯ liá»‡u 3D. Em cÃ³ tÃ¬m hiá»ƒu má»™5t vÃ i thÃ´ng tin trÃªn máº¡ng nhÆ°ng Ä‘a sá»‘ lÃ  paper mÃ  em Ä‘á»c thÃ¬ tháº¥y khÃ³ hiá»ƒu vá»›i cÃ³ nhiá»u cÃ¡i cÄƒn báº£n em chÆ°a biáº¿t. Anh chá»‹ cÃ³ thá»ƒ cho em xin má»™t sá»‘ cuá»‘n sÃ¡ch nÃ o vá» lÄ©nh vá»±c nÃ y Ä‘á»ƒ em cÃ³ thá»ƒ tÃ¬m hiá»ƒu tá»« cÆ¡ báº£n trÆ°á»›c khÃ´ng áº¡. Em xin cáº£m Æ¡n áº¡.",,,"#Q&A, #cv",,
"Má»i ngÆ°á»i Æ¡i, má»i ngÆ°á»i cho em há»i lÃ  lÃ m sao kiá»ƒm soÃ¡t Ä‘Æ°á»£c cÃ¢u tráº£ lá»i cá»§a chat gpt api váº­y áº¡? Em cÃ³ tÃ­ch há»£p vÃ o chatbot Ä‘Æ°a thÃ´ng tin sáº£n pháº©m giÃ¡ 300k mÃ  nÃ³ tráº£ lá»i khÃ¡ch 150k. Em cÃ³ tÃ¬m cÃ¡c thuá»™c tÃ­nh cá»§a nÃ³ vÃ  Ä‘á»c cÃ¡c tÃ i liá»‡u rá»“i nhÆ°ng mÃ  váº«n chÆ°a tÃ¬m ra áº¡","Má»i ngÆ°á»i Æ¡i, má»i ngÆ°á»i cho em há»i lÃ  lÃ m sao kiá»ƒm soÃ¡t Ä‘Æ°á»£c cÃ¢u tráº£ lá»i cá»§a chat gpt api váº­y áº¡? Em cÃ³ tÃ­ch há»£p vÃ o chatbot Ä‘Æ°a thÃ´ng tin sáº£n pháº©m giÃ¡ 300k mÃ  nÃ³ tráº£ lá»i khÃ¡ch 150k. Em cÃ³ tÃ¬m cÃ¡c thuá»™c tÃ­nh cá»§a nÃ³ vÃ  Ä‘á»c cÃ¡c tÃ i liá»‡u rá»“i nhÆ°ng mÃ  váº«n chÆ°a tÃ¬m ra áº¡",,,"#Q&A, #nlp",,
"ChÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i táº­p python cáº§n dÃ¹ng turicreate Ä‘á»ƒ sá»­ dá»¥ng sframe. NhÆ°ng khÃ´ng thá»ƒ cÃ i Ä‘Æ°á»£c Ä‘á»ƒ sá»­ dá»¥ng. TrÃªn group cÃ³ ai tá»«ng sá»­ duÌ£ng turicreate hoáº·c tÆ°Æ¡ng tá»± chá»‰ giÃºp e vá»›i áº¡. Em Ä‘ang cháº¡y song song Win 10 vÃ  Ubuntu 18.04 áº¡.
Cáº£m Æ¡n má»i ngÆ°Æ¡Ì€i!!!",ChÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i táº­p python cáº§n dÃ¹ng turicreate Ä‘á»ƒ sá»­ dá»¥ng sframe. NhÆ°ng khÃ´ng thá»ƒ cÃ i Ä‘Æ°á»£c Ä‘á»ƒ sá»­ dá»¥ng. TrÃªn group cÃ³ ai tá»«ng sá»­ duÌ£ng turicreate hoáº·c tÆ°Æ¡ng tá»± chá»‰ giÃºp e vá»›i áº¡. Em Ä‘ang cháº¡y song song Win 10 vÃ  Ubuntu 18.04 áº¡. Cáº£m Æ¡n má»i ngÆ°Æ¡Ì€i!!!,,,"#Q&A, #python",,
"Má»i ngÆ°á»i cho em há»i cÃ¡ch cÃ i Ä‘áº·t Turicreate trÃªn Python Ä‘Æ°á»£c khÃ´ng áº¡. Em cÃ³ thá»­ lÃ m theo nhá»¯ng cÃ¡ch á»Ÿ trÃªn máº¡ng nhÆ°ng váº«n bá»‹ bÃ¡o lá»—i áº¥y áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i trÆ°á»›c",Má»i ngÆ°á»i cho em há»i cÃ¡ch cÃ i Ä‘áº·t Turicreate trÃªn Python Ä‘Æ°á»£c khÃ´ng áº¡. Em cÃ³ thá»­ lÃ m theo nhá»¯ng cÃ¡ch á»Ÿ trÃªn máº¡ng nhÆ°ng váº«n bá»‹ bÃ¡o lá»—i áº¥y áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i trÆ°á»›c,,,#Q&A,,
"Em chÃ o má»i ngÆ°á»i áº¡, chuyá»‡n lÃ  em Ä‘ang lÃ m má»™t project vá» sinh áº£nh biá»ƒn bÃ¡o giao thÃ´ng sá»­ dá»¥ng mÃ´ hÃ¬nh diffusion. Em muá»‘n há»i má»i ngÆ°á»i, mÃ¬nh muá»‘n láº¥y datasets biá»ƒn bÃ¡o giao thÃ´ng chá»— nÃ o á»•n áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡","Em chÃ o má»i ngÆ°á»i áº¡, chuyá»‡n lÃ  em Ä‘ang lÃ m má»™t project vá» sinh áº£nh biá»ƒn bÃ¡o giao thÃ´ng sá»­ dá»¥ng mÃ´ hÃ¬nh diffusion. Em muá»‘n há»i má»i ngÆ°á»i, mÃ¬nh muá»‘n láº¥y datasets biá»ƒn bÃ¡o giao thÃ´ng chá»— nÃ o á»•n áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡",,,"#Q&A, #cv",,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh muá»‘n chia sáº» 1 python package NLP mÃ¬nh build cho cÃ´ng viá»‡c + cÃ¡ nhÃ¢n, má»i ngÆ°á»i cÃ³ thá»ƒ dÃ¹ng thá»­ vÃ  cho mÃ¬nh feedback Ä‘á»ƒ mÃ¬nh improve cÃ¡i package nÃ y hÆ¡n nhÃ©, táº¡i Ä‘Ã¢y cÅ©ng lÃ  tÃ¢m huyáº¿t cá»§a mÃ¬nh máº¥y thÃ¡ng qua ğŸ˜…
ThÆ° viá»‡n nÃ y mÃ¬nh build gá»“m 2 pháº§n chÃ­nh,
- P1: Supervised learning: dÃ¹ng HuggingFace's masked language model (cÃ³ thá»ƒ sá»­ dá»¥ng phobert hay envibert luÃ´n) hay causal language model (kiá»ƒu cá»§a gpt, cho tiáº¿ng viá»‡t thÃ¬ cÃ³ NlpHUST/gpt2-vietnamese) cho cÃ¡c task: classification, regression; vá»«a classification vá»«a regression, classification cÃ¡c level khÃ¡c nhau (mÃ¬nh gá»i nÃ³ lÃ  multihead); vÃ  cáº£ multilabel
- P2: Language model training: cho phÃ©p mÃ¬nh train 1 LLM (masked hoáº·c causal) from scratch, hoáº·c lÃ  cho LM fine-tuning (kiá»ƒu mÃ¬nh dÃ¹ng phobert mÃ  Ä‘Ã£ Ä‘Æ°á»£c train trÃªn táº­p dataset tiáº¿ng viá»‡t ráº¥t lá»›n gá»“m wikipedia hay bÃ¡o), xong mÃ¬nh train tiáº¿p nÃ³ cho táº­p data comment cá»§a user trÃªn sÃ n e-commerce, Ä‘á»ƒ nÃ³ Ä‘c finetune tá»‘t hÆ¡n trÃªn táº­p data nÃ y). Idea nÃ y mÃ¬nh nhá»› báº¯t Ä‘áº§u tá»« paper ULMFiT. CÃ¡i lá»£i cá»§a viá»‡c nÃ y lÃ  sau khi mÃ¬nh cho model train trÃªn táº­p data nÃ y xong (e.g. data user comment), mÃ¬nh cho model há»c tiáº¿p nhá»¯ng cÃ¡i supervised learning task nháº¯c tá»›i á»Ÿ pháº§n 1, kiá»ƒu predict coi user nÃ y Ä‘ang comment vá» category gÃ¬, thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³ sáº½ Ä‘Æ°á»£c boost lÃªn 1 chÃºt ná»¯a.
Vá»›i tá»«ng pháº§n á»Ÿ trÃªn thÃ¬ mÃ¬nh chia nÃ³ thÃ nh 2 process: 1 process chuyÃªn lÃ m text preprocessing (cÃ³ thá»ƒ lÃ m Ä‘a luá»“ng luÃ´n, vÃ¬ backend mÃ¬nh dÃ¹ng HuggingFace Datasets lib), e.g. load data, filter data, text transform, cÃ³ cáº£ text augmentation), vÃ  1 process lÃ  Ä‘á»ƒ build model (Ä‘á»ƒ train model, log, save and load model ...)
Táº¥t cáº£ cÃ¡c thÃ´ng tin mÃ¬nh cÃ³ viáº¿t documentation vÃ  cÃ³ tutorial cho tá»«ng Ä‘oáº¡n, má»i ngÆ°á»i cÃ³ thá»ƒ xem qua á»Ÿ Ä‘Ã¢y: https://anhquan0412.github.io/that-nlp-library/. Cáº£m Æ¡n má»i ngÆ°á»i áº¡ :D","ChÃ o má»i ngÆ°á»i, mÃ¬nh muá»‘n chia sáº» 1 python package NLP mÃ¬nh build cho cÃ´ng viá»‡c + cÃ¡ nhÃ¢n, má»i ngÆ°á»i cÃ³ thá»ƒ dÃ¹ng thá»­ vÃ  cho mÃ¬nh feedback Ä‘á»ƒ mÃ¬nh improve cÃ¡i package nÃ y hÆ¡n nhÃ©, táº¡i Ä‘Ã¢y cÅ©ng lÃ  tÃ¢m huyáº¿t cá»§a mÃ¬nh máº¥y thÃ¡ng qua ThÆ° viá»‡n nÃ y mÃ¬nh build gá»“m 2 pháº§n chÃ­nh, - P1: Supervised learning: dÃ¹ng HuggingFace's masked language model (cÃ³ thá»ƒ sá»­ dá»¥ng phobert hay envibert luÃ´n) hay causal language model (kiá»ƒu cá»§a gpt, cho tiáº¿ng viá»‡t thÃ¬ cÃ³ NlpHUST/gpt2-vietnamese) cho cÃ¡c task: classification, regression; vá»«a classification vá»«a regression, classification cÃ¡c level khÃ¡c nhau (mÃ¬nh gá»i nÃ³ lÃ  multihead); vÃ  cáº£ multilabel - P2: Language model training: cho phÃ©p mÃ¬nh train 1 LLM (masked hoáº·c causal) from scratch, hoáº·c lÃ  cho LM fine-tuning (kiá»ƒu mÃ¬nh dÃ¹ng phobert mÃ  Ä‘Ã£ Ä‘Æ°á»£c train trÃªn táº­p dataset tiáº¿ng viá»‡t ráº¥t lá»›n gá»“m wikipedia hay bÃ¡o), xong mÃ¬nh train tiáº¿p nÃ³ cho táº­p data comment cá»§a user trÃªn sÃ n e-commerce, Ä‘á»ƒ nÃ³ Ä‘c finetune tá»‘t hÆ¡n trÃªn táº­p data nÃ y). Idea nÃ y mÃ¬nh nhá»› báº¯t Ä‘áº§u tá»« paper ULMFiT. CÃ¡i lá»£i cá»§a viá»‡c nÃ y lÃ  sau khi mÃ¬nh cho model train trÃªn táº­p data nÃ y xong (e.g. data user comment), mÃ¬nh cho model há»c tiáº¿p nhá»¯ng cÃ¡i supervised learning task nháº¯c tá»›i á»Ÿ pháº§n 1, kiá»ƒu predict coi user nÃ y Ä‘ang comment vá» category gÃ¬, thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³ sáº½ Ä‘Æ°á»£c boost lÃªn 1 chÃºt ná»¯a. Vá»›i tá»«ng pháº§n á»Ÿ trÃªn thÃ¬ mÃ¬nh chia nÃ³ thÃ nh 2 process: 1 process chuyÃªn lÃ m text preprocessing (cÃ³ thá»ƒ lÃ m Ä‘a luá»“ng luÃ´n, vÃ¬ backend mÃ¬nh dÃ¹ng HuggingFace Datasets lib), e.g. load data, filter data, text transform, cÃ³ cáº£ text augmentation), vÃ  1 process lÃ  Ä‘á»ƒ build model (Ä‘á»ƒ train model, log, save and load model ...) Táº¥t cáº£ cÃ¡c thÃ´ng tin mÃ¬nh cÃ³ viáº¿t documentation vÃ  cÃ³ tutorial cho tá»«ng Ä‘oáº¡n, má»i ngÆ°á»i cÃ³ thá»ƒ xem qua á»Ÿ Ä‘Ã¢y: https://anhquan0412.github.io/that-nlp-library/. Cáº£m Æ¡n má»i ngÆ°á»i áº¡ :D",,,"#sharing, #python",,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 02/2023 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 02/2023 vÃ o comment cá»§a post nÃ y.",,,#sharing,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2023 vÃ o comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n cÃ³ má»™t ká»³ nghá»‰ lá»… vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2023 vÃ o comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n cÃ³ má»™t ká»³ nghá»‰ lá»… vui váº».",,,#sharing,,
Mng cho em há»i: ai cÃ³ táº­p dataset liÃªn quan Ä‘áº¿n cÃ¡c chá»‰ sá»‘ vá» cháº¥t lÆ°á»£ng khÃ´ng khÃ­ nhÆ° nÃ y á»Ÿ viá»‡t nam khÃ´ng áº¡.,Mng cho em há»i: ai cÃ³ táº­p dataset liÃªn quan Ä‘áº¿n cÃ¡c chá»‰ sá»‘ vá» cháº¥t lÆ°á»£ng khÃ´ng khÃ­ nhÆ° nÃ y á»Ÿ viá»‡t nam khÃ´ng áº¡.,,,"#Q&A, #data",,
"Hi anh chá»‹, em Ä‘ang lÃ m bÃ i táº­p vá» Linear Regression dá»± Ä‘oÃ¡n giÃ¡ nhÃ  báº±ng thuáº­t toÃ¡n Gradient Decent( Giáº£m Ä‘á»™ dá»‘c), nhÆ°ng sau khi em test thá»­ model thÃ¬ cÃ¡c giÃ¡ trá»‹ predicton nÃ³ cÃ³ giÃ¡ trá»‹ ""nan"" lÃ  bá»‹ sao váº­y áº¡, mÃ´ hÃ¬nh nÃ y em test vá»›i táº­p dá»¯ liá»‡u nhá» thÃ¬ nÃ³ cho ra cÃ¡c dá»± Ä‘oÃ¡n khÃ¡ sÃ¡t vá»›i cÃ¡c giÃ¡ trá»‹ thá»±c táº¿, nhÆ°ng khi em thá»­ cÃ¡c táº­p dá»¯ liá»‡u khÃ¡ lá»›n thÃ¬ cÃ¡c giÃ¡ trá»‹ prediction báº±ng ""nan"", em Ä‘Ã£ thá»­ Ä‘iá»u chá»‰nh learing rate nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£ áº¡. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡, em cáº£m Æ¡n áº¡ !
Link github: https://github.com/bigboss151102/Linear_Regression/blob/master/prediction_house_TUD.ipynb","Hi anh chá»‹, em Ä‘ang lÃ m bÃ i táº­p vá» Linear Regression dá»± Ä‘oÃ¡n giÃ¡ nhÃ  báº±ng thuáº­t toÃ¡n Gradient Decent( Giáº£m Ä‘á»™ dá»‘c), nhÆ°ng sau khi em test thá»­ model thÃ¬ cÃ¡c giÃ¡ trá»‹ predicton nÃ³ cÃ³ giÃ¡ trá»‹ ""nan"" lÃ  bá»‹ sao váº­y áº¡, mÃ´ hÃ¬nh nÃ y em test vá»›i táº­p dá»¯ liá»‡u nhá» thÃ¬ nÃ³ cho ra cÃ¡c dá»± Ä‘oÃ¡n khÃ¡ sÃ¡t vá»›i cÃ¡c giÃ¡ trá»‹ thá»±c táº¿, nhÆ°ng khi em thá»­ cÃ¡c táº­p dá»¯ liá»‡u khÃ¡ lá»›n thÃ¬ cÃ¡c giÃ¡ trá»‹ prediction báº±ng ""nan"", em Ä‘Ã£ thá»­ Ä‘iá»u chá»‰nh learing rate nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£ áº¡. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡, em cáº£m Æ¡n áº¡ ! Link github: https://github.com/bigboss151102/Linear_Regression/blob/master/prediction_house_TUD.ipynb",,,"#Q&A, #machine_learning",,
"Xin chÃ o má»i ngÆ°á»i, em cÃ³ Ã½ Ä‘á»‹nh sáº½ táº¡o ra má»™t con AI / ML cÃ³ kháº£ nÄƒng generate ra model 3d nhÃ  theo phong cÃ¡ch kiáº¿n trÃºc Viá»‡t Nam, ngoÃ i ra em cÅ©ng tÃ² mÃ², muá»‘n hiá»ƒu sÃ¢u vá» cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng, hiá»ƒu rÃµ báº£n cháº¥t cá»§a cÃ¡c á»©ng dá»¥ng giáº£ giá»ng nÃ³i áº¡. NhÆ°ng hiá»‡n táº¡i kiáº¿n thá»©c vá» ML hay AI cá»§a em gáº§n nhÆ° báº±ng 0, do Ä‘Ã³ e Ä‘Ã£ Ä‘áº·t ra má»¥c tiÃªu dÃ i háº¡n sáº½ há»c vá» AI / ML Ä‘á»ƒ hoÃ n thÃ nh Ä‘c má»¥c tiÃªu e Ä‘Ã£ Ä‘á» cáº­p áº¡
VÃ¬ váº­y cÃ³ bÃ¡c nÃ o rÃ nh vá» lÄ©nh vá»±c nÃ y cÃ³ thá»ƒ tÆ° váº¥n giÃºp em lá»™ trÃ¬nh há»c hiá»‡u quáº£ theo hÆ°á»›ng cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘c 2 nhu cáº§u trÃªn cá»§a e ko áº¡, em cÃ¡m Æ¡n.","Xin chÃ o má»i ngÆ°á»i, em cÃ³ Ã½ Ä‘á»‹nh sáº½ táº¡o ra má»™t con AI / ML cÃ³ kháº£ nÄƒng generate ra model 3d nhÃ  theo phong cÃ¡ch kiáº¿n trÃºc Viá»‡t Nam, ngoÃ i ra em cÅ©ng tÃ² mÃ², muá»‘n hiá»ƒu sÃ¢u vá» cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng, hiá»ƒu rÃµ báº£n cháº¥t cá»§a cÃ¡c á»©ng dá»¥ng giáº£ giá»ng nÃ³i áº¡. NhÆ°ng hiá»‡n táº¡i kiáº¿n thá»©c vá» ML hay AI cá»§a em gáº§n nhÆ° báº±ng 0, do Ä‘Ã³ e Ä‘Ã£ Ä‘áº·t ra má»¥c tiÃªu dÃ i háº¡n sáº½ há»c vá» AI / ML Ä‘á»ƒ hoÃ n thÃ nh Ä‘c má»¥c tiÃªu e Ä‘Ã£ Ä‘á» cáº­p áº¡ VÃ¬ váº­y cÃ³ bÃ¡c nÃ o rÃ nh vá» lÄ©nh vá»±c nÃ y cÃ³ thá»ƒ tÆ° váº¥n giÃºp em lá»™ trÃ¬nh há»c hiá»‡u quáº£ theo hÆ°á»›ng cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘c 2 nhu cáº§u trÃªn cá»§a e ko áº¡, em cÃ¡m Æ¡n.",,,#Q&A,,
"Em Ä‘ang táº­p tÃ nh chuyá»ƒn qua google colab nhÆ°ng khi upload file lÃªn thÃ¬ cÃ¡c hÃ¬nh áº£nh trong Markdown Ä‘á»u bá»‹ lá»—i khÃ´ng load Ä‘Æ°á»£c máº·c dÃ¹ Ä‘Ã£ Ä‘Ãºng Ä‘Æ°á»ng dáº«n áº¡.
Edit:
Sau má»™t há»“i nghiÃªn cá»©u thÃ¬ cÃ³ váº» nhÆ° tháº» <img> trong MarkDown khÃ´ng hoáº¡t Ä‘á»™ng trong Ä‘Æ°á»ng dáº«n local vÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³ (trong khi sá»­ dá»¥ng cÃ¹ng format Ä‘Æ°á»ng dáº«n Ä‘á»ƒ read file thÃ¬ ok) nhÆ°ng láº¡i hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c vá»›i cÃ¡c URL global. DÆ°á»›i Ä‘Ã¢y lÃ  video cÃ¡ch láº¥y link cÃ¡c file áº£nh trong google drive Ä‘á»ƒ sá»­ dá»¥ng vÃ o colab.
Anh em nÃ o cÃ³ phÆ°Æ¡ng phÃ¡p hay Ã½ kiáº¿n tá»‘t hÆ¡n má»i bÃ¬nh luáº­n bÃªn dÆ°á»›i áº¡. Thank
https://www.youtube.com/watch?v=gCsmANNdmfo",Em Ä‘ang táº­p tÃ nh chuyá»ƒn qua google colab nhÆ°ng khi upload file lÃªn thÃ¬ cÃ¡c hÃ¬nh áº£nh trong Markdown Ä‘á»u bá»‹ lá»—i khÃ´ng load Ä‘Æ°á»£c máº·c dÃ¹ Ä‘Ã£ Ä‘Ãºng Ä‘Æ°á»ng dáº«n áº¡. Edit: Sau má»™t há»“i nghiÃªn cá»©u thÃ¬ cÃ³ váº» nhÆ° tháº» <img> trong MarkDown khÃ´ng hoáº¡t Ä‘á»™ng trong Ä‘Æ°á»ng dáº«n local vÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³ (trong khi sá»­ dá»¥ng cÃ¹ng format Ä‘Æ°á»ng dáº«n Ä‘á»ƒ read file thÃ¬ ok) nhÆ°ng láº¡i hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c vá»›i cÃ¡c URL global. DÆ°á»›i Ä‘Ã¢y lÃ  video cÃ¡ch láº¥y link cÃ¡c file áº£nh trong google drive Ä‘á»ƒ sá»­ dá»¥ng vÃ o colab. Anh em nÃ o cÃ³ phÆ°Æ¡ng phÃ¡p hay Ã½ kiáº¿n tá»‘t hÆ¡n má»i bÃ¬nh luáº­n bÃªn dÆ°á»›i áº¡. Thank https://www.youtube.com/watch?v=gCsmANNdmfo,,,#Q&A,,
"ChÃ o buá»•i tá»‘i má»i ngÆ°á»i,
LÃºc launching Vietcuna thÃ¬ team VILM cÃ³ há»©a sáº½ cÃ³ phiÃªn báº£n 40B cá»§a Vietcuna. HÃ´m nay team ráº¥t vui giá»›i thiá»‡u 2 model má»›i nháº¥t cá»§a team lÃ  Vulture-40B vÃ  Vulture-180B vá»›i há»— trá»£ lÃªn tá»›i 12 ngÃ´n ngá»¯, táº¥t nhiÃªn lÃ  cÃ³ há»— trá»£ tiáº¿ng Viá»‡t. VILM mong Vulture series sáº½ lÃ  cÃ´ng cá»¥ Ä‘áº¯c lá»±c giÃºp cÃ¡c cÃ´ng ty Viá»‡t Nam vÆ°Æ¡n ra biá»ƒn lá»›n! ğŸ™‚
Supported Languages: English, German, Spanish, French, Portugese, Russian, Italian, Vietnamese, Indonesian, Chinese, Japanese and Chinese
Announcement: [https://www.vilm.org/research/meet-vulture-40b-and-180b-worlds-largest-multilingual-language-models]
Vulture-40B: [https://huggingface.co/vilm/vulture-40b]
Vulture-180B: [https://huggingface.co/vilm/vulture-180b]","ChÃ o buá»•i tá»‘i má»i ngÆ°á»i, LÃºc launching Vietcuna thÃ¬ team VILM cÃ³ há»©a sáº½ cÃ³ phiÃªn báº£n 40B cá»§a Vietcuna. HÃ´m nay team ráº¥t vui giá»›i thiá»‡u 2 model má»›i nháº¥t cá»§a team lÃ  Vulture-40B vÃ  Vulture-180B vá»›i há»— trá»£ lÃªn tá»›i 12 ngÃ´n ngá»¯, táº¥t nhiÃªn lÃ  cÃ³ há»— trá»£ tiáº¿ng Viá»‡t. VILM mong Vulture series sáº½ lÃ  cÃ´ng cá»¥ Ä‘áº¯c lá»±c giÃºp cÃ¡c cÃ´ng ty Viá»‡t Nam vÆ°Æ¡n ra biá»ƒn lá»›n! Supported Languages: English, German, Spanish, French, Portugese, Russian, Italian, Vietnamese, Indonesian, Chinese, Japanese and Chinese Announcement: [https://www.vilm.org/research/meet-vulture-40b-and-180b-worlds-largest-multilingual-language-models] Vulture-40B: [https://huggingface.co/vilm/vulture-40b] Vulture-180B: [https://huggingface.co/vilm/vulture-180b]",,,"#sharing, #nlp",,
"Generative Knowledge AI Ä‘ang phÃ¡t triá»ƒn vá»›i tá»‘c Ä‘á»™ vÅ© bÃ£o, nháº¥t lÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models).
Tuy nhiÃªn, lÄ©nh vá»±c nghiÃªn cá»©u áº£nh táº¡o sinh vá»›i cÃ¡c mÃ´ hÃ¬nh nhÆ° DALLE (hiá»‡n DALLE-3 Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o ChatGPT-4(v), báº£n DALLE-2 cÃ³ open source nhÃ©) vÃ  Ä‘áº·c biá»‡t lÃ  open source Stable Diffusions (ControlNet lÃ  1 dáº¡ng variants tá»« SD) giá»¯ vai trÃ² quan trá»ng viá»‡c sÃ¡ng táº¡o ná»™i dung (content creation). VÃ­ dá»¥ ta cÃ³ thá»ƒ prompts ra áº£nh annimate trong truyá»‡n tranh hay vá» lÄ©nh vá»±c thiáº¿t káº¿ cÃ´ng nghiá»‡p/Ä‘á»“ hoáº¡/kiáº¿n trÃºc/xÃ¢y dá»±ng/..., ta cÃ³ thá»ƒ váº½ sketch rá»“i prompts cho ra sáº£n pháº©m â€œhoÃ n chá»‰nhâ€. ChÆ°a ká»ƒ chÃºng ta cÃ³ thá»ƒ nghiÃªn cá»©u á»©ng dá»¥ng SD vÃ o cÃ¡c domain chuyÃªn ngÃ nh háº¹p. Hi vá»ng mÃ¬nh cÃ³ thá»ƒ sá»›m ""khoe"" káº¿t quáº£ nÃ y trong thá»i gian sáº¯p tá»›i!!

Äá»ƒ lÃ m sinh Ä‘á»™ng hÆ¡n hÃ¬nh áº£nh tÄ©nh táº¡o sinh, gáº§n Ä‘Ã¢y cÃ¡c nhÃ  khoa há»c Ä‘Ã£ giá»›i thiá»‡u tá»›i má»i ngÆ°á»i source code cÃ³ thá»ƒ táº¡o áº£nh Ä‘Ã´ng (*gif) cÃ³ tÃªn lÃ  Annimatediff (táº¡i Ä‘Ã¢y https://github.com/guoyww/AnimateDiff) vÃ  Hotshot (táº¡i Ä‘Ã¢y https://github.com/hotshotco/Hotshot-XL)
Cáº£ 2 thÆ° viá»‡n nÃ y giÃºp chÃºng ta finetune model SD thÃ nh dáº¡ng áº£nh Ä‘á»™ng (*gif) thay vÃ¬ áº£nh tÄ©nh (jpg/png).
Hi vá»ng thÆ° viá»‡n nÃ y giÃºp cÃ¡c báº¡n há»c táº­p vÃ o thá»±c hÃ nh theo hÆ°á»›ng mÃ¬nh mong muá»‘n.","Generative Knowledge AI Ä‘ang phÃ¡t triá»ƒn vá»›i tá»‘c Ä‘á»™ vÅ© bÃ£o, nháº¥t lÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models). Tuy nhiÃªn, lÄ©nh vá»±c nghiÃªn cá»©u áº£nh táº¡o sinh vá»›i cÃ¡c mÃ´ hÃ¬nh nhÆ° DALLE (hiá»‡n DALLE-3 Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o ChatGPT-4(v), báº£n DALLE-2 cÃ³ open source nhÃ©) vÃ  Ä‘áº·c biá»‡t lÃ  open source Stable Diffusions (ControlNet lÃ  1 dáº¡ng variants tá»« SD) giá»¯ vai trÃ² quan trá»ng viá»‡c sÃ¡ng táº¡o ná»™i dung (content creation). VÃ­ dá»¥ ta cÃ³ thá»ƒ prompts ra áº£nh annimate trong truyá»‡n tranh hay vá» lÄ©nh vá»±c thiáº¿t káº¿ cÃ´ng nghiá»‡p/Ä‘á»“ hoáº¡/kiáº¿n trÃºc/xÃ¢y dá»±ng/..., ta cÃ³ thá»ƒ váº½ sketch rá»“i prompts cho ra sáº£n pháº©m â€œhoÃ n chá»‰nhâ€. ChÆ°a ká»ƒ chÃºng ta cÃ³ thá»ƒ nghiÃªn cá»©u á»©ng dá»¥ng SD vÃ o cÃ¡c domain chuyÃªn ngÃ nh háº¹p. Hi vá»ng mÃ¬nh cÃ³ thá»ƒ sá»›m ""khoe"" káº¿t quáº£ nÃ y trong thá»i gian sáº¯p tá»›i!! Äá»ƒ lÃ m sinh Ä‘á»™ng hÆ¡n hÃ¬nh áº£nh tÄ©nh táº¡o sinh, gáº§n Ä‘Ã¢y cÃ¡c nhÃ  khoa há»c Ä‘Ã£ giá»›i thiá»‡u tá»›i má»i ngÆ°á»i source code cÃ³ thá»ƒ táº¡o áº£nh Ä‘Ã´ng (*gif) cÃ³ tÃªn lÃ  Annimatediff (táº¡i Ä‘Ã¢y https://github.com/guoyww/AnimateDiff) vÃ  Hotshot (táº¡i Ä‘Ã¢y https://github.com/hotshotco/Hotshot-XL) Cáº£ 2 thÆ° viá»‡n nÃ y giÃºp chÃºng ta finetune model SD thÃ nh dáº¡ng áº£nh Ä‘á»™ng (*gif) thay vÃ¬ áº£nh tÄ©nh (jpg/png). Hi vá»ng thÆ° viá»‡n nÃ y giÃºp cÃ¡c báº¡n há»c táº­p vÃ o thá»±c hÃ nh theo hÆ°á»›ng mÃ¬nh mong muá»‘n.",,,"#sharing, #python",,
"Má»™t trong nhá»¯ng yáº¿u tá»‘ giÃºp chÃºng ta cÃ³ prompts tá»‘t Ä‘á»ƒ generate ra ná»™i  mong muá»‘n lÃ  viá»‡c lÃ m khÃ³. NÃªn má»›i cÃ³ nghá» má»›i gá»i lÃ  prompt engineers/engineering. DÆ°á»›i Ä‘Ã¢y lÃ  tá»•ng káº¿t 6 Ä‘iá»ƒm mÃ  tÃ´i copy&paste cá»§a Francois Chollet (tÃ¡c giáº£ bÃ i bÃ¡o vá» mÃ´ hÃ¬nh Inception vÃ  lÃ  ngÆ°á»i viáº¿t thÆ° viá»‡n Keras cá»§a Google)
""My interpretation of prompt engineering is this:
1. A LLM is a repository of many (millions) of vector programs mined from human-generated data, learned implicitly as a by-product of language compression. A ""vector program"" is just a very non-linear function that maps part of the latent space unto itself.
2. When you're prompting, you're fetching one of these programs and running it on an input -- part of your prompt serves as a kind of ""program key"" (as in database key) and part serves as program argument(s). Like, in ""write this paragraph in the style of Shakespeare: {my paragraph}"", the part ""write this paragraph in the stye of X: Y"" is a program key, with arguments X=Shakespeare and Y={my paragraph}.
3. The program fetched by your key may or may not work well for the task at hand. There's no reason why it should be optimal. There are lots of related programs to choose from.
4. Prompt engineering represents a search over many keys in order a find a program that is empirically more accurate for what you're trying to do. It's no different than trying different keywords when searching for a Python library.
5. Everything else is unnecessary anthropomorphism on the part of the prompter. You're not talking to a human who understands language the way you do. Stop pretending you are.â€
https://x.com/fchollet/status/1709242747293511939?s=46...
MÃ¬nh tá»«ng cÃ³ láº§n chia sáº» vá» viá»‡c cÃ³ ngÆ°á»i tá»•ng há»£p cÃ¡c áº£nh vÃ  prompts liÃªn quan tá»›i chá»§ Ä‘á»ƒ sinh áº£nh. MÃ¬nh sáº½ tÃ¬m láº¡i link GitHub cá»§a nÃ³ vÃ  chia sáº» bÃªn dÆ°á»›i.","Má»™t trong nhá»¯ng yáº¿u tá»‘ giÃºp chÃºng ta cÃ³ prompts tá»‘t Ä‘á»ƒ generate ra ná»™i mong muá»‘n lÃ  viá»‡c lÃ m khÃ³. NÃªn má»›i cÃ³ nghá» má»›i gá»i lÃ  prompt engineers/engineering. DÆ°á»›i Ä‘Ã¢y lÃ  tá»•ng káº¿t 6 Ä‘iá»ƒm mÃ  tÃ´i copy&paste cá»§a Francois Chollet (tÃ¡c giáº£ bÃ i bÃ¡o vá» mÃ´ hÃ¬nh Inception vÃ  lÃ  ngÆ°á»i viáº¿t thÆ° viá»‡n Keras cá»§a Google) ""My interpretation of prompt engineering is this: 1. A LLM is a repository of many (millions) of vector programs mined from human-generated data, learned implicitly as a by-product of language compression. A ""vector program"" is just a very non-linear function that maps part of the latent space unto itself. 2. When you're prompting, you're fetching one of these programs and running it on an input -- part of your prompt serves as a kind of ""program key"" (as in database key) and part serves as program argument(s). Like, in ""write this paragraph in the style of Shakespeare: {my paragraph}"", the part ""write this paragraph in the stye of X: Y"" is a program key, with arguments X=Shakespeare and Y={my paragraph}. 3. The program fetched by your key may or may not work well for the task at hand. There's no reason why it should be optimal. There are lots of related programs to choose from. 4. Prompt engineering represents a search over many keys in order a find a program that is empirically more accurate for what you're trying to do. It's no different than trying different keywords when searching for a Python library. 5. Everything else is unnecessary anthropomorphism on the part of the prompter. You're not talking to a human who understands language the way you do. Stop pretending you are.â€ https://x.com/fchollet/status/1709242747293511939?s=46... MÃ¬nh tá»«ng cÃ³ láº§n chia sáº» vá» viá»‡c cÃ³ ngÆ°á»i tá»•ng há»£p cÃ¡c áº£nh vÃ  prompts liÃªn quan tá»›i chá»§ Ä‘á»ƒ sinh áº£nh. MÃ¬nh sáº½ tÃ¬m láº¡i link GitHub cá»§a nÃ³ vÃ  chia sáº» bÃªn dÆ°á»›i.",,,"#sharing, #nlp",,
Netfilx System Design Backend,Netfilx System Design Backend,,,,,
ğŸ‘‰ FYI 04-05/10 | TÃ¢n SÆ¡n Nháº¥t Pavillon - HCM,FYI 04-05/10 | TÃ¢n SÆ¡n Nháº¥t Pavillon - HCM,,,,,
"Em chÃ o má»i ngÆ°á»i , e lÃ  newbie , e má»›i train 1 model trÃªn kaggle sau khi táº­p tÃ nh fine tuning 1 model (model Ä‘Ã³ fine tune dá»±a vÃ o Llama2 vÃ  Blomz trÃªn táº­p data tiáº¿ng viá»‡t ) trÃªn hugging face xong thÃ¬ e cÃ³ nháº¥n save model , sau Ä‘Ã³ vÃ o láº¡i thÃ¬ chá»‰ tháº¥y cÃ³ máº¥y file nhÆ° adapter _model.bin , adapter_config.json , redme, events.out.tfevens , Sau Ä‘Ã³ em cÃ³ táº£i koboldcpp vá» Ä‘á»ƒ cháº¡y nhÆ°ng khÃ´ng Ä‘Æ°á»£c . Má»i ngÆ°á»i cÃ³ biáº¿t cÃ¡ch nÃ o Ä‘á»ƒ cháº¡y file nÃ y ko áº¡ .VÃ  input Ä‘áº§u vÃ o cÃ³ nháº¥t thiáº¿t pháº£i cÃ³ dáº¡ng "" instruction , input ,output,response: , em muá»‘n dÃ¹ng vÄƒn báº£n text Ä‘Æ°á»£c khÃ´ng áº¡ ? em cáº£m Æ¡n áº¡!!!!","Em chÃ o má»i ngÆ°á»i , e lÃ  newbie , e má»›i train 1 model trÃªn kaggle sau khi táº­p tÃ nh fine tuning 1 model (model Ä‘Ã³ fine tune dá»±a vÃ o Llama2 vÃ  Blomz trÃªn táº­p data tiáº¿ng viá»‡t ) trÃªn hugging face xong thÃ¬ e cÃ³ nháº¥n save model , sau Ä‘Ã³ vÃ o láº¡i thÃ¬ chá»‰ tháº¥y cÃ³ máº¥y file nhÆ° adapter _model.bin , adapter_config.json , redme, events.out.tfevens , Sau Ä‘Ã³ em cÃ³ táº£i koboldcpp vá» Ä‘á»ƒ cháº¡y nhÆ°ng khÃ´ng Ä‘Æ°á»£c . Má»i ngÆ°á»i cÃ³ biáº¿t cÃ¡ch nÃ o Ä‘á»ƒ cháº¡y file nÃ y ko áº¡ .VÃ  input Ä‘áº§u vÃ o cÃ³ nháº¥t thiáº¿t pháº£i cÃ³ dáº¡ng "" instruction , input ,output,response: , em muá»‘n dÃ¹ng vÄƒn báº£n text Ä‘Æ°á»£c khÃ´ng áº¡ ? em cáº£m Æ¡n áº¡!!!!",,,"#Q&A, #nlp",,
"Xin phÃ©p chia sáº» vá»›i cÃ¡c bÃ¡c vá» Ä‘á»“ Ã¡n Text Image Retrieval cá»§a má»™t há»c sinh khÃ³a MLE em Ä‘ang training. Model Ä‘Æ°á»£c deploy trÃªn GKE vÃ  expose sá»­ dá»¥ng Nginx Ingress. Jenkins Ä‘á»ƒ build CI/CD pipeline Ä‘Æ°á»£c deploy trÃªn GCE sá»­ dá»¥ng Ansible. BÃªn cáº¡nh Ä‘Ã³, báº¡n cÅ©ng dÃ¹ng GKE Ä‘á»ƒ deploy cÃ¡c monitoring tools Ä‘á»ƒ observe há»‡ thá»‘ng. README Ä‘Æ°á»£c viáº¿t ráº¥t chi tiáº¿t, nÃªn em hy vá»ng sáº½ lÃ  má»™t nguá»“n tÃ i liá»‡u há»¯u Ã­ch khÃ¡c bÃªn cáº¡nh MLOps Crash Course láº§n trÆ°á»›c em chia sáº» ğŸ˜ƒ.
https://github.com/.../continuous-deployment-to-gke-cluster
Má»i ngÆ°á»i Ä‘á»«ng quÃªn Ä‘á»™ng viÃªn báº¡n Nguyen Tran Dang Duong má»™t Github star náº¿u tháº¥y cÃ³ Ã­ch nhÃ© áº¡ ğŸ˜‰.
ChÃºc cÃ¡c bÃ¡c cuá»‘i tuáº§n vui váº»!","Xin phÃ©p chia sáº» vá»›i cÃ¡c bÃ¡c vá» Ä‘á»“ Ã¡n Text Image Retrieval cá»§a má»™t há»c sinh khÃ³a MLE em Ä‘ang training. Model Ä‘Æ°á»£c deploy trÃªn GKE vÃ  expose sá»­ dá»¥ng Nginx Ingress. Jenkins Ä‘á»ƒ build CI/CD pipeline Ä‘Æ°á»£c deploy trÃªn GCE sá»­ dá»¥ng Ansible. BÃªn cáº¡nh Ä‘Ã³, báº¡n cÅ©ng dÃ¹ng GKE Ä‘á»ƒ deploy cÃ¡c monitoring tools Ä‘á»ƒ observe há»‡ thá»‘ng. README Ä‘Æ°á»£c viáº¿t ráº¥t chi tiáº¿t, nÃªn em hy vá»ng sáº½ lÃ  má»™t nguá»“n tÃ i liá»‡u há»¯u Ã­ch khÃ¡c bÃªn cáº¡nh MLOps Crash Course láº§n trÆ°á»›c em chia sáº» . https://github.com/.../continuous-deployment-to-gke-cluster Má»i ngÆ°á»i Ä‘á»«ng quÃªn Ä‘á»™ng viÃªn báº¡n Nguyen Tran Dang Duong má»™t Github star náº¿u tháº¥y cÃ³ Ã­ch nhÃ© áº¡ . ChÃºc cÃ¡c bÃ¡c cuá»‘i tuáº§n vui váº»!",,,"#sharing,#cv, #nlp ",,
"ChÃ o má»i ngÆ°á»i áº¡!
Má»i ngÆ°á»i cho em há»i lÃ  cÃ³ ai Ä‘Ã£ tá»«ng pretraining (hoáº·c further training) TrOCR hoáº·c 1 multimodal nÃ o Ä‘Ã³ báº±ng Hugging Face ko áº¡? Em muá»‘n há»i Ä‘á»ƒ láº¥y thÃªm kinh nghiá»‡m áº¡!",ChÃ o má»i ngÆ°á»i áº¡! Má»i ngÆ°á»i cho em há»i lÃ  cÃ³ ai Ä‘Ã£ tá»«ng pretraining (hoáº·c further training) TrOCR hoáº·c 1 multimodal nÃ o Ä‘Ã³ báº±ng Hugging Face ko áº¡? Em muá»‘n há»i Ä‘á»ƒ láº¥y thÃªm kinh nghiá»‡m áº¡!,,,#Q&A,,
"ChÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang muá»‘n cÃ³ Ä‘á»‹nh hÆ°á»›ng há»c AI. Em biáº¿t Python dá»¥ng Ä‘á»ƒ phÃ¡t triá»ƒn vÃ  huáº§n luyá»‡n cÃ¡c model AI. NhÆ°ng deploy model trong thá»±c táº¿ nhÆ° viáº¿t má»™t cÃ¡i backend cháº³ng háº¡n thÃ¬ cáº§n hiá»‡u suáº¥t cao hÆ¡n vÃ  nhanh hÆ¡n thÃ¬ ngÆ°á»i ta dÃ¹ng ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c hoáº·c tÃ­ch há»£p AI vÃ o há»‡ thá»‘ng nhÃºng dÃ¹ng C/C++. Má»i ngÆ°á»i ai Ä‘Ã£ Ä‘i lÃ m ngoÃ i thá»±c táº¿ xin kháº£o sÃ¡t má»™t vÃ i ngÃ´n ngá»¯ láº­p trÃ¬nh thÆ°á»ng mÃ  cÃ´ng ty, doanh nghiá»‡p cá»§a cÃ¡c anh chá»‹ thÆ°á»ng sá»­ dá»¥ng Ä‘á»ƒ deploy model AI ra thá»±c táº¿ vá»›i áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u áº¡.","ChÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang muá»‘n cÃ³ Ä‘á»‹nh hÆ°á»›ng há»c AI. Em biáº¿t Python dá»¥ng Ä‘á»ƒ phÃ¡t triá»ƒn vÃ  huáº§n luyá»‡n cÃ¡c model AI. NhÆ°ng deploy model trong thá»±c táº¿ nhÆ° viáº¿t má»™t cÃ¡i backend cháº³ng háº¡n thÃ¬ cáº§n hiá»‡u suáº¥t cao hÆ¡n vÃ  nhanh hÆ¡n thÃ¬ ngÆ°á»i ta dÃ¹ng ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c hoáº·c tÃ­ch há»£p AI vÃ o há»‡ thá»‘ng nhÃºng dÃ¹ng C/C++. Má»i ngÆ°á»i ai Ä‘Ã£ Ä‘i lÃ m ngoÃ i thá»±c táº¿ xin kháº£o sÃ¡t má»™t vÃ i ngÃ´n ngá»¯ láº­p trÃ¬nh thÆ°á»ng mÃ  cÃ´ng ty, doanh nghiá»‡p cá»§a cÃ¡c anh chá»‹ thÆ°á»ng sá»­ dá»¥ng Ä‘á»ƒ deploy model AI ra thá»±c táº¿ vá»›i áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u áº¡.",,,#Q&A,,
"Gáº§n Ä‘Ã¢y mÃ¬nh Ä‘Æ°á»£c cáº¥p quyá»n sá»­ dá»¥ng High Performance Computers (HPC), (cÃ²n trÆ°á»›c Ä‘Ã¢y chá»‰ cÃ³ má»—i 1 mÃ¡y vá»›i 1 GPU 3090, nÃªn mÃ¬nh chá»‰ dÃ¹ng AnyDesk Ä‘á»ƒ Ä‘iá»u khiá»ƒn tá»« xa), nÃªn mÃ¬nh dÃ nh nhiá»u thá»i gian há»c Ä‘á»ƒ Ä‘iá»u khiá»ƒn nÃ³. VÃ¬ váº­y mÃ¬nh pháº£i há»c má»™t sá»‘ cÃ´ng cá»¥ nhÆ° Tmate, Screen, SSH, Code Tunnel,... NhÆ°ng quan trong hÆ¡n lÃ  pháº£i há»c thÃªm nhiá»u vá» bash scripts. Nay tháº¥y 1 repo khÃ¡ thÃº vá»‹ hÆ°á»›ng dáº«n cÃ¡c bash scripts phá»• biáº¿n dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh lá»›n trÃªn HPC nÃªn mÃ¬nh chia sáº» láº¡i táº¡i Ä‘Ã¢y https://github.com/stas00/ml-engineering.
Hi vá»ng nÃ³ sáº½ giÃºp Ã­ch vá»›i cÃ¡c báº¡n cÃ³ Ä‘iá»u kiá»‡n sá»­ dá»¥ng HPC.","Gáº§n Ä‘Ã¢y mÃ¬nh Ä‘Æ°á»£c cáº¥p quyá»n sá»­ dá»¥ng High Performance Computers (HPC), (cÃ²n trÆ°á»›c Ä‘Ã¢y chá»‰ cÃ³ má»—i 1 mÃ¡y vá»›i 1 GPU 3090, nÃªn mÃ¬nh chá»‰ dÃ¹ng AnyDesk Ä‘á»ƒ Ä‘iá»u khiá»ƒn tá»« xa), nÃªn mÃ¬nh dÃ nh nhiá»u thá»i gian há»c Ä‘á»ƒ Ä‘iá»u khiá»ƒn nÃ³. VÃ¬ váº­y mÃ¬nh pháº£i há»c má»™t sá»‘ cÃ´ng cá»¥ nhÆ° Tmate, Screen, SSH, Code Tunnel,... NhÆ°ng quan trong hÆ¡n lÃ  pháº£i há»c thÃªm nhiá»u vá» bash scripts. Nay tháº¥y 1 repo khÃ¡ thÃº vá»‹ hÆ°á»›ng dáº«n cÃ¡c bash scripts phá»• biáº¿n dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh lá»›n trÃªn HPC nÃªn mÃ¬nh chia sáº» láº¡i táº¡i Ä‘Ã¢y https://github.com/stas00/ml-engineering. Hi vá»ng nÃ³ sáº½ giÃºp Ã­ch vá»›i cÃ¡c báº¡n cÃ³ Ä‘iá»u kiá»‡n sá»­ dá»¥ng HPC.",,,#sharing,,
"Cho mÃ¬nh há»i embedding vectors tiáº¿ng Viá»‡t gá»i sao váº­y áº¡? MÃ¬nh dá»‹ch táº¡m lÃ  ""vÃ©c tÆ¡ nhÃºng"" nhÆ°ng cÃ³ váº» nÃ³ khÃ´ng thá»ƒ hiá»‡n Ä‘Æ°á»£c tinh tháº§n cá»§a chá»¯ ""embedding""
Trong trang cá»§a ML cÆ¡ báº£n thÃ¬ váº«n giá»¯ nguyÃªn chá»¯ embedding: https://machinelearningcoban.com/tabml_book/ch_embedding/embedding.html
CÃ³ chÄƒng mÃ¬nh khÃ´ng thá»ƒ ""viá»‡t hoÃ¡"" hoÃ n toÃ n tá»« nÃ y?","Cho mÃ¬nh há»i embedding vectors tiáº¿ng Viá»‡t gá»i sao váº­y áº¡? MÃ¬nh dá»‹ch táº¡m lÃ  ""vÃ©c tÆ¡ nhÃºng"" nhÆ°ng cÃ³ váº» nÃ³ khÃ´ng thá»ƒ hiá»‡n Ä‘Æ°á»£c tinh tháº§n cá»§a chá»¯ ""embedding"" Trong trang cá»§a ML cÆ¡ báº£n thÃ¬ váº«n giá»¯ nguyÃªn chá»¯ embedding: https://machinelearningcoban.com/tabml_book/ch_embedding/embedding.html CÃ³ chÄƒng mÃ¬nh khÃ´ng thá»ƒ ""viá»‡t hoÃ¡"" hoÃ n toÃ n tá»« nÃ y?",,,"#Q&A, #nlp",,
"Generative AI (AI táº¡o sinh) vÃ  Predictive AI (AI dá»± Ä‘oÃ¡n) khÃ¡c nhau vá» cÃ¡ch chÃºng xá»­ lÃ½ cÃ¡c á»©ng dá»¥ng vÃ  dá»¯ liá»‡u cÃ³ cáº¥u trÃºc láº«n phi cáº¥u trÃºc tÆ°Æ¡ng á»©ng. CÃ¹ng tÃ¬m hiá»ƒu nhá»¯ng lá»£i Ã­ch vÃ  cÃ¡c háº¡n cháº¿ cá»§a má»—i loáº¡i trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿ cá»§a chÃºng.
#GenerativeAI #PredictiveAI #AI",Generative AI (AI táº¡o sinh) vÃ  Predictive AI (AI dá»± Ä‘oÃ¡n) khÃ¡c nhau vá» cÃ¡ch chÃºng xá»­ lÃ½ cÃ¡c á»©ng dá»¥ng vÃ  dá»¯ liá»‡u cÃ³ cáº¥u trÃºc láº«n phi cáº¥u trÃºc tÆ°Æ¡ng á»©ng. CÃ¹ng tÃ¬m hiá»ƒu nhá»¯ng lá»£i Ã­ch vÃ  cÃ¡c háº¡n cháº¿ cá»§a má»—i loáº¡i trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿ cá»§a chÃºng.,#GenerativeAI	#PredictiveAI	#AI,,#sharing,,
"ChÃ o cÃ¡c anh chá»‹, cÃ¡c báº¡n, tiá»n bá»‘i trong ngÃ nh áº¡. Mong anh chá»‹ cho em má»™t chÃºt nháº­n xÃ©t vá» CV nÃ y cá»§a em vá»›i áº¡. Liá»‡u Ä‘Ã£ Ä‘á»§ Ä‘iá»u kiá»‡n Ä‘á»ƒ cÃ³ thá»ƒ xin Ä‘i thá»±c táº­p chÆ°a áº¡. Náº¿u Ä‘Æ°á»£c mong anh chá»‹ cho em vÃ i gÃ³p Ã½ cáº§n bá»• sung vÃ  cáº£i thiá»‡n thÃªm (cáº£ hÃ¬nh thá»©c vÃ  ná»™i dung) áº¡. ChÃºc má»i ngÆ°á»i má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng áº¡.","ChÃ o cÃ¡c anh chá»‹, cÃ¡c báº¡n, tiá»n bá»‘i trong ngÃ nh áº¡. Mong anh chá»‹ cho em má»™t chÃºt nháº­n xÃ©t vá» CV nÃ y cá»§a em vá»›i áº¡. Liá»‡u Ä‘Ã£ Ä‘á»§ Ä‘iá»u kiá»‡n Ä‘á»ƒ cÃ³ thá»ƒ xin Ä‘i thá»±c táº­p chÆ°a áº¡. Náº¿u Ä‘Æ°á»£c mong anh chá»‹ cho em vÃ i gÃ³p Ã½ cáº§n bá»• sung vÃ  cáº£i thiá»‡n thÃªm (cáº£ hÃ¬nh thá»©c vÃ  ná»™i dung) áº¡. ChÃºc má»i ngÆ°á»i má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng áº¡.",,,#sharing,,
"Xin chÃ o má»i ngÆ°á»i, anh chá»‹ trong nhÃ³m áº¡.Em xin phÃ©p há»i lÃ  em Ä‘ang nghiÃªn cá»©u vá» mÃ´ hÃ¬nh há»c mÃ¡y vá» data bÃªn máº£ng xÃ¢y dá»±ng áº¡, nÃªn em muá»‘n xin tÃ i liá»‡u tham kháº£o vÃ  code trÃªn github cÅ©ng Ä‘Æ°á»£c áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u.","Xin chÃ o má»i ngÆ°á»i, anh chá»‹ trong nhÃ³m áº¡.Em xin phÃ©p há»i lÃ  em Ä‘ang nghiÃªn cá»©u vá» mÃ´ hÃ¬nh há»c mÃ¡y vá» data bÃªn máº£ng xÃ¢y dá»±ng áº¡, nÃªn em muá»‘n xin tÃ i liá»‡u tham kháº£o vÃ  code trÃªn github cÅ©ng Ä‘Æ°á»£c áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u.",,,"#Q&A, #machine_learning",,
"Äáº¡i há»c Harvard vá»«a cÃ´ng bá»‘ khÃ³a há»c vá» Data Science vá»›i Python thuá»™c bá»™ mÃ´n Computer Science.
KhÃ³a há»c hoÃ n toÃ n miá»…n phÃ­ vÃ  kÃ©o dÃ i trong 8 tuáº§n.
Link: https://pll.harvard.edu/.../introduction-data-science-python",Äáº¡i há»c Harvard vá»«a cÃ´ng bá»‘ khÃ³a há»c vá» Data Science vá»›i Python thuá»™c bá»™ mÃ´n Computer Science. KhÃ³a há»c hoÃ n toÃ n miá»…n phÃ­ vÃ  kÃ©o dÃ i trong 8 tuáº§n. Link: https://pll.harvard.edu/.../introduction-data-science-python,,,#sharing,,
Tuáº§n sau cÃ³ anh chá»‹ cÃ¡c báº¡n nÃ o tham gia ICCV á»Ÿ Paris ko cÃ¹ng káº¿t ná»‘i tham gia xong thÄƒm thÃº cho vui áº¡ ğŸ˜„,Tuáº§n sau cÃ³ anh chá»‹ cÃ¡c báº¡n nÃ o tham gia ICCV á»Ÿ Paris ko cÃ¹ng káº¿t ná»‘i tham gia xong thÄƒm thÃº cho vui áº¡,,,#Q&A,,
Há»‡ thá»‘ng AI cáº£i tiáº¿n cÃ³ thá»ƒ giáº£i mÃ£ cáº£m xÃºc cá»§a gÃ .,Há»‡ thá»‘ng AI cáº£i tiáº¿n cÃ³ thá»ƒ giáº£i mÃ£ cáº£m xÃºc cá»§a gÃ .,,,#sharing,,
"ChÃ o mn. Em Ä‘ang lÃ m nhiá»‡m vá»¥ lÃ m giáº£m thá»i gian inference model bert bá»Ÿi pháº£i infer tá»›i 1 triá»‡u cÃ¢u . Em Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng lÃ  ghÃ©p cÃ¡c cÃ¢u láº¡i cÃ³ dáº¡ng <cls> sentence A <sep> sentence b <sep> ...... . thÃ¬ mÃ¬nh ghÃ©p Ä‘Æ°á»£c bao nhiÃªu cÃ¢u thÃ¬ tá»‘c Ä‘á»™ sáº½ giáº£m Ä‘i tá»«ng Ä‘Ã³ láº§n , vÃ  bÃ i toÃ¡n yá»« multi class sáº½ chuyá»ƒn thÃ nh multi label. Tháº¿ nhÆ°ng khi em ghÃ©p vÃ o káº¿t quáº£ infer ráº¥t tá»‡ (Ä‘Ã£ train trÃªn cÃ¢u ghÃ©p). KhÃ´ng biáº¿t mn á»Ÿ Ä‘Ã¢y Ä‘Ã£ ai tá»«ng lÃ m chÆ°a cÃ³ thá»ƒ cho em cÃ¡i suggest khÃ´ng áº¡. Em cáº£m Æ¡n","ChÃ o mn. Em Ä‘ang lÃ m nhiá»‡m vá»¥ lÃ m giáº£m thá»i gian inference model bert bá»Ÿi pháº£i infer tá»›i 1 triá»‡u cÃ¢u . Em Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng lÃ  ghÃ©p cÃ¡c cÃ¢u láº¡i cÃ³ dáº¡ng <cls> sentence A <sep> sentence b <sep> ...... . thÃ¬ mÃ¬nh ghÃ©p Ä‘Æ°á»£c bao nhiÃªu cÃ¢u thÃ¬ tá»‘c Ä‘á»™ sáº½ giáº£m Ä‘i tá»«ng Ä‘Ã³ láº§n , vÃ  bÃ i toÃ¡n yá»« multi class sáº½ chuyá»ƒn thÃ nh multi label. Tháº¿ nhÆ°ng khi em ghÃ©p vÃ o káº¿t quáº£ infer ráº¥t tá»‡ (Ä‘Ã£ train trÃªn cÃ¢u ghÃ©p). KhÃ´ng biáº¿t mn á»Ÿ Ä‘Ã¢y Ä‘Ã£ ai tá»«ng lÃ m chÆ°a cÃ³ thá»ƒ cho em cÃ¡i suggest khÃ´ng áº¡. Em cáº£m Æ¡n",,,#Q&A,,
Cáº©m nang chi tiáº¿t cho báº¡n nÃ o xÃ¢y CV nhÃ©,Cáº©m nang chi tiáº¿t cho báº¡n nÃ o xÃ¢y CV nhÃ©,,,#sharing,,
"Mn cÃ³ biáº¿t bÃ¡o nÃ o hay web nÃ o cÃ³ nhá»¯ng nghiÃªn cá»©u model vá» tÃ i chÃ­nh, dá»¯ liá»‡u cÃ³ Ä‘á»™ tin cáº­y cao khÃ´ng áº¡ cho em xin vá»›i áº¡","Mn cÃ³ biáº¿t bÃ¡o nÃ o hay web nÃ o cÃ³ nhá»¯ng nghiÃªn cá»©u model vá» tÃ i chÃ­nh, dá»¯ liá»‡u cÃ³ Ä‘á»™ tin cáº­y cao khÃ´ng áº¡ cho em xin vá»›i áº¡",,,#Q&A,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m 1 project nlp cáº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n tiáº¿ng Viá»‡t. Cho em há»i cÃ³ package nÃ o há»— trá»£ chuáº©n hoÃ¡ cÃ¡ch bá» dáº¥u cÃ¢u (""Ã²a"" - ""oÃ "", ""Ãºy"" - uÃ½) vÃ  lá»—i y i (""má»³"" - ""mÃ¬"", ""li ti"", ""cÃ¡i ly"") khÃ´ng áº¡.","ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m 1 project nlp cáº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n tiáº¿ng Viá»‡t. Cho em há»i cÃ³ package nÃ o há»— trá»£ chuáº©n hoÃ¡ cÃ¡ch bá» dáº¥u cÃ¢u (""Ã²a"" - ""oÃ "", ""Ãºy"" - uÃ½) vÃ  lá»—i y i (""má»³"" - ""mÃ¬"", ""li ti"", ""cÃ¡i ly"") khÃ´ng áº¡.",,,"#Q&A, #data, #nlp",,
"Dá»± Ã¡n hiá»‡n táº¡i cá»§a em lÃ  xÃ¢y dá»±ng má»™t data engine cho má»™t phÃ²ng lab thá»±c táº¿ áº£o ( VR Experiment sá»­ dá»¥ng Oculus). Váº¥n Ä‘á» Ä‘áº·t ra lÃ  hiá»‡n táº¡i lab áº£o nÃ y Ä‘ang sá»­ dá»¥ng má»™t sá»‘ mock data tá»« lab tháº­t Ä‘Æ°á»£c náº¡p vÃ o vÃ  má»—i khi ngÆ°á»i dÃ¹ng thá»±c hiá»‡n hÃ nh Ä‘á»™ng thÃ¬ output sáº½ lÃ  mock data chá»© khÃ´ng pháº£i lÃ  data tháº­t.
Tháº§y muá»‘n em táº¡o má»™t data engine Ä‘á»ƒ há»c vÃ  dá»± Ä‘oÃ¡n output dá»±a trÃªn nhá»¯ng data Ä‘Æ°á»£c lÆ°u láº¡i trÆ°á»›c Ä‘Ã³ (lab tháº­t cÃ³ xuáº¥t ra má»™t file excel lÆ°u data nhá»¯ng láº§n cháº¡y) V
áº­y thÃ¬, Em cáº§n há»c nhá»¯ng thuáº­t toÃ¡n gÃ¬? CÃ´ng nghá»‡ gÃ¬? Sá»­ dá»¥ng data storage nÃ o? LÃ  tá»‘i Æ°u nháº¥t áº¡? Em cÃ³ há»c qua computer vision vÃ  Ä‘Ã£ tá»«ng lÃ m má»™t sá»‘ project vá» image classification nhÆ°ng chÆ°a cÃ³ kinh nghiá»‡m nÃ o vá» máº£ng nÃ y áº¡.
Cáº£m Æ¡n mn","Dá»± Ã¡n hiá»‡n táº¡i cá»§a em lÃ  xÃ¢y dá»±ng má»™t data engine cho má»™t phÃ²ng lab thá»±c táº¿ áº£o ( VR Experiment sá»­ dá»¥ng Oculus). Váº¥n Ä‘á» Ä‘áº·t ra lÃ  hiá»‡n táº¡i lab áº£o nÃ y Ä‘ang sá»­ dá»¥ng má»™t sá»‘ mock data tá»« lab tháº­t Ä‘Æ°á»£c náº¡p vÃ o vÃ  má»—i khi ngÆ°á»i dÃ¹ng thá»±c hiá»‡n hÃ nh Ä‘á»™ng thÃ¬ output sáº½ lÃ  mock data chá»© khÃ´ng pháº£i lÃ  data tháº­t. Tháº§y muá»‘n em táº¡o má»™t data engine Ä‘á»ƒ há»c vÃ  dá»± Ä‘oÃ¡n output dá»±a trÃªn nhá»¯ng data Ä‘Æ°á»£c lÆ°u láº¡i trÆ°á»›c Ä‘Ã³ (lab tháº­t cÃ³ xuáº¥t ra má»™t file excel lÆ°u data nhá»¯ng láº§n cháº¡y) V áº­y thÃ¬, Em cáº§n há»c nhá»¯ng thuáº­t toÃ¡n gÃ¬? CÃ´ng nghá»‡ gÃ¬? Sá»­ dá»¥ng data storage nÃ o? LÃ  tá»‘i Æ°u nháº¥t áº¡? Em cÃ³ há»c qua computer vision vÃ  Ä‘Ã£ tá»«ng lÃ m má»™t sá»‘ project vá» image classification nhÆ°ng chÆ°a cÃ³ kinh nghiá»‡m nÃ o vá» máº£ng nÃ y áº¡. Cáº£m Æ¡n mn",,,"#Q&A, #data",,
"Xin chÃ o má»i ngÆ°á»i, em thá»±c hiá»‡n time series analysis vá»›i mÃ´ hÃ¬nh ARIMA dÃ¹ng Python tuy nhiÃªn nháº­n Ä‘Æ°á»£c giÃ¡ trá»‹ dá»± Ä‘oÃ¡n lÃ  gáº§n giá»‘ng nhÆ° giÃ¡ trá»‹ trung bÃ¬nh nhÆ° hÃ¬nh á»Ÿ dÆ°á»›i áº¡. Data nÃ y Ä‘Ã£ láº¥y sai phÃ¢n báº­c 1 mÃ  giÃ¡ trá»‹ p,d,q thu Ä‘Æ°á»£c sau khi thá»­ báº±ng auto_arima.
Xin mn chá»‰ giÃ¡o cÃ¡ch tiáº¿p cáº­n vÃ  sá»­a mÃ´ hÃ¬nh nÃ y áº¡. Em cáº£m Æ¡n nhiá»u.","Xin chÃ o má»i ngÆ°á»i, em thá»±c hiá»‡n time series analysis vá»›i mÃ´ hÃ¬nh ARIMA dÃ¹ng Python tuy nhiÃªn nháº­n Ä‘Æ°á»£c giÃ¡ trá»‹ dá»± Ä‘oÃ¡n lÃ  gáº§n giá»‘ng nhÆ° giÃ¡ trá»‹ trung bÃ¬nh nhÆ° hÃ¬nh á»Ÿ dÆ°á»›i áº¡. Data nÃ y Ä‘Ã£ láº¥y sai phÃ¢n báº­c 1 mÃ  giÃ¡ trá»‹ p,d,q thu Ä‘Æ°á»£c sau khi thá»­ báº±ng auto_arima. Xin mn chá»‰ giÃ¡o cÃ¡ch tiáº¿p cáº­n vÃ  sá»­a mÃ´ hÃ¬nh nÃ y áº¡. Em cáº£m Æ¡n nhiá»u.",,,#Q&A,,
"#question
Mn cho e há»i lÃ  há»c machine learning thÃ¬ cÃ³ nÃªn há»c sÃ¢u vá» thuáº­t toÃ¡n (backtrack, Ä‘á»‡ quy . . ) Em ráº¥t thÃ­ch há»c thuáº­t toÃ¡n vÃ  váº«n há»c nÃ³ hÃ ng ngÃ y. NhÆ°ng mÃ  khi há»c ML thÃ¬ nÃ³ cÃ³ nhá»¯ng thuáº­t toÃ¡n riÃªng khÃ´ng biáº¿t lÃ  cÃ¡i viá»‡c há»c thuáº­t toÃ¡n nÃ³ cÃ³ tÃ¡c dá»¥ng gÃ¬ khi mÃ¬nh theo ML khÃ´ng áº¡ ?
Em cáº£m Æ¡n!","Mn cho e há»i lÃ  há»c machine learning thÃ¬ cÃ³ nÃªn há»c sÃ¢u vá» thuáº­t toÃ¡n (backtrack, Ä‘á»‡ quy . . ) Em ráº¥t thÃ­ch há»c thuáº­t toÃ¡n vÃ  váº«n há»c nÃ³ hÃ ng ngÃ y. NhÆ°ng mÃ  khi há»c ML thÃ¬ nÃ³ cÃ³ nhá»¯ng thuáº­t toÃ¡n riÃªng khÃ´ng biáº¿t lÃ  cÃ¡i viá»‡c há»c thuáº­t toÃ¡n nÃ³ cÃ³ tÃ¡c dá»¥ng gÃ¬ khi mÃ¬nh theo ML khÃ´ng áº¡ ? Em cáº£m Æ¡n!",#question,,"#Q&A, #math",,
"Em bá»‹ lá»—i nÃ y má»—i khi submit cell trÃªn jupyter, em Ä‘Ã£ kiá»ƒm tra java/bashrc/whichjava thÃ¬ Ä‘á»u Ä‘Ã£ Ä‘Ãºng Ä‘Æ°á»ng dáº«n kÃ¨m cÃ i mÃ´i trÆ°á»ng cho nÃ³ rá»“i.
Má»i ngÆ°á»i ai rÃ nh giÃºp em vá»›i em xin gá»­i bá»¯a Äƒn sÃ¡ng áº¡ :*","Em bá»‹ lá»—i nÃ y má»—i khi submit cell trÃªn jupyter, em Ä‘Ã£ kiá»ƒm tra java/bashrc/whichjava thÃ¬ Ä‘á»u Ä‘Ã£ Ä‘Ãºng Ä‘Æ°á»ng dáº«n kÃ¨m cÃ i mÃ´i trÆ°á»ng cho nÃ³ rá»“i. Má»i ngÆ°á»i ai rÃ nh giÃºp em vá»›i em xin gá»­i bá»¯a Äƒn sÃ¡ng áº¡ :*",,,#Q&A,,
"Xin chÃ o má»i ngÆ°á»i, cÃ³ anh/chá»‹/em nÃ o cÃ³ biáº¿t web cho thuÃª server váº­t lÃ½ gpu Ä‘á»ƒ deploy api giÃ¡ ngon / bá»•/ ráº» khÃ´ng áº¡ ? , . Em biáº¿t 2 web lÃ  https://hostkey.com/ khÃ¡ lÃ  ok nhÆ°ng máº¡ng cháº­p chá»n quÃ¡ ( hÃ¬nh nhÆ° hay bá»‹ ddos ) . CÃ¡c bÃ¡c nÃ o biáº¿t cho em xin vá»›i , em cáº£m Æ¡n .","Xin chÃ o má»i ngÆ°á»i, cÃ³ anh/chá»‹/em nÃ o cÃ³ biáº¿t web cho thuÃª server váº­t lÃ½ gpu Ä‘á»ƒ deploy api giÃ¡ ngon / bá»•/ ráº» khÃ´ng áº¡ ? , . Em biáº¿t 2 web lÃ  https://hostkey.com/ khÃ¡ lÃ  ok nhÆ°ng máº¡ng cháº­p chá»n quÃ¡ ( hÃ¬nh nhÆ° hay bá»‹ ddos ) . CÃ¡c bÃ¡c nÃ o biáº¿t cho em xin vá»›i , em cáº£m Æ¡n .",,,#Q&A,,
"Má»i ngÆ°á»i Æ¡i, cho em há»i lÃ  vÃ¬ sao pre-trained model nhÆ° PhoBert, GPT-3 thÃ¬ khi xÃ¢y chatbot rasa vá»›i cÃ¡c model Ä‘Ã³, em váº«n pháº£i xÃ¡c Ä‘á»‹nh intent vÃ  example áº¡, kh pháº£i nÃ³ dc train rá»“i hay sao áº¡.
Em lÃ  newbie nÃªn há»i cÃ³ khi hÆ¡i ngÃ´ nghÃª, mong mng bá» qua.
Cáº£m Æ¡n mng Ä‘Ã£ giáº£i Ä‘Ã¡p","Má»i ngÆ°á»i Æ¡i, cho em há»i lÃ  vÃ¬ sao pre-trained model nhÆ° PhoBert, GPT-3 thÃ¬ khi xÃ¢y chatbot rasa vá»›i cÃ¡c model Ä‘Ã³, em váº«n pháº£i xÃ¡c Ä‘á»‹nh intent vÃ  example áº¡, kh pháº£i nÃ³ dc train rá»“i hay sao áº¡. Em lÃ  newbie nÃªn há»i cÃ³ khi hÆ¡i ngÃ´ nghÃª, mong mng bá» qua. Cáº£m Æ¡n mng Ä‘Ã£ giáº£i Ä‘Ã¡p",,,"#Q&A, #nlp",,
"Hi má»i ngÆ°á»i, sau cuá»™c thi ZaloAi thÃ¬ mÃ¬nh tháº¥y Cinnamon AI marathon lÃ  cuá»™c thi cÃ³ nhiá»u thÃº vá»‹.
Trong cuá»™c thi nÃ y cÃ³ 3 Ä‘á» tÃ i chÃ­nh
- Handwriting OCR for Vietnamese Address
- Document Layout Analysis
- Real Time Facial LandMark Detection
Do mÃ¬nh tháº¥y cuá»™c thi nÃ y khÃ¡ thÃº vá»‹ mÃ  khÃ´ng cÃ³ nhiá»u cá»™ng Ä‘á»“ng support nÃªn mÃ¬nh cung cáº¥p code base cá»§a Ä‘á» bÃ i OCR cho má»i ngÆ°á»i tham kháº£o.
Vá» bÃ i toÃ¡n OCR thÃ¬ chung ta cáº§n nháº­n diá»‡n cÃ¡c kÃ­ tá»± trong hÃ¬nh áº£nh scan cá»§a má»™t Ä‘oáº¡n text. Bá»™ dá»¯ liá»‡u gá»“m 2000 máº«u.
MÃ´ hÃ¬nh mÃ¬nh sá»§ dá»¥ng lÃ  CRNN +CTCLoss. CNN dÃ¹ng Ä‘á»ƒ extract features, sau Ä‘Ã³ Ä‘Æ°Æ¡c Ä‘Æ°a vÃ o RNN Ä‘á»ƒ nháº­n dáº¡ng kÃ­ tá»± táº¡i timestep hiá»‡n táº¡i.
Káº¿t quáº£ mÃ¬nh tháº¥y khÃ¡ kháº£ quan, nháº­n diá»‡n cÅ©ng tÆ°Æ¡ng Ä‘á»‘i chÃ­nh xÃ¡c vá»›i normalize editdistance 0.28x.
Báº¡n nÃ o cÃ³ hÆ°ng thÃº tÃ¬m hiá»ƒu vá» OCR cÅ©ng nhÆ° cuá»™c thi thÃ¬ cÃ³ thá»ƒ tham kháº£o codebase nÃ y nhÃ©.
----------------------------------------------
https://github.com/pbcquoc/vietnamese_ocr","Hi má»i ngÆ°á»i, sau cuá»™c thi ZaloAi thÃ¬ mÃ¬nh tháº¥y Cinnamon AI marathon lÃ  cuá»™c thi cÃ³ nhiá»u thÃº vá»‹. Trong cuá»™c thi nÃ y cÃ³ 3 Ä‘á» tÃ i chÃ­nh - Handwriting OCR for Vietnamese Address - Document Layout Analysis - Real Time Facial LandMark Detection Do mÃ¬nh tháº¥y cuá»™c thi nÃ y khÃ¡ thÃº vá»‹ mÃ  khÃ´ng cÃ³ nhiá»u cá»™ng Ä‘á»“ng support nÃªn mÃ¬nh cung cáº¥p code base cá»§a Ä‘á» bÃ i OCR cho má»i ngÆ°á»i tham kháº£o. Vá» bÃ i toÃ¡n OCR thÃ¬ chung ta cáº§n nháº­n diá»‡n cÃ¡c kÃ­ tá»± trong hÃ¬nh áº£nh scan cá»§a má»™t Ä‘oáº¡n text. Bá»™ dá»¯ liá»‡u gá»“m 2000 máº«u. MÃ´ hÃ¬nh mÃ¬nh sá»§ dá»¥ng lÃ  CRNN +CTCLoss. CNN dÃ¹ng Ä‘á»ƒ extract features, sau Ä‘Ã³ Ä‘Æ°Æ¡c Ä‘Æ°a vÃ o RNN Ä‘á»ƒ nháº­n dáº¡ng kÃ­ tá»± táº¡i timestep hiá»‡n táº¡i. Káº¿t quáº£ mÃ¬nh tháº¥y khÃ¡ kháº£ quan, nháº­n diá»‡n cÅ©ng tÆ°Æ¡ng Ä‘á»‘i chÃ­nh xÃ¡c vá»›i normalize editdistance 0.28x. Báº¡n nÃ o cÃ³ hÆ°ng thÃº tÃ¬m hiá»ƒu vá» OCR cÅ©ng nhÆ° cuá»™c thi thÃ¬ cÃ³ thá»ƒ tham kháº£o codebase nÃ y nhÃ©. ---------------------------------------------- https://github.com/pbcquoc/vietnamese_ocr",,,"#sharing, #cv, #nlp",,
"Hello má»i ngÆ°á»i,
Hiá»‡n nay mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» imbalanced dataset, má»i ngÆ°á»i cÃ³ ai cÃ³ biáº¿t sÃ¡ch nÃ o nÃ³i vá» váº¥n Ä‘á» nÃ y khÃ´ng, sÃ¡ch Ä‘Æ°á»£c phÃ¡t hÃ nh á»Ÿ viá»‡t nam cÃ ng tá»‘t ğŸ˜","Hello má»i ngÆ°á»i, Hiá»‡n nay mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» imbalanced dataset, má»i ngÆ°á»i cÃ³ ai cÃ³ biáº¿t sÃ¡ch nÃ o nÃ³i vá» váº¥n Ä‘á» nÃ y khÃ´ng, sÃ¡ch Ä‘Æ°á»£c phÃ¡t hÃ nh á»Ÿ viá»‡t nam cÃ ng tá»‘t",,,"#Q&A, #data",,
"DÆ°á»ng nhÆ° cÃ¡c báº¡n cÃ³ váº» thÃ­ch thÃº vá»›i chá»§ Ä‘á» Machine Learning engineering mÃ  mÃ¬nh post hÃ´m qua táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/permalink/1784048968719169/).
Váº­y nÃªn, hÃ´m nay mÃ¬nh chia sáº» tiáº¿p má»™t GitHub cá»§a Google cÃ³ tá»›i > 22k stars, cÃ³ tÃªn lÃ  Tuning_PlayBook vá» chá»§ Ä‘á» lÃ m sao ta cÃ³ thá»ƒ finetune pretrained models má»™t cÃ¡ch hiá»‡u quáº£ cho downstream tasks nhÆ°:
1/ Chá»n kiáº¿n trÃºc models
2/ Chá»n hÃ m tá»‘i Æ°u;
3/ Chá»n Batch sizes;
4/ Huáº¥n luyá»‡n model bao nhiÃªu epochs/steps;
5/ ÄÃ¡nh giÃ¡ hiá»‡u nÄƒng cá»§a models;
.... vÃ  nhiá»u thÃ´ng tin thÃº vá»‹ khÃ¡c ná»¯a!!!
CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o repository nÃ y táº¡i Ä‘Ã¢y: https://github.com/google-research/tuning_playbook#deep-learning-tuning-playbook
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng trong viá»‡c tá»‘i Æ°u dá»± Ã¡n vÃ  quÃ¡ trÃ¬nh há»c táº­p cá»§a mÃ¬nh!","DÆ°á»ng nhÆ° cÃ¡c báº¡n cÃ³ váº» thÃ­ch thÃº vá»›i chá»§ Ä‘á» Machine Learning engineering mÃ  mÃ¬nh post hÃ´m qua táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/permalink/1784048968719169/). Váº­y nÃªn, hÃ´m nay mÃ¬nh chia sáº» tiáº¿p má»™t GitHub cá»§a Google cÃ³ tá»›i > 22k stars, cÃ³ tÃªn lÃ  Tuning_PlayBook vá» chá»§ Ä‘á» lÃ m sao ta cÃ³ thá»ƒ finetune pretrained models má»™t cÃ¡ch hiá»‡u quáº£ cho downstream tasks nhÆ°: 1/ Chá»n kiáº¿n trÃºc models 2/ Chá»n hÃ m tá»‘i Æ°u; 3/ Chá»n Batch sizes; 4/ Huáº¥n luyá»‡n model bao nhiÃªu epochs/steps; 5/ ÄÃ¡nh giÃ¡ hiá»‡u nÄƒng cá»§a models; .... vÃ  nhiá»u thÃ´ng tin thÃº vá»‹ khÃ¡c ná»¯a!!! CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o repository nÃ y táº¡i Ä‘Ã¢y: https://github.com/google-research/tuning_playbook#deep-learning-tuning-playbook ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng trong viá»‡c tá»‘i Æ°u dá»± Ã¡n vÃ  quÃ¡ trÃ¬nh há»c táº­p cá»§a mÃ¬nh!",,,"#sharing, #machine_learning",,
"HÃ´m trÆ°á»›c khÃ¡ nhiá»u ngÆ°á»i há»i vá» quy trÃ¬nh thu tháº­p dá»¯ liá»‡u cÅ©ng nhÆ° training cá»§a LLM Vietcuna tá»« VILM. HÃ´m nay team VILM chÃ­nh thá»©c cÃ´ng bá»‘ toÃ n bá»™ quy trÃ¬nh Ä‘á»ƒ lÃ m ra Vietcuna.
Vá»›i hÆ°á»›ng dáº«n nÃ y kÃ¨m vá»›i model Vietcuna Ä‘Ã£ cÃ³ sáºµn, mong sáº½ cÃ³ nhiá»u báº¡n vÃ  doanh nghiá»‡p Viá»‡t Nam táº¡o ra cÃ¡c sáº£n pháº©m AI mang tÃ­nh thá»±c táº¿ cao trong cuá»™c sá»‘ng :)
Link:","HÃ´m trÆ°á»›c khÃ¡ nhiá»u ngÆ°á»i há»i vá» quy trÃ¬nh thu tháº­p dá»¯ liá»‡u cÅ©ng nhÆ° training cá»§a LLM Vietcuna tá»« VILM. HÃ´m nay team VILM chÃ­nh thá»©c cÃ´ng bá»‘ toÃ n bá»™ quy trÃ¬nh Ä‘á»ƒ lÃ m ra Vietcuna. Vá»›i hÆ°á»›ng dáº«n nÃ y kÃ¨m vá»›i model Vietcuna Ä‘Ã£ cÃ³ sáºµn, mong sáº½ cÃ³ nhiá»u báº¡n vÃ  doanh nghiá»‡p Viá»‡t Nam táº¡o ra cÃ¡c sáº£n pháº©m AI mang tÃ­nh thá»±c táº¿ cao trong cuá»™c sá»‘ng :) Link:",,,"#sharing, #data",,
"ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang cáº§n train model vá»›i bá»™ data khoáº£ng 129GB dáº¡ng zip, nhÆ°ng vá»›i colab free thÃ¬ nÃ³ chá»‰ cÃ³ khoáº£ng 70 gb á»• nhá»› free. CÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ train khÃ´ng giÃºp mÃ¬nh vá»›i áº¡. Mong mn giÃºp Ä‘á»¡ áº¡.","ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang cáº§n train model vá»›i bá»™ data khoáº£ng 129GB dáº¡ng zip, nhÆ°ng vá»›i colab free thÃ¬ nÃ³ chá»‰ cÃ³ khoáº£ng 70 gb á»• nhá»› free. CÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ train khÃ´ng giÃºp mÃ¬nh vá»›i áº¡. Mong mn giÃºp Ä‘á»¡ áº¡.",,,"#Q&A, #data",,
"HÃ´m trÆ°á»›c mÃ¬nh tháº¥y cÃ³ má»™t sá»‘ cÃ¢u há»i vá» server vÃ  colab, thá»±c sá»±, mÃ¬nh cÅ©ng Ä‘Ã£ gáº·p khÃ¡ nhiá»u váº¥n Ä‘á» vá»›i giá»›i háº¡n thá»i gian sá»­ dá»¥ng colab, giá»›i háº¡n dung lÆ°á»£ng RAM vÃ  giá»›i háº¡n pháº§n cá»©ng. MÃ¬nh Ä‘Ã£ pháº£i mua gÃ³i pro hoáº·c tháº­m chÃ­ lÃ  gÃ³i pro+ Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y. Tuy nhiÃªn, viá»‡c Ä‘Ã³ váº«n khÃ´ng hoÃ n toÃ n thuáº­n lá»£i vÃ¬ Ä‘Ã´i khi mÃ¬nh quÃªn táº¯t colab, dáº«n Ä‘áº¿n viá»‡c nÃ³ treo vÃ  tiáº¿p tá»¥c trá»« tÃ i khoáº£n tÃ­nh tiá»n, nhÆ° gÃ³i pro+ giÃ¡ $49 má»—i thÃ¡ng. Gáº§n Ä‘Ã¢y, mÃ¬nh Ä‘Ã£ tÃ¬m ra má»™t giáº£i phÃ¡p tá»‘t hÆ¡n lÃ  sá»­ dá»¥ng Gradient. Gradient cung cáº¥p cho chÃºng ta má»™t container Docker hoÃ n chá»‰nh cho má»—i notebook, vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n káº¿t trá»±c tiáº¿p vá»›i mÃ¡y chá»§ chÃ­nh. HÆ¡n ná»¯a, phiÃªn báº£n miá»…n phÃ­ cá»§a Gradient cung cáº¥p 5GB dung lÆ°á»£ng lÆ°u trá»¯ vÄ©nh viá»…n, dá»¯ liá»‡u trong Ä‘Ã³ khÃ´ng bá»‹ máº¥t, ngay cáº£ khi notebook gáº·p váº¥n Ä‘á» vÃ  mÃ¬nh xÃ³a toÃ n bá»™. Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Gradient miá»…n phÃ­ trong 6 giá» liÃªn tá»¥c cho má»—i phiÃªn notebook, nÃ³ sáº½ khÃ´ng bá»‹ táº¯t giá»¯a chá»«ng nhÆ° colab. Äiá»u thÃº vá»‹ lÃ  vá»›i gÃ³i pro chá»‰ $8 má»—i thÃ¡ng, báº¡n cÃ³ thá»ƒ tráº£i nghiá»‡m nhiá»u cáº¥u hÃ¬nh miá»…n phÃ­ tuyá»‡t vá»i, vÃ­ dá»¥ nhÆ° P5000 vá»›i 30GB RAM, 8G CPU vÃ  16GB GPU, hoáº·c A400 vá»›i 45GB RAM, 8G CPU vÃ  16GB GPU... Quan trá»ng lÃ  sau 6 giá», báº¡n cÃ³ thá»ƒ káº¿t ná»‘i vÃ  tiáº¿p tá»¥c sá»­ dá»¥ng vá»›i khoáº£n phÃ­ $8 Ä‘Ã³, nhÆ° má»™t khoáº£n phÃ­ duy trÃ¬. Náº¿u báº¡n Ä‘Äƒng kÃ½ gÃ³i GROWTH, báº¡n sáº½ cÃ³ nhiá»u mÃ¡y chá»§ miá»…n phÃ­ hÆ¡n, tháº­m chÃ­ cÃ³ A100 vá»›i 80GB GPU miá»…n phÃ­ :)). Tuy nhiÃªn, vá»›i phiÃªn báº£n miá»…n phÃ­, sau 6 giá» sá»­ dá»¥ng, nÃ³ sáº½ tá»± Ä‘á»™ng táº¯t vÃ  báº¡n cáº§n tÃ¬m má»™t mÃ¡y chá»§ khÃ¡c Ä‘á»ƒ káº¿t ná»‘i tiáº¿p. TÃ³m láº¡i, mÃ¬nh tháº¥y Gradient ngon hÆ¡n nhiá»u so vá»›i colab ğŸ˜‚ğŸ˜‚.","HÃ´m trÆ°á»›c mÃ¬nh tháº¥y cÃ³ má»™t sá»‘ cÃ¢u há»i vá» server vÃ  colab, thá»±c sá»±, mÃ¬nh cÅ©ng Ä‘Ã£ gáº·p khÃ¡ nhiá»u váº¥n Ä‘á» vá»›i giá»›i háº¡n thá»i gian sá»­ dá»¥ng colab, giá»›i háº¡n dung lÆ°á»£ng RAM vÃ  giá»›i háº¡n pháº§n cá»©ng. MÃ¬nh Ä‘Ã£ pháº£i mua gÃ³i pro hoáº·c tháº­m chÃ­ lÃ  gÃ³i pro+ Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y. Tuy nhiÃªn, viá»‡c Ä‘Ã³ váº«n khÃ´ng hoÃ n toÃ n thuáº­n lá»£i vÃ¬ Ä‘Ã´i khi mÃ¬nh quÃªn táº¯t colab, dáº«n Ä‘áº¿n viá»‡c nÃ³ treo vÃ  tiáº¿p tá»¥c trá»« tÃ i khoáº£n tÃ­nh tiá»n, nhÆ° gÃ³i pro+ giÃ¡ $49 má»—i thÃ¡ng. Gáº§n Ä‘Ã¢y, mÃ¬nh Ä‘Ã£ tÃ¬m ra má»™t giáº£i phÃ¡p tá»‘t hÆ¡n lÃ  sá»­ dá»¥ng Gradient. Gradient cung cáº¥p cho chÃºng ta má»™t container Docker hoÃ n chá»‰nh cho má»—i notebook, vÃ  dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n káº¿t trá»±c tiáº¿p vá»›i mÃ¡y chá»§ chÃ­nh. HÆ¡n ná»¯a, phiÃªn báº£n miá»…n phÃ­ cá»§a Gradient cung cáº¥p 5GB dung lÆ°á»£ng lÆ°u trá»¯ vÄ©nh viá»…n, dá»¯ liá»‡u trong Ä‘Ã³ khÃ´ng bá»‹ máº¥t, ngay cáº£ khi notebook gáº·p váº¥n Ä‘á» vÃ  mÃ¬nh xÃ³a toÃ n bá»™. Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Gradient miá»…n phÃ­ trong 6 giá» liÃªn tá»¥c cho má»—i phiÃªn notebook, nÃ³ sáº½ khÃ´ng bá»‹ táº¯t giá»¯a chá»«ng nhÆ° colab. Äiá»u thÃº vá»‹ lÃ  vá»›i gÃ³i pro chá»‰ $8 má»—i thÃ¡ng, báº¡n cÃ³ thá»ƒ tráº£i nghiá»‡m nhiá»u cáº¥u hÃ¬nh miá»…n phÃ­ tuyá»‡t vá»i, vÃ­ dá»¥ nhÆ° P5000 vá»›i 30GB RAM, 8G CPU vÃ  16GB GPU, hoáº·c A400 vá»›i 45GB RAM, 8G CPU vÃ  16GB GPU... Quan trá»ng lÃ  sau 6 giá», báº¡n cÃ³ thá»ƒ káº¿t ná»‘i vÃ  tiáº¿p tá»¥c sá»­ dá»¥ng vá»›i khoáº£n phÃ­ $8 Ä‘Ã³, nhÆ° má»™t khoáº£n phÃ­ duy trÃ¬. Náº¿u báº¡n Ä‘Äƒng kÃ½ gÃ³i GROWTH, báº¡n sáº½ cÃ³ nhiá»u mÃ¡y chá»§ miá»…n phÃ­ hÆ¡n, tháº­m chÃ­ cÃ³ A100 vá»›i 80GB GPU miá»…n phÃ­ :)). Tuy nhiÃªn, vá»›i phiÃªn báº£n miá»…n phÃ­, sau 6 giá» sá»­ dá»¥ng, nÃ³ sáº½ tá»± Ä‘á»™ng táº¯t vÃ  báº¡n cáº§n tÃ¬m má»™t mÃ¡y chá»§ khÃ¡c Ä‘á»ƒ káº¿t ná»‘i tiáº¿p. TÃ³m láº¡i, mÃ¬nh tháº¥y Gradient ngon hÆ¡n nhiá»u so vá»›i colab .",,,#sharing,,
"Xin chÃ o má»i ngÆ°á»i, e Ä‘ang lÃ m nhÃ£n cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh . Em cÃ³ 1 tháº¯c máº¯c lÃ  : vá»›i áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i nhá» ( 100x100 ), cháº¥t lÆ°á»£ng hÆ¡i kÃ©m, kÃ­ch thÆ°á»›c cá»§a Ä‘á»“ váº­t cáº§n phÃ¢n loáº¡i nhá» trong áº£nh, vÃ  cÅ©ng hÆ¡i má» thÃ¬ nÃªn phÃ¢n loáº¡i áº£nh lÃ  negative hay positive áº¡. Náº¿u lÃ  máº¯t con ngÆ°á»i thÃ¬ cÃ³ thá»ƒ Ä‘oÃ¡n Ä‘Æ°á»£c lÃ  Ä‘á»“ váº­t Ä‘Ã³ ( positive ), nhÆ°ng Ä‘á»ƒ lÃ  mÃ¡y Ä‘oÃ¡n dc thÃ¬ quÃ¡ khÃ³ , VÃ­ dá»¥ nhá»¯ng áº£nh dÆ°á»›i Ä‘Ã¢y chá»©a xe Ä‘áº¡p ( máº¯t ngÆ°á»i thÃ¬ Ä‘oÃ¡n Ä‘c ),nhÆ°ng Ä‘á»ƒ AI Ä‘oÃ¡n Ä‘Æ°á»£c lÃ  xe Ä‘áº¡p thÃ¬ quÃ¡ khÃ³. Theo má»i ngÆ°á»i thÃ¬ nÃªn phÃ¢n loáº¡i gÃ¬ áº¡ ?. Em cáº£m Æ¡n nhiá»u ,","Xin chÃ o má»i ngÆ°á»i, e Ä‘ang lÃ m nhÃ£n cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh . Em cÃ³ 1 tháº¯c máº¯c lÃ  : vá»›i áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i nhá» ( 100x100 ), cháº¥t lÆ°á»£ng hÆ¡i kÃ©m, kÃ­ch thÆ°á»›c cá»§a Ä‘á»“ váº­t cáº§n phÃ¢n loáº¡i nhá» trong áº£nh, vÃ  cÅ©ng hÆ¡i má» thÃ¬ nÃªn phÃ¢n loáº¡i áº£nh lÃ  negative hay positive áº¡. Náº¿u lÃ  máº¯t con ngÆ°á»i thÃ¬ cÃ³ thá»ƒ Ä‘oÃ¡n Ä‘Æ°á»£c lÃ  Ä‘á»“ váº­t Ä‘Ã³ ( positive ), nhÆ°ng Ä‘á»ƒ lÃ  mÃ¡y Ä‘oÃ¡n dc thÃ¬ quÃ¡ khÃ³ , VÃ­ dá»¥ nhá»¯ng áº£nh dÆ°á»›i Ä‘Ã¢y chá»©a xe Ä‘áº¡p ( máº¯t ngÆ°á»i thÃ¬ Ä‘oÃ¡n Ä‘c ),nhÆ°ng Ä‘á»ƒ AI Ä‘oÃ¡n Ä‘Æ°á»£c lÃ  xe Ä‘áº¡p thÃ¬ quÃ¡ khÃ³. Theo má»i ngÆ°á»i thÃ¬ nÃªn phÃ¢n loáº¡i gÃ¬ áº¡ ?. Em cáº£m Æ¡n nhiá»u ,",,,"#Q&A, #data",,
"Hi má»i ngÆ°á»i,
Em Ä‘ang tÃ­nh lÃ m má»™t dá»± Ã¡n vá»› Llama 2. Em cÃ³ má»™t tháº¯c máº¯c vá» data privacy.NhÆ° khi em dÃ¹ng chatGPT, thÃ¬ má»i thÃ´ng tin tá»« prompt, hoáº·c data mÃ  mÃ¬nh dÃ¹ng Ä‘á»ƒ fine-tune sáº½ Ä‘Æ°á»£c Ä‘Æ°a vá» OpenAI. Váº­y cho em há»i náº¿u em fine-tuned Llama 2 model, thÃ¬ data mÃ¬nh dÃ¹ng Ä‘á»ƒ fine-tune hoáº·c prompt cá»§a mÃ¬nh khi sá»­ dá»¥ng model cÃ³ bá»‹ lÆ°u bá»Ÿi Meta k áº¡? Em cáº£m Æ¡n!","Hi má»i ngÆ°á»i, Em Ä‘ang tÃ­nh lÃ m má»™t dá»± Ã¡n vá»› Llama 2. Em cÃ³ má»™t tháº¯c máº¯c vá» data privacy.NhÆ° khi em dÃ¹ng chatGPT, thÃ¬ má»i thÃ´ng tin tá»« prompt, hoáº·c data mÃ  mÃ¬nh dÃ¹ng Ä‘á»ƒ fine-tune sáº½ Ä‘Æ°á»£c Ä‘Æ°a vá» OpenAI. Váº­y cho em há»i náº¿u em fine-tuned Llama 2 model, thÃ¬ data mÃ¬nh dÃ¹ng Ä‘á»ƒ fine-tune hoáº·c prompt cá»§a mÃ¬nh khi sá»­ dá»¥ng model cÃ³ bá»‹ lÆ°u bá»Ÿi Meta k áº¡? Em cáº£m Æ¡n!",,,"#Q&A, #data, #nlp",,
"NgÃ y há»™i TrÃ­ tuá»‡ nhÃ¢n táº¡o Viá»‡t Nam (AI4VN 2023) cÃ³ chá»§ Ä‘á» ""Sá»©c máº¡nh cho cuá»™c sá»‘ng"" vá»›i bá»‘n hoáº¡t Ä‘á»™ng chÃ­nh: AI workshop; AI Summit; AI Expo; CTO Summit 2023 - vinh danh cÃ¡c cÃ´ng ty cÃ³ mÃ´i trÆ°á»ng cÃ´ng nghá»‡ tá»‘t nháº¥t.PhiÃªn khai máº¡c ngÃ y 21/9 mang Ä‘áº¿n bÃ¡o cÃ¡o Chá»‰ sá»‘ sáºµn sÃ ng AI cá»§a chÃ­nh phá»§ nÄƒm 2022, trÃ¬nh bÃ y bá»Ÿi Ã´ng Pablo Fuentes Nettel - ChuyÃªn gia tÆ° váº¥n cáº¥p cao táº¡i Oxford Insights. Ngay sau Ä‘Ã³ lÃ  cÃ¡c pháº§n tham luáº­n vá» á»©ng dá»¥ng AI trong tÆ°Æ¡ng lai, kinh nghiá»‡m triá»ƒn khai thá»±c táº¿ táº¡i HÃ n Quá»‘c, lÃ m chá»§ AI táº¡o sinh... qua gÃ³c nhÃ¬n cá»§a cÃ¡c chuyÃªn gia VinBigdata, Naver, VNPT, Aqua.
#AI4VN #VietAI #AI4VN2023","NgÃ y há»™i TrÃ­ tuá»‡ nhÃ¢n táº¡o Viá»‡t Nam (AI4VN 2023) cÃ³ chá»§ Ä‘á» ""Sá»©c máº¡nh cho cuá»™c sá»‘ng"" vá»›i bá»‘n hoáº¡t Ä‘á»™ng chÃ­nh: AI workshop; AI Summit; AI Expo; CTO Summit 2023 - vinh danh cÃ¡c cÃ´ng ty cÃ³ mÃ´i trÆ°á»ng cÃ´ng nghá»‡ tá»‘t nháº¥t.PhiÃªn khai máº¡c ngÃ y 21/9 mang Ä‘áº¿n bÃ¡o cÃ¡o Chá»‰ sá»‘ sáºµn sÃ ng AI cá»§a chÃ­nh phá»§ nÄƒm 2022, trÃ¬nh bÃ y bá»Ÿi Ã´ng Pablo Fuentes Nettel - ChuyÃªn gia tÆ° váº¥n cáº¥p cao táº¡i Oxford Insights. Ngay sau Ä‘Ã³ lÃ  cÃ¡c pháº§n tham luáº­n vá» á»©ng dá»¥ng AI trong tÆ°Æ¡ng lai, kinh nghiá»‡m triá»ƒn khai thá»±c táº¿ táº¡i HÃ n Quá»‘c, lÃ m chá»§ AI táº¡o sinh... qua gÃ³c nhÃ¬n cá»§a cÃ¡c chuyÃªn gia VinBigdata, Naver, VNPT, Aqua.",#AI4VN	#VietAI	#AI4VN2023,,#sharing,,
"Yeahhhhh! ğŸŒŸ
MÃ¬nh ráº¥t vui giá»›i thiá»‡u VietAssistant-GPT phiÃªn báº£n 1.0 ğŸ‡»ğŸ‡³. LÃ  má»™t trá»£ lÃ½ Ä‘a nÄƒng  (general domain)..
Dá»±a trÃªn phÃ¡t triá»ƒn cá»§a open-source LLaMa 2, phiÃªn báº£n nÃ y Ä‘Ã£ Ä‘Æ°á»£c finetune Ä‘á»ƒ cung cáº¥p cho báº¡n nhá»¯ng cÃ¢u tráº£ há»¯u Ã­ch hÆ¡n trong nhiá»u lÄ©nh vá»±c trÃªn Tiáº¿ng Viá»‡t. VÃ  Ä‘ang trong quÃ¡ trÃ¬nh cáº£i thiá»‡nğŸ“š
Finetuned model vÃ  dataset Ä‘Æ°á»£c cung cáº¥p á»Ÿ link sau:
https://github.com/VietnamAIHub/Vietnamese_LLMs
Demo Link:
Vietnamese llama2 13B  Demo https://c4242d50778850141a.gradio.live/
Vietnamese llama2 7B Model Demo https://31fee86ed135939f28.gradio.live
Ráº¥t mong chá» sá»± pháº£n há»“i vÃ  Ã½ kiáº¿n cá»§a má»i ngÆ°á»i ! ğŸ™Œ","Yeahhhhh! MÃ¬nh ráº¥t vui giá»›i thiá»‡u VietAssistant-GPT phiÃªn báº£n 1.0 . LÃ  má»™t trá»£ lÃ½ Ä‘a nÄƒng (general domain).. Dá»±a trÃªn phÃ¡t triá»ƒn cá»§a open-source LLaMa 2, phiÃªn báº£n nÃ y Ä‘Ã£ Ä‘Æ°á»£c finetune Ä‘á»ƒ cung cáº¥p cho báº¡n nhá»¯ng cÃ¢u tráº£ há»¯u Ã­ch hÆ¡n trong nhiá»u lÄ©nh vá»±c trÃªn Tiáº¿ng Viá»‡t. VÃ  Ä‘ang trong quÃ¡ trÃ¬nh cáº£i thiá»‡n Finetuned model vÃ  dataset Ä‘Æ°á»£c cung cáº¥p á»Ÿ link sau: https://github.com/VietnamAIHub/Vietnamese_LLMs Demo Link: Vietnamese llama2 13B Demo https://c4242d50778850141a.gradio.live/ Vietnamese llama2 7B Model Demo https://31fee86ed135939f28.gradio.live Ráº¥t mong chá» sá»± pháº£n há»“i vÃ  Ã½ kiáº¿n cá»§a má»i ngÆ°á»i !",,,"#sharing, #nlp",,
"KhÃ´ng biáº¿t cÃ³ ace báº¡n nÃ o cÃ³ biáº¿t qua bÃ i nÃ y khÃ´ng áº¡?
NASA: Neural Articulated Shape Approximation
Cho mÃ¬nh há»i vÃ i cÃ¢u há»i bÃªn dÆ°á»›i (cháº¯c sáº½ cÃ²n há»i thÃªm):
1/ Query á»Ÿ Ä‘Ã¢y lÃ  cÃ¡i gÃ¬ ??
- Pháº§n tÃ³m táº¯t contribution cÃ³ cÃ¢u sau: 
""The differentiable occupancy supports efficient constant time queries, avoiding the need to convert to separate representations, or the dynamic update of spatial acceleration data structures;"" 
- Pháº§n related work cÃ³ nÃ³i:
Object intersection queries: Registration, template matching, 3D tracking, collision detection, and other tasks require efficient inside/outside tests. A disadvantage of polygonal meshes is that they do not efficiently support these queries, as meshes often contain thousands of individual triangles that must be tested for each query. This has led to the development of a variety of spatial data structures to accelerate point-object queries
Káº¿t há»£p thÃªm cÃ¡i hÃ¬nh Figure 1 nÃ y. chá»— O(x|Î¸) lÃ  cÃ¡i gÃ¬ ? nhÃ¬n khÃ³ hiá»ƒu.
Chá»— nÃ y em thá»±c sá»± cháº³ng hiá»ƒu cÃ¡i query á»Ÿ Ä‘Ã¢y lÃ  query cÃ¡i gÃ¬?
Rá»‘t cuá»™c input/output cá»§a paper nÃ y lÃ  gÃ¬ ? (Tháº¥y nÃ³ Ä‘Æ°á»£c train trÃªn AMASS dataset? váº­y input lÃ  pointcloud ?
Táº¡i sao pháº§n demo á»©ng dá»¥ng thÃ¬ láº¡i chá»n tracking body?
(Em ko rÃ nh bÃªn 3D CV nÃ y mÃ  bá»‹ gÃ¡n cho presentation trong mÃ´n há»c mÃ  chá»‰ cÃ³ vÃ i ngÃ y chuáº©n bá»‹ nÃªn hÆ¡i quÃ¡ táº£i).
Hi vá»ng cÃ³ ace nÃ o biáº¿t chá»‰ giÃ¡o vá»›i áº¡.
Em cáº£m Æ¡n ğŸ˜Š","KhÃ´ng biáº¿t cÃ³ ace báº¡n nÃ o cÃ³ biáº¿t qua bÃ i nÃ y khÃ´ng áº¡? NASA: Neural Articulated Shape Approximation Cho mÃ¬nh há»i vÃ i cÃ¢u há»i bÃªn dÆ°á»›i (cháº¯c sáº½ cÃ²n há»i thÃªm): 1/ Query á»Ÿ Ä‘Ã¢y lÃ  cÃ¡i gÃ¬ ?? - Pháº§n tÃ³m táº¯t contribution cÃ³ cÃ¢u sau: ""The differentiable occupancy supports efficient constant time queries, avoiding the need to convert to separate representations, or the dynamic update of spatial acceleration data structures;"" - Pháº§n related work cÃ³ nÃ³i: Object intersection queries: Registration, template matching, 3D tracking, collision detection, and other tasks require efficient inside/outside tests. A disadvantage of polygonal meshes is that they do not efficiently support these queries, as meshes often contain thousands of individual triangles that must be tested for each query. This has led to the development of a variety of spatial data structures to accelerate point-object queries Káº¿t há»£p thÃªm cÃ¡i hÃ¬nh Figure 1 nÃ y. chá»— O(x|Î¸) lÃ  cÃ¡i gÃ¬ ? nhÃ¬n khÃ³ hiá»ƒu. Chá»— nÃ y em thá»±c sá»± cháº³ng hiá»ƒu cÃ¡i query á»Ÿ Ä‘Ã¢y lÃ  query cÃ¡i gÃ¬? Rá»‘t cuá»™c input/output cá»§a paper nÃ y lÃ  gÃ¬ ? (Tháº¥y nÃ³ Ä‘Æ°á»£c train trÃªn AMASS dataset? váº­y input lÃ  pointcloud ? Táº¡i sao pháº§n demo á»©ng dá»¥ng thÃ¬ láº¡i chá»n tracking body? (Em ko rÃ nh bÃªn 3D CV nÃ y mÃ  bá»‹ gÃ¡n cho presentation trong mÃ´n há»c mÃ  chá»‰ cÃ³ vÃ i ngÃ y chuáº©n bá»‹ nÃªn hÆ¡i quÃ¡ táº£i). Hi vá»ng cÃ³ ace nÃ o biáº¿t chá»‰ giÃ¡o vá»›i áº¡. Em cáº£m Æ¡n",,,"#Q&A, #cv, #math",,
"MÃ¬nh tháº¥y giá» nhiá»u báº¡n lo háº¿t viá»‡c, sá»£ AI thay tháº¿, sá»£ cáº¡nh tranh cao... Tuy nhiÃªn theo mÃ¬nh thÃ¬ nhu cáº§u cÃ´ng viá»‡c ngoÃ i kia khÃ´ng thiáº¿u, cÃ¡i thiáº¿u á»Ÿ Ä‘Ã¢y lÃ  thiáº¿u ngÆ°á»i giá»i vÃ  ngÆ°á»i phÃ¹ há»£p. Váº­y nÃªn, cÃ³ nhá»¯ng thá»© cÃ¡c báº¡n khÃ´ng thá»ƒ kiá»ƒm soÃ¡t Ä‘Æ°á»£c thÃ¬ khÃ´ng nÃªn tá»‘n nÄƒng lÆ°á»£ng lÃ m gÃ¬, cÃ¡i cÃ¡c báº¡n cáº§n lÃ  hÃ£y nÃ¢ng cao nÄƒng lá»±c, giá»i tá»›i má»©c ngÆ°á»i ta khÃ´ng thá»ƒ ngÃ³ lÆ¡ thÃ¬ má»i thá»© sáº½ tuyá»‡t vá»i hÆ¡n ráº¥t nhiá»u.","MÃ¬nh tháº¥y giá» nhiá»u báº¡n lo háº¿t viá»‡c, sá»£ AI thay tháº¿, sá»£ cáº¡nh tranh cao... Tuy nhiÃªn theo mÃ¬nh thÃ¬ nhu cáº§u cÃ´ng viá»‡c ngoÃ i kia khÃ´ng thiáº¿u, cÃ¡i thiáº¿u á»Ÿ Ä‘Ã¢y lÃ  thiáº¿u ngÆ°á»i giá»i vÃ  ngÆ°á»i phÃ¹ há»£p. Váº­y nÃªn, cÃ³ nhá»¯ng thá»© cÃ¡c báº¡n khÃ´ng thá»ƒ kiá»ƒm soÃ¡t Ä‘Æ°á»£c thÃ¬ khÃ´ng nÃªn tá»‘n nÄƒng lÆ°á»£ng lÃ m gÃ¬, cÃ¡i cÃ¡c báº¡n cáº§n lÃ  hÃ£y nÃ¢ng cao nÄƒng lá»±c, giá»i tá»›i má»©c ngÆ°á»i ta khÃ´ng thá»ƒ ngÃ³ lÆ¡ thÃ¬ má»i thá»© sáº½ tuyá»‡t vá»i hÆ¡n ráº¥t nhiá»u.",,,#sharing,,
"Khai phÃ¡ dá»¯ liá»‡u lÃ  má»™t pháº§n viá»‡c ráº¥t quan trá»ng Ä‘á»ƒ hiá»ƒu vá» dá»¯ liá»‡u cho cÃ¡c má»¥c Ä‘Ã­ch phÃ¢n tÃ­ch chuyÃªn sÃ¢u tiáº¿p theo. ÄÃ¢y cuá»‘n sÃ¡ch gáº§n 400 trang hÆ°á»›ng dáº«n biá»ƒu diá»…n dá»¯ liá»‡u sá»­ dá»¥ng Python (Matplotlib vÃ  Seaborn) nhÆ°: (1) má»™t sá»‘ kÄ© thuáº­t lá»±a chá»n dáº¡ng biá»ƒu Ä‘á»“ phÃ¹ há»£p; (2) xá»­ lÃ­ missing data/outliers; (3) pháº§n biá»ƒu diá»…n dá»¯ liá»‡u Ä‘á»‹a lÃ½ (báº£n Ä‘á»“~geospatial data); vÃ  (4) biá»ƒu diá»…n dá»¯ liá»‡u dáº¡ng 3D táº¡i Ä‘Ã¢y https://theswissbay.ch/pdf/Gentoomen%20Library/Programming/Python/Beginning%20Python%20Visualization%20-%20Crafting%20Visual%20Transformation%20Scripts%20%282009%29.pdf; https://pyoflife.com/beginning-python-visualization-crafting-visual-transformation-scripts/
Hi vá»ng nÃ³ cÃ³ Ã­ch vá»›i má»i ngÆ°á»i",Khai phÃ¡ dá»¯ liá»‡u lÃ  má»™t pháº§n viá»‡c ráº¥t quan trá»ng Ä‘á»ƒ hiá»ƒu vá» dá»¯ liá»‡u cho cÃ¡c má»¥c Ä‘Ã­ch phÃ¢n tÃ­ch chuyÃªn sÃ¢u tiáº¿p theo. ÄÃ¢y cuá»‘n sÃ¡ch gáº§n 400 trang hÆ°á»›ng dáº«n biá»ƒu diá»…n dá»¯ liá»‡u sá»­ dá»¥ng Python (Matplotlib vÃ  Seaborn) nhÆ°: (1) má»™t sá»‘ kÄ© thuáº­t lá»±a chá»n dáº¡ng biá»ƒu Ä‘á»“ phÃ¹ há»£p; (2) xá»­ lÃ­ missing data/outliers; (3) pháº§n biá»ƒu diá»…n dá»¯ liá»‡u Ä‘á»‹a lÃ½ (báº£n Ä‘á»“~geospatial data); vÃ  (4) biá»ƒu diá»…n dá»¯ liá»‡u dáº¡ng 3D táº¡i Ä‘Ã¢y https://theswissbay.ch/pdf/Gentoomen%20Library/Programming/Python/Beginning%20Python%20Visualization%20-%20Crafting%20Visual%20Transformation%20Scripts%20%282009%29.pdf; https://pyoflife.com/beginning-python-visualization-crafting-visual-transformation-scripts/ Hi vá»ng nÃ³ cÃ³ Ã­ch vá»›i má»i ngÆ°á»i,,,"#sharing, #data",,
"Dáº¡o nÃ y em Ä‘á»c vá» RLHF (Reinforcement learning from human feedback) tháº¥y khÃ¡ thÃº vá»‹ + practical in production khÃ¡ cao. Em Ä‘ang tÃ­nh lÃ m 1 project Ä‘á»ƒ extract features tá»« description cá»§a sáº£n pháº©m, trong Ä‘Ã³ model nháº­n feedback tá»« ngÆ°á»i dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem output cá»§a model chÃ­nh xÃ¡c tá»›i cá»¡ nÃ o vÃ  model dÃ¹ng Ä‘Ã³ Ä‘á»ƒ reward/penalty trong loss function.
KhÃ´ng biáº¿t cÃ¡c bÃ¡c cÃ³ kinh nghiá»‡m gÃ¬ vá» máº£ng nÃ y khÃ´ng áº¡?","Dáº¡o nÃ y em Ä‘á»c vá» RLHF (Reinforcement learning from human feedback) tháº¥y khÃ¡ thÃº vá»‹ + practical in production khÃ¡ cao. Em Ä‘ang tÃ­nh lÃ m 1 project Ä‘á»ƒ extract features tá»« description cá»§a sáº£n pháº©m, trong Ä‘Ã³ model nháº­n feedback tá»« ngÆ°á»i dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem output cá»§a model chÃ­nh xÃ¡c tá»›i cá»¡ nÃ o vÃ  model dÃ¹ng Ä‘Ã³ Ä‘á»ƒ reward/penalty trong loss function. KhÃ´ng biáº¿t cÃ¡c bÃ¡c cÃ³ kinh nghiá»‡m gÃ¬ vá» máº£ng nÃ y khÃ´ng áº¡?",,,"#Q&A, #deep_learning",,
"Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá»›i Ä‘á» táº¡i lÃ  trÃ­ch xuáº¥t ná»™i dung tá»« danh thiáº¿p báº±ng OCR , tuy nhiÃªn do data Ã­t nÃªn em Ä‘Äƒng bÃ i nÃ y mong muá»‘n kiáº¿m má»™t lÆ°á»£ng lá»›n data vá» danh thiáº¿p Ä‘á»ƒ bá»• sung vÃ o Ä‘atn áº¡, náº¿u ai cÃ³ thÃ¬ cho em xin hoáº·c mua láº¡i áº¡, em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡","Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá»›i Ä‘á» táº¡i lÃ  trÃ­ch xuáº¥t ná»™i dung tá»« danh thiáº¿p báº±ng OCR , tuy nhiÃªn do data Ã­t nÃªn em Ä‘Äƒng bÃ i nÃ y mong muá»‘n kiáº¿m má»™t lÆ°á»£ng lá»›n data vá» danh thiáº¿p Ä‘á»ƒ bá»• sung vÃ o Ä‘atn áº¡, náº¿u ai cÃ³ thÃ¬ cho em xin hoáº·c mua láº¡i áº¡, em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡",,,"#Q&A, #cv, #data",,
"Xin chÃ o má»i ngÆ°á»i!
Hiá»‡n táº¡i mÃ¬nh Ä‘ang thá»±c hiá»‡n 1 Project cho Product, á»©ng dá»¥ng LLM. Tuy nhiÃªn do data Ã­t nÃªn mÃ¬nh Ä‘Äƒng bÃ i nÃ y vá»›i mong muá»‘n tÃ¬m kiáº¿m thÃªm data Ä‘á»ƒ Project Ä‘Æ°á»£c hoÃ n thiá»‡n.
Data mÃ¬nh cáº§n lÃ  áº£nh cÃ¡c loáº¡i hÃ³a Ä‘Æ¡n thÆ°Æ¡ng máº¡i. Náº¿u ai cÃ³ nguá»“n data nhÆ° váº­y thÃ¬ cÃ³ thá»ƒ cho mÃ¬nh xin (hoáº·c mua náº¿u cáº§n) Ä‘Æ°á»£c khÃ´ng áº¡?
MÃ¬nh xin cáº£m Æ¡n áº¡!","Xin chÃ o má»i ngÆ°á»i! Hiá»‡n táº¡i mÃ¬nh Ä‘ang thá»±c hiá»‡n 1 Project cho Product, á»©ng dá»¥ng LLM. Tuy nhiÃªn do data Ã­t nÃªn mÃ¬nh Ä‘Äƒng bÃ i nÃ y vá»›i mong muá»‘n tÃ¬m kiáº¿m thÃªm data Ä‘á»ƒ Project Ä‘Æ°á»£c hoÃ n thiá»‡n. Data mÃ¬nh cáº§n lÃ  áº£nh cÃ¡c loáº¡i hÃ³a Ä‘Æ¡n thÆ°Æ¡ng máº¡i. Náº¿u ai cÃ³ nguá»“n data nhÆ° váº­y thÃ¬ cÃ³ thá»ƒ cho mÃ¬nh xin (hoáº·c mua náº¿u cáº§n) Ä‘Æ°á»£c khÃ´ng áº¡? MÃ¬nh xin cáº£m Æ¡n áº¡!",,,"#Q&A, #data",,
"Váº­y lÃ  Mojo, ngÃ´n ngá»¯ má»›i cho ML/DL/AI, Ä‘Ã£ cho phÃ©p cÃ i Ä‘áº·t trÃªn mÃ¡y tÃ­nh cÃ¡ nhÃ¢n. Hiá»‡n táº¡i, Mojo má»›i há»— trá»£ há»‡ Ä‘iá»u hÃ nh Linux. CÃ¡c báº¡n cÃ³ thá»ƒ test báº±ng cÃ¡ch Ä‘Äƒng kÃ­ vÃ  cÃ i Ä‘áº·t táº¡i Ä‘Ã¢y","Váº­y lÃ  Mojo, ngÃ´n ngá»¯ má»›i cho ML/DL/AI, Ä‘Ã£ cho phÃ©p cÃ i Ä‘áº·t trÃªn mÃ¡y tÃ­nh cÃ¡ nhÃ¢n. Hiá»‡n táº¡i, Mojo má»›i há»— trá»£ há»‡ Ä‘iá»u hÃ nh Linux. CÃ¡c báº¡n cÃ³ thá»ƒ test báº±ng cÃ¡ch Ä‘Äƒng kÃ­ vÃ  cÃ i Ä‘áº·t táº¡i Ä‘Ã¢y",,,#sharing,,
"#question
Mn cÃ³ thá»ƒ recommend cho e 1 vÃ i kÃªnh há»c lÃ½ thuyáº¿t ML tá»« basic khÃ´ng áº¡. Em muá»‘n náº¯m dc basic ML má»™t cÃ¡ch nhanh chÃ³ng nhÆ°ng cáº£m giÃ¡c bá»‹ há»•ng Ä‘Ã¢u Ä‘Ã³ vá» lÃ½ thuyáº¿t nhÆ°ng khÃ´ng biáº¿t lÃ  chá»— nÃ o. Em cáº£m Æ¡n",Mn cÃ³ thá»ƒ recommend cho e 1 vÃ i kÃªnh há»c lÃ½ thuyáº¿t ML tá»« basic khÃ´ng áº¡. Em muá»‘n náº¯m dc basic ML má»™t cÃ¡ch nhanh chÃ³ng nhÆ°ng cáº£m giÃ¡c bá»‹ há»•ng Ä‘Ã¢u Ä‘Ã³ vá» lÃ½ thuyáº¿t nhÆ°ng khÃ´ng biáº¿t lÃ  chá»— nÃ o. Em cáº£m Æ¡n,#question,,"#Q&A, #machine_learning",,
"Dáº¡ anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u bÃ i táº­p vá» Linear Regression vÃ   Logistic Regression , cho em xin áº¡ . Dáº¡ em cáº£m  Æ¡n  ","Dáº¡ anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u bÃ i táº­p vá» Linear Regression vÃ  Logistic Regression , cho em xin áº¡ . Dáº¡ em cáº£m Æ¡n",,,"#Q&A, #machine_learning",,
Má»i ngÆ°á»i cho e há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ dá»‹ch tá»« tiáº¿ng anh vá» tiáº¿ng viá»‡t cho nÃ³ tá»± nhiÃªn hÆ¡n khÃ´ng áº¡ (khÃ´ng dÃ¹ng chatgpt vÃ  google)?,Má»i ngÆ°á»i cho e há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ dá»‹ch tá»« tiáº¿ng anh vá» tiáº¿ng viá»‡t cho nÃ³ tá»± nhiÃªn hÆ¡n khÃ´ng áº¡ (khÃ´ng dÃ¹ng chatgpt vÃ  google)?,,,#Q&A,,
"Xin chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n,
MÃ¬nh lÃ m vá» dá»± bÃ¡o má»©c tiÃªu thá»¥ nÄƒng lÆ°á»£ng cá»§a má»™t quá»‘c gia á»Ÿ Má»¹ Latin, dá»¯ liá»‡u dáº¡ng time series Ä‘Æ°á»£c tá»•ng káº¿t cuá»‘i nÄƒm.
MÃ¬nh Ä‘á»c thÃ¬ cÃ³ má»™t sá»‘ mÃ´ hÃ¬nh dá»± bÃ¡o tá»‘t nhÆ° ARIMA vÃ  LSTM,... trong Ä‘Ã³ thÃ¬ mÃ¬nh cáº£m tháº¥y thÃ­ch ARIMA hÆ¡n vÃ¬ nÃ³ dá»… vÃ  káº¿t quáº£ cÅ©ng tá»‘t.
CÃ¡c anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u Ä‘á»ƒ Ä‘á»c vá» váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ giá»›i thiá»‡u cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡? mÃ¬nh hÆ¡i lÆ¡ mÆ¡ vá» cÃ¡ch chá»n cÃ¡c tham sá»‘ p,d,q, Ä‘áº·c biá»‡t lÃ  khi sá»‘ lÆ°á»£ng biáº¿n nhiá»u mÃ  láº¡i lÃ m viá»‡c vá»›i univariate (do mÃ¬nh cÃ²n kÃ©m kinh nghiá»‡m).
Náº¿u anh chá»‹ nÃ o cÃ³ thá»ƒ chia sáº» Ä‘Æ°á»£c vá» pháº§n nÃ y mÃ¬nh ráº¥t cáº£m Æ¡n áº¡.","Xin chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n, MÃ¬nh lÃ m vá» dá»± bÃ¡o má»©c tiÃªu thá»¥ nÄƒng lÆ°á»£ng cá»§a má»™t quá»‘c gia á»Ÿ Má»¹ Latin, dá»¯ liá»‡u dáº¡ng time series Ä‘Æ°á»£c tá»•ng káº¿t cuá»‘i nÄƒm. MÃ¬nh Ä‘á»c thÃ¬ cÃ³ má»™t sá»‘ mÃ´ hÃ¬nh dá»± bÃ¡o tá»‘t nhÆ° ARIMA vÃ  LSTM,... trong Ä‘Ã³ thÃ¬ mÃ¬nh cáº£m tháº¥y thÃ­ch ARIMA hÆ¡n vÃ¬ nÃ³ dá»… vÃ  káº¿t quáº£ cÅ©ng tá»‘t. CÃ¡c anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u Ä‘á»ƒ Ä‘á»c vá» váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ giá»›i thiá»‡u cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡? mÃ¬nh hÆ¡i lÆ¡ mÆ¡ vá» cÃ¡ch chá»n cÃ¡c tham sá»‘ p,d,q, Ä‘áº·c biá»‡t lÃ  khi sá»‘ lÆ°á»£ng biáº¿n nhiá»u mÃ  láº¡i lÃ m viá»‡c vá»›i univariate (do mÃ¬nh cÃ²n kÃ©m kinh nghiá»‡m). Náº¿u anh chá»‹ nÃ o cÃ³ thá»ƒ chia sáº» Ä‘Æ°á»£c vá» pháº§n nÃ y mÃ¬nh ráº¥t cáº£m Æ¡n áº¡.",,,"#Q&A, #deep_learning",,
"MÃ¬nh cÃ³ lÃ m má»™t game basic vá» ML vÃ  xá»­ lÃ­ áº£nh Computer Vision báº±ng python, project nÃ y chá»§ yáº¿u lÃ  demo cho há»c sinh vÃ  cÃ¡c báº¡n sinh viÃªn cá»§a mÃ¬nh. Báº¡n nÃ o thÃ­ch thÃ¬ cÃ³ thá»ƒ tham kháº£o vÃ  táº£i vá» nhÃ© ğŸ˜€","MÃ¬nh cÃ³ lÃ m má»™t game basic vá» ML vÃ  xá»­ lÃ­ áº£nh Computer Vision báº±ng python, project nÃ y chá»§ yáº¿u lÃ  demo cho há»c sinh vÃ  cÃ¡c báº¡n sinh viÃªn cá»§a mÃ¬nh. Báº¡n nÃ o thÃ­ch thÃ¬ cÃ³ thá»ƒ tham kháº£o vÃ  táº£i vá» nhÃ©",,,"#sharing, #cv",,
"Morning mn, má»i nghÄ© sao vá» viá»‡c mÃ¬nh dÃ¹ng chat gpt api,... cÃ¡c ai khÃ¡c ná»¯a Ä‘á»ƒ convert video vá» dáº¡ng text Ä‘á»ƒ láº¥y cÃ¡c keywords xong sau Ä‘Ã³ mÃ¬nh dá»±a vÃ o cÃ¡c keywords Ä‘á»ƒ match vá»›i cÃ¡c khÃ¡ch hÃ ng care vá» sáº£n pháº©m Ä‘Ã³ vÃ  dá»±a vÃ o content cá»§a video Ä‘Ã³ Ä‘á»ƒ generate cÃ¡i email marketing áº¡. nÃ y ideal Ä‘á»ƒ lÃ m automation dá»±a trÃªn cÃ¡c con AI hiá»‡n táº¡i nhÆ° chat-gpt, zapier,..","Morning mn, má»i nghÄ© sao vá» viá»‡c mÃ¬nh dÃ¹ng chat gpt api,... cÃ¡c ai khÃ¡c ná»¯a Ä‘á»ƒ convert video vá» dáº¡ng text Ä‘á»ƒ láº¥y cÃ¡c keywords xong sau Ä‘Ã³ mÃ¬nh dá»±a vÃ o cÃ¡c keywords Ä‘á»ƒ match vá»›i cÃ¡c khÃ¡ch hÃ ng care vá» sáº£n pháº©m Ä‘Ã³ vÃ  dá»±a vÃ o content cá»§a video Ä‘Ã³ Ä‘á»ƒ generate cÃ¡i email marketing áº¡. nÃ y ideal Ä‘á»ƒ lÃ m automation dá»±a trÃªn cÃ¡c con AI hiá»‡n táº¡i nhÆ° chat-gpt, zapier,..",,,#Q&A,,
"Em xin phÃ©p admin Ä‘Æ°á»£c chia sáº» tá»›i cÃ¡c thÃ nh viÃªn group mÃ¬nh cuá»™c thi vá» trÃ­ tuá»‡ nhÃ¢n táº¡o do FPT tá»• chá»©c.
CUá»˜C THI á»¨NG Dá»¤NG TRÃ TUá»† NHÃ‚N Táº O Vá»šI Tá»”NG GIÃ TRá»Š GIáº¢I THÆ¯á»NG 370 TRIá»†U Äá»’NG
FPT AI Challenge 2023 - cuá»™c thi vá» trÃ­ tuá»‡ nhÃ¢n táº¡o lá»›n nháº¥t do Táº­p Ä‘oÃ n FPT tá»• chá»©c. Vá»›i tá»•ng giáº£i thÆ°á»Ÿng 370 triá»‡u Ä‘á»“ng, cuá»™c thi tÃ¬m kiáº¿m nhá»¯ng Ã½ tÆ°á»Ÿng, sáº£n pháº©m vÃ  giáº£i phÃ¡p á»©ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o giÃºp giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n thá»±c táº¿ trong Ä‘á»i sá»‘ng. ÄÃ¢y lÃ  sÃ¢n chÆ¡i ká»¹ thuáº­t dÃ nh cho nhá»¯ng ngÆ°á»i cÃ³ niá»m Ä‘am mÃª vá»›i AI trÃªn toÃ n tháº¿ giá»›i.
Thá»i gian Ä‘Äƒng kÃ½: tá»« 12h00 ngÃ y 09.09 - 10.10.2023
CÃ¡c thÃ­ sinh tham gia cuá»™c thi theo hÃ¬nh thá»©c cÃ¡ nhÃ¢n hoáº·c nhÃ³m vá»›i tá»‘i Ä‘a 3 thÃ nh viÃªn vÃ  Ä‘Äƒng kÃ½ táº¡i trang web https://hackathon.quynhon.ai/registration.
á» VÃ²ng loáº¡i, cÃ¡c Ä‘á»™i thi sáº½ chá»n cho mÃ¬nh chá»§ Ä‘á» phÃ¹ há»£p vÃ  tiáº¿n hÃ nh xÃ¢y dá»±ng nhá»¯ng sáº£n pháº©m/giáº£i phÃ¡p giÃºp giáº£i quyáº¿t bÃ i toÃ¡n mÃ  Ban Tá»• chá»©c Ä‘Æ°a ra. 06 Ä‘á»™i thi cÃ³ Ä‘iá»ƒm sá»‘ cao nháº¥t sáº½ vÃ o VÃ²ng Chung káº¿t.
Ba chá»§ Ä‘á» cá»§a cuá»™c thi FPT AI Challenge 2023 bao gá»“m:
- AI-enable optimization for Binh Dinh province
- Leveraging large language models (LLMs) for sustainable business recommendations:
- AI techniques for computer vision applications
Táº¡i VÃ²ng Chung káº¿t, top 06 Ã½ tÆ°á»Ÿng sÃ¡ng táº¡o nháº¥t sáº½ trÃ¬nh bÃ y Ã½ tÆ°á»Ÿng vá» sáº£n pháº©m vÃ  giáº£i phÃ¡p cá»§a mÃ¬nh vá»›i Ban GiÃ¡m kháº£o qua hÃ¬nh thá»©c online. Top 03 chung cuá»™c sáº½ Ä‘Æ°á»£c tham dá»± Lá»… trao giáº£i vÃ  trÆ°ng bÃ y sáº£n pháº©m trá»±c tiáº¿p táº¡i sá»± kiá»‡n triá»ƒn lÃ£m cÃ´ng nghá»‡ FPT Tech Day 2023.
Äá»™i chiáº¿n tháº¯ng sáº½ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tiá»n máº·t vá»›i giáº£i nháº¥t trá»‹ giÃ¡ 200 triá»‡u Ä‘á»“ng, giáº£i nhÃ¬ 100 triá»‡u Ä‘á»“ng, giáº£i ba 70 triá»‡u Ä‘á»“ng, cÃ¹ng giáº¥y chá»©ng nháº­n cá»§a Ban Tá»• chá»©c. Top 3 chung cuá»™c sáº½ Ä‘Æ°á»£c tÃ i trá»£ má»™t tuáº§n du lá»‹ch táº¡i Viá»‡t Nam, tham gia giao lÆ°u vÄƒn hoÃ¡ quá»‘c táº¿ vÃ  triá»ƒn lÃ£m sáº£n pháº©m cá»§a mÃ¬nh táº¡i sá»± kiá»‡n FPT Tech Day 2023 Ä‘Æ°á»£c tá»• chá»©c vÃ o thÃ¡ng 10.2023 táº¡i HÃ  Ná»™i. NgoÃ i ra, cÃ¡c Ä‘á»™i thi sáº½ cÃ³ cÆ¡ há»™i tham gia nhá»¯ng buá»•i tham luáº­n cÃ¹ng vá»›i cÃ¡c chuyÃªn gia vÃ  ká»¹ sÆ° Ä‘áº§u ngÃ nh; nháº­n Ä‘Æ°á»£c cÆ¡ há»™i viá»‡c lÃ m vá»›i má»©c lÆ°Æ¡ng háº¥p dáº«n táº¡i cÃ´ng ty cÃ´ng nghá»‡ hÃ ng Ä‘áº§u Viá»‡t Nam.
ThÃ´ng tin chi tiáº¿t cá»§a cuá»™c thi Ä‘Æ°á»£c Ä‘Äƒng táº£i trÃªn website: https://hackathon.quynhon.ai/","Em xin phÃ©p admin Ä‘Æ°á»£c chia sáº» tá»›i cÃ¡c thÃ nh viÃªn group mÃ¬nh cuá»™c thi vá» trÃ­ tuá»‡ nhÃ¢n táº¡o do FPT tá»• chá»©c. CUá»˜C THI á»¨NG Dá»¤NG TRÃ TUá»† NHÃ‚N Táº O Vá»šI Tá»”NG GIÃ TRá»Š GIáº¢I THÆ¯á»NG 370 TRIá»†U Äá»’NG FPT AI Challenge 2023 - cuá»™c thi vá» trÃ­ tuá»‡ nhÃ¢n táº¡o lá»›n nháº¥t do Táº­p Ä‘oÃ n FPT tá»• chá»©c. Vá»›i tá»•ng giáº£i thÆ°á»Ÿng 370 triá»‡u Ä‘á»“ng, cuá»™c thi tÃ¬m kiáº¿m nhá»¯ng Ã½ tÆ°á»Ÿng, sáº£n pháº©m vÃ  giáº£i phÃ¡p á»©ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o giÃºp giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n thá»±c táº¿ trong Ä‘á»i sá»‘ng. ÄÃ¢y lÃ  sÃ¢n chÆ¡i ká»¹ thuáº­t dÃ nh cho nhá»¯ng ngÆ°á»i cÃ³ niá»m Ä‘am mÃª vá»›i AI trÃªn toÃ n tháº¿ giá»›i. Thá»i gian Ä‘Äƒng kÃ½: tá»« 12h00 ngÃ y 09.09 - 10.10.2023 CÃ¡c thÃ­ sinh tham gia cuá»™c thi theo hÃ¬nh thá»©c cÃ¡ nhÃ¢n hoáº·c nhÃ³m vá»›i tá»‘i Ä‘a 3 thÃ nh viÃªn vÃ  Ä‘Äƒng kÃ½ táº¡i trang web https://hackathon.quynhon.ai/registration. á» VÃ²ng loáº¡i, cÃ¡c Ä‘á»™i thi sáº½ chá»n cho mÃ¬nh chá»§ Ä‘á» phÃ¹ há»£p vÃ  tiáº¿n hÃ nh xÃ¢y dá»±ng nhá»¯ng sáº£n pháº©m/giáº£i phÃ¡p giÃºp giáº£i quyáº¿t bÃ i toÃ¡n mÃ  Ban Tá»• chá»©c Ä‘Æ°a ra. 06 Ä‘á»™i thi cÃ³ Ä‘iá»ƒm sá»‘ cao nháº¥t sáº½ vÃ o VÃ²ng Chung káº¿t. Ba chá»§ Ä‘á» cá»§a cuá»™c thi FPT AI Challenge 2023 bao gá»“m: - AI-enable optimization for Binh Dinh province - Leveraging large language models (LLMs) for sustainable business recommendations: - AI techniques for computer vision applications Táº¡i VÃ²ng Chung káº¿t, top 06 Ã½ tÆ°á»Ÿng sÃ¡ng táº¡o nháº¥t sáº½ trÃ¬nh bÃ y Ã½ tÆ°á»Ÿng vá» sáº£n pháº©m vÃ  giáº£i phÃ¡p cá»§a mÃ¬nh vá»›i Ban GiÃ¡m kháº£o qua hÃ¬nh thá»©c online. Top 03 chung cuá»™c sáº½ Ä‘Æ°á»£c tham dá»± Lá»… trao giáº£i vÃ  trÆ°ng bÃ y sáº£n pháº©m trá»±c tiáº¿p táº¡i sá»± kiá»‡n triá»ƒn lÃ£m cÃ´ng nghá»‡ FPT Tech Day 2023. Äá»™i chiáº¿n tháº¯ng sáº½ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tiá»n máº·t vá»›i giáº£i nháº¥t trá»‹ giÃ¡ 200 triá»‡u Ä‘á»“ng, giáº£i nhÃ¬ 100 triá»‡u Ä‘á»“ng, giáº£i ba 70 triá»‡u Ä‘á»“ng, cÃ¹ng giáº¥y chá»©ng nháº­n cá»§a Ban Tá»• chá»©c. Top 3 chung cuá»™c sáº½ Ä‘Æ°á»£c tÃ i trá»£ má»™t tuáº§n du lá»‹ch táº¡i Viá»‡t Nam, tham gia giao lÆ°u vÄƒn hoÃ¡ quá»‘c táº¿ vÃ  triá»ƒn lÃ£m sáº£n pháº©m cá»§a mÃ¬nh táº¡i sá»± kiá»‡n FPT Tech Day 2023 Ä‘Æ°á»£c tá»• chá»©c vÃ o thÃ¡ng 10.2023 táº¡i HÃ  Ná»™i. NgoÃ i ra, cÃ¡c Ä‘á»™i thi sáº½ cÃ³ cÆ¡ há»™i tham gia nhá»¯ng buá»•i tham luáº­n cÃ¹ng vá»›i cÃ¡c chuyÃªn gia vÃ  ká»¹ sÆ° Ä‘áº§u ngÃ nh; nháº­n Ä‘Æ°á»£c cÆ¡ há»™i viá»‡c lÃ m vá»›i má»©c lÆ°Æ¡ng háº¥p dáº«n táº¡i cÃ´ng ty cÃ´ng nghá»‡ hÃ ng Ä‘áº§u Viá»‡t Nam. ThÃ´ng tin chi tiáº¿t cá»§a cuá»™c thi Ä‘Æ°á»£c Ä‘Äƒng táº£i trÃªn website: https://hackathon.quynhon.ai/",,,#sharing,,
MACHINE LEARNING PAPERs EXPLAINED,MACHINE LEARNING PAPERs EXPLAINED,,,,,
"Em xin chÃ o má»i ngÆ°á»i. Em Ä‘ang thá»­ train model text recognition sá»­ dá»¥ng mÃ´ hÃ¬nh CRNN-CTC vá»›i tool tá»« PaddleOCR. Em train thá»­ 100 epochs trÃªn bá»™ dá»¯ liá»‡u ICDAR2015, vá»›i pretrained model tá»« PaddleOCR (https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar). Káº¿t quáº£ model bá»‹ overfit máº¡nh trÃªn táº­p ICDAR2015 áº¡, training accurracy tÄƒng ráº¥t nhanh (khÃºc sau tá»›i gáº§n 100%), nhÆ°ng káº¿t quáº£ test láº¡i ráº¥t tháº¥p chá»‰ 51.4% (em cÃ³ Ä‘Ã­nh kÃ¨m hÃ¬nh bÃªn dÆ°á»›i).
Em muá»‘n xin há»i lÃ m sao Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y áº¡. Em cÃ³ tÃ¬m hiá»ƒu trÃªn máº¡ng thÃ¬ cÃ³ 1 chá»— ghi lÃ  do bá»™ ICDAR2015 nÃ y Ã­t áº£nh (cá»¡ 4 ngÃ n máº¥y) nÃªn bá»‹ overfit. NgÆ°á»i ta train thÃ¬ dÃ¹ng cÃ¡c bá»™ dataset lá»›n nhÆ° SynthText (9 triá»‡u áº£nh). Tuy nhiÃªn em dÃ¹ng Google Colab nÃªn khÃ´ng Ä‘á»§ bá»™ nhá»› Ä‘á»ƒ train nhá»¯ng táº­p lá»›n nhÆ° váº­y (vá»›i táº­p ICDAR2015 mÃ  khi train bá»™ nhá»› CPU GPU colab Ä‘Ã£ gáº§n bá»‹ overflow rá»“i). KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ link vá» cÃ¡c bá»™ dataset nÃ o cÃ³ kÃ­ch thÆ°á»›c vá»«a pháº£i cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ train thá»­ nghiá»‡m trÃªn Google Colab cho bÃ i toÃ¡n scene text recognition khÃ´ng áº¡?
Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.","Em xin chÃ o má»i ngÆ°á»i. Em Ä‘ang thá»­ train model text recognition sá»­ dá»¥ng mÃ´ hÃ¬nh CRNN-CTC vá»›i tool tá»« PaddleOCR. Em train thá»­ 100 epochs trÃªn bá»™ dá»¯ liá»‡u ICDAR2015, vá»›i pretrained model tá»« PaddleOCR (https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar). Káº¿t quáº£ model bá»‹ overfit máº¡nh trÃªn táº­p ICDAR2015 áº¡, training accurracy tÄƒng ráº¥t nhanh (khÃºc sau tá»›i gáº§n 100%), nhÆ°ng káº¿t quáº£ test láº¡i ráº¥t tháº¥p chá»‰ 51.4% (em cÃ³ Ä‘Ã­nh kÃ¨m hÃ¬nh bÃªn dÆ°á»›i). Em muá»‘n xin há»i lÃ m sao Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y áº¡. Em cÃ³ tÃ¬m hiá»ƒu trÃªn máº¡ng thÃ¬ cÃ³ 1 chá»— ghi lÃ  do bá»™ ICDAR2015 nÃ y Ã­t áº£nh (cá»¡ 4 ngÃ n máº¥y) nÃªn bá»‹ overfit. NgÆ°á»i ta train thÃ¬ dÃ¹ng cÃ¡c bá»™ dataset lá»›n nhÆ° SynthText (9 triá»‡u áº£nh). Tuy nhiÃªn em dÃ¹ng Google Colab nÃªn khÃ´ng Ä‘á»§ bá»™ nhá»› Ä‘á»ƒ train nhá»¯ng táº­p lá»›n nhÆ° váº­y (vá»›i táº­p ICDAR2015 mÃ  khi train bá»™ nhá»› CPU GPU colab Ä‘Ã£ gáº§n bá»‹ overflow rá»“i). KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ link vá» cÃ¡c bá»™ dataset nÃ o cÃ³ kÃ­ch thÆ°á»›c vá»«a pháº£i cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ train thá»­ nghiá»‡m trÃªn Google Colab cho bÃ i toÃ¡n scene text recognition khÃ´ng áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.",,,"#Q&A, #data, #cv",,
"GiÃ¡o sÆ° Dunhui Deng, Bá»™ mÃ´n KHMT cá»§a Äáº¡i há»c Thanh Hoa (Tsinghua University) bÃªn TQ cÃ³ giá»›i thiá»‡u cuá»‘n sÃ¡ch vá» Algorithims viáº¿t cho cho cÃ¡c ngÃ´n ngá»¯ C+(+, Python, Go, JavaScript, TypeScript, C, C#, Swift, Zig, Rust, and Dart.
Ráº¥t tiáº¿c sÃ¡ch viáº¿t báº±ng tiáº¿ng tÃ u, tuy nhiÃªn, mÃ¬nh Ä‘Ã£ thá»­ dá»¥ng má»™t sá»‘ cÃ´ng cá»¥ dá»‹ch nhÆ° Google Translate, Bard, Claude-2 vÃ  ChatGPT-3.5 thÃ¬ tháº¥y cháº¥t lÆ°á»£ng dá»‹ch ra tiáº¿ng Anh vÃ  tiáº¿ng Viá»‡t khÃ¡ á»•n.
VÃ¬ váº­y, mÃ¬nh xin giá»›i thiá»‡u source code cá»§a cuá»‘n sÃ¡ch nÃ y táº¡i Ä‘Ã¢y https://github.com/krahets/hello-algo

VÃ  cÃ³ báº¡n Ä‘Ã£ tÃ¬m tháº¥y branch báº£n dá»‹ch tiáº¿ng Anh cá»§a cuá»‘n sÃ¡ch vÃ  source code táº¡i Ä‘Ã¢y https://github.com/yuelinxin/hello-algo-en?fbclid=IwAR310jM6QwOOYgEtgAdCVJQOdOWnKmpiEcFN0F00rhq_5dNIUN04VIP0nck
Cáº£m Æ¡n báº¡n Nghia Be 

ChÃºc cÃ¡c báº¡n cÃ³ ngÃ y cuá»‘i tuáº§n vui váº»!","GiÃ¡o sÆ° Dunhui Deng, Bá»™ mÃ´n KHMT cá»§a Äáº¡i há»c Thanh Hoa (Tsinghua University) bÃªn TQ cÃ³ giá»›i thiá»‡u cuá»‘n sÃ¡ch vá» Algorithims viáº¿t cho cho cÃ¡c ngÃ´n ngá»¯ C+(+, Python, Go, JavaScript, TypeScript, C, C#, Swift, Zig, Rust, and Dart. Ráº¥t tiáº¿c sÃ¡ch viáº¿t báº±ng tiáº¿ng tÃ u, tuy nhiÃªn, mÃ¬nh Ä‘Ã£ thá»­ dá»¥ng má»™t sá»‘ cÃ´ng cá»¥ dá»‹ch nhÆ° Google Translate, Bard, Claude-2 vÃ  ChatGPT-3.5 thÃ¬ tháº¥y cháº¥t lÆ°á»£ng dá»‹ch ra tiáº¿ng Anh vÃ  tiáº¿ng Viá»‡t khÃ¡ á»•n. VÃ¬ váº­y, mÃ¬nh xin giá»›i thiá»‡u source code cá»§a cuá»‘n sÃ¡ch nÃ y táº¡i Ä‘Ã¢y https://github.com/krahets/hello-algo VÃ  cÃ³ báº¡n Ä‘Ã£ tÃ¬m tháº¥y branch báº£n dá»‹ch tiáº¿ng Anh cá»§a cuá»‘n sÃ¡ch vÃ  source code táº¡i Ä‘Ã¢y https://github.com/yuelinxin/hello-algo-en?fbclid=IwAR310jM6QwOOYgEtgAdCVJQOdOWnKmpiEcFN0F00rhq_5dNIUN04VIP0nck Cáº£m Æ¡n báº¡n Nghia Be ChÃºc cÃ¡c báº¡n cÃ³ ngÃ y cuá»‘i tuáº§n vui váº»!",,,#sharing,,
"ChÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu má»™t sá»‘ bÃ i toÃ¡n vá» speech. Em tÃ¬m hiá»ƒu vÃ  cÃ³ biáº¿t bá»™ dataset vá» giá»›i tÃ­nh vÃ  vÃ¹ng miá»n Voice Gender cá»§a Zalo AI Challenger 2018. Em Ä‘Ã£ cá»‘ gáº¯ng tÃ¬m cÃ¡c nguá»“n public trÃªn máº¡ng nhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c dá»¯ liá»‡u nÃ y. Trang chá»§ cuá»™c thi hiá»‡n nay lÃ  nÄƒm 2022 vÃ  khÃ´ng xem láº¡i Ä‘Æ°á»£c dá»¯ liá»‡u nÄƒm trÆ°á»›c.
Má»i ngÆ°á»i trong nhÃ³m ai cÃ²n lÆ°u trá»¯ bá»™ dataset nÃ y cho em xin vá»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i.","ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu má»™t sá»‘ bÃ i toÃ¡n vá» speech. Em tÃ¬m hiá»ƒu vÃ  cÃ³ biáº¿t bá»™ dataset vá» giá»›i tÃ­nh vÃ  vÃ¹ng miá»n Voice Gender cá»§a Zalo AI Challenger 2018. Em Ä‘Ã£ cá»‘ gáº¯ng tÃ¬m cÃ¡c nguá»“n public trÃªn máº¡ng nhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c dá»¯ liá»‡u nÃ y. Trang chá»§ cuá»™c thi hiá»‡n nay lÃ  nÄƒm 2022 vÃ  khÃ´ng xem láº¡i Ä‘Æ°á»£c dá»¯ liá»‡u nÄƒm trÆ°á»›c. Má»i ngÆ°á»i trong nhÃ³m ai cÃ²n lÆ°u trá»¯ bá»™ dataset nÃ y cho em xin vá»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i.",,,"#Q&A, #data",,
"ğŸ‡»ğŸ‡³ Cá»™ng Ä‘á»“ng LLMs Viá»‡t Nam!

Hiá»‡n táº¡i, mÃ¬nh Ä‘ang xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ thuáº§n Viá»‡t (#Vietnamese_LLM). Dá»± Ã¡n cá»§a mÃ¬nh dá»±a trÃªn sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯  dá»±a trÃªn Open-source LLM nhÆ° #BLOOMZ, #Open_LlaMA, vÃ  nhiá»u mÃ´ hÃ¬nh #khÃ¡c.
ThÃ´ng tin sÆ¡ lÆ°á»£c vá» dá»± Ã¡n trÃ¬nh bÃ y trong file Ä‘Ã­nh kÃ¨m:
#Káº¿ hoáº¡ch cá»§a mÃ¬nh bao gá»“m viá»‡c phÃ¡t triá»ƒn: #1. Táº¡o bá»™ dá»¯ liá»‡u Vietnamese (self-instruct dataset) vÃ  #2. Finetuning  vÃ  Training cÃ¡c Open-source LLMs trÃªn bá»™ dá»¯ liá»‡u tiáº¿ng Viá»‡t.
#1. PhÃ¡t triá»ƒn bá»™ dá»¯ liá»‡u tiáº¿ngViá»‡t (Self-Instruct Vietnamse):
+ Dá»±a trÃªn cÃ¡c bá»™ dá»¯ liá»‡u tiáº¿ng Anh hiá»‡n cÃ³ nhÆ° #Alpaca, #Dolly, #OpenAssistant, #ShareGPT vÃ  cÃ¡c nhiá»u bá»™ dá»¯ liá»‡u khÃ¡c. MÃ¬nh Ä‘ang sá»­ dá»¥ng API Azure OpenAI: GPT3, GPT 3.5 vÃ  GPT-4 Ä‘á»ƒ dá»‹ch cÃ¡c bá»™ dá»¯ liá»‡u nÃ y sang tiáº¿ng Viá»‡t.
+ Táº¡o thÃªm 100.000 (cÃ³ thá»ƒ nhiá»u hÆ¡n) cÃ¢u hÆ°á»›ng dáº«n tá»± há»c giá»‘ng nhÆ° dá»± Ã¡n Alpaca hoáº·c cÃ¡c mÃ´ hÃ¬nh táº¡o dá»¯ liá»‡u khÃ¡c.
+ TÃ¬m hiá»ƒu thÃªm vá» cÃ¡c nguá»“n dá»¯ liá»‡u tiáº¿ng Viá»‡t khÃ¡c táº­p trung cho cÃ¡c lÄ©nh vá»±c khÃ¡c nhau. nhÆ° bÃ¡o chÃ­, Ä‘iá»‡n áº£nh, y há»c... (Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n gÃ³p Ã½ tá»« má»i ngÆ°á»i).
#2. Äá»ƒ huáº¥n luyá»‡n (#Finetuning & Traning ) cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ LLM, mÃ¬nh sáº½ sá»­ dá»¥ng ká»¹ thuáº­t #LoRA vÃ  #QLoRA trÃªn mÃ¡y chá»§ Azure server cÃ³ 8 GPUs Nvidia #A100 80GB. Äiá»u nÃ y sáº½ giÃºp mÃ¬nh Finetune vÃ  Train cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ (LLM) tá»« 7B tá»· Ä‘áº¿n 65B tá»· hoáº·c nhiá»u hÆ¡n.
MÃ¬nh ráº¥t mong sá»± káº¿t ná»‘i vá»›i cÃ¡c báº¡n cÃ³ mong muá»‘n thá»±c hiá»‡n dá»± Ã¡n nÃ y vÃ  hoan nghÃªnh sá»± Ä‘Ã³ng gÃ³p tá»« cá»™ng Ä‘á»“ng.
Náº¿u báº¡n cÃ³ sá»± gÃ³p Ã½ vá» dá»¯ liá»‡u hoáº·c , xin vui lÃ²ng chia sáº».
CÃ¹ng nhau, chÃºng ta cÃ³ thá»ƒ phÃ¡t triá»ƒn mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiáº¿ng Viá»‡t cháº¥t lÆ°á»£ng cao. Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± quan tÃ¢m vÃ  há»— trá»£ cá»§a má»i ngÆ°á»i!
Form Ä‘Äƒng kÃ½ tham gia: https://docs.google.com/forms/d/e/1FAIpQLSfoc4tnV6R0RJvVPmsH4cyfgnkKdUkASgYFA-sTuL1hfDE9sA/viewform?usp=pp_url

MÃ¬nh lÃ  Nhiá»‡m, má»™t nghiÃªn cá»©u sinh tiáº¿n sÄ© Ä‘ang cÃ´ng tÃ¡c táº¡i National Central University, Researcher Foxconn AI, Taiwan.
Tráº§n Nhiá»‡m. Email. tvnhiemhmus@g.ncu.edu.tw
zalo: +886 934 311 751.
linkedIn: https://www.linkedin.com/in/tran-nhiem-ab1851125/
#VietnameseLLMs
File Ä‘Ã­nh kÃ¨m:
https://drive.google.com/file/d/182T0ExiJFKfIUvK1Vm3WQqeju8kw9J6J/view?usp=sharing ","Cá»™ng Ä‘á»“ng LLMs Viá»‡t Nam! Hiá»‡n táº¡i, mÃ¬nh Ä‘ang xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ thuáº§n Viá»‡t (#Vietnamese_LLM). Dá»± Ã¡n cá»§a mÃ¬nh dá»±a trÃªn sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn Open-source LLM nhÆ° vÃ  nhiá»u mÃ´ hÃ¬nh ThÃ´ng tin sÆ¡ lÆ°á»£c vá» dá»± Ã¡n trÃ¬nh bÃ y trong file Ä‘Ã­nh kÃ¨m: hoáº¡ch cá»§a mÃ¬nh bao gá»“m viá»‡c phÃ¡t triá»ƒn: Táº¡o bá»™ dá»¯ liá»‡u Vietnamese (self-instruct dataset) vÃ  Finetuning vÃ  Training cÃ¡c Open-source LLMs trÃªn bá»™ dá»¯ liá»‡u tiáº¿ng Viá»‡t. PhÃ¡t triá»ƒn bá»™ dá»¯ liá»‡u tiáº¿ngViá»‡t (Self-Instruct Vietnamse): + Dá»±a trÃªn cÃ¡c bá»™ dá»¯ liá»‡u tiáº¿ng Anh hiá»‡n cÃ³ nhÆ° vÃ  cÃ¡c nhiá»u bá»™ dá»¯ liá»‡u khÃ¡c. MÃ¬nh Ä‘ang sá»­ dá»¥ng API Azure OpenAI: GPT3, GPT 3.5 vÃ  GPT-4 Ä‘á»ƒ dá»‹ch cÃ¡c bá»™ dá»¯ liá»‡u nÃ y sang tiáº¿ng Viá»‡t. + Táº¡o thÃªm 100.000 (cÃ³ thá»ƒ nhiá»u hÆ¡n) cÃ¢u hÆ°á»›ng dáº«n tá»± há»c giá»‘ng nhÆ° dá»± Ã¡n Alpaca hoáº·c cÃ¡c mÃ´ hÃ¬nh táº¡o dá»¯ liá»‡u khÃ¡c. + TÃ¬m hiá»ƒu thÃªm vá» cÃ¡c nguá»“n dá»¯ liá»‡u tiáº¿ng Viá»‡t khÃ¡c táº­p trung cho cÃ¡c lÄ©nh vá»±c khÃ¡c nhau. nhÆ° bÃ¡o chÃ­, Ä‘iá»‡n áº£nh, y há»c... (Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n gÃ³p Ã½ tá»« má»i ngÆ°á»i). Äá»ƒ huáº¥n luyá»‡n (#Finetuning & Traning ) cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ LLM, mÃ¬nh sáº½ sá»­ dá»¥ng ká»¹ thuáº­t vÃ  trÃªn mÃ¡y chá»§ Azure server cÃ³ 8 GPUs Nvidia 80GB. Äiá»u nÃ y sáº½ giÃºp mÃ¬nh Finetune vÃ  Train cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ (LLM) tá»« 7B tá»· Ä‘áº¿n 65B tá»· hoáº·c nhiá»u hÆ¡n. MÃ¬nh ráº¥t mong sá»± káº¿t ná»‘i vá»›i cÃ¡c báº¡n cÃ³ mong muá»‘n thá»±c hiá»‡n dá»± Ã¡n nÃ y vÃ  hoan nghÃªnh sá»± Ä‘Ã³ng gÃ³p tá»« cá»™ng Ä‘á»“ng. Náº¿u báº¡n cÃ³ sá»± gÃ³p Ã½ vá» dá»¯ liá»‡u hoáº·c , xin vui lÃ²ng chia sáº». CÃ¹ng nhau, chÃºng ta cÃ³ thá»ƒ phÃ¡t triá»ƒn mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiáº¿ng Viá»‡t cháº¥t lÆ°á»£ng cao. Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± quan tÃ¢m vÃ  há»— trá»£ cá»§a má»i ngÆ°á»i! Form Ä‘Äƒng kÃ½ tham gia: https://docs.google.com/forms/d/e/1FAIpQLSfoc4tnV6R0RJvVPmsH4cyfgnkKdUkASgYFA-sTuL1hfDE9sA/viewform?usp=pp_url MÃ¬nh lÃ  Nhiá»‡m, má»™t nghiÃªn cá»©u sinh tiáº¿n sÄ© Ä‘ang cÃ´ng tÃ¡c táº¡i National Central University, Researcher Foxconn AI, Taiwan. Tráº§n Nhiá»‡m. Email. tvnhiemhmus@g.ncu.edu.tw zalo: +886 934 311 751. linkedIn: https://www.linkedin.com/in/tran-nhiem-ab1851125/ File Ä‘Ã­nh kÃ¨m: https://drive.google.com/file/d/182T0ExiJFKfIUvK1Vm3WQqeju8kw9J6J/view?usp=sharing","#BLOOMZ,	#Open_LlaMA,	#khÃ¡c.	#Káº¿	#1.	#2.	#1.	#Alpaca,	#Dolly,	#OpenAssistant,	#ShareGPT	#2.	#LoRA	#QLoRA	#A100	#VietnameseLLMs",,"#Q&A, #nlp, #data",,
"ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i, mÃ¬nh Ä‘ang tiáº¿n hÃ nh Ä‘iá»u chá»‰nh (fine-tuning) mÃ´ hÃ¬nh BartPho-word-base Ä‘á»ƒ thá»±c hiá»‡n tÃ¡c vá»¥ tÃ³m táº¯t vÄƒn báº£n. Tuy nhiÃªn, khi mÃ¬nh dá»± Ä‘oÃ¡n káº¿t quáº£, láº¡i gáº·p pháº£i tÃ¬nh tráº¡ng káº¿t quáº£ dá»± Ä‘oÃ¡n chá»©a nhá»¯ng kÃ½ tá»± khÃ´ng xÃ¡c Ä‘á»‹nh (<unk>). Sau khi tÃ¬m hiá»ƒu, nháº­n ra ráº±ng nguyÃªn nhÃ¢n cÃ³ thá»ƒ lÃ  do dá»¯ liá»‡u huáº¥n luyá»‡n chá»©a nhiá»…u hoáº·c tá»« vá»±ng cá»§a mÃ´ hÃ¬nh BartPho chÆ°a Ä‘á»§ phong phÃº Ä‘á»ƒ xá»­ lÃ½ tá»‘t tÃ¬nh huá»‘ng nÃ y.
MÃ¬nh Ä‘Ã£ thá»­ nhiá»u cÃ¡ch nhÆ°ng chÆ°a xá»­ lÃ­ Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y, vÃ¬ tháº¿ mÃ¬nh lÃªn Ä‘Ã¢y tÃ¬m kiáº¿m gá»£i Ã½ vÃ  kinh nghiá»‡m tá»« má»i ngÆ°á»i. Hi vá»ng má»i ngÆ°á»i giÃºp Ä‘á»¡.","ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i, mÃ¬nh Ä‘ang tiáº¿n hÃ nh Ä‘iá»u chá»‰nh (fine-tuning) mÃ´ hÃ¬nh BartPho-word-base Ä‘á»ƒ thá»±c hiá»‡n tÃ¡c vá»¥ tÃ³m táº¯t vÄƒn báº£n. Tuy nhiÃªn, khi mÃ¬nh dá»± Ä‘oÃ¡n káº¿t quáº£, láº¡i gáº·p pháº£i tÃ¬nh tráº¡ng káº¿t quáº£ dá»± Ä‘oÃ¡n chá»©a nhá»¯ng kÃ½ tá»± khÃ´ng xÃ¡c Ä‘á»‹nh (<unk>). Sau khi tÃ¬m hiá»ƒu, nháº­n ra ráº±ng nguyÃªn nhÃ¢n cÃ³ thá»ƒ lÃ  do dá»¯ liá»‡u huáº¥n luyá»‡n chá»©a nhiá»…u hoáº·c tá»« vá»±ng cá»§a mÃ´ hÃ¬nh BartPho chÆ°a Ä‘á»§ phong phÃº Ä‘á»ƒ xá»­ lÃ½ tá»‘t tÃ¬nh huá»‘ng nÃ y. MÃ¬nh Ä‘Ã£ thá»­ nhiá»u cÃ¡ch nhÆ°ng chÆ°a xá»­ lÃ­ Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y, vÃ¬ tháº¿ mÃ¬nh lÃªn Ä‘Ã¢y tÃ¬m kiáº¿m gá»£i Ã½ vÃ  kinh nghiá»‡m tá»« má»i ngÆ°á»i. Hi vá»ng má»i ngÆ°á»i giÃºp Ä‘á»¡.",,,"#Q&A, #deep_learing, #nlp",,
"Closed.
Cáº£m Æ¡n cáº£ nhÃ  Ä‘Ã£ Ä‘Æ°a ra nhiá»u gá»£i Ã½ giÃºp mÃ¬nh hiá»ƒu váº¥n Ä‘á» hÆ¡n vÃ  Ä‘Ã£ giáº£i quyáº¿t xong case nÃ y. 
PhÆ°Æ¡ng Ã¡n giáº£i quyáº¿t lÃ  chá»‰ Ä‘Æ°a vÃ o hÃ m map vá»›i tf.numpy_function thao tÃ¡c Ä‘á»c tÃªn áº£nh Ä‘á»ƒ map sang feature. CÃ²n viá»‡c map caps thÃ nh vector sáº½ dÃ¹ng hÃ m map khÃ¡c vá»›i auto graph. LÃ½ do lÃ  map vá»›i numpy_function ráº¥t khÃ³ control vÃ  thÆ°á»ng hay máº¥t shape nÃªn gÃ¢y lá»—i Ä‘áº§u vÃ o vá»›i TextVectorization (hoáº·c cÃ³ thá»ƒ layer nÃ o khÃ¡c cÅ©ng sáº½ bá»‹ lá»—i tÆ°Æ¡ng tá»±).
-----------------------------------------------------
ChÃ o cáº£ nhÃ . MÃ¬nh cÃ³ 1 project CV dÃ¹ng Tensorflow. Tuy nhiÃªn Ä‘ang bá»‹ máº¯c káº¹t trong viá»‡c táº¡o TF dataset nhÆ° sau:
MÃ¬nh táº¡o tf dataset: tÃªn áº£nh, caps
map báº±ng tf.numpy_function Ä‘á»ƒ cÃ³ dataset: feature, caps.
=> cho vÃ o train.
Náº¿u cháº¡y GPU Colab vá»›i num_parallel_calls trong khi map feature thÃ¬ sáº½ lá»—i runtime á»Ÿ 1 chá»— nÃ o Ä‘Ã³ khi train mÃ´ hÃ¬nh. Vá»›i 1 táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh, má»—i láº§n cháº¡y cÃ³ thá»ƒ lá»—i á»Ÿ cÃ¡c áº£nh khÃ¡c nhau. Náº¿u thá»­ vá»›i 1 táº­p dá»¯ liá»‡u nhá» thÃ¬ cÃ³ thá»ƒ may máº¯n cháº¡y Ä‘Æ°á»£c 1 vÃ i epoch má»›i lá»—i (tháº­m chÃ­ cÃ³ láº§n cháº¡y Ä‘Æ°á»£c háº¿t táº¥t cáº£ cÃ¡c epoch).
Tuy nhiÃªn náº¿u cháº¡y CPU hoáº·c cháº¡y GPU mÃ  khÃ´ng dÃ¹ng num_parallel_calls thÃ¬ khÃ´ng lá»—i, cháº¡y bÃ¬nh thÆ°á»ng.
Chi tiáº¿t mÃ¬nh Ä‘Äƒng trÃªn Stackoverflow mÃ  chÆ°a cÃ³ ai tráº£ lá»i.
https://stackoverflow.com/questions/77007077/runtime-error-when-use-dataset-map-with-tf-numpy-function-and-num-parallel-cal
CÃ¡c cao nhÃ¢n Ä‘i qua xin vui lÃ²ng chá»‰ giÃ¡o. 
Cáº£m Æ¡n ráº¥t nhiá»u.","Closed. Cáº£m Æ¡n cáº£ nhÃ  Ä‘Ã£ Ä‘Æ°a ra nhiá»u gá»£i Ã½ giÃºp mÃ¬nh hiá»ƒu váº¥n Ä‘á» hÆ¡n vÃ  Ä‘Ã£ giáº£i quyáº¿t xong case nÃ y. PhÆ°Æ¡ng Ã¡n giáº£i quyáº¿t lÃ  chá»‰ Ä‘Æ°a vÃ o hÃ m map vá»›i tf.numpy_function thao tÃ¡c Ä‘á»c tÃªn áº£nh Ä‘á»ƒ map sang feature. CÃ²n viá»‡c map caps thÃ nh vector sáº½ dÃ¹ng hÃ m map khÃ¡c vá»›i auto graph. LÃ½ do lÃ  map vá»›i numpy_function ráº¥t khÃ³ control vÃ  thÆ°á»ng hay máº¥t shape nÃªn gÃ¢y lá»—i Ä‘áº§u vÃ o vá»›i TextVectorization (hoáº·c cÃ³ thá»ƒ layer nÃ o khÃ¡c cÅ©ng sáº½ bá»‹ lá»—i tÆ°Æ¡ng tá»±). ----------------------------------------------------- ChÃ o cáº£ nhÃ . MÃ¬nh cÃ³ 1 project CV dÃ¹ng Tensorflow. Tuy nhiÃªn Ä‘ang bá»‹ máº¯c káº¹t trong viá»‡c táº¡o TF dataset nhÆ° sau: MÃ¬nh táº¡o tf dataset: tÃªn áº£nh, caps map báº±ng tf.numpy_function Ä‘á»ƒ cÃ³ dataset: feature, caps. => cho vÃ o train. Náº¿u cháº¡y GPU Colab vá»›i num_parallel_calls trong khi map feature thÃ¬ sáº½ lá»—i runtime á»Ÿ 1 chá»— nÃ o Ä‘Ã³ khi train mÃ´ hÃ¬nh. Vá»›i 1 táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh, má»—i láº§n cháº¡y cÃ³ thá»ƒ lá»—i á»Ÿ cÃ¡c áº£nh khÃ¡c nhau. Náº¿u thá»­ vá»›i 1 táº­p dá»¯ liá»‡u nhá» thÃ¬ cÃ³ thá»ƒ may máº¯n cháº¡y Ä‘Æ°á»£c 1 vÃ i epoch má»›i lá»—i (tháº­m chÃ­ cÃ³ láº§n cháº¡y Ä‘Æ°á»£c háº¿t táº¥t cáº£ cÃ¡c epoch). Tuy nhiÃªn náº¿u cháº¡y CPU hoáº·c cháº¡y GPU mÃ  khÃ´ng dÃ¹ng num_parallel_calls thÃ¬ khÃ´ng lá»—i, cháº¡y bÃ¬nh thÆ°á»ng. Chi tiáº¿t mÃ¬nh Ä‘Äƒng trÃªn Stackoverflow mÃ  chÆ°a cÃ³ ai tráº£ lá»i. https://stackoverflow.com/questions/77007077/runtime-error-when-use-dataset-map-with-tf-numpy-function-and-num-parallel-cal CÃ¡c cao nhÃ¢n Ä‘i qua xin vui lÃ²ng chá»‰ giÃ¡o. Cáº£m Æ¡n ráº¥t nhiá»u.",,,"#Q&A, #python",,
"VinAI Seminar - ""Rumour and Disinformation Detection in Online Conversations""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Jey Han Lau, University of Melbourne
Time: 10:00 am - 11:00 am (GMT+7), Sep 14, 2023","VinAI Seminar - ""Rumour and Disinformation Detection in Online Conversations"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Jey Han Lau, University of Melbourne Time: 10:00 am - 11:00 am (GMT+7), Sep 14, 2023",,,,,
Tool Amazon Machine Learning: Developer Guide,Tool Amazon Machine Learning: Developer Guide,,,,,
"MÃ¬nh Ä‘ang cáº§n tÃ¬m cuá»‘n sÃ¡ch nÃ y. Ensemble Learning Algorithms With Python: Make Better Predictions with Bagging, Boosting and Stacking cá»§a tÃ¡c giáº£ Jason Brownlee. Link https://machinelearningmastery.com/ensemble-learning.../ Báº¡n nÃ o cÃ³ cho mÃ¬nh xin vá»›i. Cáº£m Æ¡n nhiá»u nhÃ©","MÃ¬nh Ä‘ang cáº§n tÃ¬m cuá»‘n sÃ¡ch nÃ y. Ensemble Learning Algorithms With Python: Make Better Predictions with Bagging, Boosting and Stacking cá»§a tÃ¡c giáº£ Jason Brownlee. Link https://machinelearningmastery.com/ensemble-learning.../ Báº¡n nÃ o cÃ³ cho mÃ¬nh xin vá»›i. Cáº£m Æ¡n nhiá»u nhÃ©",,,#Q&A,,
"Xin chÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ Ã½ Ä‘á»‹nh lÃ m má»™t prj NLP nho nhá» Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ CV, trong Ä‘Ã³ Ã½ tÆ°á»Ÿng chÃ­nh cá»§a em lÃ  ngÆ°á»i dÃ¹ng nháº­p vÃ o má»™t Ä‘oáº¡n miÃªu táº£ CV cá»§a há» (gá»“m nghá» nghiá»‡p, kinh nghiá»‡m lÃ m viá»‡c, ká»¹ nÄƒng,...) vÃ  bÃªn tuyá»ƒn dá»¥ng nháº­p vÃ o JD rá»“i so sÃ¡nh Ä‘á»™ matching giá»¯a 2 yáº¿u tá»‘ Ä‘áº¥y. Tuy nhiÃªn em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ ngay bÆ°á»›c Ä‘áº§u tiÃªn khi cáº§n biá»ƒu diá»…n Ä‘oáº¡n vÄƒn báº£n input thÃ nh cÃ¡c vector cÃ³ cÃ¹ng Ä‘á»™ dÃ i Ä‘á»ƒ tiá»‡n Ä‘á»‘i chiáº¿u. E cáº£m tháº¥y thuáº­t word2vec bÃ¬nh thÆ°á»ng khÃ´ng hiá»‡u quáº£ vá»›i dá»¯ liá»‡u bÃ©, vÃ­ dá»¥ nÃ³ sáº½ khÃ´ng thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c ""TÃ´i lÃ  fresher IT"" vÃ  ""TÃ´i lÃ  senior IT"" vÃ¬ cÃ³ cÃ¹ng context
Má»i ngÆ°á»i cho em gá»£i Ã½ Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y vá»›i áº¡, liá»‡u cÃ³ cÃ¡ch word embedding nÃ o khÃ¡c khÃ´ng áº¡? VÃ  e nÃªn dÃ¹ng thuáº­t gÃ¬ Ä‘á»ƒ Ä‘o Ä‘á»™ matching giá»¯a CV vÃ  JD áº¡?","Xin chÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ Ã½ Ä‘á»‹nh lÃ m má»™t prj NLP nho nhá» Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ CV, trong Ä‘Ã³ Ã½ tÆ°á»Ÿng chÃ­nh cá»§a em lÃ  ngÆ°á»i dÃ¹ng nháº­p vÃ o má»™t Ä‘oáº¡n miÃªu táº£ CV cá»§a há» (gá»“m nghá» nghiá»‡p, kinh nghiá»‡m lÃ m viá»‡c, ká»¹ nÄƒng,...) vÃ  bÃªn tuyá»ƒn dá»¥ng nháº­p vÃ o JD rá»“i so sÃ¡nh Ä‘á»™ matching giá»¯a 2 yáº¿u tá»‘ Ä‘áº¥y. Tuy nhiÃªn em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ ngay bÆ°á»›c Ä‘áº§u tiÃªn khi cáº§n biá»ƒu diá»…n Ä‘oáº¡n vÄƒn báº£n input thÃ nh cÃ¡c vector cÃ³ cÃ¹ng Ä‘á»™ dÃ i Ä‘á»ƒ tiá»‡n Ä‘á»‘i chiáº¿u. E cáº£m tháº¥y thuáº­t word2vec bÃ¬nh thÆ°á»ng khÃ´ng hiá»‡u quáº£ vá»›i dá»¯ liá»‡u bÃ©, vÃ­ dá»¥ nÃ³ sáº½ khÃ´ng thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c ""TÃ´i lÃ  fresher IT"" vÃ  ""TÃ´i lÃ  senior IT"" vÃ¬ cÃ³ cÃ¹ng context Má»i ngÆ°á»i cho em gá»£i Ã½ Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y vá»›i áº¡, liá»‡u cÃ³ cÃ¡ch word embedding nÃ o khÃ¡c khÃ´ng áº¡? VÃ  e nÃªn dÃ¹ng thuáº­t gÃ¬ Ä‘á»ƒ Ä‘o Ä‘á»™ matching giá»¯a CV vÃ  JD áº¡?",,,"#Q&A, #nlp",,
"Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang eval cho model cá»§a mÃ¬nh trÃªn coco2015 test dev Ä‘á»ƒ tiá»‡n so sÃ¡nh vá»›i cÃ¡c paper khÃ¡c, cÆ¡ mÃ  sever submit Ä‘Ã£ bá»‹ disable vÃ  trÃªn web má»›i cá»§a codalab thÃ¬ hÃ¬nh nhÆ° khÃ´ng cÃ²n support submit cho coco ná»¯a thÃ¬ pháº£i, annotations thÃ¬ há» cÅ©ng khÃ´ng cÃ´ng bá»‘ vÃ  em tÃ¬m kháº¯p nÆ¡i trÃªn internet cÅ©ng khÃ´ng tháº¥y cÃ³ leak. CÃ²n cÃ¡ch nÃ o Ä‘á»ƒ eval trÃªn dataset nÃ y khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡.","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang eval cho model cá»§a mÃ¬nh trÃªn coco2015 test dev Ä‘á»ƒ tiá»‡n so sÃ¡nh vá»›i cÃ¡c paper khÃ¡c, cÆ¡ mÃ  sever submit Ä‘Ã£ bá»‹ disable vÃ  trÃªn web má»›i cá»§a codalab thÃ¬ hÃ¬nh nhÆ° khÃ´ng cÃ²n support submit cho coco ná»¯a thÃ¬ pháº£i, annotations thÃ¬ há» cÅ©ng khÃ´ng cÃ´ng bá»‘ vÃ  em tÃ¬m kháº¯p nÆ¡i trÃªn internet cÅ©ng khÃ´ng tháº¥y cÃ³ leak. CÃ²n cÃ¡ch nÃ o Ä‘á»ƒ eval trÃªn dataset nÃ y khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡.",,,"#Q&A, #data",,
"ChÃ o cÃ¡c bÃ¡c, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» Sentiment Analysis. CÃ¡c bÃ¡c Ä‘i trÆ°á»›c cÃ³ tÃ i liá»‡u hay nguá»“n há»c nÃ o hay cho em xin vá»›i áº¡!
Em cÃ¡m má»i ngÆ°á»i nhiá»u!","ChÃ o cÃ¡c bÃ¡c, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» Sentiment Analysis. CÃ¡c bÃ¡c Ä‘i trÆ°á»›c cÃ³ tÃ i liá»‡u hay nguá»“n há»c nÃ o hay cho em xin vá»›i áº¡! Em cÃ¡m má»i ngÆ°á»i nhiá»u!",,,"#Q&A, #nlp",,
BÃ i bÃ¡o má»›i Ä‘áº¿n tá»« Google cÃ³ tÃªn: TSMixer: An all-MLP architecture for time series forecasting (https://arxiv.org/pdf/2303.06053),BÃ i bÃ¡o má»›i Ä‘áº¿n tá»« Google cÃ³ tÃªn: TSMixer: An all-MLP architecture for time series forecasting (https://arxiv.org/pdf/2303.06053),,,#sharing,,
"Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang cáº§n deploy chatbot lÃªn facebook message nhÆ°ng cáº§n xÃ¡c minh doanh nghiá»‡p cho quyá»n pages_messing. Má»i ngÆ°á»i cÃ³ ai Ä‘ang lÃ m hay quan tÃ¢m váº¥n Ä‘á» nÃ y cho em xin Ã½ kiáº¿n tham kháº£o vá»›i áº¡. Em dÃ¹ng tÃ i khoáº£n Ä‘Ã£ xÃ¡c minh doanh nghiá»‡p nhÆ°ng váº«n khÃ´ng xin Ä‘Æ°á»£c quyá»n tá»« facebook.","Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang cáº§n deploy chatbot lÃªn facebook message nhÆ°ng cáº§n xÃ¡c minh doanh nghiá»‡p cho quyá»n pages_messing. Má»i ngÆ°á»i cÃ³ ai Ä‘ang lÃ m hay quan tÃ¢m váº¥n Ä‘á» nÃ y cho em xin Ã½ kiáº¿n tham kháº£o vá»›i áº¡. Em dÃ¹ng tÃ i khoáº£n Ä‘Ã£ xÃ¡c minh doanh nghiá»‡p nhÆ°ng váº«n khÃ´ng xin Ä‘Æ°á»£c quyá»n tá»« facebook.",,,#Q&A,,
"Em má»›i há»c vá» AI Ä‘ang muá»‘n train model phÃ¢n loáº¡i ná»™i dung video theo má»©c Ä‘á»™ phÃ¹ há»£p cá»§a tá»«ng lá»©a tuá»•i, ai cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ cÃ³ thá»ƒ sp em Ä‘c khÃ´ng áº¡ :V","Em má»›i há»c vá» AI Ä‘ang muá»‘n train model phÃ¢n loáº¡i ná»™i dung video theo má»©c Ä‘á»™ phÃ¹ há»£p cá»§a tá»«ng lá»©a tuá»•i, ai cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ cÃ³ thá»ƒ sp em Ä‘c khÃ´ng áº¡ :V",,,"#Q&A, #cv",,
"Explain Paper - The Fastest Way to Read Research Papers
Explain Paper lÃ  má»™t cÃ´ng cá»¥ giÃºp quÃ¡ trÃ¬nh Ä‘á»c paper trá»Ÿ nÃªn Ä‘Æ¡n giáº£n hÆ¡n. CÃ´ng cá»¥ nÃ y ráº¥t há»¯u Ã­ch vá»›i cÃ¡c báº¡n má»›i báº¯t Ä‘áº§u Ä‘á»c paper.
CÃ¡c báº¡n chá»‰ cáº§n táº£i paper lÃªn, highlight text mÃ  báº¡n khÃ´ng hiá»ƒu. Sau Ä‘Ã³, AI sáº½ giÃºp báº¡n giáº£i thÃ­ch pháº§n highlight Ä‘Ã³. BÃªn cáº¡nh cÃ¡c thuáº­t ngá»¯, AI cÅ©ng cÃ³ thá»ƒ giáº£i thÃ­ch cáº£ má»™t Ä‘oáº¡n text.
Website: https://www.explainpaper.com/","Explain Paper - The Fastest Way to Read Research Papers Explain Paper lÃ  má»™t cÃ´ng cá»¥ giÃºp quÃ¡ trÃ¬nh Ä‘á»c paper trá»Ÿ nÃªn Ä‘Æ¡n giáº£n hÆ¡n. CÃ´ng cá»¥ nÃ y ráº¥t há»¯u Ã­ch vá»›i cÃ¡c báº¡n má»›i báº¯t Ä‘áº§u Ä‘á»c paper. CÃ¡c báº¡n chá»‰ cáº§n táº£i paper lÃªn, highlight text mÃ  báº¡n khÃ´ng hiá»ƒu. Sau Ä‘Ã³, AI sáº½ giÃºp báº¡n giáº£i thÃ­ch pháº§n highlight Ä‘Ã³. BÃªn cáº¡nh cÃ¡c thuáº­t ngá»¯, AI cÅ©ng cÃ³ thá»ƒ giáº£i thÃ­ch cáº£ má»™t Ä‘oáº¡n text. Website: https://www.explainpaper.com/",,,#sharing,,
"Cháº¯c má»i ngÆ°á»i biáº¿t tá»›i á»©ng dá»¥ng Code Interpreter cá»§a OpenAI vÃ  Code LLaMA cá»§a Meta, nay mÃ¬nh tháº¥y cÃ³ ngÆ°á»i viáº¿t API cÃ³ thá»ƒ káº¿t ná»‘i cáº£ 2 backends nÃ y Ä‘á»ƒ cháº¡y trong terminal, cÃ³ tÃªn lÃ  Open Interpreter. Náº¿u vá»›i Code Interpreter thÃ¬ sáº½ cháº¡y inference online dá»±a trÃªn GPT-3.5, cÃ²n Code LLaMA sáº½ cháº¡y inference offline dá»±a trÃªn cáº¥u hÃ¬nh mÃ¡y cÃ¡ nhÃ¢n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o source code táº¡i Ä‘Ã¢y","Cháº¯c má»i ngÆ°á»i biáº¿t tá»›i á»©ng dá»¥ng Code Interpreter cá»§a OpenAI vÃ  Code LLaMA cá»§a Meta, nay mÃ¬nh tháº¥y cÃ³ ngÆ°á»i viáº¿t API cÃ³ thá»ƒ káº¿t ná»‘i cáº£ 2 backends nÃ y Ä‘á»ƒ cháº¡y trong terminal, cÃ³ tÃªn lÃ  Open Interpreter. Náº¿u vá»›i Code Interpreter thÃ¬ sáº½ cháº¡y inference online dá»±a trÃªn GPT-3.5, cÃ²n Code LLaMA sáº½ cháº¡y inference offline dá»±a trÃªn cáº¥u hÃ¬nh mÃ¡y cÃ¡ nhÃ¢n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o source code táº¡i Ä‘Ã¢y",,,"#sharing, #nlp",,
"Hey everyone - sharing these 2 initiatives for Vietnamese startups that are interested in Gen AI:
(1) AWS Gen AI Day in Vietnam (Offline + Online)
Join us on September 15 in HCMC for AWS Gen AI Day! Experience insightful sessions with AI experts, Gen AI startup demos, and network with fellow startups, VCs, SMEs, and Enterprises. Content will be broadcasted to online participants. RSVP here: https://lu.ma/BuildingGenerativeAIonAWS
(2) AWS ASEAN Gen AI Accelerator Program (Sep 26 - Oct 26) Deadline: 16 September
Apply for the AWS x Accelerating Asia ASEAN Gen AI Reactor program (http://bit.ly/aseangenai). Get 5 weeks of intensive support, mentorship from AI experts and thought leaders, up to $200K in AWS credits and demo day with VCs. This is open to early stage startups in ASEAN with existing or in-progress solutions in Gen AI.","Hey everyone - sharing these 2 initiatives for Vietnamese startups that are interested in Gen AI: (1) AWS Gen AI Day in Vietnam (Offline + Online) Join us on September 15 in HCMC for AWS Gen AI Day! Experience insightful sessions with AI experts, Gen AI startup demos, and network with fellow startups, VCs, SMEs, and Enterprises. Content will be broadcasted to online participants. RSVP here: https://lu.ma/BuildingGenerativeAIonAWS (2) AWS ASEAN Gen AI Accelerator Program (Sep 26 - Oct 26) Deadline: 16 September Apply for the AWS x Accelerating Asia ASEAN Gen AI Reactor program (http://bit.ly/aseangenai). Get 5 weeks of intensive support, mentorship from AI experts and thought leaders, up to $200K in AWS credits and demo day with VCs. This is open to early stage startups in ASEAN with existing or in-progress solutions in Gen AI.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡:v
Em Ä‘ang tÃ¬m hiá»ƒu vá» LLMs vÃ  vá»«a má»›i fine-tune Ä‘Æ°á»£c 1 model lÃ m chatbot vÃ  em cÃ³ 3 cÃ¢u há»i mong má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p:
1. Em muá»‘n deploy model lÃªn web Ä‘á»ƒ cÃ³ thá»ƒ nháº­n feedback tá»« ngÆ°á»i dÃ¹ng qua Internet thÃ¬ cÃ³ nhá»¯ng cÃ¡ch phá»• biá»ƒn nÃ o hay dÃ¹ng áº¡?
Em cÃ³ tra thÃ¬ tháº¥y cÃ³ 1 bÃªn cháº¡y trÃªn Ä‘Æ°á»£c huggingface
https://huggingface.co/spaces/project-baize/chat-with-baize nhÆ° nÃ y. NhÆ°ng em tÃ¬m hiá»ƒu thÃ¬ váº«n chÆ°a biáº¿t Ä‘Æ°a lÃªn kiá»ƒu gÃ¬:<
2. Chatbot cá»§a em thÃ¬ má»›i cÃ³ thá»ƒ tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i 1-1. ChÆ°a ghi nhá»› Ä‘Æ°á»£c Ä‘oáº¡n há»™i thoáº¡i cÅ© Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i má»›i (kiá»ƒu chatgpt). Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ lÃ m Ä‘Æ°á»£c nhÆ° váº­y, hoáº·c má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘Æ°a em tá»« khÃ³a Ä‘á»ƒ em search áº¡.
3. Vá»›i nhá»¯ng chatbot Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« LLMs thÃ¬ mÃ¬nh cÃ³ thá»ƒ xÃ¢y dá»±ng ká»‹ch báº£n cho nÃ³ khÃ´ng áº¡? VÃ­ dá»¥ nhÆ° chatbot Ä‘á»ƒ tráº£ lá»i CSKH, thá»‰nh thoáº£ng sáº½ tá»± Ä‘á»™ng ra 1 cÃ¢u há»i khi khÃ¡ch hÃ ng chÆ°a há»i cÃ¢u há»i Ä‘áº¥y.
Em cáº£m Æ¡n mn áº¡.","Em chÃ o má»i ngÆ°á»i áº¡:v Em Ä‘ang tÃ¬m hiá»ƒu vá» LLMs vÃ  vá»«a má»›i fine-tune Ä‘Æ°á»£c 1 model lÃ m chatbot vÃ  em cÃ³ 3 cÃ¢u há»i mong má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p: 1. Em muá»‘n deploy model lÃªn web Ä‘á»ƒ cÃ³ thá»ƒ nháº­n feedback tá»« ngÆ°á»i dÃ¹ng qua Internet thÃ¬ cÃ³ nhá»¯ng cÃ¡ch phá»• biá»ƒn nÃ o hay dÃ¹ng áº¡? Em cÃ³ tra thÃ¬ tháº¥y cÃ³ 1 bÃªn cháº¡y trÃªn Ä‘Æ°á»£c huggingface https://huggingface.co/spaces/project-baize/chat-with-baize nhÆ° nÃ y. NhÆ°ng em tÃ¬m hiá»ƒu thÃ¬ váº«n chÆ°a biáº¿t Ä‘Æ°a lÃªn kiá»ƒu gÃ¬:< 2. Chatbot cá»§a em thÃ¬ má»›i cÃ³ thá»ƒ tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i 1-1. ChÆ°a ghi nhá»› Ä‘Æ°á»£c Ä‘oáº¡n há»™i thoáº¡i cÅ© Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i má»›i (kiá»ƒu chatgpt). Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ lÃ m Ä‘Æ°á»£c nhÆ° váº­y, hoáº·c má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘Æ°a em tá»« khÃ³a Ä‘á»ƒ em search áº¡. 3. Vá»›i nhá»¯ng chatbot Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« LLMs thÃ¬ mÃ¬nh cÃ³ thá»ƒ xÃ¢y dá»±ng ká»‹ch báº£n cho nÃ³ khÃ´ng áº¡? VÃ­ dá»¥ nhÆ° chatbot Ä‘á»ƒ tráº£ lá»i CSKH, thá»‰nh thoáº£ng sáº½ tá»± Ä‘á»™ng ra 1 cÃ¢u há»i khi khÃ¡ch hÃ ng chÆ°a há»i cÃ¢u há»i Ä‘áº¥y. Em cáº£m Æ¡n mn áº¡.",,,"#Q&A, #nlp",,
"Xin chÃ o anh chá»‹ trong group, em vá»«a tÃ¬m hiá»ƒu vá» phÆ°Æ¡ng phÃ¡p word2vec trong NLP (cá»¥ thá»ƒ lÃ  skip-gram). DÃ¹ Ä‘Ã£ Ä‘á»c qua vÃ i bÃ i (gá»“m cáº£ cá»§a anh Tiá»‡p) vÃ  xem vid trÃªn Youtube nhÆ°ng váº«n cÃ³ má»™t vÃ i Ä‘oáº¡n em chÆ°a hiá»ƒu láº¯m nÃªn mong anh chá»‹ giáº£i thÃ­ch thÃªm áº¡:

Thá»© nháº¥t, theo em hiá»ƒu thÃ¬ vá»›i má»—i target word ta sáº½ tÃ¬m cÃ¡c weight matrix (U vÃ  V) Ä‘á»ƒ xÃ¡c suáº¥t cá»§a context word lÃ  cao nháº¥t, báº±ng phÆ°Æ¡ng phÃ¡p backprobagation; sau Ä‘Ã³ láº·p láº¡i quÃ¡ trÃ¬nh vá»›i C context words (vá»›i C lÃ  context window); sau Ä‘Ã³ láº¡i láº·p láº¡i quÃ¡ trÃ¬nh Ä‘áº¥y vá»›i N tá»« trong tá»« Ä‘iá»ƒn. NhÆ° váº­y sá»‘ láº§n pháº£i lÃ m backprobagation lÃ  C * N. NhÆ°ng khi há»c vá» MLP thÃ¬ em Ä‘Æ°á»£c biáº¿t backprobagation lÃ  quÃ¡ trÃ¬nh khÃ¡ tá»‘n kÃ©m thá»i gian (khÃ´ng biáº¿t liá»‡u viá»‡c chá»‰ cÃ³ 1 hidden layer vÃ  no activation function cÃ³ lÃ m giáº£m thá»i gian khÃ´ng) nÃªn ta cáº§n chá»n C, N nhÆ° nÃ o Ä‘á»ƒ Ä‘áº£m báº£o cáº£ thá»i gian vÃ  accuracy áº¡? 
Má»—i tá»« Ä‘áº§u vÃ o biá»ƒu diá»…n dÆ°á»›i dáº¡ng one-hot coding, tuy nhiÃªn khi trá»±c quan hÃ³a nÃ³ dÆ°á»›i dáº¡ng hÃ¬nh áº£nh (nhÆ° á»Ÿ Ä‘Ã¢y: https://projector.tensorflow.org/) thÃ¬ em láº¡i tháº¥y ngÆ°á»i ta tÃ¬m context dá»±a trÃªn tá»« ""á»Ÿ gáº§n"" vá»›i target word nháº¥t (khÃ´ng biáº¿t lÃ  gáº§n theo Euclid distance hay nhÆ° nÃ o) vÃ  coi má»—i tá»« trong tá»« Ä‘iá»ƒn lÃ  má»™t vector cÃ³ Ä‘á»™ dÃ i báº±ng nhau trong khÃ´ng gian. Váº­y cÃ¡c vector Ä‘áº¥y láº¥y á»Ÿ Ä‘Ã¢u áº¡? Cháº¯c khÃ´ng pháº£i lÃ  vector biá»ƒu diá»…n one-hot encoding mÃ  lÃ  embedding vector trong ma tráº­n U, V mÃ  ta Ä‘Ã£ tÃ¬m á»Ÿ trÃªn áº¡? Náº¿u hiá»ƒu theo nghÄ©a Ä‘áº¥y thÃ¬ kÃ­ch thÆ°á»›c má»—i vector chÃ­nh lÃ  sá»‘ neuron trong hidden vector Ä‘Ãºng khÃ´ng áº¡? 
Táº¡i sao khÃ´ng dÃ¹ng nhiá»u hidden layer cho thuáº­t toÃ¡n nhÆ° MLP tháº¿ áº¡? 
NgoÃ i ra náº¿u khi trá»±c quan hÃ³a ta dÃ¹ng vector trong weight matrix tÃ¬m ra thÃ¬ dÃ¹ng vector trong target matrix U hay context matrix V áº¡?
CÆ¡ sá»Ÿ toÃ¡n há»c nÃ o Ä‘áº±ng sau viá»‡c mÃ´ hÃ¬nh hÃ³a nÃ y áº¡? Ã em lÃ , lÃ m sao khoáº£ng cÃ¡ch euclid giá»¯a cÃ¡c vector cá»§a weight matrix trong khÃ´ng gian láº¡i cÃ³ liÃªn quan Ä‘áº¿n mÃ´ hÃ¬nh xÃ¡c suáº¥t mÃ  ta xÃ¢y dá»±ng á»Ÿ thuáº­t toÃ¡n áº¡? 


 ","Xin chÃ o anh chá»‹ trong group, em vá»«a tÃ¬m hiá»ƒu vá» phÆ°Æ¡ng phÃ¡p word2vec trong NLP (cá»¥ thá»ƒ lÃ  skip-gram). DÃ¹ Ä‘Ã£ Ä‘á»c qua vÃ i bÃ i (gá»“m cáº£ cá»§a anh Tiá»‡p) vÃ  xem vid trÃªn Youtube nhÆ°ng váº«n cÃ³ má»™t vÃ i Ä‘oáº¡n em chÆ°a hiá»ƒu láº¯m nÃªn mong anh chá»‹ giáº£i thÃ­ch thÃªm áº¡: Thá»© nháº¥t, theo em hiá»ƒu thÃ¬ vá»›i má»—i target word ta sáº½ tÃ¬m cÃ¡c weight matrix (U vÃ  V) Ä‘á»ƒ xÃ¡c suáº¥t cá»§a context word lÃ  cao nháº¥t, báº±ng phÆ°Æ¡ng phÃ¡p backprobagation; sau Ä‘Ã³ láº·p láº¡i quÃ¡ trÃ¬nh vá»›i C context words (vá»›i C lÃ  context window); sau Ä‘Ã³ láº¡i láº·p láº¡i quÃ¡ trÃ¬nh Ä‘áº¥y vá»›i N tá»« trong tá»« Ä‘iá»ƒn. NhÆ° váº­y sá»‘ láº§n pháº£i lÃ m backprobagation lÃ  C * N. NhÆ°ng khi há»c vá» MLP thÃ¬ em Ä‘Æ°á»£c biáº¿t backprobagation lÃ  quÃ¡ trÃ¬nh khÃ¡ tá»‘n kÃ©m thá»i gian (khÃ´ng biáº¿t liá»‡u viá»‡c chá»‰ cÃ³ 1 hidden layer vÃ  no activation function cÃ³ lÃ m giáº£m thá»i gian khÃ´ng) nÃªn ta cáº§n chá»n C, N nhÆ° nÃ o Ä‘á»ƒ Ä‘áº£m báº£o cáº£ thá»i gian vÃ  accuracy áº¡? Má»—i tá»« Ä‘áº§u vÃ o biá»ƒu diá»…n dÆ°á»›i dáº¡ng one-hot coding, tuy nhiÃªn khi trá»±c quan hÃ³a nÃ³ dÆ°á»›i dáº¡ng hÃ¬nh áº£nh (nhÆ° á»Ÿ Ä‘Ã¢y: https://projector.tensorflow.org/) thÃ¬ em láº¡i tháº¥y ngÆ°á»i ta tÃ¬m context dá»±a trÃªn tá»« ""á»Ÿ gáº§n"" vá»›i target word nháº¥t (khÃ´ng biáº¿t lÃ  gáº§n theo Euclid distance hay nhÆ° nÃ o) vÃ  coi má»—i tá»« trong tá»« Ä‘iá»ƒn lÃ  má»™t vector cÃ³ Ä‘á»™ dÃ i báº±ng nhau trong khÃ´ng gian. Váº­y cÃ¡c vector Ä‘áº¥y láº¥y á»Ÿ Ä‘Ã¢u áº¡? Cháº¯c khÃ´ng pháº£i lÃ  vector biá»ƒu diá»…n one-hot encoding mÃ  lÃ  embedding vector trong ma tráº­n U, V mÃ  ta Ä‘Ã£ tÃ¬m á»Ÿ trÃªn áº¡? Náº¿u hiá»ƒu theo nghÄ©a Ä‘áº¥y thÃ¬ kÃ­ch thÆ°á»›c má»—i vector chÃ­nh lÃ  sá»‘ neuron trong hidden vector Ä‘Ãºng khÃ´ng áº¡? Táº¡i sao khÃ´ng dÃ¹ng nhiá»u hidden layer cho thuáº­t toÃ¡n nhÆ° MLP tháº¿ áº¡? NgoÃ i ra náº¿u khi trá»±c quan hÃ³a ta dÃ¹ng vector trong weight matrix tÃ¬m ra thÃ¬ dÃ¹ng vector trong target matrix U hay context matrix V áº¡? CÆ¡ sá»Ÿ toÃ¡n há»c nÃ o Ä‘áº±ng sau viá»‡c mÃ´ hÃ¬nh hÃ³a nÃ y áº¡? Ã em lÃ , lÃ m sao khoáº£ng cÃ¡ch euclid giá»¯a cÃ¡c vector cá»§a weight matrix trong khÃ´ng gian láº¡i cÃ³ liÃªn quan Ä‘áº¿n mÃ´ hÃ¬nh xÃ¡c suáº¥t mÃ  ta xÃ¢y dá»±ng á»Ÿ thuáº­t toÃ¡n áº¡?",,,"#Q&A, #nlp",,
"MÃ¬nh cÃ³ tÃ¬m hiá»ƒu vá» Image generation thÃ¬ tháº¥y LoRA khÃ¡ phá»• biáº¿n khi finetuning Stable Diffusion. Tuy nhiÃªn thÃ¬ láº¡i tháº¥y khÃ¡ Ã­t chá»— nÃ³i vá» cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng Ä‘á»‘i vá»›i SD, chá»§ yáº¿u chá»‰ tháº¥y mention trong PEFT cá»§a NLP. Hy vá»ng bÃ i viáº¿t cÃ³ thá»ƒ giÃºp má»i ngÆ°á»i hiá»ƒu hÆ¡n vá» cÃ¡ch LoRA giáº£m computation cost vÃ  kÃ­ch cá»¡ file lÆ°u trá»¯ khi finetune SD nhÃ©!","MÃ¬nh cÃ³ tÃ¬m hiá»ƒu vá» Image generation thÃ¬ tháº¥y LoRA khÃ¡ phá»• biáº¿n khi finetuning Stable Diffusion. Tuy nhiÃªn thÃ¬ láº¡i tháº¥y khÃ¡ Ã­t chá»— nÃ³i vá» cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng Ä‘á»‘i vá»›i SD, chá»§ yáº¿u chá»‰ tháº¥y mention trong PEFT cá»§a NLP. Hy vá»ng bÃ i viáº¿t cÃ³ thá»ƒ giÃºp má»i ngÆ°á»i hiá»ƒu hÆ¡n vá» cÃ¡ch LoRA giáº£m computation cost vÃ  kÃ­ch cá»¡ file lÆ°u trá»¯ khi finetune SD nhÃ©!",,,"#sharing, #cv",,
CÃ³ ngÆ°á»i Ä‘Ã£ tá»•ng há»£p tá»›i 14 triá»‡u áº£nh kÃ¨m prompt sinh ra tá»« cÃ¡c mÃ´ hÃ¬nh diffusions táº¡i Ä‘Ã¢y,CÃ³ ngÆ°á»i Ä‘Ã£ tá»•ng há»£p tá»›i 14 triá»‡u áº£nh kÃ¨m prompt sinh ra tá»« cÃ¡c mÃ´ hÃ¬nh diffusions táº¡i Ä‘Ã¢y,,,#sharing,,
"NhÃ¢n dá»‹p mÃ¬nh cÃ³ Pull Request (GLIGEN model Pipeline) Ä‘Æ°á»£c merge vÃ o thÆ° viá»‡n Huggingface/Diffuser mÃ¬nh xin phÃ©p chia sáº» Ä‘áº¿n má»i ngÆ°á»i. Hiá»‡n nay cÃ¡c phÆ°Æ¡ng phÃ¡p finetune personal diffusion nhÆ° Textual Inversion, Dreambooth hay LoRA sáº½ giÃºp ta thÃªm object hoáº·c style báº¥t kÃ¬ vÃ o áº£nh mÃ  ta muá»‘n sinh. NhÆ°ng cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y Ä‘á»u yÃªu cáº§u pháº£i cÃ³ má»™t lÆ°á»£ng data vÃ  finetuneing. GLIGEN Pipeline há»— trá»£ viá»‡c thÃªm object hoáº·c style mÃ  khÃ´ng cáº§n finetune (Zero-shot), ta chá»‰ cáº§n truyá»n má»™t bá»©c áº£nh chá»©a object hoáº·c style vÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ sinh ra áº£nh dá»±a trÃªn Ä‘Ã³. Chi tiáº¿t hÆ¡n cÃ³ thá»ƒ tham kháº£o á»Ÿ paper: https://arxiv.org/abs/2301.07093. NgoÃ i ra GLIGEN Pipeline cÃ²n cÃ³ thá»ƒ cho báº¡n xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ Ä‘áº·t váº­t thá»ƒ trong áº£nh sinh ra báº±ng viá»‡c cung cáº¥p tá»a Ä‘á»™ box. Hiá»‡n táº¡i mÃ¬nh support 2 model lÃ  Generation vÃ  Inpainting. Má»i ngÆ°á»i há»©ng thÃº cÃ³ thá»ƒ thá»­, code example Ä‘Æ°á»£c mÃ¬nh Ä‘Ã­nh kÃ¨m á»Ÿ model card.
Generation: https://huggingface.co/anhnct/Gligen_Text_Image
Inpainting: https://huggingface.co/anhnct/Gligen_Inpainting_Text_Image","NhÃ¢n dá»‹p mÃ¬nh cÃ³ Pull Request (GLIGEN model Pipeline) Ä‘Æ°á»£c merge vÃ o thÆ° viá»‡n Huggingface/Diffuser mÃ¬nh xin phÃ©p chia sáº» Ä‘áº¿n má»i ngÆ°á»i. Hiá»‡n nay cÃ¡c phÆ°Æ¡ng phÃ¡p finetune personal diffusion nhÆ° Textual Inversion, Dreambooth hay LoRA sáº½ giÃºp ta thÃªm object hoáº·c style báº¥t kÃ¬ vÃ o áº£nh mÃ  ta muá»‘n sinh. NhÆ°ng cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y Ä‘á»u yÃªu cáº§u pháº£i cÃ³ má»™t lÆ°á»£ng data vÃ  finetuneing. GLIGEN Pipeline há»— trá»£ viá»‡c thÃªm object hoáº·c style mÃ  khÃ´ng cáº§n finetune (Zero-shot), ta chá»‰ cáº§n truyá»n má»™t bá»©c áº£nh chá»©a object hoáº·c style vÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ sinh ra áº£nh dá»±a trÃªn Ä‘Ã³. Chi tiáº¿t hÆ¡n cÃ³ thá»ƒ tham kháº£o á»Ÿ paper: https://arxiv.org/abs/2301.07093. NgoÃ i ra GLIGEN Pipeline cÃ²n cÃ³ thá»ƒ cho báº¡n xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ Ä‘áº·t váº­t thá»ƒ trong áº£nh sinh ra báº±ng viá»‡c cung cáº¥p tá»a Ä‘á»™ box. Hiá»‡n táº¡i mÃ¬nh support 2 model lÃ  Generation vÃ  Inpainting. Má»i ngÆ°á»i há»©ng thÃº cÃ³ thá»ƒ thá»­, code example Ä‘Æ°á»£c mÃ¬nh Ä‘Ã­nh kÃ¨m á»Ÿ model card. Generation: https://huggingface.co/anhnct/Gligen_Text_Image Inpainting: https://huggingface.co/anhnct/Gligen_Inpainting_Text_Image",,,"#sharing, #deep_learning",,
"Gáº§n Ä‘Ã¢y mÃ¬nh quan sÃ¡t tháº¥y hiá»‡n tÆ°á»£ng hay xu tháº¿ chuyá»ƒn Ä‘á»•i code tá»« Python qua C/C++ cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. NhÆ°ng chÆ°a tháº¥y ai viáº¿t láº¡i models vÃ  train nÃ³ tá»« chÃ­nh C/C++. Tuy nhiÃªn, trong ngÃ´n Rust thÃ¬ xu tháº¿ viáº¿t láº¡i models vÃ  training loop Ä‘ang Ä‘Æ°á»£c cá»™ng Ä‘á»“ng lÃ m khÃ¡ máº¡nh, trong Ä‘Ã³ cÃ³ Huggingface. TrÆ°á»›c Ä‘Ã³, Huggingface Ä‘Ã£ viáº¿t má»™t sá»‘ thÆ° viá»‡n báº±ng Rust nhÆ° datasets, safetensors,... vÃ  gáº§n Ä‘Ã¢y há» báº¯t Ä‘áº§u viáº¿t láº¡i cáº£ models vÃ  training loop cho chÃºng báº±ng ngÃ´n ngá»¯ Rust. https://github.com/huggingface/candle;
Tháº­m chÃ­, cÃ³ ngÆ°á»i khÃ¡c cÃ²n port cáº£ pytorch sang Rust nhÆ° á»Ÿ Ä‘Ã¢y https://github.com/burn-rs/burn/tree/main vÃ  cÃ³ 1 sá»‘ examples vá» build vÃ  train models báº±ng Rust.
Hi vá»ng, vá»›i thÃ´ng tin nÃ y sáº½ gá»£i Ã½ cho cÃ¡c báº¡n thÃªm phÆ°Æ¡ng Ã¡n trong lá»™ trÃ¬nh há»c táº­p vÃ  lÃ m viá»‡c.
Ps. CÃ¡ch Ä‘Ã¢y vÃ i thÃ¡ng mÃ¬nh cÃ³ biáº¿t Elon Musk cÃ²n cÃ³ 1 post vá» Rust ná»¯a cÆ¡. CÃ³ láº½ tiá»m nÄƒng cá»§a Rust sáº½ ráº¥t lá»›n trong tÆ°Æ¡ng lai gáº§n.","Gáº§n Ä‘Ã¢y mÃ¬nh quan sÃ¡t tháº¥y hiá»‡n tÆ°á»£ng hay xu tháº¿ chuyá»ƒn Ä‘á»•i code tá»« Python qua C/C++ cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. NhÆ°ng chÆ°a tháº¥y ai viáº¿t láº¡i models vÃ  train nÃ³ tá»« chÃ­nh C/C++. Tuy nhiÃªn, trong ngÃ´n Rust thÃ¬ xu tháº¿ viáº¿t láº¡i models vÃ  training loop Ä‘ang Ä‘Æ°á»£c cá»™ng Ä‘á»“ng lÃ m khÃ¡ máº¡nh, trong Ä‘Ã³ cÃ³ Huggingface. TrÆ°á»›c Ä‘Ã³, Huggingface Ä‘Ã£ viáº¿t má»™t sá»‘ thÆ° viá»‡n báº±ng Rust nhÆ° datasets, safetensors,... vÃ  gáº§n Ä‘Ã¢y há» báº¯t Ä‘áº§u viáº¿t láº¡i cáº£ models vÃ  training loop cho chÃºng báº±ng ngÃ´n ngá»¯ Rust. https://github.com/huggingface/candle; Tháº­m chÃ­, cÃ³ ngÆ°á»i khÃ¡c cÃ²n port cáº£ pytorch sang Rust nhÆ° á»Ÿ Ä‘Ã¢y https://github.com/burn-rs/burn/tree/main vÃ  cÃ³ 1 sá»‘ examples vá» build vÃ  train models báº±ng Rust. Hi vá»ng, vá»›i thÃ´ng tin nÃ y sáº½ gá»£i Ã½ cho cÃ¡c báº¡n thÃªm phÆ°Æ¡ng Ã¡n trong lá»™ trÃ¬nh há»c táº­p vÃ  lÃ m viá»‡c. Ps. CÃ¡ch Ä‘Ã¢y vÃ i thÃ¡ng mÃ¬nh cÃ³ biáº¿t Elon Musk cÃ²n cÃ³ 1 post vá» Rust ná»¯a cÆ¡. CÃ³ láº½ tiá»m nÄƒng cá»§a Rust sáº½ ráº¥t lá»›n trong tÆ°Æ¡ng lai gáº§n.",,,#sharing,,
"MÃ¬nh Ä‘Ã£ nhÃ¬n tháº¥y post nÃ y (dÆ°á»›i comment) khÃ¡ lÃ¢u trong group, cÃ³ nhiá»u likes vÃ  shares nÃªn tháº¥y cÃ³ trÃ¡ch nhiá»‡m pháº£n há»“i káº»o nhiá»u báº¡n hiá»ƒu sai váº¥n Ä‘á».
Báº¡n chá»§ post nÃ³i Ä‘Ãºng á»Ÿ chá»— khÃ´ng nÃªn nháº¯m máº¯t Ä‘iá»n giÃ¡ trá»‹ thiáº¿u báº±ng 0 mÃ  cáº§n hiá»ƒu ká»¹ phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u.
Tuy nhiÃªn, nÃ³i â€œTUYá»†T Äá»I KHÃ”NGâ€ lÃ  ráº¥t há»“ Ä‘á»“. Äiá»u báº¡n quan sÃ¡t Ä‘Æ°á»£c chá»‰ Ä‘Ãºng trong cÃ¡c trÆ°á»ng há»£p báº¡n tháº¥y, Ä‘á»«ng vá»™i generalize ra toÃ n bá»™ káº»o bá»‹ overfitting vá»›i nhá»¯ng gÃ¬ mÃ¬nh tháº¥y.
Nhá»¯ng gÃ¬ báº¡n phÃ¢n tÃ­ch chá»‰ Ã¡p dá»¥ng trong trÆ°á»ng há»£p toÃ n bá»™ cÃ¡c biáº¿n á»Ÿ dáº¡ng sá»‘ thá»±c. Vá»›i dá»¯ liá»‡u háº¡ng má»¥c thÃ¬ khÃ´ng cÃ³ khÃ¡i niá»‡m KNN!
Ká»ƒ cáº£ vá»›i dá»¯ liá»‡u dáº¡ng sá»‘ thá»±c thÃ¬ scale cá»§a cÃ¡c biáº¿n áº£nh hÆ°á»Ÿng ráº¥t nhiá»u Ä‘áº¿n khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm. NÃªn báº¡n nÃ³i lÃ  KNN sáº½ cho lá»±a chá»n chÃ­nh xÃ¡c lÃ  chÆ°a Ä‘Ãºng.
Vá» dá»¯ liá»‡u bá»‹ khuyáº¿t, cáº§n cÃ³ domain knowledge Ä‘á»ƒ hiá»ƒu dá»¯ liá»‡u Ä‘Ã³ lÃ  khuyáº¿t ngáº«u nhiÃªn hay khÃ´ng vÃ  dÃ¹ng cÃ¡c phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng á»©ng (xem [1]) cho phÃ¹ há»£p.
Náº¿u khÃ´ng cháº¯c cÃ¡ch impute missing data nhÆ° tháº¿ nÃ o thÃ¬ báº¯t Ä‘áº§u vá»›i cÃ¡ch dá»… nháº¥t rá»“i xem xÃ©t metrics vÃ  thá»­ vá»›i nhiá»u cÃ¡ch khÃ¡c nhau. Äá»«ng tá»± Ä‘Ã³ng mÃ¬nh vá»›i má»™t cÃ¡i gÃ¬ â€œTUYá»†T Äá»I KHÃ”NGâ€.
Tham kháº£o:
[1]
https://www.ncbi.nlm.nih.gov/books/NBK493614/#:~:text=Missing%20at%20random%20(MAR).,but%20not%20the%20unobserved%20data.
[2]
https://en.wikipedia.org/wiki/Missing_data","MÃ¬nh Ä‘Ã£ nhÃ¬n tháº¥y post nÃ y (dÆ°á»›i comment) khÃ¡ lÃ¢u trong group, cÃ³ nhiá»u likes vÃ  shares nÃªn tháº¥y cÃ³ trÃ¡ch nhiá»‡m pháº£n há»“i káº»o nhiá»u báº¡n hiá»ƒu sai váº¥n Ä‘á». Báº¡n chá»§ post nÃ³i Ä‘Ãºng á»Ÿ chá»— khÃ´ng nÃªn nháº¯m máº¯t Ä‘iá»n giÃ¡ trá»‹ thiáº¿u báº±ng 0 mÃ  cáº§n hiá»ƒu ká»¹ phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u. Tuy nhiÃªn, nÃ³i â€œTUYá»†T Äá»I KHÃ”NGâ€ lÃ  ráº¥t há»“ Ä‘á»“. Äiá»u báº¡n quan sÃ¡t Ä‘Æ°á»£c chá»‰ Ä‘Ãºng trong cÃ¡c trÆ°á»ng há»£p báº¡n tháº¥y, Ä‘á»«ng vá»™i generalize ra toÃ n bá»™ káº»o bá»‹ overfitting vá»›i nhá»¯ng gÃ¬ mÃ¬nh tháº¥y. Nhá»¯ng gÃ¬ báº¡n phÃ¢n tÃ­ch chá»‰ Ã¡p dá»¥ng trong trÆ°á»ng há»£p toÃ n bá»™ cÃ¡c biáº¿n á»Ÿ dáº¡ng sá»‘ thá»±c. Vá»›i dá»¯ liá»‡u háº¡ng má»¥c thÃ¬ khÃ´ng cÃ³ khÃ¡i niá»‡m KNN! Ká»ƒ cáº£ vá»›i dá»¯ liá»‡u dáº¡ng sá»‘ thá»±c thÃ¬ scale cá»§a cÃ¡c biáº¿n áº£nh hÆ°á»Ÿng ráº¥t nhiá»u Ä‘áº¿n khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm. NÃªn báº¡n nÃ³i lÃ  KNN sáº½ cho lá»±a chá»n chÃ­nh xÃ¡c lÃ  chÆ°a Ä‘Ãºng. Vá» dá»¯ liá»‡u bá»‹ khuyáº¿t, cáº§n cÃ³ domain knowledge Ä‘á»ƒ hiá»ƒu dá»¯ liá»‡u Ä‘Ã³ lÃ  khuyáº¿t ngáº«u nhiÃªn hay khÃ´ng vÃ  dÃ¹ng cÃ¡c phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng á»©ng (xem [1]) cho phÃ¹ há»£p. Náº¿u khÃ´ng cháº¯c cÃ¡ch impute missing data nhÆ° tháº¿ nÃ o thÃ¬ báº¯t Ä‘áº§u vá»›i cÃ¡ch dá»… nháº¥t rá»“i xem xÃ©t metrics vÃ  thá»­ vá»›i nhiá»u cÃ¡ch khÃ¡c nhau. Äá»«ng tá»± Ä‘Ã³ng mÃ¬nh vá»›i má»™t cÃ¡i gÃ¬ â€œTUYá»†T Äá»I KHÃ”NGâ€. Tham kháº£o: [1] https://www.ncbi.nlm.nih.gov/books/NBK493614/#:~:text=Missing%20at%20random%20(MAR).,but%20not%20the%20unobserved%20data. [2] https://en.wikipedia.org/wiki/Missing_data",,,"#sharing, #data",,
"TUYá»†T Äá»I KHÃ”NG bao giá» Ä‘iá»n giÃ¡ trá»‹ thiáº¿u báº±ng Mean (hoáº·c zero).
ÄÃ¢y lÃ  nhá»¯ng gÃ¬ xáº£y ra khi chÃºng ta thá»±c hiá»‡n fill value bá»Ÿi Mean/0:
.
.
Thay tháº¿ (Ä‘iá»n) giÃ¡ trá»‹ thiáº¿u báº±ng trung bÃ¬nh hoáº·c zero hoáº·c báº¥t ká»³ giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh nÃ o khÃ¡c:
- LÃ m thay Ä‘á»•i cÃ¡c thá»‘ng kÃª tÃ³m táº¯t
- LÃ m thay Ä‘á»•i phÃ¢n phá»‘i
- LÃ m tÄƒng sá»± hiá»‡n diá»‡n cá»§a má»™t giÃ¡ trá»‹ cá»¥ thá»ƒ
Äiá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n:
- LÃ m mÃ´ hÃ¬nh khÃ´ng chÃ­nh xÃ¡c
- Khiáº¿n káº¿t luáº­n sai láº§m, vÃ  nhiá»u hÆ¡n ná»¯a.
- Thay vÃ o Ä‘Ã³, luÃ´n cá»‘ gáº¯ng Ä‘iá»n giÃ¡ trá»‹ thiáº¿u vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n.
Nhá»¯ng trÆ°á»ng há»£p nhÆ° váº­y thÃ¬ KNN imputer thÆ°á»ng lÃ  má»™t lá»±a chá»n Æ°u tiÃªn hÆ¡n
=> NÃ³ Ä‘iá»n giÃ¡ trá»‹ thiáº¿u báº±ng cÃ¡ch sá»­ dá»¥ng k-Nearest Neighbors.
CÃ¡c giÃ¡ trá»‹ trá»‘ng sáº½ Ä‘Æ°á»£c Ä‘iá»n báº±ng cÃ¡ch cháº¡y kNN trÃªn cÃ¡c giÃ¡ trá»‹ cÃ²n láº¡i.
Hiá»‡u quáº£ cá»§a nÃ³ so vá»›i Mean / Zero imputation thÃ¬ hoÃ n toÃ n Ä‘Æ°á»£c minh há»a nhÆ° hÃ¬nh bÃªn dÆ°á»›i:
- Mean / Zero thay Ä‘á»•i thá»‘ng kÃª tÃ³m táº¯t vÃ  phÃ¢n phá»‘i
- KNN imputer giÃºp giá»¯ nguyÃªn
share by: learning and sharing for machine learning&ai
download tÃ i liá»‡u mÃ¬nh chia sáº» táº¡i: https://bit.ly/drive-tailieu-ebook","TUYá»†T Äá»I KHÃ”NG bao giá» Ä‘iá»n giÃ¡ trá»‹ thiáº¿u báº±ng Mean (hoáº·c zero). ÄÃ¢y lÃ  nhá»¯ng gÃ¬ xáº£y ra khi chÃºng ta thá»±c hiá»‡n fill value bá»Ÿi Mean/0: . . Thay tháº¿ (Ä‘iá»n) giÃ¡ trá»‹ thiáº¿u báº±ng trung bÃ¬nh hoáº·c zero hoáº·c báº¥t ká»³ giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh nÃ o khÃ¡c: - LÃ m thay Ä‘á»•i cÃ¡c thá»‘ng kÃª tÃ³m táº¯t - LÃ m thay Ä‘á»•i phÃ¢n phá»‘i - LÃ m tÄƒng sá»± hiá»‡n diá»‡n cá»§a má»™t giÃ¡ trá»‹ cá»¥ thá»ƒ Äiá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n: - LÃ m mÃ´ hÃ¬nh khÃ´ng chÃ­nh xÃ¡c - Khiáº¿n káº¿t luáº­n sai láº§m, vÃ  nhiá»u hÆ¡n ná»¯a. - Thay vÃ o Ä‘Ã³, luÃ´n cá»‘ gáº¯ng Ä‘iá»n giÃ¡ trá»‹ thiáº¿u vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n. Nhá»¯ng trÆ°á»ng há»£p nhÆ° váº­y thÃ¬ KNN imputer thÆ°á»ng lÃ  má»™t lá»±a chá»n Æ°u tiÃªn hÆ¡n => NÃ³ Ä‘iá»n giÃ¡ trá»‹ thiáº¿u báº±ng cÃ¡ch sá»­ dá»¥ng k-Nearest Neighbors. CÃ¡c giÃ¡ trá»‹ trá»‘ng sáº½ Ä‘Æ°á»£c Ä‘iá»n báº±ng cÃ¡ch cháº¡y kNN trÃªn cÃ¡c giÃ¡ trá»‹ cÃ²n láº¡i. Hiá»‡u quáº£ cá»§a nÃ³ so vá»›i Mean / Zero imputation thÃ¬ hoÃ n toÃ n Ä‘Æ°á»£c minh há»a nhÆ° hÃ¬nh bÃªn dÆ°á»›i: - Mean / Zero thay Ä‘á»•i thá»‘ng kÃª tÃ³m táº¯t vÃ  phÃ¢n phá»‘i - KNN imputer giÃºp giá»¯ nguyÃªn share by: learning and sharing for machine learning&ai download tÃ i liá»‡u mÃ¬nh chia sáº» táº¡i: https://bit.ly/drive-tailieu-ebook",,,"#sharing , #data",,
"Má»i ngÆ°á»i cho em há»i sá»± khÃ¡c biá»‡t giá»¯a normalization vÃ  standardization lÃ  gÃ¬ váº­y áº¡? Khi nÃ o thÃ¬ nÃªn dÃ¹ng cÃ¡i nÃ o áº¡? Em Ä‘á»c tÃ i liá»‡u mÃ  tháº¥y chá»‰ hÆ°á»›ng dáº«n cÃ¡ch tÃ­nh toÃ¡n nÃªn hÆ¡i hoang mang khÃ´ng biáº¿t nÃªn dÃ¹ng cÃ¡i nÃ o (vÃ­ dá»¥ KNN, Logistic Regression)
Em cáº£m Æ¡n má»i ngÆ°á»i","Má»i ngÆ°á»i cho em há»i sá»± khÃ¡c biá»‡t giá»¯a normalization vÃ  standardization lÃ  gÃ¬ váº­y áº¡? Khi nÃ o thÃ¬ nÃªn dÃ¹ng cÃ¡i nÃ o áº¡? Em Ä‘á»c tÃ i liá»‡u mÃ  tháº¥y chá»‰ hÆ°á»›ng dáº«n cÃ¡ch tÃ­nh toÃ¡n nÃªn hÆ¡i hoang mang khÃ´ng biáº¿t nÃªn dÃ¹ng cÃ¡i nÃ o (vÃ­ dá»¥ KNN, Logistic Regression) Em cáº£m Æ¡n má»i ngÆ°á»i",,,"#Q&A, #machine_learning",,
"Xin chÃ o anh chá»‹ áº¡, anh chá»‹ cho em há»i ká»¹ nÄƒng/kiáº¿n thá»©c chuyÃªn mÃ´n giá»¯a AI Engineer vá»›i AI Researcher/Scientist cÃ³ kháº£ nÄƒng bá»• trá»£ láº«n nhau khÃ´ng áº¡? Em muá»‘n Ä‘á»‹nh hÆ°á»›ng theo hÆ°á»›ng AI Engineer nhÆ°ng tháº¯c máº¯c liá»‡u viá»‡c tham gia cÃ¡c Lab/Ä‘á» tÃ i nghiÃªn cá»©u cÃ³ giÃºp mÃ¬nh trong viá»‡c lÃ m ká»¹ sÆ° khÃ´ng áº¡ (nhÆ° hiá»ƒu rÃµ cÃ¡c model/hiá»ƒu thÃªm cÃ¡c cÃ´ng nghá»‡/Ã½ tÆ°á»Ÿng má»›iâ€¦)?","Xin chÃ o anh chá»‹ áº¡, anh chá»‹ cho em há»i ká»¹ nÄƒng/kiáº¿n thá»©c chuyÃªn mÃ´n giá»¯a AI Engineer vá»›i AI Researcher/Scientist cÃ³ kháº£ nÄƒng bá»• trá»£ láº«n nhau khÃ´ng áº¡? Em muá»‘n Ä‘á»‹nh hÆ°á»›ng theo hÆ°á»›ng AI Engineer nhÆ°ng tháº¯c máº¯c liá»‡u viá»‡c tham gia cÃ¡c Lab/Ä‘á» tÃ i nghiÃªn cá»©u cÃ³ giÃºp mÃ¬nh trong viá»‡c lÃ m ká»¹ sÆ° khÃ´ng áº¡ (nhÆ° hiá»ƒu rÃµ cÃ¡c model/hiá»ƒu thÃªm cÃ¡c cÃ´ng nghá»‡/Ã½ tÆ°á»Ÿng má»›iâ€¦)?",,,#Q&A,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t táº­p dá»¯ liá»‡u gá»“m cÃ¡c chuá»—i thÃ´ng sá»‘ vÃ­ dá»¥ 34,3,38,48,55,... vÃ  nhÃ£n cá»§a má»—i chuá»—i nÃ y lÃ  0 hoáº·c 1( báº¥t thÆ°á»ng/khÃ´ng báº¥t thÆ°á»ng ).
Em nÃªn dÃ¹ng LSTM hay model nÃ o ok hÆ¡n áº¡
Em cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t táº­p dá»¯ liá»‡u gá»“m cÃ¡c chuá»—i thÃ´ng sá»‘ vÃ­ dá»¥ 34,3,38,48,55,... vÃ  nhÃ£n cá»§a má»—i chuá»—i nÃ y lÃ  0 hoáº·c 1( báº¥t thÆ°á»ng/khÃ´ng báº¥t thÆ°á»ng ). Em nÃªn dÃ¹ng LSTM hay model nÃ o ok hÆ¡n áº¡ Em cáº£m Æ¡n",,,"#Q&A, #deep_learning",,
"Tuy Claude-2, cáº¡nh tranh vá»›i ChatGPT vÃ  Bard, chÆ°a Ä‘Æ°á»£c triá»ƒn táº¡i Viá»‡t Nam, nhÆ°ng mÃ¬nh Ä‘Ã£ dÃ¹ng Ä‘Æ°á»£c 1 thá»i gian vÃ  cÃ³ áº¥n tÆ°á»£ng tá»‘t vá»›i chat bot nÃ y. Æ¯u Ä‘iá»ƒm cá»§a Claude-2 lÃ  cÃ³ kháº£ nÄƒng ""suy luáº­n"" vá»›i long content/text. Váº­y cÃ¢u há»i ráº±ng lÃ m sao cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c nÃ³ mÃ  khÃ´ng cÃ³ VNP, giáº£i phÃ¡p Ä‘Æ¡n giáº£n nháº¥t lÃ  dÃ¹ng Opera Browser (trÆ°á»›c mÃ¬nh dÃ¹ng Brave, nhÆ°ng Opera cÅ©ng cÃ³ kháº£ nÄƒng cháº·n quáº£ng cÃ¡o ráº¥t tá»‘t). Sau Ä‘Ã¢y, Anthropic lÃ  cÃ´ng ti máº¹ cá»§a Claude-2 giá»›i thiá»‡u Cook Book cÃ¡ch dÃ¹ng vá»›i long context táº¡i Ä‘Ã¢y","Tuy Claude-2, cáº¡nh tranh vá»›i ChatGPT vÃ  Bard, chÆ°a Ä‘Æ°á»£c triá»ƒn táº¡i Viá»‡t Nam, nhÆ°ng mÃ¬nh Ä‘Ã£ dÃ¹ng Ä‘Æ°á»£c 1 thá»i gian vÃ  cÃ³ áº¥n tÆ°á»£ng tá»‘t vá»›i chat bot nÃ y. Æ¯u Ä‘iá»ƒm cá»§a Claude-2 lÃ  cÃ³ kháº£ nÄƒng ""suy luáº­n"" vá»›i long content/text. Váº­y cÃ¢u há»i ráº±ng lÃ m sao cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c nÃ³ mÃ  khÃ´ng cÃ³ VNP, giáº£i phÃ¡p Ä‘Æ¡n giáº£n nháº¥t lÃ  dÃ¹ng Opera Browser (trÆ°á»›c mÃ¬nh dÃ¹ng Brave, nhÆ°ng Opera cÅ©ng cÃ³ kháº£ nÄƒng cháº·n quáº£ng cÃ¡o ráº¥t tá»‘t). Sau Ä‘Ã¢y, Anthropic lÃ  cÃ´ng ti máº¹ cá»§a Claude-2 giá»›i thiá»‡u Cook Book cÃ¡ch dÃ¹ng vá»›i long context táº¡i Ä‘Ã¢y",,,"#sharing, #nlp",,
"Em xin chÃ o cÃ¡c anh chá»‹ áº¡. Em Ä‘á»c vá» máº¡ng RNN dáº¡ng Vec2seq, trong sÃ¡ch cÃ³ Ä‘oáº¡n nhÆ° hÃ¬nh bÃªn dÆ°á»›i áº¡. Anh chá»‹ nÃ o hiá»ƒu Ä‘Æ°á»£c cÃ¡i phÆ°Æ¡ng trÃ¬nh 15.1 Ä‘Ã³ cÃ³ Ã½ nghÄ©a nhÆ° nÃ o khÃ´ng áº¡ hay cho em xin cÃ¡ch Ä‘á»c nÃ³ áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u áº¡. ChÃºc má»i ngÆ°á»i má»™t ngÃ y vui váº» bÃ¬nh an.","Em xin chÃ o cÃ¡c anh chá»‹ áº¡. Em Ä‘á»c vá» máº¡ng RNN dáº¡ng Vec2seq, trong sÃ¡ch cÃ³ Ä‘oáº¡n nhÆ° hÃ¬nh bÃªn dÆ°á»›i áº¡. Anh chá»‹ nÃ o hiá»ƒu Ä‘Æ°á»£c cÃ¡i phÆ°Æ¡ng trÃ¬nh 15.1 Ä‘Ã³ cÃ³ Ã½ nghÄ©a nhÆ° nÃ o khÃ´ng áº¡ hay cho em xin cÃ¡ch Ä‘á»c nÃ³ áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u áº¡. ChÃºc má»i ngÆ°á»i má»™t ngÃ y vui váº» bÃ¬nh an.",,,"#Q&A, #deep_learning, #math",,
"E chÃ o cáº£ nhÃ , e cÃ³ tháº¯c máº¯c vá» cÃ¡ch fune-tune YOLOV8 Ä‘á»ƒ model cÃ³ performance tá»‘t hÆ¡n áº¡. E Ä‘ang train yolov8 báº±ng default settings, vÃ  cÃ³ má»™t sá»‘ váº¥n Ä‘á» e Ä‘ang gáº·p pháº£i áº¡:
- HÃ m loss Ä‘ang á»Ÿ má»©c ráº¥t cao, cáº£ trÃªn táº­p training vÃ  val, e Ä‘ang khÃ´ng biáº¿t táº¡i sao láº¡i nhÆ° váº­y áº¡, vÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ giáº£m nÃ³ xuá»‘ng khÃ´ng áº¡??
-Dataset lÃ  vá» fabric defect, vÃ  cÃ³ distribution e nhÆ° trong hÃ¬nh áº¡, vÃ  e khÃ´ng thá»ƒ thu tháº­p thÃªm data Ä‘Æ°á»£c ná»¯a, thÃ¬ e sá»­ dá»¥ng má»™t sá»‘ máº¡ng GAN Ä‘á»ƒ sinh thÃªm dá»¯ liá»‡u thÃ¬ cÃ³ hiá»‡u quáº£ trong bÃ i toÃ¡n nÃ y khÃ´ng áº¡?? Hoáº·c Ã¡p dá»¥ng thÃªm cÃ¡c ká»¹ thuáº­t augmentation nÃ o khÃ¡c ngoÃ i default setting cá»§a Yolov8 Ä‘á»ƒ cÃ³ performance tá»‘t hÆ¡n áº¡?
- Má»i ngÆ°á»i gá»£i Ã½ giÃºp em cÃ¡ch fine-tune cÃ¡c hyperparameter Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡!!
E Ä‘ang train vá»›i card 2080ti 11gb, default settings cá»§a YOLOv8 áº¡:
task: detect
mode: train
model: yolov8s.pt
data: /root/data/andy/yolo8/Fabricv6/data.yaml
epochs: 400
patience: 50
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: null
exist_ok: false
pretrained: false
optimizer: SGD
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 0
resume: false
amp: true
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
show: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
vid_stride: 1
line_width: null
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
boxes: true
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
cfg: null
v5loader: false
tracker: botsort.yaml
save_dir: runs/detect/train31
Em cÃ¡m Æ¡n cáº£ nhÃ  áº¡!!","E chÃ o cáº£ nhÃ , e cÃ³ tháº¯c máº¯c vá» cÃ¡ch fune-tune YOLOV8 Ä‘á»ƒ model cÃ³ performance tá»‘t hÆ¡n áº¡. E Ä‘ang train yolov8 báº±ng default settings, vÃ  cÃ³ má»™t sá»‘ váº¥n Ä‘á» e Ä‘ang gáº·p pháº£i áº¡: - HÃ m loss Ä‘ang á»Ÿ má»©c ráº¥t cao, cáº£ trÃªn táº­p training vÃ  val, e Ä‘ang khÃ´ng biáº¿t táº¡i sao láº¡i nhÆ° váº­y áº¡, vÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ giáº£m nÃ³ xuá»‘ng khÃ´ng áº¡?? -Dataset lÃ  vá» fabric defect, vÃ  cÃ³ distribution e nhÆ° trong hÃ¬nh áº¡, vÃ  e khÃ´ng thá»ƒ thu tháº­p thÃªm data Ä‘Æ°á»£c ná»¯a, thÃ¬ e sá»­ dá»¥ng má»™t sá»‘ máº¡ng GAN Ä‘á»ƒ sinh thÃªm dá»¯ liá»‡u thÃ¬ cÃ³ hiá»‡u quáº£ trong bÃ i toÃ¡n nÃ y khÃ´ng áº¡?? Hoáº·c Ã¡p dá»¥ng thÃªm cÃ¡c ká»¹ thuáº­t augmentation nÃ o khÃ¡c ngoÃ i default setting cá»§a Yolov8 Ä‘á»ƒ cÃ³ performance tá»‘t hÆ¡n áº¡? - Má»i ngÆ°á»i gá»£i Ã½ giÃºp em cÃ¡ch fine-tune cÃ¡c hyperparameter Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡!! E Ä‘ang train vá»›i card 2080ti 11gb, default settings cá»§a YOLOv8 áº¡: task: detect mode: train model: yolov8s.pt data: /root/data/andy/yolo8/Fabricv6/data.yaml epochs: 400 patience: 50 batch: 16 imgsz: 640 save: true save_period: -1 cache: false device: null workers: 8 project: null name: null exist_ok: false pretrained: false optimizer: SGD verbose: true seed: 0 deterministic: true single_cls: false rect: false cos_lr: false close_mosaic: 0 resume: false amp: true overlap_mask: true mask_ratio: 4 dropout: 0.0 val: true split: val save_json: false save_hybrid: false conf: null iou: 0.7 max_det: 300 half: false dnn: false plots: true source: null show: false save_txt: false save_conf: false save_crop: false show_labels: true show_conf: true vid_stride: 1 line_width: null visualize: false augment: false agnostic_nms: false classes: null retina_masks: false boxes: true format: torchscript keras: false optimize: false int8: false dynamic: false simplify: false opset: null workspace: 4 nms: false lr0: 0.01 lrf: 0.01 momentum: 0.937 weight_decay: 0.0005 warmup_epochs: 3.0 warmup_momentum: 0.8 warmup_bias_lr: 0.1 box: 7.5 cls: 0.5 dfl: 1.5 pose: 12.0 kobj: 1.0 label_smoothing: 0.0 nbs: 64 hsv_h: 0.015 hsv_s: 0.7 hsv_v: 0.4 degrees: 0.0 translate: 0.1 scale: 0.5 shear: 0.0 perspective: 0.0 flipud: 0.0 fliplr: 0.5 mosaic: 1.0 mixup: 0.0 copy_paste: 0.0 cfg: null v5loader: false tracker: botsort.yaml save_dir: runs/detect/train31 Em cÃ¡m Æ¡n cáº£ nhÃ  áº¡!!",,,"#Q&A, #deep_learning, #cv",,
FREE R BOOKS FOR DATA SCIENCE,FREE R BOOKS FOR DATA SCIENCE,,,,,
"Technical review (Ä‘Ãªm ngÃ y 22 thÃ¡ng 8 nÄƒm 2023, GMT+7):
1/ OpenAi cho phÃ©p ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ tá»± finetune model GPT-3.5 turbo (model GPT-4 sáº½ Ä‘Æ°á»£c finetune vÃ o mÃ¹a thu, mÃ¹a thu á»Ÿ Báº¯c bÃ¡n cáº§u thÆ°á»ng tÃ­nh vÃ o ngÃ y 22-9 tá»›i 21-12 hÃ ng nÄƒm) vá»›i giá»ng vÄƒn vÃ  cÃ¡c tÃ­nh nÄƒng mÃ  ngÆ°á»i finetune muá»‘n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y 

2/ Meta giá»›i thiá»‡u SeamlessM4T, a Multimodal AI Model for Speech and Text Translations trong Ä‘Ã³ cÃ³ há»— trá»£ tiáº¿ng Viá»‡t nhÃ© cÃ¡c báº¡n (xem chi tiáº¿t táº¡i Ä‘Ã¢y https://about.fb.com/news/2023/08/seamlessm4t-ai-translation-model/), vÃ  má»Ÿ source táº¡i Ä‘Ã¢y https://github.com/facebookresearch/seamless_communication
3/ HuggingFace giá»›i thiá»‡u IDEFICS: an open reproduction of State-of-the-Art Visual Language model https://huggingface.co/blog/idefics","Technical review (Ä‘Ãªm ngÃ y 22 thÃ¡ng 8 nÄƒm 2023, GMT+7): 1/ OpenAi cho phÃ©p ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ tá»± finetune model GPT-3.5 turbo (model GPT-4 sáº½ Ä‘Æ°á»£c finetune vÃ o mÃ¹a thu, mÃ¹a thu á»Ÿ Báº¯c bÃ¡n cáº§u thÆ°á»ng tÃ­nh vÃ o ngÃ y 22-9 tá»›i 21-12 hÃ ng nÄƒm) vá»›i giá»ng vÄƒn vÃ  cÃ¡c tÃ­nh nÄƒng mÃ  ngÆ°á»i finetune muá»‘n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y 2/ Meta giá»›i thiá»‡u SeamlessM4T, a Multimodal AI Model for Speech and Text Translations trong Ä‘Ã³ cÃ³ há»— trá»£ tiáº¿ng Viá»‡t nhÃ© cÃ¡c báº¡n (xem chi tiáº¿t táº¡i Ä‘Ã¢y https://about.fb.com/news/2023/08/seamlessm4t-ai-translation-model/), vÃ  má»Ÿ source táº¡i Ä‘Ã¢y https://github.com/facebookresearch/seamless_communication 3/ HuggingFace giá»›i thiá»‡u IDEFICS: an open reproduction of State-of-the-Art Visual Language model https://huggingface.co/blog/idefics",,,#sharing,,
"VinAI Seminar - ""Principled Frameworks for Designing Deep Learning Models: Efficiency, Robustness, and Expressivity""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Tan Nguyen, NUS
Time: 10:00 am - 11:00 am (GMT+7), Aug 28, 2023","VinAI Seminar - ""Principled Frameworks for Designing Deep Learning Models: Efficiency, Robustness, and Expressivity"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Tan Nguyen, NUS Time: 10:00 am - 11:00 am (GMT+7), Aug 28, 2023",,,#webinar,,
"[GÃ“C NHá»œ TÆ¯ Váº¤N]: tÃ´i muá»‘n há»i vá» viá»‡c prompt engineering cho áº£nh táº¡o sinh qua Stable Diffusion.
1/ CÃ³ báº¡n nÃ o chuáº©n bá»‹ dá»¯ liá»‡u cáº£ áº£nh vÃ  text Ä‘á»ƒ finetune cÃ¡c models Stable Diffusion vÃ  ControlNet chÆ°a? Náº¿u cÃ³, xin báº¡n hÃ£y chia sáº» kinh nghiá»‡m vá» viá»‡c nÃ y;
2/ Kinh nghiá»‡m cá»§a báº¡n vá» viá»‡c prompt sao cho models sinh ra áº£nh mÃ  báº¡n mong muá»‘n?
MÃ¬nh xin cáº£m Æ¡n nhá»¯ng chia sáº» cá»§a cÃ¡c báº¡n trÆ°á»›c nhÃ©.
TrÃ¢n trá»ng","[GÃ“C NHá»œ TÆ¯ Váº¤N]: tÃ´i muá»‘n há»i vá» viá»‡c prompt engineering cho áº£nh táº¡o sinh qua Stable Diffusion. 1/ CÃ³ báº¡n nÃ o chuáº©n bá»‹ dá»¯ liá»‡u cáº£ áº£nh vÃ  text Ä‘á»ƒ finetune cÃ¡c models Stable Diffusion vÃ  ControlNet chÆ°a? Náº¿u cÃ³, xin báº¡n hÃ£y chia sáº» kinh nghiá»‡m vá» viá»‡c nÃ y; 2/ Kinh nghiá»‡m cá»§a báº¡n vá» viá»‡c prompt sao cho models sinh ra áº£nh mÃ  báº¡n mong muá»‘n? MÃ¬nh xin cáº£m Æ¡n nhá»¯ng chia sáº» cá»§a cÃ¡c báº¡n trÆ°á»›c nhÃ©. TrÃ¢n trá»ng",,,#Q&A,,
"Xin chÃ o mn. CÃ³ thá»ƒ nhiá»u ngÆ°á»i Ä‘Ã£ biáº¿t trang nÃ y nhÆ°ng mÃ¬nh tháº¥y khÃ¡ há»¯u Ã­ch nÃªn váº«n muá»‘n chia sáº» cÃ¹ng mn. Náº¿u cÃ¡c báº¡n muá»‘n tÃ¬m luáº­n vÄƒn hoáº·c luáº­n Ã¡n cá»§a cÃ¡c trÆ°á»ng dh trÃªn tháº¿ giá»›i cÃ³ thá»ƒ vÃ o Ä‘Ã¢y nhÃ©. Ko Ä‘áº§y Ä‘á»§ háº¿t cÃ¡c trÆ°á»ng nhÆ°ng lÄ©nh vá»±c khÃ¡ Ä‘a dáº¡ng, táº¥t nhiÃªn bao gá»“m cáº£ AI.
https://oatd.org
Hi vá»ng cÃ³ thá»ƒ giÃºp Ã­ch cho mn!","Xin chÃ o mn. CÃ³ thá»ƒ nhiá»u ngÆ°á»i Ä‘Ã£ biáº¿t trang nÃ y nhÆ°ng mÃ¬nh tháº¥y khÃ¡ há»¯u Ã­ch nÃªn váº«n muá»‘n chia sáº» cÃ¹ng mn. Náº¿u cÃ¡c báº¡n muá»‘n tÃ¬m luáº­n vÄƒn hoáº·c luáº­n Ã¡n cá»§a cÃ¡c trÆ°á»ng dh trÃªn tháº¿ giá»›i cÃ³ thá»ƒ vÃ o Ä‘Ã¢y nhÃ©. Ko Ä‘áº§y Ä‘á»§ háº¿t cÃ¡c trÆ°á»ng nhÆ°ng lÄ©nh vá»±c khÃ¡ Ä‘a dáº¡ng, táº¥t nhiÃªn bao gá»“m cáº£ AI. https://oatd.org Hi vá»ng cÃ³ thá»ƒ giÃºp Ã­ch cho mn!",,,#sharing,,
"CÃ¡c a/c cho em há»i má»™t váº¥n Ä‘á» nho nhá» áº¡? Em há»c vá» OCR vÃ  e Ä‘ang clone paddleOCR báº£n release 2.6 vá» colab Ä‘á»ƒ train bÃ i toÃ¡n text recognition. Tuy nhiÃªn khi clone vá» vÃ  cháº¡y dÃ²ng lá»‡nh nhÆ° trÃªn áº£nh, thÃ¬ gáº·p lá»—i trong file setup.py. A/c cÃ³ thá»ƒ cho em biáº¿t lÃ  táº¡i sao lá»—i vÃ  cÃ¡c sá»­a nhÆ° tháº¿ nÃ o khÃ´ng áº¡? Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡. (lá»—i nÃ y khÃ´ng pháº£i do pip vÃ  em cÅ©ng Ä‘Ã£ tÃ¬m hiá»ƒu nhiá»u mÃ  mÃ£i chÆ°a sá»­a Ä‘c áº¡ TT)","CÃ¡c a/c cho em há»i má»™t váº¥n Ä‘á» nho nhá» áº¡? Em há»c vá» OCR vÃ  e Ä‘ang clone paddleOCR báº£n release 2.6 vá» colab Ä‘á»ƒ train bÃ i toÃ¡n text recognition. Tuy nhiÃªn khi clone vá» vÃ  cháº¡y dÃ²ng lá»‡nh nhÆ° trÃªn áº£nh, thÃ¬ gáº·p lá»—i trong file setup.py. A/c cÃ³ thá»ƒ cho em biáº¿t lÃ  táº¡i sao lá»—i vÃ  cÃ¡c sá»­a nhÆ° tháº¿ nÃ o khÃ´ng áº¡? Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡. (lá»—i nÃ y khÃ´ng pháº£i do pip vÃ  em cÅ©ng Ä‘Ã£ tÃ¬m hiá»ƒu nhiá»u mÃ  mÃ£i chÆ°a sá»­a Ä‘c áº¡ TT)",,,"#Q&A, #cv",,
Em Ä‘Æ°á»£c giao phÃ¢n loáº¡i Ã½ Ä‘á»‹nh cá»§a 1 ngÆ°á»i trong 1 Ä‘oáº¡n há»™i thoáº¡i Ã­t nháº¥t 2 ngÆ°á»i. Anh chá»‹ nÃ o cÃ³ kinh nghiá»‡m hay biáº¿t cÃ³ paper nÃ o cÃ³ thá»ƒ cho em xin chÃºt hÆ°á»›ng dáº«n khÃ´ng áº¡. Em search gáº§n nhÆ° chá»‰ cÃ³ phÃ¢n loáº¡i Ã½ Ä‘á»‹nh cá»§a táº¥t cáº£ mn. Em cáº£m Æ¡n áº¡.,Em Ä‘Æ°á»£c giao phÃ¢n loáº¡i Ã½ Ä‘á»‹nh cá»§a 1 ngÆ°á»i trong 1 Ä‘oáº¡n há»™i thoáº¡i Ã­t nháº¥t 2 ngÆ°á»i. Anh chá»‹ nÃ o cÃ³ kinh nghiá»‡m hay biáº¿t cÃ³ paper nÃ o cÃ³ thá»ƒ cho em xin chÃºt hÆ°á»›ng dáº«n khÃ´ng áº¡. Em search gáº§n nhÆ° chá»‰ cÃ³ phÃ¢n loáº¡i Ã½ Ä‘á»‹nh cá»§a táº¥t cáº£ mn. Em cáº£m Æ¡n áº¡.,,,#Q&A,,
Má»i ngÆ°á»i cho em há»i cÃ³ ai cÃ³ bá»™ test data cá»§a cuá»™c thi PhÃ¢n loáº¡i sáº¯c thÃ¡i bÃ¬nh luáº­n https://www.aivivn.com/contests/1 . Em cáº£m Æ¡n áº¡.,Má»i ngÆ°á»i cho em há»i cÃ³ ai cÃ³ bá»™ test data cá»§a cuá»™c thi PhÃ¢n loáº¡i sáº¯c thÃ¡i bÃ¬nh luáº­n https://www.aivivn.com/contests/1 . Em cáº£m Æ¡n áº¡.,,,"#Q&A, #nlp",,
"Em Ä‘ang cÃ³ bÃ i táº­p lá»›n dÃ¹ng RNN hoáº·c LSTM Ä‘á»ƒ cÃ¢n báº±ng kÃªnh Ã¢m thanh, bro cÅ©ng máº£ng nÃ y khÃ´ng cho em xin Ã­t kinh nghiá»‡m vá»›i áº¡","Em Ä‘ang cÃ³ bÃ i táº­p lá»›n dÃ¹ng RNN hoáº·c LSTM Ä‘á»ƒ cÃ¢n báº±ng kÃªnh Ã¢m thanh, bro cÅ©ng máº£ng nÃ y khÃ´ng cho em xin Ã­t kinh nghiá»‡m vá»›i áº¡",,,"#Q&A, #deep_learning",,
"PROJECT Dá»° BÃO Äá»˜T QUá»´ TIM (Heart Attack) Full
(vá»«a Ã½ nghÄ©a vá»«a há»c táº­p)
---
TÃ i liá»‡u hÆ°á»›ng dáº«n Tá»«ng step by step cho 1 Project ML:
- TÃ¬m hiá»ƒu dá»¯ liá»‡u,
- Quan sÃ¡t dá»¯ liá»‡u,
- Pre processsing : GÃ¡n nhÃ£n, phÃ¢n loáº¡i dá»¯ liá»‡u. Chia tá»‡p Data thÃ nh cÃ¡c biáº¿n Ä‘á»™c láº­p vÃ  phá»¥ thuá»™c. Chia data thÃ nh Training & Test Dataset.
- Táº¡o ML Modeling function Ä‘á»ƒ Ã¡p dá»¥ng thuáº­t toÃ¡n phÃ¢n loáº¡i
---
Link táº£i file pdf : https://drive.google.com/drive/u/0/folders/13s3qEAGXMaLELJSWe_MZyb9uITWK1ZU8
Link Dataset Kaggle: https://www.kaggle.com/.../heart-attack-analysis...
Share by: Learning and sharing for machine learning&Ai","PROJECT Dá»° BÃO Äá»˜T QUá»´ TIM (Heart Attack) Full (vá»«a Ã½ nghÄ©a vá»«a há»c táº­p) --- TÃ i liá»‡u hÆ°á»›ng dáº«n Tá»«ng step by step cho 1 Project ML: - TÃ¬m hiá»ƒu dá»¯ liá»‡u, - Quan sÃ¡t dá»¯ liá»‡u, - Pre processsing : GÃ¡n nhÃ£n, phÃ¢n loáº¡i dá»¯ liá»‡u. Chia tá»‡p Data thÃ nh cÃ¡c biáº¿n Ä‘á»™c láº­p vÃ  phá»¥ thuá»™c. Chia data thÃ nh Training & Test Dataset. - Táº¡o ML Modeling function Ä‘á»ƒ Ã¡p dá»¥ng thuáº­t toÃ¡n phÃ¢n loáº¡i --- Link táº£i file pdf : https://drive.google.com/drive/u/0/folders/13s3qEAGXMaLELJSWe_MZyb9uITWK1ZU8 Link Dataset Kaggle: https://www.kaggle.com/.../heart-attack-analysis... Share by: Learning and sharing for machine learning&Ai",,,#sharing,,
"E chÃ o má»i ngÆ°á»i áº¡, e cÃ i cÃ´ng cá»¥ annotation CVAT trÃªn windows qua git bash theo link hÆ°á»¡ng dáº«n https://opencv.github.io/cvat/docs/administration/basics/installation/,
Ä‘áº¿n bÆ°á»›c táº¡o superuser thÃ¬ bá»‹ bÃ¡o lá»—i
: bash: sudo: command not found
vÃ 
$ docker exec -it cvat_server /bin/bash
the input device is not a TTY. If you are using mintty, try prefixing the command with 'winpty'
mng cho e lá»i khuyÃªn vá»›i áº¡ e cÃ¡m Æ¡n mng nhiá»u!!!","E chÃ o má»i ngÆ°á»i áº¡, e cÃ i cÃ´ng cá»¥ annotation CVAT trÃªn windows qua git bash theo link hÆ°á»¡ng dáº«n https://opencv.github.io/cvat/docs/administration/basics/installation/, Ä‘áº¿n bÆ°á»›c táº¡o superuser thÃ¬ bá»‹ bÃ¡o lá»—i : bash: sudo: command not found vÃ  $ docker exec -it cvat_server /bin/bash the input device is not a TTY. If you are using mintty, try prefixing the command with 'winpty' mng cho e lá»i khuyÃªn vá»›i áº¡ e cÃ¡m Æ¡n mng nhiá»u!!!",,,#Q&A,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang thá»­ sá»­a cÃ¡ch trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh vÃ  muá»‘n há»i nhÆ° sau. 
Em cÃ³ má»™t bá»©c áº£nh vÃ  cÃ¡c bounding box phÃ¡t hiá»‡n ra ngÆ°á»i tá»« bá»©c áº£nh Ä‘Ã³. á» mÃ´ hÃ¬nh Ä‘á» xuáº¥t cá»§a 1 paper em Ä‘ang Ä‘á»c, tÃ¡c giáº£ cÃ³ dÃ¹ng tá»a Ä‘á»™ cá»§a cÃ¡c bounding box (kÃ­ch thÆ°á»›c khÃ¡c nhau) Ä‘á»ƒ cáº¯t ra áº£nh cá»§a tá»«ng ngÆ°á»i trong khung hÃ¬nh. Sau Ä‘Ã³, má»—i bá»©c áº£nh Ä‘Æ°á»£c resize vá» kÃ­ch thÆ°á»›c (224, 224) vÃ  Ä‘Æ°a qua ResNet-34 Ä‘á»ƒ trÃ­ch xuáº¥t ra 1 vÃ©c-tÆ¡ Ä‘áº·c trÆ°ng 512 chiá»u. 
BÃ¢y giá» em muá»‘n dÃ¹ng 1 máº¡ng CNN Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng toÃ n áº£nh thÃ nh 1 feature map, rá»“i biáº¿n Ä‘á»•i width vÃ  height cá»§a bounding box vá» tÆ°Æ¡ng á»©ng vá»›i width vÃ  height cá»§a feature map, vÃ  sau Ä‘Ã³ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« feature map vÃ  biáº¿n Ä‘á»•i vá» thÃ nh 1 vÃ©c-tÆ¡ 512 chiá»u thÃ¬ cÃ³ kháº£ thi khÃ´ng áº¡?.
Em cÃ³ thá»­ vÃ  biáº¿t ráº±ng viá»‡c trÃ­ch xuáº¥t tá»« cÃ¡c bounding box cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau sáº½ cho ra cÃ¡c Tensor cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  khÃ´ng reshape vá» cÃ¹ng 1 kÃ­ch thÆ°á»›c Ä‘Æ°á»£c. Má»i ngÆ°á»i cho em xin gá»£i Ã½ vá»›i áº¡. ","ChÃ o má»i ngÆ°á»i, em Ä‘ang thá»­ sá»­a cÃ¡ch trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh vÃ  muá»‘n há»i nhÆ° sau. Em cÃ³ má»™t bá»©c áº£nh vÃ  cÃ¡c bounding box phÃ¡t hiá»‡n ra ngÆ°á»i tá»« bá»©c áº£nh Ä‘Ã³. á» mÃ´ hÃ¬nh Ä‘á» xuáº¥t cá»§a 1 paper em Ä‘ang Ä‘á»c, tÃ¡c giáº£ cÃ³ dÃ¹ng tá»a Ä‘á»™ cá»§a cÃ¡c bounding box (kÃ­ch thÆ°á»›c khÃ¡c nhau) Ä‘á»ƒ cáº¯t ra áº£nh cá»§a tá»«ng ngÆ°á»i trong khung hÃ¬nh. Sau Ä‘Ã³, má»—i bá»©c áº£nh Ä‘Æ°á»£c resize vá» kÃ­ch thÆ°á»›c (224, 224) vÃ  Ä‘Æ°a qua ResNet-34 Ä‘á»ƒ trÃ­ch xuáº¥t ra 1 vÃ©c-tÆ¡ Ä‘áº·c trÆ°ng 512 chiá»u. BÃ¢y giá» em muá»‘n dÃ¹ng 1 máº¡ng CNN Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng toÃ n áº£nh thÃ nh 1 feature map, rá»“i biáº¿n Ä‘á»•i width vÃ  height cá»§a bounding box vá» tÆ°Æ¡ng á»©ng vá»›i width vÃ  height cá»§a feature map, vÃ  sau Ä‘Ã³ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« feature map vÃ  biáº¿n Ä‘á»•i vá» thÃ nh 1 vÃ©c-tÆ¡ 512 chiá»u thÃ¬ cÃ³ kháº£ thi khÃ´ng áº¡?. Em cÃ³ thá»­ vÃ  biáº¿t ráº±ng viá»‡c trÃ­ch xuáº¥t tá»« cÃ¡c bounding box cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau sáº½ cho ra cÃ¡c Tensor cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  khÃ´ng reshape vá» cÃ¹ng 1 kÃ­ch thÆ°á»›c Ä‘Æ°á»£c. Má»i ngÆ°á»i cho em xin gá»£i Ã½ vá»›i áº¡.",,,"#Q&A, #cv, #deep_learning",,
"TrÃ­ tuá»‡ NhÃ¢n táº¡o (AI) Ä‘Ã£ len lá»i kháº¯p nÆ¡i, Ä‘i vÃ o má»i ngÃ³c ngÃ¡ch cá»§a cuá»™c sá»‘ng, cÃ´ng viá»‡c, giáº£i trÃ­,... Váº­y cÃ³ ai chá»£t Ä‘áº·t ra cÃ¢u há»i: AI lÃ  gÃ¬? Táº¡i sao hiá»‡n nay nÃ³ Ä‘ang nháº­n Ä‘Æ°á»£c sá»± quan tÃ¢m ráº¥t lá»›n tá»« kháº¯p má»i ngÃ nh?
#AI #NVIDIA #NTC #TheGioiMayChu","TrÃ­ tuá»‡ NhÃ¢n táº¡o (AI) Ä‘Ã£ len lá»i kháº¯p nÆ¡i, Ä‘i vÃ o má»i ngÃ³c ngÃ¡ch cá»§a cuá»™c sá»‘ng, cÃ´ng viá»‡c, giáº£i trÃ­,... Váº­y cÃ³ ai chá»£t Ä‘áº·t ra cÃ¢u há»i: AI lÃ  gÃ¬? Táº¡i sao hiá»‡n nay nÃ³ Ä‘ang nháº­n Ä‘Æ°á»£c sá»± quan tÃ¢m ráº¥t lá»›n tá»« kháº¯p má»i ngÃ nh?",#AI	#NVIDIA	#NTC	#TheGioiMayChu,,#sharing,,
"ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m 1 project vá» sinh giá»ng nÃ³i áº¡, nhÆ°ng em láº¡i khÃ´ng cÃ³ nhiá»u kiáº¿n thá»©c vá» máº£ng nÃ y nÃªn káº¿t quáº£ ra khÃ´ng Ä‘Æ°á»£c nhÆ° Ã½ áº¡.
Cho em há»i á»Ÿ Viá»‡t Nam cá»§a mÃ¬nh cÃ³ cá»™ng dá»“ng nÃ o xá»­ lÃ½ Ã¢m thanh khÃ´ng áº¡? VÃ¬ em muá»‘n tham kháº£o 1 sá»‘ kiáº¿n thá»©c áº¡.
Cáº£m Æ¡n cÃ¡c báº¡n vÃ  anh chá»‹ trong nhÃ³m.","ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m 1 project vá» sinh giá»ng nÃ³i áº¡, nhÆ°ng em láº¡i khÃ´ng cÃ³ nhiá»u kiáº¿n thá»©c vá» máº£ng nÃ y nÃªn káº¿t quáº£ ra khÃ´ng Ä‘Æ°á»£c nhÆ° Ã½ áº¡. Cho em há»i á»Ÿ Viá»‡t Nam cá»§a mÃ¬nh cÃ³ cá»™ng dá»“ng nÃ o xá»­ lÃ½ Ã¢m thanh khÃ´ng áº¡? VÃ¬ em muá»‘n tham kháº£o 1 sá»‘ kiáº¿n thá»©c áº¡. Cáº£m Æ¡n cÃ¡c báº¡n vÃ  anh chá»‹ trong nhÃ³m.",,,#Q&A,,
"em chÃ o má»i ngÆ°á»i áº¡, em cÃ³ táº­p dá»¯ liá»‡u lÃ  cÃ¡c báº£n tin tráº¡ng thÃ¡i cá»§a thiáº¿t bá»‹ trong Smart Home gá»­i lÃªn server.
Tá»« táº­p dá»¯ liá»‡u nÃ y, xá»­ lÃ½ bÃ i toÃ¡n nÃ o Ä‘Æ°á»£c nhá»‰....
Em Ä‘ang Ä‘á»‹nh phÃ¢n tÃ­ch hÃ nh vi ngÆ°á»i dÃ¹ng, nhÆ°ng cÅ©ng chÆ°a biáº¿t kÄ© thuáº­t sá»­ dá»¥ng. Ai cÃ³ Ä‘á»‹nh hÆ°á»›ng vÃ  phÆ°Æ¡ng phÃ¡p nÃ o khÃ´ng áº¡ giÃºp em vá»›i","em chÃ o má»i ngÆ°á»i áº¡, em cÃ³ táº­p dá»¯ liá»‡u lÃ  cÃ¡c báº£n tin tráº¡ng thÃ¡i cá»§a thiáº¿t bá»‹ trong Smart Home gá»­i lÃªn server. Tá»« táº­p dá»¯ liá»‡u nÃ y, xá»­ lÃ½ bÃ i toÃ¡n nÃ o Ä‘Æ°á»£c nhá»‰.... Em Ä‘ang Ä‘á»‹nh phÃ¢n tÃ­ch hÃ nh vi ngÆ°á»i dÃ¹ng, nhÆ°ng cÅ©ng chÆ°a biáº¿t kÄ© thuáº­t sá»­ dá»¥ng. Ai cÃ³ Ä‘á»‹nh hÆ°á»›ng vÃ  phÆ°Æ¡ng phÃ¡p nÃ o khÃ´ng áº¡ giÃºp em vá»›i",,,#Q&A,,
"CÃ³ váº» nhÆ° cÃ¡c báº¡n khÃ¡ thÃ­ch thÃº vá»›i cÃ¡c tÃ i liá»‡u hÆ°á»›ng dáº«n, nháº¥t lÃ  dÆ°á»›i dáº¡ng cookbook. Nay mÃ¬nh giá»›i thiá»‡u thÃªm (cháº¯c cháº¯n cÃ³ nhiá»u báº¡n Ä‘Ã£ biáº¿t tá»›i) vá» cookbook cá»§a OpenAI. Hiá»‡n nÃ³ Ä‘Ã£ cÃ³ tá»›i >46k sao, vÃ  Ä‘Æ°á»£c cáº­p nháº­t thÆ°á»ng xuyÃªn. MÃ¬nh cháº¯c cháº¯n sáº½ nghiá»n ngáº«m repository nÃ y","CÃ³ váº» nhÆ° cÃ¡c báº¡n khÃ¡ thÃ­ch thÃº vá»›i cÃ¡c tÃ i liá»‡u hÆ°á»›ng dáº«n, nháº¥t lÃ  dÆ°á»›i dáº¡ng cookbook. Nay mÃ¬nh giá»›i thiá»‡u thÃªm (cháº¯c cháº¯n cÃ³ nhiá»u báº¡n Ä‘Ã£ biáº¿t tá»›i) vá» cookbook cá»§a OpenAI. Hiá»‡n nÃ³ Ä‘Ã£ cÃ³ tá»›i >46k sao, vÃ  Ä‘Æ°á»£c cáº­p nháº­t thÆ°á»ng xuyÃªn. MÃ¬nh cháº¯c cháº¯n sáº½ nghiá»n ngáº«m repository nÃ y",,,#sharing,,
CÃ³ anh chá»‹ nÃ o Ä‘Ã£ tá»«ng dÃ¹ng CRAFT Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin thÃ nh cÃ´ng chÆ°a áº¡?,CÃ³ anh chá»‹ nÃ o Ä‘Ã£ tá»«ng dÃ¹ng CRAFT Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin thÃ nh cÃ´ng chÆ°a áº¡?,,,#Q&A,,
Kaggle cung cáº¥p cÃ¡c khÃ³a há»c cháº¥t lÆ°á»£ng cao vá» Khoa há»c Dá»¯ liá»‡u.,Kaggle cung cáº¥p cÃ¡c khÃ³a há»c cháº¥t lÆ°á»£ng cao vá» Khoa há»c Dá»¯ liá»‡u.,,,"#sharing, #data",,
"CÃ¡c há»‡ thá»‘ng OVX tÃ­ch há»£p NVIDIA GPU má»›i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÄƒng tá»‘c quy trÃ¬nh Ä‘Ã o táº¡o vÃ  suy luáº­n AI, cÃ¡c táº£i xá»­ lÃ½ chuyÃªn sÃ¢u vá» Ä‘á»“ há»a. Má»™t loáº¡t cÃ¡c nhÃ  cung cáº¥p lá»›n nhÆ° Dell Technologies, Hewlett Packard Enterprise, Lenovo, Supermicro,v.v... sáº¯p cho ra máº¯t sáº£n pháº©m.
#NVIDIA #OVX #OvxServer #Omniverse","CÃ¡c há»‡ thá»‘ng OVX tÃ­ch há»£p NVIDIA GPU má»›i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÄƒng tá»‘c quy trÃ¬nh Ä‘Ã o táº¡o vÃ  suy luáº­n AI, cÃ¡c táº£i xá»­ lÃ½ chuyÃªn sÃ¢u vá» Ä‘á»“ há»a. Má»™t loáº¡t cÃ¡c nhÃ  cung cáº¥p lá»›n nhÆ° Dell Technologies, Hewlett Packard Enterprise, Lenovo, Supermicro,v.v... sáº¯p cho ra máº¯t sáº£n pháº©m.",#NVIDIA	#OVX	#OvxServer	#Omniverse,,#sharing,,
Xin chÃ o mn. Mn cho mÃ¬nh há»i hiá»‡n nay cÃ³ mÃ´ hÃ¬nh hoáº·c phÆ°Æ¡ng phÃ¡p nÃ o hiá»‡u quáº£ trong viá»‡c detect nhá»¯ng Ä‘á»‘i tÆ°á»£ng ráº¥t ráº¥t nhá» (táº¡m gá»i tiny object). Mong Ä‘Æ°á»£c mn chia sáº».,Xin chÃ o mn. Mn cho mÃ¬nh há»i hiá»‡n nay cÃ³ mÃ´ hÃ¬nh hoáº·c phÆ°Æ¡ng phÃ¡p nÃ o hiá»‡u quáº£ trong viá»‡c detect nhá»¯ng Ä‘á»‘i tÆ°á»£ng ráº¥t ráº¥t nhá» (táº¡m gá»i tiny object). Mong Ä‘Æ°á»£c mn chia sáº».,,,"#Q&A, #cv",,
"Padding trong Convolutional Neural Network (CNN) lÃ  quÃ¡ trÃ¬nh thÃªm cÃ¡c giÃ¡ trá»‹ 0 (hoáº·c giÃ¡ trá»‹ khÃ¡c tuá»³ theo cÃ¡ch thiáº¿t láº­p) vÃ o xung quanh cÃ¡c biÃªn cá»§a áº£nh hoáº·c Ä‘áº·c trÆ°ng trÆ°á»›c khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p. Má»¥c Ä‘Ã­ch chÃ­nh cá»§a viá»‡c thÃªm padding lÃ  tÄƒng kÃ­ch thÆ°á»›c cá»§a Ä‘áº·c trÆ°ng hoáº·c áº£nh ban Ä‘áº§u Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng cÃ¡c biÃªn cá»§a áº£nh cÅ©ng Ä‘Æ°á»£c xá»­ lÃ½ má»™t cÃ¡ch hiá»‡u quáº£.
CÃ³ hai loáº¡i padding chÃ­nh:
Valid Padding (Zero Padding): Trong loáº¡i nÃ y, khÃ´ng cÃ³ padding Ä‘Æ°á»£c thÃªm vÃ o, vÃ  phÃ©p tÃ­ch cháº­p Ä‘Æ°á»£c thá»±c hiá»‡n trá»±c tiáº¿p trÃªn cÃ¡c vÃ¹ng khÃ´ng gian. Äiá»u nÃ y dáº«n Ä‘áº¿n viá»‡c giáº£m kÃ­ch thÆ°á»›c cá»§a Ä‘áº·c trÆ°ng hoáº·c áº£nh sau khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p.
Same Padding: ÄÃ¢y lÃ  loáº¡i padding phá»• biáº¿n, trong Ä‘Ã³ padding Ä‘Æ°á»£c thÃªm vÃ o sao cho kÃ­ch thÆ°á»›c cá»§a Ä‘áº·c trÆ°ng hoáº·c áº£nh sau khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p váº«n giá»¯ nguyÃªn kÃ­ch thÆ°á»›c so vá»›i ban Ä‘áº§u. ThÃ´ng thÆ°á»ng, giÃ¡ trá»‹ padding Ä‘Æ°á»£c tÃ­nh dá»±a trÃªn kÃ­ch thÆ°á»›c cá»§a ma tráº­n bá»™ lá»c vÃ  cÃ¡c bÆ°á»›c cá»§a phÃ©p tÃ­ch cháº­p.
Padding cÃ³ thá»ƒ giÃºp duy trÃ¬ thÃ´ng tin á»Ÿ biÃªn cá»§a áº£nh hoáº·c Ä‘áº·c trÆ°ng sau khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p vÃ  giÃºp trÃ¡nh viá»‡c máº¥t mÃ¡t thÃ´ng tin quÃ¡ nhiá»u. NÃ³ cÅ©ng cÃ³ thá»ƒ giÃºp kiá»ƒm soÃ¡t viá»‡c giáº£m kÃ­ch thÆ°á»›c quÃ¡ nhanh cá»§a Ä‘áº·c trÆ°ng, Ä‘áº·c biá»‡t khi sá»­ dá»¥ng nhiá»u lá»›p tÃ­ch cháº­p liÃªn tiáº¿p.","Padding trong Convolutional Neural Network (CNN) lÃ  quÃ¡ trÃ¬nh thÃªm cÃ¡c giÃ¡ trá»‹ 0 (hoáº·c giÃ¡ trá»‹ khÃ¡c tuá»³ theo cÃ¡ch thiáº¿t láº­p) vÃ o xung quanh cÃ¡c biÃªn cá»§a áº£nh hoáº·c Ä‘áº·c trÆ°ng trÆ°á»›c khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p. Má»¥c Ä‘Ã­ch chÃ­nh cá»§a viá»‡c thÃªm padding lÃ  tÄƒng kÃ­ch thÆ°á»›c cá»§a Ä‘áº·c trÆ°ng hoáº·c áº£nh ban Ä‘áº§u Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng cÃ¡c biÃªn cá»§a áº£nh cÅ©ng Ä‘Æ°á»£c xá»­ lÃ½ má»™t cÃ¡ch hiá»‡u quáº£. CÃ³ hai loáº¡i padding chÃ­nh: Valid Padding (Zero Padding): Trong loáº¡i nÃ y, khÃ´ng cÃ³ padding Ä‘Æ°á»£c thÃªm vÃ o, vÃ  phÃ©p tÃ­ch cháº­p Ä‘Æ°á»£c thá»±c hiá»‡n trá»±c tiáº¿p trÃªn cÃ¡c vÃ¹ng khÃ´ng gian. Äiá»u nÃ y dáº«n Ä‘áº¿n viá»‡c giáº£m kÃ­ch thÆ°á»›c cá»§a Ä‘áº·c trÆ°ng hoáº·c áº£nh sau khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p. Same Padding: ÄÃ¢y lÃ  loáº¡i padding phá»• biáº¿n, trong Ä‘Ã³ padding Ä‘Æ°á»£c thÃªm vÃ o sao cho kÃ­ch thÆ°á»›c cá»§a Ä‘áº·c trÆ°ng hoáº·c áº£nh sau khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p váº«n giá»¯ nguyÃªn kÃ­ch thÆ°á»›c so vá»›i ban Ä‘áº§u. ThÃ´ng thÆ°á»ng, giÃ¡ trá»‹ padding Ä‘Æ°á»£c tÃ­nh dá»±a trÃªn kÃ­ch thÆ°á»›c cá»§a ma tráº­n bá»™ lá»c vÃ  cÃ¡c bÆ°á»›c cá»§a phÃ©p tÃ­ch cháº­p. Padding cÃ³ thá»ƒ giÃºp duy trÃ¬ thÃ´ng tin á»Ÿ biÃªn cá»§a áº£nh hoáº·c Ä‘áº·c trÆ°ng sau khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p vÃ  giÃºp trÃ¡nh viá»‡c máº¥t mÃ¡t thÃ´ng tin quÃ¡ nhiá»u. NÃ³ cÅ©ng cÃ³ thá»ƒ giÃºp kiá»ƒm soÃ¡t viá»‡c giáº£m kÃ­ch thÆ°á»›c quÃ¡ nhanh cá»§a Ä‘áº·c trÆ°ng, Ä‘áº·c biá»‡t khi sá»­ dá»¥ng nhiá»u lá»›p tÃ­ch cháº­p liÃªn tiáº¿p.",,,"#sharing, #deep_learning",,
"E chÃ o mng áº¡, e Ä‘ang xá»­ lÃ­ dataset cho bÃ i toÃ¡n defect detection báº±ng YOLO, em bÄƒn khoÄƒn lÃ  ngoÃ i cÃ¡c áº£nh thuá»™c cÃ¡c classes lá»—i, thÃ¬ e cÃ³ nÃªn cho vÃ o áº£nh khÃ´ng cÃ³ lá»—i (Just as background without object), náº¿u thÃªm vÃ o thÃ¬ cÃ³ cáº£i thiá»‡n hiá»‡u nÄƒng cá»§a model khÃ´ng áº¡?? E cÃ¡m Æ¡n mng áº¡!!!","E chÃ o mng áº¡, e Ä‘ang xá»­ lÃ­ dataset cho bÃ i toÃ¡n defect detection báº±ng YOLO, em bÄƒn khoÄƒn lÃ  ngoÃ i cÃ¡c áº£nh thuá»™c cÃ¡c classes lá»—i, thÃ¬ e cÃ³ nÃªn cho vÃ o áº£nh khÃ´ng cÃ³ lá»—i (Just as background without object), náº¿u thÃªm vÃ o thÃ¬ cÃ³ cáº£i thiá»‡n hiá»‡u nÄƒng cá»§a model khÃ´ng áº¡?? E cÃ¡m Æ¡n mng áº¡!!!",,,"#Q&A, #data, #cv",,
"NVIDIA AI Workbench lÃ  gÃ¬? Táº¡i sao nÃ³ há»¯u Ã­ch cho viá»‡c phÃ¡t triá»ƒn cÃ¡c á»©ng dá»¥ng Generative AI vÃ  Ä‘Ã o táº¡o, tÃ¹y biáº¿n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nÃ³i chung?
#NVIDIA #AI #Workbench #GenerativeAI #LLM","NVIDIA AI Workbench lÃ  gÃ¬? Táº¡i sao nÃ³ há»¯u Ã­ch cho viá»‡c phÃ¡t triá»ƒn cÃ¡c á»©ng dá»¥ng Generative AI vÃ  Ä‘Ã o táº¡o, tÃ¹y biáº¿n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nÃ³i chung?",#NVIDIA	#AI	#Workbench	#GenerativeAI	#LLM,,,,
"Hi mng em cÃ³ má»™t sá»‘ tháº¯c máº¯c á»Ÿ giai Ä‘oáº¡n tiá»n xá»­ lÃ½ data khi mÃ¬nh lÃ m vá» Object Detection áº¡.
LÃºc mÃ¬nh Ä‘Ã£ cÃ³ má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c label tá»« tool labelImg trÃªn github thÃ¬ em tháº¥y thÆ°á»ng thÃ¬ sáº½ pháº£i cáº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u nÃ y rá»“i má»›i cho vÃ o train. Em cÃ³ Ä‘á»c má»™t pj trÃªn Kaggle thÃ¬ tháº¥y ngta Ä‘á»ƒ má»¥c Ä‘Ã³ lÃ  Data pipeline thÃ¬ em khÃ´ng hiá»ƒu láº¯m vá» cá»¥ thá»ƒ cÃ¡c bÆ°á»›c trong Ä‘Ã¢y mÃ¬nh cáº§n lÃ m gÃ¬ áº¡? MÃ¬nh cÃ³ nhá»¯ng giai Ä‘oáº¡n nÃ o nhá»¯ng viá»‡c lÃ m gÃ¬ mÃ¬nh cáº§n Ä‘á»ƒ Ã½ tá»›i vÃ  cáº§n pháº£i lÃ m trong bÆ°á»›c nÃ y (Data pipeline vÃ  pre-processing data).
Mong má»i ngÆ°á»i giÃºp em áº¡. Náº¿u Ä‘Æ°á»£c thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t sá»‘ trang hoáº·c sÃ¡ch cÃ³ nÃ³i cá»¥ thá»ƒ vá» quÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.",Hi mng em cÃ³ má»™t sá»‘ tháº¯c máº¯c á»Ÿ giai Ä‘oáº¡n tiá»n xá»­ lÃ½ data khi mÃ¬nh lÃ m vá» Object Detection áº¡. LÃºc mÃ¬nh Ä‘Ã£ cÃ³ má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c label tá»« tool labelImg trÃªn github thÃ¬ em tháº¥y thÆ°á»ng thÃ¬ sáº½ pháº£i cáº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u nÃ y rá»“i má»›i cho vÃ o train. Em cÃ³ Ä‘á»c má»™t pj trÃªn Kaggle thÃ¬ tháº¥y ngta Ä‘á»ƒ má»¥c Ä‘Ã³ lÃ  Data pipeline thÃ¬ em khÃ´ng hiá»ƒu láº¯m vá» cá»¥ thá»ƒ cÃ¡c bÆ°á»›c trong Ä‘Ã¢y mÃ¬nh cáº§n lÃ m gÃ¬ áº¡? MÃ¬nh cÃ³ nhá»¯ng giai Ä‘oáº¡n nÃ o nhá»¯ng viá»‡c lÃ m gÃ¬ mÃ¬nh cáº§n Ä‘á»ƒ Ã½ tá»›i vÃ  cáº§n pháº£i lÃ m trong bÆ°á»›c nÃ y (Data pipeline vÃ  pre-processing data). Mong má»i ngÆ°á»i giÃºp em áº¡. Náº¿u Ä‘Æ°á»£c thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t sá»‘ trang hoáº·c sÃ¡ch cÃ³ nÃ³i cá»¥ thá»ƒ vá» quÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.,,,"#Q&A, #data, #cv",,
700-page PDF â€” [#Algorithms] for Decision-Making â€” download brilliant & comprehensive FREE eBook from MIT: http://bit.ly/3wyNcnQ,700-page PDF â€” [#Algorithms] for Decision-Making â€” download brilliant & comprehensive FREE eBook from MIT: http://bit.ly/3wyNcnQ,,,,,
"ChÃ o cÃ¡c báº¡n,
CÃ¡c báº¡n cho mÃ¬nh há»i framework nÃ o vá» reinforcement learning good nháº¥t cho training má»™t Agent áº¡?","ChÃ o cÃ¡c báº¡n, CÃ¡c báº¡n cho mÃ¬nh há»i framework nÃ o vá» reinforcement learning good nháº¥t cho training má»™t Agent áº¡?",,,"#Q&A, #machine_learning",,
"Hiá»‡p há»™i OpenUSD (Alliance for OpenUSD) sáº½ tiáº¿n Ä‘áº¿n Ä‘áº£m báº£o kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch hoÃ n toÃ n cho cÃ¡c ná»™i dung vÃ  cÃ´ng cá»¥ 3D nháº±m triá»ƒn khai sá»‘ hÃ³a giá»¯a cÃ¡c ngÃ nh cÃ´ng nghiá»‡p.
#OpenUSD #AOUSD #UniversalSceneDescription #NVIDIA #3dworld",Hiá»‡p há»™i OpenUSD (Alliance for OpenUSD) sáº½ tiáº¿n Ä‘áº¿n Ä‘áº£m báº£o kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch hoÃ n toÃ n cho cÃ¡c ná»™i dung vÃ  cÃ´ng cá»¥ 3D nháº±m triá»ƒn khai sá»‘ hÃ³a giá»¯a cÃ¡c ngÃ nh cÃ´ng nghiá»‡p.,#OpenUSD	#AOUSD	#UniversalSceneDescription	#NVIDIA	#3dworld,,#sharing,,
"Máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN) lÃ  má»™t kiáº¿n trÃºc máº¡ng nÆ¡-ron Ä‘áº·c biá»‡t dÃ nh cho viá»‡c xá»­ lÃ½ dá»¯ liá»‡u hÃ¬nh áº£nh vÃ  giÃºp mÃ¡y tÃ­nh hiá»ƒu vÃ  phÃ¢n tÃ­ch hÃ¬nh áº£nh má»™t cÃ¡ch tá»± Ä‘á»™ng. NguyÃªn táº¯c hoáº¡t Ä‘á»™ng cá»§a CNN dá»±a trÃªn ba khÃ¡i niá»‡m chÃ­nh: tÃ­ch cháº­p, tá»•ng há»£p vÃ  kÃ­ch hoáº¡t.
TÃ­ch cháº­p (Convolution): Lá»›p tÃ­ch cháº­p lÃ  lá»›p Ä‘áº§u tiÃªn trong máº¡ng CNN. NÃ³ sá»­ dá»¥ng cÃ¡c bá»™ lá»c (hay cÃ²n gá»i lÃ  kernel) Ä‘á»ƒ trÆ°á»£t qua áº£nh Ä‘áº§u vÃ o. Má»—i bá»™ lá»c cÃ³ thá»ƒ nháº­n biáº¿t cÃ¡c Ä‘áº·c trÆ°ng cá»¥ thá»ƒ trong áº£nh nhÆ° cáº¡nh, gÃ³c, hoáº·c hÃ¬nh dáº¡ng. Khi bá»™ lá»c trÆ°á»£t qua áº£nh, nÃ³ táº¡o ra cÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng (feature maps) báº±ng cÃ¡ch thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p giá»¯a bá»™ lá»c vÃ  vÃ¹ng tÆ°Æ¡ng á»©ng trÃªn áº£nh. CÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng nÃ y giÃºp mÃ´ hÃ¬nh nháº­n biáº¿t cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng trong hÃ¬nh áº£nh.
Tá»•ng há»£p (Pooling): Lá»›p tá»•ng há»£p thÆ°á»ng Ä‘áº·t sau lá»›p tÃ­ch cháº­p. Nhiá»‡m vá»¥ cá»§a lá»›p nÃ y lÃ  giáº£m kÃ­ch thÆ°á»›c cá»§a cÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng báº±ng cÃ¡ch láº¥y giÃ¡ trá»‹ lá»›n nháº¥t hoáº·c trung bÃ¬nh tá»« cÃ¡c vÃ¹ng nhá» trÃªn báº£n Ä‘á»“ Ä‘áº·c trÆ°ng. Viá»‡c nÃ y giÃºp giáº£m sá»‘ lÆ°á»£ng tham sá»‘ vÃ  chi phÃ­ tÃ­nh toÃ¡n, Ä‘á»“ng thá»i lÃ m giáº£m nguy cÆ¡ overfitting.
KÃ­ch hoáº¡t (Activation): Lá»›p kÃ­ch hoáº¡t Ã¡p dá»¥ng má»™t hÃ m kÃ­ch hoáº¡t phi tuyáº¿n lÃªn cÃ¡c giÃ¡ trá»‹ trong cÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng. PhÃ©p kÃ­ch hoáº¡t nÃ y giÃºp mÃ´ hÃ¬nh há»c cÃ¡ch biá»ƒu diá»…n cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p vÃ  táº¡o tÃ­nh phi tuyáº¿n cho máº¡ng.
Lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§ (Fully Connected Layer): Sau khi thÃ´ng qua cÃ¡c lá»›p tÃ­ch cháº­p, tá»•ng há»£p vÃ  kÃ­ch hoáº¡t, dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Æ°a vÃ o lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§ Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ nhÆ° phÃ¢n loáº¡i hoáº·c dá»± Ä‘oÃ¡n. Trong lá»›p nÃ y, cÃ¡c nÆ¡-ron káº¿t ná»‘i vá»›i táº¥t cáº£ cÃ¡c nÆ¡-ron trong lá»›p trÆ°á»›c, giÃºp há»c cÃ¡ch tá»• há»£p cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.
ToÃ n bá»™ quÃ¡ trÃ¬nh nÃ y, tá»« lá»›p tÃ­ch cháº­p cho Ä‘áº¿n lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§, lÃ  quÃ¡ trÃ¬nh há»c tá»± Ä‘á»™ng. Máº¡ng nÆ¡-ron tá»± Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cá»§a cÃ¡c lá»›p Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t cho nhiá»‡m vá»¥ cá»¥ thá»ƒ, cháº³ng háº¡n nhÆ° phÃ¢n loáº¡i áº£nh.","Máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN) lÃ  má»™t kiáº¿n trÃºc máº¡ng nÆ¡-ron Ä‘áº·c biá»‡t dÃ nh cho viá»‡c xá»­ lÃ½ dá»¯ liá»‡u hÃ¬nh áº£nh vÃ  giÃºp mÃ¡y tÃ­nh hiá»ƒu vÃ  phÃ¢n tÃ­ch hÃ¬nh áº£nh má»™t cÃ¡ch tá»± Ä‘á»™ng. NguyÃªn táº¯c hoáº¡t Ä‘á»™ng cá»§a CNN dá»±a trÃªn ba khÃ¡i niá»‡m chÃ­nh: tÃ­ch cháº­p, tá»•ng há»£p vÃ  kÃ­ch hoáº¡t. TÃ­ch cháº­p (Convolution): Lá»›p tÃ­ch cháº­p lÃ  lá»›p Ä‘áº§u tiÃªn trong máº¡ng CNN. NÃ³ sá»­ dá»¥ng cÃ¡c bá»™ lá»c (hay cÃ²n gá»i lÃ  kernel) Ä‘á»ƒ trÆ°á»£t qua áº£nh Ä‘áº§u vÃ o. Má»—i bá»™ lá»c cÃ³ thá»ƒ nháº­n biáº¿t cÃ¡c Ä‘áº·c trÆ°ng cá»¥ thá»ƒ trong áº£nh nhÆ° cáº¡nh, gÃ³c, hoáº·c hÃ¬nh dáº¡ng. Khi bá»™ lá»c trÆ°á»£t qua áº£nh, nÃ³ táº¡o ra cÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng (feature maps) báº±ng cÃ¡ch thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p giá»¯a bá»™ lá»c vÃ  vÃ¹ng tÆ°Æ¡ng á»©ng trÃªn áº£nh. CÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng nÃ y giÃºp mÃ´ hÃ¬nh nháº­n biáº¿t cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng trong hÃ¬nh áº£nh. Tá»•ng há»£p (Pooling): Lá»›p tá»•ng há»£p thÆ°á»ng Ä‘áº·t sau lá»›p tÃ­ch cháº­p. Nhiá»‡m vá»¥ cá»§a lá»›p nÃ y lÃ  giáº£m kÃ­ch thÆ°á»›c cá»§a cÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng báº±ng cÃ¡ch láº¥y giÃ¡ trá»‹ lá»›n nháº¥t hoáº·c trung bÃ¬nh tá»« cÃ¡c vÃ¹ng nhá» trÃªn báº£n Ä‘á»“ Ä‘áº·c trÆ°ng. Viá»‡c nÃ y giÃºp giáº£m sá»‘ lÆ°á»£ng tham sá»‘ vÃ  chi phÃ­ tÃ­nh toÃ¡n, Ä‘á»“ng thá»i lÃ m giáº£m nguy cÆ¡ overfitting. KÃ­ch hoáº¡t (Activation): Lá»›p kÃ­ch hoáº¡t Ã¡p dá»¥ng má»™t hÃ m kÃ­ch hoáº¡t phi tuyáº¿n lÃªn cÃ¡c giÃ¡ trá»‹ trong cÃ¡c báº£n Ä‘á»“ Ä‘áº·c trÆ°ng. PhÃ©p kÃ­ch hoáº¡t nÃ y giÃºp mÃ´ hÃ¬nh há»c cÃ¡ch biá»ƒu diá»…n cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p vÃ  táº¡o tÃ­nh phi tuyáº¿n cho máº¡ng. Lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§ (Fully Connected Layer): Sau khi thÃ´ng qua cÃ¡c lá»›p tÃ­ch cháº­p, tá»•ng há»£p vÃ  kÃ­ch hoáº¡t, dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Æ°a vÃ o lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§ Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ nhÆ° phÃ¢n loáº¡i hoáº·c dá»± Ä‘oÃ¡n. Trong lá»›p nÃ y, cÃ¡c nÆ¡-ron káº¿t ná»‘i vá»›i táº¥t cáº£ cÃ¡c nÆ¡-ron trong lá»›p trÆ°á»›c, giÃºp há»c cÃ¡ch tá»• há»£p cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng. ToÃ n bá»™ quÃ¡ trÃ¬nh nÃ y, tá»« lá»›p tÃ­ch cháº­p cho Ä‘áº¿n lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§, lÃ  quÃ¡ trÃ¬nh há»c tá»± Ä‘á»™ng. Máº¡ng nÆ¡-ron tá»± Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cá»§a cÃ¡c lá»›p Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t cho nhiá»‡m vá»¥ cá»¥ thá»ƒ, cháº³ng háº¡n nhÆ° phÃ¢n loáº¡i áº£nh.",,,"#Q&A, #deep_learning",,
"ChÃ o cÃ¡c a/chá»‹ cá»§a group, em cÃ³ há»c vÃ  táº­p tÃ nh á»©ng dá»¥ng AI Ä‘Æ°á»£c trong khoáº£ng hÆ¡n 1 nÄƒm thÃ¬ cÃ³ má»™t vÃ i tháº¯c máº¯c mong a/chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p giÃºp em áº¡:
Em cÃ³ thá»­ hai máº£ng lá»›n lÃ  CV vÃ  NLP vÃ  cÅ©ng tÃ¬m tÃ²i cÃ¡c paper Ä‘á»c Ä‘á»ƒ hiá»ƒu idea rá»“i so sÃ¡nh vá»›i cÃ¡c idea khÃ¡c cÅ©ng nhÆ° rÃ¨n luyá»‡n ká»¹ nÄƒng láº­p trÃ¬nh tÆ°Æ¡ng á»©ng cho cÃ¡c paper thÃ¬ cÃ³ tháº¥y má»™t Ä‘iá»u lÃ  nghÃ nh nÃ y quÃ¡ rá»™ng Ä‘á»ƒ Ä‘Ã o sÃ¢u cho tá»«ng chuyÃªn mÃ´n náº¿u muá»‘n Ä‘áº¡t level expert. CÃ¡i nÃ y Ä‘áº·t ra cho em tháº¯c máº¯c lÃ  liá»‡u cÃ³ cÃ¡i gá»i lÃ  ""AI Engineer"" hay khÃ´ng khi mÃ  lÆ°á»£ng kiáº¿n thá»©c cá»§a má»™t máº£ng (vÃ­ dá»¥: NLP) Ä‘Ã£ thá»±c sá»± ráº¥t sÃ¢u rá»“i (theo em sÃ¢u lÃ  hiá»ƒu cáº·n káº½, biáº¿t Æ°u nhÆ°á»£c Ä‘iá»ƒm vÃ  biáº¿t cÃ¡ch tÃ¬m ra solution tá»‘i Æ°u, chÆ°a ká»ƒ cÃ¡c váº¥n Ä‘á» liÃªn quan nhÆ° data, deploy, etc.). Váº­y theo cÃ¡i title cá»§a vá»‹ trÃ­ kia thÃ¬ Ä‘á»“ng nghÄ©a há» pháº£i hiá»ƒu sÃ¢u ráº¥t nhiá»u máº£ng pháº£i khÃ´ng áº¡ ? (Nhiá»u khi cÃ²n cáº£ máº¥y máº£ng má»Ÿ rá»™ng nhÆ° kiá»ƒu Generative, Video, 3D, etc.)
Trong thá»±c táº¿ thÃ¬ má»™t flow lÃ m viá»‡c thÃ¬ má»i ngÆ°á»i thÆ°á»ng chá»n cÃ¡ch tiáº¿p cáº­n vá»›i mÃ´ hÃ¬nh nhÆ° nÃ o áº¡ ? Má»i ngÆ°á»i sáº½ code láº¡i paper tá»« Ä‘áº§u rá»“i tweak thá»§ cÃ´ng hay lÃ  sáº½ bÃª nguyÃªn wrapper nhÆ° kiá»ƒu HuggingFace Ä‘á»ƒ sá»­ dá»¥ng áº¡ ?
CÃ¡c váº¥n Ä‘á» chuyÃªn sÃ¢u vá» MLOps thÃ¬ má»™t ká»¹ sÆ° trong máº£ng nÃ y nÃªn cÃ³ trong khoáº£ng bao nÄƒm kinh nghiá»‡m áº¡ lÃ  tá»‘t áº¡ ? Liá»‡u nhÃ¢n lá»±c máº£ng nÃ y vÃ  máº£ng Software nÃ³i chung sáº½ giao thoa vá» nhá»¯ng skills gÃ¬ áº¡ ? Theo em nghÄ© lÃ  láº­p trÃ¬nh nÃ³i chung, Cloud, Design.
Em cáº£m Æ¡n a/chá»‹ nhiá»u áº¡.","ChÃ o cÃ¡c a/chá»‹ cá»§a group, em cÃ³ há»c vÃ  táº­p tÃ nh á»©ng dá»¥ng AI Ä‘Æ°á»£c trong khoáº£ng hÆ¡n 1 nÄƒm thÃ¬ cÃ³ má»™t vÃ i tháº¯c máº¯c mong a/chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p giÃºp em áº¡: Em cÃ³ thá»­ hai máº£ng lá»›n lÃ  CV vÃ  NLP vÃ  cÅ©ng tÃ¬m tÃ²i cÃ¡c paper Ä‘á»c Ä‘á»ƒ hiá»ƒu idea rá»“i so sÃ¡nh vá»›i cÃ¡c idea khÃ¡c cÅ©ng nhÆ° rÃ¨n luyá»‡n ká»¹ nÄƒng láº­p trÃ¬nh tÆ°Æ¡ng á»©ng cho cÃ¡c paper thÃ¬ cÃ³ tháº¥y má»™t Ä‘iá»u lÃ  nghÃ nh nÃ y quÃ¡ rá»™ng Ä‘á»ƒ Ä‘Ã o sÃ¢u cho tá»«ng chuyÃªn mÃ´n náº¿u muá»‘n Ä‘áº¡t level expert. CÃ¡i nÃ y Ä‘áº·t ra cho em tháº¯c máº¯c lÃ  liá»‡u cÃ³ cÃ¡i gá»i lÃ  ""AI Engineer"" hay khÃ´ng khi mÃ  lÆ°á»£ng kiáº¿n thá»©c cá»§a má»™t máº£ng (vÃ­ dá»¥: NLP) Ä‘Ã£ thá»±c sá»± ráº¥t sÃ¢u rá»“i (theo em sÃ¢u lÃ  hiá»ƒu cáº·n káº½, biáº¿t Æ°u nhÆ°á»£c Ä‘iá»ƒm vÃ  biáº¿t cÃ¡ch tÃ¬m ra solution tá»‘i Æ°u, chÆ°a ká»ƒ cÃ¡c váº¥n Ä‘á» liÃªn quan nhÆ° data, deploy, etc.). Váº­y theo cÃ¡i title cá»§a vá»‹ trÃ­ kia thÃ¬ Ä‘á»“ng nghÄ©a há» pháº£i hiá»ƒu sÃ¢u ráº¥t nhiá»u máº£ng pháº£i khÃ´ng áº¡ ? (Nhiá»u khi cÃ²n cáº£ máº¥y máº£ng má»Ÿ rá»™ng nhÆ° kiá»ƒu Generative, Video, 3D, etc.) Trong thá»±c táº¿ thÃ¬ má»™t flow lÃ m viá»‡c thÃ¬ má»i ngÆ°á»i thÆ°á»ng chá»n cÃ¡ch tiáº¿p cáº­n vá»›i mÃ´ hÃ¬nh nhÆ° nÃ o áº¡ ? Má»i ngÆ°á»i sáº½ code láº¡i paper tá»« Ä‘áº§u rá»“i tweak thá»§ cÃ´ng hay lÃ  sáº½ bÃª nguyÃªn wrapper nhÆ° kiá»ƒu HuggingFace Ä‘á»ƒ sá»­ dá»¥ng áº¡ ? CÃ¡c váº¥n Ä‘á» chuyÃªn sÃ¢u vá» MLOps thÃ¬ má»™t ká»¹ sÆ° trong máº£ng nÃ y nÃªn cÃ³ trong khoáº£ng bao nÄƒm kinh nghiá»‡m áº¡ lÃ  tá»‘t áº¡ ? Liá»‡u nhÃ¢n lá»±c máº£ng nÃ y vÃ  máº£ng Software nÃ³i chung sáº½ giao thoa vá» nhá»¯ng skills gÃ¬ áº¡ ? Theo em nghÄ© lÃ  láº­p trÃ¬nh nÃ³i chung, Cloud, Design. Em cáº£m Æ¡n a/chá»‹ nhiá»u áº¡.",,,#Q&A,,
"ChÃ o cáº£ nhÃ . Em lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o (Y khoa) nhÆ°ng Ä‘ang dá»‹ch má»™t bÃ i bÃ¡o liÃªn quan Ä‘áº¿n sá»± káº¿t há»£p giá»¯a ML vÃ  Y há»c áº¡.
Hiá»‡n táº¡i em Ä‘Ã£ dá»‹ch xong rá»“i nhÆ°ng cáº§n ngÆ°á»i cÃ³ chuyÃªn mÃ´n review vÃ¬ em khÃ´ng pháº£i ngÆ°á»i trong ngÃ nh nÃªn sá»£ chÆ°a dÃ¹ng tá»« Ä‘Ãºng chuáº©n.
Xin cáº£ nhÃ  giÃºp Ä‘á»¡ áº¡.",ChÃ o cáº£ nhÃ . Em lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o (Y khoa) nhÆ°ng Ä‘ang dá»‹ch má»™t bÃ i bÃ¡o liÃªn quan Ä‘áº¿n sá»± káº¿t há»£p giá»¯a ML vÃ  Y há»c áº¡. Hiá»‡n táº¡i em Ä‘Ã£ dá»‹ch xong rá»“i nhÆ°ng cáº§n ngÆ°á»i cÃ³ chuyÃªn mÃ´n review vÃ¬ em khÃ´ng pháº£i ngÆ°á»i trong ngÃ nh nÃªn sá»£ chÆ°a dÃ¹ng tá»« Ä‘Ãºng chuáº©n. Xin cáº£ nhÃ  giÃºp Ä‘á»¡ áº¡.,,,#Q&A,,
"Kubernetes (K8s) khÃ´ng cÃ²n lÃ  má»™t cÃ´ng cá»¥ chá»‰ Ä‘á»ƒ cháº¡y cÃ¡c workload nhÆ° á»©ng dá»¥ng web hay microservices, nÃ³ chÃ­nh lÃ  ná»n táº£ng lÃ½ tÆ°á»Ÿng Ä‘á»ƒ há»— trá»£ toÃ n bá»™ vÃ²ng Ä‘á»i cá»§a cÃ¡c workload lá»›n vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vÃ  Há»c mÃ¡y (ML), cháº³ng háº¡n nhÆ° cÃ¡c MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs).
#kubernetes #k8s #AI #LLM","Kubernetes (K8s) khÃ´ng cÃ²n lÃ  má»™t cÃ´ng cá»¥ chá»‰ Ä‘á»ƒ cháº¡y cÃ¡c workload nhÆ° á»©ng dá»¥ng web hay microservices, nÃ³ chÃ­nh lÃ  ná»n táº£ng lÃ½ tÆ°á»Ÿng Ä‘á»ƒ há»— trá»£ toÃ n bá»™ vÃ²ng Ä‘á»i cá»§a cÃ¡c workload lá»›n vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vÃ  Há»c mÃ¡y (ML), cháº³ng háº¡n nhÆ° cÃ¡c MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs).",#kubernetes	#k8s	#AI	#LLM,,#sharing,,
"MÃ¬nh tin á»Ÿ Ä‘Ã¢y cÃ³ nhiá»u báº¡n biáº¿t Ä‘áº¿n trang nÃ y https://github.com/TheAlgorithms/ do cÃ¡c báº¡n áº¤n Äá»™ viáº¿t Ä‘á»ƒ hÆ°á»›ng dáº«n vá» giáº£i thuáº­t báº±ng cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau. Trong Ä‘Ã³ repo https://github.com/TheAlgorithms/Python cÃ³ nhiá»u sao nháº¥t, vá»›i hÆ¡n 164k. Hi vá»ng, mÃ¬nh chia sáº» á»Ÿ Ä‘Ã¢y, cho cÃ¡c báº¡n chÆ°a biáº¿t tá»›i nÃ³, cÃ³ thá»ƒ lÃ  tÃ i liá»‡u tham kháº£o tá»‘t cho má»i ngÆ°á»i","MÃ¬nh tin á»Ÿ Ä‘Ã¢y cÃ³ nhiá»u báº¡n biáº¿t Ä‘áº¿n trang nÃ y https://github.com/TheAlgorithms/ do cÃ¡c báº¡n áº¤n Äá»™ viáº¿t Ä‘á»ƒ hÆ°á»›ng dáº«n vá» giáº£i thuáº­t báº±ng cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau. Trong Ä‘Ã³ repo https://github.com/TheAlgorithms/Python cÃ³ nhiá»u sao nháº¥t, vá»›i hÆ¡n 164k. Hi vá»ng, mÃ¬nh chia sáº» á»Ÿ Ä‘Ã¢y, cho cÃ¡c báº¡n chÆ°a biáº¿t tá»›i nÃ³, cÃ³ thá»ƒ lÃ  tÃ i liá»‡u tham kháº£o tá»‘t cho má»i ngÆ°á»i",,,"#sharing, #math",,
"E chÃ o cÃ¡c anh chá»‹ a, e Ä‘ang lÃ m bÃ i toÃ¡n object detection, e cÃ³ dataset vÃ  e muá»‘n visualize cáº£ bounding box lÃªn cÃ¹ng 1 áº£nh Ä‘á»ƒ check bounding box vÃ  label Ä‘Ã£ chÃ­nh xÃ¡c hay chÆ°a, E dÃ¹ng cÃ´ng cá»¥ online lÃ  roboflow nhÆ°ng nÃ³ cháº­m quÃ¡, anh chá»‹ cÃ³ biáº¿t tool nÃ o offline khÃ´ng áº¡, em cÃ¡m Æ¡n áº¡","E chÃ o cÃ¡c anh chá»‹ a, e Ä‘ang lÃ m bÃ i toÃ¡n object detection, e cÃ³ dataset vÃ  e muá»‘n visualize cáº£ bounding box lÃªn cÃ¹ng 1 áº£nh Ä‘á»ƒ check bounding box vÃ  label Ä‘Ã£ chÃ­nh xÃ¡c hay chÆ°a, E dÃ¹ng cÃ´ng cá»¥ online lÃ  roboflow nhÆ°ng nÃ³ cháº­m quÃ¡, anh chá»‹ cÃ³ biáº¿t tool nÃ o offline khÃ´ng áº¡, em cÃ¡m Æ¡n áº¡",,,"#Q&A, #cv",,
"Xin chÃ o cac ban,
Minh Ä‘Ã£ tong hop má»™t repo cung cáº¥p cÃ¡c tÃ i nguyÃªn cho OOD detection, robustness, and generalization in Deep Learning. Repo nay bao gom cÃ¡c bÃ i bÃ¡o, bÃ i nÃ³i chuyá»‡n, thÆ° viá»‡n, papers, v.v. Repo nÃ y sáº½ Ä‘Æ°á»£c duy trÃ¬ vÃ  cáº­p nháº­t vá»›i cÃ¡c nguá»“n cháº¥t lÆ°á»£ng cao! Minh hy vá»ng nÃ³ sáº½ trá»Ÿ thÃ nh mot noi lÃ½ tÆ°á»Ÿng cho báº¥t ká»³ thá»© gÃ¬ OOD trong bookmark cá»§a báº¡n. HÃ£y cho nÃ³ má»™t ngÃ´i sao de ung ho minh náº¿u báº¡n tháº¥y nÃ³ há»¯u Ã­ch;) Cam on nhieu nha!","Xin chÃ o cac ban, Minh Ä‘Ã£ tong hop má»™t repo cung cáº¥p cÃ¡c tÃ i nguyÃªn cho OOD detection, robustness, and generalization in Deep Learning. Repo nay bao gom cÃ¡c bÃ i bÃ¡o, bÃ i nÃ³i chuyá»‡n, thÆ° viá»‡n, papers, v.v. Repo nÃ y sáº½ Ä‘Æ°á»£c duy trÃ¬ vÃ  cáº­p nháº­t vá»›i cÃ¡c nguá»“n cháº¥t lÆ°á»£ng cao! Minh hy vá»ng nÃ³ sáº½ trá»Ÿ thÃ nh mot noi lÃ½ tÆ°á»Ÿng cho báº¥t ká»³ thá»© gÃ¬ OOD trong bookmark cá»§a báº¡n. HÃ£y cho nÃ³ má»™t ngÃ´i sao de ung ho minh náº¿u báº¡n tháº¥y nÃ³ há»¯u Ã­ch;) Cam on nhieu nha!",,,"#sharing, #deep_learning",,
CÃ¡c nhÃ  nghiÃªn cá»©u tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c cá»§a Anh Ä‘Ã£ phÃ¡t triá»ƒn má»™t AI cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n thao tÃ¡c gÃµ phÃ­m cá»§a ngÆ°á»i dÃ¹ng vá»›i Ä‘á»™ chÃ­nh xÃ¡c 95% báº±ng cÃ¡ch láº¯ng nghe Ã¢m thanh phÃ¡t ra khi gÃµ trÃªn bÃ n phÃ­m.,CÃ¡c nhÃ  nghiÃªn cá»©u tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c cá»§a Anh Ä‘Ã£ phÃ¡t triá»ƒn má»™t AI cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n thao tÃ¡c gÃµ phÃ­m cá»§a ngÆ°á»i dÃ¹ng vá»›i Ä‘á»™ chÃ­nh xÃ¡c 95% báº±ng cÃ¡ch láº¯ng nghe Ã¢m thanh phÃ¡t ra khi gÃµ trÃªn bÃ n phÃ­m.,,,#sharing,,
"Em chÃ o cÃ¡c tiá»n bá»‘i
Nay em ngoi lÃªn Ä‘Ã¢y Ä‘á»ƒ xin cÃ¡c tiá»n bá»‘i xem cÃ³ quyá»ƒn sÃ¡ch vÃ o vá» Reinforcement Learning hay khÃ´ng áº¡, kiá»ƒu vá»«a cÃ³ code implemented vá»«a cÃ³ pháº§n giáº£i thÃ­ch
Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡","Em chÃ o cÃ¡c tiá»n bá»‘i Nay em ngoi lÃªn Ä‘Ã¢y Ä‘á»ƒ xin cÃ¡c tiá»n bá»‘i xem cÃ³ quyá»ƒn sÃ¡ch vÃ o vá» Reinforcement Learning hay khÃ´ng áº¡, kiá»ƒu vá»«a cÃ³ code implemented vá»«a cÃ³ pháº§n giáº£i thÃ­ch Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡",,,#Q&A,,
"Hi mng, em Ä‘ang lÃ m má»™t mÃ´ hÃ¬nh nÃ³ nháº­n diá»‡n Ä‘Æ°á»£c con láº¯c Ä‘Æ¡n. Em cÃ³ chuáº©n bá»‹ má»™t táº­p dá»¯ liá»‡u báº±ng cÃ¡c hÃ¬nh áº£nh con láº¯c Ä‘Æ¡n vÃ  dÃ¹ng LabelIMG Ä‘á»ƒ label áº£nh, sau Ä‘Ã³ cho nÃ³ vÃ o má»™t file csv.
Em cÃ³ thá»­ train model trÃªn táº­p dá»¯ liá»‡u Ä‘Ã³ thÃ¬ nÃ³ cho ra má»™t káº¿t quáº£ nhÆ° áº£nh dÆ°á»›i Ä‘Ã¢y. ThÃ¬ em cÃ³ tháº¯c máº¯c lÃ  liá»‡u Ä‘Ã¢y cÃ³ fai má»™t trÆ°á»ng há»£p Overfitting vÃ  lÃ m sao Ä‘á»ƒ cÃ³ thá»ƒ sá»­a nÃ³ áº¡.
Em cÃ³ má»™t cÃ¢u há»i ná»±a lÃ  sau khi em train xong nhÆ° váº­y thÃ¬ em sáº½ lÃ m nhÆ° nÃ o Ä‘á»ƒ model cÃ³ thá»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n váº­y áº¡?
Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡ ğŸ¥¹ Em lÃ  newbie nÃªn cÃ³ nhá»¯ng chá»— em chÆ°a hiá»ƒu áº¡.","Hi mng, em Ä‘ang lÃ m má»™t mÃ´ hÃ¬nh nÃ³ nháº­n diá»‡n Ä‘Æ°á»£c con láº¯c Ä‘Æ¡n. Em cÃ³ chuáº©n bá»‹ má»™t táº­p dá»¯ liá»‡u báº±ng cÃ¡c hÃ¬nh áº£nh con láº¯c Ä‘Æ¡n vÃ  dÃ¹ng LabelIMG Ä‘á»ƒ label áº£nh, sau Ä‘Ã³ cho nÃ³ vÃ o má»™t file csv. Em cÃ³ thá»­ train model trÃªn táº­p dá»¯ liá»‡u Ä‘Ã³ thÃ¬ nÃ³ cho ra má»™t káº¿t quáº£ nhÆ° áº£nh dÆ°á»›i Ä‘Ã¢y. ThÃ¬ em cÃ³ tháº¯c máº¯c lÃ  liá»‡u Ä‘Ã¢y cÃ³ fai má»™t trÆ°á»ng há»£p Overfitting vÃ  lÃ m sao Ä‘á»ƒ cÃ³ thá»ƒ sá»­a nÃ³ áº¡. Em cÃ³ má»™t cÃ¢u há»i ná»±a lÃ  sau khi em train xong nhÆ° váº­y thÃ¬ em sáº½ lÃ m nhÆ° nÃ o Ä‘á»ƒ model cÃ³ thá»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n váº­y áº¡? Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡ Em lÃ  newbie nÃªn cÃ³ nhá»¯ng chá»— em chÆ°a hiá»ƒu áº¡.",,,"#Q&A, #cv",,
"E chÃ o cÃ¡c ace áº¡, e Ä‘ang lÃ m Ä‘á» tÃ i Fabric defect detection trÃªn Yolov8 vá»›i dataset Ä‘Æ°á»£c cung cáº¥p sáºµn, e dÃ¹ng default model YoloV8(s) Ä‘á»ƒ training nhÆ°ng káº¿t quáº£ kÃ©m quÃ¡ áº¡, Precision vÃ  recall vÃ  mAP chá»‰ táº§m 0.5 vÃ  hÃ m loss ráº¥t cao, cÃ³ pháº£i dataset cá»§a em Ä‘ang cÃ³ váº¥n Ä‘á» khÃ´ng áº¡ (em nghÄ© lÃ  cháº¥t cÃ³ thá»ƒ cháº¥t lÆ°á»£ng annontation khÃ´ng Ä‘áº£m báº£o vÃ  imbalanced áº¡), hoáº·c cÃ³ thá»ƒ do nguyÃªn nhÃ¢n nÃ o khÃ¡c mÃ  output cá»§a em kÃ©m váº­y áº¡??, mng cho e lá»i khuyÃªn Ä‘á»ƒ cáº£i thiá»‡n Ä‘Æ°á»£c khÃ´ng áº¡, em cáº£m Æ¡n ráº¥t nhiá»u áº¡!!","E chÃ o cÃ¡c ace áº¡, e Ä‘ang lÃ m Ä‘á» tÃ i Fabric defect detection trÃªn Yolov8 vá»›i dataset Ä‘Æ°á»£c cung cáº¥p sáºµn, e dÃ¹ng default model YoloV8(s) Ä‘á»ƒ training nhÆ°ng káº¿t quáº£ kÃ©m quÃ¡ áº¡, Precision vÃ  recall vÃ  mAP chá»‰ táº§m 0.5 vÃ  hÃ m loss ráº¥t cao, cÃ³ pháº£i dataset cá»§a em Ä‘ang cÃ³ váº¥n Ä‘á» khÃ´ng áº¡ (em nghÄ© lÃ  cháº¥t cÃ³ thá»ƒ cháº¥t lÆ°á»£ng annontation khÃ´ng Ä‘áº£m báº£o vÃ  imbalanced áº¡), hoáº·c cÃ³ thá»ƒ do nguyÃªn nhÃ¢n nÃ o khÃ¡c mÃ  output cá»§a em kÃ©m váº­y áº¡??, mng cho e lá»i khuyÃªn Ä‘á»ƒ cáº£i thiá»‡n Ä‘Æ°á»£c khÃ´ng áº¡, em cáº£m Æ¡n ráº¥t nhiá»u áº¡!!",,,"#Q&A, #cv",,
"Hi má»i ngÆ°á»i , mÃ¬nh cÃ³ há»c vá» Vision Transfomer vÃ  tháº¥y trong kiáº¿n trÃºc Ä‘Ã³ cÃ³ 1 thá»© gá»i lÃ  residual connection(káº¿t ná»‘i dÆ°) , nÃ³ sáº½ láº¥y input cá»§a 1 lá»›p trong 1 khá»‘i(vÃ­ dá»¥ nhÆ° khá»‘i multi self-attention) ná»‘i vá»›i output cá»§a lá»›p cuá»‘i cÃ¹ng trong khá»‘i Ä‘Ã³, mÃ¬nh Ä‘á»c thÃ¬ há» nÃ³i lÃ  trong quÃ¡ trÃ¬nh truyá»n ngÆ°á»£c, 1 sá»‘ hÃ m kÃ­ch hoáº¡t phi tuyáº¿n tÃ­nh sáº½ bá»‹ bá» qua. NhÆ°ng mÃ¬nh váº«n láº¥n cáº¥n 1 sá»‘ thá»© nhÆ° lÃ  : cá»¥ thá»ƒ má»¥c Ä‘Ã­ch vÃ  nguyÃªn nhÃ¢n há» bá» qua 1 sá»‘ lá»›p hay hÃ m kÃ­ch hoáº¡t lÃ  gÃ¬, hÃ m kÃ­ch hoáº¡t hay lá»›p kiá»ƒu j sáº½ bá»‹ loáº¡i bá» vÃ  táº¡i soa há» láº¡i ná»‘i input cá»§a 1 lá»›p nÃ y vá»›i output cá»§a lá»›p cuá»‘i cÃ¹ng. Ai cÃ³ kiáº¿n thá»©c giáº£i Ä‘Ã¡p giÃºp mÃ¬nh vá»›i áº¡. Thank má»i ngÆ°á»i!","Hi má»i ngÆ°á»i , mÃ¬nh cÃ³ há»c vá» Vision Transfomer vÃ  tháº¥y trong kiáº¿n trÃºc Ä‘Ã³ cÃ³ 1 thá»© gá»i lÃ  residual connection(káº¿t ná»‘i dÆ°) , nÃ³ sáº½ láº¥y input cá»§a 1 lá»›p trong 1 khá»‘i(vÃ­ dá»¥ nhÆ° khá»‘i multi self-attention) ná»‘i vá»›i output cá»§a lá»›p cuá»‘i cÃ¹ng trong khá»‘i Ä‘Ã³, mÃ¬nh Ä‘á»c thÃ¬ há» nÃ³i lÃ  trong quÃ¡ trÃ¬nh truyá»n ngÆ°á»£c, 1 sá»‘ hÃ m kÃ­ch hoáº¡t phi tuyáº¿n tÃ­nh sáº½ bá»‹ bá» qua. NhÆ°ng mÃ¬nh váº«n láº¥n cáº¥n 1 sá»‘ thá»© nhÆ° lÃ  : cá»¥ thá»ƒ má»¥c Ä‘Ã­ch vÃ  nguyÃªn nhÃ¢n há» bá» qua 1 sá»‘ lá»›p hay hÃ m kÃ­ch hoáº¡t lÃ  gÃ¬, hÃ m kÃ­ch hoáº¡t hay lá»›p kiá»ƒu j sáº½ bá»‹ loáº¡i bá» vÃ  táº¡i soa há» láº¡i ná»‘i input cá»§a 1 lá»›p nÃ y vá»›i output cá»§a lá»›p cuá»‘i cÃ¹ng. Ai cÃ³ kiáº¿n thá»©c giáº£i Ä‘Ã¡p giÃºp mÃ¬nh vá»›i áº¡. Thank má»i ngÆ°á»i!",,,"#Q&A, #deep_learning",,
"Má»i ngÆ°á»i cho em há»i lÃ  trong bÃ i toÃ¡n cá»§a computer vision nhÆ° object detection, segmentation,.. thÃ¬ thÆ°á»ng cÃ¡c cty sáº½ táº­n dá»¥ng cÃ¡c model Ä‘Ã£ cÃ³ sáºµn Ä‘á»ƒ á»©ng dá»¥ng trá»±c tiáº¿p vd nhÆ° YOLO, Detectron,.. hay sáº½ pháº§n lá»›n lÃ  tá»± build láº¡i áº¡? Em cáº£m Æ¡n!","Má»i ngÆ°á»i cho em há»i lÃ  trong bÃ i toÃ¡n cá»§a computer vision nhÆ° object detection, segmentation,.. thÃ¬ thÆ°á»ng cÃ¡c cty sáº½ táº­n dá»¥ng cÃ¡c model Ä‘Ã£ cÃ³ sáºµn Ä‘á»ƒ á»©ng dá»¥ng trá»±c tiáº¿p vd nhÆ° YOLO, Detectron,.. hay sáº½ pháº§n lá»›n lÃ  tá»± build láº¡i áº¡? Em cáº£m Æ¡n!",,,"#Q&A, #cv",,
"Hi má»i ngÆ°á»i,
HÃ´m nay Vietcuna trÃ¬nh báº£n phiÃªn báº£n thá»© 3 cá»§a LLM Vietcuna 7B.
ÄÃ¢y lÃ  má»™t báº£n big update tá»« má»™t mÃ´ hÃ¬nh instruction only sang model chat. NgoÃ i ra kháº£ nÄƒng code cÅ©ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ.
Äáº·c biá»‡t, Vietcuna sáº½ cho phÃ©p báº¡n dÃ¹ng trá»±c tiáº¿p trÃªn web nhÆ° ChatGPT, vÃ  sáº½ luÃ´n miá»…n phÃ­.
Link: https://chat.vilm.org/
NgoÃ i ra, báº¡n cÃ³ thá»ƒ tá»± táº£i vÃ  host model, finetune theo use case cá»¥ thá»ƒ cá»§a mÃ¬nh tá»« HuggingFace (chÃº Ã½ Ä‘á»c kÄ© Model Card). Tá»« phiÃªn báº£n thá»© 3 trá»Ÿ Ä‘i, Vietcuna chÃ­nh thá»©c miá»…n phÃ­ cho má»i má»¥c Ä‘Ã­ch sá»­ dá»¥ng.
Link HuggingFace: https://huggingface.co/vilm/vietcuna-7b-v3
ChÃºc má»i ngÆ°á»i cÃ³ má»™t tráº£i nghiá»‡m tháº­t tá»‘t :)","Hi má»i ngÆ°á»i, HÃ´m nay Vietcuna trÃ¬nh báº£n phiÃªn báº£n thá»© 3 cá»§a LLM Vietcuna 7B. ÄÃ¢y lÃ  má»™t báº£n big update tá»« má»™t mÃ´ hÃ¬nh instruction only sang model chat. NgoÃ i ra kháº£ nÄƒng code cÅ©ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ. Äáº·c biá»‡t, Vietcuna sáº½ cho phÃ©p báº¡n dÃ¹ng trá»±c tiáº¿p trÃªn web nhÆ° ChatGPT, vÃ  sáº½ luÃ´n miá»…n phÃ­. Link: https://chat.vilm.org/ NgoÃ i ra, báº¡n cÃ³ thá»ƒ tá»± táº£i vÃ  host model, finetune theo use case cá»¥ thá»ƒ cá»§a mÃ¬nh tá»« HuggingFace (chÃº Ã½ Ä‘á»c kÄ© Model Card). Tá»« phiÃªn báº£n thá»© 3 trá»Ÿ Ä‘i, Vietcuna chÃ­nh thá»©c miá»…n phÃ­ cho má»i má»¥c Ä‘Ã­ch sá»­ dá»¥ng. Link HuggingFace: https://huggingface.co/vilm/vietcuna-7b-v3 ChÃºc má»i ngÆ°á»i cÃ³ má»™t tráº£i nghiá»‡m tháº­t tá»‘t :)",,,"#sharing, #nlp",,
,nan,,,,,
"CÃ¡c bÃ¡c Æ¡i cÃ³ bÃ¡c nÃ o Ä‘ang dÃ¹ng api AI lÃ m nÃ©t áº£nh giá»‘ng snapedit hoáº·credmini ko áº¡, cho e xin gá»£i Ã½ má»™t sá»‘ api vá»›i áº¡, free cÃ ng tá»‘t. E cÃ¡m Æ¡n cÃ¡c bÃ¡c nhiá»u","CÃ¡c bÃ¡c Æ¡i cÃ³ bÃ¡c nÃ o Ä‘ang dÃ¹ng api AI lÃ m nÃ©t áº£nh giá»‘ng snapedit hoáº·credmini ko áº¡, cho e xin gá»£i Ã½ má»™t sá»‘ api vá»›i áº¡, free cÃ ng tá»‘t. E cÃ¡m Æ¡n cÃ¡c bÃ¡c nhiá»u",,,#Q&A,,
Äá»«ng Ä‘á»ƒ tiáº¿ng Anh mÃ£i lÃ  rÃ o cáº£n vá»›i báº¡n!,Äá»«ng Ä‘á»ƒ tiáº¿ng Anh mÃ£i lÃ  rÃ o cáº£n vá»›i báº¡n!,,,#sharing,,
"MÃ´ hÃ¬nh OncoNPC Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn táº¡i MIT vÃ  Viá»‡n Ung thÆ° Dana-Farber cho phÃ©p dá»± Ä‘oÃ¡n vÃ  xÃ¡c Ä‘á»‹nh nÆ¡i hÃ¬nh thÃ nh khá»‘i u trÆ°á»›c di cÄƒn thÃ´ng qua phÃ¢n tÃ­ch khoáº£ng 400 gen thÆ°á»ng bá»‹ Ä‘á»™t biáº¿n trong ung thÆ° , tá»« Ä‘Ã³ Ä‘Æ°a ra cÃ¡c liá»‡u trÃ¬nh Ä‘iá»u trá»‹ phÃ¹ há»£p vÃ  hiá»‡u quáº£ hÆ¡n so vá»›i trÆ°á»›c Ä‘Ã¢y
Má»™t bÆ°á»›c tiáº¿n má»›i trong viá»‡c Ã¡p dá»¥ng AI vÃ o Y há»c
CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm qua bÃ i viáº¿t cá»§a MIT bÃªn dÆ°á»›i","MÃ´ hÃ¬nh OncoNPC Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn táº¡i MIT vÃ  Viá»‡n Ung thÆ° Dana-Farber cho phÃ©p dá»± Ä‘oÃ¡n vÃ  xÃ¡c Ä‘á»‹nh nÆ¡i hÃ¬nh thÃ nh khá»‘i u trÆ°á»›c di cÄƒn thÃ´ng qua phÃ¢n tÃ­ch khoáº£ng 400 gen thÆ°á»ng bá»‹ Ä‘á»™t biáº¿n trong ung thÆ° , tá»« Ä‘Ã³ Ä‘Æ°a ra cÃ¡c liá»‡u trÃ¬nh Ä‘iá»u trá»‹ phÃ¹ há»£p vÃ  hiá»‡u quáº£ hÆ¡n so vá»›i trÆ°á»›c Ä‘Ã¢y Má»™t bÆ°á»›c tiáº¿n má»›i trong viá»‡c Ã¡p dá»¥ng AI vÃ o Y há»c CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm qua bÃ i viáº¿t cá»§a MIT bÃªn dÆ°á»›i",,,"#sharing, #cv",,
"Má»i ngÆ°á»i Æ¡i, em Ä‘Æ°á»£c biáº¿t lÃ  thÆ°á»ng thÃ¬ Loss Function sá»­ dá»¥ng lÃºc train vÃ  lÃºc test khÃ´ng giá»‘ng nhau. Má»i ngÆ°á»i cho em há»i cÃ¡ch xÃ¢y dá»±ng Loss Function á»Ÿ lÃºc train vÃ  lÃºc test khÃ¡c nhau nhÆ° tháº¿ nÃ o áº¡, ngoÃ i pháº§n khÃ¡c nhau vá» regularization thÃ¬ chÃºng cÃ²n khÃ¡c nhau á»Ÿ pháº§n Loss trung bÃ¬nh.
Má»i ngÆ°á»i giÃºp em hiá»ƒu rÃµ hÆ¡n vá» váº¥n Ä‘á» nÃ y vá»›i .
Em cáº£m Æ¡n !!!
Nguá»“n: Machine Learning: MÃ¬, sÃºp vÃ ....","Má»i ngÆ°á»i Æ¡i, em Ä‘Æ°á»£c biáº¿t lÃ  thÆ°á»ng thÃ¬ Loss Function sá»­ dá»¥ng lÃºc train vÃ  lÃºc test khÃ´ng giá»‘ng nhau. Má»i ngÆ°á»i cho em há»i cÃ¡ch xÃ¢y dá»±ng Loss Function á»Ÿ lÃºc train vÃ  lÃºc test khÃ¡c nhau nhÆ° tháº¿ nÃ o áº¡, ngoÃ i pháº§n khÃ¡c nhau vá» regularization thÃ¬ chÃºng cÃ²n khÃ¡c nhau á»Ÿ pháº§n Loss trung bÃ¬nh. Má»i ngÆ°á»i giÃºp em hiá»ƒu rÃµ hÆ¡n vá» váº¥n Ä‘á» nÃ y vá»›i . Em cáº£m Æ¡n !!! Nguá»“n: Machine Learning: MÃ¬, sÃºp vÃ ....",,,"#Q&A, #math, #machine_learning",,
"Em chÃ o má»i ngÆ°á»i, em cÃ³ Ä‘á»c qua cÃ¡c bÃ i viáº¿t vá» XAI. Vá» máº·t lÃ½ thuyáº¿t lÃ  nÃ³ khÃ´ng pháº£i blackbox. Tuy váº­y, em váº«n cÃ²n nhá»¯ng cÃ¢u há»i:
NhÆ°ng tháº¿ nÃ o lÃ  blackbox?
VÃ  cÃ¡c mÃ´ hÃ¬nh nhÆ° CNN vÃ  Transformer cÃ³ lÃ  cÃ¡c blackbox hay khÃ´ng?
Nhá»¯ng tiÃªu chuáº©n nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»™t mÃ´ hÃ¬nh lÃ  blackbox?
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡","Em chÃ o má»i ngÆ°á»i, em cÃ³ Ä‘á»c qua cÃ¡c bÃ i viáº¿t vá» XAI. Vá» máº·t lÃ½ thuyáº¿t lÃ  nÃ³ khÃ´ng pháº£i blackbox. Tuy váº­y, em váº«n cÃ²n nhá»¯ng cÃ¢u há»i: NhÆ°ng tháº¿ nÃ o lÃ  blackbox? VÃ  cÃ¡c mÃ´ hÃ¬nh nhÆ° CNN vÃ  Transformer cÃ³ lÃ  cÃ¡c blackbox hay khÃ´ng? Nhá»¯ng tiÃªu chuáº©n nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»™t mÃ´ hÃ¬nh lÃ  blackbox? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,"#Q&A, #deep_learning",,
"Dáº¡ em chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong group. Em lÃ  ngÆ°á»i má»›i báº¯t Ä‘áº§u há»c nÃªn muá»‘n tÃ¬m cÃ¡c sÃ¡ch vá» Machine learning báº±ng tiáº¿ng Viá»‡t áº¡. Anh, chá»‹, báº¡n nÃ o cÃ³ sÃ¡ch giáº¥y Ä‘Ã£ há»c xong khÃ´ng dÃ¹ng ná»¯a cÃ³ thá»ƒ pass láº¡i cho em khÃ´ng áº¡. Em á»Ÿ SÃ i GÃ²n áº¡.","Dáº¡ em chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong group. Em lÃ  ngÆ°á»i má»›i báº¯t Ä‘áº§u há»c nÃªn muá»‘n tÃ¬m cÃ¡c sÃ¡ch vá» Machine learning báº±ng tiáº¿ng Viá»‡t áº¡. Anh, chá»‹, báº¡n nÃ o cÃ³ sÃ¡ch giáº¥y Ä‘Ã£ há»c xong khÃ´ng dÃ¹ng ná»¯a cÃ³ thá»ƒ pass láº¡i cho em khÃ´ng áº¡. Em á»Ÿ SÃ i GÃ²n áº¡.",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i , em lÃ  ngÆ°á»i má»›i há»c ML , em Ä‘ang lÃ m 1 dá»± Ã¡n phÃ¢n loáº¡i hÃ¬nh áº£nh ( 1 sá»‘ loáº¡i hoa ) thÃ´ng qua app , model cá»§a em cháº¡y á»Ÿ phÃ­a server . Chuyá»‡n lÃ  em dÃ¹ng model mobilenet_v2 cá»§a tensorflow hub Ä‘á»ƒ transfer , sau Ä‘Ã³ lÆ°u model báº±ng lá»‡nh : model.save(os.path.join('/content/drive/MyDrive/models','flower.h5')) .
sau Ä‘Ã³ load láº¡i vÃ  sá»­ dá»¥ng model báº±ng cÃ¡ch gá»i :
flower_model = tf.keras.models.load_model(
(""model/flower/model_flower.h5""),
custom_objects={'KerasLayer':hub.KerasLayer}
)
nÃ³ hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng nhÆ°ng sau Ä‘Ã³ 1 khoáº£ng thá»i gian thÃ¬ nÃ³ láº¡i khÃ´ng cháº¡y Ä‘Æ°á»£c . nÃ³ bÃ¡o : Exception encountered: Trying to load a model of incompatible/unknown type.
'C:\Users\Lenovo\AppData\Local\Temp\tfhub_modules\145bb06ec3b59b08fb564ab752bd5aa222bfb50a' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.
vá» cÆ¡ báº£n thÃ¬ em Ä‘Ã£ cÃ³ thá»ƒ fix Ä‘Æ°á»£c lá»—i báº±ng cÃ¡ch xÃ³a cÃ¡i folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a Ä‘i Ä‘á»ƒ tiáº¿n hÃ nh táº£i láº¡i cÃ¡i má»›i . nÃ³ hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng nhÆ°ng Ä‘áº¥y chá»‰ lÃ  cÃ¡ch trá»‹ ngá»n thÃ´i khÃ´ng trá»‹ Ä‘Æ°á»£c gá»‘c vÃ¬ sau 1 khoáº£ng thá»i gian nÃ³ láº¡i ko hoáº¡t Ä‘á»™ng .
Nhá»¯ng gÃ¬ em hiá»ƒu Ä‘Æ°á»£c lÃ  : TensorFlow sáº½ táº¡o má»™t thÆ° má»¥c táº¡m thá»i Ä‘á»ƒ giá»¯ cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ táº£i; tuy nhiÃªn, sau má»™t vÃ i ngÃ y hoáº·c lÃ¢u hÆ¡n, ná»™i dung cá»§a cÃ¡c foler (mÃ´ hÃ¬nh Ä‘Ã£ táº£i) sáº½ bá»‹ xÃ³a. Sau Ä‘Ã³, khi muá»‘n táº£i láº¡i má»™t mÃ´ hÃ¬nh, TensorFlow sáº½ Ä‘á»‹nh tuyáº¿n Ä‘áº¿n thÆ° má»¥c táº¡m thá»i, nhÆ°ng mÃ´ hÃ¬nh sáº½ bá»‹ xÃ³a khá»i thÆ° má»¥c táº¡m thá»i. Tá»©c lÃ  cÃ¡i cáº§n thiáº¿t Ä‘á»ƒ cháº¡y pre model lÃ  má»™t model( táº£i tá»« tensorflow hub ) Ä‘ang Ä‘Æ°á»£c lÆ°u trá»¯ á»Ÿ 1 thÆ° má»¥c táº¡m thá»i ( thÆ° má»¥c sáº½ bá»‹ xÃ³a sau má»™t khoáº£ng thá»i gian ) vÃ¬ váº­y nÃ³ sáº½ gÃ¢y ra lá»—i ko tÃ¬m tháº¥y file .pb hay .pbtxt Ä‘á»ƒ cháº¡y model .
Em nghÄ© ráº±ng lá»—i sáº½ náº±m á»Ÿ pháº§n tensorflow nÃ³ quáº£n lÃ½ tá»± Ä‘á»™ng file pb ( pbtxt) khiáº¿n cho mÃ¬nh ko thá»ƒ chá»‰ Ä‘á»‹nh chÃ­nh xÃ¡c 2 file pb vÃ  pbtxt vÃ o 1 Ä‘Æ°á»ng dáº«n cá»¥ thá»ƒ ( ko thá»ƒ bá»‹ xÃ³a tá»± Ä‘á»™ng ) . Hoáº·c lá»—i gÃ¢y ra bá»Ÿi quÃ¡ trÃ¬nh load model .
Má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng gáº·p lá»—i tÆ°Æ¡ng tá»¥ nhÆ° váº­y chÆ°a cho em hÆ°á»›ng dáº«n fix vá»›i .
ÄÃ¢y lÃ  nhá»¯ng gÃ¬ trong folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a","ChÃ o má»i ngÆ°á»i , em lÃ  ngÆ°á»i má»›i há»c ML , em Ä‘ang lÃ m 1 dá»± Ã¡n phÃ¢n loáº¡i hÃ¬nh áº£nh ( 1 sá»‘ loáº¡i hoa ) thÃ´ng qua app , model cá»§a em cháº¡y á»Ÿ phÃ­a server . Chuyá»‡n lÃ  em dÃ¹ng model mobilenet_v2 cá»§a tensorflow hub Ä‘á»ƒ transfer , sau Ä‘Ã³ lÆ°u model báº±ng lá»‡nh : model.save(os.path.join('/content/drive/MyDrive/models','flower.h5')) . sau Ä‘Ã³ load láº¡i vÃ  sá»­ dá»¥ng model báº±ng cÃ¡ch gá»i : flower_model = tf.keras.models.load_model( (""model/flower/model_flower.h5""), custom_objects={'KerasLayer':hub.KerasLayer} ) nÃ³ hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng nhÆ°ng sau Ä‘Ã³ 1 khoáº£ng thá»i gian thÃ¬ nÃ³ láº¡i khÃ´ng cháº¡y Ä‘Æ°á»£c . nÃ³ bÃ¡o : Exception encountered: Trying to load a model of incompatible/unknown type. 'C:\Users\Lenovo\AppData\Local\Temp\tfhub_modules\145bb06ec3b59b08fb564ab752bd5aa222bfb50a' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'. vá» cÆ¡ báº£n thÃ¬ em Ä‘Ã£ cÃ³ thá»ƒ fix Ä‘Æ°á»£c lá»—i báº±ng cÃ¡ch xÃ³a cÃ¡i folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a Ä‘i Ä‘á»ƒ tiáº¿n hÃ nh táº£i láº¡i cÃ¡i má»›i . nÃ³ hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng nhÆ°ng Ä‘áº¥y chá»‰ lÃ  cÃ¡ch trá»‹ ngá»n thÃ´i khÃ´ng trá»‹ Ä‘Æ°á»£c gá»‘c vÃ¬ sau 1 khoáº£ng thá»i gian nÃ³ láº¡i ko hoáº¡t Ä‘á»™ng . Nhá»¯ng gÃ¬ em hiá»ƒu Ä‘Æ°á»£c lÃ  : TensorFlow sáº½ táº¡o má»™t thÆ° má»¥c táº¡m thá»i Ä‘á»ƒ giá»¯ cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ táº£i; tuy nhiÃªn, sau má»™t vÃ i ngÃ y hoáº·c lÃ¢u hÆ¡n, ná»™i dung cá»§a cÃ¡c foler (mÃ´ hÃ¬nh Ä‘Ã£ táº£i) sáº½ bá»‹ xÃ³a. Sau Ä‘Ã³, khi muá»‘n táº£i láº¡i má»™t mÃ´ hÃ¬nh, TensorFlow sáº½ Ä‘á»‹nh tuyáº¿n Ä‘áº¿n thÆ° má»¥c táº¡m thá»i, nhÆ°ng mÃ´ hÃ¬nh sáº½ bá»‹ xÃ³a khá»i thÆ° má»¥c táº¡m thá»i. Tá»©c lÃ  cÃ¡i cáº§n thiáº¿t Ä‘á»ƒ cháº¡y pre model lÃ  má»™t model( táº£i tá»« tensorflow hub ) Ä‘ang Ä‘Æ°á»£c lÆ°u trá»¯ á»Ÿ 1 thÆ° má»¥c táº¡m thá»i ( thÆ° má»¥c sáº½ bá»‹ xÃ³a sau má»™t khoáº£ng thá»i gian ) vÃ¬ váº­y nÃ³ sáº½ gÃ¢y ra lá»—i ko tÃ¬m tháº¥y file .pb hay .pbtxt Ä‘á»ƒ cháº¡y model . Em nghÄ© ráº±ng lá»—i sáº½ náº±m á»Ÿ pháº§n tensorflow nÃ³ quáº£n lÃ½ tá»± Ä‘á»™ng file pb ( pbtxt) khiáº¿n cho mÃ¬nh ko thá»ƒ chá»‰ Ä‘á»‹nh chÃ­nh xÃ¡c 2 file pb vÃ  pbtxt vÃ o 1 Ä‘Æ°á»ng dáº«n cá»¥ thá»ƒ ( ko thá»ƒ bá»‹ xÃ³a tá»± Ä‘á»™ng ) . Hoáº·c lá»—i gÃ¢y ra bá»Ÿi quÃ¡ trÃ¬nh load model . Má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng gáº·p lá»—i tÆ°Æ¡ng tá»¥ nhÆ° váº­y chÆ°a cho em hÆ°á»›ng dáº«n fix vá»›i . ÄÃ¢y lÃ  nhá»¯ng gÃ¬ trong folder 145bb06ec3b59b08fb564ab752bd5aa222bfb50a",,,"#Q&A, #python, #cv",,
9 FREE [#GenerativeAI] Courses from Google,9 FREE [#GenerativeAI] Courses from Google,,,,,
"Full Project: Airline Passenger Booking Analyze and Forecast using ML
---
TÃ i liá»‡u hÆ°á»›ng dáº«n Tá»«ng step by step cho 1 Project ML:
- TÃ¬m hiá»ƒu dá»¯ liá»‡u,
- Quan sÃ¡t dá»¯ liá»‡u,
- Pre processsing : GÃ¡n nhÃ£n, phÃ¢n loáº¡i dá»¯ liá»‡u. Chia tá»‡p Data thÃ nh cÃ¡c biáº¿n Ä‘á»™c láº­p vÃ  phá»¥ thuá»™c. Chia data thÃ nh Training & Test Dataset.
- Táº¡o ML Modeling function Ä‘á»ƒ Ã¡p dá»¥ng thuáº­t toÃ¡n phÃ¢n loáº¡i
- Link download: https://bit.ly/Drive-MachineLearning
----------------
TÃ i liá»‡u Ä‘Æ°á»£c chia sáº» bá»Ÿi: Learning&sharing for machine learning & Ai","Full Project: Airline Passenger Booking Analyze and Forecast using ML --- TÃ i liá»‡u hÆ°á»›ng dáº«n Tá»«ng step by step cho 1 Project ML: - TÃ¬m hiá»ƒu dá»¯ liá»‡u, - Quan sÃ¡t dá»¯ liá»‡u, - Pre processsing : GÃ¡n nhÃ£n, phÃ¢n loáº¡i dá»¯ liá»‡u. Chia tá»‡p Data thÃ nh cÃ¡c biáº¿n Ä‘á»™c láº­p vÃ  phá»¥ thuá»™c. Chia data thÃ nh Training & Test Dataset. - Táº¡o ML Modeling function Ä‘á»ƒ Ã¡p dá»¥ng thuáº­t toÃ¡n phÃ¢n loáº¡i - Link download: https://bit.ly/Drive-MachineLearning ---------------- TÃ i liá»‡u Ä‘Æ°á»£c chia sáº» bá»Ÿi: Learning&sharing for machine learning & Ai",,,"#sharing, #machine_learning, #data",,
"CUá»N SÃCH KHÃ”NG THá»‚ Bá» QUA Vá»€ AUTOMATED MACHINE LEARNING
Cuá»‘n sÃ¡ch nÃ y giÃºp báº¡n hiá»ƒu rÃµ vá» AutoML - tá»± Ä‘á»™ng hÃ³a quÃ¡ trÃ¬nh há»c mÃ¡y.
âœ… Hiá»ƒu vá» AutoML vÃ  vai trÃ² quan trá»ng cá»§a AutoML trong viá»‡c Ä‘Æ¡n giáº£n hÃ³a quÃ¡ trÃ¬nh há»c mÃ¡y.
âœ… KhÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p vÃ  ká»¹ thuáº­t sá»­ dá»¥ng trong AutoML, tá»« viá»‡c chá»n Ä‘áº·c trÆ°ng, lá»±a chá»n mÃ´ hÃ¬nh, Ä‘iá»u chá»‰nh siÃªu tham sá»‘ Ä‘áº¿n Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.
âœ… TÃ¬m hiá»ƒu vá» cÃ¡c há»‡ thá»‘ng vÃ  cÃ´ng cá»¥ AutoML hiá»‡n cÃ³ trÃªn thá»‹ trÆ°á»ng, qua cÃ¡c vÃ­ dá»¥ vÃ  nghiÃªn cá»©u thá»±c táº¿.
âœ… Äá»‘i máº·t vÃ  vÆ°á»£t qua cÃ¡c thÃ¡ch thá»©c, nhÆ° kháº£ nÄƒng má»Ÿ rá»™ng, kháº£ nÄƒng giáº£i thÃ­ch vÃ  xá»­ lÃ½ dá»¯ liá»‡u phá»©c táº¡p.
âœ… Äá»™ tin cáº­y trong cÃ¡c há»‡ thá»‘ng há»c mÃ¡y tá»± Ä‘á»™ng.
ğŸ“š Cuá»‘n sÃ¡ch cung cáº¥p cÃ¡c á»©ng dá»¥ng thá»±c táº¿ cá»§a AutoML trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau nhÆ° y táº¿, tÃ i chÃ­nh vÃ  marketing, giÃºp báº¡n tháº¥y rÃµ lá»£i Ã­ch cá»§a AutoML trong viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y chÃ­nh xÃ¡c má»™t cÃ¡ch nhanh chÃ³ng.
Link download qua drive dÆ°á»›i comment.
---------------
TÃ i liá»‡u Ä‘Æ°á»£c chia sáº» bá»Ÿi: Learning and Sharing for Machine Learning & AI","CUá»N SÃCH KHÃ”NG THá»‚ Bá» QUA Vá»€ AUTOMATED MACHINE LEARNING Cuá»‘n sÃ¡ch nÃ y giÃºp báº¡n hiá»ƒu rÃµ vá» AutoML - tá»± Ä‘á»™ng hÃ³a quÃ¡ trÃ¬nh há»c mÃ¡y. Hiá»ƒu vá» AutoML vÃ  vai trÃ² quan trá»ng cá»§a AutoML trong viá»‡c Ä‘Æ¡n giáº£n hÃ³a quÃ¡ trÃ¬nh há»c mÃ¡y. KhÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p vÃ  ká»¹ thuáº­t sá»­ dá»¥ng trong AutoML, tá»« viá»‡c chá»n Ä‘áº·c trÆ°ng, lá»±a chá»n mÃ´ hÃ¬nh, Ä‘iá»u chá»‰nh siÃªu tham sá»‘ Ä‘áº¿n Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. TÃ¬m hiá»ƒu vá» cÃ¡c há»‡ thá»‘ng vÃ  cÃ´ng cá»¥ AutoML hiá»‡n cÃ³ trÃªn thá»‹ trÆ°á»ng, qua cÃ¡c vÃ­ dá»¥ vÃ  nghiÃªn cá»©u thá»±c táº¿. Äá»‘i máº·t vÃ  vÆ°á»£t qua cÃ¡c thÃ¡ch thá»©c, nhÆ° kháº£ nÄƒng má»Ÿ rá»™ng, kháº£ nÄƒng giáº£i thÃ­ch vÃ  xá»­ lÃ½ dá»¯ liá»‡u phá»©c táº¡p. Äá»™ tin cáº­y trong cÃ¡c há»‡ thá»‘ng há»c mÃ¡y tá»± Ä‘á»™ng. Cuá»‘n sÃ¡ch cung cáº¥p cÃ¡c á»©ng dá»¥ng thá»±c táº¿ cá»§a AutoML trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau nhÆ° y táº¿, tÃ i chÃ­nh vÃ  marketing, giÃºp báº¡n tháº¥y rÃµ lá»£i Ã­ch cá»§a AutoML trong viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y chÃ­nh xÃ¡c má»™t cÃ¡ch nhanh chÃ³ng. Link download qua drive dÆ°á»›i comment. --------------- TÃ i liá»‡u Ä‘Æ°á»£c chia sáº» bá»Ÿi: Learning and Sharing for Machine Learning & AI",,,"#sharing, #machine_learning",,
,nan,,,,,
"Máº¡ng nÆ¡-ron há»“i quy Ä‘a lá»›p phÃ¢n tÃ¡n (Distributed Multilayer Recurrent Neural Network - DM-RNN) lÃ  má»™t kiá»ƒu máº¡ng nÆ¡-ron há»“i quy (RNN) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ thÃ´ng tin tá»« nhiá»u nguá»“n Ä‘á»“ng thá»i vÃ  Ä‘a lá»›p. NÃ³ lÃ  má»™t biáº¿n thá»ƒ cá»§a máº¡ng nÆ¡-ron há»“i quy Ä‘a lá»›p (ML-RNN), trong Ä‘Ã³ cÃ¡c Ä‘Æ¡n vá»‹ nÆ¡-ron trong máº¡ng Ä‘Æ°á»£c phÃ¢n chia thÃ nh nhiá»u nhÃ³m, vÃ  má»—i nhÃ³m chá»‰ xá»­ lÃ½ má»™t pháº§n cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o.
MÃ´ hÃ¬nh DM-RNN giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a máº¡ng há»“i quy khi xá»­ lÃ½ dá»¯ liá»‡u phá»©c táº¡p vÃ  Ä‘a nguá»“n, nhÆ° trong cÃ¡c á»©ng dá»¥ng nhÆ° xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nháº­n dáº¡ng giá»ng nÃ³i, dá»± Ä‘oÃ¡n chuá»—i thá»i gian vÃ  nhiá»u tÃ¡c vá»¥ há»c táº­p khÃ¡c. Báº±ng cÃ¡ch phÃ¢n tÃ¡n cÃ¡c Ä‘Æ¡n vá»‹ nÆ¡-ron, máº¡ng DM-RNN cÃ³ kháº£ nÄƒng xá»­ lÃ½ thÃ´ng tin tá»« nhiá»u nguá»“n cÃ¹ng má»™t lÃºc vÃ  truyá»n táº£i thÃ´ng tin giá»¯a cÃ¡c lá»›p máº¡ng má»™t cÃ¡ch hiá»‡u quáº£.
CÃ¡c Æ°u Ä‘iá»ƒm cá»§a máº¡ng DM-RNN bao gá»“m:
Xá»­ lÃ½ Ä‘a nguá»“n: Máº¡ng DM-RNN cho phÃ©p xá»­ lÃ½ thÃ´ng tin tá»« nhiá»u nguá»“n Ä‘á»“ng thá»i, giÃºp cáº£i thiá»‡n kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u phá»©c táº¡p vÃ  Ä‘a dáº¡ng.
Hiá»‡u quáº£ tÃ­nh toÃ¡n: Do cÃ¡c Ä‘Æ¡n vá»‹ nÆ¡-ron Ä‘Æ°á»£c phÃ¢n tÃ¡n vÃ  chá»‰ xá»­ lÃ½ má»™t pháº§n dá»¯ liá»‡u, máº¡ng DM-RNN cÃ³ kháº£ nÄƒng tÃ­nh toÃ¡n hiá»‡u quáº£ vÃ  trÃ¡nh cÃ¡c váº¥n Ä‘á» vá» tÃ­nh toÃ¡n phá»©c táº¡p.
TÃ­nh linh hoáº¡t: Máº¡ng DM-RNN cÃ³ tÃ­nh linh hoáº¡t cao trong viá»‡c káº¿t há»£p cÃ¡c nguá»“n thÃ´ng tin khÃ¡c nhau vÃ  Ä‘iá»u chá»‰nh kiáº¿n trÃºc máº¡ng dá»… dÃ ng Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ¡c tÃ¡c vá»¥ xá»­ lÃ½ dá»¯ liá»‡u cá»¥ thá»ƒ.
Tuy nhiÃªn, máº¡ng DM-RNN cÅ©ng cÃ³ má»™t sá»‘ thÃ¡ch thá»©c, bao gá»“m:
ÄÃ²i há»i nhiá»u dá»¯ liá»‡u huáº¥n luyá»‡n: Do mÃ´ hÃ¬nh cÃ³ nhiá»u tham sá»‘ vÃ  cáº¥u trÃºc phá»©c táº¡p, viá»‡c huáº¥n luyá»‡n máº¡ng DM-RNN cÃ³ thá»ƒ Ä‘Ã²i há»i má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t.
Äiá»u chá»‰nh tham sá»‘ phá»©c táº¡p: Viá»‡c Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ vÃ  kiáº¿n trÃºc cá»§a máº¡ng DM-RNN cÃ³ thá»ƒ phá»©c táº¡p vÃ  Ä‘Ã²i há»i sá»± chuyÃªn mÃ´n cao.
Má»™t sá»‘ á»©ng dá»¥ng cá»§a máº¡ng DM-RNN bao gá»“m xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nháº­n dáº¡ng giá»ng nÃ³i, dá»± Ä‘oÃ¡n chuá»—i thá»i gian vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u chuá»—i. MÃ´ hÃ¬nh nÃ y Ä‘Ã£ Ä‘em láº¡i nhá»¯ng káº¿t quáº£ Ä‘Ã¡ng ká»ƒ trong viá»‡c xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u phá»©c táº¡p vÃ  Ä‘a nguá»“n.","Máº¡ng nÆ¡-ron há»“i quy Ä‘a lá»›p phÃ¢n tÃ¡n (Distributed Multilayer Recurrent Neural Network - DM-RNN) lÃ  má»™t kiá»ƒu máº¡ng nÆ¡-ron há»“i quy (RNN) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ thÃ´ng tin tá»« nhiá»u nguá»“n Ä‘á»“ng thá»i vÃ  Ä‘a lá»›p. NÃ³ lÃ  má»™t biáº¿n thá»ƒ cá»§a máº¡ng nÆ¡-ron há»“i quy Ä‘a lá»›p (ML-RNN), trong Ä‘Ã³ cÃ¡c Ä‘Æ¡n vá»‹ nÆ¡-ron trong máº¡ng Ä‘Æ°á»£c phÃ¢n chia thÃ nh nhiá»u nhÃ³m, vÃ  má»—i nhÃ³m chá»‰ xá»­ lÃ½ má»™t pháº§n cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o. MÃ´ hÃ¬nh DM-RNN giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a máº¡ng há»“i quy khi xá»­ lÃ½ dá»¯ liá»‡u phá»©c táº¡p vÃ  Ä‘a nguá»“n, nhÆ° trong cÃ¡c á»©ng dá»¥ng nhÆ° xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nháº­n dáº¡ng giá»ng nÃ³i, dá»± Ä‘oÃ¡n chuá»—i thá»i gian vÃ  nhiá»u tÃ¡c vá»¥ há»c táº­p khÃ¡c. Báº±ng cÃ¡ch phÃ¢n tÃ¡n cÃ¡c Ä‘Æ¡n vá»‹ nÆ¡-ron, máº¡ng DM-RNN cÃ³ kháº£ nÄƒng xá»­ lÃ½ thÃ´ng tin tá»« nhiá»u nguá»“n cÃ¹ng má»™t lÃºc vÃ  truyá»n táº£i thÃ´ng tin giá»¯a cÃ¡c lá»›p máº¡ng má»™t cÃ¡ch hiá»‡u quáº£. CÃ¡c Æ°u Ä‘iá»ƒm cá»§a máº¡ng DM-RNN bao gá»“m: Xá»­ lÃ½ Ä‘a nguá»“n: Máº¡ng DM-RNN cho phÃ©p xá»­ lÃ½ thÃ´ng tin tá»« nhiá»u nguá»“n Ä‘á»“ng thá»i, giÃºp cáº£i thiá»‡n kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u phá»©c táº¡p vÃ  Ä‘a dáº¡ng. Hiá»‡u quáº£ tÃ­nh toÃ¡n: Do cÃ¡c Ä‘Æ¡n vá»‹ nÆ¡-ron Ä‘Æ°á»£c phÃ¢n tÃ¡n vÃ  chá»‰ xá»­ lÃ½ má»™t pháº§n dá»¯ liá»‡u, máº¡ng DM-RNN cÃ³ kháº£ nÄƒng tÃ­nh toÃ¡n hiá»‡u quáº£ vÃ  trÃ¡nh cÃ¡c váº¥n Ä‘á» vá» tÃ­nh toÃ¡n phá»©c táº¡p. TÃ­nh linh hoáº¡t: Máº¡ng DM-RNN cÃ³ tÃ­nh linh hoáº¡t cao trong viá»‡c káº¿t há»£p cÃ¡c nguá»“n thÃ´ng tin khÃ¡c nhau vÃ  Ä‘iá»u chá»‰nh kiáº¿n trÃºc máº¡ng dá»… dÃ ng Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ¡c tÃ¡c vá»¥ xá»­ lÃ½ dá»¯ liá»‡u cá»¥ thá»ƒ. Tuy nhiÃªn, máº¡ng DM-RNN cÅ©ng cÃ³ má»™t sá»‘ thÃ¡ch thá»©c, bao gá»“m: ÄÃ²i há»i nhiá»u dá»¯ liá»‡u huáº¥n luyá»‡n: Do mÃ´ hÃ¬nh cÃ³ nhiá»u tham sá»‘ vÃ  cáº¥u trÃºc phá»©c táº¡p, viá»‡c huáº¥n luyá»‡n máº¡ng DM-RNN cÃ³ thá»ƒ Ä‘Ã²i há»i má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t. Äiá»u chá»‰nh tham sá»‘ phá»©c táº¡p: Viá»‡c Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ vÃ  kiáº¿n trÃºc cá»§a máº¡ng DM-RNN cÃ³ thá»ƒ phá»©c táº¡p vÃ  Ä‘Ã²i há»i sá»± chuyÃªn mÃ´n cao. Má»™t sá»‘ á»©ng dá»¥ng cá»§a máº¡ng DM-RNN bao gá»“m xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nháº­n dáº¡ng giá»ng nÃ³i, dá»± Ä‘oÃ¡n chuá»—i thá»i gian vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u chuá»—i. MÃ´ hÃ¬nh nÃ y Ä‘Ã£ Ä‘em láº¡i nhá»¯ng káº¿t quáº£ Ä‘Ã¡ng ká»ƒ trong viá»‡c xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u phá»©c táº¡p vÃ  Ä‘a nguá»“n.",,,"#deep_learning, #sharing",,
"ChÃ o cÃ¡c anh chá»‹, anh chá»‹ cho há»i em má»›i báº¯t Ä‘áº§u há»c cÃ¡c khÃ³a ML cá»§a bÃ¡c Andrew Ng trÃªn cousera thÃ¬ tháº¥y á»Ÿ cuá»‘i thÆ°á»ng cÃ³ optional lab nhÆ°ng mÃ  nÃ³ khÃ´ng giáº£i thÃ­ch Ã½ nghÄ©a, cÃ¡ch dÃ¹ng tá»«ng cÃ¢u lá»‡nh. Váº­y em pháº£i tá»± há»c thÃªm cÃ¡ch sá»­ dá»¥ng máº¥y thÆ° viá»‡n nhÆ° numpy,... á»Ÿ ngoÃ i pháº£i khÃ´ng áº¡ táº¡i em cÅ©ng chÆ°a biáº¿t gÃ¬ vá» python láº¯m áº¡. Em xin cáº£m Æ¡n.","ChÃ o cÃ¡c anh chá»‹, anh chá»‹ cho há»i em má»›i báº¯t Ä‘áº§u há»c cÃ¡c khÃ³a ML cá»§a bÃ¡c Andrew Ng trÃªn cousera thÃ¬ tháº¥y á»Ÿ cuá»‘i thÆ°á»ng cÃ³ optional lab nhÆ°ng mÃ  nÃ³ khÃ´ng giáº£i thÃ­ch Ã½ nghÄ©a, cÃ¡ch dÃ¹ng tá»«ng cÃ¢u lá»‡nh. Váº­y em pháº£i tá»± há»c thÃªm cÃ¡ch sá»­ dá»¥ng máº¥y thÆ° viá»‡n nhÆ° numpy,... á»Ÿ ngoÃ i pháº£i khÃ´ng áº¡ táº¡i em cÅ©ng chÆ°a biáº¿t gÃ¬ vá» python láº¯m áº¡. Em xin cáº£m Æ¡n.",,,"#machine_learning, #Q&A, #python",,
"Cho báº¡n nÃ o chÆ°a biáº¿t , cÅ©ng nhÆ° váº«n Ä‘ang Ä‘á»£i request tá»« Meta Ä‘á»ƒ access LLaMA 2
Hiá»‡n táº¡i , Meta Ä‘Ã£ má»Ÿ link má»›i Ä‘á»ƒ request access vÃ o LLaMA 2 , cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘iá»n form láº¡i , cÅ©ng nhÆ° Ä‘á»“ng bá»™ vá»›i repo cá»§a Meta trÃªn Hugging Face ( email khi báº¡n Ä‘iá»n form pháº£i Ä‘Ãºng vá»›i email tÃ i khoáº£n trÃªn huggingface má»›i access Ä‘Æ°á»£c repo nhÃ© )
Báº¡n nÃ o muá»‘n tráº£i nghiá»‡m model LLaMA 2 cÃ³ thá»ƒ Ä‘Äƒng kÃ½ qua form bÃªn dÆ°á»›i
https://ai.meta.com/.../models-and.../llama-downloads/","Cho báº¡n nÃ o chÆ°a biáº¿t , cÅ©ng nhÆ° váº«n Ä‘ang Ä‘á»£i request tá»« Meta Ä‘á»ƒ access LLaMA 2 Hiá»‡n táº¡i , Meta Ä‘Ã£ má»Ÿ link má»›i Ä‘á»ƒ request access vÃ o LLaMA 2 , cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘iá»n form láº¡i , cÅ©ng nhÆ° Ä‘á»“ng bá»™ vá»›i repo cá»§a Meta trÃªn Hugging Face ( email khi báº¡n Ä‘iá»n form pháº£i Ä‘Ãºng vá»›i email tÃ i khoáº£n trÃªn huggingface má»›i access Ä‘Æ°á»£c repo nhÃ© ) Báº¡n nÃ o muá»‘n tráº£i nghiá»‡m model LLaMA 2 cÃ³ thá»ƒ Ä‘Äƒng kÃ½ qua form bÃªn dÆ°á»›i https://ai.meta.com/.../models-and.../llama-downloads/",,,#sharing,,
"ChÃ o má»i ngÆ°á»i áº¡, cho em há»i lÃ  em táº­p data vá»›i má»—i hÃ¬nh kÃ­ch thÆ°á»›c 5120x5120 thÃ¬ cÃ³ cÃ¡ch nÃ o em giáº£m kÃ­ch thÆ°á»›c mÃ  tá»‘i Æ°u nháº¥t khÃ´ng áº¡. VÃ  viá»‡c em cáº¯t thÃ nh 20 áº£nh kÃ­ch thÆ°á»›c 256x256 liá»‡u sau khi train cÃ³ áº£nh hÆ°á»Ÿng tá»›i tÃ­nh tá»•ng quÃ¡t cá»§a bá»©c hÃ¬nh khÃ´ng áº¡. Em cáº£m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i áº¡, cho em há»i lÃ  em táº­p data vá»›i má»—i hÃ¬nh kÃ­ch thÆ°á»›c 5120x5120 thÃ¬ cÃ³ cÃ¡ch nÃ o em giáº£m kÃ­ch thÆ°á»›c mÃ  tá»‘i Æ°u nháº¥t khÃ´ng áº¡. VÃ  viá»‡c em cáº¯t thÃ nh 20 áº£nh kÃ­ch thÆ°á»›c 256x256 liá»‡u sau khi train cÃ³ áº£nh hÆ°á»Ÿng tá»›i tÃ­nh tá»•ng quÃ¡t cá»§a bá»©c hÃ¬nh khÃ´ng áº¡. Em cáº£m Æ¡n áº¡",,,#Q&A. #data,,
"[GÃ³c tÃ¬m developers]
Xin Update: váº©n cáº§n team lÃ m Ä‘Æ°á»£c
TÃ i chÃ­nh 200 chá»‹u quay Ä‘áº§u, há»£p Ä‘á»“ng cÃ´ng chá»©ng Ä‘Ã ng hoÃ ng.
Xin chÃ o anh em, mÃ¬nh cÃ³ vÃ i idea váº§y cÃ³ anh em nÃ o cÃ³ thá»ƒ lÃ m forex/stock/crypto/metal trading engine nhÆ° sau khÃ´ng áº¡? Xin chÃ¢n thÃ nh tÃ¬m Ä‘Æ°á»£c ngÆ°á»i
Xin cÃ¡m Æ¡n cÃ¡i devs","[GÃ³c tÃ¬m developers] Xin Update: váº©n cáº§n team lÃ m Ä‘Æ°á»£c TÃ i chÃ­nh 200 chá»‹u quay Ä‘áº§u, há»£p Ä‘á»“ng cÃ´ng chá»©ng Ä‘Ã ng hoÃ ng. Xin chÃ o anh em, mÃ¬nh cÃ³ vÃ i idea váº§y cÃ³ anh em nÃ o cÃ³ thá»ƒ lÃ m forex/stock/crypto/metal trading engine nhÆ° sau khÃ´ng áº¡? Xin chÃ¢n thÃ nh tÃ¬m Ä‘Æ°á»£c ngÆ°á»i Xin cÃ¡m Æ¡n cÃ¡i devs",,,#sharing,,
"Tiáº¿p theo series ngÃ y hÃ´m qua thÃ¬ hÃ´m nay thÃªm Ä‘oáº¡n train LoRA Ä‘á»ƒ sinh ra cÃ¡c áº£nh theo cÃ¡ch cá»§a riÃªng mÃ¬nh.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c trÃªn con Ä‘Æ°á»ng tÃ¬m hiá»ƒu vá» #stablediffusion. Pháº§n link video Ä‘á»ƒ á»Ÿ pháº§n bÃ¬nh luáº­n nhÃ© (sorry vÃ¬ ko hiá»ƒu sao Ã´ng Face bÃ³p tÆ°Æ¡ng tÃ¡c cÃ¡c post cÃ³ link trong nÃ y, khÃ³ hiá»ƒu tháº­t sá»±)
#miai","Tiáº¿p theo series ngÃ y hÃ´m qua thÃ¬ hÃ´m nay thÃªm Ä‘oáº¡n train LoRA Ä‘á»ƒ sinh ra cÃ¡c áº£nh theo cÃ¡ch cá»§a riÃªng mÃ¬nh. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c trÃªn con Ä‘Æ°á»ng tÃ¬m hiá»ƒu vá» Pháº§n link video Ä‘á»ƒ á»Ÿ pháº§n bÃ¬nh luáº­n nhÃ© (sorry vÃ¬ ko hiá»ƒu sao Ã´ng Face bÃ³p tÆ°Æ¡ng tÃ¡c cÃ¡c post cÃ³ link trong nÃ y, khÃ³ hiá»ƒu tháº­t sá»±)",#stablediffusion.	#miai,,"#sharing, #cv",,
"MÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ nhiá»u á»©ng dá»¥ng há»©a háº¹n trong thá»±c táº¿, Ä‘áº·c biá»‡t lÃ  trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  há»c mÃ¡y. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ vÃ­ dá»¥ vá» cÃ¡c á»©ng dá»¥ng cá»§a mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng:

mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nháº­n diá»‡n cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng trong hÃ¬nh áº£nh má»™t cÃ¡ch chÃ­nh xÃ¡c hÆ¡n.
Trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ giÃºp táº­p trung vÃ o viá»‡c há»c cÃ¡c máº«u ngÃ´n ngá»¯ phá»©c táº¡p vÃ  quan trá»ng hÆ¡n trong dá»¯ liá»‡u vÄƒn báº£n.
Trong á»©ng dá»¥ng nháº­n dáº¡ng giá»ng nÃ³i, mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c há»c cÃ¡c Ä‘áº·c Ä‘iá»ƒm quan trá»ng cá»§a giá»ng nÃ³i, nhÆ° cÃ¡ch luyáº¿n Ã¡i, nhá»‹p Ä‘iá»‡u vÃ  ngá»¯ Ä‘iá»‡u, giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trong viá»‡c nháº­n dáº¡ng vÃ  phÃ¢n tÃ­ch giá»ng nÃ³i.
Trong lÄ©nh vá»±c tá»± Ä‘á»™ng lÃ¡i xe, mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c pháº£n á»©ng vÃ  quyáº¿t Ä‘á»‹nh cá»§a há»‡ thá»‘ng lÃ¡i xe trÃªn cÆ¡ sá»Ÿ cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿.

So vá»›i cÃ¡c mÃ´ hÃ¬nh phá»• biáº¿n hiá»‡n nay nhÆ° máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN) hoáº·c máº¡ng nÆ¡-ron há»“i quy (RNN), mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ Ä‘áº·c Ä‘iá»ƒm vÃ  hiá»‡u quáº£ khÃ¡c biá»‡t trong viá»‡c táº­p trung vÃ o viá»‡c há»c cÃ¡c máº«u quan trá»ng trong dá»¯ liá»‡u.Tuy nhiÃªn, viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÅ©ng cÃ³ thá»ƒ Ä‘Ã²i há»i nhiá»u dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  tÃ­nh toÃ¡n phá»©c táº¡p hÆ¡n Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cá»§a máº¡ng.","MÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ nhiá»u á»©ng dá»¥ng há»©a háº¹n trong thá»±c táº¿, Ä‘áº·c biá»‡t lÃ  trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  há»c mÃ¡y. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ vÃ­ dá»¥ vá» cÃ¡c á»©ng dá»¥ng cá»§a mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng: mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nháº­n diá»‡n cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng trong hÃ¬nh áº£nh má»™t cÃ¡ch chÃ­nh xÃ¡c hÆ¡n. Trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ giÃºp táº­p trung vÃ o viá»‡c há»c cÃ¡c máº«u ngÃ´n ngá»¯ phá»©c táº¡p vÃ  quan trá»ng hÆ¡n trong dá»¯ liá»‡u vÄƒn báº£n. Trong á»©ng dá»¥ng nháº­n dáº¡ng giá»ng nÃ³i, mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c há»c cÃ¡c Ä‘áº·c Ä‘iá»ƒm quan trá»ng cá»§a giá»ng nÃ³i, nhÆ° cÃ¡ch luyáº¿n Ã¡i, nhá»‹p Ä‘iá»‡u vÃ  ngá»¯ Ä‘iá»‡u, giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trong viá»‡c nháº­n dáº¡ng vÃ  phÃ¢n tÃ­ch giá»ng nÃ³i. Trong lÄ©nh vá»±c tá»± Ä‘á»™ng lÃ¡i xe, mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c pháº£n á»©ng vÃ  quyáº¿t Ä‘á»‹nh cá»§a há»‡ thá»‘ng lÃ¡i xe trÃªn cÆ¡ sá»Ÿ cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿. So vá»›i cÃ¡c mÃ´ hÃ¬nh phá»• biáº¿n hiá»‡n nay nhÆ° máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN) hoáº·c máº¡ng nÆ¡-ron há»“i quy (RNN), mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ Ä‘áº·c Ä‘iá»ƒm vÃ  hiá»‡u quáº£ khÃ¡c biá»‡t trong viá»‡c táº­p trung vÃ o viá»‡c há»c cÃ¡c máº«u quan trá»ng trong dá»¯ liá»‡u.Tuy nhiÃªn, viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÅ©ng cÃ³ thá»ƒ Ä‘Ã²i há»i nhiá»u dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  tÃ­nh toÃ¡n phá»©c táº¡p hÆ¡n Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cá»§a máº¡ng.",,,"#sharing, #machine_learning",,
"CÃ³ bao giá» anh em tháº¯c máº¯c lÃ m sao mÃ  mÃ´ hÃ¬nh nhÆ° GPT4 cÃ³ thá»ƒ vá»«a xá»­ lÃ½ áº£nh láº«n prompt chÆ°a? Dáº¡o nÃ y mÃ¬nh tÃ¬m hiá»ƒu vá» Vision-Language models thÃ¬ tháº¥y tháº±ng BLIP-2 cÃ³ cÃ¡ch á»©ng dá»¥ng ViT + LLM mÃ  khÃ´ng cáº§n train láº¡i 2 Ã´ng to Ä‘Ã¹ng kia => Vá»«a tiáº¿t kiá»‡m mÃ  láº¡i táº­n dá»¥ng Ä‘Æ°á»£c sá»©c máº¡nh cá»§a pretrained ViT + LLM. Hi vá»ng bÃ i viáº¿t sáº½ giÃºp má»i ngÆ°á»i hiá»ƒu hÆ¡n vá» cÃ¡ch multimodal models hoáº¡t Ä‘á»™ng nhÃ©! 
Link Viblo: https://viblo.asia/p/giai-quyet-bai-toan-vision-language-voi-blip-2-va-instructblip-W13VMeW7VY7",CÃ³ bao giá» anh em tháº¯c máº¯c lÃ m sao mÃ  mÃ´ hÃ¬nh nhÆ° GPT4 cÃ³ thá»ƒ vá»«a xá»­ lÃ½ áº£nh láº«n prompt chÆ°a? Dáº¡o nÃ y mÃ¬nh tÃ¬m hiá»ƒu vá» Vision-Language models thÃ¬ tháº¥y tháº±ng BLIP-2 cÃ³ cÃ¡ch á»©ng dá»¥ng ViT + LLM mÃ  khÃ´ng cáº§n train láº¡i 2 Ã´ng to Ä‘Ã¹ng kia => Vá»«a tiáº¿t kiá»‡m mÃ  láº¡i táº­n dá»¥ng Ä‘Æ°á»£c sá»©c máº¡nh cá»§a pretrained ViT + LLM. Hi vá»ng bÃ i viáº¿t sáº½ giÃºp má»i ngÆ°á»i hiá»ƒu hÆ¡n vá» cÃ¡ch multimodal models hoáº¡t Ä‘á»™ng nhÃ©! Link Viblo: https://viblo.asia/p/giai-quyet-bai-toan-vision-language-voi-blip-2-va-instructblip-W13VMeW7VY7,,,"#sharing, #cv, #deep_learning",,
"KÃ­nh gá»­i cÃ¡c bÃ¡c. Tranh thá»§ Ä‘ang há»c vá» Stable Diffusion em máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng cáº£ nhÃ . Clip chá»‰ vá»›i má»¥c Ä‘Ã­ch tÃ¬m hiá»ƒu siÃªu cÆ¡ báº£n vá» SD vÃ  hÆ°á»›ng tá»›i cÃ¡c báº¡n má»›i há»c.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n!",KÃ­nh gá»­i cÃ¡c bÃ¡c. Tranh thá»§ Ä‘ang há»c vá» Stable Diffusion em máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng cáº£ nhÃ . Clip chá»‰ vá»›i má»¥c Ä‘Ã­ch tÃ¬m hiá»ƒu siÃªu cÆ¡ báº£n vá» SD vÃ  hÆ°á»›ng tá»›i cÃ¡c báº¡n má»›i há»c. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n!,,,"#sharing, #deep_learning",,
"MÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng (Asymmetric Learning Model) lÃ  má»™t loáº¡i mÃ´ hÃ¬nh há»c mÃ¡y hoáº·c mÃ´ hÃ¬nh há»c táº­p trong Ä‘Ã³ quÃ¡ trÃ¬nh há»c vÃ  Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cá»§a máº¡ng neuron Ä‘Æ°á»£c thá»±c hiá»‡n khÃ´ng Ä‘á»‘i xá»©ng giá»¯a cÃ¡c káº¿t ná»‘i nÆ¡-ron.
Trong mÃ´ hÃ¬nh há»c táº­p Ä‘á»‘i xá»©ng, cÃ¡c trá»ng sá»‘ cá»§a máº¡ng neuron Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cÃ¹ng má»™t lÆ°á»£ng cho táº¥t cáº£ cÃ¡c káº¿t ná»‘i nÆ¡-ron. Tá»©c lÃ , khi máº¡ng nháº­n Ä‘Æ°á»£c má»™t tÃ­n hiá»‡u Ä‘áº§u vÃ o vÃ  táº¡o ra Ä‘áº§u ra tÆ°Æ¡ng á»©ng, táº¥t cáº£ cÃ¡c trá»ng sá»‘ sáº½ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh theo cÃ¹ng má»™t cÃ¡ch Ä‘á»ƒ giáº£m thiá»ƒu sai sá»‘ giá»¯a Ä‘áº§u ra thá»±c táº¿ vÃ  Ä‘áº§u ra mong Ä‘á»£i.
Tuy nhiÃªn, trong mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng, quÃ¡ trÃ¬nh Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c thá»±c hiá»‡n cÃ¹ng má»™t cÃ¡ch cho táº¥t cáº£ cÃ¡c káº¿t ná»‘i nÆ¡-ron. Thay vÃ o Ä‘Ã³, Ä‘iá»u chá»‰nh trá»ng sá»‘ cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¹y chá»‰nh theo cÃ¡ch khÃ´ng Ä‘á»‘i xá»©ng dá»±a trÃªn Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra. Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh há»c táº­p chá»§ Ä‘á»™ng táº­p trung vÃ o viá»‡c há»c cÃ¡c máº«u phá»©c táº¡p hoáº·c quan trá»ng hÆ¡n trong dá»¯ liá»‡u, trong khi loáº¡i bá» nhá»¯ng máº«u Ã­t quan trá»ng hoáº·c nhiá»…u.
MÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ cÃ³ á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c cá»§a há»c mÃ¡y vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o, vÃ  nÃ³ lÃ  má»™t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p má»Ÿ rá»™ng vÃ  tá»‘i Æ°u hÃ³a há»c táº­p truyá»n thá»‘ng Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t cao hÆ¡n vÃ  kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch vá»›i cÃ¡c tÃ¡c vá»¥ phá»©c táº¡p hÆ¡n.","MÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng (Asymmetric Learning Model) lÃ  má»™t loáº¡i mÃ´ hÃ¬nh há»c mÃ¡y hoáº·c mÃ´ hÃ¬nh há»c táº­p trong Ä‘Ã³ quÃ¡ trÃ¬nh há»c vÃ  Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cá»§a máº¡ng neuron Ä‘Æ°á»£c thá»±c hiá»‡n khÃ´ng Ä‘á»‘i xá»©ng giá»¯a cÃ¡c káº¿t ná»‘i nÆ¡-ron. Trong mÃ´ hÃ¬nh há»c táº­p Ä‘á»‘i xá»©ng, cÃ¡c trá»ng sá»‘ cá»§a máº¡ng neuron Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cÃ¹ng má»™t lÆ°á»£ng cho táº¥t cáº£ cÃ¡c káº¿t ná»‘i nÆ¡-ron. Tá»©c lÃ , khi máº¡ng nháº­n Ä‘Æ°á»£c má»™t tÃ­n hiá»‡u Ä‘áº§u vÃ o vÃ  táº¡o ra Ä‘áº§u ra tÆ°Æ¡ng á»©ng, táº¥t cáº£ cÃ¡c trá»ng sá»‘ sáº½ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh theo cÃ¹ng má»™t cÃ¡ch Ä‘á»ƒ giáº£m thiá»ƒu sai sá»‘ giá»¯a Ä‘áº§u ra thá»±c táº¿ vÃ  Ä‘áº§u ra mong Ä‘á»£i. Tuy nhiÃªn, trong mÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng, quÃ¡ trÃ¬nh Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c thá»±c hiá»‡n cÃ¹ng má»™t cÃ¡ch cho táº¥t cáº£ cÃ¡c káº¿t ná»‘i nÆ¡-ron. Thay vÃ o Ä‘Ã³, Ä‘iá»u chá»‰nh trá»ng sá»‘ cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¹y chá»‰nh theo cÃ¡ch khÃ´ng Ä‘á»‘i xá»©ng dá»±a trÃªn Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra. Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh há»c táº­p chá»§ Ä‘á»™ng táº­p trung vÃ o viá»‡c há»c cÃ¡c máº«u phá»©c táº¡p hoáº·c quan trá»ng hÆ¡n trong dá»¯ liá»‡u, trong khi loáº¡i bá» nhá»¯ng máº«u Ã­t quan trá»ng hoáº·c nhiá»…u. MÃ´ hÃ¬nh há»c táº­p khÃ´ng Ä‘á»‘i xá»©ng cÃ³ thá»ƒ cÃ³ á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c cá»§a há»c mÃ¡y vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o, vÃ  nÃ³ lÃ  má»™t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p má»Ÿ rá»™ng vÃ  tá»‘i Æ°u hÃ³a há»c táº­p truyá»n thá»‘ng Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t cao hÆ¡n vÃ  kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch vá»›i cÃ¡c tÃ¡c vá»¥ phá»©c táº¡p hÆ¡n.",,,"#sharing, #machine_learning",,
"Meta AI is open-sourcing AudioCraft, a multi-purpose framework for generating music and sounds and enabling compression capabilities.","Meta AI is open-sourcing AudioCraft, a multi-purpose framework for generating music and sounds and enabling compression capabilities.",,,,,
"ChÃ o má»i ngÆ°á»i, trong nhÃ³m mÃ¬nh ai cÃ³ code vá» faster r cnn thÃ¬ cho mÃ¬nh tham kháº£o vá»›i áº¡, náº¿u Ä‘Æ°á»£c lÃ  triá»ƒn khai tá»« Ä‘áº§u toÃ n bá»™ khÃ´ng dÃ¹ng model cÃ³ sáºµn nhÃ© má»i ngÆ°á»i, mÃ¬nh muá»‘n hiá»ƒu kÄ© hÆ¡n vÃ  tiáº¿p cáº­n nÃ³ tá»‘t hÆ¡n. Cáº£m Æ¡n má»i ngÆ°á»i!","ChÃ o má»i ngÆ°á»i, trong nhÃ³m mÃ¬nh ai cÃ³ code vá» faster r cnn thÃ¬ cho mÃ¬nh tham kháº£o vá»›i áº¡, náº¿u Ä‘Æ°á»£c lÃ  triá»ƒn khai tá»« Ä‘áº§u toÃ n bá»™ khÃ´ng dÃ¹ng model cÃ³ sáºµn nhÃ© má»i ngÆ°á»i, mÃ¬nh muá»‘n hiá»ƒu kÄ© hÆ¡n vÃ  tiáº¿p cáº­n nÃ³ tá»‘t hÆ¡n. Cáº£m Æ¡n má»i ngÆ°á»i!",,,"#Q&A, #deep_learning",,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  KhÃ´i Nguyá»…n. Má»™t nÄƒm vá»«a qua, mÃ¬nh cÃ³ thá»i gian Ä‘á»c vÃ  tháº£o luáº­n ná»™i dung cá»§a cuá»‘n sÃ¡ch ""Probabilistic Machine Learning"" cá»§a tÃ¡c giáº£ Kevin Murphy, Ä‘Ã¢y lÃ  xuáº¥t báº£n má»›i cá»§a cuá»‘n sÃ¡ch ná»•i tiáº¿ng ""Machine Learning: A Probabilistic Perspective"", xuáº¥t báº£n nÄƒm 2012. ÄÃ¢y lÃ  má»™t trong nhá»¯ng cuá»‘n sÃ¡ch hay nháº¥t vá» Machine Learning (ML), cung cáº¥p nhá»¯ng kiáº¿n thá»©c ná»n táº£ng vÃ  má»Ÿ rá»™ng cá»§a lÄ©nh vá»±c nÃ y. Sau 10 nÄƒm, nháº­n tháº¥y kiáº¿n thá»©c vá» ML tiáº¿p tá»¥c thay Ä‘á»•i vÃ  cáº­p nháº­t thÃ¬ tÃ¡c giáº£ cÃ³ cáº­p nháº­t vÃ  má»Ÿ rá»™ng cuá»‘n sÃ¡ch cá»§a mÃ¬nh, cÅ©ng nhÆ° sáº¯p xáº¿p láº¡i ná»™i dung cho phÃ¹ há»£p hÆ¡n. CÃ¡c kiáº¿n thá»©c má»›i Ä‘Æ°á»£c cáº­p nháº­t bao gá»“m cáº£ vá» Machine Learning vÃ  Deep Learning, cover cáº£ vá» Generative Model, Few-shot Learning, Continual Learning, Graph Neural Network, Transformer,... Cuá»‘n sÃ¡ch má»›i Ä‘Æ°á»£c chia lÃ m 2 cuá»‘n con, Ä‘Ã£ vÃ  Ä‘ang Ä‘Æ°á»£c xuáº¥t báº£n trong nÄƒm 2022 vÃ  2023 nÃ y.
Nháº­n tháº¥y ná»™i dung cuá»‘n sÃ¡ch ráº¥t há»¯u Ã­ch nÃªn mÃ¬nh cÃ³ Ã½ Ä‘á»‹nh chia sáº½ hÆ°á»›ng dáº«n Ä‘á»c cuá»‘n sÃ¡ch nÃ y. LÃ½ do chÃ­nh lÃ  ná»™i dung khÃ¡ lÃ  nhiá»u, xem nhÆ° lÃ  Bible vá» Machine Learning, náº¿u cÃ³ hÆ°á»›ng dáº«n thÃ¬ viá»‡c Ä‘á»c sáº½ thuáº­n lá»£i hÆ¡n pháº§n nÃ o. Hy vá»ng ráº±ng, sau khi Ä‘á»c cuá»‘n sÃ¡ch nÃ y (vÃ  cÃ³ thá»ƒ nhiá»u láº§n Ä‘á»c ná»¯a) thÃ¬ cÃ¡c báº¡n cÃ³ thá»ƒ tÃ­ch luá»¹ Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c cáº§n thiáº¿t phá»¥c vá»¥ cho cÃ´ng viá»‡c cá»§a mÃ¬nh sau nÃ y, Ä‘áº·c biá»‡t lÃ  cÃ¡c cÃ´ng viá»‡c nghiÃªn cá»©u vá» ML/AI. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c.
Link cá»§a tÃ i liá»‡u hÆ°á»›ng dáº«n táº¡i Ä‘Ã¢y: https://tinyurl.com/ProbML","ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  KhÃ´i Nguyá»…n. Má»™t nÄƒm vá»«a qua, mÃ¬nh cÃ³ thá»i gian Ä‘á»c vÃ  tháº£o luáº­n ná»™i dung cá»§a cuá»‘n sÃ¡ch ""Probabilistic Machine Learning"" cá»§a tÃ¡c giáº£ Kevin Murphy, Ä‘Ã¢y lÃ  xuáº¥t báº£n má»›i cá»§a cuá»‘n sÃ¡ch ná»•i tiáº¿ng ""Machine Learning: A Probabilistic Perspective"", xuáº¥t báº£n nÄƒm 2012. ÄÃ¢y lÃ  má»™t trong nhá»¯ng cuá»‘n sÃ¡ch hay nháº¥t vá» Machine Learning (ML), cung cáº¥p nhá»¯ng kiáº¿n thá»©c ná»n táº£ng vÃ  má»Ÿ rá»™ng cá»§a lÄ©nh vá»±c nÃ y. Sau 10 nÄƒm, nháº­n tháº¥y kiáº¿n thá»©c vá» ML tiáº¿p tá»¥c thay Ä‘á»•i vÃ  cáº­p nháº­t thÃ¬ tÃ¡c giáº£ cÃ³ cáº­p nháº­t vÃ  má»Ÿ rá»™ng cuá»‘n sÃ¡ch cá»§a mÃ¬nh, cÅ©ng nhÆ° sáº¯p xáº¿p láº¡i ná»™i dung cho phÃ¹ há»£p hÆ¡n. CÃ¡c kiáº¿n thá»©c má»›i Ä‘Æ°á»£c cáº­p nháº­t bao gá»“m cáº£ vá» Machine Learning vÃ  Deep Learning, cover cáº£ vá» Generative Model, Few-shot Learning, Continual Learning, Graph Neural Network, Transformer,... Cuá»‘n sÃ¡ch má»›i Ä‘Æ°á»£c chia lÃ m 2 cuá»‘n con, Ä‘Ã£ vÃ  Ä‘ang Ä‘Æ°á»£c xuáº¥t báº£n trong nÄƒm 2022 vÃ  2023 nÃ y. Nháº­n tháº¥y ná»™i dung cuá»‘n sÃ¡ch ráº¥t há»¯u Ã­ch nÃªn mÃ¬nh cÃ³ Ã½ Ä‘á»‹nh chia sáº½ hÆ°á»›ng dáº«n Ä‘á»c cuá»‘n sÃ¡ch nÃ y. LÃ½ do chÃ­nh lÃ  ná»™i dung khÃ¡ lÃ  nhiá»u, xem nhÆ° lÃ  Bible vá» Machine Learning, náº¿u cÃ³ hÆ°á»›ng dáº«n thÃ¬ viá»‡c Ä‘á»c sáº½ thuáº­n lá»£i hÆ¡n pháº§n nÃ o. Hy vá»ng ráº±ng, sau khi Ä‘á»c cuá»‘n sÃ¡ch nÃ y (vÃ  cÃ³ thá»ƒ nhiá»u láº§n Ä‘á»c ná»¯a) thÃ¬ cÃ¡c báº¡n cÃ³ thá»ƒ tÃ­ch luá»¹ Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c cáº§n thiáº¿t phá»¥c vá»¥ cho cÃ´ng viá»‡c cá»§a mÃ¬nh sau nÃ y, Ä‘áº·c biá»‡t lÃ  cÃ¡c cÃ´ng viá»‡c nghiÃªn cá»©u vá» ML/AI. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c. Link cá»§a tÃ i liá»‡u hÆ°á»›ng dáº«n táº¡i Ä‘Ã¢y: https://tinyurl.com/ProbML",,,"#sharing, #machine_learning",,
"120 Python Project cÃ³ Source Code phÃ¹ há»£p cho táº¥t cáº£ cÃ¡c báº¡n Newbie, Beginers, Intermediate, Advanced.
Link: https://s.net.vn/VFws","120 Python Project cÃ³ Source Code phÃ¹ há»£p cho táº¥t cáº£ cÃ¡c báº¡n Newbie, Beginers, Intermediate, Advanced. Link: https://s.net.vn/VFws",,,"#sharing, #python",,
Kiáº¿n trÃºc vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng Stable Diffusion.,Kiáº¿n trÃºc vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng Stable Diffusion.,,,"#sharing, #deep_learning",,
TÃ i liá»‡u khÃ³a há»c NLP cháº¥t lÆ°á»£ng cao CS224n cá»§a ÄH Stanford ğŸ˜˜,TÃ i liá»‡u khÃ³a há»c NLP cháº¥t lÆ°á»£ng cao CS224n cá»§a ÄH Stanford,,,"#sharing, #nlp",,
"ChÃ o má»i ngÆ°á»i
Sáº¯p tá»›i em cÃ³ buá»•i phá»ng váº¥n vá»‹ trÃ­ Intern AI, anh chá»‹ cÃ³ thá»ƒ cho em biáº¿t cÃ¡c cÃ¢u há»i phá»ng váº¥n thÆ°á»ng gáº·p hay táº¯c tÃ¬nh huá»‘ng khi Ä‘i phá»ng váº¥n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i Sáº¯p tá»›i em cÃ³ buá»•i phá»ng váº¥n vá»‹ trÃ­ Intern AI, anh chá»‹ cÃ³ thá»ƒ cho em biáº¿t cÃ¡c cÃ¢u há»i phá»ng váº¥n thÆ°á»ng gáº·p hay táº¯c tÃ¬nh huá»‘ng khi Ä‘i phá»ng váº¥n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n áº¡.",,,#Q&A,,
"Google DeepMind has unveiled Robotic Transformer 2 (RT-2), a pioneering vision-language-action model that equips robots with exceptional capabilities. By translating web and robotics data into general instructions, RT-2 offers groundbreaking improvements in generalization and semantic understanding, setting a new milestone for robotic intelligence","Google DeepMind has unveiled Robotic Transformer 2 (RT-2), a pioneering vision-language-action model that equips robots with exceptional capabilities. By translating web and robotics data into general instructions, RT-2 offers groundbreaking improvements in generalization and semantic understanding, setting a new milestone for robotic intelligence",,,,,
"120 Python Project cÃ³ Source Code phÃ¹ há»£p cho táº¥t cáº£ cÃ¡c báº¡n Newbie, Beginers, Intermediate, Advanced.","120 Python Project cÃ³ Source Code phÃ¹ há»£p cho táº¥t cáº£ cÃ¡c báº¡n Newbie, Beginers, Intermediate, Advanced.",,,"#sharing, #python",,
"Má»™t sinh viÃªn Harvard, Maya Bodnick, Ä‘Ã£ kiá»ƒm tra kháº£ nÄƒng cá»§a GPT-4 trong viá»‡c viáº¿t cÃ¡c bÃ i luáº­n khoa há»c xÃ£ há»™i vÃ  nhÃ¢n vÄƒn nÄƒm thá»© nháº¥t. Káº¿t quáº£ lÃ  GPT-4 Ä‘áº¡t Ä‘iá»ƒm trung bÃ¬nh 3,57 ""Ä‘Ã¡ng ná»ƒ""!","Má»™t sinh viÃªn Harvard, Maya Bodnick, Ä‘Ã£ kiá»ƒm tra kháº£ nÄƒng cá»§a GPT-4 trong viá»‡c viáº¿t cÃ¡c bÃ i luáº­n khoa há»c xÃ£ há»™i vÃ  nhÃ¢n vÄƒn nÄƒm thá»© nháº¥t. Káº¿t quáº£ lÃ  GPT-4 Ä‘áº¡t Ä‘iá»ƒm trung bÃ¬nh 3,57 ""Ä‘Ã¡ng ná»ƒ""!",,,"#sharing, #nlp",,
FLASK: a new evaluation protocol designed to provide a comprehensive analysis of LLMs performance based on 12 specific skills.,FLASK: a new evaluation protocol designed to provide a comprehensive analysis of LLMs performance based on 12 specific skills.,,,,,
1/. Universal Adversarial LLM Attacks - finds universal and transferable adversarial attacks that cause aligned models like ChatGPT and Bard to generate objectionable behaviors; the approach automatically produces adversarial suffixes using greedy and gradient search.,1/. Universal Adversarial LLM Attacks - finds universal and transferable adversarial attacks that cause aligned models like ChatGPT and Bard to generate objectionable behaviors; the approach automatically produces adversarial suffixes using greedy and gradient search.,,,,,
"PYTHON VÃ€ TÃ€I CHÃNH: Dá»° ÄOÃN CHá»ˆ Sá» CHá»¨NG KHOÃN VNINDEX Báº°NG MODEL LOGISTIC REGRESSION
Chá»©ng khoÃ¡n VNINDEX lÃ  chá»‰ sá»‘ chung cá»§a thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam vÃ  Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c Ä‘o lÆ°á»ng sá»± biáº¿n Ä‘á»™ng vÃ  pháº£n Ã¡nh xu hÆ°á»›ng cá»§a thá»‹ trÆ°á»ng. Dá»± Ä‘oÃ¡n biáº¿n Ä‘á»™ng cá»§a VNINDEX cÃ³ thá»ƒ há»— trá»£ nhÃ  Ä‘áº§u tÆ° vÃ  cÃ¡c chuyÃªn gia tÃ i chÃ­nh trong viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh thÃ´ng minh vá» Ä‘áº§u tÆ° vÃ  quáº£n lÃ½ rá»§i ro. Trong bÃ i viáº¿t nÃ y, hÃ£y cÃ¹ng ICLS Tech tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh Logistic Regression Ä‘á»ƒ dá»± Ä‘oÃ¡n chá»‰ sá»‘ chá»©ng khoÃ¡n VNINDEX vÃ  Ä‘áº¡t tá»· lá»‡ Ä‘Ãºng dá»± Ä‘oÃ¡n trÃªn 50% nhÃ©!
#ICLSTech #ThuvienPython #PythonLibraries #AlgoTrading #FinTech #QuantitativeFinance #DataScience
Nguá»“n: ICLS Tech","PYTHON VÃ€ TÃ€I CHÃNH: Dá»° ÄOÃN CHá»ˆ Sá» CHá»¨NG KHOÃN VNINDEX Báº°NG MODEL LOGISTIC REGRESSION Chá»©ng khoÃ¡n VNINDEX lÃ  chá»‰ sá»‘ chung cá»§a thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam vÃ  Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c Ä‘o lÆ°á»ng sá»± biáº¿n Ä‘á»™ng vÃ  pháº£n Ã¡nh xu hÆ°á»›ng cá»§a thá»‹ trÆ°á»ng. Dá»± Ä‘oÃ¡n biáº¿n Ä‘á»™ng cá»§a VNINDEX cÃ³ thá»ƒ há»— trá»£ nhÃ  Ä‘áº§u tÆ° vÃ  cÃ¡c chuyÃªn gia tÃ i chÃ­nh trong viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh thÃ´ng minh vá» Ä‘áº§u tÆ° vÃ  quáº£n lÃ½ rá»§i ro. Trong bÃ i viáº¿t nÃ y, hÃ£y cÃ¹ng ICLS Tech tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh Logistic Regression Ä‘á»ƒ dá»± Ä‘oÃ¡n chá»‰ sá»‘ chá»©ng khoÃ¡n VNINDEX vÃ  Ä‘áº¡t tá»· lá»‡ Ä‘Ãºng dá»± Ä‘oÃ¡n trÃªn 50% nhÃ©! Nguá»“n: ICLS Tech",#ICLSTech	#ThuvienPython	#PythonLibraries	#AlgoTrading	#FinTech	#QuantitativeFinance	#DataScience,,"#machine_learning, #python, #sharing",,
"[GÃ³c tÆ° váº¥n]
Hi m.n, cho mÃ¬nh há»i ráº±ng liá»‡u laptop Macbook pro M2 cÃ³ phÃ¹ há»£p viá»‡c há»c cho láº­p trÃ¬nh machine learning khÃ´ng? VÃ  viá»‡c cÃ i Ä‘áº·t thÆ° viá»‡n cho machine learning trÃªn Macbook M2 cÃ³ tÆ°Æ¡ng thÃ­ch hay lÃ  bá»‹ xung Ä‘á»™t nhiá»u ko áº¡?
MÃ¬nh Ä‘á»‹nh mua laptop Macbook pro M2 Ä‘á»ƒ há»c ML thÃ´i? ChÆ°a cáº§n pháº£i lÃ m viá»‡c vs khá»‘i lÆ°á»£ng lá»›n dá»¯ liá»‡u nhÆ° khi Ä‘i lÃ m Ä‘Ã¢u áº¡?
Thanks m.n !!!","[GÃ³c tÆ° váº¥n] Hi m.n, cho mÃ¬nh há»i ráº±ng liá»‡u laptop Macbook pro M2 cÃ³ phÃ¹ há»£p viá»‡c há»c cho láº­p trÃ¬nh machine learning khÃ´ng? VÃ  viá»‡c cÃ i Ä‘áº·t thÆ° viá»‡n cho machine learning trÃªn Macbook M2 cÃ³ tÆ°Æ¡ng thÃ­ch hay lÃ  bá»‹ xung Ä‘á»™t nhiá»u ko áº¡? MÃ¬nh Ä‘á»‹nh mua laptop Macbook pro M2 Ä‘á»ƒ há»c ML thÃ´i? ChÆ°a cáº§n pháº£i lÃ m viá»‡c vs khá»‘i lÆ°á»£ng lá»›n dá»¯ liá»‡u nhÆ° khi Ä‘i lÃ m Ä‘Ã¢u áº¡? Thanks m.n !!!",,,"#Q&A, #machine_learning",,
"Stability AI released Stable Diffusion XL (SDXL) 1.0 ğŸš€
ğŸ’¡ SDXL 1.0 is an open access image model with a large parameter count. It has a 3.5 billion parameter base model and a 6.6 billion parameter model ensemble pipeline. A refiner component improves the base model's output with better color, contrast, and details.","Stability AI released Stable Diffusion XL (SDXL) 1.0 SDXL 1.0 is an open access image model with a large parameter count. It has a 3.5 billion parameter base model and a 6.6 billion parameter model ensemble pipeline. A refiner component improves the base model's output with better color, contrast, and details.",,,,,
"ChÃ o má»i ngÆ°á»i, e dá»± Ä‘á»‹nh há»c tháº¡c sÄ© vÃ  nghiÃªn cá»©u vÃ o ""machine learning"". E má»›i báº¯t Ä‘áº§u há»c nÃªn khÃ´ng biáº¿t rÃµ 1 sá»‘ mÃ´n nÃªn há»c trÆ°á»›c hay sau.
Cá»¥ thá»ƒ trong trÆ°á»ng e cÃ³ 1 sá»‘ mÃ´n tá»± chá»n, vÃ  e tÃ­nh lÃ  sáº½ há»c ""machine learning"" trÆ°á»›c sau Ä‘Ã³ sáº½ lÃ  ""deep learning"". NhÆ°ng cÃ³ 1 mÃ´n lÃ  ""Data Warehousing and Big Data"" thÃ¬ e khÃ´ng biáº¿t lÃ  mÃ´n nÃ y cÃ³ liÃªn quan máº­t thiáº¿t vá»›i viá»‡c há»c machine learning khÃ´ng vÃ  nÃªn há»c nÃ³ trÆ°á»›c hay sau ""machine learning vÃ  deep learning""? TÆ°Æ¡ng tá»± vá»›i mÃ´n ""Cloud Computing"" áº¡ ?
e cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, e dá»± Ä‘á»‹nh há»c tháº¡c sÄ© vÃ  nghiÃªn cá»©u vÃ o ""machine learning"". E má»›i báº¯t Ä‘áº§u há»c nÃªn khÃ´ng biáº¿t rÃµ 1 sá»‘ mÃ´n nÃªn há»c trÆ°á»›c hay sau. Cá»¥ thá»ƒ trong trÆ°á»ng e cÃ³ 1 sá»‘ mÃ´n tá»± chá»n, vÃ  e tÃ­nh lÃ  sáº½ há»c ""machine learning"" trÆ°á»›c sau Ä‘Ã³ sáº½ lÃ  ""deep learning"". NhÆ°ng cÃ³ 1 mÃ´n lÃ  ""Data Warehousing and Big Data"" thÃ¬ e khÃ´ng biáº¿t lÃ  mÃ´n nÃ y cÃ³ liÃªn quan máº­t thiáº¿t vá»›i viá»‡c há»c machine learning khÃ´ng vÃ  nÃªn há»c nÃ³ trÆ°á»›c hay sau ""machine learning vÃ  deep learning""? TÆ°Æ¡ng tá»± vá»›i mÃ´n ""Cloud Computing"" áº¡ ? e cáº£m Æ¡n",,,"#Q&A, #machine_learning",,
"Xin chÃ o mn áº¡, mÃ¬nh lÃ  ngÆ°á»i ko cÃ³ kiáº¿n thá»©c sÃ¢u vá» AI, NLP, NLU,... muá»‘n xÃ¢y dá»±ng má»™t model theo cÃ¡c data cÃ³ sáºµn mÃ¬nh lá»¥m Ä‘Æ°á»£c trÃªn máº¡ng nhÆ° nÃ y, nhá» mng chá»‰ cÃ¡ch mÃ¬nh train Ä‘á»ƒ táº¡o thÃ nh model vá»›i áº¡
https://github.com/lab914hust/SmartHomeNLU. git","Xin chÃ o mn áº¡, mÃ¬nh lÃ  ngÆ°á»i ko cÃ³ kiáº¿n thá»©c sÃ¢u vá» AI, NLP, NLU,... muá»‘n xÃ¢y dá»±ng má»™t model theo cÃ¡c data cÃ³ sáºµn mÃ¬nh lá»¥m Ä‘Æ°á»£c trÃªn máº¡ng nhÆ° nÃ y, nhá» mng chá»‰ cÃ¡ch mÃ¬nh train Ä‘á»ƒ táº¡o thÃ nh model vá»›i áº¡ https://github.com/lab914hust/SmartHomeNLU. git",,,"#Q&A, #machine_learning",,
"CÃ³ thá»ƒ nhiá»u ngÆ°á»i biáº¿t rá»“i, nhÆ°ng mÃ¬nh tháº¥y Channel nÃ y trÃªn youtube khÃ¡ hay:
https://www.youtube.com/@statquest
Trong Ä‘Ã³ cÃ³ nhiá»u playlists cho Statistics, ML, DeepLearning, ...","CÃ³ thá»ƒ nhiá»u ngÆ°á»i biáº¿t rá»“i, nhÆ°ng mÃ¬nh tháº¥y Channel nÃ y trÃªn youtube khÃ¡ hay: https://www.youtube.com/@statquest Trong Ä‘Ã³ cÃ³ nhiá»u playlists cho Statistics, ML, DeepLearning, ...",,,"#sharing, #machine_learning",,
"ChÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i nhÃ³m em/mÃ¬nh Ä‘ang thá»±c hiá»‡n má»™t khÃ³a luáº­n tá»‘t nghiá»‡p vá» thá»­ Ä‘á»“ áº£o vÃ  gá»£i Ã½ trang phá»¥c (virtual try-on & outfit recommendation). NhÃ³m cÃ³ xÃ¢y dá»±ng má»™t website - ğŸ‘•KiseKloset há»— trá»£ 2 tÃ­nh nÄƒng nÃ y vá»›i má»¥c Ä‘Ã­ch giÃºp tÄƒng tráº£i nghiá»‡m khi mua sáº¯m quáº§n Ã¡o online. Há»‡ thá»‘ng sáº½ cho phÃ©p thá»­ Ä‘á»“ áº£o tá»« áº£nh ngÆ°á»i máº«u vÃ  áº£nh Ã¡o (hiá»‡n nay chá»‰ má»›i chá»‰ há»— trá»£ thá»­ Ã¡o) sau Ä‘Ã³ Ä‘á» xuáº¥t thÃªm cÃ¡c trang phá»¥c dá»±a vÃ o máº«u Ã¡o báº¡n sá»­ dá»¥ng vÃ  cÃ¡c thÃ´ng tin cung cáº¥p thÃªm dÆ°á»›i dáº¡ng text.
ğŸ“Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c thÃªm hÆ°á»›ng dáº«n trong trang web Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t cÃ¡ch sá»­ dá»¥ng.
Ráº¥t mong má»i ngÆ°á»i dÃ nh chÃºt thá»i gian Ä‘á»ƒ tráº£i nghiá»‡m thá»­ á»©ng dá»¥ng vÃ  Ä‘Ã¡nh giÃ¡. Má»i Ã½ kiáº¿n cá»§a má»i ngÆ°á»i Ä‘á»u ráº¥t giÃ¡ trá»‹ Ä‘á»ƒ nhÃ³m Ä‘Ã¡nh giÃ¡ vÃ  cáº£i tiáº¿n á»©ng dá»¥ng ğŸ¥°
ğŸ“ŒLink website: http://selab.edu.vn:20440 or thevncore-lab.mooo(dot)com:20440
ğŸ“ŒMong má»i ngÆ°á»i cho Ã½ kiáº¿n qua kháº£o sÃ¡t: https://forms.gle/NNpqY7XiLkdiUh7D9
Em/mÃ¬nh xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i nhÃ³m em/mÃ¬nh Ä‘ang thá»±c hiá»‡n má»™t khÃ³a luáº­n tá»‘t nghiá»‡p vá» thá»­ Ä‘á»“ áº£o vÃ  gá»£i Ã½ trang phá»¥c (virtual try-on & outfit recommendation). NhÃ³m cÃ³ xÃ¢y dá»±ng má»™t website - KiseKloset há»— trá»£ 2 tÃ­nh nÄƒng nÃ y vá»›i má»¥c Ä‘Ã­ch giÃºp tÄƒng tráº£i nghiá»‡m khi mua sáº¯m quáº§n Ã¡o online. Há»‡ thá»‘ng sáº½ cho phÃ©p thá»­ Ä‘á»“ áº£o tá»« áº£nh ngÆ°á»i máº«u vÃ  áº£nh Ã¡o (hiá»‡n nay chá»‰ má»›i chá»‰ há»— trá»£ thá»­ Ã¡o) sau Ä‘Ã³ Ä‘á» xuáº¥t thÃªm cÃ¡c trang phá»¥c dá»±a vÃ o máº«u Ã¡o báº¡n sá»­ dá»¥ng vÃ  cÃ¡c thÃ´ng tin cung cáº¥p thÃªm dÆ°á»›i dáº¡ng text. Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c thÃªm hÆ°á»›ng dáº«n trong trang web Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t cÃ¡ch sá»­ dá»¥ng. Ráº¥t mong má»i ngÆ°á»i dÃ nh chÃºt thá»i gian Ä‘á»ƒ tráº£i nghiá»‡m thá»­ á»©ng dá»¥ng vÃ  Ä‘Ã¡nh giÃ¡. Má»i Ã½ kiáº¿n cá»§a má»i ngÆ°á»i Ä‘á»u ráº¥t giÃ¡ trá»‹ Ä‘á»ƒ nhÃ³m Ä‘Ã¡nh giÃ¡ vÃ  cáº£i tiáº¿n á»©ng dá»¥ng Link website: http://selab.edu.vn:20440 or thevncore-lab.mooo(dot)com:20440 Mong má»i ngÆ°á»i cho Ã½ kiáº¿n qua kháº£o sÃ¡t: https://forms.gle/NNpqY7XiLkdiUh7D9 Em/mÃ¬nh xin cáº£m Æ¡n.",,,"#sharing, #machine_learning",,
"TRá»°C QUAN HÃ“A Máº NG NEURAL NETWORK.
Trang web http://playground.tensorflow.org/ lÃ  má»™t cÃ´ng cá»¥ trá»±c quan vÃ  tÆ°Æ¡ng tÃ¡c cho phÃ©p ngÆ°á»i dÃ¹ng thá»­ nghiá»‡m vÃ  há»c táº­p vá» cÃ¡c mÃ´ hÃ¬nh máº¡ng nÆ¡-ron (neural network) Ä‘Æ¡n giáº£n.",TRá»°C QUAN HÃ“A Máº NG NEURAL NETWORK. Trang web http://playground.tensorflow.org/ lÃ  má»™t cÃ´ng cá»¥ trá»±c quan vÃ  tÆ°Æ¡ng tÃ¡c cho phÃ©p ngÆ°á»i dÃ¹ng thá»­ nghiá»‡m vÃ  há»c táº­p vá» cÃ¡c mÃ´ hÃ¬nh máº¡ng nÆ¡-ron (neural network) Ä‘Æ¡n giáº£n.,,,"#sharing, #deep_learning",,
CÃ¡c anh chá»‹ em cho mÃ¬nh há»i á»Ÿ sg chá»— nÃ o Ä‘Ã o táº¡o ngoÃ i giá» data sientist á»•n váº­y áº¡? MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i!!,CÃ¡c anh chá»‹ em cho mÃ¬nh há»i á»Ÿ sg chá»— nÃ o Ä‘Ã o táº¡o ngoÃ i giá» data sientist á»•n váº­y áº¡? MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i!!,,,"#Q&A, #data",,
"Má»i ngÆ°á»i cho em xin chá»— hay tÃ i liá»‡u dáº¡y vá» YOLO v7 vÃ  cÃ¡ch training nÃ³ vá»›i áº¡, trÃªn máº¡ng Ã­t tÃ i liá»‡u vá» nÃ³ tháº­t sá»±.","Má»i ngÆ°á»i cho em xin chá»— hay tÃ i liá»‡u dáº¡y vá» YOLO v7 vÃ  cÃ¡ch training nÃ³ vá»›i áº¡, trÃªn máº¡ng Ã­t tÃ i liá»‡u vá» nÃ³ tháº­t sá»±.",,,"#Q&A, #deep_learning",,
"âš™ Data Platforms Architecture âš™
CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a má»™t Data Platform hoÃ n chá»‰nh:
1ï¸âƒ£ Data Governance
2ï¸âƒ£ Data Catalog
3ï¸âƒ£ Metadata Management
4ï¸âƒ£ Data Security
5ï¸âƒ£ Data Privacy and Compliance
6ï¸âƒ£ Data Monitoring and Auditing
7ï¸âƒ£ Disaster Recovery and Business Continuity
8ï¸âƒ£ Performance Optimization
9ï¸âƒ£ Scalability and Elasticity
ğŸ”Ÿ Continuous Improvement",Data Platforms Architecture CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a má»™t Data Platform hoÃ n chá»‰nh: 1âƒ£ Data Governance 2âƒ£ Data Catalog 3âƒ£ Metadata Management 4âƒ£ Data Security 5âƒ£ Data Privacy and Compliance 6âƒ£ Data Monitoring and Auditing 7âƒ£ Disaster Recovery and Business Continuity 8âƒ£ Performance Optimization 9âƒ£ Scalability and Elasticity Continuous Improvement,,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm tÆ° ngÃ nh Khoa há»c mÃ¡y tÃ­nh. Hiá»‡n táº¡i e vÃ  nhÃ³m Ä‘ang phÃ¡t triá»ƒn má»™t á»©ng dá»¥ng quÃ©t Ä‘Æ¡n thuá»‘c tá»± Ä‘á»™ng. á»¨ng dá»¥ng sáº½ quÃ©t áº£nh chá»¥p Ä‘Æ¡n thuá»‘c giÃºp ngÆ°á»i dÃ¹ng tra cá»©u thÃ´ng tin vá» cÃ¡c loáº¡i thuá»‘c mÃ¬nh Ä‘ang sá»­ dá»¥ng, Ä‘á»“ng thá»i cÃ³ thá»ƒ Ä‘áº·t lá»‹ch uá»‘ng thuá»‘c Ä‘á»ƒ trÃ¡nh trÆ°á»ng hÆ¡p sá»­ dá»¥ng thuá»‘c khÃ´ng Ä‘Ãºng cÃ¡ch. á»¨ng dá»¥ng cá»§a nhÃ³m Ä‘Ã£ cÃ³ thá»ƒ táº£i xuá»‘ng trÃªn cá»§a hÃ ng Play store (do khÃ´ng Ä‘á»§ kinh phÃ­ nÃªn chÆ°a thá»ƒ Ä‘Äƒng lÃªn Appstore áº¡). Ráº¥t mong má»i ngÆ°á»i dÃ nh Ã­t thá»i gian tráº£i nghiá»‡m á»©ng dá»¥ng. Má»i pháº£n há»“i cá»§a má»i ngÆ°á»i Ä‘á»u ráº¥t giÃ¡ trá»‹ vá»›i nhÃ³m chÃºng em. Em xin chÃ¢n thÃ nh cáº£m Æ¡n.
Link táº£i App: https://bit.ly/3q3VGWz
Ps: Em cÃ³ Ä‘Ã­nh kÃ¨m QR vá»›i áº£nh demo test app bÃªn dÆ°á»›i, mn cÃ³ thá»ƒ táº£i vÃ  sá»­ dá»¥ng nhÃ©.","ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm tÆ° ngÃ nh Khoa há»c mÃ¡y tÃ­nh. Hiá»‡n táº¡i e vÃ  nhÃ³m Ä‘ang phÃ¡t triá»ƒn má»™t á»©ng dá»¥ng quÃ©t Ä‘Æ¡n thuá»‘c tá»± Ä‘á»™ng. á»¨ng dá»¥ng sáº½ quÃ©t áº£nh chá»¥p Ä‘Æ¡n thuá»‘c giÃºp ngÆ°á»i dÃ¹ng tra cá»©u thÃ´ng tin vá» cÃ¡c loáº¡i thuá»‘c mÃ¬nh Ä‘ang sá»­ dá»¥ng, Ä‘á»“ng thá»i cÃ³ thá»ƒ Ä‘áº·t lá»‹ch uá»‘ng thuá»‘c Ä‘á»ƒ trÃ¡nh trÆ°á»ng hÆ¡p sá»­ dá»¥ng thuá»‘c khÃ´ng Ä‘Ãºng cÃ¡ch. á»¨ng dá»¥ng cá»§a nhÃ³m Ä‘Ã£ cÃ³ thá»ƒ táº£i xuá»‘ng trÃªn cá»§a hÃ ng Play store (do khÃ´ng Ä‘á»§ kinh phÃ­ nÃªn chÆ°a thá»ƒ Ä‘Äƒng lÃªn Appstore áº¡). Ráº¥t mong má»i ngÆ°á»i dÃ nh Ã­t thá»i gian tráº£i nghiá»‡m á»©ng dá»¥ng. Má»i pháº£n há»“i cá»§a má»i ngÆ°á»i Ä‘á»u ráº¥t giÃ¡ trá»‹ vá»›i nhÃ³m chÃºng em. Em xin chÃ¢n thÃ nh cáº£m Æ¡n. Link táº£i App: https://bit.ly/3q3VGWz Ps: Em cÃ³ Ä‘Ã­nh kÃ¨m QR vá»›i áº£nh demo test app bÃªn dÆ°á»›i, mn cÃ³ thá»ƒ táº£i vÃ  sá»­ dá»¥ng nhÃ©.",,,"#sharing, #cv",,
"VinAI Seminar - ""Domain Adaptation on Wheels: Closing the Gap to the Open-world""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Tuan-Hung Vu, Valeo.ai
Time: 03:00 pm - 04:00 pm (GMT+7), Jul 25, 2023","VinAI Seminar - ""Domain Adaptation on Wheels: Closing the Gap to the Open-world"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Tuan-Hung Vu, Valeo.ai Time: 03:00 pm - 04:00 pm (GMT+7), Jul 25, 2023",,,,,
MÃ¬nh xin phÃ©p chia sáº» cho má»i ngÆ°á»i bÃ i viáº¿t giáº£i thÃ­ch chi tiáº¿t vá» paper LLaMa-2 - má»™t LLM Ä‘Ã¬nh Ä‘Ã¡m cá»§a Meta má»›i ra máº¯t Ä‘Ã¬nh Ä‘Ã¡m trong tuáº§n vá»«a qua. Hi vá»ng ráº±ng nÃ³ sáº½ lÃ m thay Ä‘á»•i nhiá»u thá»© trong tÆ°Æ¡ng lai cá»§a LLM,MÃ¬nh xin phÃ©p chia sáº» cho má»i ngÆ°á»i bÃ i viáº¿t giáº£i thÃ­ch chi tiáº¿t vá» paper LLaMa-2 - má»™t LLM Ä‘Ã¬nh Ä‘Ã¡m cá»§a Meta má»›i ra máº¯t Ä‘Ã¬nh Ä‘Ã¡m trong tuáº§n vá»«a qua. Hi vá»ng ráº±ng nÃ³ sáº½ lÃ m thay Ä‘á»•i nhiá»u thá»© trong tÆ°Æ¡ng lai cá»§a LLM,,,"#sharing, #deep_learning",,
"Hello everyone, I wish you have a happy weekend.
Recently, Meta introduced LLaMA v2, which is an upgrade version of LLaMA with far and wide improvements in terms of excellent performance, length of context, and amount of training tokens.
Let's shed light on the application of this model.","Hello everyone, I wish you have a happy weekend. Recently, Meta introduced LLaMA v2, which is an upgrade version of LLaMA with far and wide improvements in terms of excellent performance, length of context, and amount of training tokens. Let's shed light on the application of this model.",,,,,
"[About linear regression/linear algebra] I would like to ask the following question in English since it will be more convenient.
We are given a input feature matrix X of shape nxd, where n>d and the associated label vector y of size nx1. We know that the solution of the least square min_{beta}|| X beta -y||^2_2 is given by: beta = (X^T X)^{-1}Xy.
Now consider an arbitrary binary matrix B of shape nxd, B_{i,j} in {0,1} and ||B||_0 = (n-1) * d, i.e the number of zeroes in B is d. Using least squares with data matrix X1 = X*B, and the label y, we obtain beta1 = (X1^TX)^{-1}X1y. Here * denotes the elementwise product.
Find B so that ||B||_0 = d and beta_1 = beta ?
Note: It is easy to see one such solution is when exactly one row of B is zeros, and the rest of other entries are 1. Does that exists other solutions ?","[About linear regression/linear algebra] I would like to ask the following question in English since it will be more convenient. We are given a input feature matrix X of shape nxd, where n>d and the associated label vector y of size nx1. We know that the solution of the least square min_{beta}|| X beta -y||^2_2 is given by: beta = (X^T X)^{-1}Xy. Now consider an arbitrary binary matrix B of shape nxd, B_{i,j} in {0,1} and ||B||_0 = (n-1) * d, i.e the number of zeroes in B is d. Using least squares with data matrix X1 = X*B, and the label y, we obtain beta1 = (X1^TX)^{-1}X1y. Here * denotes the elementwise product. Find B so that ||B||_0 = d and beta_1 = beta ? Note: It is easy to see one such solution is when exactly one row of B is zeros, and the rest of other entries are 1. Does that exists other solutions ?",,,,,
Em Ä‘Æ°á»£c giao bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n nhÆ°ng trÆ°á»›c tiÃªn pháº£i phÃ¡t hiá»‡n slot trÆ°á»›c rá»“i sau Ä‘Ã³ phÃ¢n loáº¡i vÄƒn báº£n sáº½ dá»±a vÃ o nhá»¯ng slot Ä‘Ã³ káº¿t há»£p ngá»¯ nghÄ©a cÃ¢u Ä‘á»ƒ phÃ¢n loáº¡i. Em cÃ³ tÃ¬m nhá»¯ng paper vá» joint intent and slot filling hay model diet Ä‘á»u theo kiá»ƒu phÃ¢n loáº¡i trÆ°á»›c rá»“i tá»« phÃ¢n loáº¡i vÄƒn báº£n má»›i tÃ¬m slot nÃªn bá»‹ ngÆ°á»£c vá»›i bÃ i toÃ¡n cá»§a em. Em cÃ³ thá»­ láº¥y cÃ¡c model áº¥y test thÃ¬ káº¿t quáº£ cÃ²n tá»‡ hÆ¡n náº¿u mÃ¬nh chá»‰ dÃ¹ng má»—i model nhÆ° bert Ä‘á»ƒ phÃ¢n loáº¡i. KhÃ´ng biáº¿t anh chá»‹ cÃ³ link paper nÃ o cÃ³ thá»ƒ share cho em vá»›i Ä‘Æ°á»£c khÃ´ng nhá»‰. Em kiáº¿m mÃ£i khÃ´ng tÃ¬m tháº¥y paper nÃ o lÃ m nhÆ° váº­y . em cáº£m Æ¡n,Em Ä‘Æ°á»£c giao bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n nhÆ°ng trÆ°á»›c tiÃªn pháº£i phÃ¡t hiá»‡n slot trÆ°á»›c rá»“i sau Ä‘Ã³ phÃ¢n loáº¡i vÄƒn báº£n sáº½ dá»±a vÃ o nhá»¯ng slot Ä‘Ã³ káº¿t há»£p ngá»¯ nghÄ©a cÃ¢u Ä‘á»ƒ phÃ¢n loáº¡i. Em cÃ³ tÃ¬m nhá»¯ng paper vá» joint intent and slot filling hay model diet Ä‘á»u theo kiá»ƒu phÃ¢n loáº¡i trÆ°á»›c rá»“i tá»« phÃ¢n loáº¡i vÄƒn báº£n má»›i tÃ¬m slot nÃªn bá»‹ ngÆ°á»£c vá»›i bÃ i toÃ¡n cá»§a em. Em cÃ³ thá»­ láº¥y cÃ¡c model áº¥y test thÃ¬ káº¿t quáº£ cÃ²n tá»‡ hÆ¡n náº¿u mÃ¬nh chá»‰ dÃ¹ng má»—i model nhÆ° bert Ä‘á»ƒ phÃ¢n loáº¡i. KhÃ´ng biáº¿t anh chá»‹ cÃ³ link paper nÃ o cÃ³ thá»ƒ share cho em vá»›i Ä‘Æ°á»£c khÃ´ng nhá»‰. Em kiáº¿m mÃ£i khÃ´ng tÃ¬m tháº¥y paper nÃ o lÃ m nhÆ° váº­y . em cáº£m Æ¡n,,,"#Q&A, #nlp",,
AI sáº½ thay Ä‘á»•i toÃ n bá»™ ngÃ nh nÃ´ng nghiá»‡p!,AI sáº½ thay Ä‘á»•i toÃ n bá»™ ngÃ nh nÃ´ng nghiá»‡p!,,,,,
"MÃ¬nh cÃ³ 1 bÃ i toÃ¡n nhÆ° sau. MÃ¬nh cÃ³ input lÃ  tÃªn 1 váº­t (dáº¡ng text), vÃ  mÃ¬nh muá»‘n ra output lÃ  mÃ´ táº£ cá»§a váº­t Ä‘Ã³ (dáº¡ng text). MÃ´ táº£ cá»§a váº­t thÃ¬ cÃ³ 1 format nháº¥t Ä‘á»‹nh, vdu nÃ³ lÃ  Ä‘á»™ng váº­t hay thá»±c váº­t, rá»“i thuá»™c há» j, cÃ³ máº¥y chÃ¢n, vvv. MÃ¬nh ko lÃ m vá» NLP nÃªn ko rÃµ hiá»‡n táº¡i cÃ³ kÄ© thuáº­t j cÃ³ thá»ƒ lÃ m Ä‘c? Hoáº·c cÃ¡c báº¡n cÃ³ thá»ƒ gá»£i Ã½ keywords cÅ©ng Ä‘c. MÃ¬nh cáº£m Æ¡n nhiá»u.","MÃ¬nh cÃ³ 1 bÃ i toÃ¡n nhÆ° sau. MÃ¬nh cÃ³ input lÃ  tÃªn 1 váº­t (dáº¡ng text), vÃ  mÃ¬nh muá»‘n ra output lÃ  mÃ´ táº£ cá»§a váº­t Ä‘Ã³ (dáº¡ng text). MÃ´ táº£ cá»§a váº­t thÃ¬ cÃ³ 1 format nháº¥t Ä‘á»‹nh, vdu nÃ³ lÃ  Ä‘á»™ng váº­t hay thá»±c váº­t, rá»“i thuá»™c há» j, cÃ³ máº¥y chÃ¢n, vvv. MÃ¬nh ko lÃ m vá» NLP nÃªn ko rÃµ hiá»‡n táº¡i cÃ³ kÄ© thuáº­t j cÃ³ thá»ƒ lÃ m Ä‘c? Hoáº·c cÃ¡c báº¡n cÃ³ thá»ƒ gá»£i Ã½ keywords cÅ©ng Ä‘c. MÃ¬nh cáº£m Æ¡n nhiá»u.",,,"#Q&A, #nlp",,
"ğŸ”¥Meta vÃ  Microsoft há»£p tÃ¡c cÃ´ng bá»‘ Llama 2: CÃ³ phiÃªn báº£n Chat, cho phÃ©p thÆ°Æ¡ng máº¡i hÃ³ağŸ’¥
ğŸ“ŒMá»˜T Sá» THÃ”NG TIN QUAN TRá»ŒNG:
âœ…Dá»¯ liá»‡u: 2 nghÃ¬n tá»‰ tokens. Nhiá»u hÆ¡n 40% so vá»›i Llama 1.
âœ…Context length: 4096.
âœ…KÃ­ch cá»¡: 7B, 13B, 70B tham sá»‘ (phiÃªn báº£n 34B chÆ°a Ä‘Æ°á»£c cÃ´ng bá»‘ vÃ¬ chÆ°a Ä‘áº¡t tiÃªu chÃ­ an toÃ n).
âœ…Hai phiÃªn báº£n: Llama-2 vÃ  Llama-2-chat (Ä‘Æ°á»£c supervised fine-tune trÃªn hÆ¡n 100,000 samples vÃ  huáº¥n luyÃªn vá»›i RLHF trÃªn hÆ¡n 1 triá»‡u samples).
Nguá»“n áº£nh: real.ml.memes
-------------------------------
Nguá»“n: VietAI","Meta vÃ  Microsoft há»£p tÃ¡c cÃ´ng bá»‘ Llama 2: CÃ³ phiÃªn báº£n Chat, cho phÃ©p thÆ°Æ¡ng máº¡i hÃ³a Má»˜T Sá» THÃ”NG TIN QUAN TRá»ŒNG: Dá»¯ liá»‡u: 2 nghÃ¬n tá»‰ tokens. Nhiá»u hÆ¡n 40% so vá»›i Llama 1. Context length: 4096. KÃ­ch cá»¡: 7B, 13B, 70B tham sá»‘ (phiÃªn báº£n 34B chÆ°a Ä‘Æ°á»£c cÃ´ng bá»‘ vÃ¬ chÆ°a Ä‘áº¡t tiÃªu chÃ­ an toÃ n). Hai phiÃªn báº£n: Llama-2 vÃ  Llama-2-chat (Ä‘Æ°á»£c supervised fine-tune trÃªn hÆ¡n 100,000 samples vÃ  huáº¥n luyÃªn vá»›i RLHF trÃªn hÆ¡n 1 triá»‡u samples). Nguá»“n áº£nh: real.ml.memes ------------------------------- Nguá»“n: VietAI",,,"#sharing, #deep_learning",,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ model classification cÃ³ input 2 áº£nh vÃ  Ä‘Ã¢u ra lÃ  label 0 hoáº·c 1 (HÃ¬nh bÃªn dÆ°á»›i). Tuy nhiÃªn pháº§n data preparation em khÃ´ng biáº¿t chuáº©n bá»‹ tháº¿ nÃ o. Máº·c dÃ¹ cÃ³ nghiÃªn cá»©u nhiá»u blog trÃªn máº¡ng tuy nhiÃªn gáº·p khÃ¡ nhiá»u lá»—i (Blog: https://github.com/keras-team/keras/issues/8130). BÃªn dÆ°á»›i lÃ  code data preparation vá»›i ImageDataGenerator. Mong hÆ°á»›ng dáº«n pháº§n data preparation cho model 2 input áº£nh. MÃ¬nh cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ model classification cÃ³ input 2 áº£nh vÃ  Ä‘Ã¢u ra lÃ  label 0 hoáº·c 1 (HÃ¬nh bÃªn dÆ°á»›i). Tuy nhiÃªn pháº§n data preparation em khÃ´ng biáº¿t chuáº©n bá»‹ tháº¿ nÃ o. Máº·c dÃ¹ cÃ³ nghiÃªn cá»©u nhiá»u blog trÃªn máº¡ng tuy nhiÃªn gáº·p khÃ¡ nhiá»u lá»—i (Blog: https://github.com/keras-team/keras/issues/8130). BÃªn dÆ°á»›i lÃ  code data preparation vá»›i ImageDataGenerator. Mong hÆ°á»›ng dáº«n pháº§n data preparation cho model 2 input áº£nh. MÃ¬nh cáº£m Æ¡n.",,,"#Q&A, #cv, #data",,
"ChÃ o má»i ngÆ°á»i, bÃªn em Ä‘ang lÃ m 1 dá»± Ã¡n trading forex vÃ  hÃ ng hÃ³a. Má»i ngÆ°á»i cho em há»i lÃ  model machine learning nÃ o phÃ¹ há»£p nháº¥t dÃ¹ng cho trading áº¡. Bá»™ data thÃ¬ bÃªn em Ä‘ang láº¥y táº¡m trÃªn tradingview xuá»‘ng. Em cÃ¡m Æ¡n","ChÃ o má»i ngÆ°á»i, bÃªn em Ä‘ang lÃ m 1 dá»± Ã¡n trading forex vÃ  hÃ ng hÃ³a. Má»i ngÆ°á»i cho em há»i lÃ  model machine learning nÃ o phÃ¹ há»£p nháº¥t dÃ¹ng cho trading áº¡. Bá»™ data thÃ¬ bÃªn em Ä‘ang láº¥y táº¡m trÃªn tradingview xuá»‘ng. Em cÃ¡m Æ¡n",,,"#Q&A, #machine_learning",,
"ChÃ o cÃ¡c bÃ¡c, Em cÃ³ má»™t váº¥n Ä‘á» chÆ°a tÃ¬m ra cÃ¡ch giáº£i quyáº¿t khi sá»­ dá»¥ng model yolov8 detection Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng ONNX.
CÃ³ thá»ƒ tháº¥y trÃªn hÃ¬nh dÆ°á»›i
Äáº§u vÃ o
```
name: images
type: float32[1,3,640,640]
```
Äáº§u ra
```
name: output0
type: float32[1,6,8400]
``` 
á» Ä‘Ã¢y theo em hiá»ƒu thÃ¬
Äáº§u vÃ o lÃ  má»™t array float mÃ u RGB kÃ­ch cá»¡ 640x640 chiá»u tá»« trÃ¡i qua pháº£i, tá»« trÃªn xuá»‘ng dÆ°á»›i.
Äáº§u ra cÃ³ 6 object array float má»—i 1  object cÃ³ 8400 giÃ¡ trá»‹ float. DÆ°á»›i Ä‘Ã¢y lÃ  máº«u:
```
{6.489357,14.580679,30.33416,36.84166,37.909622,42.389004,48.190636,55.96879,65.08879,72.705215,80.317604,87.94593,94.21246,100.19607,102.2921,108.48764,117.27652,149.78645,162.2814,167.18387,170.57477,173.82574,180.09859.....},
...
{22.857464,11.46661,7.262705,8.254338,8.966676,9.688668,10.24382,9.745479,9.374667,10.221896,10.54862,10.452046,10.352717,9.953964,10.596357,10.261409,7.7730684,6.377458,7.735608,9.637968,11.539716,13.111305,13.758495,13.440787,10.037614,8.329343,9.301963,8.501963,6.6712275,6.865048.....},
```
Em Ä‘ang khÃ´ng rÃµ dÃ£y nÃ y Ä‘Æ°á»£c Ä‘á»c nhÆ° tháº¿ nÃ o, cÃ¡c bÃ¡c Ä‘Ã£ tá»«ng lÃ m qua cho em xin hÆ°á»›ng tiáº¿p cáº­n Ä‘á»ƒ Ä‘á»c output áº¡.
Em cáº£m Æ¡n trÆ°á»›c, chÃºc cÃ¡c bÃ¡c má»™t ngÃ y vui váº».","ChÃ o cÃ¡c bÃ¡c, Em cÃ³ má»™t váº¥n Ä‘á» chÆ°a tÃ¬m ra cÃ¡ch giáº£i quyáº¿t khi sá»­ dá»¥ng model yolov8 detection Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng ONNX. CÃ³ thá»ƒ tháº¥y trÃªn hÃ¬nh dÆ°á»›i Äáº§u vÃ o ``` name: images type: float32[1,3,640,640] ``` Äáº§u ra ``` name: output0 type: float32[1,6,8400] ``` á» Ä‘Ã¢y theo em hiá»ƒu thÃ¬ Äáº§u vÃ o lÃ  má»™t array float mÃ u RGB kÃ­ch cá»¡ 640x640 chiá»u tá»« trÃ¡i qua pháº£i, tá»« trÃªn xuá»‘ng dÆ°á»›i. Äáº§u ra cÃ³ 6 object array float má»—i 1 object cÃ³ 8400 giÃ¡ trá»‹ float. DÆ°á»›i Ä‘Ã¢y lÃ  máº«u: ``` {6.489357,14.580679,30.33416,36.84166,37.909622,42.389004,48.190636,55.96879,65.08879,72.705215,80.317604,87.94593,94.21246,100.19607,102.2921,108.48764,117.27652,149.78645,162.2814,167.18387,170.57477,173.82574,180.09859.....}, ... {22.857464,11.46661,7.262705,8.254338,8.966676,9.688668,10.24382,9.745479,9.374667,10.221896,10.54862,10.452046,10.352717,9.953964,10.596357,10.261409,7.7730684,6.377458,7.735608,9.637968,11.539716,13.111305,13.758495,13.440787,10.037614,8.329343,9.301963,8.501963,6.6712275,6.865048.....}, ``` Em Ä‘ang khÃ´ng rÃµ dÃ£y nÃ y Ä‘Æ°á»£c Ä‘á»c nhÆ° tháº¿ nÃ o, cÃ¡c bÃ¡c Ä‘Ã£ tá»«ng lÃ m qua cho em xin hÆ°á»›ng tiáº¿p cáº­n Ä‘á»ƒ Ä‘á»c output áº¡. Em cáº£m Æ¡n trÆ°á»›c, chÃºc cÃ¡c bÃ¡c má»™t ngÃ y vui váº».",,,,,
"Nhá» cÃ¡c anh giÃºp em xÃ¡c Ä‘á»‹nh output vÃ  input !
Em dÃ¹ng Machine Learning trong Visual studio Sá»­ dá»¥ng tÃ­nh nÄƒng object detection ra Ä‘Æ°á»£c file onnx nhÆ° tháº¿ nÃ y
NhÆ°ng khi mÃ¬nh Ä‘iá»n input vÃ  ouput vÃ o pipeline dÃ¹ng thÆ° viá»‡n ML.net thÃ¬ bÃ¡o sai input vÃ  output :( !
KhÃ´ng biáº¿t táº¡i sao :(
[ColumnName(""input"")]
[VectorType(1, 3, 600, 800)]
public float[] Input { get; set; }
[ColumnName(""boxes"")]
[VectorType(1, 4)]
public float[] Boxes { get; set; }
[ColumnName(""labels"")]
[VectorType(1)]
public long[] Labels { get; set; }
[ColumnName(""scores"")]
[VectorType(1)]
public float[] Scores { get; set;
var pipeline =context.Transforms.ResizeImages(resizing: Microsoft.ML.Transforms.Image.ImageResizingEstimator.ResizingKind.Fill,
outputColumnName: ""resize"",
imageWidth: 800,
imageHeight: 600,
inputColumnName: nameof(RTFInput.ImageSource)
)
.Append(
context.Transforms.ExtractPixels(
offsetImage: 127f,
scaleImage: 1 / 128f,
inputColumnName: ""resize"",
outputColumnName: ""input"")
).Append(
context.Transforms.ApplyOnnxModel(
modelFile: modelFile,
inputColumnNames: new string[] { ""input"" },
outputColumnNames: new string[] { ""scores"", ""boxes"", ""labels"" }));","Nhá» cÃ¡c anh giÃºp em xÃ¡c Ä‘á»‹nh output vÃ  input ! Em dÃ¹ng Machine Learning trong Visual studio Sá»­ dá»¥ng tÃ­nh nÄƒng object detection ra Ä‘Æ°á»£c file onnx nhÆ° tháº¿ nÃ y NhÆ°ng khi mÃ¬nh Ä‘iá»n input vÃ  ouput vÃ o pipeline dÃ¹ng thÆ° viá»‡n ML.net thÃ¬ bÃ¡o sai input vÃ  output :( ! KhÃ´ng biáº¿t táº¡i sao :( [ColumnName(""input"")] [VectorType(1, 3, 600, 800)] public float[] Input { get; set; } [ColumnName(""boxes"")] [VectorType(1, 4)] public float[] Boxes { get; set; } [ColumnName(""labels"")] [VectorType(1)] public long[] Labels { get; set; } [ColumnName(""scores"")] [VectorType(1)] public float[] Scores { get; set; var pipeline =context.Transforms.ResizeImages(resizing: Microsoft.ML.Transforms.Image.ImageResizingEstimator.ResizingKind.Fill, outputColumnName: ""resize"", imageWidth: 800, imageHeight: 600, inputColumnName: nameof(RTFInput.ImageSource) ) .Append( context.Transforms.ExtractPixels( offsetImage: 127f, scaleImage: 1 / 128f, inputColumnName: ""resize"", outputColumnName: ""input"") ).Append( context.Transforms.ApplyOnnxModel( modelFile: modelFile, inputColumnNames: new string[] { ""input"" }, outputColumnNames: new string[] { ""scores"", ""boxes"", ""labels"" }));",,,"#Q&A, #deep_learning",,
"#hoidap
MÃ¬nh má»›i cÃ  Ä‘Æ°á»£c táº§m 6000 comment trÃªn trang tripnow .MÃ¬nh Ä‘á»‹nh lÃ m sentiment analysis. Má»—i comment cÃ³ score nÃªn mÃ¬nh láº¥y nÃ³ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ comment lÃ  tÃ­ch cá»±c hay tiÃªu cá»±c.NhÆ°ng trÆ°á»›c khi Ä‘i vÃ o model thÃ¬ bÆ°á»›c preprocessing mÃ¬nh cÃ³ chÃºt tháº¯c máº¯c Ä‘Ã³ lÃ  trong tiáº¿ng viá»‡t khi ""Tokenizer"" thÃ¬ má»i ngÆ°á»i hay lÃ m tháº¿ nÃ o. DÃ¹ng 1-gram hay Bigram.
p/s :Do láº§n Ä‘áº§u Ã¡p dá»¥ng trong tiáº¿ng viá»‡t mong má»i ngÆ°á»i giÃºp Ä‘á»¡.","MÃ¬nh má»›i cÃ  Ä‘Æ°á»£c táº§m 6000 comment trÃªn trang tripnow .MÃ¬nh Ä‘á»‹nh lÃ m sentiment analysis. Má»—i comment cÃ³ score nÃªn mÃ¬nh láº¥y nÃ³ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ comment lÃ  tÃ­ch cá»±c hay tiÃªu cá»±c.NhÆ°ng trÆ°á»›c khi Ä‘i vÃ o model thÃ¬ bÆ°á»›c preprocessing mÃ¬nh cÃ³ chÃºt tháº¯c máº¯c Ä‘Ã³ lÃ  trong tiáº¿ng viá»‡t khi ""Tokenizer"" thÃ¬ má»i ngÆ°á»i hay lÃ m tháº¿ nÃ o. DÃ¹ng 1-gram hay Bigram. p/s :Do láº§n Ä‘áº§u Ã¡p dá»¥ng trong tiáº¿ng viá»‡t mong má»i ngÆ°á»i giÃºp Ä‘á»¡.",#hoidap,,"#Q&A, #nlp",,
"Hi mng nha, em lÃ  SV bÃªn ngÃ nh tá»± Ä‘á»™ng hoÃ¡ trÆ°á»ng BK HCM, Ä‘á»£t lÃ m luáº­n vÄƒn vá»«a rá»“i em cÃ³ lÃ m Ä‘á» tÃ i vá» â€œ3D Object detection vÃ  6D Pose estimation application for robotics bin picking systemâ€, thÃ¬ khÃ¡ thÃ­ch vÃ  Ä‘am mÃª vá» máº£ng Computer vision/Machine vision muá»‘n theo sau khi tá»‘t nghiá»‡p, nÃªn sau khi vá»«a hoÃ n táº¥t chÆ°Æ¡ng trÃ¬nh há»c Ä‘á»£t thÃ¡ng 6 vá»«a rá»“i thÃ¬ em cÃ³ tá»± há»c kha khÃ¡ cÃ¡c thuáº­t toÃ¡n cá»§a machine learning, thÃ¬ cÃ³ tham kháº£o cÃ¡c bÃªn tuyá»ƒn dá»¥ng hiá»‡n cÃ³ thÃ¬ pháº§n lá»›n cÃ¡c bÃªn tuyá»ƒn dá»¥ng sáº½ hÆ°á»›ng Ä‘áº¿n AI engineer luÃ´n vÃ  sáº½ Ä‘Ã²i há»i biáº¿t cáº£ computer vision vÃ  NLP, thÃ¬ em phÃ¢n vÃ¢n bÃ¢y giá» cÃ³ cáº§n há»c luÃ´n kiáº¿n thá»©c cáº£ NLP vÃ  CV luÃ´n khÃ´ng hay táº­p trung Ä‘áº©y máº¡nh máº£ng CV. Táº¡i em cÅ©ng muá»‘n rÃºt ngáº¯n thá»i gian tá»± há»c Ä‘á»ƒ cÃ³ thá»ƒ xin Ä‘i intern tÃ­ch thÃªm kinh nghiá»‡m thay vÃ¬ chá» há»c xong full táº¥t cáº£ thÃ¬ quÃ¡ lÃ¢u. Hi vá»ng mng cÃ³ thá»ƒ cho em tÃ­ lá»i khuyÃªn áº¡. Em cáº£m Æ¡n!","Hi mng nha, em lÃ  SV bÃªn ngÃ nh tá»± Ä‘á»™ng hoÃ¡ trÆ°á»ng BK HCM, Ä‘á»£t lÃ m luáº­n vÄƒn vá»«a rá»“i em cÃ³ lÃ m Ä‘á» tÃ i vá» â€œ3D Object detection vÃ  6D Pose estimation application for robotics bin picking systemâ€, thÃ¬ khÃ¡ thÃ­ch vÃ  Ä‘am mÃª vá» máº£ng Computer vision/Machine vision muá»‘n theo sau khi tá»‘t nghiá»‡p, nÃªn sau khi vá»«a hoÃ n táº¥t chÆ°Æ¡ng trÃ¬nh há»c Ä‘á»£t thÃ¡ng 6 vá»«a rá»“i thÃ¬ em cÃ³ tá»± há»c kha khÃ¡ cÃ¡c thuáº­t toÃ¡n cá»§a machine learning, thÃ¬ cÃ³ tham kháº£o cÃ¡c bÃªn tuyá»ƒn dá»¥ng hiá»‡n cÃ³ thÃ¬ pháº§n lá»›n cÃ¡c bÃªn tuyá»ƒn dá»¥ng sáº½ hÆ°á»›ng Ä‘áº¿n AI engineer luÃ´n vÃ  sáº½ Ä‘Ã²i há»i biáº¿t cáº£ computer vision vÃ  NLP, thÃ¬ em phÃ¢n vÃ¢n bÃ¢y giá» cÃ³ cáº§n há»c luÃ´n kiáº¿n thá»©c cáº£ NLP vÃ  CV luÃ´n khÃ´ng hay táº­p trung Ä‘áº©y máº¡nh máº£ng CV. Táº¡i em cÅ©ng muá»‘n rÃºt ngáº¯n thá»i gian tá»± há»c Ä‘á»ƒ cÃ³ thá»ƒ xin Ä‘i intern tÃ­ch thÃªm kinh nghiá»‡m thay vÃ¬ chá» há»c xong full táº¥t cáº£ thÃ¬ quÃ¡ lÃ¢u. Hi vá»ng mng cÃ³ thá»ƒ cho em tÃ­ lá»i khuyÃªn áº¡. Em cáº£m Æ¡n!",,,"#Q&A, #cv",,
"Má»i ngÆ°á»i cho em há»i áº¡: Em cÃ³ 1 bá»™ dá»¯ liá»‡u khÃ¡ lá»›n, náº¿u mÃ  train cáº£ 1 epoch thÃ¬ sáº½ quÃ¡ thá»i gian cháº¡y tá»‘i Ä‘a trÃªn Kaggle. NÃªn em Ä‘á»‹nh chia Ä‘Ã´i thÃ nh 2 datasets vÃ  lÃ m theo 1 trong 2 cÃ¡ch sau Ä‘Æ°á»£c khÃ´ng hay lÃ  nÃªn lÃ m theo cÃ¡ch khÃ¡c tá»‘t hÆ¡n áº¡:
1. Train luÃ¢n phiÃªn 1 epoch vá»›i dataset 1 rá»“i Ä‘áº¿n 1 epoch vá»›i dataset 2
2. Train xong vá»›i dataset 1 rá»“i train tiáº¿p Ä‘áº¿n dataset 2
Em cáº£m Æ¡n áº¡","Má»i ngÆ°á»i cho em há»i áº¡: Em cÃ³ 1 bá»™ dá»¯ liá»‡u khÃ¡ lá»›n, náº¿u mÃ  train cáº£ 1 epoch thÃ¬ sáº½ quÃ¡ thá»i gian cháº¡y tá»‘i Ä‘a trÃªn Kaggle. NÃªn em Ä‘á»‹nh chia Ä‘Ã´i thÃ nh 2 datasets vÃ  lÃ m theo 1 trong 2 cÃ¡ch sau Ä‘Æ°á»£c khÃ´ng hay lÃ  nÃªn lÃ m theo cÃ¡ch khÃ¡c tá»‘t hÆ¡n áº¡: 1. Train luÃ¢n phiÃªn 1 epoch vá»›i dataset 1 rá»“i Ä‘áº¿n 1 epoch vá»›i dataset 2 2. Train xong vá»›i dataset 1 rá»“i train tiáº¿p Ä‘áº¿n dataset 2 Em cáº£m Æ¡n áº¡",,,"#Q&A, #machine_learning, #data",,
"ChÃ o cÃ¡c anh chá»‹ trong group, em má»›i tÃ¬m hiá»ƒu vá» machine learning, Ä‘á»c Ä‘áº¿m Ä‘oáº¡n nÃ y thÃ¬ e cÃ³ 2 cÃ¢u há»i:
+) âˆ’âˆ‡f0(x0) lÃ  gÃ¬? VÃ¬ trÆ°á»›c h em hiá»ƒu Ä‘Ã³ lÃ  vector gradient nhÆ°ng trong bÃ i viáº¿t láº¡i ghi lÃ  vector phÃ¡p tuyáº¿n
+) máº·t pháº³ng supporting hyperlane trÃ´ng ntn trong kgian 3 chiá»u,
Mong cÃ¡c anh chá»‹ giáº£i Ä‘Ã¡p giÃºp e áº¡, em cáº£m Æ¡n áº¡","ChÃ o cÃ¡c anh chá»‹ trong group, em má»›i tÃ¬m hiá»ƒu vá» machine learning, Ä‘á»c Ä‘áº¿m Ä‘oáº¡n nÃ y thÃ¬ e cÃ³ 2 cÃ¢u há»i: +) âˆ’âˆ‡f0(x0) lÃ  gÃ¬? VÃ¬ trÆ°á»›c h em hiá»ƒu Ä‘Ã³ lÃ  vector gradient nhÆ°ng trong bÃ i viáº¿t láº¡i ghi lÃ  vector phÃ¡p tuyáº¿n +) máº·t pháº³ng supporting hyperlane trÃ´ng ntn trong kgian 3 chiá»u, Mong cÃ¡c anh chá»‹ giáº£i Ä‘Ã¡p giÃºp e áº¡, em cáº£m Æ¡n áº¡",,,"#Q&A, #math",,
"Má»i ngÆ°á»i cho em há»i: Vá»›i Text to speech, Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cháº¥t lÆ°á»£ng thÆ°Æ¡ng máº¡i nhÆ° cá»§a Vbee, Vietel, FPT thÃ¬ há» cáº§n khoáº£ng bao nhiÃªu giá» dá»¯ liá»‡u váº­y? (Bá» qua váº¥n Ä‘á» ká»¹ thuáº­t)","Má»i ngÆ°á»i cho em há»i: Vá»›i Text to speech, Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cháº¥t lÆ°á»£ng thÆ°Æ¡ng máº¡i nhÆ° cá»§a Vbee, Vietel, FPT thÃ¬ há» cáº§n khoáº£ng bao nhiÃªu giá» dá»¯ liá»‡u váº­y? (Bá» qua váº¥n Ä‘á» ká»¹ thuáº­t)",,,"#Q&A, #nlp",,
"Hi má»i ngÆ°á»i , em Ä‘ang tÃ¬m hiá»ƒu vÃ  sá»­ dá»¥ng Yolov7 Pose : https://github.com/WongKinYiu/yolov7/tree/pose . Em tháº¥y tÃ¡c giáº£ Ä‘á» cáº­p Ä‘áº¿n model nÃ y dá»±a theo bÃ i bÃ¡o : https://arxiv.org/ftp/arxiv/papers/2204/2204.06806.pdf . Em lÃ  newbie trong máº£ng nÃ y nÃªn chÆ°a biáº¿t model hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o , lÃ m tháº¿ nÃ o Ä‘á»ƒ láº¥y Ä‘Æ°á»£c Keypoint ... Mong má»i ngÆ°á»i chá»‰ giÃ¡o áº¡ . Má»i ngÆ°á»i cÃ³ resources nÃ o thÃ¬ cho em tham kháº£o vá»›i áº¡ . Em xin chÃ¢n thÃ nh cáº£m Æ¡n !!!","Hi má»i ngÆ°á»i , em Ä‘ang tÃ¬m hiá»ƒu vÃ  sá»­ dá»¥ng Yolov7 Pose : https://github.com/WongKinYiu/yolov7/tree/pose . Em tháº¥y tÃ¡c giáº£ Ä‘á» cáº­p Ä‘áº¿n model nÃ y dá»±a theo bÃ i bÃ¡o : https://arxiv.org/ftp/arxiv/papers/2204/2204.06806.pdf . Em lÃ  newbie trong máº£ng nÃ y nÃªn chÆ°a biáº¿t model hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o , lÃ m tháº¿ nÃ o Ä‘á»ƒ láº¥y Ä‘Æ°á»£c Keypoint ... Mong má»i ngÆ°á»i chá»‰ giÃ¡o áº¡ . Má»i ngÆ°á»i cÃ³ resources nÃ o thÃ¬ cho em tham kháº£o vá»›i áº¡ . Em xin chÃ¢n thÃ nh cáº£m Æ¡n !!!",,,"#Q&A, #deep_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡,em Ä‘ang lÃ m bÃ i toÃ¡n sá»­ dá»¥ng local Naive Bayes Nearest Neighbour phÃ¢n loáº¡i áº£nh thÃº cÆ°ng :chuá»™t ,mÃ¨o (táº­p train cá»§a má»—i class sáº½ cÃ³ 20 áº£nh ,cÃ¡c áº£nh Ä‘á»u láº¥y tá»« trÃªn máº¡ng)Em cÃ³ sá»­ dá»¥ng SIFT Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng ,nhÆ°ng káº¿t quáº£ ko Ä‘c nhÆ° mong muá»‘n,em xin há»i liá»‡u cÃ³ phÆ°Æ¡ng phÃ¡p Ä‘Ãª cáº£i thiá»‡n bÃ i toÃ¡n khÃ´ng áº¡? Em cáº£m Æ¡n áº¡","Em chÃ o má»i ngÆ°á»i áº¡,em Ä‘ang lÃ m bÃ i toÃ¡n sá»­ dá»¥ng local Naive Bayes Nearest Neighbour phÃ¢n loáº¡i áº£nh thÃº cÆ°ng :chuá»™t ,mÃ¨o (táº­p train cá»§a má»—i class sáº½ cÃ³ 20 áº£nh ,cÃ¡c áº£nh Ä‘á»u láº¥y tá»« trÃªn máº¡ng)Em cÃ³ sá»­ dá»¥ng SIFT Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng ,nhÆ°ng káº¿t quáº£ ko Ä‘c nhÆ° mong muá»‘n,em xin há»i liá»‡u cÃ³ phÆ°Æ¡ng phÃ¡p Ä‘Ãª cáº£i thiá»‡n bÃ i toÃ¡n khÃ´ng áº¡? Em cáº£m Æ¡n áº¡",,,"#Q&A, #cv, #machine_learning",,
Machine Learning Operations (MLOps) - End-to-End Process,Machine Learning Operations (MLOps) - End-to-End Process,,,,,
"ChÃ o cÃ¡c báº¡n, nguyÃªn vÄƒn cá»§a chuyÃªn gia computer vision FPT cÃ³ Ä‘oáº¡n viáº¿t cho bÃ i toÃ¡n chá»©ng minh thÆ°: :D
""1. Cropper
TÃ¡c vá»¥ nÃ y xÃ¡c Ä‘á»‹nh 4 gÃ³c cá»§a tháº» CMND vÃ  sau Ä‘Ã³ cáº¯t vá» dáº¡ng áº£nh chá»¯ nháº­t. Ã nghÄ©a chÃ­nh cá»§a tÃ¡c vá»¥ lÃ  phá»¥c vá»¥ cho viá»‡c Detector liá»n ká» sau Ä‘Ã³ dá»… dÃ ng hÆ¡n.
CÃ¡c mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng (object detection) phá»• biáº¿n hiá»‡n nay chá»‰ tráº£ vá» 2 gÃ³c (trÃ¡i trÃªn pháº£i dÆ°á»›i, hoáº·c tÃ¢m box kÃ¨m giÃ¡ trá»‹ chiá»u ngang dá»c) giÃºp ta Ä‘á»‹nh hÃ¬nh má»™t box hÃ¬nh chá»¯ nháº­t. ChÃºng tÃ´i sá»­ dá»¥ng má»™t máº¹o nhá» báº±ng cÃ¡ch coi má»—i gÃ³c cá»§a CMND lÃ  má»™t Ä‘á»‘i tÆ°á»£ng vÃ  sau Ä‘Ã³ phÃ¡t hiá»‡n 4 gÃ³c nÃ y. Tiáº¿p theo Ä‘Ã³ báº±ng cÃ¡ch Ã¡p dá»¥ng má»™t vÃ i phÃ©p biáº¿n Ä‘á»•i hÃ¬nh há»c cÆ¡ báº£n Ä‘á»ƒ cáº¯t vá» dáº¡ng áº£nh chá»¯ nháº­t.
MÃ´ hÃ¬nh phÃ¡t hiá»‡n mÃ  nhÃ³m nghiÃªn cá»©u Ä‘ang sá»­ dá»¥ng lÃ  bá»™ phÃ¡t hiá»‡n Ä‘Æ¡n pha: SSD (SSD: Single Shot MultiBox Detector), vá»›i bá»™ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng lÃ  MobileNet v2 (MobileNetV2: Inverted Residuals vÃ  Linear Bottlenecks).
SSD cung cáº¥p cho nhÃ³m nghiÃªn cá»©u tá»‘c Ä‘á»™ truy xuáº¥t nhanh, trong khi MobileNet v2 giáº£m sá»‘ lÆ°á»£ng tÃ­nh toÃ¡n vÃ  bá»™ nhá»› sá»­ dá»¥ng nhÆ°ng váº«n duy trÃ¬ Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c tá»‘t.""
MÃ¬nh nghÄ© lÃ  há» muá»‘n detect chÃ­nh xÃ¡c 4 Ä‘iá»ƒm giá»‘ng nhÆ° regression, tuy váº­y mÃ¬nh Ä‘ang khÃ´ng hiá»ƒu cÃ¡i máº¹o nhá» cá»§a há» á»Ÿ Ä‘Ã¢y cá»¥ thá»ƒ lÃ  gÃ¬? Há» coi má»—i gÃ³c lÃ  má»™t object??? NghÄ©a lÃ  tháº¿ nÃ o? SSD dÃ¹ng á»Ÿ Ä‘Ã¢y lÃ  Ä‘á»ƒ detect vÃ¹ng chá»©ng minh thÆ° theo há»™p chá»¯ nháº­t chá»© lÃ m sao detect 4 Ä‘iá»ƒm?
CÃ¡c báº¡n cÃ³ Ã½ kiáº¿n gÃ¬ khÃ´ng?","ChÃ o cÃ¡c báº¡n, nguyÃªn vÄƒn cá»§a chuyÃªn gia computer vision FPT cÃ³ Ä‘oáº¡n viáº¿t cho bÃ i toÃ¡n chá»©ng minh thÆ°: :D ""1. Cropper TÃ¡c vá»¥ nÃ y xÃ¡c Ä‘á»‹nh 4 gÃ³c cá»§a tháº» CMND vÃ  sau Ä‘Ã³ cáº¯t vá» dáº¡ng áº£nh chá»¯ nháº­t. Ã nghÄ©a chÃ­nh cá»§a tÃ¡c vá»¥ lÃ  phá»¥c vá»¥ cho viá»‡c Detector liá»n ká» sau Ä‘Ã³ dá»… dÃ ng hÆ¡n. CÃ¡c mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng (object detection) phá»• biáº¿n hiá»‡n nay chá»‰ tráº£ vá» 2 gÃ³c (trÃ¡i trÃªn pháº£i dÆ°á»›i, hoáº·c tÃ¢m box kÃ¨m giÃ¡ trá»‹ chiá»u ngang dá»c) giÃºp ta Ä‘á»‹nh hÃ¬nh má»™t box hÃ¬nh chá»¯ nháº­t. ChÃºng tÃ´i sá»­ dá»¥ng má»™t máº¹o nhá» báº±ng cÃ¡ch coi má»—i gÃ³c cá»§a CMND lÃ  má»™t Ä‘á»‘i tÆ°á»£ng vÃ  sau Ä‘Ã³ phÃ¡t hiá»‡n 4 gÃ³c nÃ y. Tiáº¿p theo Ä‘Ã³ báº±ng cÃ¡ch Ã¡p dá»¥ng má»™t vÃ i phÃ©p biáº¿n Ä‘á»•i hÃ¬nh há»c cÆ¡ báº£n Ä‘á»ƒ cáº¯t vá» dáº¡ng áº£nh chá»¯ nháº­t. MÃ´ hÃ¬nh phÃ¡t hiá»‡n mÃ  nhÃ³m nghiÃªn cá»©u Ä‘ang sá»­ dá»¥ng lÃ  bá»™ phÃ¡t hiá»‡n Ä‘Æ¡n pha: SSD (SSD: Single Shot MultiBox Detector), vá»›i bá»™ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng lÃ  MobileNet v2 (MobileNetV2: Inverted Residuals vÃ  Linear Bottlenecks). SSD cung cáº¥p cho nhÃ³m nghiÃªn cá»©u tá»‘c Ä‘á»™ truy xuáº¥t nhanh, trong khi MobileNet v2 giáº£m sá»‘ lÆ°á»£ng tÃ­nh toÃ¡n vÃ  bá»™ nhá»› sá»­ dá»¥ng nhÆ°ng váº«n duy trÃ¬ Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c tá»‘t."" MÃ¬nh nghÄ© lÃ  há» muá»‘n detect chÃ­nh xÃ¡c 4 Ä‘iá»ƒm giá»‘ng nhÆ° regression, tuy váº­y mÃ¬nh Ä‘ang khÃ´ng hiá»ƒu cÃ¡i máº¹o nhá» cá»§a há» á»Ÿ Ä‘Ã¢y cá»¥ thá»ƒ lÃ  gÃ¬? Há» coi má»—i gÃ³c lÃ  má»™t object??? NghÄ©a lÃ  tháº¿ nÃ o? SSD dÃ¹ng á»Ÿ Ä‘Ã¢y lÃ  Ä‘á»ƒ detect vÃ¹ng chá»©ng minh thÆ° theo há»™p chá»¯ nháº­t chá»© lÃ m sao detect 4 Ä‘iá»ƒm? CÃ¡c báº¡n cÃ³ Ã½ kiáº¿n gÃ¬ khÃ´ng?",,,"#Q&A, #cv",,
"Má»i ngÆ°á»i cho mÃ¬nh há»i , giá» mÃ¬nh cÃ³ 1 áº£nh chá»©a 1 sá»‘ lÃ¡ bÃ i . Váº­y thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ Ä‘á»c Ä‘Æ°á»£c tá»« hÃ¬nh áº£nh rá»“i ra text gá»“m giÃ¡ trá»‹ lÃ¡ bÃ i + Cháº¥t cá»§a lÃ¡ bÃ i Ä‘Ã³ khÃ´ng ! Cáº£m Æ¡n","Má»i ngÆ°á»i cho mÃ¬nh há»i , giá» mÃ¬nh cÃ³ 1 áº£nh chá»©a 1 sá»‘ lÃ¡ bÃ i . Váº­y thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ Ä‘á»c Ä‘Æ°á»£c tá»« hÃ¬nh áº£nh rá»“i ra text gá»“m giÃ¡ trá»‹ lÃ¡ bÃ i + Cháº¥t cá»§a lÃ¡ bÃ i Ä‘Ã³ khÃ´ng ! Cáº£m Æ¡n",,,"#Q&A, #cv",,
"Dáº¡ má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin thÃ´ng tin vá» cÃ¡c tráº¡i hÃ¨, trÆ°á»ng hÃ¨, workshop, conference, Seminar (offline nÄƒm nay) liÃªn quan Ä‘áº¿n AI/Machine Learning á»Ÿ Viá»‡t Nam khÃ´ng áº¡? Em hi vá»ng post nÃ y cÃ³ thá»ƒ tá»•ng há»£p Ä‘Æ°á»£c thÃ´ng tin vá» cÃ¡c sá»± kiá»‡n nhÆ° tháº¿ Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng sá»Ÿ thÃ­ch cÃ³ thá»ƒ gáº·p gá»¡ vÃ  trao Ä‘á»•i áº¡ ^^.","Dáº¡ má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin thÃ´ng tin vá» cÃ¡c tráº¡i hÃ¨, trÆ°á»ng hÃ¨, workshop, conference, Seminar (offline nÄƒm nay) liÃªn quan Ä‘áº¿n AI/Machine Learning á»Ÿ Viá»‡t Nam khÃ´ng áº¡? Em hi vá»ng post nÃ y cÃ³ thá»ƒ tá»•ng há»£p Ä‘Æ°á»£c thÃ´ng tin vá» cÃ¡c sá»± kiá»‡n nhÆ° tháº¿ Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng sá»Ÿ thÃ­ch cÃ³ thá»ƒ gáº·p gá»¡ vÃ  trao Ä‘á»•i áº¡ ^^.",,,#webinar,,
Bard cá»§a Google Ä‘Ã£ há»— trá»£ thÃªm cÃ¡c ngÃ´n ngá»¯ má»›i trong Ä‘Ã³ cÃ³ tiáº¿ng Viá»‡t. CÃ¹ng má»™t sá»‘ tÃ­nh nÄƒng Ä‘Ã¡ng chÃº Ã½. Chi tiáº¿t táº¡i link sau:,Bard cá»§a Google Ä‘Ã£ há»— trá»£ thÃªm cÃ¡c ngÃ´n ngá»¯ má»›i trong Ä‘Ã³ cÃ³ tiáº¿ng Viá»‡t. CÃ¹ng má»™t sá»‘ tÃ­nh nÄƒng Ä‘Ã¡ng chÃº Ã½. Chi tiáº¿t táº¡i link sau:,,,"#sharing, #nlp",,
"Cho mÃ¬nh há»i,
MÃ¬nh Ä‘ang xá»­ lÃ½ bÃ i toÃ¡n xáº¿p thá»i khoÃ¡ biá»ƒu, qua tÃ¬m hiá»ƒu thÃ¬ dÃ¹ng thuáº­t toÃ¡ Genetic Algorithm (GA) váº«n lÃ  phá»• biáº¿n nháº¥t.
CÃ³ ai Ä‘Ã£ dÃ¹ng nhiá»u vÃ  chá»‰ giÃºp thÆ° viá»‡n nÃ o tá»‘t nháº¥t Ä‘á»ƒ á»©ng dá»¥ng GA nÃ y cho ná»n .Net khÃ´ng?
Cáº£m Æ¡n!","Cho mÃ¬nh há»i, MÃ¬nh Ä‘ang xá»­ lÃ½ bÃ i toÃ¡n xáº¿p thá»i khoÃ¡ biá»ƒu, qua tÃ¬m hiá»ƒu thÃ¬ dÃ¹ng thuáº­t toÃ¡ Genetic Algorithm (GA) váº«n lÃ  phá»• biáº¿n nháº¥t. CÃ³ ai Ä‘Ã£ dÃ¹ng nhiá»u vÃ  chá»‰ giÃºp thÆ° viá»‡n nÃ o tá»‘t nháº¥t Ä‘á»ƒ á»©ng dá»¥ng GA nÃ y cho ná»n .Net khÃ´ng? Cáº£m Æ¡n!",,,"#Q&A, #machine_learning",,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng thÃ´ng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, vÃ  sá»± kiá»‡n thÃ¡ng 7/2023 vÃ o post nÃ y.
ChÃºc cÃ¡c báº¡n má»™t mÃ¹a hÃ¨ vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng thÃ´ng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, vÃ  sá»± kiá»‡n thÃ¡ng 7/2023 vÃ o post nÃ y. ChÃºc cÃ¡c báº¡n má»™t mÃ¹a hÃ¨ vui váº».",,,#sharing,,
"Em chÃ o táº¥t cáº£ cÃ¡c anh chá»‹ cÃ³ trong Ä‘Ã¢y áº¡. Em lÃ  sinh viÃªn vÃ  em cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» transformer. Cá»¥ thá»ƒ lÃ  bÃ i toÃ¡n text summarization vá»›i mÃ´ hÃ¬nh PEGASUS . Db lÃ  tiáº¿ng viá»‡t nhÆ°ng em Ä‘ang gáº·p 1 sá»‘ váº¥n Ä‘á» kiá»ƒu khi em Train ra Ä‘oáº¡n text summarization nÃ³ bá»‹ tÃ¬nh tráº¡ng máº¥t dáº¥u, máº¥t chá»¯ cÃ¡i tiáº¿ng viá»‡t. Anh chá»‹ cÃ³ thá»ƒ giÃºp em tÃ¬m lÃ½ do vÃ  kháº¯c phá»¥c Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n","Em chÃ o táº¥t cáº£ cÃ¡c anh chá»‹ cÃ³ trong Ä‘Ã¢y áº¡. Em lÃ  sinh viÃªn vÃ  em cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» transformer. Cá»¥ thá»ƒ lÃ  bÃ i toÃ¡n text summarization vá»›i mÃ´ hÃ¬nh PEGASUS . Db lÃ  tiáº¿ng viá»‡t nhÆ°ng em Ä‘ang gáº·p 1 sá»‘ váº¥n Ä‘á» kiá»ƒu khi em Train ra Ä‘oáº¡n text summarization nÃ³ bá»‹ tÃ¬nh tráº¡ng máº¥t dáº¥u, máº¥t chá»¯ cÃ¡i tiáº¿ng viá»‡t. Anh chá»‹ cÃ³ thá»ƒ giÃºp em tÃ¬m lÃ½ do vÃ  kháº¯c phá»¥c Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n",,,"#Q&A, #nlp, #deep_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡.Em lÃ  newbie má»›i nháº­p mÃ´n cá»§a ngÃ nh.Chuyá»‡n lÃ  trong quÃ¡ trÃ¬nh xá»­ lÃ½ data em cÃ³ 1 sá»‘ tháº¯c máº¯c mong Ä‘c mn giáº£i Ä‘Ã¡p áº¡:
1.Táº¡i sao láº¡i fit trÃªn train vÃ  transform trÃªn test? (CÃ¡i nÃ y em cÃ³ Ä‘á»c qua vÃ  hiá»ƒu sÆ¡ sÆ¡ nhÆ°ng mong Ä‘c má»i ngÆ°á»i giáº£i Ä‘Ã¡p rÃµ rÃ ng hÆ¡n áº¡) VÃ  náº¿u nhÆ° váº­y thÃ¬ cÃ³ bá»‹ xem lÃ  data leakage khi cÃ¡c tham sá»‘ sáº½ tÃ­nh trong quÃ¡ trÃ¬nh fit trÃªn train láº¡i Ä‘c Ã¡p dá»¥ng trÃªn test ?
HÆ¡n ná»¯a theo nhÆ° em tháº¥y thÃ´ng thÆ°á»ng khi normalize hay encode cÃ¡c thá»© thÃ¬ sáº½ fit(fit_transform) trÃªn train vÃ  transform trÃªn test váº­y vá»›i cÃ¡c kÄ© thuáº­t khÃ¡c nhÆ° xá»­ lÃ½ outlier hay missing value thÃ¬ mÃ¬nh cÅ©ng lÃ m nhÆ° váº­y hay lÃ  lÃ m vá»›i táº­p nÃ o thÃ¬ mÃ¬nh fit_transform trÃªn táº­p Ä‘áº¥y luÃ´n áº¡?
2.Vá» data leakage áº¡(cÅ©ng nhÆ° cÃ¡i trÃªn thÃ¬ cÃ¡i nÃ y em cÅ©ng cÃ³ Ä‘á»c qua)nhÆ°ng vÃ¬ muá»‘n hiá»ƒu cáº·n káº½ hÆ¡n nÃªn em mong Ä‘Æ°á»£c mn giáº£i thÃ­ch vÃ  cÃ¡ch kháº¯c phá»¥c,háº¡n cháº¿ hay nhá»¯ng Ä‘iá»u k Ä‘c phÃ©p lÃ m Ä‘á»ƒ trÃ¡nh hiá»‡n tÆ°á»£ng nÃ y áº¡!
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i áº¡ !","Em chÃ o má»i ngÆ°á»i áº¡.Em lÃ  newbie má»›i nháº­p mÃ´n cá»§a ngÃ nh.Chuyá»‡n lÃ  trong quÃ¡ trÃ¬nh xá»­ lÃ½ data em cÃ³ 1 sá»‘ tháº¯c máº¯c mong Ä‘c mn giáº£i Ä‘Ã¡p áº¡: 1.Táº¡i sao láº¡i fit trÃªn train vÃ  transform trÃªn test? (CÃ¡i nÃ y em cÃ³ Ä‘á»c qua vÃ  hiá»ƒu sÆ¡ sÆ¡ nhÆ°ng mong Ä‘c má»i ngÆ°á»i giáº£i Ä‘Ã¡p rÃµ rÃ ng hÆ¡n áº¡) VÃ  náº¿u nhÆ° váº­y thÃ¬ cÃ³ bá»‹ xem lÃ  data leakage khi cÃ¡c tham sá»‘ sáº½ tÃ­nh trong quÃ¡ trÃ¬nh fit trÃªn train láº¡i Ä‘c Ã¡p dá»¥ng trÃªn test ? HÆ¡n ná»¯a theo nhÆ° em tháº¥y thÃ´ng thÆ°á»ng khi normalize hay encode cÃ¡c thá»© thÃ¬ sáº½ fit(fit_transform) trÃªn train vÃ  transform trÃªn test váº­y vá»›i cÃ¡c kÄ© thuáº­t khÃ¡c nhÆ° xá»­ lÃ½ outlier hay missing value thÃ¬ mÃ¬nh cÅ©ng lÃ m nhÆ° váº­y hay lÃ  lÃ m vá»›i táº­p nÃ o thÃ¬ mÃ¬nh fit_transform trÃªn táº­p Ä‘áº¥y luÃ´n áº¡? 2.Vá» data leakage áº¡(cÅ©ng nhÆ° cÃ¡i trÃªn thÃ¬ cÃ¡i nÃ y em cÅ©ng cÃ³ Ä‘á»c qua)nhÆ°ng vÃ¬ muá»‘n hiá»ƒu cáº·n káº½ hÆ¡n nÃªn em mong Ä‘Æ°á»£c mn giáº£i thÃ­ch vÃ  cÃ¡ch kháº¯c phá»¥c,háº¡n cháº¿ hay nhá»¯ng Ä‘iá»u k Ä‘c phÃ©p lÃ m Ä‘á»ƒ trÃ¡nh hiá»‡n tÆ°á»£ng nÃ y áº¡! Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i áº¡ !",,,"#Q&A, #data",,
"ChÃ o anh chá»‹ áº¡ , em hiá»‡n táº¡i Ä‘Ã£ káº¿t thÃºc nÄƒm 1 cntt ,chuáº©n bá»‹ sang nÄƒm 2 em muá»‘n theo AI thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t sá»‘ tÃ i liá»‡u , YouTube, hay khoÃ¡ há»c nÃ o trÃªn máº¡ng ,tiáº¿ng anh hoáº·c tráº£ phÃ­ Ä‘á»u Ä‘Æ°á»£c áº¡ em cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o anh chá»‹ áº¡ , em hiá»‡n táº¡i Ä‘Ã£ káº¿t thÃºc nÄƒm 1 cntt ,chuáº©n bá»‹ sang nÄƒm 2 em muá»‘n theo AI thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t sá»‘ tÃ i liá»‡u , YouTube, hay khoÃ¡ há»c nÃ o trÃªn máº¡ng ,tiáº¿ng anh hoáº·c tráº£ phÃ­ Ä‘á»u Ä‘Æ°á»£c áº¡ em cáº£m Æ¡n má»i ngÆ°á»i",,,"#Q&A, #machine_learning",,
cho mÃ¬nh há»i thÆ° viá»‡n VietOCR cá»§a a Quá»‘c cÃ³ cáº¥u táº¡o lÃ  vgg19 vÃ  transformer Ä‘Ãºng khÃ´ng áº¡,cho mÃ¬nh há»i thÆ° viá»‡n VietOCR cá»§a a Quá»‘c cÃ³ cáº¥u táº¡o lÃ  vgg19 vÃ  transformer Ä‘Ãºng khÃ´ng áº¡,,,"#Q&A, #deep_learning",,
"ğŸ”¥KERAS CORE RA Máº®T: Há»– TRá»¢ Äá»’NG THá»œI PYTORCH, TENSORFLOW VÃ€ JAXğŸ”¥
âœ…Giá»›i thiá»‡u Keras Core, tiá»n thÃ¢n cá»§a Keras 3.0, cho phÃ©p sá»­ dá»¥ng PyTorch, TensorFlow vÃ  JAX trong má»™t Ä‘oáº¡n code duy nháº¥t.
ğŸ‘¨â€ğŸ’»""We're excited to share with you a new library called Keras Core, a preview version of the future of Keras. In Fall 2023, this library will become Keras 3.0. Keras Core is a full rewrite of the Keras codebase that rebases it on top of a modular backend architecture. It makes it possible to run Keras workflows on top of arbitrary frameworks â€” starting with TensorFlow, JAX, and PyTorch."" - Keras Team.
Nguá»“n: VietAI","KERAS CORE RA Máº®T: Há»– TRá»¢ Äá»’NG THá»œI PYTORCH, TENSORFLOW VÃ€ JAX Giá»›i thiá»‡u Keras Core, tiá»n thÃ¢n cá»§a Keras 3.0, cho phÃ©p sá»­ dá»¥ng PyTorch, TensorFlow vÃ  JAX trong má»™t Ä‘oáº¡n code duy nháº¥t. ""We're excited to share with you a new library called Keras Core, a preview version of the future of Keras. In Fall 2023, this library will become Keras 3.0. Keras Core is a full rewrite of the Keras codebase that rebases it on top of a modular backend architecture. It makes it possible to run Keras workflows on top of arbitrary frameworks â€” starting with TensorFlow, JAX, and PyTorch."" - Keras Team. Nguá»“n: VietAI",,,"#sharing, #python",,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» Kafka vÃ  tháº¥y cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c cho ML nÃªn xin máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ . Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c.
Link video: https://www.youtube.com/watch?v=JaBXLUdHEDU",KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» Kafka vÃ  tháº¥y cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c cho ML nÃªn xin máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ . Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c. Link video: https://www.youtube.com/watch?v=JaBXLUdHEDU,,,"#sharing, #data",,
"VinAI Seminar - ""Innovations in Text-Guided Visual Content Generation""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Wang Hao, Nanyang Technological University
Time: 11:00 am - 12:00 pm (GMT+7), Mon, Jul 17, 2023","VinAI Seminar - ""Innovations in Text-Guided Visual Content Generation"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Wang Hao, Nanyang Technological University Time: 11:00 am - 12:00 pm (GMT+7), Mon, Jul 17, 2023",,,,,
"Em chÃ o má»i ngÆ°á»i. Em cÃ³ má»™t tháº¯c máº¯c. Em hiá»‡n táº¡i tÃ¬m vá» ML Ä‘Æ°á»£c má»™t thá»i gian rá»“i, em cÅ©ng cÃ³ má»™t vÃ i project cÃ¡ nhÃ¢n. Hiá»‡n táº¡i em muá»‘n tÃ¬m má»™t vá»‹ trÃ­ thá»±c táº­p. Tuy nhiÃªn khi em tÃ¬m hiá»ƒu thÃ¬ em nháº­n tháº¥y ráº±ng cÃ³ khÃ¡ Ã­t cÃ´ng ty tuyá»ƒn vá»‹ trÃ­ tá»« thá»±c táº­p sinh Ä‘áº¿n Junior, Middle- (Chá»§ yáº¿u lÃ  em tháº¥y cÃ³ á»Ÿ Viettel, Vin vÃ  FPT). Em cáº£m tháº¥y khÃ¡ hoang mang vá» tÆ°Æ¡ng lai cá»§a mÃ¬nh khi em nháº­n tháº¥y cÃ³ ráº¥t nhiá»u ngÆ°á»i Ä‘i theo máº£ng nÃ y nhÆ°ng cÃ³ ráº¥t Ã­t chá»— tuyá»ƒn dá»¥ng (Em chÆ°a cÃ³ Ã½ Ä‘á»‹nh há»c lÃªn vÃ  nghiÃªn cá»©u do Ä‘iá»u kiá»‡n tÃ i chÃ­nh khÃ´ng cho phÃ©p). Má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t vÃ i lá»i khuyÃªn cÅ©ng nhÆ° giá»›i thiá»‡u giÃºp em má»™t vÃ i nÆ¡i Ä‘á»ƒ em cÃ³ thá»ƒ xin thá»±c táº­p cÅ©ng nhÆ° phÃ¡t triá»ƒn tÆ°Æ¡ng lai Ä‘Æ°á»£c khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n!","Em chÃ o má»i ngÆ°á»i. Em cÃ³ má»™t tháº¯c máº¯c. Em hiá»‡n táº¡i tÃ¬m vá» ML Ä‘Æ°á»£c má»™t thá»i gian rá»“i, em cÅ©ng cÃ³ má»™t vÃ i project cÃ¡ nhÃ¢n. Hiá»‡n táº¡i em muá»‘n tÃ¬m má»™t vá»‹ trÃ­ thá»±c táº­p. Tuy nhiÃªn khi em tÃ¬m hiá»ƒu thÃ¬ em nháº­n tháº¥y ráº±ng cÃ³ khÃ¡ Ã­t cÃ´ng ty tuyá»ƒn vá»‹ trÃ­ tá»« thá»±c táº­p sinh Ä‘áº¿n Junior, Middle- (Chá»§ yáº¿u lÃ  em tháº¥y cÃ³ á»Ÿ Viettel, Vin vÃ  FPT). Em cáº£m tháº¥y khÃ¡ hoang mang vá» tÆ°Æ¡ng lai cá»§a mÃ¬nh khi em nháº­n tháº¥y cÃ³ ráº¥t nhiá»u ngÆ°á»i Ä‘i theo máº£ng nÃ y nhÆ°ng cÃ³ ráº¥t Ã­t chá»— tuyá»ƒn dá»¥ng (Em chÆ°a cÃ³ Ã½ Ä‘á»‹nh há»c lÃªn vÃ  nghiÃªn cá»©u do Ä‘iá»u kiá»‡n tÃ i chÃ­nh khÃ´ng cho phÃ©p). Má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t vÃ i lá»i khuyÃªn cÅ©ng nhÆ° giá»›i thiá»‡u giÃºp em má»™t vÃ i nÆ¡i Ä‘á»ƒ em cÃ³ thá»ƒ xin thá»±c táº­p cÅ©ng nhÆ° phÃ¡t triá»ƒn tÆ°Æ¡ng lai Ä‘Æ°á»£c khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n!",,,"#Q&A, #machine_learning",,
"#ask #Transformer #attention
ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Transformer architecture. Paper ""Attention is all you need"" khÃ´ng mÃ´ táº£ chi tiáº¿t vá» query, key, value Ä‘á»ƒ xÃ¡c Ä‘á»‹nh dependency. Theo mÃ¬nh hiá»ƒu thÃ¬ 3 vectors nÃ y Ä‘Æ°á»£c táº¡o ra báº±ng multiplication between embedding vectors and randomized (?) Q/ K/ V matrics, rá»“i dÃ¹ng dot-product attention.
1. Tuy nhiÃªn underlying idea/ intuition cá»§a viá»‡c sá»­ dá»¥ng Q, K, V nÃ y lÃ  gÃ¬? Paper chá»‰ Ä‘á» cáº­p how they did it, but not why.
2. Vai trÃ² cá»¥ thá»ƒ cá»§a query, key, value lÃ  gÃ¬? VÃ¬ trong encoder-decoder attention layers, queries come from the decoder layer, keys and values come from the output of the decoder; while for encoder self-attention layers/ decoder self-attention layers, keys, values and queries come from the same place.
Thanks!","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Transformer architecture. Paper ""Attention is all you need"" khÃ´ng mÃ´ táº£ chi tiáº¿t vá» query, key, value Ä‘á»ƒ xÃ¡c Ä‘á»‹nh dependency. Theo mÃ¬nh hiá»ƒu thÃ¬ 3 vectors nÃ y Ä‘Æ°á»£c táº¡o ra báº±ng multiplication between embedding vectors and randomized (?) Q/ K/ V matrics, rá»“i dÃ¹ng dot-product attention. 1. Tuy nhiÃªn underlying idea/ intuition cá»§a viá»‡c sá»­ dá»¥ng Q, K, V nÃ y lÃ  gÃ¬? Paper chá»‰ Ä‘á» cáº­p how they did it, but not why. 2. Vai trÃ² cá»¥ thá»ƒ cá»§a query, key, value lÃ  gÃ¬? VÃ¬ trong encoder-decoder attention layers, queries come from the decoder layer, keys and values come from the output of the decoder; while for encoder self-attention layers/ decoder self-attention layers, keys, values and queries come from the same place. Thanks!",#ask	#Transformer	#attention,,"#Q&A, #deep_learning",,
"Hi má»i ngÆ°á»i,
HÃ´m nay mÃ¬nh xin phÃ©p chia sáº» blog vá» tá»•ng quan mÃ´ hÃ¬nh Transformer, má»™t mÃ´ hÃ¬nh khÃ¡ ná»•i tiáº¿ng trong deep learning, mÃ´ hÃ¬nh nÃ y cÅ©ng lÃ  cÆ¡ sá»Ÿ cá»§a cÃ¡c mÃ´ hÃ¬nh BERT khÃ¡c (vÃ  nhiá»u thá»© khÃ¡c). Do Ä‘Ã³, Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c BERTs cÃ¡c báº¡n cáº§n náº¯m ráº¥t rÃµ vá» mÃ´ hÃ¬nh Transformer nÃ y. 

á» blog nÃ y mÃ¬nh giá»›i thiá»‡u tá»« tá»•ng quan Ä‘áº¿n cá»±c kÃ¬ chi tiáº¿t kiáº¿n trÃºc mÃ´ hÃ¬nh, giáº£i thÃ­ch táº¡i sao cÃ¡c Ä‘á» xuáº¥t vá» cÆ¡ tháº¿ positional encoding vÃ  self attention láº¡i há»£p lÃ½. Äá»“ng thá»i cÃ¡c Ä‘iá»ƒm lÆ°u Ã½ Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. 

Äá»“ng thá»i mÃ¬nh cÅ©ng cung cáº¥p source code Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Transformer trÃªn táº­p song ngá»¯ TED gá»“m 600k cÃ¢u do mÃ¬nh tá»± thu tháº­p vÃ  matching cho cÃ¡c báº¡n tham kháº£o. Vá»›i bá»™ dá»¯ liá»‡u hy vá»ng giáº£m bá»›t khÃ³ khÄƒn khi Ä‘i xin dá»¯ liá»‡u :)

Blog cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c táº¡i Ä‘Ã¢y nhÃ©.
https://pbcquoc.github.io/transformer/
Source code notebook thÃ¬ cÃ¡c báº¡n clone vá» táº¡i Ä‘Ã¢y.
https://github.com/pbcquoc/transformer
Notebook tÃ¬m táº¡i Ä‘Ã¢y: 
https://github.com/pbcquoc/transformer/blob/master/transformer.ipynb
Bá»™ dá»¯ liá»‡u song ngá»¯ anh-viá»‡t táº¡i Ä‘Ã¢y. 
https://drive.google.com/file/d/141kAeLKRHxHHkWCru6t1QZS6PRo8i_vE/view?usp=sharing
CÃ¡c báº¡n cÃ³ thá»ƒ tháº£o luáº­n táº¡i Ä‘Ã¢y hoáº·c táº¡i blog cá»§a mÃ¬nh nhÃ©. ","Hi má»i ngÆ°á»i, HÃ´m nay mÃ¬nh xin phÃ©p chia sáº» blog vá» tá»•ng quan mÃ´ hÃ¬nh Transformer, má»™t mÃ´ hÃ¬nh khÃ¡ ná»•i tiáº¿ng trong deep learning, mÃ´ hÃ¬nh nÃ y cÅ©ng lÃ  cÆ¡ sá»Ÿ cá»§a cÃ¡c mÃ´ hÃ¬nh BERT khÃ¡c (vÃ  nhiá»u thá»© khÃ¡c). Do Ä‘Ã³, Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c BERTs cÃ¡c báº¡n cáº§n náº¯m ráº¥t rÃµ vá» mÃ´ hÃ¬nh Transformer nÃ y. á» blog nÃ y mÃ¬nh giá»›i thiá»‡u tá»« tá»•ng quan Ä‘áº¿n cá»±c kÃ¬ chi tiáº¿t kiáº¿n trÃºc mÃ´ hÃ¬nh, giáº£i thÃ­ch táº¡i sao cÃ¡c Ä‘á» xuáº¥t vá» cÆ¡ tháº¿ positional encoding vÃ  self attention láº¡i há»£p lÃ½. Äá»“ng thá»i cÃ¡c Ä‘iá»ƒm lÆ°u Ã½ Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Äá»“ng thá»i mÃ¬nh cÅ©ng cung cáº¥p source code Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Transformer trÃªn táº­p song ngá»¯ TED gá»“m 600k cÃ¢u do mÃ¬nh tá»± thu tháº­p vÃ  matching cho cÃ¡c báº¡n tham kháº£o. Vá»›i bá»™ dá»¯ liá»‡u hy vá»ng giáº£m bá»›t khÃ³ khÄƒn khi Ä‘i xin dá»¯ liá»‡u :) Blog cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c táº¡i Ä‘Ã¢y nhÃ©. https://pbcquoc.github.io/transformer/ Source code notebook thÃ¬ cÃ¡c báº¡n clone vá» táº¡i Ä‘Ã¢y. https://github.com/pbcquoc/transformer Notebook tÃ¬m táº¡i Ä‘Ã¢y: https://github.com/pbcquoc/transformer/blob/master/transformer.ipynb Bá»™ dá»¯ liá»‡u song ngá»¯ anh-viá»‡t táº¡i Ä‘Ã¢y. https://drive.google.com/file/d/141kAeLKRHxHHkWCru6t1QZS6PRo8i_vE/view?usp=sharing CÃ¡c báº¡n cÃ³ thá»ƒ tháº£o luáº­n táº¡i Ä‘Ã¢y hoáº·c táº¡i blog cá»§a mÃ¬nh nhÃ©.",,,"#sharing, #deep_learning",,
"ChÃ o má»i ngÆ°á»i !!.Em hiá»‡n táº¡i cÃ³ mong muá»‘n ngáº¯n háº¡n lÃ  trá»Ÿ thÃ nh thá»±c táº­p sinh AI ,mong anh chá»‹ cÃ³ thá»ƒ tÆ° váº¥n giÃºp em cáº§n pháº£i lÃ m nhÆ° tháº¿ nÃ o ,vá» lá»™ trÃ¬nh cáº§n há»c, ká»¹ nÄƒng tÃ¬m kiáº¿m viá»‡c,cÅ©ng nhÆ° chá»©ng minh Ä‘á»§ nÄƒng lá»±c vá»›i nhÃ  tuyá»ƒn dá»¥ng, ,Em Ä‘ang lÃ  sinh viÃªn nÄƒm 3 cÃ´ng nghá»‡ thÃ´ng tin muá»‘n theo Ä‘uá»•i Ä‘am mÃª lÃ  AI , em cÃ³ ná»n táº£ng cÆ¡ báº£n lÃ  toÃ¡n nhÆ°ng láº¡i khÃ¡ Ä‘uá»‘i tiáº¿ng anh chá»‰ cÃ³ thá»ƒ dá»‹ch cÆ¡ báº£n tiáº¿ng anh,em cÅ©ng Ä‘Ã£ thá»­ sá»©c vá»›i neural network,CNN,rnn, training ,framework tensorflow, pytorch, má»™t sá»‘ thuáº­t toÃ¡n machine learning, cÅ©ng nhÆ° code cÃ³ má»™t sá»‘ code cÆ¡ báº£n deeplearning vá» nháº­n diá»‡n ,táº¡o áº£nh ,táº¡o vÄƒn báº£n.","ChÃ o má»i ngÆ°á»i !!.Em hiá»‡n táº¡i cÃ³ mong muá»‘n ngáº¯n háº¡n lÃ  trá»Ÿ thÃ nh thá»±c táº­p sinh AI ,mong anh chá»‹ cÃ³ thá»ƒ tÆ° váº¥n giÃºp em cáº§n pháº£i lÃ m nhÆ° tháº¿ nÃ o ,vá» lá»™ trÃ¬nh cáº§n há»c, ká»¹ nÄƒng tÃ¬m kiáº¿m viá»‡c,cÅ©ng nhÆ° chá»©ng minh Ä‘á»§ nÄƒng lá»±c vá»›i nhÃ  tuyá»ƒn dá»¥ng, ,Em Ä‘ang lÃ  sinh viÃªn nÄƒm 3 cÃ´ng nghá»‡ thÃ´ng tin muá»‘n theo Ä‘uá»•i Ä‘am mÃª lÃ  AI , em cÃ³ ná»n táº£ng cÆ¡ báº£n lÃ  toÃ¡n nhÆ°ng láº¡i khÃ¡ Ä‘uá»‘i tiáº¿ng anh chá»‰ cÃ³ thá»ƒ dá»‹ch cÆ¡ báº£n tiáº¿ng anh,em cÅ©ng Ä‘Ã£ thá»­ sá»©c vá»›i neural network,CNN,rnn, training ,framework tensorflow, pytorch, má»™t sá»‘ thuáº­t toÃ¡n machine learning, cÅ©ng nhÆ° code cÃ³ má»™t sá»‘ code cÆ¡ báº£n deeplearning vá» nháº­n diá»‡n ,táº¡o áº£nh ,táº¡o vÄƒn báº£n.",,,"#Q&A, #machine_learning",,
Xin phÃ©p chia sáº» vá»›i cÃ¡c bÃ¡c má»™t lá»™ trÃ¬nh trá»Ÿ thÃ nh Data Scientist áº¡. Lá»™ trÃ¬nh nÃ y Ä‘Æ°á»£c Ä‘Ãºt káº¿t tá»« chÃ­nh kinh nghiá»‡m cá»§a báº£n thÃ¢n nÃªn xin cÃ¡c bÃ¡c gáº¡ch Ä‘Ã¡ nháº¹ tay áº¡ ğŸ¥².,Xin phÃ©p chia sáº» vá»›i cÃ¡c bÃ¡c má»™t lá»™ trÃ¬nh trá»Ÿ thÃ nh Data Scientist áº¡. Lá»™ trÃ¬nh nÃ y Ä‘Æ°á»£c Ä‘Ãºt káº¿t tá»« chÃ­nh kinh nghiá»‡m cá»§a báº£n thÃ¢n nÃªn xin cÃ¡c bÃ¡c gáº¡ch Ä‘Ã¡ nháº¹ tay áº¡ .,,,"#Q&A, #data",,
"ChÃ o anh chá»‹, em muá»‘n há»i vá» tiá»n xá»­ lÃ½ dá»¯ liá»‡u áº¡.
Trong dataset movie cÃ³ má»™t sá»‘ categorical feature cÃ³ nhiá»u giÃ¡ trá»‹ cho má»™t record. VÃ­ dá»¥ nhÆ° credits lÃ  danh sÃ¡ch cÃ¡c diá»…n viÃªn, Ä‘áº¡o diá»…n cá»§a phim. Má»—i record chá»©a má»™t list gá»“m trung bÃ¬nh 15-30 giÃ¡ trá»‹, cÃ³ khoáº£ng 140000 giÃ¡ trá»‹ khÃ¡c nhau cho toÃ n bá»™ dataset.
Em tháº¯c máº¯c lÃ  mÃ¬nh nÃªn dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘á»ƒ chuyá»ƒn vá» vector sá»‘ cho vÃ o model ML (Catboost, XGBoost,...) áº¡? Bá»Ÿi vÃ¬ one-hot encoding hoáº·c tokenizer em tháº¥y Ä‘á»u khÃ´ng kháº£ thi.
Em cáº£m Æ¡n áº¡.","ChÃ o anh chá»‹, em muá»‘n há»i vá» tiá»n xá»­ lÃ½ dá»¯ liá»‡u áº¡. Trong dataset movie cÃ³ má»™t sá»‘ categorical feature cÃ³ nhiá»u giÃ¡ trá»‹ cho má»™t record. VÃ­ dá»¥ nhÆ° credits lÃ  danh sÃ¡ch cÃ¡c diá»…n viÃªn, Ä‘áº¡o diá»…n cá»§a phim. Má»—i record chá»©a má»™t list gá»“m trung bÃ¬nh 15-30 giÃ¡ trá»‹, cÃ³ khoáº£ng 140000 giÃ¡ trá»‹ khÃ¡c nhau cho toÃ n bá»™ dataset. Em tháº¯c máº¯c lÃ  mÃ¬nh nÃªn dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘á»ƒ chuyá»ƒn vá» vector sá»‘ cho vÃ o model ML (Catboost, XGBoost,...) áº¡? Bá»Ÿi vÃ¬ one-hot encoding hoáº·c tokenizer em tháº¥y Ä‘á»u khÃ´ng kháº£ thi. Em cáº£m Æ¡n áº¡.",,,"#Q&A, #data",,
"ChÃ o má»i ngÆ°á»i áº¡ , mÃ¬nh má»›i há»c vá» object deetection vÃ  Faster R-CNN, minhd cÃ³ tham kháº£o vÃ  cháº¡y thá»­ code https://github.com/wingedrasengan927/pytorch-tutorials/blob/master/Object%20Detection/utils.py

code gá»‘c thÃ¬ train báº±ng cpi, vÃ  mÃ¬nh muá»‘n dÃ¹ng gpu Ä‘á»ƒ train , nhÆ°ng láº¡ lÃ  mÃ¬nh Ä‘Ã£ to(device) cáº£ mÃ´ hÃ¬nh vÃ  data trong hÃ m train:

def training_loop(model, learning_rate, train_dataloader, n_epochs,device):
model.to(device)
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
model.train()
loss_list = []
for i in tqdm(range(n_epochs)):
total_loss = 0
for img_batch, gt_bboxes_batch, gt_classes_batch in train_dataloader:
img_batch = img_batch.to(device)
gt_bboxes_batch = gt_bboxes_batch.to(device)
gt_classes_batch = gt_classes_batch.to(device)
# forward pass
loss = model(img_batch, gt_bboxes_batch, gt_classes_batch)
# backpropagation
optimizer.zero_grad()
loss.backward()
optimizer.step()
total_loss += loss.item()
loss_list.append(total_loss)
return loss_list

nhÆ°ng váº«n gáº·p lá»—i 
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-23-ba5d2a14be34> in <cell line: 4>()
      2 n_epochs = 1000
      3 
----> 4 loss_list = training_loop(detector, learning_rate, od_dataloader, n_epochs,device)
8 frames
<ipython-input-22-14c287b01571> in training_loop(model, learning_rate, train_dataloader, n_epochs, device)
     16 
     17             # forward pass
---> 18             loss = model(img_batch, gt_bboxes_batch, gt_classes_batch)
     19 
     20             # backpropagation
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
   1499                 or _global_backward_pre_hooks or _global_backward_hooks
   1500                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1501             return forward_call(*args, **kwargs)
   1502         # Do not call functions when jit is used
   1503         full_backward_hooks, non_full_backward_hooks = [], []
<ipython-input-3-e0dda12f5636> in forward(self, images, gt_bboxes, gt_classes)
    189 
    190         total_rpn_loss, feature_map, proposals, \
--> 191         positive_anc_ind_sep, GT_class_pos = self.rpn(images, gt_bboxes, gt_classes)
    192 
    193         # get separate proposals for each sample
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
   1499                 or _global_backward_pre_hooks or _global_backward_hooks
   1500                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1501             return forward_call(*args, **kwargs)
   1502         # Do not call functions when jit is used
   1503         full_backward_hooks, non_full_backward_hooks = [], []
<ipython-input-3-e0dda12f5636> in forward(self, images, gt_bboxes, gt_classes)
     88         positive_anc_ind, negative_anc_ind, GT_conf_scores, \
     89         GT_offsets, GT_class_pos, positive_anc_coords, \
---> 90         negative_anc_coords, positive_anc_ind_sep = get_req_anchors(anc_boxes_all, gt_bboxes_proj, gt_classes)
     91 
     92         # pass through the proposal module
<ipython-input-2-3424462ffbf3> in get_req_anchors(anc_boxes_all, gt_bboxes_all, gt_classes_all, pos_thresh, neg_thresh)
    190     # get the iou matrix which contains iou of every anchor box
    191     # against all the groundtruth bboxes in an image
--> 192     iou_mat = get_iou_mat(B, anc_boxes_all, gt_bboxes_all)
    193 
    194     # for every groundtruth bbox in an image, find the iou
<ipython-input-2-3424462ffbf3> in get_iou_mat(batch_size, anc_boxes_all, gt_bboxes_all)
    149         gt_bboxes = gt_bboxes_all[i]
    150         anc_boxes = anc_boxes_flat[i]
--> 151         ious_mat[i, :] = ops.box_iou(anc_boxes, gt_bboxes)
    152 
    153     return ious_mat
/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py in box_iou(boxes1, boxes2)
    269     if not torch.jit.is_scripting() and not torch.jit.is_tracing():
    270         _log_api_usage_once(box_iou)
--> 271     inter, union = _box_inter_union(boxes1, boxes2)
    272     iou = inter / union
    273     return iou
/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py in _box_inter_union(boxes1, boxes2)
    242     area2 = box_area(boxes2)
    243 
--> 244     lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]
    245     rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]
    246
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
code cá»§a mÃ¬nh á»Ÿ link dÆ°á»›i, ai cÃ³ thá»ƒ giÃºp mÃ¬nh sá»­a lá»—i vá»›i áº¡
https://colab.research.google.com/drive/1WBX5GwKH5_pWajqJe60vVhzRDotf-LI8?usp=sharing","ChÃ o má»i ngÆ°á»i áº¡ , mÃ¬nh má»›i há»c vá» object deetection vÃ  Faster R-CNN, minhd cÃ³ tham kháº£o vÃ  cháº¡y thá»­ code https://github.com/wingedrasengan927/pytorch-tutorials/blob/master/Object%20Detection/utils.py code gá»‘c thÃ¬ train báº±ng cpi, vÃ  mÃ¬nh muá»‘n dÃ¹ng gpu Ä‘á»ƒ train , nhÆ°ng láº¡ lÃ  mÃ¬nh Ä‘Ã£ to(device) cáº£ mÃ´ hÃ¬nh vÃ  data trong hÃ m train: def training_loop(model, learning_rate, train_dataloader, n_epochs,device): model.to(device) optimizer = optim.Adam(model.parameters(), lr=learning_rate) model.train() loss_list = [] for i in tqdm(range(n_epochs)): total_loss = 0 for img_batch, gt_bboxes_batch, gt_classes_batch in train_dataloader: img_batch = img_batch.to(device) gt_bboxes_batch = gt_bboxes_batch.to(device) gt_classes_batch = gt_classes_batch.to(device) # forward pass loss = model(img_batch, gt_bboxes_batch, gt_classes_batch) # backpropagation optimizer.zero_grad() loss.backward() optimizer.step() total_loss += loss.item() loss_list.append(total_loss) return loss_list nhÆ°ng váº«n gáº·p lá»—i --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) <ipython-input-23-ba5d2a14be34> in <cell line: 4>() 2 n_epochs = 1000 3 ----> 4 loss_list = training_loop(detector, learning_rate, od_dataloader, n_epochs,device) 8 frames <ipython-input-22-14c287b01571> in training_loop(model, learning_rate, train_dataloader, n_epochs, device) 16 17 # forward pass ---> 18 loss = model(img_batch, gt_bboxes_batch, gt_classes_batch) 19 20 # backpropagation /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs) 1499 or _global_backward_pre_hooks or _global_backward_hooks 1500 or _global_forward_hooks or _global_forward_pre_hooks): -> 1501 return forward_call(*args, **kwargs) 1502 # Do not call functions when jit is used 1503 full_backward_hooks, non_full_backward_hooks = [], [] <ipython-input-3-e0dda12f5636> in forward(self, images, gt_bboxes, gt_classes) 189 190 total_rpn_loss, feature_map, proposals, \ --> 191 positive_anc_ind_sep, GT_class_pos = self.rpn(images, gt_bboxes, gt_classes) 192 193 # get separate proposals for each sample /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs) 1499 or _global_backward_pre_hooks or _global_backward_hooks 1500 or _global_forward_hooks or _global_forward_pre_hooks): -> 1501 return forward_call(*args, **kwargs) 1502 # Do not call functions when jit is used 1503 full_backward_hooks, non_full_backward_hooks = [], [] <ipython-input-3-e0dda12f5636> in forward(self, images, gt_bboxes, gt_classes) 88 positive_anc_ind, negative_anc_ind, GT_conf_scores, \ 89 GT_offsets, GT_class_pos, positive_anc_coords, \ ---> 90 negative_anc_coords, positive_anc_ind_sep = get_req_anchors(anc_boxes_all, gt_bboxes_proj, gt_classes) 91 92 # pass through the proposal module <ipython-input-2-3424462ffbf3> in get_req_anchors(anc_boxes_all, gt_bboxes_all, gt_classes_all, pos_thresh, neg_thresh) 190 # get the iou matrix which contains iou of every anchor box 191 # against all the groundtruth bboxes in an image --> 192 iou_mat = get_iou_mat(B, anc_boxes_all, gt_bboxes_all) 193 194 # for every groundtruth bbox in an image, find the iou <ipython-input-2-3424462ffbf3> in get_iou_mat(batch_size, anc_boxes_all, gt_bboxes_all) 149 gt_bboxes = gt_bboxes_all[i] 150 anc_boxes = anc_boxes_flat[i] --> 151 ious_mat[i, :] = ops.box_iou(anc_boxes, gt_bboxes) 152 153 return ious_mat /usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py in box_iou(boxes1, boxes2) 269 if not torch.jit.is_scripting() and not torch.jit.is_tracing(): 270 _log_api_usage_once(box_iou) --> 271 inter, union = _box_inter_union(boxes1, boxes2) 272 iou = inter / union 273 return iou /usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py in _box_inter_union(boxes1, boxes2) 242 area2 = box_area(boxes2) 243 --> 244 lt = torch.max(boxes1[:, None, :2], boxes2[:, :2]) # [N,M,2] 245 rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:]) # [N,M,2] 246 RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! code cá»§a mÃ¬nh á»Ÿ link dÆ°á»›i, ai cÃ³ thá»ƒ giÃºp mÃ¬nh sá»­a lá»—i vá»›i áº¡ https://colab.research.google.com/drive/1WBX5GwKH5_pWajqJe60vVhzRDotf-LI8?usp=sharing",,,"#Q&A, #deep_learning",,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em cÃ³ Ä‘áº©y má»™t project python lÃªn Pythonanywhere, má»i thá»© Ä‘á»u ráº¥t á»•n ngoáº¡i trá»« cÃ¡i Tesseract, em khÃ´ng rÃµ táº¡i sao nÃ³ láº¡i trá»Ÿ nÃªn quÃ¡ cháº­m
from tesserocr import PyTessBaseAPI
with PyTessBaseAPI(path=TESSDATA_DIR) as api:
for _img in gray_images:
pil_image = Image.fromarray(_img)
api.SetImage(pil_image)
start_time = time.time()
text = ''.join(re.findall(r'\d+', api.GetUTF8Text()))
print('get_cells_2-ocr: ', time.time() - start_time)
_results.append(text)

On local:
get_cells_2-ocr:  0.009741067886352539
get_cells_2-ocr:  0.007970333099365234
get_cells_2-ocr:  0.0022356510162353516
get_cells_2-ocr:  0.00189208984375
get_cells_2-ocr:  0.25850939750671387
get_cells_2-ocr:  0.16674566268920898
get_cells_2-ocr:  1.3970351219177246
get_cells_2-ocr:  0.06349921226501465
get_cells_2-ocr:  0.05964350700378418
get_cells_2-ocr:  0.05002236366271973
get_cells_2-ocr:  0.06497740745544434
get_cells_2-ocr:  0.018608570098876953
On Pythonanywhere:
2023-07-10 04:03:57 3.670355796813965
2023-07-10 04:03:57 
2023-07-10 04:04:01 get_cells_2-ocr: 
2023-07-10 04:04:01  
2023-07-10 04:04:01 3.228891134262085
2023-07-10 04:04:01 
2023-07-10 04:04:06 get_cells_2-ocr: 
2023-07-10 04:04:06  
2023-07-10 04:04:06 5.227738380432129
2023-07-10 04:04:06 
2023-07-10 04:04:13 get_cells_2-ocr: 
2023-07-10 04:04:13  
2023-07-10 04:04:13 7.223729372024536
2023-07-10 04:04:13 
2023-07-10 04:04:17 get_cells_2-ocr: 
2023-07-10 04:04:17  
2023-07-10 04:04:17 3.716923475265503
2023-07-10 04:04:17 
2023-07-10 04:04:22 get_cells_2-ocr: 
2023-07-10 04:04:22  
2023-07-10 04:04:22 4.74852442741394

NhÆ° má»i ngÆ°á»i tháº¥y thÃ¬ hiá»‡u suáº¥t cá»§a tesseract trÃªn pythonanywhere chÃªnh lá»‡ch quÃ¡ lá»›n so vá»›i trÃªn mÃ¡y local, cÃ³ báº¡n nÃ o tá»«ng gáº·p váº¥n Ä‘á» tÆ°Æ¡ng tá»± chÆ°a áº¡, cho mÃ¬nh xin chÃºt Ã½ kiáº¿n vá»›i","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em cÃ³ Ä‘áº©y má»™t project python lÃªn Pythonanywhere, má»i thá»© Ä‘á»u ráº¥t á»•n ngoáº¡i trá»« cÃ¡i Tesseract, em khÃ´ng rÃµ táº¡i sao nÃ³ láº¡i trá»Ÿ nÃªn quÃ¡ cháº­m from tesserocr import PyTessBaseAPI with PyTessBaseAPI(path=TESSDATA_DIR) as api: for _img in gray_images: pil_image = Image.fromarray(_img) api.SetImage(pil_image) start_time = time.time() text = ''.join(re.findall(r'\d+', api.GetUTF8Text())) print('get_cells_2-ocr: ', time.time() - start_time) _results.append(text) On local: get_cells_2-ocr: 0.009741067886352539 get_cells_2-ocr: 0.007970333099365234 get_cells_2-ocr: 0.0022356510162353516 get_cells_2-ocr: 0.00189208984375 get_cells_2-ocr: 0.25850939750671387 get_cells_2-ocr: 0.16674566268920898 get_cells_2-ocr: 1.3970351219177246 get_cells_2-ocr: 0.06349921226501465 get_cells_2-ocr: 0.05964350700378418 get_cells_2-ocr: 0.05002236366271973 get_cells_2-ocr: 0.06497740745544434 get_cells_2-ocr: 0.018608570098876953 On Pythonanywhere: 2023-07-10 04:03:57 3.670355796813965 2023-07-10 04:03:57 2023-07-10 04:04:01 get_cells_2-ocr: 2023-07-10 04:04:01 2023-07-10 04:04:01 3.228891134262085 2023-07-10 04:04:01 2023-07-10 04:04:06 get_cells_2-ocr: 2023-07-10 04:04:06 2023-07-10 04:04:06 5.227738380432129 2023-07-10 04:04:06 2023-07-10 04:04:13 get_cells_2-ocr: 2023-07-10 04:04:13 2023-07-10 04:04:13 7.223729372024536 2023-07-10 04:04:13 2023-07-10 04:04:17 get_cells_2-ocr: 2023-07-10 04:04:17 2023-07-10 04:04:17 3.716923475265503 2023-07-10 04:04:17 2023-07-10 04:04:22 get_cells_2-ocr: 2023-07-10 04:04:22 2023-07-10 04:04:22 4.74852442741394 NhÆ° má»i ngÆ°á»i tháº¥y thÃ¬ hiá»‡u suáº¥t cá»§a tesseract trÃªn pythonanywhere chÃªnh lá»‡ch quÃ¡ lá»›n so vá»›i trÃªn mÃ¡y local, cÃ³ báº¡n nÃ o tá»«ng gáº·p váº¥n Ä‘á» tÆ°Æ¡ng tá»± chÆ°a áº¡, cho mÃ¬nh xin chÃºt Ã½ kiáº¿n vá»›i",,,"#Q&A, #python",,
"HÃ´m nay nhÃ¢n dá»‹p Vietcuna 3B cÃ¡n má»‘c 1.6k lÆ°á»£t táº£i, team mÃ¬nh phÃ¡t hÃ nh báº£n alpha cá»§a Vietcuna 7B.
DÃ¹ Ä‘Ã£ Ä‘Æ°á»£c finetune instruction nhÆ°ng Ä‘Ã¢y khÃ´ng pháº£i phiÃªn báº£n hoÃ n chá»‰nh nháº¥t. Má»¥c Ä‘Ã­ch cá»§a phiÃªn báº£n nÃ y lÃ  má»™t base model cho cá»™ng Ä‘á»“ng tá»± finetune thÃªm. PhiÃªn báº£n hoÃ n chá»‰nh sáº½ chá»‰ Ä‘Æ°á»£c phÃ¡t hÃ nh cho cÃ¡c doanh nghiá»‡p (liÃªn há»‡ riÃªng vá»›i mÃ¬nh) trong khoáº£ng thá»i gian nÃ y.
NgoÃ i ra láº§n nÃ y mÃ¬nh cÅ©ng phÃ¡t hÃ nh luÃ´n phiÃªn báº£n dá»‹ch tiáº¿ng Viá»‡t cá»§a Dataset Lima. LÆ°u Ã½ Ä‘Ã¢y lÃ  phiÃªn báº£n Ä‘Æ°á»£c dá»‹ch tá»« phiÃªn báº£n gá»‘c vá»›i model en2vi cá»§a VinAI nÃªn sáº½ chá»‰ Ä‘Æ°á»£c dÃ¹ng vá»›i má»¥c Ä‘Ã­ch nghiÃªn cá»©u. PhiÃªn báº£n augmented Ä‘Æ°á»£c lÃ m báº±ng tay vá»›i cá»™ng tÃ¡c viÃªn cÅ©ng sáº½ chá»‰ Ä‘Æ°á»£c phÃ¡t hÃ nh cho cÃ¡c doanh nhiá»‡p.
HuggingFace Model: https://huggingface.co/vilm/vietcuna-7b-alpha
GitHub with Gradio UI: https://github.com/vilm-ai/vietcuna
Lima-vi Dataset: https://huggingface.co/datasets/vilm/lima-vi
Mong má»i ngÆ°á»i cÃ¹ng nhau phÃ¡t triá»ƒn phiÃªn báº£n alpha nÃ y Ä‘á»ƒ cá»™ng Ä‘á»“ng cÃ³ cÃ¡c phiÃªn báº£n máº¡nh máº½ hÆ¡n cá»§a Vietcuna :D","HÃ´m nay nhÃ¢n dá»‹p Vietcuna 3B cÃ¡n má»‘c 1.6k lÆ°á»£t táº£i, team mÃ¬nh phÃ¡t hÃ nh báº£n alpha cá»§a Vietcuna 7B. DÃ¹ Ä‘Ã£ Ä‘Æ°á»£c finetune instruction nhÆ°ng Ä‘Ã¢y khÃ´ng pháº£i phiÃªn báº£n hoÃ n chá»‰nh nháº¥t. Má»¥c Ä‘Ã­ch cá»§a phiÃªn báº£n nÃ y lÃ  má»™t base model cho cá»™ng Ä‘á»“ng tá»± finetune thÃªm. PhiÃªn báº£n hoÃ n chá»‰nh sáº½ chá»‰ Ä‘Æ°á»£c phÃ¡t hÃ nh cho cÃ¡c doanh nghiá»‡p (liÃªn há»‡ riÃªng vá»›i mÃ¬nh) trong khoáº£ng thá»i gian nÃ y. NgoÃ i ra láº§n nÃ y mÃ¬nh cÅ©ng phÃ¡t hÃ nh luÃ´n phiÃªn báº£n dá»‹ch tiáº¿ng Viá»‡t cá»§a Dataset Lima. LÆ°u Ã½ Ä‘Ã¢y lÃ  phiÃªn báº£n Ä‘Æ°á»£c dá»‹ch tá»« phiÃªn báº£n gá»‘c vá»›i model en2vi cá»§a VinAI nÃªn sáº½ chá»‰ Ä‘Æ°á»£c dÃ¹ng vá»›i má»¥c Ä‘Ã­ch nghiÃªn cá»©u. PhiÃªn báº£n augmented Ä‘Æ°á»£c lÃ m báº±ng tay vá»›i cá»™ng tÃ¡c viÃªn cÅ©ng sáº½ chá»‰ Ä‘Æ°á»£c phÃ¡t hÃ nh cho cÃ¡c doanh nhiá»‡p. HuggingFace Model: https://huggingface.co/vilm/vietcuna-7b-alpha GitHub with Gradio UI: https://github.com/vilm-ai/vietcuna Lima-vi Dataset: https://huggingface.co/datasets/vilm/lima-vi Mong má»i ngÆ°á»i cÃ¹ng nhau phÃ¡t triá»ƒn phiÃªn báº£n alpha nÃ y Ä‘á»ƒ cá»™ng Ä‘á»“ng cÃ³ cÃ¡c phiÃªn báº£n máº¡nh máº½ hÆ¡n cá»§a Vietcuna :D",,,"#sharing, #nlp",,
"Pydantic 2.0 vá»«a release Ä‘áº©y má»™t pháº§n core qua xá»­ lÃ½ báº±ng Rust giÃºp tá»‘i Æ°u tá»‘c Ä‘á»™ lÃªn tá»›i 5 láº§n, bÃ¡c nÃ o dÃ¹ng FastAPI chÃº Ã½ nhÃ© áº¡ ğŸ§","Pydantic 2.0 vá»«a release Ä‘áº©y má»™t pháº§n core qua xá»­ lÃ½ báº±ng Rust giÃºp tá»‘i Æ°u tá»‘c Ä‘á»™ lÃªn tá»›i 5 láº§n, bÃ¡c nÃ o dÃ¹ng FastAPI chÃº Ã½ nhÃ© áº¡",,,#sharing,,
Em hiá»‡n lÃ  sinh viÃªn nÄƒm 3 vÃ  muá»‘n tham gia cÃ¡c cuá»™c thi Ä‘á»ƒ bá»• sung thÃ nh tÃ­ch vÃ o CV thÃ¬ em muá»‘n há»i má»i ngÆ°á»i bÃªn máº£ng AI hay ML cÃ³ cuá»™c thi nÃ o trong nÆ°á»›c khÃ´ng áº¡?,Em hiá»‡n lÃ  sinh viÃªn nÄƒm 3 vÃ  muá»‘n tham gia cÃ¡c cuá»™c thi Ä‘á»ƒ bá»• sung thÃ nh tÃ­ch vÃ o CV thÃ¬ em muá»‘n há»i má»i ngÆ°á»i bÃªn máº£ng AI hay ML cÃ³ cuá»™c thi nÃ o trong nÆ°á»›c khÃ´ng áº¡?,,,"#Q&A, #machine_learning",,
"â“Báº N ÄÃƒ BIáº¾T GÃŒ Vá»€ GOOGLE I/O EXTENDED CLOUD HANOIâ“
ğŸ“Œ ÄÄƒng kÃ½ tham gia sá»± kiá»‡n ngay táº¡i: https://bit.ly/3NdmYkJ
â€”-------------------
Google I/O Extended Cloud Hanoi lÃ  má»™t trong nhá»¯ng sá»± kiá»‡n thÆ°á»ng niÃªn ná»•i báº­t vá» cÃ´ng nghá»‡, Ä‘áº·c biá»‡t lÃ  cÃ´ng nghá»‡ Cloud táº¡i HÃ  Ná»™i. ÄÆ°á»£c tá»• chá»©c láº§n Ä‘áº§u vÃ o nÄƒm 2021 bá»Ÿi Google Developer Group Cloud Hanoi(GDG Cloud Hanoi), sá»± kiá»‡n Ä‘Ã£ chinh phá»¥c trÃ¡i tim cá»§a nhá»¯ng báº¡n tráº» Ä‘am mÃª cÃ´ng nghá»‡.
âœ¨ HÃ nh trÃ¬nh Ä‘áº§y Ã½ nghÄ©a nÃ y Ä‘Ã£ lan tá»a sá»© má»‡nh káº¿t ná»‘i, chia sáº» vÃ  truyá»n cáº£m há»©ng Ä‘áº¿n cá»™ng Ä‘á»“ng cÃ´ng nghá»‡ táº¡i Viá»‡t Nam vÃ  Ä‘áº·c biá»‡t lÃ  táº¡i HÃ  Ná»™i.
HÃ£y cÃ¹ng GDG Cloud Hanoi nhÃ¬n láº¡i nhá»¯ng dáº¥u áº¥n Ä‘Ã¡ng nhá»› trÃªn hÃ nh trÃ¬nh 3 nÄƒm qua cá»§a sá»± kiá»‡n:
ğŸ”» Tá»• chá»©c thÃ nh cÃ´ng Google I/O Extended Cloud Hanoi láº§n Ä‘áº§u tiÃªn vÃ o nÄƒm 2021
ğŸ”» Tráº£i qua 2 mÃ¹a cÃ´ng nghá»‡ Ä‘Ã¡ng nhá»› vá»›i sá»± tham gia nhiá»‡t tÃ¬nh cá»§a cá»™ng Ä‘á»“ng
ğŸ”» 11 phiÃªn tháº£o luáº­n háº¥p dáº«n vá»›i nhiá»u chá»§ Ä‘á» Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao
ğŸ”» 1000+ lÆ°á»£t tham dá»± cÃ¹ng vá»›i sá»± hiá»‡n diá»‡n cá»§a 16 chuyÃªn gia hÃ ng Ä‘áº§u
ğŸ”» Há»£p tÃ¡c vá»›i 10+ Ä‘á»‘i tÃ¡c Ä‘a ngÃ nh
ğŸ‰ Tiáº¿p ná»‘i hÃ nh trÃ¬nh vá»›i nÄƒm 2023, Google I/O Extended Cloud Hanoi há»©a háº¹n sáº½ tiáº¿p tá»¥c mang Ä‘áº¿n cho ngÆ°á»i tham dá»± nhá»¯ng phiÃªn tháº£o luáº­n sÃ´i ná»•i vÃ  bá»• Ã­ch vá» cÃ¡c cÃ´ng nghá»‡ má»›i nháº¥t, Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi cÃ¡c chuyÃªn gia hÃ ng Ä‘áº§u Ä‘áº¿n tá»« trong vÃ  ngoÃ i nÆ°á»›c. NgoÃ i kiáº¿n thá»©c, nhá»¯ng pháº§n quÃ  táº·ng siÃªu ngáº§u vÃ  cÃ¡c hoáº¡t Ä‘á»™ng bÃªn lá» sáº½ gÃ³p pháº§n mang láº¡i tráº£i nghiá»‡m khÃ´ng thá»ƒ bá» qua cho cÃ¡c dÃ¢n chÆ¡i cÃ´ng nghá»‡ thá»±c thá»¥ ğŸ˜‹.
ğŸ˜‰ Báº¡n cÃ³ ká»‰ niá»‡m Ä‘Ã¡ng nhá»› nÃ o vá»›i Google I/O Extended Cloud Hanoi khÃ´ng? HÃ£y cÃ¹ng chia sáº» nhá»¯ng ká»· niá»‡m Ä‘Ã³ vá»›i GDG Cloud Hanoi trong pháº§n bÃ¬nh luáº­n bÃªn dÆ°á»›i nhÃ©.
ğŸ’ª Äá»«ng bá» lá»¡ cÆ¡ há»™i cÃ¹ng chÃºng tÃ´i Unleashing the Power of Cloud trong sá»± kiá»‡n nÄƒm nay nha!!!
â€”-------------------
ğ†ğğğ†ğ‹ğ„ ğˆ/ğ ğ„ğ—ğ“ğ„ğğƒğ„ğƒ ğ‚ğ‹ğğ”ğƒ ğ‡ğ€ğğğˆ ğŸğŸğŸğŸ‘ - Sá»± kiá»‡n dÃ nh cho cá»™ng Ä‘á»“ng yÃªu cÃ´ng nghá»‡ â€œchÃ¡yâ€ nháº¥t mÃ¹a hÃ¨ nÄƒm nay táº¡i HÃ  Ná»™i
ğŸ“Œ Thá»i gian: 13:00 - 17:00 Thá»© Báº£y, ngÃ y 29/7/2023
ğŸ“Œ Äá»‹a Ä‘iá»ƒm tá»• chá»©c: Há»™i trÆ°á»ng Táº§ng 8, FPT Tower, sá»‘ 10 Pháº¡m VÄƒn Báº¡ch, Dá»‹ch Vá»ng, Cáº§u Giáº¥y, HÃ  Ná»™i
ğŸ“Œ Link Ä‘Äƒng kÃ½ (miá»…n phÃ­): https://bit.ly/3NdmYkJ
Deadline: 25/07/2023, hoáº·c Ä‘Ã³ng sá»›m khi Ä‘á»§ sá»‘ lÆ°á»£ng
ğŸ‘‰ LiÃªn há»‡ tÃ i trá»£, Ä‘Äƒng kÃ½ diá»…n giáº£, gian hÃ ng: Ms. HÆ°Æ¡ng Nguyá»…n - 0377 484 425
ğŸ‘‰ ThÃ´ng tin chÆ°Æ¡ng trÃ¬nh, bÃ¡o chÃ­: Mr. Huy Äáº·ng - 0373 952 446
#GoogleIO #GDGCloudHanoi #GoogleIOExtendedCloudHanoi","Báº N ÄÃƒ BIáº¾T GÃŒ Vá»€ GOOGLE I/O EXTENDED CLOUD HANOI ÄÄƒng kÃ½ tham gia sá»± kiá»‡n ngay táº¡i: https://bit.ly/3NdmYkJ â€”------------------- Google I/O Extended Cloud Hanoi lÃ  má»™t trong nhá»¯ng sá»± kiá»‡n thÆ°á»ng niÃªn ná»•i báº­t vá» cÃ´ng nghá»‡, Ä‘áº·c biá»‡t lÃ  cÃ´ng nghá»‡ Cloud táº¡i HÃ  Ná»™i. ÄÆ°á»£c tá»• chá»©c láº§n Ä‘áº§u vÃ o nÄƒm 2021 bá»Ÿi Google Developer Group Cloud Hanoi(GDG Cloud Hanoi), sá»± kiá»‡n Ä‘Ã£ chinh phá»¥c trÃ¡i tim cá»§a nhá»¯ng báº¡n tráº» Ä‘am mÃª cÃ´ng nghá»‡. HÃ nh trÃ¬nh Ä‘áº§y Ã½ nghÄ©a nÃ y Ä‘Ã£ lan tá»a sá»© má»‡nh káº¿t ná»‘i, chia sáº» vÃ  truyá»n cáº£m há»©ng Ä‘áº¿n cá»™ng Ä‘á»“ng cÃ´ng nghá»‡ táº¡i Viá»‡t Nam vÃ  Ä‘áº·c biá»‡t lÃ  táº¡i HÃ  Ná»™i. HÃ£y cÃ¹ng GDG Cloud Hanoi nhÃ¬n láº¡i nhá»¯ng dáº¥u áº¥n Ä‘Ã¡ng nhá»› trÃªn hÃ nh trÃ¬nh 3 nÄƒm qua cá»§a sá»± kiá»‡n: Tá»• chá»©c thÃ nh cÃ´ng Google I/O Extended Cloud Hanoi láº§n Ä‘áº§u tiÃªn vÃ o nÄƒm 2021 Tráº£i qua 2 mÃ¹a cÃ´ng nghá»‡ Ä‘Ã¡ng nhá»› vá»›i sá»± tham gia nhiá»‡t tÃ¬nh cá»§a cá»™ng Ä‘á»“ng 11 phiÃªn tháº£o luáº­n háº¥p dáº«n vá»›i nhiá»u chá»§ Ä‘á» Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao 1000+ lÆ°á»£t tham dá»± cÃ¹ng vá»›i sá»± hiá»‡n diá»‡n cá»§a 16 chuyÃªn gia hÃ ng Ä‘áº§u Há»£p tÃ¡c vá»›i 10+ Ä‘á»‘i tÃ¡c Ä‘a ngÃ nh Tiáº¿p ná»‘i hÃ nh trÃ¬nh vá»›i nÄƒm 2023, Google I/O Extended Cloud Hanoi há»©a háº¹n sáº½ tiáº¿p tá»¥c mang Ä‘áº¿n cho ngÆ°á»i tham dá»± nhá»¯ng phiÃªn tháº£o luáº­n sÃ´i ná»•i vÃ  bá»• Ã­ch vá» cÃ¡c cÃ´ng nghá»‡ má»›i nháº¥t, Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi cÃ¡c chuyÃªn gia hÃ ng Ä‘áº§u Ä‘áº¿n tá»« trong vÃ  ngoÃ i nÆ°á»›c. NgoÃ i kiáº¿n thá»©c, nhá»¯ng pháº§n quÃ  táº·ng siÃªu ngáº§u vÃ  cÃ¡c hoáº¡t Ä‘á»™ng bÃªn lá» sáº½ gÃ³p pháº§n mang láº¡i tráº£i nghiá»‡m khÃ´ng thá»ƒ bá» qua cho cÃ¡c dÃ¢n chÆ¡i cÃ´ng nghá»‡ thá»±c thá»¥ . Báº¡n cÃ³ ká»‰ niá»‡m Ä‘Ã¡ng nhá»› nÃ o vá»›i Google I/O Extended Cloud Hanoi khÃ´ng? HÃ£y cÃ¹ng chia sáº» nhá»¯ng ká»· niá»‡m Ä‘Ã³ vá»›i GDG Cloud Hanoi trong pháº§n bÃ¬nh luáº­n bÃªn dÆ°á»›i nhÃ©. Äá»«ng bá» lá»¡ cÆ¡ há»™i cÃ¹ng chÃºng tÃ´i Unleashing the Power of Cloud trong sá»± kiá»‡n nÄƒm nay nha!!! â€”------------------- / - Sá»± kiá»‡n dÃ nh cho cá»™ng Ä‘á»“ng yÃªu cÃ´ng nghá»‡ â€œchÃ¡yâ€ nháº¥t mÃ¹a hÃ¨ nÄƒm nay táº¡i HÃ  Ná»™i Thá»i gian: 13:00 - 17:00 Thá»© Báº£y, ngÃ y 29/7/2023 Äá»‹a Ä‘iá»ƒm tá»• chá»©c: Há»™i trÆ°á»ng Táº§ng 8, FPT Tower, sá»‘ 10 Pháº¡m VÄƒn Báº¡ch, Dá»‹ch Vá»ng, Cáº§u Giáº¥y, HÃ  Ná»™i Link Ä‘Äƒng kÃ½ (miá»…n phÃ­): https://bit.ly/3NdmYkJ Deadline: 25/07/2023, hoáº·c Ä‘Ã³ng sá»›m khi Ä‘á»§ sá»‘ lÆ°á»£ng LiÃªn há»‡ tÃ i trá»£, Ä‘Äƒng kÃ½ diá»…n giáº£, gian hÃ ng: Ms. HÆ°Æ¡ng Nguyá»…n - 0377 484 425 ThÃ´ng tin chÆ°Æ¡ng trÃ¬nh, bÃ¡o chÃ­: Mr. Huy Äáº·ng - 0373 952 446",#GoogleIO	#GDGCloudHanoi	#GoogleIOExtendedCloudHanoi,,#webinar,,
Mn Æ¡i cho e há»i vá» kiáº¿n thá»©c toÃ¡n. Em cáº§n há»c nhá»¯ng kiáº¿n thá»©c toÃ¡n gÃ¬ trÆ°á»›c áº¡ vÃ  thá»© tá»± há»c cÃ¡i kiáº¿n thá»©c Ä‘Ã³ ra sao Ä‘á»ƒ theo ML áº¡,Mn Æ¡i cho e há»i vá» kiáº¿n thá»©c toÃ¡n. Em cáº§n há»c nhá»¯ng kiáº¿n thá»©c toÃ¡n gÃ¬ trÆ°á»›c áº¡ vÃ  thá»© tá»± há»c cÃ¡i kiáº¿n thá»©c Ä‘Ã³ ra sao Ä‘á»ƒ theo ML áº¡,,,"#Q&A, #math",,
"em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em cÃ³ Ä‘ang lÃ m trÃ­ch xuáº¥t thá»±c thá»ƒ trong vÄƒn báº£n tiáº¿ng viá»‡t vÃ  PoS dá»±a theo toolkit phonlp (embedding lÃ  phoBERT) vÃ  dataset lÃ  VLSP2016 thÃ¬ cÃ³ má»™t sá»‘ lÃ  cho ra tháº» Ä‘Ãºng cÃ²n má»™t sá»‘ thÃ¬ em cÃ³ gáº·p váº¥n Ä‘á» vá» thá»«a tháº» trong tÃ¡c vá»¥ PoS áº¡ á»Ÿ Ä‘Ã¢y em cÃ³ vÃ­ dá»¥ cá»¥ thá»ƒ luÃ´n áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p tháº¯c máº¯c lÃ  táº¡i sao láº¡i bá»‹ thá»«a tháº» ko áº¡. Hiá»‡n táº¡i nhÃ³m em Ä‘ang giáº£ thuyáº¿t lÃ  do embedding cá»§a phoBERT vÃ  dataset. Em xin cáº£m Æ¡n
(note: trong vÃ­ dá»¥ lÃ  em bá»‹ thá»«a 2 tháº» Ä‘áº§u lÃ  Ny)","em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em cÃ³ Ä‘ang lÃ m trÃ­ch xuáº¥t thá»±c thá»ƒ trong vÄƒn báº£n tiáº¿ng viá»‡t vÃ  PoS dá»±a theo toolkit phonlp (embedding lÃ  phoBERT) vÃ  dataset lÃ  VLSP2016 thÃ¬ cÃ³ má»™t sá»‘ lÃ  cho ra tháº» Ä‘Ãºng cÃ²n má»™t sá»‘ thÃ¬ em cÃ³ gáº·p váº¥n Ä‘á» vá» thá»«a tháº» trong tÃ¡c vá»¥ PoS áº¡ á»Ÿ Ä‘Ã¢y em cÃ³ vÃ­ dá»¥ cá»¥ thá»ƒ luÃ´n áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p tháº¯c máº¯c lÃ  táº¡i sao láº¡i bá»‹ thá»«a tháº» ko áº¡. Hiá»‡n táº¡i nhÃ³m em Ä‘ang giáº£ thuyáº¿t lÃ  do embedding cá»§a phoBERT vÃ  dataset. Em xin cáº£m Æ¡n (note: trong vÃ­ dá»¥ lÃ  em bá»‹ thá»«a 2 tháº» Ä‘áº§u lÃ  Ny)",,,"#Q&A, #deep_learning, #nlp",,
"Hi má»i ngÆ°á»i cho phÃ©p em há»i vá» thuáº­t toÃ¡n Coordinate ascent variational inference (CAVI) áº¡. Em Ä‘ang Ä‘á»c paper nÃ y (https://arxiv.org/pdf/1601.00670.pdf). Tuy nhiÃªn em ko hiá»ƒu Ä‘Æ°á»£c chá»— Equation 19 táº¡i sao cÃ³ thá»ƒ nÃ³i ELBO(q) maximize khi q_j(z_j) báº±ng q*_j(z_j) áº¡.
VÃ¬ Ä‘á»ƒ cÃ³ eq 18 thÃ¬ em Ä‘ang hiá»ƒu lÃ  pháº£i cÃ´ng nháº­n káº¿t quáº£ cá»§a eq17. MÃ  eq17 lÃ  káº¿t quáº£ luÃ´n Ä‘Æ°á»£c thá»«a nháº­n luÃ´n rá»“i thÃ¬ em tháº¥y reasoning Ä‘ang bá»‹ circular.
CÃ³ bÃ¡c nÃ o cÃ³ cao kiáº¿n gÃ³p Ã½ cho em vá»›i áº¡.",Hi má»i ngÆ°á»i cho phÃ©p em há»i vá» thuáº­t toÃ¡n Coordinate ascent variational inference (CAVI) áº¡. Em Ä‘ang Ä‘á»c paper nÃ y (https://arxiv.org/pdf/1601.00670.pdf). Tuy nhiÃªn em ko hiá»ƒu Ä‘Æ°á»£c chá»— Equation 19 táº¡i sao cÃ³ thá»ƒ nÃ³i ELBO(q) maximize khi q_j(z_j) báº±ng q*_j(z_j) áº¡. VÃ¬ Ä‘á»ƒ cÃ³ eq 18 thÃ¬ em Ä‘ang hiá»ƒu lÃ  pháº£i cÃ´ng nháº­n káº¿t quáº£ cá»§a eq17. MÃ  eq17 lÃ  káº¿t quáº£ luÃ´n Ä‘Æ°á»£c thá»«a nháº­n luÃ´n rá»“i thÃ¬ em tháº¥y reasoning Ä‘ang bá»‹ circular. CÃ³ bÃ¡c nÃ o cÃ³ cao kiáº¿n gÃ³p Ã½ cho em vá»›i áº¡.,,,"#Q&A, #machine_learning",,
"Machine Learning cho ngÆ°á»i ngoáº¡i Ä‘áº¡o.
ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh Ä‘ang lÃ  nghiÃªn cá»©u vá» phÃ¢n tÃ­ch chuyá»ƒn Ä‘á»™ng cá»§a con ngÆ°á»i.
Pháº§n nghiÃªn cá»©u cá»§a mÃ¬nh cÃ³ liÃªn quan nhiá»u Ä‘áº¿n tÃ­nh toÃ¡n cÃ¡c thÃ´ng sá»‘ cá»§a chuyá»ƒn Ä‘á»™ng giá»‘ng nhÆ° bÃªn ngÃ nh ká»¹ thuáº­t tÃ­nh toÃ¡n chuyá»ƒn Ä‘á»™ng cá»§a cÃ¡nh tay robot. NÃªn ML Ä‘Æ°á»£c á»©ng dá»¥ng ráº¥t nhiá»u Ä‘á»ƒ tÃ­nh toÃ¡n vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n.
MÃ¬nh cÃ³ má»™t chÃºt kiáº¿n thá»©c vá» phÃ¢n tÃ­ch dá»¯ liá»‡u báº±ng R, tuy nhiÃªn lÃ  do mÃ¬nh tá»± há»c nÃªn nÃ³ khÃ´ng cÃ³ há»‡ thá»‘ng, cáº§n phÃ¢n tÃ­ch cÃ¡i gÃ¬ thÃ¬ láº¡i dÃ¹ng google tra cá»©u.
Cho nÃªn hiá»‡n mÃ¬nh ráº¥t muá»‘n há»c ML vÃ  Data Analysis má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng, ná»n táº£ng tá»« cÆ¡ báº£n Ä‘i lÃªn.
Má»i ngÆ°á»i cÃ³ tÆ° váº¥n giÃºp mÃ¬nh má»™t sá»‘ tháº¯c máº¯c?
- Kiáº¿n thá»©c cÆ¡ báº£n vá» toÃ¡n vÃ  tin cáº§n nhá»¯ng gÃ¬? (mÃ¬nh há»c y nÃªn há»“i Ä‘áº¡i há»c khÃ´ng há»c vá» toÃ¡n- tin cao cáº¥p).
- Kiáº¿n thá»©c vá» cÆ¡ báº£n vá» ML cáº§n há»c cÃ¡i gÃ¬ trÆ°á»›c tiÃªn?
Cáº£m Æ¡n má»i ngÆ°á»i.","Machine Learning cho ngÆ°á»i ngoáº¡i Ä‘áº¡o. ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh Ä‘ang lÃ  nghiÃªn cá»©u vá» phÃ¢n tÃ­ch chuyá»ƒn Ä‘á»™ng cá»§a con ngÆ°á»i. Pháº§n nghiÃªn cá»©u cá»§a mÃ¬nh cÃ³ liÃªn quan nhiá»u Ä‘áº¿n tÃ­nh toÃ¡n cÃ¡c thÃ´ng sá»‘ cá»§a chuyá»ƒn Ä‘á»™ng giá»‘ng nhÆ° bÃªn ngÃ nh ká»¹ thuáº­t tÃ­nh toÃ¡n chuyá»ƒn Ä‘á»™ng cá»§a cÃ¡nh tay robot. NÃªn ML Ä‘Æ°á»£c á»©ng dá»¥ng ráº¥t nhiá»u Ä‘á»ƒ tÃ­nh toÃ¡n vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n. MÃ¬nh cÃ³ má»™t chÃºt kiáº¿n thá»©c vá» phÃ¢n tÃ­ch dá»¯ liá»‡u báº±ng R, tuy nhiÃªn lÃ  do mÃ¬nh tá»± há»c nÃªn nÃ³ khÃ´ng cÃ³ há»‡ thá»‘ng, cáº§n phÃ¢n tÃ­ch cÃ¡i gÃ¬ thÃ¬ láº¡i dÃ¹ng google tra cá»©u. Cho nÃªn hiá»‡n mÃ¬nh ráº¥t muá»‘n há»c ML vÃ  Data Analysis má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng, ná»n táº£ng tá»« cÆ¡ báº£n Ä‘i lÃªn. Má»i ngÆ°á»i cÃ³ tÆ° váº¥n giÃºp mÃ¬nh má»™t sá»‘ tháº¯c máº¯c? - Kiáº¿n thá»©c cÆ¡ báº£n vá» toÃ¡n vÃ  tin cáº§n nhá»¯ng gÃ¬? (mÃ¬nh há»c y nÃªn há»“i Ä‘áº¡i há»c khÃ´ng há»c vá» toÃ¡n- tin cao cáº¥p). - Kiáº¿n thá»©c vá» cÆ¡ báº£n vá» ML cáº§n há»c cÃ¡i gÃ¬ trÆ°á»›c tiÃªn? Cáº£m Æ¡n má»i ngÆ°á»i.",,,"#Q&A, #machine_learning",,
"em chÃ o cÃ¡c tháº§y/cÃ´, anh/chá»‹ vÃ  cÃ¡c báº¡n áº¡,
Má»i ngÆ°á»i cho e nhá» chÃºt áº¡,
Em Ä‘ang lÃ m viá»‡c vá»›i bÃ i toÃ¡n Object detection, má»¥c tiÃªu lÃ  Ã¡p dá»¥ng vÃ  cáº£i tiáº¿n model YOLOv8 trÃªn custom dataset Ä‘Æ°á»£c cung cáº¥p, em Ä‘ang tÃ¬m hiá»ƒu vá» cáº¥u trÃºc máº¡ng cá»§a model yolov8, nhÆ°ng nÃ³ cÃ²n quÃ¡ má»›i vÃ  chÆ°a cÃ³ official paper áº¡, Em muá»‘n tÃ¬m hiá»ƒu vÃ  Ä‘á»c thÃªm cÃ¡c latest techniques vá» Object detection Ä‘á»ƒ cÃ³ thá»ƒ mang vá» cáº£i tiáº¿n model Yolov8 gá»‘c Ä‘á»ƒ cÃ³ thá»ƒ viáº¿t paper áº¡, em xin cÃ¡c anh chá»‹ recommend giÃºp e cÃ¡c trang/ journal hoáº·c nÆ¡i nÃ o Ä‘á»ƒ Ä‘á»c vá» cÃ¡c novelty techniques vá» bÃ i toÃ¡n Object detection áº¡, hoáº·c anh chá»‹ cÃ³ gá»£i Ã½ cáº£i thiá»‡n model thÃ¬ tá»‘t quÃ¡ áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡.","em chÃ o cÃ¡c tháº§y/cÃ´, anh/chá»‹ vÃ  cÃ¡c báº¡n áº¡, Má»i ngÆ°á»i cho e nhá» chÃºt áº¡, Em Ä‘ang lÃ m viá»‡c vá»›i bÃ i toÃ¡n Object detection, má»¥c tiÃªu lÃ  Ã¡p dá»¥ng vÃ  cáº£i tiáº¿n model YOLOv8 trÃªn custom dataset Ä‘Æ°á»£c cung cáº¥p, em Ä‘ang tÃ¬m hiá»ƒu vá» cáº¥u trÃºc máº¡ng cá»§a model yolov8, nhÆ°ng nÃ³ cÃ²n quÃ¡ má»›i vÃ  chÆ°a cÃ³ official paper áº¡, Em muá»‘n tÃ¬m hiá»ƒu vÃ  Ä‘á»c thÃªm cÃ¡c latest techniques vá» Object detection Ä‘á»ƒ cÃ³ thá»ƒ mang vá» cáº£i tiáº¿n model Yolov8 gá»‘c Ä‘á»ƒ cÃ³ thá»ƒ viáº¿t paper áº¡, em xin cÃ¡c anh chá»‹ recommend giÃºp e cÃ¡c trang/ journal hoáº·c nÆ¡i nÃ o Ä‘á»ƒ Ä‘á»c vá» cÃ¡c novelty techniques vá» bÃ i toÃ¡n Object detection áº¡, hoáº·c anh chá»‹ cÃ³ gá»£i Ã½ cáº£i thiá»‡n model thÃ¬ tá»‘t quÃ¡ áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡.",,,"#Q&A, #cv, #deep_learning",,
"Em chÃ o má»i ngÆ°á»i.
Hiá»‡n em Ä‘ang muá»‘n sá»­ dá»¥ng mÃ´ hÃ¬nh VNCoreNLP, tuy nhiÃªn, khi cÃ i Ä‘áº·t trÃªn vscode thÃ¬ em gáº·p lá»—i nhÆ° trong áº£nh. Ai biáº¿t cÃ¡ch kháº¯c phá»¥c thÃ¬ giÃºp em vá»›i.
Em cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i. Hiá»‡n em Ä‘ang muá»‘n sá»­ dá»¥ng mÃ´ hÃ¬nh VNCoreNLP, tuy nhiÃªn, khi cÃ i Ä‘áº·t trÃªn vscode thÃ¬ em gáº·p lá»—i nhÆ° trong áº£nh. Ai biáº¿t cÃ¡ch kháº¯c phá»¥c thÃ¬ giÃºp em vá»›i. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,"#Q&A, #deep_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡ . Giá» em muá»‘n sá»­ dá»¥ng 1 mÃ´ hÃ¬nh Ä‘á»ƒ liÃªn tá»¥c nháº­n vÃ  phÃ¢n loáº¡i dá»¯ liá»‡u trong 24h thÃ nh 2 nhÃ£n thÃ¬ nÃªn sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p gÃ¬ .
( em Ä‘Ã£ cÃ³ sáºµn 1 bá»™ dá»¯ liá»‡u Ä‘Ã£ phÃ¢n loáº¡i 2 nhÃ£n nÃ y trong quÃ¡ khá»© Ä‘á»ƒ train mÃ´ hÃ¬nh phÃ¢n loáº¡i )",Em chÃ o má»i ngÆ°á»i áº¡ . Giá» em muá»‘n sá»­ dá»¥ng 1 mÃ´ hÃ¬nh Ä‘á»ƒ liÃªn tá»¥c nháº­n vÃ  phÃ¢n loáº¡i dá»¯ liá»‡u trong 24h thÃ nh 2 nhÃ£n thÃ¬ nÃªn sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p gÃ¬ . ( em Ä‘Ã£ cÃ³ sáºµn 1 bá»™ dá»¯ liá»‡u Ä‘Ã£ phÃ¢n loáº¡i 2 nhÃ£n nÃ y trong quÃ¡ khá»© Ä‘á»ƒ train mÃ´ hÃ¬nh phÃ¢n loáº¡i ),,,"#Q&A, #machine_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ bÃ i táº­p lÃ  build 1 Recommendation System (RS), nhÆ°ng em hiá»‡n táº¡i váº«n khÃ¡ mÃ¹ má» vÃ¬ chÆ°a hiá»ƒu rÃµ pháº§n train vÃ  pháº§n test Ä‘Æ°á»£c thá»±c hiá»‡n ntn.
NhÆ° em Ä‘Ã£ tÃ¬m hiá»ƒu thÃ¬ trong machine learning, táº­p train sáº½ xáº¥p xá»‰ hÃ m dá»± Ä‘oÃ¡n cÃ²n táº­p test sáº½ Ä‘á»ƒ xÄ‘ xem hÃ m Ä‘Ã³ tá»‘t Ä‘áº¿n Ä‘Ã¢u. NhÆ°ng á»Ÿ pháº§n RS nÃ y, cÃ³ 1 sá»‘ thuáº­t toÃ¡n Ä‘á»ƒ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c luÃ´n Ä‘Ã¡nh giÃ¡ cá»§a ngÆ°á»i dÃ¹ng (Collaborative-filtering user-based/item-based, matrix factorization,...) thÃ¬ mÃ¬nh chá»‰ cáº§n Ã¡p dá»¥ng thuáº­t toÃ¡n vá»›i dataset sau khi xá»­ lÃ­ Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c cÃ¡c Ä‘Ã¡nh giÃ¡ xáº¥p xá»‰. HÆ¡n ná»¯a, em tÃ¬m tháº¥y code máº«u trÃªn máº¡ng ( em Ä‘á»ƒ link bÃªn dÆ°á»›i) thÃ¬ tháº¥y ngÆ°á»i ta váº«n thá»«a sá»‘ hÃ³a cáº£ ma tráº­n ratings, tuy nhiÃªn chá»‰ cá»‘ gáº¯ng minimize loss cá»§a pháº§n train - 1 subset cá»§a ma tráº­n ratings trÃªn vÃ  tháº£ trÃ´i pháº§n test - pháº§n cÃ²n láº¡i cá»§a ma tráº­n. Äáº¿n Ä‘Ã¢y em kiá»ƒu bá»‹ @@, vÃ¬ sao k thá»«a sá»‘ hÃ³a rá»“i minimize loss cá»§a cáº£ ma tráº­n náº¿u nhÆ° test loss nhá» lÃ  tá»‘t. Tá»« Ä‘áº¥y dáº«n Ä‘áº¿n cÃ¢u há»i ban Ä‘áº§u cá»§a em: Táº¡i sao láº¡i chia train vs test ra ngay tá»« ban Ä‘áº§u?
Em xin trÃ¢n thÃ nh cáº£m Æ¡n má»i Ã½ kiáº¿n Ä‘Ã³ng gÃ³p áº¡. Link bÃ i code Ä‘Ã¢y áº¡ (cá»¥ thá»ƒ á»Ÿ pháº§n function build_model): https://colab.research.google.com/github/google/eng-edu/blob/main/ml/recommendation-systems/recommendation-systems.ipynb?utm_source=ss-recommendation-systems&utm_campaign=colab-external&utm_medium=referral&utm_content=recommendation-systems#scrollTo=M9RxIX_Oo4tp
PS: Vá»›i láº¡i cho em há»i thÃªm lÃ  cÃ³ pháº£i phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ loss chÆ°a tá»‘i Æ°u, bá»Ÿi theo nghiÃªn cá»©u cá»§a tÃ¡c giáº£ Äá»— Thá»‹ LiÃªn vÃ  cá»™ng sá»± (https://portal.ptit.edu.vn/saudaihoc/wp-content/uploads/2020/02/LA_%C4%90%E1%BB%97-Th%E1%BB%8B-Li%C3%AAn.pdf?fbclid=IwAR1BU24ivQHfe6mg8dYbi0iwq5Plcmew3B2ODYf0SmZubAtOIscNChQQO_I#page23) táº¡i trang 51, cáº§n pháº£i áº©n Ä‘i 1 sá»‘ p Ä‘Ã¡nh giÃ¡ Ä‘Ã£ biáº¿t cá»§a ngÆ°á»i dÃ¹ng trÃªn táº­p test, sau Ä‘Ã³ so sÃ¡nh giÃ¡ trá»‹ dá»± Ä‘oÃ¡n vá»›i p giÃ¡ trá»‹ thá»±c. Tuy nhiÃªn trong cÃ¡c pháº§n sau vÃ  pháº§n káº¿t quáº£, tÃ¡c giáº£ k Ä‘á» cáº­p Ä‘áº¿n viá»‡c Ä‘Ã£ láº¥y p chiáº¿m bao nhiÃªu % nÃªn em muá»‘n há»i má»i ngÆ°á»i lÃ  nÃªn Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng ntn vÃ  náº¿u lÃ  cÃ¡ch cá»§a tÃ¡c giáº£ LiÃªn thÃ¬ láº¥y p lÃ  bao nhiÃªu % áº¡.
1 láº§n ná»¯a em xin chÃ¢n thÃ nh cáº£m Æ¡n nhiá»u áº¡","Em chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ bÃ i táº­p lÃ  build 1 Recommendation System (RS), nhÆ°ng em hiá»‡n táº¡i váº«n khÃ¡ mÃ¹ má» vÃ¬ chÆ°a hiá»ƒu rÃµ pháº§n train vÃ  pháº§n test Ä‘Æ°á»£c thá»±c hiá»‡n ntn. NhÆ° em Ä‘Ã£ tÃ¬m hiá»ƒu thÃ¬ trong machine learning, táº­p train sáº½ xáº¥p xá»‰ hÃ m dá»± Ä‘oÃ¡n cÃ²n táº­p test sáº½ Ä‘á»ƒ xÄ‘ xem hÃ m Ä‘Ã³ tá»‘t Ä‘áº¿n Ä‘Ã¢u. NhÆ°ng á»Ÿ pháº§n RS nÃ y, cÃ³ 1 sá»‘ thuáº­t toÃ¡n Ä‘á»ƒ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c luÃ´n Ä‘Ã¡nh giÃ¡ cá»§a ngÆ°á»i dÃ¹ng (Collaborative-filtering user-based/item-based, matrix factorization,...) thÃ¬ mÃ¬nh chá»‰ cáº§n Ã¡p dá»¥ng thuáº­t toÃ¡n vá»›i dataset sau khi xá»­ lÃ­ Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c cÃ¡c Ä‘Ã¡nh giÃ¡ xáº¥p xá»‰. HÆ¡n ná»¯a, em tÃ¬m tháº¥y code máº«u trÃªn máº¡ng ( em Ä‘á»ƒ link bÃªn dÆ°á»›i) thÃ¬ tháº¥y ngÆ°á»i ta váº«n thá»«a sá»‘ hÃ³a cáº£ ma tráº­n ratings, tuy nhiÃªn chá»‰ cá»‘ gáº¯ng minimize loss cá»§a pháº§n train - 1 subset cá»§a ma tráº­n ratings trÃªn vÃ  tháº£ trÃ´i pháº§n test - pháº§n cÃ²n láº¡i cá»§a ma tráº­n. Äáº¿n Ä‘Ã¢y em kiá»ƒu bá»‹ @@, vÃ¬ sao k thá»«a sá»‘ hÃ³a rá»“i minimize loss cá»§a cáº£ ma tráº­n náº¿u nhÆ° test loss nhá» lÃ  tá»‘t. Tá»« Ä‘áº¥y dáº«n Ä‘áº¿n cÃ¢u há»i ban Ä‘áº§u cá»§a em: Táº¡i sao láº¡i chia train vs test ra ngay tá»« ban Ä‘áº§u? Em xin trÃ¢n thÃ nh cáº£m Æ¡n má»i Ã½ kiáº¿n Ä‘Ã³ng gÃ³p áº¡. Link bÃ i code Ä‘Ã¢y áº¡ (cá»¥ thá»ƒ á»Ÿ pháº§n function build_model): https://colab.research.google.com/github/google/eng-edu/blob/main/ml/recommendation-systems/recommendation-systems.ipynb?utm_source=ss-recommendation-systems&utm_campaign=colab-external&utm_medium=referral&utm_content=recommendation-systems#scrollTo=M9RxIX_Oo4tp PS: Vá»›i láº¡i cho em há»i thÃªm lÃ  cÃ³ pháº£i phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ loss chÆ°a tá»‘i Æ°u, bá»Ÿi theo nghiÃªn cá»©u cá»§a tÃ¡c giáº£ Äá»— Thá»‹ LiÃªn vÃ  cá»™ng sá»± (https://portal.ptit.edu.vn/saudaihoc/wp-content/uploads/2020/02/LA_%C4%90%E1%BB%97-Th%E1%BB%8B-Li%C3%AAn.pdf?fbclid=IwAR1BU24ivQHfe6mg8dYbi0iwq5Plcmew3B2ODYf0SmZubAtOIscNChQQO_I#page23) táº¡i trang 51, cáº§n pháº£i áº©n Ä‘i 1 sá»‘ p Ä‘Ã¡nh giÃ¡ Ä‘Ã£ biáº¿t cá»§a ngÆ°á»i dÃ¹ng trÃªn táº­p test, sau Ä‘Ã³ so sÃ¡nh giÃ¡ trá»‹ dá»± Ä‘oÃ¡n vá»›i p giÃ¡ trá»‹ thá»±c. Tuy nhiÃªn trong cÃ¡c pháº§n sau vÃ  pháº§n káº¿t quáº£, tÃ¡c giáº£ k Ä‘á» cáº­p Ä‘áº¿n viá»‡c Ä‘Ã£ láº¥y p chiáº¿m bao nhiÃªu % nÃªn em muá»‘n há»i má»i ngÆ°á»i lÃ  nÃªn Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng ntn vÃ  náº¿u lÃ  cÃ¡ch cá»§a tÃ¡c giáº£ LiÃªn thÃ¬ láº¥y p lÃ  bao nhiÃªu % áº¡. 1 láº§n ná»¯a em xin chÃ¢n thÃ nh cáº£m Æ¡n nhiá»u áº¡",,,"#Q&A, #machine_learning",,
"MÃ¬nh lÃ m háº¡ táº§ng pháº§n cá»©ng, cÃ³ thá»ƒ há»— trá»£ share lab cÃ³ sáºµn cÃ¡c tÃ i nguyÃªn mÃ¡y áº£o, káº¿t ná»‘i hadoop, cÃ³ máº¡ng Internet Ä‘á»ƒ tá»± cÃ i thÃªm package. Báº¡n nÃ o cáº§n tÃ i nguyÃªn tráº£i nghiá»‡m, test cÃ³ thá»ƒ ib mÃ¬nh, lab tá»“n táº¡i Ä‘Æ°á»£c 10 ngÃ y má»—i láº§n khá»Ÿi táº¡o. Má»—i mÃ¡y áº£o linux cÃ³ 24GB RAM","MÃ¬nh lÃ m háº¡ táº§ng pháº§n cá»©ng, cÃ³ thá»ƒ há»— trá»£ share lab cÃ³ sáºµn cÃ¡c tÃ i nguyÃªn mÃ¡y áº£o, káº¿t ná»‘i hadoop, cÃ³ máº¡ng Internet Ä‘á»ƒ tá»± cÃ i thÃªm package. Báº¡n nÃ o cáº§n tÃ i nguyÃªn tráº£i nghiá»‡m, test cÃ³ thá»ƒ ib mÃ¬nh, lab tá»“n táº¡i Ä‘Æ°á»£c 10 ngÃ y má»—i láº§n khá»Ÿi táº¡o. Má»—i mÃ¡y áº£o linux cÃ³ 24GB RAM",,,#sharing,,
"Anh/chá»‹/báº¡n trong group mÃ¬nh cÃ³ thá»ƒ cho em xin cÃ¡c nguá»“n thÃ´ng tin mÃ  má»i ngÆ°á»i cáº­p nháº­t thÃ´ng tin vá» cÃ¡c cÃ´ng nghá»‡ machine learning, cÃ¡c thuáº­t toÃ¡n, cÃ¡c dÃ²ng code hay á»Ÿ Ä‘Ã¢u khÃ´ng áº¡? Táº¡i vÃ¬ em lÃ  newbie nÃªn khÃ´ng rÃµ diá»…n Ä‘Ã n nÃ o hay vÃ  cÃ³ Ä‘á»™ tháº£o luáº­n cao. CÃ¡c diá»…n Ä‘Ã n báº±ng tiáº¿ng anh cÃ ng tá»‘t áº¡ <3.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c post, chÃºc má»i ngÆ°á»i lÃ m viá»‡c tháº­t nÄƒng suáº¥t!","Anh/chá»‹/báº¡n trong group mÃ¬nh cÃ³ thá»ƒ cho em xin cÃ¡c nguá»“n thÃ´ng tin mÃ  má»i ngÆ°á»i cáº­p nháº­t thÃ´ng tin vá» cÃ¡c cÃ´ng nghá»‡ machine learning, cÃ¡c thuáº­t toÃ¡n, cÃ¡c dÃ²ng code hay á»Ÿ Ä‘Ã¢u khÃ´ng áº¡? Táº¡i vÃ¬ em lÃ  newbie nÃªn khÃ´ng rÃµ diá»…n Ä‘Ã n nÃ o hay vÃ  cÃ³ Ä‘á»™ tháº£o luáº­n cao. CÃ¡c diá»…n Ä‘Ã n báº±ng tiáº¿ng anh cÃ ng tá»‘t áº¡ <3. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c post, chÃºc má»i ngÆ°á»i lÃ m viá»‡c tháº­t nÄƒng suáº¥t!",,,"#Q&A, #machine_learning",,
"Má»™t video thÃº vá»‹ vá» toÃ¡n. Hi vá»ng nÃ³ giáº£i thÃ­ch cáº·n káº½ Ä‘á»ƒ ta hiá»ƒu táº¡i sao láº¡i cÃ³ sá»‘ Pi, sá»‘ e,â€¦","Má»™t video thÃº vá»‹ vá» toÃ¡n. Hi vá»ng nÃ³ giáº£i thÃ­ch cáº·n káº½ Ä‘á»ƒ ta hiá»ƒu táº¡i sao láº¡i cÃ³ sá»‘ Pi, sá»‘ e,â€¦",,,"#sharing, #math",,
"ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn Ä‘ang theo há»c AI/ML, em cÃ³ má»™t tháº¯c máº¯c vá» hÆ°á»›ng Ä‘i trong ngÃ nh. Theo em biáº¿t thÃ¬ cÃ³ 2 hÆ°á»›ng chÃ­nh lÃ  Research vÃ  Engineer, anh/chá»‹ cho em há»i nhá»¯ng Ä‘iá»ƒm khÃ¡c nhau cá»§a 2 hÆ°á»›ng nÃ y, vÃ  cÆ¡ há»™i cá»§a hÆ°á»›ng nÃ o sáº½ lÃ  nhiá»u hÆ¡n áº¡.","ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn Ä‘ang theo há»c AI/ML, em cÃ³ má»™t tháº¯c máº¯c vá» hÆ°á»›ng Ä‘i trong ngÃ nh. Theo em biáº¿t thÃ¬ cÃ³ 2 hÆ°á»›ng chÃ­nh lÃ  Research vÃ  Engineer, anh/chá»‹ cho em há»i nhá»¯ng Ä‘iá»ƒm khÃ¡c nhau cá»§a 2 hÆ°á»›ng nÃ y, vÃ  cÆ¡ há»™i cá»§a hÆ°á»›ng nÃ o sáº½ lÃ  nhiá»u hÆ¡n áº¡.",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t á»Ÿ tp.HCM cÃ³ nÆ¡i nÃ o bÃ¡n sÃ¡ch  Calculus Early Transcendentals Ninth Edition khÃ´ng, máº·c dÃ¹ cÃ³ báº£n pdf nhÆ°ng mÃ¬nh lÃ m viá»‡c vá»›i mÃ¡y tÃ­nh ráº¥t nhiá»u nÃªn muá»‘n Ä‘á»c báº£n giáº¥y cho Ä‘á»¡ Ä‘au máº¯t vÃ  giáº£i trÃ­ trong thá»i gian ráº£nh má»™t tÃ­.","ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t á»Ÿ tp.HCM cÃ³ nÆ¡i nÃ o bÃ¡n sÃ¡ch Calculus Early Transcendentals Ninth Edition khÃ´ng, máº·c dÃ¹ cÃ³ báº£n pdf nhÆ°ng mÃ¬nh lÃ m viá»‡c vá»›i mÃ¡y tÃ­nh ráº¥t nhiá»u nÃªn muá»‘n Ä‘á»c báº£n giáº¥y cho Ä‘á»¡ Ä‘au máº¯t vÃ  giáº£i trÃ­ trong thá»i gian ráº£nh má»™t tÃ­.",,,"#Q&A, #math",,
"Em chÃ o má»i ngÆ°á»i áº¡,em lÃ  newbie cháº­p chá»¯ng vÃ o nghá» Ä‘ang gáº·p 1 váº¥n Ä‘á» á»Ÿ 1 bÃ i toÃ¡n mong Ä‘Æ°á»£c mn giáº£i Ä‘Ã¡p áº¡!
BÃ i toÃ¡n:Em cÃ³ Ã¡p dá»¥ng HOG Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng áº£nh,áº£nh cá»§a em lÃ  150*150.khi dÃ¹ng HOG thÃ¬ em cho orientations = 8,pixel per cell =16,cell per block =4 thÃ¬ khi trÃ­ch xuáº¥t xong 1 áº£nh sáº½ Ä‘c biá»ƒu diá»…n dÆ°á»›i 1 vector kÃ­ch thÆ°á»›c (4608,)
1.Em cÃ³ tháº¯c máº¯c con sá»‘ 4608 nÃ y táº¡o ra ntn áº¡?
2.Táº¡i vÃ¬ em tháº¥y size áº£nh k chia háº¿t cho pixel per cell vÃ  náº¿u luáº­n ngÆ°á»£c lÃªn 4608 / 8*4*4= 36 =6*6(vá»›i 8*4*4 lÃ  Ä‘á»™ dÃ i Vector HOG cá»§a má»—i block) hay nÃ³i cÃ¡ch khÃ¡c trÃªn má»—i phÆ°Æ¡ng sáº½ khi Ä‘i tá»« trÃ¡i qua pháº£i hoáº·c trÃªn xuá»‘ng dÆ°á»›i ta sáº½ pháº£i tÃ­nh HOG trÃªn 6 block káº¿t há»£p vs viá»‡c 4 cell cho má»—i block thÃ¬ ta sáº½ cÃ³ Ä‘c sá»‘ cell theo tá»«ng phÆ°Æ¡ng lÃ  9
Nma náº¿u tÃ­nh nhÆ° váº­y thÃ¬ sá»‘ pixel theo má»—i phÆ°Æ¡ng sáº½ lÃ  9*16 < 150 nhÆ° Ä‘Ãºng size áº£nh gá»‘c váº­y liá»‡u cÃ³ pháº£i Ä‘Ã¡m pixel cÃ²n láº¡i bá»‹ thiáº¿u sáº½ bá»‹ cáº¯t Ä‘i k dÃ¹ng Ä‘áº¿n khi tÃ­nh hay lÃ  sáº½ Ä‘Æ°á»£c nÃ©m vÃ o cÃ¡c cell trong 9 cell cÃ³ sáºµn Ä‘Ã³ áº¡ ?
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡,mong sáº½ Ä‘Æ°á»£c admin duyá»‡t bÃ i sá»›m vÃ  sá»›m nháº­n Ä‘Æ°á»£c giÃºp Ä‘á»¡ tá»« mn áº¡!!!","Em chÃ o má»i ngÆ°á»i áº¡,em lÃ  newbie cháº­p chá»¯ng vÃ o nghá» Ä‘ang gáº·p 1 váº¥n Ä‘á» á»Ÿ 1 bÃ i toÃ¡n mong Ä‘Æ°á»£c mn giáº£i Ä‘Ã¡p áº¡! BÃ i toÃ¡n:Em cÃ³ Ã¡p dá»¥ng HOG Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng áº£nh,áº£nh cá»§a em lÃ  150*150.khi dÃ¹ng HOG thÃ¬ em cho orientations = 8,pixel per cell =16,cell per block =4 thÃ¬ khi trÃ­ch xuáº¥t xong 1 áº£nh sáº½ Ä‘c biá»ƒu diá»…n dÆ°á»›i 1 vector kÃ­ch thÆ°á»›c (4608,) 1.Em cÃ³ tháº¯c máº¯c con sá»‘ 4608 nÃ y táº¡o ra ntn áº¡? 2.Táº¡i vÃ¬ em tháº¥y size áº£nh k chia háº¿t cho pixel per cell vÃ  náº¿u luáº­n ngÆ°á»£c lÃªn 4608 / 8*4*4= 36 =6*6(vá»›i 8*4*4 lÃ  Ä‘á»™ dÃ i Vector HOG cá»§a má»—i block) hay nÃ³i cÃ¡ch khÃ¡c trÃªn má»—i phÆ°Æ¡ng sáº½ khi Ä‘i tá»« trÃ¡i qua pháº£i hoáº·c trÃªn xuá»‘ng dÆ°á»›i ta sáº½ pháº£i tÃ­nh HOG trÃªn 6 block káº¿t há»£p vs viá»‡c 4 cell cho má»—i block thÃ¬ ta sáº½ cÃ³ Ä‘c sá»‘ cell theo tá»«ng phÆ°Æ¡ng lÃ  9 Nma náº¿u tÃ­nh nhÆ° váº­y thÃ¬ sá»‘ pixel theo má»—i phÆ°Æ¡ng sáº½ lÃ  9*16 < 150 nhÆ° Ä‘Ãºng size áº£nh gá»‘c váº­y liá»‡u cÃ³ pháº£i Ä‘Ã¡m pixel cÃ²n láº¡i bá»‹ thiáº¿u sáº½ bá»‹ cáº¯t Ä‘i k dÃ¹ng Ä‘áº¿n khi tÃ­nh hay lÃ  sáº½ Ä‘Æ°á»£c nÃ©m vÃ o cÃ¡c cell trong 9 cell cÃ³ sáºµn Ä‘Ã³ áº¡ ? Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡,mong sáº½ Ä‘Æ°á»£c admin duyá»‡t bÃ i sá»›m vÃ  sá»›m nháº­n Ä‘Æ°á»£c giÃºp Ä‘á»¡ tá»« mn áº¡!!!",,,"#Q&A, #cv",,
"Xin Ä‘Æ°á»£c share vá»›i cÃ¡c bÃ¡c 1 seminar dÃ nh chung cho táº¥t cáº£ cÃ¡c anh em há»©ng thÃº vá»›i MLOps vá»›i chá»§ Ä‘á»:
â€œOptimize ML serviceâ€™s performance with continuous right-sizing containers in Kubernetesâ€",Xin Ä‘Æ°á»£c share vá»›i cÃ¡c bÃ¡c 1 seminar dÃ nh chung cho táº¥t cáº£ cÃ¡c anh em há»©ng thÃº vá»›i MLOps vá»›i chá»§ Ä‘á»: â€œOptimize ML serviceâ€™s performance with continuous right-sizing containers in Kubernetesâ€,,,#webinar,,
"THUÃŠ SERVER TRÃŠN VAST.AI
ChÃ o má»i ngÆ°á»i, trong group mÃ¬nh cÃ³ ai Ä‘Ã£ tá»«ng thuÃª server trÃªn vast.ai chÆ°a áº¡ cho mÃ¬nh Ã­t review. Tháº¥y giÃ¡ cÅ©ng ráº» mÃ  nhá»‰. Em Ä‘á»‹nh dÃ¹ng Ä‘á»ƒ train model AI thay vÃ¬ Kaggle hay Colab ko biáº¿t cÃ³ nhanh hÆ¡n ko. Vá»›i láº¡i nÃ³ cáº§n credit card Ä‘á»ƒ náº¡p tiá»n vÃ o mÃ  giá» em khÃ´ng cÃ³ credit card thÃ¬ ko biáº¿t cÃ³ giáº£i phÃ¡p nÃ o ko. Em xin cáº£m Æ¡n.","THUÃŠ SERVER TRÃŠN VAST.AI ChÃ o má»i ngÆ°á»i, trong group mÃ¬nh cÃ³ ai Ä‘Ã£ tá»«ng thuÃª server trÃªn vast.ai chÆ°a áº¡ cho mÃ¬nh Ã­t review. Tháº¥y giÃ¡ cÅ©ng ráº» mÃ  nhá»‰. Em Ä‘á»‹nh dÃ¹ng Ä‘á»ƒ train model AI thay vÃ¬ Kaggle hay Colab ko biáº¿t cÃ³ nhanh hÆ¡n ko. Vá»›i láº¡i nÃ³ cáº§n credit card Ä‘á»ƒ náº¡p tiá»n vÃ o mÃ  giá» em khÃ´ng cÃ³ credit card thÃ¬ ko biáº¿t cÃ³ giáº£i phÃ¡p nÃ o ko. Em xin cáº£m Æ¡n.",,,#Q&A,,
Khoa há»c dá»¯ liá»‡u (Data Science) lÃ  má»™t lÄ©nh vá»±c Ä‘ang phÃ¡t triá»ƒn nhanh chÃ³ng vá»›i nhiá»u cÆ¡ há»™i nghá» nghiá»‡p. HÃ£y cÃ¹ng khÃ¡m phÃ¡ má»™t sá»‘ vai trÃ² chÃ­nh trong lÄ©nh vá»±c Khoa há»c dá»¯ liá»‡u.,Khoa há»c dá»¯ liá»‡u (Data Science) lÃ  má»™t lÄ©nh vá»±c Ä‘ang phÃ¡t triá»ƒn nhanh chÃ³ng vá»›i nhiá»u cÆ¡ há»™i nghá» nghiá»‡p. HÃ£y cÃ¹ng khÃ¡m phÃ¡ má»™t sá»‘ vai trÃ² chÃ­nh trong lÄ©nh vá»±c Khoa há»c dá»¯ liá»‡u.,,,"#sharing, #data",,
ğŸ”¥ Vision Transformer (ViT) - Hiá»‡n tÆ°á»£ng má»›i trong lÄ©nh vá»±c thá»‹ giÃ¡c mÃ¡y tÃ­nh! ğŸ”¥,Vision Transformer (ViT) - Hiá»‡n tÆ°á»£ng má»›i trong lÄ©nh vá»±c thá»‹ giÃ¡c mÃ¡y tÃ­nh!,,,"#sharing, #cv, #deep_learning",,
"MÃ¬nh Ä‘ang cÃ y project Ä‘á»ƒ apply xin viá»‡c. MÃ¬nh Ä‘ang tÃ¬m cÃ¡c competitions Ä‘á»ƒ luyá»‡n táº­p. Bao gá»“m EDA, Pre-Processing, Modeling vÃ  Predict. Hiá»‡n táº¡i mÃ¬nh má»›i tham gia 2 cuá»™c thi nhÆ°ng káº¿t quáº£ cá»§a mÃ¬nh chá»‰ giao Ä‘á»™ng tá»« 40-55% so vá»›i Ä‘á»™ chÃ­nh xÃ¡c cá»§a cuá»™c thi do mÃ¬nh khÃ´ng biáº¿t optimize (hoáº·c optimize xong thÃ¬ kernel die cháº³ng háº¡n). MÃ¬nh muá»‘n tÃ¬m báº¡n colab vá»›i mÃ¬nh, cÃ¹ng nhau cÃ y project kiáº¿m medal. Cháº³ng háº¡n mÃ¬nh cÃ³ thá»ƒ Pre-Processing, EDA,... cÃ²n báº¡n lÃ m pháº§n cÃ²n láº¡i, hoáº·c cáº£ 2 cÃ¹ng tháº£o luáº­n vá» cÃ¡c cÃ¡ch lÃ m... KhÃ´ng nháº¥t thiáº¿t ngÃ y nÃ o cÅ©ng pháº£i lÃ m cÃ¹ng nhau nhÆ°ng cá»‘ gáº¯ng tuáº§n nÃ o cÅ©ng trao Ä‘á»•i ğŸ¥°ğŸ¥° ad duyá»‡t cho mÃ¬nh kiáº¿m tÃ½ medal vá»›iiiii","MÃ¬nh Ä‘ang cÃ y project Ä‘á»ƒ apply xin viá»‡c. MÃ¬nh Ä‘ang tÃ¬m cÃ¡c competitions Ä‘á»ƒ luyá»‡n táº­p. Bao gá»“m EDA, Pre-Processing, Modeling vÃ  Predict. Hiá»‡n táº¡i mÃ¬nh má»›i tham gia 2 cuá»™c thi nhÆ°ng káº¿t quáº£ cá»§a mÃ¬nh chá»‰ giao Ä‘á»™ng tá»« 40-55% so vá»›i Ä‘á»™ chÃ­nh xÃ¡c cá»§a cuá»™c thi do mÃ¬nh khÃ´ng biáº¿t optimize (hoáº·c optimize xong thÃ¬ kernel die cháº³ng háº¡n). MÃ¬nh muá»‘n tÃ¬m báº¡n colab vá»›i mÃ¬nh, cÃ¹ng nhau cÃ y project kiáº¿m medal. Cháº³ng háº¡n mÃ¬nh cÃ³ thá»ƒ Pre-Processing, EDA,... cÃ²n báº¡n lÃ m pháº§n cÃ²n láº¡i, hoáº·c cáº£ 2 cÃ¹ng tháº£o luáº­n vá» cÃ¡c cÃ¡ch lÃ m... KhÃ´ng nháº¥t thiáº¿t ngÃ y nÃ o cÅ©ng pháº£i lÃ m cÃ¹ng nhau nhÆ°ng cá»‘ gáº¯ng tuáº§n nÃ o cÅ©ng trao Ä‘á»•i ad duyá»‡t cho mÃ¬nh kiáº¿m tÃ½ medal vá»›iiiii",,,"#sharing, #machine_learning",,
"Anh chá»‹ cÃ³ kinh nghiá»‡m cho em há»i chÃºt vá»›i áº¡. Em tháº¥y trong cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng thá»±c thá»ƒ ngÆ°á»i ta hay káº¿t há»£p model transformer + CRF . thÃ¬ cho em há»i táº¡i sao mÃ¬nh láº¡i cho qua CRF mÃ  ko phÃ¢n loáº¡i luÃ´n áº¡. Bá»Ÿi vÃ¬ em tháº¥y cÃ¡c tá»« lÃºc nÃ y Ä‘á»u cÃ³ 1 Ã½ nghÄ©a riÃªng rá»“i mÃ  nhá»‰, vÃ¬ em cÃ³ Ä‘á»c tÃ¬m hiá»ƒu trÃªn máº¡ng nhÆ°ng tháº¥y váº«n chÆ°a Ä‘Æ°á»£c giáº£i thÃ­ch Ä‘Ãºng láº¯m . Em cáº£m Æ¡n nhá»¯ng lá»i giáº£i thÃ­ch áº¡","Anh chá»‹ cÃ³ kinh nghiá»‡m cho em há»i chÃºt vá»›i áº¡. Em tháº¥y trong cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng thá»±c thá»ƒ ngÆ°á»i ta hay káº¿t há»£p model transformer + CRF . thÃ¬ cho em há»i táº¡i sao mÃ¬nh láº¡i cho qua CRF mÃ  ko phÃ¢n loáº¡i luÃ´n áº¡. Bá»Ÿi vÃ¬ em tháº¥y cÃ¡c tá»« lÃºc nÃ y Ä‘á»u cÃ³ 1 Ã½ nghÄ©a riÃªng rá»“i mÃ  nhá»‰, vÃ¬ em cÃ³ Ä‘á»c tÃ¬m hiá»ƒu trÃªn máº¡ng nhÆ°ng tháº¥y váº«n chÆ°a Ä‘Æ°á»£c giáº£i thÃ­ch Ä‘Ãºng láº¯m . Em cáº£m Æ¡n nhá»¯ng lá»i giáº£i thÃ­ch áº¡",,,"#Q&A, #cv, #deep_learning",,
"Em xin chÃ o má»i ngÆ°á»i, lÃ  em sinh viÃªn ngÃ nh Khoa há»c MÃ¡y tÃ­nh.
VÃ¬ quÃ¡ mÃ´ng lung trÃªn con Ä‘Æ°á»ng há»c Ä‘á»ƒ trá»Ÿ Computer Vision Engineer, nÃªn em muá»‘n há»i mn
""CÃ¡ch há»c CV nhÆ° tháº¿ nÃ o Ä‘á»ƒ sau nÃ y cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c viá»‡c áº¡"".
Hiá»‡n táº¡i thÃ¬ em Ä‘Ã£ há»c ANN, CNN, RNN, LSTM (á»Ÿ má»©c cÆ¡ báº£n thÃ´i áº¡), em Ä‘á»‹nh hÆ°á»›ng lÃ  sáº½ code theo cÃ¡c project trÃªn máº¡ng, trÃªn sÃ¡ch Ä‘á»ƒ lÃ m quen. NhÆ°ng code xong em cáº£m tháº¥y nÃ³ khÃ´ng pháº£i lÃ  cá»§a mÃ¬nh, vÃ  cÅ©ng khÃ´ng thá»ƒ tá»± code Ä‘Æ°á»£c cÃ¡i gÃ¬?
Em khÃ´ng biáº¿t há»c nhÆ° tháº¿ nÃ o cho Ä‘Ãºng? Mong má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em tráº§m cáº£m vÃ´ cÃ¹ng.","Em xin chÃ o má»i ngÆ°á»i, lÃ  em sinh viÃªn ngÃ nh Khoa há»c MÃ¡y tÃ­nh. VÃ¬ quÃ¡ mÃ´ng lung trÃªn con Ä‘Æ°á»ng há»c Ä‘á»ƒ trá»Ÿ Computer Vision Engineer, nÃªn em muá»‘n há»i mn ""CÃ¡ch há»c CV nhÆ° tháº¿ nÃ o Ä‘á»ƒ sau nÃ y cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c viá»‡c áº¡"". Hiá»‡n táº¡i thÃ¬ em Ä‘Ã£ há»c ANN, CNN, RNN, LSTM (á»Ÿ má»©c cÆ¡ báº£n thÃ´i áº¡), em Ä‘á»‹nh hÆ°á»›ng lÃ  sáº½ code theo cÃ¡c project trÃªn máº¡ng, trÃªn sÃ¡ch Ä‘á»ƒ lÃ m quen. NhÆ°ng code xong em cáº£m tháº¥y nÃ³ khÃ´ng pháº£i lÃ  cá»§a mÃ¬nh, vÃ  cÅ©ng khÃ´ng thá»ƒ tá»± code Ä‘Æ°á»£c cÃ¡i gÃ¬? Em khÃ´ng biáº¿t há»c nhÆ° tháº¿ nÃ o cho Ä‘Ãºng? Mong má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em tráº§m cáº£m vÃ´ cÃ¹ng.",,,"#Q&A, #cv, #deep_learning",,
Anh/chá»‹ cho em há»i muá»‘n há»c ML thÃ¬ nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡?,Anh/chá»‹ cho em há»i muá»‘n há»c ML thÃ¬ nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡?,,,"#Q&A, #machine_learning",,
"ChÃ o cÃ¡c báº¡n
MÃ¬nh Ä‘ang tÃ¬m host Ä‘á»ƒ deploy con services AI xá»­ lÃ½ áº£nh. Má»i ng thÆ°á»ng triá»ƒn khai á»Ÿ Ä‘Ã¢u? Æ¯u tiÃªn ngon bá»• ráº» nhÃ© ae
Cáº£m Æ¡n anh em",ChÃ o cÃ¡c báº¡n MÃ¬nh Ä‘ang tÃ¬m host Ä‘á»ƒ deploy con services AI xá»­ lÃ½ áº£nh. Má»i ng thÆ°á»ng triá»ƒn khai á»Ÿ Ä‘Ã¢u? Æ¯u tiÃªn ngon bá»• ráº» nhÃ© ae Cáº£m Æ¡n anh em,,,#Q&A,,
"Em chÃ o má»i ngÆ°á»i áº¡,
Em Ä‘ang tham kháº£o vá» má»™t Ä‘á» tÃ i LVTN xoay quanh AI lÃ m vá» má»™t há»‡ thá»‘ng social network káº¿t ná»‘i cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng vÃ  chuyÃªn gia.
Cá»¥ thá»ƒ, cÃ³ nhá»¯ng nhÃ³m cÃ´ng ty DN, cÃ¡ nhÃ¢n, cÃ³ nhá»¯ng bÃ i toÃ¡n Ä‘áº·c thÃ¹ vá» AI. NhÆ°ng khÃ´ng biáº¿t giáº£i quyáº¿t nhÆ° tháº¿ nÃ o, thay vÃ¬ pháº£i há»c vÃ  pháº£i tá»‘n thá»i gian Ä‘á»ƒ há»c, há» muá»‘n giáº£i quyáº¿t Ä‘Æ°á»£c nhá»¯ng bÃ i toÃ¡n nÃ y trong thá»i gian ngáº¯n. ThÃ¬ há»‡ thá»‘ng nÃ y sáº½ lÃ  há»‡ thá»‘ng social network Ä‘á»ƒ káº¿t ná»‘i nhá»¯ng nhu cáº§u nÃ y. Há»‡ thá»‘ng sáº½ mang Ä‘áº·c thÃ¹ káº¿t ná»‘i, cá»™ng tÃ¡c giá»¯a cÃ¡c bÃªn cÃ³ bÃ i toÃ¡n nhÆ°ng khÃ´ng biáº¿t lÃ m gÃ¬, giá»¯a cÃ¡c bÃªn cÃ³ kÄ© nÄƒng. Tuy nhiÃªn, khÃ´ng Ä‘Æ¡n giáº£n chá»‰ tÆ°Æ¡ng tÃ¡c. MÃ  pháº£i duy trÃ¬, vÃ  quáº£n trá»‹ káº¿t ná»‘i Ä‘Ã³ (VÃ­ dá»¥ khi Ä‘ang lÃ m giá»¯a chá»«ng, mÃ  bÃªn lÃ m há» rÃºt khÃ´ng lÃ m ná»¯a thÃ¬ pháº£i xá»­ lÃ­ nhÆ° tháº¿ nÃ o). Há»‡ thá»‘ng cÅ©ng pháº£i Ä‘áº£m báº£o tá»± Ä‘á»™ng, thÃ´ng minh, káº¿t ná»‘i cÃ¡c bÃªn liÃªn quan. Giáº£ sá»­ cÃ³ nhu cáº§u vá» 10 bÃ i toÃ¡n AI khÃ¡c nhau, thÃ¬ há»‡ thá»‘ng pháº£i lÃ m sao Ä‘á» xuáº¥t Ä‘Æ°á»£c nguá»“n lá»±c nÃ o, háº¡ táº§ng nÃ o phÃ¹ há»£p cho tá»«ng nhu cáº§u cá»¥ thá»ƒ (KhÃ´ng Ä‘Æ¡n thuáº§n chá»‰ lÃ  up bÃ i lÃªn rá»“i ngÆ°á»i khÃ¡c vÃ o tráº£ lá»i).
Má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng lÃ m qua hoáº·c biáº¿t cÃ³ thá»ƒ cho em xin má»™t sá»‘ tÃ i liá»‡u liÃªn quan Ä‘Æ°á»£c khÃ´ng áº¡. VÃ  mn cÃ³ thá»ƒ cho em xin má»™t sá»‘ há»‡ thá»‘ng giá»‘ng nhÆ° trÃªn á»Ÿ thá»±c táº¿ Ä‘á»ƒ cÃ³ thá»ƒ tham kháº£o khÃ´ng áº¡. VÃ¬ em cÃ³ search nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i, chÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» ^^","Em chÃ o má»i ngÆ°á»i áº¡, Em Ä‘ang tham kháº£o vá» má»™t Ä‘á» tÃ i LVTN xoay quanh AI lÃ m vá» má»™t há»‡ thá»‘ng social network káº¿t ná»‘i cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng vÃ  chuyÃªn gia. Cá»¥ thá»ƒ, cÃ³ nhá»¯ng nhÃ³m cÃ´ng ty DN, cÃ¡ nhÃ¢n, cÃ³ nhá»¯ng bÃ i toÃ¡n Ä‘áº·c thÃ¹ vá» AI. NhÆ°ng khÃ´ng biáº¿t giáº£i quyáº¿t nhÆ° tháº¿ nÃ o, thay vÃ¬ pháº£i há»c vÃ  pháº£i tá»‘n thá»i gian Ä‘á»ƒ há»c, há» muá»‘n giáº£i quyáº¿t Ä‘Æ°á»£c nhá»¯ng bÃ i toÃ¡n nÃ y trong thá»i gian ngáº¯n. ThÃ¬ há»‡ thá»‘ng nÃ y sáº½ lÃ  há»‡ thá»‘ng social network Ä‘á»ƒ káº¿t ná»‘i nhá»¯ng nhu cáº§u nÃ y. Há»‡ thá»‘ng sáº½ mang Ä‘áº·c thÃ¹ káº¿t ná»‘i, cá»™ng tÃ¡c giá»¯a cÃ¡c bÃªn cÃ³ bÃ i toÃ¡n nhÆ°ng khÃ´ng biáº¿t lÃ m gÃ¬, giá»¯a cÃ¡c bÃªn cÃ³ kÄ© nÄƒng. Tuy nhiÃªn, khÃ´ng Ä‘Æ¡n giáº£n chá»‰ tÆ°Æ¡ng tÃ¡c. MÃ  pháº£i duy trÃ¬, vÃ  quáº£n trá»‹ káº¿t ná»‘i Ä‘Ã³ (VÃ­ dá»¥ khi Ä‘ang lÃ m giá»¯a chá»«ng, mÃ  bÃªn lÃ m há» rÃºt khÃ´ng lÃ m ná»¯a thÃ¬ pháº£i xá»­ lÃ­ nhÆ° tháº¿ nÃ o). Há»‡ thá»‘ng cÅ©ng pháº£i Ä‘áº£m báº£o tá»± Ä‘á»™ng, thÃ´ng minh, káº¿t ná»‘i cÃ¡c bÃªn liÃªn quan. Giáº£ sá»­ cÃ³ nhu cáº§u vá» 10 bÃ i toÃ¡n AI khÃ¡c nhau, thÃ¬ há»‡ thá»‘ng pháº£i lÃ m sao Ä‘á» xuáº¥t Ä‘Æ°á»£c nguá»“n lá»±c nÃ o, háº¡ táº§ng nÃ o phÃ¹ há»£p cho tá»«ng nhu cáº§u cá»¥ thá»ƒ (KhÃ´ng Ä‘Æ¡n thuáº§n chá»‰ lÃ  up bÃ i lÃªn rá»“i ngÆ°á»i khÃ¡c vÃ o tráº£ lá»i). Má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng lÃ m qua hoáº·c biáº¿t cÃ³ thá»ƒ cho em xin má»™t sá»‘ tÃ i liá»‡u liÃªn quan Ä‘Æ°á»£c khÃ´ng áº¡. VÃ  mn cÃ³ thá»ƒ cho em xin má»™t sá»‘ há»‡ thá»‘ng giá»‘ng nhÆ° trÃªn á»Ÿ thá»±c táº¿ Ä‘á»ƒ cÃ³ thá»ƒ tham kháº£o khÃ´ng áº¡. VÃ¬ em cÃ³ search nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c áº¡. Cáº£m Æ¡n má»i ngÆ°á»i, chÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» ^^",,,#Q&A,,
"ChÃ o má»i ngÆ°á»i,
Phoenix Team xin chia sáº» vá»›i má»i ngÆ°á»i source code cá»§a 1st private-test solution, Zalo AI Challenge 2020 pháº§n traffic sign detection.
Má»™t sá»‘ tricks mÃ  team cÃ³ sá»­ dá»¥ng:

1. Training data preprocessing
- Chia áº£nh thÃ nh cÃ¡c grid nhá» hÆ¡n, sá»­ dá»¥ng input size 160x160 vÃ  stried window 40x40.
- Loáº¡i bá»›t cÃ¡c áº£nh background vÃ  cÃ¡c áº£nh cÃ³ dÃ­nh 1 pháº§n box quÃ¡ nhá» (< 10% diá»‡n tÃ­ch box), chá»‰ Ä‘á»ƒ tá»‰ lá»‡ 1:3.

2. Training pharse
- Augmentation: Mosaic (9) + mixup.
- Model: Yolov5x, SGD Optimizer + Ema.
- 5-Stratified CV (chia áº£nh gá»‘c, sau Ä‘Ã³ preprocess sau).

3. Inference 
- Chia áº£nh thÃ nh cÃ¡c grid 384x384, scale-up lÃªn input 608x608, stride 84x88. 
-Sau khi Ä‘i qua model, NMS Ä‘Æ°á»£c sá»­ dá»¥ng giá»¯a cÃ¡c áº£nh nhá» theo area cá»§a cÃ¡c box, iou 0.1.
- WBF (Weighted boxes fusion) Ä‘Æ°á»£c sá»­ dá»¥ng giá»¯a cÃ¡c fold.
- Best 5-fold fp16 model: 60.5
CÃ¡c báº¡n cÃ³ cÃ¢u há»i nÃ o cÃ³ thá»ƒ viáº¿t dÆ°á»›i post nÃ y hoáº·c Ä‘á»ƒ láº¡i á»Ÿ pháº§n issue cá»§a git. 

CÃ¡c thÃ nh viÃªn trong team: Háº£i Nam Nguyá»…n (xSeries - FUNiX), ThÃ¢n CÆ°á»ng (AI Engineer - Asilla), Nguyen Hai Son (BKHN - AI Intern, Asilla).
ChÃºc cÃ¡c báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng má»™t trong cÃ¡c tricks á»Ÿ trÃªn vÃ o cuá»™c thi cá»§a VinBigData Sáº¯p tá»›i :)
 ","ChÃ o má»i ngÆ°á»i, Phoenix Team xin chia sáº» vá»›i má»i ngÆ°á»i source code cá»§a 1st private-test solution, Zalo AI Challenge 2020 pháº§n traffic sign detection. Má»™t sá»‘ tricks mÃ  team cÃ³ sá»­ dá»¥ng: 1. Training data preprocessing - Chia áº£nh thÃ nh cÃ¡c grid nhá» hÆ¡n, sá»­ dá»¥ng input size 160x160 vÃ  stried window 40x40. - Loáº¡i bá»›t cÃ¡c áº£nh background vÃ  cÃ¡c áº£nh cÃ³ dÃ­nh 1 pháº§n box quÃ¡ nhá» (< 10% diá»‡n tÃ­ch box), chá»‰ Ä‘á»ƒ tá»‰ lá»‡ 1:3. 2. Training pharse - Augmentation: Mosaic (9) + mixup. - Model: Yolov5x, SGD Optimizer + Ema. - 5-Stratified CV (chia áº£nh gá»‘c, sau Ä‘Ã³ preprocess sau). 3. Inference - Chia áº£nh thÃ nh cÃ¡c grid 384x384, scale-up lÃªn input 608x608, stride 84x88. -Sau khi Ä‘i qua model, NMS Ä‘Æ°á»£c sá»­ dá»¥ng giá»¯a cÃ¡c áº£nh nhá» theo area cá»§a cÃ¡c box, iou 0.1. - WBF (Weighted boxes fusion) Ä‘Æ°á»£c sá»­ dá»¥ng giá»¯a cÃ¡c fold. - Best 5-fold fp16 model: 60.5 CÃ¡c báº¡n cÃ³ cÃ¢u há»i nÃ o cÃ³ thá»ƒ viáº¿t dÆ°á»›i post nÃ y hoáº·c Ä‘á»ƒ láº¡i á»Ÿ pháº§n issue cá»§a git. CÃ¡c thÃ nh viÃªn trong team: Háº£i Nam Nguyá»…n (xSeries - FUNiX), ThÃ¢n CÆ°á»ng (AI Engineer - Asilla), Nguyen Hai Son (BKHN - AI Intern, Asilla). ChÃºc cÃ¡c báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng má»™t trong cÃ¡c tricks á»Ÿ trÃªn vÃ o cuá»™c thi cá»§a VinBigData Sáº¯p tá»›i :)",,,"#sharing, #cv",,
"Mn Æ¡i em há»c Ä‘áº¿n bÃ i nÃ y thÃ¬ khÃ´ng biáº¿t sao láº¡i cÃ³ cÃ´ng thá»©c thá»© 2 áº¡. Mn giÃºp em vá»›i.
https://machinelearningcoban.com/2017/01/16/gradientdescent2/",Mn Æ¡i em há»c Ä‘áº¿n bÃ i nÃ y thÃ¬ khÃ´ng biáº¿t sao láº¡i cÃ³ cÃ´ng thá»©c thá»© 2 áº¡. Mn giÃºp em vá»›i. https://machinelearningcoban.com/2017/01/16/gradientdescent2/,,,"#Q&A, #math",,
"VinAI Seminar - ""Ubiquitous 3D Vision in the Wild""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Minh Vo, Spree3D
Time: 10:00 am - 11:00 am (GMT+7), Mon, Jul 03, 2023","VinAI Seminar - ""Ubiquitous 3D Vision in the Wild"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Minh Vo, Spree3D Time: 10:00 am - 11:00 am (GMT+7), Mon, Jul 03, 2023",,,,,
"xin chÃ o má»i ngÆ°á»i
má»i ngÆ°á»i cho em há»i lÃ  cÃ¡ch láº¥y dá»¯ liá»‡u tá»« trang web nhÆ° tháº¿ nÃ o áº¡,
vÃ­ dá»¥: em muá»‘n láº¥y táº¥t cáº£ bÃ i viáº¿t trong nhÃ³m trÃªn fb vá», trong Ä‘Ã³ 1 sá»‘ bÃ i viáº¿t cÃ³ áº£nh, má»™t sá»‘ bÃ i khÃ´ng, em muá»‘n láº¥y vá» háº¿t gá»“m : tiÃªu Ä‘á», ná»™i dung, áº£nh (náº¿u cÃ³)
em xin cáº£m Æ¡n áº¡","xin chÃ o má»i ngÆ°á»i má»i ngÆ°á»i cho em há»i lÃ  cÃ¡ch láº¥y dá»¯ liá»‡u tá»« trang web nhÆ° tháº¿ nÃ o áº¡, vÃ­ dá»¥: em muá»‘n láº¥y táº¥t cáº£ bÃ i viáº¿t trong nhÃ³m trÃªn fb vá», trong Ä‘Ã³ 1 sá»‘ bÃ i viáº¿t cÃ³ áº£nh, má»™t sá»‘ bÃ i khÃ´ng, em muá»‘n láº¥y vá» háº¿t gá»“m : tiÃªu Ä‘á», ná»™i dung, áº£nh (náº¿u cÃ³) em xin cáº£m Æ¡n áº¡",,,"#Q&A, #data",,
Mn cho em há»i xá»­ lÃ­ cÃ¡c tá»« viáº¿t táº¯t tiáº¿ng nhÆ° nÃ o v ? E Ä‘ang lÃ m sentiment analysis mÃ  Ä‘á»•i tá»«ng tá»« viáº¿t táº¯t sang hoÃ n chá»‰nh cháº¯c cháº¿t máº¥t.,Mn cho em há»i xá»­ lÃ­ cÃ¡c tá»« viáº¿t táº¯t tiáº¿ng nhÆ° nÃ o v ? E Ä‘ang lÃ m sentiment analysis mÃ  Ä‘á»•i tá»«ng tá»« viáº¿t táº¯t sang hoÃ n chá»‰nh cháº¯c cháº¿t máº¥t.,,,"#Q&A, #nlp",,
"Má»i ngÆ°á»i cÃ³ tÃ i liá»‡u, papers, books Ä‘á»ƒ báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» derivative-free optimization hay blackbox optimization khÃ´ng áº¡. Em xin cáº£m Æ¡n","Má»i ngÆ°á»i cÃ³ tÃ i liá»‡u, papers, books Ä‘á»ƒ báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» derivative-free optimization hay blackbox optimization khÃ´ng áº¡. Em xin cáº£m Æ¡n",,,"#Q&A, #machine_learning",,
ChÃ o mn áº¡. Em Ä‘ang mong muá»‘ tÃ¬m job intern/fresher Al á»Ÿ HÃ  Ná»™i áº¡. Em cáº£m Æ¡n áº¡,ChÃ o mn áº¡. Em Ä‘ang mong muá»‘ tÃ¬m job intern/fresher Al á»Ÿ HÃ  Ná»™i áº¡. Em cáº£m Æ¡n áº¡,,,"#Q&A, #machine_learning",,
"Em chÃ o mn. em tá»± há»c bÃ i Gradient Descent Ä‘áº¿n Ä‘oáº¡n cÃ´ng thá»©c nÃ y thÃ¬ khÃ´ng hiá»ƒu táº¡i sao. mn giáº£i thÃ­ch giÃºp em vá»›i.
https://machinelearningcoban.com/2017/01/16/gradientdescent2/",Em chÃ o mn. em tá»± há»c bÃ i Gradient Descent Ä‘áº¿n Ä‘oáº¡n cÃ´ng thá»©c nÃ y thÃ¬ khÃ´ng hiá»ƒu táº¡i sao. mn giáº£i thÃ­ch giÃºp em vá»›i. https://machinelearningcoban.com/2017/01/16/gradientdescent2/,,,"#Q&A, #math",,
"Em chÃ o cáº£ nhÃ !
Em hiá»‡n lÃ m viá»‡c cho má»™t cÃ´ng ty vá» thiáº¿t káº¿ xÃ¢y dá»±ng á»Ÿ nÆ°á»›c ngoÃ i vÃ  cÃ³ há»c thÃªm má»™t Master vá» Data Science nhÆ°ng má»i thá»© vá» DS Ä‘á»u khÃ¡ má»›i vá»›i em, nÃªn muá»‘n há»i cÃ¡c báº­c cao nhÃ¢n trong nhÃ³m nhÆ° sau áº¡:
Má»i ngÆ°á»i cho em há»i cÃ³ ai xá»­ dá»¥ng mÃ´ hÃ¬nh Neural Networks trong Deep learning Ä‘á»ƒ giáº£i bÃ i toÃ¡n tá»‘i Æ°u trong kÄ© thuáº­t khÃ´ng áº¡? Cháº³ng háº¡n, tÃ¬m nghiá»‡m X=(x1,x2,...,xn) sao cho hÃ m f(X) Ä‘áº¡t cá»±c tiá»ƒu. ÄÃ¢y lÃ  bÃ i toÃ¡n tá»‘i Æ°u thuáº§n ToÃ¡n, tuy nhiÃªn láº¡i Ã¡p dá»¥ng nhiá»u trong kÄ© thuáº­t vÃ  thiáº¿t káº¿.
Em cáº£m Æ¡n vÃ  mong má»i ngÆ°á»i cho em xin gÃ³p Ã½!","Em chÃ o cáº£ nhÃ ! Em hiá»‡n lÃ m viá»‡c cho má»™t cÃ´ng ty vá» thiáº¿t káº¿ xÃ¢y dá»±ng á»Ÿ nÆ°á»›c ngoÃ i vÃ  cÃ³ há»c thÃªm má»™t Master vá» Data Science nhÆ°ng má»i thá»© vá» DS Ä‘á»u khÃ¡ má»›i vá»›i em, nÃªn muá»‘n há»i cÃ¡c báº­c cao nhÃ¢n trong nhÃ³m nhÆ° sau áº¡: Má»i ngÆ°á»i cho em há»i cÃ³ ai xá»­ dá»¥ng mÃ´ hÃ¬nh Neural Networks trong Deep learning Ä‘á»ƒ giáº£i bÃ i toÃ¡n tá»‘i Æ°u trong kÄ© thuáº­t khÃ´ng áº¡? Cháº³ng háº¡n, tÃ¬m nghiá»‡m X=(x1,x2,...,xn) sao cho hÃ m f(X) Ä‘áº¡t cá»±c tiá»ƒu. ÄÃ¢y lÃ  bÃ i toÃ¡n tá»‘i Æ°u thuáº§n ToÃ¡n, tuy nhiÃªn láº¡i Ã¡p dá»¥ng nhiá»u trong kÄ© thuáº­t vÃ  thiáº¿t káº¿. Em cáº£m Æ¡n vÃ  mong má»i ngÆ°á»i cho em xin gÃ³p Ã½!",,,"#Q&A, #math",,
"CÃ´ng ty trá»£ lÃ½ áº£o, dÃ¹ng trá»£ lÃ½ áº£o, tuyá»ƒn ngÆ°á»i phÃ¡t triá»ƒn trá»£ lÃ½ áº£oğŸ¥³

LÃ  má»™t Ä‘Æ¡n vá»‹ tiÃªn phong phÃ¡t triá»ƒn chatbot, trá»£ lÃ½ áº£o tháº¿ há»‡ má»›i trÃªn cÃ´ng nghá»‡ ChatGPT táº¡i Viá»‡t Nam, hiá»‡n mindmaid.ai Ä‘ang cÃ³ nhu cáº§u tuyá»ƒn dá»¥ng Thá»±c táº­p sinh Content Marketing & Chatbot Development. Nhiá»‡m vá»¥ chÃ­nh bao gá»“m: nghÄ© vá»›i ChatGPT, viáº¿t vá»›i ChatGPT, chuáº©n bá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n trá»£ lÃ½ áº£o cÅ©ng báº±ng ChatGPT. 

ÄÃ¢y lÃ  vá»‹ trÃ­ Æ°u tiÃªn cho cÃ¡c báº¡n content, tuy nhiÃªn vÃ¬ chuáº©n bá»‹ content cho trá»£ lÃ½ áº£o, nÃªn cÃ´ng ty cÅ©ng muá»‘n Æ°u tiÃªn má»™t sá»‘ suáº¥t cho cÃ¡c báº¡n cÃ³ hiá»ƒu biáº¿t tá»‘t vá» cÃ´ng nghá»‡, AI vÃ  muá»‘n khÃ¡m phÃ¡ lÄ©nh vá»±c trá»£ lÃ½ áº£o nÃ y. 
MÃ´i trÆ°á»ng lÃ m viá»‡c startup nÄƒng Ä‘á»™ng, vÄƒn phÃ²ng khu vá»±c trung tÃ¢m, cÃ´ng cá»¥ lÃ m viá»‡c Lark xá»‹n sÃ², vÃ  Ä‘áº·c biá»‡t lÃ  luÃ´n Ä‘Æ°á»£c há»c há»i vá» nhá»¯ng skill má»›i nháº¥t thÃ´ng qua Growth Day hÃ ng tuáº§n.
Nhá» anh chá»‹ em báº¡n bÃ¨ tháº¥y cÃ³ CV nÃ o phÃ¹ há»£p giá»›i thiá»‡u giÃºp.
ğŸ‘‰ThÃ´ng tin chi tiáº¿t vá» JD, hÃ¬nh thá»©c gá»­i CV...má»i chat trá»±c tiáº¿p vá»›i trá»£ lÃ½ áº£o áº¡: https://aivtuyendung.mindmaid.ai

(p/s: xin phÃ©p ad Ä‘Äƒng lÃªn group vÃ¬ khÃ´ng tÃ¬m tháº¥y post gom Ä‘Äƒng bÃ i tuyá»ƒn dá»¥ng trÃªn nhÃ³m)","CÃ´ng ty trá»£ lÃ½ áº£o, dÃ¹ng trá»£ lÃ½ áº£o, tuyá»ƒn ngÆ°á»i phÃ¡t triá»ƒn trá»£ lÃ½ áº£o LÃ  má»™t Ä‘Æ¡n vá»‹ tiÃªn phong phÃ¡t triá»ƒn chatbot, trá»£ lÃ½ áº£o tháº¿ há»‡ má»›i trÃªn cÃ´ng nghá»‡ ChatGPT táº¡i Viá»‡t Nam, hiá»‡n mindmaid.ai Ä‘ang cÃ³ nhu cáº§u tuyá»ƒn dá»¥ng Thá»±c táº­p sinh Content Marketing & Chatbot Development. Nhiá»‡m vá»¥ chÃ­nh bao gá»“m: nghÄ© vá»›i ChatGPT, viáº¿t vá»›i ChatGPT, chuáº©n bá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n trá»£ lÃ½ áº£o cÅ©ng báº±ng ChatGPT. ÄÃ¢y lÃ  vá»‹ trÃ­ Æ°u tiÃªn cho cÃ¡c báº¡n content, tuy nhiÃªn vÃ¬ chuáº©n bá»‹ content cho trá»£ lÃ½ áº£o, nÃªn cÃ´ng ty cÅ©ng muá»‘n Æ°u tiÃªn má»™t sá»‘ suáº¥t cho cÃ¡c báº¡n cÃ³ hiá»ƒu biáº¿t tá»‘t vá» cÃ´ng nghá»‡, AI vÃ  muá»‘n khÃ¡m phÃ¡ lÄ©nh vá»±c trá»£ lÃ½ áº£o nÃ y. MÃ´i trÆ°á»ng lÃ m viá»‡c startup nÄƒng Ä‘á»™ng, vÄƒn phÃ²ng khu vá»±c trung tÃ¢m, cÃ´ng cá»¥ lÃ m viá»‡c Lark xá»‹n sÃ², vÃ  Ä‘áº·c biá»‡t lÃ  luÃ´n Ä‘Æ°á»£c há»c há»i vá» nhá»¯ng skill má»›i nháº¥t thÃ´ng qua Growth Day hÃ ng tuáº§n. Nhá» anh chá»‹ em báº¡n bÃ¨ tháº¥y cÃ³ CV nÃ o phÃ¹ há»£p giá»›i thiá»‡u giÃºp. ThÃ´ng tin chi tiáº¿t vá» JD, hÃ¬nh thá»©c gá»­i CV...má»i chat trá»±c tiáº¿p vá»›i trá»£ lÃ½ áº£o áº¡: https://aivtuyendung.mindmaid.ai (p/s: xin phÃ©p ad Ä‘Äƒng lÃªn group vÃ¬ khÃ´ng tÃ¬m tháº¥y post gom Ä‘Äƒng bÃ i tuyá»ƒn dá»¥ng trÃªn nhÃ³m)",,,"#sharing, #nlp",,
"Dáº¡ em chÃ o má»i ngÆ°á»i, em lÃ  newbie tá»± há»c vá» ML Ä‘Æ°á»£c vÃ i thÃ¡ng. Em tháº¥y nhiá»u anh chá»‹ khuyÃªn nÃªn lÃ m project trÃªn kaggle, váº­y cá»¥ thá»ƒ lÃ  mÃ¬nh lÃ m nhÆ° tháº¿ nÃ o, cÃ¡c bÆ°á»›c ra sao áº¡? Do em tháº¥y trÃªn kaggle khÃ´ng cÃ³ má»¥c project mÃ  chá»‰ cÃ³ má»¥c dataset vÃ  competition áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p, em xin cáº£m Æ¡n áº¡","Dáº¡ em chÃ o má»i ngÆ°á»i, em lÃ  newbie tá»± há»c vá» ML Ä‘Æ°á»£c vÃ i thÃ¡ng. Em tháº¥y nhiá»u anh chá»‹ khuyÃªn nÃªn lÃ m project trÃªn kaggle, váº­y cá»¥ thá»ƒ lÃ  mÃ¬nh lÃ m nhÆ° tháº¿ nÃ o, cÃ¡c bÆ°á»›c ra sao áº¡? Do em tháº¥y trÃªn kaggle khÃ´ng cÃ³ má»¥c project mÃ  chá»‰ cÃ³ má»¥c dataset vÃ  competition áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p, em xin cáº£m Æ¡n áº¡",,,"#Q&A, #machine_learning",,
"ğŸ”¥ğŸ”¥ğŸ”¥ ğ™ƒğ’Ì£ğ™˜ ğ™™ğ’‚ğ™©ğ’‚ ğ’—ğ™–Ì€ ğ™«ğ’Šğ™šÌ£Ì‚ğ’„ ğ’ğ™–Ì€ğ’ ğ‘«ğ™–ğ’•ğ™–. ğŸ”¥ğŸ”¥ğŸ”¥
Gáº§n Ä‘Ã¢y, trÃªn cÃ¡c cá»™ng Ä‘á»“ng cÃ³ nhiá»u tranh cÃ£i Ã½ kiáº¿n cho ráº±ng â€œÄá»«ng nÃªn há»c data ná»¯a, ngÃ nh data bÃ£o hÃ²a rá»“i, há»c data khÃ´ng xin Ä‘Æ°á»£c viá»‡c Ä‘Ã¢u?â€
Vá»›i quan Ä‘iá»ƒm cá»§a mÃ¬nh, trÆ°á»›c khi quyáº¿t Ä‘á»‹nh há»c hay theo Ä‘uá»•i má»™t ngÃ nh nÃ o Ä‘Ã³ cÃ¡c báº¡n hÃ£y tá»± há»i báº£n thÃ¢n trÆ°á»›c 3 cÃ¢u há»i:
- Cá»¥ thá»ƒ, mÃ¬nh Ä‘ang muá»‘n gÃ¬?
- Má»¥c Ä‘Ã­ch cá»§a viá»‡c há»c nÃ y lÃ  gÃ¬?
- Náº¿u cÃ³ nÃ³ mÃ¬nh sáº½ Ä‘Æ°á»£c nhá»¯ng lá»£i Ã­ch gÃ¬? Náº¿u khÃ´ng cÃ³ nÃ³ mÃ¬nh cÃ³ thá»ƒ sáº½ máº¥t Ä‘i cÆ¡ há»™i gÃ¬?
ğŸ‘‰ Náº¿u cÃ¡c báº¡n cho ráº±ng ngÃ nh data Ä‘Ã£ bÃ£o hÃ²a vÃ  khÃ³ xin viá»‡c thÃ¬ hÃ£y hiá»ƒu nguyÃªn nhÃ¢n táº¡i sao?
1. Hiá»‡n táº¡i, tÃ¬nh hÃ¬nh kinh táº¿ chung Ä‘ang khÃ³ khÄƒn, cÃ¡c doanh nghiá»‡p cÃ²n Ä‘ang lay off, nhiá»u ngÃ nh nghá» khÃ¡c cÅ©ng khÃ³ khÄƒn vÃ  tháº¥t nghiá»‡p khÃ´ng riÃªng gÃ¬ trong lÄ©nh vá»±c data.
2. Thá»±c táº¿ ráº±ng nhu cáº§u tuyá»ƒn dá»¥ng data váº«n ráº¥t lá»›n, cáº¯t giáº£m tuyá»ƒn level tháº¥p táº¡i vÃ¬ doanh nghiá»‡p cáº§n pháº£i tá»‘i Æ°u hÃ³a chi phÃ­, táº­p trung giáº£i quyáº¿t váº¥n Ä‘á» trÆ°á»›c máº¯t nÃªn há» muá»‘n tÃ¬m nhá»¯ng ngÆ°á»i cÃ³ thá»ƒ báº¯t Ä‘áº§u ngay vá»›i cÃ´ng viá»‡c vÃ  táº¡o ra giÃ¡ trá»‹ thay vÃ¬ Ä‘Ã o táº¡o, nuÃ´i dÆ°á»¡ng nguá»“n nhÃ¢n lá»±c má»›i.
- Báº£n cháº¥t cá»§a viá»‡c tuyá»ƒn intern, fresher lÃ  Ä‘áº§u tÆ° chi phÃ­ Ä‘á»ƒ Ä‘Ã o táº¡o con ngÆ°á»i Ä‘á»ƒ Ä‘áº£m báº£o nguá»“n nhÃ¢n lá»±c phÃ¡t triá»ƒn lÃ¢u dÃ i chá»© khÃ´ng pháº£i giáº£i quyáº¿t váº¥n Ä‘á» trÆ°á»›c máº¯t.
- CÃ¡c doanh nghiá»‡p tuyá»ƒn Senior, Leader level lÃ  vÃ¬ Ä‘a sá»‘ doanh nghiá»‡p, lÄ©nh vá»±c Ä‘ang báº¯t Ä‘áº§u á»©ng dá»¥ng vÃ  xÃ¢y dá»±ng data platform cáº§n ngÆ°á»i cÃ³ kinh nghiá»‡m Ä‘á»ƒ báº¯t Ä‘áº§u, thiáº¿t káº¿, vÃ  Ä‘Ã o táº¡o vÃ  Ä‘áº¿n má»™t giai Ä‘oáº¡n nÃ o Ä‘Ã³ khi há»‡ thá»‘ng Ä‘Ã£ phÃ¡t triá»ƒn há» k thá»ƒ mÃ£i tÃ¬m Ä‘Æ°á»£c cÃ¡c DE, DA level cao vÃ¬ náº¿u khÃ´ng Ä‘Ã o táº¡o lá»›p tráº» thÃ¬ sáº½ k cÃ³ cÃ¡c senior tÆ°Æ¡ng lai. VÃ¬ váº­y, sáº½ cÃ³ giai Ä‘oáº¡n, nhu cáº§u tuyá»ƒn dá»¥ng level tháº¥p quay láº¡i nhiá»u hÆ¡nâ€¦ Náº¿u khÃ´ng há»c, khÃ´ng chuáº©n bá»‹ trÆ°á»›c cho tÆ°Æ¡ng lai thÃ¬ lÃ m sao báº¡n náº¯m báº¯t cÃ¡c cÆ¡ há»™i phÃ­ trÆ°á»›c/
ğŸ‘‰ Náº¿u cÃ¡c báº¡n báº£o táº¡i sao yÃªu cáº§u nhÃ  tuyá»ƒn dá»¥ng ngÃ y cÃ ng cao, biáº¿t nhiá»u ká»¹ nÄƒng nhÆ°: SQL, Power BI, Python,... váº«n khÃ´ng Ä‘Æ°á»£c tuyá»ƒn?
1. HÃ£y Ä‘áº·t láº¡i cÃ¢u há»i, táº¡i sao há» pháº£i tuyá»ƒn báº¡n? Báº¡n cÃ³ gÃ¬ Ä‘á»ƒ mang láº¡i giÃ¡ trá»‹ cho cÃ´ng ty há»?
- Báº¡n hÃ£y xem phá»ng váº¥n, tÃ¬m viá»‡c (khÃ´ng pháº£i xin viá»‡c =)) ) lÃ  Ä‘i chá»£, viá»‡c lÃ m, má»©c lÆ°Æ¡ng lÃ  hÃ ng hÃ³a vÃ  tiá»n. Báº¡n Ä‘ang bÃ¡n sá»©c lao Ä‘á»™ng vÃ  giÃ¡ trá»‹ cho cÃ´ng ty nÃªn â€œThuáº­n mua, vá»«a bÃ¡nâ€. Má»©c lÆ°Æ¡ng vÃ  cÃ´ng viá»‡c sáº½ Ä‘i theo quy luáº­t cung cáº§u cá»§a thá»‹ trÆ°á»ng (Ä‘iá»u nÃ y Ä‘Ãºng cho táº¥t cáº£ ngÃ nh nghá»)
- NgÃ nh data ngÃ y cÃ ng hot vÃ¬ má»©c lÆ°Æ¡ng, má»©c Ä‘Ã£i ngá»™ háº¥p dáº«n vá»›i nhiá»u cÆ¡ há»™i phÃ¡t triá»ƒn do váº­y ngÃ y cÃ ng nhiá»u ngÆ°á»i chÃº Ã½ vÃ  há»c vá» Data nÃªn sá»± cáº¡nh tranh sáº½ lÃªn cao. TrÆ°á»›c kia Ã­t ngÆ°á»i há»c, khÃ³ tuyá»ƒn ngÆ°á»i nÃªn yÃªu cáº§u Ä‘Æ¡n giáº£n, bÃ¢y giá» Ä‘Ã£ cÃ³ nhiá»u ngÆ°á»i há»c vÃ  cÃ³ nhá»¯ng ngÆ°á»i cÃ³ tÆ° duy, tÆ° cháº¥t tá»‘t hÆ¡n biáº¿t nhiá»u hÆ¡n thÃ¬ há» cÃ³ quyá»n chá»n ngÆ°á»i tá»‘t hÆ¡n, yÃªu cáº§u cao hÆ¡n chá»©.
2. HÃ£y bá» tÆ° tÆ°á»Ÿng â€œÄƒn xá»•iâ€.
- Báº¡n báº£o báº¡n biáº¿t SQL, BI tools, láº­p trÃ¬nh .. nhÆ°ng báº¡n tháº­t sá»± biáº¿t Ä‘áº¿n Ä‘Ã¢u- thÃ nh tháº¡o Ä‘áº¿n Ä‘Ã¢u? BÃ i Ä‘Äƒng nÃ o cá»§a cÃ¡c báº¡n em cÅ©ng chá»‰ tháº¥y nÃ³i â€œem cÃ³ há»c vÃ  biáº¿t má»™t chÃºtâ€ chá»© k nÃ³i em thÃ nh tháº¡o vÃ  Ä‘Ã£ lÃ m nhá»¯ng dá»± Ã¡n A, B, C vá» SQL, Data warehouse hay BI dashboard.
- Báº¡n hÃ£y quÃªn Ä‘i giáº¥c mÆ¡ há»c 3, 6 thÃ¡ng á»Ÿ khÃ³a há»c ngáº¯n háº¡n vÃ  cháº¯c cháº¯n cÃ³ viá»‡c. CÃ¡c báº¡n há»c 3 -6 thÃ¡ng vÃ  tin theo lá»i quáº£ng cÃ¡o cá»§a trung tÃ¢m lÃ  cháº¯c cháº¯n cÃ³ viá»‡c = )) . HÃ£y suy nghÄ© cÃ¡c báº¡n láº¥y gÃ¬ Ä‘á»ƒ cáº¡nh tranh vá»›i nhá»¯ng báº¡n Ä‘Ã£ há»c 4 nÄƒm Ä‘áº¡i há»c hay ngá»“i há»c ngÃ y há»c Ä‘Ãªm Ä‘á»ƒ nÃ¢ng cao ká»¹ nÄƒng tá»«ng ngÃ y mÃ  chá»‰ tin tÆ°á»Ÿng vÃ  tuáº§n 2 buá»•i há»c trong 3 thÃ¡ng lÃ  giá»i rá»“i, Ä‘i lÃ m tá»‘t rá»“i ..
- Táº¥t nhiá»u má»™t sá»‘ báº¡n, cÃ³ thá»ƒ nÃ³i lÃ  nhiá»u báº¡n xin viá»‡c trong 3 thÃ¡ng , 6 thÃ¡ng, tháº­m chÃ­ lÃ  2 thÃ¡ng há»c vá» data nhÆ°ng Ä‘Ã³ cháº¯c cháº¯n lÃ  nhiá»u sá»± Ä‘Ã¡nh Ä‘á»•i cá»‘ gáº¯ng vÃ  Ä‘Ã´i khi lÃ  may máº¯n náº¯m báº¯t Ä‘Æ°á»£c Ä‘Ãºng cÆ¡ há»™i,..
Nhiá»u báº¡n há»c sinh cá»§a mÃ¬nh Ä‘Ã£ nháº­n Ä‘Æ°á»£c viá»‡c 2 thÃ¡ng, 3 thÃ¡ng há»c (dÃ¹ chÆ°a Ä‘Æ°á»£c há»c Ä‘áº§y Ä‘á»§ kiáº¿n thá»©c nhÆ°ng cÅ©ng cÃ³ nhiá»u báº¡n há»c xong rá»“i nhá»¯ng loay hoay mÃ£i chÆ°a tÃ¬m Ä‘Æ°á»£c cÆ¡ há»™i, MÃ¬nh nháº­n tháº¥y ráº±ng cÃ¡c báº¡n tÃ¬m Ä‘Æ°á»£c viá»‡c sá»›m cÃ³ má»™t sá»‘ lÃ  do cÃ³ tá»‘ cháº¥t tá»‘t hÆ¡n vá» cáº£ hard skill vÃ  soft skill, cÃ³ má»™t sá»‘ chÄƒm chá»‰ hÆ¡n, cá»‘ gáº¯ng nhiá»u hÆ¡n vÃ  Ä‘a sá»‘ lÃ  do may máº¯n gáº·p thá»i Ä‘iá»ƒm tá»‘t hÆ¡n, náº¯m báº¯t Ä‘Æ°á»£c cÆ¡ há»™i =)) vÃ¬ mÃ¬nh dáº¡y vÃ  Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c trÃ¬nh Ä‘á»™i cÃ¡c báº¡n Ä‘Ã´i lÃºc khÃ´ng chÃªnh lá»‡ch nhiá»u tháº­m chÃ­ báº¡n k tÃ¬m Ä‘Æ°á»£c viá»‡c cÃ²n tá»‘t hÆ¡n báº¡n Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c =))
- TÃ¬m viá»‡c lÃ  sá»± phÃ¹ há»£p vs cÃ´ng ty khÃ´ng chá»‰ vá» ká»¹ nÄƒng vÃ  nhiá»u yáº¿u tá»‘ khÃ¡c.
Khi mÃ¬nh tá»‘t nghiá»‡p Ä‘áº¡i há»c, mÃ¬nh tá»± tin cÃ³ má»™t ná»n táº£ng kiáº¿n thá»©c vá»¯ng cháº¯c (mÃ¬nh Ä‘Ã£ skip ráº¥t nhiá»u vá» software Ä‘á»ƒ táº­p trung há»c AI vÃ  Data), mÃ¬nh cÃ³ hÆ¡n 1 nÄƒm nghiÃªn cá»©u táº¡i Lab trÃ­ tuá»‡ nhÃ¢n táº¡o, MÃ¬nh lÃ  first author 1 paper trong há»™i nghá»‹ RANK A, cÃ³ 2 nÄƒm kinh nghiá»‡m part time táº¡i má»™t cÃ´ng ty lá»›n nhÆ°ng mÃ¬nh váº«n â€œBá»Š TRÆ¯á»¢T PHá»NG Váº¤N Vá»Š TRÃ FRESHER Cá»¦A Má»˜T CÃ”NG TY VNâ€ (Ä‘oáº¡n nÃ y khoe chá»‰ lÃ  pháº§n nhá» thÃ´i, pháº§n lá»›n Ä‘á»ƒ cho cÃ¡c báº¡n tháº¥y phÃ¹ há»£p quan trá»ng tháº¿ nÃ o. Náº¿u cÃ³ dá»‹p mÃ¬nh sáº½ chia sáº» vá» láº§n PV trÆ°á»£t áº¥y) bá»Ÿi vÃ¬ táº¡i thá»i Ä‘iá»ƒm áº¥y há» k cáº§n nhá»¯ng ngÆ°á»i lÃ m viá»‡c nhÆ° mÃ¬nh, vÃ  há» cÃ³ nhiá»u option cÃ³ thá»ƒ tá»‘t hÆ¡n, cÃ³ thá»ƒ phÃ¹ há»£p hÆ¡n.
ğŸ‘‰ HÃ£y xÃ¡c Ä‘á»‹nh há»c Ä‘á»ƒ lÃ m gÃ¬? Minh luÃ´n quan Ä‘iá»ƒm há»c Ä‘á»ƒ áº¥m vÃ o thÃ¢n, Ä‘á»ƒ xÃ¢y dá»±ng kiáº¿n thá»©c trÆ°á»›c.
- Náº¿u pháº§n trÃªn nÃ³i Ä‘áº¿n tÆ° tÆ°á»Ÿng Äƒn xá»•i, cÃ³ nhiá»u báº¡n gá»i cho mÃ¬nh vÃ  há»i há»c xong 1 khÃ³a, 2 khÃ³a há»c cá»§a anh em cÃ³ xin viá»‡c khÃ´ng vÃ  mÃ¬nh tráº£ lá»i â€œXin Ä‘Æ°á»£c viá»‡c hay khÃ´ng do sá»± cá»‘ gáº¯ng vÃ  may máº¯n cá»§a báº¡n khÃ´ng pháº£i á»Ÿ mÃ¬nh vÃ  cÃ¡i mÃ¬nh cam káº¿t vÃ  cháº¥t lÆ°á»£ng kiáº¿n thá»©c vÃ  báº¡n cáº£m tháº¥y mÃ¬nh Ä‘ang hiá»ƒu biáº¿t lÃªn, Ä‘ang há»c Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c cÃ³ Ã­ch chá»© MÃŒNH KHÃ”NG BAO GIá»œ CAM Káº¾T VIá»†C LÃ€Mâ€ vÃ  Ä‘áº¿n 90 % cÃ¡c báº¡n tháº¥t vá»ng vÃ  khÃ´ng há»c. MÃ¬nh xin chÃºc cÃ¡c báº¡n â€œmay máº¯n hÆ¡n á»Ÿ má»™t nÆ¡i nÃ o Ä‘Ã³ há» cam káº¿t há»c xong cÃ³ viá»‡câ€
- Táº¡i sao cÃ¡c báº¡n khÃ´ng nghÄ© Ä‘áº¿n viá»‡c há»c Ä‘á»ƒ láº¥y kiáº¿n thá»©c cho báº£n thÃ¢n trÆ°á»›c, rá»“i khi cÃ³ kiáº¿n thá»©c cÃ¡c cÆ¡ há»™i sáº½ tá»± tÃ¬m thá»i vÃ  mÃ¬nh sáº½ khÃ´ng bá» lá»¡ nhá»¯ng cÆ¡ há»™i trong tÆ°Æ¡ng lai?
- Táº¡i sao cÃ¡c báº¡n luÃ´n cÃ³ tÆ° tÆ°á»Ÿng há»c Ä‘á»ƒ chuyá»ƒn má»™t cÃ´ng viá»‡c má»›i sang lÃ m Data luÃ´n mÃ  khÃ´ng nghÄ© Ä‘á»ƒ phá»¥c vá»¥ cho chuyÃªn ngÃ nh, cho cÃ´ng viá»‡c khÃ¡c cá»§a mÃ¬nh sau nÃ y. CÃ¡c báº¡n hÃ£y Ä‘á»ƒ Ã½ thá»i kÃ¬ cÃ´ng nghá»‡ thÃ´ng tin báº¯t Ä‘áº§u bÃ¹ng ná»•, giÃ¡ trá»‹ cá»§a nhá»¯ng ngÆ°á»i Ä‘Ã£ biáº¿t sá»­ dá»¥ng mÃ¡y tÃ­nh, thÃ nh tháº¡o tin há»c vÄƒn phÃ²ng trong CV cao nhÆ° tháº¿ nÃ o vÃ  hiá»‡n táº¡i ai cÅ©ng cáº£m nháº­n rÃµ mÃ¬nh Ä‘ang bÆ°á»›c chÃ¢n vÃ o thá»i ká»³ má»›i lÃ  â€œData Drivenâ€ váº­y nhá»¯ng ngÆ°á»i cÃ³ ká»¹ nÄƒng tá»‘t vá» dá»¯ liá»‡u liá»‡u cÃ³ cÆ¡ há»™i, cÃ³ tháº¿ máº¡nh Ä‘á»ƒ cáº¡nh tranh hÆ¡n trong lÄ©nh vá»±c cá»§a há» hay khÃ´ng?
ThÃ´i viáº¿t dÃ i quÃ¡, má»i tay, Ä‘Ã³i bá»¥ng,... náº¿u cÃ³ cÆ¡ há»™i mÃ¬nh sáº½ chia sáº» sÃ¢u hÆ¡n vá» tá»«ng quan Ä‘iá»ƒm trong bÃ i viáº¿t. Ã€ cÃ³ má»™t váº¥n Ä‘á», mÃ¬nh vá»«a nghÄ© vá»«a gÃµ mÃ¡y sáº½ bá»‹ cÃ¡c lá»—i chÃ­nh táº£ nÃªn cÃ³ gáº·p nhiá»u lá»—i chÃ­nh táº£ xin cÃ¡c báº¡n Ä‘á»«ng cÆ°á»i, vÃ  táº­p trung vÃ o ná»™i dung bÃ i viáº¿t vÃ  cÃ¡c luáº­n Ä‘iá»ƒm mÃ¬nh muá»‘n truyá»n Ä‘áº¡t, cÃ³ ai Ä‘Ã³ Ä‘Ã£ tá»«ng nÃ³i ráº±ng
â€œMá»™t khi Ä‘Ã£ sai chÃ­nh táº£ thÃ¬ má»i láº­p luáº­n Ä‘á»u vÃ´ nghÄ©aâ€ =))","Ì£ Ì€ Ì£Ì‚ Ì€ . Gáº§n Ä‘Ã¢y, trÃªn cÃ¡c cá»™ng Ä‘á»“ng cÃ³ nhiá»u tranh cÃ£i Ã½ kiáº¿n cho ráº±ng â€œÄá»«ng nÃªn há»c data ná»¯a, ngÃ nh data bÃ£o hÃ²a rá»“i, há»c data khÃ´ng xin Ä‘Æ°á»£c viá»‡c Ä‘Ã¢u?â€ Vá»›i quan Ä‘iá»ƒm cá»§a mÃ¬nh, trÆ°á»›c khi quyáº¿t Ä‘á»‹nh há»c hay theo Ä‘uá»•i má»™t ngÃ nh nÃ o Ä‘Ã³ cÃ¡c báº¡n hÃ£y tá»± há»i báº£n thÃ¢n trÆ°á»›c 3 cÃ¢u há»i: - Cá»¥ thá»ƒ, mÃ¬nh Ä‘ang muá»‘n gÃ¬? - Má»¥c Ä‘Ã­ch cá»§a viá»‡c há»c nÃ y lÃ  gÃ¬? - Náº¿u cÃ³ nÃ³ mÃ¬nh sáº½ Ä‘Æ°á»£c nhá»¯ng lá»£i Ã­ch gÃ¬? Náº¿u khÃ´ng cÃ³ nÃ³ mÃ¬nh cÃ³ thá»ƒ sáº½ máº¥t Ä‘i cÆ¡ há»™i gÃ¬? Náº¿u cÃ¡c báº¡n cho ráº±ng ngÃ nh data Ä‘Ã£ bÃ£o hÃ²a vÃ  khÃ³ xin viá»‡c thÃ¬ hÃ£y hiá»ƒu nguyÃªn nhÃ¢n táº¡i sao? 1. Hiá»‡n táº¡i, tÃ¬nh hÃ¬nh kinh táº¿ chung Ä‘ang khÃ³ khÄƒn, cÃ¡c doanh nghiá»‡p cÃ²n Ä‘ang lay off, nhiá»u ngÃ nh nghá» khÃ¡c cÅ©ng khÃ³ khÄƒn vÃ  tháº¥t nghiá»‡p khÃ´ng riÃªng gÃ¬ trong lÄ©nh vá»±c data. 2. Thá»±c táº¿ ráº±ng nhu cáº§u tuyá»ƒn dá»¥ng data váº«n ráº¥t lá»›n, cáº¯t giáº£m tuyá»ƒn level tháº¥p táº¡i vÃ¬ doanh nghiá»‡p cáº§n pháº£i tá»‘i Æ°u hÃ³a chi phÃ­, táº­p trung giáº£i quyáº¿t váº¥n Ä‘á» trÆ°á»›c máº¯t nÃªn há» muá»‘n tÃ¬m nhá»¯ng ngÆ°á»i cÃ³ thá»ƒ báº¯t Ä‘áº§u ngay vá»›i cÃ´ng viá»‡c vÃ  táº¡o ra giÃ¡ trá»‹ thay vÃ¬ Ä‘Ã o táº¡o, nuÃ´i dÆ°á»¡ng nguá»“n nhÃ¢n lá»±c má»›i. - Báº£n cháº¥t cá»§a viá»‡c tuyá»ƒn intern, fresher lÃ  Ä‘áº§u tÆ° chi phÃ­ Ä‘á»ƒ Ä‘Ã o táº¡o con ngÆ°á»i Ä‘á»ƒ Ä‘áº£m báº£o nguá»“n nhÃ¢n lá»±c phÃ¡t triá»ƒn lÃ¢u dÃ i chá»© khÃ´ng pháº£i giáº£i quyáº¿t váº¥n Ä‘á» trÆ°á»›c máº¯t. - CÃ¡c doanh nghiá»‡p tuyá»ƒn Senior, Leader level lÃ  vÃ¬ Ä‘a sá»‘ doanh nghiá»‡p, lÄ©nh vá»±c Ä‘ang báº¯t Ä‘áº§u á»©ng dá»¥ng vÃ  xÃ¢y dá»±ng data platform cáº§n ngÆ°á»i cÃ³ kinh nghiá»‡m Ä‘á»ƒ báº¯t Ä‘áº§u, thiáº¿t káº¿, vÃ  Ä‘Ã o táº¡o vÃ  Ä‘áº¿n má»™t giai Ä‘oáº¡n nÃ o Ä‘Ã³ khi há»‡ thá»‘ng Ä‘Ã£ phÃ¡t triá»ƒn há» k thá»ƒ mÃ£i tÃ¬m Ä‘Æ°á»£c cÃ¡c DE, DA level cao vÃ¬ náº¿u khÃ´ng Ä‘Ã o táº¡o lá»›p tráº» thÃ¬ sáº½ k cÃ³ cÃ¡c senior tÆ°Æ¡ng lai. VÃ¬ váº­y, sáº½ cÃ³ giai Ä‘oáº¡n, nhu cáº§u tuyá»ƒn dá»¥ng level tháº¥p quay láº¡i nhiá»u hÆ¡nâ€¦ Náº¿u khÃ´ng há»c, khÃ´ng chuáº©n bá»‹ trÆ°á»›c cho tÆ°Æ¡ng lai thÃ¬ lÃ m sao báº¡n náº¯m báº¯t cÃ¡c cÆ¡ há»™i phÃ­ trÆ°á»›c/ Náº¿u cÃ¡c báº¡n báº£o táº¡i sao yÃªu cáº§u nhÃ  tuyá»ƒn dá»¥ng ngÃ y cÃ ng cao, biáº¿t nhiá»u ká»¹ nÄƒng nhÆ°: SQL, Power BI, Python,... váº«n khÃ´ng Ä‘Æ°á»£c tuyá»ƒn? 1. HÃ£y Ä‘áº·t láº¡i cÃ¢u há»i, táº¡i sao há» pháº£i tuyá»ƒn báº¡n? Báº¡n cÃ³ gÃ¬ Ä‘á»ƒ mang láº¡i giÃ¡ trá»‹ cho cÃ´ng ty há»? - Báº¡n hÃ£y xem phá»ng váº¥n, tÃ¬m viá»‡c (khÃ´ng pháº£i xin viá»‡c =)) ) lÃ  Ä‘i chá»£, viá»‡c lÃ m, má»©c lÆ°Æ¡ng lÃ  hÃ ng hÃ³a vÃ  tiá»n. Báº¡n Ä‘ang bÃ¡n sá»©c lao Ä‘á»™ng vÃ  giÃ¡ trá»‹ cho cÃ´ng ty nÃªn â€œThuáº­n mua, vá»«a bÃ¡nâ€. Má»©c lÆ°Æ¡ng vÃ  cÃ´ng viá»‡c sáº½ Ä‘i theo quy luáº­t cung cáº§u cá»§a thá»‹ trÆ°á»ng (Ä‘iá»u nÃ y Ä‘Ãºng cho táº¥t cáº£ ngÃ nh nghá») - NgÃ nh data ngÃ y cÃ ng hot vÃ¬ má»©c lÆ°Æ¡ng, má»©c Ä‘Ã£i ngá»™ háº¥p dáº«n vá»›i nhiá»u cÆ¡ há»™i phÃ¡t triá»ƒn do váº­y ngÃ y cÃ ng nhiá»u ngÆ°á»i chÃº Ã½ vÃ  há»c vá» Data nÃªn sá»± cáº¡nh tranh sáº½ lÃªn cao. TrÆ°á»›c kia Ã­t ngÆ°á»i há»c, khÃ³ tuyá»ƒn ngÆ°á»i nÃªn yÃªu cáº§u Ä‘Æ¡n giáº£n, bÃ¢y giá» Ä‘Ã£ cÃ³ nhiá»u ngÆ°á»i há»c vÃ  cÃ³ nhá»¯ng ngÆ°á»i cÃ³ tÆ° duy, tÆ° cháº¥t tá»‘t hÆ¡n biáº¿t nhiá»u hÆ¡n thÃ¬ há» cÃ³ quyá»n chá»n ngÆ°á»i tá»‘t hÆ¡n, yÃªu cáº§u cao hÆ¡n chá»©. 2. HÃ£y bá» tÆ° tÆ°á»Ÿng â€œÄƒn xá»•iâ€. - Báº¡n báº£o báº¡n biáº¿t SQL, BI tools, láº­p trÃ¬nh .. nhÆ°ng báº¡n tháº­t sá»± biáº¿t Ä‘áº¿n Ä‘Ã¢u- thÃ nh tháº¡o Ä‘áº¿n Ä‘Ã¢u? BÃ i Ä‘Äƒng nÃ o cá»§a cÃ¡c báº¡n em cÅ©ng chá»‰ tháº¥y nÃ³i â€œem cÃ³ há»c vÃ  biáº¿t má»™t chÃºtâ€ chá»© k nÃ³i em thÃ nh tháº¡o vÃ  Ä‘Ã£ lÃ m nhá»¯ng dá»± Ã¡n A, B, C vá» SQL, Data warehouse hay BI dashboard. - Báº¡n hÃ£y quÃªn Ä‘i giáº¥c mÆ¡ há»c 3, 6 thÃ¡ng á»Ÿ khÃ³a há»c ngáº¯n háº¡n vÃ  cháº¯c cháº¯n cÃ³ viá»‡c. CÃ¡c báº¡n há»c 3 -6 thÃ¡ng vÃ  tin theo lá»i quáº£ng cÃ¡o cá»§a trung tÃ¢m lÃ  cháº¯c cháº¯n cÃ³ viá»‡c = )) . HÃ£y suy nghÄ© cÃ¡c báº¡n láº¥y gÃ¬ Ä‘á»ƒ cáº¡nh tranh vá»›i nhá»¯ng báº¡n Ä‘Ã£ há»c 4 nÄƒm Ä‘áº¡i há»c hay ngá»“i há»c ngÃ y há»c Ä‘Ãªm Ä‘á»ƒ nÃ¢ng cao ká»¹ nÄƒng tá»«ng ngÃ y mÃ  chá»‰ tin tÆ°á»Ÿng vÃ  tuáº§n 2 buá»•i há»c trong 3 thÃ¡ng lÃ  giá»i rá»“i, Ä‘i lÃ m tá»‘t rá»“i .. - Táº¥t nhiá»u má»™t sá»‘ báº¡n, cÃ³ thá»ƒ nÃ³i lÃ  nhiá»u báº¡n xin viá»‡c trong 3 thÃ¡ng , 6 thÃ¡ng, tháº­m chÃ­ lÃ  2 thÃ¡ng há»c vá» data nhÆ°ng Ä‘Ã³ cháº¯c cháº¯n lÃ  nhiá»u sá»± Ä‘Ã¡nh Ä‘á»•i cá»‘ gáº¯ng vÃ  Ä‘Ã´i khi lÃ  may máº¯n náº¯m báº¯t Ä‘Æ°á»£c Ä‘Ãºng cÆ¡ há»™i,.. Nhiá»u báº¡n há»c sinh cá»§a mÃ¬nh Ä‘Ã£ nháº­n Ä‘Æ°á»£c viá»‡c 2 thÃ¡ng, 3 thÃ¡ng há»c (dÃ¹ chÆ°a Ä‘Æ°á»£c há»c Ä‘áº§y Ä‘á»§ kiáº¿n thá»©c nhÆ°ng cÅ©ng cÃ³ nhiá»u báº¡n há»c xong rá»“i nhá»¯ng loay hoay mÃ£i chÆ°a tÃ¬m Ä‘Æ°á»£c cÆ¡ há»™i, MÃ¬nh nháº­n tháº¥y ráº±ng cÃ¡c báº¡n tÃ¬m Ä‘Æ°á»£c viá»‡c sá»›m cÃ³ má»™t sá»‘ lÃ  do cÃ³ tá»‘ cháº¥t tá»‘t hÆ¡n vá» cáº£ hard skill vÃ  soft skill, cÃ³ má»™t sá»‘ chÄƒm chá»‰ hÆ¡n, cá»‘ gáº¯ng nhiá»u hÆ¡n vÃ  Ä‘a sá»‘ lÃ  do may máº¯n gáº·p thá»i Ä‘iá»ƒm tá»‘t hÆ¡n, náº¯m báº¯t Ä‘Æ°á»£c cÆ¡ há»™i =)) vÃ¬ mÃ¬nh dáº¡y vÃ  Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c trÃ¬nh Ä‘á»™i cÃ¡c báº¡n Ä‘Ã´i lÃºc khÃ´ng chÃªnh lá»‡ch nhiá»u tháº­m chÃ­ báº¡n k tÃ¬m Ä‘Æ°á»£c viá»‡c cÃ²n tá»‘t hÆ¡n báº¡n Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c =)) - TÃ¬m viá»‡c lÃ  sá»± phÃ¹ há»£p vs cÃ´ng ty khÃ´ng chá»‰ vá» ká»¹ nÄƒng vÃ  nhiá»u yáº¿u tá»‘ khÃ¡c. Khi mÃ¬nh tá»‘t nghiá»‡p Ä‘áº¡i há»c, mÃ¬nh tá»± tin cÃ³ má»™t ná»n táº£ng kiáº¿n thá»©c vá»¯ng cháº¯c (mÃ¬nh Ä‘Ã£ skip ráº¥t nhiá»u vá» software Ä‘á»ƒ táº­p trung há»c AI vÃ  Data), mÃ¬nh cÃ³ hÆ¡n 1 nÄƒm nghiÃªn cá»©u táº¡i Lab trÃ­ tuá»‡ nhÃ¢n táº¡o, MÃ¬nh lÃ  first author 1 paper trong há»™i nghá»‹ RANK A, cÃ³ 2 nÄƒm kinh nghiá»‡m part time táº¡i má»™t cÃ´ng ty lá»›n nhÆ°ng mÃ¬nh váº«n â€œBá»Š TRÆ¯á»¢T PHá»NG Váº¤N Vá»Š TRÃ FRESHER Cá»¦A Má»˜T CÃ”NG TY VNâ€ (Ä‘oáº¡n nÃ y khoe chá»‰ lÃ  pháº§n nhá» thÃ´i, pháº§n lá»›n Ä‘á»ƒ cho cÃ¡c báº¡n tháº¥y phÃ¹ há»£p quan trá»ng tháº¿ nÃ o. Náº¿u cÃ³ dá»‹p mÃ¬nh sáº½ chia sáº» vá» láº§n PV trÆ°á»£t áº¥y) bá»Ÿi vÃ¬ táº¡i thá»i Ä‘iá»ƒm áº¥y há» k cáº§n nhá»¯ng ngÆ°á»i lÃ m viá»‡c nhÆ° mÃ¬nh, vÃ  há» cÃ³ nhiá»u option cÃ³ thá»ƒ tá»‘t hÆ¡n, cÃ³ thá»ƒ phÃ¹ há»£p hÆ¡n. HÃ£y xÃ¡c Ä‘á»‹nh há»c Ä‘á»ƒ lÃ m gÃ¬? Minh luÃ´n quan Ä‘iá»ƒm há»c Ä‘á»ƒ áº¥m vÃ o thÃ¢n, Ä‘á»ƒ xÃ¢y dá»±ng kiáº¿n thá»©c trÆ°á»›c. - Náº¿u pháº§n trÃªn nÃ³i Ä‘áº¿n tÆ° tÆ°á»Ÿng Äƒn xá»•i, cÃ³ nhiá»u báº¡n gá»i cho mÃ¬nh vÃ  há»i há»c xong 1 khÃ³a, 2 khÃ³a há»c cá»§a anh em cÃ³ xin viá»‡c khÃ´ng vÃ  mÃ¬nh tráº£ lá»i â€œXin Ä‘Æ°á»£c viá»‡c hay khÃ´ng do sá»± cá»‘ gáº¯ng vÃ  may máº¯n cá»§a báº¡n khÃ´ng pháº£i á»Ÿ mÃ¬nh vÃ  cÃ¡i mÃ¬nh cam káº¿t vÃ  cháº¥t lÆ°á»£ng kiáº¿n thá»©c vÃ  báº¡n cáº£m tháº¥y mÃ¬nh Ä‘ang hiá»ƒu biáº¿t lÃªn, Ä‘ang há»c Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c cÃ³ Ã­ch chá»© MÃŒNH KHÃ”NG BAO GIá»œ CAM Káº¾T VIá»†C LÃ€Mâ€ vÃ  Ä‘áº¿n 90 % cÃ¡c báº¡n tháº¥t vá»ng vÃ  khÃ´ng há»c. MÃ¬nh xin chÃºc cÃ¡c báº¡n â€œmay máº¯n hÆ¡n á»Ÿ má»™t nÆ¡i nÃ o Ä‘Ã³ há» cam káº¿t há»c xong cÃ³ viá»‡câ€ - Táº¡i sao cÃ¡c báº¡n khÃ´ng nghÄ© Ä‘áº¿n viá»‡c há»c Ä‘á»ƒ láº¥y kiáº¿n thá»©c cho báº£n thÃ¢n trÆ°á»›c, rá»“i khi cÃ³ kiáº¿n thá»©c cÃ¡c cÆ¡ há»™i sáº½ tá»± tÃ¬m thá»i vÃ  mÃ¬nh sáº½ khÃ´ng bá» lá»¡ nhá»¯ng cÆ¡ há»™i trong tÆ°Æ¡ng lai? - Táº¡i sao cÃ¡c báº¡n luÃ´n cÃ³ tÆ° tÆ°á»Ÿng há»c Ä‘á»ƒ chuyá»ƒn má»™t cÃ´ng viá»‡c má»›i sang lÃ m Data luÃ´n mÃ  khÃ´ng nghÄ© Ä‘á»ƒ phá»¥c vá»¥ cho chuyÃªn ngÃ nh, cho cÃ´ng viá»‡c khÃ¡c cá»§a mÃ¬nh sau nÃ y. CÃ¡c báº¡n hÃ£y Ä‘á»ƒ Ã½ thá»i kÃ¬ cÃ´ng nghá»‡ thÃ´ng tin báº¯t Ä‘áº§u bÃ¹ng ná»•, giÃ¡ trá»‹ cá»§a nhá»¯ng ngÆ°á»i Ä‘Ã£ biáº¿t sá»­ dá»¥ng mÃ¡y tÃ­nh, thÃ nh tháº¡o tin há»c vÄƒn phÃ²ng trong CV cao nhÆ° tháº¿ nÃ o vÃ  hiá»‡n táº¡i ai cÅ©ng cáº£m nháº­n rÃµ mÃ¬nh Ä‘ang bÆ°á»›c chÃ¢n vÃ o thá»i ká»³ má»›i lÃ  â€œData Drivenâ€ váº­y nhá»¯ng ngÆ°á»i cÃ³ ká»¹ nÄƒng tá»‘t vá» dá»¯ liá»‡u liá»‡u cÃ³ cÆ¡ há»™i, cÃ³ tháº¿ máº¡nh Ä‘á»ƒ cáº¡nh tranh hÆ¡n trong lÄ©nh vá»±c cá»§a há» hay khÃ´ng? ThÃ´i viáº¿t dÃ i quÃ¡, má»i tay, Ä‘Ã³i bá»¥ng,... náº¿u cÃ³ cÆ¡ há»™i mÃ¬nh sáº½ chia sáº» sÃ¢u hÆ¡n vá» tá»«ng quan Ä‘iá»ƒm trong bÃ i viáº¿t. Ã€ cÃ³ má»™t váº¥n Ä‘á», mÃ¬nh vá»«a nghÄ© vá»«a gÃµ mÃ¡y sáº½ bá»‹ cÃ¡c lá»—i chÃ­nh táº£ nÃªn cÃ³ gáº·p nhiá»u lá»—i chÃ­nh táº£ xin cÃ¡c báº¡n Ä‘á»«ng cÆ°á»i, vÃ  táº­p trung vÃ o ná»™i dung bÃ i viáº¿t vÃ  cÃ¡c luáº­n Ä‘iá»ƒm mÃ¬nh muá»‘n truyá»n Ä‘áº¡t, cÃ³ ai Ä‘Ã³ Ä‘Ã£ tá»«ng nÃ³i ráº±ng â€œMá»™t khi Ä‘Ã£ sai chÃ­nh táº£ thÃ¬ má»i láº­p luáº­n Ä‘á»u vÃ´ nghÄ©aâ€ =))",,,"#sharing, #data",,
"Em chÃ o anh chá»‹ trong group,
Em má»›i tÃ¬m hiá»ƒu vá» Machine Learning vÃ  em mong muá»‘n tÃ¬m cuá»‘n sÃ¡ch hoáº·c khoÃ¡ há»c Ä‘á»ƒ cÃ³ thá»ƒ hiá»ƒu rÃµ vá» cÃ¡c thuáº­t toÃ¡n Ä‘áº±ng sau cÃ¡c mÃ´ hÃ¬nh vÃ  cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh phÃ¹ há»£p cho tá»«ng bÃ i toÃ¡n khÃ¡c nhau. Mong Ä‘Æ°á»£c anh chá»‹ giÃºp Ä‘á»¡ cho em áº¡.
Em cáº£m Æ¡n.","Em chÃ o anh chá»‹ trong group, Em má»›i tÃ¬m hiá»ƒu vá» Machine Learning vÃ  em mong muá»‘n tÃ¬m cuá»‘n sÃ¡ch hoáº·c khoÃ¡ há»c Ä‘á»ƒ cÃ³ thá»ƒ hiá»ƒu rÃµ vá» cÃ¡c thuáº­t toÃ¡n Ä‘áº±ng sau cÃ¡c mÃ´ hÃ¬nh vÃ  cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh phÃ¹ há»£p cho tá»«ng bÃ i toÃ¡n khÃ¡c nhau. Mong Ä‘Æ°á»£c anh chá»‹ giÃºp Ä‘á»¡ cho em áº¡. Em cáº£m Æ¡n.",,,"#Q&A, #machine_learning",,
"Thuáº­t toÃ¡n Monte Carlo Tree Search trong AlphaGo.
ChÃ o cÃ¡c báº¡n, mÃ¬nh tÃ¬m tháº¥y má»™t bÃ i viáº¿t khÃ¡ hay vá» thuáº­t toÃ¡n Monte Carlo Tree Search - trÃ¡i tim cá»§a há»‡ thá»‘ng Ä‘Ã¡nh cá» vÃ¢y Alpha Go. MÃ¬nh xin giá»›i thiá»‡u nÃ³ vá»›i cÃ¡c báº¡n, vÃ  tiá»‡n thá»ƒ mÃ¬nh cÅ©ng dá»‹ch nÃ³ ra tiáº¿ng Viá»‡t luÃ´n cho báº¡n nÃ o quan tÃ¢m.
VÃ  kÃ¨m theo cáº£ python code sá»­ dá»¥ng Monte Carlo cho trÃ² cá» vÃ¢y vÃ  tic-tac-toe (cá» caro 3*3).
BÃ i dá»‹ch: https://ngdmau.github.io/Monte-Carlo-Tree-Search/
BÃ i gá»‘c: https://int8.io/monte-carlo-tree-search-beginners-guide/
Link code python:
Cá» vÃ¢y: https://github.com/int8/gomcts
Tic-tac-toe: https://github.com/int8/monte-carlo-tree-search
Xin cáº£m Æ¡n vÃ  chÃºc cÃ¡c báº¡n buá»•i tá»‘i vui váº» ^^.
#python #montecarlo #mcts #alphago #gametheory","Thuáº­t toÃ¡n Monte Carlo Tree Search trong AlphaGo. ChÃ o cÃ¡c báº¡n, mÃ¬nh tÃ¬m tháº¥y má»™t bÃ i viáº¿t khÃ¡ hay vá» thuáº­t toÃ¡n Monte Carlo Tree Search - trÃ¡i tim cá»§a há»‡ thá»‘ng Ä‘Ã¡nh cá» vÃ¢y Alpha Go. MÃ¬nh xin giá»›i thiá»‡u nÃ³ vá»›i cÃ¡c báº¡n, vÃ  tiá»‡n thá»ƒ mÃ¬nh cÅ©ng dá»‹ch nÃ³ ra tiáº¿ng Viá»‡t luÃ´n cho báº¡n nÃ o quan tÃ¢m. VÃ  kÃ¨m theo cáº£ python code sá»­ dá»¥ng Monte Carlo cho trÃ² cá» vÃ¢y vÃ  tic-tac-toe (cá» caro 3*3). BÃ i dá»‹ch: https://ngdmau.github.io/Monte-Carlo-Tree-Search/ BÃ i gá»‘c: https://int8.io/monte-carlo-tree-search-beginners-guide/ Link code python: Cá» vÃ¢y: https://github.com/int8/gomcts Tic-tac-toe: https://github.com/int8/monte-carlo-tree-search Xin cáº£m Æ¡n vÃ  chÃºc cÃ¡c báº¡n buá»•i tá»‘i vui váº» ^^.",#python	#montecarlo	#mcts	#alphago	#gametheory,,"#sharing, #machine_learning",,
"TÃ¡c giáº£ cá»§a ""Effective Pandas"" - anh Matt Harrison - táº·ng sÃ¡ch.
Máº·c dÃ¹ ai cÅ©ng biáº¿t chá»— Ä‘á»ƒ táº£i cuá»‘n sÃ¡ch mÃ¬nh muá»‘n, nhÆ°ng náº¿u Ä‘Æ°á»£c chÃ­nh tÃ¡c giáº£ táº·ng thÃ¬ cáº£m giÃ¡c váº«n ráº¥t khÃ¡c biá»‡t.
CÃ¡c báº¡n lÃ m theo hÆ°á»›ng dáº«n Ä‘á»ƒ Ä‘Æ°á»£c táº·ng sÃ¡ch miá»…n phÃ­ nhÃ©.","TÃ¡c giáº£ cá»§a ""Effective Pandas"" - anh Matt Harrison - táº·ng sÃ¡ch. Máº·c dÃ¹ ai cÅ©ng biáº¿t chá»— Ä‘á»ƒ táº£i cuá»‘n sÃ¡ch mÃ¬nh muá»‘n, nhÆ°ng náº¿u Ä‘Æ°á»£c chÃ­nh tÃ¡c giáº£ táº·ng thÃ¬ cáº£m giÃ¡c váº«n ráº¥t khÃ¡c biá»‡t. CÃ¡c báº¡n lÃ m theo hÆ°á»›ng dáº«n Ä‘á»ƒ Ä‘Æ°á»£c táº·ng sÃ¡ch miá»…n phÃ­ nhÃ©.",,,#sharing,,
"Em 27 tuá»•i dev quÃ¨n Ä‘ang gáº·m quyá»ƒn thÃ¡nh kinh cá»§a anh Tiá»‡p Ä‘á»ƒ chuyá»ƒn viá»‡c.
CÃ´ng nháº­n ngÃ nh khÃ³ voÃ£i máº¥y bÃ¡c áº¡, ko biáº¿t cÃ³ bÃ¡c nÃ o lá»›n lá»›n chia sáº» Ã­t kinh nghiá»‡m tá»± há»c khÃ´ng, em ko cÃ³ background khoa há»c mÃ¡y tÃ­nh theo cÃ³ á»•n hay Ä‘uá»‘i ko á»£.
(em cÃ³ báº±ng Ä‘h máº¡ng mÃ¡y tÃ­nh, cháº£ LQ, dev quÃ¨n cÅ©ng Ã­t dÃ­nh luÃ´n, hjx)
Em cáº£m Æ¡n.","Em 27 tuá»•i dev quÃ¨n Ä‘ang gáº·m quyá»ƒn thÃ¡nh kinh cá»§a anh Tiá»‡p Ä‘á»ƒ chuyá»ƒn viá»‡c. CÃ´ng nháº­n ngÃ nh khÃ³ voÃ£i máº¥y bÃ¡c áº¡, ko biáº¿t cÃ³ bÃ¡c nÃ o lá»›n lá»›n chia sáº» Ã­t kinh nghiá»‡m tá»± há»c khÃ´ng, em ko cÃ³ background khoa há»c mÃ¡y tÃ­nh theo cÃ³ á»•n hay Ä‘uá»‘i ko á»£. (em cÃ³ báº±ng Ä‘h máº¡ng mÃ¡y tÃ­nh, cháº£ LQ, dev quÃ¨n cÅ©ng Ã­t dÃ­nh luÃ´n, hjx) Em cáº£m Æ¡n.",,,"#Q&A, #machine_learning",,
Xin chia sáº» vá»›i má»i ngÆ°á»i má»™t thÆ° viá»‡n hay ho giÃºp tá»‘i Æ°u bá»™ nhá»› khi triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh LLM lÃªn mÃ´i trÆ°á»ng production áº¡ ğŸ˜,Xin chia sáº» vá»›i má»i ngÆ°á»i má»™t thÆ° viá»‡n hay ho giÃºp tá»‘i Æ°u bá»™ nhá»› khi triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh LLM lÃªn mÃ´i trÆ°á»ng production áº¡,,,"#Q&A, #deep_learning",,
"FinGPT: Open-Source Financial LLMs
Cung cáº¥p toÃ n bá»™ quy trÃ¬nh LLM training and finetuning trong lÄ©nh vá»±c tÃ i chÃ­nh.
paper: https://arxiv.org/abs/2306.06031
Code: https://github.com/AI4Finance-Foundation/FinGPT",FinGPT: Open-Source Financial LLMs Cung cáº¥p toÃ n bá»™ quy trÃ¬nh LLM training and finetuning trong lÄ©nh vá»±c tÃ i chÃ­nh. paper: https://arxiv.org/abs/2306.06031 Code: https://github.com/AI4Finance-Foundation/FinGPT,,,"#sharing, #deep_learning",,
"ChÃ o cÃ¡c a/chá»‹ trong group áº¡.
Em má»›i má»c mÃ²i nghiÃªn cá»©u vá» NLP thÃ¬ cÃ³ má»™t tháº¯c máº¯c mong nháº­n Ä‘Æ°á»£c má»™t sá»‘ Ã½ kiáº¿n Ä‘á»ƒ tham kháº£o áº¡:
á» trong quÃ¡ trÃ¬nh preprocess, em cÃ³ tháº¥y lÃ  Ä‘a sá»‘ cÃ¡c há»‡ thá»‘ng sáº½ sá»­ dá»¥ng BPE Ä‘á»ƒ tokenize Ä‘áº§u vÃ o. Tuy nhiÃªn em cÃ³ Ä‘á»c Ä‘Æ°á»£c paper cá»§a PhoBERT (MÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»§a VN) thÃ¬ há» cÃ³ Ä‘á» cáº­p lÃ  há» Ä‘Ã£ WordSegment trÆ°á»›c khi Ã¡p dá»¥ng BPE.
Vá» máº·t trá»±c giÃ¡c thÃ¬ do PhoBERT lÃ  mÃ´ hÃ¬nh Ä‘Æ¡n ngÃ´n ngá»¯ (monolingual) nÃªn viá»‡c segment cÃ¡c tá»«, tá»« ghÃ©p thÃ¬ Ä‘Ãºng lÃ  sáº½ giÃºp Ã­ch ráº¥t nhiá»u cho viá»‡c tokenize Ä‘á»ƒ bá»• trá»£ feature cho cÃ¡c task vá» sau.
Tháº¯c máº¯c cá»§a em lÃ  náº¿u ta cáº§n giáº£i quyáº¿t má»™t bÃ i toÃ¡n Ä‘a ngÃ´n ngá»¯ trong Ä‘Ã³ bao gá»“m ngÃ´n ngá»¯ cÃ¡c unit cá»§a nÃ³ Ä‘Æ°á»£c tÃ¡ch biá»‡t rÃµ rÃ ng nhÆ° English (Whitespace) vÃ  cÃ¡c ngÃ´n ngá»¯ cÃ³ cÃ¡ch biá»ƒu diá»…n khÃ¡c nhÆ° VN (tá»« ghÃ©p) hay JP (ko cÃ³ whitespace) thÃ¬ mÃ¬nh sáº½ preprocess nhÆ° nÃ o áº¡ ?
Em cáº£m Æ¡n a.chá»‹.","ChÃ o cÃ¡c a/chá»‹ trong group áº¡. Em má»›i má»c mÃ²i nghiÃªn cá»©u vá» NLP thÃ¬ cÃ³ má»™t tháº¯c máº¯c mong nháº­n Ä‘Æ°á»£c má»™t sá»‘ Ã½ kiáº¿n Ä‘á»ƒ tham kháº£o áº¡: á» trong quÃ¡ trÃ¬nh preprocess, em cÃ³ tháº¥y lÃ  Ä‘a sá»‘ cÃ¡c há»‡ thá»‘ng sáº½ sá»­ dá»¥ng BPE Ä‘á»ƒ tokenize Ä‘áº§u vÃ o. Tuy nhiÃªn em cÃ³ Ä‘á»c Ä‘Æ°á»£c paper cá»§a PhoBERT (MÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»§a VN) thÃ¬ há» cÃ³ Ä‘á» cáº­p lÃ  há» Ä‘Ã£ WordSegment trÆ°á»›c khi Ã¡p dá»¥ng BPE. Vá» máº·t trá»±c giÃ¡c thÃ¬ do PhoBERT lÃ  mÃ´ hÃ¬nh Ä‘Æ¡n ngÃ´n ngá»¯ (monolingual) nÃªn viá»‡c segment cÃ¡c tá»«, tá»« ghÃ©p thÃ¬ Ä‘Ãºng lÃ  sáº½ giÃºp Ã­ch ráº¥t nhiá»u cho viá»‡c tokenize Ä‘á»ƒ bá»• trá»£ feature cho cÃ¡c task vá» sau. Tháº¯c máº¯c cá»§a em lÃ  náº¿u ta cáº§n giáº£i quyáº¿t má»™t bÃ i toÃ¡n Ä‘a ngÃ´n ngá»¯ trong Ä‘Ã³ bao gá»“m ngÃ´n ngá»¯ cÃ¡c unit cá»§a nÃ³ Ä‘Æ°á»£c tÃ¡ch biá»‡t rÃµ rÃ ng nhÆ° English (Whitespace) vÃ  cÃ¡c ngÃ´n ngá»¯ cÃ³ cÃ¡ch biá»ƒu diá»…n khÃ¡c nhÆ° VN (tá»« ghÃ©p) hay JP (ko cÃ³ whitespace) thÃ¬ mÃ¬nh sáº½ preprocess nhÆ° nÃ o áº¡ ? Em cáº£m Æ¡n a.chá»‹.",,,"#Q&A, #nlp, #deep_learning",,
"Em Ä‘ang cÃ³ 1 váº¥n Ä‘á» nhÆ° nÃ y áº¡, mong Ä‘c giáº£i Ä‘Ã¡p
DÆ°á»›i Ä‘Ã¢y lÃ  2 video em quay láº¡i 2 á»©ng dá»¥ng sá»­ dá»¥ng text-to-speech, bÃªn trÃ¡i lÃ  á»©ng dá»¥ng trÃªn máº¡ng, bÃªn pháº£i lÃ  em tá»± code. ThÆ° viá»‡n e sá»­ dá»¥ng lÃ  gTTS cÃ³ sáºµn cá»§a Python, nhÆ°ng khÃ´ng hiá»ƒu sao nghe nÃ³ khÃ¡ lÃ  Ä‘uá»“i :(
Em cÃ³ chá»‰nh láº¡i tham sá»‘ Ä‘áº§y Ä‘á»§ cá»§a gTTS cho nÃ³ sá»­ dá»¥ng api cá»§a tÃªn miá»n google.com.vn vÃ  ngÃ´n lÃ  vi nhÆ°ng váº«n k Ä‘áº¡t Ä‘Æ°á»£c cháº¥t lÆ°á»£ng cá»§a voice nhÆ° bÃªn pháº£i. Voice cá»§a video bÃªn pháº£i Ä‘Æ°á»£c sá»­ dá»¥ng khÃ¡ nhiá»u, bÃªn J2Team cÅ©ng sá»­ dá»¥ng voice nÃ y mÃ  em khÃ´ng biáº¿t láº¥y Ä‘Ã¢u ra hay lÃ m sao Ä‘áº¡t Ä‘Æ°á»£c, ai cÃ³ kinh nghiá»‡m thÃ¬ giÃºp em vá»›i, em cÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u áº¡","Em Ä‘ang cÃ³ 1 váº¥n Ä‘á» nhÆ° nÃ y áº¡, mong Ä‘c giáº£i Ä‘Ã¡p DÆ°á»›i Ä‘Ã¢y lÃ  2 video em quay láº¡i 2 á»©ng dá»¥ng sá»­ dá»¥ng text-to-speech, bÃªn trÃ¡i lÃ  á»©ng dá»¥ng trÃªn máº¡ng, bÃªn pháº£i lÃ  em tá»± code. ThÆ° viá»‡n e sá»­ dá»¥ng lÃ  gTTS cÃ³ sáºµn cá»§a Python, nhÆ°ng khÃ´ng hiá»ƒu sao nghe nÃ³ khÃ¡ lÃ  Ä‘uá»“i :( Em cÃ³ chá»‰nh láº¡i tham sá»‘ Ä‘áº§y Ä‘á»§ cá»§a gTTS cho nÃ³ sá»­ dá»¥ng api cá»§a tÃªn miá»n google.com.vn vÃ  ngÃ´n lÃ  vi nhÆ°ng váº«n k Ä‘áº¡t Ä‘Æ°á»£c cháº¥t lÆ°á»£ng cá»§a voice nhÆ° bÃªn pháº£i. Voice cá»§a video bÃªn pháº£i Ä‘Æ°á»£c sá»­ dá»¥ng khÃ¡ nhiá»u, bÃªn J2Team cÅ©ng sá»­ dá»¥ng voice nÃ y mÃ  em khÃ´ng biáº¿t láº¥y Ä‘Ã¢u ra hay lÃ m sao Ä‘áº¡t Ä‘Æ°á»£c, ai cÃ³ kinh nghiá»‡m thÃ¬ giÃºp em vá»›i, em cÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u áº¡",,,"#Q&A, #nlp, #python",,
Em xin chia sáº» má»™t bÃ i ngáº¯n vá» a == None vÃ  a is None cho bÃ¡c nÃ o quan tÃ¢m áº¡ ğŸ˜,Em xin chia sáº» má»™t bÃ i ngáº¯n vá» a == None vÃ  a is None cho bÃ¡c nÃ o quan tÃ¢m áº¡,,,"#sharing, #python",,
"ChÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i sáº½ tá»‘t nghiá»‡p vÃ o thÃ¡ng 8 vÃ  Ä‘ang muá»‘n tÃ¬m má»™t job vá» AI Engineer. TrÆ°á»›c Ä‘Ã³ thÃ¬ em Ä‘Ã£ cÃ³ khoáº£ng 9 thÃ¡ng intern vá» CV á»Ÿ Viettel. Má»i ngÆ°á»i cho em há»i lÃ  á»Ÿ HÃ  Ná»™i thÃ¬ cÃ³ nhá»¯ng cÃ´ng ty nÃ o tá»‘t lÃ m vá» AI áº¡?","ChÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i sáº½ tá»‘t nghiá»‡p vÃ o thÃ¡ng 8 vÃ  Ä‘ang muá»‘n tÃ¬m má»™t job vá» AI Engineer. TrÆ°á»›c Ä‘Ã³ thÃ¬ em Ä‘Ã£ cÃ³ khoáº£ng 9 thÃ¡ng intern vá» CV á»Ÿ Viettel. Má»i ngÆ°á»i cho em há»i lÃ  á»Ÿ HÃ  Ná»™i thÃ¬ cÃ³ nhá»¯ng cÃ´ng ty nÃ o tá»‘t lÃ m vá» AI áº¡?",,,"#Q&A, #machine_learning",,
"Giá»‘ng nhÆ° cÃ´ng cá»¥ Warp cá»§a Photoshop, nhÆ°ng máº¡nh máº½ hÆ¡n nhiá»u.
MÃ´ hÃ¬nh AI má»›i nÃ y giÃºp chá»‰nh sá»­a hÃ¬nh áº£nh báº±ng thao tÃ¡c báº¥m vÃ  kÃ©o tháº£ Ä‘Æ¡n giáº£n. Xoay Ä‘á»‘i tÆ°á»£ng cá»§a áº£nh nhÆ° thá»ƒ Ä‘Ã³ lÃ  má»™t mÃ´ hÃ¬nh 3D.
Xem thÃªm:","Giá»‘ng nhÆ° cÃ´ng cá»¥ Warp cá»§a Photoshop, nhÆ°ng máº¡nh máº½ hÆ¡n nhiá»u. MÃ´ hÃ¬nh AI má»›i nÃ y giÃºp chá»‰nh sá»­a hÃ¬nh áº£nh báº±ng thao tÃ¡c báº¥m vÃ  kÃ©o tháº£ Ä‘Æ¡n giáº£n. Xoay Ä‘á»‘i tÆ°á»£ng cá»§a áº£nh nhÆ° thá»ƒ Ä‘Ã³ lÃ  má»™t mÃ´ hÃ¬nh 3D. Xem thÃªm:",,,"#sharing, #cv, #machine_learning",,
"Xin chÃ o táº¥t cáº£ má»i ngÆ°á»i,
TÃ´i muá»‘n mua má»™t cuá»‘n sÃ¡ch Ä‘á»ƒ lÃ m quÃ  báº±ng tiáº¿ng Anh. Nhá»¯ng cuá»‘n sÃ¡ch hay nháº¥t vá» Machine Learning, Deep Learning mÃ  báº¡n cÃ³ thá»ƒ Ä‘á» xuáº¥t lÃ  gÃ¬.
Cáº£m Æ¡n cÃ¡c báº¡n ráº¥t nhiá»u.","Xin chÃ o táº¥t cáº£ má»i ngÆ°á»i, TÃ´i muá»‘n mua má»™t cuá»‘n sÃ¡ch Ä‘á»ƒ lÃ m quÃ  báº±ng tiáº¿ng Anh. Nhá»¯ng cuá»‘n sÃ¡ch hay nháº¥t vá» Machine Learning, Deep Learning mÃ  báº¡n cÃ³ thá»ƒ Ä‘á» xuáº¥t lÃ  gÃ¬. Cáº£m Æ¡n cÃ¡c báº¡n ráº¥t nhiá»u.",,,"#Q&A, #machine_learning",,
ChÃ o mn áº¡. MÃ¬nh tá»‘t nghiá»‡p Ä‘áº¡i há»c BÃ¡ch khoa HÃ  ná»™i chuyÃªn ngÃ nh CÆ¡ Ä‘iá»‡n tá»­. MÃ¬nh Ä‘á»‹nh hÆ°á»›ng chuyÃªn sÃ¢u máº£ng robotics and Al. MÃ¬nh Ä‘ang muá»‘n tÃ¬m job intern/fresher vá» Al á»Ÿ HÃ  ná»™i. Cáº£m Æ¡n mn áº¡,ChÃ o mn áº¡. MÃ¬nh tá»‘t nghiá»‡p Ä‘áº¡i há»c BÃ¡ch khoa HÃ  ná»™i chuyÃªn ngÃ nh CÆ¡ Ä‘iá»‡n tá»­. MÃ¬nh Ä‘á»‹nh hÆ°á»›ng chuyÃªn sÃ¢u máº£ng robotics and Al. MÃ¬nh Ä‘ang muá»‘n tÃ¬m job intern/fresher vá» Al á»Ÿ HÃ  ná»™i. Cáº£m Æ¡n mn áº¡,,,"#Q&A, #machine_learning",,
"Em chÃ o anh chá»‹ trong nhÃ³m áº¡. Hiá»‡n em Ä‘Ã£ tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i chuyÃªn ngÃ nh CÆ  Ä‘iá»‡n tá»­, em Ä‘ang tÃ¬m viá»‡c Intern/fresher vá» Al táº¡i HÃ  Ná»™i. KhÃ´ng biáº¿t anh/chá»‹ á»Ÿ cÃ´ng ty nÃ o cÃ³ cÃ²n open cho vá»‹ trÃ­ Intern/fresher khÃ´ng áº¡?","Em chÃ o anh chá»‹ trong nhÃ³m áº¡. Hiá»‡n em Ä‘Ã£ tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i chuyÃªn ngÃ nh CÆ  Ä‘iá»‡n tá»­, em Ä‘ang tÃ¬m viá»‡c Intern/fresher vá» Al táº¡i HÃ  Ná»™i. KhÃ´ng biáº¿t anh/chá»‹ á»Ÿ cÃ´ng ty nÃ o cÃ³ cÃ²n open cho vá»‹ trÃ­ Intern/fresher khÃ´ng áº¡?",,,"#Q&A, #machine_learning",,
"[ GÃ³c INTERN ]
ChÃ o má»i ngÆ°á»i
Em sinh viÃªn nÄƒm cuá»‘i táº¡i HCM ngÃ nh Ä‘iá»‡n tá»­ cÃ´ng nghiá»‡p
CÃ³ kiáº¿n thá»©c vá» Machine learning,Deep learning, Neutral Network.
Image Processing vÃ  cÃ¡c framework AI tensor flow, Numpy, keras.....
Má»™t sá»‘ project vá» sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n á»©ng dá»¥ng vÃ o há»‡ thá»‘ng nhÃºng chá»§ yáº¿u lÃ  cÃ¡c váº¥n Ä‘á» nháº­n diá»‡n ( nháº­n diá»‡n khuÃ´n máº·t Ä‘á»ƒ má»Ÿ cá»­a, nháº­n diá»‡n biá»ƒn sá»‘ xe, nháº­n diá»‡n khuÃ´n máº·t Ä‘eo kháº©u trang...)
Em mong muá»‘n tÃ¬m cÃ´ng viá»‡c internship táº¡i HCM áº¡","[ GÃ³c INTERN ] ChÃ o má»i ngÆ°á»i Em sinh viÃªn nÄƒm cuá»‘i táº¡i HCM ngÃ nh Ä‘iá»‡n tá»­ cÃ´ng nghiá»‡p CÃ³ kiáº¿n thá»©c vá» Machine learning,Deep learning, Neutral Network. Image Processing vÃ  cÃ¡c framework AI tensor flow, Numpy, keras..... Má»™t sá»‘ project vá» sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n á»©ng dá»¥ng vÃ o há»‡ thá»‘ng nhÃºng chá»§ yáº¿u lÃ  cÃ¡c váº¥n Ä‘á» nháº­n diá»‡n ( nháº­n diá»‡n khuÃ´n máº·t Ä‘á»ƒ má»Ÿ cá»­a, nháº­n diá»‡n biá»ƒn sá»‘ xe, nháº­n diá»‡n khuÃ´n máº·t Ä‘eo kháº©u trang...) Em mong muá»‘n tÃ¬m cÃ´ng viá»‡c internship táº¡i HCM áº¡",,,"#Q&A, #machine_learning",,
"[Nhá» trá»£ giÃºp]
ChÃ o cÃ¡c bÃ¡c, vÃ­ dá»¥ cÃ³ 1 text nhÆ° nÃ y ""tÃ´iÄ‘anghá»ibáº¡n"", bá»‹ lá»—i dÃ­nh chá»¯, máº¥t dáº¥u cÃ¡ch. CÃ³ thÆ° viá»‡n nÃ o cÃ³ thá»ƒ sá»­a Ä‘Æ°á»£c cÃ¢u trÃªn thÃ nh cÃ¢u hoÃ n chá»‰nh khÃ´ng áº¡? # output: ""tÃ´i Ä‘ang há»i báº¡n"".
Náº¿u chuá»—i lÃ  tiáº¿ng Anh thÃ¬ lÃ m Ä‘Æ°á»£c, cÃ²n tiáº¿ng Viá»‡t thÃ¬ em chÆ°a biáº¿t cÃ¡ch nÃ o.ğŸ¥²","[Nhá» trá»£ giÃºp] ChÃ o cÃ¡c bÃ¡c, vÃ­ dá»¥ cÃ³ 1 text nhÆ° nÃ y ""tÃ´iÄ‘anghá»ibáº¡n"", bá»‹ lá»—i dÃ­nh chá»¯, máº¥t dáº¥u cÃ¡ch. CÃ³ thÆ° viá»‡n nÃ o cÃ³ thá»ƒ sá»­a Ä‘Æ°á»£c cÃ¢u trÃªn thÃ nh cÃ¢u hoÃ n chá»‰nh khÃ´ng áº¡? # output: ""tÃ´i Ä‘ang há»i báº¡n"". Náº¿u chuá»—i lÃ  tiáº¿ng Anh thÃ¬ lÃ m Ä‘Æ°á»£c, cÃ²n tiáº¿ng Viá»‡t thÃ¬ em chÆ°a biáº¿t cÃ¡ch nÃ o.",,,"#Q&A,  #data",,
"Em chÃ o anh/chá»‹ áº¡. Hiá»‡n táº¡i em má»›i tá»‘t nghiá»‡p vÃ  Ä‘ang mong muá»‘n tÃ¬m viá»‡c Fresher/Intern AI hoáº·c liÃªn quan tá»›i Data táº¡i HÃ  Ná»™i áº¡.
Anh/chá»‹ Ä‘ang tuyá»ƒn thÃ¬ cho em xin JD vá»›i áº¡ hoáº·c em sáº½ inbox gá»­i CV áº¡.",Em chÃ o anh/chá»‹ áº¡. Hiá»‡n táº¡i em má»›i tá»‘t nghiá»‡p vÃ  Ä‘ang mong muá»‘n tÃ¬m viá»‡c Fresher/Intern AI hoáº·c liÃªn quan tá»›i Data táº¡i HÃ  Ná»™i áº¡. Anh/chá»‹ Ä‘ang tuyá»ƒn thÃ¬ cho em xin JD vá»›i áº¡ hoáº·c em sáº½ inbox gá»­i CV áº¡.,,,"#Q&A, #machine_learning, #data",,
"Em chÃ o cÃ¡c anh chá»‹ áº¡
Em Ä‘ang lÃ  sinh viÃªn nÄƒm 2 em cÃ³ Ä‘á»‹nh hÆ°á»›ng muá»‘n theo AI nhÆ°ng khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u, anh/chá»‹ cÃ³ thá»ƒ cho em xin roadmap Ä‘Æ°á»£c khÃ´ng áº¡?Em cáº£m Æ¡n áº¡","Em chÃ o cÃ¡c anh chá»‹ áº¡ Em Ä‘ang lÃ  sinh viÃªn nÄƒm 2 em cÃ³ Ä‘á»‹nh hÆ°á»›ng muá»‘n theo AI nhÆ°ng khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u, anh/chá»‹ cÃ³ thá»ƒ cho em xin roadmap Ä‘Æ°á»£c khÃ´ng áº¡?Em cáº£m Æ¡n áº¡",,,"#Q&A, #machine_learning",,
"GÃ³c tÃ¬m Ä‘á»“ng Ä‘á»™i tham gia Team dá»± cuá»™c thi ""The 4th Annual International Competition in Data Science & Artificial Intelligence""
ChÃ o cÃ¡c báº¡n, tá»« 01/7/2023 ~ 31/8/2023 ISODS, USA tá»• chá»©c cuá»™c thi quá»‘c táº¿ dÃ nh cho sinh viÃªn, nghiÃªn cá»©u viÃªn vá» ná»™i dung Data Science & Artificial Intelligence.
NhÃ³m mÃ¬nh cáº§n tÃ¬m 05 thÃ nh viÃªn tham gia Team, náº¿u báº¡n nÃ o tháº¥y yÃªu thÃ­ch, phÃ¹ há»£p thÃ¬ gá»­i CV mÃ´ táº£ nÄƒng lá»±c vÃ  kinh nghiá»‡m liÃªn quan qua email cho mÃ¬nh nhÃ©.
Háº¡n nháº­n Email: 25/06/2023.
TiÃªu chÃ­:
- CÃ³ kinh nghiá»‡m, ká»¹ nÄƒng láº­p trÃ¬nh liÃªn quan Ä‘áº¿n Data science, Machine learning, Deep learning vÃ  Computer vision.
- TÆ° duy thuáº­t toÃ¡n tá»‘t.
- Æ¯u tiÃªn cÃ¡c báº¡n sinh viÃªn nÄƒm 4.
Quyá»n lá»£i:
- LÃ m viá»‡c, cá»™ng tÃ¡c vá»›i nhá»¯ng báº¡n cÃ³ kinh nghiá»‡m trong lÄ©nh vá»±c liÃªn quan.
- Nhá»¯ng báº¡n phÃ¹ há»£p, Ä‘Ã¡p á»©ng nÄƒng lá»±c sáº½ Ä‘Æ°á»£c nháº­n há»c bá»•ng toÃ n pháº§n Master/PhD táº¡i Lab cá»§a mÃ¬nh táº¡i trÆ°á»ng Äáº¡i há»c Kyonggi, HÃ n Quá»‘c. Báº¯t Ä‘áº§u há»c vÃ o ká»³ mÃ¹a XuÃ¢n, thÃ¡ng 3/2024.
- TÃ­ch lÅ©y kinh nghiá»‡m, há»“ sÆ¡ xin há»c bá»•ng Master/PhD táº¡i nÆ°á»›c ngoÃ i.
CÃ¡c thÃ´ng tin liÃªn quan:
Website vá» cuá»™c thi: http://isods.org/
Website cá»§a Lab: http://ctrl.kyonggi.ac.kr/
Email cá»§a mÃ¬nh: phamdinhlam@kgu.ac.kr
Cáº£m Æ¡n Admin Ä‘Ã£ duyá»‡t bÃ i!","GÃ³c tÃ¬m Ä‘á»“ng Ä‘á»™i tham gia Team dá»± cuá»™c thi ""The 4th Annual International Competition in Data Science & Artificial Intelligence"" ChÃ o cÃ¡c báº¡n, tá»« 01/7/2023 ~ 31/8/2023 ISODS, USA tá»• chá»©c cuá»™c thi quá»‘c táº¿ dÃ nh cho sinh viÃªn, nghiÃªn cá»©u viÃªn vá» ná»™i dung Data Science & Artificial Intelligence. NhÃ³m mÃ¬nh cáº§n tÃ¬m 05 thÃ nh viÃªn tham gia Team, náº¿u báº¡n nÃ o tháº¥y yÃªu thÃ­ch, phÃ¹ há»£p thÃ¬ gá»­i CV mÃ´ táº£ nÄƒng lá»±c vÃ  kinh nghiá»‡m liÃªn quan qua email cho mÃ¬nh nhÃ©. Háº¡n nháº­n Email: 25/06/2023. TiÃªu chÃ­: - CÃ³ kinh nghiá»‡m, ká»¹ nÄƒng láº­p trÃ¬nh liÃªn quan Ä‘áº¿n Data science, Machine learning, Deep learning vÃ  Computer vision. - TÆ° duy thuáº­t toÃ¡n tá»‘t. - Æ¯u tiÃªn cÃ¡c báº¡n sinh viÃªn nÄƒm 4. Quyá»n lá»£i: - LÃ m viá»‡c, cá»™ng tÃ¡c vá»›i nhá»¯ng báº¡n cÃ³ kinh nghiá»‡m trong lÄ©nh vá»±c liÃªn quan. - Nhá»¯ng báº¡n phÃ¹ há»£p, Ä‘Ã¡p á»©ng nÄƒng lá»±c sáº½ Ä‘Æ°á»£c nháº­n há»c bá»•ng toÃ n pháº§n Master/PhD táº¡i Lab cá»§a mÃ¬nh táº¡i trÆ°á»ng Äáº¡i há»c Kyonggi, HÃ n Quá»‘c. Báº¯t Ä‘áº§u há»c vÃ o ká»³ mÃ¹a XuÃ¢n, thÃ¡ng 3/2024. - TÃ­ch lÅ©y kinh nghiá»‡m, há»“ sÆ¡ xin há»c bá»•ng Master/PhD táº¡i nÆ°á»›c ngoÃ i. CÃ¡c thÃ´ng tin liÃªn quan: Website vá» cuá»™c thi: http://isods.org/ Website cá»§a Lab: http://ctrl.kyonggi.ac.kr/ Email cá»§a mÃ¬nh: phamdinhlam@kgu.ac.kr Cáº£m Æ¡n Admin Ä‘Ã£ duyá»‡t bÃ i!",,,"#sharing, #machine_learning",,
"ChÃ o má»i ngÆ°á»i, má»™t ngÆ°á»i quen cá»§a em cáº§n trá»£ giÃºp cho viá»‡c thá»­ nghiá»‡m cÃ¡c ká»¹ thuáº­t há»c mÃ¡y trÃªn táº­p dá»¯ liá»‡u kinh táº¿, táº¥t nhiÃªn lÃ  cÃ³ tráº£ phÃ­ áº¡.
Dá»¯ liá»‡u bao gá»“m: (1) time series tabular dataset, cÃ¡c cá»™t Ä‘áº·c trÆ°ng bao gá»“m Ä‘áº·c trÆ°ng sá»‘ thá»±c vÃ  Ä‘áº·c trÆ°ng háº¡ng má»¥c, dáº·c trÆ°ng cÃ³ dáº¡ng sai phÃ¢n so vá»›i ""cÃ¹ng ká»³ nÄƒm xxx"", dáº¡ng tá»· lá»‡ so vá»›i ""cÃ¹ng ká»³ nÄƒm xxx""; (2) dá»¯ liá»‡u binary thá»ƒ hiá»‡n sá»± xuáº¥t hiá»‡n cá»§a keyword vá» kinh táº¿ táº¡i má»—i má»‘c thá»i gian. CÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c phÃ¢n vá» nhiá»u nhÃ³m vÃ  giá»¯a cÃ¡c nhÃ³m cÃ³ thá»ƒ cÃ³ sai khÃ¡c vá» má»‘c thá»i gian thá»±c hiá»‡n phÃ©p Ä‘o, sai khÃ¡c vá» chu ká»³ thá»±c hiá»‡n phÃ©p Ä‘o; cÃ³ thá»ƒ cÃ³ missing value trong cÃ¡c nhÃ³m Ä‘áº·c trÆ°ng.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c áº¡.","ChÃ o má»i ngÆ°á»i, má»™t ngÆ°á»i quen cá»§a em cáº§n trá»£ giÃºp cho viá»‡c thá»­ nghiá»‡m cÃ¡c ká»¹ thuáº­t há»c mÃ¡y trÃªn táº­p dá»¯ liá»‡u kinh táº¿, táº¥t nhiÃªn lÃ  cÃ³ tráº£ phÃ­ áº¡. Dá»¯ liá»‡u bao gá»“m: (1) time series tabular dataset, cÃ¡c cá»™t Ä‘áº·c trÆ°ng bao gá»“m Ä‘áº·c trÆ°ng sá»‘ thá»±c vÃ  Ä‘áº·c trÆ°ng háº¡ng má»¥c, dáº·c trÆ°ng cÃ³ dáº¡ng sai phÃ¢n so vá»›i ""cÃ¹ng ká»³ nÄƒm xxx"", dáº¡ng tá»· lá»‡ so vá»›i ""cÃ¹ng ká»³ nÄƒm xxx""; (2) dá»¯ liá»‡u binary thá»ƒ hiá»‡n sá»± xuáº¥t hiá»‡n cá»§a keyword vá» kinh táº¿ táº¡i má»—i má»‘c thá»i gian. CÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c phÃ¢n vá» nhiá»u nhÃ³m vÃ  giá»¯a cÃ¡c nhÃ³m cÃ³ thá»ƒ cÃ³ sai khÃ¡c vá» má»‘c thá»i gian thá»±c hiá»‡n phÃ©p Ä‘o, sai khÃ¡c vá» chu ká»³ thá»±c hiá»‡n phÃ©p Ä‘o; cÃ³ thá»ƒ cÃ³ missing value trong cÃ¡c nhÃ³m Ä‘áº·c trÆ°ng. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c áº¡.",,,"#sharing, #machine_learning",,
"CÃ¡c bÃ¡c giÃºp em vá»›i áº¡!
Em Ä‘ang dÃ¹ng thá»­ VNCORENLP cho bÃ i toÃ¡n ner áº¡ , váº¥n Ä‘á» lÃ  vÄƒn báº£n pháº£i Ä‘Æ°á»£c chuáº©n hÃ³a(viáº¿t hoa tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm,...) thÃ¬ má»›i phÃ¡t huy Ä‘Æ°á»£c áº¡ cÃ²n Ä‘á»ƒ táº¥t cÃ²n Ä‘á»ƒ á»Ÿ chá»¯ thÆ°á»ng thÃ¬ gáº§n nhÆ° lÃ  khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c gÃ¬ áº¡ :(
CÃ¡c bÃ¡c cÃ³ model nÃ o Ä‘á»ƒ chuáº©n hÃ³a tiáº¿ng viá»‡t khÃ´ng áº¡ ,giá»›i thiá»‡u em vá»›i áº¡ !
Em cáº£m Æ¡n","CÃ¡c bÃ¡c giÃºp em vá»›i áº¡! Em Ä‘ang dÃ¹ng thá»­ VNCORENLP cho bÃ i toÃ¡n ner áº¡ , váº¥n Ä‘á» lÃ  vÄƒn báº£n pháº£i Ä‘Æ°á»£c chuáº©n hÃ³a(viáº¿t hoa tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm,...) thÃ¬ má»›i phÃ¡t huy Ä‘Æ°á»£c áº¡ cÃ²n Ä‘á»ƒ táº¥t cÃ²n Ä‘á»ƒ á»Ÿ chá»¯ thÆ°á»ng thÃ¬ gáº§n nhÆ° lÃ  khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c gÃ¬ áº¡ :( CÃ¡c bÃ¡c cÃ³ model nÃ o Ä‘á»ƒ chuáº©n hÃ³a tiáº¿ng viá»‡t khÃ´ng áº¡ ,giá»›i thiá»‡u em vá»›i áº¡ ! Em cáº£m Æ¡n",,,"#Q&A, #nlp, #data",,
"Giá»‘ng nhÆ° cÃ¢y bÃºt cáº§n pháº£i Ä‘á»c ráº¥t nhiá»u truyá»‡n Ä‘á»ƒ trá»Ÿ thÃ nh má»™t â€œtÃ i nÄƒng ká»ƒ chuyá»‡nâ€, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cáº§n pháº£i Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t lÆ°á»£ng lá»›n vÄƒn báº£n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± thÃ nh thá»¥c. CÃ ng Ä‘á»c vÃ  há»c nhiá»u, chÃºng cÃ ng hiá»ƒu vÃ  sinh ra ngÃ´n ngá»¯ tá»‘t hÆ¡n.","Giá»‘ng nhÆ° cÃ¢y bÃºt cáº§n pháº£i Ä‘á»c ráº¥t nhiá»u truyá»‡n Ä‘á»ƒ trá»Ÿ thÃ nh má»™t â€œtÃ i nÄƒng ká»ƒ chuyá»‡nâ€, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cáº§n pháº£i Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t lÆ°á»£ng lá»›n vÄƒn báº£n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± thÃ nh thá»¥c. CÃ ng Ä‘á»c vÃ  há»c nhiá»u, chÃºng cÃ ng hiá»ƒu vÃ  sinh ra ngÃ´n ngá»¯ tá»‘t hÆ¡n.",,,"#sharing, #nlp",,
"ChÃ o má»i ngÆ°á»i!
Sau 1 tuáº§n nháº­n Ä‘Æ°á»£c ráº¥t nhiá»u feedback tá»« má»i ngÆ°á»i, Ä‘áº·c biá»‡t lÃ  tá»« má»™t sá»‘ báº¡n cÃ³ háº¡n cháº¿ vá» GPU, team Ä‘Ã£ convert thÃ nh cÃ´ng Vietcuna sang C++ vá»›i thÆ° viá»‡n GGML vÃ  cháº¡y trÃªn CPU chá»‰ vá»›i 3GB RAM.
Má»i ngÆ°á»i cÃ³ thá»ƒ táº£i model C++ táº¡i Ä‘Ã¢y
Báº£n quantized (4bit): https://huggingface.co/vilm/vietcuna-3b-ggml-fp16-q4_0
Báº£n non-quantized: https://huggingface.co/vilm/vietcuna-3b-ggml-fp16
NgoÃ i ra phiÃªn báº£n 7B dá»± kiáº¿n sáº½ sá»›m Ä‘Æ°á»£c phÃ¡t hÃ nh.
https://github.com/vilm-ai/vietcuna.cpp","ChÃ o má»i ngÆ°á»i! Sau 1 tuáº§n nháº­n Ä‘Æ°á»£c ráº¥t nhiá»u feedback tá»« má»i ngÆ°á»i, Ä‘áº·c biá»‡t lÃ  tá»« má»™t sá»‘ báº¡n cÃ³ háº¡n cháº¿ vá» GPU, team Ä‘Ã£ convert thÃ nh cÃ´ng Vietcuna sang C++ vá»›i thÆ° viá»‡n GGML vÃ  cháº¡y trÃªn CPU chá»‰ vá»›i 3GB RAM. Má»i ngÆ°á»i cÃ³ thá»ƒ táº£i model C++ táº¡i Ä‘Ã¢y Báº£n quantized (4bit): https://huggingface.co/vilm/vietcuna-3b-ggml-fp16-q4_0 Báº£n non-quantized: https://huggingface.co/vilm/vietcuna-3b-ggml-fp16 NgoÃ i ra phiÃªn báº£n 7B dá»± kiáº¿n sáº½ sá»›m Ä‘Æ°á»£c phÃ¡t hÃ nh. https://github.com/vilm-ai/vietcuna.cpp",,,#sharing,,
"Em chÃ o má»i ngÆ°á»i áº¡.Em lÃ  sv nÄƒm 2 má»›i cháº­p chá»¯ng bÆ°á»›c vÃ o ML vÃ  mong muá»‘n hÆ°á»›ng Ä‘áº¿n sau nÃ y lÃ  ML engineer.Tuy má»›i bÆ°á»›c Ä‘áº§u vÃ  trÃ¬nh Ä‘á»™ cháº³ng báº±ng ai nhÆ°ng em cÃ³ Ä‘am mÃª lá»›n vs ML cÅ©ng nhÆ° AI áº¡.Em Ä‘ang tá»± há»c vÃ  tÃ¬m hiá»ƒu qua blog cá»§a anh Tiá»‡p,nhÆ°ng mÃ  em cÅ©ng muá»‘n cÃ y láº¡i cÄƒn báº£n tá»« Ä‘áº§u lá»™ trÃ¬nh Ä‘á»ƒ hÆ°á»›ng Ä‘áº¿n AI engineer báº±ng cÃ¡ch tham gia cÃ¡c khoÃ¡ há»c trÃªn máº¡ng cá»§a coursera,udemy â€¦
VÃ¬ má»›i cháº­p chá»¯ng nháº­p mÃ´n nÃªn em ráº¥t mÆ¡ há»“ vÃ  k rÃµ lá»™ trÃ¬nh cÅ©ng nhÆ° thá»© tá»± cÃ¡c khoÃ¡ há»c mÃ  mÃ¬nh nÃªn focus ğŸ˜ LÃ m phiá»n anh/chá»‹,cÅ©ng nhÆ° cÃ´/chÃº cÃ³ thá»ƒ chá»‰ giÃºp em 1 lá»™ trÃ¬nh vÃ  cÃ¡c khoÃ¡ há»c tá»« cÄƒn báº£n Ä‘áº¿n nÃ¢ng cao k áº¡.
Tá»« 1 Ä‘á»©a cháº³ng cÃ³ gÃ¬,em mong muá»‘n Ä‘c sá»‘ng vs Ä‘am mÃª vÃ  táº¡o ra 1 giÃ¡ trá»‹ gÃ¬ Ä‘Ã³ dÃ¹ em biáº¿t AI lÃ  1 trÆ°á»ng phÃ¡i ráº¥t ráº¥t khÃ³ vÃ  Ä‘Ã²i há»i 1 quÃ¡ trÃ¬nh chÄƒm chá»‰ lÃ¢u dÃ i,nhÆ°ng em sáº½ cá»‘ háº¿t sá»©c cÃ³ thá»ƒ áº¡!
Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u!!","Em chÃ o má»i ngÆ°á»i áº¡.Em lÃ  sv nÄƒm 2 má»›i cháº­p chá»¯ng bÆ°á»›c vÃ o ML vÃ  mong muá»‘n hÆ°á»›ng Ä‘áº¿n sau nÃ y lÃ  ML engineer.Tuy má»›i bÆ°á»›c Ä‘áº§u vÃ  trÃ¬nh Ä‘á»™ cháº³ng báº±ng ai nhÆ°ng em cÃ³ Ä‘am mÃª lá»›n vs ML cÅ©ng nhÆ° AI áº¡.Em Ä‘ang tá»± há»c vÃ  tÃ¬m hiá»ƒu qua blog cá»§a anh Tiá»‡p,nhÆ°ng mÃ  em cÅ©ng muá»‘n cÃ y láº¡i cÄƒn báº£n tá»« Ä‘áº§u lá»™ trÃ¬nh Ä‘á»ƒ hÆ°á»›ng Ä‘áº¿n AI engineer báº±ng cÃ¡ch tham gia cÃ¡c khoÃ¡ há»c trÃªn máº¡ng cá»§a coursera,udemy â€¦ VÃ¬ má»›i cháº­p chá»¯ng nháº­p mÃ´n nÃªn em ráº¥t mÆ¡ há»“ vÃ  k rÃµ lá»™ trÃ¬nh cÅ©ng nhÆ° thá»© tá»± cÃ¡c khoÃ¡ há»c mÃ  mÃ¬nh nÃªn focus LÃ m phiá»n anh/chá»‹,cÅ©ng nhÆ° cÃ´/chÃº cÃ³ thá»ƒ chá»‰ giÃºp em 1 lá»™ trÃ¬nh vÃ  cÃ¡c khoÃ¡ há»c tá»« cÄƒn báº£n Ä‘áº¿n nÃ¢ng cao k áº¡. Tá»« 1 Ä‘á»©a cháº³ng cÃ³ gÃ¬,em mong muá»‘n Ä‘c sá»‘ng vs Ä‘am mÃª vÃ  táº¡o ra 1 giÃ¡ trá»‹ gÃ¬ Ä‘Ã³ dÃ¹ em biáº¿t AI lÃ  1 trÆ°á»ng phÃ¡i ráº¥t ráº¥t khÃ³ vÃ  Ä‘Ã²i há»i 1 quÃ¡ trÃ¬nh chÄƒm chá»‰ lÃ¢u dÃ i,nhÆ°ng em sáº½ cá»‘ háº¿t sá»©c cÃ³ thá»ƒ áº¡! Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u!!",,,"#Q&A, #machine_learning",,
GIáº¢I THÃCH CÃCH HOáº T Äá»˜NG Cá»¦A SELF- ATTENTION.,GIáº¢I THÃCH CÃCH HOáº T Äá»˜NG Cá»¦A SELF- ATTENTION.,,,"#sharing, #deep_learning",,
"Xin phÃ©p cÃ¡c bÃ¡c admin cho em chia sáº» playlist Software Engineering Fundamentals táº¡o bá»Ÿi anh em group MLOpsVN cho bÃ¡c Data Scientist/AI Engineer nÃ o quan tÃ¢m áº¡.
https://www.youtube.com/playlist?list=PLvmLXlo5OR87Gifw5IT-YWllj67YHhaEw",Xin phÃ©p cÃ¡c bÃ¡c admin cho em chia sáº» playlist Software Engineering Fundamentals táº¡o bá»Ÿi anh em group MLOpsVN cho bÃ¡c Data Scientist/AI Engineer nÃ o quan tÃ¢m áº¡. https://www.youtube.com/playlist?list=PLvmLXlo5OR87Gifw5IT-YWllj67YHhaEw,,,"#sharing, #machine_learning",,
"ChÃ o táº¥t cáº£ ACE trong group.
Cho em há»i lÃ  trong group mÃ¬nh cÃ³ ai Ä‘Ã£ sá»­ dá»¥ng MMtracking cá»§a openmmlab chÆ°a áº¡? Em gáº·p váº¥n Ä‘á» vá» implement vÃ  modify; máº·c dÃ¹ Ä‘Ã£ tÃ¬m hiá»ƒu cáº£ tuáº§n nay nhÆ°ng váº«n chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c nÃªn e Ä‘Äƒng stt nÃ y hy vá»ng má»i ngÆ°á»i giÃºp e áº¡. Do váº¥n Ä‘á» dÃ i dÃ²ng quÃ¡ nÃªn khÃ´ng viáº¿t lÃªn Ä‘Ã¢y Ä‘Æ°á»£c áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin <3",ChÃ o táº¥t cáº£ ACE trong group. Cho em há»i lÃ  trong group mÃ¬nh cÃ³ ai Ä‘Ã£ sá»­ dá»¥ng MMtracking cá»§a openmmlab chÆ°a áº¡? Em gáº·p váº¥n Ä‘á» vá» implement vÃ  modify; máº·c dÃ¹ Ä‘Ã£ tÃ¬m hiá»ƒu cáº£ tuáº§n nay nhÆ°ng váº«n chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c nÃªn e Ä‘Äƒng stt nÃ y hy vá»ng má»i ngÆ°á»i giÃºp e áº¡. Do váº¥n Ä‘á» dÃ i dÃ²ng quÃ¡ nÃªn khÃ´ng viáº¿t lÃªn Ä‘Ã¢y Ä‘Æ°á»£c áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin <3,,,"#Q&A, #cv",,
"Microsoft is offering FREE courses in following areas AI, IOT, DATA SCIENCE, MACHINE LEARNING","Microsoft is offering FREE courses in following areas AI, IOT, DATA SCIENCE, MACHINE LEARNING",,,,,
"Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n mÃ´ hÃ¬nh Vietcuna do bÃªn mÃ¬nh má»›i train. Hiá»‡n chá»‰ public báº£n 3B, phiÃªn báº£n 7B vÃ  40B váº«n Ä‘ang tiáº¿p tá»¥c cáº£i thiá»‡n vÃ  trong káº¿ hoáº¡ch release","Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n mÃ´ hÃ¬nh Vietcuna do bÃªn mÃ¬nh má»›i train. Hiá»‡n chá»‰ public báº£n 3B, phiÃªn báº£n 7B vÃ  40B váº«n Ä‘ang tiáº¿p tá»¥c cáº£i thiá»‡n vÃ  trong káº¿ hoáº¡ch release",,,"#sharing, #machine_learning",,
"ChÃ o anh chá»‹ trong nhÃ³m
Anh chá»‹ cho em há»i em há»c ngÃ nh cÆ¡ Ä‘iá»‡n tá»­ Ä‘ang kiáº¿m cÆ¡ há»™i thá»±c táº­p cÃ¡c cÃ´ng ty liÃªn quan Ä‘iáº¿n ngÃ nh há»c hiá»‡n táº¡i
Em cÃ³ vÃ i cÃ¢u há»i sau Ä‘Ã¢y:
Mong anh chá»‹ tráº£ lá»i
CÆ¡ Ä‘iá»‡n tá»­ á»Ÿ viá»‡t nam Ä‘i thá»±c táº­p chá»§ yáº¿u lÃ m gÃ¬?
TÃ¬m thÃ´ng tin trÃªn máº¡ng mÃ´ng lung quÃ¡
ÄÃ´i nÃ©t báº£n thÃ¢n: em lÃ  sinh viÃªn Ä‘áº§u nÄƒm 3 má»™t trÆ°á»ng ká»¹ thuáº­t táº¡i sÃ i gÃ²n
tiáº¿ng anh cá»§a em Ä‘á»c hiá»ƒu nghe nÃ³i k váº¥n Ä‘á» giao tiáº¿p tá»‘t, sÃ i Ä‘Æ°á»£c ngÃ´n ngá»¯ c, vba, matlab á»Ÿ má»©c cÄƒn báº£n, python, cad, solidworks, plc, inventor
Má»™t sá»‘ chá»©ng chá»‰ trÃªn coursera liÃªn quan Ä‘áº¿n máº¥y pháº§n má»m á»Ÿ trÃªn ,cs50p
Mong anh chá»‹ cho em thÃ´ng tin thá»±c táº­p táº¡i cÃ´ng ty liÃªn quan Ä‘áº¿n chuyÃªn ngÃ nh cá»§a em
Cuá»‘i nÄƒm nay em thi thÃªm tiáº¿ng trung hsk thÃ¬ liá»‡u cÃ³ tÄƒng thÃªm cÆ¡ há»™i thá»±c táº­p táº¡i cÃ¡c cÃ´ng ty khÃ´ng
Em khÃ´ng ngáº¡i khÃ³ anh chá»‹ chá»‰ em chá»— thá»±c táº­p Ä‘á»ƒ há»c há»i vÃ  trau dá»“i cho báº£n thÃ¢n.
Anh chá»‹ giáº£i Ä‘Ã¡p vá»›i.
CÃ²n láº­p trÃ¬nh nhÃºng , thiáº¿t káº¿ cÆ¡ khÃ­ cÃ³ anh chá»‹ nÃ o lÃ m máº£ng nÃ y khÃ´ng, mÃ¬nh cÃ³ thá»ƒ trao Ä‘á»•i táº¡i bÃ i post nÃ y.
CÃ²n data science thÃ¬ há»c kiáº¿n thá»©c gÃ¬ trÆ°á»›c trÆ°á»›c khi tÃ¬m hiá»ƒu máº£ng nay táº¡i trÃªn máº¡ng nÃ³i nhiá»u cÃ¡i mÃ´ng lung quÃ¡
Em xin lá»—i vÃ¬ há»i hÆ¡i ngá»› ngá»›.
Cáº£m Æ¡n anh chá»‹ Ä‘á»c bÃ i!","ChÃ o anh chá»‹ trong nhÃ³m Anh chá»‹ cho em há»i em há»c ngÃ nh cÆ¡ Ä‘iá»‡n tá»­ Ä‘ang kiáº¿m cÆ¡ há»™i thá»±c táº­p cÃ¡c cÃ´ng ty liÃªn quan Ä‘iáº¿n ngÃ nh há»c hiá»‡n táº¡i Em cÃ³ vÃ i cÃ¢u há»i sau Ä‘Ã¢y: Mong anh chá»‹ tráº£ lá»i CÆ¡ Ä‘iá»‡n tá»­ á»Ÿ viá»‡t nam Ä‘i thá»±c táº­p chá»§ yáº¿u lÃ m gÃ¬? TÃ¬m thÃ´ng tin trÃªn máº¡ng mÃ´ng lung quÃ¡ ÄÃ´i nÃ©t báº£n thÃ¢n: em lÃ  sinh viÃªn Ä‘áº§u nÄƒm 3 má»™t trÆ°á»ng ká»¹ thuáº­t táº¡i sÃ i gÃ²n tiáº¿ng anh cá»§a em Ä‘á»c hiá»ƒu nghe nÃ³i k váº¥n Ä‘á» giao tiáº¿p tá»‘t, sÃ i Ä‘Æ°á»£c ngÃ´n ngá»¯ c, vba, matlab á»Ÿ má»©c cÄƒn báº£n, python, cad, solidworks, plc, inventor Má»™t sá»‘ chá»©ng chá»‰ trÃªn coursera liÃªn quan Ä‘áº¿n máº¥y pháº§n má»m á»Ÿ trÃªn ,cs50p Mong anh chá»‹ cho em thÃ´ng tin thá»±c táº­p táº¡i cÃ´ng ty liÃªn quan Ä‘áº¿n chuyÃªn ngÃ nh cá»§a em Cuá»‘i nÄƒm nay em thi thÃªm tiáº¿ng trung hsk thÃ¬ liá»‡u cÃ³ tÄƒng thÃªm cÆ¡ há»™i thá»±c táº­p táº¡i cÃ¡c cÃ´ng ty khÃ´ng Em khÃ´ng ngáº¡i khÃ³ anh chá»‹ chá»‰ em chá»— thá»±c táº­p Ä‘á»ƒ há»c há»i vÃ  trau dá»“i cho báº£n thÃ¢n. Anh chá»‹ giáº£i Ä‘Ã¡p vá»›i. CÃ²n láº­p trÃ¬nh nhÃºng , thiáº¿t káº¿ cÆ¡ khÃ­ cÃ³ anh chá»‹ nÃ o lÃ m máº£ng nÃ y khÃ´ng, mÃ¬nh cÃ³ thá»ƒ trao Ä‘á»•i táº¡i bÃ i post nÃ y. CÃ²n data science thÃ¬ há»c kiáº¿n thá»©c gÃ¬ trÆ°á»›c trÆ°á»›c khi tÃ¬m hiá»ƒu máº£ng nay táº¡i trÃªn máº¡ng nÃ³i nhiá»u cÃ¡i mÃ´ng lung quÃ¡ Em xin lá»—i vÃ¬ há»i hÆ¡i ngá»› ngá»›. Cáº£m Æ¡n anh chá»‹ Ä‘á»c bÃ i!",,,#Q&A,,
"ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang thá»±c hiá»‡n project cÃ¡ nhÃ¢n vÃ  trÆ°á»›c Ä‘Ã³ sá»­ dá»¥ng VOC dataset. Tuy nhiÃªn Ä‘á»ƒ so sÃ¡nh vá»›i cÃ¡c thá»±c nghiá»‡m cá»§a cÃ¡c tÃ¡c giáº£ trong paper thÃ¬ em pháº£i so sÃ¡nh trÃªn COCO. Tuy nhiÃªn COCO cÃ³ má»™t váº¥n Ä‘á» lÃ  nÃ³ tá»“n táº¡i nhiá»u bá»©c áº£nh khÃ´ng cÃ³ object nÃ o thuá»™c COCO class, cÃ¡c module cá»§a em khÃ´ng Ä‘Æ°á»£c thiáº¿t káº¿ cho viá»‡c nÃ y vÃ  chá»‰nh sá»­a láº¡i ráº¥t máº¥t thá»i gian. Bá» nhá»¯ng táº¥m áº£nh nÃ y Ä‘i thÃ¬ ráº¥t dá»… nhÆ°ng em nghÄ© lÃ  nÃ³ cÅ©ng sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c train vÃ  tÃ­nh mAP. Trong cÃ¡c paper thÃ¬ cÃ¡c tÃ¡c giáº£ khÃ´ng Ä‘á» cáº­p Ä‘áº¿n viá»‡c nÃ y. Váº­y hiá»‡n nay cÃ¡ch lÃ m phá»• biáº¿n lÃ  Ä‘Æ¡n giáº£n bá» nhá»¯ng data nhÆ° trÃªn ra khá»i táº­p train vÃ  valid hay váº«n giá»¯ váº­y áº¡.","ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang thá»±c hiá»‡n project cÃ¡ nhÃ¢n vÃ  trÆ°á»›c Ä‘Ã³ sá»­ dá»¥ng VOC dataset. Tuy nhiÃªn Ä‘á»ƒ so sÃ¡nh vá»›i cÃ¡c thá»±c nghiá»‡m cá»§a cÃ¡c tÃ¡c giáº£ trong paper thÃ¬ em pháº£i so sÃ¡nh trÃªn COCO. Tuy nhiÃªn COCO cÃ³ má»™t váº¥n Ä‘á» lÃ  nÃ³ tá»“n táº¡i nhiá»u bá»©c áº£nh khÃ´ng cÃ³ object nÃ o thuá»™c COCO class, cÃ¡c module cá»§a em khÃ´ng Ä‘Æ°á»£c thiáº¿t káº¿ cho viá»‡c nÃ y vÃ  chá»‰nh sá»­a láº¡i ráº¥t máº¥t thá»i gian. Bá» nhá»¯ng táº¥m áº£nh nÃ y Ä‘i thÃ¬ ráº¥t dá»… nhÆ°ng em nghÄ© lÃ  nÃ³ cÅ©ng sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c train vÃ  tÃ­nh mAP. Trong cÃ¡c paper thÃ¬ cÃ¡c tÃ¡c giáº£ khÃ´ng Ä‘á» cáº­p Ä‘áº¿n viá»‡c nÃ y. Váº­y hiá»‡n nay cÃ¡ch lÃ m phá»• biáº¿n lÃ  Ä‘Æ¡n giáº£n bá» nhá»¯ng data nhÆ° trÃªn ra khá»i táº­p train vÃ  valid hay váº«n giá»¯ váº­y áº¡.",,,"#Q&A, #data",,
Má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xÃ³a cÃ¡c Ä‘Æ°á»ng tháº³ng trong cÃ¡c áº£nh trong hÃ¬nh khÃ´ng áº¡? Em Ä‘á»‹nh dÃ¹ng Hough Ä‘á»ƒ nháº­n diá»‡n nhÆ°ng ngáº·t ná»—i sá»‘ 7 vá»›i sá»‘ 1 nÃ³ cÅ©ng nháº­n vÃ o. Em dá»± Ä‘á»‹nh xÃ³a cÃ¡c Ä‘Æ°á»ng Ä‘á»ƒ rá»“i sau Ä‘Ã³ tÃ¬m ra Ä‘Æ°á»£c khung nhá» nháº¥t chá»©a sá»‘,Má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xÃ³a cÃ¡c Ä‘Æ°á»ng tháº³ng trong cÃ¡c áº£nh trong hÃ¬nh khÃ´ng áº¡? Em Ä‘á»‹nh dÃ¹ng Hough Ä‘á»ƒ nháº­n diá»‡n nhÆ°ng ngáº·t ná»—i sá»‘ 7 vá»›i sá»‘ 1 nÃ³ cÅ©ng nháº­n vÃ o. Em dá»± Ä‘á»‹nh xÃ³a cÃ¡c Ä‘Æ°á»ng Ä‘á»ƒ rá»“i sau Ä‘Ã³ tÃ¬m ra Ä‘Æ°á»£c khung nhá» nháº¥t chá»©a sá»‘,,,"#Q&A, #cv",,
"If you are attending #CVPR2023 in-person, join us","If you are attending in-person, join us",#CVPR2023,,,,
"Cháº³ng lÃ  em cÃ³ dÃ¹ng MINST Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ­ tá»± sá»‘, sá»­ dá»¥ng mÃ´ hÃ¬nh MLP. Sau Ä‘Ã³ em thu tháº­p thÃªm cÃ¡c kÃ­ tá»± sá»‘ viáº¿t tay cá»§a nhiá»u ngÆ°á»i. ThÃ¬ vá»›i táº­p dá»¯ liá»‡u má»›i nÃ y thÃ¬ MNIST cho káº¿t quáº£ nháº­n diá»‡n khÃ´ng tá»‘t láº¯m (khoáº£ng 65%). Em Ä‘á»‹nh training tiáº¿p mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u má»›i, thÃ¬ em nÃªn chia táº­p training-test nhÆ° tháº¿ nÃ o áº¡? VÃ¬ táº­p dá»¯ má»›i cá»§a em khÃ´ng Ä‘Æ°á»£c cÃ¢n cho láº¯m, vÃ­ dá»¥ nhÆ° táº­p sá»‘ 0 cÃ³ 100 áº£nh, táº­p sá»‘ 8 cÃ³ 70 áº£nh, trong khi Ä‘Ã³ táº­p sá»‘ 1 chá»‰ cÃ³ khoáº£ng 15 áº£nh thÃ´i, hay táº­p sá»‘ 4 chá»‰ cÃ³ 20 áº£nh","Cháº³ng lÃ  em cÃ³ dÃ¹ng MINST Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ­ tá»± sá»‘, sá»­ dá»¥ng mÃ´ hÃ¬nh MLP. Sau Ä‘Ã³ em thu tháº­p thÃªm cÃ¡c kÃ­ tá»± sá»‘ viáº¿t tay cá»§a nhiá»u ngÆ°á»i. ThÃ¬ vá»›i táº­p dá»¯ liá»‡u má»›i nÃ y thÃ¬ MNIST cho káº¿t quáº£ nháº­n diá»‡n khÃ´ng tá»‘t láº¯m (khoáº£ng 65%). Em Ä‘á»‹nh training tiáº¿p mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u má»›i, thÃ¬ em nÃªn chia táº­p training-test nhÆ° tháº¿ nÃ o áº¡? VÃ¬ táº­p dá»¯ má»›i cá»§a em khÃ´ng Ä‘Æ°á»£c cÃ¢n cho láº¯m, vÃ­ dá»¥ nhÆ° táº­p sá»‘ 0 cÃ³ 100 áº£nh, táº­p sá»‘ 8 cÃ³ 70 áº£nh, trong khi Ä‘Ã³ táº­p sá»‘ 1 chá»‰ cÃ³ khoáº£ng 15 áº£nh thÃ´i, hay táº­p sá»‘ 4 chá»‰ cÃ³ 20 áº£nh",,,"#Q&A, #cv, #data",,
[Mong ad approve sá»›m áº¡],[Mong ad approve sá»›m áº¡],,,,,
"Xin chÃ o cÃ¡c anh em trong nhÃ³m,
MÃ¬nh lÃ  ngÆ°á»i khÃ´ng chuyÃªn, nhÆ°ng Ä‘ang thá»­ á»©ng dá»¥ng ML cho 1 bÃ i toÃ¡n cá»§a cÃ´ng ty. MÃ¬nh nghÄ© bÃ i toÃ¡n nÃ y dÃ¹ng ML lÃ  Ä‘á»§ chá»© ko cáº§n DL.
Do chÆ°a cÃ³ nhiá»u kinh nghiá»‡m nÃªn mÃ¬nh cÃ³ cÃ¢u há»i nhÆ° sau. Hiá»‡n táº¡i 1 sample cá»§a mÃ¬nh cÃ³ 8 feauture (dimension ), nhÆ°ng thá»±c táº¿ chá»‰ cÃ³ 2 LOáº I feauture thÃ´i, vÃ¬ 1 sample nÃ y Ä‘Æ°á»£c láº¥y tá»« 4 sensor, má»—i sensor cho thu vá» 2 loáº¡i feauture. 1 cÃ¡i lÃ  Váº­n tá»‘c, 1 lÃ  Ã¡p suáº¥t táº¡i van Ä‘Ã³. NhÆ°ng 4 van nÃ y Ä‘á»• vá» 1 khuÃ´n chá»©a, tá»« Ä‘Ã³ táº¡o ra sáº£n pháº©m, nÃªn ko thá»ƒ bá» Ä‘Æ°á»£c feauture nÃ o háº¿t.
NgoÃ i viá»‡c Ä‘Æ°a cáº£ 8 feauture vÃ o, hoáº·c nghÄ© ra 1 cÃ´ng thá»©c Ä‘á»ƒ sinh feauture má»›i, thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ Model hiá»ƒu 8 feauture, nhÆ°ng thá»±c cháº¥t lÃ  cÃ³ 2 loáº¡i chÃ­nh Ä‘Æ°á»£c ko áº¡?
MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n Clustering.
Mong Ä‘Æ°á»£c hÆ°á»›ng dáº«n hoáº·c cho keyword nÃ o liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y. Xin cáº£m Æ¡n!","Xin chÃ o cÃ¡c anh em trong nhÃ³m, MÃ¬nh lÃ  ngÆ°á»i khÃ´ng chuyÃªn, nhÆ°ng Ä‘ang thá»­ á»©ng dá»¥ng ML cho 1 bÃ i toÃ¡n cá»§a cÃ´ng ty. MÃ¬nh nghÄ© bÃ i toÃ¡n nÃ y dÃ¹ng ML lÃ  Ä‘á»§ chá»© ko cáº§n DL. Do chÆ°a cÃ³ nhiá»u kinh nghiá»‡m nÃªn mÃ¬nh cÃ³ cÃ¢u há»i nhÆ° sau. Hiá»‡n táº¡i 1 sample cá»§a mÃ¬nh cÃ³ 8 feauture (dimension ), nhÆ°ng thá»±c táº¿ chá»‰ cÃ³ 2 LOáº I feauture thÃ´i, vÃ¬ 1 sample nÃ y Ä‘Æ°á»£c láº¥y tá»« 4 sensor, má»—i sensor cho thu vá» 2 loáº¡i feauture. 1 cÃ¡i lÃ  Váº­n tá»‘c, 1 lÃ  Ã¡p suáº¥t táº¡i van Ä‘Ã³. NhÆ°ng 4 van nÃ y Ä‘á»• vá» 1 khuÃ´n chá»©a, tá»« Ä‘Ã³ táº¡o ra sáº£n pháº©m, nÃªn ko thá»ƒ bá» Ä‘Æ°á»£c feauture nÃ o háº¿t. NgoÃ i viá»‡c Ä‘Æ°a cáº£ 8 feauture vÃ o, hoáº·c nghÄ© ra 1 cÃ´ng thá»©c Ä‘á»ƒ sinh feauture má»›i, thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ Model hiá»ƒu 8 feauture, nhÆ°ng thá»±c cháº¥t lÃ  cÃ³ 2 loáº¡i chÃ­nh Ä‘Æ°á»£c ko áº¡? MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n Clustering. Mong Ä‘Æ°á»£c hÆ°á»›ng dáº«n hoáº·c cho keyword nÃ o liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y. Xin cáº£m Æ¡n!",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i,
Em hiá»‡n lÃ  sinh viÃªn ngÃ nh CÆ¡ Äiá»‡n Tá»­ muá»‘n tÃ¬m hiá»ƒu vá» Machine Learning Ä‘á»ƒ Ã¡p dá»¥ng vÃ o ngÃ nh cá»§a mÃ¬nh trong tÆ°Æ¡ng lai.
Hiá»‡n táº¡i em Ä‘Ã£ há»c xong vÃ  náº¯m cháº¯c cÃ¡c kiáº¿n thá»©c liÃªn quan Ä‘áº¿n ToÃ¡n (Giáº£i TÃ­ch, XÃ¡c suáº¥t, Äáº¡i Sá»‘ Tuyáº¿n TÃ­nh,...). Vá» láº­p trÃ¬nh thÃ¬ em Ä‘Ã£ biáº¿t C vÃ  R.
Nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp em lá»™ trÃ¬nh cÅ©ng nhÆ° cÃ¡c khÃ³a há»c hay vá» Machine Learning cho sinh viÃªn má»›i báº¯t Ä‘áº§u nhÆ° em áº¡.
Em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, Em hiá»‡n lÃ  sinh viÃªn ngÃ nh CÆ¡ Äiá»‡n Tá»­ muá»‘n tÃ¬m hiá»ƒu vá» Machine Learning Ä‘á»ƒ Ã¡p dá»¥ng vÃ o ngÃ nh cá»§a mÃ¬nh trong tÆ°Æ¡ng lai. Hiá»‡n táº¡i em Ä‘Ã£ há»c xong vÃ  náº¯m cháº¯c cÃ¡c kiáº¿n thá»©c liÃªn quan Ä‘áº¿n ToÃ¡n (Giáº£i TÃ­ch, XÃ¡c suáº¥t, Äáº¡i Sá»‘ Tuyáº¿n TÃ­nh,...). Vá» láº­p trÃ¬nh thÃ¬ em Ä‘Ã£ biáº¿t C vÃ  R. Nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp em lá»™ trÃ¬nh cÅ©ng nhÆ° cÃ¡c khÃ³a há»c hay vá» Machine Learning cho sinh viÃªn má»›i báº¯t Ä‘áº§u nhÆ° em áº¡. Em xin cáº£m Æ¡n.",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i trong nhÃ³m áº¡
Em lÃ  sinh viÃªn má»›i ra trÆ°á»ng, trÆ°á»›c Ä‘Ã¢y thÃ¬ e cÃ³ theo hÆ°á»›ng láº­p trÃ¬nh web, app bÃ¢y giá» em muá»‘n tÃ¬m hiá»ƒu sang cáº£ há»c mÃ¡y ná»¯a nhÆ°ng chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t cÃ¡i roadmap dÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u nhÆ° em khÃ´ng áº¡? Em xin cáº£m Æ¡n mn nhiá»u","ChÃ o má»i ngÆ°á»i trong nhÃ³m áº¡ Em lÃ  sinh viÃªn má»›i ra trÆ°á»ng, trÆ°á»›c Ä‘Ã¢y thÃ¬ e cÃ³ theo hÆ°á»›ng láº­p trÃ¬nh web, app bÃ¢y giá» em muá»‘n tÃ¬m hiá»ƒu sang cáº£ há»c mÃ¡y ná»¯a nhÆ°ng chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t cÃ¡i roadmap dÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u nhÆ° em khÃ´ng áº¡? Em xin cáº£m Æ¡n mn nhiá»u",,,"#Q&A, #machine_learning",,
"MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» deep learning trong viá»‡c xá»­ lÃ½ hÃ¬nh áº£nh, sau khi tra internet thÃ¬ mÃ¬nh cÃ³ nhá»¯ng tháº¯c máº¯c sau Ä‘Ã¢y, má»i ngÆ°á»i cÃ³ thá»ƒ chia sáº» vá»›i mÃ¬nh vá» cÃ¡c cÃ¢u há»i nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n.
1. Embedding lÃ  quÃ¡ trÃ¬nh gÃ¬? PhÃ¢n biá»‡t word embedding vÃ  image embedding?
â†’ Hiá»ƒu: embedding lÃ  quÃ¡ trÃ¬nh chuyá»ƒn vector nhiá»u chiá»u thÃ nh vector cÃ³ sá»‘ chiá»u Ã­t hÆ¡n báº±ng cÃ¡ch táº¡o ra má»™t khÃ´ng gian nhÃºng dÃ nh cho cÃ¡c tá»« cÃ³ Ã½ nghÄ©a gáº§n giá»‘ng nhau. Word embedding vÃ  image embedding Ä‘á»u xá»­ lÃ½ viá»‡c biáº¿n input tá»« nhiá»u dimension thÃ nh vector/tensor cÃ³ Ã­t dimension hÆ¡n (vÃ­ dá»¥, thay vÃ¬ cÃ³ 10 words, thÃ¬ ta sáº½ cÃ³ dáº¡ng tensor Ä‘á»ƒ biá»ƒu diá»…n cho tá»«ng word lÃ  10 dimension - (0,0,...,1,0) - 9 sá»‘ 0 vÃ  1 sá»‘ 1. â†’ ta sáº½ phÃ¡t hiá»‡n ra nhá»¯ng tá»« cÃ³ cÃ¹ng ngá»¯ nghÄ©a vÃ  táº¡o nÃªn má»™t embedded space (1 tensor). Sau nÃ y khi biá»ƒu diá»…n cÃ¡c ngÃ´n ngá»¯ khÃ¡c thÃ¬ chá»‰ cáº§n 1 vector chá»‰ index cá»§a tá»« Ä‘Ã³ Ä‘á»ƒ nhÃ¢n vá»›i embedded tensor.
2. Pre-trained model cá»§a quÃ¡ trÃ¬nh nháº­n dáº¡ng hÃ¬nh áº£nh Ä‘Æ°á»£c thá»±c hiá»‡n qua cÃ¡c bÆ°á»›c chÃ­nh nÃ o? inception_v3 cá»§a torchvision.models há»— trá»£ nhá»¯ng gÃ¬ trong quÃ¡ trÃ¬nh pre-trained hoáº·c nháº­n dáº¡ng hÃ¬nh áº£nh?
3. Hidden layer vÃ  embed layer khÃ¡c gÃ¬ nhau?
4. Ecoder vÃ  embedding khÃ¡c gÃ¬ nhau?
Opinion: encoder biáº¿n text/iamge thÃ nh vector, embedding lÃ  quÃ¡ trÃ¬nh giáº£m dimension cá»§a vector","MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» deep learning trong viá»‡c xá»­ lÃ½ hÃ¬nh áº£nh, sau khi tra internet thÃ¬ mÃ¬nh cÃ³ nhá»¯ng tháº¯c máº¯c sau Ä‘Ã¢y, má»i ngÆ°á»i cÃ³ thá»ƒ chia sáº» vá»›i mÃ¬nh vá» cÃ¡c cÃ¢u há»i nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n. 1. Embedding lÃ  quÃ¡ trÃ¬nh gÃ¬? PhÃ¢n biá»‡t word embedding vÃ  image embedding? â†’ Hiá»ƒu: embedding lÃ  quÃ¡ trÃ¬nh chuyá»ƒn vector nhiá»u chiá»u thÃ nh vector cÃ³ sá»‘ chiá»u Ã­t hÆ¡n báº±ng cÃ¡ch táº¡o ra má»™t khÃ´ng gian nhÃºng dÃ nh cho cÃ¡c tá»« cÃ³ Ã½ nghÄ©a gáº§n giá»‘ng nhau. Word embedding vÃ  image embedding Ä‘á»u xá»­ lÃ½ viá»‡c biáº¿n input tá»« nhiá»u dimension thÃ nh vector/tensor cÃ³ Ã­t dimension hÆ¡n (vÃ­ dá»¥, thay vÃ¬ cÃ³ 10 words, thÃ¬ ta sáº½ cÃ³ dáº¡ng tensor Ä‘á»ƒ biá»ƒu diá»…n cho tá»«ng word lÃ  10 dimension - (0,0,...,1,0) - 9 sá»‘ 0 vÃ  1 sá»‘ 1. â†’ ta sáº½ phÃ¡t hiá»‡n ra nhá»¯ng tá»« cÃ³ cÃ¹ng ngá»¯ nghÄ©a vÃ  táº¡o nÃªn má»™t embedded space (1 tensor). Sau nÃ y khi biá»ƒu diá»…n cÃ¡c ngÃ´n ngá»¯ khÃ¡c thÃ¬ chá»‰ cáº§n 1 vector chá»‰ index cá»§a tá»« Ä‘Ã³ Ä‘á»ƒ nhÃ¢n vá»›i embedded tensor. 2. Pre-trained model cá»§a quÃ¡ trÃ¬nh nháº­n dáº¡ng hÃ¬nh áº£nh Ä‘Æ°á»£c thá»±c hiá»‡n qua cÃ¡c bÆ°á»›c chÃ­nh nÃ o? inception_v3 cá»§a torchvision.models há»— trá»£ nhá»¯ng gÃ¬ trong quÃ¡ trÃ¬nh pre-trained hoáº·c nháº­n dáº¡ng hÃ¬nh áº£nh? 3. Hidden layer vÃ  embed layer khÃ¡c gÃ¬ nhau? 4. Ecoder vÃ  embedding khÃ¡c gÃ¬ nhau? Opinion: encoder biáº¿n text/iamge thÃ nh vector, embedding lÃ  quÃ¡ trÃ¬nh giáº£m dimension cá»§a vector",,,"#Q&A, #deep_learning, #cv",,
"Xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang báº¯t Ä‘áº§u há»c python Ä‘á»ƒ dÃ¹ng cho ML, má»i ngÆ°á»i cÃ³ thá»ƒ giá»›i thiá»‡u cho em há»c cÃ¡c khÃ³a há»c online nÃ o thÃ¬ phÃ¹ há»£p áº¡.
P/S: Em cÃ³ kiáº¿n thá»©c vá» láº­p trÃ¬nh cÄƒn báº£n rá»“i nÃªn em nghÄ© em há»c sáº½ khÃ¡ nhanh
Cáº£m Æ¡n má»i ngÆ°á»i áº¡ <3","Xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang báº¯t Ä‘áº§u há»c python Ä‘á»ƒ dÃ¹ng cho ML, má»i ngÆ°á»i cÃ³ thá»ƒ giá»›i thiá»‡u cho em há»c cÃ¡c khÃ³a há»c online nÃ o thÃ¬ phÃ¹ há»£p áº¡. P/S: Em cÃ³ kiáº¿n thá»©c vá» láº­p trÃ¬nh cÄƒn báº£n rá»“i nÃªn em nghÄ© em há»c sáº½ khÃ¡ nhanh Cáº£m Æ¡n má»i ngÆ°á»i áº¡ <3",,,"#Q&A, #machine_learning, #python",,
"ChÃ o má»i ngÆ°á»i, em cÃ³ ngÆ°á»i quen cáº§n tÃ¬m giáº£i phÃ¡p lÃ m má»m áº£nh bitmap thÃ nh áº£nh vector cÃ³ thá»ƒ dÃ¹ng cho thÃªu cÃ´ng nghiá»‡p wilcom. YÃªu cáº§u xá»­ lÃ½ Ä‘Æ°á»£c pencil hatching pattern, lá»c bá» Ä‘Æ°á»£c chi tiáº¿t thá»«a Ä‘á»ƒ phÃ¹ há»£p vá»›i áº£nh thÃªu. KhÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai cung cáº¥p giáº£i phÃ¡p chÆ°a áº¡? Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.
áº¢nh minh hoáº¡","ChÃ o má»i ngÆ°á»i, em cÃ³ ngÆ°á»i quen cáº§n tÃ¬m giáº£i phÃ¡p lÃ m má»m áº£nh bitmap thÃ nh áº£nh vector cÃ³ thá»ƒ dÃ¹ng cho thÃªu cÃ´ng nghiá»‡p wilcom. YÃªu cáº§u xá»­ lÃ½ Ä‘Æ°á»£c pencil hatching pattern, lá»c bá» Ä‘Æ°á»£c chi tiáº¿t thá»«a Ä‘á»ƒ phÃ¹ há»£p vá»›i áº£nh thÃªu. KhÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai cung cáº¥p giáº£i phÃ¡p chÆ°a áº¡? Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u. áº¢nh minh hoáº¡",,,"#sharing, #cv",,
"ChÃ o má»i ngÆ°á»i, táº¡i sao AlexNet sá»­ dá»¥ng Group Convolution nhÆ°ng háº§u háº¿t nhá»¯ng implementation cá»™ng Ä‘á»“ng cá»§a AlexNet láº¡i chá»‰ dÃ¹ng Convolution thÃ´ng thÆ°á»ng áº¡?","ChÃ o má»i ngÆ°á»i, táº¡i sao AlexNet sá»­ dá»¥ng Group Convolution nhÆ°ng háº§u háº¿t nhá»¯ng implementation cá»™ng Ä‘á»“ng cá»§a AlexNet láº¡i chá»‰ dÃ¹ng Convolution thÃ´ng thÆ°á»ng áº¡?",,,"#Q&A, #deep_learning",,
"Xin chÃ o má»i ngÆ°á»i, em cÃ³ 1 vÃ i váº¥n Ä‘á» cáº§n má»i ngÆ°á»i trong nhÃ³m tÆ° váº¥n vÃ  há»— trá»£ áº¡.
Em Ä‘ang cÃ³ 1 Ä‘á» tÃ i vá» á»©ng dá»¥ng AI trong giÃ¡m sÃ¡t máº¡ng. Dá»± Ä‘á»‹nh cá»§a em sáº½ sá»­ dá»¥ng Zabbix cho pháº§n giÃ¡m sÃ¡t máº¡ng, nhÆ°ng em tÃ¬m hiá»ƒu thÃ¬ zabbix nÃ³ há»— trá»£ ráº¥t Ã­t AI hoáº·c khÃ´ng cÃ³ á»©ng dá»¥ng AI rÃµ rÃ ng trong Ä‘Ã³. NÃªn em Ä‘á»‹nh chuyá»ƒn tiáº¿p cÃ¡c thÃ´ng tin log thu tháº­p Ä‘Æ°á»£c tá»« zabbix vá» 1 cÃ´ng cá»¥ AI cá»§a bÃªn khÃ¡c Ä‘á»ƒ phÃ¢n tÃ­ch rÃµ hÆ¡n.
VÃ¬ tháº¿ em muá»‘n há»i má»i ngÆ°á»i trong nhÃ³m tÆ° váº¥n cho em cÃ¡c tool vá» 1 vÃ i cÃ´ng cá»¥ AI Ä‘Ã³ ( chá»§ yáº¿u sá»­ dá»¥ng qua webui chá»© khÃ´ng pháº£i láº­p trÃ¬nh vÃ¬ em khÃ´ng chuyÃªn vá» láº­p trÃ¬nh áº¡) hoáº·c á»©ng dá»¥ng cÃ³ tÃ­ch há»£p AI trong giÃ¡m máº¡ng cÃ³ thá»ƒ thay tháº¿ Ä‘Æ°á»£c Zabbix áº¡.
Em cáº£m Æ¡n áº¡.","Xin chÃ o má»i ngÆ°á»i, em cÃ³ 1 vÃ i váº¥n Ä‘á» cáº§n má»i ngÆ°á»i trong nhÃ³m tÆ° váº¥n vÃ  há»— trá»£ áº¡. Em Ä‘ang cÃ³ 1 Ä‘á» tÃ i vá» á»©ng dá»¥ng AI trong giÃ¡m sÃ¡t máº¡ng. Dá»± Ä‘á»‹nh cá»§a em sáº½ sá»­ dá»¥ng Zabbix cho pháº§n giÃ¡m sÃ¡t máº¡ng, nhÆ°ng em tÃ¬m hiá»ƒu thÃ¬ zabbix nÃ³ há»— trá»£ ráº¥t Ã­t AI hoáº·c khÃ´ng cÃ³ á»©ng dá»¥ng AI rÃµ rÃ ng trong Ä‘Ã³. NÃªn em Ä‘á»‹nh chuyá»ƒn tiáº¿p cÃ¡c thÃ´ng tin log thu tháº­p Ä‘Æ°á»£c tá»« zabbix vá» 1 cÃ´ng cá»¥ AI cá»§a bÃªn khÃ¡c Ä‘á»ƒ phÃ¢n tÃ­ch rÃµ hÆ¡n. VÃ¬ tháº¿ em muá»‘n há»i má»i ngÆ°á»i trong nhÃ³m tÆ° váº¥n cho em cÃ¡c tool vá» 1 vÃ i cÃ´ng cá»¥ AI Ä‘Ã³ ( chá»§ yáº¿u sá»­ dá»¥ng qua webui chá»© khÃ´ng pháº£i láº­p trÃ¬nh vÃ¬ em khÃ´ng chuyÃªn vá» láº­p trÃ¬nh áº¡) hoáº·c á»©ng dá»¥ng cÃ³ tÃ­ch há»£p AI trong giÃ¡m máº¡ng cÃ³ thá»ƒ thay tháº¿ Ä‘Æ°á»£c Zabbix áº¡. Em cáº£m Æ¡n áº¡.",,,"#Q&A, #machine_learning",,
"chaÌ€o moÌ£i ngÆ°Æ¡Ì€i, miÌ€nh xin pheÌp hoÌ‰i Ä‘ÃªÌn mÃ´Ì£t sÃ´Ì vÃ¢Ìn Ä‘ÃªÌ€ cuÌ‰a face recognition.
1.MiÌ€nh thÄƒÌc mÄƒÌc laÌ€ trong caÌc thÆ° viÃªÌ£n nhÆ° face_recognition thiÌ€ Ä‘Ã¢Ì€u ra cuÌ‰a noÌ laÌ€ 1 vector 128 chiÃªÌ€u , hay laÌ€ mÃ´Ì£t index sau khi Ä‘Æ°Æ¡Ì£c softmax.
2. MiÌ€nh coÌ tiÌ€m hiÃªÌ‰u thiÌ€ thÃ¢Ìy rÄƒÌ€ng hoÌ£ sÆ°Ì‰ duÌ£ng model facenet trong thÆ° viÃªÌ£n face_recognition. MiÌ€nh cuÌƒng chÆ°a hiÃªÌ‰u facenet lÄƒÌm, mk coÌ Ä‘oÌ£c Ä‘Æ°Æ¡Ì£c laÌ€ noÌ train bÄƒÌ€ng softmax Æ¡Ì‰ lÆ¡Ìp cuÃ´Ìi, nhÆ°ng lÃ¢u lÃ¢u miÌ€nh laÌ£i thÃ¢Ìy Ä‘Ã¢u Ä‘oÌ coÌ taÌ€i liÃªÌ£u noÌi rÄƒÌ€ng noÌ seÌƒ nhuÌng aÌ‰nh thaÌ€nh vector 128 chiÃªÌ€u. VÃ¢Ì£y coÌ phaÌ‰i laÌ€ trÆ°Æ¡Ìc lÆ¡Ìp cuÃ´Ìi laÌ€ 1 linear 128 chiÃªÌ€u vaÌ€ lÆ¡Ìp cuÃ´Ìi laÌ€ 1 softmax linear Ä‘uÌng k nhiÌ‰, hay laÌ€ lÆ¡Ìp cuÃ´Ìi cuÌ€ng chiÌ‰ laÌ€ 1 linear 128 chiÃªÌ€u sau Ä‘oÌ sÆ°Ì‰ duÌ£ng l2_distance Ä‘ÃªÌ‰ Ä‘o Ä‘Ã´Ì£ tÆ°Æ¡ng Ä‘Ã´Ì€ng hoÄƒÌ£c tiÌnh loss nhiÌ‰ ?
3. VD miÌ€nh coÌ 1 thÆ° muÌ£c coÌ 30 aÌ‰nh cuÌ‰a 30 ngÆ°Æ¡Ì€i khaÌc nhau. Sau Ä‘oÌ sÆ°Ì‰ duÌ£ng face_recognition thiÌ€ vÆ¡Ìi vÃ¢Ìn Ä‘ÃªÌ€ thÆ°Ì 2 chÆ°a giaÌ‰i quyÃªÌt Ä‘Æ°Æ¡Ì£c noÌ seÌƒ sinh ra vÃ¢Ìn Ä‘ÃªÌ€ tiÃªÌp laÌ€: nÃªÌu lÆ¡Ìp cuÃ´Ìi cuÌ€ng laÌ€ 1 softmax linear vaÌ€ trÆ°Æ¡Ìc noÌ laÌ€ 1 linear 128 chiÃªÌ€u thiÌ€ coÌ phaÌ‰i thÆ° viÃªÌ£n seÌƒ Ä‘oÌng bÄƒng toaÌ€n bÃ´Ì£ weight trÆ°Ì€ caÌi weight kÃªÌt nÃ´Ìi cuÌ‰a 2 linear trÃªn Ä‘uÌng khÃ´ng nhiÌ‰? ( lyÌ do miÌ€nh nghiÌƒ nhÆ° vÃ¢Ì£y laÌ€ viÌ€ weight kÃªÌt nÃ´Ìi mÆ¡Ìi khÆ¡Ì‰i taÌ£o rÃ¢Ìt dÃªÌƒ taÌ£o ra loss lÆ¡Ìn, maÌ€ laÌ£i phaÌ‰i update toaÌ€n bÃ´Ì£ weight thiÌ€ noÌ seÌƒ nhÆ° kiÃªÌ‰u big learning rate Ã¢Ìy). CaÌi naÌ€y miÌ€nh Ä‘oaÌn moÌ€ th, ai thÃ¢Ìy sai thiÌ€ giuÌp miÌ€nh vÆ¡Ìi aÌ£.
ThÆ°Ì£c ra thiÌ€ saÌng nay miÌ€nh coÌ gÄƒÌ£p mÃ´Ì£t ngÆ°Æ¡Ì€i vaÌ€ coÌ kÃªu miÌ€nh rÄƒÌ€ng thay viÌ€ em nhuÌng ra 128 vector rÃ´Ì€i tiÌnh Ä‘Ã´Ì£ tÆ°Æ¡ng Ä‘Ã´Ì€ng giÆ°Ìƒa caÌc khuÃ´n mÄƒÌ£t thiÌ€ taÌ£i sao em khÃ´ng cho model chaÌ£y qua rÃ´Ì€i 1 phaÌt cho ra kÃªÌt quaÌ‰ luÃ´n. MiÌ€nh Ä‘ang nghiÌƒ viÃªÌ£c naÌ€y khÃ´ng coÌ khaÌ‰ thi cho lÄƒÌm TaÌ£i viÌ€ nÃªÌu model caÌ€ng sÃ¢u thiÌ€ vÆ¡Ìi dÆ°Ìƒ liÃªÌ£u iÌt oÌ‰i chiÌ‰ coÌ 30 hiÌ€nh aÌ‰nh thiÌ€ rÃ¢Ìt dÃªÌƒ biÌ£ overfiting coÌ€n nÃªÌu model quaÌ nÃ´ng thiÌ€ khoÌ maÌ€ coÌ thÃªÌ‰ nhÃ¢Ì£n diÃªÌ£n chiÌnh xaÌc Ä‘Æ°Æ¡Ì£c. ÄiÃªÌ€u naÌ€y laÌ€ miÌ€nh Ä‘aÌƒ thÆ°Ì£c nghiÃªÌ£m khi train mobilefacenet +arcMargin trÃªn tÃ¢Ì£p dÆ°Ìƒ liÃªÌ£u 5000 aÌ‰nh cuÌ‰a hÆ¡n 1000 Ä‘Ã´Ìi tÆ°Æ¡Ì£ng vÃ¢Ìƒn biÌ£ overfitting. NhÆ°ng maÌ€ do miÌ€nh chÆ°a data Agumentation nÃªn cuÌƒng khÃ´ng chÄƒÌc, maÌ€ miÌ€nh hÃªÌt colab uÌ€i, ai tÆ°Ì€ng laÌ€m qua kiÃªÌ‰u 1 phaÌt cho ra kÃªÌt quaÌ‰ luÃ´n thiÌ€ chia seÌƒ cho miÌ€nh vÆ¡Ìi aÌ£.
LÆ¡Ìƒ miÌ€nh coÌ hoÌ‰i ngu quaÌ thiÌ€ mong mn cuÌƒng Ä‘Æ°Ì€ng neÌm Ä‘aÌ quaÌ ha!!! caÌ‰m Æ¡n mn Ä‘aÌƒ Ä‘oÌ£c aÌ£.","chaÌ€o moÌ£i ngÆ°Æ¡Ì€i, miÌ€nh xin pheÌp hoÌ‰i Ä‘ÃªÌn mÃ´Ì£t sÃ´Ì vÃ¢Ìn Ä‘ÃªÌ€ cuÌ‰a face recognition. 1.MiÌ€nh thÄƒÌc mÄƒÌc laÌ€ trong caÌc thÆ° viÃªÌ£n nhÆ° face_recognition thiÌ€ Ä‘Ã¢Ì€u ra cuÌ‰a noÌ laÌ€ 1 vector 128 chiÃªÌ€u , hay laÌ€ mÃ´Ì£t index sau khi Ä‘Æ°Æ¡Ì£c softmax. 2. MiÌ€nh coÌ tiÌ€m hiÃªÌ‰u thiÌ€ thÃ¢Ìy rÄƒÌ€ng hoÌ£ sÆ°Ì‰ duÌ£ng model facenet trong thÆ° viÃªÌ£n face_recognition. MiÌ€nh cuÌƒng chÆ°a hiÃªÌ‰u facenet lÄƒÌm, mk coÌ Ä‘oÌ£c Ä‘Æ°Æ¡Ì£c laÌ€ noÌ train bÄƒÌ€ng softmax Æ¡Ì‰ lÆ¡Ìp cuÃ´Ìi, nhÆ°ng lÃ¢u lÃ¢u miÌ€nh laÌ£i thÃ¢Ìy Ä‘Ã¢u Ä‘oÌ coÌ taÌ€i liÃªÌ£u noÌi rÄƒÌ€ng noÌ seÌƒ nhuÌng aÌ‰nh thaÌ€nh vector 128 chiÃªÌ€u. VÃ¢Ì£y coÌ phaÌ‰i laÌ€ trÆ°Æ¡Ìc lÆ¡Ìp cuÃ´Ìi laÌ€ 1 linear 128 chiÃªÌ€u vaÌ€ lÆ¡Ìp cuÃ´Ìi laÌ€ 1 softmax linear Ä‘uÌng k nhiÌ‰, hay laÌ€ lÆ¡Ìp cuÃ´Ìi cuÌ€ng chiÌ‰ laÌ€ 1 linear 128 chiÃªÌ€u sau Ä‘oÌ sÆ°Ì‰ duÌ£ng l2_distance Ä‘ÃªÌ‰ Ä‘o Ä‘Ã´Ì£ tÆ°Æ¡ng Ä‘Ã´Ì€ng hoÄƒÌ£c tiÌnh loss nhiÌ‰ ? 3. VD miÌ€nh coÌ 1 thÆ° muÌ£c coÌ 30 aÌ‰nh cuÌ‰a 30 ngÆ°Æ¡Ì€i khaÌc nhau. Sau Ä‘oÌ sÆ°Ì‰ duÌ£ng face_recognition thiÌ€ vÆ¡Ìi vÃ¢Ìn Ä‘ÃªÌ€ thÆ°Ì 2 chÆ°a giaÌ‰i quyÃªÌt Ä‘Æ°Æ¡Ì£c noÌ seÌƒ sinh ra vÃ¢Ìn Ä‘ÃªÌ€ tiÃªÌp laÌ€: nÃªÌu lÆ¡Ìp cuÃ´Ìi cuÌ€ng laÌ€ 1 softmax linear vaÌ€ trÆ°Æ¡Ìc noÌ laÌ€ 1 linear 128 chiÃªÌ€u thiÌ€ coÌ phaÌ‰i thÆ° viÃªÌ£n seÌƒ Ä‘oÌng bÄƒng toaÌ€n bÃ´Ì£ weight trÆ°Ì€ caÌi weight kÃªÌt nÃ´Ìi cuÌ‰a 2 linear trÃªn Ä‘uÌng khÃ´ng nhiÌ‰? ( lyÌ do miÌ€nh nghiÌƒ nhÆ° vÃ¢Ì£y laÌ€ viÌ€ weight kÃªÌt nÃ´Ìi mÆ¡Ìi khÆ¡Ì‰i taÌ£o rÃ¢Ìt dÃªÌƒ taÌ£o ra loss lÆ¡Ìn, maÌ€ laÌ£i phaÌ‰i update toaÌ€n bÃ´Ì£ weight thiÌ€ noÌ seÌƒ nhÆ° kiÃªÌ‰u big learning rate Ã¢Ìy). CaÌi naÌ€y miÌ€nh Ä‘oaÌn moÌ€ th, ai thÃ¢Ìy sai thiÌ€ giuÌp miÌ€nh vÆ¡Ìi aÌ£. ThÆ°Ì£c ra thiÌ€ saÌng nay miÌ€nh coÌ gÄƒÌ£p mÃ´Ì£t ngÆ°Æ¡Ì€i vaÌ€ coÌ kÃªu miÌ€nh rÄƒÌ€ng thay viÌ€ em nhuÌng ra 128 vector rÃ´Ì€i tiÌnh Ä‘Ã´Ì£ tÆ°Æ¡ng Ä‘Ã´Ì€ng giÆ°Ìƒa caÌc khuÃ´n mÄƒÌ£t thiÌ€ taÌ£i sao em khÃ´ng cho model chaÌ£y qua rÃ´Ì€i 1 phaÌt cho ra kÃªÌt quaÌ‰ luÃ´n. MiÌ€nh Ä‘ang nghiÌƒ viÃªÌ£c naÌ€y khÃ´ng coÌ khaÌ‰ thi cho lÄƒÌm TaÌ£i viÌ€ nÃªÌu model caÌ€ng sÃ¢u thiÌ€ vÆ¡Ìi dÆ°Ìƒ liÃªÌ£u iÌt oÌ‰i chiÌ‰ coÌ 30 hiÌ€nh aÌ‰nh thiÌ€ rÃ¢Ìt dÃªÌƒ biÌ£ overfiting coÌ€n nÃªÌu model quaÌ nÃ´ng thiÌ€ khoÌ maÌ€ coÌ thÃªÌ‰ nhÃ¢Ì£n diÃªÌ£n chiÌnh xaÌc Ä‘Æ°Æ¡Ì£c. ÄiÃªÌ€u naÌ€y laÌ€ miÌ€nh Ä‘aÌƒ thÆ°Ì£c nghiÃªÌ£m khi train mobilefacenet +arcMargin trÃªn tÃ¢Ì£p dÆ°Ìƒ liÃªÌ£u 5000 aÌ‰nh cuÌ‰a hÆ¡n 1000 Ä‘Ã´Ìi tÆ°Æ¡Ì£ng vÃ¢Ìƒn biÌ£ overfitting. NhÆ°ng maÌ€ do miÌ€nh chÆ°a data Agumentation nÃªn cuÌƒng khÃ´ng chÄƒÌc, maÌ€ miÌ€nh hÃªÌt colab uÌ€i, ai tÆ°Ì€ng laÌ€m qua kiÃªÌ‰u 1 phaÌt cho ra kÃªÌt quaÌ‰ luÃ´n thiÌ€ chia seÌƒ cho miÌ€nh vÆ¡Ìi aÌ£. LÆ¡Ìƒ miÌ€nh coÌ hoÌ‰i ngu quaÌ thiÌ€ mong mn cuÌƒng Ä‘Æ°Ì€ng neÌm Ä‘aÌ quaÌ ha!!! caÌ‰m Æ¡n mn Ä‘aÌƒ Ä‘oÌ£c aÌ£.",,,"#Q&A, #cv, #machine_learning",,
" ChÃ o má»i ngÆ°á»i, mÃ¬nh 30t lÃ  ngÆ°á»i trÃ¡i ngÃ nh vÃ  Ä‘ang cÃ³ há»©ng thÃº tÃ¬m hiá»ƒu vá» AI. MÃ¬nh cÃ³ tham kháº£o nhiá»u nguá»“n vÃ  Ä‘ang theo lá»™ trÃ¬nh tá»± há»c AI 6 khÃ³a trÃªn udemy (khÃ³a thá»© 6 á»Ÿ bÃªn dÆ°á»›i lÃ : Ãp dá»¥ng AI:
Applied Machine Learning for Healthcare (Hadelin de Ponteves, Kirill Eremenko)KhÃ³a há»c nÃ y táº­p trung vÃ o á»©ng dá»¥ng Machine Learning trong lÄ©nh vá»±c y táº¿ vÃ  dá»¯ liá»‡u y táº¿.
) do con chatGPT Ä‘Æ°a ra vÃ  Ä‘Ã£ há»c xong khÃ³a 1 trÃªn. Theo má»i ngÆ°á»i lá»™ trÃ¬nh nÃ y cÃ³ á»•n khÃ´ng. ThÃªm ná»¯a má»i ngÆ°á»i cho mÃ¬nh xin tÃªn/link cÃ¡c khÃ³a há»c toÃ¡n trÃªn Youtube hoáº·c Udemy/Cousera Ä‘á»ƒ theo ngÃ nh nÃ y ná»¯a áº¡. Cáº£m Æ¡n má»i ngÆ°á»i!","ChÃ o má»i ngÆ°á»i, mÃ¬nh 30t lÃ  ngÆ°á»i trÃ¡i ngÃ nh vÃ  Ä‘ang cÃ³ há»©ng thÃº tÃ¬m hiá»ƒu vá» AI. MÃ¬nh cÃ³ tham kháº£o nhiá»u nguá»“n vÃ  Ä‘ang theo lá»™ trÃ¬nh tá»± há»c AI 6 khÃ³a trÃªn udemy (khÃ³a thá»© 6 á»Ÿ bÃªn dÆ°á»›i lÃ : Ãp dá»¥ng AI: Applied Machine Learning for Healthcare (Hadelin de Ponteves, Kirill Eremenko)KhÃ³a há»c nÃ y táº­p trung vÃ o á»©ng dá»¥ng Machine Learning trong lÄ©nh vá»±c y táº¿ vÃ  dá»¯ liá»‡u y táº¿. ) do con chatGPT Ä‘Æ°a ra vÃ  Ä‘Ã£ há»c xong khÃ³a 1 trÃªn. Theo má»i ngÆ°á»i lá»™ trÃ¬nh nÃ y cÃ³ á»•n khÃ´ng. ThÃªm ná»¯a má»i ngÆ°á»i cho mÃ¬nh xin tÃªn/link cÃ¡c khÃ³a há»c toÃ¡n trÃªn Youtube hoáº·c Udemy/Cousera Ä‘á»ƒ theo ngÃ nh nÃ y ná»¯a áº¡. Cáº£m Æ¡n má»i ngÆ°á»i!",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m má»™t sáº£n pháº©m Ä‘á»ƒ dá»± thi cuá»™c thi KHKT THPT vá» viá»‡c cáº£i thiá»‡n thá»i gian Ä‘Ã¨n giao thÃ´ng báº±ng ML. Em lÃ m Ä‘Æ°á»£c pháº§n Car Detection roi nhma tá»›i khÃºc xá»­ lÃ½ Ä‘á»ƒ Ä‘Æ°a ra má»™t thá»i gian chÃ­nh xÃ¡c thÃ¬ em Ä‘ang phÃ¢n giá»¯a viá»‡c tÃ¬m ra má»™t cÃ´ng thá»©c toÃ¡n hay lÃ  dÃ¹ng má»™t model ML.
Em cÃ³ má»™t tháº¯c máº¯c lÃ  liá»‡u mÃ¬nh cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c thá»i gian Ä‘Ã¨n xanh/Ä‘á»/vÃ ng á»Ÿ má»™t ngÃ£ tÆ° nÃ o Ä‘Ã³ dá»±a vÃ o cÃ¡c features lÃ  : lÆ°u lÆ°á»£ng xe , sá»‘ lÆ°á»£ng xe táº¡i thá»i Ä‘iá»ƒm t á»Ÿ cáº£ bá»‘n cá»™t Ä‘Ã¨n giao thÃ´ng khÃ´ng áº¡.
Náº¿u Ä‘Æ°á»£c thÃ¬ mÃ¬nh pháº£i label báº±ng tay cho táº­p dá»¯ liá»‡u Ä‘Ãºng k áº¡? Liá»‡u mÃ¬nh cÃ³ cÃ²n cÃ¡ch nÃ o khÃ¡c nhanh hÆ¡n khÃ´ng áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m má»™t sáº£n pháº©m Ä‘á»ƒ dá»± thi cuá»™c thi KHKT THPT vá» viá»‡c cáº£i thiá»‡n thá»i gian Ä‘Ã¨n giao thÃ´ng báº±ng ML. Em lÃ m Ä‘Æ°á»£c pháº§n Car Detection roi nhma tá»›i khÃºc xá»­ lÃ½ Ä‘á»ƒ Ä‘Æ°a ra má»™t thá»i gian chÃ­nh xÃ¡c thÃ¬ em Ä‘ang phÃ¢n giá»¯a viá»‡c tÃ¬m ra má»™t cÃ´ng thá»©c toÃ¡n hay lÃ  dÃ¹ng má»™t model ML. Em cÃ³ má»™t tháº¯c máº¯c lÃ  liá»‡u mÃ¬nh cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c thá»i gian Ä‘Ã¨n xanh/Ä‘á»/vÃ ng á»Ÿ má»™t ngÃ£ tÆ° nÃ o Ä‘Ã³ dá»±a vÃ o cÃ¡c features lÃ  : lÆ°u lÆ°á»£ng xe , sá»‘ lÆ°á»£ng xe táº¡i thá»i Ä‘iá»ƒm t á»Ÿ cáº£ bá»‘n cá»™t Ä‘Ã¨n giao thÃ´ng khÃ´ng áº¡. Náº¿u Ä‘Æ°á»£c thÃ¬ mÃ¬nh pháº£i label báº±ng tay cho táº­p dá»¯ liá»‡u Ä‘Ãºng k áº¡? Liá»‡u mÃ¬nh cÃ³ cÃ²n cÃ¡ch nÃ o khÃ¡c nhanh hÆ¡n khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,"#Q&A, #cv, #machine_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡,
Em má»›i chuyá»ƒn qua lÃ m NLP Ä‘Æ°á»£c vÃ i thÃ¡ng nay, trÆ°á»›c Ä‘Ã³ em lÃ m máº£ng vision, nÃªn em cÃ³ má»™t vÃ i cÃ¢u há»i muá»‘n tham váº¥n má»i ngÆ°á»i áº¡. Giáº£ sá»­ quy mÃ´ dá»¯ liá»‡u lá»›n (>= 10M short Arabic text sentences of less than 100 words), nguá»“n lá»±c khoáº£ng 50 human annotators, em gáº·p váº¥n Ä‘á» nhÆ° sau:
Äá»‘i vá»›i bÃ i toÃ¡n sentiment classification (SC), annotation cá»§a human thÆ°á»ng ráº¥t subjective, Ä‘áº·c biá»‡t Ä‘á»‘i vá»›i cÃ¡c sentences cÃ³ cáº£ POS vÃ  NEG sentiments thÃ¬ ráº¥t khÃ³ gÃ¡n nhÃ£n
Má»™t sá»‘ nguá»“n gá»£i Ã½ sá»­ dá»¥ng clustering words thÃ nh POS/NEG/NEU trÆ°á»›c, rá»“i Ä‘áº¿m sá»‘ POS/NEG/NEU trong má»—i sentences Ä‘á»ƒ táº¡o pseudo-label. Tuy nhiÃªn em tháº¥y cÃ¡ch nÃ y chÆ°a toÃ n diá»‡n, vÃ¬ nghÄ©a cá»§a tá»« cÃ²n phá»¥ thuá»™c nhiá»u vÃ o context
Em cÃ³ thá»­ sá»­ dá»¥ng má»™t sá»‘ SC models (pre-trained on big data) trÃªn huggingface Ä‘á»ƒ sinh benchmark trÃªn nhiá»u public datasets khÃ¡c nhau thÃ¬ tháº¥y Ä‘á»™ chÃ­nh xÃ¡c chá»‰ á»Ÿ má»©c 70% => Em Ä‘oÃ¡n lÃ  do cÃ¡ch Ä‘á»‹nh nghÄ©a POS/NEU/NEG sentiments cá»§a má»—i bá»™ dataset cÅ©ng khÃ¡c nhau nhiá»u
Ngay cáº£ viá»‡c Ä‘á»‹nh nghÄ©a tháº¿ nÃ o lÃ  NEU sentiment em cÅ©ng chÆ°a tÃ¬m tháº¥y thÃ´ng tin Ä‘á»§ tá»‘t áº¡. Trong bÃ i [1], tÃ¡c giáº£ cá»§a bÃ¡o cÃ³ Ä‘á» xuáº¥t NEU sentiment nghÄ©a lÃ  ""no positive and no negative"". CÆ¡ mÃ  nhÆ° tháº¿ nÃ o lÃ  ""no positive"" vÃ  ""no negative"" thÃ¬ cÅ©ng ráº¥t Ä‘Æ°a ra 1 quy táº¯c nháº¥t quÃ¡n
CÃ³ má»™t cÃ¡ch Ä‘á»ƒ generate consistent SC labels lÃ  sá»­ dá»¥ng public pre-trained LLMs (e.g. GPT), tuy nhiÃªn em cÃ³ thá»­ GPT thÃ¬ tháº¥y cháº¥t lÆ°á»£ng khÃ¡ tá»‡. Ká»ƒ cáº£ Google Dá»‹ch cÅ©ng perform badly on Arabic (em so káº¿t quáº£ dá»‹ch cá»§a Google vá»›i káº¿t quáº£ dá»‹ch cá»§a human translator) => Em Ä‘oÃ¡n lÃ  NLP models hiá»‡n táº¡i váº«n chÆ°a hoáº¡t Ä‘á»™ng tá»‘t vá»›i Arabic
Em ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i áº¡!
TrÃ­ch dáº«n:
[1] https://www.reddit.com/r/MachineLearning/comments/1my83q/the_importance_of_neutral_class_in_sentiment/","Em chÃ o má»i ngÆ°á»i áº¡, Em má»›i chuyá»ƒn qua lÃ m NLP Ä‘Æ°á»£c vÃ i thÃ¡ng nay, trÆ°á»›c Ä‘Ã³ em lÃ m máº£ng vision, nÃªn em cÃ³ má»™t vÃ i cÃ¢u há»i muá»‘n tham váº¥n má»i ngÆ°á»i áº¡. Giáº£ sá»­ quy mÃ´ dá»¯ liá»‡u lá»›n (>= 10M short Arabic text sentences of less than 100 words), nguá»“n lá»±c khoáº£ng 50 human annotators, em gáº·p váº¥n Ä‘á» nhÆ° sau: Äá»‘i vá»›i bÃ i toÃ¡n sentiment classification (SC), annotation cá»§a human thÆ°á»ng ráº¥t subjective, Ä‘áº·c biá»‡t Ä‘á»‘i vá»›i cÃ¡c sentences cÃ³ cáº£ POS vÃ  NEG sentiments thÃ¬ ráº¥t khÃ³ gÃ¡n nhÃ£n Má»™t sá»‘ nguá»“n gá»£i Ã½ sá»­ dá»¥ng clustering words thÃ nh POS/NEG/NEU trÆ°á»›c, rá»“i Ä‘áº¿m sá»‘ POS/NEG/NEU trong má»—i sentences Ä‘á»ƒ táº¡o pseudo-label. Tuy nhiÃªn em tháº¥y cÃ¡ch nÃ y chÆ°a toÃ n diá»‡n, vÃ¬ nghÄ©a cá»§a tá»« cÃ²n phá»¥ thuá»™c nhiá»u vÃ o context Em cÃ³ thá»­ sá»­ dá»¥ng má»™t sá»‘ SC models (pre-trained on big data) trÃªn huggingface Ä‘á»ƒ sinh benchmark trÃªn nhiá»u public datasets khÃ¡c nhau thÃ¬ tháº¥y Ä‘á»™ chÃ­nh xÃ¡c chá»‰ á»Ÿ má»©c 70% => Em Ä‘oÃ¡n lÃ  do cÃ¡ch Ä‘á»‹nh nghÄ©a POS/NEU/NEG sentiments cá»§a má»—i bá»™ dataset cÅ©ng khÃ¡c nhau nhiá»u Ngay cáº£ viá»‡c Ä‘á»‹nh nghÄ©a tháº¿ nÃ o lÃ  NEU sentiment em cÅ©ng chÆ°a tÃ¬m tháº¥y thÃ´ng tin Ä‘á»§ tá»‘t áº¡. Trong bÃ i [1], tÃ¡c giáº£ cá»§a bÃ¡o cÃ³ Ä‘á» xuáº¥t NEU sentiment nghÄ©a lÃ  ""no positive and no negative"". CÆ¡ mÃ  nhÆ° tháº¿ nÃ o lÃ  ""no positive"" vÃ  ""no negative"" thÃ¬ cÅ©ng ráº¥t Ä‘Æ°a ra 1 quy táº¯c nháº¥t quÃ¡n CÃ³ má»™t cÃ¡ch Ä‘á»ƒ generate consistent SC labels lÃ  sá»­ dá»¥ng public pre-trained LLMs (e.g. GPT), tuy nhiÃªn em cÃ³ thá»­ GPT thÃ¬ tháº¥y cháº¥t lÆ°á»£ng khÃ¡ tá»‡. Ká»ƒ cáº£ Google Dá»‹ch cÅ©ng perform badly on Arabic (em so káº¿t quáº£ dá»‹ch cá»§a Google vá»›i káº¿t quáº£ dá»‹ch cá»§a human translator) => Em Ä‘oÃ¡n lÃ  NLP models hiá»‡n táº¡i váº«n chÆ°a hoáº¡t Ä‘á»™ng tá»‘t vá»›i Arabic Em ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i áº¡! TrÃ­ch dáº«n: [1] https://www.reddit.com/r/MachineLearning/comments/1my83q/the_importance_of_neutral_class_in_sentiment/",,,"#Q&A, #nlp",,
"Em chÃ o má»i ngÆ°á»i áº¡
Hiá»‡n em Ä‘ang lÃ m 1 project cuá»‘i kÃ¬ vá» ML
1.1.BÃ i toÃ¡n: BÃ i toÃ¡n Æ°á»›c lÆ°á»£ng
CÃ´ng ty tÃ i chÃ­nh A cáº§n kiá»ƒm soÃ¡t thanh khoáº£n cá»§a dÃ²ng tiá»n. Táº¡i thá»i Ä‘iá»ƒm Ä‘áº§u thÃ¡ng 04.2023 cáº§n Æ°á»›c lÆ°á»£ng sá»‘ tiá»n thu cá»§a khÃ¡ch hÃ ng trong thÃ¡ng 4.2023 lÃ  bao nhiÃªu.
Dá»±a vÃ o data cÃ³ sáºµn
YÃªu cáº§u
Requirements:
1.Clean data and train the models
2.Diagnose and assess the results
3.Use tools
Tuy nhiÃªn project khi lÃ m ra Ä‘Æ°á»£c cmt lÃ  sai trong viá»‡c sá»­ dá»¥ng thá»‘ng kÃª suy luáº­n, Ä‘ang xÃ i R. Hiá»‡n táº¡i em váº«n chÆ°a tÃ¬m ra chá»— fix chá»— Ä‘Ã³ nÃªn máº¡o muá»™i muá»‘n há»i thÃªm cÃ¡c anh chá»‹ a, em cáº£m Æ¡n","Em chÃ o má»i ngÆ°á»i áº¡ Hiá»‡n em Ä‘ang lÃ m 1 project cuá»‘i kÃ¬ vá» ML 1.1.BÃ i toÃ¡n: BÃ i toÃ¡n Æ°á»›c lÆ°á»£ng CÃ´ng ty tÃ i chÃ­nh A cáº§n kiá»ƒm soÃ¡t thanh khoáº£n cá»§a dÃ²ng tiá»n. Táº¡i thá»i Ä‘iá»ƒm Ä‘áº§u thÃ¡ng 04.2023 cáº§n Æ°á»›c lÆ°á»£ng sá»‘ tiá»n thu cá»§a khÃ¡ch hÃ ng trong thÃ¡ng 4.2023 lÃ  bao nhiÃªu. Dá»±a vÃ o data cÃ³ sáºµn YÃªu cáº§u Requirements: 1.Clean data and train the models 2.Diagnose and assess the results 3.Use tools Tuy nhiÃªn project khi lÃ m ra Ä‘Æ°á»£c cmt lÃ  sai trong viá»‡c sá»­ dá»¥ng thá»‘ng kÃª suy luáº­n, Ä‘ang xÃ i R. Hiá»‡n táº¡i em váº«n chÆ°a tÃ¬m ra chá»— fix chá»— Ä‘Ã³ nÃªn máº¡o muá»™i muá»‘n há»i thÃªm cÃ¡c anh chá»‹ a, em cáº£m Æ¡n",,,"#Q&A, #machine_learning",,
MÃ´ hÃ¬nh AI chuyá»ƒn Ä‘á»•i video 2D thÃ nh cáº¥u trÃºc 3D chi tiáº¿t!,MÃ´ hÃ¬nh AI chuyá»ƒn Ä‘á»•i video 2D thÃ nh cáº¥u trÃºc 3D chi tiáº¿t!,,,"#sharing, #machine_learning",,
"CÃ³ bÃ¡c nÃ o lÃ m viá»‡c vá»›i segmentation trong YOLO chÆ°a áº¡, cho em há»i vá»›i lÃ  sau khi em train xong model thÃ¬ Ä‘áº§u vÃ o áº£nh cá»§a em pháº£i chuáº©n hÃ³a nhÆ° nÃ o má»›i cho vÃ o model nháº­n diá»‡n Ä‘Æ°á»£c váº­y áº¡","CÃ³ bÃ¡c nÃ o lÃ m viá»‡c vá»›i segmentation trong YOLO chÆ°a áº¡, cho em há»i vá»›i lÃ  sau khi em train xong model thÃ¬ Ä‘áº§u vÃ o áº£nh cá»§a em pháº£i chuáº©n hÃ³a nhÆ° nÃ o má»›i cho vÃ o model nháº­n diá»‡n Ä‘Æ°á»£c váº­y áº¡",,,"#Q&A, #cv",,
"Em chÃ o mn áº¡,
Em Ä‘ang lÃ  sinh viÃªn Ä‘i thá»±c táº­p vÃ  em cÃ³ Ä‘Æ°á»£c giao má»™t task lÃ  crawl thÃ´ng tin vá» cÃ¡c teams cÅ©ng nhÆ° lá»‹ch sá»­ Ä‘áº¥u, lá»‹ch thi Ä‘áº¥u cá»§a giáº£i Ä‘áº¥u Premier League. Em cÃ³ kiá»ƒm tra khi vÃ o trang thÃ¬ web cÃ³ gá»i API tá»›i Ä‘á»ƒ vá» data. Tuy nhiÃªn em vÃ o API thÃ¬ bá»‹ error 403. Em cÃ³ dÃ¹ng cheerio Ä‘á»ƒ crawl thuáº§n nhÆ°ng cÃ¡i HTML nÃ³ tráº£ vá» thÃ¬ láº¡i khÃ´ng chá»©a thÃ´ng tin do nÃ³ dyniamic render. Mn ai cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ hÆ°á»›ng dáº«n giÃºp em vá»›i áº¡.
Em cáº£m Æ¡n mn.
https://www.premierleague.com/","Em chÃ o mn áº¡, Em Ä‘ang lÃ  sinh viÃªn Ä‘i thá»±c táº­p vÃ  em cÃ³ Ä‘Æ°á»£c giao má»™t task lÃ  crawl thÃ´ng tin vá» cÃ¡c teams cÅ©ng nhÆ° lá»‹ch sá»­ Ä‘áº¥u, lá»‹ch thi Ä‘áº¥u cá»§a giáº£i Ä‘áº¥u Premier League. Em cÃ³ kiá»ƒm tra khi vÃ o trang thÃ¬ web cÃ³ gá»i API tá»›i Ä‘á»ƒ vá» data. Tuy nhiÃªn em vÃ o API thÃ¬ bá»‹ error 403. Em cÃ³ dÃ¹ng cheerio Ä‘á»ƒ crawl thuáº§n nhÆ°ng cÃ¡i HTML nÃ³ tráº£ vá» thÃ¬ láº¡i khÃ´ng chá»©a thÃ´ng tin do nÃ³ dyniamic render. Mn ai cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ hÆ°á»›ng dáº«n giÃºp em vá»›i áº¡. Em cáº£m Æ¡n mn. https://www.premierleague.com/",,,"#Q&A, #data",,
"Cuá»‘i tuáº§n sau CVPR khai máº¡c á»Ÿ Vancouver, Canada. MÃ¬nh ko cÃ³ paper nhÆ°ng cÅ©ng cÃ³ máº·t ngÃ y chá»§ nháº­t, báº¡n nÃ o trong group cÅ©ng Ä‘i thÃ¬ há»™i Viá»‡t Nam hangout nhÃ©.","Cuá»‘i tuáº§n sau CVPR khai máº¡c á»Ÿ Vancouver, Canada. MÃ¬nh ko cÃ³ paper nhÆ°ng cÅ©ng cÃ³ máº·t ngÃ y chá»§ nháº­t, báº¡n nÃ o trong group cÅ©ng Ä‘i thÃ¬ há»™i Viá»‡t Nam hangout nhÃ©.",,,#sharing,,
"HCM - Decoding Generative AI - Startups
ThÃ¢n má»i cáº£ nhÃ  cÃ¹ng Ä‘áº¿n tham dá»± sá»± kiá»‡n Decoding Generative AI - Startups do Techies Story, WeBuild vÃ  AWS Vietnam tá»• chá»©c.
Thá»i gian: 14:00 - 16:30, ngÃ y 20/06/2023
Äá»‹a Ä‘iá»ƒm: Quáº­n 1, TP Há»“ ChÃ­ Minh.
Link Ä‘Äƒng kÃ½: https://lu.ma/TechEventGenAI
Agenda: tiáº¿ng Anh
2:00pm - 2:05pm: Welcome remarks 2:05pm - 2:35pm: Sharing by Nathan Wangerin Lile, Chief of Staff, Stability AI
2:35pm - 3:05pm: Sharing by Nadav Magnezi, Business & Strategy, AI21 Labs
3:05pm - 3.20pm - Tea Break
3:20pm - 3.40pm: Sharing by Tin Nguyen, CEO & Founder, Ather Labs
3.40pm - 4pm: Sharing by Girish Dilip Patil, Head of Tech, Digital Native Business, ASEAN, Amazon Web Services (AWS)
4pm - 4:30pm: Q&A
About the speakers:
Amazon Web Service (AWS)'s mission for artificial intelligence (AI) is to empower developers to redefine the capabilities of the Internet by offering them robust tools and top-notch security measures. With a focus on effectiveness and innovation, AWS aims to provide the necessary resources for developers to build groundbreaking AI solutions.
Stability AI, headquartered in London with developers distributed across the globe, was founded to build the foundation to activate humanity's potential through artificial intelligence (AI). As the leader in multimodal, open-source AI model development and deployment, Stability AI collaborates with public and private sector partners to bring this next generation infrastructure to a global audience.
AI21 Labs is building state of the art language models with a laser focus on understanding meaning. And to do this, they are simultaneously introducing scientific innovations and tackling frontier software engineering challenges posed by models of this size and sophistication. AI21 Labs was founded by AI pioneers and technology veterans in 2017, including Prof. Yoav Shoham (Professor Emeritus at Stanford), Ori Goshen (Founder of CrowdX), and chairman, Prof. Amnon Shashua (Founder, Mobileye).
Ather Labs is a gaming & technology studio building compelling entertainment experiences using innovative technologies.
About the organizers:
Techie Story: The Untold shares the lives and works of profound individuals who work in tech, including tech veterans, the software engineers, the art wizards, the HRs. Techie Story is also dedicated to enriching the knowledge and skills of developers through a range of engaging events, both online and offline.
WeBuild Community is a forum that connects developers in Vietnam, where they can share their knowledge and experience while working, learning, and building cool stuffs together with more than 3,500 members on Discord.","HCM - Decoding Generative AI - Startups ThÃ¢n má»i cáº£ nhÃ  cÃ¹ng Ä‘áº¿n tham dá»± sá»± kiá»‡n Decoding Generative AI - Startups do Techies Story, WeBuild vÃ  AWS Vietnam tá»• chá»©c. Thá»i gian: 14:00 - 16:30, ngÃ y 20/06/2023 Äá»‹a Ä‘iá»ƒm: Quáº­n 1, TP Há»“ ChÃ­ Minh. Link Ä‘Äƒng kÃ½: https://lu.ma/TechEventGenAI Agenda: tiáº¿ng Anh 2:00pm - 2:05pm: Welcome remarks 2:05pm - 2:35pm: Sharing by Nathan Wangerin Lile, Chief of Staff, Stability AI 2:35pm - 3:05pm: Sharing by Nadav Magnezi, Business & Strategy, AI21 Labs 3:05pm - 3.20pm - Tea Break 3:20pm - 3.40pm: Sharing by Tin Nguyen, CEO & Founder, Ather Labs 3.40pm - 4pm: Sharing by Girish Dilip Patil, Head of Tech, Digital Native Business, ASEAN, Amazon Web Services (AWS) 4pm - 4:30pm: Q&A About the speakers: Amazon Web Service (AWS)'s mission for artificial intelligence (AI) is to empower developers to redefine the capabilities of the Internet by offering them robust tools and top-notch security measures. With a focus on effectiveness and innovation, AWS aims to provide the necessary resources for developers to build groundbreaking AI solutions. Stability AI, headquartered in London with developers distributed across the globe, was founded to build the foundation to activate humanity's potential through artificial intelligence (AI). As the leader in multimodal, open-source AI model development and deployment, Stability AI collaborates with public and private sector partners to bring this next generation infrastructure to a global audience. AI21 Labs is building state of the art language models with a laser focus on understanding meaning. And to do this, they are simultaneously introducing scientific innovations and tackling frontier software engineering challenges posed by models of this size and sophistication. AI21 Labs was founded by AI pioneers and technology veterans in 2017, including Prof. Yoav Shoham (Professor Emeritus at Stanford), Ori Goshen (Founder of CrowdX), and chairman, Prof. Amnon Shashua (Founder, Mobileye). Ather Labs is a gaming & technology studio building compelling entertainment experiences using innovative technologies. About the organizers: Techie Story: The Untold shares the lives and works of profound individuals who work in tech, including tech veterans, the software engineers, the art wizards, the HRs. Techie Story is also dedicated to enriching the knowledge and skills of developers through a range of engaging events, both online and offline. WeBuild Community is a forum that connects developers in Vietnam, where they can share their knowledge and experience while working, learning, and building cool stuffs together with more than 3,500 members on Discord.",,,,,
"ChÃºc cÃ¡c báº¡n buá»•i tá»‘i chá»§ nháº­t vui váº» vÃ  áº¥m Ã¡p bÃªn ngÆ°á»i thÃ¢n yÃªu. Trong tuáº§n qua mÃ¬nh Ä‘Ã£ thá»±c hiá»‡n 2 bÃ i viáº¿t vá»ƒ sá»­ dá»¥ng Typst (Ä‘Æ°á»£c viáº¿t báº±ng Rust-lang) Ä‘á»ƒ soáº¡n tháº£o luáº­n vÄƒn/luáº­n Ã¡n vÃ  presentation slides. MÃ¬nh hi vá»ng nÃ³ há»¯u Ã­ch cho cÃ¡c báº¡n muá»‘n há»c vÃ  Ã¡p dá»¥ng vÃ o quÃ¡ trÃ¬nh biÃªn soáº¡n tÃ i liá»‡u cho cÃ¡c báº¡n.
Trong khoa há»c, cÃ¡c sinh viÃªn cÃ²n cÃ³ thá»ƒ pháº£i lÃ m Poster Ä‘á»ƒ tham gia cÃ¡c Conferences. Váº­y nÃªn, trong chuá»—i bÃ i vá» Typst, mÃ¬nh xin chia sáº» bÃ i cÃ²n láº¡i sá»­ dá»¥ng Typst Ä‘á»ƒ lÃ m Poster táº¡i Ä‘Ã¢y: https://github.com/linhduongtuan/VNUHCM-typst-poster.
Mong ráº±ng máº¥y bÃ i vá» chá»§ Ä‘á» Typst nÃ y cÃ³ giÃ¡ trá»‹ sá»­ dá»¥ng trong cÃ´ng viá»‡c há»c táº­p vÃ  nghiÃªn cá»©u cá»§a cÃ¡c báº¡n. Náº¿u cÃ¡c báº¡n tháº¥y nÃ³ cÃ³ Ã½ nghÄ©a vá»›i báº£n thÃ¢n mÃ¬nh thÃ¬ xin Ä‘á»«ng tiáº¿c 1 Star cho cÃ¡c repositories cá»§a mÃ¬nh nhÃ©. Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u.
Ps. MÃ¬nh hi vá»ng, cÃ¡c Journals sáº½ sá»›m cháº¥p nháº­n Typst nhÆ° 1 typsetting (nhÆ° Word hay LaTeX) cho viá»‡c soáº¡n tháº£o manuscripts gá»­i cho cÃ¡c táº­p san/nhÃ  xuáº¥t báº£n trong thá»i gian gáº§n nháº¥t.","ChÃºc cÃ¡c báº¡n buá»•i tá»‘i chá»§ nháº­t vui váº» vÃ  áº¥m Ã¡p bÃªn ngÆ°á»i thÃ¢n yÃªu. Trong tuáº§n qua mÃ¬nh Ä‘Ã£ thá»±c hiá»‡n 2 bÃ i viáº¿t vá»ƒ sá»­ dá»¥ng Typst (Ä‘Æ°á»£c viáº¿t báº±ng Rust-lang) Ä‘á»ƒ soáº¡n tháº£o luáº­n vÄƒn/luáº­n Ã¡n vÃ  presentation slides. MÃ¬nh hi vá»ng nÃ³ há»¯u Ã­ch cho cÃ¡c báº¡n muá»‘n há»c vÃ  Ã¡p dá»¥ng vÃ o quÃ¡ trÃ¬nh biÃªn soáº¡n tÃ i liá»‡u cho cÃ¡c báº¡n. Trong khoa há»c, cÃ¡c sinh viÃªn cÃ²n cÃ³ thá»ƒ pháº£i lÃ m Poster Ä‘á»ƒ tham gia cÃ¡c Conferences. Váº­y nÃªn, trong chuá»—i bÃ i vá» Typst, mÃ¬nh xin chia sáº» bÃ i cÃ²n láº¡i sá»­ dá»¥ng Typst Ä‘á»ƒ lÃ m Poster táº¡i Ä‘Ã¢y: https://github.com/linhduongtuan/VNUHCM-typst-poster. Mong ráº±ng máº¥y bÃ i vá» chá»§ Ä‘á» Typst nÃ y cÃ³ giÃ¡ trá»‹ sá»­ dá»¥ng trong cÃ´ng viá»‡c há»c táº­p vÃ  nghiÃªn cá»©u cá»§a cÃ¡c báº¡n. Náº¿u cÃ¡c báº¡n tháº¥y nÃ³ cÃ³ Ã½ nghÄ©a vá»›i báº£n thÃ¢n mÃ¬nh thÃ¬ xin Ä‘á»«ng tiáº¿c 1 Star cho cÃ¡c repositories cá»§a mÃ¬nh nhÃ©. Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u. Ps. MÃ¬nh hi vá»ng, cÃ¡c Journals sáº½ sá»›m cháº¥p nháº­n Typst nhÆ° 1 typsetting (nhÆ° Word hay LaTeX) cho viá»‡c soáº¡n tháº£o manuscripts gá»­i cho cÃ¡c táº­p san/nhÃ  xuáº¥t báº£n trong thá»i gian gáº§n nháº¥t.",,,#sharing,,
"Dáº¡ em chÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ má»™t chÃºt khÃºc máº¯c trong bÃ i toÃ¡n binary classification sá»­ dá»¥ng dataset nÃ y https://github.com/IBM/TabFormer/tree/main/data/credit_card, cá»¥ thá»ƒ hÆ¡n lÃ  Ä‘iá»ƒm F1 training cá»§a model tháº¥p, nhÆ°ng Ä‘iá»ƒm F1 cá»§a validation vÃ  testing thÃ¬ láº¡i cao.  Vá» dataset, Ä‘Ã¢y lÃ  dataset vá» giao dá»‹ch tháº» tÃ­n dá»¥ng, vÃ  má»¥c tiÃªu dá»± Ä‘oÃ¡n lÃ  xem cuá»™c giao dá»‹ch Ä‘áº¥y cÃ³ pháº£i lá»«a Ä‘áº£o hay khÃ´ng (""Is Fraud?""). PhÃ¢n bá»‘ class nÃ y ráº¥t máº¥t cÃ¢n báº±ng, cá»¥ thá»ƒ lÃ :
24 triá»‡u cuá»™c giao dá»‹ch
30,000 giao dá»‹ch lá»«a Ä‘áº£o (0.1% of tá»•ng giao dá»‹ch)
Sau pháº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u, em cÃ³ chia ra 3 sets Training (Cuá»™c giao dá»‹ch trÆ°á»›c 2018), Validation (trong 2018) vÃ  Testing (sau 2018), vá»›i pháº§n phÃ¢n bá»‘ class nhÆ° sau (0 lÃ  giao dá»‹ch khÃ´ng lá»«a Ä‘áº£o, 1 lÃ  giao dá»‹ch lá»«a Ä‘áº£o)
Training Data: 
Class 0:  20579668 
Class 1: 25179 
Validation Data: 
Class 0: 1719124 
Class 1: 2491 
Testing Data: 
Class 0: 2058351 
Class 1: 2087
Em hiá»‡n táº¡i Ä‘ang sá»­ dá»¥ng model XGBoost Ä‘á»ƒ dá»± Ä‘oÃ¡n, vÃ  em cÃ³ thu láº¡i Ä‘Æ°á»£c má»™t sá»‘ káº¿t quáº£ nhÆ° sau:
F1 Score on Training Data : 0.57417479049085 
F1 Score on Testing Data : 0.8719438392641008 
PR AUC score on Training Data : 0.9918559271777408 
PR AUC score on Testing Data : 0.9077624174590952
Training report
precision recall f1-score support

0 1.00 1.00 1.00 20579668
1 0.47 1.00 0.64 25179

accuracy 1.00 20604847
macro avg 0.73 1.00 0.82 20604847
weighted avg 1.00 1.00 1.00 20604847

Test report
precision recall f1-score support

0 1.00 1.00 1.00 2058351
1 0.83 0.93 0.87 2087

accuracy 1.00 2060438
macro avg 0.91 0.96 0.94 2060438
weighted avg 1.00 1.00 1.00 2060438
NhÆ° em tháº¥y, thÃ¬ model khÃ´ng há»c Ä‘Æ°á»£c tá»‘t trÃªn dá»¯ liá»‡u training nhÆ°ng láº¡i cÃ³ káº¿t quáº£ ráº¥t tá»‘t á»Ÿ trÃªn dá»¯ liá»‡u testing (VÃ  cáº£ á»Ÿ trÃªn validation set), vÃ  bÃ¢y giá» em cáº£m tháº¥y hÆ¡i khÃ³ hiá»ƒu vá» trÆ°á»ng há»£p nhÆ° váº§y. Em cÃ³ hiá»ƒu model sáº½ bá»‹ underfit náº¿u nhÆ° model khÃ´ng thá»ƒ há»c Ä‘á»§ kiáº¿n thá»©c tá»« dá»¯ liá»‡u training, vÃ  nhÆ° váº­y thÃ¬ model sáº½ khÃ´ng dá»± Ä‘oÃ¡n tá»‘t Ä‘Æ°á»£c cÃ¡c dá»¯ liá»‡u tÆ°Æ¡ng lai, nhÆ° dá»¯ liá»‡u test. CÃ²n model sáº½ overfit náº¿u nhÆ° model há»c quÃ¡ khá»›p vá»›i dá»¯ liá»‡u training, vÃ  nhá»› toÃ n bá»™ cÃ¡c thÃ´ng tin cá»§a dá»¯ liá»‡u Ä‘Ã³ thay vÃ¬ há»c cÃ¡ch phÃ¢n loáº¡i, nÃªn vÃ¬ tháº¿ model sáº½ khÃ´ng thá»±c hiá»‡n tá»‘t viá»‡c phÃ¢n loáº¡i. Tuy nhiÃªn á»Ÿ trÆ°á»ng há»£p cá»§a em, model há»c kÃ©m á»Ÿ trÃªn dá»¯ liá»‡u training, nhÆ°ng láº¡i tráº£ káº¿t quáº£ ráº¥t cao cho dá»¯ liá»‡u testing vÃ  validation (Em khÃ´ng gá»­i kÃ¨m dá»¯ liá»‡u validation á»Ÿ Ä‘Ã¢y, nhÆ°ng káº¿t quáº£ cÅ©ng na nÃ¡ pháº§n testing).   Váº§y nÃªn em muá»‘n há»i má»i ngÆ°á»i ráº±ng bÃ i toÃ¡n cá»§a em hiá»‡n táº¡i Ä‘ang gáº·p váº¥n Ä‘á» gÃ¬, vÃ  á»Ÿ trong trÆ°á»ng há»£p nÃ o áº¡? Em cÃ³ gá»­i kÃ¨m thÃªm má»™t sá»‘ thÃ´ng tin Ä‘áº±ng sau, gá»“m loss cá»§a model lÃºc training, learning curve vÃ  cÃ¡c ma tráº­n confusion. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡!
Loss cá»§a model (validation_0 lÃ  dá»¯ liá»‡u training, validation_1 lÃ  dá»¯ liá»‡u testing)
[0] validation_0-aucpr:0.75831 validation_0-logloss:0.67418 validation_1-aucpr:0.17989 validation_1-logloss:0.67417
[10] validation_0-aucpr:0.78157 validation_0-logloss:0.52305 validation_1-aucpr:0.42574 validation_1-logloss:0.51965
[20] validation_0-aucpr:0.83228 validation_0-logloss:0.41181 validation_1-aucpr:0.79299 validation_1-logloss:0.40593
[30] validation_0-aucpr:0.84335 validation_0-logloss:0.32956 validation_1-aucpr:0.82845 validation_1-logloss:0.32171
[40] validation_0-aucpr:0.86026 validation_0-logloss:0.26683 validation_1-aucpr:0.86401 validation_1-logloss:0.25788
[50] validation_0-aucpr:0.87519 validation_0-logloss:0.21770 validation_1-aucpr:0.86298 validation_1-logloss:0.20919
[60] validation_0-aucpr:0.88714 validation_0-logloss:0.17906 validation_1-aucpr:0.86130 validation_1-logloss:0.17034
[70] validation_0-aucpr:0.89531 validation_0-logloss:0.14839 validation_1-aucpr:0.86285 validation_1-logloss:0.14016
[80] validation_0-aucpr:0.89770 validation_0-logloss:0.12463 validation_1-aucpr:0.86329 validation_1-logloss:0.11545
[90] validation_0-aucpr:0.90004 validation_0-logloss:0.10519 validation_1-aucpr:0.86052 validation_1-logloss:0.09647
[100] validation_0-aucpr:0.90534 validation_0-logloss:0.08897 validation_1-aucpr:0.87044 validation_1-logloss:0.07986
[110] validation_0-aucpr:0.91044 validation_0-logloss:0.07617 validation_1-aucpr:0.86994 validation_1-logloss:0.06662
[120] validation_0-aucpr:0.91458 validation_0-logloss:0.06538 validation_1-aucpr:0.86962 validation_1-logloss:0.05589
[130] validation_0-aucpr:0.91902 validation_0-logloss:0.05645 validation_1-aucpr:0.87092 validation_1-logloss:0.04684
[140] validation_0-aucpr:0.92276 validation_0-logloss:0.04895 validation_1-aucpr:0.87258 validation_1-logloss:0.03967
[150] validation_0-aucpr:0.92713 validation_0-logloss:0.04308 validation_1-aucpr:0.87285 validation_1-logloss:0.03377
[160] validation_0-aucpr:0.93179 validation_0-logloss:0.03788 validation_1-aucpr:0.87703 validation_1-logloss:0.02851
[170] validation_0-aucpr:0.93487 validation_0-logloss:0.03361 validation_1-aucpr:0.87967 validation_1-logloss:0.02426
[180] validation_0-aucpr:0.93875 validation_0-logloss:0.03013 validation_1-aucpr:0.88027 validation_1-logloss:0.02093
[190] validation_0-aucpr:0.94333 validation_0-logloss:0.02688 validation_1-aucpr:0.88284 validation_1-logloss:0.01781
[200] validation_0-aucpr:0.94592 validation_0-logloss:0.02454 validation_1-aucpr:0.88497 validation_1-logloss:0.01577
[210] validation_0-aucpr:0.95043 validation_0-logloss:0.02236 validation_1-aucpr:0.89025 validation_1-logloss:0.01363
[220] validation_0-aucpr:0.95464 validation_0-logloss:0.02033 validation_1-aucpr:0.89146 validation_1-logloss:0.01172
[230] validation_0-aucpr:0.95761 validation_0-logloss:0.01880 validation_1-aucpr:0.89327 validation_1-logloss:0.01044
[240] validation_0-aucpr:0.96080 validation_0-logloss:0.01747 validation_1-aucpr:0.89531 validation_1-logloss:0.00912
[250] validation_0-aucpr:0.96417 validation_0-logloss:0.01625 validation_1-aucpr:0.89891 validation_1-logloss:0.00802
[260] validation_0-aucpr:0.96675 validation_0-logloss:0.01519 validation_1-aucpr:0.90279 validation_1-logloss:0.00712
[270] validation_0-aucpr:0.96898 validation_0-logloss:0.01434 validation_1-aucpr:0.90530 validation_1-logloss:0.00645
[280] validation_0-aucpr:0.97143 validation_0-logloss:0.01353 validation_1-aucpr:0.90629 validation_1-logloss:0.00573
[290] validation_0-aucpr:0.97334 validation_0-logloss:0.01284 validation_1-aucpr:0.90836 validation_1-logloss:0.00520
[300] validation_0-aucpr:0.97506 validation_0-logloss:0.01216 validation_1-aucpr:0.90954 validation_1-logloss:0.00468
[310] validation_0-aucpr:0.97660 validation_0-logloss:0.01161 validation_1-aucpr:0.91150 validation_1-logloss:0.00427
[320] validation_0-aucpr:0.97800 validation_0-logloss:0.01108 validation_1-aucpr:0.91411 validation_1-logloss:0.00386
[330] validation_0-aucpr:0.97927 validation_0-logloss:0.01068 validation_1-aucpr:0.91551 validation_1-logloss:0.00361
[340] validation_0-aucpr:0.98054 validation_0-logloss:0.01019 validation_1-aucpr:0.91600 validation_1-logloss:0.00323
[350] validation_0-aucpr:0.98177 validation_0-logloss:0.00977 validation_1-aucpr:0.91776 validation_1-logloss:0.00299
[360] validation_0-aucpr:0.98272 validation_0-logloss:0.00938 validation_1-aucpr:0.92028 validation_1-logloss:0.00275
[370] validation_0-aucpr:0.98370 validation_0-logloss:0.00903 validation_1-aucpr:0.92015 validation_1-logloss:0.00256
[380] validation_0-aucpr:0.98444 validation_0-logloss:0.00877 validation_1-aucpr:0.92196 validation_1-logloss:0.00242
[390] validation_0-aucpr:0.98514 validation_0-logloss:0.00851 validation_1-aucpr:0.92389 validation_1-logloss:0.00229
[400] validation_0-aucpr:0.98580 validation_0-logloss:0.00828 validation_1-aucpr:0.92348 validation_1-logloss:0.00219
[410] validation_0-aucpr:0.98643 validation_0-logloss:0.00801 validation_1-aucpr:0.92514 validation_1-logloss:0.00203
[420] validation_0-aucpr:0.98711 validation_0-logloss:0.00774 validation_1-aucpr:0.92575 validation_1-logloss:0.00189
[430] validation_0-aucpr:0.98774 validation_0-logloss:0.00750 validation_1-aucpr:0.92427 validation_1-logloss:0.00177
[440] validation_0-aucpr:0.98832 validation_0-logloss:0.00725 validation_1-aucpr:0.92531 validation_1-logloss:0.00164
[450] validation_0-aucpr:0.98887 validation_0-logloss:0.00708 validation_1-aucpr:0.92623 validation_1-logloss:0.00160
[460] validation_0-aucpr:0.98931 validation_0-logloss:0.00690 validation_1-aucpr:0.92806 validation_1-logloss:0.00151
[470] validation_0-aucpr:0.98963 validation_0-logloss:0.00674 validation_1-aucpr:0.92860 validation_1-logloss:0.00146
[480] validation_0-aucpr:0.99005 validation_0-logloss:0.00656 validation_1-aucpr:0.92980 validation_1-logloss:0.00140
[490] validation_0-aucpr:0.99038 validation_0-logloss:0.00642 validation_1-aucpr:0.93051 validation_1-logloss:0.00135
[500] validation_0-aucpr:0.99077 validation_0-logloss:0.00628 validation_1-aucpr:0.93089 validation_1-logloss:0.00131
[510] validation_0-aucpr:0.99108 validation_0-logloss:0.00613 validation_1-aucpr:0.93270 validation_1-logloss:0.00126
[520] validation_0-aucpr:0.99138 validation_0-logloss:0.00601 validation_1-aucpr:0.93254 validation_1-logloss:0.00122
[530] validation_0-aucpr:0.99166 validation_0-logloss:0.00590 validation_1-aucpr:0.93199 validation_1-logloss:0.00119
[540] validation_0-aucpr:0.99197 validation_0-logloss:0.00577 validation_1-aucpr:0.93318 validation_1-logloss:0.00116
[550] validation_0-aucpr:0.99224 validation_0-logloss:0.00566 validation_1-aucpr:0.93408 validation_1-logloss:0.00112
[560] validation_0-aucpr:0.99250 validation_0-logloss:0.00554 validation_1-aucpr:0.93327 validation_1-logloss:0.00109
[570] validation_0-aucpr:0.99278 validation_0-logloss:0.00542 validation_1-aucpr:0.93397 validation_1-logloss:0.00106
[580] validation_0-aucpr:0.99300 validation_0-logloss:0.00530 validation_1-aucpr:0.93339 validation_1-logloss:0.00102
[590] validation_0-aucpr:0.99324 validation_0-logloss:0.00521 validation_1-aucpr:0.93372 validation_1-logloss:0.00100
[599] validation_0-aucpr:0.99338 validation_0-logloss:0.00513 validation_1-aucpr:0.93378 validation_1-logloss:0.00099","Dáº¡ em chÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ má»™t chÃºt khÃºc máº¯c trong bÃ i toÃ¡n binary classification sá»­ dá»¥ng dataset nÃ y https://github.com/IBM/TabFormer/tree/main/data/credit_card, cá»¥ thá»ƒ hÆ¡n lÃ  Ä‘iá»ƒm F1 training cá»§a model tháº¥p, nhÆ°ng Ä‘iá»ƒm F1 cá»§a validation vÃ  testing thÃ¬ láº¡i cao. Vá» dataset, Ä‘Ã¢y lÃ  dataset vá» giao dá»‹ch tháº» tÃ­n dá»¥ng, vÃ  má»¥c tiÃªu dá»± Ä‘oÃ¡n lÃ  xem cuá»™c giao dá»‹ch Ä‘áº¥y cÃ³ pháº£i lá»«a Ä‘áº£o hay khÃ´ng (""Is Fraud?""). PhÃ¢n bá»‘ class nÃ y ráº¥t máº¥t cÃ¢n báº±ng, cá»¥ thá»ƒ lÃ : 24 triá»‡u cuá»™c giao dá»‹ch 30,000 giao dá»‹ch lá»«a Ä‘áº£o (0.1% of tá»•ng giao dá»‹ch) Sau pháº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u, em cÃ³ chia ra 3 sets Training (Cuá»™c giao dá»‹ch trÆ°á»›c 2018), Validation (trong 2018) vÃ  Testing (sau 2018), vá»›i pháº§n phÃ¢n bá»‘ class nhÆ° sau (0 lÃ  giao dá»‹ch khÃ´ng lá»«a Ä‘áº£o, 1 lÃ  giao dá»‹ch lá»«a Ä‘áº£o) Training Data: Class 0: 20579668 Class 1: 25179 Validation Data: Class 0: 1719124 Class 1: 2491 Testing Data: Class 0: 2058351 Class 1: 2087 Em hiá»‡n táº¡i Ä‘ang sá»­ dá»¥ng model XGBoost Ä‘á»ƒ dá»± Ä‘oÃ¡n, vÃ  em cÃ³ thu láº¡i Ä‘Æ°á»£c má»™t sá»‘ káº¿t quáº£ nhÆ° sau: F1 Score on Training Data : 0.57417479049085 F1 Score on Testing Data : 0.8719438392641008 PR AUC score on Training Data : 0.9918559271777408 PR AUC score on Testing Data : 0.9077624174590952 Training report precision recall f1-score support 0 1.00 1.00 1.00 20579668 1 0.47 1.00 0.64 25179 accuracy 1.00 20604847 macro avg 0.73 1.00 0.82 20604847 weighted avg 1.00 1.00 1.00 20604847 Test report precision recall f1-score support 0 1.00 1.00 1.00 2058351 1 0.83 0.93 0.87 2087 accuracy 1.00 2060438 macro avg 0.91 0.96 0.94 2060438 weighted avg 1.00 1.00 1.00 2060438 NhÆ° em tháº¥y, thÃ¬ model khÃ´ng há»c Ä‘Æ°á»£c tá»‘t trÃªn dá»¯ liá»‡u training nhÆ°ng láº¡i cÃ³ káº¿t quáº£ ráº¥t tá»‘t á»Ÿ trÃªn dá»¯ liá»‡u testing (VÃ  cáº£ á»Ÿ trÃªn validation set), vÃ  bÃ¢y giá» em cáº£m tháº¥y hÆ¡i khÃ³ hiá»ƒu vá» trÆ°á»ng há»£p nhÆ° váº§y. Em cÃ³ hiá»ƒu model sáº½ bá»‹ underfit náº¿u nhÆ° model khÃ´ng thá»ƒ há»c Ä‘á»§ kiáº¿n thá»©c tá»« dá»¯ liá»‡u training, vÃ  nhÆ° váº­y thÃ¬ model sáº½ khÃ´ng dá»± Ä‘oÃ¡n tá»‘t Ä‘Æ°á»£c cÃ¡c dá»¯ liá»‡u tÆ°Æ¡ng lai, nhÆ° dá»¯ liá»‡u test. CÃ²n model sáº½ overfit náº¿u nhÆ° model há»c quÃ¡ khá»›p vá»›i dá»¯ liá»‡u training, vÃ  nhá»› toÃ n bá»™ cÃ¡c thÃ´ng tin cá»§a dá»¯ liá»‡u Ä‘Ã³ thay vÃ¬ há»c cÃ¡ch phÃ¢n loáº¡i, nÃªn vÃ¬ tháº¿ model sáº½ khÃ´ng thá»±c hiá»‡n tá»‘t viá»‡c phÃ¢n loáº¡i. Tuy nhiÃªn á»Ÿ trÆ°á»ng há»£p cá»§a em, model há»c kÃ©m á»Ÿ trÃªn dá»¯ liá»‡u training, nhÆ°ng láº¡i tráº£ káº¿t quáº£ ráº¥t cao cho dá»¯ liá»‡u testing vÃ  validation (Em khÃ´ng gá»­i kÃ¨m dá»¯ liá»‡u validation á»Ÿ Ä‘Ã¢y, nhÆ°ng káº¿t quáº£ cÅ©ng na nÃ¡ pháº§n testing). Váº§y nÃªn em muá»‘n há»i má»i ngÆ°á»i ráº±ng bÃ i toÃ¡n cá»§a em hiá»‡n táº¡i Ä‘ang gáº·p váº¥n Ä‘á» gÃ¬, vÃ  á»Ÿ trong trÆ°á»ng há»£p nÃ o áº¡? Em cÃ³ gá»­i kÃ¨m thÃªm má»™t sá»‘ thÃ´ng tin Ä‘áº±ng sau, gá»“m loss cá»§a model lÃºc training, learning curve vÃ  cÃ¡c ma tráº­n confusion. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡! Loss cá»§a model (validation_0 lÃ  dá»¯ liá»‡u training, validation_1 lÃ  dá»¯ liá»‡u testing) [0] validation_0-aucpr:0.75831 validation_0-logloss:0.67418 validation_1-aucpr:0.17989 validation_1-logloss:0.67417 [10] validation_0-aucpr:0.78157 validation_0-logloss:0.52305 validation_1-aucpr:0.42574 validation_1-logloss:0.51965 [20] validation_0-aucpr:0.83228 validation_0-logloss:0.41181 validation_1-aucpr:0.79299 validation_1-logloss:0.40593 [30] validation_0-aucpr:0.84335 validation_0-logloss:0.32956 validation_1-aucpr:0.82845 validation_1-logloss:0.32171 [40] validation_0-aucpr:0.86026 validation_0-logloss:0.26683 validation_1-aucpr:0.86401 validation_1-logloss:0.25788 [50] validation_0-aucpr:0.87519 validation_0-logloss:0.21770 validation_1-aucpr:0.86298 validation_1-logloss:0.20919 [60] validation_0-aucpr:0.88714 validation_0-logloss:0.17906 validation_1-aucpr:0.86130 validation_1-logloss:0.17034 [70] validation_0-aucpr:0.89531 validation_0-logloss:0.14839 validation_1-aucpr:0.86285 validation_1-logloss:0.14016 [80] validation_0-aucpr:0.89770 validation_0-logloss:0.12463 validation_1-aucpr:0.86329 validation_1-logloss:0.11545 [90] validation_0-aucpr:0.90004 validation_0-logloss:0.10519 validation_1-aucpr:0.86052 validation_1-logloss:0.09647 [100] validation_0-aucpr:0.90534 validation_0-logloss:0.08897 validation_1-aucpr:0.87044 validation_1-logloss:0.07986 [110] validation_0-aucpr:0.91044 validation_0-logloss:0.07617 validation_1-aucpr:0.86994 validation_1-logloss:0.06662 [120] validation_0-aucpr:0.91458 validation_0-logloss:0.06538 validation_1-aucpr:0.86962 validation_1-logloss:0.05589 [130] validation_0-aucpr:0.91902 validation_0-logloss:0.05645 validation_1-aucpr:0.87092 validation_1-logloss:0.04684 [140] validation_0-aucpr:0.92276 validation_0-logloss:0.04895 validation_1-aucpr:0.87258 validation_1-logloss:0.03967 [150] validation_0-aucpr:0.92713 validation_0-logloss:0.04308 validation_1-aucpr:0.87285 validation_1-logloss:0.03377 [160] validation_0-aucpr:0.93179 validation_0-logloss:0.03788 validation_1-aucpr:0.87703 validation_1-logloss:0.02851 [170] validation_0-aucpr:0.93487 validation_0-logloss:0.03361 validation_1-aucpr:0.87967 validation_1-logloss:0.02426 [180] validation_0-aucpr:0.93875 validation_0-logloss:0.03013 validation_1-aucpr:0.88027 validation_1-logloss:0.02093 [190] validation_0-aucpr:0.94333 validation_0-logloss:0.02688 validation_1-aucpr:0.88284 validation_1-logloss:0.01781 [200] validation_0-aucpr:0.94592 validation_0-logloss:0.02454 validation_1-aucpr:0.88497 validation_1-logloss:0.01577 [210] validation_0-aucpr:0.95043 validation_0-logloss:0.02236 validation_1-aucpr:0.89025 validation_1-logloss:0.01363 [220] validation_0-aucpr:0.95464 validation_0-logloss:0.02033 validation_1-aucpr:0.89146 validation_1-logloss:0.01172 [230] validation_0-aucpr:0.95761 validation_0-logloss:0.01880 validation_1-aucpr:0.89327 validation_1-logloss:0.01044 [240] validation_0-aucpr:0.96080 validation_0-logloss:0.01747 validation_1-aucpr:0.89531 validation_1-logloss:0.00912 [250] validation_0-aucpr:0.96417 validation_0-logloss:0.01625 validation_1-aucpr:0.89891 validation_1-logloss:0.00802 [260] validation_0-aucpr:0.96675 validation_0-logloss:0.01519 validation_1-aucpr:0.90279 validation_1-logloss:0.00712 [270] validation_0-aucpr:0.96898 validation_0-logloss:0.01434 validation_1-aucpr:0.90530 validation_1-logloss:0.00645 [280] validation_0-aucpr:0.97143 validation_0-logloss:0.01353 validation_1-aucpr:0.90629 validation_1-logloss:0.00573 [290] validation_0-aucpr:0.97334 validation_0-logloss:0.01284 validation_1-aucpr:0.90836 validation_1-logloss:0.00520 [300] validation_0-aucpr:0.97506 validation_0-logloss:0.01216 validation_1-aucpr:0.90954 validation_1-logloss:0.00468 [310] validation_0-aucpr:0.97660 validation_0-logloss:0.01161 validation_1-aucpr:0.91150 validation_1-logloss:0.00427 [320] validation_0-aucpr:0.97800 validation_0-logloss:0.01108 validation_1-aucpr:0.91411 validation_1-logloss:0.00386 [330] validation_0-aucpr:0.97927 validation_0-logloss:0.01068 validation_1-aucpr:0.91551 validation_1-logloss:0.00361 [340] validation_0-aucpr:0.98054 validation_0-logloss:0.01019 validation_1-aucpr:0.91600 validation_1-logloss:0.00323 [350] validation_0-aucpr:0.98177 validation_0-logloss:0.00977 validation_1-aucpr:0.91776 validation_1-logloss:0.00299 [360] validation_0-aucpr:0.98272 validation_0-logloss:0.00938 validation_1-aucpr:0.92028 validation_1-logloss:0.00275 [370] validation_0-aucpr:0.98370 validation_0-logloss:0.00903 validation_1-aucpr:0.92015 validation_1-logloss:0.00256 [380] validation_0-aucpr:0.98444 validation_0-logloss:0.00877 validation_1-aucpr:0.92196 validation_1-logloss:0.00242 [390] validation_0-aucpr:0.98514 validation_0-logloss:0.00851 validation_1-aucpr:0.92389 validation_1-logloss:0.00229 [400] validation_0-aucpr:0.98580 validation_0-logloss:0.00828 validation_1-aucpr:0.92348 validation_1-logloss:0.00219 [410] validation_0-aucpr:0.98643 validation_0-logloss:0.00801 validation_1-aucpr:0.92514 validation_1-logloss:0.00203 [420] validation_0-aucpr:0.98711 validation_0-logloss:0.00774 validation_1-aucpr:0.92575 validation_1-logloss:0.00189 [430] validation_0-aucpr:0.98774 validation_0-logloss:0.00750 validation_1-aucpr:0.92427 validation_1-logloss:0.00177 [440] validation_0-aucpr:0.98832 validation_0-logloss:0.00725 validation_1-aucpr:0.92531 validation_1-logloss:0.00164 [450] validation_0-aucpr:0.98887 validation_0-logloss:0.00708 validation_1-aucpr:0.92623 validation_1-logloss:0.00160 [460] validation_0-aucpr:0.98931 validation_0-logloss:0.00690 validation_1-aucpr:0.92806 validation_1-logloss:0.00151 [470] validation_0-aucpr:0.98963 validation_0-logloss:0.00674 validation_1-aucpr:0.92860 validation_1-logloss:0.00146 [480] validation_0-aucpr:0.99005 validation_0-logloss:0.00656 validation_1-aucpr:0.92980 validation_1-logloss:0.00140 [490] validation_0-aucpr:0.99038 validation_0-logloss:0.00642 validation_1-aucpr:0.93051 validation_1-logloss:0.00135 [500] validation_0-aucpr:0.99077 validation_0-logloss:0.00628 validation_1-aucpr:0.93089 validation_1-logloss:0.00131 [510] validation_0-aucpr:0.99108 validation_0-logloss:0.00613 validation_1-aucpr:0.93270 validation_1-logloss:0.00126 [520] validation_0-aucpr:0.99138 validation_0-logloss:0.00601 validation_1-aucpr:0.93254 validation_1-logloss:0.00122 [530] validation_0-aucpr:0.99166 validation_0-logloss:0.00590 validation_1-aucpr:0.93199 validation_1-logloss:0.00119 [540] validation_0-aucpr:0.99197 validation_0-logloss:0.00577 validation_1-aucpr:0.93318 validation_1-logloss:0.00116 [550] validation_0-aucpr:0.99224 validation_0-logloss:0.00566 validation_1-aucpr:0.93408 validation_1-logloss:0.00112 [560] validation_0-aucpr:0.99250 validation_0-logloss:0.00554 validation_1-aucpr:0.93327 validation_1-logloss:0.00109 [570] validation_0-aucpr:0.99278 validation_0-logloss:0.00542 validation_1-aucpr:0.93397 validation_1-logloss:0.00106 [580] validation_0-aucpr:0.99300 validation_0-logloss:0.00530 validation_1-aucpr:0.93339 validation_1-logloss:0.00102 [590] validation_0-aucpr:0.99324 validation_0-logloss:0.00521 validation_1-aucpr:0.93372 validation_1-logloss:0.00100 [599] validation_0-aucpr:0.99338 validation_0-logloss:0.00513 validation_1-aucpr:0.93378 validation_1-logloss:0.00099",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i, sau nhiá»u thÃ¡ng cháº­m trá»…, em cÅ©ng Ä‘Ã£ hoÃ n thÃ nh Ä‘á» tÃ i OCR cho chá»¯ HÃ¡n-NÃ´m mÃ  Ä‘Ã£ Ä‘Æ°á»£c má»i ngÆ°á»i gÃ³p Ã½ qua trÆ°á»›c Ä‘Ã¢y.  
Link bÃ i post cÅ©: https://www.facebook.com/groups/machinelearningcoban/posts/1423658951424841 
Hiá»‡n táº¡i, nhÃ³m em Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng 1 bá»™ dá»¯ liá»‡u OCR dÃ nh cho cÃ¡c tÃ i liá»‡u lá»‹ch sá»­ cÅ© Ä‘Æ°á»£c viáº¿t tay báº±ng chá»¯ HÃ¡n-NÃ´m vá»›i 2953 Page vÃ  38318 Patch, phá»¥c vá»¥ cho cáº£ 2 bÃ i toÃ¡n Text Detection vÃ  Text Recognition. Bá»™ dá»¯ liá»‡u dá»±a trÃªn 3 tÃ¡c pháº©m lá»›n gá»“m: 
- Trá»n bá»™ 24 quyá»ƒn cá»§a Äáº¡i Viá»‡t Sá»­ KÃ½ ToÃ n ThÆ°. 
- Truyá»‡n Kiá»u cÃ¡c báº£n nÄƒm 1866, 1871, vÃ  1872. 
- Lá»¥c VÃ¢n TiÃªn.  
NgoÃ i ra, em cÅ©ng Ä‘Ã£ cÃ i Ä‘áº·t vÃ  thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh theo sequence level thay vÃ¬ character level nhÆ° cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c, trong Ä‘Ã³:
- Text Detection: sá»­ dá»¥ng 2 mÃ´ hÃ¬nh Ä‘áº¡i diá»‡n cho 2 hÆ°á»›ng tiáº¿p cáº­n Regression-based vÃ  Segmentation-based, Ä‘Æ°á»£c tham kháº£o tá»« cuá»™c thi vá» Scene Text Detection trÃªn bá»™ dá»¯ liá»‡u ICDAR 2015.
- Text Recognition: giáº£i quyáº¿t theo 4 hÆ°á»›ng tiáº¿p cáº­n khÃ¡c nhau cÃ¹ng vá»›i 2 phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n gá»“m Fine-tuning trÃªn 1 bá»™ dá»¯ liá»‡u Synthetic vá»›i hÆ¡n 100k Patch vÃ  Retraining tá»« Ä‘áº§u trÃªn dá»¯ liá»‡u tháº­t Ä‘á»ƒ so sÃ¡nh káº¿t quáº£ vá»›i khi Fine-tuning.
GitHub: https://github.com/ds4v/NomNaOCR
Dataset: https://www.kaggle.com/datasets/quandang/nomnaocr 
Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¡c gÃ³p Ã½ tá»« má»i ngÆ°á»i Ä‘á»ƒ em cÃ³ thá»ƒ há»c há»i cÅ©ng nhÆ° Ä‘á»ƒ cáº£i thiá»‡n thÃªm cho project trong tÆ°Æ¡ng lai.
 â€” vá»›i Nguyá»…n Äá»©c Duy Anh.","ChÃ o má»i ngÆ°á»i, sau nhiá»u thÃ¡ng cháº­m trá»…, em cÅ©ng Ä‘Ã£ hoÃ n thÃ nh Ä‘á» tÃ i OCR cho chá»¯ HÃ¡n-NÃ´m mÃ  Ä‘Ã£ Ä‘Æ°á»£c má»i ngÆ°á»i gÃ³p Ã½ qua trÆ°á»›c Ä‘Ã¢y. Link bÃ i post cÅ©: https://www.facebook.com/groups/machinelearningcoban/posts/1423658951424841 Hiá»‡n táº¡i, nhÃ³m em Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng 1 bá»™ dá»¯ liá»‡u OCR dÃ nh cho cÃ¡c tÃ i liá»‡u lá»‹ch sá»­ cÅ© Ä‘Æ°á»£c viáº¿t tay báº±ng chá»¯ HÃ¡n-NÃ´m vá»›i 2953 Page vÃ  38318 Patch, phá»¥c vá»¥ cho cáº£ 2 bÃ i toÃ¡n Text Detection vÃ  Text Recognition. Bá»™ dá»¯ liá»‡u dá»±a trÃªn 3 tÃ¡c pháº©m lá»›n gá»“m: - Trá»n bá»™ 24 quyá»ƒn cá»§a Äáº¡i Viá»‡t Sá»­ KÃ½ ToÃ n ThÆ°. - Truyá»‡n Kiá»u cÃ¡c báº£n nÄƒm 1866, 1871, vÃ  1872. - Lá»¥c VÃ¢n TiÃªn. NgoÃ i ra, em cÅ©ng Ä‘Ã£ cÃ i Ä‘áº·t vÃ  thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh theo sequence level thay vÃ¬ character level nhÆ° cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c, trong Ä‘Ã³: - Text Detection: sá»­ dá»¥ng 2 mÃ´ hÃ¬nh Ä‘áº¡i diá»‡n cho 2 hÆ°á»›ng tiáº¿p cáº­n Regression-based vÃ  Segmentation-based, Ä‘Æ°á»£c tham kháº£o tá»« cuá»™c thi vá» Scene Text Detection trÃªn bá»™ dá»¯ liá»‡u ICDAR 2015. - Text Recognition: giáº£i quyáº¿t theo 4 hÆ°á»›ng tiáº¿p cáº­n khÃ¡c nhau cÃ¹ng vá»›i 2 phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n gá»“m Fine-tuning trÃªn 1 bá»™ dá»¯ liá»‡u Synthetic vá»›i hÆ¡n 100k Patch vÃ  Retraining tá»« Ä‘áº§u trÃªn dá»¯ liá»‡u tháº­t Ä‘á»ƒ so sÃ¡nh káº¿t quáº£ vá»›i khi Fine-tuning. GitHub: https://github.com/ds4v/NomNaOCR Dataset: https://www.kaggle.com/datasets/quandang/nomnaocr Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¡c gÃ³p Ã½ tá»« má»i ngÆ°á»i Ä‘á»ƒ em cÃ³ thá»ƒ há»c há»i cÅ©ng nhÆ° Ä‘á»ƒ cáº£i thiá»‡n thÃªm cho project trong tÆ°Æ¡ng lai. â€” vá»›i Nguyá»…n Äá»©c Duy Anh.",,,"#sharing, #cv, #deep_learning",,
Nghá» cá»§a tÆ°Æ¡ng lai: #PromptEngineering,Nghá» cá»§a tÆ°Æ¡ng lai:,#PromptEngineering,,#sharing,,
"ChÃ o cÃ¡c anh,chá»‹ trong forum.
Em hiá»‡n Ä‘ang há»c vá» GIS (há»‡ thá»‘ng thÃ´ng tin Ä‘á»‹a lÃ½). CÃ¡c anh chá»‹ cho em há»i liá»‡u Machine Learning cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c vÃ o GIS khÃ´ng áº¡ vÃ  Ã¡p dá»¥ng nhÆ° tháº¿ nÃ o váº­y áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡ğŸ¥°ğŸ¥°","ChÃ o cÃ¡c anh,chá»‹ trong forum. Em hiá»‡n Ä‘ang há»c vá» GIS (há»‡ thá»‘ng thÃ´ng tin Ä‘á»‹a lÃ½). CÃ¡c anh chá»‹ cho em há»i liá»‡u Machine Learning cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c vÃ o GIS khÃ´ng áº¡ vÃ  Ã¡p dá»¥ng nhÆ° tháº¿ nÃ o váº­y áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,"#Q&A, #machine_learning",,
"Xin chÃ o má»i ngÆ°á»i,
HÃ¨ nÃ y em tÃ­nh Ä‘áº§u tÆ° thá»i gian Ä‘á»ƒ há»c Machine Learning. TrÃªn Coursera cÃ³ hai khÃ³a Machine Learning tá»‘t nháº¥t Ä‘Ã³ lÃ  khÃ³a Machine Learning Specialization cá»§a DeepLearning.ai vÃ  khÃ³a Machine Learning Professional Certificate cá»§a IBM.
Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n lÃ  khÃ³a nÃ o lÃ  khÃ³a tá»‘t nháº¥t vÃ  chuyÃªn sÃ¢u nháº¥t.
Em khÃ´ng cáº§n khÃ³a beginner-friendly, em chá»‰ cáº§n khÃ³a nÃ o dáº¡y Ä‘áº§y Ä‘á»§ nháº¥t.
Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","Xin chÃ o má»i ngÆ°á»i, HÃ¨ nÃ y em tÃ­nh Ä‘áº§u tÆ° thá»i gian Ä‘á»ƒ há»c Machine Learning. TrÃªn Coursera cÃ³ hai khÃ³a Machine Learning tá»‘t nháº¥t Ä‘Ã³ lÃ  khÃ³a Machine Learning Specialization cá»§a DeepLearning.ai vÃ  khÃ³a Machine Learning Professional Certificate cá»§a IBM. Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n lÃ  khÃ³a nÃ o lÃ  khÃ³a tá»‘t nháº¥t vÃ  chuyÃªn sÃ¢u nháº¥t. Em khÃ´ng cáº§n khÃ³a beginner-friendly, em chá»‰ cáº§n khÃ³a nÃ o dáº¡y Ä‘áº§y Ä‘á»§ nháº¥t. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,"#Q&A, #machine_learning",,
Chuyá»‡n lÃ  em Ä‘ang lÃ m 1 project vá» image classfication trÃªn mobile. Em cÃ³ quantizition model xuá»‘ng int8. Em cÃ³ xuáº¥t output thÃ¬ nÃ³ ra 1 máº£ng giÃ¡ trÃ­ nhÆ° trong hÃ¬nh. Em muá»‘n convert nÃ³ thÃ nh pháº§n trÄƒm tá»‰ lá»‡ chÃ­nh xÃ¡c. LÃªn máº¡ng kiáº¿m tÃ i liá»‡u nhÆ°ng khÃ´ng biáº¿t nhÆ° tháº¿ nÃ o. Anh chá»‹ nÃ o biáº¿t chá»‰ em vá»›i áº¡. Em cÃ¡m Æ¡n.,Chuyá»‡n lÃ  em Ä‘ang lÃ m 1 project vá» image classfication trÃªn mobile. Em cÃ³ quantizition model xuá»‘ng int8. Em cÃ³ xuáº¥t output thÃ¬ nÃ³ ra 1 máº£ng giÃ¡ trÃ­ nhÆ° trong hÃ¬nh. Em muá»‘n convert nÃ³ thÃ nh pháº§n trÄƒm tá»‰ lá»‡ chÃ­nh xÃ¡c. LÃªn máº¡ng kiáº¿m tÃ i liá»‡u nhÆ°ng khÃ´ng biáº¿t nhÆ° tháº¿ nÃ o. Anh chá»‹ nÃ o biáº¿t chá»‰ em vá»›i áº¡. Em cÃ¡m Æ¡n.,,,"#Q&A, #cv",,
"ChÃ o cÃ¡c báº¡n,
Tuáº§n trÆ°á»›c mÃ¬nh nháº­n Ä‘Æ°á»£c má»™t email ráº¥t dÃ i nhá» tÆ° váº¥n cho má»™t dá»± Ã¡n tiÃªn Ä‘oÃ¡n má»©c Ä‘á»™ ung thÆ° vÃº trong tÆ°Æ¡ng lai cho phá»¥ ná»¯ Viá»‡t Nam. MÃ¬nh Ä‘Ã£ nÃ³i chuyá»‡n vá»›i team vÃ  tháº¥y ráº±ng Ä‘Ã¢y lÃ  má»™t dá»± Ã¡n Ã½ nghÄ©a, mÃ¬nh Ä‘Ã£ nháº­n lá»i káº¿t ná»‘i dá»± Ã¡n vá»›i cá»™ng Ä‘á»“ng.
Hiá»‡n nhÃ³m Ä‘Ã£ cÃ³ khÃ¡ nhiá»u dá»¯ liá»‡u, cáº£ vá» áº£nh láº«n dá»¯ liá»‡u báº£ng, cÃ³ chuyÃªn gia vá» máº·t y táº¿ vÃ  cÃ³ cÃ¡c báº¡n láº­p trÃ¬nh viÃªn há»— trá»£. Tuy nhiÃªn váº«n cÃ²n nhiá»u Ä‘iá»ƒm cÃ³ thá»ƒ cáº£i thiá»‡n báº±ng cáº£ computer vision vÃ  data science. Theo mÃ¬nh Ä‘Ã¢y cÅ©ng lÃ  má»™t cÆ¡ há»™i tá»‘t cho cÃ¡c báº¡n nghiÃªn cá»©u vá» ML cho Y Sinh Ä‘Æ°á»£c tiáº¿p cáº­n nguá»“n dá»¯ liá»‡u tá»‘t vÃ  lÃ m vá»›i má»™t dá»± Ã¡n thá»±c táº¿.
Váº­y nÃªn mÃ¬nh viáº¿t post nÃ y giÃºp káº¿t ná»‘i cÃ¡c báº¡n cÃ³ kinh nghiá»‡m trong lÄ©nh vá»±c nÃ y vá»›i dá»± Ã¡n. ThÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n vÃ  cÃ¡ch liÃªn há»‡ há»£p tÃ¡c Ä‘Æ°á»£c cho trong comment.
Cáº£m Æ¡n cÃ¡c báº¡n.","ChÃ o cÃ¡c báº¡n, Tuáº§n trÆ°á»›c mÃ¬nh nháº­n Ä‘Æ°á»£c má»™t email ráº¥t dÃ i nhá» tÆ° váº¥n cho má»™t dá»± Ã¡n tiÃªn Ä‘oÃ¡n má»©c Ä‘á»™ ung thÆ° vÃº trong tÆ°Æ¡ng lai cho phá»¥ ná»¯ Viá»‡t Nam. MÃ¬nh Ä‘Ã£ nÃ³i chuyá»‡n vá»›i team vÃ  tháº¥y ráº±ng Ä‘Ã¢y lÃ  má»™t dá»± Ã¡n Ã½ nghÄ©a, mÃ¬nh Ä‘Ã£ nháº­n lá»i káº¿t ná»‘i dá»± Ã¡n vá»›i cá»™ng Ä‘á»“ng. Hiá»‡n nhÃ³m Ä‘Ã£ cÃ³ khÃ¡ nhiá»u dá»¯ liá»‡u, cáº£ vá» áº£nh láº«n dá»¯ liá»‡u báº£ng, cÃ³ chuyÃªn gia vá» máº·t y táº¿ vÃ  cÃ³ cÃ¡c báº¡n láº­p trÃ¬nh viÃªn há»— trá»£. Tuy nhiÃªn váº«n cÃ²n nhiá»u Ä‘iá»ƒm cÃ³ thá»ƒ cáº£i thiá»‡n báº±ng cáº£ computer vision vÃ  data science. Theo mÃ¬nh Ä‘Ã¢y cÅ©ng lÃ  má»™t cÆ¡ há»™i tá»‘t cho cÃ¡c báº¡n nghiÃªn cá»©u vá» ML cho Y Sinh Ä‘Æ°á»£c tiáº¿p cáº­n nguá»“n dá»¯ liá»‡u tá»‘t vÃ  lÃ m vá»›i má»™t dá»± Ã¡n thá»±c táº¿. Váº­y nÃªn mÃ¬nh viáº¿t post nÃ y giÃºp káº¿t ná»‘i cÃ¡c báº¡n cÃ³ kinh nghiá»‡m trong lÄ©nh vá»±c nÃ y vá»›i dá»± Ã¡n. ThÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n vÃ  cÃ¡ch liÃªn há»‡ há»£p tÃ¡c Ä‘Æ°á»£c cho trong comment. Cáº£m Æ¡n cÃ¡c báº¡n.",,,"#sharing, #machine_learning",,
"Máº¥y ngÃ y trÆ°á»›c mÃ¬nh cÃ³ táº¡o ra template Ä‘á»ƒ viáº¿t luáº­n vÄƒn/luáº­n Ã¡n sá»­ dá»¥ng Typst táº¡i Ä‘Ã¢y https://github.com/linhduongtuan/BKHN-Thesis_template_typst.
HÃ´m nay, mÃ¬nh xin gá»­i Ä‘áº¿n cÃ¡c báº¡n 1 template khÃ¡c vá»›i má»¥c Ä‘Ã­ch viáº¿t Slides Ä‘á»ƒ bÃ¡o cÃ¡o. Xin tham kháº£o táº¡i Ä‘Ã¢y: https://github.com/linhduongtuan/DTU-typst-presentation
Hi vá»ng vá»›i combo thÆ° viá»‡n nÃ y sáº½ giÃºp chÃºng ta cÃ³ thÃªm cÃ´ng cá»¥ Ä‘á»ƒ soáº¡n tháº£o vÄƒn báº£n vÃ  bÃ i thuyáº¿t trÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£.
ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº».
Ps. Náº¿u cÃ¡c báº¡n tháº¥y repositories cá»§a mÃ¬nh cÃ³ Ã­ch, xin Ä‘á»«ng tiáº¿c má»™t Star cho má»—i thÆ° viá»‡n nÃ³i trÃªn.
TrÃ¢n trá»ng","Máº¥y ngÃ y trÆ°á»›c mÃ¬nh cÃ³ táº¡o ra template Ä‘á»ƒ viáº¿t luáº­n vÄƒn/luáº­n Ã¡n sá»­ dá»¥ng Typst táº¡i Ä‘Ã¢y https://github.com/linhduongtuan/BKHN-Thesis_template_typst. HÃ´m nay, mÃ¬nh xin gá»­i Ä‘áº¿n cÃ¡c báº¡n 1 template khÃ¡c vá»›i má»¥c Ä‘Ã­ch viáº¿t Slides Ä‘á»ƒ bÃ¡o cÃ¡o. Xin tham kháº£o táº¡i Ä‘Ã¢y: https://github.com/linhduongtuan/DTU-typst-presentation Hi vá»ng vá»›i combo thÆ° viá»‡n nÃ y sáº½ giÃºp chÃºng ta cÃ³ thÃªm cÃ´ng cá»¥ Ä‘á»ƒ soáº¡n tháº£o vÄƒn báº£n vÃ  bÃ i thuyáº¿t trÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£. ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº». Ps. Náº¿u cÃ¡c báº¡n tháº¥y repositories cá»§a mÃ¬nh cÃ³ Ã­ch, xin Ä‘á»«ng tiáº¿c má»™t Star cho má»—i thÆ° viá»‡n nÃ³i trÃªn. TrÃ¢n trá»ng",,,#sharing,,
Xin chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n. MÃ¬nh lÃ m vá» data á»Ÿ TÃ¢y Ban Nha. MÃ¬nh muá»‘n join vÃ o dá»± Ã¡n nÃ o Ä‘Ã³ á»Ÿ VN mÃ  cÃ³ liÃªn quan tá»›i Crypto Curency thÃ¬ tá»‘t. MÃ¬nh khÃ´ng yÃªu cáº§u tráº£ lÆ°Æ¡ng chá»‰ mong Ä‘Æ°á»£c há»c há»i tá»« cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n.,Xin chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n. MÃ¬nh lÃ m vá» data á»Ÿ TÃ¢y Ban Nha. MÃ¬nh muá»‘n join vÃ o dá»± Ã¡n nÃ o Ä‘Ã³ á»Ÿ VN mÃ  cÃ³ liÃªn quan tá»›i Crypto Curency thÃ¬ tá»‘t. MÃ¬nh khÃ´ng yÃªu cáº§u tráº£ lÆ°Æ¡ng chá»‰ mong Ä‘Æ°á»£c há»c há»i tá»« cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n.,,,"#sharing, #data",,
"Em chÃ o anh chá»‹ trong nhÃ³m áº¡. Hiá»‡n em Ä‘Ã£ tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i, em Ä‘ang tÃ¬m viá»‡c Intern/fresher vá» Al táº¡i HÃ  Ná»™i. KhÃ´ng biáº¿t anh/chá»‹ á»Ÿ cÃ´ng ty nÃ o cÃ³ cÃ²n open cho vá»‹ trÃ­ Intern/fresher khÃ´ng áº¡?","Em chÃ o anh chá»‹ trong nhÃ³m áº¡. Hiá»‡n em Ä‘Ã£ tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i, em Ä‘ang tÃ¬m viá»‡c Intern/fresher vá» Al táº¡i HÃ  Ná»™i. KhÃ´ng biáº¿t anh/chá»‹ á»Ÿ cÃ´ng ty nÃ o cÃ³ cÃ²n open cho vá»‹ trÃ­ Intern/fresher khÃ´ng áº¡?",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i em Ä‘ang tÃ¬m hiá»ƒu vá» chatbot tiáº¿ng viá»‡t sá»­ dá»¥ng Underthesea. NhÆ°ng em tháº¥y Ã­t tÃ i liá»‡u vá» Ä‘á» tÃ i nÃ y, má»i ngÆ°á»i cÃ³ tÃ i liá»‡u hoáº·c code liÃªn quan cho em xin tham kháº£o vá»›i áº¡. Em cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i em Ä‘ang tÃ¬m hiá»ƒu vá» chatbot tiáº¿ng viá»‡t sá»­ dá»¥ng Underthesea. NhÆ°ng em tháº¥y Ã­t tÃ i liá»‡u vá» Ä‘á» tÃ i nÃ y, má»i ngÆ°á»i cÃ³ tÃ i liá»‡u hoáº·c code liÃªn quan cho em xin tham kháº£o vá»›i áº¡. Em cáº£m Æ¡n",,,"#Q&A, #nlp",,
Má»™t bÃ i bÃ¡o cá»§a DeepMind sá»­ dá»¥ng AlphaDev tÃ¬m ra Ä‘Æ°á»£c thuáº­t toÃ¡n sáº¯p xáº¿p hiá»‡u quáº£ hÆ¡n. Chi tiáº¿t bÃ i bÃ¡o:,Má»™t bÃ i bÃ¡o cá»§a DeepMind sá»­ dá»¥ng AlphaDev tÃ¬m ra Ä‘Æ°á»£c thuáº­t toÃ¡n sáº¯p xáº¿p hiá»‡u quáº£ hÆ¡n. Chi tiáº¿t bÃ i bÃ¡o:,,,"#sharing, #machine_learning",,
"Not only generating images but also drawing, editing, inpainting, outpainting, and removal. https://lunai.art/imagetool","Not only generating images but also drawing, editing, inpainting, outpainting, and removal. https://lunai.art/imagetool",,,,,
"[Sharing Generative AI google free courses]
Google has created a Generative AI learning path with 9 FREE courses!
Topics cover:
- Intro to LLMs
- Attention Mechanism
- Image Generation/Captioning
- Intro to Responsible AI
From the fundamentals of LLMs to creating & deploying generative AI solutions!",[Sharing Generative AI google free courses] Google has created a Generative AI learning path with 9 FREE courses! Topics cover: - Intro to LLMs - Attention Mechanism - Image Generation/Captioning - Intro to Responsible AI From the fundamentals of LLMs to creating & deploying generative AI solutions!,,,,,
"*** CÃ¢u há»i phá»ng váº¥n ***
Em lÃ  AI engineer, kinh nghiá»‡m 2.5 nÄƒm, em sáº¯p Ä‘i phá»ng váº¥n mÃ  táº¡i Ä‘Ã³ giá» em lÃ m 1 cÃ´ng ty, chá»§ yáº¿u lÃ m computer vision nÃªn hÆ¡i tá»± ti 1 tÃ­.
Má»—i ngÆ°á»i Ä‘i qua tháº¥y post cá»§a em cÃ³ thá»ƒ cho em 1 vÃ i cÃ¢u há»i phá»ng váº¥n liÃªn quan hoáº·c 1 bÃ i toÃ¡n gÃ¬ má»i ngÆ°á»i Ä‘Æ°á»£c há»i Ä‘á»ƒ giáº£i quyáº¿t nhanh trong cuá»™c phá»ng váº¥n Ä‘Æ°á»£c ko áº¡?
*** Nhá»¯ng kÄ© nÄƒng cá»§a em
+ Pytorch, Tensoflow
+ MÃ´ hÃ¬nh Yolov7, mask rcnn, efficientnet, efficientdet,...
+ Project thÃ¬ chá»§ yáº¿u liÃªn quan Ä‘áº¿n defect detection, classification, segmentation, theo dÃµi Ä‘á»‘i tÆ°á»£ng báº±ng deepsort.","*** CÃ¢u há»i phá»ng váº¥n *** Em lÃ  AI engineer, kinh nghiá»‡m 2.5 nÄƒm, em sáº¯p Ä‘i phá»ng váº¥n mÃ  táº¡i Ä‘Ã³ giá» em lÃ m 1 cÃ´ng ty, chá»§ yáº¿u lÃ m computer vision nÃªn hÆ¡i tá»± ti 1 tÃ­. Má»—i ngÆ°á»i Ä‘i qua tháº¥y post cá»§a em cÃ³ thá»ƒ cho em 1 vÃ i cÃ¢u há»i phá»ng váº¥n liÃªn quan hoáº·c 1 bÃ i toÃ¡n gÃ¬ má»i ngÆ°á»i Ä‘Æ°á»£c há»i Ä‘á»ƒ giáº£i quyáº¿t nhanh trong cuá»™c phá»ng váº¥n Ä‘Æ°á»£c ko áº¡? *** Nhá»¯ng kÄ© nÄƒng cá»§a em + Pytorch, Tensoflow + MÃ´ hÃ¬nh Yolov7, mask rcnn, efficientnet, efficientdet,... + Project thÃ¬ chá»§ yáº¿u liÃªn quan Ä‘áº¿n defect detection, classification, segmentation, theo dÃµi Ä‘á»‘i tÆ°á»£ng báº±ng deepsort.",,,"#Q&A, #cv, #machine_learning",,
"Cho há»i cÃ³ ai biáº¿t trang opnai.net ko? MÃ¬nh tháº¥y nÃ³ tráº£ lá»i cÃ¢u há»i cÅ©ng giá»‘ng chat gpt, ko biáº¿t cÃ³ pháº£i trang máº¡o danh nháº±m má»¥c Ä‘Ã­ch gÃ¬ á»Ÿ ngÆ°á»i dÃ¹ng ko hay lÃ  trang nÃ y muá»‘n giÃºp cho ngÆ°á»i viá»‡t Ä‘Æ°á»£c dÃ¹ng chatgpt táº¡i vn?","Cho há»i cÃ³ ai biáº¿t trang opnai.net ko? MÃ¬nh tháº¥y nÃ³ tráº£ lá»i cÃ¢u há»i cÅ©ng giá»‘ng chat gpt, ko biáº¿t cÃ³ pháº£i trang máº¡o danh nháº±m má»¥c Ä‘Ã­ch gÃ¬ á»Ÿ ngÆ°á»i dÃ¹ng ko hay lÃ  trang nÃ y muá»‘n giÃºp cho ngÆ°á»i viá»‡t Ä‘Æ°á»£c dÃ¹ng chatgpt táº¡i vn?",,,"#Q&A, #nlp",,
Tool cho ae dÃ¹ng AI chá»‰nh sá»­a áº£nh.,Tool cho ae dÃ¹ng AI chá»‰nh sá»­a áº£nh.,,,"#sharing, #machine_learning",,
"Cháº¯c cÃ¡c báº¡n trong forum nÃ y nhiá»u ngÆ°á»i sá»­ dá»¥ng LaTeX/Overleaf Ä‘á»ƒ soáº¡n tháº£o vÄƒn báº£n, luáº­n vÄƒn, bÃ i bÃ¡o,... Máº·c dÃ¹ cá»™ng Ä‘á»“ng LaTex ráº¥t máº¡nh, nhÆ°ng mÃ¬nh ráº¥t ghÃ©t khi muá»‘n xuáº¥t file pháº£i báº¥m `compile`, chá» nÃ³ quay khÃ¡ lÃ¢u, rá»“i lá»—i (náº¿u cÃ³) tÆ°Æ¡ng Ä‘á»‘i khÃ³ Ä‘á»c. Gáº§n Ä‘Ã¢y ngÃ´n ngá»¯ Rust ná»•i lÃªn thay tháº¿ C/C++, vÃ  rá»“i Typst (https://github.com/typst/typst) vÃ  (online ver. tÆ°Æ¡ng tá»± Overleaf https://typst.app/) Ä‘Æ°á»£c phÃ¡t triá»ƒn nhÆ° lÃ  trÃ¬nh biÃªn soáº¡n má»›i, vÃ  mÃ¬nh nghÄ© Typst tuy cÃ²n non tráº» nhÆ°ng nÃ³ sáº½ cÃ³ chá»— Ä‘á»©ng cá»§a riÃªng nÃ³. Typst xuáº¥t file pdf gáº§n nhÆ° theo thá»i gian tháº­t mÃ  khÃ´ng cáº§n compile. Vá» syntax cá»§a Typst tÆ°Æ¡ng Ä‘á»‘i dá»… Ä‘á»c. Váº­y nÃªn mÃ¬nh thá»­ táº¡o ra 1 template cho viá»‡c biÃªn soáº¡n luáº­n vÄƒn sá»­ dá»¥ng Typst táº¡i Ä‘Ã¢y https://github.com/linhduongtuan/BKHN-Thesis_template_typst. Hi vá»ng, vá»›i template nÃ y cÃ¡c báº¡n cÃ³ thá»ƒ tá»«ng bÆ°á»›c há»c cÃ¡ch sá»­ dá»¥ng Typst vÃ  xa hÆ¡n lÃ  há»c Rust.
ChÃºc má»i ngÆ°á»i buá»•i tá»‘i vui váº»!
Náº¿u cÃ¡c báº¡n tháº¥y repository cá»§a mÃ¬nh thÃº vá»‹, xin Ä‘á»«ng tiáº¿c 1 Star cho nÃ³ nhÃ©. TrÃ¢n trá»ng cáº£m Æ¡n.","Cháº¯c cÃ¡c báº¡n trong forum nÃ y nhiá»u ngÆ°á»i sá»­ dá»¥ng LaTeX/Overleaf Ä‘á»ƒ soáº¡n tháº£o vÄƒn báº£n, luáº­n vÄƒn, bÃ i bÃ¡o,... Máº·c dÃ¹ cá»™ng Ä‘á»“ng LaTex ráº¥t máº¡nh, nhÆ°ng mÃ¬nh ráº¥t ghÃ©t khi muá»‘n xuáº¥t file pháº£i báº¥m `compile`, chá» nÃ³ quay khÃ¡ lÃ¢u, rá»“i lá»—i (náº¿u cÃ³) tÆ°Æ¡ng Ä‘á»‘i khÃ³ Ä‘á»c. Gáº§n Ä‘Ã¢y ngÃ´n ngá»¯ Rust ná»•i lÃªn thay tháº¿ C/C++, vÃ  rá»“i Typst (https://github.com/typst/typst) vÃ  (online ver. tÆ°Æ¡ng tá»± Overleaf https://typst.app/) Ä‘Æ°á»£c phÃ¡t triá»ƒn nhÆ° lÃ  trÃ¬nh biÃªn soáº¡n má»›i, vÃ  mÃ¬nh nghÄ© Typst tuy cÃ²n non tráº» nhÆ°ng nÃ³ sáº½ cÃ³ chá»— Ä‘á»©ng cá»§a riÃªng nÃ³. Typst xuáº¥t file pdf gáº§n nhÆ° theo thá»i gian tháº­t mÃ  khÃ´ng cáº§n compile. Vá» syntax cá»§a Typst tÆ°Æ¡ng Ä‘á»‘i dá»… Ä‘á»c. Váº­y nÃªn mÃ¬nh thá»­ táº¡o ra 1 template cho viá»‡c biÃªn soáº¡n luáº­n vÄƒn sá»­ dá»¥ng Typst táº¡i Ä‘Ã¢y https://github.com/linhduongtuan/BKHN-Thesis_template_typst. Hi vá»ng, vá»›i template nÃ y cÃ¡c báº¡n cÃ³ thá»ƒ tá»«ng bÆ°á»›c há»c cÃ¡ch sá»­ dá»¥ng Typst vÃ  xa hÆ¡n lÃ  há»c Rust. ChÃºc má»i ngÆ°á»i buá»•i tá»‘i vui váº»! Náº¿u cÃ¡c báº¡n tháº¥y repository cá»§a mÃ¬nh thÃº vá»‹, xin Ä‘á»«ng tiáº¿c 1 Star cho nÃ³ nhÃ©. TrÃ¢n trá»ng cáº£m Æ¡n.",,,#sharing,,
"Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t danh sÃ¡ch dÃ i tá»•ng há»£p nhá»¯ng textbooks xuáº¥t sáº¯c vá» cÃ¡c chá»§ Ä‘á» tá»« Machine Learning, Statistical Learning, Optimization, Optimal Transport, Algebraic Statisics, etc Ä‘Æ°á»£c chia sáº» miá»…n phÃ­ Ä‘áº¿n vá»›i cá»™ng Ä‘á»“ng bá»Ÿi chÃ­nh nhá»¯ng tÃ¡c giáº£ viáº¿t ra nhá»¯ng cuá»‘n sÃ¡ch nÃ y, vá»›i tÃªn tuá»•i lá»›n hÃ ng Ä‘áº§u trong giá»›i khoa há»c nhÆ° Sutton (RL), Szeliski (CompVis), Hastie (Stats), Villani (OT)
Danh sÃ¡ch Ä‘Æ°á»£c tá»•ng há»£p vÃ  chia sáº» bá»Ÿi Dr. Frank Nielsen: https://franknielsen.github.io/Books/CuratedBookLists.html","Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t danh sÃ¡ch dÃ i tá»•ng há»£p nhá»¯ng textbooks xuáº¥t sáº¯c vá» cÃ¡c chá»§ Ä‘á» tá»« Machine Learning, Statistical Learning, Optimization, Optimal Transport, Algebraic Statisics, etc Ä‘Æ°á»£c chia sáº» miá»…n phÃ­ Ä‘áº¿n vá»›i cá»™ng Ä‘á»“ng bá»Ÿi chÃ­nh nhá»¯ng tÃ¡c giáº£ viáº¿t ra nhá»¯ng cuá»‘n sÃ¡ch nÃ y, vá»›i tÃªn tuá»•i lá»›n hÃ ng Ä‘áº§u trong giá»›i khoa há»c nhÆ° Sutton (RL), Szeliski (CompVis), Hastie (Stats), Villani (OT) Danh sÃ¡ch Ä‘Æ°á»£c tá»•ng há»£p vÃ  chia sáº» bá»Ÿi Dr. Frank Nielsen: https://franknielsen.github.io/Books/CuratedBookLists.html",,,"#sharing, #machine_learning, #math",,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang scan kháº£ nÄƒng sá»­ dá»¥ng YoLo vÃ o nhá»¯ng á»©ng dá»¥ng trong nghiÃªn cá»©u cá»§a mÃ¬nh táº¡i Nauy. Cá»¥ thá»ƒ lÃ  kiá»ƒu nhÆ° hÃ¬nh vÃ  link phÃ­a dÆ°á»›i trong nhÆ°ng lÃ  monitor cÃ¡c háº¡t ráº¯n trong lÃ² pháº£n á»©ng cá»§a mÃ¬nh thÃ´ng qua camera.
Trong nhÃ³m nÃ y cÃ³ ACE nÃ o Ä‘Ã£ lÃ m vá»›i YoLo khÃ´ng cho mÃ¬nh xin chÃºt Ã­t kinh nghiá»‡m/Input, comment hoáº·c ib mÃ¬nh sáº½ liÃªn láº¡c trao Ä‘á»•i thÃªm nhÃ©.
Cáº£m Æ¡n má»i
https://www.youtube.com/watch?v=dm3FcR_WrvQ","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang scan kháº£ nÄƒng sá»­ dá»¥ng YoLo vÃ o nhá»¯ng á»©ng dá»¥ng trong nghiÃªn cá»©u cá»§a mÃ¬nh táº¡i Nauy. Cá»¥ thá»ƒ lÃ  kiá»ƒu nhÆ° hÃ¬nh vÃ  link phÃ­a dÆ°á»›i trong nhÆ°ng lÃ  monitor cÃ¡c háº¡t ráº¯n trong lÃ² pháº£n á»©ng cá»§a mÃ¬nh thÃ´ng qua camera. Trong nhÃ³m nÃ y cÃ³ ACE nÃ o Ä‘Ã£ lÃ m vá»›i YoLo khÃ´ng cho mÃ¬nh xin chÃºt Ã­t kinh nghiá»‡m/Input, comment hoáº·c ib mÃ¬nh sáº½ liÃªn láº¡c trao Ä‘á»•i thÃªm nhÃ©. Cáº£m Æ¡n má»i https://www.youtube.com/watch?v=dm3FcR_WrvQ",,,"#Q&A, #cv, #deep_learning",,
"Xin chÃ o má»i ngÆ°á»i
MÃ¬nh Ä‘ang muá»‘n tÃ¬m há»c vá» AI nhÆ°ng chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vÃ  cáº§n há»c nhá»¯ng gÃ¬
Mong muá»‘n cá»§a mÃ¬nh lÃ  cÃ³ thá»ƒ sá»­ dá»¥ng AI Ã¡p dá»¥ng vÃ o lÄ©nh vá»±c pháº§n má»m,cÃ¡c tool há»— trá»£ trong lÄ©nh vá»±c phÃ¡t triá»ƒn web , app
Mong má»i ngÆ°á»i tÆ° váº¥n lá»™ trÃ¬nh áº¡","Xin chÃ o má»i ngÆ°á»i MÃ¬nh Ä‘ang muá»‘n tÃ¬m há»c vá» AI nhÆ°ng chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vÃ  cáº§n há»c nhá»¯ng gÃ¬ Mong muá»‘n cá»§a mÃ¬nh lÃ  cÃ³ thá»ƒ sá»­ dá»¥ng AI Ã¡p dá»¥ng vÃ o lÄ©nh vá»±c pháº§n má»m,cÃ¡c tool há»— trá»£ trong lÄ©nh vá»±c phÃ¡t triá»ƒn web , app Mong má»i ngÆ°á»i tÆ° váº¥n lá»™ trÃ¬nh áº¡",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i em cÃ³ 2 cÃ¢u há»i nÃ y vá» universal approximation theorem:
1/ MLP cÃ³ thá»ƒ xáº¥p xá»‰ skip connection vÃ  recurrent connection khÃ´ng?
2/ CNN cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ i Ä‘áº·t báº±ng MLP, nhÆ°ng cÅ©ng cÃ³ thá»ƒ coi MLP lÃ  CNN vá»›i kernel spatial size báº±ng 1x1. Váº­y CNN vÃ  MLP cÃ¡i nÃ o ""tá»•ng quÃ¡t"" hÆ¡n? Náº¿u CNN ""tá»•ng quÃ¡t"" hÆ¡n, nÃ³ cÃ³ riÃªng cho mÃ¬nh má»™t approximation theorem khÃ´ng? TÆ°Æ¡ng tá»±, RNN, máº¡ng cÃ³ skip connection, v.v. cÃ³ approximation theorem cho riÃªng nÃ³ khÃ´ng?
Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i em cÃ³ 2 cÃ¢u há»i nÃ y vá» universal approximation theorem: 1/ MLP cÃ³ thá»ƒ xáº¥p xá»‰ skip connection vÃ  recurrent connection khÃ´ng? 2/ CNN cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ i Ä‘áº·t báº±ng MLP, nhÆ°ng cÅ©ng cÃ³ thá»ƒ coi MLP lÃ  CNN vá»›i kernel spatial size báº±ng 1x1. Váº­y CNN vÃ  MLP cÃ¡i nÃ o ""tá»•ng quÃ¡t"" hÆ¡n? Náº¿u CNN ""tá»•ng quÃ¡t"" hÆ¡n, nÃ³ cÃ³ riÃªng cho mÃ¬nh má»™t approximation theorem khÃ´ng? TÆ°Æ¡ng tá»±, RNN, máº¡ng cÃ³ skip connection, v.v. cÃ³ approximation theorem cho riÃªng nÃ³ khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i.",,,"#Q&A, #deep_learning",,
"Em chÃ o anh chá»‹ trong nhÃ³m áº¡. Hiá»‡n em Ä‘Ã£ tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i, em Ä‘ang tÃ¬m viá»‡c Intern/fresher vá» Machine Learning/AI/Deep Learning táº¡i HÃ  Ná»™i. KhÃ´ng biáº¿t anh/chá»‹ á»Ÿ cÃ´ng ty nÃ o cÃ³ cÃ²n open cho vá»‹ trÃ­ Intern/fresher khÃ´ng áº¡? Em sáº½ chá»§ Ä‘á»™ng inbox gá»­i CV áº¡.","Em chÃ o anh chá»‹ trong nhÃ³m áº¡. Hiá»‡n em Ä‘Ã£ tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i, em Ä‘ang tÃ¬m viá»‡c Intern/fresher vá» Machine Learning/AI/Deep Learning táº¡i HÃ  Ná»™i. KhÃ´ng biáº¿t anh/chá»‹ á»Ÿ cÃ´ng ty nÃ o cÃ³ cÃ²n open cho vá»‹ trÃ­ Intern/fresher khÃ´ng áº¡? Em sáº½ chá»§ Ä‘á»™ng inbox gá»­i CV áº¡.",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh xin giá»›i thiá»‡u chuá»—i seminar thÃº vá»‹ vá» viá»‡c cung cáº¥p ná»n táº£ng vá» viá»‡c triá»ƒn khai ML models vá»›i nhá»¯ng kiáº¿n thá»©c trong industry.
1. Seminar 1 (5/6): MLOps Marathon Sample Solution
2. Seminar 2 (6/6): Fundamental Series: Linux basics
3. Seminar 3 (7/6): Fundamental Series: Git, Github and Github actions
4. Seminar 4 (8/6): Containerization and Orchestration
5. Seminar 5 (13/6): WebAPI, FastAPI and NGINX
6. Seminar 6 (14/6): Data Drift and Solutions","ChÃ o má»i ngÆ°á»i, mÃ¬nh xin giá»›i thiá»‡u chuá»—i seminar thÃº vá»‹ vá» viá»‡c cung cáº¥p ná»n táº£ng vá» viá»‡c triá»ƒn khai ML models vá»›i nhá»¯ng kiáº¿n thá»©c trong industry. 1. Seminar 1 (5/6): MLOps Marathon Sample Solution 2. Seminar 2 (6/6): Fundamental Series: Linux basics 3. Seminar 3 (7/6): Fundamental Series: Git, Github and Github actions 4. Seminar 4 (8/6): Containerization and Orchestration 5. Seminar 5 (13/6): WebAPI, FastAPI and NGINX 6. Seminar 6 (14/6): Data Drift and Solutions",,,"#sharing, #machine_learning",,
"Xin chÃ o cÃ¡c anh em, hiá»‡n táº¡i em Ä‘ang gáº·p váº¥n Ä‘á» vá» Ä‘á»™ chÃ­nh xÃ¡c khi sá»­ dá»¥ng Python Ä‘á»ƒ Ä‘á»c káº¿t quáº£ trÃªn mÃ´ hÃ¬nh ONNX. Cá»¥ thá»ƒ hÆ¡n, trÃªn mÃ´i trÆ°á»ng Visual Studio, em sá»­ dá»¥ng mÃ´ hÃ¬nh tá»± Ä‘á»™ng (AutoML) Ä‘á»ƒ phÃ¢n lá»›p hÃ¬nh áº£nh (Image Classification) cá»§a ML.NET, Ä‘áº§u vÃ o lÃ  7 lá»›p. MÃ´ hÃ¬nh cá»§a AutoML sá»­ dá»¥ng huáº¥n luyá»‡n lÃ  DNN + ResNeXt-50. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ  100% Ä‘á»™ chÃ­nh xÃ¡c, em cÃ³ thá»­ 10 hÃ¬nh áº£nh test cho má»—i lá»›p, káº¿t quáº£ Ä‘á»u Ä‘Ãºng. Tuy nhiÃªn khi sá»­ dá»¥ng mÃ´ hÃ¬nh ONNX Ä‘á»ƒ sá»­ dá»¥ng trÃªn mÃ´i trÆ°á»ng Python cá»§a Google Colab. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ  hoÃ n toÃ n khÃ´ng chÃ­nh xÃ¡c. Cá»¥ thá»ƒ, khi em Ä‘Æ°a báº¥t cá»© hÃ¬nh áº£nh nÃ o vÃ o, káº¿t quáº£ cÅ©ng chá»‰ Ä‘áº¡t Ä‘Æ°á»£c lÃ  duy nháº¥t. Em Ä‘Ã£ thá»­ chuyá»ƒn mÃ´ hÃ¬nh onnx sang Tensorflow báº±ng thÆ° viá»‡n onnx2tf nhÆ°ng cÅ©ng chá»‰ cho ra má»™t káº¿t quáº£ duy nháº¥t. Em hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ giÃºp em cÃ³ cÃ¡ch nÃ o cÃ³ káº¿t quáº£ mÃ´ hÃ¬nh ONNX Ä‘Ãºng nháº¥t. DÆ°á»›i Ä‘Ã¢y lÃ  link post issue trÃªn Github, tuy váº­y cÅ©ng khÃ¡ lÃ¢u rá»“i chÆ°a cÃ³ cÃ¡ch nÃ o cáº£i thiá»‡n Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y cáº£.
https://github.com/microsoft/onnxruntime/issues/16001#issuecomment-1554819072
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem bÃ i vÃ  mong má»i ngÆ°á»i giÃºp Ä‘á»¡ em.","Xin chÃ o cÃ¡c anh em, hiá»‡n táº¡i em Ä‘ang gáº·p váº¥n Ä‘á» vá» Ä‘á»™ chÃ­nh xÃ¡c khi sá»­ dá»¥ng Python Ä‘á»ƒ Ä‘á»c káº¿t quáº£ trÃªn mÃ´ hÃ¬nh ONNX. Cá»¥ thá»ƒ hÆ¡n, trÃªn mÃ´i trÆ°á»ng Visual Studio, em sá»­ dá»¥ng mÃ´ hÃ¬nh tá»± Ä‘á»™ng (AutoML) Ä‘á»ƒ phÃ¢n lá»›p hÃ¬nh áº£nh (Image Classification) cá»§a ML.NET, Ä‘áº§u vÃ o lÃ  7 lá»›p. MÃ´ hÃ¬nh cá»§a AutoML sá»­ dá»¥ng huáº¥n luyá»‡n lÃ  DNN + ResNeXt-50. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ  100% Ä‘á»™ chÃ­nh xÃ¡c, em cÃ³ thá»­ 10 hÃ¬nh áº£nh test cho má»—i lá»›p, káº¿t quáº£ Ä‘á»u Ä‘Ãºng. Tuy nhiÃªn khi sá»­ dá»¥ng mÃ´ hÃ¬nh ONNX Ä‘á»ƒ sá»­ dá»¥ng trÃªn mÃ´i trÆ°á»ng Python cá»§a Google Colab. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ  hoÃ n toÃ n khÃ´ng chÃ­nh xÃ¡c. Cá»¥ thá»ƒ, khi em Ä‘Æ°a báº¥t cá»© hÃ¬nh áº£nh nÃ o vÃ o, káº¿t quáº£ cÅ©ng chá»‰ Ä‘áº¡t Ä‘Æ°á»£c lÃ  duy nháº¥t. Em Ä‘Ã£ thá»­ chuyá»ƒn mÃ´ hÃ¬nh onnx sang Tensorflow báº±ng thÆ° viá»‡n onnx2tf nhÆ°ng cÅ©ng chá»‰ cho ra má»™t káº¿t quáº£ duy nháº¥t. Em hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ giÃºp em cÃ³ cÃ¡ch nÃ o cÃ³ káº¿t quáº£ mÃ´ hÃ¬nh ONNX Ä‘Ãºng nháº¥t. DÆ°á»›i Ä‘Ã¢y lÃ  link post issue trÃªn Github, tuy váº­y cÅ©ng khÃ¡ lÃ¢u rá»“i chÆ°a cÃ³ cÃ¡ch nÃ o cáº£i thiá»‡n Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y cáº£. https://github.com/microsoft/onnxruntime/issues/16001#issuecomment-1554819072 Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem bÃ i vÃ  mong má»i ngÆ°á»i giÃºp Ä‘á»¡ em.",,,"#Q&A, #machine_learning, #python",,
"Dáº¡ em chÃ o máº¥y Tháº§y, CÃ´, Anh, Chá»‹.
Em lÃ  thÃ nh viÃªn má»›i cá»§a nhÃ³m, hiá»‡n táº¡i em Ä‘ang báº¯t Ä‘áº§u nghiÃªn cá»©u há»c vá» Machine Learning. Cho em há»i Tháº§y, CÃ´, Anh, Chá»‹ nÃ o cÃ³ Lá»™ TrÃ¬nh Há»c hay Website Ä‘á»ƒ há»c Machine Learning cho em tham kháº£o vá»›i Ä‘Æ°á»£c khÃ´ng áº¡.
Em cáº£m Æ¡n cÃ¡c Tháº§y, CÃ´, Anh, Chá»‹ áº¡ ğŸ¥°","Dáº¡ em chÃ o máº¥y Tháº§y, CÃ´, Anh, Chá»‹. Em lÃ  thÃ nh viÃªn má»›i cá»§a nhÃ³m, hiá»‡n táº¡i em Ä‘ang báº¯t Ä‘áº§u nghiÃªn cá»©u há»c vá» Machine Learning. Cho em há»i Tháº§y, CÃ´, Anh, Chá»‹ nÃ o cÃ³ Lá»™ TrÃ¬nh Há»c hay Website Ä‘á»ƒ há»c Machine Learning cho em tham kháº£o vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n cÃ¡c Tháº§y, CÃ´, Anh, Chá»‹ áº¡",,,"#Q&A, #machine_learning",,
"VinAI Seminar - ""Annotation-Efficient Learning for Object Discovery and Detection""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Huy Vo, AI Research Scientist at Meta.
Time: 2:30 pm - 3:30 pm (GMT+7), Tue, Jun 06, 2023","VinAI Seminar - ""Annotation-Efficient Learning for Object Discovery and Detection"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Huy Vo, AI Research Scientist at Meta. Time: 2:30 pm - 3:30 pm (GMT+7), Tue, Jun 06, 2023",,,,,
"Xin chÃ o, cÃ³ tháº§y nÃ o lÃ m mentor data engineer hoáº·c machine learning theo project. Em xin theo há»c vá»›i.","Xin chÃ o, cÃ³ tháº§y nÃ o lÃ m mentor data engineer hoáº·c machine learning theo project. Em xin theo há»c vá»›i.",,,"#Q&A, #machine_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang gáº·p khÃ³ vá» viá»‡c cÃ i tensorflow GPU. Em Ä‘Ã£ cÃ i Ä‘áº§y Ä‘á»§ package vÃ  path nhÆ° trÃªn máº¡ng hÆ°á»›ng dáº«n.
- tensorflow 2.12
cuda 12.1
cudnn 8.1.0.77
python 3.10.11
NhÆ°ng khi kiá»ƒm tra thÃ¬ váº«n khÃ´ng cÃ³ GPU . Mong má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em xin cáº£m Æ¡n áº¡.",Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang gáº·p khÃ³ vá» viá»‡c cÃ i tensorflow GPU. Em Ä‘Ã£ cÃ i Ä‘áº§y Ä‘á»§ package vÃ  path nhÆ° trÃªn máº¡ng hÆ°á»›ng dáº«n. - tensorflow 2.12 cuda 12.1 cudnn 8.1.0.77 python 3.10.11 NhÆ°ng khi kiá»ƒm tra thÃ¬ váº«n khÃ´ng cÃ³ GPU . Mong má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em xin cáº£m Æ¡n áº¡.,,,"#Q&A, #python",,
"Xin chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang há»c mÃ´n machine learning cÆ¡ báº£n vÃ  giáº£ng viÃªn giao cho lÃ m má»™t cÃ¡i project cÃ¡ nhÃ¢n. 
Em Ä‘Ã£ chá»n Ä‘Æ°á»£c má»™t bÃ i bÃ¡o vá» y sinh há»c, cá»¥ thá»ƒ lÃ  em dÃ¹ng mÃ´ hÃ¬nh Bio-Bert Ä‘á»ƒ lÃ m project, nhÆ°ng váº¥n Ä‘á» lÃ  em tÃ¬m hiá»ƒu vÃ  cháº¡y code nhÆ°ng khÃ´ng Ä‘Æ°á»£c
Má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em hiá»ƒu rÃµ hÆ¡n vá» bÃ i bÃ¡o vÃ  Ä‘oáº¡n code Ä‘Æ°á»£c khÃ´ng áº¡, vÃ¬ em cÅ©ng má»›i há»c vá» machine learning nÃªn em tháº¥y code khÃ¡ nhiá»u
Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u
Link bÃ i bÃ¡o: https://paperswithcode.com/paper/biobert-a-pre-trained-biomedical-language
Link code : https://github.com/dmis-lab/biobert/blob/master/README.md","Xin chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang há»c mÃ´n machine learning cÆ¡ báº£n vÃ  giáº£ng viÃªn giao cho lÃ m má»™t cÃ¡i project cÃ¡ nhÃ¢n. Em Ä‘Ã£ chá»n Ä‘Æ°á»£c má»™t bÃ i bÃ¡o vá» y sinh há»c, cá»¥ thá»ƒ lÃ  em dÃ¹ng mÃ´ hÃ¬nh Bio-Bert Ä‘á»ƒ lÃ m project, nhÆ°ng váº¥n Ä‘á» lÃ  em tÃ¬m hiá»ƒu vÃ  cháº¡y code nhÆ°ng khÃ´ng Ä‘Æ°á»£c Má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em hiá»ƒu rÃµ hÆ¡n vá» bÃ i bÃ¡o vÃ  Ä‘oáº¡n code Ä‘Æ°á»£c khÃ´ng áº¡, vÃ¬ em cÅ©ng má»›i há»c vá» machine learning nÃªn em tháº¥y code khÃ¡ nhiá»u Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u Link bÃ i bÃ¡o: https://paperswithcode.com/paper/biobert-a-pre-trained-biomedical-language Link code : https://github.com/dmis-lab/biobert/blob/master/README.md",,,"#Q&A, #machine_learning",,
"Em chÃ o má»i ngÆ°á»i, em Ä‘ang deploy model tensorflow sang graph(.pb) mÃ  khi cv2.dnn.readNetFromTensorflow thÃ¬ khÃ´ng nháº­n Ä‘Æ°á»£c layer nÃ o tá»« model
https://colab.research.google.com/drive/1m-kOQRKsyrfxKVzGrZAx2WT8Fs9IQ_wY?usp=sharing
Mong má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em xin cáº£m Æ¡n","Em chÃ o má»i ngÆ°á»i, em Ä‘ang deploy model tensorflow sang graph(.pb) mÃ  khi cv2.dnn.readNetFromTensorflow thÃ¬ khÃ´ng nháº­n Ä‘Æ°á»£c layer nÃ o tá»« model https://colab.research.google.com/drive/1m-kOQRKsyrfxKVzGrZAx2WT8Fs9IQ_wY?usp=sharing Mong má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em xin cáº£m Æ¡n",,,"#Q&A, #python",,
"MÃ¬nh muá»‘n há»i cÃ¡ch xá»­ lÃ½ bÃ i toÃ¡n há»“i quy logistic nhÆ° tháº¿ nÃ o khi Ä‘áº§u vÃ o nhÆ° hÃ¬nh. HÃ m logit Ä‘Æ°á»£c giáº£ Ä‘á»‹nh lÃ  tuyáº¿n tÃ­nh vá»›i cÃ¡c biáº¿n Ä‘á»™c láº­p x nhÆ°ng Decision boundary lÃºc nÃ y khÃ´ng thá»ƒ lÃ  dáº¡ng tuyáº¿n tÃ­nh a+bX bÃ¬nh thÆ°á»ng mÃ  pháº£i lÃ  phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng trÃ²n. Váº­y lÃ m thá»ƒ nÃ o Ä‘á»ƒ xá»­ lÃ½ Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y, Ä‘áº·c biá»‡t khi ta khÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£c hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u. Tra cá»©u thÃ¬ cÃ³ giáº£i phÃ¡p lÃ  chuyá»ƒn sang há»‡ tá»a Ä‘á»™ cá»±c mÃ  mÃ¬nh khÃ´ng hiá»ƒu láº¯m.","MÃ¬nh muá»‘n há»i cÃ¡ch xá»­ lÃ½ bÃ i toÃ¡n há»“i quy logistic nhÆ° tháº¿ nÃ o khi Ä‘áº§u vÃ o nhÆ° hÃ¬nh. HÃ m logit Ä‘Æ°á»£c giáº£ Ä‘á»‹nh lÃ  tuyáº¿n tÃ­nh vá»›i cÃ¡c biáº¿n Ä‘á»™c láº­p x nhÆ°ng Decision boundary lÃºc nÃ y khÃ´ng thá»ƒ lÃ  dáº¡ng tuyáº¿n tÃ­nh a+bX bÃ¬nh thÆ°á»ng mÃ  pháº£i lÃ  phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng trÃ²n. Váº­y lÃ m thá»ƒ nÃ o Ä‘á»ƒ xá»­ lÃ½ Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y, Ä‘áº·c biá»‡t khi ta khÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£c hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u. Tra cá»©u thÃ¬ cÃ³ giáº£i phÃ¡p lÃ  chuyá»ƒn sang há»‡ tá»a Ä‘á»™ cá»±c mÃ  mÃ¬nh khÃ´ng hiá»ƒu láº¯m.",,,"#Q&A, #machine_learning",,
"ChÃ o má»i ngÆ°á»i, e Ä‘ang lÃ  sinh viÃªn Ä‘i thá»±c táº­p, em Ä‘ang lÃ m 1 project liÃªn quan Ä‘áº¿n bÃ i toÃ¡n mÃ  táº­p train vÃ  test Ä‘áº¿n tá»« 2 phÃ¢n phá»‘i khÃ¡c nhau , anh chá»‹ cÃ³ thá»ƒ cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ train model cÃ³ káº¿t quáº£ cao khÃ´ng áº¡","ChÃ o má»i ngÆ°á»i, e Ä‘ang lÃ  sinh viÃªn Ä‘i thá»±c táº­p, em Ä‘ang lÃ m 1 project liÃªn quan Ä‘áº¿n bÃ i toÃ¡n mÃ  táº­p train vÃ  test Ä‘áº¿n tá»« 2 phÃ¢n phá»‘i khÃ¡c nhau , anh chá»‹ cÃ³ thá»ƒ cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ train model cÃ³ káº¿t quáº£ cao khÃ´ng áº¡",,,"#Q&A, #machine_learning",,
"Váº¥n Ä‘á» cross-validation.
ChÃ o má»i ngÆ°á»i.MÃ¬nh Ä‘ang táº­p tÃ nh thá»±c hÃ nh cÃ¡c project machine learning vÃ  gáº·p má»™t váº¥n Ä‘á» mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp áº¡.
MÃ¬nh cÃ³ 1 bá»™ imbalanced dataset. Theo google thÃ¬ Ä‘á»ƒ xá»­ lÃ½ imbalanced thÃ¬ mÃ¬nh dÃ¹ng StratifiedKFold vá»›i weight Ä‘á»ƒ xá»­ lÃ½. Khi Ä‘Ã³, mÃ¬nh thu Ä‘Æ°á»£c K model vÃ  tÃ­nh trung bÃ¬nh cÃ¡c score trÃªn táº­p valid Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model.
modelX = LogisticClassifier(para_1=a, ....., para_n = t)
kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=12).split(X,y)
Sau Ä‘Ã³, mÃ¬nh láº¡i cÃ³ 1 bá»™ test set hoÃ n toÃ n tÃ¡ch biá»‡t vá»›i bá»™ data trÃªn Ä‘á»ƒ dá»± Ä‘oÃ¡n. LÃºc Ä‘áº¥y mÃ¬nh suy nghÄ© Ä‘áº¿n viá»‡c cÃ³ pháº£i nÃªn lá»±a chá»n model cÃ³ perform tá»‘t nháº¥t trong K model Ä‘Ã³ Ä‘á»ƒ predict cho test set Ä‘Ãºng khÃ´ng? MÃ¬nh cÃ³ tra google vÃ  theo kháº£ nÄƒng Ä‘á»c hiá»ƒu cá»§a báº£n thÃ¢n thÃ¬, viá»‡c cross-valid trÃªn K model trÃªn thá»±c cháº¥t chá»‰ lÃ  má»™t cÃ¡ch Ä‘á»ƒ kiá»ƒm tra performance vÃ  Ä‘á» phÃ²ng TH bá»™ train -val cá»§a mÃ¬nh bá»‹ chia lá»‡ch. CÃ²n thá»±c cháº¥t khi predict ta sáº½ váº«n predict trÃªn model ban Ä‘áº§u (kiá»ƒu y_pred=modelX.predict(X_test)) Ä‘Ãºng khÃ´ng má»i ngÆ°á»i.CÃ²n viá»‡c Ä‘á»•i performance thÃ¬ phá»¥ thuá»™c vÃ o viá»‡c mÃ¬nh hiá»‡u chá»‰nh parameter nhÆ° tháº¿ nÃ o.
KhÃ´ng biáº¿t mÃ¬nh hiá»ƒu váº¥n Ä‘á» nhÆ° váº­y cÃ³ Ä‘Ãºng khÃ´ng má»i ngÆ°á»i? MÃ¬nh mong nháº­n Ä‘Æ°á»£c sá»± giáº£i Ä‘Ã¡p cá»§a má»i ngÆ°á»i áº¡.","Váº¥n Ä‘á» cross-validation. ChÃ o má»i ngÆ°á»i.MÃ¬nh Ä‘ang táº­p tÃ nh thá»±c hÃ nh cÃ¡c project machine learning vÃ  gáº·p má»™t váº¥n Ä‘á» mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp áº¡. MÃ¬nh cÃ³ 1 bá»™ imbalanced dataset. Theo google thÃ¬ Ä‘á»ƒ xá»­ lÃ½ imbalanced thÃ¬ mÃ¬nh dÃ¹ng StratifiedKFold vá»›i weight Ä‘á»ƒ xá»­ lÃ½. Khi Ä‘Ã³, mÃ¬nh thu Ä‘Æ°á»£c K model vÃ  tÃ­nh trung bÃ¬nh cÃ¡c score trÃªn táº­p valid Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model. modelX = LogisticClassifier(para_1=a, ....., para_n = t) kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=12).split(X,y) Sau Ä‘Ã³, mÃ¬nh láº¡i cÃ³ 1 bá»™ test set hoÃ n toÃ n tÃ¡ch biá»‡t vá»›i bá»™ data trÃªn Ä‘á»ƒ dá»± Ä‘oÃ¡n. LÃºc Ä‘áº¥y mÃ¬nh suy nghÄ© Ä‘áº¿n viá»‡c cÃ³ pháº£i nÃªn lá»±a chá»n model cÃ³ perform tá»‘t nháº¥t trong K model Ä‘Ã³ Ä‘á»ƒ predict cho test set Ä‘Ãºng khÃ´ng? MÃ¬nh cÃ³ tra google vÃ  theo kháº£ nÄƒng Ä‘á»c hiá»ƒu cá»§a báº£n thÃ¢n thÃ¬, viá»‡c cross-valid trÃªn K model trÃªn thá»±c cháº¥t chá»‰ lÃ  má»™t cÃ¡ch Ä‘á»ƒ kiá»ƒm tra performance vÃ  Ä‘á» phÃ²ng TH bá»™ train -val cá»§a mÃ¬nh bá»‹ chia lá»‡ch. CÃ²n thá»±c cháº¥t khi predict ta sáº½ váº«n predict trÃªn model ban Ä‘áº§u (kiá»ƒu y_pred=modelX.predict(X_test)) Ä‘Ãºng khÃ´ng má»i ngÆ°á»i.CÃ²n viá»‡c Ä‘á»•i performance thÃ¬ phá»¥ thuá»™c vÃ o viá»‡c mÃ¬nh hiá»‡u chá»‰nh parameter nhÆ° tháº¿ nÃ o. KhÃ´ng biáº¿t mÃ¬nh hiá»ƒu váº¥n Ä‘á» nhÆ° váº­y cÃ³ Ä‘Ãºng khÃ´ng má»i ngÆ°á»i? MÃ¬nh mong nháº­n Ä‘Æ°á»£c sá»± giáº£i Ä‘Ã¡p cá»§a má»i ngÆ°á»i áº¡.",,,"#Q&A, #machine_learning, #data",,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh hiá»‡n táº¡i Ä‘ang lÃ m viá»‡c trong lÄ©nh vá»±c Web scraping vá» quáº£ng cÃ¡o báº¥t Ä‘á»™ng sáº£n/xe hÆ¡i vÃ  MLOps. MÃ¬nh muá»‘n Ä‘Ã³ng gÃ³p/há»— trá»£ cÃ¡c dá»± Ã¡n cÃ´ng Ä‘á»“ng Ä‘á»ƒ trao dá»“i thÃªm kinh nghiá»‡m vá» MLOps.
Náº¿u mn cÃ³ dá»± Ã¡n cÃ´ng Ä‘á»“ng nÃ o cáº§n thu tháº­p public data hoáº·c xÃ¢y dá»±ng ML pipelines thÃ¬ ping mÃ¬nh nhÃ©.","ChÃ o má»i ngÆ°á»i, MÃ¬nh hiá»‡n táº¡i Ä‘ang lÃ m viá»‡c trong lÄ©nh vá»±c Web scraping vá» quáº£ng cÃ¡o báº¥t Ä‘á»™ng sáº£n/xe hÆ¡i vÃ  MLOps. MÃ¬nh muá»‘n Ä‘Ã³ng gÃ³p/há»— trá»£ cÃ¡c dá»± Ã¡n cÃ´ng Ä‘á»“ng Ä‘á»ƒ trao dá»“i thÃªm kinh nghiá»‡m vá» MLOps. Náº¿u mn cÃ³ dá»± Ã¡n cÃ´ng Ä‘á»“ng nÃ o cáº§n thu tháº­p public data hoáº·c xÃ¢y dá»±ng ML pipelines thÃ¬ ping mÃ¬nh nhÃ©.",,,"#Q&A, #machine_learning, #data",,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh vá»«a phá»ng váº¥n á»Ÿ má»™t cÃ´ng ty á»Ÿ Anh tuyá»ƒn summer internship á»Ÿ vá»‹ trÃ­ Machine Learning, mÃ¬nh muá»‘n viáº¿t bÃ i nÃ y Ä‘á»ƒ chia sáº½ Ä‘á»£t phá»ng váº¥n nÃ y má»¥c Ä‘Ã­ch Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng nhau bÃ n luáº­n vÃ¬ mÃ¬nh cÅ©ng chÆ°a biáº¿t lÃ  cÃ¢u tráº£ lá»i cá»§a mÃ¬nh lÃ  á»•n chÆ°a, cá»¥ thá»ƒ lÃ  nhÆ° sau:
CÃ´ng ty há» nghiÃªn cá»©u vá» Hyperspectral Camera(Camera quang phá»•) cá»¥ thá»ƒ lÃ  táº¥m hÃ¬nh sáº½ cÃ³ hÆ¡n 50 chiá»u khÃ´ng gian mÃ u thay vÃ¬ chá»‰ cÃ³ 3. Khi sá»­ dá»¥ng hyperspectral images thÃ¬ dá»¯ liá»‡u sáº½ chÃ­nh xÃ¡c vÃ  nhiá»u thÃ´ng tin hÆ¡n. MÃ¬nh Ä‘áº¿n Ä‘á»£t phá»ng váº¥n 2 cÃ³ cÃ¢u há»i nhÆ° sau:
ThÃ¬ há» há»i mÃ¬nh Ä‘áº¡i khÃ¡i lÃ : Báº¡n cÃ³ nhá»¯ng cÃ¡ch nÃ o Ä‘á»ƒ compress má»™t bá»©c hÃ¬nh vÃ  Ä‘á»‘i vá»›i hyperspectral images thÃ¬ lÃ m sao?
MÃ¬nh suy nghÄ© má»™t chÃºt vÃ  tráº£ lá»i nhÆ° sau: má»™t cÃ¡ch mÃ¬nh cÃ³ thá»ƒ nghÄ© ra liá»n lÃ  cÃ³ thá»ƒ dÃ¹ng convolutional methods nhÆ° má»™t bá»©c hÃ¬nh bÃ¬nh thÆ°á»ng hoáº·c PCA
Há» há»i thÃªm lÃ : Váº­y báº¡n cÃ³ biáº¿t effects sau khi deploy methods nhÆ° váº­y lÃ  gÃ¬ khÃ´ng?
LÃºc Ä‘Ã³ mÃ¬nh tráº£ lá»i Ä‘Æ¡n giáº£n lÃ  sáº½ giáº£m cháº¥t lÆ°á»£ng vÃ  thÃ´ng tin dá»¯ liá»‡u
LÃºc Ä‘Ã³ mÃ¬nh hÆ¡i run nÃªn cÅ©ng khÃ´ng hÃ¬nh dung Ä‘Æ°á»£c cÃ³ cÃ¡ch nÃ o ná»¯a.
LÃºc cuá»‘i mÃ¬nh há»i thÃªm ráº±ng cÃ³ pháº£i viá»‡c compress hyperspectral images lÃ  má»™t trong nhá»¯ng váº¥n Ä‘á» team nghiÃªn cá»©u Ä‘ang Ä‘á»‘i máº·t Ä‘Ãºng khÃ´ng? ThÃ¬ há» nÃ³i Ä‘Ãºng váº­y tháº­t.
Tháº­t sá»± mÃ¬nh tá»± há»c khÃ¡ nhiá»u nÃªn kinh nghiá»‡m cÃ²n ráº¥t Ã­t nÃªn khi phá»ng váº¥n mÃ¬nh chá»‰ tráº£ lá»i nhá»¯ng gÃ¬ mÃ¬nh nghÄ© ra liá»n lÃºc Ä‘Ã³ thÃ´i.
Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m trong máº£ng nÃ y, cho mÃ¬nh há»i cÃ³ cÃ¢u tráº£ lá»i nÃ o tá»‘t hÆ¡n cho bá»©c hÃ¬nh 50+ khÃ´ng gian mÃ u nhÆ° váº­y khÃ´ng? MÃ¬nh cáº£m Æ¡n","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh vá»«a phá»ng váº¥n á»Ÿ má»™t cÃ´ng ty á»Ÿ Anh tuyá»ƒn summer internship á»Ÿ vá»‹ trÃ­ Machine Learning, mÃ¬nh muá»‘n viáº¿t bÃ i nÃ y Ä‘á»ƒ chia sáº½ Ä‘á»£t phá»ng váº¥n nÃ y má»¥c Ä‘Ã­ch Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng nhau bÃ n luáº­n vÃ¬ mÃ¬nh cÅ©ng chÆ°a biáº¿t lÃ  cÃ¢u tráº£ lá»i cá»§a mÃ¬nh lÃ  á»•n chÆ°a, cá»¥ thá»ƒ lÃ  nhÆ° sau: CÃ´ng ty há» nghiÃªn cá»©u vá» Hyperspectral Camera(Camera quang phá»•) cá»¥ thá»ƒ lÃ  táº¥m hÃ¬nh sáº½ cÃ³ hÆ¡n 50 chiá»u khÃ´ng gian mÃ u thay vÃ¬ chá»‰ cÃ³ 3. Khi sá»­ dá»¥ng hyperspectral images thÃ¬ dá»¯ liá»‡u sáº½ chÃ­nh xÃ¡c vÃ  nhiá»u thÃ´ng tin hÆ¡n. MÃ¬nh Ä‘áº¿n Ä‘á»£t phá»ng váº¥n 2 cÃ³ cÃ¢u há»i nhÆ° sau: ThÃ¬ há» há»i mÃ¬nh Ä‘áº¡i khÃ¡i lÃ : Báº¡n cÃ³ nhá»¯ng cÃ¡ch nÃ o Ä‘á»ƒ compress má»™t bá»©c hÃ¬nh vÃ  Ä‘á»‘i vá»›i hyperspectral images thÃ¬ lÃ m sao? MÃ¬nh suy nghÄ© má»™t chÃºt vÃ  tráº£ lá»i nhÆ° sau: má»™t cÃ¡ch mÃ¬nh cÃ³ thá»ƒ nghÄ© ra liá»n lÃ  cÃ³ thá»ƒ dÃ¹ng convolutional methods nhÆ° má»™t bá»©c hÃ¬nh bÃ¬nh thÆ°á»ng hoáº·c PCA Há» há»i thÃªm lÃ : Váº­y báº¡n cÃ³ biáº¿t effects sau khi deploy methods nhÆ° váº­y lÃ  gÃ¬ khÃ´ng? LÃºc Ä‘Ã³ mÃ¬nh tráº£ lá»i Ä‘Æ¡n giáº£n lÃ  sáº½ giáº£m cháº¥t lÆ°á»£ng vÃ  thÃ´ng tin dá»¯ liá»‡u LÃºc Ä‘Ã³ mÃ¬nh hÆ¡i run nÃªn cÅ©ng khÃ´ng hÃ¬nh dung Ä‘Æ°á»£c cÃ³ cÃ¡ch nÃ o ná»¯a. LÃºc cuá»‘i mÃ¬nh há»i thÃªm ráº±ng cÃ³ pháº£i viá»‡c compress hyperspectral images lÃ  má»™t trong nhá»¯ng váº¥n Ä‘á» team nghiÃªn cá»©u Ä‘ang Ä‘á»‘i máº·t Ä‘Ãºng khÃ´ng? ThÃ¬ há» nÃ³i Ä‘Ãºng váº­y tháº­t. Tháº­t sá»± mÃ¬nh tá»± há»c khÃ¡ nhiá»u nÃªn kinh nghiá»‡m cÃ²n ráº¥t Ã­t nÃªn khi phá»ng váº¥n mÃ¬nh chá»‰ tráº£ lá»i nhá»¯ng gÃ¬ mÃ¬nh nghÄ© ra liá»n lÃºc Ä‘Ã³ thÃ´i. Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m trong máº£ng nÃ y, cho mÃ¬nh há»i cÃ³ cÃ¢u tráº£ lá»i nÃ o tá»‘t hÆ¡n cho bá»©c hÃ¬nh 50+ khÃ´ng gian mÃ u nhÆ° váº­y khÃ´ng? MÃ¬nh cáº£m Æ¡n",,,"#Q&A, #machine_learning",,
"HÃ´m nay check github cá»§a sÃ¡ch chá»£t nháº­n ra Ä‘Ã£ Ä‘Æ°á»£c gáº§n 1k stars :)
CÃ¡c báº¡n cÃ³ thá»ƒ táº£i sÃ¡ch miá»…n phÃ­ táº¡i https://github.com/tiepvupsu/ebookMLCB. Äá»«ng quÃªn Ä‘á»ƒ láº¡i má»™t star náº¿u báº¡n tháº¥y há»¯u Ã­ch.",HÃ´m nay check github cá»§a sÃ¡ch chá»£t nháº­n ra Ä‘Ã£ Ä‘Æ°á»£c gáº§n 1k stars :) CÃ¡c báº¡n cÃ³ thá»ƒ táº£i sÃ¡ch miá»…n phÃ­ táº¡i https://github.com/tiepvupsu/ebookMLCB. Äá»«ng quÃªn Ä‘á»ƒ láº¡i má»™t star náº¿u báº¡n tháº¥y há»¯u Ã­ch.,,,#sharing,,
"[GÃ³c há»i Ä‘Ã¡p]
Má»i ngÆ°á»i Ä‘Ã£ tá»«ng dÃ¹ng Stacked Hourglass Network Ä‘á»ƒ nháº­n diá»‡n Pose Estimation cho em há»i chÃºt Ä‘Æ°á»£c khÃ´ng áº¡?
Äáº§u vÃ o cá»§a model lÃ  áº£nh RGB vÃ  label lÃ  15 keypoints(x, y). CÃ²n Ä‘áº§u ra cá»§a model lÃ  15 heatmaps.
1. Váº­y Ä‘á»ƒ tÃ­nh hÃ m loss thÃ¬ mÃ¬nh tÃ­nh dá»±a trÃªn 15 heatmaps hay extract heatmap thÃ nh 15keypoints Ä‘á»ƒ tÃ­nh loss áº¡?
2. Náº¿u tÃ­nh loss báº±ng heatmaps thÃ¬ lÃ m sao Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh áº¡? VÃ¬ áº£nh vÃ o lÃ  RGB vÃ  label lÃ  15 keypoints cÃ²n outputs cá»§a model lÃ  15 heatmaps?
3. Em cÃ³ sai á»Ÿ dá»¯ liá»‡u label hay input Ä‘áº§u vÃ o khÃ´ng áº¡? Mong má»i ngÆ°á»i gÃ³p Ã½ giÃºp em áº¡..
Em cÃ¡m Æ¡n..","[GÃ³c há»i Ä‘Ã¡p] Má»i ngÆ°á»i Ä‘Ã£ tá»«ng dÃ¹ng Stacked Hourglass Network Ä‘á»ƒ nháº­n diá»‡n Pose Estimation cho em há»i chÃºt Ä‘Æ°á»£c khÃ´ng áº¡? Äáº§u vÃ o cá»§a model lÃ  áº£nh RGB vÃ  label lÃ  15 keypoints(x, y). CÃ²n Ä‘áº§u ra cá»§a model lÃ  15 heatmaps. 1. Váº­y Ä‘á»ƒ tÃ­nh hÃ m loss thÃ¬ mÃ¬nh tÃ­nh dá»±a trÃªn 15 heatmaps hay extract heatmap thÃ nh 15keypoints Ä‘á»ƒ tÃ­nh loss áº¡? 2. Náº¿u tÃ­nh loss báº±ng heatmaps thÃ¬ lÃ m sao Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh áº¡? VÃ¬ áº£nh vÃ o lÃ  RGB vÃ  label lÃ  15 keypoints cÃ²n outputs cá»§a model lÃ  15 heatmaps? 3. Em cÃ³ sai á»Ÿ dá»¯ liá»‡u label hay input Ä‘áº§u vÃ o khÃ´ng áº¡? Mong má»i ngÆ°á»i gÃ³p Ã½ giÃºp em áº¡.. Em cÃ¡m Æ¡n..",,,"#Q&A, #cv, #deep_learning",,
"LÃ m viá»‡c trong lÄ©nh vá»±c ML trong má»™t thá»i gian rá»“i mÃ  chÆ°a cÃ³ bÃ i nÃ o trong forum mÃ¬nh. NhÃ¢n dá»‹p Ä‘ang lÃ m viá»‡c vá» Diffusion Models, mÃ¬nh xin phÃ©p chia sáº» bÃ i viáº¿t mÃ¬nh tá»•ng há»£p láº¡i vÃ  giáº£i thÃ­ch má»™t sá»‘ kiáº¿n thá»©c vá» Diffusion Models. Hy vá»ng sáº½ cÃ³ Ã­ch vá»›i cÃ¡c báº¡n tÃ¬m hiá»ƒu vá» nÃ³.
https://viblo.asia/p/diffusion-models-co-ban-phan-1-E1XVOx884Mz","LÃ m viá»‡c trong lÄ©nh vá»±c ML trong má»™t thá»i gian rá»“i mÃ  chÆ°a cÃ³ bÃ i nÃ o trong forum mÃ¬nh. NhÃ¢n dá»‹p Ä‘ang lÃ m viá»‡c vá» Diffusion Models, mÃ¬nh xin phÃ©p chia sáº» bÃ i viáº¿t mÃ¬nh tá»•ng há»£p láº¡i vÃ  giáº£i thÃ­ch má»™t sá»‘ kiáº¿n thá»©c vá» Diffusion Models. Hy vá»ng sáº½ cÃ³ Ã­ch vá»›i cÃ¡c báº¡n tÃ¬m hiá»ƒu vá» nÃ³. https://viblo.asia/p/diffusion-models-co-ban-phan-1-E1XVOx884Mz",,,"#sharing, #machine_learning",,
"Hi má»i ngÆ°á»i.
TÃ¬nh hÃ¬nh lÃ  em Ä‘ang báº¯t Ä‘áº§u há»c vÃ  luyá»‡n bÃªn ML/DL.
Vá» kiáº¿n thá»©c thÃ¬ e Ä‘Ã£ cÃ³ cÃ¡c source cho mÃ¬nh rá»“i.
NhÆ°ng vá» luyá»‡n code thÃ¬ em chÆ°a biáº¿t cÃ³ ná»n táº£ng nÃ o good hay khÃ´ng. ThÆ°á»ng nghe luyá»‡n code thÃ¬ nghÄ© Ä‘áº¿n hackerrank vÃ  leetcode nhÆ°ng á»Ÿ trÃªn nÃ y háº§u nhÆ° luyá»‡n algorithms, data structures, ... chá»© em Ã­t tháº¥y problem cho ML vÃ  DL.
Nhá» cÃ¡c anh/chá»‹/báº¡n cÃ³ thá»ƒ share cho em cÃ¡c ná»n táº£ng ok Ä‘á»ƒ luyá»‡n code vá» ML/DL áº¡.
Em xin cáº£m Æ¡n ^^.","Hi má»i ngÆ°á»i. TÃ¬nh hÃ¬nh lÃ  em Ä‘ang báº¯t Ä‘áº§u há»c vÃ  luyá»‡n bÃªn ML/DL. Vá» kiáº¿n thá»©c thÃ¬ e Ä‘Ã£ cÃ³ cÃ¡c source cho mÃ¬nh rá»“i. NhÆ°ng vá» luyá»‡n code thÃ¬ em chÆ°a biáº¿t cÃ³ ná»n táº£ng nÃ o good hay khÃ´ng. ThÆ°á»ng nghe luyá»‡n code thÃ¬ nghÄ© Ä‘áº¿n hackerrank vÃ  leetcode nhÆ°ng á»Ÿ trÃªn nÃ y háº§u nhÆ° luyá»‡n algorithms, data structures, ... chá»© em Ã­t tháº¥y problem cho ML vÃ  DL. Nhá» cÃ¡c anh/chá»‹/báº¡n cÃ³ thá»ƒ share cho em cÃ¡c ná»n táº£ng ok Ä‘á»ƒ luyá»‡n code vá» ML/DL áº¡. Em xin cáº£m Æ¡n ^^.",,,,,
"Em chÃ o má»i ngÆ°á»i!
Em Ä‘ang tÃ¬m hiá»ƒu vá» zero-shot learning cho bÃ i toÃ¡n multi-label nhÆ°ng em Ä‘Ã£ Ä‘á»c má»™t sá»‘ bÃ i bÃ¡o nhÆ°ng em váº«n chÆ°a hiá»ƒu cÃ¡ch zero-shot learning cÃ³ thá»ƒ predict Ä‘Æ°á»£c nhá»¯ng label khÃ´ng cÃ³ trong táº­p train. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ 1 bÃ i viáº¿t nÃ o Ä‘Ã³ vá» váº¥n Ä‘á» nÃ y, cÃ³ thá»ƒ suggest cho em Ä‘Æ°á»£c khÃ´ng áº¡, em cáº£m Æ¡n !","Em chÃ o má»i ngÆ°á»i! Em Ä‘ang tÃ¬m hiá»ƒu vá» zero-shot learning cho bÃ i toÃ¡n multi-label nhÆ°ng em Ä‘Ã£ Ä‘á»c má»™t sá»‘ bÃ i bÃ¡o nhÆ°ng em váº«n chÆ°a hiá»ƒu cÃ¡ch zero-shot learning cÃ³ thá»ƒ predict Ä‘Æ°á»£c nhá»¯ng label khÃ´ng cÃ³ trong táº­p train. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ 1 bÃ i viáº¿t nÃ o Ä‘Ã³ vá» váº¥n Ä‘á» nÃ y, cÃ³ thá»ƒ suggest cho em Ä‘Æ°á»£c khÃ´ng áº¡, em cáº£m Æ¡n !",,,"#Q&A, #machine_learning",,
"Má»™t bÃ i tá»•ng há»£p vá» kiáº¿n trÃºc mÃ´ hÃ¬nh SSD, má»™t trong nhá»¯ng mÃ´ hÃ¬nh cÃ³ tá»‘c Ä‘á»™ xá»­ lÃ½ cao vÃ  Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t trong lá»›p cÃ¡c mÃ´ hÃ¬nh object detection.","Má»™t bÃ i tá»•ng há»£p vá» kiáº¿n trÃºc mÃ´ hÃ¬nh SSD, má»™t trong nhá»¯ng mÃ´ hÃ¬nh cÃ³ tá»‘c Ä‘á»™ xá»­ lÃ½ cao vÃ  Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t trong lá»›p cÃ¡c mÃ´ hÃ¬nh object detection.",,,"#sharing, #cv, #deep_learning",,
"[Transformer model pytorch]
Má»i ngÆ°á»i cho em há»i má»™t chÃºt vá» Transformer trÃªn Pytorch áº¡.
Em Ä‘ang gáº·p má»™t váº¥n Ä‘á» lÃ  khi set d_model = d_FFN = 512 thÃ¬ model há»™i tá»¥ bÃ¬nh thÆ°á»ng - báº¥t biáº¿n vá»›i sá»‘ block encoder vÃ  decoder .
CÃ²n khi set d_model = 512 , d_FFN = d_model x (2^n) ,
thÃ¬ loss chá»‰ giáº£m má»™t chÃºt rá»“i sau Ä‘Ã³ nÃ³ gáº§n nhÆ° khÃ´ng Ä‘á»•i.
Em mong má»i ngÆ°á»i gÃ³p Ã½, em xin cáº£m Æ¡n áº¡.","[Transformer model pytorch] Má»i ngÆ°á»i cho em há»i má»™t chÃºt vá» Transformer trÃªn Pytorch áº¡. Em Ä‘ang gáº·p má»™t váº¥n Ä‘á» lÃ  khi set d_model = d_FFN = 512 thÃ¬ model há»™i tá»¥ bÃ¬nh thÆ°á»ng - báº¥t biáº¿n vá»›i sá»‘ block encoder vÃ  decoder . CÃ²n khi set d_model = 512 , d_FFN = d_model x (2^n) , thÃ¬ loss chá»‰ giáº£m má»™t chÃºt rá»“i sau Ä‘Ã³ nÃ³ gáº§n nhÆ° khÃ´ng Ä‘á»•i. Em mong má»i ngÆ°á»i gÃ³p Ã½, em xin cáº£m Æ¡n áº¡.",,,"#Q&A, #deep_learning",,
"Cho em há»i nhÃ³m mÃ¬nh ai cÃ³ há»©ng thÃº vá»›i dá»¯ liá»‡u tÃ i chÃ­nh khÃ´ng áº¡?
Em Ä‘ang há»c táº¡i trÆ°á»ng Keimyung,khoa cá»§a em tá»• chá»©c cuá»™c thi phÃ¢n tÃ­ch dá»¯ liá»‡u , thÃ´ng tin má»i ngÆ°á»i xem áº£nh nha.
Bá»™ dá»¯ liá»‡u má»i ngÆ°á»i cÃ³ thá»ƒ xem á»Ÿ link nÃ y : https://drive.google.com/drive/folders/1Pxy1uRX3Zx4OvIsEloyH6tCKO_KCJQYO?usp=share_link
Ká»¹ nÄƒng cá»§a em chá»‰ á»Ÿ má»©c cÆ¡ báº£n thÃ´i , chá»§ yáº¿u muá»‘n há»c tá»« má»i ngÆ°á»i lÃ  chÃ­nh áº¡.
Giáº£i nháº¥t 570$
2 Giáº£i nhÃ¬ 400$
5 Giáº£i ba 230$
Giáº£i chia Ä‘á»u cho 3 ngÆ°á»i trong nhÃ³m áº¡, nhÃ³m Ä‘Ã£ cÃ³ 2 ngÆ°á»i rÃ¹i !","Cho em há»i nhÃ³m mÃ¬nh ai cÃ³ há»©ng thÃº vá»›i dá»¯ liá»‡u tÃ i chÃ­nh khÃ´ng áº¡? Em Ä‘ang há»c táº¡i trÆ°á»ng Keimyung,khoa cá»§a em tá»• chá»©c cuá»™c thi phÃ¢n tÃ­ch dá»¯ liá»‡u , thÃ´ng tin má»i ngÆ°á»i xem áº£nh nha. Bá»™ dá»¯ liá»‡u má»i ngÆ°á»i cÃ³ thá»ƒ xem á»Ÿ link nÃ y : https://drive.google.com/drive/folders/1Pxy1uRX3Zx4OvIsEloyH6tCKO_KCJQYO?usp=share_link Ká»¹ nÄƒng cá»§a em chá»‰ á»Ÿ má»©c cÆ¡ báº£n thÃ´i , chá»§ yáº¿u muá»‘n há»c tá»« má»i ngÆ°á»i lÃ  chÃ­nh áº¡. Giáº£i nháº¥t 570$ 2 Giáº£i nhÃ¬ 400$ 5 Giáº£i ba 230$ Giáº£i chia Ä‘á»u cho 3 ngÆ°á»i trong nhÃ³m áº¡, nhÃ³m Ä‘Ã£ cÃ³ 2 ngÆ°á»i rÃ¹i !",,,"#sharing, #data",,
"Má»i ngÆ°á»i cho e há»i, ma tráº­n dáº¡ng nhÆ° tháº¿ nÃ y Ä‘Æ°á»£c gá»i tÃªn lÃ  gÃ¬ vÃ  cÃ³ nhá»¯ng tÃ­nh cháº¥t nhÆ° tháº¿ nÃ o? Cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Má»i ngÆ°á»i cho e há»i, ma tráº­n dáº¡ng nhÆ° tháº¿ nÃ y Ä‘Æ°á»£c gá»i tÃªn lÃ  gÃ¬ vÃ  cÃ³ nhá»¯ng tÃ­nh cháº¥t nhÆ° tháº¿ nÃ o? Cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,"#Q&A, #math",,
"Sau hÆ¡n 1 thÃ¡ng phÃ¡t triá»ƒn, AnyLabeling - cÃ´ng cá»¥ gÃ¡n nhÃ£n dá»¯ liá»‡u áº£nh vá»›i AI models Ä‘Ã£ hoÃ n thiá»‡n hÆ¡n: 
ğŸ”¥ TÃ­ch há»£p Segment Anything, YOLOv5, YOLOv8. Há»— trá»£ náº¡p Custom Models Ä‘á»ƒ cÃ³ thá»ƒ táº¡o thÃ nh vÃ²ng láº·p GÃ¡n nhÃ£n - Huáº¥n luyá»‡n, phÃ¡t triá»ƒn model dáº§n dáº§n. 
ğŸ”¥ Há»— trá»£ gÃ¡n nhÃ£n OCR, KIE vá»›i trÆ°á»ng text vÃ  tÃ­nh nÄƒng grouping. 
ğŸ”¥ Há»— trá»£ Ä‘a ngÃ´n ngá»¯: Tiáº¿ng Anh, Tiáº¿ng Viá»‡t, Tiáº¿ng Trung. 
ğŸ”¥ CÃ i Ä‘áº·t dá»… dÃ ng vá»›i Pip, hoáº·c cÃ¡c tá»‡p thá»±c thi. 
ğŸ”¥ TÃ i liá»‡u Ä‘áº§y Ä‘á»§ táº¡i https://anylabeling.com/docs.  
CÃ´ng cá»¥ nÃ y sáº½ giÃºp tÄƒng tá»‘c viá»‡c gÃ¡n nhÃ£n cho nhiá»u bÃ i toÃ¡n khÃ¡c nhau. Xin Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘áº¿n táº¥t cáº£ má»i ngÆ°á»i!
- MÃ£ nguá»“n: https://github.com/vietanhdev/anylabeling
- Blog: https://aicurious.io/.../2023-04-22-create-a-segment...
#anylabeling #segmentanything #yolo #yolov5 #yolov8","Sau hÆ¡n 1 thÃ¡ng phÃ¡t triá»ƒn, AnyLabeling - cÃ´ng cá»¥ gÃ¡n nhÃ£n dá»¯ liá»‡u áº£nh vá»›i AI models Ä‘Ã£ hoÃ n thiá»‡n hÆ¡n: TÃ­ch há»£p Segment Anything, YOLOv5, YOLOv8. Há»— trá»£ náº¡p Custom Models Ä‘á»ƒ cÃ³ thá»ƒ táº¡o thÃ nh vÃ²ng láº·p GÃ¡n nhÃ£n - Huáº¥n luyá»‡n, phÃ¡t triá»ƒn model dáº§n dáº§n. Há»— trá»£ gÃ¡n nhÃ£n OCR, KIE vá»›i trÆ°á»ng text vÃ  tÃ­nh nÄƒng grouping. Há»— trá»£ Ä‘a ngÃ´n ngá»¯: Tiáº¿ng Anh, Tiáº¿ng Viá»‡t, Tiáº¿ng Trung. CÃ i Ä‘áº·t dá»… dÃ ng vá»›i Pip, hoáº·c cÃ¡c tá»‡p thá»±c thi. TÃ i liá»‡u Ä‘áº§y Ä‘á»§ táº¡i https://anylabeling.com/docs. CÃ´ng cá»¥ nÃ y sáº½ giÃºp tÄƒng tá»‘c viá»‡c gÃ¡n nhÃ£n cho nhiá»u bÃ i toÃ¡n khÃ¡c nhau. Xin Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘áº¿n táº¥t cáº£ má»i ngÆ°á»i! - MÃ£ nguá»“n: https://github.com/vietanhdev/anylabeling - Blog: https://aicurious.io/.../2023-04-22-create-a-segment...",#anylabeling	#segmentanything	#yolo	#yolov5	#yolov8,,"#sharing, #cv, #deep_learning",,
"PHÆ¯Æ NG PHÃP Dáº Y CHATGPT Há»ŒC ÄÆ¯á»¢C KIáº¾N THá»¨C Má»šI
Xin chia sáº» tá»›i cÃ¡c anh em trong group mÃ´ hÃ¬nh tá»•ng quÃ¡t vÃ  cÃ¡c kÄ© thuáº­t Ä‘á»ƒ dáº¡y ChatGPT hiá»‡u quáº£. ÄÃ¢y lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng thá»±c táº¿ vá»›i giáº£i phÃ¡p GPT SaleBot cá»§a bá»n mÃ¬nh. Ráº¥t mong sáº½ nháº­n Ä‘Æ°á»£c thÃªm nhiá»u Ã½ kiáº¿n Ä‘Ã³ng gÃ³p vá» cÃ¡c cÃ¡ch thá»©c hiá»‡u quáº£ hÆ¡n.
A. NGUYÃŠN LÃ CHUNG
ChatGPT nÃ³i riÃªng vÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) nÃ³i chung cÃ³ má»™t tÃ­nh cháº¥t ráº¥t Ä‘áº·c biá»‡t. ÄÃ³ lÃ  nÃ³ cÃ³ má»™t ""trÃ­ nhá»› ngáº¯n háº¡n"" mÃ  náº¿u Ä‘Æ°a dá»¯ liá»‡u má»›i vÃ o vÃ¹ng nhá»› nÃ y, thÃ¬ mÃ´ hÃ¬nh sáº½ há»c Ä‘Æ°á»£c dá»¯ liá»‡u má»›i nÃ y vÃ  sá»­ dá»¥ng trong ná»™i dung tráº£ lá»i. Thuáº­t ngá»¯ gá»i lÃ  in-context learning, hoáº·c one/few-shot learning. ÄÃ¢y lÃ  má»™t Ä‘áº·c Ä‘iá»ƒm cÃ³ tÃ­nh cÃ¡ch máº¡ng, bá»Ÿi nÃ³ giÃºp huáº¥n luyá»‡n ChatGPT nhanh chÃ³ng vÃ  dá»… dÃ ng hÆ¡n ráº¥t nhiá»u so vá»›i giáº£i phÃ¡p ""fine-tune"" truyá»n thá»‘ng.
So sÃ¡nh Ä‘Æ¡n giáº£n, cÃ¡ch huáº¥n luyá»‡n AI truyá»n thá»‘ng giá»‘ng nhÆ° má»™t anh há»c trÃ² pháº£i bá» cÃ´ng bá» sá»©c Ã´n táº­p Ä‘á»ƒ cÃ³ kiáº¿n thá»©c Ä‘i thi. Trong khi Ä‘Ã³ huáº¥n luyá»‡n ChatGPT theo in-context learning thÃ¬ giá»‘ng nhÆ° anh há»c trÃ² Ä‘Ã³ sá»­ dá»¥ng phao. CÃ¹ng má»™t má»¥c Ä‘Ã­ch lÃ  tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i cá»§a ngÆ°á»i ra Ä‘á», thÃ¬ rÃµ rÃ ng dÃ¹ng phao sáº½ nhanh chÃ³ng vÃ  tháº­m chÃ­ trong nhiá»u trÆ°á»ng há»£p cÃ²n chÃ­nh xÃ¡c hÆ¡n lÃ  tá»± há»c, vá»›i Ä‘iá»u kiá»‡n lÃ  há»c trÃ² nÃ y pháº£i ráº¥t thÃ´ng minh, lÃ  Ä‘iá»u mÃ  ChatGPT cÃ³ thá»«a.
Äáº·c Ä‘iá»ƒm cÃ³ tÃ­nh cÃ¡ch máº¡ng nÃ y cá»§a ChatGPT vÃ  LLM má»Ÿ Ä‘Æ°á»ng cho ráº¥t nhiá»u á»©ng dá»¥ng khÃ¡c nhau cÃ³ thá»ƒ phÃ¡t triá»ƒn trÃªn ná»n ChatGPT, vá»›i chi phÃ­ ráº» hÆ¡n ráº¥t nhiá»u so vá»›i truyá»n thá»‘ng.
Vá» tá»•ng thá»ƒ nhá»¯ng á»©ng dá»¥ng nÃ y sáº½ Ä‘á»u hoáº¡t Ä‘á»™ng theo mÃ´ hÃ¬nh nhÆ° sau. MÃ¬nh tiáº¿p tá»¥c láº¥y vÃ­ dá»¥ thi cá»­ á»Ÿ trÃªn cho dá»… hiá»ƒu
BÆ°á»›c 1: Äá»c Ä‘á», phÃ¢n tÃ­ch Ä‘á»
á» bÆ°á»›c nÃ y, há»‡ thá»‘ng sáº½ láº¥y cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng, vÃ  phÃ¢n tÃ­ch Ã½ Ä‘á»“ (intention) cá»§a cÃ¢u há»i Ä‘Ã³ lÃ  gÃ¬?
BÆ°á»›c 2: TÃ¬m ""phao"" phÃ¹ há»£p
Phao á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  Ä‘oáº¡n dá»¯ liá»‡u phÃ¹ há»£p cáº§n Ä‘Æ°a vÃ o bá»™ nhá»› ngáº¯n háº¡n cá»§a ChatGPT Ä‘á»ƒ nÃ³ tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i. Viá»‡c chá»n phao nÃ y gá»i lÃ  truy váº¥n thÃ´ng tin (information retrieval) mÃ  mÃ¬nh sáº½ giá»›i thiá»‡u cÃ¡c kÄ© thuáº­t chÃ­nh cá»§a nÃ³ á»Ÿ pháº§n tiáº¿p
BÆ°á»›c 3: Sá»­ dá»¥ng ""phao"" Ä‘á»ƒ xÃ¢y dá»±ng Ä‘Ã¡p Ã¡n
á» bÆ°á»›c nÃ y thÃ¬ cho ChatGPT Ä‘á»c hiá»ƒu thÃ´ng tin trong ""phao"" vÃ  sá»­ dá»¥ng thÃ´ng tin nÃ y Ä‘á»ƒ tráº£ lá»i cho ngÆ°á»i dÃ¹ng. CÃ³ thá»ƒ Ä‘iá»u khiá»ƒn quÃ¡ trÃ¬nh nÃ y báº±ng ""prompt Ä‘iá»u khiá»ƒn"", giÃºp cÃ¢u tráº£ lá»i cÃ³ tÃ­nh cÃ¡ch vÃ  vÄƒn phong khÃ¡c nhau. Hiá»ƒu Ä‘Æ¡n giáº£n lÃ  cÃ¹ng má»™t Ä‘á» bÃ i, dÃ¹ng cÃ¹ng má»™t phao, thÃ¬ cÃ¡c anh há»c trÃ² khÃ¡c nhau sáº½ cho ra cÃ¡c cÃ¢u tráº£ lá»i theo phong thÃ¡i riÃªng.
B. CÃC KÄ¨ THUáº¬T Láº¤Y Dá»® LIá»†U Tá»ª Bá»˜ NHá»š DÃ€I Háº N
Trong mÃ´ hÃ¬nh huáº¥n luyá»‡n ChatGPT ká»ƒ trÃªn, thÃ¬ khÃ¢u quan trá»ng nháº¥t chÃ­nh lÃ  chuáº©n bá»‹ vÃ  chá»n ra Ä‘Æ°á»£c Ä‘Ãºng ""phao"" tá»« Ä‘á»‘ng kiáº¿n thá»©c lá»›n chung. KhÃ¢u nÃ y quyáº¿t Ä‘á»‹nh toÃ n bá»™ cháº¥t lÆ°á»£ng tráº£ lá»i cá»§a ChatGPT, hay hiá»ƒu Ä‘Æ¡n giáº£n lÃ  chuáº©n bá»‹ ""phao"" lá»‡ch tá»§, hay dÃ¹ng ""phao"" lá»‡ch Ä‘á» bÃ i thÃ¬ Ä‘á»u khiáº¿n thi trÆ°á»£t.
KhÃ¢u nÃ y trong khoa há»c mÃ¡y tÃ­nh gá»i lÃ  truy váº¥n thÃ´ng tin (information retrieval - IR), lÃ  má»™t lÄ©nh vá»±c Ä‘Æ°á»£c phÃ¡t triá»ƒn ráº¥t lÃ¢u dÃ i. CÃ³ ráº¥t nhiá»u kÄ© thuáº­t IR khÃ¡c nhau, nhÆ°ng dÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ kÄ© thuáº­t cÃ³ thá»ƒ Ã¡p dá»¥ng hiá»‡u quáº£ vá»›i bÃ i toÃ¡n huáº¥n luyá»‡n ChatGPT:
Fuzzy matching (so khá»›p vÄƒn báº£n)
ÄÃ¢y lÃ  kÄ© thuáº­t Ä‘Æ¡n giáº£n nháº¥t, nÃ³ Ä‘Æ¡n thuáº§n so sÃ¡nh sá»± khÃ¡c biá»‡t vá» tá»« khoÃ¡ giá»¯a cÃ¢u há»i vá»›i láº¡i dá»¯ liá»‡u phÃ¹ há»£p Ä‘á»ƒ tráº£ lá»i. KÄ© thuáº­t nÃ y giá»‘ng nhÆ° anh há»c sinh dá»‘t trong Ä‘áº§u khÃ´ng cÃ³ kiáº¿n thá»©c gÃ¬, chá»‰ xem Ä‘á» bÃ i nháº¯c Ä‘áº¿n tá»« khoÃ¡ gÃ¬ thÃ¬ tÃ¬m phao cÃ³ chá»©a nhiá»u tá»« trÃ¹ng nháº¥t Ä‘á»ƒ chÃ©p
BM25 
ÄÃ¢y lÃ  kÄ© thuáº­t cao cáº¥p hÆ¡n Fuzzy matching, nÃ³ biáº¿t trong cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ  dá»¯ liá»‡u tráº£ lá»i, thÃ¬ Ä‘Ã¢u lÃ  tá»« khoÃ¡ quan trá»ng, Ä‘Ã¢u lÃ  tá»« khoÃ¡ Ã­t quan trá»ng. KÄ© thuáº­t nÃ y giá»‘ng nhÆ° anh há»c sinh cÃ³ nghe giáº£ng, dÃ¹ cÅ©ng chÆ°a thá»±c sá»± hiá»ƒu láº¯m nhÆ°ng cÅ©ng nhá»› Ä‘Æ°á»£c vÃ i tá»« khoÃ¡ thÃ y cÃ´ hay nháº¯c tá»›i, nÃªn trong cÃ¡c phao na nÃ¡ nhau, thÃ¬ anh biáº¿t chá»n phao chá»©a nhiá»u tá»« khoÃ¡ quan trá»ng nháº¥t cÃ³ trong Ä‘á» bÃ i. Äiá»u thÃº vá»‹ á»Ÿ Ä‘Ã¢y lÃ  trong thá»±c tiá»…n, dÃ¹ anh há»c sinh cháº³ng hiá»ƒu gÃ¬ bÃ i giáº£ng, chá»‰ dÃ¹ng ""máº¹o"" thÃ¬ máº¹o nÃ y cÅ©ng ráº¥t hiá»‡u quáº£.
Semantic search (vector search)
Cuá»™c Ä‘á»i khÃ´ng bao giá» Ä‘Æ¡n giáº£n kiá»ƒu há»c gÃ¬ thi náº¥y, mÃ  Ä‘á» bÃ i luÃ´n Ä‘Æ°á»£c cÃ¡c thÃ y cÃ´ ra kiá»ƒu láº¯t lÃ©o mÃ  pháº£i tÆ° duy thÃ¬ má»›i hiá»ƒu Ä‘Æ°á»£c Ä‘Ã¢y lÃ  dáº¡ng bÃ i gÃ¬, Ã¡p dá»¥ng kiáº¿n thá»©c Ä‘Ã£ há»c nÃ o. ÄÃ¢y chÃ­nh lÃ  chá»— mÃ  kÄ© thuáº­t semantic search Ã¡p dá»¥ng. Tá»« cÃ¡i tÃªn cÅ©ng Ä‘Ã£ nÃ³i lÃªn kÄ© thuáº­t nÃ y, Ä‘Ã³ lÃ  thay vÃ¬ chá»‰ nhÃ¬n vÃ o máº·t chá»¯, thÃ¬ ""Ä‘á»c hiá»ƒu"" cÃ¢u há»i, rá»“i tÃ¬m xem kiáº¿n thá»©c nÃ o trong nhá»¯ng cÃ¡i Ä‘Ã£ biáº¿t thá»±c sá»± liÃªn quan tá»›i ná»™i dung nÃ y. QuÃ¡ trÃ¬nh ""Ä‘á»c hiá»ƒu"" nÃ y cá»§a mÃ¡y gá»i lÃ  embedding, dá»¯ liá»‡u ngá»¯ nghÄ©a cá»§a cÃ¢u há»i Ä‘Æ°á»£c biá»ƒu diá»…n á»Ÿ dáº¡ng vector, vÃ  quÃ¡ trÃ¬nh tÃ¬m kiáº¿m lÃ  quÃ¡ trÃ¬nh so sÃ¡nh Ä‘á»™ gáº§n-xa giá»¯a cÃ¡c vector nÃªn kÄ© thuáº­t nÃ y cÃ²n gá»i lÃ  vector search. LÄ©nh vá»±c vector search Ä‘ang Ä‘Æ°á»£c thÃºc Ä‘áº©y phÃ¡t triá»ƒn ráº¥t nhanh sau khi ChatGPT xuáº¥t hiá»‡n.
C. ÄÃNH GIÃ
Tá»« thá»±c tiá»…n Ã¡p dá»¥ng, phá»‘i há»£p cÃ¡c kÄ© thuáº­t huáº¥n luyá»‡n ChatGPT ká»ƒ trÃªn vÃ o sáº£n pháº©m GPT SaleBot (demo táº¡i: https://support.gptsalebot.com), mÃ¬nh rÃºt ra Ä‘Æ°á»£c má»™t sá»‘ Ä‘Ã¡nh giÃ¡:
Fuzzy matching ráº¥t thÃ­ch há»£p Ä‘á»ƒ Ã¡p dá»¥ng cho cÃ¡c cÃ¢u há»i cá»¥ thá»ƒ, rÃµ nghÄ©a, dÃ¹ng chuáº©n thuáº­t ngá»¯
BM25 ráº¥t thÃ­ch há»£p vá»›i nhá»¯ng cÃ¢u há»i dÃ i, cÃ³ nhiá»u chi tiáº¿t
Semantic search thÃ­ch há»£p vá»›i nhá»¯ng ná»™i dung ngáº¯n, vÃ  giá»i trong viá»‡c phÃ¢n biá»‡t cÃ¡c cÃ¢u na nÃ¡ nhau vá» hÃ¬nh thá»©c nhÆ°ng khÃ¡c nhau vá» ngá»¯ nghÄ©a
TrÃªn thá»±c táº¿, Ä‘á»ƒ huáº¥n luyá»‡n ChatGPT hiá»‡u quáº£, thÃ¬ khÃ´ng chá»‰ sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p, mÃ  cáº§n káº¿t há»£p nhiá»u phÆ°Æ¡ng phÃ¡p láº¡i vá»›i nhau. VÃ  team GPT SaleBot hiá»‡n Ä‘Ã£ triá»ƒn khai cÃ¡c kÄ© thuáº­t Ä‘á»ƒ huáº¥n luyá»‡n ChatGPT Ä‘áº¡t cháº¥t lÆ°á»£ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng chatbot Fin cá»§a Intercom, lÃ  phiÃªn báº£n tiÃªn tiáº¿n nháº¥t cá»§a trÃ¹m chatbot quá»‘c táº¿ (https://www.intercom.com/fin). á» trÃ¬nh Ä‘á»™ nÃ y, chatbot khÃ´ng nhá»¯ng cáº§n hiá»ƒu tá»‘t cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng, vÃ  tráº£ lá»i chÃ­nh xÃ¡c theo thÃ´ng tin Ä‘Æ°á»£c huáº¥n luyá»‡n, mÃ  cÃ²n pháº£i cÃ³ kháº£ nÄƒng xá»­ lÃ½ cÃ¡c dáº¡ng viáº¿t táº¯t, viáº¿t sai chÃ­nh táº£, tá»« lÃ³ng, cÃ³ kháº£ nÄƒng Ä‘áº·t láº¡i cÃ¢u há»i lÃ m rÃµ nghÄ©a vÃ  gá»£i Ã½ cÃ¡c cÃ¢u há»i follow-up Ä‘á»ƒ tiáº¿p tá»¥c há»™i thoáº¡i.
CÃ¡c báº¡n cÃ³ thá»ƒ tráº£i nghiá»‡m thá»­ cÃ¡c tÃ­nh nÄƒng nÃ y táº¡i: https://support.gptsalebot.com
D. Má» Rá»˜NG
Huáº¥n luyá»‡n ChatGPT trÃªn dá»¯ liá»‡u riÃªng, vÃ  Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y vÃ o cÃ¡c bÃ i toÃ¡n cá»¥ thá»ƒ nhÆ° chatbot Ä‘ang lÃ  lÄ©nh vá»±c phÃ¡t triá»ƒn nhanh vÃ  sáº½ cÃ²n cÃ³ nhiá»u giáº£i phÃ¡p thÃº vá»‹ hÆ¡n trong tÆ°Æ¡ng lai. Náº¿u báº¡n muá»‘n náº¯m báº¯t cÆ¡ há»™i vÃ  trá»Ÿ thÃ nh cÃ¡c chuyÃªn gia vá» triá»ƒn khai chatbot, chuyÃªn gia huáº¥n luyá»‡n ChatGPT theo bÃ i toÃ¡n Ä‘áº·c thÃ¹ cá»§a doanh nghiá»‡p thÃ¬ cÃ³ thá»ƒ Ä‘Äƒng kÃ½ trá»Ÿ thÃ nh partner triá»ƒn khai hoáº·c nhÃ¢n sá»± cá»§a GPT SaleBot theo link dÆ°á»›i Ä‘Ã¢y: https://aivgroupworking.sg.larksuite.com/.../shrlgvtifZ8t...
Quyá»n lá»£i cá»§a partner lÃ  sáº½ Ä‘Æ°á»£c tiáº¿p cáº­n nhá»¯ng hiá»ƒu biáº¿t sÃ¢u vá» cÃ´ng nghá»‡ ChatGPT, nhá»¯ng insight trong viá»‡c triá»ƒn khai chatbot, trá»£ lÃ½ áº£o thÃ nh cÃ´ng vÃ  Ä‘Ã³n Ä‘áº§u lÃ n sÃ³ng conversational marketing Ä‘ang diá»…n ra nhanh chÃ³ng sáº¯p tá»›i.
Lá»™c Äáº·ng","PHÆ¯Æ NG PHÃP Dáº Y CHATGPT Há»ŒC ÄÆ¯á»¢C KIáº¾N THá»¨C Má»šI Xin chia sáº» tá»›i cÃ¡c anh em trong group mÃ´ hÃ¬nh tá»•ng quÃ¡t vÃ  cÃ¡c kÄ© thuáº­t Ä‘á»ƒ dáº¡y ChatGPT hiá»‡u quáº£. ÄÃ¢y lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng thá»±c táº¿ vá»›i giáº£i phÃ¡p GPT SaleBot cá»§a bá»n mÃ¬nh. Ráº¥t mong sáº½ nháº­n Ä‘Æ°á»£c thÃªm nhiá»u Ã½ kiáº¿n Ä‘Ã³ng gÃ³p vá» cÃ¡c cÃ¡ch thá»©c hiá»‡u quáº£ hÆ¡n. A. NGUYÃŠN LÃ CHUNG ChatGPT nÃ³i riÃªng vÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) nÃ³i chung cÃ³ má»™t tÃ­nh cháº¥t ráº¥t Ä‘áº·c biá»‡t. ÄÃ³ lÃ  nÃ³ cÃ³ má»™t ""trÃ­ nhá»› ngáº¯n háº¡n"" mÃ  náº¿u Ä‘Æ°a dá»¯ liá»‡u má»›i vÃ o vÃ¹ng nhá»› nÃ y, thÃ¬ mÃ´ hÃ¬nh sáº½ há»c Ä‘Æ°á»£c dá»¯ liá»‡u má»›i nÃ y vÃ  sá»­ dá»¥ng trong ná»™i dung tráº£ lá»i. Thuáº­t ngá»¯ gá»i lÃ  in-context learning, hoáº·c one/few-shot learning. ÄÃ¢y lÃ  má»™t Ä‘áº·c Ä‘iá»ƒm cÃ³ tÃ­nh cÃ¡ch máº¡ng, bá»Ÿi nÃ³ giÃºp huáº¥n luyá»‡n ChatGPT nhanh chÃ³ng vÃ  dá»… dÃ ng hÆ¡n ráº¥t nhiá»u so vá»›i giáº£i phÃ¡p ""fine-tune"" truyá»n thá»‘ng. So sÃ¡nh Ä‘Æ¡n giáº£n, cÃ¡ch huáº¥n luyá»‡n AI truyá»n thá»‘ng giá»‘ng nhÆ° má»™t anh há»c trÃ² pháº£i bá» cÃ´ng bá» sá»©c Ã´n táº­p Ä‘á»ƒ cÃ³ kiáº¿n thá»©c Ä‘i thi. Trong khi Ä‘Ã³ huáº¥n luyá»‡n ChatGPT theo in-context learning thÃ¬ giá»‘ng nhÆ° anh há»c trÃ² Ä‘Ã³ sá»­ dá»¥ng phao. CÃ¹ng má»™t má»¥c Ä‘Ã­ch lÃ  tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i cá»§a ngÆ°á»i ra Ä‘á», thÃ¬ rÃµ rÃ ng dÃ¹ng phao sáº½ nhanh chÃ³ng vÃ  tháº­m chÃ­ trong nhiá»u trÆ°á»ng há»£p cÃ²n chÃ­nh xÃ¡c hÆ¡n lÃ  tá»± há»c, vá»›i Ä‘iá»u kiá»‡n lÃ  há»c trÃ² nÃ y pháº£i ráº¥t thÃ´ng minh, lÃ  Ä‘iá»u mÃ  ChatGPT cÃ³ thá»«a. Äáº·c Ä‘iá»ƒm cÃ³ tÃ­nh cÃ¡ch máº¡ng nÃ y cá»§a ChatGPT vÃ  LLM má»Ÿ Ä‘Æ°á»ng cho ráº¥t nhiá»u á»©ng dá»¥ng khÃ¡c nhau cÃ³ thá»ƒ phÃ¡t triá»ƒn trÃªn ná»n ChatGPT, vá»›i chi phÃ­ ráº» hÆ¡n ráº¥t nhiá»u so vá»›i truyá»n thá»‘ng. Vá» tá»•ng thá»ƒ nhá»¯ng á»©ng dá»¥ng nÃ y sáº½ Ä‘á»u hoáº¡t Ä‘á»™ng theo mÃ´ hÃ¬nh nhÆ° sau. MÃ¬nh tiáº¿p tá»¥c láº¥y vÃ­ dá»¥ thi cá»­ á»Ÿ trÃªn cho dá»… hiá»ƒu BÆ°á»›c 1: Äá»c Ä‘á», phÃ¢n tÃ­ch Ä‘á» á» bÆ°á»›c nÃ y, há»‡ thá»‘ng sáº½ láº¥y cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng, vÃ  phÃ¢n tÃ­ch Ã½ Ä‘á»“ (intention) cá»§a cÃ¢u há»i Ä‘Ã³ lÃ  gÃ¬? BÆ°á»›c 2: TÃ¬m ""phao"" phÃ¹ há»£p Phao á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  Ä‘oáº¡n dá»¯ liá»‡u phÃ¹ há»£p cáº§n Ä‘Æ°a vÃ o bá»™ nhá»› ngáº¯n háº¡n cá»§a ChatGPT Ä‘á»ƒ nÃ³ tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i. Viá»‡c chá»n phao nÃ y gá»i lÃ  truy váº¥n thÃ´ng tin (information retrieval) mÃ  mÃ¬nh sáº½ giá»›i thiá»‡u cÃ¡c kÄ© thuáº­t chÃ­nh cá»§a nÃ³ á»Ÿ pháº§n tiáº¿p BÆ°á»›c 3: Sá»­ dá»¥ng ""phao"" Ä‘á»ƒ xÃ¢y dá»±ng Ä‘Ã¡p Ã¡n á» bÆ°á»›c nÃ y thÃ¬ cho ChatGPT Ä‘á»c hiá»ƒu thÃ´ng tin trong ""phao"" vÃ  sá»­ dá»¥ng thÃ´ng tin nÃ y Ä‘á»ƒ tráº£ lá»i cho ngÆ°á»i dÃ¹ng. CÃ³ thá»ƒ Ä‘iá»u khiá»ƒn quÃ¡ trÃ¬nh nÃ y báº±ng ""prompt Ä‘iá»u khiá»ƒn"", giÃºp cÃ¢u tráº£ lá»i cÃ³ tÃ­nh cÃ¡ch vÃ  vÄƒn phong khÃ¡c nhau. Hiá»ƒu Ä‘Æ¡n giáº£n lÃ  cÃ¹ng má»™t Ä‘á» bÃ i, dÃ¹ng cÃ¹ng má»™t phao, thÃ¬ cÃ¡c anh há»c trÃ² khÃ¡c nhau sáº½ cho ra cÃ¡c cÃ¢u tráº£ lá»i theo phong thÃ¡i riÃªng. B. CÃC KÄ¨ THUáº¬T Láº¤Y Dá»® LIá»†U Tá»ª Bá»˜ NHá»š DÃ€I Háº N Trong mÃ´ hÃ¬nh huáº¥n luyá»‡n ChatGPT ká»ƒ trÃªn, thÃ¬ khÃ¢u quan trá»ng nháº¥t chÃ­nh lÃ  chuáº©n bá»‹ vÃ  chá»n ra Ä‘Æ°á»£c Ä‘Ãºng ""phao"" tá»« Ä‘á»‘ng kiáº¿n thá»©c lá»›n chung. KhÃ¢u nÃ y quyáº¿t Ä‘á»‹nh toÃ n bá»™ cháº¥t lÆ°á»£ng tráº£ lá»i cá»§a ChatGPT, hay hiá»ƒu Ä‘Æ¡n giáº£n lÃ  chuáº©n bá»‹ ""phao"" lá»‡ch tá»§, hay dÃ¹ng ""phao"" lá»‡ch Ä‘á» bÃ i thÃ¬ Ä‘á»u khiáº¿n thi trÆ°á»£t. KhÃ¢u nÃ y trong khoa há»c mÃ¡y tÃ­nh gá»i lÃ  truy váº¥n thÃ´ng tin (information retrieval - IR), lÃ  má»™t lÄ©nh vá»±c Ä‘Æ°á»£c phÃ¡t triá»ƒn ráº¥t lÃ¢u dÃ i. CÃ³ ráº¥t nhiá»u kÄ© thuáº­t IR khÃ¡c nhau, nhÆ°ng dÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ kÄ© thuáº­t cÃ³ thá»ƒ Ã¡p dá»¥ng hiá»‡u quáº£ vá»›i bÃ i toÃ¡n huáº¥n luyá»‡n ChatGPT: Fuzzy matching (so khá»›p vÄƒn báº£n) ÄÃ¢y lÃ  kÄ© thuáº­t Ä‘Æ¡n giáº£n nháº¥t, nÃ³ Ä‘Æ¡n thuáº§n so sÃ¡nh sá»± khÃ¡c biá»‡t vá» tá»« khoÃ¡ giá»¯a cÃ¢u há»i vá»›i láº¡i dá»¯ liá»‡u phÃ¹ há»£p Ä‘á»ƒ tráº£ lá»i. KÄ© thuáº­t nÃ y giá»‘ng nhÆ° anh há»c sinh dá»‘t trong Ä‘áº§u khÃ´ng cÃ³ kiáº¿n thá»©c gÃ¬, chá»‰ xem Ä‘á» bÃ i nháº¯c Ä‘áº¿n tá»« khoÃ¡ gÃ¬ thÃ¬ tÃ¬m phao cÃ³ chá»©a nhiá»u tá»« trÃ¹ng nháº¥t Ä‘á»ƒ chÃ©p BM25 ÄÃ¢y lÃ  kÄ© thuáº­t cao cáº¥p hÆ¡n Fuzzy matching, nÃ³ biáº¿t trong cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ  dá»¯ liá»‡u tráº£ lá»i, thÃ¬ Ä‘Ã¢u lÃ  tá»« khoÃ¡ quan trá»ng, Ä‘Ã¢u lÃ  tá»« khoÃ¡ Ã­t quan trá»ng. KÄ© thuáº­t nÃ y giá»‘ng nhÆ° anh há»c sinh cÃ³ nghe giáº£ng, dÃ¹ cÅ©ng chÆ°a thá»±c sá»± hiá»ƒu láº¯m nhÆ°ng cÅ©ng nhá»› Ä‘Æ°á»£c vÃ i tá»« khoÃ¡ thÃ y cÃ´ hay nháº¯c tá»›i, nÃªn trong cÃ¡c phao na nÃ¡ nhau, thÃ¬ anh biáº¿t chá»n phao chá»©a nhiá»u tá»« khoÃ¡ quan trá»ng nháº¥t cÃ³ trong Ä‘á» bÃ i. Äiá»u thÃº vá»‹ á»Ÿ Ä‘Ã¢y lÃ  trong thá»±c tiá»…n, dÃ¹ anh há»c sinh cháº³ng hiá»ƒu gÃ¬ bÃ i giáº£ng, chá»‰ dÃ¹ng ""máº¹o"" thÃ¬ máº¹o nÃ y cÅ©ng ráº¥t hiá»‡u quáº£. Semantic search (vector search) Cuá»™c Ä‘á»i khÃ´ng bao giá» Ä‘Æ¡n giáº£n kiá»ƒu há»c gÃ¬ thi náº¥y, mÃ  Ä‘á» bÃ i luÃ´n Ä‘Æ°á»£c cÃ¡c thÃ y cÃ´ ra kiá»ƒu láº¯t lÃ©o mÃ  pháº£i tÆ° duy thÃ¬ má»›i hiá»ƒu Ä‘Æ°á»£c Ä‘Ã¢y lÃ  dáº¡ng bÃ i gÃ¬, Ã¡p dá»¥ng kiáº¿n thá»©c Ä‘Ã£ há»c nÃ o. ÄÃ¢y chÃ­nh lÃ  chá»— mÃ  kÄ© thuáº­t semantic search Ã¡p dá»¥ng. Tá»« cÃ¡i tÃªn cÅ©ng Ä‘Ã£ nÃ³i lÃªn kÄ© thuáº­t nÃ y, Ä‘Ã³ lÃ  thay vÃ¬ chá»‰ nhÃ¬n vÃ o máº·t chá»¯, thÃ¬ ""Ä‘á»c hiá»ƒu"" cÃ¢u há»i, rá»“i tÃ¬m xem kiáº¿n thá»©c nÃ o trong nhá»¯ng cÃ¡i Ä‘Ã£ biáº¿t thá»±c sá»± liÃªn quan tá»›i ná»™i dung nÃ y. QuÃ¡ trÃ¬nh ""Ä‘á»c hiá»ƒu"" nÃ y cá»§a mÃ¡y gá»i lÃ  embedding, dá»¯ liá»‡u ngá»¯ nghÄ©a cá»§a cÃ¢u há»i Ä‘Æ°á»£c biá»ƒu diá»…n á»Ÿ dáº¡ng vector, vÃ  quÃ¡ trÃ¬nh tÃ¬m kiáº¿m lÃ  quÃ¡ trÃ¬nh so sÃ¡nh Ä‘á»™ gáº§n-xa giá»¯a cÃ¡c vector nÃªn kÄ© thuáº­t nÃ y cÃ²n gá»i lÃ  vector search. LÄ©nh vá»±c vector search Ä‘ang Ä‘Æ°á»£c thÃºc Ä‘áº©y phÃ¡t triá»ƒn ráº¥t nhanh sau khi ChatGPT xuáº¥t hiá»‡n. C. ÄÃNH GIÃ Tá»« thá»±c tiá»…n Ã¡p dá»¥ng, phá»‘i há»£p cÃ¡c kÄ© thuáº­t huáº¥n luyá»‡n ChatGPT ká»ƒ trÃªn vÃ o sáº£n pháº©m GPT SaleBot (demo táº¡i: https://support.gptsalebot.com), mÃ¬nh rÃºt ra Ä‘Æ°á»£c má»™t sá»‘ Ä‘Ã¡nh giÃ¡: Fuzzy matching ráº¥t thÃ­ch há»£p Ä‘á»ƒ Ã¡p dá»¥ng cho cÃ¡c cÃ¢u há»i cá»¥ thá»ƒ, rÃµ nghÄ©a, dÃ¹ng chuáº©n thuáº­t ngá»¯ BM25 ráº¥t thÃ­ch há»£p vá»›i nhá»¯ng cÃ¢u há»i dÃ i, cÃ³ nhiá»u chi tiáº¿t Semantic search thÃ­ch há»£p vá»›i nhá»¯ng ná»™i dung ngáº¯n, vÃ  giá»i trong viá»‡c phÃ¢n biá»‡t cÃ¡c cÃ¢u na nÃ¡ nhau vá» hÃ¬nh thá»©c nhÆ°ng khÃ¡c nhau vá» ngá»¯ nghÄ©a TrÃªn thá»±c táº¿, Ä‘á»ƒ huáº¥n luyá»‡n ChatGPT hiá»‡u quáº£, thÃ¬ khÃ´ng chá»‰ sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p, mÃ  cáº§n káº¿t há»£p nhiá»u phÆ°Æ¡ng phÃ¡p láº¡i vá»›i nhau. VÃ  team GPT SaleBot hiá»‡n Ä‘Ã£ triá»ƒn khai cÃ¡c kÄ© thuáº­t Ä‘á»ƒ huáº¥n luyá»‡n ChatGPT Ä‘áº¡t cháº¥t lÆ°á»£ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng chatbot Fin cá»§a Intercom, lÃ  phiÃªn báº£n tiÃªn tiáº¿n nháº¥t cá»§a trÃ¹m chatbot quá»‘c táº¿ (https://www.intercom.com/fin). á» trÃ¬nh Ä‘á»™ nÃ y, chatbot khÃ´ng nhá»¯ng cáº§n hiá»ƒu tá»‘t cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng, vÃ  tráº£ lá»i chÃ­nh xÃ¡c theo thÃ´ng tin Ä‘Æ°á»£c huáº¥n luyá»‡n, mÃ  cÃ²n pháº£i cÃ³ kháº£ nÄƒng xá»­ lÃ½ cÃ¡c dáº¡ng viáº¿t táº¯t, viáº¿t sai chÃ­nh táº£, tá»« lÃ³ng, cÃ³ kháº£ nÄƒng Ä‘áº·t láº¡i cÃ¢u há»i lÃ m rÃµ nghÄ©a vÃ  gá»£i Ã½ cÃ¡c cÃ¢u há»i follow-up Ä‘á»ƒ tiáº¿p tá»¥c há»™i thoáº¡i. CÃ¡c báº¡n cÃ³ thá»ƒ tráº£i nghiá»‡m thá»­ cÃ¡c tÃ­nh nÄƒng nÃ y táº¡i: https://support.gptsalebot.com D. Má» Rá»˜NG Huáº¥n luyá»‡n ChatGPT trÃªn dá»¯ liá»‡u riÃªng, vÃ  Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y vÃ o cÃ¡c bÃ i toÃ¡n cá»¥ thá»ƒ nhÆ° chatbot Ä‘ang lÃ  lÄ©nh vá»±c phÃ¡t triá»ƒn nhanh vÃ  sáº½ cÃ²n cÃ³ nhiá»u giáº£i phÃ¡p thÃº vá»‹ hÆ¡n trong tÆ°Æ¡ng lai. Náº¿u báº¡n muá»‘n náº¯m báº¯t cÆ¡ há»™i vÃ  trá»Ÿ thÃ nh cÃ¡c chuyÃªn gia vá» triá»ƒn khai chatbot, chuyÃªn gia huáº¥n luyá»‡n ChatGPT theo bÃ i toÃ¡n Ä‘áº·c thÃ¹ cá»§a doanh nghiá»‡p thÃ¬ cÃ³ thá»ƒ Ä‘Äƒng kÃ½ trá»Ÿ thÃ nh partner triá»ƒn khai hoáº·c nhÃ¢n sá»± cá»§a GPT SaleBot theo link dÆ°á»›i Ä‘Ã¢y: https://aivgroupworking.sg.larksuite.com/.../shrlgvtifZ8t... Quyá»n lá»£i cá»§a partner lÃ  sáº½ Ä‘Æ°á»£c tiáº¿p cáº­n nhá»¯ng hiá»ƒu biáº¿t sÃ¢u vá» cÃ´ng nghá»‡ ChatGPT, nhá»¯ng insight trong viá»‡c triá»ƒn khai chatbot, trá»£ lÃ½ áº£o thÃ nh cÃ´ng vÃ  Ä‘Ã³n Ä‘áº§u lÃ n sÃ³ng conversational marketing Ä‘ang diá»…n ra nhanh chÃ³ng sáº¯p tá»›i. Lá»™c Äáº·ng",,,"#sharing, #nlp",,
"Xin chÃ o cÃ¡c báº¡n, mÃ¬nh lÃ m máº£ng geospatial ráº½ ngang, cá»¥ thá»ƒ lÃ  data capture & processing point cloud data & 3D modelling. MÃ¬nh chá»‰ viáº¿t vÃ i script cÆ¡ báº£n phá»¥c vá»¥ cÃ´ng viá»‡c trÃªn python. Giá» muá»‘n tham gia sÃ¢u hÆ¡n vÃ o ML.
KhÃ´ng biáº¿t trong group mÃ¬nh cÃ³ ai lÃ m vá» máº£ng nÃ y khÃ´ng áº¡? MÃ¬nh xin phÃ©p Ä‘Æ°á»£c káº¿t báº¡n vÃ  há»c há»i thÃªm.
MÃ¬nh á»Ÿ Melbourne, Australia. Náº¿u cÃ³ báº¡n nÃ o á»Ÿ Ä‘Ã¢y mÃ¬nh xin má»i cÃ  phÃª áº¡ ğŸ™‚","Xin chÃ o cÃ¡c báº¡n, mÃ¬nh lÃ m máº£ng geospatial ráº½ ngang, cá»¥ thá»ƒ lÃ  data capture & processing point cloud data & 3D modelling. MÃ¬nh chá»‰ viáº¿t vÃ i script cÆ¡ báº£n phá»¥c vá»¥ cÃ´ng viá»‡c trÃªn python. Giá» muá»‘n tham gia sÃ¢u hÆ¡n vÃ o ML. KhÃ´ng biáº¿t trong group mÃ¬nh cÃ³ ai lÃ m vá» máº£ng nÃ y khÃ´ng áº¡? MÃ¬nh xin phÃ©p Ä‘Æ°á»£c káº¿t báº¡n vÃ  há»c há»i thÃªm. MÃ¬nh á»Ÿ Melbourne, Australia. Náº¿u cÃ³ báº¡n nÃ o á»Ÿ Ä‘Ã¢y mÃ¬nh xin má»i cÃ  phÃª áº¡",,,"#Q&A, #machine_learning",,
"[HCM]
ChÃ o cÃ¡c anh/chá»‹.
Em lÃ  ngÆ°á»i trÃ¡i ngÃ nh, cÃ³ Ä‘am mÃª vá» lÄ©nh vá»±c AI vÃ  Ä‘ang mong muá»‘n tÃ¬m kiáº¿m cÃ´ng viá»‡c bÃªn máº£ng nÃ y (MLE, DS, DE)
Hiá»‡n táº¡i thÃ¬ tÃ¬nh hÃ¬nh xin viá»‡c fresher cho ML/DL cÅ©ng khÃ³ khÄƒn, nÃªn em muá»‘n dÃ nh thÃªm thá»i gian Ä‘á»ƒ tiáº¿p tá»¥c trau dá»“i báº£n thÃ¢n, nÃ¢ng cao kháº£ nÄƒng cá»§a mÃ¬nh lÃªn.
Váº­y nÃªn, em viáº¿t post nÃ y mong Ä‘Æ°á»£c anh/chá»‹ nÃ o cÃ³ thá»ƒ cho em cÆ¡ há»™i, nháº­n em vÃ o lÃ m Ä‘á»ƒ há»c há»i thÃªm, cÃ³ cÆ¡ há»™i tiáº¿p xÃºc vá»›i dá»± Ã¡n thá»±c táº¿. (cÃ´ng ty hay freelance Ä‘á»u Ä‘Æ°á»£c áº¡).
Em ko quan trá»ng chuyá»‡n lÆ°Æ¡ng.
E á»Ÿ HCM.
Anh/chá»‹ cmt e sáº½ inbox CV áº¡.
Em cáº£m Æ¡n nhiá»u.","[HCM] ChÃ o cÃ¡c anh/chá»‹. Em lÃ  ngÆ°á»i trÃ¡i ngÃ nh, cÃ³ Ä‘am mÃª vá» lÄ©nh vá»±c AI vÃ  Ä‘ang mong muá»‘n tÃ¬m kiáº¿m cÃ´ng viá»‡c bÃªn máº£ng nÃ y (MLE, DS, DE) Hiá»‡n táº¡i thÃ¬ tÃ¬nh hÃ¬nh xin viá»‡c fresher cho ML/DL cÅ©ng khÃ³ khÄƒn, nÃªn em muá»‘n dÃ nh thÃªm thá»i gian Ä‘á»ƒ tiáº¿p tá»¥c trau dá»“i báº£n thÃ¢n, nÃ¢ng cao kháº£ nÄƒng cá»§a mÃ¬nh lÃªn. Váº­y nÃªn, em viáº¿t post nÃ y mong Ä‘Æ°á»£c anh/chá»‹ nÃ o cÃ³ thá»ƒ cho em cÆ¡ há»™i, nháº­n em vÃ o lÃ m Ä‘á»ƒ há»c há»i thÃªm, cÃ³ cÆ¡ há»™i tiáº¿p xÃºc vá»›i dá»± Ã¡n thá»±c táº¿. (cÃ´ng ty hay freelance Ä‘á»u Ä‘Æ°á»£c áº¡). Em ko quan trá»ng chuyá»‡n lÆ°Æ¡ng. E á»Ÿ HCM. Anh/chá»‹ cmt e sáº½ inbox CV áº¡. Em cáº£m Æ¡n nhiá»u.",,,"#sharing, #machine_learning",,
"Xin phÃ©p spam group má»™t chÃºt. HÃ nh Ä‘á»™ng nÃ y Ä‘Ã¡ng bá»‹ lÃªn Ã¡n.
TÃ´i luÃ´n pháº£n Ä‘á»‘i chuyá»‡n Ä‘áº¡o vÄƒn khÃ´ng trÃ­ch nguá»“n. Äáº±ng nÃ y báº¡n 'tháº§y Henry' nÃ y cÃ²n láº¥y luÃ´n cáº£ slide rá»“i ghi tÃªn mÃ¬nh vÃ o.
TÃ i khoáº£n nÃ y trÆ°á»›c Ä‘Ã¢y Ä‘Äƒng khÃ¡ nhiá»u bÃ i trong group vÃ  tá»± xÆ°ng lÃ  'tháº§y Henry', tÃ´i xin phÃ©p xÃ³a tÃ i khoáº£n vÃ  cÃ¡c bÃ i liÃªn quan. Báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ qua group cá»§a 'tháº§y' theo dÃµi.","Xin phÃ©p spam group má»™t chÃºt. HÃ nh Ä‘á»™ng nÃ y Ä‘Ã¡ng bá»‹ lÃªn Ã¡n. TÃ´i luÃ´n pháº£n Ä‘á»‘i chuyá»‡n Ä‘áº¡o vÄƒn khÃ´ng trÃ­ch nguá»“n. Äáº±ng nÃ y báº¡n 'tháº§y Henry' nÃ y cÃ²n láº¥y luÃ´n cáº£ slide rá»“i ghi tÃªn mÃ¬nh vÃ o. TÃ i khoáº£n nÃ y trÆ°á»›c Ä‘Ã¢y Ä‘Äƒng khÃ¡ nhiá»u bÃ i trong group vÃ  tá»± xÆ°ng lÃ  'tháº§y Henry', tÃ´i xin phÃ©p xÃ³a tÃ i khoáº£n vÃ  cÃ¡c bÃ i liÃªn quan. Báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ qua group cá»§a 'tháº§y' theo dÃµi.",,,#sharing,,
"Má»i ngÆ°á»i nghÄ© sao vá» Tensorflow Developer Certificate á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i ? 
Em/mÃ¬nh background vá» computer science + Ä‘Ã£ lÃ m viá»‡c/nghiÃªn cá»©u vá»›i ML gáº§n 2 nÄƒm, Ä‘ang bÄƒn khoÄƒn cÃ³ nÃªn Ã´n thi lÃ m Ä‘áº¹p CV khÃ´ng vÃ¬ Ä‘á»c review cÃ³ váº» khÃ´ng yÃªu cáº§u chuyÃªn mÃ´n cao vÃ  cÃ´ng viá»‡c hiá»‡n táº¡i á»Ÿ cÃ´ng ty chÆ°a nhiá»u Ã¡p lá»±c.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c.","Má»i ngÆ°á»i nghÄ© sao vá» Tensorflow Developer Certificate á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i ? Em/mÃ¬nh background vá» computer science + Ä‘Ã£ lÃ m viá»‡c/nghiÃªn cá»©u vá»›i ML gáº§n 2 nÄƒm, Ä‘ang bÄƒn khoÄƒn cÃ³ nÃªn Ã´n thi lÃ m Ä‘áº¹p CV khÃ´ng vÃ¬ Ä‘á»c review cÃ³ váº» khÃ´ng yÃªu cáº§u chuyÃªn mÃ´n cao vÃ  cÃ´ng viá»‡c hiá»‡n táº¡i á»Ÿ cÃ´ng ty chÆ°a nhiá»u Ã¡p lá»±c. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c.",,,"#sharing, #machine_learning",,
"Em chÃ o má»i ngÆ°á»i áº¡
CÃ³ ai cÃ³ thá»ƒ cho em tÃ i liá»‡u tham kháº£o vá» viá»‡c sá»­ dá»¥ng Bayesian Neural Network ( BNN Model) Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ BTC báº±ng python khÃ´ng áº¡. Em lÃ m Ä‘á»“ Ã¡n nhÆ°ng kiáº¿m tÃ i liá»‡u vá» thuáº­t toÃ¡n nÃ y thÃ¬ láº¡i ráº¥t Ã­t áº¡",Em chÃ o má»i ngÆ°á»i áº¡ CÃ³ ai cÃ³ thá»ƒ cho em tÃ i liá»‡u tham kháº£o vá» viá»‡c sá»­ dá»¥ng Bayesian Neural Network ( BNN Model) Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ BTC báº±ng python khÃ´ng áº¡. Em lÃ m Ä‘á»“ Ã¡n nhÆ°ng kiáº¿m tÃ i liá»‡u vá» thuáº­t toÃ¡n nÃ y thÃ¬ láº¡i ráº¥t Ã­t áº¡,,,"#Q&A, #deep_learning",,
"ChÃ o cÃ¡c anh,chá»‹ trong forum.
Em sn 2000 Ä‘Ã£ ra trÆ°á»ng. Táº¥t cáº£ kiáº¿n thá»©c vá» AI em Ä‘á»u tá»± há»c nÃªn nhiá»u pháº§n kiáº¿n thá»©c láº¡i thiáº¿u mÃ  cÃ³ pháº§n láº¡i tá»‘t, vÃ  em khÃ´ng kinh nghiá»‡m cÃ¡c dá»± Ã¡n thá»±c táº¿, vÃ¬ váº­y em viáº¿t post nÃ y Ä‘á»ƒ mong anh/chá»‹ nÃ o cÃ³ thá»ƒ cho em cÆ¡ há»™i lÃ m viá»‡c Ä‘á»ƒ há»c há»i thÃªm, Ä‘Æ°á»£c lÃ m viá»‡c trong dá»± Ã¡n thá»±c táº¿. Em cÃ³ thá»ƒ thá»±c táº­p hay fresher táº¡i HCM.
Em tá»± tin vá» pháº§n giao tiáº¿p tiáº¿ng Anh hay tá»‘t nghiá»‡p á»Ÿ Ä‘h tá»‘t, mÃ  cho em há»i ngu lÃ  máº¥y anh chá»‹ tuyá»ƒn dá»¥ng giá» cÃ³ nhÃ¬n vÃ o nhá»¯ng yáº¿u tá»‘ nÃ y khÃ´ng áº¡?","ChÃ o cÃ¡c anh,chá»‹ trong forum. Em sn 2000 Ä‘Ã£ ra trÆ°á»ng. Táº¥t cáº£ kiáº¿n thá»©c vá» AI em Ä‘á»u tá»± há»c nÃªn nhiá»u pháº§n kiáº¿n thá»©c láº¡i thiáº¿u mÃ  cÃ³ pháº§n láº¡i tá»‘t, vÃ  em khÃ´ng kinh nghiá»‡m cÃ¡c dá»± Ã¡n thá»±c táº¿, vÃ¬ váº­y em viáº¿t post nÃ y Ä‘á»ƒ mong anh/chá»‹ nÃ o cÃ³ thá»ƒ cho em cÆ¡ há»™i lÃ m viá»‡c Ä‘á»ƒ há»c há»i thÃªm, Ä‘Æ°á»£c lÃ m viá»‡c trong dá»± Ã¡n thá»±c táº¿. Em cÃ³ thá»ƒ thá»±c táº­p hay fresher táº¡i HCM. Em tá»± tin vá» pháº§n giao tiáº¿p tiáº¿ng Anh hay tá»‘t nghiá»‡p á»Ÿ Ä‘h tá»‘t, mÃ  cho em há»i ngu lÃ  máº¥y anh chá»‹ tuyá»ƒn dá»¥ng giá» cÃ³ nhÃ¬n vÃ o nhá»¯ng yáº¿u tá»‘ nÃ y khÃ´ng áº¡?",,,"#Q&A, #machine_learning",,
"Em chÃ o anh chá»‹ trong group áº¡, hiá»‡n táº¡i em Ä‘ang dÃ¹ng yolov5 Ä‘á»ƒ detect object nhÆ°ng gáº·p tÃ¬nh tráº¡ng box cá»§a váº­t thá»ƒ bá»‹ chia thÃ nh 2 box nhá» thÃ¬ cÃ³ cÃ¡ch nÃ o giáº£i quyáº¿t khÃ´ng áº¡ ?
Em cáº£m Æ¡n nhiá»u.","Em chÃ o anh chá»‹ trong group áº¡, hiá»‡n táº¡i em Ä‘ang dÃ¹ng yolov5 Ä‘á»ƒ detect object nhÆ°ng gáº·p tÃ¬nh tráº¡ng box cá»§a váº­t thá»ƒ bá»‹ chia thÃ nh 2 box nhá» thÃ¬ cÃ³ cÃ¡ch nÃ o giáº£i quyáº¿t khÃ´ng áº¡ ? Em cáº£m Æ¡n nhiá»u.",,,"#Q&A, #deep_learning, #cv",,
"ChÃ o má»i ngÆ°á»i,
Cho em há»i vá» bÃ i toÃ¡n Object Detection, liá»‡u mÃ¬nh cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ cung cáº¥p thÃ´ng tin bá»• sung cho mÃ´ hÃ¬nh khÃ´ng áº¡.
VÃ­ dá»¥ nhÆ° sá»‘ lÆ°á»£ng object khÃ´ng quÃ¡ n, hoáº·c background cá»§a cÃ¡c áº£nh luÃ´n giá»‘ng nhau.
Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, Cho em há»i vá» bÃ i toÃ¡n Object Detection, liá»‡u mÃ¬nh cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ cung cáº¥p thÃ´ng tin bá»• sung cho mÃ´ hÃ¬nh khÃ´ng áº¡. VÃ­ dá»¥ nhÆ° sá»‘ lÆ°á»£ng object khÃ´ng quÃ¡ n, hoáº·c background cá»§a cÃ¡c áº£nh luÃ´n giá»‘ng nhau. Em cáº£m Æ¡n áº¡.",,,"#Q&A, #cv",,
"CHia sáº» láº¡i cho cÃ¡c báº¡n má»™t bÃ i viáº¿t cá»±c hay vá» á»©ng dá»¥ng cá»§a ML DS trong ngÃ¢n hÃ ng vÃ  cÃ¡c tá»• chá»©c tÃ i chÃ­nh.
MÃ¬nh Ä‘ang lÃ m vá» risk management cho bank thÃ¬ tháº¥y bÃ i viáº¿t Ä‘áº·c biá»‡t há»¯u Ã­ch khi mÃ¬nh hiá»ƒu thÃªm vá» cÃ¡c mÃ´ hÃ¬nh machine learning Ä‘ang Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ  khai thÃ¡c trong cÃ¡c há»‡ thá»‘ng cá»§a ngÃ¢n hÃ ng.
https://www.facebook.com/groups/1083842528922368/posts/1259824431324176",CHia sáº» láº¡i cho cÃ¡c báº¡n má»™t bÃ i viáº¿t cá»±c hay vá» á»©ng dá»¥ng cá»§a ML DS trong ngÃ¢n hÃ ng vÃ  cÃ¡c tá»• chá»©c tÃ i chÃ­nh. MÃ¬nh Ä‘ang lÃ m vá» risk management cho bank thÃ¬ tháº¥y bÃ i viáº¿t Ä‘áº·c biá»‡t há»¯u Ã­ch khi mÃ¬nh hiá»ƒu thÃªm vá» cÃ¡c mÃ´ hÃ¬nh machine learning Ä‘ang Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ  khai thÃ¡c trong cÃ¡c há»‡ thá»‘ng cá»§a ngÃ¢n hÃ ng. https://www.facebook.com/groups/1083842528922368/posts/1259824431324176,,,"#sharing, #machine_learning",,
"ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang optimize láº¡i code cá»§a em, trong lÃºc optimize thÃ¬ em nháº­n tháº¥y má»™t Ä‘iá»u kÃ¬ láº¡.
Cá»¥ thá»ƒ lÃ  nhÆ° hÃ¬nh 1, em táº¡o 1 tensor lÃ  mathched, sau Ä‘Ã³ truyá»n images vÃ o network, rá»“i em Ä‘o thá»i gian gÃ¡n matched[0] thÃ¬ káº¿t quáº£ lÃ  láº§n láº·p Ä‘áº§u luÃ´n tá»‘n ráº¥t nhiá»u thá»i gian mÃ  em khÃ´ng biáº¿t táº¡i sao. Váº¥n Ä‘á» Ä‘Ã³ chá»‰ lÃ  má»™t phÃ©p gÃ¡n.
NhÆ°ng nhÆ° trong hÃ¬nh 2, náº¿u em khÃ´ng truyá»n images vÃ o network vÃ  Ä‘o thá»i gian em gÃ¡n matched[0] thÃ¬ nÃ³ láº¡i ráº¥t nhanh. Váº­y lÃ­ do lÃ  do Ä‘Ã¢u váº­y áº¡.
// em Ä‘ang Ä‘á»ƒ config.device = ""cuda""","ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang optimize láº¡i code cá»§a em, trong lÃºc optimize thÃ¬ em nháº­n tháº¥y má»™t Ä‘iá»u kÃ¬ láº¡. Cá»¥ thá»ƒ lÃ  nhÆ° hÃ¬nh 1, em táº¡o 1 tensor lÃ  mathched, sau Ä‘Ã³ truyá»n images vÃ o network, rá»“i em Ä‘o thá»i gian gÃ¡n matched[0] thÃ¬ káº¿t quáº£ lÃ  láº§n láº·p Ä‘áº§u luÃ´n tá»‘n ráº¥t nhiá»u thá»i gian mÃ  em khÃ´ng biáº¿t táº¡i sao. Váº¥n Ä‘á» Ä‘Ã³ chá»‰ lÃ  má»™t phÃ©p gÃ¡n. NhÆ°ng nhÆ° trong hÃ¬nh 2, náº¿u em khÃ´ng truyá»n images vÃ o network vÃ  Ä‘o thá»i gian em gÃ¡n matched[0] thÃ¬ nÃ³ láº¡i ráº¥t nhanh. Váº­y lÃ­ do lÃ  do Ä‘Ã¢u váº­y áº¡. // em Ä‘ang Ä‘á»ƒ config.device = ""cuda""",,,"#Q&A, #deep_learning",,
"ChÃ o cáº£ nhÃ . MÃ¬nh Ä‘ang bá»‹ váº¥n Ä‘á» nÃ y khi cháº¡y TheBloke/vicuna-7B-GPTQ-4bit-128g hoáº·c Neko-Institute-of-Science/LLaMA-13B-4bit-128g trÃªn text-generation-webui vÃ  khÃ´ng biáº¿t táº¡i sao láº¡i bá»‹ váº­y. 
MÃ¬nh cÅ©ng Ä‘Ã£ test cháº¡y anon8231489123/vicuna-13b-GPTQ-4bit-128g vá»›i cÃ¹ng thÃ´ng sá»‘ vÃ  khÃ´ng bá»‹ váº¥n Ä‘á» gÃ¬ cáº£.

- ÄÃ¢y lÃ  cÃ¢u lá»‡nh Ä‘á»ƒ mÃ¬nh cháº¡y server:
 python server.py --share --auto-devices --chat --model-menu --wbits 4 --groupsize 128
Mong má»i ngÆ°á»i giÃºp mÃ¬nh. MÃ¬nh cÃ¡m Æ¡n ráº¥t nhiá»u!",ChÃ o cáº£ nhÃ . MÃ¬nh Ä‘ang bá»‹ váº¥n Ä‘á» nÃ y khi cháº¡y TheBloke/vicuna-7B-GPTQ-4bit-128g hoáº·c Neko-Institute-of-Science/LLaMA-13B-4bit-128g trÃªn text-generation-webui vÃ  khÃ´ng biáº¿t táº¡i sao láº¡i bá»‹ váº­y. MÃ¬nh cÅ©ng Ä‘Ã£ test cháº¡y anon8231489123/vicuna-13b-GPTQ-4bit-128g vá»›i cÃ¹ng thÃ´ng sá»‘ vÃ  khÃ´ng bá»‹ váº¥n Ä‘á» gÃ¬ cáº£. - ÄÃ¢y lÃ  cÃ¢u lá»‡nh Ä‘á»ƒ mÃ¬nh cháº¡y server: python server.py --share --auto-devices --chat --model-menu --wbits 4 --groupsize 128 Mong má»i ngÆ°á»i giÃºp mÃ¬nh. MÃ¬nh cÃ¡m Æ¡n ráº¥t nhiá»u!,,,#Q&A,,
"MEDIAPIPE: LOW-CODE NO-CODE AI FOR EVERYONE
Báº¡n nÃ o quan tÃ¢m Ä‘áº¿n á»©ng dá»¥ng AI thÃ¬ nhá»› dÃ¹ng thá»­ MediaPipe lÃ  thÆ° viá»‡n Ä‘á»ƒ cÃ¡c báº¡n developer cÃ³ thá»ƒ tÃ­ch há»£p AI vÃ o á»©ng dá»¥ng cá»§a mÃ¬nh má»™t cÃ¡ch dá»… dÃ ng chá»‰ vá»›i má»™t vÃ i dÃ²ng code nhÃ©. Team mÃ¬nh má»›i ra máº¯t phiÃªn báº£n má»›i cá»§a MediaPipe á»Ÿ Google I/O nÄƒm nay vá»›i 14 API phá»¥c vá»¥ nhiá»u use case khÃ¡c nhau nhÆ° face landmark detection, selfie segmentation v.v. CÃ¡c báº¡n muá»‘n biáº¿t cá»¥ thá»ƒ hÆ¡n thÃ¬ xem video I/O nÃ y cá»§a mÃ¬nh nhÃ©. Hy vá»ng thÆ° viá»‡n nÃ y sáº½ há»¯u Ã­ch cho cÃ¡c báº¡n! https://youtu.be/yOP_FY2KTm8P/S: Bonus thÃªm dÆ°á»›i comment lÃ  video vá» Project Gameface, cÃ´ng cá»¥ Ä‘á»ƒ dÃ¹ng khuÃ´n máº·t Ä‘iá»u khiá»ƒn con chuá»™t mÃ¡y tÃ­nh bá»n mÃ¬nh build vá»›i MediaPipe. Source code cÃ³ trÃªn GitHub cho nhá»¯ng báº¡n muá»‘n tÃ¬m hiá»ƒu ká»¹ hÆ¡n nhÃ©.","MEDIAPIPE: LOW-CODE NO-CODE AI FOR EVERYONE Báº¡n nÃ o quan tÃ¢m Ä‘áº¿n á»©ng dá»¥ng AI thÃ¬ nhá»› dÃ¹ng thá»­ MediaPipe lÃ  thÆ° viá»‡n Ä‘á»ƒ cÃ¡c báº¡n developer cÃ³ thá»ƒ tÃ­ch há»£p AI vÃ o á»©ng dá»¥ng cá»§a mÃ¬nh má»™t cÃ¡ch dá»… dÃ ng chá»‰ vá»›i má»™t vÃ i dÃ²ng code nhÃ©. Team mÃ¬nh má»›i ra máº¯t phiÃªn báº£n má»›i cá»§a MediaPipe á»Ÿ Google I/O nÄƒm nay vá»›i 14 API phá»¥c vá»¥ nhiá»u use case khÃ¡c nhau nhÆ° face landmark detection, selfie segmentation v.v. CÃ¡c báº¡n muá»‘n biáº¿t cá»¥ thá»ƒ hÆ¡n thÃ¬ xem video I/O nÃ y cá»§a mÃ¬nh nhÃ©. Hy vá»ng thÆ° viá»‡n nÃ y sáº½ há»¯u Ã­ch cho cÃ¡c báº¡n! https://youtu.be/yOP_FY2KTm8P/S: Bonus thÃªm dÆ°á»›i comment lÃ  video vá» Project Gameface, cÃ´ng cá»¥ Ä‘á»ƒ dÃ¹ng khuÃ´n máº·t Ä‘iá»u khiá»ƒn con chuá»™t mÃ¡y tÃ­nh bá»n mÃ¬nh build vá»›i MediaPipe. Source code cÃ³ trÃªn GitHub cho nhá»¯ng báº¡n muá»‘n tÃ¬m hiá»ƒu ká»¹ hÆ¡n nhÃ©.",,,"#sharing, #machine_learning",,
"Hi má»i ngÆ°á»i,

MÃ¬nh muá»‘n há»i chÃºt vá» cÃ¡ch freeze 1 custom model.

MÃ¬nh cÃ³ 1 model gá»“m 2 blocks,
MÃ¬nh muá»‘n train tá»«ng block theo cÃ¡ch nhÆ° sau:
Freeze block 2, train block 1 vÃ  lÆ°u weight
Load weight Ä‘Ã£ lÆ°u, freeze block 1 vÃ  train block 2.
MÃ¬nh muá»‘n há»i lÃ  lÃ m cÃ¡ch nÃ o Ä‘á»ƒ freeze cÃ¡c layer á»Ÿ má»—i block dÃ¹ng pytorch?
MÃ¬nh Ä‘Ã£ thá»­:

for param in block1.parameters():
    param.requires_grad = True (False)

NhÆ°ng khi lÃ m nhÆ° nÃ y thÃ¬ táº¥t cáº£ param Ä‘á»u bá»‹ set requires_grad = False háº¿t. Náº¿u k dÃ¹ng Ä‘oáº¡n code trÃªn (nghÄ©a lÃ  k set gÃ¬ cáº£) thÃ¬ requires_grad cá»§a cÃ¡c param trong 2 blocks váº«n lÃ  True.

Ae ai gáº·p pháº£i váº¥n Ä‘á» nhÆ° váº­y cho mÃ¬nh Ã½ kiáº¿n vs nhÃ©. Thank you!","Hi má»i ngÆ°á»i, MÃ¬nh muá»‘n há»i chÃºt vá» cÃ¡ch freeze 1 custom model. MÃ¬nh cÃ³ 1 model gá»“m 2 blocks, MÃ¬nh muá»‘n train tá»«ng block theo cÃ¡ch nhÆ° sau: Freeze block 2, train block 1 vÃ  lÆ°u weight Load weight Ä‘Ã£ lÆ°u, freeze block 1 vÃ  train block 2. MÃ¬nh muá»‘n há»i lÃ  lÃ m cÃ¡ch nÃ o Ä‘á»ƒ freeze cÃ¡c layer á»Ÿ má»—i block dÃ¹ng pytorch? MÃ¬nh Ä‘Ã£ thá»­: for param in block1.parameters(): param.requires_grad = True (False) NhÆ°ng khi lÃ m nhÆ° nÃ y thÃ¬ táº¥t cáº£ param Ä‘á»u bá»‹ set requires_grad = False háº¿t. Náº¿u k dÃ¹ng Ä‘oáº¡n code trÃªn (nghÄ©a lÃ  k set gÃ¬ cáº£) thÃ¬ requires_grad cá»§a cÃ¡c param trong 2 blocks váº«n lÃ  True. Ae ai gáº·p pháº£i váº¥n Ä‘á» nhÆ° váº­y cho mÃ¬nh Ã½ kiáº¿n vs nhÃ©. Thank you!",,,"#Q&A, #machine_learning",,
"Xin chÃ o má»i ngÆ°á»i, em cÃ³ má»™t cÃ¢u há»i nhÆ° nÃ y áº¡, e tÃ­nh hÃ¨ nÃ y sáº½ há»c hai khoÃ¡ vá» ML trÃªn cousera nhÆ°ng má»i ngÆ°á»i nÃ³i há»c máº¥y khoÃ¡ Ä‘Ã³ Ä‘á»ƒ cÃ³ kiáº¿n thá»©c ná»n táº£ng chá»© basic quÃ¡, Ä‘i lÃ m khÃ´ng Äƒn thua.
Váº­y náº¿u nhÆ° há»c xong thÃ¬ mÃ¬nh nÃªn lÃ m gÃ¬, há»c gÃ¬ tiáº¿p theo Ä‘á»ƒ cÃ³ thá»ƒ Ä‘i lÃ m Ä‘Æ°á»£c áº¡. Em váº«n chÆ°a hÃ¬nh dung ra. Bá»Ÿi vÃ¬ e tháº¥y cac cty chá»‰ tuyá»ƒn ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» ML Ä‘i lÃ m chá»© k tuyá»ƒn intern.
Mong mn giáº£i Ä‘Ã¡p áº¡.","Xin chÃ o má»i ngÆ°á»i, em cÃ³ má»™t cÃ¢u há»i nhÆ° nÃ y áº¡, e tÃ­nh hÃ¨ nÃ y sáº½ há»c hai khoÃ¡ vá» ML trÃªn cousera nhÆ°ng má»i ngÆ°á»i nÃ³i há»c máº¥y khoÃ¡ Ä‘Ã³ Ä‘á»ƒ cÃ³ kiáº¿n thá»©c ná»n táº£ng chá»© basic quÃ¡, Ä‘i lÃ m khÃ´ng Äƒn thua. Váº­y náº¿u nhÆ° há»c xong thÃ¬ mÃ¬nh nÃªn lÃ m gÃ¬, há»c gÃ¬ tiáº¿p theo Ä‘á»ƒ cÃ³ thá»ƒ Ä‘i lÃ m Ä‘Æ°á»£c áº¡. Em váº«n chÆ°a hÃ¬nh dung ra. Bá»Ÿi vÃ¬ e tháº¥y cac cty chá»‰ tuyá»ƒn ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» ML Ä‘i lÃ m chá»© k tuyá»ƒn intern. Mong mn giáº£i Ä‘Ã¡p áº¡.",,,"#Q&A, #machine_learning",,
em cÃ³ má»™t bÃ i táº­p training model nhÆ°ng bá»‹ lá»—i SPPF khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai bá»‹ lá»—i nÃ y nhÆ° em khÃ´ng áº¡. Em Ä‘ang tÃ¬m cÃ¡ch fix mong anh chá»‹ giÃºp Ä‘á»¡,em cÃ³ má»™t bÃ i táº­p training model nhÆ°ng bá»‹ lá»—i SPPF khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai bá»‹ lá»—i nÃ y nhÆ° em khÃ´ng áº¡. Em Ä‘ang tÃ¬m cÃ¡ch fix mong anh chá»‹ giÃºp Ä‘á»¡,,,"#Q&A, #machine_learning",,
"Dáº¡ chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang muá»‘n fine-tune mÃ´ hÃ¬nh TrOCR cho dá»¯ liá»‡u bao gá»“m cÃ´ng thá»©c Latex, tiáº¿ng Viá»‡t vÃ  cáº£ tiáº¿ng Anh nhÆ°ng trÆ°á»›c háº¿t em Ä‘ang thá»­ vá»›i má»—i Latex khÃ´ng thÃ´i xem nhÆ° tháº¿ nÃ o thÃ¬ CER mÃ£i váº«n khÃ´ng xuá»‘ng quÃ¡ 0.27, khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ kinh nghiá»‡m gÃ¬ khi fine-tune mÃ´ hÃ¬nh trÃªn má»™t táº­p dataset custom vÃ  cÃ³ thá»ƒ cho em vÃ i gá»£i Ã½ Ä‘á»ƒ thá»±c hiá»‡n bÃ i toÃ¡n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? VÃ¬ em chÆ°a cÃ³ nhiá»u kinh nghiá»‡m nÃªn gáº·p khÃ³ khÄƒn, em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i.","Dáº¡ chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang muá»‘n fine-tune mÃ´ hÃ¬nh TrOCR cho dá»¯ liá»‡u bao gá»“m cÃ´ng thá»©c Latex, tiáº¿ng Viá»‡t vÃ  cáº£ tiáº¿ng Anh nhÆ°ng trÆ°á»›c háº¿t em Ä‘ang thá»­ vá»›i má»—i Latex khÃ´ng thÃ´i xem nhÆ° tháº¿ nÃ o thÃ¬ CER mÃ£i váº«n khÃ´ng xuá»‘ng quÃ¡ 0.27, khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ kinh nghiá»‡m gÃ¬ khi fine-tune mÃ´ hÃ¬nh trÃªn má»™t táº­p dataset custom vÃ  cÃ³ thá»ƒ cho em vÃ i gá»£i Ã½ Ä‘á»ƒ thá»±c hiá»‡n bÃ i toÃ¡n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? VÃ¬ em chÆ°a cÃ³ nhiá»u kinh nghiá»‡m nÃªn gáº·p khÃ³ khÄƒn, em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i.",,,"#Q&A, #deep_learning",,
"ChÃ o cÃ¡c anh,chá»‹ trong forum.
Em sn 2000 Ä‘Ã£ ra trÆ°á»ng. Do lÃºc trÆ°á»›c Ä‘i há»c khÃ´ng cÃ³ Ä‘á»‹nh hÆ°á»›ng sá»›m nÃªn pháº£i Ä‘áº¿n gáº§n lÃºc ra trÆ°á»ng má»›i xÃ¡c Ä‘á»‹nh theo AI. Em Ä‘Ã£ Ä‘i thá»±c táº­p nhÆ°ng hiá»‡n táº¡i khÃ´ng cÃ³ viá»‡c lÃ m.
Táº¥t cáº£ kiáº¿n thá»©c vá» AI em Ä‘á»u tá»± há»c nÃªn thiáº¿u kinh nghiá»‡m lÃ m viá»‡c táº¡i cÃ¡c dá»± Ã¡n thá»±c táº¿, vÃ¬ váº­y em viáº¿t post nÃ y Ä‘á»ƒ mong anh/chá»‹ nÃ o cÃ³ thá»ƒ cho em cÆ¡ há»™i lÃ m viá»‡c Ä‘á»ƒ há»c há»i thÃªm, Ä‘Æ°á»£c lÃ m viá»‡c trong dá»± Ã¡n thá»±c táº¿. Em cÃ³ thá»ƒ Ä‘i lÃ m khÃ´ng lÆ°Æ¡ng vÃ  lÃ m viá»‡c táº¡i HÃ  Ná»™i.
Em cáº£m Æ¡n nhiá»u.","ChÃ o cÃ¡c anh,chá»‹ trong forum. Em sn 2000 Ä‘Ã£ ra trÆ°á»ng. Do lÃºc trÆ°á»›c Ä‘i há»c khÃ´ng cÃ³ Ä‘á»‹nh hÆ°á»›ng sá»›m nÃªn pháº£i Ä‘áº¿n gáº§n lÃºc ra trÆ°á»ng má»›i xÃ¡c Ä‘á»‹nh theo AI. Em Ä‘Ã£ Ä‘i thá»±c táº­p nhÆ°ng hiá»‡n táº¡i khÃ´ng cÃ³ viá»‡c lÃ m. Táº¥t cáº£ kiáº¿n thá»©c vá» AI em Ä‘á»u tá»± há»c nÃªn thiáº¿u kinh nghiá»‡m lÃ m viá»‡c táº¡i cÃ¡c dá»± Ã¡n thá»±c táº¿, vÃ¬ váº­y em viáº¿t post nÃ y Ä‘á»ƒ mong anh/chá»‹ nÃ o cÃ³ thá»ƒ cho em cÆ¡ há»™i lÃ m viá»‡c Ä‘á»ƒ há»c há»i thÃªm, Ä‘Æ°á»£c lÃ m viá»‡c trong dá»± Ã¡n thá»±c táº¿. Em cÃ³ thá»ƒ Ä‘i lÃ m khÃ´ng lÆ°Æ¡ng vÃ  lÃ m viá»‡c táº¡i HÃ  Ná»™i. Em cáº£m Æ¡n nhiá»u.",,,"#Q&A, #machine_learning",,
Em Ä‘ang cÃ³ bÃ i táº­p lÃ  vá» seq2seq cho bÃ i toÃ¡n summarization nhÆ°ng trÃªn model nÃ³ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c lÃ  khoáº£ng 0.4% lÃ  cÃ³ thá»ƒ dá»± Ä‘oÃ¡n cÃ¡c tá»« tiáº¿p theo. CÃ¡c bÃ¡c cÃ³ thá»ƒ xem code dÆ°á»›i Ä‘Ã¢y cho em há»i code em dá»± Ä‘oÃ¡n Ä‘Ãºng chÆ°a hay em Ä‘ang lÃ m sai chá»— nÃ o. Em xin cÃ¡m Æ¡n.,Em Ä‘ang cÃ³ bÃ i táº­p lÃ  vá» seq2seq cho bÃ i toÃ¡n summarization nhÆ°ng trÃªn model nÃ³ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c lÃ  khoáº£ng 0.4% lÃ  cÃ³ thá»ƒ dá»± Ä‘oÃ¡n cÃ¡c tá»« tiáº¿p theo. CÃ¡c bÃ¡c cÃ³ thá»ƒ xem code dÆ°á»›i Ä‘Ã¢y cho em há»i code em dá»± Ä‘oÃ¡n Ä‘Ãºng chÆ°a hay em Ä‘ang lÃ m sai chá»— nÃ o. Em xin cÃ¡m Æ¡n.,,,"#Q&A, #deep_learning, #nlp",,
"ChÃ o má»i ngÆ°á»i áº¡! E lÃ  sinh viÃªn, e má»›i mua Ä‘Æ°á»£c chiáº¿c vga rtx 3060 vÃ  32GB RAM, e muá»‘n build 1 PC Ä‘á»ƒ há»c táº­p vÃ  lÃ m nghiÃªn cá»©u vá» computer vision, vÃ¬ budget cá»§a e khÃ´ng Ä‘Æ°á»£c cao láº¯m nÃªn e Ä‘ang tÃ­nh mua con CPU i3 12100F. Má»i ngÆ°á»i cho e há»i con CPU nÃ y cÃ³ Ä‘á»§ cho viá»‡c há»c táº­p vÃ  nghiÃªn cá»©u vá» Computer Vision, deep learning khÃ´ng áº¡? E cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i áº¡! E lÃ  sinh viÃªn, e má»›i mua Ä‘Æ°á»£c chiáº¿c vga rtx 3060 vÃ  32GB RAM, e muá»‘n build 1 PC Ä‘á»ƒ há»c táº­p vÃ  lÃ m nghiÃªn cá»©u vá» computer vision, vÃ¬ budget cá»§a e khÃ´ng Ä‘Æ°á»£c cao láº¯m nÃªn e Ä‘ang tÃ­nh mua con CPU i3 12100F. Má»i ngÆ°á»i cho e há»i con CPU nÃ y cÃ³ Ä‘á»§ cho viá»‡c há»c táº­p vÃ  nghiÃªn cá»©u vá» Computer Vision, deep learning khÃ´ng áº¡? E cáº£m Æ¡n má»i ngÆ°á»i",,,"#Q&A, #cv",,
"ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t á»Ÿ Ä‘Ã¢y cÃ³ báº¡n sinh viÃªn nÃ o Ä‘ang lÃ m project vá» computer vision k áº¡, cÃ³ thá»ƒ cho mÃ¬nh 1 chÃ¢n vÃ´ há»— trá»£ khÃ´ng cÃ´ng Ä‘Æ°á»£c k táº¡i mÃ¬nh muá»‘n tÃ­ch lÅ©y thÃªm kinh nghiá»‡m tá»« nhá»¯ng project áº¥y nÃªn chá»§ yáº¿u vá»«a giÃºp láº¡i vá»«a há»c há»i cÃ¡i má»›i luÃ´n áº¡. Ai cÃ³ nhu cáº§u thÃ¬ cá»© cmt mÃ¬nh giÃºp háº¿t mÃ¬nh nha !!!!","ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t á»Ÿ Ä‘Ã¢y cÃ³ báº¡n sinh viÃªn nÃ o Ä‘ang lÃ m project vá» computer vision k áº¡, cÃ³ thá»ƒ cho mÃ¬nh 1 chÃ¢n vÃ´ há»— trá»£ khÃ´ng cÃ´ng Ä‘Æ°á»£c k táº¡i mÃ¬nh muá»‘n tÃ­ch lÅ©y thÃªm kinh nghiá»‡m tá»« nhá»¯ng project áº¥y nÃªn chá»§ yáº¿u vá»«a giÃºp láº¡i vá»«a há»c há»i cÃ¡i má»›i luÃ´n áº¡. Ai cÃ³ nhu cáº§u thÃ¬ cá»© cmt mÃ¬nh giÃºp háº¿t mÃ¬nh nha !!!!",,,"#Q&A, #cv",,
"Mojo Programming Language

Chris Lattner (tÃ¡c giáº£ LLVM, ngÃ´n ngá»¯ Swift), Tim Davis vÃ  team Modular vá»«a cho ra máº¯t ngÃ´n ngá»¯ láº­p trÃ¬nh Mojo. ÄÆ°á»£c cho lÃ  dá»… Ä‘á»c nhÆ° Python, nhanh hÆ¡n tá»‘c Ä‘á»™ cá»§a C++ vÃ  safety nhÆ° Rust - gáº§n nhÆ° lÃ  tháº¿ máº¡nh cá»§a tá»«ng ngÃ´n ngá»¯ - vÃ o trong Mojo. Äiá»ƒm hay ho cá»§a Mojo lÃ  cho phÃ©p truy cáº­p toÃ n bá»™ há»‡ sinh thÃ¡i cÃ³ sáºµn cá»§a Python, vÃ­ dá»¥ nhÆ° lÃ  NumPy, Pandas, Matplotlib trá»±c tiáº¿p trong Mojo (Mojo is actually a superset of Python, so I can use my Python code).

Hiá»‡n táº¡i Mojo Ä‘ang á»Ÿ trong giai Ä‘oáº¡n beta.

Product Launch 2023 Keynote ngÃ y 03/05/2023 cÃ²n nÃªu ra nhá»¯ng váº¥n Ä‘á» vá» chi phÃ­, pháº§n cá»©ng, cÆ¡ sá»Ÿ háº¡ táº§ng khi triá»ƒn khai vÃ  xÃ¢y dá»±ng cÃ¡c há»‡ thá»‘ng AI.

Náº¿u nhá»¯ng gÃ¬ team Modular nÃ³i lÃ  Ä‘Ãºng, thÃ¬ Ä‘Ã¢y sáº½ lÃ  má»™t bÆ°á»›c ngoáº·t tÆ°Æ¡ng Ä‘á»‘i lá»›n ğŸ‘€

Link: https://www.youtube.com/watch?v=-3Kf2ZZU-dg","Mojo Programming Language Chris Lattner (tÃ¡c giáº£ LLVM, ngÃ´n ngá»¯ Swift), Tim Davis vÃ  team Modular vá»«a cho ra máº¯t ngÃ´n ngá»¯ láº­p trÃ¬nh Mojo. ÄÆ°á»£c cho lÃ  dá»… Ä‘á»c nhÆ° Python, nhanh hÆ¡n tá»‘c Ä‘á»™ cá»§a C++ vÃ  safety nhÆ° Rust - gáº§n nhÆ° lÃ  tháº¿ máº¡nh cá»§a tá»«ng ngÃ´n ngá»¯ - vÃ o trong Mojo. Äiá»ƒm hay ho cá»§a Mojo lÃ  cho phÃ©p truy cáº­p toÃ n bá»™ há»‡ sinh thÃ¡i cÃ³ sáºµn cá»§a Python, vÃ­ dá»¥ nhÆ° lÃ  NumPy, Pandas, Matplotlib trá»±c tiáº¿p trong Mojo (Mojo is actually a superset of Python, so I can use my Python code). Hiá»‡n táº¡i Mojo Ä‘ang á»Ÿ trong giai Ä‘oáº¡n beta. Product Launch 2023 Keynote ngÃ y 03/05/2023 cÃ²n nÃªu ra nhá»¯ng váº¥n Ä‘á» vá» chi phÃ­, pháº§n cá»©ng, cÆ¡ sá»Ÿ háº¡ táº§ng khi triá»ƒn khai vÃ  xÃ¢y dá»±ng cÃ¡c há»‡ thá»‘ng AI. Náº¿u nhá»¯ng gÃ¬ team Modular nÃ³i lÃ  Ä‘Ãºng, thÃ¬ Ä‘Ã¢y sáº½ lÃ  má»™t bÆ°á»›c ngoáº·t tÆ°Æ¡ng Ä‘á»‘i lá»›n Link: https://www.youtube.com/watch?v=-3Kf2ZZU-dg",,,"#sharing, #python",,
"ChÃ o cáº£ nhÃ ,
Hiá»‡n em Ä‘ang Ä‘á»c hiá»ƒu paper nÃ y (https://arxiv.org/abs/1907.02189) vá» convergence proof cá»§a federated learning. Khi chá»©ng minh Theorem 1 á»Ÿ cuá»‘i trang 14 thÃ¬ tÃ¡c giáº£ cÃ³ chuyá»ƒn tá»« F^*_k sang F^* nhÆ° trong hÃ¬nh Ä‘Ã­nh kÃ¨m. Má»i ngÆ°á»i cho em há»i lÃ  táº¡i sao láº¡i lÃ m nhÆ° váº­y Ä‘Æ°á»£c khÃ´ng áº¡?
Cáº£m Æ¡n má»i ngÆ°á»i!","ChÃ o cáº£ nhÃ , Hiá»‡n em Ä‘ang Ä‘á»c hiá»ƒu paper nÃ y (https://arxiv.org/abs/1907.02189) vá» convergence proof cá»§a federated learning. Khi chá»©ng minh Theorem 1 á»Ÿ cuá»‘i trang 14 thÃ¬ tÃ¡c giáº£ cÃ³ chuyá»ƒn tá»« F^*_k sang F^* nhÆ° trong hÃ¬nh Ä‘Ã­nh kÃ¨m. Má»i ngÆ°á»i cho em há»i lÃ  táº¡i sao láº¡i lÃ m nhÆ° váº­y Ä‘Æ°á»£c khÃ´ng áº¡? Cáº£m Æ¡n má»i ngÆ°á»i!",,,"#Q&A, #math",,
,nan,,,,,
"Hello chÃ o cáº£ nhÃ ! MÃ¬nh muá»‘n há»i build 1 con server Ä‘á»ƒ training vá»›i cáº¥u hÃ¬nh sau:
- cpu: intel core i7 12700K
- gpu: x2 RTX 3060 12GB
ThÃ¬ liá»‡u chip core cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u nÄƒng khi sá»­ dá»¥ng cÃ¹ng vá»›i 2 card rá»i khÃ´ng hay main quyáº¿t Ä‘á»‹nh áº¡.
Mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p.
MÃ¬nh cÃ¡m Æ¡n.",Hello chÃ o cáº£ nhÃ ! MÃ¬nh muá»‘n há»i build 1 con server Ä‘á»ƒ training vá»›i cáº¥u hÃ¬nh sau: - cpu: intel core i7 12700K - gpu: x2 RTX 3060 12GB ThÃ¬ liá»‡u chip core cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u nÄƒng khi sá»­ dá»¥ng cÃ¹ng vá»›i 2 card rá»i khÃ´ng hay main quyáº¿t Ä‘á»‹nh áº¡. Mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p. MÃ¬nh cÃ¡m Æ¡n.,,,#Q&A,,
"Hello everyone, I need a data set of Danish language including handwriting or typing. Anyone who can share or sell, please comment below. Main purpose for research research and study.Thank you everyone","Hello everyone, I need a data set of Danish language including handwriting or typing. Anyone who can share or sell, please comment below. Main purpose for research research and study.Thank you everyone",,,#data,,
"ChÃ o má»i ngÆ°á»i , em lÃ  má»™t há»c sinh cáº¥p 3 Ä‘ang tÃ¬m tÃ²i vá» cÃ¡c kiáº¿n thá»©c cá»§a Machine learning vÃ  xá»­ lÃ½ áº£nh cho cuá»™c thi nghiÃªn cá»©u khoa há»c . Em Ä‘ang lÃ m má»™t mini-project vá» phÃ¢n loáº¡i rÃ¡c thÃ¬ em cÃ³ tháº¯c máº¯c lÃ  giá»¯a rÃ¡c tÃ¡i cháº¿ vÃ  rÃ¡c khÃ´ng tÃ¡i cháº¿ thÃ¬ khi xá»­ lÃ½ áº£nh em cáº§n pháº£i phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ nÃ o cá»§a rÃ¡c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°a vÃ o táº­p dá»¯ liá»‡u . Song vá»›i Ä‘Ã³ lÃ  em cÅ©ng muá»‘n Ä‘Æ°á»£c má»i ngÆ°á»i chá»‰ giÃ¡o vá» cÃ¡c hÆ°á»›ng Ä‘á»ƒ phÃ¢n tÃ­ch áº£nh áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i , em lÃ  má»™t há»c sinh cáº¥p 3 Ä‘ang tÃ¬m tÃ²i vá» cÃ¡c kiáº¿n thá»©c cá»§a Machine learning vÃ  xá»­ lÃ½ áº£nh cho cuá»™c thi nghiÃªn cá»©u khoa há»c . Em Ä‘ang lÃ m má»™t mini-project vá» phÃ¢n loáº¡i rÃ¡c thÃ¬ em cÃ³ tháº¯c máº¯c lÃ  giá»¯a rÃ¡c tÃ¡i cháº¿ vÃ  rÃ¡c khÃ´ng tÃ¡i cháº¿ thÃ¬ khi xá»­ lÃ½ áº£nh em cáº§n pháº£i phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ nÃ o cá»§a rÃ¡c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°a vÃ o táº­p dá»¯ liá»‡u . Song vá»›i Ä‘Ã³ lÃ  em cÅ©ng muá»‘n Ä‘Æ°á»£c má»i ngÆ°á»i chá»‰ giÃ¡o vá» cÃ¡c hÆ°á»›ng Ä‘á»ƒ phÃ¢n tÃ­ch áº£nh áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,"#Q&A, #machine_learning, #cv",,
"ğŸ”¥ #Neuron #Rendering, nhá»¯ng bÆ°á»›c tiáº¿n má»›i nháº¥t trong xá»­ lÃ½ Ä‘á»“ há»a vá»›i AI",nhá»¯ng bÆ°á»›c tiáº¿n má»›i nháº¥t trong xá»­ lÃ½ Ä‘á»“ há»a vá»›i AI,"#Neuron	#Rendering,",,"#sharing, #cv",,
"Hello cáº£ nhÃ  cho mÃ¬nh xin phÃ©p chia sáº» má»™t táº­p podcast episode mÃ  bÃªn Forward Vietnam Podcast bá»n mÃ¬nh vá»«a thu vá»›i anh Phong Nguyen - Chief AI Officer táº¡i FPT Software. Náº¿u má»i ngÆ°á»i trong group muá»‘n tÃ¬m hiá»ƒu thÃªm vá» Al, ChatGPT, vÃ  FPT thÃ¬ cÃ³ thá»ƒ check it out á»Ÿ Ä‘Ã¢y áº¡:
Youtube: https://youtu.be/UhP417Xn-L0
Spotify: https://open.spotify.com/episode/5tiEqSwcZALcJ6Z6OP4T18?si=KJcNKw7sTi2zCaDjh7HzVw
Apple Podcast: https://podcasts.apple.com/us/podcast/forward-vietnam-podcast/id1653799053?i=1000611506073
Forward Vietnam Podcast lÃ  nÆ¡i chÃºng mÃ¬nh bÃ n luáº­n vÃ  chia sáº» tá»›i cá»™ng Ä‘á»“ng nhá»¯ng cuá»™c tháº£o luáº­n vá» cÃ´ng viá»‡c, tÃ i chÃ­nh, kinh doanh, cÃ´ng nghá»‡ vÃ  cuá»™c sá»‘ng cá»§a cÃ¡c báº¡n tráº» tá»« Viá»‡t Nam. CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm vá» podcast cá»§a bá»n mÃ¬nh táº¡i Ä‘Æ°á»ng link dÆ°á»›i Ä‘Ã¢y nha. ChÃºng mÃ¬nh ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± pháº£n há»“i tá»« má»i ngÆ°á»i nhÃ©!
https://linktr.ee/forwardvietnampodcast","Hello cáº£ nhÃ  cho mÃ¬nh xin phÃ©p chia sáº» má»™t táº­p podcast episode mÃ  bÃªn Forward Vietnam Podcast bá»n mÃ¬nh vá»«a thu vá»›i anh Phong Nguyen - Chief AI Officer táº¡i FPT Software. Náº¿u má»i ngÆ°á»i trong group muá»‘n tÃ¬m hiá»ƒu thÃªm vá» Al, ChatGPT, vÃ  FPT thÃ¬ cÃ³ thá»ƒ check it out á»Ÿ Ä‘Ã¢y áº¡: Youtube: https://youtu.be/UhP417Xn-L0 Spotify: https://open.spotify.com/episode/5tiEqSwcZALcJ6Z6OP4T18?si=KJcNKw7sTi2zCaDjh7HzVw Apple Podcast: https://podcasts.apple.com/us/podcast/forward-vietnam-podcast/id1653799053?i=1000611506073 Forward Vietnam Podcast lÃ  nÆ¡i chÃºng mÃ¬nh bÃ n luáº­n vÃ  chia sáº» tá»›i cá»™ng Ä‘á»“ng nhá»¯ng cuá»™c tháº£o luáº­n vá» cÃ´ng viá»‡c, tÃ i chÃ­nh, kinh doanh, cÃ´ng nghá»‡ vÃ  cuá»™c sá»‘ng cá»§a cÃ¡c báº¡n tráº» tá»« Viá»‡t Nam. CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm vá» podcast cá»§a bá»n mÃ¬nh táº¡i Ä‘Æ°á»ng link dÆ°á»›i Ä‘Ã¢y nha. ChÃºng mÃ¬nh ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± pháº£n há»“i tá»« má»i ngÆ°á»i nhÃ©! https://linktr.ee/forwardvietnampodcast",,,"#sharing, #machine_learning",,
"ChÃ o má»i ngÆ°á»i, hiá»‡n em lÃ  tháº¡c sá»¹ ngÃ´n ngá»¯ há»c, e Ä‘ang tÃ¬m hiá»ƒu vá» á»©ng dá»¥ng ngÃ´n ngá»¯ vÃ o khoa há»c mÃ¡y tÃ­nh, e cÃ³ tháº¥y máº£ng xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP) thÃ¬ káº¿t há»£p cáº£ kiáº¿n thá»©c vá» ngÃ´n ngá»¯ há»c vÃ  mÃ¡y tÃ­nh. Do em chÆ°a cÃ³ kiáº¿n thá»©c gÃ¬ vá» ngÃ nh khoa há»c mÃ¡y tÃ­nh, cÃ¡c anh/ chá»‹ cho em há»i Ä‘á»‘i vá»›i ngÆ°á»i chÆ°a cÃ³ ná»n táº£ng IT nhÆ° em thÃ¬ nÃªn báº¯t Ä‘áº§u há»c tá»« Ä‘Ã¢u vÃ  nhá»¯ng máº£ng nÃ o trong ngÃ nh cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c kiáº¿n thá»©c chuyÃªn sÃ¢u vá» ngÃ´n ngá»¯, ngá»¯ Ã¢m Ä‘Æ°á»£c áº¡. Em cÃ¡m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i, hiá»‡n em lÃ  tháº¡c sá»¹ ngÃ´n ngá»¯ há»c, e Ä‘ang tÃ¬m hiá»ƒu vá» á»©ng dá»¥ng ngÃ´n ngá»¯ vÃ o khoa há»c mÃ¡y tÃ­nh, e cÃ³ tháº¥y máº£ng xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP) thÃ¬ káº¿t há»£p cáº£ kiáº¿n thá»©c vá» ngÃ´n ngá»¯ há»c vÃ  mÃ¡y tÃ­nh. Do em chÆ°a cÃ³ kiáº¿n thá»©c gÃ¬ vá» ngÃ nh khoa há»c mÃ¡y tÃ­nh, cÃ¡c anh/ chá»‹ cho em há»i Ä‘á»‘i vá»›i ngÆ°á»i chÆ°a cÃ³ ná»n táº£ng IT nhÆ° em thÃ¬ nÃªn báº¯t Ä‘áº§u há»c tá»« Ä‘Ã¢u vÃ  nhá»¯ng máº£ng nÃ o trong ngÃ nh cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c kiáº¿n thá»©c chuyÃªn sÃ¢u vá» ngÃ´n ngá»¯, ngá»¯ Ã¢m Ä‘Æ°á»£c áº¡. Em cÃ¡m Æ¡n áº¡",,,"#Q&A, #nlp",,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 04/2023 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 04/2023 vÃ o comment cá»§a post nÃ y.",,,#sharing,,
"CÃ³ thá»ƒ cÃ¢u há»i Ä‘Ã£ cÅ© nhÆ°ng mÃ  cÃ¡c bÃ¡c cho em há»i vá»›i lÃ  chi tiáº¿t cÃ¡ch xÃ¡c Ä‘á»‹nh Anchor box trong YOLO vá»›i áº¡ ! khÃ´ng thÃ¬ bÃ¡c nÃ o cÃ³ tÃ i liá»‡u hay cho em xin Ä‘á»c vá»›i, chá»© em Ä‘á»c miáº¿t mÃ  nhá»¯ng cÃ¢u tráº£ lá»i chÆ°a lÃ m em tháº¥y thá»a mÃ£n hic !
P/S: Em cáº£m Æ¡n vÃ  ghi nháº­n táº¥t cáº£ cÃ¡c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p tá»« má»i ngÆ°á»i áº¡","CÃ³ thá»ƒ cÃ¢u há»i Ä‘Ã£ cÅ© nhÆ°ng mÃ  cÃ¡c bÃ¡c cho em há»i vá»›i lÃ  chi tiáº¿t cÃ¡ch xÃ¡c Ä‘á»‹nh Anchor box trong YOLO vá»›i áº¡ ! khÃ´ng thÃ¬ bÃ¡c nÃ o cÃ³ tÃ i liá»‡u hay cho em xin Ä‘á»c vá»›i, chá»© em Ä‘á»c miáº¿t mÃ  nhá»¯ng cÃ¢u tráº£ lá»i chÆ°a lÃ m em tháº¥y thá»a mÃ£n hic ! P/S: Em cáº£m Æ¡n vÃ  ghi nháº­n táº¥t cáº£ cÃ¡c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p tá»« má»i ngÆ°á»i áº¡",,,"#Q&A, #deep_learning",,
"MLOpsVN tiáº¿p tá»¥c tá»• chá»©c seminar FREE vá» cÃ´ng nghá»‡ search hay Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng khuyáº¿n nghá»‹ (recommendation system) vÃ o tá»‘i thá»© 5 tuáº§n nÃ y, má»i cÃ¡c bÃ¡c quan tÃ¢m Ä‘Äƒng kÃ½ tham gia áº¡ ğŸ˜","MLOpsVN tiáº¿p tá»¥c tá»• chá»©c seminar FREE vá» cÃ´ng nghá»‡ search hay Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng khuyáº¿n nghá»‹ (recommendation system) vÃ o tá»‘i thá»© 5 tuáº§n nÃ y, má»i cÃ¡c bÃ¡c quan tÃ¢m Ä‘Äƒng kÃ½ tham gia áº¡",,,#webinar,,
"Xin chÃ o má»i ngÆ°á»i, máº¥y ngÃ y nay e báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» Transformer model vÃ  e cÅ©ng Ä‘Ã£ tÃ¬m Ä‘á»c cÃ¡c blog Ä‘á»ƒ xem kÄ© hÆ¡n vá» cÃ¡c thuáº­t toÃ¡n cá»§a nÃ³ nhÆ°ng mÃ  e tháº¥y cÃ³ khÃ¡ Ã­t blog báº±ng Tiáº¿ng Viá»‡t nÃ³i Ä‘áº¿n . Váº­y nÃªn trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu, e Ä‘Ã£ viáº¿t 1 bÃ i viáº¿t nÃ³i chi tiáº¿t tá»«ng bÆ°á»›c má»™t sá»‘ thuáº­t toÃ¡n cÆ¡ báº£n cá»§a Transformer model theo cÃ¡i cÃ¡ch mÃ  e Ä‘Ã£ hiá»ƒu . Bá»Ÿi vÃ¬ e cÅ©ng má»›i há»c nÃªn sá»± nháº§m láº«n vá» kiáº¿n thá»©c sáº½ xáº£y ra nÃªn e hy vá»ng sáº½ nháº­n Ä‘Æ°á»£c pháº£n há»“i cá»§a mn áº¡ @@ e cáº£m Æ¡n áº¡ !","Xin chÃ o má»i ngÆ°á»i, máº¥y ngÃ y nay e báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» Transformer model vÃ  e cÅ©ng Ä‘Ã£ tÃ¬m Ä‘á»c cÃ¡c blog Ä‘á»ƒ xem kÄ© hÆ¡n vá» cÃ¡c thuáº­t toÃ¡n cá»§a nÃ³ nhÆ°ng mÃ  e tháº¥y cÃ³ khÃ¡ Ã­t blog báº±ng Tiáº¿ng Viá»‡t nÃ³i Ä‘áº¿n . Váº­y nÃªn trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu, e Ä‘Ã£ viáº¿t 1 bÃ i viáº¿t nÃ³i chi tiáº¿t tá»«ng bÆ°á»›c má»™t sá»‘ thuáº­t toÃ¡n cÆ¡ báº£n cá»§a Transformer model theo cÃ¡i cÃ¡ch mÃ  e Ä‘Ã£ hiá»ƒu . Bá»Ÿi vÃ¬ e cÅ©ng má»›i há»c nÃªn sá»± nháº§m láº«n vá» kiáº¿n thá»©c sáº½ xáº£y ra nÃªn e hy vá»ng sáº½ nháº­n Ä‘Æ°á»£c pháº£n há»“i cá»§a mn áº¡ @@ e cáº£m Æ¡n áº¡ !",,,,,"#sharing, #deep_learning"
"MLOps Marathon lÃ  cuá»™c thi vá» MLOps Ä‘áº§u tiÃªn Ä‘Æ°á»£c tá»• chá»©c táº¡i Viá»‡t Nam nháº±m táº¡o sÃ¢n chÆ¡i cho cÃ¡c Ä‘á»™i vá»«a xÃ¢y dá»±ng cÃ¡c AI/ML model vá»«a triá»ƒn khai vÃ  váº­n hÃ nh nÃ³ trÃªn mÃ´i trÆ°á»ng production.
KhÃ´ng chá»‰ váº­y, giáº£i nháº¥t cÃ³ giÃ¡ trá»‹ lÃªn tá»›i 100 triá»‡u Ä‘á»“ng, Ä‘Äƒng kÃ½ tham gia thÃ´i nÃ o má»i ngÆ°á»i Æ¡i ğŸ¥³","MLOps Marathon lÃ  cuá»™c thi vá» MLOps Ä‘áº§u tiÃªn Ä‘Æ°á»£c tá»• chá»©c táº¡i Viá»‡t Nam nháº±m táº¡o sÃ¢n chÆ¡i cho cÃ¡c Ä‘á»™i vá»«a xÃ¢y dá»±ng cÃ¡c AI/ML model vá»«a triá»ƒn khai vÃ  váº­n hÃ nh nÃ³ trÃªn mÃ´i trÆ°á»ng production. KhÃ´ng chá»‰ váº­y, giáº£i nháº¥t cÃ³ giÃ¡ trá»‹ lÃªn tá»›i 100 triá»‡u Ä‘á»“ng, Ä‘Äƒng kÃ½ tham gia thÃ´i nÃ o má»i ngÆ°á»i Æ¡i",,,,,#sharing
"[ Há»i vá» thÆ° viá»‡n Python] MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n Æ°á»›c lÆ°á»£ng phÃ¢n bá»‘ cá»§a P(Y |X), vá»›i Y lÃ  multi dependent/correlated output, vÃ  X lÃ  multivariate continuous (not categorical) features. MÃ¬nh muá»‘n tÃ¬m thÆ° viá»‡n Python mÃ  implement Ä‘Æ°á»£c xÃ¡c suáº¥t theo kiá»ƒu :(1) approximate P(Y|X) ~ N(m, S), where off-diagonal entries are not zeros hoáº·c lÃ  cÃ³ thá»ƒ sample Ä‘Æ°á»£c Y~ P(Y|X).
ÄÃ¢y lÃ  bÃ i toÃ¡n Bayesan multi-dependent output regression. Tuy nhiÃªn máº¥y thÆ° viá»‡n nhÆ° Gaussian process á»Ÿ sklearn thÃ¬ hiá»‡n táº¡i implementation, treat cÃ¡c output independent vá»›i nha","[ Há»i vá» thÆ° viá»‡n Python] MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n Æ°á»›c lÆ°á»£ng phÃ¢n bá»‘ cá»§a P(Y |X), vá»›i Y lÃ  multi dependent/correlated output, vÃ  X lÃ  multivariate continuous (not categorical) features. MÃ¬nh muá»‘n tÃ¬m thÆ° viá»‡n Python mÃ  implement Ä‘Æ°á»£c xÃ¡c suáº¥t theo kiá»ƒu :(1) approximate P(Y|X) ~ N(m, S), where off-diagonal entries are not zeros hoáº·c lÃ  cÃ³ thá»ƒ sample Ä‘Æ°á»£c Y~ P(Y|X). ÄÃ¢y lÃ  bÃ i toÃ¡n Bayesan multi-dependent output regression. Tuy nhiÃªn máº¥y thÆ° viá»‡n nhÆ° Gaussian process á»Ÿ sklearn thÃ¬ hiá»‡n táº¡i implementation, treat cÃ¡c output independent vá»›i nha",,,,,"#Q&A, #math, #python"
"Hi everyone, I am trying to use some voice conversion model. Due to hardware limitation, each voice input file can only be as long as N seconds. I can still naively cut the input into various segments if there are enough silence segments. Howevers, some inputs have long stretches of non-silence segments. My idea is that I can split the input into overlapped segments, feed them into the model, then merge the outputs into one single outputs. So my question is how to properly do the merging. Not sure if it can be solved with audio englneering or signal processing or even deep learning.
Thank you very much. Have a great day.","Hi everyone, I am trying to use some voice conversion model. Due to hardware limitation, each voice input file can only be as long as N seconds. I can still naively cut the input into various segments if there are enough silence segments. Howevers, some inputs have long stretches of non-silence segments. My idea is that I can split the input into overlapped segments, feed them into the model, then merge the outputs into one single outputs. So my question is how to properly do the merging. Not sure if it can be solved with audio englneering or signal processing or even deep learning. Thank you very much. Have a great day.",,,,,bá»
"Hello má»i ngÆ°á»i!
MÃ¬nh cÃ³ bÃ i toÃ¡n build má»™t regression model Ä‘á»ƒ predict target variable cÃ³ distribution nhÆ° nÃ y. MÃ¬nh Ä‘Ã£ thá»­ nhÃ¬u cÃ¡ch, dÃ¹ng SOTA gradient boosted algorithm nhÆ° LGBM hay XGBoost mÃ  RMSE váº«n ráº¥t cao. Theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ Ä‘Ã¢y lÃ  Tweedie Distribution, ko biáº¿t cÃ³ cao nhÃ¢n nÃ o biáº¿t cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» nÃ y khÃ´ng áº¡?","Hello má»i ngÆ°á»i! MÃ¬nh cÃ³ bÃ i toÃ¡n build má»™t regression model Ä‘á»ƒ predict target variable cÃ³ distribution nhÆ° nÃ y. MÃ¬nh Ä‘Ã£ thá»­ nhÃ¬u cÃ¡ch, dÃ¹ng SOTA gradient boosted algorithm nhÆ° LGBM hay XGBoost mÃ  RMSE váº«n ráº¥t cao. Theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ Ä‘Ã¢y lÃ  Tweedie Distribution, ko biáº¿t cÃ³ cao nhÃ¢n nÃ o biáº¿t cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» nÃ y khÃ´ng áº¡?",,,,,"#Q&A, #machine_learning"
"VÃ¬ vá»¥ viá»‡c nÃ y liÃªn quan tá»›i ba thá»©: machine learning, Penn State University, vÃ  viá»‡c Ä‘áº¡o vÄƒn, tÃ´i tháº¥y cáº§n pháº£i lÃªn tiáº¿ng. Hy vá»ng chÆ°a cÃ³ báº¡n nÃ o trong group tá»«ng bá» ra sá»‘ tiá»n lá»›n Ä‘á»ƒ theo há»c táº¡i Ä‘Ã¢y:

https://forum.machinelearningcoban.com/t/mot-vai-nghi-van-ve-vien-ung-dung-toan-hoc-big-data-data-analytics-data-mining/5420","VÃ¬ vá»¥ viá»‡c nÃ y liÃªn quan tá»›i ba thá»©: machine learning, Penn State University, vÃ  viá»‡c Ä‘áº¡o vÄƒn, tÃ´i tháº¥y cáº§n pháº£i lÃªn tiáº¿ng. Hy vá»ng chÆ°a cÃ³ báº¡n nÃ o trong group tá»«ng bá» ra sá»‘ tiá»n lá»›n Ä‘á»ƒ theo há»c táº¡i Ä‘Ã¢y: https://forum.machinelearningcoban.com/t/mot-vai-nghi-van-ve-vien-ung-dung-toan-hoc-big-data-data-analytics-data-mining/5420",,,,,"#sharing, #machine_learning"
"#PyTorch Multi-GPUs training trong PyTorch
ChÃ o má»i ngÆ°á»i. Xin phÃ©p há»i cÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m vá» training model báº±ng PyTorch trÃªn nhiá»u GPUs. Hiá»‡n táº¡i em Ä‘ang gáº·p váº¥n Ä‘á» khi cháº¡y code trÃªn 1 GPU thÃ¬ ko sáº£y ra váº¥n Ä‘á» gÃ¬, nhÆ°ng khi Ä‘áº©y lÃªn nhiá»u GPUs thÃ¬ bá»‹ lá»—i khi thá»±c hiá»‡n backward cho loss. Em xin mÃ´ táº£ code á»Ÿ vÃ­ dá»¥ Ä‘Æ¡n giáº£n nhÆ° áº£nh bÃªn dÆ°á»›i Ä‘Ã¢y.
Váº¥n Ä‘á» nÃ y em cÃ³ tÃ¬m kiáº¿m thÃ¬ biáº¿t ráº±ng cho training trÃªn nhiá»u GPUs thÃ¬ tÆ°Æ¡ng Ä‘Æ°Æ¡ng cÃ³ chá»«ng áº¥y outputs Ä‘Æ°á»£c tráº£ vá» cÃ¹ng lÃºc. Do váº­y viá»‡c backprop thÃ´ng qua `loss.backward()` sáº½ sáº£y ra lá»—i, do `loss` lÃºc nÃ y lÃ  1 Tensor nhiá»u chiá»u (PyTorch chá»‰ cho phÃ©p backward vá»›i scalar). Má»™t cÃ¡ch kháº¯c phá»¥c em tÃ¬m Ä‘Æ°á»£c lÃ  sá»­ dá»¥ng `loss.sum().backward()` hoáº·c `loss.mean().backward()`.
CÃ¢u há»i em Ä‘áº·t ra lÃ  viá»‡c láº¥y `sum` hoáº·c láº¥y `mean` cá»§a cÃ¡c losses trÃªn sau Ä‘Ã³ backward thÃ¬ cÃ³ thay Ä‘á»•i báº£n cháº¥t hoáº·c káº¿t quáº£ cá»§a quÃ¡ trÃ¬nh backpropagation hay khÃ´ng ? NgoÃ i ra cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘Æ¡n giáº£n hÆ¡n Ä‘á»ƒ khÃ´ng pháº£i dÃ¹ng sum hoáº·c mean cá»§a loss trÆ°á»›c khi backward hay khÃ´ng ? Em xin cáº£m Æ¡n má»i ngÆ°á»i.","Multi-GPUs training trong PyTorch ChÃ o má»i ngÆ°á»i. Xin phÃ©p há»i cÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m vá» training model báº±ng PyTorch trÃªn nhiá»u GPUs. Hiá»‡n táº¡i em Ä‘ang gáº·p váº¥n Ä‘á» khi cháº¡y code trÃªn 1 GPU thÃ¬ ko sáº£y ra váº¥n Ä‘á» gÃ¬, nhÆ°ng khi Ä‘áº©y lÃªn nhiá»u GPUs thÃ¬ bá»‹ lá»—i khi thá»±c hiá»‡n backward cho loss. Em xin mÃ´ táº£ code á»Ÿ vÃ­ dá»¥ Ä‘Æ¡n giáº£n nhÆ° áº£nh bÃªn dÆ°á»›i Ä‘Ã¢y. Váº¥n Ä‘á» nÃ y em cÃ³ tÃ¬m kiáº¿m thÃ¬ biáº¿t ráº±ng cho training trÃªn nhiá»u GPUs thÃ¬ tÆ°Æ¡ng Ä‘Æ°Æ¡ng cÃ³ chá»«ng áº¥y outputs Ä‘Æ°á»£c tráº£ vá» cÃ¹ng lÃºc. Do váº­y viá»‡c backprop thÃ´ng qua `loss.backward()` sáº½ sáº£y ra lá»—i, do `loss` lÃºc nÃ y lÃ  1 Tensor nhiá»u chiá»u (PyTorch chá»‰ cho phÃ©p backward vá»›i scalar). Má»™t cÃ¡ch kháº¯c phá»¥c em tÃ¬m Ä‘Æ°á»£c lÃ  sá»­ dá»¥ng `loss.sum().backward()` hoáº·c `loss.mean().backward()`. CÃ¢u há»i em Ä‘áº·t ra lÃ  viá»‡c láº¥y `sum` hoáº·c láº¥y `mean` cá»§a cÃ¡c losses trÃªn sau Ä‘Ã³ backward thÃ¬ cÃ³ thay Ä‘á»•i báº£n cháº¥t hoáº·c káº¿t quáº£ cá»§a quÃ¡ trÃ¬nh backpropagation hay khÃ´ng ? NgoÃ i ra cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘Æ¡n giáº£n hÆ¡n Ä‘á»ƒ khÃ´ng pháº£i dÃ¹ng sum hoáº·c mean cá»§a loss trÆ°á»›c khi backward hay khÃ´ng ? Em xin cáº£m Æ¡n má»i ngÆ°á»i.",#PyTorch,,,,"#Q&A, #python"
5 CÃ”NG NGHá»† Má»šI TRONG DATA ENGINEERING.,5 CÃ”NG NGHá»† Má»šI TRONG DATA ENGINEERING.,,,,,#sharing
"ChÃ o m.n vÃ  a Tiep VuHuu, e Ä‘ang cÃ³ bÃ i toÃ¡n nhÆ° tháº¿ nÃ y nhá» m.n giÃºp Ä‘á»¡:
Export ra file bÃ¡o cÃ¡o dá»±a trÃªn cÃ¢u thoáº¡i trÃªn zalo
VÃ­ dá»¥ cÃ¢u nÃ y: ""Em lÃ  VÄƒn Thanh, hÃ´m nay 01/01/2023 em Ä‘Ã£ lÃ m xong task a, b ,c""
Expect: NgÃ y 01/01/2023, VÄƒn Thanh, task a, b, c: Ä‘Ã£ xong
Hoáº·c: ""ChÃ o anh Tuáº¥n, em lÃ  Thanh, hÃ´m nay 31/01/2023 e vÃ´ trá»… nÃªn lÃ m chÆ°a ká»‹p task a, má»›i xong b, c thÃ´i. NgoÃ i ra task d e cÅ©ng chÆ°a lÃ m""
Expect: NgÃ y 31/01/2023, Thanh, task b, c: Ä‘Ã£ xong; task a, d chÆ°a xong
Em bá» ML 6 nÄƒm r nÃªn giá» quÃªn háº¿t, m.n cho e há»i Ä‘Ã¢y lÃ  dáº¡ng bÃ i toÃ¡n gÃ¬ (e nghÄ© lÃ  speech to text vÃ  data mining, ko biáº¿t Ä‘Ãºng ko); vÃ  cÃ³ thÆ° viá»‡n nÃ o mÃ¬ Äƒn liá»n ko áº¡ (e prefer Java vÃ¬ cÃ¡c dá»± Ã¡n hiá»‡n táº¡i Ä‘á»u viáº¿t báº±ng Java)
Thank m.n","ChÃ o m.n vÃ  a Tiep VuHuu, e Ä‘ang cÃ³ bÃ i toÃ¡n nhÆ° tháº¿ nÃ y nhá» m.n giÃºp Ä‘á»¡: Export ra file bÃ¡o cÃ¡o dá»±a trÃªn cÃ¢u thoáº¡i trÃªn zalo VÃ­ dá»¥ cÃ¢u nÃ y: ""Em lÃ  VÄƒn Thanh, hÃ´m nay 01/01/2023 em Ä‘Ã£ lÃ m xong task a, b ,c"" Expect: NgÃ y 01/01/2023, VÄƒn Thanh, task a, b, c: Ä‘Ã£ xong Hoáº·c: ""ChÃ o anh Tuáº¥n, em lÃ  Thanh, hÃ´m nay 31/01/2023 e vÃ´ trá»… nÃªn lÃ m chÆ°a ká»‹p task a, má»›i xong b, c thÃ´i. NgoÃ i ra task d e cÅ©ng chÆ°a lÃ m"" Expect: NgÃ y 31/01/2023, Thanh, task b, c: Ä‘Ã£ xong; task a, d chÆ°a xong Em bá» ML 6 nÄƒm r nÃªn giá» quÃªn háº¿t, m.n cho e há»i Ä‘Ã¢y lÃ  dáº¡ng bÃ i toÃ¡n gÃ¬ (e nghÄ© lÃ  speech to text vÃ  data mining, ko biáº¿t Ä‘Ãºng ko); vÃ  cÃ³ thÆ° viá»‡n nÃ o mÃ¬ Äƒn liá»n ko áº¡ (e prefer Java vÃ¬ cÃ¡c dá»± Ã¡n hiá»‡n táº¡i Ä‘á»u viáº¿t báº±ng Java) Thank m.n",,,,,"#Q&A, #python, #nlp"
"ChÃ o mn áº¡, theo káº¿t quáº£ cá»§a giáº£i tÃ­ch 2 thÃ¬ náº¿u tá»“n táº¡i Ä‘áº¡o hÃ m cÃ³ hÆ°á»›ng táº¡i Ä‘iá»ƒm theta vÃ  vector gradient táº¡i theta khÃ¡c 0 thÃ¬ ká»ƒ tá»« Ä‘iá»ƒm theta hÃ m y sáº½ giáº£m nhiá»u nháº¥t theo hÆ°á»›ng cá»§a vector gradient. Váº­y thÆ°á»ng hÃ m lá»—i trong há»c sÃ¢u cÃ³ thoáº£ mÃ£n Ä‘iá»u kiá»‡n tá»“n táº¡i Ä‘áº¡o hÃ m cÃ³ hÆ°á»›ng táº¡i má»i Ä‘iá»ƒm khÃ´ng áº¡? Náº¿u khÃ´ng thÃ¬ vá»›i nhá»¯ng tÃ­nh cháº¥t nÃ o cá»§a mÃ´ hÃ¬nh vÃ  hÃ m lá»—i thÃ¬ hÃ m lá»—i sáº½ cÃ³ Ä‘áº¡o hÃ m cÃ³ hÆ°á»›ng táº¡i má»i Ä‘iá»ƒm áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o mn áº¡, theo káº¿t quáº£ cá»§a giáº£i tÃ­ch 2 thÃ¬ náº¿u tá»“n táº¡i Ä‘áº¡o hÃ m cÃ³ hÆ°á»›ng táº¡i Ä‘iá»ƒm theta vÃ  vector gradient táº¡i theta khÃ¡c 0 thÃ¬ ká»ƒ tá»« Ä‘iá»ƒm theta hÃ m y sáº½ giáº£m nhiá»u nháº¥t theo hÆ°á»›ng cá»§a vector gradient. Váº­y thÆ°á»ng hÃ m lá»—i trong há»c sÃ¢u cÃ³ thoáº£ mÃ£n Ä‘iá»u kiá»‡n tá»“n táº¡i Ä‘áº¡o hÃ m cÃ³ hÆ°á»›ng táº¡i má»i Ä‘iá»ƒm khÃ´ng áº¡? Náº¿u khÃ´ng thÃ¬ vá»›i nhá»¯ng tÃ­nh cháº¥t nÃ o cá»§a mÃ´ hÃ¬nh vÃ  hÃ m lá»—i thÃ¬ hÃ m lá»—i sáº½ cÃ³ Ä‘áº¡o hÃ m cÃ³ hÆ°á»›ng táº¡i má»i Ä‘iá»ƒm áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,"#Q&A, #math, #machine_learning"
#AR vÃ  #AI Ä‘ang thay Ä‘á»•i cuá»™c chÆ¡i!,vÃ  Ä‘ang thay Ä‘á»•i cuá»™c chÆ¡i!,#AR	#AI,,,,#sharing
"MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Máº¡ng MLP vÃ  lan truyá»n ngÆ°á»£c
mn cho em há»i vá» cÃ¡c biáº¿n dáº¡ng cá»§a lan truyá»n ngÆ°á»£c Ä‘Æ°á»£c khÃ´ng áº¡! em tÃ¬m trÃªn máº¡ng thÃ¬ tháº¥y Ã­t tÃ i liá»‡u vá» nÃ³ vÃ  há»i chatgpt thÃ¬ cÃ¢u tráº£ lá»i má»—i lÃºc má»—i khÃ¡c áº¡! em cáº£m Æ¡n",MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Máº¡ng MLP vÃ  lan truyá»n ngÆ°á»£c mn cho em há»i vá» cÃ¡c biáº¿n dáº¡ng cá»§a lan truyá»n ngÆ°á»£c Ä‘Æ°á»£c khÃ´ng áº¡! em tÃ¬m trÃªn máº¡ng thÃ¬ tháº¥y Ã­t tÃ i liá»‡u vá» nÃ³ vÃ  há»i chatgpt thÃ¬ cÃ¢u tráº£ lá»i má»—i lÃºc má»—i khÃ¡c áº¡! em cáº£m Æ¡n,,,,,"#Q&A, #machine_learning"
"hello all, cho mÃ¬nh há»i
ngoÃ i Elastic cÃ³ engine nÃ o support Search sá»­ dá»¥ng ML Ä‘á»ƒ cÃ¡ nhÃ¢n hÃ³a káº¿t quáº£ k mn?
mÃ¬nh muá»‘n lÃ m chá»©c nÄƒng search cho trang tÃ¬m kiáº¿m Job sá»­ dá»¥ng ML, giáº£ sá»­ user tÃ¬m kiáº¿m job PHP á»Ÿ hÃ  ná»™i, hoáº·c user click xem cÃ¡c job á»Ÿ hÃ  ná»™i (khÃ´ng thá»±c hiá»‡n search) , thÃ¬ nÃ³ sáº½ suggest vÃ  Ä‘Æ°a cÃ¡c job á»Ÿ hÃ  ná»™i lÃªn hÃ ng Ä‘áº§u
vÃ¬ project cá»§a mÃ¬nh nhá» ( search khoáº£ng 1k item thÃ´i ) nÃªn dÃ¹ng Elastic lÃ  hÆ¡i thá»«a, vá»›i láº¡i nÃ³ ngá»‘n Ram quÃ¡, mÃ¬nh chá»‰ Ä‘á»‹nh cháº¡y trÃªn con Vps 1gb RAM thÃ´i","hello all, cho mÃ¬nh há»i ngoÃ i Elastic cÃ³ engine nÃ o support Search sá»­ dá»¥ng ML Ä‘á»ƒ cÃ¡ nhÃ¢n hÃ³a káº¿t quáº£ k mn? mÃ¬nh muá»‘n lÃ m chá»©c nÄƒng search cho trang tÃ¬m kiáº¿m Job sá»­ dá»¥ng ML, giáº£ sá»­ user tÃ¬m kiáº¿m job PHP á»Ÿ hÃ  ná»™i, hoáº·c user click xem cÃ¡c job á»Ÿ hÃ  ná»™i (khÃ´ng thá»±c hiá»‡n search) , thÃ¬ nÃ³ sáº½ suggest vÃ  Ä‘Æ°a cÃ¡c job á»Ÿ hÃ  ná»™i lÃªn hÃ ng Ä‘áº§u vÃ¬ project cá»§a mÃ¬nh nhá» ( search khoáº£ng 1k item thÃ´i ) nÃªn dÃ¹ng Elastic lÃ  hÆ¡i thá»«a, vá»›i láº¡i nÃ³ ngá»‘n Ram quÃ¡, mÃ¬nh chá»‰ Ä‘á»‹nh cháº¡y trÃªn con Vps 1gb RAM thÃ´i",,,,,#Q&A
AI má»›i tá»± phÃ¡t triá»ƒn dá»±a trÃªn Thuyáº¿t tiáº¿n hÃ³a Darwin.,AI má»›i tá»± phÃ¡t triá»ƒn dá»±a trÃªn Thuyáº¿t tiáº¿n hÃ³a Darwin.,,,,,#sharing
"Xin há»i cÃ³ anh/chá»‹/em/báº¡n nÃ o Ä‘ang táº­p trung há»c cuá»‘n ""Dive into Deep Learning"" ko áº¡? MÃ¬nh muá»‘n tÃ¬m kiáº¿m má»™t nhÃ³m báº¡n cÃ¹ng há»c Ä‘á»ƒ tiá»‡n trao Ä‘á»•i vÃ  há»c há»i. MXNet tháº¥y hÆ¡i khÃ³ nháº±n. Hi","Xin há»i cÃ³ anh/chá»‹/em/báº¡n nÃ o Ä‘ang táº­p trung há»c cuá»‘n ""Dive into Deep Learning"" ko áº¡? MÃ¬nh muá»‘n tÃ¬m kiáº¿m má»™t nhÃ³m báº¡n cÃ¹ng há»c Ä‘á»ƒ tiá»‡n trao Ä‘á»•i vÃ  há»c há»i. MXNet tháº¥y hÆ¡i khÃ³ nháº±n. Hi",,,,,#Q&A
"Cáº§n giÃºp Ä‘á»¡ vá» cÃ¡ch sá»­ dá»¥ng pretrained model.
Em lÃ  software engineer Ä‘ang lÃ m project trong Ä‘Ã³ cÃ³ chá»©c nÄƒng vá» similarity search. VÃ¬ khÃ´ng pháº£i dÃ¢n chuyÃªn AI nÃªn em chá»‰ há»c cÃ¡ch dÃ¹ng pretrained model. Process cá»§a em nhÆ° sau:
1. DÃ¹ng pyvi.ViTokenizer Ä‘á»ƒ tokenize input
2. DÃ¹ng model vinai/phobert-large Ä‘á»ƒ encode thÃ nh vector:
3. LÆ°u vector nÃ y vÃ o Postgres vá»›i extension ankane/pgvector
4. Search vector báº±ng cosine_distance, provided by pgvector
Má»i thá»© khÃ¡ á»•n khi em lÃ m POC, em search báº±ng nhá»¯ng cÃ¢u hoÃ n chá»‰nh nhÆ°: ""nhÃ  cung cáº¥p mainboard H110i táº¡i HCM"". NhÆ°ng Ä‘Æ°a vÃ o sá»­ dá»¥ng thÃ¬ khÃ¡ch hÃ ng query ráº¥t váº¯n táº¯t kiá»ƒu: ""H110i"" vÃ  káº¿t quáº£ tráº£ vá» cÃ²n thua cáº£ full text search, tháº­m chÃ­ khÃ´ng match Ä‘Æ°á»£c cÃ¢u nÃ o cÃ³ chá»¯ ""H110i"", trong khi search nguyÃªn cÃ¢u thÃ¬ láº¡i cÃ³.
Expect cá»§a em lÃ  ká»ƒ cáº£ khi khÃ¡ch hÃ ng chá»‰ nháº­p tÃªn mÃ£ sáº£n pháº©m thÃ¬ Ã­t nháº¥t cÅ©ng tráº£ vá» nhá»¯ng cÃ¢u cÃ³ chá»©a mÃ£ sáº£n pháº©m Ä‘Ã³.
Em khÃ¡ báº¿ táº¯c á»Ÿ chá»— nÃ y, mong Ä‘Æ°á»£c má»i ngÆ°á»i tÆ° váº¥n.","Cáº§n giÃºp Ä‘á»¡ vá» cÃ¡ch sá»­ dá»¥ng pretrained model. Em lÃ  software engineer Ä‘ang lÃ m project trong Ä‘Ã³ cÃ³ chá»©c nÄƒng vá» similarity search. VÃ¬ khÃ´ng pháº£i dÃ¢n chuyÃªn AI nÃªn em chá»‰ há»c cÃ¡ch dÃ¹ng pretrained model. Process cá»§a em nhÆ° sau: 1. DÃ¹ng pyvi.ViTokenizer Ä‘á»ƒ tokenize input 2. DÃ¹ng model vinai/phobert-large Ä‘á»ƒ encode thÃ nh vector: 3. LÆ°u vector nÃ y vÃ o Postgres vá»›i extension ankane/pgvector 4. Search vector báº±ng cosine_distance, provided by pgvector Má»i thá»© khÃ¡ á»•n khi em lÃ m POC, em search báº±ng nhá»¯ng cÃ¢u hoÃ n chá»‰nh nhÆ°: ""nhÃ  cung cáº¥p mainboard H110i táº¡i HCM"". NhÆ°ng Ä‘Æ°a vÃ o sá»­ dá»¥ng thÃ¬ khÃ¡ch hÃ ng query ráº¥t váº¯n táº¯t kiá»ƒu: ""H110i"" vÃ  káº¿t quáº£ tráº£ vá» cÃ²n thua cáº£ full text search, tháº­m chÃ­ khÃ´ng match Ä‘Æ°á»£c cÃ¢u nÃ o cÃ³ chá»¯ ""H110i"", trong khi search nguyÃªn cÃ¢u thÃ¬ láº¡i cÃ³. Expect cá»§a em lÃ  ká»ƒ cáº£ khi khÃ¡ch hÃ ng chá»‰ nháº­p tÃªn mÃ£ sáº£n pháº©m thÃ¬ Ã­t nháº¥t cÅ©ng tráº£ vá» nhá»¯ng cÃ¢u cÃ³ chá»©a mÃ£ sáº£n pháº©m Ä‘Ã³. Em khÃ¡ báº¿ táº¯c á»Ÿ chá»— nÃ y, mong Ä‘Æ°á»£c má»i ngÆ°á»i tÆ° váº¥n.",,,,,"#Q&A, #nlp, #deep_learning"
"Xin chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m bÃ i vá» object detection vÃ  Ä‘ang dÃ¹ng yolo v8. Má»i ngÆ°á»i cho em há»i á»Ÿ trong pháº§n gáº¯n nhÃ£n thÃ¬ gáº¯n nhÃ£n kiá»ƒu rectangle hay polygon cÃ³ hiá»‡u quáº£ hÆ¡n áº¡, vÃ  yolo cÃ³ há»— trá»£ detect bounding box dáº¡ng polygon khÃ´ng áº¡, em xin cáº£m Æ¡n","Xin chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m bÃ i vá» object detection vÃ  Ä‘ang dÃ¹ng yolo v8. Má»i ngÆ°á»i cho em há»i á»Ÿ trong pháº§n gáº¯n nhÃ£n thÃ¬ gáº¯n nhÃ£n kiá»ƒu rectangle hay polygon cÃ³ hiá»‡u quáº£ hÆ¡n áº¡, vÃ  yolo cÃ³ há»— trá»£ detect bounding box dáº¡ng polygon khÃ´ng áº¡, em xin cáº£m Æ¡n",,,,,"#Q&A, #cv, #deep_learning"
"ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang Ä‘á»c bÃ i viáº¿t vá» PCA cá»§a tháº§y Tiá»‡p. Em cÃ³ má»™t chá»— tháº¯c máº¯c lÃ  : trong bÃ i viáº¿t cÃ³ má»™t cÃ¢u tháº¿ nÃ y ""PCA cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  phÆ°Æ¡ng phÃ¡p Ä‘i tÃ¬m má»™t há»‡ cÆ¡ sá»Ÿ trá»±c chuáº©n Ä‘Ã³ng vai trÃ² má»™t phÃ©p xoay, sao cho trong há»‡ cÆ¡ sá»Ÿ má»›i nÃ y, phÆ°Æ¡ng sai theo má»™t sá»‘ chiá»u nÃ o Ä‘Ã³ lÃ  ráº¥t nhá», vÃ  ta cÃ³ thá»ƒ bá» qua"". Tuy nhiÃªn giáº£ sá»­ em cÃ³ má»™t ma tráº­n dá»¯ liá»‡u X vÃ  má»™t phÃ©p xoay á»©ng vá»›i ma tráº­n trá»±c giao U, tá»©c lÃ  X = UY. RÃµ rÃ ng ma tráº­n hiá»‡p phÆ°Æ¡ng sai cá»§a X vÃ  Y lÃ  nhÆ° nhau, tuy em láº¡i tháº¥y Ä‘iá»u nÃ y ráº¥t pháº£n trá»±c giÃ¡c. VÃ­ dá»¥ cá»¥ thá»ƒ nhÆ° hÃ¬nh bÃªn dÆ°á»›i, rÃµ rÃ ng khi Ã¡p dá»¥ng má»™t phÃ©p xoay thÃ¬ phÆ°Æ¡ng sai Ä‘Ã£ bá»‹ thay Ä‘á»•i, tuy nhiÃªn trong cÃ´ng thá»©c trÃªn thÃ¬ ma tráº­n hiá»‡p phÆ°Æ¡ng sai lÃ  nhÆ° nhau. Em Ä‘Ã£ hiá»ƒu sai á»Ÿ Ä‘Ã¢u váº­y áº¡.","ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang Ä‘á»c bÃ i viáº¿t vá» PCA cá»§a tháº§y Tiá»‡p. Em cÃ³ má»™t chá»— tháº¯c máº¯c lÃ  : trong bÃ i viáº¿t cÃ³ má»™t cÃ¢u tháº¿ nÃ y ""PCA cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  phÆ°Æ¡ng phÃ¡p Ä‘i tÃ¬m má»™t há»‡ cÆ¡ sá»Ÿ trá»±c chuáº©n Ä‘Ã³ng vai trÃ² má»™t phÃ©p xoay, sao cho trong há»‡ cÆ¡ sá»Ÿ má»›i nÃ y, phÆ°Æ¡ng sai theo má»™t sá»‘ chiá»u nÃ o Ä‘Ã³ lÃ  ráº¥t nhá», vÃ  ta cÃ³ thá»ƒ bá» qua"". Tuy nhiÃªn giáº£ sá»­ em cÃ³ má»™t ma tráº­n dá»¯ liá»‡u X vÃ  má»™t phÃ©p xoay á»©ng vá»›i ma tráº­n trá»±c giao U, tá»©c lÃ  X = UY. RÃµ rÃ ng ma tráº­n hiá»‡p phÆ°Æ¡ng sai cá»§a X vÃ  Y lÃ  nhÆ° nhau, tuy em láº¡i tháº¥y Ä‘iá»u nÃ y ráº¥t pháº£n trá»±c giÃ¡c. VÃ­ dá»¥ cá»¥ thá»ƒ nhÆ° hÃ¬nh bÃªn dÆ°á»›i, rÃµ rÃ ng khi Ã¡p dá»¥ng má»™t phÃ©p xoay thÃ¬ phÆ°Æ¡ng sai Ä‘Ã£ bá»‹ thay Ä‘á»•i, tuy nhiÃªn trong cÃ´ng thá»©c trÃªn thÃ¬ ma tráº­n hiá»‡p phÆ°Æ¡ng sai lÃ  nhÆ° nhau. Em Ä‘Ã£ hiá»ƒu sai á»Ÿ Ä‘Ã¢u váº­y áº¡.",,,,,"#Q&A, #math, #machine_learning"
"TÆ¯Æ NG LAI Cá»¦A TRÃ TUá»† NHÃ‚N Táº O Táº O SINH 2023 - NIC
ThÃ¢n má»i a Tiá»‡p cÃ¹ng cÃ¡c báº¡n bÃªn Forum machine learning cÆ¡ báº£n tá»›i tham gia sá»± kiá»‡n: "" The future of Generative AI 2023"" do bÃªn NIC tá»• chá»©c.
Trung tÃ¢m Äá»•i má»›i sÃ¡ng táº¡o Quá»‘c gia (NIC), Bá»™ Káº¿ hoáº¡ch vÃ  Äáº§u tÆ° phá»‘i há»£p vá»›i Máº¡ng lÆ°á»›i Äá»•i má»›i sÃ¡ng táº¡o Viá»‡t Nam táº¡i Thung lÅ©ng Silicon tá»• chá»©c há»™i tháº£o â€œTÆ°Æ¡ng lai cá»§a sá»± sÃ¡ng táº¡o tá»« cÃ´ng nghá»‡ AI 2023â€.
Há»™i tháº£o cÃ³ sá»± gÃ³p máº·t cá»§a cÃ¡c chuyÃªn gia AI hÃ ng Ä‘áº§u tá»« Thung lÅ©ng Silicon vÃ  Viá»‡t Nam, dá»± kiáº¿n thu hÃºt Ä‘Æ°á»£c sá»± quan tÃ¢m Ä‘Ã¡ng ká»ƒ tá»« cÃ¡c nhÃ  lÃ£nh Ä‘áº¡o, nhÃ  nghiÃªn cá»©u vÃ  nhá»¯ng ngÆ°á»i Ä‘am mÃª ngÃ nh AI trÃªn toÃ n tháº¿ giá»›i, mang Ä‘áº¿n cÆ¡ há»™i duy nháº¥t Ä‘á»ƒ káº¿t ná»‘i vá»›i cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ vÃ  tÃ i nÄƒng hÃ ng Ä‘áº§u cá»§a Viá»‡t Nam vÃ  Hoa Ká»³.
Anh Kim Pham - Cohost AI
Anh Hung Tran - GotIt AI
Chá»‹ TÃ¢m LÃª - Turing
Anh Phong Nguyen FPT AI
Anh VÃµ Minh Tuá»‡ - Ká»¹ sÆ° AI
Chá»‹ Lan Shuezhao - BasisSet
NgoÃ i ra, vá»›i má»¥c Ä‘Ã­ch mang Ä‘áº¿n cho ngÆ°á»i tham dá»± cÆ¡ há»™i trao Ä‘á»•i trá»±c tiáº¿p vá»›i Ä‘áº¡i diá»‡n cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ tá»« Silicon Valley, cÃ¡c xu hÆ°á»›ng má»›i nháº¥t vÃ  cÃ¡ch Ã¡p dá»¥ng AI Ä‘á»ƒ cáº£i thiá»‡n hoáº¡t Ä‘á»™ng kinh doanh, phÃ¡t triá»ƒn thá»‹ trÆ°á»ng.
Thá»i gian: 8:30 - 12:00 ngÃ y 20/04/2023
Link Ä‘Äƒng kÃ½: bit.ly/cohost-nic
Sá»± kiá»‡n Online qua Zoom vÃ  Offline táº¡i VP NIC sá»‘ 7 TÃ´n Tháº¥t Thuyáº¿t, Cáº§u Giáº¥y, HÃ  Ná»™i.
 â€” vá»›i Hung Tran vÃ  4 ngÆ°á»i khÃ¡c.","TÆ¯Æ NG LAI Cá»¦A TRÃ TUá»† NHÃ‚N Táº O Táº O SINH 2023 - NIC ThÃ¢n má»i a Tiá»‡p cÃ¹ng cÃ¡c báº¡n bÃªn Forum machine learning cÆ¡ báº£n tá»›i tham gia sá»± kiá»‡n: "" The future of Generative AI 2023"" do bÃªn NIC tá»• chá»©c. Trung tÃ¢m Äá»•i má»›i sÃ¡ng táº¡o Quá»‘c gia (NIC), Bá»™ Káº¿ hoáº¡ch vÃ  Äáº§u tÆ° phá»‘i há»£p vá»›i Máº¡ng lÆ°á»›i Äá»•i má»›i sÃ¡ng táº¡o Viá»‡t Nam táº¡i Thung lÅ©ng Silicon tá»• chá»©c há»™i tháº£o â€œTÆ°Æ¡ng lai cá»§a sá»± sÃ¡ng táº¡o tá»« cÃ´ng nghá»‡ AI 2023â€. Há»™i tháº£o cÃ³ sá»± gÃ³p máº·t cá»§a cÃ¡c chuyÃªn gia AI hÃ ng Ä‘áº§u tá»« Thung lÅ©ng Silicon vÃ  Viá»‡t Nam, dá»± kiáº¿n thu hÃºt Ä‘Æ°á»£c sá»± quan tÃ¢m Ä‘Ã¡ng ká»ƒ tá»« cÃ¡c nhÃ  lÃ£nh Ä‘áº¡o, nhÃ  nghiÃªn cá»©u vÃ  nhá»¯ng ngÆ°á»i Ä‘am mÃª ngÃ nh AI trÃªn toÃ n tháº¿ giá»›i, mang Ä‘áº¿n cÆ¡ há»™i duy nháº¥t Ä‘á»ƒ káº¿t ná»‘i vá»›i cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ vÃ  tÃ i nÄƒng hÃ ng Ä‘áº§u cá»§a Viá»‡t Nam vÃ  Hoa Ká»³. Anh Kim Pham - Cohost AI Anh Hung Tran - GotIt AI Chá»‹ TÃ¢m LÃª - Turing Anh Phong Nguyen FPT AI Anh VÃµ Minh Tuá»‡ - Ká»¹ sÆ° AI Chá»‹ Lan Shuezhao - BasisSet NgoÃ i ra, vá»›i má»¥c Ä‘Ã­ch mang Ä‘áº¿n cho ngÆ°á»i tham dá»± cÆ¡ há»™i trao Ä‘á»•i trá»±c tiáº¿p vá»›i Ä‘áº¡i diá»‡n cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ tá»« Silicon Valley, cÃ¡c xu hÆ°á»›ng má»›i nháº¥t vÃ  cÃ¡ch Ã¡p dá»¥ng AI Ä‘á»ƒ cáº£i thiá»‡n hoáº¡t Ä‘á»™ng kinh doanh, phÃ¡t triá»ƒn thá»‹ trÆ°á»ng. Thá»i gian: 8:30 - 12:00 ngÃ y 20/04/2023 Link Ä‘Äƒng kÃ½: bit.ly/cohost-nic Sá»± kiá»‡n Online qua Zoom vÃ  Offline táº¡i VP NIC sá»‘ 7 TÃ´n Tháº¥t Thuyáº¿t, Cáº§u Giáº¥y, HÃ  Ná»™i. â€” vá»›i Hung Tran vÃ  4 ngÆ°á»i khÃ¡c.",,,,,"#sharing, #webinar"
"Seminar tiáº¿p theo tá»• chá»©c bá»Ÿi MLOpsVN vá»›i chá»§ Ä‘á» Model Optimization sáº½ diá»…n ra online lÃºc 8h tá»‘i thá»© 5 tuáº§n nÃ y, má»i cáº£ nhÃ  Ä‘Äƒng kÃ½ tham gia náº¿u quan tÃ¢m áº¡ ğŸ˜","Seminar tiáº¿p theo tá»• chá»©c bá»Ÿi MLOpsVN vá»›i chá»§ Ä‘á» Model Optimization sáº½ diá»…n ra online lÃºc 8h tá»‘i thá»© 5 tuáº§n nÃ y, má»i cáº£ nhÃ  Ä‘Äƒng kÃ½ tham gia náº¿u quan tÃ¢m áº¡",,,,,"#sharing, #webinar"
"Má»i ngÆ°á»i cho em há»i táº¡i sao accuracy_score cá»§a decision tree láº¡i cao hÆ¡n cáº£ Random Forest váº­y áº¡?
code: https://github.com/akirayorunoe/MLLearning/blob/main/SONAR%20Rock%20vs%20Mine%20Prediction/rock_vs_mine_score.py",Má»i ngÆ°á»i cho em há»i táº¡i sao accuracy_score cá»§a decision tree láº¡i cao hÆ¡n cáº£ Random Forest váº­y áº¡? code: https://github.com/akirayorunoe/MLLearning/blob/main/SONAR%20Rock%20vs%20Mine%20Prediction/rock_vs_mine_score.py,,,,,"#Q&A, #machine_learning"
"Hello all, mÃ¬nh Ä‘ang tÃ¬m thÃ´ng tin vá» ranh giá»›i lat/long chi tiáº¿t cá»§a tá»«ng tá»‰nh/huyá»‡n/xÃ£ á»Ÿ VN cáº­p nháº­t má»›i nháº¥t. Check trang https://gadm.org/download_country.html rá»“i chá»n VN thÃ¬ cÃ³ Ä‘Ã¢y Ä‘á»§ thÃ´ng tin, nhÆ°ng thÃ´ng tin hÆ¡i cÅ©, 1 sá»‘ nÆ¡i á»Ÿ VN Ä‘Ã£ xÃ¡c nháº­p, Ä‘á»•i tÃªn nhÆ° ThÃ nh Phá»‘ Thá»§ Äá»©c thÃ¬ ko cÃ³. NÃªn lÃªn Ä‘Ã¢y nhá» má»i ngÆ°á»i, náº¿u ai cÃ³ data má»›i nháº¥t thÃ¬ share giÃºp mÃ¬nh vá»›i. Many thanks.","Hello all, mÃ¬nh Ä‘ang tÃ¬m thÃ´ng tin vá» ranh giá»›i lat/long chi tiáº¿t cá»§a tá»«ng tá»‰nh/huyá»‡n/xÃ£ á»Ÿ VN cáº­p nháº­t má»›i nháº¥t. Check trang https://gadm.org/download_country.html rá»“i chá»n VN thÃ¬ cÃ³ Ä‘Ã¢y Ä‘á»§ thÃ´ng tin, nhÆ°ng thÃ´ng tin hÆ¡i cÅ©, 1 sá»‘ nÆ¡i á»Ÿ VN Ä‘Ã£ xÃ¡c nháº­p, Ä‘á»•i tÃªn nhÆ° ThÃ nh Phá»‘ Thá»§ Äá»©c thÃ¬ ko cÃ³. NÃªn lÃªn Ä‘Ã¢y nhá» má»i ngÆ°á»i, náº¿u ai cÃ³ data má»›i nháº¥t thÃ¬ share giÃºp mÃ¬nh vá»›i. Many thanks.",,,,,"#Q&A, #data"
"Xin chÃ o má»i ngÆ°á»i!
MÃ¬nh Ä‘ang phÃ¡t triá»ƒn má»™t tool gÃ¡n nhÃ£n dá»¯ liá»‡u má»›i base trÃªn LabelMe vÃ  mÃ´ hÃ¬nh Segment Anything má»›i nháº¥t cá»§a Facebook.
Xin phÃ©p Ä‘Æ°á»£c chia sáº» Ä‘áº¿n toÃ n thá»ƒ nhÃ³m mÃ¬nh Ä‘á»ƒ xin gáº¡ch Ä‘Ã¡ vÃ  comment Ä‘á»ƒ tiáº¿p tá»¥c cáº£i tiáº¿n.
- Link: https://github.com/vietanhdev/anylabeling
- Demo: https://www.youtube.com/watch?v=5iQSGL7ebXE",Xin chÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang phÃ¡t triá»ƒn má»™t tool gÃ¡n nhÃ£n dá»¯ liá»‡u má»›i base trÃªn LabelMe vÃ  mÃ´ hÃ¬nh Segment Anything má»›i nháº¥t cá»§a Facebook. Xin phÃ©p Ä‘Æ°á»£c chia sáº» Ä‘áº¿n toÃ n thá»ƒ nhÃ³m mÃ¬nh Ä‘á»ƒ xin gáº¡ch Ä‘Ã¡ vÃ  comment Ä‘á»ƒ tiáº¿p tá»¥c cáº£i tiáº¿n. - Link: https://github.com/vietanhdev/anylabeling - Demo: https://www.youtube.com/watch?v=5iQSGL7ebXE,,,,,#sharing
"Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i, em vá»«a há»c xong 2 machine learning vÃ  deep learning specializations cá»§a tháº§y Andrew Ng. Má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ cho em má»™t sá»‘ project Ã¡p dá»¥ng kiáº¿n thá»©c Ä‘Ã£ há»c vÃ  há»c tiáº¿p nhá»¯ng kiáº¿n thá»©c gÃ¬ cho thá»‹ giÃ¡c mÃ¡y tÃ­nh Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i","Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i, em vá»«a há»c xong 2 machine learning vÃ  deep learning specializations cá»§a tháº§y Andrew Ng. Má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ cho em má»™t sá»‘ project Ã¡p dá»¥ng kiáº¿n thá»©c Ä‘Ã£ há»c vÃ  há»c tiáº¿p nhá»¯ng kiáº¿n thá»©c gÃ¬ cho thá»‹ giÃ¡c mÃ¡y tÃ­nh Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,#Q&A
"Má»™t thÃ´ng tin mÃ  mÃ¬nh cho lÃ  quan trá»ng náº¿u báº¡n nÃ o muá»‘n sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n lá»›n (LLM) vÃ o viá»‡c phÃ¡t triá»ƒn sáº£n pháº©m thÆ°Æ¡ng máº¡i.
TrÃ­ch nguá»“n:",Má»™t thÃ´ng tin mÃ  mÃ¬nh cho lÃ  quan trá»ng náº¿u báº¡n nÃ o muá»‘n sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n lá»›n (LLM) vÃ o viá»‡c phÃ¡t triá»ƒn sáº£n pháº©m thÆ°Æ¡ng máº¡i. TrÃ­ch nguá»“n:,,,,,"#sharing, #nlp"
,nan,,,,,bá»
"Náº¿u báº¡n há»i tÃ´i sau nhá»¯ng hÃ o quang ChatGPT, GPT-4 thÃ¬ tiáº¿p theo sáº½ lÃ  gÃ¬, tÃ´i sáº½ tráº£ lá»i lÃ  AutoGPT, vá»›i khoáº£ng 30.000 sao á»Ÿ repo trÃªn Github.
Vá»›i AutoGPT cÃ¡c prompt sáº½ Ä‘Æ°á»£c liÃªn káº¿t vá»›i nhau táº¡o ra má»™t agents, cÃ³ thá»ƒ lÃªn suy nghÄ©, lÃªn káº¿ hoáº¡ch, thá»±c hiá»‡n tá»«ng bÆ°á»›c má»™t vÃ  Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu. VÃ­ dá»¥, báº¡n há»i cÃ¡ch táº¡o má»™t startup vá»›i 100$ funding, thay vÃ¬ tráº£ lá»i trá»±c tiáº¿p, AutoGPT sáº½ lÃªn plan:
1. Research low-cost business models that require minimal funding.
2. Identify potential target markets and their needs.
3. Develop a lean MVP and test with target market to validate demand.
Sau Ä‘Ã³, vá»›i má»—i task mÃ´ hÃ¬nh GPT sáº½ sinh ra cÃ¡c cÃ¢u tráº£ lá»i dá»±a vÃ o thÃ´ng tin trÃªn internet, vÃ  cÃ³ thá»ƒ sáº½ cÃ³ cÃ¡c task nhá» Ä‘Æ°á»£c break down ra ná»¯a. Cuá»‘i cÃ¹ng nÃ³ sáº½ tá»•ng há»£p láº¡i vÃ  cho ra káº¿t quáº£ cuá»‘i cÃ¹ng. VÃ  táº¥t cáº£ Ä‘á»u tá»± Ä‘á»™ng ^^","Náº¿u báº¡n há»i tÃ´i sau nhá»¯ng hÃ o quang ChatGPT, GPT-4 thÃ¬ tiáº¿p theo sáº½ lÃ  gÃ¬, tÃ´i sáº½ tráº£ lá»i lÃ  AutoGPT, vá»›i khoáº£ng 30.000 sao á»Ÿ repo trÃªn Github. Vá»›i AutoGPT cÃ¡c prompt sáº½ Ä‘Æ°á»£c liÃªn káº¿t vá»›i nhau táº¡o ra má»™t agents, cÃ³ thá»ƒ lÃªn suy nghÄ©, lÃªn káº¿ hoáº¡ch, thá»±c hiá»‡n tá»«ng bÆ°á»›c má»™t vÃ  Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu. VÃ­ dá»¥, báº¡n há»i cÃ¡ch táº¡o má»™t startup vá»›i 100$ funding, thay vÃ¬ tráº£ lá»i trá»±c tiáº¿p, AutoGPT sáº½ lÃªn plan: 1. Research low-cost business models that require minimal funding. 2. Identify potential target markets and their needs. 3. Develop a lean MVP and test with target market to validate demand. Sau Ä‘Ã³, vá»›i má»—i task mÃ´ hÃ¬nh GPT sáº½ sinh ra cÃ¡c cÃ¢u tráº£ lá»i dá»±a vÃ o thÃ´ng tin trÃªn internet, vÃ  cÃ³ thá»ƒ sáº½ cÃ³ cÃ¡c task nhá» Ä‘Æ°á»£c break down ra ná»¯a. Cuá»‘i cÃ¹ng nÃ³ sáº½ tá»•ng há»£p láº¡i vÃ  cho ra káº¿t quáº£ cuá»‘i cÃ¹ng. VÃ  táº¥t cáº£ Ä‘á»u tá»± Ä‘á»™ng ^^",,,,,"#shairng, #deep_learning, #nlp"
"Hi má»i ngÆ°á»i, hÃ´m nay mÃ¬nh muá»‘n chia sáº» má»™t tool khÃ¡ hay á»©ng dá»¥ng cá»§a chatgpt/LLM Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi CNext, giÃºp há»— trá»£ ngÆ°á»i dÃ¹ng tráº£ lá»i cÃ¢u há»i, tÃ¬m insight tá»« dá»¯ liá»‡u báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn.
Theo mÃ¬nh tháº¥y CNext hoáº¡t Ä‘á»™ng khÃ¡ áº¥n tÆ°á»Ÿng, dÃ¹ báº¡n cÃ³ kiáº¿n thá»©c vá» láº­p trÃ¬nh hay khÃ´ng thÃ¬ má»™t sá»‘ task yÃªu cáº§u phá»©c táº¡p báº¡n chá»‰ cáº§n mÃ´ táº£ Ã½ tÆ°á»Ÿng cá»§a mÃ¬nh CNext cÃ³ thá»ƒ há»— trá»£ báº¡n triá»ƒn khai Ã½ tÆ°á»Ÿng Ä‘Ã³ trÃªn dá»¯ liá»‡u cá»§a báº¡n.
MÃ¬nh tháº¥y tool cÃ³ khÃ¡ nhiá»u api há»— trá»£:
Import data: Táº£i lÃªn má»™t file dÆ°á»›i Ä‘á»‹nh dáº¡ng .csv (Ä‘Ã¢y sáº½ lÃ  file báº¡n mong muá»‘n phÃ¢n tÃ­ch vÃ  tÃ¬m insight)
Table ops: Thao tÃ¡c xá»­ lÃ½ dá»¯ liá»‡u trÃªn cÃ¡c trÆ°á»ng dá»¯ liá»‡u
Google search: cho phÃ©p báº¡n search thÃ´ng tin trÃªn google vÃ  tráº£ vá» Ä‘á»‹nh dáº¡ng json dá»… dÃ ng Ä‘á»ƒ khai thÃ¡c dá»¯ liá»‡u
Twitter search hoáº·c Twitter Entities: Cho phÃ©p láº¥y thÃ´ng tin trÃªn twitter (ráº¥t phÃ¹ há»£p trong viá»‡c phÃ¢n tÃ­ch má»™t trend hoáº·c má»™t sáº£n pháº©m Ä‘Æ°á»£c giá»›i thiá»‡u trÃªn twitter, giÃºp ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ theo dÃµi má»©c Ä‘á»™ quan tÃ¢m hoáº·c thÃ¡i Ä‘á»™ cá»§a má»i ngÆ°á»i Ä‘á»‘i vá»›i tweet cá»§a mÃ¬nh
Plotting: Cho phÃ©p visualize dá»¯ liá»‡u, design biá»ƒu Ä‘á»“ thÃ´ng qua Ã½ tÆ°á»Ÿng ngÃ´n ngá»¯ tá»± nhiÃªn nháº¥t cÃ³ thá»ƒ
NgoÃ i ra cÃ²n má»™t sá»‘ api khÃ¡c giÃºp cho cÃ¡c báº¡n HR cÃ³ thá»ƒ tÃ¬m kiáº¿m á»©ng viÃªn trÃªn linkedin phÃ¹ há»£p vá»›i tiÃªu chÃ­ cá»§a má»i ngÆ°á»i Ä‘áº·t ra,...
Má»™t sá»‘ hÆ°á»›ng dáº«n vÃ  vÃ­ dá»¥ báº¡n cÃ³ thá»ƒ xem á»Ÿ Ä‘Ã¢y: https://docs.cnext.io/sample-playbooks
https://twitter.com/cnextdotio
DÆ°á»›i Ä‘Ã¢y lÃ  má»™t demo khÃ¡ thÃº vá»‹ vá» cÃ¡ch CNext xá»­ lÃ½ dá»¯ liá»‡u. Hy vá»ng bÃ i viáº¿t há»¯u Ã­ch vá»›i má»i ngÆ°á»i. ChÃºc má»i ngÆ°á»i má»™t ngÃ y vui váº» ğŸ¤—","Hi má»i ngÆ°á»i, hÃ´m nay mÃ¬nh muá»‘n chia sáº» má»™t tool khÃ¡ hay á»©ng dá»¥ng cá»§a chatgpt/LLM Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi CNext, giÃºp há»— trá»£ ngÆ°á»i dÃ¹ng tráº£ lá»i cÃ¢u há»i, tÃ¬m insight tá»« dá»¯ liá»‡u báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn. Theo mÃ¬nh tháº¥y CNext hoáº¡t Ä‘á»™ng khÃ¡ áº¥n tÆ°á»Ÿng, dÃ¹ báº¡n cÃ³ kiáº¿n thá»©c vá» láº­p trÃ¬nh hay khÃ´ng thÃ¬ má»™t sá»‘ task yÃªu cáº§u phá»©c táº¡p báº¡n chá»‰ cáº§n mÃ´ táº£ Ã½ tÆ°á»Ÿng cá»§a mÃ¬nh CNext cÃ³ thá»ƒ há»— trá»£ báº¡n triá»ƒn khai Ã½ tÆ°á»Ÿng Ä‘Ã³ trÃªn dá»¯ liá»‡u cá»§a báº¡n. MÃ¬nh tháº¥y tool cÃ³ khÃ¡ nhiá»u api há»— trá»£: Import data: Táº£i lÃªn má»™t file dÆ°á»›i Ä‘á»‹nh dáº¡ng .csv (Ä‘Ã¢y sáº½ lÃ  file báº¡n mong muá»‘n phÃ¢n tÃ­ch vÃ  tÃ¬m insight) Table ops: Thao tÃ¡c xá»­ lÃ½ dá»¯ liá»‡u trÃªn cÃ¡c trÆ°á»ng dá»¯ liá»‡u Google search: cho phÃ©p báº¡n search thÃ´ng tin trÃªn google vÃ  tráº£ vá» Ä‘á»‹nh dáº¡ng json dá»… dÃ ng Ä‘á»ƒ khai thÃ¡c dá»¯ liá»‡u Twitter search hoáº·c Twitter Entities: Cho phÃ©p láº¥y thÃ´ng tin trÃªn twitter (ráº¥t phÃ¹ há»£p trong viá»‡c phÃ¢n tÃ­ch má»™t trend hoáº·c má»™t sáº£n pháº©m Ä‘Æ°á»£c giá»›i thiá»‡u trÃªn twitter, giÃºp ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ theo dÃµi má»©c Ä‘á»™ quan tÃ¢m hoáº·c thÃ¡i Ä‘á»™ cá»§a má»i ngÆ°á»i Ä‘á»‘i vá»›i tweet cá»§a mÃ¬nh Plotting: Cho phÃ©p visualize dá»¯ liá»‡u, design biá»ƒu Ä‘á»“ thÃ´ng qua Ã½ tÆ°á»Ÿng ngÃ´n ngá»¯ tá»± nhiÃªn nháº¥t cÃ³ thá»ƒ NgoÃ i ra cÃ²n má»™t sá»‘ api khÃ¡c giÃºp cho cÃ¡c báº¡n HR cÃ³ thá»ƒ tÃ¬m kiáº¿m á»©ng viÃªn trÃªn linkedin phÃ¹ há»£p vá»›i tiÃªu chÃ­ cá»§a má»i ngÆ°á»i Ä‘áº·t ra,... Má»™t sá»‘ hÆ°á»›ng dáº«n vÃ  vÃ­ dá»¥ báº¡n cÃ³ thá»ƒ xem á»Ÿ Ä‘Ã¢y: https://docs.cnext.io/sample-playbooks https://twitter.com/cnextdotio DÆ°á»›i Ä‘Ã¢y lÃ  má»™t demo khÃ¡ thÃº vá»‹ vá» cÃ¡ch CNext xá»­ lÃ½ dá»¯ liá»‡u. Hy vá»ng bÃ i viáº¿t há»¯u Ã­ch vá»›i má»i ngÆ°á»i. ChÃºc má»i ngÆ°á»i má»™t ngÃ y vui váº»",,,,,"#shairng, #deep_learning, #nlp"
"Hello má»i ngÆ°á»i, viá»‡c cÃ¡c cÃ´ng cá»¥ nhÆ° ChatGPT vÃ  Midjourney trá»Ÿ nÃªn phá»• biáº¿n trong thá»i gian gáº§n Ä‘Ã¢y Ä‘Ã£ gÃ¢y ra vÃ´ sá»‘ Ã½ kiáº¿n trÃ¡i chiá»u trong nhiá»u lÄ©nh vá»±c khÃ¡c nhau. Trong bÃ i viáº¿t nÃ y mÃ¬nh phÃ¢n tÃ­ch hai khÃ­a cáº¡nh vá» sá»± sá»¥t giáº£m cháº¥t lÆ°á»£ng vÃ  sá»‘ lÆ°á»£ng content táº¡o ra bá»Ÿi con ngÆ°á»i cÃ¹ng vá»›i viá»‡c thiáº¿u dá»¯ liá»‡u dÃ¹ng cho training generative model trong tÆ°Æ¡ng lai. Náº¿u má»i ngÆ°á»i cÃ³ insight vá» sá»± áº£nh hÆ°á»Ÿng cá»§a AI trong cÃ¡c lÄ©nh vá»±c nhÆ° design hoáº·c content writing thÃ¬ cÅ©ng cÃ³ thá»ƒ cÃ¹ng chia sáº» nhÃ©.","Hello má»i ngÆ°á»i, viá»‡c cÃ¡c cÃ´ng cá»¥ nhÆ° ChatGPT vÃ  Midjourney trá»Ÿ nÃªn phá»• biáº¿n trong thá»i gian gáº§n Ä‘Ã¢y Ä‘Ã£ gÃ¢y ra vÃ´ sá»‘ Ã½ kiáº¿n trÃ¡i chiá»u trong nhiá»u lÄ©nh vá»±c khÃ¡c nhau. Trong bÃ i viáº¿t nÃ y mÃ¬nh phÃ¢n tÃ­ch hai khÃ­a cáº¡nh vá» sá»± sá»¥t giáº£m cháº¥t lÆ°á»£ng vÃ  sá»‘ lÆ°á»£ng content táº¡o ra bá»Ÿi con ngÆ°á»i cÃ¹ng vá»›i viá»‡c thiáº¿u dá»¯ liá»‡u dÃ¹ng cho training generative model trong tÆ°Æ¡ng lai. Náº¿u má»i ngÆ°á»i cÃ³ insight vá» sá»± áº£nh hÆ°á»Ÿng cá»§a AI trong cÃ¡c lÄ©nh vá»±c nhÆ° design hoáº·c content writing thÃ¬ cÅ©ng cÃ³ thá»ƒ cÃ¹ng chia sáº» nhÃ©.",,,,,"#sharing, #deep_learning"
"VinAI Seminar - ""An Integrated Framework for Controllable Text Generation""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Wei Xu, Assist. Prof. at Georgia Institute of Technology
Time: 9:30 am - 10:30 am (GMT+7), Tue, Apr 11, 2023","VinAI Seminar - ""An Integrated Framework for Controllable Text Generation"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Wei Xu, Assist. Prof. at Georgia Institute of Technology Time: 9:30 am - 10:30 am (GMT+7), Tue, Apr 11, 2023",,,,,bá»
"Gáº§n Ä‘Ã¢y (r-)Polars ná»•i lÃªn nhÆ° 1 thÆ° viá»‡n cáº¡nh tranh vá»›i Pandas/Tidyverse vá» tá»‘c Ä‘á»™ xá»­ lÃ½ dá»¯ liá»‡u lá»›n dáº¡ng báº£ng. Trong repository (https://github.com/linhduongtuan/Polars_vs_Pandas) nÃ y cá»§a mÃ¬nh, mÃ¬nh sáº½ thá»­ tá»‘c Ä‘á»™ dá»¯ liá»‡u lá»›n cÃ³ tÃªn lÃ  69M_reddit_account.csv. Dá»¯ liá»‡u nÃ y cÃ³ 69 triá»‡u dÃ²ng vÃ  7 biáº¿n sá»‘ (cá»™t). Khi giáº£i nÃ©n file *gz thÃ nh *csv nÃ³ náº·ng ~3.3Gb. MÃ¬nh sáº½ so sÃ¡nh hiá»‡u nÄƒng Ä‘á»c cÃ¡c files nÃ y (Ä‘á»‹nh dáº¡ng CSV, Parquet, vÃ  Feather) báº±ng Polars so vá»›i Pandas (version 2) sá»­ dá»¥ng NumPy  vÃ  PyArrow backends.

Káº¿t quáº£ cho tháº¥y:
Polars tháº¯ng trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m;
Pandas vá»›i PyArrow backend tiá»‡m cáº­n tá»‘c Ä‘á»™ Polars, vÃ  nhanh hÆ¡n Ä‘Ã¡ng ká»ƒ khi Ä‘á»c files *parquet vÃ  *feather (nhÆ°ng láº¡i cháº­m hÆ¡n vá»›i *csv).
Lá»i táº¡m káº¿t:
MÃ¬nh nghÄ© Polars Ä‘Ã£ vÃ  Ä‘ang lÃ  Ä‘á»‘i thá»§ lá»›n cá»§a Pandas;
Rust sáº½ lÃ  ngÃ´n ngÃ´n láº­p trÃ¬nh ráº¥t thÃº vá»‹ vÃ  Ä‘Ã¡ng chÃºng ta Ä‘áº§u tÆ° thá»i gian Ä‘á»ƒ há»c.
Dá»¯ liá»‡u táº£i táº¡i Ä‘Ã¢y (https://files.pushshift.io/reddit/69M_reddit_accounts.csv.gz)
CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o káº¿t quáº£ thÃ­ nghiá»‡m cá»§a mÃ¬nh táº¡i Ä‘Ã¢y (https://github.com/linhduongtuan/Polars_vs_Pandas) ","Gáº§n Ä‘Ã¢y (r-)Polars ná»•i lÃªn nhÆ° 1 thÆ° viá»‡n cáº¡nh tranh vá»›i Pandas/Tidyverse vá» tá»‘c Ä‘á»™ xá»­ lÃ½ dá»¯ liá»‡u lá»›n dáº¡ng báº£ng. Trong repository (https://github.com/linhduongtuan/Polars_vs_Pandas) nÃ y cá»§a mÃ¬nh, mÃ¬nh sáº½ thá»­ tá»‘c Ä‘á»™ dá»¯ liá»‡u lá»›n cÃ³ tÃªn lÃ  69M_reddit_account.csv. Dá»¯ liá»‡u nÃ y cÃ³ 69 triá»‡u dÃ²ng vÃ  7 biáº¿n sá»‘ (cá»™t). Khi giáº£i nÃ©n file *gz thÃ nh *csv nÃ³ náº·ng ~3.3Gb. MÃ¬nh sáº½ so sÃ¡nh hiá»‡u nÄƒng Ä‘á»c cÃ¡c files nÃ y (Ä‘á»‹nh dáº¡ng CSV, Parquet, vÃ  Feather) báº±ng Polars so vá»›i Pandas (version 2) sá»­ dá»¥ng NumPy vÃ  PyArrow backends. Káº¿t quáº£ cho tháº¥y: Polars tháº¯ng trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m; Pandas vá»›i PyArrow backend tiá»‡m cáº­n tá»‘c Ä‘á»™ Polars, vÃ  nhanh hÆ¡n Ä‘Ã¡ng ká»ƒ khi Ä‘á»c files *parquet vÃ  *feather (nhÆ°ng láº¡i cháº­m hÆ¡n vá»›i *csv). Lá»i táº¡m káº¿t: MÃ¬nh nghÄ© Polars Ä‘Ã£ vÃ  Ä‘ang lÃ  Ä‘á»‘i thá»§ lá»›n cá»§a Pandas; Rust sáº½ lÃ  ngÃ´n ngÃ´n láº­p trÃ¬nh ráº¥t thÃº vá»‹ vÃ  Ä‘Ã¡ng chÃºng ta Ä‘áº§u tÆ° thá»i gian Ä‘á»ƒ há»c. Dá»¯ liá»‡u táº£i táº¡i Ä‘Ã¢y (https://files.pushshift.io/reddit/69M_reddit_accounts.csv.gz) CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o káº¿t quáº£ thÃ­ nghiá»‡m cá»§a mÃ¬nh táº¡i Ä‘Ã¢y (https://github.com/linhduongtuan/Polars_vs_Pandas)",,,,,"#sharing, #python"
"[MLOps] 
Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m Data Scientist cho 1 cÃ´ng ty Big 4 á»Ÿ Báº¯c Má»¹. Do mÃ¬nh muá»‘n há»c thÃªm máº£ng MLOps Ä‘á»ƒ chuáº©n bá»‹ Ä‘á»•i viá»‡c, nÃªn cÃ³ vÃ i tháº¯c máº¯c, ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i chá»‰ giÃºp áº¡.
1. Vá»›i working directory nhÆ° hÃ¬nh, thÃ¬ mÃ¬nh cÃ³ váº» nhÆ° Ä‘ang dockerize chÆ°a Ä‘Ãºng, má»i ngÆ°á»i cÃ³ thá»ƒ xem giÃºp mÃ¬nh vá»›i áº¡. VÃ¬ khi mÃ¬nh cháº¡y app tá»« docker image (  Network URL: http://172.17.0.4:8501,   External URL: http://76.64.53.12:8501) thÃ¬ browser khÃ´ng load Ä‘Æ°á»£c.
2. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ khi cháº¡y app thÃ¬ tá»± Ä‘á»™ng má»Ÿ browser luÃ´n thay vÃ¬ pháº£i click tay vÃ o URL khÃ´ng áº¡?
3. Sau khi Dockerized xong, má»i ngÆ°á»i cÃ³ suggest gÃ¬ vá» Cloud Ä‘á»ƒ mÃ¬nh deploy app nÃ y lÃªn free vÃ  lÃ m portfolio Ä‘á»ƒ mÃ¬nh xin viá»‡c.
MÃ¬nh cáº£m Æ¡n nhiá»u áº¡. VÃ  ráº¥t mong Ä‘Æ°á»£c káº¿t báº¡n vá»›i má»i ngÆ°á»i Ä‘á»ƒ há»c há»i.","[MLOps] Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m Data Scientist cho 1 cÃ´ng ty Big 4 á»Ÿ Báº¯c Má»¹. Do mÃ¬nh muá»‘n há»c thÃªm máº£ng MLOps Ä‘á»ƒ chuáº©n bá»‹ Ä‘á»•i viá»‡c, nÃªn cÃ³ vÃ i tháº¯c máº¯c, ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i chá»‰ giÃºp áº¡. 1. Vá»›i working directory nhÆ° hÃ¬nh, thÃ¬ mÃ¬nh cÃ³ váº» nhÆ° Ä‘ang dockerize chÆ°a Ä‘Ãºng, má»i ngÆ°á»i cÃ³ thá»ƒ xem giÃºp mÃ¬nh vá»›i áº¡. VÃ¬ khi mÃ¬nh cháº¡y app tá»« docker image ( Network URL: http://172.17.0.4:8501, External URL: http://76.64.53.12:8501) thÃ¬ browser khÃ´ng load Ä‘Æ°á»£c. 2. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ khi cháº¡y app thÃ¬ tá»± Ä‘á»™ng má»Ÿ browser luÃ´n thay vÃ¬ pháº£i click tay vÃ o URL khÃ´ng áº¡? 3. Sau khi Dockerized xong, má»i ngÆ°á»i cÃ³ suggest gÃ¬ vá» Cloud Ä‘á»ƒ mÃ¬nh deploy app nÃ y lÃªn free vÃ  lÃ m portfolio Ä‘á»ƒ mÃ¬nh xin viá»‡c. MÃ¬nh cáº£m Æ¡n nhiá»u áº¡. VÃ  ráº¥t mong Ä‘Æ°á»£c káº¿t báº¡n vá»›i má»i ngÆ°á»i Ä‘á»ƒ há»c há»i.",,,,,#Q&A
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 03/2023 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 03/2023 vÃ o comment cá»§a post nÃ y.",,,,,bá»
"Em chÃ o má»i ngÆ°á»i, em cáº§n tÃ¬m gpu Ä‘á»ƒ train dá»¯ liá»‡u khoáº£ng 70gb, áº£nh lÃ  dáº¡ng áº£nh 3d google map nÃªn ráº¥t náº·ng áº¡. Xin má»i ngÆ°á»i tÆ° váº¥n cho em vá» google driver vÃ  google colab áº¡","Em chÃ o má»i ngÆ°á»i, em cáº§n tÃ¬m gpu Ä‘á»ƒ train dá»¯ liá»‡u khoáº£ng 70gb, áº£nh lÃ  dáº¡ng áº£nh 3d google map nÃªn ráº¥t náº·ng áº¡. Xin má»i ngÆ°á»i tÆ° váº¥n cho em vá» google driver vÃ  google colab áº¡",,,,,#Q&A
"VinAI Seminar - ""Neural scene representations for learning-based view synthesis and its applications""
Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams.
Speaker: Phong Nguyen-Ha, Ph.D. candidate at University of Oulu, Finland
Time: 2:30 pm - 3:30 pm (GMT+7), Fri, Apr 07, 2023","VinAI Seminar - ""Neural scene representations for learning-based view synthesis and its applications"" Register here [https://forms.office.com/r/uSc77kJJx7] to access seminar via Ms. Teams. Speaker: Phong Nguyen-Ha, Ph.D. candidate at University of Oulu, Finland Time: 2:30 pm - 3:30 pm (GMT+7), Fri, Apr 07, 2023",,,,,bá»
"[OpenSource] VnGPT - MÃ£ nguá»“n má»Ÿ giÃºp dá»±ng server ChatGPT riÃªng trÃªn mÃ¡y cÃ¡ nhÃ¢n cÃ¹ng nhiá»u á»©ng dá»¥ng AI thÃº vá»‹ khÃ¡c

LÃ¢u lÃ¢u má»›i láº¡i cÃ³ project opensource Ä‘á»ƒ chia sáº» cÃ¹ng cÃ¡c anh em trong group. Sáº£n pháº©m nÃ y cÅ©ng khÃ¡ Ä‘Æ¡n giáº£n, sá»­ dá»¥ng Gradio Ä‘á»ƒ call API ChatGPT, Whisper tá»« OpenAI vÃ  tiáº¿p tá»¥c má»Ÿ rá»™ng, káº¿t ná»‘i luá»“ng vá»›i nhau Ä‘á»ƒ táº¡o ra giao diá»‡n tiá»‡n dá»¥ng cuá»‘i cho ngÆ°á»i dÃ¹ng. PhÃ¹ há»£p Ä‘á»ƒ cÃ¡c anh em nghiÃªn cá»©u vá» AI tá»± dá»±ng server Ä‘á»ƒ test ChatGPT, hoáº·c dá»±ng server ChatGPT dÃ¹ng riÃªng cho báº¡n bÃ¨, gia Ä‘Ã¬nh, cÃ´ng ty. 

CÃ²n Ã½ nghÄ©a sÃ¢u xa cá»§a project thÃ¬ má»i cÃ¡c anh em Ä‘á»c táº¡i Ä‘Ã¢y:
https://www.facebook.com/photo/?fbid=159818203592346&set=a.116382481269252

Nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a cÃ´ng cá»¥ nÃ y:
MÃ£ nguá»“n má»Ÿ vÃ  miá»…n phÃ­
CÃ i Ä‘áº·t dá»… dÃ ng trÃªn mÃ¡y tÃ­nh cÃ¡ nhÃ¢n (Windows, MacOS, Ubuntu) chá»‰ vá»›i má»™t click
TÃ­ch há»£p sáºµn: ChatGPT, Whisper...vÃ  liÃªn tá»¥c bá»• sung cÃ¡c dá»‹ch vá»¥ AI má»›i
Tá»± setup server riÃªng Ä‘á»ƒ sá»­ dá»¥ng cÃ¡ nhÃ¢n, hoáº·c chia sáº» qua Internet Ä‘á»ƒ báº¡n bÃ¨, ngÆ°á»i thÃ¢n cÃ¹ng sá»­ dá»¥ng
Cáº¥u hÃ¬nh cÃ¡c tham sá»‘ nÃ¢ng cao, giÃºp má»Ÿ khÃ³a nhiá»u chá»©c nÄƒng má»›i cho ChatGPT, Whisper, VnAlert...

VnGPT hiá»‡n Ä‘Æ°á»£c cam káº¿t duy trÃ¬ quáº£n lÃ½, phÃ¡t triá»ƒn bá»Ÿi AIV Group. Tuy nhiÃªn lÃ  sáº£n pháº©m nguá»“n má»Ÿ nÃªn cÃ¡c anh em clone vá» thoáº£i mÃ¡i. Náº¿u cÃ³ thá»ƒ commit back trá»Ÿ láº¡i mÃ£ nguá»“n gá»‘c thÃ¬ cÃ ng tá»‘t. 
-------------------------
ğŸ‘‰ DÃ¹ng thá»­ VnGPT táº¡i: https://vngpt.aivgroup.vn
ğŸ‘‰ Táº£i vÃ  cÃ i Ä‘áº·t VnGPT táº¡i: https://github.com/AIV-Group/VnGPT-CE
ğŸ‘‰ Cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng & phÃ¡t triá»ƒn VnGPT: Cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng VnGPT
ğŸ‘‰ Há»— trá»£ sá»­ dá»¥ng trá»±c tiáº¿p trÃªn Zalo: Há»i Ä‘Ã¡p cÃ¡ch dÃ¹ng VnGPT","[OpenSource] VnGPT - MÃ£ nguá»“n má»Ÿ giÃºp dá»±ng server ChatGPT riÃªng trÃªn mÃ¡y cÃ¡ nhÃ¢n cÃ¹ng nhiá»u á»©ng dá»¥ng AI thÃº vá»‹ khÃ¡c LÃ¢u lÃ¢u má»›i láº¡i cÃ³ project opensource Ä‘á»ƒ chia sáº» cÃ¹ng cÃ¡c anh em trong group. Sáº£n pháº©m nÃ y cÅ©ng khÃ¡ Ä‘Æ¡n giáº£n, sá»­ dá»¥ng Gradio Ä‘á»ƒ call API ChatGPT, Whisper tá»« OpenAI vÃ  tiáº¿p tá»¥c má»Ÿ rá»™ng, káº¿t ná»‘i luá»“ng vá»›i nhau Ä‘á»ƒ táº¡o ra giao diá»‡n tiá»‡n dá»¥ng cuá»‘i cho ngÆ°á»i dÃ¹ng. PhÃ¹ há»£p Ä‘á»ƒ cÃ¡c anh em nghiÃªn cá»©u vá» AI tá»± dá»±ng server Ä‘á»ƒ test ChatGPT, hoáº·c dá»±ng server ChatGPT dÃ¹ng riÃªng cho báº¡n bÃ¨, gia Ä‘Ã¬nh, cÃ´ng ty. CÃ²n Ã½ nghÄ©a sÃ¢u xa cá»§a project thÃ¬ má»i cÃ¡c anh em Ä‘á»c táº¡i Ä‘Ã¢y: https://www.facebook.com/photo/?fbid=159818203592346&set=a.116382481269252 Nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a cÃ´ng cá»¥ nÃ y: MÃ£ nguá»“n má»Ÿ vÃ  miá»…n phÃ­ CÃ i Ä‘áº·t dá»… dÃ ng trÃªn mÃ¡y tÃ­nh cÃ¡ nhÃ¢n (Windows, MacOS, Ubuntu) chá»‰ vá»›i má»™t click TÃ­ch há»£p sáºµn: ChatGPT, Whisper...vÃ  liÃªn tá»¥c bá»• sung cÃ¡c dá»‹ch vá»¥ AI má»›i Tá»± setup server riÃªng Ä‘á»ƒ sá»­ dá»¥ng cÃ¡ nhÃ¢n, hoáº·c chia sáº» qua Internet Ä‘á»ƒ báº¡n bÃ¨, ngÆ°á»i thÃ¢n cÃ¹ng sá»­ dá»¥ng Cáº¥u hÃ¬nh cÃ¡c tham sá»‘ nÃ¢ng cao, giÃºp má»Ÿ khÃ³a nhiá»u chá»©c nÄƒng má»›i cho ChatGPT, Whisper, VnAlert... VnGPT hiá»‡n Ä‘Æ°á»£c cam káº¿t duy trÃ¬ quáº£n lÃ½, phÃ¡t triá»ƒn bá»Ÿi AIV Group. Tuy nhiÃªn lÃ  sáº£n pháº©m nguá»“n má»Ÿ nÃªn cÃ¡c anh em clone vá» thoáº£i mÃ¡i. Náº¿u cÃ³ thá»ƒ commit back trá»Ÿ láº¡i mÃ£ nguá»“n gá»‘c thÃ¬ cÃ ng tá»‘t. ------------------------- DÃ¹ng thá»­ VnGPT táº¡i: https://vngpt.aivgroup.vn Táº£i vÃ  cÃ i Ä‘áº·t VnGPT táº¡i: https://github.com/AIV-Group/VnGPT-CE Cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng & phÃ¡t triá»ƒn VnGPT: Cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng VnGPT Há»— trá»£ sá»­ dá»¥ng trá»±c tiáº¿p trÃªn Zalo: Há»i Ä‘Ã¡p cÃ¡ch dÃ¹ng VnGPT",,,,,"#sharing, #nlp"
"""With >30 hours of video content (all free, no ads!), you'll learn how to create and train a Stable Diffusion model starting from pure Python""","""With >30 hours of video content (all free, no ads!), you'll learn how to create and train a Stable Diffusion model starting from pure Python""",,,,,bá»
"Tiáº¿p tá»¥c chá»§ Ä‘á» chatbot. Láº§n nhÃ³m mÃ¬nh tiáº¿p cáº­n finetune cho model Bloomz-7b1-mt, káº¿t há»£p vá»›i Low-rank adaptation cho cÆ¡ sá»Ÿ dá»¯ liá»‡u há»i Ä‘Ã¡p vá»›i bÃ¡c sÄ© vá» bá»‡nh táº­t (báº±ng tiáº¿ng Anh). BÃ i bÃ¡o gá»‘c táº¡i Ä‘Ã¢y https://arxiv.org/pdf/2303.14070.pdf.
LÃ½ do nhÃ³m mÃ¬nh chá»n Bloomz-7b1-mt lÃ m model gá»‘c lÃ  váº¥n Ä‘á» báº£n quyá»n má»Ÿ cá»§a BigScience. NÃ³ khÃ¡c vá»›i nhá»¯ng rÃ ng buá»™c báº£n quyá»n cho LLaMA. VÃ  Bloom Ä‘Æ°á»£c train trÃªn dataset cÃ³ tÃªn lÃ  ROOT cÃ³ kha khÃ¡ dá»¯ liá»‡u lÃ  tiáº¿ng Viá»‡t. NÃ³ cÃ³ thá»ƒ giÃºp cÃ¡c báº¡n finetune thÃªm báº±ng tiáº¿ng Viá»‡t thuáº­n lá»£i hÆ¡n náº¿u muá»‘n.
Káº¿t quáº£ prompt mÃ¬nh cÃ³ so sÃ¡nh trong source code cá»§a nhÃ³m mÃ¬nh. MÃ¬nh Ä‘áº·t tÃªn cho finetuned model lÃ  Doctor with Bloom (táº¡m dá»‹ch bÃ¡c sÄ© vá»›i hoa). ÄÃ¢y lÃ  source code cá»§a mÃ¬nh.  https://github.com/linhduongtuan/doctorwithbloom
Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i. VÃ  xin Ä‘á»«ng tiáº¿c **** náº¿u báº¡n thÃ­ch repository nÃ y.
 â€” vá»›i Pháº¡m Ngá»c Ninh.","Tiáº¿p tá»¥c chá»§ Ä‘á» chatbot. Láº§n nhÃ³m mÃ¬nh tiáº¿p cáº­n finetune cho model Bloomz-7b1-mt, káº¿t há»£p vá»›i Low-rank adaptation cho cÆ¡ sá»Ÿ dá»¯ liá»‡u há»i Ä‘Ã¡p vá»›i bÃ¡c sÄ© vá» bá»‡nh táº­t (báº±ng tiáº¿ng Anh). BÃ i bÃ¡o gá»‘c táº¡i Ä‘Ã¢y https://arxiv.org/pdf/2303.14070.pdf. LÃ½ do nhÃ³m mÃ¬nh chá»n Bloomz-7b1-mt lÃ m model gá»‘c lÃ  váº¥n Ä‘á» báº£n quyá»n má»Ÿ cá»§a BigScience. NÃ³ khÃ¡c vá»›i nhá»¯ng rÃ ng buá»™c báº£n quyá»n cho LLaMA. VÃ  Bloom Ä‘Æ°á»£c train trÃªn dataset cÃ³ tÃªn lÃ  ROOT cÃ³ kha khÃ¡ dá»¯ liá»‡u lÃ  tiáº¿ng Viá»‡t. NÃ³ cÃ³ thá»ƒ giÃºp cÃ¡c báº¡n finetune thÃªm báº±ng tiáº¿ng Viá»‡t thuáº­n lá»£i hÆ¡n náº¿u muá»‘n. Káº¿t quáº£ prompt mÃ¬nh cÃ³ so sÃ¡nh trong source code cá»§a nhÃ³m mÃ¬nh. MÃ¬nh Ä‘áº·t tÃªn cho finetuned model lÃ  Doctor with Bloom (táº¡m dá»‹ch bÃ¡c sÄ© vá»›i hoa). ÄÃ¢y lÃ  source code cá»§a mÃ¬nh. https://github.com/linhduongtuan/doctorwithbloom Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i. VÃ  xin Ä‘á»«ng tiáº¿c **** náº¿u báº¡n thÃ­ch repository nÃ y. â€” vá»›i Pháº¡m Ngá»c Ninh.",,,,,"#sharing, #deep_learning"
Em Ä‘ang muá»‘n build server cÃ³ khoáº£ng 10 GPU. CÃ¡c anh chá»‹ cho em há»i mua GPU vÃ  mother board á»Ÿ HÃ  Ná»™i á»Ÿ Ä‘Ã¢u áº¡? Em nÃªn mua GPU vÃ  mother board loáº¡i nÃ o áº¡.,Em Ä‘ang muá»‘n build server cÃ³ khoáº£ng 10 GPU. CÃ¡c anh chá»‹ cho em há»i mua GPU vÃ  mother board á»Ÿ HÃ  Ná»™i á»Ÿ Ä‘Ã¢u áº¡? Em nÃªn mua GPU vÃ  mother board loáº¡i nÃ o áº¡.,,,,,#sharing
"Dáº¡ em xin chÃ o má»i ngÆ°á»i!
Má»i ngÆ°á»i cÃ³ cÃ¡c bá»™ data liÃªn quan Ä‘áº¿n cÃ¡c biá»ƒu hiá»‡n trÃªn khuÃ´n máº·t khÃ´ng áº¡? VÃ­ dá»¥ cÃ¡c bá»™ data Ä‘á»ƒ phÃ¢n biá»‡t cÃ¡c biá»ƒu hiá»‡n sau:
1- Dá»¯ liá»‡u khuÃ´n máº·t cá»§a ngÆ°á»i bá»‹ á»‘m (bá»‹ bá»‡nh/ má»‡t má»i)
2- Dá»¯ liá»‡u khuÃ´n máº·t cá»§a ngÆ°á»i bá»‹ Ä‘au Ä‘á»›n (khÃ³ chá»‹u)
Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡. ChÃºc má»i ngÆ°á»i tuáº§n má»›i lÃ m viá»‡c hiá»‡u quáº£ .",Dáº¡ em xin chÃ o má»i ngÆ°á»i! Má»i ngÆ°á»i cÃ³ cÃ¡c bá»™ data liÃªn quan Ä‘áº¿n cÃ¡c biá»ƒu hiá»‡n trÃªn khuÃ´n máº·t khÃ´ng áº¡? VÃ­ dá»¥ cÃ¡c bá»™ data Ä‘á»ƒ phÃ¢n biá»‡t cÃ¡c biá»ƒu hiá»‡n sau: 1- Dá»¯ liá»‡u khuÃ´n máº·t cá»§a ngÆ°á»i bá»‹ á»‘m (bá»‹ bá»‡nh/ má»‡t má»i) 2- Dá»¯ liá»‡u khuÃ´n máº·t cá»§a ngÆ°á»i bá»‹ Ä‘au Ä‘á»›n (khÃ³ chá»‹u) Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡. ChÃºc má»i ngÆ°á»i tuáº§n má»›i lÃ m viá»‡c hiá»‡u quáº£ .,,,,,"#Q&A, #data"
"[Nhá» giÃºp Ä‘á»¡ vá» dá»± bÃ¡o thá»i tiáº¿t Timeseries]
ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m project dá»± bÃ¡o thá»i tiáº¿t vÃ  em Ä‘ang cÃ³ báº£ng dá»¯ liá»‡u nhÆ° hÃ¬nh (cÃ³ thá»ƒ lÃ m thÃªm cÃ¡c feild khÃ¡c náº¿u cáº§n Ä‘á»ƒ training model).
Cá»¥ thá»ƒ lÃ :
-Má»—i 1h, há»‡ thá»‘ng sáº½ thu dá»¯ liá»‡u Nhiá»‡t Ä‘á»™, Ä‘á»™ áº©m, Ã¡p suáº¥t tá»« cáº£m biáº¿n vÃ  Ä‘Æ°a lÃªn database MySQL sau Ä‘Ã³ Ä‘Æ°a lÃªn web nhÆ° hÃ¬nh. Sau Ä‘Ã³ toÃ n bá»™ dá»¯ liá»‡u cá»§a há»‡ thá»‘ng sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ train model vÃ  Ä‘Æ°a ra dá»± bÃ¡o.
Em muá»‘n dá»± bÃ¡o thá»i tiáº¿t trong 7 ngÃ y tá»›i (time series) nhÆ°ng chÆ°a biáº¿t tÃ¬m hiá»ƒu tá»« Ä‘Ã¢u, hay dÃ¹ng model gÃ¬ (em má»›i tÃ¬m hiá»ƒu vá» AI ML). Em xin cáº£m Æ¡n áº¡ ğŸ¥¹ğŸ¥¹ğŸ¥¹","[Nhá» giÃºp Ä‘á»¡ vá» dá»± bÃ¡o thá»i tiáº¿t Timeseries] ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m project dá»± bÃ¡o thá»i tiáº¿t vÃ  em Ä‘ang cÃ³ báº£ng dá»¯ liá»‡u nhÆ° hÃ¬nh (cÃ³ thá»ƒ lÃ m thÃªm cÃ¡c feild khÃ¡c náº¿u cáº§n Ä‘á»ƒ training model). Cá»¥ thá»ƒ lÃ : -Má»—i 1h, há»‡ thá»‘ng sáº½ thu dá»¯ liá»‡u Nhiá»‡t Ä‘á»™, Ä‘á»™ áº©m, Ã¡p suáº¥t tá»« cáº£m biáº¿n vÃ  Ä‘Æ°a lÃªn database MySQL sau Ä‘Ã³ Ä‘Æ°a lÃªn web nhÆ° hÃ¬nh. Sau Ä‘Ã³ toÃ n bá»™ dá»¯ liá»‡u cá»§a há»‡ thá»‘ng sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ train model vÃ  Ä‘Æ°a ra dá»± bÃ¡o. Em muá»‘n dá»± bÃ¡o thá»i tiáº¿t trong 7 ngÃ y tá»›i (time series) nhÆ°ng chÆ°a biáº¿t tÃ¬m hiá»ƒu tá»« Ä‘Ã¢u, hay dÃ¹ng model gÃ¬ (em má»›i tÃ¬m hiá»ƒu vá» AI ML). Em xin cáº£m Æ¡n áº¡",,,,,"#Q&A, #data, #machine_learning"
AI Cá»¦A DUOLINGO,AI Cá»¦A DUOLINGO,,,,,bá»
"BÃ¡o cÃ¡o 150 trang bá»Ÿi team Microsofts vá» GPT-4.
Vá»›i GPT-4, tá»« ""GPT cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c gÃ¬"" Ä‘Ã£ chuyá»ƒn thÃ nh ""CÃ³ gÃ¬ mÃ  GPT khÃ´ng lÃ m Ä‘Æ°á»£c"".
Má»™t cÃ¡ch Ä‘áº§y báº¥t ngá», LLMs Ä‘Ã£ khiáº¿n nhá»¯ng ngÆ°á»i lÃ m AI tháº¥y Ä‘Æ°á»£c má»™t tia sÃ¡ng trong cÃ´ng cuá»™c tiáº¿p cáº­n AGI.
https://vuanhtran.substack.com/p/2-sparks-of-artificial-general-intelligence?sd=pf
1 tuáº§n mÃ¬nh sáº½ viáº¿t 1-2 blogs, má»i ngÆ°á»i subscribe nhÃ©","BÃ¡o cÃ¡o 150 trang bá»Ÿi team Microsofts vá» GPT-4. Vá»›i GPT-4, tá»« ""GPT cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c gÃ¬"" Ä‘Ã£ chuyá»ƒn thÃ nh ""CÃ³ gÃ¬ mÃ  GPT khÃ´ng lÃ m Ä‘Æ°á»£c"". Má»™t cÃ¡ch Ä‘áº§y báº¥t ngá», LLMs Ä‘Ã£ khiáº¿n nhá»¯ng ngÆ°á»i lÃ m AI tháº¥y Ä‘Æ°á»£c má»™t tia sÃ¡ng trong cÃ´ng cuá»™c tiáº¿p cáº­n AGI. https://vuanhtran.substack.com/p/2-sparks-of-artificial-general-intelligence?sd=pf 1 tuáº§n mÃ¬nh sáº½ viáº¿t 1-2 blogs, má»i ngÆ°á»i subscribe nhÃ©",,,,,#sharing
"ChÃ o anh chá»‹ áº¡, em cÃ³ má»™t vÃ i tháº¯c máº¯c vá» cÃ¡c vá»‹ trÃ­ nghá» nghiá»‡p trong ngÃ nh AI.
Vá» máº£ng data thÃ¬ e Ä‘Ã£ biáº¿t má»™t vÃ i vá»‹ trÃ­ nhÆ° Data Scientist, Data Analyst, ... Tuy nhiÃªn cÃ¡c vá»‹ trÃ­ khÃ¡c - em táº¡m gá»i lÃ  máº£ng AI (lÃ m viá»‡c vá»›i models, ...) thÃ¬ e chÆ°a hÃ¬nh dung rÃµ vÃ  chÆ°a biáº¿t tÃªn áº¡.
Anh chá»‹ cho e xin review vá» cÃ¡c jobs liÃªn quan Ä‘áº¿n máº£ng AI (tÃªn vá»‹ trÃ­, cÃ¡c tasks khi Ä‘i lÃ m) vá»›i áº¡.
Cáº£m Æ¡n admin vÃ  mng ráº¥t nhiá»u","ChÃ o anh chá»‹ áº¡, em cÃ³ má»™t vÃ i tháº¯c máº¯c vá» cÃ¡c vá»‹ trÃ­ nghá» nghiá»‡p trong ngÃ nh AI. Vá» máº£ng data thÃ¬ e Ä‘Ã£ biáº¿t má»™t vÃ i vá»‹ trÃ­ nhÆ° Data Scientist, Data Analyst, ... Tuy nhiÃªn cÃ¡c vá»‹ trÃ­ khÃ¡c - em táº¡m gá»i lÃ  máº£ng AI (lÃ m viá»‡c vá»›i models, ...) thÃ¬ e chÆ°a hÃ¬nh dung rÃµ vÃ  chÆ°a biáº¿t tÃªn áº¡. Anh chá»‹ cho e xin review vá» cÃ¡c jobs liÃªn quan Ä‘áº¿n máº£ng AI (tÃªn vá»‹ trÃ­, cÃ¡c tasks khi Ä‘i lÃ m) vá»›i áº¡. Cáº£m Æ¡n admin vÃ  mng ráº¥t nhiá»u",,,,,#Q&A
Em xin phÃ©p share má»™t webinar khÃ¡c diá»…n ra vÃ o 8h tá»‘i nay (30/3) tá»• chá»©c bá»Ÿi MLOpsVN,Em xin phÃ©p share má»™t webinar khÃ¡c diá»…n ra vÃ o 8h tá»‘i nay (30/3) tá»• chá»©c bá»Ÿi MLOpsVN,,,,,#webinar
"Xin phÃ©p má»i ngÆ°á»i trong nhÃ³m. Hiá»‡n táº¡i em Ä‘ang chuáº©n bá»‹ lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p hÆ°á»›ng cá»§a em muá»‘n lÃ m lÃ  vá» human pose, em muá»‘n bÃ i toÃ¡n hÆ°á»›ng Ä‘áº¿n 1 sá»‘ á»©ng dá»¥ng nhÆ° phÃ¡t hiá»‡n ngÆ°á»i bá»‹ Ä‘uá»‘i nÆ°á»›c, ngÆ°á»i bá»‹ ngÃ£ cho ngÆ°á»i giÃ  Ä‘á»™t quá»µ hay tráº» nhá», hÃ nh vi ngÆ°á»i tham gia giao thÃ´ng nhÆ° chuáº©n bá»‹ bÄƒng qua Ä‘Æ°á»ng Ã¡p dá»¥ng cho Ã´tÃ´. VÃ¬ láº§n Ä‘áº§u tiÃªn em tiáº¿p cáº­n vá»›i hÆ°á»›ng nÃ y khÃ´ng biáº¿t nhá»¯ng bÃ i toÃ¡n trÃªn cá»§a em cÃ³ kháº£ thi hay khÃ³ khÄƒn nÃ o khÃ´ng em xin phÃ©p xin Ã½ kiáº¿n má»i ngÆ°á»i Ä‘Ã£ tá»«ng lÃ m vá» á»©ng dá»¥ng vá» hÆ°á»›ng nÃ y áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.","Xin phÃ©p má»i ngÆ°á»i trong nhÃ³m. Hiá»‡n táº¡i em Ä‘ang chuáº©n bá»‹ lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p hÆ°á»›ng cá»§a em muá»‘n lÃ m lÃ  vá» human pose, em muá»‘n bÃ i toÃ¡n hÆ°á»›ng Ä‘áº¿n 1 sá»‘ á»©ng dá»¥ng nhÆ° phÃ¡t hiá»‡n ngÆ°á»i bá»‹ Ä‘uá»‘i nÆ°á»›c, ngÆ°á»i bá»‹ ngÃ£ cho ngÆ°á»i giÃ  Ä‘á»™t quá»µ hay tráº» nhá», hÃ nh vi ngÆ°á»i tham gia giao thÃ´ng nhÆ° chuáº©n bá»‹ bÄƒng qua Ä‘Æ°á»ng Ã¡p dá»¥ng cho Ã´tÃ´. VÃ¬ láº§n Ä‘áº§u tiÃªn em tiáº¿p cáº­n vá»›i hÆ°á»›ng nÃ y khÃ´ng biáº¿t nhá»¯ng bÃ i toÃ¡n trÃªn cá»§a em cÃ³ kháº£ thi hay khÃ³ khÄƒn nÃ o khÃ´ng em xin phÃ©p xin Ã½ kiáº¿n má»i ngÆ°á»i Ä‘Ã£ tá»«ng lÃ m vá» á»©ng dá»¥ng vá» hÆ°á»›ng nÃ y áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,"#Q&A, #cv"
"Em chÃ o má»i ngÆ°á»i áº¡,
Má»i ngÆ°á»i cÃ³ thá»ƒ giá»›i thiá»‡u cho em má»™t sá»‘ paper ná»•i tiáº¿ng, kinh Ä‘iá»ƒn cho task Face Verification Ä‘Æ°á»£c khÃ´ng áº¡. Kinh Ä‘iá»ƒn theo Ã½ em tá»©c lÃ  khi nháº¯c tá»›i task nÃ y thÃ¬ má»i ngÆ°á»i nghÄ© ngay tá»›i paper nÃ o Ã½ áº¡.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i áº¡, Má»i ngÆ°á»i cÃ³ thá»ƒ giá»›i thiá»‡u cho em má»™t sá»‘ paper ná»•i tiáº¿ng, kinh Ä‘iá»ƒn cho task Face Verification Ä‘Æ°á»£c khÃ´ng áº¡. Kinh Ä‘iá»ƒn theo Ã½ em tá»©c lÃ  khi nháº¯c tá»›i task nÃ y thÃ¬ má»i ngÆ°á»i nghÄ© ngay tá»›i paper nÃ o Ã½ áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡.",,,,,"#Q&A, #cv"
"Em chÃ o má»i ngÆ°á»i,
Em Ä‘ang cáº§n tÃ¬m má»™t encoder model Ä‘á»ƒ encode rá»“i lÃ m clustering. Hiá»‡n táº¡i em má»›i chá»‰ tÃ¬m ra BERT tá»« nÄƒm 2018 lÃ  phá»• biáº¿n nháº¥t. KhÃ´ng biáº¿t lÃ  cÃ³ pretrained encoder nÃ o tá»‘t hÆ¡n BERT khÃ´ng áº¡. Náº¿u cÃ³ bÃ i bÃ o nÃ o Ä‘Ã¡nh giÃ¡ tá»•ng quan cÃ¡c encoder model dÃ¹ng transformer thÃ¬ cÃ ng tá»‘t áº¡","Em chÃ o má»i ngÆ°á»i, Em Ä‘ang cáº§n tÃ¬m má»™t encoder model Ä‘á»ƒ encode rá»“i lÃ m clustering. Hiá»‡n táº¡i em má»›i chá»‰ tÃ¬m ra BERT tá»« nÄƒm 2018 lÃ  phá»• biáº¿n nháº¥t. KhÃ´ng biáº¿t lÃ  cÃ³ pretrained encoder nÃ o tá»‘t hÆ¡n BERT khÃ´ng áº¡. Náº¿u cÃ³ bÃ i bÃ o nÃ o Ä‘Ã¡nh giÃ¡ tá»•ng quan cÃ¡c encoder model dÃ¹ng transformer thÃ¬ cÃ ng tá»‘t áº¡",,,,,"#Q&A, #deep_learning"
"NLP. ChÃ o má»i ngÆ°á»i áº¡. Em má»›i há»c vÃ  tÃ¬m hiá»ƒu xá»­ lÃ½ vá» NLP trong tiáº¿ng viá»‡t. Tháº§y em cho em má»™t sá»‘ thÆ° viá»‡n khÃ¡ phá»• biáº¿n nhÆ° NLTK. Cho em há»i lÃ  thÆ° viá»‡ NLTK cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c cho tiáº¿ng viá»‡t khÃ´ng áº¡? Em cáº£m Æ¡n.
Tiá»‡n thá»ƒ em muá»‘n há»i lÃ  xá»­ lÃ½ vÄƒn báº£n tiáº¿ng viá»‡t thÃ¬ ra trÆ°á»ng cÃ³ cÆ¡ há»™i tÃ¬m kiáº¿m viá»‡c lÃ m tá»‘t khÃ´ng áº¡?",NLP. ChÃ o má»i ngÆ°á»i áº¡. Em má»›i há»c vÃ  tÃ¬m hiá»ƒu xá»­ lÃ½ vá» NLP trong tiáº¿ng viá»‡t. Tháº§y em cho em má»™t sá»‘ thÆ° viá»‡n khÃ¡ phá»• biáº¿n nhÆ° NLTK. Cho em há»i lÃ  thÆ° viá»‡ NLTK cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c cho tiáº¿ng viá»‡t khÃ´ng áº¡? Em cáº£m Æ¡n. Tiá»‡n thá»ƒ em muá»‘n há»i lÃ  xá»­ lÃ½ vÄƒn báº£n tiáº¿ng viá»‡t thÃ¬ ra trÆ°á»ng cÃ³ cÆ¡ há»™i tÃ¬m kiáº¿m viá»‡c lÃ m tá»‘t khÃ´ng áº¡?,,,,,"#Q&A, #nlp, #python"
"Báº¥t ká»ƒ ai lÃ  ngÆ°á»i chiáº¿n tháº¯ng trong cuá»™c Ä‘ua AI, thÃ¬ Ä‘Ã¢y lÃ  cÃ´ng ty váº«n ung dung hÆ°á»Ÿng lá»£i! CÃ´ng ty náº¯m giá»¯ vÅ© khÃ­ tá»‘i thÆ°á»£ng cá»§a cÃ´ng nghá»‡ AI.
#A100 #SmartTechnology #FutureTech","Báº¥t ká»ƒ ai lÃ  ngÆ°á»i chiáº¿n tháº¯ng trong cuá»™c Ä‘ua AI, thÃ¬ Ä‘Ã¢y lÃ  cÃ´ng ty váº«n ung dung hÆ°á»Ÿng lá»£i! CÃ´ng ty náº¯m giá»¯ vÅ© khÃ­ tá»‘i thÆ°á»£ng cá»§a cÃ´ng nghá»‡ AI.",#A100	#SmartTechnology	#FutureTech,,,,#sharing
"Bá»Ÿi nhá»¯ng váº¥n Ä‘á» vá» giá»›i háº¡n báº£n quyá»n cá»§a model LLaMA, mÃ¬nh vÃ  báº¡n Pháº¡m Ngá»c Ninh Ä‘Ã£ sá»­ dá»¥ng model BLOOM khÃ´ng bá»‹ giá»›i háº¡n báº£n quyá»n (bÃ i bÃ¡o táº¡i Ä‘Ã¢yhttps://arxiv.org/abs/2211.05100) Ä‘á»ƒ train models theo hÆ°á»›ng Alpaca-LoRA. VÃ¬ BLOOM Ä‘Æ°á»£c train vá»›i 2,7% dataset lÃ  tiáº¿ng Viá»‡t (tham kháº£o táº¡i Ä‘Ã¢y https://huggingface.co/bigscience/bloom). HÆ¡n ná»¯a, mÃ¬nh cÃ³ tháº¥y Andrej Karpathy khuyÃªn khÃ­ch nÃªn dÃ¹ng BLOOM nhÆ° hÃ¬nh bÃªn dÆ°á»›i. Vá»›i nhá»¯ng lÃ½ do trÃªn, mÃ¬nh vÃ  báº¡n Ninh Ä‘Ã£ train model BLOOM-56M vÃ  BLOOM-7b1 káº¿t há»£p vá»›i LoRA, cÅ©ng nhÆ° sá»­ dá»¥ng dá»¯ liá»‡u Alpaca_data_cleaned.json táº¡i Ä‘Ã¢y (https://github.com/gururise/AlpacaDataCleaned).
ÄÃ¢y lÃ  repository mÃ  mÃ¬nh vÃ  báº¡n Ninh Ä‘Ã£ reimplemnt https://github.com/linhduongtuan/BLOOM-LORA.
Hi vá»ng cuá»‘i tuáº§n cÃ³ thá»© Ä‘á»ƒ mua vui vá»›i má»i ngÆ°á»i.
 â€” vá»›i Pháº¡m Ngá»c Ninh.","Bá»Ÿi nhá»¯ng váº¥n Ä‘á» vá» giá»›i háº¡n báº£n quyá»n cá»§a model LLaMA, mÃ¬nh vÃ  báº¡n Pháº¡m Ngá»c Ninh Ä‘Ã£ sá»­ dá»¥ng model BLOOM khÃ´ng bá»‹ giá»›i háº¡n báº£n quyá»n (bÃ i bÃ¡o táº¡i Ä‘Ã¢yhttps://arxiv.org/abs/2211.05100) Ä‘á»ƒ train models theo hÆ°á»›ng Alpaca-LoRA. VÃ¬ BLOOM Ä‘Æ°á»£c train vá»›i 2,7% dataset lÃ  tiáº¿ng Viá»‡t (tham kháº£o táº¡i Ä‘Ã¢y https://huggingface.co/bigscience/bloom). HÆ¡n ná»¯a, mÃ¬nh cÃ³ tháº¥y Andrej Karpathy khuyÃªn khÃ­ch nÃªn dÃ¹ng BLOOM nhÆ° hÃ¬nh bÃªn dÆ°á»›i. Vá»›i nhá»¯ng lÃ½ do trÃªn, mÃ¬nh vÃ  báº¡n Ninh Ä‘Ã£ train model BLOOM-56M vÃ  BLOOM-7b1 káº¿t há»£p vá»›i LoRA, cÅ©ng nhÆ° sá»­ dá»¥ng dá»¯ liá»‡u Alpaca_data_cleaned.json táº¡i Ä‘Ã¢y (https://github.com/gururise/AlpacaDataCleaned). ÄÃ¢y lÃ  repository mÃ  mÃ¬nh vÃ  báº¡n Ninh Ä‘Ã£ reimplemnt https://github.com/linhduongtuan/BLOOM-LORA. Hi vá»ng cuá»‘i tuáº§n cÃ³ thá»© Ä‘á»ƒ mua vui vá»›i má»i ngÆ°á»i. â€” vá»›i Pháº¡m Ngá»c Ninh.",,,,,"#sharing, #deep_learning"
"ChÃ o cÃ¡c báº¡n.
MÃ¬nh vá»«a hoÃ n thÃ nh cÃ¡c jupyter notebook sá»­ dá»¥ng pandas vÃ  sqlalchemy Ä‘á»ƒ mÃ´ phá»ng MySQL code, hy vá»ng sáº½ giÃºp Ã­ch Ä‘Æ°á»£c ai Ä‘Ã³.
Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m áº¡.","ChÃ o cÃ¡c báº¡n. MÃ¬nh vá»«a hoÃ n thÃ nh cÃ¡c jupyter notebook sá»­ dá»¥ng pandas vÃ  sqlalchemy Ä‘á»ƒ mÃ´ phá»ng MySQL code, hy vá»ng sáº½ giÃºp Ã­ch Ä‘Æ°á»£c ai Ä‘Ã³. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m áº¡.",,,,,#sharing
"Xin chÃ o anh em, nhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» Data Visualize nÃªn chia sáº» cÃ¹ng anh em má»™t cÃ´ng cá»¥ nhá». Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c!","Xin chÃ o anh em, nhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» Data Visualize nÃªn chia sáº» cÃ¹ng anh em má»™t cÃ´ng cá»¥ nhá». Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c!",,,,,"#sharing, #data"
Má»i ngÆ°á»i Ä‘á»u biáº¿t vá» sá»©c máº¡nh vÆ°á»£t trá»™i cá»§a GPT-4 trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. Nay Microsft mang sá»©c máº¡nh cá»§a GPT-4 lÃªn Github vá»›i cÃ´ng cá»¥ GitHub Copilot X. Vá»›i lÆ°á»£ng dá»¯ liá»‡u (code) khá»•ng lá»“ trÃªn Github thÃ¬ AI sáº½ há»— trá»£ ráº¥t nhiá»u cho láº­p trÃ¬nh viÃªn trong nhiá»u cÃ´ng viá»‡c khÃ¡c nhau.,Má»i ngÆ°á»i Ä‘á»u biáº¿t vá» sá»©c máº¡nh vÆ°á»£t trá»™i cá»§a GPT-4 trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. Nay Microsft mang sá»©c máº¡nh cá»§a GPT-4 lÃªn Github vá»›i cÃ´ng cá»¥ GitHub Copilot X. Vá»›i lÆ°á»£ng dá»¯ liá»‡u (code) khá»•ng lá»“ trÃªn Github thÃ¬ AI sáº½ há»— trá»£ ráº¥t nhiá»u cho láº­p trÃ¬nh viÃªn trong nhiá»u cÃ´ng viá»‡c khÃ¡c nhau.,,,,,"#sharing, #nlp"
"Sau tiáº¿ng vang lá»›n cá»§a ChatGPT, mÃ¬nh tháº¥y cÃ³ ngÆ°á»i reimplement láº¡i mÃ´ hÃ¬nh nÃ y dÆ°á»›i cÃ¡i tÃªn minChatGPT (sá»­ dá»¥ng kiáº¿n trÃºc GPT-2) táº¡i Ä‘Ã¢y https://github.com/ethanyanjiali/minChatGPT. CÃ³ láº½ Ä‘Ã¢y lÃ  phong cÃ¡ch Ä‘Æ°á»£c Ä‘á»‹nh hÃ¬nh bá»Ÿi Andrej Karpathy, khi Andrej reimplemt mÃ´ hÃ¬nh GPT-2 vá»›i 2 repos lÃ  minGPT vÃ  nanoGPT.
CÃ³ báº¡n nÃ o thÃ­ch thÃº vá»›i Ã½ tÆ°á»Ÿng nÃ y, mÃ¬nh nghÄ© hoÃ n toÃ n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc khÃ¡c nhÆ° LLaMA, BLOOM, GPT-NEOX,...","Sau tiáº¿ng vang lá»›n cá»§a ChatGPT, mÃ¬nh tháº¥y cÃ³ ngÆ°á»i reimplement láº¡i mÃ´ hÃ¬nh nÃ y dÆ°á»›i cÃ¡i tÃªn minChatGPT (sá»­ dá»¥ng kiáº¿n trÃºc GPT-2) táº¡i Ä‘Ã¢y https://github.com/ethanyanjiali/minChatGPT. CÃ³ láº½ Ä‘Ã¢y lÃ  phong cÃ¡ch Ä‘Æ°á»£c Ä‘á»‹nh hÃ¬nh bá»Ÿi Andrej Karpathy, khi Andrej reimplemt mÃ´ hÃ¬nh GPT-2 vá»›i 2 repos lÃ  minGPT vÃ  nanoGPT. CÃ³ báº¡n nÃ o thÃ­ch thÃº vá»›i Ã½ tÆ°á»Ÿng nÃ y, mÃ¬nh nghÄ© hoÃ n toÃ n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc khÃ¡c nhÆ° LLaMA, BLOOM, GPT-NEOX,...",,,,,"#sharing, #deep_learning"
"Nay mÃ¬nh giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t cÃ´ng cá»¥ há»— trá»£ viáº¿t code cÃ²n thÃ´ng minh hÆ¡n Copilot.
Cursor lÃ  má»™t pháº§n má»m Ä‘á»ƒ láº­p trÃ¬nh (IDE) vá»›i sá»± há»— trá»£ AI. Hiá»‡n táº¡i má»™t sá»‘ tÃ­nh nÄƒng mÃ  Cursor há»— trá»£: - Write: Sinh code vá»›i AI, thÃ´ng minh hÆ¡n Copilot - Diff: YÃªu cáº§u AI sá»­a vÃ  cáº£i tiáº¿n Ä‘oáº¡n code - Chat: Dáº¡ng ChatGPT nhÆ°ng hiá»ƒu ngá»¯ cáº£nh cá»§a file, project NgoÃ i ra cÃ³ cÃ¡c tÃ­nh nÄƒng nhÆ°: tá»± Ä‘á»™ng sinh ra comment, test case, xÃ¡c Ä‘á»‹nh vÃ¹ng code cÃ³ kháº£ nÄƒng bá»‹ lá»—i, vÃ  sá»­a luÃ´n...","Nay mÃ¬nh giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t cÃ´ng cá»¥ há»— trá»£ viáº¿t code cÃ²n thÃ´ng minh hÆ¡n Copilot. Cursor lÃ  má»™t pháº§n má»m Ä‘á»ƒ láº­p trÃ¬nh (IDE) vá»›i sá»± há»— trá»£ AI. Hiá»‡n táº¡i má»™t sá»‘ tÃ­nh nÄƒng mÃ  Cursor há»— trá»£: - Write: Sinh code vá»›i AI, thÃ´ng minh hÆ¡n Copilot - Diff: YÃªu cáº§u AI sá»­a vÃ  cáº£i tiáº¿n Ä‘oáº¡n code - Chat: Dáº¡ng ChatGPT nhÆ°ng hiá»ƒu ngá»¯ cáº£nh cá»§a file, project NgoÃ i ra cÃ³ cÃ¡c tÃ­nh nÄƒng nhÆ°: tá»± Ä‘á»™ng sinh ra comment, test case, xÃ¡c Ä‘á»‹nh vÃ¹ng code cÃ³ kháº£ nÄƒng bá»‹ lá»—i, vÃ  sá»­a luÃ´n...",,,,,#sharing
"Em chÃ o anh chá»‹ áº¡, em muá»‘n xin review tá»« cÃ¡c anh chá»‹ Ä‘Ã£ theo há»c chÆ°Æ¡ng trÃ¬nh Khoa há»c dá»¯ liá»‡u cá»§a Ä‘áº¡i há»c khoa há»c tá»± nhiÃªn hÃ  ná»™i. VÃ¬ lÃ½ do tÃ i chÃ­nh vÃ  gia Ä‘Ã¬nh nÃªn em quyáº¿t Ä‘á»‹nh theo há»c tháº¡c sÄ© á»Ÿ HÃ  Ná»™i thay vÃ¬ Ä‘i du há»c. CÃ¡c anh chá»‹ tháº¥y chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o vÃ  cháº¥t lÆ°á»£ng giáº£ng dáº¡y tháº¡c sÄ© cá»§a trÆ°á»ng tháº¿ nÃ o áº¡?
Em cáº£m Æ¡n anh chá»‹ nhiá»u áº¡","Em chÃ o anh chá»‹ áº¡, em muá»‘n xin review tá»« cÃ¡c anh chá»‹ Ä‘Ã£ theo há»c chÆ°Æ¡ng trÃ¬nh Khoa há»c dá»¯ liá»‡u cá»§a Ä‘áº¡i há»c khoa há»c tá»± nhiÃªn hÃ  ná»™i. VÃ¬ lÃ½ do tÃ i chÃ­nh vÃ  gia Ä‘Ã¬nh nÃªn em quyáº¿t Ä‘á»‹nh theo há»c tháº¡c sÄ© á»Ÿ HÃ  Ná»™i thay vÃ¬ Ä‘i du há»c. CÃ¡c anh chá»‹ tháº¥y chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o vÃ  cháº¥t lÆ°á»£ng giáº£ng dáº¡y tháº¡c sÄ© cá»§a trÆ°á»ng tháº¿ nÃ o áº¡? Em cáº£m Æ¡n anh chá»‹ nhiá»u áº¡",,,,,#Q&A
"Vá»«a rá»“i mÃ¬nh cÃ³ tham gia challenge Player Contact Detection á»Ÿ kaggle vÃ  may máº¯n Ä‘Æ°á»£c top1. MÃ¬nh xin chia sáº½ code vÃ  solution hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n má»›i.
Challenge page: https://www.kaggle.com/competitions/nfl-player-contact-detection/leaderboard
Solution: shorturl.at/kJNW0
Source code: https://github.com/nvnnghia/nfl3_1st",Vá»«a rá»“i mÃ¬nh cÃ³ tham gia challenge Player Contact Detection á»Ÿ kaggle vÃ  may máº¯n Ä‘Æ°á»£c top1. MÃ¬nh xin chia sáº½ code vÃ  solution hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n má»›i. Challenge page: https://www.kaggle.com/competitions/nfl-player-contact-detection/leaderboard Solution: shorturl.at/kJNW0 Source code: https://github.com/nvnnghia/nfl3_1st,,,,,#sharing
"Chá»‰ trong vÃ i nÄƒm qua, tÃ¡c Ä‘á»™ng cá»§a Microsoft trong viá»‡c thÃºc Ä‘áº©y lÄ©nh vá»±c AI lÃ  ráº¥t áº¥n tÆ°á»£ng. Microsoft Ä‘ang hoÃ n toÃ n thá»‘ng trá»‹, cháº¡y nhanh hÆ¡n vÃ  bá» xa cÃ¡c Ä‘á»‘i thá»§ khÃ¡c ğŸ˜³","Chá»‰ trong vÃ i nÄƒm qua, tÃ¡c Ä‘á»™ng cá»§a Microsoft trong viá»‡c thÃºc Ä‘áº©y lÄ©nh vá»±c AI lÃ  ráº¥t áº¥n tÆ°á»£ng. Microsoft Ä‘ang hoÃ n toÃ n thá»‘ng trá»‹, cháº¡y nhanh hÆ¡n vÃ  bá» xa cÃ¡c Ä‘á»‘i thá»§ khÃ¡c",,,,,bá»
"#chatbot
Em chÃ o má»i ngÆ°á»i áº¡,
Hiá»‡n táº¡i em Ä‘ang pháº£i build chatbot cho 1 cÃ´ng ty vá» tÆ° váº¥n tÃ¢m lÃ½, ngÆ°á»i ta muá»‘n chatbot cÃ³ thá»ƒ Ä‘áº·t nhiá»u cÃ¢u há»i kiá»ƒu open-question cho ngÆ°á»i dÃ¹ng Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c váº¥n Ä‘á» tÃ¢m lÃ½ cá»§a ngÆ°á»i dÃ¹ng.
Em Ä‘Ã£ thá»­ ParlAI vÃ  dÃ¹ng Empathetic Dialogues, thÃ¬ model khÃ¡ tá»‘t, thá»ƒ hiá»‡n Ä‘Æ°á»£c sá»± Ä‘á»“ng cáº£m vá»›i ngÆ°á»i dÃ¹ng nhÆ°ng chÆ°a Ä‘áº·t thÃªm Ä‘Æ°á»£c cÃ¢u há»i cho ngÆ°á»i dÃ¹ng. ÄÃ¢y lÃ  github link áº¡ https://github.com/facebookresearch/ParlAI
Em Ä‘Ã£ thá»­ thÃªm dataset vÃ  train láº¡i model dá»±a trÃªn trained model, em cÃ³ Ä‘á»ƒ --gpu 1 nhÆ°ng lÃºc á»Ÿ task manager thÃ¬ em láº¡i tháº¥y GPU khÃ´ng hoáº¡t Ä‘á»™ng gÃ¬, cÃ²n CPU vÃ  memnory thÃ¬ táº§m 90% - 100% luÃ´n. NÃªn em chÆ°a thÃ nh cÃ´ng train láº¡i model khi dÃ¹ng ParlAI áº¡.
Em sá»£ build model tá»« Ä‘áº§u, khÃ´ng dÃ¹ng pretrained model thÃ¬ káº¿t quáº£ chÆ°a cháº¯c Ä‘Ã£ báº±ng pretrained model. NÃªn em khÃ´ng biáº¿t lÃ m tháº¿ nÃ o.
https://dl.acm.org/doi/abs/10.1145/3313831.3376131
HÆ°á»›ng em muá»‘n build chatbot lÃ  nhÆ° bÃ i bÃ¡o nÃ y áº¡. NhÆ°ng mÃ  em khÃ´ng tÃ¬m tháº¥y code cá»§a bÃ i bÃ¡o nÃ y, nÃªn em cÅ©ng khÃ´ng biáº¿t lÃ m nhÆ° nÃ o.
Má»i ngÆ°á»i cÃ³ thá»ƒ tÆ° váº«n giÃºp em, em nÃªn lÃ m gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i áº¡. ğŸ˜„ğŸ™","Em chÃ o má»i ngÆ°á»i áº¡, Hiá»‡n táº¡i em Ä‘ang pháº£i build chatbot cho 1 cÃ´ng ty vá» tÆ° váº¥n tÃ¢m lÃ½, ngÆ°á»i ta muá»‘n chatbot cÃ³ thá»ƒ Ä‘áº·t nhiá»u cÃ¢u há»i kiá»ƒu open-question cho ngÆ°á»i dÃ¹ng Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c váº¥n Ä‘á» tÃ¢m lÃ½ cá»§a ngÆ°á»i dÃ¹ng. Em Ä‘Ã£ thá»­ ParlAI vÃ  dÃ¹ng Empathetic Dialogues, thÃ¬ model khÃ¡ tá»‘t, thá»ƒ hiá»‡n Ä‘Æ°á»£c sá»± Ä‘á»“ng cáº£m vá»›i ngÆ°á»i dÃ¹ng nhÆ°ng chÆ°a Ä‘áº·t thÃªm Ä‘Æ°á»£c cÃ¢u há»i cho ngÆ°á»i dÃ¹ng. ÄÃ¢y lÃ  github link áº¡ https://github.com/facebookresearch/ParlAI Em Ä‘Ã£ thá»­ thÃªm dataset vÃ  train láº¡i model dá»±a trÃªn trained model, em cÃ³ Ä‘á»ƒ --gpu 1 nhÆ°ng lÃºc á»Ÿ task manager thÃ¬ em láº¡i tháº¥y GPU khÃ´ng hoáº¡t Ä‘á»™ng gÃ¬, cÃ²n CPU vÃ  memnory thÃ¬ táº§m 90% - 100% luÃ´n. NÃªn em chÆ°a thÃ nh cÃ´ng train láº¡i model khi dÃ¹ng ParlAI áº¡. Em sá»£ build model tá»« Ä‘áº§u, khÃ´ng dÃ¹ng pretrained model thÃ¬ káº¿t quáº£ chÆ°a cháº¯c Ä‘Ã£ báº±ng pretrained model. NÃªn em khÃ´ng biáº¿t lÃ m tháº¿ nÃ o. https://dl.acm.org/doi/abs/10.1145/3313831.3376131 HÆ°á»›ng em muá»‘n build chatbot lÃ  nhÆ° bÃ i bÃ¡o nÃ y áº¡. NhÆ°ng mÃ  em khÃ´ng tÃ¬m tháº¥y code cá»§a bÃ i bÃ¡o nÃ y, nÃªn em cÅ©ng khÃ´ng biáº¿t lÃ m nhÆ° nÃ o. Má»i ngÆ°á»i cÃ³ thá»ƒ tÆ° váº«n giÃºp em, em nÃªn lÃ m gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.",#chatbot,,,,"#sharing, #Q&A, #nlp"
"ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n em Ä‘ang cÃ³ má»™t project nho nhá», em Ä‘ang imple model SSD Ä‘á»ƒ test vá»›i dataset lÃ  VOC sau Ä‘Ã³ náº¿u Ä‘Æ°á»£c káº¿t quáº£ tá»‘t thÃ¬ chá»‰nh sá»­a láº¡i kiáº¿n trÃºc má»™t tÃ­ vÃ  thá»­ trÃªn má»™t dataset cá»§a riÃªng em. Tuy nhiÃªn em khÃ´ng cÃ³ chá»— train, mÃ¡y em khÃ´ng Ä‘á»§ vram, cÃ²n colab pro em cÃ³ nghe nÃ³i lÃ  chá»‰ ná»›i rá»™ng thá»i gian train thÃ´i chá»© random ra gpu cÅ©ng khÃ´ng ngon láº¯m. MÃ  báº£n pro plus thÃ¬ em Ä‘ang lÃ  sv nÃªn khÃ´ng Ä‘á»§ Ä‘iá»u kiá»‡n mua. Váº­y náº¿u em muá»‘n train SSD thÃ¬ cÃ³ giáº£i phÃ¡p nÃ o cho em khÃ´ng áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n em Ä‘ang cÃ³ má»™t project nho nhá», em Ä‘ang imple model SSD Ä‘á»ƒ test vá»›i dataset lÃ  VOC sau Ä‘Ã³ náº¿u Ä‘Æ°á»£c káº¿t quáº£ tá»‘t thÃ¬ chá»‰nh sá»­a láº¡i kiáº¿n trÃºc má»™t tÃ­ vÃ  thá»­ trÃªn má»™t dataset cá»§a riÃªng em. Tuy nhiÃªn em khÃ´ng cÃ³ chá»— train, mÃ¡y em khÃ´ng Ä‘á»§ vram, cÃ²n colab pro em cÃ³ nghe nÃ³i lÃ  chá»‰ ná»›i rá»™ng thá»i gian train thÃ´i chá»© random ra gpu cÅ©ng khÃ´ng ngon láº¯m. MÃ  báº£n pro plus thÃ¬ em Ä‘ang lÃ  sv nÃªn khÃ´ng Ä‘á»§ Ä‘iá»u kiá»‡n mua. Váº­y náº¿u em muá»‘n train SSD thÃ¬ cÃ³ giáº£i phÃ¡p nÃ o cho em khÃ´ng áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,"#Q&A, #deep_learning"
"ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm cuá»‘i ngÃ nh CNTT trÆ°á»ng BK. Táº§m thÃ¡ng 8 nÄƒm nay em sáº½ tá»‘t nghiá»‡p. Em Ä‘ang cÃ³ dá»± Ä‘á»‹nh Ä‘i há»c Master ML/DL á»Ÿ Ãšc.
Background cá»§a em thÃ¬ em cÃ³ GPA tÃ­ch luá»¹ tá»›i kÃ¬ thá»© 7 ~ 3.8, ielts 7.0, cÃ³ ná»n táº£ng vá» thá»‘ng kÃª, xá»­ lÃ­, trá»±c quan hoÃ¡, handle dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng, nÃ³i chung lÃ  em cÃ³ biáº¿t cÆ¡ báº£n vá» khdl, implement cÃ¡c model báº±ng keras vÃ  tf, nhÆ°ng mÃ  linear algebra thÃ¬ hiá»‡n táº¡i em quÃªn háº¿t rá»“i áº¡ táº¡i há»c tá»« nÄƒm 1 ğŸ˜ nhÆ°ng mÃ  em cÃ³ thá»ƒ tá»± há»c láº¡i táº¡i em cÅ©ng thÃ­ch há»c toÃ¡n.
Hiá»‡n táº¡i em hÆ¡i máº¥t Ä‘á»‹nh hÆ°á»›ng, kiá»ƒu cÃ¡c báº¡n cÃ¹ng khoÃ¡ cá»§a em (90% khÃ´ng theo hÆ°á»›ng ML) Ä‘Ã£ Ä‘i lÃ m rá»“i áº¡, nhÆ°ng mÃ  em váº«n chÆ°a Ä‘i vÃ¬ em chÆ°a nháº­n Ä‘Æ°á»£c offer nÃ o phÃ¹ há»£p. Job ML cho level tháº¥p nhÆ° em khÃ¡ Ã­t vÃ  khi ngÆ°á»i ta nghe em nÃ³i em chá»‰ cÃ³ thá»ƒ lÃ m Ä‘áº¿n háº¿t 2023 khÃ´ng thá»ƒ commit vá»›i cÃ´ng ty Ä‘Æ°á»£c ngÆ°á»i ta cÅ©ng khÃ´ng muá»‘n tuyá»ƒn em Ã­ ğŸ˜. Em muá»‘n em há»c Master xong cÃ³ thá»ƒ á»Ÿ Ä‘Ã³ lÃ m cÃ¡c ngÃ nh liÃªn quan Ä‘áº¿n major cá»§a em vÃ i nÄƒm rá»“i má»›i vá» nÆ°á»›c áº¡. NhÆ°ng mÃ  em sá»£ náº¿u em khÃ´ng cÃ³ work experience thÃ¬ khÃ´ng thá»ƒ Ä‘i lÃ m Ä‘Æ°á»£c á»Ÿ Ãšc. Em hi vá»ng mn cÃ³ thá»ƒ cho Ã½ kiáº¿n giÃºp em ráº±ng em nÃªn á»Ÿ Ä‘Ã¢y lÃ m cÃ¡c job liÃªn quan rá»“i má»›i Ä‘i há»c, hay lÃ  tá»‘t nghiá»‡p xong em Ä‘i luÃ´n áº¡? VÃ  khÃ´ng biáº¿t lÃ  á»Ÿ Ãšc thÃ¬ con Ä‘Æ°á»ng cho ML cÃ³ rá»™ng má»Ÿ khÃ´ng áº¡? Em cáº§n chuáº©n bá»‹ nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n nÃ o trÆ°á»›c khi em chÃ­nh thá»©c vÃ o há»c Master ML khÃ´ng áº¡? Em khÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬ vá» tÃ i chÃ­nh, bá»‘ máº¹ em cÃ³ thá»ƒ chu cáº¥p cho em Ä‘i há»c ms liá»n sau khi em tá»‘t nghiá»‡p bk áº¡, chá»‰ lÃ  em tháº¥y cÃ¡c báº¡n Ä‘i lÃ m em Ã¡p lá»±c vÃ  em Ä‘ang hoÃ i nghi vá» chuyá»‡n em muá»‘n theo Ä‘uá»•i ML huhu ğŸ˜ Em mong má»i ngÆ°á»i cho em lá»i khuyÃªn, em cáº£m Æ¡n mnn","ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm cuá»‘i ngÃ nh CNTT trÆ°á»ng BK. Táº§m thÃ¡ng 8 nÄƒm nay em sáº½ tá»‘t nghiá»‡p. Em Ä‘ang cÃ³ dá»± Ä‘á»‹nh Ä‘i há»c Master ML/DL á»Ÿ Ãšc. Background cá»§a em thÃ¬ em cÃ³ GPA tÃ­ch luá»¹ tá»›i kÃ¬ thá»© 7 ~ 3.8, ielts 7.0, cÃ³ ná»n táº£ng vá» thá»‘ng kÃª, xá»­ lÃ­, trá»±c quan hoÃ¡, handle dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng, nÃ³i chung lÃ  em cÃ³ biáº¿t cÆ¡ báº£n vá» khdl, implement cÃ¡c model báº±ng keras vÃ  tf, nhÆ°ng mÃ  linear algebra thÃ¬ hiá»‡n táº¡i em quÃªn háº¿t rá»“i áº¡ táº¡i há»c tá»« nÄƒm 1 nhÆ°ng mÃ  em cÃ³ thá»ƒ tá»± há»c láº¡i táº¡i em cÅ©ng thÃ­ch há»c toÃ¡n. Hiá»‡n táº¡i em hÆ¡i máº¥t Ä‘á»‹nh hÆ°á»›ng, kiá»ƒu cÃ¡c báº¡n cÃ¹ng khoÃ¡ cá»§a em (90% khÃ´ng theo hÆ°á»›ng ML) Ä‘Ã£ Ä‘i lÃ m rá»“i áº¡, nhÆ°ng mÃ  em váº«n chÆ°a Ä‘i vÃ¬ em chÆ°a nháº­n Ä‘Æ°á»£c offer nÃ o phÃ¹ há»£p. Job ML cho level tháº¥p nhÆ° em khÃ¡ Ã­t vÃ  khi ngÆ°á»i ta nghe em nÃ³i em chá»‰ cÃ³ thá»ƒ lÃ m Ä‘áº¿n háº¿t 2023 khÃ´ng thá»ƒ commit vá»›i cÃ´ng ty Ä‘Æ°á»£c ngÆ°á»i ta cÅ©ng khÃ´ng muá»‘n tuyá»ƒn em Ã­ . Em muá»‘n em há»c Master xong cÃ³ thá»ƒ á»Ÿ Ä‘Ã³ lÃ m cÃ¡c ngÃ nh liÃªn quan Ä‘áº¿n major cá»§a em vÃ i nÄƒm rá»“i má»›i vá» nÆ°á»›c áº¡. NhÆ°ng mÃ  em sá»£ náº¿u em khÃ´ng cÃ³ work experience thÃ¬ khÃ´ng thá»ƒ Ä‘i lÃ m Ä‘Æ°á»£c á»Ÿ Ãšc. Em hi vá»ng mn cÃ³ thá»ƒ cho Ã½ kiáº¿n giÃºp em ráº±ng em nÃªn á»Ÿ Ä‘Ã¢y lÃ m cÃ¡c job liÃªn quan rá»“i má»›i Ä‘i há»c, hay lÃ  tá»‘t nghiá»‡p xong em Ä‘i luÃ´n áº¡? VÃ  khÃ´ng biáº¿t lÃ  á»Ÿ Ãšc thÃ¬ con Ä‘Æ°á»ng cho ML cÃ³ rá»™ng má»Ÿ khÃ´ng áº¡? Em cáº§n chuáº©n bá»‹ nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n nÃ o trÆ°á»›c khi em chÃ­nh thá»©c vÃ o há»c Master ML khÃ´ng áº¡? Em khÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬ vá» tÃ i chÃ­nh, bá»‘ máº¹ em cÃ³ thá»ƒ chu cáº¥p cho em Ä‘i há»c ms liá»n sau khi em tá»‘t nghiá»‡p bk áº¡, chá»‰ lÃ  em tháº¥y cÃ¡c báº¡n Ä‘i lÃ m em Ã¡p lá»±c vÃ  em Ä‘ang hoÃ i nghi vá» chuyá»‡n em muá»‘n theo Ä‘uá»•i ML huhu Em mong má»i ngÆ°á»i cho em lá»i khuyÃªn, em cáº£m Æ¡n mnn",,,,,#Q&A
"#imageclassification
Hi má»i ngÆ°á»i, hiá»‡n giá» e Ä‘ang muá»‘n build má»™t image classifcation model cÃ³ thá»ƒ phÃ¢n loáº¡i flowers and leaf. Vá» pháº§n training, e Ä‘ang train trÃªn dataset táº§m 10GB áº£nh, 124 training classes. Giá» váº¥n Ä‘á» e gáº·p pháº£i lÃ  náº¿u mÃ  trong test images mÃ  cÃ³ images mÃ  ko thuá»™c training class nÃ o, thÃ¬ lÃ m tháº¿ nÃ o model cá»§a e cÃ³ thá»ƒ detect Ä‘Æ°á»£c lÃ  cÃ¡i images Ä‘áº¥y ko thuá»™c training class nÃ o. E Ä‘á»‹nh dÃ¹ng neural network vá»›i output layer cÃ³ sigmoid activation function. Náº¿u mÃ  sigmoid score cho tá»«ng class < 0.5, thÃ¬ e sáº½ classify táº¥m images Ä‘áº¥y ko thuá»™c training class nÃ o. Liá»‡u ráº±ng approach cá»§a e cÃ³ kháº£ dÄ© ko hay má»i ng cÃ³ approach nÃ o khÃ¡c?","Hi má»i ngÆ°á»i, hiá»‡n giá» e Ä‘ang muá»‘n build má»™t image classifcation model cÃ³ thá»ƒ phÃ¢n loáº¡i flowers and leaf. Vá» pháº§n training, e Ä‘ang train trÃªn dataset táº§m 10GB áº£nh, 124 training classes. Giá» váº¥n Ä‘á» e gáº·p pháº£i lÃ  náº¿u mÃ  trong test images mÃ  cÃ³ images mÃ  ko thuá»™c training class nÃ o, thÃ¬ lÃ m tháº¿ nÃ o model cá»§a e cÃ³ thá»ƒ detect Ä‘Æ°á»£c lÃ  cÃ¡i images Ä‘áº¥y ko thuá»™c training class nÃ o. E Ä‘á»‹nh dÃ¹ng neural network vá»›i output layer cÃ³ sigmoid activation function. Náº¿u mÃ  sigmoid score cho tá»«ng class < 0.5, thÃ¬ e sáº½ classify táº¥m images Ä‘áº¥y ko thuá»™c training class nÃ o. Liá»‡u ráº±ng approach cá»§a e cÃ³ kháº£ dÄ© ko hay má»i ng cÃ³ approach nÃ o khÃ¡c?",#imageclassification,,,,"#Q&A, #cv, #deep_learning"
"***** Äiá»ƒm tin vá» LLaMA (https://arxiv.org/abs/2302.13971; https://github.com/facebookresearch/llama) vÃ  cÃ¡c biáº¿n thá»ƒ cÅ©ng nhÆ° giáº£i phÃ¡p kÄ© thuáº­t cáº£i tiáº¿n LLaMA *****
NhÆ° chÃºng ta Ä‘Ã£ biáº¿n sá»©c nÃ³ng cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models ~ LLM) lá»›n tá»›i má»©c nhÆ° tháº¿ nÃ o, Ä‘áº·c biá»‡t lÃ  ChatGPT vÃ  GPT-4 do OpenAI táº¡o ra. Tuy nhiÃªn, ráº¥t tiáº¿c OpenAI nhÆ°ng láº¡i khÃ´ng Open, nhÆ°ng FacebookResearch (FAIR) Ä‘Æ°á»£c lÃ£nh Ä‘áº¡o bá»Ÿi bÃ¡c Yan LeCun chá»§ trÆ°Æ¡ng Open (source code vÃ  data). CÃ³ láº§n mÃ¬nh nghe bÃ¡c LeCun nÃ³i, kiáº¿n trÃºc Convolutional Neural Network (CNN) Ä‘Æ°á»£c bÃ¡c áº¥y phÃ¡t minh tá»« nÄƒm 1988-89, nhÆ°ng vÃ¬ nhiá»u lÃ½ vá» báº£n quyá»n (nÆ¡i bÃ¡c áº¥y tá»«ng lÃ m viá»‡c, vÃ­ dá»¥ Bell Labs) nÃªn AI bá»‹ rÆ¡i vÃ o ""ngá»§ Ä‘Ã´ng"". RÃºt kinh nghiá»‡m tá»« Ä‘Ã³, bÃ¡c LeCun chá»§ trÆ°Æ¡ng Open Science (cÃ¡c báº¡n cÃ³ thá»ƒ sáº½ gáº·p thuáº­t ngá»¯ nÃ y ngÃ y má»™t nhiá»u hÆ¡n, vÃ­ dá»¥ OPEN: source code, data, access, review,...) giÃºp khoa há»c dissemination and exploitation nhanh vÃ  tá»‘t hÆ¡n.
Quay láº¡i LLaMA má»Ÿ mÃ£ nguá»“n vÃ  trained weights ta sáº½ tháº¥y Ä‘iá»u trÃªn Ä‘Ãºng vá»›i nhá»¯ng cáº£i tiáº¿n mÃ  tÃ´i Ä‘Æ°á»£c biáº¿t cho tá»›i nay (9AM GMT+7, ngÃ y 18/3/2023):
1/ NhÃ³m nghiÃªn cá»©u á»Ÿ Äáº¡i Há»c Stanford Ä‘Ã£ sá»­ dá»¥ng kÄ© thuáº­t mÃ  há» cÃ´ng bá»‘ trÆ°á»›c Ä‘Ã³ lÃ  Self-Instruction (https://arxiv.org/abs/2212.10560) Ä‘á»ƒ cáº£i tiáº¿n hiá»‡u nÄƒng mÃ´ hÃ¬nh vÃ  Ä‘áº·t tÃªn biáº¿n thá»ƒ lÃ  Alpaca. Source code táº¡i Ä‘Ã¢y: https://github.com/tatsu-lab/stanford_alpaca; á»©ng dung Demo giá»‘ng nhÆ° ChatGPT táº¡i Ä‘Ã¢y: https://alpaca-ai-custom4.ngrok.io/ (táº¡m thá»i Ä‘ang ngá»«ng hoáº¡t Ä‘á»™ng Ä‘á»ƒ nÃ¢ng cáº¥p)
2/ Tiáº¿p thu kinh nghiá»‡m cá»§a nhÃ³m Tastu á»Ÿ ÄH Stanford, Eric J. Wang Ä‘Ã£ sá»­ dá»¥ng ká»¹ thuáº­t Low-Rank LLaMA Instruct-Tuning (https://arxiv.org/pdf/2106.09685.pdf) Ä‘á»ƒ finetune LLaMA vÃ  Ä‘áº·t tÃªn lÃ  LLaMA-lora (source code táº¡i Ä‘Ã¢y: https://github.com/tloen/alpaca-lora). HÆ¡n ná»¯a, LLaMA-lora cÃ³ thá»ƒ train model vá»›i precision=8-bit sá»­ dá»¥ng thÆ° viá»‡n bitsandbytes mÃ  chá»‰ cáº§n 1 GPU nhÆ° RTX 4090. MÃ¬nh Ä‘ang chá» xem cÃ³ ai sá»­ dá»¥ng accelerate Ä‘á»ƒ train model vá»›i precision=8-bit (fp8=True)???
3/ Tiáº¿p theo váº¥n Ä‘á» liÃªn quan tá»›i quantization Ä‘á»ƒ giáº£m bá»™ nhá»›, cáº¥u hÃ¬nh mÃ¡y tÃ­nh, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y https://github.com/qwopqwop200/GPTQ-for-LLaMa (paper: https://arxiv.org/abs/2302.13971 vÃ  original code táº¡i Ä‘Ã¢y: https://github.com/IST-DASLab/gptq)
4/ Káº¿t há»£p giá»¯a quantization, chuyá»ƒn trained weighted cá»§a LLaMA sang C/C++ vÃ  deploy lÃªn edged device cÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi GitHub nÃ y: https://github.com/ggerganov/llama.cpp. TÆ°Æ¡ng tá»±, vá»›i trained weighted cá»§a Alpaca xuá»‘ng 4-bit vÃ  C/C++ táº¡i Ä‘Ã¢y https://github.com/antimatter15/alpaca.cpp
5/ Last but not least, mÃ¬nh tháº¥y cÃ³ 1 nhÃ³m á»Ÿ Bá»“ ÄÃ o Nha, sá»­ dá»¥ng ChatGPT Ä‘á»ƒ dá»‹ch dá»¯ liá»‡u alpaca_data.json dÃ¹ng trong Alpaca (má»¥c 1/) sang tiáº¿ng Bá»“ rá»“i train mÃ´ hÃ¬nh giá»‘ng vá»›i LLaMA-lora (má»¥c 2/) táº¡i Ä‘Ã¢y: https://github.com/22-hours/cabrita. Báº¡n nÃ o cÃ³ nhÃ£ há»©ng vá»›i tiáº¿ng Viá»‡t, theo mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng Ã½ tÆ°á»›ng cá»§a nhÃ³m Bá»“ ÄÃ o Nha nÃ y. HÃ³ng cÃ¡c báº¡n reimplementation source code nÃ y. LÆ°u Ã½ 1 chÃºt, Eric J. Wang cÃ³ phÃ n nÃ y vá» cháº¥t lÆ°á»£ng cá»§a dataset dÃ¹ng Ä‘á»ƒ finetune Alpaca, nÃªn cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm dataset nÃ y alpaca_data_cleaned.json táº¡i Ä‘Ã¢y (https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_cleaned.json).
...
n/ vÃ  cháº¯c cháº¯n sáº½ cÃ²n ráº¥t nhiá»u Ã½ tÆ°á»Ÿng thÃº vá»‹ liÃªn quan tá»›i chá»§ Ä‘á» nÃ y sáº½ Ä‘Æ°á»£c giá»›i thiá»‡u trong thá»i gian ngáº¯n tá»›i","***** Äiá»ƒm tin vá» LLaMA (https://arxiv.org/abs/2302.13971; https://github.com/facebookresearch/llama) vÃ  cÃ¡c biáº¿n thá»ƒ cÅ©ng nhÆ° giáº£i phÃ¡p kÄ© thuáº­t cáº£i tiáº¿n LLaMA ***** NhÆ° chÃºng ta Ä‘Ã£ biáº¿n sá»©c nÃ³ng cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models ~ LLM) lá»›n tá»›i má»©c nhÆ° tháº¿ nÃ o, Ä‘áº·c biá»‡t lÃ  ChatGPT vÃ  GPT-4 do OpenAI táº¡o ra. Tuy nhiÃªn, ráº¥t tiáº¿c OpenAI nhÆ°ng láº¡i khÃ´ng Open, nhÆ°ng FacebookResearch (FAIR) Ä‘Æ°á»£c lÃ£nh Ä‘áº¡o bá»Ÿi bÃ¡c Yan LeCun chá»§ trÆ°Æ¡ng Open (source code vÃ  data). CÃ³ láº§n mÃ¬nh nghe bÃ¡c LeCun nÃ³i, kiáº¿n trÃºc Convolutional Neural Network (CNN) Ä‘Æ°á»£c bÃ¡c áº¥y phÃ¡t minh tá»« nÄƒm 1988-89, nhÆ°ng vÃ¬ nhiá»u lÃ½ vá» báº£n quyá»n (nÆ¡i bÃ¡c áº¥y tá»«ng lÃ m viá»‡c, vÃ­ dá»¥ Bell Labs) nÃªn AI bá»‹ rÆ¡i vÃ o ""ngá»§ Ä‘Ã´ng"". RÃºt kinh nghiá»‡m tá»« Ä‘Ã³, bÃ¡c LeCun chá»§ trÆ°Æ¡ng Open Science (cÃ¡c báº¡n cÃ³ thá»ƒ sáº½ gáº·p thuáº­t ngá»¯ nÃ y ngÃ y má»™t nhiá»u hÆ¡n, vÃ­ dá»¥ OPEN: source code, data, access, review,...) giÃºp khoa há»c dissemination and exploitation nhanh vÃ  tá»‘t hÆ¡n. Quay láº¡i LLaMA má»Ÿ mÃ£ nguá»“n vÃ  trained weights ta sáº½ tháº¥y Ä‘iá»u trÃªn Ä‘Ãºng vá»›i nhá»¯ng cáº£i tiáº¿n mÃ  tÃ´i Ä‘Æ°á»£c biáº¿t cho tá»›i nay (9AM GMT+7, ngÃ y 18/3/2023): 1/ NhÃ³m nghiÃªn cá»©u á»Ÿ Äáº¡i Há»c Stanford Ä‘Ã£ sá»­ dá»¥ng kÄ© thuáº­t mÃ  há» cÃ´ng bá»‘ trÆ°á»›c Ä‘Ã³ lÃ  Self-Instruction (https://arxiv.org/abs/2212.10560) Ä‘á»ƒ cáº£i tiáº¿n hiá»‡u nÄƒng mÃ´ hÃ¬nh vÃ  Ä‘áº·t tÃªn biáº¿n thá»ƒ lÃ  Alpaca. Source code táº¡i Ä‘Ã¢y: https://github.com/tatsu-lab/stanford_alpaca; á»©ng dung Demo giá»‘ng nhÆ° ChatGPT táº¡i Ä‘Ã¢y: https://alpaca-ai-custom4.ngrok.io/ (táº¡m thá»i Ä‘ang ngá»«ng hoáº¡t Ä‘á»™ng Ä‘á»ƒ nÃ¢ng cáº¥p) 2/ Tiáº¿p thu kinh nghiá»‡m cá»§a nhÃ³m Tastu á»Ÿ ÄH Stanford, Eric J. Wang Ä‘Ã£ sá»­ dá»¥ng ká»¹ thuáº­t Low-Rank LLaMA Instruct-Tuning (https://arxiv.org/pdf/2106.09685.pdf) Ä‘á»ƒ finetune LLaMA vÃ  Ä‘áº·t tÃªn lÃ  LLaMA-lora (source code táº¡i Ä‘Ã¢y: https://github.com/tloen/alpaca-lora). HÆ¡n ná»¯a, LLaMA-lora cÃ³ thá»ƒ train model vá»›i precision=8-bit sá»­ dá»¥ng thÆ° viá»‡n bitsandbytes mÃ  chá»‰ cáº§n 1 GPU nhÆ° RTX 4090. MÃ¬nh Ä‘ang chá» xem cÃ³ ai sá»­ dá»¥ng accelerate Ä‘á»ƒ train model vá»›i precision=8-bit (fp8=True)??? 3/ Tiáº¿p theo váº¥n Ä‘á» liÃªn quan tá»›i quantization Ä‘á»ƒ giáº£m bá»™ nhá»›, cáº¥u hÃ¬nh mÃ¡y tÃ­nh, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y https://github.com/qwopqwop200/GPTQ-for-LLaMa (paper: https://arxiv.org/abs/2302.13971 vÃ  original code táº¡i Ä‘Ã¢y: https://github.com/IST-DASLab/gptq) 4/ Káº¿t há»£p giá»¯a quantization, chuyá»ƒn trained weighted cá»§a LLaMA sang C/C++ vÃ  deploy lÃªn edged device cÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi GitHub nÃ y: https://github.com/ggerganov/llama.cpp. TÆ°Æ¡ng tá»±, vá»›i trained weighted cá»§a Alpaca xuá»‘ng 4-bit vÃ  C/C++ táº¡i Ä‘Ã¢y https://github.com/antimatter15/alpaca.cpp 5/ Last but not least, mÃ¬nh tháº¥y cÃ³ 1 nhÃ³m á»Ÿ Bá»“ ÄÃ o Nha, sá»­ dá»¥ng ChatGPT Ä‘á»ƒ dá»‹ch dá»¯ liá»‡u alpaca_data.json dÃ¹ng trong Alpaca (má»¥c 1/) sang tiáº¿ng Bá»“ rá»“i train mÃ´ hÃ¬nh giá»‘ng vá»›i LLaMA-lora (má»¥c 2/) táº¡i Ä‘Ã¢y: https://github.com/22-hours/cabrita. Báº¡n nÃ o cÃ³ nhÃ£ há»©ng vá»›i tiáº¿ng Viá»‡t, theo mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng Ã½ tÆ°á»›ng cá»§a nhÃ³m Bá»“ ÄÃ o Nha nÃ y. HÃ³ng cÃ¡c báº¡n reimplementation source code nÃ y. LÆ°u Ã½ 1 chÃºt, Eric J. Wang cÃ³ phÃ n nÃ y vá» cháº¥t lÆ°á»£ng cá»§a dataset dÃ¹ng Ä‘á»ƒ finetune Alpaca, nÃªn cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm dataset nÃ y alpaca_data_cleaned.json táº¡i Ä‘Ã¢y (https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_cleaned.json). ... n/ vÃ  cháº¯c cháº¯n sáº½ cÃ²n ráº¥t nhiá»u Ã½ tÆ°á»Ÿng thÃº vá»‹ liÃªn quan tá»›i chá»§ Ä‘á» nÃ y sáº½ Ä‘Æ°á»£c giá»›i thiá»‡u trong thá»i gian ngáº¯n tá»›i",,,,,#sharing
"CÃ³ báº¡n nÃ o trong group nÃ y táº£i Ä‘Æ°á»£c trained weights cá»§a LLaMA (bÃ i bÃ¡o táº¡i Ä‘Ã¢y https://arxiv.org/abs/2302.13971v1) vÃ  link chia sáº» torrent táº¡i Ä‘Ã¢y https://github.com/facebookresearch/llama/pull/73/files, cá»¥ thá»ƒ lÃ  link magnet torrent nÃ y magnet:?xt=urn:btih:ZXXDAUWYLRUXXBHUYEMS6Q5CE5WA3LVA&dn=LLaMA; MÃ¬nh thá»­ thÃ¬ traffic Ä‘á»ƒ download == 0%.
==> Váº­y báº¡n nÃ o Ä‘Ã£ táº£i Ä‘Æ°á»£c trained weights cá»§a LLaMA thÃ¬ cho mÃ¬nh xin vá»›i nhÃ©.
Xin Ä‘a táº¡ trÆ°á»›c vá»›i má»i ngÆ°á»i.","CÃ³ báº¡n nÃ o trong group nÃ y táº£i Ä‘Æ°á»£c trained weights cá»§a LLaMA (bÃ i bÃ¡o táº¡i Ä‘Ã¢y https://arxiv.org/abs/2302.13971v1) vÃ  link chia sáº» torrent táº¡i Ä‘Ã¢y https://github.com/facebookresearch/llama/pull/73/files, cá»¥ thá»ƒ lÃ  link magnet torrent nÃ y magnet:?xt=urn:btih:ZXXDAUWYLRUXXBHUYEMS6Q5CE5WA3LVA&dn=LLaMA; MÃ¬nh thá»­ thÃ¬ traffic Ä‘á»ƒ download == 0%. ==> Váº­y báº¡n nÃ o Ä‘Ã£ táº£i Ä‘Æ°á»£c trained weights cá»§a LLaMA thÃ¬ cho mÃ¬nh xin vá»›i nhÃ©. Xin Ä‘a táº¡ trÆ°á»›c vá»›i má»i ngÆ°á»i.",,,,,"#Q&A, #sharing"
"What's New with OpenAI GPT-4?
#AI #DataScience #MachineLearning #GPT4",What's New with OpenAI GPT-4?,#AI	#DataScience	#MachineLearning	#GPT4,,,,
"MÃ¬nh muá»‘n táº¡o 1 mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sá»‘ lÆ°á»£ng bá»‡nh nhÃ¢n tá»›i khÃ¡m tá»«ng phÃ²ng khÃ¡m. Dá»¯ liá»‡u vá»›i cÃ¡c dÃ²ng lÃ : phÃ²ng khÃ¡m, thá»i gian tá»›i khÃ¡m, thá»i gian khÃ¡m xong, bá»‡nh nhÃ¢n.
Dá»¯ liá»‡u muá»‘n dá»± Ä‘oÃ¡n lÃ . TÃªn phÃ²ng khÃ¡m + khoáº£ng thá»i gian â€”> dá»± Ä‘oÃ¡n sá»‘ lÆ°á»£ng bá»‡nh nhÃ¢n khÃ¡m, bá»‡nh nhÃ¢n
Nhá» cÃ¡c báº¡n tÆ° váº¥n giÃºp mÃ¬nh Ã­t keyword Ä‘á»ƒ cÃ³ hÆ°á»›ng nghiÃªn cá»©u. Xin cáº£m Æ¡n Ä‘Ã£ Ä‘á»c bÃ i.","MÃ¬nh muá»‘n táº¡o 1 mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sá»‘ lÆ°á»£ng bá»‡nh nhÃ¢n tá»›i khÃ¡m tá»«ng phÃ²ng khÃ¡m. Dá»¯ liá»‡u vá»›i cÃ¡c dÃ²ng lÃ : phÃ²ng khÃ¡m, thá»i gian tá»›i khÃ¡m, thá»i gian khÃ¡m xong, bá»‡nh nhÃ¢n. Dá»¯ liá»‡u muá»‘n dá»± Ä‘oÃ¡n lÃ . TÃªn phÃ²ng khÃ¡m + khoáº£ng thá»i gian â€”> dá»± Ä‘oÃ¡n sá»‘ lÆ°á»£ng bá»‡nh nhÃ¢n khÃ¡m, bá»‡nh nhÃ¢n Nhá» cÃ¡c báº¡n tÆ° váº¥n giÃºp mÃ¬nh Ã­t keyword Ä‘á»ƒ cÃ³ hÆ°á»›ng nghiÃªn cá»©u. Xin cáº£m Æ¡n Ä‘Ã£ Ä‘á»c bÃ i.",,,,,"#Q&A, #machine_learning"
ğŸ¯ Google giá»›i thiá»‡u trÃ¬nh tÃ¬m kiáº¿m báº±ng chat giá»‘ng ChatGPT,Google giá»›i thiá»‡u trÃ¬nh tÃ¬m kiáº¿m báº±ng chat giá»‘ng ChatGPT,,,,,#sharing
"ChÃ o cÃ¡c báº¡n. TÃ´i xin chia sáº» bÃ i nÃ³i chuyá»‡n cá»§a tÃ´i vá» AI-for-dev (trÆ°á»›c Táº¿t 1 tuáº§n mÃ  giá» pháº£i cáº­p nháº­t slides ráº¥t nhiá»u rá»“i) hy vá»ng cÃ³ vÃ i thÃ´ng tin há»¯u Ã­ch cho cÃ¡c báº¡n tráº» Ä‘ang lÃ  láº­p trÃ¬nh viÃªn vÃ  muá»‘n tÃ¬m hiá»ƒu phÃ¡t triá»ƒn AI. 

Náº¿u cÃ¡c báº¡n seniors cÃ³ insights & resources gÃ¬ khÃ¡c cÅ©ng xin comment Ä‘á»ƒ tÃ´i cáº­p nháº­t thÃªm nhÃ©. Cheers!

Talk Title: AI4Dev: Landscapes, Toolsets, Roadmaps, Collabs
Slides & video recording: https://gem.cot.ai/p/-9_Wl26kz#/
Abstract:
The field of Artificial Intelligence (AI) is radically changing every aspect of human life, from the way we shop and entertain, lend and earn, to the way we learn and create. There are exponentially many AI ideas, principles, procedures, applications, tools and platforms being developed and shared freely. This on the one hand provides young talents with tremendous opportunities, on the other hand poses new challenges in the development of their knowledge and skills.
Specifically, AI is now widely considered software 2.0. As a dev, you need to be well prepared for whatâ€™s coming next. In this talk I will walk you through comprehensive landscapes of the many exciting topics in AI, introduce wonderful AI-powered dev tools, recommend pragmatic training roadmaps for you to quickly upgrade your AI capabilities, and invite you to collaborate & altogether build a strong community of AI4Dev by joining study groups and contributing to many exciting fullstack production AI projects.

#AI4Dev #AI4VN #Startup","ChÃ o cÃ¡c báº¡n. TÃ´i xin chia sáº» bÃ i nÃ³i chuyá»‡n cá»§a tÃ´i vá» AI-for-dev (trÆ°á»›c Táº¿t 1 tuáº§n mÃ  giá» pháº£i cáº­p nháº­t slides ráº¥t nhiá»u rá»“i) hy vá»ng cÃ³ vÃ i thÃ´ng tin há»¯u Ã­ch cho cÃ¡c báº¡n tráº» Ä‘ang lÃ  láº­p trÃ¬nh viÃªn vÃ  muá»‘n tÃ¬m hiá»ƒu phÃ¡t triá»ƒn AI. Náº¿u cÃ¡c báº¡n seniors cÃ³ insights & resources gÃ¬ khÃ¡c cÅ©ng xin comment Ä‘á»ƒ tÃ´i cáº­p nháº­t thÃªm nhÃ©. Cheers! Talk Title: AI4Dev: Landscapes, Toolsets, Roadmaps, Collabs Slides & video recording: https://gem.cot.ai/p/-9_Wl26kz#/ Abstract: The field of Artificial Intelligence (AI) is radically changing every aspect of human life, from the way we shop and entertain, lend and earn, to the way we learn and create. There are exponentially many AI ideas, principles, procedures, applications, tools and platforms being developed and shared freely. This on the one hand provides young talents with tremendous opportunities, on the other hand poses new challenges in the development of their knowledge and skills. Specifically, AI is now widely considered software 2.0. As a dev, you need to be well prepared for whatâ€™s coming next. In this talk I will walk you through comprehensive landscapes of the many exciting topics in AI, introduce wonderful AI-powered dev tools, recommend pragmatic training roadmaps for you to quickly upgrade your AI capabilities, and invite you to collaborate & altogether build a strong community of AI4Dev by joining study groups and contributing to many exciting fullstack production AI projects.",#AI4Dev	#AI4VN	#Startup,,,,#sharing
"[Poe cá»§a Quora - 1 á»©ng dá»¥ng thay tháº¿ tuyá»‡t vá»i cho ChatGPT]

Hello má»i ngÆ°á»i,
LÃ  má»™t cá»™ng Ä‘á»“ng vá» ML, mÃ¬nh cháº¯c ráº±ng nhu cáº§u sá»­ dá»¥ng ChatGPT cá»§a má»i ngÆ°á»i ráº¥t cao nhÆ°ng viá»‡c truy cáº­p vÃ  sá»­ dá»¥ng láº¡i tÆ°Æ¡ng Ä‘á»‘i khÃ³ khÄƒn (khÃ³ táº¡o account, thÆ°á»ng pháº£i dÃ¹ng VPN, láº¡i hay bá»‹ rate limit, etc. ). MÃ¬nh muá»‘n giá»›i thiá»‡u vá»›i má»i ngÆ°á»i 1 á»©ng dá»¥ng má»›i, mÃ  theo quan Ä‘iá»ƒm chá»§ quan cá»§a mÃ¬nh lÃ  tiá»‡n lá»£i hÆ¡n ChatGPT ráº¥t nhiá»u, Ä‘Ã³ lÃ  Poe cá»§a Quora. VÃ¢ng, chÃ­nh lÃ  trang há»i Ä‘Ã¡p Quora mÃ  báº¡n hay tháº¥y Ä‘Ã³.

1 vÃ i Æ°u Ä‘iá»ƒm cá»§a Poe so vá»›i ChatGPT mÃ  mÃ¬nh tháº¥y:
ğŸ“šPoe cá»§a Quora lÃ  á»©ng dá»¥ng tÃ­ch há»£p nhiá»u chatbot, nÃªn báº¡n cÃ³ thá»ƒ dÃ¹ng ChatGPT thÃ´ng qua Poe.
ğŸ“§ Táº¡o account ráº¥t Ä‘Æ¡n giáº£n, khÃ´ng cÃ³ giá»›i háº¡n gÃ¬ cáº£. Láº¡i cÃ²n khÃ´ng cáº§n dÃ¹ng VPN.
ğŸ’» Giao diá»‡n xinh xáº¯n dá»… thÆ°Æ¡ng.
ğŸƒTá»‘c Ä‘á»™ ráº¥t nhanh, nhiá»u báº¡n á»Ÿ VN dÃ¹ng báº£o lÃ  sá»­ dá»¥ng ChatGPT á»Ÿ Poe cho káº¿t quáº£ nhanh gáº¥p 3, 4 láº§n so vá»›i ChatGPT Pro tá»« web chÃ­nh.
ğŸ’°KhÃ´ng cÃ³ rate limit vÃ  hoÃ n toÃ n miá»…n phÃ­ .
ğŸ§ KhÃ´ng chá»‰ cÃ³ ChatGPT, á»Ÿ Ä‘Ã¢y cÃ²n cÃ³ Claude lÃ  model cá»§a Anthropic, cÃ´ng ty vá»«a Ä‘Æ°á»£c Google Ä‘áº§u tÆ° $300 triá»‡u vÃ  Sage lÃ  custom model cá»§a Quora dá»±a vÃ o OpenAI. Táº¡i sao láº¡i váº¥t váº£ dÃ¹ng ChatGPT trong khi á»Ÿ Poe, báº¡n vá»«a dÃ¹ng Ä‘Æ°á»£c ChatGPT, vá»«a Ä‘Æ°á»£c dÃ¹ng nhá»¯ng state-of-the-art model má»›i nháº¥t?

Hiá»‡n nay báº¡n cÃ³ thá»ƒ dÃ¹ng Poe trÃªn iOS hoáº·c lÃ  desktop nhÃ©. Báº£n Android cÅ©ng sáº½ sá»›m Ä‘Æ°á»£c ra máº¯t.

[Disclaimer]: mÃ¬nh lÃ m viá»‡c trong team Poe á»Ÿ Quora nÃªn dÄ© nhiÃªn lÃ  sáº½ khen nhiá»u hÆ¡n chÃª. á»¨ng dá»¥ng cá»§a bá»n mÃ¬nh sinh sau Ä‘áº» muá»™n nÃªn sáº½ cÃ²n khuyáº¿t Ä‘iá»ƒm, má»i ngÆ°á»i cÃ³ Ä‘Ã³ng gÃ³p gÃ¬ thÃ¬ cá»© comment vÃ o post nhÃ©, khÃ´ng chá»«ng sáº½ tháº¥y Ã½ kiáº¿n cá»§a báº£n thÃ¢n Ä‘Æ°á»£c Ä‘Æ°a vÃ o app Ä‘Ã³ ğŸ˜œ","[Poe cá»§a Quora - 1 á»©ng dá»¥ng thay tháº¿ tuyá»‡t vá»i cho ChatGPT] Hello má»i ngÆ°á»i, LÃ  má»™t cá»™ng Ä‘á»“ng vá» ML, mÃ¬nh cháº¯c ráº±ng nhu cáº§u sá»­ dá»¥ng ChatGPT cá»§a má»i ngÆ°á»i ráº¥t cao nhÆ°ng viá»‡c truy cáº­p vÃ  sá»­ dá»¥ng láº¡i tÆ°Æ¡ng Ä‘á»‘i khÃ³ khÄƒn (khÃ³ táº¡o account, thÆ°á»ng pháº£i dÃ¹ng VPN, láº¡i hay bá»‹ rate limit, etc. ). MÃ¬nh muá»‘n giá»›i thiá»‡u vá»›i má»i ngÆ°á»i 1 á»©ng dá»¥ng má»›i, mÃ  theo quan Ä‘iá»ƒm chá»§ quan cá»§a mÃ¬nh lÃ  tiá»‡n lá»£i hÆ¡n ChatGPT ráº¥t nhiá»u, Ä‘Ã³ lÃ  Poe cá»§a Quora. VÃ¢ng, chÃ­nh lÃ  trang há»i Ä‘Ã¡p Quora mÃ  báº¡n hay tháº¥y Ä‘Ã³. 1 vÃ i Æ°u Ä‘iá»ƒm cá»§a Poe so vá»›i ChatGPT mÃ  mÃ¬nh tháº¥y: Poe cá»§a Quora lÃ  á»©ng dá»¥ng tÃ­ch há»£p nhiá»u chatbot, nÃªn báº¡n cÃ³ thá»ƒ dÃ¹ng ChatGPT thÃ´ng qua Poe. Táº¡o account ráº¥t Ä‘Æ¡n giáº£n, khÃ´ng cÃ³ giá»›i háº¡n gÃ¬ cáº£. Láº¡i cÃ²n khÃ´ng cáº§n dÃ¹ng VPN. Giao diá»‡n xinh xáº¯n dá»… thÆ°Æ¡ng. Tá»‘c Ä‘á»™ ráº¥t nhanh, nhiá»u báº¡n á»Ÿ VN dÃ¹ng báº£o lÃ  sá»­ dá»¥ng ChatGPT á»Ÿ Poe cho káº¿t quáº£ nhanh gáº¥p 3, 4 láº§n so vá»›i ChatGPT Pro tá»« web chÃ­nh. KhÃ´ng cÃ³ rate limit vÃ  hoÃ n toÃ n miá»…n phÃ­ . KhÃ´ng chá»‰ cÃ³ ChatGPT, á»Ÿ Ä‘Ã¢y cÃ²n cÃ³ Claude lÃ  model cá»§a Anthropic, cÃ´ng ty vá»«a Ä‘Æ°á»£c Google Ä‘áº§u tÆ° $300 triá»‡u vÃ  Sage lÃ  custom model cá»§a Quora dá»±a vÃ o OpenAI. Táº¡i sao láº¡i váº¥t váº£ dÃ¹ng ChatGPT trong khi á»Ÿ Poe, báº¡n vá»«a dÃ¹ng Ä‘Æ°á»£c ChatGPT, vá»«a Ä‘Æ°á»£c dÃ¹ng nhá»¯ng state-of-the-art model má»›i nháº¥t? Hiá»‡n nay báº¡n cÃ³ thá»ƒ dÃ¹ng Poe trÃªn iOS hoáº·c lÃ  desktop nhÃ©. Báº£n Android cÅ©ng sáº½ sá»›m Ä‘Æ°á»£c ra máº¯t. [Disclaimer]: mÃ¬nh lÃ m viá»‡c trong team Poe á»Ÿ Quora nÃªn dÄ© nhiÃªn lÃ  sáº½ khen nhiá»u hÆ¡n chÃª. á»¨ng dá»¥ng cá»§a bá»n mÃ¬nh sinh sau Ä‘áº» muá»™n nÃªn sáº½ cÃ²n khuyáº¿t Ä‘iá»ƒm, má»i ngÆ°á»i cÃ³ Ä‘Ã³ng gÃ³p gÃ¬ thÃ¬ cá»© comment vÃ o post nhÃ©, khÃ´ng chá»«ng sáº½ tháº¥y Ã½ kiáº¿n cá»§a báº£n thÃ¢n Ä‘Æ°á»£c Ä‘Æ°a vÃ o app Ä‘Ã³",,,,,#sharing
"NgÆ°á»i tÃ¢y ráº¥t hay chÆ¡i chá»¯ kiá»ƒu LLaMA (lÃ  má»™t loÃ i Ä‘á»™ng váº­t há» láº¡c Ä‘Ã  Ä‘Æ°á»£c nuÃ´i á»Ÿ Nam Má»¹ Ä‘á»ƒ láº¥y lÃ´ng) vÃ  cÅ©ng lÃ  tÃªn model xá»­ lÃ½ ngÃ´n ngá»¯ gáº§n Ä‘Ã¢y Ä‘Æ°á»£c FacebookResearch cÃ´ng bá»‘. Ná»­a Ä‘Ãªm qua, 1 nhÃ³m nghiÃªn cá»©u á»Ÿ Äáº¡i há»c Stanford cÃ³ finetune nhá» nháº¥t model LLaMA 7B theo cÆ¡ cháº¿ Self-Instruct (bÃ i bÃ¡o táº¡i Ä‘Ã¢y https://arxiv.org/abs/2212.10560). Há» Ä‘áº·t tÃªn cho model cá»§a há» lÃ  Alpaca (má»™t loÃ i thuá»™c há» láº¡c Ä‘Ã , cÃ³ Ä‘áº·c Ä‘iá»ƒm sinh há»c gáº§n giá»‘ng vá»›i Llama, cÅ©ng Ä‘Æ°á»£c nuÃ´i á»Ÿ dÃ£y Andes, Nam Má»¹ Ä‘á»ƒ láº¥y lÃ´ng). ÄÃ¢y lÃ  source code cho Alpaca (https://github.com/tatsu-lab/stanford_alpaca). BÃªn cáº¡nh Ä‘Ã³, há» cÅ©ng Ä‘ang merge request lÃªn HuggingFace/transformers, vÃ  cáº§n thÃªm 1 ngÆ°á»i review code trÆ°á»›c khi PR lÃªn transformers. NgoÃ i ra, há» cÅ©ng xÃ¢y dá»±ng giao diá»‡n ná»n web giá»‘ng ChatGPT (nhÆ°ng k cáº§n Ä‘Äƒng kÃ½ Ä‘á»ƒ xá»­ dá»¥ng) táº¡i Ä‘Ã¢y https://alpaca-ai-custom1.ngrok.io/
***** Hi vá»ng má»i ngÆ°á»i sáº½ thÃ­ch thÃº vá»›i nhá»¯ng cÃ´ng cá»¥ sinh ra ngÃ´n ngá»¯ *****","NgÆ°á»i tÃ¢y ráº¥t hay chÆ¡i chá»¯ kiá»ƒu LLaMA (lÃ  má»™t loÃ i Ä‘á»™ng váº­t há» láº¡c Ä‘Ã  Ä‘Æ°á»£c nuÃ´i á»Ÿ Nam Má»¹ Ä‘á»ƒ láº¥y lÃ´ng) vÃ  cÅ©ng lÃ  tÃªn model xá»­ lÃ½ ngÃ´n ngá»¯ gáº§n Ä‘Ã¢y Ä‘Æ°á»£c FacebookResearch cÃ´ng bá»‘. Ná»­a Ä‘Ãªm qua, 1 nhÃ³m nghiÃªn cá»©u á»Ÿ Äáº¡i há»c Stanford cÃ³ finetune nhá» nháº¥t model LLaMA 7B theo cÆ¡ cháº¿ Self-Instruct (bÃ i bÃ¡o táº¡i Ä‘Ã¢y https://arxiv.org/abs/2212.10560). Há» Ä‘áº·t tÃªn cho model cá»§a há» lÃ  Alpaca (má»™t loÃ i thuá»™c há» láº¡c Ä‘Ã , cÃ³ Ä‘áº·c Ä‘iá»ƒm sinh há»c gáº§n giá»‘ng vá»›i Llama, cÅ©ng Ä‘Æ°á»£c nuÃ´i á»Ÿ dÃ£y Andes, Nam Má»¹ Ä‘á»ƒ láº¥y lÃ´ng). ÄÃ¢y lÃ  source code cho Alpaca (https://github.com/tatsu-lab/stanford_alpaca). BÃªn cáº¡nh Ä‘Ã³, há» cÅ©ng Ä‘ang merge request lÃªn HuggingFace/transformers, vÃ  cáº§n thÃªm 1 ngÆ°á»i review code trÆ°á»›c khi PR lÃªn transformers. NgoÃ i ra, há» cÅ©ng xÃ¢y dá»±ng giao diá»‡n ná»n web giá»‘ng ChatGPT (nhÆ°ng k cáº§n Ä‘Äƒng kÃ½ Ä‘á»ƒ xá»­ dá»¥ng) táº¡i Ä‘Ã¢y https://alpaca-ai-custom1.ngrok.io/ ***** Hi vá»ng má»i ngÆ°á»i sáº½ thÃ­ch thÃº vá»›i nhá»¯ng cÃ´ng cá»¥ sinh ra ngÃ´n ngá»¯ *****",,,,,"#sharing, #deep_learning"
Hi mn. Hiá»‡n táº¡i e Ä‘ang lÃ m project cÃ¡ nhÃ¢n Crawl data shopee. Äa sá»‘ cÃ¡c fields Ä‘á»u láº¥y Ä‘Ãºng nhÆ°ng chá»‰ cÃ³ Price vÃ  Stock lÃ  bá»‹ sai sá»‘. Mn chá»‰ e chá»— nÃ y vá»›i áº¡. E xin cáº£m Æ¡n,Hi mn. Hiá»‡n táº¡i e Ä‘ang lÃ m project cÃ¡ nhÃ¢n Crawl data shopee. Äa sá»‘ cÃ¡c fields Ä‘á»u láº¥y Ä‘Ãºng nhÆ°ng chá»‰ cÃ³ Price vÃ  Stock lÃ  bá»‹ sai sá»‘. Mn chá»‰ e chá»— nÃ y vá»›i áº¡. E xin cáº£m Æ¡n,,,,,"#Q&A, #data"
ChÃ o má»i ngÆ°á»i. Hiá»‡n e Ä‘ang cÃ³ bá»™ data cÃ³ cáº¥u trÃºc tÆ°Æ¡ng tá»± nhÆ° hÃ¬nh. E tháº¥y data Ä‘ang bá»‹ duplicate theo hÃ ng cá»§a vÃ i trÄƒm cá»™t Ä‘áº§u. E Ä‘ang tÃ¬m hiá»ƒu theo hÆ°á»›ng grouping láº¡i thay vÃ¬ Ä‘á»ƒ duplicates nhÆ° v mÃ  train model nhÆ°ng ko cÃ³ key word Ä‘á»ƒ tÃ¬m hiá»ƒu. Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o vs áº¡.,ChÃ o má»i ngÆ°á»i. Hiá»‡n e Ä‘ang cÃ³ bá»™ data cÃ³ cáº¥u trÃºc tÆ°Æ¡ng tá»± nhÆ° hÃ¬nh. E tháº¥y data Ä‘ang bá»‹ duplicate theo hÃ ng cá»§a vÃ i trÄƒm cá»™t Ä‘áº§u. E Ä‘ang tÃ¬m hiá»ƒu theo hÆ°á»›ng grouping láº¡i thay vÃ¬ Ä‘á»ƒ duplicates nhÆ° v mÃ  train model nhÆ°ng ko cÃ³ key word Ä‘á»ƒ tÃ¬m hiá»ƒu. Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o vs áº¡.,,,,,"#Q&A, #data"
"[RoomGPT - Room Generation]

CÃ¡c báº¡n cÃ³ muá»‘n thiáº¿t káº¿ vÄƒn phÃ²ng, phÃ²ng khÃ¡ch, phÃ²ng ngá»§, phÃ²ng táº¯m,... cá»§a mÃ¬nh trá»Ÿ nÃªn Ä‘áº¹p hÆ¡n, nhÆ°ng láº¡i bá»‹ thiáº¿u Ã½ tÆ°á»Ÿng. HÃ£y Ä‘á» RoomGPT giÃºp báº¡n. CÃ¡c báº¡n chá»n loáº¡i phÃ²ng vÃ  phong cÃ¡ch mong muá»‘n (modern, vintage, minimalist,...), sau Ä‘Ã³ táº£i áº£nh cÄƒn phÃ²ng hiá»‡n táº¡i cá»§a báº¡n lÃªn, RoomGPT sáº½ giÃºp báº¡n lÃ m cÄƒn phÃ²ng trá»Ÿ lÃªn lá»™ng láº«y hÆ¡n.

á»¨ng dá»¥ng hoÃ n toÃ n miá»…n phÃ­ táº¡i: https://www.roomgpt.io/

CÃ¡c báº¡n cÃ²n chá» gÃ¬ ná»¯a mÃ  khÃ´ng biáº¿n cÃ¡i á»• chuá»™t cá»§a mÃ¬nh trá»Ÿ nÃªn sang trá»ng hÆ¡n ^^","[RoomGPT - Room Generation] CÃ¡c báº¡n cÃ³ muá»‘n thiáº¿t káº¿ vÄƒn phÃ²ng, phÃ²ng khÃ¡ch, phÃ²ng ngá»§, phÃ²ng táº¯m,... cá»§a mÃ¬nh trá»Ÿ nÃªn Ä‘áº¹p hÆ¡n, nhÆ°ng láº¡i bá»‹ thiáº¿u Ã½ tÆ°á»Ÿng. HÃ£y Ä‘á» RoomGPT giÃºp báº¡n. CÃ¡c báº¡n chá»n loáº¡i phÃ²ng vÃ  phong cÃ¡ch mong muá»‘n (modern, vintage, minimalist,...), sau Ä‘Ã³ táº£i áº£nh cÄƒn phÃ²ng hiá»‡n táº¡i cá»§a báº¡n lÃªn, RoomGPT sáº½ giÃºp báº¡n lÃ m cÄƒn phÃ²ng trá»Ÿ lÃªn lá»™ng láº«y hÆ¡n. á»¨ng dá»¥ng hoÃ n toÃ n miá»…n phÃ­ táº¡i: https://www.roomgpt.io/ CÃ¡c báº¡n cÃ²n chá» gÃ¬ ná»¯a mÃ  khÃ´ng biáº¿n cÃ¡i á»• chuá»™t cá»§a mÃ¬nh trá»Ÿ nÃªn sang trá»ng hÆ¡n ^^",,,,,"#sharing, #cv, #deep_learning"
"Cháº¯c cÃ¡c báº¡n quan tÃ¢m tá»›i chá»§ Ä‘á» GPT-xx khÃ´ng thá»ƒ khÃ´ng biáº¿t codebase transformers cá»§a HuggingFace. Hay gáº§n Ä‘Ã¢y, Andrej Karpathy cÃ³ lÃ m series bÃ i giáº£ng vÃ  source code vá» GPT-2 cÃ³ tÃªn lÃ  nanoGPT (https://github.com/karpathy/nanoGPT/tree/master). TrÆ°á»›c Ä‘Ã³ vÃ i nÄƒm Andrej cÅ©ng táº¡o repo cÃ³ tÃªn lÃ  minGPT (https://github.com/karpathy/minGPT/tree/master). SÃ¡ng sá»›m nay, TySam cÃ³ lÃ m repo tÆ°Æ¡ng tá»± nanoGPT cÃ³ tÃªn lÃ  hlb-GPT ~hyperlightspeedbench-gpt táº¡i Ä‘Ã¢y (https://github.com/tysam-code/hlb-gpt/tree/main), anh nÃ y cÃ³ sá»Ÿ trÆ°á»ng lÃ m má»i thá»© Ä‘Æ¡n giáº£n, hiá»‡u quáº£, dá»… Ä‘á»c, dá»… hiá»ƒu, mÃ  benchmark láº¡i ráº¥t á»•n! Hi vá»ng vá»›i thÃ´ng tin nÃ y, cÃ¡c báº¡n sáº½ cÃ³ thÃªm kiáº¿n thá»©c, kÄ© nÄƒng má»›i cho mÃ¬nh.","Cháº¯c cÃ¡c báº¡n quan tÃ¢m tá»›i chá»§ Ä‘á» GPT-xx khÃ´ng thá»ƒ khÃ´ng biáº¿t codebase transformers cá»§a HuggingFace. Hay gáº§n Ä‘Ã¢y, Andrej Karpathy cÃ³ lÃ m series bÃ i giáº£ng vÃ  source code vá» GPT-2 cÃ³ tÃªn lÃ  nanoGPT (https://github.com/karpathy/nanoGPT/tree/master). TrÆ°á»›c Ä‘Ã³ vÃ i nÄƒm Andrej cÅ©ng táº¡o repo cÃ³ tÃªn lÃ  minGPT (https://github.com/karpathy/minGPT/tree/master). SÃ¡ng sá»›m nay, TySam cÃ³ lÃ m repo tÆ°Æ¡ng tá»± nanoGPT cÃ³ tÃªn lÃ  hlb-GPT ~hyperlightspeedbench-gpt táº¡i Ä‘Ã¢y (https://github.com/tysam-code/hlb-gpt/tree/main), anh nÃ y cÃ³ sá»Ÿ trÆ°á»ng lÃ m má»i thá»© Ä‘Æ¡n giáº£n, hiá»‡u quáº£, dá»… Ä‘á»c, dá»… hiá»ƒu, mÃ  benchmark láº¡i ráº¥t á»•n! Hi vá»ng vá»›i thÃ´ng tin nÃ y, cÃ¡c báº¡n sáº½ cÃ³ thÃªm kiáº¿n thá»©c, kÄ© nÄƒng má»›i cho mÃ¬nh.",,,,,"#sharing, #deep_learning"
"[Person Re-Identification]
Hiá»‡n nay cÃ¡c paper sota trÃªn táº­p dá»¯ liá»‡u Market-101 (chá»§ yáº¿u lÃ  resnet) cho bÃ i toÃ¡n ReID khi Ã¡p dá»¥ng trÃªn dá»¯ liá»‡u thá»±c táº¿ Ä‘á»u khÃ´ng cho káº¿t quáº£ Ä‘Ã¡ng mong Ä‘á»£i (dÃ¹ Ä‘Ã£ retrain model trÃªn data cá»§a doanh nghiá»‡p). Mong má»i ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m trong máº£ng nÃ y cÃ³ thá»ƒ cho em xin cao kiáº¿n. Em xin phÃ©p Ä‘Æ°á»£c há»i má»™t vÃ i cÃ¢u nhÆ° sau:
1. Liá»‡u dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ retrain váº«n cÃ²n quÃ¡ nhá» Ä‘á»ƒ model cÃ³ thá»ƒ há»c Ä‘Æ°á»£c?
2. CÃ³ pháº£i cÃ¡c paper public sáº½ khÃ´ng Ã¡p dá»¥ng vÃ o thÆ°c táº¿ Ä‘Æ°á»£c?
3. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cáº£i thiá»‡n má»™t model ReID Ä‘á»ƒ cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o trong bÃ i toÃ¡n thá»±c táº¿ mÃ  khÃ´ng cáº§n pháº£i thu tháº­p sá»‘ lÆ°á»£ng data lá»›n?
Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i tá»« táº¥t cáº£ má»i ngÆ°á»i, em xin cáº£m Æ¡n.","[Person Re-Identification] Hiá»‡n nay cÃ¡c paper sota trÃªn táº­p dá»¯ liá»‡u Market-101 (chá»§ yáº¿u lÃ  resnet) cho bÃ i toÃ¡n ReID khi Ã¡p dá»¥ng trÃªn dá»¯ liá»‡u thá»±c táº¿ Ä‘á»u khÃ´ng cho káº¿t quáº£ Ä‘Ã¡ng mong Ä‘á»£i (dÃ¹ Ä‘Ã£ retrain model trÃªn data cá»§a doanh nghiá»‡p). Mong má»i ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m trong máº£ng nÃ y cÃ³ thá»ƒ cho em xin cao kiáº¿n. Em xin phÃ©p Ä‘Æ°á»£c há»i má»™t vÃ i cÃ¢u nhÆ° sau: 1. Liá»‡u dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ retrain váº«n cÃ²n quÃ¡ nhá» Ä‘á»ƒ model cÃ³ thá»ƒ há»c Ä‘Æ°á»£c? 2. CÃ³ pháº£i cÃ¡c paper public sáº½ khÃ´ng Ã¡p dá»¥ng vÃ o thÆ°c táº¿ Ä‘Æ°á»£c? 3. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cáº£i thiá»‡n má»™t model ReID Ä‘á»ƒ cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o trong bÃ i toÃ¡n thá»±c táº¿ mÃ  khÃ´ng cáº§n pháº£i thu tháº­p sá»‘ lÆ°á»£ng data lá»›n? Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i tá»« táº¥t cáº£ má»i ngÆ°á»i, em xin cáº£m Æ¡n.",,,,,"#Q&A, #data, #cv, #deep_learning"
"Hello má»i ngÆ°á»i,
HÃ´m nay mÃ¬nh cÃ³ má»™t discussion vá»›i Ä‘á»“ng nghiá»‡p cá»§a mÃ¬nh vá» má»™t cÃ¡i khÃ¡ lÃ  basic trong ML nhÆ°ng cÅ©ng khÃ¡ hay Ä‘á»ƒ tháº£o luáº­n. MÃ¬nh muá»‘n Ä‘Æ°a ra Ä‘Ã¢y Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng tháº£o luáº­n:
Váº¥n Ä‘á» cá»§a mÃ¬nh lÃ  má»™t bÃ i toÃ¡n vá» time series based vÃ  deployment in production.
MÃ¬nh cÃ³ má»™t ML model, Ä‘Æ°á»£c train má»—i ngÃ y vá»›i dá»¯ liá»‡u má»›i Ä‘Æ°á»£c cáº­p nháº­t (feedback cá»§a model hÃ´m trÆ°á»›c) vÃ  deploy má»—i ngÃ y vÃ¬ data freshness ráº¥t ráº¥t quan trá»ng khi cÃ³ quÃ¡ nhiá»u data drift. Ä‘áº·c biá»‡t lÃ  data cá»§a ngÃ y N-1 lÃ  quan trá»ng nháº¥t vÃ¬ nÃ³ chá»©a nhiá»u thÃ´ng tin há»¯u Ã­ch nháº¥t.
CÃ¡ch lÃ m nÃ o lÃ  tá»‘t nháº¥t vÃ  cÃ³ thá»ƒ lÃ  best practice trong cÃ¡c trÆ°á»ng há»£p dÆ°á»›i Ä‘Ã¢y:
Suppose lÃ  ngÃ y N lÃ  ngÃ y deployment, mÃ¬nh chá»‰ cÃ³ dá»¯ liá»‡u Ä‘áº¿n ngÃ y N-1, má»¥c tiÃªu lÃ  probability predictions táº¡i ngÃ y N lÃ  tá»‘t nháº¥t vÃ  Ä‘Æ°á»£c calibrated tá»‘t nháº¥t.
Train model trÃªn data Ä‘áº¿n N-3, sau Ä‘Ã³ optimize (hyperparams search) trÃªn data N-2 rá»“i calibration trÃªn N-1
Train model trÃªn data Ä‘áº¿n N-2, sau Ä‘Ã³ optimize (hyperparams search) trÃªn data N- 1. rá»“i calibration trÃªn N - 1
Hyperparams search vá»›i time-series cross validation (5 folds) trÃªn toÃ n bá»™ data Ä‘á»ƒ obtain best params, sau Ä‘Ã³ train trÃªn toÃ n bá»™ data Ä‘áº¿n N vá»›i best params Ä‘Ã³. 
Má»i má»i ngÆ°á»i cÃ¹ng tháº£o luáº­n xem cÃ¡ch nÃ o theoretically lÃ  hiá»‡u quáº£ nháº¥t.","Hello má»i ngÆ°á»i, HÃ´m nay mÃ¬nh cÃ³ má»™t discussion vá»›i Ä‘á»“ng nghiá»‡p cá»§a mÃ¬nh vá» má»™t cÃ¡i khÃ¡ lÃ  basic trong ML nhÆ°ng cÅ©ng khÃ¡ hay Ä‘á»ƒ tháº£o luáº­n. MÃ¬nh muá»‘n Ä‘Æ°a ra Ä‘Ã¢y Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng tháº£o luáº­n: Váº¥n Ä‘á» cá»§a mÃ¬nh lÃ  má»™t bÃ i toÃ¡n vá» time series based vÃ  deployment in production. MÃ¬nh cÃ³ má»™t ML model, Ä‘Æ°á»£c train má»—i ngÃ y vá»›i dá»¯ liá»‡u má»›i Ä‘Æ°á»£c cáº­p nháº­t (feedback cá»§a model hÃ´m trÆ°á»›c) vÃ  deploy má»—i ngÃ y vÃ¬ data freshness ráº¥t ráº¥t quan trá»ng khi cÃ³ quÃ¡ nhiá»u data drift. Ä‘áº·c biá»‡t lÃ  data cá»§a ngÃ y N-1 lÃ  quan trá»ng nháº¥t vÃ¬ nÃ³ chá»©a nhiá»u thÃ´ng tin há»¯u Ã­ch nháº¥t. CÃ¡ch lÃ m nÃ o lÃ  tá»‘t nháº¥t vÃ  cÃ³ thá»ƒ lÃ  best practice trong cÃ¡c trÆ°á»ng há»£p dÆ°á»›i Ä‘Ã¢y: Suppose lÃ  ngÃ y N lÃ  ngÃ y deployment, mÃ¬nh chá»‰ cÃ³ dá»¯ liá»‡u Ä‘áº¿n ngÃ y N-1, má»¥c tiÃªu lÃ  probability predictions táº¡i ngÃ y N lÃ  tá»‘t nháº¥t vÃ  Ä‘Æ°á»£c calibrated tá»‘t nháº¥t. Train model trÃªn data Ä‘áº¿n N-3, sau Ä‘Ã³ optimize (hyperparams search) trÃªn data N-2 rá»“i calibration trÃªn N-1 Train model trÃªn data Ä‘áº¿n N-2, sau Ä‘Ã³ optimize (hyperparams search) trÃªn data N- 1. rá»“i calibration trÃªn N - 1 Hyperparams search vá»›i time-series cross validation (5 folds) trÃªn toÃ n bá»™ data Ä‘á»ƒ obtain best params, sau Ä‘Ã³ train trÃªn toÃ n bá»™ data Ä‘áº¿n N vá»›i best params Ä‘Ã³. Má»i má»i ngÆ°á»i cÃ¹ng tháº£o luáº­n xem cÃ¡ch nÃ o theoretically lÃ  hiá»‡u quáº£ nháº¥t.",,,,,"#Q&A, #machine_learning"
"[Visual ChatGPT: Sá»­ dá»¥ng ChatGPT vá»›i hÃ¬nh áº£nh]

MÃ´ hÃ¬nh ChatGPT chá»‰ há»— trá»£ má»i ngÆ°á»i tÆ°Æ¡ng tÃ¡c báº±ng ngÃ´n ngá»¯. Tuy nhiÃªn cÃ³ ráº¥t nhiá»u mÃ´ hÃ¬nh dáº¡ng hÃ¬nh áº£nh nhÆ° Visual Transformers hay Stable Diffusion.  Tháº¿ nÃªn cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘áº¿n tá»« Microsoft Ä‘Ã£ xÃ¢y dá»±ng mÃ´ hÃ¬nh Visual ChatGPT káº¿t há»£p ChatGPT vá»›i cÃ¡c mÃ´ hÃ¬nh hÃ¬nh áº£nh Ä‘á»ƒ há»— trá»£ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ gá»­i hÃ¬nh áº£nh khi chat vÃ  há»— trá»£ tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan tá»›i ná»™i dung bá»©c áº£nh.

Github: https://github.com/microsoft/visual-chatgpt",[Visual ChatGPT: Sá»­ dá»¥ng ChatGPT vá»›i hÃ¬nh áº£nh] MÃ´ hÃ¬nh ChatGPT chá»‰ há»— trá»£ má»i ngÆ°á»i tÆ°Æ¡ng tÃ¡c báº±ng ngÃ´n ngá»¯. Tuy nhiÃªn cÃ³ ráº¥t nhiá»u mÃ´ hÃ¬nh dáº¡ng hÃ¬nh áº£nh nhÆ° Visual Transformers hay Stable Diffusion. Tháº¿ nÃªn cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘áº¿n tá»« Microsoft Ä‘Ã£ xÃ¢y dá»±ng mÃ´ hÃ¬nh Visual ChatGPT káº¿t há»£p ChatGPT vá»›i cÃ¡c mÃ´ hÃ¬nh hÃ¬nh áº£nh Ä‘á»ƒ há»— trá»£ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ gá»­i hÃ¬nh áº£nh khi chat vÃ  há»— trá»£ tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan tá»›i ná»™i dung bá»©c áº£nh. Github: https://github.com/microsoft/visual-chatgpt,,,,,"#sharing, #deep_learning"
"Hi cáº£ nhÃ , em phÃ©p Ä‘Æ°á»£c chia sáº» má»™t seminar khÃ¡c tá»• chá»©c bá»Ÿi MLOpsVN cho cÃ¡c bÃ¡c nÃ o quan tÃ¢m :D. Cáº£m Æ¡n cáº£ nhÃ  nhiá»u.","Hi cáº£ nhÃ , em phÃ©p Ä‘Æ°á»£c chia sáº» má»™t seminar khÃ¡c tá»• chá»©c bá»Ÿi MLOpsVN cho cÃ¡c bÃ¡c nÃ o quan tÃ¢m :D. Cáº£m Æ¡n cáº£ nhÃ  nhiá»u.",,,,,#webinar
"CÃ³ láº½ khÃ¡i niá»‡m AGI (Artificial General Intelligence) váº«n lÃ  gÃ¬ Ä‘Ã³ chÆ°a tá»›i, nhÆ°ng cÃ¡ch GPT-4 Ä‘áº¡t káº¿t quáº£ trong cÃ¡c bÃ i kiá»ƒm tra nhÆ° BAR, LSAT, GRE, AP, Ä‘áº·c biá»‡t áº¥n tÆ°á»£ng. VÃ­ dá»¥ nhÆ° GRE, thÃ¬ bÃ i Quantitative Ä‘áº¡t 163/170, bÃ i Verbal Ä‘áº¡t 169/170 vÃ  bÃ i Writing Ä‘áº¡t 4/6.
Hiá»‡n táº¡i cÃ¡c báº¡n cÃ³ thá»ƒ thá»­ GPT-4 báº£n chá»‰ cÃ³ text trÃªn ChatGPT báº£n plus.","CÃ³ láº½ khÃ¡i niá»‡m AGI (Artificial General Intelligence) váº«n lÃ  gÃ¬ Ä‘Ã³ chÆ°a tá»›i, nhÆ°ng cÃ¡ch GPT-4 Ä‘áº¡t káº¿t quáº£ trong cÃ¡c bÃ i kiá»ƒm tra nhÆ° BAR, LSAT, GRE, AP, Ä‘áº·c biá»‡t áº¥n tÆ°á»£ng. VÃ­ dá»¥ nhÆ° GRE, thÃ¬ bÃ i Quantitative Ä‘áº¡t 163/170, bÃ i Verbal Ä‘áº¡t 169/170 vÃ  bÃ i Writing Ä‘áº¡t 4/6. Hiá»‡n táº¡i cÃ¡c báº¡n cÃ³ thá»ƒ thá»­ GPT-4 báº£n chá»‰ cÃ³ text trÃªn ChatGPT báº£n plus.",,,,,#sharing
"KHáº¢O SÃT NHU Cáº¦U THEO DÃ•I THÃ”NG TIN Vá»€ AI-ML 

Em xin phÃ©p anh Tiep VuHuu thá»±c hiá»‡n kháº£o sÃ¡t trong group. 

Hiá»‡n táº¡i lÄ©nh vá»±c AI nÃ³i chung, ML nÃ³i riÃªng Ä‘ang phÃ¡t triá»ƒn quÃ¡ nhanh chÃ³ng, vá»›i cÃ¡c bÆ°á»›c tiáº¿n tá»«ng ngÃ y. LÆ°á»£ng thÃ´ng tin liÃªn quan tá»›i AI, viá»‡c á»©ng dá»¥ng AI...vÆ°á»£t quÃ¡ kháº£ nÄƒng theo dÃµi thÃ´ng thÆ°á»ng cá»§a báº¥t kÃ¬ cÃ¡ nhÃ¢n nÃ o, trong khi hiá»ƒu vÃ  sá»­ dá»¥ng AI ngÃ y cÃ ng trá»Ÿ thÃ nh nhu cáº§u quan trá»ng trong cÃ´ng viá»‡c vÃ  Ä‘á»i sá»‘ng. 

Hiá»‡n táº¡i em vÃ  team Ä‘Ã£ cÃ³ má»™t giáº£i phÃ¡p Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n quÃ¡ táº£i thÃ´ng tin, vÃ  dá»± Ä‘á»‹nh sáº½ táº¡o má»™t phiÃªn báº£n dÃ nh riÃªng tá»‘i Æ°u cho lÄ©nh vá»±c AI/ML nháº±m giÃºp nhá»¯ng ngÆ°á»i theo dÃµi, nhÃ  nghiÃªn cá»©u, doanh nhÃ¢n khá»Ÿi nghiá»‡p trong lÄ©nh vá»±c nÃ y cÃ³ thá»ƒ theo dÃµi thÃ´ng tin tá»‘t hÆ¡n. 

Ráº¥t mong cÃ¡c anh chá»‹ em trong Group dÃ nh chÃºt thá»i gian thá»±c hiá»‡n kháº£o sÃ¡t Ä‘á»ƒ team Ä‘iá»u chá»‰nh sáº£n pháº©m tá»‘t nháº¥t. 

Káº¿t quáº£ thá»±c hiá»‡n kháº£o sÃ¡t sáº½ Ä‘Æ°á»£c phÃ¢n tÃ­ch vÃ  public trá»Ÿ láº¡i vá»›i cá»™ng Ä‘á»“ng Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng cÃ³ hiá»ƒu biáº¿t sÃ¢u hÆ¡n vá» sá»± quan tÃ¢m cá»§a ngÆ°á»i Viá»‡t tá»›i AI nÃ³i chung. 

Em xin cÃ¡m Æ¡n!

ğŸ‘‰Link thá»±c hiá»‡n kháº£o sÃ¡t: http://bit.ly/3Za2mPd","KHáº¢O SÃT NHU Cáº¦U THEO DÃ•I THÃ”NG TIN Vá»€ AI-ML Em xin phÃ©p anh Tiep VuHuu thá»±c hiá»‡n kháº£o sÃ¡t trong group. Hiá»‡n táº¡i lÄ©nh vá»±c AI nÃ³i chung, ML nÃ³i riÃªng Ä‘ang phÃ¡t triá»ƒn quÃ¡ nhanh chÃ³ng, vá»›i cÃ¡c bÆ°á»›c tiáº¿n tá»«ng ngÃ y. LÆ°á»£ng thÃ´ng tin liÃªn quan tá»›i AI, viá»‡c á»©ng dá»¥ng AI...vÆ°á»£t quÃ¡ kháº£ nÄƒng theo dÃµi thÃ´ng thÆ°á»ng cá»§a báº¥t kÃ¬ cÃ¡ nhÃ¢n nÃ o, trong khi hiá»ƒu vÃ  sá»­ dá»¥ng AI ngÃ y cÃ ng trá»Ÿ thÃ nh nhu cáº§u quan trá»ng trong cÃ´ng viá»‡c vÃ  Ä‘á»i sá»‘ng. Hiá»‡n táº¡i em vÃ  team Ä‘Ã£ cÃ³ má»™t giáº£i phÃ¡p Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n quÃ¡ táº£i thÃ´ng tin, vÃ  dá»± Ä‘á»‹nh sáº½ táº¡o má»™t phiÃªn báº£n dÃ nh riÃªng tá»‘i Æ°u cho lÄ©nh vá»±c AI/ML nháº±m giÃºp nhá»¯ng ngÆ°á»i theo dÃµi, nhÃ  nghiÃªn cá»©u, doanh nhÃ¢n khá»Ÿi nghiá»‡p trong lÄ©nh vá»±c nÃ y cÃ³ thá»ƒ theo dÃµi thÃ´ng tin tá»‘t hÆ¡n. Ráº¥t mong cÃ¡c anh chá»‹ em trong Group dÃ nh chÃºt thá»i gian thá»±c hiá»‡n kháº£o sÃ¡t Ä‘á»ƒ team Ä‘iá»u chá»‰nh sáº£n pháº©m tá»‘t nháº¥t. Káº¿t quáº£ thá»±c hiá»‡n kháº£o sÃ¡t sáº½ Ä‘Æ°á»£c phÃ¢n tÃ­ch vÃ  public trá»Ÿ láº¡i vá»›i cá»™ng Ä‘á»“ng Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng cÃ³ hiá»ƒu biáº¿t sÃ¢u hÆ¡n vá» sá»± quan tÃ¢m cá»§a ngÆ°á»i Viá»‡t tá»›i AI nÃ³i chung. Em xin cÃ¡m Æ¡n! Link thá»±c hiá»‡n kháº£o sÃ¡t: http://bit.ly/3Za2mPd",,,,,#Q&A
"#Ask Váº¥n Ä‘á» Crawling Data á»Ÿ cÃ¡c sÃ n
ChÃ o má»i ngÆ°á»i em lÃ  sinh viÃªn Ä‘ang lÃ m project De tá»‘t nghiá»‡p. Má»¥c tiÃªu cá»§a em lÃ  crawl Data á»Ÿ 1 thá»‹ trÆ°á»ng ngÃ¡ch sáº£n pháº©m lÃ m Ä‘áº¹p tá»« cÃ¡c sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ Lazada, Shopee,Tiki gá»“m cáº£ Batch láº«n Stream phá»¥c vá»¥ nhu cáº§u phÃ¢n tÃ­ch, má»i thá»© khÃ¡ ok cho Ä‘áº¿n khi em cáº§n phÃ¢n tÃ­ch doanh sá»‘ thá»‹ trÆ°á»ng ngÃ nh lÃªn Dashboard vÃ  sá»‘ lÆ°á»£ng sáº£n pháº©m thÃ¬ em gáº·p 1 vÃ i váº¥n Ä‘á» :
Tiki thÃ¬ 1 sá»‘ sáº£n pháº©m bÃ¡n missing value khÃ¡ lÃ  nhiá»u( dao Ä‘á»™ng tá»« 10-20% ) vÃ  cÃ³ nhá»¯ng case thiáº¿u táº§m 50% , nhiá»u sáº£n pháº©m quantity_sold chá»‰ rÆ¡i vÃ o 1 dÃ¹ Ä‘Äƒng khÃ¡ lÃ¢u , em khÃ¡ lÃ  Ä‘au Ä‘áº§u khi fill value vÃ o nhá»¯ng case kiá»ƒu nÃ y, thÆ°á»ng thÃ¬ em sáº½ so sÃ¡nh quy mÃ´ giá»¯a Tiki vÃ  Shoppe vá»›i cÃ¹ng 1 loáº¡i sáº£n pháº©m/táº§m giÃ¡/sá»‘ lÆ°á»£ng review tuá»³ tá»«ng th Ä‘Ã³ vÃ  dá»±a vÃ o tá»‰ lá»‡ Ä‘á»ƒ Ä‘iá»n giÃ¡ trá»‹, nhÆ°ng vá»›i nhá»¯ng case mÃ  chá»‰ Tiki cÃ³ thÃ¬ bÃ³ tay.
Äáº¿n cÃ¢u chuyá»‡n tá»•ng doanh sá»‘ thá»‹ trÆ°á»ng , thÃ¬ cÃ´ng thá»©c em sá»­ dá»¥ng váº«n lÃ  giÃ¡ bÃ¡n x sá»‘ lÆ°á»£ng bÃ¡n cá»™ng táº¥t cáº£. Vá»›i Shopee thÃ¬ khÃ¡ á»•n do giÃ¡ vÃ  sá»‘ lÆ°á»£ng sáº£n pháº©m bÃ¡n sá»‘ lÆ°á»£ng missing value Ã­t, NhÆ°ng lÃºc tÃ­nh thÃ¬ thá»‹ pháº§n Tiki thá»t so vá»›i Shopee khÃ¡ nhiá»u, 1 pháº§n áº£nh hÆ°á»Ÿng do dá»¯ liá»‡u . NgoÃ i ra khi cáº§n real-time sáº½ pháº£i tÃ­nh toÃ¡n má»—i khung thá»i gian thÃ¬ cÃ¡ch cá»§a em tÃ­nh vá»›i vÃ i chá»¥c nghÃ¬n sáº£n pháº©m cÃ¡ nhÃ¢n em tháº¥y khÃ¡ lÃ  ngu nhÆ°ng váº«n chÆ°a cÃ³ giáº£i phÃ¡p tá»‘t hÆ¡n. Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ mÃ¬nh xá»­ lÃ½ trÆ°á»ng há»£p nÃ y thÃ¬ em cáº§n cao kiáº¿n
Dá»¯ liá»‡u em crawl thÃ´ng qua API cá»§a cÃ¡c bÃªn cung cáº¥p, em cÃ³ tham kháº£o 1 sá»‘ sáº£n pháº©m nhÆ° case cá»§a Metric.vn thÃ¬ cÃ²n cÃ³ thá»ƒ crawl dá»¯ liá»‡u bÃ¡n cá»§a tá»«ng sáº£n pháº©m trong 1 má»‘c thá»i gian thá»© mÃ  lÃºc em crawl ko cÃ³, váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ crawl sá»‘ lÆ°á»£ng bÃ¡n cá»§a 1 sáº£n pháº©m trÃªn cÃ¡c sÃ n áº¡?
Do tÃ i nÄƒng vÃ  kiáº¿n thá»©c háº¡n háº¹p,ráº¥t mong Ä‘Æ°á»£c cÃ¡c bÃ¡c chá»‰ giÃ¡o ğŸ™","Váº¥n Ä‘á» Crawling Data á»Ÿ cÃ¡c sÃ n ChÃ o má»i ngÆ°á»i em lÃ  sinh viÃªn Ä‘ang lÃ m project De tá»‘t nghiá»‡p. Má»¥c tiÃªu cá»§a em lÃ  crawl Data á»Ÿ 1 thá»‹ trÆ°á»ng ngÃ¡ch sáº£n pháº©m lÃ m Ä‘áº¹p tá»« cÃ¡c sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ Lazada, Shopee,Tiki gá»“m cáº£ Batch láº«n Stream phá»¥c vá»¥ nhu cáº§u phÃ¢n tÃ­ch, má»i thá»© khÃ¡ ok cho Ä‘áº¿n khi em cáº§n phÃ¢n tÃ­ch doanh sá»‘ thá»‹ trÆ°á»ng ngÃ nh lÃªn Dashboard vÃ  sá»‘ lÆ°á»£ng sáº£n pháº©m thÃ¬ em gáº·p 1 vÃ i váº¥n Ä‘á» : Tiki thÃ¬ 1 sá»‘ sáº£n pháº©m bÃ¡n missing value khÃ¡ lÃ  nhiá»u( dao Ä‘á»™ng tá»« 10-20% ) vÃ  cÃ³ nhá»¯ng case thiáº¿u táº§m 50% , nhiá»u sáº£n pháº©m quantity_sold chá»‰ rÆ¡i vÃ o 1 dÃ¹ Ä‘Äƒng khÃ¡ lÃ¢u , em khÃ¡ lÃ  Ä‘au Ä‘áº§u khi fill value vÃ o nhá»¯ng case kiá»ƒu nÃ y, thÆ°á»ng thÃ¬ em sáº½ so sÃ¡nh quy mÃ´ giá»¯a Tiki vÃ  Shoppe vá»›i cÃ¹ng 1 loáº¡i sáº£n pháº©m/táº§m giÃ¡/sá»‘ lÆ°á»£ng review tuá»³ tá»«ng th Ä‘Ã³ vÃ  dá»±a vÃ o tá»‰ lá»‡ Ä‘á»ƒ Ä‘iá»n giÃ¡ trá»‹, nhÆ°ng vá»›i nhá»¯ng case mÃ  chá»‰ Tiki cÃ³ thÃ¬ bÃ³ tay. Äáº¿n cÃ¢u chuyá»‡n tá»•ng doanh sá»‘ thá»‹ trÆ°á»ng , thÃ¬ cÃ´ng thá»©c em sá»­ dá»¥ng váº«n lÃ  giÃ¡ bÃ¡n x sá»‘ lÆ°á»£ng bÃ¡n cá»™ng táº¥t cáº£. Vá»›i Shopee thÃ¬ khÃ¡ á»•n do giÃ¡ vÃ  sá»‘ lÆ°á»£ng sáº£n pháº©m bÃ¡n sá»‘ lÆ°á»£ng missing value Ã­t, NhÆ°ng lÃºc tÃ­nh thÃ¬ thá»‹ pháº§n Tiki thá»t so vá»›i Shopee khÃ¡ nhiá»u, 1 pháº§n áº£nh hÆ°á»Ÿng do dá»¯ liá»‡u . NgoÃ i ra khi cáº§n real-time sáº½ pháº£i tÃ­nh toÃ¡n má»—i khung thá»i gian thÃ¬ cÃ¡ch cá»§a em tÃ­nh vá»›i vÃ i chá»¥c nghÃ¬n sáº£n pháº©m cÃ¡ nhÃ¢n em tháº¥y khÃ¡ lÃ  ngu nhÆ°ng váº«n chÆ°a cÃ³ giáº£i phÃ¡p tá»‘t hÆ¡n. Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ mÃ¬nh xá»­ lÃ½ trÆ°á»ng há»£p nÃ y thÃ¬ em cáº§n cao kiáº¿n Dá»¯ liá»‡u em crawl thÃ´ng qua API cá»§a cÃ¡c bÃªn cung cáº¥p, em cÃ³ tham kháº£o 1 sá»‘ sáº£n pháº©m nhÆ° case cá»§a Metric.vn thÃ¬ cÃ²n cÃ³ thá»ƒ crawl dá»¯ liá»‡u bÃ¡n cá»§a tá»«ng sáº£n pháº©m trong 1 má»‘c thá»i gian thá»© mÃ  lÃºc em crawl ko cÃ³, váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ crawl sá»‘ lÆ°á»£ng bÃ¡n cá»§a 1 sáº£n pháº©m trÃªn cÃ¡c sÃ n áº¡? Do tÃ i nÄƒng vÃ  kiáº¿n thá»©c háº¡n háº¹p,ráº¥t mong Ä‘Æ°á»£c cÃ¡c bÃ¡c chá»‰ giÃ¡o",#Ask,,,,"#Q&A, #data"
"ğŸ‘‰ğŸ»Vá»›i trung bÃ¬nh hÆ¡n 3 nghÃ¬n lÆ°á»£t táº£i vá» gÃ³i cÃ i Ä‘áº·t má»—i thÃ¡ng, Deploy AI Systems Yourself (D.AI.S.Y) toolkit - má»™t sáº£n pháº©m cá»§a Neural Viá»‡t Nam lÃ  má»™t bá»™ cÃ´ng cá»¥ bao gá»“m cÃ¡c thuáº­t toÃ¡n trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  Ä‘Ã³ng gÃ³i. Má»¥c tiÃªu hÆ°á»›ng Ä‘áº¿n cÃ¡c báº¡n tráº» cÃ³ niá»m say mÃª vá»›i cÃ´ng nghá»‡ trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  muá»‘n thá»±c hÃ nh cÃ¡c á»©ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ o Ä‘á»i sá»‘ng thÃ´ng qua cÃ¡c cÃ¢u lá»‡nh Ä‘Æ¡n giáº£n.
ğŸ™‹ğŸ»â€â™‚ï¸ğŸ™‹ğŸ»â€â™‚ï¸BÃªn cáº¡nh cÃ¡c á»©ng dá»¥ng phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p sáºµn nhÆ°: nháº­n diá»‡n ngÆ°á»i Ä‘eo kháº©u trang, phÃ¡t hiá»‡n dÃ¡ng ngÆ°á»i,... Team Daisykit - Neural Viá»‡t Nam sáº½ tiáº¿p tá»¥c phÃ¡t triá»ƒn vÃ  cho ra máº¯t cÃ¡c á»©ng dá»¥ng má»›i trong thá»i gian sáº¯p tá»›i.","Vá»›i trung bÃ¬nh hÆ¡n 3 nghÃ¬n lÆ°á»£t táº£i vá» gÃ³i cÃ i Ä‘áº·t má»—i thÃ¡ng, Deploy AI Systems Yourself (D.AI.S.Y) toolkit - má»™t sáº£n pháº©m cá»§a Neural Viá»‡t Nam lÃ  má»™t bá»™ cÃ´ng cá»¥ bao gá»“m cÃ¡c thuáº­t toÃ¡n trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  Ä‘Ã³ng gÃ³i. Má»¥c tiÃªu hÆ°á»›ng Ä‘áº¿n cÃ¡c báº¡n tráº» cÃ³ niá»m say mÃª vá»›i cÃ´ng nghá»‡ trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  muá»‘n thá»±c hÃ nh cÃ¡c á»©ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ o Ä‘á»i sá»‘ng thÃ´ng qua cÃ¡c cÃ¢u lá»‡nh Ä‘Æ¡n giáº£n. BÃªn cáº¡nh cÃ¡c á»©ng dá»¥ng phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p sáºµn nhÆ°: nháº­n diá»‡n ngÆ°á»i Ä‘eo kháº©u trang, phÃ¡t hiá»‡n dÃ¡ng ngÆ°á»i,... Team Daisykit - Neural Viá»‡t Nam sáº½ tiáº¿p tá»¥c phÃ¡t triá»ƒn vÃ  cho ra máº¯t cÃ¡c á»©ng dá»¥ng má»›i trong thá»i gian sáº¯p tá»›i.",,,,,#sharing
"Em chÃ o má»i ngÆ°á»i áº¡. Em muá»‘n xin lá»i khuyÃªn cá»§a cÃ¡c anh chá»‹ Ä‘á»ƒ bá»• sung kiáº¿n thá»©c cho viá»‡c há»c Machine Learning.
Em hiá»‡n lÃ  sinh viÃªn nÄƒm 2 ngÃ nh Khoa há»c dá»¯ liá»‡u. Sau khi tá»‘t nghiá»‡p em muá»‘n lÃ m bÃªn máº£ng Machine Learning, cá»¥ thá»ƒ lÃ  Machine Learning Engineer hoáº·c NLP Scientist cho cÃ¡c cÃ´ng ty vá» sáº£n pháº©m cÃ´ng nghá»‡ sá»‘ nhÆ° voice assistant, xe tá»± hÃ nh, ...
NhÆ°ng do ngÃ nh nÃ y Ä‘Ã²i há»i kiáº¿n thá»©c cao (Ä‘áº·c biá»‡t lÃ  vá» ToÃ¡n), vÃ  em cÅ©ng Ä‘Æ°á»£c nghe thÆ°á»ng ngÆ°á»i ta tuyá»ƒn dÃ¢n Machine Learning tá»« PhD thÃ´i nÃªn em muá»‘n tÃ¬m hiá»ƒu nhiá»u nháº¥t vá» ML Ä‘á»ƒ cáº¡nh tranh vÃ  cÃ³ Ä‘Æ°á»£c cÃ´ng viá»‡c trong máº£ng nÃ y.
CÃ¡c kiáº¿n thá»©c em Ä‘Ã£ biáº¿t:
Láº­p trÃ¬nh cÆ¡ báº£n
Cáº¥u trÃºc dá»¯ liá»‡u vÃ  giáº£i thuáº­t
CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a má»™t model (á»Ÿ má»©c cÆ¡ báº£n, chÆ°a Ä‘Ã o sÃ¢u vá» ToÃ¡n)
CÃ¡ch dÃ¹ng libray nhÆ° sklearn Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n regression cÆ¡ báº£n trÃªn Kaggle
Hy vá»ng cÃ¡c anh chá»‹ cÃ³ thá»ƒ cho em xin tham kháº£o vá»:
TÃ i liá»‡u ML, cá»¥ thá»ƒ lÃ  cÃ¡c ná»n táº£ng vá» ToÃ¡n, Thá»‘ng KÃª cáº§n thiáº¿t cho ngÃ nh
CÃ¡c dá»± Ã¡n cÃ¡ nhÃ¢n Ä‘á»ƒ bá» vÃ´ portfolio cáº§n thá»ƒ hiá»‡n kiáº¿n thá»©c á»Ÿ máº£ng nÃ o
Sinh viÃªn cÃ³ thá»ƒ cÃ³ paper tá»‘t khÃ´ng? LÃ m sao Ä‘á»ƒ báº¯t Ä‘áº§u nghiÃªn cá»©u lÃ m paper? Hiá»‡n táº¡i em Ä‘ang lÃ m paper á»©ng dá»¥ng ML trong viá»‡c dá»± bÃ¡o, váº«n lÃ  Regression báº±ng cÃ¡ch dÃ¹ng library, nhÆ°ng em tháº¥y cÃ¡ch lÃ m nÃ y Ä‘Æ¡n giáº£n, khÃ´ng chuyÃªn sÃ¢u vÃ  chá»‰ cáº§n nghiÃªn cá»©u chÃºt lÃ  cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c. ","Em chÃ o má»i ngÆ°á»i áº¡. Em muá»‘n xin lá»i khuyÃªn cá»§a cÃ¡c anh chá»‹ Ä‘á»ƒ bá»• sung kiáº¿n thá»©c cho viá»‡c há»c Machine Learning. Em hiá»‡n lÃ  sinh viÃªn nÄƒm 2 ngÃ nh Khoa há»c dá»¯ liá»‡u. Sau khi tá»‘t nghiá»‡p em muá»‘n lÃ m bÃªn máº£ng Machine Learning, cá»¥ thá»ƒ lÃ  Machine Learning Engineer hoáº·c NLP Scientist cho cÃ¡c cÃ´ng ty vá» sáº£n pháº©m cÃ´ng nghá»‡ sá»‘ nhÆ° voice assistant, xe tá»± hÃ nh, ... NhÆ°ng do ngÃ nh nÃ y Ä‘Ã²i há»i kiáº¿n thá»©c cao (Ä‘áº·c biá»‡t lÃ  vá» ToÃ¡n), vÃ  em cÅ©ng Ä‘Æ°á»£c nghe thÆ°á»ng ngÆ°á»i ta tuyá»ƒn dÃ¢n Machine Learning tá»« PhD thÃ´i nÃªn em muá»‘n tÃ¬m hiá»ƒu nhiá»u nháº¥t vá» ML Ä‘á»ƒ cáº¡nh tranh vÃ  cÃ³ Ä‘Æ°á»£c cÃ´ng viá»‡c trong máº£ng nÃ y. CÃ¡c kiáº¿n thá»©c em Ä‘Ã£ biáº¿t: Láº­p trÃ¬nh cÆ¡ báº£n Cáº¥u trÃºc dá»¯ liá»‡u vÃ  giáº£i thuáº­t CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a má»™t model (á»Ÿ má»©c cÆ¡ báº£n, chÆ°a Ä‘Ã o sÃ¢u vá» ToÃ¡n) CÃ¡ch dÃ¹ng libray nhÆ° sklearn Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n regression cÆ¡ báº£n trÃªn Kaggle Hy vá»ng cÃ¡c anh chá»‹ cÃ³ thá»ƒ cho em xin tham kháº£o vá»: TÃ i liá»‡u ML, cá»¥ thá»ƒ lÃ  cÃ¡c ná»n táº£ng vá» ToÃ¡n, Thá»‘ng KÃª cáº§n thiáº¿t cho ngÃ nh CÃ¡c dá»± Ã¡n cÃ¡ nhÃ¢n Ä‘á»ƒ bá» vÃ´ portfolio cáº§n thá»ƒ hiá»‡n kiáº¿n thá»©c á»Ÿ máº£ng nÃ o Sinh viÃªn cÃ³ thá»ƒ cÃ³ paper tá»‘t khÃ´ng? LÃ m sao Ä‘á»ƒ báº¯t Ä‘áº§u nghiÃªn cá»©u lÃ m paper? Hiá»‡n táº¡i em Ä‘ang lÃ m paper á»©ng dá»¥ng ML trong viá»‡c dá»± bÃ¡o, váº«n lÃ  Regression báº±ng cÃ¡ch dÃ¹ng library, nhÆ°ng em tháº¥y cÃ¡ch lÃ m nÃ y Ä‘Æ¡n giáº£n, khÃ´ng chuyÃªn sÃ¢u vÃ  chá»‰ cáº§n nghiÃªn cá»©u chÃºt lÃ  cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c.",,,,,"#Q&A, #machine_learning"
"Xin há»i:
MÃ¬nh Ä‘ang lÃ m cho má»™t startup vá» thá»i trang, vÃ  Ä‘ang tÃ¬m kiáº¿m giáº£i phÃ¡p Ä‘á»c má»™t hÃ¬nh, xem trong hÃ¬nh Ä‘Ã³ ngÆ°á»i dÃ¹ng máº·t Ã¡o quáº§n gÃ¬.
ÄÆ¡n giáº£n hÆ¡n lÃ  cho hai bá»©c hÃ¬nh, tráº£ láº¡i xÃ¡c xuáº¥t hai bá»©c hÃ¬nh Ä‘Ã³ cÃ³ cÃ¹ng má»™t loáº¡i váº­t thá»ƒ .
Náº¿u pháº£i xÃ¢y dá»±ng training data thÃ¬ cáº§n cá»¡ bao nhiÃªu training data Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh kiá»ƒu nÃ y. 100k Ä‘á»§ khÃ´ng ?","Xin há»i: MÃ¬nh Ä‘ang lÃ m cho má»™t startup vá» thá»i trang, vÃ  Ä‘ang tÃ¬m kiáº¿m giáº£i phÃ¡p Ä‘á»c má»™t hÃ¬nh, xem trong hÃ¬nh Ä‘Ã³ ngÆ°á»i dÃ¹ng máº·t Ã¡o quáº§n gÃ¬. ÄÆ¡n giáº£n hÆ¡n lÃ  cho hai bá»©c hÃ¬nh, tráº£ láº¡i xÃ¡c xuáº¥t hai bá»©c hÃ¬nh Ä‘Ã³ cÃ³ cÃ¹ng má»™t loáº¡i váº­t thá»ƒ . Náº¿u pháº£i xÃ¢y dá»±ng training data thÃ¬ cáº§n cá»¡ bao nhiÃªu training data Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh kiá»ƒu nÃ y. 100k Ä‘á»§ khÃ´ng ?",,,,,"#Q&A, #data, #cv"
"#nlp #question #documentclustering
ChÃ o má»i ngÆ°á»i, Em Ä‘ang cáº§n thá»±c hiá»‡n bÃ i toÃ¡n phÃ¢n cá»¥m vÄƒn báº£n, bÃ i bÃ¡o,... ( document clustering) vá»›i sá»‘ cá»¥m khÃ´ng xÃ¡c Ä‘á»‹nh trÆ°á»›c. Vá» pháº§n phÃ¢n cá»¥m sá»­ dá»¥ng DBSCAN em Ä‘Ã£ hiá»ƒu vÃ  tháº¥y ok. Tuy nhiÃªn pháº§n embedding vÄƒn báº£n, em muá»‘n tham kháº£o Ã½ kiáº¿n má»i ngÆ°á»i phÆ°Æ¡ng phÃ¡p nÃ o tá»‘t nháº¥t hiá»‡n nay. Em Ä‘Æ°á»£c biáº¿t vá» pháº§n cÃ¢u cÃ³ cÃ¡c mÃ´ hÃ¬nh sentence embedding káº¿t quáº£ khÃ¡ ok nhÆ° sbert,... Tuy nhiÃªn vá»›i cáº£ vÄƒn báº£n dÃ i thÃ¬ em tÃ¬m hiá»ƒu khÃ´ng tháº¥y cÃ³ nhiá»u thÃ´ng tin. Mong má»i ngÆ°á»i cho Ã½ kiáº¿n vá» giáº£i phÃ¡p hoáº·c cÃ¡c keyword, bÃ i viáº¿t liÃªn quan Ä‘á»ƒ em tÃ¬m hiá»ƒu áº¡.  Em cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, Em Ä‘ang cáº§n thá»±c hiá»‡n bÃ i toÃ¡n phÃ¢n cá»¥m vÄƒn báº£n, bÃ i bÃ¡o,... ( document clustering) vá»›i sá»‘ cá»¥m khÃ´ng xÃ¡c Ä‘á»‹nh trÆ°á»›c. Vá» pháº§n phÃ¢n cá»¥m sá»­ dá»¥ng DBSCAN em Ä‘Ã£ hiá»ƒu vÃ  tháº¥y ok. Tuy nhiÃªn pháº§n embedding vÄƒn báº£n, em muá»‘n tham kháº£o Ã½ kiáº¿n má»i ngÆ°á»i phÆ°Æ¡ng phÃ¡p nÃ o tá»‘t nháº¥t hiá»‡n nay. Em Ä‘Æ°á»£c biáº¿t vá» pháº§n cÃ¢u cÃ³ cÃ¡c mÃ´ hÃ¬nh sentence embedding káº¿t quáº£ khÃ¡ ok nhÆ° sbert,... Tuy nhiÃªn vá»›i cáº£ vÄƒn báº£n dÃ i thÃ¬ em tÃ¬m hiá»ƒu khÃ´ng tháº¥y cÃ³ nhiá»u thÃ´ng tin. Mong má»i ngÆ°á»i cho Ã½ kiáº¿n vá» giáº£i phÃ¡p hoáº·c cÃ¡c keyword, bÃ i viáº¿t liÃªn quan Ä‘á»ƒ em tÃ¬m hiá»ƒu áº¡. Em cáº£m Æ¡n",#nlp	#question	#documentclustering,,,,"#Q&A, #nlp, #deep_learning, #machine_learning"
"Hi má»i ngÆ°á»i, mÃ¬nh cÃ³ má»™t tháº¯c máº¯c muá»‘n nhá» má»i ngÆ°á»i giáº£i thÃ­ch giÃºp vá»›i.
MÃ¬nh Ä‘ang thá»±c hiá»‡n má»™t dá»± Ã¡n cÃ¡ nhÃ¢n, trong Ä‘Ã³ cÃ³ má»™t pháº§n xá»­ lÃ½ Ä‘á»c cÃ¡c kÃ½ tá»± chá»¯ sá»‘ trÃªn máº·t Ä‘á»“ng há»“. Framework mÃ¬nh xá»­ dá»¥ng lÃ  detectron2.
Khi mÃ¬nh training vÃ  predict thá»­ trÃªn 2 version khÃ¡c nhau lÃ  0.6 vÃ  0.1.3 thÃ¬ káº¿t quáº£ lÃ  version 0.1.3 mÃ¬nh tháº¥y tá»‘c Ä‘á»™ há»™i tá»¥ hanh hÆ¡n nhiá»u, chá»‰ cáº§n training 2000 iter vá»›i dataset 1300/150 lÃ  Ä‘Ã£ cho káº¿t quáº£ ráº¥t áº¥n tÆ°á»£ng rá»“i. Trong khi mÃ¬nh training trÃªn báº£n 0.6 vá»›i táº­p dataset lá»›n hÆ¡n 1 chÃºt 1600/250 vá»›i 80000 iter nhÆ°ng káº¿t quáº£ tá»‘c Ä‘á»™ há»™i tá»¥ khÃ´ng á»•n Ä‘á»‹nh, nhiá»u sá»‘ khÃ´ng thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c. KhÃ´ng rÃµ cÃ³ ai gáº·p pháº£i tÃ¬nh tráº¡ng nhÆ° mÃ¬nh khÃ´ng váº­y?","Hi má»i ngÆ°á»i, mÃ¬nh cÃ³ má»™t tháº¯c máº¯c muá»‘n nhá» má»i ngÆ°á»i giáº£i thÃ­ch giÃºp vá»›i. MÃ¬nh Ä‘ang thá»±c hiá»‡n má»™t dá»± Ã¡n cÃ¡ nhÃ¢n, trong Ä‘Ã³ cÃ³ má»™t pháº§n xá»­ lÃ½ Ä‘á»c cÃ¡c kÃ½ tá»± chá»¯ sá»‘ trÃªn máº·t Ä‘á»“ng há»“. Framework mÃ¬nh xá»­ dá»¥ng lÃ  detectron2. Khi mÃ¬nh training vÃ  predict thá»­ trÃªn 2 version khÃ¡c nhau lÃ  0.6 vÃ  0.1.3 thÃ¬ káº¿t quáº£ lÃ  version 0.1.3 mÃ¬nh tháº¥y tá»‘c Ä‘á»™ há»™i tá»¥ hanh hÆ¡n nhiá»u, chá»‰ cáº§n training 2000 iter vá»›i dataset 1300/150 lÃ  Ä‘Ã£ cho káº¿t quáº£ ráº¥t áº¥n tÆ°á»£ng rá»“i. Trong khi mÃ¬nh training trÃªn báº£n 0.6 vá»›i táº­p dataset lá»›n hÆ¡n 1 chÃºt 1600/250 vá»›i 80000 iter nhÆ°ng káº¿t quáº£ tá»‘c Ä‘á»™ há»™i tá»¥ khÃ´ng á»•n Ä‘á»‹nh, nhiá»u sá»‘ khÃ´ng thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c. KhÃ´ng rÃµ cÃ³ ai gáº·p pháº£i tÃ¬nh tráº¡ng nhÆ° mÃ¬nh khÃ´ng váº­y?",,,,,"#Q&A, #cv, #deep_learning"
"ğŸ¤–ğŸ¤–ğŸ¤– ChatGPT Ä‘ang lÃ m mÆ°a lÃ m giÃ³ trÃªn toÃ n tháº¿ giá»›i nhá»¯ng ngÃ y vá»«a qua. HÃ£y cÃ¹ng team NeuralVN tÃ¬m hiá»ƒu vá» cÃ´ng nghá»‡ phÃ­a sau chatbot Ä‘Ã¬nh Ä‘Ã¡m nÃ y qua bÃ i viáº¿t ""BÃ­ máº­t cÃ´ng nghá»‡ Ä‘áº±ng sau ChatGPT"".","ChatGPT Ä‘ang lÃ m mÆ°a lÃ m giÃ³ trÃªn toÃ n tháº¿ giá»›i nhá»¯ng ngÃ y vá»«a qua. HÃ£y cÃ¹ng team NeuralVN tÃ¬m hiá»ƒu vá» cÃ´ng nghá»‡ phÃ­a sau chatbot Ä‘Ã¬nh Ä‘Ã¡m nÃ y qua bÃ i viáº¿t ""BÃ­ máº­t cÃ´ng nghá»‡ Ä‘áº±ng sau ChatGPT"".",,,,,#sharing
"ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang tÃ¬m hiá»ƒu vá» AdaDelta optimizer, cÃ³ má»™t Ä‘oáº¡n em váº«n chÆ°a hiá»ƒu Ä‘Ã³ lÃ  trong paper, tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p vá» sá»± khÃ´ng thá»‘ng nháº¥t trong Ä‘Æ¡n vá»‹ vÃ  Ä‘Æ°a ra giáº£i phÃ¡p Ä‘á» xuáº¥t. Tuy nhiÃªn em váº«n chÆ°a thá»ƒ nÃ o hÃ¬nh dung Ä‘Æ°á»£c sá»± sai lá»‡ch vá» Ä‘Æ¡n vá»‹ nÃ y lÃ  nhÆ° tháº¿ nÃ o máº·c dÃ¹ Ä‘Ã£ search vÃ  Ä‘á»c thÃªm tá»« nhiá»u nguá»“n. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t vÃ­ dá»¥ cá»¥ thá»ƒ hay má»™t giáº£i thÃ­ch trá»±c quan vá»›i áº¡.
ÄÃ¢y lÃ  paper em Ä‘ang Ä‘á»c, Ä‘á» cáº­p vá» Ä‘Æ¡n vá»‹ á»Ÿ pháº§n 3.2 (trang 3) : https://arxiv.org/pdf/1212.5701.pdf
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m, chÃºc má»i ngÆ°á»i má»™t ngÃ y tá»‘t lÃ nh.","ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang tÃ¬m hiá»ƒu vá» AdaDelta optimizer, cÃ³ má»™t Ä‘oáº¡n em váº«n chÆ°a hiá»ƒu Ä‘Ã³ lÃ  trong paper, tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p vá» sá»± khÃ´ng thá»‘ng nháº¥t trong Ä‘Æ¡n vá»‹ vÃ  Ä‘Æ°a ra giáº£i phÃ¡p Ä‘á» xuáº¥t. Tuy nhiÃªn em váº«n chÆ°a thá»ƒ nÃ o hÃ¬nh dung Ä‘Æ°á»£c sá»± sai lá»‡ch vá» Ä‘Æ¡n vá»‹ nÃ y lÃ  nhÆ° tháº¿ nÃ o máº·c dÃ¹ Ä‘Ã£ search vÃ  Ä‘á»c thÃªm tá»« nhiá»u nguá»“n. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t vÃ­ dá»¥ cá»¥ thá»ƒ hay má»™t giáº£i thÃ­ch trá»±c quan vá»›i áº¡. ÄÃ¢y lÃ  paper em Ä‘ang Ä‘á»c, Ä‘á» cáº­p vá» Ä‘Æ¡n vá»‹ á»Ÿ pháº§n 3.2 (trang 3) : https://arxiv.org/pdf/1212.5701.pdf Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m, chÃºc má»i ngÆ°á»i má»™t ngÃ y tá»‘t lÃ nh.",,,,,"#Q&A, #deep_learning"
"ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang cÃ³ má»™t tháº¯c máº¯c vá» Ã½ nghÄ©a cá»§a viá»‡c chuáº©n hÃ³a phÃ¢n phá»‘i cá»§a data vá» dáº¡ng phÃ¢n phá»‘i chuáº©n. 
CÃ³ má»™t cÃ¢u tráº£ lá»i á»Ÿ Ä‘Ã¢y mÃ  em Ä‘ang quan tÃ¢m : https://www.quora.com/Why-in-machine-learning-do-lots-of-people-want-to-convert-skewed-data-into-normal-distribution
TÃ¡c giáº£ nÃ³i ráº±ng, giáº£ sá»­ dá»¯ liá»‡u cá»§a chÃºng ta tuÃ¢n theo hÃ m y = f(x) + e vá»›i f(x) lÃ  má»™t hÃ m sá»‘ cá»‘ Ä‘á»‹nh vÃ  e lÃ  biáº¿n ngáº«u nhiÃªn tuÃ¢n theo phÃ¢n phá»‘i chuáº©n, tÃ¡c giáº£ chá»‰ ra viá»‡c chuyá»ƒn data vá» pp chuáº©n giÃºp cho e khÃ´ng phá»¥ thuá»™c vÃ o dá»¯ liá»‡u ná»¯a, tá»©c lÃ  e Ä‘ang Ä‘á»™c láº­p vÃ  cÃ³ mean báº±ng 0, náº¿u e khÃ´ng Ä‘á»™c láº­p tá»©c lÃ  e = bias + t vá»›i t lÃ  biáº¿n ngáº«u nhiÃªn Ä‘á»™c láº­p cÃ³ mean = 0. Tuy nhiÃªn láº¥y vÃ­ dá»¥ trong linear regression, máº·t pháº³ng cáº§n tÃ¬m cÃ³ dáº¡ng nhÆ° w1x1 + w2x2 + b, thÃ¬ rÃµ rÃ ng lÃ  mÃ¬nh Ä‘Ã£ cÃ³ thÃ nh pháº§n bias trong Ä‘Ã¢y rá»“i, tháº¿ thÃ¬ em má»›i náº£y ra 2 cÃ¢u há»i nhÆ° sau :
NhÆ° Ä‘Ã£ nÃ³i á»Ÿ trÃªn thÃ¬ cÃ³ pháº£i nhá»¯ng thuáº­t tÆ°Æ¡ng tá»± nhÆ° linear regression khÃ´ng cáº§n chuyá»ƒn vá» pp chuáº©n ?
XÃ©t cÃ¡c trÆ°á»ng há»£p khÃ¡c, náº¿u ta Ä‘Ã£ chuyá»ƒn pp dá»¯ liá»‡u vá» pp chuáº©n thÃ¬ khÃ´ng cáº§n thÃ nh pháº§n bias ?
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m, chÃºc má»i ngÆ°á»i má»™t ngÃ y tá»‘t lÃ nh","ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang cÃ³ má»™t tháº¯c máº¯c vá» Ã½ nghÄ©a cá»§a viá»‡c chuáº©n hÃ³a phÃ¢n phá»‘i cá»§a data vá» dáº¡ng phÃ¢n phá»‘i chuáº©n. CÃ³ má»™t cÃ¢u tráº£ lá»i á»Ÿ Ä‘Ã¢y mÃ  em Ä‘ang quan tÃ¢m : https://www.quora.com/Why-in-machine-learning-do-lots-of-people-want-to-convert-skewed-data-into-normal-distribution TÃ¡c giáº£ nÃ³i ráº±ng, giáº£ sá»­ dá»¯ liá»‡u cá»§a chÃºng ta tuÃ¢n theo hÃ m y = f(x) + e vá»›i f(x) lÃ  má»™t hÃ m sá»‘ cá»‘ Ä‘á»‹nh vÃ  e lÃ  biáº¿n ngáº«u nhiÃªn tuÃ¢n theo phÃ¢n phá»‘i chuáº©n, tÃ¡c giáº£ chá»‰ ra viá»‡c chuyá»ƒn data vá» pp chuáº©n giÃºp cho e khÃ´ng phá»¥ thuá»™c vÃ o dá»¯ liá»‡u ná»¯a, tá»©c lÃ  e Ä‘ang Ä‘á»™c láº­p vÃ  cÃ³ mean báº±ng 0, náº¿u e khÃ´ng Ä‘á»™c láº­p tá»©c lÃ  e = bias + t vá»›i t lÃ  biáº¿n ngáº«u nhiÃªn Ä‘á»™c láº­p cÃ³ mean = 0. Tuy nhiÃªn láº¥y vÃ­ dá»¥ trong linear regression, máº·t pháº³ng cáº§n tÃ¬m cÃ³ dáº¡ng nhÆ° w1x1 + w2x2 + b, thÃ¬ rÃµ rÃ ng lÃ  mÃ¬nh Ä‘Ã£ cÃ³ thÃ nh pháº§n bias trong Ä‘Ã¢y rá»“i, tháº¿ thÃ¬ em má»›i náº£y ra 2 cÃ¢u há»i nhÆ° sau : NhÆ° Ä‘Ã£ nÃ³i á»Ÿ trÃªn thÃ¬ cÃ³ pháº£i nhá»¯ng thuáº­t tÆ°Æ¡ng tá»± nhÆ° linear regression khÃ´ng cáº§n chuyá»ƒn vá» pp chuáº©n ? XÃ©t cÃ¡c trÆ°á»ng há»£p khÃ¡c, náº¿u ta Ä‘Ã£ chuyá»ƒn pp dá»¯ liá»‡u vá» pp chuáº©n thÃ¬ khÃ´ng cáº§n thÃ nh pháº§n bias ? Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m, chÃºc má»i ngÆ°á»i má»™t ngÃ y tá»‘t lÃ nh",,,,,"#Q&A, #math, #machine_learning"
BÃ¡c nÃ o gá»£i Ã½ giÃºp mÃ¬nh cÃ¡i cloud nÃ o train tá»‘t vá»›i chá»© gg colab cháº¡y thháº¿ kia bao giá» má»›i xong :3,BÃ¡c nÃ o gá»£i Ã½ giÃºp mÃ¬nh cÃ¡i cloud nÃ o train tá»‘t vá»›i chá»© gg colab cháº¡y thháº¿ kia bao giá» má»›i xong :3,,,,,#Q&A
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh lÃ  láº­p trÃ¬nh viÃªn khÃ´ng chuyÃªn AI, ML nhÆ°ng muá»‘n vá»c váº¡ch tÃ½ nÃªn cÃ³ dá»± Ä‘á»‹nh lÃ m há»‡ thá»‘ng phÃ¢n loáº¡i tÃ i liá»‡u.
MÃ¬nh Ä‘ang cÃ³ hÃ ng TB tÃ i liá»‡u Ä‘á»ƒ lá»™n xá»™n, nhiá»u Ä‘á»‹nh dáº¡ng khÃ¡c nhau, cÃ²n bá»‹ trÃ¹ng láº·p do tÃªn file khÃ¡c nhau vÃ¬ download á»Ÿ nhiá»u nguá»“n.
Nay mÃ¬nh muá»‘n phÃ¡t triá»ƒn tool tá»± Ä‘á»™ng phÃ¢n loáº¡i rá»“i gom chÃºng vÃ o cÃ¡c thÆ° má»¥c phÃ¢n theo thá»ƒ loáº¡i.
Nhá» má»i ngÆ°á»i váº¡ch ra giÃºp mÃ¬nh xem cáº§n há»c nhá»¯ng gÃ¬ vÃ  thá»±c hiá»‡n nhÆ° tháº¿ nÃ o?
MÃ¬nh cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, MÃ¬nh lÃ  láº­p trÃ¬nh viÃªn khÃ´ng chuyÃªn AI, ML nhÆ°ng muá»‘n vá»c váº¡ch tÃ½ nÃªn cÃ³ dá»± Ä‘á»‹nh lÃ m há»‡ thá»‘ng phÃ¢n loáº¡i tÃ i liá»‡u. MÃ¬nh Ä‘ang cÃ³ hÃ ng TB tÃ i liá»‡u Ä‘á»ƒ lá»™n xá»™n, nhiá»u Ä‘á»‹nh dáº¡ng khÃ¡c nhau, cÃ²n bá»‹ trÃ¹ng láº·p do tÃªn file khÃ¡c nhau vÃ¬ download á»Ÿ nhiá»u nguá»“n. Nay mÃ¬nh muá»‘n phÃ¡t triá»ƒn tool tá»± Ä‘á»™ng phÃ¢n loáº¡i rá»“i gom chÃºng vÃ o cÃ¡c thÆ° má»¥c phÃ¢n theo thá»ƒ loáº¡i. Nhá» má»i ngÆ°á»i váº¡ch ra giÃºp mÃ¬nh xem cáº§n há»c nhá»¯ng gÃ¬ vÃ  thá»±c hiá»‡n nhÆ° tháº¿ nÃ o? MÃ¬nh cáº£m Æ¡n.",,,,,"#Q&A, #nlp"
"[Final Project - Machine Learning In Production - MLOps]
[Implement MLOps for Credit Risk scoring in Banking]
This is a final project thesis about â€œBanking Credit Riskâ€ of â€œcourse 5 - Machine Learning in Production â€“ MLOpsâ€, which was implemented by young excellent students: Tran Thi Hoang Anh, Le Thi Duyen, Nguyen Bui Hoang Long.
One of my students asked me: Dear teacher, I am in the banking sector, it is really necessary to train credit risk models on a regular time base because the economic context is constantly shifting time by time. Usually, implementing these banking models according to traditional ways is difficult and brain-teasing due to manually handling Machine Learning steps. Then, I responded why don't you think about MLOps? Maybe, MLOps is a perfect remedy to overcome these hurts efficiently.
In this final project thesis, my student group has carried out a lot of experiments in terms of models and data feature engineering to boost model performance on the training dataset whilst still considerably assured the model latency as well as computational cost. Thanks to accelerating the MLOps lifecycle, models are updated with the daily dataset without imposing model degradation.
It is an enjoyable feeling mixed with mild pride when my students were able to comprehend MLOps methodologies and competently handle Banking risk models.","[Final Project - Machine Learning In Production - MLOps] [Implement MLOps for Credit Risk scoring in Banking] This is a final project thesis about â€œBanking Credit Riskâ€ of â€œcourse 5 - Machine Learning in Production â€“ MLOpsâ€, which was implemented by young excellent students: Tran Thi Hoang Anh, Le Thi Duyen, Nguyen Bui Hoang Long. One of my students asked me: Dear teacher, I am in the banking sector, it is really necessary to train credit risk models on a regular time base because the economic context is constantly shifting time by time. Usually, implementing these banking models according to traditional ways is difficult and brain-teasing due to manually handling Machine Learning steps. Then, I responded why don't you think about MLOps? Maybe, MLOps is a perfect remedy to overcome these hurts efficiently. In this final project thesis, my student group has carried out a lot of experiments in terms of models and data feature engineering to boost model performance on the training dataset whilst still considerably assured the model latency as well as computational cost. Thanks to accelerating the MLOps lifecycle, models are updated with the daily dataset without imposing model degradation. It is an enjoyable feeling mixed with mild pride when my students were able to comprehend MLOps methodologies and competently handle Banking risk models.",,,,,bá»
"Anh em Ä‘ang há»c hoáº·c Ä‘Ã£ lÃ m thÃ¬ cÃ¹ng mÃ¬nh trao Ä‘á»•i 1 sá»‘ cÃ¢u há»i vá» CV nhÃ©:
Táº¡i sao Yolov8 pretrained task object detection báº±ng táº­p COCO, trong khi task classification láº¡i dÃ¹ng táº­p ImageNet. CÃ¢u há»i váº­n dá»¥ng lÃ  náº¿u mÃ¬nh cÃ³ 1 bÃ i toÃ¡n Ä‘áº§u vÃ o áº£nh grayscale cho task object detection thÃ¬ viá»‡c dÃ¹ng pretrain trÃªn táº­p COCO cÃ³ hiá»‡u quáº£ báº±ng viá»‡c dÃ¹ng bá»™ dataset grayscale khÃ¡c ( nhÆ° mnist) hay khÃ´ng ?
Viá»‡c chá»n backbone khi xÃ¢y dá»±ng model thÃ¬ nÃªn dá»±a vÃ o yáº¿u tá»‘ nÃ o ?
LÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ viá»‡c data  agumentation thá»§ cÃ´ng cÃ³ hiá»‡u quáº£ hÆ¡n so vá»›i dÃ¹ng cÃ³ sáºµn cá»§a yolo ?","Anh em Ä‘ang há»c hoáº·c Ä‘Ã£ lÃ m thÃ¬ cÃ¹ng mÃ¬nh trao Ä‘á»•i 1 sá»‘ cÃ¢u há»i vá» CV nhÃ©: Táº¡i sao Yolov8 pretrained task object detection báº±ng táº­p COCO, trong khi task classification láº¡i dÃ¹ng táº­p ImageNet. CÃ¢u há»i váº­n dá»¥ng lÃ  náº¿u mÃ¬nh cÃ³ 1 bÃ i toÃ¡n Ä‘áº§u vÃ o áº£nh grayscale cho task object detection thÃ¬ viá»‡c dÃ¹ng pretrain trÃªn táº­p COCO cÃ³ hiá»‡u quáº£ báº±ng viá»‡c dÃ¹ng bá»™ dataset grayscale khÃ¡c ( nhÆ° mnist) hay khÃ´ng ? Viá»‡c chá»n backbone khi xÃ¢y dá»±ng model thÃ¬ nÃªn dá»±a vÃ o yáº¿u tá»‘ nÃ o ? LÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ viá»‡c data agumentation thá»§ cÃ´ng cÃ³ hiá»‡u quáº£ hÆ¡n so vá»›i dÃ¹ng cÃ³ sáºµn cá»§a yolo ?",,,,,"#Q&A, #data, #deep_learning, #cv"
"Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t tÃ i liá»‡u Ä‘Æ°á»£c viáº¿t bá»Ÿi 2 giÃ¡o sÆ° hÃ ng Ä‘áº§u cá»§a Stanford University, Prof. Jure Leskovec & Prof. Jeffrey D. Ullman, vÃ  cÃ¹ng má»™t entrepreneur ná»•i tiáº¿ng cá»§a Thung LÅ©ng Silicon Anand Rajaraman, vá» chá»§ Ä‘á» ""Mining Massive Data"". SÃ¡ch xoay quanh nhá»¯ng phÆ°Æ¡ng phÃ¡p khai thÃ¡c dá»¯ liá»‡u hiá»‡u quáº£, chÃ­nh xÃ¡c, vÃ  nhanh chÃ³ng. Link sÃ¡ch: http://www.mmds.org/, Link course: https://online.stanford.edu/courses/soe-ycs0007-mining-massive-data-sets
Äá»“ng thá»i, xin chia sáº» luÃ´n má»™t cuá»‘n sÃ¡ch cÃ¹ng chá»§ Ä‘á» Data Mining nhÆ°ng Ä‘Æ°á»£c viáº¿t theo hÆ°á»›ng á»©ng dá»¥ng hÆ¡n kÃ¨m code do Dr. Ron Zacharski chia sáº» kinh nghiá»‡m cá»§a Ã´ng miá»…n phÃ­ cho cá»™ng Ä‘á»“ng: http://guidetodatamining.com/","Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t tÃ i liá»‡u Ä‘Æ°á»£c viáº¿t bá»Ÿi 2 giÃ¡o sÆ° hÃ ng Ä‘áº§u cá»§a Stanford University, Prof. Jure Leskovec & Prof. Jeffrey D. Ullman, vÃ  cÃ¹ng má»™t entrepreneur ná»•i tiáº¿ng cá»§a Thung LÅ©ng Silicon Anand Rajaraman, vá» chá»§ Ä‘á» ""Mining Massive Data"". SÃ¡ch xoay quanh nhá»¯ng phÆ°Æ¡ng phÃ¡p khai thÃ¡c dá»¯ liá»‡u hiá»‡u quáº£, chÃ­nh xÃ¡c, vÃ  nhanh chÃ³ng. Link sÃ¡ch: http://www.mmds.org/, Link course: https://online.stanford.edu/courses/soe-ycs0007-mining-massive-data-sets Äá»“ng thá»i, xin chia sáº» luÃ´n má»™t cuá»‘n sÃ¡ch cÃ¹ng chá»§ Ä‘á» Data Mining nhÆ°ng Ä‘Æ°á»£c viáº¿t theo hÆ°á»›ng á»©ng dá»¥ng hÆ¡n kÃ¨m code do Dr. Ron Zacharski chia sáº» kinh nghiá»‡m cá»§a Ã´ng miá»…n phÃ­ cho cá»™ng Ä‘á»“ng: http://guidetodatamining.com/",,,,,"#Q&A, #data"
"Äá»£t vá»«a rá»“i mÃ¬nh vÃ  team cÃ³ tham gia má»™t cuá»™c thi vá» trÃ­ch xuáº¥t thÃ´ng tin tá»« hÃ³a Ä‘Æ¡n cÃ³ tÃªn gá»i lÃ  The Mobile capture receipts Optical Character Recognition (MC-OCR).
MÃ¬nh cÃ³ má»™t bÃ i viáº¿t chia sáº» vá» giáº£i phÃ¡p cá»§a team mÃ¬nh, má»i ngÆ°á»i tham kháº£o vÃ  gÃ³p Ã½ áº¡.","Äá»£t vá»«a rá»“i mÃ¬nh vÃ  team cÃ³ tham gia má»™t cuá»™c thi vá» trÃ­ch xuáº¥t thÃ´ng tin tá»« hÃ³a Ä‘Æ¡n cÃ³ tÃªn gá»i lÃ  The Mobile capture receipts Optical Character Recognition (MC-OCR). MÃ¬nh cÃ³ má»™t bÃ i viáº¿t chia sáº» vá» giáº£i phÃ¡p cá»§a team mÃ¬nh, má»i ngÆ°á»i tham kháº£o vÃ  gÃ³p Ã½ áº¡.",,,,,"#sharing, #cv"
Má»i ngÆ°á»i cho e há»i. Em Ä‘á»‹nh encode dá»¯ liá»‡u náº¿n nháº­t Ä‘á»ƒ train CNN phÃ¢n loáº¡i máº«u hÃ¬nh thÃ¬ liá»‡u cÃ³ hiá»‡u quáº£ khÃ´ng áº¡. CÃ³ paper hay dá»± Ã¡n nÃ o lÃ m r chÆ°a áº¡?,Má»i ngÆ°á»i cho e há»i. Em Ä‘á»‹nh encode dá»¯ liá»‡u náº¿n nháº­t Ä‘á»ƒ train CNN phÃ¢n loáº¡i máº«u hÃ¬nh thÃ¬ liá»‡u cÃ³ hiá»‡u quáº£ khÃ´ng áº¡. CÃ³ paper hay dá»± Ã¡n nÃ o lÃ m r chÆ°a áº¡?,,,,,"#Q&A, #cv, #deep_learning"
"[Data-Centric AI Course]
ThÃ´ng thÆ°á»ng cÃ¡c khÃ³a há»c vá» Machine Learning sáº½ dáº¡y nhiá»u vá» cÃ¡c mÃ´ hÃ¬nh. Tuy nhiÃªn khi lÃ m viá»‡c trong mÃ´i trÆ°á»ng thá»±c táº¿, dá»¯ liá»‡u thÆ°á»ng nhiá»…u vÃ  há»—n Ä‘á»™n (messy), tháº¿ nÃªn bÃªn cáº¡nh viá»‡c cáº£i thiá»‡n mÃ´ hÃ¬nh, chÃºng ta cÅ©ng nÃªn táº­p trung vÃ o cáº£i thiá»‡n cÃ¡c váº¥n Ä‘á» cá»§a dá»¯ liá»‡u. Data-Centric AI (DCAI) lÃ  hÆ°á»›ng nghiÃªn cá»©u má»›i, táº­p trung vÃ o viá»‡c cáº£i thiá»‡n dá»¯ liá»‡u Ä‘á»ƒ tÄƒng Ä‘á»™ hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh.
KhÃ³a nÃ y dáº¡y cÃ¡c báº¡n giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» vá» dá»¯ liá»‡u trong cÃ¡c project thá»±c táº¿ nhÆ°:
- Data-Centric AI vs. Model-Centric AI
- Label Errors
- Dataset Creation and Curation
- Data-centric Evaluation of ML Models
- Class Imbalance, Outliers, and Distribution Shift
- Growing or Compressing Datasets
- Interpretability in Data-Centric ML
- Encoding Human Priors: Data Augmentation and Prompt Engineering
- Data Privacy and Security","[Data-Centric AI Course] ThÃ´ng thÆ°á»ng cÃ¡c khÃ³a há»c vá» Machine Learning sáº½ dáº¡y nhiá»u vá» cÃ¡c mÃ´ hÃ¬nh. Tuy nhiÃªn khi lÃ m viá»‡c trong mÃ´i trÆ°á»ng thá»±c táº¿, dá»¯ liá»‡u thÆ°á»ng nhiá»…u vÃ  há»—n Ä‘á»™n (messy), tháº¿ nÃªn bÃªn cáº¡nh viá»‡c cáº£i thiá»‡n mÃ´ hÃ¬nh, chÃºng ta cÅ©ng nÃªn táº­p trung vÃ o cáº£i thiá»‡n cÃ¡c váº¥n Ä‘á» cá»§a dá»¯ liá»‡u. Data-Centric AI (DCAI) lÃ  hÆ°á»›ng nghiÃªn cá»©u má»›i, táº­p trung vÃ o viá»‡c cáº£i thiá»‡n dá»¯ liá»‡u Ä‘á»ƒ tÄƒng Ä‘á»™ hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh. KhÃ³a nÃ y dáº¡y cÃ¡c báº¡n giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» vá» dá»¯ liá»‡u trong cÃ¡c project thá»±c táº¿ nhÆ°: - Data-Centric AI vs. Model-Centric AI - Label Errors - Dataset Creation and Curation - Data-centric Evaluation of ML Models - Class Imbalance, Outliers, and Distribution Shift - Growing or Compressing Datasets - Interpretability in Data-Centric ML - Encoding Human Priors: Data Augmentation and Prompt Engineering - Data Privacy and Security",,,,,"#sharing, #data"
"Ai Ä‘Ã£ lÃ m vá» há»‡ thá»‘ng Ä‘iá»ƒm danh báº±ng camera cho mÃ¬nh xin Ã½ kiáº¿n vá» Æ°u/nhÆ°á»£c Ä‘iá»ƒm (hoáº·c nÃªn/khÃ´ng nÃªn) vá» cÃ¡c phÆ°Æ¡ng hÆ°á»›ng sau:
1- Face_recognition
2- VGG + ArcFace
3- YOLO
4- gá»£i Ã½ thÃªm ğŸ˜…
Thank.",Ai Ä‘Ã£ lÃ m vá» há»‡ thá»‘ng Ä‘iá»ƒm danh báº±ng camera cho mÃ¬nh xin Ã½ kiáº¿n vá» Æ°u/nhÆ°á»£c Ä‘iá»ƒm (hoáº·c nÃªn/khÃ´ng nÃªn) vá» cÃ¡c phÆ°Æ¡ng hÆ°á»›ng sau: 1- Face_recognition 2- VGG + ArcFace 3- YOLO 4- gá»£i Ã½ thÃªm Thank.,,,,,"#Q&A, #cv, #deep_learning"
Em xin phÃ©p chia sáº» thÃ´ng tin vá» buá»•i webinar tá»‘i nay cho cÃ¡c bÃ¡c quan tÃ¢m tá»›i MLOps ğŸ˜,Em xin phÃ©p chia sáº» thÃ´ng tin vá» buá»•i webinar tá»‘i nay cho cÃ¡c bÃ¡c quan tÃ¢m tá»›i MLOps,,,,,#webinar
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Äá»£t nÃ y nhÃ¢n dá»‹p Ä‘ang quay láº¡i há»c Reinforcement Learrning nÃªn em máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ  1 video vá» ""Deep Q Learrning"".
Váº«n vá»›i phÆ°Æ¡ng chÃ¢m Ä‘Æ¡n giáº£n, hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em má»›i há»c thÃ´i!","KÃ­nh chÃ o cÃ¡c bÃ¡c. Äá»£t nÃ y nhÃ¢n dá»‹p Ä‘ang quay láº¡i há»c Reinforcement Learrning nÃªn em máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ  1 video vá» ""Deep Q Learrning"". Váº«n vá»›i phÆ°Æ¡ng chÃ¢m Ä‘Æ¡n giáº£n, hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em má»›i há»c thÃ´i!",,,,,"#sharing, #machine_learning"
"[ChatGPT for Google - Chrome Extension]
Plugin ChatGPT for Google nÃ y sáº½ giÃºp báº¡n hiá»‡n thá»‹ ná»™i dung tráº£ lá»i cá»§a ChatGPT cho ná»™i dung báº¡n tÃ¬m kiáº¿m bÃªn cáº¡nh káº¿t quáº£ tráº£ vá» cá»§a Google.
Vá»›i sá»©c máº¡nh cá»§a ChatGPT thÃ¬ Ä‘Ã¢y lÃ  má»™t tÃ­nh nÄƒng cá»±c kÃ¬ há»¯u Ã­ch cho ngÆ°á»i dÃ¹ng. VÃ­ dá»¥ nhÆ° tÃ¬m kiáº¿m cÃ¡c cÃ¢u há»i liÃªn quan tá»›i láº­p trÃ¬nh, ChatGPT sáº½ lÃ  báº£n tá»•ng há»£p cá»§a Stackoverflow, Github,.., khi cho báº¡n cáº£ cÃ¢u tráº£ lá»i vÃ  giáº£i thÃ­ch luÃ´n. NÃ³i chung giá» anh em dev cÅ©ng nhÃ n :)))
NhÆ° á»Ÿ dÆ°á»›i mÃ¬nh há»i cÃ¡ch váº½ Bar Graph trong Python, nÃ³ sinh ra cáº£ code cÃ³ cáº£ comment luÃ´n.","[ChatGPT for Google - Chrome Extension] Plugin ChatGPT for Google nÃ y sáº½ giÃºp báº¡n hiá»‡n thá»‹ ná»™i dung tráº£ lá»i cá»§a ChatGPT cho ná»™i dung báº¡n tÃ¬m kiáº¿m bÃªn cáº¡nh káº¿t quáº£ tráº£ vá» cá»§a Google. Vá»›i sá»©c máº¡nh cá»§a ChatGPT thÃ¬ Ä‘Ã¢y lÃ  má»™t tÃ­nh nÄƒng cá»±c kÃ¬ há»¯u Ã­ch cho ngÆ°á»i dÃ¹ng. VÃ­ dá»¥ nhÆ° tÃ¬m kiáº¿m cÃ¡c cÃ¢u há»i liÃªn quan tá»›i láº­p trÃ¬nh, ChatGPT sáº½ lÃ  báº£n tá»•ng há»£p cá»§a Stackoverflow, Github,.., khi cho báº¡n cáº£ cÃ¢u tráº£ lá»i vÃ  giáº£i thÃ­ch luÃ´n. NÃ³i chung giá» anh em dev cÅ©ng nhÃ n :))) NhÆ° á»Ÿ dÆ°á»›i mÃ¬nh há»i cÃ¡ch váº½ Bar Graph trong Python, nÃ³ sinh ra cáº£ code cÃ³ cáº£ comment luÃ´n.",,,,,#sharing
"Hi má»i ngÆ°á»i, em Ä‘Ã£ káº¿t thÃºc 6 thÃ¡ng intern AI Engineer vÃ  cáº£m tháº¥y chÃºt khÃ´ng há»£p do pháº§n lá»›n thá»i gian sáº½ sá»­ dá»¥ng Ä‘á»ƒ training mÃ´ hÃ¬nh. Hiá»‡n táº¡i em muá»‘n chuyá»ƒn hÆ°á»›ng sang Data Scientist hoáº·c SE nÃªn em muá»‘n há»i má»i ngÆ°á»i trong Group, cÃ´ng viá»‡c cá»§a 1 Data Scientist sáº½ lÃ m nhá»¯ng gÃ¬ vÃ  sáº½ dÃ nh nhiá»u thá»i gian lÃ m viá»‡c gÃ¬? Em thÃ¬ hay tháº¥y báº£o lÃ m Data Scientist á»Ÿ VN mÃ  chá»‰ tá»‘t nghiá»‡p Cá»­ nhÃ¢n/ Ká»¹ sÆ° thÃ¬ lÃ m khÃ´ng hiá»‡u quáº£, mong má»i ngÆ°á»i cho lá»i khuyÃªn.
Cáº£m Æ¡n má»i ngÆ°á»i.","Hi má»i ngÆ°á»i, em Ä‘Ã£ káº¿t thÃºc 6 thÃ¡ng intern AI Engineer vÃ  cáº£m tháº¥y chÃºt khÃ´ng há»£p do pháº§n lá»›n thá»i gian sáº½ sá»­ dá»¥ng Ä‘á»ƒ training mÃ´ hÃ¬nh. Hiá»‡n táº¡i em muá»‘n chuyá»ƒn hÆ°á»›ng sang Data Scientist hoáº·c SE nÃªn em muá»‘n há»i má»i ngÆ°á»i trong Group, cÃ´ng viá»‡c cá»§a 1 Data Scientist sáº½ lÃ m nhá»¯ng gÃ¬ vÃ  sáº½ dÃ nh nhiá»u thá»i gian lÃ m viá»‡c gÃ¬? Em thÃ¬ hay tháº¥y báº£o lÃ m Data Scientist á»Ÿ VN mÃ  chá»‰ tá»‘t nghiá»‡p Cá»­ nhÃ¢n/ Ká»¹ sÆ° thÃ¬ lÃ m khÃ´ng hiá»‡u quáº£, mong má»i ngÆ°á»i cho lá»i khuyÃªn. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,#Q&A
Em Ä‘ang lÃ m model nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng báº±ng CNN. Cháº¡y file train thÃ¬ nÃ³ Ä‘áº¿n epoch 446/2000 bá»‹ dá»«ng nhÆ° váº­y vÃ  káº¿t thÃºc chÆ°Æ¡ng trÃ¬nh luÃ´n. CÃ³ ai biáº¿t lá»—i nÃ y lÃ  lá»—i gÃ¬ vÃ  cÃ¡ch fix khÃ´ng áº¡.,Em Ä‘ang lÃ m model nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng báº±ng CNN. Cháº¡y file train thÃ¬ nÃ³ Ä‘áº¿n epoch 446/2000 bá»‹ dá»«ng nhÆ° váº­y vÃ  káº¿t thÃºc chÆ°Æ¡ng trÃ¬nh luÃ´n. CÃ³ ai biáº¿t lá»—i nÃ y lÃ  lá»—i gÃ¬ vÃ  cÃ¡ch fix khÃ´ng áº¡.,,,,,"#Q&A, #cv, #deep_learning"
"Xin chÃ o má»i ngÆ°á»i.
BÃ i toÃ¡n phÃ¢n loáº¡i hÃ¬nh áº£nh (image classification) lÃ  má»™t trong nhá»¯ng bÃ i toÃ¡n quan trá»ng trong lÄ©nh vá»±c Computer Vision. Má»™t cÃ¡ch giáº£i quyáº¿t hiá»‡u quáº£ cho bÃ i toÃ¡n nÃ y lÃ  sá»­ dá»¥ng kÄ© thuáº­t transfer learning vá»‘n khÃ´ng yÃªu cáº§u quÃ¡ nhiá»u vá» data hay resource mÃ  váº«n mang láº¡i káº¿t quáº£ tá»‘t. MÃ¬nh vá»«a xÃ¢y dá»±ng repository tá»•ng há»£p cÃ¡c thuáº­t image classification mÃ  pytorch cÃ³ há»— trá»£ transfer learning: Efficientnet, resnet, vgg, googlenet. NÃ³ cÃ³ thá»ƒ sáº½ há»¯u Ã­ch vá»›i cÃ¡c báº¡n má»›i tiáº¿p xÃºc vá»›i bÃ i toÃ¡n nÃ y, má»›i tiáº¿p xÃºc vá»›i pytorch hay Ä‘Æ¡n giáº£n muá»‘n sá»­ dá»¥ng code nhanh gá»n láº¹ Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n. Äá»‘i vá»›i nhá»¯ng báº¡n Ä‘Ã£ thÃ nh tháº¡o pytorch, muá»‘n custom model vÃ  data nhiá»u hÆ¡n thÃ¬ repo nÃ y cÃ³ váº» sáº½ kÃ©m há»¯u Ã­ch vá»›i cÃ¡c báº¡n.
Trong repo nÃ y sáº½ cÃ³ cÃ¡c pháº§n code:
- LÃ m tháº¿ nÃ o load data do mÃ¬nh tá»± thu tháº­p (custom dataset) vÃ o model.
- Thay Ä‘á»•i hÃ m loss, hÃ m optimize
- Train vÃ  predict trÃªn dá»¯ liá»‡u má»›i.
link:","Xin chÃ o má»i ngÆ°á»i. BÃ i toÃ¡n phÃ¢n loáº¡i hÃ¬nh áº£nh (image classification) lÃ  má»™t trong nhá»¯ng bÃ i toÃ¡n quan trá»ng trong lÄ©nh vá»±c Computer Vision. Má»™t cÃ¡ch giáº£i quyáº¿t hiá»‡u quáº£ cho bÃ i toÃ¡n nÃ y lÃ  sá»­ dá»¥ng kÄ© thuáº­t transfer learning vá»‘n khÃ´ng yÃªu cáº§u quÃ¡ nhiá»u vá» data hay resource mÃ  váº«n mang láº¡i káº¿t quáº£ tá»‘t. MÃ¬nh vá»«a xÃ¢y dá»±ng repository tá»•ng há»£p cÃ¡c thuáº­t image classification mÃ  pytorch cÃ³ há»— trá»£ transfer learning: Efficientnet, resnet, vgg, googlenet. NÃ³ cÃ³ thá»ƒ sáº½ há»¯u Ã­ch vá»›i cÃ¡c báº¡n má»›i tiáº¿p xÃºc vá»›i bÃ i toÃ¡n nÃ y, má»›i tiáº¿p xÃºc vá»›i pytorch hay Ä‘Æ¡n giáº£n muá»‘n sá»­ dá»¥ng code nhanh gá»n láº¹ Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n. Äá»‘i vá»›i nhá»¯ng báº¡n Ä‘Ã£ thÃ nh tháº¡o pytorch, muá»‘n custom model vÃ  data nhiá»u hÆ¡n thÃ¬ repo nÃ y cÃ³ váº» sáº½ kÃ©m há»¯u Ã­ch vá»›i cÃ¡c báº¡n. Trong repo nÃ y sáº½ cÃ³ cÃ¡c pháº§n code: - LÃ m tháº¿ nÃ o load data do mÃ¬nh tá»± thu tháº­p (custom dataset) vÃ o model. - Thay Ä‘á»•i hÃ m loss, hÃ m optimize - Train vÃ  predict trÃªn dá»¯ liá»‡u má»›i. link:",,,,,"#Q&A, #cv, #deep_learning"
ChÃ o má»i ngÆ°á»i. MÃ¬nh lÃ  newbie. MÃ¬nh Ä‘ang cÃ³ nhu cáº§u tÃ¬m hiá»ƒu vá» viá»‡c render 3D tá»« áº£nh chá»¥p selfie/camera Ä‘iá»‡n thoáº¡i thÃ nh Ä‘á»‘i tÆ°á»£ng cÃ³ thá»ƒ chá»‰nh sá»­a Ä‘Æ°á»£c. CÃ¡c báº¡n cho mÃ¬nh há»i mÃ¬nh nÃªn tÃ¬m hiá»ƒu theo hÆ°á»›ng nÃ o vÃ  keywords nÃ o nhÃ©. CÃ¡m Æ¡n cÃ¡c báº¡n Ä‘Ã£ giÃºp Ä‘á»¡,ChÃ o má»i ngÆ°á»i. MÃ¬nh lÃ  newbie. MÃ¬nh Ä‘ang cÃ³ nhu cáº§u tÃ¬m hiá»ƒu vá» viá»‡c render 3D tá»« áº£nh chá»¥p selfie/camera Ä‘iá»‡n thoáº¡i thÃ nh Ä‘á»‘i tÆ°á»£ng cÃ³ thá»ƒ chá»‰nh sá»­a Ä‘Æ°á»£c. CÃ¡c báº¡n cho mÃ¬nh há»i mÃ¬nh nÃªn tÃ¬m hiá»ƒu theo hÆ°á»›ng nÃ o vÃ  keywords nÃ o nhÃ©. CÃ¡m Æ¡n cÃ¡c báº¡n Ä‘Ã£ giÃºp Ä‘á»¡,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vÃ  thá»±c hiá»‡n bÃ i toÃ¡n Recommender system vá»›i mÃ´ hÃ¬nh VAE trÃªn táº­p dá»¯ liá»‡u MovieLens. Má»i ngÆ°á»i cho em há»i lÃ  sau khi xÃ¢y dá»±ng Ä‘Æ°á»£c utility matrix (chá»©a cÃ¡c rating tá»« 1 Ä‘áº¿n 5, vÃ  0 lÃ  giÃ¡ trá»‹ thá»ƒ hiá»‡n cho item chÆ°a Ä‘Æ°á»£c user Ä‘Ã¡nh giÃ¡) thÃ¬ khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh ta cÃ³ cáº§n bÆ°á»›c normalize khÃ´ng? VÃ  náº¿u pháº£i normalize thÃ¬ ta sáº½ chá»‰ normalize cÃ¡c giÃ¡ trá»‹ khÃ¡c 0 thÃ´i pháº£i khÃ´ng áº¡ (bá»Ÿi vÃ¬ má»¥c Ä‘Ã­ch cá»§a em lÃ  sáº½ khÃ´ng tÃ­nh toÃ¡n gradient trÃªn cÃ¡c giÃ¡ trá»‹ báº±ng 0 vÃ¬ cÃ¡c giÃ¡ trá»‹ nÃ y Ä‘á»ƒ cho pháº§n test)?","Em chÃ o má»i ngÆ°á»i áº¡ Hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vÃ  thá»±c hiá»‡n bÃ i toÃ¡n Recommender system vá»›i mÃ´ hÃ¬nh VAE trÃªn táº­p dá»¯ liá»‡u MovieLens. Má»i ngÆ°á»i cho em há»i lÃ  sau khi xÃ¢y dá»±ng Ä‘Æ°á»£c utility matrix (chá»©a cÃ¡c rating tá»« 1 Ä‘áº¿n 5, vÃ  0 lÃ  giÃ¡ trá»‹ thá»ƒ hiá»‡n cho item chÆ°a Ä‘Æ°á»£c user Ä‘Ã¡nh giÃ¡) thÃ¬ khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh ta cÃ³ cáº§n bÆ°á»›c normalize khÃ´ng? VÃ  náº¿u pháº£i normalize thÃ¬ ta sáº½ chá»‰ normalize cÃ¡c giÃ¡ trá»‹ khÃ¡c 0 thÃ´i pháº£i khÃ´ng áº¡ (bá»Ÿi vÃ¬ má»¥c Ä‘Ã­ch cá»§a em lÃ  sáº½ khÃ´ng tÃ­nh toÃ¡n gradient trÃªn cÃ¡c giÃ¡ trá»‹ báº±ng 0 vÃ¬ cÃ¡c giÃ¡ trá»‹ nÃ y Ä‘á»ƒ cho pháº§n test)?",,,,,
"Em xin chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n em Ä‘ang Ä‘á»‹nh thÃªm má»™t sá»‘ tá»« Ä‘á»ƒ tokenizer vÃ  em cÃ³ tham kháº£o má»™t sá»‘ cÃ¡ch vá»›i underthesea vÃ  vncorenlp nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch nÃ o kháº£ quan.
Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.
Em xin cáº£m Æ¡n áº¡!!!",Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang Ä‘á»‹nh thÃªm má»™t sá»‘ tá»« Ä‘á»ƒ tokenizer vÃ  em cÃ³ tham kháº£o má»™t sá»‘ cÃ¡ch vá»›i underthesea vÃ  vncorenlp nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch nÃ o kháº£ quan. Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡. Em xin cáº£m Æ¡n áº¡!!!,,,,,
"HÆ°á»›ng Dáº«n TÃ­ch Há»£p OpenAI GPT-3 vÃ o Web App vá»›i Streamlit
Chia sáº» vá»›i má»i ngÆ°á»i cÃ¡ch tÃ­ch há»£p OpenAI GPT-3 vÃ o Streamlit Ä‘á»ƒ táº¡o má»™t trá»£ lÃ½ cho chÃ­nh mÃ¬nh. Streamlit lÃ  cÃ´ng cá»¥ khÃ¡ quen thuá»™c vá»›i ai lÃ m AI Ä‘á»ƒ demo sáº£n pháº©m, Ä‘áº·c biá»‡t lÃ  nhá»¯ng ai khÃ´ng quen vá»›i HTML vÃ  CSS, chÃºng ta cÃ³ thá»ƒ custom dá»… dÃ ng. Hy vá»ng video sáº½ giÃºp Ã­ch Ä‘Æ°á»£c cho má»i ngÆ°á»i.
Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i.
https://youtu.be/E1I9mBcDQSo","HÆ°á»›ng Dáº«n TÃ­ch Há»£p OpenAI GPT-3 vÃ o Web App vá»›i Streamlit Chia sáº» vá»›i má»i ngÆ°á»i cÃ¡ch tÃ­ch há»£p OpenAI GPT-3 vÃ o Streamlit Ä‘á»ƒ táº¡o má»™t trá»£ lÃ½ cho chÃ­nh mÃ¬nh. Streamlit lÃ  cÃ´ng cá»¥ khÃ¡ quen thuá»™c vá»›i ai lÃ m AI Ä‘á»ƒ demo sáº£n pháº©m, Ä‘áº·c biá»‡t lÃ  nhá»¯ng ai khÃ´ng quen vá»›i HTML vÃ  CSS, chÃºng ta cÃ³ thá»ƒ custom dá»… dÃ ng. Hy vá»ng video sáº½ giÃºp Ã­ch Ä‘Æ°á»£c cho má»i ngÆ°á»i. Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i. https://youtu.be/E1I9mBcDQSo",,,,,
"ChÃ o cÃ¡c anh chá»‹, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» â€œPersonalized Recommendation Systemâ€, cÃ³ thá»ƒ do kháº£ nÄƒng tÃ¬m kiáº¿m cÃ²n háº¡n cháº¿ nÃªn háº§u háº¿t cÃ¡c document em tÃ¬m Ä‘Æ°á»£c chá»‰ dá»«ng láº¡i á»Ÿ má»©c lÃ½ thuyáº¿t, khÃ´ng Ä‘a dáº¡ng nhÆ° nhá»¯ng Ä‘á» tÃ i khÃ¡c. Náº¿u anh/chá»‹/báº¡n nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» Ä‘á» tÃ i nÃ y em xin má»™t sá»‘ tÃ i liá»‡u Ä‘á»ƒ cÃ³ thá»ƒ tÃ¬m hiá»ƒu sÃ¢u hÆ¡n áº¡. Má»¥c Ä‘Ã­ch lÃ  cÃ³ thá»ƒ táº¡o ra má»™t PRS mini nhÆ° kiá»ƒu youtube hoáº·c cÃ¡c sÃ n tmdt khÃ¡c áº¡.","ChÃ o cÃ¡c anh chá»‹, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» â€œPersonalized Recommendation Systemâ€, cÃ³ thá»ƒ do kháº£ nÄƒng tÃ¬m kiáº¿m cÃ²n háº¡n cháº¿ nÃªn háº§u háº¿t cÃ¡c document em tÃ¬m Ä‘Æ°á»£c chá»‰ dá»«ng láº¡i á»Ÿ má»©c lÃ½ thuyáº¿t, khÃ´ng Ä‘a dáº¡ng nhÆ° nhá»¯ng Ä‘á» tÃ i khÃ¡c. Náº¿u anh/chá»‹/báº¡n nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» Ä‘á» tÃ i nÃ y em xin má»™t sá»‘ tÃ i liá»‡u Ä‘á»ƒ cÃ³ thá»ƒ tÃ¬m hiá»ƒu sÃ¢u hÆ¡n áº¡. Má»¥c Ä‘Ã­ch lÃ  cÃ³ thá»ƒ táº¡o ra má»™t PRS mini nhÆ° kiá»ƒu youtube hoáº·c cÃ¡c sÃ n tmdt khÃ¡c áº¡.",,,,,
"CÃ³ láº½ ChatGPT Ä‘Ã£ mang Ä‘áº¿n cho con ngÆ°á»i má»™t cÆ¡ há»™i Ä‘Æ°á»£c lÃ m nhá»¯ng thá»© hay ho nháº¥t cá»§a má»i viá»‡c Ä‘Ã³ lÃ  hiá»ƒu rÃµ má»¥c Ä‘Ã­ch, báº£n cháº¥t cá»§a váº¥n Ä‘á», sÃ¡ng táº¡o cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á», cÃ²n nhá»¯ng viá»‡c tay chÃ¢n thÃ¬ Ä‘Ã£ cÃ³ ChatGPT lo.","CÃ³ láº½ ChatGPT Ä‘Ã£ mang Ä‘áº¿n cho con ngÆ°á»i má»™t cÆ¡ há»™i Ä‘Æ°á»£c lÃ m nhá»¯ng thá»© hay ho nháº¥t cá»§a má»i viá»‡c Ä‘Ã³ lÃ  hiá»ƒu rÃµ má»¥c Ä‘Ã­ch, báº£n cháº¥t cá»§a váº¥n Ä‘á», sÃ¡ng táº¡o cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á», cÃ²n nhá»¯ng viá»‡c tay chÃ¢n thÃ¬ Ä‘Ã£ cÃ³ ChatGPT lo.",,,,,
"ChÃ o má»i ngÆ°á»i. Em tÃ¬m tháº¥y má»™ repo trÃªn github nÃ³i vá» PP-YOLO. CÃ¡c bÃ¡c cÃ³ ai tá»«ng triá»ƒn khai nÃ³ chÆ°a áº¡. Cho em xin lá»i khyÃªn vÃ  hÆ°á»›ng dáº«n, e Ä‘ang Ä‘á»‹nh triá»ƒn khai YOLOv7 theo cÃ¡ch nÃ y. Em xn cáº£m Æ¡n
https://github.com/PaddlePaddle/PaddleDetection","ChÃ o má»i ngÆ°á»i. Em tÃ¬m tháº¥y má»™ repo trÃªn github nÃ³i vá» PP-YOLO. CÃ¡c bÃ¡c cÃ³ ai tá»«ng triá»ƒn khai nÃ³ chÆ°a áº¡. Cho em xin lá»i khyÃªn vÃ  hÆ°á»›ng dáº«n, e Ä‘ang Ä‘á»‹nh triá»ƒn khai YOLOv7 theo cÃ¡ch nÃ y. Em xn cáº£m Æ¡n https://github.com/PaddlePaddle/PaddleDetection",,,,,
"Em chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, em muá»‘n há»i vá» cuá»™c thi VLSP2022 vá»«a qua káº¿t quáº£ cÃ¡c task (cá»¥ thá»ƒ 2 task Constituency Parsing vÃ  Machine Translation) cÃ´ng bá»‘ á»Ÿ Ä‘Ã¢u áº¡, em Ä‘Ã£ tÃ¬m kiáº¿m nhÆ°ng khÃ´ng tháº¥y thÃ´ng tin :( 
#VLSP2022 ","Em chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, em muá»‘n há»i vá» cuá»™c thi VLSP2022 vá»«a qua káº¿t quáº£ cÃ¡c task (cá»¥ thá»ƒ 2 task Constituency Parsing vÃ  Machine Translation) cÃ´ng bá»‘ á»Ÿ Ä‘Ã¢u áº¡, em Ä‘Ã£ tÃ¬m kiáº¿m nhÆ°ng khÃ´ng tháº¥y thÃ´ng tin :(",#VLSP2022,,,,
"ChÃ o cÃ¡c bÃ¡c.
Em Ä‘ang há»c ML, cÃ³ cÃ¢u lá»‡nh
%matplotlib widget
em run trÃªn jupiter vá»›i vs code nÃ³ Ä‘á»u lá»—i, cmd install ipymlp rá»“i váº«n hiá»‡n ra lÃ  k tÃ¬m tháº¥y module.
CÃ¡c bÃ¡c Ä‘Ã£ gáº·p lá»—i nÃ y chÆ°a vÃ  giáº£i quáº¿t tháº¿ nÃ o áº¡? em cáº£m Æ¡n!","ChÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c ML, cÃ³ cÃ¢u lá»‡nh %matplotlib widget em run trÃªn jupiter vá»›i vs code nÃ³ Ä‘á»u lá»—i, cmd install ipymlp rá»“i váº«n hiá»‡n ra lÃ  k tÃ¬m tháº¥y module. CÃ¡c bÃ¡c Ä‘Ã£ gáº·p lá»—i nÃ y chÆ°a vÃ  giáº£i quáº¿t tháº¿ nÃ o áº¡? em cáº£m Æ¡n!",,,,,
"CÆ¡n bÃ£o ChatGPT má»›i Ä‘á»• bá»™ gáº§n Ä‘Ã¢y váº«n chÆ°a cÃ³ dáº¥u hiá»‡u suy yáº¿u!
Sau khi thá»­ chat chit vá»›i ChatGPT thÃ¬ mÃ¬nh nghÄ© ngay tá»›i viá»‡c xÃ¢y dá»±ng má»™t Chat Bot tÆ°Æ¡ng tá»±. VÃ  mÃ¬nh tÃ¬m Ä‘Æ°á»£c má»™t video khÃ¡ thÃº vá»‹ cá»§a Andrej Karpathy (cá»±u giÃ¡m Ä‘á»‘c nghiÃªn cá»©u AI cá»§a Tesla), cÃ¡c báº¡n cÃ¹ng tham kháº£o nhÃ© ğŸ™‚","CÆ¡n bÃ£o ChatGPT má»›i Ä‘á»• bá»™ gáº§n Ä‘Ã¢y váº«n chÆ°a cÃ³ dáº¥u hiá»‡u suy yáº¿u! Sau khi thá»­ chat chit vá»›i ChatGPT thÃ¬ mÃ¬nh nghÄ© ngay tá»›i viá»‡c xÃ¢y dá»±ng má»™t Chat Bot tÆ°Æ¡ng tá»±. VÃ  mÃ¬nh tÃ¬m Ä‘Æ°á»£c má»™t video khÃ¡ thÃº vá»‹ cá»§a Andrej Karpathy (cá»±u giÃ¡m Ä‘á»‘c nghiÃªn cá»©u AI cá»§a Tesla), cÃ¡c báº¡n cÃ¹ng tham kháº£o nhÃ©",,,,,
"xin phÃ©p ad.
hiá»‡n cÃ´ng ty mÃ¬nh Ä‘ang cÃ³ bÃ i toÃ¡n Ä‘áº¿m váº­t tÆ° tá»« 1 áº£nh.
hiá»‡n vá»›i áº£nh mÃ  cÃ¡c váº­t tÆ° xáº¿p sÃ¡t nhau thÃ¬ ko nháº­n ra Ä‘Æ°á»£c.
cÃ²n áº£nh ko sÃ¡t thÃ¬ nháº­n Ä‘Æ°á»£c háº¿t.
hiá»‡n Ä‘ang sá»­ dá»¥ng yolo7 ah.
AE cho thÃªm Ã½ kiáº¿n Ä‘á»ƒ em chá»‰nh ah.",xin phÃ©p ad. hiá»‡n cÃ´ng ty mÃ¬nh Ä‘ang cÃ³ bÃ i toÃ¡n Ä‘áº¿m váº­t tÆ° tá»« 1 áº£nh. hiá»‡n vá»›i áº£nh mÃ  cÃ¡c váº­t tÆ° xáº¿p sÃ¡t nhau thÃ¬ ko nháº­n ra Ä‘Æ°á»£c. cÃ²n áº£nh ko sÃ¡t thÃ¬ nháº­n Ä‘Æ°á»£c háº¿t. hiá»‡n Ä‘ang sá»­ dá»¥ng yolo7 ah. AE cho thÃªm Ã½ kiáº¿n Ä‘á»ƒ em chá»‰nh ah.,,,,,
"Hello má»i ngÆ°á»i,
Em vá»«a Ã¡p dá»¥ng thá»­ má»™t bÃ i NN Ä‘Æ¡n giáº£n tá»« kÃªnh MÃ¬ AI:https://www.miai.vn/2019/09/23/xay-dung-he-thong-chong-trom-don-gian-bang-yolo-va-opencv/
Em Ã¡p dá»¥ng y xÃ¬ váº­y vÃ  káº¿t quáº£ bá»‹ bÃ¡o lá»—i nhÆ° cÃ¡c áº£nh dÆ°á»›i.
CÃ¡c bÃ¡c cÃ³ biáº¿t bá»‹ tháº¿ nÃ y vÃ¬ sao ko áº¡?
Em cáº£m Æ¡n trÆ°á»›c.","Hello má»i ngÆ°á»i, Em vá»«a Ã¡p dá»¥ng thá»­ má»™t bÃ i NN Ä‘Æ¡n giáº£n tá»« kÃªnh MÃ¬ AI:https://www.miai.vn/2019/09/23/xay-dung-he-thong-chong-trom-don-gian-bang-yolo-va-opencv/ Em Ã¡p dá»¥ng y xÃ¬ váº­y vÃ  káº¿t quáº£ bá»‹ bÃ¡o lá»—i nhÆ° cÃ¡c áº£nh dÆ°á»›i. CÃ¡c bÃ¡c cÃ³ biáº¿t bá»‹ tháº¿ nÃ y vÃ¬ sao ko áº¡? Em cáº£m Æ¡n trÆ°á»›c.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c.
HÃ´m nay em máº¡nh dáº¡n chia sáº» vá»›i anh em má»™t chÃºt vá» ChatGPT vÃ  cÃ¹ng nhau tÃ¬m hiá»ƒu cÃ¡chtÃ­ch há»£p ChatGPT vÃ o á»©ng dá»¥ng cÃ¡ nhÃ¢n thÃ´ng qua OpenAI API nhÃ©! BÃ i nÃ y cÃ³ má»™t chÃºt vá» Streamlit cho anh em nÃ o cáº§n nhÃ©!
Chá»‰ hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c nhÆ° mÃ¬nh!",KÃ­nh chÃ o cÃ¡c bÃ¡c. HÃ´m nay em máº¡nh dáº¡n chia sáº» vá»›i anh em má»™t chÃºt vá» ChatGPT vÃ  cÃ¹ng nhau tÃ¬m hiá»ƒu cÃ¡chtÃ­ch há»£p ChatGPT vÃ o á»©ng dá»¥ng cÃ¡ nhÃ¢n thÃ´ng qua OpenAI API nhÃ©! BÃ i nÃ y cÃ³ má»™t chÃºt vá» Streamlit cho anh em nÃ o cáº§n nhÃ©! Chá»‰ hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c nhÆ° mÃ¬nh!,,,,,
"Em chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n áº¡.
Em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» Ä‘á» tÃ i Tá»•ng há»£p tiáº¿ng nÃ³i vÃ  Ä‘ang Ä‘áº¿n pháº§n Ä‘Ã¡nh gÃ­a káº¿t quáº£ báº±ng Ä‘iá»ƒm MOS. Tuy nhiÃªn em Ä‘ang gáº·p khÃ³ khÄƒn vá» viá»‡c tÃ¬m ngÆ°á»i Ä‘Ã¡nh giÃ¡ vá»›i sá»‘ lÆ°á»£ng Ä‘á»§ lá»›n Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ tin cáº­y cao.
VÃ¬ váº­y em tha thiáº¿t hy vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em Ä‘Ã¡nh giÃ¡ káº¿t quáº£ vÃ  gÃ³p Ã½ cÃ¹ng em.Em xin cáº£m Æ¡n ráº¥t nhiá»u áº¡.
Em gá»­i link kháº£o sÃ¡t :",Em chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n áº¡. Em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» Ä‘á» tÃ i Tá»•ng há»£p tiáº¿ng nÃ³i vÃ  Ä‘ang Ä‘áº¿n pháº§n Ä‘Ã¡nh gÃ­a káº¿t quáº£ báº±ng Ä‘iá»ƒm MOS. Tuy nhiÃªn em Ä‘ang gáº·p khÃ³ khÄƒn vá» viá»‡c tÃ¬m ngÆ°á»i Ä‘Ã¡nh giÃ¡ vá»›i sá»‘ lÆ°á»£ng Ä‘á»§ lá»›n Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ tin cáº­y cao. VÃ¬ váº­y em tha thiáº¿t hy vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em Ä‘Ã¡nh giÃ¡ káº¿t quáº£ vÃ  gÃ³p Ã½ cÃ¹ng em.Em xin cáº£m Æ¡n ráº¥t nhiá»u áº¡. Em gá»­i link kháº£o sÃ¡t :,,,,,
"Dáº¡ em xin chÃ o má»i ngÆ°á»i. Xin cho phÃ©p em há»i vá» model KNN, dáº¡ em train model KNN dÃ¹ng Ä‘á»ƒ nháº­n diá»‡n khuÃ´n máº·t vá»›i data lÃ  150 hÃ¬nh/ ngÆ°á»i, cÃ³ 3 ngÆ°á»i. Em thá»­ test nháº­n diá»‡n thÃ¬ nÃ³ tráº£ vá» káº¿t quáº£ Ä‘Ãºng nhÆ°ng thá»i gian thÃ¬ lÃ¢u áº¡. Nhanh nháº¥t lÃ  1.5s Ä‘áº¿n 3s láº­n. Anh/chá»‹ cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp em cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c vÃ  tráº£ vá» káº¿t quáº£ dÆ°á»›i < 1s áº¡ hoáº·c sá»­ dá»¥ng kÄ© thuáº­t khÃ¡c áº¡ . Em xin cáº£m Æ¡n anh/chá»‹ Ä‘Ã£ bá» thá»i gian Ä‘á»c bÃ i viáº¿t cá»§a em.","Dáº¡ em xin chÃ o má»i ngÆ°á»i. Xin cho phÃ©p em há»i vá» model KNN, dáº¡ em train model KNN dÃ¹ng Ä‘á»ƒ nháº­n diá»‡n khuÃ´n máº·t vá»›i data lÃ  150 hÃ¬nh/ ngÆ°á»i, cÃ³ 3 ngÆ°á»i. Em thá»­ test nháº­n diá»‡n thÃ¬ nÃ³ tráº£ vá» káº¿t quáº£ Ä‘Ãºng nhÆ°ng thá»i gian thÃ¬ lÃ¢u áº¡. Nhanh nháº¥t lÃ  1.5s Ä‘áº¿n 3s láº­n. Anh/chá»‹ cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp em cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c vÃ  tráº£ vá» káº¿t quáº£ dÆ°á»›i < 1s áº¡ hoáº·c sá»­ dá»¥ng kÄ© thuáº­t khÃ¡c áº¡ . Em xin cáº£m Æ¡n anh/chá»‹ Ä‘Ã£ bá» thá»i gian Ä‘á»c bÃ i viáº¿t cá»§a em.",,,,,
"moÌ£i ngÆ°Æ¡Ì€i Æ¡i , em coÌ 1 cÃ¢u hoÌ‰i vÃªÌ€ viÃªÌ£c train vÆ¡Ìi tripeloss khi coÌ nhiÃªÌ€u Ä‘Ã´Ìi tÆ°Æ¡Ì£ng . nhÆ° moÌ£i ngÆ°Æ¡Ì€i Ä‘aÌƒ biÃªÌt thiÌ€ viÃªÌ£c train naÌ€y seÌƒ cÃ´Ì laÌ€m cho neg xa ancho, vaÌ€ cÃ´Ì gÄƒÌng laÌ€m gÃ¢Ì€n ancho vs pos. Em seÌƒ Ä‘ÄƒÌ£t ancho laÌ€ A, pos laÌ€ A1, neg laÌ€ B, mÃ´Ì£t Ä‘Ã´Ìi tÆ°Æ¡Ì£ng khaÌc neg vs ancho laÌ€ C. CÃ¢u hoÌ‰i cuÌ‰a em laÌ€ khi train tripeloss thiÌ€ A seÌƒ caÌ€ng gÃ¢Ì€n A1, A seÌƒ caÌ€ng xa B, nhÆ°ng nÃªÌu nhÆ° viÃªÌ£c chiÌ‰nh sÆ°Ì‰a A sao cho xa B laÌ£i vÃ´ tiÌ€nh khiÃªÌn cho A gÃ¢Ì€n C hÆ¡n thiÌ€ s aÌ£. Ai coÌ kinh nghiÃªÌ£m giaÌ‰i thiÌch caÌi naÌ€y giuÌp em vÆ¡Ìi, em caÌ‰m Æ¡n aÌ£","moÌ£i ngÆ°Æ¡Ì€i Æ¡i , em coÌ 1 cÃ¢u hoÌ‰i vÃªÌ€ viÃªÌ£c train vÆ¡Ìi tripeloss khi coÌ nhiÃªÌ€u Ä‘Ã´Ìi tÆ°Æ¡Ì£ng . nhÆ° moÌ£i ngÆ°Æ¡Ì€i Ä‘aÌƒ biÃªÌt thiÌ€ viÃªÌ£c train naÌ€y seÌƒ cÃ´Ì laÌ€m cho neg xa ancho, vaÌ€ cÃ´Ì gÄƒÌng laÌ€m gÃ¢Ì€n ancho vs pos. Em seÌƒ Ä‘ÄƒÌ£t ancho laÌ€ A, pos laÌ€ A1, neg laÌ€ B, mÃ´Ì£t Ä‘Ã´Ìi tÆ°Æ¡Ì£ng khaÌc neg vs ancho laÌ€ C. CÃ¢u hoÌ‰i cuÌ‰a em laÌ€ khi train tripeloss thiÌ€ A seÌƒ caÌ€ng gÃ¢Ì€n A1, A seÌƒ caÌ€ng xa B, nhÆ°ng nÃªÌu nhÆ° viÃªÌ£c chiÌ‰nh sÆ°Ì‰a A sao cho xa B laÌ£i vÃ´ tiÌ€nh khiÃªÌn cho A gÃ¢Ì€n C hÆ¡n thiÌ€ s aÌ£. Ai coÌ kinh nghiÃªÌ£m giaÌ‰i thiÌch caÌi naÌ€y giuÌp em vÆ¡Ìi, em caÌ‰m Æ¡n aÌ£",,,,,
"MÃ¬nh tháº¥y cÃ³ dá»± Ã¡n cá»™ng Ä‘á»“ng vá»›i má»¥c Ä‘Ã­ch thu tháº­p dá»¯ liá»‡u Ä‘á»ƒ cho ra máº¯t chat bot cáº¡nh tranh vá»›i ChatGPT vÃ  cÃ¡c chá»§ Ä‘á» generative khÃ¡c nhÆ° text-to-image, image-to-text,... Dá»± Ã¡n nÃ y Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi LAION-AI https://laion.ai/. Hi vá»ng Viá»‡t Nam cÃ³ nhiá»u Ä‘Ã³ng gÃ³p vÃ o dá»± Ã¡n má»Ÿ nÃ y, dá»± Ã¡n táº¡i Ä‘Ã¢y https://github.com/LAION-AI/Open-Assistant.","MÃ¬nh tháº¥y cÃ³ dá»± Ã¡n cá»™ng Ä‘á»“ng vá»›i má»¥c Ä‘Ã­ch thu tháº­p dá»¯ liá»‡u Ä‘á»ƒ cho ra máº¯t chat bot cáº¡nh tranh vá»›i ChatGPT vÃ  cÃ¡c chá»§ Ä‘á» generative khÃ¡c nhÆ° text-to-image, image-to-text,... Dá»± Ã¡n nÃ y Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi LAION-AI https://laion.ai/. Hi vá»ng Viá»‡t Nam cÃ³ nhiá»u Ä‘Ã³ng gÃ³p vÃ o dá»± Ã¡n má»Ÿ nÃ y, dá»± Ã¡n táº¡i Ä‘Ã¢y https://github.com/LAION-AI/Open-Assistant.",,,,,
"MÃ” HÃŒNH NGÃ”N NGá»® THUáº¦N Ã‚M TIáº¾T TIáº¾NG VIá»†T
Má»i ngÆ°á»i nghÄ© sao vá» thá»­ nghiá»‡m lÃ m mÃ´ hÃ¬nh ngÃ´n ngá»¯ cho táº­p dá»¯ liá»‡u láº¥y Ã¢m tiáº¿t tiáº¿ng Viá»‡t lÃ m trung tÃ¢m!
Láº¥y cáº£m há»©ng tá»« BabyLM chanllenge, vÃ  cramming paper (huáº¥n luyá»‡n LM trÃªn 1 GPU trong 24h), cá»• vÅ© viá»‡c scaling down LM Ä‘á»ƒ nhiá»u ngÆ°á»i cÃ³ thá»ƒ tham gia vÃ  cÃ³ nhá»¯ng khÃ¡m phÃ¡ má»›i máº» trong lÄ©nh vá»±c Ä‘ang ráº¥t hot nÃ y.
Táº I SAO Láº I THUáº¦N Ã‚M TIáº¾T?
1/ VÃ¬ nÃ³ chiáº¿m ~80% text corpus tiáº¿ng Viá»‡t. Táº­p trung vÃ o Ã¢m tiáº¿t sáº½ lÃ m ná»•i báº­t cÃ¡c Ä‘áº·c trÆ°ng cá»§a ngÃ´n ngá»¯.
2/ CÃ³ nhiá»u sÃ¡ng táº¡o hÆ¡n trong viá»‡c phÃ¢n tÃ­ch vÃ  phÃ¢n tÃ¡ch dá»¯ liá»‡u (vÃ­ dá»¥ xÃ¢y dá»±ng bá»™ vocab, custom tokenizer ...)
3/ Nhanh Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh. NgÆ°á»i ta hay dÃ¹ng character LM Ä‘á»ƒ thá»­ nghiá»‡m vÃ  so sÃ¡nh Ä‘á»™ hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh. Táº­p trung vÃ o Ã¢m tiáº¿t cÅ©ng gáº§n giá»‘ng nhÆ° character LM váº­y.
MÃ¬nh nghÄ© thá»­ nghiá»‡m nÃ y Ä‘á»§ dá»… Ä‘á»ƒ báº¥t ká»³ ai cÅ©ng tham gia Ä‘Æ°á»£c vÃ  ai cÅ©ng cÃ³ thá»ƒ cÃ³ Ä‘Ã³ng gÃ³p / sÃ¡ng táº¡o cá»§a riÃªng mÃ¬nh. VÃ  trÃªn háº¿t nÃ³ sáº½ vui vÃ  kÃ©o cá»™ng Ä‘á»“ng láº¡i gáº§n nhau hÆ¡n.","MÃ” HÃŒNH NGÃ”N NGá»® THUáº¦N Ã‚M TIáº¾T TIáº¾NG VIá»†T Má»i ngÆ°á»i nghÄ© sao vá» thá»­ nghiá»‡m lÃ m mÃ´ hÃ¬nh ngÃ´n ngá»¯ cho táº­p dá»¯ liá»‡u láº¥y Ã¢m tiáº¿t tiáº¿ng Viá»‡t lÃ m trung tÃ¢m! Láº¥y cáº£m há»©ng tá»« BabyLM chanllenge, vÃ  cramming paper (huáº¥n luyá»‡n LM trÃªn 1 GPU trong 24h), cá»• vÅ© viá»‡c scaling down LM Ä‘á»ƒ nhiá»u ngÆ°á»i cÃ³ thá»ƒ tham gia vÃ  cÃ³ nhá»¯ng khÃ¡m phÃ¡ má»›i máº» trong lÄ©nh vá»±c Ä‘ang ráº¥t hot nÃ y. Táº I SAO Láº I THUáº¦N Ã‚M TIáº¾T? 1/ VÃ¬ nÃ³ chiáº¿m ~80% text corpus tiáº¿ng Viá»‡t. Táº­p trung vÃ o Ã¢m tiáº¿t sáº½ lÃ m ná»•i báº­t cÃ¡c Ä‘áº·c trÆ°ng cá»§a ngÃ´n ngá»¯. 2/ CÃ³ nhiá»u sÃ¡ng táº¡o hÆ¡n trong viá»‡c phÃ¢n tÃ­ch vÃ  phÃ¢n tÃ¡ch dá»¯ liá»‡u (vÃ­ dá»¥ xÃ¢y dá»±ng bá»™ vocab, custom tokenizer ...) 3/ Nhanh Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh. NgÆ°á»i ta hay dÃ¹ng character LM Ä‘á»ƒ thá»­ nghiá»‡m vÃ  so sÃ¡nh Ä‘á»™ hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh. Táº­p trung vÃ o Ã¢m tiáº¿t cÅ©ng gáº§n giá»‘ng nhÆ° character LM váº­y. MÃ¬nh nghÄ© thá»­ nghiá»‡m nÃ y Ä‘á»§ dá»… Ä‘á»ƒ báº¥t ká»³ ai cÅ©ng tham gia Ä‘Æ°á»£c vÃ  ai cÅ©ng cÃ³ thá»ƒ cÃ³ Ä‘Ã³ng gÃ³p / sÃ¡ng táº¡o cá»§a riÃªng mÃ¬nh. VÃ  trÃªn háº¿t nÃ³ sáº½ vui vÃ  kÃ©o cá»™ng Ä‘á»“ng láº¡i gáº§n nhau hÆ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh muá»‘n lÃ m bÃ i toÃ¡n vá» OCR cho tiáº¿ng viá»‡t. MÃ¬nh google thÃ¬ khÃ´ng tháº¥y cÃ³ chá»— táº£i dá»¯ liá»‡u huáº¥n luyá»‡n cho tiáº¿ng viá»‡t. Váº­y cÃ³ ai cho mÃ¬nh xin bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, mÃ¬nh muá»‘n lÃ m bÃ i toÃ¡n vá» OCR cho tiáº¿ng viá»‡t. MÃ¬nh google thÃ¬ khÃ´ng tháº¥y cÃ³ chá»— táº£i dá»¯ liá»‡u huáº¥n luyá»‡n cho tiáº¿ng viá»‡t. Váº­y cÃ³ ai cho mÃ¬nh xin bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"[ChatGPT Cheat Sheet]
Báº¡n Ä‘Ã£ tá»«ng nghe vá» ChatGPT, nhÆ°ng chÆ°a biáº¿t ChatGPT cÃ³ thá»ƒ lÃ m nhá»¯ng gÃ¬?
Post nÃ y sáº½ giÃºp báº¡n tá»•ng há»£p nhá»¯ng kháº£ nÄƒng cá»§a ChatGPT, Ä‘á»ƒ tá»« Ä‘Ã³ báº¡n cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t cÃ´ng viá»‡c cá»§a mÃ¬nh. Má»™t sá»‘ á»©ng dá»¥ng cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ°:
- Tá»± Ä‘á»™ng viáº¿t code, giáº£i thÃ­ch code, sinh document cho code
- Tá»± Ä‘á»™ng váº¿t bÃ i ielts writing, tráº£ lá»i ielts speaking
- Tá»± Ä‘á»™ng viáº¿t CV dá»±a theo thÃ´ng tin báº¡n cung cáº¥p
- Tá»± Ä‘á»™ng viáº¿t email, blog, essay,...
- Há»i Ä‘Ã¡p thay Google :))","[ChatGPT Cheat Sheet] Báº¡n Ä‘Ã£ tá»«ng nghe vá» ChatGPT, nhÆ°ng chÆ°a biáº¿t ChatGPT cÃ³ thá»ƒ lÃ m nhá»¯ng gÃ¬? Post nÃ y sáº½ giÃºp báº¡n tá»•ng há»£p nhá»¯ng kháº£ nÄƒng cá»§a ChatGPT, Ä‘á»ƒ tá»« Ä‘Ã³ báº¡n cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t cÃ´ng viá»‡c cá»§a mÃ¬nh. Má»™t sá»‘ á»©ng dá»¥ng cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ°: - Tá»± Ä‘á»™ng viáº¿t code, giáº£i thÃ­ch code, sinh document cho code - Tá»± Ä‘á»™ng váº¿t bÃ i ielts writing, tráº£ lá»i ielts speaking - Tá»± Ä‘á»™ng viáº¿t CV dá»±a theo thÃ´ng tin báº¡n cung cáº¥p - Tá»± Ä‘á»™ng viáº¿t email, blog, essay,... - Há»i Ä‘Ã¡p thay Google :))",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, em hiá»‡n Ä‘ang má»™t tháº¯c máº¯c vá» cÃ¡ch design má»™t máº¡ng neural.
Hiá»‡n em Ä‘ang thá»±c hÃ nh xÃ¢y dá»±ng cÃ¡c model Ä‘Æ¡n giáº£n Ä‘á»ƒ lÃ m quen (stock prediction, heart disease prediction...), tuy nhiÃªn em Ä‘áº¿n lÃºc build model, em thÆ°á»ng chá»‰ xem theo hÆ°á»›ng dáº«n Ä‘á»ƒ build cÃ¡c layer. Em chÆ°a hiá»ƒu táº¡i sao cÃ³ khi ngÆ°á»i ta dÃ¹ng tá»›i 3 lá»›p Conv2D, cÃ³ khi láº¡i Ã­t hÆ¡n (hoáº·c nhiá»u hÆ¡n), hoáº·c maxpooling thÃ¬ dÃ¹ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ hiá»‡u quáº£ (máº¥t Ã­t thÃ´ng tin nháº¥t) cÅ©ng nhÆ° lá»±a chá»n sá»‘ chiá»u Ä‘áº§u ra cho má»—i layer nhÆ° tháº¿ nÃ o. Em cÃ³ tÃ¬m hiá»ƒu thÃ¬ chá»‰ báº¯t gáº·p vÃ i cÃ¢u tráº£ lá»i Ä‘áº¡i khÃ¡i nhÆ° ""tÃ¹y thuá»™c vÃ o data"". NhÆ°ng mÃ  cá»¥ thá»ƒ lÃ  tÃ¹y thuá»™c nhÆ° tháº¿ nÃ o thÃ¬ em chÆ°a rÃµ vÃ  em chÆ°a tÃ¬m Ä‘Æ°á»£c nguá»“n giáº£i thÃ­ch kÃ¨m theo vÃ­ dá»¥ cá»¥ thá»ƒ. Váº­y lÃ m sao Ä‘á»ƒ tá»± design cÅ©ng nhÆ° Ä‘Ã¡nh giÃ¡ vÃ  Ä‘á» xuáº¥t hÆ°á»›ng cáº£i tiáº¿n neural network cá»§a riÃªng mÃ¬nh?
Em mong má»i ngÆ°á»i giÃºp em, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡, chÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº»!","ChÃ o má»i ngÆ°á»i áº¡, em hiá»‡n Ä‘ang má»™t tháº¯c máº¯c vá» cÃ¡ch design má»™t máº¡ng neural. Hiá»‡n em Ä‘ang thá»±c hÃ nh xÃ¢y dá»±ng cÃ¡c model Ä‘Æ¡n giáº£n Ä‘á»ƒ lÃ m quen (stock prediction, heart disease prediction...), tuy nhiÃªn em Ä‘áº¿n lÃºc build model, em thÆ°á»ng chá»‰ xem theo hÆ°á»›ng dáº«n Ä‘á»ƒ build cÃ¡c layer. Em chÆ°a hiá»ƒu táº¡i sao cÃ³ khi ngÆ°á»i ta dÃ¹ng tá»›i 3 lá»›p Conv2D, cÃ³ khi láº¡i Ã­t hÆ¡n (hoáº·c nhiá»u hÆ¡n), hoáº·c maxpooling thÃ¬ dÃ¹ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ hiá»‡u quáº£ (máº¥t Ã­t thÃ´ng tin nháº¥t) cÅ©ng nhÆ° lá»±a chá»n sá»‘ chiá»u Ä‘áº§u ra cho má»—i layer nhÆ° tháº¿ nÃ o. Em cÃ³ tÃ¬m hiá»ƒu thÃ¬ chá»‰ báº¯t gáº·p vÃ i cÃ¢u tráº£ lá»i Ä‘áº¡i khÃ¡i nhÆ° ""tÃ¹y thuá»™c vÃ o data"". NhÆ°ng mÃ  cá»¥ thá»ƒ lÃ  tÃ¹y thuá»™c nhÆ° tháº¿ nÃ o thÃ¬ em chÆ°a rÃµ vÃ  em chÆ°a tÃ¬m Ä‘Æ°á»£c nguá»“n giáº£i thÃ­ch kÃ¨m theo vÃ­ dá»¥ cá»¥ thá»ƒ. Váº­y lÃ m sao Ä‘á»ƒ tá»± design cÅ©ng nhÆ° Ä‘Ã¡nh giÃ¡ vÃ  Ä‘á» xuáº¥t hÆ°á»›ng cáº£i tiáº¿n neural network cá»§a riÃªng mÃ¬nh? Em mong má»i ngÆ°á»i giÃºp em, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡, chÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº»!",,,,,
Cho mÃ¬nh há»i nhá»¯ng báº¡n Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» viá»‡c Ä‘Äƒng kÃ½ khoÃ¡ há»c Deep Learning Specialization cá»§a Coursera. Náº¿u mÃ¬nh Ä‘Äƒng kÃ½ tá»«ng khoÃ¡ há»c riÃªng láº» thÃ¬ khi khi hoÃ n táº¥t khoÃ¡ cuá»‘i cÃ¹ng mÃ¬nh cÃ³ Ä‘Æ°á»£c Deep Learning Certificate khÃ´ng? Hay mÃ¬nh pháº£i Ä‘Äƒng kÃ½ trá»n bá»™ tá»« Ä‘áº§u thÃ¬ má»›i Ä‘Æ°á»£c chá»©ng chá»‰ Ä‘Ã³? Thanks in advance,Cho mÃ¬nh há»i nhá»¯ng báº¡n Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» viá»‡c Ä‘Äƒng kÃ½ khoÃ¡ há»c Deep Learning Specialization cá»§a Coursera. Náº¿u mÃ¬nh Ä‘Äƒng kÃ½ tá»«ng khoÃ¡ há»c riÃªng láº» thÃ¬ khi khi hoÃ n táº¥t khoÃ¡ cuá»‘i cÃ¹ng mÃ¬nh cÃ³ Ä‘Æ°á»£c Deep Learning Certificate khÃ´ng? Hay mÃ¬nh pháº£i Ä‘Äƒng kÃ½ trá»n bá»™ tá»« Ä‘áº§u thÃ¬ má»›i Ä‘Æ°á»£c chá»©ng chá»‰ Ä‘Ã³? Thanks in advance,,,,,
,nan,,,,,
Tá»•ng há»£p cÃ¡c nguá»“n cung cáº¥p data miá»…n phÃ­. CÃ¡c báº¡n nÃ o Ä‘ang lÃ m dá»± Ã¡n mÃ  khÃ´ng biáº¿t láº¥y data á»Ÿ Ä‘Ã¢u thÃ¬ lÆ°u láº¡i ngay nhÃ©,Tá»•ng há»£p cÃ¡c nguá»“n cung cáº¥p data miá»…n phÃ­. CÃ¡c báº¡n nÃ o Ä‘ang lÃ m dá»± Ã¡n mÃ  khÃ´ng biáº¿t láº¥y data á»Ÿ Ä‘Ã¢u thÃ¬ lÆ°u láº¡i ngay nhÃ©,,,,,
Google vá»«a ra máº¯t Bard Ä‘á»ƒ cáº¡nh tranh trá»±c tiáº¿p vá»›i ChatGPT vÃ  sáº½ sá»›m Ä‘áº¿n tay ngÆ°á»i dÃ¹ng.,Google vá»«a ra máº¯t Bard Ä‘á»ƒ cáº¡nh tranh trá»±c tiáº¿p vá»›i ChatGPT vÃ  sáº½ sá»›m Ä‘áº¿n tay ngÆ°á»i dÃ¹ng.,,,,,
"[BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models]
Náº¿u nhÆ° mÃ´ hÃ¬nh ChatGPT chá»‰ Ä‘Æ¡n thuáº§n lÃ  giao tiáº¿p dáº¡ng ngÃ´n ngá»¯, thÃ¬ gáº§n Ä‘Ã¢y mÃ´ hÃ¬nh BLIP-2 káº¿t há»£p giá»¯a ná»™i dung bá»©c áº£nh vÃ  ngÃ´n ngá»¯ Ä‘á»‘i thoáº¡i. Cá»¥ thá»ƒ, báº¡n cÃ³ thá»ƒ input má»™t bá»©c áº£nh, vÃ  cÃ¡c cÃ¢u há»i, mÃ´ hÃ¬nh BLIP-2 sáº½ hiá»ƒu Ä‘Æ°á»£c ná»™i dung bá»©c áº£nh, vÃ  cÃ³ thá»ƒ láº¥y thÃªm cÃ¡c thÃ´ng tin nhÆ° trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘á»ƒ tráº£ lá»i.
VÃ­ dá»¥: nhÆ° input áº£nh xe audi, báº¡n há»i nhá»¯ng Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t cá»§a xe trong bá»©c áº£nh, mÃ¡y cÃ³ thá»ƒ ká»ƒ ra nhá»¯ng Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t cá»§a xe audi nhÆ° kháº£ nÄƒng tÄƒng tá»‘c nhanh, xe lai Ä‘iá»‡n,....","[BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models] Náº¿u nhÆ° mÃ´ hÃ¬nh ChatGPT chá»‰ Ä‘Æ¡n thuáº§n lÃ  giao tiáº¿p dáº¡ng ngÃ´n ngá»¯, thÃ¬ gáº§n Ä‘Ã¢y mÃ´ hÃ¬nh BLIP-2 káº¿t há»£p giá»¯a ná»™i dung bá»©c áº£nh vÃ  ngÃ´n ngá»¯ Ä‘á»‘i thoáº¡i. Cá»¥ thá»ƒ, báº¡n cÃ³ thá»ƒ input má»™t bá»©c áº£nh, vÃ  cÃ¡c cÃ¢u há»i, mÃ´ hÃ¬nh BLIP-2 sáº½ hiá»ƒu Ä‘Æ°á»£c ná»™i dung bá»©c áº£nh, vÃ  cÃ³ thá»ƒ láº¥y thÃªm cÃ¡c thÃ´ng tin nhÆ° trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘á»ƒ tráº£ lá»i. VÃ­ dá»¥: nhÆ° input áº£nh xe audi, báº¡n há»i nhá»¯ng Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t cá»§a xe trong bá»©c áº£nh, mÃ¡y cÃ³ thá»ƒ ká»ƒ ra nhá»¯ng Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t cá»§a xe audi nhÆ° kháº£ nÄƒng tÄƒng tá»‘c nhanh, xe lai Ä‘iá»‡n,....",,,,,
"Má»i ngÆ°á»i cho em há»i lÃ  cÃ³ trÆ°á»ng há»£p nÃ o do dÃ¹ng khÃ¡c version cá»§a library mÃ  sá»‘ liá»‡u tÃ­nh toÃ¡n nÃ³ ra khÃ¡c nhau khÃ´ng áº¡. TÃ¬nh tráº¡ng lÃ  em cÃ³ láº¥y code cá»§a bÃ i toÃ¡n dá»± Ä‘oÃ¡n ""doanh sá»‘ bÃ¡n hÃ ng thÃ´ng qua hÃ¬nh áº£nh sáº£n pháº©m"" cá»§a trÃªn máº¡ng vá» cháº¡y, sá»­ dá»¥ng cÃ¡c library torch, pytorch_lightning,... Ä‘á»ƒ tÃ­nh toÃ¡n MAR, WAPE. Tuy nhiÃªn káº¿t quáº£ em cháº¡y ra so vá»›i paper cá»§a há» láº¡i hÆ¡i khÃ¡c xÃ­u (vÃ­ dá»¥ 97 vÃ  96.2). NhÆ° váº­y lÃ  lá»—i do em sai hay lÃ  do version váº­y áº¡?","Má»i ngÆ°á»i cho em há»i lÃ  cÃ³ trÆ°á»ng há»£p nÃ o do dÃ¹ng khÃ¡c version cá»§a library mÃ  sá»‘ liá»‡u tÃ­nh toÃ¡n nÃ³ ra khÃ¡c nhau khÃ´ng áº¡. TÃ¬nh tráº¡ng lÃ  em cÃ³ láº¥y code cá»§a bÃ i toÃ¡n dá»± Ä‘oÃ¡n ""doanh sá»‘ bÃ¡n hÃ ng thÃ´ng qua hÃ¬nh áº£nh sáº£n pháº©m"" cá»§a trÃªn máº¡ng vá» cháº¡y, sá»­ dá»¥ng cÃ¡c library torch, pytorch_lightning,... Ä‘á»ƒ tÃ­nh toÃ¡n MAR, WAPE. Tuy nhiÃªn káº¿t quáº£ em cháº¡y ra so vá»›i paper cá»§a há» láº¡i hÆ¡i khÃ¡c xÃ­u (vÃ­ dá»¥ 97 vÃ  96.2). NhÆ° váº­y lÃ  lá»—i do em sai hay lÃ  do version váº­y áº¡?",,,,,
"PhoNLP: A joint multi-task learning toolkit for Vietnamese part-of-speech tagging, named entity recognition and dependency parsing
https://github.com/VinAIResearch/PhoNLP by Linh The Nguyen & Dat Quoc Nguyen
We present the first multi-task learning model---named PhoNLP---for joint Vietnamese part-of-speech tagging, named entity recognition and dependency parsing. Experiments on Vietnamese benchmark datasets show that PhoNLP produces state-of-the-art results, outperforming a single-task learning approach that fine-tunes the pre-trained Vietnamese language model PhoBERT for each task independently.  We publicly release PhoNLP as an open-source toolkit under the MIT License. We hope that PhoNLP can serve as a strong baseline and useful toolkit for future research and applications in  Vietnamese NLP.
PhoNLP paper will be released on ArXiv very very soon. ","PhoNLP: A joint multi-task learning toolkit for Vietnamese part-of-speech tagging, named entity recognition and dependency parsing https://github.com/VinAIResearch/PhoNLP by Linh The Nguyen & Dat Quoc Nguyen We present the first multi-task learning model---named PhoNLP---for joint Vietnamese part-of-speech tagging, named entity recognition and dependency parsing. Experiments on Vietnamese benchmark datasets show that PhoNLP produces state-of-the-art results, outperforming a single-task learning approach that fine-tunes the pre-trained Vietnamese language model PhoBERT for each task independently. We publicly release PhoNLP as an open-source toolkit under the MIT License. We hope that PhoNLP can serve as a strong baseline and useful toolkit for future research and applications in Vietnamese NLP. PhoNLP paper will be released on ArXiv very very soon.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 01/2023 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 01/2023 vÃ o comment cá»§a post nÃ y.",,,,,
"Mn cho em há»i lÃ m tháº¿ nÃ o mÃ  cÃ´ng thá»©c 1 váº¿ trÃ¡i cÃ³ transpose, cÃ´ng thá»©c 2 váº¿ trÃ¡i k cÃ³ transpose mÃ  váº¿ pháº£i cáº£ 2 cÃ´ng thá»©c lÃ  nhÆ° nhau áº¡","Mn cho em há»i lÃ m tháº¿ nÃ o mÃ  cÃ´ng thá»©c 1 váº¿ trÃ¡i cÃ³ transpose, cÃ´ng thá»©c 2 váº¿ trÃ¡i k cÃ³ transpose mÃ  váº¿ pháº£i cáº£ 2 cÃ´ng thá»©c lÃ  nhÆ° nhau áº¡",,,,,
"[DetectGPT: vá» quÃ½t dÃ y cÃ³ mÃ³ng tay nhá»n]
Sau khi cÃ¡c sinh viÃªn Ä‘áº¡i há»c cÃ³ Ã½ Ä‘á»‹nh dÃ¹ng ChatGPT Ä‘á»ƒ viáº¿t assignment, essay thÃ¬ gáº§n Ä‘Ã¢y nhÃ³m nghiÃªn cá»©u tá»›i tá»« Ä‘áº¡i há»c Stanford Ä‘Ã£ cho ra máº¯t mÃ´ hÃ¬nh DetectGPT Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem vÄƒn báº£n Ä‘Æ°á»£c sinh bá»Ÿi ChatGPT hay viáº¿t bá»Ÿi con ngÆ°á»i.","[DetectGPT: vá» quÃ½t dÃ y cÃ³ mÃ³ng tay nhá»n] Sau khi cÃ¡c sinh viÃªn Ä‘áº¡i há»c cÃ³ Ã½ Ä‘á»‹nh dÃ¹ng ChatGPT Ä‘á»ƒ viáº¿t assignment, essay thÃ¬ gáº§n Ä‘Ã¢y nhÃ³m nghiÃªn cá»©u tá»›i tá»« Ä‘áº¡i há»c Stanford Ä‘Ã£ cho ra máº¯t mÃ´ hÃ¬nh DetectGPT Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem vÄƒn báº£n Ä‘Æ°á»£c sinh bá»Ÿi ChatGPT hay viáº¿t bá»Ÿi con ngÆ°á»i.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c!
Äá»£t nÃ y nhiá»u báº¡n há»i trÃªn  Group  vá» viá»‡c lÃ m sao Ä‘á»ƒ train YOLOv8. HÃ´m nay em xin máº¡nh dáº¡n chia sáº» bÃ i nÃ y hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c thÃ´i áº¡!
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!",KÃ­nh chÃ o cÃ¡c bÃ¡c! Äá»£t nÃ y nhiá»u báº¡n há»i trÃªn Group vá» viá»‡c lÃ m sao Ä‘á»ƒ train YOLOv8. HÃ´m nay em xin máº¡nh dáº¡n chia sáº» bÃ i nÃ y hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c thÃ´i áº¡! ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!,,,,,
"Äáº§u xuÃ¢n nÄƒm má»›i gá»­i Ä‘áº¿n má»i ngÆ°á»i bÃ i Blog mÃ¬nh má»›i viáº¿t vá» Conformer: Convolution Augmented Transformer.
Trong Ä‘Ã³ mÃ¬nh cÃ³ trÃ¬nh bÃ y chi tiáº¿t vá» Conformer, cÃ¡ch Ã¡p dá»¥ng nÃ³ trong ASR vÃ  TTS. CÅ©ng nhÆ° nÃªu ra má»™t sá»‘ cÃ¢u há»i Ä‘Ã¡ng chÃº Ã½ vá» viá»‡c: CÃ³ cáº§n thiáº¿t Ã¡p dá»¥ng Macron-style vÃ  Relative Position Encoding cho Conformer trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ tiáº¿ng nÃ³i hay khÃ´ng?
https://www.aiourlife.com/2023/01/convolution-augmented-transformer.html","Äáº§u xuÃ¢n nÄƒm má»›i gá»­i Ä‘áº¿n má»i ngÆ°á»i bÃ i Blog mÃ¬nh má»›i viáº¿t vá» Conformer: Convolution Augmented Transformer. Trong Ä‘Ã³ mÃ¬nh cÃ³ trÃ¬nh bÃ y chi tiáº¿t vá» Conformer, cÃ¡ch Ã¡p dá»¥ng nÃ³ trong ASR vÃ  TTS. CÅ©ng nhÆ° nÃªu ra má»™t sá»‘ cÃ¢u há»i Ä‘Ã¡ng chÃº Ã½ vá» viá»‡c: CÃ³ cáº§n thiáº¿t Ã¡p dá»¥ng Macron-style vÃ  Relative Position Encoding cho Conformer trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ tiáº¿ng nÃ³i hay khÃ´ng? https://www.aiourlife.com/2023/01/convolution-augmented-transformer.html",,,,,
"A.C.E NÃ o Ä‘Ã£ tá»«ng dÃ¹ng MMdetection nÃ y trÃªn GG colboratory chÆ°a áº¡. Cho e xin chá»‰ giÃ¡o vá»›i áº¡. NÃ³ yÃªu cáº§u pháº£i cÃ³ GPU mÃ  mÃ¡y e má»—i con AMD gháº» k cháº¡y Ä‘Æ°á»£c tÃ¬m cÃ¡ch Ä‘áº©y lÃªn GG thÃ¬ chÆ°a tháº¥y cÃ³ ai lÃ m máº¥y. ğŸ™ doc nÃ y viáº¿t hÆ¡i khÃ³ chá»‹u áº¡ (Cá»§a China ). A/C Ä‘Ã£ dÃ¹ng thÃ¬ cho e xin há»i Ä‘Ã´i chÃºt â¤
#Github: https://github.com/open-mmlab/mmdetection
#Docs : https://mmdetection.readthedocs.io/en/latest/",A.C.E NÃ o Ä‘Ã£ tá»«ng dÃ¹ng MMdetection nÃ y trÃªn GG colboratory chÆ°a áº¡. Cho e xin chá»‰ giÃ¡o vá»›i áº¡. NÃ³ yÃªu cáº§u pháº£i cÃ³ GPU mÃ  mÃ¡y e má»—i con AMD gháº» k cháº¡y Ä‘Æ°á»£c tÃ¬m cÃ¡ch Ä‘áº©y lÃªn GG thÃ¬ chÆ°a tháº¥y cÃ³ ai lÃ m máº¥y. doc nÃ y viáº¿t hÆ¡i khÃ³ chá»‹u áº¡ (Cá»§a China ). A/C Ä‘Ã£ dÃ¹ng thÃ¬ cho e xin há»i Ä‘Ã´i chÃºt https://github.com/open-mmlab/mmdetection : https://mmdetection.readthedocs.io/en/latest/,#Github:	#Docs,,,,
"Dáº¡ chÃ o má»i ngÆ°á»i, láº¡i lÃ  em Ä‘Ã¢y áº¡.
HÃ´m nay em Ä‘em Ä‘áº¿n 1 váº¥n Ä‘á» nhÆ° sau: Gáº§n Ä‘Ã¢y thÃ¬ cÃ³ ráº¥t nhiá»u paper á»©ng dá»¥ng cÃ¡c method Transformer-based cho time series data. Tuy nhiÃªn sau khi tiáº¿p thá»¥ tri thá»©c tá»« 1 vÃ i nguá»“n thÃ¬ em nháº­n Ä‘Æ°á»£c 1 sá»‘ cÃ¢u há»i nhÆ° nÃ y:
1. KhÃ¡c vá»›i ngÃ´n ngá»¯, dá»¯ liá»‡u dáº¡ng time series cÃ³ sá»± liÃªn há»‡ á»Ÿ thá»i gian t vá»›i thá»i gian t-1. NÃªn liá»‡u viá»‡c ta sá»­ dá»¥ng self-attention cho dá»¯ liá»‡u dáº¡ng nÃ y cÃ³ á»•n khÃ´ng?
2. Liá»‡u transformer-based cÃ³ lÃ  1 lá»±a chá»n tá»‘t cho cÃ¡c dá»¯ liá»‡u khÃ¡c nhÆ° dá»¯ liá»‡u tÃ i chÃ­nh, nhiá»‡t Ä‘á»™, ...
VÃ  tá»« 2 cÃ¢u há»i trÃªn thÃ¬ em cÃ³ tham kháº£o 1 paper (https://arxiv.org/abs/2205.13504) nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i cho 2 cÃ¢u há»i trÃªn.
Váº­y liá»‡u self-attention cÃ³ thá»±c sá»± lÃ m máº¥t Ä‘i Ã­t nhiá»u thÃ´ng tin tá»« sá»± tÆ°Æ¡ng quan cá»§a data khÃ´ng? Náº¿u transformer cÃ³ káº¿t quáº£ tháº¥p hÆ¡n cÃ¡c model linear nhÆ° trong paper Ä‘Ã£ trÃ¬nh bÃ y thÃ¬ cÃ³ nhá»¯ng hÆ°á»›ng tiáº¿p cáº­n nÃ o tá»‘t hÆ¡n cho dáº¡ng data nÃ y khÃ´ng?
Em xin cáº£m Æ¡n","Dáº¡ chÃ o má»i ngÆ°á»i, láº¡i lÃ  em Ä‘Ã¢y áº¡. HÃ´m nay em Ä‘em Ä‘áº¿n 1 váº¥n Ä‘á» nhÆ° sau: Gáº§n Ä‘Ã¢y thÃ¬ cÃ³ ráº¥t nhiá»u paper á»©ng dá»¥ng cÃ¡c method Transformer-based cho time series data. Tuy nhiÃªn sau khi tiáº¿p thá»¥ tri thá»©c tá»« 1 vÃ i nguá»“n thÃ¬ em nháº­n Ä‘Æ°á»£c 1 sá»‘ cÃ¢u há»i nhÆ° nÃ y: 1. KhÃ¡c vá»›i ngÃ´n ngá»¯, dá»¯ liá»‡u dáº¡ng time series cÃ³ sá»± liÃªn há»‡ á»Ÿ thá»i gian t vá»›i thá»i gian t-1. NÃªn liá»‡u viá»‡c ta sá»­ dá»¥ng self-attention cho dá»¯ liá»‡u dáº¡ng nÃ y cÃ³ á»•n khÃ´ng? 2. Liá»‡u transformer-based cÃ³ lÃ  1 lá»±a chá»n tá»‘t cho cÃ¡c dá»¯ liá»‡u khÃ¡c nhÆ° dá»¯ liá»‡u tÃ i chÃ­nh, nhiá»‡t Ä‘á»™, ... VÃ  tá»« 2 cÃ¢u há»i trÃªn thÃ¬ em cÃ³ tham kháº£o 1 paper (https://arxiv.org/abs/2205.13504) nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i cho 2 cÃ¢u há»i trÃªn. Váº­y liá»‡u self-attention cÃ³ thá»±c sá»± lÃ m máº¥t Ä‘i Ã­t nhiá»u thÃ´ng tin tá»« sá»± tÆ°Æ¡ng quan cá»§a data khÃ´ng? Náº¿u transformer cÃ³ káº¿t quáº£ tháº¥p hÆ¡n cÃ¡c model linear nhÆ° trong paper Ä‘Ã£ trÃ¬nh bÃ y thÃ¬ cÃ³ nhá»¯ng hÆ°á»›ng tiáº¿p cáº­n nÃ o tá»‘t hÆ¡n cho dáº¡ng data nÃ y khÃ´ng? Em xin cáº£m Æ¡n",,,,,
"CodeGPT - VSCode Sáº¼ Máº NH Máº¼ hÆ¡n vá»›i tÃ­nh nÄƒng tÆ°Æ¡ng tá»± ChatGPT
MÃ¬nh xin chia sáº» vá»›i má»i ngÆ°á»i full hÆ°á»›ng dáº«n cÃ i Ä‘áº·t, setting vÃ  sá»­ dá»¥ng Code GPT extension trong VSCode. Code GPT lÃ  má»™t cÃ´ng cá»¥ tÆ°Æ¡ng tá»± nhÆ° GitHub Copilot. BÃ¢y giá» má»i ngÆ°á»i cÃ³ thá»ƒ thao tÃ¡c trá»±c tiáº¿p ngay trong VSCode vÃ  cÃ³ thÃªm má»™t cÃ´ng cá»¥ há»— trá»£ Ä‘áº¯c lá»±c hÆ¡n ná»¯a trong viá»‡c coding.
Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i.
https://youtu.be/kwXn0s31fpE","CodeGPT - VSCode Sáº¼ Máº NH Máº¼ hÆ¡n vá»›i tÃ­nh nÄƒng tÆ°Æ¡ng tá»± ChatGPT MÃ¬nh xin chia sáº» vá»›i má»i ngÆ°á»i full hÆ°á»›ng dáº«n cÃ i Ä‘áº·t, setting vÃ  sá»­ dá»¥ng Code GPT extension trong VSCode. Code GPT lÃ  má»™t cÃ´ng cá»¥ tÆ°Æ¡ng tá»± nhÆ° GitHub Copilot. BÃ¢y giá» má»i ngÆ°á»i cÃ³ thá»ƒ thao tÃ¡c trá»±c tiáº¿p ngay trong VSCode vÃ  cÃ³ thÃªm má»™t cÃ´ng cá»¥ há»— trá»£ Ä‘áº¯c lá»±c hÆ¡n ná»¯a trong viá»‡c coding. Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i. https://youtu.be/kwXn0s31fpE",,,,,
"anh chá»‹ giÃºp Ä‘á»¡ em vá»›i áº¡
em chÆ°a hiá»ƒu khÃºc X[label == 0, :] hoáº¡t Ä‘á»™ng sao áº¡
Anh chá»‹ giÃºp em hiá»ƒu rÃµ khÃºc Ä‘Ã³ Ä‘c ko Ã£
Em newbie nÃªn mong mn chá»‰ giÃ¡o áº¡ :(","anh chá»‹ giÃºp Ä‘á»¡ em vá»›i áº¡ em chÆ°a hiá»ƒu khÃºc X[label == 0, :] hoáº¡t Ä‘á»™ng sao áº¡ Anh chá»‹ giÃºp em hiá»ƒu rÃµ khÃºc Ä‘Ã³ Ä‘c ko Ã£ Em newbie nÃªn mong mn chá»‰ giÃ¡o áº¡ :(",,,,,
"ChÃ o má»i ngÆ°á»i, trÆ°á»›c háº¿t chÃºc má»i ngÆ°á»i cÃ³ nhá»¯ng ngÃ y táº¿t vui váº».
Hiá»‡n táº¡i mÃ¬nh Ä‘ang há»c khÃ³a Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization tuáº§n 1 ( KhÃ³a 2 cá»§a DLS). MÃ¬nh cÃ³ chá»— khÃ´ng hiá»ƒu nhÆ° sau:
- L2 regularization:
1. Vá» phÆ°Æ¡ng phÃ¡p L2 regularization viá»‡c tÄƒng lambda khi cáº­p nháº­t W giá»‘ng nhÆ° tÄƒng alpha khi update W (W = W - alpha * dW).
2. NhÆ° slide How does regularization prevent overfitting bÃªn dÆ°á»›i thÃ¬ Ä‘oáº¡n mÃ u Ä‘á» Ä‘Ã³ lÃ  viá»‡c regularization nÃ³ trÆ°á»£t xuá»‘ng khi hÃ m tá»‘i Æ°u tá»« 1 vá» 0 nhÆ°ng mÃ¬nh nghe khi lambda cao quÃ¡ nÃ³ sáº½ lÃ m g(z) gáº§n nhÆ° vá» tuyáº¿n tÃ­nh. MÃ¬nh khÃ´ng hiá»ƒu láº¯m, má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch rÃµ hÆ¡n hoáº·c Ä‘Æ°a ra vÃ­ dá»¥ Ä‘Æ°á»£c khÃ´ng áº¡.
- Dropout:
1. NÃ³ sáº½ táº¯t ngáº«u nhiÃªn tá»«ng nhÃ¢n vÃ  sá»­ dá»¥ng ""Inverted dropout"" Ä‘á»ƒ giá»¯ cho layer sau hoáº¡t Ä‘á»™ng má»™t cÃ¡ch bÃ¬nh thÆ°á»ng. Tuy nhiÃªn, á»Ÿ clip Understanding dropout viá»‡c táº¯t ngáº«u nhiÃªn nháº±m: ""Can't rely on any one feature, so have to spread out weights."". Theo mÃ¬nh hiá»ƒu lÃ  nÃ³ sáº½ táº¯t má»™t sá»‘ nhÃ¢n khi forward propagation vÃ  viá»‡c update (back propagation) lÃ  nÃ³ sáº½ váº«n bÃ¬nh thÆ°á»ng Ä‘Ãºng khÃ´ng áº¡?
2. MÃ¬nh váº«n mÆ¡ há»“ vá» viá»‡c táº¯t 1 sá»‘ nhÃ¢n giá»‘ng nhÆ° L2 regularization. MÃ¬nh mong nháº­n Ä‘Æ°á»£c vÃ­ dá»¥ hay giáº£i thÃ­ch rÃµ rÃ ng hÆ¡n áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.","ChÃ o má»i ngÆ°á»i, trÆ°á»›c háº¿t chÃºc má»i ngÆ°á»i cÃ³ nhá»¯ng ngÃ y táº¿t vui váº». Hiá»‡n táº¡i mÃ¬nh Ä‘ang há»c khÃ³a Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization tuáº§n 1 ( KhÃ³a 2 cá»§a DLS). MÃ¬nh cÃ³ chá»— khÃ´ng hiá»ƒu nhÆ° sau: - L2 regularization: 1. Vá» phÆ°Æ¡ng phÃ¡p L2 regularization viá»‡c tÄƒng lambda khi cáº­p nháº­t W giá»‘ng nhÆ° tÄƒng alpha khi update W (W = W - alpha * dW). 2. NhÆ° slide How does regularization prevent overfitting bÃªn dÆ°á»›i thÃ¬ Ä‘oáº¡n mÃ u Ä‘á» Ä‘Ã³ lÃ  viá»‡c regularization nÃ³ trÆ°á»£t xuá»‘ng khi hÃ m tá»‘i Æ°u tá»« 1 vá» 0 nhÆ°ng mÃ¬nh nghe khi lambda cao quÃ¡ nÃ³ sáº½ lÃ m g(z) gáº§n nhÆ° vá» tuyáº¿n tÃ­nh. MÃ¬nh khÃ´ng hiá»ƒu láº¯m, má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch rÃµ hÆ¡n hoáº·c Ä‘Æ°a ra vÃ­ dá»¥ Ä‘Æ°á»£c khÃ´ng áº¡. - Dropout: 1. NÃ³ sáº½ táº¯t ngáº«u nhiÃªn tá»«ng nhÃ¢n vÃ  sá»­ dá»¥ng ""Inverted dropout"" Ä‘á»ƒ giá»¯ cho layer sau hoáº¡t Ä‘á»™ng má»™t cÃ¡ch bÃ¬nh thÆ°á»ng. Tuy nhiÃªn, á»Ÿ clip Understanding dropout viá»‡c táº¯t ngáº«u nhiÃªn nháº±m: ""Can't rely on any one feature, so have to spread out weights."". Theo mÃ¬nh hiá»ƒu lÃ  nÃ³ sáº½ táº¯t má»™t sá»‘ nhÃ¢n khi forward propagation vÃ  viá»‡c update (back propagation) lÃ  nÃ³ sáº½ váº«n bÃ¬nh thÆ°á»ng Ä‘Ãºng khÃ´ng áº¡? 2. MÃ¬nh váº«n mÆ¡ há»“ vá» viá»‡c táº¯t 1 sá»‘ nhÃ¢n giá»‘ng nhÆ° L2 regularization. MÃ¬nh mong nháº­n Ä‘Æ°á»£c vÃ­ dá»¥ hay giáº£i thÃ­ch rÃµ rÃ ng hÆ¡n áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.",,,,,
"Dáº¡ chÃ o cÃ¡c anh chá»‹, hiá»‡n em cÃ³ nháº­n Ä‘Æ°á»£c thÃ´ng tin cuá»™c thi AI City challenge 2023 Ä‘Ã£ cÃ´ng bá»‘ cÃ¡c tracks vÃ  em cÅ©ng Ä‘ang muá»‘n tham gia cuá»™c thi Ä‘á»ƒ há»c há»i thÃªm kinh nghiá»‡m.
Em viáº¿t bÃ i viáº¿t nÃ y Ä‘á»ƒ tÃ¬m kiáº¿m mentor hoáº·c may máº¯n hÆ¡n lÃ  tÃ¬m kiáº¿m 1 team tham gia cuá»™c thi. Hiá»‡n em Ä‘ang cÃ³ mong muá»‘n tham gia track 2 nhÆ°ng náº¿u Ä‘Æ°á»£c thÃ¬ em váº«n mong muá»‘n cÃ³ thá»ƒ há»c á»Ÿ nhÆ°ng track khÃ¡c náº¿u Ä‘Æ°á»£c.
Em xin cáº£m Æ¡n","Dáº¡ chÃ o cÃ¡c anh chá»‹, hiá»‡n em cÃ³ nháº­n Ä‘Æ°á»£c thÃ´ng tin cuá»™c thi AI City challenge 2023 Ä‘Ã£ cÃ´ng bá»‘ cÃ¡c tracks vÃ  em cÅ©ng Ä‘ang muá»‘n tham gia cuá»™c thi Ä‘á»ƒ há»c há»i thÃªm kinh nghiá»‡m. Em viáº¿t bÃ i viáº¿t nÃ y Ä‘á»ƒ tÃ¬m kiáº¿m mentor hoáº·c may máº¯n hÆ¡n lÃ  tÃ¬m kiáº¿m 1 team tham gia cuá»™c thi. Hiá»‡n em Ä‘ang cÃ³ mong muá»‘n tham gia track 2 nhÆ°ng náº¿u Ä‘Æ°á»£c thÃ¬ em váº«n mong muá»‘n cÃ³ thá»ƒ há»c á»Ÿ nhÆ°ng track khÃ¡c náº¿u Ä‘Æ°á»£c. Em xin cáº£m Æ¡n",,,,,
"Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t áº¥n pháº©m má»›i vÃ  Ä‘ang dáº§n hoÃ n thiá»‡n cá»§a Dr. Simon J.D. Prince, Senior Lecturer cá»§a University College London. TÃ¡c giáº£ nÃ y tá»«ng cho ra má»™t cuá»‘n sÃ¡ch Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ ráº¥t ráº¥t cao trong lÄ©nh vá»±c Computer Vision lÃ  ""Computer Vision: Models, Learning, and Inference.""
áº¤n pháº©m dá»± kiáº¿n xuáº¥t báº£n nÄƒm 2024, báº£n phÃ¡t tháº£o Ä‘Æ°á»£c published hÃ´m 24/01 vÃ  cover cáº£ nhá»¯ng chá»§ Ä‘á» ráº¥t nÃ³ng nhÆ° Diffusion models. Dr. Prince Ä‘ang kÃªu gá»i má»i ngÆ°á»i Ä‘á» xuáº¥t vÃ  chá»‰nh lÃ½ náº¿u cÃ³ sai sÃ³t.
Link:","Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t áº¥n pháº©m má»›i vÃ  Ä‘ang dáº§n hoÃ n thiá»‡n cá»§a Dr. Simon J.D. Prince, Senior Lecturer cá»§a University College London. TÃ¡c giáº£ nÃ y tá»«ng cho ra má»™t cuá»‘n sÃ¡ch Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ ráº¥t ráº¥t cao trong lÄ©nh vá»±c Computer Vision lÃ  ""Computer Vision: Models, Learning, and Inference."" áº¤n pháº©m dá»± kiáº¿n xuáº¥t báº£n nÄƒm 2024, báº£n phÃ¡t tháº£o Ä‘Æ°á»£c published hÃ´m 24/01 vÃ  cover cáº£ nhá»¯ng chá»§ Ä‘á» ráº¥t nÃ³ng nhÆ° Diffusion models. Dr. Prince Ä‘ang kÃªu gá»i má»i ngÆ°á»i Ä‘á» xuáº¥t vÃ  chá»‰nh lÃ½ náº¿u cÃ³ sai sÃ³t. Link:",,,,,
"Há»c bá»•ng há»™i tháº£o Wikimania 2023 vÃ o 16â€“19 August 2023 táº¡i Singapore.
Náº¿u ai cÃ³ Ä‘Ã³ng gÃ³p hoáº·c nghiÃªn cá»©u vá» Wikipedia vÃ  cÃ¡c dá»± Ã¡n chá»‹ em liÃªn quan nhÆ° Wikidata, Wiktionary,... thÃ¬ cÃ³ thá»ƒ xem thÃ´ng tin Ä‘á»ƒ Ä‘Äƒng kÃ½!
https://wikimania.wikimedia.org/wiki/2023:Scholarships
https://wikimania.wikimedia.org/wiki/2023:Scholarships/Travel_Scholarship_application","Há»c bá»•ng há»™i tháº£o Wikimania 2023 vÃ o 16â€“19 August 2023 táº¡i Singapore. Náº¿u ai cÃ³ Ä‘Ã³ng gÃ³p hoáº·c nghiÃªn cá»©u vá» Wikipedia vÃ  cÃ¡c dá»± Ã¡n chá»‹ em liÃªn quan nhÆ° Wikidata, Wiktionary,... thÃ¬ cÃ³ thá»ƒ xem thÃ´ng tin Ä‘á»ƒ Ä‘Äƒng kÃ½! https://wikimania.wikimedia.org/wiki/2023:Scholarships https://wikimania.wikimedia.org/wiki/2023:Scholarships/Travel_Scholarship_application",,,,,
Distributed Training cho huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c sÃ¢u,Distributed Training cho huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c sÃ¢u,,,,,
"Hi má»i ngÆ°á»i,
Em Ä‘ang lÃ m má»™t dá»± Ã¡n NLP vá» tÃ³m táº¯t. Hiá»‡n táº¡i em gáº·p váº¥n Ä‘á» khi tÃ³m táº¯t má»™t lÆ°á»£ng text dÃ i thÃ¬ cost cháº¡y model nhiá»u. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ em cÃ³ thá»ƒ giá»¯ Ä‘Æ°á»£c context khÃ´ng áº¡? Em lÃ  newbie trong máº£ng nÃ y nÃªn má»i ngÆ°á»i biáº¿t keyword, bÃ i bÃ¡o gÃ¬ em nÃªn cáº§n há»c thÃ¬ chá»‰ em vá»›i. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u ^^","Hi má»i ngÆ°á»i, Em Ä‘ang lÃ m má»™t dá»± Ã¡n NLP vá» tÃ³m táº¯t. Hiá»‡n táº¡i em gáº·p váº¥n Ä‘á» khi tÃ³m táº¯t má»™t lÆ°á»£ng text dÃ i thÃ¬ cost cháº¡y model nhiá»u. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ em cÃ³ thá»ƒ giá»¯ Ä‘Æ°á»£c context khÃ´ng áº¡? Em lÃ  newbie trong máº£ng nÃ y nÃªn má»i ngÆ°á»i biáº¿t keyword, bÃ i bÃ¡o gÃ¬ em nÃªn cáº§n há»c thÃ¬ chá»‰ em vá»›i. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u ^^",,,,,
"ChÃºc má»i ngÆ°á»i má»™t nÄƒm má»›i máº¡nh khá»e. ChÃºc cho AI Viá»‡t Nam sáº½ cÃ³ nhiá»u bÆ°á»›c tiáº¿n má»›i, khai phÃ¡ nhá»¯ng vÃ¹ng Ä‘áº¥t má»›i Ä‘á»ƒ anh em cÃ³ nhiá»u viá»‡c lÃ m. ChÃºc diá»…n Ä‘Ã n ngÃ y cÃ ng cÃ³ nhiá»u cÃ¢u há»i vÃ  post chia sáº» hay.","ChÃºc má»i ngÆ°á»i má»™t nÄƒm má»›i máº¡nh khá»e. ChÃºc cho AI Viá»‡t Nam sáº½ cÃ³ nhiá»u bÆ°á»›c tiáº¿n má»›i, khai phÃ¡ nhá»¯ng vÃ¹ng Ä‘áº¥t má»›i Ä‘á»ƒ anh em cÃ³ nhiá»u viá»‡c lÃ m. ChÃºc diá»…n Ä‘Ã n ngÃ y cÃ ng cÃ³ nhiá»u cÃ¢u há»i vÃ  post chia sáº» hay.",,,,,
"Dáº¡ chÃ o má»i ngÆ°á»i, hÃ´m nay em cÃ³ cÃ¢u há»i nhÆ° sau:
Trong paper vá» Batch Norm thÃ¬ tÃ¡c giáº£ cÃ³ nháº¯c Ä‘áº¿n Ä‘á»‹nh nghÄ©a Internal Covariate Shift. Theo cÃ¡ nhÃ¢n em hiá»ƒu thÃ¬ Ä‘Ã¢y lÃ  sá»± thay Ä‘á»•i vá» phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u sau khi Ä‘i qua cÃ¡c layer cá»§a máº¡ng. Tuy nhiÃªn cÃ³ má»™t láº­p luáº­n lÃ  do BN sá»­ dá»¥ng 2 hyperparameters lÃ  Î³ vÃ  Î² nÃªn 2 tham sá»‘ nÃ y cÅ©ng gÃ³p pháº§n táº¡o ra Internal Covariate Shift chá»© khÃ´ng giáº£i quyáº¿t ICS.
CÃ²n lÃ½ do mÃ  BN cÃ³ thá»ƒ lÃ m tÄƒng tá»‘c training vÃ¬ optimizer chá»‰ cáº§n quáº£n lÃ½ phÃ¢n phá»‘i giá»¯a cÃ¡c layer báº±ng 2 tham sá»‘ trÃªn.
Anh/chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p cho em vá» váº¥n Ä‘á» nÃ y khÃ´ng áº¡?
https://blog.paperspace.com/busting-the-myths-about-batch-normalization/","Dáº¡ chÃ o má»i ngÆ°á»i, hÃ´m nay em cÃ³ cÃ¢u há»i nhÆ° sau: Trong paper vá» Batch Norm thÃ¬ tÃ¡c giáº£ cÃ³ nháº¯c Ä‘áº¿n Ä‘á»‹nh nghÄ©a Internal Covariate Shift. Theo cÃ¡ nhÃ¢n em hiá»ƒu thÃ¬ Ä‘Ã¢y lÃ  sá»± thay Ä‘á»•i vá» phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u sau khi Ä‘i qua cÃ¡c layer cá»§a máº¡ng. Tuy nhiÃªn cÃ³ má»™t láº­p luáº­n lÃ  do BN sá»­ dá»¥ng 2 hyperparameters lÃ  Î³ vÃ  Î² nÃªn 2 tham sá»‘ nÃ y cÅ©ng gÃ³p pháº§n táº¡o ra Internal Covariate Shift chá»© khÃ´ng giáº£i quyáº¿t ICS. CÃ²n lÃ½ do mÃ  BN cÃ³ thá»ƒ lÃ m tÄƒng tá»‘c training vÃ¬ optimizer chá»‰ cáº§n quáº£n lÃ½ phÃ¢n phá»‘i giá»¯a cÃ¡c layer báº±ng 2 tham sá»‘ trÃªn. Anh/chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p cho em vá» váº¥n Ä‘á» nÃ y khÃ´ng áº¡? https://blog.paperspace.com/busting-the-myths-about-batch-normalization/",,,,,
"ğŸ’—ğŸ’—ğŸ’—ğŸ±ğŸ±ğŸ±
NÄƒm má»›i mÃ¨o chá»— má»i ngÆ°á»i nhÆ° tháº¿ nÃ o, cÃ²n Ä‘Ã¢y lÃ  mÃ¨o AI cá»§a mÃ¬nh tá»« Midjouney nhÃ¬n nÃ³ láº¡ láº¯m.
Midjourney cÅ©ng tÆ°Æ¡ng tá»± nhÆ° DALL-E 2 vÃ  Stable Diffusion giÃºp sinh áº£nh tá»« text nháº­p vÃ o. CÃ³ ngÆ°á»i Ä‘Ã£ dÃ¹ng áº£nh Ä‘Æ°á»£c táº¡o báº±ng Midjourney vÃ  chiáº¿n tháº¯ng trong má»™t cuá»™c thi vá» áº£nh. Má»i ngÆ°á»i cÃ¹ng tÃ¬m hiá»ƒu vá» cÃ¡ch sá»­ dá»¥ng Midjourney Ä‘á»ƒ sinh áº£nh.
Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i.","NÄƒm má»›i mÃ¨o chá»— má»i ngÆ°á»i nhÆ° tháº¿ nÃ o, cÃ²n Ä‘Ã¢y lÃ  mÃ¨o AI cá»§a mÃ¬nh tá»« Midjouney nhÃ¬n nÃ³ láº¡ láº¯m. Midjourney cÅ©ng tÆ°Æ¡ng tá»± nhÆ° DALL-E 2 vÃ  Stable Diffusion giÃºp sinh áº£nh tá»« text nháº­p vÃ o. CÃ³ ngÆ°á»i Ä‘Ã£ dÃ¹ng áº£nh Ä‘Æ°á»£c táº¡o báº±ng Midjourney vÃ  chiáº¿n tháº¯ng trong má»™t cuá»™c thi vá» áº£nh. Má»i ngÆ°á»i cÃ¹ng tÃ¬m hiá»ƒu vá» cÃ¡ch sá»­ dá»¥ng Midjourney Ä‘á»ƒ sinh áº£nh. Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i.",,,,,
"MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» cÆ¡ cháº¿ Attention trong Deep Learning vÃ  Ä‘ang cÃ³ má»™t tháº¯c máº¯c lÃ  cÆ¡ cháº¿ embedding cÃ³ pháº£i lÃ  má»™t bÆ°á»›c cá»§a Attention khÃ´ng? Hay lÃ  2 cÆ¡ cháº¿ nÃ y cÃ³ liÃªn quan gÃ¬ Ä‘áº¿n nhau khÃ´ng áº¡?
Theo mÃ¬nh hiá»ƒu thÃ¬
Embedding: giáº£m dimensions cá»§a input --> má»¥c Ä‘Ã­ch giáº£m nháº¹ khá»‘i lÆ°á»£ng input (?) - mÃ¬nh khÃ´ng cháº¯c láº¯m
Attention: táº­p trung vÃ o vÃ  biá»ƒu diá»…n chá»‰ nhá»¯ng Ä‘iá»ƒm quan trá»ng cá»§a input Ä‘á»ƒ Ä‘Æ°a qua cÃ¡c layer tiáº¿p theo (?) - Link tham kháº£o: https://viblo.asia/p/tim-hieu-ve-co-che-attention-924lJjbmlPM
Mong má»i ngÆ°á»i giÃºp mÃ¬nh giáº£i Ä‘Ã¡p tháº¯c máº¯c nÃ y vá»›i áº¡. MÃ¬nh cáº£m Æ¡n.",MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» cÆ¡ cháº¿ Attention trong Deep Learning vÃ  Ä‘ang cÃ³ má»™t tháº¯c máº¯c lÃ  cÆ¡ cháº¿ embedding cÃ³ pháº£i lÃ  má»™t bÆ°á»›c cá»§a Attention khÃ´ng? Hay lÃ  2 cÆ¡ cháº¿ nÃ y cÃ³ liÃªn quan gÃ¬ Ä‘áº¿n nhau khÃ´ng áº¡? Theo mÃ¬nh hiá»ƒu thÃ¬ Embedding: giáº£m dimensions cá»§a input --> má»¥c Ä‘Ã­ch giáº£m nháº¹ khá»‘i lÆ°á»£ng input (?) - mÃ¬nh khÃ´ng cháº¯c láº¯m Attention: táº­p trung vÃ o vÃ  biá»ƒu diá»…n chá»‰ nhá»¯ng Ä‘iá»ƒm quan trá»ng cá»§a input Ä‘á»ƒ Ä‘Æ°a qua cÃ¡c layer tiáº¿p theo (?) - Link tham kháº£o: https://viblo.asia/p/tim-hieu-ve-co-che-attention-924lJjbmlPM Mong má»i ngÆ°á»i giÃºp mÃ¬nh giáº£i Ä‘Ã¡p tháº¯c máº¯c nÃ y vá»›i áº¡. MÃ¬nh cáº£m Æ¡n.,,,,,
"Let's build GPT: from scratch, in code, spelled out.
Author:Andrej Karpathy - Ex Director of Tesla AI
We build a Generatively Pretrained Transformer (GPT), following the paper ""Attention is All You Need"" and OpenAI's GPT-2 / GPT-3. We talk about connections to ChatGPT, which has taken the world by storm. We watch GitHub Copilot, itself a GPT, help us write a GPT (meta :D!) . I recommend people watch the earlier makemore videos to get comfortable with the autoregressive language modeling framework and basics of tensors and PyTorch nn, which we take for granted in this video.
https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathyLinks:
- Google colab for the video: https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing
- GitHub repo for the video: https://github.com/karpathy/ng-video-lecture
#deeplearning #chatgpt ","Let's build GPT: from scratch, in code, spelled out. Author:Andrej Karpathy - Ex Director of Tesla AI We build a Generatively Pretrained Transformer (GPT), following the paper ""Attention is All You Need"" and OpenAI's GPT-2 / GPT-3. We talk about connections to ChatGPT, which has taken the world by storm. We watch GitHub Copilot, itself a GPT, help us write a GPT (meta :D!) . I recommend people watch the earlier makemore videos to get comfortable with the autoregressive language modeling framework and basics of tensors and PyTorch nn, which we take for granted in this video. https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathyLinks: - Google colab for the video: https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing - GitHub repo for the video: https://github.com/karpathy/ng-video-lecture",#deeplearning	#chatgpt,,,,
"CÃ¢u há»i vá» RNN vÃ  BPTT - Backpropagation through time.
Cáº£ nhÃ  cho em há»i táº¡i sao trong RNN Ä‘áº¡o hÃ m cá»§a Loss Function so vá»›i so vá»›i cÃ¡c nodes ngay phÃ­a trÆ°á»›c láº¡i báº±ng 1 áº¡?
Em cÃ¡m Æ¡n áº¡",CÃ¢u há»i vá» RNN vÃ  BPTT - Backpropagation through time. Cáº£ nhÃ  cho em há»i táº¡i sao trong RNN Ä‘áº¡o hÃ m cá»§a Loss Function so vá»›i so vá»›i cÃ¡c nodes ngay phÃ­a trÆ°á»›c láº¡i báº±ng 1 áº¡? Em cÃ¡m Æ¡n áº¡,,,,,
"MÃ¬nh Ä‘ang Ä‘á»c paper vá» sales forecasting cho sáº£n pháº©m má»›i thÃ´ng qua hÃ¬nh áº£nh + text data + temporal data + ggtrends.
Má»i ngÆ°á»i cho mÃ¬nh há»i Ä‘oáº¡n highlight nÃ y Ã½ muá»‘n nÃ³i dá»± Ä‘oÃ¡n doanh sá»‘ cá»§a sáº£n pháº©m má»›i chá»‰ báº±ng cÃ¡ch sá»­ dá»¥ng image cá»§a sp má»›i nÃ y vÃ  image cá»§a sp trÆ°á»›c Ä‘Ã³, káº¿t há»£p vá»›i temporal data + ggtrends hiá»‡n táº¡i thÃ´i Ä‘Ãºng khÃ´ng áº¡? KhÃ´ng sá»­ dá»¥ng cÃ¡c features khÃ¡c cá»§a nhá»¯ng product trÆ°á»›c (ngoáº¡i trá»« image).
Link paper: https://arxiv.org/pdf/2204.06972v2.pdf","MÃ¬nh Ä‘ang Ä‘á»c paper vá» sales forecasting cho sáº£n pháº©m má»›i thÃ´ng qua hÃ¬nh áº£nh + text data + temporal data + ggtrends. Má»i ngÆ°á»i cho mÃ¬nh há»i Ä‘oáº¡n highlight nÃ y Ã½ muá»‘n nÃ³i dá»± Ä‘oÃ¡n doanh sá»‘ cá»§a sáº£n pháº©m má»›i chá»‰ báº±ng cÃ¡ch sá»­ dá»¥ng image cá»§a sp má»›i nÃ y vÃ  image cá»§a sp trÆ°á»›c Ä‘Ã³, káº¿t há»£p vá»›i temporal data + ggtrends hiá»‡n táº¡i thÃ´i Ä‘Ãºng khÃ´ng áº¡? KhÃ´ng sá»­ dá»¥ng cÃ¡c features khÃ¡c cá»§a nhá»¯ng product trÆ°á»›c (ngoáº¡i trá»« image). Link paper: https://arxiv.org/pdf/2204.06972v2.pdf",,,,,
"chÃ o mn áº¡
Hiá»‡n táº¡i trong nhÃ³m cÃ³ ai cÃ²n cÃ³ sÃ¡ch nÃ y báº£n má»m k dÃ¹ng cÃ³ tháº¿ pass láº¡i cho e Ä‘c khÃ´ng áº¡
Thanks mn !!!!",chÃ o mn áº¡ Hiá»‡n táº¡i trong nhÃ³m cÃ³ ai cÃ²n cÃ³ sÃ¡ch nÃ y báº£n má»m k dÃ¹ng cÃ³ tháº¿ pass láº¡i cho e Ä‘c khÃ´ng áº¡ Thanks mn !!!!,,,,,
"Hello má»i ngÆ°á»i, em Ä‘ang bá»‹ lá»—i nhÆ° nÃ y khÃ´ng thá»ƒ active nvpmodel.service Ä‘Æ°á»£c, vÃ o thÆ° má»¥c thÃ¬ cÅ©ng khÃ´ng cÃ³ nhá»¯ng file trÃªn. CÃ¡c cao nhÃ¢n cÃ³ cao kiáº¿n gÃ¬ giÃºp em ko áº¡?","Hello má»i ngÆ°á»i, em Ä‘ang bá»‹ lá»—i nhÆ° nÃ y khÃ´ng thá»ƒ active nvpmodel.service Ä‘Æ°á»£c, vÃ o thÆ° má»¥c thÃ¬ cÅ©ng khÃ´ng cÃ³ nhá»¯ng file trÃªn. CÃ¡c cao nhÃ¢n cÃ³ cao kiáº¿n gÃ¬ giÃºp em ko áº¡?",,,,,
"YOLOv8 demo
Chia sáº» vá»›i anh em video Ä‘áº§u tiÃªn trong tutorials hÆ°á»›ng dáº«n Yolov8. ÄÃ¢y lÃ  káº¿t quáº£ demo cho bÃ i toÃ¡n object detection vÃ  instance segmentation vá»›i video Ä‘Æ°á»ng phá»‘ HÃ  Ná»™i cuá»‘i nÄƒm.
Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i.
https://youtu.be/ZyKK4o4HaAM",YOLOv8 demo Chia sáº» vá»›i anh em video Ä‘áº§u tiÃªn trong tutorials hÆ°á»›ng dáº«n Yolov8. ÄÃ¢y lÃ  káº¿t quáº£ demo cho bÃ i toÃ¡n object detection vÃ  instance segmentation vá»›i video Ä‘Æ°á»ng phá»‘ HÃ  Ná»™i cuá»‘i nÄƒm. Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i. https://youtu.be/ZyKK4o4HaAM,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c!
Nhiá»u báº¡n há»i vá» viá»‡c lÃ m sao Ä‘á»ƒ chá»n cÃ¡c siÃªu tham sá»‘ nhÆ°: sá»‘ lá»›p áº©n, sá»‘ unit trong lá»›p áº©n, learning rate... cho tá»‘i Æ°u. HÃ´m nay mÃ¬nh chia sáº» bÃ i nÃ y hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n nhÃ©!
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!
Ps: BÃ i nÃ y em chia sáº» dá»±a trÃªn hiá»ƒu biáº¿t cÃ¡ nhÃ¢n vÃ  hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c áº¡!","KÃ­nh chÃ o cÃ¡c bÃ¡c! Nhiá»u báº¡n há»i vá» viá»‡c lÃ m sao Ä‘á»ƒ chá»n cÃ¡c siÃªu tham sá»‘ nhÆ°: sá»‘ lá»›p áº©n, sá»‘ unit trong lá»›p áº©n, learning rate... cho tá»‘i Æ°u. HÃ´m nay mÃ¬nh chia sáº» bÃ i nÃ y hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n nhÃ©! ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng! Ps: BÃ i nÃ y em chia sáº» dá»±a trÃªn hiá»ƒu biáº¿t cÃ¡ nhÃ¢n vÃ  hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c áº¡!",,,,,
,nan,,,,,
Sinh viÃªn viáº¿t á»©ng dá»¥ng GPTZero chá»‘ng Ä‘áº¡o vÄƒn AI thÃ nh cÃ´ng,Sinh viÃªn viáº¿t á»©ng dá»¥ng GPTZero chá»‘ng Ä‘áº¡o vÄƒn AI thÃ nh cÃ´ng,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» applications cá»§a thuáº­t toÃ¡n k-means, em cÃ³ code theo code máº«u cá»§a anh Tiá»‡p thÃ¬ bá»‹ lá»—i á»Ÿ pháº§n gáº¡ch mÃ u vÃ ng áº¡ (hÃ¬nh 1) thÃ¬ Ä‘Æ°á»£c bÃ¡o lá»—i (hÃ¬nh 2)
Em Ä‘Ã£ download database cá»§a MNIST vá» mÃ¡y vÃ  Ä‘Ã£ giáº£i nÃ©n cÃ¡c file cáº§n thiáº¿t nhÆ°ng láº¡i bá»‹ bÃ¡o lá»—i khÃ´ng tÃ¬m tháº¥y file áº¡. Má»i ngÆ°á»i náº¿u Ä‘Ã£ tá»«ng bá»‹ lá»—i nÃ y cÃ³ thá»ƒ cho em xin hÆ°á»›ng giáº£i quyáº¿t Ä‘Æ°á»£c khÃ´ng áº¡?","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» applications cá»§a thuáº­t toÃ¡n k-means, em cÃ³ code theo code máº«u cá»§a anh Tiá»‡p thÃ¬ bá»‹ lá»—i á»Ÿ pháº§n gáº¡ch mÃ u vÃ ng áº¡ (hÃ¬nh 1) thÃ¬ Ä‘Æ°á»£c bÃ¡o lá»—i (hÃ¬nh 2) Em Ä‘Ã£ download database cá»§a MNIST vá» mÃ¡y vÃ  Ä‘Ã£ giáº£i nÃ©n cÃ¡c file cáº§n thiáº¿t nhÆ°ng láº¡i bá»‹ bÃ¡o lá»—i khÃ´ng tÃ¬m tháº¥y file áº¡. Má»i ngÆ°á»i náº¿u Ä‘Ã£ tá»«ng bá»‹ lá»—i nÃ y cÃ³ thá»ƒ cho em xin hÆ°á»›ng giáº£i quyáº¿t Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"Mn cho em há»i data normalization( Ä‘Æ°a vá» sá»‘ nhá» hÆ¡n) khÃ¡c data transformation( Ä‘Æ°a data vá» normal distribution) á»Ÿ chá»— nÃ o áº¡ vÃ¬ em tháº¥y normalization cÅ©ng cÃ³ thá»ƒ Ä‘Æ°a data vá» dáº¡ng normal distrinution Ä‘c. Váº­y thÃ¬ data transformation cÃ³ tÃ¡c dá»¥ng gÃ¬ khi normalization Ä‘Ã£ Ä‘Æ°a data vá» normal distribution mÃ  khÃ´ng lÃ m máº¥t Ä‘i Ã½ nghÄ©a cá»§a data( khi transfrom thÃ¬ data khÃ´ng cÃ²n Ã½ nghÄ©a nhÆ° ban Ä‘áº§u ná»¯a, cÃ²n normaklization thÃ¬ váº«n cÃ²n)? Em tháº¥y 1 sá»‘ bÃ i machine learning nÃ³ vá»«a normalization vá»«a transformation áº¡.","Mn cho em há»i data normalization( Ä‘Æ°a vá» sá»‘ nhá» hÆ¡n) khÃ¡c data transformation( Ä‘Æ°a data vá» normal distribution) á»Ÿ chá»— nÃ o áº¡ vÃ¬ em tháº¥y normalization cÅ©ng cÃ³ thá»ƒ Ä‘Æ°a data vá» dáº¡ng normal distrinution Ä‘c. Váº­y thÃ¬ data transformation cÃ³ tÃ¡c dá»¥ng gÃ¬ khi normalization Ä‘Ã£ Ä‘Æ°a data vá» normal distribution mÃ  khÃ´ng lÃ m máº¥t Ä‘i Ã½ nghÄ©a cá»§a data( khi transfrom thÃ¬ data khÃ´ng cÃ²n Ã½ nghÄ©a nhÆ° ban Ä‘áº§u ná»¯a, cÃ²n normaklization thÃ¬ váº«n cÃ²n)? Em tháº¥y 1 sá»‘ bÃ i machine learning nÃ³ vá»«a normalization vá»«a transformation áº¡.",,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i lá»—i nÃ y cÃ³ thá»ƒ do Ä‘Ã¢u váº­y nhá»‰: 
-""failed to start local kernel module""

    2.- CUDA Error: no kernel image is available for execution on the device
polarisnnet: ./src/cuda.c:36: check_error: Assertion `0' failed.
/home/nvidia/test.sh: line 4: 10345 Aborted                 (core dumped) ./polarisnnet detector line data/test/t.data data/test/t.cfg data/test/t.weights data/test/t.mp4
MÃ¬nh Ä‘ang láº¯p Ä‘áº·t Nvidia AGX Xavier cÃ i Jetpack 4.2, khi flash xong thÃ¬ load screen hiá»‡n lá»—i ""failed to start local kernel module"" vÃ  máº¥t luÃ´n hai cá»•ng USB khÃ´ng thá»ƒ sá»­ dá»¥ng. MÃ¬nh thá»­ flash nhÆ° váº­y trÃªn Nvidia TX2 thÃ¬ váº«n bÃ¡o lá»—i nhÆ° trÃªn nhÆ°ng khi cháº¡y thá»­ file test thÃ¬ hiá»‡n lá»—i nhÆ° má»¥c (2).
CÃ¡c bÃ¡c cÃ³ cao kiáº¿n gÃ¬ chá»‰ mÃ¬nh khÃ´ng?","Má»i ngÆ°á»i cho mÃ¬nh há»i lá»—i nÃ y cÃ³ thá»ƒ do Ä‘Ã¢u váº­y nhá»‰: -""failed to start local kernel module"" 2.- CUDA Error: no kernel image is available for execution on the device polarisnnet: ./src/cuda.c:36: check_error: Assertion `0' failed. /home/nvidia/test.sh: line 4: 10345 Aborted (core dumped) ./polarisnnet detector line data/test/t.data data/test/t.cfg data/test/t.weights data/test/t.mp4 MÃ¬nh Ä‘ang láº¯p Ä‘áº·t Nvidia AGX Xavier cÃ i Jetpack 4.2, khi flash xong thÃ¬ load screen hiá»‡n lá»—i ""failed to start local kernel module"" vÃ  máº¥t luÃ´n hai cá»•ng USB khÃ´ng thá»ƒ sá»­ dá»¥ng. MÃ¬nh thá»­ flash nhÆ° váº­y trÃªn Nvidia TX2 thÃ¬ váº«n bÃ¡o lá»—i nhÆ° trÃªn nhÆ°ng khi cháº¡y thá»­ file test thÃ¬ hiá»‡n lá»—i nhÆ° má»¥c (2). CÃ¡c bÃ¡c cÃ³ cao kiáº¿n gÃ¬ chá»‰ mÃ¬nh khÃ´ng?",,,,,
"#jetsonnano
ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang há»c CV vá»›i jetson nano. Em cÃ³ váº¥n Ä‘á» lÃ  lÃºc má»Ÿ cam báº±ng opencv thÃ¬ nÃ³ bÃ¡o lá»—i nhÆ° dÆ°á»›i áº£nh. Em Ä‘Ã£ test thá»­ theo hÆ°á»›ng dáº«n cá»§a bÃªn bÃ¡n hÃ ng thÃ¬ váº«n má»Ÿ Ä‘Æ°á»£c cam, khÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬.
Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o áº¡.","ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang há»c CV vá»›i jetson nano. Em cÃ³ váº¥n Ä‘á» lÃ  lÃºc má»Ÿ cam báº±ng opencv thÃ¬ nÃ³ bÃ¡o lá»—i nhÆ° dÆ°á»›i áº£nh. Em Ä‘Ã£ test thá»­ theo hÆ°á»›ng dáº«n cá»§a bÃªn bÃ¡n hÃ ng thÃ¬ váº«n má»Ÿ Ä‘Æ°á»£c cam, khÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬. Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o áº¡.",#jetsonnano,,,,
"#python #Kmeans #MNIST
Em cÃ³ Ä‘ang lÃ m pháº§n nháº­n diá»‡n chá»¯ sá»‘ vá»›i data MNIST áº¡. Má»i ngÆ°á»i cho em há»i error nÃ y lÃ  sao áº¡ vÃ  fix tháº¿ nÃ o ah. Em xin cáº£m Æ¡n áº¡",Em cÃ³ Ä‘ang lÃ m pháº§n nháº­n diá»‡n chá»¯ sá»‘ vá»›i data MNIST áº¡. Má»i ngÆ°á»i cho em há»i error nÃ y lÃ  sao áº¡ vÃ  fix tháº¿ nÃ o ah. Em xin cáº£m Æ¡n áº¡,#python	#Kmeans	#MNIST,,,,
"Má»™t sá»‘ ghi chÃ©p vá» vÃ i cÃ¢u há»i trong lÃ½ thuyáº¿t há»c mÃ¡y hiá»‡n Ä‘áº¡i:
MSE hay CE cho bÃ i toÃ¡n phÃ¢n lá»›p
Bias-Variance, Double descent - kim chá»‰ nam cho tÆ° duy giáº£i quyáº¿t váº¥n Ä‘á» má»›i trong há»c mÃ¡y
TÃ­nh cháº¥t hÃ m má»¥c tiÃªu cÃ¡c mÃ´ hÃ¬nh overparameterized
MÃ´ hÃ¬nh lá»›n bao nhiÃªu lÃ  Ä‘á»§? Dá»¯ liá»‡u cáº§n bao nhiÃªu?","Má»™t sá»‘ ghi chÃ©p vá» vÃ i cÃ¢u há»i trong lÃ½ thuyáº¿t há»c mÃ¡y hiá»‡n Ä‘áº¡i: MSE hay CE cho bÃ i toÃ¡n phÃ¢n lá»›p Bias-Variance, Double descent - kim chá»‰ nam cho tÆ° duy giáº£i quyáº¿t váº¥n Ä‘á» má»›i trong há»c mÃ¡y TÃ­nh cháº¥t hÃ m má»¥c tiÃªu cÃ¡c mÃ´ hÃ¬nh overparameterized MÃ´ hÃ¬nh lá»›n bao nhiÃªu lÃ  Ä‘á»§? Dá»¯ liá»‡u cáº§n bao nhiÃªu?",,,,,
"Hi má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» KNN vÃ  Ä‘ang khÃ´ng hiá»ƒu lÃ  vote á»Ÿ Ä‘Ã¢y lÃ  tá»•ng vote cá»§a 3 class 1 gáº§n nháº¥t hay sao áº¡.
Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em.
Em cáº£m Æ¡n áº¡.","Hi má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» KNN vÃ  Ä‘ang khÃ´ng hiá»ƒu lÃ  vote á»Ÿ Ä‘Ã¢y lÃ  tá»•ng vote cá»§a 3 class 1 gáº§n nháº¥t hay sao áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em. Em cáº£m Æ¡n áº¡.",,,,,
"Xin chÃ o cáº£ nhÃ ,
MÃ¬nh xin phÃ©p Ä‘Æ°á»£c chia sáº» láº¡i khoÃ¡ há»c MLOps Crash Course báº±ng Tiáº¿ng Viá»‡t (FREE) do MLOpsVN team táº¡o ra á»Ÿ Ä‘Ã¢y, khoÃ¡ há»c hiá»‡n Ä‘Ã£ Ä‘Æ°á»£c gáº§n 1000 ngÆ°á»i Ä‘Äƒng kÃ½ vÃ  may máº¯n nháº­n Ä‘Æ°á»£c nhiá»u pháº£n há»“i tÃ­ch cá»±c.
KhoÃ¡ há»c hÆ°á»›ng dáº«n má»i ngÆ°á»i step by step tá»« bÆ°á»›c phÃ¢n tÃ­ch yÃªu cáº§u bÃ i toÃ¡n cho tá»›i viá»‡c thá»±c hiá»‡n POC, xÃ¢y dá»±ng feature store, data pipeline, model serving API cho tá»›i viáº¿t cÃ¡c CI/CD pipeline Ä‘á»ƒ giáº£m thiá»ƒu tá»‘i Ä‘a cÃ¡c cÃ´ng viá»‡c thá»§ cÃ´ng.
Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘Äƒng kÃ½ khoÃ¡ há»c táº¡i Ä‘Ã¢y https://mlops.vn/#registration. Äá»ƒ láº¥y ACCESS CODE, phiá»n má»i ngÆ°á»i Ä‘iá»ƒn giÃºp bá»n mÃ¬nh kháº£o sÃ¡t nhá» vá» má»©c Ä‘á»™ quan tÃ¢m cá»§a má»i ngÆ°á»i Ä‘á»‘i cuá»™c thi MLOps Marathon sáº¯p tá»›i táº¡i link nÃ y https://bit.ly/mlops-marathon-survey-2023.
Cáº£m Æ¡n cáº£ nhÃ  nhiá»u!
#mlops","Xin chÃ o cáº£ nhÃ , MÃ¬nh xin phÃ©p Ä‘Æ°á»£c chia sáº» láº¡i khoÃ¡ há»c MLOps Crash Course báº±ng Tiáº¿ng Viá»‡t (FREE) do MLOpsVN team táº¡o ra á»Ÿ Ä‘Ã¢y, khoÃ¡ há»c hiá»‡n Ä‘Ã£ Ä‘Æ°á»£c gáº§n 1000 ngÆ°á»i Ä‘Äƒng kÃ½ vÃ  may máº¯n nháº­n Ä‘Æ°á»£c nhiá»u pháº£n há»“i tÃ­ch cá»±c. KhoÃ¡ há»c hÆ°á»›ng dáº«n má»i ngÆ°á»i step by step tá»« bÆ°á»›c phÃ¢n tÃ­ch yÃªu cáº§u bÃ i toÃ¡n cho tá»›i viá»‡c thá»±c hiá»‡n POC, xÃ¢y dá»±ng feature store, data pipeline, model serving API cho tá»›i viáº¿t cÃ¡c CI/CD pipeline Ä‘á»ƒ giáº£m thiá»ƒu tá»‘i Ä‘a cÃ¡c cÃ´ng viá»‡c thá»§ cÃ´ng. Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘Äƒng kÃ½ khoÃ¡ há»c táº¡i Ä‘Ã¢y https://mlops.vn/#registration. Äá»ƒ láº¥y ACCESS CODE, phiá»n má»i ngÆ°á»i Ä‘iá»ƒn giÃºp bá»n mÃ¬nh kháº£o sÃ¡t nhá» vá» má»©c Ä‘á»™ quan tÃ¢m cá»§a má»i ngÆ°á»i Ä‘á»‘i cuá»™c thi MLOps Marathon sáº¯p tá»›i táº¡i link nÃ y https://bit.ly/mlops-marathon-survey-2023. Cáº£m Æ¡n cáº£ nhÃ  nhiá»u!",#mlops,,,,
YOLOv8 vá»«a ra lÃ² nÃ³ng há»•i cho anh em vá»«a thá»•i vá»«a â€¦.,YOLOv8 vá»«a ra lÃ² nÃ³ng há»•i cho anh em vá»«a thá»•i vá»«a â€¦.,,,,,
YOLOv8 vá»«a ra lÃ² nÃ³ng há»•i cho anh em vá»«a thá»•i vá»«a â€¦.,YOLOv8 vá»«a ra lÃ² nÃ³ng há»•i cho anh em vá»«a thá»•i vá»«a â€¦.,,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang viáº¿t model dectect biá»ƒn sá»‘ xe Viá»‡t Nam báº±ng haar cascade. Hiá»‡n táº¡i e Ä‘ang k kiáº¿m Ä‘c file CascadeClassifier.txt cho biá»ƒn VN. TrÃªn gg hiá»‡n cÃ³ cho biá»ƒn cá»§a áº¤n Äá»™ vá»›i Nga. Size biá»ƒn sá»‘ khÃ¡c nhau. Khi cháº¡y file cá»§a áº¤n cho khung bá»‹ nhá» cÃ²n file cá»§a Nga thÃ¬ khung láº¡i to quÃ¡. KhÃ´ng biáº¿t cÃ³ bÃ¡c nÃ o cÃ³ file cá»§a VN vá»›i size thÃ­ch há»£p cho em xin vá»›i áº¡.
Em cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, Em Ä‘ang viáº¿t model dectect biá»ƒn sá»‘ xe Viá»‡t Nam báº±ng haar cascade. Hiá»‡n táº¡i e Ä‘ang k kiáº¿m Ä‘c file CascadeClassifier.txt cho biá»ƒn VN. TrÃªn gg hiá»‡n cÃ³ cho biá»ƒn cá»§a áº¤n Äá»™ vá»›i Nga. Size biá»ƒn sá»‘ khÃ¡c nhau. Khi cháº¡y file cá»§a áº¤n cho khung bá»‹ nhá» cÃ²n file cá»§a Nga thÃ¬ khung láº¡i to quÃ¡. KhÃ´ng biáº¿t cÃ³ bÃ¡c nÃ o cÃ³ file cá»§a VN vá»›i size thÃ­ch há»£p cho em xin vá»›i áº¡. Em cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Hidden Markov Model. Cá»¥ thá»ƒ lÃ  á»©ng dá»¥ng nÃ³ trong nhá»¯ng task cá»¥ thá»ƒ. CÃ³ báº¡n nÃ o biáº¿t cuá»‘n sÃ¡ch hoáº·c video courses nÃ o nÃ³i vá» viá»‡c á»©ng dá»¥ng cá»§a HMM cÃ³ thá»ƒ giá»›i thiá»‡u mÃ¬nh khÃ´ng? CÃ³ thÃªm pháº§n code/package nÃ o hay thÃ¬ cÃ ng tá»‘t?
Cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Hidden Markov Model. Cá»¥ thá»ƒ lÃ  á»©ng dá»¥ng nÃ³ trong nhá»¯ng task cá»¥ thá»ƒ. CÃ³ báº¡n nÃ o biáº¿t cuá»‘n sÃ¡ch hoáº·c video courses nÃ o nÃ³i vá» viá»‡c á»©ng dá»¥ng cá»§a HMM cÃ³ thá»ƒ giá»›i thiá»‡u mÃ¬nh khÃ´ng? CÃ³ thÃªm pháº§n code/package nÃ o hay thÃ¬ cÃ ng tá»‘t? Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Em hiá»‡n táº¡i Ä‘ang tÃ¬m hiá»ƒu vá» deep learning trong viá»‡c xá»­ lÃ½ hÃ¬nh áº£nh (cá»¥ thá»ƒ lÃ  neural network). Má»i ngÆ°á»i cho em tháº¯c máº¯c dÃ²ng code tá»« 82-85 trong hÃ¬nh bÃªn dÆ°á»›i mang Ã½ nghÄ©a gÃ¬ váº­y áº¡?
Theo em hiá»ƒu thÃ¬ láº¥y 5 layers cuá»‘i cÃ¹ng trong cnn, trong má»—i layer nÃ y thÃ¬ sáº½ cÃ³ p tham sá»‘ (chÆ°a biáº¿t tham sá»‘ vá» cÃ¡i gÃ¬?), vÃ  xÃ©t requires_grad lÃ  true cho tá»«ng tham sá»‘ p.
Em hiá»ƒu nhÆ° váº­y cÃ³ sai gÃ¬ khÃ´ng má»i ngÆ°á»i? Vá»›i láº¡i requires_grad lÃ  False thÃ¬ mang Ä‘áº¿n tÃ¡c dá»¥ng gÃ¬ áº¡, em váº«n chÆ°a hiá»ƒu láº¯m. Mong má»i ngÆ°á»i hÆ°á»›ng dáº«n cho em thÃªm vá»›i áº¡. Em cáº£m Æ¡n.","Em hiá»‡n táº¡i Ä‘ang tÃ¬m hiá»ƒu vá» deep learning trong viá»‡c xá»­ lÃ½ hÃ¬nh áº£nh (cá»¥ thá»ƒ lÃ  neural network). Má»i ngÆ°á»i cho em tháº¯c máº¯c dÃ²ng code tá»« 82-85 trong hÃ¬nh bÃªn dÆ°á»›i mang Ã½ nghÄ©a gÃ¬ váº­y áº¡? Theo em hiá»ƒu thÃ¬ láº¥y 5 layers cuá»‘i cÃ¹ng trong cnn, trong má»—i layer nÃ y thÃ¬ sáº½ cÃ³ p tham sá»‘ (chÆ°a biáº¿t tham sá»‘ vá» cÃ¡i gÃ¬?), vÃ  xÃ©t requires_grad lÃ  true cho tá»«ng tham sá»‘ p. Em hiá»ƒu nhÆ° váº­y cÃ³ sai gÃ¬ khÃ´ng má»i ngÆ°á»i? Vá»›i láº¡i requires_grad lÃ  False thÃ¬ mang Ä‘áº¿n tÃ¡c dá»¥ng gÃ¬ áº¡, em váº«n chÆ°a hiá»ƒu láº¯m. Mong má»i ngÆ°á»i hÆ°á»›ng dáº«n cho em thÃªm vá»›i áº¡. Em cáº£m Æ¡n.",,,,,
"ChÃ o anh chá»‹ trong nhÃ³m. Hiá»‡n em Ä‘ang lÃ m bÃ i toÃ¡n trÃ­ch xuáº¥t thÃ´ng tin trÃªn vÄƒn báº£n cÃ³ cáº¥u trÃºc nÃªn em cÃ³ 1 sá»‘ tháº¯c máº¯c nhÆ° sau:
1. Náº¿u so sÃ¡nh hiá»‡u quáº£ thÃ¬ detector thÃ¬ Segmentation-Based hay Regression-Based sáº½ hiá»‡u quáº£ hÆ¡n (cÃ³ káº¿t há»£p cÃ¡c bÆ°á»›c tiá»n xá»© lÃ½). Yáº¿u tá»‘ xem xÃ©t á»Ÿ Ä‘Ã¢y lÃ  cáº£ vá» tÃ i nguyÃªn vÃ  thá»i gian áº¡.
2. Viá»‡c sá»­ dá»¥ng bá»™ detector train trÃªn dá»¯ liá»‡u phi cáº¥u trÃºc nhÆ° DBNet++ cho dá»¯ liá»‡u cÃ³ cáº¥u trÃºc thÃ¬ cÃ³ á»•n khÃ´ng (em cÃ³ thá»­ thÃ¬ acc táº§m > 90%).
3. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc LayoutLMv3. Anh/ chá»‹ cÃ³ thá»ƒ cho em cÃ¡i nhÃ¬n vÃ  má»™t sá»‘ Ä‘Ã¡nh giÃ¡ liÃªn quan Ä‘áº¿n kiáº¿n trÃºc nÃ y khÃ´ng? Vá» tÃ­nh hiá»‡u quáº£, dá»… hiá»ƒu, dá»… tinh chá»‰nh.
Em xin cáº£m Æ¡n","ChÃ o anh chá»‹ trong nhÃ³m. Hiá»‡n em Ä‘ang lÃ m bÃ i toÃ¡n trÃ­ch xuáº¥t thÃ´ng tin trÃªn vÄƒn báº£n cÃ³ cáº¥u trÃºc nÃªn em cÃ³ 1 sá»‘ tháº¯c máº¯c nhÆ° sau: 1. Náº¿u so sÃ¡nh hiá»‡u quáº£ thÃ¬ detector thÃ¬ Segmentation-Based hay Regression-Based sáº½ hiá»‡u quáº£ hÆ¡n (cÃ³ káº¿t há»£p cÃ¡c bÆ°á»›c tiá»n xá»© lÃ½). Yáº¿u tá»‘ xem xÃ©t á»Ÿ Ä‘Ã¢y lÃ  cáº£ vá» tÃ i nguyÃªn vÃ  thá»i gian áº¡. 2. Viá»‡c sá»­ dá»¥ng bá»™ detector train trÃªn dá»¯ liá»‡u phi cáº¥u trÃºc nhÆ° DBNet++ cho dá»¯ liá»‡u cÃ³ cáº¥u trÃºc thÃ¬ cÃ³ á»•n khÃ´ng (em cÃ³ thá»­ thÃ¬ acc táº§m > 90%). 3. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc LayoutLMv3. Anh/ chá»‹ cÃ³ thá»ƒ cho em cÃ¡i nhÃ¬n vÃ  má»™t sá»‘ Ä‘Ã¡nh giÃ¡ liÃªn quan Ä‘áº¿n kiáº¿n trÃºc nÃ y khÃ´ng? Vá» tÃ­nh hiá»‡u quáº£, dá»… hiá»ƒu, dá»… tinh chá»‰nh. Em xin cáº£m Æ¡n",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, em má»›i tÃ¬m hiá»ƒu vá» machine learning vÃ  Ä‘ang Ä‘á»c blog cá»§a tháº§y Tiá»‡p. CÃ³ má»™t chá»— em Ä‘á»c qua vÃ  ngáº«m nhiá»u láº§n rá»“i mÃ  váº«n chÆ°a thá»±c sá»± hiá»ƒu, mong má»i ngÆ°á»i giÃºp em :
Cá»¥ thá»ƒ lÃ  á»Ÿ pháº§n 2 cá»§a bÃ i viáº¿t nÃ y :
https://machinelearningcoban.com/2017/04/09/smv/
TÃ¡c giáº£ cÃ³ má»™t giáº£ sá»­ lÃ  luÃ´n tá»“n táº¡i sá»‘ k (nhÆ° Ä‘Ã£ trÃ¬nh bÃ y trong hÃ¬nh bÃªn dÆ°á»›i), tuy nhiÃªn em cho ráº±ng rÃ ng buá»™c á»Ÿ (2) pháº£i cÃ³ thÃªm Ä‘iá»u kiá»‡n tá»“n táº¡i Ã­t nháº¥t 1 Ä‘iá»ƒm x thá»a mÃ£n * (cÃ¡i kÃ­ hiá»‡u dáº¥u sao mÃ u Ä‘á» em Ä‘Ã£ Ä‘Ã¡nh dáº¥u) thÃ¬ giáº£ sá»­ cá»§a ta má»›i cÃ³ Ã½ nghÄ©a. Náº¿u khÃ´ng thÃ¬ ta cÃ³ thá»ƒ tÃ¹y chá»n má»™t sá»‘ delta Ä‘á»§ nhá» Ä‘á»ƒ thay vÃ o váº¿ pháº£i cá»§a * cÃ³ thá»ƒ thay báº±ng delta (tá»©c lÃ  thay sá»‘ 1 báº±ng sá»‘ delta Ä‘Ã³) , náº¿u delta Ä‘á»§ nhá» thÃ¬ rÃ ng buá»™c á»Ÿ (2) hoÃ n toÃ n cÃ³ thá»ƒ bá» Ä‘i. KhÃ´ng biáº¿t em Ä‘Ã£ hiá»ƒu sai á»Ÿ chá»— nÃ o váº­y áº¡?
Edit : Em xin lá»—i vÃ¬ chÆ°a trÃ¬nh bÃ y váº¥n Ä‘á» rÃµ rÃ ng Ä‘Æ°á»£c vÃ¬ háº¡n cháº¿ lÃ  em khÃ´ng viáº¿t Ä‘Æ°á»£c biá»ƒu thá»©c toÃ¡n há»c á»Ÿ Ä‘Ã¢y, chá»‰ cÃ³ thá»ƒ chá»¥p láº¡i pháº§n trÃ¬nh bÃ y cá»§a tÃ¡c giáº£ vÃ  dá»±a vÃ o Ä‘á»ƒ Ä‘áº·t cÃ¢u há»i, ráº¥t mong má»i ngÆ°á»i thÃ´ng cáº£m cho em.","Em chÃ o má»i ngÆ°á»i áº¡, em má»›i tÃ¬m hiá»ƒu vá» machine learning vÃ  Ä‘ang Ä‘á»c blog cá»§a tháº§y Tiá»‡p. CÃ³ má»™t chá»— em Ä‘á»c qua vÃ  ngáº«m nhiá»u láº§n rá»“i mÃ  váº«n chÆ°a thá»±c sá»± hiá»ƒu, mong má»i ngÆ°á»i giÃºp em : Cá»¥ thá»ƒ lÃ  á»Ÿ pháº§n 2 cá»§a bÃ i viáº¿t nÃ y : https://machinelearningcoban.com/2017/04/09/smv/ TÃ¡c giáº£ cÃ³ má»™t giáº£ sá»­ lÃ  luÃ´n tá»“n táº¡i sá»‘ k (nhÆ° Ä‘Ã£ trÃ¬nh bÃ y trong hÃ¬nh bÃªn dÆ°á»›i), tuy nhiÃªn em cho ráº±ng rÃ ng buá»™c á»Ÿ (2) pháº£i cÃ³ thÃªm Ä‘iá»u kiá»‡n tá»“n táº¡i Ã­t nháº¥t 1 Ä‘iá»ƒm x thá»a mÃ£n * (cÃ¡i kÃ­ hiá»‡u dáº¥u sao mÃ u Ä‘á» em Ä‘Ã£ Ä‘Ã¡nh dáº¥u) thÃ¬ giáº£ sá»­ cá»§a ta má»›i cÃ³ Ã½ nghÄ©a. Náº¿u khÃ´ng thÃ¬ ta cÃ³ thá»ƒ tÃ¹y chá»n má»™t sá»‘ delta Ä‘á»§ nhá» Ä‘á»ƒ thay vÃ o váº¿ pháº£i cá»§a * cÃ³ thá»ƒ thay báº±ng delta (tá»©c lÃ  thay sá»‘ 1 báº±ng sá»‘ delta Ä‘Ã³) , náº¿u delta Ä‘á»§ nhá» thÃ¬ rÃ ng buá»™c á»Ÿ (2) hoÃ n toÃ n cÃ³ thá»ƒ bá» Ä‘i. KhÃ´ng biáº¿t em Ä‘Ã£ hiá»ƒu sai á»Ÿ chá»— nÃ o váº­y áº¡? Edit : Em xin lá»—i vÃ¬ chÆ°a trÃ¬nh bÃ y váº¥n Ä‘á» rÃµ rÃ ng Ä‘Æ°á»£c vÃ¬ háº¡n cháº¿ lÃ  em khÃ´ng viáº¿t Ä‘Æ°á»£c biá»ƒu thá»©c toÃ¡n há»c á»Ÿ Ä‘Ã¢y, chá»‰ cÃ³ thá»ƒ chá»¥p láº¡i pháº§n trÃ¬nh bÃ y cá»§a tÃ¡c giáº£ vÃ  dá»±a vÃ o Ä‘á»ƒ Ä‘áº·t cÃ¢u há»i, ráº¥t mong má»i ngÆ°á»i thÃ´ng cáº£m cho em.",,,,,
"Hi má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang Ä‘á»‹nh hÆ°á»›ng há»c graph neural network (GNN), má»i ngÆ°á»i cho em há»i cÃ³ sÃ¡ch nÃ o hoáº·c github repository nÃ o tá»•ng há»£p vá» GNN k áº¡? Em cáº£m Æ¡n áº¡.","Hi má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang Ä‘á»‹nh hÆ°á»›ng há»c graph neural network (GNN), má»i ngÆ°á»i cho em há»i cÃ³ sÃ¡ch nÃ o hoáº·c github repository nÃ o tá»•ng há»£p vá» GNN k áº¡? Em cáº£m Æ¡n áº¡.",,,,,
"Dáº¡ chÃ o má»i ngÆ°á»i, láº¡i lÃ  em Ä‘Ã¢y.
HÃ´m nay em láº¡i lÃªn Ä‘Ã¢y vá»›i má»™t tháº¯c máº¯c nhÆ° sau:
ğŸ“‘Liá»‡u sá»­ dá»¥ng VNtokenizers cÃ³ thá»±c sá»± Ä‘em láº¡i hiá»‡u quáº£ so vá»›i sá»­ dá»¥ng tokenizers trong BERT nguyÃªn báº£n khÃ´ng? Náº¿u cÃ³ thÃ¬ lÃ½ do lÃ  vÃ¬ sao?
ğŸ–ŒCÃ¡ nhÃ¢n em thÃ¬ cÃ³ má»™t láº­p luáº­n lÃ  do cÃ¡c tiá»n tá»‘ vÃ  háº­u tá»‘ trong tiáº¿ng anh Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn ra thÃ nh cÃ¡c tá»« trong tiáº¿ng Viá»‡t nÃªn viá»‡c khai thÃ¡c cÃ¡c tiá»n tá»‘ vÃ  háº­u tá»‘ nÃ y khÃ´ng cÃ²n hiá»‡u quáº£ nhÆ° trong tiáº¿ng Anh.
VÃ­ dá»¥ nhÆ° tá»« ""lowest"" tÃ¡ch ra lÃ  ""low-est"" nhÆ°ng tiáº¿ng Viá»‡t thÃ¬ khÃ´ng cÃ³ 1 háº­u tá»‘ nÃ o cÃ³ tÃ¡c dá»¥ng nhÆ° est mÃ  thay vÃ o Ä‘Ã³ lÃ  tá»« ""nháº¥t"" kÃ¨m theo ngá»¯ cáº£nh cÃ¢u.
Em xin cáº£m Æ¡n.","Dáº¡ chÃ o má»i ngÆ°á»i, láº¡i lÃ  em Ä‘Ã¢y. HÃ´m nay em láº¡i lÃªn Ä‘Ã¢y vá»›i má»™t tháº¯c máº¯c nhÆ° sau: Liá»‡u sá»­ dá»¥ng VNtokenizers cÃ³ thá»±c sá»± Ä‘em láº¡i hiá»‡u quáº£ so vá»›i sá»­ dá»¥ng tokenizers trong BERT nguyÃªn báº£n khÃ´ng? Náº¿u cÃ³ thÃ¬ lÃ½ do lÃ  vÃ¬ sao? CÃ¡ nhÃ¢n em thÃ¬ cÃ³ má»™t láº­p luáº­n lÃ  do cÃ¡c tiá»n tá»‘ vÃ  háº­u tá»‘ trong tiáº¿ng anh Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn ra thÃ nh cÃ¡c tá»« trong tiáº¿ng Viá»‡t nÃªn viá»‡c khai thÃ¡c cÃ¡c tiá»n tá»‘ vÃ  háº­u tá»‘ nÃ y khÃ´ng cÃ²n hiá»‡u quáº£ nhÆ° trong tiáº¿ng Anh. VÃ­ dá»¥ nhÆ° tá»« ""lowest"" tÃ¡ch ra lÃ  ""low-est"" nhÆ°ng tiáº¿ng Viá»‡t thÃ¬ khÃ´ng cÃ³ 1 háº­u tá»‘ nÃ o cÃ³ tÃ¡c dá»¥ng nhÆ° est mÃ  thay vÃ o Ä‘Ã³ lÃ  tá»« ""nháº¥t"" kÃ¨m theo ngá»¯ cáº£nh cÃ¢u. Em xin cáº£m Æ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» OCR Ä‘á»c CCCD tá»« áº£nh chá»¥p, em cÃ³ tháº¯c máº¯c lÃ  vá»›i nhá»¯ng áº£nh bá»‹ xoay nghiÃªng , chá»¥p mÃ©o hay chá»¥p ngÆ°á»£c 180 Ä‘á»™ , váº­y mÃ¬nh cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ model cÃ³ thá»ƒ tá»± nháº­n ra Ä‘Æ°á»£c vÃ  align vá» áº£nh tháº³ng Ä‘Æ°á»£c khÃ´ng áº¡? Em cÃ³ tÃ¬m hiá»ƒu vá» phÆ°Æ¡ng phÃ¡p perspective transform thÃ¬ khÃ´ng biáº¿t lÃ  khi gÃ¡n nhÃ£n 4 gÃ³c cá»§a cccd rá»“i Ä‘i train model thÃ¬ cÃ³ Ä‘Æ°á»£c khÃ´ng áº¡ ? Em xin cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» OCR Ä‘á»c CCCD tá»« áº£nh chá»¥p, em cÃ³ tháº¯c máº¯c lÃ  vá»›i nhá»¯ng áº£nh bá»‹ xoay nghiÃªng , chá»¥p mÃ©o hay chá»¥p ngÆ°á»£c 180 Ä‘á»™ , váº­y mÃ¬nh cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ model cÃ³ thá»ƒ tá»± nháº­n ra Ä‘Æ°á»£c vÃ  align vá» áº£nh tháº³ng Ä‘Æ°á»£c khÃ´ng áº¡? Em cÃ³ tÃ¬m hiá»ƒu vá» phÆ°Æ¡ng phÃ¡p perspective transform thÃ¬ khÃ´ng biáº¿t lÃ  khi gÃ¡n nhÃ£n 4 gÃ³c cá»§a cccd rá»“i Ä‘i train model thÃ¬ cÃ³ Ä‘Æ°á»£c khÃ´ng áº¡ ? Em xin cáº£m Æ¡n áº¡.",,,,,
"[ChatBCG: AI lÃ m slide]

Sau sá»± thÃ nh cÃ´ng cá»§a DALL-E 2 cho viá»‡c sinh áº£nh, ChatGPT cho viá»‡c sinh chá»¯, gáº§n Ä‘Ã¢y mÃ´ hÃ¬nh ChatBCG Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘á»ƒ sinh ra slide, cÃ¡c báº¡n chá»‰ cáº§n nháº­p keyword, title hoáº·c ná»™i dung chÃ­nh, slide gá»“m cáº£ áº£nh vÃ  text sinh Ä‘á»™ng sáº½ Ä‘Æ°á»£c sinh ra.

Hiá»‡n táº¡i thÃ¬ váº«n Ä‘ang trong giai Ä‘oáº¡n demo nÃªn sá»‘ lÆ°á»£ng slide sinh ra váº«n giá»›i háº¡n vÃ  chÆ°a Ä‘á»§ tÃ­nh nÄƒng, nhÆ°ng triá»ƒn vá»ng vÃ  cháº¥t lÆ°á»£ng cá»§a slide thÃ¬ Ä‘Ã¡ng mong Ä‘á»£i.

Link demo: https://www.chatbcg.com/","[ChatBCG: AI lÃ m slide] Sau sá»± thÃ nh cÃ´ng cá»§a DALL-E 2 cho viá»‡c sinh áº£nh, ChatGPT cho viá»‡c sinh chá»¯, gáº§n Ä‘Ã¢y mÃ´ hÃ¬nh ChatBCG Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘á»ƒ sinh ra slide, cÃ¡c báº¡n chá»‰ cáº§n nháº­p keyword, title hoáº·c ná»™i dung chÃ­nh, slide gá»“m cáº£ áº£nh vÃ  text sinh Ä‘á»™ng sáº½ Ä‘Æ°á»£c sinh ra. Hiá»‡n táº¡i thÃ¬ váº«n Ä‘ang trong giai Ä‘oáº¡n demo nÃªn sá»‘ lÆ°á»£ng slide sinh ra váº«n giá»›i háº¡n vÃ  chÆ°a Ä‘á»§ tÃ­nh nÄƒng, nhÆ°ng triá»ƒn vá»ng vÃ  cháº¥t lÆ°á»£ng cá»§a slide thÃ¬ Ä‘Ã¡ng mong Ä‘á»£i. Link demo: https://www.chatbcg.com/",,,,,
"CÃ¡c bÃ¡c cho e há»i
1. E dÃ¹ng hÃ m kmean trong sklearn vá»›i k=5 mÃ  nÃ³ cháº¡y tá»« 0 Ä‘áº¿n 4. Em muá»‘n nÃ³ cháº¡y tá»« 1-5 thÃ¬ lÃ m nhÆ° tháº¿ nÃ o áº¡.
2. CÃ¡i random-state cÃ³ áº£nh hÆ°á»Ÿng ntn Ä‘áº¿n mÃ´ hÃ¬nh áº¡. Táº¡i e thay Ä‘á»•i cÃ¡i Ä‘Ã³ thÃ¬ phÃ¢n loáº¡i cÅ©ng thay Ä‘á»•i khÃ¡ nhiá»u
Thankss áº¡",CÃ¡c bÃ¡c cho e há»i 1. E dÃ¹ng hÃ m kmean trong sklearn vá»›i k=5 mÃ  nÃ³ cháº¡y tá»« 0 Ä‘áº¿n 4. Em muá»‘n nÃ³ cháº¡y tá»« 1-5 thÃ¬ lÃ m nhÆ° tháº¿ nÃ o áº¡. 2. CÃ¡i random-state cÃ³ áº£nh hÆ°á»Ÿng ntn Ä‘áº¿n mÃ´ hÃ¬nh áº¡. Táº¡i e thay Ä‘á»•i cÃ¡i Ä‘Ã³ thÃ¬ phÃ¢n loáº¡i cÅ©ng thay Ä‘á»•i khÃ¡ nhiá»u Thankss áº¡,,,,,
"Dáº¡ em xin chÃ o anh/chá»‹ vÃ  cÃ¡c báº¡n! Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project cuá»‘i khÃ³a cÃ³ sá»­ dá»¥ng MÃ´ hÃ¬nh CNN Ä‘á»ƒ nháº­n phÃ¢n loáº¡i áº£nh vÃ  cÃ³ má»™t sá»‘ tháº¯c máº¯c mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡! Project cá»§a em sá»­ dá»¥ng Nucleo F446RE Ä‘á»ƒ Ä‘á»c giÃ¡ trá»‹ cÃ¡c cáº£m biáº¿n vÃ  em Ä‘á»‹nh dÃ¹ng con Nucleo nÃ y káº¿t há»£p vá»›i 1 module Camera Ä‘á»ƒ chá»¥p vÃ  phÃ¢n loáº¡i áº£nh dÃ¹ng CNN, em cÃ³ tham kháº£o cÃ¡c Ä‘á» tÃ i trÃªn máº¡ng vÃ  tháº¥y Ä‘a sá»‘ cÃ¡c tÃ¡c giáº£ dÃ¹ng Raspberry Pi Ä‘á»ƒ thá»±c hiá»‡n Ä‘á» tÃ i nÃ y, váº­y má»i ngÆ°á»i cho em há»i con Nucleo F446RE cÃ³ thá»±c hiá»‡n Ä‘Æ°á»£c khÃ´ng áº¡, vÃ  náº¿u Ä‘Æ°á»£c thÃ¬ nÃªn dÃ¹ng káº¿t há»£p module Camera nÃ o lÃ  tá»‘i Æ°u nháº¥t? Em cáº£m Æ¡n anh/chá»‹ vÃ  cÃ¡c báº¡n Ä‘Ã£ xem cÃ¢u há»i áº¡!","Dáº¡ em xin chÃ o anh/chá»‹ vÃ  cÃ¡c báº¡n! Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project cuá»‘i khÃ³a cÃ³ sá»­ dá»¥ng MÃ´ hÃ¬nh CNN Ä‘á»ƒ nháº­n phÃ¢n loáº¡i áº£nh vÃ  cÃ³ má»™t sá»‘ tháº¯c máº¯c mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡! Project cá»§a em sá»­ dá»¥ng Nucleo F446RE Ä‘á»ƒ Ä‘á»c giÃ¡ trá»‹ cÃ¡c cáº£m biáº¿n vÃ  em Ä‘á»‹nh dÃ¹ng con Nucleo nÃ y káº¿t há»£p vá»›i 1 module Camera Ä‘á»ƒ chá»¥p vÃ  phÃ¢n loáº¡i áº£nh dÃ¹ng CNN, em cÃ³ tham kháº£o cÃ¡c Ä‘á» tÃ i trÃªn máº¡ng vÃ  tháº¥y Ä‘a sá»‘ cÃ¡c tÃ¡c giáº£ dÃ¹ng Raspberry Pi Ä‘á»ƒ thá»±c hiá»‡n Ä‘á» tÃ i nÃ y, váº­y má»i ngÆ°á»i cho em há»i con Nucleo F446RE cÃ³ thá»±c hiá»‡n Ä‘Æ°á»£c khÃ´ng áº¡, vÃ  náº¿u Ä‘Æ°á»£c thÃ¬ nÃªn dÃ¹ng káº¿t há»£p module Camera nÃ o lÃ  tá»‘i Æ°u nháº¥t? Em cáº£m Æ¡n anh/chá»‹ vÃ  cÃ¡c báº¡n Ä‘Ã£ xem cÃ¢u há»i áº¡!",,,,,
"#GÃ³c nhá» váº£. ChÃ o ace trong group, m Ä‘ang lÃ m quen vá»›i nature language processing, m cÃ³ 1 data frame trong Ä‘Ã³ cÃ³ cá»™t Job tiltle, m dá»± Ä‘á»‹nh tÃ¡ch cÃ¡c cÃ´ng viá»‡c sau má»—i dáº¥u "" , "" ( tÃªn cv cÃ³ tá»« Ä‘Æ¡n vÃ  tá»« ghÃ©p Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ãºng Ã½ nghÄ©a cá»§a tÃªn cv), sau Ä‘Ã³ m sáº½ label theo nhÃ³m mÃ  m Ä‘Ã£ Ä‘á»‹nh sáºµn nhÆ° áº£nh Ä‘Ã­nh kÃ¨m. Ace cÃ³ thá»ƒ tÆ° váº¥n giÃºp m nÃªn dÃ¹ng code gÃ¬ trong python Ä‘á»ƒ xá»­ lÃ½ tÃ¡c vá»¥ nÃ y Ä‘c ko áº¡? CÃ¡m Æ¡n ace trÆ°á»›c, chÃºc mn 1 nÄƒm má»›i Ä‘áº§y nhiá»‡t huyáº¿t vÃ  Ä‘am mÃª vá»›i ngÃ nh.","nhá» váº£. ChÃ o ace trong group, m Ä‘ang lÃ m quen vá»›i nature language processing, m cÃ³ 1 data frame trong Ä‘Ã³ cÃ³ cá»™t Job tiltle, m dá»± Ä‘á»‹nh tÃ¡ch cÃ¡c cÃ´ng viá»‡c sau má»—i dáº¥u "" , "" ( tÃªn cv cÃ³ tá»« Ä‘Æ¡n vÃ  tá»« ghÃ©p Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ãºng Ã½ nghÄ©a cá»§a tÃªn cv), sau Ä‘Ã³ m sáº½ label theo nhÃ³m mÃ  m Ä‘Ã£ Ä‘á»‹nh sáºµn nhÆ° áº£nh Ä‘Ã­nh kÃ¨m. Ace cÃ³ thá»ƒ tÆ° váº¥n giÃºp m nÃªn dÃ¹ng code gÃ¬ trong python Ä‘á»ƒ xá»­ lÃ½ tÃ¡c vá»¥ nÃ y Ä‘c ko áº¡? CÃ¡m Æ¡n ace trÆ°á»›c, chÃºc mn 1 nÄƒm má»›i Ä‘áº§y nhiá»‡t huyáº¿t vÃ  Ä‘am mÃª vá»›i ngÃ nh.",#GÃ³c,,,,
"ChÃ o má»i ngÆ°á»i, chÃºng mÃ¬nh lÃ  Team Lightning tham gia  ZaloAIChallenge2022. NhÃ³m mÃ¬nh chá»‰ Ä‘áº¡t káº¿t quáº£ khiÃªm tá»‘n top 5 trÃªn private leaderboard cuá»™c thi, tuy nhiÃªn do nhÃ³m ráº¥t tÃ¢m Ä‘áº¯c vá»›i má»™t giáº£i phÃ¡p má»›i (so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã£ cÃ´ng bá»‘), nÃªn xin phÃ©p chia sáº» cho má»i ngÆ°á»i cÃ¹ng tham kháº£o. NhÃ³m mÃ¬nh top tháº¥p nhÆ°ng Ä‘Æ°á»£c cÃ¡i bÃ i viáº¿t nÃ y bÃ´i dÃ i, cÅ©ng lÃ  mang tÃ­nh phÃ¢n tÃ­ch, mong sáº½ cÃ³ Ã­ch cho má»i ngÆ°á»i theo cÃ¡ch nÃ o Ä‘Ã³ :D
Related Solutions:
Vietnamese end-to-end speech recognition using wav2vec 2.0 (https://github.com/vietai/ASR)
ÄÃ¢y lÃ  giáº£i phÃ¡p cá»§a anh BÃ¬nh (team New Dad) cÃ´ng bá»‘ tá»« trÆ°á»›c vÃ  Ä‘Ã£ sá»­ dá»¥ng trong cuá»™c thi, sáº½ ráº¥t Ä‘Æ°á»£c Æ°a chuá»™ng vá»›i viá»‡c pre-train má»™t mÃ´ hÃ¬nh ASR vá»›i CTC-loss. Giáº£i phÃ¡p nÃ y train vá»›i sub-word, khÃ´ng pháº£i phoneme-based, nÃªn khÃ´ng cáº§n tá»« Ä‘iá»ƒn Grapheme2Phoneme. Äáº·c biá»‡t vá»›i dá»¯ liá»‡u khÃ¡ noisy, viá»‡c pre-train ASR trÃªn cÃ¡c táº­p dataset ASR sáº½ táº¡o ra má»™t mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c Forced Alignment Ä‘á»§ tá»‘t trÃªn má»™t dataset Ä‘á»§ lá»›n. Sau Ä‘Ã³ chÃºng ta cÃ³ thá»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cÃ³ finetune trÃªn táº­p Train Dataset BTC hay khÃ´ng.
NhÃ³m mÃ¬nh Ä‘Ã£ thá»­ nghiá»‡m phÆ°Æ¡ng phÃ¡p nÃ y, tuy nhiÃªn vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lá»›n, viá»‡c train láº¡i / finetune khÃ¡ lÃ¢u, Ä‘áº·c biá»‡t vá»›i viá»‡c chÃºng mÃ¬nh gáº·p má»™t chÃºt limit vá» GPU cÅ©ng nhÆ° muá»‘n mÃ´ hÃ¬nh pháº£i cÃ³ tá»‘c Ä‘á»™ inference nhanh chá»‰ trÃªn CPU (muá»‘n sure kÃ¨o vÃ o vÃ²ng trong outperform tá»‘c Ä‘á»™ inference táº¥t cáº£, nhÆ°ng láº¡i táº¡ch á»Ÿ top 5 :D). ThÃªm ná»¯a, káº¿t quáº£ giáº£i phÃ¡p nÃ y khÃ´ng quÃ¡ cao sau khi finetune nÃªn nhÃ³m Ä‘Ã£ dá»«ng giáº£i phÃ¡p nÃ y, coi nÃ³ lÃ  Baseline1
Improving Lyrics Alignment through Joint Pitch Detection (https://arxiv.org/abs/2202.01646 - https://github.com/jhuang448/LyricsAlignment-MTL)
Giáº£i phÃ¡p nÃ y Ä‘Æ°á»£c chÃºng mÃ¬nh dá»±ng lÃ m Baseline 2. MÃ¬nh cÅ©ng Ä‘á»c Ä‘Æ°á»£c má»™t sá»‘ nhÃ³m sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y vÃ  cÃ³ káº¿t quáº£ khÃ¡ cao (cao hÆ¡n cáº£ nhÃ³m mÃ¬nh). Äiá»ƒm máº¡nh cá»§a phÆ°Æ¡ng phÃ¡p lÃ  ngoÃ i viá»‡c train khÃ´ng cáº§n nhÃ£n thá»i gian, chá»‰ cáº§n nhÃ£n text, vÃ  train Multitask vá»›i nhÃ£n pitch note (D2-B5 khÃ´ng pháº£i D2-C6 nhÆ° trong paper). BÃ i toÃ¡n Ä‘Æ°a vá» vá»«a train forced alignment cho lyrics, káº¿t há»£p train phÃ¢n loáº¡i note cho tá»«ng cÃ¢u tá»« má»™t, giÃºp káº¿t quáº£ tá»‘t (Ä‘áº·c biá»‡t vá»›i thá»ƒ loáº¡i nháº¡c khÃ´ng pháº£i nháº¡c Rap).
NhÃ³m mÃ¬nh Ä‘Ã£ cháº¡y thá»­ nghiá»‡m khÃ¡ nhiá»u vá»›i pretrained model cá»§a phÆ°Æ¡ng phÃ¡p nÃ y, tuy nhiÃªn cÃ³ nhÆ°á»£c Ä‘iá»ƒm lÃ  sáº½ máº¥t thá»i gian Ä‘Ã¡ng ká»ƒ cho viá»‡c cháº¡y Spleeter/Demucs Ä‘á»ƒ láº¥y vocal. BÃªn cáº¡nh Ä‘Ã³, phÆ°Æ¡ng phÃ¡p nÃ y lÃ  phoneme-based, váº­y nÃªn pretrained cÅ©ng Ä‘Ã£ train vá»›i G2p_en (báº£n tiáº¿ng Anh), khiáº¿n phoneme há»c Ä‘Æ°á»£c cá»§a mÃ´ hÃ¬nh hoÃ n toÃ n lÃ  theo Anh ngá»¯. Muá»‘n finetune pháº£i cÃ³ Grapheme2Phoneme riÃªng láº¡i cho tiáº¿ng Viá»‡t Ä‘á»ƒ trÃ¡nh bá»‹ sai Ã¢m, cá»™ng thÃªm thá»i gian inference mÃ´ hÃ¬nh Multitask khÃ´ng nhanh nhÆ° ká»³ vá»ng, káº¿t quáº£ láº¡i khÃ´ng quÃ¡ ná»•i trá»™i tÆ°Æ¡ng xá»©ng vá»›i thá»i gian, nÃªn sau má»™t há»“i tranh luáº­n gáº¯t gao Ä‘Ã£ chá»‘t lÃ  thÃ´i, train háº³n mÃ´ hÃ¬nh má»›i, khÃ´ng xÃ i ná»¯a vÃ  coi nÃ³ lÃ m Baseline 2.
PROPOSED MODEL:
NhÃ³m mÃ¬nh sá»­ dá»¥ng kiáº¿n trÃºc Conformer - má»™t kiáº¿n trÃºc khÃ¡ máº¡nh trong bÃ i toÃ¡n ASR. Káº¿t há»£p cÃ¹ng vá»›i Ä‘Ã³ lÃ  train Multitask vá»›i pitch note tá»± extract. Hai Ä‘iá»ƒm nÃ y cá»§a mÃ´ hÃ¬nh Ä‘Ã£ vÃ¡ láº¡i cÃ¡c nhÆ°á»£c Ä‘iá»ƒm ká»ƒ á»Ÿ hai baselines trÃªn, hoáº¡t Ä‘á»™ng tá»‘t vá»›i cáº£ nháº¡c Rap láº«n nháº¡c nhiá»u thanh Ä‘iá»‡u. VÃ¬ táº­p train khÃ¡ noisy, nhÃ£n khÃ´ng consistent vÃ  reliable cho láº¯m, nÃªn chÃºng mÃ¬nh Ä‘Ã£ train khÃ´ng dÃ¹ng nhÃ£n alignment cá»§a Zalo, chá»‰ dÃ¹ng CTC loss Forced Alignment, vÃ  loss phÃ¢n loáº¡i note.  Äáº·c biá»‡t chÃºng mÃ¬nh khÃ´ng dÃ¹ng vocal separation, cá»© nÃ©m tháº³ng cáº£ audio vÃ o Ä‘á»ƒ train, káº¿t há»£p Data Augmentation vá»›i SpecAug giÃºp mÃ´ hÃ¬nh predict mÃ  khÃ´ng cáº§n extract vocal.
Vá» pháº§n dá»¯ liá»‡u train, chÃºng mÃ¬nh sá»­ dá»¥ng táº­p VinBigData ASR cÃ´ng khai tá»« vÃ i nÄƒm trÆ°á»›c, train má»™t cÃ¡i unsupervised model. Sau Ä‘Ã³ thá»­ nghiá»‡m train Finetune láº¡i trÃªn táº­p nháº¡c cá»§a BTC (tuy nhiÃªn viá»‡c nÃ y tháº­m chÃ­ lÃ m mÃ´ hÃ¬nh há»c tá»‡ Ä‘i :( )
CÃ¡c Ä‘iá»ƒm trÃªn giÃºp mÃ´ hÃ¬nh cá»§a chÃºng mÃ¬nh ráº¥t Ä‘Æ¡n giáº£n vÃ  nhá» vá»›i khoáº£ng 2M tham sá»‘, tá»‘c Ä‘á»™ inference chÆ°a tá»›i 45s cho toÃ n bá»™ táº­p Public test, chá»‰ cháº¡y trÃªn CPU Core I5.
Results:
CÃ¡c baseline Ä‘áº§u tiÃªn cho káº¿t quáº£ khÃ¡ trá»“i sá»¥t. Äáº·c biá»‡t vá»›i mÃ´ hÃ¬nh LyricsAlignmentMTL, chÃºng mÃ¬nh Ä‘Ã£ á»‘p má»™t vÃ i trick nhÆ° shift nhÃ£n vá» bÃªn trÃ¡i táº§m 30-50 ms, kÃ©o Ä‘áº§u align tá»« sau dÃ­nh vÃ o Ä‘uÃ´i align cá»§a tá»« trÆ°á»›c. Viá»‡c nÃªn á»‘p trick hay khÃ´ng lÃ  khÃ¡ Ä‘au Ä‘áº§u vÃ¬ káº¿t quáº£ trÃªn cÃ¡c báº£ng xáº¿p háº¡ng cÅ©ng khÃ´ng há» Ä‘Ã¡ng tin.
Cuá»‘i cÃ¹ng, nhÃ³m mÃ¬nh chá»‘t láº¡i lÃ : â€œKá»¹ NÄƒng ThÆ°á»£ng Thá»«a KhÃ´ng Báº±ng Sá»©c Máº¡nh Tuyá»‡t Äá»‘iâ€ ğŸ˜€. Submit cuá»‘i cÃ¹ng sáº½ ná»™p mÃ´ hÃ¬nh tá»± propose vÃ  khÃ´ng post-process (vÃ¬ sau khi check nhÃ£n tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ align khÃ¡ chuáº©n, chá»‰nh chá»‰ lÃ m tá»‡ thÃªm). CÃ¡c Ä‘oáº¡n ngÃ¢n cuá»‘i bÃ i cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c detect khÃ¡ chuáº©n. Check láº¡i nhÃ£n cÅ©ng tháº¥y mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng cáº¯t chuáº©n phoneme má»Ÿ Ä‘áº§u thá»±c sá»± Ä‘Æ°á»£c phÃ¡t ra. Ráº¥t tiáº¿c Ä‘áº¿n lÃºc ná»™p submission quyáº¿t Ä‘á»‹nh (á»Ÿ láº§n submit sá»‘ 2), nhÃ³m mÃ¬nh Ä‘Ã£ submit nháº§m báº£n Shifted (á»‘p cÃ¡c trick linh tinh). Ngay sau Ä‘Ã³ nhÃ³m mÃ¬nh Ä‘Ã£ submit láº¡i báº£n chuáº©n nhÆ° trong docker ná»™p cho Zalo, káº¿t quáº£ nháº£y lÃªn top 2 private leaderboard, nhÆ°ng BTC Zalo Ä‘Ã£ remove háº¿t táº¥t cáº£ cÃ¡c Submission tá»« sá»‘ 3 Ä‘á»• Ä‘i Ä‘á»ƒ káº¿t thÃºc viá»‡c probing leaderboard cá»§a anh em tham dá»± =)).
ThÃªm má»™t kinh nghiá»‡m nhá» nhá» (hÆ¡i Ä‘au Ä‘á»›n) lÃ  nhÃ³m mÃ¬nh cáº£m tháº¥y cÃ ng finetune, make use of public dataset, káº¿t quáº£ cÃ ng kÃ©m Ä‘i. CÃ³ thá»ƒ do kinh nghiá»‡m / kiáº¿n thá»©c cá»§a chÃºng mÃ¬nh cÃ²n háº¡n háº¹p chÆ°a biáº¿t táº­n dá»¥ng, nhÆ°ng káº¿t quáº£ sáº½ xuá»‘ng kha khÃ¡ Ä‘i khi force mÃ´ hÃ¬nh há»c cÃ¡c dataset nhiá»u noise vÃ  sai nhÃ£n. MÃ¬nh Ä‘oÃ¡n nhiá»u nhÃ³m sáº½ gáº·p pháº£i trÆ°á»ng há»£p nÃ y, khiáº¿n mÃ´ hÃ¬nh cá»§a cÃ¡c báº¡n perform tá»‡ Ä‘i (khÃ´ng biáº¿t cÃ³ bao gá»“m giáº£i phÃ¡p cá»§a anh BÃ¬nh New Dad khÃ´ng, khi káº¿t quáº£ public test cá»§a team New Dad ráº¥t Ä‘Ã¡ng ná»ƒâ€¦)
Conclusion:
MÃ´ hÃ¬nh cá»§a chÃºng mÃ¬nh cÃ²n tá»“n táº¡i nhiá»u thiáº¿u sÃ³t, vÃ­ dá»¥ nhÆ° viá»‡c task pitch detection cÃ²n chÆ°a thá»±c sá»± cÃ³ leverage, chá»§ yáº¿u káº¿t quáº£ váº«n lÃ  pháº§n Conformer ASR gÃ¡nh. Pháº§n Ä‘Ã³ng docker cÅ©ng khiáº¿n chÃºng mÃ¬nh khÃ¡ loay hoay khi khÃ´ng pháº£i upload lÃªn Dockerhub mÃ  láº¡i lÃ  Drive, vá»›i tá»‘c Ä‘á»™ ráº¥t giá»›i háº¡n. Láº§n Ä‘áº§u tiÃªn chÃºng mÃ¬nh lÃ m viá»‡c vá»›i má»™t task liÃªn quan khÃ´ng chá»‰ voice/speech mÃ  lÃ  toÃ n bá»™ audio, music, giÃºp nhÃ³m há»c Ä‘Æ°á»£c ráº¥t nhiá»u kinh nghiá»‡m. Äáº·c biá»‡t hÆ¡n, Ä‘Æ°á»£c tham gia cÃ¹ng vá»›i cÃ¡c top Team siÃªu giá»i nhÆ° anh BÃ¬nh (New Dad), team Telegram, v.vâ€¦ giÃºp chÃºng mÃ¬nh tá»± tin hÆ¡n trÆ°á»›c ráº¥t nhiá»u, Ä‘Æ°á»£c truyá»n cáº£m há»©ng cho cÃ¡c cÃ´ng viá»‡c liÃªn quan trong tÆ°Æ¡ng lai.
ToÃ n bá»™ Code vÃ  Pretrained model Ä‘Ã£ cÃ³ trÃªn link github dÆ°á»›i Ä‘Ã¢y:
littlebeanhp/ZAC2022-LightningConformer: Team Lightning's solution for Zalo AI Challenge 2022 (github.com)
Cuá»‘i bÃ i, Team Lightning chÃºng mÃ¬nh cáº£m Æ¡n Zalo Ä‘Ã£ táº¡o ra sÃ¢n chÆ¡i ráº¥t thÃº vá»‹, giÃºp káº¿t ná»‘i cÃ¡c anh em lÃ m AI chÃºng mÃ¬nh gáº§n nhau hÆ¡n, Ä‘Æ°á»£c tháº£o luáº­n vÃ  tÄƒng Ä‘á»™ lá»›n máº¡nh cá»§a cá»™ng Ä‘á»“ng! Mong ráº±ng trong tÆ°Æ¡ng lai sáº½ cÃ²n nhiá»u sÃ¢n chÆ¡i vá»›i giáº£i thÆ°á»Ÿng ngÃ y cÃ ng to hÆ¡n Ä‘á»ƒ chÃºng mÃ¬nh cÃ³ thá»ƒ há»c há»i Ä‘Æ°á»£c tá»« nhá»¯ng Ä‘á»™i thi máº¡nh hÆ¡n!","ChÃ o má»i ngÆ°á»i, chÃºng mÃ¬nh lÃ  Team Lightning tham gia ZaloAIChallenge2022. NhÃ³m mÃ¬nh chá»‰ Ä‘áº¡t káº¿t quáº£ khiÃªm tá»‘n top 5 trÃªn private leaderboard cuá»™c thi, tuy nhiÃªn do nhÃ³m ráº¥t tÃ¢m Ä‘áº¯c vá»›i má»™t giáº£i phÃ¡p má»›i (so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã£ cÃ´ng bá»‘), nÃªn xin phÃ©p chia sáº» cho má»i ngÆ°á»i cÃ¹ng tham kháº£o. NhÃ³m mÃ¬nh top tháº¥p nhÆ°ng Ä‘Æ°á»£c cÃ¡i bÃ i viáº¿t nÃ y bÃ´i dÃ i, cÅ©ng lÃ  mang tÃ­nh phÃ¢n tÃ­ch, mong sáº½ cÃ³ Ã­ch cho má»i ngÆ°á»i theo cÃ¡ch nÃ o Ä‘Ã³ :D Related Solutions: Vietnamese end-to-end speech recognition using wav2vec 2.0 (https://github.com/vietai/ASR) ÄÃ¢y lÃ  giáº£i phÃ¡p cá»§a anh BÃ¬nh (team New Dad) cÃ´ng bá»‘ tá»« trÆ°á»›c vÃ  Ä‘Ã£ sá»­ dá»¥ng trong cuá»™c thi, sáº½ ráº¥t Ä‘Æ°á»£c Æ°a chuá»™ng vá»›i viá»‡c pre-train má»™t mÃ´ hÃ¬nh ASR vá»›i CTC-loss. Giáº£i phÃ¡p nÃ y train vá»›i sub-word, khÃ´ng pháº£i phoneme-based, nÃªn khÃ´ng cáº§n tá»« Ä‘iá»ƒn Grapheme2Phoneme. Äáº·c biá»‡t vá»›i dá»¯ liá»‡u khÃ¡ noisy, viá»‡c pre-train ASR trÃªn cÃ¡c táº­p dataset ASR sáº½ táº¡o ra má»™t mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c Forced Alignment Ä‘á»§ tá»‘t trÃªn má»™t dataset Ä‘á»§ lá»›n. Sau Ä‘Ã³ chÃºng ta cÃ³ thá»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cÃ³ finetune trÃªn táº­p Train Dataset BTC hay khÃ´ng. NhÃ³m mÃ¬nh Ä‘Ã£ thá»­ nghiá»‡m phÆ°Æ¡ng phÃ¡p nÃ y, tuy nhiÃªn vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lá»›n, viá»‡c train láº¡i / finetune khÃ¡ lÃ¢u, Ä‘áº·c biá»‡t vá»›i viá»‡c chÃºng mÃ¬nh gáº·p má»™t chÃºt limit vá» GPU cÅ©ng nhÆ° muá»‘n mÃ´ hÃ¬nh pháº£i cÃ³ tá»‘c Ä‘á»™ inference nhanh chá»‰ trÃªn CPU (muá»‘n sure kÃ¨o vÃ o vÃ²ng trong outperform tá»‘c Ä‘á»™ inference táº¥t cáº£, nhÆ°ng láº¡i táº¡ch á»Ÿ top 5 :D). ThÃªm ná»¯a, káº¿t quáº£ giáº£i phÃ¡p nÃ y khÃ´ng quÃ¡ cao sau khi finetune nÃªn nhÃ³m Ä‘Ã£ dá»«ng giáº£i phÃ¡p nÃ y, coi nÃ³ lÃ  Baseline1 Improving Lyrics Alignment through Joint Pitch Detection (https://arxiv.org/abs/2202.01646 - https://github.com/jhuang448/LyricsAlignment-MTL) Giáº£i phÃ¡p nÃ y Ä‘Æ°á»£c chÃºng mÃ¬nh dá»±ng lÃ m Baseline 2. MÃ¬nh cÅ©ng Ä‘á»c Ä‘Æ°á»£c má»™t sá»‘ nhÃ³m sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y vÃ  cÃ³ káº¿t quáº£ khÃ¡ cao (cao hÆ¡n cáº£ nhÃ³m mÃ¬nh). Äiá»ƒm máº¡nh cá»§a phÆ°Æ¡ng phÃ¡p lÃ  ngoÃ i viá»‡c train khÃ´ng cáº§n nhÃ£n thá»i gian, chá»‰ cáº§n nhÃ£n text, vÃ  train Multitask vá»›i nhÃ£n pitch note (D2-B5 khÃ´ng pháº£i D2-C6 nhÆ° trong paper). BÃ i toÃ¡n Ä‘Æ°a vá» vá»«a train forced alignment cho lyrics, káº¿t há»£p train phÃ¢n loáº¡i note cho tá»«ng cÃ¢u tá»« má»™t, giÃºp káº¿t quáº£ tá»‘t (Ä‘áº·c biá»‡t vá»›i thá»ƒ loáº¡i nháº¡c khÃ´ng pháº£i nháº¡c Rap). NhÃ³m mÃ¬nh Ä‘Ã£ cháº¡y thá»­ nghiá»‡m khÃ¡ nhiá»u vá»›i pretrained model cá»§a phÆ°Æ¡ng phÃ¡p nÃ y, tuy nhiÃªn cÃ³ nhÆ°á»£c Ä‘iá»ƒm lÃ  sáº½ máº¥t thá»i gian Ä‘Ã¡ng ká»ƒ cho viá»‡c cháº¡y Spleeter/Demucs Ä‘á»ƒ láº¥y vocal. BÃªn cáº¡nh Ä‘Ã³, phÆ°Æ¡ng phÃ¡p nÃ y lÃ  phoneme-based, váº­y nÃªn pretrained cÅ©ng Ä‘Ã£ train vá»›i G2p_en (báº£n tiáº¿ng Anh), khiáº¿n phoneme há»c Ä‘Æ°á»£c cá»§a mÃ´ hÃ¬nh hoÃ n toÃ n lÃ  theo Anh ngá»¯. Muá»‘n finetune pháº£i cÃ³ Grapheme2Phoneme riÃªng láº¡i cho tiáº¿ng Viá»‡t Ä‘á»ƒ trÃ¡nh bá»‹ sai Ã¢m, cá»™ng thÃªm thá»i gian inference mÃ´ hÃ¬nh Multitask khÃ´ng nhanh nhÆ° ká»³ vá»ng, káº¿t quáº£ láº¡i khÃ´ng quÃ¡ ná»•i trá»™i tÆ°Æ¡ng xá»©ng vá»›i thá»i gian, nÃªn sau má»™t há»“i tranh luáº­n gáº¯t gao Ä‘Ã£ chá»‘t lÃ  thÃ´i, train háº³n mÃ´ hÃ¬nh má»›i, khÃ´ng xÃ i ná»¯a vÃ  coi nÃ³ lÃ m Baseline 2. PROPOSED MODEL: NhÃ³m mÃ¬nh sá»­ dá»¥ng kiáº¿n trÃºc Conformer - má»™t kiáº¿n trÃºc khÃ¡ máº¡nh trong bÃ i toÃ¡n ASR. Káº¿t há»£p cÃ¹ng vá»›i Ä‘Ã³ lÃ  train Multitask vá»›i pitch note tá»± extract. Hai Ä‘iá»ƒm nÃ y cá»§a mÃ´ hÃ¬nh Ä‘Ã£ vÃ¡ láº¡i cÃ¡c nhÆ°á»£c Ä‘iá»ƒm ká»ƒ á»Ÿ hai baselines trÃªn, hoáº¡t Ä‘á»™ng tá»‘t vá»›i cáº£ nháº¡c Rap láº«n nháº¡c nhiá»u thanh Ä‘iá»‡u. VÃ¬ táº­p train khÃ¡ noisy, nhÃ£n khÃ´ng consistent vÃ  reliable cho láº¯m, nÃªn chÃºng mÃ¬nh Ä‘Ã£ train khÃ´ng dÃ¹ng nhÃ£n alignment cá»§a Zalo, chá»‰ dÃ¹ng CTC loss Forced Alignment, vÃ  loss phÃ¢n loáº¡i note. Äáº·c biá»‡t chÃºng mÃ¬nh khÃ´ng dÃ¹ng vocal separation, cá»© nÃ©m tháº³ng cáº£ audio vÃ o Ä‘á»ƒ train, káº¿t há»£p Data Augmentation vá»›i SpecAug giÃºp mÃ´ hÃ¬nh predict mÃ  khÃ´ng cáº§n extract vocal. Vá» pháº§n dá»¯ liá»‡u train, chÃºng mÃ¬nh sá»­ dá»¥ng táº­p VinBigData ASR cÃ´ng khai tá»« vÃ i nÄƒm trÆ°á»›c, train má»™t cÃ¡i unsupervised model. Sau Ä‘Ã³ thá»­ nghiá»‡m train Finetune láº¡i trÃªn táº­p nháº¡c cá»§a BTC (tuy nhiÃªn viá»‡c nÃ y tháº­m chÃ­ lÃ m mÃ´ hÃ¬nh há»c tá»‡ Ä‘i :( ) CÃ¡c Ä‘iá»ƒm trÃªn giÃºp mÃ´ hÃ¬nh cá»§a chÃºng mÃ¬nh ráº¥t Ä‘Æ¡n giáº£n vÃ  nhá» vá»›i khoáº£ng 2M tham sá»‘, tá»‘c Ä‘á»™ inference chÆ°a tá»›i 45s cho toÃ n bá»™ táº­p Public test, chá»‰ cháº¡y trÃªn CPU Core I5. Results: CÃ¡c baseline Ä‘áº§u tiÃªn cho káº¿t quáº£ khÃ¡ trá»“i sá»¥t. Äáº·c biá»‡t vá»›i mÃ´ hÃ¬nh LyricsAlignmentMTL, chÃºng mÃ¬nh Ä‘Ã£ á»‘p má»™t vÃ i trick nhÆ° shift nhÃ£n vá» bÃªn trÃ¡i táº§m 30-50 ms, kÃ©o Ä‘áº§u align tá»« sau dÃ­nh vÃ o Ä‘uÃ´i align cá»§a tá»« trÆ°á»›c. Viá»‡c nÃªn á»‘p trick hay khÃ´ng lÃ  khÃ¡ Ä‘au Ä‘áº§u vÃ¬ káº¿t quáº£ trÃªn cÃ¡c báº£ng xáº¿p háº¡ng cÅ©ng khÃ´ng há» Ä‘Ã¡ng tin. Cuá»‘i cÃ¹ng, nhÃ³m mÃ¬nh chá»‘t láº¡i lÃ : â€œKá»¹ NÄƒng ThÆ°á»£ng Thá»«a KhÃ´ng Báº±ng Sá»©c Máº¡nh Tuyá»‡t Äá»‘iâ€ . Submit cuá»‘i cÃ¹ng sáº½ ná»™p mÃ´ hÃ¬nh tá»± propose vÃ  khÃ´ng post-process (vÃ¬ sau khi check nhÃ£n tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ align khÃ¡ chuáº©n, chá»‰nh chá»‰ lÃ m tá»‡ thÃªm). CÃ¡c Ä‘oáº¡n ngÃ¢n cuá»‘i bÃ i cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c detect khÃ¡ chuáº©n. Check láº¡i nhÃ£n cÅ©ng tháº¥y mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng cáº¯t chuáº©n phoneme má»Ÿ Ä‘áº§u thá»±c sá»± Ä‘Æ°á»£c phÃ¡t ra. Ráº¥t tiáº¿c Ä‘áº¿n lÃºc ná»™p submission quyáº¿t Ä‘á»‹nh (á»Ÿ láº§n submit sá»‘ 2), nhÃ³m mÃ¬nh Ä‘Ã£ submit nháº§m báº£n Shifted (á»‘p cÃ¡c trick linh tinh). Ngay sau Ä‘Ã³ nhÃ³m mÃ¬nh Ä‘Ã£ submit láº¡i báº£n chuáº©n nhÆ° trong docker ná»™p cho Zalo, káº¿t quáº£ nháº£y lÃªn top 2 private leaderboard, nhÆ°ng BTC Zalo Ä‘Ã£ remove háº¿t táº¥t cáº£ cÃ¡c Submission tá»« sá»‘ 3 Ä‘á»• Ä‘i Ä‘á»ƒ káº¿t thÃºc viá»‡c probing leaderboard cá»§a anh em tham dá»± =)). ThÃªm má»™t kinh nghiá»‡m nhá» nhá» (hÆ¡i Ä‘au Ä‘á»›n) lÃ  nhÃ³m mÃ¬nh cáº£m tháº¥y cÃ ng finetune, make use of public dataset, káº¿t quáº£ cÃ ng kÃ©m Ä‘i. CÃ³ thá»ƒ do kinh nghiá»‡m / kiáº¿n thá»©c cá»§a chÃºng mÃ¬nh cÃ²n háº¡n háº¹p chÆ°a biáº¿t táº­n dá»¥ng, nhÆ°ng káº¿t quáº£ sáº½ xuá»‘ng kha khÃ¡ Ä‘i khi force mÃ´ hÃ¬nh há»c cÃ¡c dataset nhiá»u noise vÃ  sai nhÃ£n. MÃ¬nh Ä‘oÃ¡n nhiá»u nhÃ³m sáº½ gáº·p pháº£i trÆ°á»ng há»£p nÃ y, khiáº¿n mÃ´ hÃ¬nh cá»§a cÃ¡c báº¡n perform tá»‡ Ä‘i (khÃ´ng biáº¿t cÃ³ bao gá»“m giáº£i phÃ¡p cá»§a anh BÃ¬nh New Dad khÃ´ng, khi káº¿t quáº£ public test cá»§a team New Dad ráº¥t Ä‘Ã¡ng ná»ƒâ€¦) Conclusion: MÃ´ hÃ¬nh cá»§a chÃºng mÃ¬nh cÃ²n tá»“n táº¡i nhiá»u thiáº¿u sÃ³t, vÃ­ dá»¥ nhÆ° viá»‡c task pitch detection cÃ²n chÆ°a thá»±c sá»± cÃ³ leverage, chá»§ yáº¿u káº¿t quáº£ váº«n lÃ  pháº§n Conformer ASR gÃ¡nh. Pháº§n Ä‘Ã³ng docker cÅ©ng khiáº¿n chÃºng mÃ¬nh khÃ¡ loay hoay khi khÃ´ng pháº£i upload lÃªn Dockerhub mÃ  láº¡i lÃ  Drive, vá»›i tá»‘c Ä‘á»™ ráº¥t giá»›i háº¡n. Láº§n Ä‘áº§u tiÃªn chÃºng mÃ¬nh lÃ m viá»‡c vá»›i má»™t task liÃªn quan khÃ´ng chá»‰ voice/speech mÃ  lÃ  toÃ n bá»™ audio, music, giÃºp nhÃ³m há»c Ä‘Æ°á»£c ráº¥t nhiá»u kinh nghiá»‡m. Äáº·c biá»‡t hÆ¡n, Ä‘Æ°á»£c tham gia cÃ¹ng vá»›i cÃ¡c top Team siÃªu giá»i nhÆ° anh BÃ¬nh (New Dad), team Telegram, v.vâ€¦ giÃºp chÃºng mÃ¬nh tá»± tin hÆ¡n trÆ°á»›c ráº¥t nhiá»u, Ä‘Æ°á»£c truyá»n cáº£m há»©ng cho cÃ¡c cÃ´ng viá»‡c liÃªn quan trong tÆ°Æ¡ng lai. ToÃ n bá»™ Code vÃ  Pretrained model Ä‘Ã£ cÃ³ trÃªn link github dÆ°á»›i Ä‘Ã¢y: littlebeanhp/ZAC2022-LightningConformer: Team Lightning's solution for Zalo AI Challenge 2022 (github.com) Cuá»‘i bÃ i, Team Lightning chÃºng mÃ¬nh cáº£m Æ¡n Zalo Ä‘Ã£ táº¡o ra sÃ¢n chÆ¡i ráº¥t thÃº vá»‹, giÃºp káº¿t ná»‘i cÃ¡c anh em lÃ m AI chÃºng mÃ¬nh gáº§n nhau hÆ¡n, Ä‘Æ°á»£c tháº£o luáº­n vÃ  tÄƒng Ä‘á»™ lá»›n máº¡nh cá»§a cá»™ng Ä‘á»“ng! Mong ráº±ng trong tÆ°Æ¡ng lai sáº½ cÃ²n nhiá»u sÃ¢n chÆ¡i vá»›i giáº£i thÆ°á»Ÿng ngÃ y cÃ ng to hÆ¡n Ä‘á»ƒ chÃºng mÃ¬nh cÃ³ thá»ƒ há»c há»i Ä‘Æ°á»£c tá»« nhá»¯ng Ä‘á»™i thi máº¡nh hÆ¡n!",,,,,
"Xin chÃ o má»i ngÆ°á»i!
BÃ¡c nÃ o cÃ³ link hay tÃ i liá»‡u nÃ o vá» inreforcement learning ko (cÃ³ code thá»­ cÃ ng tá»‘t)? Share mÃ¬nh tham kháº£o vá»›i. Thanks!",Xin chÃ o má»i ngÆ°á»i! BÃ¡c nÃ o cÃ³ link hay tÃ i liá»‡u nÃ o vá» inreforcement learning ko (cÃ³ code thá»­ cÃ ng tá»‘t)? Share mÃ¬nh tham kháº£o vá»›i. Thanks!,,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i, cÃ³ chá»©ng chá»‰ nÃ o free vá» machine learning cá»§a google hoáº·c chá»— khÃ¡c Ä‘á»ƒ tÄƒng kinh nghiá»‡m vÃ  lÃ m Ä‘áº¹p CV khÃ´ng áº¡. MÃ¬nh cáº£m Æ¡n","Má»i ngÆ°á»i cho mÃ¬nh há»i, cÃ³ chá»©ng chá»‰ nÃ o free vá» machine learning cá»§a google hoáº·c chá»— khÃ¡c Ä‘á»ƒ tÄƒng kinh nghiá»‡m vÃ  lÃ m Ä‘áº¹p CV khÃ´ng áº¡. MÃ¬nh cáº£m Æ¡n",,,,,
"MÃ¬nh cáº§n tÃ¬m má»™t mentor cÃ³ kinh nghiá»‡m vá» xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n kinh doanh vÃ  NLP.
HÃ¬nh thá»©c Q&A theo giá» phÃ¹ há»£p cá»§a hai bÃªn
Chi phÃ­ thoáº£ thuáº­n.",MÃ¬nh cáº§n tÃ¬m má»™t mentor cÃ³ kinh nghiá»‡m vá» xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n kinh doanh vÃ  NLP. HÃ¬nh thá»©c Q&A theo giá» phÃ¹ há»£p cá»§a hai bÃªn Chi phÃ­ thoáº£ thuáº­n.,,,,,
"Cuá»™c thi ""Novozymes Enzyme Stability Prediction"" trÃªn kaggle má»™t láº§n ná»¯a láº¡i thá»ƒ hiá»‡n sá»± biáº¿n Ä‘á»™ng máº¡nh vá» xáº¿p háº¡ng giá»¯a public LB vÃ  private LB. Táº¡i public LB, anh Chris Deotte dáº«n Ä‘áº§u trong thá»i gian dÃ i vá»›i sá»‘ Ä‘iá»ƒm vÆ°á»£t trá»™i so vá»›i pháº§n cÃ²n láº¡i, nhÆ°ng táº¡i private LB anh chá»‰ giá»¯ vá»‹ trÃ­ 968 (xem áº£nh chá»¥p). ÄÃ¢y lÃ  má»™t cuá»™c thi khÃ³ vÃ¬ nÃ³ yÃªu cáº§u kiáº¿n thá»©c ná»n ráº¥t khÃ¡c biá»‡t so vá»›i dÃ¢n IT, vÃ  cÅ©ng ráº¥t vui khi phÃ¡t hiá»‡n ra cÃ´ng dÃ¢n ÄÃ´ng LÃ o Ä‘áº¡t Ä‘Æ°á»£c thá»© háº¡ng cao trong cuá»™c thi nÃ y.
BÃ i toÃ¡n phÃ¡t hiá»‡n liá»‡u mÃ´ hÃ¬nh cÃ³ bá»‹ overfit hay khÃ´ng váº«n lÃ  khÃ³ nháº±n, ká»ƒ cáº£ vá»›i cao thá»§ háº¡ng nháº¥t tháº¿ giá»›i.","Cuá»™c thi ""Novozymes Enzyme Stability Prediction"" trÃªn kaggle má»™t láº§n ná»¯a láº¡i thá»ƒ hiá»‡n sá»± biáº¿n Ä‘á»™ng máº¡nh vá» xáº¿p háº¡ng giá»¯a public LB vÃ  private LB. Táº¡i public LB, anh Chris Deotte dáº«n Ä‘áº§u trong thá»i gian dÃ i vá»›i sá»‘ Ä‘iá»ƒm vÆ°á»£t trá»™i so vá»›i pháº§n cÃ²n láº¡i, nhÆ°ng táº¡i private LB anh chá»‰ giá»¯ vá»‹ trÃ­ 968 (xem áº£nh chá»¥p). ÄÃ¢y lÃ  má»™t cuá»™c thi khÃ³ vÃ¬ nÃ³ yÃªu cáº§u kiáº¿n thá»©c ná»n ráº¥t khÃ¡c biá»‡t so vá»›i dÃ¢n IT, vÃ  cÅ©ng ráº¥t vui khi phÃ¡t hiá»‡n ra cÃ´ng dÃ¢n ÄÃ´ng LÃ o Ä‘áº¡t Ä‘Æ°á»£c thá»© háº¡ng cao trong cuá»™c thi nÃ y. BÃ i toÃ¡n phÃ¡t hiá»‡n liá»‡u mÃ´ hÃ¬nh cÃ³ bá»‹ overfit hay khÃ´ng váº«n lÃ  khÃ³ nháº±n, ká»ƒ cáº£ vá»›i cao thá»§ háº¡ng nháº¥t tháº¿ giá»›i.",,,,,
"Share event vá» AI cho bÃ  con tháº£o luáº­n trÆ°á»›c Táº¿t ğŸ˜€
ÄÆ°á»£c chia sáº» bá»Ÿi anh HÆ°ng NgÃ´ - Founder/ CEO cá»§a CoTAI.
ÄÄƒng kÃ½ ngay nhÃ©: https://gambaru.io/en/events/te15-ai4dev-landscapes-roadmaps-collabs
â° Thá»i gian: 07/01, sÃ¡ng thá»© 7, 9h30-11h30
ğŸ’» Online qua Zoom

Lá»£i Ã­ch khi tham dá»±:
1) Hiá»ƒu rÃµ vá» AI cÅ©ng nhÆ° cÃ¡c cÃ´ng cá»¥, á»©ng dá»¥ng, xu tháº¿ cá»§a AI lÃªn ngÃ nh pháº§n má»m
2) Tháº¥y Ä‘Æ°á»£c bá»©c tranh tá»•ng thá»ƒ vá» cÃ¡c lÄ©nh vá»±c nghiÃªn cá»©u vÃ  á»©ng dá»¥ng sÃ´i Ä‘á»™ng cá»§a AI
3) CÃ³ Ä‘Æ°á»£c cÃ¡c lá»™ trÃ¬nh há»c táº­p tá»‘i Æ°u Ä‘á»ƒ phÃ¡t triá»ƒn nghá» nghiá»‡p cÃ³ sá»­ dá»¥ng AI
4) Náº¯m báº¯t cÃ¡c nguá»“n tÃ i nguyÃªn, cÃ¡c cá»™ng Ä‘á»“ng, vÃ  cÃ¡c cÆ¡ há»™i cá»™ng tÃ¡c há»c táº­p cÅ©ng nhÆ° lÃ m dá»± Ã¡n sáº£n pháº©m AI.","Share event vá» AI cho bÃ  con tháº£o luáº­n trÆ°á»›c Táº¿t ÄÆ°á»£c chia sáº» bá»Ÿi anh HÆ°ng NgÃ´ - Founder/ CEO cá»§a CoTAI. ÄÄƒng kÃ½ ngay nhÃ©: https://gambaru.io/en/events/te15-ai4dev-landscapes-roadmaps-collabs â° Thá»i gian: 07/01, sÃ¡ng thá»© 7, 9h30-11h30 Online qua Zoom Lá»£i Ã­ch khi tham dá»±: 1) Hiá»ƒu rÃµ vá» AI cÅ©ng nhÆ° cÃ¡c cÃ´ng cá»¥, á»©ng dá»¥ng, xu tháº¿ cá»§a AI lÃªn ngÃ nh pháº§n má»m 2) Tháº¥y Ä‘Æ°á»£c bá»©c tranh tá»•ng thá»ƒ vá» cÃ¡c lÄ©nh vá»±c nghiÃªn cá»©u vÃ  á»©ng dá»¥ng sÃ´i Ä‘á»™ng cá»§a AI 3) CÃ³ Ä‘Æ°á»£c cÃ¡c lá»™ trÃ¬nh há»c táº­p tá»‘i Æ°u Ä‘á»ƒ phÃ¡t triá»ƒn nghá» nghiá»‡p cÃ³ sá»­ dá»¥ng AI 4) Náº¯m báº¯t cÃ¡c nguá»“n tÃ i nguyÃªn, cÃ¡c cá»™ng Ä‘á»“ng, vÃ  cÃ¡c cÆ¡ há»™i cá»™ng tÃ¡c há»c táº­p cÅ©ng nhÆ° lÃ m dá»± Ã¡n sáº£n pháº©m AI.",,,,,
"Em chÃ o anh chá»‹ áº¡,
Em Ä‘ang cáº§n tÃ¬m 1 cÃ´ng cá»¥ xá»­ lÃ½ hÃ¬nh áº£nh, cÃ³ thá»ƒ lÃ  dÃ¹ng báº¥t cá»© mÃ´ hÃ¬nh ML hoáº·c DL Ä‘á»ƒ xÃ¡c Ä‘á»‹nh váº¿t ná»©t tá»« 2 áº£nh nÄƒm 2009 vÃ  2014 ( váº¿t ná»©t lÃ  cÃ¡i Ä‘Æ°á»£c khoanh trÃ²n xanh trong hÃ¬nh Ä‘Ã­nh kÃ¨m ) vÃ  sau Ä‘Ã³ so sÃ¡nh Ä‘á»™ dÃ i 2 váº¿t ná»©t vá»›i nhau. Anh chá»‹ nÃ o Ä‘Ã£ lÃ m váº¥n Ä‘á» tÆ°Æ¡ng tá»± cÃ³ thá»ƒ chá»‰ cho em 1 sá»‘ cÃ´ng cá»¥ hoáº·c mÃ´ hÃ¬nh cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» khÃ´ng áº¡? Hoáº·c anh chá»‹ nÃ o Ä‘Ã£ lÃ m image segmentation cho Ä‘á»‘i tÆ°á»£ng nhá» cÃ³ thá»ƒ gá»£i Ã½ cho em má»™t sá»‘ mÃ´ hÃ¬nh DL hoáº·c ML lÃ m image segmentation cho Ä‘á»‘i tÆ°á»£ng
""Nhá»"" hoáº·c object detection? Hoáº·c cÃ¡c cÃ´ng cá»¥ giÃºp xá»­ lÃ½ hÃ¬nh áº£nh tá»‘t khÃ´ng sá»­ dá»¥ng ML hoáº·c DL cÅ©ng Ä‘Æ°á»£c áº¡.
Em cáº£m Æ¡n áº¡.","Em chÃ o anh chá»‹ áº¡, Em Ä‘ang cáº§n tÃ¬m 1 cÃ´ng cá»¥ xá»­ lÃ½ hÃ¬nh áº£nh, cÃ³ thá»ƒ lÃ  dÃ¹ng báº¥t cá»© mÃ´ hÃ¬nh ML hoáº·c DL Ä‘á»ƒ xÃ¡c Ä‘á»‹nh váº¿t ná»©t tá»« 2 áº£nh nÄƒm 2009 vÃ  2014 ( váº¿t ná»©t lÃ  cÃ¡i Ä‘Æ°á»£c khoanh trÃ²n xanh trong hÃ¬nh Ä‘Ã­nh kÃ¨m ) vÃ  sau Ä‘Ã³ so sÃ¡nh Ä‘á»™ dÃ i 2 váº¿t ná»©t vá»›i nhau. Anh chá»‹ nÃ o Ä‘Ã£ lÃ m váº¥n Ä‘á» tÆ°Æ¡ng tá»± cÃ³ thá»ƒ chá»‰ cho em 1 sá»‘ cÃ´ng cá»¥ hoáº·c mÃ´ hÃ¬nh cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» khÃ´ng áº¡? Hoáº·c anh chá»‹ nÃ o Ä‘Ã£ lÃ m image segmentation cho Ä‘á»‘i tÆ°á»£ng nhá» cÃ³ thá»ƒ gá»£i Ã½ cho em má»™t sá»‘ mÃ´ hÃ¬nh DL hoáº·c ML lÃ m image segmentation cho Ä‘á»‘i tÆ°á»£ng ""Nhá»"" hoáº·c object detection? Hoáº·c cÃ¡c cÃ´ng cá»¥ giÃºp xá»­ lÃ½ hÃ¬nh áº£nh tá»‘t khÃ´ng sá»­ dá»¥ng ML hoáº·c DL cÅ©ng Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n áº¡.",,,,,
"Dáº¡ chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ má»™t mÃ´ hÃ¬nh nhÆ° váº­y vÃ  cÃ³ Ä‘áº§u vÃ o lÃ  1000 Ä‘iá»ƒm x,y cá»§a 2 Ä‘Æ°á»ng R vÃ  J vÃ  cÃ³ R0, J0. Em Ä‘Æ°á»£c gá»£i Ã½ lÃ  sá»­ dá»¥ng Variational AutoEncoder Ä‘á»ƒ tÃ­nh há»‡ sá»‘ a,b,c,d nhÆ°ng em khÃ´ng biáº¿t sá»­ dá»¥ng nhÆ° tháº¿ nÃ o. Anh chá»‹ cÃ³ thá»ƒ giÃºp em xÃ¢y dá»±ng neutral network Ä‘Æ°á»£c khÃ´ng áº¡.
Em xin cáº£m Æ¡n.","Dáº¡ chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ má»™t mÃ´ hÃ¬nh nhÆ° váº­y vÃ  cÃ³ Ä‘áº§u vÃ o lÃ  1000 Ä‘iá»ƒm x,y cá»§a 2 Ä‘Æ°á»ng R vÃ  J vÃ  cÃ³ R0, J0. Em Ä‘Æ°á»£c gá»£i Ã½ lÃ  sá»­ dá»¥ng Variational AutoEncoder Ä‘á»ƒ tÃ­nh há»‡ sá»‘ a,b,c,d nhÆ°ng em khÃ´ng biáº¿t sá»­ dá»¥ng nhÆ° tháº¿ nÃ o. Anh chá»‹ cÃ³ thá»ƒ giÃºp em xÃ¢y dá»±ng neutral network Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n.",,,,,
"Dáº¡ em xin chÃ o má»i ngÆ°á»i áº¡! HÃ´m nay á»Ÿ trÃªn lá»›p em Ä‘Æ°á»£c há»c vá» Naivy Bayes áº¡!
Hiá»‡n táº¡i em Ä‘ang gáº·p khÃ³ khÄƒn vá» bÃ i toÃ¡n nÃ y áº¡!
Cho em há»i lÃ  táº¡i sao tÃ­nh Ä‘Æ°á»£c nhá»¯ng giÃ¡ trá»‹ nhÆ° trong dá»¯ liá»‡u huáº¥n luyá»‡n nhÆ° bÃªn dÆ°á»›i áº¡!:
P(a/A) = 4/6 = 0.67
P(b/A) = 2/6 = 0.33
P(a/B) = 0/2 = 0
P(b/B) = 2/2 = 1
Nhá»¯ng pháº§n nÃ y lÃ  em trÃ­ch ra tá»« pháº§n em gáº¡ch Ä‘á» áº¡!. Mong Ä‘Æ°á»£c anh chá»‹ giÃºp Ä‘á»¡ áº¡!",Dáº¡ em xin chÃ o má»i ngÆ°á»i áº¡! HÃ´m nay á»Ÿ trÃªn lá»›p em Ä‘Æ°á»£c há»c vá» Naivy Bayes áº¡! Hiá»‡n táº¡i em Ä‘ang gáº·p khÃ³ khÄƒn vá» bÃ i toÃ¡n nÃ y áº¡! Cho em há»i lÃ  táº¡i sao tÃ­nh Ä‘Æ°á»£c nhá»¯ng giÃ¡ trá»‹ nhÆ° trong dá»¯ liá»‡u huáº¥n luyá»‡n nhÆ° bÃªn dÆ°á»›i áº¡!: P(a/A) = 4/6 = 0.67 P(b/A) = 2/6 = 0.33 P(a/B) = 0/2 = 0 P(b/B) = 2/2 = 1 Nhá»¯ng pháº§n nÃ y lÃ  em trÃ­ch ra tá»« pháº§n em gáº¡ch Ä‘á» áº¡!. Mong Ä‘Æ°á»£c anh chá»‹ giÃºp Ä‘á»¡ áº¡!,,,,,
"[Xin trá»£ giÃºp vá» xÃ¡c suáº¥t] MÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u vÃ  gáº·p bÃ i toÃ¡n sau Ä‘Ã¢y. MÃ¬nh xin phÃ©p viáº¿t tiáº¿ng Anh cho dá»….
Consider a multivariate Gaussian random variable X ~ N(m, C) of d variables. Denote Y as the index (among d entries) of X that has the maximum values. In particular Y = argmax_i X_i.
Compute P(Y=i) for a given i in {1, 2,..,d}?
Xin cáº£m Æ¡n.","[Xin trá»£ giÃºp vá» xÃ¡c suáº¥t] MÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u vÃ  gáº·p bÃ i toÃ¡n sau Ä‘Ã¢y. MÃ¬nh xin phÃ©p viáº¿t tiáº¿ng Anh cho dá»…. Consider a multivariate Gaussian random variable X ~ N(m, C) of d variables. Denote Y as the index (among d entries) of X that has the maximum values. In particular Y = argmax_i X_i. Compute P(Y=i) for a given i in {1, 2,..,d}? Xin cáº£m Æ¡n.",,,,,
"MÃ¬nh Ä‘á»‹nh khÃ´ng viáº¿t post nÃ y, nhÆ°ng tháº¥y nhiá»u báº¡n há»i, xong rá»“i nhiá»u báº¡n vÃ o quÄƒng cho 1 cÃ¡i link (mÃ¬nh nghÄ© báº¡n nÃ y cÅ©ng chá»‰ search google). Nhá»¯ng báº¡n chÆ°a biáº¿t gÃ¬ mÃ  bá»‹ rÆ¡i vÃ o ma cung kiá»ƒu nÃ y ráº¥t khá»• (mÃ¬nh tá»«ng lÃ  náº¡n nhÃ¢n). NÃªn mÃ¬nh sáº½ chia sáº½ nhá»¯ng gÃ¬ mÃ¬nh Ä‘Ã£ há»c, vÃ  tháº¥y cÃ³ Ã­ch.
1) Reinforcement Learning: Báº¡n search google thÃ¬ sáº½ ra recommend: http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html
Book: http://incompleteideas.net/sutton/book/bookdraft2017june.pdf
Náº¿u báº¡n chÆ°a biáº¿t gÃ¬ mÃ  há»c vÃ  Ä‘á»c sÃ¡ch nÃ y, báº¡n trá»¥ Ä‘Æ°á»£c 1 tuáº§n, tÃ´i phá»¥c báº¡n.
Recommend cá»§a tÃ´i: báº¡n nÃªn báº¯t Ä‘áº§u tá»« khoÃ¡:
https://learning.edx.org/course/course-v1:Microsoft+DAT257x+3T2018
Cáº§n biáº¿t thÃªm kiáº¿n thá»©c vá» Markov Decision Process thÃ¬ xem pháº§n cuá»‘i cá»§a khoÃ¡ stat110 vÃ  cuá»‘n sÃ¡ch Ä‘i kÃ¨m:
https://projects.iq.harvard.edu/stat110/home
2) Data Science:
Báº¡n muá»‘n báº¯t Ä‘áº§u mÃ  chÆ°a biáº¿t nhiá»u vá» Python hay xá»­ lÃ½ dá»¯ liá»‡u thÃ¬ nÃªn báº¯t Ä‘áº§u vá»›i khoÃ¡ CS109 cá»§a Harvard:http://cs109.github.io/2015/ (chÃº Ã½ tÃ¬m lecture cá»§a 2015, homework cá»§a 2013). Há» sáº½ dáº¡y báº¡n tá»« collect dá»¯ liá»‡u, lÃ m sáº¡ch dá»¯ liá»‡u vÃ  xá»­ lÃ½ dá»¯ liá»‡u.
Báº¡n cáº§n thÃªm kiáº¿n thá»©c vá» xÃ¡c suáº¥t: Há»c khoÃ¡ Stat110 nhÆ° bÃªn trÃªn tÃ´i Ä‘á» cáº­p. Há»c xong khoÃ¡ nÃ y báº¡n sáº½ tháº¥y sá»± diá»‡u kÃ¬ cá»§a xÃ¡c suáº¥t:
https://projects.iq.harvard.edu/stat110/home
Báº¡n muá»‘n cÃ³ 1 chá»©ng chá»‰ free liÃªn quan Ä‘áº¿n Data Science: há»c khoÃ¡ Stat Learning cá»§a Stanford ( tiá»‡n thá»ƒ há»c thÃªm Ã­t vá» ngÃ´n ngá»¯ R luÃ´n), sÃ¡ch Ä‘i kÃ¨m free nhÃ©: https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/courseware/995220423fd14a4588d8e47920f1b5df/99faa3a82fca4fc19adc577ce9f75afd/
3) Game Theory:
Báº¡n há»c khoÃ¡ nÃ y cá»§a Stanford: https://www.coursera.org/learn/game-theory-1
NhÆ°ng Ä‘á»c thÃªm quyá»ƒn sÃ¡ch Game Theory 101, vÃ  giáº£i thÃ­ch cá»§a tÃ¡c giáº£ trÃªn youtube ( vÃ¬ quyá»ƒn Ä‘i kÃ¨m vá»›i khoÃ¡ Stanford cÅ©ng toÃ n lÃ½ thuyáº¿t).
4) Deep Learning - Tensorflow
Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i khoÃ¡ cá»§a IBM, cÃ³ chá»©ng chá»‰ free cho báº¡n, cÃ³ code cho báº¡n cháº¡y: trÃªn trang nÃ y cÃ³ nhiá»u khoÃ¡ khÃ¡c, thÃ­ch thÃ¬ báº¡n cÃ³ thá»ƒ há»c.
https://cognitiveclass.ai/courses/deep-learning-tensorflow/
or https://classroom.udacity.com/courses/ud730
Sau Ä‘Ã³ nghe thÃªm video: Tensorflow and deep learning - without a Phd
https://www.youtube.com/watch?v=vq2nnJ4g6N0
Tiáº¿p Ä‘Ã³ Ä‘á»ƒ hiá»ƒu sÃ¢u hÆ¡n, tham kháº£o khoÃ¡ CS231 cá»§a Stanford:
http://cs231n.stanford.edu/2016/syllabus.html
Nhá»› xem github cá»§a thÃ¡nh Andrej Karpathy
5) NLP - Chatbot
KhoÃ¡ nÃ y má»›i má»Ÿ trÃªn coursera, táº¥t cáº£ má»i thá»© clear Ä‘áº¿n tá»«ng chi tiáº¿t:
https://www.coursera.org/learn/nlp-sequence-models
NgoÃ i ra Ä‘á»ƒ chuyÃªn sÃ¢u hÆ¡n, báº¡n cáº§n há»c Natural Language Processing (CS224D), Deep Learning (CS231) trÆ°á»›c, sau Ä‘Ã³ down code cá»§a Huyá»n Chip vá» tham kháº£o ( nhá»› tÃ¬m Ä‘Ãºng version cá»§a Tensorflow Ä‘á»ƒ cháº¡y): Thá»±c ra cÃ³ thá»ƒ down code luÃ´n vá» cháº¡y nhÃ¬n káº¿t quáº£ cÅ©ng okie.
https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/chatbot
6) Bigdata
Báº¡n nÃ o muá»‘n tÃ¬m hiá»ƒu vá» Spark, cÃ³ thá»ƒ há»c 3 khoÃ¡ nÃ y, cÃ³ thá»ƒ giá» khÃ´ng má»Ÿ nhÆ°ng báº¡n váº«n xem Ä‘Æ°á»£c video vÃ  láº¥y bÃ i lab vá» cháº¡y bÃ¬nh thÆ°á»ng, cáº§n solution tÃ´i cÃ³ thá»ƒ gá»­i. Há»c xong báº¡n sáº½ biáº¿t Spark, Map Reduce, Machine Learning,...:
https://courses.edx.org/dashboard/programs/a06a1f8b-21e6-49c8-887e-1016d3639de3/
Báº¡n muá»‘n biáº¿t thá»±c sá»± xá»­ lÃ½ Big Data phá»©c táº¡p nhÆ° nÃ o, báº¡n há»c khoÃ¡ nÃ y, há»c xong cÃ³ chá»©ng chá»‰ nhÃ©, khoÃ¡ nÃ y náº·ng nhÆ°ng hay láº¯m:
http://online.stanford.edu/course/mining-massive-datasets-self-paced
7) AI chung ( Algorithms, Machine Learning, Reinforcement Learning)
Báº¡n há»c khoÃ¡ nÃ y: https://courses.edx.org/courses/course-v1:ColumbiaX+CSMM.101x+2T2017/course/
VÃ  cuá»‘n sÃ¡ch kinh Ä‘iá»ƒn Ä‘i cÃ¹ng: Artificial Intelligence A Modern Approach, Third Edition
8) Book Ä‘á»ƒ Ä‘i phá»ng váº¥n xin viá»‡c:
Cracking the Coding Interview 6
Elements of Programming Interviews in Java (Python, C++)
Introduction to Algorithms 3","MÃ¬nh Ä‘á»‹nh khÃ´ng viáº¿t post nÃ y, nhÆ°ng tháº¥y nhiá»u báº¡n há»i, xong rá»“i nhiá»u báº¡n vÃ o quÄƒng cho 1 cÃ¡i link (mÃ¬nh nghÄ© báº¡n nÃ y cÅ©ng chá»‰ search google). Nhá»¯ng báº¡n chÆ°a biáº¿t gÃ¬ mÃ  bá»‹ rÆ¡i vÃ o ma cung kiá»ƒu nÃ y ráº¥t khá»• (mÃ¬nh tá»«ng lÃ  náº¡n nhÃ¢n). NÃªn mÃ¬nh sáº½ chia sáº½ nhá»¯ng gÃ¬ mÃ¬nh Ä‘Ã£ há»c, vÃ  tháº¥y cÃ³ Ã­ch. 1) Reinforcement Learning: Báº¡n search google thÃ¬ sáº½ ra recommend: http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html Book: http://incompleteideas.net/sutton/book/bookdraft2017june.pdf Náº¿u báº¡n chÆ°a biáº¿t gÃ¬ mÃ  há»c vÃ  Ä‘á»c sÃ¡ch nÃ y, báº¡n trá»¥ Ä‘Æ°á»£c 1 tuáº§n, tÃ´i phá»¥c báº¡n. Recommend cá»§a tÃ´i: báº¡n nÃªn báº¯t Ä‘áº§u tá»« khoÃ¡: https://learning.edx.org/course/course-v1:Microsoft+DAT257x+3T2018 Cáº§n biáº¿t thÃªm kiáº¿n thá»©c vá» Markov Decision Process thÃ¬ xem pháº§n cuá»‘i cá»§a khoÃ¡ stat110 vÃ  cuá»‘n sÃ¡ch Ä‘i kÃ¨m: https://projects.iq.harvard.edu/stat110/home 2) Data Science: Báº¡n muá»‘n báº¯t Ä‘áº§u mÃ  chÆ°a biáº¿t nhiá»u vá» Python hay xá»­ lÃ½ dá»¯ liá»‡u thÃ¬ nÃªn báº¯t Ä‘áº§u vá»›i khoÃ¡ CS109 cá»§a Harvard:http://cs109.github.io/2015/ (chÃº Ã½ tÃ¬m lecture cá»§a 2015, homework cá»§a 2013). Há» sáº½ dáº¡y báº¡n tá»« collect dá»¯ liá»‡u, lÃ m sáº¡ch dá»¯ liá»‡u vÃ  xá»­ lÃ½ dá»¯ liá»‡u. Báº¡n cáº§n thÃªm kiáº¿n thá»©c vá» xÃ¡c suáº¥t: Há»c khoÃ¡ Stat110 nhÆ° bÃªn trÃªn tÃ´i Ä‘á» cáº­p. Há»c xong khoÃ¡ nÃ y báº¡n sáº½ tháº¥y sá»± diá»‡u kÃ¬ cá»§a xÃ¡c suáº¥t: https://projects.iq.harvard.edu/stat110/home Báº¡n muá»‘n cÃ³ 1 chá»©ng chá»‰ free liÃªn quan Ä‘áº¿n Data Science: há»c khoÃ¡ Stat Learning cá»§a Stanford ( tiá»‡n thá»ƒ há»c thÃªm Ã­t vá» ngÃ´n ngá»¯ R luÃ´n), sÃ¡ch Ä‘i kÃ¨m free nhÃ©: https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/courseware/995220423fd14a4588d8e47920f1b5df/99faa3a82fca4fc19adc577ce9f75afd/ 3) Game Theory: Báº¡n há»c khoÃ¡ nÃ y cá»§a Stanford: https://www.coursera.org/learn/game-theory-1 NhÆ°ng Ä‘á»c thÃªm quyá»ƒn sÃ¡ch Game Theory 101, vÃ  giáº£i thÃ­ch cá»§a tÃ¡c giáº£ trÃªn youtube ( vÃ¬ quyá»ƒn Ä‘i kÃ¨m vá»›i khoÃ¡ Stanford cÅ©ng toÃ n lÃ½ thuyáº¿t). 4) Deep Learning - Tensorflow Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i khoÃ¡ cá»§a IBM, cÃ³ chá»©ng chá»‰ free cho báº¡n, cÃ³ code cho báº¡n cháº¡y: trÃªn trang nÃ y cÃ³ nhiá»u khoÃ¡ khÃ¡c, thÃ­ch thÃ¬ báº¡n cÃ³ thá»ƒ há»c. https://cognitiveclass.ai/courses/deep-learning-tensorflow/ or https://classroom.udacity.com/courses/ud730 Sau Ä‘Ã³ nghe thÃªm video: Tensorflow and deep learning - without a Phd https://www.youtube.com/watch?v=vq2nnJ4g6N0 Tiáº¿p Ä‘Ã³ Ä‘á»ƒ hiá»ƒu sÃ¢u hÆ¡n, tham kháº£o khoÃ¡ CS231 cá»§a Stanford: http://cs231n.stanford.edu/2016/syllabus.html Nhá»› xem github cá»§a thÃ¡nh Andrej Karpathy 5) NLP - Chatbot KhoÃ¡ nÃ y má»›i má»Ÿ trÃªn coursera, táº¥t cáº£ má»i thá»© clear Ä‘áº¿n tá»«ng chi tiáº¿t: https://www.coursera.org/learn/nlp-sequence-models NgoÃ i ra Ä‘á»ƒ chuyÃªn sÃ¢u hÆ¡n, báº¡n cáº§n há»c Natural Language Processing (CS224D), Deep Learning (CS231) trÆ°á»›c, sau Ä‘Ã³ down code cá»§a Huyá»n Chip vá» tham kháº£o ( nhá»› tÃ¬m Ä‘Ãºng version cá»§a Tensorflow Ä‘á»ƒ cháº¡y): Thá»±c ra cÃ³ thá»ƒ down code luÃ´n vá» cháº¡y nhÃ¬n káº¿t quáº£ cÅ©ng okie. https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/chatbot 6) Bigdata Báº¡n nÃ o muá»‘n tÃ¬m hiá»ƒu vá» Spark, cÃ³ thá»ƒ há»c 3 khoÃ¡ nÃ y, cÃ³ thá»ƒ giá» khÃ´ng má»Ÿ nhÆ°ng báº¡n váº«n xem Ä‘Æ°á»£c video vÃ  láº¥y bÃ i lab vá» cháº¡y bÃ¬nh thÆ°á»ng, cáº§n solution tÃ´i cÃ³ thá»ƒ gá»­i. Há»c xong báº¡n sáº½ biáº¿t Spark, Map Reduce, Machine Learning,...: https://courses.edx.org/dashboard/programs/a06a1f8b-21e6-49c8-887e-1016d3639de3/ Báº¡n muá»‘n biáº¿t thá»±c sá»± xá»­ lÃ½ Big Data phá»©c táº¡p nhÆ° nÃ o, báº¡n há»c khoÃ¡ nÃ y, há»c xong cÃ³ chá»©ng chá»‰ nhÃ©, khoÃ¡ nÃ y náº·ng nhÆ°ng hay láº¯m: http://online.stanford.edu/course/mining-massive-datasets-self-paced 7) AI chung ( Algorithms, Machine Learning, Reinforcement Learning) Báº¡n há»c khoÃ¡ nÃ y: https://courses.edx.org/courses/course-v1:ColumbiaX+CSMM.101x+2T2017/course/ VÃ  cuá»‘n sÃ¡ch kinh Ä‘iá»ƒn Ä‘i cÃ¹ng: Artificial Intelligence A Modern Approach, Third Edition 8) Book Ä‘á»ƒ Ä‘i phá»ng váº¥n xin viá»‡c: Cracking the Coding Interview 6 Elements of Programming Interviews in Java (Python, C++) Introduction to Algorithms 3",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  Há»£p, Ä‘áº¿n tá»« team NNN Ä‘áº¡t top 2 cuá»™c thi Zalo AI Challenge vá»›i track Liveness Detection. MÃ¬nh muá»‘n thay máº·t team chia sáº» solution cho cuá»™c thi.
Team mÃ¬nh cáº£m tháº¥y ráº¥t may máº¯n khi Ä‘áº¡t Ä‘Æ°á»£c top 2 Final; cÅ©ng nhÆ° Ä‘á»“ng top 1 trong LB Public test 1 vÃ  top 30 LB Public test 2. Sau Ä‘Ã¢y lÃ  solution cá»§a team:
1.Xá»­ lÃ½ dá»¯ liá»‡u: Team mÃ¬nh chia táº­p train-val Ä‘Æ¡n giáº£n theo tá»· lá»‡ 80/20 theo id video vÃ  cáº¯t láº¥y 1 frame trÃªn 1s.
2.Huáº¥n luyá»‡n
Public test 1: Giai Ä‘oáº¡n Ä‘áº§u tá»¥i mÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh baseline vá»›i mÃ´ hÃ¬nh Efficientnet-B4 Noisy Student input size 512, sá»­ dá»¥ng má»™t sá»‘ augmentation Ä‘Æ¡n giáº£n nhÆ° H/V Flip, ColorJitter. MÃ´ hÃ¬nh Ä‘Ã£ fit Ä‘Æ°á»£c táº­p public test 1 ráº¥t tá»‘t. Vá»›i má»™t vÃ i láº§n submit vÃ  thá»­ nghiá»‡m tay (vá»›i má»™t chÃºt may máº¯n) metric EER, team mÃ¬nh Ä‘Ã£ cÃ³ Ä‘Æ°á»£c ground-truth cá»§a táº­p nÃ y.
Public test 2: Vá»›i táº­p dá»¯ liá»‡u má»›i nÃ y, team mÃ¬nh Ä‘Ã¡nh giÃ¡ dá»¯ liá»‡u cÃ³ cháº¥t lÆ°á»£ng video kÃ©m hÆ¡n so vá»›i trÆ°á»›c, cáº£m giÃ¡c nhÆ° video bá»‹ cáº¯t nhá», lÃ m má», â€¦ NÃªn tá»¥i mÃ¬nh Ä‘Æ°a ra 1 sá»‘ hÆ°á»›ng Ä‘á»ƒ giáº£i quyáº¿t.
PhÆ°Æ¡ng phÃ¡p 1 (PP1): Bá»• sung vÃ o táº­p Val hiá»‡n táº¡i cÃ¡c augs cá»§a chÃ­nh nÃ³, cá»‘ Ä‘á»‹nh thÃ nh má»™t táº­p Val-aug má»›i (sá»‘ lÆ°á»£ng x2 Val cÅ©).
PhÆ°Æ¡ng phÃ¡p 2 (PP2): CÃ¡c aug cho táº­p Val Ä‘Æ°á»£c tÃ¹y biáº¿n má»—i khi load dá»¯ liá»‡u (tÆ°Æ¡ng tá»± cÃ¡ch aug cho táº­p Train).
Má»¥c tiÃªu cá»§a 2 hÆ°á»›ng trÃªn lÃ  tÃ¬m ra má»™t khÃ´ng gian Augmentation cá»§a táº­p Val miÃªu táº£ chÃ­nh xÃ¡c nháº¥t, team mÃ¬nh sá»­ dá»¥ng mÃ´ hÃ¬nh Swin Transformer Ä‘á»ƒ huáº¥n luyá»‡n cho cáº£ 2 phÆ°Æ¡ng phÃ¡p trÃªn.
MÃ´ hÃ¬nh Swin_PP1:
Kiáº¿n trÃºc: swin_large_patch4_window12_384 vá»›i drop_path_rate: 0.3
Optimizer: LR: 1e-5, Weight decay: 3e-5
LR Scheduler: CosineAnnealingWarmRestarts vá»›i T0: 600, T_mult: 1, Eta_min: 1e-7
Train Augmentation: RandomResizedCrop 0.49-1.0, RandomHorizontalFlip 0.5, RandomVerticalFlip 0.2, GaussianBlur kernel_size 3 sigma 0.2-2.0, ColorJitter contrast 0.2.
Offline-Augmentation Val: Downsize Image: CenterCrop 0.75 * height - 0.75 * width, Resize 0.375 * height - 0.375 * width.
Chuáº©n bá»‹ dá»¯ liá»‡u Val-aug = táº­p val gá»‘c + offline-augmentation val.
Trainer: Mixed Precision vá»›i FP16, Batch size 16, Max 12000 step, validation má»—i epoch, lÆ°u 2 mÃ´ hÃ¬nh val loss tháº¥p nháº¥t, láº¥y mÃ´ hÃ¬nh vá»›i val accuracy cao nháº¥t trong 2.
MÃ´ hÃ¬nh Swin_PP2:
Kiáº¿n trÃºc: swin_large_patch4_window12_384
Optimizer: LR: 3e-5, Weight decay: 1e-6
LR Scheduler: StepLR vá»›i step_size: 5, gamma: 0.2
Train / Val Augmentation: RandomResizedCrop 0.49-1.0, RandomVerticalFlip 0.2, GaussianBlur kernel_size 3 sigma 0.2-2.0.
Trainer: Mixed Precision vá»›i FP16, Batch size 16, Max 20 epoch, validation má»—i epoch, lÆ°u 3 mÃ´ hÃ¬nh val loss tháº¥p nháº¥t vÃ  last checkpoint. Qua thá»­ nghiá»‡m tá»¥i mÃ¬nh chá»n last checkpoint.
Tá»¥i mÃ¬nh Ä‘Ã¡nh giÃ¡ 2 mÃ´ hÃ¬nh Swin_PP1 vÃ  Swin_PP2 nháº­n tháº¥y mÃ´ hÃ¬nh PP1 tá»‘t trÃªn public test 1, mÃ´ hÃ¬nh PP2 láº¡i tá»‘t trÃªn public test 2 nÃªn team Ä‘Ã£ ensemble 2 mÃ´ hÃ¬nh láº¡i vÃ  tháº¥y mÃ´ hÃ¬nh Ensemble nÃ y cho káº¿t quáº£ (EER vÃ  TEER) tá»‘t hÆ¡n.
Má»™t sá»‘ Ä‘iá»ƒm tá»‘t mÃ  tá»¥i mÃ¬nh Ä‘Ã¡nh giÃ¡ Ä‘em láº¡i thÃ nh cÃ´ng cho mÃ´ hÃ¬nh:
Training vá»›i Mixed Precision. Team mÃ¬nh tá»« Ä‘áº§u cuá»™c thi cÅ©ng cÃ¢n nháº¯c vá» time constraint vÃ  chÃº Ã½ training vá»›i mixed precision, nÃ³ giÃºp cÃ¡c mÃ´ hÃ¬nh tá»¥i mÃ¬nh inference nhanh nhÆ°ng hiá»‡u quáº£ khÃ´ng kÃ©m mÃ´ hÃ¬nh FP32.
Ensemble: tá»¥i mÃ¬nh chá»‰ muá»‘n ensemble 2 mÃ´ hÃ¬nh tá»‘t nháº¥t trÃªn cÃ¡c LB, nhÆ°ng cÃ³ láº½ nÃªn dÃ¹ng nhiá»u hÆ¡n.
Augmentation offline vÃ  online: team xÃ¡c Ä‘á»‹nh cÃ¡c loáº¡i augs phÃ¹ há»£p vÃ  tuning :)
May máº¯n: team khÃ¡ gáº·p may máº¯n khi hoÃ n thÃ nh Ä‘Æ°á»£c codebase vÃ  baseline khÃ¡ sá»›m, cÅ©ng nhÆ° má»™t sá»‘ may máº¯n á»Ÿ trÃªn, tá»¥i mÃ¬nh chá»‰ phÃ¢n tÃ­ch lá»—i vÃ  Ä‘á»ƒ nÃ³ tuning liÃªn tá»¥c thÃ´i :â€™)
Training code vÃ  inference Ä‘á»u náº±m trong repo. MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.","ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  Há»£p, Ä‘áº¿n tá»« team NNN Ä‘áº¡t top 2 cuá»™c thi Zalo AI Challenge vá»›i track Liveness Detection. MÃ¬nh muá»‘n thay máº·t team chia sáº» solution cho cuá»™c thi. Team mÃ¬nh cáº£m tháº¥y ráº¥t may máº¯n khi Ä‘áº¡t Ä‘Æ°á»£c top 2 Final; cÅ©ng nhÆ° Ä‘á»“ng top 1 trong LB Public test 1 vÃ  top 30 LB Public test 2. Sau Ä‘Ã¢y lÃ  solution cá»§a team: 1.Xá»­ lÃ½ dá»¯ liá»‡u: Team mÃ¬nh chia táº­p train-val Ä‘Æ¡n giáº£n theo tá»· lá»‡ 80/20 theo id video vÃ  cáº¯t láº¥y 1 frame trÃªn 1s. 2.Huáº¥n luyá»‡n Public test 1: Giai Ä‘oáº¡n Ä‘áº§u tá»¥i mÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh baseline vá»›i mÃ´ hÃ¬nh Efficientnet-B4 Noisy Student input size 512, sá»­ dá»¥ng má»™t sá»‘ augmentation Ä‘Æ¡n giáº£n nhÆ° H/V Flip, ColorJitter. MÃ´ hÃ¬nh Ä‘Ã£ fit Ä‘Æ°á»£c táº­p public test 1 ráº¥t tá»‘t. Vá»›i má»™t vÃ i láº§n submit vÃ  thá»­ nghiá»‡m tay (vá»›i má»™t chÃºt may máº¯n) metric EER, team mÃ¬nh Ä‘Ã£ cÃ³ Ä‘Æ°á»£c ground-truth cá»§a táº­p nÃ y. Public test 2: Vá»›i táº­p dá»¯ liá»‡u má»›i nÃ y, team mÃ¬nh Ä‘Ã¡nh giÃ¡ dá»¯ liá»‡u cÃ³ cháº¥t lÆ°á»£ng video kÃ©m hÆ¡n so vá»›i trÆ°á»›c, cáº£m giÃ¡c nhÆ° video bá»‹ cáº¯t nhá», lÃ m má», â€¦ NÃªn tá»¥i mÃ¬nh Ä‘Æ°a ra 1 sá»‘ hÆ°á»›ng Ä‘á»ƒ giáº£i quyáº¿t. PhÆ°Æ¡ng phÃ¡p 1 (PP1): Bá»• sung vÃ o táº­p Val hiá»‡n táº¡i cÃ¡c augs cá»§a chÃ­nh nÃ³, cá»‘ Ä‘á»‹nh thÃ nh má»™t táº­p Val-aug má»›i (sá»‘ lÆ°á»£ng x2 Val cÅ©). PhÆ°Æ¡ng phÃ¡p 2 (PP2): CÃ¡c aug cho táº­p Val Ä‘Æ°á»£c tÃ¹y biáº¿n má»—i khi load dá»¯ liá»‡u (tÆ°Æ¡ng tá»± cÃ¡ch aug cho táº­p Train). Má»¥c tiÃªu cá»§a 2 hÆ°á»›ng trÃªn lÃ  tÃ¬m ra má»™t khÃ´ng gian Augmentation cá»§a táº­p Val miÃªu táº£ chÃ­nh xÃ¡c nháº¥t, team mÃ¬nh sá»­ dá»¥ng mÃ´ hÃ¬nh Swin Transformer Ä‘á»ƒ huáº¥n luyá»‡n cho cáº£ 2 phÆ°Æ¡ng phÃ¡p trÃªn. MÃ´ hÃ¬nh Swin_PP1: Kiáº¿n trÃºc: swin_large_patch4_window12_384 vá»›i drop_path_rate: 0.3 Optimizer: LR: 1e-5, Weight decay: 3e-5 LR Scheduler: CosineAnnealingWarmRestarts vá»›i T0: 600, T_mult: 1, Eta_min: 1e-7 Train Augmentation: RandomResizedCrop 0.49-1.0, RandomHorizontalFlip 0.5, RandomVerticalFlip 0.2, GaussianBlur kernel_size 3 sigma 0.2-2.0, ColorJitter contrast 0.2. Offline-Augmentation Val: Downsize Image: CenterCrop 0.75 * height - 0.75 * width, Resize 0.375 * height - 0.375 * width. Chuáº©n bá»‹ dá»¯ liá»‡u Val-aug = táº­p val gá»‘c + offline-augmentation val. Trainer: Mixed Precision vá»›i FP16, Batch size 16, Max 12000 step, validation má»—i epoch, lÆ°u 2 mÃ´ hÃ¬nh val loss tháº¥p nháº¥t, láº¥y mÃ´ hÃ¬nh vá»›i val accuracy cao nháº¥t trong 2. MÃ´ hÃ¬nh Swin_PP2: Kiáº¿n trÃºc: swin_large_patch4_window12_384 Optimizer: LR: 3e-5, Weight decay: 1e-6 LR Scheduler: StepLR vá»›i step_size: 5, gamma: 0.2 Train / Val Augmentation: RandomResizedCrop 0.49-1.0, RandomVerticalFlip 0.2, GaussianBlur kernel_size 3 sigma 0.2-2.0. Trainer: Mixed Precision vá»›i FP16, Batch size 16, Max 20 epoch, validation má»—i epoch, lÆ°u 3 mÃ´ hÃ¬nh val loss tháº¥p nháº¥t vÃ  last checkpoint. Qua thá»­ nghiá»‡m tá»¥i mÃ¬nh chá»n last checkpoint. Tá»¥i mÃ¬nh Ä‘Ã¡nh giÃ¡ 2 mÃ´ hÃ¬nh Swin_PP1 vÃ  Swin_PP2 nháº­n tháº¥y mÃ´ hÃ¬nh PP1 tá»‘t trÃªn public test 1, mÃ´ hÃ¬nh PP2 láº¡i tá»‘t trÃªn public test 2 nÃªn team Ä‘Ã£ ensemble 2 mÃ´ hÃ¬nh láº¡i vÃ  tháº¥y mÃ´ hÃ¬nh Ensemble nÃ y cho káº¿t quáº£ (EER vÃ  TEER) tá»‘t hÆ¡n. Má»™t sá»‘ Ä‘iá»ƒm tá»‘t mÃ  tá»¥i mÃ¬nh Ä‘Ã¡nh giÃ¡ Ä‘em láº¡i thÃ nh cÃ´ng cho mÃ´ hÃ¬nh: Training vá»›i Mixed Precision. Team mÃ¬nh tá»« Ä‘áº§u cuá»™c thi cÅ©ng cÃ¢n nháº¯c vá» time constraint vÃ  chÃº Ã½ training vá»›i mixed precision, nÃ³ giÃºp cÃ¡c mÃ´ hÃ¬nh tá»¥i mÃ¬nh inference nhanh nhÆ°ng hiá»‡u quáº£ khÃ´ng kÃ©m mÃ´ hÃ¬nh FP32. Ensemble: tá»¥i mÃ¬nh chá»‰ muá»‘n ensemble 2 mÃ´ hÃ¬nh tá»‘t nháº¥t trÃªn cÃ¡c LB, nhÆ°ng cÃ³ láº½ nÃªn dÃ¹ng nhiá»u hÆ¡n. Augmentation offline vÃ  online: team xÃ¡c Ä‘á»‹nh cÃ¡c loáº¡i augs phÃ¹ há»£p vÃ  tuning :) May máº¯n: team khÃ¡ gáº·p may máº¯n khi hoÃ n thÃ nh Ä‘Æ°á»£c codebase vÃ  baseline khÃ¡ sá»›m, cÅ©ng nhÆ° má»™t sá»‘ may máº¯n á»Ÿ trÃªn, tá»¥i mÃ¬nh chá»‰ phÃ¢n tÃ­ch lá»—i vÃ  Ä‘á»ƒ nÃ³ tuning liÃªn tá»¥c thÃ´i :â€™) Training code vÃ  inference Ä‘á»u náº±m trong repo. MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.",,,,,
"Dáº¡ em chÃ o cÃ¡c anh chá»‹,
Em má»›i táº­p tÃ nh há»c vá» machine learning nÃªn cÃ³ nhiá»u váº¥n Ä‘á» em chÆ°a rÃµ. Cá»¥ thá»ƒ lÃ  em gáº·p khÃ³ khÄƒn trong bÃ i toÃ¡n tÃ¬m SVM.
Trong bÃ i toÃ¡n SVM, Ä‘á»ƒ tÃ¬m nghiá»‡m tá»‘i Æ°u, ta thÆ°á»ng Ä‘Æ°a vá» bÃ i toÃ¡n Ä‘á»‘i ngáº«u (dual problem). Tuy nhiÃªn, váº¥n Ä‘á» lÃ  bÃ i toÃ¡n Ä‘á»‘i ngáº«u mÃ  giáº£i báº±ng há»‡ KKT cÅ©ng sáº½ gáº·p khÃ³ khÄƒn (khi sá»‘ áº©n lá»›n). Trong quyá»ƒn machine learning cÆ¡ báº£n cá»§a anh Tiá»‡p cÅ©ng cÃ³ nÃ³i vá» khÃ³ khÄƒn nÃ y vÃ  Ä‘Æ°a ra hÆ°á»›ng giáº£i quyáº¿t lÃ  sá»­ dá»¥ng thuáº­t toÃ¡n SMO Ä‘á»ƒ giáº£i. Em tháº¥y trong bÃ i giáº£ng tháº§y Andrew cÅ©ng nháº¯c vá» thuáº­t toÃ¡n nÃ y.
Em cÅ©ng cÃ³ tÃ¬m hiá»ƒu vá» nÃ³ (Ä‘á»c bÃ i bÃ¡o gá»‘c cá»§a tÃ¡c giáº£ John Platt, xem cÃ¡c video trÃªn youtube) nhÆ°ng mÃ  em váº«n chÆ°a hÃ¬nh dung Ä‘Æ°á»£c nÃ³ hoáº¡t Ä‘á»™ng cá»¥ thá»ƒ ra sao. Hai video trÃªn youtube mÃ  em Ä‘Ã£ xem qua Ä‘Ã³ lÃ 
Video 1: https://www.youtube.com/watch?v=Mfp7HQKLSAo&t=909s
Video 2: https://www.youtube.com/watch?v=lHaFpRCKHF8&t=4s.
Em hiá»ƒu Ã½ tÆ°á»Ÿng chung cá»§a thuáº­t toÃ¡n nÃ y lÃ  (khÃ´ng biáº¿t em hiá»ƒu Ä‘Ãºng khÃ´ng, nhá» má»i ngÆ°á»i confirm giÃºp em nhÃ©)
+ BÆ°á»›c 1: MÃ¬nh sáº½ chá»n initial guess: Chá»n má»™t bá»™ alpha thá»a mÃ£n cÃ¡c rÃ ng buá»™c.
+ BÆ°á»›c 2: Chá»n 2 pháº§n tá»­ trong Ä‘Ã³ vÃ  tiáº¿n hÃ¬nh maximize nÃ³.
Repeat cho tá»›i khi thuáº­t tá»‘i há»™i tá»¥ (thá»a Ä‘iá»u kiá»‡n KKT)
Váº¥n Ä‘á» lÃ : Chá»n 2 pháº§n tá»­ nhÆ° tháº¿ nÃ o Ä‘á»ƒ bÃ i toÃ¡n nhanh chÃ³ng há»™i tá»¥? Hai video em xem cÅ©ng khÃ´ng cÃ³ Ä‘á» cáº­p tá»›i. Há» nháº¯c chung chung má»™t cÃ¢u lÃ  ""heuristics to choose these 2 variables"" nhÆ°ng em khÃ´ng hiá»ƒu cÃ¢u nÃ y láº¯m :(
VÃ­ dá»¥ xÃ©t bÃ i toÃ¡n SVM trong khÃ´ng gian 2 chiá»u, vá»›i bá»™ dá»¯ liá»‡u cÃ³ 5 Ä‘iá»ƒm thÃ´i, thÃ¬ sá»‘ trÆ°á»ng há»£p náº¿u giáº£i báº±ng há»‡ KKT sáº½ lÃ  2^5=32 trÆ°á»ng há»£p.
Náº¿u giáº£i SMO thÃ¬ chá»n 2 Ä‘iá»ƒm trong 5 Ä‘iá»ƒm sáº½ cÃ³ 10 cÃ¡ch chá»n. NhÆ°ng Ä‘Ã³ chá»‰ lÃ  1 step, váº«n chÆ°a biáº¿t khi nÃ o nÃ³ há»™i tá»¥. Em chÆ°a tháº¥y Ä‘Æ°á»£c viá»‡c thuáº­t toÃ¡n SMO sáº½ nhanh hÆ¡n viá»‡c giáº£i há»‡ KKT chá»— nÃ o? (CÃ³ láº½ vÃ¬ em chÆ°a hiá»ƒu cÃ¢u ""heuristics to choose these 2 variables"").
Em cÃ³ cho thá»­ má»™t bÃ i toÃ¡n nhÆ° tháº¿ nÃ y (SVM with non separable case): Consider two classes of data, where three points $(0.5,0),(2,1),(1,1)$ have the label $+1$ and two points $(1,0),(0,1)$ have the label $-1$. Let's choose $C=5$. Compute the maximum margin hyperplane that separates the two classes of data.
Äá»ƒ cho tiá»‡n, em cÃ³ ghi láº¡i bÃ i toÃ¡n Ä‘á»‘i ngáº«u cá»§a nÃ³ (em Ä‘Ã­nh kÃ¨m á»Ÿ hÃ¬nh váº½)
Má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em cháº¡y thá»­ báº±ng cÆ¡m thuáº­t toÃ¡n SMO Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Ä‘á»‘i ngáº«u cho bÃ i toÃ¡n nÃ y khÃ´ng áº¡?
Em cáº£m Æ¡n anh chá»‹ Ä‘Ã£ quan tÃ¢m.","Dáº¡ em chÃ o cÃ¡c anh chá»‹, Em má»›i táº­p tÃ nh há»c vá» machine learning nÃªn cÃ³ nhiá»u váº¥n Ä‘á» em chÆ°a rÃµ. Cá»¥ thá»ƒ lÃ  em gáº·p khÃ³ khÄƒn trong bÃ i toÃ¡n tÃ¬m SVM. Trong bÃ i toÃ¡n SVM, Ä‘á»ƒ tÃ¬m nghiá»‡m tá»‘i Æ°u, ta thÆ°á»ng Ä‘Æ°a vá» bÃ i toÃ¡n Ä‘á»‘i ngáº«u (dual problem). Tuy nhiÃªn, váº¥n Ä‘á» lÃ  bÃ i toÃ¡n Ä‘á»‘i ngáº«u mÃ  giáº£i báº±ng há»‡ KKT cÅ©ng sáº½ gáº·p khÃ³ khÄƒn (khi sá»‘ áº©n lá»›n). Trong quyá»ƒn machine learning cÆ¡ báº£n cá»§a anh Tiá»‡p cÅ©ng cÃ³ nÃ³i vá» khÃ³ khÄƒn nÃ y vÃ  Ä‘Æ°a ra hÆ°á»›ng giáº£i quyáº¿t lÃ  sá»­ dá»¥ng thuáº­t toÃ¡n SMO Ä‘á»ƒ giáº£i. Em tháº¥y trong bÃ i giáº£ng tháº§y Andrew cÅ©ng nháº¯c vá» thuáº­t toÃ¡n nÃ y. Em cÅ©ng cÃ³ tÃ¬m hiá»ƒu vá» nÃ³ (Ä‘á»c bÃ i bÃ¡o gá»‘c cá»§a tÃ¡c giáº£ John Platt, xem cÃ¡c video trÃªn youtube) nhÆ°ng mÃ  em váº«n chÆ°a hÃ¬nh dung Ä‘Æ°á»£c nÃ³ hoáº¡t Ä‘á»™ng cá»¥ thá»ƒ ra sao. Hai video trÃªn youtube mÃ  em Ä‘Ã£ xem qua Ä‘Ã³ lÃ  Video 1: https://www.youtube.com/watch?v=Mfp7HQKLSAo&t=909s Video 2: https://www.youtube.com/watch?v=lHaFpRCKHF8&t=4s. Em hiá»ƒu Ã½ tÆ°á»Ÿng chung cá»§a thuáº­t toÃ¡n nÃ y lÃ  (khÃ´ng biáº¿t em hiá»ƒu Ä‘Ãºng khÃ´ng, nhá» má»i ngÆ°á»i confirm giÃºp em nhÃ©) + BÆ°á»›c 1: MÃ¬nh sáº½ chá»n initial guess: Chá»n má»™t bá»™ alpha thá»a mÃ£n cÃ¡c rÃ ng buá»™c. + BÆ°á»›c 2: Chá»n 2 pháº§n tá»­ trong Ä‘Ã³ vÃ  tiáº¿n hÃ¬nh maximize nÃ³. Repeat cho tá»›i khi thuáº­t tá»‘i há»™i tá»¥ (thá»a Ä‘iá»u kiá»‡n KKT) Váº¥n Ä‘á» lÃ : Chá»n 2 pháº§n tá»­ nhÆ° tháº¿ nÃ o Ä‘á»ƒ bÃ i toÃ¡n nhanh chÃ³ng há»™i tá»¥? Hai video em xem cÅ©ng khÃ´ng cÃ³ Ä‘á» cáº­p tá»›i. Há» nháº¯c chung chung má»™t cÃ¢u lÃ  ""heuristics to choose these 2 variables"" nhÆ°ng em khÃ´ng hiá»ƒu cÃ¢u nÃ y láº¯m :( VÃ­ dá»¥ xÃ©t bÃ i toÃ¡n SVM trong khÃ´ng gian 2 chiá»u, vá»›i bá»™ dá»¯ liá»‡u cÃ³ 5 Ä‘iá»ƒm thÃ´i, thÃ¬ sá»‘ trÆ°á»ng há»£p náº¿u giáº£i báº±ng há»‡ KKT sáº½ lÃ  2^5=32 trÆ°á»ng há»£p. Náº¿u giáº£i SMO thÃ¬ chá»n 2 Ä‘iá»ƒm trong 5 Ä‘iá»ƒm sáº½ cÃ³ 10 cÃ¡ch chá»n. NhÆ°ng Ä‘Ã³ chá»‰ lÃ  1 step, váº«n chÆ°a biáº¿t khi nÃ o nÃ³ há»™i tá»¥. Em chÆ°a tháº¥y Ä‘Æ°á»£c viá»‡c thuáº­t toÃ¡n SMO sáº½ nhanh hÆ¡n viá»‡c giáº£i há»‡ KKT chá»— nÃ o? (CÃ³ láº½ vÃ¬ em chÆ°a hiá»ƒu cÃ¢u ""heuristics to choose these 2 variables""). Em cÃ³ cho thá»­ má»™t bÃ i toÃ¡n nhÆ° tháº¿ nÃ y (SVM with non separable case): Consider two classes of data, where three points $(0.5,0),(2,1),(1,1)$ have the label $+1$ and two points $(1,0),(0,1)$ have the label $-1$. Let's choose $C=5$. Compute the maximum margin hyperplane that separates the two classes of data. Äá»ƒ cho tiá»‡n, em cÃ³ ghi láº¡i bÃ i toÃ¡n Ä‘á»‘i ngáº«u cá»§a nÃ³ (em Ä‘Ã­nh kÃ¨m á»Ÿ hÃ¬nh váº½) Má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em cháº¡y thá»­ báº±ng cÆ¡m thuáº­t toÃ¡n SMO Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Ä‘á»‘i ngáº«u cho bÃ i toÃ¡n nÃ y khÃ´ng áº¡? Em cáº£m Æ¡n anh chá»‹ Ä‘Ã£ quan tÃ¢m.",,,,,
"Hi cÃ¡c bÃ¡c, em Ä‘ang muá»‘n dÃ¹ng colab Ä‘á»ƒ predict model sau Ä‘Ã³ gá»­i káº¿t quáº£ vá» mÃ¡y local thÃ¬ cÃ³ cÃ¡ch nÃ o kháº£ thi ko.
Em cáº£m Æ¡n áº¡ Em Ä‘Ã£ thá»­ pydrive nhÆ°ng pydrive chá»‰ cho em Ä‘c káº¿t quáº£ cá»§a láº§n Ä‘áº§u cháº¡y thÃ´i (tá»©c lÃ  ko láº¥y realtime Ä‘c)","Hi cÃ¡c bÃ¡c, em Ä‘ang muá»‘n dÃ¹ng colab Ä‘á»ƒ predict model sau Ä‘Ã³ gá»­i káº¿t quáº£ vá» mÃ¡y local thÃ¬ cÃ³ cÃ¡ch nÃ o kháº£ thi ko. Em cáº£m Æ¡n áº¡ Em Ä‘Ã£ thá»­ pydrive nhÆ°ng pydrive chá»‰ cho em Ä‘c káº¿t quáº£ cá»§a láº§n Ä‘áº§u cháº¡y thÃ´i (tá»©c lÃ  ko láº¥y realtime Ä‘c)",,,,,
"This comment and its author have been removed from this group. Vietnamese and English are allowed here, hate speech is not!
This forum is where members are free to share their ideas/opinions about AI/ML topics in either language as long as the original posters are comfortable with the one they choose. A large portion of members in this forum study and work in an English environment, that makes them more fluent in this language when discussing technical topics.","This comment and its author have been removed from this group. Vietnamese and English are allowed here, hate speech is not! This forum is where members are free to share their ideas/opinions about AI/ML topics in either language as long as the original posters are comfortable with the one they choose. A large portion of members in this forum study and work in an English environment, that makes them more fluent in this language when discussing technical topics.",,,,,
"For those who want to try a better grounded version of ChatGPT in Vietnam, this is YouChat - a conversational search feature inside You Search Engine","For those who want to try a better grounded version of ChatGPT in Vietnam, this is YouChat - a conversational search feature inside You Search Engine",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, em lÃ  newbie má»›i há»c vá» Deep Learning (cá»¥ thá»ƒ lÃ  RNN).
Em cÃ³ xem vÃ  lÃ m theo video trÃªn youtube bÃ i hÆ°á»›ng dáº«n vá» dá»± Ä‘oÃ¡n doanh sá»‘ cÆ¡ báº£n sá»­ dá»¥ng RNN, nhÆ°ng em cÃ³ gáº·p tÃ¬nh tráº¡ng lÃ  khi run model á»Ÿ cÃ¡c láº§n khÃ¡c nhau thÃ¬ totalLoss cÃ ng giáº£m (nhÆ° hÃ¬nh), khÃ´ng láº§n nÃ o giá»‘ng vá»›i láº§n trÆ°á»›c. CÃ¡c anh chá»‹ cho em há»i táº¡i sao láº¡i xuáº¥t hiá»‡n tÃ¬nh tráº¡ng nÃ y váº­y áº¡?","ChÃ o má»i ngÆ°á»i áº¡, em lÃ  newbie má»›i há»c vá» Deep Learning (cá»¥ thá»ƒ lÃ  RNN). Em cÃ³ xem vÃ  lÃ m theo video trÃªn youtube bÃ i hÆ°á»›ng dáº«n vá» dá»± Ä‘oÃ¡n doanh sá»‘ cÆ¡ báº£n sá»­ dá»¥ng RNN, nhÆ°ng em cÃ³ gáº·p tÃ¬nh tráº¡ng lÃ  khi run model á»Ÿ cÃ¡c láº§n khÃ¡c nhau thÃ¬ totalLoss cÃ ng giáº£m (nhÆ° hÃ¬nh), khÃ´ng láº§n nÃ o giá»‘ng vá»›i láº§n trÆ°á»›c. CÃ¡c anh chá»‹ cho em há»i táº¡i sao láº¡i xuáº¥t hiá»‡n tÃ¬nh tráº¡ng nÃ y váº­y áº¡?",,,,,
"MÃ¬nh tháº¥y cÃ³ 1 repo nhiá»u sao (*) vá» láº­p trÃ¬nh cho Robot viáº¿t báº±ng ngÃ´n ngá»¯ Python, táº¡i Ä‘Ã¢y https://github.com/AtsushiSakai/PythonRobotics.
Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i nhiá»u báº¡n.","MÃ¬nh tháº¥y cÃ³ 1 repo nhiá»u sao (*) vá» láº­p trÃ¬nh cho Robot viáº¿t báº±ng ngÃ´n ngá»¯ Python, táº¡i Ä‘Ã¢y https://github.com/AtsushiSakai/PythonRobotics. Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i nhiá»u báº¡n.",,,,,
"em xin chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vÃ  Ä‘á»‹nh lÃ m vá» bÃ i toÃ¡n detect ngÆ°á»i vÃ  Ä‘áº¿m sá»‘ lÆ°á»£ng Ä‘á»ƒ Ä‘Æ°a ra cáº£nh bÃ¡o. tuy nhiÃªn khi tÃ¬m data cÃ³ 2 bá»™ dá»¯ liá»‡u: CityPersons https://www.v7labs.com/open-datasets/citypersons vÃ  EurocityPersons https://eurocity-dataset.tudelft.nl/ mÃ  em váº«n chÆ°a thá»ƒ download Ä‘Æ°á»£c. khÃ´ng biáº¿t trong group mÃ¬nh Ä‘Ã£ ai táº£i 2 táº­p nÃ y chÆ°a cÃ³ thá»ƒ share cho em Ä‘Æ°á»£c khÃ´ng áº¡.
em cáº£m Æ¡n má»i ngÆ°á»i!","em xin chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vÃ  Ä‘á»‹nh lÃ m vá» bÃ i toÃ¡n detect ngÆ°á»i vÃ  Ä‘áº¿m sá»‘ lÆ°á»£ng Ä‘á»ƒ Ä‘Æ°a ra cáº£nh bÃ¡o. tuy nhiÃªn khi tÃ¬m data cÃ³ 2 bá»™ dá»¯ liá»‡u: CityPersons https://www.v7labs.com/open-datasets/citypersons vÃ  EurocityPersons https://eurocity-dataset.tudelft.nl/ mÃ  em váº«n chÆ°a thá»ƒ download Ä‘Æ°á»£c. khÃ´ng biáº¿t trong group mÃ¬nh Ä‘Ã£ ai táº£i 2 táº­p nÃ y chÆ°a cÃ³ thá»ƒ share cho em Ä‘Æ°á»£c khÃ´ng áº¡. em cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"HÆ°á»›ng dáº«n Ä‘Äƒng kÃ½, tráº£i nghiá»‡m ChatGPT - AI ChatBot hot nháº¥t hiá»‡n nay
ChatGPT cá»§a OpenAI Ä‘ang ráº¥t hot trÃªn kháº¯p cÃ¡c diá»…n Ä‘Ã n. Trong video nÃ y mÃ¬nh sáº½ chia sáº» vá»›i anh em má»™t sá»‘ thÃ´ng tin vá» ChatGPT - má»™t language model cá»±c xá»‹n cá»§a OpenAI Ä‘Æ°á»£c fine tune tá»« GPT3.5 vá»›i há»c giÃ¡m sÃ¡t vÃ  tÄƒng cÆ°á»ng, cÃ¡ch Ä‘Äƒng kÃ½ Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng tá»« Viá»‡t Nam vÃ  tráº£i nghiá»‡m vá»›i nÃ³.
ChÃº Ã½: Náº¿u anh em khÃ´ng cÃ³ tháº» hoáº·c khÃ´ng tá»± Ä‘Äƒng kÃ½ Ä‘á»ƒ tráº£i nghiá»‡m Ä‘Æ°á»£c thÃ¬ cÃ³ thá»ƒ ib mÃ¬nh
https://youtu.be/pmEkdkJ0hmg","HÆ°á»›ng dáº«n Ä‘Äƒng kÃ½, tráº£i nghiá»‡m ChatGPT - AI ChatBot hot nháº¥t hiá»‡n nay ChatGPT cá»§a OpenAI Ä‘ang ráº¥t hot trÃªn kháº¯p cÃ¡c diá»…n Ä‘Ã n. Trong video nÃ y mÃ¬nh sáº½ chia sáº» vá»›i anh em má»™t sá»‘ thÃ´ng tin vá» ChatGPT - má»™t language model cá»±c xá»‹n cá»§a OpenAI Ä‘Æ°á»£c fine tune tá»« GPT3.5 vá»›i há»c giÃ¡m sÃ¡t vÃ  tÄƒng cÆ°á»ng, cÃ¡ch Ä‘Äƒng kÃ½ Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng tá»« Viá»‡t Nam vÃ  tráº£i nghiá»‡m vá»›i nÃ³. ChÃº Ã½: Náº¿u anh em khÃ´ng cÃ³ tháº» hoáº·c khÃ´ng tá»± Ä‘Äƒng kÃ½ Ä‘á»ƒ tráº£i nghiá»‡m Ä‘Æ°á»£c thÃ¬ cÃ³ thá»ƒ ib mÃ¬nh https://youtu.be/pmEkdkJ0hmg",,,,,
"CÃ¡c báº¡n cho mÃ¬nh há»i vá» deploy má»™t sklearn model.
Giáº£ sá»­ ta cÃ³ má»™t pipeline bao gá»“m feature engineering theo sau bá»Ÿi má»™t sklearn model. ThÆ°á»ng thÃ¬ vá»›i cÃ¡c built-in transformers vÃ  built-in sklearn model thÃ¬ cÃ³ thá»ƒ dump rá»“i load pickle rá»“i cháº¡y Ä‘á»™c láº­p khÃ´ng cáº§n code ban Ä‘áº§u. Tuy nhiÃªn trong pháº§n feature engineering cÃ³ ráº¥t nhiá»u custom code khiáº¿n cho viá»‡c chá»‰ lÆ°u file pickle thÃ¬ khÃ´ng Ä‘á»§ mÃ  cÃ²n pháº£i lÆ°u cáº£ code. Váº¥n Ä‘á» xáº£y ra lÃ  khi code thay Ä‘á»•i má»™t chÃºt thÃ¬ input vÃ o model cÅ©ng cÃ³ kháº³ nÄƒng thay Ä‘á»•i, dáº«n Ä‘áº¿n viá»‡c pháº£i lÆ°u cáº£ version cua code cÃ¹ng vá»›i file pickle kia. Má»™t giáº£i phÃ¡p mÃ¬nh Ä‘ang dÃ¹ng lÃ  lÆ°u cáº£ file pickle vÃ  git commit hash táº¡i thá»i Ä‘iá»ƒm file pickle Ä‘Æ°á»£c táº¡o ra, á»Ÿ serving thÃ¬ git checkout commit Ä‘Ã³ rá»“i inference.
MÃ¬nh nghÄ© cÃ¡ch nÃ y khÃ´ng Ä‘Æ°á»£c tá»‘i Æ°u, muá»‘n tham kháº£o cÃ¡c báº¡n xem cÃ³ giáº£i phÃ¡p nÃ o tá»‘t hÆ¡n khÃ´ng.
Trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m cÃ¡c giáº£i phÃ¡p, mÃ¬nh tháº¥y dill (link trong comment) Ä‘Æ°á»£c cho lÃ  cÃ³ kháº£ nÄƒng lÆ°u cáº£ code nhÆ°ng dill lÃ  third-party nÃªn mÃ¬nh khÃ´ng biáº¿t cÃ³ pháº£i cÃ¡ch tá»‘t nháº¥t khÃ´ng.
Cáº£m Æ¡n cÃ¡c báº¡n","CÃ¡c báº¡n cho mÃ¬nh há»i vá» deploy má»™t sklearn model. Giáº£ sá»­ ta cÃ³ má»™t pipeline bao gá»“m feature engineering theo sau bá»Ÿi má»™t sklearn model. ThÆ°á»ng thÃ¬ vá»›i cÃ¡c built-in transformers vÃ  built-in sklearn model thÃ¬ cÃ³ thá»ƒ dump rá»“i load pickle rá»“i cháº¡y Ä‘á»™c láº­p khÃ´ng cáº§n code ban Ä‘áº§u. Tuy nhiÃªn trong pháº§n feature engineering cÃ³ ráº¥t nhiá»u custom code khiáº¿n cho viá»‡c chá»‰ lÆ°u file pickle thÃ¬ khÃ´ng Ä‘á»§ mÃ  cÃ²n pháº£i lÆ°u cáº£ code. Váº¥n Ä‘á» xáº£y ra lÃ  khi code thay Ä‘á»•i má»™t chÃºt thÃ¬ input vÃ o model cÅ©ng cÃ³ kháº³ nÄƒng thay Ä‘á»•i, dáº«n Ä‘áº¿n viá»‡c pháº£i lÆ°u cáº£ version cua code cÃ¹ng vá»›i file pickle kia. Má»™t giáº£i phÃ¡p mÃ¬nh Ä‘ang dÃ¹ng lÃ  lÆ°u cáº£ file pickle vÃ  git commit hash táº¡i thá»i Ä‘iá»ƒm file pickle Ä‘Æ°á»£c táº¡o ra, á»Ÿ serving thÃ¬ git checkout commit Ä‘Ã³ rá»“i inference. MÃ¬nh nghÄ© cÃ¡ch nÃ y khÃ´ng Ä‘Æ°á»£c tá»‘i Æ°u, muá»‘n tham kháº£o cÃ¡c báº¡n xem cÃ³ giáº£i phÃ¡p nÃ o tá»‘t hÆ¡n khÃ´ng. Trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m cÃ¡c giáº£i phÃ¡p, mÃ¬nh tháº¥y dill (link trong comment) Ä‘Æ°á»£c cho lÃ  cÃ³ kháº£ nÄƒng lÆ°u cáº£ code nhÆ°ng dill lÃ  third-party nÃªn mÃ¬nh khÃ´ng biáº¿t cÃ³ pháº£i cÃ¡ch tá»‘t nháº¥t khÃ´ng. Cáº£m Æ¡n cÃ¡c báº¡n",,,,,
"Giá»›i thiá»‡u thÆ° viá»‡n má»›i thay tháº¿ Pandas cÃ³ tÃªn lÃ  Polars (https://github.com/pola-rs/polars). ThÆ° viá»‡n nÃ y Ä‘Æ°á»£c viáº¿t báº±ng ngÃ´n ngá»¯ Rust, nhÆ°ng Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i cáº£ báº±ng Python. MÃ¬nh test thá»­ quáº£ tháº­t nÃ³ ráº¥t nhanh, nhanh hÆ¡n nhiá»u láº§n so vá»›i Pandas vÃ  nhiá»u thÆ° viá»‡n phá»• biáº¿n khÃ¡c ná»¯a. Vá» benchmark cá»§a Polars (trÃªn dá»¯ liá»‡u 10^9 dÃ²ng vÃ  9 cá»™t) so vá»›i cÃ¡c thÆ° viá»‡n khÃ¡c, cÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm á»Ÿ Ä‘Ã¢y (https://h2oai.github.io/db-benchmark/; https://www.pola.rs/benchmarks.html). NhÃ³m tÃ¡c giáº£ cÃ³ viáº¿t hÆ°á»›ng dáº«n cho thÆ° viá»‡n báº±ng cáº£ ngÃ´n ngá»¯ Rust vÃ  Python táº¡i Ä‘Ã¢y (https://pola-rs.github.io/polars-book/user-guide/introduction.html).","Giá»›i thiá»‡u thÆ° viá»‡n má»›i thay tháº¿ Pandas cÃ³ tÃªn lÃ  Polars (https://github.com/pola-rs/polars). ThÆ° viá»‡n nÃ y Ä‘Æ°á»£c viáº¿t báº±ng ngÃ´n ngá»¯ Rust, nhÆ°ng Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i cáº£ báº±ng Python. MÃ¬nh test thá»­ quáº£ tháº­t nÃ³ ráº¥t nhanh, nhanh hÆ¡n nhiá»u láº§n so vá»›i Pandas vÃ  nhiá»u thÆ° viá»‡n phá»• biáº¿n khÃ¡c ná»¯a. Vá» benchmark cá»§a Polars (trÃªn dá»¯ liá»‡u 10^9 dÃ²ng vÃ  9 cá»™t) so vá»›i cÃ¡c thÆ° viá»‡n khÃ¡c, cÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm á»Ÿ Ä‘Ã¢y (https://h2oai.github.io/db-benchmark/; https://www.pola.rs/benchmarks.html). NhÃ³m tÃ¡c giáº£ cÃ³ viáº¿t hÆ°á»›ng dáº«n cho thÆ° viá»‡n báº±ng cáº£ ngÃ´n ngá»¯ Rust vÃ  Python táº¡i Ä‘Ã¢y (https://pola-rs.github.io/polars-book/user-guide/introduction.html).",,,,,
"VinAI Seminar - ""Fairness in Natural Language Processing""
Register here [https://lnkd.in/gJnhj2rm] to access seminar via Ms. Teams.
Speaker: Tim Baldwin, Assoc. Provost at MBZUAI and Melbourne Laureate Prof. at The University of Melbourne
Time: 2:00 pm - 3:00 pm (GMT+7), Tue, Dec 20, 2022","VinAI Seminar - ""Fairness in Natural Language Processing"" Register here [https://lnkd.in/gJnhj2rm] to access seminar via Ms. Teams. Speaker: Tim Baldwin, Assoc. Provost at MBZUAI and Melbourne Laureate Prof. at The University of Melbourne Time: 2:00 pm - 3:00 pm (GMT+7), Tue, Dec 20, 2022",,,,,
"CÃ¡c anh chá»‹ cÃ³ hiá»ƒu biáº¿t vá» machine learning, Ä‘áº¡i khÃ¡i lÃ  vá» K- Means Clustering (Äá» tÃ i: PhÃ¢n Cá»¥m MÃ u Sáº¯c )
hiá»‡n táº¡i trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu vÃ  há»c thÃ¬ em cÃ³ gáº·p má»™t chÃºt khÃ³ khÄƒn, mong anh chá»‹ nÃ o Ä‘i ngang qua, hiá»ƒu rÃµ cÃ³ thá»ƒ Ä‘á»ƒ láº¡i 1 cmt Ä‘á»ƒ e cÃ³ thá»ƒ hoÃ n thiá»‡n vá» cÃ¡i project nÃ y vá»›i áº¡ !! Sau Ä‘Ã¢y lÃ  nhá»¯ng khÃ³ khÄƒn em gáº·p pháº£i áº¡.
**KhÃ³ KhÄƒn:
0) LÃ m sao Ä‘á»ƒ tÃ¬m ra K ?
- CÃ¡i nÃ y thÃ¬ em váº«n chÆ°a hiá»ƒu ra cÃ¡ch Ä‘á»ƒ tÃ¬m K áº¡.
1) Trá»¥c tung, trá»¥c hoÃ nh lÃ m sao Ä‘á»ƒ hiá»ƒu nÃ³ trong elbow graph ?
- nhÆ° em tÃ¬m hiá»ƒu thÃ¬ pháº§n náº±m ngang nÃ³ lÃ  giÃ¡ trá»‹ cá»§a K) váº­y thÃ¬ cÃ²n trá»¥c náº±m dá»c thÃ¬ lÃ m sao Ä‘á»ƒ kiáº¿m Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a nÃ³ áº¡(Distortion)
2) Tháº¿ nÃ o lÃ  cá»¥m dá»¯ liá»‡u khÃ´ng thay Ä‘á»•i ?
- cÃ¡i nÃ y thÃ¬ e kiáº¿m tÃ i liá»‡u cÃ³ tá»±a tá»±a lÃ  khi â€œtrá»ng tÃ¢m khÃ´ng thay Ä‘á»•iâ€ e khÃ´ng biáº¿t lÃ  cÃ³ Ä‘Ãºng khÃ´ng, náº¿u sai thÃ¬ cÃ¡c anh chá»‹ cho e xin Ä‘á»‹nh nghÄ©a Ä‘Ãºng vá» nÃ³ vá»›i áº¡
3) HÃ m gÃ¬ khÃ´ng thay Ä‘á»•i ?
-nhÆ° e tÃ¬m hiá»ƒu thÃ¬ lÃ  hÃ m máº¥t mÃ¡t khÃ´ng thay Ä‘á»•i, nhÆ°ng e nghe cÃ¡c anh chá»‹ khac báº£o lÃ  hÃ m nÃ y ráº¥t khÃ³ hiá»ƒu, váº­y thÃ¬ cÃ²n hÃ m nÃ o khÃ´ng thay Ä‘á»•i ná»¯a k áº¡
-4) Vá»›i trá»ng tÃ¢m khá»Ÿi táº¡o khÃ¡c nhau, thÃ¬ trá»ng tÃ¢m cÃ³ thay Ä‘á»•i khÃ´ng
- thÃ¬ em nghÄ© lÃ  cÃ³, nhÆ°ng táº¡i vÃ¬ sao thÃ¬ e chÆ°a rÃµ, mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p áº¡.
5) Ä‘iá»u kiá»‡n dá»«ng lÃ  gÃ¬ ??
- Theo em thÃ¬ khi trá»ng tÃ¢m khÃ´ng thay Ä‘á»•i ná»¯a thÃ¬ nÃ³ sáº½ dá»«ng
***
á» trÃªn lÃ  nhá»¯ng khÃ³ khÄƒn khi e tÃ¬m hiá»ƒu vá» K means, vÃ  Ä‘Æ°a ra nhá»¯ng Ä‘Ã¡p Ã¡n mÃ  e tÃ¬m Ä‘Æ°á»£c thÃ´ng qua tÃ i liá»‡u, nÃªn cÃ³ thá»ƒ sai lá»‡ch, mong anh chá»‹ cÃ³ kiáº¿n thá»©c vá» K mean Clustering cÃ³ thá»ƒ há»— trá»£ em giáº£i Ä‘Ã¡p vá» cÃ¡c hÆ°á»›ng Ä‘i cÅ©ng nhÆ° cÃ¡c khÃ³ khÄƒn cá»§a e khi tÃ¬m hiá»ƒu á»Ÿ phÃ­a trÃªn vá»›i áº¡.
EM XIN Cáº¢M Æ N !!!!","CÃ¡c anh chá»‹ cÃ³ hiá»ƒu biáº¿t vá» machine learning, Ä‘áº¡i khÃ¡i lÃ  vá» K- Means Clustering (Äá» tÃ i: PhÃ¢n Cá»¥m MÃ u Sáº¯c ) hiá»‡n táº¡i trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu vÃ  há»c thÃ¬ em cÃ³ gáº·p má»™t chÃºt khÃ³ khÄƒn, mong anh chá»‹ nÃ o Ä‘i ngang qua, hiá»ƒu rÃµ cÃ³ thá»ƒ Ä‘á»ƒ láº¡i 1 cmt Ä‘á»ƒ e cÃ³ thá»ƒ hoÃ n thiá»‡n vá» cÃ¡i project nÃ y vá»›i áº¡ !! Sau Ä‘Ã¢y lÃ  nhá»¯ng khÃ³ khÄƒn em gáº·p pháº£i áº¡. **KhÃ³ KhÄƒn: 0) LÃ m sao Ä‘á»ƒ tÃ¬m ra K ? - CÃ¡i nÃ y thÃ¬ em váº«n chÆ°a hiá»ƒu ra cÃ¡ch Ä‘á»ƒ tÃ¬m K áº¡. 1) Trá»¥c tung, trá»¥c hoÃ nh lÃ m sao Ä‘á»ƒ hiá»ƒu nÃ³ trong elbow graph ? - nhÆ° em tÃ¬m hiá»ƒu thÃ¬ pháº§n náº±m ngang nÃ³ lÃ  giÃ¡ trá»‹ cá»§a K) váº­y thÃ¬ cÃ²n trá»¥c náº±m dá»c thÃ¬ lÃ m sao Ä‘á»ƒ kiáº¿m Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a nÃ³ áº¡(Distortion) 2) Tháº¿ nÃ o lÃ  cá»¥m dá»¯ liá»‡u khÃ´ng thay Ä‘á»•i ? - cÃ¡i nÃ y thÃ¬ e kiáº¿m tÃ i liá»‡u cÃ³ tá»±a tá»±a lÃ  khi â€œtrá»ng tÃ¢m khÃ´ng thay Ä‘á»•iâ€ e khÃ´ng biáº¿t lÃ  cÃ³ Ä‘Ãºng khÃ´ng, náº¿u sai thÃ¬ cÃ¡c anh chá»‹ cho e xin Ä‘á»‹nh nghÄ©a Ä‘Ãºng vá» nÃ³ vá»›i áº¡ 3) HÃ m gÃ¬ khÃ´ng thay Ä‘á»•i ? -nhÆ° e tÃ¬m hiá»ƒu thÃ¬ lÃ  hÃ m máº¥t mÃ¡t khÃ´ng thay Ä‘á»•i, nhÆ°ng e nghe cÃ¡c anh chá»‹ khac báº£o lÃ  hÃ m nÃ y ráº¥t khÃ³ hiá»ƒu, váº­y thÃ¬ cÃ²n hÃ m nÃ o khÃ´ng thay Ä‘á»•i ná»¯a k áº¡ -4) Vá»›i trá»ng tÃ¢m khá»Ÿi táº¡o khÃ¡c nhau, thÃ¬ trá»ng tÃ¢m cÃ³ thay Ä‘á»•i khÃ´ng - thÃ¬ em nghÄ© lÃ  cÃ³, nhÆ°ng táº¡i vÃ¬ sao thÃ¬ e chÆ°a rÃµ, mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p áº¡. 5) Ä‘iá»u kiá»‡n dá»«ng lÃ  gÃ¬ ?? - Theo em thÃ¬ khi trá»ng tÃ¢m khÃ´ng thay Ä‘á»•i ná»¯a thÃ¬ nÃ³ sáº½ dá»«ng *** á» trÃªn lÃ  nhá»¯ng khÃ³ khÄƒn khi e tÃ¬m hiá»ƒu vá» K means, vÃ  Ä‘Æ°a ra nhá»¯ng Ä‘Ã¡p Ã¡n mÃ  e tÃ¬m Ä‘Æ°á»£c thÃ´ng qua tÃ i liá»‡u, nÃªn cÃ³ thá»ƒ sai lá»‡ch, mong anh chá»‹ cÃ³ kiáº¿n thá»©c vá» K mean Clustering cÃ³ thá»ƒ há»— trá»£ em giáº£i Ä‘Ã¡p vá» cÃ¡c hÆ°á»›ng Ä‘i cÅ©ng nhÆ° cÃ¡c khÃ³ khÄƒn cá»§a e khi tÃ¬m hiá»ƒu á»Ÿ phÃ­a trÃªn vá»›i áº¡. EM XIN Cáº¢M Æ N !!!!",,,,,
"mn cho em há»i cÃ¡ch hoáº·c trang web Ã¡p dá»¥ng Reinforcement Learning vÃ o bÃ i toÃ¡n controlling traffic light vá»›i áº¡
Em cÃ¡m Æ¡n áº¡",mn cho em há»i cÃ¡ch hoáº·c trang web Ã¡p dá»¥ng Reinforcement Learning vÃ o bÃ i toÃ¡n controlling traffic light vá»›i áº¡ Em cÃ¡m Æ¡n áº¡,,,,,
"Hi cÃ¡c bÃ¡c, em Ä‘ang tÃ¬m hiá»ƒu bÃ i toÃ¡n table structure recognition.
Em khÃ´ng chuyÃªn CV nÃªn khÃ´ng biáº¿t cÃ³ heuristic nÃ o tá»« cÃ¡c Ä‘Æ°á»ng phÃ¢n cÃ¡ch (12 grids) thÃ nh 9 cells (relative cells) khÃ´ng áº¡ ?
CÃ¡c bÃ¡c cá»© tá»± do cho em keywords, hÆ°á»›ng cá»§a cÃ¡c bÃ¡c, em vÃ´ cÃ¹ng cáº£m kÃ­ch.
Em cáº£m Æ¡n cÃ¡c bÃ¡c nhiá»u áº¡.
#tabledetection #tablestructurerecognition","Hi cÃ¡c bÃ¡c, em Ä‘ang tÃ¬m hiá»ƒu bÃ i toÃ¡n table structure recognition. Em khÃ´ng chuyÃªn CV nÃªn khÃ´ng biáº¿t cÃ³ heuristic nÃ o tá»« cÃ¡c Ä‘Æ°á»ng phÃ¢n cÃ¡ch (12 grids) thÃ nh 9 cells (relative cells) khÃ´ng áº¡ ? CÃ¡c bÃ¡c cá»© tá»± do cho em keywords, hÆ°á»›ng cá»§a cÃ¡c bÃ¡c, em vÃ´ cÃ¹ng cáº£m kÃ­ch. Em cáº£m Æ¡n cÃ¡c bÃ¡c nhiá»u áº¡.",#tabledetection	#tablestructurerecognition,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  newbie, em Ä‘ang tÃ¬m thuáº­t toÃ¡n Ä‘Ãºng nháº¥t Ä‘á»ƒ xÃ¢y dá»±ng má»™t recommendation model (gá»£i Ã½ má»™t list category khi ngÆ°á»i dÃ¹ng thao tÃ¡c vá»›i má»™t hoáº·c nhiá»u items), cho má»™t bá»™ dá»¯ liá»‡u(datasets) vá»›i format CSV nhÆ° sau:
+) ~1500 items, ~2000 categories. Má»™t product cÃ³ nhiá»u categories vÃ  ngÆ°á»£c láº¡i.
+) 1 triá»‡u data interactions (dá»¯ liá»‡u users mua item, khÃ´ng mua ko tÃ­nh vÃ o interaction) - user nÃ o, mua item gÃ¬, á»Ÿ thá»i gian nÃ o
+) 300k users vá»›i thÃ´ng tin vá» nhÃ³m tuá»•i, giá»›i tÃ­nh
##############################
Input: 1 list unique ItemIDs
Output: 1 list unique Categories
Káº¿t quáº£ pháº£i dá»±a trÃªn nhá»¯ng thÃ´ng tin sau:
categories cá»§a item + thÃ´ng tin tuá»•i + giá»›i tÃ­nh cá»§a user
##############################
Do khÃ´ng cÃ³ kinh nghiá»‡m vÃ  thá»i gian quÃ¡ gáº¥p nÃªn dá»± Ã¡n pháº£i dÃ¹ng AWS Sagemaker Ä‘á»ƒ build. Em cÅ©ng Ä‘Ã£ tÃ¬m hiá»ƒu vá» supervised, unsupervised vÃ  RL, one-hot-encode. Em cÅ©ng Ä‘Ã£ Ä‘á»c vÃ  lÃ m sample vá»›i nhiá»u thuáº­t toÃ¡n khÃ¡c nhau(Factorization Machine) nhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c thuáº­t toÃ¡n Ä‘Ãºng.
Mong má»i ngÆ°á»i chá»‰ giÃ¡o vÃ  suggest thuáº­t toÃ¡n Machine Learning dÃ¹ng Ä‘Æ°á»£c cho bÃ i toÃ¡n nÃ y áº¡. Hiá»‡n táº¡i em Ä‘ang Ä‘á»c vá» tháº±ng Linear Learner. Em cáº£m Æ¡n áº¡!","ChÃ o má»i ngÆ°á»i, em lÃ  newbie, em Ä‘ang tÃ¬m thuáº­t toÃ¡n Ä‘Ãºng nháº¥t Ä‘á»ƒ xÃ¢y dá»±ng má»™t recommendation model (gá»£i Ã½ má»™t list category khi ngÆ°á»i dÃ¹ng thao tÃ¡c vá»›i má»™t hoáº·c nhiá»u items), cho má»™t bá»™ dá»¯ liá»‡u(datasets) vá»›i format CSV nhÆ° sau: +) ~1500 items, ~2000 categories. Má»™t product cÃ³ nhiá»u categories vÃ  ngÆ°á»£c láº¡i. +) 1 triá»‡u data interactions (dá»¯ liá»‡u users mua item, khÃ´ng mua ko tÃ­nh vÃ o interaction) - user nÃ o, mua item gÃ¬, á»Ÿ thá»i gian nÃ o +) 300k users vá»›i thÃ´ng tin vá» nhÃ³m tuá»•i, giá»›i tÃ­nh ############################## Input: 1 list unique ItemIDs Output: 1 list unique Categories Káº¿t quáº£ pháº£i dá»±a trÃªn nhá»¯ng thÃ´ng tin sau: categories cá»§a item + thÃ´ng tin tuá»•i + giá»›i tÃ­nh cá»§a user ############################## Do khÃ´ng cÃ³ kinh nghiá»‡m vÃ  thá»i gian quÃ¡ gáº¥p nÃªn dá»± Ã¡n pháº£i dÃ¹ng AWS Sagemaker Ä‘á»ƒ build. Em cÅ©ng Ä‘Ã£ tÃ¬m hiá»ƒu vá» supervised, unsupervised vÃ  RL, one-hot-encode. Em cÅ©ng Ä‘Ã£ Ä‘á»c vÃ  lÃ m sample vá»›i nhiá»u thuáº­t toÃ¡n khÃ¡c nhau(Factorization Machine) nhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c thuáº­t toÃ¡n Ä‘Ãºng. Mong má»i ngÆ°á»i chá»‰ giÃ¡o vÃ  suggest thuáº­t toÃ¡n Machine Learning dÃ¹ng Ä‘Æ°á»£c cho bÃ i toÃ¡n nÃ y áº¡. Hiá»‡n táº¡i em Ä‘ang Ä‘á»c vá» tháº±ng Linear Learner. Em cáº£m Æ¡n áº¡!",,,,,
"Dáº¡ chÃ o anh chá»‹, láº¡i lÃ  em Ä‘Ã¢y. HÃ´m nay em trá»Ÿ láº¡i vá»›i má»™t cÃ¢u há»i vá» Transformer.
VÃ¬ viá»‡c náº¡p táº¥t cáº£ cÃ¡c tá»« trong cÃ¢u vÃ o trong máº¡ng sáº½ dáº«n Ä‘áº¿n viá»‡c khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c thá»© tá»± cá»§a tá»« nÃªn tÃ¡c giáº£ cÃ³ Ä‘á» xuáº¥t thÃªm pháº§n ""Positional Encoding"" vÃ o ma tráº­n biá»ƒu diá»…n input. TÃ¡c giáº£ cÅ©ng Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng viá»‡c lá»±a chá»n hÃ m sin, cos Ä‘em láº¡i hiá»‡u quáº£. Váº­y náº¿u em dÃ¹ng 1 hÃ m tÄƒng giÃ¡ trá»‹ theo tuyáº¿n tÃ­nh thay vÃ¬ hÃ m Ä‘á» xuáº¥t thÃ¬ cÃ³ áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n hiá»‡u quáº£ khÃ´ng? (giáº£ sá»­ Ä‘á»™ dÃ i input lÃ  512 thÃ¬ em sáº½ cá»™ng thÃªm 1 ma tráº­n nÃ³ cÃ³ dáº¡ng [1, 2, 3, ..., 512] vÃ o má»—i hÃ ng cáº£u ma tráº­n input)
Em xin cáº£m Æ¡n
#NLP","Dáº¡ chÃ o anh chá»‹, láº¡i lÃ  em Ä‘Ã¢y. HÃ´m nay em trá»Ÿ láº¡i vá»›i má»™t cÃ¢u há»i vá» Transformer. VÃ¬ viá»‡c náº¡p táº¥t cáº£ cÃ¡c tá»« trong cÃ¢u vÃ o trong máº¡ng sáº½ dáº«n Ä‘áº¿n viá»‡c khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c thá»© tá»± cá»§a tá»« nÃªn tÃ¡c giáº£ cÃ³ Ä‘á» xuáº¥t thÃªm pháº§n ""Positional Encoding"" vÃ o ma tráº­n biá»ƒu diá»…n input. TÃ¡c giáº£ cÅ©ng Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng viá»‡c lá»±a chá»n hÃ m sin, cos Ä‘em láº¡i hiá»‡u quáº£. Váº­y náº¿u em dÃ¹ng 1 hÃ m tÄƒng giÃ¡ trá»‹ theo tuyáº¿n tÃ­nh thay vÃ¬ hÃ m Ä‘á» xuáº¥t thÃ¬ cÃ³ áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n hiá»‡u quáº£ khÃ´ng? (giáº£ sá»­ Ä‘á»™ dÃ i input lÃ  512 thÃ¬ em sáº½ cá»™ng thÃªm 1 ma tráº­n nÃ³ cÃ³ dáº¡ng [1, 2, 3, ..., 512] vÃ o má»—i hÃ ng cáº£u ma tráº­n input) Em xin cáº£m Æ¡n",#NLP,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang thá»±c hiá»‡n dá»± Ã¡n web nghe nháº¡c giá» muá»‘n nghiÃªn cá»©u tÃ¬m kiáº¿m theo giai Ä‘iá»‡u nhÆ°ng khÃ´ng biáº¿t tÃ¬m Ä‘á»c tÃ i liá»‡u gÃ¬ .xin má»i ngÆ°á»i chá»‰ giÃºp","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang thá»±c hiá»‡n dá»± Ã¡n web nghe nháº¡c giá» muá»‘n nghiÃªn cá»©u tÃ¬m kiáº¿m theo giai Ä‘iá»‡u nhÆ°ng khÃ´ng biáº¿t tÃ¬m Ä‘á»c tÃ i liá»‡u gÃ¬ .xin má»i ngÆ°á»i chá»‰ giÃºp",,,,,
"Xin chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘áº¡i diá»‡n cho nhÃ³m Cool Water hÃ´m nay xin chia sáº» solution cho Ä‘á» bÃ i Liveness Detection trong cuá»™c thi Zalo AI Challenge 2022.
Chung cuá»™c thÃ¬ nhÃ³m mÃ¬nh may máº¯n Ä‘á»©ng thá»© nháº¥t vá» Ä‘iá»ƒm T-EER (Time + EER) cÃ´ng bá»‘ á»Ÿ Zalo AI Summit ngÃ y 17/12/2022.
Solution cho Ä‘á» bÃ i nÃ y nhÃ³m mÃ¬nh sá»­ dá»¥ng ká»¹ thuáº­t ensemble cÃ¡c mÃ´ hÃ¬nh á»Ÿ cÃ¡c resolution khÃ¡c nhau Ä‘á»ƒ trÃ¡nh bá»‹ overfit trÃªn bá»™ private vÃ  cÃ³ sá»­ dá»¥ng thÃªm má»™t sá»‘ ká»¹ thuáº­t nhá» nhÆ° heavy augmentation, label smoothing, training EMA Ä‘á»ƒ cáº£i thiá»‡n Ä‘iá»ƒm CV láº«n LB. Tuy nhiÃªn do ensemble khÃ¡ nhiá»u mÃ´ hÃ¬nh nÃªn tá»‘c Ä‘á»™ nhÃ³m mÃ¬nh gáº§n nhÆ° cháº­m gáº¥p Ä‘Ã´i so vá»›i cÃ¡c Ä‘á»™i khÃ¡c ğŸ˜…
Code vÃ  má»™t sá»‘ káº¿t quáº£ thá»­ nghiá»‡m cá»§a nhÃ³m má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y:
https://github.com/hungk64it1x/zac-2022
Lá»i cuá»‘i mÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n BTC Zalo AI Ä‘Ã£ tá»• chá»©c má»™t cuá»™c thi vá» AI ráº¥t thÃº vá»‹, thá»­ thÃ¡ch vÃ  Ä‘áº§y Ã½ nghÄ©a thá»±c tiá»…n. ChÃºc cho nhiá»u nÄƒm tá»›i BTC sáº½ tá»• chá»©c Ä‘Æ°á»£c nhiá»u cuá»™c thi vá» AI tháº­t thÃ nh cÃ´ng hÆ¡n ná»¯a.
 â€” vá»›i BiÃªn DÆ°Æ¡ng VÄƒn vÃ  2 ngÆ°á»i khÃ¡c.","Xin chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘áº¡i diá»‡n cho nhÃ³m Cool Water hÃ´m nay xin chia sáº» solution cho Ä‘á» bÃ i Liveness Detection trong cuá»™c thi Zalo AI Challenge 2022. Chung cuá»™c thÃ¬ nhÃ³m mÃ¬nh may máº¯n Ä‘á»©ng thá»© nháº¥t vá» Ä‘iá»ƒm T-EER (Time + EER) cÃ´ng bá»‘ á»Ÿ Zalo AI Summit ngÃ y 17/12/2022. Solution cho Ä‘á» bÃ i nÃ y nhÃ³m mÃ¬nh sá»­ dá»¥ng ká»¹ thuáº­t ensemble cÃ¡c mÃ´ hÃ¬nh á»Ÿ cÃ¡c resolution khÃ¡c nhau Ä‘á»ƒ trÃ¡nh bá»‹ overfit trÃªn bá»™ private vÃ  cÃ³ sá»­ dá»¥ng thÃªm má»™t sá»‘ ká»¹ thuáº­t nhá» nhÆ° heavy augmentation, label smoothing, training EMA Ä‘á»ƒ cáº£i thiá»‡n Ä‘iá»ƒm CV láº«n LB. Tuy nhiÃªn do ensemble khÃ¡ nhiá»u mÃ´ hÃ¬nh nÃªn tá»‘c Ä‘á»™ nhÃ³m mÃ¬nh gáº§n nhÆ° cháº­m gáº¥p Ä‘Ã´i so vá»›i cÃ¡c Ä‘á»™i khÃ¡c Code vÃ  má»™t sá»‘ káº¿t quáº£ thá»­ nghiá»‡m cá»§a nhÃ³m má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y: https://github.com/hungk64it1x/zac-2022 Lá»i cuá»‘i mÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n BTC Zalo AI Ä‘Ã£ tá»• chá»©c má»™t cuá»™c thi vá» AI ráº¥t thÃº vá»‹, thá»­ thÃ¡ch vÃ  Ä‘áº§y Ã½ nghÄ©a thá»±c tiá»…n. ChÃºc cho nhiá»u nÄƒm tá»›i BTC sáº½ tá»• chá»©c Ä‘Æ°á»£c nhiá»u cuá»™c thi vá» AI tháº­t thÃ nh cÃ´ng hÆ¡n ná»¯a. â€” vá»›i BiÃªn DÆ°Æ¡ng VÄƒn vÃ  2 ngÆ°á»i khÃ¡c.",,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh xin Ä‘áº¡i diá»‡n cho team VTS-HTML chia sáº» solution cho track Lyric Alignment trong cuá»™c thi Zalo AI Challenge 2022 (Top 3 Private test).
*Tá»•ng quan vá» solution cá»§a nhÃ³m:
- TÃ¡ch vocal tá»« audio gá»‘c
- Xá»­ lÃ½ noise trong datasets
- Xá»­ lÃ½ misalignment cá»§a GT: sá»­ dá»¥ng pseudo-labels vá»›i nhá»¯ng samples audio cÃ³ IoU tháº¥p < 0.7 (giá»¯a pseudo-label tá»« pretrained vÃ  GT cá»§a BTC)
- Fine-tune Acoustics models vá»›i dataset á»Ÿ bÆ°á»›c 2 vÃ  align báº±ng thuáº­t toÃ¡n Viterbi forced alignment
- Post-process blank giá»¯a dá»± Ä‘oÃ¡n cá»§a 2 tá»« liÃªn ká»
Chi tiáº¿t ká»¹ thuáº­t Ä‘Æ°á»£c trÃ¬nh bÃ y á»Ÿ repo: https://github.com/vieduy/zac2022-lyric-alignment
Qua Ä‘Ã¢y xin cáº£m Æ¡n BTC Zalo AI Challenge Ä‘Ã£ tá»• chá»©c má»™t cuá»™c thi vÃ´ cÃ¹ng bá»• Ã­ch. Hy vá»ng chÃºng ta sáº½ cÃ³ thÃªm nhiá»u cuá»™c thi AI mang tÃ­nh thá»±c tiá»…n hÆ¡n trong tÆ°Æ¡ng lai.","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh xin Ä‘áº¡i diá»‡n cho team VTS-HTML chia sáº» solution cho track Lyric Alignment trong cuá»™c thi Zalo AI Challenge 2022 (Top 3 Private test). *Tá»•ng quan vá» solution cá»§a nhÃ³m: - TÃ¡ch vocal tá»« audio gá»‘c - Xá»­ lÃ½ noise trong datasets - Xá»­ lÃ½ misalignment cá»§a GT: sá»­ dá»¥ng pseudo-labels vá»›i nhá»¯ng samples audio cÃ³ IoU tháº¥p < 0.7 (giá»¯a pseudo-label tá»« pretrained vÃ  GT cá»§a BTC) - Fine-tune Acoustics models vá»›i dataset á»Ÿ bÆ°á»›c 2 vÃ  align báº±ng thuáº­t toÃ¡n Viterbi forced alignment - Post-process blank giá»¯a dá»± Ä‘oÃ¡n cá»§a 2 tá»« liÃªn ká» Chi tiáº¿t ká»¹ thuáº­t Ä‘Æ°á»£c trÃ¬nh bÃ y á»Ÿ repo: https://github.com/vieduy/zac2022-lyric-alignment Qua Ä‘Ã¢y xin cáº£m Æ¡n BTC Zalo AI Challenge Ä‘Ã£ tá»• chá»©c má»™t cuá»™c thi vÃ´ cÃ¹ng bá»• Ã­ch. Hy vá»ng chÃºng ta sáº½ cÃ³ thÃªm nhiá»u cuá»™c thi AI mang tÃ­nh thá»±c tiá»…n hÆ¡n trong tÆ°Æ¡ng lai.",,,,,
"Em chÃ o anh chá»‹. Em cÃ³ má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n nhÆ° nÃ y Ä‘á»ƒ nháº­n diá»‡n má»™t há»‡ thá»‘ng.
Giáº£ sá»­ em cho nháº­n diá»‡n hÃ m y=3x, váº­y káº¿t quáº£ dy/dx tÃ­nh theo máº¡ng neuron cÃ³ cho báº±ng 3 khÃ´ng áº¡?","Em chÃ o anh chá»‹. Em cÃ³ má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n nhÆ° nÃ y Ä‘á»ƒ nháº­n diá»‡n má»™t há»‡ thá»‘ng. Giáº£ sá»­ em cho nháº­n diá»‡n hÃ m y=3x, váº­y káº¿t quáº£ dy/dx tÃ­nh theo máº¡ng neuron cÃ³ cho báº±ng 3 khÃ´ng áº¡?",,,,,
"Xin chÃ o má»i ngÆ°á»i hÃ´m nay mÃ¬nh Ä‘áº¡i diá»‡n Team Telegram chia sáº» solution cho cÃ¡c task E2E Question Answering vÃ  task Lyric Alignment trong chuá»—i cÃ¡c cuá»™c thi Zalo AI Challenge 2022.
Team mÃ¬nh táº­p trung hÆ¡n vÃ o task NLP - E2E Question Answering, solution cá»§a nhÃ³m xoay quanh viá»‡c search candidates (2 stage) vÃ  re-ranking (2 stage) cÃ¹ng vá»›i Ä‘Ã³ lÃ  finetuning MRCQA model, pseudo labeling, chi tiáº¿t hÆ¡n vá» pipeline cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ repo (link á»Ÿ bÃªn dÆ°á»›i), cÃ²n vá» task Lyric Alignment nháº­n tháº¥y dá»¯ liá»‡u training quÃ¡ noise vÃ  tracking Ä‘iá»ƒm local, visualize sample data, public leaderboard khÃ´ng consistent nÃªn team quyáº¿t Ä‘á»‹nh sá»­ dá»¥ng solution Ä‘Æ¡n giáº£n vÃ  finish trong tuáº§n Ä‘áº§u cá»§a challenge.
UPDATE: Káº¿t quáº£ chung cuá»™c cÃ´ng bá»‘ táº¡i Zalo AI Submit (17/12/2022) thÃ¬ bÃ i E2E Question Answering Ä‘Æ°á»£c Top 1 Private Leaderboard (time and accuracy) vÃ  bÃ i Lyric Alignment Ä‘Æ°á»£c Top 2 Private Leaderboard (time and iou metric).
Code cho Solution cá»§a cÃ¡c Task má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c vÃ  tham kháº£o á»Ÿ Ä‘Ã¢y (má»i ngÆ°á»i ai cÃ³ cÃ¢u há»i gÃ¬ cÃ³ thá»ƒ há»i á»Ÿ Issues cá»§a repo hoáº·c bÃ¬nh luáº­n á»Ÿ bÃ i viáº¿t nÃ y, náº¿u má»i ngÆ°á»i tháº¥y há»¯u Ã­ch cÃ³ thá»ƒ cho nhÃ³m má»™t Star ğŸ˜€
Task Lyric Alignment: https://github.com/Telegram-Zalo/zac2022-lyric-alignment
Task E2E Question Answering: https://github.com/Telegram-Zalo/zac2022-e2e-qa
Cuá»‘i cÃ¹ng mÃ¬nh xin Ä‘Æ°á»£c cáº£m Æ¡n BTC cuá»™c thi Zalo AI Challenge Ä‘Ã£ tá»• chá»©c nhá»¯ng cuá»™c thi vÃ´ cÃ¹ng thÃº vá»‹ vÃ  Ä‘áº§y thá»­ thÃ¡ch, hy vá»ng nhá»¯ng nÄƒm tá»›i cuá»™c thi sáº½ Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ´ng hÆ¡n ná»¯a. Cáº£m Æ¡n táº¥t cáº£ cÃ¡c Ä‘á»™i thi cÃ¹ng nhau thi Ä‘áº¥u, ná»— lá»±c cáº£i thiá»‡n giáº£i phÃ¡p, BXH thay Ä‘á»•i liÃªn tá»¥c cÅ©ng lÃ  Ä‘á»™ng lá»±c cho team mÃ¬nh cá»‘ gáº¯ng hÆ¡n ná»¯a. Äáº·c biá»‡t mÃ¬nh xin Ä‘Æ°á»£c cáº£m Æ¡n Ä‘áº¿n 2 anh mentor cá»§a mÃ¬nh Ä‘Ã³ lÃ  anh KhÃ´i Tuáº¥n Nguyá»…n vÃ  anh Nguyá»…n QuÃ¡n Anh Minh trong suá»‘t thá»i gian tham gia cuá»™c thi.
P/s: LÆ°u Ã½ Code vÃ  README Ä‘ang á»Ÿ trong giai Ä‘oáº¡n refactor vÃ  cleaning.
README sáº½ Ä‘Æ°á»£c cáº­p nháº­t chi tiáº¿t hÆ¡n.
 â€” vá»›i Nguyá»…n QuÃ¡n Anh Minh vÃ  KhÃ´i Tuáº¥n Nguyá»…n.","Xin chÃ o má»i ngÆ°á»i hÃ´m nay mÃ¬nh Ä‘áº¡i diá»‡n Team Telegram chia sáº» solution cho cÃ¡c task E2E Question Answering vÃ  task Lyric Alignment trong chuá»—i cÃ¡c cuá»™c thi Zalo AI Challenge 2022. Team mÃ¬nh táº­p trung hÆ¡n vÃ o task NLP - E2E Question Answering, solution cá»§a nhÃ³m xoay quanh viá»‡c search candidates (2 stage) vÃ  re-ranking (2 stage) cÃ¹ng vá»›i Ä‘Ã³ lÃ  finetuning MRCQA model, pseudo labeling, chi tiáº¿t hÆ¡n vá» pipeline cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ repo (link á»Ÿ bÃªn dÆ°á»›i), cÃ²n vá» task Lyric Alignment nháº­n tháº¥y dá»¯ liá»‡u training quÃ¡ noise vÃ  tracking Ä‘iá»ƒm local, visualize sample data, public leaderboard khÃ´ng consistent nÃªn team quyáº¿t Ä‘á»‹nh sá»­ dá»¥ng solution Ä‘Æ¡n giáº£n vÃ  finish trong tuáº§n Ä‘áº§u cá»§a challenge. UPDATE: Káº¿t quáº£ chung cuá»™c cÃ´ng bá»‘ táº¡i Zalo AI Submit (17/12/2022) thÃ¬ bÃ i E2E Question Answering Ä‘Æ°á»£c Top 1 Private Leaderboard (time and accuracy) vÃ  bÃ i Lyric Alignment Ä‘Æ°á»£c Top 2 Private Leaderboard (time and iou metric). Code cho Solution cá»§a cÃ¡c Task má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c vÃ  tham kháº£o á»Ÿ Ä‘Ã¢y (má»i ngÆ°á»i ai cÃ³ cÃ¢u há»i gÃ¬ cÃ³ thá»ƒ há»i á»Ÿ Issues cá»§a repo hoáº·c bÃ¬nh luáº­n á»Ÿ bÃ i viáº¿t nÃ y, náº¿u má»i ngÆ°á»i tháº¥y há»¯u Ã­ch cÃ³ thá»ƒ cho nhÃ³m má»™t Star Task Lyric Alignment: https://github.com/Telegram-Zalo/zac2022-lyric-alignment Task E2E Question Answering: https://github.com/Telegram-Zalo/zac2022-e2e-qa Cuá»‘i cÃ¹ng mÃ¬nh xin Ä‘Æ°á»£c cáº£m Æ¡n BTC cuá»™c thi Zalo AI Challenge Ä‘Ã£ tá»• chá»©c nhá»¯ng cuá»™c thi vÃ´ cÃ¹ng thÃº vá»‹ vÃ  Ä‘áº§y thá»­ thÃ¡ch, hy vá»ng nhá»¯ng nÄƒm tá»›i cuá»™c thi sáº½ Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ´ng hÆ¡n ná»¯a. Cáº£m Æ¡n táº¥t cáº£ cÃ¡c Ä‘á»™i thi cÃ¹ng nhau thi Ä‘áº¥u, ná»— lá»±c cáº£i thiá»‡n giáº£i phÃ¡p, BXH thay Ä‘á»•i liÃªn tá»¥c cÅ©ng lÃ  Ä‘á»™ng lá»±c cho team mÃ¬nh cá»‘ gáº¯ng hÆ¡n ná»¯a. Äáº·c biá»‡t mÃ¬nh xin Ä‘Æ°á»£c cáº£m Æ¡n Ä‘áº¿n 2 anh mentor cá»§a mÃ¬nh Ä‘Ã³ lÃ  anh KhÃ´i Tuáº¥n Nguyá»…n vÃ  anh Nguyá»…n QuÃ¡n Anh Minh trong suá»‘t thá»i gian tham gia cuá»™c thi. P/s: LÆ°u Ã½ Code vÃ  README Ä‘ang á»Ÿ trong giai Ä‘oáº¡n refactor vÃ  cleaning. README sáº½ Ä‘Æ°á»£c cáº­p nháº­t chi tiáº¿t hÆ¡n. â€” vá»›i Nguyá»…n QuÃ¡n Anh Minh vÃ  KhÃ´i Tuáº¥n Nguyá»…n.",,,,,
"Dáº¡ chÃ o anh chá»‹ trong gr, nay em láº¡i cÃ³ tháº¯c máº¯c nhÆ° sau áº¡. Khi tÃ¬m hiá»ƒu thÃ¬ em Ä‘Æ°á»£c biáº¿t váº¥n Ä‘á» cá»§a cÃ¡c DNNs(Deep neural networks) á»Ÿ thá»i gian Ä‘áº§u lÃ  gradient cÃ³ thá»ƒ bá»‹ vanishing/exploding. Vá»›i Exploding thÃ¬ ta cÃ³ thá»ƒ dÃ¹ng Gradient Clipping hoáº·c Gradient Scaling. NhÆ°ng vá»›i Vanishing thÃ¬ láº¡i chá»‰ nháº­n Ä‘Æ°á»£c hÆ°á»›ng dáº«n lÃ  sá»­ dá»¥ng cÃ¡c hÃ m cÃ³ dáº¡ng ReLU Ä‘á»ƒ trÃ¡nh Ä‘Æ°a Ä‘áº¡o hÃ m vá» 1 Ä‘oáº¡n giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh nhÆ° hÃ m Tanh hoáº·c Sigmod. Váº­y em cÃ³ cÃ¢u há»i sau:
1. Liá»‡u cÃ¡c hÃ m dáº¡ng ReLU cÃ³ thá»±c sá»± giáº£i quyáº¿t triá»‡t Ä‘á»ƒ váº¥n Ä‘á» Vanishing khÃ´ng?
2. NgoÃ i viá»‡c chá»n activity function thÃ¬ ta cÃ²n cÃ³ nhá»¯ng hÆ°á»›ng giáº£i quyáº¿t nÃ o cho váº¥n Ä‘á» nÃ y?
Em xin cáº£m Æ¡n
#RNN #ML","Dáº¡ chÃ o anh chá»‹ trong gr, nay em láº¡i cÃ³ tháº¯c máº¯c nhÆ° sau áº¡. Khi tÃ¬m hiá»ƒu thÃ¬ em Ä‘Æ°á»£c biáº¿t váº¥n Ä‘á» cá»§a cÃ¡c DNNs(Deep neural networks) á»Ÿ thá»i gian Ä‘áº§u lÃ  gradient cÃ³ thá»ƒ bá»‹ vanishing/exploding. Vá»›i Exploding thÃ¬ ta cÃ³ thá»ƒ dÃ¹ng Gradient Clipping hoáº·c Gradient Scaling. NhÆ°ng vá»›i Vanishing thÃ¬ láº¡i chá»‰ nháº­n Ä‘Æ°á»£c hÆ°á»›ng dáº«n lÃ  sá»­ dá»¥ng cÃ¡c hÃ m cÃ³ dáº¡ng ReLU Ä‘á»ƒ trÃ¡nh Ä‘Æ°a Ä‘áº¡o hÃ m vá» 1 Ä‘oáº¡n giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh nhÆ° hÃ m Tanh hoáº·c Sigmod. Váº­y em cÃ³ cÃ¢u há»i sau: 1. Liá»‡u cÃ¡c hÃ m dáº¡ng ReLU cÃ³ thá»±c sá»± giáº£i quyáº¿t triá»‡t Ä‘á»ƒ váº¥n Ä‘á» Vanishing khÃ´ng? 2. NgoÃ i viá»‡c chá»n activity function thÃ¬ ta cÃ²n cÃ³ nhá»¯ng hÆ°á»›ng giáº£i quyáº¿t nÃ o cho váº¥n Ä‘á» nÃ y? Em xin cáº£m Æ¡n",#RNN	#ML,,,,
"GIá»šI THIá»†U TRANG WEB HAY Äá»‚ Äá»ŒC VÃ€ Tá»”NG Há»¢P CÃC BÃ€I BÃO
ChÃ o anh/chá»‹/cÃ¡c báº¡n,
Gáº§n Ä‘Ã¢y em/mÃ¬nh Ä‘Æ°á»£c giá»›i thiá»‡u vá» Research Rabbit (https://www.researchrabbit.ai/), má»™t cÃ´ng cá»¥ tuyá»‡t vá»i Ä‘á»ƒ Ä‘á»c vÃ  tá»•ng há»£p cÃ¡c tÃ i liá»‡u tham kháº£o cho pháº§n Literature review. CÃ´ng cá»¥ nÃ y cho phÃ©p tÃ¬m kiáº¿m cÃ¡c bÃ i bÃ¡o (bao gá»“m cÃ¡c bÃ i bÃ¡o tÆ°Æ¡ng tá»± vá»›i nhá»¯ng bÃ i Ä‘Ã£ lÆ°u), hiá»ƒn thá»‹ báº£n tÃ³m táº¯t (abstract) cÃ¡c bÃ i bÃ¡o Ä‘Ã³ vÃ  Ä‘á» xuáº¥t cÃ´ng trÃ¬nh nghiÃªn cá»©u liÃªn quan.
KhÃ´ng chá»‰ váº­y Research Rabbit cÃ²n cho phÃ©p ngÆ°á»i dÃ¹ng chia sáº» cÃ¡c bá»™ sÆ°u táº­p (collections) cho ngÆ°á»i khÃ¡c vÃ  há»— trá»£ viá»‡c trÃ­ch xuáº¥t cÃ¡c tÃ i liá»‡u tham kháº£o má»™t cÃ¡ch dá»… dÃ ng thÃ´ng qua Shareable link vÃ  BibTeX (hÃ¬nh minh há»a).
Hy vá»ng bÃ i nÃ y sáº½ giÃºp Ã­ch cho cÃ¡c nhÃ  nghiÃªn cá»©u tÃ¬m kiáº¿m, quáº£n lÃ½ tÃ i liá»‡u tham kháº£o nhanh vÃ  hiá»‡u quáº£ hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng.
Nguá»“n tham kháº£o: https://twitter.com/MushtaqBilalPhD/status/1583392303183712256","GIá»šI THIá»†U TRANG WEB HAY Äá»‚ Äá»ŒC VÃ€ Tá»”NG Há»¢P CÃC BÃ€I BÃO ChÃ o anh/chá»‹/cÃ¡c báº¡n, Gáº§n Ä‘Ã¢y em/mÃ¬nh Ä‘Æ°á»£c giá»›i thiá»‡u vá» Research Rabbit (https://www.researchrabbit.ai/), má»™t cÃ´ng cá»¥ tuyá»‡t vá»i Ä‘á»ƒ Ä‘á»c vÃ  tá»•ng há»£p cÃ¡c tÃ i liá»‡u tham kháº£o cho pháº§n Literature review. CÃ´ng cá»¥ nÃ y cho phÃ©p tÃ¬m kiáº¿m cÃ¡c bÃ i bÃ¡o (bao gá»“m cÃ¡c bÃ i bÃ¡o tÆ°Æ¡ng tá»± vá»›i nhá»¯ng bÃ i Ä‘Ã£ lÆ°u), hiá»ƒn thá»‹ báº£n tÃ³m táº¯t (abstract) cÃ¡c bÃ i bÃ¡o Ä‘Ã³ vÃ  Ä‘á» xuáº¥t cÃ´ng trÃ¬nh nghiÃªn cá»©u liÃªn quan. KhÃ´ng chá»‰ váº­y Research Rabbit cÃ²n cho phÃ©p ngÆ°á»i dÃ¹ng chia sáº» cÃ¡c bá»™ sÆ°u táº­p (collections) cho ngÆ°á»i khÃ¡c vÃ  há»— trá»£ viá»‡c trÃ­ch xuáº¥t cÃ¡c tÃ i liá»‡u tham kháº£o má»™t cÃ¡ch dá»… dÃ ng thÃ´ng qua Shareable link vÃ  BibTeX (hÃ¬nh minh há»a). Hy vá»ng bÃ i nÃ y sáº½ giÃºp Ã­ch cho cÃ¡c nhÃ  nghiÃªn cá»©u tÃ¬m kiáº¿m, quáº£n lÃ½ tÃ i liá»‡u tham kháº£o nhanh vÃ  hiá»‡u quáº£ hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng. Nguá»“n tham kháº£o: https://twitter.com/MushtaqBilalPhD/status/1583392303183712256",,,,,
"Hiá»‡n táº¡i em/mÃ¬nh Ä‘ang cáº§n tá»‘i Æ°u hoÃ¡ cho viá»‡c inference model trÃªn CPU. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ share 1 sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c khÃ´ng áº¡. Sá»­ dá»¥ng static, dynamic quantize vÃ  pruning thÃ¬ bá»‹ trade off acc nÃªn e Ä‘Ã£ bá» ra khá»i cÃ¡c option. E cÃ³ Ã½ convert sang jax dÃ¹ng framework flax, tuy nhiÃªn e cÃ³ thá»­ vs 1 máº¡ng neural chá»‰ gá»“m cnn nhá» vÃ  tháº¥y trÃªn cpu tháº­m chÃ­ jax cháº­m hÆ¡n gáº¥p Ä‘Ã´i torch. ÄÆ°a vá» C++ khÃ´ng biáº¿t cÃ³ thá»ƒ giáº£m Ä‘c nhiá»u thá»i gian hÆ¡n khÃ´ng hay cÃ²n cÃ³ cÃ¡c cÃ¡ch khÃ¡c, mong má»i ngÆ°á»i cho thÃªm cao kiáº¿n áº¡.","Hiá»‡n táº¡i em/mÃ¬nh Ä‘ang cáº§n tá»‘i Æ°u hoÃ¡ cho viá»‡c inference model trÃªn CPU. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ share 1 sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c khÃ´ng áº¡. Sá»­ dá»¥ng static, dynamic quantize vÃ  pruning thÃ¬ bá»‹ trade off acc nÃªn e Ä‘Ã£ bá» ra khá»i cÃ¡c option. E cÃ³ Ã½ convert sang jax dÃ¹ng framework flax, tuy nhiÃªn e cÃ³ thá»­ vs 1 máº¡ng neural chá»‰ gá»“m cnn nhá» vÃ  tháº¥y trÃªn cpu tháº­m chÃ­ jax cháº­m hÆ¡n gáº¥p Ä‘Ã´i torch. ÄÆ°a vá» C++ khÃ´ng biáº¿t cÃ³ thá»ƒ giáº£m Ä‘c nhiá»u thá»i gian hÆ¡n khÃ´ng hay cÃ²n cÃ³ cÃ¡c cÃ¡ch khÃ¡c, mong má»i ngÆ°á»i cho thÃªm cao kiáº¿n áº¡.",,,,,
"Xin chÃ o má»i ngÆ°á»i, káº¿t quáº£ 2 teams lá»t vÃ o top2 táº¡m thá»i Ä‘Ã£ cÃ³ cá»§a cÃ¡c cuá»™c thi Zalo Challenge 2022. Tuy chÆ°a biáº¿t score cuá»‘i cÃ¹ng cÅ©ng nhÆ° team nÃ o sáº½ lÃ  team chiáº¿n tháº¯ng chung cuá»™c, hÃ´m nay, mÃ¬nh Ä‘áº¡i diá»‡n cho team Telegram, KHIÃŠU CHIáº¾N team Famers vá» performance cá»§a giáº£i phÃ¡p hai Ä‘á»™i side by side trÃªn táº­p private test bao gá»“m 465 samples.
DÆ°á»›i Ä‘Ã¢y lÃ  káº¿t quáº£ cá»§a mÃ´ hÃ¬nh hai Ä‘á»™i má»i cÃ¡c báº¡n xem qua áº¡. (https://www.youtube.com/watch?v=wcwMFT9QiTc).
Xin cáº£m Æ¡n Zalo vÃ¬ Ä‘Ã£ Ä‘em Ä‘áº¿n má»™t cuá»™c thi thÃº vá»‹ vÃ  ráº¥t thá»±c tiá»…n. Vá»›i káº¿t quáº£ trÃªn cá»§a 2 giáº£i phÃ¡p, mÃ¬nh tin ráº±ng cáº£ 2 giáº£i phÃ¡p Ä‘á»u Ä‘Ã£ Ä‘á»§ tá»‘t Ä‘á»ƒ Ã¡p dá»¥ng cho cÃ¡c bÃ i toÃ¡n thá»±c táº¿.
Náº¿u cÃ¡c báº¡n cÃ³ cÃ¢u há»i hay nháº­n xÃ©t gÃ¬ vá» performance cá»§a cáº£ hai giáº£i phÃ¡p thÃ¬ Ä‘á»«ng ngáº§n ngáº¡i comment phÃ­a dÆ°á»›i áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i ğŸ¥²ğŸ¥²ğŸ¥², chÃºc má»i ngÆ°á»i cÃ³ ngÃ y cuá»‘i tuáº§n vui váº» ğŸ˜ŠğŸ˜ŠğŸ˜Š.
 â€” Ä‘ang cáº£m tháº¥y trá»‘ng váº¯ng cÃ¹ng vá»›i KhÃ¡nh VÅ© Duy vÃ  3 ngÆ°á»i khÃ¡c.","Xin chÃ o má»i ngÆ°á»i, káº¿t quáº£ 2 teams lá»t vÃ o top2 táº¡m thá»i Ä‘Ã£ cÃ³ cá»§a cÃ¡c cuá»™c thi Zalo Challenge 2022. Tuy chÆ°a biáº¿t score cuá»‘i cÃ¹ng cÅ©ng nhÆ° team nÃ o sáº½ lÃ  team chiáº¿n tháº¯ng chung cuá»™c, hÃ´m nay, mÃ¬nh Ä‘áº¡i diá»‡n cho team Telegram, KHIÃŠU CHIáº¾N team Famers vá» performance cá»§a giáº£i phÃ¡p hai Ä‘á»™i side by side trÃªn táº­p private test bao gá»“m 465 samples. DÆ°á»›i Ä‘Ã¢y lÃ  káº¿t quáº£ cá»§a mÃ´ hÃ¬nh hai Ä‘á»™i má»i cÃ¡c báº¡n xem qua áº¡. (https://www.youtube.com/watch?v=wcwMFT9QiTc). Xin cáº£m Æ¡n Zalo vÃ¬ Ä‘Ã£ Ä‘em Ä‘áº¿n má»™t cuá»™c thi thÃº vá»‹ vÃ  ráº¥t thá»±c tiá»…n. Vá»›i káº¿t quáº£ trÃªn cá»§a 2 giáº£i phÃ¡p, mÃ¬nh tin ráº±ng cáº£ 2 giáº£i phÃ¡p Ä‘á»u Ä‘Ã£ Ä‘á»§ tá»‘t Ä‘á»ƒ Ã¡p dá»¥ng cho cÃ¡c bÃ i toÃ¡n thá»±c táº¿. Náº¿u cÃ¡c báº¡n cÃ³ cÃ¢u há»i hay nháº­n xÃ©t gÃ¬ vá» performance cá»§a cáº£ hai giáº£i phÃ¡p thÃ¬ Ä‘á»«ng ngáº§n ngáº¡i comment phÃ­a dÆ°á»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i , chÃºc má»i ngÆ°á»i cÃ³ ngÃ y cuá»‘i tuáº§n vui váº» . â€” Ä‘ang cáº£m tháº¥y trá»‘ng váº¯ng cÃ¹ng vá»›i KhÃ¡nh VÅ© Duy vÃ  3 ngÆ°á»i khÃ¡c.",,,,,
MÃ¬nh Ä‘ang Ä‘á»c vá» PhoBert vÃ  cÃ³ má»™t tháº¯c máº¯c nhá». Khi PhoBert lÃ m viá»‡c vá»›i Tiáº¿ng Viá»‡t cÃ³ dáº¥u vÃ  khÃ´ng dáº¥u thÃ¬ hiá»‡u quáº£ cÃ³ khÃ¡c nhau nhiá»u khÃ´ng? MÃ¬nh Ä‘á»c paper cá»§a PhoBert thÃ¬ khÃ´ng tháº¥y nháº¯c Ä‘áº¿n táº­p dá»¯ liá»‡u TV khÃ´ng dáº¥u. KhÃ´ng biáº¿t báº¡n nÃ o review váº¥n Ä‘á» nÃ y chÆ°a.,MÃ¬nh Ä‘ang Ä‘á»c vá» PhoBert vÃ  cÃ³ má»™t tháº¯c máº¯c nhá». Khi PhoBert lÃ m viá»‡c vá»›i Tiáº¿ng Viá»‡t cÃ³ dáº¥u vÃ  khÃ´ng dáº¥u thÃ¬ hiá»‡u quáº£ cÃ³ khÃ¡c nhau nhiá»u khÃ´ng? MÃ¬nh Ä‘á»c paper cá»§a PhoBert thÃ¬ khÃ´ng tháº¥y nháº¯c Ä‘áº¿n táº­p dá»¯ liá»‡u TV khÃ´ng dáº¥u. KhÃ´ng biáº¿t báº¡n nÃ o review váº¥n Ä‘á» nÃ y chÆ°a.,,,,,
"Hi cÃ¡c báº¡n,
Láº§n nÃ y, thay vÃ¬ dÃ¹ng AI Ä‘á»ƒ há»— trá»£ chÆ¡i game qua cá»­ chá»‰ tay hoáº·c khuÃ´n máº·t, mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n 1 mÃ´ hÃ¬nh AI Ä‘á»ƒ cÃ³ thá»ƒ tá»± chÆ¡i game mÃ  khÃ´ng cáº§n con ngÆ°á»i can thiá»‡p. Cá»¥ thá»ƒ, mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n AI vá»›i thuáº­t toÃ¡n Deep Q-learning trong 2 triá»‡u vÃ²ng láº·p vá»›i tá»±a game Flappy Bird, vÃ  káº¿t quáº£ lÃ  AI cá»§a mÃ¬nh cÃ³ thá»ƒ chÆ¡i game mÃ£i mÃ£i mÃ  khÃ´ng cháº¿t bao giá». CÃ¡c báº¡n cÃ³ thá»ƒ tá»± kiá»ƒm chá»©ng vá»›i source code cá»§a mÃ¬nh. Cháº¡y chÆ°Æ¡ng trÃ¬nh, xong Ä‘i ngá»§, sÃ¡ng hÃ´m sau dáº­y báº¡n váº«n sáº½ tháº¥y AI Ä‘ang chÆ¡i game ğŸ˜ğŸ˜ğŸ˜
Qua video nÃ y, mÃ¬nh muá»‘n hÆ°á»›ng dáº«n cÃ¡c báº¡n nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n nháº¥t vá» Reinforcement learning (há»c tÄƒng cÆ°á»ng) cÃ¹ng vá»›i 1 trong nhá»¯ng thuáº­t toÃ¡n cÆ¡ báº£n nháº¥t cá»§a máº£ng nÃ y - Deep Q-learning. Há»c tÄƒng cÆ°á»ng Ã­t phá»• biáº¿n hÆ¡n 2 máº£ng cÃ²n láº¡i cá»§a há»c mÃ¡y, nhÆ°ng nhá»¯ng á»©ng dá»¥ng cá»§a máº£ng nÃ y thÃº vá»‹ khÃ´ng há» kÃ©m cáº¡nh Ä‘Ã¢u nhÃ© ğŸ¤©

I hope you enjoy it!
Full video: https://youtu.be/hGO0ztpA19g

#ReinforcementLearning #flappybird","Hi cÃ¡c báº¡n, Láº§n nÃ y, thay vÃ¬ dÃ¹ng AI Ä‘á»ƒ há»— trá»£ chÆ¡i game qua cá»­ chá»‰ tay hoáº·c khuÃ´n máº·t, mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n 1 mÃ´ hÃ¬nh AI Ä‘á»ƒ cÃ³ thá»ƒ tá»± chÆ¡i game mÃ  khÃ´ng cáº§n con ngÆ°á»i can thiá»‡p. Cá»¥ thá»ƒ, mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n AI vá»›i thuáº­t toÃ¡n Deep Q-learning trong 2 triá»‡u vÃ²ng láº·p vá»›i tá»±a game Flappy Bird, vÃ  káº¿t quáº£ lÃ  AI cá»§a mÃ¬nh cÃ³ thá»ƒ chÆ¡i game mÃ£i mÃ£i mÃ  khÃ´ng cháº¿t bao giá». CÃ¡c báº¡n cÃ³ thá»ƒ tá»± kiá»ƒm chá»©ng vá»›i source code cá»§a mÃ¬nh. Cháº¡y chÆ°Æ¡ng trÃ¬nh, xong Ä‘i ngá»§, sÃ¡ng hÃ´m sau dáº­y báº¡n váº«n sáº½ tháº¥y AI Ä‘ang chÆ¡i game Qua video nÃ y, mÃ¬nh muá»‘n hÆ°á»›ng dáº«n cÃ¡c báº¡n nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n nháº¥t vá» Reinforcement learning (há»c tÄƒng cÆ°á»ng) cÃ¹ng vá»›i 1 trong nhá»¯ng thuáº­t toÃ¡n cÆ¡ báº£n nháº¥t cá»§a máº£ng nÃ y - Deep Q-learning. Há»c tÄƒng cÆ°á»ng Ã­t phá»• biáº¿n hÆ¡n 2 máº£ng cÃ²n láº¡i cá»§a há»c mÃ¡y, nhÆ°ng nhá»¯ng á»©ng dá»¥ng cá»§a máº£ng nÃ y thÃº vá»‹ khÃ´ng há» kÃ©m cáº¡nh Ä‘Ã¢u nhÃ© I hope you enjoy it! Full video: https://youtu.be/hGO0ztpA19g",#ReinforcementLearning	#flappybird,,,,
"Khai phÃ¡ dá»¯ liá»‡u quyáº¿t Ä‘á»‹nh chi Äƒn nhÃ  hÃ ng. Vá»›i bÃ i nÃ y nÃªn dÃ¹ng há»“i quy, phÃ¢n lá»›p hay cÃ¢y quyáº¿t Ä‘á»‹nh áº¡.","Khai phÃ¡ dá»¯ liá»‡u quyáº¿t Ä‘á»‹nh chi Äƒn nhÃ  hÃ ng. Vá»›i bÃ i nÃ y nÃªn dÃ¹ng há»“i quy, phÃ¢n lá»›p hay cÃ¢y quyáº¿t Ä‘á»‹nh áº¡.",,,,,
"[ChatGPT: Optimizing Language Models for Dialogue]

Gáº§n Ä‘Ã¢y OpenAI cho ra máº¯t mÃ´ hÃ¬nh ChatGPT, giÃºp ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c AI theo hÃ¬nh thá»©c Chatbot. ChatGPT cÃ³ thá»ƒ hiá»ƒu ná»™i dung cuá»™c nÃ³i chuyá»‡n vÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng. Kháº£ nÄƒng giao tiáº¿p vÃ  tráº£ lá»i cá»§a ChatGPT cÃ³ thá»ƒ sáº½ khiáº¿n má»i ngÆ°á»i ngáº¡c nhiÃªn: tá»« viáº¿t code, viáº¿t latex, Ä‘áº¿n viáº¿t truyá»‡n, viáº¿t vÄƒn, lÃ m assignment,....

Chi tiáº¿t á»Ÿ Ä‘Ã¢y: https://openai.com/blog/chatgpt/
Demo: https://chat.openai.com/","[ChatGPT: Optimizing Language Models for Dialogue] Gáº§n Ä‘Ã¢y OpenAI cho ra máº¯t mÃ´ hÃ¬nh ChatGPT, giÃºp ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c AI theo hÃ¬nh thá»©c Chatbot. ChatGPT cÃ³ thá»ƒ hiá»ƒu ná»™i dung cuá»™c nÃ³i chuyá»‡n vÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng. Kháº£ nÄƒng giao tiáº¿p vÃ  tráº£ lá»i cá»§a ChatGPT cÃ³ thá»ƒ sáº½ khiáº¿n má»i ngÆ°á»i ngáº¡c nhiÃªn: tá»« viáº¿t code, viáº¿t latex, Ä‘áº¿n viáº¿t truyá»‡n, viáº¿t vÄƒn, lÃ m assignment,.... Chi tiáº¿t á»Ÿ Ä‘Ã¢y: https://openai.com/blog/chatgpt/ Demo: https://chat.openai.com/",,,,,
"ChÃ o má»i ngÆ°á»i, Ä‘áº¡i diá»‡n nhÃ³m Shadow chicken sua gau gau (Liveness detection track, Zalo AI Challenge 2022, top 6 private test) mÃ¬nh xin phÃ©p chia sáº» solution cá»§a nhÃ³m:
-  Sau quÃ¡ trÃ¬nh experiment, nhÃ³m mÃ¬nh phÃ¡t hiá»‡n ra RandomResizedCrop tá»‘t cho táº­p dá»¯ liá»‡u public test 2, kÃ­ch thÆ°á»›c áº£nh nhá» hÆ¡n thÃ¬ bá»›t overfit hÆ¡n trÃªn táº­p public test 2, kÃ­ch thÆ°á»›c áº£nh to hÆ¡n thÃ¬ Ä‘áº¡t Ä‘iá»ƒm CV cao hÆ¡n, nÃªn nhÃ³m mÃ¬nh quyáº¿t Ä‘á»‹nh ensemble Ä‘a dáº¡ng kÃ­ch thÆ°á»›c áº£nh. NgoÃ i ra nhÃ³m mÃ¬nh sá»­ dá»¥ng thÃªm cutout vÃ  mixup data augmentation. Optimizer sá»­ dá»¥ng lÃ  ADAN. Lá»±a chá»n model dá»±a vÃ o accuracy metric. Táº­p pub 1 thÃ¬ cÃ²n tháº¥y nhiá»…u vÃ¢n, táº­p pub 2 thÃ¬ nhÃ¬n má»i máº¯t cháº³ng tháº¥y cÃ¡i nÃ o. náº¿u ban tá»• chá»©c cho phÃ©p pseudo label thÃ¬ tá»‘t, káº¿t quáº£ sá»­ dá»¥ng model train báº±ng pseudo pub1 Ä‘áº¡t Ä‘iá»ƒm cao hÆ¡n trÃªn pub 2. Sá»­ dá»¥ng toÃ n bá»™ bá»©c áº£nh Ä‘á»ƒ training thay vÃ¬ chá»‰ crop khuÃ´n máº·t. Má»—i epoch, má»—i video láº¥y ra ngáº«u nhiÃªn 1 frame Ä‘á»ƒ training. Eval báº±ng cÃ¡ch má»—i video láº¥y ra 5 frames cÃ¡ch Ä‘á»u nhau, sau Ä‘Ã³ voting.
-  Káº¿t quáº£ trÃªn leaderboard2 (0.00855) lÃ  ensemble cá»§a 5 loáº¡i  model, má»—i loáº¡i 5 fold, bao gá»“m:
convnext_base_384_in22ft1k, train image size   384, test image size 448, sá»­ dá»¥ng áº£nh  YCBCB Ä‘á»ƒ training
convnext_base_in22ft1k, train image size   224, test image size 288, áº£nh RGB
swin_large_patch4_window12_384_in22k, train   image size 384, test image size 384, áº£nh RGB, model nÃ y Ä‘áº¡t   CV cao nháº¥t.
swin_large_patch4_window7_224_in22k,  train   image size 224, test image size 224, áº£nh RGB. Sá»­ dá»¥ng yolov7   Ä‘á»ƒ detect máº·t, sau Ä‘Ã³ sá»­ dá»¥ng box khuÃ´n máº·t Ä‘á»ƒ   random che Ä‘i khuÃ´n máº·t khi training, vÃ¬ cÃ³ nhiá»u diá»…n   viÃªn xuáº¥t hiá»‡n trong cáº£ táº­p training vÃ  public test 1,   public test 2, vÃ  xuáº¥t hiá»‡n á»Ÿ cáº£ trong nhiá»u video, nÃªn   muá»‘n che Ä‘i khuÃ´n máº·t Ä‘á»ƒ model khÃ´ng nhá»› khuÃ´n máº·t   cá»§a diá»…n viÃªn.
efficientnet B5, train image size 512, test   image size 618, áº£nh BGR. Model nÃ y dá»± Ä‘oÃ¡n áº£nh real ráº¥t   tá»‘t.
TTA 3 láº§n, bao gá»“m áº£nh gá»‘c, áº£nh   hlip, áº£nh vlip. Lá»±a chá»n ra 11 frame cÃ¡ch Ä‘á»u nhau tá»«   video Ä‘á»ƒ voting, do nhÃ³m mÃ¬nh quan sÃ¡t tháº¥y cÃ³ má»™t sá»‘   video káº¿t quáº£ inference xuáº¥t hiá»‡n cáº£ Ä‘oáº¡n real vÃ    fake xen káº½ nhau.
- Káº¿t quáº£ trÃªn private test (0.06373), do  ban Ä‘áº§u khÃ´ng Ä‘á»ƒ Ã½ Ä‘áº¿n time constraint â€œThe minimum  accepted running speed is real time. If the total inference time is  longer than the total length of videos, the result will not be  evaluated.â€ , nÃªn nhÃ³m mÃ¬nh chá»‰ táº­p trung vÃ o tá»‘i Æ°u  hÃ³a metric eer, Ä‘áº¿n thá»© 7 sÃ¡t ngÃ y ná»™p má»›i biáº¿t vá»  time constraint. VÃ¬ váº­y, káº¿t quáº£ submit chá»‰ cÃ²n lÃ  ensemble cá»§a 4  model (Trá»« Ä‘i efficientnet B5), tá»•ng cá»™ng 20 weights, láº¥y  ra 8 frame tá»« má»—i video sau Ä‘Ã³ vlip 4 frame, tá»•ng cá»™ng má»—i  video pháº£i inference 12 áº£nh. Quantize táº¥t cáº£ weight model  xuá»‘ng float16. Ensemble cá»§a 4 loáº¡i model (20 weights) Ä‘áº¡t  Public 2 test eer score  = 0.019, sau khi quantize thÃ¬ eer giáº£m  xuá»‘ng cÃ²n 0.02137
- Báº¥t ngá» khi táº£i xuá»‘ng táº­p private  test, nhÃ³m mÃ¬nh nháº­n ra nhiá»u diá»…n viÃªn xuáº¥t hiá»‡n trong  private test xuáº¥t hiá»‡n trong cáº£ training dataset vÃ  pub 1,  pub 2. Náº¿u muá»‘n Ä‘Ã¡nh giÃ¡ tá»‘t hÆ¡n, nhÃ³m mÃ¬nh nghÄ© nÃªn  lÆ°u láº¡i id cá»§a diá»…n viÃªn vÃ  trÃ¡nh viá»‡c má»™t diá»…n viÃªn  xuáº¥t hiá»‡n trong cáº£ táº­p train vÃ  táº­p test.
- Má»™t sá»‘ hÆ°á»›ng Ä‘ang thá»­ nhÆ°ng chÆ°a thÃ nh cÃ´ng, DeePixBiS, arcface, stack cÃ¡c frame trong video theo chiá»u channel thÃ nh áº£nh 2.5D nhÆ°ng train khÃ´ng há»™i tá»¥, sá»­ dá»¥ng pyslowfast káº¿t quáº£ Ä‘áº¡t accuracy kháº£ quan (HÆ°á»›ng nÃ y cÃ³ nhiá»u tiá»m nÄƒng, do chÆ°a tunning mÃ  accuracy Ä‘Ã£ xáº¥p xá»‰ 96, 97%, model sá»­ dá»¥ng lÃ  X3D) nhÆ°ng nhÃ³m khÃ´ng theo hÆ°á»›ng giáº£i phÃ¡p nÃ y do khÃ´ng cÃ³ thá»i gian Ä‘á»ƒ tunning mÃ´ hÃ¬nh.
- Training source code public táº¡i:  https://github.com/VTCC-uTVM/Zalo-AI-Challenge-2022-Liveness-Detection
 â€” vá»›i Tráº§n Máº¡nh TÃ¹ng vÃ  Nguyá»…n VÄƒn PhÃºc.","ChÃ o má»i ngÆ°á»i, Ä‘áº¡i diá»‡n nhÃ³m Shadow chicken sua gau gau (Liveness detection track, Zalo AI Challenge 2022, top 6 private test) mÃ¬nh xin phÃ©p chia sáº» solution cá»§a nhÃ³m: - Sau quÃ¡ trÃ¬nh experiment, nhÃ³m mÃ¬nh phÃ¡t hiá»‡n ra RandomResizedCrop tá»‘t cho táº­p dá»¯ liá»‡u public test 2, kÃ­ch thÆ°á»›c áº£nh nhá» hÆ¡n thÃ¬ bá»›t overfit hÆ¡n trÃªn táº­p public test 2, kÃ­ch thÆ°á»›c áº£nh to hÆ¡n thÃ¬ Ä‘áº¡t Ä‘iá»ƒm CV cao hÆ¡n, nÃªn nhÃ³m mÃ¬nh quyáº¿t Ä‘á»‹nh ensemble Ä‘a dáº¡ng kÃ­ch thÆ°á»›c áº£nh. NgoÃ i ra nhÃ³m mÃ¬nh sá»­ dá»¥ng thÃªm cutout vÃ  mixup data augmentation. Optimizer sá»­ dá»¥ng lÃ  ADAN. Lá»±a chá»n model dá»±a vÃ o accuracy metric. Táº­p pub 1 thÃ¬ cÃ²n tháº¥y nhiá»…u vÃ¢n, táº­p pub 2 thÃ¬ nhÃ¬n má»i máº¯t cháº³ng tháº¥y cÃ¡i nÃ o. náº¿u ban tá»• chá»©c cho phÃ©p pseudo label thÃ¬ tá»‘t, káº¿t quáº£ sá»­ dá»¥ng model train báº±ng pseudo pub1 Ä‘áº¡t Ä‘iá»ƒm cao hÆ¡n trÃªn pub 2. Sá»­ dá»¥ng toÃ n bá»™ bá»©c áº£nh Ä‘á»ƒ training thay vÃ¬ chá»‰ crop khuÃ´n máº·t. Má»—i epoch, má»—i video láº¥y ra ngáº«u nhiÃªn 1 frame Ä‘á»ƒ training. Eval báº±ng cÃ¡ch má»—i video láº¥y ra 5 frames cÃ¡ch Ä‘á»u nhau, sau Ä‘Ã³ voting. - Káº¿t quáº£ trÃªn leaderboard2 (0.00855) lÃ  ensemble cá»§a 5 loáº¡i model, má»—i loáº¡i 5 fold, bao gá»“m: convnext_base_384_in22ft1k, train image size 384, test image size 448, sá»­ dá»¥ng áº£nh YCBCB Ä‘á»ƒ training convnext_base_in22ft1k, train image size 224, test image size 288, áº£nh RGB swin_large_patch4_window12_384_in22k, train image size 384, test image size 384, áº£nh RGB, model nÃ y Ä‘áº¡t CV cao nháº¥t. swin_large_patch4_window7_224_in22k, train image size 224, test image size 224, áº£nh RGB. Sá»­ dá»¥ng yolov7 Ä‘á»ƒ detect máº·t, sau Ä‘Ã³ sá»­ dá»¥ng box khuÃ´n máº·t Ä‘á»ƒ random che Ä‘i khuÃ´n máº·t khi training, vÃ¬ cÃ³ nhiá»u diá»…n viÃªn xuáº¥t hiá»‡n trong cáº£ táº­p training vÃ  public test 1, public test 2, vÃ  xuáº¥t hiá»‡n á»Ÿ cáº£ trong nhiá»u video, nÃªn muá»‘n che Ä‘i khuÃ´n máº·t Ä‘á»ƒ model khÃ´ng nhá»› khuÃ´n máº·t cá»§a diá»…n viÃªn. efficientnet B5, train image size 512, test image size 618, áº£nh BGR. Model nÃ y dá»± Ä‘oÃ¡n áº£nh real ráº¥t tá»‘t. TTA 3 láº§n, bao gá»“m áº£nh gá»‘c, áº£nh hlip, áº£nh vlip. Lá»±a chá»n ra 11 frame cÃ¡ch Ä‘á»u nhau tá»« video Ä‘á»ƒ voting, do nhÃ³m mÃ¬nh quan sÃ¡t tháº¥y cÃ³ má»™t sá»‘ video káº¿t quáº£ inference xuáº¥t hiá»‡n cáº£ Ä‘oáº¡n real vÃ  fake xen káº½ nhau. - Káº¿t quáº£ trÃªn private test (0.06373), do ban Ä‘áº§u khÃ´ng Ä‘á»ƒ Ã½ Ä‘áº¿n time constraint â€œThe minimum accepted running speed is real time. If the total inference time is longer than the total length of videos, the result will not be evaluated.â€ , nÃªn nhÃ³m mÃ¬nh chá»‰ táº­p trung vÃ o tá»‘i Æ°u hÃ³a metric eer, Ä‘áº¿n thá»© 7 sÃ¡t ngÃ y ná»™p má»›i biáº¿t vá» time constraint. VÃ¬ váº­y, káº¿t quáº£ submit chá»‰ cÃ²n lÃ  ensemble cá»§a 4 model (Trá»« Ä‘i efficientnet B5), tá»•ng cá»™ng 20 weights, láº¥y ra 8 frame tá»« má»—i video sau Ä‘Ã³ vlip 4 frame, tá»•ng cá»™ng má»—i video pháº£i inference 12 áº£nh. Quantize táº¥t cáº£ weight model xuá»‘ng float16. Ensemble cá»§a 4 loáº¡i model (20 weights) Ä‘áº¡t Public 2 test eer score = 0.019, sau khi quantize thÃ¬ eer giáº£m xuá»‘ng cÃ²n 0.02137 - Báº¥t ngá» khi táº£i xuá»‘ng táº­p private test, nhÃ³m mÃ¬nh nháº­n ra nhiá»u diá»…n viÃªn xuáº¥t hiá»‡n trong private test xuáº¥t hiá»‡n trong cáº£ training dataset vÃ  pub 1, pub 2. Náº¿u muá»‘n Ä‘Ã¡nh giÃ¡ tá»‘t hÆ¡n, nhÃ³m mÃ¬nh nghÄ© nÃªn lÆ°u láº¡i id cá»§a diá»…n viÃªn vÃ  trÃ¡nh viá»‡c má»™t diá»…n viÃªn xuáº¥t hiá»‡n trong cáº£ táº­p train vÃ  táº­p test. - Má»™t sá»‘ hÆ°á»›ng Ä‘ang thá»­ nhÆ°ng chÆ°a thÃ nh cÃ´ng, DeePixBiS, arcface, stack cÃ¡c frame trong video theo chiá»u channel thÃ nh áº£nh 2.5D nhÆ°ng train khÃ´ng há»™i tá»¥, sá»­ dá»¥ng pyslowfast káº¿t quáº£ Ä‘áº¡t accuracy kháº£ quan (HÆ°á»›ng nÃ y cÃ³ nhiá»u tiá»m nÄƒng, do chÆ°a tunning mÃ  accuracy Ä‘Ã£ xáº¥p xá»‰ 96, 97%, model sá»­ dá»¥ng lÃ  X3D) nhÆ°ng nhÃ³m khÃ´ng theo hÆ°á»›ng giáº£i phÃ¡p nÃ y do khÃ´ng cÃ³ thá»i gian Ä‘á»ƒ tunning mÃ´ hÃ¬nh. - Training source code public táº¡i: https://github.com/VTCC-uTVM/Zalo-AI-Challenge-2022-Liveness-Detection â€” vá»›i Tráº§n Máº¡nh TÃ¹ng vÃ  Nguyá»…n VÄƒn PhÃºc.",,,,,
"Má»™t thÆ° viá»‡n khÃ¡ hay, x400 nhanh hÆ¡n weka (: :)
https://github.com/mikeizbicki/HLearn","Má»™t thÆ° viá»‡n khÃ¡ hay, x400 nhanh hÆ¡n weka (: :) https://github.com/mikeizbicki/HLearn",,,,,
"Má»i ngÆ°á»i cho em há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng gpu vá»›i mediapipe váº­y áº¡. Máº·c dÃ¹ mÃ¡y tÃ­nh cá»§a em cÃ³ sá»­ dá»¥ng gpu rtx 2070 vÃ  Ä‘Ã£ cÃ i Ä‘áº§y Ä‘á»§ CUDA CUDnn tuy nhiÃªn khi em sá»­ dá»¥ng mediapipe vÃ  kiá»ƒm tra gpu thÃ¬ chá»‰ tháº¥y gpu hoáº¡t Ä‘á»™ng 5% Ä‘á»“ng thá»i nÃ³ hiá»‡n lÃªn thÃ´ng bÃ¡o"" INFO: Created TensorFlow Lite XNNPACK delegate for CPU"" trong quÃ¡ trÃ¬nh nháº­n dáº¡ng. Mong má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em kháº¯c phá»¥c nÃ³, em cáº£m Æ¡n áº¡.","Má»i ngÆ°á»i cho em há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng gpu vá»›i mediapipe váº­y áº¡. Máº·c dÃ¹ mÃ¡y tÃ­nh cá»§a em cÃ³ sá»­ dá»¥ng gpu rtx 2070 vÃ  Ä‘Ã£ cÃ i Ä‘áº§y Ä‘á»§ CUDA CUDnn tuy nhiÃªn khi em sá»­ dá»¥ng mediapipe vÃ  kiá»ƒm tra gpu thÃ¬ chá»‰ tháº¥y gpu hoáº¡t Ä‘á»™ng 5% Ä‘á»“ng thá»i nÃ³ hiá»‡n lÃªn thÃ´ng bÃ¡o"" INFO: Created TensorFlow Lite XNNPACK delegate for CPU"" trong quÃ¡ trÃ¬nh nháº­n dáº¡ng. Mong má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em kháº¯c phá»¥c nÃ³, em cáº£m Æ¡n áº¡.",,,,,
"Náº¿u má»i ngÆ°á»i quan tÃ¢m Ä‘áº¿n AI vÃ  tech thÃ¬ khÃ´ng nÃªn bá» qua sá»± kiá»‡n Zalo AI Summit 2022 - diá»…n Ä‘Ã n cÃ´ng nghá»‡ do Zalo tá»• chá»©c má»—i nÄƒm.
ÄÃ¢y lÃ  dá»‹p Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ nghe nhá»¯ng chuyÃªn gia chia sáº» vá» nhá»¯ng sáº£n pháº©m, bÃ i toÃ¡n cÃ´ng nghá»‡ má»›i; chiÃªm ngÆ°á»¡ng nhá»¯ng sáº£n pháº©m láº§n Ä‘áº§u trÃ¬nh lÃ ng; giao lÆ°u vá»›i cá»™ng Ä‘á»“ng Ä‘am mÃª AI vÃ  tech
Má»i nÄƒm, Zalo AiI Summit chá»‰ dÃ nh cho cÃ¡c ká»¹ sÆ° Zalo, nhÆ°ng nÄƒm nay thÃ¬ má»Ÿ cá»­a cho nhá»¯ng ai quan tÃ¢m Ä‘áº¿n lÄ©nh vá»±c nÃ y. Váº­y nÃªn má»i ngÆ°á»i Ä‘Äƒng kÃ­ tham gia thÃ´ng qua website náº¿u cÃ³ há»©ng thÃº nhÃ©!
https://summit.zalo.ai/","Náº¿u má»i ngÆ°á»i quan tÃ¢m Ä‘áº¿n AI vÃ  tech thÃ¬ khÃ´ng nÃªn bá» qua sá»± kiá»‡n Zalo AI Summit 2022 - diá»…n Ä‘Ã n cÃ´ng nghá»‡ do Zalo tá»• chá»©c má»—i nÄƒm. ÄÃ¢y lÃ  dá»‹p Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ nghe nhá»¯ng chuyÃªn gia chia sáº» vá» nhá»¯ng sáº£n pháº©m, bÃ i toÃ¡n cÃ´ng nghá»‡ má»›i; chiÃªm ngÆ°á»¡ng nhá»¯ng sáº£n pháº©m láº§n Ä‘áº§u trÃ¬nh lÃ ng; giao lÆ°u vá»›i cá»™ng Ä‘á»“ng Ä‘am mÃª AI vÃ  tech Má»i nÄƒm, Zalo AiI Summit chá»‰ dÃ nh cho cÃ¡c ká»¹ sÆ° Zalo, nhÆ°ng nÄƒm nay thÃ¬ má»Ÿ cá»­a cho nhá»¯ng ai quan tÃ¢m Ä‘áº¿n lÄ©nh vá»±c nÃ y. Váº­y nÃªn má»i ngÆ°á»i Ä‘Äƒng kÃ­ tham gia thÃ´ng qua website náº¿u cÃ³ há»©ng thÃº nhÃ©! https://summit.zalo.ai/",,,,,
"CÃ¡c báº¡n cho há»i (theo kinh nghiá»‡m cÃ¡ nhÃ¢n), kiáº¿n trÃºc model (cho chá»§ Ä‘á» #objectdetection) nÃ o cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n chÃ­nh xÃ¡c nhiá»u váº­t thá»ƒ nhá» nháº¥t trong má»—i khung hÃ¬nh? Xin cáº£m Æ¡n cÃ¡c báº¡n trÆ°á»›c nhÃ©!","CÃ¡c báº¡n cho há»i (theo kinh nghiá»‡m cÃ¡ nhÃ¢n), kiáº¿n trÃºc model (cho chá»§ Ä‘á» nÃ o cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n chÃ­nh xÃ¡c nhiá»u váº­t thá»ƒ nhá» nháº¥t trong má»—i khung hÃ¬nh? Xin cáº£m Æ¡n cÃ¡c báº¡n trÆ°á»›c nhÃ©!",#objectdetection),,,,
"ChÃ o má»i ngÆ°á»i, trÆ°á»›c tiÃªn mÃ¬nh muá»‘n chÃºc má»«ng cÃ¡c team cá»§a cuá»™c thi Zalo AI 2022 Ä‘Ã£ hoÃ n thÃ nh cuá»™c thi vÃ  cÃ³ nhá»¯ng káº¿t quáº£ háº¿t sá»©c áº¥n tÆ°á»£ng. NÄƒm nay mÃ¬nh tham gia cuá»™c thi dÆ°á»›i danh nghÄ©a team New Dad tranh tÃ i á»Ÿ task Lyric Alignment. New Dad cÃ³ may máº¯n Ä‘á»©ng nháº¥t á»Ÿ public leaderboard tuy nhiÃªn á»Ÿ private leaderboard thÃ¬ chá»‰ Ä‘á»©ng á»Ÿ vá»‹ trÃ­ thá»© 7. Tuy váº­y mÃ¬nh váº«n muá»‘n chia sáº» giáº£i phÃ¡p mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng vÃ  public source code cÃ¹ng data, hi vá»ng cÃ³ thá»ƒ giÃºp Ã­ch cho má»i ngÆ°á»i. TÃ³m táº¯t thÃ¬ hÆ°á»›ng tiáº¿p cáº­n cá»§a mÃ¬nh bao gá»“m:
- Xá»­ lÃ½ lyric dáº¡ng viáº¿t sang dáº¡ng nÃ³i (sá»‘, ngÃ y thÃ¡ng, tá»« ngoáº¡i lai).
- Crawl data 30.000 bÃ i hÃ¡t ~ 1500h audio music (nhÃ¬n chung mÃ¬nh khÃ´ng sá»­ dá»¥ng data cá»§a BTC Ä‘á»ƒ train model).
- Finetune ASR model cho music audio.
- Audio & lyric align sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p CTC force alignment.
Chi tiáº¿t code finetune, infer vÃ  align má»i ngÆ°á»i xem theo link github: https://github.com/nguyenvulebinh/lyric-alignment
1500h data music & lyric: https://huggingface.co/datasets/nguyenvulebinh/song_dataset","ChÃ o má»i ngÆ°á»i, trÆ°á»›c tiÃªn mÃ¬nh muá»‘n chÃºc má»«ng cÃ¡c team cá»§a cuá»™c thi Zalo AI 2022 Ä‘Ã£ hoÃ n thÃ nh cuá»™c thi vÃ  cÃ³ nhá»¯ng káº¿t quáº£ háº¿t sá»©c áº¥n tÆ°á»£ng. NÄƒm nay mÃ¬nh tham gia cuá»™c thi dÆ°á»›i danh nghÄ©a team New Dad tranh tÃ i á»Ÿ task Lyric Alignment. New Dad cÃ³ may máº¯n Ä‘á»©ng nháº¥t á»Ÿ public leaderboard tuy nhiÃªn á»Ÿ private leaderboard thÃ¬ chá»‰ Ä‘á»©ng á»Ÿ vá»‹ trÃ­ thá»© 7. Tuy váº­y mÃ¬nh váº«n muá»‘n chia sáº» giáº£i phÃ¡p mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng vÃ  public source code cÃ¹ng data, hi vá»ng cÃ³ thá»ƒ giÃºp Ã­ch cho má»i ngÆ°á»i. TÃ³m táº¯t thÃ¬ hÆ°á»›ng tiáº¿p cáº­n cá»§a mÃ¬nh bao gá»“m: - Xá»­ lÃ½ lyric dáº¡ng viáº¿t sang dáº¡ng nÃ³i (sá»‘, ngÃ y thÃ¡ng, tá»« ngoáº¡i lai). - Crawl data 30.000 bÃ i hÃ¡t ~ 1500h audio music (nhÃ¬n chung mÃ¬nh khÃ´ng sá»­ dá»¥ng data cá»§a BTC Ä‘á»ƒ train model). - Finetune ASR model cho music audio. - Audio & lyric align sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p CTC force alignment. Chi tiáº¿t code finetune, infer vÃ  align má»i ngÆ°á»i xem theo link github: https://github.com/nguyenvulebinh/lyric-alignment 1500h data music & lyric: https://huggingface.co/datasets/nguyenvulebinh/song_dataset",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2022 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2022 vÃ o comment cá»§a post nÃ y.",,,,,
TÃ¡ch nhanh mp3 tá»« video vá»›i Python ğŸ˜Š,TÃ¡ch nhanh mp3 tá»« video vá»›i Python,,,,,
"Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t bÃ i bÃ¡o xuáº¥t sáº¯c tá»« Dr. Michael A. Lones, Ä‘Æ°á»£c viáº¿t ráº¥t dá»… hiá»ƒu vá» cÃ¡ch Ä‘á»ƒ trÃ¡nh nhá»¯ng cáº¡m báº«y trong Machine Learning. BÃ i bÃ¡o Ä‘Æ°á»£c trÃ¬nh bÃ y ráº¥t trá»±c quan dÆ°á»›i dáº¡ng Do and Don't.
Äá»‘i vá»›i cÃ¡c tiá»n bá»‘i thÃ¬ nhá»¯ng Ä‘iá»u trong nÃ y cháº¯c cháº¯n lÃ  Ä‘Ã£ náº±m lÃ²ng, nhÆ°ng Ä‘á»‘i vá»›i cÃ¡c báº¡n má»›i tiáº¿p cáº­n ML hay nhá»¯ng nhÃ  nghiÃªn cá»©u á»Ÿ lÄ©nh vá»±c khÃ¡c thÃ¬ bÃ i bÃ¡o nÃ y ráº¥t há»¯u Ã­ch, giÃºp cho cÃ¡c báº¡n lÃ£nh há»™i ngay Ã­t nháº¥t 6 thÃ¡ng-1 nÄƒm kinh nghiá»‡m vÃ  trÃ¡nh lÃ£ng phÃ­ vÃ i trÄƒm giá» train model khÃ´ng hiá»‡u quáº£.
Link bÃ i bÃ¡o:
https://arxiv.org/abs/2108.02497","Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t bÃ i bÃ¡o xuáº¥t sáº¯c tá»« Dr. Michael A. Lones, Ä‘Æ°á»£c viáº¿t ráº¥t dá»… hiá»ƒu vá» cÃ¡ch Ä‘á»ƒ trÃ¡nh nhá»¯ng cáº¡m báº«y trong Machine Learning. BÃ i bÃ¡o Ä‘Æ°á»£c trÃ¬nh bÃ y ráº¥t trá»±c quan dÆ°á»›i dáº¡ng Do and Don't. Äá»‘i vá»›i cÃ¡c tiá»n bá»‘i thÃ¬ nhá»¯ng Ä‘iá»u trong nÃ y cháº¯c cháº¯n lÃ  Ä‘Ã£ náº±m lÃ²ng, nhÆ°ng Ä‘á»‘i vá»›i cÃ¡c báº¡n má»›i tiáº¿p cáº­n ML hay nhá»¯ng nhÃ  nghiÃªn cá»©u á»Ÿ lÄ©nh vá»±c khÃ¡c thÃ¬ bÃ i bÃ¡o nÃ y ráº¥t há»¯u Ã­ch, giÃºp cho cÃ¡c báº¡n lÃ£nh há»™i ngay Ã­t nháº¥t 6 thÃ¡ng-1 nÄƒm kinh nghiá»‡m vÃ  trÃ¡nh lÃ£ng phÃ­ vÃ i trÄƒm giá» train model khÃ´ng hiá»‡u quáº£. Link bÃ i bÃ¡o: https://arxiv.org/abs/2108.02497",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c!
ÄÃºng lá»i há»©a chia sáº» cÃ¹ng anh em má»™t bÃ i vá» Äá»‹nh giÃ¡ SIM sá»‘. Dáº¡y mÃ¡y tÃ­nh lÃ m tháº§y SIM Sá» nÃ o :D
BÃ i nÃ y Ã¡p dá»¥ng nhiá»u vá» LSTM vÃ  xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº§u vÃ o nhÃ©!
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c!",KÃ­nh chÃ o cÃ¡c bÃ¡c! ÄÃºng lá»i há»©a chia sáº» cÃ¹ng anh em má»™t bÃ i vá» Äá»‹nh giÃ¡ SIM sá»‘. Dáº¡y mÃ¡y tÃ­nh lÃ m tháº§y SIM Sá» nÃ o :D BÃ i nÃ y Ã¡p dá»¥ng nhiá»u vá» LSTM vÃ  xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº§u vÃ o nhÃ©! Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c!,,,,,
"ChÃ o má»i ngÆ°á»i, nhÃ³m mÃ¬nh cÅ©ng má»›i tham gia Zalo AI Challenge 2022 (Lyric Track, top 2 private test) cÅ©ng muá»‘n share code solution cá»§a nhÃ³m ğŸ˜€
Training/model definition má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o á»Ÿ Ä‘Ã¢y [https://github.com/anhvth/WKaraokeMaker]
NgoÃ i ra mÃ¬nh cÃ³ thÃªm  1 scripts Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ visualize káº¿t quáº£ nhÆ° karaoke ( demo video karaoke https://www.youtube.com/watch?v=16RjtOygs7o) vÃ  cÃ³ demo colab, pretrained cho báº¡n nÃ o muá»‘n thá»­ thÃªm ğŸ˜€, náº¿u báº¡n tháº¥y repo há»¯u Ã­ch thÃ¬ cho nhÃ³m xin 1 ngÃ´i sao hy vá»ng ^^
CÃ³ cÃ¢u há»i hay Ã½ kiáº¿n Ä‘Ã³ng gÃ³p gÃ¬ cÃ¡c báº¡n cá»© open issue hoáº·c comment bÃªn dÆ°á»›i cÅ©ng Ä‘Æ°á»£c
Cáº£m Æ¡n má»i ngÆ°á»i ğŸ˜€!
 â€” vá»›i Nguyá»…n VÄƒn Báº£o KhÃ¡nh.","ChÃ o má»i ngÆ°á»i, nhÃ³m mÃ¬nh cÅ©ng má»›i tham gia Zalo AI Challenge 2022 (Lyric Track, top 2 private test) cÅ©ng muá»‘n share code solution cá»§a nhÃ³m Training/model definition má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o á»Ÿ Ä‘Ã¢y [https://github.com/anhvth/WKaraokeMaker] NgoÃ i ra mÃ¬nh cÃ³ thÃªm 1 scripts Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ visualize káº¿t quáº£ nhÆ° karaoke ( demo video karaoke https://www.youtube.com/watch?v=16RjtOygs7o) vÃ  cÃ³ demo colab, pretrained cho báº¡n nÃ o muá»‘n thá»­ thÃªm , náº¿u báº¡n tháº¥y repo há»¯u Ã­ch thÃ¬ cho nhÃ³m xin 1 ngÃ´i sao hy vá»ng ^^ CÃ³ cÃ¢u há»i hay Ã½ kiáº¿n Ä‘Ã³ng gÃ³p gÃ¬ cÃ¡c báº¡n cá»© open issue hoáº·c comment bÃªn dÆ°á»›i cÅ©ng Ä‘Æ°á»£c Cáº£m Æ¡n má»i ngÆ°á»i ! â€” vá»›i Nguyá»…n VÄƒn Báº£o KhÃ¡nh.",,,,,
"Xin chÃ o má»i ngÆ°á»i hÃ´m nay em Ä‘áº¡i diá»‡n nhÃ³m CTA Zero9 (TrÃ¹ng há»£p lÃ  team vá» thá»© 9 ğŸ™„) chia sáº» solution cho challenge Lyric Alignment trong cuá»™c thi Zalo AI Challenge 2022. NhÃ³m em cÅ©ng Ä‘Ã£ há»c Ä‘Æ°á»£c kha khÃ¡ kiáº¿n thá»©c vá» xá»­ lÃ­ audio thÃ´ng qua challenge nÃ y luÃ´n. ğŸ¤£

Source Lyric Alignment: https://github.com/vnk8071/CTA-Zero9-ZAIC2022-Lyric-Alignment

SÆ¡ lÆ°á»£c vá» solution, nhÃ³m em cháº¡y cáº£ 2 solution song song bao gá»“m:
Wav2Vec: Ráº¥t tiá»m nÄƒng nhÆ°ng nhÃ³m khÃ´ng thá»ƒ tÃ¬m ra cÃ¡ch tá»‘i Æ°u solution. 
MFA (Montreal Forced Aligner): Model nÃ y dÃ¹ng lÃ m baseline nhÆ°ng vá» sau láº¡i Ä‘Æ°á»£c cáº£i thiá»‡n nhiá»u vÃ  dÃ¹ng Ä‘á»ƒ lÃ m solution chÃ­nh.
Team tá»¥i em xin Ä‘Æ°á»£c cáº£m Æ¡n BTC cuá»™c thi Zalo AI Challenge Ä‘Ã£ tá»• chá»©c cuá»™c thi thÆ°á»ng niÃªn vá»›i nhá»¯ng challenges vÃ´ cÃ¹ng thÃº vá»‹ vÃ  thá»­ thÃ¡ch. Mong nhá»¯ng nÄƒm tá»›i cuá»™c thi sáº½ cÃ ng cÃ³ nhiá»u báº¡n tham gia hÆ¡n ná»¯a Ä‘á»ƒ leaderboard thÃªm pháº§n sÃ´i Ä‘á»™ng áº¡. 
Tá»¥i em ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a cÃ¡ch anh chá»‹ Ä‘á»ƒ cáº£i thiá»‡n solution áº¡. 
 â€” vá»›i KhÃ´i VN.","Xin chÃ o má»i ngÆ°á»i hÃ´m nay em Ä‘áº¡i diá»‡n nhÃ³m CTA Zero9 (TrÃ¹ng há»£p lÃ  team vá» thá»© 9 ) chia sáº» solution cho challenge Lyric Alignment trong cuá»™c thi Zalo AI Challenge 2022. NhÃ³m em cÅ©ng Ä‘Ã£ há»c Ä‘Æ°á»£c kha khÃ¡ kiáº¿n thá»©c vá» xá»­ lÃ­ audio thÃ´ng qua challenge nÃ y luÃ´n. Source Lyric Alignment: https://github.com/vnk8071/CTA-Zero9-ZAIC2022-Lyric-Alignment SÆ¡ lÆ°á»£c vá» solution, nhÃ³m em cháº¡y cáº£ 2 solution song song bao gá»“m: Wav2Vec: Ráº¥t tiá»m nÄƒng nhÆ°ng nhÃ³m khÃ´ng thá»ƒ tÃ¬m ra cÃ¡ch tá»‘i Æ°u solution. MFA (Montreal Forced Aligner): Model nÃ y dÃ¹ng lÃ m baseline nhÆ°ng vá» sau láº¡i Ä‘Æ°á»£c cáº£i thiá»‡n nhiá»u vÃ  dÃ¹ng Ä‘á»ƒ lÃ m solution chÃ­nh. Team tá»¥i em xin Ä‘Æ°á»£c cáº£m Æ¡n BTC cuá»™c thi Zalo AI Challenge Ä‘Ã£ tá»• chá»©c cuá»™c thi thÆ°á»ng niÃªn vá»›i nhá»¯ng challenges vÃ´ cÃ¹ng thÃº vá»‹ vÃ  thá»­ thÃ¡ch. Mong nhá»¯ng nÄƒm tá»›i cuá»™c thi sáº½ cÃ ng cÃ³ nhiá»u báº¡n tham gia hÆ¡n ná»¯a Ä‘á»ƒ leaderboard thÃªm pháº§n sÃ´i Ä‘á»™ng áº¡. Tá»¥i em ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a cÃ¡ch anh chá»‹ Ä‘á»ƒ cáº£i thiá»‡n solution áº¡. â€” vá»›i KhÃ´i VN.",,,,,
"MÃŒnh cÃ³ má»™t Ä‘á» bÃ i dá»± Ä‘oÃ¡n giÃ¡ sim, khÃ´ng biáº¿t nÃªn chia thÃ nh cÃ¡c features gÃ¬ vÃ  hÆ°á»›ng Ä‘i ntn cho há»£p lÃ½ mong mn giáº£i Ä‘Ã¡p","MÃŒnh cÃ³ má»™t Ä‘á» bÃ i dá»± Ä‘oÃ¡n giÃ¡ sim, khÃ´ng biáº¿t nÃªn chia thÃ nh cÃ¡c features gÃ¬ vÃ  hÆ°á»›ng Ä‘i ntn cho há»£p lÃ½ mong mn giáº£i Ä‘Ã¡p",,,,,
"Can ChatGPT pass the MLE interview?
Here is my git repo to validate the hypothesis by sampling questions from HuyenChip and Data Science. ğŸ¥¸",Can ChatGPT pass the MLE interview? Here is my git repo to validate the hypothesis by sampling questions from HuyenChip and Data Science.,,,,,
"ChÃ o cÃ¡c anh chá»‹ trong nhÃ³m, hiá»‡n táº¡i em Ä‘ang lÃ m vá» bÃ i toÃ¡n Information Retrieval thÃ¬ em cÃ³ tÃ¬m hiá»ƒu vÃ  tháº¥y thuáº­t toÃ¡n BIRCH vÃ  cÃ¡c paper phÃ¡t triá»ƒn tá»« phÆ°Æ¡ng phÃ¡p nÃ y Ä‘áº¡t hiá»‡u quáº£ cao (xem táº¡i https://aclanthology.org/D19-3004/). Em cÃ³ tháº¯c máº¯c lÃ :
1. PhÆ°Æ¡ng phÃ¡p nÃ y cÃ³ nhÆ°á»£c Ä‘iá»ƒm gÃ¬? 
2. CÃ³ Ä‘á»‹nh hÆ°á»›ng giáº£i quyáº¿t nÃ o cho cÃ¡c nhÆ°á»£c Ä‘iá»ƒm trÃªn khÃ´ng? 
3. NgoÃ i phÆ°Æ¡ng phÃ¡p nÃ y thÃ¬ cÃ²n nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ o cho hiá»‡u quáº£ cao hÆ¡n vá»›i bÃ i toÃ¡n nÃ y khÃ´ng?
Em xin cáº£m Æ¡n
#nlp #IR","ChÃ o cÃ¡c anh chá»‹ trong nhÃ³m, hiá»‡n táº¡i em Ä‘ang lÃ m vá» bÃ i toÃ¡n Information Retrieval thÃ¬ em cÃ³ tÃ¬m hiá»ƒu vÃ  tháº¥y thuáº­t toÃ¡n BIRCH vÃ  cÃ¡c paper phÃ¡t triá»ƒn tá»« phÆ°Æ¡ng phÃ¡p nÃ y Ä‘áº¡t hiá»‡u quáº£ cao (xem táº¡i https://aclanthology.org/D19-3004/). Em cÃ³ tháº¯c máº¯c lÃ : 1. PhÆ°Æ¡ng phÃ¡p nÃ y cÃ³ nhÆ°á»£c Ä‘iá»ƒm gÃ¬? 2. CÃ³ Ä‘á»‹nh hÆ°á»›ng giáº£i quyáº¿t nÃ o cho cÃ¡c nhÆ°á»£c Ä‘iá»ƒm trÃªn khÃ´ng? 3. NgoÃ i phÆ°Æ¡ng phÃ¡p nÃ y thÃ¬ cÃ²n nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ o cho hiá»‡u quáº£ cao hÆ¡n vá»›i bÃ i toÃ¡n nÃ y khÃ´ng? Em xin cáº£m Æ¡n",#nlp	#IR,,,,
"[Data Engine - Tesla]
""Data scientists spend 80% of their time cleaning data"" - Nay mÃ¬nh chia sáº» vá» Data Engine cá»§a Tesla Ä‘á»ƒ má»i ngÆ°á»i tháº¥y táº§m quan trá»ng cá»§a dá»¯ liá»‡u khi xÃ¢y dá»±ng mÃ´ hÃ¬nh.","[Data Engine - Tesla] ""Data scientists spend 80% of their time cleaning data"" - Nay mÃ¬nh chia sáº» vá» Data Engine cá»§a Tesla Ä‘á»ƒ má»i ngÆ°á»i tháº¥y táº§m quan trá»ng cá»§a dá»¯ liá»‡u khi xÃ¢y dá»±ng mÃ´ hÃ¬nh.",,,,,
"ChÃ o mn áº¡. Em Ä‘ang gáº·p váº¥n Ä‘á» nÃ y mong mn giÃºp em. Em Ä‘ang tá»± mÃ y mÃ² vá» machine learning Ä‘á»ƒ build ra má»™t model dá»± Ä‘oÃ¡n giÃ¡ cá»§a cá»• phiáº¿u báº±ng mÃ´ hÃ¬nh ARIMA. Em lÃ m theo hÆ°á»›ng dáº«n cá»§a blog nÃ y (https://phamdinhkhanh.github.io/2019/12/12/ARIMAmodel.html).
Cá»¥ thá»ƒ thÃ¬ em muá»‘n dá»± Ä‘oÃ¡n giÃ¡ Ä‘Ã³ng cá»­a cá»§a mÃ£ cá»‘ phiáº¿u ASG. Em Ä‘Ã£ dÃ¹ng package vnquant Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u rá»“i tÃ­nh chuá»—i lá»£i suáº¥t. Em cÅ©ng Ä‘Ã£ dÃ¹ng kiá»ƒm Ä‘á»‹nh Argument dickey fuller trÃªn chuá»—i Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ã¢y lÃ  chuá»—i dá»«ng. Em cÅ©ng váº½ biá»ƒu Ä‘á»“ ACF vÃ  PACF cá»§a chuá»—i. Dá»±a vÃ o biá»ƒu Ä‘á»“ nÃ y, em sáº½ chá»n mÃ´ hÃ¬nh ARIMA(3,0,3).
Táº­p training cá»§a e chÃ­nh lÃ  chuá»—i nÃ y trong khoáº£ng thá»i gian 11 thÃ¡ng Ä‘áº§u tiÃªn cá»§a nÄƒm 2021(244 Ä‘iá»ƒm dá»¯ liá»‡u) cÃ²n táº­p test lÃ  thÃ¡ng 12/2021(23 Ä‘iá»ƒm dá»¯ liá»‡u). Em Ä‘Ã£ lÃ m háº¿t nhá»¯ng gÃ¬ mÃ¬nh biáº¿t nhÆ°ng mÃ´ hÃ¬nh cá»§a e váº«n bá»‹ underfitting nghiÃªm trá»ng trÃªn táº­p test. Mn cho e há»i lÃ  giá» e pháº£i lÃ m gÃ¬ Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh khÃ´ng áº¡?","ChÃ o mn áº¡. Em Ä‘ang gáº·p váº¥n Ä‘á» nÃ y mong mn giÃºp em. Em Ä‘ang tá»± mÃ y mÃ² vá» machine learning Ä‘á»ƒ build ra má»™t model dá»± Ä‘oÃ¡n giÃ¡ cá»§a cá»• phiáº¿u báº±ng mÃ´ hÃ¬nh ARIMA. Em lÃ m theo hÆ°á»›ng dáº«n cá»§a blog nÃ y (https://phamdinhkhanh.github.io/2019/12/12/ARIMAmodel.html). Cá»¥ thá»ƒ thÃ¬ em muá»‘n dá»± Ä‘oÃ¡n giÃ¡ Ä‘Ã³ng cá»­a cá»§a mÃ£ cá»‘ phiáº¿u ASG. Em Ä‘Ã£ dÃ¹ng package vnquant Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u rá»“i tÃ­nh chuá»—i lá»£i suáº¥t. Em cÅ©ng Ä‘Ã£ dÃ¹ng kiá»ƒm Ä‘á»‹nh Argument dickey fuller trÃªn chuá»—i Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ã¢y lÃ  chuá»—i dá»«ng. Em cÅ©ng váº½ biá»ƒu Ä‘á»“ ACF vÃ  PACF cá»§a chuá»—i. Dá»±a vÃ o biá»ƒu Ä‘á»“ nÃ y, em sáº½ chá»n mÃ´ hÃ¬nh ARIMA(3,0,3). Táº­p training cá»§a e chÃ­nh lÃ  chuá»—i nÃ y trong khoáº£ng thá»i gian 11 thÃ¡ng Ä‘áº§u tiÃªn cá»§a nÄƒm 2021(244 Ä‘iá»ƒm dá»¯ liá»‡u) cÃ²n táº­p test lÃ  thÃ¡ng 12/2021(23 Ä‘iá»ƒm dá»¯ liá»‡u). Em Ä‘Ã£ lÃ m háº¿t nhá»¯ng gÃ¬ mÃ¬nh biáº¿t nhÆ°ng mÃ´ hÃ¬nh cá»§a e váº«n bá»‹ underfitting nghiÃªm trá»ng trÃªn táº­p test. Mn cho e há»i lÃ  giá» e pháº£i lÃ m gÃ¬ Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh khÃ´ng áº¡?",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang thá»±c hiá»‡n fine tune cÃ¡c mÃ´ hÃ¬nh bert cho cÃ¡c task tiáº¿ng Viá»‡t. CÃ¡c mÃ´ hÃ¬nh nhÃ¬n chung lÃ  Ä‘á»u cháº¡y, tuy nhiÃªn khi em sá»­ dá»¥ng Ä‘áº¿n mÃ´ hÃ¬nh phobert-base cá»§a VinAI thÃ¬ colab bÃ¡o lá»—i nhÆ° tháº¿ nÃ y áº¡, em cÅ©ng thá»­ trÃªn kaggle thÃ¬ lá»—i tÆ°Æ¡ng tá»±. Hy vá»ng má»i ngÆ°á»i cho em hÆ°á»›ng giáº£i quyáº¿t áº¡, em cáº£m Æ¡n áº¡!","ChÃ o má»i ngÆ°á»i áº¡, em Ä‘ang thá»±c hiá»‡n fine tune cÃ¡c mÃ´ hÃ¬nh bert cho cÃ¡c task tiáº¿ng Viá»‡t. CÃ¡c mÃ´ hÃ¬nh nhÃ¬n chung lÃ  Ä‘á»u cháº¡y, tuy nhiÃªn khi em sá»­ dá»¥ng Ä‘áº¿n mÃ´ hÃ¬nh phobert-base cá»§a VinAI thÃ¬ colab bÃ¡o lá»—i nhÆ° tháº¿ nÃ y áº¡, em cÅ©ng thá»­ trÃªn kaggle thÃ¬ lá»—i tÆ°Æ¡ng tá»±. Hy vá»ng má»i ngÆ°á»i cho em hÆ°á»›ng giáº£i quyáº¿t áº¡, em cáº£m Æ¡n áº¡!",,,,,
"KhÃ´ng biáº¿t á»Ÿ Ä‘Ã¢y cÃ³ bÃ¡c nÃ o lÃ m vá» dá»± Ä‘oÃ¡n tá»‰ sá»‘ cÃ¡c tráº­n Ä‘áº¥u thuá»™c cÃ¡c giáº£i vÃ²ng trÃ²n Round-Robin chÆ°a, náº¿u cÃ³ thÃ¬ em cÃ³ 1 tháº¯c máº¯c lÃ  em dÃ¹ng KNN, Bayes cÅ©ng nhÆ° XGBoost, khi log_loss cÃ ng tháº¥p thÃ¬ tá»‰ lá»‡ dá»± Ä‘oÃ¡n hÃ²a cÃ ng tháº¥p, tháº­m chÃ­ lÃ  khÃ´ng cÃ³ luÃ´n váº­y áº¡?","KhÃ´ng biáº¿t á»Ÿ Ä‘Ã¢y cÃ³ bÃ¡c nÃ o lÃ m vá» dá»± Ä‘oÃ¡n tá»‰ sá»‘ cÃ¡c tráº­n Ä‘áº¥u thuá»™c cÃ¡c giáº£i vÃ²ng trÃ²n Round-Robin chÆ°a, náº¿u cÃ³ thÃ¬ em cÃ³ 1 tháº¯c máº¯c lÃ  em dÃ¹ng KNN, Bayes cÅ©ng nhÆ° XGBoost, khi log_loss cÃ ng tháº¥p thÃ¬ tá»‰ lá»‡ dá»± Ä‘oÃ¡n hÃ²a cÃ ng tháº¥p, tháº­m chÃ­ lÃ  khÃ´ng cÃ³ luÃ´n váº­y áº¡?",,,,,
ChÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang cáº§n lÃ m 1 bÃ i toÃ¡n vá» thay Ä‘á»•i giá»ng nÃ³i tá»« ngÆ°á»i nÃ y thÃ nh ngÆ°á»i khÃ¡c. Khi em search thÃ¬ toÃ n ra thay Ä‘á»•i voice tá»« ngÆ°á»i thÃ nh giá»ng robot hoáº·c cÃ³ tiáº¿ng vang. KhÃ´ng biáº¿t anh chá»‹ nÃ o tá»«ng lÃ m rá»“i cÃ³ thá»ƒ cho em keyword Ä‘á»ƒ search Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n áº¡,ChÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang cáº§n lÃ m 1 bÃ i toÃ¡n vá» thay Ä‘á»•i giá»ng nÃ³i tá»« ngÆ°á»i nÃ y thÃ nh ngÆ°á»i khÃ¡c. Khi em search thÃ¬ toÃ n ra thay Ä‘á»•i voice tá»« ngÆ°á»i thÃ nh giá»ng robot hoáº·c cÃ³ tiáº¿ng vang. KhÃ´ng biáº¿t anh chá»‹ nÃ o tá»«ng lÃ m rá»“i cÃ³ thá»ƒ cho em keyword Ä‘á»ƒ search Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n áº¡,,,,,
ChÃ o má»i ngÆ°á»i! Em Ä‘ang build má»™t cÃ¡i model nhÆ° hÃ¬nh bÃªn dÆ°á»›i áº¡. LÃºc training thÃ¬ mÃ´ hÃ¬nh cá»§a em tÆ°Æ¡ng tá»± nhÆ° Siamese Neural Network. NhÆ°ng lÃºc em sá»­ dá»¥ng mÃ´ hÃ¬nh thÃ¬ em chá»‰ muá»‘n Ä‘Æ°a vÃ o 1 input nháº­n 1 output. Hiá»‡n táº¡i Ã½ tÆ°á»Ÿng cá»§a em lÃ  nhÃ¢n Ä‘Ã´i cÃ¡i input lÃªn nhÆ°ng nhÆ° váº­y thá»i gian predict sáº½ tÄƒng x2. Má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng nÃ o tá»‘t hÆ¡n thÃ¬ gÃ³p Ã½ giÃºp em vá»›i áº¡!,ChÃ o má»i ngÆ°á»i! Em Ä‘ang build má»™t cÃ¡i model nhÆ° hÃ¬nh bÃªn dÆ°á»›i áº¡. LÃºc training thÃ¬ mÃ´ hÃ¬nh cá»§a em tÆ°Æ¡ng tá»± nhÆ° Siamese Neural Network. NhÆ°ng lÃºc em sá»­ dá»¥ng mÃ´ hÃ¬nh thÃ¬ em chá»‰ muá»‘n Ä‘Æ°a vÃ o 1 input nháº­n 1 output. Hiá»‡n táº¡i Ã½ tÆ°á»Ÿng cá»§a em lÃ  nhÃ¢n Ä‘Ã´i cÃ¡i input lÃªn nhÆ°ng nhÆ° váº­y thá»i gian predict sáº½ tÄƒng x2. Má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng nÃ o tá»‘t hÆ¡n thÃ¬ gÃ³p Ã½ giÃºp em vá»›i áº¡!,,,,,
"Hiá»‡n táº¡i e Ä‘ang tham gia cuá»™c thi RSNA kaggle tá»•ng giáº£i thÆ°á»Ÿng $50,000. Cuá»™c thi báº¯t Ä‘áº§u Ä‘Æ°á»£c 2 ngÃ y vÃ  káº¿t thÃºc vÃ o 28/2. NhÃ³m e Ä‘Æ°á»£c 3tv vÃ  má»›i mong muá»‘n tÃ¬m thÃªm 1 mentor join team.Mn há»©ng thÃº vá»›i cuá»™c thi nÃ y thÃ¬ ib e Ä‘á»ƒ trao Ä‘á»•i","Hiá»‡n táº¡i e Ä‘ang tham gia cuá»™c thi RSNA kaggle tá»•ng giáº£i thÆ°á»Ÿng $50,000. Cuá»™c thi báº¯t Ä‘áº§u Ä‘Æ°á»£c 2 ngÃ y vÃ  káº¿t thÃºc vÃ o 28/2. NhÃ³m e Ä‘Æ°á»£c 3tv vÃ  má»›i mong muá»‘n tÃ¬m thÃªm 1 mentor join team.Mn há»©ng thÃº vá»›i cuá»™c thi nÃ y thÃ¬ ib e Ä‘á»ƒ trao Ä‘á»•i",,,,,
"ChÃ o a chá»‹, cho e há»i vá» svm,lÃ m sao tÃ­nh Ä‘Æ°á»£c w vÃ  b,má»—i bÃ i toÃ¡n áº¡. E Ä‘ang cáº§n nháº­n dáº¡ng áº£nh, áº£nh Ä‘Ã³ cÃ³ dáº¥u hiá»‡u (m nÃ o Ä‘Ã³),e báº¯t Ä‘áº§u tá»« áº£nh [3x3].Mong ad duyá»‡t bÃ i sá»›m áº¡.","ChÃ o a chá»‹, cho e há»i vá» svm,lÃ m sao tÃ­nh Ä‘Æ°á»£c w vÃ  b,má»—i bÃ i toÃ¡n áº¡. E Ä‘ang cáº§n nháº­n dáº¡ng áº£nh, áº£nh Ä‘Ã³ cÃ³ dáº¥u hiá»‡u (m nÃ o Ä‘Ã³),e báº¯t Ä‘áº§u tá»« áº£nh [3x3].Mong ad duyá»‡t bÃ i sá»›m áº¡.",,,,,
"Em chÃ o cÃ¡c anh chá»‹ áº¡.
Hiá»‡n nay em Ä‘ang cá»‘ giáº£i bÃ i toÃ¡n POS tagging báº±ng Hidden Markov Model vÃ  ráº¥t mong cÃ¡c anh chá»‹ cÃ³ thá»ƒ gÃ³p Ã½ áº¡. Cá»¥ thá»ƒ hÆ°á»›ng Ä‘i hiá»‡n nay cá»§a em lÃ  maximize likelihood cá»§a chuá»—i cÃ¡c tá»« trong cÃ¢u trong sá»­ dá»¥ng Viterbi algorithm vÃ  Ä‘ang Ä‘áº¡t khoáº£ng 83-84% accuracy on test (mix cáº£ nhá»¯ng tá»« chÆ°a gáº·p vÃ  Ä‘Ã£ gáº·p). Em váº«n muá»‘n cÃ i thiá»‡n thÃªm vÃ  hiá»‡n Ä‘Ã¢y lÃ  nhá»¯ng váº¥n Ä‘á» em nghÄ© cÃ³ thá»ƒ giáº£i quyáº¿t vÃ  mong Ä‘Æ°á»£c nghe Ã½ kiáº¿n cá»§a má»i ngÆ°á»i áº¡:
1. Ambiguous tag: Trong train vÃ  test set cÃ³ 1 sá»‘ nhá»¯ng tá»« cÃ³ ambiguous tag khi vai trÃ² cá»§a tá»« chÆ°a rÃµ rÃ ng (vÃ­ dá»¥ nhÆ° ""developed"" : VVD-VVN). Em khÃ´ng rÃµ cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ disambiguate nhá»¯ng trÆ°á»ng há»£p nhÆ° tháº¿ nÃ y áº¡? VÃ  cÃ³ nÃªn táº­p trung vÃ o viá»‡c nÃ y ko áº¡?
2. Unseen word: Hiá»‡n táº¡i em dÃ¹ng Laplace smoothing Ä‘á»ƒ trÃ¡nh probability = 0 cho nhá»¯ng tá»« ko cÃ³ trong training. Tuy nhiÃªn em ko cháº¯c Ä‘Ã¢y lÃ  cÃ¡ch tá»‘t nháº¥t áº¡.
Em cáº£m Æ¡n group nhiá»u áº¡!
https://medium.com/data-science-in-your-pocket/pos-tagging-using-hidden-markov-models-hmm-viterbi-algorithm-in-nlp-mathematics-explained-d43ca89347c4
#NLP","Em chÃ o cÃ¡c anh chá»‹ áº¡. Hiá»‡n nay em Ä‘ang cá»‘ giáº£i bÃ i toÃ¡n POS tagging báº±ng Hidden Markov Model vÃ  ráº¥t mong cÃ¡c anh chá»‹ cÃ³ thá»ƒ gÃ³p Ã½ áº¡. Cá»¥ thá»ƒ hÆ°á»›ng Ä‘i hiá»‡n nay cá»§a em lÃ  maximize likelihood cá»§a chuá»—i cÃ¡c tá»« trong cÃ¢u trong sá»­ dá»¥ng Viterbi algorithm vÃ  Ä‘ang Ä‘áº¡t khoáº£ng 83-84% accuracy on test (mix cáº£ nhá»¯ng tá»« chÆ°a gáº·p vÃ  Ä‘Ã£ gáº·p). Em váº«n muá»‘n cÃ i thiá»‡n thÃªm vÃ  hiá»‡n Ä‘Ã¢y lÃ  nhá»¯ng váº¥n Ä‘á» em nghÄ© cÃ³ thá»ƒ giáº£i quyáº¿t vÃ  mong Ä‘Æ°á»£c nghe Ã½ kiáº¿n cá»§a má»i ngÆ°á»i áº¡: 1. Ambiguous tag: Trong train vÃ  test set cÃ³ 1 sá»‘ nhá»¯ng tá»« cÃ³ ambiguous tag khi vai trÃ² cá»§a tá»« chÆ°a rÃµ rÃ ng (vÃ­ dá»¥ nhÆ° ""developed"" : VVD-VVN). Em khÃ´ng rÃµ cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ disambiguate nhá»¯ng trÆ°á»ng há»£p nhÆ° tháº¿ nÃ y áº¡? VÃ  cÃ³ nÃªn táº­p trung vÃ o viá»‡c nÃ y ko áº¡? 2. Unseen word: Hiá»‡n táº¡i em dÃ¹ng Laplace smoothing Ä‘á»ƒ trÃ¡nh probability = 0 cho nhá»¯ng tá»« ko cÃ³ trong training. Tuy nhiÃªn em ko cháº¯c Ä‘Ã¢y lÃ  cÃ¡ch tá»‘t nháº¥t áº¡. Em cáº£m Æ¡n group nhiá»u áº¡! https://medium.com/data-science-in-your-pocket/pos-tagging-using-hidden-markov-models-hmm-viterbi-algorithm-in-nlp-mathematics-explained-d43ca89347c4",#NLP,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡.
Em lÃ  beginner vá»«a há»c Machine Learning Ä‘Æ°á»£c vÃ i thÃ¡ng thÃ´i áº¡. Em muá»‘n tÃ¬m má»™t báº¡n/anh chá»‹ nÃ o Ä‘Ã³ há»c chung.
Em vÃ  1 báº¡n Trung Quá»‘c ná»¯a Ä‘ang lÃ m contest nÃ y, anh chá»‹ nÃ o vá»«a há»c ML á»Ÿ má»©c cÆ¡ báº£n náº¿u cÃ³ thá»i gian hÃ£y tham gia cÃ¹ng bá»n em vÃ  chia sáº» kiáº¿n thá»©c .
CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.","Xin chÃ o má»i ngÆ°á»i áº¡. Em lÃ  beginner vá»«a há»c Machine Learning Ä‘Æ°á»£c vÃ i thÃ¡ng thÃ´i áº¡. Em muá»‘n tÃ¬m má»™t báº¡n/anh chá»‹ nÃ o Ä‘Ã³ há»c chung. Em vÃ  1 báº¡n Trung Quá»‘c ná»¯a Ä‘ang lÃ m contest nÃ y, anh chá»‹ nÃ o vá»«a há»c ML á»Ÿ má»©c cÆ¡ báº£n náº¿u cÃ³ thá»i gian hÃ£y tham gia cÃ¹ng bá»n em vÃ  chia sáº» kiáº¿n thá»©c . CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"Em cÃ³ model nhÆ° nÃ y vÃ  em cÃ³ set 1000 Ä‘iá»ƒm (x,y)
Anh chá»‹ cÃ³ thá»ƒ chá»‰ cho em cÃ¡ch táº¡o neural network cÅ©ng nhÆ° train Ä‘c ko áº¡ :(","Em cÃ³ model nhÆ° nÃ y vÃ  em cÃ³ set 1000 Ä‘iá»ƒm (x,y) Anh chá»‹ cÃ³ thá»ƒ chá»‰ cho em cÃ¡ch táº¡o neural network cÅ©ng nhÆ° train Ä‘c ko áº¡ :(",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang giáº£i quyáº¿t 1 bÃ i táº­p lá»›n liÃªn quan Ä‘áº¿n máº¡ng neural káº¿t há»£p cÃ¹ng há»‡ má», há»‡ thá»‘ng Ä‘ang Ä‘Æ°á»£c Ä‘Æ°a vá» dáº¡ng gáº§n giá»‘ng vá»›i ANFIS(Adaptive neuro fuzzy inference system), trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu, em cÃ³ 1 sá»‘ tháº¯c máº¯c:
Layer Ä‘Ã³ng vai trÃ² lÃ  hÃ m thÃ nh viÃªn vá»›i tham sá»‘ lÃ  a vÃ  b cá»§a neuron(Gá»‰a sá»­ chá»n hÃ m thÃ nh viÃªn lÃ  hÃ m tam giÃ¡c), quÃ¡ trÃ¬nh há»c cho máº¡ng neuron chÃ­nh lÃ  Ä‘á»ƒ tÃ¬m ra 2 sá»‘ a vÃ  b tá»‘i Æ°u cho há»‡ thá»‘ng. NhÆ° á»Ÿ hÃ¬nh 2 thÃ¬ em Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡ch tÃ­nh a vÃ  b cho má»—i luáº­t táº¡o thÃ nh vá»›i trá»ng sá»‘ cá»§a luáº­t tÆ°Æ¡ng á»©ng vá»›i Wi. CÃ¢u há»i em muá»‘n Ä‘áº·t ra lÃ  vÃ­ dá»¥ vá»›i hÃ¬nh 1, A1 liÃªn káº¿t vá»›i cáº£ R1,R2,R3 thÃ¬ quÃ¡ trÃ¬nh back-propagation sáº½ diá»…n ra nhÆ° tháº¿ nÃ o Ä‘á»ƒ Ä‘iá»u chá»‰nh a vÃ  b cá»§a A1. VÃ¬ trong cÃ´ng thá»©c trong hÃ¬nh 2, a vÃ  b Ä‘á»u Ä‘ang chá»‰ Ä‘iá»u chá»‰nh dá»±a trÃªn trá»ng sá»‘ cá»§a 1 luáº­t Wi chá»© khÃ´ng pháº£i lÃ  cáº£ 3 luáº­t nhÆ° hÃ¬nh.
Em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang giáº£i quyáº¿t 1 bÃ i táº­p lá»›n liÃªn quan Ä‘áº¿n máº¡ng neural káº¿t há»£p cÃ¹ng há»‡ má», há»‡ thá»‘ng Ä‘ang Ä‘Æ°á»£c Ä‘Æ°a vá» dáº¡ng gáº§n giá»‘ng vá»›i ANFIS(Adaptive neuro fuzzy inference system), trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu, em cÃ³ 1 sá»‘ tháº¯c máº¯c: Layer Ä‘Ã³ng vai trÃ² lÃ  hÃ m thÃ nh viÃªn vá»›i tham sá»‘ lÃ  a vÃ  b cá»§a neuron(Gá»‰a sá»­ chá»n hÃ m thÃ nh viÃªn lÃ  hÃ m tam giÃ¡c), quÃ¡ trÃ¬nh há»c cho máº¡ng neuron chÃ­nh lÃ  Ä‘á»ƒ tÃ¬m ra 2 sá»‘ a vÃ  b tá»‘i Æ°u cho há»‡ thá»‘ng. NhÆ° á»Ÿ hÃ¬nh 2 thÃ¬ em Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡ch tÃ­nh a vÃ  b cho má»—i luáº­t táº¡o thÃ nh vá»›i trá»ng sá»‘ cá»§a luáº­t tÆ°Æ¡ng á»©ng vá»›i Wi. CÃ¢u há»i em muá»‘n Ä‘áº·t ra lÃ  vÃ­ dá»¥ vá»›i hÃ¬nh 1, A1 liÃªn káº¿t vá»›i cáº£ R1,R2,R3 thÃ¬ quÃ¡ trÃ¬nh back-propagation sáº½ diá»…n ra nhÆ° tháº¿ nÃ o Ä‘á»ƒ Ä‘iá»u chá»‰nh a vÃ  b cá»§a A1. VÃ¬ trong cÃ´ng thá»©c trong hÃ¬nh 2, a vÃ  b Ä‘á»u Ä‘ang chá»‰ Ä‘iá»u chá»‰nh dá»±a trÃªn trá»ng sá»‘ cá»§a 1 luáº­t Wi chá»© khÃ´ng pháº£i lÃ  cáº£ 3 luáº­t nhÆ° hÃ¬nh. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ  sinh viÃªn vÃ  cÃ³ mong muá»‘n há»c Machine Learning báº±ng cÃ¡ch tá»± há»c Ä‘á»ƒ tham gia cÃ¡c cuá»™c thi vÃ  dá»± Ã¡n nghiÃªn cá»©u. Hiá»‡n táº¡i em Ä‘Ã£ cÃ³ tÃ i liá»‡u lÃ½ thuyáº¿t vá» Machine Learning, cÃ³ ná»n táº£ng láº­p trÃ¬nh vÃ  cÃ³ lá»™ trÃ¬nh tá»± há»c nhÆ° sau : 
Äá»c tÃ i liá»‡u Ä‘á»ƒ hiá»ƒu cÆ¡ sá»Ÿ. 
LÃ m bÃ i táº­p nhá» Ä‘á» rÃ  soÃ¡t láº¡i kiáº¿n thá»©c vÃ  hiá»ƒu sÃ¢u hÆ¡n vá» nhá»¯ng váº¥n Ä‘á» Ä‘Æ°á»£c há»c.
Káº¿t há»£p nhá»¯ng kÄ© nÄƒng Ä‘á»ƒ tham gia vÃ o cÃ¡c project tá»« nhá» tá»›i lá»›n Ä‘á»ƒ tÃ­ch lÅ©y thÃªm kinh nghiá»‡m vÃ  kiáº¿n thá»©c.
Em cÅ©ng Ä‘Ã£ tham kháº£o cÃ¡c kÃªnh, trang nhÆ°ng háº§u háº¿t Ä‘á»u chá»‰ dá»«ng láº¡i má»©c lÃ½ thuyáº¿t hoáº·c lÃ  Ä‘i vÃ o thá»±c hÃ nh project luÃ´n (cÃ³ thá»ƒ do em chÆ°a tham gia báº¥t cá»© online course nÃ o). Do Ä‘Ã³ em mong Ä‘Æ°á»£c cÃ¡c báº­c tiá»n bá»‘i á»Ÿ Ä‘Ã¢y cÃ³ thá»ƒ chia sáº» giÃºp em nhá»¯ng trang training vÃ  gÃ³p Ã½ xÃ¢y dá»±ng Ä‘á»ƒ em cÃ³ thá»ƒ tiáº¿n bá»™ hÆ¡n trong tÆ°Æ¡ng lai. Em xin cáº£m Æ¡n áº¡. ","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ  sinh viÃªn vÃ  cÃ³ mong muá»‘n há»c Machine Learning báº±ng cÃ¡ch tá»± há»c Ä‘á»ƒ tham gia cÃ¡c cuá»™c thi vÃ  dá»± Ã¡n nghiÃªn cá»©u. Hiá»‡n táº¡i em Ä‘Ã£ cÃ³ tÃ i liá»‡u lÃ½ thuyáº¿t vá» Machine Learning, cÃ³ ná»n táº£ng láº­p trÃ¬nh vÃ  cÃ³ lá»™ trÃ¬nh tá»± há»c nhÆ° sau : Äá»c tÃ i liá»‡u Ä‘á»ƒ hiá»ƒu cÆ¡ sá»Ÿ. LÃ m bÃ i táº­p nhá» Ä‘á» rÃ  soÃ¡t láº¡i kiáº¿n thá»©c vÃ  hiá»ƒu sÃ¢u hÆ¡n vá» nhá»¯ng váº¥n Ä‘á» Ä‘Æ°á»£c há»c. Káº¿t há»£p nhá»¯ng kÄ© nÄƒng Ä‘á»ƒ tham gia vÃ o cÃ¡c project tá»« nhá» tá»›i lá»›n Ä‘á»ƒ tÃ­ch lÅ©y thÃªm kinh nghiá»‡m vÃ  kiáº¿n thá»©c. Em cÅ©ng Ä‘Ã£ tham kháº£o cÃ¡c kÃªnh, trang nhÆ°ng háº§u háº¿t Ä‘á»u chá»‰ dá»«ng láº¡i má»©c lÃ½ thuyáº¿t hoáº·c lÃ  Ä‘i vÃ o thá»±c hÃ nh project luÃ´n (cÃ³ thá»ƒ do em chÆ°a tham gia báº¥t cá»© online course nÃ o). Do Ä‘Ã³ em mong Ä‘Æ°á»£c cÃ¡c báº­c tiá»n bá»‘i á»Ÿ Ä‘Ã¢y cÃ³ thá»ƒ chia sáº» giÃºp em nhá»¯ng trang training vÃ  gÃ³p Ã½ xÃ¢y dá»±ng Ä‘á»ƒ em cÃ³ thá»ƒ tiáº¿n bá»™ hÆ¡n trong tÆ°Æ¡ng lai. Em xin cáº£m Æ¡n áº¡.",,,,,
"Trong Status trÆ°á»›c cá»§a mÃ¬nh há»i vá» viá»‡c #objectdetection vá»›i váº­t thá»ƒ nhá» vÃ  ráº¥t nhá» á»Ÿ Ä‘Ã¢y (shorturl.at/dmpvY). MÃ¬nh Ä‘ang lÃ m thÃ­ nghiá»‡m theo cÃ¡c gá»£i Ã½ cá»§a cÃ¡c báº¡n. Tuy nhiÃªn, cÅ©ng dáº¡ng dataset nÃ y, nhÆ°ng vá»›i #Semanticsegmentation mÃ¬nh thá»­ nghiá»‡m vá»›i Segformer (bÃ i bÃ¡o táº¡i Ä‘Ã¢y https://arxiv.org/abs/2105.15203) thÃ¬ tháº¥y káº¿t quáº£ khÃ¡ kháº£ quan. CÃ¢u há»i Ä‘áº·t ra, cÃ³ báº¡n nÃ o biáº¿t cÃ³ ai Ä‘Ã³ Ä‘Ã£ hack Segformer cho chá»§ Ä‘á» #objectdetection hay chÆ°a?","Trong Status trÆ°á»›c cá»§a mÃ¬nh há»i vá» viá»‡c vá»›i váº­t thá»ƒ nhá» vÃ  ráº¥t nhá» á»Ÿ Ä‘Ã¢y (shorturl.at/dmpvY). MÃ¬nh Ä‘ang lÃ m thÃ­ nghiá»‡m theo cÃ¡c gá»£i Ã½ cá»§a cÃ¡c báº¡n. Tuy nhiÃªn, cÅ©ng dáº¡ng dataset nÃ y, nhÆ°ng vá»›i mÃ¬nh thá»­ nghiá»‡m vá»›i Segformer (bÃ i bÃ¡o táº¡i Ä‘Ã¢y https://arxiv.org/abs/2105.15203) thÃ¬ tháº¥y káº¿t quáº£ khÃ¡ kháº£ quan. CÃ¢u há»i Ä‘áº·t ra, cÃ³ báº¡n nÃ o biáº¿t cÃ³ ai Ä‘Ã³ Ä‘Ã£ hack Segformer cho chá»§ Ä‘á» hay chÆ°a?",#objectdetection	#Semanticsegmentation	#objectdetection,,,,
Em Ä‘ang cÃ³ há»©ng thÃº vá»›i Reinforcement Learning vÃ  Ä‘Ã£ há»c má»™t vÃ i course á»Ÿ trÃªn Coursera. Em cÃ³ vÃ o vÃ i homepage cá»§a cÃ¡c giÃ¡o sÆ° ná»•i tiáº¿ng trÃªn tháº¿ giá»›i thÃ¬ chá»‰ tháº¥y há» lÃ m vá» lÃ­ thuyáº¿t. Má»i ngÆ°á»i cho em xin nhá»¯ng topic thiÃªn vá» á»©ng dá»¥ng cá»§a RL hay Deep RL Ä‘á»ƒ cÃ³ thá»ƒ nghiÃªn cá»©u áº¡.,Em Ä‘ang cÃ³ há»©ng thÃº vá»›i Reinforcement Learning vÃ  Ä‘Ã£ há»c má»™t vÃ i course á»Ÿ trÃªn Coursera. Em cÃ³ vÃ o vÃ i homepage cá»§a cÃ¡c giÃ¡o sÆ° ná»•i tiáº¿ng trÃªn tháº¿ giá»›i thÃ¬ chá»‰ tháº¥y há» lÃ m vá» lÃ­ thuyáº¿t. Má»i ngÆ°á»i cho em xin nhá»¯ng topic thiÃªn vá» á»©ng dá»¥ng cá»§a RL hay Deep RL Ä‘á»ƒ cÃ³ thá»ƒ nghiÃªn cá»©u áº¡.,,,,,
"má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp mÃ¬nh bug nÃ y lÃ  gÃ¬ ko áº¡? MÃ¬nh Ä‘ang sá»­ dá»¥ng VGG Ä‘á»ƒ tÃ­nh toÃ¡n loss cho GAN. NhÆ°ng khÃ´ng hiá»ƒu sao input pháº£i cÃ³ size nhÆ° yÃªu cáº§u áº¡.
Source project cá»§a mÃ¬nh: https://github.com/phuocnguyenbk/pytorch
MÃ¬nh Ä‘ang reseach AI nÃªn ae cÃ³ gÃ¬ thÃ´ng cáº£m cho nhá»¯ng cÃ¢u há»i basic nÃ y nhÃ©.",má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp mÃ¬nh bug nÃ y lÃ  gÃ¬ ko áº¡? MÃ¬nh Ä‘ang sá»­ dá»¥ng VGG Ä‘á»ƒ tÃ­nh toÃ¡n loss cho GAN. NhÆ°ng khÃ´ng hiá»ƒu sao input pháº£i cÃ³ size nhÆ° yÃªu cáº§u áº¡. Source project cá»§a mÃ¬nh: https://github.com/phuocnguyenbk/pytorch MÃ¬nh Ä‘ang reseach AI nÃªn ae cÃ³ gÃ¬ thÃ´ng cáº£m cho nhá»¯ng cÃ¢u há»i basic nÃ y nhÃ©.,,,,,
"Em chÃ o má»i ngÆ°á»i. Em Ä‘ang research vá» Machine Learning cho há»‡ thá»‘ng tÃ­nh Ä‘iá»ƒm Credit Scoring. em Ä‘Ã£ rs Ä‘Æ°á»£c Algorithmic Credit Scoring (AdaBoost, XGBoost, Random Forest...), hiá»‡n táº¡i em cáº§n rs sÃ¢u hÆ¡n vá» fields cá»§a cá»§a cÃ¡c thuáº­t toÃ¡n nÃ y (nhÆ° tÃªn field, kiá»ƒu dá»¯ liá»‡u, nguá»“n láº¥y). Má»i ngÆ°á»i cho em xin keyword hoáº·c cÃ¡c papers nghiÃªn cá»©u nhÃ©. Em cáº£m Æ¡n nhiá»u áº¡!!!","Em chÃ o má»i ngÆ°á»i. Em Ä‘ang research vá» Machine Learning cho há»‡ thá»‘ng tÃ­nh Ä‘iá»ƒm Credit Scoring. em Ä‘Ã£ rs Ä‘Æ°á»£c Algorithmic Credit Scoring (AdaBoost, XGBoost, Random Forest...), hiá»‡n táº¡i em cáº§n rs sÃ¢u hÆ¡n vá» fields cá»§a cá»§a cÃ¡c thuáº­t toÃ¡n nÃ y (nhÆ° tÃªn field, kiá»ƒu dá»¯ liá»‡u, nguá»“n láº¥y). Má»i ngÆ°á»i cho em xin keyword hoáº·c cÃ¡c papers nghiÃªn cá»©u nhÃ©. Em cáº£m Æ¡n nhiá»u áº¡!!!",,,,,
Em Ä‘ang cÃ³ bÃ i toÃ¡n binary classification nhÆ°ng dá»¯ liá»‡u cá»§a em quÃ¡ imblance chá»‰ cÃ³ 10% lÃ  lá»›p 1 cÃ²n láº¡i lÃ  lá»›p 0. Em cÅ©ng Ä‘Ã£ thá»­ cáº£ Oversampling vÃ  Undersampling vá»›i cÃ¡c model há» nhÃ  tree nhÆ° random forest hay Xgboost thÃ¬ Ä‘á»u cho ra káº¿t quáº£ f1-score cá»§a lá»›p 1 ráº¥t tháº¥p gáº§n 20%. Anh chá»‹ cÃ³ thá»ƒ cÃ³ gá»£i Ã½ cho em má»™t sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ cáº£i thiá»‡n f1 cá»§a lá»›p 1 khÃ´ng áº¡? Em cáº£m Æ¡n.,Em Ä‘ang cÃ³ bÃ i toÃ¡n binary classification nhÆ°ng dá»¯ liá»‡u cá»§a em quÃ¡ imblance chá»‰ cÃ³ 10% lÃ  lá»›p 1 cÃ²n láº¡i lÃ  lá»›p 0. Em cÅ©ng Ä‘Ã£ thá»­ cáº£ Oversampling vÃ  Undersampling vá»›i cÃ¡c model há» nhÃ  tree nhÆ° random forest hay Xgboost thÃ¬ Ä‘á»u cho ra káº¿t quáº£ f1-score cá»§a lá»›p 1 ráº¥t tháº¥p gáº§n 20%. Anh chá»‹ cÃ³ thá»ƒ cÃ³ gá»£i Ã½ cho em má»™t sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ cáº£i thiá»‡n f1 cá»§a lá»›p 1 khÃ´ng áº¡? Em cáº£m Æ¡n.,,,,,
"ChÃ o mn áº¡, em Ä‘ang thá»±c hiá»‡n Q&A task vá»›i sá»± hÆ°á»›ng dáº«n cá»§a Hugging Face. Ã Ä‘á»‹nh cá»§a em lÃ  muá»‘n hiá»ƒn thá»‹ Accuracy, F1 vÃ  Validation Los (Ä‘ang bá»‹ no log) trong quÃ¡ trÃ¬nh train áº¡. Hi vá»ng Ä‘Æ°á»£c mn giÃºp Ä‘á»¡ áº¡. Em xin cáº£m Æ¡n áº¡!","ChÃ o mn áº¡, em Ä‘ang thá»±c hiá»‡n Q&A task vá»›i sá»± hÆ°á»›ng dáº«n cá»§a Hugging Face. Ã Ä‘á»‹nh cá»§a em lÃ  muá»‘n hiá»ƒn thá»‹ Accuracy, F1 vÃ  Validation Los (Ä‘ang bá»‹ no log) trong quÃ¡ trÃ¬nh train áº¡. Hi vá»ng Ä‘Æ°á»£c mn giÃºp Ä‘á»¡ áº¡. Em xin cáº£m Æ¡n áº¡!",,,,,
"Hi all,
MÃ¬nh tÃªn lÃ  Viá»‡t, Hiá»‡n táº¡i mÃ¬nh lÃ  senior AI engineer Ä‘ang lÃ m viá»‡c cho https://sporttotal.tv/ - cÃ´ng ty vá» sport broadcasting á»Ÿ Berlin, Äá»©c. Sau khi chia sáº» video hÆ°á»›ng dáº«n vá» AirGesture - chÆ¡i game khÃ´ng cáº§n dÃ¹ng bÃ n phÃ­m tuáº§n trÆ°á»›c, mÃ¬nh Ä‘á»c Ä‘Æ°á»£c 1 vÃ i comment cÃ¡c báº¡n nÃ³i ráº±ng chÆ¡i game kiá»ƒu nÃ y thÃ¬ má»i tay quÃ¡. VÃ¬ tháº¿ nÃªn trong video nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n 1 phiÃªn báº£n cao cáº¥p hÆ¡n: chÆ¡i game mÃ  tháº­m chÃ­ cÃ¡c báº¡n khÃ´ng cáº§n pháº£i dÃ¹ng Ä‘áº¿n tay. Thay vÃ¬ Mediapipe Hands, láº§n nÃ y chÃºng ta sáº½ thá»­ nghiá»‡m Mediapipe Face Mesh - giáº£i phÃ¡p dÃ nh cho khuÃ´n máº·t. 

CÃ¡ch chÆ¡i nÃ y chá»‘ng chá»‰ Ä‘á»‹nh cho nhá»¯ng báº¡n vá»«a nhá»• rÄƒng khÃ´n hay Ä‘ang bá»‹ Ä‘au máº¯t nhÃ©. ChÃºc cÃ¡c báº¡n cÃ³ 1 tráº£i nghiá»‡m chÆ¡i game vui váº»
Full demo + hÆ°á»›ng dáº«n + source code: https://youtu.be/Hcl-cREVo9Q","Hi all, MÃ¬nh tÃªn lÃ  Viá»‡t, Hiá»‡n táº¡i mÃ¬nh lÃ  senior AI engineer Ä‘ang lÃ m viá»‡c cho https://sporttotal.tv/ - cÃ´ng ty vá» sport broadcasting á»Ÿ Berlin, Äá»©c. Sau khi chia sáº» video hÆ°á»›ng dáº«n vá» AirGesture - chÆ¡i game khÃ´ng cáº§n dÃ¹ng bÃ n phÃ­m tuáº§n trÆ°á»›c, mÃ¬nh Ä‘á»c Ä‘Æ°á»£c 1 vÃ i comment cÃ¡c báº¡n nÃ³i ráº±ng chÆ¡i game kiá»ƒu nÃ y thÃ¬ má»i tay quÃ¡. VÃ¬ tháº¿ nÃªn trong video nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n 1 phiÃªn báº£n cao cáº¥p hÆ¡n: chÆ¡i game mÃ  tháº­m chÃ­ cÃ¡c báº¡n khÃ´ng cáº§n pháº£i dÃ¹ng Ä‘áº¿n tay. Thay vÃ¬ Mediapipe Hands, láº§n nÃ y chÃºng ta sáº½ thá»­ nghiá»‡m Mediapipe Face Mesh - giáº£i phÃ¡p dÃ nh cho khuÃ´n máº·t. CÃ¡ch chÆ¡i nÃ y chá»‘ng chá»‰ Ä‘á»‹nh cho nhá»¯ng báº¡n vá»«a nhá»• rÄƒng khÃ´n hay Ä‘ang bá»‹ Ä‘au máº¯t nhÃ©. ChÃºc cÃ¡c báº¡n cÃ³ 1 tráº£i nghiá»‡m chÆ¡i game vui váº» Full demo + hÆ°á»›ng dáº«n + source code: https://youtu.be/Hcl-cREVo9Q",,,,,
"Hi cÃ¡c báº¡n,
Äá»©c lÃ  1 trong sá»‘ Ã­t cÃ¡c quá»‘c gia miá»…n hoÃ n toÃ n há»c phÃ­ cho táº¥t cáº£ cÃ¡c cáº¥p há»c, tá»« máº«u giÃ¡o cho Ä‘áº¿n cao há»c (ÄÃ¢y cÅ©ng lÃ  lÃ½ do chÃ­nh mÃ¬nh chá»n Äá»©c Ä‘á»ƒ há»c master ğŸ¥²). Tuy miá»…n há»c phÃ­ nhÆ°ng cháº¥t lÆ°á»£ng giÃ¡o dá»¥c cá»§a Äá»©c lÃ  ráº¥t cao (CÃ³ ráº¥t nhiá»u trÆ°á»ng cá»§a Äá»©c náº±m trong top ranking tháº¿ giá»›i). NgoÃ i ra cÆ¡ há»™i viá»‡c lÃ m á»Ÿ Äá»©c sau khi tá»‘t nghiá»‡p cÅ©ng lÃ  ráº¥t lá»›n, Ä‘áº·c biá»‡t cho cÃ¡c báº¡n há»c IT (MÃ¬nh xin Ä‘Æ°á»£c viá»‡c ngay sau khi ra trÆ°á»ng vá»›i tiáº¿ng Äá»©c báº±ng 0 ğŸ¥²). Do váº­y mÃ¬nh lÃ m video nÃ y Ä‘á»ƒ chia sáº» vá»›i nhá»¯ng báº¡n Ä‘ang cÃ³ Ã½ Ä‘á»‹nh tÃ¬m hiá»ƒu du há»c:
Nhá»¯ng thÃ´ng tin cÆ¡ báº£n nháº¥t vá» há»‡ thá»‘ng giÃ¡o dá»¥c Äá»©c
CÃ¡ch Ä‘á»ƒ tra world rank (xáº¿p háº¡ng tháº¿ giá»›i) cá»§a 1 trÆ°á»ng báº¥t kÃ¬ trÃªn tháº¿ giá»›i
QuÃ¡ trÃ¬nh 2.5 nÄƒm mÃ¬nh há»c master vá» AI á»Ÿ Munich, Äá»©c
Pháº§n cuá»‘i cÃ¹ng tuy lÃ  pháº§n dÃ i nháº¥t nhÆ°ng chá»‰ lÃ  chia sáº» tráº£i nghiá»‡m cá»§a báº£n thÃ¢n mÃ¬nh, nÃªn cÃ¡c báº¡n cÃ³ thá»ƒ hoÃ n toÃ n bá» qua nhÃ©.
MÃ¬nh hy vá»ng video nÃ y sáº½ giÃºp Ã­ch Ä‘Æ°á»£c cho cÃ¡c báº¡n ğŸ˜Š.
Video: https://youtu.be/eXAxTmCyuEw","Hi cÃ¡c báº¡n, Äá»©c lÃ  1 trong sá»‘ Ã­t cÃ¡c quá»‘c gia miá»…n hoÃ n toÃ n há»c phÃ­ cho táº¥t cáº£ cÃ¡c cáº¥p há»c, tá»« máº«u giÃ¡o cho Ä‘áº¿n cao há»c (ÄÃ¢y cÅ©ng lÃ  lÃ½ do chÃ­nh mÃ¬nh chá»n Äá»©c Ä‘á»ƒ há»c master ). Tuy miá»…n há»c phÃ­ nhÆ°ng cháº¥t lÆ°á»£ng giÃ¡o dá»¥c cá»§a Äá»©c lÃ  ráº¥t cao (CÃ³ ráº¥t nhiá»u trÆ°á»ng cá»§a Äá»©c náº±m trong top ranking tháº¿ giá»›i). NgoÃ i ra cÆ¡ há»™i viá»‡c lÃ m á»Ÿ Äá»©c sau khi tá»‘t nghiá»‡p cÅ©ng lÃ  ráº¥t lá»›n, Ä‘áº·c biá»‡t cho cÃ¡c báº¡n há»c IT (MÃ¬nh xin Ä‘Æ°á»£c viá»‡c ngay sau khi ra trÆ°á»ng vá»›i tiáº¿ng Äá»©c báº±ng 0 ). Do váº­y mÃ¬nh lÃ m video nÃ y Ä‘á»ƒ chia sáº» vá»›i nhá»¯ng báº¡n Ä‘ang cÃ³ Ã½ Ä‘á»‹nh tÃ¬m hiá»ƒu du há»c: Nhá»¯ng thÃ´ng tin cÆ¡ báº£n nháº¥t vá» há»‡ thá»‘ng giÃ¡o dá»¥c Äá»©c CÃ¡ch Ä‘á»ƒ tra world rank (xáº¿p háº¡ng tháº¿ giá»›i) cá»§a 1 trÆ°á»ng báº¥t kÃ¬ trÃªn tháº¿ giá»›i QuÃ¡ trÃ¬nh 2.5 nÄƒm mÃ¬nh há»c master vá» AI á»Ÿ Munich, Äá»©c Pháº§n cuá»‘i cÃ¹ng tuy lÃ  pháº§n dÃ i nháº¥t nhÆ°ng chá»‰ lÃ  chia sáº» tráº£i nghiá»‡m cá»§a báº£n thÃ¢n mÃ¬nh, nÃªn cÃ¡c báº¡n cÃ³ thá»ƒ hoÃ n toÃ n bá» qua nhÃ©. MÃ¬nh hy vá»ng video nÃ y sáº½ giÃºp Ã­ch Ä‘Æ°á»£c cho cÃ¡c báº¡n . Video: https://youtu.be/eXAxTmCyuEw",,,,,
"Hi cÃ¡c báº¡n,
2 video dÆ°á»›i Ä‘Ã¢y, 1 lÃ  sáº£n pháº©m cá»§a digital human, 1 lÃ  sáº£n pháº©m cá»§a Deepfake. ÄÃ¢y lÃ  2 khÃ¡i niá»‡m ráº¥t hay bá»‹ nháº§m láº«n vá»›i nhau. Trong video nÃ y mÃ¬nh sáº½ giáº£i thÃ­ch ngáº¯n gá»n cho cÃ¡c báº¡n vá» 2 khÃ¡i niá»‡m nÃ y cÅ©ng nhÆ° sá»± khÃ¡c nhau cÆ¡ báº£n cá»§a chÃºng. MÃ¬nh hy vá»ng video nÃ y sáº½ há»¯u Ã­ch vá»›i cÃ¡c báº¡n, Ä‘áº·c biá»‡t lÃ  nhá»¯ng báº¡n Ä‘ang há»c cÅ©ng nhÆ° Ä‘ang Ä‘i lÃ m trong máº£ng AI/Computer Vision. Video chá»‰ dÃ i hÆ¡n 5 phÃºt thÃ´i nÃªn cÃ¡c báº¡n Ä‘á»«ng skip nhÃ©.
Full videos + giáº£i thÃ­ch: https://youtu.be/Zs3hzOZTPaw","Hi cÃ¡c báº¡n, 2 video dÆ°á»›i Ä‘Ã¢y, 1 lÃ  sáº£n pháº©m cá»§a digital human, 1 lÃ  sáº£n pháº©m cá»§a Deepfake. ÄÃ¢y lÃ  2 khÃ¡i niá»‡m ráº¥t hay bá»‹ nháº§m láº«n vá»›i nhau. Trong video nÃ y mÃ¬nh sáº½ giáº£i thÃ­ch ngáº¯n gá»n cho cÃ¡c báº¡n vá» 2 khÃ¡i niá»‡m nÃ y cÅ©ng nhÆ° sá»± khÃ¡c nhau cÆ¡ báº£n cá»§a chÃºng. MÃ¬nh hy vá»ng video nÃ y sáº½ há»¯u Ã­ch vá»›i cÃ¡c báº¡n, Ä‘áº·c biá»‡t lÃ  nhá»¯ng báº¡n Ä‘ang há»c cÅ©ng nhÆ° Ä‘ang Ä‘i lÃ m trong máº£ng AI/Computer Vision. Video chá»‰ dÃ i hÆ¡n 5 phÃºt thÃ´i nÃªn cÃ¡c báº¡n Ä‘á»«ng skip nhÃ©. Full videos + giáº£i thÃ­ch: https://youtu.be/Zs3hzOZTPaw",,,,,
"Hi all,

MÃ¬nh  Ä‘Ã£ há»c vÃ  lÃ m viá»‡c trong lÄ©nh vá»±c AI á»Ÿ Äá»©c Ä‘Æ°á»£c 7 nÄƒm rá»“i. Trong thá»i  gian nÃ y mÃ¬nh Ä‘Ã£ tráº£i qua cÃ¡c vá»‹ trÃ­ tá»« Data scientist, ML engineer cho  Ä‘áº¿n AI engineer nhÆ° hiá»‡n táº¡i, trÃªn cáº£ 2 máº£ng lá»›n lÃ  NLP (xá»­ lÃ½ ngÃ´n ngá»¯  tá»± nhiÃªn) cÅ©ng nhÆ° Computer Vision (thá»‹ giÃ¡c mÃ¡y tÃ­nh). Trong video nÃ y  mÃ¬nh muá»‘n chia sáº» vá»›i cÃ¡c báº¡n Roadmap Ä‘á»ƒ trá»Ÿ thÃ nh 1 Data scientist/ML  engineer/AI engineer, dá»±a trÃªn nhá»¯ng gÃ¬ báº£n thÃ¢n mÃ¬nh Ä‘Ã£ tráº£i qua, tá»«  lÃºc báº¯t Ä‘áº§u há»c vá» AI cho Ä‘áº¿n giá». MÃ¬nh hi vá»ng nhá»¯ng chia sáº» nÃ y cá»§a  mÃ¬nh sáº½ giÃºp Ä‘Æ°á»£c pháº§n nÃ o cÃ¡c báº¡n trong quÃ¡ trÃ¬nh cÃ¡c báº¡n theo Ä‘uá»•i  lÄ©nh vá»±c chÃ´ng gai nhÆ°ng cÅ©ng vÃ´ cÃ¹ng thÃº vá»‹ nÃ y

Link to video: https://youtu.be/B6N44PkQG6o","Hi all, MÃ¬nh Ä‘Ã£ há»c vÃ  lÃ m viá»‡c trong lÄ©nh vá»±c AI á»Ÿ Äá»©c Ä‘Æ°á»£c 7 nÄƒm rá»“i. Trong thá»i gian nÃ y mÃ¬nh Ä‘Ã£ tráº£i qua cÃ¡c vá»‹ trÃ­ tá»« Data scientist, ML engineer cho Ä‘áº¿n AI engineer nhÆ° hiá»‡n táº¡i, trÃªn cáº£ 2 máº£ng lá»›n lÃ  NLP (xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn) cÅ©ng nhÆ° Computer Vision (thá»‹ giÃ¡c mÃ¡y tÃ­nh). Trong video nÃ y mÃ¬nh muá»‘n chia sáº» vá»›i cÃ¡c báº¡n Roadmap Ä‘á»ƒ trá»Ÿ thÃ nh 1 Data scientist/ML engineer/AI engineer, dá»±a trÃªn nhá»¯ng gÃ¬ báº£n thÃ¢n mÃ¬nh Ä‘Ã£ tráº£i qua, tá»« lÃºc báº¯t Ä‘áº§u há»c vá» AI cho Ä‘áº¿n giá». MÃ¬nh hi vá»ng nhá»¯ng chia sáº» nÃ y cá»§a mÃ¬nh sáº½ giÃºp Ä‘Æ°á»£c pháº§n nÃ o cÃ¡c báº¡n trong quÃ¡ trÃ¬nh cÃ¡c báº¡n theo Ä‘uá»•i lÄ©nh vá»±c chÃ´ng gai nhÆ°ng cÅ©ng vÃ´ cÃ¹ng thÃº vá»‹ nÃ y Link to video: https://youtu.be/B6N44PkQG6o",,,,,
"Xin chÃ o má»i ngÆ°á»i trong group, em Ä‘ang tá»± há»c data analysis cÆ¡ báº£n, cá»¥ thá»ƒ lÃ  phÃ¢n tÃ­ch giÃ¡ cá»• phiáº¿u cá»§a nÆ°á»›c mÃ¬nh. BÃ i toÃ¡n cá»¥ thá»ƒ em Ä‘ang muá»‘n giáº£i quyáº¿t Ä‘Ã³ lÃ  tÃ¬m ra Ä‘Æ°á»£c 3 mÃ£ cá»‘ phiáº¿u cÃ³ giÃ¡ tÄƒng trÆ°á»Ÿng nhanh nháº¥t trong danh má»¥c cá»• phiáº¿u cá»§a chá»‰ sá»‘ VNINDEX trong má»™t giai Ä‘oáº¡n thá»i gian cá»¥ thá»ƒ( theo cÃ´ng thá»©c growth rate = (giÃ¡ ngÃ y cuá»‘i - giÃ¡ ngÃ y Ä‘áº§u)/giÃ¡ ngÃ y Ä‘áº§u). Viá»‡c em cáº§n lÃ m lÃ  pháº£i tÃ­nh Ä‘Æ°á»£c growth rate cá»§a táº¥t cáº£ cÃ¡c mÃ£ cá»‘ phiáº¿u thuá»™c danh má»¥c VNINDEX vÃ  chá»n ra giÃ¡ trá»‹ lá»›n nháº¥t. Má»i ngÆ°á»i cho em há»i lÃ  cÃ³ hÃ m nÃ o trong pandas hay vnquant cÃ³ thá»ƒ lÃ m Ä‘c cÃ´ng viá»‡c nÃ y khÃ´ng áº¡? Hoáº·c náº¿u pháº£i tá»± viáº¿t thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ clone data cá»§a táº¥t cáº£ cÃ¡c mÃ£ mÃ  khÃ´ng pháº£i lÃ m thá»§ cÃ´ng hay khÃ´ng áº¡? Em xin cáº£m Æ¡n.","Xin chÃ o má»i ngÆ°á»i trong group, em Ä‘ang tá»± há»c data analysis cÆ¡ báº£n, cá»¥ thá»ƒ lÃ  phÃ¢n tÃ­ch giÃ¡ cá»• phiáº¿u cá»§a nÆ°á»›c mÃ¬nh. BÃ i toÃ¡n cá»¥ thá»ƒ em Ä‘ang muá»‘n giáº£i quyáº¿t Ä‘Ã³ lÃ  tÃ¬m ra Ä‘Æ°á»£c 3 mÃ£ cá»‘ phiáº¿u cÃ³ giÃ¡ tÄƒng trÆ°á»Ÿng nhanh nháº¥t trong danh má»¥c cá»• phiáº¿u cá»§a chá»‰ sá»‘ VNINDEX trong má»™t giai Ä‘oáº¡n thá»i gian cá»¥ thá»ƒ( theo cÃ´ng thá»©c growth rate = (giÃ¡ ngÃ y cuá»‘i - giÃ¡ ngÃ y Ä‘áº§u)/giÃ¡ ngÃ y Ä‘áº§u). Viá»‡c em cáº§n lÃ m lÃ  pháº£i tÃ­nh Ä‘Æ°á»£c growth rate cá»§a táº¥t cáº£ cÃ¡c mÃ£ cá»‘ phiáº¿u thuá»™c danh má»¥c VNINDEX vÃ  chá»n ra giÃ¡ trá»‹ lá»›n nháº¥t. Má»i ngÆ°á»i cho em há»i lÃ  cÃ³ hÃ m nÃ o trong pandas hay vnquant cÃ³ thá»ƒ lÃ m Ä‘c cÃ´ng viá»‡c nÃ y khÃ´ng áº¡? Hoáº·c náº¿u pháº£i tá»± viáº¿t thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ clone data cá»§a táº¥t cáº£ cÃ¡c mÃ£ mÃ  khÃ´ng pháº£i lÃ m thá»§ cÃ´ng hay khÃ´ng áº¡? Em xin cáº£m Æ¡n.",,,,,
"Xin chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm cuá»‘i hiá»‡n Ä‘ang cÃ³ bÃ i táº­p nhÆ° hÃ¬nh. Qua quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu em cÃ³ 1 tháº¯c máº¯c Ä‘áº¿n giá» váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c lá»i giáº£i:
Há»‡ thá»‘ng nÃ y sáº½ há»c báº±ng cÃ¡ch nÃ o? How to learning algorithm? VÃ¬ quÃ¡ trÃ¬nh há»c diá»…n ra á»Ÿ Há»‡ má» nÃªn ko biáº¿t Ä‘Æ°á»£c target output thÃ¬ training Neural network báº±ng cÃ¡ch nÃ o dá»±a trÃªn data cÃ³ sáºµn, lsao Ä‘á»ƒ Ä‘Ã¡nh láº¡i weight láº«n bias?","Xin chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm cuá»‘i hiá»‡n Ä‘ang cÃ³ bÃ i táº­p nhÆ° hÃ¬nh. Qua quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu em cÃ³ 1 tháº¯c máº¯c Ä‘áº¿n giá» váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c lá»i giáº£i: Há»‡ thá»‘ng nÃ y sáº½ há»c báº±ng cÃ¡ch nÃ o? How to learning algorithm? VÃ¬ quÃ¡ trÃ¬nh há»c diá»…n ra á»Ÿ Há»‡ má» nÃªn ko biáº¿t Ä‘Æ°á»£c target output thÃ¬ training Neural network báº±ng cÃ¡ch nÃ o dá»±a trÃªn data cÃ³ sáºµn, lsao Ä‘á»ƒ Ä‘Ã¡nh láº¡i weight láº«n bias?",,,,,
"Xin nhá» cÃ¡c cao nhÃ¢n hÆ°á»›ng dáº«n em cÃ¡ch cÃ i package linear_assignment. Em search trÃªn máº¡ng khÃ´ng tháº¥y cÃ¡ch cÃ i Ä‘á»ƒ trÃ¡nh lá»—i khÃ´ng Ä‘á»‹nh danh Ä‘Æ°á»£c
from sklearn.utils.linear_assignment_ import linear_assignment",Xin nhá» cÃ¡c cao nhÃ¢n hÆ°á»›ng dáº«n em cÃ¡ch cÃ i package linear_assignment. Em search trÃªn máº¡ng khÃ´ng tháº¥y cÃ¡ch cÃ i Ä‘á»ƒ trÃ¡nh lá»—i khÃ´ng Ä‘á»‹nh danh Ä‘Æ°á»£c from sklearn.utils.linear_assignment_ import linear_assignment,,,,,
"ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘Ã£ train xong model yolov7 Ä‘á»ƒ detect Ä‘Æ°á»£c biá»ƒn sá»‘, tuy nhiÃªn custom model cá»§a em láº¡i ko detect Ä‘Æ°á»£c xe. Váº­y má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c cáº£ weights cá»§a pretrained model vÃ  custom weights Ä‘á»ƒ detect Ä‘Æ°á»£c cáº£ xe vÃ  biá»ƒn sá»‘ hay khÃ´ng, hay láº¡i pháº£i quay vá» custom dataset Ä‘á»ƒ Ä‘Ã¡nh nhÃ£n cáº£ xe vÃ  biá»ƒn rá»“i quay láº¡i train áº¡?","ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘Ã£ train xong model yolov7 Ä‘á»ƒ detect Ä‘Æ°á»£c biá»ƒn sá»‘, tuy nhiÃªn custom model cá»§a em láº¡i ko detect Ä‘Æ°á»£c xe. Váº­y má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c cáº£ weights cá»§a pretrained model vÃ  custom weights Ä‘á»ƒ detect Ä‘Æ°á»£c cáº£ xe vÃ  biá»ƒn sá»‘ hay khÃ´ng, hay láº¡i pháº£i quay vá» custom dataset Ä‘á»ƒ Ä‘Ã¡nh nhÃ£n cáº£ xe vÃ  biá»ƒn rá»“i quay láº¡i train áº¡?",,,,,
"Cho em há»i cÃ¡c dá»± Ã¡n thá»±c táº¿ cÃ³ á»©ng dá»¥ng computer vision ngÆ°á»i ta code cÃ¡i pháº§n gÃ¬ báº±ng c++ áº¡?
Em theo computer vision thÃ¬ ko rÃµ, yÃªu cáº§u c++ cÃ³ pháº£i báº¯t buá»™c cáº§n biáº¿t Ä‘á»ƒ Ä‘i lÃ m ko.
Em cáº£m Æ¡n áº¡","Cho em há»i cÃ¡c dá»± Ã¡n thá»±c táº¿ cÃ³ á»©ng dá»¥ng computer vision ngÆ°á»i ta code cÃ¡i pháº§n gÃ¬ báº±ng c++ áº¡? Em theo computer vision thÃ¬ ko rÃµ, yÃªu cáº§u c++ cÃ³ pháº£i báº¯t buá»™c cáº§n biáº¿t Ä‘á»ƒ Ä‘i lÃ m ko. Em cáº£m Æ¡n áº¡",,,,,
"Dáº¡ em chÃ o má»i ngÆ°á»i trong gr, em Ä‘ang thá»±c hiá»‡n má»™t bÃ i toÃ¡n cáº§n dÃ¹ng wikiextractor Ä‘á»ƒ extract tá»« cÃ¡c file dump wiki nhÆ°ng output chá»‰ gá»“m 4 field id, url, title, text. Em muá»‘n cÃ³ thÃªm trÆ°á»ng charoffset hoáº·c text_with_links nhÆ° bÃªn hotpotQA thÃ¬ pháº£i xá»­ lÃ½ ntn áº¡!
https://hotpotqa.github.io/wiki-readme.html","Dáº¡ em chÃ o má»i ngÆ°á»i trong gr, em Ä‘ang thá»±c hiá»‡n má»™t bÃ i toÃ¡n cáº§n dÃ¹ng wikiextractor Ä‘á»ƒ extract tá»« cÃ¡c file dump wiki nhÆ°ng output chá»‰ gá»“m 4 field id, url, title, text. Em muá»‘n cÃ³ thÃªm trÆ°á»ng charoffset hoáº·c text_with_links nhÆ° bÃªn hotpotQA thÃ¬ pháº£i xá»­ lÃ½ ntn áº¡! https://hotpotqa.github.io/wiki-readme.html",,,,,
"ÄÃ³ng gÃ³p tiáº¿p theo Ä‘áº¿n tá»« VietAI research team cho thÆ° viá»‡n huggingface/diffusers: Latent Diffusion Super Resolution pipeline, chuyÃªn trá»‹ áº£nh out nÃ©t cho cÃ¡c â€œthÃ¡nh sá»‘ng áº£oâ€ ğŸ˜.

Tráº£i nghiá»‡m táº¡i: https://bom.so/nCZW9c","ÄÃ³ng gÃ³p tiáº¿p theo Ä‘áº¿n tá»« VietAI research team cho thÆ° viá»‡n huggingface/diffusers: Latent Diffusion Super Resolution pipeline, chuyÃªn trá»‹ áº£nh out nÃ©t cho cÃ¡c â€œthÃ¡nh sá»‘ng áº£oâ€ . Tráº£i nghiá»‡m táº¡i: https://bom.so/nCZW9c",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang cÃ³ 1 dá»± Ã¡n sinh viÃªn, cÃ³ 1 chá»©c nÄƒng Ä‘Ã³ lÃ  dÃ¹ng camera gáº·p á»Ÿ cÃ¡c ká»‡ trÆ°ng bÃ y trong triá»ƒn lÃ£m, báº£o tÃ ng Ä‘á»ƒ Ä‘o sá»‘ lÆ°á»£ng ngÆ°á»i Ä‘á»©ng trÆ°á»›c sáº£n pháº©m. VÃ¬ cam Ä‘áº·t táº§m ngang ngÆ°á»i nÃªn em khÃ´ng dÃ¹ng Ä‘Æ°á»£c bÃ i toÃ¡n in-store heatmap Ä‘Æ°á»£c. Em mong má»i ngÆ°á»i cÃ³ thá»ƒ cho em gá»£i Ã½ áº¡","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang cÃ³ 1 dá»± Ã¡n sinh viÃªn, cÃ³ 1 chá»©c nÄƒng Ä‘Ã³ lÃ  dÃ¹ng camera gáº·p á»Ÿ cÃ¡c ká»‡ trÆ°ng bÃ y trong triá»ƒn lÃ£m, báº£o tÃ ng Ä‘á»ƒ Ä‘o sá»‘ lÆ°á»£ng ngÆ°á»i Ä‘á»©ng trÆ°á»›c sáº£n pháº©m. VÃ¬ cam Ä‘áº·t táº§m ngang ngÆ°á»i nÃªn em khÃ´ng dÃ¹ng Ä‘Æ°á»£c bÃ i toÃ¡n in-store heatmap Ä‘Æ°á»£c. Em mong má»i ngÆ°á»i cÃ³ thá»ƒ cho em gá»£i Ã½ áº¡",,,,,
"Hiá»‡n nay e Ä‘ang há»c nÄƒm thá»© 3 chuyÃªn ngÃ nh AI vÃ  Ä‘Ã£ Ä‘áº¿n ká»³ thá»±c táº­p, e search trÃªn google thÃ¬ tháº¥y ráº¥t Ã­t cÃ´ng ty Ä‘ang tuyá»ƒn thá»±c táº­p sinh, má»i ngÆ°á»i cÃ³ thÃ´ng tin tuyá»ƒn dá»¥ng cÃ´ng ty nÃ o giÃºp e vá»›i áº¡, e cáº£m Æ¡n.","Hiá»‡n nay e Ä‘ang há»c nÄƒm thá»© 3 chuyÃªn ngÃ nh AI vÃ  Ä‘Ã£ Ä‘áº¿n ká»³ thá»±c táº­p, e search trÃªn google thÃ¬ tháº¥y ráº¥t Ã­t cÃ´ng ty Ä‘ang tuyá»ƒn thá»±c táº­p sinh, má»i ngÆ°á»i cÃ³ thÃ´ng tin tuyá»ƒn dá»¥ng cÃ´ng ty nÃ o giÃºp e vá»›i áº¡, e cáº£m Æ¡n.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c.
Cuá»‘i tuáº§n em xin phÃ©p share cÃ¹ng anh em má»™t game vui váº» vá»›i Mediapipe vÃ  OpenCV. ChÃºc anh em thÃ nh cÃ´ng!",KÃ­nh chÃ o cÃ¡c bÃ¡c. Cuá»‘i tuáº§n em xin phÃ©p share cÃ¹ng anh em má»™t game vui váº» vá»›i Mediapipe vÃ  OpenCV. ChÃºc anh em thÃ nh cÃ´ng!,,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» bÃ i toÃ¡n viáº¿t láº¡i ná»™i dung 1 bÃ i bÃ¡o tiáº¿ng Viá»‡t. 
Má»i ngÆ°á»i ai Ä‘Ã£ lÃ m rá»“i cho em xin giáº£i phÃ¡p. Náº¿u cÃ³ opensource nÃ o cho em xin Ä‘á»ƒ há»c há»i vá»›i áº¡.
Em cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» bÃ i toÃ¡n viáº¿t láº¡i ná»™i dung 1 bÃ i bÃ¡o tiáº¿ng Viá»‡t. Má»i ngÆ°á»i ai Ä‘Ã£ lÃ m rá»“i cho em xin giáº£i phÃ¡p. Náº¿u cÃ³ opensource nÃ o cho em xin Ä‘á»ƒ há»c há»i vá»›i áº¡. Em cáº£m Æ¡n!",,,,,
"Hi all. 
MÃ¬nh tÃªn lÃ  Viá»‡t, Hiá»‡n táº¡i mÃ¬nh lÃ  senior AI engineer Ä‘ang lÃ m viá»‡c cho https://sporttotal.tv/ - cÃ´ng ty vá» sport broadcasting á»Ÿ Berlin, Äá»©c. Trong lÃºc ráº£nh rá»—i mÃ¬nh hay lÃ m 1 vÃ i mini project liÃªn quan Ä‘áº¿n AI/Computer Vision. Trong video nÃ y mÃ¬nh xin hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡ch sá»­ dá»¥ng framework ráº¥t ná»•i tiáº¿ng Mediapipe cá»§a Google Ä‘á»ƒ cÃ³ thá»ƒ táº¡o ra nhá»¯ng á»©ng dá»¥ng chÆ¡i game khÃ´ng cáº§n bÃ n phÃ­m cá»§a riÃªng báº¡n. Have fun!
Full demo + hÆ°á»›ng dáº«n: https://youtu.be/iJIDLYQbGDI","Hi all. MÃ¬nh tÃªn lÃ  Viá»‡t, Hiá»‡n táº¡i mÃ¬nh lÃ  senior AI engineer Ä‘ang lÃ m viá»‡c cho https://sporttotal.tv/ - cÃ´ng ty vá» sport broadcasting á»Ÿ Berlin, Äá»©c. Trong lÃºc ráº£nh rá»—i mÃ¬nh hay lÃ m 1 vÃ i mini project liÃªn quan Ä‘áº¿n AI/Computer Vision. Trong video nÃ y mÃ¬nh xin hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡ch sá»­ dá»¥ng framework ráº¥t ná»•i tiáº¿ng Mediapipe cá»§a Google Ä‘á»ƒ cÃ³ thá»ƒ táº¡o ra nhá»¯ng á»©ng dá»¥ng chÆ¡i game khÃ´ng cáº§n bÃ n phÃ­m cá»§a riÃªng báº¡n. Have fun! Full demo + hÆ°á»›ng dáº«n: https://youtu.be/iJIDLYQbGDI",,,,,
"Register now for VinAI Winter Workshop 2022 (Sat, 19 Nov): http://bit.ly/3UDu7gV
We will discuss ""How to get your paper accepted to top-tier conferences?"" & showcase our latest R&D results.","Register now for VinAI Winter Workshop 2022 (Sat, 19 Nov): http://bit.ly/3UDu7gV We will discuss ""How to get your paper accepted to top-tier conferences?"" & showcase our latest R&D results.",,,,,
"Hi má»i ngÆ°á»i, hiá»‡n táº¡i em cÃ³ Ä‘ang lÃ m má»™t dá»± Ã¡n vá» image retrieval cho Android app. NhÆ° lÃ  em cÃ³ má»™t data set vá» táº¥t cáº£ áº£nh chá»¥p mÃ n hÃ¬nh cá»§a má»™t Android app báº¥t kÃ¬ nÃ o Ä‘Ã³, rá»“i khi em cÃ³ má»™t cÃ¡i áº£nh truy váº¥n, em muá»‘n láº¥y ra cÃ¡i áº£nh mÃ  giá»‘ng vá»›i cÃ¡i áº£nh truy váº¥n nháº¥t (áº£nh mÃ n hÃ¬nh táº¡i cÃ¹ng trang cá»§a app vá»›i query image). Em cÃ³ thá»­ dÃ¹ng hash-code Ä‘á»ƒ so sÃ¡nh giá»¯a áº£nh truy váº¥n vÃ  tá»«ng áº£nh trong kho dá»¯ liá»‡u, nhÆ°ng khÃ´ng hiá»‡u quÃ¡ cho láº¯m. Em muá»‘n há»i lÃ  cÃ³ Machine Learning hoáº·c Deep Learning model nÃ o mÃ  em cÃ³ thá»ƒ giÃºp mÃ¬nh trong viá»‡c so sÃ¡nh áº£nh truy váº¥n vá»›i áº£nh trong dá»¯ liá»‡u rá»“i láº¥y ra áº£nh giá»‘ng nháº¥t k áº¡? Em cáº£m Æ¡n áº¡","Hi má»i ngÆ°á»i, hiá»‡n táº¡i em cÃ³ Ä‘ang lÃ m má»™t dá»± Ã¡n vá» image retrieval cho Android app. NhÆ° lÃ  em cÃ³ má»™t data set vá» táº¥t cáº£ áº£nh chá»¥p mÃ n hÃ¬nh cá»§a má»™t Android app báº¥t kÃ¬ nÃ o Ä‘Ã³, rá»“i khi em cÃ³ má»™t cÃ¡i áº£nh truy váº¥n, em muá»‘n láº¥y ra cÃ¡i áº£nh mÃ  giá»‘ng vá»›i cÃ¡i áº£nh truy váº¥n nháº¥t (áº£nh mÃ n hÃ¬nh táº¡i cÃ¹ng trang cá»§a app vá»›i query image). Em cÃ³ thá»­ dÃ¹ng hash-code Ä‘á»ƒ so sÃ¡nh giá»¯a áº£nh truy váº¥n vÃ  tá»«ng áº£nh trong kho dá»¯ liá»‡u, nhÆ°ng khÃ´ng hiá»‡u quÃ¡ cho láº¯m. Em muá»‘n há»i lÃ  cÃ³ Machine Learning hoáº·c Deep Learning model nÃ o mÃ  em cÃ³ thá»ƒ giÃºp mÃ¬nh trong viá»‡c so sÃ¡nh áº£nh truy váº¥n vá»›i áº£nh trong dá»¯ liá»‡u rá»“i láº¥y ra áº£nh giá»‘ng nháº¥t k áº¡? Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o cáº£ nhÃ  mÃ¬nh Ä‘ang train model. Khi train vá»›i táº­p dá»¯ liá»‡u nhá» (30 áº£nh) thÃ¬ ra káº¿t quáº£, nhÆ°ng khi tÄƒng cÆ°á»ng táº­p dá»¯ liá»‡u train (tá»« 30 áº£nh thÃ nh 1620 áº£nh) láº¡i thÃ¬ xuáº¥t hiá»‡n lá»—i nÃ y. Nhá» Má»i ngÆ°á»i xem giÃºp lá»—i nÃ y lÃ  tháº¿ nÃ o? MÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng fix mÃ  chÆ°a Ä‘Æ°á»£c. Thanks All!","ChÃ o cáº£ nhÃ  mÃ¬nh Ä‘ang train model. Khi train vá»›i táº­p dá»¯ liá»‡u nhá» (30 áº£nh) thÃ¬ ra káº¿t quáº£, nhÆ°ng khi tÄƒng cÆ°á»ng táº­p dá»¯ liá»‡u train (tá»« 30 áº£nh thÃ nh 1620 áº£nh) láº¡i thÃ¬ xuáº¥t hiá»‡n lá»—i nÃ y. Nhá» Má»i ngÆ°á»i xem giÃºp lá»—i nÃ y lÃ  tháº¿ nÃ o? MÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng fix mÃ  chÆ°a Ä‘Æ°á»£c. Thanks All!",,,,,
Em Ä‘ang lÃ  hs muá»‘n tÃ¬m hiá»ƒu vÃ  há»c há»i kinh nghiá»‡m cáº§n tÃ¬m ngÆ°á»i chung Ä‘á»™i há»— trá»£ cho cuá»™c thi ZALO AI. Ai chÆ°a cÃ³ Ä‘á»™i ib,Em Ä‘ang lÃ  hs muá»‘n tÃ¬m hiá»ƒu vÃ  há»c há»i kinh nghiá»‡m cáº§n tÃ¬m ngÆ°á»i chung Ä‘á»™i há»— trá»£ cho cuá»™c thi ZALO AI. Ai chÆ°a cÃ³ Ä‘á»™i ib,,,,,
"Máº·c dÃ¹ mÃ¡y tÃ­nh ngÃ y cÃ ng trá»Ÿ nÃªn hiá»‡n Ä‘áº¡i, AI ngÃ y cÃ ng trá»Ÿ nÃªn thÃ´ng minh vÃ  Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i trÃªn má»i lÄ©nh vá»±c, thÃ¬ vá» máº·t báº£n cháº¥t, cÃ¡c mÃ´ hÃ¬nh AI nÃ³i riÃªng hay cÃ¡c (siÃªu) mÃ¡y tÃ­nh ngÃ y nay nÃ³i chung cÅ©ng khÃ´ng khÃ¡c gÃ¬ vá»›i nhá»¯ng chiáº¿c mÃ¡y tÃ­nh cá»• tá»« thá»i nhÃ  Tá»‘ng á»Ÿ 1 Ä‘iá»ƒm cá»‘t lÃµi: Chá»‰ hiá»ƒu Ä‘Æ°á»£c 2 con sá»‘ 0 vÃ  1! ÄÃºng váº­y, báº¥t ká»ƒ dá»¯ liá»‡u cÃ¡c báº¡n Ä‘Æ°a vÃ o lÃ  1 dÃ£y sá»‘ cÃ³ n chá»¯ sá»‘, vÄƒn báº£n, Ã¢m thanh, hÃ¬nh áº£nh, â€¦, mÃ¡y tÃ­nh sáº½ khÃ´ng bao giá» trá»±c tiáº¿p lÃ m viá»‡c vá»›i nhá»¯ng dá»¯ liá»‡u áº¥y, vÃ¬ Ä‘Æ¡n giáº£n lÃ  chÃºng hoÃ n toÃ n khÃ´ng hiá»ƒu nhá»¯ng dá»¯ liá»‡u nÃ y. Trong AI/Machine Learning cÅ©ng váº­y, háº§u háº¿t dá»¯ liá»‡u Ä‘á»u cáº§n pháº£i Ä‘Æ°á»£c mÃ£ hÃ³a (encoding) Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Trong video nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡c ká»¹ thuáº­t encoding cÆ¡ báº£n nháº¥t, mÃ  báº¥t cá»© ai muá»‘n tÃ¬m hiá»ƒu hay lÃ m viá»‡c trong lÄ©nh vá»±c nÃ y Ä‘á»u cáº§n pháº£i náº¯m Ä‘Æ°á»£c. NhÆ° má»i video trÆ°á»›c, mÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng trÃ¬nh bÃ y Ä‘Æ¡n giáº£n nháº¥t cÃ³ thá»ƒ. MÃ¬nh mong nháº­n Ä‘Æ°á»£c sá»± á»§ng há»™ cÅ©ng nhÆ° gÃ³p Ã½ cá»§a cÃ¡c báº¡n.
Video: https://youtu.be/2iO6vU2BCh4
#tutorial","Máº·c dÃ¹ mÃ¡y tÃ­nh ngÃ y cÃ ng trá»Ÿ nÃªn hiá»‡n Ä‘áº¡i, AI ngÃ y cÃ ng trá»Ÿ nÃªn thÃ´ng minh vÃ  Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i trÃªn má»i lÄ©nh vá»±c, thÃ¬ vá» máº·t báº£n cháº¥t, cÃ¡c mÃ´ hÃ¬nh AI nÃ³i riÃªng hay cÃ¡c (siÃªu) mÃ¡y tÃ­nh ngÃ y nay nÃ³i chung cÅ©ng khÃ´ng khÃ¡c gÃ¬ vá»›i nhá»¯ng chiáº¿c mÃ¡y tÃ­nh cá»• tá»« thá»i nhÃ  Tá»‘ng á»Ÿ 1 Ä‘iá»ƒm cá»‘t lÃµi: Chá»‰ hiá»ƒu Ä‘Æ°á»£c 2 con sá»‘ 0 vÃ  1! ÄÃºng váº­y, báº¥t ká»ƒ dá»¯ liá»‡u cÃ¡c báº¡n Ä‘Æ°a vÃ o lÃ  1 dÃ£y sá»‘ cÃ³ n chá»¯ sá»‘, vÄƒn báº£n, Ã¢m thanh, hÃ¬nh áº£nh, â€¦, mÃ¡y tÃ­nh sáº½ khÃ´ng bao giá» trá»±c tiáº¿p lÃ m viá»‡c vá»›i nhá»¯ng dá»¯ liá»‡u áº¥y, vÃ¬ Ä‘Æ¡n giáº£n lÃ  chÃºng hoÃ n toÃ n khÃ´ng hiá»ƒu nhá»¯ng dá»¯ liá»‡u nÃ y. Trong AI/Machine Learning cÅ©ng váº­y, háº§u háº¿t dá»¯ liá»‡u Ä‘á»u cáº§n pháº£i Ä‘Æ°á»£c mÃ£ hÃ³a (encoding) Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Trong video nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡c ká»¹ thuáº­t encoding cÆ¡ báº£n nháº¥t, mÃ  báº¥t cá»© ai muá»‘n tÃ¬m hiá»ƒu hay lÃ m viá»‡c trong lÄ©nh vá»±c nÃ y Ä‘á»u cáº§n pháº£i náº¯m Ä‘Æ°á»£c. NhÆ° má»i video trÆ°á»›c, mÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng trÃ¬nh bÃ y Ä‘Æ¡n giáº£n nháº¥t cÃ³ thá»ƒ. MÃ¬nh mong nháº­n Ä‘Æ°á»£c sá»± á»§ng há»™ cÅ©ng nhÆ° gÃ³p Ã½ cá»§a cÃ¡c báº¡n. Video: https://youtu.be/2iO6vU2BCh4",#tutorial,,,,
"Hi mn, hiá»‡n táº¡i e Ä‘ang lÃ m nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng model ssd mobilenetv2 nhÆ°ng gáº·p pháº£i váº¥n Ä‘á» vá» viá»‡c láº¥y ra Ä‘Æ°á»£c biá»ƒn sá»‘ xe theo thá»© tá»± chÃ­nh xÃ¡c: tá»« trÃ¡i sang pháº£i rá»“i tá»« trÃªn xuá»‘ng dÆ°á»›i. Mong má»i ngÆ°á»i cÃ³ thá»ƒ gÃ³p Ã½ giÃºp e áº¡","Hi mn, hiá»‡n táº¡i e Ä‘ang lÃ m nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng model ssd mobilenetv2 nhÆ°ng gáº·p pháº£i váº¥n Ä‘á» vá» viá»‡c láº¥y ra Ä‘Æ°á»£c biá»ƒn sá»‘ xe theo thá»© tá»± chÃ­nh xÃ¡c: tá»« trÃ¡i sang pháº£i rá»“i tá»« trÃªn xuá»‘ng dÆ°á»›i. Mong má»i ngÆ°á»i cÃ³ thá»ƒ gÃ³p Ã½ giÃºp e áº¡",,,,,
"Nay mÃ¬nh giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t cuá»‘n sÃ¡ch tiáº¿p cáº­n AI (ML, DL) theo hÆ°á»›ng hands-on, kiá»ƒu thá»±c hÃ nh chá»© khÃ´ng nhiá»u lÃ½ thuyáº¿t.
SÃ¡ch Ä‘á» cáº­p vÃ  nÃªu hÆ°á»›ng xá»­ lÃ½ Ä‘a dáº¡ng cÃ¡c bÃ i toÃ¡n tá»« xá»­ lÃ½ áº£nh: phÃ¢n loáº¡i áº£nh, nháº­n dáº¡ng váº­t thá»ƒ, cÃ¡c mÃ´ hÃ¬nh sinh,.. tá»›i cÃ¡c bÃ i toÃ¡n vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn: tÃ³m táº¯t vÄƒn báº£n, sinh chá»¯, nháº­n dáº¡ng chá»¯ cÃ¡i,...
Vá»›i má»—i chá»§ Ä‘á», sÃ¡ch nÃªu bÃ i toÃ¡n, hÆ°á»›ng tiáº¿p cáº­p, cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  code Ä‘i kÃ¨m, vÃ¬ sÃ¡ch xuáº¥t báº£n 2022 luÃ´n nÃªn cÃ¡c báº¡n khÃ´ng sá»£ code cÅ© khÃ´ng cháº¡y hoáº·c thÆ° viá»‡n bá»‹ out-of-date.","Nay mÃ¬nh giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t cuá»‘n sÃ¡ch tiáº¿p cáº­n AI (ML, DL) theo hÆ°á»›ng hands-on, kiá»ƒu thá»±c hÃ nh chá»© khÃ´ng nhiá»u lÃ½ thuyáº¿t. SÃ¡ch Ä‘á» cáº­p vÃ  nÃªu hÆ°á»›ng xá»­ lÃ½ Ä‘a dáº¡ng cÃ¡c bÃ i toÃ¡n tá»« xá»­ lÃ½ áº£nh: phÃ¢n loáº¡i áº£nh, nháº­n dáº¡ng váº­t thá»ƒ, cÃ¡c mÃ´ hÃ¬nh sinh,.. tá»›i cÃ¡c bÃ i toÃ¡n vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn: tÃ³m táº¯t vÄƒn báº£n, sinh chá»¯, nháº­n dáº¡ng chá»¯ cÃ¡i,... Vá»›i má»—i chá»§ Ä‘á», sÃ¡ch nÃªu bÃ i toÃ¡n, hÆ°á»›ng tiáº¿p cáº­p, cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  code Ä‘i kÃ¨m, vÃ¬ sÃ¡ch xuáº¥t báº£n 2022 luÃ´n nÃªn cÃ¡c báº¡n khÃ´ng sá»£ code cÅ© khÃ´ng cháº¡y hoáº·c thÆ° viá»‡n bá»‹ out-of-date.",,,,,
"Hi anh em, náº¿u anh em theo dÃµi thá»‹ trÆ°á»ng chá»©ng khoÃ¡n thÃ¬ biáº¿t rá»“i, ná»­a nÄƒm nay thá»‹ trÆ°á»ng diá»…n biáº¿n ráº¥t xáº¥u, ráº¥t nhiá»u mÃ£ chia Ä‘Ã´i, má»™t sá»‘ mÃ£ Ä‘áº·c biá»‡t nhÆ° DIG, L14 thÃ¬ tháº­m chÃ­ cÃ²n chia 10. 
Äiá»u nÃ y khÃ´ng chá»‰ áº£nh hÆ°á»Ÿng tá»›i danh má»¥c cá»§a khÃ¡ch hÃ ng, mÃ  cÃ²n áº£nh hÆ°á»Ÿng tá»›i danh má»¥c cho vay cá»§a cÃ¡c CTCK. Giáº£i thÃ­ch má»™t cÃ¡ch dá»… hiá»ƒu thÃ¬ CTCK cÃ³ nháº­n má»™t sá»‘ chá»©ng khoÃ¡n lÃ m TÃ i sáº£n Ä‘áº£m báº£o Ä‘á»ƒ phÃ¡t vay, há» sáº½ Ä‘á»‹nh giÃ¡ vÃ  cÃ³ má»™t GiÃ¡ Ä‘á»‹nh giÃ¡ theo há» lÃ  phÃ¹ há»£p. ThÃ´ng thÆ°á»ng thÃ¬ cÃ¡i giÃ¡ Ä‘á»‹nh giÃ¡ nÃ y sáº½ báº±ng khoáº£ng 1 ná»­a giÃ¡ thá»‹ trÆ°á»ng, tÃ¹y thá»i Ä‘iá»ƒm nhÆ°ng cÃ³ nghÄ©a lÃ  náº¿u cá»• phiáº¿u chia Ä‘Ã´i mÃ  chá»©ng khoÃ¡n khÃ´ng thá»ƒ bÃ¡n Ä‘Æ°á»£c, thÃ¬ CTCK máº¥t vá»‘n.
Tuy nhiÃªn, vá»›i thá»‹ trÆ°á»ng nÃ y, thÃ¬ cÃ³ láº½ khÃ´ng cÃ³ giÃ¡ Ä‘á»‹nh giÃ¡ nÃ o lÃ  phÃ¹ há»£p ná»¯a, sáº½ cÃ³ khÃ¡ nhiá»u CTCK máº¥t vá»‘n. 

MÃ¬nh hiá»‡n Ä‘ang nghiÃªn cá»©u chá»§ Ä‘á» nÃ y, bÃ i toÃ¡n Ä‘áº·t ra lÃ  quáº£n trá»‹ rá»§i ro cho danh má»¥c cho vay kÃ½ quá»¹ cá»§a CTCK. Theo mÃ¬nh suy nghÄ© thÃ¬ rá»§i ro lá»›n nháº¥t cá»§a CTCK chÃ­nh lÃ  chá»©ng khoÃ¡n khÃ´ng bÃ¡n Ä‘Æ°á»£c, nÃªn ta pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c:
Nhá»¯ng chá»©ng khoÃ¡n nÃ o thanh khoáº£n áº£o, khi thá»‹ trÆ°á»ng xáº¥u lÃ  khÃ´ng ai thÃ¨m mua.
Má»©c dá»± kiáº¿n lá»— tá»‘i Ä‘a cho tá»«ng mÃ£ chá»©ng khoÃ¡n
XÃ¡c suáº¥t máº¥t vá»‘n abc xyz
CÃ³ báº¡n nÃ o Ä‘Ã£ tá»«ng lÃ m cÃ³ thá»ƒ chia sáº» kinh nghiá»‡m / gá»£i Ã½ / cho keywords Ä‘á»ƒ tÃ¬m hiá»ƒu Ä‘Æ°á»£c khÃ´ng áº¡. Náº¿u Ä‘Æ°á»£c tham kháº£o code vÃ  model thÃ¬ tá»‘t quÃ¡.

Xin cáº£m Æ¡n anh em Ä‘Ã£ Ä‘á»c máº¥y dÃ²ng lan man.","Hi anh em, náº¿u anh em theo dÃµi thá»‹ trÆ°á»ng chá»©ng khoÃ¡n thÃ¬ biáº¿t rá»“i, ná»­a nÄƒm nay thá»‹ trÆ°á»ng diá»…n biáº¿n ráº¥t xáº¥u, ráº¥t nhiá»u mÃ£ chia Ä‘Ã´i, má»™t sá»‘ mÃ£ Ä‘áº·c biá»‡t nhÆ° DIG, L14 thÃ¬ tháº­m chÃ­ cÃ²n chia 10. Äiá»u nÃ y khÃ´ng chá»‰ áº£nh hÆ°á»Ÿng tá»›i danh má»¥c cá»§a khÃ¡ch hÃ ng, mÃ  cÃ²n áº£nh hÆ°á»Ÿng tá»›i danh má»¥c cho vay cá»§a cÃ¡c CTCK. Giáº£i thÃ­ch má»™t cÃ¡ch dá»… hiá»ƒu thÃ¬ CTCK cÃ³ nháº­n má»™t sá»‘ chá»©ng khoÃ¡n lÃ m TÃ i sáº£n Ä‘áº£m báº£o Ä‘á»ƒ phÃ¡t vay, há» sáº½ Ä‘á»‹nh giÃ¡ vÃ  cÃ³ má»™t GiÃ¡ Ä‘á»‹nh giÃ¡ theo há» lÃ  phÃ¹ há»£p. ThÃ´ng thÆ°á»ng thÃ¬ cÃ¡i giÃ¡ Ä‘á»‹nh giÃ¡ nÃ y sáº½ báº±ng khoáº£ng 1 ná»­a giÃ¡ thá»‹ trÆ°á»ng, tÃ¹y thá»i Ä‘iá»ƒm nhÆ°ng cÃ³ nghÄ©a lÃ  náº¿u cá»• phiáº¿u chia Ä‘Ã´i mÃ  chá»©ng khoÃ¡n khÃ´ng thá»ƒ bÃ¡n Ä‘Æ°á»£c, thÃ¬ CTCK máº¥t vá»‘n. Tuy nhiÃªn, vá»›i thá»‹ trÆ°á»ng nÃ y, thÃ¬ cÃ³ láº½ khÃ´ng cÃ³ giÃ¡ Ä‘á»‹nh giÃ¡ nÃ o lÃ  phÃ¹ há»£p ná»¯a, sáº½ cÃ³ khÃ¡ nhiá»u CTCK máº¥t vá»‘n. MÃ¬nh hiá»‡n Ä‘ang nghiÃªn cá»©u chá»§ Ä‘á» nÃ y, bÃ i toÃ¡n Ä‘áº·t ra lÃ  quáº£n trá»‹ rá»§i ro cho danh má»¥c cho vay kÃ½ quá»¹ cá»§a CTCK. Theo mÃ¬nh suy nghÄ© thÃ¬ rá»§i ro lá»›n nháº¥t cá»§a CTCK chÃ­nh lÃ  chá»©ng khoÃ¡n khÃ´ng bÃ¡n Ä‘Æ°á»£c, nÃªn ta pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c: Nhá»¯ng chá»©ng khoÃ¡n nÃ o thanh khoáº£n áº£o, khi thá»‹ trÆ°á»ng xáº¥u lÃ  khÃ´ng ai thÃ¨m mua. Má»©c dá»± kiáº¿n lá»— tá»‘i Ä‘a cho tá»«ng mÃ£ chá»©ng khoÃ¡n XÃ¡c suáº¥t máº¥t vá»‘n abc xyz CÃ³ báº¡n nÃ o Ä‘Ã£ tá»«ng lÃ m cÃ³ thá»ƒ chia sáº» kinh nghiá»‡m / gá»£i Ã½ / cho keywords Ä‘á»ƒ tÃ¬m hiá»ƒu Ä‘Æ°á»£c khÃ´ng áº¡. Náº¿u Ä‘Æ°á»£c tham kháº£o code vÃ  model thÃ¬ tá»‘t quÃ¡. Xin cáº£m Æ¡n anh em Ä‘Ã£ Ä‘á»c máº¥y dÃ²ng lan man.",,,,,
"ChÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin hÆ°á»›ng Ä‘i cho bÃ i toÃ¡n tÃ¬m há»‡ sá»‘ cá»§a há»‡ phÆ°Æ¡ng trÃ¬nh vi phÃ¢n tuyáº¿n tÃ­nh dÆ°á»›i Ä‘Ã¢y Ä‘Æ°á»£c khÃ´ng áº¡.
Cá»¥ thá»ƒ nhÆ° sau: Cho dataset 1000 bá»™ (R, J) vá»›i time step = 0.001 TÃ¬m a, b, c, d trong há»‡ bÃªn dÆ°á»›i thá»a dataset vÃ  R(0) = -2, J(0) = 3. Biáº¿t dataset cÃ³ vÃ i dá»¯ liá»‡u nhiá»…u.","ChÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin hÆ°á»›ng Ä‘i cho bÃ i toÃ¡n tÃ¬m há»‡ sá»‘ cá»§a há»‡ phÆ°Æ¡ng trÃ¬nh vi phÃ¢n tuyáº¿n tÃ­nh dÆ°á»›i Ä‘Ã¢y Ä‘Æ°á»£c khÃ´ng áº¡. Cá»¥ thá»ƒ nhÆ° sau: Cho dataset 1000 bá»™ (R, J) vá»›i time step = 0.001 TÃ¬m a, b, c, d trong há»‡ bÃªn dÆ°á»›i thá»a dataset vÃ  R(0) = -2, J(0) = 3. Biáº¿t dataset cÃ³ vÃ i dá»¯ liá»‡u nhiá»…u.",,,,,
"Em chÃ o anh chá»‹ áº¡,
Em xin phÃ©p nhá» anh chá»‹ tÆ° váº¥n má»™t chÃºt vá» váº¥n Ä‘á» há»c tháº¡c sÄ© khoa há»c dá»¯ liá»‡u vá»›i áº¡:
Em Ä‘ang cÃ³ dá»± Ä‘á»‹nh há»c táº¡i tháº¡c sÄ© ngÃ nh khoa há»c dá»¯ liá»‡u táº¡i Viá»‡t Nam, hiá»‡n táº¡i em tháº¥y cÃ³ 2 trÆ°á»ng lÃ  trÆ°á»ng Ä‘áº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  trÆ°á»ng Ä‘áº¡i há»c Quá»‘c Gia HÃ  Ná»™i. Anh chá»‹ cÃ³ thá»ƒ tÆ° váº¥n giÃºp em lá»±a chá»n nÃ o sáº½ lÃ  tá»‘t hÆ¡n khÃ´ng áº¡? Hoáº·c náº¿u anh chá»‹ cÃ³ má»™t trÆ°á»ng nÃ o khÃ¡c cÃ³ ngÃ nh tháº¡c sÄ© khoa há»c dá»¯ liá»‡u tá»‘t cÃ³ thá»ƒ cho em má»™t chÃºt gá»£i Ã½ cÅ©ng Ä‘Æ°á»£c áº¡
Trong thá»i gian há»c Ä‘áº¡i há»c chuyÃªn ngÃ nh cá»§a em lÃ  TÃ i ChÃ­nh NgÃ¢n HÃ ng, hiá»‡n táº¡i em Ä‘ang lÃ m modeling trong bank. Váº­y vá»›i background nÃ y em sáº½ gáº·p nhá»¯ng khÃ³ khÄƒn gÃ¬ khi theo há»c tháº¡c sÄ© chuyÃªn ngÃ nh khoa há»c dá»¯ liá»‡u nÃ y áº¡. VÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kháº¯c phá»¥c khÃ´ng áº¡.
Mong nháº­n Ä‘Æ°á»£c sá»± tÆ° váº¥n cá»§a anh chá»‹. Em cáº£m Æ¡n anh chá»‹ áº¡","Em chÃ o anh chá»‹ áº¡, Em xin phÃ©p nhá» anh chá»‹ tÆ° váº¥n má»™t chÃºt vá» váº¥n Ä‘á» há»c tháº¡c sÄ© khoa há»c dá»¯ liá»‡u vá»›i áº¡: Em Ä‘ang cÃ³ dá»± Ä‘á»‹nh há»c táº¡i tháº¡c sÄ© ngÃ nh khoa há»c dá»¯ liá»‡u táº¡i Viá»‡t Nam, hiá»‡n táº¡i em tháº¥y cÃ³ 2 trÆ°á»ng lÃ  trÆ°á»ng Ä‘áº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  trÆ°á»ng Ä‘áº¡i há»c Quá»‘c Gia HÃ  Ná»™i. Anh chá»‹ cÃ³ thá»ƒ tÆ° váº¥n giÃºp em lá»±a chá»n nÃ o sáº½ lÃ  tá»‘t hÆ¡n khÃ´ng áº¡? Hoáº·c náº¿u anh chá»‹ cÃ³ má»™t trÆ°á»ng nÃ o khÃ¡c cÃ³ ngÃ nh tháº¡c sÄ© khoa há»c dá»¯ liá»‡u tá»‘t cÃ³ thá»ƒ cho em má»™t chÃºt gá»£i Ã½ cÅ©ng Ä‘Æ°á»£c áº¡ Trong thá»i gian há»c Ä‘áº¡i há»c chuyÃªn ngÃ nh cá»§a em lÃ  TÃ i ChÃ­nh NgÃ¢n HÃ ng, hiá»‡n táº¡i em Ä‘ang lÃ m modeling trong bank. Váº­y vá»›i background nÃ y em sáº½ gáº·p nhá»¯ng khÃ³ khÄƒn gÃ¬ khi theo há»c tháº¡c sÄ© chuyÃªn ngÃ nh khoa há»c dá»¯ liá»‡u nÃ y áº¡. VÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kháº¯c phá»¥c khÃ´ng áº¡. Mong nháº­n Ä‘Æ°á»£c sá»± tÆ° váº¥n cá»§a anh chá»‹. Em cáº£m Æ¡n anh chá»‹ áº¡",,,,,
"E chÃ o a/c, chÃºc a/c Ä‘áº§u tuáº§n nghiÃªn cá»©u hÄƒng say, hiá»‡u quáº£. NhÃ¢n tiá»‡n báº¯t Ä‘áº§u cho e xin há»i trá»ng máº¡ng ResNet50, 2 khá»‘i conv vÃ  identity e tháº¥y cÃ³ khÃ¡c gÃ¬ nhau Ä‘Ã¢u nhá»‰, má»—i á»Ÿ conv cÃ³ thÃªm conv á»Ÿ Ä‘Æ°á»ng táº¯t, váº­y Ã½ nghÄ©a 2 khá»‘i nÃ y lÃ m gÃ¬ áº¡, sao pháº£i tÃ¡ch lÃ m 2 vÃ  phÃ¢n biá»‡t tÃªn tháº¿ áº¡. E cáº£m Æ¡n!","E chÃ o a/c, chÃºc a/c Ä‘áº§u tuáº§n nghiÃªn cá»©u hÄƒng say, hiá»‡u quáº£. NhÃ¢n tiá»‡n báº¯t Ä‘áº§u cho e xin há»i trá»ng máº¡ng ResNet50, 2 khá»‘i conv vÃ  identity e tháº¥y cÃ³ khÃ¡c gÃ¬ nhau Ä‘Ã¢u nhá»‰, má»—i á»Ÿ conv cÃ³ thÃªm conv á»Ÿ Ä‘Æ°á»ng táº¯t, váº­y Ã½ nghÄ©a 2 khá»‘i nÃ y lÃ m gÃ¬ áº¡, sao pháº£i tÃ¡ch lÃ m 2 vÃ  phÃ¢n biá»‡t tÃªn tháº¿ áº¡. E cáº£m Æ¡n!",,,,,
"ChÃ o táº¥t cáº£ Anh/Chá»‹/Em
MÃ¬nh training 1 model vá»›i má»¥c Ä‘Ã­ch image segmentation cho 2 lá»›p ( 1 lá»›p background vÃ  1 lá»›p bÃ³ng cá»§a cÃ¢y cá»‘i). Sau khi train 200 epochs thÃ¬ thu Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c IoU nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y. MÃ¬nh tháº¥y dcx giao Ä‘á»™ng ráº¥t nhiá»u, vÃ  ngÃ y cÃ ng Ä‘i xuá»‘ng. Váº­y theo nhÆ° kinh nghiá»‡m cá»§a má»i ngÆ°á»i thÃ¬ nguyÃªn nhÃ¢n do Ä‘Ã¢u vÃ  vui lÃ²ng gá»£i Ã½ cÃ¡ch kháº¯c phá»¥c giÃºp mÃ¬nh nhÃ©.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c vÃ  chia sáº» <3","ChÃ o táº¥t cáº£ Anh/Chá»‹/Em MÃ¬nh training 1 model vá»›i má»¥c Ä‘Ã­ch image segmentation cho 2 lá»›p ( 1 lá»›p background vÃ  1 lá»›p bÃ³ng cá»§a cÃ¢y cá»‘i). Sau khi train 200 epochs thÃ¬ thu Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c IoU nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y. MÃ¬nh tháº¥y dcx giao Ä‘á»™ng ráº¥t nhiá»u, vÃ  ngÃ y cÃ ng Ä‘i xuá»‘ng. Váº­y theo nhÆ° kinh nghiá»‡m cá»§a má»i ngÆ°á»i thÃ¬ nguyÃªn nhÃ¢n do Ä‘Ã¢u vÃ  vui lÃ²ng gá»£i Ã½ cÃ¡ch kháº¯c phá»¥c giÃºp mÃ¬nh nhÃ©. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c vÃ  chia sáº» <3",,,,,
"NgÃ y nay, khi cÃ¡c mÃ´ hÃ¬nh vá» AI Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao vá»›i cÃ¡c káº¿t quáº£ ráº¥t áº¥n tÆ°á»£ng, thÃ¬ váº¥n Ä‘á» giáº£i thÃ­ch mÃ´ hÃ¬nh cÃ ng Ä‘Æ°á»£c chÃº trá»ng hÆ¡n. Trong workshop nÃ y, giÃ¡o sÆ° Hima Lakkaraju, tá»« Ä‘áº¡i há»c Harvard chia sáº» vá» cÃ¡c kÄ© thuáº­t interpretable machine learning tá»« Ä‘Ã³ giÃºp giáº£i thÃ­ch, xÃ¡c Ä‘á»‹nh lá»—i cá»§a mÃ´ hÃ¬nh cÅ©ng nhÆ° xÃ¢y dá»±ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh tá»‘t hÆ¡n.

BÃ i giáº£ng: https://lnkd.in/gzfmJug9
Slide: https://lnkd.in/e_RsBVPx","NgÃ y nay, khi cÃ¡c mÃ´ hÃ¬nh vá» AI Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao vá»›i cÃ¡c káº¿t quáº£ ráº¥t áº¥n tÆ°á»£ng, thÃ¬ váº¥n Ä‘á» giáº£i thÃ­ch mÃ´ hÃ¬nh cÃ ng Ä‘Æ°á»£c chÃº trá»ng hÆ¡n. Trong workshop nÃ y, giÃ¡o sÆ° Hima Lakkaraju, tá»« Ä‘áº¡i há»c Harvard chia sáº» vá» cÃ¡c kÄ© thuáº­t interpretable machine learning tá»« Ä‘Ã³ giÃºp giáº£i thÃ­ch, xÃ¡c Ä‘á»‹nh lá»—i cá»§a mÃ´ hÃ¬nh cÅ©ng nhÆ° xÃ¢y dá»±ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh tá»‘t hÆ¡n. BÃ i giáº£ng: https://lnkd.in/gzfmJug9 Slide: https://lnkd.in/e_RsBVPx",,,,,
"CÃ¡ch Ä‘Ã¢y trÃ²n 6 nÄƒm, vÃ o thÃ¡ng 11/2016, Quick, Draw! - trÃ² chÆ¡i trá»±c tuyáº¿n dá»±a trÃªn neural network Ä‘Ã£ Ä‘Æ°á»£c Google cho ra máº¯t. ÄÃ¢y cÅ©ng Ä‘á»“ng thá»i lÃ  tÃªn bá»™ dá»¯ liá»‡u khá»•ng lá»“ vá»›i 50 triá»‡u báº£n váº½ tay cá»§a ngÆ°á»i dÃ¹ng trÃªn kháº¯p tháº¿ giá»›i Ä‘Æ°á»£c Google chia sáº» cÃ´ng khai. Ngay tá»« thá»i Ä‘iá»ƒm má»›i ra máº¯t, Quick, Draw! Ä‘Ã£ táº¡o nÃªn 1 cÆ¡n sá»‘t vÃ´ cÃ¹ng lá»›n trÃªn kháº¯p cÃ¡c diá»…n Ä‘Ã n cÅ©ng nhÆ° máº¡ng xÃ£ há»™i vá» AI nhÆ° reddit, twitter, linkedin. NhÃ¢n dá»‹p ká»· niá»‡m Quick, Draw! 6 nÄƒm tuá»•i, mÃ¬nh lÃ m video demo nÃ y vá»›i AI model Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i Quick, Draw!. Äá»“ng thá»i mÃ¬nh cÅ©ng sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡ch lÃ m viá»‡c vá»›i bá»™ dataset vÃ´ cÃ¹ng thÃº vá»‹ nÃ y

Video: https://youtu.be/b8aJGt56b74
#AI #QuickDraw","CÃ¡ch Ä‘Ã¢y trÃ²n 6 nÄƒm, vÃ o thÃ¡ng 11/2016, Quick, Draw! - trÃ² chÆ¡i trá»±c tuyáº¿n dá»±a trÃªn neural network Ä‘Ã£ Ä‘Æ°á»£c Google cho ra máº¯t. ÄÃ¢y cÅ©ng Ä‘á»“ng thá»i lÃ  tÃªn bá»™ dá»¯ liá»‡u khá»•ng lá»“ vá»›i 50 triá»‡u báº£n váº½ tay cá»§a ngÆ°á»i dÃ¹ng trÃªn kháº¯p tháº¿ giá»›i Ä‘Æ°á»£c Google chia sáº» cÃ´ng khai. Ngay tá»« thá»i Ä‘iá»ƒm má»›i ra máº¯t, Quick, Draw! Ä‘Ã£ táº¡o nÃªn 1 cÆ¡n sá»‘t vÃ´ cÃ¹ng lá»›n trÃªn kháº¯p cÃ¡c diá»…n Ä‘Ã n cÅ©ng nhÆ° máº¡ng xÃ£ há»™i vá» AI nhÆ° reddit, twitter, linkedin. NhÃ¢n dá»‹p ká»· niá»‡m Quick, Draw! 6 nÄƒm tuá»•i, mÃ¬nh lÃ m video demo nÃ y vá»›i AI model Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i Quick, Draw!. Äá»“ng thá»i mÃ¬nh cÅ©ng sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡ch lÃ m viá»‡c vá»›i bá»™ dataset vÃ´ cÃ¹ng thÃº vá»‹ nÃ y Video: https://youtu.be/b8aJGt56b74",#AI	#QuickDraw,,,,
"ChÃ o má»i ngÆ°á»i. HÃ´m nay mÃ¬nh muá»‘n chia sáº» vá»›i má»i ngÆ°á»i mÃ´ hÃ¬nh há»c tá»± giÃ¡m sÃ¡t (self-supervised) cho dá»¯ liá»‡u audio dá»±a trÃªn kiáº¿n trÃºc wav2vec2. MÃ´ hÃ¬nh nÃ y mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n sá»­ dá»¥ng 13 nghÃ¬n giá» dá»¯ liá»‡u youtube vá»›i Ä‘a dáº¡ng cÃ¡c loáº¡i Ã¢m thanh nhÆ° (clean, noisy, conversation, dialects,..). MÃ´ hÃ¬nh nÃ y mÃ¬nh Ä‘Ã£ thá»­ nghiá»‡m vÃ  cho káº¿t quáº£ ráº¥t tá»‘t cho bÃ i toÃ¡n nháº­n dáº¡ng tiáº¿ng nÃ³i. Hi vá»ng sáº½ giÃºp Ã­ch cho má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i. HÃ´m nay mÃ¬nh muá»‘n chia sáº» vá»›i má»i ngÆ°á»i mÃ´ hÃ¬nh há»c tá»± giÃ¡m sÃ¡t (self-supervised) cho dá»¯ liá»‡u audio dá»±a trÃªn kiáº¿n trÃºc wav2vec2. MÃ´ hÃ¬nh nÃ y mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n sá»­ dá»¥ng 13 nghÃ¬n giá» dá»¯ liá»‡u youtube vá»›i Ä‘a dáº¡ng cÃ¡c loáº¡i Ã¢m thanh nhÆ° (clean, noisy, conversation, dialects,..). MÃ´ hÃ¬nh nÃ y mÃ¬nh Ä‘Ã£ thá»­ nghiá»‡m vÃ  cho káº¿t quáº£ ráº¥t tá»‘t cho bÃ i toÃ¡n nháº­n dáº¡ng tiáº¿ng nÃ³i. Hi vá»ng sáº½ giÃºp Ã­ch cho má»i ngÆ°á»i.",,,,,
"Em chÃ o anh chá»‹ áº¡, em cÃ³ 1 tháº¯c máº¯c lÃ  khÃ´ng biáº¿t trong cÃ¡c dá»± Ã¡n AI, Computer vision thÃ¬ C/C++ cÃ³ vai trÃ² gÃ¬ váº­y áº¡. VÃ  cÃ³ liÃªn há»‡ gÃ¬ giá»¯a nhÃºng vÃ  Ai áº¡.","Em chÃ o anh chá»‹ áº¡, em cÃ³ 1 tháº¯c máº¯c lÃ  khÃ´ng biáº¿t trong cÃ¡c dá»± Ã¡n AI, Computer vision thÃ¬ C/C++ cÃ³ vai trÃ² gÃ¬ váº­y áº¡. VÃ  cÃ³ liÃªn há»‡ gÃ¬ giá»¯a nhÃºng vÃ  Ai áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i,
Liá»‡u mÃ¬nh cÃ³ thá»ƒ cháº¡y model inference vá»›i nhiá»u CPU khÃ´ng nhá»‰, mÃ¬nh cÃ³ 1 pretrained model vÃ  muá»‘n dá»± Ä‘oÃ¡n label cá»§a nhiá»u bá»©c áº£nh má»™t cÃ¡ch song song. Náº¿u Ä‘Æ°á»£c thÃ¬ lÃ m tháº¿ cÃ³ nhanh hÆ¡n so vá»›i viá»‡c dÃ¹ng 1 CPU duy nháº¥t khÃ´ng.
MÃ¬nh Ä‘Ã£ thá»­ search google nhÆ°ng ko tÃ¬m Ä‘Æ°á»£c cÃ¢u tráº£ lá»i rÃµ rÃ ng. Báº¡n nÃ o cÃ³ kinh nghiá»‡m implement rá»“i cho mÃ¬nh chÃºt gá»£i Ã½.
Cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i, Liá»‡u mÃ¬nh cÃ³ thá»ƒ cháº¡y model inference vá»›i nhiá»u CPU khÃ´ng nhá»‰, mÃ¬nh cÃ³ 1 pretrained model vÃ  muá»‘n dá»± Ä‘oÃ¡n label cá»§a nhiá»u bá»©c áº£nh má»™t cÃ¡ch song song. Náº¿u Ä‘Æ°á»£c thÃ¬ lÃ m tháº¿ cÃ³ nhanh hÆ¡n so vá»›i viá»‡c dÃ¹ng 1 CPU duy nháº¥t khÃ´ng. MÃ¬nh Ä‘Ã£ thá»­ search google nhÆ°ng ko tÃ¬m Ä‘Æ°á»£c cÃ¢u tráº£ lá»i rÃµ rÃ ng. Báº¡n nÃ o cÃ³ kinh nghiá»‡m implement rá»“i cho mÃ¬nh chÃºt gá»£i Ã½. Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Cáº§n láº¯m 1 chiáº¿n há»¯u láº­p team thi Zalo AI Challenge 2022. NÄƒm nay giáº£i thÆ°á»Ÿng tiáº¿p tá»¥c siÃªu to khá»•ng lá»“, giáº£i nháº¥t táº§m 90tr. Em thi Ä‘á»ƒ tiá»‡n há»‘t luÃ´n bá»™ data cá»§a Zalo
Äá» thi nÄƒm nay Ä‘Ã¢y áº¡:
E2E Question Answering - tÃ¬m cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c nháº¥t tá»« Wikipedia cho má»™t cÃ¢u há»
Liveness Detection - xÃ¡c Ä‘á»‹nh khuÃ´n máº·t ngÆ°á»i trong video lÃ  tháº­t hay giáº£ máº¡o
Lyric Alignment - lÃ m lá»i bÃ i hÃ¡t trÃ¹ng khá»›p vá»›i nháº¡c.","Cáº§n láº¯m 1 chiáº¿n há»¯u láº­p team thi Zalo AI Challenge 2022. NÄƒm nay giáº£i thÆ°á»Ÿng tiáº¿p tá»¥c siÃªu to khá»•ng lá»“, giáº£i nháº¥t táº§m 90tr. Em thi Ä‘á»ƒ tiá»‡n há»‘t luÃ´n bá»™ data cá»§a Zalo Äá» thi nÄƒm nay Ä‘Ã¢y áº¡: E2E Question Answering - tÃ¬m cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c nháº¥t tá»« Wikipedia cho má»™t cÃ¢u há» Liveness Detection - xÃ¡c Ä‘á»‹nh khuÃ´n máº·t ngÆ°á»i trong video lÃ  tháº­t hay giáº£ máº¡o Lyric Alignment - lÃ m lá»i bÃ i hÃ¡t trÃ¹ng khá»›p vá»›i nháº¡c.",,,,,
"Hi mng, mÃ¬nh lÃ  tv má»›i. Mng cho mÃ¬nh há»i vá»›i cÃ¡c projects ML sau khi Ä‘Æ°á»£c táº¡o ra thÃ¬ sáº½ push lÃªn production ntn váº­y áº¡? Cá»¥ thá»ƒ nhÆ° má»™t project Ä‘Æ°á»£c viáº¿t trÃªn Jupyter notebook thÃ¬ sau khi xong thÃ¬ mÃ¬nh Ã¡p dá»¥ng ntn vÃ o thá»±c táº¿ áº¡? Táº¡i vÃ¬ trÆ°á»›c Ä‘Ã¢y mÃ¬nh chá»‰ táº¡o model -> cháº¡y káº¿t quáº£ -> lÃ m nghiÃªn cá»©u nÃªn cÃ²n mÆ¡ há»“ lÃ  nÃ³ sáº½ Ã¡p dá»¥ng vÃ o thá»±c táº¿ ntn áº¡? tks all!","Hi mng, mÃ¬nh lÃ  tv má»›i. Mng cho mÃ¬nh há»i vá»›i cÃ¡c projects ML sau khi Ä‘Æ°á»£c táº¡o ra thÃ¬ sáº½ push lÃªn production ntn váº­y áº¡? Cá»¥ thá»ƒ nhÆ° má»™t project Ä‘Æ°á»£c viáº¿t trÃªn Jupyter notebook thÃ¬ sau khi xong thÃ¬ mÃ¬nh Ã¡p dá»¥ng ntn vÃ o thá»±c táº¿ áº¡? Táº¡i vÃ¬ trÆ°á»›c Ä‘Ã¢y mÃ¬nh chá»‰ táº¡o model -> cháº¡y káº¿t quáº£ -> lÃ m nghiÃªn cá»©u nÃªn cÃ²n mÆ¡ há»“ lÃ  nÃ³ sáº½ Ã¡p dá»¥ng vÃ o thá»±c táº¿ ntn áº¡? tks all!",,,,,
Cho mÃ¬nh há»i cÃ³ ai biáº¿t thÆ° viá»‡n hoáº·c code nÃ o thá»±c hiá»‡n word alignment tá»‘t cho anh-viá»‡t khÃ´ng. MÃ¬nh cáº£m Æ¡n.,Cho mÃ¬nh há»i cÃ³ ai biáº¿t thÆ° viá»‡n hoáº·c code nÃ o thá»±c hiá»‡n word alignment tá»‘t cho anh-viá»‡t khÃ´ng. MÃ¬nh cáº£m Æ¡n.,,,,,
"CÃ¡ch Ä‘Ã¢y hai nÄƒm mÃ¬nh cÃ³ viáº¿t má»™t bÃ i vá» T-Shaped Skills cho Data Scientist. Tuy nhiÃªn trong quÃ¡ trÃ¬nh lÃ m viá»‡c, mÃ¬nh nháº­n tháº¥y lÄ©nh vá»±c nÃ y Ä‘Ã£ thay Ä‘á»•i ráº¥t nhiá»u so vá»›i hai nÄƒm trÆ°á»›c. Sau khi trao Ä‘á»•i vá»›i nhiá»u cÃ´ng ty khÃ¡c nhau á»Ÿ Ãšc, mÃ¬nh cÃ ng má»™t láº§n ná»¯a tháº¥y rÃµ Ä‘a pháº§n má»i ngÆ°á»i Ä‘ang Ä‘i theo má»™t chiá»u hÆ°á»›ng phÃ¡t triá»ƒn chung vá»›i tá»‘c Ä‘á»™ khÃ¡ giá»‘ng nhau vÃ  gáº·p nhá»¯ng váº¥n Ä‘á» tÆ°Æ¡ng tá»± nhau. Trong bÃ i viáº¿t nÃ y mÃ¬nh sáº½ refresh láº¡i cÃ¡i nhÃ¬n vá» lÄ©nh vá»±c Data Science vÃ  chia sáº» nhá»¯ng con Ä‘Æ°á»ng khÃ¡c nhau Ä‘á»ƒ cÃ¡c báº¡n chuáº©n bá»‹.
https://datasciencevn.com/chuyen-nghe/146-xu-huong-phat-trien-cua-nganh-data-science-va-ban-nen-hoc-gi-de-chuan-bi.html?fbclid=IwAR1x1snLjUVL4KCzQ1TYeIAFGu3Opmt1KsP_KrDzoEN-wVGbLKLRSKD6L0g","CÃ¡ch Ä‘Ã¢y hai nÄƒm mÃ¬nh cÃ³ viáº¿t má»™t bÃ i vá» T-Shaped Skills cho Data Scientist. Tuy nhiÃªn trong quÃ¡ trÃ¬nh lÃ m viá»‡c, mÃ¬nh nháº­n tháº¥y lÄ©nh vá»±c nÃ y Ä‘Ã£ thay Ä‘á»•i ráº¥t nhiá»u so vá»›i hai nÄƒm trÆ°á»›c. Sau khi trao Ä‘á»•i vá»›i nhiá»u cÃ´ng ty khÃ¡c nhau á»Ÿ Ãšc, mÃ¬nh cÃ ng má»™t láº§n ná»¯a tháº¥y rÃµ Ä‘a pháº§n má»i ngÆ°á»i Ä‘ang Ä‘i theo má»™t chiá»u hÆ°á»›ng phÃ¡t triá»ƒn chung vá»›i tá»‘c Ä‘á»™ khÃ¡ giá»‘ng nhau vÃ  gáº·p nhá»¯ng váº¥n Ä‘á» tÆ°Æ¡ng tá»± nhau. Trong bÃ i viáº¿t nÃ y mÃ¬nh sáº½ refresh láº¡i cÃ¡i nhÃ¬n vá» lÄ©nh vá»±c Data Science vÃ  chia sáº» nhá»¯ng con Ä‘Æ°á»ng khÃ¡c nhau Ä‘á»ƒ cÃ¡c báº¡n chuáº©n bá»‹. https://datasciencevn.com/chuyen-nghe/146-xu-huong-phat-trien-cua-nganh-data-science-va-ban-nen-hoc-gi-de-chuan-bi.html?fbclid=IwAR1x1snLjUVL4KCzQ1TYeIAFGu3Opmt1KsP_KrDzoEN-wVGbLKLRSKD6L0g",,,,,
"MÃ¬nh Ä‘ang cÃ³ project OCR Ä‘á»c bill hÃ³a Ä‘Æ¡n, sau khi Ä‘á»c xong thÃ¬ tÃªn sáº£n pháº©m bá»‹ sai hoáº·c bá»‹ thiáº¿u. CÃ¡c báº¡n cÃ³ kinh nghiá»‡m chá»‰ giÃºp mÃ¬nh key,giáº£i phÃ¡p lÃ m sao Ä‘á»ƒ ra Ä‘Ãºng tÃªn sáº£n pháº©m vs áº¡. xin cáº£m Æ¡n!","MÃ¬nh Ä‘ang cÃ³ project OCR Ä‘á»c bill hÃ³a Ä‘Æ¡n, sau khi Ä‘á»c xong thÃ¬ tÃªn sáº£n pháº©m bá»‹ sai hoáº·c bá»‹ thiáº¿u. CÃ¡c báº¡n cÃ³ kinh nghiá»‡m chá»‰ giÃºp mÃ¬nh key,giáº£i phÃ¡p lÃ m sao Ä‘á»ƒ ra Ä‘Ãºng tÃªn sáº£n pháº©m vs áº¡. xin cáº£m Æ¡n!",,,,,
"CÃ¡c bÃ¡c cho em há»i: Em tÃ­nh dÃ¹ng AI tÃ¬m cÃ¡c hÃ¬nh trÃ²n, hÃ¬nh vuÃ´ng, Ä‘Æ°á»ng káº» trÃªn phiáº¿u tráº¯c nghiá»‡m á»Ÿ Mobile. Em tháº¥y báº£o lÃ  AI tÃ¬m sáº½ lÃ¢u vÃ  khÃ´ng phÃ¹ há»£p do cháº¥m tráº¯c nghiá»‡m cáº§n tgian <= 2 giÃ¢y.
CÃ¡c bÃ¡c tháº¥y phÆ°Æ¡ng Ã¡n AI nÃ o kháº£ thi ko áº¡?","CÃ¡c bÃ¡c cho em há»i: Em tÃ­nh dÃ¹ng AI tÃ¬m cÃ¡c hÃ¬nh trÃ²n, hÃ¬nh vuÃ´ng, Ä‘Æ°á»ng káº» trÃªn phiáº¿u tráº¯c nghiá»‡m á»Ÿ Mobile. Em tháº¥y báº£o lÃ  AI tÃ¬m sáº½ lÃ¢u vÃ  khÃ´ng phÃ¹ há»£p do cháº¥m tráº¯c nghiá»‡m cáº§n tgian <= 2 giÃ¢y. CÃ¡c bÃ¡c tháº¥y phÆ°Æ¡ng Ã¡n AI nÃ o kháº£ thi ko áº¡?",,,,,
"Xin chÃ o anh chá»‹, em lÃ  sinh viÃªn cdt sáº¯p tá»‘t nghiá»‡p Ä‘áº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  lÃ  ngoáº¡i Ä‘áº¡o,há»c AI Ä‘Ã£ Ä‘Æ°á»£c 1 nÄƒm, em Ä‘ang tÃ¬m kiáº¿m vá»‹ trÃ­ fresher AI táº¡i HÃ  Ná»™i mÃ  tháº¥y cÃ¡c job toÃ n yÃªu cáº§u Ã­t nháº¥t 1 nÄƒm kinh nghiá»‡m Em mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn cá»§a anh chá»‹, em cam Æ¡n ráº¥t nhiá»u áº¡","Xin chÃ o anh chá»‹, em lÃ  sinh viÃªn cdt sáº¯p tá»‘t nghiá»‡p Ä‘áº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  lÃ  ngoáº¡i Ä‘áº¡o,há»c AI Ä‘Ã£ Ä‘Æ°á»£c 1 nÄƒm, em Ä‘ang tÃ¬m kiáº¿m vá»‹ trÃ­ fresher AI táº¡i HÃ  Ná»™i mÃ  tháº¥y cÃ¡c job toÃ n yÃªu cáº§u Ã­t nháº¥t 1 nÄƒm kinh nghiá»‡m Em mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn cá»§a anh chá»‹, em cam Æ¡n ráº¥t nhiá»u áº¡",,,,,
"Em hiá»‡n táº¡i Ä‘ang cÃ³ bÃ i táº­p vá» dá»± Ä‘oÃ¡n giÃ¡ sim theo dá»¯ liá»‡u cho trÆ°á»›c. MÃ¬nh nÃªn phÃ¢n loáº¡i cÃ¡c thuá»™c tÃ­nh sim nhÆ° tháº¿ nÃ o áº¡, má»i ngÆ°á»i cÃ³ cÃ¡ch tiáº¿p cáº­n nÃ o khÃ´ng áº¡","Em hiá»‡n táº¡i Ä‘ang cÃ³ bÃ i táº­p vá» dá»± Ä‘oÃ¡n giÃ¡ sim theo dá»¯ liá»‡u cho trÆ°á»›c. MÃ¬nh nÃªn phÃ¢n loáº¡i cÃ¡c thuá»™c tÃ­nh sim nhÆ° tháº¿ nÃ o áº¡, má»i ngÆ°á»i cÃ³ cÃ¡ch tiáº¿p cáº­n nÃ o khÃ´ng áº¡",,,,,
"CÃ¡c ban Æ¡i, mÃ¬nh Ä‘ang nghiÃªn cá»©u vá» resnet50, cÃ¡c báº¡n cho mÃ¬nh há»i chi tiáº¿t vá» hiá»‡n tÆ°á»£ng Vanishing, vÃ  Ã½ nghÄ©a cá»§a khá»‘i pháº§n dÆ°.Thanks all","CÃ¡c ban Æ¡i, mÃ¬nh Ä‘ang nghiÃªn cá»©u vá» resnet50, cÃ¡c báº¡n cho mÃ¬nh há»i chi tiáº¿t vá» hiá»‡n tÆ°á»£ng Vanishing, vÃ  Ã½ nghÄ©a cá»§a khá»‘i pháº§n dÆ°.Thanks all",,,,,
"ChÃ o má»i ngÆ°á»i.
Em Ä‘ang phÃ¢n vÃ¢n nÃªn theo há»c master Khoa há»c dá»¯ liá»‡u á»Ÿ trÆ°á»ng BÃ¡ch KhÃ³a HN hay lÃ  Khoa Há»c Tá»± NhiÃªn HN, cÃ³ anh/chá»‹ nÃ o Ä‘Ã£ há»c 1 trong 2 trÆ°á»ng nÃ y cho em xin Ã½ kiáº¿n vá»›i áº¡:
Tá»•ng chi phÃ­ toÃ n khÃ³a há»c lÃ  khoáº£ng bao nhiÃªu.
Cháº¥t lÆ°á»£ng dáº¡y há»c nhÆ° tháº¿ nÃ o.
CÆ¡ há»™i nghá» nghiá»‡p.
Náº¿u sau nÃ y xin há»c bá»•ng nghiÃªn cá»©u sinh á»Ÿ cÃ¡c nÆ°á»›c khÃ¡c thÃ¬ trÆ°á»ng nÃ o sáº½ cÃ³ lá»£i tháº¿ hÆ¡n áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","ChÃ o má»i ngÆ°á»i. Em Ä‘ang phÃ¢n vÃ¢n nÃªn theo há»c master Khoa há»c dá»¯ liá»‡u á»Ÿ trÆ°á»ng BÃ¡ch KhÃ³a HN hay lÃ  Khoa Há»c Tá»± NhiÃªn HN, cÃ³ anh/chá»‹ nÃ o Ä‘Ã£ há»c 1 trong 2 trÆ°á»ng nÃ y cho em xin Ã½ kiáº¿n vá»›i áº¡: Tá»•ng chi phÃ­ toÃ n khÃ³a há»c lÃ  khoáº£ng bao nhiÃªu. Cháº¥t lÆ°á»£ng dáº¡y há»c nhÆ° tháº¿ nÃ o. CÆ¡ há»™i nghá» nghiá»‡p. Náº¿u sau nÃ y xin há»c bá»•ng nghiÃªn cá»©u sinh á»Ÿ cÃ¡c nÆ°á»›c khÃ¡c thÃ¬ trÆ°á»ng nÃ o sáº½ cÃ³ lá»£i tháº¿ hÆ¡n áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  sau khi tÃ¬m Ä‘áº¡o hÃ m cá»§a hÃ m máº¥t mÃ¡t trong logistic regression thÃ¬ nghiá»‡m w cá»§a phÆ°Æ¡ng trÃ¬nh Ä‘áº¡o hÃ m báº±ng 0 tÃ­nh nhÆ° tháº¿ nÃ o?
Tai sao chÃºng ta ko dÃ¹ng nghiá»‡m w Ä‘Ã³ Ä‘á»ƒ lÃ m w_init luÃ´n thay tÃ­nh gáº§n Ä‘Ãºng w báº±ng gradient decent?",Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  sau khi tÃ¬m Ä‘áº¡o hÃ m cá»§a hÃ m máº¥t mÃ¡t trong logistic regression thÃ¬ nghiá»‡m w cá»§a phÆ°Æ¡ng trÃ¬nh Ä‘áº¡o hÃ m báº±ng 0 tÃ­nh nhÆ° tháº¿ nÃ o? Tai sao chÃºng ta ko dÃ¹ng nghiá»‡m w Ä‘Ã³ Ä‘á»ƒ lÃ m w_init luÃ´n thay tÃ­nh gáº§n Ä‘Ãºng w báº±ng gradient decent?,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c!
NhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u vá» Loan Repayment Prediction, em xin máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ .
Warning: BÃ i nÃ y chá»‰ dÃ¹ng Ä‘á»ƒ há»c táº­p, khi Ã¡p dá»¥ng thá»±c táº¿ cÃ²n cáº§n ráº¥t nhiá»u ká»¹ thuáº­t xá»­ lÃ½ náº±m ngoÃ i kháº£ nÄƒng cá»§a em :)","KÃ­nh chÃ o cÃ¡c bÃ¡c! NhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u vá» Loan Repayment Prediction, em xin máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ . Warning: BÃ i nÃ y chá»‰ dÃ¹ng Ä‘á»ƒ há»c táº­p, khi Ã¡p dá»¥ng thá»±c táº¿ cÃ²n cáº§n ráº¥t nhiá»u ká»¹ thuáº­t xá»­ lÃ½ náº±m ngoÃ i kháº£ nÄƒng cá»§a em :)",,,,,
"#rfm #segmentation #machinelearning #python #datascience
THE SERIES OF DATA SCIENCE WITH PYTHON - PART 3
Hi All,
Step by Step Customer Segmentation by RFM
Learn now ğŸ‘‡","THE SERIES OF DATA SCIENCE WITH PYTHON - PART 3 Hi All, Step by Step Customer Segmentation by RFM Learn now",#rfm	#segmentation	#machinelearning	#python	#datascience,,,,
"Tiá»‡p cho mÃ¬nh share thÃ´ng tin syllabus lá»›p Foundation of Machine Learning vÃ  Data Science (miá»…n phÃ­ há»c phÃ­ vÃ  báº±ng tiáº¿ng Viá»‡t) mÃ  mÃ¬nh sáº½ báº¯t Ä‘áº§u vÃ o thÃ¡ng 8 nÃ y.
CÃ¡c bÃ i giáº£ng sáº½ Ä‘Æ°á»£c record vÃ  upload trá»±c tiáº¿p trÃªn page khoa há»c dá»¯ liá»‡u: https://www.facebook.com/khoahocvadulieu/
--- Lá»›p nÃ y sáº½ chia thÃ nh 2 há»c pháº§n: ""Introduction to Machine Learning and Data Science"" vÃ  ""Advanced Machine Learning and Data Science"".
Vá» há»c pháº§n ""Introduction to Machine Learning and Data Science"", cÃ¡c báº¡n khÃ´ng cáº§n biáº¿t nhiá»u vá» ToÃ¡n váº«n há»c Ä‘Æ°á»£c (mÃ¬nh sáº½ giáº£m thiá»ƒu Math nhiá»u nháº¥t cÃ³ thá»ƒ). ChÆ°Æ¡ng trÃ¬nh dáº¡y cá»§a lá»›p nÃ y sáº½ gáº§n vá»›i chÆ°Æ¡ng trÃ¬nh dáº¡y vá» introduction to ML vÃ  DS táº¡i cÃ¡c trÆ°á»ng hÃ ng Ä‘áº§u táº¡i Má»¹.
Vá» há»c pháº§n ""Advanced Machine Learning and Data Science"", Ä‘Ã¢y dÃ nh cho cÃ¡c báº¡n muá»‘n hiá»ƒu sÃ¢u vá» ML vÃ  Data Science (vÃ  cÃ³ Ä‘á»‹nh hÆ°á»›ng há»c cao há»c trong cÃ¡c ngÃ nh nÃ y). CÃ¡c topics trong há»c pháº§n nÃ y sáº½ khÃ¡ náº·ng vá» Math. Báº¡n há»c xong há»c pháº§n nÃ y cÃ³ thá»ƒ báº¯t Ä‘áº§u lÃ m nghiÃªn cá»©u cháº¥t lÆ°á»£ng cao bÃªn ML vÃ  Deep Leanring.
DÆ°á»›i Ä‘Ã¢y mÃ¬nh sáº½ highlight má»™t sá»‘ chá»§ Ä‘á» mÃ  má»—i há»c pháº§n sáº½ cover (danh sÃ¡ch cÃ¡c chá»§ Ä‘á» sáº½ liÃªn tá»¥c Ä‘Æ°á»£c cáº­p nháº­t táº¡i page khoa há»c dá»¯ liá»‡u):
********** Há»c pháº§n ""Introduction to Machine Learning and Data Science"":
--- Warm up: Review of basic Probability Notion
--- Introduction to Statistical Learning and Inference
--- Linear models
--- Classification Methods
--- Linear model selection and regularization
--- Nonlinear models
--- Tree-based methods
--- Support Vector Machine
--- Unsupervised Learning: Clustering, Dimension Reduction, etc.
--- Introduction to Deep Learning
--- Introduction to Reinforcement Learning
************** Há»c pháº§n ""Advanced Machine Learning and Data Science"":
--- Deep Generative Model (Variational Auto Encoder, GANs, Diffusion Models, etc.)
--- Optimal Transport in Machine Learning and Data Science
--- Foundation of Variational Inference (for Bayesian methods)
--- Some Theoretical Perspective of Self-Supervised Learning
--- Transformer-based models: Old and New
--- Optimization in Statistical Models and Deep Learning
--- Deep Learning Theory
--- Foundation of Bayesian Hierarchical Mode","Tiá»‡p cho mÃ¬nh share thÃ´ng tin syllabus lá»›p Foundation of Machine Learning vÃ  Data Science (miá»…n phÃ­ há»c phÃ­ vÃ  báº±ng tiáº¿ng Viá»‡t) mÃ  mÃ¬nh sáº½ báº¯t Ä‘áº§u vÃ o thÃ¡ng 8 nÃ y. CÃ¡c bÃ i giáº£ng sáº½ Ä‘Æ°á»£c record vÃ  upload trá»±c tiáº¿p trÃªn page khoa há»c dá»¯ liá»‡u: https://www.facebook.com/khoahocvadulieu/ --- Lá»›p nÃ y sáº½ chia thÃ nh 2 há»c pháº§n: ""Introduction to Machine Learning and Data Science"" vÃ  ""Advanced Machine Learning and Data Science"". Vá» há»c pháº§n ""Introduction to Machine Learning and Data Science"", cÃ¡c báº¡n khÃ´ng cáº§n biáº¿t nhiá»u vá» ToÃ¡n váº«n há»c Ä‘Æ°á»£c (mÃ¬nh sáº½ giáº£m thiá»ƒu Math nhiá»u nháº¥t cÃ³ thá»ƒ). ChÆ°Æ¡ng trÃ¬nh dáº¡y cá»§a lá»›p nÃ y sáº½ gáº§n vá»›i chÆ°Æ¡ng trÃ¬nh dáº¡y vá» introduction to ML vÃ  DS táº¡i cÃ¡c trÆ°á»ng hÃ ng Ä‘áº§u táº¡i Má»¹. Vá» há»c pháº§n ""Advanced Machine Learning and Data Science"", Ä‘Ã¢y dÃ nh cho cÃ¡c báº¡n muá»‘n hiá»ƒu sÃ¢u vá» ML vÃ  Data Science (vÃ  cÃ³ Ä‘á»‹nh hÆ°á»›ng há»c cao há»c trong cÃ¡c ngÃ nh nÃ y). CÃ¡c topics trong há»c pháº§n nÃ y sáº½ khÃ¡ náº·ng vá» Math. Báº¡n há»c xong há»c pháº§n nÃ y cÃ³ thá»ƒ báº¯t Ä‘áº§u lÃ m nghiÃªn cá»©u cháº¥t lÆ°á»£ng cao bÃªn ML vÃ  Deep Leanring. DÆ°á»›i Ä‘Ã¢y mÃ¬nh sáº½ highlight má»™t sá»‘ chá»§ Ä‘á» mÃ  má»—i há»c pháº§n sáº½ cover (danh sÃ¡ch cÃ¡c chá»§ Ä‘á» sáº½ liÃªn tá»¥c Ä‘Æ°á»£c cáº­p nháº­t táº¡i page khoa há»c dá»¯ liá»‡u): ********** Há»c pháº§n ""Introduction to Machine Learning and Data Science"": --- Warm up: Review of basic Probability Notion --- Introduction to Statistical Learning and Inference --- Linear models --- Classification Methods --- Linear model selection and regularization --- Nonlinear models --- Tree-based methods --- Support Vector Machine --- Unsupervised Learning: Clustering, Dimension Reduction, etc. --- Introduction to Deep Learning --- Introduction to Reinforcement Learning ************** Há»c pháº§n ""Advanced Machine Learning and Data Science"": --- Deep Generative Model (Variational Auto Encoder, GANs, Diffusion Models, etc.) --- Optimal Transport in Machine Learning and Data Science --- Foundation of Variational Inference (for Bayesian methods) --- Some Theoretical Perspective of Self-Supervised Learning --- Transformer-based models: Old and New --- Optimization in Statistical Models and Deep Learning --- Deep Learning Theory --- Foundation of Bayesian Hierarchical Mode",,,,,
"Em hiá»‡n lÃ  sinh viÃªn Ä‘ang há»c táº¡i trÆ°á»ng Äáº¡i há»c Kinh táº¿ TP.HCM.
Hiá»‡n em cÃ³ má»™t dá»± Ã¡n Hackathon cáº§n triá»ƒn khai sáº£n pháº©m, Ä‘Ã³ lÃ  build má»™t con mÃ¡y phÃ¢n loáº¡i rÃ¡c tá»± Ä‘á»™ng - giáº£i phÃ¡p Ä‘Ã£ Ä‘áº¡t giáº£i Ã quÃ¢n cuá»™c thi UEH Biztech Hackathon 2022.
Hiá»‡n nhÃ³m em Ä‘ang cáº§n lÃ m má»™t sáº£n pháº©m lÃ  má»™t mÃ¡y camera sá»­ dá»¥ng cÃ´ng nghá»‡ Machine Learning Ä‘á»ƒ phÃ¢n loáº¡i rÃ¡c. Em hiá»‡n Ä‘ang cáº§n tÃ¬m thÃªm Ä‘á»“ng Ä‘á»™i bÃªn Tech, cÃ³ hiá»ƒu biáº¿t vá» Machine Learning cÃ¹ng nhÃ³m em triá»ƒn khai xÃ¢y dá»±ng sáº£n pháº©m nÃ y.
NhÃ³m em Ä‘Ã£ cÃ³ 4 ngÆ°á»i, dá»± Ã¡n Ä‘Æ°á»£c hoÃ n thÃ nh trong 6 thÃ¡ng, hiá»‡n Ä‘Ã£ cÃ³ khÃ¡ch hÃ ng.
Dá»± Ã¡n Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Viá»‡n Ä‘á»•i má»›i sÃ¡ng táº¡o UEH (UII).
Em ráº¥t mong muá»‘n tÃ¬m gáº·p má»™t teammate phÃ¹ há»£p Ä‘i cÃ¹ng vá»›i nhÃ³m, gáº·p gá»¡, trao Ä‘á»•i cÅ©ng nhÆ° há»c há»i thÃªm nhiá»u ká»¹ nÄƒng Tech, khá»Ÿi nghiá»‡p, chiáº¿n lÆ°á»£c marketing,... vÃ  Ä‘áº·c biá»‡t lÃ  Ä‘á»“ng hÃ nh lÃ¢u dÃ i vá»›i nhÃ³m.
Má»i ngÆ°á»i quan tÃ¢m liÃªn há»‡ em gá»­i toÃ n bá»™ file káº¿ hoáº¡ch vá» sáº£n pháº©m nhÃ© áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","Em hiá»‡n lÃ  sinh viÃªn Ä‘ang há»c táº¡i trÆ°á»ng Äáº¡i há»c Kinh táº¿ TP.HCM. Hiá»‡n em cÃ³ má»™t dá»± Ã¡n Hackathon cáº§n triá»ƒn khai sáº£n pháº©m, Ä‘Ã³ lÃ  build má»™t con mÃ¡y phÃ¢n loáº¡i rÃ¡c tá»± Ä‘á»™ng - giáº£i phÃ¡p Ä‘Ã£ Ä‘áº¡t giáº£i Ã quÃ¢n cuá»™c thi UEH Biztech Hackathon 2022. Hiá»‡n nhÃ³m em Ä‘ang cáº§n lÃ m má»™t sáº£n pháº©m lÃ  má»™t mÃ¡y camera sá»­ dá»¥ng cÃ´ng nghá»‡ Machine Learning Ä‘á»ƒ phÃ¢n loáº¡i rÃ¡c. Em hiá»‡n Ä‘ang cáº§n tÃ¬m thÃªm Ä‘á»“ng Ä‘á»™i bÃªn Tech, cÃ³ hiá»ƒu biáº¿t vá» Machine Learning cÃ¹ng nhÃ³m em triá»ƒn khai xÃ¢y dá»±ng sáº£n pháº©m nÃ y. NhÃ³m em Ä‘Ã£ cÃ³ 4 ngÆ°á»i, dá»± Ã¡n Ä‘Æ°á»£c hoÃ n thÃ nh trong 6 thÃ¡ng, hiá»‡n Ä‘Ã£ cÃ³ khÃ¡ch hÃ ng. Dá»± Ã¡n Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Viá»‡n Ä‘á»•i má»›i sÃ¡ng táº¡o UEH (UII). Em ráº¥t mong muá»‘n tÃ¬m gáº·p má»™t teammate phÃ¹ há»£p Ä‘i cÃ¹ng vá»›i nhÃ³m, gáº·p gá»¡, trao Ä‘á»•i cÅ©ng nhÆ° há»c há»i thÃªm nhiá»u ká»¹ nÄƒng Tech, khá»Ÿi nghiá»‡p, chiáº¿n lÆ°á»£c marketing,... vÃ  Ä‘áº·c biá»‡t lÃ  Ä‘á»“ng hÃ nh lÃ¢u dÃ i vá»›i nhÃ³m. Má»i ngÆ°á»i quan tÃ¢m liÃªn há»‡ em gá»­i toÃ n bá»™ file káº¿ hoáº¡ch vá» sáº£n pháº©m nhÃ© áº¡. Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"Em má»›i báº¯t Ä‘áº§u há»c python, nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vá»›i cÃ³ tÃ i liá»‡u em tham kháº£o vá»›i áº¡","Em má»›i báº¯t Ä‘áº§u há»c python, nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vá»›i cÃ³ tÃ i liá»‡u em tham kháº£o vá»›i áº¡",,,,,
"Hi ace, e dang lÃ m final project cá»§a machine learning. topic lÃ  identify a bird dÃ¹ng CNN. e Ä‘á»‹nh dÃ¹ng matlab Ä‘á»ƒ lÃ m. a chá»‹ nÃ o cÃ³ tÃ i liá»‡u liÃªn quan tá»›i topic nay ko? (Code, data...) cho e xin Ä‘Æ°á»£c ko?. e cáº£m Æ¡n.","Hi ace, e dang lÃ m final project cá»§a machine learning. topic lÃ  identify a bird dÃ¹ng CNN. e Ä‘á»‹nh dÃ¹ng matlab Ä‘á»ƒ lÃ m. a chá»‹ nÃ o cÃ³ tÃ i liá»‡u liÃªn quan tá»›i topic nay ko? (Code, data...) cho e xin Ä‘Æ°á»£c ko?. e cáº£m Æ¡n.",,,,,
"[The Kaggle book]

Má»i ngÆ°á»i há»c vá» Data Science, Machine Learning cháº¯c khÃ´ng láº¡ gÃ¬ Kaggle, má»™t ná»n táº£ng tá»• chá»©c cÃ¡c cuá»™c thi vá» DS, cÅ©ng nhÆ° cÃ³ ráº¥t nhiá»u public dataset, notebook hay Ä‘á»ƒ há»c há»i. Báº±ng viá»‡c tham gia cÃ¡c cuá»™c thi, cÃ¡c báº¡n sáº½ Ä‘Æ°á»£c há»c thÃªm cÃ¡c kinh nghiá»‡m trá»±c quan hÃ³a, xá»­ lÃ½ dá»¯ liá»‡u, xÃ¢y dá»±ng, Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. NgÆ°á»i ta hay nÃ³i Kaggle chÃ­nh lÃ  cáº§u ná»‘i giá»¯a viá»‡c há»c lÃ½ thuyáº¿t vÃ  Ä‘i lÃ m trong ngÃ nh khoa há»c dá»¯ liá»‡u.

SÃ¡ch ""The Kaggle Book: Data analysis and machine learning for competitive data science"" Ä‘Æ°á»£c viáº¿t bá»Ÿi hai Grandmaster - Kaggle. SÃ¡ch tá»•ng há»£p cÃ¡c kÄ© thuáº­t Ä‘Æ°á»£c cÃ¡c Grandmaster Ä‘Ãºc káº¿t tá»« cÃ¡c cuá»™c thi mÃ  há» tham gia. SÃ¡ch phÃ¹ há»£p cho cáº£ ngÆ°á»i há»c tham gia Kaggle láº«n nhá»¯ng ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m. Náº¿u báº¡n muá»‘n cáº£i thiá»‡n kÄ© nÄƒng, há»c há»i thÃªm kiáº¿n thá»©c má»›i vÃ  Ä‘áº·c biá»‡t dÃ nh thá»© háº¡ng cao hÆ¡n trong cÃ¡c cuá»™c thi trÃªn Kaggle thÃ¬ sÃ¡ch nÃ y lÃ  dÃ nh cho báº¡n.

Link sÃ¡ch: https://www.amazon.com/Data-Analysis-Machine-Learning-Kaggle-ebook/dp/B09F3STL34","[The Kaggle book] Má»i ngÆ°á»i há»c vá» Data Science, Machine Learning cháº¯c khÃ´ng láº¡ gÃ¬ Kaggle, má»™t ná»n táº£ng tá»• chá»©c cÃ¡c cuá»™c thi vá» DS, cÅ©ng nhÆ° cÃ³ ráº¥t nhiá»u public dataset, notebook hay Ä‘á»ƒ há»c há»i. Báº±ng viá»‡c tham gia cÃ¡c cuá»™c thi, cÃ¡c báº¡n sáº½ Ä‘Æ°á»£c há»c thÃªm cÃ¡c kinh nghiá»‡m trá»±c quan hÃ³a, xá»­ lÃ½ dá»¯ liá»‡u, xÃ¢y dá»±ng, Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. NgÆ°á»i ta hay nÃ³i Kaggle chÃ­nh lÃ  cáº§u ná»‘i giá»¯a viá»‡c há»c lÃ½ thuyáº¿t vÃ  Ä‘i lÃ m trong ngÃ nh khoa há»c dá»¯ liá»‡u. SÃ¡ch ""The Kaggle Book: Data analysis and machine learning for competitive data science"" Ä‘Æ°á»£c viáº¿t bá»Ÿi hai Grandmaster - Kaggle. SÃ¡ch tá»•ng há»£p cÃ¡c kÄ© thuáº­t Ä‘Æ°á»£c cÃ¡c Grandmaster Ä‘Ãºc káº¿t tá»« cÃ¡c cuá»™c thi mÃ  há» tham gia. SÃ¡ch phÃ¹ há»£p cho cáº£ ngÆ°á»i há»c tham gia Kaggle láº«n nhá»¯ng ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m. Náº¿u báº¡n muá»‘n cáº£i thiá»‡n kÄ© nÄƒng, há»c há»i thÃªm kiáº¿n thá»©c má»›i vÃ  Ä‘áº·c biá»‡t dÃ nh thá»© háº¡ng cao hÆ¡n trong cÃ¡c cuá»™c thi trÃªn Kaggle thÃ¬ sÃ¡ch nÃ y lÃ  dÃ nh cho báº¡n. Link sÃ¡ch: https://www.amazon.com/Data-Analysis-Machine-Learning-Kaggle-ebook/dp/B09F3STL34",,,,,
"dáº¡ má»i ngÆ°á»i cÃ³ ai bik vá» tÃ i liá»‡u hay trang web nÃ o nÃ³i vá» cÃ¡i thuáº­t toÃ¡n bi-directional matching Ä‘Æ°á»£c nháº¯c Ä‘áº¿n trong bÃ i bÃ¡o
Implicit Skills Extraction Using Document Embedding and Its Use in Job Recommendation , thÃ¬ cho em xin link hoáº·c tÃ i liá»‡u vá»›i áº¡ , em Ä‘ang cáº§n tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n nÃ y, em cáº£m Æ¡n","dáº¡ má»i ngÆ°á»i cÃ³ ai bik vá» tÃ i liá»‡u hay trang web nÃ o nÃ³i vá» cÃ¡i thuáº­t toÃ¡n bi-directional matching Ä‘Æ°á»£c nháº¯c Ä‘áº¿n trong bÃ i bÃ¡o Implicit Skills Extraction Using Document Embedding and Its Use in Job Recommendation , thÃ¬ cho em xin link hoáº·c tÃ i liá»‡u vá»›i áº¡ , em Ä‘ang cáº§n tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n nÃ y, em cáº£m Æ¡n",,,,,
"#hoidap
ChÃ o má»i ngÆ°á»i áº¡. Anh chá»‹ cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘Æ¡n giáº£n giÃºp em vá» phÆ°Æ¡ng sai khÃ´ng Ä‘á»•i trong trÆ°á»ng há»£p nÃ y khÃ´ng áº¡ ? em Ä‘á»c mÃ  khÃ´ng hiá»ƒu láº¯m. CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.",ChÃ o má»i ngÆ°á»i áº¡. Anh chá»‹ cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘Æ¡n giáº£n giÃºp em vá» phÆ°Æ¡ng sai khÃ´ng Ä‘á»•i trong trÆ°á»ng há»£p nÃ y khÃ´ng áº¡ ? em Ä‘á»c mÃ  khÃ´ng hiá»ƒu láº¯m. CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.,#hoidap,,,,
"Em chÃ o má»i ngÆ°á»i
Em Ä‘ang thá»­ nghiá»‡m bá»™ dataset car trong bÃ i toÃ¡n classification. Em dÃ¹ng model resnet50 nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c chá»‰ Ä‘Æ°á»£c táº§m 60%
Má»i ngÆ°á»i cho em lá»i khuyÃªn áº¡",Em chÃ o má»i ngÆ°á»i Em Ä‘ang thá»­ nghiá»‡m bá»™ dataset car trong bÃ i toÃ¡n classification. Em dÃ¹ng model resnet50 nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c chá»‰ Ä‘Æ°á»£c táº§m 60% Má»i ngÆ°á»i cho em lá»i khuyÃªn áº¡,,,,,
,nan,,,,,
"TÃ¬m giáº£i phÃ¡p cho bÃ i toÃ¡n Regression vá»›i imbalance data.
ChÃ o cáº£ nhÃ , em Ä‘ang muá»‘n tÃ¬m má»™t giáº£i phÃ¡p Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n regression dá»± Ä‘oÃ¡n sáº£n lÆ°á»£ng cÃ¡. Vá»›i output lÃ  'ton' lÃ  sáº£n lÆ°á»£ng cÃ¡ Ä‘Ã¡nh Ä‘Ã¡nh báº¯t Ä‘Æ°á»£c. Vá»›i giáº£ thuyáº¿t Ä‘Æ°a ra lÃ  náº¿u tÃ u Ä‘ang quay Ä‘áº§u chuyá»ƒn hÆ°á»›ng thÃ¬ lÆ°á»£ng cÃ¡ Ä‘Ã¡nh báº¯t Ä‘Æ°á»£c lÃ  0, cÃ²n náº¿u Ä‘i nhÆ° bÃ¬nh thÆ°á»ng thÃ¬ lÆ°á»£ng cÃ¡ sáº½ Ä‘Æ°á»£c record láº¡i trong cá»™t 'ton'. Vá»›i label ton = 0 Ä‘ang chiáº¿m Ä‘áº¿n 70% trÃªn tá»•ng sá»‘ samples.DÆ°á»›i Ä‘Ã¢y lÃ  link Ä‘áº¿n report vá» dataset vÃ  feature detail.
Report: https://drive.google.com/file/d/172O870cB5btjVRaZyonaWNG98tiR_Rcj/view?usp=sharing
Data detail: https://github.com/NgToanRob/AI4Sea/blob/main/data_detail.md
Cáº£m Æ¡n sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i áº¡! <3 ","TÃ¬m giáº£i phÃ¡p cho bÃ i toÃ¡n Regression vá»›i imbalance data. ChÃ o cáº£ nhÃ , em Ä‘ang muá»‘n tÃ¬m má»™t giáº£i phÃ¡p Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n regression dá»± Ä‘oÃ¡n sáº£n lÆ°á»£ng cÃ¡. Vá»›i output lÃ  'ton' lÃ  sáº£n lÆ°á»£ng cÃ¡ Ä‘Ã¡nh Ä‘Ã¡nh báº¯t Ä‘Æ°á»£c. Vá»›i giáº£ thuyáº¿t Ä‘Æ°a ra lÃ  náº¿u tÃ u Ä‘ang quay Ä‘áº§u chuyá»ƒn hÆ°á»›ng thÃ¬ lÆ°á»£ng cÃ¡ Ä‘Ã¡nh báº¯t Ä‘Æ°á»£c lÃ  0, cÃ²n náº¿u Ä‘i nhÆ° bÃ¬nh thÆ°á»ng thÃ¬ lÆ°á»£ng cÃ¡ sáº½ Ä‘Æ°á»£c record láº¡i trong cá»™t 'ton'. Vá»›i label ton = 0 Ä‘ang chiáº¿m Ä‘áº¿n 70% trÃªn tá»•ng sá»‘ samples.DÆ°á»›i Ä‘Ã¢y lÃ  link Ä‘áº¿n report vá» dataset vÃ  feature detail. Report: https://drive.google.com/file/d/172O870cB5btjVRaZyonaWNG98tiR_Rcj/view?usp=sharing Data detail: https://github.com/NgToanRob/AI4Sea/blob/main/data_detail.md Cáº£m Æ¡n sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i áº¡! <3",,,,,
"MÃ¬nh muá»‘n tÃ¬m khÃ³a há»c AI online , vÃ¬ mÃ¬nh má»›i chuyá»ƒn sang máº£ng nÃ y vÃ  muá»‘n cÃ³ kiáº¿n thá»©c ná»n táº£ng vá»¯ng Ä‘á»ƒ xin viá»‡c
Má»i ngÆ°á»i review giÃºp mÃ¬nh vá»›i áº¡
MÃ¬nh cáº£m Æ¡n nhiá»u","MÃ¬nh muá»‘n tÃ¬m khÃ³a há»c AI online , vÃ¬ mÃ¬nh má»›i chuyá»ƒn sang máº£ng nÃ y vÃ  muá»‘n cÃ³ kiáº¿n thá»©c ná»n táº£ng vá»¯ng Ä‘á»ƒ xin viá»‡c Má»i ngÆ°á»i review giÃºp mÃ¬nh vá»›i áº¡ MÃ¬nh cáº£m Æ¡n nhiá»u",,,,,
"TÃ¬m Model Speech-to-text cho tiáº¿ng Viá»‡t.text cho tiáº¿ng Viá»‡t.
ChÃ o cáº£ nhÃ , mÃ¬nh muá»‘n tim 1 sá»‘ model xá»­ lÃ½ Speech-to-text cho tiáº¿ng Viá»‡t cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c nhá»¯ng tá»« tiáº¿ng anh.
Hiá»‡n mÃ¬nh cÃ³ dÃ¹ng API cá»§a Azure vÃ  cÅ©ng Ä‘Ã£ xá»­ lÃ½ khÃ¡ tá»‘t 1 sá»‘ tá»« tiáº¿ng Anh trong business, tuy nhiÃªn chá»‰ táº§m 20% Ä‘Æ°á»£c cover.
(TrÆ°á»›c mÃ¬nh cÃ³ Ä‘á»c Ä‘Æ°á»£c cÃ³ team Ä‘Ã£ training model báº±ng data manual subtitle trÃªn youtube. MÃ¬nh tháº¥y khÃ¡ hay nhÆ°ng giá» khÃ´ng tÃ¬m tháº¥y Ä‘Ã¢u)
Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a cáº£ nhÃ  áº¡!","TÃ¬m Model Speech-to-text cho tiáº¿ng Viá»‡t.text cho tiáº¿ng Viá»‡t. ChÃ o cáº£ nhÃ , mÃ¬nh muá»‘n tim 1 sá»‘ model xá»­ lÃ½ Speech-to-text cho tiáº¿ng Viá»‡t cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c nhá»¯ng tá»« tiáº¿ng anh. Hiá»‡n mÃ¬nh cÃ³ dÃ¹ng API cá»§a Azure vÃ  cÅ©ng Ä‘Ã£ xá»­ lÃ½ khÃ¡ tá»‘t 1 sá»‘ tá»« tiáº¿ng Anh trong business, tuy nhiÃªn chá»‰ táº§m 20% Ä‘Æ°á»£c cover. (TrÆ°á»›c mÃ¬nh cÃ³ Ä‘á»c Ä‘Æ°á»£c cÃ³ team Ä‘Ã£ training model báº±ng data manual subtitle trÃªn youtube. MÃ¬nh tháº¥y khÃ¡ hay nhÆ°ng giá» khÃ´ng tÃ¬m tháº¥y Ä‘Ã¢u) Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a cáº£ nhÃ  áº¡!",,,,,
"Em chÃ o cáº£ nhÃ . Dáº¡ cho em há»i hiá»‡n táº¡i nhÃ³m tá»¥i em Ä‘ang nghiÃªn cá»©u vá» váº¥n Ä‘á» nháº­n diá»‡n cÃ¡c Ä‘á»™ng tÃ¡c Yoga vÃ  hiá»‡n táº¡i Ä‘ang dá»± tÃ­nh dÃ¹ng bá»™ dataset Yoga-82. NhÆ°ng sau khi em download data tá»« cÃ¡c link url áº£nh vá» (vÃ¬ cÃ¡c áº£nh cá»§a bá»™ dataset nÃ y lÆ°u dÆ°á»›i dáº¡ng file url) thÃ¬ hiá»‡n cÃ³ ráº¥t nhiá»u áº£nh khÃ´ng cÃ²n láº¥y vá» Ä‘Æ°á»£c ná»¯a. KhÃ´ng biáº¿t hiá»‡n táº¡i cÃ²n cÃ¡ch nÃ o láº¥y bá»™ dataset nÃ y trá»n váº¹n hay khÃ´ng áº¡ vÃ  cÃ²n nhá»¯ng bá»™ dataset nÃ o khÃ¡c liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y khÃ´ng áº¡ ?
Em xin cáº£m Æ¡n áº¡.",Em chÃ o cáº£ nhÃ . Dáº¡ cho em há»i hiá»‡n táº¡i nhÃ³m tá»¥i em Ä‘ang nghiÃªn cá»©u vá» váº¥n Ä‘á» nháº­n diá»‡n cÃ¡c Ä‘á»™ng tÃ¡c Yoga vÃ  hiá»‡n táº¡i Ä‘ang dá»± tÃ­nh dÃ¹ng bá»™ dataset Yoga-82. NhÆ°ng sau khi em download data tá»« cÃ¡c link url áº£nh vá» (vÃ¬ cÃ¡c áº£nh cá»§a bá»™ dataset nÃ y lÆ°u dÆ°á»›i dáº¡ng file url) thÃ¬ hiá»‡n cÃ³ ráº¥t nhiá»u áº£nh khÃ´ng cÃ²n láº¥y vá» Ä‘Æ°á»£c ná»¯a. KhÃ´ng biáº¿t hiá»‡n táº¡i cÃ²n cÃ¡ch nÃ o láº¥y bá»™ dataset nÃ y trá»n váº¹n hay khÃ´ng áº¡ vÃ  cÃ²n nhá»¯ng bá»™ dataset nÃ o khÃ¡c liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y khÃ´ng áº¡ ? Em xin cáº£m Æ¡n áº¡.,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, má»i ngÆ°á»i cho em há»i ai cÃ³ tÃ i liá»‡u vá» triá»ƒn khai mÃ´ hÃ¬nh seq2seq vá»›i Attention sá»­ dá»¥ng BiLSTM vÃ  Depth LSTM ko áº¡? Náº¿u cÃ³ thÃ¬ cÃ³ thá»ƒ cho em xin Ä‘Æ°á»£c ko áº¡, hoáº·c ko thÃ¬ cÃ³ thá»ƒ ib Ä‘á»ƒ em há»i chÃºt Ä‘Æ°á»£c ko áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡","Em chÃ o má»i ngÆ°á»i áº¡, má»i ngÆ°á»i cho em há»i ai cÃ³ tÃ i liá»‡u vá» triá»ƒn khai mÃ´ hÃ¬nh seq2seq vá»›i Attention sá»­ dá»¥ng BiLSTM vÃ  Depth LSTM ko áº¡? Náº¿u cÃ³ thÃ¬ cÃ³ thá»ƒ cho em xin Ä‘Æ°á»£c ko áº¡, hoáº·c ko thÃ¬ cÃ³ thá»ƒ ib Ä‘á»ƒ em há»i chÃºt Ä‘Æ°á»£c ko áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡",,,,,
"[ğ•ğˆğ„ğ“ğ€ğˆ ğ± ğ‡ğ”ğ†ğ†ğˆğğ† ğ…ğ€ğ‚ğ„]
ğŸ”¥VietAI káº¿t há»£p Hugging Face cÃ´ng bá»‘ mÃ£ nguá»“n JAX Ä‘á»ƒ huáº¥n luyá»‡n Stable Diffusion, Textual Inversion, DreamBooth: Nhanh hÆ¡n ğŸ•ğŸ% so vá»›i PyTorch.
ğŸ“Œğ…ğ¢ğ§ğ-ğ­ğ®ğ§ğ¢ğ§ğ  ğ’ğ­ğšğ›ğ¥ğ ğƒğ¢ğŸğŸğ®ğ¬ğ¢ğ¨ğ§: https://github.com/huggingface/diffusers/tree/main/examples/text_to_image#training-with-flaxjax
ğŸ“Œğ“ğğ±ğ­ğ®ğšğ¥ ğˆğ§ğ¯ğğ«ğ¬ğ¢ğ¨ğ§:
https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion#training-with-flaxjax
ğŸ“Œğƒğ«ğğšğ¦ğğ¨ğ¨ğ­ğ¡: https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#running-with-flaxjax","[ ] VietAI káº¿t há»£p Hugging Face cÃ´ng bá»‘ mÃ£ nguá»“n JAX Ä‘á»ƒ huáº¥n luyá»‡n Stable Diffusion, Textual Inversion, DreamBooth: Nhanh hÆ¡n % so vá»›i PyTorch. - : https://github.com/huggingface/diffusers/tree/main/examples/text_to_image#training-with-flaxjax : https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion#training-with-flaxjax : https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#running-with-flaxjax",,,,,
Anh chá»‹ cho em há»i pháº§n max_depth trong thuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh vá»›i hÃ m Ä‘Ã¡nh giÃ¡ lÃ  entropy em Ä‘á»ƒ lá»›n hÆ¡n sá»‘ thuá»™c tÃ­nh thÃ¬ khi Ä‘Ã³ Ä‘á»™ chÃ­nh xÃ¡c nÃ³ váº«n tÄƒng lÃ  tháº¿ nÃ o áº¡. A/c giáº£i Ä‘Ã¡p e vá»›i áº¡. E cÃ¡m Æ¡n.,Anh chá»‹ cho em há»i pháº§n max_depth trong thuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh vá»›i hÃ m Ä‘Ã¡nh giÃ¡ lÃ  entropy em Ä‘á»ƒ lá»›n hÆ¡n sá»‘ thuá»™c tÃ­nh thÃ¬ khi Ä‘Ã³ Ä‘á»™ chÃ­nh xÃ¡c nÃ³ váº«n tÄƒng lÃ  tháº¿ nÃ o áº¡. A/c giáº£i Ä‘Ã¡p e vá»›i áº¡. E cÃ¡m Æ¡n.,,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  ngÆ°á»i má»›i nháº­p mÃ´n, tháº§y em cÃ³ giao Ä‘á» tÃ i nghiÃªn cá»©u vá» machine learning model pipeline. Em cÃ³ vÃ i tháº¯c máº¯c. Pipeline cÃ³ pháº£i lÃ  quy trÃ¬nh tiá»n xá»­ lÃ½ xong mÃ¬nh bá» cÃ¡c model vÃ o rá»“i chá»n ra model tá»‘t nháº¥t khÃ´ng áº¡.Vá»›i láº¡i machine learning model pipeline gá»“m nhá»¯ng model nÃ o (cÃ³ CNN hay máº¥y cÃ¡i tÆ°Æ¡ng tá»± khÃ´ng áº¡ ?). Ai cÃ³ tÃ i liá»‡u tham kháº£o, hay hÆ°á»›ng dáº«n giÃºp em vá»›i áº¡. Em cáº£m Æ¡n áº¡!","ChÃ o má»i ngÆ°á»i, em lÃ  ngÆ°á»i má»›i nháº­p mÃ´n, tháº§y em cÃ³ giao Ä‘á» tÃ i nghiÃªn cá»©u vá» machine learning model pipeline. Em cÃ³ vÃ i tháº¯c máº¯c. Pipeline cÃ³ pháº£i lÃ  quy trÃ¬nh tiá»n xá»­ lÃ½ xong mÃ¬nh bá» cÃ¡c model vÃ o rá»“i chá»n ra model tá»‘t nháº¥t khÃ´ng áº¡.Vá»›i láº¡i machine learning model pipeline gá»“m nhá»¯ng model nÃ o (cÃ³ CNN hay máº¥y cÃ¡i tÆ°Æ¡ng tá»± khÃ´ng áº¡ ?). Ai cÃ³ tÃ i liá»‡u tham kháº£o, hay hÆ°á»›ng dáº«n giÃºp em vá»›i áº¡. Em cáº£m Æ¡n áº¡!",,,,,
"Hi má»i ngÆ°á»i,
Má»i ngÆ°á»i cho em há»i lÃ  náº¿u mÃ¬nh train YOLO trÃªn kaggle, config cá»§a YOLO lÃ  pháº£i cÃ³ label vá»›i images chung 1 thÆ° má»¥c.Vá»›i lÆ°á»£ng data á»Ÿ thÆ° má»¥c input nhá» thÃ¬ mÃ¬nh copy qua thÆ° má»¥c /kaggle/working vÃ  config train Ä‘Æ°á»£c. NhÆ°ng trong trÆ°á»ng há»£p dá»¯ liá»‡u 30Gb á»Ÿ thÆ° má»¥c input, thÃ¬ lÃ m sao Ä‘á»ƒ mÃ¬nh config vÃ  train Ä‘Æ°á»£c (nghÄ©a lÃ  táº¡o 1 thÆ° má»¥c sao cho cÃ³ áº£nh vÃ  label trong khi thÆ° má»¥c /kaggle/working chá»‰ cÃ³ 19.5Gb).
Cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Hi má»i ngÆ°á»i, Má»i ngÆ°á»i cho em há»i lÃ  náº¿u mÃ¬nh train YOLO trÃªn kaggle, config cá»§a YOLO lÃ  pháº£i cÃ³ label vá»›i images chung 1 thÆ° má»¥c.Vá»›i lÆ°á»£ng data á»Ÿ thÆ° má»¥c input nhá» thÃ¬ mÃ¬nh copy qua thÆ° má»¥c /kaggle/working vÃ  config train Ä‘Æ°á»£c. NhÆ°ng trong trÆ°á»ng há»£p dá»¯ liá»‡u 30Gb á»Ÿ thÆ° má»¥c input, thÃ¬ lÃ m sao Ä‘á»ƒ mÃ¬nh config vÃ  train Ä‘Æ°á»£c (nghÄ©a lÃ  táº¡o 1 thÆ° má»¥c sao cho cÃ³ áº£nh vÃ  label trong khi thÆ° má»¥c /kaggle/working chá»‰ cÃ³ 19.5Gb). Cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2022 vÃ o comment cá»§a post nÃ y.
Xin lá»—i vÃ¬ Ä‘Ã£ sáº¯p háº¿t thÃ¡ng 9 rá»“i.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2022 vÃ o comment cá»§a post nÃ y. Xin lá»—i vÃ¬ Ä‘Ã£ sáº¯p háº¿t thÃ¡ng 9 rá»“i.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n em muá»‘n tÃ¬m 1 model huáº¥n luyá»‡n Ä‘á»ƒ cÃ³ thá»ƒ táº¡o 1 cÃ¢u hoÃ n chá»‰nh tá»« cÃ¡c key input. VD input: [A,B,5p] => Output: "" Äi tá»« A Ä‘áº¿n B máº¥t 5p"". Má»i ngÆ°á»i giÃºp em vá»›i áº¡","ChÃ o má»i ngÆ°á»i, hiá»‡n em muá»‘n tÃ¬m 1 model huáº¥n luyá»‡n Ä‘á»ƒ cÃ³ thá»ƒ táº¡o 1 cÃ¢u hoÃ n chá»‰nh tá»« cÃ¡c key input. VD input: [A,B,5p] => Output: "" Äi tá»« A Ä‘áº¿n B máº¥t 5p"". Má»i ngÆ°á»i giÃºp em vá»›i áº¡",,,,,
"KhÃ´ng biáº¿t cÃ³ ai biáº¿t model translate VI -> EN nÃ o tá»‘t khÃ´ng áº¡?
Hiá»‡n team mÃ¬nh cÃ³ thá»­ 1 sá»‘ translation model nhÆ°ng káº¿t quáº£ khÃ´ng Ä‘Æ°á»£c nhÆ° Ã½ láº¯m... MÃ¬nh cÅ©ng báºµng 1 thá»i gian khÃ´ng cáº­p nháº­t thÃªm nhá»¯ng dá»± Ã¡n má»›i nÃªn ráº¥t mong má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp Ä‘á»¡ áº¡
MÃ¬nh cÃ³ vá»«a thá»­ 1 sá»‘ model nhÆ° á»Ÿ dÆ°á»›i
https://huggingface.co/vinai/vinai-translate-vi2en
https://huggingface.co/NlpHUST/t5-en-vi-small",KhÃ´ng biáº¿t cÃ³ ai biáº¿t model translate VI -> EN nÃ o tá»‘t khÃ´ng áº¡? Hiá»‡n team mÃ¬nh cÃ³ thá»­ 1 sá»‘ translation model nhÆ°ng káº¿t quáº£ khÃ´ng Ä‘Æ°á»£c nhÆ° Ã½ láº¯m... MÃ¬nh cÅ©ng báºµng 1 thá»i gian khÃ´ng cáº­p nháº­t thÃªm nhá»¯ng dá»± Ã¡n má»›i nÃªn ráº¥t mong má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp Ä‘á»¡ áº¡ MÃ¬nh cÃ³ vá»«a thá»­ 1 sá»‘ model nhÆ° á»Ÿ dÆ°á»›i https://huggingface.co/vinai/vinai-translate-vi2en https://huggingface.co/NlpHUST/t5-en-vi-small,,,,,
"Má»i ngÆ°á»i cÃ³ biáº¿t platform nÃ o á»Ÿ VN mÃ¬nh cho (data) freelancers khÃ´ng? Giá»‘ng nhÆ° Got-it.ai hoáº·c Freelancer.com.
MÃ¬nh hay cÃ³ máº¥y viá»‡c nhá» nhá» cáº§n khoáº£ng 2 - 3 tiáº¿ng mÃ  Ä‘á»u Ä‘Äƒng lÃªn freelancer.com háº¿t cáº£. Máº¥y báº¡n áº¤n Äá»™ + Bangladesh ná»™p proposals nhiá»u, mÃ  khÃ´ng tháº¥y ai á»Ÿ VN cáº£.","Má»i ngÆ°á»i cÃ³ biáº¿t platform nÃ o á»Ÿ VN mÃ¬nh cho (data) freelancers khÃ´ng? Giá»‘ng nhÆ° Got-it.ai hoáº·c Freelancer.com. MÃ¬nh hay cÃ³ máº¥y viá»‡c nhá» nhá» cáº§n khoáº£ng 2 - 3 tiáº¿ng mÃ  Ä‘á»u Ä‘Äƒng lÃªn freelancer.com háº¿t cáº£. Máº¥y báº¡n áº¤n Äá»™ + Bangladesh ná»™p proposals nhiá»u, mÃ  khÃ´ng tháº¥y ai á»Ÿ VN cáº£.",,,,,
"Em xin chÃ o má»i ngÆ°á»i.
Hiá»‡n em cÃ³ dá»± Ä‘á»‹nh nghiÃªn cá»©u theo nhá»¯ng máº£ng liÃªn quan toÃ¡n nhiá»u trong machine learning nhÆ° machine reasoning, bayesian inference & optimal transport do em cÃ³ há»©ng thÃº vÃ  tÃ² mÃ² vá» lÃ½ thuyáº¿t cÅ©ng nhÆ° cÃ¡ch toÃ¡n há»c váº­n hÃ nh trong ML/DL.
Vá» kiáº¿n thá»©c em Ä‘Ã£ Ä‘á»c qua cÃ¡c cuá»‘n sÃ¡ch nhÆ° ML CÆ¡ báº£n cá»§a anh Tiá»‡p, Dive into DL, Mathematics in ML, Linear Algebra by Gilbert Strang, All of Statistics: A Concise Course in Statistics (50%) vÃ  sÃ¡ch cá»§a Bishop (50%). Tuy nhiÃªn vá» kinh nghiá»‡m nghiÃªn cá»©u thÃ¬ em táº­p trung chá»§ yáº¿u á»Ÿ integrated CV & NLP cá»™ng má»™t Ã­t vá» GNN, em váº«n chÆ°a hÃ¬nh dung háº¿t vá» cÃ¡ch nghiÃªn cá»©u cá»§a cÃ¡c máº£ng thiÃªn vá» toÃ¡n nhiá»u.
Váº¥n Ä‘á» hiá»‡n táº¡i cá»§a em lÃ  tuy em Ä‘Ã£ cá»‘ gáº¯ng bá»• sung cÃ¡c kiáº¿n thá»©c ná»n táº£ng vÃ  kháº£ nÄƒng nghiÃªn cá»©u bÃªn nhá»¯ng máº£ng khÃ¡c, nhÆ°ng em váº«n khÃ´ng thá»ƒ Ä‘á»c hiá»ƒu má»™t paper thuáº§n vá» mathematics vÃ  statistic trong ML, cÅ©ng nhÆ° em váº«n chÆ°a náº¯m khÃ¡i niá»‡m cá»¥ thá»ƒ vá» nhá»¯ng cáº£i tiáº¿n hay lÃ½ thuyáº¿t trong máº£ng nÃ y.
Em muá»‘n há»i kinh nghiá»‡m má»i ngÆ°á»i Ä‘i trÆ°á»›c lÃ  khi báº¯t Ä‘áº§u thÃ¬ liá»‡u cÃ³ nhá»¯ng paper tiÃªu biá»ƒu, hay nhá»¯ng blog/link nÃ o hÆ°á»›ng dáº«n chi tiáº¿t cho nhá»¯ng bÆ°á»›c khá»Ÿi Ä‘áº§u nÃ y khÃ´ng áº¡. Vá» hÆ°á»›ng Ä‘i tiáº¿p theo em váº«n tÃ­nh theo nhá»¯ng máº£ng Ä‘Ã£ cÃ³ nghiÃªn cá»©u, nhÆ°ng vá» nhá»¯ng bÆ°á»›c lÃ¢u hÆ¡n em váº«n muá»‘n theo Ä‘uá»•i máº£ng náº·ng vá» toÃ¡n vÃ  lÃ½ thuyáº¿t hÆ¡n, nÃªn náº¿u Ä‘Æ°á»£c em mong má»i ngÆ°á»i chia sáº» em nhá»¯ng kinh nghiá»‡m vÃ  hÆ°á»›ng há»£p lÃ½ khi báº¯t Ä‘áº§u máº£ng nÃ y áº¡ :'>.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Em xin chÃ o má»i ngÆ°á»i. Hiá»‡n em cÃ³ dá»± Ä‘á»‹nh nghiÃªn cá»©u theo nhá»¯ng máº£ng liÃªn quan toÃ¡n nhiá»u trong machine learning nhÆ° machine reasoning, bayesian inference & optimal transport do em cÃ³ há»©ng thÃº vÃ  tÃ² mÃ² vá» lÃ½ thuyáº¿t cÅ©ng nhÆ° cÃ¡ch toÃ¡n há»c váº­n hÃ nh trong ML/DL. Vá» kiáº¿n thá»©c em Ä‘Ã£ Ä‘á»c qua cÃ¡c cuá»‘n sÃ¡ch nhÆ° ML CÆ¡ báº£n cá»§a anh Tiá»‡p, Dive into DL, Mathematics in ML, Linear Algebra by Gilbert Strang, All of Statistics: A Concise Course in Statistics (50%) vÃ  sÃ¡ch cá»§a Bishop (50%). Tuy nhiÃªn vá» kinh nghiá»‡m nghiÃªn cá»©u thÃ¬ em táº­p trung chá»§ yáº¿u á»Ÿ integrated CV & NLP cá»™ng má»™t Ã­t vá» GNN, em váº«n chÆ°a hÃ¬nh dung háº¿t vá» cÃ¡ch nghiÃªn cá»©u cá»§a cÃ¡c máº£ng thiÃªn vá» toÃ¡n nhiá»u. Váº¥n Ä‘á» hiá»‡n táº¡i cá»§a em lÃ  tuy em Ä‘Ã£ cá»‘ gáº¯ng bá»• sung cÃ¡c kiáº¿n thá»©c ná»n táº£ng vÃ  kháº£ nÄƒng nghiÃªn cá»©u bÃªn nhá»¯ng máº£ng khÃ¡c, nhÆ°ng em váº«n khÃ´ng thá»ƒ Ä‘á»c hiá»ƒu má»™t paper thuáº§n vá» mathematics vÃ  statistic trong ML, cÅ©ng nhÆ° em váº«n chÆ°a náº¯m khÃ¡i niá»‡m cá»¥ thá»ƒ vá» nhá»¯ng cáº£i tiáº¿n hay lÃ½ thuyáº¿t trong máº£ng nÃ y. Em muá»‘n há»i kinh nghiá»‡m má»i ngÆ°á»i Ä‘i trÆ°á»›c lÃ  khi báº¯t Ä‘áº§u thÃ¬ liá»‡u cÃ³ nhá»¯ng paper tiÃªu biá»ƒu, hay nhá»¯ng blog/link nÃ o hÆ°á»›ng dáº«n chi tiáº¿t cho nhá»¯ng bÆ°á»›c khá»Ÿi Ä‘áº§u nÃ y khÃ´ng áº¡. Vá» hÆ°á»›ng Ä‘i tiáº¿p theo em váº«n tÃ­nh theo nhá»¯ng máº£ng Ä‘Ã£ cÃ³ nghiÃªn cá»©u, nhÆ°ng vá» nhá»¯ng bÆ°á»›c lÃ¢u hÆ¡n em váº«n muá»‘n theo Ä‘uá»•i máº£ng náº·ng vá» toÃ¡n vÃ  lÃ½ thuyáº¿t hÆ¡n, nÃªn náº¿u Ä‘Æ°á»£c em mong má»i ngÆ°á»i chia sáº» em nhá»¯ng kinh nghiá»‡m vÃ  hÆ°á»›ng há»£p lÃ½ khi báº¯t Ä‘áº§u máº£ng nÃ y áº¡ :'>. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"Smartphone dÃ¹ng ká»¹ thuáº­t gÃ¬ Ä‘á»ƒ nháº­n dáº¡ng khuÃ´n máº·t?
Siamese network hoáº¡t Ä‘á»™ng dá»±a trÃªn ká»¹ thuáº­t one shot learning khÃ´ng Ä‘Ã²i há»i huáº¥n luyá»‡n, cho máº¡ng hai bá»©c áº£nh khuÃ´n máº·t vÃ  máº¡ng sáº½ ra káº¿t luáº­n 2 áº£nh nÃ y cÃ³ giá»‘ng nhau khÃ´ng.
PhÆ°Æ¡ng phÃ¡p nÃ y giÃºp nháº­n dáº¡ng tÆ°Æ¡ng Ä‘á»‘i chÃ­nh xÃ¡c, cÃ³ thá»ƒ cÃ i Ä‘áº·t trÃªn Ä‘iá»‡n thoáº¡i Android hay iOS.
https://github.com/adityajn105/Face-Recognition-Siamese-Network
https://en.wikipedia.org/wiki/Siamese_neural_network","Smartphone dÃ¹ng ká»¹ thuáº­t gÃ¬ Ä‘á»ƒ nháº­n dáº¡ng khuÃ´n máº·t? Siamese network hoáº¡t Ä‘á»™ng dá»±a trÃªn ká»¹ thuáº­t one shot learning khÃ´ng Ä‘Ã²i há»i huáº¥n luyá»‡n, cho máº¡ng hai bá»©c áº£nh khuÃ´n máº·t vÃ  máº¡ng sáº½ ra káº¿t luáº­n 2 áº£nh nÃ y cÃ³ giá»‘ng nhau khÃ´ng. PhÆ°Æ¡ng phÃ¡p nÃ y giÃºp nháº­n dáº¡ng tÆ°Æ¡ng Ä‘á»‘i chÃ­nh xÃ¡c, cÃ³ thá»ƒ cÃ i Ä‘áº·t trÃªn Ä‘iá»‡n thoáº¡i Android hay iOS. https://github.com/adityajn105/Face-Recognition-Siamese-Network https://en.wikipedia.org/wiki/Siamese_neural_network",,,,,
"End to End Machine Learning Projects
19 Videos
https://www.youtube.com/playlist?list=PL_1pt6K-CLoDcWw_c196kZn7aPeLdRDOU",End to End Machine Learning Projects 19 Videos https://www.youtube.com/playlist?list=PL_1pt6K-CLoDcWw_c196kZn7aPeLdRDOU,,,,,
"[AI Share - aman.ai]
aman.ai lÃ  má»™t trang web tá»•ng há»£p ráº¥t nhiá»u thá»© vá» AI, Ä‘Æ°á»£c chia lÃ m 5 pháº§n chÃ­nh:
- Distilled AI: tá»•ng há»£p cÃ¡c khÃ³a há»c cá»§a Stanford CS229, CS230, CS231n, CS224n, Recommendation Systems, Coursera Deep learning,...
- Research: tá»•ng há»£p cÃ¡c paper vá» NLP, CV,..
- Primers: tuyá»ƒn táº­p cÃ¡c bÃ i viáº¿t vá» cÃ¡c khÃ¡i niá»‡m, nguyÃªn táº¯c, quÃ¡ trÃ¬nh huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡ káº¿t quáº£. CÃ³ cáº£ chia theo cÃ¡c thÆ° viá»‡n nhÆ° Numpy, Pandas, Pytorch, Tensorflow,Math,..
- Coding: tá»« cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n nhÆ° Sort/Search Ä‘áº¿n Cáº¥u trÃºc dá»¯ liá»‡u nÃ¢ng cao hÆ¡n nhÆ° Stack, Queue, Linked List, Binary tree,.. vÃ  Ä‘á»™ phá»©c táº¡p cá»§a thuáº­t toÃ¡n.
- Reading: tá»•ng há»£p cÃ¡c list paper chia theo cÃ¡c chá»§ Ä‘á» theo tá»«ng nÄƒm vÃ  nhá»¯ng ghi chÃº, cÃ¡c sÃ¡ch, blog, video tham kháº£o theo cÃ¡c chá»§ Ä‘á».
Link: https://aman.ai/","[AI Share - aman.ai] aman.ai lÃ  má»™t trang web tá»•ng há»£p ráº¥t nhiá»u thá»© vá» AI, Ä‘Æ°á»£c chia lÃ m 5 pháº§n chÃ­nh: - Distilled AI: tá»•ng há»£p cÃ¡c khÃ³a há»c cá»§a Stanford CS229, CS230, CS231n, CS224n, Recommendation Systems, Coursera Deep learning,... - Research: tá»•ng há»£p cÃ¡c paper vá» NLP, CV,.. - Primers: tuyá»ƒn táº­p cÃ¡c bÃ i viáº¿t vá» cÃ¡c khÃ¡i niá»‡m, nguyÃªn táº¯c, quÃ¡ trÃ¬nh huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡ káº¿t quáº£. CÃ³ cáº£ chia theo cÃ¡c thÆ° viá»‡n nhÆ° Numpy, Pandas, Pytorch, Tensorflow,Math,.. - Coding: tá»« cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n nhÆ° Sort/Search Ä‘áº¿n Cáº¥u trÃºc dá»¯ liá»‡u nÃ¢ng cao hÆ¡n nhÆ° Stack, Queue, Linked List, Binary tree,.. vÃ  Ä‘á»™ phá»©c táº¡p cá»§a thuáº­t toÃ¡n. - Reading: tá»•ng há»£p cÃ¡c list paper chia theo cÃ¡c chá»§ Ä‘á» theo tá»«ng nÄƒm vÃ  nhá»¯ng ghi chÃº, cÃ¡c sÃ¡ch, blog, video tham kháº£o theo cÃ¡c chá»§ Ä‘á». Link: https://aman.ai/",,,,,
"[CÃ¢u há»i vá» LSTM][Pytorch]
Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  cÃ³ cáº§n thiáº¿t pháº£i initialize hidden state trong hÃ m forward khÃ´ng áº¡?
MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.",[CÃ¢u há»i vá» LSTM][Pytorch] Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  cÃ³ cáº§n thiáº¿t pháº£i initialize hidden state trong hÃ m forward khÃ´ng áº¡? MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m tiá»ƒu luáº­n chuyÃªn ngÃ nh vá» sá»­ dá»¥ng Polynomial Classifiers Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u nhÆ°ng Ä‘ang gáº·p khÃ³ khÄƒn vá» tÃ¬m kiáº¿m thuáº­t toÃ¡n cÅ©ng nhÆ° cÃ¡ch tÃ­nh vá» model Polynomial Classifiers. Anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u liÃªn quan Ä‘áº¿n Polynomial Classifiers cÃ³ thá»ƒ cho em xin thao kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡","Em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m tiá»ƒu luáº­n chuyÃªn ngÃ nh vá» sá»­ dá»¥ng Polynomial Classifiers Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u nhÆ°ng Ä‘ang gáº·p khÃ³ khÄƒn vá» tÃ¬m kiáº¿m thuáº­t toÃ¡n cÅ©ng nhÆ° cÃ¡ch tÃ­nh vá» model Polynomial Classifiers. Anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u liÃªn quan Ä‘áº¿n Polynomial Classifiers cÃ³ thá»ƒ cho em xin thao kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang nghiÃªn cá»©u vá» pháº§n nÃ y nÃªn máº¡nh dáº¡n chia sáº» cho má»i ngÆ°á»i cÃ¡ch triá»ƒn khai Object Detection on Video Streaming trÃªn web.
Hi vá»ng giÃºp Ä‘Æ°á»£c cáº£ nhÃ !",KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang nghiÃªn cá»©u vá» pháº§n nÃ y nÃªn máº¡nh dáº¡n chia sáº» cho má»i ngÆ°á»i cÃ¡ch triá»ƒn khai Object Detection on Video Streaming trÃªn web. Hi vá»ng giÃºp Ä‘Æ°á»£c cáº£ nhÃ !,,,,,
"HiÃªÌ£n taÌ£i em Ä‘ang thÆ°Ì£c hiÃªÌ£n Ä‘Ã´Ì€ aÌn vÃªÌ€ self-driving car. Em coÌ tham khaÌ‰o git Behavioral Cloning thÆ°Ì£c hiÃªÌ£n theo thiÌ€ chaÌ£y Ä‘Æ°Æ¡Ì£c trÃªn map mÃ¢Ìƒu, nhÆ°ng khi em thÆ°Ì£c hiÃªÌ£n Æ¡Ì‰ map custom khaÌc thiÌ€ khÃ´ng Ä‘Æ°á»£c tÃ´Ìt cho láº¯m. Anh chiÌ£ naÌ€o coÌ kinh nghiÃªÌ£m coÌ thÃªÌ‰ gÆ¡Ì£i yÌ hoÄƒÌ£c hÃ´Ìƒ trÆ¡Ì£ em Ä‘Æ°Æ¡Ì£c khÃ´ng aÌ£.
Link github em tham kháº£o: https://github.com/ndrplz/self-driving-car
#self_driving_car #autonomous_vehicle","HiÃªÌ£n taÌ£i em Ä‘ang thÆ°Ì£c hiÃªÌ£n Ä‘Ã´Ì€ aÌn vÃªÌ€ self-driving car. Em coÌ tham khaÌ‰o git Behavioral Cloning thÆ°Ì£c hiÃªÌ£n theo thiÌ€ chaÌ£y Ä‘Æ°Æ¡Ì£c trÃªn map mÃ¢Ìƒu, nhÆ°ng khi em thÆ°Ì£c hiÃªÌ£n Æ¡Ì‰ map custom khaÌc thiÌ€ khÃ´ng Ä‘Æ°á»£c tÃ´Ìt cho láº¯m. Anh chiÌ£ naÌ€o coÌ kinh nghiÃªÌ£m coÌ thÃªÌ‰ gÆ¡Ì£i yÌ hoÄƒÌ£c hÃ´Ìƒ trÆ¡Ì£ em Ä‘Æ°Æ¡Ì£c khÃ´ng aÌ£. Link github em tham kháº£o: https://github.com/ndrplz/self-driving-car",#self_driving_car	#autonomous_vehicle,,,,
"Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t tÃ i liá»‡u khá»§ng (2188 trang) do hai giÃ¡o sÆ° Jean Gallier & Jocelyn Quaintance cá»§a University of Pennsylvania biÃªn soáº¡n. TÃ i liá»‡u gáº§n nhÆ° cover háº¿t nhá»¯ng chá»§ Ä‘á» toÃ¡n há»c phá»¥c vá»¥ cho Machine Learning/Deep Learning.
https://www.cis.upenn.edu/~jean/math-deep.pdf
Source: https://twitter.com/deliprao/status/1582531571394916352",Xin giá»›i thiá»‡u vá»›i má»i ngÆ°á»i má»™t tÃ i liá»‡u khá»§ng (2188 trang) do hai giÃ¡o sÆ° Jean Gallier & Jocelyn Quaintance cá»§a University of Pennsylvania biÃªn soáº¡n. TÃ i liá»‡u gáº§n nhÆ° cover háº¿t nhá»¯ng chá»§ Ä‘á» toÃ¡n há»c phá»¥c vá»¥ cho Machine Learning/Deep Learning. https://www.cis.upenn.edu/~jean/math-deep.pdf Source: https://twitter.com/deliprao/status/1582531571394916352,,,,,
"MÃ¬nh (má»›i) dÃ¹ng RSelenium Ä‘á»ƒ download data tá»« URL nÃ y:
https://www.cbd.gov.au/get-assessed/how/find-rated-building
MÃ¬nh muá»‘n chá»n má»™t state (vÃ­ dá»¥ ACT), click Search Ä‘á»ƒ hiá»ƒn thá»‹ táº¥t cáº£ cÃ¡c káº¿t quáº£ cá»§a bang ACT nÃ y. Tuy nhiÃªn khi findelement Ä‘á»ƒ chá»n state thÃ¬ Ä‘á»u bá»‹ lá»—i khÃ´ng tÃ¬m Ä‘Æ°á»£c (NoSuchElement: An element could not be located on the page using the given search parameters).
Code dÆ°á»›i Ä‘Ã¢y mÃ¬nh tÃ¬m theo Xpath:
stateselect <- remDr$findElement(using = 'xpath', value = '//*[@id=""state""]')
HÃ¬nh Ä‘Ã­nh kÃ¨m lÃ  inspect page vÃ  screenshots hiá»ƒn thá»‹ káº¿t quáº£ mong muá»‘n.
Nhá» má»i ngÆ°á»i xem giÃºp.
MÃ¬nh cáº£m Æ¡n.
C","MÃ¬nh (má»›i) dÃ¹ng RSelenium Ä‘á»ƒ download data tá»« URL nÃ y: https://www.cbd.gov.au/get-assessed/how/find-rated-building MÃ¬nh muá»‘n chá»n má»™t state (vÃ­ dá»¥ ACT), click Search Ä‘á»ƒ hiá»ƒn thá»‹ táº¥t cáº£ cÃ¡c káº¿t quáº£ cá»§a bang ACT nÃ y. Tuy nhiÃªn khi findelement Ä‘á»ƒ chá»n state thÃ¬ Ä‘á»u bá»‹ lá»—i khÃ´ng tÃ¬m Ä‘Æ°á»£c (NoSuchElement: An element could not be located on the page using the given search parameters). Code dÆ°á»›i Ä‘Ã¢y mÃ¬nh tÃ¬m theo Xpath: stateselect <- remDr$findElement(using = 'xpath', value = '//*[@id=""state""]') HÃ¬nh Ä‘Ã­nh kÃ¨m lÃ  inspect page vÃ  screenshots hiá»ƒn thá»‹ káº¿t quáº£ mong muá»‘n. Nhá» má»i ngÆ°á»i xem giÃºp. MÃ¬nh cáº£m Æ¡n. C",,,,,
"Em chÃ o má»i ngÆ°á»i , em cÃ³ má»™t cÃ¢u há»i vá» viá»‡c sá»­ dá»¥ng cÃ¡c model text2text nhÆ° BART, T5,... vá»›i cÃ¡c bÃ i toÃ¡n extract/abstract keywords/keyphrasekeyphrase Ä‘Æ°á»£c ngÄƒn cÃ¡ch bá»Ÿi dáº¥u , hoáº·c ;

Khi model predict sá»­ dá»¥ng model.generate chÃºng ta chá»‰ cÃ³ thá»ƒ kiá»ƒm soÃ¡t Ä‘Æ°Æ¡c max_length cá»§a list keywords/keyphrase Ä‘Ã³ chá»© khÃ´ng kiá»ƒm soÃ¡t Ä‘Æ°á»£c max_length cá»§a tá»«ng keyword hoáº·c keyphrase Ä‘Ã³

Má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ dá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y khÃ´ng áº¡, á»Ÿ viá»‡c training hay Ä‘Ã¡nh giÃ¡

Em cáº£m Æ¡n má»i ngÆ°á»i !
#nlp #huggingface
 â€” Ä‘ang cáº£m tháº¥y bá»‘i rá»‘i.","Em chÃ o má»i ngÆ°á»i , em cÃ³ má»™t cÃ¢u há»i vá» viá»‡c sá»­ dá»¥ng cÃ¡c model text2text nhÆ° BART, T5,... vá»›i cÃ¡c bÃ i toÃ¡n extract/abstract keywords/keyphrasekeyphrase Ä‘Æ°á»£c ngÄƒn cÃ¡ch bá»Ÿi dáº¥u , hoáº·c ; Khi model predict sá»­ dá»¥ng model.generate chÃºng ta chá»‰ cÃ³ thá»ƒ kiá»ƒm soÃ¡t Ä‘Æ°Æ¡c max_length cá»§a list keywords/keyphrase Ä‘Ã³ chá»© khÃ´ng kiá»ƒm soÃ¡t Ä‘Æ°á»£c max_length cá»§a tá»«ng keyword hoáº·c keyphrase Ä‘Ã³ Má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ dá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y khÃ´ng áº¡, á»Ÿ viá»‡c training hay Ä‘Ã¡nh giÃ¡ Em cáº£m Æ¡n má»i ngÆ°á»i ! â€” Ä‘ang cáº£m tháº¥y bá»‘i rá»‘i.",#nlp	#huggingface,,,,
"Random Seed
A. Váº¤N Äá»€
Khi báº¡n Ä‘á»c 1 paper vá» chá»§ Ä‘á» mÃ¬nh quan tÃ¢m vÃ  cÃ³ public code trÃªn github, hoáº·c Ä‘Æ¡n giáº£n báº¡n muá»‘n táº£i 1 project trÃªn github vá» vÃ  thá»±c hiá»‡n láº¡i trÃªn mÃ¡y tÃ­nh cá»§a mÃ¬nh, thÃ¬ kháº£ nÄƒng káº¿t quáº£ thu Ä‘Æ°á»£c khÃ´ng giá»‘ng vá»›i paper gá»‘c ráº¥t cao. Tháº­m chÃ­ khi báº¡n rebuild project vá»›i cáº¥u hÃ¬nh mÃ¡y tÃ­nh, cáº¥u trÃºc dá»¯ liá»‡u, kiáº¿n trÃºc mÃ´ hÃ¬nh, â€¦ giá»‘ng nhau nhÆ°ng káº¿t quáº£ thu Ä‘Æ°á»£c sau má»—i láº§n cháº¡y cÃ³ thá»ƒ khÃ¡c nhau. Báº¡n Ä‘Ã£ lo láº¯ng, nghi ngá» vá» kháº£ nÄƒng cá»§a báº£n thÃ¢n? Xin báº¡n hÃ£y yÃªn tÃ¢m, Ä‘iá»u Ä‘Ã³ lÃ  hoÃ n toÃ n bÃ¬nh thÆ°á»ng. Váº­y nguyÃªn nhÃ¢n do Ä‘Ã¢u vÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o? ChÃºng ta hÃ£y cÃ¹ng tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» nÃ y ngay sau Ä‘Ã¢y.
B. CÃCH GIáº¢I QUYáº¾T
CÃ³ ráº¥t nhiá»u nguyÃªn nhÃ¢n vÃ  cÃ¡ch kháº¯c phá»¥c tÃ¬nh tráº¡ng nÃ y, báº¡n cÃ³ thá»ƒ tham kháº£o trong cÃ¡c tÃ i liá»‡u vá» Reproducibility. Trong Ä‘Ã³ cÃ¡c váº¥n Ä‘á» vá» random seed nhÆ° viá»‡c khá»Ÿi táº¡o cÃ¡c giÃ¡ trá»‹ ngáº«u nhiÃªn, cÃ¡c biáº¿n Ä‘á»•i tÄƒng cÆ°á»ng dá»¯ liá»‡u ngáº«u nhiÃªn, thÃªm ngáº«u nhiÃªn cÃ¡c nhiá»…u, viá»‡c chá»n lá»±a ngáº«u nhiÃªn cÃ¡c layers áº©n, dropout, â€¦ cÅ©ng má»™t pháº§n lÃ m thay Ä‘á»•i káº¿t quáº£ sau má»—i láº§n thá»±c hiá»‡n. Trong bÃ i viáº¿t nÃ y chÃºng ta cÃ¹ng tÃ¬m hiá»ƒu Ä‘Ã´i chÃºt vá» Random Seed, cÅ©ng nhÆ° cÃ¡ch sá»­ dá»¥ng Random Seed má»™t cÃ¡ch hiá»‡u quáº£.
Random Seed lÃ  gÃ¬?
Random Seed Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘áº£m báº£o khi thá»±c hiá»‡n re-implement project qua nhiá»u láº§n vá»›i cÃ¹ng input, code, model cÃ³ thá»ƒ cho ra cÃ¹ng 1 output
2. LÃ m tháº¿ nÃ o Ä‘á»ƒ sá»­ dá»¥ng Random Seed 1 cÃ¡ch hiá»‡u quáº£?
Sau Ä‘Ã¢y lÃ  3 phÆ°Æ¡ng phÃ¡p phá»• biáº¿n Ä‘Æ°á»£c Ã¡p dá»¥ng:
2.1 Kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh táº¡o sá»‘ ngáº«u nhiÃªn (Random Number Generator - RNG) trong PyTorch cho cÃ¡c thiáº¿t bá»‹ CPU vÃ  CUDA
import torch
torch.manual_seed(seed_value)
2.2 Äáº·t cá»‘ Ä‘á»‹nh cÃ¡c giÃ¡ trá»‹ ngáº«u nhiÃªn trong Python
import random
random.seed(seed_value)
2.3 TrÃ¬nh táº¡o giÃ¡ trá»‹ ngáº«u nhiÃªn trong Numpy
import numpy as np
np.random.seed(seed_value)
Trong Ä‘Ã³ seed_value lÃ  1 con sá»‘ tÃ¹y Ã½.
C. VÃ Dá»¤ MINH Há»ŒA
import numpy as np
import torch
import os
import random
#############################
def seed_everything(seed):
os.environ['PYTHONHASHSEED'] = str(seed) # set environ
random.seed(seed) # set python seed
np.random.seed(seed) # seed the global NumPy RNG
torch.manual_seed(seed) # seed the RNG for all devices (both CPU and CUDA):
torch.cuda.manual_seed_all(seed)
torch.use_deterministic_algorithms(True)
#############################
seed = 152022 # set seed value
seed_everything(seed)
Ãp dá»¥ng trong phÃ¢n chia táº­p dá»¯ liá»‡u thÃ nh train/test sá»­ dá»¥ng hÃ m train_test_split trong sklearn.model_selection. Khi Ä‘Ã³ tham sá»‘ random_state = 42 set random seed cÃ¹ng má»™t giÃ¡ trá»‹ má»—i khi báº¡n cháº¡y code sau. CÃ³ nghÄ©a lÃ  báº¡n sáº½ nháº­n cÃ¹ng 1 phÃ¢n bá»‘ dá»¯ liá»‡u (y_train, y_test) á»Ÿ má»—i láº§n phÃ¢n chia
from sklearn import datasets
from sklearn.model_selection import train_test_split
iris = datasets.load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
np.bincount(y_train) # array([31, 37, 37])
np.bincount(y_test) # array([19, 13, 13])
Náº¿u bá» qua tham sá»‘ random_state thÃ¬ phÃ¢n bá»‘ dá»¯ liá»‡u á»Ÿ má»—i láº§n cháº¡y sáº½ khÃ¡c nhau
X_train, X_tesst, y_train, y_test = train_test_split(X, y, test_size = 0.3 )
np.bincount(y_train) # array([37, 34, 34]) # array([33, 40, 32])
np.bincount(y_test) # array([13, 16, 16]) # array([17, 10, 18])
D. Káº¾T LUáº¬N
Khi kiá»ƒm soÃ¡t Ä‘Æ°á»£c giÃ¡ trá»‹ ngáº«u nhiÃªn thÃ¬ má»—i láº§n thá»±c hiá»‡n láº¡i project vá»›i cÃ¹ng input vÃ  kiáº¿n trÃºc mÃ´ hÃ¬nh, code, â€¦ thÃ¬ sáº½ thu Ä‘Æ°á»£c cÃ¹ng output
E. THAM KHáº¢O
https://pytorch.org/docs/stable/notes/randomness.html
https://neptune.ai/blog/how-to-solve-reproducibility-in-ml?fbclid=IwAR0MgKGQ2orpoeV1H3yESOFDpwQd-YPrdu2HmjeCHOt4Fuj4LkguHEIqZw4
https://vitalflux.com/why-use-random-seed-in-machine-learning/
https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79","Random Seed A. Váº¤N Äá»€ Khi báº¡n Ä‘á»c 1 paper vá» chá»§ Ä‘á» mÃ¬nh quan tÃ¢m vÃ  cÃ³ public code trÃªn github, hoáº·c Ä‘Æ¡n giáº£n báº¡n muá»‘n táº£i 1 project trÃªn github vá» vÃ  thá»±c hiá»‡n láº¡i trÃªn mÃ¡y tÃ­nh cá»§a mÃ¬nh, thÃ¬ kháº£ nÄƒng káº¿t quáº£ thu Ä‘Æ°á»£c khÃ´ng giá»‘ng vá»›i paper gá»‘c ráº¥t cao. Tháº­m chÃ­ khi báº¡n rebuild project vá»›i cáº¥u hÃ¬nh mÃ¡y tÃ­nh, cáº¥u trÃºc dá»¯ liá»‡u, kiáº¿n trÃºc mÃ´ hÃ¬nh, â€¦ giá»‘ng nhau nhÆ°ng káº¿t quáº£ thu Ä‘Æ°á»£c sau má»—i láº§n cháº¡y cÃ³ thá»ƒ khÃ¡c nhau. Báº¡n Ä‘Ã£ lo láº¯ng, nghi ngá» vá» kháº£ nÄƒng cá»§a báº£n thÃ¢n? Xin báº¡n hÃ£y yÃªn tÃ¢m, Ä‘iá»u Ä‘Ã³ lÃ  hoÃ n toÃ n bÃ¬nh thÆ°á»ng. Váº­y nguyÃªn nhÃ¢n do Ä‘Ã¢u vÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o? ChÃºng ta hÃ£y cÃ¹ng tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» nÃ y ngay sau Ä‘Ã¢y. B. CÃCH GIáº¢I QUYáº¾T CÃ³ ráº¥t nhiá»u nguyÃªn nhÃ¢n vÃ  cÃ¡ch kháº¯c phá»¥c tÃ¬nh tráº¡ng nÃ y, báº¡n cÃ³ thá»ƒ tham kháº£o trong cÃ¡c tÃ i liá»‡u vá» Reproducibility. Trong Ä‘Ã³ cÃ¡c váº¥n Ä‘á» vá» random seed nhÆ° viá»‡c khá»Ÿi táº¡o cÃ¡c giÃ¡ trá»‹ ngáº«u nhiÃªn, cÃ¡c biáº¿n Ä‘á»•i tÄƒng cÆ°á»ng dá»¯ liá»‡u ngáº«u nhiÃªn, thÃªm ngáº«u nhiÃªn cÃ¡c nhiá»…u, viá»‡c chá»n lá»±a ngáº«u nhiÃªn cÃ¡c layers áº©n, dropout, â€¦ cÅ©ng má»™t pháº§n lÃ m thay Ä‘á»•i káº¿t quáº£ sau má»—i láº§n thá»±c hiá»‡n. Trong bÃ i viáº¿t nÃ y chÃºng ta cÃ¹ng tÃ¬m hiá»ƒu Ä‘Ã´i chÃºt vá» Random Seed, cÅ©ng nhÆ° cÃ¡ch sá»­ dá»¥ng Random Seed má»™t cÃ¡ch hiá»‡u quáº£. Random Seed lÃ  gÃ¬? Random Seed Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘áº£m báº£o khi thá»±c hiá»‡n re-implement project qua nhiá»u láº§n vá»›i cÃ¹ng input, code, model cÃ³ thá»ƒ cho ra cÃ¹ng 1 output 2. LÃ m tháº¿ nÃ o Ä‘á»ƒ sá»­ dá»¥ng Random Seed 1 cÃ¡ch hiá»‡u quáº£? Sau Ä‘Ã¢y lÃ  3 phÆ°Æ¡ng phÃ¡p phá»• biáº¿n Ä‘Æ°á»£c Ã¡p dá»¥ng: 2.1 Kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh táº¡o sá»‘ ngáº«u nhiÃªn (Random Number Generator - RNG) trong PyTorch cho cÃ¡c thiáº¿t bá»‹ CPU vÃ  CUDA import torch torch.manual_seed(seed_value) 2.2 Äáº·t cá»‘ Ä‘á»‹nh cÃ¡c giÃ¡ trá»‹ ngáº«u nhiÃªn trong Python import random random.seed(seed_value) 2.3 TrÃ¬nh táº¡o giÃ¡ trá»‹ ngáº«u nhiÃªn trong Numpy import numpy as np np.random.seed(seed_value) Trong Ä‘Ã³ seed_value lÃ  1 con sá»‘ tÃ¹y Ã½. C. VÃ Dá»¤ MINH Há»ŒA import numpy as np import torch import os import random ############################# def seed_everything(seed): os.environ['PYTHONHASHSEED'] = str(seed) # set environ random.seed(seed) # set python seed np.random.seed(seed) # seed the global NumPy RNG torch.manual_seed(seed) # seed the RNG for all devices (both CPU and CUDA): torch.cuda.manual_seed_all(seed) torch.use_deterministic_algorithms(True) ############################# seed = 152022 # set seed value seed_everything(seed) Ãp dá»¥ng trong phÃ¢n chia táº­p dá»¯ liá»‡u thÃ nh train/test sá»­ dá»¥ng hÃ m train_test_split trong sklearn.model_selection. Khi Ä‘Ã³ tham sá»‘ random_state = 42 set random seed cÃ¹ng má»™t giÃ¡ trá»‹ má»—i khi báº¡n cháº¡y code sau. CÃ³ nghÄ©a lÃ  báº¡n sáº½ nháº­n cÃ¹ng 1 phÃ¢n bá»‘ dá»¯ liá»‡u (y_train, y_test) á»Ÿ má»—i láº§n phÃ¢n chia from sklearn import datasets from sklearn.model_selection import train_test_split iris = datasets.load_iris() X = iris.data y = iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) np.bincount(y_train) # array([31, 37, 37]) np.bincount(y_test) # array([19, 13, 13]) Náº¿u bá» qua tham sá»‘ random_state thÃ¬ phÃ¢n bá»‘ dá»¯ liá»‡u á»Ÿ má»—i láº§n cháº¡y sáº½ khÃ¡c nhau X_train, X_tesst, y_train, y_test = train_test_split(X, y, test_size = 0.3 ) np.bincount(y_train) # array([37, 34, 34]) # array([33, 40, 32]) np.bincount(y_test) # array([13, 16, 16]) # array([17, 10, 18]) D. Káº¾T LUáº¬N Khi kiá»ƒm soÃ¡t Ä‘Æ°á»£c giÃ¡ trá»‹ ngáº«u nhiÃªn thÃ¬ má»—i láº§n thá»±c hiá»‡n láº¡i project vá»›i cÃ¹ng input vÃ  kiáº¿n trÃºc mÃ´ hÃ¬nh, code, â€¦ thÃ¬ sáº½ thu Ä‘Æ°á»£c cÃ¹ng output E. THAM KHáº¢O https://pytorch.org/docs/stable/notes/randomness.html https://neptune.ai/blog/how-to-solve-reproducibility-in-ml?fbclid=IwAR0MgKGQ2orpoeV1H3yESOFDpwQd-YPrdu2HmjeCHOt4Fuj4LkguHEIqZw4 https://vitalflux.com/why-use-random-seed-in-machine-learning/ https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79",,,,,
"CÃ³ váº» nhÆ° Collab Ä‘Ã£ thay Ä‘á»•i dá»‹ch vá»¥ sá»­ dá»¥ng tÃ i nguyÃªn cá»§a mÃ¬nh.
Má»i ngÆ°á»i cho mÃ¬nh xin review gÃ³i Collab pro vá»›i, khÃ´ng biáº¿t cÃ³ Ä‘Æ°á»£c P100 nhÆ° ngÃ y trÆ°á»›c khÃ´ng áº¡, mÃ¬nh xin cáº£m Æ¡n !","CÃ³ váº» nhÆ° Collab Ä‘Ã£ thay Ä‘á»•i dá»‹ch vá»¥ sá»­ dá»¥ng tÃ i nguyÃªn cá»§a mÃ¬nh. Má»i ngÆ°á»i cho mÃ¬nh xin review gÃ³i Collab pro vá»›i, khÃ´ng biáº¿t cÃ³ Ä‘Æ°á»£c P100 nhÆ° ngÃ y trÆ°á»›c khÃ´ng áº¡, mÃ¬nh xin cáº£m Æ¡n !",,,,,
"CÃ¡c tiá»n bá»‘i cho em xin bÃ­ quyáº¿t tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a máº¡ng Siamese Model . em dÃ¹ng Xception + Triplet Loss ( Khoáº£ng cÃ¡ch Euclid ).
Äá»™ chÃ­nh xÃ¡c táº§m 0.66 ~ 0.72 lÃ  háº¿t cá»¡",CÃ¡c tiá»n bá»‘i cho em xin bÃ­ quyáº¿t tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a máº¡ng Siamese Model . em dÃ¹ng Xception + Triplet Loss ( Khoáº£ng cÃ¡ch Euclid ). Äá»™ chÃ­nh xÃ¡c táº§m 0.66 ~ 0.72 lÃ  háº¿t cá»¡,,,,,
"ChÃ o má»i ngÆ°á»i,

Hiá»‡n táº¡i em Ä‘ang tÃ¬m cÃ¡ch xÃ¢y dá»±ng láº¡i mÃ´ hÃ¬nh tá»« bÃ i bÃ¡o
Lifelog Moment Retrieval with Visual Concept Fusion and Text-based Query Expansion cá»§a Äáº¡i há»c Khoa Há»c Tá»± NhiÃªn TPHCM.
Trong bÃ i bÃ¡o cÃ³ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u lifelog cá»§a CLEF. 
NhÆ°ng em chÆ°a cÃ³ Ä‘Æ°á»£c dá»¯ liá»‡u.
KhÃ´ng biáº¿t anh chá»‹ nÃ o cÃ³ bá»™ dá»¯ liá»‡u nÃ y hoáº·c 1 bá»™ lifelog khÃ¡c khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang tÃ¬m cÃ¡ch xÃ¢y dá»±ng láº¡i mÃ´ hÃ¬nh tá»« bÃ i bÃ¡o Lifelog Moment Retrieval with Visual Concept Fusion and Text-based Query Expansion cá»§a Äáº¡i há»c Khoa Há»c Tá»± NhiÃªn TPHCM. Trong bÃ i bÃ¡o cÃ³ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u lifelog cá»§a CLEF. NhÆ°ng em chÆ°a cÃ³ Ä‘Æ°á»£c dá»¯ liá»‡u. KhÃ´ng biáº¿t anh chá»‹ nÃ o cÃ³ bá»™ dá»¯ liá»‡u nÃ y hoáº·c 1 bá»™ lifelog khÃ¡c khÃ´ng áº¡?",,,,,
# Huyen Chip,# Huyen Chip,,,,,
"#hoidap
Cho em há»i trong 1 dataset cÃ³ má»™t sá»‘ cá»™t thÃ¬ dÃ¹ng standard scaler , 1 sá»‘ cá»™t dÃ¹ng Min max sacler váº­y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ train khÃ´ng ?
CÃ¡m Æ¡n má»i ngÆ°á»i áº¡ !","Cho em há»i trong 1 dataset cÃ³ má»™t sá»‘ cá»™t thÃ¬ dÃ¹ng standard scaler , 1 sá»‘ cá»™t dÃ¹ng Min max sacler váº­y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ train khÃ´ng ? CÃ¡m Æ¡n má»i ngÆ°á»i áº¡ !",#hoidap,,,,
mÃ¬nh muá»‘n tÃ¬m tÃ i liá»‡u trainning module cá»§a mediapipe vá» Hands. báº¡n nÃ o biáº¿t á»Ÿ Ä‘Ã¢u cÃ³ cho mÃ¬nh tham kháº£o vá»›i áº¡ :'). mÃ¬nh cáº£m Æ¡n ráº¥t nhiá»u,mÃ¬nh muá»‘n tÃ¬m tÃ i liá»‡u trainning module cá»§a mediapipe vá» Hands. báº¡n nÃ o biáº¿t á»Ÿ Ä‘Ã¢u cÃ³ cho mÃ¬nh tham kháº£o vá»›i áº¡ :'). mÃ¬nh cáº£m Æ¡n ráº¥t nhiá»u,,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i lÃ  dá»¯ liá»‡u cá»§a em Ä‘Ã£ lÃ m sáº¡ch, nhÆ°ng khi em dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh CNN há»“i quy vÃ  nÃ³ dá»± Ä‘oÃ¡n sai khÃ¡ lÃ  nhiá»u thÃ¬ kháº£ nÄƒng cao lÃ  em Ä‘Ã£ bá»‹ dÃ­nh pháº£i lá»—i gÃ¬ áº¡? 
Em cáº£m Æ¡n sá»± Ä‘Ã³ng gÃ³p cá»§a táº¥t cáº£ má»i ngÆ°á»i áº¡ !
 â€” Ä‘ang cáº£m tháº¥y tÃ² mÃ².","Má»i ngÆ°á»i Æ¡i cho em há»i lÃ  dá»¯ liá»‡u cá»§a em Ä‘Ã£ lÃ m sáº¡ch, nhÆ°ng khi em dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh CNN há»“i quy vÃ  nÃ³ dá»± Ä‘oÃ¡n sai khÃ¡ lÃ  nhiá»u thÃ¬ kháº£ nÄƒng cao lÃ  em Ä‘Ã£ bá»‹ dÃ­nh pháº£i lá»—i gÃ¬ áº¡? Em cáº£m Æ¡n sá»± Ä‘Ã³ng gÃ³p cá»§a táº¥t cáº£ má»i ngÆ°á»i áº¡ ! â€” Ä‘ang cáº£m tháº¥y tÃ² mÃ².",,,,,
"Cho em há»i cÃ¢u nÃ y LUÃ”N Ä‘Ãºng vá»›i má»i trÆ°á»ng há»£p khÃ´ng áº¡? 
The less the Root Mean Squared Error (RMSE), The better the model is.

Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em
CÃ¡m Æ¡n má»i ngÆ°á»i áº¡ ","Cho em há»i cÃ¢u nÃ y LUÃ”N Ä‘Ãºng vá»›i má»i trÆ°á»ng há»£p khÃ´ng áº¡? The less the Root Mean Squared Error (RMSE), The better the model is. Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em CÃ¡m Æ¡n má»i ngÆ°á»i áº¡",,,,,
"#hoidap
[Problem with LSTM]
Xin chÃ o má»i ngÆ°á»i áº¡.
HIá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m má»™t project liÃªn quan Ä‘áº¿n LSTM model nhÆ°ng mÃ¬nh pháº§n accuracy cá»§a mÃ¬nh hÆ¡i cÃ³ váº¥n Ä‘á».
Vá»›i má»—i random seed mÃ¬nh dÃ¹ng thÃ¬ mÃ¬nh sáº½ nháº­n Ä‘Æ°á»£c accuracy khÃ¡c nhau. VÃ­ dá»¥ random seed cá»§a mÃ¬nh lÃ  0 thÃ¬ accuracy lÃ  80%, nhÆ°ng náº¿u nÃ³ lÃ  42 thÃ¬ accuracy lÃ  1%, nhÆ° kiá»ƒu model khÃ´ng há» learn áº¥y áº¡.
ÄÃ£ cÃ³ ai gáº·p váº¥n Ä‘á» nÃ y chÆ°a áº¡?
MÃ¬nh xin cáº£m Æ¡n áº¡!
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-
UPDATE:
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡ mÃ¬nh áº¡ â˜ºï¸. MÃ¬nh Ä‘Ã£ tÃ¬m ra lá»—i vÃ  Ä‘Ã³ lÃ  do sá»± ngoongok cá»§a mÃ¬nh khi quen tay set activation function lÃ  ReLU mÃ  khÃ´ng pháº£i lÃ  Sigmoid hay Tanh áº¡ ğŸ˜.","[Problem with LSTM] Xin chÃ o má»i ngÆ°á»i áº¡. HIá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m má»™t project liÃªn quan Ä‘áº¿n LSTM model nhÆ°ng mÃ¬nh pháº§n accuracy cá»§a mÃ¬nh hÆ¡i cÃ³ váº¥n Ä‘á». Vá»›i má»—i random seed mÃ¬nh dÃ¹ng thÃ¬ mÃ¬nh sáº½ nháº­n Ä‘Æ°á»£c accuracy khÃ¡c nhau. VÃ­ dá»¥ random seed cá»§a mÃ¬nh lÃ  0 thÃ¬ accuracy lÃ  80%, nhÆ°ng náº¿u nÃ³ lÃ  42 thÃ¬ accuracy lÃ  1%, nhÆ° kiá»ƒu model khÃ´ng há» learn áº¥y áº¡. ÄÃ£ cÃ³ ai gáº·p váº¥n Ä‘á» nÃ y chÆ°a áº¡? MÃ¬nh xin cáº£m Æ¡n áº¡! â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”- UPDATE: Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡ mÃ¬nh áº¡ . MÃ¬nh Ä‘Ã£ tÃ¬m ra lá»—i vÃ  Ä‘Ã³ lÃ  do sá»± ngoongok cá»§a mÃ¬nh khi quen tay set activation function lÃ  ReLU mÃ  khÃ´ng pháº£i lÃ  Sigmoid hay Tanh áº¡ .",#hoidap,,,,
"Nguá»“n tá»•ng há»£p cÃ¡c tÃ i liá»‡u vá» toÃ¡n há»c cho machine learning ráº¥t há»¯u Ã­ch bao gá»“m sÃ¡ch, paper vÃ  cÃ¡c video bÃ i giáº£ng... CÃ¡c báº¡n lÆ°u láº¡i tham kháº£o","Nguá»“n tá»•ng há»£p cÃ¡c tÃ i liá»‡u vá» toÃ¡n há»c cho machine learning ráº¥t há»¯u Ã­ch bao gá»“m sÃ¡ch, paper vÃ  cÃ¡c video bÃ i giáº£ng... CÃ¡c báº¡n lÆ°u láº¡i tham kháº£o",,,,,
"ChÃ o má»i ngÆ°á»i, 

Em Ä‘ang cÃ³ 1 bá»™ dá»¯ liá»‡u gá»“m:
Cá»™t: 3 cá»™t Ä‘iá»ƒm,  táº¡m gá»i lÃ  A,B,C
HÃ ng: má»—i hÃ ng trong báº£ng biá»ƒu thá»‹ Ä‘iá»ƒm cá»§a 1 láº§n test
Äá»‘i vá»›i má»—i láº§n test, Ä‘iá»ƒm A,B, C cÃ ng cao cÃ ng tá»‘t. Khi xem xÃ©t, em muá»‘n sá»­ dá»¥ng cáº£ Ä‘iá»ƒm A,B, C Ä‘á»ƒ xem test nÃ o tá»‘t nháº¥t. Do Ä‘Ã³, em cÃ³ Ã½ Ä‘á»‹nh táº¡o ra 1 cá»™t giÃ¡ trá»‹ (k) tá»•ng há»£p nÃ o Ä‘Ã³ báº±ng cÃ¡ch Ä‘Ã¡nh weights cho A,B, C. Vai trÃ² cá»§a cÃ¡c Ä‘iá»ƒm nÃ y khÃ´ng quÃ¡ chÃªnh lá»‡ch nhau nÃªn weights sáº½ khÃ´ng khÃ¡c nhau lÃ  máº¥y. 

Váº¥n Ä‘á» lÃ , giÃ¡ trá»‹ cá»§a A,B, C quÃ¡ chÃªnh lá»‡ch nhau. VÃ­ dá»¥ A thuá»™c Ä‘oáº¡n [1;10] thÃ¬ B thuá»™c Ä‘oáº¡n [40;70] cháº£ háº¡n nÃªn lÃºc Ä‘Ã¡nh weights em tháº¥y nÃ³ dá»… bá»‹ bias áº¡. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m cho em há»i trong TH nÃ y em nÃªn táº¡o (k) nhÆ° tháº¿ nÃ o cho phÃ¹ há»£p áº¡? Má»i ngÆ°á»i cÃ³ cÃ¡ch hay tÃ i liá»‡u gÃ¬ cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y thÃ¬ cho em xin. Em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang cÃ³ 1 bá»™ dá»¯ liá»‡u gá»“m: Cá»™t: 3 cá»™t Ä‘iá»ƒm, táº¡m gá»i lÃ  A,B,C HÃ ng: má»—i hÃ ng trong báº£ng biá»ƒu thá»‹ Ä‘iá»ƒm cá»§a 1 láº§n test Äá»‘i vá»›i má»—i láº§n test, Ä‘iá»ƒm A,B, C cÃ ng cao cÃ ng tá»‘t. Khi xem xÃ©t, em muá»‘n sá»­ dá»¥ng cáº£ Ä‘iá»ƒm A,B, C Ä‘á»ƒ xem test nÃ o tá»‘t nháº¥t. Do Ä‘Ã³, em cÃ³ Ã½ Ä‘á»‹nh táº¡o ra 1 cá»™t giÃ¡ trá»‹ (k) tá»•ng há»£p nÃ o Ä‘Ã³ báº±ng cÃ¡ch Ä‘Ã¡nh weights cho A,B, C. Vai trÃ² cá»§a cÃ¡c Ä‘iá»ƒm nÃ y khÃ´ng quÃ¡ chÃªnh lá»‡ch nhau nÃªn weights sáº½ khÃ´ng khÃ¡c nhau lÃ  máº¥y. Váº¥n Ä‘á» lÃ , giÃ¡ trá»‹ cá»§a A,B, C quÃ¡ chÃªnh lá»‡ch nhau. VÃ­ dá»¥ A thuá»™c Ä‘oáº¡n [1;10] thÃ¬ B thuá»™c Ä‘oáº¡n [40;70] cháº£ háº¡n nÃªn lÃºc Ä‘Ã¡nh weights em tháº¥y nÃ³ dá»… bá»‹ bias áº¡. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m cho em há»i trong TH nÃ y em nÃªn táº¡o (k) nhÆ° tháº¿ nÃ o cho phÃ¹ há»£p áº¡? Má»i ngÆ°á»i cÃ³ cÃ¡ch hay tÃ i liá»‡u gÃ¬ cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y thÃ¬ cho em xin. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Xin chÃ o má»i ngÆ°á»i,
Vá»«a rá»“i thÃ¬ OpenAI cÃ³ giá»›i thiá»‡u mÃ´ hÃ¬nh Whisper - open source multilingual speech recognition, trong Ä‘Ã³ cÃ³ cáº£ tiáº¿ng Tiáº¿ng Viá»‡t. Tuy nhiÃªn thÃ¬ á»Ÿ official code cá»§a OpenAI khÃ´ng cÃ³ pháº§n finetune mÃ´ hÃ¬nh, NÃªn mÃ¬nh cÃ³ tham kháº£o má»™t sá»‘ nguá»“n vÃ  triá»ƒn khai láº¡i viá»‡c finetune trÃªn tiáº¿ng Viá»‡t cho mÃ´ hÃ¬nh nÃ y, hi vá»ng cÃ³ thá»ƒ Ä‘Ã³ng gÃ³p cho cá»™ng Ä‘á»“ng,
Do háº¡n cháº¿ vá» máº·t tÃ i nguyÃªn, nÃªn mÃ¬nh cÃ³ thá»­ nghiá»‡m nhanh trÃªn GG colab vá»›i mÃ´ hÃ¬nh base vá»›i bá»™ data Vivos, thÃ¬ káº¿t quáº£ chÆ°a thá»±c sá»± tá»‘t (cÃ³ thá»ƒ nguyÃªn nhÃ¢n do chÆ°a cÃ³ pháº§n chuáº©n hÃ³a riÃªng cho tiáº¿ng Viá»‡t). Sau khi finetune khoáº£ng 5 epoch thÃ¬ WER mÃ´ hÃ¬nh giáº£m tá»« 45.56% xuá»‘ng 24.27%. Káº¿t quáº£ chÆ°a thá»±c sá»± tá»‘t nhÆ°ng mÃ¬nh tháº¥y khÃ¡ triá»ƒn vá»ng, náº¿u cÃ³ nhiá»u dá»¯ liá»‡u hÆ¡n, Ä‘Æ°á»£c tuning, vÃ  háº­u xá»­ lÃ½ cáº©n tháº­n hÆ¡n thÃ¬ cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh Ä‘Ã¡ng ká»ƒ, cÃ¡ nhÃ¢n mÃ¬nh tháº¥y Ä‘iá»ƒm máº¡nh cá»§a Whisper lÃ  mÃ´ hÃ¬nh xá»­ lÃ½ khÃ¡ tá»‘t vá»›i cÃ¡c tá»« nÆ°á»›c ngoÃ i.
MÃ¬nh cÅ©ng ráº¥t hoan nghÃªnh Ä‘Ã³ng gÃ³p cá»§a má»i ngÆ°á»i Ä‘á»ƒ cáº£i thiá»‡n kÄ© nÄƒng code cá»§a báº£n thÃ¢n, xa hÆ¡n cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t cÃ´ng cá»¥ ASR máº¡nh, open-source cho Tiáº¿ng Viá»‡t.
Link Repo: https://github.com/ducanhdt/openai_whisper_finetuning
Link colab example:
https://colab.research.google.com/drive/1aXj6ssi_y3qow-h6M8M1Q5tFgHE0n3UP?usp=sharing
Thanks,","Xin chÃ o má»i ngÆ°á»i, Vá»«a rá»“i thÃ¬ OpenAI cÃ³ giá»›i thiá»‡u mÃ´ hÃ¬nh Whisper - open source multilingual speech recognition, trong Ä‘Ã³ cÃ³ cáº£ tiáº¿ng Tiáº¿ng Viá»‡t. Tuy nhiÃªn thÃ¬ á»Ÿ official code cá»§a OpenAI khÃ´ng cÃ³ pháº§n finetune mÃ´ hÃ¬nh, NÃªn mÃ¬nh cÃ³ tham kháº£o má»™t sá»‘ nguá»“n vÃ  triá»ƒn khai láº¡i viá»‡c finetune trÃªn tiáº¿ng Viá»‡t cho mÃ´ hÃ¬nh nÃ y, hi vá»ng cÃ³ thá»ƒ Ä‘Ã³ng gÃ³p cho cá»™ng Ä‘á»“ng, Do háº¡n cháº¿ vá» máº·t tÃ i nguyÃªn, nÃªn mÃ¬nh cÃ³ thá»­ nghiá»‡m nhanh trÃªn GG colab vá»›i mÃ´ hÃ¬nh base vá»›i bá»™ data Vivos, thÃ¬ káº¿t quáº£ chÆ°a thá»±c sá»± tá»‘t (cÃ³ thá»ƒ nguyÃªn nhÃ¢n do chÆ°a cÃ³ pháº§n chuáº©n hÃ³a riÃªng cho tiáº¿ng Viá»‡t). Sau khi finetune khoáº£ng 5 epoch thÃ¬ WER mÃ´ hÃ¬nh giáº£m tá»« 45.56% xuá»‘ng 24.27%. Káº¿t quáº£ chÆ°a thá»±c sá»± tá»‘t nhÆ°ng mÃ¬nh tháº¥y khÃ¡ triá»ƒn vá»ng, náº¿u cÃ³ nhiá»u dá»¯ liá»‡u hÆ¡n, Ä‘Æ°á»£c tuning, vÃ  háº­u xá»­ lÃ½ cáº©n tháº­n hÆ¡n thÃ¬ cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh Ä‘Ã¡ng ká»ƒ, cÃ¡ nhÃ¢n mÃ¬nh tháº¥y Ä‘iá»ƒm máº¡nh cá»§a Whisper lÃ  mÃ´ hÃ¬nh xá»­ lÃ½ khÃ¡ tá»‘t vá»›i cÃ¡c tá»« nÆ°á»›c ngoÃ i. MÃ¬nh cÅ©ng ráº¥t hoan nghÃªnh Ä‘Ã³ng gÃ³p cá»§a má»i ngÆ°á»i Ä‘á»ƒ cáº£i thiá»‡n kÄ© nÄƒng code cá»§a báº£n thÃ¢n, xa hÆ¡n cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t cÃ´ng cá»¥ ASR máº¡nh, open-source cho Tiáº¿ng Viá»‡t. Link Repo: https://github.com/ducanhdt/openai_whisper_finetuning Link colab example: https://colab.research.google.com/drive/1aXj6ssi_y3qow-h6M8M1Q5tFgHE0n3UP?usp=sharing Thanks,",,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡,
Em xin tá»± giá»›i thiá»‡u em lÃ  sinh viÃªn má»›i ra trÆ°á»ng, chuyÃªn ngÃ nh vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o. TrÆ°á»›c Ä‘Ã¢y em cÅ©ng Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» lÃ m research vÃ  cÅ©ng Ä‘Ã£ cÃ³ má»™t sá»‘ bÃ i bÃ¡o á»Ÿ cÃ¡c há»™i nghá»‹, tuy nhiÃªn chá»‰ á»Ÿ má»©c nhá» vÃ  á»Ÿ trong nÆ°á»›c thÃ´i áº¡. Em cÃ³ dá»± Ä‘á»‹nh du há»c vÃ  há»c tiáº¿p Ä‘á»ƒ láº¥y báº±ng cao hÆ¡n, nÃªn ráº¥t cáº§n tÃ¬m hiá»ƒu vá» cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o nhÃ¢n tÃ i cá»§a cÃ¡c cÃ´ng ty mÃ  Ä‘á»‹nh hÆ°á»›ng vá» nghiÃªn cá»©u AI Ä‘Ã³ áº¡.
Xin nhá» má»i ngÆ°á»i cho em xin thÃ´ng tin cÃ¡c nÆ¡i nhÆ° tháº¿, vÃ¬ em muá»‘n mÃ¬nh cÃ³ bÃ i bÃ¡o á»Ÿ cÃ¡c top-tier conferences Ä‘á»ƒ cÃ³ thá»ƒ dá»… hÆ¡n trong viá»‡c xin há»c bá»•ng PhD áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i ğŸ¤©","Xin chÃ o má»i ngÆ°á»i áº¡, Em xin tá»± giá»›i thiá»‡u em lÃ  sinh viÃªn má»›i ra trÆ°á»ng, chuyÃªn ngÃ nh vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o. TrÆ°á»›c Ä‘Ã¢y em cÅ©ng Ä‘Ã£ cÃ³ kinh nghiá»‡m vá» lÃ m research vÃ  cÅ©ng Ä‘Ã£ cÃ³ má»™t sá»‘ bÃ i bÃ¡o á»Ÿ cÃ¡c há»™i nghá»‹, tuy nhiÃªn chá»‰ á»Ÿ má»©c nhá» vÃ  á»Ÿ trong nÆ°á»›c thÃ´i áº¡. Em cÃ³ dá»± Ä‘á»‹nh du há»c vÃ  há»c tiáº¿p Ä‘á»ƒ láº¥y báº±ng cao hÆ¡n, nÃªn ráº¥t cáº§n tÃ¬m hiá»ƒu vá» cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o nhÃ¢n tÃ i cá»§a cÃ¡c cÃ´ng ty mÃ  Ä‘á»‹nh hÆ°á»›ng vá» nghiÃªn cá»©u AI Ä‘Ã³ áº¡. Xin nhá» má»i ngÆ°á»i cho em xin thÃ´ng tin cÃ¡c nÆ¡i nhÆ° tháº¿, vÃ¬ em muá»‘n mÃ¬nh cÃ³ bÃ i bÃ¡o á»Ÿ cÃ¡c top-tier conferences Ä‘á»ƒ cÃ³ thá»ƒ dá»… hÆ¡n trong viá»‡c xin há»c bá»•ng PhD áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Cho e há»i á»Ÿ dÃ²ng 15 vÃ  dÃ²ng 19 random_state Ä‘á»ƒ = 0 & 1 cÃ³ má»¥c Ä‘Ã­ch gÃ¬ tháº¿ áº¡. Em cáº£m Æ¡n !
#question",Cho e há»i á»Ÿ dÃ²ng 15 vÃ  dÃ²ng 19 random_state Ä‘á»ƒ = 0 & 1 cÃ³ má»¥c Ä‘Ã­ch gÃ¬ tháº¿ áº¡. Em cáº£m Æ¡n !,#question,,,,
"Cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ láº¥y Ä‘Æ°á»£c phÆ°Æ¡ng trÃ¬nh y =mx +b cá»§a regplot hay lmplot khÃ´ng áº¡?
LÃ­ do lÃ  em cÃ³ 2 cá»™t dá»¯ liá»‡u nhÆ°ng 1 cá»™t bá»‹ thiáº¿u khoáº£ng 30% . 2 cá»™t nÃ y cÃ³ tÆ°Æ¡ng quan khÃ¡ cao nÃªn em muá»‘n láº¥y má»™t cá»™t Ä‘á»ƒ fill cá»™t cÃ²n láº¡i.
Hay cÃ³ cÃ¡ch nÃ o hay hÆ¡n má»i ngÆ°á»i hÆ°á»›ng dáº«n giÃºp em.
CÃ¡m Æ¡n má»i ngÆ°á»i áº¡ğŸ˜ƒ",Cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ láº¥y Ä‘Æ°á»£c phÆ°Æ¡ng trÃ¬nh y =mx +b cá»§a regplot hay lmplot khÃ´ng áº¡? LÃ­ do lÃ  em cÃ³ 2 cá»™t dá»¯ liá»‡u nhÆ°ng 1 cá»™t bá»‹ thiáº¿u khoáº£ng 30% . 2 cá»™t nÃ y cÃ³ tÆ°Æ¡ng quan khÃ¡ cao nÃªn em muá»‘n láº¥y má»™t cá»™t Ä‘á»ƒ fill cá»™t cÃ²n láº¡i. Hay cÃ³ cÃ¡ch nÃ o hay hÆ¡n má»i ngÆ°á»i hÆ°á»›ng dáº«n giÃºp em. CÃ¡m Æ¡n má»i ngÆ°á»i áº¡,,,,,
"Xin chÃ o anh chá»‹, em lÃ  sinh viÃªn má»›i tá»‘t nghiá»‡p Ä‘áº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  lÃ  ngoáº¡i Ä‘áº¡o,há»c AI Ä‘Ã£ Ä‘Æ°á»£c 1 nÄƒm, em Ä‘ang tÃ¬m kiáº¿m vá»‹ trÃ­ fresher AI táº¡i HÃ  Ná»™i mÃ  tháº¥y cÃ¡c job toÃ n yÃªu cáº§u Ã­t nháº¥t 1 nÄƒm kinh nghiá»‡m, em Ä‘ang ráº¥t hoang mang lo sá»£ tÃ¬nh tráº¡ng tháº¥t nghiá»‡p. Em mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn cá»§a anh chá»‹, em cam Æ¡n ráº¥t nhiá»u áº¡","Xin chÃ o anh chá»‹, em lÃ  sinh viÃªn má»›i tá»‘t nghiá»‡p Ä‘áº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  lÃ  ngoáº¡i Ä‘áº¡o,há»c AI Ä‘Ã£ Ä‘Æ°á»£c 1 nÄƒm, em Ä‘ang tÃ¬m kiáº¿m vá»‹ trÃ­ fresher AI táº¡i HÃ  Ná»™i mÃ  tháº¥y cÃ¡c job toÃ n yÃªu cáº§u Ã­t nháº¥t 1 nÄƒm kinh nghiá»‡m, em Ä‘ang ráº¥t hoang mang lo sá»£ tÃ¬nh tráº¡ng tháº¥t nghiá»‡p. Em mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn cá»§a anh chá»‹, em cam Æ¡n ráº¥t nhiá»u áº¡",,,,,
"xin chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm 3 vÃ  Ä‘ang tÃ¬m chá»§ Ä‘á» Ä‘á»ƒ viáº¿t paper, em Ä‘Ã£ accept táº¡n sá»‘ há»™i nghá»‹ nhá», tiáº¿p theo em Ä‘ang Ä‘á»‹nh tÃ¬m vÃ i chá»§ Ä‘á» Ä‘á»ƒ submit lÃªn cÃ¡c há»™i nghá»‹ rank C hoáº·c B, má»i ngÆ°á»i cho em xin má»™t sá»‘ chá»§ Ä‘á» vá»›i áº¡. Cá»¥ thá»ƒ em lÃ m vá» hÆ°á»›ng computer vision hoáº·c tá»‘i Æ°u cÃ¡c giáº£i thuáº­t machine learning truyá»n thá»‘ng. Em cáº£m Æ¡n áº¡","xin chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn nÄƒm 3 vÃ  Ä‘ang tÃ¬m chá»§ Ä‘á» Ä‘á»ƒ viáº¿t paper, em Ä‘Ã£ accept táº¡n sá»‘ há»™i nghá»‹ nhá», tiáº¿p theo em Ä‘ang Ä‘á»‹nh tÃ¬m vÃ i chá»§ Ä‘á» Ä‘á»ƒ submit lÃªn cÃ¡c há»™i nghá»‹ rank C hoáº·c B, má»i ngÆ°á»i cho em xin má»™t sá»‘ chá»§ Ä‘á» vá»›i áº¡. Cá»¥ thá»ƒ em lÃ m vá» hÆ°á»›ng computer vision hoáº·c tá»‘i Æ°u cÃ¡c giáº£i thuáº­t machine learning truyá»n thá»‘ng. Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m Ä‘á» tÃ i dÃ¹ng Reinforcement Learning (RL) cho xe tá»± lÃ¡i. Má»¥c tiÃªu lÃ  cho xe cháº¡y theo hÃ nh lang trong má»™t toÃ  nhÃ  theo má»™t lá»™ trÃ¬nh Ä‘á»‹nh sáºµn vÃ  trÃ¡nh Ä‘Æ°á»£c cÃ¡c váº­t cáº£n. TrÃªn xe cÃ³ trang bá»‹ camera vÃ  Lidar. Xe Ä‘Æ°á»£c Ä‘á»‹nh vá»‹ dá»±a vÃ o cÃ¡c Ä‘iá»ƒm phÃ¡t wifi cá»§a tÃ²a nhÃ . Em Ä‘ang vÆ°á»›ng chá»— xÃ¡c Ä‘á»‹nh cÃ¡c state, reward vÃ  action. CÃ³ ai Ä‘Ã£ lÃ m rá»“i thÃ¬ cho em xin Ã½ kiáº¿n vá»›i áº¡? Hoáº·c cÃ³ tÃ i liá»‡u nÃ o thÃ¬ giá»›i thiá»‡u em vá»›i. Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m Ä‘á» tÃ i dÃ¹ng Reinforcement Learning (RL) cho xe tá»± lÃ¡i. Má»¥c tiÃªu lÃ  cho xe cháº¡y theo hÃ nh lang trong má»™t toÃ  nhÃ  theo má»™t lá»™ trÃ¬nh Ä‘á»‹nh sáºµn vÃ  trÃ¡nh Ä‘Æ°á»£c cÃ¡c váº­t cáº£n. TrÃªn xe cÃ³ trang bá»‹ camera vÃ  Lidar. Xe Ä‘Æ°á»£c Ä‘á»‹nh vá»‹ dá»±a vÃ o cÃ¡c Ä‘iá»ƒm phÃ¡t wifi cá»§a tÃ²a nhÃ . Em Ä‘ang vÆ°á»›ng chá»— xÃ¡c Ä‘á»‹nh cÃ¡c state, reward vÃ  action. CÃ³ ai Ä‘Ã£ lÃ m rá»“i thÃ¬ cho em xin Ã½ kiáº¿n vá»›i áº¡? Hoáº·c cÃ³ tÃ i liá»‡u nÃ o thÃ¬ giá»›i thiá»‡u em vá»›i. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang muá»‘n theo há»c tháº¡c sÄ© vá» ngÃ nh machine learning hoáº·c data science á»Ÿ tphcm, khÃ´ng biáº¿t mÃ¬nh cÃ³ recommend vá» trÆ°á»ng nÃ o dáº¡y á»•n Ä‘á»ƒ em theo há»c khÃ´ng áº¡ ? vÃ  báº±ng tháº¡c sÄ© vá» machine learning hoáº·c data science chá»© khÃ´ng pháº£i ká»¹ sÆ° pháº§n má»m áº¡, em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang muá»‘n theo há»c tháº¡c sÄ© vá» ngÃ nh machine learning hoáº·c data science á»Ÿ tphcm, khÃ´ng biáº¿t mÃ¬nh cÃ³ recommend vá» trÆ°á»ng nÃ o dáº¡y á»•n Ä‘á»ƒ em theo há»c khÃ´ng áº¡ ? vÃ  báº±ng tháº¡c sÄ© vá» machine learning hoáº·c data science chá»© khÃ´ng pháº£i ká»¹ sÆ° pháº§n má»m áº¡, em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
"Dáº¡ mn cho em há»i lÃ  cÃ³ ai Ä‘Ã£ lÃ m nlp vá» bÃªn y táº¿ chÆ°a áº¡, náº¿u cÃ³ thÃ¬ cho em xin thÃ´ng tin vÃ  data áº¡. Em xin cÃ¡m Æ¡n.","Dáº¡ mn cho em há»i lÃ  cÃ³ ai Ä‘Ã£ lÃ m nlp vá» bÃªn y táº¿ chÆ°a áº¡, náº¿u cÃ³ thÃ¬ cho em xin thÃ´ng tin vÃ  data áº¡. Em xin cÃ¡m Æ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn vá»«a ra trÆ°á»ng vÃ  chuyá»ƒn sang máº£ng AI.
Em muá»‘n tÃ¬m khÃ³a há»c AI offline táº¡i hÃ  ná»™i áº¡
Má»i ngÆ°á»i recommend giÃºp em vá»›i áº¡
Em cáº£m Æ¡n áº¡","Em chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn vá»«a ra trÆ°á»ng vÃ  chuyá»ƒn sang máº£ng AI. Em muá»‘n tÃ¬m khÃ³a há»c AI offline táº¡i hÃ  ná»™i áº¡ Má»i ngÆ°á»i recommend giÃºp em vá»›i áº¡ Em cáº£m Æ¡n áº¡",,,,,
"#hoidap
Cho em há»i khi dÃ¹ng standard scaller trong Pipeline thÃ¬ sáº½ Ã¡p dá»¥ng trÃªn toÃ n dá»¯ liá»‡u Ä‘Ãºng khÃ´ng áº¡?
Náº¿u mÃ¬nh muá»‘n scale 1 sá»‘ cá»™t nÃ o Ä‘Ã³ thÃ´i thÃ¬ pháº£i lÃ m sao ?
CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m .",Cho em há»i khi dÃ¹ng standard scaller trong Pipeline thÃ¬ sáº½ Ã¡p dá»¥ng trÃªn toÃ n dá»¯ liá»‡u Ä‘Ãºng khÃ´ng áº¡? Náº¿u mÃ¬nh muá»‘n scale 1 sá»‘ cá»™t nÃ o Ä‘Ã³ thÃ´i thÃ¬ pháº£i lÃ m sao ? CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m .,#hoidap,,,,
"VinAI Seminar - ""Enriching Communication between Humans and AI Agents""
Speaker: Khanh Nguyen, Postdoctoral Researcher at Princeton University
Time: 10:00 am - 11.00 am (GMT+7), Fri, Oct 7, 2022","VinAI Seminar - ""Enriching Communication between Humans and AI Agents"" Speaker: Khanh Nguyen, Postdoctoral Researcher at Princeton University Time: 10:00 am - 11.00 am (GMT+7), Fri, Oct 7, 2022",,,,,
"Cho em há»i lÃ  em 23 tuá»•i, há»c trÃ¡i ngÃ nh mÃ  giá» má»›i Ä‘i intern AI thÃ¬ cÃ³ gá»i lÃ  muá»™n khÃ´ng áº¡? Vá»›i cáº£ má»i ngÆ°á»i cho em xin chÃºt thÃ´ng tin vá» má»™t sá»‘ nÆ¡i intern vá» máº£ng NLP á»Ÿ HÃ  Ná»™i Ä‘Æ°á»£c ko áº¡? Em Ä‘á»‹nh hÆ°á»›ng phÃ¡t triá»ƒn theo NLP áº¡","Cho em há»i lÃ  em 23 tuá»•i, há»c trÃ¡i ngÃ nh mÃ  giá» má»›i Ä‘i intern AI thÃ¬ cÃ³ gá»i lÃ  muá»™n khÃ´ng áº¡? Vá»›i cáº£ má»i ngÆ°á»i cho em xin chÃºt thÃ´ng tin vá» má»™t sá»‘ nÆ¡i intern vá» máº£ng NLP á»Ÿ HÃ  Ná»™i Ä‘Æ°á»£c ko áº¡? Em Ä‘á»‹nh hÆ°á»›ng phÃ¡t triá»ƒn theo NLP áº¡",,,,,
"ChÃ o cÃ¡c báº¡n. MÃ¬nh cáº§n tÃ¬m má»™t hÃ m f(x1, x2) Ä‘Ã¡p á»©ng cÃ¡c yÃªu cáº§u sau:
(a) x1, x2 lÃ  hai sá»‘ thá»±c >= 0
(b) 0 <= x1 + x2 <= 1
(c) f(x1, x2) cÃ ng lá»›n khi x1 vÃ  x2 cÃ ng bÃ©, Ä‘áº¡t cá»±c Ä‘áº¡i khi x1=0 vÃ  x2=0
(d) f( a, a ) > f(x1, x2) khi x1 != x2 vÃ  a = (x1 + x2)/2
VÃ­ dá»¥:
f(0.1, 0.1) > f(0.15, 0.15)
f(0.1, 0.1) > f(0.095, 0.105) > f(0.09, 0.11)
Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u áº¡.","ChÃ o cÃ¡c báº¡n. MÃ¬nh cáº§n tÃ¬m má»™t hÃ m f(x1, x2) Ä‘Ã¡p á»©ng cÃ¡c yÃªu cáº§u sau: (a) x1, x2 lÃ  hai sá»‘ thá»±c >= 0 (b) 0 <= x1 + x2 <= 1 (c) f(x1, x2) cÃ ng lá»›n khi x1 vÃ  x2 cÃ ng bÃ©, Ä‘áº¡t cá»±c Ä‘áº¡i khi x1=0 vÃ  x2=0 (d) f( a, a ) > f(x1, x2) khi x1 != x2 vÃ  a = (x1 + x2)/2 VÃ­ dá»¥: f(0.1, 0.1) > f(0.15, 0.15) f(0.1, 0.1) > f(0.095, 0.105) > f(0.09, 0.11) Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u áº¡.",,"#Q&A, #math",,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em cÃ³ váº¥n Ä‘á» nÃ y cáº§n sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c cao thá»§ áº¡h.
Cháº£ lÃ  em cÃ³ 1 GPU Ä‘á»ƒ train model AI, hiá»‡n viá»‡c train cÅ©ng khÃ´ng thÆ°á»ng xuyÃªn láº¯m nÃªn em muá»‘n chia sáº» cho cÃ¡c báº¡n sinh viÃªn (miá»…n phÃ­) Ä‘á»ƒ cÃ¡c báº¡n train model cho Ä‘á»“ Ã¡n, bÃ i táº­p lá»›n.
Tuy nhiÃªn náº¿u em share thá»§ cÃ´ng vÃ  thu há»“i viá»‡c share thá»§ cÃ´ng thÃ¬ khÃ¡ máº¥t time mÃ  em cÅ©ng báº­n quÃ¡.
NÃªn má»›i há»i cÃ¡c bÃ¡c lÃ m nhiá»u cÃ³ cÃ¡i opensource nÃ o cÃ³ thá»ƒ cho phÃ©p cÃ¡c báº¡n vÃ o Ä‘Äƒng kÃ½ user, sá»­ dá»¥ng GPU trong 1 thá»i gian giá»›i háº¡n nÃ o Ä‘Ã³ Ä‘á»ƒ train nhÆ° kiá»ƒu Colab bÃ¢y giá».
Em ká»³ vá»ng cÃ¡c báº¡n sáº½ Ä‘Äƒng kÃ½, truy cáº­p vÃ o Jupyter Notebook vÃ  dÃ¹ng trong thá»i gian Ä‘Äƒng kÃ½ trÆ°á»›c. Háº¿t time Ä‘Ã³ thÃ¬ quyá»n truy cáº­p sáº½ bá»‹ thu há»“i Ä‘á»ƒ dÃ nh cho cÃ¡c báº¡n khÃ¡c.
Mong Ä‘Æ°á»£c cÃ¡c bÃ¡c giÃºp Ä‘á»¡!","KÃ­nh chÃ o cÃ¡c bÃ¡c, em cÃ³ váº¥n Ä‘á» nÃ y cáº§n sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c cao thá»§ áº¡h. Cháº£ lÃ  em cÃ³ 1 GPU Ä‘á»ƒ train model AI, hiá»‡n viá»‡c train cÅ©ng khÃ´ng thÆ°á»ng xuyÃªn láº¯m nÃªn em muá»‘n chia sáº» cho cÃ¡c báº¡n sinh viÃªn (miá»…n phÃ­) Ä‘á»ƒ cÃ¡c báº¡n train model cho Ä‘á»“ Ã¡n, bÃ i táº­p lá»›n. Tuy nhiÃªn náº¿u em share thá»§ cÃ´ng vÃ  thu há»“i viá»‡c share thá»§ cÃ´ng thÃ¬ khÃ¡ máº¥t time mÃ  em cÅ©ng báº­n quÃ¡. NÃªn má»›i há»i cÃ¡c bÃ¡c lÃ m nhiá»u cÃ³ cÃ¡i opensource nÃ o cÃ³ thá»ƒ cho phÃ©p cÃ¡c báº¡n vÃ o Ä‘Äƒng kÃ½ user, sá»­ dá»¥ng GPU trong 1 thá»i gian giá»›i háº¡n nÃ o Ä‘Ã³ Ä‘á»ƒ train nhÆ° kiá»ƒu Colab bÃ¢y giá». Em ká»³ vá»ng cÃ¡c báº¡n sáº½ Ä‘Äƒng kÃ½, truy cáº­p vÃ o Jupyter Notebook vÃ  dÃ¹ng trong thá»i gian Ä‘Äƒng kÃ½ trÆ°á»›c. Háº¿t time Ä‘Ã³ thÃ¬ quyá»n truy cáº­p sáº½ bá»‹ thu há»“i Ä‘á»ƒ dÃ nh cho cÃ¡c báº¡n khÃ¡c. Mong Ä‘Æ°á»£c cÃ¡c bÃ¡c giÃºp Ä‘á»¡!",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c! Nháº­n dá»‹p Ä‘ang tÃ¬m hiá»ƒu em xin máº¡nh dáº¡n chia sáº» chi tiáº¿t báº±ng kinh nghiá»‡m cÃ¡ nhÃ¢n dÃ nh riÃªng cho cÃ¡c báº¡n sinh viÃªn Ä‘ang há»c AI, ML vÃ  Ä‘ang vÆ°á»›ng khi lÃ m bÃ i táº­p lá»›n, Ä‘á»“ Ã¡n.
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!","KÃ­nh chÃ o cÃ¡c bÃ¡c! Nháº­n dá»‹p Ä‘ang tÃ¬m hiá»ƒu em xin máº¡nh dáº¡n chia sáº» chi tiáº¿t báº±ng kinh nghiá»‡m cÃ¡ nhÃ¢n dÃ nh riÃªng cho cÃ¡c báº¡n sinh viÃªn Ä‘ang há»c AI, ML vÃ  Ä‘ang vÆ°á»›ng khi lÃ m bÃ i táº­p lá»›n, Ä‘á»“ Ã¡n. ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!",,,,,
"Em chÃ o anh chá»‹ áº¡
Em cÃ³ cÃ¢u há»i lÃ : Äá»ƒ Ä‘Æ°á»£c Ä‘i Intern vá» Machine Learning Engineering thÃ¬ cáº§n nhá»¯ng vÃ¹ng kiáº¿n thá»©c nÃ o áº¡, em cÅ©ng cÃ³ Ä‘á»c vá» cÃ¡c models trÃªn trang machinelearningcoban, em cÅ©ng Ä‘ang há»c vá» MLOps, há»“i Ä‘i Intern anh chá»‹ lÃ m project nÃ o Ä‘á»ƒ Ä‘i phá»ng váº¥n áº¡, em cáº£m Æ¡n anh chá»‹ nhiá»u áº¡!","Em chÃ o anh chá»‹ áº¡ Em cÃ³ cÃ¢u há»i lÃ : Äá»ƒ Ä‘Æ°á»£c Ä‘i Intern vá» Machine Learning Engineering thÃ¬ cáº§n nhá»¯ng vÃ¹ng kiáº¿n thá»©c nÃ o áº¡, em cÅ©ng cÃ³ Ä‘á»c vá» cÃ¡c models trÃªn trang machinelearningcoban, em cÅ©ng Ä‘ang há»c vá» MLOps, há»“i Ä‘i Intern anh chá»‹ lÃ m project nÃ o Ä‘á»ƒ Ä‘i phá»ng váº¥n áº¡, em cáº£m Æ¡n anh chá»‹ nhiá»u áº¡!",,,,,
"#hoidap
cho em há»i sá»­ dá»¥ng Principal Component Analysis cho há»“i quy vÃ  phÃ¢n loáº¡i Ä‘á»u Ä‘Æ°á»£c Ä‘Ãºng khÃ´ng áº¡?
CÃ³ khi nÃ o sá»­ dá»¥ng PCA xong rá»“i train mÃ´ hÃ¬nh cho ra káº¿t quáº£ xáº¥u hÆ¡n khÃ´ng áº¡ ?",cho em há»i sá»­ dá»¥ng Principal Component Analysis cho há»“i quy vÃ  phÃ¢n loáº¡i Ä‘á»u Ä‘Æ°á»£c Ä‘Ãºng khÃ´ng áº¡? CÃ³ khi nÃ o sá»­ dá»¥ng PCA xong rá»“i train mÃ´ hÃ¬nh cho ra káº¿t quáº£ xáº¥u hÆ¡n khÃ´ng áº¡ ?,#hoidap,,,,
"MÃ¬nh tháº¥y má»™t repo hay vá» viá»‡c á»©ng dá»¥ng GPT-3 cá»§a OpenAI trong viá»‡c tÃ¬m kiáº¿m trÃªn website táº¡i Ä‘Ã¢y https://github.com/nat/natbot.
Demo theo tweet cá»§a tÃ¡c giáº£ táº¡i Ä‘Ã¢y https://twitter.com/natfriedman/status/1575631194032549888",MÃ¬nh tháº¥y má»™t repo hay vá» viá»‡c á»©ng dá»¥ng GPT-3 cá»§a OpenAI trong viá»‡c tÃ¬m kiáº¿m trÃªn website táº¡i Ä‘Ã¢y https://github.com/nat/natbot. Demo theo tweet cá»§a tÃ¡c giáº£ táº¡i Ä‘Ã¢y https://twitter.com/natfriedman/status/1575631194032549888,,,,,
"VinAI Seminar - ""Variable Selection with Theoretical Guarantees on High-dimensional Data""
Speaker: Binh Nguyen, Postdoc at Telecom Paris, France
Time: 10.00 am - 11.00 am (GMT+7), Fri, Sep 30, 2022","VinAI Seminar - ""Variable Selection with Theoretical Guarantees on High-dimensional Data"" Speaker: Binh Nguyen, Postdoc at Telecom Paris, France Time: 10.00 am - 11.00 am (GMT+7), Fri, Sep 30, 2022",,,,,
"[FPS (frame per second) trÃªn mÃ¡y MACOS]
ChÃ o má»i ngÆ°á»i, mÃ¬nh láº§n Ä‘áº§u dÃ¹ng MACOS nÃªn chÆ°a cÃ³ kinh nghiá»‡m, nhá» má»i ngÆ°á»i chá»‰ giÃºp. MÃ¬nh dÃ¹ng opencv Ä‘á»ƒ Ä‘á»c vÃ  xuáº¥t cÃ¡c frame áº£nh cá»§a video thu Ä‘Æ°á»£c tá»« camera trÃªn mÃ¡y mac. Khi tÃ­nh FPS thÃ¬ Ä‘o Ä‘Æ°á»£c Ä‘Ã¢u Ä‘Ã³ táº§m 30 fps Ã  (hiá»‡n táº¡i lÃ  chá»‰ Ä‘ocj vÃ  ghi frame chá»© khÃ´ng lÃ m thÃªm tÃ¡c vá»¥ nÃ o khÃ¡c). Tá»‘c Ä‘á»™ nÃ y khÃ¡ lÃ  cháº­m vÃ  mÃ¬nh chÆ°a biáº¿t váº¥n Ä‘á» náº±m á»Ÿ chá»— nÃ o. á» Ä‘Ã¢y cÃ³ ACE nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m tÃ­nh toÃ¡n FPS trÃªn mac vÃ  tÄƒng FPS rate thÃ¬ chá»‰ giÃºp mÃ¬nh nha.
Cáº¥u hÃ¬nh mÃ¡y: Apple M1 pro, 16GB.
Xin cáº£m Æ¡n má»i ngÆ°á»i.","[FPS (frame per second) trÃªn mÃ¡y MACOS] ChÃ o má»i ngÆ°á»i, mÃ¬nh láº§n Ä‘áº§u dÃ¹ng MACOS nÃªn chÆ°a cÃ³ kinh nghiá»‡m, nhá» má»i ngÆ°á»i chá»‰ giÃºp. MÃ¬nh dÃ¹ng opencv Ä‘á»ƒ Ä‘á»c vÃ  xuáº¥t cÃ¡c frame áº£nh cá»§a video thu Ä‘Æ°á»£c tá»« camera trÃªn mÃ¡y mac. Khi tÃ­nh FPS thÃ¬ Ä‘o Ä‘Æ°á»£c Ä‘Ã¢u Ä‘Ã³ táº§m 30 fps Ã  (hiá»‡n táº¡i lÃ  chá»‰ Ä‘ocj vÃ  ghi frame chá»© khÃ´ng lÃ m thÃªm tÃ¡c vá»¥ nÃ o khÃ¡c). Tá»‘c Ä‘á»™ nÃ y khÃ¡ lÃ  cháº­m vÃ  mÃ¬nh chÆ°a biáº¿t váº¥n Ä‘á» náº±m á»Ÿ chá»— nÃ o. á» Ä‘Ã¢y cÃ³ ACE nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m tÃ­nh toÃ¡n FPS trÃªn mac vÃ  tÄƒng FPS rate thÃ¬ chá»‰ giÃºp mÃ¬nh nha. Cáº¥u hÃ¬nh mÃ¡y: Apple M1 pro, 16GB. Xin cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Em chÃ o anh/chá»‹ trong gr, Em lÃ  sinh viÃªn Ä‘ang thá»±c hiá»‡n má»™t bÃ i táº­p lá»›n yÃªu cáº§u xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n kháº£ nÄƒng tráº£ ná»£ cá»§a khÃ¡ch hÃ ng cÃ¡ nhÃ¢n táº¡i ngÃ¢n hÃ ng thÆ°Æ¡ng máº¡i. Hiá»‡n em Ä‘ang cÃ³ bá»™ dá»¯ liá»‡u gá»“m 1143 dÃ²ng vÃ  10 thuá»™c tÃ­nh. Em muá»‘n há»i lÃ  náº¿u chá»‰ dÃ¹ng thuáº­t toÃ¡n Random Forest Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh nÃ y thÃ¬ Ä‘Ã£ Ä‘á»§ chÆ°a áº¡ (vÃ¬ Ä‘Ã¢y khÃ´ng pháº£i mÃ´n chuyÃªn ngÃ nh cá»§a em, nÃªn em cÃ³ há»i nhá»¯ng cÃ¢u cÆ¡ báº£n :( ) Ráº¥t mong Ä‘Æ°á»£c anh/chá»‹ giÃºp Ä‘á»¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡","Em chÃ o anh/chá»‹ trong gr, Em lÃ  sinh viÃªn Ä‘ang thá»±c hiá»‡n má»™t bÃ i táº­p lá»›n yÃªu cáº§u xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n kháº£ nÄƒng tráº£ ná»£ cá»§a khÃ¡ch hÃ ng cÃ¡ nhÃ¢n táº¡i ngÃ¢n hÃ ng thÆ°Æ¡ng máº¡i. Hiá»‡n em Ä‘ang cÃ³ bá»™ dá»¯ liá»‡u gá»“m 1143 dÃ²ng vÃ  10 thuá»™c tÃ­nh. Em muá»‘n há»i lÃ  náº¿u chá»‰ dÃ¹ng thuáº­t toÃ¡n Random Forest Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh nÃ y thÃ¬ Ä‘Ã£ Ä‘á»§ chÆ°a áº¡ (vÃ¬ Ä‘Ã¢y khÃ´ng pháº£i mÃ´n chuyÃªn ngÃ nh cá»§a em, nÃªn em cÃ³ há»i nhá»¯ng cÃ¢u cÆ¡ báº£n :( ) Ráº¥t mong Ä‘Æ°á»£c anh/chá»‹ giÃºp Ä‘á»¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡",,,,,
"Dáº¡ mn cho em há»i vá» feature engineering in NLP thÃ¬ thÃ´ng thÆ°á»ng cÃ³ nhá»¯ng bÆ°á»›c nhÆ° nÃ o áº¡?, em tÃ¬m hiá»ƒu thÃ¬ mÃ¬nh cÃ³ thá»ƒ thÃªm feature, CountVec hoáº·c TFIDF, cÃ²n náº¿u dÃ¹ng pretrained model nhÆ° BERT thÃ¬ input vÃ o model sáº½ lÃ  cÃ³ format riÃªng cá»§a model Ä‘Ã³ thÃ¬ mÃ¬nh dÃ¹ng feature engineer á»Ÿ bÆ°á»›c nÃ o áº¡? Em xin cÃ¡m Æ¡n","Dáº¡ mn cho em há»i vá» feature engineering in NLP thÃ¬ thÃ´ng thÆ°á»ng cÃ³ nhá»¯ng bÆ°á»›c nhÆ° nÃ o áº¡?, em tÃ¬m hiá»ƒu thÃ¬ mÃ¬nh cÃ³ thá»ƒ thÃªm feature, CountVec hoáº·c TFIDF, cÃ²n náº¿u dÃ¹ng pretrained model nhÆ° BERT thÃ¬ input vÃ o model sáº½ lÃ  cÃ³ format riÃªng cá»§a model Ä‘Ã³ thÃ¬ mÃ¬nh dÃ¹ng feature engineer á»Ÿ bÆ°á»›c nÃ o áº¡? Em xin cÃ¡m Æ¡n",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em cÃ³ má»™t cÃ¢u há»i ko liÃªn quan Ä‘áº¿n ML láº¯m, mong mn giáº£i Ä‘Ã¡p áº¡. Em cÃ³ 1 báº£ng gá»‘c lÃ  báº£ng trÃªn cÃ¹ng, sau Ä‘Ã³ thá»±c hiá»‡n groupby grouping set ra káº¿t quáº£ nhÆ° báº£ng thá»© 2. BÃ¢y giá» em muá»‘n chuyá»ƒn thÃ nh báº£ng thá»© 3 ( thá»±c hiá»‡n =trong Spark Dataset hoáº·c Spark SQL) thÃ¬ mÃ¬nh cÃ³ solution nÃ o ko áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i","Em chÃ o má»i ngÆ°á»i áº¡ Em cÃ³ má»™t cÃ¢u há»i ko liÃªn quan Ä‘áº¿n ML láº¯m, mong mn giáº£i Ä‘Ã¡p áº¡. Em cÃ³ 1 báº£ng gá»‘c lÃ  báº£ng trÃªn cÃ¹ng, sau Ä‘Ã³ thá»±c hiá»‡n groupby grouping set ra káº¿t quáº£ nhÆ° báº£ng thá»© 2. BÃ¢y giá» em muá»‘n chuyá»ƒn thÃ nh báº£ng thá»© 3 ( thá»±c hiá»‡n =trong Spark Dataset hoáº·c Spark SQL) thÃ¬ mÃ¬nh cÃ³ solution nÃ o ko áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"MÃ¬nh biáº¿t cÃ³ nhiá»u báº¡n pháº£i soáº¡n bÃ i giáº£ng dá»±a trÃªn Jupyter káº¿t há»£p vá»›i Markdown. Nay mÃ¬nh má»›i biáº¿t cÃ³ dá»± Ã¡n vá»›i tÃªn Quarto (táº¡i Ä‘Ã¢y https://quarto.org/). Quarto há»— trá»£ xuáº¥t file ra dáº¡ng *html, *docx, vÃ  cáº£ *tex (XeLatex) ráº¥t tá»‘t. MÃ¬nh tháº¥y cÃ³ hÆ°á»›ng dáº«n khÃ¡ thÃº vá»‹ nÃ y khi káº¿t há»£p dÃ¹ng Quarto trÃªn RStudio (series 4 bÃ i giáº£ng https://www.youtube.com/watch?v=31Q9ZTZOHIM). VÃ  nÃ³ cÅ©ng hoáº¡t Ä‘á»™ng tá»‘t vá»›i cáº£ VSCode (https://quarto.org/docs/tools/vscode.html; https://arinbasu.medium.com/why-quarto-with-vscode-is-a...).
Quarto theo mÃ¬nh biáº¿t hiá»‡n nÃ³ Ä‘ang há»— trá»£ cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh hÆ°á»›ng Ä‘á»‘i tÆ°á»£ng nhÆ° R, Python, Julia.
Hi vá»ng ngÃ y cuá»‘i tuáº§n cÃ³ thÃªm thÃ´ng tin giáº£i trÃ­ cho má»i ngÆ°á»i!","MÃ¬nh biáº¿t cÃ³ nhiá»u báº¡n pháº£i soáº¡n bÃ i giáº£ng dá»±a trÃªn Jupyter káº¿t há»£p vá»›i Markdown. Nay mÃ¬nh má»›i biáº¿t cÃ³ dá»± Ã¡n vá»›i tÃªn Quarto (táº¡i Ä‘Ã¢y https://quarto.org/). Quarto há»— trá»£ xuáº¥t file ra dáº¡ng *html, *docx, vÃ  cáº£ *tex (XeLatex) ráº¥t tá»‘t. MÃ¬nh tháº¥y cÃ³ hÆ°á»›ng dáº«n khÃ¡ thÃº vá»‹ nÃ y khi káº¿t há»£p dÃ¹ng Quarto trÃªn RStudio (series 4 bÃ i giáº£ng https://www.youtube.com/watch?v=31Q9ZTZOHIM). VÃ  nÃ³ cÅ©ng hoáº¡t Ä‘á»™ng tá»‘t vá»›i cáº£ VSCode (https://quarto.org/docs/tools/vscode.html; https://arinbasu.medium.com/why-quarto-with-vscode-is-a...). Quarto theo mÃ¬nh biáº¿t hiá»‡n nÃ³ Ä‘ang há»— trá»£ cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh hÆ°á»›ng Ä‘á»‘i tÆ°á»£ng nhÆ° R, Python, Julia. Hi vá»ng ngÃ y cuá»‘i tuáº§n cÃ³ thÃªm thÃ´ng tin giáº£i trÃ­ cho má»i ngÆ°á»i!",,,,,
"ChÃ o má»i ngÆ°á»i, 
NhÃ³m mÃ¬nh LQDBD may máº¯n Ä‘á»©ng thá»© háº¡ng 2 private test trong bÃ i toÃ¡n AI4VN: Air Quality Forcasting trong khuÃ´n khá»• há»™i nghá»‹ AI Summit 2022. CÅ©ng mong chia sáº» Ã½ tÆ°á»Ÿng source code cá»§a nhÃ³m trong cuá»™c thi láº§n nÃ y. Náº¿u cÃ³ gÃ¬ khÃ´ng rÃµ rÃ ng vÃ  cáº§n pháº£i tháº£o luáº­n thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ há»i team mÃ¬nh trong issue cá»§a repo. CÃ¡m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, NhÃ³m mÃ¬nh LQDBD may máº¯n Ä‘á»©ng thá»© háº¡ng 2 private test trong bÃ i toÃ¡n AI4VN: Air Quality Forcasting trong khuÃ´n khá»• há»™i nghá»‹ AI Summit 2022. CÅ©ng mong chia sáº» Ã½ tÆ°á»Ÿng source code cá»§a nhÃ³m trong cuá»™c thi láº§n nÃ y. Náº¿u cÃ³ gÃ¬ khÃ´ng rÃµ rÃ ng vÃ  cáº§n pháº£i tháº£o luáº­n thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ há»i team mÃ¬nh trong issue cá»§a repo. CÃ¡m Æ¡n má»i ngÆ°á»i.",,,,,
"Em chÃ o cÃ¡c anh chá»‹.

Em Ä‘ang cÃ³ tháº¯c máº¯c vá» thuáº­t toÃ¡n Content Based Filtering khi tÃ¬m hiá»ƒu, mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ giáº£i Ä‘Ã¡p.

Theo em tÃ¬m hiá»ƒu thÃ¬ Content Based Filtering sáº½ dá»±a vÃ o Ä‘áº·c Ä‘iá»ƒm cá»§a má»™t sáº£n pháº©m Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ cho ngÆ°á»i dÃ¹ng khi há» áº¥n vÃ o sáº£n pháº©m Ä‘Ã³.

Em cÃ³ thá»­ cháº¡y vá»›i thÆ° viá»‡n Algolia: https://www.algolia.com/ trong má»¥c Recommened -> Related Products. (Website Ä‘Æ°a ra ráº±ng há»‡ thá»‘ng cá»§a há» cháº¡y dá»±a trÃªn Content Based Filtering)

Input nháº­p vÃ o lÃ  má»™t dataset cÃ¡c sáº£n pháº©m vÃ  Define key object attributes (á»Ÿ Ä‘Ã¢y em chá»n dataset lÃ  giÃ y vÃ  define key lÃ  category cá»§a sáº£n pháº©m)

Sau khi train thÃ nh cÃ´ng, khi em áº¥n vÃ o má»™t sáº£n pháº©m cÃ³ category lÃ  ""Formal"" thÃ¬ Algolia sáº½ gá»£i Ã½ ra cÃ¡c sáº£n pháº©m cÅ©ng cÃ³ category lÃ  Formal.

Váº­y, khÃ¡c biá»‡t cá»§a Content Based Filtering so vá»›i viá»‡c ngÆ°á»i dÃ¹ng áº¥n vÃ o má»™t sáº£n pháº©m (tá»©c lÃ  cÃ³ id cá»§a sáº£n pháº©m áº¥y) rá»“i truy váº¥n Ä‘áº¿n database SELECT ra cÃ¡c sáº£n pháº©m cÃ³ category tÆ°á»Ÿng tá»± lÃ  gÃ¬ áº¡?

CÃ¢u há»i cá»§a em hÆ¡i dÃ i, mong má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p giÃºp em áº¡. Em xin cáº£m Æ¡n.","Em chÃ o cÃ¡c anh chá»‹. Em Ä‘ang cÃ³ tháº¯c máº¯c vá» thuáº­t toÃ¡n Content Based Filtering khi tÃ¬m hiá»ƒu, mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ giáº£i Ä‘Ã¡p. Theo em tÃ¬m hiá»ƒu thÃ¬ Content Based Filtering sáº½ dá»±a vÃ o Ä‘áº·c Ä‘iá»ƒm cá»§a má»™t sáº£n pháº©m Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ cho ngÆ°á»i dÃ¹ng khi há» áº¥n vÃ o sáº£n pháº©m Ä‘Ã³. Em cÃ³ thá»­ cháº¡y vá»›i thÆ° viá»‡n Algolia: https://www.algolia.com/ trong má»¥c Recommened -> Related Products. (Website Ä‘Æ°a ra ráº±ng há»‡ thá»‘ng cá»§a há» cháº¡y dá»±a trÃªn Content Based Filtering) Input nháº­p vÃ o lÃ  má»™t dataset cÃ¡c sáº£n pháº©m vÃ  Define key object attributes (á»Ÿ Ä‘Ã¢y em chá»n dataset lÃ  giÃ y vÃ  define key lÃ  category cá»§a sáº£n pháº©m) Sau khi train thÃ nh cÃ´ng, khi em áº¥n vÃ o má»™t sáº£n pháº©m cÃ³ category lÃ  ""Formal"" thÃ¬ Algolia sáº½ gá»£i Ã½ ra cÃ¡c sáº£n pháº©m cÅ©ng cÃ³ category lÃ  Formal. Váº­y, khÃ¡c biá»‡t cá»§a Content Based Filtering so vá»›i viá»‡c ngÆ°á»i dÃ¹ng áº¥n vÃ o má»™t sáº£n pháº©m (tá»©c lÃ  cÃ³ id cá»§a sáº£n pháº©m áº¥y) rá»“i truy váº¥n Ä‘áº¿n database SELECT ra cÃ¡c sáº£n pháº©m cÃ³ category tÆ°á»Ÿng tá»± lÃ  gÃ¬ áº¡? CÃ¢u há»i cá»§a em hÆ¡i dÃ i, mong má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p giÃºp em áº¡. Em xin cáº£m Æ¡n.",,,,,
"[Whisper - English speech recognition]
OpenAI má»›i Ä‘Ã¢y cho ra mÃ´ hÃ¬nh Whisper cÃ³ kháº£ nÄƒng nháº­n diá»‡n giá»ng nÃ³i Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« 680,000 giá» tá»« cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau. RiÃªng vá»›i ngÃ´n ngá»¯ tiáº¿ng anh, mÃ´ mÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c Ä‘áº¡t tá»›i má»©c Ä‘á»™ cá»§a con ngÆ°á»i. MÃ´ hÃ¬nh cÃ³ thá»ƒ thá»±c hiá»‡n tá»‘t vá»›i cÃ¡c giá»ng Ä‘á»‹a phÆ°Æ¡ng vÃ  ngÃ´n ngá»¯ kÄ© thuáº­t. Cuá»‘i cÃ¹ng, Whisper lÃ  mÃ´ hÃ¬nh dáº¡ng mÃ£ nguá»“n má»Ÿ vÃ  miá»…n phÃ­ Ä‘á»ƒ sá»­ dá»¥ng.
Chi tiáº¿t cÃ¡c báº¡n xem á»Ÿ Ä‘Ã¢y: https://openai.com/blog/whisper/","[Whisper - English speech recognition] OpenAI má»›i Ä‘Ã¢y cho ra mÃ´ hÃ¬nh Whisper cÃ³ kháº£ nÄƒng nháº­n diá»‡n giá»ng nÃ³i Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« 680,000 giá» tá»« cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau. RiÃªng vá»›i ngÃ´n ngá»¯ tiáº¿ng anh, mÃ´ mÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c Ä‘áº¡t tá»›i má»©c Ä‘á»™ cá»§a con ngÆ°á»i. MÃ´ hÃ¬nh cÃ³ thá»ƒ thá»±c hiá»‡n tá»‘t vá»›i cÃ¡c giá»ng Ä‘á»‹a phÆ°Æ¡ng vÃ  ngÃ´n ngá»¯ kÄ© thuáº­t. Cuá»‘i cÃ¹ng, Whisper lÃ  mÃ´ hÃ¬nh dáº¡ng mÃ£ nguá»“n má»Ÿ vÃ  miá»…n phÃ­ Ä‘á»ƒ sá»­ dá»¥ng. Chi tiáº¿t cÃ¡c báº¡n xem á»Ÿ Ä‘Ã¢y: https://openai.com/blog/whisper/",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2022 vÃ o trong comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2022 vÃ o trong comment cá»§a post nÃ y.",,,,,
"#NLP #beautifulsoup #KMeans #hierarchy #streamlit
======== RECOMMENDATION SYSTEM ========  
Hello Everyone,  
Have a great weekend!
I built End-to-end Recommendation System project with Python involving:     
1/ Web Scraping
Using Beautiful Soup to extract data from the web         
Clean the text and drop null entries              
2/ Clustering Analysis        
Using Unsupervised Learning techniques Kmeans, DBSCAN, Hierarchy & natural language processing (NLP)          
Tokenizing, stemming and are vectorized using NLTK's TF-IDF vectorizer         
 From the TF-IDF matrix, the similarity distances between the texts are computed by substracting the cosine of vectors from 1.
Finally, recommendations are queried using the matrix: once a game is selected, the top 5 closest games are returned.          
3/ Web App Development         
Using Streamlit framework to build local Web App         
To be... Deploy Web App

Please do not hesitate to contact us should you have any queries or require further information.
Thank All <3
Let's watch video on my Youtube channel ~~~
https://youtu.be/83HFInoJsTA",#ERROR!,#NLP	#beautifulsoup	#KMeans	#hierarchy	#streamlit,,,,
"Em chÃ o mn, e cÃ³ cÃ¢u há»i mong Ä‘c mn giáº£i Ä‘Ã¡p áº¡. KhÃ´ng biáº¿t trong nhÃ³m mÃ¬nh Ä‘Ã£ cÃ³ ai lÃ m pháº§n triá»ƒn khai mÃ´ hÃ¬nh sau khi Ä‘Ã£ huáº¥n luyá»‡n xong, cá»¥ thá»ƒ lÃ  pháº§n triton inference server chÆ°a áº¡. E cÃ³ lÃ m theo hÆ°á»›ng dáº«n git chÃ­nh thá»©c cá»§a tÃ¡c giáº£, tuy nhiÃªn vá»›i cÃ¡c mÃ´ hÃ¬nh classification vÃ­ dá»¥ Resnet thÃ¬ e cháº¡y vÃ  káº¿t quáº£ tráº£ vá» Ä‘Ãºng, cÃ²n Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh detect vÃ­ dá»¥ FasterRCNN hoáº·c Yolov5 thÃ¬ khi e cháº¡y client, response tráº£ vá» k chá»©a káº¿t quáº£ bounding box, labels,... mong muá»‘n. File config káº¿t quáº£ tráº£ vá» thÃ¬ e cÃ³ Ä‘i tham kháº£o trÃªn máº¡ng vÃ  nghÄ© váº¥n Ä‘á» k pháº£i do nÃ³. MÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³ Ä‘Æ°á»£c chuyá»ƒn qua ONNX vÃ  e cÅ©ng Ä‘Ã£ thá»­ láº¡i Ä‘á»ƒ cháº¯c cháº¯n mÃ´ hÃ¬nh sau khi chuyá»ƒn Ä‘á»•i tráº£ vá» Ä‘Ãºng káº¿t quáº£. K biáº¿t cÃ³ pháº£i do thÆ° viá»‡n tritonclient Ä‘Ã£ xá»­ lÃ­ káº¿t quáº£ nÃ y trÆ°á»›c nÃªn dáº«n Ä‘áº¿n lá»—i nÃ y k, vÃ¬ e k thá»ƒ truy cáº­p Ä‘c vÃ o thÆ° viá»‡n nÃ y.
Ai cÃ³ kinh nghiá»‡m giÃºp e vá»›i, e xin cáº£m Æ¡n áº¡","Em chÃ o mn, e cÃ³ cÃ¢u há»i mong Ä‘c mn giáº£i Ä‘Ã¡p áº¡. KhÃ´ng biáº¿t trong nhÃ³m mÃ¬nh Ä‘Ã£ cÃ³ ai lÃ m pháº§n triá»ƒn khai mÃ´ hÃ¬nh sau khi Ä‘Ã£ huáº¥n luyá»‡n xong, cá»¥ thá»ƒ lÃ  pháº§n triton inference server chÆ°a áº¡. E cÃ³ lÃ m theo hÆ°á»›ng dáº«n git chÃ­nh thá»©c cá»§a tÃ¡c giáº£, tuy nhiÃªn vá»›i cÃ¡c mÃ´ hÃ¬nh classification vÃ­ dá»¥ Resnet thÃ¬ e cháº¡y vÃ  káº¿t quáº£ tráº£ vá» Ä‘Ãºng, cÃ²n Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh detect vÃ­ dá»¥ FasterRCNN hoáº·c Yolov5 thÃ¬ khi e cháº¡y client, response tráº£ vá» k chá»©a káº¿t quáº£ bounding box, labels,... mong muá»‘n. File config káº¿t quáº£ tráº£ vá» thÃ¬ e cÃ³ Ä‘i tham kháº£o trÃªn máº¡ng vÃ  nghÄ© váº¥n Ä‘á» k pháº£i do nÃ³. MÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³ Ä‘Æ°á»£c chuyá»ƒn qua ONNX vÃ  e cÅ©ng Ä‘Ã£ thá»­ láº¡i Ä‘á»ƒ cháº¯c cháº¯n mÃ´ hÃ¬nh sau khi chuyá»ƒn Ä‘á»•i tráº£ vá» Ä‘Ãºng káº¿t quáº£. K biáº¿t cÃ³ pháº£i do thÆ° viá»‡n tritonclient Ä‘Ã£ xá»­ lÃ­ káº¿t quáº£ nÃ y trÆ°á»›c nÃªn dáº«n Ä‘áº¿n lá»—i nÃ y k, vÃ¬ e k thá»ƒ truy cáº­p Ä‘c vÃ o thÆ° viá»‡n nÃ y. Ai cÃ³ kinh nghiá»‡m giÃºp e vá»›i, e xin cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i ,em má»›i táº­p viáº¿t blog mong má»i ngÆ°á»i á»§ng há»™ áº¡.
https://viblo.asia/p/gioi-thieu-ve-diffussion-model-EvbLbOKWVnk?fbclid=IwAR2xDSfBkao6pkYfUhN1FGZ3C0JxaQV3MB9vZNba0k7qK01cdu2meEO8DHU","ChÃ o má»i ngÆ°á»i ,em má»›i táº­p viáº¿t blog mong má»i ngÆ°á»i á»§ng há»™ áº¡. https://viblo.asia/p/gioi-thieu-ve-diffussion-model-EvbLbOKWVnk?fbclid=IwAR2xDSfBkao6pkYfUhN1FGZ3C0JxaQV3MB9vZNba0k7qK01cdu2meEO8DHU",,,,,
"ChÃ o má»i ngÆ°á»i, sau khi train model vá»›i YOLO mÃ¬nh nháº­n ra 1 Ä‘áº·c Ä‘iá»ƒm. Khi mÃ¬nh train 3 class láº§n lÆ°á»£t lÃ  1,2,3 tÆ°Æ¡ng á»©ng vá»›i 3 hÃ¬nh vuÃ´ng , tam giÃ¡c, thoi thÃ¬ model nháº­n diá»‡n ráº¥t tá»‘t vá»›i áº£nh test(hÃ¬nh 1). Tuy nhiÃªn , náº¿u Ä‘á»•i chá»— 3 hÃ¬nh nÃ y cho nhau trong 1 áº£nh thÃ¬ model nháº­n diá»‡n sai nhÃ£n ( hÃ¬nh 2 ).
Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c Ä‘iá»u nÃ y khÃ´ng?
P/S:MÃ¬nh nghÄ© lÃ  náº¿u bá»• sung thÃªm data cho cÃ¡c trÆ°á»ng há»£p sau cÃ³ há»£p lÃ½ khÃ´ng?","ChÃ o má»i ngÆ°á»i, sau khi train model vá»›i YOLO mÃ¬nh nháº­n ra 1 Ä‘áº·c Ä‘iá»ƒm. Khi mÃ¬nh train 3 class láº§n lÆ°á»£t lÃ  1,2,3 tÆ°Æ¡ng á»©ng vá»›i 3 hÃ¬nh vuÃ´ng , tam giÃ¡c, thoi thÃ¬ model nháº­n diá»‡n ráº¥t tá»‘t vá»›i áº£nh test(hÃ¬nh 1). Tuy nhiÃªn , náº¿u Ä‘á»•i chá»— 3 hÃ¬nh nÃ y cho nhau trong 1 áº£nh thÃ¬ model nháº­n diá»‡n sai nhÃ£n ( hÃ¬nh 2 ). Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c Ä‘iá»u nÃ y khÃ´ng? P/S:MÃ¬nh nghÄ© lÃ  náº¿u bá»• sung thÃªm data cho cÃ¡c trÆ°á»ng há»£p sau cÃ³ há»£p lÃ½ khÃ´ng?",,,,,
"ChÃ o mn,
Theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ khi Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, AUPR cho tháº¥y má»‘i tÆ°Æ¡ng quan giá»¯a giÃ¡ trá»‹ precision vÃ  recall theo cÃ¡c ngÆ°á»¡ng. Vá»›i bÃ i cá»§a mÃ¬nh, AUPR = 0.758 cÅ©ng táº¡m cháº¥p nháº­n, nhÆ°ng precision = 0.06 vÃ  recall = 0.95. False positive nhiá»u nÃªn áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ precision.
Cho mÃ¬nh há»i, vÃ¬ sao precision quÃ¡ tháº¥p mÃ  AUPR táº¡m cháº¥p nháº­n váº­y áº¡? VÃ  cÃ¡ch cáº£i thiá»‡n lÃ  gÃ¬?
Xin cÃ¡m Æ¡n ace.","ChÃ o mn, Theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ khi Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, AUPR cho tháº¥y má»‘i tÆ°Æ¡ng quan giá»¯a giÃ¡ trá»‹ precision vÃ  recall theo cÃ¡c ngÆ°á»¡ng. Vá»›i bÃ i cá»§a mÃ¬nh, AUPR = 0.758 cÅ©ng táº¡m cháº¥p nháº­n, nhÆ°ng precision = 0.06 vÃ  recall = 0.95. False positive nhiá»u nÃªn áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ precision. Cho mÃ¬nh há»i, vÃ¬ sao precision quÃ¡ tháº¥p mÃ  AUPR táº¡m cháº¥p nháº­n váº­y áº¡? VÃ  cÃ¡ch cáº£i thiá»‡n lÃ  gÃ¬? Xin cÃ¡m Æ¡n ace.",,,,,
MÃ¬nh xin giá»›i thiá»‡u tá»›i cÃ¡c báº¡n video cá»§a sá»± kiá»‡n DataQuest thá»© 9 vá» á»©ng dá»¥ng phÃ¢n tÃ­ch tÃ i chÃ­nh trÃªn package vnquant.,MÃ¬nh xin giá»›i thiá»‡u tá»›i cÃ¡c báº¡n video cá»§a sá»± kiá»‡n DataQuest thá»© 9 vá» á»©ng dá»¥ng phÃ¢n tÃ­ch tÃ i chÃ­nh trÃªn package vnquant.,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, em hiá»‡n táº¡i Ä‘ang viáº¿t tool báº±ng python Ä‘á»ƒ upload cÃ¡c file lÃªn ná»n táº£ng youtube, vÃ  em Ä‘ang muá»‘n sá»­ dá»¥ng machine learning Ä‘á»ƒ tá»± nháº­n diá»‡n cÃ¡c nÃºt báº¥m trÃªn giao diá»‡n web cá»§a youtube vÃ  khi Ä‘Ã³ tool cá»§a em cÃ³ thá»ƒ tá»± xá»­ lÃ½, háº¡n cháº¿ báº¥m nháº§m nÃºt. Váº­y má»i ngÆ°á»i cho em há»i thÆ° viá»‡n nÃ o thÃ¬ phÃ¹ há»£p nháº¥t vá»›i em Ä‘á»ƒ báº¯t Ä‘áº§u áº¡? Em xin cáº£m Æ¡n áº¡","Em chÃ o má»i ngÆ°á»i áº¡, em hiá»‡n táº¡i Ä‘ang viáº¿t tool báº±ng python Ä‘á»ƒ upload cÃ¡c file lÃªn ná»n táº£ng youtube, vÃ  em Ä‘ang muá»‘n sá»­ dá»¥ng machine learning Ä‘á»ƒ tá»± nháº­n diá»‡n cÃ¡c nÃºt báº¥m trÃªn giao diá»‡n web cá»§a youtube vÃ  khi Ä‘Ã³ tool cá»§a em cÃ³ thá»ƒ tá»± xá»­ lÃ½, háº¡n cháº¿ báº¥m nháº§m nÃºt. Váº­y má»i ngÆ°á»i cho em há»i thÆ° viá»‡n nÃ o thÃ¬ phÃ¹ há»£p nháº¥t vá»›i em Ä‘á»ƒ báº¯t Ä‘áº§u áº¡? Em xin cáº£m Æ¡n áº¡",,,,,
"BÃªn mÃ¬nh Ä‘ang triá»ƒn khai dá»± Ã¡n cáº§n outsource module phÃ¡t hiá»‡n ná»™i dung báº­y báº¡, chÃ­nh trá»‹, tin giáº£... Báº¡n nÃ o Ä‘Ã£ cÃ³ giáº£i phÃ¡p inbox mÃ¬nh Ä‘á»ƒ há»£p tÃ¡c nhÃ©.","BÃªn mÃ¬nh Ä‘ang triá»ƒn khai dá»± Ã¡n cáº§n outsource module phÃ¡t hiá»‡n ná»™i dung báº­y báº¡, chÃ­nh trá»‹, tin giáº£... Báº¡n nÃ o Ä‘Ã£ cÃ³ giáº£i phÃ¡p inbox mÃ¬nh Ä‘á»ƒ há»£p tÃ¡c nhÃ©.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘áº¿n tá»« team Laugh Tale, mÃ¬nh xin chia sáº» solution team mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng Ä‘á»ƒ giÃ nh Ä‘Æ°á»£c top 1 private test táº¡i Quy Nhon AI Hackathon 2022 challenge smart menu.
Náº¿u cÃ³ gÃ¬ chÆ°a rÃµ rÃ ng vÃ  cáº§n tháº£o luáº­n thÃ¬ cÃ¡c báº¡n cÃ³ thá»ƒ há»i mÃ¬nh trong issue cá»§a repo. Thank all.
 â€” vá»›i Thiá»u Nguyá»…n.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘áº¿n tá»« team Laugh Tale, mÃ¬nh xin chia sáº» solution team mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng Ä‘á»ƒ giÃ nh Ä‘Æ°á»£c top 1 private test táº¡i Quy Nhon AI Hackathon 2022 challenge smart menu. Náº¿u cÃ³ gÃ¬ chÆ°a rÃµ rÃ ng vÃ  cáº§n tháº£o luáº­n thÃ¬ cÃ¡c báº¡n cÃ³ thá»ƒ há»i mÃ¬nh trong issue cá»§a repo. Thank all. â€” vá»›i Thiá»u Nguyá»…n.",,,,,
"#hoidap
#python
Cho em há»i OneHotEncoder vÃ  get_dummies khÃ¡c nhau chá»— nao váº­y áº¡?",Cho em há»i OneHotEncoder vÃ  get_dummies khÃ¡c nhau chá»— nao váº­y áº¡?,#hoidap	#python,,,,
"[AI application] AI agent plays Color lines (Line 98)
Line 98 lÃ  1 trong cÃ¡c tá»±a game mÃ¬nh vÃ´ cÃ¹ng yÃªu thÃ­ch khi cÃ²n bÃ©. Hiá»‡n táº¡i khi Ä‘ang lÃ m viá»‡c trong lÄ©nh vá»±c AI, mÃ  cá»¥ thá»ƒ hÆ¡n lÃ  Reinforcement Learning, mÃ¬nh Ä‘áº·c biá»‡t cÃ³ há»©ng thÃº vá»›i cÃ¡c á»©ng dá»¥ng cá»§a AI trong game. Trong project nÃ y, AI agent sáº½ tá»± khÃ¡m phÃ¡ vÃ  há»c cÃ¡ch chÆ¡i Color lines.
Source code: https://github.com/uvipen/Color-lines-deep-Q-learning-pytorch
Demo: https://youtu.be/gd_EJJK_wQg","[AI application] AI agent plays Color lines (Line 98) Line 98 lÃ  1 trong cÃ¡c tá»±a game mÃ¬nh vÃ´ cÃ¹ng yÃªu thÃ­ch khi cÃ²n bÃ©. Hiá»‡n táº¡i khi Ä‘ang lÃ m viá»‡c trong lÄ©nh vá»±c AI, mÃ  cá»¥ thá»ƒ hÆ¡n lÃ  Reinforcement Learning, mÃ¬nh Ä‘áº·c biá»‡t cÃ³ há»©ng thÃº vá»›i cÃ¡c á»©ng dá»¥ng cá»§a AI trong game. Trong project nÃ y, AI agent sáº½ tá»± khÃ¡m phÃ¡ vÃ  há»c cÃ¡ch chÆ¡i Color lines. Source code: https://github.com/uvipen/Color-lines-deep-Q-learning-pytorch Demo: https://youtu.be/gd_EJJK_wQg",,,,,
"em xin chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá» speech2text cho tiáº¿ng viá»‡t vÃ  cÃ³ biáº¿t tá»›i bá»™ dataset VLNP. nhÆ°ng mÃ  em khÃ´ng thá»ƒ truy cáº­p Ä‘Æ°á»£c qua web: https://vlsp.org.vn/resources. vÃ¬ váº­y má»i ngÆ°á»i ai Ä‘Ã£ downloaded bá»™ nÃ y cÃ³ thá»ƒ cho em xin khÃ´ng áº¡?
em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡!","em xin chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá» speech2text cho tiáº¿ng viá»‡t vÃ  cÃ³ biáº¿t tá»›i bá»™ dataset VLNP. nhÆ°ng mÃ  em khÃ´ng thá»ƒ truy cáº­p Ä‘Æ°á»£c qua web: https://vlsp.org.vn/resources. vÃ¬ váº­y má»i ngÆ°á»i ai Ä‘Ã£ downloaded bá»™ nÃ y cÃ³ thá»ƒ cho em xin khÃ´ng áº¡? em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡!",,,,,
"Trong group cÃ³ ai giÃºp báº¡n nÃ y Ä‘Æ°á»£c khÃ´ng? MÃ¬nh chÆ°a á»Ÿ trong trÆ°á»ng há»£p cá»§a báº¡n áº¥y nÃªn cÅ©ng khÃ´ng biáº¿t khuyÃªn tháº¿ nÃ o cho tá»‘t. Mong cÃ¡c báº¡n giÃºp Ä‘á»¡. Cáº£m Æ¡n cÃ¡c báº¡n.
-------------------
Em chÃ o anh áº¡,
Em biáº¿t lÃ  anh Ä‘ang ráº¥t báº­n cÅ©ng nhÆ° nhiá»u viá»‡c nhÆ°ng náº¿u e khÃ´ng bá»‹ rÆ¡i vÃ o hoÃ n cáº£nh nÃ y thÃ¬ em cÅ©ng khÃ´ng dÃ¡m lÃ m phiá»n anh Ä‘Ã¢u áº¡. Chá»‰ lÃ  e hiá»‡n Ä‘ang quÃ¡ rá»‘i vÃ  chÃ´ng chÃªnh vÃ  ngoÃ i anh ra em khÃ´ng biáº¿t nÃªn há»i ai ná»¯a áº¡.
Em nÄƒm nay nÄƒm 4, há»c vá» kinh táº¿. Em nÄƒm ngoÃ¡i cÃ³ Ä‘i thá»±c táº­p vá»‹ trÃ­ BA trong 1 sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ táº¡i viá»‡t nam nhÆ°ng chá»§ yáº¿u BA vá» máº£ng tÃ i chÃ­nh vÃ  lÃ m báº±ng Google Spreadsheets. Tá»›i khoáº£ng gáº§n 6 thÃ¡ng gáº§n Ä‘Ã¢y em má»›i báº¯t Ä‘áº§u há»c python Ä‘á»ƒ Ä‘a nhiá»‡m hÃ³a kháº£ nÄƒng cá»§a báº£n thÃ¢n. Em tá»± há»c nhÆ°ng vá»«a Ä‘i lÃ m vá»«a Ä‘i há»c nÃªn em khÃ´ng táº­p trung 100% vÃ o há»c code. NghÄ©a lÃ  6 thÃ¡ng qua khÃ´ng pháº£i hoÃ n toÃ n 100% e há»c python vÃ  cÅ©ng khÃ´ng cÃ³ ai dáº¡y cáº£ nÃªn em toÃ n tá»± nghÄ© ra váº¥n Ä‘á», tá»± tÃ¬m hÆ°á»›ng giáº£i quyáº¿t. (Em tá»± Ä‘Ã¡nh giÃ¡ tháº¥y em Ä‘ang dá»«ng láº¡i á»Ÿ Mining dá»¯ liá»‡u thÃ´i áº¡, cÃ²n cÃ¡c cÃ¡i cÃ²n láº¡i má»›i chá»‰ dá»«ng láº¡i á»Ÿ basic).
Em Ä‘á»‹nh hÆ°á»›ng sáº½ theo Machine Learning vÃ¬ tuy má»›i chá»‰ dá»«ng láº¡i á»Ÿ Data Analysis nhÆ°ng em tháº¥y nÃ³ ráº¥t cuá»‘n hÃºt vÃ  kiá»ƒu giá»‘ng cÃ³ gÃ¬ Ä‘Ã³ á»Ÿ nÃ³ tá»a ra ráº¥t háº¥p dáº«n, giá»‘ng nhÆ° kiá»ƒu sá»± kÃ¬ diá»‡u cá»§a logic, toÃ¡n há»c vÃ  dá»¯ liá»‡u Ã½ anh áº¡, em khÃ´ng cháº¯c láº¯m nhÆ°ng hiá»‡n táº¡i em cÅ©ng cÃ³ tÃ¬m hiá»ƒu lÃ  em cáº§n cháº¯c vá» Data Science Ä‘á»ƒ phÃ¡t triá»ƒn sÃ¢u hÆ¡n sau nÃ y náº¿u muá»‘n nÃ¢ng cao lÃ m ML.
Em cÃ³ khÃ¡ nhiá»u giá»›i háº¡n nhÆ° sáº¯p ra trÆ°á»ng, muá»‘n theo ngÃ nh nÃ y nhÆ°ng khÃ´ng cÃ³ nhiá»u kinh nghiá»‡m vÃ  cÅ©ng khÃ´ng cÃ³ biáº¿t Ä‘Æ°á»£c lÃ  con Ä‘Æ°á»ng mÃ¬nh cáº§n nhá»¯ng gÃ¬ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cÃ¡i mong muá»‘n Ä‘Ã³.
Em thá»±c sá»± lÃ  Ä‘ang vÃ´ cÃ¹ng báº¿ táº¯c vÃ  khá»§ng hoáº£ng. Em khÃ´ng biáº¿t em nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u hay lÃ m tháº¿ nÃ o ná»¯a anh áº¡. Em ráº¥t muá»‘n nháº­n Ä‘Æ°á»£c lá»i khuyÃªn tá»« anh vÃ  cÃ³ thá»ƒ thÃ¬ anh cÃ³ thá»ƒ cho e 1 vÃ i má»‘c em cáº§n lÃ m vÃ  cáº§n cÃ³ nhá»¯ng gÃ¬ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³ áº¡. Em tháº¥y á»Ÿ Vn cÃ³ váº» nhÆ° cÃ¡c máº£ng ML hoáº·c DS hÃ¬nh nhÆ° cÃ²n chÆ°a nhiá»u láº¯m vÃ¬ em Ä‘ang ráº¥t thÃ¨m Ä‘Æ°á»£c sá»‘ng trong cÃ¡i hÆ¡i thá»Ÿ cá»§a DS,ML nhÆ°ng khÃ´ng tÃ¬m ra anh áº¡. (Ä‘Ã³ cÅ©ng 1 trong sá»‘ lÃ½ do khiáº¿n em khÃ¡ cÄƒng tháº³ng vÃ  stress).
1 láº§n ná»¯a em ráº¥t xin lá»—i náº¿u lÃ m phiá»n anh mÃ  anh Ä‘ang ráº¥t báº­n, nhÆ°ng em ráº¥t mong nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« anh.
Em cáº£m Æ¡n anh Ä‘Ã£ dÃ nh thá»i gian cho em ráº¥t nhiá»u áº¡.
Em ráº¥t mong sá»›m nháº­n Ä‘Æ°á»£c tin tá»« anh!","Trong group cÃ³ ai giÃºp báº¡n nÃ y Ä‘Æ°á»£c khÃ´ng? MÃ¬nh chÆ°a á»Ÿ trong trÆ°á»ng há»£p cá»§a báº¡n áº¥y nÃªn cÅ©ng khÃ´ng biáº¿t khuyÃªn tháº¿ nÃ o cho tá»‘t. Mong cÃ¡c báº¡n giÃºp Ä‘á»¡. Cáº£m Æ¡n cÃ¡c báº¡n. ------------------- Em chÃ o anh áº¡, Em biáº¿t lÃ  anh Ä‘ang ráº¥t báº­n cÅ©ng nhÆ° nhiá»u viá»‡c nhÆ°ng náº¿u e khÃ´ng bá»‹ rÆ¡i vÃ o hoÃ n cáº£nh nÃ y thÃ¬ em cÅ©ng khÃ´ng dÃ¡m lÃ m phiá»n anh Ä‘Ã¢u áº¡. Chá»‰ lÃ  e hiá»‡n Ä‘ang quÃ¡ rá»‘i vÃ  chÃ´ng chÃªnh vÃ  ngoÃ i anh ra em khÃ´ng biáº¿t nÃªn há»i ai ná»¯a áº¡. Em nÄƒm nay nÄƒm 4, há»c vá» kinh táº¿. Em nÄƒm ngoÃ¡i cÃ³ Ä‘i thá»±c táº­p vá»‹ trÃ­ BA trong 1 sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ táº¡i viá»‡t nam nhÆ°ng chá»§ yáº¿u BA vá» máº£ng tÃ i chÃ­nh vÃ  lÃ m báº±ng Google Spreadsheets. Tá»›i khoáº£ng gáº§n 6 thÃ¡ng gáº§n Ä‘Ã¢y em má»›i báº¯t Ä‘áº§u há»c python Ä‘á»ƒ Ä‘a nhiá»‡m hÃ³a kháº£ nÄƒng cá»§a báº£n thÃ¢n. Em tá»± há»c nhÆ°ng vá»«a Ä‘i lÃ m vá»«a Ä‘i há»c nÃªn em khÃ´ng táº­p trung 100% vÃ o há»c code. NghÄ©a lÃ  6 thÃ¡ng qua khÃ´ng pháº£i hoÃ n toÃ n 100% e há»c python vÃ  cÅ©ng khÃ´ng cÃ³ ai dáº¡y cáº£ nÃªn em toÃ n tá»± nghÄ© ra váº¥n Ä‘á», tá»± tÃ¬m hÆ°á»›ng giáº£i quyáº¿t. (Em tá»± Ä‘Ã¡nh giÃ¡ tháº¥y em Ä‘ang dá»«ng láº¡i á»Ÿ Mining dá»¯ liá»‡u thÃ´i áº¡, cÃ²n cÃ¡c cÃ¡i cÃ²n láº¡i má»›i chá»‰ dá»«ng láº¡i á»Ÿ basic). Em Ä‘á»‹nh hÆ°á»›ng sáº½ theo Machine Learning vÃ¬ tuy má»›i chá»‰ dá»«ng láº¡i á»Ÿ Data Analysis nhÆ°ng em tháº¥y nÃ³ ráº¥t cuá»‘n hÃºt vÃ  kiá»ƒu giá»‘ng cÃ³ gÃ¬ Ä‘Ã³ á»Ÿ nÃ³ tá»a ra ráº¥t háº¥p dáº«n, giá»‘ng nhÆ° kiá»ƒu sá»± kÃ¬ diá»‡u cá»§a logic, toÃ¡n há»c vÃ  dá»¯ liá»‡u Ã½ anh áº¡, em khÃ´ng cháº¯c láº¯m nhÆ°ng hiá»‡n táº¡i em cÅ©ng cÃ³ tÃ¬m hiá»ƒu lÃ  em cáº§n cháº¯c vá» Data Science Ä‘á»ƒ phÃ¡t triá»ƒn sÃ¢u hÆ¡n sau nÃ y náº¿u muá»‘n nÃ¢ng cao lÃ m ML. Em cÃ³ khÃ¡ nhiá»u giá»›i háº¡n nhÆ° sáº¯p ra trÆ°á»ng, muá»‘n theo ngÃ nh nÃ y nhÆ°ng khÃ´ng cÃ³ nhiá»u kinh nghiá»‡m vÃ  cÅ©ng khÃ´ng cÃ³ biáº¿t Ä‘Æ°á»£c lÃ  con Ä‘Æ°á»ng mÃ¬nh cáº§n nhá»¯ng gÃ¬ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cÃ¡i mong muá»‘n Ä‘Ã³. Em thá»±c sá»± lÃ  Ä‘ang vÃ´ cÃ¹ng báº¿ táº¯c vÃ  khá»§ng hoáº£ng. Em khÃ´ng biáº¿t em nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u hay lÃ m tháº¿ nÃ o ná»¯a anh áº¡. Em ráº¥t muá»‘n nháº­n Ä‘Æ°á»£c lá»i khuyÃªn tá»« anh vÃ  cÃ³ thá»ƒ thÃ¬ anh cÃ³ thá»ƒ cho e 1 vÃ i má»‘c em cáº§n lÃ m vÃ  cáº§n cÃ³ nhá»¯ng gÃ¬ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³ áº¡. Em tháº¥y á»Ÿ Vn cÃ³ váº» nhÆ° cÃ¡c máº£ng ML hoáº·c DS hÃ¬nh nhÆ° cÃ²n chÆ°a nhiá»u láº¯m vÃ¬ em Ä‘ang ráº¥t thÃ¨m Ä‘Æ°á»£c sá»‘ng trong cÃ¡i hÆ¡i thá»Ÿ cá»§a DS,ML nhÆ°ng khÃ´ng tÃ¬m ra anh áº¡. (Ä‘Ã³ cÅ©ng 1 trong sá»‘ lÃ½ do khiáº¿n em khÃ¡ cÄƒng tháº³ng vÃ  stress). 1 láº§n ná»¯a em ráº¥t xin lá»—i náº¿u lÃ m phiá»n anh mÃ  anh Ä‘ang ráº¥t báº­n, nhÆ°ng em ráº¥t mong nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« anh. Em cáº£m Æ¡n anh Ä‘Ã£ dÃ nh thá»i gian cho em ráº¥t nhiá»u áº¡. Em ráº¥t mong sá»›m nháº­n Ä‘Æ°á»£c tin tá»« anh!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh (Ä‘Ã£ vÃ  Ä‘ang) viáº¿t má»™t blog nhá» vá» Há»c tÄƒng cÆ°á»ng. Há»c tÄƒng cÆ°á»ng á»Ÿ Viá»‡t Nam cÅ©ng Ä‘Ã£ cÃ³ nhiá»u tÃ i liá»‡u chia sáº» nhiá»u kiáº¿n thá»©c cÆ¡ báº£n cÅ©ng nhÆ° nhá»¯ng mÃ´ hÃ¬nh há»c tÄƒng cÆ°á»ng hiá»‡n Ä‘áº¡i, tuy nhiÃªn, mÃ¬nh tháº¥y ráº±ng Ã­t cÃ³ tÃ i liá»‡u Ä‘á» cáº­p tá»›i nhá»¯ng váº¥n Ä‘á» cÆ¡ báº£n nháº¥t vÃ  dáº«n dáº¯t tá»›i nhá»¯ng Ã½ tÆ°á»Ÿng hiá»‡n Ä‘áº¡i. ChÃ­nh vÃ¬ váº­y, mÃ¬nh Ä‘Ã£ lá»±a chá»n viá»‡c viáº¿t má»™t blog Ä‘á»ƒ chia sáº» nhá»¯ng Ã½ tÆ°á»Ÿng cÄƒn báº£n nháº¥t cá»§a Há»c tÄƒng cÆ°á»ng.
Má»¥c Ä‘Ã­ch cá»§a blog: Chia sáº» kiáº¿n thá»©c mÃ¬nh hiá»ƒu biáº¿t vá» há»c tÄƒng cÆ°á»ng, hoÃ n toÃ n lÃ  má»¥c Ä‘Ã­ch cá»™ng Ä‘á»“ng.
Äá»‘i tÆ°á»£ng blog nÃ y hÆ°á»›ng tá»›i: Nhá»¯ng báº¡n má»›i báº¯t Ä‘áº§u vá»›i há»c tÄƒng cÆ°á»ng hoáº·c cÃ³ Ã½ Ä‘á»‹nh muá»‘n tÃ¬m hiá»ƒu vÃ  mong muá»‘n cÃ³ 'shortcut' Ä‘á»ƒ cÃ³ thá»ƒ báº¯t Ä‘áº§u vÃ o há»c lÄ©nh vá»±c nÃ y sÃ¢u hÆ¡n.
ThÃ nh pháº§n cá»§a blog: Blog táº­p trung trÃ¬nh bÃ y nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n, Ã½ tÆ°á»Ÿng thuáº­t toÃ¡n vÃ  cÃ¡ch cÃ i Ä‘áº·t thuáº­t toÃ¡n, ngoÃ i ra cÃ²n cÃ³ má»™t sá»‘ pháº§n cÃ i Ä‘áº·t chÆ°Æ¡ng trÃ¬nh máº«u.
Blog nÃ y khÃ´ng cÃ³: MÃ¬nh khÃ´ng trÃ¬nh bÃ y cÃ¡c chá»©ng minh chi tiáº¿t cÅ©ng nhÆ° cÃ¡c káº¿t quáº£ ToÃ¡n há»c quÃ¡ sÃ¢u vÃ¬ báº£n thÃ¢n mÃ¬nh cÅ©ng khÃ´ng hiá»ƒu.
Má»™t sá»‘ lÆ°u Ã½: Há»c tÄƒng cÆ°á»ng khÃ¡c vá»›i cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y thÃ´ng thÆ°á»ng. CÃ¡c báº¡n khÃ´ng thá»ƒ lÃªn máº¡ng tÃ¬m má»™t táº­p dá»¯ liá»‡u rá»“i cÃ i Ä‘áº·t cÃ¡c mÃ´ hÃ¬nh Ä‘á»ƒ cháº¡y ra káº¿t quáº£ so sÃ¡nh ngay. Äá»ƒ cÃ³ thá»ƒ cÃ i Ä‘áº·t cÃ¡c thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng, báº£n thÃ¢n bÆ°á»›c Ä‘áº§u tiÃªn Ä‘Ã£ pháº£i tá»± mÃ´ hÃ¬nh MDP cho bÃ i toÃ¡n Ä‘Ã³, chÃ­nh vÃ¬ váº­y, mÃ¬nh khÃ´ng trÃ¬nh bÃ y chi tiáº¿t vá» pháº§n cÃ i Ä‘áº·t, dÃ¹ mÃ¬nh Ä‘Ã£ tá»± cÃ i Ä‘áº·t má»™t sá»‘ cÃ¡c thuáº­t toÃ¡n nÃ y báº±ng tay rá»“i.
CÃ´ng viá»‡c sáº¯p tá»›i: Blog nÃ y váº«n Ä‘ang Ä‘Æ°á»£c mÃ¬nh viáº¿t vÃ  mÃ¬nh hy vá»ng Ä‘Æ°á»£c má»i ngÆ°á»i á»§ng há»™ cÅ©ng nhÆ° Ä‘Ã³ng gÃ³p Ã½ kiáº¿n Ä‘á»ƒ cÃ³ thá»ƒ viáº¿t tiáº¿p vá»›i Ä‘am mÃª cá»§a mÃ¬nh. MÃ¬nh sáº½ hoÃ n thiá»‡n thÃªm blog cÅ©ng nhÆ° viáº¿t thÃªm vá» cÃ¡c bÃ i toÃ¡n trong khÃ´ng gian MDP vÃ´ háº¡n vÃ  cÃ³ thá»ƒ tÃ¬m hiá»ƒu vá» cÃ¡c thuáº­t toÃ¡n Há»c tÄƒng cÆ°á»ng hiá»‡n Ä‘áº¡i hÆ¡n.
MÃ¬nh xin gá»­i link blog: https://anavuongdin.github.io/reinforcement-learning/
Cáº£m Æ¡n má»i ngÆ°á»i vÃ¬ Ä‘Ã£ Ä‘á»c!","ChÃ o má»i ngÆ°á»i, mÃ¬nh (Ä‘Ã£ vÃ  Ä‘ang) viáº¿t má»™t blog nhá» vá» Há»c tÄƒng cÆ°á»ng. Há»c tÄƒng cÆ°á»ng á»Ÿ Viá»‡t Nam cÅ©ng Ä‘Ã£ cÃ³ nhiá»u tÃ i liá»‡u chia sáº» nhiá»u kiáº¿n thá»©c cÆ¡ báº£n cÅ©ng nhÆ° nhá»¯ng mÃ´ hÃ¬nh há»c tÄƒng cÆ°á»ng hiá»‡n Ä‘áº¡i, tuy nhiÃªn, mÃ¬nh tháº¥y ráº±ng Ã­t cÃ³ tÃ i liá»‡u Ä‘á» cáº­p tá»›i nhá»¯ng váº¥n Ä‘á» cÆ¡ báº£n nháº¥t vÃ  dáº«n dáº¯t tá»›i nhá»¯ng Ã½ tÆ°á»Ÿng hiá»‡n Ä‘áº¡i. ChÃ­nh vÃ¬ váº­y, mÃ¬nh Ä‘Ã£ lá»±a chá»n viá»‡c viáº¿t má»™t blog Ä‘á»ƒ chia sáº» nhá»¯ng Ã½ tÆ°á»Ÿng cÄƒn báº£n nháº¥t cá»§a Há»c tÄƒng cÆ°á»ng. Má»¥c Ä‘Ã­ch cá»§a blog: Chia sáº» kiáº¿n thá»©c mÃ¬nh hiá»ƒu biáº¿t vá» há»c tÄƒng cÆ°á»ng, hoÃ n toÃ n lÃ  má»¥c Ä‘Ã­ch cá»™ng Ä‘á»“ng. Äá»‘i tÆ°á»£ng blog nÃ y hÆ°á»›ng tá»›i: Nhá»¯ng báº¡n má»›i báº¯t Ä‘áº§u vá»›i há»c tÄƒng cÆ°á»ng hoáº·c cÃ³ Ã½ Ä‘á»‹nh muá»‘n tÃ¬m hiá»ƒu vÃ  mong muá»‘n cÃ³ 'shortcut' Ä‘á»ƒ cÃ³ thá»ƒ báº¯t Ä‘áº§u vÃ o há»c lÄ©nh vá»±c nÃ y sÃ¢u hÆ¡n. ThÃ nh pháº§n cá»§a blog: Blog táº­p trung trÃ¬nh bÃ y nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n, Ã½ tÆ°á»Ÿng thuáº­t toÃ¡n vÃ  cÃ¡ch cÃ i Ä‘áº·t thuáº­t toÃ¡n, ngoÃ i ra cÃ²n cÃ³ má»™t sá»‘ pháº§n cÃ i Ä‘áº·t chÆ°Æ¡ng trÃ¬nh máº«u. Blog nÃ y khÃ´ng cÃ³: MÃ¬nh khÃ´ng trÃ¬nh bÃ y cÃ¡c chá»©ng minh chi tiáº¿t cÅ©ng nhÆ° cÃ¡c káº¿t quáº£ ToÃ¡n há»c quÃ¡ sÃ¢u vÃ¬ báº£n thÃ¢n mÃ¬nh cÅ©ng khÃ´ng hiá»ƒu. Má»™t sá»‘ lÆ°u Ã½: Há»c tÄƒng cÆ°á»ng khÃ¡c vá»›i cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y thÃ´ng thÆ°á»ng. CÃ¡c báº¡n khÃ´ng thá»ƒ lÃªn máº¡ng tÃ¬m má»™t táº­p dá»¯ liá»‡u rá»“i cÃ i Ä‘áº·t cÃ¡c mÃ´ hÃ¬nh Ä‘á»ƒ cháº¡y ra káº¿t quáº£ so sÃ¡nh ngay. Äá»ƒ cÃ³ thá»ƒ cÃ i Ä‘áº·t cÃ¡c thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng, báº£n thÃ¢n bÆ°á»›c Ä‘áº§u tiÃªn Ä‘Ã£ pháº£i tá»± mÃ´ hÃ¬nh MDP cho bÃ i toÃ¡n Ä‘Ã³, chÃ­nh vÃ¬ váº­y, mÃ¬nh khÃ´ng trÃ¬nh bÃ y chi tiáº¿t vá» pháº§n cÃ i Ä‘áº·t, dÃ¹ mÃ¬nh Ä‘Ã£ tá»± cÃ i Ä‘áº·t má»™t sá»‘ cÃ¡c thuáº­t toÃ¡n nÃ y báº±ng tay rá»“i. CÃ´ng viá»‡c sáº¯p tá»›i: Blog nÃ y váº«n Ä‘ang Ä‘Æ°á»£c mÃ¬nh viáº¿t vÃ  mÃ¬nh hy vá»ng Ä‘Æ°á»£c má»i ngÆ°á»i á»§ng há»™ cÅ©ng nhÆ° Ä‘Ã³ng gÃ³p Ã½ kiáº¿n Ä‘á»ƒ cÃ³ thá»ƒ viáº¿t tiáº¿p vá»›i Ä‘am mÃª cá»§a mÃ¬nh. MÃ¬nh sáº½ hoÃ n thiá»‡n thÃªm blog cÅ©ng nhÆ° viáº¿t thÃªm vá» cÃ¡c bÃ i toÃ¡n trong khÃ´ng gian MDP vÃ´ háº¡n vÃ  cÃ³ thá»ƒ tÃ¬m hiá»ƒu vá» cÃ¡c thuáº­t toÃ¡n Há»c tÄƒng cÆ°á»ng hiá»‡n Ä‘áº¡i hÆ¡n. MÃ¬nh xin gá»­i link blog: https://anavuongdin.github.io/reinforcement-learning/ Cáº£m Æ¡n má»i ngÆ°á»i vÃ¬ Ä‘Ã£ Ä‘á»c!",,,,,
"ChÃ o má»i ngÆ°á»i áº¡. Em cÃ³ 1 cÃ¢u há»i nhÆ° sau ráº¥t mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p áº¡.
Trong quÃ¡ trÃ¬nh triá»ƒn khai cÃ¡c model Yolo. Em gáº·p 1 váº¥n Ä‘á»:
Khi cháº¡y model báº±ng Dnn cá»§a openCV báº±ng Cpu thÃ¬ tá»‘c Ä‘á»™ nhanh hÆ¡n Cháº¡y model trÃªn ná»n Darknet khoáº£ng 10 láº§n(CÃ³ váº» nhÆ° lÃ  do opencv Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi intel nÃªn khi cháº¡y trÃªn cpu intel cho tá»‘c Ä‘á»™ nhanh).
Khi cháº¡y báº±ng Gpu thÃ¬ detect báº±ng Dnn-opencv vÃ  darknet cho tá»‘c Ä‘á»™ gáº§n nhÆ° nhau.
Em sá»­ dá»¥ng con card RtX3060. Em cÃ³ má»™t cÃ¢u há»i lÃ  liá»‡u cÃ³ pháº£i do card hÃ¬nh cá»§a em máº¡nh nÃªn tá»‘c Ä‘á»™ xá»­ lÃ½ gpu trÃªn dnn vÃ  darknet nhÆ° nhau khÃ´ng? vÃ  Náº¿u cháº¡y báº±ng Gpu cáº¥u hÃ¬nh nhá» thÃ¬ tá»‘c Ä‘á»™ xá»­ lÃ½ cá»§a 2 máº¡ng dnn -opencv vÃ  darknet tháº¿ nÃ o? liá»‡u dnn cÃ³ nhanh hÆ¡n darknet khÃ´ng?
Em cáº£m Æ¡n!",ChÃ o má»i ngÆ°á»i áº¡. Em cÃ³ 1 cÃ¢u há»i nhÆ° sau ráº¥t mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p áº¡. Trong quÃ¡ trÃ¬nh triá»ƒn khai cÃ¡c model Yolo. Em gáº·p 1 váº¥n Ä‘á»: Khi cháº¡y model báº±ng Dnn cá»§a openCV báº±ng Cpu thÃ¬ tá»‘c Ä‘á»™ nhanh hÆ¡n Cháº¡y model trÃªn ná»n Darknet khoáº£ng 10 láº§n(CÃ³ váº» nhÆ° lÃ  do opencv Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi intel nÃªn khi cháº¡y trÃªn cpu intel cho tá»‘c Ä‘á»™ nhanh). Khi cháº¡y báº±ng Gpu thÃ¬ detect báº±ng Dnn-opencv vÃ  darknet cho tá»‘c Ä‘á»™ gáº§n nhÆ° nhau. Em sá»­ dá»¥ng con card RtX3060. Em cÃ³ má»™t cÃ¢u há»i lÃ  liá»‡u cÃ³ pháº£i do card hÃ¬nh cá»§a em máº¡nh nÃªn tá»‘c Ä‘á»™ xá»­ lÃ½ gpu trÃªn dnn vÃ  darknet nhÆ° nhau khÃ´ng? vÃ  Náº¿u cháº¡y báº±ng Gpu cáº¥u hÃ¬nh nhá» thÃ¬ tá»‘c Ä‘á»™ xá»­ lÃ½ cá»§a 2 máº¡ng dnn -opencv vÃ  darknet tháº¿ nÃ o? liá»‡u dnn cÃ³ nhanh hÆ¡n darknet khÃ´ng? Em cáº£m Æ¡n!,,,,,
"Em xin chÃ o táº¥t cáº£ cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m áº¡.
Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» topic 3D reconstruction vÃ  Ä‘ang Ä‘á»c paper BANMo: Building Animatable 3D Neural Models from Many Casual Videos (project page: https://banmo-www.github.io) thÃ¬ gáº·p cÃ¡c thuáº­t ngá»¯ nhÆ° canonical embedding, canonical 3D model, canonical space, neural implicit model, neural implicit function,... em chÆ°a hiá»ƒu Ä‘Æ°á»£c nÃªn nhá» má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡. 
NhÃ¢n thá»ƒ má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ vÃ  Ä‘ang lÃ m hay tÃ¬m hiá»ƒu vá» topic 3D reconstruction hay cá»¥ thá»ƒ lÃ  deformable shape reconstruction from video(s) cÃ³ thá»ƒ cho em xin tham kháº£o tÃ i liá»‡u hay khoÃ¡ há»c Ä‘á»ƒ tá»± há»c vá» topic nÃ y Ä‘Æ°á»£c khÃ´ng áº¡. 
Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u!","Em xin chÃ o táº¥t cáº£ cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m áº¡. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» topic 3D reconstruction vÃ  Ä‘ang Ä‘á»c paper BANMo: Building Animatable 3D Neural Models from Many Casual Videos (project page: https://banmo-www.github.io) thÃ¬ gáº·p cÃ¡c thuáº­t ngá»¯ nhÆ° canonical embedding, canonical 3D model, canonical space, neural implicit model, neural implicit function,... em chÆ°a hiá»ƒu Ä‘Æ°á»£c nÃªn nhá» má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡. NhÃ¢n thá»ƒ má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ vÃ  Ä‘ang lÃ m hay tÃ¬m hiá»ƒu vá» topic 3D reconstruction hay cá»¥ thá»ƒ lÃ  deformable shape reconstruction from video(s) cÃ³ thá»ƒ cho em xin tham kháº£o tÃ i liá»‡u hay khoÃ¡ há»c Ä‘á»ƒ tá»± há»c vá» topic nÃ y Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u!",,,,,
"Hi cÃ¡c bÃ¡c,
Em cÃ³ má»™t bÃ i toÃ¡n, bÃ³c tÃ¡ch Ä‘á»‹a chá»‰ á»Ÿ Viá»‡t Nam (kiá»ƒu dá»¯ liá»‡u text phi cáº¥u trÃºc). VÃ­ dá»¥:
gh cho e den 285 duong cmtt, p12, q10, hcm nha
gh cho e den 285 cmt8, p.12, q10, tp.hcm nha
gh cho em den 285 d.cmt8, p12, q.10, tp hcm nha
285 09028388993 cmt8 p12 q10
285 cmt8, p.12, q10 09028388993
Em muá»‘n so sÃ¡nh cÃ¡c chuá»—i nÃ y sá»­ dá»¥ng Machine learning, vÃ  Ä‘Æ°a ra káº¿t quáº£ lÃ  match hoáº·c not match.
Em chÆ°a biáº¿t giáº£i phÃ¡p nhÆ° tháº¿ nÃ o, vÃ  cÃ¡c bÃ¡c cÃ³ tÃ i liá»‡u thÃ¬ cho em xin tham kháº£o áº¡. Em cáº£m Æ¡n!","Hi cÃ¡c bÃ¡c, Em cÃ³ má»™t bÃ i toÃ¡n, bÃ³c tÃ¡ch Ä‘á»‹a chá»‰ á»Ÿ Viá»‡t Nam (kiá»ƒu dá»¯ liá»‡u text phi cáº¥u trÃºc). VÃ­ dá»¥: gh cho e den 285 duong cmtt, p12, q10, hcm nha gh cho e den 285 cmt8, p.12, q10, tp.hcm nha gh cho em den 285 d.cmt8, p12, q.10, tp hcm nha 285 09028388993 cmt8 p12 q10 285 cmt8, p.12, q10 09028388993 Em muá»‘n so sÃ¡nh cÃ¡c chuá»—i nÃ y sá»­ dá»¥ng Machine learning, vÃ  Ä‘Æ°a ra káº¿t quáº£ lÃ  match hoáº·c not match. Em chÆ°a biáº¿t giáº£i phÃ¡p nhÆ° tháº¿ nÃ o, vÃ  cÃ¡c bÃ¡c cÃ³ tÃ i liá»‡u thÃ¬ cho em xin tham kháº£o áº¡. Em cáº£m Æ¡n!",,,,,
"Tiá»‡p cho mÃ¬nh chia sáº» thÃªm thÃ´ng tin vá» lá»›p Foundation of DS vÃ  ML (miá»…n phÃ­ vÃ  báº±ng tiáº¿ng Viá»‡t) cho cÃ¡c báº¡n nÃ o quan tÃ¢m á»Ÿ Ä‘Ã¢y nhÃ©.
--- MÃ¬nh gá»­i slides cho bÃ i giáº£ng Ä‘áº§u tiÃªn cho lá»›p ""Foundation of Data Science and Machine Learning"" (Há»c pháº§n CÆ¡ Báº£n) á»Ÿ Ä‘Ã¢y: https://nhatptnk8912.github.io/Warmup_New.pdf . Khi mÃ¬nh cÃ³ thá»i gian thÃ¬ mÃ¬nh sáº½ thu Ã¢m láº¡i bÃ i giáº£ng vÃ  gá»­i lÃªn homepage vÃ  page khoa há»c dá»¯ liá»‡u (https://www.facebook.com/khoahocvadulieu). MÃ¬nh sáº½ dÃ¹ng tiáº¿ng Viá»‡t Ä‘á»ƒ giáº£ng máº·c dÃ¹ ngÃ´n ngá»¯ trong slides lÃ  tiáº¿ng Anh. CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c slides tham kháº£o trÆ°á»›c.
BÃ i giáº£ng Ä‘áº§u tiÃªn chá»§ yáº¿u review láº¡i nhá»¯ng chá»§ Ä‘á» chÃºng mÃ¬nh sáº½ há»c, nhá»¯ng nguyÃªn táº¯c khi lÃ m DS vÃ  ML, vÃ  nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n vá» xÃ¡c suáº¥t (sáº½ há»¯u dá»¥ng cho cÃ¡c báº¡n khi há»c cÃ¡c bÃ i giáº£ng vá» sau).
BÃ i giáº£ng phÃ¹ há»£p cho cÃ¡c báº¡n Ä‘ang báº¯t Ä‘áº§u há»c vá» DS vÃ  ML. BÃ i giáº£ng cÅ©ng dá»±a vÃ o ráº¥t nhiá»u bÃ i giáº£ng mÃ¬nh dáº¡y táº¡i Má»¹ cho cÃ¡c báº¡n muá»‘n tÃ¬m hiá»ƒu vá» DS vÃ  ML. VÃ¬ váº­y, cÃ¡c báº¡n khÃ´ng cÃ³ background bÃªn khá»‘i ká»¹ thuáº­t nhÆ° kinh táº¿, ngoáº¡i thÆ°Æ¡ng, xÃ£ há»™i há»c Ä‘á»u cÃ³ thá»ƒ há»c Ä‘Æ°á»£c.
MÃ¬nh sáº½ update thÃªm slides vÃ  bÃ i giáº£ng trÃªn page trong thá»i gian sáº¯p tá»›i. VÃ¬ váº­y, báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ theo dÃµi thÃªm.","Tiá»‡p cho mÃ¬nh chia sáº» thÃªm thÃ´ng tin vá» lá»›p Foundation of DS vÃ  ML (miá»…n phÃ­ vÃ  báº±ng tiáº¿ng Viá»‡t) cho cÃ¡c báº¡n nÃ o quan tÃ¢m á»Ÿ Ä‘Ã¢y nhÃ©. --- MÃ¬nh gá»­i slides cho bÃ i giáº£ng Ä‘áº§u tiÃªn cho lá»›p ""Foundation of Data Science and Machine Learning"" (Há»c pháº§n CÆ¡ Báº£n) á»Ÿ Ä‘Ã¢y: https://nhatptnk8912.github.io/Warmup_New.pdf . Khi mÃ¬nh cÃ³ thá»i gian thÃ¬ mÃ¬nh sáº½ thu Ã¢m láº¡i bÃ i giáº£ng vÃ  gá»­i lÃªn homepage vÃ  page khoa há»c dá»¯ liá»‡u (https://www.facebook.com/khoahocvadulieu). MÃ¬nh sáº½ dÃ¹ng tiáº¿ng Viá»‡t Ä‘á»ƒ giáº£ng máº·c dÃ¹ ngÃ´n ngá»¯ trong slides lÃ  tiáº¿ng Anh. CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c slides tham kháº£o trÆ°á»›c. BÃ i giáº£ng Ä‘áº§u tiÃªn chá»§ yáº¿u review láº¡i nhá»¯ng chá»§ Ä‘á» chÃºng mÃ¬nh sáº½ há»c, nhá»¯ng nguyÃªn táº¯c khi lÃ m DS vÃ  ML, vÃ  nhá»¯ng khÃ¡i niá»‡m cÆ¡ báº£n vá» xÃ¡c suáº¥t (sáº½ há»¯u dá»¥ng cho cÃ¡c báº¡n khi há»c cÃ¡c bÃ i giáº£ng vá» sau). BÃ i giáº£ng phÃ¹ há»£p cho cÃ¡c báº¡n Ä‘ang báº¯t Ä‘áº§u há»c vá» DS vÃ  ML. BÃ i giáº£ng cÅ©ng dá»±a vÃ o ráº¥t nhiá»u bÃ i giáº£ng mÃ¬nh dáº¡y táº¡i Má»¹ cho cÃ¡c báº¡n muá»‘n tÃ¬m hiá»ƒu vá» DS vÃ  ML. VÃ¬ váº­y, cÃ¡c báº¡n khÃ´ng cÃ³ background bÃªn khá»‘i ká»¹ thuáº­t nhÆ° kinh táº¿, ngoáº¡i thÆ°Æ¡ng, xÃ£ há»™i há»c Ä‘á»u cÃ³ thá»ƒ há»c Ä‘Æ°á»£c. MÃ¬nh sáº½ update thÃªm slides vÃ  bÃ i giáº£ng trÃªn page trong thá»i gian sáº¯p tá»›i. VÃ¬ váº­y, báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ theo dÃµi thÃªm.",,,,,
"Em chÃ o táº¥t cáº£ cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m.
Em muá»‘n tÃ¬m hiá»ƒu vá» Face Recognition trÆ°á»›c tiÃªn lÃ  vá»›i áº£nh, vá»›i video vÃ  cuá»‘i cÃ¹ng lÃ  Face Recognition vá»›i video stream. Em cÃ³ kiáº¿n thá»©c cáº§n thiáº¿t vá» Machine Learning, cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n trong Machine Learning. CÃ³ kiáº¿n thá»©c vá» CNN vÃ  Ä‘Ã£ lÃ m quen vá»›i tensorflow, keras. Em Ä‘ang há»c khoÃ¡ Deep Learnning Specialization trÃªn coursera (Ä‘Ã£ há»c xong course 2 ), vÃ  khoÃ¡ vá» triá»ƒn khai Tensorflow developer. Em cÃ³ Ä‘á»c qua (chÆ°a ká»¹ ) vá» cuá»‘n sÃ¡ch Deep Learning cÆ¡ báº£n cá»§a anh Nguyá»…n Thanh Tuáº¥n, cuá»‘n sÃ¡ch Computer Vision with Jason Br.
Em Ä‘Äƒng bÃ i muá»‘n nhá» cÃ¡c Anh (Chá»‹) trong nhÃ³m chia sáº» vÃ  tÆ° váº¥n kinh nghiá»‡m há»c táº­p (cÃ¡c kiáº¿n thá»©c cáº§n thiáº¿t, cÃ¡c má»¥c quan trá»ng), hÆ°á»›ng há»c táº­p phÃ¹ há»£p vá»›i em vÃ  cÃ¡c nguá»“n tÃ i liá»‡u há»c táº­p vá» máº£ng nÃ y.
Em cáº£m Æ¡n ráº¥t nhiá»u áº¡!","Em chÃ o táº¥t cáº£ cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m. Em muá»‘n tÃ¬m hiá»ƒu vá» Face Recognition trÆ°á»›c tiÃªn lÃ  vá»›i áº£nh, vá»›i video vÃ  cuá»‘i cÃ¹ng lÃ  Face Recognition vá»›i video stream. Em cÃ³ kiáº¿n thá»©c cáº§n thiáº¿t vá» Machine Learning, cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n trong Machine Learning. CÃ³ kiáº¿n thá»©c vá» CNN vÃ  Ä‘Ã£ lÃ m quen vá»›i tensorflow, keras. Em Ä‘ang há»c khoÃ¡ Deep Learnning Specialization trÃªn coursera (Ä‘Ã£ há»c xong course 2 ), vÃ  khoÃ¡ vá» triá»ƒn khai Tensorflow developer. Em cÃ³ Ä‘á»c qua (chÆ°a ká»¹ ) vá» cuá»‘n sÃ¡ch Deep Learning cÆ¡ báº£n cá»§a anh Nguyá»…n Thanh Tuáº¥n, cuá»‘n sÃ¡ch Computer Vision with Jason Br. Em Ä‘Äƒng bÃ i muá»‘n nhá» cÃ¡c Anh (Chá»‹) trong nhÃ³m chia sáº» vÃ  tÆ° váº¥n kinh nghiá»‡m há»c táº­p (cÃ¡c kiáº¿n thá»©c cáº§n thiáº¿t, cÃ¡c má»¥c quan trá»ng), hÆ°á»›ng há»c táº­p phÃ¹ há»£p vá»›i em vÃ  cÃ¡c nguá»“n tÃ i liá»‡u há»c táº­p vá» máº£ng nÃ y. Em cáº£m Æ¡n ráº¥t nhiá»u áº¡!",,,,,
"Em má»›i nháº­p mÃ´n FundaML mong anh chá»‹ thÃ´ng cáº£m.
Em tháº¯c máº¯c vÃ¬ sao cÃ³ thá»ƒ giáº£i 4.9 báº±ng cÃ¡ch tÃ­nh Ä‘áº¡o hÃ m báº±ng 0 áº¡? VÃ¬ Ä‘áº¡o hÃ m báº±ng 0 chá»‰ lÃ  chá»‰ ra táº¡i Ä‘Ã³ hÃ m cÃ³ cá»±c trá»‹ thÃ´i mÃ . Sao biáº¿t Ä‘Æ°á»£c lÃ  cá»±c Ä‘áº¡i hay cá»±c tiá»ƒu áº¡? Em xin cáº£m Æ¡n.",Em má»›i nháº­p mÃ´n FundaML mong anh chá»‹ thÃ´ng cáº£m. Em tháº¯c máº¯c vÃ¬ sao cÃ³ thá»ƒ giáº£i 4.9 báº±ng cÃ¡ch tÃ­nh Ä‘áº¡o hÃ m báº±ng 0 áº¡? VÃ¬ Ä‘áº¡o hÃ m báº±ng 0 chá»‰ lÃ  chá»‰ ra táº¡i Ä‘Ã³ hÃ m cÃ³ cá»±c trá»‹ thÃ´i mÃ . Sao biáº¿t Ä‘Æ°á»£c lÃ  cá»±c Ä‘áº¡i hay cá»±c tiá»ƒu áº¡? Em xin cáº£m Æ¡n.,,"#math, #Q&A",,,
"Em chÃ o má»i ngÆ°á»i áº¡!!! Em cÃ³ dá»± Ä‘á»‹nh Ä‘Äƒng kÃ­ khoÃ¡ há»c data bÃªn funix áº¡. Ai Ä‘Äƒng kÃ­ há»c bÃªn funix rÃ¹i cho em xin Ã­t review Ä‘Æ°á»£c khÃ´ng áº¡ ?? Má»i ngÆ°á»i recommend cho em má»™t sá»‘ chá»— há»c uy tÃ­n khÃ¡c Ä‘Æ°á»£c khÃ´ng áº¡
Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡ ğŸ˜„
P/s: Em lÃ  sinh viÃªn nÄƒm 3 áº¡ !!!",Em chÃ o má»i ngÆ°á»i áº¡!!! Em cÃ³ dá»± Ä‘á»‹nh Ä‘Äƒng kÃ­ khoÃ¡ há»c data bÃªn funix áº¡. Ai Ä‘Äƒng kÃ­ há»c bÃªn funix rÃ¹i cho em xin Ã­t review Ä‘Æ°á»£c khÃ´ng áº¡ ?? Má»i ngÆ°á»i recommend cho em má»™t sá»‘ chá»— há»c uy tÃ­n khÃ¡c Ä‘Æ°á»£c khÃ´ng áº¡ Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡ P/s: Em lÃ  sinh viÃªn nÄƒm 3 áº¡ !!!,,,,,
"Anh chá»‹ em há»c tiáº¿ng Anh cháº¯c Ä‘á»u biáº¿t collocations, 
Hiá»‡n táº¡i mÃ¬nh muá»‘n tÃ¬m collocations patterns trong 1 Ä‘oáº¡n vÄƒn, mÃ  chÆ°a biáº¿t  hÆ°á»›ng lÃ m nhÆ° tháº¿ nÃ o.
vÃ­ dá»¥ Sheâ€™s perfectly capable of running her business. 
thÃ¬ perfectly capablevÃ  running... business lÃ  2 collocations.

Hiá»‡n táº¡i mÃ¬nh má»›i nghÄ© ra tÃ¡ch ra n-gram, rá»“i dÃ¹ng metric nÃ o Ä‘Ã³ Ä‘á»ƒ so sÃ¡nh collocations trong tá»« Ä‘iá»ƒn Ä‘á»ƒ ra Ä‘á»™ similarity. nhÆ°ng tháº¿ nÃ y Ä‘á»™ phá»©c táº¡p váº«n lá»›n quÃ¡.

ace cÃ³ Ã½ tÆ°á»Ÿng nÃ o khÃ¡c,  pretrain gÃ¬ Ä‘á»ƒ xá»­ lÃ½ bÃ i nÃ y khÃ´ng áº¡, em cÃ¡m Æ¡n.","Anh chá»‹ em há»c tiáº¿ng Anh cháº¯c Ä‘á»u biáº¿t collocations, Hiá»‡n táº¡i mÃ¬nh muá»‘n tÃ¬m collocations patterns trong 1 Ä‘oáº¡n vÄƒn, mÃ  chÆ°a biáº¿t hÆ°á»›ng lÃ m nhÆ° tháº¿ nÃ o. vÃ­ dá»¥ Sheâ€™s perfectly capable of running her business. thÃ¬ perfectly capablevÃ  running... business lÃ  2 collocations. Hiá»‡n táº¡i mÃ¬nh má»›i nghÄ© ra tÃ¡ch ra n-gram, rá»“i dÃ¹ng metric nÃ o Ä‘Ã³ Ä‘á»ƒ so sÃ¡nh collocations trong tá»« Ä‘iá»ƒn Ä‘á»ƒ ra Ä‘á»™ similarity. nhÆ°ng tháº¿ nÃ y Ä‘á»™ phá»©c táº¡p váº«n lá»›n quÃ¡. ace cÃ³ Ã½ tÆ°á»Ÿng nÃ o khÃ¡c, pretrain gÃ¬ Ä‘á»ƒ xá»­ lÃ½ bÃ i nÃ y khÃ´ng áº¡, em cÃ¡m Æ¡n.",,,,,
"Em Ä‘ang muá»‘n build há»‡ thá»‘ng quáº£ng cÃ¡o trÃªn máº¡ng xÃ£ há»™i theo cÃ¡ nhÃ¢n hÃ³a ngÆ°á»i dÃ¹ng. Ai cÃ³ thá»ƒ sp thÃ¬ inb em vá»›i, em cáº£m Æ¡n áº¡.","Em Ä‘ang muá»‘n build há»‡ thá»‘ng quáº£ng cÃ¡o trÃªn máº¡ng xÃ£ há»™i theo cÃ¡ nhÃ¢n hÃ³a ngÆ°á»i dÃ¹ng. Ai cÃ³ thá»ƒ sp thÃ¬ inb em vá»›i, em cáº£m Æ¡n áº¡.",,,,,
"Em chÃ o anh chá»‹, anh chá»‹ cho em há»i lÃ  cÃ³ trang nÃ o lÃ m quiz machine learning á»•n khÃ´ng áº¡, tiáº¿ng viá»‡t cÃ ng tá»‘t.
Em cáº£m Æ¡n áº¡","Em chÃ o anh chá»‹, anh chá»‹ cho em há»i lÃ  cÃ³ trang nÃ o lÃ m quiz machine learning á»•n khÃ´ng áº¡, tiáº¿ng viá»‡t cÃ ng tá»‘t. Em cáº£m Æ¡n áº¡",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em khÃ´ng pháº£i dÃ¢n chuyÃªn vá» DevOps hay Ops mÃ  chá»‰ chuyÃªn Dev. Tuy nhiÃªn gáº§n Ä‘Ã¢y cÃ³ nhiá»u báº¡n há»i vá» Docker cho Deep Learning nÃªn cÅ©ng máº¡nh dáº¡n lÃ m clip chia sáº».
Clip lÃ  cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n nháº¥t lÃ m base cho cÃ¡c báº¡n tham kháº£o vÃ  nghiÃªn cá»©u thÃªm. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c!
Cáº£m Æ¡n cáº£ nhÃ !","KÃ­nh chÃ o cÃ¡c bÃ¡c, em khÃ´ng pháº£i dÃ¢n chuyÃªn vá» DevOps hay Ops mÃ  chá»‰ chuyÃªn Dev. Tuy nhiÃªn gáº§n Ä‘Ã¢y cÃ³ nhiá»u báº¡n há»i vá» Docker cho Deep Learning nÃªn cÅ©ng máº¡nh dáº¡n lÃ m clip chia sáº». Clip lÃ  cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n nháº¥t lÃ m base cho cÃ¡c báº¡n tham kháº£o vÃ  nghiÃªn cá»©u thÃªm. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c! Cáº£m Æ¡n cáº£ nhÃ !",,,,,
"MÃ¬nh ma má»›i, cÃ¡c báº¡n nhiá»u kinh nghiá»‡m xem giÃºp mÃ¬nh, trong 3 cÃ¡i model mÃ¬nh train Ä‘Æ°á»£c, thÃ¬ cÃ¡i nÃ o á»•n nháº¥t, vÃ  khi minh train mÃ¬nh Ä‘á»ƒ EarlyStopping(monitor='val_accuracy') thÃ¬ trong quÃ¡ trÃ¬nh val_accuracy tÄƒng thÃ¬ val_loss khÃ´ng giáº£m mÃ  láº¡i tÄƒng nhÆ° trong anh sá»‘ 2, nhÆ° váº­y cÃ³ Ä‘Æ°á»£c gá»i lÃ  overfiting khÃ´ng, má»©c Ä‘á»™ overfiting nhÆ° váº­y cÃ³ lá»›n láº¯m khÃ´ng. Cáº£m Æ¡n cÃ¡c báº¡n.","MÃ¬nh ma má»›i, cÃ¡c báº¡n nhiá»u kinh nghiá»‡m xem giÃºp mÃ¬nh, trong 3 cÃ¡i model mÃ¬nh train Ä‘Æ°á»£c, thÃ¬ cÃ¡i nÃ o á»•n nháº¥t, vÃ  khi minh train mÃ¬nh Ä‘á»ƒ EarlyStopping(monitor='val_accuracy') thÃ¬ trong quÃ¡ trÃ¬nh val_accuracy tÄƒng thÃ¬ val_loss khÃ´ng giáº£m mÃ  láº¡i tÄƒng nhÆ° trong anh sá»‘ 2, nhÆ° váº­y cÃ³ Ä‘Æ°á»£c gá»i lÃ  overfiting khÃ´ng, má»©c Ä‘á»™ overfiting nhÆ° váº­y cÃ³ lá»›n láº¯m khÃ´ng. Cáº£m Æ¡n cÃ¡c báº¡n.",,,,,
"ChÃ o má»i ngÆ°á»i.
Láº§n trÆ°á»›c mÃ¬nh cÃ³ há»i vá» váº¥n Ä‘á» triá»ƒn khai á»©ng dá»¥ng cÃ¡c mÃ´ hÃ¬nh AI/DL trÃªn mobile vÃ  Ä‘Ã£ nháº­n Ä‘Æ°á»£c nhiá»u sá»± há»— trá»£. Team mÃ¬nh cÅ©ng Ä‘Ã£ hoÃ n thÃ nh Ä‘Æ°á»£c task nÃ y báº±ng viá»‡c dÃ¹ng NCNN chuyá»ƒn mÃ´ hÃ¬nh qua C++ rá»“i tÃ­ch há»£p vÃ o mobile SDK. MÃ¬nh ráº¥t cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ há»— trá»£ nhiá»‡t tÃ¬nh!
HÃ´m nay, mÃ¬nh cÃ³ má»™t váº¥n Ä‘á» khÃ¡ tÆ°Æ¡ng tá»± mong má»i ngÆ°á»i tiáº¿p tá»¥c giÃºp Ä‘á»¡ lÃ  triá»ƒn khai mÃ´ hÃ¬nh AI/DL trÃªn ná»n web client - tá»©c lÃ  cÃ¡c yÃªu cáº§u Ä‘Æ°á»£c xá»­ lÃ½ ngay táº¡i phÃ­a client, khÃ´ng cáº§n pháº£i gá»­i request/áº£nh vá» server. VÃ¬ mÃ¬nh khÃ´ng cÃ³ nhiá»u kinh nghiá»‡m vá» web (chá»‰ hiá»ƒu basic vá» html, css vÃ  javascript) nÃªn mong má»i chá»‰ chi tiáº¿t má»™t chÃºt. NgoÃ i ra, mÃ¬nh lÃ m Web SDK thay vÃ¬ web app nÃªn cÃ³ mong muá»‘n sá»­ dá»¥ng Ã­t thÆ° viá»‡c, dependencies Ã­t nháº¥t cÃ³ thá»ƒ.
Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ cá»§a má»i ngÆ°á»i.
ChÃ¢n thÃ nh cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i. Láº§n trÆ°á»›c mÃ¬nh cÃ³ há»i vá» váº¥n Ä‘á» triá»ƒn khai á»©ng dá»¥ng cÃ¡c mÃ´ hÃ¬nh AI/DL trÃªn mobile vÃ  Ä‘Ã£ nháº­n Ä‘Æ°á»£c nhiá»u sá»± há»— trá»£. Team mÃ¬nh cÅ©ng Ä‘Ã£ hoÃ n thÃ nh Ä‘Æ°á»£c task nÃ y báº±ng viá»‡c dÃ¹ng NCNN chuyá»ƒn mÃ´ hÃ¬nh qua C++ rá»“i tÃ­ch há»£p vÃ o mobile SDK. MÃ¬nh ráº¥t cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ há»— trá»£ nhiá»‡t tÃ¬nh! HÃ´m nay, mÃ¬nh cÃ³ má»™t váº¥n Ä‘á» khÃ¡ tÆ°Æ¡ng tá»± mong má»i ngÆ°á»i tiáº¿p tá»¥c giÃºp Ä‘á»¡ lÃ  triá»ƒn khai mÃ´ hÃ¬nh AI/DL trÃªn ná»n web client - tá»©c lÃ  cÃ¡c yÃªu cáº§u Ä‘Æ°á»£c xá»­ lÃ½ ngay táº¡i phÃ­a client, khÃ´ng cáº§n pháº£i gá»­i request/áº£nh vá» server. VÃ¬ mÃ¬nh khÃ´ng cÃ³ nhiá»u kinh nghiá»‡m vá» web (chá»‰ hiá»ƒu basic vá» html, css vÃ  javascript) nÃªn mong má»i chá»‰ chi tiáº¿t má»™t chÃºt. NgoÃ i ra, mÃ¬nh lÃ m Web SDK thay vÃ¬ web app nÃªn cÃ³ mong muá»‘n sá»­ dá»¥ng Ã­t thÆ° viá»‡c, dependencies Ã­t nháº¥t cÃ³ thá»ƒ. Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ cá»§a má»i ngÆ°á»i. ChÃ¢n thÃ nh cáº£m Æ¡n!",,,,,
"MÃ¬nh cáº§n tÃ¬m vÃ­ dá»¥ code vá» MLP mode trong keras Ä‘á»ƒ predict probabilities cá»§a tá»«ng class/label mÃ  khÃ´ng dÃ¹ng hÃ m predict_prob.
Náº¿u báº¡n nÃ o cÃ³ cho mÃ¬nh tham kháº£o vá»›i.
Ráº¥t cÃ¡m Æ¡n.",MÃ¬nh cáº§n tÃ¬m vÃ­ dá»¥ code vá» MLP mode trong keras Ä‘á»ƒ predict probabilities cá»§a tá»«ng class/label mÃ  khÃ´ng dÃ¹ng hÃ m predict_prob. Náº¿u báº¡n nÃ o cÃ³ cho mÃ¬nh tham kháº£o vá»›i. Ráº¥t cÃ¡m Æ¡n.,,,,,
"I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Em chÃ o má»i ngÆ°á»i , em Ä‘ang há»c vá» ML cÆ¡ báº£n , thÃ¬ há»c tá»›i Binary Classification , TensorFlow láº¡i bÃ¡o lá»—i nhÆ° nÃ y áº¡. 
TrÃªn Colab thÃ¬ nÃ³ cháº¡y bthg nhma trÃªn mÃ¡y em láº¡i bá»‹ lá»—i nhÆ° trÃªn áº¡

Mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡","I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX AVX2 To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. Em chÃ o má»i ngÆ°á»i , em Ä‘ang há»c vá» ML cÆ¡ báº£n , thÃ¬ há»c tá»›i Binary Classification , TensorFlow láº¡i bÃ¡o lá»—i nhÆ° nÃ y áº¡. TrÃªn Colab thÃ¬ nÃ³ cháº¡y bthg nhma trÃªn mÃ¡y em láº¡i bá»‹ lá»—i nhÆ° trÃªn áº¡ Mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡",,,,,
"MÃ¬nh chia sáº» slides vá» thuáº­t toÃ¡n gradient descent trong há»c mÃ¡y mÃ  mÃ¬nh Ä‘ang dáº¡y á»Ÿ Má»¹ táº¡i Ä‘Ã¢y: https://nhatptnk8912.github.io/Gradient_Descent...
Máº·c dÃ¹ thuáº­t toÃ¡n gradient descent Ä‘Ã£ quÃ¡ quen thuá»™c vá»›i má»i ngÆ°á»i; tuy nhiÃªn nhá»¯ng gÃ¬ chÃºng ta hiá»ƒu gÃ¬ thuáº­t toÃ¡n nÃ y cÃ²n nhiá»u háº¡n cháº¿, Ä‘áº·c biá»‡t khi chÃºng ta nÃ³i vá» ngá»¯ cáº£nh cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y. Trong bÃ i giáº£ng, mÃ¬nh cÅ©ng thÃªm vÃ o nhiá»u káº¿t quáº£ nghiÃªn cá»©u gáº§n Ä‘Ã¢y cá»§a thuáº­t toÃ¡n nÃ y vÃ  nhá»¯ng váº¥n Ä‘á» má»Ÿ cá»§a nÃ³. Trong bÃ i giáº£ng sau (mÃ¬nh cÅ©ng sáº½ upload lÃªn trang homepage cÃ¡ nhÃ¢n), mÃ¬nh sáº½ Ä‘Æ°a ra má»™t sá»‘ insight tá»« cÃ¡c cÃ´ng trÃ¬nh nghiÃªn cá»©u gáº§n Ä‘Ã¢y cá»§a báº£n thÃ¢n Ä‘á»ƒ lÃ m sao giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» cá»§a gradient descent.
Do Ä‘Ã¢y lÃ  lá»›p cho sinh viÃªn tiáº¿n sÄ©/ tháº¡c sÄ© nÃªn lÆ°á»£ng kiáº¿n thá»©c trong bÃ i giáº£ng khÃ¡ nhiá»u. CÃ¡c báº¡n nÃ o Ä‘Ã£ há»c qua cÃ¡c lá»›p cÆ¡ báº£n vÃ  muá»‘n Ä‘i sÃ¢u vÃ o há»c mÃ¡y thÃ¬ cÃ³ thá»ƒ Ä‘á»c.","MÃ¬nh chia sáº» slides vá» thuáº­t toÃ¡n gradient descent trong há»c mÃ¡y mÃ  mÃ¬nh Ä‘ang dáº¡y á»Ÿ Má»¹ táº¡i Ä‘Ã¢y: https://nhatptnk8912.github.io/Gradient_Descent... Máº·c dÃ¹ thuáº­t toÃ¡n gradient descent Ä‘Ã£ quÃ¡ quen thuá»™c vá»›i má»i ngÆ°á»i; tuy nhiÃªn nhá»¯ng gÃ¬ chÃºng ta hiá»ƒu gÃ¬ thuáº­t toÃ¡n nÃ y cÃ²n nhiá»u háº¡n cháº¿, Ä‘áº·c biá»‡t khi chÃºng ta nÃ³i vá» ngá»¯ cáº£nh cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y. Trong bÃ i giáº£ng, mÃ¬nh cÅ©ng thÃªm vÃ o nhiá»u káº¿t quáº£ nghiÃªn cá»©u gáº§n Ä‘Ã¢y cá»§a thuáº­t toÃ¡n nÃ y vÃ  nhá»¯ng váº¥n Ä‘á» má»Ÿ cá»§a nÃ³. Trong bÃ i giáº£ng sau (mÃ¬nh cÅ©ng sáº½ upload lÃªn trang homepage cÃ¡ nhÃ¢n), mÃ¬nh sáº½ Ä‘Æ°a ra má»™t sá»‘ insight tá»« cÃ¡c cÃ´ng trÃ¬nh nghiÃªn cá»©u gáº§n Ä‘Ã¢y cá»§a báº£n thÃ¢n Ä‘á»ƒ lÃ m sao giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» cá»§a gradient descent. Do Ä‘Ã¢y lÃ  lá»›p cho sinh viÃªn tiáº¿n sÄ©/ tháº¡c sÄ© nÃªn lÆ°á»£ng kiáº¿n thá»©c trong bÃ i giáº£ng khÃ¡ nhiá»u. CÃ¡c báº¡n nÃ o Ä‘Ã£ há»c qua cÃ¡c lá»›p cÆ¡ báº£n vÃ  muá»‘n Ä‘i sÃ¢u vÃ o há»c mÃ¡y thÃ¬ cÃ³ thá»ƒ Ä‘á»c.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, nhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u vá» YOLOv7 em máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¡ch train YOLOv7, nháº­n diá»‡n YOLv7 nhanh báº±ng cÃ¡ch ""táº­n dá»¥ng"" GPU cá»§a Colab cÃ¹ng cÃ¡c báº¡n má»›i há»c.
Xin cáº£m Æ¡n cáº£ nhÃ !","KÃ­nh chÃ o cÃ¡c bÃ¡c, nhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u vá» YOLOv7 em máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¡ch train YOLOv7, nháº­n diá»‡n YOLv7 nhanh báº±ng cÃ¡ch ""táº­n dá»¥ng"" GPU cá»§a Colab cÃ¹ng cÃ¡c báº¡n má»›i há»c. Xin cáº£m Æ¡n cáº£ nhÃ !",,,,,
"ChÃ o má»i ngÆ°á»i áº¡
M.n trong nhÃ³m ai Ä‘Ã£ tá»«ng lÃ m mÃ´ hÃ¬nh Mask RCNN trÃªn Net framework 4.7.x hoáº·c chuyá»ƒn model mask qua ONNX Ä‘á»ƒ triá»ƒn khai trÃªn Net framework cÃ³ thá»ƒ cho em xin Ã­t kinh nghiá»‡m hoáº·c cÃ¡c hÆ°á»›ng dáº«n Ä‘á»ƒ triá»ƒn khai Ä‘Æ°á»£c khÃ´ng áº¡.
Em xin Ä‘Æ°á»£c gá»­i há»c phÃ­ náº¿u cÃ³ áº¡.
Thanks m.n.",ChÃ o má»i ngÆ°á»i áº¡ M.n trong nhÃ³m ai Ä‘Ã£ tá»«ng lÃ m mÃ´ hÃ¬nh Mask RCNN trÃªn Net framework 4.7.x hoáº·c chuyá»ƒn model mask qua ONNX Ä‘á»ƒ triá»ƒn khai trÃªn Net framework cÃ³ thá»ƒ cho em xin Ã­t kinh nghiá»‡m hoáº·c cÃ¡c hÆ°á»›ng dáº«n Ä‘á»ƒ triá»ƒn khai Ä‘Æ°á»£c khÃ´ng áº¡. Em xin Ä‘Æ°á»£c gá»­i há»c phÃ­ náº¿u cÃ³ áº¡. Thanks m.n.,,,,,
"VinAI - AI Day 2022 - 26, 27 Aug 2022
ğŸ’¥Tutorial Zone at AI Day 2022ğŸ’¥
ğŸš€An opportunity to learn from VinAIâ€™s Best and Brightest Minds in the Tutorial Zone!ğŸš€
Registration Link: please see below.","VinAI - AI Day 2022 - 26, 27 Aug 2022 Tutorial Zone at AI Day 2022 An opportunity to learn from VinAIâ€™s Best and Brightest Minds in the Tutorial Zone! Registration Link: please see below.",,,,,
"Em chÃ o mn!
Em Ä‘ang train mÃ´ hÃ¬nh, em cÃ³ Ä‘Ã¡nh giÃ¡ trÃªn cáº£ táº­p train vÃ  test theo AUC.
Em Ä‘ang gáº·p má»™t váº¥n Ä‘á» lÃ  nhÃ£n 1 thá»±c táº¿ cá»§a táº­p test lÃ  gáº§n 300, nhÆ°ng khi predict mÃ´ hÃ¬nh chá»‰ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c 6 nhÃ£n 1.
Em Ä‘Ã£ kiá»ƒm tra phÃ¢n phá»‘i cá»§a cÃ¡c pred = 0 cÅ©ng khÃ´ng khÃ¡c nhiá»u so vá»›i pred = 1.
Nhá» mn giáº£i thÃ­ch giÃºp em, em Ä‘ang gáº·p lá»—i gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡?
Em cáº£m Æ¡n mn!","Em chÃ o mn! Em Ä‘ang train mÃ´ hÃ¬nh, em cÃ³ Ä‘Ã¡nh giÃ¡ trÃªn cáº£ táº­p train vÃ  test theo AUC. Em Ä‘ang gáº·p má»™t váº¥n Ä‘á» lÃ  nhÃ£n 1 thá»±c táº¿ cá»§a táº­p test lÃ  gáº§n 300, nhÆ°ng khi predict mÃ´ hÃ¬nh chá»‰ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c 6 nhÃ£n 1. Em Ä‘Ã£ kiá»ƒm tra phÃ¢n phá»‘i cá»§a cÃ¡c pred = 0 cÅ©ng khÃ´ng khÃ¡c nhiá»u so vá»›i pred = 1. Nhá» mn giáº£i thÃ­ch giÃºp em, em Ä‘ang gáº·p lá»—i gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n mn!",,,,,
"Em Ä‘ang lÃ m bÃ i toÃ¡n id card vÃ  Ä‘Ã£ detect ra Ä‘Æ°á»£c nhá»¯ng thÃ´ng tin cáº§n thiáº¿t tuy nhiÃªn chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n nháº­n dáº¡ng vÄƒn báº£n tiáº¿ng Viá»‡t.
Ráº¥t mong má»i ngÆ°á»i chia sáº» cho em Ã­t tÃ i liá»‡u tham kháº£o vá»›i áº¡....
Em Ä‘ang lÃ m vá»›i bá»™ thÆ° viá»‡n tesseract thÃ¬ káº¿t quáº£ chÆ°a Ä‘c nhÆ° Ã½.",Em Ä‘ang lÃ m bÃ i toÃ¡n id card vÃ  Ä‘Ã£ detect ra Ä‘Æ°á»£c nhá»¯ng thÃ´ng tin cáº§n thiáº¿t tuy nhiÃªn chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n nháº­n dáº¡ng vÄƒn báº£n tiáº¿ng Viá»‡t. Ráº¥t mong má»i ngÆ°á»i chia sáº» cho em Ã­t tÃ i liá»‡u tham kháº£o vá»›i áº¡.... Em Ä‘ang lÃ m vá»›i bá»™ thÆ° viá»‡n tesseract thÃ¬ káº¿t quáº£ chÆ°a Ä‘c nhÆ° Ã½.,,,,,
"xin chÃ o má»i ngÆ°á»i vÃ  anh Tiá»‡p, em Ä‘ang convert model tá»« onnx -> tflite theo git nÃ y: https://github.com/sithu31296/PyTorch-ONNX-TFLite mÃ  láº¡i gáº·p lá»—i dÆ°á»›i, em Ä‘Ã£ search vÃ  thá»­ nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau mÃ  váº«n chÆ°a fix Ä‘c. mn ai Ä‘Ã£ tá»«ng cÃ³ kinh nghiá»‡m giÃºp em vá»›i áº¡!","xin chÃ o má»i ngÆ°á»i vÃ  anh Tiá»‡p, em Ä‘ang convert model tá»« onnx -> tflite theo git nÃ y: https://github.com/sithu31296/PyTorch-ONNX-TFLite mÃ  láº¡i gáº·p lá»—i dÆ°á»›i, em Ä‘Ã£ search vÃ  thá»­ nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau mÃ  váº«n chÆ°a fix Ä‘c. mn ai Ä‘Ã£ tá»«ng cÃ³ kinh nghiá»‡m giÃºp em vá»›i áº¡!",,,,,
"ThÆ°a anh chá»‹, em hiá»‡n Ä‘ang cÃ³ váº¥n Ä‘á» nÃ y. Hiá»‡n táº¡i em Ä‘Ã£ cÃ³ file Ä‘áº§u vÃ o lÃ  dá»¯ liá»‡u cÃ¡c file speech to text vá» ná»™i dung cÃ´ng viá»‡c. File nÃ y thÃ¬ Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ¡n ngÆ°á»i giao viá»‡c, vá»›i content cÃ´ng viá»‡c. Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ³ thá»ƒ trÃ­ch xuáº¥t ra ngÆ°á»i Ä‘Æ°á»£c giao viá»‡c vá»›i ná»™i dung cÃ´ng viá»‡c Ä‘Ã³. KhÃ´ng biáº¿t cÃ³ ai Ä‘Ã£ tá»«ng lÃ m bÃ i toÃ¡n nÃ y chÆ°a áº¡ hay cÃ³ tÃ i liá»‡u nÃ o cÃ³ thá»ƒ Ä‘Æ°a giÃºp em tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡ . BÃ i toÃ¡n dÃ¹ng cho tiáº¿ng viá»‡t áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u","ThÆ°a anh chá»‹, em hiá»‡n Ä‘ang cÃ³ váº¥n Ä‘á» nÃ y. Hiá»‡n táº¡i em Ä‘Ã£ cÃ³ file Ä‘áº§u vÃ o lÃ  dá»¯ liá»‡u cÃ¡c file speech to text vá» ná»™i dung cÃ´ng viá»‡c. File nÃ y thÃ¬ Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ¡n ngÆ°á»i giao viá»‡c, vá»›i content cÃ´ng viá»‡c. Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ³ thá»ƒ trÃ­ch xuáº¥t ra ngÆ°á»i Ä‘Æ°á»£c giao viá»‡c vá»›i ná»™i dung cÃ´ng viá»‡c Ä‘Ã³. KhÃ´ng biáº¿t cÃ³ ai Ä‘Ã£ tá»«ng lÃ m bÃ i toÃ¡n nÃ y chÆ°a áº¡ hay cÃ³ tÃ i liá»‡u nÃ o cÃ³ thá»ƒ Ä‘Æ°a giÃºp em tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡ . BÃ i toÃ¡n dÃ¹ng cho tiáº¿ng viá»‡t áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u",,,,,
"Xin chÃ o. MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu GNN Ä‘á»ƒ Ã¡p dá»¥ng cho 1 bÃ i toÃ¡n cá»§a mÃ¬nh. Cá»¥ thá»ƒ lÃ  mÃ¬nh cÃ³ ráº¥t nhiá»u small knowledge graph (nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m), vÃ  mÃ¬nh muá»‘n sinh ra embedding vector cho tá»«ng graph Ä‘Ã³. VÃ¬ cÃ¡c nodes/edges trong knowledge graph cÃ³ nhÃ£n (textual label) nÃªn mÃ¬nh sáº½ dÃ¹ng 1 sentence embedding model Ä‘á»ƒ sinh embedding features cho cÃ¡c nodes/edges, sau Ä‘Ã³ dÃ¹ng má»™t mÃ´ hÃ¬nh GNN nÃ o Ä‘Ã³ Ä‘á»ƒ sinh ra graph vector representation. Minh thá»­ tÃ¬m trong PyG (PyTorch Geometric) nhÆ°ng chÆ°a tháº¥y vÃ­ dá»¥ nhÆ° mong muá»‘n. CÃ¡c báº¡n cÃ³ ai biáº¿t thÆ° viá»‡n nÃ o há»— trá»£ cÃ¡ch lÃ m nhÆ° váº­y khÃ´ng? Náº¿u cÃ³ thá»ƒ, nhá» báº¡n tÆ° váº¥n giÃºp xem mÃ¬nh nÃªn lÃ m nhÆ° tháº¿ nÃ o cho bÃ i toÃ¡n nÃ y. Thanks","Xin chÃ o. MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu GNN Ä‘á»ƒ Ã¡p dá»¥ng cho 1 bÃ i toÃ¡n cá»§a mÃ¬nh. Cá»¥ thá»ƒ lÃ  mÃ¬nh cÃ³ ráº¥t nhiá»u small knowledge graph (nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m), vÃ  mÃ¬nh muá»‘n sinh ra embedding vector cho tá»«ng graph Ä‘Ã³. VÃ¬ cÃ¡c nodes/edges trong knowledge graph cÃ³ nhÃ£n (textual label) nÃªn mÃ¬nh sáº½ dÃ¹ng 1 sentence embedding model Ä‘á»ƒ sinh embedding features cho cÃ¡c nodes/edges, sau Ä‘Ã³ dÃ¹ng má»™t mÃ´ hÃ¬nh GNN nÃ o Ä‘Ã³ Ä‘á»ƒ sinh ra graph vector representation. Minh thá»­ tÃ¬m trong PyG (PyTorch Geometric) nhÆ°ng chÆ°a tháº¥y vÃ­ dá»¥ nhÆ° mong muá»‘n. CÃ¡c báº¡n cÃ³ ai biáº¿t thÆ° viá»‡n nÃ o há»— trá»£ cÃ¡ch lÃ m nhÆ° váº­y khÃ´ng? Náº¿u cÃ³ thá»ƒ, nhá» báº¡n tÆ° váº¥n giÃºp xem mÃ¬nh nÃªn lÃ m nhÆ° tháº¿ nÃ o cho bÃ i toÃ¡n nÃ y. Thanks",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡,
Em Ä‘ang Ä‘á»c má»™t bÃ i bÃ¡o vá» dÃ¹ng ML Ä‘á»ƒ predict student performance [1]. Em Ä‘á»c Ä‘áº¿n cÃ´ng thá»©c tÃ­nh thÃ¬ cÃ³ má»™t cÃ¡i annotation chÆ°a hiá»ƒu láº¯m, em cÃ³ Ä‘Ã¡nh dáº¥u trong hÃ¬nh áº¡. CÃ´ng thá»©c thÃ¬ em hiá»ƒu rá»“i nhÆ°ng chá»¯ GPA cÃ¡i mÅ© cÃ³ nghÄ©a lÃ  gÃ¬ áº¡, tá»©c lÃ  cÃ³ mÅ© nÃ³ khÃ¡c gÃ¬ khÃ´ng cÃ³ mÅ© áº¡.
Em cÃ¡m Æ¡n má»i ngÆ°á»i áº¡.
[1] Jie, Kyeong, Mihaela, A Machine Learning Approach for Tracking and Predicting Student Performance in Degree Programs","Em chÃ o má»i ngÆ°á»i áº¡, Em Ä‘ang Ä‘á»c má»™t bÃ i bÃ¡o vá» dÃ¹ng ML Ä‘á»ƒ predict student performance [1]. Em Ä‘á»c Ä‘áº¿n cÃ´ng thá»©c tÃ­nh thÃ¬ cÃ³ má»™t cÃ¡i annotation chÆ°a hiá»ƒu láº¯m, em cÃ³ Ä‘Ã¡nh dáº¥u trong hÃ¬nh áº¡. CÃ´ng thá»©c thÃ¬ em hiá»ƒu rá»“i nhÆ°ng chá»¯ GPA cÃ¡i mÅ© cÃ³ nghÄ©a lÃ  gÃ¬ áº¡, tá»©c lÃ  cÃ³ mÅ© nÃ³ khÃ¡c gÃ¬ khÃ´ng cÃ³ mÅ© áº¡. Em cÃ¡m Æ¡n má»i ngÆ°á»i áº¡. [1] Jie, Kyeong, Mihaela, A Machine Learning Approach for Tracking and Predicting Student Performance in Degree Programs",,,,,
"Em lÃ  ma má»›i, e Ä‘ang cÃ³ bÃ i táº­p cáº§n train mÃ´ hÃ¬nh, em muá»‘n dÃ¹ng google colab nhÆ°ng data láº¡i á»Ÿ onedrive, cho em há»i láº¥y dá»¯ liá»‡u tá»« onedrive sang colab kiá»ƒu gÃ¬ áº¡, hay pháº£i up qua google drive, mÃ  dung lÆ°á»£ng gmail cá»§a em khÃ´ng Ä‘á»§ (T_T)","Em lÃ  ma má»›i, e Ä‘ang cÃ³ bÃ i táº­p cáº§n train mÃ´ hÃ¬nh, em muá»‘n dÃ¹ng google colab nhÆ°ng data láº¡i á»Ÿ onedrive, cho em há»i láº¥y dá»¯ liá»‡u tá»« onedrive sang colab kiá»ƒu gÃ¬ áº¡, hay pháº£i up qua google drive, mÃ  dung lÆ°á»£ng gmail cá»§a em khÃ´ng Ä‘á»§ (T_T)",,,,,
"[KhÃ³a há»c miá»…n phÃ­ MLOps]
Nay mÃ¬nh chia sáº» vá»›i cÃ¡c báº¡n khÃ³a há»c ráº¥t hay vÃ  chi tiáº¿t vá» MLOps. KhÃ³a há»c nÃ y dáº¡y má»i thá»© liÃªn quan Ä‘áº¿n MLOps tá»« thiáº¿t káº¿, mÃ´ hÃ¬nh hÃ³a Ä‘áº¿n kiá»ƒm thá»­ vÃ  triá»ƒn khai mÃ´ hÃ¬nh Machine Learning.
Chi tiáº¿t khÃ³a há»c xem á»Ÿ Ä‘Ã¢y: https://madewithml.com/#mlops","[KhÃ³a há»c miá»…n phÃ­ MLOps] Nay mÃ¬nh chia sáº» vá»›i cÃ¡c báº¡n khÃ³a há»c ráº¥t hay vÃ  chi tiáº¿t vá» MLOps. KhÃ³a há»c nÃ y dáº¡y má»i thá»© liÃªn quan Ä‘áº¿n MLOps tá»« thiáº¿t káº¿, mÃ´ hÃ¬nh hÃ³a Ä‘áº¿n kiá»ƒm thá»­ vÃ  triá»ƒn khai mÃ´ hÃ¬nh Machine Learning. Chi tiáº¿t khÃ³a há»c xem á»Ÿ Ä‘Ã¢y: https://madewithml.com/#mlops",,,,,
"[GÃ³c chia sáº» - AI Webinar 2022 ]
Xin chÃ o má»i ngÆ°á»i,
Xin phÃ©p chia sáº» vá»›i má»i ngÆ°á»i má»™t webinar vá» AI sáº¯p diá»…n ra mÃ  mÃ¬nh cáº£m tháº¥y khÃ¡ háº¥p dáº«n. Sá»± kiá»‡n cÃ³ sá»± tham gia cá»§a cÃ¡c speaker lÃ  cÃ¡c Vice President, Director of AI, Chief Data, C-level trong ngÃ nh Ä‘áº¿n tá»« cÃ¡c tÃªn tuá»•i lá»›n nhÆ° Google, Microsoft, Mercedes-Benz, AWS, Volkswagen, IBM, SAP, Samsung SDS, Oxford, vÃ  cÃ¡c cÃ´ng ty táº­p Ä‘oÃ n lá»›n tá»« kháº¯p 5 chÃ¢u.
Má»i ngÆ°á»i ai cÃ³ há»©ng thÃº Ä‘á»u cÃ³ thá»ƒ Ä‘Äƒng kÃ½ vÃ¬ nÃ³ hoÃ n toÃ n miá»…n phÃ­, Ä‘Æ°á»£c giao lÆ°u trá»±c tiáº¿p vá»›i diá»…n giáº£ vÃ  Ä‘Æ°á»£c káº¿t ná»‘i vá»›i cá»™ng Ä‘á»“ng AI tá»« kháº¯p nÆ¡i trÃªn tháº¿ giá»›i.
Máº·c dÃ¹ cÃ³ ráº¥t nhiá»u sá»± kiá»‡n tráº£ phÃ­ trÃªn máº¡ng, nhÆ°ng Worldwide AI Webinar (https://wow-ai.com/event) khÃ´ng chá»‰ MIá»„N PHÃ mÃ  cÃ²n mang Ä‘áº¿n cho báº¡n cÆ¡ há»™i giÃ nh Ä‘Æ°á»£c tá»›i 10.000 USD tiá»n máº·t chá»‰ báº±ng cÃ¡ch há»i nhá»¯ng ngÆ°á»i thuyáº¿t trÃ¬nh thÃº vá»‹. cÃ¡c cÃ¢u há»i. TÃ´i vá»«a nháº­n Ä‘Æ°á»£c thÃ´ng tin nÃ y hÃ´m nay vÃ  tÃ´i muá»‘n chia sáº» vá»›i báº¡n lá»±a chá»n nÃ y.
Trong má»—i phiÃªn, báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch tÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p vá»›i cÃ¡c diá»…n giáº£ chÃ­nh báº±ng cÃ¡ch há»i há» nhá»¯ng cÃ¢u há»i thÃº vá»‹. VÃ o cuá»‘i má»—i phiÃªn, cÃ¡c diá»…n giáº£ chÃ­nh sáº½ quyáº¿t Ä‘á»‹nh cÃ¢u há»i nÃ o mÃ  há» cho lÃ  thÃº vá»‹ nháº¥t. NgÆ°á»i tháº¯ng cuá»™c sáº½ nháº­n Ä‘Æ°á»£c pháº§n thÆ°á»Ÿng báº±ng tiá»n máº·t ngay sau sá»± kiá»‡n.
Giáº£i thÆ°á»Ÿng:
â€¢ 300 USD cho má»—i ngÆ°á»i chiáº¿n tháº¯ng trong má»—i buá»•i phÃ¡t biá»ƒu quan trá»ng
â€¢ 500 USD cho má»—i ngÆ°á»i chiáº¿n tháº¯ng trong má»—i phiÃªn há»™i tháº£o
ÄÃ¢y lÃ  liÃªn káº¿t Ä‘á»ƒ Ä‘Äƒng kÃ½:
https://meetyoo.live/register/1/worldwideAI2022","[GÃ³c chia sáº» - AI Webinar 2022 ] Xin chÃ o má»i ngÆ°á»i, Xin phÃ©p chia sáº» vá»›i má»i ngÆ°á»i má»™t webinar vá» AI sáº¯p diá»…n ra mÃ  mÃ¬nh cáº£m tháº¥y khÃ¡ háº¥p dáº«n. Sá»± kiá»‡n cÃ³ sá»± tham gia cá»§a cÃ¡c speaker lÃ  cÃ¡c Vice President, Director of AI, Chief Data, C-level trong ngÃ nh Ä‘áº¿n tá»« cÃ¡c tÃªn tuá»•i lá»›n nhÆ° Google, Microsoft, Mercedes-Benz, AWS, Volkswagen, IBM, SAP, Samsung SDS, Oxford, vÃ  cÃ¡c cÃ´ng ty táº­p Ä‘oÃ n lá»›n tá»« kháº¯p 5 chÃ¢u. Má»i ngÆ°á»i ai cÃ³ há»©ng thÃº Ä‘á»u cÃ³ thá»ƒ Ä‘Äƒng kÃ½ vÃ¬ nÃ³ hoÃ n toÃ n miá»…n phÃ­, Ä‘Æ°á»£c giao lÆ°u trá»±c tiáº¿p vá»›i diá»…n giáº£ vÃ  Ä‘Æ°á»£c káº¿t ná»‘i vá»›i cá»™ng Ä‘á»“ng AI tá»« kháº¯p nÆ¡i trÃªn tháº¿ giá»›i. Máº·c dÃ¹ cÃ³ ráº¥t nhiá»u sá»± kiá»‡n tráº£ phÃ­ trÃªn máº¡ng, nhÆ°ng Worldwide AI Webinar (https://wow-ai.com/event) khÃ´ng chá»‰ MIá»„N PHÃ mÃ  cÃ²n mang Ä‘áº¿n cho báº¡n cÆ¡ há»™i giÃ nh Ä‘Æ°á»£c tá»›i 10.000 USD tiá»n máº·t chá»‰ báº±ng cÃ¡ch há»i nhá»¯ng ngÆ°á»i thuyáº¿t trÃ¬nh thÃº vá»‹. cÃ¡c cÃ¢u há»i. TÃ´i vá»«a nháº­n Ä‘Æ°á»£c thÃ´ng tin nÃ y hÃ´m nay vÃ  tÃ´i muá»‘n chia sáº» vá»›i báº¡n lá»±a chá»n nÃ y. Trong má»—i phiÃªn, báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch tÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p vá»›i cÃ¡c diá»…n giáº£ chÃ­nh báº±ng cÃ¡ch há»i há» nhá»¯ng cÃ¢u há»i thÃº vá»‹. VÃ o cuá»‘i má»—i phiÃªn, cÃ¡c diá»…n giáº£ chÃ­nh sáº½ quyáº¿t Ä‘á»‹nh cÃ¢u há»i nÃ o mÃ  há» cho lÃ  thÃº vá»‹ nháº¥t. NgÆ°á»i tháº¯ng cuá»™c sáº½ nháº­n Ä‘Æ°á»£c pháº§n thÆ°á»Ÿng báº±ng tiá»n máº·t ngay sau sá»± kiá»‡n. Giáº£i thÆ°á»Ÿng: â€¢ 300 USD cho má»—i ngÆ°á»i chiáº¿n tháº¯ng trong má»—i buá»•i phÃ¡t biá»ƒu quan trá»ng â€¢ 500 USD cho má»—i ngÆ°á»i chiáº¿n tháº¯ng trong má»—i phiÃªn há»™i tháº£o ÄÃ¢y lÃ  liÃªn káº¿t Ä‘á»ƒ Ä‘Äƒng kÃ½: https://meetyoo.live/register/1/worldwideAI2022",,,,,
"ChÃ o má»i ngÆ°á»i
Em Ä‘ang thá»±c hiá»‡n má»™t PJ nhá» á»Ÿ THPT vá» ML , em cÃ³ tháº¯c máº¯c lÃ  mÃ¬nh cÃ³ má»™t cÄƒn nhÃ  vÃ  N tá»a Ä‘á»™ GPS cá»§a N phÃ²ng thÃ¬ mÃ¬nh pháº£i thá»±c hiá»‡n nhÆ° tháº¿ nÃ o Ä‘á»ƒ cho ML cÃ³ thá»ƒ di chuyá»ƒn tá»›i cÄƒn phÃ²ng mÃ¬nh mong muá»‘n. Em cÃ³ Ã½ Ä‘á»‹nh lÃ  cÃ i Ä‘áº·t sáºµn Ä‘Æ°á»ng Ä‘i cho tá»«ng cÄƒn phÃ²ng , nhma nhÆ° váº­y vá»›i má»™t tÃ²a nhÃ  lá»›n hÆ¡n thÃ¬ lÃ m nhÆ° váº­y khÃ¡ lÃ¢u. Em thá»­ Ä‘á»•i qua Mapping nhÆ°ng láº¡i k biáº¿t tÃ¬m hiá»ƒu tá»« Ä‘Ã¢u , má»i ngÆ°á»i cÃ³ thá»ƒ cho em tÃ i liá»‡u hay lÃ  cÃ¡c nguá»“n Ä‘á»ƒ em cÃ³ thá»ƒ tÃ¬m hiá»ƒu vá» Mapping Ä‘Æ°á»£c khÃ´ng áº¡","ChÃ o má»i ngÆ°á»i Em Ä‘ang thá»±c hiá»‡n má»™t PJ nhá» á»Ÿ THPT vá» ML , em cÃ³ tháº¯c máº¯c lÃ  mÃ¬nh cÃ³ má»™t cÄƒn nhÃ  vÃ  N tá»a Ä‘á»™ GPS cá»§a N phÃ²ng thÃ¬ mÃ¬nh pháº£i thá»±c hiá»‡n nhÆ° tháº¿ nÃ o Ä‘á»ƒ cho ML cÃ³ thá»ƒ di chuyá»ƒn tá»›i cÄƒn phÃ²ng mÃ¬nh mong muá»‘n. Em cÃ³ Ã½ Ä‘á»‹nh lÃ  cÃ i Ä‘áº·t sáºµn Ä‘Æ°á»ng Ä‘i cho tá»«ng cÄƒn phÃ²ng , nhma nhÆ° váº­y vá»›i má»™t tÃ²a nhÃ  lá»›n hÆ¡n thÃ¬ lÃ m nhÆ° váº­y khÃ¡ lÃ¢u. Em thá»­ Ä‘á»•i qua Mapping nhÆ°ng láº¡i k biáº¿t tÃ¬m hiá»ƒu tá»« Ä‘Ã¢u , má»i ngÆ°á»i cÃ³ thá»ƒ cho em tÃ i liá»‡u hay lÃ  cÃ¡c nguá»“n Ä‘á»ƒ em cÃ³ thá»ƒ tÃ¬m hiá»ƒu vá» Mapping Ä‘Æ°á»£c khÃ´ng áº¡",,,,,
"[Update â€“ Worldwide AI Webinar 2022]
ChÃ o má»i ngÆ°á»i,
Cháº¯c má»i ngÆ°á»i Ä‘Ã£ xem qua cÃ¡c bÃ i viáº¿t vá» Worldwide AI Webinar cÅ©ng nhÆ° Ä‘Ã£ tá»«ng tham gia vÃ o má»™t sá»‘ webinar vá» AI khÃ¡c. Do hÃ´m nay mÃ¬nh vá»«a nháº­n Ä‘Æ°á»£c thÃ´ng tin má»›i tá»« phÃ­a host vÃ  tháº¥y khÃ¡ hay nÃªn muá»‘n chia sáº» láº¡i vá»›i má»i ngÆ°á»i.
Theo nhÆ° ban tá»• chá»©c, webinar láº§n nÃ y vá»«a lÃ  cÆ¡ há»™i miá»…n phÃ­ Ä‘á»ƒ má»i ngÆ°á»i há»c táº­p mÃ  vá»«a cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c pháº§n thÆ°á»Ÿng báº±ng cÃ¡ch Ä‘áº·t ra cÃ¢u há»i cho cÃ¡c speaker, tá»•ng giÃ¡ trá»‹ lÃªn tá»›i 10,000 USD. Cá»¥ thá»ƒ lÃ  á»Ÿ má»—i live session, thÃ­nh giáº£ Ä‘Æ°á»£c khuyáº¿n khÃ­ch tÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p vá»›i speaker vÃ  Ä‘Æ°a ra cÃ¡c cÃ¢u há»i hay vÃ  khÃ³ vá» chá»§ Ä‘á» AI/ML trong doanh nghiá»‡p. Cuá»‘i má»—i session, speaker sáº½ chá»n ra cÃ¢u há»i há» cho lÃ  háº¥p dáº«n nháº¥t vÃ  giáº£i thÆ°á»Ÿng 300 â€“ 500 USD sáº½ Ä‘Æ°á»£c trao cho ngÆ°á»i chiáº¿n tháº¯ng (tiá»n máº·t Ä‘Æ°á»£c trao sau event).
Sá»± kiá»‡n free mÃ  cÃ²n Ä‘Æ°á»£c nháº­n tiá»n ğŸ˜. Má»i ngÆ°á»i xem thÃªm thÃ´ng tin táº¡i Ä‘Ã¢y: https://event.wow-ai.com/worldwideAI2022/","[Update â€“ Worldwide AI Webinar 2022] ChÃ o má»i ngÆ°á»i, Cháº¯c má»i ngÆ°á»i Ä‘Ã£ xem qua cÃ¡c bÃ i viáº¿t vá» Worldwide AI Webinar cÅ©ng nhÆ° Ä‘Ã£ tá»«ng tham gia vÃ o má»™t sá»‘ webinar vá» AI khÃ¡c. Do hÃ´m nay mÃ¬nh vá»«a nháº­n Ä‘Æ°á»£c thÃ´ng tin má»›i tá»« phÃ­a host vÃ  tháº¥y khÃ¡ hay nÃªn muá»‘n chia sáº» láº¡i vá»›i má»i ngÆ°á»i. Theo nhÆ° ban tá»• chá»©c, webinar láº§n nÃ y vá»«a lÃ  cÆ¡ há»™i miá»…n phÃ­ Ä‘á»ƒ má»i ngÆ°á»i há»c táº­p mÃ  vá»«a cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c pháº§n thÆ°á»Ÿng báº±ng cÃ¡ch Ä‘áº·t ra cÃ¢u há»i cho cÃ¡c speaker, tá»•ng giÃ¡ trá»‹ lÃªn tá»›i 10,000 USD. Cá»¥ thá»ƒ lÃ  á»Ÿ má»—i live session, thÃ­nh giáº£ Ä‘Æ°á»£c khuyáº¿n khÃ­ch tÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p vá»›i speaker vÃ  Ä‘Æ°a ra cÃ¡c cÃ¢u há»i hay vÃ  khÃ³ vá» chá»§ Ä‘á» AI/ML trong doanh nghiá»‡p. Cuá»‘i má»—i session, speaker sáº½ chá»n ra cÃ¢u há»i há» cho lÃ  háº¥p dáº«n nháº¥t vÃ  giáº£i thÆ°á»Ÿng 300 â€“ 500 USD sáº½ Ä‘Æ°á»£c trao cho ngÆ°á»i chiáº¿n tháº¯ng (tiá»n máº·t Ä‘Æ°á»£c trao sau event). Sá»± kiá»‡n free mÃ  cÃ²n Ä‘Æ°á»£c nháº­n tiá»n . Má»i ngÆ°á»i xem thÃªm thÃ´ng tin táº¡i Ä‘Ã¢y: https://event.wow-ai.com/worldwideAI2022/",,,,,
"QuÃ¡ trÃ¬nh phÃ¡t triá»ƒn cÃ¡c sáº£n pháº©m AI luÃ´n tá»“n táº¡i nhá»¯ng thÃ¡ch thá»©c. Má»i cÃ¡c báº¡n theo dÃµi sá»± kiá»‡n Ä‘á»ƒ láº¯ng nghe chia sáº» tá»« chuyÃªn gia hÃ ng Ä‘áº§u vá» AI/Machine Learning/Data Scientist trong talkshow AI production challenge Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi cÃ´ng ty Neurond vÃ  tá»• chá»©c bá»Ÿi DataScienceWorld.Kan.

Thá»i gian tá»« 10:45 AM-12:00 AM ngÃ y 21-August-2022
- live stream youtube:
https://youtu.be/02FCIk8anVo
- link Ä‘áº·t cÃ¢u há»i:
https://forms.gle/igM4mncYFcjDhV1W6",QuÃ¡ trÃ¬nh phÃ¡t triá»ƒn cÃ¡c sáº£n pháº©m AI luÃ´n tá»“n táº¡i nhá»¯ng thÃ¡ch thá»©c. Má»i cÃ¡c báº¡n theo dÃµi sá»± kiá»‡n Ä‘á»ƒ láº¯ng nghe chia sáº» tá»« chuyÃªn gia hÃ ng Ä‘áº§u vá» AI/Machine Learning/Data Scientist trong talkshow AI production challenge Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi cÃ´ng ty Neurond vÃ  tá»• chá»©c bá»Ÿi DataScienceWorld.Kan. Thá»i gian tá»« 10:45 AM-12:00 AM ngÃ y 21-August-2022 - live stream youtube: https://youtu.be/02FCIk8anVo - link Ä‘áº·t cÃ¢u há»i: https://forms.gle/igM4mncYFcjDhV1W6,,,,,
"BÃ i viáº¿t hay vá» phÃ¢n tÃ­ch yÃªu cáº§u vÃ  thiáº¿t káº¿ MLOps platform cá»§a iFunny
---
Má»i ngÆ°á»i quan tÃ¢m tá»›i ML Engineering/MLOps thÃ¬ join group MLOps VN Ä‘á»ƒ cÃ¹ng giao lÆ°u há»c há»i vÃ  chia sáº» kiáº¿n thá»©c nhÃ© áº¡
https://www.facebook.com/groups/mlopsvn",BÃ i viáº¿t hay vá» phÃ¢n tÃ­ch yÃªu cáº§u vÃ  thiáº¿t káº¿ MLOps platform cá»§a iFunny --- Má»i ngÆ°á»i quan tÃ¢m tá»›i ML Engineering/MLOps thÃ¬ join group MLOps VN Ä‘á»ƒ cÃ¹ng giao lÆ°u há»c há»i vÃ  chia sáº» kiáº¿n thá»©c nhÃ© áº¡ https://www.facebook.com/groups/mlopsvn,,,,,
"Em chÃ o cÃ¡c anh chá»‹ áº¡, hiá»‡n táº¡i e Ä‘ang lÃ  sinh viÃªn nÄƒm cuá»‘i Ä‘á»‹nh hÆ°á»›ng theo AI. Em Ä‘ang muá»‘n sau khi ra trÆ°á»ng e Ä‘i há»c lÃªn láº¥y báº±ng Master luÃ´n, thÃ¬ theo má»i ngÆ°á»i khi má»›i ra trÆ°á»ng mÃ¬nh Ä‘i há»c lÃªn luÃ´n hay Ä‘i lÃ m 1, 2 nÄƒm rá»“i má»›i Ä‘i há»c áº¡. Náº¿u cÃ³ Ä‘i thÃ¬ cÃ¡c anh chá»‹ cÃ³ thá»ƒ chia sáº» cho em kinh nghiá»‡m láº¥y há»c bá»•ng bÃªn Äá»©c, PhÃ¡p hoáº·c Má»¹ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","Em chÃ o cÃ¡c anh chá»‹ áº¡, hiá»‡n táº¡i e Ä‘ang lÃ  sinh viÃªn nÄƒm cuá»‘i Ä‘á»‹nh hÆ°á»›ng theo AI. Em Ä‘ang muá»‘n sau khi ra trÆ°á»ng e Ä‘i há»c lÃªn láº¥y báº±ng Master luÃ´n, thÃ¬ theo má»i ngÆ°á»i khi má»›i ra trÆ°á»ng mÃ¬nh Ä‘i há»c lÃªn luÃ´n hay Ä‘i lÃ m 1, 2 nÄƒm rá»“i má»›i Ä‘i há»c áº¡. Náº¿u cÃ³ Ä‘i thÃ¬ cÃ¡c anh chá»‹ cÃ³ thá»ƒ chia sáº» cho em kinh nghiá»‡m láº¥y há»c bá»•ng bÃªn Äá»©c, PhÃ¡p hoáº·c Má»¹ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"Em chÃ o cÃ¡c anh cÃ¡c chá»‹, em cÃ³ má»™t bÃ i toÃ¡n lÃ  :
Em cÃ³ má»™t mÃ¡y vision hÃ¬nh áº£nh ngoáº¡i quan cá»§a sáº£n pháº©m thÃ´ng qua camera. Dá»±a trÃªn bá» máº·t cá»§a sáº£n pháº©m thÃ´ng qua hÃ¬nh áº£nh sáº½ Ä‘Ã¡nh giÃ¡ xem sáº£n pháº©m cÃ³ bá»‹ lá»—i hay khÃ´ng náº¿u cÃ³ lá»—i thÃ¬ bá»‹ lá»—i gÃ¬, danh sÃ¡ch lá»—i bao gá»“m khoáº£ng 10 lá»—i, má»—i lá»—i sáº½ cÃ³ hÃ¬nh dáº¡ng khÃ¡c nhau. VÃ­ dá»¥ nhÆ° hÃ¬nh áº£nh bÃªn dÆ°á»›i pháº§n em khoanh mÃ u Ä‘á» lÃ  Ä‘áº¡i diá»‡n cho lá»—i A cháº³ng háº¡n. TrÃªn má»™t hÃ¬nh áº£nh cÃ³ thá»ƒ cÃ³ nhiá»u loáº¡i lá»—i á»Ÿ nhiá»u vá»‹ trÃ­ khÃ¡c nhau trÃªn áº£nh hoáº·c chá»‰ 1 lá»—i tÃ¹y vÃ o sáº£n pháº©m. Em muá»‘n Ã¡p dá»¥ng ML Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng dá»±a trÃªn hÃ¬nh áº£nh Ä‘áº§u vÃ o tá»« camera thÃ¬ em nÃªn dÃ¹ng mÃ´ hÃ¬nh cÃ³ sáºµn nÃ o hay Ä‘i theo hÆ°á»›ng nÃ o mong cÃ¡c anh chá»‹ chá»‰ báº£o áº¡.","Em chÃ o cÃ¡c anh cÃ¡c chá»‹, em cÃ³ má»™t bÃ i toÃ¡n lÃ  : Em cÃ³ má»™t mÃ¡y vision hÃ¬nh áº£nh ngoáº¡i quan cá»§a sáº£n pháº©m thÃ´ng qua camera. Dá»±a trÃªn bá» máº·t cá»§a sáº£n pháº©m thÃ´ng qua hÃ¬nh áº£nh sáº½ Ä‘Ã¡nh giÃ¡ xem sáº£n pháº©m cÃ³ bá»‹ lá»—i hay khÃ´ng náº¿u cÃ³ lá»—i thÃ¬ bá»‹ lá»—i gÃ¬, danh sÃ¡ch lá»—i bao gá»“m khoáº£ng 10 lá»—i, má»—i lá»—i sáº½ cÃ³ hÃ¬nh dáº¡ng khÃ¡c nhau. VÃ­ dá»¥ nhÆ° hÃ¬nh áº£nh bÃªn dÆ°á»›i pháº§n em khoanh mÃ u Ä‘á» lÃ  Ä‘áº¡i diá»‡n cho lá»—i A cháº³ng háº¡n. TrÃªn má»™t hÃ¬nh áº£nh cÃ³ thá»ƒ cÃ³ nhiá»u loáº¡i lá»—i á»Ÿ nhiá»u vá»‹ trÃ­ khÃ¡c nhau trÃªn áº£nh hoáº·c chá»‰ 1 lá»—i tÃ¹y vÃ o sáº£n pháº©m. Em muá»‘n Ã¡p dá»¥ng ML Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng dá»±a trÃªn hÃ¬nh áº£nh Ä‘áº§u vÃ o tá»« camera thÃ¬ em nÃªn dÃ¹ng mÃ´ hÃ¬nh cÃ³ sáºµn nÃ o hay Ä‘i theo hÆ°á»›ng nÃ o mong cÃ¡c anh chá»‹ chá»‰ báº£o áº¡.",,,,,
"VinAI Seminar - Despoina Paschalidou - Stanford University - ""Learning Compositional Representations for Understanding and Generating Controllable 3D Environments""
11.00 am - 12.00 pm (Vietnam time, GMT+7), Fri, Aug 19, 2022","VinAI Seminar - Despoina Paschalidou - Stanford University - ""Learning Compositional Representations for Understanding and Generating Controllable 3D Environments"" 11.00 am - 12.00 pm (Vietnam time, GMT+7), Fri, Aug 19, 2022",,,,,
"ChÃ o má»i ngÆ°á»i, hÃ´m nay mÃ¬nh xin giá»›i thiá»‡u Ä‘áº¿n má»i ngÆ°á»i má»™t pretrain sentence embeddings cho tiáº¿ng Viá»‡t mÃ¬nh vá»«a training xong tÃªn lÃ  SimCSE_Vietnamese, mÃ¬nh sá»­ dá»¥ng kiáº¿n trÃºc tÆ°Æ¡ng tá»± SimCSE vá»›i encoding input mÃ¬nh dÃ¹ng lÃ  Phobert.
MÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng nÃ³ vÃ o bÃ i toÃ¡n semantic search káº¿t há»£p vá»›i elasticsearch káº¿t quáº£ hiá»‡n táº¡i ráº¥t á»•n.
Má»i ngÆ°á»i cÃ³ thá»ƒ xem chi tiáº¿t Ä‘Ã¢y : https://viblo.asia/p/nlp-cai-thien-elasticsearch-trong-bai-toan-semantic-search-su-dung-phuong-phap-sentence-embeddings-Qpmley4rlrd.
Má»i ngÆ°á»i cÃ³ thá»ƒ test SimCSE_Vietnamese trá»±c tiáº¿p táº¡i link colab nÃ y : https://colab.research.google.com/drive/12__EXJoQYHe9nhi4aXLTf9idtXT8yr7H?usp=sharing
ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» !","ChÃ o má»i ngÆ°á»i, hÃ´m nay mÃ¬nh xin giá»›i thiá»‡u Ä‘áº¿n má»i ngÆ°á»i má»™t pretrain sentence embeddings cho tiáº¿ng Viá»‡t mÃ¬nh vá»«a training xong tÃªn lÃ  SimCSE_Vietnamese, mÃ¬nh sá»­ dá»¥ng kiáº¿n trÃºc tÆ°Æ¡ng tá»± SimCSE vá»›i encoding input mÃ¬nh dÃ¹ng lÃ  Phobert. MÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng nÃ³ vÃ o bÃ i toÃ¡n semantic search káº¿t há»£p vá»›i elasticsearch káº¿t quáº£ hiá»‡n táº¡i ráº¥t á»•n. Má»i ngÆ°á»i cÃ³ thá»ƒ xem chi tiáº¿t Ä‘Ã¢y : https://viblo.asia/p/nlp-cai-thien-elasticsearch-trong-bai-toan-semantic-search-su-dung-phuong-phap-sentence-embeddings-Qpmley4rlrd. Má»i ngÆ°á»i cÃ³ thá»ƒ test SimCSE_Vietnamese trá»±c tiáº¿p táº¡i link colab nÃ y : https://colab.research.google.com/drive/12__EXJoQYHe9nhi4aXLTf9idtXT8yr7H?usp=sharing ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» !",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Em Ä‘ang chuáº©n bá»‹ vÃ o nÄƒm nháº¥t vÃ  cÃ³ nhu cáº§u mua laptop má»›i Ä‘á»ƒ phá»¥c vá»¥ viá»‡c trÃªn model vÃ  há»c DS áº¡.
Má»i ngÆ°á»i cÃ³ thá»ƒ recommend cho em con laptop tá»‘t Ä‘á»ƒ há»c Ä‘Æ°á»£c khÃ´ng áº¡.
Budget cá»§a em: 20m Ä‘á»• xuá»‘ng áº¡
Em cáº£m Æ¡n nhiá»u áº¡",Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang chuáº©n bá»‹ vÃ o nÄƒm nháº¥t vÃ  cÃ³ nhu cáº§u mua laptop má»›i Ä‘á»ƒ phá»¥c vá»¥ viá»‡c trÃªn model vÃ  há»c DS áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ recommend cho em con laptop tá»‘t Ä‘á»ƒ há»c Ä‘Æ°á»£c khÃ´ng áº¡. Budget cá»§a em: 20m Ä‘á»• xuá»‘ng áº¡ Em cáº£m Æ¡n nhiá»u áº¡,,,,,
"xin chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu bÃ i toÃ¡n nháº­n diá»‡n báº£ng thá»§ ngá»¯ tiáº¿ng viá»‡t, nhÆ°ng em Ä‘ang máº¯c á»Ÿ bÆ°á»›c cÃ³ vÃ i chá»¯ cÃ¡i gá»“m 2 cá»­ chá»‰ tay thÃ¬ khÃ´ng detect Ä‘Æ°á»£c, mong má»i ngÆ°á»i giÃºp em hÆ°á»›ng giáº£i quyáº¿t áº¡","xin chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu bÃ i toÃ¡n nháº­n diá»‡n báº£ng thá»§ ngá»¯ tiáº¿ng viá»‡t, nhÆ°ng em Ä‘ang máº¯c á»Ÿ bÆ°á»›c cÃ³ vÃ i chá»¯ cÃ¡i gá»“m 2 cá»­ chá»‰ tay thÃ¬ khÃ´ng detect Ä‘Æ°á»£c, mong má»i ngÆ°á»i giÃºp em hÆ°á»›ng giáº£i quyáº¿t áº¡",,,,,
"ChÃ o cÃ¡c bÃ¡c, hÆ¡i k liÃªn quan má»™t chÃºt nhÆ°ng mÃ¬nh muá»‘n xin tÆ° váº¥n áº¡.
MÃ¬nh hiá»‡n Ä‘ang há»c ngÃ nh NgÃ´n ngá»¯, cÃ´ng nghá»‡ vÃ  truyá»n thÃ´ng. NgÃ nh cá»§a mÃ¬nh theo hÆ°á»›ng á»©ng dá»¥ng AI (artificial intelligence) vÃ  cáº§n há»c vá» python, machine learning, NLP... Tuy nhiÃªn thÃ¬ mÃ¬nh chÆ°a náº¯m Ä‘c python cÆ¡ báº£n láº¯m vÃ  nhá»¯ng mÃ´n khÃ¡c nhÆ° Thuáº­t toÃ¡n vÃ  Cáº¥u trÃºc dá»¯ liá»‡u cÅ©ng yáº¿u vÃ¬ trÆ°á»›c Ä‘Ã¢y mÃ¬nh dá»± Ä‘á»‹nh theo ngÃ nh ngÃ´n ngá»¯ nÃªn Ä‘Ã¢y lÃ  1 hÆ°á»›ng Ä‘i hÆ¡i má»›i vá»›i mÃ¬nh ğŸ˜…
Váº­y nÃªn mÃ¬nh muá»‘n há»c 1 khoÃ¡ ngáº¯n háº¡n vÃ  mÃ¬nh Ä‘Ã£ tÃ¬m hiá»ƒu khoÃ¡ Python Developer for AI á»Ÿ VTC Academy, k biáº¿t cÃ³ bÃ¡c nÃ o Ä‘Ã£ há»c á»Ÿ Ä‘Ã¢y chÆ°a áº¡?
NgoÃ i ra cÃ³ ai nháº­n dáº¡y thÃªm trong thÃ¡ng 9 nhá»¯ng mÃ´n lquan trÃªn k áº¡? VÃ¬ mÃ¬nh cÅ©ng mong muá»‘n tÃ¬m giá» há»c linh hoáº¡t chÃºt.
Cáº£m Æ¡n cáº£ nhÃ  Ä‘Ã£ Ä‘á»c bÃ i áº¡ ğŸ˜ŠğŸ˜ŠğŸ˜Š","ChÃ o cÃ¡c bÃ¡c, hÆ¡i k liÃªn quan má»™t chÃºt nhÆ°ng mÃ¬nh muá»‘n xin tÆ° váº¥n áº¡. MÃ¬nh hiá»‡n Ä‘ang há»c ngÃ nh NgÃ´n ngá»¯, cÃ´ng nghá»‡ vÃ  truyá»n thÃ´ng. NgÃ nh cá»§a mÃ¬nh theo hÆ°á»›ng á»©ng dá»¥ng AI (artificial intelligence) vÃ  cáº§n há»c vá» python, machine learning, NLP... Tuy nhiÃªn thÃ¬ mÃ¬nh chÆ°a náº¯m Ä‘c python cÆ¡ báº£n láº¯m vÃ  nhá»¯ng mÃ´n khÃ¡c nhÆ° Thuáº­t toÃ¡n vÃ  Cáº¥u trÃºc dá»¯ liá»‡u cÅ©ng yáº¿u vÃ¬ trÆ°á»›c Ä‘Ã¢y mÃ¬nh dá»± Ä‘á»‹nh theo ngÃ nh ngÃ´n ngá»¯ nÃªn Ä‘Ã¢y lÃ  1 hÆ°á»›ng Ä‘i hÆ¡i má»›i vá»›i mÃ¬nh Váº­y nÃªn mÃ¬nh muá»‘n há»c 1 khoÃ¡ ngáº¯n háº¡n vÃ  mÃ¬nh Ä‘Ã£ tÃ¬m hiá»ƒu khoÃ¡ Python Developer for AI á»Ÿ VTC Academy, k biáº¿t cÃ³ bÃ¡c nÃ o Ä‘Ã£ há»c á»Ÿ Ä‘Ã¢y chÆ°a áº¡? NgoÃ i ra cÃ³ ai nháº­n dáº¡y thÃªm trong thÃ¡ng 9 nhá»¯ng mÃ´n lquan trÃªn k áº¡? VÃ¬ mÃ¬nh cÅ©ng mong muá»‘n tÃ¬m giá» há»c linh hoáº¡t chÃºt. Cáº£m Æ¡n cáº£ nhÃ  Ä‘Ã£ Ä‘á»c bÃ i áº¡",,,,,
"BÃ i toÃ¡n Detect Forged ID Card (Kiá»ƒm tra CCCD giáº£)
Em chÃ o má»i ngÆ°á»i áº¡, em hiá»‡n Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n kiá»ƒm tra CCCD giáº£ vá»›i cÃ¡c chi tiáº¿t nhÆ° sau.
- Input: áº¢nh chá»¥p CCCD (cÃ³ thá»ƒ cÃ³ yÃªu cáº§u ngÆ°á»i chá»¥p Ä‘á»ƒ CCCD á»Ÿ 1 gÃ³c cá»‘ Ä‘á»‹nh, táº¡o frame hÆ°á»›ng dáº«n chá»¥p)
- Output: Classified CCCD cÃ³ bá»‹ chá»‰nh sá»­a hÃ¬nh áº£nh hay khÃ´ng
BÃ i toÃ¡n cá»§a em chá»‰ giá»›i háº¡n á»Ÿ detect 2 dáº¡ng chá»‰nh sá»­a phá»• biáº¿n:
- Chá»¥p láº¡i mÃ n hÃ¬nh cá»§a Ä‘iá»‡n thoáº¡i chá»©a áº£nh CCCD bá»‹ chá»‰nh sá»­a -> PhÃ¢n biá»‡t áº£nh tháº­t vÃ  áº£nh qua mÃ n hÃ¬nh Ä‘iá»‡n thoáº¡i
- In áº£nh giáº£ vÃ  Ä‘Ã¨ lÃªn CCCD tháº­t vÃ  chá»¥p áº£nh CCCD Ä‘Ã³
Em muá»‘n xin Ã½ kiáº¿n vá» hÆ°á»›ng tiáº¿p cáº­n bÃ i toÃ¡n áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c áº¡.","BÃ i toÃ¡n Detect Forged ID Card (Kiá»ƒm tra CCCD giáº£) Em chÃ o má»i ngÆ°á»i áº¡, em hiá»‡n Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n kiá»ƒm tra CCCD giáº£ vá»›i cÃ¡c chi tiáº¿t nhÆ° sau. - Input: áº¢nh chá»¥p CCCD (cÃ³ thá»ƒ cÃ³ yÃªu cáº§u ngÆ°á»i chá»¥p Ä‘á»ƒ CCCD á»Ÿ 1 gÃ³c cá»‘ Ä‘á»‹nh, táº¡o frame hÆ°á»›ng dáº«n chá»¥p) - Output: Classified CCCD cÃ³ bá»‹ chá»‰nh sá»­a hÃ¬nh áº£nh hay khÃ´ng BÃ i toÃ¡n cá»§a em chá»‰ giá»›i háº¡n á»Ÿ detect 2 dáº¡ng chá»‰nh sá»­a phá»• biáº¿n: - Chá»¥p láº¡i mÃ n hÃ¬nh cá»§a Ä‘iá»‡n thoáº¡i chá»©a áº£nh CCCD bá»‹ chá»‰nh sá»­a -> PhÃ¢n biá»‡t áº£nh tháº­t vÃ  áº£nh qua mÃ n hÃ¬nh Ä‘iá»‡n thoáº¡i - In áº£nh giáº£ vÃ  Ä‘Ã¨ lÃªn CCCD tháº­t vÃ  chá»¥p áº£nh CCCD Ä‘Ã³ Em muá»‘n xin Ã½ kiáº¿n vá» hÆ°á»›ng tiáº¿p cáº­n bÃ i toÃ¡n áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c áº¡.",,,,,
"chÃ o cÃ¡c báº¡n,
MÃ¬nh Ä‘áº¿n tá»« team Wano, mÃ¬nh xin chia sáº» solution team mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng Ä‘á»ƒ giÃ nh Ä‘Æ°á»£c top 1 private test táº¡i zalo AI challenge 2021 task hum to song.
á» task nÃ y vÃ¬ háº¡n cháº¿ vá» pháº§n cá»©ng nÃªn hÆ°á»›ng Ä‘i tá»« Ä‘áº§u cá»§a team mÃ¬nh lÃ  data centric, táº­p trung clean vÃ  augment data. Team mÃ¬nh sá»­ dá»¥ng model resnet18 vá»›i má»™t vÃ i má»Ÿ rá»™ng vÃ  arcface loss Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng tá»« mel spectrogram. Trong quÃ¡ trÃ¬nh training vÃ  inference tá»¥i mÃ¬nh hoÃ n toÃ n chá»‰ sá»­ dá»¥ng colab pro. Äá»‘i vá»›i táº­p private test vÃ¬ khÃ´ng Ä‘Æ°á»£c thÃ´ng bÃ¡o tá»« trÆ°á»›c data sáº½ lá»›n nhÆ° váº­y (12.5GB) nÃªn team Ä‘Ã£ khÃ´ng Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° reranking Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c máº·c dÃ¹ váº­y team cÅ©ng Ä‘Ã£ may máº¯n giÃ nh Ä‘Æ°á»£c top 1 vá»›i thá»i gian xá»­ lÃ½ khÃ¡ nhanh ( khoáº£ng 1h ).
ToÃ n bá»™ source code tá»« clean, augment data Ä‘áº¿n train vÃ  inference tá»¥i mÃ¬nh Ä‘Ã£ Ä‘á»ƒ háº¿t trong repo má»i ngÆ°á»i tham kháº£o ( náº¿u tháº¥y hay cho mÃ¬nh xin 1 star ğŸ˜ğŸ˜ )
Thiá»u Nguyá»…n, Thá»‹nh BÃ¡ LÃ¢m","chÃ o cÃ¡c báº¡n, MÃ¬nh Ä‘áº¿n tá»« team Wano, mÃ¬nh xin chia sáº» solution team mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng Ä‘á»ƒ giÃ nh Ä‘Æ°á»£c top 1 private test táº¡i zalo AI challenge 2021 task hum to song. á» task nÃ y vÃ¬ háº¡n cháº¿ vá» pháº§n cá»©ng nÃªn hÆ°á»›ng Ä‘i tá»« Ä‘áº§u cá»§a team mÃ¬nh lÃ  data centric, táº­p trung clean vÃ  augment data. Team mÃ¬nh sá»­ dá»¥ng model resnet18 vá»›i má»™t vÃ i má»Ÿ rá»™ng vÃ  arcface loss Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng tá»« mel spectrogram. Trong quÃ¡ trÃ¬nh training vÃ  inference tá»¥i mÃ¬nh hoÃ n toÃ n chá»‰ sá»­ dá»¥ng colab pro. Äá»‘i vá»›i táº­p private test vÃ¬ khÃ´ng Ä‘Æ°á»£c thÃ´ng bÃ¡o tá»« trÆ°á»›c data sáº½ lá»›n nhÆ° váº­y (12.5GB) nÃªn team Ä‘Ã£ khÃ´ng Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° reranking Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c máº·c dÃ¹ váº­y team cÅ©ng Ä‘Ã£ may máº¯n giÃ nh Ä‘Æ°á»£c top 1 vá»›i thá»i gian xá»­ lÃ½ khÃ¡ nhanh ( khoáº£ng 1h ). ToÃ n bá»™ source code tá»« clean, augment data Ä‘áº¿n train vÃ  inference tá»¥i mÃ¬nh Ä‘Ã£ Ä‘á»ƒ háº¿t trong repo má»i ngÆ°á»i tham kháº£o ( náº¿u tháº¥y hay cho mÃ¬nh xin 1 star ) Thiá»u Nguyá»…n, Thá»‹nh BÃ¡ LÃ¢m",,,,,
"Yann LeCun's Deep Learning 2021 course má»›i ra lÃ² cÃ¡ch Ä‘Ã¢y gáº§n 1 tuáº§n, ai quan tÃ¢m thÃ¬ xem nhÃ©. CÃ³ 1 blog Ä‘i cÃ¹ng khÃ¡ lÃ  cháº¥t lÆ°á»£ng Ä‘Ã³.","Yann LeCun's Deep Learning 2021 course má»›i ra lÃ² cÃ¡ch Ä‘Ã¢y gáº§n 1 tuáº§n, ai quan tÃ¢m thÃ¬ xem nhÃ©. CÃ³ 1 blog Ä‘i cÃ¹ng khÃ¡ lÃ  cháº¥t lÆ°á»£ng Ä‘Ã³.",,,,,
Buá»•i chia sáº» há»¯u Ã­ch tá»« má»™t Senior ML Engineer ğŸ˜,Buá»•i chia sáº» há»¯u Ã­ch tá»« má»™t Senior ML Engineer,,,,,
"[GÃ³c chia sáº» - AI Webinar 2022 ]
Xin chÃ o má»i ngÆ°á»i,
Xin phÃ©p chia sáº» vá»›i má»i ngÆ°á»i má»™t webinar vá» AI sáº¯p diá»…n ra mÃ  mÃ¬nh cáº£m tháº¥y khÃ¡ háº¥p dáº«n. Sá»± kiá»‡n cÃ³ sá»± tham gia cá»§a cÃ¡c speaker lÃ  cÃ¡c Vice President, Director of AI, Chief Data, C-level trong ngÃ nh Ä‘áº¿n tá»« cÃ¡c tÃªn tuá»•i lá»›n nhÆ° Google, Microsoft, Mercedes-Benz, AWS, Volkswagen, IBM, SAP, Samsung SDS, Oxford, vÃ  cÃ¡c cÃ´ng ty táº­p Ä‘oÃ n lá»›n tá»« kháº¯p 5 chÃ¢u.
Link Ä‘Äƒng kÃ½ mn cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y:
https://meetyoo.live/register/1/worldwideAI2022","[GÃ³c chia sáº» - AI Webinar 2022 ] Xin chÃ o má»i ngÆ°á»i, Xin phÃ©p chia sáº» vá»›i má»i ngÆ°á»i má»™t webinar vá» AI sáº¯p diá»…n ra mÃ  mÃ¬nh cáº£m tháº¥y khÃ¡ háº¥p dáº«n. Sá»± kiá»‡n cÃ³ sá»± tham gia cá»§a cÃ¡c speaker lÃ  cÃ¡c Vice President, Director of AI, Chief Data, C-level trong ngÃ nh Ä‘áº¿n tá»« cÃ¡c tÃªn tuá»•i lá»›n nhÆ° Google, Microsoft, Mercedes-Benz, AWS, Volkswagen, IBM, SAP, Samsung SDS, Oxford, vÃ  cÃ¡c cÃ´ng ty táº­p Ä‘oÃ n lá»›n tá»« kháº¯p 5 chÃ¢u. Link Ä‘Äƒng kÃ½ mn cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y: https://meetyoo.live/register/1/worldwideAI2022",,,,,
"Thay vÃ¬ nÃ³i vá» ML/DL/AI, theo tÃ´i mÃ´ hÃ¬nh thá»‘ng kÃª cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c nhiá»u bÃ i toÃ¡n trong thá»±c tiá»…n, Ä‘áº·c biá»‡t trong y há»c vÃ¬ tÃ­nh Transparency, Reliability, vÃ  Explainability. Nay mÃ¬nh muá»‘n giá»›i thiá»‡u 1 sá»‘ vÃ­ dá»¥ trong sÃ¡ch cá»§a chÃ­nh GS Faraway nÃ³i vá» Mixed Effect Models viáº¿t báº±ng ngÃ´n ngá»¯ R táº¡i Ä‘Ã¢y https://github.com/julianfaraway/rexamples
Ná»™i dung gá»“m:
1/ Single Random Effect - the pulp data
2/ Randomized Block Design - the penicillin data
3/ Split Plot Design - the irrigation data
4/ Nested Effects - the eggs data
5/ Crossed Effects - the abrasion data
6/ Multilevel Models - the jsp data
7/ Longitudinal Models - the psid data
8/ Repeated Measures - the vision data
9/ Multiple Response Models - the jsp data
Pháº§n source code nÃ y thuá»™c 2 chÆ°Æ¡ng cá»§a cuá»‘n sÃ¡ch cÃ³ tÃªn ""Extending the Linear Model with R"" cá»§a cÃ¹ng tÃ¡c giáº£.
Hi vá»ng nÃ³ gÃ³p vui cho cÃ¡c báº¡n ngÃ y cuá»‘i tuáº§n!","Thay vÃ¬ nÃ³i vá» ML/DL/AI, theo tÃ´i mÃ´ hÃ¬nh thá»‘ng kÃª cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c nhiá»u bÃ i toÃ¡n trong thá»±c tiá»…n, Ä‘áº·c biá»‡t trong y há»c vÃ¬ tÃ­nh Transparency, Reliability, vÃ  Explainability. Nay mÃ¬nh muá»‘n giá»›i thiá»‡u 1 sá»‘ vÃ­ dá»¥ trong sÃ¡ch cá»§a chÃ­nh GS Faraway nÃ³i vá» Mixed Effect Models viáº¿t báº±ng ngÃ´n ngá»¯ R táº¡i Ä‘Ã¢y https://github.com/julianfaraway/rexamples Ná»™i dung gá»“m: 1/ Single Random Effect - the pulp data 2/ Randomized Block Design - the penicillin data 3/ Split Plot Design - the irrigation data 4/ Nested Effects - the eggs data 5/ Crossed Effects - the abrasion data 6/ Multilevel Models - the jsp data 7/ Longitudinal Models - the psid data 8/ Repeated Measures - the vision data 9/ Multiple Response Models - the jsp data Pháº§n source code nÃ y thuá»™c 2 chÆ°Æ¡ng cá»§a cuá»‘n sÃ¡ch cÃ³ tÃªn ""Extending the Linear Model with R"" cá»§a cÃ¹ng tÃ¡c giáº£. Hi vá»ng nÃ³ gÃ³p vui cho cÃ¡c báº¡n ngÃ y cuá»‘i tuáº§n!",,,,,
"ğ¯ğ¢-ğ›ğšğ«ğ­ğŸğ¥ğšğ±-ğ¥ğšğ«ğ ğ-ğ§ğğ°ğ¬: MÃ´ hÃ¬nh BART trÃªn miá»n tin tá»©c tiáº¿ng Viá»‡t
ğŸ”¥Sau khi cÃ´ng bá»‘ bartflax, VietAI Ä‘Ã£ nháº­n Ä‘Æ°á»£c nhá»¯ng cÃ¢u há»i vá» káº¿t quáº£ khi sá»­ dá»¥ng implementation nÃ y. ChÃºng tÃ´i Ä‘Ã£ huáº¥n luyá»‡n kiáº¿n trÃºc BART-large trÃªn táº­p dá»¯ liá»‡u tin tá»©c tiáº¿ng Viá»‡t gá»“m 20 triá»‡u bÃ i bÃ¡o, vÃ  finetune mÃ´ hÃ¬nh thu Ä‘Æ°á»£c trÃªn táº­p dá»¯ liá»‡u tÃ³m táº¯t vÄƒn báº£n VNDS (Vietnews). Báº£ng 1 trÃ¬nh bÃ y káº¿t quáº£ chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c khi so sÃ¡nh vá»›i má»™t sá»‘ mÃ´ hÃ¬nh BART tiáº¿ng Viá»‡t tá»«ng Ä‘Æ°á»£c cÃ´ng bá»‘.
ğŸ”¥Äá»ƒ reproduce káº¿t quáº£ trÃªn, cÃ¡c cÃ³ thá»ƒ sá»­ dá»¥ng vÃ­ dá»¥ run_summarization_flax.py cá»§a thÆ° viá»‡n transformers (link táº¡i cuá»‘i bÃ i viáº¿t), vá»›i tham sá»‘ --dataset_name=duongna/vietnews vÃ  --model_name_or_path=VietAI/vi-bartflax-large-news.
ğŸ‘‰Tham kháº£o bÃ i viáº¿t trÃªn VietAI Ä‘á»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ y!","---: MÃ´ hÃ¬nh BART trÃªn miá»n tin tá»©c tiáº¿ng Viá»‡t Sau khi cÃ´ng bá»‘ bartflax, VietAI Ä‘Ã£ nháº­n Ä‘Æ°á»£c nhá»¯ng cÃ¢u há»i vá» káº¿t quáº£ khi sá»­ dá»¥ng implementation nÃ y. ChÃºng tÃ´i Ä‘Ã£ huáº¥n luyá»‡n kiáº¿n trÃºc BART-large trÃªn táº­p dá»¯ liá»‡u tin tá»©c tiáº¿ng Viá»‡t gá»“m 20 triá»‡u bÃ i bÃ¡o, vÃ  finetune mÃ´ hÃ¬nh thu Ä‘Æ°á»£c trÃªn táº­p dá»¯ liá»‡u tÃ³m táº¯t vÄƒn báº£n VNDS (Vietnews). Báº£ng 1 trÃ¬nh bÃ y káº¿t quáº£ chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c khi so sÃ¡nh vá»›i má»™t sá»‘ mÃ´ hÃ¬nh BART tiáº¿ng Viá»‡t tá»«ng Ä‘Æ°á»£c cÃ´ng bá»‘. Äá»ƒ reproduce káº¿t quáº£ trÃªn, cÃ¡c cÃ³ thá»ƒ sá»­ dá»¥ng vÃ­ dá»¥ run_summarization_flax.py cá»§a thÆ° viá»‡n transformers (link táº¡i cuá»‘i bÃ i viáº¿t), vá»›i tham sá»‘ --dataset_name=duongna/vietnews vÃ  --model_name_or_path=VietAI/vi-bartflax-large-news. Tham kháº£o bÃ i viáº¿t trÃªn VietAI Ä‘á»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ y!",,,,,
"Hi ACE,
MiÌ€nh muÃ´Ìn hoÌ‰i mÃ´Ì£t cÃ¢u rÃ¢Ìt cÆ¡ baÌ‰n, miÌ€nh Ä‘ang duÌ€ng thuÃ¢Ì£t toaÌn Random forest Ä‘ÃªÌ‰ phÃ¢n loaÌ£i bÃªÌ£nh. HiÃªÌ£n taÌ£i thiÌ€ Ä‘Ã´Ì£ chiÌnh xaÌc cuÌ‰a noÌ khoaÌ‰ng 97%, nhÆ°ng miÌ€nh coÌ€n mÃ´Ì£t vaÌ€i caÌ thÃªÌ‰ (3/100) mÃ¢Ìƒu biÌ£ phÃ¢n loaÌ£i sai. LaÌ€m thÃªÌ naÌ€o Ä‘ÃªÌ‰ biÃªÌt Ä‘Æ°Æ¡Ì£c liÌ do taÌ£i sao thuÃ¢Ì£t toaÌn laÌ£i ko thÃªÌ‰ phÃ¢n loaÌ£i Ä‘uÌng Ä‘Æ°Æ¡Ì£c caÌc (3) caÌ thÃªÌ‰ trÃªn.
CaÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i Ä‘aÌƒ traÌ‰ lÆ¡Ì€i.","Hi ACE, MiÌ€nh muÃ´Ìn hoÌ‰i mÃ´Ì£t cÃ¢u rÃ¢Ìt cÆ¡ baÌ‰n, miÌ€nh Ä‘ang duÌ€ng thuÃ¢Ì£t toaÌn Random forest Ä‘ÃªÌ‰ phÃ¢n loaÌ£i bÃªÌ£nh. HiÃªÌ£n taÌ£i thiÌ€ Ä‘Ã´Ì£ chiÌnh xaÌc cuÌ‰a noÌ khoaÌ‰ng 97%, nhÆ°ng miÌ€nh coÌ€n mÃ´Ì£t vaÌ€i caÌ thÃªÌ‰ (3/100) mÃ¢Ìƒu biÌ£ phÃ¢n loaÌ£i sai. LaÌ€m thÃªÌ naÌ€o Ä‘ÃªÌ‰ biÃªÌt Ä‘Æ°Æ¡Ì£c liÌ do taÌ£i sao thuÃ¢Ì£t toaÌn laÌ£i ko thÃªÌ‰ phÃ¢n loaÌ£i Ä‘uÌng Ä‘Æ°Æ¡Ì£c caÌc (3) caÌ thÃªÌ‰ trÃªn. CaÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i Ä‘aÌƒ traÌ‰ lÆ¡Ì€i.",,,,,
"VinAI Seminar - Dr. Thanh Nguyen - University of Oregon - ""Vulnerabilities in Data-Centered Decision Making""
11.00 am â€“ 12.00 pm (Vietnam time, GMT+7), Monday, August 15, 2022","VinAI Seminar - Dr. Thanh Nguyen - University of Oregon - ""Vulnerabilities in Data-Centered Decision Making"" 11.00 am â€“ 12.00 pm (Vietnam time, GMT+7), Monday, August 15, 2022",,,,,
"[GÃ³c chia sáº» - Worldwide AI Webinar 2022 ]
Xin chÃ o má»i ngÆ°á»i,
Xin phÃ©p chia sáº» vá»›i má»i ngÆ°á»i má»™t webinar vá» AI sáº¯p diá»…n ra mÃ  em/mÃ¬nh cáº£m tháº¥y khÃ¡ háº¥p dáº«n. Sá»± kiá»‡n cÃ³ sá»± tham gia cá»§a cÃ¡c speaker lÃ  cÃ¡c Vice President, Director of AI, Chief Data, C-level trong ngÃ nh Ä‘áº¿n tá»« cÃ¡c tÃªn tuá»•i lá»›n nhÆ° Google, Microsoft, Mercedes-Benz, AWS, Volkswagen, IBM, SAP, Samsung SDS, Oxford, vÃ  cÃ¡c cÃ´ng ty táº­p Ä‘oÃ n lá»›n tá»« kháº¯p 5 chÃ¢u.
Má»i ngÆ°á»i ai cÃ³ há»©ng thÃº Ä‘á»u cÃ³ thá»ƒ Ä‘Äƒng kÃ½ vÃ¬ nÃ³ hoÃ n toÃ n miá»…n phÃ­, Ä‘Æ°á»£c giao lÆ°u trá»±c tiáº¿p vá»›i diá»…n giáº£ vÃ  Ä‘Æ°á»£c káº¿t ná»‘i vá»›i cá»™ng Ä‘á»“ng AI tá»« kháº¯p nÆ¡i trÃªn tháº¿ giá»›i.
Web: https://event.wow-ai.com/worldwideAI2022/","[GÃ³c chia sáº» - Worldwide AI Webinar 2022 ] Xin chÃ o má»i ngÆ°á»i, Xin phÃ©p chia sáº» vá»›i má»i ngÆ°á»i má»™t webinar vá» AI sáº¯p diá»…n ra mÃ  em/mÃ¬nh cáº£m tháº¥y khÃ¡ háº¥p dáº«n. Sá»± kiá»‡n cÃ³ sá»± tham gia cá»§a cÃ¡c speaker lÃ  cÃ¡c Vice President, Director of AI, Chief Data, C-level trong ngÃ nh Ä‘áº¿n tá»« cÃ¡c tÃªn tuá»•i lá»›n nhÆ° Google, Microsoft, Mercedes-Benz, AWS, Volkswagen, IBM, SAP, Samsung SDS, Oxford, vÃ  cÃ¡c cÃ´ng ty táº­p Ä‘oÃ n lá»›n tá»« kháº¯p 5 chÃ¢u. Má»i ngÆ°á»i ai cÃ³ há»©ng thÃº Ä‘á»u cÃ³ thá»ƒ Ä‘Äƒng kÃ½ vÃ¬ nÃ³ hoÃ n toÃ n miá»…n phÃ­, Ä‘Æ°á»£c giao lÆ°u trá»±c tiáº¿p vá»›i diá»…n giáº£ vÃ  Ä‘Æ°á»£c káº¿t ná»‘i vá»›i cá»™ng Ä‘á»“ng AI tá»« kháº¯p nÆ¡i trÃªn tháº¿ giá»›i. Web: https://event.wow-ai.com/worldwideAI2022/",,,,,
"Giai Ä‘oáº¡n tá»« sau khi OpenAI GPT-3 ra Ä‘á»i cÃ³ thá»ƒ xem nhÆ° má»™t thá»i kÃ¬ trÄƒm hoa Ä‘ua ná»Ÿ cá»§a cÃ¡c mÃ´ hÃ¬nh AI vá» ngÃ´n ngá»¯ lá»›n vá»›i kÃ­ch thÆ°á»›c hÃ ng trÄƒm tá»· tham sá»‘. Nhá»¯ng trá»Ÿ ngáº¡i vá» háº¡ táº§ng tÃ­nh toÃ¡n vÃ  dá»¯ liá»‡u lá»›n Ä‘Ã£ khiáº¿n cho nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi nhá»¯ng big tech tÃªn tuá»•i lá»›n. BLOOM nhÆ° má»™t mÃ´ hÃ¬nh Ä‘áº§u tiÃªn Ä‘Ã¡nh dáº¥u sá»± há»£p tÃ¡c tá»« cÃ¡c nhÃ  nghiÃªn cá»©u thuá»™c nhiá»u tá»• chá»©c khÃ¡c nhau nháº±m táº¡o ra má»™t mÃ´ hÃ¬nh minh báº¡ch, cÃ³ thá»ƒ kiáº¿m toÃ¡n Ä‘Æ°á»£c vÃ  mang tÃ­nh Ä‘áº¡i diá»‡n. Dá»± Ã¡n nhÆ° má»™t lá»i kháº³ng Ä‘á»‹nh ráº±ng sá»± há»£p tÃ¡c cÃ³ thá»ƒ mang láº¡i sá»©c máº¡nh Ä‘á»ƒ chá»‘ng láº¡i sá»± Ä‘á»™c quyá»n tá»« cÃ¡c big tech trong viá»‡c táº¡o ra Large Language Models.","Giai Ä‘oáº¡n tá»« sau khi OpenAI GPT-3 ra Ä‘á»i cÃ³ thá»ƒ xem nhÆ° má»™t thá»i kÃ¬ trÄƒm hoa Ä‘ua ná»Ÿ cá»§a cÃ¡c mÃ´ hÃ¬nh AI vá» ngÃ´n ngá»¯ lá»›n vá»›i kÃ­ch thÆ°á»›c hÃ ng trÄƒm tá»· tham sá»‘. Nhá»¯ng trá»Ÿ ngáº¡i vá» háº¡ táº§ng tÃ­nh toÃ¡n vÃ  dá»¯ liá»‡u lá»›n Ä‘Ã£ khiáº¿n cho nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi nhá»¯ng big tech tÃªn tuá»•i lá»›n. BLOOM nhÆ° má»™t mÃ´ hÃ¬nh Ä‘áº§u tiÃªn Ä‘Ã¡nh dáº¥u sá»± há»£p tÃ¡c tá»« cÃ¡c nhÃ  nghiÃªn cá»©u thuá»™c nhiá»u tá»• chá»©c khÃ¡c nhau nháº±m táº¡o ra má»™t mÃ´ hÃ¬nh minh báº¡ch, cÃ³ thá»ƒ kiáº¿m toÃ¡n Ä‘Æ°á»£c vÃ  mang tÃ­nh Ä‘áº¡i diá»‡n. Dá»± Ã¡n nhÆ° má»™t lá»i kháº³ng Ä‘á»‹nh ráº±ng sá»± há»£p tÃ¡c cÃ³ thá»ƒ mang láº¡i sá»©c máº¡nh Ä‘á»ƒ chá»‘ng láº¡i sá»± Ä‘á»™c quyá»n tá»« cÃ¡c big tech trong viá»‡c táº¡o ra Large Language Models.",,,,,
"Em chÃ o má»i ngÆ°á»i, em nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp em cÃ¢u há»i.
Em lÃ  sinh viÃªn nÄƒm 3, dá»± Ä‘á»‹nh theo hÆ°á»›ng Machine Learning Engineer, tuy nhiÃªn em cÃ³ tÃ¬m hiá»ƒu thÃ¬ tháº¥y Ä‘a sá»‘ khÃ´ng cÃ³ má»™t giÃ¡o trÃ¬nh Ä‘Ã o táº¡o chuyÃªn sÃ¢u cho máº£ng nÃ y.
Váº­y em muá»‘n theo Machine Learning Engineer thÃ¬ em cáº§n pháº£i há»c nhá»¯ng gÃ¬, lá»™ trÃ¬nh há»c nhÆ° tháº¿ nÃ o áº¡? 
Hiá»‡n em biáº¿t vá» Python vÃ  cÃ¡c thuáº­t toÃ¡n ML cÆ¡ báº£n.
Em nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp. Em lÃ  newbie áº¡, xin cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","Em chÃ o má»i ngÆ°á»i, em nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp em cÃ¢u há»i. Em lÃ  sinh viÃªn nÄƒm 3, dá»± Ä‘á»‹nh theo hÆ°á»›ng Machine Learning Engineer, tuy nhiÃªn em cÃ³ tÃ¬m hiá»ƒu thÃ¬ tháº¥y Ä‘a sá»‘ khÃ´ng cÃ³ má»™t giÃ¡o trÃ¬nh Ä‘Ã o táº¡o chuyÃªn sÃ¢u cho máº£ng nÃ y. Váº­y em muá»‘n theo Machine Learning Engineer thÃ¬ em cáº§n pháº£i há»c nhá»¯ng gÃ¬, lá»™ trÃ¬nh há»c nhÆ° tháº¿ nÃ o áº¡? Hiá»‡n em biáº¿t vá» Python vÃ  cÃ¡c thuáº­t toÃ¡n ML cÆ¡ báº£n. Em nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp. Em lÃ  newbie áº¡, xin cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"[Formal Algorithms for Transformers]

Ká»ƒ tá»« khi Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Google Brain vÃ o nÄƒm 2017, mÃ´ hÃ¬nh Transformer Ä‘áº¡t Ä‘Æ°á»£c ráº¥t nhiá»u thÃ nh cÃ´ng trÃªn nhiá»u lÄ©nh vá»±c nhÆ° xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP), xá»­ lÃ½ áº£nh (CV), Graph,... Ráº¥t nhiá»u paper liÃªn quan tá»›i Transformer vá»›i nhá»¯ng cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ Ä‘Ã£ Ä‘Æ°á»£c publish, tuy nhiÃªn ráº¥t Ã­t paper cÃ³ pseudocode (giáº£ mÃ£) - giáº£i thÃ­ch cÃ¡c bÆ°á»›c hoáº¡t Ä‘á»™ng cá»§a mÃ´ hÃ¬nh.

Gáº§n Ä‘Ã¢y, nhÃ³m nghiÃªn cá»©u tá»›i tá»« DeepMind Ä‘Ã£ cho xuáº¥t báº£n paper Formal Algorithms for Transformers, biá»ƒu diá»…n hÆ¡n 15 biáº¿n thá»ƒ cá»§a mÃ´ hÃ¬nh Transformer dÆ°á»›i dáº¡ng giáº£ mÃ£, ngáº¯n gá»n, xÃºc tÃ­ch vÃ  Ä‘áº§y Ä‘á»§ cÃ¡c bÆ°á»›c. ThÃªm vÃ o Ä‘Ã³, tÃ¡c giáº£ cÃ²n giáº£i thÃ­ch Transformer lÃ  gÃ¬, Ã½ tÆ°á»Ÿng kiáº¿n trÃºc mÃ´ hÃ¬nh tá»« Ä‘Ã¢u, cÃ¡ch tokenize dá»¯ liá»‡u tháº¿ nÃ o, lÃ m sao Ä‘á»ƒ train mÃ´ hÃ¬nh vÃ  nhá»¯ng lá»i khuyÃªn khi sá»­ dá»¥ng mÃ´ hÃ¬nh Transformer.

Paper: https://arxiv.org/pdf/2207.09238.pdf","[Formal Algorithms for Transformers] Ká»ƒ tá»« khi Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Google Brain vÃ o nÄƒm 2017, mÃ´ hÃ¬nh Transformer Ä‘áº¡t Ä‘Æ°á»£c ráº¥t nhiá»u thÃ nh cÃ´ng trÃªn nhiá»u lÄ©nh vá»±c nhÆ° xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP), xá»­ lÃ½ áº£nh (CV), Graph,... Ráº¥t nhiá»u paper liÃªn quan tá»›i Transformer vá»›i nhá»¯ng cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ Ä‘Ã£ Ä‘Æ°á»£c publish, tuy nhiÃªn ráº¥t Ã­t paper cÃ³ pseudocode (giáº£ mÃ£) - giáº£i thÃ­ch cÃ¡c bÆ°á»›c hoáº¡t Ä‘á»™ng cá»§a mÃ´ hÃ¬nh. Gáº§n Ä‘Ã¢y, nhÃ³m nghiÃªn cá»©u tá»›i tá»« DeepMind Ä‘Ã£ cho xuáº¥t báº£n paper Formal Algorithms for Transformers, biá»ƒu diá»…n hÆ¡n 15 biáº¿n thá»ƒ cá»§a mÃ´ hÃ¬nh Transformer dÆ°á»›i dáº¡ng giáº£ mÃ£, ngáº¯n gá»n, xÃºc tÃ­ch vÃ  Ä‘áº§y Ä‘á»§ cÃ¡c bÆ°á»›c. ThÃªm vÃ o Ä‘Ã³, tÃ¡c giáº£ cÃ²n giáº£i thÃ­ch Transformer lÃ  gÃ¬, Ã½ tÆ°á»Ÿng kiáº¿n trÃºc mÃ´ hÃ¬nh tá»« Ä‘Ã¢u, cÃ¡ch tokenize dá»¯ liá»‡u tháº¿ nÃ o, lÃ m sao Ä‘á»ƒ train mÃ´ hÃ¬nh vÃ  nhá»¯ng lá»i khuyÃªn khi sá»­ dá»¥ng mÃ´ hÃ¬nh Transformer. Paper: https://arxiv.org/pdf/2207.09238.pdf",,,,,
"Xin chÃ o má»i ngÆ°á»i!
Em/MÃ¬nh Ä‘ang vÆ°á»›ng váº¥n Ä‘á» triá»ƒn khai mÃ  lÃ¢u nay mÃ¬nh nghiÃªn cá»©u mÃ  chÆ°a cÃ³ giáº£i phÃ¡p há»¯u hiá»‡u. BÃ i toÃ¡n triá»ƒn khai Ä‘áº·t ra lÃ :
Nhiá»u IP cameras (truy cáº­p thÃ´ng qua rtsp) gá»­i dá»¯ liá»‡u vá» cho server. Server (chá»©a cÃ¡c mÃ´ hÃ¬nh AI cho bÃ i toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng) sáº½ xá»­ lÃ½, váº½ bouding boxes vÃ  lÆ°u trá»¯ khung áº£nh. Server streaming káº¿t quáº£ cho client (trÃ¬nh duyá»‡t web hoáº·c lÃ  desktop GUI (java, c#)).
Em/MÃ¬nh Ä‘Ã£ thá»­ nghiá»‡m:
Server Ä‘á»c báº±ng opencv, cÃ³ káº¿t quáº£ numpy vÃ  Ä‘Æ°a vÃ o mÃ´ hÃ¬nh AI, váº½ bouding boxes lÃªn frame, chuyá»ƒn thÃ nh dáº¡ng byte vÃ  truyá»n vá» cho browser dÆ°á»›i dáº¡ng HTTP response.
Váº¥n Ä‘á»:
+ Opencv Ä‘á»c cÃ¡c luá»“ng rtsps bá»‹ delay khÃ¡ nhiá»u.
+ Viá»‡c convert thÃ nh bytes vÃ  gá»­i vá» client qua giao thá»©c HTTP cÅ©ng máº¥t nhiá»u thá»i gian.
Em/mÃ¬nh nghÄ© cÃ³ thá»ƒ cÃ¡ch tiáº¿p cáº­n cá»§a mÃ¬nh Ä‘ang quÃ¡ Ä‘Æ¡n giáº£n. Mong nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ tá»« má»i ngÆ°á»i áº¡.","Xin chÃ o má»i ngÆ°á»i! Em/MÃ¬nh Ä‘ang vÆ°á»›ng váº¥n Ä‘á» triá»ƒn khai mÃ  lÃ¢u nay mÃ¬nh nghiÃªn cá»©u mÃ  chÆ°a cÃ³ giáº£i phÃ¡p há»¯u hiá»‡u. BÃ i toÃ¡n triá»ƒn khai Ä‘áº·t ra lÃ : Nhiá»u IP cameras (truy cáº­p thÃ´ng qua rtsp) gá»­i dá»¯ liá»‡u vá» cho server. Server (chá»©a cÃ¡c mÃ´ hÃ¬nh AI cho bÃ i toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng) sáº½ xá»­ lÃ½, váº½ bouding boxes vÃ  lÆ°u trá»¯ khung áº£nh. Server streaming káº¿t quáº£ cho client (trÃ¬nh duyá»‡t web hoáº·c lÃ  desktop GUI (java, c#)). Em/MÃ¬nh Ä‘Ã£ thá»­ nghiá»‡m: Server Ä‘á»c báº±ng opencv, cÃ³ káº¿t quáº£ numpy vÃ  Ä‘Æ°a vÃ o mÃ´ hÃ¬nh AI, váº½ bouding boxes lÃªn frame, chuyá»ƒn thÃ nh dáº¡ng byte vÃ  truyá»n vá» cho browser dÆ°á»›i dáº¡ng HTTP response. Váº¥n Ä‘á»: + Opencv Ä‘á»c cÃ¡c luá»“ng rtsps bá»‹ delay khÃ¡ nhiá»u. + Viá»‡c convert thÃ nh bytes vÃ  gá»­i vá» client qua giao thá»©c HTTP cÅ©ng máº¥t nhiá»u thá»i gian. Em/mÃ¬nh nghÄ© cÃ³ thá»ƒ cÃ¡ch tiáº¿p cáº­n cá»§a mÃ¬nh Ä‘ang quÃ¡ Ä‘Æ¡n giáº£n. Mong nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ tá»« má»i ngÆ°á»i áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang lÃ m Ä‘á»“ Ã¡n nghiÃªn cá»©u phÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n áº£nh giáº£ máº¡o dá»±a trÃªn há»c mÃ¡y. Anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u hay model liÃªn quan cho mÃ¬nh xin vá»›i áº¡.
CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u áº¡!",ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang lÃ m Ä‘á»“ Ã¡n nghiÃªn cá»©u phÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n áº£nh giáº£ máº¡o dá»±a trÃªn há»c mÃ¡y. Anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u hay model liÃªn quan cho mÃ¬nh xin vá»›i áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u áº¡!,,,,,
"MLOps lÃ  má»™t khÃ¡i niá»‡m khÃ¡ hot trong thá»i gian gáº§n Ä‘Ã¢y vÃ  ngÃ y cÃ ng Ä‘Æ°á»£c nhiá»u cÃ´ng ty á»©ng dá»¥ng Ä‘á»ƒ rÃºt ngáº¯n thá»i gian triá»ƒn khai vÃ  nÃ¢ng cao hiá»‡u quáº£ cÅ©ng nhÆ° Ä‘á»™ tin cáº­y cá»§a cÃ¡c há»‡ thá»‘ng ML. 
Váº­y MLOps lÃ  gÃ¬ vÃ  cÃ³ Ã­ch nhÆ° tháº¿ nÃ o Ä‘á»‘i vá»›i dá»± Ã¡n ML? Hy vá»ng bÃ i talk nhá» cá»§a mÃ¬nh cÃ³ thá»ƒ giÃºp má»i ngÆ°á»i nháº­n ra pháº§n nÃ o táº§m quan trá»ng cá»§a viá»‡c á»©ng dá»¥ng MLOps.
Video: https://www.youtube.com/watch?v=tBY5DZ5v0jQ
Slide: https://docs.google.com/presentation/d/1WEESpXdcL8qQDG4aAbdrmSYC-1BDNJGf0G9T0SkXFi4",MLOps lÃ  má»™t khÃ¡i niá»‡m khÃ¡ hot trong thá»i gian gáº§n Ä‘Ã¢y vÃ  ngÃ y cÃ ng Ä‘Æ°á»£c nhiá»u cÃ´ng ty á»©ng dá»¥ng Ä‘á»ƒ rÃºt ngáº¯n thá»i gian triá»ƒn khai vÃ  nÃ¢ng cao hiá»‡u quáº£ cÅ©ng nhÆ° Ä‘á»™ tin cáº­y cá»§a cÃ¡c há»‡ thá»‘ng ML. Váº­y MLOps lÃ  gÃ¬ vÃ  cÃ³ Ã­ch nhÆ° tháº¿ nÃ o Ä‘á»‘i vá»›i dá»± Ã¡n ML? Hy vá»ng bÃ i talk nhá» cá»§a mÃ¬nh cÃ³ thá»ƒ giÃºp má»i ngÆ°á»i nháº­n ra pháº§n nÃ o táº§m quan trá»ng cá»§a viá»‡c á»©ng dá»¥ng MLOps. Video: https://www.youtube.com/watch?v=tBY5DZ5v0jQ Slide: https://docs.google.com/presentation/d/1WEESpXdcL8qQDG4aAbdrmSYC-1BDNJGf0G9T0SkXFi4,,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» transfer learning trong bÃ i toÃ¡n phÃ¢n loáº¡i hÃ¬nh áº£nh.
HÃ´m nay, mÃ¬nh cÃ³ tham kháº£o má»™t mÃ£ nguá»“n trÃªn máº¡ng (nhÆ° áº£nh). Táº¡i Ä‘Ã¢y, tÃ¡c giáº£ khÃ´ng frozen pre-train model & fine-tune mÃ  sá»­ dá»¥ng trá»±c tiáº¿p pre-train model EfficientNet Ä‘á»ƒ phÃ¢n loáº¡i hÃ¬nh áº£nh.
Káº¿t quáº£ khi evaluation vá»›i cÃ¡c tham sá»‘: acc, f1 score,... cÅ©ng khÃ¡ tá»‘t
Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ¡ch tiáº¿p cáº­n cá»§a tÃ¡c gá»‰a Ä‘Æ°á»£c gá»i lÃ  gÃ¬? Cáº£m Æ¡n ace.","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» transfer learning trong bÃ i toÃ¡n phÃ¢n loáº¡i hÃ¬nh áº£nh. HÃ´m nay, mÃ¬nh cÃ³ tham kháº£o má»™t mÃ£ nguá»“n trÃªn máº¡ng (nhÆ° áº£nh). Táº¡i Ä‘Ã¢y, tÃ¡c giáº£ khÃ´ng frozen pre-train model & fine-tune mÃ  sá»­ dá»¥ng trá»±c tiáº¿p pre-train model EfficientNet Ä‘á»ƒ phÃ¢n loáº¡i hÃ¬nh áº£nh. Káº¿t quáº£ khi evaluation vá»›i cÃ¡c tham sá»‘: acc, f1 score,... cÅ©ng khÃ¡ tá»‘t Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ¡ch tiáº¿p cáº­n cá»§a tÃ¡c gá»‰a Ä‘Æ°á»£c gá»i lÃ  gÃ¬? Cáº£m Æ¡n ace.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 6/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 6/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"[Homework challenge lesson 10 - Probability distribution]
PhÃ¢n phá»‘i xÃ¡c suáº¥t lÃ  kiáº¿n thá»©c nguyÃªn lÃ½ vÃ  ná»n táº£ng cá»§a ráº¥t nhiá»u cÃ¡c á»©ng dá»¥ng trong lÄ©nh vá»±c thá»‘ng kÃª vÃ  machine learning. Dá»±a vÃ o phÃ¢n phá»‘i xÃ¡c suáº¥t chÃºng ta cÃ³ thá»ƒ mÃ´ phá»ng Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng vá» phÃ¢n bá»‘ dá»¯ liá»‡u cá»§a nhiá»u loáº¡i biáº¿n ngáº«u nhiÃªn liÃªn tá»¥c hoáº·c rá»i ráº¡c. Tá»« Ä‘Ã³ cÃ³ thá»ƒ tÃ­nh toÃ¡n, Æ°á»›c lÆ°á»£ng vÃ  dá»± bÃ¡o xÃ¡c suáº¥t, khoáº£ng tin cáº­y, kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿tâ€¦. vÃ  phÃ¡t triá»ƒn cÃ¡c thuáº­t toÃ¡n trong thá»‘ng kÃª vÃ  Machine Learning.
TrÃªn thá»±c táº¿, cÃ¡c phÃ¢n phá»‘i mÃ  chÃºng ta Ä‘Æ°á»£c há»c nhÆ° phÃ¢n phá»‘i Gaussian, T-student, Fisher, Chi-square, Uniform, Binary, Bernoulli, Poisson,â€¦ hoÃ n toÃ n khÃ´ng Ä‘Æ°á»£c tÃ¬m ra má»™t cÃ¡ch ngáº«u nhiÃªn mÃ  chÃºng Ä‘á»u dá»±a trÃªn viá»‡c quan sÃ¡t vÃ  thá»‘ng kÃª cÃ¡c máº«u kÃ­ch thÆ°á»›c lá»›n vÃ  theo má»™t cÃ¡ch tÃ¬nh cá» nÃ o Ä‘Ã³, nhá»¯ng qui luáº­t nÃ y Ä‘Æ°á»£c phÃ¡t hiá»‡n ra vÃ  Ä‘Ãºng trÃªn ráº¥t nhiá»u dá»¯ liá»‡u. CÃ³ nhiá»u nhÃ  khoa há»c cho ráº±ng toÃ¡n há»c khÃ´ng pháº£i lÃ  do con ngÆ°á»i nghÄ© ra mÃ  Ä‘Ã³ lÃ  qui luáº­t cá»§a vÅ© trá»¥, con ngÆ°á»i chá»‰ tÃ¬nh cá» phÃ¡t hiá»‡n ra chÃºng. Pháº£i chÄƒng Ä‘iá»u nÃ y lÃ  sá»± tháº­t? Sau cÃ¹ng lÃ  ná»— lá»±c lá»›n lao cá»§a cÃ¡c nhÃ  ToÃ¡n há»c nháº±m mÃ´ hÃ¬nh hÃ³a nhá»¯ng qui luáº­t tá»± nhiÃªn nÃ y thÃ nh má»™t phÆ°Æ¡ng trÃ¬nh máº«u má»±c mÃ  chÃºng ta thÆ°á»ng gá»i lÃ  hÃ m máº­t Ä‘á»™ xÃ¡c suáº¥t (probability density function Ä‘á»‘i vá»›i biáº¿n liÃªn tá»¥c) hoáº·c hÃ m khá»‘i xÃ¡c suáº¥t (probability mass function Ä‘á»‘i vá»›i biáº¿n rá»i ráº¡c).
Cháº³ng háº¡n nhÃ  toÃ¡n há»c Gauss Ä‘Ã£ tÃ¬m ra phÃ¢n phá»‘i Gaussian khi Ã´ng quan sÃ¡t Ä‘á»“ thá»‹ phÃ¢n phá»‘i cá»§a cÃ¡c biáº¿n ngáº«u nhiÃªn liÃªn tá»¥c vÃ  Ã´ng nháº­n ra chÃºng Ä‘á»u cÃ³ hÃ¬nh dáº¡ng giá»‘ng nhau lÃ  má»™t quáº£ chuÃ´ng Ä‘á»‘i xá»©ng hai bÃªn. Vá»›i má»™t nhÃ  toÃ¡n há»c thiÃªn tÃ i vá» tÃ­nh toÃ¡n nhÆ° Gauss thÃ¬ viá»‡c tÃ¬m ra má»™t phÆ°Æ¡ng trÃ¬nh pdf dá»±a trÃªn trung bÃ¬nh vÃ  phÆ°Æ¡ng sai lÃ  Ä‘iá»u mÃ  mÃ¬nh nghÄ© lÃ  khÃ´ng khÃ³. Äá»«ng quÃªn ráº±ng Ã´ng Ä‘Ã£ biáº¿t cÃ¡ch tÃ­nh nháº©m tá»•ng cÃ¡c sá»‘ tá»« 1 â†’ 100 ngay tá»« lá»›p 2, cÃ´ng thá»©c mÃ  ngÃ y nay há»c sinh tiá»ƒu há»c Ä‘Æ°á»£c há»c thuá»™c lÃ²ng. Sau nÃ y khi Ä‘Ã£ lÃ  má»™t nhÃ  toÃ¡n há»c, nhá» kháº£ nÄƒng tÃ­nh toÃ¡n, Ã´ng Ä‘Ã£ giÃºp tÃ¬m láº¡i má»™t tiá»ƒu hÃ nh tinh bá»‹ tháº¥t láº¡c dá»±a vÃ o cÃ¡c sá»‘ liá»‡u Ã­t á»i trÆ°á»›c Ä‘Ã³ Ä‘Æ°á»£c ghi chÃ©p trÆ°á»›c khi nÃ³ bá»‹ láº«n vÃ o Ã¡nh sÃ¡ng cá»§a cÃ¡c ngÃ´i sao khÃ¡c. NgÆ°á»i Äá»©c vÃ´ cÃ¹ng tá»± hÃ o vá» viá»‡c phÃ¡t minh ra phÃ¢n phá»‘i chuáº©n cá»§a Gauss vÃ  há» Ä‘Ã£ vinh danh Ã´ng trÃªn Ä‘á»“ng tiá»n kÃ¨m theo má»™t hÃ¬nh quáº£ chuÃ´ng chuáº©n. CÃ´ng thá»©c phÃ¢n phá»‘i chuáº©n Ä‘Ã£ trá»Ÿ thÃ nh má»™t trong 10 phÆ°Æ¡ng trÃ¬nh Ä‘áº¹p nháº¥t cá»§a nháº¥t loáº¡i.
Sá»± tÃ i tÃ¬nh cá»§a Gauss Ä‘Ã³ lÃ  Ã´ng Ä‘Ã£ tÃ¬m ra Ä‘Ãºng cÃ¡c tham sá»‘ áº£nh Ä‘á»ƒ mÃ´ phá»ng hÃ¬nh dáº¡ng quáº£ chuÃ´ng lÃ  trung bÃ¬nh vÃ  phÆ°Æ¡ng sai. Äiá»u mÃ  pháº£i ráº¥t thÃ´ng minh vÃ  tinh táº¿ má»›i phÃ¡t hiá»‡n ra Ä‘Æ°á»£c. Sau Ä‘Ã³ thÃ¬ viá»‡c tÃ¬m kiáº¿m phÆ°Æ¡ng trÃ¬nh mÃ´ phá»ng chá»‰ nhÆ° lÃ  cÃ´ng viá»‡c nhiá»u niÃªm vui vÃ  mang tÃ­nh giáº£i trÃ­ Ä‘á»‘i vá»›i Ã´ng, má»™t nhÃ  toÃ¡n há»c lá»—i láº¡c vá»›i ráº¥t nhiá»u ká»‰ lá»¥c.
ThÃ nh cÃ´ng cá»§a phÃ¢n phá»‘i Gaussian giÃºp chÃºng ta nháº­n ra ráº±ng viá»‡c xÃ¡c Ä‘á»‹nh há» tham sá»‘ Ä‘áº·c trÆ°ng (parameter family) cá»§a tá»«ng dáº¡ng phÃ¢n phá»‘i lÃ  ráº¥t quan trá»ng. Tá»« Ä‘Ã³ tÃ¬m ra Æ°á»›c lÆ°á»£ng há»£p lÃ½ nháº¥t cá»§a chÃºng trÃªn má»™t bá»™ dá»¯ liá»‡u cá»¥ thá»ƒ thÃ´ng qua viá»‡c tÃ¬m kiáº¿m giÃ¡ trá»‹ tham sá»‘ mÃ  bá»™ dá»¯ liá»‡u lÃ  há»£p lÃ½ nháº¥t. Má»©c Ä‘á»™ há»£p lÃ½ Ä‘Æ°á»£c Ä‘o lÆ°á»ng báº±ng má»™t hÃ m há»£p lÃ½ (Likelihood Function) mÃ  hÃ m nÃ y thá»ƒ hiá»‡n xÃ¡c suáº¥t cá»§a dá»¯ liá»‡u. VÃ  nhÆ° váº­y quÃ¡ trÃ¬nh Æ°á»›c lÆ°á»£ng thÆ°á»ng dáº«n tá»›i bÃ i toÃ¡n tá»‘i Ä‘a hÃ³a hÃ m há»£p lÃ½ (Maximum Likelihood Function). Äá»“ng thá»i Æ°á»›c lÆ°á»£ng tÃ¬m Ä‘Æ°á»£c cá»§a bÃ i toÃ¡n tá»‘i Æ°u nÃ y Ä‘Æ°á»£c gá»i lÃ  Æ°á»›c lÆ°á»£ng há»£p lÃ½ tá»‘i Ä‘a (Maximum Likelihood Estimation).
Æ¯á»›c lÆ°á»£ng há»£p lÃ½ tá»‘i Ä‘a cÃ³ ráº¥t nhiá»u á»©ng dá»¥ng trong thá»‘ng kÃª. ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p cho phÃ©p ta tÃ¬m ra Ä‘Æ°á»£c cÃ¡c tham sá»‘ tá»‘i Æ°u cá»§a má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t cá»¥ thá»ƒ. Tá»« Ä‘Ã³ dá»±a vÃ o phÃ¢n phá»‘i cá»§a chÃºng, chÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c nhiá»u viá»‡c mÃ  má»™t trong sá»‘ chÃºng quan trá»ng nháº¥t lÃ : Æ¯á»›c lÆ°á»£ng khoáº£ng tin cáº­y; xÃ¢y dá»±ng vÃ  kiá»ƒm Ä‘á»‹nh cÃ¡c giáº£ thuyáº¿t vá»›i má»™t má»©c Ä‘á»™ tin cáº­y cao (thÆ°á»ng lÃ  95%); TÃ­nh toÃ¡n xÃ¡c suáº¥t cá»§a biáº¿n khi chÃºng rÆ¡i vÃ o má»™t miá»n giÃ¡ trá»‹ cá»¥ thá»ƒ.
ThÃ´ng kÃª lÃ  má»™t ngÃ nh há»c lÃ¢u Ä‘á»i mÃ  ban Ä‘áº§u Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn ná»n táº£ng cá»§a phÃ¢n phá»‘i xÃ¡c suáº¥t vÃ  toÃ¡n há»c. ChÃ­nh vÃ¬ váº­y trÆ°á»›c khi há»c vá» thá»‘ng kÃª thÃ¬ báº¡n cáº§n náº¯m vá»¯ng vá» xÃ¡c suáº¥t trÆ°á»›c. Káº¿t há»£p hai lÄ©nh vá»±c nÃ y láº¡i lÃ  mÃ´n há»c kinh Ä‘iá»ƒn XÃ¡c suáº¥t Thá»‘ng kÃª, má»™t mÃ´n há»c Ä‘áº§y thÃº vá»‹, khÃ´ng quÃ¡ khÃ³, nhÆ°ng cÅ©ng tiÃªu tá»‘n khÃ¡ nhiá»u tiá»n há»c nÃ¢ng Ä‘iá»ƒm cá»§a sinh viÃªn. Báº¡n cÃ³ thá»ƒ khÃ´ng yÃªu thÃ­ch xÃ¡c suáº¥t vÃ  thá»‘ng kÃª láº¯m, vÃ  báº¡n nghÄ© nÃ³ khÃ´ng quan trá»ng. NhÆ°ng cÃ¡c báº¡n cÃ³ biáº¿t ráº±ng cÃ³ ráº¥t nhiá»u cÃ¡c qui luáº­t phÃ¢n phá»‘i trong thá»‘ng kÃª Ä‘ang tri phá»‘i Ä‘áº¿n cuá»™c sá»‘ng cá»§a chÃºng ta hÃ ng ngÃ y mÃ  mÃ¬nh tin ráº±ng náº¯m báº¯t Ä‘Æ°á»£c chÃºng sáº½ ráº¥t ráº¥t há»¯u Ã­ch. Bá»Ÿi nhá»¯ng qui luáº­t nÃ y ráº¥t quan trá»ng nÃªn cÃ³ nhiá»u lÄ©nh vá»±c, ngÃ nh nghá» khÃ¡c nhau nhÆ° quáº£n trá»‹ rá»§i ro, tÃ i chÃ­nh ngÃ¢n hÃ ng, báº£o hiá»ƒm, kinh táº¿ há»c, xÃ£ há»™i há»c, marketing,â€¦ Ä‘ang á»©ng dá»¥ng thá»‘ng kÃª Ä‘á»ƒ tÃ¬m ra má»™t phÆ°Æ¡ng cÃ¡ch quáº£n trá»‹ vÃ  kiá»ƒm soÃ¡t tá»‘t hÆ¡n cho cÃ¡c sá»± kiá»‡n khÃ´ng cháº¯c cháº¯n.
Cuá»‘i cÃ¹ng, Ä‘á»ƒ cá»§ng cá»‘ kiáº¿n thá»©c vá» phÃ¢n phá»‘i xÃ¡c suáº¥t sáº½ lÃ  má»™t Ä‘á» kiá»ƒm tra nho nhá» dÃ nh cho cÃ¡c báº¡n.","[Homework challenge lesson 10 - Probability distribution] PhÃ¢n phá»‘i xÃ¡c suáº¥t lÃ  kiáº¿n thá»©c nguyÃªn lÃ½ vÃ  ná»n táº£ng cá»§a ráº¥t nhiá»u cÃ¡c á»©ng dá»¥ng trong lÄ©nh vá»±c thá»‘ng kÃª vÃ  machine learning. Dá»±a vÃ o phÃ¢n phá»‘i xÃ¡c suáº¥t chÃºng ta cÃ³ thá»ƒ mÃ´ phá»ng Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng vá» phÃ¢n bá»‘ dá»¯ liá»‡u cá»§a nhiá»u loáº¡i biáº¿n ngáº«u nhiÃªn liÃªn tá»¥c hoáº·c rá»i ráº¡c. Tá»« Ä‘Ã³ cÃ³ thá»ƒ tÃ­nh toÃ¡n, Æ°á»›c lÆ°á»£ng vÃ  dá»± bÃ¡o xÃ¡c suáº¥t, khoáº£ng tin cáº­y, kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿tâ€¦. vÃ  phÃ¡t triá»ƒn cÃ¡c thuáº­t toÃ¡n trong thá»‘ng kÃª vÃ  Machine Learning. TrÃªn thá»±c táº¿, cÃ¡c phÃ¢n phá»‘i mÃ  chÃºng ta Ä‘Æ°á»£c há»c nhÆ° phÃ¢n phá»‘i Gaussian, T-student, Fisher, Chi-square, Uniform, Binary, Bernoulli, Poisson,â€¦ hoÃ n toÃ n khÃ´ng Ä‘Æ°á»£c tÃ¬m ra má»™t cÃ¡ch ngáº«u nhiÃªn mÃ  chÃºng Ä‘á»u dá»±a trÃªn viá»‡c quan sÃ¡t vÃ  thá»‘ng kÃª cÃ¡c máº«u kÃ­ch thÆ°á»›c lá»›n vÃ  theo má»™t cÃ¡ch tÃ¬nh cá» nÃ o Ä‘Ã³, nhá»¯ng qui luáº­t nÃ y Ä‘Æ°á»£c phÃ¡t hiá»‡n ra vÃ  Ä‘Ãºng trÃªn ráº¥t nhiá»u dá»¯ liá»‡u. CÃ³ nhiá»u nhÃ  khoa há»c cho ráº±ng toÃ¡n há»c khÃ´ng pháº£i lÃ  do con ngÆ°á»i nghÄ© ra mÃ  Ä‘Ã³ lÃ  qui luáº­t cá»§a vÅ© trá»¥, con ngÆ°á»i chá»‰ tÃ¬nh cá» phÃ¡t hiá»‡n ra chÃºng. Pháº£i chÄƒng Ä‘iá»u nÃ y lÃ  sá»± tháº­t? Sau cÃ¹ng lÃ  ná»— lá»±c lá»›n lao cá»§a cÃ¡c nhÃ  ToÃ¡n há»c nháº±m mÃ´ hÃ¬nh hÃ³a nhá»¯ng qui luáº­t tá»± nhiÃªn nÃ y thÃ nh má»™t phÆ°Æ¡ng trÃ¬nh máº«u má»±c mÃ  chÃºng ta thÆ°á»ng gá»i lÃ  hÃ m máº­t Ä‘á»™ xÃ¡c suáº¥t (probability density function Ä‘á»‘i vá»›i biáº¿n liÃªn tá»¥c) hoáº·c hÃ m khá»‘i xÃ¡c suáº¥t (probability mass function Ä‘á»‘i vá»›i biáº¿n rá»i ráº¡c). Cháº³ng háº¡n nhÃ  toÃ¡n há»c Gauss Ä‘Ã£ tÃ¬m ra phÃ¢n phá»‘i Gaussian khi Ã´ng quan sÃ¡t Ä‘á»“ thá»‹ phÃ¢n phá»‘i cá»§a cÃ¡c biáº¿n ngáº«u nhiÃªn liÃªn tá»¥c vÃ  Ã´ng nháº­n ra chÃºng Ä‘á»u cÃ³ hÃ¬nh dáº¡ng giá»‘ng nhau lÃ  má»™t quáº£ chuÃ´ng Ä‘á»‘i xá»©ng hai bÃªn. Vá»›i má»™t nhÃ  toÃ¡n há»c thiÃªn tÃ i vá» tÃ­nh toÃ¡n nhÆ° Gauss thÃ¬ viá»‡c tÃ¬m ra má»™t phÆ°Æ¡ng trÃ¬nh pdf dá»±a trÃªn trung bÃ¬nh vÃ  phÆ°Æ¡ng sai lÃ  Ä‘iá»u mÃ  mÃ¬nh nghÄ© lÃ  khÃ´ng khÃ³. Äá»«ng quÃªn ráº±ng Ã´ng Ä‘Ã£ biáº¿t cÃ¡ch tÃ­nh nháº©m tá»•ng cÃ¡c sá»‘ tá»« 1 â†’ 100 ngay tá»« lá»›p 2, cÃ´ng thá»©c mÃ  ngÃ y nay há»c sinh tiá»ƒu há»c Ä‘Æ°á»£c há»c thuá»™c lÃ²ng. Sau nÃ y khi Ä‘Ã£ lÃ  má»™t nhÃ  toÃ¡n há»c, nhá» kháº£ nÄƒng tÃ­nh toÃ¡n, Ã´ng Ä‘Ã£ giÃºp tÃ¬m láº¡i má»™t tiá»ƒu hÃ nh tinh bá»‹ tháº¥t láº¡c dá»±a vÃ o cÃ¡c sá»‘ liá»‡u Ã­t á»i trÆ°á»›c Ä‘Ã³ Ä‘Æ°á»£c ghi chÃ©p trÆ°á»›c khi nÃ³ bá»‹ láº«n vÃ o Ã¡nh sÃ¡ng cá»§a cÃ¡c ngÃ´i sao khÃ¡c. NgÆ°á»i Äá»©c vÃ´ cÃ¹ng tá»± hÃ o vá» viá»‡c phÃ¡t minh ra phÃ¢n phá»‘i chuáº©n cá»§a Gauss vÃ  há» Ä‘Ã£ vinh danh Ã´ng trÃªn Ä‘á»“ng tiá»n kÃ¨m theo má»™t hÃ¬nh quáº£ chuÃ´ng chuáº©n. CÃ´ng thá»©c phÃ¢n phá»‘i chuáº©n Ä‘Ã£ trá»Ÿ thÃ nh má»™t trong 10 phÆ°Æ¡ng trÃ¬nh Ä‘áº¹p nháº¥t cá»§a nháº¥t loáº¡i. Sá»± tÃ i tÃ¬nh cá»§a Gauss Ä‘Ã³ lÃ  Ã´ng Ä‘Ã£ tÃ¬m ra Ä‘Ãºng cÃ¡c tham sá»‘ áº£nh Ä‘á»ƒ mÃ´ phá»ng hÃ¬nh dáº¡ng quáº£ chuÃ´ng lÃ  trung bÃ¬nh vÃ  phÆ°Æ¡ng sai. Äiá»u mÃ  pháº£i ráº¥t thÃ´ng minh vÃ  tinh táº¿ má»›i phÃ¡t hiá»‡n ra Ä‘Æ°á»£c. Sau Ä‘Ã³ thÃ¬ viá»‡c tÃ¬m kiáº¿m phÆ°Æ¡ng trÃ¬nh mÃ´ phá»ng chá»‰ nhÆ° lÃ  cÃ´ng viá»‡c nhiá»u niÃªm vui vÃ  mang tÃ­nh giáº£i trÃ­ Ä‘á»‘i vá»›i Ã´ng, má»™t nhÃ  toÃ¡n há»c lá»—i láº¡c vá»›i ráº¥t nhiá»u ká»‰ lá»¥c. ThÃ nh cÃ´ng cá»§a phÃ¢n phá»‘i Gaussian giÃºp chÃºng ta nháº­n ra ráº±ng viá»‡c xÃ¡c Ä‘á»‹nh há» tham sá»‘ Ä‘áº·c trÆ°ng (parameter family) cá»§a tá»«ng dáº¡ng phÃ¢n phá»‘i lÃ  ráº¥t quan trá»ng. Tá»« Ä‘Ã³ tÃ¬m ra Æ°á»›c lÆ°á»£ng há»£p lÃ½ nháº¥t cá»§a chÃºng trÃªn má»™t bá»™ dá»¯ liá»‡u cá»¥ thá»ƒ thÃ´ng qua viá»‡c tÃ¬m kiáº¿m giÃ¡ trá»‹ tham sá»‘ mÃ  bá»™ dá»¯ liá»‡u lÃ  há»£p lÃ½ nháº¥t. Má»©c Ä‘á»™ há»£p lÃ½ Ä‘Æ°á»£c Ä‘o lÆ°á»ng báº±ng má»™t hÃ m há»£p lÃ½ (Likelihood Function) mÃ  hÃ m nÃ y thá»ƒ hiá»‡n xÃ¡c suáº¥t cá»§a dá»¯ liá»‡u. VÃ  nhÆ° váº­y quÃ¡ trÃ¬nh Æ°á»›c lÆ°á»£ng thÆ°á»ng dáº«n tá»›i bÃ i toÃ¡n tá»‘i Ä‘a hÃ³a hÃ m há»£p lÃ½ (Maximum Likelihood Function). Äá»“ng thá»i Æ°á»›c lÆ°á»£ng tÃ¬m Ä‘Æ°á»£c cá»§a bÃ i toÃ¡n tá»‘i Æ°u nÃ y Ä‘Æ°á»£c gá»i lÃ  Æ°á»›c lÆ°á»£ng há»£p lÃ½ tá»‘i Ä‘a (Maximum Likelihood Estimation). Æ¯á»›c lÆ°á»£ng há»£p lÃ½ tá»‘i Ä‘a cÃ³ ráº¥t nhiá»u á»©ng dá»¥ng trong thá»‘ng kÃª. ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p cho phÃ©p ta tÃ¬m ra Ä‘Æ°á»£c cÃ¡c tham sá»‘ tá»‘i Æ°u cá»§a má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t cá»¥ thá»ƒ. Tá»« Ä‘Ã³ dá»±a vÃ o phÃ¢n phá»‘i cá»§a chÃºng, chÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c nhiá»u viá»‡c mÃ  má»™t trong sá»‘ chÃºng quan trá»ng nháº¥t lÃ : Æ¯á»›c lÆ°á»£ng khoáº£ng tin cáº­y; xÃ¢y dá»±ng vÃ  kiá»ƒm Ä‘á»‹nh cÃ¡c giáº£ thuyáº¿t vá»›i má»™t má»©c Ä‘á»™ tin cáº­y cao (thÆ°á»ng lÃ  95%); TÃ­nh toÃ¡n xÃ¡c suáº¥t cá»§a biáº¿n khi chÃºng rÆ¡i vÃ o má»™t miá»n giÃ¡ trá»‹ cá»¥ thá»ƒ. ThÃ´ng kÃª lÃ  má»™t ngÃ nh há»c lÃ¢u Ä‘á»i mÃ  ban Ä‘áº§u Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn ná»n táº£ng cá»§a phÃ¢n phá»‘i xÃ¡c suáº¥t vÃ  toÃ¡n há»c. ChÃ­nh vÃ¬ váº­y trÆ°á»›c khi há»c vá» thá»‘ng kÃª thÃ¬ báº¡n cáº§n náº¯m vá»¯ng vá» xÃ¡c suáº¥t trÆ°á»›c. Káº¿t há»£p hai lÄ©nh vá»±c nÃ y láº¡i lÃ  mÃ´n há»c kinh Ä‘iá»ƒn XÃ¡c suáº¥t Thá»‘ng kÃª, má»™t mÃ´n há»c Ä‘áº§y thÃº vá»‹, khÃ´ng quÃ¡ khÃ³, nhÆ°ng cÅ©ng tiÃªu tá»‘n khÃ¡ nhiá»u tiá»n há»c nÃ¢ng Ä‘iá»ƒm cá»§a sinh viÃªn. Báº¡n cÃ³ thá»ƒ khÃ´ng yÃªu thÃ­ch xÃ¡c suáº¥t vÃ  thá»‘ng kÃª láº¯m, vÃ  báº¡n nghÄ© nÃ³ khÃ´ng quan trá»ng. NhÆ°ng cÃ¡c báº¡n cÃ³ biáº¿t ráº±ng cÃ³ ráº¥t nhiá»u cÃ¡c qui luáº­t phÃ¢n phá»‘i trong thá»‘ng kÃª Ä‘ang tri phá»‘i Ä‘áº¿n cuá»™c sá»‘ng cá»§a chÃºng ta hÃ ng ngÃ y mÃ  mÃ¬nh tin ráº±ng náº¯m báº¯t Ä‘Æ°á»£c chÃºng sáº½ ráº¥t ráº¥t há»¯u Ã­ch. Bá»Ÿi nhá»¯ng qui luáº­t nÃ y ráº¥t quan trá»ng nÃªn cÃ³ nhiá»u lÄ©nh vá»±c, ngÃ nh nghá» khÃ¡c nhau nhÆ° quáº£n trá»‹ rá»§i ro, tÃ i chÃ­nh ngÃ¢n hÃ ng, báº£o hiá»ƒm, kinh táº¿ há»c, xÃ£ há»™i há»c, marketing,â€¦ Ä‘ang á»©ng dá»¥ng thá»‘ng kÃª Ä‘á»ƒ tÃ¬m ra má»™t phÆ°Æ¡ng cÃ¡ch quáº£n trá»‹ vÃ  kiá»ƒm soÃ¡t tá»‘t hÆ¡n cho cÃ¡c sá»± kiá»‡n khÃ´ng cháº¯c cháº¯n. Cuá»‘i cÃ¹ng, Ä‘á»ƒ cá»§ng cá»‘ kiáº¿n thá»©c vá» phÃ¢n phá»‘i xÃ¡c suáº¥t sáº½ lÃ  má»™t Ä‘á» kiá»ƒm tra nho nhá» dÃ nh cho cÃ¡c báº¡n.",,"#sharing, #math",,,
"[labmlai- Deep Learning Paper Implementations - 10,9k stars]
labmlai- Deep Learning Paper Implementations lÃ  táº­p há»£p hÆ°á»›ng dáº«n triá»ƒn khai cÃ¡c paper deep learning báº±ng Pytorch. CÃ¡c triá»ƒn khai nÃ y Ä‘Æ°á»£c viáº¿t vá»›i cÃ¡c hÆ°á»›ng dáº«n vÃ  code song song vá»›i nhau (side-by-side notes ğŸ“), bÃªn trÃ¡i lÃ  hÆ°á»›ng dáº«n, giáº£i thÃ­ch vÃ  bÃªn pháº£i lÃ  code giÃºp ngÆ°á»i Ä‘á»c cÃ³ thá»ƒ dá»… hiá»ƒu nháº¥t.
CÃ¡c triá»ƒn khai nÃ y bao gá»“m cÃ¡c topic quen thuá»™c nhÆ° :
- transformers (original, xl, switch, feedback, vit, ...)
- optimizers (adam, adabelief, ...)
- gans(cyclegan, stylegan2, ...)
- reinforcement learning (ppo, dqn),
- capsnet, distillation
Má»i ngÆ°á»i xem chi tiáº¿t á»Ÿ Ä‘Ã¢y:
Web: https://nn.labml.ai/
Github: https://github.com/labmlai/annotated_deep_learning_paper_implementations","[labmlai- Deep Learning Paper Implementations - 10,9k stars] labmlai- Deep Learning Paper Implementations lÃ  táº­p há»£p hÆ°á»›ng dáº«n triá»ƒn khai cÃ¡c paper deep learning báº±ng Pytorch. CÃ¡c triá»ƒn khai nÃ y Ä‘Æ°á»£c viáº¿t vá»›i cÃ¡c hÆ°á»›ng dáº«n vÃ  code song song vá»›i nhau (side-by-side notes ), bÃªn trÃ¡i lÃ  hÆ°á»›ng dáº«n, giáº£i thÃ­ch vÃ  bÃªn pháº£i lÃ  code giÃºp ngÆ°á»i Ä‘á»c cÃ³ thá»ƒ dá»… hiá»ƒu nháº¥t. CÃ¡c triá»ƒn khai nÃ y bao gá»“m cÃ¡c topic quen thuá»™c nhÆ° : - transformers (original, xl, switch, feedback, vit, ...) - optimizers (adam, adabelief, ...) - gans(cyclegan, stylegan2, ...) - reinforcement learning (ppo, dqn), - capsnet, distillation Má»i ngÆ°á»i xem chi tiáº¿t á»Ÿ Ä‘Ã¢y: Web: https://nn.labml.ai/ Github: https://github.com/labmlai/annotated_deep_learning_paper_implementations",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 3/2022 vÃ o trong comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 3/2022 vÃ o trong comment cá»§a post nÃ y.",,,,,
"VietAI cÃ´ng bá»‘ mÃ´ hÃ¬nh ngÃ´n ngá»¯ dÃ¹ng riÃªng cho tiáº¿ng Viá»‡t:
ğŸ“ŒGPT-3 1.3 tá»· tham sá»‘ (cÃ³ thá»ƒ tráº£i nghiá»‡m trá»±c tiáº¿p trÃªn Hugging Face Hub giá»‘ng nhÆ° trong video): https://huggingface.co/VietAI/gpt-neo-1.3B-vietnamese-news.
ğŸ“ŒGPT-3 6 tá»· tham sá»‘ (cáº§n download vá» má»™t mÃ¡y tÃ­nh cÃ³ Ä‘á»§ tÃ i nguyÃªn Ä‘á»ƒ thá»±c hiá»‡n inference - tá»‘i thiá»ƒu 12GB RAM): https://huggingface.co/VietAI/gpt-j-6B-vietnamese-news.",VietAI cÃ´ng bá»‘ mÃ´ hÃ¬nh ngÃ´n ngá»¯ dÃ¹ng riÃªng cho tiáº¿ng Viá»‡t: GPT-3 1.3 tá»· tham sá»‘ (cÃ³ thá»ƒ tráº£i nghiá»‡m trá»±c tiáº¿p trÃªn Hugging Face Hub giá»‘ng nhÆ° trong video): https://huggingface.co/VietAI/gpt-neo-1.3B-vietnamese-news. GPT-3 6 tá»· tham sá»‘ (cáº§n download vá» má»™t mÃ¡y tÃ­nh cÃ³ Ä‘á»§ tÃ i nguyÃªn Ä‘á»ƒ thá»±c hiá»‡n inference - tá»‘i thiá»ƒu 12GB RAM): https://huggingface.co/VietAI/gpt-j-6B-vietnamese-news.,,,,,
"Em chaÌ€o moÌ£i ngÆ°Æ¡Ì€i. Em coÌ mÃ´Ì£t baÌ€i tÃ¢Ì£p nhoÌ‰ vÃªÌ€ linear programming vaÌ€ maximizing value by Excel. CuÌ£ thÃªÌ‰ laÌ€ vÃªÌ€ mÃ´Ì£t doanh nghiÃªÌ£p Ä‘ang muÃ´Ìn phÃ¢n tiÌch 2 loaÌ£i maÌy Ä‘ÃªÌ‰ saÌ‰n xuÃ¢Ìt vaÌ€ Ä‘aÌ£t tÃ´Ìi Ä‘a doanh thu. LoaÌ£i maÌy X vaÌ€ Y coÌ caÌc data khaÌc nhau nhÆ°: Amount/hour laÌ€ mÃ´Ì£t tiÃªÌng cÆ¡ sÆ¡Ì‰ Ä‘oÌ coÌ thÃªÌ‰ saÌ‰n xuÃ¢Ìt Ä‘Æ°Æ¡Ì£c bao nhiÃªu maÌy. Profit/unit laÌ€ mÃ´Ìƒi maÌy baÌn ra thu dc bao nhiÃªu lÆ¡Ì£i nhuÃ¢Ì£n. Capacity/week laÌ€ mÃ´Ìƒi tuÃ¢Ì€n, nhaÌ€ maÌy coÌ thÃªÌ‰ saÌ‰n xuÃ¢Ìt tÃ´Ìi Ä‘a bao nhiÃªu maÌy. VaÌ€ Hour/week laÌ€ mÃ´Ìƒi tuÃ¢Ì€n nhaÌ€ maÌy coÌ thÃªÌ‰ vÃ¢Ì£n haÌ€nh trong bao nhiÃªu giÆ¡Ì€, cÆ¡ baÌ‰n laÌ€ chiÌ‰ coÌ 40 giÆ¡Ì€ mÃ´Ìƒi tuÃ¢Ì€n. Mong moÌ£i ngÆ°Æ¡Ì€i giuÌp em tiÌ€m hÆ°Æ¡Ìng giaÌ‰i quyÃªÌt vÃ¢Ìn Ä‘ÃªÌ€ aÌ£ (objective function and constraints) Ä‘ÃªÌ‰ thoÌ‰a maÌƒn caÌc cÃ¢u hoÌ‰i Æ¡Ì‰ Ã´ bÃªn phaÌ‰i. Em xin caÌ‰m Æ¡n aÌ£!","Em chaÌ€o moÌ£i ngÆ°Æ¡Ì€i. Em coÌ mÃ´Ì£t baÌ€i tÃ¢Ì£p nhoÌ‰ vÃªÌ€ linear programming vaÌ€ maximizing value by Excel. CuÌ£ thÃªÌ‰ laÌ€ vÃªÌ€ mÃ´Ì£t doanh nghiÃªÌ£p Ä‘ang muÃ´Ìn phÃ¢n tiÌch 2 loaÌ£i maÌy Ä‘ÃªÌ‰ saÌ‰n xuÃ¢Ìt vaÌ€ Ä‘aÌ£t tÃ´Ìi Ä‘a doanh thu. LoaÌ£i maÌy X vaÌ€ Y coÌ caÌc data khaÌc nhau nhÆ°: Amount/hour laÌ€ mÃ´Ì£t tiÃªÌng cÆ¡ sÆ¡Ì‰ Ä‘oÌ coÌ thÃªÌ‰ saÌ‰n xuÃ¢Ìt Ä‘Æ°Æ¡Ì£c bao nhiÃªu maÌy. Profit/unit laÌ€ mÃ´Ìƒi maÌy baÌn ra thu dc bao nhiÃªu lÆ¡Ì£i nhuÃ¢Ì£n. Capacity/week laÌ€ mÃ´Ìƒi tuÃ¢Ì€n, nhaÌ€ maÌy coÌ thÃªÌ‰ saÌ‰n xuÃ¢Ìt tÃ´Ìi Ä‘a bao nhiÃªu maÌy. VaÌ€ Hour/week laÌ€ mÃ´Ìƒi tuÃ¢Ì€n nhaÌ€ maÌy coÌ thÃªÌ‰ vÃ¢Ì£n haÌ€nh trong bao nhiÃªu giÆ¡Ì€, cÆ¡ baÌ‰n laÌ€ chiÌ‰ coÌ 40 giÆ¡Ì€ mÃ´Ìƒi tuÃ¢Ì€n. Mong moÌ£i ngÆ°Æ¡Ì€i giuÌp em tiÌ€m hÆ°Æ¡Ìng giaÌ‰i quyÃªÌt vÃ¢Ìn Ä‘ÃªÌ€ aÌ£ (objective function and constraints) Ä‘ÃªÌ‰ thoÌ‰a maÌƒn caÌc cÃ¢u hoÌ‰i Æ¡Ì‰ Ã´ bÃªn phaÌ‰i. Em xin caÌ‰m Æ¡n aÌ£!",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh tÃªn lÃ  Viá»‡t. MÃ¬nh lÃ  AI engineer Ä‘ang lÃ m viá»‡c táº¡i Berlin. CÃ´ng ty cá»§a mÃ¬nh Ä‘ang cáº§n tuyá»ƒn thÃªm 2-3 AI engineer. Náº¿u báº¡n nÃ o cÃ³ kinh nghiá»‡m lÃ m viá»‡c trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o/thá»‹ giÃ¡c mÃ¡y tÃ­nh, thÃ¬ liÃªn láº¡c vá»›i mÃ¬nh nhÃ©. NgoÃ i ra cÃ´ng ty mÃ¬nh cÅ©ng sponsor visa, nÃªn náº¿u cÃ¡c báº¡n cÃ³ báº¡n bÃ¨ á»Ÿ VN quan tÃ¢m cÅ©ng nhÆ° phÃ¹ há»£p vá»›i vá»‹ trÃ­, thÃ¬ lÃ m Æ¡n giá»›i thiá»‡u dÃ¹m mÃ¬nh. MÃ¬nh Ä‘á»ƒ link job description á»Ÿ dÆ°á»›i. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","ChÃ o má»i ngÆ°á»i, MÃ¬nh tÃªn lÃ  Viá»‡t. MÃ¬nh lÃ  AI engineer Ä‘ang lÃ m viá»‡c táº¡i Berlin. CÃ´ng ty cá»§a mÃ¬nh Ä‘ang cáº§n tuyá»ƒn thÃªm 2-3 AI engineer. Náº¿u báº¡n nÃ o cÃ³ kinh nghiá»‡m lÃ m viá»‡c trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o/thá»‹ giÃ¡c mÃ¡y tÃ­nh, thÃ¬ liÃªn láº¡c vá»›i mÃ¬nh nhÃ©. NgoÃ i ra cÃ´ng ty mÃ¬nh cÅ©ng sponsor visa, nÃªn náº¿u cÃ¡c báº¡n cÃ³ báº¡n bÃ¨ á»Ÿ VN quan tÃ¢m cÅ©ng nhÆ° phÃ¹ há»£p vá»›i vá»‹ trÃ­, thÃ¬ lÃ m Æ¡n giá»›i thiá»‡u dÃ¹m mÃ¬nh. MÃ¬nh Ä‘á»ƒ link job description á»Ÿ dÆ°á»›i. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
"MÃ¬nh Ä‘ang muá»‘n Ã´n láº¡i vá» Statistics. CÃ¡c báº¡n Data Scientist cÃ³ thá»ƒ recommend mÃ¬nh 1-2 cuá»‘n dáº¡ng textbook vÃ  cÃ³ báº£n free pdf khÃ´ng?
Cáº£m Æ¡n cÃ¡c báº¡n.
--- Update ---
MÃ¬nh tháº¥y cuá»‘n nÃ y Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ dÆ°á»›i khÃ¡ ok
https://www.kdnuggets.com/2020/04/statistics-concise-course-statistical-inference-free-ebook.html?fbclid=IwAR0xE3tjSZYHSC2Rw7lpXc0gST5rbPW3tGVPnUony1eAD6le7btf90NBPXg.",MÃ¬nh Ä‘ang muá»‘n Ã´n láº¡i vá» Statistics. CÃ¡c báº¡n Data Scientist cÃ³ thá»ƒ recommend mÃ¬nh 1-2 cuá»‘n dáº¡ng textbook vÃ  cÃ³ báº£n free pdf khÃ´ng? Cáº£m Æ¡n cÃ¡c báº¡n. --- Update --- MÃ¬nh tháº¥y cuá»‘n nÃ y Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ dÆ°á»›i khÃ¡ ok https://www.kdnuggets.com/2020/04/statistics-concise-course-statistical-inference-free-ebook.html?fbclid=IwAR0xE3tjSZYHSC2Rw7lpXc0gST5rbPW3tGVPnUony1eAD6le7btf90NBPXg.,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang ngÃ¢m cá»©u mÃ³n YOLOv6 nÃªn máº¡nh dáº¡n ra tiáº¿p video Pháº§n 2 vá» Deploy thÃ nh API, WEB cho cÃ¡c báº¡n má»›i há»c tham kháº£o.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n áº¡!","KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang ngÃ¢m cá»©u mÃ³n YOLOv6 nÃªn máº¡nh dáº¡n ra tiáº¿p video Pháº§n 2 vá» Deploy thÃ nh API, WEB cho cÃ¡c báº¡n má»›i há»c tham kháº£o. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n áº¡!",,,,,
"""Há»c machine learning""
chÃ o mn,
e hiá»‡n Ä‘ang lÃ  du há»c sinh Ä‘á»©c ngÃ nh electrical engineering muá»‘n há»c vá» machine learning cÅ©ng nhÆ° data science. Do má»›i há»c nÃªn cÃ³ ráº¥t nhiá»u tháº¯c máº¯c. KhÃ´ng biáº¿t a/c/b nÃ o cÃ³ nhu cáº§u há»c tiáº¿ng Ä‘á»©c hoáº·c tiáº¿ng anh (vÃ­ dá»¥: Ä‘á»ƒ sang Ä‘á»©c há»c hoáº·c lÃ m viá»‡c) ko? E cÃ³ báº±ng C1 English vs German nÃªn cÃ³ thá»ƒ dáº¡y a/c/b, Ä‘á»•i láº¡i a/c/b cÃ³ thá»ƒ chá»‰ dáº¡y e má»™t chÃºt vá» ML!
a/c/b nÃ o quan tÃ¢m cÃ³ thá»ƒ comment or inbox trá»±c tiáº¿p e!","""Há»c machine learning"" chÃ o mn, e hiá»‡n Ä‘ang lÃ  du há»c sinh Ä‘á»©c ngÃ nh electrical engineering muá»‘n há»c vá» machine learning cÅ©ng nhÆ° data science. Do má»›i há»c nÃªn cÃ³ ráº¥t nhiá»u tháº¯c máº¯c. KhÃ´ng biáº¿t a/c/b nÃ o cÃ³ nhu cáº§u há»c tiáº¿ng Ä‘á»©c hoáº·c tiáº¿ng anh (vÃ­ dá»¥: Ä‘á»ƒ sang Ä‘á»©c há»c hoáº·c lÃ m viá»‡c) ko? E cÃ³ báº±ng C1 English vs German nÃªn cÃ³ thá»ƒ dáº¡y a/c/b, Ä‘á»•i láº¡i a/c/b cÃ³ thá»ƒ chá»‰ dáº¡y e má»™t chÃºt vá» ML! a/c/b nÃ o quan tÃ¢m cÃ³ thá»ƒ comment or inbox trá»±c tiáº¿p e!",,,,,
"Em chÃ o mn. Em Ä‘ang muá»‘n hiá»ƒu rÃµ sá»± khÃ¡c biá»‡t cá»§a dynamic programming(DP), monte carlo(MC) vÃ  temporal difference(TD). Theo nhÆ° trÃªn course cá»§a DeepMind thÃ¬ ngoÃ i sá»± khÃ¡c biá»‡t vá» cÃ¡ch update value function dá»±a trÃªn estimation hoáº·c real value(boostrapping), thÃ¬ cÃ²n khÃ¡c nhau vá» cÃ¡ch sampling. XÃ©t sampling experience thÃ¬ cáº£ MC vÃ  TD Ä‘á»u sample environment, cÃ²n DP thÃ¬ khÃ´ng sample nhÆ°ng sáº½ xÃ©t táº¥t cáº£ cÃ¡c possibilities sau Ä‘Ã³ vÃ  update láº¡i value function. NhÆ°ng DP cÅ©ng dÃ¹ng max operator Ä‘á»ƒ láº¥y action value cao nháº¥t. NhÆ° váº­y khÃ¡c gÃ¬ MC vÃ  TD áº¡. Hay cÃ¡ch sample cá»§a MC vÃ  TD lÃ  hoÃ n toÃ n ngáº«u nhiÃªn?","Em chÃ o mn. Em Ä‘ang muá»‘n hiá»ƒu rÃµ sá»± khÃ¡c biá»‡t cá»§a dynamic programming(DP), monte carlo(MC) vÃ  temporal difference(TD). Theo nhÆ° trÃªn course cá»§a DeepMind thÃ¬ ngoÃ i sá»± khÃ¡c biá»‡t vá» cÃ¡ch update value function dá»±a trÃªn estimation hoáº·c real value(boostrapping), thÃ¬ cÃ²n khÃ¡c nhau vá» cÃ¡ch sampling. XÃ©t sampling experience thÃ¬ cáº£ MC vÃ  TD Ä‘á»u sample environment, cÃ²n DP thÃ¬ khÃ´ng sample nhÆ°ng sáº½ xÃ©t táº¥t cáº£ cÃ¡c possibilities sau Ä‘Ã³ vÃ  update láº¡i value function. NhÆ°ng DP cÅ©ng dÃ¹ng max operator Ä‘á»ƒ láº¥y action value cao nháº¥t. NhÆ° váº­y khÃ¡c gÃ¬ MC vÃ  TD áº¡. Hay cÃ¡ch sample cá»§a MC vÃ  TD lÃ  hoÃ n toÃ n ngáº«u nhiÃªn?",,,,,
"#hoidap
Xin chÃ o má»i ngÆ°á»i,
CÃ¡c báº¡n lÃ m Æ¡n cho mÃ¬nh há»i, á»Ÿ Viá»‡t Nam cÃ³ cÃ¡c cÃ´ng ty nÃ o lÃ m vá» Data Annotation cho Computer Vision váº­y áº¡? MÃ¬nh xin cÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.","Xin chÃ o má»i ngÆ°á»i, CÃ¡c báº¡n lÃ m Æ¡n cho mÃ¬nh há»i, á»Ÿ Viá»‡t Nam cÃ³ cÃ¡c cÃ´ng ty nÃ o lÃ m vá» Data Annotation cho Computer Vision váº­y áº¡? MÃ¬nh xin cÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.",#hoidap,,,,
"[Deep Learning free courses youtube]
NgÃ y nay cÃ¡c tÃ i liá»‡u vá» Deep Learning lÃ  vÃ´ cÃ¹ng dá»“i dÃ o vÃ  viá»‡c tiáº¿p cáº­n chÃºng cÅ©ng trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n nhá» cÃ¡c kÃªnh youtube vÃ  chÃ­nh sÃ¡ch cá»Ÿi má»Ÿ cá»§a cÃ¡c trÆ°á»ng Ä‘áº¡i há»c, viá»‡n nghiÃªn cá»©u. Tháº¿ nhÆ°ng khÃ´ng pháº£i nguá»“n tÃ i liá»‡u nÃ o vá» Deep Learning cÅ©ng chuáº©n hÃ³a vÃ  cháº¥t lÆ°á»£ng. ÄÃ¢y lÃ  danh sÃ¡ch gáº§n 500 khÃ³a há»c Ä‘Ã£ Ä‘Æ°á»£c tuyá»ƒn lá»±a vá» Deep Learning Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi cÃ¡c giÃ¡o sÆ° táº¡i nhá»¯ng trÆ°á»ng Ä‘áº¡i há»c hÃ ng Ä‘áº§u tháº¿ giá»›i vá» lÄ©nh vá»±c AI kÃ¨m theo link youtube, nÄƒm phÃ¡t hÃ nh vÃ  phÃ¢n loáº¡i topics cá»§a má»—i khÃ³a há»c. Nhá»¯ng khÃ³a há»c nÃ y hoÃ n toÃ n free vÃ  cover Ä‘Æ°á»£c ráº¥t nhiá»u chá»§ Ä‘á» lá»›n trong Deep Learning mÃ  báº¡n Ä‘á»c cÃ³ thá»ƒ tÃ¬m tháº¥y nhÆ°:
â€¢ Deep Learning (Deep Neural Networks)
â€¢ Machine Learning Fundamentals
â€¢ Optimization for Machine Learning
â€¢ General Machine Learning
â€¢ Reinforcement Learning
â€¢ Bayesian Deep Learning
â€¢ Graph Neural Networks
â€¢ Probabilistic Graphical Models
â€¢ Natural Language Processing
â€¢ Automatic Speech Recognition
â€¢ Modern Computer Vision
â€¢ Boot Camps or Summer Schools
â€¢ Medical Imaging
â€¢ Bird's-eye view of Artificial Intelligence
Deep Learning thá»±c sá»± ráº¥t rá»™ng lá»›n Ä‘á»ƒ chÃºng ta cÃ³ thá»ƒ bao quÃ¡t háº¿t Ä‘Æ°á»£c, vÃ  Ä‘á»ƒ chinh phá»¥c chÃºng thÃ¬ báº¡n cÃ³ thá»ƒ tuÃ¢n theo lá»i khuyÃªn cá»§a Prof. Geoffrey Hinton, University of Toronto:
""Read enough so you start developing intuitions and then trust your intuitions and go for it!""
Link website:
https://deep-learning-drizzle.github.io/index.html#contents","[Deep Learning free courses youtube] NgÃ y nay cÃ¡c tÃ i liá»‡u vá» Deep Learning lÃ  vÃ´ cÃ¹ng dá»“i dÃ o vÃ  viá»‡c tiáº¿p cáº­n chÃºng cÅ©ng trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n nhá» cÃ¡c kÃªnh youtube vÃ  chÃ­nh sÃ¡ch cá»Ÿi má»Ÿ cá»§a cÃ¡c trÆ°á»ng Ä‘áº¡i há»c, viá»‡n nghiÃªn cá»©u. Tháº¿ nhÆ°ng khÃ´ng pháº£i nguá»“n tÃ i liá»‡u nÃ o vá» Deep Learning cÅ©ng chuáº©n hÃ³a vÃ  cháº¥t lÆ°á»£ng. ÄÃ¢y lÃ  danh sÃ¡ch gáº§n 500 khÃ³a há»c Ä‘Ã£ Ä‘Æ°á»£c tuyá»ƒn lá»±a vá» Deep Learning Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi cÃ¡c giÃ¡o sÆ° táº¡i nhá»¯ng trÆ°á»ng Ä‘áº¡i há»c hÃ ng Ä‘áº§u tháº¿ giá»›i vá» lÄ©nh vá»±c AI kÃ¨m theo link youtube, nÄƒm phÃ¡t hÃ nh vÃ  phÃ¢n loáº¡i topics cá»§a má»—i khÃ³a há»c. Nhá»¯ng khÃ³a há»c nÃ y hoÃ n toÃ n free vÃ  cover Ä‘Æ°á»£c ráº¥t nhiá»u chá»§ Ä‘á» lá»›n trong Deep Learning mÃ  báº¡n Ä‘á»c cÃ³ thá»ƒ tÃ¬m tháº¥y nhÆ°: â€¢ Deep Learning (Deep Neural Networks) â€¢ Machine Learning Fundamentals â€¢ Optimization for Machine Learning â€¢ General Machine Learning â€¢ Reinforcement Learning â€¢ Bayesian Deep Learning â€¢ Graph Neural Networks â€¢ Probabilistic Graphical Models â€¢ Natural Language Processing â€¢ Automatic Speech Recognition â€¢ Modern Computer Vision â€¢ Boot Camps or Summer Schools â€¢ Medical Imaging â€¢ Bird's-eye view of Artificial Intelligence Deep Learning thá»±c sá»± ráº¥t rá»™ng lá»›n Ä‘á»ƒ chÃºng ta cÃ³ thá»ƒ bao quÃ¡t háº¿t Ä‘Æ°á»£c, vÃ  Ä‘á»ƒ chinh phá»¥c chÃºng thÃ¬ báº¡n cÃ³ thá»ƒ tuÃ¢n theo lá»i khuyÃªn cá»§a Prof. Geoffrey Hinton, University of Toronto: ""Read enough so you start developing intuitions and then trust your intuitions and go for it!"" Link website: https://deep-learning-drizzle.github.io/index.html#contents",,,,,
"[Ideas Worth Sharing]
TÃ u ngáº§m cá»§a group Ä‘Ã£ lÃ¢u, nay mÃ¬nh chia sáº» nhá»¯ng Ä‘iá»u mÃ¬nh note láº¡i tá»« 1 podcast cá»§a Lex Fridman - podcast chuyÃªn phá»ng váº¥n nhá»¯ng chuyÃªn gia hÃ ng Ä‘áº§u tháº¿ giá»›i, cháº¯c ai há»c AI cÅ©ng Ã­t nhiá»u biáº¿t Ä‘áº¿n podcast nÃ y, nghÄ© láº¡i náº¿u ko share giá»¯ cho mÃ¬nh thÃ¬ hÆ¡i phÃ­ =)).
Äoáº¡n note mÃ¬nh chia sáº» lÃ  cuá»™c nÃ³i chuyá»‡n vá»›i Jeremy Howard, Ä‘á»“ng sÃ¡ng láº­p cá»§a course fast.ai ná»•i tiáº¿ng. NÃ³i chung mÃ¬nh há»c Ä‘Æ°á»£c khÃ¡ nhiá»u Ä‘áº·c biá»‡t lÃ  cÃ¡i nhÃ¬n thá»±c táº¿ vÃ  cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» dÃ¹ng AI cá»§a á»•ng.
Link podcast: https://www.youtube.com/watch?v=J6XcP4JOHmk&t=30s
--------------------------------------------------------------------------
02:49 - Programming coupled with Music may generate creative ideas
41:51 - Things that make high practical impact are transfer learning, active learning (get more of the human beings in the loop)
43:36 - ULMFiT algorithm introduced transfer learning to NLP and smashed the state-of-the-art in one of the most important dataset in the field he knows nothing about 
48:47 - Figure out how to accomplish faster with just 1 GPU that a normal person could afford
51:13 - Train Imagenet dataset with smaller image size (64), then later use fewer epoch to train with original size (224)
53:00 - Imagenette dataset, a small subset of Imagenet. The result training in this dataset in 10 minutes in a single GPU can be transferable to Imagenet nearly all the time. Link: https://github.com/fastai/imagenette
54:00 - Deep learning should be accessible for normal people and trained on a single GPU
55:48 - DeOldify, a technique to colorize white-and-black movies and can colorize the whole movie in a couple of hours using a single GPU
59:00 - Practicalities of training neural network quickly and accurately
1:01:01 - Super-Convergence: Fast Training of NN with Very Large Learning Rate paper
1:02:22 - No idea how optimizers really work (combination of epsilon, weight decay, learning rate,â€¦)
1:04:58 - Looking at the data (particular from the lens of which part of the data the model says is important) is the key part before training the model => then finetune the model => learn to analyze the results of the model (looking at examples of misclassified images, classification matrix,â€¦) => after that you can learn about important features, which groups are misclassified (like using the model to debug the data and to learn more about the data, becoming a domain expert more quickly)
1:07:49 - GCP is the best to start
1:19:18 - Strong coders and know nothing about statistics pickup fast.ai course the best
1:20:59 - The key difference between people who succeed and people who fail is tenacity (persistence)
1:21:40:
Advice for starting with deep learning:
 â€¢ Train a lot of models
 â€¢ Get a lot of experiments (like change the input a little and then look at how the output varies) to get an intuitive understanding of what is going on
 To become an expert:
 â€¢ We need experts at using deep learning for a specific domain area (passion area)
 â€¢ Interesting research is to try to solve an actual problem and solve it really well
 â€¢ Understanding sufficient tools for the deep learning side and becoming an expert at a particular domain (like if you're studying self-driving car then really experiencing driving the car to see what happen to you and improve upon it)

To create a successful startup:
 â€¢ Never give up and stick to it (key things)
 â€¢ Keep costs super low and try to save up some money beforehand
 â€¢ 1:28:14: (Do not understand)
 â€¢ Stay from venture capital (VC) money as long as possible preferably forever. Run a self-funded startup instead.

1:36:50: When reading papers, identify important concepts and understand them deeply and actually digest them and decided if it's worth incorporated into his library (implementing) or how he do things or it's not worth it
1:37:23: Committed to spending at least half of everyday learning or practicing something new => do everything faster 
1:38:30: How he designs every Chinese flashcards
1:40:22: Future of AI is to use existing tools to solve a lot of societally currently unsolved problems (like labor force displacement
--------------------------------------------------------------------------
VÃ¬ mÃ¬nh note khi Ä‘ang xem video nÃªn cÃ³ thá»ƒ nhiá»u pháº§n khÃ³ hiá»ƒu vá»›i cáº£ quÃ¡ váº¯n táº¯t nÃªn má»i ngÆ°á»i gÃ³p Ã½ thÃªm nhÃ©. Khuyáº¿n khÃ­ch má»i ngÆ°á»i xem cáº£ video ğŸ˜Š","[Ideas Worth Sharing] TÃ u ngáº§m cá»§a group Ä‘Ã£ lÃ¢u, nay mÃ¬nh chia sáº» nhá»¯ng Ä‘iá»u mÃ¬nh note láº¡i tá»« 1 podcast cá»§a Lex Fridman - podcast chuyÃªn phá»ng váº¥n nhá»¯ng chuyÃªn gia hÃ ng Ä‘áº§u tháº¿ giá»›i, cháº¯c ai há»c AI cÅ©ng Ã­t nhiá»u biáº¿t Ä‘áº¿n podcast nÃ y, nghÄ© láº¡i náº¿u ko share giá»¯ cho mÃ¬nh thÃ¬ hÆ¡i phÃ­ =)). Äoáº¡n note mÃ¬nh chia sáº» lÃ  cuá»™c nÃ³i chuyá»‡n vá»›i Jeremy Howard, Ä‘á»“ng sÃ¡ng láº­p cá»§a course fast.ai ná»•i tiáº¿ng. NÃ³i chung mÃ¬nh há»c Ä‘Æ°á»£c khÃ¡ nhiá»u Ä‘áº·c biá»‡t lÃ  cÃ¡i nhÃ¬n thá»±c táº¿ vÃ  cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» dÃ¹ng AI cá»§a á»•ng. Link podcast: https://www.youtube.com/watch?v=J6XcP4JOHmk&t=30s -------------------------------------------------------------------------- 02:49 - Programming coupled with Music may generate creative ideas 41:51 - Things that make high practical impact are transfer learning, active learning (get more of the human beings in the loop) 43:36 - ULMFiT algorithm introduced transfer learning to NLP and smashed the state-of-the-art in one of the most important dataset in the field he knows nothing about 48:47 - Figure out how to accomplish faster with just 1 GPU that a normal person could afford 51:13 - Train Imagenet dataset with smaller image size (64), then later use fewer epoch to train with original size (224) 53:00 - Imagenette dataset, a small subset of Imagenet. The result training in this dataset in 10 minutes in a single GPU can be transferable to Imagenet nearly all the time. Link: https://github.com/fastai/imagenette 54:00 - Deep learning should be accessible for normal people and trained on a single GPU 55:48 - DeOldify, a technique to colorize white-and-black movies and can colorize the whole movie in a couple of hours using a single GPU 59:00 - Practicalities of training neural network quickly and accurately 1:01:01 - Super-Convergence: Fast Training of NN with Very Large Learning Rate paper 1:02:22 - No idea how optimizers really work (combination of epsilon, weight decay, learning rate,â€¦) 1:04:58 - Looking at the data (particular from the lens of which part of the data the model says is important) is the key part before training the model => then finetune the model => learn to analyze the results of the model (looking at examples of misclassified images, classification matrix,â€¦) => after that you can learn about important features, which groups are misclassified (like using the model to debug the data and to learn more about the data, becoming a domain expert more quickly) 1:07:49 - GCP is the best to start 1:19:18 - Strong coders and know nothing about statistics pickup fast.ai course the best 1:20:59 - The key difference between people who succeed and people who fail is tenacity (persistence) 1:21:40: Advice for starting with deep learning: â€¢ Train a lot of models â€¢ Get a lot of experiments (like change the input a little and then look at how the output varies) to get an intuitive understanding of what is going on To become an expert: â€¢ We need experts at using deep learning for a specific domain area (passion area) â€¢ Interesting research is to try to solve an actual problem and solve it really well â€¢ Understanding sufficient tools for the deep learning side and becoming an expert at a particular domain (like if you're studying self-driving car then really experiencing driving the car to see what happen to you and improve upon it) To create a successful startup: â€¢ Never give up and stick to it (key things) â€¢ Keep costs super low and try to save up some money beforehand â€¢ 1:28:14: (Do not understand) â€¢ Stay from venture capital (VC) money as long as possible preferably forever. Run a self-funded startup instead. 1:36:50: When reading papers, identify important concepts and understand them deeply and actually digest them and decided if it's worth incorporated into his library (implementing) or how he do things or it's not worth it 1:37:23: Committed to spending at least half of everyday learning or practicing something new => do everything faster 1:38:30: How he designs every Chinese flashcards 1:40:22: Future of AI is to use existing tools to solve a lot of societally currently unsolved problems (like labor force displacement -------------------------------------------------------------------------- VÃ¬ mÃ¬nh note khi Ä‘ang xem video nÃªn cÃ³ thá»ƒ nhiá»u pháº§n khÃ³ hiá»ƒu vá»›i cáº£ quÃ¡ váº¯n táº¯t nÃªn má»i ngÆ°á»i gÃ³p Ã½ thÃªm nhÃ©. Khuyáº¿n khÃ­ch má»i ngÆ°á»i xem cáº£ video",,,,,
"Em chÃ o mn. Em cÃ³ 1 bÃ i toÃ¡n tá»‘i Æ°u cÃ³ rÃ ng buá»™c nhÆ° nÃ y. Em ko biáº¿t search tá»« khÃ³a nhÆ° nÃ o Ä‘á»ƒ tÃ¬m ra algorithm phÃ¹ há»£p mong mn chá»‰ giÃºp em áº¡. Em cÃ³ 100 phÆ°á»ng cÃ³ lat long, 10 kho cÃ³ lat long Ä‘ang phá»¥c vá»¥ ship hÃ ng cho 100 phÆ°á»ng kia( data cÃ³ má»—i row lÃ  phÆ°á»ng nÃ o thuá»™c kho nÃ o, lÆ°á»£ng Ä‘Æ¡n cá»§a phÆ°á»ng Ä‘Ã³ lÃ  bn).
Váº¥n Ä‘á» lÃ  hiá»‡n táº¡i cÃ³ nhiá»u kho láº¡i phá»¥c vá»¥ phÆ°á»ng ráº¥t xa (mÃ  phÆ°á»ng Ä‘Ã³ gáº§n kho khÃ¡c hÆ¡n) Ä‘áº¡i loáº¡i vá»‹ trÃ­ ko tá»‘i Æ°u. HÃ m má»¥c tiÃªu cá»§a em lÃ  tá»‘i Æ°u minimum hÃ m:
f()= xÃ­ch ma ( sá»‘ Ä‘Æ¡n cá»§a phÆ°á»ng i * khoáº£ng cÃ¡ch Ä‘áº¿n kho má»›i) ( chÆ°a biáº¿t kho má»›i lÃ  kho nÃ o nhÃ© áº¡)
trong Ä‘Ã³ khoáº£ng cÃ¡ch thÃ¬ tÃ­nh theo lat long cá»§a phÆ°á»ng vÃ  kho.
Em search tá»« khÃ³a thÃ¬ ra nÃ³ lÃ  Constraint optimization nhÆ°ng tháº¥y nhiá»u thuáº­t toÃ¡n quÃ¡ nÃªn hÆ¡i rá»‘i, náº¿u Ä‘á»c tá»«ng cÃ¡i khÃ¡ lÃ¢u. Ã€ RÃ€NG BUá»˜C cá»§a em lÃ  10 kho kia sau khi rearrange láº¡i cÃ¡c phÆ°á»ng phá»¥c vá»¥ thÃ¬ tá»•ng sáº£n lÆ°á»£ng cá»§a kho sau rearrange lÃ  <= 110% so vá»›i sáº£n lÆ°á»£ng Ä‘ang phá»¥c vá»¥ hiá»‡n táº¡i do diá»‡n tÃ­ch kho cÃ³ háº¡n ( sáº£n lÆ°á»£ng cá»§a kho = tá»•ng sáº£n lÆ°á»£ng cá»§a cÃ¡c phÆ°á»ng nÃ³ phá»¥c vá»¥)","Em chÃ o mn. Em cÃ³ 1 bÃ i toÃ¡n tá»‘i Æ°u cÃ³ rÃ ng buá»™c nhÆ° nÃ y. Em ko biáº¿t search tá»« khÃ³a nhÆ° nÃ o Ä‘á»ƒ tÃ¬m ra algorithm phÃ¹ há»£p mong mn chá»‰ giÃºp em áº¡. Em cÃ³ 100 phÆ°á»ng cÃ³ lat long, 10 kho cÃ³ lat long Ä‘ang phá»¥c vá»¥ ship hÃ ng cho 100 phÆ°á»ng kia( data cÃ³ má»—i row lÃ  phÆ°á»ng nÃ o thuá»™c kho nÃ o, lÆ°á»£ng Ä‘Æ¡n cá»§a phÆ°á»ng Ä‘Ã³ lÃ  bn). Váº¥n Ä‘á» lÃ  hiá»‡n táº¡i cÃ³ nhiá»u kho láº¡i phá»¥c vá»¥ phÆ°á»ng ráº¥t xa (mÃ  phÆ°á»ng Ä‘Ã³ gáº§n kho khÃ¡c hÆ¡n) Ä‘áº¡i loáº¡i vá»‹ trÃ­ ko tá»‘i Æ°u. HÃ m má»¥c tiÃªu cá»§a em lÃ  tá»‘i Æ°u minimum hÃ m: f()= xÃ­ch ma ( sá»‘ Ä‘Æ¡n cá»§a phÆ°á»ng i * khoáº£ng cÃ¡ch Ä‘áº¿n kho má»›i) ( chÆ°a biáº¿t kho má»›i lÃ  kho nÃ o nhÃ© áº¡) trong Ä‘Ã³ khoáº£ng cÃ¡ch thÃ¬ tÃ­nh theo lat long cá»§a phÆ°á»ng vÃ  kho. Em search tá»« khÃ³a thÃ¬ ra nÃ³ lÃ  Constraint optimization nhÆ°ng tháº¥y nhiá»u thuáº­t toÃ¡n quÃ¡ nÃªn hÆ¡i rá»‘i, náº¿u Ä‘á»c tá»«ng cÃ¡i khÃ¡ lÃ¢u. Ã€ RÃ€NG BUá»˜C cá»§a em lÃ  10 kho kia sau khi rearrange láº¡i cÃ¡c phÆ°á»ng phá»¥c vá»¥ thÃ¬ tá»•ng sáº£n lÆ°á»£ng cá»§a kho sau rearrange lÃ  <= 110% so vá»›i sáº£n lÆ°á»£ng Ä‘ang phá»¥c vá»¥ hiá»‡n táº¡i do diá»‡n tÃ­ch kho cÃ³ háº¡n ( sáº£n lÆ°á»£ng cá»§a kho = tá»•ng sáº£n lÆ°á»£ng cá»§a cÃ¡c phÆ°á»ng nÃ³ phá»¥c vá»¥)",,"#Q&A,#math",,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» YOLOv6 vá» cÃ¡ch train, cÃ¡ch test vÃ  deploy nÃªn em máº¡nh dáº¡n lÃ m clip chia sáº» cho cÃ¡c báº¡n má»›i há»c.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em!","KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» YOLOv6 vá» cÃ¡ch train, cÃ¡ch test vÃ  deploy nÃªn em máº¡nh dáº¡n lÃ m clip chia sáº» cho cÃ¡c báº¡n má»›i há»c. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em!",,,,,
"Xin chÃ o cÃ¡c báº¡n,
MÃ¬nh cÃ³ má»™t cÃ¢u há»i nhanh mong nháº­n Ä‘Æ°á»£c sá»± trá»£ giÃºp cá»§a cÃ¡c báº¡n:
MÃ¬nh cÃ³ má»™t dict.key() gá»“m khoáº£ng 500 sheet_ name trong má»™t file excel, (mÃ¬nh copy vÃ i cÃ¡i nhÆ° sau):
46 P09-4 (Position Terrestrâ€¦
47 P10_D09 (Position Terresâ€¦
48 P10_D10 (Position Terresâ€¦
49 P10_D11 (Position Terresâ€¦
giá» mÃ¬nh muá»‘n dÃ¹ng regular expression Ä‘á»ƒ cáº¯t háº¿t pháº§n ""(Position Terrestrâ€¦"" rá»“i giá»¯ láº¡i pháº§n Ä‘áº§u cá»§a tÃªn cho tiá»‡n truy cáº­p.
MÃ¬nh Ä‘Ã£ dÃ¹ng lá»‡nh re.findall Ä‘á»ƒ lá»c nhÆ°ng mÃ¬nh ráº¥t mong báº¡n nÃ o cÃ³ thá»ƒ chá»‰ giÃºp mÃ¬nh cÃ¡ch dÃ¹ng lá»‡nh re.sub Ä‘á»ƒ cáº¯t cho nhanh.
Xin cáº£m Æ¡n má»i ngÆ°á»i vÃ  ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± trá»£ giÃºp tá»« cÃ¡c báº¡n.","Xin chÃ o cÃ¡c báº¡n, MÃ¬nh cÃ³ má»™t cÃ¢u há»i nhanh mong nháº­n Ä‘Æ°á»£c sá»± trá»£ giÃºp cá»§a cÃ¡c báº¡n: MÃ¬nh cÃ³ má»™t dict.key() gá»“m khoáº£ng 500 sheet_ name trong má»™t file excel, (mÃ¬nh copy vÃ i cÃ¡i nhÆ° sau): 46 P09-4 (Position Terrestrâ€¦ 47 P10_D09 (Position Terresâ€¦ 48 P10_D10 (Position Terresâ€¦ 49 P10_D11 (Position Terresâ€¦ giá» mÃ¬nh muá»‘n dÃ¹ng regular expression Ä‘á»ƒ cáº¯t háº¿t pháº§n ""(Position Terrestrâ€¦"" rá»“i giá»¯ láº¡i pháº§n Ä‘áº§u cá»§a tÃªn cho tiá»‡n truy cáº­p. MÃ¬nh Ä‘Ã£ dÃ¹ng lá»‡nh re.findall Ä‘á»ƒ lá»c nhÆ°ng mÃ¬nh ráº¥t mong báº¡n nÃ o cÃ³ thá»ƒ chá»‰ giÃºp mÃ¬nh cÃ¡ch dÃ¹ng lá»‡nh re.sub Ä‘á»ƒ cáº¯t cho nhanh. Xin cáº£m Æ¡n má»i ngÆ°á»i vÃ  ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± trá»£ giÃºp tá»« cÃ¡c báº¡n.",,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ má»™t váº¥n Ä‘á» nhá» anh em há»— trá»£ lÃ  cÃ¡c thuáº­t toÃ¡n nháº­n dáº¡ng báº¥t thÆ°á»ng (ngoáº¡i lai) cá»§a dá»¯ liá»‡u Ä‘Æ¡n biáº¿n nhÆ° IQR (Interquartile Range), Median Absolute Deviation, phÆ°Æ¡ng phÃ¡p Generalized ESD (GESD), K-Nearest Neighbours, LOF (Local Outlier Factor). Histogram-based Outlier Score (HBOS), iForest. thÆ°á»ng thÃ¬ sáº½ Ä‘Æ°a dá»¯ liá»‡u vÃ o Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh phÃ¹ há»£p. Váº¥n Ä‘á» mÃ¬nh cáº§n tÃ¬m hiá»ƒu lÃ  bá»™ dá»¯ liá»‡u cáº¥u trÃºc nhÆ° tháº¿ nÃ o Ä‘á»ƒ má»—i thuáº­t toÃ¡n Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chinh xÃ¡c cao nháº¥t.
Báº¡n nÃ o cÃ³ paper hay tÃ i liá»‡u nÃ o chá»‰ mÃ¬nh vá»›i.
Xin cáº£m Æ¡n.","ChÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ má»™t váº¥n Ä‘á» nhá» anh em há»— trá»£ lÃ  cÃ¡c thuáº­t toÃ¡n nháº­n dáº¡ng báº¥t thÆ°á»ng (ngoáº¡i lai) cá»§a dá»¯ liá»‡u Ä‘Æ¡n biáº¿n nhÆ° IQR (Interquartile Range), Median Absolute Deviation, phÆ°Æ¡ng phÃ¡p Generalized ESD (GESD), K-Nearest Neighbours, LOF (Local Outlier Factor). Histogram-based Outlier Score (HBOS), iForest. thÆ°á»ng thÃ¬ sáº½ Ä‘Æ°a dá»¯ liá»‡u vÃ o Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh phÃ¹ há»£p. Váº¥n Ä‘á» mÃ¬nh cáº§n tÃ¬m hiá»ƒu lÃ  bá»™ dá»¯ liá»‡u cáº¥u trÃºc nhÆ° tháº¿ nÃ o Ä‘á»ƒ má»—i thuáº­t toÃ¡n Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chinh xÃ¡c cao nháº¥t. Báº¡n nÃ o cÃ³ paper hay tÃ i liá»‡u nÃ o chá»‰ mÃ¬nh vá»›i. Xin cáº£m Æ¡n.",,,,,
"For some technical reason, I donâ€™t see any pending post from the OP. Helping him post this:
-------
Hi all, VinAI is pleased to publicly release the pre-trained text translation models ""vinai/vinai-translate-vi2en"" and ""vinai/vinai-translate-en2vi"" that are currently used in the translation component of the VinAI Translate system (https://vinai-translate.vinai.io). The pre-trained models are state-of-the-art text translation models for Vietnamese-to-English and English-to-Vietnamese, which can be used with the popular library ""transformers"".
Please find details about the pre-trained models at: https://github.com/VinAIResearch/VinAI_Translate
Experimental results of the pre-trained models can be found in the VinAI Translate system paper ""A Vietnamese-English Neural Machine Translation System"" (https://openreview.net/forum?id=CRg-RaxKnai), which will be presented at the Interspeech 2022 Show & Tell session.
Other Vietnamese NLP resources from VinAI:
- https://github.com/VinAIResearch/BARTpho (INTERSPEECH 2022): Pre-trained sequence-to-sequence models for Vietnamese.
- https://github.com/VinAIResearch/PhoMT (EMNLP 2021): A high-quality and large-scale benchmark dataset for Vietnamese-English machine translation.
- https://github.com/VinAIResearch/JointIDSF/tree/main/PhoATIS (INTERSPEECH 2021): An intent detection and slot filling dataset for Vietnamese.
- https://github.com/VinAIResearch/PhoNLP (NAACL 2021): A BERT-based multi-task learning toolkit for Vietnamese POS tagging, named entity recognition and dependency parsing.
- https://github.com/VinAIResearch/PhoNER_COVID19 (NAACL 2021): A dataset for Vietnamese named entity recognition.
- https://github.com/VinAIResearch/ViText2SQL (EMNLP 2020 Findings): A dataset for Vietnamese Text2SQL semantic parsing.
- https://github.com/VinAIResearch/PhoBERT (EMNLP 2020 Findings): Pre-trained language models for Vietnamese.
- https://github.com/datquocnguyen/PhoW2V (2020): Pre-trained Word2Vec syllable- and word-level embeddings for Vietnamese.
 â€” vá»›i Dat Quoc Nguyen.","For some technical reason, I donâ€™t see any pending post from the OP. Helping him post this: ------- Hi all, VinAI is pleased to publicly release the pre-trained text translation models ""vinai/vinai-translate-vi2en"" and ""vinai/vinai-translate-en2vi"" that are currently used in the translation component of the VinAI Translate system (https://vinai-translate.vinai.io). The pre-trained models are state-of-the-art text translation models for Vietnamese-to-English and English-to-Vietnamese, which can be used with the popular library ""transformers"". Please find details about the pre-trained models at: https://github.com/VinAIResearch/VinAI_Translate Experimental results of the pre-trained models can be found in the VinAI Translate system paper ""A Vietnamese-English Neural Machine Translation System"" (https://openreview.net/forum?id=CRg-RaxKnai), which will be presented at the Interspeech 2022 Show & Tell session. Other Vietnamese NLP resources from VinAI: - https://github.com/VinAIResearch/BARTpho (INTERSPEECH 2022): Pre-trained sequence-to-sequence models for Vietnamese. - https://github.com/VinAIResearch/PhoMT (EMNLP 2021): A high-quality and large-scale benchmark dataset for Vietnamese-English machine translation. - https://github.com/VinAIResearch/JointIDSF/tree/main/PhoATIS (INTERSPEECH 2021): An intent detection and slot filling dataset for Vietnamese. - https://github.com/VinAIResearch/PhoNLP (NAACL 2021): A BERT-based multi-task learning toolkit for Vietnamese POS tagging, named entity recognition and dependency parsing. - https://github.com/VinAIResearch/PhoNER_COVID19 (NAACL 2021): A dataset for Vietnamese named entity recognition. - https://github.com/VinAIResearch/ViText2SQL (EMNLP 2020 Findings): A dataset for Vietnamese Text2SQL semantic parsing. - https://github.com/VinAIResearch/PhoBERT (EMNLP 2020 Findings): Pre-trained language models for Vietnamese. - https://github.com/datquocnguyen/PhoW2V (2020): Pre-trained Word2Vec syllable- and word-level embeddings for Vietnamese. â€” vá»›i Dat Quoc Nguyen.",,,,,
"Do cÃ³ nhu cáº§u pre-train BART nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c open source implementation phÃ¹ há»£p nÃªn mÃ¬nh Ä‘Ã£ thá»­ viáº¿t. CÃ¡c báº¡n cÃ³ nhu cáº§u tÆ°Æ¡ng tá»± cÃ³ thá»ƒ tham kháº£o.
https://github.com/duongna21/bartflax
[More info] Implementation nÃ y Ä‘Ã£ Ä‘Æ°á»£c huggingface/transformers approved lÃ m official example cho BART pre-training, sáº½ merged into master branch trong vÃ i ngÃ y tá»›i. PR discussion: https://github.com/huggingface/transformers/pull/18297.","Do cÃ³ nhu cáº§u pre-train BART nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c open source implementation phÃ¹ há»£p nÃªn mÃ¬nh Ä‘Ã£ thá»­ viáº¿t. CÃ¡c báº¡n cÃ³ nhu cáº§u tÆ°Æ¡ng tá»± cÃ³ thá»ƒ tham kháº£o. https://github.com/duongna21/bartflax [More info] Implementation nÃ y Ä‘Ã£ Ä‘Æ°á»£c huggingface/transformers approved lÃ m official example cho BART pre-training, sáº½ merged into master branch trong vÃ i ngÃ y tá»›i. PR discussion: https://github.com/huggingface/transformers/pull/18297.",,,,,
"Hi,
MÃ¬nh Ä‘ang lÃ m senior program committee (meta-reviewer) cho AAAI-23 vÃ  cÃ³ thá»ƒ nominate reviewers. Báº¡n nÃ o muá»‘n cÃ³ kinh nghiá»‡m lÃ m reviewer cho AAAI-23 thÃ¬ cÃ³ thá»ƒ inbox mÃ¬nh Ä‘á»ƒ mÃ¬nh nominate (YÃªu cáº§u: ÄÃ£ cÃ³ publications vÃ¬ cáº§n DBLP profile má»›i nominate Ä‘Æ°á»£c)
Best,
Thanh","Hi, MÃ¬nh Ä‘ang lÃ m senior program committee (meta-reviewer) cho AAAI-23 vÃ  cÃ³ thá»ƒ nominate reviewers. Báº¡n nÃ o muá»‘n cÃ³ kinh nghiá»‡m lÃ m reviewer cho AAAI-23 thÃ¬ cÃ³ thá»ƒ inbox mÃ¬nh Ä‘á»ƒ mÃ¬nh nominate (YÃªu cáº§u: ÄÃ£ cÃ³ publications vÃ¬ cáº§n DBLP profile má»›i nominate Ä‘Æ°á»£c) Best, Thanh",,,,,
"[CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation]
Gáº§n Ä‘Ã¢y, cÃ¡c á»©ng dá»¥ng cá»§a Transformer trong cÃ¡c bÃ i toÃ¡n Computer Vision Ä‘ang ngÃ y trá»Ÿ nÃªn phá»• biáº¿n. KhÃ´ng chá»‰ dá»«ng láº¡i á»Ÿ Image Classification, Object Detection. Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, kiáº¿n trÃºc nÃ y cÃ²n Ä‘Æ°á»£c Ã¡p dá»¥ng ráº¥t thÃ nh cÃ´ng trong bÃ i toÃ¡n Image Segmentation nhá» kháº£ nÄƒng capture Ä‘Æ°á»£c global context vÃ  clustering behavior cá»§a cÃ¡c tokens há»c Ä‘Æ°á»£c trÃªn cÃ¡c chuá»—i sequence Ä‘Æ°á»£c mÃ£ hÃ³a tá»« hÃ¬nh áº£nh Ä‘áº§u vÃ o thÃ´ng qua kiáº¿n trÃºc Transformer Encoder-Decoder mÃ  thuáº­t toÃ¡n Ä‘Ã£ chá»©ng minh Ä‘Æ°á»£c tÃ­nh hiá»‡u quáº£ vÃ  giÃºp cáº£i thiá»‡n accuracy so vá»›i cÃ¡c thuáº­t toÃ¡n sá»­ dá»¥ng thuáº§n CNN trÆ°á»›c Ä‘Ã³.
Trong tuáº§n nÃ y chÃºng ta cÃ¹ng nhau phÃ¢n tÃ­ch kiáº¿n trÃºc CMT-DeepLab Ä‘Ã£ káº¿ thá»«a láº¡i DETR nháº±m giáº£i quyáº¿t bÃ i toÃ¡n Panoptic Segmentation thÃ nh cÃ´ng nhÆ° tháº¿ nÃ o? NghiÃªn cá»©u Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi nhÃ³m tÃ¡c giáº£ tráº»: Quihang Yu, Huiyu Wang vÃ  cÃ¡c cá»™ng sá»± Ä‘áº¿n tá»« Ä‘áº¡i há»c John Hopskins, KAIST vÃ  Google Research","[CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation] Gáº§n Ä‘Ã¢y, cÃ¡c á»©ng dá»¥ng cá»§a Transformer trong cÃ¡c bÃ i toÃ¡n Computer Vision Ä‘ang ngÃ y trá»Ÿ nÃªn phá»• biáº¿n. KhÃ´ng chá»‰ dá»«ng láº¡i á»Ÿ Image Classification, Object Detection. Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, kiáº¿n trÃºc nÃ y cÃ²n Ä‘Æ°á»£c Ã¡p dá»¥ng ráº¥t thÃ nh cÃ´ng trong bÃ i toÃ¡n Image Segmentation nhá» kháº£ nÄƒng capture Ä‘Æ°á»£c global context vÃ  clustering behavior cá»§a cÃ¡c tokens há»c Ä‘Æ°á»£c trÃªn cÃ¡c chuá»—i sequence Ä‘Æ°á»£c mÃ£ hÃ³a tá»« hÃ¬nh áº£nh Ä‘áº§u vÃ o thÃ´ng qua kiáº¿n trÃºc Transformer Encoder-Decoder mÃ  thuáº­t toÃ¡n Ä‘Ã£ chá»©ng minh Ä‘Æ°á»£c tÃ­nh hiá»‡u quáº£ vÃ  giÃºp cáº£i thiá»‡n accuracy so vá»›i cÃ¡c thuáº­t toÃ¡n sá»­ dá»¥ng thuáº§n CNN trÆ°á»›c Ä‘Ã³. Trong tuáº§n nÃ y chÃºng ta cÃ¹ng nhau phÃ¢n tÃ­ch kiáº¿n trÃºc CMT-DeepLab Ä‘Ã£ káº¿ thá»«a láº¡i DETR nháº±m giáº£i quyáº¿t bÃ i toÃ¡n Panoptic Segmentation thÃ nh cÃ´ng nhÆ° tháº¿ nÃ o? NghiÃªn cá»©u Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi nhÃ³m tÃ¡c giáº£ tráº»: Quihang Yu, Huiyu Wang vÃ  cÃ¡c cá»™ng sá»± Ä‘áº¿n tá»« Ä‘áº¡i há»c John Hopskins, KAIST vÃ  Google Research",,,,,
"ChÃ o má»i ngÆ°á»i
MÃ¬nh cÃ³ danh sÃ¡ch cÃ¡c mÃ´n há»c vÃ  Ä‘c chá»n 5 units
KhÃ´ng biáº¿t thá»© tá»± Ä‘á»™ khÃ³, vai trÃ² quan trá»ng cá»§a units ntn xin má»i ngÆ°á»i hÆ°á»›ng dáº«n ?","ChÃ o má»i ngÆ°á»i MÃ¬nh cÃ³ danh sÃ¡ch cÃ¡c mÃ´n há»c vÃ  Ä‘c chá»n 5 units KhÃ´ng biáº¿t thá»© tá»± Ä‘á»™ khÃ³, vai trÃ² quan trá»ng cá»§a units ntn xin má»i ngÆ°á»i hÆ°á»›ng dáº«n ?",,,,,
MÃ¬nh má»›i biáº¿t Ä‘áº¿n cuá»™c thi trÃªn AIVIVN trong Ä‘Ã³ cÃ³ PhÃ¢n loáº¡i sáº¯c thÃ¡i bÃ¬nh luáº­n nhÆ°ng Ä‘Ã£ káº¿t thÃºc vÃ o máº¥y thÃ¡ng trÆ°á»›c giá» mÃ¬nh Ä‘ang muá»‘n lÃ m láº¡i nhÆ°ng láº¡i khÃ´ng cÃ²n data ná»¯a khÃ´ng biáº¿t trÆ°á»›c má»i ngÆ°á»i lÃ m vá» bÃ i thi nÃ y cÃ²n lÆ°u láº¡i data cÃ³ thá»ƒ share cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡ ğŸ˜ƒğŸ˜ƒ,MÃ¬nh má»›i biáº¿t Ä‘áº¿n cuá»™c thi trÃªn AIVIVN trong Ä‘Ã³ cÃ³ PhÃ¢n loáº¡i sáº¯c thÃ¡i bÃ¬nh luáº­n nhÆ°ng Ä‘Ã£ káº¿t thÃºc vÃ o máº¥y thÃ¡ng trÆ°á»›c giá» mÃ¬nh Ä‘ang muá»‘n lÃ m láº¡i nhÆ°ng láº¡i khÃ´ng cÃ²n data ná»¯a khÃ´ng biáº¿t trÆ°á»›c má»i ngÆ°á»i lÃ m vá» bÃ i thi nÃ y cÃ²n lÆ°u láº¡i data cÃ³ thá»ƒ share cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡,,,,,
"Hi má»i ngÆ°á»i.
MÃ¬nh má»›i chuyá»ƒn sang tÃ¬m hiá»ƒu lÄ©nh vá»±c 3D printing. MÃ¬nh Ä‘ang muá»‘n chuyá»ƒn 1 file 3D obj cÃ³ mÃ u sang 3D obj xÃ¡m báº±ng python. MÃ¬nh Ä‘Ã£ tÃ¬m trÃªn máº¡ng nhÆ°ng chÆ°a tháº¥y Ä‘Æ°á»£c cÃ¡ch nÃ y. Báº¡n nÃ o kinh nghiá»‡m chia sáº» giÃºp mÃ¬nh tÃ i liá»‡u vá»›i.
Thanks má»i ngÆ°á»i.",Hi má»i ngÆ°á»i. MÃ¬nh má»›i chuyá»ƒn sang tÃ¬m hiá»ƒu lÄ©nh vá»±c 3D printing. MÃ¬nh Ä‘ang muá»‘n chuyá»ƒn 1 file 3D obj cÃ³ mÃ u sang 3D obj xÃ¡m báº±ng python. MÃ¬nh Ä‘Ã£ tÃ¬m trÃªn máº¡ng nhÆ°ng chÆ°a tháº¥y Ä‘Æ°á»£c cÃ¡ch nÃ y. Báº¡n nÃ o kinh nghiá»‡m chia sáº» giÃºp mÃ¬nh tÃ i liá»‡u vá»›i. Thanks má»i ngÆ°á»i.,,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 7/2022 vÃ o trong comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 7/2022 vÃ o trong comment cá»§a post nÃ y.",,,,,
"ChÃ o mn trong nhÃ³m
Em/mÃ¬nh cÃ³ má»™t cÃ¢u há»i nhÆ° sau:
Hiá»‡n táº¡i em/mÃ¬nh Ä‘ang sá»­ dá»¥ng pháº§n tracking cá»§a https://github.com/theAIGuysCode/yolov4-deepsort cho má»™t pháº§n cá»§a bÃ i toÃ¡n em/mÃ¬nh Ä‘ang lÃ m.
MÃ¬nh cÃ³ Ä‘á»c paper thÃ¬ ngta cÃ³ nÃ³i ráº±ng deepsort sinh ra Ä‘á»ƒ cáº£i thiá»‡n váº¥n Ä‘á» ID Shifting (switch) so vá»›i sort. Tuy nhiÃªn, khi Ã¡p dá»¥ng, mÃ¬nh tháº¥y hiá»‡n tÆ°á»£ng trÃªn váº«n thÆ°á»ng xuyÃªn xáº£y ra. Pháº£i chÄƒng mÃ¬nh config cÃ¡c params chÆ°a Ä‘Ãºng??
Má»i ngÆ°á»i cÃ³ thá»ƒ cho em/mÃ¬nh xin Ã½ kiáº¿n Ä‘Æ°á»£c khÃ´ng áº¡.
Vá»›i má»™t váº¥n Ä‘á» ná»¯a lÃ  mÃ¬nh tháº¥y deepsort nÃ y cÃ³ váº» khÃ¡ náº·ng, mn cÃ³ thá»ƒ recomend cho mÃ¬nh cÃ¡ch khÃ¡c nháº¹ hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡?
Cáº£m Æ¡n mn áº¡","ChÃ o mn trong nhÃ³m Em/mÃ¬nh cÃ³ má»™t cÃ¢u há»i nhÆ° sau: Hiá»‡n táº¡i em/mÃ¬nh Ä‘ang sá»­ dá»¥ng pháº§n tracking cá»§a https://github.com/theAIGuysCode/yolov4-deepsort cho má»™t pháº§n cá»§a bÃ i toÃ¡n em/mÃ¬nh Ä‘ang lÃ m. MÃ¬nh cÃ³ Ä‘á»c paper thÃ¬ ngta cÃ³ nÃ³i ráº±ng deepsort sinh ra Ä‘á»ƒ cáº£i thiá»‡n váº¥n Ä‘á» ID Shifting (switch) so vá»›i sort. Tuy nhiÃªn, khi Ã¡p dá»¥ng, mÃ¬nh tháº¥y hiá»‡n tÆ°á»£ng trÃªn váº«n thÆ°á»ng xuyÃªn xáº£y ra. Pháº£i chÄƒng mÃ¬nh config cÃ¡c params chÆ°a Ä‘Ãºng?? Má»i ngÆ°á»i cÃ³ thá»ƒ cho em/mÃ¬nh xin Ã½ kiáº¿n Ä‘Æ°á»£c khÃ´ng áº¡. Vá»›i má»™t váº¥n Ä‘á» ná»¯a lÃ  mÃ¬nh tháº¥y deepsort nÃ y cÃ³ váº» khÃ¡ náº·ng, mn cÃ³ thá»ƒ recomend cho mÃ¬nh cÃ¡ch khÃ¡c nháº¹ hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡? Cáº£m Æ¡n mn áº¡",,,,,
"Em chaÌ€o moÌ£i ngÆ°Æ¡Ì€i.
HiÃªÌ£n taÌ£i em Ä‘ang tiÌ€m kiÃªÌm dÆ°Ìƒ liÃªÌ£u vÃªÌ€ gioÌ£ng noÌi, Ä‘ÃªÌ‰ phuÌ£c vuÌ£ cho viÃªÌ£c fine tune model speech recognition tiÃªÌng Anh bias cho ngÆ°Æ¡Ì€i ViÃªÌ£t. CaÌc nguÃ´Ì€n hÆ°Æ¡Ìng Ä‘ÃªÌn bao gÃ´Ì€m video, podcast, webminar hay caÌc baÌ€i representation cuÌ‰a ngÆ°Æ¡Ì€i ViÃªÌ£t nhÆ°ng sÆ°Ì‰ duÌ£ng ngÃ´n ngÆ°Ìƒ tiÃªÌng Anh, vÃªÌ€ chuÌ‰ Ä‘ÃªÌ€ giÌ€ cuÌƒng Ä‘Æ°Æ¡Ì£c aÌ£.
MoÌ£i ngÆ°Æ¡Ì€i coÌ kinh nghiÃªÌ£m xem nhÆ°Ìƒng nguÃ´Ì€n trÃªn nhiÃªÌ€u coÌ thÃªÌ‰ giuÌp em mÃ´Ì£t vaÌ€i keyword hoÄƒÌ£c nguÃ´Ì€n caÌ€ng tÃ´Ìt aÌ£. Em caÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i trÆ°Æ¡Ìc.","Em chaÌ€o moÌ£i ngÆ°Æ¡Ì€i. HiÃªÌ£n taÌ£i em Ä‘ang tiÌ€m kiÃªÌm dÆ°Ìƒ liÃªÌ£u vÃªÌ€ gioÌ£ng noÌi, Ä‘ÃªÌ‰ phuÌ£c vuÌ£ cho viÃªÌ£c fine tune model speech recognition tiÃªÌng Anh bias cho ngÆ°Æ¡Ì€i ViÃªÌ£t. CaÌc nguÃ´Ì€n hÆ°Æ¡Ìng Ä‘ÃªÌn bao gÃ´Ì€m video, podcast, webminar hay caÌc baÌ€i representation cuÌ‰a ngÆ°Æ¡Ì€i ViÃªÌ£t nhÆ°ng sÆ°Ì‰ duÌ£ng ngÃ´n ngÆ°Ìƒ tiÃªÌng Anh, vÃªÌ€ chuÌ‰ Ä‘ÃªÌ€ giÌ€ cuÌƒng Ä‘Æ°Æ¡Ì£c aÌ£. MoÌ£i ngÆ°Æ¡Ì€i coÌ kinh nghiÃªÌ£m xem nhÆ°Ìƒng nguÃ´Ì€n trÃªn nhiÃªÌ€u coÌ thÃªÌ‰ giuÌp em mÃ´Ì£t vaÌ€i keyword hoÄƒÌ£c nguÃ´Ì€n caÌ€ng tÃ´Ìt aÌ£. Em caÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i trÆ°Æ¡Ìc.",,,,,
"Hello cáº£ nhÃ , mÃ¬nh má»›i táº¡o báº£ng so sÃ¡nh tÃ­nh nÄƒng cá»§a má»™t sá»‘ giáº£i phÃ¡p model serving phá»• biáº¿n (khÃ´ng phá»¥ thuá»™c training framework), hy vá»ng cÃ³ Ã­ch vá»›i má»i ngÆ°á»i.
---
Ai quan tÃ¢m tá»›i ML engineering/MLOps thÃ¬ cÃ³ thá»ƒ join cá»™ng Ä‘á»“ng nÃ y nha: https://www.facebook.com/groups/mlopsvn","Hello cáº£ nhÃ , mÃ¬nh má»›i táº¡o báº£ng so sÃ¡nh tÃ­nh nÄƒng cá»§a má»™t sá»‘ giáº£i phÃ¡p model serving phá»• biáº¿n (khÃ´ng phá»¥ thuá»™c training framework), hy vá»ng cÃ³ Ã­ch vá»›i má»i ngÆ°á»i. --- Ai quan tÃ¢m tá»›i ML engineering/MLOps thÃ¬ cÃ³ thá»ƒ join cá»™ng Ä‘á»“ng nÃ y nha: https://www.facebook.com/groups/mlopsvn",,,,,
"MÃ¬nh phÃ©p chia sáº» vá» Optimization Techniques cho cÃ¡c Deep Neural Network dá»±a trÃªn cÃ¡c kinh nghiá»‡m dá»± Ã¡n cá»§a mÃ¬nh. ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº».
VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n!",MÃ¬nh phÃ©p chia sáº» vá» Optimization Techniques cho cÃ¡c Deep Neural Network dá»±a trÃªn cÃ¡c kinh nghiá»‡m dá»± Ã¡n cá»§a mÃ¬nh. ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº». VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n!,,,,,
ChÃ o má»i ngÆ°á»i áº¡. Anh chá»‹ (cÃ¡c báº¡n) cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ cho em há»i : cÃ³ open source nÃ o mÃ  cÃ³ thá»ƒ nháº­n biáº¿t Ä‘Æ°á»£c phoneme(cÃ¡ch phÃ¡t Ã¢m 1 tá»«) tá»« audio khÃ´ng áº¡. Em search thÃ¬ gáº§n nhÆ° khÃ´ng tÃ¬m tháº¥y open source. Em (mÃ¬nh ) cáº£m Æ¡n má»i ngÆ°á»i,ChÃ o má»i ngÆ°á»i áº¡. Anh chá»‹ (cÃ¡c báº¡n) cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ cho em há»i : cÃ³ open source nÃ o mÃ  cÃ³ thá»ƒ nháº­n biáº¿t Ä‘Æ°á»£c phoneme(cÃ¡ch phÃ¡t Ã¢m 1 tá»«) tá»« audio khÃ´ng áº¡. Em search thÃ¬ gáº§n nhÆ° khÃ´ng tÃ¬m tháº¥y open source. Em (mÃ¬nh ) cáº£m Æ¡n má»i ngÆ°á»i,,,,,
"[Xin gá»£i Ã½ paper Ä‘á»ƒ reimplement cho dÃ¢n beginner]
Em xin chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em má»›i há»c xong 1 sá»‘ course vá» Computer Vision vÃ  Python nÃªn muá»‘n á»©ng dá»¥ng ká»¹ nÄƒng thá»±c hÃ nh.
Em muá»‘n xin gá»£i Ã½ cÃ¡c paper liÃªn quan tá»›i Computer Vision mÃ  Ä‘Ã£ Ä‘Æ°á»£c reimplement nhiá»u Ä‘á»ƒ em thá»­ code áº¡. Em cáº£m Æ¡n mn nhiá»u.","[Xin gá»£i Ã½ paper Ä‘á»ƒ reimplement cho dÃ¢n beginner] Em xin chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em má»›i há»c xong 1 sá»‘ course vá» Computer Vision vÃ  Python nÃªn muá»‘n á»©ng dá»¥ng ká»¹ nÄƒng thá»±c hÃ nh. Em muá»‘n xin gá»£i Ã½ cÃ¡c paper liÃªn quan tá»›i Computer Vision mÃ  Ä‘Ã£ Ä‘Æ°á»£c reimplement nhiá»u Ä‘á»ƒ em thá»­ code áº¡. Em cáº£m Æ¡n mn nhiá»u.",,,,,
Xin há»i cÃ¡c báº¡n má»™t vÃ i tÃ i liá»‡u cÆ¡ báº£n cho ngÆ°á»i má»›i báº¯t Ä‘áº§u vá»›i Data Science áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.,Xin há»i cÃ¡c báº¡n má»™t vÃ i tÃ i liá»‡u cÆ¡ báº£n cho ngÆ°á»i má»›i báº¯t Ä‘áº§u vá»›i Data Science áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.,,,,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang muá»‘n tÃ¬m model Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vai trÃ² cá»§a cÃ¡c tá»« (hoáº·c cá»¥m tá»«) trong cÃ¢u
VÃ­ dá»¥ nhÆ°: My car has broken down. -> [My car](S) [has](A-Verb) [broken down](Verb)
Em cáº£m Æ¡n áº¡",ChÃ o má»i ngÆ°á»i. Em Ä‘ang muá»‘n tÃ¬m model Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vai trÃ² cá»§a cÃ¡c tá»« (hoáº·c cá»¥m tá»«) trong cÃ¢u VÃ­ dá»¥ nhÆ°: My car has broken down. -> [My car](S) [has](A-Verb) [broken down](Verb) Em cáº£m Æ¡n áº¡,,,,,
"Xin chÃ o anh em ML cÆ¡ báº£n.
Tranh thá»§ Ä‘ang tÃ¬m hiá»ƒu vá» DBSCAN nÃªn mÃ¬nh máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng má»i ngÆ°á»i.
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em cÃ³ thÃªm cÃ´ng cá»¥ chiáº¿n Ä‘áº¥u vÃ  chÆ¡i vá»›i data.",Xin chÃ o anh em ML cÆ¡ báº£n. Tranh thá»§ Ä‘ang tÃ¬m hiá»ƒu vá» DBSCAN nÃªn mÃ¬nh máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng má»i ngÆ°á»i. Hi vá»ng giÃºp Ä‘Æ°á»£c anh em cÃ³ thÃªm cÃ´ng cá»¥ chiáº¿n Ä‘áº¥u vÃ  chÆ¡i vá»›i data.,,,,,
Em Ä‘ang lÃ m má»™t model Ä‘á»ƒ forecast dá»¯ liá»‡u theo time series dÃ¹ng RNN áº¡. Sau khi ra káº¿t quáº£ thÃ¬ cÃ³ cÃ¢u há»i yÃªu cáº§u tÃ­nh mean square error vÃ  standard deviation (SD). Em tháº¯c máº¯c lÃ  cÃ¡i standard deviation nÃ y tÃ­nh nhÆ° tháº¿ nÃ o? Em nghÄ© nÃ³ liÃªn quan Ä‘áº¿n Ä‘Ã¡nh giÃ¡ accuracy cá»§a model. CÃ³ pháº£i tÃ­nh SD dá»±a trÃªn n dá»¯ liá»‡u predictions cá»§a model khÃ´ng? Hay lÃ  SD cá»§a error (y - y_predicted) áº¡?,Em Ä‘ang lÃ m má»™t model Ä‘á»ƒ forecast dá»¯ liá»‡u theo time series dÃ¹ng RNN áº¡. Sau khi ra káº¿t quáº£ thÃ¬ cÃ³ cÃ¢u há»i yÃªu cáº§u tÃ­nh mean square error vÃ  standard deviation (SD). Em tháº¯c máº¯c lÃ  cÃ¡i standard deviation nÃ y tÃ­nh nhÆ° tháº¿ nÃ o? Em nghÄ© nÃ³ liÃªn quan Ä‘áº¿n Ä‘Ã¡nh giÃ¡ accuracy cá»§a model. CÃ³ pháº£i tÃ­nh SD dá»±a trÃªn n dá»¯ liá»‡u predictions cá»§a model khÃ´ng? Hay lÃ  SD cá»§a error (y - y_predicted) áº¡?,,,,,
"Em chÃ o cÃ¡c anh/chá»‹ trong group áº¡, mong má»i ngÆ°á»i sáº½ há»— trá»£ em:
Em lÃ  sinh viÃªn nÄƒm 3, dá»± Ä‘á»‹nh theo hÆ°á»›ng AI Engineer, bÃªn cáº¡nh viá»‡c há»c cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n vÃ  cÃ¡c giÃ¡o trÃ¬nh chuyÃªn sÃ¢u, em muá»‘n tham kháº£o thÃªm cÃ¡c khÃ³a há»c vÃ  chia sáº» tá»« chuyÃªn gia trong ngÃ nh thÃ¬ nÃªn tÃ¬m á»Ÿ Ä‘Ã¢u áº¡?
Theo em biáº¿t thÃ¬ hiá»‡n táº¡i khÃ´ng cÃ³ nhiá»u sá»± kiá»‡n hay khÃ³a há»c vá» AI/ML, em á»Ÿ hcm áº¡. Náº¿u mng tháº¥y khÃ³a há»c hay há»™i tháº£o, tá»a Ä‘Ã m nÃ o hay hay thÃ¬ chá»‰ em vá»›i nhÃ©, xin cáº£m Æ¡n mng ráº¥t nhiá»u","Em chÃ o cÃ¡c anh/chá»‹ trong group áº¡, mong má»i ngÆ°á»i sáº½ há»— trá»£ em: Em lÃ  sinh viÃªn nÄƒm 3, dá»± Ä‘á»‹nh theo hÆ°á»›ng AI Engineer, bÃªn cáº¡nh viá»‡c há»c cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n vÃ  cÃ¡c giÃ¡o trÃ¬nh chuyÃªn sÃ¢u, em muá»‘n tham kháº£o thÃªm cÃ¡c khÃ³a há»c vÃ  chia sáº» tá»« chuyÃªn gia trong ngÃ nh thÃ¬ nÃªn tÃ¬m á»Ÿ Ä‘Ã¢u áº¡? Theo em biáº¿t thÃ¬ hiá»‡n táº¡i khÃ´ng cÃ³ nhiá»u sá»± kiá»‡n hay khÃ³a há»c vá» AI/ML, em á»Ÿ hcm áº¡. Náº¿u mng tháº¥y khÃ³a há»c hay há»™i tháº£o, tá»a Ä‘Ã m nÃ o hay hay thÃ¬ chá»‰ em vá»›i nhÃ©, xin cáº£m Æ¡n mng ráº¥t nhiá»u",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang implement Q-Learning nhÆ°ng cÃ³ chÃºt tháº¯c máº¯c vá» viá»‡c update Q-value áº¡. NhÆ° trong cuá»‘n ""Deep Reinforcement Learning Hands-On"" thÃ¬ Q value Ä‘Æ°á»£c update nhÆ° trong hÃ¬nh. NhÆ°ng em cÃ³ tham kháº£o má»™t sá»‘ nguá»“n khÃ¡c nhÆ° trÃªn towardatascience thÃ¬ lÃºc update Q value, á»Ÿ future reward há» tÃ­nh báº±ng cÃ¡ch láº¥y gamma * (max Q value(given state, action) - immediate reward). Em khÃ´ng biáº¿t cÃ¡ch update Q value nÃ o lÃ  chuáº©n nháº¥t áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, em Ä‘ang implement Q-Learning nhÆ°ng cÃ³ chÃºt tháº¯c máº¯c vá» viá»‡c update Q-value áº¡. NhÆ° trong cuá»‘n ""Deep Reinforcement Learning Hands-On"" thÃ¬ Q value Ä‘Æ°á»£c update nhÆ° trong hÃ¬nh. NhÆ°ng em cÃ³ tham kháº£o má»™t sá»‘ nguá»“n khÃ¡c nhÆ° trÃªn towardatascience thÃ¬ lÃºc update Q value, á»Ÿ future reward há» tÃ­nh báº±ng cÃ¡ch láº¥y gamma * (max Q value(given state, action) - immediate reward). Em khÃ´ng biáº¿t cÃ¡ch update Q value nÃ o lÃ  chuáº©n nháº¥t áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i.",,,,,
"[The best AI papers 2022 - Louis - Montreal Canada]
Má»™t danh sÃ¡ch Ä‘Æ°á»£c tuyá»ƒn chá»n vá» nhá»¯ng Ä‘á»™t phÃ¡ má»›i nháº¥t trong AI theo ngÃ y phÃ¡t hÃ nh kÃ¨m theo lá»i giáº£i thÃ­ch báº±ng video rÃµ rÃ ng, liÃªn káº¿t Ä‘áº¿n má»™t bÃ i viáº¿t chuyÃªn sÃ¢u vÃ  code.
Trong khi tháº¿ giá»›i váº«n Ä‘ang phá»¥c há»“i sau Ä‘áº¡i dá»‹ch thÃ¬ lÄ©nh vá»±c nghiÃªn cá»©u khÃ´ng bá»‹ cháº­m láº¡i tá»‘c Ä‘á»™ Ä‘iÃªn cuá»“ng cá»§a nÃ³, Ä‘áº·c biá»‡t lÃ  trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o. HÆ¡n ná»¯a, nhiá»u khÃ­a cáº¡nh quan trá»ng Ä‘Ã£ Ä‘Æ°á»£c nÃªu báº­t trong nÄƒm nay, nhÆ° ethical, biases, governance, transparency vÃ  nhiá»u khÃ­a cáº¡nh khÃ¡c. TrÃ­ tuá»‡ nhÃ¢n táº¡o, sá»± hiá»ƒu biáº¿t cá»§a chÃºng ta vá» bá»™ nÃ£o con ngÆ°á»i vÃ  má»‘i liÃªn káº¿t cá»§a nÃ³ vá»›i AI Ä‘ang khÃ´ng ngá»«ng phÃ¡t triá»ƒn, cho tháº¥y nhá»¯ng á»©ng dá»¥ng Ä‘áº§y há»©a háº¹n cáº£i thiá»‡n cháº¥t lÆ°á»£ng cuá»™c sá»‘ng cá»§a chÃºng ta trong tÆ°Æ¡ng lai gáº§n. Tuy nhiÃªn, chÃºng ta nÃªn cáº©n tháº­n vá»›i cÃ´ng nghá»‡ mÃ  chÃºng ta chá»n Ã¡p dá»¥ng.
""Science cannot tell us what we ought to do, only what we can do.""
- Jean-Paul Sartre, Being and Nothingness
ÄÃ¢y lÃ  cÃ´ng trÃ¬nh nghiÃªn cá»©u cÃ¡c tÃ i liá»‡u nghiÃªn cá»©u thÃº vá»‹ nháº¥t cho nÄƒm 2022 Ä‘ang Ä‘Æ°á»£c tiáº¿n hÃ nh. TÃ³m láº¡i, ÄÃ¢y lÃ  danh sÃ¡ch cÃ¡c bÆ°á»›c Ä‘á»™t phÃ¡ má»›i nháº¥t trong AI vÃ  Khoa há»c dá»¯ liá»‡u Ä‘Æ°á»£c sáº¯p xáº¿p theo ngÃ y phÃ¡t hÃ nh kÃ¨m theo video giáº£i thÃ­ch rÃµ rÃ ng, liÃªn káº¿t Ä‘áº¿n má»™t bÃ i bÃ¡o chuyÃªn sÃ¢u vÃ  code (náº¿u cÃ³). ChÃºc báº¡n Ä‘á»c vui váº»!
https://github.com/louisfb01/best_AI_papers_2022
---------------------------------------------------------------------------
A curated list of the latest breakthroughs in AI by release date with a clear video explanation, link to a more in-depth article, and code.
While the world is still recovering, research hasn't slowed its frenetic pace, especially in the field of artificial intelligence. More, many important aspects were highlighted this year, like the ethical aspects, important biases, governance, transparency and much more. Artificial intelligence and our understanding of the human brain and its link to AI are constantly evolving, showing promising applications improving our life's quality in the near future. Still, we ought to be careful with which technology we choose to apply.
""Science cannot tell us what we ought to do, only what we can do.""
- Jean-Paul Sartre, Being and Nothingness
Here is a work in progress of the most interesting research papers for 2022. In short, it is curated list of the latest breakthroughs in AI and Data Science by release date with a clear video explanation, link to a more in-depth article, and code (if applicable). Enjoy the read!
https://github.com/louisfb01/best_AI_papers_2022","[The best AI papers 2022 - Louis - Montreal Canada] Má»™t danh sÃ¡ch Ä‘Æ°á»£c tuyá»ƒn chá»n vá» nhá»¯ng Ä‘á»™t phÃ¡ má»›i nháº¥t trong AI theo ngÃ y phÃ¡t hÃ nh kÃ¨m theo lá»i giáº£i thÃ­ch báº±ng video rÃµ rÃ ng, liÃªn káº¿t Ä‘áº¿n má»™t bÃ i viáº¿t chuyÃªn sÃ¢u vÃ  code. Trong khi tháº¿ giá»›i váº«n Ä‘ang phá»¥c há»“i sau Ä‘áº¡i dá»‹ch thÃ¬ lÄ©nh vá»±c nghiÃªn cá»©u khÃ´ng bá»‹ cháº­m láº¡i tá»‘c Ä‘á»™ Ä‘iÃªn cuá»“ng cá»§a nÃ³, Ä‘áº·c biá»‡t lÃ  trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o. HÆ¡n ná»¯a, nhiá»u khÃ­a cáº¡nh quan trá»ng Ä‘Ã£ Ä‘Æ°á»£c nÃªu báº­t trong nÄƒm nay, nhÆ° ethical, biases, governance, transparency vÃ  nhiá»u khÃ­a cáº¡nh khÃ¡c. TrÃ­ tuá»‡ nhÃ¢n táº¡o, sá»± hiá»ƒu biáº¿t cá»§a chÃºng ta vá» bá»™ nÃ£o con ngÆ°á»i vÃ  má»‘i liÃªn káº¿t cá»§a nÃ³ vá»›i AI Ä‘ang khÃ´ng ngá»«ng phÃ¡t triá»ƒn, cho tháº¥y nhá»¯ng á»©ng dá»¥ng Ä‘áº§y há»©a háº¹n cáº£i thiá»‡n cháº¥t lÆ°á»£ng cuá»™c sá»‘ng cá»§a chÃºng ta trong tÆ°Æ¡ng lai gáº§n. Tuy nhiÃªn, chÃºng ta nÃªn cáº©n tháº­n vá»›i cÃ´ng nghá»‡ mÃ  chÃºng ta chá»n Ã¡p dá»¥ng. ""Science cannot tell us what we ought to do, only what we can do."" - Jean-Paul Sartre, Being and Nothingness ÄÃ¢y lÃ  cÃ´ng trÃ¬nh nghiÃªn cá»©u cÃ¡c tÃ i liá»‡u nghiÃªn cá»©u thÃº vá»‹ nháº¥t cho nÄƒm 2022 Ä‘ang Ä‘Æ°á»£c tiáº¿n hÃ nh. TÃ³m láº¡i, ÄÃ¢y lÃ  danh sÃ¡ch cÃ¡c bÆ°á»›c Ä‘á»™t phÃ¡ má»›i nháº¥t trong AI vÃ  Khoa há»c dá»¯ liá»‡u Ä‘Æ°á»£c sáº¯p xáº¿p theo ngÃ y phÃ¡t hÃ nh kÃ¨m theo video giáº£i thÃ­ch rÃµ rÃ ng, liÃªn káº¿t Ä‘áº¿n má»™t bÃ i bÃ¡o chuyÃªn sÃ¢u vÃ  code (náº¿u cÃ³). ChÃºc báº¡n Ä‘á»c vui váº»! https://github.com/louisfb01/best_AI_papers_2022 --------------------------------------------------------------------------- A curated list of the latest breakthroughs in AI by release date with a clear video explanation, link to a more in-depth article, and code. While the world is still recovering, research hasn't slowed its frenetic pace, especially in the field of artificial intelligence. More, many important aspects were highlighted this year, like the ethical aspects, important biases, governance, transparency and much more. Artificial intelligence and our understanding of the human brain and its link to AI are constantly evolving, showing promising applications improving our life's quality in the near future. Still, we ought to be careful with which technology we choose to apply. ""Science cannot tell us what we ought to do, only what we can do."" - Jean-Paul Sartre, Being and Nothingness Here is a work in progress of the most interesting research papers for 2022. In short, it is curated list of the latest breakthroughs in AI and Data Science by release date with a clear video explanation, link to a more in-depth article, and code (if applicable). Enjoy the read! https://github.com/louisfb01/best_AI_papers_2022",,,,,
"ChÃ o má»i ngÆ°á»i. Khi báº¯t Ä‘áº§u má»™t project deep learning, em khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nÃªn Ä‘Ã£ Ä‘á»c source code vá» cÃ¡c project Ä‘Ã³. Tuy nhiÃªn, code cá»§a há» báº±ng pytorch vÃ  cÃ³ nhiá»u file vÃ  má»—i file ráº¥t nhiá»u. E Ä‘á»c khÃ´ng liÃªn káº¿t Ä‘Æ°á»£c chÃºng nÃªn k hiá»ƒu Ä‘Æ°á»£c nhiá»u. E muá»‘n há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ hiá»ƒu code tá»‘t khÃ´ng áº¡? NgoÃ i ra, lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ tá»± viáº¿t code khÃ¡c so vá»›i source code mk Ä‘Ã£ Ä‘á»c áº¡? E xin cáº£m Æ¡n mn áº¡.","ChÃ o má»i ngÆ°á»i. Khi báº¯t Ä‘áº§u má»™t project deep learning, em khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nÃªn Ä‘Ã£ Ä‘á»c source code vá» cÃ¡c project Ä‘Ã³. Tuy nhiÃªn, code cá»§a há» báº±ng pytorch vÃ  cÃ³ nhiá»u file vÃ  má»—i file ráº¥t nhiá»u. E Ä‘á»c khÃ´ng liÃªn káº¿t Ä‘Æ°á»£c chÃºng nÃªn k hiá»ƒu Ä‘Æ°á»£c nhiá»u. E muá»‘n há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ hiá»ƒu code tá»‘t khÃ´ng áº¡? NgoÃ i ra, lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ tá»± viáº¿t code khÃ¡c so vá»›i source code mk Ä‘Ã£ Ä‘á»c áº¡? E xin cáº£m Æ¡n mn áº¡.",,,,,
"[AI Generate Documentation]

CÃ³ bao giá» báº¡n viáº¿t code xong nhÆ°ng lÆ°á»i viáº¿t document cho Ä‘oáº¡n code áº¥y? Mintlify lÃ  tiá»‡n Ã­ch giÃºp má»i ngÆ°á»i sinh document cho code, nÃ³ cÃ³ plugin Ä‘á»ƒ tÃ­ch há»£p trÃªn VSCode vÃ  IntelliJ. Mintlify há»— trá»£ ráº¥t nhiá»u ngÃ´n ngá»¯, cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ°: Python, JavaScript, C and C++, PHP, Java, C#, Ruby, Rust, Dart, Go, etc. 

Website: https://www.mintlify.com/writer
Github: https://github.com/mintlify/writer","[AI Generate Documentation] CÃ³ bao giá» báº¡n viáº¿t code xong nhÆ°ng lÆ°á»i viáº¿t document cho Ä‘oáº¡n code áº¥y? Mintlify lÃ  tiá»‡n Ã­ch giÃºp má»i ngÆ°á»i sinh document cho code, nÃ³ cÃ³ plugin Ä‘á»ƒ tÃ­ch há»£p trÃªn VSCode vÃ  IntelliJ. Mintlify há»— trá»£ ráº¥t nhiá»u ngÃ´n ngá»¯, cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ°: Python, JavaScript, C and C++, PHP, Java, C#, Ruby, Rust, Dart, Go, etc. Website: https://www.mintlify.com/writer Github: https://github.com/mintlify/writer",,,,,
"A great book with comprehensive guides to Machine Learning in Production. I have read all course materials online (link in comment) and am now reading the book. Hat off to the author!
 â€” vá»›i Huyen Nguyen.",A great book with comprehensive guides to Machine Learning in Production. I have read all course materials online (link in comment) and am now reading the book. Hat off to the author! â€” vá»›i Huyen Nguyen.,,,,,
"ChÃ o má»i ngÆ°á»i e Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c thuáº­t toÃ¡n face detection.
E cÃ³ tÃ¬m thÃ¬ tháº¥y má»™t model Caffe vÃ  ngÆ°á»i ta cÃ³ chÃº thÃ­ch: res10_300x300_ssd_iter_140000.caffemodel
E khÃ´ng hiá»ƒu láº¯m mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃ¹m e model vÃ  thuáº­t toÃ¡n nÃ y lÃ  nhÆ° tháº¿ nÃ o áº¡. ChÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i",ChÃ o má»i ngÆ°á»i e Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c thuáº­t toÃ¡n face detection. E cÃ³ tÃ¬m thÃ¬ tháº¥y má»™t model Caffe vÃ  ngÆ°á»i ta cÃ³ chÃº thÃ­ch: res10_300x300_ssd_iter_140000.caffemodel E khÃ´ng hiá»ƒu láº¯m mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃ¹m e model vÃ  thuáº­t toÃ¡n nÃ y lÃ  nhÆ° tháº¿ nÃ o áº¡. ChÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i,,,,,
Chia sáº» bÃ i viáº¿t vá» cÃ¡c website cung cáº¥p Open Data. CÃ¡c website nÃ y sáº½ giÃºp Ã­ch ráº¥t nhiá»u cho dá»± Ã¡n cá»§a cÃ¡c báº¡n.,Chia sáº» bÃ i viáº¿t vá» cÃ¡c website cung cáº¥p Open Data. CÃ¡c website nÃ y sáº½ giÃºp Ã­ch ráº¥t nhiá»u cho dá»± Ã¡n cá»§a cÃ¡c báº¡n.,,,,,
HÃ´m trÆ°á»›c cÃ³ báº¡n nÃ o post bÃ i toÃ¡n OCR hÃ³a Ä‘Æ¡n bÃ¡n hÃ ng mÃ  mÃ¬nh tÃ¬m láº¡i chÆ°a Ä‘Æ°á»£c. Náº¿u báº¡n nÃ o Ä‘Ã£ lÃ m thuáº­t toÃ¡n nÃ y (khÃ´ng dÃ¹ng tesseract) cháº¡y ok rá»“i thÃ¬ liÃªn láº¡c vá»›i mÃ¬nh Ä‘á»ƒ trao Ä‘á»•i nhÃ©. MÃ¬nh cÅ©ng Ä‘ang cáº§n nÃ³. Xin cáº£m Æ¡n!,HÃ´m trÆ°á»›c cÃ³ báº¡n nÃ o post bÃ i toÃ¡n OCR hÃ³a Ä‘Æ¡n bÃ¡n hÃ ng mÃ  mÃ¬nh tÃ¬m láº¡i chÆ°a Ä‘Æ°á»£c. Náº¿u báº¡n nÃ o Ä‘Ã£ lÃ m thuáº­t toÃ¡n nÃ y (khÃ´ng dÃ¹ng tesseract) cháº¡y ok rá»“i thÃ¬ liÃªn láº¡c vá»›i mÃ¬nh Ä‘á»ƒ trao Ä‘á»•i nhÃ©. MÃ¬nh cÅ©ng Ä‘ang cáº§n nÃ³. Xin cáº£m Æ¡n!,,,,,
"Nhá» admin duyá»‡t tin. Xin cáº£m Æ¡n.
MÃ¬nh Ä‘ang lÃ m giáº£i phÃ¡p y táº¿ vá» dá»± bÃ¡o dá»‹ch bá»‡nh.
Hiá»‡n Ä‘ang tham gia chÆ°Æ¡ng trÃ¬nh Äá»•i má»›i sÃ¡ng táº¡o do Sá»Ÿ KH&CN Tp.HCM tá»• chá»©c. Giáº£i phÃ¡p Ä‘ang á»Ÿ giai Ä‘oáº¡n láº¥y Ã½ kiáº¿n vá» cá»™ng Ä‘á»“ng.
CÃ¡c báº¡n quan tÃ¢m like Ä‘á»ƒ á»§ng há»™ giáº£i phÃ¡p (dÃ¹ng facebook Ä‘á»ƒ like)
MÃ¬nh gá»­i link bÃ¬nh chá»n dÆ°á»›i Ä‘Ã¢y, cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ like á»§ng há»™.
https://doimoisangtao.vn/giai-thuong-dmst/2022/3/17/n2001-hsmart-he-thong-canh-bao-som-dich-benh-su-dung-tri-tue-nhan-tao-du-lieu-lon
PS: MÃ¬nh hy vá»ng nháº­n Ä‘Æ°á»£c nhiá»u gÃ³p Ã½ chuyÃªn gia y khoa, khoa há»c dá»¯ liá»‡u, CNTT sáºµn sÃ ng há»£p tÃ¡c Ä‘á»ƒ hoÃ n thiá»‡n giáº£i phÃ¡p tá»‘i Æ°u hÆ¡n.","Nhá» admin duyá»‡t tin. Xin cáº£m Æ¡n. MÃ¬nh Ä‘ang lÃ m giáº£i phÃ¡p y táº¿ vá» dá»± bÃ¡o dá»‹ch bá»‡nh. Hiá»‡n Ä‘ang tham gia chÆ°Æ¡ng trÃ¬nh Äá»•i má»›i sÃ¡ng táº¡o do Sá»Ÿ KH&CN Tp.HCM tá»• chá»©c. Giáº£i phÃ¡p Ä‘ang á»Ÿ giai Ä‘oáº¡n láº¥y Ã½ kiáº¿n vá» cá»™ng Ä‘á»“ng. CÃ¡c báº¡n quan tÃ¢m like Ä‘á»ƒ á»§ng há»™ giáº£i phÃ¡p (dÃ¹ng facebook Ä‘á»ƒ like) MÃ¬nh gá»­i link bÃ¬nh chá»n dÆ°á»›i Ä‘Ã¢y, cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ like á»§ng há»™. https://doimoisangtao.vn/giai-thuong-dmst/2022/3/17/n2001-hsmart-he-thong-canh-bao-som-dich-benh-su-dung-tri-tue-nhan-tao-du-lieu-lon PS: MÃ¬nh hy vá»ng nháº­n Ä‘Æ°á»£c nhiá»u gÃ³p Ã½ chuyÃªn gia y khoa, khoa há»c dá»¯ liá»‡u, CNTT sáºµn sÃ ng há»£p tÃ¡c Ä‘á»ƒ hoÃ n thiá»‡n giáº£i phÃ¡p tá»‘i Æ°u hÆ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ Ä‘ang nghiÃªn cá»©u vá» cÃ¡c thuáº­t toÃ¡n mÃ¡y há»c. Vá» váº¥n Ä‘á» hiá»ƒu thÃ¬ e chá»‰ má»›i hiá»ƒu Ä‘Æ°á»£c cÃ¡i pháº§n cÆ¡ báº£n, má»©c ná»n. Khi Ä‘á»c sÃ¢u vÃ o pháº§n toÃ¡n thÃ¬ e láº¡i tháº¥y hÆ¡i khÃ³ hiá»ƒu vÃ  phá»©c táº¡p. Má»i ngÆ°á»i cho em há»i em cÃ³ cáº§n pháº£i há»c sÃ¢u vá» pháº§n toÃ¡n trong táº¥t cáº£ cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n cho hiá»ƒu trÆ°á»›c háº¿t rá»“i má»›i Ä‘i sÃ¢u vÃ o hay khi nÃ o cáº§n thÃ¬ mÃ¬nh má»›i Ä‘á»c láº¡i thÃ´i áº¡. Xin anh chá»‹ Ä‘i trÆ°á»›c cho em xin Ã­t Ã½ kiáº¿n áº¡. Em xin cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, em cÃ³ Ä‘ang nghiÃªn cá»©u vá» cÃ¡c thuáº­t toÃ¡n mÃ¡y há»c. Vá» váº¥n Ä‘á» hiá»ƒu thÃ¬ e chá»‰ má»›i hiá»ƒu Ä‘Æ°á»£c cÃ¡i pháº§n cÆ¡ báº£n, má»©c ná»n. Khi Ä‘á»c sÃ¢u vÃ o pháº§n toÃ¡n thÃ¬ e láº¡i tháº¥y hÆ¡i khÃ³ hiá»ƒu vÃ  phá»©c táº¡p. Má»i ngÆ°á»i cho em há»i em cÃ³ cáº§n pháº£i há»c sÃ¢u vá» pháº§n toÃ¡n trong táº¥t cáº£ cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n cho hiá»ƒu trÆ°á»›c háº¿t rá»“i má»›i Ä‘i sÃ¢u vÃ o hay khi nÃ o cáº§n thÃ¬ mÃ¬nh má»›i Ä‘á»c láº¡i thÃ´i áº¡. Xin anh chá»‹ Ä‘i trÆ°á»›c cho em xin Ã­t Ã½ kiáº¿n áº¡. Em xin cáº£m Æ¡n",,,,,
"Xin chÃ o mn áº¡,
Mn cÃ³ muá»‘n tham gia workshop Ä‘á»ƒ tÃ¬m hiá»ƒu nhiá»u hÆ¡n vá» viá»‡c há»c Khoa há»c mÃ¡y tÃ­nh á»Ÿ nhiá»u nÆ°á»›c khÃ¡c nhau trÃªn tháº¿ giá»›i á»Ÿ nhiá»u báº­c nhÆ° cá»­ nhÃ¢n, tháº¡c sÄ©, Ä‘áº¡i há»c vÃ  tÃ¬m hiá»ƒu vá» quÃ¡ trÃ¬nh start-up cÃ´ng ty cÃ´ng nghÃª hay xin viá»‡c lÃ m trong ngÃ nh khÃ´ng áº¡?
Mn quan tÃ¢m mÃ¬nh sáº½ gá»­i thÃ´ng tin áº¡!","Xin chÃ o mn áº¡, Mn cÃ³ muá»‘n tham gia workshop Ä‘á»ƒ tÃ¬m hiá»ƒu nhiá»u hÆ¡n vá» viá»‡c há»c Khoa há»c mÃ¡y tÃ­nh á»Ÿ nhiá»u nÆ°á»›c khÃ¡c nhau trÃªn tháº¿ giá»›i á»Ÿ nhiá»u báº­c nhÆ° cá»­ nhÃ¢n, tháº¡c sÄ©, Ä‘áº¡i há»c vÃ  tÃ¬m hiá»ƒu vá» quÃ¡ trÃ¬nh start-up cÃ´ng ty cÃ´ng nghÃª hay xin viá»‡c lÃ m trong ngÃ nh khÃ´ng áº¡? Mn quan tÃ¢m mÃ¬nh sáº½ gá»­i thÃ´ng tin áº¡!",,,,,
"Em chÃ o cÃ¡c anh chá»‹, em Ä‘ang lÃ m Ä‘á»“ Ã¡n 1, bá»n em Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u vá» doanh sá»‘ bÃ¡n hÃ ng , sau khi tiáº¿n hÃ nh phÃ¢n tÃ­ch dá»¯ liá»‡u xong bá»n em muá»‘n hÆ°á»›ng Ä‘áº¿n dá»± Ä‘oÃ¡n dá»¯ liá»‡u ( dá»± Ä‘oÃ¡n doanh sá»‘ trong tÆ°Æ¡ng lai cá»§a má»™t sáº£n pháº©m) . Váº­y bá»n em cÃ³ thá»ƒ cÃ³ nhá»¯ng hÆ°á»›ng Ä‘i nÃ o Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y áº¡?
Bá»n em cÃ²n chÆ°a nhiá»u kiáº¿n thá»©c vÃ  Ä‘ang trong quÃ¡ trÃ¬nh há»c há»i, náº¿u cÃ¢u há»i quÃ¡ amateur mong anh chá»‹ thÃ´ng cáº£m vÃ  giÃºp Ä‘á»¡ áº¡ ğŸ™ğŸ¾â˜ºï¸","Em chÃ o cÃ¡c anh chá»‹, em Ä‘ang lÃ m Ä‘á»“ Ã¡n 1, bá»n em Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u vá» doanh sá»‘ bÃ¡n hÃ ng , sau khi tiáº¿n hÃ nh phÃ¢n tÃ­ch dá»¯ liá»‡u xong bá»n em muá»‘n hÆ°á»›ng Ä‘áº¿n dá»± Ä‘oÃ¡n dá»¯ liá»‡u ( dá»± Ä‘oÃ¡n doanh sá»‘ trong tÆ°Æ¡ng lai cá»§a má»™t sáº£n pháº©m) . Váº­y bá»n em cÃ³ thá»ƒ cÃ³ nhá»¯ng hÆ°á»›ng Ä‘i nÃ o Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y áº¡? Bá»n em cÃ²n chÆ°a nhiá»u kiáº¿n thá»©c vÃ  Ä‘ang trong quÃ¡ trÃ¬nh há»c há»i, náº¿u cÃ¢u há»i quÃ¡ amateur mong anh chá»‹ thÃ´ng cáº£m vÃ  giÃºp Ä‘á»¡ áº¡",,,,,
"Em chÃ o má»i ngÆ°á»i!
Em má»›i tÃ¬m hiá»ƒu vá» Machine Learning em cÃ³ test thá»­ code vá» pose estimation mÃ  khi cháº¡y project bá»‹ lá»—i nÃ y. Má»i ngÆ°á»i giÃºp em vá»›i áº¡
Em xin cáº£m Æ¡n áº¡",Em chÃ o má»i ngÆ°á»i! Em má»›i tÃ¬m hiá»ƒu vá» Machine Learning em cÃ³ test thá»­ code vá» pose estimation mÃ  khi cháº¡y project bá»‹ lá»—i nÃ y. Má»i ngÆ°á»i giÃºp em vá»›i áº¡ Em xin cáº£m Æ¡n áº¡,,,,,
"Trong viá»‡c lá»±a chá»n feature cho ML model mÃ¬nh nÃªn loáº¡i bá» cÃ¡c feature cÃ³ Ä‘á»™ tÆ°Æ¡ng quan cao Ä‘Ãºng khÃ´ng cÃ¡c bÃ¡c ? 
em tham kháº£o tháº¥y cÃ³ bÃ i bá» háº¿t náº¿t abs(corrlation) > 0.5, cÃ³ bÃ i láº¡i bá» háº¿t abs(corrlation) > 0.5 nhÆ°ng giá»¯ láº¡i feature cÃ³ correlation cao nháº¥t. (nhÆ° áº£nh monthly_average giá»¯ láº¡i vÃ¬ cÃ³ tÆ°Æ¡ng quan cao nháº¥t tá»›i sales)
nÃªn em khÃ´ng rÃµ cÃ³ quy táº¯c nÃ o Ä‘á»ƒ feature selection tá»« correlation khÃ´ng ? hay pháº§n nÃ y mang náº·ng tÃ­nh heuristic - kinh nghiá»‡m cá»§a ngÆ°á»i lÃ m nhá»‰ ?","Trong viá»‡c lá»±a chá»n feature cho ML model mÃ¬nh nÃªn loáº¡i bá» cÃ¡c feature cÃ³ Ä‘á»™ tÆ°Æ¡ng quan cao Ä‘Ãºng khÃ´ng cÃ¡c bÃ¡c ? em tham kháº£o tháº¥y cÃ³ bÃ i bá» háº¿t náº¿t abs(corrlation) > 0.5, cÃ³ bÃ i láº¡i bá» háº¿t abs(corrlation) > 0.5 nhÆ°ng giá»¯ láº¡i feature cÃ³ correlation cao nháº¥t. (nhÆ° áº£nh monthly_average giá»¯ láº¡i vÃ¬ cÃ³ tÆ°Æ¡ng quan cao nháº¥t tá»›i sales) nÃªn em khÃ´ng rÃµ cÃ³ quy táº¯c nÃ o Ä‘á»ƒ feature selection tá»« correlation khÃ´ng ? hay pháº§n nÃ y mang náº·ng tÃ­nh heuristic - kinh nghiá»‡m cá»§a ngÆ°á»i lÃ m nhá»‰ ?",,,,,
"ChÃ o cÃ¡c ace trÃªn group.
E Ä‘ang lÃ m liÃªn quan Ä‘áº¿n data fusion sá»­ dá»¥ng Bayesian inference.
Sau khi tá»•ng há»£p tá»« cÃ¡c thÃ´ng tin biáº¿t trÆ°á»›c. ThÃ¬ e thu Ä‘Æ°á»£c xÃ¡c xuáº¥t xáº£y ra táº¡i pháº§n tá»­ i lÃ  P(i) (cÃ³ n pháº§n tá»­)
NhÆ°ng sau Ä‘Ã³ e láº¡i tháº¥y cÃ³ tÃ¡c giáº£ dÃ¹ng cÃ´ng thá»©c nhÆ° trÃªn hÃ¬nh Q(i) = sqrt(P(i)*P(n+1-i). Äiá»u nÃ y lÃ m cho chÃºng Ä‘á»‘i xá»©ng. CÃ³ bÃ¡c nÃ o tá»«ng dÃ¹ng cÃ´ng thá»©c nÃ y, hoáº·c tháº¥y cÃ³ giáº£i thÃ­ch á»Ÿ lÃ½ do á»Ÿ Ä‘Ã¢u thÃ¬ chá»‰ cho e áº¡.
E cÃ¡m Æ¡n!","ChÃ o cÃ¡c ace trÃªn group. E Ä‘ang lÃ m liÃªn quan Ä‘áº¿n data fusion sá»­ dá»¥ng Bayesian inference. Sau khi tá»•ng há»£p tá»« cÃ¡c thÃ´ng tin biáº¿t trÆ°á»›c. ThÃ¬ e thu Ä‘Æ°á»£c xÃ¡c xuáº¥t xáº£y ra táº¡i pháº§n tá»­ i lÃ  P(i) (cÃ³ n pháº§n tá»­) NhÆ°ng sau Ä‘Ã³ e láº¡i tháº¥y cÃ³ tÃ¡c giáº£ dÃ¹ng cÃ´ng thá»©c nhÆ° trÃªn hÃ¬nh Q(i) = sqrt(P(i)*P(n+1-i). Äiá»u nÃ y lÃ m cho chÃºng Ä‘á»‘i xá»©ng. CÃ³ bÃ¡c nÃ o tá»«ng dÃ¹ng cÃ´ng thá»©c nÃ y, hoáº·c tháº¥y cÃ³ giáº£i thÃ­ch á»Ÿ lÃ½ do á»Ÿ Ä‘Ã¢u thÃ¬ chá»‰ cho e áº¡. E cÃ¡m Æ¡n!",,"#math, #Q&A",,,
,nan,,,,,
YoloV7 real-time object detection through Visual Data Preparation (VDP) which is an open-source visual data ETL tool,YoloV7 real-time object detection through Visual Data Preparation (VDP) which is an open-source visual data ETL tool,,,,,
"Nhá» anh em giáº£i toÃ¡n (code python cÃ ng tá»‘t áº¡):
CÃ³ má»™t ma tráº­n sá»‘ dÆ°Æ¡ng vuÃ´ng (n x n Ã´). Táº¡i má»—i hÃ ng vÃ  má»—i cá»™t láº¥y duy nháº¥t má»™t sá»‘, Ä‘Æ°á»£c n sá»‘. TÃ¬m tá»a Ä‘á»™ n sá»‘ sao cho tá»•ng cá»§a chÃºng lÃ  lá»›n nháº¥t.
MÃ¬nh chá»‰ nghÄ© ra Ä‘Æ°á»£c cÃ¡ch thá»§ cÃ´ng lÃ  táº¡o ra má»i tá»• há»£p tá»a Ä‘á»™ Ä‘Ã¡p á»©ng yÃªu cáº§u bÃ i toÃ¡n, tÃ­nh tá»•ng rá»“i chá»n ra Ä‘Ã¡p Ã¡n lá»›n nháº¥t.
Anh em cÃ³ cÃ¡ch nhanh hÆ¡n thÃ¬ giÃºp mÃ¬nh vá»›i. Cáº£m Æ¡n ráº¥t nhiá»u.","Nhá» anh em giáº£i toÃ¡n (code python cÃ ng tá»‘t áº¡): CÃ³ má»™t ma tráº­n sá»‘ dÆ°Æ¡ng vuÃ´ng (n x n Ã´). Táº¡i má»—i hÃ ng vÃ  má»—i cá»™t láº¥y duy nháº¥t má»™t sá»‘, Ä‘Æ°á»£c n sá»‘. TÃ¬m tá»a Ä‘á»™ n sá»‘ sao cho tá»•ng cá»§a chÃºng lÃ  lá»›n nháº¥t. MÃ¬nh chá»‰ nghÄ© ra Ä‘Æ°á»£c cÃ¡ch thá»§ cÃ´ng lÃ  táº¡o ra má»i tá»• há»£p tá»a Ä‘á»™ Ä‘Ã¡p á»©ng yÃªu cáº§u bÃ i toÃ¡n, tÃ­nh tá»•ng rá»“i chá»n ra Ä‘Ã¡p Ã¡n lá»›n nháº¥t. Anh em cÃ³ cÃ¡ch nhanh hÆ¡n thÃ¬ giÃºp mÃ¬nh vá»›i. Cáº£m Æ¡n ráº¥t nhiá»u.",,"#Q&A, #math",,,
má»i ngÆ°á»i cho mÃ¬nh cÃ³ api cá»§a dá»‹ch vá»¥ nÃ o giÃºp mÃ¬nh Ä‘Æ°a vÃ o keyword => cho mÃ¬nh output 1 cÃ¢u dc ko?,má»i ngÆ°á»i cho mÃ¬nh cÃ³ api cá»§a dá»‹ch vá»¥ nÃ o giÃºp mÃ¬nh Ä‘Æ°a vÃ o keyword => cho mÃ¬nh output 1 cÃ¢u dc ko?,,,,,
"ChÃ o cÃ¡c anh chá»‹,
Hiá»‡n em Ä‘ang cÃ i Ä‘áº·t driver nvidia-515 cho ubutu 20.04 nhÆ°ng khÃ´ng cÃ i Ä‘Æ°á»£c vÃ  gáº·p lá»—i nhÆ° trÃªn hÃ¬nh áº¡, khÃ´ng biáº¿t anh chá»‹ nÃ o Ä‘Ã£ tá»«ng gáº·p lá»—i nhÆ° nÃ y chÆ°a áº¡, cÃ³ thá»ƒ chá»‰ em cÃ¡ch fix Ä‘Æ°á»£c khÃ´ng áº¡, em cáº£m Æ¡n.","ChÃ o cÃ¡c anh chá»‹, Hiá»‡n em Ä‘ang cÃ i Ä‘áº·t driver nvidia-515 cho ubutu 20.04 nhÆ°ng khÃ´ng cÃ i Ä‘Æ°á»£c vÃ  gáº·p lá»—i nhÆ° trÃªn hÃ¬nh áº¡, khÃ´ng biáº¿t anh chá»‹ nÃ o Ä‘Ã£ tá»«ng gáº·p lá»—i nhÆ° nÃ y chÆ°a áº¡, cÃ³ thá»ƒ chá»‰ em cÃ¡ch fix Ä‘Æ°á»£c khÃ´ng áº¡, em cáº£m Æ¡n.",,,,,
"ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n!
Em cÃ³ Ä‘ang tÃ¬m hiá»ƒu paper phÆ°Æ¡ng phÃ¡p tÃ¡ch tá»« cá»§a VnCoreNLP (link paper: http://www.lrec-conf.org/proceedings/lrec2018/pdf/55.pdf) . Em cÃ³ chÃºt tháº¯c máº¯c:
Trong paper tÃ¡c giáº£ cÃ³ nÃ³i ráº±ng sáº½ há»c cÃ¢y SCRDR rá»“i sau Ä‘Ã³ sá»­ dá»¥ng cÃ¢y Ä‘Ã³ Ä‘á»ƒ tÃ¡ch tá»« trong cÃ¡c cÃ¢u má»›i. Theo em hiá»ƒu thÃ¬ vá»›i má»—i tá»« sáº½ cÃ³ 1 cÃ¢y SCRDR, khÃ´ng biáº¿t em Ä‘Ã£ hiá»ƒu Ä‘Ãºng chÆ°a áº¡!
Em cáº£m Æ¡n ac!","ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n! Em cÃ³ Ä‘ang tÃ¬m hiá»ƒu paper phÆ°Æ¡ng phÃ¡p tÃ¡ch tá»« cá»§a VnCoreNLP (link paper: http://www.lrec-conf.org/proceedings/lrec2018/pdf/55.pdf) . Em cÃ³ chÃºt tháº¯c máº¯c: Trong paper tÃ¡c giáº£ cÃ³ nÃ³i ráº±ng sáº½ há»c cÃ¢y SCRDR rá»“i sau Ä‘Ã³ sá»­ dá»¥ng cÃ¢y Ä‘Ã³ Ä‘á»ƒ tÃ¡ch tá»« trong cÃ¡c cÃ¢u má»›i. Theo em hiá»ƒu thÃ¬ vá»›i má»—i tá»« sáº½ cÃ³ 1 cÃ¢y SCRDR, khÃ´ng biáº¿t em Ä‘Ã£ hiá»ƒu Ä‘Ãºng chÆ°a áº¡! Em cáº£m Æ¡n ac!",,,,,
"Hi má»i ngÆ°á»i,
Hiá»‡n táº¡i, em Ä‘ang tÃ¬m hiá»ƒu vá» seq2seq lstm cho machine translation (pytorch framework). Em Ä‘ang cÃ²n chÃºt ko rÃµ vá» viá»‡c preprocessing mong nÃªn Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡.
1) Khi táº¡o batch thÃ¬ em tháº¥y cÃ¡c batch (batch_size=8) cÃ³ sequence length khÃ¡c nhau (vd: torch.size((256,8)), torch.size((10009,8)) ). Trong trÆ°á»ng há»£p, mÃ¬nh cÃ³ pháº£i buá»™c táº¥t cáº£ cÃ¡c batch pháº£i cÃ³ cÃ¹ng shape hay Ä‘á»ƒ tá»± nhiÃªn nhÆ° nÃ y Ä‘Æ°á»£c?
2) MÃ¬nh cÃ³ pháº£i rÃ ng buá»™c max length cho input hay length nhÆ° tháº¿ nÃ o cÅ©ng Ä‘Æ°á»£c?","Hi má»i ngÆ°á»i, Hiá»‡n táº¡i, em Ä‘ang tÃ¬m hiá»ƒu vá» seq2seq lstm cho machine translation (pytorch framework). Em Ä‘ang cÃ²n chÃºt ko rÃµ vá» viá»‡c preprocessing mong nÃªn Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡. 1) Khi táº¡o batch thÃ¬ em tháº¥y cÃ¡c batch (batch_size=8) cÃ³ sequence length khÃ¡c nhau (vd: torch.size((256,8)), torch.size((10009,8)) ). Trong trÆ°á»ng há»£p, mÃ¬nh cÃ³ pháº£i buá»™c táº¥t cáº£ cÃ¡c batch pháº£i cÃ³ cÃ¹ng shape hay Ä‘á»ƒ tá»± nhiÃªn nhÆ° nÃ y Ä‘Æ°á»£c? 2) MÃ¬nh cÃ³ pháº£i rÃ ng buá»™c max length cho input hay length nhÆ° tháº¿ nÃ o cÅ©ng Ä‘Æ°á»£c?",,,,,
"Hi cáº£ nhÃ , kubeflow pipeline tutorials mÃ¬nh Ä‘Äƒng bÃªn MLOps VN Ä‘Æ°á»£c khÃ¡ nhiá»u ngÆ°á»i quan tÃ¢m nÃªn hÃ´m nay mÃ¬nh xin phÃ©p share láº¡i á»Ÿ Ä‘Ã¢y, hy vá»ng sáº½ giÃºp má»i ngÆ°á»i bá»›t pháº§n nÃ o khÃ³ khÄƒn khi lÃ m viá»‡c vá»›i tool nÃ y.
https://github.com/quan-dang/kubeflow-tutorials
----
Link group MLOps VN mÃ¬nh Ä‘á» cáº­p á»Ÿ trÃªn: https://www.facebook.com/groups/mlopsvn","Hi cáº£ nhÃ , kubeflow pipeline tutorials mÃ¬nh Ä‘Äƒng bÃªn MLOps VN Ä‘Æ°á»£c khÃ¡ nhiá»u ngÆ°á»i quan tÃ¢m nÃªn hÃ´m nay mÃ¬nh xin phÃ©p share láº¡i á»Ÿ Ä‘Ã¢y, hy vá»ng sáº½ giÃºp má»i ngÆ°á»i bá»›t pháº§n nÃ o khÃ³ khÄƒn khi lÃ m viá»‡c vá»›i tool nÃ y. https://github.com/quan-dang/kubeflow-tutorials ---- Link group MLOps VN mÃ¬nh Ä‘á» cáº­p á»Ÿ trÃªn: https://www.facebook.com/groups/mlopsvn",,,,,
"[Graph Transformer - a breakthrough of Transformer with graph data]
Transformer lÃ  lá»›p kiáº¿n trÃºc cÃ³ thá»ƒ há»c táº­p hiá»‡u quáº£ tá»« dá»¯ liá»‡u dáº¡ng sequential data cháº³ng háº¡n nhÆ° vÄƒn báº£n, Ã¢m thanh, chuá»—i thá»i gian. Tuy nhiÃªn chÃºng cho tháº¥y giá»›i háº¡n trong viá»‡c há»c cÃ¡c dá»¯ liá»‡u dáº¡ng graph (lÃ  nhá»¯ng dá»¯ liá»‡u káº¿t há»£p giá»¯a nodes vÃ  edges nhÆ° social network, logistic, entity relationship, consumption  behaviors). Má»™t biáº¿n thá»ƒ má»›i lÃ  Graph Transformer https://arxiv.org/abs/2012.09699 Ä‘Ã£ cho phÃ©p Ã¡p khÃ¡i quÃ¡t hÃ³a Transformer trÃªn má»™t graph báº¥t kÃ¬.
1. Äiá»ƒm má»›i máº»:
Vijay Prakash Dwivedi vÃ  Xavier Bresson táº¡i Nanyang Technological University Ä‘Ã£ táº¡o ra Graph Transformer (GT), má»™t Transfomer layer Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u graph. Xáº¿p chá»“ng cÃ¡c lá»›p GT sáº½ cung cáº¥p má»™t giáº£i phÃ¡p Transformer-based thay tháº¿ cho cÃ¡c Graph Neural Network Ä‘iá»ƒn hÃ¬nh, má»™t dáº¡ng kiáº¿n trÃºc Ã¡p dá»¥ng trÃªn dá»¯ liá»‡u dáº¡ng cÃ¡c node vÃ  edge káº¿t ná»‘i láº«n nhau.  Má»™t vÃ­ dá»¥ vá» dá»¯ liá»‡u dáº¡ng nÃ y: khÃ¡ch hÃ ng káº¿t ná»‘i vá»›i sáº£n pháº©m há» Ä‘Ã£ mua; tÃ i khoáº£n facebook cá»§a báº¡n káº¿t ná»‘i tá»›i nhá»¯ng ngÆ°á»i báº¡n tÆ°Æ¡ng tÃ¡c;  Hoáº·c cÃ¡c nguyÃªn tá»­ káº¿t ná»‘i vá»›i nhau trong phÃ¢n tá»­.
2. Äiá»ƒm máº¥u chá»‘t:
CÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ Ã¡p dá»¥ng Transformer cho graph data báº±ng cÃ¡ch gÃ¡n má»™t token cho má»—i node vÃ  tÃ­nh toÃ¡n attention giá»¯a má»—i má»™t cáº·p. PhÆ°Æ¡ng phÃ¡p nÃ y mÃ£ hÃ³a Ä‘Æ°á»£c:
- local relationships: Cháº³ng háº¡n nhÆ° cÃ¡c nodes nÃ o lÃ  hÃ ng xÃ³m (Ä‘Æ°a ra má»™t hyperparameter giÃºp xÃ¡c Ä‘á»‹nh vÃ¹ng lÃ¢n cáº­n náº±m trong má»™t sá»‘ má»©c Ä‘á»™ tÃ¡ch biá»‡t)
- global information: Cháº³ng háº¡n nhÆ° khoáº£ng cÃ¡ch cá»§a node vá»›i cÃ¡c nodes khÃ´ng hÃ ng xÃ³m.
Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n nÃ y cá»±c ká»³ tá»‘n kÃ©m Ä‘á»‘i vá»›i cÃ¡c Ä‘á»“ thá»‹ lá»›n, vÃ¬ tÃ­nh toÃ¡n cáº§n thiáº¿t cho self-attention tÄƒng lÃªn sá»‘ láº§n báº±ng báº­c hai kÃ­ch thÆ°á»›c cá»§a Ä‘áº§u vÃ o. Ãp dá»¥ng attention chá»‰ tá»›i cÃ¡c nodes hÃ ng xÃ³m giÃºp náº¯m báº¯t thÃ´ng tin cá»¥c bá»™ quan trá»ng trong khi cáº¯t giáº£m gÃ¡nh náº·ng tÃ­nh toÃ¡n. Trong khi Ä‘Ã³, má»™t positional vector biá»ƒu thá»‹ khoáº£ng cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i cá»§a má»—i cáº·p nodes cÃ³ thá»ƒ náº¯m báº¯t global information theo cÃ¡ch hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n.
3. NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng
CÃ¡c tÃ¡c giáº£ Ä‘Ã£ xÃ¢y dá»±ng ba mÃ´ hÃ¬nh, má»—i mÃ´ hÃ¬nh bao gá»“m cÃ¡c embedding layers, 10 GT layers (bao gá»“m self-attention vÃ  fully connected layers) theo sau lÃ  má»™t máº¡ng neural network thÃ´ng thÆ°á»ng. Má»—i mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n cho má»™t nhiá»‡m vá»¥ khÃ¡c nhau: phÃ¢n loáº¡i hai lá»›p, phÃ¢n loáº¡i sÃ¡u lá»›p vÃ  há»“i quy Æ°á»›c tÃ­nh Ä‘á»™ hÃ²a tan cá»§a cÃ¡c há»£p cháº¥t hÃ³a há»c cÃ³ chá»©a káº½m.
- Cho má»™t Ä‘á»“ thá»‹, cÃ¡c embedding layers táº¡o ra má»™t embedding vector vÃ  positional vector cho má»—i nÃºt. Sá»­ dá»¥ng constrastive learning Ä‘á»ƒ táº¡o ra cÃ¡c positional vector tÆ°Æ¡ng tá»± cho cÃ¡c node hÃ ng xÃ³m vÃ  cÃ¡c positinal vector khÃ¡c nhau cho cÃ¡c nodes cÃ¡ch xa.  Cá»™ng embedding vector vÃ  positional vector Ä‘á»ƒ táº¡o thÃ nh vector biá»ƒu diá»…n cho má»—i node.
- Lá»›p GT Ä‘Ã£ mÃ i gá»t tá»«ng biá»ƒu diá»…n node báº±ng cÃ¡ch Ã¡p dá»¥ng self-attention giá»¯a node Ä‘Ã³ vá»›i cÃ¡c nodes lÃ¢n cáº­n. Sau Ä‘Ã³, nÃ³ chuyá»ƒn cÃ¡c biá»ƒu diá»…n nodes sang fully connected layer.
- MÃ´ hÃ¬nh Ä‘Ã£ thá»±c hiá»‡n liÃªn tiáº¿p nhá»¯ng bÆ°á»›c nÃ y qua 10 layers vÃ  cung cáº¥p cÃ¡c biá»ƒu diá»…n cuá»‘i cÃ¹ng cho má»™t neural network thÃ´ng thÆ°á»ng nháº±m thá»±c hiá»‡n phÃ¢n loáº¡i hoáº·c há»“i quy.
4. Káº¿t quáº£:
MÃ´ hÃ¬nh cá»§a cÃ¡c tÃ¡c giáº£ láº§n lÆ°á»£t Ä‘áº¡t Ä‘Æ°á»£c 73,17% vÃ  84,81% accuracy Ä‘á»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  sÃ¡u lá»›p. Má»™t baseline khÃ¡c lÃ  GAT (ICLR 2018): https://arxiv.org/pdf/1710.10903.pdfÃ¡p dá»¥ng attention qua cÃ¡c biá»ƒu diá»…n node hÃ ng xÃ³m Ä‘áº¡t accuracy láº§n lÆ°á»£t lÃ  70,58% vÃ  78,27% accuracy. Trong nhiá»‡m vá»¥ há»“i quy, mÃ´ hÃ¬nh cá»§a cÃ¡c tÃ¡c giáº£ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh (MAE) lÃ  0,226 so vá»›i GAT lÃ  0,384 (MAE cÃ ng tháº¥p cÃ ng tá»‘t). Tuy nhiÃªn, nÃ³ hoáº¡t Ä‘á»™ng kÃ©m hÆ¡n má»™t chÃºt so vá»›i Gated Graph ConvNet: https://arxiv.org/abs/1711.07553trong cáº£ ba tÃ¡c vá»¥ nÃ y
5. Suy nghÄ© cá»§a tÃ´i:
Ká»ƒ tá»« khi ra Ä‘á»i vÃ o nÄƒm 2017 trong paper â€œAttention is all you needâ€, cÃ¡c kiáº¿n trÃºc há» Transformer Ä‘Ã£ chá»©ng minh Ä‘Æ°á»£c sá»©c máº¡nh cá»§a chÃºng Ä‘á»‘i vá»›i ban Ä‘áº§u lÃ  dá»¯ liá»‡u vÄƒn báº£n, Ã¢m thanh vÃ  sau Ä‘Ã³ lÃ  hÃ¬nh áº£nh, timeseries data. KhÃ´ng nhá»¯ng tháº¿, Ä‘á»‘i vá»›i graph data thÃ¬ paper nÃ y Ä‘Ã£ chá»©ng minh chÃºng lÃ  hoÃ n toÃ n há»¯u Ã­ch. Máº·c dÃ¹ Graph Transformer khÃ´ng pháº£i lÃ  máº¡ng neural network máº¡nh nháº¥t nhÆ°ng Ä‘Ã£ táº¡o ra má»™t strong baseline cá»§ng cá»‘ cho nhá»¯ng nghiÃªn cá»©u tiáº¿p theo trong lÄ©nh vá»±c nÃ y. Sáº½ lÃ  tháº¿ nÃ o náº¿u Ã¡p dá»¥ng Graph Transformer trÃªn dá»¯ liá»‡u vÄƒn báº£n, Ã¢m thanh, hÃ¬nh áº£nh?
------------------------------------------------------------------------
KhÃ³a há»c vá»ƒ Machine Learning in Production â€“ MLOps, khai giáº£ng 24/07, nháº±m cung cáº¥p kiáº¿n thá»©c thá»±c tiá»…n vá» cÃ¡ch xÃ¢y dá»±ng, duy trÃ¬, váº­n hÃ nh vÃ  quáº£n trá»‹ mÃ´ hÃ¬nh Machine Learning vÃ  hÆ°á»›ng tá»›i trao quyá»n cho cÃ¡c doanh nghiá»‡p vá»«a vÃ  nhá» nÄƒng lá»±c thá»±c thi mÃ´ hÃ¬nh trÃªn cloud service: https://forms.gle/o38H5RG479ojTQ6B6","[Graph Transformer - a breakthrough of Transformer with graph data] Transformer lÃ  lá»›p kiáº¿n trÃºc cÃ³ thá»ƒ há»c táº­p hiá»‡u quáº£ tá»« dá»¯ liá»‡u dáº¡ng sequential data cháº³ng háº¡n nhÆ° vÄƒn báº£n, Ã¢m thanh, chuá»—i thá»i gian. Tuy nhiÃªn chÃºng cho tháº¥y giá»›i háº¡n trong viá»‡c há»c cÃ¡c dá»¯ liá»‡u dáº¡ng graph (lÃ  nhá»¯ng dá»¯ liá»‡u káº¿t há»£p giá»¯a nodes vÃ  edges nhÆ° social network, logistic, entity relationship, consumption behaviors). Má»™t biáº¿n thá»ƒ má»›i lÃ  Graph Transformer https://arxiv.org/abs/2012.09699 Ä‘Ã£ cho phÃ©p Ã¡p khÃ¡i quÃ¡t hÃ³a Transformer trÃªn má»™t graph báº¥t kÃ¬. 1. Äiá»ƒm má»›i máº»: Vijay Prakash Dwivedi vÃ  Xavier Bresson táº¡i Nanyang Technological University Ä‘Ã£ táº¡o ra Graph Transformer (GT), má»™t Transfomer layer Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u graph. Xáº¿p chá»“ng cÃ¡c lá»›p GT sáº½ cung cáº¥p má»™t giáº£i phÃ¡p Transformer-based thay tháº¿ cho cÃ¡c Graph Neural Network Ä‘iá»ƒn hÃ¬nh, má»™t dáº¡ng kiáº¿n trÃºc Ã¡p dá»¥ng trÃªn dá»¯ liá»‡u dáº¡ng cÃ¡c node vÃ  edge káº¿t ná»‘i láº«n nhau. Má»™t vÃ­ dá»¥ vá» dá»¯ liá»‡u dáº¡ng nÃ y: khÃ¡ch hÃ ng káº¿t ná»‘i vá»›i sáº£n pháº©m há» Ä‘Ã£ mua; tÃ i khoáº£n facebook cá»§a báº¡n káº¿t ná»‘i tá»›i nhá»¯ng ngÆ°á»i báº¡n tÆ°Æ¡ng tÃ¡c; Hoáº·c cÃ¡c nguyÃªn tá»­ káº¿t ná»‘i vá»›i nhau trong phÃ¢n tá»­. 2. Äiá»ƒm máº¥u chá»‘t: CÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ Ã¡p dá»¥ng Transformer cho graph data báº±ng cÃ¡ch gÃ¡n má»™t token cho má»—i node vÃ  tÃ­nh toÃ¡n attention giá»¯a má»—i má»™t cáº·p. PhÆ°Æ¡ng phÃ¡p nÃ y mÃ£ hÃ³a Ä‘Æ°á»£c: - local relationships: Cháº³ng háº¡n nhÆ° cÃ¡c nodes nÃ o lÃ  hÃ ng xÃ³m (Ä‘Æ°a ra má»™t hyperparameter giÃºp xÃ¡c Ä‘á»‹nh vÃ¹ng lÃ¢n cáº­n náº±m trong má»™t sá»‘ má»©c Ä‘á»™ tÃ¡ch biá»‡t) - global information: Cháº³ng háº¡n nhÆ° khoáº£ng cÃ¡ch cá»§a node vá»›i cÃ¡c nodes khÃ´ng hÃ ng xÃ³m. Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n nÃ y cá»±c ká»³ tá»‘n kÃ©m Ä‘á»‘i vá»›i cÃ¡c Ä‘á»“ thá»‹ lá»›n, vÃ¬ tÃ­nh toÃ¡n cáº§n thiáº¿t cho self-attention tÄƒng lÃªn sá»‘ láº§n báº±ng báº­c hai kÃ­ch thÆ°á»›c cá»§a Ä‘áº§u vÃ o. Ãp dá»¥ng attention chá»‰ tá»›i cÃ¡c nodes hÃ ng xÃ³m giÃºp náº¯m báº¯t thÃ´ng tin cá»¥c bá»™ quan trá»ng trong khi cáº¯t giáº£m gÃ¡nh náº·ng tÃ­nh toÃ¡n. Trong khi Ä‘Ã³, má»™t positional vector biá»ƒu thá»‹ khoáº£ng cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i cá»§a má»—i cáº·p nodes cÃ³ thá»ƒ náº¯m báº¯t global information theo cÃ¡ch hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n. 3. NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng CÃ¡c tÃ¡c giáº£ Ä‘Ã£ xÃ¢y dá»±ng ba mÃ´ hÃ¬nh, má»—i mÃ´ hÃ¬nh bao gá»“m cÃ¡c embedding layers, 10 GT layers (bao gá»“m self-attention vÃ  fully connected layers) theo sau lÃ  má»™t máº¡ng neural network thÃ´ng thÆ°á»ng. Má»—i mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n cho má»™t nhiá»‡m vá»¥ khÃ¡c nhau: phÃ¢n loáº¡i hai lá»›p, phÃ¢n loáº¡i sÃ¡u lá»›p vÃ  há»“i quy Æ°á»›c tÃ­nh Ä‘á»™ hÃ²a tan cá»§a cÃ¡c há»£p cháº¥t hÃ³a há»c cÃ³ chá»©a káº½m. - Cho má»™t Ä‘á»“ thá»‹, cÃ¡c embedding layers táº¡o ra má»™t embedding vector vÃ  positional vector cho má»—i nÃºt. Sá»­ dá»¥ng constrastive learning Ä‘á»ƒ táº¡o ra cÃ¡c positional vector tÆ°Æ¡ng tá»± cho cÃ¡c node hÃ ng xÃ³m vÃ  cÃ¡c positinal vector khÃ¡c nhau cho cÃ¡c nodes cÃ¡ch xa. Cá»™ng embedding vector vÃ  positional vector Ä‘á»ƒ táº¡o thÃ nh vector biá»ƒu diá»…n cho má»—i node. - Lá»›p GT Ä‘Ã£ mÃ i gá»t tá»«ng biá»ƒu diá»…n node báº±ng cÃ¡ch Ã¡p dá»¥ng self-attention giá»¯a node Ä‘Ã³ vá»›i cÃ¡c nodes lÃ¢n cáº­n. Sau Ä‘Ã³, nÃ³ chuyá»ƒn cÃ¡c biá»ƒu diá»…n nodes sang fully connected layer. - MÃ´ hÃ¬nh Ä‘Ã£ thá»±c hiá»‡n liÃªn tiáº¿p nhá»¯ng bÆ°á»›c nÃ y qua 10 layers vÃ  cung cáº¥p cÃ¡c biá»ƒu diá»…n cuá»‘i cÃ¹ng cho má»™t neural network thÃ´ng thÆ°á»ng nháº±m thá»±c hiá»‡n phÃ¢n loáº¡i hoáº·c há»“i quy. 4. Káº¿t quáº£: MÃ´ hÃ¬nh cá»§a cÃ¡c tÃ¡c giáº£ láº§n lÆ°á»£t Ä‘áº¡t Ä‘Æ°á»£c 73,17% vÃ  84,81% accuracy Ä‘á»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  sÃ¡u lá»›p. Má»™t baseline khÃ¡c lÃ  GAT (ICLR 2018): https://arxiv.org/pdf/1710.10903.pdfÃ¡p dá»¥ng attention qua cÃ¡c biá»ƒu diá»…n node hÃ ng xÃ³m Ä‘áº¡t accuracy láº§n lÆ°á»£t lÃ  70,58% vÃ  78,27% accuracy. Trong nhiá»‡m vá»¥ há»“i quy, mÃ´ hÃ¬nh cá»§a cÃ¡c tÃ¡c giáº£ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh (MAE) lÃ  0,226 so vá»›i GAT lÃ  0,384 (MAE cÃ ng tháº¥p cÃ ng tá»‘t). Tuy nhiÃªn, nÃ³ hoáº¡t Ä‘á»™ng kÃ©m hÆ¡n má»™t chÃºt so vá»›i Gated Graph ConvNet: https://arxiv.org/abs/1711.07553trong cáº£ ba tÃ¡c vá»¥ nÃ y 5. Suy nghÄ© cá»§a tÃ´i: Ká»ƒ tá»« khi ra Ä‘á»i vÃ o nÄƒm 2017 trong paper â€œAttention is all you needâ€, cÃ¡c kiáº¿n trÃºc há» Transformer Ä‘Ã£ chá»©ng minh Ä‘Æ°á»£c sá»©c máº¡nh cá»§a chÃºng Ä‘á»‘i vá»›i ban Ä‘áº§u lÃ  dá»¯ liá»‡u vÄƒn báº£n, Ã¢m thanh vÃ  sau Ä‘Ã³ lÃ  hÃ¬nh áº£nh, timeseries data. KhÃ´ng nhá»¯ng tháº¿, Ä‘á»‘i vá»›i graph data thÃ¬ paper nÃ y Ä‘Ã£ chá»©ng minh chÃºng lÃ  hoÃ n toÃ n há»¯u Ã­ch. Máº·c dÃ¹ Graph Transformer khÃ´ng pháº£i lÃ  máº¡ng neural network máº¡nh nháº¥t nhÆ°ng Ä‘Ã£ táº¡o ra má»™t strong baseline cá»§ng cá»‘ cho nhá»¯ng nghiÃªn cá»©u tiáº¿p theo trong lÄ©nh vá»±c nÃ y. Sáº½ lÃ  tháº¿ nÃ o náº¿u Ã¡p dá»¥ng Graph Transformer trÃªn dá»¯ liá»‡u vÄƒn báº£n, Ã¢m thanh, hÃ¬nh áº£nh? ------------------------------------------------------------------------ KhÃ³a há»c vá»ƒ Machine Learning in Production â€“ MLOps, khai giáº£ng 24/07, nháº±m cung cáº¥p kiáº¿n thá»©c thá»±c tiá»…n vá» cÃ¡ch xÃ¢y dá»±ng, duy trÃ¬, váº­n hÃ nh vÃ  quáº£n trá»‹ mÃ´ hÃ¬nh Machine Learning vÃ  hÆ°á»›ng tá»›i trao quyá»n cho cÃ¡c doanh nghiá»‡p vá»«a vÃ  nhá» nÄƒng lá»±c thá»±c thi mÃ´ hÃ¬nh trÃªn cloud service: https://forms.gle/o38H5RG479ojTQ6B6",,,,,
MÃ¬nh muá»‘n chuyá»ƒn tá»« chá»¯ viáº¿t tay trÃªn áº£nh sang dá»¯ liá»‡u file text. Má»i ngÆ°á»i cÃ³ tÃ i liá»‡u nÃ o Ä‘á»ƒ tham kháº£o cho mÃ¬nh xin áº¡.,MÃ¬nh muá»‘n chuyá»ƒn tá»« chá»¯ viáº¿t tay trÃªn áº£nh sang dá»¯ liá»‡u file text. Má»i ngÆ°á»i cÃ³ tÃ i liá»‡u nÃ o Ä‘á»ƒ tham kháº£o cho mÃ¬nh xin áº¡.,,,,,
"ChÃ o mn, e cÃ³ má»™t sá»‘ cÃ¢u há»i vá» viá»‡c sá»­ dá»¥ng package pytorch geometric/PyG áº¡
1/ E xin cÃ¡ch mn cÃ i pytorch_geometric trÃªn colab áº¡. E Ä‘Ã£ cÃ i Ä‘Ãºng nhÆ° hÆ°á»›ng dáº«n trÃªn doc cá»§a PyG, cÃ i Ä‘Æ°á»£c nhÆ°ng khi import thÃ¬ láº¡i ra lá»—i package not found
2/ Trong pytorch cÃ³ class nÃ o tÆ°Æ¡ng tá»± nhÆ° cÃ¡i pytorch_geometric.data.Data khÃ´ng áº¡? E tháº¥y thÆ°á»ng code ngÆ°á»i ta sá»­ dá»¥ng pytorch_geometric.data.Data cÃ³ thá»ƒ set Ä‘á»§ loáº¡i property cho datapoint, e cÅ©ng Ä‘ang cáº§n dÃ¹ng tÃ­nh nÄƒng nÃ y nhÆ°ng ko cáº§n Ä‘áº¿n viá»‡c pháº£i lÆ°u dá»¯ liá»‡u Ä‘á»“ thá»‹","ChÃ o mn, e cÃ³ má»™t sá»‘ cÃ¢u há»i vá» viá»‡c sá»­ dá»¥ng package pytorch geometric/PyG áº¡ 1/ E xin cÃ¡ch mn cÃ i pytorch_geometric trÃªn colab áº¡. E Ä‘Ã£ cÃ i Ä‘Ãºng nhÆ° hÆ°á»›ng dáº«n trÃªn doc cá»§a PyG, cÃ i Ä‘Æ°á»£c nhÆ°ng khi import thÃ¬ láº¡i ra lá»—i package not found 2/ Trong pytorch cÃ³ class nÃ o tÆ°Æ¡ng tá»± nhÆ° cÃ¡i pytorch_geometric.data.Data khÃ´ng áº¡? E tháº¥y thÆ°á»ng code ngÆ°á»i ta sá»­ dá»¥ng pytorch_geometric.data.Data cÃ³ thá»ƒ set Ä‘á»§ loáº¡i property cho datapoint, e cÅ©ng Ä‘ang cáº§n dÃ¹ng tÃ­nh nÄƒng nÃ y nhÆ°ng ko cáº§n Ä‘áº¿n viá»‡c pháº£i lÆ°u dá»¯ liá»‡u Ä‘á»“ thá»‹",,,,,
"[Pen and Paper Exercises in Machine Learning]

Bá»™ sÆ°u táº­p hÆ¡n 200 trang, chá»§ yáº¿u lÃ  cÃ¡c bÃ i táº­p biáº¿n Ä‘á»•i báº±ng tay trong Machine Learning. CÃ¡c bÃ i táº­p thuá»™c cÃ¡c chá»§ Ä‘á» sau: 
- Linear algebra
- Optimisation
- Directed graphical models
- Undirected graphical models
- Expressive power of graphical models
- Factor graphs and message passing
- Inference for hidden Markov models
- Model-based learning (including ICA and unnormalised models)
- Variational inference

Má»i ngÆ°á»i download á»Ÿ Ä‘Ã¢y:
https://arxiv.org/pdf/2206.13446.pdf","[Pen and Paper Exercises in Machine Learning] Bá»™ sÆ°u táº­p hÆ¡n 200 trang, chá»§ yáº¿u lÃ  cÃ¡c bÃ i táº­p biáº¿n Ä‘á»•i báº±ng tay trong Machine Learning. CÃ¡c bÃ i táº­p thuá»™c cÃ¡c chá»§ Ä‘á» sau: - Linear algebra - Optimisation - Directed graphical models - Undirected graphical models - Expressive power of graphical models - Factor graphs and message passing - Inference for hidden Markov models - Model-based learning (including ICA and unnormalised models) - Variational inference Má»i ngÆ°á»i download á»Ÿ Ä‘Ã¢y: https://arxiv.org/pdf/2206.13446.pdf",,,,,
"Hi anh, chá»‹,
- Em Ä‘ang lÃ m luáº­n vÄƒn Tháº¡c SÄ© CNTT, em lÃ m vá» machine learning, Ä‘á» tÃ i cá»§a em ""Loan Repayment Prediction Using Machine Learning Algorithms"",  
- Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i bÃ¡o nÃ y lÃ  tá»« Lending Club, má»™t trang web káº¿t ná»‘i ngÆ°á»i vay vÃ  nhÃ  Ä‘áº§u tÆ° qua Internet. NÃ³ bao gá»“m 9.578 quan sÃ¡t Ä‘Æ°á»£c tÃ i trá»£ thÃ´ng qua ná»n táº£ng LendingClub.com tá»« thÃ¡ng 5 nÄƒm 2007 Ä‘áº¿n thÃ¡ng 2 nÄƒm 2010
- CÃ¡c bÆ°á»›c em thá»±c hiá»‡n bÃ i toÃ¡n: 
1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u - Data preprocessing:
   a. TÃ¬m há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c thuá»™c tÃ­nh.
   b. Xá»­ lÃ½ cÃ¡c thuá»™c tÃ­nh dáº¡ng vÄƒn báº£n
   c. Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ bá»‹ thiáº¿u(Data Imputation - Missing Data Replacement)
   d. TÃ¡ch dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra
   e. Chuáº©n hÃ³a dá»¯ liá»‡u
2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh:
   a. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng kiá»ƒm Ä‘á»‹nh chÃ©o
   b. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng ma tráº­n nháº§m láº«n
      + Presision
      + Recall
      + F1-Score
      + ÄÆ°á»ng cong ROC
=> Káº¿t quáº£ cá»§a em khÃ´ng Ä‘Æ°á»£c tá»‘t láº¯m, Em mong anh, chi cÃ³ kinh nghiá»‡m hÆ°á»›ng dáº«n, gÃ³p Ã½ giÃºp em hoáº·c cÃ³ thá»ƒ inbox, em xin Ä‘a táº¡.
- Em upload link github gá»“m data, code náº¿u Ä‘Æ°á»£c anh, chá»‹ xem giÃºp áº¡. em xin chÃ¢n thÃ nh cáº£m Æ¡n.","Hi anh, chá»‹, - Em Ä‘ang lÃ m luáº­n vÄƒn Tháº¡c SÄ© CNTT, em lÃ m vá» machine learning, Ä‘á» tÃ i cá»§a em ""Loan Repayment Prediction Using Machine Learning Algorithms"", - Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i bÃ¡o nÃ y lÃ  tá»« Lending Club, má»™t trang web káº¿t ná»‘i ngÆ°á»i vay vÃ  nhÃ  Ä‘áº§u tÆ° qua Internet. NÃ³ bao gá»“m 9.578 quan sÃ¡t Ä‘Æ°á»£c tÃ i trá»£ thÃ´ng qua ná»n táº£ng LendingClub.com tá»« thÃ¡ng 5 nÄƒm 2007 Ä‘áº¿n thÃ¡ng 2 nÄƒm 2010 - CÃ¡c bÆ°á»›c em thá»±c hiá»‡n bÃ i toÃ¡n: 1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u - Data preprocessing: a. TÃ¬m há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c thuá»™c tÃ­nh. b. Xá»­ lÃ½ cÃ¡c thuá»™c tÃ­nh dáº¡ng vÄƒn báº£n c. Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ bá»‹ thiáº¿u(Data Imputation - Missing Data Replacement) d. TÃ¡ch dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra e. Chuáº©n hÃ³a dá»¯ liá»‡u 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh: a. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng kiá»ƒm Ä‘á»‹nh chÃ©o b. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng ma tráº­n nháº§m láº«n + Presision + Recall + F1-Score + ÄÆ°á»ng cong ROC => Káº¿t quáº£ cá»§a em khÃ´ng Ä‘Æ°á»£c tá»‘t láº¯m, Em mong anh, chi cÃ³ kinh nghiá»‡m hÆ°á»›ng dáº«n, gÃ³p Ã½ giÃºp em hoáº·c cÃ³ thá»ƒ inbox, em xin Ä‘a táº¡. - Em upload link github gá»“m data, code náº¿u Ä‘Æ°á»£c anh, chá»‹ xem giÃºp áº¡. em xin chÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
"Help Required!
I want to hide personal information in documents like passport number, national security number, name and home address in an image.
First: I have applied OCR to recognize all the words in document then i put If statement and some specific part like passport number.
The problem is that sometime OCR wrongly recognize the passport number and sometime other fields as well and bypass the if statement. Thus, it is fail to hide personal information in document.
Please recommend me any solution?","Help Required! I want to hide personal information in documents like passport number, national security number, name and home address in an image. First: I have applied OCR to recognize all the words in document then i put If statement and some specific part like passport number. The problem is that sometime OCR wrongly recognize the passport number and sometime other fields as well and bypass the if statement. Thus, it is fail to hide personal information in document. Please recommend me any solution?",,,,,
"ChÃ o cáº£ nhÃ , em/mÃ¬nh mong Ä‘Æ°á»£c há»i thÄƒm vÃ i chá»‰ dáº«n vá» cá»™ng Ä‘á»“ng ML/ Computer vision á»Ÿ Viá»‡t Nam
Cty em/mÃ¬nh cÃ³ 1 team dÃ y dáº¡n hÆ¡n 15+ nÄƒm kinh nghiá»‡m á»©ng dá»¥ng AI vÃ o xá»­ lÃ½ & quáº£n lÃ½ hÆ¡n 200+ triá»‡u dá»¯ liá»‡u hÃ¬nh áº£nh, vÃ  gáº§n Ä‘Ã¢y báº¯t Ä‘áº§u phÃ¢n phá»‘i cÃ¡c dá»¯ liá»‡u nÃ y cho dá»± Ã¡n AI táº¡i Panasonic, Honda, SoftBank...
BÃªn mÃ¬nh nháº­n tháº¥y dá»¯ liá»‡u tá»± nhiÃªn trÃªn thá»‹ trÆ°á»ng cÅ©ng nhiá»u nhÆ°ng chÆ°a Ä‘Æ°á»£c phÃ¢n luá»“ng hiá»‡u quáº£, nÃªn Ä‘Ã£ máº¡nh dáº¡n nghiÃªn cá»©u má»™t kÃªnh phÃ¢n phá»‘i dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n vá» viá»‡c tiáº¿p cáº­n dá»¯ liá»‡u hÃ¬nh áº£nh sá»‘ lÆ°á»£ng lá»›n, cháº¥t lÆ°á»£ng cao, chi phÃ­ há»£p lÃ½ cho cÃ¡c dá»± Ã¡n ML.
Hiá»‡n team em/mÃ¬nh ráº¥t mong Ä‘Æ°á»£c
1- Trao Ä‘á»•i insights tá»« cÃ¡c anh chá»‹ em data scientists, ML engineers cÃ³ kinh nghiá»‡m trong cÃ¡c bÃ i toÃ¡n computer vision Ä‘á»ƒ lÃ m rÃµ cÃ¡c giáº£ thiáº¿t vá» nhu cáº§u thá»±c tiá»…n.
2- Giao lÆ°u vá»›i cá»™ng Ä‘á»“ng AI/ML á»Ÿ Viá»‡t Nam Ä‘á»ƒ tÄƒng cÆ°á»ng chia sáº» thÃ´ng tin & cÆ¡ há»™i
Em/ mÃ¬nh ráº¥t mong Ä‘Æ°á»£c há»— trá»£
1- Giá»›i thiá»‡u má»™t sá»‘ anh chá»‹ em trong ngÃ nh cÃ³ thá»ƒ dÃ nh ra 20-30p chia sáº» vá»›i team em/mÃ¬nh vá» Ã½ tÆ°á»Ÿng nÃ y
2- Giá»›i thiá»‡u má»™t sá»‘ kÃªnh giao lÆ°u hiá»‡u quáº£. Hoáº·c náº¿u cÃ³ anh chá»‹ em nÃ o Ä‘Ã£ (hoáº·c sáº½) tham gia VinAI hoáº·c AI Summit thÃ¬ mong Ä‘Æ°á»£c chia sáº» kinh nghiá»‡m Ä‘Äƒng kÃ½ workshop/expo á»Ÿ Ä‘áº¥y áº¡ :D
Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u ğŸ«°ğŸ™","ChÃ o cáº£ nhÃ , em/mÃ¬nh mong Ä‘Æ°á»£c há»i thÄƒm vÃ i chá»‰ dáº«n vá» cá»™ng Ä‘á»“ng ML/ Computer vision á»Ÿ Viá»‡t Nam Cty em/mÃ¬nh cÃ³ 1 team dÃ y dáº¡n hÆ¡n 15+ nÄƒm kinh nghiá»‡m á»©ng dá»¥ng AI vÃ o xá»­ lÃ½ & quáº£n lÃ½ hÆ¡n 200+ triá»‡u dá»¯ liá»‡u hÃ¬nh áº£nh, vÃ  gáº§n Ä‘Ã¢y báº¯t Ä‘áº§u phÃ¢n phá»‘i cÃ¡c dá»¯ liá»‡u nÃ y cho dá»± Ã¡n AI táº¡i Panasonic, Honda, SoftBank... BÃªn mÃ¬nh nháº­n tháº¥y dá»¯ liá»‡u tá»± nhiÃªn trÃªn thá»‹ trÆ°á»ng cÅ©ng nhiá»u nhÆ°ng chÆ°a Ä‘Æ°á»£c phÃ¢n luá»“ng hiá»‡u quáº£, nÃªn Ä‘Ã£ máº¡nh dáº¡n nghiÃªn cá»©u má»™t kÃªnh phÃ¢n phá»‘i dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n vá» viá»‡c tiáº¿p cáº­n dá»¯ liá»‡u hÃ¬nh áº£nh sá»‘ lÆ°á»£ng lá»›n, cháº¥t lÆ°á»£ng cao, chi phÃ­ há»£p lÃ½ cho cÃ¡c dá»± Ã¡n ML. Hiá»‡n team em/mÃ¬nh ráº¥t mong Ä‘Æ°á»£c 1- Trao Ä‘á»•i insights tá»« cÃ¡c anh chá»‹ em data scientists, ML engineers cÃ³ kinh nghiá»‡m trong cÃ¡c bÃ i toÃ¡n computer vision Ä‘á»ƒ lÃ m rÃµ cÃ¡c giáº£ thiáº¿t vá» nhu cáº§u thá»±c tiá»…n. 2- Giao lÆ°u vá»›i cá»™ng Ä‘á»“ng AI/ML á»Ÿ Viá»‡t Nam Ä‘á»ƒ tÄƒng cÆ°á»ng chia sáº» thÃ´ng tin & cÆ¡ há»™i Em/ mÃ¬nh ráº¥t mong Ä‘Æ°á»£c há»— trá»£ 1- Giá»›i thiá»‡u má»™t sá»‘ anh chá»‹ em trong ngÃ nh cÃ³ thá»ƒ dÃ nh ra 20-30p chia sáº» vá»›i team em/mÃ¬nh vá» Ã½ tÆ°á»Ÿng nÃ y 2- Giá»›i thiá»‡u má»™t sá»‘ kÃªnh giao lÆ°u hiá»‡u quáº£. Hoáº·c náº¿u cÃ³ anh chá»‹ em nÃ o Ä‘Ã£ (hoáº·c sáº½) tham gia VinAI hoáº·c AI Summit thÃ¬ mong Ä‘Æ°á»£c chia sáº» kinh nghiá»‡m Ä‘Äƒng kÃ½ workshop/expo á»Ÿ Ä‘áº¥y áº¡ :D Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
HIá»‡n táº¡i e Ä‘ang táº­p tÃ nh vá» Data Analyst. Em cÃ³ má»™t cÃ¢u há»i ráº¥t mong cÃ¡c a/c lÃ m trong lÄ©nh vá»±c nÃ y giáº£i Ä‘Ã¡p áº¡. ÄÃ³ lÃ  khi lá»±a chá»n Ä‘áº·c trÆ°ng Ä‘á»ƒ cho vÃ o mÃ´ hÃ¬nh huáº¥n luyá»‡n ( giáº£ sá»­ cho bÃ i toÃ¡n phÃ¢n loáº¡i) . Em cÃ³
Má»Œi ngÆ°á»i thÆ°á»ng tÃ¬m insight tá»« data nhÆ° tháº¿ nÃ o ngoÃ i viá»‡c phÃ¢n tÃ­ch EDA ra áº¡ (giáº£ sá»­ Ä‘Ã£ qua bÆ°á»›c tÃ¬m hiá»ƒu nghiá»‡p vá»¥ vá» thuá»™c tÃ­nh Ä‘Ã³ rá»“i). E tháº¥y phÃ¢n tÃ­ch EDA chá»‰ ra Ä‘Æ°á»£c insight Ä‘á»‘i vá»›i cÃ¡c bá»™ dá»¯ liá»‡u Ä‘áº¹p trÃªn máº¡ng, thá»±c táº¿ thÃ¬ dá»¯ liá»‡u bÃªn ngoÃ i nÃ³ ko nhÆ° tháº¿ ( tá»©c chá»“ng láº¥n lÃªn nhau)
Dá»¯ liá»‡u thá»±c táº¿ e tháº¥y ráº¥t há»—n Ä‘á»™n. Trong thá»±c táº¿ cÃ¡c a/c cÃ³ khi nÃ o thu tháº­p pháº£i dá»¯ liá»‡u mÃ  ko cÃ³ tÃ¡c dá»¥ng cho mÃ´ hÃ¬nh ko áº¡
Em cáº£m Æ¡n mn nhiá»u","Em chÃ o má»i ngÆ°á»i áº¡. HIá»‡n táº¡i e Ä‘ang táº­p tÃ nh vá» Data Analyst. Em cÃ³ má»™t cÃ¢u há»i ráº¥t mong cÃ¡c a/c lÃ m trong lÄ©nh vá»±c nÃ y giáº£i Ä‘Ã¡p áº¡. ÄÃ³ lÃ  khi lá»±a chá»n Ä‘áº·c trÆ°ng Ä‘á»ƒ cho vÃ o mÃ´ hÃ¬nh huáº¥n luyá»‡n ( giáº£ sá»­ cho bÃ i toÃ¡n phÃ¢n loáº¡i) . Em cÃ³ Má»Œi ngÆ°á»i thÆ°á»ng tÃ¬m insight tá»« data nhÆ° tháº¿ nÃ o ngoÃ i viá»‡c phÃ¢n tÃ­ch EDA ra áº¡ (giáº£ sá»­ Ä‘Ã£ qua bÆ°á»›c tÃ¬m hiá»ƒu nghiá»‡p vá»¥ vá» thuá»™c tÃ­nh Ä‘Ã³ rá»“i). E tháº¥y phÃ¢n tÃ­ch EDA chá»‰ ra Ä‘Æ°á»£c insight Ä‘á»‘i vá»›i cÃ¡c bá»™ dá»¯ liá»‡u Ä‘áº¹p trÃªn máº¡ng, thá»±c táº¿ thÃ¬ dá»¯ liá»‡u bÃªn ngoÃ i nÃ³ ko nhÆ° tháº¿ ( tá»©c chá»“ng láº¥n lÃªn nhau) Dá»¯ liá»‡u thá»±c táº¿ e tháº¥y ráº¥t há»—n Ä‘á»™n. Trong thá»±c táº¿ cÃ¡c a/c cÃ³ khi nÃ o thu tháº­p pháº£i dá»¯ liá»‡u mÃ  ko cÃ³ tÃ¡c dá»¥ng cho mÃ´ hÃ¬nh ko áº¡ Em cáº£m Æ¡n mn nhiá»u",,,,,
"Em chÃ o cÃ¡c anh chá»‹,
Hiá»‡n táº¡i em lÃ  sinh viÃªn nÄƒm 3 Ä‘áº¡i há»c BÃ¡ch khoa, kÃ¬ nÃ y nhÃ³m em Ä‘ang lÃ m Ä‘á»“ Ã¡n 1 nhiá»‡m vá»¥ lÃ  Viáº¿t website bÃ¡n hÃ ng báº±ng web framework django vÃ  káº¿t há»£p machine cho há»‡ thá»‘ng recommendation ( gá»£i Ã½ sáº£n pháº©m cho khÃ¡ch hÃ ng). Em Ä‘ang lÃ m xong cÃ¡c pháº§n cÆ¡ báº£n cho trang web, train vÃ  test dá»¯ liá»‡u trÃªn kaggle nhÆ°ng khi Ä‘Æ°a vÃ o trang web Ä‘ang gáº·p má»™t sá»‘ váº¥n Ä‘á»:
+dá»¯ liá»‡u quÃ¡ lá»›n khÃ´ng thá»ƒ tá»± thÃªm cÃ¡c sáº£n pháº©m, hÃ¬nh áº£nh vÃ o web
+ QuÃ¡ nhiá»u cÃ¡ch Ä‘á»ƒ thá»±c hiá»‡n giao tiáº¿p API nhÆ° Flask, REST, GraphQL, hiá»‡n táº¡i em khÃ´ng biáº¿t cÃ¡i nÃ o tá»‘t nháº¥t
+Em Ä‘Ã£ xem trÃªn youtube vá» GraphQL cho django nhÆ°ng chá»‰ giá»›i thiá»‡u qua vÃ  khi Ä‘Æ°a vÃ o trong django láº¡i khÃ´ng hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c.
=>> CÃ¡c anh chi cÃ³ thá»ƒ cho em lá»i khuyÃªn vÃ  hÆ°á»›ng dáº«n Ä‘Æ°á»£c khÃ´ng áº¡.
Em cáº£m Æ¡n nhiá»u áº¡.","Em chÃ o cÃ¡c anh chá»‹, Hiá»‡n táº¡i em lÃ  sinh viÃªn nÄƒm 3 Ä‘áº¡i há»c BÃ¡ch khoa, kÃ¬ nÃ y nhÃ³m em Ä‘ang lÃ m Ä‘á»“ Ã¡n 1 nhiá»‡m vá»¥ lÃ  Viáº¿t website bÃ¡n hÃ ng báº±ng web framework django vÃ  káº¿t há»£p machine cho há»‡ thá»‘ng recommendation ( gá»£i Ã½ sáº£n pháº©m cho khÃ¡ch hÃ ng). Em Ä‘ang lÃ m xong cÃ¡c pháº§n cÆ¡ báº£n cho trang web, train vÃ  test dá»¯ liá»‡u trÃªn kaggle nhÆ°ng khi Ä‘Æ°a vÃ o trang web Ä‘ang gáº·p má»™t sá»‘ váº¥n Ä‘á»: +dá»¯ liá»‡u quÃ¡ lá»›n khÃ´ng thá»ƒ tá»± thÃªm cÃ¡c sáº£n pháº©m, hÃ¬nh áº£nh vÃ o web + QuÃ¡ nhiá»u cÃ¡ch Ä‘á»ƒ thá»±c hiá»‡n giao tiáº¿p API nhÆ° Flask, REST, GraphQL, hiá»‡n táº¡i em khÃ´ng biáº¿t cÃ¡i nÃ o tá»‘t nháº¥t +Em Ä‘Ã£ xem trÃªn youtube vá» GraphQL cho django nhÆ°ng chá»‰ giá»›i thiá»‡u qua vÃ  khi Ä‘Æ°a vÃ o trong django láº¡i khÃ´ng hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c. =>> CÃ¡c anh chi cÃ³ thá»ƒ cho em lá»i khuyÃªn vÃ  hÆ°á»›ng dáº«n Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n nhiá»u áº¡.",,,,,
"chÃ o má»i ngÆ°á»i.
CÃ³ anh chá»‹ nÃ o Ä‘Ã£ tá»«ng dÃ¹ng api cá»§a google text to speech chÆ°a áº¡. Em Ä‘ang gáº·p váº¥n Ä‘á» khÃ´ng biáº¿t cÃ¡ch láº¥y phoneme (Ä‘á»ƒ lÃ m má»¥c Ä‘Ã­ch khÃ¡c ). Anh chá»‹ (cÃ¡c báº¡n) Ä‘Ã£ tá»«ng lÃ m rá»“i cÃ³ thá»ƒ cho em keyword hoáº·c hÆ°á»›ng dáº«n em cÃ¡ch lÃ m khÃ´ng áº¡. Em cáº£m Æ¡n .",chÃ o má»i ngÆ°á»i. CÃ³ anh chá»‹ nÃ o Ä‘Ã£ tá»«ng dÃ¹ng api cá»§a google text to speech chÆ°a áº¡. Em Ä‘ang gáº·p váº¥n Ä‘á» khÃ´ng biáº¿t cÃ¡ch láº¥y phoneme (Ä‘á»ƒ lÃ m má»¥c Ä‘Ã­ch khÃ¡c ). Anh chá»‹ (cÃ¡c báº¡n) Ä‘Ã£ tá»«ng lÃ m rá»“i cÃ³ thá»ƒ cho em keyword hoáº·c hÆ°á»›ng dáº«n em cÃ¡ch lÃ m khÃ´ng áº¡. Em cáº£m Æ¡n .,,,,,
"Em Ä‘ang há»c nÃªn máº¡nh dáº¡n chia sáº» cÃ¹ng anh em má»™t bÃ i toÃ¡n má»›i trong lÄ©nh vá»±c Computer Vision lÃ  Intrusion Detection - phÃ¡t hiá»‡n Ä‘á»™t nháº­p.
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em lÃ m Ä‘á»“ Ã¡n vÃ  má»›i há»c.
Cáº£m Æ¡n cÃ¡c bÃ¡c!",Em Ä‘ang há»c nÃªn máº¡nh dáº¡n chia sáº» cÃ¹ng anh em má»™t bÃ i toÃ¡n má»›i trong lÄ©nh vá»±c Computer Vision lÃ  Intrusion Detection - phÃ¡t hiá»‡n Ä‘á»™t nháº­p. Hi vá»ng giÃºp Ä‘Æ°á»£c anh em lÃ m Ä‘á»“ Ã¡n vÃ  má»›i há»c. Cáº£m Æ¡n cÃ¡c bÃ¡c!,,,,,
"Em chÃ o má»i ngÆ°á»i.
Em Ä‘ang lÃ m Ä‘á»“ Ã¡n Ä‘á» tÃ i ""NghiÃªn cá»©u thuáº­t toÃ¡n nháº­n diá»‡n Ä‘Ã¨n tÃ­n hiá»‡u giao thÃ´ng"". Em cÃ³ tham kháº£o vÃ  cÃ³ Ã½ Ä‘á»‹nh phÃ¡t triá»ƒn thuáº­t toÃ¡n theo link github nÃ y https://github.com/SandeepAswathnarayana/traffic-light-classifier_faster-r-cnn
Em Ä‘Ã£ tá»± thu tháº­p data riÃªng cá»§a em vá»›i hÆ¡n 300 áº£nh, em Ä‘á»‹nh gÃ¡n 3 nhÃ£n Ä‘Æ¡n giáº£n lÃ  ""Green"", ""Yellow"", ""Red"". NhÆ°ng em Ä‘ang khÃ´ng biáº¿t triá»ƒn khai bá»™ data má»›i cá»§a em thay tháº¿ bá»™ data cÅ© cá»§a ngÆ°á»i ta nhÆ° tháº¿ nÃ o áº¡.
Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n giÃºp Ä‘á»¡ vá»›i áº¡!","Em chÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m Ä‘á»“ Ã¡n Ä‘á» tÃ i ""NghiÃªn cá»©u thuáº­t toÃ¡n nháº­n diá»‡n Ä‘Ã¨n tÃ­n hiá»‡u giao thÃ´ng"". Em cÃ³ tham kháº£o vÃ  cÃ³ Ã½ Ä‘á»‹nh phÃ¡t triá»ƒn thuáº­t toÃ¡n theo link github nÃ y https://github.com/SandeepAswathnarayana/traffic-light-classifier_faster-r-cnn Em Ä‘Ã£ tá»± thu tháº­p data riÃªng cá»§a em vá»›i hÆ¡n 300 áº£nh, em Ä‘á»‹nh gÃ¡n 3 nhÃ£n Ä‘Æ¡n giáº£n lÃ  ""Green"", ""Yellow"", ""Red"". NhÆ°ng em Ä‘ang khÃ´ng biáº¿t triá»ƒn khai bá»™ data má»›i cá»§a em thay tháº¿ bá»™ data cÅ© cá»§a ngÆ°á»i ta nhÆ° tháº¿ nÃ o áº¡. Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n giÃºp Ä‘á»¡ vá»›i áº¡!",,,,,
"Dáº¡ chÃ o má»i ngÆ°á»i, em Ä‘ang táº­p lÃ m Chatbot, cÃ³ theo dÃµi Series cá»§a anh Tháº¯ng. Hiá»‡n táº¡i em Ä‘ang bá»‹ vÆ°á»›ng ngay bÆ°á»›c Ä‘áº§u lÃ  cÃ i Ä‘áº·t Rasa.
Python em dÃ¹ng version: 8.0
Pip version 22.1.2
Em cÃ i Ä‘áº·t Rasa theo 2 cÃ¡ch:
pip install rasa (Cháº¡y cÃ¡i nÃ y thÃ¬ nÃ³ báº£o lÃ  required tensorflow)
pip3 install rasa ( Ra log bÃªn hÃ¬nh dÆ°á»›i )
NhÆ°ng bá»‹ bÃ¡o lá»—i, em Ä‘Ã£ thá»­ upgrade python lÃªn báº£n 3.9 or 3.10 nhÆ°ng nÃ³ váº«n bá»‹. Nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡
Cáº£m Æ¡n má»i ngÆ°á»i
#Chatbot
#Rasa","Dáº¡ chÃ o má»i ngÆ°á»i, em Ä‘ang táº­p lÃ m Chatbot, cÃ³ theo dÃµi Series cá»§a anh Tháº¯ng. Hiá»‡n táº¡i em Ä‘ang bá»‹ vÆ°á»›ng ngay bÆ°á»›c Ä‘áº§u lÃ  cÃ i Ä‘áº·t Rasa. Python em dÃ¹ng version: 8.0 Pip version 22.1.2 Em cÃ i Ä‘áº·t Rasa theo 2 cÃ¡ch: pip install rasa (Cháº¡y cÃ¡i nÃ y thÃ¬ nÃ³ báº£o lÃ  required tensorflow) pip3 install rasa ( Ra log bÃªn hÃ¬nh dÆ°á»›i ) NhÆ°ng bá»‹ bÃ¡o lá»—i, em Ä‘Ã£ thá»­ upgrade python lÃªn báº£n 3.9 or 3.10 nhÆ°ng nÃ³ váº«n bá»‹. Nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡ Cáº£m Æ¡n má»i ngÆ°á»i",#Chatbot	#Rasa,,,,
"Em chÃ o mn áº¡. Em cÃ³ 1 topic vá» forecast time series ( cÃ³ thÃªm 1 sá»‘ biáº¿n giáº£ categorical ná»¯a) Em má»›i sá»­ dá»¥ng 1 sá»‘ techique kiá»ƒu MA, exponential, holt-winter. Em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ chá»— lÃ  chÆ°a biáº¿t há»‡ thá»‘ng hÃ³a cÃ¡c technique/model Ä‘á»ƒ phÃ¢n loáº¡i lÃ  vá»›i data nhÆ° nÃ o thÃ¬ nÃªn dÃ¹ng model gÃ¬ áº¡, mÃ  em Ä‘ang cáº§n khÃ¡ gáº¥p. Nhá» cÃ¡c anh chá»‹ guide giÃºp em chá»— nÃ y áº¡. Em cáº£m Æ¡n <3 <3 <3","Em chÃ o mn áº¡. Em cÃ³ 1 topic vá» forecast time series ( cÃ³ thÃªm 1 sá»‘ biáº¿n giáº£ categorical ná»¯a) Em má»›i sá»­ dá»¥ng 1 sá»‘ techique kiá»ƒu MA, exponential, holt-winter. Em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ chá»— lÃ  chÆ°a biáº¿t há»‡ thá»‘ng hÃ³a cÃ¡c technique/model Ä‘á»ƒ phÃ¢n loáº¡i lÃ  vá»›i data nhÆ° nÃ o thÃ¬ nÃªn dÃ¹ng model gÃ¬ áº¡, mÃ  em Ä‘ang cáº§n khÃ¡ gáº¥p. Nhá» cÃ¡c anh chá»‹ guide giÃºp em chá»— nÃ y áº¡. Em cáº£m Æ¡n <3 <3 <3",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» chá»§ Ä‘á» giáº£i mÃ£ Captcha kÃ­ tá»± sá»‘, thÃ´ng tin áº£nh dá»±a trÃªn mÃ´ hÃ¬nh mÃ¡y há»c.
Em cÅ©ng Ä‘Ã£ nghiÃªn cá»©u qua cÃ¡c mÃ´ hÃ¬nh Captcha hiá»‡n nay, tuy nhiÃªn dá»¯ liá»‡u chÆ°a phong phÃº, má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p hay mÃ´ hÃ¬nh Ä‘Ã£ xÃ¢y dá»±ng sáºµn thÃ¬ cho em há»c há»i thÃªm. Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» chá»§ Ä‘á» giáº£i mÃ£ Captcha kÃ­ tá»± sá»‘, thÃ´ng tin áº£nh dá»±a trÃªn mÃ´ hÃ¬nh mÃ¡y há»c. Em cÅ©ng Ä‘Ã£ nghiÃªn cá»©u qua cÃ¡c mÃ´ hÃ¬nh Captcha hiá»‡n nay, tuy nhiÃªn dá»¯ liá»‡u chÆ°a phong phÃº, má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p hay mÃ´ hÃ¬nh Ä‘Ã£ xÃ¢y dá»±ng sáºµn thÃ¬ cho em há»c há»i thÃªm. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"E Ä‘ang lÃ m bÃ i táº­p nlp, Ä‘á» bÃ i cho 1 cÃ¢u vÄƒn ( tiáº¿ng viá»‡t), fix cÃ¡c tá»« trong cÃ¢u (thay báº±ng 1 tá»« trong data vocab cÃ³ sáºµn) sao cho cÃ¢u thÃ nh 1 cÃ¢u vÄƒn Ä‘Ãºng ngá»¯ phÃ¡p, ai cÃ³ tÃ i liá»‡u cho e xin vá»›i áº¡","E Ä‘ang lÃ m bÃ i táº­p nlp, Ä‘á» bÃ i cho 1 cÃ¢u vÄƒn ( tiáº¿ng viá»‡t), fix cÃ¡c tá»« trong cÃ¢u (thay báº±ng 1 tá»« trong data vocab cÃ³ sáºµn) sao cho cÃ¢u thÃ nh 1 cÃ¢u vÄƒn Ä‘Ãºng ngá»¯ phÃ¡p, ai cÃ³ tÃ i liá»‡u cho e xin vá»›i áº¡",,,,,
playlist giá»›i thiá»‡u vá» má»™t sá»‘ cÃ¡ch xá»­ lÃ½ dá»¯ liá»‡u khuyáº¿t cÆ¡ báº£n trong python,playlist giá»›i thiá»‡u vá» má»™t sá»‘ cÃ¡ch xá»­ lÃ½ dá»¯ liá»‡u khuyáº¿t cÆ¡ báº£n trong python,,,,,
"Em chÃ o cÃ¡c anh chá»‹ áº¡. Em lÃ  ngÆ°á»i ngoáº¡i Ä‘áº¡o Ä‘ang táº­p tÃ nh há»c vá» ML nÃªn cÃ³ má»™t sá»‘ bÃ i táº­p vá» phÃ¢n loáº¡i 10 lá»›p vá»›i Softmax vÃ  phÃ¢n loáº¡i hai lá»›p vá»›i logistic regression muá»‘n xin Ä‘Æ°á»£c chá»‰ dáº¡y vÃ  giáº£i Ä‘Ã¡p tá»« cÃ¡c cao nhÃ¢n vá» ML áº¡.
Äáº·c biá»‡t pháº§n Class Softmax Classifier (BÃ i TODO 13-16)
Em xin Ä‘Ã­nh kÃ¨m link Google Collab vÃ  má»™t sá»‘ hÃ¬nh áº£nh Ä‘oáº¡n code cáº§n hoÃ n thÃ nh áº¡.
Em xin trÃ¢n trá»ng cáº£m Æ¡n táº¥t cáº£ má»i ngÆ°á»i áº¡.
https://colab.research.google.com/drive/1azkkce0FU4F3hN_evuj8vwWyfSkcBUhs?usp=sharing",Em chÃ o cÃ¡c anh chá»‹ áº¡. Em lÃ  ngÆ°á»i ngoáº¡i Ä‘áº¡o Ä‘ang táº­p tÃ nh há»c vá» ML nÃªn cÃ³ má»™t sá»‘ bÃ i táº­p vá» phÃ¢n loáº¡i 10 lá»›p vá»›i Softmax vÃ  phÃ¢n loáº¡i hai lá»›p vá»›i logistic regression muá»‘n xin Ä‘Æ°á»£c chá»‰ dáº¡y vÃ  giáº£i Ä‘Ã¡p tá»« cÃ¡c cao nhÃ¢n vá» ML áº¡. Äáº·c biá»‡t pháº§n Class Softmax Classifier (BÃ i TODO 13-16) Em xin Ä‘Ã­nh kÃ¨m link Google Collab vÃ  má»™t sá»‘ hÃ¬nh áº£nh Ä‘oáº¡n code cáº§n hoÃ n thÃ nh áº¡. Em xin trÃ¢n trá»ng cáº£m Æ¡n táº¥t cáº£ má»i ngÆ°á»i áº¡. https://colab.research.google.com/drive/1azkkce0FU4F3hN_evuj8vwWyfSkcBUhs?usp=sharing,,,,,
"ğŸ’¡ How to grow as an AI Engineer? ğŸ’¡
by Nguyá»…n VÄƒn TÃ¢m, AI Engineer @ Instill AI
https://www.facebook.com/instilltech/posts/565849418605636
#AIEngineer #AI #career

After 7 years of working as a software engineer (firmware/middleware, mobile and backend application), I switched to AI engineer role 4 years ago. Here are my takeaways from a +10-year software industry journey:
â¶ Polish your MLOps tooling skill
â·  Monitor production domain drift and iterate fast
â¸ Collaborate across different roles","How to grow as an AI Engineer? by Nguyá»…n VÄƒn TÃ¢m, AI Engineer @ Instill AI https://www.facebook.com/instilltech/posts/565849418605636 After 7 years of working as a software engineer (firmware/middleware, mobile and backend application), I switched to AI engineer role 4 years ago. Here are my takeaways from a +10-year software industry journey: Polish your MLOps tooling skill Monitor production domain drift and iterate fast Collaborate across different roles",#AIEngineer	#AI	#career,,,,
"[MÃ´ hÃ¬nh Minerva - Giáº£i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p]
Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cho ra cÃ¡c káº¿t quáº£ áº¥n tÆ°á»£ng trong nhiá»u bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nhÆ° BERT, GPT-3, Gopher vÃ  PaLM. Äiá»ƒn hÃ¬nh cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh sinh ra code, sinh ra thÆ¡,...
Trong bÃ i bÃ¡o â€œSolving Quantitative Reasoning Problems With Language Modelsâ€, nhÃ³m tÃ¡c giáº£ tá»« Google Ä‘á» xuáº¥t mÃ´ hÃ¬nh Minerva vá»›i kháº£ nÄƒng giáº£i cÃ¡c cÃ¢u há»i toÃ¡n há»c tá»«ng bÆ°á»›c má»™t.
Chi tiáº¿t má»i ngÆ°á»i xem á»Ÿ Ä‘Ã¢y: https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html","[MÃ´ hÃ¬nh Minerva - Giáº£i cÃ¡c bÃ i toÃ¡n phá»©c táº¡p] Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cho ra cÃ¡c káº¿t quáº£ áº¥n tÆ°á»£ng trong nhiá»u bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nhÆ° BERT, GPT-3, Gopher vÃ  PaLM. Äiá»ƒn hÃ¬nh cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh sinh ra code, sinh ra thÆ¡,... Trong bÃ i bÃ¡o â€œSolving Quantitative Reasoning Problems With Language Modelsâ€, nhÃ³m tÃ¡c giáº£ tá»« Google Ä‘á» xuáº¥t mÃ´ hÃ¬nh Minerva vá»›i kháº£ nÄƒng giáº£i cÃ¡c cÃ¢u há»i toÃ¡n há»c tá»«ng bÆ°á»›c má»™t. Chi tiáº¿t má»i ngÆ°á»i xem á»Ÿ Ä‘Ã¢y: https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html",,,,,
"ChÃ o má»i ngÆ°á»i,
ThÃ¡ng 7 nÃ y náº¿u anh chá»‹ nÃ o á»Ÿ HÃ  Ná»™i quan tÃ¢m vá» Web Development, ML/AI, Google Developer Expert,â€¦v.vâ€¦ cÃ¹ng nhiá»u chá»§ Ä‘á» khÃ¡c vÃ  gáº·p gá»¡ cÃ¡c speaker tá»« Google, em xin giá»›i thiá»‡u má»i ngÆ°á»i sá»± kiá»‡n nÃ y nÃ¨: https://www.facebook.com/events/1517940821993351
ğŸ‘‰ğŸ» Link Ä‘Äƒng kÃ½: https://forms.gle/EtsCHAuXSwkK8rVL9ÄÃ£ lÃ¢u rá»“i má»›i cÃ³ sá»± kiá»‡n cá»§a GDG offline sau dá»‹ch, hi vá»ng má»i ngÆ°á»i sáº½ thÃ­ch thÃº vÃ  tham gia vá»›i nhá»¯ng siÃªu quyá»n lá»£i:
ğŸ‘‰ğŸ» Trá»Ÿ thÃ nh nhá»¯ng ngÆ°á»i Ä‘áº§u tiÃªn tham dá»± sá»± kiá»‡n Offline trá»Ÿ láº¡i cá»§a GDGHanoi!
ğŸ‘‰ğŸ» Gáº·p gá»¡ nhá»¯ng chuyÃªn gia CÃ´ng nghá»‡ cÃ¹ng nhá»¯ng bÃ i chia sáº» chuyÃªn sÃ¢u!
ğŸ‘‰ğŸ» Tráº£i nghiá»‡m cÃ¡c gian hÃ ng vá»›i nhiá»u hoáº¡t Ä‘á»™ng lÃ½ thÃº!
ğŸ‘‰ğŸ» Gáº·p gá»¡ cá»™ng Ä‘á»“ng CÃ´ng nghá»‡ sau 2 nÄƒm xa cÃ¡ch!
ğŸ‘‰ğŸ» VÃ  hÃ ng trÄƒm pháº§n quÃ¡ háº¥p dáº«n, quyá»n lá»£i khÃ¡c táº¡i ngÃ y diá»…n ra sá»± kiá»‡n!
ğŸ“Œ ÄÄƒng kÃ½ ngay táº¡i: https://forms.gle/EtsCHAuXSwkK8rVL9","ChÃ o má»i ngÆ°á»i, ThÃ¡ng 7 nÃ y náº¿u anh chá»‹ nÃ o á»Ÿ HÃ  Ná»™i quan tÃ¢m vá» Web Development, ML/AI, Google Developer Expert,â€¦v.vâ€¦ cÃ¹ng nhiá»u chá»§ Ä‘á» khÃ¡c vÃ  gáº·p gá»¡ cÃ¡c speaker tá»« Google, em xin giá»›i thiá»‡u má»i ngÆ°á»i sá»± kiá»‡n nÃ y nÃ¨: https://www.facebook.com/events/1517940821993351 Link Ä‘Äƒng kÃ½: https://forms.gle/EtsCHAuXSwkK8rVL9ÄÃ£ lÃ¢u rá»“i má»›i cÃ³ sá»± kiá»‡n cá»§a GDG offline sau dá»‹ch, hi vá»ng má»i ngÆ°á»i sáº½ thÃ­ch thÃº vÃ  tham gia vá»›i nhá»¯ng siÃªu quyá»n lá»£i: Trá»Ÿ thÃ nh nhá»¯ng ngÆ°á»i Ä‘áº§u tiÃªn tham dá»± sá»± kiá»‡n Offline trá»Ÿ láº¡i cá»§a GDGHanoi! Gáº·p gá»¡ nhá»¯ng chuyÃªn gia CÃ´ng nghá»‡ cÃ¹ng nhá»¯ng bÃ i chia sáº» chuyÃªn sÃ¢u! Tráº£i nghiá»‡m cÃ¡c gian hÃ ng vá»›i nhiá»u hoáº¡t Ä‘á»™ng lÃ½ thÃº! Gáº·p gá»¡ cá»™ng Ä‘á»“ng CÃ´ng nghá»‡ sau 2 nÄƒm xa cÃ¡ch! VÃ  hÃ ng trÄƒm pháº§n quÃ¡ háº¥p dáº«n, quyá»n lá»£i khÃ¡c táº¡i ngÃ y diá»…n ra sá»± kiá»‡n! ÄÄƒng kÃ½ ngay táº¡i: https://forms.gle/EtsCHAuXSwkK8rVL9",,,,,
"Hi a/c/e!
MÃ¬nh cÃ³ váº¥n Ä‘á» nÃ y mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡. Team mÃ¬nh Ä‘ang Ä‘Æ°a cÃ¡c mÃ´ hÃ¬nh DL xuá»‘ng mobile dÃ¹ng tflife cá»§a google. Hiá»‡n team Ä‘Ã£ convert Ä‘Æ°á»£c mÃ´ hÃ¬nh. Tuy nhiÃªn, Ä‘á»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c mÃ´ hÃ¬nh thÃ¬ cáº§n viáº¿t thÃªm code postprocess. TrÃªn python thÃ¬ code nÃ y khÃ¡ dá»… chá»‰ cáº§n dÃ¹ng cÃ¡c thÆ° viá»‡n numpy, opencv code má»™t chÃºt lÃ  Ä‘Æ°á»£c - ko khÃ³ Ä‘á»‘i vá»›i AI Engineer. Tuy nhiÃªn, viá»‡c code postprocess Ä‘á»‘i vá»›i a/e coder Java (Android), Swift (iOS) thÃ¬ khÃ¡ lÃ  cá»±c do ko cÃ³ chuyÃªn vá» thuáº­t toÃ¡n, vá» xá»­ lÃ½ áº£nh, vá» AI/DL. KhÃ´ng biáº¿t cÃ³ giáº£i phÃ¡p nÃ o Ä‘á»ƒ Ä‘Ã³ng gÃ³i thÃ nh lib Ä‘á»ƒ bÃªn app chá»‰ cáº§n truyá»n input (áº£nh) vÃ  nháº­n Ä‘áº§u ra lÃ  cÃ¡c class luÃ´n ko?
Nhá» a/c/e tÆ° váº¥n giÃºp. Many thanks ~
----
á» trÃªn mÃ¬nh mÃ´ táº£ bÃ i toÃ¡n chung. BÃ i toÃ¡n cá»¥ thá»ƒ cá»§a mÃ¬nh lÃ  viáº¿t má»™t chÆ°Æ¡ng trÃ¬nh AI cháº¡y trÃªn mobile nháº­n Ä‘áº§u vÃ o lÃ  áº£nh chá»¥p khuÃ´n máº·t, Ä‘áº§u ra lÃ  káº¿t quáº£ phÃ¢n loáº¡i máº·t Ä‘ang quay trÃ¡i, quay pháº£i, chÃ­nh diá»‡n, ngÆ°á»›c lÃªn trÃªn hay cÃºi xuá»‘ng. MÃ¬nh dÃ¹ng mÃ´ hÃ¬nh AI Ä‘á»ƒ xÃ¡c Ä‘á»‹nh 68 Ä‘iá»ƒm landmark trÃªn khuÃ´n máº·t. Tá»« 68 Ä‘iá»ƒm landmark sáº½ dÃ¹ng cÃ¡c phÃ©p toÃ¡n há»c Ä‘á»ƒ tÃ­nh ra yaw, pitch vÃ  roll. Dá»±a vÃ o yaw, pitch, roll Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÆ°á»›ng khuÃ´n máº·t.
MÃ¬nh Ä‘Ã£ dÃ¹ng tflife Ä‘á»ƒ convert mÃ´ hÃ¬nh xÃ¡c Ä‘á»‹nh lamdmark sang Ä‘á»‹nh Ä‘áº¡ng trÃªn mobile. Tuy nhiÃªn, a/e dev mobile thÃ¬ Ä‘ang kÃªu khÃ³ khi viáº¿t code thuáº­t toÃ¡n háº­u xá»­ lÃ½ tiáº¿p theo.
MÃ¬nh cÅ©ng ko cÃ³ rÃµ vá» mobile nÃªn nhá» cÃ¡c a/c/e tÆ° váº¥n giÃºp.","Hi a/c/e! MÃ¬nh cÃ³ váº¥n Ä‘á» nÃ y mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡. Team mÃ¬nh Ä‘ang Ä‘Æ°a cÃ¡c mÃ´ hÃ¬nh DL xuá»‘ng mobile dÃ¹ng tflife cá»§a google. Hiá»‡n team Ä‘Ã£ convert Ä‘Æ°á»£c mÃ´ hÃ¬nh. Tuy nhiÃªn, Ä‘á»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c mÃ´ hÃ¬nh thÃ¬ cáº§n viáº¿t thÃªm code postprocess. TrÃªn python thÃ¬ code nÃ y khÃ¡ dá»… chá»‰ cáº§n dÃ¹ng cÃ¡c thÆ° viá»‡n numpy, opencv code má»™t chÃºt lÃ  Ä‘Æ°á»£c - ko khÃ³ Ä‘á»‘i vá»›i AI Engineer. Tuy nhiÃªn, viá»‡c code postprocess Ä‘á»‘i vá»›i a/e coder Java (Android), Swift (iOS) thÃ¬ khÃ¡ lÃ  cá»±c do ko cÃ³ chuyÃªn vá» thuáº­t toÃ¡n, vá» xá»­ lÃ½ áº£nh, vá» AI/DL. KhÃ´ng biáº¿t cÃ³ giáº£i phÃ¡p nÃ o Ä‘á»ƒ Ä‘Ã³ng gÃ³i thÃ nh lib Ä‘á»ƒ bÃªn app chá»‰ cáº§n truyá»n input (áº£nh) vÃ  nháº­n Ä‘áº§u ra lÃ  cÃ¡c class luÃ´n ko? Nhá» a/c/e tÆ° váº¥n giÃºp. Many thanks ~ ---- á» trÃªn mÃ¬nh mÃ´ táº£ bÃ i toÃ¡n chung. BÃ i toÃ¡n cá»¥ thá»ƒ cá»§a mÃ¬nh lÃ  viáº¿t má»™t chÆ°Æ¡ng trÃ¬nh AI cháº¡y trÃªn mobile nháº­n Ä‘áº§u vÃ o lÃ  áº£nh chá»¥p khuÃ´n máº·t, Ä‘áº§u ra lÃ  káº¿t quáº£ phÃ¢n loáº¡i máº·t Ä‘ang quay trÃ¡i, quay pháº£i, chÃ­nh diá»‡n, ngÆ°á»›c lÃªn trÃªn hay cÃºi xuá»‘ng. MÃ¬nh dÃ¹ng mÃ´ hÃ¬nh AI Ä‘á»ƒ xÃ¡c Ä‘á»‹nh 68 Ä‘iá»ƒm landmark trÃªn khuÃ´n máº·t. Tá»« 68 Ä‘iá»ƒm landmark sáº½ dÃ¹ng cÃ¡c phÃ©p toÃ¡n há»c Ä‘á»ƒ tÃ­nh ra yaw, pitch vÃ  roll. Dá»±a vÃ o yaw, pitch, roll Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÆ°á»›ng khuÃ´n máº·t. MÃ¬nh Ä‘Ã£ dÃ¹ng tflife Ä‘á»ƒ convert mÃ´ hÃ¬nh xÃ¡c Ä‘á»‹nh lamdmark sang Ä‘á»‹nh Ä‘áº¡ng trÃªn mobile. Tuy nhiÃªn, a/e dev mobile thÃ¬ Ä‘ang kÃªu khÃ³ khi viáº¿t code thuáº­t toÃ¡n háº­u xá»­ lÃ½ tiáº¿p theo. MÃ¬nh cÅ©ng ko cÃ³ rÃµ vá» mobile nÃªn nhá» cÃ¡c a/c/e tÆ° váº¥n giÃºp.",,,,,
"Em xin chÃ o anh chá»‹ trong nhÃ³m. Em cÃ³ 1 xÃ­u tháº¯c máº¯c mong anh chá»‹ giÃºp Ä‘á»¡ áº¡.
Trong dataset cá»§a em cÃ³ 2 phÆ°Æ¡ng thá»©c lÃ  GET vÃ  POST, thÃ¬ chá»‰ cÃ³ POST má»›i dÃ¹ng dá»¯ liá»‡u cá»™t length, content cÃ²n GET thÃ¬ khÃ´ng cÃ³.
Váº­y em nÃªn xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ NaN hay lÃ  chia ra 1 cÃ¡i lÃ m cho POST 1 cÃ¡i lÃ m cho GET áº¡, hay lÃ m 1 cÃ¡ch khÃ¡c a ? Em cáº£m Æ¡n anh chá»‹ Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c bÃ i viáº¿t","Em xin chÃ o anh chá»‹ trong nhÃ³m. Em cÃ³ 1 xÃ­u tháº¯c máº¯c mong anh chá»‹ giÃºp Ä‘á»¡ áº¡. Trong dataset cá»§a em cÃ³ 2 phÆ°Æ¡ng thá»©c lÃ  GET vÃ  POST, thÃ¬ chá»‰ cÃ³ POST má»›i dÃ¹ng dá»¯ liá»‡u cá»™t length, content cÃ²n GET thÃ¬ khÃ´ng cÃ³. Váº­y em nÃªn xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ NaN hay lÃ  chia ra 1 cÃ¡i lÃ m cho POST 1 cÃ¡i lÃ m cho GET áº¡, hay lÃ m 1 cÃ¡ch khÃ¡c a ? Em cáº£m Æ¡n anh chá»‹ Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c bÃ i viáº¿t",,,,,
"ThÃ¡ng 9 nÃ y, mÃ¬nh sáº½ dáº¡y mÃ´n ""Statistical Optimization in Machine Learning and Data Science"" táº¡i University of Texas, Austin. Lá»›p nÃ y lÃ  Advanced Level dÃ nh cho cÃ¡c báº¡n muá»‘n lÃ m nghiÃªn cá»©u vá» ML, DS, vÃ  Deep Learning (DL).
CÃ¡c bÃ i giáº£ng cá»§a lá»›p nÃ y mÃ¬nh sáº½ Ä‘Äƒng trÃªn trang web cÃ¡ nhÃ¢n cá»§a mÃ¬nh táº¡i Ä‘Ã¢y: https://nhatptnk8912.github.io/index.html
+++++ Vá» syllabus cá»§a lá»›p thÃ¬ gá»“m hai chá»§ Ä‘á» lá»›n sau:
***** Foundation of Optimization Methods:
--- Gradient Descent for Constrained and Unconstrained problems
--- Adaptive Gradient Descent (Adagrad, RMSProp, etc.)
--- Accelerated Gradient Descent Methods
--- Stochastic Gradient Descent and Its Variants
--- Newtonâ€™s Method and Quasi-Newtonâ€™s Method
***** Applications of Optimization Methods for Machine Learning Models:
--- Computational Optimal Transport: Old and New
--- (Stochastic) Variational Inference, such as Mean-Field approximation, etc.
--- Optimization Landscape of Deep Neural Networks
--- Unsupervised Methods (e.g., K-means, Gaussian Mixture Models, Factor Analysis, PCA, etc.)
--- Minimax Optimization in Deep Generative Models
--- Federated Learning
++++++ CÃ¡c báº¡n nÃ o quan tÃ¢m thÃ¬ theo dÃµi nhÃ©.","ThÃ¡ng 9 nÃ y, mÃ¬nh sáº½ dáº¡y mÃ´n ""Statistical Optimization in Machine Learning and Data Science"" táº¡i University of Texas, Austin. Lá»›p nÃ y lÃ  Advanced Level dÃ nh cho cÃ¡c báº¡n muá»‘n lÃ m nghiÃªn cá»©u vá» ML, DS, vÃ  Deep Learning (DL). CÃ¡c bÃ i giáº£ng cá»§a lá»›p nÃ y mÃ¬nh sáº½ Ä‘Äƒng trÃªn trang web cÃ¡ nhÃ¢n cá»§a mÃ¬nh táº¡i Ä‘Ã¢y: https://nhatptnk8912.github.io/index.html +++++ Vá» syllabus cá»§a lá»›p thÃ¬ gá»“m hai chá»§ Ä‘á» lá»›n sau: ***** Foundation of Optimization Methods: --- Gradient Descent for Constrained and Unconstrained problems --- Adaptive Gradient Descent (Adagrad, RMSProp, etc.) --- Accelerated Gradient Descent Methods --- Stochastic Gradient Descent and Its Variants --- Newtonâ€™s Method and Quasi-Newtonâ€™s Method ***** Applications of Optimization Methods for Machine Learning Models: --- Computational Optimal Transport: Old and New --- (Stochastic) Variational Inference, such as Mean-Field approximation, etc. --- Optimization Landscape of Deep Neural Networks --- Unsupervised Methods (e.g., K-means, Gaussian Mixture Models, Factor Analysis, PCA, etc.) --- Minimax Optimization in Deep Generative Models --- Federated Learning ++++++ CÃ¡c báº¡n nÃ o quan tÃ¢m thÃ¬ theo dÃµi nhÃ©.",,,,,
"ÄÄƒng láº¡i bÃ i tá»« group Viet Tech vÃ¬ group Ä‘Ã³ kÃ­n.

HÃ´m trÆ°á»›c trong buá»•i nÃ³i chuyá»‡n vá»›i Viet Tech mÃ¬nh cÃ³ Ä‘á» cáº­p tá»›i viá»‡c cÃ³ thá»ƒ start training model vÃ  Ä‘Æ°a vÃ o online serving trong vÃ²ng 1 ngÃ y khi lÃ m viá»‡c á»Ÿ Google. MÃ¬nh xin tÃ³m táº¯t láº¡i nhá»¯ng hiá»ƒu biáº¿t cá»§a minh dá»±a trÃªn cÃ´ng viá»‡c hÃ ng ngÃ y mÃ¬nh lÃ m. Xin lá»—i   mÃ¬nh viáº¿t nhanh nÃªn cÃ²n nhiá»u cá»¥m cÃ²n Ä‘á»ƒ tiáº¿ng Anh.
LÆ°u Ã½: Google cÃ³ ráº¥t nhiá»u team vá»›i nhiá»u bÃ i toÃ¡n vÃ  infrastructure khÃ¡c nhau. Nhá»¯ng chia sáº» trong bÃ i nÃ y dá»±a trÃªn cÃ´ng viá»‡c hÃ ng ngÃ y cá»§a mÃ¬nh. CÃ¡c Googlers á»Ÿ team khÃ¡c cÃ³ thá»ƒ sáº½ tháº¥y nhá»¯ng sá»± khÃ¡c biá»‡t.
DATA
CÃ³ hai loáº¡i dá»¯ liá»‡u chÃ­nh lÃ  thÃ´ vÃ  tinh. Dá»¯ liá»‡u thÃ´ Ä‘Æ°á»£c lÆ°u gáº§n nhÆ° theo thá»i gian thá»±c vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u lÃºc serving. Dá»¯ liá»‡u thÃ´ nÃ y Ä‘Æ°á»£c xá»­ lÃ½ vÃ  táº¡o thÃ nh cÃ¡c feature mÃ  mÃ´ hÃ¬nh ML cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c â€“ táº¡m gá»i lÃ  dá»¯ liá»‡u tinh, cÃ³ Ä‘á»™ trá»… khoáº£ng vÃ i giá» so vá»›i thá»i gian thá»±c. CÃ¡c bá»™ dá»¯ liá»‡u nÃ y cÃ³ TTL vÃ  liÃªn tá»¥c Ä‘Æ°á»£c cáº­p nháº­t theo stream cá»§a dá»¯ liá»‡u serving.
Dá»¯ liá»‡u tinh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c model. ThÆ°á»ng thÃ¬ vÃ¬ dá»¯ liá»‡u lá»›n nÃªn model chá»‰ cáº§n train má»—i Ä‘iá»ƒm dá»¯ liá»‡u má»™t láº§n theo trÃ¬nh tá»± thá»i gian tá»« cÅ© Ä‘áº¿n má»›i. Má»—i model khi training cÃ³ training delay nháº¥t Ä‘á»‹nh, tuá»³ thuá»™c vÃ o Ä‘á»™ trá»… cá»§a dá»¯ liá»‡u tinh vÃ  label cá»§a bÃ i toÃ¡n. CÃ³ nhá»¯ng bÃ i toÃ¡n mÃ  label tá»›i muá»™n sau cáº£ tuáº§n, e.g. khÃ¡ch hÃ ng mua má»™t sáº£n pháº©m sau khi nhÃ¬n tháº¥y máº©u quáº£ng cÃ¡o má»™t tuáº§n trÆ°á»›c, thÃ¬ training delay cÃ³ thá»ƒ lÃ  má»™t tuáº§n. Má»™t khi model Ä‘Ã£ train tá»›i dá»¯ liá»‡u á»Ÿ thá»i Ä‘iá»ƒm training delay thÃ¬ ta gá»i lÃ  model Ä‘Ã£ caught up. Khi Ä‘Ã£ caught up, model dá»«ng á»Ÿ Ä‘Ã³ vÃ  chá» khi nÃ o cÃ³ dá»¯ liá»‡u má»›i thÃ¬ tá»± Ä‘á»™ng train tiáº¿p.
Ngay cáº£ khi model Ä‘Ã£ Ä‘Æ°a vÃ o trong serving, viá»‡c training váº«n tiáº¿p tá»¥c diá»…n ra nhÆ° váº­y. Model checkpoint Ä‘Æ°á»£c inject liÃªn tá»¥c sau vÃ i tiáº¿ng. Äiá»u nÃ y nghÄ©a lÃ  model Ä‘Æ°á»£c thay Ä‘á»•i liÃªn tá»¥c ngay cáº£ khi Ä‘Ã£ deploy, chá»‰ cÃ³ model architecture lÃ  Ä‘Æ°á»£c giá»¯ nguyÃªn.
HARDWARE AND RESOURCES
TrÆ°á»›c khi caught up, model sá»­ dá»¥ng ráº¥t nhiá»u computing resources (Ä‘ang chuyá»ƒn dáº§n sang hoÃ n toÃ n dÃ¹ng TPU) Ä‘á»ƒ cÃ³ thá»ƒ train háº¿t lÆ°á»£ng dá»¯ liá»‡u tá»« xa trong quÃ¡ khá»© cho tá»›i khi caught up. Má»™t khi Ä‘Ã£ caught up, model tá»± Ä‘á»™ng chuyá»ƒn sang cháº¿ Ä‘á»™ sá»­ dá»¥ng Ã­t tÃ i nguyÃªn hÆ¡n vÃ  nhÆ°á»ng tÃ i nguyÃªn cho cÃ¡c model khÃ¡c.
ÄÃ´i khi vÃ¬ lÃ½ do nÃ o Ä‘Ã³ mÃ  model bá»‹ dá»«ng huáº¥n luyá»‡n vÃ  â€œstale"". Stale ráº¥t nguy hiá»ƒm vÃ¬ cÃ³ dá»¯ liá»‡u trending cÃ³ thá»ƒ thay Ä‘á»•i hÃ ng ngÃ y nÃªn team mÃ¬nh ráº¥t chÃº trá»ng vÃ o viá»‡c monitor xem model cÃ³ bá»‹ stale hay khÃ´ng. Vá»›i cÃ¡c mÃ´ hÃ¬nh trong production, khi bá»‹ stale, nÃ³ sáº½ tá»± Ä‘á»™ng láº¥y computing resources tá»« cÃ¡c experimental/offline model khÃ¡c Ä‘á»ƒ Ä‘uá»•i ká»‹p tá»›i training delay.
NhÃ¬n chung, hardware cho training vÃ  serving lÃ  khÃ¡c nhau vÃ¬ hai tasks nÃ y cÃ³ nhiá»u Ä‘iá»ƒm khÃ´ng tÆ°Æ¡ng Ä‘á»“ng. Viá»‡c sá»­ dá»¥ng hardware khÃ¡c nhau nÃ y Ä‘Ã´i khi dáº«n Ä‘áº¿n nhá»¯ng káº¿t quáº£ khÃ¡c nhau giá»¯a training vÃ  serving, chá»§ yáº¿u do quantization. VÃ¬ váº­y, cÃ³ má»™t bÆ°á»›c quan trá»ng trÆ°á»›c khi inject model checkpoint lÃ  validation. Táº¡i bÆ°á»›c validation, hardware tÆ°Æ¡ng tá»± nhÆ° trong serving Ä‘Æ°á»£c sá»­ dá»¥ng. Ráº¥t nhiá»u metrics cÃ³ thá»ƒ Ä‘Æ°á»£c kiá»ƒm duyá»‡t á»Ÿ bÆ°á»›c nÃ y trÆ°á»›c khi checkpoints má»›i Ä‘Æ°á»£c injected. Dá»¯ liá»‡u táº¡i bÆ°á»›c validation nÃ y thÆ°á»ng lÃ  dá»¯ liá»‡u má»›i nháº¥t trong dá»¯ liá»‡u tinh mÃ  model chÆ°a nhÃ¬n tháº¥y.
OFFLINE EVALUATION
BÆ°á»›c validation mÃ¬nh nÃ³i á»Ÿ trÃªn Ä‘Æ°á»£c thá»±c hiá»‡n tá»± Ä‘á»™ng. Táº¥t nhiÃªn, khÃ´ng pháº£i checkpoint nÃ o Ä‘Ã£ pass validation Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°a lÃªn serving Ä‘Æ°á»£c.
TrÆ°á»›c khi cÃ³ thá»ƒ lÃªn serving, cÃ¡c team thÆ°á»ng pháº£i kiá»ƒm tra ká»¹ cÃ¡c metrics liÃªn quan vÃ  so sÃ¡nh cÃ¡c metrics Ä‘Ã³ vá»›i baseline. CÃ¡i nÃ y cÃ³ tool riÃªng ráº¥t powerful giÃºp ML engineers cÃ³ thá»ƒ so sÃ¡nh trá»±c tiáº¿p nhiá»u model cÃ¹ng nhau trÃªn nhiá»u traffic slices khÃ¡c nhau. Viá»‡c nÃ y ráº¥t quan trá»ng trÆ°á»›c khi setup online experiment má»›i.
ONLINE EXPERIMENT
Má»™t mÃ´ hÃ¬nh cÃ³ offline metrics tá»‘t chÆ°a cháº¯c Ä‘Ã£ mang láº¡i hiá»‡u quáº£ trong online experiment vÃ¬ cÃ³ nhiá»u quan há»‡ phá»©c táº¡p khi dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh áº£nh hÆ°á»Ÿng tá»›i káº¿t quáº£ serving. CÃ¡c online metrics cÅ©ng khÃ¡c so vá»›i offline metrics khi cÃ¡c con sá»‘ thá»±c sá»± vá» revenue Ä‘Æ°á»£c quan tÃ¢m. VÃ¬ váº­y, cÃ¡c online experiment Ä‘Æ°á»£c thá»±c hiá»‡n tá»« lÆ°á»£ng traffic tá»« nhá» Ä‘áº¿n lá»›n vÃ  cÃ³ thá»ƒ bá»‹ dá»«ng ngay náº¿u káº¿t quáº£ báº¥t thÆ°á»ng.
Viá»‡c Ä‘Æ°a má»™t mÃ´ hÃ¬nh tá»« offline sang online chá»‰ máº¥t khoáº£ng vÃ i tiáº¿ng, chá»§ yáº¿u lÃ  thá»i gian chá» viá»‡c phÃ¢n bá»• tÃ i nguyÃªn vÃ  cháº¡y unit tests. Viá»‡c nÃ y team mÃ¬nh khÃ´ng pháº£i lÃ m gÃ¬ nhiá»u mÃ  cÃ³ cÃ¡c team khÃ¡c chuyÃªn lo cÃ¡c váº¥n Ä‘á» nÃ y.
MONITORING SYSTEM
Há»‡ thá»‘ng monitoring cÃ³ má»™t nhiá»‡m vá»¥ ráº¥t quan trá»ng Ä‘á»‘i vá»›i online experiment. Vá»›i má»—i model, cÃ¡c team cáº§n thiáº¿t láº­p cÃ¡c há»‡ thá»‘ng theo dÃµi vÃ  bÃ¡o Ä‘á»™ng cho nhiá»u metrics khÃ¡c nhau. Label, prediction, model staleness, skewed features lÃ  bá»‘n trong sá»‘ nhá»¯ng thá»© quan trá»ng nháº¥t cáº§n Ä‘Æ°á»£c monitor. Khi cÃ³ dáº¥u hiá»‡u thay Ä‘á»•i trong nhá»¯ng giÃ¡ trá»‹ nÃ y thÃ¬ oncall/SRE sáº½ bá»‹ bÃ¡o Ä‘á»™ng vÃ  pháº£i tÃ¬m hiá»ƒu nguyÃªn nhÃ¢n cÅ©ng nhÆ° kháº¯c phá»¥c trong thá»i gian ngáº¯n nháº¥t cÃ³ thá»ƒ.
Cuá»‘i cÃ¹ng, há»‡ thá»‘ng ML cá»§a Gg khÃ¡ mature, má»—i má»™t thÃ nh pháº§n nhá» Ä‘á»u cÃ³ má»™t Ä‘á»™i ngÅ© Ä‘Ã´ng Ä‘áº£o cÃ¡c engineers quáº£n lÃ½, theo dÃµi vÃ  nÃ¢ng cáº¥p. Quy trÃ¬nh xá»­ lÃ½ sá»± cá»‘ cÅ©ng Ä‘Æ°á»£c ghi chÃ©p láº¡i ká»¹ cÃ ng Ä‘á»ƒ háº¡n cháº¿ nhá»¯ng tai náº¡n trong serving. ChÃ­nh vÃ¬ viá»‡c cÃ³ nhá»¯ng há»‡ thá»‘ng cáº£nh bÃ¡o nhiá»u lá»›p nÃ y mÃ  ráº¥t nhiá»u cÃ¡c experiment cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n má»™t cÃ¡ch nhanh chÃ³ng vÃ  Ã­t gÃ¢y rá»§i ro.
TÃ³m láº¡i, nhá»¯ng lÃ½ do chÃ­nh khiáº¿n viá»‡c thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m á»Ÿ Gg cÃ³ thá»ƒ diá»…n ra nhanh chÃ³ng:
Data pipeline giá»¯a training vÃ  serving Ä‘Æ°á»£c theo dÃµi vÃ  Ä‘áº£m báº£o Ã­t cÃ³ skew.
Computing resources lá»›n (TPU) vÃ  Ä‘Æ°á»£c quáº£n lÃ½ má»™t cÃ¡ch hiá»‡u quáº£.
CÃ³ nhá»¯ng cÃ´ng cá»¥ giÃºp viá»‡c Ä‘Ã¡nh giÃ¡ káº¿t quáº£ offline má»™t cÃ¡ch nhanh chÃ³ng.
Há»‡ thá»‘ng há»— trá»£ online experiment hiá»‡u quáº£.
Há»‡ thá»‘ng monitor cÃ¡c thÃ­ nghiá»‡m cÅ©ng Ä‘Æ°á»£c thiáº¿t láº­p giÃºp cÃ¡c engineers xá»­ lÃ½ ká»‹p thá»i khi cÃ³ incidents.","ÄÄƒng láº¡i bÃ i tá»« group Viet Tech vÃ¬ group Ä‘Ã³ kÃ­n. HÃ´m trÆ°á»›c trong buá»•i nÃ³i chuyá»‡n vá»›i Viet Tech mÃ¬nh cÃ³ Ä‘á» cáº­p tá»›i viá»‡c cÃ³ thá»ƒ start training model vÃ  Ä‘Æ°a vÃ o online serving trong vÃ²ng 1 ngÃ y khi lÃ m viá»‡c á»Ÿ Google. MÃ¬nh xin tÃ³m táº¯t láº¡i nhá»¯ng hiá»ƒu biáº¿t cá»§a minh dá»±a trÃªn cÃ´ng viá»‡c hÃ ng ngÃ y mÃ¬nh lÃ m. Xin lá»—i mÃ¬nh viáº¿t nhanh nÃªn cÃ²n nhiá»u cá»¥m cÃ²n Ä‘á»ƒ tiáº¿ng Anh. LÆ°u Ã½: Google cÃ³ ráº¥t nhiá»u team vá»›i nhiá»u bÃ i toÃ¡n vÃ  infrastructure khÃ¡c nhau. Nhá»¯ng chia sáº» trong bÃ i nÃ y dá»±a trÃªn cÃ´ng viá»‡c hÃ ng ngÃ y cá»§a mÃ¬nh. CÃ¡c Googlers á»Ÿ team khÃ¡c cÃ³ thá»ƒ sáº½ tháº¥y nhá»¯ng sá»± khÃ¡c biá»‡t. DATA CÃ³ hai loáº¡i dá»¯ liá»‡u chÃ­nh lÃ  thÃ´ vÃ  tinh. Dá»¯ liá»‡u thÃ´ Ä‘Æ°á»£c lÆ°u gáº§n nhÆ° theo thá»i gian thá»±c vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u lÃºc serving. Dá»¯ liá»‡u thÃ´ nÃ y Ä‘Æ°á»£c xá»­ lÃ½ vÃ  táº¡o thÃ nh cÃ¡c feature mÃ  mÃ´ hÃ¬nh ML cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c â€“ táº¡m gá»i lÃ  dá»¯ liá»‡u tinh, cÃ³ Ä‘á»™ trá»… khoáº£ng vÃ i giá» so vá»›i thá»i gian thá»±c. CÃ¡c bá»™ dá»¯ liá»‡u nÃ y cÃ³ TTL vÃ  liÃªn tá»¥c Ä‘Æ°á»£c cáº­p nháº­t theo stream cá»§a dá»¯ liá»‡u serving. Dá»¯ liá»‡u tinh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c model. ThÆ°á»ng thÃ¬ vÃ¬ dá»¯ liá»‡u lá»›n nÃªn model chá»‰ cáº§n train má»—i Ä‘iá»ƒm dá»¯ liá»‡u má»™t láº§n theo trÃ¬nh tá»± thá»i gian tá»« cÅ© Ä‘áº¿n má»›i. Má»—i model khi training cÃ³ training delay nháº¥t Ä‘á»‹nh, tuá»³ thuá»™c vÃ o Ä‘á»™ trá»… cá»§a dá»¯ liá»‡u tinh vÃ  label cá»§a bÃ i toÃ¡n. CÃ³ nhá»¯ng bÃ i toÃ¡n mÃ  label tá»›i muá»™n sau cáº£ tuáº§n, e.g. khÃ¡ch hÃ ng mua má»™t sáº£n pháº©m sau khi nhÃ¬n tháº¥y máº©u quáº£ng cÃ¡o má»™t tuáº§n trÆ°á»›c, thÃ¬ training delay cÃ³ thá»ƒ lÃ  má»™t tuáº§n. Má»™t khi model Ä‘Ã£ train tá»›i dá»¯ liá»‡u á»Ÿ thá»i Ä‘iá»ƒm training delay thÃ¬ ta gá»i lÃ  model Ä‘Ã£ caught up. Khi Ä‘Ã£ caught up, model dá»«ng á»Ÿ Ä‘Ã³ vÃ  chá» khi nÃ o cÃ³ dá»¯ liá»‡u má»›i thÃ¬ tá»± Ä‘á»™ng train tiáº¿p. Ngay cáº£ khi model Ä‘Ã£ Ä‘Æ°a vÃ o trong serving, viá»‡c training váº«n tiáº¿p tá»¥c diá»…n ra nhÆ° váº­y. Model checkpoint Ä‘Æ°á»£c inject liÃªn tá»¥c sau vÃ i tiáº¿ng. Äiá»u nÃ y nghÄ©a lÃ  model Ä‘Æ°á»£c thay Ä‘á»•i liÃªn tá»¥c ngay cáº£ khi Ä‘Ã£ deploy, chá»‰ cÃ³ model architecture lÃ  Ä‘Æ°á»£c giá»¯ nguyÃªn. HARDWARE AND RESOURCES TrÆ°á»›c khi caught up, model sá»­ dá»¥ng ráº¥t nhiá»u computing resources (Ä‘ang chuyá»ƒn dáº§n sang hoÃ n toÃ n dÃ¹ng TPU) Ä‘á»ƒ cÃ³ thá»ƒ train háº¿t lÆ°á»£ng dá»¯ liá»‡u tá»« xa trong quÃ¡ khá»© cho tá»›i khi caught up. Má»™t khi Ä‘Ã£ caught up, model tá»± Ä‘á»™ng chuyá»ƒn sang cháº¿ Ä‘á»™ sá»­ dá»¥ng Ã­t tÃ i nguyÃªn hÆ¡n vÃ  nhÆ°á»ng tÃ i nguyÃªn cho cÃ¡c model khÃ¡c. ÄÃ´i khi vÃ¬ lÃ½ do nÃ o Ä‘Ã³ mÃ  model bá»‹ dá»«ng huáº¥n luyá»‡n vÃ  â€œstale"". Stale ráº¥t nguy hiá»ƒm vÃ¬ cÃ³ dá»¯ liá»‡u trending cÃ³ thá»ƒ thay Ä‘á»•i hÃ ng ngÃ y nÃªn team mÃ¬nh ráº¥t chÃº trá»ng vÃ o viá»‡c monitor xem model cÃ³ bá»‹ stale hay khÃ´ng. Vá»›i cÃ¡c mÃ´ hÃ¬nh trong production, khi bá»‹ stale, nÃ³ sáº½ tá»± Ä‘á»™ng láº¥y computing resources tá»« cÃ¡c experimental/offline model khÃ¡c Ä‘á»ƒ Ä‘uá»•i ká»‹p tá»›i training delay. NhÃ¬n chung, hardware cho training vÃ  serving lÃ  khÃ¡c nhau vÃ¬ hai tasks nÃ y cÃ³ nhiá»u Ä‘iá»ƒm khÃ´ng tÆ°Æ¡ng Ä‘á»“ng. Viá»‡c sá»­ dá»¥ng hardware khÃ¡c nhau nÃ y Ä‘Ã´i khi dáº«n Ä‘áº¿n nhá»¯ng káº¿t quáº£ khÃ¡c nhau giá»¯a training vÃ  serving, chá»§ yáº¿u do quantization. VÃ¬ váº­y, cÃ³ má»™t bÆ°á»›c quan trá»ng trÆ°á»›c khi inject model checkpoint lÃ  validation. Táº¡i bÆ°á»›c validation, hardware tÆ°Æ¡ng tá»± nhÆ° trong serving Ä‘Æ°á»£c sá»­ dá»¥ng. Ráº¥t nhiá»u metrics cÃ³ thá»ƒ Ä‘Æ°á»£c kiá»ƒm duyá»‡t á»Ÿ bÆ°á»›c nÃ y trÆ°á»›c khi checkpoints má»›i Ä‘Æ°á»£c injected. Dá»¯ liá»‡u táº¡i bÆ°á»›c validation nÃ y thÆ°á»ng lÃ  dá»¯ liá»‡u má»›i nháº¥t trong dá»¯ liá»‡u tinh mÃ  model chÆ°a nhÃ¬n tháº¥y. OFFLINE EVALUATION BÆ°á»›c validation mÃ¬nh nÃ³i á»Ÿ trÃªn Ä‘Æ°á»£c thá»±c hiá»‡n tá»± Ä‘á»™ng. Táº¥t nhiÃªn, khÃ´ng pháº£i checkpoint nÃ o Ä‘Ã£ pass validation Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°a lÃªn serving Ä‘Æ°á»£c. TrÆ°á»›c khi cÃ³ thá»ƒ lÃªn serving, cÃ¡c team thÆ°á»ng pháº£i kiá»ƒm tra ká»¹ cÃ¡c metrics liÃªn quan vÃ  so sÃ¡nh cÃ¡c metrics Ä‘Ã³ vá»›i baseline. CÃ¡i nÃ y cÃ³ tool riÃªng ráº¥t powerful giÃºp ML engineers cÃ³ thá»ƒ so sÃ¡nh trá»±c tiáº¿p nhiá»u model cÃ¹ng nhau trÃªn nhiá»u traffic slices khÃ¡c nhau. Viá»‡c nÃ y ráº¥t quan trá»ng trÆ°á»›c khi setup online experiment má»›i. ONLINE EXPERIMENT Má»™t mÃ´ hÃ¬nh cÃ³ offline metrics tá»‘t chÆ°a cháº¯c Ä‘Ã£ mang láº¡i hiá»‡u quáº£ trong online experiment vÃ¬ cÃ³ nhiá»u quan há»‡ phá»©c táº¡p khi dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh áº£nh hÆ°á»Ÿng tá»›i káº¿t quáº£ serving. CÃ¡c online metrics cÅ©ng khÃ¡c so vá»›i offline metrics khi cÃ¡c con sá»‘ thá»±c sá»± vá» revenue Ä‘Æ°á»£c quan tÃ¢m. VÃ¬ váº­y, cÃ¡c online experiment Ä‘Æ°á»£c thá»±c hiá»‡n tá»« lÆ°á»£ng traffic tá»« nhá» Ä‘áº¿n lá»›n vÃ  cÃ³ thá»ƒ bá»‹ dá»«ng ngay náº¿u káº¿t quáº£ báº¥t thÆ°á»ng. Viá»‡c Ä‘Æ°a má»™t mÃ´ hÃ¬nh tá»« offline sang online chá»‰ máº¥t khoáº£ng vÃ i tiáº¿ng, chá»§ yáº¿u lÃ  thá»i gian chá» viá»‡c phÃ¢n bá»• tÃ i nguyÃªn vÃ  cháº¡y unit tests. Viá»‡c nÃ y team mÃ¬nh khÃ´ng pháº£i lÃ m gÃ¬ nhiá»u mÃ  cÃ³ cÃ¡c team khÃ¡c chuyÃªn lo cÃ¡c váº¥n Ä‘á» nÃ y. MONITORING SYSTEM Há»‡ thá»‘ng monitoring cÃ³ má»™t nhiá»‡m vá»¥ ráº¥t quan trá»ng Ä‘á»‘i vá»›i online experiment. Vá»›i má»—i model, cÃ¡c team cáº§n thiáº¿t láº­p cÃ¡c há»‡ thá»‘ng theo dÃµi vÃ  bÃ¡o Ä‘á»™ng cho nhiá»u metrics khÃ¡c nhau. Label, prediction, model staleness, skewed features lÃ  bá»‘n trong sá»‘ nhá»¯ng thá»© quan trá»ng nháº¥t cáº§n Ä‘Æ°á»£c monitor. Khi cÃ³ dáº¥u hiá»‡u thay Ä‘á»•i trong nhá»¯ng giÃ¡ trá»‹ nÃ y thÃ¬ oncall/SRE sáº½ bá»‹ bÃ¡o Ä‘á»™ng vÃ  pháº£i tÃ¬m hiá»ƒu nguyÃªn nhÃ¢n cÅ©ng nhÆ° kháº¯c phá»¥c trong thá»i gian ngáº¯n nháº¥t cÃ³ thá»ƒ. Cuá»‘i cÃ¹ng, há»‡ thá»‘ng ML cá»§a Gg khÃ¡ mature, má»—i má»™t thÃ nh pháº§n nhá» Ä‘á»u cÃ³ má»™t Ä‘á»™i ngÅ© Ä‘Ã´ng Ä‘áº£o cÃ¡c engineers quáº£n lÃ½, theo dÃµi vÃ  nÃ¢ng cáº¥p. Quy trÃ¬nh xá»­ lÃ½ sá»± cá»‘ cÅ©ng Ä‘Æ°á»£c ghi chÃ©p láº¡i ká»¹ cÃ ng Ä‘á»ƒ háº¡n cháº¿ nhá»¯ng tai náº¡n trong serving. ChÃ­nh vÃ¬ viá»‡c cÃ³ nhá»¯ng há»‡ thá»‘ng cáº£nh bÃ¡o nhiá»u lá»›p nÃ y mÃ  ráº¥t nhiá»u cÃ¡c experiment cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n má»™t cÃ¡ch nhanh chÃ³ng vÃ  Ã­t gÃ¢y rá»§i ro. TÃ³m láº¡i, nhá»¯ng lÃ½ do chÃ­nh khiáº¿n viá»‡c thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m á»Ÿ Gg cÃ³ thá»ƒ diá»…n ra nhanh chÃ³ng: Data pipeline giá»¯a training vÃ  serving Ä‘Æ°á»£c theo dÃµi vÃ  Ä‘áº£m báº£o Ã­t cÃ³ skew. Computing resources lá»›n (TPU) vÃ  Ä‘Æ°á»£c quáº£n lÃ½ má»™t cÃ¡ch hiá»‡u quáº£. CÃ³ nhá»¯ng cÃ´ng cá»¥ giÃºp viá»‡c Ä‘Ã¡nh giÃ¡ káº¿t quáº£ offline má»™t cÃ¡ch nhanh chÃ³ng. Há»‡ thá»‘ng há»— trá»£ online experiment hiá»‡u quáº£. Há»‡ thá»‘ng monitor cÃ¡c thÃ­ nghiá»‡m cÅ©ng Ä‘Æ°á»£c thiáº¿t láº­p giÃºp cÃ¡c engineers xá»­ lÃ½ ká»‹p thá»i khi cÃ³ incidents.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 6/2022 vÃ o trong comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 6/2022 vÃ o trong comment cá»§a post nÃ y.",,,,,
"LÃ m cÃ¡ch nÃ o Ä‘á»ƒ xÃ¢y dá»±ng má»™t trang web cho mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sá»­ dá»¥ng thuáº­t toÃ¡n Machine Learning - XGBOOST?
Hi má»i ngÆ°á»i,
Video bÃªn dÆ°á»›i mÃ¬nh chia sáº» cÃ¡ch cÆ¡ báº£n vÃ  Ä‘Æ¡n giáº£n Ä‘á»ƒ xÃ¢y dá»±ng má»™t trang Web Local cho viá»‡c dá»± Ä‘oÃ¡n xem liá»‡u nhÃ¢n viÃªn cÃ³ rá»i bá» cÃ´ng ty cá»§a mÃ¬nh hay khÃ´ng? MÃ¬nh sáº½ sá»­ dá»¥ng mÃ´ hÃ¬nh XGBOOST, Flask API, JavaScripts, HTML, CSS Ä‘á»ƒ lÃ m viá»‡c nÃ y.
Dá»±a trÃªn data máº«u cÃ³ sáºµn mÃ¬nh sáº½ thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
1. Äá»c dá»¯ liá»‡u - nhÃ¢n viÃªn cÃ³ rá»i bá» cÃ´ng ty hay khÃ´ng? 2. Chia dá»¯ liá»‡u thÃ nh táº­p train vÃ  test  3. Ãp dá»¥ng mÃ´ hÃ¬nh XGBOOST (sá»­ dá»¥ng cÃ¡c tham sá»‘ máº·c Ä‘á»‹nh, á»Ÿ Ä‘Ã¢y mÃ¬nh khÃ´ng hÆ°á»›ng dáº«n cÃ¡ch Ä‘iá»u chá»‰nh/lá»±a chá»n tham sá»‘ tá»‘t nháº¥t cho mÃ´ hÃ¬nh) 4. Thá»­ dá»± Ä‘oÃ¡n vá»›i data máº«u 5. LÆ°u model báº±ng pickle/joblib 6. Viáº¿t API báº±ng Flask cho mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n 7. Test API báº±ng Postman 8. XÃ¢y dá»±ng trang Web Local báº±ng JavaScripts, HTML, CSS
Done!
Thanks All! Enjoy your weekend
https://youtu.be/CNvPUH41eHU","LÃ m cÃ¡ch nÃ o Ä‘á»ƒ xÃ¢y dá»±ng má»™t trang web cho mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sá»­ dá»¥ng thuáº­t toÃ¡n Machine Learning - XGBOOST? Hi má»i ngÆ°á»i, Video bÃªn dÆ°á»›i mÃ¬nh chia sáº» cÃ¡ch cÆ¡ báº£n vÃ  Ä‘Æ¡n giáº£n Ä‘á»ƒ xÃ¢y dá»±ng má»™t trang Web Local cho viá»‡c dá»± Ä‘oÃ¡n xem liá»‡u nhÃ¢n viÃªn cÃ³ rá»i bá» cÃ´ng ty cá»§a mÃ¬nh hay khÃ´ng? MÃ¬nh sáº½ sá»­ dá»¥ng mÃ´ hÃ¬nh XGBOOST, Flask API, JavaScripts, HTML, CSS Ä‘á»ƒ lÃ m viá»‡c nÃ y. Dá»±a trÃªn data máº«u cÃ³ sáºµn mÃ¬nh sáº½ thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau: 1. Äá»c dá»¯ liá»‡u - nhÃ¢n viÃªn cÃ³ rá»i bá» cÃ´ng ty hay khÃ´ng? 2. Chia dá»¯ liá»‡u thÃ nh táº­p train vÃ  test 3. Ãp dá»¥ng mÃ´ hÃ¬nh XGBOOST (sá»­ dá»¥ng cÃ¡c tham sá»‘ máº·c Ä‘á»‹nh, á»Ÿ Ä‘Ã¢y mÃ¬nh khÃ´ng hÆ°á»›ng dáº«n cÃ¡ch Ä‘iá»u chá»‰nh/lá»±a chá»n tham sá»‘ tá»‘t nháº¥t cho mÃ´ hÃ¬nh) 4. Thá»­ dá»± Ä‘oÃ¡n vá»›i data máº«u 5. LÆ°u model báº±ng pickle/joblib 6. Viáº¿t API báº±ng Flask cho mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n 7. Test API báº±ng Postman 8. XÃ¢y dá»±ng trang Web Local báº±ng JavaScripts, HTML, CSS Done! Thanks All! Enjoy your weekend https://youtu.be/CNvPUH41eHU",,,,,
"*GÃ³c nhá» váº£*
ChÃ o táº¥t cáº£ má»i ngÆ°á»i, m Ä‘ang theo Ä‘uá»•i Ä‘á» tÃ i xÃ¢y dá»±ng há»‡ thá»‘ng viá»‡c lÃ m dá»±a vÃ o Content-based filtering vÃ  Natural Language Processing, m Ä‘ang sá»­ dá»¥ng US technology Jobs #dataset, thá»±c táº¿ lÃ  m muá»‘n lÃ m má»™t há»‡ thá»‘ng giá»›i thiá»‡u viá»‡c lÃ m free cho ngÆ°á»i Viá»‡t, xin há»i ace trong group ai cÃ³ nguá»“n dataset cho há»‡ thá»‘ng gá»£i Ã½ viá»‡c lÃ m khÃ´ng áº¡, náº¿u Ä‘Æ°á»£c cho m xin Ä‘Æ°á»£c chia sáº».
CÃ¡m Æ¡n ace trÆ°á»›c áº¡.","*GÃ³c nhá» váº£* ChÃ o táº¥t cáº£ má»i ngÆ°á»i, m Ä‘ang theo Ä‘uá»•i Ä‘á» tÃ i xÃ¢y dá»±ng há»‡ thá»‘ng viá»‡c lÃ m dá»±a vÃ o Content-based filtering vÃ  Natural Language Processing, m Ä‘ang sá»­ dá»¥ng US technology Jobs thá»±c táº¿ lÃ  m muá»‘n lÃ m má»™t há»‡ thá»‘ng giá»›i thiá»‡u viá»‡c lÃ m free cho ngÆ°á»i Viá»‡t, xin há»i ace trong group ai cÃ³ nguá»“n dataset cho há»‡ thá»‘ng gá»£i Ã½ viá»‡c lÃ m khÃ´ng áº¡, náº¿u Ä‘Æ°á»£c cho m xin Ä‘Æ°á»£c chia sáº». CÃ¡m Æ¡n ace trÆ°á»›c áº¡.","#dataset,",,,,
"Dear cáº£ nhÃ !
Hiá»‡n táº¡i em  Ä‘ang tÃ¬m mua dataset vá»›i labeling theo má»™t sá»‘ tiÃªu chÃ­:
Dataset  vá» cÃ¡c loáº¡i xe Ã´ tÃ´ gáº§n Ä‘Ã¢y vá»›i labelling vá»‹ trÃ­ box cá»§a xe dÆ°á»›i dang  *.xml hoáº·c *.json
Dataset vá» vá»‹  trÃ­ biá»ƒn sá»‘ xe Ã´ tÃ´ vá»›i labelling vá»‹ trÃ­ box cá»§a xe dÆ°á»›i dáº¡ng *.xml hoáº·c *.json
Em Ä‘Äƒng bÃ i Ä‘Ã¢y nhá» cÃ¡c anh chá»‹ em náº¿u cÃ³ ai cÃ³ nguá»“n dataset vui lÃ²ng liÃªn há»‡ vá»›i em Ä‘á»ƒ bÃ¡o giÃ¡ áº¡. Em ráº¥t cáº£m Æ¡n cÃ¡c anh chá»‹.
ChÃºc cáº£ nhÃ  ngÃ y tá»‘t lÃ nh áº¡!",Dear cáº£ nhÃ ! Hiá»‡n táº¡i em Ä‘ang tÃ¬m mua dataset vá»›i labeling theo má»™t sá»‘ tiÃªu chÃ­: Dataset vá» cÃ¡c loáº¡i xe Ã´ tÃ´ gáº§n Ä‘Ã¢y vá»›i labelling vá»‹ trÃ­ box cá»§a xe dÆ°á»›i dang *.xml hoáº·c *.json Dataset vá» vá»‹ trÃ­ biá»ƒn sá»‘ xe Ã´ tÃ´ vá»›i labelling vá»‹ trÃ­ box cá»§a xe dÆ°á»›i dáº¡ng *.xml hoáº·c *.json Em Ä‘Äƒng bÃ i Ä‘Ã¢y nhá» cÃ¡c anh chá»‹ em náº¿u cÃ³ ai cÃ³ nguá»“n dataset vui lÃ²ng liÃªn há»‡ vá»›i em Ä‘á»ƒ bÃ¡o giÃ¡ áº¡. Em ráº¥t cáº£m Æ¡n cÃ¡c anh chá»‹. ChÃºc cáº£ nhÃ  ngÃ y tá»‘t lÃ nh áº¡!,,,,,
Anh/chá»‹ cho em há»i lÃ  khÃ³a há»c ná»•i tiáº¿ng vá» Machine Learning cá»§a tháº§y Andrew Ng trÃªn coursera Ä‘Ã£ bá»‹ xÃ³a rá»“i áº¡ ? Em tÃ¬m há»c thÃ¬ khÃ´ng tháº¥y ná»¯a. CÃ²n cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ há»c khÃ³a nÃ y khÃ´ng áº¡ ? Em cáº£m Æ¡n!,Anh/chá»‹ cho em há»i lÃ  khÃ³a há»c ná»•i tiáº¿ng vá» Machine Learning cá»§a tháº§y Andrew Ng trÃªn coursera Ä‘Ã£ bá»‹ xÃ³a rá»“i áº¡ ? Em tÃ¬m há»c thÃ¬ khÃ´ng tháº¥y ná»¯a. CÃ²n cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ há»c khÃ³a nÃ y khÃ´ng áº¡ ? Em cáº£m Æ¡n!,,,,,
"Má»i cÃ¡c báº¡n tháº£o luáº­n vá» viá»‡c dá»¯ liá»‡u cÃ¡ nhÃ¢n bá»‹ leak sá»‘ lÆ°á»£ng lá»›n á»Ÿ VN. Theo cÃ¡c báº¡n, nguyÃªn nhÃ¢n cá»§a viá»‡c dá»¯ liá»‡u cÃ¡ nhÃ¢n bá»‹ rÃ² rá»‰ lÃ  gÃ¬? NgÆ°á»i dÃ¹ng cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº£o vá»‡ dá»¯ liá»‡u cá»§a mÃ¬nh hay khÃ´ng? Liá»‡u ráº±ng cÃ¡c cÃ´ng ty, cÆ¡ quan cÃ³ cá»‘ gáº¯ng báº£o vá» dá»¯ liá»‡u khÃ¡ch hÃ ng hay khÃ´ng?","Má»i cÃ¡c báº¡n tháº£o luáº­n vá» viá»‡c dá»¯ liá»‡u cÃ¡ nhÃ¢n bá»‹ leak sá»‘ lÆ°á»£ng lá»›n á»Ÿ VN. Theo cÃ¡c báº¡n, nguyÃªn nhÃ¢n cá»§a viá»‡c dá»¯ liá»‡u cÃ¡ nhÃ¢n bá»‹ rÃ² rá»‰ lÃ  gÃ¬? NgÆ°á»i dÃ¹ng cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº£o vá»‡ dá»¯ liá»‡u cá»§a mÃ¬nh hay khÃ´ng? Liá»‡u ráº±ng cÃ¡c cÃ´ng ty, cÆ¡ quan cÃ³ cá»‘ gáº¯ng báº£o vá» dá»¯ liá»‡u khÃ¡ch hÃ ng hay khÃ´ng?",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c! NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» Airlfow cho ML, AI. Em máº¡nh dáº¡n lÃ m clip cho anh em vá» Airflow - crawl dá»¯ liá»‡u, train model hoÃ n toÃ n tá»± Ä‘á»™ng.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem, hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c!","KÃ­nh chÃ o cÃ¡c bÃ¡c! NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» Airlfow cho ML, AI. Em máº¡nh dáº¡n lÃ m clip cho anh em vá» Airflow - crawl dá»¯ liá»‡u, train model hoÃ n toÃ n tá»± Ä‘á»™ng. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem, hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c!",,,,,
"ToÃ¡n há»c lÃ  má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u cá»§a má»™t DataScientist/AI Researcher giá»i. Má»i cÃ¡c báº¡n tham gia thá»­ thÃ¡ch giáº£i bÃ i táº­p vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh cá»§a DataScienceWorld.Kan.
Giáº£i toÃ¡n vÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n, Fighting!
 â€” Ä‘ang cáº£m tháº¥y máº¡nh máº½.","ToÃ¡n há»c lÃ  má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u cá»§a má»™t DataScientist/AI Researcher giá»i. Má»i cÃ¡c báº¡n tham gia thá»­ thÃ¡ch giáº£i bÃ i táº­p vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh cá»§a DataScienceWorld.Kan. Giáº£i toÃ¡n vÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n, Fighting! â€” Ä‘ang cáº£m tháº¥y máº¡nh máº½.",,,,,
"ChÃ o cáº£ nhÃ !
Hiá»‡n táº¡i mÃ¬nh Ä‘ang tÃ¬m dataset cho cÃ¡c loáº¡i xe vÃ  area biá»ƒn sá»‘ xe Ã´ tÃ´, trong group mÃ¬nh cÃ³ biáº¿t source dataset nÃ o cÃ³ thá»ƒ share cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng? Source dataset cÃ³ labelling bounding box thÃ¬ cÃ ng tá»‘t nhÃ© ^^
MÃ¬nh xin cáº£m Æ¡n nhÃ©!
P/s mÃ¬nh Ä‘Ã£ sÃ i dataset cá»§a standford vá» car model do dataset Ä‘Ã³ khÃ¡ lÃ¢u tá»« 2012 nÃªn mÃ¬nh Ä‘ang tÃ¬m thÃªm dataset má»›i cáº­p nháº­t gáº§n Ä‘Ã¢y áº¡.","ChÃ o cáº£ nhÃ ! Hiá»‡n táº¡i mÃ¬nh Ä‘ang tÃ¬m dataset cho cÃ¡c loáº¡i xe vÃ  area biá»ƒn sá»‘ xe Ã´ tÃ´, trong group mÃ¬nh cÃ³ biáº¿t source dataset nÃ o cÃ³ thá»ƒ share cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng? Source dataset cÃ³ labelling bounding box thÃ¬ cÃ ng tá»‘t nhÃ© ^^ MÃ¬nh xin cáº£m Æ¡n nhÃ©! P/s mÃ¬nh Ä‘Ã£ sÃ i dataset cá»§a standford vá» car model do dataset Ä‘Ã³ khÃ¡ lÃ¢u tá»« 2012 nÃªn mÃ¬nh Ä‘ang tÃ¬m thÃªm dataset má»›i cáº­p nháº­t gáº§n Ä‘Ã¢y áº¡.",,,,,
"#Outmemorycuda
ChÃ o má»i ngÆ°á»i
Cá»¥ thá»ƒ lÃ  mÃ¬nh Ä‘Ã£ cÃ³ model rá»“i sau Ä‘Ã³ mÃ¬nh dÃ¹ng model Ä‘i validate trÃªn táº­p dá»¯ liá»‡u nhá» hÆ¡n thÃ¬ bÃ¡o lá»—i bá»‹ out memory cuda
VÃ  sau nhiá»u láº§n debug mÃ¬nh tÃ¬m ra lá»—i náº¿u thÃªm vÃ o tÃ­nh loss vÃ  call loss.backward() thÃ¬ mÃ¬nh cháº¡y trÆ¡n tru mÆ°á»£t mÃ . Váº­y cÃ³ pháº£i loss.backward() thÃ¬ sáº½ free memory hay khÃ´ng ?",ChÃ o má»i ngÆ°á»i Cá»¥ thá»ƒ lÃ  mÃ¬nh Ä‘Ã£ cÃ³ model rá»“i sau Ä‘Ã³ mÃ¬nh dÃ¹ng model Ä‘i validate trÃªn táº­p dá»¯ liá»‡u nhá» hÆ¡n thÃ¬ bÃ¡o lá»—i bá»‹ out memory cuda VÃ  sau nhiá»u láº§n debug mÃ¬nh tÃ¬m ra lá»—i náº¿u thÃªm vÃ o tÃ­nh loss vÃ  call loss.backward() thÃ¬ mÃ¬nh cháº¡y trÆ¡n tru mÆ°á»£t mÃ . Váº­y cÃ³ pháº£i loss.backward() thÃ¬ sáº½ free memory hay khÃ´ng ?,#Outmemorycuda,,,,
"## Update: MÃ¬nh implement nháº§m residual connection á»Ÿ decoder
Link model má»›i: https://colab.research.google.com/drive/1Vf1BvVAC0s2LDVOWc0Rf9slT9cO6S9Ch#scrollTo=P8y7Xp5AQUFq

ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang táº­p tÃ nh implement láº¡i tá»« paper: https://arxiv.org/abs/2101.10804. BÃ i toÃ¡n lÃ  image captioning train tá»« bá»™ data Flickr8k. train data lÃ  1 áº£nh -> 5 captions
Hiá»‡n táº¡i mÃ¬nh cÃ³ train 2 model, cáº£ 2 model dÃ¹ng pretrained vision transfomer lÃ m encoder Ä‘á»ƒ trÃ­ch xuáº¥t features tá»« áº£nh
Model thá»© nháº¥t thÃ¬ mÃ¬nh dÃ¹ng 4 layers decoder tá»« transfomers thÃ¬ káº¿t quáº£ lÃ  model khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c->loss khÃ´ng giáº£m nhiá»u. 
+ Link colab: https://colab.research.google.com/drive/1xbtIPWTX-f6m5cgjD_s5zS8nhyiKBx9Z?usp=sharing
Model thá»© 2 mÃ¬nh giáº£m nÃ³ xuá»‘ng cÃ²n 1 decoder layer thÃ¬ mÃ¬nh cáº£m tháº¥y model Ä‘ang há»c tá»‘t vÃ   loss cÃ³ giáº£m vÃ  inference ra Ä‘Æ°á»£c máº·c dÃ¹ káº¿t quáº£ khÃ´ng tá»‘t.
+ Link colab: https://colab.research.google.com/drive/15ZRJ5E3a5H-yLkZl-7I853J3bxwnAsvj?usp=sharing
Theo lÃ½ thuyáº¿t thÃ¬ dÃ¹ng Ä‘áº¿n 4 decoder layers thÃ¬ model sáº½ há»c Ä‘Æ°á»£c features tá»‘t hÆ¡n nhÆ°ng khi mÃ¬nh train thÃ¬ 4 decoder layers thÃ¬ model láº¡i bá»‹ underfitting, mÃ¬nh váº«n chÆ°a hiá»ƒu táº¡i sai mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p.","## Update: MÃ¬nh implement nháº§m residual connection á»Ÿ decoder Link model má»›i: https://colab.research.google.com/drive/1Vf1BvVAC0s2LDVOWc0Rf9slT9cO6S9Ch#scrollTo=P8y7Xp5AQUFq ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang táº­p tÃ nh implement láº¡i tá»« paper: https://arxiv.org/abs/2101.10804. BÃ i toÃ¡n lÃ  image captioning train tá»« bá»™ data Flickr8k. train data lÃ  1 áº£nh -> 5 captions Hiá»‡n táº¡i mÃ¬nh cÃ³ train 2 model, cáº£ 2 model dÃ¹ng pretrained vision transfomer lÃ m encoder Ä‘á»ƒ trÃ­ch xuáº¥t features tá»« áº£nh Model thá»© nháº¥t thÃ¬ mÃ¬nh dÃ¹ng 4 layers decoder tá»« transfomers thÃ¬ káº¿t quáº£ lÃ  model khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c->loss khÃ´ng giáº£m nhiá»u. + Link colab: https://colab.research.google.com/drive/1xbtIPWTX-f6m5cgjD_s5zS8nhyiKBx9Z?usp=sharing Model thá»© 2 mÃ¬nh giáº£m nÃ³ xuá»‘ng cÃ²n 1 decoder layer thÃ¬ mÃ¬nh cáº£m tháº¥y model Ä‘ang há»c tá»‘t vÃ  loss cÃ³ giáº£m vÃ  inference ra Ä‘Æ°á»£c máº·c dÃ¹ káº¿t quáº£ khÃ´ng tá»‘t. + Link colab: https://colab.research.google.com/drive/15ZRJ5E3a5H-yLkZl-7I853J3bxwnAsvj?usp=sharing Theo lÃ½ thuyáº¿t thÃ¬ dÃ¹ng Ä‘áº¿n 4 decoder layers thÃ¬ model sáº½ há»c Ä‘Æ°á»£c features tá»‘t hÆ¡n nhÆ°ng khi mÃ¬nh train thÃ¬ 4 decoder layers thÃ¬ model láº¡i bá»‹ underfitting, mÃ¬nh váº«n chÆ°a hiá»ƒu táº¡i sai mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p.",,,,,
"""Responsible sources""? Äáº¿n cÃ¡i cá»‘c cÃ²n Ä‘Æ°á»£c Ä‘Ã³ng mÃ¡c ""responsible"" tháº¿ nÃ y, thÃ¬ cÃ¡c giáº£i phÃ¡p AI cÃ²n pháº£i cáº§n ""Ä‘Ã³ng mÃ¡c"" nhá»¯ng gÃ¬? Náº¿u báº¡n Ä‘ang lÃ m nghiÃªn cá»©u vÃ  quan tÃ¢m Ä‘áº¿n ReliableML thÃ¬ cÃ¢n nháº¯c submit vÃ o special session team tá»• chá»©c á»Ÿ ICONIP'22 nhÃ©, chá»§ Ä‘á»: Reliable, Robust, and Secure Machine Learning Algorithms. 

Accepted papers sáº½ Ä‘Æ°á»£c index cÃ¹ng vá»›i proceedings cá»§a conference nhÃ© cÃ¡c báº¡n. ThÃ´ng tin thÃªm má»i cÃ¡c ACE Ä‘á»c á»Ÿ website [1].

****
Deadline of Special Session Papers: July 07, 2022
Organizers:
Monowar Bhuyan, UmeÃ¥ University, Sweden
Xuan-Son Vu, UmeÃ¥ University, Sweden
Harry Nguyen, University of Glasgow, Singapore
Erik Elmroth, UmeÃ¥ University, Sweden
****
[1] Special session homepage: https://reliableml.cs.umu.se/","""Responsible sources""? Äáº¿n cÃ¡i cá»‘c cÃ²n Ä‘Æ°á»£c Ä‘Ã³ng mÃ¡c ""responsible"" tháº¿ nÃ y, thÃ¬ cÃ¡c giáº£i phÃ¡p AI cÃ²n pháº£i cáº§n ""Ä‘Ã³ng mÃ¡c"" nhá»¯ng gÃ¬? Náº¿u báº¡n Ä‘ang lÃ m nghiÃªn cá»©u vÃ  quan tÃ¢m Ä‘áº¿n ReliableML thÃ¬ cÃ¢n nháº¯c submit vÃ o special session team tá»• chá»©c á»Ÿ ICONIP'22 nhÃ©, chá»§ Ä‘á»: Reliable, Robust, and Secure Machine Learning Algorithms. Accepted papers sáº½ Ä‘Æ°á»£c index cÃ¹ng vá»›i proceedings cá»§a conference nhÃ© cÃ¡c báº¡n. ThÃ´ng tin thÃªm má»i cÃ¡c ACE Ä‘á»c á»Ÿ website [1]. **** Deadline of Special Session Papers: July 07, 2022 Organizers: Monowar Bhuyan, UmeÃ¥ University, Sweden Xuan-Son Vu, UmeÃ¥ University, Sweden Harry Nguyen, University of Glasgow, Singapore Erik Elmroth, UmeÃ¥ University, Sweden **** [1] Special session homepage: https://reliableml.cs.umu.se/",,,,,
"Need help for web development
Xin chÃ o cáº£ nhÃ 
MÃ¬nh lÃ m nghiÃªn cá»©u vá» dá»± bÃ¡o má»±c nÆ°á»›c trÃªn sÃ´ng sá»­ dá»¥ng DL (LSTMs) vÃ  cáº§n lÃ m 1 website vá» dá»± bÃ¡o dÃ i háº¡n má»±c nÆ°á»›c trÃªn cÃ¡c sÃ´ng lá»›n trÃªn toÃ n tháº¿ giá»›i. Vá» máº·t sá»‘ liá»‡u vÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã£ táº¡m á»•n nhÆ°ng bá»‹ hÃ³c chá»— web development Ä‘á»ƒ cho káº¿t quáº£ lÃªn do mÃ¬nh khÃ´ng cÃ³ chuyÃªn mÃ´n vá» máº£ng nÃ y nÃªn viáº¿t nÃªn Ä‘Ã¢y hy vá»ng báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp.
Website dá»± kiáº¿n cÃ³ form giá»‘ng nhÆ° website sau: https://hydroweb.theia-land.fr/?lang=en& , vá»›i báº£n Ä‘á»“ background active/zoomable, trÃ¬nh bÃ y vÃ  trÃ­ch xuáº¥t sá»‘ liá»‡u (data Ä‘Ã£ cháº¡y sáºµn) táº¡i cÃ¡i Ä‘iá»ƒm Ä‘o https://hydroweb.theia-land.fr/hydroweb/view/R_RHONE_DOUBS_KM0619?lang=en. Báº¡n nÃ o cÃ³ thá»ƒ chá»‰ giÃºp minh lÃ m cÃ¡ch nÃ o Ä‘á»ƒ lÃ m cÃ¡i báº£n Ä‘á»“ nhÆ° váº­y khÃ´ng áº¡? (website vÃ  sá»‘ liá»‡u trong báº£n Ä‘á»“ mÃ¬nh cÃ³)
MÃ¬nh xin lá»—i vÃ¬ cÃ¢u há»i thiÃªn vá» á»©ng dá»¥ng thá»±c táº¿ hÆ¡n lÃ  cÆ¡ báº£n, mong cÃ¡c báº¡n thÃ´ng cáº£m.
Xin chÃ¢n thÃ nh cáº£m Æ¡n admin vÃ  sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c báº¡n
(má»i sá»± gÃ³p Ã½/giÃºp Ä‘á»¡ xin nháº¯n vÃ o inbox giÃ¹m áº¡).","Need help for web development Xin chÃ o cáº£ nhÃ  MÃ¬nh lÃ m nghiÃªn cá»©u vá» dá»± bÃ¡o má»±c nÆ°á»›c trÃªn sÃ´ng sá»­ dá»¥ng DL (LSTMs) vÃ  cáº§n lÃ m 1 website vá» dá»± bÃ¡o dÃ i háº¡n má»±c nÆ°á»›c trÃªn cÃ¡c sÃ´ng lá»›n trÃªn toÃ n tháº¿ giá»›i. Vá» máº·t sá»‘ liá»‡u vÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã£ táº¡m á»•n nhÆ°ng bá»‹ hÃ³c chá»— web development Ä‘á»ƒ cho káº¿t quáº£ lÃªn do mÃ¬nh khÃ´ng cÃ³ chuyÃªn mÃ´n vá» máº£ng nÃ y nÃªn viáº¿t nÃªn Ä‘Ã¢y hy vá»ng báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp. Website dá»± kiáº¿n cÃ³ form giá»‘ng nhÆ° website sau: https://hydroweb.theia-land.fr/?lang=en& , vá»›i báº£n Ä‘á»“ background active/zoomable, trÃ¬nh bÃ y vÃ  trÃ­ch xuáº¥t sá»‘ liá»‡u (data Ä‘Ã£ cháº¡y sáºµn) táº¡i cÃ¡i Ä‘iá»ƒm Ä‘o https://hydroweb.theia-land.fr/hydroweb/view/R_RHONE_DOUBS_KM0619?lang=en. Báº¡n nÃ o cÃ³ thá»ƒ chá»‰ giÃºp minh lÃ m cÃ¡ch nÃ o Ä‘á»ƒ lÃ m cÃ¡i báº£n Ä‘á»“ nhÆ° váº­y khÃ´ng áº¡? (website vÃ  sá»‘ liá»‡u trong báº£n Ä‘á»“ mÃ¬nh cÃ³) MÃ¬nh xin lá»—i vÃ¬ cÃ¢u há»i thiÃªn vá» á»©ng dá»¥ng thá»±c táº¿ hÆ¡n lÃ  cÆ¡ báº£n, mong cÃ¡c báº¡n thÃ´ng cáº£m. Xin chÃ¢n thÃ nh cáº£m Æ¡n admin vÃ  sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c báº¡n (má»i sá»± gÃ³p Ã½/giÃºp Ä‘á»¡ xin nháº¯n vÃ o inbox giÃ¹m áº¡).",,,,,
"má»i ngÆ°á»i cho em há»i vá»›i áº¡, khi plot price cá»§a computer theo cÃ¡c variable khÃ¡c em Ä‘Æ°á»£c graphs nhÆ° nÃ y. thÃ¬ sao mÃ¬nh cÃ³ thá»ƒ káº¿t luáº­n Ä‘Æ°á»£c Ä‘Ã¢u lÃ  promising predictors áº¡. em cáº£m Æ¡n áº¡","má»i ngÆ°á»i cho em há»i vá»›i áº¡, khi plot price cá»§a computer theo cÃ¡c variable khÃ¡c em Ä‘Æ°á»£c graphs nhÆ° nÃ y. thÃ¬ sao mÃ¬nh cÃ³ thá»ƒ káº¿t luáº­n Ä‘Æ°á»£c Ä‘Ã¢u lÃ  promising predictors áº¡. em cáº£m Æ¡n áº¡",,,,,
"KiÌnh chaÌ€o cÃ´ chuÌ vaÌ€ caÌc anh chiÌ£.
Em xin noÌi thÄƒÌ‰ng em laÌ€ dÃ¢n ngoaÌ£i Ä‘aÌ£o chÆ°Ì khÃ´ng theo hoÌ£c khoa hoÌ£c dÆ°Ìƒ liÃªÌ£u hay IT noÌi chung. Em thiÌ‰nh thoaÌ‰ng coÌ thuÌ vui laÌ€ Ä‘i cÃ¢u caÌ. Trong khi cÃ¢u thÆ°Æ¡Ì€ng coÌ haÌ€ng tiÃªÌng Ä‘Ã´Ì€ng hÃ´Ì€ ngÃ´Ì€i chÆ¡Ì€ caÌ cÄƒÌn vaÌ€ chiÌ‰ coÌ 1-2 phuÌt cÃ¢Ì€n tÃ¢Ì£p trung khi coÌ tiÌn hiÃªÌ£u Æ¡Ì‰ phao. ÄiÃªÌ€u naÌ€y khiÃªÌn cho viÃªÌ£c vÆ°Ì€a ngÃ´Ì€i vÆ°Ì€a thÆ° giaÌƒn, noÌi chuyÃªÌ£n vÆ¡Ìi baÌ£n beÌ€ bÃªn caÌ£nh laÌ€ hÆ¡i khoÌ viÌ€ dÃªÌƒ boÌ‰ lÆ¡Ìƒ nhiÌ£p caÌ Äƒn.
Em muÃ´Ìn hoÌ‰i laÌ€ coÌ caÌch naÌ€o code Ä‘Æ°Æ¡Ì£c 1 caÌi app Ä‘iÃªÌ£n thoaÌ£i. TÆ°Ì£ Ä‘Ã´Ì£ng baÌo khi noÌ nhÃ¢Ì£n diÃªÌ£n Ä‘Æ°Æ¡Ì£c tiÌn hiÃªÌ£u phao khÃ´ng aÌ£? KiÃªÌ‰u setup caÌi giaÌ Ä‘Æ¡Ìƒ Ä‘iÃªÌ£n thoaÌ£i, mÆ¡Ì‰ app cho noÌ zoom thÄƒÌ‰ng vaÌ€o phao Ä‘ÃªÌ‰ noÌ nhÃ¢Ì£n phao. MÃ´Ìƒi khi phao nÃ´Ì‰i lÃªn hay thuÌ£t xuÃ´Ìng noÌ seÌƒ coÌ Ã¢m baÌo. ThÃ¢Ì£m chiÌ cao cÃ¢Ìp hÆ¡n coÌ khaÌ‰ nÄƒng baÌo tÆ°Æ¡ng Ä‘Ã´Ìi chiÌnh xaÌc loaÌ£i caÌ naÌ€o Ä‘ang/vÆ°Ì€a Äƒn mÃ´Ì€i dÆ°Ì£a vaÌ€o tiÌn hiÃªÌ£u phao nhÆ°ng caÌi naÌ€y khÃ´ng quan troÌ£ng viÌ€ dÃ¢n cÃ¢u chuyÃªn cuÌƒng chiÌ‰ Ä‘oaÌn Ä‘uÌng tÃ¢Ì€m 70% thÃ´i. Em nghiÌƒ app naÌ€y seÌƒ taÌc duÌ£ng vÃ´ cuÌ€ng khi maÌ€ ngÆ°Æ¡Ì€i cÃ¢u caÌ khÃ´ng cÃ¢Ì€n cÄƒng mÄƒÌt mÃ¢Ìy tiÃªÌng Ä‘Ã´Ì€ng hÃ´Ì€ nhiÌ€n caÌi phao nÆ°Ìƒa. HoÌ£ seÌƒ thoÌ‰a maÌi ngÃ´Ì€i thÆ° giaÌƒn, noÌi chuyÃªÌ£n vÆ¡Ìi baÌ£n beÌ€ vaÌ€ chiÌ‰ phaÌ‰i tÃ¢Ì£p trung khi Ä‘iÃªÌ£n thoaÌ£i baÌo coÌ tiÌn hiÃªÌ£u phao. ÄiÃªÌ€u nÆ°Ìƒa laÌ€ dÃ¢n cÃ¢u thÆ°Æ¡Ì€ng thuÃ´Ì£c daÌ£ng thu nhÃ¢Ì£p trung biÌ€nh trÆ¡Ì‰ lÃªn nÃªn em nghiÌƒ seÌƒ rÃ¢Ìt nhiÃªÌ€u cÆ¡ hÃ´Ì£i Ä‘ÃªÌ‰ cheÌ€n quaÌ‰ng caÌo vaÌ€o app. LiÃªÌ£u code 1 caÌi app nhÆ° vÃ¢Ì£y coÌ khaÌ‰ thi khÃ´ng aÌ£?","KiÌnh chaÌ€o cÃ´ chuÌ vaÌ€ caÌc anh chiÌ£. Em xin noÌi thÄƒÌ‰ng em laÌ€ dÃ¢n ngoaÌ£i Ä‘aÌ£o chÆ°Ì khÃ´ng theo hoÌ£c khoa hoÌ£c dÆ°Ìƒ liÃªÌ£u hay IT noÌi chung. Em thiÌ‰nh thoaÌ‰ng coÌ thuÌ vui laÌ€ Ä‘i cÃ¢u caÌ. Trong khi cÃ¢u thÆ°Æ¡Ì€ng coÌ haÌ€ng tiÃªÌng Ä‘Ã´Ì€ng hÃ´Ì€ ngÃ´Ì€i chÆ¡Ì€ caÌ cÄƒÌn vaÌ€ chiÌ‰ coÌ 1-2 phuÌt cÃ¢Ì€n tÃ¢Ì£p trung khi coÌ tiÌn hiÃªÌ£u Æ¡Ì‰ phao. ÄiÃªÌ€u naÌ€y khiÃªÌn cho viÃªÌ£c vÆ°Ì€a ngÃ´Ì€i vÆ°Ì€a thÆ° giaÌƒn, noÌi chuyÃªÌ£n vÆ¡Ìi baÌ£n beÌ€ bÃªn caÌ£nh laÌ€ hÆ¡i khoÌ viÌ€ dÃªÌƒ boÌ‰ lÆ¡Ìƒ nhiÌ£p caÌ Äƒn. Em muÃ´Ìn hoÌ‰i laÌ€ coÌ caÌch naÌ€o code Ä‘Æ°Æ¡Ì£c 1 caÌi app Ä‘iÃªÌ£n thoaÌ£i. TÆ°Ì£ Ä‘Ã´Ì£ng baÌo khi noÌ nhÃ¢Ì£n diÃªÌ£n Ä‘Æ°Æ¡Ì£c tiÌn hiÃªÌ£u phao khÃ´ng aÌ£? KiÃªÌ‰u setup caÌi giaÌ Ä‘Æ¡Ìƒ Ä‘iÃªÌ£n thoaÌ£i, mÆ¡Ì‰ app cho noÌ zoom thÄƒÌ‰ng vaÌ€o phao Ä‘ÃªÌ‰ noÌ nhÃ¢Ì£n phao. MÃ´Ìƒi khi phao nÃ´Ì‰i lÃªn hay thuÌ£t xuÃ´Ìng noÌ seÌƒ coÌ Ã¢m baÌo. ThÃ¢Ì£m chiÌ cao cÃ¢Ìp hÆ¡n coÌ khaÌ‰ nÄƒng baÌo tÆ°Æ¡ng Ä‘Ã´Ìi chiÌnh xaÌc loaÌ£i caÌ naÌ€o Ä‘ang/vÆ°Ì€a Äƒn mÃ´Ì€i dÆ°Ì£a vaÌ€o tiÌn hiÃªÌ£u phao nhÆ°ng caÌi naÌ€y khÃ´ng quan troÌ£ng viÌ€ dÃ¢n cÃ¢u chuyÃªn cuÌƒng chiÌ‰ Ä‘oaÌn Ä‘uÌng tÃ¢Ì€m 70% thÃ´i. Em nghiÌƒ app naÌ€y seÌƒ taÌc duÌ£ng vÃ´ cuÌ€ng khi maÌ€ ngÆ°Æ¡Ì€i cÃ¢u caÌ khÃ´ng cÃ¢Ì€n cÄƒng mÄƒÌt mÃ¢Ìy tiÃªÌng Ä‘Ã´Ì€ng hÃ´Ì€ nhiÌ€n caÌi phao nÆ°Ìƒa. HoÌ£ seÌƒ thoÌ‰a maÌi ngÃ´Ì€i thÆ° giaÌƒn, noÌi chuyÃªÌ£n vÆ¡Ìi baÌ£n beÌ€ vaÌ€ chiÌ‰ phaÌ‰i tÃ¢Ì£p trung khi Ä‘iÃªÌ£n thoaÌ£i baÌo coÌ tiÌn hiÃªÌ£u phao. ÄiÃªÌ€u nÆ°Ìƒa laÌ€ dÃ¢n cÃ¢u thÆ°Æ¡Ì€ng thuÃ´Ì£c daÌ£ng thu nhÃ¢Ì£p trung biÌ€nh trÆ¡Ì‰ lÃªn nÃªn em nghiÌƒ seÌƒ rÃ¢Ìt nhiÃªÌ€u cÆ¡ hÃ´Ì£i Ä‘ÃªÌ‰ cheÌ€n quaÌ‰ng caÌo vaÌ€o app. LiÃªÌ£u code 1 caÌi app nhÆ° vÃ¢Ì£y coÌ khaÌ‰ thi khÃ´ng aÌ£?",,,,,
"ChÃ o cÃ¡c anh chá»‹ em trong group
Hiá»‡n táº¡i mÃ¬nh Ä‘ang tÃ¬m tÃ i liá»‡u cho viá»‡c phÃ¡t triá»ƒn tÃ­ch há»£p OCR vÃ o swiftUI trÃªn cÃ¡c thiáº¿t bá»‹ sá»­ dá»¥ng apple silicon.
CÃ¡c mÃ´ hÃ¬nh hiá»‡n nay nhÆ° easyOCR, paddleOCR, .... & cÃ¡c framework Ä‘á»u Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn trÃªn kiáº¿n trÃºc ARM
TesseractOCR thÃ¬ ... Ã  mÃ  thÃ´i, bá» Ä‘i
Má»™t sá»‘ mÃ´ hÃ¬nh OCR há»— trá»£ cho swift nhÆ° SwiftOCR, MacOCR cÅ©ng Ä‘á»u lÃ  nhá»¯ng lib Ä‘Ã£ cÅ©, cháº¡y trÃªn series apple Ä‘áº§u A, mÃ¬nh ko dÃ¡m Ä‘áº£m báº£o nÃ³ sáº½ cháº¡y Ä‘Æ°á»£c trÃªn chip má»›i cá»§a apple
KhÃ´ng biáº¿t anh chá»‹ em nÃ o cÃ³ giáº£i phÃ¡p cho váº¥n Ä‘á» nÃ y khÃ´ng, em xin cáº£m Æ¡n trÆ°á»›c.
p/s: á»Ÿ Ä‘Ã¢y mÃ¬nh ko muá»‘n sá»­ dá»¥ng cloud service hay build server váº­t lÃ½ Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y.","ChÃ o cÃ¡c anh chá»‹ em trong group Hiá»‡n táº¡i mÃ¬nh Ä‘ang tÃ¬m tÃ i liá»‡u cho viá»‡c phÃ¡t triá»ƒn tÃ­ch há»£p OCR vÃ o swiftUI trÃªn cÃ¡c thiáº¿t bá»‹ sá»­ dá»¥ng apple silicon. CÃ¡c mÃ´ hÃ¬nh hiá»‡n nay nhÆ° easyOCR, paddleOCR, .... & cÃ¡c framework Ä‘á»u Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn trÃªn kiáº¿n trÃºc ARM TesseractOCR thÃ¬ ... Ã  mÃ  thÃ´i, bá» Ä‘i Má»™t sá»‘ mÃ´ hÃ¬nh OCR há»— trá»£ cho swift nhÆ° SwiftOCR, MacOCR cÅ©ng Ä‘á»u lÃ  nhá»¯ng lib Ä‘Ã£ cÅ©, cháº¡y trÃªn series apple Ä‘áº§u A, mÃ¬nh ko dÃ¡m Ä‘áº£m báº£o nÃ³ sáº½ cháº¡y Ä‘Æ°á»£c trÃªn chip má»›i cá»§a apple KhÃ´ng biáº¿t anh chá»‹ em nÃ o cÃ³ giáº£i phÃ¡p cho váº¥n Ä‘á» nÃ y khÃ´ng, em xin cáº£m Æ¡n trÆ°á»›c. p/s: á»Ÿ Ä‘Ã¢y mÃ¬nh ko muá»‘n sá»­ dá»¥ng cloud service hay build server váº­t lÃ½ Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y.",,,,,
"Xin chÃ o má»i ngÆ°á»i. Em vá»«a má»›i theo há»c deep learning gáº§n Ä‘Ã¢y. Em cÃ³ váº¥n Ä‘á» muá»‘n tham kháº£o cÃ¡c anh/chá»‹ Ä‘Ã£ cÃ³ kinh nghiá»‡m trong lÄ©nh vá»±c nÃ y. TÃ¬nh hÃ¬nh lÃ  em Ä‘ang develop má»™t há»‡ thá»‘ng nháº­n diá»‡n chá»¯ viáº¿t tay online, model em Ä‘ang dÃ¹ng lÃ  GRU. Hiá»‡n táº¡i thÃ¬ em Ä‘ang dÃ¹ng kiá»ƒu cho tá»«ng stroke vÃ o rá»“i nháº­n diá»‡n stroke Ä‘Ã³ lÃ  chá»¯ cÃ¡i gÃ¬ trong báº£ng alphabet. Input lÃ  cÃ¡c vector Ä‘áº¡i diá»‡n cho hÆ°á»›ng táº¡i cÃ¡c point, output lÃ  one-hot vector Ä‘áº¡i diá»‡n cho má»™t chá»¯ cÃ¡i.
Äáº¿n Ä‘Ã¢y cháº¯c cÃ¡c anh/chá»‹ cÅ©ng nháº­n ra lÃ  cÃ³ váº¥n Ä‘á» rá»“i pháº£i khÃ´ng áº¡. VÃ¢ng, em Ä‘ang cÃ³ trÆ°á»ng há»£p lÃ  má»™t sá»‘ stroke viáº¿t tay nÃ³ Ä‘áº¡i diá»‡n cho nhiá»u chá»¯ cÃ¡i chá»© khÃ´ng pháº£i chá»‰ má»™t. VÃ­ dá»¥, ngÆ°á»i ta viáº¿t chá»¯ ""moon"" chá»‰ vá»›i 1 nÃ©t, em khÃ´ng biáº¿t pháº£i biá»ƒu diá»…n target output nhÆ° tháº¿ nÃ o Ä‘á»ƒ GRU cÃ³ thá»ƒ há»c Ä‘Æ°á»£c. Mong ráº±ng cÃ³ anh/chá»‹ nÃ o Ä‘Ã³ tá»‘t bá»¥ng giáº£i Ä‘Ã¡p giÃºp em. Em xin cáº£m Æ¡n trÆ°á»›c.","Xin chÃ o má»i ngÆ°á»i. Em vá»«a má»›i theo há»c deep learning gáº§n Ä‘Ã¢y. Em cÃ³ váº¥n Ä‘á» muá»‘n tham kháº£o cÃ¡c anh/chá»‹ Ä‘Ã£ cÃ³ kinh nghiá»‡m trong lÄ©nh vá»±c nÃ y. TÃ¬nh hÃ¬nh lÃ  em Ä‘ang develop má»™t há»‡ thá»‘ng nháº­n diá»‡n chá»¯ viáº¿t tay online, model em Ä‘ang dÃ¹ng lÃ  GRU. Hiá»‡n táº¡i thÃ¬ em Ä‘ang dÃ¹ng kiá»ƒu cho tá»«ng stroke vÃ o rá»“i nháº­n diá»‡n stroke Ä‘Ã³ lÃ  chá»¯ cÃ¡i gÃ¬ trong báº£ng alphabet. Input lÃ  cÃ¡c vector Ä‘áº¡i diá»‡n cho hÆ°á»›ng táº¡i cÃ¡c point, output lÃ  one-hot vector Ä‘áº¡i diá»‡n cho má»™t chá»¯ cÃ¡i. Äáº¿n Ä‘Ã¢y cháº¯c cÃ¡c anh/chá»‹ cÅ©ng nháº­n ra lÃ  cÃ³ váº¥n Ä‘á» rá»“i pháº£i khÃ´ng áº¡. VÃ¢ng, em Ä‘ang cÃ³ trÆ°á»ng há»£p lÃ  má»™t sá»‘ stroke viáº¿t tay nÃ³ Ä‘áº¡i diá»‡n cho nhiá»u chá»¯ cÃ¡i chá»© khÃ´ng pháº£i chá»‰ má»™t. VÃ­ dá»¥, ngÆ°á»i ta viáº¿t chá»¯ ""moon"" chá»‰ vá»›i 1 nÃ©t, em khÃ´ng biáº¿t pháº£i biá»ƒu diá»…n target output nhÆ° tháº¿ nÃ o Ä‘á»ƒ GRU cÃ³ thá»ƒ há»c Ä‘Æ°á»£c. Mong ráº±ng cÃ³ anh/chá»‹ nÃ o Ä‘Ã³ tá»‘t bá»¥ng giáº£i Ä‘Ã¡p giÃºp em. Em xin cáº£m Æ¡n trÆ°á»›c.",,,,,
"Dáº¡, em chÃ o máº¥y anh/chá»‹ áº¡.
em Ä‘ang lÃ m vá» Ä‘á» tÃ i lÃ  nháº­n diá»‡n náº¥m linh chi Ä‘á» trÆ°á»Ÿng thÃ nh báº±ng camera. NhÆ°ng theo má»™t sá»‘ thÃ´ng tin em Ä‘á»c Ä‘Æ°á»£c thÃ¬ Ä‘iá»ƒm khÃ¡c nhau giá»¯a cÃ¢y trÆ°á»Ÿng thÃ nh vÃ  cÃ¢y chÆ°a trÆ°á»Ÿng thÃ nh lÃ  Ä‘á»™ Ä‘áº­m nháº¡t cá»§a mÃ u Ä‘á» trÃªn cÃ¢y áº¡. Má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o kháº£ quan khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡","Dáº¡, em chÃ o máº¥y anh/chá»‹ áº¡. em Ä‘ang lÃ m vá» Ä‘á» tÃ i lÃ  nháº­n diá»‡n náº¥m linh chi Ä‘á» trÆ°á»Ÿng thÃ nh báº±ng camera. NhÆ°ng theo má»™t sá»‘ thÃ´ng tin em Ä‘á»c Ä‘Æ°á»£c thÃ¬ Ä‘iá»ƒm khÃ¡c nhau giá»¯a cÃ¢y trÆ°á»Ÿng thÃ nh vÃ  cÃ¢y chÆ°a trÆ°á»Ÿng thÃ nh lÃ  Ä‘á»™ Ä‘áº­m nháº¡t cá»§a mÃ u Ä‘á» trÃªn cÃ¢y áº¡. Má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o kháº£ quan khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,,,
"Hi cÃ¡c anh, chi,
Em Ä‘ang lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p Tháº¡c SÄ© ngÃ y CNTT, thÃ¡ng 10/2022 nÃ y em báº£o vá»‡ luáº­n vÄƒn tá»‘t nghiá»‡p, Em lÃ m Ä‘á» tÃ i ""Loan Repayment Prediction Using Machine Learning Algorithms"", Em thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u - Data preprocessing:    
a. TÃ¬m há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c thuá»™c tÃ­nh.    
b. Xá»­ lÃ½ cÃ¡c thuá»™c tÃ­nh dáº¡ng vÄƒn báº£n   
c. Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ bá»‹ thiáº¿u(Data Imputation - Missing Data Replacement)    
d. TÃ¡ch dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra    
e. Chuáº©n hÃ³a dá»¯ liá»‡u 
2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh:    
a. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng kiá»ƒm Ä‘á»‹nh chÃ©o    
b. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng ma tráº­n nháº§m láº«n      
 + Presision      
 + Recall       
+ F1-Score       
+ ÄÆ°á»ng cong ROC
--> Tuy nhiÃªn káº¿t quáº£ thÃ¬ cÅ©ng khÃ´ng tá»‘t láº¯m: Ä‘Ã¢y lÃ  káº¿t quáº£ cháº¡y thá»±c nghiá»‡m cá»§a em, Em xin Ã½ kiáº¿n vÃ  gÃ³p Ã½ cá»§a cÃ¡c anh, chá»‹, em xin cáº£m Æ¡n.
Em xin gá»­i link github database, code cá»§a em Ä‘Æ°á»£c khÃ´ng áº¡. anh chá»‹ vÃ o gÃ³p Ã½ kiáº¿n dÃ¹m em, em xin cáº£m Æ¡n.
Link: https://github.com/binhht7777/LuanVanTotNghiep","Hi cÃ¡c anh, chi, Em Ä‘ang lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p Tháº¡c SÄ© ngÃ y CNTT, thÃ¡ng 10/2022 nÃ y em báº£o vá»‡ luáº­n vÄƒn tá»‘t nghiá»‡p, Em lÃ m Ä‘á» tÃ i ""Loan Repayment Prediction Using Machine Learning Algorithms"", Em thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau: 1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u - Data preprocessing: a. TÃ¬m há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c thuá»™c tÃ­nh. b. Xá»­ lÃ½ cÃ¡c thuá»™c tÃ­nh dáº¡ng vÄƒn báº£n c. Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ bá»‹ thiáº¿u(Data Imputation - Missing Data Replacement) d. TÃ¡ch dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra e. Chuáº©n hÃ³a dá»¯ liá»‡u 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh: a. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng kiá»ƒm Ä‘á»‹nh chÃ©o b. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c báº±ng ma tráº­n nháº§m láº«n + Presision + Recall + F1-Score + ÄÆ°á»ng cong ROC --> Tuy nhiÃªn káº¿t quáº£ thÃ¬ cÅ©ng khÃ´ng tá»‘t láº¯m: Ä‘Ã¢y lÃ  káº¿t quáº£ cháº¡y thá»±c nghiá»‡m cá»§a em, Em xin Ã½ kiáº¿n vÃ  gÃ³p Ã½ cá»§a cÃ¡c anh, chá»‹, em xin cáº£m Æ¡n. Em xin gá»­i link github database, code cá»§a em Ä‘Æ°á»£c khÃ´ng áº¡. anh chá»‹ vÃ o gÃ³p Ã½ kiáº¿n dÃ¹m em, em xin cáº£m Æ¡n. Link: https://github.com/binhht7777/LuanVanTotNghiep",,,,,
"Xin chÃ o má»i ngÆ°á»i, Em cÃ³ má»™t vÃ i tháº¯c máº¯c vá» Speech Recognition muá»‘n tham kháº£o Ã½ kiáº¿n cá»§a má»i ngÆ°á»i.
Em Ä‘ang lÃ m project xá»­ lÃ½ tiáº¿ng nÃ³i Ä‘á»ƒ cho robotic chuyá»ƒn Ä‘á»™ng: bá»™ tá»« vá»±ng chá»‰ cÃ³ ""lÃªn, xuá»‘ng, trÃ¡i, pháº£i""
Em Ä‘Ã£ thu dá»¯ liá»‡u báº±ng cÃ¡c Ä‘oáº¡n file wav, trÃ­ch xuáº¥t 39 MFCCs cho má»—i sample ~ 1 tá»«. Tuy nhiÃªn em gáº·p 1 váº¥n Ä‘á» trong lÃºc phÃ¢n loáº¡i: em muá»‘n normalize toÃ n bá»™ cÃ¡c sample báº±ng Z-score tuy nhiÃªn cÃ¡c sample láº¡i cÃ³ shape ko giá»‘ng nhau: (39, 5); (39, 10); (39, 8); (39, 25);... Khiáº¿n em chÆ°a nghÄ© ra phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ normalize Ä‘Æ°á»£c cÃ¡c sample.
Em Ä‘Ã£ thá»­ concatenate cÃ¡c sample theo chiá»u ngang Ä‘á»ƒ thÃ nh 1 tabulet to Ä‘Ã¹ng shape (39, D) rá»“i normalize nhÆ°ng láº¡i cho káº¿t quáº£ phÃ¢n lá»›p vÃ´ cÃ¹ng tá»‡ háº¡i. Em Ä‘Ã£ thá»­ truncate táº¥t cáº£ vá» (39, 5) rá»“i flattened Ä‘á»ƒ normalize vÃ  Ã¡p dá»¥ng DTW thu Ä‘Æ°á»£c 0.84 accuracy (dataset cá»§a em lÃ  balance)
Em muá»‘n há»i lÃ  náº¿u ko truncate vá» sample size bÃ© nháº¥t thÃ¬ cÃ²n cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ normalize toÃ n bá»™ cÃ¡c sample khÃ´ng?
VÃ  em cÅ©ng cÃ³ 1 váº¥n Ä‘á» ná»¯a lÃ  náº¿u signal input khÃ´ng thuá»™c cÃ¡c class label trong train set thÃ¬ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ handle vÃ  bá» qua nÃ³? Liá»‡u em cÃ³ pháº£i dá»±ng 1 threehold vá» distance trong khi DTW Ä‘á»ƒ handle, hay em nÃªn tÃ­nh correlation giá»¯a input vÃ  cÃ¡c sample trong trainset trÆ°á»›c rá»“i má»›i sá»­ dá»¥ng DTW?
Em xin cÃ¡m Æ¡n má»i sá»± giáº£i Ä‘Ã¡p áº¡.","Xin chÃ o má»i ngÆ°á»i, Em cÃ³ má»™t vÃ i tháº¯c máº¯c vá» Speech Recognition muá»‘n tham kháº£o Ã½ kiáº¿n cá»§a má»i ngÆ°á»i. Em Ä‘ang lÃ m project xá»­ lÃ½ tiáº¿ng nÃ³i Ä‘á»ƒ cho robotic chuyá»ƒn Ä‘á»™ng: bá»™ tá»« vá»±ng chá»‰ cÃ³ ""lÃªn, xuá»‘ng, trÃ¡i, pháº£i"" Em Ä‘Ã£ thu dá»¯ liá»‡u báº±ng cÃ¡c Ä‘oáº¡n file wav, trÃ­ch xuáº¥t 39 MFCCs cho má»—i sample ~ 1 tá»«. Tuy nhiÃªn em gáº·p 1 váº¥n Ä‘á» trong lÃºc phÃ¢n loáº¡i: em muá»‘n normalize toÃ n bá»™ cÃ¡c sample báº±ng Z-score tuy nhiÃªn cÃ¡c sample láº¡i cÃ³ shape ko giá»‘ng nhau: (39, 5); (39, 10); (39, 8); (39, 25);... Khiáº¿n em chÆ°a nghÄ© ra phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ normalize Ä‘Æ°á»£c cÃ¡c sample. Em Ä‘Ã£ thá»­ concatenate cÃ¡c sample theo chiá»u ngang Ä‘á»ƒ thÃ nh 1 tabulet to Ä‘Ã¹ng shape (39, D) rá»“i normalize nhÆ°ng láº¡i cho káº¿t quáº£ phÃ¢n lá»›p vÃ´ cÃ¹ng tá»‡ háº¡i. Em Ä‘Ã£ thá»­ truncate táº¥t cáº£ vá» (39, 5) rá»“i flattened Ä‘á»ƒ normalize vÃ  Ã¡p dá»¥ng DTW thu Ä‘Æ°á»£c 0.84 accuracy (dataset cá»§a em lÃ  balance) Em muá»‘n há»i lÃ  náº¿u ko truncate vá» sample size bÃ© nháº¥t thÃ¬ cÃ²n cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ normalize toÃ n bá»™ cÃ¡c sample khÃ´ng? VÃ  em cÅ©ng cÃ³ 1 váº¥n Ä‘á» ná»¯a lÃ  náº¿u signal input khÃ´ng thuá»™c cÃ¡c class label trong train set thÃ¬ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ handle vÃ  bá» qua nÃ³? Liá»‡u em cÃ³ pháº£i dá»±ng 1 threehold vá» distance trong khi DTW Ä‘á»ƒ handle, hay em nÃªn tÃ­nh correlation giá»¯a input vÃ  cÃ¡c sample trong trainset trÆ°á»›c rá»“i má»›i sá»­ dá»¥ng DTW? Em xin cÃ¡m Æ¡n má»i sá»± giáº£i Ä‘Ã¡p áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i, sau má»™t thá»i gian dÃ i triá»ƒn khai cÃ¡c á»©ng dá»¥ng ML/DL lÃ m mÃ¬nh quÃªn Ä‘i má»™t sá»‘ lÃ½ thuyáº¿t cÆ¡ báº£n. HÃ´m nay ráº£nh rang ngá»“i Ä‘á»c láº¡i bÃ i note ngÃ y xÆ°a khi tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc transformer tháº¥y khÃ¡ há»¯u Ã­ch nÃªn Ä‘Äƒng láº¡i trÃªn viblo vÃ  chia sáº» cho má»i ngÆ°á»i.
Anh em lÃ m á»©ng dá»¥ng nhiá»u thi thoáº£ng cÅ©ng Ã´n luyá»‡n láº¡i chÃºt káº»o quÃªn háº¿t nhÃ© =)))","ChÃ o má»i ngÆ°á»i, sau má»™t thá»i gian dÃ i triá»ƒn khai cÃ¡c á»©ng dá»¥ng ML/DL lÃ m mÃ¬nh quÃªn Ä‘i má»™t sá»‘ lÃ½ thuyáº¿t cÆ¡ báº£n. HÃ´m nay ráº£nh rang ngá»“i Ä‘á»c láº¡i bÃ i note ngÃ y xÆ°a khi tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc transformer tháº¥y khÃ¡ há»¯u Ã­ch nÃªn Ä‘Äƒng láº¡i trÃªn viblo vÃ  chia sáº» cho má»i ngÆ°á»i. Anh em lÃ m á»©ng dá»¥ng nhiá»u thi thoáº£ng cÅ©ng Ã´n luyá»‡n láº¡i chÃºt káº»o quÃªn háº¿t nhÃ© =)))",,,,,
Má»i ngÆ°á»i ai cÃ³ nguá»“n video cÃ¡ trÃªn bÄƒng chuyá»n kiá»ƒu nÃ y khÃ´ng cho em xin vá»›i . Em cáº£m Æ¡n áº¡.,Má»i ngÆ°á»i ai cÃ³ nguá»“n video cÃ¡ trÃªn bÄƒng chuyá»n kiá»ƒu nÃ y khÃ´ng cho em xin vá»›i . Em cáº£m Æ¡n áº¡.,,,,,
"MÃ¡y mÃ³c cÃ³ thá»ƒ suy nghÄ© nhÆ° con ngÆ°á»i Ä‘Æ°á»£c khÃ´ng?
NhÃ  triáº¿t há»c Aristotle (384-322 TCN) Ä‘Ã£ phÃ¡t minh ra thuyáº¿t Ã¢m tiáº¿t (má»™t quÃ¡ trÃ¬nh logic trong Ä‘Ã³ hai phÃ¡t biá»ƒu chung dáº«n Ä‘áº¿n má»™t phÃ¡t biá»ƒu cá»¥ thá»ƒ hÆ¡n) lÃ m ná»n táº£ng cho lÃ½ luáº­n vÃ  tÆ° duy. NghÄ©a lÃ  theo quan Ä‘iá»ƒm hiá»‡n táº¡i, chÃºng ta cÃ³ thá»ƒ cÃ´ng thá»©c hÃ³a tÆ° duy cá»§a con ngÆ°á»i.
Tá»« Ä‘Ã³, máº¡ng nÆ¡-ron Ä‘Æ°á»£c sinh ra Ä‘á»ƒ mÃ´ táº£ láº¡i há»‡ thá»‘ng nÃ£o bá»™ cá»§a con ngÆ°á»i, nÃ³ giÃºp mÃ¡y tÃ­nh cÃ³ thá»ƒ cÃ³ cÃ¡ch tÆ° duy giá»‘ng vá»›i con ngÆ°á»i.
Trong pháº§n cuá»‘i cá»§a series vá» lÃ½ thuyáº¿t toÃ¡n dÃ nh cho Machine Learning, chÃºng ta sáº½ tÃ¬m hiá»ƒu vá» há»c sÃ¢u, vÃ  cÃ¡c bÆ°á»›c tiáº¿n cá»§a viá»‡c Ä‘áº¡i sá»‘ hÃ³a suy nghÄ© cá»§a con ngÆ°á»i.","MÃ¡y mÃ³c cÃ³ thá»ƒ suy nghÄ© nhÆ° con ngÆ°á»i Ä‘Æ°á»£c khÃ´ng? NhÃ  triáº¿t há»c Aristotle (384-322 TCN) Ä‘Ã£ phÃ¡t minh ra thuyáº¿t Ã¢m tiáº¿t (má»™t quÃ¡ trÃ¬nh logic trong Ä‘Ã³ hai phÃ¡t biá»ƒu chung dáº«n Ä‘áº¿n má»™t phÃ¡t biá»ƒu cá»¥ thá»ƒ hÆ¡n) lÃ m ná»n táº£ng cho lÃ½ luáº­n vÃ  tÆ° duy. NghÄ©a lÃ  theo quan Ä‘iá»ƒm hiá»‡n táº¡i, chÃºng ta cÃ³ thá»ƒ cÃ´ng thá»©c hÃ³a tÆ° duy cá»§a con ngÆ°á»i. Tá»« Ä‘Ã³, máº¡ng nÆ¡-ron Ä‘Æ°á»£c sinh ra Ä‘á»ƒ mÃ´ táº£ láº¡i há»‡ thá»‘ng nÃ£o bá»™ cá»§a con ngÆ°á»i, nÃ³ giÃºp mÃ¡y tÃ­nh cÃ³ thá»ƒ cÃ³ cÃ¡ch tÆ° duy giá»‘ng vá»›i con ngÆ°á»i. Trong pháº§n cuá»‘i cá»§a series vá» lÃ½ thuyáº¿t toÃ¡n dÃ nh cho Machine Learning, chÃºng ta sáº½ tÃ¬m hiá»ƒu vá» há»c sÃ¢u, vÃ  cÃ¡c bÆ°á»›c tiáº¿n cá»§a viá»‡c Ä‘áº¡i sá»‘ hÃ³a suy nghÄ© cá»§a con ngÆ°á»i.",,,,,
"BÃªn MLOps VN cÃ³ share 1 link vá» cÃ¡ch tÃ­nh AUC-ROC khi chÆ°a cÃ³ ground truth, mÃ¬nh xin share láº¡i 
https://towardsdatascience.com/predict-your-models-performance-without-waiting-for-the-control-group-3f5c9363a7da","BÃªn MLOps VN cÃ³ share 1 link vá» cÃ¡ch tÃ­nh AUC-ROC khi chÆ°a cÃ³ ground truth, mÃ¬nh xin share láº¡i https://towardsdatascience.com/predict-your-models-performance-without-waiting-for-the-control-group-3f5c9363a7da",,,,,
"[Vietnam stock bid/ask recommender system ]
â˜‘ï¸ The stock market is always uncertain, volatile, and risky but also brings opportunities to investors. Depending on two main approaches fundamental analysis and technical analysis, the investors can make evaluations, movement laws, and trends in order to release timely buy and sell.
â˜‘ï¸ Fundamental analysis usually relies on an analystâ€™s subjective thoughts. Therefore, its decisions are not consistent but majorly depended on each expert. Whereas, an AI model can draw a very consistent conclusion based on the rules learned from big data. Currently, technical analysis is mainly based on pattern recognition on the technical charts. The application of AI models in technical analysis is not comprehensive and effective whereas the AI model strength is gradually demonstrated through their drastic development today.
â˜‘ï¸ Therefore, the main target of this competition â€œVietnam stock bid/ask recommender systemâ€ is to construct a recommender model, which recommends up and down sessions for investors on a portfolio of 30 encoded symbols in the Vietnam stock market. AI models take advantage of drawing rules from big data, having strong feature transformation via multi-layers deep learning architectures, and owning black box characteristics that cannot be explained by humans. That is why the application of the AI model in trading has proven its effectiveness in advanced markets like the USA, EU, Japan, etc.
â˜‘ï¸ In this contest, you are provided with a set of data, which is extracted from the vnquant package, including those important stock information: price, transaction volume; financial report, business report, and cashflow report. The price and volume data are organized according to time series with daily frequency whereas quarterly frequency for corporate reports.
â˜‘ï¸ Letâ€™s use the potential Deep Learning architectures trained in provided tabular datasets to support the investor in forecasting the increasing/decreasing stocks session on the Vietnam stock market.
â˜‘ï¸ Contest information:
- Overview: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/overview
- Data: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/data
- Rule: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/rules
- Sample code: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/code","[Vietnam stock bid/ask recommender system ] The stock market is always uncertain, volatile, and risky but also brings opportunities to investors. Depending on two main approaches fundamental analysis and technical analysis, the investors can make evaluations, movement laws, and trends in order to release timely buy and sell. Fundamental analysis usually relies on an analystâ€™s subjective thoughts. Therefore, its decisions are not consistent but majorly depended on each expert. Whereas, an AI model can draw a very consistent conclusion based on the rules learned from big data. Currently, technical analysis is mainly based on pattern recognition on the technical charts. The application of AI models in technical analysis is not comprehensive and effective whereas the AI model strength is gradually demonstrated through their drastic development today. Therefore, the main target of this competition â€œVietnam stock bid/ask recommender systemâ€ is to construct a recommender model, which recommends up and down sessions for investors on a portfolio of 30 encoded symbols in the Vietnam stock market. AI models take advantage of drawing rules from big data, having strong feature transformation via multi-layers deep learning architectures, and owning black box characteristics that cannot be explained by humans. That is why the application of the AI model in trading has proven its effectiveness in advanced markets like the USA, EU, Japan, etc. In this contest, you are provided with a set of data, which is extracted from the vnquant package, including those important stock information: price, transaction volume; financial report, business report, and cashflow report. The price and volume data are organized according to time series with daily frequency whereas quarterly frequency for corporate reports. Letâ€™s use the potential Deep Learning architectures trained in provided tabular datasets to support the investor in forecasting the increasing/decreasing stocks session on the Vietnam stock market. Contest information: - Overview: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/overview - Data: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/data - Rule: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/rules - Sample code: https://www.kaggle.com/competitions/vietnam-stock-bidask-recommender-system/code",,,,,
"ÄÃ¢y lÃ  link tá»›i bÃ i lÃºc trÆ°á»›c mÃ¬nh xoÃ¡ vÃ¬ tÆ°á»Ÿng lÃ  bÃ¡n kem trá»™n.
VÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³ mÃ  báº¡n tÃ¡c giáº£ khÃ´ng post bÃ i Ä‘Æ°á»£c ná»¯a nÃªn mÃ¬nh post giÃºp.
https://hieuphung97.com/danh-gia-tham-my-anh-cung-tri-tue-nhan-tao.html?fbclid=IwAR3r2NGiKI7bVjARD8KaJVRyLc7avlZ2KwLMewc58HOJNS96wG6nog1rqMU",ÄÃ¢y lÃ  link tá»›i bÃ i lÃºc trÆ°á»›c mÃ¬nh xoÃ¡ vÃ¬ tÆ°á»Ÿng lÃ  bÃ¡n kem trá»™n. VÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³ mÃ  báº¡n tÃ¡c giáº£ khÃ´ng post bÃ i Ä‘Æ°á»£c ná»¯a nÃªn mÃ¬nh post giÃºp. https://hieuphung97.com/danh-gia-tham-my-anh-cung-tri-tue-nhan-tao.html?fbclid=IwAR3r2NGiKI7bVjARD8KaJVRyLc7avlZ2KwLMewc58HOJNS96wG6nog1rqMU,,,,,
"Hi cáº£ nhÃ , em xin Ä‘Ã³ng gÃ³p má»™t bÃ i viáº¿t nhá» vá» cÃ¡ch serve 1 model dÃ¹ng FastAPI vÃ  Kubernetes (k8s), hy vá»ng cÃ³ Ã­ch cho má»i ngÆ°á»i :D
https://quan-dang.github.io/2022/05/19/deploy-model-fastapi-k8s/
NhÃ¢n tiá»‡n em láº¡i xin phÃ©p Ä‘Æ°á»£c PR cho group MLOps VN (https://www.facebook.com/groups/mlopsvn) dÃ nh cho má»i ngÆ°á»i quan tÃ¢m tá»›i ML Engineering/MLOps nha :v","Hi cáº£ nhÃ , em xin Ä‘Ã³ng gÃ³p má»™t bÃ i viáº¿t nhá» vá» cÃ¡ch serve 1 model dÃ¹ng FastAPI vÃ  Kubernetes (k8s), hy vá»ng cÃ³ Ã­ch cho má»i ngÆ°á»i :D https://quan-dang.github.io/2022/05/19/deploy-model-fastapi-k8s/ NhÃ¢n tiá»‡n em láº¡i xin phÃ©p Ä‘Æ°á»£c PR cho group MLOps VN (https://www.facebook.com/groups/mlopsvn) dÃ nh cho má»i ngÆ°á»i quan tÃ¢m tá»›i ML Engineering/MLOps nha :v",,,,,
"Dáº¡ cho em há»i lÃ  nhÃ³m mÃ¬nh cÃ³ ai lÃ m vá» Bioelectrical Impedance Analysis (BIA) chÆ°a áº¡ vÃ  mÃ¬nh cÃ³ thá»ƒ kiáº¿m data á»Ÿ Ä‘Ã¢u áº¡, em cÃ¡m Æ¡n áº¡.","Dáº¡ cho em há»i lÃ  nhÃ³m mÃ¬nh cÃ³ ai lÃ m vá» Bioelectrical Impedance Analysis (BIA) chÆ°a áº¡ vÃ  mÃ¬nh cÃ³ thá»ƒ kiáº¿m data á»Ÿ Ä‘Ã¢u áº¡, em cÃ¡m Æ¡n áº¡.",,,,,
"Cuá»‘n Thá»±c hÃ nh há»c mÃ¡y tiáº¿p tá»¥c bá»‹ vi pháº¡m báº£n quyá»n. Báº£n nÃ y Ä‘Æ°á»£c shared trÃªn SCRIBD, hiá»‡n Ä‘Ã£ bá»‹ gá»¡ sau khi nháº­n Ä‘Æ°á»£c report tá»« team dá»‹ch.
Cáº£m Æ¡n má»™t báº¡n Ä‘á»c (mÃ¬nh khÃ´ng nÃªu tÃªn vÃ¬ chÆ°a xin Ã½ kiáº¿n) Ä‘Ã£ thÃ´ng bÃ¡o vá»›i nhÃ³m Ä‘á»ƒ cÃ³ hÃ nh Ä‘á»™ng ká»‹p thá»i.","Cuá»‘n Thá»±c hÃ nh há»c mÃ¡y tiáº¿p tá»¥c bá»‹ vi pháº¡m báº£n quyá»n. Báº£n nÃ y Ä‘Æ°á»£c shared trÃªn SCRIBD, hiá»‡n Ä‘Ã£ bá»‹ gá»¡ sau khi nháº­n Ä‘Æ°á»£c report tá»« team dá»‹ch. Cáº£m Æ¡n má»™t báº¡n Ä‘á»c (mÃ¬nh khÃ´ng nÃªu tÃªn vÃ¬ chÆ°a xin Ã½ kiáº¿n) Ä‘Ã£ thÃ´ng bÃ¡o vá»›i nhÃ³m Ä‘á»ƒ cÃ³ hÃ nh Ä‘á»™ng ká»‹p thá»i.",,,,,
"Vá»«a rá»“i cÃ³ má»™t post Ä‘Äƒng áº£nh má»™t em gÃ¡i xinh vÃ  tiÃªu Ä‘á» cÃ³ gÃ¬ Ä‘Ã³ liÃªn quan Ä‘áº¿n tháº©m má»¹. MÃ¬nh tay nhanh hÆ¡n máº¯t Ä‘Ã£ block báº¡n tÃ¡c giáº£. Sau Ä‘Ã³ má»›i nháº­n ra lÃ  bÃ i Ä‘Ã³ nÃ³i vá» dÃ¹ng AI Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ tháº©m má»¹ cá»§a áº£nh thÃ¬ Ä‘Ã£ quÃ¡ muá»™n. Táº¡i gáº§n Ä‘Ã¢y nhiá»u post spam quÃ¡ mÃ¬nh quen tay.
Náº¿u báº¡n tÃ¡c giáº£ (Ä‘Ã£ bá»‹ block) báº±ng má»™t cÃ¡ch nÃ o Ä‘Ã³ nhÃ¬n tháº¥y post nÃ y thÃ¬ cho mÃ¬nh xin lá»—i nhÃ©. Báº¡n cÃ³ thá»ƒ connect qua DM Ä‘á»ƒ mÃ¬nh add láº¡i vÃ o group.",Vá»«a rá»“i cÃ³ má»™t post Ä‘Äƒng áº£nh má»™t em gÃ¡i xinh vÃ  tiÃªu Ä‘á» cÃ³ gÃ¬ Ä‘Ã³ liÃªn quan Ä‘áº¿n tháº©m má»¹. MÃ¬nh tay nhanh hÆ¡n máº¯t Ä‘Ã£ block báº¡n tÃ¡c giáº£. Sau Ä‘Ã³ má»›i nháº­n ra lÃ  bÃ i Ä‘Ã³ nÃ³i vá» dÃ¹ng AI Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ tháº©m má»¹ cá»§a áº£nh thÃ¬ Ä‘Ã£ quÃ¡ muá»™n. Táº¡i gáº§n Ä‘Ã¢y nhiá»u post spam quÃ¡ mÃ¬nh quen tay. Náº¿u báº¡n tÃ¡c giáº£ (Ä‘Ã£ bá»‹ block) báº±ng má»™t cÃ¡ch nÃ o Ä‘Ã³ nhÃ¬n tháº¥y post nÃ y thÃ¬ cho mÃ¬nh xin lá»—i nhÃ©. Báº¡n cÃ³ thá»ƒ connect qua DM Ä‘á»ƒ mÃ¬nh add láº¡i vÃ o group.,,,,,
"#ETL #MLOPs
Hi All,
MÃ¬nh cÃ³ lÃ m video vá» ETL/MLOPs sá»­ dá»¥ng thÆ° viá»‡n Perfect trong Python.
ThÆ° viá»‡n nÃ y giÃºp viá»‡c ETL má»™t cÃ¡ch tá»± Ä‘á»™ng, chuyÃªn nghiá»‡p hÆ¡n. Cá»¥ thá»ƒ thÃ¬ mÃ¬nh Ä‘Ã£ demo trong video.
Má»i ngÆ°á»i xem qua cho em gÃ³p Ã½ cÅ©ng nhÆ° cÃ³ Tools nÃ o hay hÆ¡n khÃ´ng áº¡. Theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ ngoÃ i Perfect thÃ¬ cÃ²n cÃ³ thÆ° viá»‡n Airflow ná»¯a.
Mong Ä‘Æ°á»£c admin duyá»‡t bÃ i áº¡!
Thanks All!","Hi All, MÃ¬nh cÃ³ lÃ m video vá» ETL/MLOPs sá»­ dá»¥ng thÆ° viá»‡n Perfect trong Python. ThÆ° viá»‡n nÃ y giÃºp viá»‡c ETL má»™t cÃ¡ch tá»± Ä‘á»™ng, chuyÃªn nghiá»‡p hÆ¡n. Cá»¥ thá»ƒ thÃ¬ mÃ¬nh Ä‘Ã£ demo trong video. Má»i ngÆ°á»i xem qua cho em gÃ³p Ã½ cÅ©ng nhÆ° cÃ³ Tools nÃ o hay hÆ¡n khÃ´ng áº¡. Theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ ngoÃ i Perfect thÃ¬ cÃ²n cÃ³ thÆ° viá»‡n Airflow ná»¯a. Mong Ä‘Æ°á»£c admin duyá»‡t bÃ i áº¡! Thanks All!",#ETL	#MLOPs,,,,
Má»i cÃ¡c báº¡n theo dÃµi pháº§n tiáº¿p theo cá»§a series cÆ¡ sá»Ÿ toÃ¡n há»c cho Machine Learning.,Má»i cÃ¡c báº¡n theo dÃµi pháº§n tiáº¿p theo cá»§a series cÆ¡ sá»Ÿ toÃ¡n há»c cho Machine Learning.,,,,,
Má»i ngÆ°á»i cho em há»i em Ä‘Ã£ cÃ i opencv Cuda rá»“i nhÆ°ng khi cháº¡y code yolov4 thÃ¬ nÃ³ chuyá»ƒn sang CPU thÃ¬ cÃ³ cÃ¡c nÃ o kháº¯c phá»¥c khÃ´ng áº¡. Em cháº¡y trÃªn jetson xavier,Má»i ngÆ°á»i cho em há»i em Ä‘Ã£ cÃ i opencv Cuda rá»“i nhÆ°ng khi cháº¡y code yolov4 thÃ¬ nÃ³ chuyá»ƒn sang CPU thÃ¬ cÃ³ cÃ¡c nÃ o kháº¯c phá»¥c khÃ´ng áº¡. Em cháº¡y trÃªn jetson xavier,,,,,
"Xin chÃ o má»i ngÆ°á»i,
Do nhiá»u báº¡n há»i mÃ¬nh vá» liá»‡u lá»›p cÃ³ TA Ä‘á»ƒ há»— trá»£ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» cÃ¡c bÃ i giáº£ng vÃ  tháº­m chÃ­ lÃ  bÃ i táº­p (náº¿u cÃ³) cho 2 há»c pháº§n ""Introduction to (Machine Learning) ML vÃ  (Data Science) DS"" vÃ  ""Advanced ML vÃ  DS"" (xem thÃªm thÃ´ng tin cÃ¡c lá»›p nÃ y á»Ÿ Ä‘Ã¢y: https://www.facebook.com/groups/machinelearningcoban/posts/1472717289852340/), thÃ¬ mÃ¬nh cÅ©ng muá»‘n cáº­p nháº­t danh sÃ¡ch TA hiá»‡n táº¡i cho cÃ¡c lá»›p nÃ y.
********** Danh sÃ¡ch cÃ¡c báº¡n TA hiá»‡n táº¡i (sáº½ liÃªn tá»¥c Ä‘Æ°á»£c cáº­p nháº­t thÃªm):
--- LÃª Quang DÅ©ng (Huy ChÆ°Æ¡ng VÃ ng ToÃ¡n Quá»‘c Táº¿ (IMO); Thá»§ Khoa Äáº¡i Há»c Khoa Há»c Tá»± NhiÃªn HÃ  Ná»™i)
--- Nguyá»…n Tuáº¥n Háº£i ÄÄƒng (Huy ChÆ°Æ¡ng Báº¡c ToÃ¡n Quá»‘c Táº¿ (IMO); Thá»§ Khoa ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin táº¡i trÆ°á»ng Äáº¡i Há»c á»Ÿ Tokyo)
--- Nguyá»…n Minh Huy (Thá»§ Khoa toÃ n trÆ°á»ng Äáº¡i Há»c Khoa Há»c Tá»± NhiÃªn ThÃ nh Phá»‘ Há»“ ChÃ­ Minh; Äiá»ƒm GPA cÃ³ thá»ƒ coi cao nháº¥t trong lá»‹ch sá»­ thÃ nh láº­p cá»§a trÆ°á»ng)
--- VÅ© LÃª Tháº¿ Anh (Thá»§ Khoa ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin trÆ°á»ng Äáº¡i Há»c Khoa Há»c Tá»± NhiÃªn ThÃ nh Phá»‘ Há»“ ChÃ­ Minh)","Xin chÃ o má»i ngÆ°á»i, Do nhiá»u báº¡n há»i mÃ¬nh vá» liá»‡u lá»›p cÃ³ TA Ä‘á»ƒ há»— trá»£ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» cÃ¡c bÃ i giáº£ng vÃ  tháº­m chÃ­ lÃ  bÃ i táº­p (náº¿u cÃ³) cho 2 há»c pháº§n ""Introduction to (Machine Learning) ML vÃ  (Data Science) DS"" vÃ  ""Advanced ML vÃ  DS"" (xem thÃªm thÃ´ng tin cÃ¡c lá»›p nÃ y á»Ÿ Ä‘Ã¢y: https://www.facebook.com/groups/machinelearningcoban/posts/1472717289852340/), thÃ¬ mÃ¬nh cÅ©ng muá»‘n cáº­p nháº­t danh sÃ¡ch TA hiá»‡n táº¡i cho cÃ¡c lá»›p nÃ y. ********** Danh sÃ¡ch cÃ¡c báº¡n TA hiá»‡n táº¡i (sáº½ liÃªn tá»¥c Ä‘Æ°á»£c cáº­p nháº­t thÃªm): --- LÃª Quang DÅ©ng (Huy ChÆ°Æ¡ng VÃ ng ToÃ¡n Quá»‘c Táº¿ (IMO); Thá»§ Khoa Äáº¡i Há»c Khoa Há»c Tá»± NhiÃªn HÃ  Ná»™i) --- Nguyá»…n Tuáº¥n Háº£i ÄÄƒng (Huy ChÆ°Æ¡ng Báº¡c ToÃ¡n Quá»‘c Táº¿ (IMO); Thá»§ Khoa ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin táº¡i trÆ°á»ng Äáº¡i Há»c á»Ÿ Tokyo) --- Nguyá»…n Minh Huy (Thá»§ Khoa toÃ n trÆ°á»ng Äáº¡i Há»c Khoa Há»c Tá»± NhiÃªn ThÃ nh Phá»‘ Há»“ ChÃ­ Minh; Äiá»ƒm GPA cÃ³ thá»ƒ coi cao nháº¥t trong lá»‹ch sá»­ thÃ nh láº­p cá»§a trÆ°á»ng) --- VÅ© LÃª Tháº¿ Anh (Thá»§ Khoa ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin trÆ°á»ng Äáº¡i Há»c Khoa Há»c Tá»± NhiÃªn ThÃ nh Phá»‘ Há»“ ChÃ­ Minh)",,,,,
"Sau má»™t thá»i gian dÃ i nghiÃªn cá»©u vÃ  há»c há»i thÃ¬ cÃ¡c báº¡n há»c viÃªn cá»§a tá»› Ä‘Ã£ cho ra Ä‘á»i má»™t á»©ng dá»¥ng AI giÃºp Ä‘Ã¡nh giÃ¡ hÃ m lÆ°á»£ng dinh dÆ°á»¡ng bá»¯a Äƒn. Hi vá»ng sáº½ giÃºp Ã­ch cho cá»™ng Ä‘á»“ng mÃ¬nh, Ä‘áº·c biá»‡t lÃ  nhá»¯ng ai Ä‘ang quan tÃ¢m tá»›i váº¥n Ä‘á» chÄƒm sÃ³c sá»©c khá»e vÃ  Äƒn uá»‘ng. Sáº£n pháº©m Ä‘áº§u tay cÃ²n nhiá»u khÃ³ khÄƒn, bá»¡ ngá»¡. Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n Ä‘Ã¡nh giÃ¡ tá»« cÃ¡c báº¡n Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n. VÃ  Ä‘áº·c biá»‡t chÃºng tá»› cÅ©ng muá»‘n nháº­n Ä‘Æ°á»£c sá»± Ä‘áº§u tÆ° vÃ  há»£p tÃ¡c Ä‘á»ƒ phÃ¡t triá»ƒn sáº£n pháº©m nÃ y.","Sau má»™t thá»i gian dÃ i nghiÃªn cá»©u vÃ  há»c há»i thÃ¬ cÃ¡c báº¡n há»c viÃªn cá»§a tá»› Ä‘Ã£ cho ra Ä‘á»i má»™t á»©ng dá»¥ng AI giÃºp Ä‘Ã¡nh giÃ¡ hÃ m lÆ°á»£ng dinh dÆ°á»¡ng bá»¯a Äƒn. Hi vá»ng sáº½ giÃºp Ã­ch cho cá»™ng Ä‘á»“ng mÃ¬nh, Ä‘áº·c biá»‡t lÃ  nhá»¯ng ai Ä‘ang quan tÃ¢m tá»›i váº¥n Ä‘á» chÄƒm sÃ³c sá»©c khá»e vÃ  Äƒn uá»‘ng. Sáº£n pháº©m Ä‘áº§u tay cÃ²n nhiá»u khÃ³ khÄƒn, bá»¡ ngá»¡. Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n Ä‘Ã¡nh giÃ¡ tá»« cÃ¡c báº¡n Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n. VÃ  Ä‘áº·c biá»‡t chÃºng tá»› cÅ©ng muá»‘n nháº­n Ä‘Æ°á»£c sá»± Ä‘áº§u tÆ° vÃ  há»£p tÃ¡c Ä‘á»ƒ phÃ¡t triá»ƒn sáº£n pháº©m nÃ y.",,,,,
"ChÃ o anh, chá»‹,
Láº¡i lÃ  em Ä‘Ã¢y, em lÃ m Ä‘á» tÃ i ""Loan Repayment Prediction Using Machine Learning Algorithms"", sau khi em táº£i táº­p dá»¯ liá»‡u khÃ¡c trÃªn Lending.club, táº­p dá»¯ liá»‡u cÃ³ 21,968 record thÃ¬ cÃ¡c mÃ´ hÃ¬nh cá»§a em cháº¡y ra káº¿t quáº£ cÅ©ng khÃ¡ tá»‘t áº¡, cÃ¡ch Ä‘Ã¢y máº¥y ngÃ y thÃ¬ káº¿t quáº£ khÃ´ng tá»‘t, cháº¯c lÃ  do táº­p dá»¯ liá»‡u cÅ© khÃ´ng Ä‘á»§ tá»‘t Ä‘á»ƒ huáº¥n luyá»‡n, em cáº£m Æ¡n anh, chá»‹ nhiá»u.
ROC:","ChÃ o anh, chá»‹, Láº¡i lÃ  em Ä‘Ã¢y, em lÃ m Ä‘á» tÃ i ""Loan Repayment Prediction Using Machine Learning Algorithms"", sau khi em táº£i táº­p dá»¯ liá»‡u khÃ¡c trÃªn Lending.club, táº­p dá»¯ liá»‡u cÃ³ 21,968 record thÃ¬ cÃ¡c mÃ´ hÃ¬nh cá»§a em cháº¡y ra káº¿t quáº£ cÅ©ng khÃ¡ tá»‘t áº¡, cÃ¡ch Ä‘Ã¢y máº¥y ngÃ y thÃ¬ káº¿t quáº£ khÃ´ng tá»‘t, cháº¯c lÃ  do táº­p dá»¯ liá»‡u cÅ© khÃ´ng Ä‘á»§ tá»‘t Ä‘á»ƒ huáº¥n luyá»‡n, em cáº£m Æ¡n anh, chá»‹ nhiá»u. ROC:",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i e má»›i táº­p tÃ nh vá» phÃ¢n tÃ­ch dá»¯ liá»‡u, em cÃ³ má»™t cÃ¢u há»i mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡. ÄÃ³ lÃ  thÆ°á»ng trÆ°á»›c khi cho dá»¯ liá»‡u vÃ o mÃ´ hÃ¬nh thÃ¬ mÃ¬nh cáº§n bÆ°á»›c phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ lá»±a chá»n Ä‘áº·c trÆ°ng Ä‘Æ°a vÃ o mÃ´ hÃ¬nh ( giáº£ sá»­ vá»›i bÃ i toÃ¡n phÃ¢n loáº¡i thÃ¬ cáº§n xÃ¡c Ä‘á»‹nh xem giá»¯a cÃ¡c feature cá»§a cÃ¡c lá»›p thÃ¬ nÃ³ khÃ¡c nhau ntn). DO trÆ°á»›c giá» em chá»‰ quen phÃ¢n tÃ­ch tá»«ng feature riÃªng ráº½ nÃªn e mong mn ai cÃ³ kinh nghiá»‡m giáº£i Ä‘Ã¡p giÃºp e áº¡
Trong thá»±c tháº¿ ( giáº£ sá»­ mÃ¬nh Ä‘Ã£ hiá»ƒu business lÃ  cáº§n phÃ¢n tÃ­ch thuá»™c tÃ­nh nÃ o), thÃ¬ thá»±c táº¿ cÃ³ khÃ¡ nhiá»u thuá»™c tÃ­nh cáº§n phÃ¢n tÃ­ch ( giáº£ sá»­ 20 thuá»™c tÃ­nh cháº³ng háº¡n), thÃ¬ mÃ¬nh cÃ³ pp nÃ o Ä‘á»ƒ phÃ¢n tÃ­ch sá»± tÆ°Æ¡ng quan giá»¯a cÃ¡c biáº¿n ko áº¡. ( E cÃ³ nghe Ä‘áº¿n pair plot nhÆ°ng chá»‰ váº½ Ä‘c tÆ°Æ¡ng quan 2 biáº¿t, PCA nhÆ°ng e ko rÃµ mÃ¬nh sáº½ giáº£m vá» bao nhiÃªu chiá»u )
Dá»¯ liá»‡u á»Ÿ dáº¡ng cÃ¹ng má»™t feature nhÆ°ng biáº¿n Ä‘á»•i theo thÃ¡ng ( cÃ³ ráº¥t nhiá»u sample nhÆ° váº­y), thÃ¬ mÃ¬nh cÃ³ pp nÃ o phÃ¢n tÃ­ch hiá»‡u quáº£ ko áº¡, vÃ¬ váº½ time series lÃªn thÃ¬ cÃ³ hÃ ng ngÃ n sample thÃ¬ ko quan sÃ¡t Ä‘c )
3. Dá»¯ liá»‡u trong thá»±c táº¿ bá»‹ máº¥t cÃ¢n báº±ng ráº¥t nhiá»u thÃ¬ mÃ¬nh cÃ³ pp nÃ o Ä‘á»ƒ phÃ¢n tÃ­ch khÃ¡ch quan hÆ¡n ko áº¡ ( E cÃ³ tháº¥y sampling tá»« phÃ¢n phá»‘i cá»§a lá»›p nhiá»u sampe hÆ¡n Ä‘á»ƒ phÃ¢n tÃ­ch, nhÆ°ng e tháº¥y data tá»« lá»›p nhiá»u sample hÆ¡n láº¡i ko theo phÃ¢n phá»‘i chuáº©n thÃ¬ mÃ¬nh cÃ³ cÃ¡ch nÃ o ngoÃ i viá»‡c collect thÃªm data ko áº¡)
3. Anh chá»‹ nÃ o Ä‘ang lÃ m DA/Modelling cÃ³ thá»ƒ cho e xin Ã­t kinh nghiá»‡m/ lá»™ trÃ¬nh Ä‘á»ƒ Ä‘i Ä‘c xa trong ngÃ nh nÃ y Ä‘c ko áº¡.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i e má»›i táº­p tÃ nh vá» phÃ¢n tÃ­ch dá»¯ liá»‡u, em cÃ³ má»™t cÃ¢u há»i mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡. ÄÃ³ lÃ  thÆ°á»ng trÆ°á»›c khi cho dá»¯ liá»‡u vÃ o mÃ´ hÃ¬nh thÃ¬ mÃ¬nh cáº§n bÆ°á»›c phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ lá»±a chá»n Ä‘áº·c trÆ°ng Ä‘Æ°a vÃ o mÃ´ hÃ¬nh ( giáº£ sá»­ vá»›i bÃ i toÃ¡n phÃ¢n loáº¡i thÃ¬ cáº§n xÃ¡c Ä‘á»‹nh xem giá»¯a cÃ¡c feature cá»§a cÃ¡c lá»›p thÃ¬ nÃ³ khÃ¡c nhau ntn). DO trÆ°á»›c giá» em chá»‰ quen phÃ¢n tÃ­ch tá»«ng feature riÃªng ráº½ nÃªn e mong mn ai cÃ³ kinh nghiá»‡m giáº£i Ä‘Ã¡p giÃºp e áº¡ Trong thá»±c tháº¿ ( giáº£ sá»­ mÃ¬nh Ä‘Ã£ hiá»ƒu business lÃ  cáº§n phÃ¢n tÃ­ch thuá»™c tÃ­nh nÃ o), thÃ¬ thá»±c táº¿ cÃ³ khÃ¡ nhiá»u thuá»™c tÃ­nh cáº§n phÃ¢n tÃ­ch ( giáº£ sá»­ 20 thuá»™c tÃ­nh cháº³ng háº¡n), thÃ¬ mÃ¬nh cÃ³ pp nÃ o Ä‘á»ƒ phÃ¢n tÃ­ch sá»± tÆ°Æ¡ng quan giá»¯a cÃ¡c biáº¿n ko áº¡. ( E cÃ³ nghe Ä‘áº¿n pair plot nhÆ°ng chá»‰ váº½ Ä‘c tÆ°Æ¡ng quan 2 biáº¿t, PCA nhÆ°ng e ko rÃµ mÃ¬nh sáº½ giáº£m vá» bao nhiÃªu chiá»u ) Dá»¯ liá»‡u á»Ÿ dáº¡ng cÃ¹ng má»™t feature nhÆ°ng biáº¿n Ä‘á»•i theo thÃ¡ng ( cÃ³ ráº¥t nhiá»u sample nhÆ° váº­y), thÃ¬ mÃ¬nh cÃ³ pp nÃ o phÃ¢n tÃ­ch hiá»‡u quáº£ ko áº¡, vÃ¬ váº½ time series lÃªn thÃ¬ cÃ³ hÃ ng ngÃ n sample thÃ¬ ko quan sÃ¡t Ä‘c ) 3. Dá»¯ liá»‡u trong thá»±c táº¿ bá»‹ máº¥t cÃ¢n báº±ng ráº¥t nhiá»u thÃ¬ mÃ¬nh cÃ³ pp nÃ o Ä‘á»ƒ phÃ¢n tÃ­ch khÃ¡ch quan hÆ¡n ko áº¡ ( E cÃ³ tháº¥y sampling tá»« phÃ¢n phá»‘i cá»§a lá»›p nhiá»u sampe hÆ¡n Ä‘á»ƒ phÃ¢n tÃ­ch, nhÆ°ng e tháº¥y data tá»« lá»›p nhiá»u sample hÆ¡n láº¡i ko theo phÃ¢n phá»‘i chuáº©n thÃ¬ mÃ¬nh cÃ³ cÃ¡ch nÃ o ngoÃ i viá»‡c collect thÃªm data ko áº¡) 3. Anh chá»‹ nÃ o Ä‘ang lÃ m DA/Modelling cÃ³ thá»ƒ cho e xin Ã­t kinh nghiá»‡m/ lá»™ trÃ¬nh Ä‘á»ƒ Ä‘i Ä‘c xa trong ngÃ nh nÃ y Ä‘c ko áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m nháº­n dáº¡ng cÃ¡/tÃ´m sá»­ dá»¥ng YOLOv4 (AlexeyAB/darknet: YOLOv4 / Scaled-YOLOv4 / YOLO - Neural Networks for Object Detection (Windows and Linux version of Darknet ) (github.com))
Em thá»­ train 1 class cÃ¡ trÆ°á»›c vÃ  Ä‘Æ°á»£c káº¿t quáº£ sau khi train trÃªn táº­p valid (áº£nh 1) vÃ  táº­p test (áº£nh 2) gáº§n giá»‘ng nhau
TÆ°Æ¡ng tá»± vá»›i 1 class tÃ´m (káº¿t quáº£ trÃªn táº­p valid lÃ  áº£nh 3 vÃ  test lÃ  áº£nh 4)
NhÆ°ng khi gá»™p dataset cÃ¡ + tÃ´m Ä‘á»ƒ train 2 class khÃ¬ káº¿t quáº£ trÃªn táº­p valid (áº£nh 5) vÃ  táº­p test (áº£nh 6) chÃªnh lá»‡ch khÃ¡ nhiá»u.
Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin cÃ¡ch xá»­ lÃ½ trong trÆ°á»ng há»£p nÃ y Ä‘Æ°á»£c khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m nháº­n dáº¡ng cÃ¡/tÃ´m sá»­ dá»¥ng YOLOv4 (AlexeyAB/darknet: YOLOv4 / Scaled-YOLOv4 / YOLO - Neural Networks for Object Detection (Windows and Linux version of Darknet ) (github.com)) Em thá»­ train 1 class cÃ¡ trÆ°á»›c vÃ  Ä‘Æ°á»£c káº¿t quáº£ sau khi train trÃªn táº­p valid (áº£nh 1) vÃ  táº­p test (áº£nh 2) gáº§n giá»‘ng nhau TÆ°Æ¡ng tá»± vá»›i 1 class tÃ´m (káº¿t quáº£ trÃªn táº­p valid lÃ  áº£nh 3 vÃ  test lÃ  áº£nh 4) NhÆ°ng khi gá»™p dataset cÃ¡ + tÃ´m Ä‘á»ƒ train 2 class khÃ¬ káº¿t quáº£ trÃªn táº­p valid (áº£nh 5) vÃ  táº­p test (áº£nh 6) chÃªnh lá»‡ch khÃ¡ nhiá»u. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin cÃ¡ch xá»­ lÃ½ trong trÆ°á»ng há»£p nÃ y Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"#PhÃ¢n_tÃ­ch_thÃ nh_pháº§n_chÃ­nh
#pca
ChÃ o má»i ngÆ°á»i. Em cÃ³ chÃºt tháº¯c máº¯c vá» phÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh mong giáº£i phÃ¡p tá»« cÃ¡c anh chá»‹ áº¡.
Em cÃ³ dá»¯ liá»‡u gá»“m 1000 áº£nh vá» nháº­n dáº¡ng quáº§n Ã¡o. Má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c 28*28 (gray scale). Khi kÃ©o dÃ£n ra sáº½ lÃ  ma tráº­n (1000*784) .
Em dÃ¹ng phÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh giáº£m sá»‘ chiá»u tá»« 784 xuá»‘ng cÃ²n 2 chiá»u vÃ  trá»±c quan hÃ³a nÃ³ trong khÃ´ng gian 2d.
á» 2 áº£nh dÆ°á»›i chÃ­nh lÃ  Trá»±c quan hÃ³a vá»›i 2 chiá»u sau khi em phÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh.
- áº¢nh 1 : Láº¥y 2 chiá»u cuá»‘i cÃ¹ng
- áº¢nh 2 : Láº¥y 2 chiá»u Ä‘áº§u tiÃªn
- áº¢nh 3 : Code
á» Ä‘Ã¢y em cÃ³ 2 cÃ¢u há»i áº¡ .
Q1 :  NhÆ° code em viáº¿t á»Ÿ áº£nh 3 , sau khi dÃ¹ng thÆ° viá»‡n pca cá»§a sklearn thÃ¬ cÃ¡c chiá»u Ä‘Æ°á»£c xáº¿p theo thá»© tá»± chiá»u thá»ƒ hiá»‡n Ã­t dá»¯ liá»‡u xáº¿p trÆ°á»›c cÃ²n chiá»u nhiá»u dá»¯ liá»‡u thÃ¬ xáº¿p sau Ä‘Ãºng khÃ´ng áº¡ ?
Q2 : Giáº£ sá»­ nhÆ° Q1 Ä‘Ãºng thÃ¬ táº¡i sao á»Ÿ áº¢nh 1 nÆ¡i cÃ³ 2 chiá»u thá»ƒ hiá»‡n dá»¯ liá»‡u nhiá»u nháº¥t láº¡i cÃ³ phÃ¢n bá»‘ má»™t cÃ¡ch ngáº«u nhiÃªn xung quanh tÃ¢m (giao cá»§a 2 kÃ¬ vá»ng 2 chiá»u Ä‘Ã³). CÃ²n á»Ÿ áº¢nh 2 cÃ³ sá»± phÃ¢n bá»‘ rÃµ rÃ ng hÆ¡n  , khÃ´ng Ä‘áº¿n ná»—i tÃ¡ch Ä‘Æ°á»£c tuyáº¿n tÃ­nh hoáº·c gáº§n tÃ¡ch Ä‘Æ°á»£c tuyáº¿n tÃ­nh nhÆ°ng nhin nÃ³ láº¡i dá»… dÃ ng phÃ¢n ra cÃ¡c cá»¥m hÆ¡n . Em khÃ´ng biáº¿t táº¡i sao láº¡i cÃ³ hiá»‡n tÆ°á»£ng nÃ y áº¡ ?","ChÃ o má»i ngÆ°á»i. Em cÃ³ chÃºt tháº¯c máº¯c vá» phÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh mong giáº£i phÃ¡p tá»« cÃ¡c anh chá»‹ áº¡. Em cÃ³ dá»¯ liá»‡u gá»“m 1000 áº£nh vá» nháº­n dáº¡ng quáº§n Ã¡o. Má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c 28*28 (gray scale). Khi kÃ©o dÃ£n ra sáº½ lÃ  ma tráº­n (1000*784) . Em dÃ¹ng phÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh giáº£m sá»‘ chiá»u tá»« 784 xuá»‘ng cÃ²n 2 chiá»u vÃ  trá»±c quan hÃ³a nÃ³ trong khÃ´ng gian 2d. á» 2 áº£nh dÆ°á»›i chÃ­nh lÃ  Trá»±c quan hÃ³a vá»›i 2 chiá»u sau khi em phÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh. - áº¢nh 1 : Láº¥y 2 chiá»u cuá»‘i cÃ¹ng - áº¢nh 2 : Láº¥y 2 chiá»u Ä‘áº§u tiÃªn - áº¢nh 3 : Code á» Ä‘Ã¢y em cÃ³ 2 cÃ¢u há»i áº¡ . Q1 : NhÆ° code em viáº¿t á»Ÿ áº£nh 3 , sau khi dÃ¹ng thÆ° viá»‡n pca cá»§a sklearn thÃ¬ cÃ¡c chiá»u Ä‘Æ°á»£c xáº¿p theo thá»© tá»± chiá»u thá»ƒ hiá»‡n Ã­t dá»¯ liá»‡u xáº¿p trÆ°á»›c cÃ²n chiá»u nhiá»u dá»¯ liá»‡u thÃ¬ xáº¿p sau Ä‘Ãºng khÃ´ng áº¡ ? Q2 : Giáº£ sá»­ nhÆ° Q1 Ä‘Ãºng thÃ¬ táº¡i sao á»Ÿ áº¢nh 1 nÆ¡i cÃ³ 2 chiá»u thá»ƒ hiá»‡n dá»¯ liá»‡u nhiá»u nháº¥t láº¡i cÃ³ phÃ¢n bá»‘ má»™t cÃ¡ch ngáº«u nhiÃªn xung quanh tÃ¢m (giao cá»§a 2 kÃ¬ vá»ng 2 chiá»u Ä‘Ã³). CÃ²n á»Ÿ áº¢nh 2 cÃ³ sá»± phÃ¢n bá»‘ rÃµ rÃ ng hÆ¡n , khÃ´ng Ä‘áº¿n ná»—i tÃ¡ch Ä‘Æ°á»£c tuyáº¿n tÃ­nh hoáº·c gáº§n tÃ¡ch Ä‘Æ°á»£c tuyáº¿n tÃ­nh nhÆ°ng nhin nÃ³ láº¡i dá»… dÃ ng phÃ¢n ra cÃ¡c cá»¥m hÆ¡n . Em khÃ´ng biáº¿t táº¡i sao láº¡i cÃ³ hiá»‡n tÆ°á»£ng nÃ y áº¡ ?",#PhÃ¢n_tÃ­ch_thÃ nh_pháº§n_chÃ­nh	#pca,,,,
"[Chia sáº»]
LÃ¢u rá»“i em/mÃ¬nh khÃ´ng viáº¿t blog, nay viáº¿t láº¡i cÃ³ hÆ¡i lá»§ng cá»§ng má»i ngÆ°á»i thÃ´ng cáº£m. Em/mÃ¬nh xin chia sáº» vá»›i gÃ³c nhÃ¬n data-centric, mong má»i ngÆ°á»i Ä‘Ã³ng gÃ³p Ã½ kiáº¿n Ä‘á»ƒ em há»c há»i nhiá»u hÆ¡n :)","[Chia sáº»] LÃ¢u rá»“i em/mÃ¬nh khÃ´ng viáº¿t blog, nay viáº¿t láº¡i cÃ³ hÆ¡i lá»§ng cá»§ng má»i ngÆ°á»i thÃ´ng cáº£m. Em/mÃ¬nh xin chia sáº» vá»›i gÃ³c nhÃ¬n data-centric, mong má»i ngÆ°á»i Ä‘Ã³ng gÃ³p Ã½ kiáº¿n Ä‘á»ƒ em há»c há»i nhiá»u hÆ¡n :)",,,,,
"[TrÃ­ Tuá»‡ NhÃ¢n Táº¡o Cho Má»i NgÆ°á»i]
ChÃ o má»i ngÆ°á»i,
NÄƒm ngoÃ¡i khi Ä‘ang há»c PhD, tÃ´i Ä‘Ã£ viáº¿t quyá»ƒn sÃ¡ch ""TrÃ­ Tuá»‡ NhÃ¢n Táº¡o Cho Má»i NgÆ°á»i"" Ä‘á»ƒ giá»›i thiá»‡u trÃ­ tuá»‡ nhÃ¢n táº¡o tá»›i sá»‘ Ä‘Ã´ng.
Hiá»‡n táº¡i tÃ´i Ä‘Ã£ tá»‘t nghiá»‡p PhD nÃªn xin Ä‘Æ°á»£c chia sáº» vá»›i cÃ¡c báº¡n trÃªn Forum Machine Learning CÆ¡ Báº£n nÃ y.
Má»i cÃ¡c báº¡n Ä‘á»c sÃ¡ch (báº£n miá»…n phÃ­) trÃªn trang web cÃ¡ nhÃ¢n cá»§a tÃ´i: https://www.maitieulong.com/2022/03/Sach-Tri-tue-nhan-tao-cho-moi-nguoi.html
-----------------------------------------
Lá»i má»Ÿ Ä‘áº§u
TrÃ­ Tuá»‡ NhÃ¢n Táº¡o Cho Má»i NgÆ°á»i
TÃ¡c giáº£: Mai Tiá»ƒu Long
Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Ã£ trá»Ÿ thÃ nh má»™t ngÃ nh thá»i thÆ°á»£ng. CÃ¡c á»©ng dá»¥ng liÃªn quan cung cáº¥p cho con ngÆ°á»i nhá»¯ng tiá»‡n Ã­ch vÆ°á»£t trá»™i mÃ  chá»‰ vÃ i nÄƒm trÆ°á»›c tÆ°á»Ÿng chá»«ng khÃ´ng thá»ƒ nÃ o tá»“n táº¡i. Iphone cho phÃ©p má»Ÿ khÃ³a Ä‘iá»‡n thoáº¡i báº±ng nháº­n dáº¡ng khuÃ´n máº·t. Youtube gá»£i Ã½ phim theo sá»Ÿ thÃ­ch. ChÆ°Æ¡ng trÃ¬nh chÆ¡i cá» vÃ¢y vÆ°á»£t máº·t con ngÆ°á»i. Táº¥t cáº£ táº¡o nÃªn Ã¡nh hÃ o quang xung quanh má»™t cÃ´ng nghá»‡ má»›i.
Máº·c dÃ¹ váº­y, trÃ­ tuá»‡ nhÃ¢n táº¡o váº«n cÃ²n lÃ  má»™t cÃ´ng nghá»‡ khÃ³ hiá»ƒu Ä‘á»‘i vá»›i sá»‘ Ä‘Ã´ng. Äa pháº§n cÃ¡c sÃ¡ch chuyÃªn ngÃ nh táº­p trung vÃ o viá»‡c truyá»n táº£i kiáº¿n thá»©c cho ká»¹ sÆ° pháº§n má»m Ä‘á»ƒ Ä‘Ã¡p á»©ng nhu cáº§u nhÃ¢n lá»±c trÆ°á»›c máº¯t. NgÆ°á»£c láº¡i, bÃ¡o chÃ­ vÃ  truyá»n thÃ´ng Ä‘Ã£ Ã­t nhiá»u Ä‘á» cáº­p tá»›i nhÆ°ng váº«n chÆ°a Ä‘á»§ sÃ¢u sáº¯c vÃ  hoÃ n chá»‰nh. Nhiá»u Ä‘á»™c giáº£ cáº§n tÃ¬m hiá»ƒu thÃªm vá» cÃ´ng nghá»‡ má»›i thÃ¬ khÃ´ng cÃ³ nguá»“n Ä‘á»ƒ tham kháº£o. ÄÃ³ lÃ  lÃ½ do cuá»‘n sÃ¡ch nÃ y ra Ä‘á»i.
Äá»‘i tÆ°á»£ng Ä‘á»™c giáº£ cá»§a cuá»‘n sÃ¡ch nÃ y lÃ  táº¥t cáº£ báº¡n Ä‘á»c quan tÃ¢m tá»›i trÃ­ tuá»‡ nhÃ¢n táº¡o nhÆ°ng khÃ´ng nháº¥t Ä‘á»‹nh pháº£i trá»Ÿ thÃ nh nhÃ  nghiÃªn cá»©u chuyÃªn nghiá»‡p. Cuá»‘n sÃ¡ch Ä‘Æ°á»£c viáº¿t theo phong cÃ¡ch Ä‘Æ¡n giáº£n Ä‘á»ƒ cÃ³ thá»ƒ truyá»n táº£i hiá»‡u quáº£ nhá»¯ng cÃ´ng nghá»‡ liÃªn quan. NgoÃ i ra, trong tÃ¬nh hÃ¬nh nÆ°á»›c ta Ä‘ang phÃ¡t triá»ƒn máº¡nh máº£ng kinh táº¿ tri thá»©c vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  má»™t mÅ©i nhá»n, tÃ¡c giáº£ hi vá»ng cÃ³ thá»ƒ gÃ³p pháº§n giÃºp cÃ¡c nhÃ  lÃ m chÃ­nh sÃ¡ch cÃ³ thÃªm má»™t kÃªnh tiáº¿p cáº­n cÃ´ng nghá»‡ má»›i thÃ´ng qua quyá»ƒn sÃ¡ch nÃ y.
Xin trÃ¢n trá»ng cáº£m Æ¡n!
Äáº¡i cÃ´ng quá»‘c Luxembourg, thÃ¡ng 4/2021,
Mai Tiá»ƒu Long
-----------------------------------------
Má»¥c lá»¥c
ChÆ°Æ¡ng 0: CÃ¢u chuyá»‡n cá» vÃ¢y
ChÆ°Æ¡ng 1: BÃ i kiá»ƒm tra Turing
ChÆ°Æ¡ng 2: Thuáº­t toÃ¡n lan truyá»n ngÆ°á»£c
ChÆ°Æ¡ng 3: HÃ¬nh áº£nh vÃ  ngÃ´n ngá»¯
ChÆ°Æ¡ng 4: Cuá»™c thi nháº­n dáº¡ng váº­t thá»ƒ
ChÆ°Æ¡ng 5: BÃ i giáº£ng cho má»i ngÆ°á»i
ChÆ°Æ¡ng 6: NgÆ°á»i táº¡o giáº¥c mÆ¡
ChÆ°Æ¡ng 7: Táº¥n cÃ´ng vÃ  phÃ²ng thá»§
ChÆ°Æ¡ng 8: PhÃ¢n biá»‡t 7 tá»· ngÆ°á»i
ChÆ°Æ¡ng 9: Má»™t hÆ°á»›ng Ä‘i khÃ¡c
ChÆ°Æ¡ng 10: Tháº¿ nÃ o lÃ  trÃ­ thÃ´ng minh?
Lá»i káº¿t","[TrÃ­ Tuá»‡ NhÃ¢n Táº¡o Cho Má»i NgÆ°á»i] ChÃ o má»i ngÆ°á»i, NÄƒm ngoÃ¡i khi Ä‘ang há»c PhD, tÃ´i Ä‘Ã£ viáº¿t quyá»ƒn sÃ¡ch ""TrÃ­ Tuá»‡ NhÃ¢n Táº¡o Cho Má»i NgÆ°á»i"" Ä‘á»ƒ giá»›i thiá»‡u trÃ­ tuá»‡ nhÃ¢n táº¡o tá»›i sá»‘ Ä‘Ã´ng. Hiá»‡n táº¡i tÃ´i Ä‘Ã£ tá»‘t nghiá»‡p PhD nÃªn xin Ä‘Æ°á»£c chia sáº» vá»›i cÃ¡c báº¡n trÃªn Forum Machine Learning CÆ¡ Báº£n nÃ y. Má»i cÃ¡c báº¡n Ä‘á»c sÃ¡ch (báº£n miá»…n phÃ­) trÃªn trang web cÃ¡ nhÃ¢n cá»§a tÃ´i: https://www.maitieulong.com/2022/03/Sach-Tri-tue-nhan-tao-cho-moi-nguoi.html ----------------------------------------- Lá»i má»Ÿ Ä‘áº§u TrÃ­ Tuá»‡ NhÃ¢n Táº¡o Cho Má»i NgÆ°á»i TÃ¡c giáº£: Mai Tiá»ƒu Long Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Ã£ trá»Ÿ thÃ nh má»™t ngÃ nh thá»i thÆ°á»£ng. CÃ¡c á»©ng dá»¥ng liÃªn quan cung cáº¥p cho con ngÆ°á»i nhá»¯ng tiá»‡n Ã­ch vÆ°á»£t trá»™i mÃ  chá»‰ vÃ i nÄƒm trÆ°á»›c tÆ°á»Ÿng chá»«ng khÃ´ng thá»ƒ nÃ o tá»“n táº¡i. Iphone cho phÃ©p má»Ÿ khÃ³a Ä‘iá»‡n thoáº¡i báº±ng nháº­n dáº¡ng khuÃ´n máº·t. Youtube gá»£i Ã½ phim theo sá»Ÿ thÃ­ch. ChÆ°Æ¡ng trÃ¬nh chÆ¡i cá» vÃ¢y vÆ°á»£t máº·t con ngÆ°á»i. Táº¥t cáº£ táº¡o nÃªn Ã¡nh hÃ o quang xung quanh má»™t cÃ´ng nghá»‡ má»›i. Máº·c dÃ¹ váº­y, trÃ­ tuá»‡ nhÃ¢n táº¡o váº«n cÃ²n lÃ  má»™t cÃ´ng nghá»‡ khÃ³ hiá»ƒu Ä‘á»‘i vá»›i sá»‘ Ä‘Ã´ng. Äa pháº§n cÃ¡c sÃ¡ch chuyÃªn ngÃ nh táº­p trung vÃ o viá»‡c truyá»n táº£i kiáº¿n thá»©c cho ká»¹ sÆ° pháº§n má»m Ä‘á»ƒ Ä‘Ã¡p á»©ng nhu cáº§u nhÃ¢n lá»±c trÆ°á»›c máº¯t. NgÆ°á»£c láº¡i, bÃ¡o chÃ­ vÃ  truyá»n thÃ´ng Ä‘Ã£ Ã­t nhiá»u Ä‘á» cáº­p tá»›i nhÆ°ng váº«n chÆ°a Ä‘á»§ sÃ¢u sáº¯c vÃ  hoÃ n chá»‰nh. Nhiá»u Ä‘á»™c giáº£ cáº§n tÃ¬m hiá»ƒu thÃªm vá» cÃ´ng nghá»‡ má»›i thÃ¬ khÃ´ng cÃ³ nguá»“n Ä‘á»ƒ tham kháº£o. ÄÃ³ lÃ  lÃ½ do cuá»‘n sÃ¡ch nÃ y ra Ä‘á»i. Äá»‘i tÆ°á»£ng Ä‘á»™c giáº£ cá»§a cuá»‘n sÃ¡ch nÃ y lÃ  táº¥t cáº£ báº¡n Ä‘á»c quan tÃ¢m tá»›i trÃ­ tuá»‡ nhÃ¢n táº¡o nhÆ°ng khÃ´ng nháº¥t Ä‘á»‹nh pháº£i trá»Ÿ thÃ nh nhÃ  nghiÃªn cá»©u chuyÃªn nghiá»‡p. Cuá»‘n sÃ¡ch Ä‘Æ°á»£c viáº¿t theo phong cÃ¡ch Ä‘Æ¡n giáº£n Ä‘á»ƒ cÃ³ thá»ƒ truyá»n táº£i hiá»‡u quáº£ nhá»¯ng cÃ´ng nghá»‡ liÃªn quan. NgoÃ i ra, trong tÃ¬nh hÃ¬nh nÆ°á»›c ta Ä‘ang phÃ¡t triá»ƒn máº¡nh máº£ng kinh táº¿ tri thá»©c vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  má»™t mÅ©i nhá»n, tÃ¡c giáº£ hi vá»ng cÃ³ thá»ƒ gÃ³p pháº§n giÃºp cÃ¡c nhÃ  lÃ m chÃ­nh sÃ¡ch cÃ³ thÃªm má»™t kÃªnh tiáº¿p cáº­n cÃ´ng nghá»‡ má»›i thÃ´ng qua quyá»ƒn sÃ¡ch nÃ y. Xin trÃ¢n trá»ng cáº£m Æ¡n! Äáº¡i cÃ´ng quá»‘c Luxembourg, thÃ¡ng 4/2021, Mai Tiá»ƒu Long ----------------------------------------- Má»¥c lá»¥c ChÆ°Æ¡ng 0: CÃ¢u chuyá»‡n cá» vÃ¢y ChÆ°Æ¡ng 1: BÃ i kiá»ƒm tra Turing ChÆ°Æ¡ng 2: Thuáº­t toÃ¡n lan truyá»n ngÆ°á»£c ChÆ°Æ¡ng 3: HÃ¬nh áº£nh vÃ  ngÃ´n ngá»¯ ChÆ°Æ¡ng 4: Cuá»™c thi nháº­n dáº¡ng váº­t thá»ƒ ChÆ°Æ¡ng 5: BÃ i giáº£ng cho má»i ngÆ°á»i ChÆ°Æ¡ng 6: NgÆ°á»i táº¡o giáº¥c mÆ¡ ChÆ°Æ¡ng 7: Táº¥n cÃ´ng vÃ  phÃ²ng thá»§ ChÆ°Æ¡ng 8: PhÃ¢n biá»‡t 7 tá»· ngÆ°á»i ChÆ°Æ¡ng 9: Má»™t hÆ°á»›ng Ä‘i khÃ¡c ChÆ°Æ¡ng 10: Tháº¿ nÃ o lÃ  trÃ­ thÃ´ng minh? Lá»i káº¿t",,,,,
"[Text to Image]
DALL-E2 váº«n chÆ°a háº¿t hot thÃ¬ má»›i Ä‘Ã¢y Google giá»›i thiá»‡u má»™t mÃ´ hÃ¬nh má»›i lÃ  Imagen Ä‘Ã¡nh báº¡i DALL-E2, trá»Ÿ thÃ nh SOTA trong bÃ i toÃ¡n chuyá»ƒn tá»« text sang áº£nh ^^.
Vá» kiáº¿n trÃºc, Imagen Ä‘Æ¡n giáº£n hÆ¡n nhiá»u so vá»›i DALL-E2.
Má»i ngÆ°á»i Ä‘á»c thÃªm á»Ÿ Ä‘Ã¢y:
Page: https://imagen.research.google/
Github: https://github.com/lucidrains/imagen-pytorch
Paper: https://arxiv.org/pdf/2205.11487.pdf","[Text to Image] DALL-E2 váº«n chÆ°a háº¿t hot thÃ¬ má»›i Ä‘Ã¢y Google giá»›i thiá»‡u má»™t mÃ´ hÃ¬nh má»›i lÃ  Imagen Ä‘Ã¡nh báº¡i DALL-E2, trá»Ÿ thÃ nh SOTA trong bÃ i toÃ¡n chuyá»ƒn tá»« text sang áº£nh ^^. Vá» kiáº¿n trÃºc, Imagen Ä‘Æ¡n giáº£n hÆ¡n nhiá»u so vá»›i DALL-E2. Má»i ngÆ°á»i Ä‘á»c thÃªm á»Ÿ Ä‘Ã¢y: Page: https://imagen.research.google/ Github: https://github.com/lucidrains/imagen-pytorch Paper: https://arxiv.org/pdf/2205.11487.pdf",,,,,
"Xin Ä‘Æ°á»£c chia sáº» vá»›i cÃ¡c báº¡n hai hÆ°á»›ng tiáº¿p cáº­n trong trÆ°á»ng há»£p thiáº¿u dá»¯ liá»‡u cÃ³ nhÃ£n lÃ  Active Learning vÃ  Semi supervised learning. CÃ¡c báº¡n like share Ä‘á»ƒ mÃ¬nh cÃ³ thÃªm Ä‘á»™ng lá»±c chia sáº» cÃ¡c pháº§n tiáº¿p theo nhÃ©.
https://viblo.asia/p/lam-gi-khi-mo-hinh-hoc-may-thieu-du-lieu-co-nhan-phan-1-tong-quan-ve-active-learning-RQqKLRLbl7z
https://viblo.asia/p/lam-gi-khi-mo-hinh-hoc-may-thieu-du-lieu-co-nhan-phan-2-semi-supervised-learning-vyDZOREkKwj",Xin Ä‘Æ°á»£c chia sáº» vá»›i cÃ¡c báº¡n hai hÆ°á»›ng tiáº¿p cáº­n trong trÆ°á»ng há»£p thiáº¿u dá»¯ liá»‡u cÃ³ nhÃ£n lÃ  Active Learning vÃ  Semi supervised learning. CÃ¡c báº¡n like share Ä‘á»ƒ mÃ¬nh cÃ³ thÃªm Ä‘á»™ng lá»±c chia sáº» cÃ¡c pháº§n tiáº¿p theo nhÃ©. https://viblo.asia/p/lam-gi-khi-mo-hinh-hoc-may-thieu-du-lieu-co-nhan-phan-1-tong-quan-ve-active-learning-RQqKLRLbl7z https://viblo.asia/p/lam-gi-khi-mo-hinh-hoc-may-thieu-du-lieu-co-nhan-phan-2-semi-supervised-learning-vyDZOREkKwj,,,,,
"CÃ³ báº¡n nÃ o muá»‘n qua Na Uy lÃ m post doc khÃ´ng
Postdoctoral Research Fellow at the intersection of artificial intelligence and biology:
https://www.jobbnorge.no/en/available-jobs/job/227549/postdoctoral-research-fellow-at-the-intersection-of-artificial-intelligence-and-biology
Postdoctoral Research Fellow within explainable artificial intelligence for clinical prognostic tools:
https://www.simula.no/about/job/postdoctoral-fellow-within-explainable-artificial-intelligence-clinical-prognostic-tools
Qua mÃ¬nh dáº«n Ä‘i chÆ¡i :))",CÃ³ báº¡n nÃ o muá»‘n qua Na Uy lÃ m post doc khÃ´ng Postdoctoral Research Fellow at the intersection of artificial intelligence and biology: https://www.jobbnorge.no/en/available-jobs/job/227549/postdoctoral-research-fellow-at-the-intersection-of-artificial-intelligence-and-biology Postdoctoral Research Fellow within explainable artificial intelligence for clinical prognostic tools: https://www.simula.no/about/job/postdoctoral-fellow-within-explainable-artificial-intelligence-clinical-prognostic-tools Qua mÃ¬nh dáº«n Ä‘i chÆ¡i :)),,,,,
"[Hopular - Äá»™t phÃ¡ cá»§a Deep Learning trong dá»¯ liá»‡u báº£ng]
Máº·c dÃ¹ Deep Learning xá»­ lÃ½ ráº¥t tá»‘t vá»›i dá»¯ liá»‡u dáº¡ng hÃ¬nh áº£nh, ngÃ´n ngá»¯ tá»± nhiÃªn, nhÆ°ng vá»›i dá»¯ liá»‡u dáº¡ng báº£ng thÃ¬ cÃ¡c thuáº­t toÃ¡n boosting nhÆ° XGBoost, CatBoost hay LightGBM thÆ°á»ng cÃ³ káº¿t quáº£ tá»‘t hÆ¡n. Trong bÃ i nÃ y tÃ¡c giáº£ Ä‘á» suáº¥t mÃ´ hÃ¬nh deep learning â€œHopularâ€ cho hiá»‡u suáº¥t tá»‘t hÆ¡n cÃ¡c thuáº­t toÃ¡n Machine Learning ká»ƒ trÃªn vá»›i cáº£ dá»¯ liá»‡u cá»¡ vá»«a (10,000 dá»¯ liá»‡u) vÃ  dá»¯ liá»‡u cá»¡ nhá» (Ã­t hÆ¡n 1000 dá»¯ liá»‡u). CÃ¡i hay cá»§a máº¡ng Hopfield lÃ  má»—i layer cÃ³ thá»ƒ truy xuáº¥t trá»±c tiáº¿p tá»›i cÃ¡c dá»¯ liá»‡u trong dataset thÃ´ng qua máº¡ng Hopfield.
Paper: https://arxiv.org/abs/2206.00664
Github: https://github.com/ml-jku/hopular
Project page: https://ml-jku.github.io/hopular/","[Hopular - Äá»™t phÃ¡ cá»§a Deep Learning trong dá»¯ liá»‡u báº£ng] Máº·c dÃ¹ Deep Learning xá»­ lÃ½ ráº¥t tá»‘t vá»›i dá»¯ liá»‡u dáº¡ng hÃ¬nh áº£nh, ngÃ´n ngá»¯ tá»± nhiÃªn, nhÆ°ng vá»›i dá»¯ liá»‡u dáº¡ng báº£ng thÃ¬ cÃ¡c thuáº­t toÃ¡n boosting nhÆ° XGBoost, CatBoost hay LightGBM thÆ°á»ng cÃ³ káº¿t quáº£ tá»‘t hÆ¡n. Trong bÃ i nÃ y tÃ¡c giáº£ Ä‘á» suáº¥t mÃ´ hÃ¬nh deep learning â€œHopularâ€ cho hiá»‡u suáº¥t tá»‘t hÆ¡n cÃ¡c thuáº­t toÃ¡n Machine Learning ká»ƒ trÃªn vá»›i cáº£ dá»¯ liá»‡u cá»¡ vá»«a (10,000 dá»¯ liá»‡u) vÃ  dá»¯ liá»‡u cá»¡ nhá» (Ã­t hÆ¡n 1000 dá»¯ liá»‡u). CÃ¡i hay cá»§a máº¡ng Hopfield lÃ  má»—i layer cÃ³ thá»ƒ truy xuáº¥t trá»±c tiáº¿p tá»›i cÃ¡c dá»¯ liá»‡u trong dataset thÃ´ng qua máº¡ng Hopfield. Paper: https://arxiv.org/abs/2206.00664 Github: https://github.com/ml-jku/hopular Project page: https://ml-jku.github.io/hopular/",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 4/2022 vÃ o trong comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 4/2022 vÃ o trong comment cá»§a post nÃ y.",,,,,
"Há»i vá» Code R
ChÃ o m.n. Em Ä‘ang thá»±c hiá»‡n phÃ¢n loáº¡i whitepaper cá»§a cÃ¡c ICO theo ROI Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nÃ³ thÃ nh cÃ´ng hay khÃ´ng. (sá»­ dá»¥ng mÃ´ hÃ¬nh Naive Bayes)
Hiá»‡n data em Ä‘ang cÃ³ tá»•ng cá»™ng 101 file text cÃ¡c whitepaper. CÃ¡c whitepaper thÃ nh cÃ´ng sáº½ cÃ³ chá»‰ sá»‘ ROI >100%, vÃ  khÃ´ng thÃ nh cÃ´ng lÃ  ROI dÆ°á»›i 30%, ngoÃ i ra cÃ²n cÃ³ Ä‘iá»u kiá»‡n lÃ  whitepaper nÃ o cÃ³ lá»£i nhuáº­n bÃ© hÆ¡n 50% vÃ  cÃ³ chá»‰ sá»‘ ATH ROI bÃ© hÆ¡n 100% thÃ¬ cÅ©ng ko thÃ nh cÃ´ng ná»‘t.
Em cÃ³ Ä‘Æ°á»£c há»— trá»£ 1 Ä‘oáº¡n code Ä‘á»ƒ thá»±c hiá»‡n (hÃ¬nh bÃªn dÆ°á»›i). NhÆ°ng cÃ³ má»™t pháº§n ko hiá»ƒu nÃªn muá»‘n nhá» há»— trá»£. Äoáº¡n code em Ä‘ang ko hiá»ƒu lÃ :
Data$type[36:101] <- ""unsuccessful""
Data$type[90:99] <- ""successful""
Mong nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ cá»§a m.n áº¡! Em má»›i biáº¿t sÆ¡ lÆ°á»£c vá» R nÃªn náº¿u thÃ´ng tin Ä‘Æ°a ra cÃ³ thiáº¿u vÃ  cáº§n bá»• sung Ä‘á»ƒ dá»… lÃ½ giáº£i váº¥n Ä‘á» mong m.n cÃ³ thá»ƒ cmt Ä‘á»ƒ em bá»• sung, mong m.n há»— trá»£ áº¡!
 â€” vá»›i Há»“ng YÃªn.","Há»i vá» Code R ChÃ o m.n. Em Ä‘ang thá»±c hiá»‡n phÃ¢n loáº¡i whitepaper cá»§a cÃ¡c ICO theo ROI Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nÃ³ thÃ nh cÃ´ng hay khÃ´ng. (sá»­ dá»¥ng mÃ´ hÃ¬nh Naive Bayes) Hiá»‡n data em Ä‘ang cÃ³ tá»•ng cá»™ng 101 file text cÃ¡c whitepaper. CÃ¡c whitepaper thÃ nh cÃ´ng sáº½ cÃ³ chá»‰ sá»‘ ROI >100%, vÃ  khÃ´ng thÃ nh cÃ´ng lÃ  ROI dÆ°á»›i 30%, ngoÃ i ra cÃ²n cÃ³ Ä‘iá»u kiá»‡n lÃ  whitepaper nÃ o cÃ³ lá»£i nhuáº­n bÃ© hÆ¡n 50% vÃ  cÃ³ chá»‰ sá»‘ ATH ROI bÃ© hÆ¡n 100% thÃ¬ cÅ©ng ko thÃ nh cÃ´ng ná»‘t. Em cÃ³ Ä‘Æ°á»£c há»— trá»£ 1 Ä‘oáº¡n code Ä‘á»ƒ thá»±c hiá»‡n (hÃ¬nh bÃªn dÆ°á»›i). NhÆ°ng cÃ³ má»™t pháº§n ko hiá»ƒu nÃªn muá»‘n nhá» há»— trá»£. Äoáº¡n code em Ä‘ang ko hiá»ƒu lÃ : Data$type[36:101] <- ""unsuccessful"" Data$type[90:99] <- ""successful"" Mong nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ cá»§a m.n áº¡! Em má»›i biáº¿t sÆ¡ lÆ°á»£c vá» R nÃªn náº¿u thÃ´ng tin Ä‘Æ°a ra cÃ³ thiáº¿u vÃ  cáº§n bá»• sung Ä‘á»ƒ dá»… lÃ½ giáº£i váº¥n Ä‘á» mong m.n cÃ³ thá»ƒ cmt Ä‘á»ƒ em bá»• sung, mong m.n há»— trá»£ áº¡! â€” vá»›i Há»“ng YÃªn.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em hiá»‡n táº¡i Ä‘ang lÃ m vá» project nháº­n diá»‡n hÃ nh Ä‘á»™ng cá»§a ngÆ°á»i dá»±a trÃªn khung xÆ°Æ¡ng. Em Ä‘Ã£ train Ä‘Æ°á»£c model Ä‘á»ƒ nháº­n diá»‡n rá»“i. Khi train thÃ¬ má»—i hÃ nh Ä‘á»™ng nÃ³ sáº½ cÃ³ sá»‘ frame thá»±c hiá»‡n khÃ¡c nhau.
BÃ¢y giá» e muá»‘n Ã¡p dá»¥ng model Ä‘Ã³ vÃ o video ( video trÃªn táº­p test ), nhÆ°ng bá»‹ gáº·p váº¥n Ä‘á» nhÆ° sau áº¡
VÃ¬ lÃ  lÃ m trÃªn video cÃ³ nhiá»u hÃ nh Ä‘á»™ng nÃªn e dÃ¹ng cá»­a sá»• trÆ°á»£t, cá»© khi nÃ o cÃ³ hÃ nh Ä‘á»™ng vÃ  stack Ä‘á»§ 32 frame thÃ¬ e Ä‘Æ°a vÃ o nháº­n dáº¡ng. VÃ¬ váº­y tá»« data train ban Ä‘áº§u, vÃ­ dá»¥ hÃ nh Ä‘á»™ng A thá»±c hiá»‡n trong 60 frame cháº³ng háº¡n, thÃ¬ e tÃ¡ch ra thÃ nh nhá»¯ng Ä‘oáº¡n 32 frame, stride = 4 frame Ä‘á»ƒ Ä‘Æ°a vÃ o train. Tuy nhiÃªn, cÃ³ váº» nhÆ° lá»±a chá»n nhÆ° váº­y sáº½ khÃ´ng Ä‘á»§ thÃ´ng tin cá»§a hÃ nh Ä‘á»™ng, nÃªn khi gÃ¡n nhÃ£n sáº½ cÃ³ nhÆ°ng cá»­a sá»• 32 frame cÃ³ thÃ´ng tin khung xÆ°Æ¡ng tÆ°Æ¡ng Ä‘á»“ng nhÆ°ng nhÃ£n láº¡i khÃ¡c nhau, nÃªn khi train mÃ´ hÃ¬nh ko há»™i tá»¥ Ä‘Æ°á»£c. 
VÃ¬ nhá»¯ng hÃ nh Ä‘á»™ng cÃ³ thá»i gian thá»±c hiá»‡n khÃ¡c nhau nÃªn e ko biáº¿t lá»±a chá»n kÃ­ch thÆ°á»›c cá»­a sá»• bao nhiÃªu Ä‘á»ƒ train cho phÃ¹ há»£p.  ( cÃ³ hÃ nh Ä‘á»™ng thá»±c hiá»‡n trong 60 frame, cÃ³ hÃ nh Ä‘á»™ng láº¡i thá»±c hiá»‡n trong 30 frame , ... )
Em cÃ³ tham kháº£o má»™t sá»‘ bÃ i toÃ¡n khÃ¡c ( vd violence detection, real time action recognition open pose, hand gesture recognition ) thÃ¬ khi Ã¡p dá»¥ng trÃªn video real time thÃ¬ há» Ä‘á»u tiáº¿p cáº­n dá»±a trÃªn pp cá»­a sá»• trÆ°á»£t nhÆ° tháº¿ nÃ y áº¡.
VÃ¬ váº­y, e ráº¥t mong anh/chá»‹ nÃ o Ä‘ang lÃ m vá» nháº­n dáº¡ng hÃ nh Ä‘á»™ng nÃ³i chung hoáº·c nháº­n dáº¡ng dá»±a trÃªn khung xÆ°Æ¡ng nÃ³i riÃªng cÃ³ thá»ƒ cho e gÃ³p Ã½ Ä‘á»ƒ cÃ³ thá»ƒ Ã¡p dá»¥ng model Ä‘Ã£ train Ä‘á»ƒ nháº­n dáº¡ng Ä‘c hÃ nh Ä‘á»™ng liÃªn tá»¥c trÃªn video ko áº¡.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i áº¡ Em hiá»‡n táº¡i Ä‘ang lÃ m vá» project nháº­n diá»‡n hÃ nh Ä‘á»™ng cá»§a ngÆ°á»i dá»±a trÃªn khung xÆ°Æ¡ng. Em Ä‘Ã£ train Ä‘Æ°á»£c model Ä‘á»ƒ nháº­n diá»‡n rá»“i. Khi train thÃ¬ má»—i hÃ nh Ä‘á»™ng nÃ³ sáº½ cÃ³ sá»‘ frame thá»±c hiá»‡n khÃ¡c nhau. BÃ¢y giá» e muá»‘n Ã¡p dá»¥ng model Ä‘Ã³ vÃ o video ( video trÃªn táº­p test ), nhÆ°ng bá»‹ gáº·p váº¥n Ä‘á» nhÆ° sau áº¡ VÃ¬ lÃ  lÃ m trÃªn video cÃ³ nhiá»u hÃ nh Ä‘á»™ng nÃªn e dÃ¹ng cá»­a sá»• trÆ°á»£t, cá»© khi nÃ o cÃ³ hÃ nh Ä‘á»™ng vÃ  stack Ä‘á»§ 32 frame thÃ¬ e Ä‘Æ°a vÃ o nháº­n dáº¡ng. VÃ¬ váº­y tá»« data train ban Ä‘áº§u, vÃ­ dá»¥ hÃ nh Ä‘á»™ng A thá»±c hiá»‡n trong 60 frame cháº³ng háº¡n, thÃ¬ e tÃ¡ch ra thÃ nh nhá»¯ng Ä‘oáº¡n 32 frame, stride = 4 frame Ä‘á»ƒ Ä‘Æ°a vÃ o train. Tuy nhiÃªn, cÃ³ váº» nhÆ° lá»±a chá»n nhÆ° váº­y sáº½ khÃ´ng Ä‘á»§ thÃ´ng tin cá»§a hÃ nh Ä‘á»™ng, nÃªn khi gÃ¡n nhÃ£n sáº½ cÃ³ nhÆ°ng cá»­a sá»• 32 frame cÃ³ thÃ´ng tin khung xÆ°Æ¡ng tÆ°Æ¡ng Ä‘á»“ng nhÆ°ng nhÃ£n láº¡i khÃ¡c nhau, nÃªn khi train mÃ´ hÃ¬nh ko há»™i tá»¥ Ä‘Æ°á»£c. VÃ¬ nhá»¯ng hÃ nh Ä‘á»™ng cÃ³ thá»i gian thá»±c hiá»‡n khÃ¡c nhau nÃªn e ko biáº¿t lá»±a chá»n kÃ­ch thÆ°á»›c cá»­a sá»• bao nhiÃªu Ä‘á»ƒ train cho phÃ¹ há»£p. ( cÃ³ hÃ nh Ä‘á»™ng thá»±c hiá»‡n trong 60 frame, cÃ³ hÃ nh Ä‘á»™ng láº¡i thá»±c hiá»‡n trong 30 frame , ... ) Em cÃ³ tham kháº£o má»™t sá»‘ bÃ i toÃ¡n khÃ¡c ( vd violence detection, real time action recognition open pose, hand gesture recognition ) thÃ¬ khi Ã¡p dá»¥ng trÃªn video real time thÃ¬ há» Ä‘á»u tiáº¿p cáº­n dá»±a trÃªn pp cá»­a sá»• trÆ°á»£t nhÆ° tháº¿ nÃ y áº¡. VÃ¬ váº­y, e ráº¥t mong anh/chá»‹ nÃ o Ä‘ang lÃ m vá» nháº­n dáº¡ng hÃ nh Ä‘á»™ng nÃ³i chung hoáº·c nháº­n dáº¡ng dá»±a trÃªn khung xÆ°Æ¡ng nÃ³i riÃªng cÃ³ thá»ƒ cho e gÃ³p Ã½ Ä‘á»ƒ cÃ³ thá»ƒ Ã¡p dá»¥ng model Ä‘Ã£ train Ä‘á»ƒ nháº­n dáº¡ng Ä‘c hÃ nh Ä‘á»™ng liÃªn tá»¥c trÃªn video ko áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c bÃ i toÃ¡n video understanding vÃ  Ä‘ang thá»±c hiá»‡n bÃ i toÃ¡n nháº­n biáº¿t vÃ¹ng hÃ nh Ä‘á»™ng, Ä‘á»™ng tÃ¡c, cá»¥ thá»ƒ lÃ  cÃ¡c Ä‘á»™ng tÃ¡c khá»Ÿi Ä‘á»™ng nháº¹ nhÆ° video dÆ°á»›i.
Hiá»‡n táº¡i nhá»¯ng bá»™ dá»¯ liá»‡u hiá»‡n cÃ³ mÃ  em tÃ¬m Ä‘Æ°á»£c (thumos14, actnet1.3, ...) thÆ°á»ng gá»“m nhá»¯ng hÃ nh Ä‘á»™ng dÃ i, camera khÃ´ng cá»‘ Ä‘á»‹nh vÃ  khÃ´ng cÃ³ class nÃ o phÃ¹ há»£p vá»›i bÃ i cá»§a em (hoáº·c lÃ  em chÆ°a tÃ¬m ra @@), cÃ²n nhá»¯ng bá»™ data vá» khá»Ÿi Ä‘á»™ng em tÃ¬m Ä‘Æ°á»£c thÆ°á»ng chá»‰ cÃ³ features (vá»‹ trÃ­ cÃ¡c keypoints), chá»© khÃ´ng cÃ³ videos (UI-PRMD, KIMORE, ...). Em Ä‘ang muá»‘n má»™t bá»™ dá»¯ liá»‡u bao gá»“m nhá»¯ng Ä‘á»™ng tÃ¡c khá»Ÿi Ä‘á»™ng thá»ƒ dá»¥c nháº¹ (camera cÃ³ thá»ƒ cá»‘ Ä‘á»‹nh Ä‘Æ°á»£c thÃ¬ tá»‘t), vá»›i má»—i láº§n thá»±c hiá»‡n xong má»™t Ä‘á»™ng tÃ¡c thÃ¬ Ä‘Æ°á»£c coi lÃ  1 vÃ¹ng hÃ nh Ä‘á»™ng (segments).
Trong Ä‘Ã¢y cÃ³ bÃ¡c nÃ o tÃ¬m hiá»ƒu vá» máº£ng nÃ y cÃ³ thá»ƒ gá»£i Ã½ hÆ°á»›ng Ä‘i hoáº·c bá»™ dá»¯ liá»‡u phÃ¹ há»£p giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡.
Em xin cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c bÃ i toÃ¡n video understanding vÃ  Ä‘ang thá»±c hiá»‡n bÃ i toÃ¡n nháº­n biáº¿t vÃ¹ng hÃ nh Ä‘á»™ng, Ä‘á»™ng tÃ¡c, cá»¥ thá»ƒ lÃ  cÃ¡c Ä‘á»™ng tÃ¡c khá»Ÿi Ä‘á»™ng nháº¹ nhÆ° video dÆ°á»›i. Hiá»‡n táº¡i nhá»¯ng bá»™ dá»¯ liá»‡u hiá»‡n cÃ³ mÃ  em tÃ¬m Ä‘Æ°á»£c (thumos14, actnet1.3, ...) thÆ°á»ng gá»“m nhá»¯ng hÃ nh Ä‘á»™ng dÃ i, camera khÃ´ng cá»‘ Ä‘á»‹nh vÃ  khÃ´ng cÃ³ class nÃ o phÃ¹ há»£p vá»›i bÃ i cá»§a em (hoáº·c lÃ  em chÆ°a tÃ¬m ra @@), cÃ²n nhá»¯ng bá»™ data vá» khá»Ÿi Ä‘á»™ng em tÃ¬m Ä‘Æ°á»£c thÆ°á»ng chá»‰ cÃ³ features (vá»‹ trÃ­ cÃ¡c keypoints), chá»© khÃ´ng cÃ³ videos (UI-PRMD, KIMORE, ...). Em Ä‘ang muá»‘n má»™t bá»™ dá»¯ liá»‡u bao gá»“m nhá»¯ng Ä‘á»™ng tÃ¡c khá»Ÿi Ä‘á»™ng thá»ƒ dá»¥c nháº¹ (camera cÃ³ thá»ƒ cá»‘ Ä‘á»‹nh Ä‘Æ°á»£c thÃ¬ tá»‘t), vá»›i má»—i láº§n thá»±c hiá»‡n xong má»™t Ä‘á»™ng tÃ¡c thÃ¬ Ä‘Æ°á»£c coi lÃ  1 vÃ¹ng hÃ nh Ä‘á»™ng (segments). Trong Ä‘Ã¢y cÃ³ bÃ¡c nÃ o tÃ¬m hiá»ƒu vá» máº£ng nÃ y cÃ³ thá»ƒ gá»£i Ã½ hÆ°á»›ng Ä‘i hoáº·c bá»™ dá»¯ liá»‡u phÃ¹ há»£p giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n!",,,,,
" Hi anh, chá»‹,
Anh, chá»‹ cho em há»i lÃ  em cÃ³ 4 mÃ´ hÃ¬nh sau: Random Forest, KNN, Logistic Regresstion, SVC, em muá»‘n káº¿t há»£p 2 mÃ´ hÃ¬nh tá»«ng cáº·p vá»›i nhau: 
VD: káº¿t há»£p mÃ´ hÃ¬nh logistic Regression vá»›i Random Forest, em cÃ³ dÃ¹ng Stacking vÃ  Voting, nhÆ° váº­y thÃ¬ cÃ³ Ä‘Ãºng khÃ´ng.?
- Em cÃ³ Ä‘á»c tÃ i liá»‡u thÃ¬ biáº¿t Ä‘Æ°á»£c dÃ¹ng ""ensemble methods classification"" tuy nhiÃªn em cÃ²n chÆ°a hiá»ƒu rÃµ láº¯m.
Bagging: Em chÆ°a hiá»ƒu phÆ°Æ¡ng thá»©c nÃ y
Stacking: káº¿t há»£p Ä‘Æ°á»£c nhiá»u mÃ´ hÃ¬nh - em Ä‘Ã£ lÃ m Ä‘Æ°á»£c
Voting: káº¿t há»£p Ä‘Æ°á»£c nhiá»u mÃ´ hÃ¬nh - em Ä‘Ã£ lÃ m Ä‘Æ°á»£c
Boosting: Em chÆ°a hiá»ƒu phÆ°Æ¡ng thá»©c nÃ y
- Em nhá» cÃ¡c anh, chá»‹ giáº£i thÃ­ch hoáº·c chá»‰ giÃºp em ""ensemble methods classification"", em xin cáº£m Æ¡n.","Hi anh, chá»‹, Anh, chá»‹ cho em há»i lÃ  em cÃ³ 4 mÃ´ hÃ¬nh sau: Random Forest, KNN, Logistic Regresstion, SVC, em muá»‘n káº¿t há»£p 2 mÃ´ hÃ¬nh tá»«ng cáº·p vá»›i nhau: VD: káº¿t há»£p mÃ´ hÃ¬nh logistic Regression vá»›i Random Forest, em cÃ³ dÃ¹ng Stacking vÃ  Voting, nhÆ° váº­y thÃ¬ cÃ³ Ä‘Ãºng khÃ´ng.? - Em cÃ³ Ä‘á»c tÃ i liá»‡u thÃ¬ biáº¿t Ä‘Æ°á»£c dÃ¹ng ""ensemble methods classification"" tuy nhiÃªn em cÃ²n chÆ°a hiá»ƒu rÃµ láº¯m. Bagging: Em chÆ°a hiá»ƒu phÆ°Æ¡ng thá»©c nÃ y Stacking: káº¿t há»£p Ä‘Æ°á»£c nhiá»u mÃ´ hÃ¬nh - em Ä‘Ã£ lÃ m Ä‘Æ°á»£c Voting: káº¿t há»£p Ä‘Æ°á»£c nhiá»u mÃ´ hÃ¬nh - em Ä‘Ã£ lÃ m Ä‘Æ°á»£c Boosting: Em chÆ°a hiá»ƒu phÆ°Æ¡ng thá»©c nÃ y - Em nhá» cÃ¡c anh, chá»‹ giáº£i thÃ­ch hoáº·c chá»‰ giÃºp em ""ensemble methods classification"", em xin cáº£m Æ¡n.",,,,,
"CÃ¡c anh chá»‹ cho em há»i: Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, em sáº½ láº·p 100 láº§n, má»—i láº§n Ä‘Ã¡nh giÃ¡ 5foldCV. TÃ­nh AUC trung bÃ¬nh thÃ¬ em hiá»ƒu, nhÆ°ng Ä‘áº¿n khi váº½ biá»ƒu Ä‘á»“ thÃ¬ em chÆ°a biáº¿t nÃªn thá»ƒ hiá»‡n cÃ¡i gÃ¬. Náº¿u chá»‰ láº·p 1 láº§n thÃ¬ em váº½ 1 biá»ƒu Ä‘á»“ gá»“m 5 Ä‘Æ°á»ng tÆ°Æ¡ng á»©ng 5 fold. BÃ¢y giá» láº·p 100 láº§n thÃ¬ em nÃªn thá»ƒ hiá»‡n nhÆ° tháº¿ nÃ o áº¡?
CÃ¡m Æ¡n mn!","CÃ¡c anh chá»‹ cho em há»i: Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, em sáº½ láº·p 100 láº§n, má»—i láº§n Ä‘Ã¡nh giÃ¡ 5foldCV. TÃ­nh AUC trung bÃ¬nh thÃ¬ em hiá»ƒu, nhÆ°ng Ä‘áº¿n khi váº½ biá»ƒu Ä‘á»“ thÃ¬ em chÆ°a biáº¿t nÃªn thá»ƒ hiá»‡n cÃ¡i gÃ¬. Náº¿u chá»‰ láº·p 1 láº§n thÃ¬ em váº½ 1 biá»ƒu Ä‘á»“ gá»“m 5 Ä‘Æ°á»ng tÆ°Æ¡ng á»©ng 5 fold. BÃ¢y giá» láº·p 100 láº§n thÃ¬ em nÃªn thá»ƒ hiá»‡n nhÆ° tháº¿ nÃ o áº¡? CÃ¡m Æ¡n mn!",,,,,
"SHARE SOLUTION BKAI-NAVER Challenge 2022
NhÃ³m OVERFIT xin chia sáº» slide + bÃ¡o cÃ¡o cho task Body Segmentation vÃ  Gesture Recognition. Solution Ä‘Ã£ Ä‘áº¡t Top 1 táº¡i cuá»™c thi. Vá» pháº§n code hiá»‡n táº¡i bá»n mÃ¬nh cÃ³ Ä‘ang viáº¿t 1 paper liÃªn quan nÃªn khi nÃ o cÃ³ káº¿t qá»§a cá»§a paper thÃ¬ bÃªn mÃ¬nh sáº½ share full cáº£ paper vÃ  source code sau áº¡. NhÃ³m mÃ¬nh cÅ©ng ráº¥t hi vá»ng nháº­n Ä‘Æ°á»£c sá»± chia sáº» cá»§a cÃ¡c Ä‘á»™i báº¡n áº¡",SHARE SOLUTION BKAI-NAVER Challenge 2022 NhÃ³m OVERFIT xin chia sáº» slide + bÃ¡o cÃ¡o cho task Body Segmentation vÃ  Gesture Recognition. Solution Ä‘Ã£ Ä‘áº¡t Top 1 táº¡i cuá»™c thi. Vá» pháº§n code hiá»‡n táº¡i bá»n mÃ¬nh cÃ³ Ä‘ang viáº¿t 1 paper liÃªn quan nÃªn khi nÃ o cÃ³ káº¿t qá»§a cá»§a paper thÃ¬ bÃªn mÃ¬nh sáº½ share full cáº£ paper vÃ  source code sau áº¡. NhÃ³m mÃ¬nh cÅ©ng ráº¥t hi vá»ng nháº­n Ä‘Æ°á»£c sá»± chia sáº» cá»§a cÃ¡c Ä‘á»™i báº¡n áº¡,,,,,
"[Article Summarization - Final Project Deep Learning K1] English version in the last.
â–¶ï¸ Sá»± bÃ¹ng ná»• internet vÃ  truyá»n thÃ´ng Ä‘a phÆ°Æ¡ng tiá»‡n dáº«n tá»›i má»™t lÆ°á»£ng dá»¯ liá»‡u vÄƒn báº£n khá»•ng lá»“ lÃ  tÃ i nguyÃªn ráº¥t quÃ­ giÃ¡ nhÆ°ng chÆ°a Ä‘Æ°á»£c khai phÃ¡ háº¿t. CÃ³ ráº¥t nhiá»u tÃ¡c vá»¥ NLP khÃ¡c nhau Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ khai thÃ¡c thÃ´ng tin tá»« dá»¯ liá»‡u nÃ y nhÆ°: Machine Learning Translation, Sentiment Analysis, Name Entity Recognition, Part of Speech, Question and Answering, Text Summarization, Text Generation,â€¦. Tá»« nhá»¯ng thuáº­t toÃ¡n nÃ y chÃºng ta cÃ³ thá»ƒ phÃ¡t triá»ƒn Ä‘Æ°á»£c nhá»¯ng á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c khÃ¡c nhau.
â–¶ï¸ Trong Ä‘Ã³ Text Summarization lÃ  phÆ°Æ¡ng phÃ¡p quan trá»ng nháº±m tá»•ng há»£p ná»™i dung cá»§a má»™t vÄƒn báº£n dÃ i thÃ nh má»™t vÄƒn báº£n nhá» gá»n nhÆ°ng váº«n báº£o toÃ n Ä‘Æ°á»£c ná»™i dung chÃ­nh cá»§a cá»§a vÄƒn báº£n gá»‘c. Trong nghiÃªn cá»©u nÃ y hai báº¡n há»c viÃªn Deep Learning K1 lÃ  Thá»©c Äáº·ng vÃ  Trá»ng Hiáº¿u Ä‘Ã£ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh tÃ³m táº¯t vÄƒn báº£n tá»± Ä‘á»™ng (ATS - Automatic Text Summarization) vÃ  cho ra Ä‘á»i má»™t á»©ng dá»¥ng web há»¯u Ã­ch.
â–¶ï¸ Vá» lá»›p cÃ¡c mÃ´ hÃ¬nh Ã¡p dá»¥ng, dá»¯ liá»‡u vÃ  káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi táº¡i slide: https://docs.google.com/presentation/d/10hltPpkzHQ9otUaZunijWWbFddxPiEqa/edit?usp=sharing&ouid=102966915028274203909&rtpof=true&sd=true
â–¶ï¸ Káº¿t quáº£ web demo Ä‘Æ°á»£c tiáº¿n hÃ nh Ä‘á»‘i vá»›i má»™t sá»‘ bÃ i bÃ¡o thuá»™c nhiá»u lÄ©nh vá»±c khÃ¡c nhau nhÆ° Thá»ƒ Thao, Kinh Táº¿, ChÃ­nh Trá»‹, XÃ£ Há»™i tÆ°Æ¡ng Ä‘á»‘i chuáº©n xÃ¡c. CÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi káº¿t quáº£ demo táº¡i link: https://youtu.be/LBNWYvntjZ0 ----------------------------------------------------------------
â–¶ï¸ The internet boom and multimedia facilitate a generation of the immense amount of document data that is a precious resource but was not yet thoroughly mined. a variety of NLP tasks was particularly created to serve mining this information from this resource such as Machine Learning Translation, Sentiment Analysis, Named Entity Recognition, Part of Speech, Question and Answering, Text Summarization, Text Generation,â€¦. Based on those algorithms we can develop many applications in multidisciplinary.
â–¶ï¸ Text summarization is an important method towards summarize the main content of a long-form document to become a short form whereas still reserving the main content of the original article. In this research, two young researchers Thuc Dang and Trong Hieu developed Automatic Text Summarization and launched a useful web application.
â–¶ï¸ The algorithms, datasets, and evaluation reports were listed in the slide: https://docs.google.com/presentation/d/10hltPpkzHQ9otUaZunijWWbFddxPiEqa/edit?usp=sharing&ouid=102966915028274203909&rtpof=true&sd=true
â–¶ï¸ The web demo makes predictions in the several articles of diverse sectors such as sport, economy, politics, and society are accurate and promising as the below link: https://youtu.be/LBNWYvntjZ0","[Article Summarization - Final Project Deep Learning K1] English version in the last. Sá»± bÃ¹ng ná»• internet vÃ  truyá»n thÃ´ng Ä‘a phÆ°Æ¡ng tiá»‡n dáº«n tá»›i má»™t lÆ°á»£ng dá»¯ liá»‡u vÄƒn báº£n khá»•ng lá»“ lÃ  tÃ i nguyÃªn ráº¥t quÃ­ giÃ¡ nhÆ°ng chÆ°a Ä‘Æ°á»£c khai phÃ¡ háº¿t. CÃ³ ráº¥t nhiá»u tÃ¡c vá»¥ NLP khÃ¡c nhau Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ khai thÃ¡c thÃ´ng tin tá»« dá»¯ liá»‡u nÃ y nhÆ°: Machine Learning Translation, Sentiment Analysis, Name Entity Recognition, Part of Speech, Question and Answering, Text Summarization, Text Generation,â€¦. Tá»« nhá»¯ng thuáº­t toÃ¡n nÃ y chÃºng ta cÃ³ thá»ƒ phÃ¡t triá»ƒn Ä‘Æ°á»£c nhá»¯ng á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c khÃ¡c nhau. Trong Ä‘Ã³ Text Summarization lÃ  phÆ°Æ¡ng phÃ¡p quan trá»ng nháº±m tá»•ng há»£p ná»™i dung cá»§a má»™t vÄƒn báº£n dÃ i thÃ nh má»™t vÄƒn báº£n nhá» gá»n nhÆ°ng váº«n báº£o toÃ n Ä‘Æ°á»£c ná»™i dung chÃ­nh cá»§a cá»§a vÄƒn báº£n gá»‘c. Trong nghiÃªn cá»©u nÃ y hai báº¡n há»c viÃªn Deep Learning K1 lÃ  Thá»©c Äáº·ng vÃ  Trá»ng Hiáº¿u Ä‘Ã£ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh tÃ³m táº¯t vÄƒn báº£n tá»± Ä‘á»™ng (ATS - Automatic Text Summarization) vÃ  cho ra Ä‘á»i má»™t á»©ng dá»¥ng web há»¯u Ã­ch. Vá» lá»›p cÃ¡c mÃ´ hÃ¬nh Ã¡p dá»¥ng, dá»¯ liá»‡u vÃ  káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi táº¡i slide: https://docs.google.com/presentation/d/10hltPpkzHQ9otUaZunijWWbFddxPiEqa/edit?usp=sharing&ouid=102966915028274203909&rtpof=true&sd=true Káº¿t quáº£ web demo Ä‘Æ°á»£c tiáº¿n hÃ nh Ä‘á»‘i vá»›i má»™t sá»‘ bÃ i bÃ¡o thuá»™c nhiá»u lÄ©nh vá»±c khÃ¡c nhau nhÆ° Thá»ƒ Thao, Kinh Táº¿, ChÃ­nh Trá»‹, XÃ£ Há»™i tÆ°Æ¡ng Ä‘á»‘i chuáº©n xÃ¡c. CÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi káº¿t quáº£ demo táº¡i link: https://youtu.be/LBNWYvntjZ0 ---------------------------------------------------------------- The internet boom and multimedia facilitate a generation of the immense amount of document data that is a precious resource but was not yet thoroughly mined. a variety of NLP tasks was particularly created to serve mining this information from this resource such as Machine Learning Translation, Sentiment Analysis, Named Entity Recognition, Part of Speech, Question and Answering, Text Summarization, Text Generation,â€¦. Based on those algorithms we can develop many applications in multidisciplinary. Text summarization is an important method towards summarize the main content of a long-form document to become a short form whereas still reserving the main content of the original article. In this research, two young researchers Thuc Dang and Trong Hieu developed Automatic Text Summarization and launched a useful web application. The algorithms, datasets, and evaluation reports were listed in the slide: https://docs.google.com/presentation/d/10hltPpkzHQ9otUaZunijWWbFddxPiEqa/edit?usp=sharing&ouid=102966915028274203909&rtpof=true&sd=true The web demo makes predictions in the several articles of diverse sectors such as sport, economy, politics, and society are accurate and promising as the below link: https://youtu.be/LBNWYvntjZ0",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 5/2022 vÃ o trong comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 5/2022 vÃ o trong comment cá»§a post nÃ y.",,,,,
"Hi everyone,
LIVE NOW from Amazon Web Services Facebook page - the next episode of Learn with AWS Experts. In today's episodes, Donnie Prakoso, our Senior Developer Advocate, AWS will demo Amazon SageMaker Canvas and guide you how to build machine learning predictions without writing code. You can also ask the expert live questions. Donâ€™t miss out.
https://www.facebook.com/amazonwebservices/videos/985065088939549/","Hi everyone, LIVE NOW from Amazon Web Services Facebook page - the next episode of Learn with AWS Experts. In today's episodes, Donnie Prakoso, our Senior Developer Advocate, AWS will demo Amazon SageMaker Canvas and guide you how to build machine learning predictions without writing code. You can also ask the expert live questions. Donâ€™t miss out. https://www.facebook.com/amazonwebservices/videos/985065088939549/",,,,,
"xin chÃ o má»i ngÆ°á»i,  em Ä‘ang há»c Ä‘áº¿n bÃ i nÃ y https://www.youtube.com/watch?v=ChoV5h7tw5A...
trong khÃ³a DL cá»§a andrew Ng, em tháº¯c máº¯c lÃ  táº¡i sao trong bÃ i giáº£ng nÃ y cÃ ng nhá»¯ng layer sÃ¢u Ä‘áº±ng sau thÃ¬ cÃ¡i filter nÃ³ láº¡i cÃ ng nhÃ¬n rÃµ áº£nh hÆ¡n . Theo nhÆ° e hiá»ƒu thÃ¬ cÃ¡c feature map cÃ ng nhá»¯ng layer sau model  há»c cÃ ng phá»©c táº¡p thÃ¬ feature map cÃ ng kiá»ƒu khÃ´ng thá»ƒ nháº­n biáº¿t nÃ³ báº±ng máº¯t Ä‘Æ°á»£c,váº­y thÃ¬ Ã¡p filter vÃ o thÃ¬ nÃ³ cÅ©ng pháº£i há»c Ä‘Æ°á»£c nhá»¯ng thá»© khÃ³ hÃ¬nh dung nhÆ° áº£nh chá»© sao nÃ³ láº¡i há»c Ä‘c nhá»¯ng thá»© nhÃ¬n rÃµ nhÆ° trong video váº­y áº¡, mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em, em cáº£m Æ¡n","xin chÃ o má»i ngÆ°á»i, em Ä‘ang há»c Ä‘áº¿n bÃ i nÃ y https://www.youtube.com/watch?v=ChoV5h7tw5A... trong khÃ³a DL cá»§a andrew Ng, em tháº¯c máº¯c lÃ  táº¡i sao trong bÃ i giáº£ng nÃ y cÃ ng nhá»¯ng layer sÃ¢u Ä‘áº±ng sau thÃ¬ cÃ¡i filter nÃ³ láº¡i cÃ ng nhÃ¬n rÃµ áº£nh hÆ¡n . Theo nhÆ° e hiá»ƒu thÃ¬ cÃ¡c feature map cÃ ng nhá»¯ng layer sau model há»c cÃ ng phá»©c táº¡p thÃ¬ feature map cÃ ng kiá»ƒu khÃ´ng thá»ƒ nháº­n biáº¿t nÃ³ báº±ng máº¯t Ä‘Æ°á»£c,váº­y thÃ¬ Ã¡p filter vÃ o thÃ¬ nÃ³ cÅ©ng pháº£i há»c Ä‘Æ°á»£c nhá»¯ng thá»© khÃ³ hÃ¬nh dung nhÆ° áº£nh chá»© sao nÃ³ láº¡i há»c Ä‘c nhá»¯ng thá»© nhÃ¬n rÃµ nhÆ° trong video váº­y áº¡, mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em, em cáº£m Æ¡n",,,,,
"Xin hÆ°á»›ng lÃ m nháº­n diá»‡n hÃ ng Ã´ chá»¯ sá»‘ viáº¿t tay trong sheet.
Hi cÃ¡c bÃ¡c, e Ä‘ang tÃ¬m hiá»ƒu vÃ  lÃ m 1 bÃ i toÃ¡n nhÆ° sau.
Ã TÆ¯á»NG
CÃ³ 1 sheet golf score vÃ  muá»‘n láº¥y 1 hÃ ng chá»¯ sá»‘ Ä‘á»ƒ Ä‘iá»n vÃ o á»©ng dá»¥ng khÃ¡c. Thay vÃ¬ báº±ng cÆ¡m thÃ¬ báº±ng nháº­n diá»‡n OCR, má»—i Ã´ lÃ  1 sá»‘, cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng nhÆ° Ä‘ang bÃª dÃ£y sá»‘ káº¿t quáº£ tá»« áº£nh vÃ o app khÃ¡c cÃ³ khung tÆ°Æ¡ng tá»±
CÃCH LÃ€M E ÄANG NGHÄ¨ RA
Chá»¥p hÃ¬nh (OK)
Cho user váº½ Ã´ Ä‘á» Ä‘á»ƒ giá»›i háº¡n vÃ¹ng nháº­n diá»‡n vÃ  xÃ³a vÃ¹ng khÃ¡c (OK)
Nháº­n diá»‡n (chÆ°a biáº¿t lÃ m)
        - Nháº­n diá»‡n sá»‘ viáº¿t tay  
        - TÃ¡ch cÃ¡c sá»‘ riÃªng dá»±a vÃ o cÃ¡c Ã´ mÃ  chÃºng Ä‘ang á»Ÿ
    4. ÄÆ°a ra káº¿t quáº£ (chÆ°a biáº¿t lÃ m)

NgoÃ i ra cÃ²n cÃ³ case viáº¿t tay trong 1 Ã´ cÃ³ ng viáº¿t nhÆ° áº£nh 2, e muá»‘n xÃ³a cÃ¡i chá»¯ nhá» Ä‘i giá»¯ láº¡i sá»‘ 8

Káº¾T QUáº¢ MONG MUá»N
Buget/ thá»i gian/ Ä‘á»™ chÃ­nh xÃ¡c -> Æ°u tiÃªn Ä‘á»™ chÃ­nh xÃ¡c nháº¥t
á» má»©c Ä‘á»™ chá»¯ xáº¥u vá»«a pháº£i thÃ¬ cÃ³ nháº­n Ä‘Ãºng dc khoáº£ng 80% chá»¯ sá»‘/ dÃ£y
Náº¿u cÃ³ dá»‹ch vá»¥ cloud nÃ o dáº¡ng má»³ Äƒn liá»n nhÆ° cá»§a GCP, AWS cÃ ng tá»‘t
PhÃ¢n cÃ¡ch Ä‘Ãºng dc theo Ã´

CÃC BÃC CÃ“ KINH NGHIá»†M HOáº¶C Ã TÆ¯á»NG HOáº¶C HÆ¯á»šNG LÃ€M XIN CHIA Sáºº CHO EM áº .
CÃM Æ N CÃC BÃC ","Xin hÆ°á»›ng lÃ m nháº­n diá»‡n hÃ ng Ã´ chá»¯ sá»‘ viáº¿t tay trong sheet. Hi cÃ¡c bÃ¡c, e Ä‘ang tÃ¬m hiá»ƒu vÃ  lÃ m 1 bÃ i toÃ¡n nhÆ° sau. Ã TÆ¯á»NG CÃ³ 1 sheet golf score vÃ  muá»‘n láº¥y 1 hÃ ng chá»¯ sá»‘ Ä‘á»ƒ Ä‘iá»n vÃ o á»©ng dá»¥ng khÃ¡c. Thay vÃ¬ báº±ng cÆ¡m thÃ¬ báº±ng nháº­n diá»‡n OCR, má»—i Ã´ lÃ  1 sá»‘, cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng nhÆ° Ä‘ang bÃª dÃ£y sá»‘ káº¿t quáº£ tá»« áº£nh vÃ o app khÃ¡c cÃ³ khung tÆ°Æ¡ng tá»± CÃCH LÃ€M E ÄANG NGHÄ¨ RA Chá»¥p hÃ¬nh (OK) Cho user váº½ Ã´ Ä‘á» Ä‘á»ƒ giá»›i háº¡n vÃ¹ng nháº­n diá»‡n vÃ  xÃ³a vÃ¹ng khÃ¡c (OK) Nháº­n diá»‡n (chÆ°a biáº¿t lÃ m) - Nháº­n diá»‡n sá»‘ viáº¿t tay - TÃ¡ch cÃ¡c sá»‘ riÃªng dá»±a vÃ o cÃ¡c Ã´ mÃ  chÃºng Ä‘ang á»Ÿ 4. ÄÆ°a ra káº¿t quáº£ (chÆ°a biáº¿t lÃ m) NgoÃ i ra cÃ²n cÃ³ case viáº¿t tay trong 1 Ã´ cÃ³ ng viáº¿t nhÆ° áº£nh 2, e muá»‘n xÃ³a cÃ¡i chá»¯ nhá» Ä‘i giá»¯ láº¡i sá»‘ 8 Káº¾T QUáº¢ MONG MUá»N Buget/ thá»i gian/ Ä‘á»™ chÃ­nh xÃ¡c -> Æ°u tiÃªn Ä‘á»™ chÃ­nh xÃ¡c nháº¥t á» má»©c Ä‘á»™ chá»¯ xáº¥u vá»«a pháº£i thÃ¬ cÃ³ nháº­n Ä‘Ãºng dc khoáº£ng 80% chá»¯ sá»‘/ dÃ£y Náº¿u cÃ³ dá»‹ch vá»¥ cloud nÃ o dáº¡ng má»³ Äƒn liá»n nhÆ° cá»§a GCP, AWS cÃ ng tá»‘t PhÃ¢n cÃ¡ch Ä‘Ãºng dc theo Ã´ CÃC BÃC CÃ“ KINH NGHIá»†M HOáº¶C Ã TÆ¯á»NG HOáº¶C HÆ¯á»šNG LÃ€M XIN CHIA Sáºº CHO EM áº . CÃM Æ N CÃC BÃC",,,,,
"ChÃ o anh em. HÃ´m nay chÃºng ta sáº½ cÃ¹ng nhau nghiÃªn cá»©u phÆ°Æ¡ng phÃ¡p vÃ  thá»­ lÃ m bÃ i toÃ¡n in-store heatmap cÃ¹ng Yolov4 nhÃ©.
ÄÃ¢y lÃ  má»™t váº¥n Ä‘á» ráº¥t há»¯u Ã­ch, hi vá»ng giÃºp Ä‘Æ°á»£c anh em!","ChÃ o anh em. HÃ´m nay chÃºng ta sáº½ cÃ¹ng nhau nghiÃªn cá»©u phÆ°Æ¡ng phÃ¡p vÃ  thá»­ lÃ m bÃ i toÃ¡n in-store heatmap cÃ¹ng Yolov4 nhÃ©. ÄÃ¢y lÃ  má»™t váº¥n Ä‘á» ráº¥t há»¯u Ã­ch, hi vá»ng giÃºp Ä‘Æ°á»£c anh em!",,,,,
"Xin chÃ o má»i ngÆ°á»i,
Em Ä‘ang cÃ³ 1 bÃ i táº­p lá»›n nhÆ°ng chÆ°a biáº¿t pháº£i báº¯t Ä‘áº§u tháº¿ nÃ o ( Ä‘Ã¢y lÃ  láº§n Ä‘áº§u em tiáº¿p xÃºc vá»›i data dáº¡ng nÃ y )
Tá»•ng Quan data em tÃ¬m hiá»ƒu Ä‘Æ°á»£c :
- Data lÃ  má»™t chuá»—i thá»i gian tÃ­nh báº±ng giÃ¢y cÃ³ 3 trá»¥c x,y,z cho biáº¿t hÃ nh Ä‘á»™ng (label) cá»§a 1 ngÆ°á»i trong 1 khoáº£ng thá»i gian
- TÃªn file : lÃ  thá»i Ä‘iá»ƒm 1 ngÆ°á»i báº¯t Ä‘áº§u theo format
[Accelerometer-[YYYY - MM - DD - Hour - Min - Sec]-[Label]-[Male/Female][ID]
VD : Accelerometer-2011-04-11-13-28-18-brush_teeth-f1
- Sensor hoáº¡t Ä‘á»™ng lÃºc 11/4/2011 vÃ o lÃºc 13:28:18 vá»›i hÃ nh Ä‘á»™ng Ä‘Ã¡nh rÄƒng thá»±c hiá»‡n bá»Ÿi phá»¥ ná»¯ 1
- Data lÃ  file txt cÃ³ 3 cá»™t má»—i cá»™t tÆ°Æ¡ng á»©ng x,y,z sá»‘ dÃ²ng tÆ°Æ¡ng á»©ng vá»›i range thá»i gian thá»±c hiá»‡n hÃ nh Ä‘á»™ng Ä‘Ã³ nhÆ° hÃ¬nh dÆ°á»›i lÃ  hÆ¡n 250 dÃ²ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng hÆ¡n 250 giÃ¢y
Má»¥c tiÃªu : Giáº£m chiá»u cÃ¡c dá»¯ liá»‡u trÃªn vÃ  cluster cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u nÃ y vÃ  dá»± Ä‘oÃ¡n Label
Hint tá»« tháº§y : CÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u chÃ­nh lÃ  má»—i file txt, sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n ( hÃ m thÆ° viá»‡n ) giáº£m chiá»u dá»¯ liá»‡u nhÆ° PCA, t-SNE, AutoEncoder,... VÃ  dÃ¹ng cÃ¡c bÃ i toÃ¡n cluster vá»›i K=14 tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 14 label
Má»i ngÆ°á»i ai cÃ³ tÃ i liá»‡u hoáº·c project gáº§n giá»‘ng vá»›i bÃ i toÃ¡n trÃªn cÃ³ thá»ƒ cho em tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡, cÃ´ng Ä‘oáº¡n chuáº©n bá»‹ data vÃ  split dataset cÅ©ng nhÆ° ma tráº­n data cá»§a bÃ i toÃ¡n sáº½ nhÆ° tháº¿ nÃ o vá»›i áº¡.
Em xin cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c vÃ  giÃºp Ä‘á»¡ áº¡
Dataset cá»§a bÃ i : https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer","Xin chÃ o má»i ngÆ°á»i, Em Ä‘ang cÃ³ 1 bÃ i táº­p lá»›n nhÆ°ng chÆ°a biáº¿t pháº£i báº¯t Ä‘áº§u tháº¿ nÃ o ( Ä‘Ã¢y lÃ  láº§n Ä‘áº§u em tiáº¿p xÃºc vá»›i data dáº¡ng nÃ y ) Tá»•ng Quan data em tÃ¬m hiá»ƒu Ä‘Æ°á»£c : - Data lÃ  má»™t chuá»—i thá»i gian tÃ­nh báº±ng giÃ¢y cÃ³ 3 trá»¥c x,y,z cho biáº¿t hÃ nh Ä‘á»™ng (label) cá»§a 1 ngÆ°á»i trong 1 khoáº£ng thá»i gian - TÃªn file : lÃ  thá»i Ä‘iá»ƒm 1 ngÆ°á»i báº¯t Ä‘áº§u theo format [Accelerometer-[YYYY - MM - DD - Hour - Min - Sec]-[Label]-[Male/Female][ID] VD : Accelerometer-2011-04-11-13-28-18-brush_teeth-f1 - Sensor hoáº¡t Ä‘á»™ng lÃºc 11/4/2011 vÃ o lÃºc 13:28:18 vá»›i hÃ nh Ä‘á»™ng Ä‘Ã¡nh rÄƒng thá»±c hiá»‡n bá»Ÿi phá»¥ ná»¯ 1 - Data lÃ  file txt cÃ³ 3 cá»™t má»—i cá»™t tÆ°Æ¡ng á»©ng x,y,z sá»‘ dÃ²ng tÆ°Æ¡ng á»©ng vá»›i range thá»i gian thá»±c hiá»‡n hÃ nh Ä‘á»™ng Ä‘Ã³ nhÆ° hÃ¬nh dÆ°á»›i lÃ  hÆ¡n 250 dÃ²ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng hÆ¡n 250 giÃ¢y Má»¥c tiÃªu : Giáº£m chiá»u cÃ¡c dá»¯ liá»‡u trÃªn vÃ  cluster cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u nÃ y vÃ  dá»± Ä‘oÃ¡n Label Hint tá»« tháº§y : CÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u chÃ­nh lÃ  má»—i file txt, sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n ( hÃ m thÆ° viá»‡n ) giáº£m chiá»u dá»¯ liá»‡u nhÆ° PCA, t-SNE, AutoEncoder,... VÃ  dÃ¹ng cÃ¡c bÃ i toÃ¡n cluster vá»›i K=14 tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 14 label Má»i ngÆ°á»i ai cÃ³ tÃ i liá»‡u hoáº·c project gáº§n giá»‘ng vá»›i bÃ i toÃ¡n trÃªn cÃ³ thá»ƒ cho em tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡, cÃ´ng Ä‘oáº¡n chuáº©n bá»‹ data vÃ  split dataset cÅ©ng nhÆ° ma tráº­n data cá»§a bÃ i toÃ¡n sáº½ nhÆ° tháº¿ nÃ o vá»›i áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c vÃ  giÃºp Ä‘á»¡ áº¡ Dataset cá»§a bÃ i : https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh xin Ä‘Æ°á»£c chia sáº» code Ä‘áº¡t top 2 cuá»™c thi BKAI-NAVER task gesture. Má»i má»i ngÆ°á»i tham kháº£o áº¡ ğŸ˜„
Link code: https://github.com/hungk64it1x/body-segmentation-and-gesture-recognition
Link cuá»™c thi: https://bitly.com.vn/yt3m0a","ChÃ o má»i ngÆ°á»i, mÃ¬nh xin Ä‘Æ°á»£c chia sáº» code Ä‘áº¡t top 2 cuá»™c thi BKAI-NAVER task gesture. Má»i má»i ngÆ°á»i tham kháº£o áº¡ Link code: https://github.com/hungk64it1x/body-segmentation-and-gesture-recognition Link cuá»™c thi: https://bitly.com.vn/yt3m0a",,,,,
ChÃ o má»i ngÆ°á»i. Máº¥y hÃ´m nay mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu YOLOv5 vÃ  bÃ¢y giá» mÃ¬nh cÃ³ má»™t sá»‘ váº¥n Ä‘á» khÃ´ng hiá»ƒu. Má»i ngÆ°á»i cÃ³ thá»ƒ dá»«ng láº¡i má»™t chÃºt giÃºp mÃ¬nh giáº£i thÃ­ch lÃ  máº¥y cÃ¡i thÃ´ng sá»‘ kiá»ƒu 4096 á»Ÿ hÃ¬nh dÆ°á»›i lÃ  lÃ m sao ra Ä‘Æ°á»£c khÃ´ng?,ChÃ o má»i ngÆ°á»i. Máº¥y hÃ´m nay mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu YOLOv5 vÃ  bÃ¢y giá» mÃ¬nh cÃ³ má»™t sá»‘ váº¥n Ä‘á» khÃ´ng hiá»ƒu. Má»i ngÆ°á»i cÃ³ thá»ƒ dá»«ng láº¡i má»™t chÃºt giÃºp mÃ¬nh giáº£i thÃ­ch lÃ  máº¥y cÃ¡i thÃ´ng sá»‘ kiá»ƒu 4096 á»Ÿ hÃ¬nh dÆ°á»›i lÃ  lÃ m sao ra Ä‘Æ°á»£c khÃ´ng?,,,,,
"Dáº¡ em chÃ o m.n. em Ä‘ang thá»±c hiá»‡n text mining trÃªn RStudio. Em thá»±c hiá»‡n chuyá»ƒn cÃ¡c file PDF sang dáº¡ng text vÃ  phÃ¢n loáº¡i chÃºng.
Em Ä‘Ã£ lÃ m sáº¡ch cÃ¡c dáº¥m cháº¥m cÃ¢u vÃ  khoáº£ng tráº¯ng trong cÃ¢u. NhÆ°ng Ä‘áº¿n pháº§n loáº¡i bá» sá»± thÆ°a thá»›t cá»§a tá»« Ä‘á»ƒ tiáº¿n Ä‘áº¿n phÃ¢n loáº¡i, em sá»­ dá»¥ng Ä‘oáº¡n code trong hÃ¬nh vÃ  bá»‹ bÃ¡o lá»—i nÃ y:
""Error in gsub(sprintf(""(*UCP)\\b(%s)\\b"", paste(sort(words, decreasing = TRUE), :
input string 135 is invalid UTF-8""
Em Ä‘Ã£ cÃ i thÆ° viá»‡n UTF-8 vÃ  tÃ¬m má»™t sá»‘ cÃ¡ch fix nhÆ°ng váº«n chÆ°a kháº¯c phá»¥c Ä‘c. Em chÆ°a tÃ¬m hiá»ƒu Ä‘c nhiá»u vá» R nÃªn mong Ä‘c cÃ¡c ac há»— trá»£ áº¡. Em cáº£m Æ¡n áº¡","Dáº¡ em chÃ o m.n. em Ä‘ang thá»±c hiá»‡n text mining trÃªn RStudio. Em thá»±c hiá»‡n chuyá»ƒn cÃ¡c file PDF sang dáº¡ng text vÃ  phÃ¢n loáº¡i chÃºng. Em Ä‘Ã£ lÃ m sáº¡ch cÃ¡c dáº¥m cháº¥m cÃ¢u vÃ  khoáº£ng tráº¯ng trong cÃ¢u. NhÆ°ng Ä‘áº¿n pháº§n loáº¡i bá» sá»± thÆ°a thá»›t cá»§a tá»« Ä‘á»ƒ tiáº¿n Ä‘áº¿n phÃ¢n loáº¡i, em sá»­ dá»¥ng Ä‘oáº¡n code trong hÃ¬nh vÃ  bá»‹ bÃ¡o lá»—i nÃ y: ""Error in gsub(sprintf(""(*UCP)\\b(%s)\\b"", paste(sort(words, decreasing = TRUE), : input string 135 is invalid UTF-8"" Em Ä‘Ã£ cÃ i thÆ° viá»‡n UTF-8 vÃ  tÃ¬m má»™t sá»‘ cÃ¡ch fix nhÆ°ng váº«n chÆ°a kháº¯c phá»¥c Ä‘c. Em chÆ°a tÃ¬m hiá»ƒu Ä‘c nhiá»u vá» R nÃªn mong Ä‘c cÃ¡c ac há»— trá»£ áº¡. Em cáº£m Æ¡n áº¡",,,,,
Xin giá»›i thiá»‡u cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n viá»‡c phá»ng váº¥n vá» Machine Learning á»Ÿ cÃ¡c cÃ´ng ty FAANG. https://rebrand.ly/mldesignbook Báº¡n cÃ³ thá»ƒ Ä‘á»c sample á»Ÿ Ä‘Ã¢y: https://rebrand.ly/MachineLearningDesignShort,Xin giá»›i thiá»‡u cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n viá»‡c phá»ng váº¥n vá» Machine Learning á»Ÿ cÃ¡c cÃ´ng ty FAANG. https://rebrand.ly/mldesignbook Báº¡n cÃ³ thá»ƒ Ä‘á»c sample á»Ÿ Ä‘Ã¢y: https://rebrand.ly/MachineLearningDesignShort,,,,,
"em chÃ o mn, em Ä‘ang há»c vá» Perceptron thÃ¬ tháº¥y máº¯c Ä‘oáº¡n nÃ y.
bÃ¬nh thÆ°á»ng náº¿u data Ä‘Æ¡n giáº£n Ã­t chiá»u vÃ  dá»… visualize thÃ¬ sáº½ biáº¿t lÃ  nhÃ³m nÃ o bÃªn trÃªn nhÃ³m nÃ o bÃªn dÆ°á»›i, nhÆ°ng vá»›i data lá»›n vÃ  Ä‘a chiá»u hÆ¡n thÃ¬ ko thá»ƒ visual Ä‘Æ°á»£c. Giáº£ sá»­ ban Ä‘áº§u cá»© gÃ¡n nhÃ£n x lÃ  +1 cÃ²n tam giÃ¡c lÃ  -1 nhÆ° kia, vÃ  giáº£ sá»­ bÆ°á»›c Ä‘áº§u tiÃªn mÃ¡y chá»n ra para ngáº«u nhiÃªn lÃ  (0 -1 -1) nhÆ° kia thÃ¬ kia tÃ­nh tÃ­ch vÃ´ hÆ°á»›ng sáº½ cho ra giÃ¡ trá»‹ lÃ  trÃ¡i dáº¥u vá»›i label, tá»©c lÃ  Ä‘iá»ƒm x tá»a Ä‘á»™ (1,1) bá»‹ misclassified (nhÆ°ng thá»±c ra lÃ  true classified)
Em muá»‘n há»i lÃ  lÃ m sao mÃ¡y nÃ³ phÃ¢n biá»‡t Ä‘Æ°á»£c Ä‘á»ƒ chá»n para ban Ä‘áº§u phÃ¹ há»£p vá»›i cÃ¡i label cá»§a data áº¡? hay lÃ  nÃ³ tháº­t sá»± sáº½ há»™i tá»¥ vá» para tá»‘t nháº¥t Ä‘Æ°á»£c dÃ¹ para ban Ä‘áº§u cÃ³ nhÆ° nÃ o áº¡?
cÃ¢u 2 lÃ  vá» pháº§n chá»©ng minh há»™i tá»¥, vÃ¬ sao láº¡i cÃ³ thá»ƒ Ä‘áº¿n 1 Ä‘iá»ƒm ko cÃ²n Ä‘iá»ƒm nÃ o bá»‹ phÃ¢n lá»—i áº¡? náº¿u 2 class data bá»‹ overlap nhau thÃ¬ váº«n cÃ³ thá»ƒ cÃ³ Ä‘iá»ƒm bá»‹ phÃ¢n lá»—i chá»© áº¡?
Em cáº£m Æ¡n!","em chÃ o mn, em Ä‘ang há»c vá» Perceptron thÃ¬ tháº¥y máº¯c Ä‘oáº¡n nÃ y. bÃ¬nh thÆ°á»ng náº¿u data Ä‘Æ¡n giáº£n Ã­t chiá»u vÃ  dá»… visualize thÃ¬ sáº½ biáº¿t lÃ  nhÃ³m nÃ o bÃªn trÃªn nhÃ³m nÃ o bÃªn dÆ°á»›i, nhÆ°ng vá»›i data lá»›n vÃ  Ä‘a chiá»u hÆ¡n thÃ¬ ko thá»ƒ visual Ä‘Æ°á»£c. Giáº£ sá»­ ban Ä‘áº§u cá»© gÃ¡n nhÃ£n x lÃ  +1 cÃ²n tam giÃ¡c lÃ  -1 nhÆ° kia, vÃ  giáº£ sá»­ bÆ°á»›c Ä‘áº§u tiÃªn mÃ¡y chá»n ra para ngáº«u nhiÃªn lÃ  (0 -1 -1) nhÆ° kia thÃ¬ kia tÃ­nh tÃ­ch vÃ´ hÆ°á»›ng sáº½ cho ra giÃ¡ trá»‹ lÃ  trÃ¡i dáº¥u vá»›i label, tá»©c lÃ  Ä‘iá»ƒm x tá»a Ä‘á»™ (1,1) bá»‹ misclassified (nhÆ°ng thá»±c ra lÃ  true classified) Em muá»‘n há»i lÃ  lÃ m sao mÃ¡y nÃ³ phÃ¢n biá»‡t Ä‘Æ°á»£c Ä‘á»ƒ chá»n para ban Ä‘áº§u phÃ¹ há»£p vá»›i cÃ¡i label cá»§a data áº¡? hay lÃ  nÃ³ tháº­t sá»± sáº½ há»™i tá»¥ vá» para tá»‘t nháº¥t Ä‘Æ°á»£c dÃ¹ para ban Ä‘áº§u cÃ³ nhÆ° nÃ o áº¡? cÃ¢u 2 lÃ  vá» pháº§n chá»©ng minh há»™i tá»¥, vÃ¬ sao láº¡i cÃ³ thá»ƒ Ä‘áº¿n 1 Ä‘iá»ƒm ko cÃ²n Ä‘iá»ƒm nÃ o bá»‹ phÃ¢n lá»—i áº¡? náº¿u 2 class data bá»‹ overlap nhau thÃ¬ váº«n cÃ³ thá»ƒ cÃ³ Ä‘iá»ƒm bá»‹ phÃ¢n lá»—i chá»© áº¡? Em cáº£m Æ¡n!",,,,,
NgÃ y mai mÃ¬nh cÃ³ buá»•i nÃ³i chuyá»‡n cÃ¹ng nhiá»u chuyÃªn gia vá» ML in production. Má»i cÃ¡c báº¡n theo dÃµi.,NgÃ y mai mÃ¬nh cÃ³ buá»•i nÃ³i chuyá»‡n cÃ¹ng nhiá»u chuyÃªn gia vá» ML in production. Má»i cÃ¡c báº¡n theo dÃµi.,,,,,
"ChÃ o má»i ngÆ°á»i, theo e Ä‘Æ°á»£c biáº¿t thÃ¬ pháº£i split train-test set rá»“i má»›i normalization hoáº·c standardization. VÃ  test set pháº£i Ä‘Æ°á»£c normalize/standardize theo tham sá»‘ normalization/standardization cá»§a train set. Váº­y giá» náº¿u e chá»n normalization thÃ¬ khi normalize test set, thay vÃ¬ dÃ¹ng
x_norm = (x - min_train)/(max_train - min_train)
(Tá»©c, x_norm cÃ³ thá»ƒ < 0 hoáº·c > 1)
em dÃ¹ng
if x > max_train: x = max_train
elif x < min_train: x = min_train
else pass
x_norm = (x - min_train)/(max_train - min_train)
(Tá»©c, x_norm luÃ´n thuá»™c Ä‘oáº¡n [0,1])
thÃ¬ cÃ³ váº¥n Ä‘á» gÃ¬ ko áº¡? Cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i, theo e Ä‘Æ°á»£c biáº¿t thÃ¬ pháº£i split train-test set rá»“i má»›i normalization hoáº·c standardization. VÃ  test set pháº£i Ä‘Æ°á»£c normalize/standardize theo tham sá»‘ normalization/standardization cá»§a train set. Váº­y giá» náº¿u e chá»n normalization thÃ¬ khi normalize test set, thay vÃ¬ dÃ¹ng x_norm = (x - min_train)/(max_train - min_train) (Tá»©c, x_norm cÃ³ thá»ƒ < 0 hoáº·c > 1) em dÃ¹ng if x > max_train: x = max_train elif x < min_train: x = min_train else pass x_norm = (x - min_train)/(max_train - min_train) (Tá»©c, x_norm luÃ´n thuá»™c Ä‘oáº¡n [0,1]) thÃ¬ cÃ³ váº¥n Ä‘á» gÃ¬ ko áº¡? Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"[GÃ³c BERT]
MÃ¬nh dÃ¹ng PhoBERT cá»§a VinAI cho bÃ i toÃ¡n phÃ¢n loáº¡i sáº¯c thÃ¡i bÃ¬nh luáº­n cá»§a AIviVN. Káº¿t quáº£ hiá»‡n táº¡i 0.90849 public leaderboard, so vá»›i cao nháº¥t trÆ°á»›c Ä‘Ã³ lÃ  0.90087.
Má»™t sá»‘ ká»¹ thuáº­t mÃ¬nh hay dÃ¹ng Ä‘á»ƒ finetune Bert:
- Concat biá»ƒu diá»…n cá»§a token [CLS] cá»§a 4 layer cuá»‘i, (kinh nghiá»‡m thÃ¬ layer gáº§n cuá»‘i thÆ°á»ng lÃ  tá»‘t nháº¥t náº¿u chá»‰ muá»‘n láº¥y 1)
- Train kiá»ƒu fastai, freeze pháº§n pretrained trong epoch Ä‘áº§u Ä‘á»ƒ warmup rá»“i unfreeze train toÃ n bá»™.
- DÃ¹ng optimizer máº·c Ä‘á»‹nh AdamW vÃ  linear learning rate scheduler váº«n lÃ  tá»‘t nháº¥t.","[GÃ³c BERT] MÃ¬nh dÃ¹ng PhoBERT cá»§a VinAI cho bÃ i toÃ¡n phÃ¢n loáº¡i sáº¯c thÃ¡i bÃ¬nh luáº­n cá»§a AIviVN. Káº¿t quáº£ hiá»‡n táº¡i 0.90849 public leaderboard, so vá»›i cao nháº¥t trÆ°á»›c Ä‘Ã³ lÃ  0.90087. Má»™t sá»‘ ká»¹ thuáº­t mÃ¬nh hay dÃ¹ng Ä‘á»ƒ finetune Bert: - Concat biá»ƒu diá»…n cá»§a token [CLS] cá»§a 4 layer cuá»‘i, (kinh nghiá»‡m thÃ¬ layer gáº§n cuá»‘i thÆ°á»ng lÃ  tá»‘t nháº¥t náº¿u chá»‰ muá»‘n láº¥y 1) - Train kiá»ƒu fastai, freeze pháº§n pretrained trong epoch Ä‘áº§u Ä‘á»ƒ warmup rá»“i unfreeze train toÃ n bá»™. - DÃ¹ng optimizer máº·c Ä‘á»‹nh AdamW vÃ  linear learning rate scheduler váº«n lÃ  tá»‘t nháº¥t.",,,,,
"UPDATE post: nhá» gá»£i Ã½ cá»§a báº¡n XuÃ¢n Huy Nguyá»…n mÃ¬nh Ä‘Ã£ lÃ m Ä‘Æ°á»£c. Xin cáº£m Æ¡n.
MÃ¬nh xin há»i 1 váº¥n Ä‘á» hÆ¡i out of group nhÆ°ng chÆ°a biáº¿t há»i á»Ÿ Ä‘Ã¢u. CÃ³ báº¡n nÃ o biáº¿t cÃ¡ch Ä‘á»•i tÃªn file hÃ ng loáº¡t mÃ  cÃ³ háº­u tá»‘ lÃ  sá»‘ thá»© tá»± cÃ¡ch nhau n Ä‘Æ¡n vá»‹ khÃ´ng, vÃ  sá»‘ Ä‘áº§u tiÃªn cÃ³ thá»ƒ báº¯t Ä‘áº§u tá»« má»™t sá»‘ báº¥t ká»³.
VÃ­ dá»¥ mÃ¬nh cÃ³ folder chá»©a 100 file tÃªn lÃ  a_0, a_1, a_2, â€¦, a_99. Giá» mÃ¬nh muá»‘n Ä‘á»•i tÃªn táº¥t cáº£ cÃ¡c file trong folder thÃ nh b_20, b_24, b_28, b_32â€¦ cho Ä‘áº¿n háº¿t. Google mÃ£i chÆ°a ra cÃ¡ch. Xin nhá» giÃºp Ä‘á»¡. MÃ¬nh cáº£m Æ¡n nhiá»u.","UPDATE post: nhá» gá»£i Ã½ cá»§a báº¡n XuÃ¢n Huy Nguyá»…n mÃ¬nh Ä‘Ã£ lÃ m Ä‘Æ°á»£c. Xin cáº£m Æ¡n. MÃ¬nh xin há»i 1 váº¥n Ä‘á» hÆ¡i out of group nhÆ°ng chÆ°a biáº¿t há»i á»Ÿ Ä‘Ã¢u. CÃ³ báº¡n nÃ o biáº¿t cÃ¡ch Ä‘á»•i tÃªn file hÃ ng loáº¡t mÃ  cÃ³ háº­u tá»‘ lÃ  sá»‘ thá»© tá»± cÃ¡ch nhau n Ä‘Æ¡n vá»‹ khÃ´ng, vÃ  sá»‘ Ä‘áº§u tiÃªn cÃ³ thá»ƒ báº¯t Ä‘áº§u tá»« má»™t sá»‘ báº¥t ká»³. VÃ­ dá»¥ mÃ¬nh cÃ³ folder chá»©a 100 file tÃªn lÃ  a_0, a_1, a_2, â€¦, a_99. Giá» mÃ¬nh muá»‘n Ä‘á»•i tÃªn táº¥t cáº£ cÃ¡c file trong folder thÃ nh b_20, b_24, b_28, b_32â€¦ cho Ä‘áº¿n háº¿t. Google mÃ£i chÆ°a ra cÃ¡ch. Xin nhá» giÃºp Ä‘á»¡. MÃ¬nh cáº£m Æ¡n nhiá»u.",,,,,
"Hi má»i ngÆ°á»i.
Em Ä‘ang lÃ m 1 project vá» image classification vÃ  má»—i label cá»§a e chá»‰ cÃ³ 5 áº£nh. E Ä‘Ã£ thá»­ data augmentation vÃ  sá»­ dá»¥ng simple model nhÆ°ng váº«n bá»‹ overfit áº¡, cÃ²n náº¿u dÃ¹ng object detection thÃ¬ khÃ¡ chÃ­nh xÃ¡c nhÆ°ng láº¡i cáº§n manually object annotation vÃ  project cáº§n dá»… scale nÃªn hÆ°á»›ng nÃ y khÃ¡ khÃ³ triá»ƒn khai áº¡. KhÃ´ng biáº¿t vá»›i dataset Ã­t nhÆ° váº­y thÃ¬ cÃ³ cÃ¡ch nÃ o build Ä‘c model khÃ´ng bá»‹ overfitting vÃ  cÅ©ng ko bá»‹ underfiting khÃ´ng áº¡. Em cáº£m Æ¡n áº¡.","Hi má»i ngÆ°á»i. Em Ä‘ang lÃ m 1 project vá» image classification vÃ  má»—i label cá»§a e chá»‰ cÃ³ 5 áº£nh. E Ä‘Ã£ thá»­ data augmentation vÃ  sá»­ dá»¥ng simple model nhÆ°ng váº«n bá»‹ overfit áº¡, cÃ²n náº¿u dÃ¹ng object detection thÃ¬ khÃ¡ chÃ­nh xÃ¡c nhÆ°ng láº¡i cáº§n manually object annotation vÃ  project cáº§n dá»… scale nÃªn hÆ°á»›ng nÃ y khÃ¡ khÃ³ triá»ƒn khai áº¡. KhÃ´ng biáº¿t vá»›i dataset Ã­t nhÆ° váº­y thÃ¬ cÃ³ cÃ¡ch nÃ o build Ä‘c model khÃ´ng bá»‹ overfitting vÃ  cÅ©ng ko bá»‹ underfiting khÃ´ng áº¡. Em cáº£m Æ¡n áº¡.",,,,,
"Hi anh, chá»‹,
- Láº¡i lÃ  em Ä‘Ã¢y, Em lÃ m Ä‘á» tÃ i ""Loan Repayment Prediction Using Machine Learning Algorithms"" sau khi em nghiÃªn cá»©u nhá»¯ng phÆ°Æ¡ng phÃ¡p anh chá»‹ gÃ³p Ã½ kiáº¿n thÃ¬ káº¿t quáº£ sau khi thá»±c nghiá»‡m cá»§a em nhÆ° sau:
- Káº¿t quáº£ trÆ°á»›c Ä‘Ã³:




- Káº¿t quáº£ sau khi dÃ¹ng Random Undersampling vÃ  Oversampling:

P/S: Vá»›i cÃ¢u chÃ¢m ngÃ´n ""Há»c lÃ  chia sáº½""","Hi anh, chá»‹, - Láº¡i lÃ  em Ä‘Ã¢y, Em lÃ m Ä‘á» tÃ i ""Loan Repayment Prediction Using Machine Learning Algorithms"" sau khi em nghiÃªn cá»©u nhá»¯ng phÆ°Æ¡ng phÃ¡p anh chá»‹ gÃ³p Ã½ kiáº¿n thÃ¬ káº¿t quáº£ sau khi thá»±c nghiá»‡m cá»§a em nhÆ° sau: - Káº¿t quáº£ trÆ°á»›c Ä‘Ã³: - Káº¿t quáº£ sau khi dÃ¹ng Random Undersampling vÃ  Oversampling: P/S: Vá»›i cÃ¢u chÃ¢m ngÃ´n ""Há»c lÃ  chia sáº½""",,,,,
"[Just for fun] New way to design captcha questions LoL
Credit: https://twitter.com/knmnyn/status/1298804839485304833?s=21",[Just for fun] New way to design captcha questions LoL Credit: https://twitter.com/knmnyn/status/1298804839485304833?s=21,,,,,
"ChÃ o má»i ngÆ°á»i, em má»›i tÃ¬m hiá»ƒu ML, em Ä‘ang cÃ³ bÃ i toÃ¡n giáº£i captcha áº£nh nÃ y. TÃ­nh tá»•ng máº·t trÃªn
Em muá»‘n xÃ¡c Ä‘á»‹nh cÃ¡c máº·t(gÃ³c, cáº¡nh) cá»§a xÃºc xáº¯c tá»« Ä‘Ã³ tÃ­nh tá»•ng máº·t trÃªn cá»§a 2 xÃºc xáº¯c trong má»—i hÃ¬nh liá»‡u cÃ³ kháº£ thi khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, em má»›i tÃ¬m hiá»ƒu ML, em Ä‘ang cÃ³ bÃ i toÃ¡n giáº£i captcha áº£nh nÃ y. TÃ­nh tá»•ng máº·t trÃªn Em muá»‘n xÃ¡c Ä‘á»‹nh cÃ¡c máº·t(gÃ³c, cáº¡nh) cá»§a xÃºc xáº¯c tá»« Ä‘Ã³ tÃ­nh tá»•ng máº·t trÃªn cá»§a 2 xÃºc xáº¯c trong má»—i hÃ¬nh liá»‡u cÃ³ kháº£ thi khÃ´ng áº¡?",,,,,
"#textrecognition #labelize #labeltools
ChÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i e muá»‘n lÃ m 1 bÃ i toÃ¡n vá» nháº­n diá»‡n text trong áº£nh (áº£nh chá»‰ cÃ³ 1 dÃ²ng)
Váº¥n Ä‘á» cá»§a e bÃ¢y giá» lÃ  muá»‘n táº¡o label cho áº£nh thá»±c, tá»©c lÃ  táº¡o text cho áº£nh thá»±c. E Ä‘Ã£ táº¡o synthetic data tá»« text ra áº£nh, sau Ä‘Ã³ dÃ¹ng áº£nh synthetic Ä‘á»ƒ train, model cháº¡y tá»‘t, predict tá»‘t trÃªn áº£nh test cá»§a synthetic nhÆ°ng láº¡i khÃ´ng há» tá»‘t trÃªn áº£nh thá»±c. Váº­y nÃªn e muá»‘n labelize thÃªm áº£nh thá»±c Ä‘á»ƒ train xem káº¿t quáº£ ra sao.
HÃ¬nh dung lÃ  mÃ¬nh cÃ³ táº­p áº£nh cÃ³ chá»©a text (mÃ  chá»‰ cÃ³ 1 dÃ²ng). Má»¥c Ä‘Ã­ch cá»§a mÃ¬nh lÃ  predict Ä‘oáº¡n text trong áº£nh áº¥y (bÃ i toÃ¡n OCR). Äá»ƒ train bÃ i toÃ¡n nÃ y thÃ¬ cáº§n cÃ³ dataset lÃ  gá»“m cÃ³ áº£nh vÃ  text trong áº£nh Ä‘Ã³ (áº£nh vÃ  label). Hiá»‡n táº¡i mÃ¬nh chá»‰ cÃ³ áº£nh mÃ  chÆ°a biáº¿t cÃ¡ch nÃ o Ä‘á»ƒ cÃ³ thá»ƒ táº¡o file text (label cá»§a áº£nh Ä‘Ã³) 1 cÃ¡ch thuáº­n lá»£i vÃ  nhanh chÃ³ng. ÄÃ³ lÃ  cÃ¡i mÃ¬nh muá»‘n há»i vá» 1 tool nhÆ° tháº¿.
1 tool giá»‘ng nhÆ° kiá»ƒu captcha dÆ°á»›i Ä‘Ã¢y
NhÆ°ng hiá»‡n táº¡i e ko biáº¿t cÃ³ cÃ´ng cá»¥/tools nÃ o mÃ  cho phÃ©p mÃ¬nh dá»… dÃ ng, thuáº­n tiá»‡n trong viá»‡c táº¡o text label cho áº£nh thá»±c Ä‘á»ƒ lÃ m cÃ´ng viá»‡c text recognition khÃ´ng áº¡? E tÃ¬m trÃªn máº¡ng rá»“i mÃ  váº«n chÆ°a tháº¥y.
E xin cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i e muá»‘n lÃ m 1 bÃ i toÃ¡n vá» nháº­n diá»‡n text trong áº£nh (áº£nh chá»‰ cÃ³ 1 dÃ²ng) Váº¥n Ä‘á» cá»§a e bÃ¢y giá» lÃ  muá»‘n táº¡o label cho áº£nh thá»±c, tá»©c lÃ  táº¡o text cho áº£nh thá»±c. E Ä‘Ã£ táº¡o synthetic data tá»« text ra áº£nh, sau Ä‘Ã³ dÃ¹ng áº£nh synthetic Ä‘á»ƒ train, model cháº¡y tá»‘t, predict tá»‘t trÃªn áº£nh test cá»§a synthetic nhÆ°ng láº¡i khÃ´ng há» tá»‘t trÃªn áº£nh thá»±c. Váº­y nÃªn e muá»‘n labelize thÃªm áº£nh thá»±c Ä‘á»ƒ train xem káº¿t quáº£ ra sao. HÃ¬nh dung lÃ  mÃ¬nh cÃ³ táº­p áº£nh cÃ³ chá»©a text (mÃ  chá»‰ cÃ³ 1 dÃ²ng). Má»¥c Ä‘Ã­ch cá»§a mÃ¬nh lÃ  predict Ä‘oáº¡n text trong áº£nh áº¥y (bÃ i toÃ¡n OCR). Äá»ƒ train bÃ i toÃ¡n nÃ y thÃ¬ cáº§n cÃ³ dataset lÃ  gá»“m cÃ³ áº£nh vÃ  text trong áº£nh Ä‘Ã³ (áº£nh vÃ  label). Hiá»‡n táº¡i mÃ¬nh chá»‰ cÃ³ áº£nh mÃ  chÆ°a biáº¿t cÃ¡ch nÃ o Ä‘á»ƒ cÃ³ thá»ƒ táº¡o file text (label cá»§a áº£nh Ä‘Ã³) 1 cÃ¡ch thuáº­n lá»£i vÃ  nhanh chÃ³ng. ÄÃ³ lÃ  cÃ¡i mÃ¬nh muá»‘n há»i vá» 1 tool nhÆ° tháº¿. 1 tool giá»‘ng nhÆ° kiá»ƒu captcha dÆ°á»›i Ä‘Ã¢y NhÆ°ng hiá»‡n táº¡i e ko biáº¿t cÃ³ cÃ´ng cá»¥/tools nÃ o mÃ  cho phÃ©p mÃ¬nh dá»… dÃ ng, thuáº­n tiá»‡n trong viá»‡c táº¡o text label cho áº£nh thá»±c Ä‘á»ƒ lÃ m cÃ´ng viá»‡c text recognition khÃ´ng áº¡? E tÃ¬m trÃªn máº¡ng rá»“i mÃ  váº«n chÆ°a tháº¥y. E xin cáº£m Æ¡n áº¡.",#textrecognition	#labelize	#labeltools,,,,
"MÃ¬nh cháº¡y má»™t cÃ¡i captcha láº¥y source tá»« nguá»“n https://github.com/chxj1992/captcha_cracker , Captcha cÃ³ Ä‘á»‹nh dáº¡ng 280x160 vÃ  cÃ³ 6 kÃ­ tá»± , train 45k file vÃ  test 16,423 file.  trong file pack_data.py mÃ¬nh Ä‘Ã£ Ä‘á»•i
 classes = '12346789ABCDEFGHJMNPQRTUXYZ'
data = {'data': np.empty(shape=(0, 280, 160, 3), dtype=float), 'labels': np.empty(shape=(0, 1), dtype=int)}
NhÆ°ng khi cháº¡y file train.py thÃ¬ bá»‹ lá»—i nÃ y
    raise ValueError(str(e))
ValueError: Dimension 0 in both shapes must be equal, but are 165376 and 2688. Shapes are [165376,512] and [2688,512]. for 'Assign_8' (op: 'Assign') with input shapes: [165376,512], [2688,512].
báº¡n nÃ o sá»­a giÃºp mÃ¬nh lá»—i nÃ y cÃ¡i , Thank ","MÃ¬nh cháº¡y má»™t cÃ¡i captcha láº¥y source tá»« nguá»“n https://github.com/chxj1992/captcha_cracker , Captcha cÃ³ Ä‘á»‹nh dáº¡ng 280x160 vÃ  cÃ³ 6 kÃ­ tá»± , train 45k file vÃ  test 16,423 file. trong file pack_data.py mÃ¬nh Ä‘Ã£ Ä‘á»•i classes = '12346789ABCDEFGHJMNPQRTUXYZ' data = {'data': np.empty(shape=(0, 280, 160, 3), dtype=float), 'labels': np.empty(shape=(0, 1), dtype=int)} NhÆ°ng khi cháº¡y file train.py thÃ¬ bá»‹ lá»—i nÃ y raise ValueError(str(e)) ValueError: Dimension 0 in both shapes must be equal, but are 165376 and 2688. Shapes are [165376,512] and [2688,512]. for 'Assign_8' (op: 'Assign') with input shapes: [165376,512], [2688,512]. báº¡n nÃ o sá»­a giÃºp mÃ¬nh lá»—i nÃ y cÃ¡i , Thank",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m má»™t assignment vá» Machine Learning dataset, nhÆ°ng yÃªu cáº§u cá»§a tháº§y lÃ  khÃ´ng Ä‘Æ°á»£c dÃ¹ng cÃ¡c dataset Ä‘Ã£ public.
Phiá»n ac nÃ o cÃ³ dataset(file .csv) vÃ  source code(.py) cÃ³ thá»ƒ share cho em Ä‘Æ°á»£c khÃ´ng áº¡?
*Em cam Ä‘oan giá»¯ tÃ i liá»‡u máº­t vÃ  khÃ´ng share lung tung áº¡!
Dataset should contain a set of independent variables (3 or more) and a dependent variable.
*Dependent Variable: Variable which you are going to predict *Independent Variable: Variables that are used to predict the dependent variable. (Things that influence dependent variable) *Number of entries: No limit
Cáº£m Æ¡n mn Ä‘Ã£ Ä‘á»c bÃ i,","ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m má»™t assignment vá» Machine Learning dataset, nhÆ°ng yÃªu cáº§u cá»§a tháº§y lÃ  khÃ´ng Ä‘Æ°á»£c dÃ¹ng cÃ¡c dataset Ä‘Ã£ public. Phiá»n ac nÃ o cÃ³ dataset(file .csv) vÃ  source code(.py) cÃ³ thá»ƒ share cho em Ä‘Æ°á»£c khÃ´ng áº¡? *Em cam Ä‘oan giá»¯ tÃ i liá»‡u máº­t vÃ  khÃ´ng share lung tung áº¡! Dataset should contain a set of independent variables (3 or more) and a dependent variable. *Dependent Variable: Variable which you are going to predict *Independent Variable: Variables that are used to predict the dependent variable. (Things that influence dependent variable) *Number of entries: No limit Cáº£m Æ¡n mn Ä‘Ã£ Ä‘á»c bÃ i,",,,,,
"ChÃ o má»i ngÆ°á»i.
Em má»›i tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n dá»‹ch mÃ¡y vÃ  Ä‘ang muá»‘n xÃ¢y dá»±ng mÃ´ hÃ¬nh transformers. Má»i ngÆ°á»i cho em há»i lÃ  vá»›i tokenizer thÃ¬ mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng láº¡i tokenizer mÃ  cÃ³ cÃ¹ng thuáº­t toÃ¡n nhÆ° BPE cá»§a má»™t model khÃ¡c, hay lÃ  nÃªn tá»± train láº¡i tokenizer dá»±a trÃªn dá»¯ liá»‡u dá»‹ch cá»§a chÃ­nh mÃ¬nh thÃ´i áº¡.
VÃ  vá»›i má»™t bÃ i toÃ¡n dá»‹ch mÃ¡y cÃ³ pháº£i lÃ  cáº§n 2 tokenizer, má»™t cÃ¡i Ä‘á»ƒ encode vÃ  má»™t cÃ¡i Ä‘á»ƒ decode khÃ´ng áº¡.
Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp em thÃªm Ã­t gá»£i Ã½ vá»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c","ChÃ o má»i ngÆ°á»i. Em má»›i tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n dá»‹ch mÃ¡y vÃ  Ä‘ang muá»‘n xÃ¢y dá»±ng mÃ´ hÃ¬nh transformers. Má»i ngÆ°á»i cho em há»i lÃ  vá»›i tokenizer thÃ¬ mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng láº¡i tokenizer mÃ  cÃ³ cÃ¹ng thuáº­t toÃ¡n nhÆ° BPE cá»§a má»™t model khÃ¡c, hay lÃ  nÃªn tá»± train láº¡i tokenizer dá»±a trÃªn dá»¯ liá»‡u dá»‹ch cá»§a chÃ­nh mÃ¬nh thÃ´i áº¡. VÃ  vá»›i má»™t bÃ i toÃ¡n dá»‹ch mÃ¡y cÃ³ pháº£i lÃ  cáº§n 2 tokenizer, má»™t cÃ¡i Ä‘á»ƒ encode vÃ  má»™t cÃ¡i Ä‘á»ƒ decode khÃ´ng áº¡. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giÃºp em thÃªm Ã­t gá»£i Ã½ vá»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em Ä‘ang lÃ m 1 project vá» ML ( má»™t bÃ i toÃ¡n phÃ¢n loáº¡i 3 lá»›p). Hiá»‡n táº¡i bÆ°á»›c Ä‘áº§u lÃ  pháº£i xá»­ lÃ½ data thÃ´ Ä‘á»ƒ tÃ¬m ra Ä‘áº·c trÆ°ng mÃ  khÃ¡c biá»‡t giá»¯a cÃ¡c lá»›p Ä‘á»ƒ tÃ¬m mÃ´ hÃ¬nh phÃ¹ há»£p ( gá»i lÃ  phÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u EDA áº¡).
Em xin mÃ´ táº£ dá»¯ liá»‡u má»™t chÃºt, Ä‘áº¡i khÃ¡i nÃ³ gá»“m dá»¯ liá»‡u Ä‘Æ°á»£c ghi láº¡i liÃªn tá»¥c trong vÃ²ng 6 thÃ¡ng vÃ  nhÃ£n lá»›p cá»§a nÃ³. Trong má»—i thÃ¡ng Ä‘Ã³ bao gá»“m 10 trÆ°á»ng thuá»™c tÃ­nh khÃ¡c nhau ( dá»¯ liá»‡u bao gá»“m cáº£ numerical vÃ  categorical) => Quan sÃ¡t 10 trÆ°á»ng thuá»™c tÃ­nh Ä‘Ã³ trong 6 thÃ¡ng liÃªn tiáº¿p. Em Ä‘Ã£ thá»­ phÃ¢n tÃ­ch Ä‘Æ¡n biáº¿n (univariate analysis) sá»­ dá»¥ng má»™t sá»‘ biá»ƒu Ä‘á»“ nhÆ° box plot, smooth density plot , tÃ­nh mean, std, distribution,....(chá»‰ phÃ¢n tÃ­ch 1 trÆ°á»ng thuá»™c tÃ­nh qua cÃ¡c thÃ¡ng) nhÆ°ng váº«n chÆ°a phÃ¡t hiá»‡n ra Ä‘iá»ƒm khÃ¡c biá»‡t gÃ¬ tá»« dá»¯ liá»‡u
Váº­y e muá»‘n há»i cÃ¡c a/c lÃ  bÃ¢y giá» mÃ¬nh phÃ¢n tÃ­ch Ä‘a biáº¿n multivariate thÃ¬ mÃ¬nh phÃ¢n tÃ­ch cÃ³ nhá»¯ng kiá»ƒu pp nÃ o áº¡, vÃ  vá»›i dá»¯ liá»‡u nhÆ° kiá»ƒu bÃ i toÃ¡n cá»§a e (quan sÃ¡t trÆ°á»ng thuá»™c tÃ­nh trong 6 thÃ¡ng liÃªn tiáº¿p) thÃ¬ mÃ¬nh cÃ³ cÃ¡ch EDA Ä‘a biáº¿n nÃ o phÃ¹ há»£p Ä‘á»ƒ phÃ¢n tÃ­ch data ko áº¡.
Ráº¥t mong a/c ai Ä‘Ã£ lÃ m DE/DA/DS rá»“i cÃ³ thá»ƒ cho e lá»i khuyÃªn áº¡. Em cáº£m Æ¡n cÃ¡c a/c nhiá»u","Em chÃ o má»i ngÆ°á»i áº¡ Em Ä‘ang lÃ m 1 project vá» ML ( má»™t bÃ i toÃ¡n phÃ¢n loáº¡i 3 lá»›p). Hiá»‡n táº¡i bÆ°á»›c Ä‘áº§u lÃ  pháº£i xá»­ lÃ½ data thÃ´ Ä‘á»ƒ tÃ¬m ra Ä‘áº·c trÆ°ng mÃ  khÃ¡c biá»‡t giá»¯a cÃ¡c lá»›p Ä‘á»ƒ tÃ¬m mÃ´ hÃ¬nh phÃ¹ há»£p ( gá»i lÃ  phÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u EDA áº¡). Em xin mÃ´ táº£ dá»¯ liá»‡u má»™t chÃºt, Ä‘áº¡i khÃ¡i nÃ³ gá»“m dá»¯ liá»‡u Ä‘Æ°á»£c ghi láº¡i liÃªn tá»¥c trong vÃ²ng 6 thÃ¡ng vÃ  nhÃ£n lá»›p cá»§a nÃ³. Trong má»—i thÃ¡ng Ä‘Ã³ bao gá»“m 10 trÆ°á»ng thuá»™c tÃ­nh khÃ¡c nhau ( dá»¯ liá»‡u bao gá»“m cáº£ numerical vÃ  categorical) => Quan sÃ¡t 10 trÆ°á»ng thuá»™c tÃ­nh Ä‘Ã³ trong 6 thÃ¡ng liÃªn tiáº¿p. Em Ä‘Ã£ thá»­ phÃ¢n tÃ­ch Ä‘Æ¡n biáº¿n (univariate analysis) sá»­ dá»¥ng má»™t sá»‘ biá»ƒu Ä‘á»“ nhÆ° box plot, smooth density plot , tÃ­nh mean, std, distribution,....(chá»‰ phÃ¢n tÃ­ch 1 trÆ°á»ng thuá»™c tÃ­nh qua cÃ¡c thÃ¡ng) nhÆ°ng váº«n chÆ°a phÃ¡t hiá»‡n ra Ä‘iá»ƒm khÃ¡c biá»‡t gÃ¬ tá»« dá»¯ liá»‡u Váº­y e muá»‘n há»i cÃ¡c a/c lÃ  bÃ¢y giá» mÃ¬nh phÃ¢n tÃ­ch Ä‘a biáº¿n multivariate thÃ¬ mÃ¬nh phÃ¢n tÃ­ch cÃ³ nhá»¯ng kiá»ƒu pp nÃ o áº¡, vÃ  vá»›i dá»¯ liá»‡u nhÆ° kiá»ƒu bÃ i toÃ¡n cá»§a e (quan sÃ¡t trÆ°á»ng thuá»™c tÃ­nh trong 6 thÃ¡ng liÃªn tiáº¿p) thÃ¬ mÃ¬nh cÃ³ cÃ¡ch EDA Ä‘a biáº¿n nÃ o phÃ¹ há»£p Ä‘á»ƒ phÃ¢n tÃ­ch data ko áº¡. Ráº¥t mong a/c ai Ä‘Ã£ lÃ m DE/DA/DS rá»“i cÃ³ thá»ƒ cho e lá»i khuyÃªn áº¡. Em cáº£m Æ¡n cÃ¡c a/c nhiá»u",,,,,
"[Deep learning for Candlestick - Patterns recognition in Financial market]
ÄÃ¢y lÃ  má»™t project khÃ¡ ná»•i báº­t mÃ  hai báº¡n sinh viÃªn Trá»ng Duy vÃ  Äá»©c Quang cá»§a Deep Learning K1 Ä‘Ã£ thá»±c hiá»‡n vá» Ä‘á» tÃ i nháº­n dáº¡ng máº«u biá»ƒu Ä‘á»“ Ä‘á»‘i vá»›i thá»‹ trÆ°á»ng chá»©ng khoÃ¡n.
1. Äáº·t váº¥n Ä‘á»:
Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n luÃ´n tiá»m áº©n rá»§i ro cao Ä‘á»‘i vá»›i nhá»¯ng nhÃ  Ä‘áº§u tÆ°. CÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau trong há»c mÃ¡y vÃ  kinh táº¿ lÆ°á»£ng Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  dá»± Ä‘oÃ¡n cá»• phiáº¿u trong ngáº¯n háº¡n vÃ  dÃ i háº¡n. Trong Ä‘Ã³ kÄ© thuáº­t phÃ¢n tÃ­ch máº«u cá»• phiáº¿u lÃ  má»™t trong nhá»¯ng kÄ© thuáº­t Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ Ä‘Æ°á»£c cÃ¡c nhÃ  Ä‘áº§u tÆ° thá»±c hiá»‡n.
ThÃ´ng thÆ°á»ng quÃ¡ trÃ¬nh nháº­n diá»‡n máº«u lÃ  má»™t cÃ´ng viá»‡c Ä‘Ã²i há»i sá»± tinh tÆ°á»ng vÃ  kinh nghiá»‡m chuyÃªn sÃ¢u tá»« chuyÃªn gia. Do Ä‘Ã³ khÃ³ cÃ³ thá»ƒ large scale trÃªn sá»‘ lÆ°á»£ng lá»›n vÃ i trÄƒm, hoáº·c vÃ i ngÃ n cá»• phiáº¿u. Trong nghiÃªn cá»©u nÃ y, hai báº¡n há»c viÃªn cá»§a Deep Learning K1 lÃ  Trá»ng Duy vÃ  Äá»©c Quang Ä‘Ã£ xÃ¢y dá»±ng má»™t cÃ¡ch tiáº¿p cáº­n má»›i sá»­ dá»¥ng bÃ i toÃ¡n computer vision trong nháº­n dáº¡ng máº«u cá»• phiáº¿u vÃ  Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao so vá»›i cÃ¡c thuáº­t toÃ¡n hiá»‡n táº¡i.
2. PhÆ°Æ¡ng phÃ¡p:
2.1. Táº­p dataset
Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c phá»¥c vá»¥ cho trá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam nÃªn cÃ¡c máº«u Ä‘Æ°á»£c lá»±a chá»n lÃ  nhá»¯ng pattern giao dá»‹ch cá»§a 30mÃ£ chá»©ng khoÃ¡n vÃ  30 chá»‰ sá»‘ngoáº¡i há»‘i cá»§a cÃ¡c cÃ¡c sÃ n chá»©ng khoÃ¡n Viá»‡t Nam. NghiÃªn cá»©u táº­p trung vÃ o phÃ¡t hiá»‡n pattern trong ngáº¯n háº¡n nÃªn cÃ¡c máº«u dá»¯ liá»‡u Ä‘Æ°á»£c lá»±a chá»n lÃ  5 phiÃªn giao dá»‹ch cá»§a 1 tuáº§n liÃªn tiáº¿p vá»›i kÃ­ch thÆ°á»›c bÆ°á»›c nháº£y lÃ  1 ngÃ y.  NghiÃªn cá»©u nÃ y táº­p trung vÃ o phÃ¡t hiá»‡n 4patterns chÃ­nh bao gá»“m:
- HSA: Head and Shoulder. Pattern nÃ y mÃ´ táº£ sá»± Ä‘áº£o ngÆ°á»£c cá»§a xu hÆ°á»›ng tÄƒng sang giáº£m vá»›i Ä‘á»‰nh Head á»Ÿ giá»¯a vÃ  hai Ä‘á»‰nh Shoulder tháº¥p hÆ¡n á»Ÿ hai bÃªn.
https://imgur.com/8uV2uWm.png
- IHSA: Inverted Head and Shoulders nháº±m mÃ´ táº£ sá»± Ä‘áº£o ngÆ°á»£c tá»« giáº£m sang tÄƒng vá»›i Ä‘á»‰nh Head á»Ÿ giá»¯a sáº½ tháº¥p hÆ¡n so vá»›i hai Ä‘á»‰nh Shoulder á»Ÿ hai bÃªn.
https://imgur.com/UVdHKP7.png
- DT: Double TopÄ‘Æ°á»£c hÃ¬nh thÃ nh tá»« hai Ä‘á»‰nh liÃªn tiáº¿p. Pháº§n giá»¯a hai Ä‘á»‰nh táº¡o thÃ nh hÃ¬nh chá»¯ U lá»™n ngÆ°á»£c. Hai Ä‘á»‰nh cÃ³ giÃ¡ trá»‹ gáº§n tÆ°Æ¡ng tá»± nhau vá»›i má»©c chÃªnh lá»‡ch Ã­t hÆ¡n 3%. Pháº§n Ä‘Ã¡y  giá»¯a hai Ä‘á»‰nh nhá» hÆ¡n Ä‘á»‰nh tá»« 10 â€“ 20%.
https://imgur.com/9ZruggJ.png
- DB: Double Bottom lÃ  Ä‘áº£o ngÆ°á»£c cá»§a Double Top.
https://imgur.com/mHImCMd.png
2.2. Xá»­ lÃ½ dá»¯ liá»‡u
Dá»¯ liá»‡u Ä‘Æ°á»£c chuyá»ƒn tá»« candle chart sang segmentation chart Ä‘á»ƒ háº¡n cháº¿ nhiá»…u vÃ  sau Ä‘Ã³ thá»±c hiá»‡n cÃ¡c bÆ°á»›c xá»­ lÃ½ nhÆ° hÃ¬nh 1:
https://imgur.com/CDYA8ZB.png
Step 1: Chá»n hai Ä‘iá»ƒm trong má»™t Ä‘oáº¡n trong biá»ƒu Ä‘á»“ segmentation.
Step 2: Chá»n má»™t Ä‘iá»ƒm khÃ¡c sao cho cÃ³ tá»•ng khoáº£ng cÃ¡ch lá»›n nháº¥t Ä‘á»ƒ báº¯t Ä‘áº§u vÃ  káº¿t thÃºc Ä‘oáº¡n Ä‘Ã£ chá»n.
Step 3: Láº·p láº¡i Step 1 vÃ  Step 2 cho Ä‘áº¿n khi cÃ³ Ä‘á»§ Ä‘iá»ƒm trong biá»ƒu Ä‘á»“ segmentation. Báº±ng cÃ¡ch nÃ y,cÃ¡c noise cÃ³ thá»ƒ Ä‘Æ°á»£c loáº¡i bá» vÃ  sáº½ thu Ä‘Æ°á»£c má»™t Ä‘á»“ thá»‹ Ä‘Æ°á»ng Ä‘Æ¡n giáº£n hÆ¡n.
2.3. Sinh máº«u ngáº«u nhiÃªn
2.3.1. Biáº¿n Ä‘á»•i theo trá»¥c x:
- Äá»‘i vá»›i pattern HSA vÃ  IHSA.
TÃ¡c giáº£ loáº¡i bá» nhá»¯ng máº«u Ä‘á»‘i vá»›i pattern HSA khÃ´ng há»£p lá»‡ (cÃ³ Ä‘á»‰nh thá»© 2 tháº¥p hÆ¡n hai Ä‘á»‰nh cÃ²n láº¡i). Sau Ä‘Ã³ táº¡o biáº¿n thá»ƒ ngáº«u nhiÃªn trÃªn nhá»¯ng máº«u Ä‘áº¡t tiÃªu chuáº©n báº±ng cÃ¡ch khá»Ÿi táº¡o ngáº«u nhiÃªn nhá»¯ng biáº¿n Ä‘á»™ng x_p1, x_p2, x_p3; xÃ³a Ä‘i má»™t Ä‘oáº¡n báº¥t kÃ¬ táº¡i vá»‹ trÃ­ Ä‘Ã¡y vÃ  thay tháº¿ má»™t Ä‘oáº¡n giÃ¡ ngáº«u nhiÃªn. Qui trÃ¬nh thá»±c hiá»‡n nhÆ° hÃ¬nh 2:
https://imgur.com/e39JwNh.png
PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n tÆ°Æ¡ng tá»± Ä‘á»‘i vá»›i cÃ¡c pattern IHSA.
- Äá»‘i vá»›i pattern DT vÃ  DB:
Lá»±a chá»n nhá»¯ng máº«u mÃ  cÃ³ 2 Ä‘á»‰nh gáº§n báº±ng nhau nhÆ°ng chÆ°a pháº£i lÃ  DT hoáº·c DB. Tiáº¿p theo so sÃ¡nh hai Ä‘á»‰nh, sau Ä‘Ã³ xÃ³a Ä‘i Ä‘á»‰nh cao hÆ¡n vÃ  dÃ¹ng phÃ¢n phá»‘i chuáº©n Ä‘á»ƒ táº¡o thÃ nh cÃ¡c máº«u DT vÃ  DB phÃ¹ há»£p nhÆ° hÃ¬nh 3:
https://imgur.com/07dR2bg.png
2.3.2. Biáº¿n Ä‘á»•i theo trá»¥c y:
Theo trá»¥c y chÃºng ta chá»‰ cáº§n thá»±c hiá»‡n thay Ä‘á»•i giÃ¡. Äá»‘i vá»›i hai pattern HSA vÃ  IHSA pháº£i Ä‘áº£m báº£o Ä‘á»‰nh thá»© 2 pháº£i cao hÆ¡n 2 Ä‘á»‰nh cÃ²n láº¡i. Äá»‘i vá»›i DT vÃ  DB cáº§n Ä‘áº£m báº£o 2 Ä‘á»‰nh cÃ³ Ä‘á»™ cao báº±ng nhau nhÆ° hÃ¬nh 4:
https://imgur.com/dwXkIHw.png
3. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c:
Thá»­ nghiá»‡m trÃªn 5 lá»›p mÃ´ hÃ¬nh khÃ¡c nhau cá»§a Object Detections: Scaled YOLOv4, YOLOX, YOLOR,  EfficientDet,  DETR cho tháº¥y Scaled YOLOv4 nháº­n diá»‡n chÃ­nh xÃ¡c nháº¥t Ä‘á»‘i vá»›i cÃ¡c pattern RHSA (90.6%) vÃ  DT (85/3%). YOLOX Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c lá»›n nháº¥t trÃªn pattern HSA (91.7%) vÃ  YOLOR Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c lá»›n nháº¥t trÃªn pattern DB Ä‘áº¡t 87.4%. HÃ¬nh 5:
https://imgur.com/hcAWqRm.png
4. Suy nghÄ© cá»§a tÃ´i:
Vá»›i sá»± phÃ¡t triá»ƒn cá»§a há»c sÃ¢u thÃ¬ viá»‡c sá»­ dá»¥ng nhá»¯ng mÃ´ hÃ¬nh máº¡nh Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng pattern trong tÃ i chÃ­nh hoÃ n toÃ n cÃ³ thá»ƒ mang láº¡i káº¿t quáº£ vÆ°á»£t trá»™i. Hai há»c viÃªn Ä‘Ã£ khÃ©o lÃ©o Ã¡p dá»¥ng nháº­n diá»‡n pattern thÃ´ng qua hÃ¬nh áº£nh cá»§a chÃºng báº±ng nhá»¯ng thuáº­t toÃ¡n máº¡nh trong há»c sÃ¢u. Vá»›i nhá»¯ng Ã½ tÆ°á»Ÿng trong nghiÃªn cá»©u nÃ y sáº½ cÃ³ thá»ƒ táº¡o ra nhá»¯ng Ä‘á»™t phÃ¡ má»›i trong viá»‡c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh trÃªn thá»‹ trÆ°á»ng tÃ i chÃ­nh trong tÆ°Æ¡ng lai.
5. Video thuyáº¿t trÃ¬nh:
https://youtu.be/NU1EILqqVIU","[Deep learning for Candlestick - Patterns recognition in Financial market] ÄÃ¢y lÃ  má»™t project khÃ¡ ná»•i báº­t mÃ  hai báº¡n sinh viÃªn Trá»ng Duy vÃ  Äá»©c Quang cá»§a Deep Learning K1 Ä‘Ã£ thá»±c hiá»‡n vá» Ä‘á» tÃ i nháº­n dáº¡ng máº«u biá»ƒu Ä‘á»“ Ä‘á»‘i vá»›i thá»‹ trÆ°á»ng chá»©ng khoÃ¡n. 1. Äáº·t váº¥n Ä‘á»: Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n luÃ´n tiá»m áº©n rá»§i ro cao Ä‘á»‘i vá»›i nhá»¯ng nhÃ  Ä‘áº§u tÆ°. CÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau trong há»c mÃ¡y vÃ  kinh táº¿ lÆ°á»£ng Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  dá»± Ä‘oÃ¡n cá»• phiáº¿u trong ngáº¯n háº¡n vÃ  dÃ i háº¡n. Trong Ä‘Ã³ kÄ© thuáº­t phÃ¢n tÃ­ch máº«u cá»• phiáº¿u lÃ  má»™t trong nhá»¯ng kÄ© thuáº­t Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ Ä‘Æ°á»£c cÃ¡c nhÃ  Ä‘áº§u tÆ° thá»±c hiá»‡n. ThÃ´ng thÆ°á»ng quÃ¡ trÃ¬nh nháº­n diá»‡n máº«u lÃ  má»™t cÃ´ng viá»‡c Ä‘Ã²i há»i sá»± tinh tÆ°á»ng vÃ  kinh nghiá»‡m chuyÃªn sÃ¢u tá»« chuyÃªn gia. Do Ä‘Ã³ khÃ³ cÃ³ thá»ƒ large scale trÃªn sá»‘ lÆ°á»£ng lá»›n vÃ i trÄƒm, hoáº·c vÃ i ngÃ n cá»• phiáº¿u. Trong nghiÃªn cá»©u nÃ y, hai báº¡n há»c viÃªn cá»§a Deep Learning K1 lÃ  Trá»ng Duy vÃ  Äá»©c Quang Ä‘Ã£ xÃ¢y dá»±ng má»™t cÃ¡ch tiáº¿p cáº­n má»›i sá»­ dá»¥ng bÃ i toÃ¡n computer vision trong nháº­n dáº¡ng máº«u cá»• phiáº¿u vÃ  Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao so vá»›i cÃ¡c thuáº­t toÃ¡n hiá»‡n táº¡i. 2. PhÆ°Æ¡ng phÃ¡p: 2.1. Táº­p dataset Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c phá»¥c vá»¥ cho trá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam nÃªn cÃ¡c máº«u Ä‘Æ°á»£c lá»±a chá»n lÃ  nhá»¯ng pattern giao dá»‹ch cá»§a 30mÃ£ chá»©ng khoÃ¡n vÃ  30 chá»‰ sá»‘ngoáº¡i há»‘i cá»§a cÃ¡c cÃ¡c sÃ n chá»©ng khoÃ¡n Viá»‡t Nam. NghiÃªn cá»©u táº­p trung vÃ o phÃ¡t hiá»‡n pattern trong ngáº¯n háº¡n nÃªn cÃ¡c máº«u dá»¯ liá»‡u Ä‘Æ°á»£c lá»±a chá»n lÃ  5 phiÃªn giao dá»‹ch cá»§a 1 tuáº§n liÃªn tiáº¿p vá»›i kÃ­ch thÆ°á»›c bÆ°á»›c nháº£y lÃ  1 ngÃ y. NghiÃªn cá»©u nÃ y táº­p trung vÃ o phÃ¡t hiá»‡n 4patterns chÃ­nh bao gá»“m: - HSA: Head and Shoulder. Pattern nÃ y mÃ´ táº£ sá»± Ä‘áº£o ngÆ°á»£c cá»§a xu hÆ°á»›ng tÄƒng sang giáº£m vá»›i Ä‘á»‰nh Head á»Ÿ giá»¯a vÃ  hai Ä‘á»‰nh Shoulder tháº¥p hÆ¡n á»Ÿ hai bÃªn. https://imgur.com/8uV2uWm.png - IHSA: Inverted Head and Shoulders nháº±m mÃ´ táº£ sá»± Ä‘áº£o ngÆ°á»£c tá»« giáº£m sang tÄƒng vá»›i Ä‘á»‰nh Head á»Ÿ giá»¯a sáº½ tháº¥p hÆ¡n so vá»›i hai Ä‘á»‰nh Shoulder á»Ÿ hai bÃªn. https://imgur.com/UVdHKP7.png - DT: Double TopÄ‘Æ°á»£c hÃ¬nh thÃ nh tá»« hai Ä‘á»‰nh liÃªn tiáº¿p. Pháº§n giá»¯a hai Ä‘á»‰nh táº¡o thÃ nh hÃ¬nh chá»¯ U lá»™n ngÆ°á»£c. Hai Ä‘á»‰nh cÃ³ giÃ¡ trá»‹ gáº§n tÆ°Æ¡ng tá»± nhau vá»›i má»©c chÃªnh lá»‡ch Ã­t hÆ¡n 3%. Pháº§n Ä‘Ã¡y giá»¯a hai Ä‘á»‰nh nhá» hÆ¡n Ä‘á»‰nh tá»« 10 â€“ 20%. https://imgur.com/9ZruggJ.png - DB: Double Bottom lÃ  Ä‘áº£o ngÆ°á»£c cá»§a Double Top. https://imgur.com/mHImCMd.png 2.2. Xá»­ lÃ½ dá»¯ liá»‡u Dá»¯ liá»‡u Ä‘Æ°á»£c chuyá»ƒn tá»« candle chart sang segmentation chart Ä‘á»ƒ háº¡n cháº¿ nhiá»…u vÃ  sau Ä‘Ã³ thá»±c hiá»‡n cÃ¡c bÆ°á»›c xá»­ lÃ½ nhÆ° hÃ¬nh 1: https://imgur.com/CDYA8ZB.png Step 1: Chá»n hai Ä‘iá»ƒm trong má»™t Ä‘oáº¡n trong biá»ƒu Ä‘á»“ segmentation. Step 2: Chá»n má»™t Ä‘iá»ƒm khÃ¡c sao cho cÃ³ tá»•ng khoáº£ng cÃ¡ch lá»›n nháº¥t Ä‘á»ƒ báº¯t Ä‘áº§u vÃ  káº¿t thÃºc Ä‘oáº¡n Ä‘Ã£ chá»n. Step 3: Láº·p láº¡i Step 1 vÃ  Step 2 cho Ä‘áº¿n khi cÃ³ Ä‘á»§ Ä‘iá»ƒm trong biá»ƒu Ä‘á»“ segmentation. Báº±ng cÃ¡ch nÃ y,cÃ¡c noise cÃ³ thá»ƒ Ä‘Æ°á»£c loáº¡i bá» vÃ  sáº½ thu Ä‘Æ°á»£c má»™t Ä‘á»“ thá»‹ Ä‘Æ°á»ng Ä‘Æ¡n giáº£n hÆ¡n. 2.3. Sinh máº«u ngáº«u nhiÃªn 2.3.1. Biáº¿n Ä‘á»•i theo trá»¥c x: - Äá»‘i vá»›i pattern HSA vÃ  IHSA. TÃ¡c giáº£ loáº¡i bá» nhá»¯ng máº«u Ä‘á»‘i vá»›i pattern HSA khÃ´ng há»£p lá»‡ (cÃ³ Ä‘á»‰nh thá»© 2 tháº¥p hÆ¡n hai Ä‘á»‰nh cÃ²n láº¡i). Sau Ä‘Ã³ táº¡o biáº¿n thá»ƒ ngáº«u nhiÃªn trÃªn nhá»¯ng máº«u Ä‘áº¡t tiÃªu chuáº©n báº±ng cÃ¡ch khá»Ÿi táº¡o ngáº«u nhiÃªn nhá»¯ng biáº¿n Ä‘á»™ng x_p1, x_p2, x_p3; xÃ³a Ä‘i má»™t Ä‘oáº¡n báº¥t kÃ¬ táº¡i vá»‹ trÃ­ Ä‘Ã¡y vÃ  thay tháº¿ má»™t Ä‘oáº¡n giÃ¡ ngáº«u nhiÃªn. Qui trÃ¬nh thá»±c hiá»‡n nhÆ° hÃ¬nh 2: https://imgur.com/e39JwNh.png PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n tÆ°Æ¡ng tá»± Ä‘á»‘i vá»›i cÃ¡c pattern IHSA. - Äá»‘i vá»›i pattern DT vÃ  DB: Lá»±a chá»n nhá»¯ng máº«u mÃ  cÃ³ 2 Ä‘á»‰nh gáº§n báº±ng nhau nhÆ°ng chÆ°a pháº£i lÃ  DT hoáº·c DB. Tiáº¿p theo so sÃ¡nh hai Ä‘á»‰nh, sau Ä‘Ã³ xÃ³a Ä‘i Ä‘á»‰nh cao hÆ¡n vÃ  dÃ¹ng phÃ¢n phá»‘i chuáº©n Ä‘á»ƒ táº¡o thÃ nh cÃ¡c máº«u DT vÃ  DB phÃ¹ há»£p nhÆ° hÃ¬nh 3: https://imgur.com/07dR2bg.png 2.3.2. Biáº¿n Ä‘á»•i theo trá»¥c y: Theo trá»¥c y chÃºng ta chá»‰ cáº§n thá»±c hiá»‡n thay Ä‘á»•i giÃ¡. Äá»‘i vá»›i hai pattern HSA vÃ  IHSA pháº£i Ä‘áº£m báº£o Ä‘á»‰nh thá»© 2 pháº£i cao hÆ¡n 2 Ä‘á»‰nh cÃ²n láº¡i. Äá»‘i vá»›i DT vÃ  DB cáº§n Ä‘áº£m báº£o 2 Ä‘á»‰nh cÃ³ Ä‘á»™ cao báº±ng nhau nhÆ° hÃ¬nh 4: https://imgur.com/dwXkIHw.png 3. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c: Thá»­ nghiá»‡m trÃªn 5 lá»›p mÃ´ hÃ¬nh khÃ¡c nhau cá»§a Object Detections: Scaled YOLOv4, YOLOX, YOLOR, EfficientDet, DETR cho tháº¥y Scaled YOLOv4 nháº­n diá»‡n chÃ­nh xÃ¡c nháº¥t Ä‘á»‘i vá»›i cÃ¡c pattern RHSA (90.6%) vÃ  DT (85/3%). YOLOX Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c lá»›n nháº¥t trÃªn pattern HSA (91.7%) vÃ  YOLOR Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c lá»›n nháº¥t trÃªn pattern DB Ä‘áº¡t 87.4%. HÃ¬nh 5: https://imgur.com/hcAWqRm.png 4. Suy nghÄ© cá»§a tÃ´i: Vá»›i sá»± phÃ¡t triá»ƒn cá»§a há»c sÃ¢u thÃ¬ viá»‡c sá»­ dá»¥ng nhá»¯ng mÃ´ hÃ¬nh máº¡nh Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng pattern trong tÃ i chÃ­nh hoÃ n toÃ n cÃ³ thá»ƒ mang láº¡i káº¿t quáº£ vÆ°á»£t trá»™i. Hai há»c viÃªn Ä‘Ã£ khÃ©o lÃ©o Ã¡p dá»¥ng nháº­n diá»‡n pattern thÃ´ng qua hÃ¬nh áº£nh cá»§a chÃºng báº±ng nhá»¯ng thuáº­t toÃ¡n máº¡nh trong há»c sÃ¢u. Vá»›i nhá»¯ng Ã½ tÆ°á»Ÿng trong nghiÃªn cá»©u nÃ y sáº½ cÃ³ thá»ƒ táº¡o ra nhá»¯ng Ä‘á»™t phÃ¡ má»›i trong viá»‡c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh trÃªn thá»‹ trÆ°á»ng tÃ i chÃ­nh trong tÆ°Æ¡ng lai. 5. Video thuyáº¿t trÃ¬nh: https://youtu.be/NU1EILqqVIU",,,,,
"Xin chÃ o má»i ngÆ°á»i.
Má»i ngÆ°á»i cÃ³ thá»ƒ nÃ¡n láº¡i má»™t chÃºt giÃºp em giáº£i thÃ­ch Ä‘oáº¡n nÃ y Ä‘Æ°á»£c khÃ´ng.
Máº¥y nay em Ä‘ang mÃ² thuáº­t toÃ¡n yolov5 vÃ  sau khi em trai cÃ¡i model xong thÃ¬ nÃ³ láº¡i hiá»‡n ra cÃ¡i hÃ¬nh nÃ y. CÃ¡i hÃ¬nh nÃ y nÃ³i lÃªn gÃ¬ váº­y áº¡. Em khÃ´ng biáº¿t káº¿t luáº­n gÃ¬ luÃ´n.",Xin chÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cÃ³ thá»ƒ nÃ¡n láº¡i má»™t chÃºt giÃºp em giáº£i thÃ­ch Ä‘oáº¡n nÃ y Ä‘Æ°á»£c khÃ´ng. Máº¥y nay em Ä‘ang mÃ² thuáº­t toÃ¡n yolov5 vÃ  sau khi em trai cÃ¡i model xong thÃ¬ nÃ³ láº¡i hiá»‡n ra cÃ¡i hÃ¬nh nÃ y. CÃ¡i hÃ¬nh nÃ y nÃ³i lÃªn gÃ¬ váº­y áº¡. Em khÃ´ng biáº¿t káº¿t luáº­n gÃ¬ luÃ´n.,,,,,
"ChÃ o má»i ngÆ°á»i.
MÃ¬nh background kinh táº¿, hiá»‡n cÅ©ng Ä‘ang lÃ m vá» kinh táº¿.
MÃ¬nh muá»‘n há»c ÄH (hoáº·c master) vá» CS á»Ÿ HÃ  Ná»™i thÃ¬ cÃ³ thá»ƒ há»c trÆ°á»ng nÃ o vÃ  chÆ°Æ¡ng trÃ¬nh nÃ o áº¡? CÃ³ Ä‘Ã¢u tuyá»ƒn sinh trÃ¡i ngÃ nh nhÆ° trÆ°á»ng há»£p mÃ¬nh khÃ´ng?
MÃ¬nh muá»‘n kiáº¿m thÃªm cÃ¡i báº±ng. NhÆ° Ä‘á»“ng nghiá»‡p mÃ¬nh thÃ¬ pháº§n lá»›n há»c lÃªn cao há»c á»Ÿ NEU, FTU, BA nhÆ°ng mÃ¬nh ngÃ¡n cÃ¡i Ä‘Ãºng sai khÃ´ng rÃµ rÃ ng cá»§a kinh táº¿ láº¯m rá»“i. MÃ¬nh cáº£m giÃ¡c nhÆ° há»c kinh táº¿ toÃ n nÃ³i phÃ©t váº­y...","ChÃ o má»i ngÆ°á»i. MÃ¬nh background kinh táº¿, hiá»‡n cÅ©ng Ä‘ang lÃ m vá» kinh táº¿. MÃ¬nh muá»‘n há»c ÄH (hoáº·c master) vá» CS á»Ÿ HÃ  Ná»™i thÃ¬ cÃ³ thá»ƒ há»c trÆ°á»ng nÃ o vÃ  chÆ°Æ¡ng trÃ¬nh nÃ o áº¡? CÃ³ Ä‘Ã¢u tuyá»ƒn sinh trÃ¡i ngÃ nh nhÆ° trÆ°á»ng há»£p mÃ¬nh khÃ´ng? MÃ¬nh muá»‘n kiáº¿m thÃªm cÃ¡i báº±ng. NhÆ° Ä‘á»“ng nghiá»‡p mÃ¬nh thÃ¬ pháº§n lá»›n há»c lÃªn cao há»c á»Ÿ NEU, FTU, BA nhÆ°ng mÃ¬nh ngÃ¡n cÃ¡i Ä‘Ãºng sai khÃ´ng rÃµ rÃ ng cá»§a kinh táº¿ láº¯m rá»“i. MÃ¬nh cáº£m giÃ¡c nhÆ° há»c kinh táº¿ toÃ n nÃ³i phÃ©t váº­y...",,,,,
"ChÃ o anh chá»‹ em, mÃ¬nh há»i chÃºt. MÃ¬nh biáº¿t vá»›i dá»¯ liá»‡u panel data hay longitudinal data cÃ³ mÃ´ hÃ¬nh FEM/REM dÃ¹ng Ä‘Æ°á»£c. Ai cÃ³ kinh nghiá»‡m dÃ¹ng vá»›i model khÃ¡c kiá»ƒu nhÆ° LSTM.... chia sáº» mÃ¬nh vá»›i. Xin cáº£m Æ¡n.","ChÃ o anh chá»‹ em, mÃ¬nh há»i chÃºt. MÃ¬nh biáº¿t vá»›i dá»¯ liá»‡u panel data hay longitudinal data cÃ³ mÃ´ hÃ¬nh FEM/REM dÃ¹ng Ä‘Æ°á»£c. Ai cÃ³ kinh nghiá»‡m dÃ¹ng vá»›i model khÃ¡c kiá»ƒu nhÆ° LSTM.... chia sáº» mÃ¬nh vá»›i. Xin cáº£m Æ¡n.",,,,,
"ChÃ o cÃ¡c bÃ¡c. Em xin gá»­i Ä‘áº¿n anh em má»™t bÃ i tÃ¬m hiá»ƒu sÆ¡ vá» EfficientNet vá»›i má»¥c tiÃªu MÃ¬ Äƒn liÃªn, sá»­ dá»¥ng Ä‘Æ°á»£c. NhÆ°ng nÃ³i chung cÃ¡ch nghÄ© cá»§a tÃ¡c giÃ¡ vá» váº¥n Ä‘á» model scaling khÃ¡ hay.
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c thÃ´i áº¡.","ChÃ o cÃ¡c bÃ¡c. Em xin gá»­i Ä‘áº¿n anh em má»™t bÃ i tÃ¬m hiá»ƒu sÆ¡ vá» EfficientNet vá»›i má»¥c tiÃªu MÃ¬ Äƒn liÃªn, sá»­ dá»¥ng Ä‘Æ°á»£c. NhÆ°ng nÃ³i chung cÃ¡ch nghÄ© cá»§a tÃ¡c giÃ¡ vá» váº¥n Ä‘á» model scaling khÃ¡ hay. Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c thÃ´i áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i. Vá» váº¥n Ä‘á» deploy model on cloud. Má»i ngÆ°á»i thÆ°á»ng triá»ƒn khai trÃªn ná»n táº£ng gÃ¬ Ä‘á»ƒ tá»‘i Æ°u performance áº¡? VÃ¬ mÃ¬nh biáº¿t cÃ¡c REST API frameworks nhÆ° django, flask, fastapi on python khÃ´ng thá»ƒ predict dynamic batch-size Ä‘Æ°á»£c.","ChÃ o má»i ngÆ°á»i. Vá» váº¥n Ä‘á» deploy model on cloud. Má»i ngÆ°á»i thÆ°á»ng triá»ƒn khai trÃªn ná»n táº£ng gÃ¬ Ä‘á»ƒ tá»‘i Æ°u performance áº¡? VÃ¬ mÃ¬nh biáº¿t cÃ¡c REST API frameworks nhÆ° django, flask, fastapi on python khÃ´ng thá»ƒ predict dynamic batch-size Ä‘Æ°á»£c.",,,,,
"CÃ³ báº¡n nÃ o cÃ³ tá»«ng sá»­ dá»¥ng OpenKE (https://github.com/thunlp/OpenKE) chÆ°a áº¡.
MÃ¬nh gáº·p váº¥n Ä‘á» lÃ  khÃ´ng tháº¥y hÆ°á»›ng dáº«n chuyá»ƒn entity sang id tÆ°Æ¡ng á»©ng (VD: Barack Obama -> id:157). MÃ¬nh cÃ³ lÄƒn xem cÃ¡c issue nhÆ°ng váº«n chÆ°a hÃ¬nh dung Ä‘Æ°á»£c cÃ¡ch Ä‘á»ƒ chuyá»ƒn entity sang id nhÆ° váº­y. File entity2id thÃ¬ Ä‘á»ƒ cÃ¡c giÃ¡ trá»‹ khÃ¡ láº¡, mÃ¬nh khÃ´ng rÃµ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ chuyá»ƒn tá»« dáº¡ng text qua Ä‘Æ°á»£c.
Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡, mÃ¬nh xin cáº£m Æ¡n áº¡.","CÃ³ báº¡n nÃ o cÃ³ tá»«ng sá»­ dá»¥ng OpenKE (https://github.com/thunlp/OpenKE) chÆ°a áº¡. MÃ¬nh gáº·p váº¥n Ä‘á» lÃ  khÃ´ng tháº¥y hÆ°á»›ng dáº«n chuyá»ƒn entity sang id tÆ°Æ¡ng á»©ng (VD: Barack Obama -> id:157). MÃ¬nh cÃ³ lÄƒn xem cÃ¡c issue nhÆ°ng váº«n chÆ°a hÃ¬nh dung Ä‘Æ°á»£c cÃ¡ch Ä‘á»ƒ chuyá»ƒn entity sang id nhÆ° váº­y. File entity2id thÃ¬ Ä‘á»ƒ cÃ¡c giÃ¡ trá»‹ khÃ¡ láº¡, mÃ¬nh khÃ´ng rÃµ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ chuyá»ƒn tá»« dáº¡ng text qua Ä‘Æ°á»£c. Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡, mÃ¬nh xin cáº£m Æ¡n áº¡.",,,,,
"#question
#underthesea
Em chÃ o cÃ¡c anh chá»‹. KhÃ´ng biáº¿t cÃ¡c anh chá»‹ trong Ä‘Ã¢y cÃ³ ai biáº¿t cÃ¡ch áº©n thanh progress bar khi dÃ¹ng thá»±c hiá»‡n dependency parsing cá»§a thÆ° viá»‡n underthesea cÃ³ thá»ƒ chá»‰ giÃºp em khÃ´ng áº¡ ? VÃ¬ document vÃ  github cá»§a thÆ° viá»‡n khÃ´ng cÃ³ nháº¯c Ä‘áº¿n nÃªn em xin phÃ©p Ä‘áº·t cÃ¢u há»i á»Ÿ Ä‘Ã¢y. Em xin cáº£m Æ¡n!",Em chÃ o cÃ¡c anh chá»‹. KhÃ´ng biáº¿t cÃ¡c anh chá»‹ trong Ä‘Ã¢y cÃ³ ai biáº¿t cÃ¡ch áº©n thanh progress bar khi dÃ¹ng thá»±c hiá»‡n dependency parsing cá»§a thÆ° viá»‡n underthesea cÃ³ thá»ƒ chá»‰ giÃºp em khÃ´ng áº¡ ? VÃ¬ document vÃ  github cá»§a thÆ° viá»‡n khÃ´ng cÃ³ nháº¯c Ä‘áº¿n nÃªn em xin phÃ©p Ä‘áº·t cÃ¢u há»i á»Ÿ Ä‘Ã¢y. Em xin cáº£m Æ¡n!,#question	#underthesea,,,,
"Em,mÃ¬nh chÃ o anh, chá»‹ vÃ  má»i ngÆ°á»i trong nhÃ³m.
Em,mÃ¬nh Ä‘ang muá»‘n tÃ¬m má»™t bá»™ dataset liÃªn quan Ä‘áº¿n ""vihicles moving"" cÃ³ thÃ´ng sá»‘ cá»§a Ä‘á»“ng há»“ Ä‘o tá»‘c Ä‘á»™ áº¡.
Em,mÃ¬nh Ä‘Ã£ tÃ¬m ráº¥t nhiá»u trÃªn máº¡ng tuy nhiÃªn váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c bá»™ dá»¯ liá»‡u nÃ o cÃ³ cáº£ thÃ´ng sá»‘ cá»§a Ä‘á»“ng há»“ Ä‘o.
Váº­y náº¿u má»i ngÆ°á»i cÃ³ hoáº·c Ä‘Ã£ tá»«ng lÃ m vá»›i bá»™ dá»¯ liá»‡u Ä‘Ã³ cÃ³ thá»ƒ chia sáº» cho em,mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡.
Em,mÃ¬nh cáº£m Æ¡n mn áº¡.","Em,mÃ¬nh chÃ o anh, chá»‹ vÃ  má»i ngÆ°á»i trong nhÃ³m. Em,mÃ¬nh Ä‘ang muá»‘n tÃ¬m má»™t bá»™ dataset liÃªn quan Ä‘áº¿n ""vihicles moving"" cÃ³ thÃ´ng sá»‘ cá»§a Ä‘á»“ng há»“ Ä‘o tá»‘c Ä‘á»™ áº¡. Em,mÃ¬nh Ä‘Ã£ tÃ¬m ráº¥t nhiá»u trÃªn máº¡ng tuy nhiÃªn váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c bá»™ dá»¯ liá»‡u nÃ o cÃ³ cáº£ thÃ´ng sá»‘ cá»§a Ä‘á»“ng há»“ Ä‘o. Váº­y náº¿u má»i ngÆ°á»i cÃ³ hoáº·c Ä‘Ã£ tá»«ng lÃ m vá»›i bá»™ dá»¯ liá»‡u Ä‘Ã³ cÃ³ thá»ƒ chia sáº» cho em,mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡. Em,mÃ¬nh cáº£m Æ¡n mn áº¡.",,,,,
"CÃ¡c anh chá»‹ Æ¡i, cÃ³ anh chá»‹ nÃ o cÃ³ táº­p dataset vá» Credit Risk Assessment vÃ  bÃ i bÃ¡o sá»­ dá»¥ng dataset Ä‘Ã³ khÃ´ng áº¡.
Em Ä‘ang cháº­p chá»¯ng tÃ¬m hiá»ƒu vá» nÃ³, mong cÃ¡c anh chá»‹ vÃ  cao nhÃ¢n há»— trá»£ áº¡.","CÃ¡c anh chá»‹ Æ¡i, cÃ³ anh chá»‹ nÃ o cÃ³ táº­p dataset vá» Credit Risk Assessment vÃ  bÃ i bÃ¡o sá»­ dá»¥ng dataset Ä‘Ã³ khÃ´ng áº¡. Em Ä‘ang cháº­p chá»¯ng tÃ¬m hiá»ƒu vá» nÃ³, mong cÃ¡c anh chá»‹ vÃ  cao nhÃ¢n há»— trá»£ áº¡.",,,,,
"[Thá»© tá»± cá»§a nhÃ£n tá»« cÃ³ áº£nh hÆ°á»Ÿng gÃ¬ Ä‘áº¿n huáº¥n luyá»‡n lá»›p Embedding/ Huáº¥n luyá»‡n mÃ´ hÃ¬nh khÃ´ng?]
#embedding_layer #reproducibility
ChÃ o má»i nguÃ²i, em muá»‘n há»i cÃ¡c báº¡n cÃ³ kinh nghiá»‡m lÃ m viá»‡c vá» NLP lÃ : thá»© tá»± cÃ¡c nhÃ£n cá»§a tá»« khÃ¡c nhau cÃ³ gÃ¢y ra hai mÃ´ hÃ¬nh khÃ¡c nhau hay khÃ´ng? 
Em Ä‘ang tÃ¬m hiá»ƒu vá» má»™t paper (https://doi.org/10.1093/bioinformatics/bty535) sá»­ dá»¥ng GNN, trong Ä‘Ã³ má»—i nÃºt Ä‘Æ°á»£c Ä‘Ã¡nh nhÃ£n vÃ  feed vÃ o lá»›p Embedding Ä‘á»ƒ cÃ³ vector Ä‘áº·c trÆ°ng.
Thuáº­t toÃ¡n má»i ngÆ°á»i xem á»Ÿ hÃ m extract_fingerprint (https://github.com/masashitsubaki/CPI_prediction/blob/master/code/preprocess_data.py)
Má»™t file Ä‘á»ƒ má»i ngÆ°á»i visualize káº¿t quáº£ trung gian cá»§a thuáº­t toÃ¡n: main2.py
vÃ  video: https://youtu.be/gybYJVqBW7o
Báº£n cháº¥t nÃ³ lÃ  má»™t kiá»ƒu thuáº­t toÃ¡n tÃ´ mÃ u Weisfeiler-Lehman
Má»™t sá»‘ tÃ­nh cháº¥t cá»§a thuáº­t toÃ¡n Ä‘Ã¡nh nhÃ£n Ä‘Ã³:
1/ Thuáº­t toÃ¡n Ä‘áº£m báº£o cÃ¡c nÃºt ""khÃ¡c nhau"" thÃ¬ Ä‘Æ°á»£c gÃ¡n nhÃ£n khÃ¡c nhau, nhÆ°ng khÃ´ng cÃ³ má»™t ""tá»« Ä‘iá»ƒn universal"" nÃ o cho nÃºt giá»‘ng nhÆ° tá»« Ä‘iá»ƒn ngÃ´n ngá»¯ cáº£ (vÃ  cáº£ tá»« Ä‘iá»ƒn SMILES, e ko cháº¯c?!), tá»« Ä‘iá»ƒn Ä‘Æ°á»£c xÃ¢y dá»±ng dáº§n dáº§n khi thuáº­t toÃ¡n láº·p qua toÃ n bá»™ cÃ¡c Ä‘á»“ thá»‹ phÃ¢n tá»­, vÃ  thá»© tá»± cá»§a cÃ¹ng má»™t loáº¡i nÃºt cÃ³ thá»ƒ  khÃ¡c nhau náº¿u thá»© tá»± láº·p lÃ  khÃ¡c nhau. 
2/ CÃ³ nhá»¯ng nhÃ£n nÃºt sáº½ khÃ´ng bao giá» Ä‘Æ°á»£c dÃ¹ng Ä‘áº¿n, cÅ©ng cÃ³ nghÄ©a lÃ  cÃ³ nhá»¯ng trá»ng sá»‘ trong embedding layer khÃ´ng Ä‘Æ°á»£c cáº­p nháº­t hoáº·c cáº­p nháº­t mÃ  khÃ´ng Ä‘em láº¡i thÃ´ng tin gÃ¬. ÄÃ³ lÃ  vÃ¬ viá»‡c Ä‘Ã¡nh nhÃ£n Ä‘Æ°á»£c thá»±c hiá»‡n theo kiá»ƒu cáº­p nháº­t, nhÃ£n cÅ© Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ sinh nhÃ£n má»›i vÃ  nÃºt sáº½ luÃ´n cá»‘ Ä‘á»ƒ Ä‘Æ°á»£c cáº­p nháº­t nhÃ£n má»›i nháº¥t cÃ³ thá»ƒ (má»¥c Ä‘Ã­ch nháº±m Ä‘a dáº¡ng nhÃ£n giá»¯a cÃ¡c nÃºt, Ä‘á»ƒ khÃ´ng chá»‰ phÃ¢n biá»‡t loáº¡i nguyÃªn tá»‘ cá»§a cÃ¡c nÃºt mÃ  cáº£ nhá»¯ng sub-structure cáº£m sinh tá»« nÃºt Ä‘Ã³)
Tá»« 1/ vÃ  2/, cá»™ng vá»›i nhá»¯ng ká»‹ch báº£n phá»©c táº¡p khi train theo batch, dá»«ng sá»›m, v.v. KhÃ´ng biáº¿t Ä‘iá»u nÃ y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng reproducible cá»§a thá»­ nghiá»‡m ko?","[Thá»© tá»± cá»§a nhÃ£n tá»« cÃ³ áº£nh hÆ°á»Ÿng gÃ¬ Ä‘áº¿n huáº¥n luyá»‡n lá»›p Embedding/ Huáº¥n luyá»‡n mÃ´ hÃ¬nh khÃ´ng?] ChÃ o má»i nguÃ²i, em muá»‘n há»i cÃ¡c báº¡n cÃ³ kinh nghiá»‡m lÃ m viá»‡c vá» NLP lÃ : thá»© tá»± cÃ¡c nhÃ£n cá»§a tá»« khÃ¡c nhau cÃ³ gÃ¢y ra hai mÃ´ hÃ¬nh khÃ¡c nhau hay khÃ´ng? Em Ä‘ang tÃ¬m hiá»ƒu vá» má»™t paper (https://doi.org/10.1093/bioinformatics/bty535) sá»­ dá»¥ng GNN, trong Ä‘Ã³ má»—i nÃºt Ä‘Æ°á»£c Ä‘Ã¡nh nhÃ£n vÃ  feed vÃ o lá»›p Embedding Ä‘á»ƒ cÃ³ vector Ä‘áº·c trÆ°ng. Thuáº­t toÃ¡n má»i ngÆ°á»i xem á»Ÿ hÃ m extract_fingerprint (https://github.com/masashitsubaki/CPI_prediction/blob/master/code/preprocess_data.py) Má»™t file Ä‘á»ƒ má»i ngÆ°á»i visualize káº¿t quáº£ trung gian cá»§a thuáº­t toÃ¡n: main2.py vÃ  video: https://youtu.be/gybYJVqBW7o Báº£n cháº¥t nÃ³ lÃ  má»™t kiá»ƒu thuáº­t toÃ¡n tÃ´ mÃ u Weisfeiler-Lehman Má»™t sá»‘ tÃ­nh cháº¥t cá»§a thuáº­t toÃ¡n Ä‘Ã¡nh nhÃ£n Ä‘Ã³: 1/ Thuáº­t toÃ¡n Ä‘áº£m báº£o cÃ¡c nÃºt ""khÃ¡c nhau"" thÃ¬ Ä‘Æ°á»£c gÃ¡n nhÃ£n khÃ¡c nhau, nhÆ°ng khÃ´ng cÃ³ má»™t ""tá»« Ä‘iá»ƒn universal"" nÃ o cho nÃºt giá»‘ng nhÆ° tá»« Ä‘iá»ƒn ngÃ´n ngá»¯ cáº£ (vÃ  cáº£ tá»« Ä‘iá»ƒn SMILES, e ko cháº¯c?!), tá»« Ä‘iá»ƒn Ä‘Æ°á»£c xÃ¢y dá»±ng dáº§n dáº§n khi thuáº­t toÃ¡n láº·p qua toÃ n bá»™ cÃ¡c Ä‘á»“ thá»‹ phÃ¢n tá»­, vÃ  thá»© tá»± cá»§a cÃ¹ng má»™t loáº¡i nÃºt cÃ³ thá»ƒ khÃ¡c nhau náº¿u thá»© tá»± láº·p lÃ  khÃ¡c nhau. 2/ CÃ³ nhá»¯ng nhÃ£n nÃºt sáº½ khÃ´ng bao giá» Ä‘Æ°á»£c dÃ¹ng Ä‘áº¿n, cÅ©ng cÃ³ nghÄ©a lÃ  cÃ³ nhá»¯ng trá»ng sá»‘ trong embedding layer khÃ´ng Ä‘Æ°á»£c cáº­p nháº­t hoáº·c cáº­p nháº­t mÃ  khÃ´ng Ä‘em láº¡i thÃ´ng tin gÃ¬. ÄÃ³ lÃ  vÃ¬ viá»‡c Ä‘Ã¡nh nhÃ£n Ä‘Æ°á»£c thá»±c hiá»‡n theo kiá»ƒu cáº­p nháº­t, nhÃ£n cÅ© Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ sinh nhÃ£n má»›i vÃ  nÃºt sáº½ luÃ´n cá»‘ Ä‘á»ƒ Ä‘Æ°á»£c cáº­p nháº­t nhÃ£n má»›i nháº¥t cÃ³ thá»ƒ (má»¥c Ä‘Ã­ch nháº±m Ä‘a dáº¡ng nhÃ£n giá»¯a cÃ¡c nÃºt, Ä‘á»ƒ khÃ´ng chá»‰ phÃ¢n biá»‡t loáº¡i nguyÃªn tá»‘ cá»§a cÃ¡c nÃºt mÃ  cáº£ nhá»¯ng sub-structure cáº£m sinh tá»« nÃºt Ä‘Ã³) Tá»« 1/ vÃ  2/, cá»™ng vá»›i nhá»¯ng ká»‹ch báº£n phá»©c táº¡p khi train theo batch, dá»«ng sá»›m, v.v. KhÃ´ng biáº¿t Ä‘iá»u nÃ y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng reproducible cá»§a thá»­ nghiá»‡m ko?",#embedding_layer	#reproducibility,,,,
"ChÃ o anh chá»‹ áº¡, em nÄƒm nay há»c lá»›p 12, em muá»‘n há»i lÃ  náº¿u theo AI research thÃ¬ nÃªn há»c chuyÃªn ngÃ nh toÃ¡n tin hay há»c cntt áº¡, lá»£i tháº¿ vá»›i láº¡i khÃ³ khÄƒn cá»§a 2 ngÃ nh nhÆ° tháº¿ nÃ o?
Váº­y em há»c á»Ÿ tphcm thÃ¬ nÃªn há»c á»Ÿ trÆ°á»ng nÃ o áº¡?","ChÃ o anh chá»‹ áº¡, em nÄƒm nay há»c lá»›p 12, em muá»‘n há»i lÃ  náº¿u theo AI research thÃ¬ nÃªn há»c chuyÃªn ngÃ nh toÃ¡n tin hay há»c cntt áº¡, lá»£i tháº¿ vá»›i láº¡i khÃ³ khÄƒn cá»§a 2 ngÃ nh nhÆ° tháº¿ nÃ o? Váº­y em há»c á»Ÿ tphcm thÃ¬ nÃªn há»c á»Ÿ trÆ°á»ng nÃ o áº¡?",,,,,
"#question #freeze #deeplearning
ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ vÃ i cÃ¢u há»i, Ä‘Ã£ nghiÃªn cá»©u vÃ²ng vÃ²ng nhÆ°ng váº«n chÆ°a clear, mong má»i ngÆ°á»i lÆ°á»›t ngang cho Ã½ kiáº¿n áº¡:
ThÃ´ng thÆ°á»ng má»i ngÆ°á»i freeze network thÆ°á»ng cÃ³ trick gÃ¬ khÃ´ng? ÄÃ³ giá» mÃ¬nh chá»‰ freeze pháº§n encoder (thÆ°á»ng backbone lÃ  resnet), pháº§n decoder thÃ¬ trainable. NhÆ°ng gáº§n Ä‘Ã¢y mÃ¬nh phÃ¡t hiá»‡n ngÆ°á»i ta chá»‰ freeze pháº§n batchnorm thÃ´i. CÅ©ng khÃ´ng hiá»ƒu láº¯m Ã½ Ä‘á»‹nh cá»§a há» lÃ  gÃ¬.
Giáº£ sá»­ mÃ¬nh cÃ³ 1 máº¡ng DNN, thÃ´ng thÆ°á»ng mÃ¬nh tháº¥y pháº§n early layers sáº½ cÃ³ Ã­t parameters hÆ¡n cÃ¡c layer cuá»‘i. MÃ¬nh tÃ¬m hiá»ƒu tháº¥y há» báº£o vÃ¬ cÃ¡c layer Ä‘áº§u level tháº¥p nÃªn chÆ°a cÃ³ gÃ¬ Ä‘á»ƒ há»c (mÃ¬nh khÃ´ng Ä‘á»“ng tÃ¬nh láº¯m, há»c shape cÅ©ng Ä‘Æ°á»£c mÃ ), cÃ³ ngÆ°á»i thÃ¬ báº£o lÃ  lÃ m nhÆ° váº­y tÃ­nh toÃ¡n sáº½ nhanh hÆ¡n ?
Vá»›i trÆ°á»ng há»£p upsample feature, mÃ¬nh thÆ°á»ng cÃ³ 2 cÃ¡ch:
a) Interpolate (non-trainable)
b) Convolution (trainable)
ThÃ´ng thÆ°á»ng mÃ¬nh sá»­ dá»¥ng Conv, tuy nhiÃªn gáº§n Ä‘Ã¢y mÃ¬nh phÃ¡t hiá»‡n cÃ³ ngÆ°á»i xÃ i interpolate. MÃ¬nh khÃ´ng hiá»ƒu lÃ½ do gÃ¬ mÃ  há» láº¡i dÃ¹ng cÃ¡i Ä‘Ã³?
Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡!
Cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ vÃ i cÃ¢u há»i, Ä‘Ã£ nghiÃªn cá»©u vÃ²ng vÃ²ng nhÆ°ng váº«n chÆ°a clear, mong má»i ngÆ°á»i lÆ°á»›t ngang cho Ã½ kiáº¿n áº¡: ThÃ´ng thÆ°á»ng má»i ngÆ°á»i freeze network thÆ°á»ng cÃ³ trick gÃ¬ khÃ´ng? ÄÃ³ giá» mÃ¬nh chá»‰ freeze pháº§n encoder (thÆ°á»ng backbone lÃ  resnet), pháº§n decoder thÃ¬ trainable. NhÆ°ng gáº§n Ä‘Ã¢y mÃ¬nh phÃ¡t hiá»‡n ngÆ°á»i ta chá»‰ freeze pháº§n batchnorm thÃ´i. CÅ©ng khÃ´ng hiá»ƒu láº¯m Ã½ Ä‘á»‹nh cá»§a há» lÃ  gÃ¬. Giáº£ sá»­ mÃ¬nh cÃ³ 1 máº¡ng DNN, thÃ´ng thÆ°á»ng mÃ¬nh tháº¥y pháº§n early layers sáº½ cÃ³ Ã­t parameters hÆ¡n cÃ¡c layer cuá»‘i. MÃ¬nh tÃ¬m hiá»ƒu tháº¥y há» báº£o vÃ¬ cÃ¡c layer Ä‘áº§u level tháº¥p nÃªn chÆ°a cÃ³ gÃ¬ Ä‘á»ƒ há»c (mÃ¬nh khÃ´ng Ä‘á»“ng tÃ¬nh láº¯m, há»c shape cÅ©ng Ä‘Æ°á»£c mÃ ), cÃ³ ngÆ°á»i thÃ¬ báº£o lÃ  lÃ m nhÆ° váº­y tÃ­nh toÃ¡n sáº½ nhanh hÆ¡n ? Vá»›i trÆ°á»ng há»£p upsample feature, mÃ¬nh thÆ°á»ng cÃ³ 2 cÃ¡ch: a) Interpolate (non-trainable) b) Convolution (trainable) ThÃ´ng thÆ°á»ng mÃ¬nh sá»­ dá»¥ng Conv, tuy nhiÃªn gáº§n Ä‘Ã¢y mÃ¬nh phÃ¡t hiá»‡n cÃ³ ngÆ°á»i xÃ i interpolate. MÃ¬nh khÃ´ng hiá»ƒu lÃ½ do gÃ¬ mÃ  há» láº¡i dÃ¹ng cÃ¡i Ä‘Ã³? Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡! Cáº£m Æ¡n áº¡.",#question	#freeze	#deeplearning,,,,
"Cho mÃ¬nh há»i machine learning cÃ³ thá»ƒ phÃ¡t hiá»‡n Ä‘Æ°á»£c thuáº­t ngá»¯ tiáº¿ng anh chuyÃªn ngÃ nh trong má»™t cÃ¢u tiáº¿ng anh khÃ´ng. Náº¿u cÃ³ thÃ¬ lÃ m tháº¿ nÃ o?. VÃ­ dá»¥ trong cá»¥m tiáº¿n anh ""A variable name must not have any keywords, for instance, float, int, etc."" thÃ¬ ta cÃ³ 4 tá»« chuyÃªn ngÃ nh lÃ  variable, keyword, float vÃ  int. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem.","Cho mÃ¬nh há»i machine learning cÃ³ thá»ƒ phÃ¡t hiá»‡n Ä‘Æ°á»£c thuáº­t ngá»¯ tiáº¿ng anh chuyÃªn ngÃ nh trong má»™t cÃ¢u tiáº¿ng anh khÃ´ng. Náº¿u cÃ³ thÃ¬ lÃ m tháº¿ nÃ o?. VÃ­ dá»¥ trong cá»¥m tiáº¿n anh ""A variable name must not have any keywords, for instance, float, int, etc."" thÃ¬ ta cÃ³ 4 tá»« chuyÃªn ngÃ nh lÃ  variable, keyword, float vÃ  int. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem.",,,,,
"NhÃ³m mÃ¬nh cÃ³ ai lÃ m bÃ i toÃ¡n semantic role labeling cho tiáº¿ng Viá»‡t chÆ°a áº¡, em tÃ¬m dataset Tiáº¿ng Viá»‡t mÃ  khÃ³ quÃ¡ :( Tháº¥y cÃ³ paper Vietnamese Propbank mÃ  em lá»¥c tung google ko tháº¥y chá»— táº£i Ä‘Ã¢u cáº£","NhÃ³m mÃ¬nh cÃ³ ai lÃ m bÃ i toÃ¡n semantic role labeling cho tiáº¿ng Viá»‡t chÆ°a áº¡, em tÃ¬m dataset Tiáº¿ng Viá»‡t mÃ  khÃ³ quÃ¡ :( Tháº¥y cÃ³ paper Vietnamese Propbank mÃ  em lá»¥c tung google ko tháº¥y chá»— táº£i Ä‘Ã¢u cáº£",,,,,
"Chuyá»ƒn file audio thÃ nh text Tiáº¿ng Viá»‡t thÃ¬ mÃ¬nh lÃ m tháº¿ nÃ o nhá»‰, anh em cÃ³ open source khÃ´ng cho mÃ¬nh thÃ´ng tin vs nhÃ©.","Chuyá»ƒn file audio thÃ nh text Tiáº¿ng Viá»‡t thÃ¬ mÃ¬nh lÃ m tháº¿ nÃ o nhá»‰, anh em cÃ³ open source khÃ´ng cho mÃ¬nh thÃ´ng tin vs nhÃ©.",,,,,
"""Training khÃ´ng Ä‘á»“ thá»‹ nhÆ° cÃ¡c chá»‹ thiáº¿u gÆ°Æ¡ng soi"" - chÃºng ta sáº½ khÃ´ng thá»ƒ biáº¿t Ä‘Æ°á»£c model Ä‘áº¹p hay xáº¥u, ngon hay khÃ´ng? HÃ´m nay mÃ¬nh share cÃ¹ng anh em cÃ¡ch visualize Ä‘á»“ thá»‹ cÃ¡c thÃ´ng sá»‘ training realtime theo nhu cáº§u cá»§a má»™t sá»‘ anh em cÃ³ há»i trÃªn nhÃ³m.
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em!","""Training khÃ´ng Ä‘á»“ thá»‹ nhÆ° cÃ¡c chá»‹ thiáº¿u gÆ°Æ¡ng soi"" - chÃºng ta sáº½ khÃ´ng thá»ƒ biáº¿t Ä‘Æ°á»£c model Ä‘áº¹p hay xáº¥u, ngon hay khÃ´ng? HÃ´m nay mÃ¬nh share cÃ¹ng anh em cÃ¡ch visualize Ä‘á»“ thá»‹ cÃ¡c thÃ´ng sá»‘ training realtime theo nhu cáº§u cá»§a má»™t sá»‘ anh em cÃ³ há»i trÃªn nhÃ³m. Hi vá»ng giÃºp Ä‘Æ°á»£c anh em!",,,,,
MÃ¬nh Ä‘ang Ä‘á»c tÃ i liá»‡u cÃ³ gáº·p 2 thuáº­t ngá»¯ lÃ  bert vÃ  phobert. MÃ¬nh ko biáº¿t lÃ  phobert cÃ³ liÃªn quan gÃ¬ Ä‘áº¿n bert ko. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem.,MÃ¬nh Ä‘ang Ä‘á»c tÃ i liá»‡u cÃ³ gáº·p 2 thuáº­t ngá»¯ lÃ  bert vÃ  phobert. MÃ¬nh ko biáº¿t lÃ  phobert cÃ³ liÃªn quan gÃ¬ Ä‘áº¿n bert ko. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem.,,,,,
"Em xin chÃ o cÃ¡c tiá»n bá»‘i! Má»i ngÆ°á»i cho em há»i chÃºt áº¡! Má»©c Ä‘á»™ sai sá»‘ cá»§a má»™t táº­p m sample trong dataset cÃ³ tá»•ng cá»™ng n samples cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ báº±ng variance nhÆ° sau, thÃ¬ táº¡i sao pháº§n máº«u lÃ  (m-(n-1) chá»© khÃ´ng pháº£i (n-(m-1)) áº¡!
Em xin cáº£m Æ¡n!","Em xin chÃ o cÃ¡c tiá»n bá»‘i! Má»i ngÆ°á»i cho em há»i chÃºt áº¡! Má»©c Ä‘á»™ sai sá»‘ cá»§a má»™t táº­p m sample trong dataset cÃ³ tá»•ng cá»™ng n samples cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ báº±ng variance nhÆ° sau, thÃ¬ táº¡i sao pháº§n máº«u lÃ  (m-(n-1) chá»© khÃ´ng pháº£i (n-(m-1)) áº¡! Em xin cáº£m Æ¡n!",,,,,
"[Video DataQuest 5th - MLOps methodology]
Note: English version in the last.
Trong sá»± kiá»‡n DataQuest láº§n thá»© 5 nÃ y, TowardDatascience cung cáº¥p cho báº¡n kiáº¿n thá»©c chung vá» dÃ¢n chá»§ hÃ³a AI Ä‘á»ƒ cho phÃ©p nhÃ³m ná»™i bá»™ cÃ³ kháº£ nÄƒng phÃ¡t triá»ƒn vÃ  triá»ƒn khai cÃ¡c á»©ng dá»¥ng AI lÃªn mÃ´i trÆ°á»ng production. HÆ¡n ná»¯a, báº¡n cÃ³ thá»ƒ tá»• chá»©c dá»± Ã¡n cá»§a mÃ¬nh theo quáº£n lÃ½ vÃ²ng Ä‘á»i MLOps vá»›i sá»± hiá»ƒu biáº¿t sÃ¢u sáº¯c vá» viá»‡c thÃ­ch á»©ng vá»›i sá»± thay Ä‘á»•i mÃ´ hÃ¬nh theo dá»¯ liá»‡u Ä‘á»™ng. PhÆ°Æ¡ng phÃ¡p MLOps lÃ  cÃ¡ch báº¡n phÃ¢n biá»‡t thÃ nh nhiá»u má»©c Ä‘á»™ trÆ°á»Ÿng thÃ nh cá»§a MLOps tÆ°Æ¡ng á»©ng vá»›i má»©c Ä‘á»™ tá»± Ä‘á»™ng hÃ³a vÃ  tÄƒng tá»‘c chu kÃ¬ huáº¥n luyá»‡n/triá»ƒn khai vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.
I. Ná»™i dung:
- DÃ¢n chá»§ hÃ³a AI
- VÃ²ng Ä‘á»i MLOps
- PhÆ°Æ¡ng phÃ¡p MLOps
II. TÃ i liá»‡u:
Slide: https://drive.google.com/file/d/1PrGyG28c4Y2GrXuBUbO4ctYX4cTFArEd/view?usp=sharing
Video: https://youtu.be/qJrI3hNw7r0
-----------------------------------------------------------------------------------------------------
In this 5th DataQuest event, TowardDatascience provides you with a general knowledge of AI democratization that enables the in-house team the ability to develop and deploy AI applications in the production environment. Moreover, you can organize your project according to the MLOps lifecycle management with a deep understanding of adapting model change according to dynamic data. MLOps methodology is the way you differentiate into a variety of MLOps maturity levels relevant to the automation and acceleration of training, deployment, and evaluation.
I. Content:
- AI democratization
- MLOps lifecycle
- MLOps methodology
II. Resource:
Slide: https://drive.google.com/file/d/1PrGyG28c4Y2GrXuBUbO4ctYX4cTFArEd/view?usp=sharing
Video: https://youtu.be/qJrI3hNw7r0
-----â€â€------------------------â€-----â€--------------------------------
1 phÃºt quáº£ng cÃ¡o: Nháº±m cá»§ng cá»‘ thÃªm kiáº¿n thá»©c vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh, giáº£i tÃ­ch, xÃ¡c suáº¥t vÃ  thá»‘ng kÃª lÃ  nhá»¯ng trá»¥ cá»™t quan trong Machine Learning. hÃ£y Ä‘Äƒng kÃ­ khÃ³a há»c Math for Machine Learning (start 22/05/2022) theo link bÃªn dÆ°á»›i:
https://www.facebook.com/1127124110656257/posts/5031751303526832/","[Video DataQuest 5th - MLOps methodology] Note: English version in the last. Trong sá»± kiá»‡n DataQuest láº§n thá»© 5 nÃ y, TowardDatascience cung cáº¥p cho báº¡n kiáº¿n thá»©c chung vá» dÃ¢n chá»§ hÃ³a AI Ä‘á»ƒ cho phÃ©p nhÃ³m ná»™i bá»™ cÃ³ kháº£ nÄƒng phÃ¡t triá»ƒn vÃ  triá»ƒn khai cÃ¡c á»©ng dá»¥ng AI lÃªn mÃ´i trÆ°á»ng production. HÆ¡n ná»¯a, báº¡n cÃ³ thá»ƒ tá»• chá»©c dá»± Ã¡n cá»§a mÃ¬nh theo quáº£n lÃ½ vÃ²ng Ä‘á»i MLOps vá»›i sá»± hiá»ƒu biáº¿t sÃ¢u sáº¯c vá» viá»‡c thÃ­ch á»©ng vá»›i sá»± thay Ä‘á»•i mÃ´ hÃ¬nh theo dá»¯ liá»‡u Ä‘á»™ng. PhÆ°Æ¡ng phÃ¡p MLOps lÃ  cÃ¡ch báº¡n phÃ¢n biá»‡t thÃ nh nhiá»u má»©c Ä‘á»™ trÆ°á»Ÿng thÃ nh cá»§a MLOps tÆ°Æ¡ng á»©ng vá»›i má»©c Ä‘á»™ tá»± Ä‘á»™ng hÃ³a vÃ  tÄƒng tá»‘c chu kÃ¬ huáº¥n luyá»‡n/triá»ƒn khai vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. I. Ná»™i dung: - DÃ¢n chá»§ hÃ³a AI - VÃ²ng Ä‘á»i MLOps - PhÆ°Æ¡ng phÃ¡p MLOps II. TÃ i liá»‡u: Slide: https://drive.google.com/file/d/1PrGyG28c4Y2GrXuBUbO4ctYX4cTFArEd/view?usp=sharing Video: https://youtu.be/qJrI3hNw7r0 ----------------------------------------------------------------------------------------------------- In this 5th DataQuest event, TowardDatascience provides you with a general knowledge of AI democratization that enables the in-house team the ability to develop and deploy AI applications in the production environment. Moreover, you can organize your project according to the MLOps lifecycle management with a deep understanding of adapting model change according to dynamic data. MLOps methodology is the way you differentiate into a variety of MLOps maturity levels relevant to the automation and acceleration of training, deployment, and evaluation. I. Content: - AI democratization - MLOps lifecycle - MLOps methodology II. Resource: Slide: https://drive.google.com/file/d/1PrGyG28c4Y2GrXuBUbO4ctYX4cTFArEd/view?usp=sharing Video: https://youtu.be/qJrI3hNw7r0 -----â€â€------------------------â€-----â€-------------------------------- 1 phÃºt quáº£ng cÃ¡o: Nháº±m cá»§ng cá»‘ thÃªm kiáº¿n thá»©c vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh, giáº£i tÃ­ch, xÃ¡c suáº¥t vÃ  thá»‘ng kÃª lÃ  nhá»¯ng trá»¥ cá»™t quan trong Machine Learning. hÃ£y Ä‘Äƒng kÃ­ khÃ³a há»c Math for Machine Learning (start 22/05/2022) theo link bÃªn dÆ°á»›i: https://www.facebook.com/1127124110656257/posts/5031751303526832/",,,,,
"ChÃ o má»i ngÆ°á»i,
Xin há»i má»i ngÆ°á»i, model cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c tháº» CMND bá»‹ chá»‰nh sá»­a, bá»‹ photoshop hay thay Ä‘á»•i áº£nh trong tháº» áº¡?","ChÃ o má»i ngÆ°á»i, Xin há»i má»i ngÆ°á»i, model cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c tháº» CMND bá»‹ chá»‰nh sá»­a, bá»‹ photoshop hay thay Ä‘á»•i áº£nh trong tháº» áº¡?",,,,,
"em xin tÃ i liá»‡u hd nháº­n dáº¡ng tiá»n giáº£, hÃ¬nh nhÆ° group mÃ¬nh cÃ³ Ä‘Äƒng 1 láº§n thÃ¬ pháº£i
xin cÃ¡m Æ¡n cÃ¡c anh/chá»‹","em xin tÃ i liá»‡u hd nháº­n dáº¡ng tiá»n giáº£, hÃ¬nh nhÆ° group mÃ¬nh cÃ³ Ä‘Äƒng 1 láº§n thÃ¬ pháº£i xin cÃ¡m Æ¡n cÃ¡c anh/chá»‹",,,,,
"Xin chÃ o má»i ngÆ°á»i. MÃ¬nh hiá»‡n Ä‘ang lÃ m project vá» information retrieval tá»« file pdf. MÃ¬nh cÃ³ test qua má»™t vÃ i packages nhÆ°: pdfminer, PyPDF2, pdfPlumber thÃ¬ káº¿t quáº£ khÃ´ng Ä‘Æ°á»£c ok láº¯m. Sau Ä‘Ã³ mÃ¬nh cÃ³ thá»­ dÃ¹ng OCR vá»›i Tessaract thÃ¬ káº¿t quáº£ tá»‘t hÆ¡n háº³n, tuy nhiÃªn khÃ¡ cháº­m + bá»‹ vÆ°á»›ng footnote cá»§a cÃ¡c pages, mÃ¬nh dÃ¹ng thÃªm OpenCV thÃ¬ cÅ©ng xá»­ lÃ½ dc sÆ¡ sÆ¡ footnote nhÆ°ng káº¿t quáº£ lÃªn xuá»‘ng tÃ¹y thuá»™c vÃ o pdf file, hÆ¡n ná»¯a cháº¡y cÃ ng lÃ¢u. MÃ¬nh má»›i tÃ¬m hiá»ƒu thÃªm thÃ¬ cÃ³ TextSnake model vá»›i framework MMOCR. CÃ³ ai tá»«ng cÃ³ kinh nghiá»‡m lÃ m vá» máº£ng nÃ y hoáº·c Ä‘Ã£ tá»«ng dÃ¹ng TextSnake, MMOCR cÃ³ thá»ƒ cho mÃ¬nh xin chÃºt kinh nghiá»‡m Ä‘Æ°á»£c khÃ´ng áº¡.
MÃ¬nh cÅ©ng cÃ³ ngÃ³ qua Google Vision API thÃ¬ tháº¥y nÃ³ hÆ¡i nhiá»u policy.
MÃ¬nh cáº£m Æ¡n áº¡","Xin chÃ o má»i ngÆ°á»i. MÃ¬nh hiá»‡n Ä‘ang lÃ m project vá» information retrieval tá»« file pdf. MÃ¬nh cÃ³ test qua má»™t vÃ i packages nhÆ°: pdfminer, PyPDF2, pdfPlumber thÃ¬ káº¿t quáº£ khÃ´ng Ä‘Æ°á»£c ok láº¯m. Sau Ä‘Ã³ mÃ¬nh cÃ³ thá»­ dÃ¹ng OCR vá»›i Tessaract thÃ¬ káº¿t quáº£ tá»‘t hÆ¡n háº³n, tuy nhiÃªn khÃ¡ cháº­m + bá»‹ vÆ°á»›ng footnote cá»§a cÃ¡c pages, mÃ¬nh dÃ¹ng thÃªm OpenCV thÃ¬ cÅ©ng xá»­ lÃ½ dc sÆ¡ sÆ¡ footnote nhÆ°ng káº¿t quáº£ lÃªn xuá»‘ng tÃ¹y thuá»™c vÃ o pdf file, hÆ¡n ná»¯a cháº¡y cÃ ng lÃ¢u. MÃ¬nh má»›i tÃ¬m hiá»ƒu thÃªm thÃ¬ cÃ³ TextSnake model vá»›i framework MMOCR. CÃ³ ai tá»«ng cÃ³ kinh nghiá»‡m lÃ m vá» máº£ng nÃ y hoáº·c Ä‘Ã£ tá»«ng dÃ¹ng TextSnake, MMOCR cÃ³ thá»ƒ cho mÃ¬nh xin chÃºt kinh nghiá»‡m Ä‘Æ°á»£c khÃ´ng áº¡. MÃ¬nh cÅ©ng cÃ³ ngÃ³ qua Google Vision API thÃ¬ tháº¥y nÃ³ hÆ¡i nhiá»u policy. MÃ¬nh cáº£m Æ¡n áº¡",,,,,
"ChÃ o cÃ¡c bÃ¡c, em dÃ¢n ngoÃ i ngÃ nh(biáº¿t láº­p trÃ¬nh cÄƒn báº£n) muá»‘n tÃ¬m hiá»ƒu vá» AI, em muá»‘n lÃ m má»™t tool dáº¡ng nhÆ° auto content váº­y, em nháº­p vÃ o khoáº£ng 5 hay 10 tá»« gÃ¬ Ä‘Ã³, thÃ¬ nÃ³ tá»± táº¡o ra má»™t cÃ¢u hoáº·c Ä‘oáº¡n vÄƒn chá»©a Ä‘á»§ cÃ¡c tá»« nÃ y (cÃ¡c tá»« nÃ y lÃ  tiáº¿ng Anh), cÃ¡c bÃ¡c chá»‰ giÃºp em hÆ°á»›ng Ä‘i vÃ  vÃ i keyword Ä‘á»ƒ nghiÃªn cá»©u vá»›i.","ChÃ o cÃ¡c bÃ¡c, em dÃ¢n ngoÃ i ngÃ nh(biáº¿t láº­p trÃ¬nh cÄƒn báº£n) muá»‘n tÃ¬m hiá»ƒu vá» AI, em muá»‘n lÃ m má»™t tool dáº¡ng nhÆ° auto content váº­y, em nháº­p vÃ o khoáº£ng 5 hay 10 tá»« gÃ¬ Ä‘Ã³, thÃ¬ nÃ³ tá»± táº¡o ra má»™t cÃ¢u hoáº·c Ä‘oáº¡n vÄƒn chá»©a Ä‘á»§ cÃ¡c tá»« nÃ y (cÃ¡c tá»« nÃ y lÃ  tiáº¿ng Anh), cÃ¡c bÃ¡c chá»‰ giÃºp em hÆ°á»›ng Ä‘i vÃ  vÃ i keyword Ä‘á»ƒ nghiÃªn cá»©u vá»›i.",,,,,
"[SÃ¡ch Introduction to Probability for Data Science]
CÃ¡c sÃ¡ch viáº¿t vá» xÃ¡c suáº¥t trÆ°á»›c Ä‘Ã¢y thÃ¬ sáº½ theo má»™t trong hai hÆ°á»›ng: sÃ¡ch cho láº­p trÃ¬nh viÃªn hoáº·c sÃ¡ch cho dÃ¢n toÃ¡n. Trong khi sÃ¡ch xÃ¡c suáº¥t cho láº­p trÃ¬nh viÃªn thÆ°á»ng táº­p trung vÃ o cÃ¡ch dÃ¹ng thÆ° viá»‡n Ä‘á»ƒ tÃ­nh toÃ¡n, khÃ´ng chÃº trá»ng vÃ o báº£n cháº¥t toÃ¡n há»c; thÃ¬ sÃ¡ch viáº¿t cho dÃ¢n toÃ¡n thÆ°á»ng khÃ´ khan, náº·ng vá» biáº¿n Ä‘á»•i cÃ´ng thá»©c, thÃ nh ra Ä‘á»c ráº¥t dá»… chÃ¡n.
Nay mÃ¬nh giá»›i thiá»‡u má»i ngÆ°á»i cuá»‘n ""Introduction to Probability for Data Science"" cÃ³ káº¿t há»£p hÃ i hÃ²a giá»¯a lÃ½ thuyáº¿t vÃ  thá»±c hÃ nh, cÃ³ cáº£ code R vÃ  Python kÃ¨m theo sÃ¡ch. NgoÃ i ra sÃ¡ch cÃ²n giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m má»™t cÃ¡ch trá»±c quan, láº¥y vÃ­ dá»¥ liÃªn quan tá»›i khoa há»c dá»¯ liá»‡u. Pháº§n cuá»‘i sÃ¡ch cÃ²n giá»›i thiá»‡u vá» á»©ng dá»¥ng xÃ¡c suáº¥t trong cÃ¡c thuáº­t toÃ¡n vá» Machine Learning.
ThÃ´ng tin vá» sÃ¡ch á»Ÿ Ä‘Ã¢y: https://probability4datascience.com/preface.html","[SÃ¡ch Introduction to Probability for Data Science] CÃ¡c sÃ¡ch viáº¿t vá» xÃ¡c suáº¥t trÆ°á»›c Ä‘Ã¢y thÃ¬ sáº½ theo má»™t trong hai hÆ°á»›ng: sÃ¡ch cho láº­p trÃ¬nh viÃªn hoáº·c sÃ¡ch cho dÃ¢n toÃ¡n. Trong khi sÃ¡ch xÃ¡c suáº¥t cho láº­p trÃ¬nh viÃªn thÆ°á»ng táº­p trung vÃ o cÃ¡ch dÃ¹ng thÆ° viá»‡n Ä‘á»ƒ tÃ­nh toÃ¡n, khÃ´ng chÃº trá»ng vÃ o báº£n cháº¥t toÃ¡n há»c; thÃ¬ sÃ¡ch viáº¿t cho dÃ¢n toÃ¡n thÆ°á»ng khÃ´ khan, náº·ng vá» biáº¿n Ä‘á»•i cÃ´ng thá»©c, thÃ nh ra Ä‘á»c ráº¥t dá»… chÃ¡n. Nay mÃ¬nh giá»›i thiá»‡u má»i ngÆ°á»i cuá»‘n ""Introduction to Probability for Data Science"" cÃ³ káº¿t há»£p hÃ i hÃ²a giá»¯a lÃ½ thuyáº¿t vÃ  thá»±c hÃ nh, cÃ³ cáº£ code R vÃ  Python kÃ¨m theo sÃ¡ch. NgoÃ i ra sÃ¡ch cÃ²n giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m má»™t cÃ¡ch trá»±c quan, láº¥y vÃ­ dá»¥ liÃªn quan tá»›i khoa há»c dá»¯ liá»‡u. Pháº§n cuá»‘i sÃ¡ch cÃ²n giá»›i thiá»‡u vá» á»©ng dá»¥ng xÃ¡c suáº¥t trong cÃ¡c thuáº­t toÃ¡n vá» Machine Learning. ThÃ´ng tin vá» sÃ¡ch á»Ÿ Ä‘Ã¢y: https://probability4datascience.com/preface.html",,,,,
"THÃ”NG BÃO Tá»ª NHÃ“M DLBOOKVN

ğŸ‡¨ğŸ‡¦ğŸ‡¨ğŸ‡¦ğŸ‡¨ğŸ‡¦ Mila - Institut QuÃ©bÃ©cois d'Intelligence Artificielle (Viá»‡n AI Quebec Canada) thÃ´ng qua chuyáº¿n thÄƒm lÃ m viá»‡c vá»›i FPTSoftwareAILab (má»™t trong sá»‘ cÃ¡c nhÃ  tÃ i trá»£ kim cÆ°Æ¡ng cá»§a dá»± Ã¡n nÃ y), Ä‘Ã£ Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘áº¿n dá»± Ã¡n Viá»‡t hÃ³a cuá»‘n DeepLearning cá»§a nhÃ³m DLBookVN chÃºng tÃ´i. Viá»‡n Ä‘Ã£ Ä‘Äƒng táº£i thÃ´ng tin trÃªn fanpage chÃ­nh thá»©c cá»§a mÃ¬nh. Ngay sau Ä‘Ã³, bÃ¡c Yoshua Bengio cÅ©ng Ä‘Ã£ chia sáº» láº¡i bÃ i Ä‘Äƒng nÃ y trÃªn trang nhÃ . ğŸ¤©ğŸ¥°ğŸ¤ª

Cáº£m Æ¡n FPTSoftwareAILab vÃ  Viá»‡n AI Quebec Canada Ä‘Ã£ giÃºp chÃºng tÃ´i thÃªm lan tá»a dá»± Ã¡n nÃ y Ä‘áº¿n cá»™ng Ä‘á»“ng.  
#FPTSoftwareAILab #ACESoftware #SolarpowerVietnam #KaseEdutech #SucdenVietnam  
â€”-------------------------------------------------------- 
ThÃ´ng tin liÃªn há»‡: 
ğŸŒWebsite: https://dlbookvn.gitlab.io
ğŸ“Fanpage: https://www.facebook.com/deeplearningbookvn
ğŸ“©Email: dlbookvn18@gmail.com","THÃ”NG BÃO Tá»ª NHÃ“M DLBOOKVN Mila - Institut QuÃ©bÃ©cois d'Intelligence Artificielle (Viá»‡n AI Quebec Canada) thÃ´ng qua chuyáº¿n thÄƒm lÃ m viá»‡c vá»›i FPTSoftwareAILab (má»™t trong sá»‘ cÃ¡c nhÃ  tÃ i trá»£ kim cÆ°Æ¡ng cá»§a dá»± Ã¡n nÃ y), Ä‘Ã£ Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘áº¿n dá»± Ã¡n Viá»‡t hÃ³a cuá»‘n DeepLearning cá»§a nhÃ³m DLBookVN chÃºng tÃ´i. Viá»‡n Ä‘Ã£ Ä‘Äƒng táº£i thÃ´ng tin trÃªn fanpage chÃ­nh thá»©c cá»§a mÃ¬nh. Ngay sau Ä‘Ã³, bÃ¡c Yoshua Bengio cÅ©ng Ä‘Ã£ chia sáº» láº¡i bÃ i Ä‘Äƒng nÃ y trÃªn trang nhÃ . Cáº£m Æ¡n FPTSoftwareAILab vÃ  Viá»‡n AI Quebec Canada Ä‘Ã£ giÃºp chÃºng tÃ´i thÃªm lan tá»a dá»± Ã¡n nÃ y Ä‘áº¿n cá»™ng Ä‘á»“ng. â€”-------------------------------------------------------- ThÃ´ng tin liÃªn há»‡: Website: https://dlbookvn.gitlab.io Fanpage: https://www.facebook.com/deeplearningbookvn Email: dlbookvn18@gmail.com",#FPTSoftwareAILab	#ACESoftware	#SolarpowerVietnam	#KaseEdutech	#SucdenVietnam,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o ML nÃªn cÃ³ 1 cÃ¢u há»i mong cÃ¡c ace tÆ° váº¥n giÃºp áº¡ 
Hiá»‡n táº¡i em Ä‘ang cÃ³ káº¿ hoáº¡ch lÃ m 1 mock app vá» nháº­n diá»‡n object, object nháº­n diá»‡n chá»‰ Ä‘Æ¡n giáº£n nhÆ°: tÃ²a nhÃ , bá»©c tÆ°á»ng, sky 
Theo em research thÃ¬ Ä‘á»ƒ detect cÃ¡c object nÃ y cáº§n ML train  
vÃ¬ mock app ko Ä‘em Ä‘i thÆ°Æ¡ng máº¡i hay kinh doanh nÃªn vá» pháº§n chi phÃ­ khÃ¡ eo háº¹p, nÃªn em muá»‘n tham kháº£o cÃ¡c ace lÃ  cÃ³ nÆ¡i nÃ o hay chá»• nÃ o cÃ³ sharing cÃ¡c model Ä‘Ã£ Ä‘c training Ä‘á»ƒ detect cÃ¡c object trÃªn khÃ´ng, (Ä‘á»™ chÃ­nh xÃ¡c <50% cÅ©ng ko váº¥n Ä‘á» gÃ¬), hoáº·c trial khÃ´ng giÆ°á»›i háº¡n time cháº³ng háº¡n 
sr má»i ngÆ°á»i vÃ¬ cÃ¢u há»i khÃ¡ khÃ´ng liÃªn quan Ä‘áº¿n ML cho láº¯m.
 ","ChÃ o má»i ngÆ°á»i, em lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o ML nÃªn cÃ³ 1 cÃ¢u há»i mong cÃ¡c ace tÆ° váº¥n giÃºp áº¡ Hiá»‡n táº¡i em Ä‘ang cÃ³ káº¿ hoáº¡ch lÃ m 1 mock app vá» nháº­n diá»‡n object, object nháº­n diá»‡n chá»‰ Ä‘Æ¡n giáº£n nhÆ°: tÃ²a nhÃ , bá»©c tÆ°á»ng, sky Theo em research thÃ¬ Ä‘á»ƒ detect cÃ¡c object nÃ y cáº§n ML train vÃ¬ mock app ko Ä‘em Ä‘i thÆ°Æ¡ng máº¡i hay kinh doanh nÃªn vá» pháº§n chi phÃ­ khÃ¡ eo háº¹p, nÃªn em muá»‘n tham kháº£o cÃ¡c ace lÃ  cÃ³ nÆ¡i nÃ o hay chá»• nÃ o cÃ³ sharing cÃ¡c model Ä‘Ã£ Ä‘c training Ä‘á»ƒ detect cÃ¡c object trÃªn khÃ´ng, (Ä‘á»™ chÃ­nh xÃ¡c <50% cÅ©ng ko váº¥n Ä‘á» gÃ¬), hoáº·c trial khÃ´ng giÆ°á»›i háº¡n time cháº³ng háº¡n sr má»i ngÆ°á»i vÃ¬ cÃ¢u há»i khÃ¡ khÃ´ng liÃªn quan Ä‘áº¿n ML cho láº¯m.",,,,,
"#transformer
ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai tá»«ng Ã¡p dá»¥ng kiáº¿n trÃºc transformer/module transformer encoder cho dá»¯ liá»‡u cÃ³ sá»‘ channel lÃ  1 chÆ°a áº¡? E Ä‘Ã£ Google má»™t há»“i nhÆ°ng chÆ°a tháº¥y má»™t established transformer-based model nÃ o cho dá»¯ liá»‡u cÃ³ sá»‘ channel lÃ  1 nhÆ° lÃ  CNN. Hiá»‡n táº¡i thÃ¬ e má»›i giáº£i quyáº¿t báº±ng cÃ¡ch Ä‘á»ƒ má»™t linear layer phÃ­a trÆ°á»›c positional encoding (vÃ  bá» embedding layer) (ko cÃ³ activation) Ä‘á»ƒ tÄƒng cá»¡ channel cá»§a Ä‘áº§u vÃ o. Cáº£m Æ¡n mn Ä‘Ã£ giÃºp Ä‘á»¡","ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai tá»«ng Ã¡p dá»¥ng kiáº¿n trÃºc transformer/module transformer encoder cho dá»¯ liá»‡u cÃ³ sá»‘ channel lÃ  1 chÆ°a áº¡? E Ä‘Ã£ Google má»™t há»“i nhÆ°ng chÆ°a tháº¥y má»™t established transformer-based model nÃ o cho dá»¯ liá»‡u cÃ³ sá»‘ channel lÃ  1 nhÆ° lÃ  CNN. Hiá»‡n táº¡i thÃ¬ e má»›i giáº£i quyáº¿t báº±ng cÃ¡ch Ä‘á»ƒ má»™t linear layer phÃ­a trÆ°á»›c positional encoding (vÃ  bá» embedding layer) (ko cÃ³ activation) Ä‘á»ƒ tÄƒng cá»¡ channel cá»§a Ä‘áº§u vÃ o. Cáº£m Æ¡n mn Ä‘Ã£ giÃºp Ä‘á»¡",#transformer,,,,
"VinAI Spring Workshop 2022 - Latest Research Results Presented by Our AI Residents + Ask me anything with our Scientists
https://fb.watch/cH2ByFRCWZ/",VinAI Spring Workshop 2022 - Latest Research Results Presented by Our AI Residents + Ask me anything with our Scientists https://fb.watch/cH2ByFRCWZ/,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Tranh thá»§ cuá»‘i tuáº§n á»Ÿ nhÃ  em cÃ y cho anh em clip Cross Sell Prediction trong series AI in Banking. BÃ i nÃ y khÃ´ng má»›i nhÆ°ng cÃ³ nhiá»u Ä‘iá»u em má»›i há»c nÃªn máº¡nh dáº¡n chia sáº» cÃ¹ng anh em trong quÃ¡ trÃ¬nh lÃ m model ğŸ™‚
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em.",KÃ­nh chÃ o cÃ¡c bÃ¡c. Tranh thá»§ cuá»‘i tuáº§n á»Ÿ nhÃ  em cÃ y cho anh em clip Cross Sell Prediction trong series AI in Banking. BÃ i nÃ y khÃ´ng má»›i nhÆ°ng cÃ³ nhiá»u Ä‘iá»u em má»›i há»c nÃªn máº¡nh dáº¡n chia sáº» cÃ¹ng anh em trong quÃ¡ trÃ¬nh lÃ m model Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em.,,,,,
"Seldon Core lÃ  má»™t framework há»— trá»£ package, deploy, autoscale vÃ  monitor model má»™t cÃ¡ch dá»… dÃ ng trÃªn Kubernetes. MÃ¬nh xin Ä‘Æ°á»£c chia sáº» má»™t sá»‘ kiáº¿n thá»©c vÃ  kinh nghiá»‡m khi lÃ m viá»‡c vá»›i Seldon Core nhÆ° sau:
https://quan-dang.github.io/2022/01/16/advanced-model-serving-using-seldon-core-and-kubernetes-p1/
https://quan-dang.github.io/2022/04/07/advanced-model-serving-using-seldon-core-and-kubernetes-p2/
Äá»ƒ há»c há»i thÃªm vÃ  giao lÆ°u chia sáº» kinh nghiá»‡m vá» MLOps, má»i ngÆ°á»i join group nÃ y nha https://www.facebook.com/groups/mlopsvn/
ChÃºc má»i ngÆ°á»Ÿi ngÃ y má»›i tá»‘t lÃ nh! :D","Seldon Core lÃ  má»™t framework há»— trá»£ package, deploy, autoscale vÃ  monitor model má»™t cÃ¡ch dá»… dÃ ng trÃªn Kubernetes. MÃ¬nh xin Ä‘Æ°á»£c chia sáº» má»™t sá»‘ kiáº¿n thá»©c vÃ  kinh nghiá»‡m khi lÃ m viá»‡c vá»›i Seldon Core nhÆ° sau: https://quan-dang.github.io/2022/01/16/advanced-model-serving-using-seldon-core-and-kubernetes-p1/ https://quan-dang.github.io/2022/04/07/advanced-model-serving-using-seldon-core-and-kubernetes-p2/ Äá»ƒ há»c há»i thÃªm vÃ  giao lÆ°u chia sáº» kinh nghiá»‡m vá» MLOps, má»i ngÆ°á»i join group nÃ y nha https://www.facebook.com/groups/mlopsvn/ ChÃºc má»i ngÆ°á»Ÿi ngÃ y má»›i tá»‘t lÃ nh! :D",,,,,
"ChÃ o má»i ngÆ°á»i, cÃ³ má»™t project Ä‘ang cáº§n deploy model pytorch lÃªn server (EC2 aws), vÃ  cÃ³ khoáº£ng 3 request/s. Hiá»‡n táº¡i Ä‘ang deployed báº±ng fastapi, má»—i request thÃ¬ inference vá»›i batch-size = 1, MÃ¬nh muá»‘n tá»‘i Æ°u inference time báº±ng cÃ¡ch tÄƒng batch size lÃªn. KhÃ´ng biáº¿t cÃ³ dá»‹ch vá»¥ nÃ o cÃ³ sáºµn Ä‘á»ƒ tá»‘i Æ°u khÃ´ng áº¡? 
MÃ¬nh cÃ³ biáº¿t tá»›i Amazon SageMaker nhÆ°ng cÃ³ váº» nÃ³ deploy trÃªn má»™t pháº§n cá»©ng riÃªng. NhÆ°ng mÃ¬nh Ä‘Ã£ cÃ³ EC2 rá»“i vÃ  muá»‘n táº­n dá»¥ng tÃ i nguyÃªn cá»§a EC2 Ä‘á»ƒ deploy Ä‘Æ°á»£c khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, cÃ³ má»™t project Ä‘ang cáº§n deploy model pytorch lÃªn server (EC2 aws), vÃ  cÃ³ khoáº£ng 3 request/s. Hiá»‡n táº¡i Ä‘ang deployed báº±ng fastapi, má»—i request thÃ¬ inference vá»›i batch-size = 1, MÃ¬nh muá»‘n tá»‘i Æ°u inference time báº±ng cÃ¡ch tÄƒng batch size lÃªn. KhÃ´ng biáº¿t cÃ³ dá»‹ch vá»¥ nÃ o cÃ³ sáºµn Ä‘á»ƒ tá»‘i Æ°u khÃ´ng áº¡? MÃ¬nh cÃ³ biáº¿t tá»›i Amazon SageMaker nhÆ°ng cÃ³ váº» nÃ³ deploy trÃªn má»™t pháº§n cá»©ng riÃªng. NhÆ°ng mÃ¬nh Ä‘Ã£ cÃ³ EC2 rá»“i vÃ  muá»‘n táº­n dá»¥ng tÃ i nguyÃªn cá»§a EC2 Ä‘á»ƒ deploy Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ 2 viá»‡c cáº§n lÃ m nhÆ°ng chÆ°a biáº¿t báº¯t Ä‘áº§u nhÆ° tháº¿ nÃ o, nhá» má»i ngÆ°á»i há»— trá»£ keyword Ä‘á»ƒ mÃ¬nh giáº£i quyáº¿t Ä‘Æ°á»£c cÃ´ng viá»‡c
1. Äá»c thong tin tá»« Passport
2. Xá»­ lÃ½ dá»¯ liá»‡u data ngÆ°á»i dÃ¹ng Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ¡c má»¥c tiÃªu cá»¥ thá»ƒ.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ 2 viá»‡c cáº§n lÃ m nhÆ°ng chÆ°a biáº¿t báº¯t Ä‘áº§u nhÆ° tháº¿ nÃ o, nhá» má»i ngÆ°á»i há»— trá»£ keyword Ä‘á»ƒ mÃ¬nh giáº£i quyáº¿t Ä‘Æ°á»£c cÃ´ng viá»‡c 1. Äá»c thong tin tá»« Passport 2. Xá»­ lÃ½ dá»¯ liá»‡u data ngÆ°á»i dÃ¹ng Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ¡c má»¥c tiÃªu cá»¥ thá»ƒ.",,,,,
"MÃ¬nh tháº¥y quyá»ƒn nÃ y má»›i release trÃªn reddit. MÃ¬nh chÆ°a Ä‘á»c chi tiáº¿t, nhÆ°ng xem qua má»¥c lá»¥c thÃ¬ tháº¥y khÃ¡ thÃº vá»‹. NÃ³ lÃ  working-project nÃªn nhá»¯ng pháº§n váº«n chÆ°a cÃ³. Tuy nhiÃªn thÃ¬ cÃ³ thá»ƒ bookmark láº¡i, khi nÃ o ng ta release tiáº¿p thÃ¬ xem tiáº¿p.","MÃ¬nh tháº¥y quyá»ƒn nÃ y má»›i release trÃªn reddit. MÃ¬nh chÆ°a Ä‘á»c chi tiáº¿t, nhÆ°ng xem qua má»¥c lá»¥c thÃ¬ tháº¥y khÃ¡ thÃº vá»‹. NÃ³ lÃ  working-project nÃªn nhá»¯ng pháº§n váº«n chÆ°a cÃ³. Tuy nhiÃªn thÃ¬ cÃ³ thá»ƒ bookmark láº¡i, khi nÃ o ng ta release tiáº¿p thÃ¬ xem tiáº¿p.",,,,,
TÃ i liá»‡u lÃ m quen vá»›i Computer Vision trong vÃ²ng 365 ngÃ y cho ngÆ°á»i má»›i báº¯t Ä‘áº§u.,TÃ i liá»‡u lÃ m quen vá»›i Computer Vision trong vÃ²ng 365 ngÃ y cho ngÆ°á»i má»›i báº¯t Ä‘áº§u.,,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh cÃ³ gáº·p chÃºt váº¥n Ä‘á» muá»‘n xin Ã½ tÆ°á»Ÿng .
Cháº£ lÃ  mÃ¬nh Ä‘ang cÃ³ 1 máº¡ng CNN nháº­n Ä‘áº§u vÃ o lÃ  1 input áº£nh 1 kÃªnh (gray). giá» mÃ¬nh muá»‘n finetuning nÃ³ nhÆ°ng láº¡i muá»‘n áº£nh Ä‘áº§u vÃ o pháº£i lÃ  3 kÃªnh rgb . náº¿u nhÆ° tá»« rgb mÃ  convert vá» gray thÃ¬ mÃ¬nh tháº¥y sáº½ bá»‹ máº¥t thÃ´ng tin áº£nh ( áº£nh low contrast). ThÃ¬ khÃ´ng biáº¿t mn cÃ³ Ã½ tÆ°á»Ÿng cÃ¡ch nÃ o cÃ³ thá»ƒ giÃºp mÃ¬nh khÃ´ng nhá»‰. MÃ¬nh cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh cÃ³ gáº·p chÃºt váº¥n Ä‘á» muá»‘n xin Ã½ tÆ°á»Ÿng . Cháº£ lÃ  mÃ¬nh Ä‘ang cÃ³ 1 máº¡ng CNN nháº­n Ä‘áº§u vÃ o lÃ  1 input áº£nh 1 kÃªnh (gray). giá» mÃ¬nh muá»‘n finetuning nÃ³ nhÆ°ng láº¡i muá»‘n áº£nh Ä‘áº§u vÃ o pháº£i lÃ  3 kÃªnh rgb . náº¿u nhÆ° tá»« rgb mÃ  convert vá» gray thÃ¬ mÃ¬nh tháº¥y sáº½ bá»‹ máº¥t thÃ´ng tin áº£nh ( áº£nh low contrast). ThÃ¬ khÃ´ng biáº¿t mn cÃ³ Ã½ tÆ°á»Ÿng cÃ¡ch nÃ o cÃ³ thá»ƒ giÃºp mÃ¬nh khÃ´ng nhá»‰. MÃ¬nh cáº£m Æ¡n",,,,,
"[AI - EditGAN]
Máº¡ng GAN gáº§n Ä‘Ã¢y Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c á»©ng dá»¥ng chá»‰nh sá»­a hÃ¬nh áº£nh. Tuy nhiÃªn, háº§u háº¿t cÃ¡c phÆ°Æ¡ng phÃ¡p chá»‰nh sá»­a hÃ¬nh áº£nh dá»±a trÃªn máº¡ng GAN thÆ°á»ng yÃªu cáº§u bá»™ dá»¯ liá»‡u lá»›n kÃ¨m nhÃ£n cá»§a nÃ³. EditGAN lÃ  má»™t phÆ°Æ¡ng phÃ¡p chá»‰nh sá»­a hÃ¬nh áº£nh má»›i, cung cáº¥p kháº£ nÄƒng chá»‰nh sá»­a cÃ³ Ä‘á»™ chÃ­nh xÃ¡c ráº¥t cao mÃ  chá»‰ yÃªu cáº§u ráº¥t Ã­t dá»¯ liá»‡u cÃ³ chÃº thÃ­ch nhÃ£n. ThÃªm vÃ o Ä‘Ã³, EditGAN cÃ³ thá»ƒ cháº¡y trong thá»i gian thá»±c, cÃ³ thá»ƒ thao tÃ¡c chá»‰nh sá»­a dá»… dÃ ng vÃ  cÃ³ thá»ƒ chá»‰nh sá»­a nhiá»u láº§n má»™t lÃºc vÃ  váº«n giá»¯ Ä‘Æ°á»£c cháº¥t lÆ°á»£ng hÃ¬nh áº£nh.
Tham kháº£o thÃªm:
https://nv-tlabs.github.io/editGAN/","[AI - EditGAN] Máº¡ng GAN gáº§n Ä‘Ã¢y Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c á»©ng dá»¥ng chá»‰nh sá»­a hÃ¬nh áº£nh. Tuy nhiÃªn, háº§u háº¿t cÃ¡c phÆ°Æ¡ng phÃ¡p chá»‰nh sá»­a hÃ¬nh áº£nh dá»±a trÃªn máº¡ng GAN thÆ°á»ng yÃªu cáº§u bá»™ dá»¯ liá»‡u lá»›n kÃ¨m nhÃ£n cá»§a nÃ³. EditGAN lÃ  má»™t phÆ°Æ¡ng phÃ¡p chá»‰nh sá»­a hÃ¬nh áº£nh má»›i, cung cáº¥p kháº£ nÄƒng chá»‰nh sá»­a cÃ³ Ä‘á»™ chÃ­nh xÃ¡c ráº¥t cao mÃ  chá»‰ yÃªu cáº§u ráº¥t Ã­t dá»¯ liá»‡u cÃ³ chÃº thÃ­ch nhÃ£n. ThÃªm vÃ o Ä‘Ã³, EditGAN cÃ³ thá»ƒ cháº¡y trong thá»i gian thá»±c, cÃ³ thá»ƒ thao tÃ¡c chá»‰nh sá»­a dá»… dÃ ng vÃ  cÃ³ thá»ƒ chá»‰nh sá»­a nhiá»u láº§n má»™t lÃºc vÃ  váº«n giá»¯ Ä‘Æ°á»£c cháº¥t lÆ°á»£ng hÃ¬nh áº£nh. Tham kháº£o thÃªm: https://nv-tlabs.github.io/editGAN/",,,,,
"[Há»i vá» sá»± há»™i tá»¥ cá»§a gradient norm trong mÃ´ hÃ¬nh neural networks] MÃ¬nh muá»‘n há»i vá» táº¡i sao khi train 1 sá»‘ neural networks (ResNet, VGG,..) thÃ¬ accuracy vÃ  classification loss (log-loss) cá»§a mÃ´ hÃ¬nh há»™i tá»¥ theo epochs, tuy nhiÃªn gradient norm cá»§a hÃ m loss vá»›i tham sá»‘ thÃ¬ khÃ´ng há»™i tá»¥ ? Tháº­m chÃ­ gradient norm cÃ²n cÃ³ chiá»u hÆ°á»›ng Ä‘i lÃªn thay vÃ¬ giáº£m dáº§n.
MÃ¬nh Ä‘Ã£ thá»­ thay Ä‘á»•i batch-size, learning rate ( nhá» dáº§n) nhÆ°ng gradient norm vÃ¢n khÃ´ng há»™i tá»¥ vá» giÃ¡ trá»‹ gáº§n 0.
Notes: MÃ¬nh lÃ m ML kha khÃ¡ nhiá»u (8 nÄƒm), vÃ  Ä‘Ã£ publish as first authors kha khÃ¡ á»Ÿ ICML/ICLR,..va biáº¿t tá»‘c Ä‘á»™ há»™i tá»¥ cá»§a hÃ m loss/ gradient norm cá»§a cÃ¡c hÃ m convex, smooth, Lipschitz. Tuy nhiÃªn kiáº¿n thá»©c vá» sá»± há»™i tá»¥ cá»§a gradient norm vá»›i cÃ¡c hÃ m loss nhÆ° trong neural networks thÃ¬ mÃ¬nh khÃ´ng biáº¿t nhiá»u. NÃªn cáº§n chuyÃªn gia vá» optimization giáº£i thÃ­ch kÄ© váº¥n Ä‘á» nÃ y. MÃ¬nh xin cáº£m Æ¡n.","[Há»i vá» sá»± há»™i tá»¥ cá»§a gradient norm trong mÃ´ hÃ¬nh neural networks] MÃ¬nh muá»‘n há»i vá» táº¡i sao khi train 1 sá»‘ neural networks (ResNet, VGG,..) thÃ¬ accuracy vÃ  classification loss (log-loss) cá»§a mÃ´ hÃ¬nh há»™i tá»¥ theo epochs, tuy nhiÃªn gradient norm cá»§a hÃ m loss vá»›i tham sá»‘ thÃ¬ khÃ´ng há»™i tá»¥ ? Tháº­m chÃ­ gradient norm cÃ²n cÃ³ chiá»u hÆ°á»›ng Ä‘i lÃªn thay vÃ¬ giáº£m dáº§n. MÃ¬nh Ä‘Ã£ thá»­ thay Ä‘á»•i batch-size, learning rate ( nhá» dáº§n) nhÆ°ng gradient norm vÃ¢n khÃ´ng há»™i tá»¥ vá» giÃ¡ trá»‹ gáº§n 0. Notes: MÃ¬nh lÃ m ML kha khÃ¡ nhiá»u (8 nÄƒm), vÃ  Ä‘Ã£ publish as first authors kha khÃ¡ á»Ÿ ICML/ICLR,..va biáº¿t tá»‘c Ä‘á»™ há»™i tá»¥ cá»§a hÃ m loss/ gradient norm cá»§a cÃ¡c hÃ m convex, smooth, Lipschitz. Tuy nhiÃªn kiáº¿n thá»©c vá» sá»± há»™i tá»¥ cá»§a gradient norm vá»›i cÃ¡c hÃ m loss nhÆ° trong neural networks thÃ¬ mÃ¬nh khÃ´ng biáº¿t nhiá»u. NÃªn cáº§n chuyÃªn gia vá» optimization giáº£i thÃ­ch kÄ© váº¥n Ä‘á» nÃ y. MÃ¬nh xin cáº£m Æ¡n.",,,,,
"ChÃ o cÃ¡c bÃ¡c, nhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu sÆ¡ bá»™ vá» Multi Labels Classification em máº¡nh dáº¡n lÃ m clip chia sáº» cÆ¡ báº£n nháº¥t cho cÃ¡c báº¡n má»›i há»c.
Mong giÃºp Ä‘Æ°á»£c má»i ngÆ°á»i!","ChÃ o cÃ¡c bÃ¡c, nhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu sÆ¡ bá»™ vá» Multi Labels Classification em máº¡nh dáº¡n lÃ m clip chia sáº» cÆ¡ báº£n nháº¥t cho cÃ¡c báº¡n má»›i há»c. Mong giÃºp Ä‘Æ°á»£c má»i ngÆ°á»i!",,,,,
"Cuá»‘i tuáº§n rá»“i, xin gÃ³p vui vá»›i cÃ¡c báº¡n bÃ i toÃ¡n phÃ¢n loáº¡i 8 loáº¡i Ä‘á»™ng kinh (seizure) tá»« tÃ­n hiá»‡u ElectroEncephaloGram (EEG) tá»« dataset TUH seizure v1.5.2 táº¡i Ä‘Ã¢y (https://isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_seizure/v1.5.2/)
PhÆ°Æ¡ng phÃ¡p giáº£i quyáº¿t cá»§a mÃ¬nh nhÆ° sau:
B1. TrÃ­ch xuáº¥t vÃ  chuyá»ƒn dá»¯ liá»‡u dáº¡ng tÃ­n hiá»‡u thÃ nh dáº¡ng spectrogram sá»­ dá»¥ng thuáº­t toÃ¡n Fast Fourier Transform vá»›i cÃ¡c thiáº¿t láº­p nhÆ° sau: window length = 0.25 giÃ¢y, step length = 0.0625 giÃ¢y, Frequency sampling = 250 Hz. 6 trong 8 loáº¡i Ä‘á»™ng kinh sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t háº¿t dá»¯ liá»‡u, 2 trong 8 sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t láº§n lÆ°á»£t lÃ  100 vÃ  500 spectrogram samples (lÃ­ do lÃ  2 lá»›p GN vÃ  GN cÃ³ ráº¥t nhiá»u dá»¯ liá»‡u vá»›i sá»‘ bá»‡nh nhÃ¢n cÅ©ng nhÆ° thá»i gian Ä‘á»™ng kinh cho má»—i láº§n lÃ  dÃ i).
B2. Nháº­n diá»‡n cáº¡nh cá»§a spectrograms báº±ng thuáº­t toÃ¡n Sobel vÃ  chuyá»ƒn nÃ³ sang dáº¡ng áº£nh cÃ³ kÃ­ch thÆ°á»›c 32x48x1
B3. Biáº¿n áº£nh nháº­n diá»‡n cáº¡nh nÃ y thÃ nh Graph-structured data
B4. Huáº¥n luyá»‡n model GNN vá»›i 3 layers kiáº¿n trÃºc cÃ³ tÃªn lÃ  GraphConv (xem hÃ¬nh tiáº¿n trÃ¬nh Ä‘o lÆ°á»ng quÃ¡ trÃ¬nh huáº¥n luyá»‡n)
B5. Dá»± Ä‘oÃ¡n trÃªn test set nhÆ° hÃ¬nh confusion matrix
ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº».
Ps. Náº¿u má»—i láº§n Ä‘á»™ng kinh cá»§a bá»‡nh nhÃ¢n ta chá»‰ trÃ­ch xuáº¥t ngáº«u nhiÃªn 1 spectrogram thÃ¬ káº¿t quáº£ váº«n ráº¥t kháº£ quan, tuy nhiÃªn lá»›p MY khÃ´ng phÃ¢n loáº¡i Ä‘Æ°á»£c vÃ¬ chá»‰ cÃ³ 3 láº§n Ä‘á»™ng kinh loáº¡i nÃ y Ä‘Æ°á»£c ghi láº¡i trÃªn Ä‘Ãºng 2 bá»‡nh nháº­n (xem confusion matrix cÃ³ sá»‘ lÆ°á»£ng áº£nh test set nhá»!!!!) vÃ  quÃ¡ trÃ¬nh huáº¥n luyá»‡n cÅ©ng lÃ¢u há»™i tá»¥ hÆ¡n (xem training curve!)","Cuá»‘i tuáº§n rá»“i, xin gÃ³p vui vá»›i cÃ¡c báº¡n bÃ i toÃ¡n phÃ¢n loáº¡i 8 loáº¡i Ä‘á»™ng kinh (seizure) tá»« tÃ­n hiá»‡u ElectroEncephaloGram (EEG) tá»« dataset TUH seizure v1.5.2 táº¡i Ä‘Ã¢y (https://isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_seizure/v1.5.2/) PhÆ°Æ¡ng phÃ¡p giáº£i quyáº¿t cá»§a mÃ¬nh nhÆ° sau: B1. TrÃ­ch xuáº¥t vÃ  chuyá»ƒn dá»¯ liá»‡u dáº¡ng tÃ­n hiá»‡u thÃ nh dáº¡ng spectrogram sá»­ dá»¥ng thuáº­t toÃ¡n Fast Fourier Transform vá»›i cÃ¡c thiáº¿t láº­p nhÆ° sau: window length = 0.25 giÃ¢y, step length = 0.0625 giÃ¢y, Frequency sampling = 250 Hz. 6 trong 8 loáº¡i Ä‘á»™ng kinh sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t háº¿t dá»¯ liá»‡u, 2 trong 8 sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t láº§n lÆ°á»£t lÃ  100 vÃ  500 spectrogram samples (lÃ­ do lÃ  2 lá»›p GN vÃ  GN cÃ³ ráº¥t nhiá»u dá»¯ liá»‡u vá»›i sá»‘ bá»‡nh nhÃ¢n cÅ©ng nhÆ° thá»i gian Ä‘á»™ng kinh cho má»—i láº§n lÃ  dÃ i). B2. Nháº­n diá»‡n cáº¡nh cá»§a spectrograms báº±ng thuáº­t toÃ¡n Sobel vÃ  chuyá»ƒn nÃ³ sang dáº¡ng áº£nh cÃ³ kÃ­ch thÆ°á»›c 32x48x1 B3. Biáº¿n áº£nh nháº­n diá»‡n cáº¡nh nÃ y thÃ nh Graph-structured data B4. Huáº¥n luyá»‡n model GNN vá»›i 3 layers kiáº¿n trÃºc cÃ³ tÃªn lÃ  GraphConv (xem hÃ¬nh tiáº¿n trÃ¬nh Ä‘o lÆ°á»ng quÃ¡ trÃ¬nh huáº¥n luyá»‡n) B5. Dá»± Ä‘oÃ¡n trÃªn test set nhÆ° hÃ¬nh confusion matrix ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº». Ps. Náº¿u má»—i láº§n Ä‘á»™ng kinh cá»§a bá»‡nh nhÃ¢n ta chá»‰ trÃ­ch xuáº¥t ngáº«u nhiÃªn 1 spectrogram thÃ¬ káº¿t quáº£ váº«n ráº¥t kháº£ quan, tuy nhiÃªn lá»›p MY khÃ´ng phÃ¢n loáº¡i Ä‘Æ°á»£c vÃ¬ chá»‰ cÃ³ 3 láº§n Ä‘á»™ng kinh loáº¡i nÃ y Ä‘Æ°á»£c ghi láº¡i trÃªn Ä‘Ãºng 2 bá»‡nh nháº­n (xem confusion matrix cÃ³ sá»‘ lÆ°á»£ng áº£nh test set nhá»!!!!) vÃ  quÃ¡ trÃ¬nh huáº¥n luyá»‡n cÅ©ng lÃ¢u há»™i tá»¥ hÆ¡n (xem training curve!)",,,,,
TÃ i liá»‡u xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cá»§a Ä‘áº¡i há»c Oxford cho ai quan tÃ¢m,TÃ i liá»‡u xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cá»§a Ä‘áº¡i há»c Oxford cho ai quan tÃ¢m,,,,,
"#objectdetection #yolor
CÃ¡c paper thÆ°á»ng nÃ³i detection head Ä‘áº·t táº¡i layer ""nÃ´ng"" hÆ¡n thÆ°á»ng nháº­n diá»‡n object kÃ­ch thÆ°á»›c nhá» tá»‘t hÆ¡n vÃ  detection head Ä‘áº·t táº¡i layer sÃ¢u hÆ¡n nháº­n diá»‡n object kÃ­ch thÆ°á»›c lá»›n tá»‘t hÆ¡n. MÃ¬nh Ä‘Ã£ kiá»ƒm nghiá»‡m Ä‘iá»u nÃ y vá»›i YOLOR, cá»¥ thá»ƒ vá»›i YOLOR-w6 Ä‘Æ°á»£c nháº¯c tá»›i trong paper. MÃ¬nh Ä‘Ã£ tÃ¡ch 4 detection head cá»§a YOLOR-w6 (táº¡i conv layer thá»© 28, 32, 36, 40) ra lÃ m 4 model, má»—i model con cÃ³ má»™t detection head. VÃ  káº¿t quáº£ nháº­n Ä‘Æ°á»£c Ä‘Ãºng nhÆ° trÃªn lÃ½ thuyáº¿t:
log chi tiáº¿t táº¡i: https://drive.google.com/file/d/1-319l7cs56rYbIt4y0FiS7Se20-yRTaN/view?usp=sharing
NhÆ° váº­y, Ä‘á»‘i vá»›i bÃ i toÃ¡n nháº­n diá»‡n object kÃ­ch thÆ°á»›c nhá», ta cÃ³ thá»ƒ tá»‘i Æ°u chi phÃ­ tÃ­nh toÃ¡n báº±ng cÃ¡ch cáº¯t giáº£m Ä‘i cÃ¡c nhÃ¡nh khÃ´ng cáº§n thiáº¿t mÃ  váº«n giá»¯ nguyÃªn Ä‘Æ°á»£c cháº¥t lÆ°á»£ng model. káº¿t quáº£ cho tháº¥y model head1 cÃ³ inference time giáº£m 20% so vá»›i model gá»‘c NgoÃ i ra, dá»± vÃ o sá»‘ liá»‡u thá»‘ng kÃª cho tháº¥y detection head 28 tuy á»Ÿ vá»‹ trÃ­ nÃ´ng hÆ¡n detection head 32 nhÆ°ng káº¿t quáº£ nháº­n diá»‡n object nhá» táº¡i detection head 32 tá»‘t hÆ¡n, táº¡i sao?ğŸ˜£
MÃ¬nh cáº§n lÃ m gÃ¬ Ä‘á»ƒ tá»‘i Æ°u thÃªm cho model?","CÃ¡c paper thÆ°á»ng nÃ³i detection head Ä‘áº·t táº¡i layer ""nÃ´ng"" hÆ¡n thÆ°á»ng nháº­n diá»‡n object kÃ­ch thÆ°á»›c nhá» tá»‘t hÆ¡n vÃ  detection head Ä‘áº·t táº¡i layer sÃ¢u hÆ¡n nháº­n diá»‡n object kÃ­ch thÆ°á»›c lá»›n tá»‘t hÆ¡n. MÃ¬nh Ä‘Ã£ kiá»ƒm nghiá»‡m Ä‘iá»u nÃ y vá»›i YOLOR, cá»¥ thá»ƒ vá»›i YOLOR-w6 Ä‘Æ°á»£c nháº¯c tá»›i trong paper. MÃ¬nh Ä‘Ã£ tÃ¡ch 4 detection head cá»§a YOLOR-w6 (táº¡i conv layer thá»© 28, 32, 36, 40) ra lÃ m 4 model, má»—i model con cÃ³ má»™t detection head. VÃ  káº¿t quáº£ nháº­n Ä‘Æ°á»£c Ä‘Ãºng nhÆ° trÃªn lÃ½ thuyáº¿t: log chi tiáº¿t táº¡i: https://drive.google.com/file/d/1-319l7cs56rYbIt4y0FiS7Se20-yRTaN/view?usp=sharing NhÆ° váº­y, Ä‘á»‘i vá»›i bÃ i toÃ¡n nháº­n diá»‡n object kÃ­ch thÆ°á»›c nhá», ta cÃ³ thá»ƒ tá»‘i Æ°u chi phÃ­ tÃ­nh toÃ¡n báº±ng cÃ¡ch cáº¯t giáº£m Ä‘i cÃ¡c nhÃ¡nh khÃ´ng cáº§n thiáº¿t mÃ  váº«n giá»¯ nguyÃªn Ä‘Æ°á»£c cháº¥t lÆ°á»£ng model. káº¿t quáº£ cho tháº¥y model head1 cÃ³ inference time giáº£m 20% so vá»›i model gá»‘c NgoÃ i ra, dá»± vÃ o sá»‘ liá»‡u thá»‘ng kÃª cho tháº¥y detection head 28 tuy á»Ÿ vá»‹ trÃ­ nÃ´ng hÆ¡n detection head 32 nhÆ°ng káº¿t quáº£ nháº­n diá»‡n object nhá» táº¡i detection head 32 tá»‘t hÆ¡n, táº¡i sao? MÃ¬nh cáº§n lÃ m gÃ¬ Ä‘á»ƒ tá»‘i Æ°u thÃªm cho model?",#objectdetection	#yolor,,,,
"[AI News â€“ Explainable CNNs]
ChÃºng ta thÆ°á»ng biáº¿t Ä‘áº¿n mÃ´ hÃ¬nh Deep Learning nhÆ° má»™t há»™p Ä‘en. Äá»ƒ giáº£i thÃ­ch há»™p Ä‘en Ä‘Ã³, Explainable CNNs lÃ  má»™t package giÃºp visualize cho báº¥t ká»³ mÃ´ hÃ¬nh nÃ o dá»±a trÃªn CNN, Ä‘Æ°á»£c viáº¿t báº±ng Pytorch. Package nÃ y sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn dá»¯ liá»‡u ( data centric). Explainable CNNs táº¡o cÃ¡c giáº£i thÃ­ch theo tá»«ng lá»›p CNN dá»±a trÃªn gradient vÃ  xÃ¢y dá»±ng cÃ¡c biá»ƒu diá»…n khÃ¡c nhau bao gá»“m Saliency Map, Guided BackPropagation, Grad CAM and Guided Grad CAM.
Tham kháº£o thÃªm á»Ÿ Ä‘Ã¢y:
https://github.com/ashutosh1919/explainable-cnn
https://pypi.org/project/explainable-cnn/","[AI News â€“ Explainable CNNs] ChÃºng ta thÆ°á»ng biáº¿t Ä‘áº¿n mÃ´ hÃ¬nh Deep Learning nhÆ° má»™t há»™p Ä‘en. Äá»ƒ giáº£i thÃ­ch há»™p Ä‘en Ä‘Ã³, Explainable CNNs lÃ  má»™t package giÃºp visualize cho báº¥t ká»³ mÃ´ hÃ¬nh nÃ o dá»±a trÃªn CNN, Ä‘Æ°á»£c viáº¿t báº±ng Pytorch. Package nÃ y sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn dá»¯ liá»‡u ( data centric). Explainable CNNs táº¡o cÃ¡c giáº£i thÃ­ch theo tá»«ng lá»›p CNN dá»±a trÃªn gradient vÃ  xÃ¢y dá»±ng cÃ¡c biá»ƒu diá»…n khÃ¡c nhau bao gá»“m Saliency Map, Guided BackPropagation, Grad CAM and Guided Grad CAM. Tham kháº£o thÃªm á»Ÿ Ä‘Ã¢y: https://github.com/ashutosh1919/explainable-cnn https://pypi.org/project/explainable-cnn/",,,,,
"E chÃ o má»i ngÆ°á»i. E má»›i há»c ML vÃ  gáº·p 1 váº¥n Ä‘á» nhÆ° nÃ y mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡: Khi tiáº¿p cáº­n vá»›i bÃ i toÃ¡n ML, e thÆ°á»ng dÃ¹ng GridSearchCV Ä‘á»ƒ giáº£i quyáº¿t nhÆ°ng e k biáº¿t lÃ m cÃ¡ch nÃ o Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c sao nÃ³ láº¡i chá»n ra Ä‘Æ°á»£c parameters tá»‘i Æ°u nhÆ° váº­y. Kiá»ƒu e cáº£m giÃ¡c khÃ¡ lÃ  random. Cho e há»i lÃ m sao Ä‘á»ƒ mÃ¬nh hiá»ƒu Ä‘Æ°á»£c viá»‡c GridSearchCV lá»±a chá»n parameters tá»‘i Æ°u vÃ  thÃªm ná»¯a lÃ  hiá»ƒu Ä‘Æ°á»£c bÃ i toÃ¡n nÃ y thÃ¬ nÃªn Ã¡p dá»¥ng model nÃ o. Hay chá»‰ cáº§n cho háº¿t cÃ¡c model vÃ o GridSearchCV lÃ  nÃ³ tá»± Ä‘á»™ng giáº£i quyáº¿t háº¿t cho mÃ¬nh luÃ´n áº¡. E cáº£m Æ¡n","E chÃ o má»i ngÆ°á»i. E má»›i há»c ML vÃ  gáº·p 1 váº¥n Ä‘á» nhÆ° nÃ y mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡: Khi tiáº¿p cáº­n vá»›i bÃ i toÃ¡n ML, e thÆ°á»ng dÃ¹ng GridSearchCV Ä‘á»ƒ giáº£i quyáº¿t nhÆ°ng e k biáº¿t lÃ m cÃ¡ch nÃ o Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c sao nÃ³ láº¡i chá»n ra Ä‘Æ°á»£c parameters tá»‘i Æ°u nhÆ° váº­y. Kiá»ƒu e cáº£m giÃ¡c khÃ¡ lÃ  random. Cho e há»i lÃ m sao Ä‘á»ƒ mÃ¬nh hiá»ƒu Ä‘Æ°á»£c viá»‡c GridSearchCV lá»±a chá»n parameters tá»‘i Æ°u vÃ  thÃªm ná»¯a lÃ  hiá»ƒu Ä‘Æ°á»£c bÃ i toÃ¡n nÃ y thÃ¬ nÃªn Ã¡p dá»¥ng model nÃ o. Hay chá»‰ cáº§n cho háº¿t cÃ¡c model vÃ o GridSearchCV lÃ  nÃ³ tá»± Ä‘á»™ng giáº£i quyáº¿t háº¿t cho mÃ¬nh luÃ´n áº¡. E cáº£m Æ¡n",,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang convert ML model format cá»§a tensorflow sang tflite, trong Ä‘Ã³ cÃ³ LSTM layer. Tuy nhiÃªn, khi xem trÃªn Netron, thÃ¬ pháº§n activation function cá»§a LSTM layer chá»‰ cÃ²n cÃ³ má»—i hÃ m [tanh]. Trong khi Ä‘Ã³, náº¿u convert sang format ONNX thÃ¬ Netron cho tháº¥y activation function cá»§a LSTM layer lÃ  [sigmoid, tanh, tanh]. Test thá»­ vÃ i data cho model trÃªn tflite format thi káº¿t quáº£ ra inference cÅ©ng Ä‘Ãºng. NhÆ°ng mÃ¬nh váº«n lÄƒn tÄƒn cÃ¡i format tflite liá»‡u cÃ³ mising bÆ°á»›c nÃ o trÆ°á»›c khi convert khÃ´ng? Báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» tflite hoáº·c info hoáº·c document link cho mÃ¬nh xin vá»›i. Cáº£m Æ¡n.","ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang convert ML model format cá»§a tensorflow sang tflite, trong Ä‘Ã³ cÃ³ LSTM layer. Tuy nhiÃªn, khi xem trÃªn Netron, thÃ¬ pháº§n activation function cá»§a LSTM layer chá»‰ cÃ²n cÃ³ má»—i hÃ m [tanh]. Trong khi Ä‘Ã³, náº¿u convert sang format ONNX thÃ¬ Netron cho tháº¥y activation function cá»§a LSTM layer lÃ  [sigmoid, tanh, tanh]. Test thá»­ vÃ i data cho model trÃªn tflite format thi káº¿t quáº£ ra inference cÅ©ng Ä‘Ãºng. NhÆ°ng mÃ¬nh váº«n lÄƒn tÄƒn cÃ¡i format tflite liá»‡u cÃ³ mising bÆ°á»›c nÃ o trÆ°á»›c khi convert khÃ´ng? Báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» tflite hoáº·c info hoáº·c document link cho mÃ¬nh xin vá»›i. Cáº£m Æ¡n.",,,,,
"WEBINAR ON INDUSTRIAL AI ENGINEERING - event date updated
(xin phÃ©p cÃ¡c Admins cho mÃ¬nh Ä‘Ã­nh chÃ­nh ngÃ y giá» thÃ nh: sÃ¡ng Thá»© Báº£y 23/4 VNT)

MÃ¬nh xin phÃ©p chia sáº» nhanh vá»›i cá»™ng Ä‘á»“ng cÃ¡c anh chá»‹ em cÃ³ backgrounds vá» Váº­t lÃ½, Ká»¹ thuáº­t, CÃ´ng nghá»‡â€¦ vá» má»™t online event bá»n mÃ¬nh sáº¯p lÃ m vá» máº£ng AI trong ngÃ nh CÃ´ng nghiá»‡p bit.ly/industrial-ai-event-vn-fb, sáº½ Ä‘Æ°á»£c tá»• chá»©c vÃ o sÃ¡ng Thá»© Báº£y 23/4 VNT.
Bá»n mÃ¬nh sáº½ chia sáº» vá» má»™t sá»‘ ná»™i dung chÃ­nh nhÆ° sau vá» viá»‡c Ã¡p dá»¥ng AI trong cÃ¡c ngÃ nh cÃ´ng nghiá»‡p náº·ng:
CÃ¡c cÆ¡ há»™i vÃ  thá»­ thÃ¡ch lá»›n trong Industrial AI
CÃ¡c á»©ng dá»¥ng AI cÃ´ng nghiá»‡p Ä‘iá»ƒn hÃ¬nh trong HÃ ng háº£i vÃ  Chuá»—i cung á»©ng
PhÆ°Æ¡ng phÃ¡p Ã¡p dá»¥ng Domain Expertise vÃ o AI cÃ´ng nghiá»‡p (â€œKnowledge-First AI"")
Nghiá»‡p vá»¥ AI Engineering Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c há»‡ thá»‘ng AI phá»©c há»£p
CÃ¡c cÃ´ng viá»‡c hÃ ng ngÃ y cá»§a AI Engineers lÃ m AI cÃ´ng nghiá»‡p
Háº¹n gáº·p má»i ngÆ°á»i á»Ÿ Webinar! MÃ¬nh xin cáº£m Æ¡n cÃ¡c anh chá»‹ em nhiá»u!
P.S.: Sau webinar bá»n mÃ¬nh cÅ©ng cÃ³ 2 buá»•i in-person meet-ups á»Ÿ HÃ  Ná»™i vÃ  HCM, cÃ¡c anh chá»‹ em nÃ o quan tÃ¢m cÅ©ng cÃ³ thá»ƒ Ä‘Äƒng kÃ½ luÃ´n áº¡.","WEBINAR ON INDUSTRIAL AI ENGINEERING - event date updated (xin phÃ©p cÃ¡c Admins cho mÃ¬nh Ä‘Ã­nh chÃ­nh ngÃ y giá» thÃ nh: sÃ¡ng Thá»© Báº£y 23/4 VNT) MÃ¬nh xin phÃ©p chia sáº» nhanh vá»›i cá»™ng Ä‘á»“ng cÃ¡c anh chá»‹ em cÃ³ backgrounds vá» Váº­t lÃ½, Ká»¹ thuáº­t, CÃ´ng nghá»‡â€¦ vá» má»™t online event bá»n mÃ¬nh sáº¯p lÃ m vá» máº£ng AI trong ngÃ nh CÃ´ng nghiá»‡p bit.ly/industrial-ai-event-vn-fb, sáº½ Ä‘Æ°á»£c tá»• chá»©c vÃ o sÃ¡ng Thá»© Báº£y 23/4 VNT. Bá»n mÃ¬nh sáº½ chia sáº» vá» má»™t sá»‘ ná»™i dung chÃ­nh nhÆ° sau vá» viá»‡c Ã¡p dá»¥ng AI trong cÃ¡c ngÃ nh cÃ´ng nghiá»‡p náº·ng: CÃ¡c cÆ¡ há»™i vÃ  thá»­ thÃ¡ch lá»›n trong Industrial AI CÃ¡c á»©ng dá»¥ng AI cÃ´ng nghiá»‡p Ä‘iá»ƒn hÃ¬nh trong HÃ ng háº£i vÃ  Chuá»—i cung á»©ng PhÆ°Æ¡ng phÃ¡p Ã¡p dá»¥ng Domain Expertise vÃ o AI cÃ´ng nghiá»‡p (â€œKnowledge-First AI"") Nghiá»‡p vá»¥ AI Engineering Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c há»‡ thá»‘ng AI phá»©c há»£p CÃ¡c cÃ´ng viá»‡c hÃ ng ngÃ y cá»§a AI Engineers lÃ m AI cÃ´ng nghiá»‡p Háº¹n gáº·p má»i ngÆ°á»i á»Ÿ Webinar! MÃ¬nh xin cáº£m Æ¡n cÃ¡c anh chá»‹ em nhiá»u! P.S.: Sau webinar bá»n mÃ¬nh cÅ©ng cÃ³ 2 buá»•i in-person meet-ups á»Ÿ HÃ  Ná»™i vÃ  HCM, cÃ¡c anh chá»‹ em nÃ o quan tÃ¢m cÅ©ng cÃ³ thá»ƒ Ä‘Äƒng kÃ½ luÃ´n áº¡.",,,,,
"Dáº¡ hiá»‡n em Ä‘ang kiáº¿m dá»¯ liá»‡u áº£nh Ä‘á»ƒ lÃ m bá»™ dá»¯ liá»‡u cho nháº­n diá»‡n khuÃ´n máº·t, cÃ³ anh/chá»‹ nÃ o biáº¿t/Ä‘Ã£ lÃ m qua cÃ¡ch crawl dá»¯ liá»‡u áº£nh cá»§a má»™t ngÆ°á»i nÃ o tá»« facebook hay google cho ngÆ°á»i Viá»‡t Nam chÆ°a áº¡ (Náº¿u cÃ³ github cho em xin tham kháº£o vá»›i áº¡).","Dáº¡ hiá»‡n em Ä‘ang kiáº¿m dá»¯ liá»‡u áº£nh Ä‘á»ƒ lÃ m bá»™ dá»¯ liá»‡u cho nháº­n diá»‡n khuÃ´n máº·t, cÃ³ anh/chá»‹ nÃ o biáº¿t/Ä‘Ã£ lÃ m qua cÃ¡ch crawl dá»¯ liá»‡u áº£nh cá»§a má»™t ngÆ°á»i nÃ o tá»« facebook hay google cho ngÆ°á»i Viá»‡t Nam chÆ°a áº¡ (Náº¿u cÃ³ github cho em xin tham kháº£o vá»›i áº¡).",,,,,
"#objectdetection #yolor #onnx
Tá»‘i Æ°u inference time YOLOR báº±ng Onnx.
ChÃ o má»i ngÆ°á»i, sau khi cÃ³ Ä‘Æ°á»£c model phÃ¹ há»£p cho bÃ i toÃ¡n, mÃ¬nh cá»‘ gáº¯ng export model sang dáº¡ng onnx (Ä‘Ã¢y cÃ³ láº½ lÃ  cháº·ng Ä‘Æ°á»ng cuá»‘i cÃ¹ng khi giáº£i bÃ i toÃ¡n). Khi xem qua code export cá»§a tÃ¡c giáº£ (https://github.com/WongKinYiu/yolor/blob/main/models/export.py), mÃ¬nh nháº­n tháº¥y cÃ³ báº¥t thÆ°á»ng: trong khi luá»“ng xá»­ lÃ½ yolor khi inference trÃªn pytorch, input image cÃ³ thá»ƒ cÃ³ kÃ­ch thÆ°á»›c báº¥t kÃ¬ miá»…n lÃ  khÃ´ng quÃ¡ nhá». CÃ²n khi export onnx, dá»±a vÃ o code cá»§a tÃ¡c giáº£ cÃ³ thá»ƒ Ä‘oÃ¡n tÃ¡c giáº£ muá»‘n cá»‘ Ä‘á»‹nh input shape (vÃ¬ tÃ¡c giáº£ khÃ´ng Ä‘á»‹nh nghÄ©a dynamic_axes cho hÃ m torch.onnx.export()). NhÆ° váº­y khi inference báº±ng onnx, ta báº¯t buá»™c resize image vá» kÃ­ch thÆ°á»›c Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, nÃ³ sáº½ khÃ´ng tá»‘i Æ°u náº¿u kÃ­ch thÆ°á»›c gá»‘c cá»§a input image khÃ¡c input shape cá»§a model. 
MÃ¬nh Ä‘Ã£ update code export vÃ  convert model sang onnx cÃ³ thá»ƒ inference trÃªn nhá»¯ng kÃ­ch thÆ°á»›c áº£nh báº¥t kÃ¬, nhÆ°ng chá»‰ cÃ³ thá»ƒ convert Ä‘Æ°á»£c toÃ n bá»™ layer trá»« detect head layer (khi inference thÃ¬ forward model onnx, sau Ä‘Ã³ láº¥y output cá»§a nÃ³ forward tiáº¿p qua detection head báº±ng pytorch). CÃ³ anh chá»‹ nÃ o Ä‘Ã£ convert Ä‘áº§y Ä‘á»§ model yolor sang onnx chÆ°a áº¡?","Tá»‘i Æ°u inference time YOLOR báº±ng Onnx. ChÃ o má»i ngÆ°á»i, sau khi cÃ³ Ä‘Æ°á»£c model phÃ¹ há»£p cho bÃ i toÃ¡n, mÃ¬nh cá»‘ gáº¯ng export model sang dáº¡ng onnx (Ä‘Ã¢y cÃ³ láº½ lÃ  cháº·ng Ä‘Æ°á»ng cuá»‘i cÃ¹ng khi giáº£i bÃ i toÃ¡n). Khi xem qua code export cá»§a tÃ¡c giáº£ (https://github.com/WongKinYiu/yolor/blob/main/models/export.py), mÃ¬nh nháº­n tháº¥y cÃ³ báº¥t thÆ°á»ng: trong khi luá»“ng xá»­ lÃ½ yolor khi inference trÃªn pytorch, input image cÃ³ thá»ƒ cÃ³ kÃ­ch thÆ°á»›c báº¥t kÃ¬ miá»…n lÃ  khÃ´ng quÃ¡ nhá». CÃ²n khi export onnx, dá»±a vÃ o code cá»§a tÃ¡c giáº£ cÃ³ thá»ƒ Ä‘oÃ¡n tÃ¡c giáº£ muá»‘n cá»‘ Ä‘á»‹nh input shape (vÃ¬ tÃ¡c giáº£ khÃ´ng Ä‘á»‹nh nghÄ©a dynamic_axes cho hÃ m torch.onnx.export()). NhÆ° váº­y khi inference báº±ng onnx, ta báº¯t buá»™c resize image vá» kÃ­ch thÆ°á»›c Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, nÃ³ sáº½ khÃ´ng tá»‘i Æ°u náº¿u kÃ­ch thÆ°á»›c gá»‘c cá»§a input image khÃ¡c input shape cá»§a model. MÃ¬nh Ä‘Ã£ update code export vÃ  convert model sang onnx cÃ³ thá»ƒ inference trÃªn nhá»¯ng kÃ­ch thÆ°á»›c áº£nh báº¥t kÃ¬, nhÆ°ng chá»‰ cÃ³ thá»ƒ convert Ä‘Æ°á»£c toÃ n bá»™ layer trá»« detect head layer (khi inference thÃ¬ forward model onnx, sau Ä‘Ã³ láº¥y output cá»§a nÃ³ forward tiáº¿p qua detection head báº±ng pytorch). CÃ³ anh chá»‹ nÃ o Ä‘Ã£ convert Ä‘áº§y Ä‘á»§ model yolor sang onnx chÆ°a áº¡?",#objectdetection	#yolor	#onnx,,,,
"e chÃ o mn áº¡, hiá»‡n táº¡i e Ä‘ang lÃ m Ä‘á»“ Ã¡n text-to-speech https://github.com/NVIDIA/tacotron2 . Hiá»‡n táº¡i thÃ¬ viá»‡c train, test Ä‘Ã£ xong rá»“i áº¡. Em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ pháº§n chuáº©n hÃ³a text Ä‘áº§u vÃ o, cÃ¡c danh má»¥c tá»« viáº¿t táº¯t, cÃ¡c Ä‘Æ¡n vá»‹ Ä‘o theo chuáº©n hÃ³a quá»‘c táº¿ ,.. Do thá»i gian cÃ²n láº¡i Ã­t nÃªn má»i ngÆ°á»i Ä‘Ã£ ai giáº£i quyáº¿t rá»“i cÃ³ tháº¿ nÃ³i Ã½ tÆ°á»Ÿng giÃºp em hoáº·c cÃ³ api Ä‘Ã¹ng cho viá»‡c chuáº©n hÃ³a nÃ y khÃ´ng áº¡. Em xin cáº£m Æ¡n áº¡!","e chÃ o mn áº¡, hiá»‡n táº¡i e Ä‘ang lÃ m Ä‘á»“ Ã¡n text-to-speech https://github.com/NVIDIA/tacotron2 . Hiá»‡n táº¡i thÃ¬ viá»‡c train, test Ä‘Ã£ xong rá»“i áº¡. Em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ pháº§n chuáº©n hÃ³a text Ä‘áº§u vÃ o, cÃ¡c danh má»¥c tá»« viáº¿t táº¯t, cÃ¡c Ä‘Æ¡n vá»‹ Ä‘o theo chuáº©n hÃ³a quá»‘c táº¿ ,.. Do thá»i gian cÃ²n láº¡i Ã­t nÃªn má»i ngÆ°á»i Ä‘Ã£ ai giáº£i quyáº¿t rá»“i cÃ³ tháº¿ nÃ³i Ã½ tÆ°á»Ÿng giÃºp em hoáº·c cÃ³ api Ä‘Ã¹ng cho viá»‡c chuáº©n hÃ³a nÃ y khÃ´ng áº¡. Em xin cáº£m Æ¡n áº¡!",,,,,
"e chÃ o mn áº¡, hiá»‡n táº¡i e Ä‘ang lÃ m Ä‘á»“ Ã¡n text-to-speech https://github.com/NVIDIA/tacotron2 . Hiá»‡n táº¡i thÃ¬ viá»‡c train, test Ä‘Ã£ xong rá»“i áº¡. Em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ pháº§n chuáº©n hÃ³a text Ä‘áº§u vÃ o, cÃ¡c danh má»¥c tá»« viáº¿t táº¯t, cÃ¡c Ä‘Æ¡n vá»‹ Ä‘o theo chuáº©n hÃ³a quá»‘c táº¿ ,.. Do thá»i gian cÃ²n láº¡i Ã­t nÃªn má»i ngÆ°á»i Ä‘Ã£ ai giáº£i quyáº¿t rá»“i cÃ³ tháº¿ nÃ³i Ã½ tÆ°á»Ÿng giÃºp em hoáº·c cÃ³ api Ä‘Ã¹ng cho viá»‡c chuáº©n hÃ³a nÃ y khÃ´ng áº¡. Em xin cáº£m Æ¡n áº¡!","e chÃ o mn áº¡, hiá»‡n táº¡i e Ä‘ang lÃ m Ä‘á»“ Ã¡n text-to-speech https://github.com/NVIDIA/tacotron2 . Hiá»‡n táº¡i thÃ¬ viá»‡c train, test Ä‘Ã£ xong rá»“i áº¡. Em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ pháº§n chuáº©n hÃ³a text Ä‘áº§u vÃ o, cÃ¡c danh má»¥c tá»« viáº¿t táº¯t, cÃ¡c Ä‘Æ¡n vá»‹ Ä‘o theo chuáº©n hÃ³a quá»‘c táº¿ ,.. Do thá»i gian cÃ²n láº¡i Ã­t nÃªn má»i ngÆ°á»i Ä‘Ã£ ai giáº£i quyáº¿t rá»“i cÃ³ tháº¿ nÃ³i Ã½ tÆ°á»Ÿng giÃºp em hoáº·c cÃ³ api Ä‘Ã¹ng cho viá»‡c chuáº©n hÃ³a nÃ y khÃ´ng áº¡. Em xin cáº£m Æ¡n áº¡!",,,,,
"cáº¥u trÃºc model YOLOR-w6 gá»‘c, chá»¥p táº¡i pháº§n Ä‘áº§u","cáº¥u trÃºc model YOLOR-w6 gá»‘c, chá»¥p táº¡i pháº§n Ä‘áº§u",,,,,
"e chÃ o mn áº¡, e cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» deep sort. Em cÃ³ chÃºt tháº¯c máº¯c mong Ä‘c mn giáº£i Ä‘Ã¡p. Deep Sort theo nhÆ° e hiá»ƒu sáº½ cÃ³ 2 stage chÃ­nh lÃ  detection vÃ  association, cáº£ 2 stage nÃ y Ä‘á»u dÃ¹ng deep learning (stage Ä‘áº§u sá»­ dá»¥ng cho viá»‡c detect, stage 2 sá»­ dá»¥ng cho viá»‡c trÃ­ch chá»n Ä‘áº·c trÆ°ng Ä‘á»‘i tÆ°á»£ng). Váº­y thÃ¬ 2 stage nÃ y cáº§n 2 model deep learning khÃ¡c nhau Ä‘Ãºng k áº¡? do váº­y mÃ  khi cháº¡y code, mk cÅ©ng sáº½ train cáº£ 2 model tÆ°Æ¡ng á»©ng vá»›i bÃ i toÃ¡n cá»¥ thá»ƒ? (vÃ­ dá»¥ baÃ¬ toÃ¡n tracking Ã´ tÃ´ sá»­ dá»¥ng yolov5 e cáº§n training yolov5 cho detect Ã´ tÃ´ vÃ  má»™t model ná»¯a cho viá»‡c trÃ­ch trá»n Ä‘áº·c trÆ°ng Ã´ tÃ´)? Náº¿u e hiá»ƒu sai mn sá»­a giÃºp e vá»›i. E cáº£m Æ¡n nhiá»u áº¡!","e chÃ o mn áº¡, e cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» deep sort. Em cÃ³ chÃºt tháº¯c máº¯c mong Ä‘c mn giáº£i Ä‘Ã¡p. Deep Sort theo nhÆ° e hiá»ƒu sáº½ cÃ³ 2 stage chÃ­nh lÃ  detection vÃ  association, cáº£ 2 stage nÃ y Ä‘á»u dÃ¹ng deep learning (stage Ä‘áº§u sá»­ dá»¥ng cho viá»‡c detect, stage 2 sá»­ dá»¥ng cho viá»‡c trÃ­ch chá»n Ä‘áº·c trÆ°ng Ä‘á»‘i tÆ°á»£ng). Váº­y thÃ¬ 2 stage nÃ y cáº§n 2 model deep learning khÃ¡c nhau Ä‘Ãºng k áº¡? do váº­y mÃ  khi cháº¡y code, mk cÅ©ng sáº½ train cáº£ 2 model tÆ°Æ¡ng á»©ng vá»›i bÃ i toÃ¡n cá»¥ thá»ƒ? (vÃ­ dá»¥ baÃ¬ toÃ¡n tracking Ã´ tÃ´ sá»­ dá»¥ng yolov5 e cáº§n training yolov5 cho detect Ã´ tÃ´ vÃ  má»™t model ná»¯a cho viá»‡c trÃ­ch trá»n Ä‘áº·c trÆ°ng Ã´ tÃ´)? Náº¿u e hiá»ƒu sai mn sá»­a giÃºp e vá»›i. E cáº£m Æ¡n nhiá»u áº¡!",,,,,
"CÃ³ ai Ä‘Äƒng kÃ­ Ä‘Æ°á»£c tÃ i khoáº£n trÃªn openai ko áº¡? HÃ´m nay em vÃ o Ä‘Äƒng kÃ­ thÃ¬ láº¡i khÃ´ng há»— trá»£ khu vá»±c VN
Sáºµn tiá»‡n em cáº§n mua láº¡i 1 tÃ i khoáº£n openai, ai cÃ³ dÆ° khÃ´ng dÃ¹ng thÃ¬ cÃ³ thá»ƒ share láº¡i em vá»›i áº¡. Em cáº£m Æ¡n","CÃ³ ai Ä‘Äƒng kÃ­ Ä‘Æ°á»£c tÃ i khoáº£n trÃªn openai ko áº¡? HÃ´m nay em vÃ o Ä‘Äƒng kÃ­ thÃ¬ láº¡i khÃ´ng há»— trá»£ khu vá»±c VN Sáºµn tiá»‡n em cáº§n mua láº¡i 1 tÃ i khoáº£n openai, ai cÃ³ dÆ° khÃ´ng dÃ¹ng thÃ¬ cÃ³ thá»ƒ share láº¡i em vá»›i áº¡. Em cáº£m Æ¡n",,,,,
"Má»i ngÆ°á»i cho em há»i chÃºt, em muá»‘n tÃ­nh shannon-entropy cho má»™t batch áº£nh, em tÃ¬m Ä‘c má»™t sá»‘ hÃ m tÃ­nh toÃ¡n entropy trong cÃ¡c thÆ° viá»‡n nhÆ° scipy, skimage,.. nhÆ°ng chá»‰ tÃ­nh Ä‘Æ°á»£c trÃªn tá»«ng áº£nh Ä‘Æ¡n láº», cÃ³ cÃ¡ch nÃ o cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c toÃ n bá»™ giÃ¡ trá»‹ entropy cá»§a cÃ¡c áº£nh trong má»™t batch Ä‘Æ°á»£c khÃ´ng áº¡. em cáº£m Æ¡n má»i ngÆ°á»i","Má»i ngÆ°á»i cho em há»i chÃºt, em muá»‘n tÃ­nh shannon-entropy cho má»™t batch áº£nh, em tÃ¬m Ä‘c má»™t sá»‘ hÃ m tÃ­nh toÃ¡n entropy trong cÃ¡c thÆ° viá»‡n nhÆ° scipy, skimage,.. nhÆ°ng chá»‰ tÃ­nh Ä‘Æ°á»£c trÃªn tá»«ng áº£nh Ä‘Æ¡n láº», cÃ³ cÃ¡ch nÃ o cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c toÃ n bá»™ giÃ¡ trá»‹ entropy cá»§a cÃ¡c áº£nh trong má»™t batch Ä‘Æ°á»£c khÃ´ng áº¡. em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"ChÃ o cÃ¡c báº¡n,
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» multi-point statistics network, vÃ  muá»‘n Ã¡p dá»¥ng nÃ³ trong CNN. Tuy nhiÃªn mÃ¬nh chÆ°a biáº¿t cÃ¡ch tÃ­ch há»£p hard data vÃ o trong máº¡ng Ä‘á»ƒ yÃªu cáº§u máº¡ng train model tá»« hard data. MÃ¬nh cÃ³ Ä‘á»c thuáº­t toÃ¡n cá»§a cGan nhÆ°ng hÃ¬nh nhÆ° chÆ°a pháº£i cÃ¡i mÃ¬nh cáº§n. Mong Ä‘Æ°á»£c cÃ¡c báº¡n chia sáº» kinh nghiá»‡m, cÃ¡m Æ¡n nhiá»u","ChÃ o cÃ¡c báº¡n, MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» multi-point statistics network, vÃ  muá»‘n Ã¡p dá»¥ng nÃ³ trong CNN. Tuy nhiÃªn mÃ¬nh chÆ°a biáº¿t cÃ¡ch tÃ­ch há»£p hard data vÃ o trong máº¡ng Ä‘á»ƒ yÃªu cáº§u máº¡ng train model tá»« hard data. MÃ¬nh cÃ³ Ä‘á»c thuáº­t toÃ¡n cá»§a cGan nhÆ°ng hÃ¬nh nhÆ° chÆ°a pháº£i cÃ¡i mÃ¬nh cáº§n. Mong Ä‘Æ°á»£c cÃ¡c báº¡n chia sáº» kinh nghiá»‡m, cÃ¡m Æ¡n nhiá»u",,,,,
"ChÃ o cáº£ nhÃ , mÃ¬nh tháº¥y Scikit-Learn cÃ³ khÃ¡ nhiá»u hÃ m trong pre-process, váº­y trong trÆ°á»ng há»£p nÃ o thÃ¬ mÃ¬nh dÃ¹ng cÃ¡i nÃ o?
minmaxscaler 
robustscaler 
standardscaler 
 normalizer","ChÃ o cáº£ nhÃ , mÃ¬nh tháº¥y Scikit-Learn cÃ³ khÃ¡ nhiá»u hÃ m trong pre-process, váº­y trong trÆ°á»ng há»£p nÃ o thÃ¬ mÃ¬nh dÃ¹ng cÃ¡i nÃ o? minmaxscaler robustscaler standardscaler normalizer",,,,,
"Sau 7749 láº§n tra cá»©u google, mÃ¬nh Ä‘Ã£ cho ra lÃ² 'a fused TFLite LSTM model'.
NhÆ° má»i ngÆ°á»i Ä‘Æ°á»£c biáº¿t thÃ¬ hiá»‡n nay tensorflow lite lÃ  model Ä‘Æ°á»£c google táº¡o ra, nháº§m hÆ°á»›ng Ä‘áº¿n sá»­ dá»¥ng AI trÃªn cÃ¡c thiáº¿t bá»‹ mobile, IoT, . . .
VÃ  tensorflow lite thÃ¬ khÃ´ng thá»ƒ train Ä‘Æ°á»£c model LSTM, hay convert trá»±c tiáº¿p tá»« model cÃ³ LSTM.
VÃ¬ tháº¿ 'a fused TFLite LSTM model' lÃ  giáº£i phÃ¡p hiá»‡n táº¡i mÃ  google táº¡o ra Ä‘á»ƒ cÃ³ thá»ƒ convert sang tflite model.
DÆ°á»›i Ä‘Ã¢y lÃ  project Human Activity Recognition sá»­ dá»¥ng an accelerometer, a gyroscope, a magnetometer, and a linear acceleration sensor. Vá»›i thiáº¿t bá»‹ Ä‘iá»‡n thoáº¡i Ä‘Æ°á»£c bá» trong tÃºi quáº§n Ä‘á»ƒ Ä‘Æ°á»£c káº¿t quáº£.
p/s: mÃ¬nh ngá»“i xá»•m Ä‘á»ƒ Ä‘Æ°á»£c káº¿t quáº£ nhÆ° hÃ¬nh.
https://github.com/phuoctan4141/A-FUSED-TFLITE-LSTM-MODEL","Sau 7749 láº§n tra cá»©u google, mÃ¬nh Ä‘Ã£ cho ra lÃ² 'a fused TFLite LSTM model'. NhÆ° má»i ngÆ°á»i Ä‘Æ°á»£c biáº¿t thÃ¬ hiá»‡n nay tensorflow lite lÃ  model Ä‘Æ°á»£c google táº¡o ra, nháº§m hÆ°á»›ng Ä‘áº¿n sá»­ dá»¥ng AI trÃªn cÃ¡c thiáº¿t bá»‹ mobile, IoT, . . . VÃ  tensorflow lite thÃ¬ khÃ´ng thá»ƒ train Ä‘Æ°á»£c model LSTM, hay convert trá»±c tiáº¿p tá»« model cÃ³ LSTM. VÃ¬ tháº¿ 'a fused TFLite LSTM model' lÃ  giáº£i phÃ¡p hiá»‡n táº¡i mÃ  google táº¡o ra Ä‘á»ƒ cÃ³ thá»ƒ convert sang tflite model. DÆ°á»›i Ä‘Ã¢y lÃ  project Human Activity Recognition sá»­ dá»¥ng an accelerometer, a gyroscope, a magnetometer, and a linear acceleration sensor. Vá»›i thiáº¿t bá»‹ Ä‘iá»‡n thoáº¡i Ä‘Æ°á»£c bá» trong tÃºi quáº§n Ä‘á»ƒ Ä‘Æ°á»£c káº¿t quáº£. p/s: mÃ¬nh ngá»“i xá»•m Ä‘á»ƒ Ä‘Æ°á»£c káº¿t quáº£ nhÆ° hÃ¬nh. https://github.com/phuoctan4141/A-FUSED-TFLITE-LSTM-MODEL",,,,,
"MÃ¬nh Ä‘ang gáº·p lá»—i resource exhausted trÃªn colab pro khi Ã¡p dá»¥ng code máº«u seq2seq cá»§a tf. MÃ¬nh Ä‘ang sá»­ dá»¥ng data lÃ  vÄƒn báº£n dÃ i, cÃ³ thá»ƒ Ä‘áº¿n 2000 chá»¯. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh 1 sá»‘ gá»£i Ã½ Ä‘á»ƒ giáº£i quyáº¿t khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i","MÃ¬nh Ä‘ang gáº·p lá»—i resource exhausted trÃªn colab pro khi Ã¡p dá»¥ng code máº«u seq2seq cá»§a tf. MÃ¬nh Ä‘ang sá»­ dá»¥ng data lÃ  vÄƒn báº£n dÃ i, cÃ³ thá»ƒ Ä‘áº¿n 2000 chá»¯. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh 1 sá»‘ gá»£i Ã½ Ä‘á»ƒ giáº£i quyáº¿t khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
Chia sáº» thuáº­t toÃ¡n má»›i vá» há»c tÄƒng cÆ°á»ng cho má»i ngÆ°á»i,Chia sáº» thuáº­t toÃ¡n má»›i vá» há»c tÄƒng cÆ°á»ng cho má»i ngÆ°á»i,,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n vá» phÃ¡t hiá»‡n 2 class smoke, fire trong image. Má»¥c tiÃªu lÃ  cáº§n detect Ä‘Æ°á»£c náº¿u image cÃ³ smoke hoáº·c fire, khÃ´ng quan trá»ng bounding box.
 Giáº£ sá»­ mÃ¬nh Ã¡p dá»¥ng YOLO (v1)  algorithm vÃ  muá»‘n tÃ¹y chá»‰nh láº¡i algorithm Ä‘á»ƒ tá»‘i Æ°u cho bÃ i toÃ¡n cá»§a mÃ¬nh nhÆ° sau, mÃ¬nh mong cÃ¡c báº¡n gÃ³p Ã½ Ä‘á»ƒ biáº¿t liá»‡u ráº±ng nÃ³ kháº£ thi khÃ´ng: (cÃ¡c kÃ­ hiá»‡u trong bÃ i viáº¿t Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a giá»‘ng trong paper)
TÃ¹y chá»‰nh thá»© nháº¥t: VÃ¬ bÃ i toÃ¡n khÃ´ng yÃªu cáº§u thÃ´ng tin vá» bounding box nÃªn output loáº¡i bá» bx, by, bh, hw á»Ÿ má»—i grid cell.
má»—i bounding box gá»‘c bao gá»“m thÃ´ng tin {confidence, x, y, h, w}, nay sáº½ thay Ä‘á»•i thÃ nh {confidence}.
cÃ¡ch tÃ­nh confidence sáº½ thay Ä‘á»•i tá»« confidence = Pr(Object) âˆ— IOUtruth|pred thÃ nh confidence = Pr(Object).
output sáº½ trá»Ÿ thÃ nh tensor S Ã— S Ã— (B âˆ— 1 + C).
Loss function sáº½ báº±ng L_cls.
Viá»‡c giáº£m bá»›t lÆ°á»£ng params sáº½ giÃºp inference nhanh hÆ¡n vÃ  giáº£m yÃªu cáº§u pháº§n cá»©ng.
TÃ¹y chá»‰nh thá»© hai: VÃ¬ kÃ­ch thÆ°á»›c cá»§a object smoke vÃ  fire nhá» nÃªn loáº¡i bá» feature maps vá»›i grid cell nhá», giá»¯ láº¡i feature maps cÃ³ grid cell lá»›n.
Äá»ƒ giáº£m chi phÃ­ tÃ­nh toÃ¡n.
link paper YOLOv1 https://arxiv.org/pdf/1506.02640.pdf","ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n vá» phÃ¡t hiá»‡n 2 class smoke, fire trong image. Má»¥c tiÃªu lÃ  cáº§n detect Ä‘Æ°á»£c náº¿u image cÃ³ smoke hoáº·c fire, khÃ´ng quan trá»ng bounding box. Giáº£ sá»­ mÃ¬nh Ã¡p dá»¥ng YOLO (v1) algorithm vÃ  muá»‘n tÃ¹y chá»‰nh láº¡i algorithm Ä‘á»ƒ tá»‘i Æ°u cho bÃ i toÃ¡n cá»§a mÃ¬nh nhÆ° sau, mÃ¬nh mong cÃ¡c báº¡n gÃ³p Ã½ Ä‘á»ƒ biáº¿t liá»‡u ráº±ng nÃ³ kháº£ thi khÃ´ng: (cÃ¡c kÃ­ hiá»‡u trong bÃ i viáº¿t Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a giá»‘ng trong paper) TÃ¹y chá»‰nh thá»© nháº¥t: VÃ¬ bÃ i toÃ¡n khÃ´ng yÃªu cáº§u thÃ´ng tin vá» bounding box nÃªn output loáº¡i bá» bx, by, bh, hw á»Ÿ má»—i grid cell. má»—i bounding box gá»‘c bao gá»“m thÃ´ng tin {confidence, x, y, h, w}, nay sáº½ thay Ä‘á»•i thÃ nh {confidence}. cÃ¡ch tÃ­nh confidence sáº½ thay Ä‘á»•i tá»« confidence = Pr(Object) âˆ— IOUtruth|pred thÃ nh confidence = Pr(Object). output sáº½ trá»Ÿ thÃ nh tensor S Ã— S Ã— (B âˆ— 1 + C). Loss function sáº½ báº±ng L_cls. Viá»‡c giáº£m bá»›t lÆ°á»£ng params sáº½ giÃºp inference nhanh hÆ¡n vÃ  giáº£m yÃªu cáº§u pháº§n cá»©ng. TÃ¹y chá»‰nh thá»© hai: VÃ¬ kÃ­ch thÆ°á»›c cá»§a object smoke vÃ  fire nhá» nÃªn loáº¡i bá» feature maps vá»›i grid cell nhá», giá»¯ láº¡i feature maps cÃ³ grid cell lá»›n. Äá»ƒ giáº£m chi phÃ­ tÃ­nh toÃ¡n. link paper YOLOv1 https://arxiv.org/pdf/1506.02640.pdf",,,,,
"ChÃ o má»i ngÆ°á»i,
mÃ¬nh lÃ  lÃ­nh má»›i muá»‘n nhá» cÃ¡c tiá»n bá»‘i giáº£i Ä‘Ã¡p giÃºp váº¥n Ä‘á» sau:
MÃ¬nh cáº§n lÃ m binary classification (0,1), mÃ¬nh dÃ¹ng SVM vÃ  vÃ i features cá»§a data Ä‘á»ƒ train model . MÃ¬nh thá»­ train model vá»›i 1 features vÃ  10 features thÃ¬ tháº¥y Accuracy vÃ  F1 score for test data lÃ  gáº§n nhÆ° nhau. Tuy nhiÃªn náº¿u mÃ¬nh láº¥y model cá»§a 1 feature Ä‘á»ƒ predict label cho má»™t unlabeled dataset khÃ¡c thÃ¬ mÃ¬nh tháº¥y Ä‘á»™ chÃ­nh xÃ¡c láº¡i ko cao khi so vá»›i dÃ¹ng nhiá»u features.
Khi mÃ¬nh plot data distribution cá»§a 1 feature(hÃ¬nh bÃªn dÆ°á»›i) thÃ¬ tháº¥y: data range cá»§a pháº§n training (hÃ¬nh trÃªn), khÃ¡c vá»›i data range cá»§a unlabeled dataset (hÃ¬nh dÆ°á»›i), liá»‡u cÃ³ pháº£i Ä‘Ã³ lÃ  nguyÃªn nhÃ¢n khiáº¿n cho model cá»§a mÃ¬nh perform kÃ©m Ä‘i khi apply cho new dataset ko?
Cáº£m Æ¡n cÃ¡c tiá»n bá»‘i!","ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  lÃ­nh má»›i muá»‘n nhá» cÃ¡c tiá»n bá»‘i giáº£i Ä‘Ã¡p giÃºp váº¥n Ä‘á» sau: MÃ¬nh cáº§n lÃ m binary classification (0,1), mÃ¬nh dÃ¹ng SVM vÃ  vÃ i features cá»§a data Ä‘á»ƒ train model . MÃ¬nh thá»­ train model vá»›i 1 features vÃ  10 features thÃ¬ tháº¥y Accuracy vÃ  F1 score for test data lÃ  gáº§n nhÆ° nhau. Tuy nhiÃªn náº¿u mÃ¬nh láº¥y model cá»§a 1 feature Ä‘á»ƒ predict label cho má»™t unlabeled dataset khÃ¡c thÃ¬ mÃ¬nh tháº¥y Ä‘á»™ chÃ­nh xÃ¡c láº¡i ko cao khi so vá»›i dÃ¹ng nhiá»u features. Khi mÃ¬nh plot data distribution cá»§a 1 feature(hÃ¬nh bÃªn dÆ°á»›i) thÃ¬ tháº¥y: data range cá»§a pháº§n training (hÃ¬nh trÃªn), khÃ¡c vá»›i data range cá»§a unlabeled dataset (hÃ¬nh dÆ°á»›i), liá»‡u cÃ³ pháº£i Ä‘Ã³ lÃ  nguyÃªn nhÃ¢n khiáº¿n cho model cá»§a mÃ¬nh perform kÃ©m Ä‘i khi apply cho new dataset ko? Cáº£m Æ¡n cÃ¡c tiá»n bá»‘i!",,,,,
"Giá»›i thiá»‡u m.n thuáº­t toÃ¡n RANSAC- á»¨ng dá»¥ng dÃ¹ng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n trong cÃ¡c bÃ i toÃ¡n Location Determination Problem - LDP. CÃ¡c bÃ i toÃ¡n LDP nhÆ° xÃ¡c Ä‘á»‹nh khoáº£ng cÃ¡ch giá»¯a cÃ¡c váº­t, xÃ¢y dá»±ng mÃ´ hÃ¬nh 3D tá»« áº£nh 2D hay chá»¥p áº£nh panorama,...
Thank all.","Giá»›i thiá»‡u m.n thuáº­t toÃ¡n RANSAC- á»¨ng dá»¥ng dÃ¹ng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n trong cÃ¡c bÃ i toÃ¡n Location Determination Problem - LDP. CÃ¡c bÃ i toÃ¡n LDP nhÆ° xÃ¡c Ä‘á»‹nh khoáº£ng cÃ¡ch giá»¯a cÃ¡c váº­t, xÃ¢y dá»±ng mÃ´ hÃ¬nh 3D tá»« áº£nh 2D hay chá»¥p áº£nh panorama,... Thank all.",,,,,
"#hoidap
ChÃ o má»i ngÆ°á»i,
Chuyá»‡n lÃ  mÃ¬nh Ä‘ang Ä‘á»c paper vá» Swin Transformer vÃ  cÃ³ chá»— hÆ¡i khÃ³ hiá»ƒu. ÄÃ³ lÃ  khi tÃ¡c giáº£ so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh trong tÃ¡c vá»¥ image classification trÃªn táº­p ImageNet, tÃ¡c giáº£ láº¡i dÃ¹ng cá»¥m ""single crop"". MÃ¬nh cÃ³ tÃ¬m hiá»ƒu vÃ  tháº¥y ngÆ°á»i ta chá»‰ nÃ³i Ä‘áº¿n ""top-1"", ""top-2"" ... chá»© khÃ´ng cÃ³ tÃ i liá»‡u nÃ o nÃ³i vá» ""single crop"". Hoáº·c cÃ³ thá»ƒ lÃ  do mÃ¬nh search khÃ´ng Ä‘Ãºng key words.
NÃªn mÃ¬nh muá»‘n há»i vá» thuáº­t ngá»¯ ""single crop"" trong ngá»¯ cáº£nh dÆ°á»›i Ä‘Ã¢y mang hÃ m Ã½ gÃ¬:
Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, Chuyá»‡n lÃ  mÃ¬nh Ä‘ang Ä‘á»c paper vá» Swin Transformer vÃ  cÃ³ chá»— hÆ¡i khÃ³ hiá»ƒu. ÄÃ³ lÃ  khi tÃ¡c giáº£ so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh trong tÃ¡c vá»¥ image classification trÃªn táº­p ImageNet, tÃ¡c giáº£ láº¡i dÃ¹ng cá»¥m ""single crop"". MÃ¬nh cÃ³ tÃ¬m hiá»ƒu vÃ  tháº¥y ngÆ°á»i ta chá»‰ nÃ³i Ä‘áº¿n ""top-1"", ""top-2"" ... chá»© khÃ´ng cÃ³ tÃ i liá»‡u nÃ o nÃ³i vá» ""single crop"". Hoáº·c cÃ³ thá»ƒ lÃ  do mÃ¬nh search khÃ´ng Ä‘Ãºng key words. NÃªn mÃ¬nh muá»‘n há»i vá» thuáº­t ngá»¯ ""single crop"" trong ngá»¯ cáº£nh dÆ°á»›i Ä‘Ã¢y mang hÃ m Ã½ gÃ¬: Cáº£m Æ¡n má»i ngÆ°á»i.",#hoidap,,,,
"ChÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c vá» pháº§n nÃ y nÃªn máº¡nh dáº¡n chia sáº» má»™t chÃºt vá» RNN, LSTM, Time Series Data vÃ  tÃ¬m hiá»ƒu cÃ¡ch chuáº©n bá»‹ dá»¯ liá»‡u cho RNN model nhanh hÆ¡n 10 láº§n vá»›i Numpy nhÃ©!
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c áº¡!","ChÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c vá» pháº§n nÃ y nÃªn máº¡nh dáº¡n chia sáº» má»™t chÃºt vá» RNN, LSTM, Time Series Data vÃ  tÃ¬m hiá»ƒu cÃ¡ch chuáº©n bá»‹ dá»¯ liá»‡u cho RNN model nhanh hÆ¡n 10 láº§n vá»›i Numpy nhÃ©! Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c áº¡!",,,,,
"[Airflow tutorial for Data Scientist]
Airflow lÃ  1 trong nhá»¯ng tools phá»• biáº¿n vá» orchestration data pipeline trong Python.
MÃ¬nh cÃ³ lÃ m ra 1 tutorial hÆ°á»›ng dáº«n step-by-step vá» Airflow
Link: https://github.com/DatacollectorVN/Airflow-Tutorial
Trong repo mÃ¬nh ghi document ká»¹ vá» Airflow cho báº¡n nÃ o khÃ´ng chá»‰ muá»‘n Äƒn mÃ¬ mÃ  muá»‘n hiá»ƒu rÃµ vá» Airflow.",[Airflow tutorial for Data Scientist] Airflow lÃ  1 trong nhá»¯ng tools phá»• biáº¿n vá» orchestration data pipeline trong Python. MÃ¬nh cÃ³ lÃ m ra 1 tutorial hÆ°á»›ng dáº«n step-by-step vá» Airflow Link: https://github.com/DatacollectorVN/Airflow-Tutorial Trong repo mÃ¬nh ghi document ká»¹ vá» Airflow cho báº¡n nÃ o khÃ´ng chá»‰ muá»‘n Äƒn mÃ¬ mÃ  muá»‘n hiá»ƒu rÃµ vá» Airflow.,,,,,
"ChÃ o má»i ngÆ°á»i, trÆ°á»›c Ä‘Ã³ mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n nháº­n diá»‡n khÃ³i lá»­a vÃ  tá»«ng muá»‘n Ã¡p dá»¥ng YOLOv1, nhÆ°ng sau Ä‘Ã³ tá»« sá»± gÃ³p Ã½ cá»§a má»i ngÆ°á»i mÃ¬nh chuyá»ƒn qua hÆ°á»›ng tiáº¿p cáº­n chá»§ Ä‘áº¡o lÃ  classification, cá»¥ thá»ƒ Ã¡p dá»¥ng classification káº¿t há»£p vá»›i output cá»§a segmentation Ä‘á»ƒ viá»‡c phÃ¢n loáº¡i trá»Ÿ nÃªn chÃ­nh xÃ¡c hÆ¡n cho object cÃ³ kÃ­ch thÆ°á»›c nhá» nhÆ° khÃ³i lá»­a. 
Chi tiáº¿t vá» cÃ¡ch tiáº¿p cáº­n nÃ y Ä‘Ã£ Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t trong paper https://arxiv.org/pdf/1812.00291.pdf. Thay vÃ¬ sá»­ dá»¥ng model classification Ä‘Æ¡n thuáº§n, paper nÃ y káº¿t há»£p thÃªm segmentation Ä‘á»ƒ 
cho model biáº¿t cáº§n táº­p trung vÃ o vá»‹ trÃ­ nÃ o cá»§a áº£nh Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  hiá»‡u quáº£ hÆ¡n so vá»›i phÆ°Æ¡ng phÃ¡p classification truyá»n thá»‘ng.
Giáº£ sá»­ chá»‰ Ã¡p dá»¥ng kiáº¿n trÃºc cá»§a paper nÃ y, mÃ¬nh cÃ³ má»™t tÃ¹y chá»‰nh nhá», liá»‡u nÃ³ cÃ³ kháº£ thi vÃ  hiá»‡u quáº£ khÃ´ng? Äá»“ng thá»i mÃ¬nh cÅ©ng mÃ´ táº£ suy nghÄ© cá»§a mÃ¬nh vá» bÃ i toÃ¡n nÃ y. Liá»‡u ráº±ng suy nghÄ© cá»§a mÃ¬nh cÃ³ Ä‘Ãºng khÃ´ng? Mong má»i ngÆ°á»i gÃ³p Ã½ vÃ  chia sáº» thÃªm nhá»¯ng sá»­a Ä‘á»•i tinh vi Ä‘á»ƒ giÃºp model Ä‘áº¡t hiá»‡u quáº£ hÆ¡n:
Input cá»§a bÃ i toÃ¡n lÃ  video, nhÆ° váº­y thay vÃ¬ build model  segmentation Ä‘á»ƒ cÃ³ binary mask cá»§a fire/smoke, há»‡ thá»‘ng cÃ³ thá»ƒ trÃ­ch xuáº¥t binary mask cá»§a smoke vÃ  fire báº±ng chuyá»ƒn Ä‘á»™ng mÃ  nÃ³ táº¡o ra (https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html). Sá»­ dá»¥ng binary mask tá»« movement cÃ³ thá»ƒ sáº½ cho ra Ä‘áº·c trÆ°ng khÃ´ng giá»‘ng so vá»›i binary mask cá»§a model segmentation, cá»¥ thá»ƒ lÃ  báº¥t kÃ¬ object cÃ³ chuyá»ƒn Ä‘á»™ng nÃ o trong video Ä‘á»u sáº½ táº¡o ra positive táº¡i vá»‹ trÃ­ cá»§a object Ä‘Ã³. ÄÃ¢y lÃ  má»™t Ä‘áº·c trÆ°ng há»¯u Ã­ch cho bÃ i toÃ¡n vÃ¬ model sáº½ cÃ³ nhiá»u context infomation (thÃ´ng tin vá» bá»‘i cáº£nh) hÆ¡n. 
Má»Ÿ rá»™ng ra, Ä‘Ã£ cÃ³ Ä‘á»§ cÆ¡ sá»Ÿ Ä‘á»ƒ xÃ¢y dá»±ng model cáº£nh bÃ¡o cÃ³ an toÃ n vá»›i khÃ³i lá»­a hay khÃ´ng (thay vÃ¬ á»Ÿ má»©c cÆ¡ báº£n lÃ  phÃ¡t hiá»‡n cÃ³ khÃ³i lá»­a hay khÃ´ng). VÃ­ dá»¥: NgÆ°á»i lá»›n Ä‘ang náº¥u Äƒn lÃ  negative; tráº» nhá» Ä‘ang náº¥u Äƒn lÃ  positive; ngÆ°á»i lá»›n Ä‘ang báº¥t tá»‰nh khi Ä‘ang náº¥u Äƒn lÃ  positive;... 
Pháº£i nÃ³i thÃªm lÃ  vá»›i model classification Ä‘Æ¡n thuáº§n cÅ©ng cÃ³ thá»ƒ build Ä‘Æ°á»£c model cáº£nh bÃ¡o cÃ³ an toÃ n vá»›i khÃ³i lá»­a hay khÃ´ng, tuy nhiÃªn mÃ¬nh nghÄ© hiá»‡u suáº¥t sáº½ khÃ´ng báº±ng vÃ¬ cÃ³ thÃªm binary mask giÃºp model biáº¿t nÃªn táº­p trung vÃ o pháº§n nÃ o trong áº£nh Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n Ä‘á»“ng thá»i loáº¡i bá» nhiá»…u tá»« background.
Vá» cÃ¡ch xÃ¢y dá»±ng model, theo nhÆ° sá»‘ liá»‡u vÃ  ná»™i dá»¥ng pháº§n 5. ""Results and discussion"", mÃ¬nh sáº½ khá»Ÿi táº¡o model theo kiáº¿n trÃºc Ä‘Æ°á»£c mÃ´ táº£ táº¡i Figure 3c.
NgoÃ i ra mÃ¬nh cÃ³ má»™t sá»‘ cÃ¢u há»i:
Vá»›i bÃ i toÃ¡n nÃ y nÃªn chá»n backbone nÃ o Ä‘á»ƒ extract feature ?
Äá»‘i vá»›i má»™t ngÆ°á»i lÃ m vá» AI, Ä‘á»ƒ implement phÆ°Æ¡ng phÃ¡p nÃ y  sáº½ máº¥t thá»i gian bao lÃ¢u?
Trong paper cÃ³ trÃ¬nh bÃ y hai cÃ¡ch Ä‘á»ƒ káº¿t há»£p  output cá»§a segment vÃ o nhÃ¡nh chÃ­nh (main branch) lÃ  element-wise addition vÃ  element-wise multiplication. Tuy nhiÃªn mÃ¬nh nghÄ© cÃ²n cÃ³ má»™t cÃ¡ch káº¿t há»£p khÃ¡c lÃ   ""concatenate channels"" - chiá»u dÃ i vÃ  chiá»u rá»™ng cá»§a layer khÃ´ng thay Ä‘á»•i, chiá»u sÃ¢u cá»§a layer tÄƒng lÃªn. Táº¡i sao paper khÃ´ng sá»­ dá»¥ng Ä‘áº¿n, nguyÃªn nhÃ¢n cá»¥ thá»ƒ lÃ  gÃ¬?","ChÃ o má»i ngÆ°á»i, trÆ°á»›c Ä‘Ã³ mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n nháº­n diá»‡n khÃ³i lá»­a vÃ  tá»«ng muá»‘n Ã¡p dá»¥ng YOLOv1, nhÆ°ng sau Ä‘Ã³ tá»« sá»± gÃ³p Ã½ cá»§a má»i ngÆ°á»i mÃ¬nh chuyá»ƒn qua hÆ°á»›ng tiáº¿p cáº­n chá»§ Ä‘áº¡o lÃ  classification, cá»¥ thá»ƒ Ã¡p dá»¥ng classification káº¿t há»£p vá»›i output cá»§a segmentation Ä‘á»ƒ viá»‡c phÃ¢n loáº¡i trá»Ÿ nÃªn chÃ­nh xÃ¡c hÆ¡n cho object cÃ³ kÃ­ch thÆ°á»›c nhá» nhÆ° khÃ³i lá»­a. Chi tiáº¿t vá» cÃ¡ch tiáº¿p cáº­n nÃ y Ä‘Ã£ Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t trong paper https://arxiv.org/pdf/1812.00291.pdf. Thay vÃ¬ sá»­ dá»¥ng model classification Ä‘Æ¡n thuáº§n, paper nÃ y káº¿t há»£p thÃªm segmentation Ä‘á»ƒ cho model biáº¿t cáº§n táº­p trung vÃ o vá»‹ trÃ­ nÃ o cá»§a áº£nh Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  hiá»‡u quáº£ hÆ¡n so vá»›i phÆ°Æ¡ng phÃ¡p classification truyá»n thá»‘ng. Giáº£ sá»­ chá»‰ Ã¡p dá»¥ng kiáº¿n trÃºc cá»§a paper nÃ y, mÃ¬nh cÃ³ má»™t tÃ¹y chá»‰nh nhá», liá»‡u nÃ³ cÃ³ kháº£ thi vÃ  hiá»‡u quáº£ khÃ´ng? Äá»“ng thá»i mÃ¬nh cÅ©ng mÃ´ táº£ suy nghÄ© cá»§a mÃ¬nh vá» bÃ i toÃ¡n nÃ y. Liá»‡u ráº±ng suy nghÄ© cá»§a mÃ¬nh cÃ³ Ä‘Ãºng khÃ´ng? Mong má»i ngÆ°á»i gÃ³p Ã½ vÃ  chia sáº» thÃªm nhá»¯ng sá»­a Ä‘á»•i tinh vi Ä‘á»ƒ giÃºp model Ä‘áº¡t hiá»‡u quáº£ hÆ¡n: Input cá»§a bÃ i toÃ¡n lÃ  video, nhÆ° váº­y thay vÃ¬ build model segmentation Ä‘á»ƒ cÃ³ binary mask cá»§a fire/smoke, há»‡ thá»‘ng cÃ³ thá»ƒ trÃ­ch xuáº¥t binary mask cá»§a smoke vÃ  fire báº±ng chuyá»ƒn Ä‘á»™ng mÃ  nÃ³ táº¡o ra (https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html). Sá»­ dá»¥ng binary mask tá»« movement cÃ³ thá»ƒ sáº½ cho ra Ä‘áº·c trÆ°ng khÃ´ng giá»‘ng so vá»›i binary mask cá»§a model segmentation, cá»¥ thá»ƒ lÃ  báº¥t kÃ¬ object cÃ³ chuyá»ƒn Ä‘á»™ng nÃ o trong video Ä‘á»u sáº½ táº¡o ra positive táº¡i vá»‹ trÃ­ cá»§a object Ä‘Ã³. ÄÃ¢y lÃ  má»™t Ä‘áº·c trÆ°ng há»¯u Ã­ch cho bÃ i toÃ¡n vÃ¬ model sáº½ cÃ³ nhiá»u context infomation (thÃ´ng tin vá» bá»‘i cáº£nh) hÆ¡n. Má»Ÿ rá»™ng ra, Ä‘Ã£ cÃ³ Ä‘á»§ cÆ¡ sá»Ÿ Ä‘á»ƒ xÃ¢y dá»±ng model cáº£nh bÃ¡o cÃ³ an toÃ n vá»›i khÃ³i lá»­a hay khÃ´ng (thay vÃ¬ á»Ÿ má»©c cÆ¡ báº£n lÃ  phÃ¡t hiá»‡n cÃ³ khÃ³i lá»­a hay khÃ´ng). VÃ­ dá»¥: NgÆ°á»i lá»›n Ä‘ang náº¥u Äƒn lÃ  negative; tráº» nhá» Ä‘ang náº¥u Äƒn lÃ  positive; ngÆ°á»i lá»›n Ä‘ang báº¥t tá»‰nh khi Ä‘ang náº¥u Äƒn lÃ  positive;... Pháº£i nÃ³i thÃªm lÃ  vá»›i model classification Ä‘Æ¡n thuáº§n cÅ©ng cÃ³ thá»ƒ build Ä‘Æ°á»£c model cáº£nh bÃ¡o cÃ³ an toÃ n vá»›i khÃ³i lá»­a hay khÃ´ng, tuy nhiÃªn mÃ¬nh nghÄ© hiá»‡u suáº¥t sáº½ khÃ´ng báº±ng vÃ¬ cÃ³ thÃªm binary mask giÃºp model biáº¿t nÃªn táº­p trung vÃ o pháº§n nÃ o trong áº£nh Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n Ä‘á»“ng thá»i loáº¡i bá» nhiá»…u tá»« background. Vá» cÃ¡ch xÃ¢y dá»±ng model, theo nhÆ° sá»‘ liá»‡u vÃ  ná»™i dá»¥ng pháº§n 5. ""Results and discussion"", mÃ¬nh sáº½ khá»Ÿi táº¡o model theo kiáº¿n trÃºc Ä‘Æ°á»£c mÃ´ táº£ táº¡i Figure 3c. NgoÃ i ra mÃ¬nh cÃ³ má»™t sá»‘ cÃ¢u há»i: Vá»›i bÃ i toÃ¡n nÃ y nÃªn chá»n backbone nÃ o Ä‘á»ƒ extract feature ? Äá»‘i vá»›i má»™t ngÆ°á»i lÃ m vá» AI, Ä‘á»ƒ implement phÆ°Æ¡ng phÃ¡p nÃ y sáº½ máº¥t thá»i gian bao lÃ¢u? Trong paper cÃ³ trÃ¬nh bÃ y hai cÃ¡ch Ä‘á»ƒ káº¿t há»£p output cá»§a segment vÃ o nhÃ¡nh chÃ­nh (main branch) lÃ  element-wise addition vÃ  element-wise multiplication. Tuy nhiÃªn mÃ¬nh nghÄ© cÃ²n cÃ³ má»™t cÃ¡ch káº¿t há»£p khÃ¡c lÃ  ""concatenate channels"" - chiá»u dÃ i vÃ  chiá»u rá»™ng cá»§a layer khÃ´ng thay Ä‘á»•i, chiá»u sÃ¢u cá»§a layer tÄƒng lÃªn. Táº¡i sao paper khÃ´ng sá»­ dá»¥ng Ä‘áº¿n, nguyÃªn nhÃ¢n cá»¥ thá»ƒ lÃ  gÃ¬?",,,,,
"Hi all,
Äang tÃ¬m hiá»ƒu vá» 3 ká»¹ thuáº­t dá»± Ä‘oÃ¡n lÃ  linear regression, sarimax vÃ  fbprophet, tháº¥y cÃ³ Ä‘iá»ƒm khÃ³ hiá»ƒu.
1. linear regression Ä‘áº§u vÃ o khÃ¡ nhiá»u cá»™t Ä‘á»ƒ ra dá»± Ä‘oÃ¡n (array Ä‘em traing cÃ³ nhiá»u pháº§n tá»­)
2. sarimax vÃ  fbprophet : chá»‰ cÃ³ 2 cá»™t Thá»i gian vÃ  giÃ¡ trá»‹
VD dá»± bÃ¡o GDP ná»n kinh táº¿, trong khi linear regression cÃ³ thá»ƒ dÃ¹ng nhiá»u pháº§n tá»­ Ä‘á»ƒ traing nhÆ° GDP/láº¡m phÃ¡t/ná»£ nÆ°á»›c ngoÃ i/ vá»‘n FDI/ . . . . thÃ¬ sarimax /fbprophet chá»‰ cÃ³ cá»™t thá»i gian vÃ  GDP Ä‘á»ƒ dá»± Ä‘oÃ¡n GDP cá»§a chÃ­nh nÃ³ ?!
Váº­y liá»‡u sarimax /fbprophet cÃ³ chÃ­nh xÃ¡c Ä‘Æ°á»£c hÆ¡n Linear regression
Ai cÃ³ kinh nghiá»‡m giáº£i thá»‹ch há»™","Hi all, Äang tÃ¬m hiá»ƒu vá» 3 ká»¹ thuáº­t dá»± Ä‘oÃ¡n lÃ  linear regression, sarimax vÃ  fbprophet, tháº¥y cÃ³ Ä‘iá»ƒm khÃ³ hiá»ƒu. 1. linear regression Ä‘áº§u vÃ o khÃ¡ nhiá»u cá»™t Ä‘á»ƒ ra dá»± Ä‘oÃ¡n (array Ä‘em traing cÃ³ nhiá»u pháº§n tá»­) 2. sarimax vÃ  fbprophet : chá»‰ cÃ³ 2 cá»™t Thá»i gian vÃ  giÃ¡ trá»‹ VD dá»± bÃ¡o GDP ná»n kinh táº¿, trong khi linear regression cÃ³ thá»ƒ dÃ¹ng nhiá»u pháº§n tá»­ Ä‘á»ƒ traing nhÆ° GDP/láº¡m phÃ¡t/ná»£ nÆ°á»›c ngoÃ i/ vá»‘n FDI/ . . . . thÃ¬ sarimax /fbprophet chá»‰ cÃ³ cá»™t thá»i gian vÃ  GDP Ä‘á»ƒ dá»± Ä‘oÃ¡n GDP cá»§a chÃ­nh nÃ³ ?! Váº­y liá»‡u sarimax /fbprophet cÃ³ chÃ­nh xÃ¡c Ä‘Æ°á»£c hÆ¡n Linear regression Ai cÃ³ kinh nghiá»‡m giáº£i thá»‹ch há»™",,,,,
"#share #table_recognition #viblo 
BÃ i chia sáº» cá»§a mÃ¬nh vá» hÆ°á»›ng tiáº¿p cáº­n vÃ  pipeline cho bÃ i toÃ¡n tÃ¡i cáº¥u trÃºc dá»¯ liá»‡u báº£ng biá»ƒu vá»›i Deep Learning - Table Recognition 
https://viblo.asia/p/Qbq5QBYLKD8

- Table Recognition lÃ  bÃ i toÃ¡n phÃ¡t hiá»‡n, nháº­n dáº¡ng, trÃ­ch rÃºt thÃ´ng tin vÃ  lÆ°u giá»¯ chÃ­nh xÃ¡c bá»‘ cá»¥c vÃ  hÃ¬nh thÃ¡i cá»§a báº£ng biá»ƒu, tá»« Ä‘Ã³ cÃ³ thá»ƒ lÆ°u trá»¯ cÃ¡c thÃ´ng tin dáº¡ng báº£ng biá»ƒu dÆ°á»›i cÃ¡c format cÃ³ thá»ƒ chá»‰nh sá»­a Ä‘Æ°á»£c nhÆ° Docx, Excel,... LÃ  bÃ i toÃ¡n cÃ³ tÃ­nh á»©ng dá»¥ng cao trong viá»‡c sá»‘ hÃ³a vÄƒn báº£n, chá»‰nh sá»­a, tÃ¬m kiáº¿m vÃ  truy váº¥n cÃ¡c tÃ i liá»‡u. Trong thá»i gian gáº§n Ä‘Ã¢y má»›i nháº­n Ä‘Æ°á»£c sá»± quan tÃ¢m nhiá»u hÆ¡n tá»« cá»™ng Ä‘á»“ng nghiÃªn cá»©u, nhiá»u SOTA model vÃ  solution Ä‘Æ°á»£c cÃ´ng bá»‘ hÆ¡n.
- Trong bÃ i blog nÃ y, mÃ¬nh cÃ³ review vá» 1 sá»‘ cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n táº¡i, giá»›i thiá»‡u vá» pipeline vÃ  hÆ°á»›ng tiáº¿p cáº­n cá»§a mÃ¬nh, káº¿t quáº£ thá»±c nghiá»‡m vÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡, kÃ¨m theo cÃ¡c nguá»“n tÃ i liá»‡u tham kháº£o Ä‘á»ƒ á»Ÿ cuá»‘i bÃ i viáº¿t. Hi vá»ng giÃºp Ã­ch vá»›i má»i ngÆ°á»i :D","BÃ i chia sáº» cá»§a mÃ¬nh vá» hÆ°á»›ng tiáº¿p cáº­n vÃ  pipeline cho bÃ i toÃ¡n tÃ¡i cáº¥u trÃºc dá»¯ liá»‡u báº£ng biá»ƒu vá»›i Deep Learning - Table Recognition https://viblo.asia/p/Qbq5QBYLKD8 - Table Recognition lÃ  bÃ i toÃ¡n phÃ¡t hiá»‡n, nháº­n dáº¡ng, trÃ­ch rÃºt thÃ´ng tin vÃ  lÆ°u giá»¯ chÃ­nh xÃ¡c bá»‘ cá»¥c vÃ  hÃ¬nh thÃ¡i cá»§a báº£ng biá»ƒu, tá»« Ä‘Ã³ cÃ³ thá»ƒ lÆ°u trá»¯ cÃ¡c thÃ´ng tin dáº¡ng báº£ng biá»ƒu dÆ°á»›i cÃ¡c format cÃ³ thá»ƒ chá»‰nh sá»­a Ä‘Æ°á»£c nhÆ° Docx, Excel,... LÃ  bÃ i toÃ¡n cÃ³ tÃ­nh á»©ng dá»¥ng cao trong viá»‡c sá»‘ hÃ³a vÄƒn báº£n, chá»‰nh sá»­a, tÃ¬m kiáº¿m vÃ  truy váº¥n cÃ¡c tÃ i liá»‡u. Trong thá»i gian gáº§n Ä‘Ã¢y má»›i nháº­n Ä‘Æ°á»£c sá»± quan tÃ¢m nhiá»u hÆ¡n tá»« cá»™ng Ä‘á»“ng nghiÃªn cá»©u, nhiá»u SOTA model vÃ  solution Ä‘Æ°á»£c cÃ´ng bá»‘ hÆ¡n. - Trong bÃ i blog nÃ y, mÃ¬nh cÃ³ review vá» 1 sá»‘ cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n táº¡i, giá»›i thiá»‡u vá» pipeline vÃ  hÆ°á»›ng tiáº¿p cáº­n cá»§a mÃ¬nh, káº¿t quáº£ thá»±c nghiá»‡m vÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡, kÃ¨m theo cÃ¡c nguá»“n tÃ i liá»‡u tham kháº£o Ä‘á»ƒ á»Ÿ cuá»‘i bÃ i viáº¿t. Hi vá»ng giÃºp Ã­ch vá»›i má»i ngÆ°á»i :D",#share	#table_recognition	#viblo,,,,
Má»i ngÆ°á»i cho há»i dÃ¹ng Q learning dÃ¹ng trong thá»‹ trÆ°á»ng chá»©ng khoÃ¡n cÃ³ code khÃ´ng má»i ngÆ°á»i táº¡i tÃ¬m trÃªn máº¡ng HoÃ i khÃ´ng tháº¥y,Má»i ngÆ°á»i cho há»i dÃ¹ng Q learning dÃ¹ng trong thá»‹ trÆ°á»ng chá»©ng khoÃ¡n cÃ³ code khÃ´ng má»i ngÆ°á»i táº¡i tÃ¬m trÃªn máº¡ng HoÃ i khÃ´ng tháº¥y,,,,,
"Em chÃ o mn áº¡,em muá»‘n mÃ´ phá»ng graph network báº±ng c++ thÃ¬ cÃ³ gÃ³i cÃ´ng cá»¥ há»— trá»£ nÃ o khÃ´ng áº¡,mong Ä‘Æ°á»£c mn giáº£i Ä‘Ã¡p,em cáº£m Æ¡n â¤ï¸","Em chÃ o mn áº¡,em muá»‘n mÃ´ phá»ng graph network báº±ng c++ thÃ¬ cÃ³ gÃ³i cÃ´ng cá»¥ há»— trá»£ nÃ o khÃ´ng áº¡,mong Ä‘Æ°á»£c mn giáº£i Ä‘Ã¡p,em cáº£m Æ¡n",,,,,
"Tháº¿ giá»›i xÃ¡c suáº¥t Ä‘áº¯m chÃ¬m trong viá»‡c mÃ´ hÃ¬nh hÃ³a tÃ­nh cháº¯c cháº¯n cá»§a cÃ¡c sá»± kiá»‡n thÃ´ng qua báº£n Ä‘á»“ niá»m tin Ä‘áº·c táº£ bá»Ÿi cÃ¡c con sá»‘, Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi cÃ¡c nhÃ  toÃ¡n há»c qua cÃ¡c phÃ¢n bá»‘ xÃ¡c suáº¥t.
Trong bÃ i viáº¿t nÃ y chÃºng ta sáº½ tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c vá» Normalizing Flows mÃ´ hÃ¬nh hÃ³a cÃ¡c phÃ¢n bá»‘ phá»©c táº¡p báº±ng cÃ´ng thá»©c Ä‘á»•i biáº¿n qua cÃ¡c phÃ©p biáº¿n Ä‘á»•i kháº£ nghá»‹ch.","Tháº¿ giá»›i xÃ¡c suáº¥t Ä‘áº¯m chÃ¬m trong viá»‡c mÃ´ hÃ¬nh hÃ³a tÃ­nh cháº¯c cháº¯n cá»§a cÃ¡c sá»± kiá»‡n thÃ´ng qua báº£n Ä‘á»“ niá»m tin Ä‘áº·c táº£ bá»Ÿi cÃ¡c con sá»‘, Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi cÃ¡c nhÃ  toÃ¡n há»c qua cÃ¡c phÃ¢n bá»‘ xÃ¡c suáº¥t. Trong bÃ i viáº¿t nÃ y chÃºng ta sáº½ tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c vá» Normalizing Flows mÃ´ hÃ¬nh hÃ³a cÃ¡c phÃ¢n bá»‘ phá»©c táº¡p báº±ng cÃ´ng thá»©c Ä‘á»•i biáº¿n qua cÃ¡c phÃ©p biáº¿n Ä‘á»•i kháº£ nghá»‹ch.",,,,,
"Dáº¡ em chÃ o anh chá»‹, em cÃ³ má»™t Ä‘á» tÃ i vá» xÃ¢y dá»±ng 'a complex network of stock market', chá»§ yáº¿u báº±ng matlab (cÃ³ liÃªn quan má»™t chÃºt Ä‘áº¿n Python vÃ  R cÅ©ng Ä‘Æ°á»£c áº¡, em cÃ³ thá»ƒ há»c thÃªm), dá»±a vÃ o Ä‘Ã³ Ä‘á»ƒ predict. Em gáº§n nhÆ° lÃ  má»›i tiáº¿p xÃºc vÃ  chÆ°a biáº¿t gÃ¬, nÃªn em cÃ³ vÃ i cÃ¢u há»i:
- em cáº§n nhá»¯ng kiáº¿n thá»©c ná»n gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ build Ä‘Æ°á»£c complex network nÃ y? (online courses, documents, thesis, etc)
- viá»‡c láº¥y dá»¯ liá»‡u máº«u á»Ÿ Ä‘Ã¢u áº¡? (e.g: yahoo finance,..)
Em cáº£m Æ¡n áº¡!","Dáº¡ em chÃ o anh chá»‹, em cÃ³ má»™t Ä‘á» tÃ i vá» xÃ¢y dá»±ng 'a complex network of stock market', chá»§ yáº¿u báº±ng matlab (cÃ³ liÃªn quan má»™t chÃºt Ä‘áº¿n Python vÃ  R cÅ©ng Ä‘Æ°á»£c áº¡, em cÃ³ thá»ƒ há»c thÃªm), dá»±a vÃ o Ä‘Ã³ Ä‘á»ƒ predict. Em gáº§n nhÆ° lÃ  má»›i tiáº¿p xÃºc vÃ  chÆ°a biáº¿t gÃ¬, nÃªn em cÃ³ vÃ i cÃ¢u há»i: - em cáº§n nhá»¯ng kiáº¿n thá»©c ná»n gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ build Ä‘Æ°á»£c complex network nÃ y? (online courses, documents, thesis, etc) - viá»‡c láº¥y dá»¯ liá»‡u máº«u á»Ÿ Ä‘Ã¢u áº¡? (e.g: yahoo finance,..) Em cáº£m Æ¡n áº¡!",,,,,
"[Build Deep Learning Workstation]
ChÃ o má»i ngÆ°á»i!
MÃ¬nh Ä‘ang cáº§n build pháº§n cá»©ng Ä‘á»ƒ phá»¥c vá»¥ nhu cáº§u training trong team mÃ¬nh ( budget $25k~$30k).
Má»i ngÆ°á»i trong group cÃ³ kinh nghiá»‡m vá» xÃ¢y dá»±ng pháº§n cá»©ng vá» Deep Learning cho mÃ¬nh xin Ã­t kinh nghiá»‡m vá»›i áº¡.
MÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n!
Edited!
Vá»›i budget táº§m $25k~$30k thÃ¬ mÃ¬nh cÃ¢n nháº¯c xÃ¢y dá»±ng pháº§n cá»©ng tá»« 4 x GPU ~ 8 x GPU, má»¥c tiÃªu lÃ  nhiá»u ngÆ°á»i trong team cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¹ng má»™t lÃºc (tá»« 5~10 ngÆ°á»i). MÃ¬nh Ä‘ang xem xÃ©t dÃ²ng Nvidia A100 40 Gb vs RTX A6000 48Gb..(giáº£ sá»­ data chuáº©n vÃ  Ä‘á»§ nhiá»u).","[Build Deep Learning Workstation] ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang cáº§n build pháº§n cá»©ng Ä‘á»ƒ phá»¥c vá»¥ nhu cáº§u training trong team mÃ¬nh ( budget $25k~$30k). Má»i ngÆ°á»i trong group cÃ³ kinh nghiá»‡m vá» xÃ¢y dá»±ng pháº§n cá»©ng vá» Deep Learning cho mÃ¬nh xin Ã­t kinh nghiá»‡m vá»›i áº¡. MÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n! Edited! Vá»›i budget táº§m $25k~$30k thÃ¬ mÃ¬nh cÃ¢n nháº¯c xÃ¢y dá»±ng pháº§n cá»©ng tá»« 4 x GPU ~ 8 x GPU, má»¥c tiÃªu lÃ  nhiá»u ngÆ°á»i trong team cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¹ng má»™t lÃºc (tá»« 5~10 ngÆ°á»i). MÃ¬nh Ä‘ang xem xÃ©t dÃ²ng Nvidia A100 40 Gb vs RTX A6000 48Gb..(giáº£ sá»­ data chuáº©n vÃ  Ä‘á»§ nhiá»u).",,,,,
"[AI application in game] AI agent plays Sonic the Hedgehog
BÃªn cáº¡nh cÃ¡c tá»±a game kinh Ä‘iá»ƒn nhÆ° Super Mario Bros, Contra hay Tetris, thÃ¬ Sonic lÃ  1 trong cÃ¡c tá»±a game mÃ¬nh vÃ´ cÃ¹ng yÃªu thÃ­ch khi cÃ²n bÃ©. Sau nÃ y khi lÃ m viá»‡c trong lÄ©nh vá»±c AI, mÃ  cá»¥ thá»ƒ hÆ¡n lÃ  Reinforcement Learning, mÃ¬nh Ä‘áº·c biá»‡t cÃ³ há»©ng thÃº vá»›i cÃ¡c á»©ng dá»¥ng cá»§a AI trong game. Trong project nÃ y, AI agent sáº½ tá»± khÃ¡m phÃ¡ vÃ  há»c cÃ¡ch chÆ¡i Sonic the Hedgehog. DÆ°á»›i Ä‘Ã¢y lÃ  2 level Ä‘áº§u tiÃªn. Let's enjoy it!
Source code: https://github.com/uvipen/Sonic-PPO-pytorch
Demo: https://youtu.be/hN3Gw-YunBc
#python #ReinforcementLearning","[AI application in game] AI agent plays Sonic the Hedgehog BÃªn cáº¡nh cÃ¡c tá»±a game kinh Ä‘iá»ƒn nhÆ° Super Mario Bros, Contra hay Tetris, thÃ¬ Sonic lÃ  1 trong cÃ¡c tá»±a game mÃ¬nh vÃ´ cÃ¹ng yÃªu thÃ­ch khi cÃ²n bÃ©. Sau nÃ y khi lÃ m viá»‡c trong lÄ©nh vá»±c AI, mÃ  cá»¥ thá»ƒ hÆ¡n lÃ  Reinforcement Learning, mÃ¬nh Ä‘áº·c biá»‡t cÃ³ há»©ng thÃº vá»›i cÃ¡c á»©ng dá»¥ng cá»§a AI trong game. Trong project nÃ y, AI agent sáº½ tá»± khÃ¡m phÃ¡ vÃ  há»c cÃ¡ch chÆ¡i Sonic the Hedgehog. DÆ°á»›i Ä‘Ã¢y lÃ  2 level Ä‘áº§u tiÃªn. Let's enjoy it! Source code: https://github.com/uvipen/Sonic-PPO-pytorch Demo: https://youtu.be/hN3Gw-YunBc",#python	#ReinforcementLearning,,,,
"chÃ o má»i ngÆ°á»i áº¡, mÃ¬nh muá»‘n há»i lÃ  náº¿u bÃ¢y giá» mÃ¬nh muá»‘n táº¡o má»™t random network Ä‘i N ngÃ¢n hÃ ng trÃªn Python. Má»—i ngÃ¢n hÃ ng cÃ³ thá»ƒ káº¿t ná»‘i vá»›i d ngÃ¢n hÃ ng khÃ¡c. Váº­y mÃ¬nh cÃ³ thá»ƒ táº¡o ra má»™t adjacency matrix nhÆ° tháº¿ nÃ o? Cáº£m Æ¡n má»i ngÆ°á»i áº¡.","chÃ o má»i ngÆ°á»i áº¡, mÃ¬nh muá»‘n há»i lÃ  náº¿u bÃ¢y giá» mÃ¬nh muá»‘n táº¡o má»™t random network Ä‘i N ngÃ¢n hÃ ng trÃªn Python. Má»—i ngÃ¢n hÃ ng cÃ³ thá»ƒ káº¿t ná»‘i vá»›i d ngÃ¢n hÃ ng khÃ¡c. Váº­y mÃ¬nh cÃ³ thá»ƒ táº¡o ra má»™t adjacency matrix nhÆ° tháº¿ nÃ o? Cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"#feature_extraction
#handcrafted_feature
[Táº¡i sao cáº§n binning cÃ¡c numeric feature?]
ChÃ o má»i ngÆ°á»i,
Paper sau Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ thá»±c cá»§a viá»‡c binning numeric feature.
GraphDTA[2019] (https://academic.oup.com/bioinformatics/article-abstract/37/8/1140/5942970?redirectedFrom=fulltext) sá»­ dá»¥ng GNN Ä‘á»ƒ encode embedding cho dá»¯ liá»‡u thuá»‘c. Dá»¯ liá»‡u thuá»‘c ban Ä‘áº§u lÃ  Ä‘á»“ thá»‹ phÃ¢n tá»­ vá»›i nÃºt lÃ  cÃ¡c nguyÃªn tá»­; Ä‘áº·c trÆ°ng ban Ä‘áº§u cho má»—i nÃºt nguyÃªn tá»­ Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh má»™t vector 78-chiá»u. Trong Ä‘Ã³, 44 bin Ä‘áº§u tiÃªn lÃ m one hot encoding cho loáº¡i nguyÃªn tá»‘, 11 bin tiáº¿p theo lÃ m one hot encoding cho báº­c cá»§a nguyÃªn tá»­ vá»›i cÃ¡c bin lÃ  0-10, 11 bin tiáº¿p theo lÃ m one hot encoding cho sá»‘ nguyÃªn tá»­ Hydrogen liÃªn káº¿t vá»›i nÃºt vá»›i cÃ¡c bin lÃ  0-10, 11 tiáº¿p theo lÃ m one hot encoding cho sá»‘ implicit Hyrdrogen liÃªn káº¿t vá»›i nÃºt vá»›i cÃ¡c bin lÃ  0-10, 1 bin cuá»‘i cÃ¹ng lÃ m binary encoding cho 'thÆ¡m hay khÃ´ng?'. Chi tiáº¿t cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ github cá»§a GraphDTA hoáº·c báº£ng 2 cá»§a paper nÃ y:https://pubs.rsc.org/en/content/articlelanding/2020/ra/d0ra02297g
Viá»‡c one hot encoding nhÃ£n loáº¡i nguyÃªn tá»‘ thÃ¬ mÃ¬nh hiá»ƒu Ä‘Æ°á»£c, nhÆ°ng táº¡i sao cáº§n binning cÃ¡c numeric feature (báº­c nguyÃªn tá»­, sá»‘ H, sá»‘ imolicit H)? Táº¡i sao láº¡i muá»‘n feature vector cá»§a nÃºt lÃ  thÆ°a? Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡, cáº£m Æ¡n má»i ngÆ°á»i.
CÃ¡c vÃ­ dá»¥ khÃ¡c cÅ©ng thá»±c hiá»‡n binning numeric features: https://github.com/wengong-jin/iclr19-graph2graph/blob/master/fast_jtnn/mpn.py
https://colab.research.google.com/github/sunhwan/blog/blob/master/_notebooks/2021-02-20-Learning-Molecular-Representation-Using-Graph-Neural-Network-Molecular-Graph.ipynb","[Táº¡i sao cáº§n binning cÃ¡c numeric feature?] ChÃ o má»i ngÆ°á»i, Paper sau Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ thá»±c cá»§a viá»‡c binning numeric feature. GraphDTA[2019] (https://academic.oup.com/bioinformatics/article-abstract/37/8/1140/5942970?redirectedFrom=fulltext) sá»­ dá»¥ng GNN Ä‘á»ƒ encode embedding cho dá»¯ liá»‡u thuá»‘c. Dá»¯ liá»‡u thuá»‘c ban Ä‘áº§u lÃ  Ä‘á»“ thá»‹ phÃ¢n tá»­ vá»›i nÃºt lÃ  cÃ¡c nguyÃªn tá»­; Ä‘áº·c trÆ°ng ban Ä‘áº§u cho má»—i nÃºt nguyÃªn tá»­ Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh má»™t vector 78-chiá»u. Trong Ä‘Ã³, 44 bin Ä‘áº§u tiÃªn lÃ m one hot encoding cho loáº¡i nguyÃªn tá»‘, 11 bin tiáº¿p theo lÃ m one hot encoding cho báº­c cá»§a nguyÃªn tá»­ vá»›i cÃ¡c bin lÃ  0-10, 11 bin tiáº¿p theo lÃ m one hot encoding cho sá»‘ nguyÃªn tá»­ Hydrogen liÃªn káº¿t vá»›i nÃºt vá»›i cÃ¡c bin lÃ  0-10, 11 tiáº¿p theo lÃ m one hot encoding cho sá»‘ implicit Hyrdrogen liÃªn káº¿t vá»›i nÃºt vá»›i cÃ¡c bin lÃ  0-10, 1 bin cuá»‘i cÃ¹ng lÃ m binary encoding cho 'thÆ¡m hay khÃ´ng?'. Chi tiáº¿t cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ github cá»§a GraphDTA hoáº·c báº£ng 2 cá»§a paper nÃ y:https://pubs.rsc.org/en/content/articlelanding/2020/ra/d0ra02297g Viá»‡c one hot encoding nhÃ£n loáº¡i nguyÃªn tá»‘ thÃ¬ mÃ¬nh hiá»ƒu Ä‘Æ°á»£c, nhÆ°ng táº¡i sao cáº§n binning cÃ¡c numeric feature (báº­c nguyÃªn tá»­, sá»‘ H, sá»‘ imolicit H)? Táº¡i sao láº¡i muá»‘n feature vector cá»§a nÃºt lÃ  thÆ°a? Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡, cáº£m Æ¡n má»i ngÆ°á»i. CÃ¡c vÃ­ dá»¥ khÃ¡c cÅ©ng thá»±c hiá»‡n binning numeric features: https://github.com/wengong-jin/iclr19-graph2graph/blob/master/fast_jtnn/mpn.py https://colab.research.google.com/github/sunhwan/blog/blob/master/_notebooks/2021-02-20-Learning-Molecular-Representation-Using-Graph-Neural-Network-Molecular-Graph.ipynb",#feature_extraction	#handcrafted_feature,,,,
"ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i,
Em Ä‘ang coÌ mÃ´Ì£t baÌ€i toaÌn label misinformation cuÌ‰a social media dÆ°Ì£a trÃªn tiÃªÌng ViÃªÌ£t aÌ£. Em cuÌƒng Ä‘aÌƒ nghiÃªn cÆ°Ìu vaÌ€ tiÌ€m kiÃªÌm nhÆ°ng hiÃªÌ£n vÃ¢Ìƒn chÆ°a tiÌ€m bÃ´Ì£ dataset tiÃªÌng ViÃªÌ£t Ä‘ÃªÌ‰ giaÌ‰i quyÃªÌt baÌ€i toaÌn naÌ€y aÌ£. MoÌ£i ngÆ°Æ¡Ì€i cho em hoÌ‰i laÌ€ em coÌ thÃªÌ‰ tiÌ€m bÃ´Ì£ dataset cuÌ‰a tiÃªÌng ViÃªÌ£t Æ¡Ì‰ Ä‘Ã¢u aÌ£ vaÌ€ moÌ£i ngÆ°Æ¡Ì€i coÌ thÃªÌ‰ suggest cho em khÃ´ng aÌ£. Em caÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i aÌ£!","ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i, Em Ä‘ang coÌ mÃ´Ì£t baÌ€i toaÌn label misinformation cuÌ‰a social media dÆ°Ì£a trÃªn tiÃªÌng ViÃªÌ£t aÌ£. Em cuÌƒng Ä‘aÌƒ nghiÃªn cÆ°Ìu vaÌ€ tiÌ€m kiÃªÌm nhÆ°ng hiÃªÌ£n vÃ¢Ìƒn chÆ°a tiÌ€m bÃ´Ì£ dataset tiÃªÌng ViÃªÌ£t Ä‘ÃªÌ‰ giaÌ‰i quyÃªÌt baÌ€i toaÌn naÌ€y aÌ£. MoÌ£i ngÆ°Æ¡Ì€i cho em hoÌ‰i laÌ€ em coÌ thÃªÌ‰ tiÌ€m bÃ´Ì£ dataset cuÌ‰a tiÃªÌng ViÃªÌ£t Æ¡Ì‰ Ä‘Ã¢u aÌ£ vaÌ€ moÌ£i ngÆ°Æ¡Ì€i coÌ thÃªÌ‰ suggest cho em khÃ´ng aÌ£. Em caÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i aÌ£!",,,,,
"Má»i ngÆ°á»i cho há»i lÃ  mÃ¬nh Ä‘ang cÃ³ Ä‘á» tÃ i vá» Q learning cho Financial Market Predictions ( dá»± Ä‘oÃ¡n thá»‹ trÆ°á»ng chá»©ng khoÃ¡n, tÃ i chÃ­nh) cho mÃ¬nh há»i Ã½ tÆ°á»Ÿng vá»›i code tham kháº£o vá»›i táº¡i tÃ¬m trÃªn máº¡ng tháº¥y toÃ n deep q learning","Má»i ngÆ°á»i cho há»i lÃ  mÃ¬nh Ä‘ang cÃ³ Ä‘á» tÃ i vá» Q learning cho Financial Market Predictions ( dá»± Ä‘oÃ¡n thá»‹ trÆ°á»ng chá»©ng khoÃ¡n, tÃ i chÃ­nh) cho mÃ¬nh há»i Ã½ tÆ°á»Ÿng vá»›i code tham kháº£o vá»›i táº¡i tÃ¬m trÃªn máº¡ng tháº¥y toÃ n deep q learning",,,,,
"MÃ¬nh xin giá»›i thiá»‡u 1 sá»‘ NLP project tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao cÃ³ source code vÃ  dataset Ä‘á»ƒ ae tham kháº£o.
thanks all.",MÃ¬nh xin giá»›i thiá»‡u 1 sá»‘ NLP project tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao cÃ³ source code vÃ  dataset Ä‘á»ƒ ae tham kháº£o. thanks all.,,,,,
"ChÃ o má»i ngÆ°á»i,
NhÃ³m nghiÃªn cá»©u bÃªn mÃ¬nh Ä‘ang cÃ³ 1 cuá»™c kháº£o sÃ¡t vá» ""Äá»™ khÃ³ cá»§a viá»‡c há»c trÃ­ tuá»‡ nhÃ¢n táº¡o trong giÃ¡o dá»¥c Ä‘áº¡i há»c á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i"".
Qua kháº£o sÃ¡t, giáº£ng viÃªn táº¡i cÃ¡c trÆ°á»ng Äáº¡i há»c cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khÃ³ khÄƒn cá»§a sinh viÃªn trong viá»‡c tiáº¿p cáº­n vá»›i AI, tá»« Ä‘Ã³ cho ra nhá»¯ng giÃ¡o trÃ¬nh phÃ¹ há»£p hÆ¡n vá»›i sinh viÃªn cá»§a mÃ¬nh.
Kháº£o sÃ¡t gá»“m 15 cÃ¢u há»i vÃ  sáº½ chá»‰ máº¥t khoáº£ng 3-5 phÃºt Ä‘á»ƒ hoÃ n thÃ nh. âœï¸âœï¸âœï¸
Mong má»i ngÆ°á»i bá» ra chÃºt thá»i gian Ä‘á»ƒ giÃºp nhÃ³m hoÃ n thÃ nh nghiÃªn cá»©u láº§n nÃ y.
NhÃ³m xin chÃ¢n thÃ nh cáº£m Æ¡n !!! ğŸ”¥ğŸ”¥ğŸ”¥","ChÃ o má»i ngÆ°á»i, NhÃ³m nghiÃªn cá»©u bÃªn mÃ¬nh Ä‘ang cÃ³ 1 cuá»™c kháº£o sÃ¡t vá» ""Äá»™ khÃ³ cá»§a viá»‡c há»c trÃ­ tuá»‡ nhÃ¢n táº¡o trong giÃ¡o dá»¥c Ä‘áº¡i há»c á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i"". Qua kháº£o sÃ¡t, giáº£ng viÃªn táº¡i cÃ¡c trÆ°á»ng Äáº¡i há»c cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khÃ³ khÄƒn cá»§a sinh viÃªn trong viá»‡c tiáº¿p cáº­n vá»›i AI, tá»« Ä‘Ã³ cho ra nhá»¯ng giÃ¡o trÃ¬nh phÃ¹ há»£p hÆ¡n vá»›i sinh viÃªn cá»§a mÃ¬nh. Kháº£o sÃ¡t gá»“m 15 cÃ¢u há»i vÃ  sáº½ chá»‰ máº¥t khoáº£ng 3-5 phÃºt Ä‘á»ƒ hoÃ n thÃ nh. Mong má»i ngÆ°á»i bá» ra chÃºt thá»i gian Ä‘á»ƒ giÃºp nhÃ³m hoÃ n thÃ nh nghiÃªn cá»©u láº§n nÃ y. NhÃ³m xin chÃ¢n thÃ nh cáº£m Æ¡n !!!",,,,,
"Group Viet Tech má»›i Ä‘Æ°á»£c thÃ nh láº­p giÃºp cÃ¡c báº¡n Viá»‡t trao Ä‘á»•i vá» cÆ¡ há»™i nghá» nghiá»‡p vÃ  cÃ¡c váº¥n Ä‘á» liÃªn quan trong ngÃ nh Tech. NhÃ³m Admin vÃ  active members gá»“m nhiá»u cÃ¡c báº¡n Ä‘Ã£ vÃ  Ä‘ang lÃ m viá»‡c trong nhiá»u cÃ´ng ty lá»›n.
https://www.facebook.com/groups/1177470863076165",Group Viet Tech má»›i Ä‘Æ°á»£c thÃ nh láº­p giÃºp cÃ¡c báº¡n Viá»‡t trao Ä‘á»•i vá» cÆ¡ há»™i nghá» nghiá»‡p vÃ  cÃ¡c váº¥n Ä‘á» liÃªn quan trong ngÃ nh Tech. NhÃ³m Admin vÃ  active members gá»“m nhiá»u cÃ¡c báº¡n Ä‘Ã£ vÃ  Ä‘ang lÃ m viá»‡c trong nhiá»u cÃ´ng ty lá»›n. https://www.facebook.com/groups/1177470863076165,,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ Ä‘ang lÃ m 1 Ä‘á» tÃ i OCR cho chá»¯ HÃ¡n-NÃ´m gá»“m 3 bÆ°á»›c chÃ­nh:
1. XÃ¢y dá»±ng dá»¯ liá»‡u gá»“m bounding box cho cÃ¡c sentence cÃ¹ng nhÃ£n text cá»§a chÃºng trong tá»«ng page cá»§a 1 tÃ¡c pháº©m (HÃ¬nh 1).
2. Model text detection Ä‘á»ƒ phÃ¡t hiá»‡n bounding box cá»§a cÃ¡c sentence trong 1 page, tá»« Ä‘Ã³ cÃ³ thá»ƒ láº¥y ra hÃ¬nh áº£nh riÃªng láº» cá»§a tá»«ng sentence lÃ m input cho text recognition.
3. Model text recognition Ä‘á»ƒ predict nhÃ£n text tÆ°Æ¡ng á»©ng cá»§a tá»«ng hÃ¬nh áº£nh cÃ¡c sentence á»Ÿ trÃªn.
Do text recognition á»Ÿ bÆ°á»›c 3 em sá»­ dá»¥ng hÆ°á»›ng tiáº¿p cáº­n lÃ  CRNN (CNN Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng + RNN Ä‘á»ƒ náº¯m báº¯t thÃ´ng tin ngá»¯ cáº£nh) nÃªn á»Ÿ bÆ°á»›c 1 em sáº½ gÃ¡n box theo cÃ¢u (sentence level), do váº­y sáº½ tiáº¿t kiá»‡m Ä‘Æ°á»£c ráº¥t nhiá»u thá»i gian so vá»›i gÃ¡n box cho tá»«ng character. NhÆ° á»Ÿ hÃ¬nh 1 lÃ  hÃ¬nh áº£nh minh há»a cho page Ä‘áº§u tiÃªn cá»§a Truyá»‡n Kiá»u.
NhÆ°ng em cÃ³ Ä‘ang gáº·p khÃ³ khÄƒn khi thá»±c hiá»‡n bÆ°á»›c 1 Ä‘á»‘i vá»›i tÃ¡c pháº©m Äáº¡i Viá»‡t Sá»­ KÃ½ ToÃ n ThÆ°. Do Ä‘Ã¢y cÃ³ váº» lÃ  vÄƒn xuÃ´i nÃªn 1 cÃ¢u cÃ³ thá»ƒ náº±m á»Ÿ nhiá»u cá»™t vÃ  phÃ¢n biá»‡t bá»Ÿi 1 dáº¥u cháº¥m (HÃ¬nh 2) nÃªn hiá»‡n táº¡i em váº«n chÆ°a nghÄ© Ä‘Æ°á»£c cÃ¡ch gÃ¡n bounding box vÃ  nhÃ£n text cá»§a chÃºng nhÆ° tháº¿ nÃ o cÃ¹ng cÃ¡ch chuyá»ƒn giao há»£p lÃ½ giá»¯a bÆ°á»›c 2 vÃ  3 cho cÃ¡c trÆ°á»ng há»£p nÃ y.
Mong má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ giÃºp em 1 sá»‘ idea hoáº·c keyword nÃ o Ä‘Ã³ Ä‘á»ƒ tham kháº£o. Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, em cÃ³ Ä‘ang lÃ m 1 Ä‘á» tÃ i OCR cho chá»¯ HÃ¡n-NÃ´m gá»“m 3 bÆ°á»›c chÃ­nh: 1. XÃ¢y dá»±ng dá»¯ liá»‡u gá»“m bounding box cho cÃ¡c sentence cÃ¹ng nhÃ£n text cá»§a chÃºng trong tá»«ng page cá»§a 1 tÃ¡c pháº©m (HÃ¬nh 1). 2. Model text detection Ä‘á»ƒ phÃ¡t hiá»‡n bounding box cá»§a cÃ¡c sentence trong 1 page, tá»« Ä‘Ã³ cÃ³ thá»ƒ láº¥y ra hÃ¬nh áº£nh riÃªng láº» cá»§a tá»«ng sentence lÃ m input cho text recognition. 3. Model text recognition Ä‘á»ƒ predict nhÃ£n text tÆ°Æ¡ng á»©ng cá»§a tá»«ng hÃ¬nh áº£nh cÃ¡c sentence á»Ÿ trÃªn. Do text recognition á»Ÿ bÆ°á»›c 3 em sá»­ dá»¥ng hÆ°á»›ng tiáº¿p cáº­n lÃ  CRNN (CNN Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng + RNN Ä‘á»ƒ náº¯m báº¯t thÃ´ng tin ngá»¯ cáº£nh) nÃªn á»Ÿ bÆ°á»›c 1 em sáº½ gÃ¡n box theo cÃ¢u (sentence level), do váº­y sáº½ tiáº¿t kiá»‡m Ä‘Æ°á»£c ráº¥t nhiá»u thá»i gian so vá»›i gÃ¡n box cho tá»«ng character. NhÆ° á»Ÿ hÃ¬nh 1 lÃ  hÃ¬nh áº£nh minh há»a cho page Ä‘áº§u tiÃªn cá»§a Truyá»‡n Kiá»u. NhÆ°ng em cÃ³ Ä‘ang gáº·p khÃ³ khÄƒn khi thá»±c hiá»‡n bÆ°á»›c 1 Ä‘á»‘i vá»›i tÃ¡c pháº©m Äáº¡i Viá»‡t Sá»­ KÃ½ ToÃ n ThÆ°. Do Ä‘Ã¢y cÃ³ váº» lÃ  vÄƒn xuÃ´i nÃªn 1 cÃ¢u cÃ³ thá»ƒ náº±m á»Ÿ nhiá»u cá»™t vÃ  phÃ¢n biá»‡t bá»Ÿi 1 dáº¥u cháº¥m (HÃ¬nh 2) nÃªn hiá»‡n táº¡i em váº«n chÆ°a nghÄ© Ä‘Æ°á»£c cÃ¡ch gÃ¡n bounding box vÃ  nhÃ£n text cá»§a chÃºng nhÆ° tháº¿ nÃ o cÃ¹ng cÃ¡ch chuyá»ƒn giao há»£p lÃ½ giá»¯a bÆ°á»›c 2 vÃ  3 cho cÃ¡c trÆ°á»ng há»£p nÃ y. Mong má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ giÃºp em 1 sá»‘ idea hoáº·c keyword nÃ o Ä‘Ã³ Ä‘á»ƒ tham kháº£o. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"[Attention(â€¢) nhÆ°ng nháº­n Ä‘áº§u vÃ o lÃ  trá»ng sá»‘ mÃ´ hÃ¬nh chá»© khÃ´ng pháº£i hidden state?]
ChÃ o má»i ngÆ°á»i trong group áº¡, khÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai gáº·p má»™t paper nÃ o sá»­ dá»¥ng attention nhÆ° trÃªn tiÃªu Ä‘á» khÃ´ng áº¡? ThÆ°á»ng cháº¯c má»i ngÆ°á»i Ä‘Ã£ quen vá»›i viá»‡c sá»­ dá»¥ng attention nhÆ° má»™t lá»›p Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng báº­c cao, vÃ  lá»›p nÃ y nháº­n Ä‘áº§u vÃ o lÃ  hidden state. NhÆ°ng bÃ i bÃ¡o sau Ä‘Ã¢y
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04352-9
láº¡i sá»­ dá»¥ng attention Ä‘á»ƒ Ã©p cho cÃ¡c trá»ng sá»‘ thoáº£ mÃ£n Ä‘iá»u kiá»‡n similarity nÃ o Ä‘Ã³. DÃ¹ chÆ°a Ä‘á»c ká»¹ code nhÆ°ng theo nhÆ° paper trÃ¬nh bÃ y thÃ¬ tháº­t ra lá»›p attention nÃ y chá»‰ lÃ  má»™t bÆ°á»›c Ã©p scale láº¡i cÃ¡c trá»ng sá»‘ chá»© trong hÃ m attention cháº³ng cÃ³ trá»ng sá»‘ nÃ o Ä‘á»ƒ há»c cáº£.
MÃ  giáº£ sá»­ cÃ³ thá»ƒ thá»±c hiá»‡n cho attention trá»ng sá»‘ Ä‘á»±á»£c thÃ¬ cÃ¡c trá»ng sá»‘ sáº½ thay Ä‘á»i nhÆ° tháº¿ nÃ o nhá»‰? Báº£n thÃ¢n optimizer Ä‘Ã£ cáº­p nháº­t nÃ³ rá»“i mÃ ? Ráº¥t mong Ä‘Æ°á»£c cÃ¹ng má»i ngÆ°á»i bÃ n luáº­n.","[Attention(â€¢) nhÆ°ng nháº­n Ä‘áº§u vÃ o lÃ  trá»ng sá»‘ mÃ´ hÃ¬nh chá»© khÃ´ng pháº£i hidden state?] ChÃ o má»i ngÆ°á»i trong group áº¡, khÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai gáº·p má»™t paper nÃ o sá»­ dá»¥ng attention nhÆ° trÃªn tiÃªu Ä‘á» khÃ´ng áº¡? ThÆ°á»ng cháº¯c má»i ngÆ°á»i Ä‘Ã£ quen vá»›i viá»‡c sá»­ dá»¥ng attention nhÆ° má»™t lá»›p Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng báº­c cao, vÃ  lá»›p nÃ y nháº­n Ä‘áº§u vÃ o lÃ  hidden state. NhÆ°ng bÃ i bÃ¡o sau Ä‘Ã¢y https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04352-9 láº¡i sá»­ dá»¥ng attention Ä‘á»ƒ Ã©p cho cÃ¡c trá»ng sá»‘ thoáº£ mÃ£n Ä‘iá»u kiá»‡n similarity nÃ o Ä‘Ã³. DÃ¹ chÆ°a Ä‘á»c ká»¹ code nhÆ°ng theo nhÆ° paper trÃ¬nh bÃ y thÃ¬ tháº­t ra lá»›p attention nÃ y chá»‰ lÃ  má»™t bÆ°á»›c Ã©p scale láº¡i cÃ¡c trá»ng sá»‘ chá»© trong hÃ m attention cháº³ng cÃ³ trá»ng sá»‘ nÃ o Ä‘á»ƒ há»c cáº£. MÃ  giáº£ sá»­ cÃ³ thá»ƒ thá»±c hiá»‡n cho attention trá»ng sá»‘ Ä‘á»±á»£c thÃ¬ cÃ¡c trá»ng sá»‘ sáº½ thay Ä‘á»i nhÆ° tháº¿ nÃ o nhá»‰? Báº£n thÃ¢n optimizer Ä‘Ã£ cáº­p nháº­t nÃ³ rá»“i mÃ ? Ráº¥t mong Ä‘Æ°á»£c cÃ¹ng má»i ngÆ°á»i bÃ n luáº­n.",,,,,
"Trong 3 nÄƒm, chuá»—i cÃ  phÃª Starbucks thu tháº­p dá»¯ liá»‡u hÃ¬nh áº£nh khÃ¡ch hÃ ng, nghiÃªn cá»©u hÃ nh vi tiÃªu dÃ¹ng trÃªn toÃ n tháº¿ giá»›i má»—i khi cÃ³ ngÆ°á»i bÆ°á»›c vÃ o cá»­a hÃ ng trong há»‡ thá»‘ng.
3 nÄƒm sau, chá»‰ báº±ng Ä‘á»™ng thÃ¡i thay Ä‘á»•i cÃ¡ch bÃ i trÃ­ cá»§a cÃ¡c quÃ¡n cÃ  phÃª, thÆ°Æ¡ng hiá»‡u nÃ y Ä‘Ã£ tÄƒng doanh thu má»—i cá»­a hÃ ng lÃªn 30%.
Camera AI phÃ¢n biá»‡t Ä‘Æ°á»£c quáº§y hÃ ng nÃ y thÃ¬ Ä‘á»‘i tÆ°á»£ng nÃ o mua hÃ ng, Ä‘á»™ tuá»•i lÃ  bao nhiÃªu vÃ  khÃ¡c vá»›i quáº§y hÃ ng khÃ¡c ra sao. Tá»« Ä‘Ã³, DN bá»‘ trÃ­ láº¡i gian hÃ ng, phÃ¢n loáº¡i khÃ¡ch hÃ ng tráº» tá»« 18-20 tuá»•i, tÃ¡ch vá»›i lá»©a tuá»•i táº§m trung cÃ³ má»©c thu nháº­p cao hÆ¡n cÅ©ng nhÆ° lá»c Ä‘Æ°á»£c khÃ¡ch VIP.
___________________
Äá»c thÃªm: https://www.facebook.com/AI4Beginner/posts/176515428039297","Trong 3 nÄƒm, chuá»—i cÃ  phÃª Starbucks thu tháº­p dá»¯ liá»‡u hÃ¬nh áº£nh khÃ¡ch hÃ ng, nghiÃªn cá»©u hÃ nh vi tiÃªu dÃ¹ng trÃªn toÃ n tháº¿ giá»›i má»—i khi cÃ³ ngÆ°á»i bÆ°á»›c vÃ o cá»­a hÃ ng trong há»‡ thá»‘ng. 3 nÄƒm sau, chá»‰ báº±ng Ä‘á»™ng thÃ¡i thay Ä‘á»•i cÃ¡ch bÃ i trÃ­ cá»§a cÃ¡c quÃ¡n cÃ  phÃª, thÆ°Æ¡ng hiá»‡u nÃ y Ä‘Ã£ tÄƒng doanh thu má»—i cá»­a hÃ ng lÃªn 30%. Camera AI phÃ¢n biá»‡t Ä‘Æ°á»£c quáº§y hÃ ng nÃ y thÃ¬ Ä‘á»‘i tÆ°á»£ng nÃ o mua hÃ ng, Ä‘á»™ tuá»•i lÃ  bao nhiÃªu vÃ  khÃ¡c vá»›i quáº§y hÃ ng khÃ¡c ra sao. Tá»« Ä‘Ã³, DN bá»‘ trÃ­ láº¡i gian hÃ ng, phÃ¢n loáº¡i khÃ¡ch hÃ ng tráº» tá»« 18-20 tuá»•i, tÃ¡ch vá»›i lá»©a tuá»•i táº§m trung cÃ³ má»©c thu nháº­p cao hÆ¡n cÅ©ng nhÆ° lá»c Ä‘Æ°á»£c khÃ¡ch VIP. ___________________ Äá»c thÃªm: https://www.facebook.com/AI4Beginner/posts/176515428039297",,,,,
"Lang thang trÃªn máº¡ng, mÃ¬nh tháº¥y cuá»‘n sÃ¡ch ""Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning"" cá»§a GS Jean Gallier vÃ  Jocelyn Quaintance. Mn tháº¥y há»¯u Ã­ch thÃ¬ táº£i vá» tham kháº£o nhÃ©.","Lang thang trÃªn máº¡ng, mÃ¬nh tháº¥y cuá»‘n sÃ¡ch ""Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning"" cá»§a GS Jean Gallier vÃ  Jocelyn Quaintance. Mn tháº¥y há»¯u Ã­ch thÃ¬ táº£i vá» tham kháº£o nhÃ©.",,,,,
"ChÃ o má»i ngÆ°á»i. Hiá»‡n mÃ¬nh Ä‘ang cÃ³ 1 project vá» human pose. CÃ³ nhá»¯ng trÆ°á»ng há»£p khi ngÆ°á»i khuá»µu gá»‘i xuá»‘ng gÃ³c 90 Ä‘á»™, nhÆ°ng do cam chiáº¿u hÆ°á»›ng trá»±c diá»‡n nÃªn gÃ³c khá»›p gá»‘i váº«n lÃ  180 Ä‘á»™. Hiá»‡n mÃ¬nh cÃ³ giáº£i phÃ¡p lÃ  Ä‘áº·t 2 cam khÃ¡c gÃ³c chiáº¿u. NhÆ°ng Ä‘á»ƒ match cÃ¹ng 1 ngÆ°á»i trÃªn 2 cam khÃ¡c nhau khÃ¡ khÃ³. CÃ³ 2 cÃ¡ch, 1 lÃ  reID deep learning, 2 lÃ  báº£n Ä‘á»“ hoÃ¡. Má»i ngÆ°á»i cho mÃ¬nh há»i:
CÃ³ giáº£i phÃ¡p nÃ o tá»‘t hÆ¡n cÃ¡ch sá»­ dá»¥ng 2 cam khÃ´ng?
CÃ³ cÃ¡ch nÃ o match 2 cam ngoÃ i 2 cÃ¡ch trÃªn khÃ´ng?
Model reID cho ngÆ°á»i hiá»‡u quáº£ nháº¥t hiá»‡n nay?","ChÃ o má»i ngÆ°á»i. Hiá»‡n mÃ¬nh Ä‘ang cÃ³ 1 project vá» human pose. CÃ³ nhá»¯ng trÆ°á»ng há»£p khi ngÆ°á»i khuá»µu gá»‘i xuá»‘ng gÃ³c 90 Ä‘á»™, nhÆ°ng do cam chiáº¿u hÆ°á»›ng trá»±c diá»‡n nÃªn gÃ³c khá»›p gá»‘i váº«n lÃ  180 Ä‘á»™. Hiá»‡n mÃ¬nh cÃ³ giáº£i phÃ¡p lÃ  Ä‘áº·t 2 cam khÃ¡c gÃ³c chiáº¿u. NhÆ°ng Ä‘á»ƒ match cÃ¹ng 1 ngÆ°á»i trÃªn 2 cam khÃ¡c nhau khÃ¡ khÃ³. CÃ³ 2 cÃ¡ch, 1 lÃ  reID deep learning, 2 lÃ  báº£n Ä‘á»“ hoÃ¡. Má»i ngÆ°á»i cho mÃ¬nh há»i: CÃ³ giáº£i phÃ¡p nÃ o tá»‘t hÆ¡n cÃ¡ch sá»­ dá»¥ng 2 cam khÃ´ng? CÃ³ cÃ¡ch nÃ o match 2 cam ngoÃ i 2 cÃ¡ch trÃªn khÃ´ng? Model reID cho ngÆ°á»i hiá»‡u quáº£ nháº¥t hiá»‡n nay?",,,,,
"ChÃ o má»i ngÆ°á»i. Hiá»‡n mÃ¬nh Ä‘ang cÃ³ 1 bÃ i toÃ¡n vá» tÃ¡ch biÃªn áº£nh. NhÆ°ng thay vÃ¬ sá»­ dá»¥ng phÃ©p tÃ­ch cháº­p MAC thÃ¬ bá»n mÃ¬nh Ä‘Æ°á»£c yÃªu cáº§u sá»­ dá»¥ng Xnor-popcount Ä‘á»ƒ thay tháº¿.
MÃ¬nh chÆ°a cÃ³ nhiá»u kiáº¿n thá»©c vá» pháº§n xnor -popcount nÃªn mÃ¬nh khÃ´ng biáº¿t phÃ©p xnor-popcount sáº½ cÃ³ thá»ƒ thay tháº¿ MAC Ä‘á»ƒ tÃ¡ch biÃªn khÃ´ng vÃ  mÃ¬nh pháº£i dÃ¹ng kernel nÃ o Ä‘á»ƒ xnor popcount ra Ä‘Æ°á»£c biÃªn áº£nh (nhÆ° xá»­ lÃ½ áº£nh thÃ´ng thÆ°á»ng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c kernel nhÆ° Sobel, canny, ...). KhÃ´ng biáº¿t cÃ³ ai biáº¿t vá» thuáº­t toÃ¡n xnor popcount cÅ©ng nhÆ° á»©ng dá»¥ng nÃ³ vÃ o tÃ¡ch biÃªn áº£nh cÃ³ thá»ƒ giÃºp Ä‘á»¡ cho bá»n mÃ¬nh khÃ´ng áº¡.
MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i. Hiá»‡n mÃ¬nh Ä‘ang cÃ³ 1 bÃ i toÃ¡n vá» tÃ¡ch biÃªn áº£nh. NhÆ°ng thay vÃ¬ sá»­ dá»¥ng phÃ©p tÃ­ch cháº­p MAC thÃ¬ bá»n mÃ¬nh Ä‘Æ°á»£c yÃªu cáº§u sá»­ dá»¥ng Xnor-popcount Ä‘á»ƒ thay tháº¿. MÃ¬nh chÆ°a cÃ³ nhiá»u kiáº¿n thá»©c vá» pháº§n xnor -popcount nÃªn mÃ¬nh khÃ´ng biáº¿t phÃ©p xnor-popcount sáº½ cÃ³ thá»ƒ thay tháº¿ MAC Ä‘á»ƒ tÃ¡ch biÃªn khÃ´ng vÃ  mÃ¬nh pháº£i dÃ¹ng kernel nÃ o Ä‘á»ƒ xnor popcount ra Ä‘Æ°á»£c biÃªn áº£nh (nhÆ° xá»­ lÃ½ áº£nh thÃ´ng thÆ°á»ng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c kernel nhÆ° Sobel, canny, ...). KhÃ´ng biáº¿t cÃ³ ai biáº¿t vá» thuáº­t toÃ¡n xnor popcount cÅ©ng nhÆ° á»©ng dá»¥ng nÃ³ vÃ o tÃ¡ch biÃªn áº£nh cÃ³ thá»ƒ giÃºp Ä‘á»¡ cho bá»n mÃ¬nh khÃ´ng áº¡. MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"NhÃ³m nghiÃªn cá»©u sá»­ dá»¥ng cÃ´ng nghá»‡ TrÃ­ tuá»‡ NhÃ¢n táº¡o (AI) Ä‘á»ƒ dá»± Ä‘oÃ¡n ngÆ°á»i dÃ¹ng muá»‘n di chuyá»ƒn hay khÃ´ng.
Trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m, nhá»¯ng ngÆ°á»i tham gia thá»±c hiá»‡n cÃ¡c chuyá»ƒn Ä‘á»™ng khÃ¡c nhau cÃ³ thá»ƒ báº¯t Ä‘áº§u theo cÃ¹ng má»™t cÃ¡ch - Ä‘á»©ng lÃªn, báº¯t chÃ©o chÃ¢n, nghiÃªng ngÆ°á»i vá» phÃ­a trÆ°á»›c vÃ  thay Ä‘á»•i tÆ° tháº¿ ngá»“i trÃªn gháº¿.
Bá»™ khung xÆ°Æ¡ng ngoÃ i sá»­ dá»¥ng cÃ´ng nghá»‡ mÃ¡y há»c Ä‘á»ƒ dá»± Ä‘oÃ¡n khi nÃ o con ngÆ°á»i thá»±c sá»± cá»‘ gáº¯ng Ä‘á»©ng lÃªn vÃ  thá»±c hiá»‡n há»— trá»£ chuyá»ƒn Ä‘á»™ng.
______________
Äá»c thÃªm: https://www.facebook.com/AI4Beginner/posts/178495327841307","NhÃ³m nghiÃªn cá»©u sá»­ dá»¥ng cÃ´ng nghá»‡ TrÃ­ tuá»‡ NhÃ¢n táº¡o (AI) Ä‘á»ƒ dá»± Ä‘oÃ¡n ngÆ°á»i dÃ¹ng muá»‘n di chuyá»ƒn hay khÃ´ng. Trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m, nhá»¯ng ngÆ°á»i tham gia thá»±c hiá»‡n cÃ¡c chuyá»ƒn Ä‘á»™ng khÃ¡c nhau cÃ³ thá»ƒ báº¯t Ä‘áº§u theo cÃ¹ng má»™t cÃ¡ch - Ä‘á»©ng lÃªn, báº¯t chÃ©o chÃ¢n, nghiÃªng ngÆ°á»i vá» phÃ­a trÆ°á»›c vÃ  thay Ä‘á»•i tÆ° tháº¿ ngá»“i trÃªn gháº¿. Bá»™ khung xÆ°Æ¡ng ngoÃ i sá»­ dá»¥ng cÃ´ng nghá»‡ mÃ¡y há»c Ä‘á»ƒ dá»± Ä‘oÃ¡n khi nÃ o con ngÆ°á»i thá»±c sá»± cá»‘ gáº¯ng Ä‘á»©ng lÃªn vÃ  thá»±c hiá»‡n há»— trá»£ chuyá»ƒn Ä‘á»™ng. ______________ Äá»c thÃªm: https://www.facebook.com/AI4Beginner/posts/178495327841307",,,,,
"Thá»i gian vá»«a qua mÃ¬nh cÃ³ cÆ¡ há»™i tÃ¬m hiá»ƒu vá» Variational Autoencoder nÃªn mÃ¬nh muá»‘n viáº¿t 1 bÃ i vá»«a Ä‘á»ƒ tá»•ng há»£p kiáº¿n thá»©c, chia sáº» nhá»¯ng gÃ¬ mÃ¬nh tÃ¬m hiá»ƒu Ä‘Æ°á»£c vÃ  hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ sá»­a giÃºp nhá»¯ng chá»— mÃ¬nh viáº¿t chÆ°a rÃµ hoáº·c hiá»ƒu chÆ°a Ä‘Ãºng :D
https://forum.machinelearningcoban.com/t/variational-autoencoder-vae-co-ban/6494
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i ^^","Thá»i gian vá»«a qua mÃ¬nh cÃ³ cÆ¡ há»™i tÃ¬m hiá»ƒu vá» Variational Autoencoder nÃªn mÃ¬nh muá»‘n viáº¿t 1 bÃ i vá»«a Ä‘á»ƒ tá»•ng há»£p kiáº¿n thá»©c, chia sáº» nhá»¯ng gÃ¬ mÃ¬nh tÃ¬m hiá»ƒu Ä‘Æ°á»£c vÃ  hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ sá»­a giÃºp nhá»¯ng chá»— mÃ¬nh viáº¿t chÆ°a rÃµ hoáº·c hiá»ƒu chÆ°a Ä‘Ãºng :D https://forum.machinelearningcoban.com/t/variational-autoencoder-vae-co-ban/6494 Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i ^^",,,,,
"Xin chÃ o anh chá»‹ !
Em má»›i tÃ¬m hiá»ƒu vá» Machine Learning, theo lá»i khuyÃªn cá»§a cÃ¡c tiá»n bá»‘i em báº¯t Ä‘áº§u vá»›i quyá»ƒn Introduction to Machine Learning. Tuy nhiÃªn khi Ä‘á»c tá»›i Ä‘oáº¡n nÃ y em khÃ´ng hiá»ƒu cÃ¡ch giáº£i thÃ­ch vá» data points vÃ  cÃ¡ch sá»­ dá»¥ng cá»§a BernoulliNB. Do Ä‘Ã³, em hy vá»ng anh chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p tháº¯c máº¯c cá»§a em.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n.","Xin chÃ o anh chá»‹ ! Em má»›i tÃ¬m hiá»ƒu vá» Machine Learning, theo lá»i khuyÃªn cá»§a cÃ¡c tiá»n bá»‘i em báº¯t Ä‘áº§u vá»›i quyá»ƒn Introduction to Machine Learning. Tuy nhiÃªn khi Ä‘á»c tá»›i Ä‘oáº¡n nÃ y em khÃ´ng hiá»ƒu cÃ¡ch giáº£i thÃ­ch vá» data points vÃ  cÃ¡ch sá»­ dá»¥ng cá»§a BernoulliNB. Do Ä‘Ã³, em hy vá»ng anh chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p tháº¯c máº¯c cá»§a em. Em xin chÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
Má»i ngÆ°á»i Æ¡i cho em há»i ai cÃ³ kinh nghiá»‡m anonymise data cho dá»± Ã¡n ML cho em há»i document nghiÃªn cá»©u hay hÆ°á»›ng nghiÃªn cá»©u Ä‘Æ°á»£c khÃ´ng áº¡. Em Ä‘ang lÃ m dá»± Ã¡n phÃ¢n tÃ­ch Ä‘á»™ thÃ nh cÃ´ng cá»§a há»c sinh nÃªn cáº§n anonymise dá»¯ liá»‡u áº¡. Em xin cáº£m Æ¡n,Má»i ngÆ°á»i Æ¡i cho em há»i ai cÃ³ kinh nghiá»‡m anonymise data cho dá»± Ã¡n ML cho em há»i document nghiÃªn cá»©u hay hÆ°á»›ng nghiÃªn cá»©u Ä‘Æ°á»£c khÃ´ng áº¡. Em Ä‘ang lÃ m dá»± Ã¡n phÃ¢n tÃ­ch Ä‘á»™ thÃ nh cÃ´ng cá»§a há»c sinh nÃªn cáº§n anonymise dá»¯ liá»‡u áº¡. Em xin cáº£m Æ¡n,,,,,
DETR lÃ  má»™t thuáº­t toÃ¡n cÃ³ ráº¥t nhiá»u Ä‘iá»ƒm má»›i máº» mÃ  mÃ¬nh xin tá»•ng há»£p trong bÃ i viáº¿t nÃ y. DÃ¹ Ä‘Ã£ cá»‘ gáº¯ng nhÆ°ng bÃ i bÃ i viáº¿t váº«n cÃ²n cÃ³ thá»ƒ cÃ³ thiáº¿u xÃ³t. NhÆ°ng vá»›i mong muá»‘n Ä‘Ã³ng gÃ³p vÃ  xÃ¢y dá»±ng cá»™ng Ä‘á»“ng vá»¯ng máº¡nh hÆ¡n mÃ¬nh mong nháº­n Ä‘Æ°á»£c cÃ¡c Ã½ kiáº¿n pháº£n há»“i tá»« báº¡n Ä‘á»c.,DETR lÃ  má»™t thuáº­t toÃ¡n cÃ³ ráº¥t nhiá»u Ä‘iá»ƒm má»›i máº» mÃ  mÃ¬nh xin tá»•ng há»£p trong bÃ i viáº¿t nÃ y. DÃ¹ Ä‘Ã£ cá»‘ gáº¯ng nhÆ°ng bÃ i bÃ i viáº¿t váº«n cÃ²n cÃ³ thá»ƒ cÃ³ thiáº¿u xÃ³t. NhÆ°ng vá»›i mong muá»‘n Ä‘Ã³ng gÃ³p vÃ  xÃ¢y dá»±ng cá»™ng Ä‘á»“ng vá»¯ng máº¡nh hÆ¡n mÃ¬nh mong nháº­n Ä‘Æ°á»£c cÃ¡c Ã½ kiáº¿n pháº£n há»“i tá»« báº¡n Ä‘á»c.,,,,,
"ChÃ o cÃ¡c báº¡n,
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc Unet sá»­ dá»¥ng Pytorch cho bÃ i toÃ¡n multi-classes instance segmentation. MÃ¬nh Ä‘ang há»c theo hÆ°á»›ng dáº«n trong [github nÃ y](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/image_segmentation/semantic_segmentation_unet), tuy nhiÃªn báº¡n nÃ y chá»‰ lÃ m cho binary case. MÃ¬nh Ä‘Ã£ cháº¡y Ä‘c vá»›i binary case cho dá»¯ liá»‡u cá»§a riÃªng mÃ¬nh. VÃ  Ä‘ang cá»‘ gáº¯ng chuyá»ƒn code sang multi-classes (out_channel=5) khi sá»­ dá»¥ng crossentropyloss() function trong file train.py cÃ¹ng 1 sá»‘ thay Ä‘á»•i khÃ¡c nhÆ°ng ko thÃ nh cÃ´ng. Báº¡n nÃ o cÃ³ kinh nghiá»‡m tÆ° váº¥n giÃ¹m mÃ¬nh cÃ¡ch Ä‘á»•i tá»« binary sang multiclasses model vá»›i. MÃ¬nh xin cÃ¡m Æ¡n.","ChÃ o cÃ¡c báº¡n, MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc Unet sá»­ dá»¥ng Pytorch cho bÃ i toÃ¡n multi-classes instance segmentation. MÃ¬nh Ä‘ang há»c theo hÆ°á»›ng dáº«n trong [github nÃ y](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/image_segmentation/semantic_segmentation_unet), tuy nhiÃªn báº¡n nÃ y chá»‰ lÃ m cho binary case. MÃ¬nh Ä‘Ã£ cháº¡y Ä‘c vá»›i binary case cho dá»¯ liá»‡u cá»§a riÃªng mÃ¬nh. VÃ  Ä‘ang cá»‘ gáº¯ng chuyá»ƒn code sang multi-classes (out_channel=5) khi sá»­ dá»¥ng crossentropyloss() function trong file train.py cÃ¹ng 1 sá»‘ thay Ä‘á»•i khÃ¡c nhÆ°ng ko thÃ nh cÃ´ng. Báº¡n nÃ o cÃ³ kinh nghiá»‡m tÆ° váº¥n giÃ¹m mÃ¬nh cÃ¡ch Ä‘á»•i tá»« binary sang multiclasses model vá»›i. MÃ¬nh xin cÃ¡m Æ¡n.",,,,,
"1. Lá»™ trÃ¬nh Ä‘á»ƒ giá»i trong máº£ng computer vision / object detection lÃ  gÃ¬ áº¡?
2. Hiá»‡n nay team AI thÆ°á»ng nghiÃªn cá»©u chá»§ Ä‘á» gÃ¬ Ä‘á»ƒ cÃ³ model object detection tá»‘t áº¡?
3. CÃ³ pháº£i Ä‘á»ƒ xin Ä‘Æ°á»£c viá»‡c, ngÆ°á»i Ä‘Ã³ cáº§n cáº£ kiáº¿n thá»©c khoa há»c vá» Object detection vÃ  cáº£ kiáº¿n thá»©c vá» framework (vÃ­ dá»¥ tensorflow) hay cÃ³ thá»ƒ giá»i má»™t trong hai?
4. Khi lÃ m viá»‡c trong team, cÃ¡c thÃ nh viÃªn trong team cÃ³ nhá»¯ng vai trÃ²/vá»‹ trÃ­ gÃ¬? (Ä‘á»ƒ em hiá»ƒu nhá»¯ng vá»‹ trÃ­ chuyÃªn mÃ´n Ä‘á»ƒ táº­p trung há»c vÃ o má»™t trong nhá»¯ng vá»‹ trÃ­ Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ xin viá»‡c dá»… dÃ ng hÆ¡n)
5. Ä‘á»‘i vá»›i ngÆ°á»i lÃ m trong ngÃ nh AI Ä‘Æ°á»£c 2 nÄƒm, lÆ°á»£ng kiáº¿n thá»©c há» Ä‘Ã£ tÃ­ch lÅ©y bao nhiÃªu lÃ  bÃ¬nh thÆ°á»ng ( vÃ­ dá»¥ ngÆ°á»i 2 nÄƒm KN chá»‰ biáº¿t vá» má»™t máº£ng object detection cÃ³ Ä‘Æ°á»£c xem lÃ  bÃ¬nh thÆ°á»ng khÃ´ng?)
6. Viá»‡c Ä‘á»c hiá»ƒu paper Ä‘á»‘i vá»›i má»™t ngÆ°á»i 2 nÄƒm KN pháº£i á»Ÿ má»©c Ä‘á»™ nÃ o? ( má»©c Ä‘á»™ cÃ³ thá»ƒ tÃ¹y chá»‰nh layer tá»‘t hÆ¡n paper gá»‘c, cÃ³ báº¯t buá»™c pháº£i hiá»ƒu Ã½ nghÄ©a cá»§a cost function khÃ´ng?)
7. Cáº§n tiÃªu chÃ­ gÃ¬ Ä‘á»ƒ giÃºp ngÆ°á»i má»›i cÃ³ thá»ƒ trá»¥ vá»¯ng vá»›i cty?
8. Náº¿u má»™t ngÆ°á»i báº±ng cáº¥p Cao Ä‘áº³ng, Ä‘iá»ƒm GPA tháº¥p hoáº·c cÃ¡c trÆ°á»ng há»£p tÆ°Æ¡ng tá»±. Cáº§n pháº£i cÃ³ chá»©ng chá»‰ gÃ¬ hay cÃ³ nhá»¯ng giáº£i phÃ¡p gÃ¬ giÃºp ngÆ°á»i Ä‘Ã³ cÃ³ thá»ƒ bá»• sung kiáº¿n thá»©c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°á»£c nháº­n vÃ o lÃ m viá»‡c?","1. Lá»™ trÃ¬nh Ä‘á»ƒ giá»i trong máº£ng computer vision / object detection lÃ  gÃ¬ áº¡? 2. Hiá»‡n nay team AI thÆ°á»ng nghiÃªn cá»©u chá»§ Ä‘á» gÃ¬ Ä‘á»ƒ cÃ³ model object detection tá»‘t áº¡? 3. CÃ³ pháº£i Ä‘á»ƒ xin Ä‘Æ°á»£c viá»‡c, ngÆ°á»i Ä‘Ã³ cáº§n cáº£ kiáº¿n thá»©c khoa há»c vá» Object detection vÃ  cáº£ kiáº¿n thá»©c vá» framework (vÃ­ dá»¥ tensorflow) hay cÃ³ thá»ƒ giá»i má»™t trong hai? 4. Khi lÃ m viá»‡c trong team, cÃ¡c thÃ nh viÃªn trong team cÃ³ nhá»¯ng vai trÃ²/vá»‹ trÃ­ gÃ¬? (Ä‘á»ƒ em hiá»ƒu nhá»¯ng vá»‹ trÃ­ chuyÃªn mÃ´n Ä‘á»ƒ táº­p trung há»c vÃ o má»™t trong nhá»¯ng vá»‹ trÃ­ Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ xin viá»‡c dá»… dÃ ng hÆ¡n) 5. Ä‘á»‘i vá»›i ngÆ°á»i lÃ m trong ngÃ nh AI Ä‘Æ°á»£c 2 nÄƒm, lÆ°á»£ng kiáº¿n thá»©c há» Ä‘Ã£ tÃ­ch lÅ©y bao nhiÃªu lÃ  bÃ¬nh thÆ°á»ng ( vÃ­ dá»¥ ngÆ°á»i 2 nÄƒm KN chá»‰ biáº¿t vá» má»™t máº£ng object detection cÃ³ Ä‘Æ°á»£c xem lÃ  bÃ¬nh thÆ°á»ng khÃ´ng?) 6. Viá»‡c Ä‘á»c hiá»ƒu paper Ä‘á»‘i vá»›i má»™t ngÆ°á»i 2 nÄƒm KN pháº£i á»Ÿ má»©c Ä‘á»™ nÃ o? ( má»©c Ä‘á»™ cÃ³ thá»ƒ tÃ¹y chá»‰nh layer tá»‘t hÆ¡n paper gá»‘c, cÃ³ báº¯t buá»™c pháº£i hiá»ƒu Ã½ nghÄ©a cá»§a cost function khÃ´ng?) 7. Cáº§n tiÃªu chÃ­ gÃ¬ Ä‘á»ƒ giÃºp ngÆ°á»i má»›i cÃ³ thá»ƒ trá»¥ vá»¯ng vá»›i cty? 8. Náº¿u má»™t ngÆ°á»i báº±ng cáº¥p Cao Ä‘áº³ng, Ä‘iá»ƒm GPA tháº¥p hoáº·c cÃ¡c trÆ°á»ng há»£p tÆ°Æ¡ng tá»±. Cáº§n pháº£i cÃ³ chá»©ng chá»‰ gÃ¬ hay cÃ³ nhá»¯ng giáº£i phÃ¡p gÃ¬ giÃºp ngÆ°á»i Ä‘Ã³ cÃ³ thá»ƒ bá»• sung kiáº¿n thá»©c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°á»£c nháº­n vÃ o lÃ m viá»‡c?",,,,,
"ChÃ o cÃ¡c tiá»n bá»‘i.
MÃ¬nh main web backend(.net) giá» chuyá»ƒn qua bá»™ pháº­n R&D vÃ  Ä‘c nháº­n task Ä‘áº§u tiÃªn lÃ  phÃ¢n biá»‡t máº·t ngÆ°á»i(kiá»ƒu cháº¥m cÃ´ng báº±ng face recognition) vÃ  phÃ¢n biá»‡t cÃ¡c loáº¡i rau cá»§ quáº£(cáº£ size thÃ¬ cÃ ng tá»‘t). 
Hiá»‡n h chÆ°a biáº¿t chÃºt gÃ¬ vá» Python vÃ  AI,ML nÃªn cÃ³ vÃ i cÃ¢u há»i ráº¥t mong Ä‘Æ°á»£c sá»± há»“i Ä‘Ã¡p hoáº·c tá»« khÃ³a.
Muá»‘n lÃ m nháº­n face recognition thÃ¬ cháº¡y trÃªn trÃ¬nh duyá»‡t(web-non mobile app) cá»§a thiáº¿t bá»‹ tablet cÃ³ Ä‘c ko?
Muá»‘n lÃ m vá» nháº­n diá»‡n vÃ  phÃ¢n tÃ­ch xu hÆ°á»›ng báº±ng dá»¯ liá»‡u Ä‘áº§u vÃ o(Data Mining??) thÃ¬ khÃ´ng há»c sÃ¢u vá» toÃ¡n, chá»‰ há»c platform nhÆ° Tensorflow vÃ  Pytorch cÃ³ á»•n khÃ´ng?
Pytorch vÃ  Tensorflow cÃ³ Æ°u vÃ  nhÆ°á»£c Ä‘iá»ƒm ntn trong use-case thá»±c táº¿.
Náº¿u khÃ´ng muá»‘n Ä‘i sÃ¢u thÃ¬ chá»‰ sá»­ dá»¥ng cÃ¡c framework cÃ³ sáºµn nhÆ° DeepFace cÃ³ á»•n khÃ´ng? CÃ³ cÃ¡i TeachableMachine dÃ¹ng tháº¥y Ä‘á»§ xÃ i rá»“i cÆ¡ mÃ  khÃ´ng biáº¿t lÃ m tn Ä‘á»ƒ thÃªm dá»¯ liá»‡u vÃ o trong Trained Model. ;(
CÃ¡m Æ¡n mn..","ChÃ o cÃ¡c tiá»n bá»‘i. MÃ¬nh main web backend(.net) giá» chuyá»ƒn qua bá»™ pháº­n R&D vÃ  Ä‘c nháº­n task Ä‘áº§u tiÃªn lÃ  phÃ¢n biá»‡t máº·t ngÆ°á»i(kiá»ƒu cháº¥m cÃ´ng báº±ng face recognition) vÃ  phÃ¢n biá»‡t cÃ¡c loáº¡i rau cá»§ quáº£(cáº£ size thÃ¬ cÃ ng tá»‘t). Hiá»‡n h chÆ°a biáº¿t chÃºt gÃ¬ vá» Python vÃ  AI,ML nÃªn cÃ³ vÃ i cÃ¢u há»i ráº¥t mong Ä‘Æ°á»£c sá»± há»“i Ä‘Ã¡p hoáº·c tá»« khÃ³a. Muá»‘n lÃ m nháº­n face recognition thÃ¬ cháº¡y trÃªn trÃ¬nh duyá»‡t(web-non mobile app) cá»§a thiáº¿t bá»‹ tablet cÃ³ Ä‘c ko? Muá»‘n lÃ m vá» nháº­n diá»‡n vÃ  phÃ¢n tÃ­ch xu hÆ°á»›ng báº±ng dá»¯ liá»‡u Ä‘áº§u vÃ o(Data Mining??) thÃ¬ khÃ´ng há»c sÃ¢u vá» toÃ¡n, chá»‰ há»c platform nhÆ° Tensorflow vÃ  Pytorch cÃ³ á»•n khÃ´ng? Pytorch vÃ  Tensorflow cÃ³ Æ°u vÃ  nhÆ°á»£c Ä‘iá»ƒm ntn trong use-case thá»±c táº¿. Náº¿u khÃ´ng muá»‘n Ä‘i sÃ¢u thÃ¬ chá»‰ sá»­ dá»¥ng cÃ¡c framework cÃ³ sáºµn nhÆ° DeepFace cÃ³ á»•n khÃ´ng? CÃ³ cÃ¡i TeachableMachine dÃ¹ng tháº¥y Ä‘á»§ xÃ i rá»“i cÆ¡ mÃ  khÃ´ng biáº¿t lÃ m tn Ä‘á»ƒ thÃªm dá»¯ liá»‡u vÃ o trong Trained Model. ;( CÃ¡m Æ¡n mn..",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c ML cÆ¡ báº£n.
Nhiá»u anh em má»›i há»c Ä‘Ã£ mua GPU vá» train nhÆ°ng váº«n tháº¥y train model cháº­m vÃ  khÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c háº¿t kháº£ nÄƒng cá»§a GPU. Em Ä‘ang nghiÃªn cá»©u nÃªn máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ !",KÃ­nh chÃ o cÃ¡c bÃ¡c ML cÆ¡ báº£n. Nhiá»u anh em má»›i há»c Ä‘Ã£ mua GPU vá» train nhÆ°ng váº«n tháº¥y train model cháº­m vÃ  khÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c háº¿t kháº£ nÄƒng cá»§a GPU. Em Ä‘ang nghiÃªn cá»©u nÃªn máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ !,,,,,
"CÃ¡c nhÃ  nghiÃªn cá»©u vá» giao tiáº¿p Ä‘á»™ng váº­t sá»­ dá»¥ng má»™t nhÃ¡nh cá»§a AI gá»i lÃ  há»c cÃ³ giÃ¡m sÃ¡t (Supervised Machine Learning) - ná»n táº£ng gáº§n Ä‘Ã¢y Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ trong viá»‡c xá»­ lÃ½ ngÃ´n ngá»¯ cá»§a con ngÆ°á»i. NhÃ¡nh AI nÃ y cÃ³ tÃ­nh á»©ng dá»¥ng cao trong viá»‡c phÃ¢n tÃ­ch cÃ¡c tiáº¿ng kÃªu cá»§a Ä‘á»™ng váº­t.

KhÃ¡c vá»›i AI thÃ´ng thÆ°á»ng chá»‰ cáº§n ""há»c"" dá»±a trÃªn má»™t lÆ°á»£ng dá»¯ liá»‡u nháº¥t Ä‘á»‹nh Ä‘Æ°á»£c gáº¯n nhÃ£n phÃ¢n loáº¡i theo tá»«ng lÄ©nh vá»±c, AI há»c cÃ³ giÃ¡m sÃ¡t cÃ³ thá»ƒ tá»± phÃ¢n tÃ­ch cÃ¡c dá»¯ liá»‡u sáºµn cÃ³, Ä‘á»“ng thá»i thu nháº­n thÃªm ná»™i dung á»Ÿ cÃ¡c nÆ¡i khÃ¡c má»™t cÃ¡ch thÆ°á»ng xuyÃªn vÃ  chá»§ Ä‘á»™ng.
________________
Äá»c thÃªm: https://www.facebook.com/107102171647290/posts/178060687884771/","CÃ¡c nhÃ  nghiÃªn cá»©u vá» giao tiáº¿p Ä‘á»™ng váº­t sá»­ dá»¥ng má»™t nhÃ¡nh cá»§a AI gá»i lÃ  há»c cÃ³ giÃ¡m sÃ¡t (Supervised Machine Learning) - ná»n táº£ng gáº§n Ä‘Ã¢y Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ trong viá»‡c xá»­ lÃ½ ngÃ´n ngá»¯ cá»§a con ngÆ°á»i. NhÃ¡nh AI nÃ y cÃ³ tÃ­nh á»©ng dá»¥ng cao trong viá»‡c phÃ¢n tÃ­ch cÃ¡c tiáº¿ng kÃªu cá»§a Ä‘á»™ng váº­t. KhÃ¡c vá»›i AI thÃ´ng thÆ°á»ng chá»‰ cáº§n ""há»c"" dá»±a trÃªn má»™t lÆ°á»£ng dá»¯ liá»‡u nháº¥t Ä‘á»‹nh Ä‘Æ°á»£c gáº¯n nhÃ£n phÃ¢n loáº¡i theo tá»«ng lÄ©nh vá»±c, AI há»c cÃ³ giÃ¡m sÃ¡t cÃ³ thá»ƒ tá»± phÃ¢n tÃ­ch cÃ¡c dá»¯ liá»‡u sáºµn cÃ³, Ä‘á»“ng thá»i thu nháº­n thÃªm ná»™i dung á»Ÿ cÃ¡c nÆ¡i khÃ¡c má»™t cÃ¡ch thÆ°á»ng xuyÃªn vÃ  chá»§ Ä‘á»™ng. ________________ Äá»c thÃªm: https://www.facebook.com/107102171647290/posts/178060687884771/",,,,,
"[DualStyleGAN - style transfer]
Táº¡i há»™i tháº£o CVPR 2022, mÃ´ hÃ¬nh DualStyleGAN Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ cÃ³ thá»ƒ sinh ra nhá»¯ng áº£nh hoáº¡t hÃ¬nh, biáº¿m há»a, anime tá»« áº£nh gá»‘c ban Ä‘áº§u cá»§a báº¡n. áº¢nh sinh ra váº«n cÃ³ nhá»¯ng nÃ©t tá»« áº£nh ban Ä‘áº§u cá»§a báº¡n, nhÆ°ng phong cÃ¡ch sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i.
Github: https://github.com/williamyang1991/DualStyleGAN
Project: https://www.mmlab-ntu.com/project/dualstylegan/
Demo: https://huggingface.co/spaces/hysts/DualStyleGAN","[DualStyleGAN - style transfer] Táº¡i há»™i tháº£o CVPR 2022, mÃ´ hÃ¬nh DualStyleGAN Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ cÃ³ thá»ƒ sinh ra nhá»¯ng áº£nh hoáº¡t hÃ¬nh, biáº¿m há»a, anime tá»« áº£nh gá»‘c ban Ä‘áº§u cá»§a báº¡n. áº¢nh sinh ra váº«n cÃ³ nhá»¯ng nÃ©t tá»« áº£nh ban Ä‘áº§u cá»§a báº¡n, nhÆ°ng phong cÃ¡ch sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i. Github: https://github.com/williamyang1991/DualStyleGAN Project: https://www.mmlab-ntu.com/project/dualstylegan/ Demo: https://huggingface.co/spaces/hysts/DualStyleGAN",,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh má»›i phÃ¡t hiá»‡n ra 3 thÆ° viá»‡n cÃ³ tÃªn skimpy (táº¡i Ä‘Ã¢y https://github.com/aeturrell/skimpy), pandas-profiling (https://github.com/ydataai/pandas-profiling) vÃ  lux (https://github.com/lux-org/lux) há»— trá»£ ráº¥t tá»‘t viá»‡c khai phÃ¡ dá»¯ liá»‡u dáº¡ng báº£ng (Explore Data Analysis).
Viá»‡c cÃ i skimpy vÃ  pandas-profiling khÃ¡ dá»… dÃ ng nhÆ°ng viá»‡c cÃ i lux cÃ³ pháº§n phá»©c táº¡p hÆ¡n, nhÆ° cáº§n cÃ i nodejs, luxwidget, vÃ  nvm. MÃ¬nh má»›i chá»‰ cÃ i Ä‘áº·t thÃ nh cÃ´ng trÃªn Linux, Ä‘ang cá»‘ gáº¯ng cÃ i trÃªn Mac M1 xem sao.
CÃ²n Ä‘Ã¢y lÃ  jupyterlab mÃ¬nh test thá»­ skimpy, pandas-profiling vÃ  lux, hi vá»ng há»¯u Ã­ch vá»›i má»i ngÆ°á»i.
Náº¿u cÃ¡c báº¡n thÃ­ch, hÃ£y hÃ o phÃ³ng cho mÃ¬nh xin 1 sao (star) vÃ o repository cá»§a mÃ¬nh nhÃ©. Cáº£m Æ¡n cÃ¡c báº¡n!
https://github.com/linhduongtuan/data_explore_analysis_visualization","Gáº§n Ä‘Ã¢y mÃ¬nh má»›i phÃ¡t hiá»‡n ra 3 thÆ° viá»‡n cÃ³ tÃªn skimpy (táº¡i Ä‘Ã¢y https://github.com/aeturrell/skimpy), pandas-profiling (https://github.com/ydataai/pandas-profiling) vÃ  lux (https://github.com/lux-org/lux) há»— trá»£ ráº¥t tá»‘t viá»‡c khai phÃ¡ dá»¯ liá»‡u dáº¡ng báº£ng (Explore Data Analysis). Viá»‡c cÃ i skimpy vÃ  pandas-profiling khÃ¡ dá»… dÃ ng nhÆ°ng viá»‡c cÃ i lux cÃ³ pháº§n phá»©c táº¡p hÆ¡n, nhÆ° cáº§n cÃ i nodejs, luxwidget, vÃ  nvm. MÃ¬nh má»›i chá»‰ cÃ i Ä‘áº·t thÃ nh cÃ´ng trÃªn Linux, Ä‘ang cá»‘ gáº¯ng cÃ i trÃªn Mac M1 xem sao. CÃ²n Ä‘Ã¢y lÃ  jupyterlab mÃ¬nh test thá»­ skimpy, pandas-profiling vÃ  lux, hi vá»ng há»¯u Ã­ch vá»›i má»i ngÆ°á»i. Náº¿u cÃ¡c báº¡n thÃ­ch, hÃ£y hÃ o phÃ³ng cho mÃ¬nh xin 1 sao (star) vÃ o repository cá»§a mÃ¬nh nhÃ©. Cáº£m Æ¡n cÃ¡c báº¡n! https://github.com/linhduongtuan/data_explore_analysis_visualization",,,,,
"ChÃ o má»i ngÆ°á»i! Em Ä‘ang nghiÃªn cá»©u viá»‡c xÃ¢y dá»±ng app android Ä‘á»ƒ nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng, nhÆ°ng yÃªu cáº§u lÃ  láº¥y áº£nh/video tá»« camera gáº¯n ngoÃ i (endoscope camera) qua cá»•ng USB OTG cá»§a Ä‘iá»‡n thoáº¡i Android. Em Ä‘ang gáº·p khÃ³ khÄƒn lÃ m sao láº¥y tÃ­n hiá»‡u tá»« usb camera Ä‘á»ƒ view lÃªn vÃ  Ã¡p dá»¥ng mÃ´ hÃ¬nh lÃªn hÃ¬nh áº£nh Ä‘Ã³. Äá»‘i vá»›i áº£nh/video tá»« camera máº·c Ä‘á»‹nh trÃªn Ä‘iá»‡n thoáº¡i thÃ¬ cÃ³ git nÃ y Ä‘Ã£ hoáº¡t Ä‘á»™ng ok rá»“i: https://github.com/pytorch/android-demo-app/tree/master/ObjectDetection
Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m hay tÃ i liá»‡u gÃ¬ cÃ³ thá»ƒ hÆ°á»›ng dáº«n thÃªm cho em vá»›i áº¡! Thanks!","ChÃ o má»i ngÆ°á»i! Em Ä‘ang nghiÃªn cá»©u viá»‡c xÃ¢y dá»±ng app android Ä‘á»ƒ nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng, nhÆ°ng yÃªu cáº§u lÃ  láº¥y áº£nh/video tá»« camera gáº¯n ngoÃ i (endoscope camera) qua cá»•ng USB OTG cá»§a Ä‘iá»‡n thoáº¡i Android. Em Ä‘ang gáº·p khÃ³ khÄƒn lÃ m sao láº¥y tÃ­n hiá»‡u tá»« usb camera Ä‘á»ƒ view lÃªn vÃ  Ã¡p dá»¥ng mÃ´ hÃ¬nh lÃªn hÃ¬nh áº£nh Ä‘Ã³. Äá»‘i vá»›i áº£nh/video tá»« camera máº·c Ä‘á»‹nh trÃªn Ä‘iá»‡n thoáº¡i thÃ¬ cÃ³ git nÃ y Ä‘Ã£ hoáº¡t Ä‘á»™ng ok rá»“i: https://github.com/pytorch/android-demo-app/tree/master/ObjectDetection Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m hay tÃ i liá»‡u gÃ¬ cÃ³ thá»ƒ hÆ°á»›ng dáº«n thÃªm cho em vá»›i áº¡! Thanks!",,,,,
"MÃ¬nh xin chia sáº» vá»›i má»i ngÆ°á»i Ã½ tÆ°á»Ÿng, code, slide má»™t vÃ i project cá»§a cÃ¡c báº¡n lá»›p Deep Learning.
1. Image Super-Resolution: tÄƒng Ä‘á»™ phÃ¢n giáº£i cá»§a áº£nh sá»­ dá»¥ng bá»™ dá»¯ liá»‡u DIV2K vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p: - SRCNN - ResNet Super Resolution - Autoencoder Super Resolution
2. Car Detection and Tracking: phÃ¡t hiá»‡n vÃ  theo dÃµi phÆ°Æ¡ng tiá»‡n trong video giao thÃ´ng tá»« camera giÃ¡m sÃ¡t sá»­ dá»¥ng SSD MobileNet V2 vÃ  Deep Sort
3. Trigger Word Detection
4. SMS Spam Classification
Slide vÃ  code má»i ngÆ°á»i xem á»Ÿ Ä‘Ã¢y: https://drive.google.com/drive/u/0/folders/1ohkFxElbhM_LMwCY_xJwSRWWRwLu75yB?fbclid=IwAR3HFUH5T6KEBmIGLdTMLWz9b68hZrObUn1M_wFn-L51qQYV8PX1wblpmeE","MÃ¬nh xin chia sáº» vá»›i má»i ngÆ°á»i Ã½ tÆ°á»Ÿng, code, slide má»™t vÃ i project cá»§a cÃ¡c báº¡n lá»›p Deep Learning. 1. Image Super-Resolution: tÄƒng Ä‘á»™ phÃ¢n giáº£i cá»§a áº£nh sá»­ dá»¥ng bá»™ dá»¯ liá»‡u DIV2K vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p: - SRCNN - ResNet Super Resolution - Autoencoder Super Resolution 2. Car Detection and Tracking: phÃ¡t hiá»‡n vÃ  theo dÃµi phÆ°Æ¡ng tiá»‡n trong video giao thÃ´ng tá»« camera giÃ¡m sÃ¡t sá»­ dá»¥ng SSD MobileNet V2 vÃ  Deep Sort 3. Trigger Word Detection 4. SMS Spam Classification Slide vÃ  code má»i ngÆ°á»i xem á»Ÿ Ä‘Ã¢y: https://drive.google.com/drive/u/0/folders/1ohkFxElbhM_LMwCY_xJwSRWWRwLu75yB?fbclid=IwAR3HFUH5T6KEBmIGLdTMLWz9b68hZrObUn1M_wFn-L51qQYV8PX1wblpmeE",,,,,
"Hello m.n,
Viá»‡c Download 1 táº­p datasets tá»« Kaggle hay COCO khÃ´ng cÃ²n xa láº¡ gÃ¬ vá»›i ae há»c A.I. NhÆ°ng viá»‡c tinh lá»c, Ä‘iá»u chá»‰nh láº¡i dataset lÃ  Ä‘iá»u vÃ´ cÃ¹ng má»‡t má»i vÃ¬ khá»‘i lÆ°á»£ng data cÅ©ng nhÆ° sá»± thá»§ cÃ´ng trong cÃ¡c khÃ¢u Ä‘iá»u chá»‰nh. CÃ¡c cÃ´ng viá»‡c nhÆ° tÃ¬m lá»—i annotation, Label láº¡i objects, tháº­t sá»± khiáº¿n ae chÃ¡n náº£n.
Tiáº¿p tá»¥c chá»§ Ä‘á» Data-Centric Approach, mÃ¬nh xin giá»›i thiá»‡u 1 cÃ´ng cá»¥ FiftyOne- Ä‘Æ°á»£c xem lÃ  1 trong nhá»¯ng tools tá»‘t nháº¥t Ä‘á»ƒ xÃ¢y dá»±ng datasets cháº¥t lÆ°á»£ng.
Thank all.","Hello m.n, Viá»‡c Download 1 táº­p datasets tá»« Kaggle hay COCO khÃ´ng cÃ²n xa láº¡ gÃ¬ vá»›i ae há»c A.I. NhÆ°ng viá»‡c tinh lá»c, Ä‘iá»u chá»‰nh láº¡i dataset lÃ  Ä‘iá»u vÃ´ cÃ¹ng má»‡t má»i vÃ¬ khá»‘i lÆ°á»£ng data cÅ©ng nhÆ° sá»± thá»§ cÃ´ng trong cÃ¡c khÃ¢u Ä‘iá»u chá»‰nh. CÃ¡c cÃ´ng viá»‡c nhÆ° tÃ¬m lá»—i annotation, Label láº¡i objects, tháº­t sá»± khiáº¿n ae chÃ¡n náº£n. Tiáº¿p tá»¥c chá»§ Ä‘á» Data-Centric Approach, mÃ¬nh xin giá»›i thiá»‡u 1 cÃ´ng cá»¥ FiftyOne- Ä‘Æ°á»£c xem lÃ  1 trong nhá»¯ng tools tá»‘t nháº¥t Ä‘á»ƒ xÃ¢y dá»±ng datasets cháº¥t lÆ°á»£ng. Thank all.",,,,,
chÃ o cÃ¡c anh chá»‹. Em Ä‘ang tÃ­nh lÃ m má»™t bÃ i toÃ¡n dá»± Ä‘oÃ¡n lÆ°Æ¡ng dá»±a trÃªn kÄ© nÄƒng vÃ  em cÃ³ dataset nhÆ° hÃ¬nh bÃªn dÆ°á»›i. nhÆ°ng hiá»‡n táº¡i cÃ¡i Ä‘áº·c trÆ°ng top_skills nÃ³ dáº¡ng danh sÃ¡ch vÃ  chiá»u dÃ i nÃ³ khÃ´ng báº±ng nhau nhÆ° váº­y lÃ m sao Ä‘á»ƒ Ä‘Æ°a vÃ´ há»“i quy áº¡. em cáº£m Æ¡n,chÃ o cÃ¡c anh chá»‹. Em Ä‘ang tÃ­nh lÃ m má»™t bÃ i toÃ¡n dá»± Ä‘oÃ¡n lÆ°Æ¡ng dá»±a trÃªn kÄ© nÄƒng vÃ  em cÃ³ dataset nhÆ° hÃ¬nh bÃªn dÆ°á»›i. nhÆ°ng hiá»‡n táº¡i cÃ¡i Ä‘áº·c trÆ°ng top_skills nÃ³ dáº¡ng danh sÃ¡ch vÃ  chiá»u dÃ i nÃ³ khÃ´ng báº±ng nhau nhÆ° váº­y lÃ m sao Ä‘á»ƒ Ä‘Æ°a vÃ´ há»“i quy áº¡. em cáº£m Æ¡n,,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡. Em lÃ  thÃ nh viÃªn má»›i, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  Ä‘ang cá»‘ gáº¯ng viáº¿t má»™t AI cÃ³ kháº£ nÄƒng há»c vÃ  giáº£i toÃ¡n báº±ng cÃ¡ch trÃ¬nh bÃ y lá»i giáº£i. Cháº³ng háº¡n nhÆ° sau khi cho mÃ¡y ""Ä‘á»c"" má»™t sá»‘ bÃ i giáº£i phÆ°Æ¡ng trÃ¬nh báº­c nháº¥t dÆ°á»›i kiá»ƒu xÃ¢u, nÃ³ cÃ³ thá»ƒ Ä‘Æ°a ra lá»i giáº£i cho má»™t Ä‘á» bÃ i phÆ°Æ¡ng trÃ¬nh báº­c nháº¥t khÃ¡c. Em cÃ³ hai cÃ¢u há»i lÃ  má»™t AI nhÆ° váº­y thuá»™c vÃ o loáº¡i nÃ o cá»§a ML (vÃ¬ em chÆ°a tÃ¬m Ä‘Æ°á»£c sá»± giá»‘ng nhau cá»§a nÃ³ vá»›i 4 loáº¡i ML Ä‘Æ°á»£c nÃ³i trong cÃ¡c tÃ i liá»‡u), vÃ  cÃ³ tÃ i liá»‡u nÃ o liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y hay khÃ´ng. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡!","Xin chÃ o má»i ngÆ°á»i áº¡. Em lÃ  thÃ nh viÃªn má»›i, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  Ä‘ang cá»‘ gáº¯ng viáº¿t má»™t AI cÃ³ kháº£ nÄƒng há»c vÃ  giáº£i toÃ¡n báº±ng cÃ¡ch trÃ¬nh bÃ y lá»i giáº£i. Cháº³ng háº¡n nhÆ° sau khi cho mÃ¡y ""Ä‘á»c"" má»™t sá»‘ bÃ i giáº£i phÆ°Æ¡ng trÃ¬nh báº­c nháº¥t dÆ°á»›i kiá»ƒu xÃ¢u, nÃ³ cÃ³ thá»ƒ Ä‘Æ°a ra lá»i giáº£i cho má»™t Ä‘á» bÃ i phÆ°Æ¡ng trÃ¬nh báº­c nháº¥t khÃ¡c. Em cÃ³ hai cÃ¢u há»i lÃ  má»™t AI nhÆ° váº­y thuá»™c vÃ o loáº¡i nÃ o cá»§a ML (vÃ¬ em chÆ°a tÃ¬m Ä‘Æ°á»£c sá»± giá»‘ng nhau cá»§a nÃ³ vá»›i 4 loáº¡i ML Ä‘Æ°á»£c nÃ³i trong cÃ¡c tÃ i liá»‡u), vÃ  cÃ³ tÃ i liá»‡u nÃ o liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y hay khÃ´ng. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡!",,,,,
"Trong cÃ¡c stt trÆ°á»›c cá»§a mÃ¬nh vá» GNN trong bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh, cÃ³ báº¡n há»i lÃ  liá»‡u GNN cÃ³ thá»ƒ phÃ¢n loáº¡i Ä‘Æ°á»£c áº£nh mÃ u vá»›i cÃ¡c data thu tháº­p tá»± nhiÃªn (thay vÃ¬ cÃ¡c Medical Modalities) hay khÃ´ng táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/posts/1355120224945381/?comment_id=1355778824879521&reply_comment_id=1355792078211529). VÃ¬ váº­y mÃ¬nh chá»n 1 dataset khÃ¡ lÃ  challenge cho cÃ¡c máº¡ng CNNs/Transformers trong bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh lÃ  5-class flowers dataset trÃªn Kaggle táº¡i Ä‘Ã¢y https://www.kaggle.com/alxmamaev/flowers-recognition. Trong dataset nÃ y cÃ³ tá»›i 379 Notebooks liÃªn quan tá»›i nÃ³, má»™t trong sá»‘ chÃºng lÃ  Notebook nÃ y (https://www.kaggle.com/georgiisirotenko/pytorch-flowers-translearing-ensemble-test-99-67) vá»›i sá»‘ lÆ°á»£t votes Ä‘áº¡t 91, Ä‘á»©ng thá»© 5 trÃªn tá»•ng sá»‘ 379 notebooks. TÃ¡c giáº£ cá»§a notebooks nÃ y Ä‘Ã£ lÃ m thÃ­ nghiá»‡m vá»›i nhiá»u models CNNs vÃ  dÃ¹ng kÄ© thuáº­t Ensemble (vá»›i 5 models lÃ  'DenseNet_0', 'DenseNet_1', 'GooglNet', 'ResNet101', 'VGG16 with BN') Ä‘á»ƒ Ä‘áº¡t accuracy ~0.9967. Viá»‡c nÃ y Ä‘Ã²i há»i ráº¥t nhiá»u tÃ i nguyÃªn tÃ­nh toÃ¡n, vÃ  trÃªn thá»±c táº¿ ráº¥t khÃ³ Ä‘á»ƒ Ä‘Æ°a vÃ o á»©ng dá»¥ng vÃ¬ thá»i gian inference/prediction sáº½ kÃ©o dÃ i, tháº­m trÃ­ Out-of-Memory náº¿u dÃ¹ng GPU cÃ³ dung lÆ°á»£ng VRAM nhá»!
Má»™t váº¥n Ä‘á» quan trá»ng nháº¥t lÃ  GNN models cÃ³ thá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i nÃ y ráº¥t nhanh, tá»‘n tá»•ng thá»i gian < 01 giá» mÃ  thÃ´i! HÆ¡n ná»¯a, thá»i gian tiÃªu tá»‘n chá»§ yáº¿u liÃªn quan tá»›i quÃ¡ trÃ¬nh tiá»n xá»­ lÃ­ áº£nh vÃ  táº¡o Graph-structured data, thá»i gian training model chá»‰ chiáº¿m ~ 10 phÃºt cho 100 epochs mÃ  thÃ´i (thá»±c táº¿ chá»‰ cáº§n train models vá»›i 10 epochs lÃ  Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c há»™i tá»¥ rá»“i!)
ChÃºc cÃ¡c báº¡n 1 tuáº§n má»›i lÃ m viá»‡c nÄƒng suáº¥t vÃ  hiá»‡u quáº£!
Vá»›i cÃ¡c báº¡n há»c táº­p vÃ  lÃ m viá»‡c á»Ÿ phÆ°Æ¡ng TÃ¢y, chÃºc mÃ¹a nghá»‰ lá»… giÃ¡ng sinh vÃ  Ä‘Ã³n nÄƒm má»›i an lÃ nh!","Trong cÃ¡c stt trÆ°á»›c cá»§a mÃ¬nh vá» GNN trong bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh, cÃ³ báº¡n há»i lÃ  liá»‡u GNN cÃ³ thá»ƒ phÃ¢n loáº¡i Ä‘Æ°á»£c áº£nh mÃ u vá»›i cÃ¡c data thu tháº­p tá»± nhiÃªn (thay vÃ¬ cÃ¡c Medical Modalities) hay khÃ´ng táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/posts/1355120224945381/?comment_id=1355778824879521&reply_comment_id=1355792078211529). VÃ¬ váº­y mÃ¬nh chá»n 1 dataset khÃ¡ lÃ  challenge cho cÃ¡c máº¡ng CNNs/Transformers trong bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh lÃ  5-class flowers dataset trÃªn Kaggle táº¡i Ä‘Ã¢y https://www.kaggle.com/alxmamaev/flowers-recognition. Trong dataset nÃ y cÃ³ tá»›i 379 Notebooks liÃªn quan tá»›i nÃ³, má»™t trong sá»‘ chÃºng lÃ  Notebook nÃ y (https://www.kaggle.com/georgiisirotenko/pytorch-flowers-translearing-ensemble-test-99-67) vá»›i sá»‘ lÆ°á»£t votes Ä‘áº¡t 91, Ä‘á»©ng thá»© 5 trÃªn tá»•ng sá»‘ 379 notebooks. TÃ¡c giáº£ cá»§a notebooks nÃ y Ä‘Ã£ lÃ m thÃ­ nghiá»‡m vá»›i nhiá»u models CNNs vÃ  dÃ¹ng kÄ© thuáº­t Ensemble (vá»›i 5 models lÃ  'DenseNet_0', 'DenseNet_1', 'GooglNet', 'ResNet101', 'VGG16 with BN') Ä‘á»ƒ Ä‘áº¡t accuracy ~0.9967. Viá»‡c nÃ y Ä‘Ã²i há»i ráº¥t nhiá»u tÃ i nguyÃªn tÃ­nh toÃ¡n, vÃ  trÃªn thá»±c táº¿ ráº¥t khÃ³ Ä‘á»ƒ Ä‘Æ°a vÃ o á»©ng dá»¥ng vÃ¬ thá»i gian inference/prediction sáº½ kÃ©o dÃ i, tháº­m trÃ­ Out-of-Memory náº¿u dÃ¹ng GPU cÃ³ dung lÆ°á»£ng VRAM nhá»! Má»™t váº¥n Ä‘á» quan trá»ng nháº¥t lÃ  GNN models cÃ³ thá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i nÃ y ráº¥t nhanh, tá»‘n tá»•ng thá»i gian < 01 giá» mÃ  thÃ´i! HÆ¡n ná»¯a, thá»i gian tiÃªu tá»‘n chá»§ yáº¿u liÃªn quan tá»›i quÃ¡ trÃ¬nh tiá»n xá»­ lÃ­ áº£nh vÃ  táº¡o Graph-structured data, thá»i gian training model chá»‰ chiáº¿m ~ 10 phÃºt cho 100 epochs mÃ  thÃ´i (thá»±c táº¿ chá»‰ cáº§n train models vá»›i 10 epochs lÃ  Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c há»™i tá»¥ rá»“i!) ChÃºc cÃ¡c báº¡n 1 tuáº§n má»›i lÃ m viá»‡c nÄƒng suáº¥t vÃ  hiá»‡u quáº£! Vá»›i cÃ¡c báº¡n há»c táº­p vÃ  lÃ m viá»‡c á»Ÿ phÆ°Æ¡ng TÃ¢y, chÃºc mÃ¹a nghá»‰ lá»… giÃ¡ng sinh vÃ  Ä‘Ã³n nÄƒm má»›i an lÃ nh!",,,,,
"Em chÃ o cÃ¡c anh chá»‹.
Hiá»‡n táº¡i em muá»‘n thu vá» 1 file dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sá»± thÃ nh cÃ´ng cá»§a 100 loáº¡i tiá»n áº£o tá»« whitepaper cá»§a nÃ³ dá»±a trÃªn chá»‰ sá»‘ ROI. Tá»©c lÃ  sá»­ dá»¥ng text mining Ä‘á»ƒ chuyen whitepaper dáº¡ng pdf sang txt (Ä‘iá»u kiá»‡n lÃ  filter factor ROI)
Em cÃ³ sá»­ dá»¥ng PyPDF2 nhÆ°ng chá»‰ cÃ³ thá»ƒ láº¥y text tá»«ng file 1, chÆ°a biáº¿t pháº£i lá»c theo Ä‘iá»u kiá»‡n nhÆ° tháº¿ nÃ o.
Em khÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o Ä‘Ã£ tá»«ng lÃ m hoáº·c cÃ³ biáº¿t vá» cÃ´ng viá»‡c tÆ°Æ¡ng tá»± cÃ³ thá»ƒ cho em há»i thÄƒm má»™t sá»‘ váº¥n Ä‘á» khÃ´ng áº¡?
Em xin cáº£m Æ¡n áº¡!","Em chÃ o cÃ¡c anh chá»‹. Hiá»‡n táº¡i em muá»‘n thu vá» 1 file dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sá»± thÃ nh cÃ´ng cá»§a 100 loáº¡i tiá»n áº£o tá»« whitepaper cá»§a nÃ³ dá»±a trÃªn chá»‰ sá»‘ ROI. Tá»©c lÃ  sá»­ dá»¥ng text mining Ä‘á»ƒ chuyen whitepaper dáº¡ng pdf sang txt (Ä‘iá»u kiá»‡n lÃ  filter factor ROI) Em cÃ³ sá»­ dá»¥ng PyPDF2 nhÆ°ng chá»‰ cÃ³ thá»ƒ láº¥y text tá»«ng file 1, chÆ°a biáº¿t pháº£i lá»c theo Ä‘iá»u kiá»‡n nhÆ° tháº¿ nÃ o. Em khÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o Ä‘Ã£ tá»«ng lÃ m hoáº·c cÃ³ biáº¿t vá» cÃ´ng viá»‡c tÆ°Æ¡ng tá»± cÃ³ thá»ƒ cho em há»i thÄƒm má»™t sá»‘ váº¥n Ä‘á» khÃ´ng áº¡? Em xin cáº£m Æ¡n áº¡!",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 1/2022 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i nÄƒm má»›i máº¡nh khá»e vÃ  bÃ¬nh an.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 1/2022 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i nÄƒm má»›i máº¡nh khá»e vÃ  bÃ¬nh an.",,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i mÃ¬nh cÃ³ Ä‘Æ°á»£c cuá»‘n Pattern Recognition and Machine Learning cá»§a Bishop. MÃ¬nh cÃ³ gáº·p nhiá»u váº¥n Ä‘á» khi hiá»ƒu ná»™i dung cá»§a quyá»ƒn sÃ¡ch, cÃ³ ráº¥t nhiá»u má»¥c vÃ  cÅ©ng nhÆ° cÃ¡c lÃ½ thuyáº¿t vá» toÃ¡n cao cáº¥p phá»©c táº¡p, cÅ©ng nhÆ° ráº¥t khÃ³ Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c. VD lÃ  pháº§n Hessian Matrix cá»§a Neural Networks, mÃ¬nh Ä‘á»c chá»‰ hiá»ƒu Ä‘Æ°á»£c khoáº£ng dÆ°á»›i 50% ná»™i dung.
MÃ¬nh muá»‘n há»i má»i ngÆ°á»i tá»«ng Ä‘á»c cuá»‘n sÃ¡ch nÃ y lÃ  khi gáº·p nhá»¯ng pháº§n ná»™i dung khÃ³ nhÆ° váº­y, mÃ¬nh nÃªn tÃ¬m tÃ²i Ä‘á»c hiá»ƒu nhÆ° tháº¿ nÃ o hay Ä‘á»c thÃªm gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c. MÃ¬nh cÅ©ng cÃ³ Ä‘á»c qua cuá»‘n Introduction to Linear Algebra vÃ  cÅ©ng náº¯m Ä‘Æ°á»£c cÃ¡c kiáº¿n thá»©c ná»n táº£ng bÃªn Statistic (MÃ¬nh Ä‘Ã£ Ä‘á»c 14 chÆ°Æ¡ng Ä‘áº§u cá»§a All of Statistics - A Concise Course in Statistical Inference, cÅ©ng hiá»ƒu kha khÃ¡ ná»™i dung) , nhÆ°ng tháº­t sá»± viá»‡c Ä‘á»c hiá»ƒu Ä‘Æ°á»£c toÃ n bá»™ ná»™i dung cuá»‘n sÃ¡ch vá»›i mÃ¬nh quÃ¡ khÃ³ khÄƒn. MÃ¬nh cÃ³ nghe nhiá»u ngÆ°á»i nÃ³i cuá»‘n nÃ y lÃ  kinh thÆ° vÃ  cÆ¡ báº£n nÃªn mÃ¬nh muá»‘n cá»‘ gáº¯ng hiá»ƒu háº¿t ná»™i dung cuá»‘n sÃ¡ch.
MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i mÃ¬nh cÃ³ Ä‘Æ°á»£c cuá»‘n Pattern Recognition and Machine Learning cá»§a Bishop. MÃ¬nh cÃ³ gáº·p nhiá»u váº¥n Ä‘á» khi hiá»ƒu ná»™i dung cá»§a quyá»ƒn sÃ¡ch, cÃ³ ráº¥t nhiá»u má»¥c vÃ  cÅ©ng nhÆ° cÃ¡c lÃ½ thuyáº¿t vá» toÃ¡n cao cáº¥p phá»©c táº¡p, cÅ©ng nhÆ° ráº¥t khÃ³ Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c. VD lÃ  pháº§n Hessian Matrix cá»§a Neural Networks, mÃ¬nh Ä‘á»c chá»‰ hiá»ƒu Ä‘Æ°á»£c khoáº£ng dÆ°á»›i 50% ná»™i dung. MÃ¬nh muá»‘n há»i má»i ngÆ°á»i tá»«ng Ä‘á»c cuá»‘n sÃ¡ch nÃ y lÃ  khi gáº·p nhá»¯ng pháº§n ná»™i dung khÃ³ nhÆ° váº­y, mÃ¬nh nÃªn tÃ¬m tÃ²i Ä‘á»c hiá»ƒu nhÆ° tháº¿ nÃ o hay Ä‘á»c thÃªm gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c. MÃ¬nh cÅ©ng cÃ³ Ä‘á»c qua cuá»‘n Introduction to Linear Algebra vÃ  cÅ©ng náº¯m Ä‘Æ°á»£c cÃ¡c kiáº¿n thá»©c ná»n táº£ng bÃªn Statistic (MÃ¬nh Ä‘Ã£ Ä‘á»c 14 chÆ°Æ¡ng Ä‘áº§u cá»§a All of Statistics - A Concise Course in Statistical Inference, cÅ©ng hiá»ƒu kha khÃ¡ ná»™i dung) , nhÆ°ng tháº­t sá»± viá»‡c Ä‘á»c hiá»ƒu Ä‘Æ°á»£c toÃ n bá»™ ná»™i dung cuá»‘n sÃ¡ch vá»›i mÃ¬nh quÃ¡ khÃ³ khÄƒn. MÃ¬nh cÃ³ nghe nhiá»u ngÆ°á»i nÃ³i cuá»‘n nÃ y lÃ  kinh thÆ° vÃ  cÆ¡ báº£n nÃªn mÃ¬nh muá»‘n cá»‘ gáº¯ng hiá»ƒu háº¿t ná»™i dung cuá»‘n sÃ¡ch. MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡,
Cho em há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ káº¿t quáº£ training ko thay Ä‘á»•i khi train Ä‘i train láº¡i nhiá»u láº§n áº¡.
Em Ä‘Ã£ thá»­ dÃ¹ng seed nhÆ° nÃ y rá»“i : http://codepad.org/P7mmvuqt nhÆ°ng káº¿t quáº£ train váº«n bá»‹ thay Ä‘á»•i má»—i láº§n train láº¡i áº¡.
Em cÅ©ng Ä‘Ã£ thá»­ seed láº¡i má»—i sau khi khá»Ÿi táº¡o model vÃ  dataloader nhÆ°ng cÅ©ng ko dc áº¡.
Mong mn chá»‰ giÃºp áº¡, e cáº£m Æ¡n","Em chÃ o má»i ngÆ°á»i áº¡, Cho em há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ káº¿t quáº£ training ko thay Ä‘á»•i khi train Ä‘i train láº¡i nhiá»u láº§n áº¡. Em Ä‘Ã£ thá»­ dÃ¹ng seed nhÆ° nÃ y rá»“i : http://codepad.org/P7mmvuqt nhÆ°ng káº¿t quáº£ train váº«n bá»‹ thay Ä‘á»•i má»—i láº§n train láº¡i áº¡. Em cÅ©ng Ä‘Ã£ thá»­ seed láº¡i má»—i sau khi khá»Ÿi táº¡o model vÃ  dataloader nhÆ°ng cÅ©ng ko dc áº¡. Mong mn chá»‰ giÃºp áº¡, e cáº£m Æ¡n",,,,,
"[Help][Import turicreate trong Jupyter Notebook] MÃ¬nh Ä‘Ã£ cÃ i turicreate trong Ubuntu 1804 LS, nhÆ°ng import trong Jupyter khÃ´ng Ä‘Æ°á»£c. Báº¡n nÃ o giÃºp Ä‘á»¡ mÃ¬nh vá»›i. Cáº£m Æ¡n nhiá»u!!","[Help][Import turicreate trong Jupyter Notebook] MÃ¬nh Ä‘Ã£ cÃ i turicreate trong Ubuntu 1804 LS, nhÆ°ng import trong Jupyter khÃ´ng Ä‘Æ°á»£c. Báº¡n nÃ o giÃºp Ä‘á»¡ mÃ¬nh vá»›i. Cáº£m Æ¡n nhiá»u!!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh hiá»‡n Ä‘Ã£ xÃ i model YOLOv5m vá»›i Deepsort Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i id xe, tuy nhiÃªn mÃ¬nh chÆ°a biáº¿t cÃ¡ch tÃ¹y chá»‰nh Ä‘á»ƒ cÃ³ thá»ƒ Ä‘áº¿m Ä‘Æ°á»£c xe nhÆ° hÃ¬nh dÆ°á»›i. Do mÃ¬nh clone thÆ° má»¥c Deepsort tá»«: https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch thay Ä‘á»•i cÃ¡c thÃ´ng sá»‘ cháº¡y lá»‡nh command nÃªn giá» tÃ¹y chá»‰nh pháº§n code mÃ¬nh mÃ² nhÆ°ng váº«n khÃ´ng ra. CÃ³ bÃ¡c nÃ o rÃ nh vá» cÃ¡i nÃ y cho mÃ¬nh xin há»i tÃ¬m hiá»ƒu vá»›i áº¡.
MÃ¬nh cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, mÃ¬nh hiá»‡n Ä‘Ã£ xÃ i model YOLOv5m vá»›i Deepsort Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i id xe, tuy nhiÃªn mÃ¬nh chÆ°a biáº¿t cÃ¡ch tÃ¹y chá»‰nh Ä‘á»ƒ cÃ³ thá»ƒ Ä‘áº¿m Ä‘Æ°á»£c xe nhÆ° hÃ¬nh dÆ°á»›i. Do mÃ¬nh clone thÆ° má»¥c Deepsort tá»«: https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch thay Ä‘á»•i cÃ¡c thÃ´ng sá»‘ cháº¡y lá»‡nh command nÃªn giá» tÃ¹y chá»‰nh pháº§n code mÃ¬nh mÃ² nhÆ°ng váº«n khÃ´ng ra. CÃ³ bÃ¡c nÃ o rÃ nh vá» cÃ¡i nÃ y cho mÃ¬nh xin há»i tÃ¬m hiá»ƒu vá»›i áº¡. MÃ¬nh cáº£m Æ¡n.",,,,,
"Má»i ngÆ°á»i cho em há»i chÃºt áº¡. Em Ä‘ang há»c theo sÃ¡ch Mathematics for Machine Learning. á» chÆ°Æ¡ng SVD cÃ³ bÃ i tÃ¬m xáº¥p xá»‰ rank-1 cá»§a 1 ma tráº­n A, theo em Ä‘c biáº¿t thÃ¬ nÃ³ Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c Ïƒi.ui.vi^T. Váº­y cÃ²n trÆ°á»ng há»£p Ä‘á» bÃ i há»i xáº¥p xá»‰ rank 2 cá»§a ma tráº­n thÃ¬ tÃ­nh sao áº¡ ? Em xin cÃ¡m Æ¡n.","Má»i ngÆ°á»i cho em há»i chÃºt áº¡. Em Ä‘ang há»c theo sÃ¡ch Mathematics for Machine Learning. á» chÆ°Æ¡ng SVD cÃ³ bÃ i tÃ¬m xáº¥p xá»‰ rank-1 cá»§a 1 ma tráº­n A, theo em Ä‘c biáº¿t thÃ¬ nÃ³ Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c Ïƒi.ui.vi^T. Váº­y cÃ²n trÆ°á»ng há»£p Ä‘á» bÃ i há»i xáº¥p xá»‰ rank 2 cá»§a ma tráº­n thÃ¬ tÃ­nh sao áº¡ ? Em xin cÃ¡m Æ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» phÃ¡t hiá»‡n tÆ°Æ¡ng Ä‘á»“ng trong vÄƒn báº£n tiáº¿ng Viá»‡t, em chÆ°a cÃ³ kinh nghiá»‡m nhiá»u trong NLP nÃªn mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m chia sáº» hÆ°á»›ng lÃ m hay lÃ  cÃ¡c model hay thuáº­t toÃ¡n nÃ o tá»‘t vá»›i áº¡. Em cáº£m Æ¡n","Em chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» phÃ¡t hiá»‡n tÆ°Æ¡ng Ä‘á»“ng trong vÄƒn báº£n tiáº¿ng Viá»‡t, em chÆ°a cÃ³ kinh nghiá»‡m nhiá»u trong NLP nÃªn mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m chia sáº» hÆ°á»›ng lÃ m hay lÃ  cÃ¡c model hay thuáº­t toÃ¡n nÃ o tá»‘t vá»›i áº¡. Em cáº£m Æ¡n",,,,,
"Xin há»i diá»…n Ä‘Ã n cÃ³ báº¡n nÃ o quan tÃ¢m tá»›i viá»‡c nghiÃªn cá»©u phÃ¢n loáº¡i ElectroEncephaloGram (EEG) khÃ´ng? MÃ¬nh cÃ³ Ä‘ang chuyá»ƒn dá»¯ liá»‡u EEG vá» dáº¡ng Spectrogram (má»—i window lÃ  10 giÃ¢y, sampling rate=250, mÃ¬nh dÃ¹ng thÆ° viá»‡n librosa) mÃ  sao nÃ³ cháº¡y ráº¥t lÃ¢u, mÃ¬nh thá»­ dÃ¹ng cáº£ thÆ° viá»‡n multiprocessing nhÆ°ng kiá»ƒm tra CPU dÃ¹ng ráº¥t Ã­t. MÃ¬nh Ä‘oÃ¡n Ä‘á»ƒ extract háº¿t dá»¯ liá»‡u sáº½ tá»‘n cáº£ 10 ngÃ y cháº¡y. CÃ³ báº¡n nÃ o cÃ³ kinh nghiá»‡p gÃ³p Ã½ tips/trick/treat vá»¥ nÃ y cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng?
Táº­p dá»¯ liá»‡u Epilepsy cá»§a Temple University táº¡i Ä‘Ã¢y","Xin há»i diá»…n Ä‘Ã n cÃ³ báº¡n nÃ o quan tÃ¢m tá»›i viá»‡c nghiÃªn cá»©u phÃ¢n loáº¡i ElectroEncephaloGram (EEG) khÃ´ng? MÃ¬nh cÃ³ Ä‘ang chuyá»ƒn dá»¯ liá»‡u EEG vá» dáº¡ng Spectrogram (má»—i window lÃ  10 giÃ¢y, sampling rate=250, mÃ¬nh dÃ¹ng thÆ° viá»‡n librosa) mÃ  sao nÃ³ cháº¡y ráº¥t lÃ¢u, mÃ¬nh thá»­ dÃ¹ng cáº£ thÆ° viá»‡n multiprocessing nhÆ°ng kiá»ƒm tra CPU dÃ¹ng ráº¥t Ã­t. MÃ¬nh Ä‘oÃ¡n Ä‘á»ƒ extract háº¿t dá»¯ liá»‡u sáº½ tá»‘n cáº£ 10 ngÃ y cháº¡y. CÃ³ báº¡n nÃ o cÃ³ kinh nghiá»‡p gÃ³p Ã½ tips/trick/treat vá»¥ nÃ y cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng? Táº­p dá»¯ liá»‡u Epilepsy cá»§a Temple University táº¡i Ä‘Ã¢y",,,,,
"CÃ¡c bÃ¡c cho em há»i chÃºt vá»›i áº¡. Em Ä‘ang nghiÃªn cá»©u PhoBert vÃ  cÃ³ lÃªn trang github cá»§a há» nhÆ°ng váº«n chÆ°a hiá»ƒu PhoBert dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?
Em Ä‘ang hÃ¬nh dung PhoBert nhÆ° lÃ  Word2vec Ä‘á»ƒ mÃ£ hÃ³a cÃ¢u thÃ nh vector Ä‘Ãºng ko ah?
Em ko tháº¥y thÃªm tÃ¡c dÃ¹ng gÃ¬ mong cÃ¡c bÃ¡c chá»‰ giÃ¡o.",CÃ¡c bÃ¡c cho em há»i chÃºt vá»›i áº¡. Em Ä‘ang nghiÃªn cá»©u PhoBert vÃ  cÃ³ lÃªn trang github cá»§a há» nhÆ°ng váº«n chÆ°a hiá»ƒu PhoBert dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬? Em Ä‘ang hÃ¬nh dung PhoBert nhÆ° lÃ  Word2vec Ä‘á»ƒ mÃ£ hÃ³a cÃ¢u thÃ nh vector Ä‘Ãºng ko ah? Em ko tháº¥y thÃªm tÃ¡c dÃ¹ng gÃ¬ mong cÃ¡c bÃ¡c chá»‰ giÃ¡o.,,,,,
"Hello m.n,
Äá»‘i vá»›i ae A.I newbie viá»‡c thá»±c hÃ nh lÃ  vÃ´ cÃ¹ng quan trá»ng, mÃ¬nh xin giá»›i thiá»‡u má»™t sá»‘ PROJECTS cÃ³ source code vÃ  dataset Ä‘á»ƒ ae tham kháº£o.!
Thank all.","Hello m.n, Äá»‘i vá»›i ae A.I newbie viá»‡c thá»±c hÃ nh lÃ  vÃ´ cÃ¹ng quan trá»ng, mÃ¬nh xin giá»›i thiá»‡u má»™t sá»‘ PROJECTS cÃ³ source code vÃ  dataset Ä‘á»ƒ ae tham kháº£o.! Thank all.",,,,,
"ChÃ o cÃ¡c anh em. HÃ´m nay chÃºng ta sáº½ cÃ¹ng tiáº¿p cáº­n má»™t bÃ i toÃ¡n tiáº¿p theo trong Series AI in Banking lÃ  ""Thá»­ lÃ m model dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» dá»‹ch vá»¥ (Customer Churn Prediction) "".
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c tÃ¬m hiá»ƒu thÃªm má»™t mÃ³n má»›i!","ChÃ o cÃ¡c anh em. HÃ´m nay chÃºng ta sáº½ cÃ¹ng tiáº¿p cáº­n má»™t bÃ i toÃ¡n tiáº¿p theo trong Series AI in Banking lÃ  ""Thá»­ lÃ m model dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» dá»‹ch vá»¥ (Customer Churn Prediction) "". Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c tÃ¬m hiá»ƒu thÃªm má»™t mÃ³n má»›i!",,,,,
"NhÆ° má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘Ã£ biáº¿t, Graph Neural Networks hiá»‡n Ä‘ang lÃ  má»™t trong nhá»¯ng chá»§ Ä‘á» nghiÃªn cá»©u ráº¥t Ä‘Æ°á»£c quan tÃ¢m trÃªn tháº¿ giá»›i, Ä‘Æ°á»£c á»©ng dá»¥ng thÃ nh cÃ´ng trong nhiá»u lÄ©nh vá»±c nhÆ° NLP, computer vision, vÃ  drug discovery. MÃ¬nh xin chia sáº» vá»›i má»i ngÆ°á»i vá» Graph Transformer mÃ  nhÃ³m mÃ¬nh Ä‘Ã£ báº¯t Ä‘áº§u phÃ¡t triá»ƒn tá»« 3 nÄƒm trÆ°á»›c tá»›i hiá»‡n táº¡i. Paper sáº½ Ä‘Æ°á»£c trÃ¬nh bÃ y táº¡i TheWebConf WWW '22 Poster and Demo track: https://arxiv.org/pdf/1909.11855v13.pdf
Code: https://github.com/daiquocnguyen/Graph-Transformer
Abstract:
We introduce a transformer-based GNN model, named UGformer, to learn graph representations. In particular, we present two UGformer variants, wherein the first variant (publicized in September 2019) is to leverage the transformer on a set of sampled neighbors for each input node, while the second (publicized in May 2021) is to leverage the transformer on all input nodes. Experimental results demonstrate that the first UGformer variant achieves state-of-the-art accuracies on benchmark datasets for graph classification in both inductive setting and unsupervised transductive setting; and the second UGformer variant obtains state-of-the-art accuracies for inductive text classification.","NhÆ° má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘Ã£ biáº¿t, Graph Neural Networks hiá»‡n Ä‘ang lÃ  má»™t trong nhá»¯ng chá»§ Ä‘á» nghiÃªn cá»©u ráº¥t Ä‘Æ°á»£c quan tÃ¢m trÃªn tháº¿ giá»›i, Ä‘Æ°á»£c á»©ng dá»¥ng thÃ nh cÃ´ng trong nhiá»u lÄ©nh vá»±c nhÆ° NLP, computer vision, vÃ  drug discovery. MÃ¬nh xin chia sáº» vá»›i má»i ngÆ°á»i vá» Graph Transformer mÃ  nhÃ³m mÃ¬nh Ä‘Ã£ báº¯t Ä‘áº§u phÃ¡t triá»ƒn tá»« 3 nÄƒm trÆ°á»›c tá»›i hiá»‡n táº¡i. Paper sáº½ Ä‘Æ°á»£c trÃ¬nh bÃ y táº¡i TheWebConf WWW '22 Poster and Demo track: https://arxiv.org/pdf/1909.11855v13.pdf Code: https://github.com/daiquocnguyen/Graph-Transformer Abstract: We introduce a transformer-based GNN model, named UGformer, to learn graph representations. In particular, we present two UGformer variants, wherein the first variant (publicized in September 2019) is to leverage the transformer on a set of sampled neighbors for each input node, while the second (publicized in May 2021) is to leverage the transformer on all input nodes. Experimental results demonstrate that the first UGformer variant achieves state-of-the-art accuracies on benchmark datasets for graph classification in both inductive setting and unsupervised transductive setting; and the second UGformer variant obtains state-of-the-art accuracies for inductive text classification.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang muá»‘n fine tuning mÃ´ hÃ¬nh arcface trÃªn táº­p dá»¯ liá»‡u cá»§a mÃ¬nh nhÆ°ng gáº·p má»™t sá»‘ váº¥n Ä‘á» vá» viá»‡c load pretrained model. Link github sá»­ dá»¥ng:
https://github.com/auroua/InsightFace_TF/blob/master/train_nets.py
Dá»¯ liá»‡u Ä‘i qua resnet model sau Ä‘Ã³ qua hÃ m arcface_loss (hÃ¬nh 1). Em muá»‘n sá»­ dá»¥ng láº¡i trá»ng sá»‘ cá»§a resnet vÃ  thay Ä‘á»•i sá»‘ lá»›p ouput cá»§a arcface_loss nÃªn em chuyá»ƒn pháº§n restore pretrained lÃªn phÃ­a trÃªn (hÃ¬nh 2) thÃ¬ code váº«n cháº¡y Ä‘Æ°á»£c nhÆ°ng khi em sá»­a má»™t sá»‘ thá»© Ä‘á»ƒ xem embedding_tensor = test_net.outputs cÃ³ lÃ  khÃ´ng Ä‘á»•i (Ä‘á»ƒ kiá»ƒm tra Ä‘Ã£ load trá»ng sá»‘ resnet thÃ nh cÃ´ng hay chÆ°a) khi cho 1 áº£nh khuÃ´n máº·t Ä‘i qua máº¡ng thÃ¬ náº¿u Ä‘á»ƒ nguyÃªn code cÅ© thÃ¬ khÃ´ng Ä‘á»•i nhÆ°ng khi chuyá»ƒn lÃªn phÃ­a trÃªn thÃ¬ láº¡i khÃ¡c nhau.
CÃ³ anh/chá»‹/báº¡n nÃ o Ä‘Ã£ biáº¿t vá» viá»‡c fine tuning vá»›i TensorFlow 1.4 1.6, TensorLayer 1.7 cho em há»i cÃ¡ch mÃ¬nh fine tuning model vá»›i áº¡, do trong github Ä‘Ã³ xÃ i phiÃªn báº£n nÃ y áº¡. Em cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang muá»‘n fine tuning mÃ´ hÃ¬nh arcface trÃªn táº­p dá»¯ liá»‡u cá»§a mÃ¬nh nhÆ°ng gáº·p má»™t sá»‘ váº¥n Ä‘á» vá» viá»‡c load pretrained model. Link github sá»­ dá»¥ng: https://github.com/auroua/InsightFace_TF/blob/master/train_nets.py Dá»¯ liá»‡u Ä‘i qua resnet model sau Ä‘Ã³ qua hÃ m arcface_loss (hÃ¬nh 1). Em muá»‘n sá»­ dá»¥ng láº¡i trá»ng sá»‘ cá»§a resnet vÃ  thay Ä‘á»•i sá»‘ lá»›p ouput cá»§a arcface_loss nÃªn em chuyá»ƒn pháº§n restore pretrained lÃªn phÃ­a trÃªn (hÃ¬nh 2) thÃ¬ code váº«n cháº¡y Ä‘Æ°á»£c nhÆ°ng khi em sá»­a má»™t sá»‘ thá»© Ä‘á»ƒ xem embedding_tensor = test_net.outputs cÃ³ lÃ  khÃ´ng Ä‘á»•i (Ä‘á»ƒ kiá»ƒm tra Ä‘Ã£ load trá»ng sá»‘ resnet thÃ nh cÃ´ng hay chÆ°a) khi cho 1 áº£nh khuÃ´n máº·t Ä‘i qua máº¡ng thÃ¬ náº¿u Ä‘á»ƒ nguyÃªn code cÅ© thÃ¬ khÃ´ng Ä‘á»•i nhÆ°ng khi chuyá»ƒn lÃªn phÃ­a trÃªn thÃ¬ láº¡i khÃ¡c nhau. CÃ³ anh/chá»‹/báº¡n nÃ o Ä‘Ã£ biáº¿t vá» viá»‡c fine tuning vá»›i TensorFlow 1.4 1.6, TensorLayer 1.7 cho em há»i cÃ¡ch mÃ¬nh fine tuning model vá»›i áº¡, do trong github Ä‘Ã³ xÃ i phiÃªn báº£n nÃ y áº¡. Em cáº£m Æ¡n.",,,,,
"[structure from motion - Colmap]
Ko liÃªn quan láº¯m Ä‘áº¿n ML nhÆ°ng liÃªn quan Ä‘áº¿n CV áº¡. CÃ¡c anh chá»‹ cÃ³ ai Ä‘Ã£ dÃ¹ng Colmap thÃ¬ cho em inb há»i chÃºt. CÃ¢u há»i cá»¥ thá»ƒ cá»§a em (em dÃ¹ng colmap command line, ko dÃ¹ng dc GUI)
em cháº¡y colmap automatic-reconstruction mÃ  nÃ³ ko generate dense model, chá»‰ cÃ³ sparse directory dc táº¡o ra. CÃ³ ai Ä‘Ã£ dÃ¹ng tool nÃ y vÃ  gáº·p hiá»‡n tÆ°á»£ng nÃ y ko áº¡?
estimated camera intrinsics tá»« colmap automatic-reconstruction vÃ  colmap feature-extractor khÃ¡c háº³n nhau. Code pháº§n automatic_reconstructor cá»§a em trÃªn bash nhÆ° dÆ°á»›i áº£nh 1. Colmap feature-extractor tÆ°Æ¡ng tá»±, áº£nh 2
 LÃ m sao Ä‘á»ƒ visualize point cloud tá»« sparse and dense model    cá»§a Colmap? (preferably báº±ng script, ko pháº£i báº±ng hit-and-click GUI cá»§a Colmap, vÃ¬ em cÃ³ gáº§n 3k bá»™ áº£nh).
Em muá»‘n set initial guess cho intrinsic and extrinsic camera parameter for sfm model, thÃ¬ lÃ m nhÆ° tháº¿ nÃ o áº¡? Em Ä‘á»c doc tháº¥y báº£o lÃ  pháº£i modify .db file generated nhÆ°ng  db file em ko tháº¥y cÃ¡i cá»™t nÃ o cho focal length vá»›i principal point cá»§a camera háº¿t thÃ¬ sá»­a vÃ o Ä‘Ã¢u ?
Em cáº£m Æ¡n áº¡","[structure from motion - Colmap] Ko liÃªn quan láº¯m Ä‘áº¿n ML nhÆ°ng liÃªn quan Ä‘áº¿n CV áº¡. CÃ¡c anh chá»‹ cÃ³ ai Ä‘Ã£ dÃ¹ng Colmap thÃ¬ cho em inb há»i chÃºt. CÃ¢u há»i cá»¥ thá»ƒ cá»§a em (em dÃ¹ng colmap command line, ko dÃ¹ng dc GUI) em cháº¡y colmap automatic-reconstruction mÃ  nÃ³ ko generate dense model, chá»‰ cÃ³ sparse directory dc táº¡o ra. CÃ³ ai Ä‘Ã£ dÃ¹ng tool nÃ y vÃ  gáº·p hiá»‡n tÆ°á»£ng nÃ y ko áº¡? estimated camera intrinsics tá»« colmap automatic-reconstruction vÃ  colmap feature-extractor khÃ¡c háº³n nhau. Code pháº§n automatic_reconstructor cá»§a em trÃªn bash nhÆ° dÆ°á»›i áº£nh 1. Colmap feature-extractor tÆ°Æ¡ng tá»±, áº£nh 2 LÃ m sao Ä‘á»ƒ visualize point cloud tá»« sparse and dense model cá»§a Colmap? (preferably báº±ng script, ko pháº£i báº±ng hit-and-click GUI cá»§a Colmap, vÃ¬ em cÃ³ gáº§n 3k bá»™ áº£nh). Em muá»‘n set initial guess cho intrinsic and extrinsic camera parameter for sfm model, thÃ¬ lÃ m nhÆ° tháº¿ nÃ o áº¡? Em Ä‘á»c doc tháº¥y báº£o lÃ  pháº£i modify .db file generated nhÆ°ng db file em ko tháº¥y cÃ¡i cá»™t nÃ o cho focal length vá»›i principal point cá»§a camera háº¿t thÃ¬ sá»­a vÃ o Ä‘Ã¢u ? Em cáº£m Æ¡n áº¡",,,,,
"Hello m.n,
Cháº¯c ai lÃ m viá»‡c vá»›i A.i cÅ©ng tá»«ng tá»‘n khÃ¡ nhiá»u thá»i gian Ä‘á»ƒ tinh chá»‰nh model cho fit vá»›i data, hÆ¡n 80% thá»i gian chÃºng ta dÃ nh cho viá»‡c data preparation, clean data, 20% cÃ²n láº¡i cho Model vÃ  dÆ°á»ng nhÆ° Ã­t ngÆ°á»i quan tÃ¢m Ä‘áº¿n Ä‘iá»u Ä‘Ã³. Váº­y táº¡i sao ngay tá»« Ä‘áº§u chÃºng ta khÃ´ng táº­p trung tinh lá»c input cho A.i application?
em xin giá»›i thiá»‡u 1 bÃ i viáº¿t vá» DATA-CENTRIC APPROACH vÃ  MODEL-CENTRIC APPROACH.
Thanks all.","Hello m.n, Cháº¯c ai lÃ m viá»‡c vá»›i A.i cÅ©ng tá»«ng tá»‘n khÃ¡ nhiá»u thá»i gian Ä‘á»ƒ tinh chá»‰nh model cho fit vá»›i data, hÆ¡n 80% thá»i gian chÃºng ta dÃ nh cho viá»‡c data preparation, clean data, 20% cÃ²n láº¡i cho Model vÃ  dÆ°á»ng nhÆ° Ã­t ngÆ°á»i quan tÃ¢m Ä‘áº¿n Ä‘iá»u Ä‘Ã³. Váº­y táº¡i sao ngay tá»« Ä‘áº§u chÃºng ta khÃ´ng táº­p trung tinh lá»c input cho A.i application? em xin giá»›i thiá»‡u 1 bÃ i viáº¿t vá» DATA-CENTRIC APPROACH vÃ  MODEL-CENTRIC APPROACH. Thanks all.",,,,,
CÃ¡c báº¡n cÃ³ thá»ƒ tham gia má»™t sá»‘ khÃ³a há»c Machine Learning miá»…n phÃ­ á»Ÿ Ä‘Ã¢y,CÃ¡c báº¡n cÃ³ thá»ƒ tham gia má»™t sá»‘ khÃ³a há»c Machine Learning miá»…n phÃ­ á»Ÿ Ä‘Ã¢y,,,,,
VietAI cÃ´ng bá»‘ dá»± Ã¡n nghiÃªn cá»©u MTet: MÃ´ hÃ¬nh dá»‹ch mÃ¡y Anh-Viá»‡t Ä‘a lÄ©nh vá»±c tá»‘i Æ°u vá»›i dá»¯ liá»‡u lá»›n nháº¥t táº¡i Viá»‡t Nam! Chi tiáº¿t xem phÃ­a dÆ°á»›i.,VietAI cÃ´ng bá»‘ dá»± Ã¡n nghiÃªn cá»©u MTet: MÃ´ hÃ¬nh dá»‹ch mÃ¡y Anh-Viá»‡t Ä‘a lÄ©nh vá»±c tá»‘i Æ°u vá»›i dá»¯ liá»‡u lá»›n nháº¥t táº¡i Viá»‡t Nam! Chi tiáº¿t xem phÃ­a dÆ°á»›i.,,,,,
"ChÃ o anh/ chá»‹ vÃ  cÃ¡c báº¡n,
MÃ¬nh hiá»‡n Ä‘ang lÃ m vá» lÄ©nh vá»±c tÃ i chÃ­nh, Ä‘ang báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» ML. CÃ¡c báº¡n cÃ³ giá»›i thiá»‡u cho mÃ¬nh sÃ¡ch vá» ML cho beginners, giáº£i thÃ­ch nhá»¯ng khÃ¡i niá»‡m vÃ  1 vÃ i models cÆ¡ báº£n vá» ML, má»™t cÃ¡ch Ä‘Æ¡n giáº£n, cÃ³ há»‡ thá»‘ng vÃ  dá»… hiá»ƒu Ä‘c khÃ´ng áº¡, liÃªn quan Ä‘áº¿n lÄ©nh vá»±c kinh táº¿ thÃ¬ cÃ ng tá»‘t? CÃ¡m Æ¡n cÃ¡c báº¡n Ä‘Ã£ chia sáº».","ChÃ o anh/ chá»‹ vÃ  cÃ¡c báº¡n, MÃ¬nh hiá»‡n Ä‘ang lÃ m vá» lÄ©nh vá»±c tÃ i chÃ­nh, Ä‘ang báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» ML. CÃ¡c báº¡n cÃ³ giá»›i thiá»‡u cho mÃ¬nh sÃ¡ch vá» ML cho beginners, giáº£i thÃ­ch nhá»¯ng khÃ¡i niá»‡m vÃ  1 vÃ i models cÆ¡ báº£n vá» ML, má»™t cÃ¡ch Ä‘Æ¡n giáº£n, cÃ³ há»‡ thá»‘ng vÃ  dá»… hiá»ƒu Ä‘c khÃ´ng áº¡, liÃªn quan Ä‘áº¿n lÄ©nh vá»±c kinh táº¿ thÃ¬ cÃ ng tá»‘t? CÃ¡m Æ¡n cÃ¡c báº¡n Ä‘Ã£ chia sáº».",,,,,
"Trong mÃ¡u cá»§a chÃºng ta cÃ³ it nháº¥t 3 loáº¡i táº¿ bÃ o: táº¿ bÃ o há»“ng cáº§u (RBC), táº¿ bÃ o báº¡ch cáº§u (WBC) vÃ  táº¿ bÃ o tiá»ƒu cáº§u (platelets). Trong Ä‘Ã³, há»“ng cáº§u (RBC) chiáº¿m sá»‘ lÆ°á»£ng nhiá»u nháº¥t, cÃ³ nhiá»‡m vá»¥ váº­n chuyá»ƒn khÃ­ Oxy (O2) Ä‘áº¿n phá»•i vÃ  cÃ¡c mÃ´, Ä‘i kháº¯p cÆ¡ thá»ƒ, Ä‘á»“ng thá»i tiáº¿p thu cÃ¡c cháº¥t tháº£i vÃ  khÃ­ cabonic (CO2) vá» phá»•i Ä‘á»ƒ Ä‘Ã o tháº£i. Náº¿u thiáº¿u há»“ng cáº§u (thiáº¿u mÃ¡u), con ngÆ°á»i sáº½ tháº¥y má»‡t má»i vÃ  yáº¿u sá»©c.
Táº¿ bÃ o báº¡ch cáº§u (WBC) lÃ  nhá»¯ng pháº§n quan trá»ng cá»§a há»‡ thá»‘ng miá»…n dá»‹ch cá»§a chÃºng ta vÃ  chÃºng báº£o vá»‡ cÆ¡ thá»ƒ chá»‘ng láº¡i nhiá»…m trÃ¹ng báº±ng cÃ¡ch loáº¡i bá» vi rÃºt, vi khuáº©n, kÃ½ sinh trÃ¹ng vÃ  náº¥m. Sá»‘ lÆ°á»£ng loáº¡i báº¡ch cáº§u vÃ  tá»•ng sá»‘ lÆ°á»£ng báº¡ch cáº§u cung cáº¥p thÃ´ng tin quan trá»ng vá» tÃ¬nh tráº¡ng sá»©c khá»e cá»§a chÃºng ta. CÃ¡c bá»‡nh nhÆ° bá»‡nh báº¡ch cáº§u, AIDS, bá»‡nh tá»± miá»…n, suy giáº£m miá»…n dá»‹ch, bá»‡nh mÃ¡u cÃ³ thá»ƒ Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n dá»±a trÃªn sá»‘ lÆ°á»£ng báº¡ch cáº§u.
Tiá»ƒu cáº§u (Platelets) lÃ  nhá»¯ng máº£nh táº¿ bÃ o nhá», cÃ³ chá»©c nÄƒng cáº§m mÃ¡u, táº¡o cá»¥c mÃ¡u Ä‘Ã´ng, bá»‹t cÃ¡c váº¿t thÆ°Æ¡ng á»Ÿ thÃ nh máº¡ch mÃ¡u. Khi lÆ°á»£ng tiá»ƒu cáº§u quÃ¡ tháº¥p, cÃ¡c cÆ¡ quan ná»™i táº¡ng vÃ  nÃ£o bá»™ cÃ³ thá»ƒ bá»‹ xuáº¥t huyáº¿t.
Do Ä‘Ã³, viá»‡c xÃ¡c Ä‘á»‹nh vÃ  Ä‘áº¿m Ä‘Æ°á»£c sá»‘ lÆ°á»£ng há»“ng cáº§u, báº¡ch cáº§u vÃ  tiá»ƒu cáº§u trong má»™t máº«u mÃ¡u lÃ  nhiá»‡m vá»¥ quan trá»ng. NÃ³ giÃºp cÃ¡c bÃ¡c sá»¹ chuáº©n Ä‘oÃ¡n cÃ¡ch bá»‡nh nan y, Ä‘á»“ng thá»i trá»£ giÃºp Ä‘Æ°a ra cÃ¡c phÃ¡c Ä‘á»“ Ä‘iá»u trá»‹ hiá»‡u quáº£ nháº¥t.
Báº±ng viá»‡c sá»­ dá»¥ng cÃ´ng nghá»‡ AI, chÃºng ta cÃ³ thá»ƒ thiáº¿t káº¿ ra pháº§n má»m káº¿t ná»‘i trá»±c tiáº¿p vá»›i cÃ¡c loáº¡i kÃ­nh hiá»ƒn vi Ä‘iá»‡n tá»­, cho phÃ©p xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c sá»‘ lÆ°á»£ng cÃ¡c loáº¡i táº¿ bÃ o mÃ¡u trong thá»i gian thá»±c (real-time). Trong bÃ i hÆ°á»›ng dáº«n nÃ y, chÃºng tÃ´i sá»­ dá»¥ng dá»¯ liá»‡u mÃ¡u tá»« trang robolfow.com vÃ  sá»­ dá»¥ng pháº§n má»m ANS ODHUB (anscenter.com) Ä‘á»ƒ chá»©ng minh tÃ­nh kháº£ thi cá»§a cÃ´ng nghá»‡ AI trong lÄ©nh vá»±c y khoa.
Vá»›i kháº£ nÄƒng chuáº©n Ä‘oÃ¡n, nháº­n dáº¡ng vÃ  xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c váº­t thá»ƒ á»Ÿ má»©c táº¿ bÃ o, náº¿u sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± cho xÃ©t nghiá»‡m COVID19, chÃºng ta cÃ³ thá»ƒ táº¡o ra há»‡ thá»‘ng xÃ©t nghiá»‡m nhanh (30s) vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao (trÃªn 90%) náº¿u chÃºng ta cÃ³ Ä‘á»§ máº«u dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n há»‡ thá»‘ng AI. Náº¿u cÃ¡c báº¡n tháº¥y bÃ i nÃ y cÃ³ Ã­ch cho cá»™ng Ä‘á»“ng, hÃ£y giÃºp chÃºng tÃ´i chia sáº» nÃ³. Biáº¿t Ä‘Ã¢u sáº½ cÃ³ cÃ¡c nhÃ  nghiÃªn cá»©u, cÃ¡c cÃ´ng ty hay cÃ¡c cÆ¡ quan nhÃ  nÆ°á»›c á»©ng dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y nhÆ° má»™t giáº£i phÃ¡p thay tháº¿ cho xÃ©t nghiá»‡m COVID hiá»‡u quáº£.
ChÃºng tÃ´i sáº½ chia sáº» cÃ¡ch thiáº¿t káº¿ há»‡ thá»‘ng AI báº±ng ANS ODHUB Ä‘Æ°á»£c tÃ­ch há»£p vá»›i cÃ´ng nghá»‡ Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y trÃªn há»‡ thá»‘ng chá»§ (ANSCloud) trÃªn kÃªnh Youtube cá»§a ANSCENTER.","Trong mÃ¡u cá»§a chÃºng ta cÃ³ it nháº¥t 3 loáº¡i táº¿ bÃ o: táº¿ bÃ o há»“ng cáº§u (RBC), táº¿ bÃ o báº¡ch cáº§u (WBC) vÃ  táº¿ bÃ o tiá»ƒu cáº§u (platelets). Trong Ä‘Ã³, há»“ng cáº§u (RBC) chiáº¿m sá»‘ lÆ°á»£ng nhiá»u nháº¥t, cÃ³ nhiá»‡m vá»¥ váº­n chuyá»ƒn khÃ­ Oxy (O2) Ä‘áº¿n phá»•i vÃ  cÃ¡c mÃ´, Ä‘i kháº¯p cÆ¡ thá»ƒ, Ä‘á»“ng thá»i tiáº¿p thu cÃ¡c cháº¥t tháº£i vÃ  khÃ­ cabonic (CO2) vá» phá»•i Ä‘á»ƒ Ä‘Ã o tháº£i. Náº¿u thiáº¿u há»“ng cáº§u (thiáº¿u mÃ¡u), con ngÆ°á»i sáº½ tháº¥y má»‡t má»i vÃ  yáº¿u sá»©c. Táº¿ bÃ o báº¡ch cáº§u (WBC) lÃ  nhá»¯ng pháº§n quan trá»ng cá»§a há»‡ thá»‘ng miá»…n dá»‹ch cá»§a chÃºng ta vÃ  chÃºng báº£o vá»‡ cÆ¡ thá»ƒ chá»‘ng láº¡i nhiá»…m trÃ¹ng báº±ng cÃ¡ch loáº¡i bá» vi rÃºt, vi khuáº©n, kÃ½ sinh trÃ¹ng vÃ  náº¥m. Sá»‘ lÆ°á»£ng loáº¡i báº¡ch cáº§u vÃ  tá»•ng sá»‘ lÆ°á»£ng báº¡ch cáº§u cung cáº¥p thÃ´ng tin quan trá»ng vá» tÃ¬nh tráº¡ng sá»©c khá»e cá»§a chÃºng ta. CÃ¡c bá»‡nh nhÆ° bá»‡nh báº¡ch cáº§u, AIDS, bá»‡nh tá»± miá»…n, suy giáº£m miá»…n dá»‹ch, bá»‡nh mÃ¡u cÃ³ thá»ƒ Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n dá»±a trÃªn sá»‘ lÆ°á»£ng báº¡ch cáº§u. Tiá»ƒu cáº§u (Platelets) lÃ  nhá»¯ng máº£nh táº¿ bÃ o nhá», cÃ³ chá»©c nÄƒng cáº§m mÃ¡u, táº¡o cá»¥c mÃ¡u Ä‘Ã´ng, bá»‹t cÃ¡c váº¿t thÆ°Æ¡ng á»Ÿ thÃ nh máº¡ch mÃ¡u. Khi lÆ°á»£ng tiá»ƒu cáº§u quÃ¡ tháº¥p, cÃ¡c cÆ¡ quan ná»™i táº¡ng vÃ  nÃ£o bá»™ cÃ³ thá»ƒ bá»‹ xuáº¥t huyáº¿t. Do Ä‘Ã³, viá»‡c xÃ¡c Ä‘á»‹nh vÃ  Ä‘áº¿m Ä‘Æ°á»£c sá»‘ lÆ°á»£ng há»“ng cáº§u, báº¡ch cáº§u vÃ  tiá»ƒu cáº§u trong má»™t máº«u mÃ¡u lÃ  nhiá»‡m vá»¥ quan trá»ng. NÃ³ giÃºp cÃ¡c bÃ¡c sá»¹ chuáº©n Ä‘oÃ¡n cÃ¡ch bá»‡nh nan y, Ä‘á»“ng thá»i trá»£ giÃºp Ä‘Æ°a ra cÃ¡c phÃ¡c Ä‘á»“ Ä‘iá»u trá»‹ hiá»‡u quáº£ nháº¥t. Báº±ng viá»‡c sá»­ dá»¥ng cÃ´ng nghá»‡ AI, chÃºng ta cÃ³ thá»ƒ thiáº¿t káº¿ ra pháº§n má»m káº¿t ná»‘i trá»±c tiáº¿p vá»›i cÃ¡c loáº¡i kÃ­nh hiá»ƒn vi Ä‘iá»‡n tá»­, cho phÃ©p xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c sá»‘ lÆ°á»£ng cÃ¡c loáº¡i táº¿ bÃ o mÃ¡u trong thá»i gian thá»±c (real-time). Trong bÃ i hÆ°á»›ng dáº«n nÃ y, chÃºng tÃ´i sá»­ dá»¥ng dá»¯ liá»‡u mÃ¡u tá»« trang robolfow.com vÃ  sá»­ dá»¥ng pháº§n má»m ANS ODHUB (anscenter.com) Ä‘á»ƒ chá»©ng minh tÃ­nh kháº£ thi cá»§a cÃ´ng nghá»‡ AI trong lÄ©nh vá»±c y khoa. Vá»›i kháº£ nÄƒng chuáº©n Ä‘oÃ¡n, nháº­n dáº¡ng vÃ  xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c váº­t thá»ƒ á»Ÿ má»©c táº¿ bÃ o, náº¿u sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± cho xÃ©t nghiá»‡m COVID19, chÃºng ta cÃ³ thá»ƒ táº¡o ra há»‡ thá»‘ng xÃ©t nghiá»‡m nhanh (30s) vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao (trÃªn 90%) náº¿u chÃºng ta cÃ³ Ä‘á»§ máº«u dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n há»‡ thá»‘ng AI. Náº¿u cÃ¡c báº¡n tháº¥y bÃ i nÃ y cÃ³ Ã­ch cho cá»™ng Ä‘á»“ng, hÃ£y giÃºp chÃºng tÃ´i chia sáº» nÃ³. Biáº¿t Ä‘Ã¢u sáº½ cÃ³ cÃ¡c nhÃ  nghiÃªn cá»©u, cÃ¡c cÃ´ng ty hay cÃ¡c cÆ¡ quan nhÃ  nÆ°á»›c á»©ng dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y nhÆ° má»™t giáº£i phÃ¡p thay tháº¿ cho xÃ©t nghiá»‡m COVID hiá»‡u quáº£. ChÃºng tÃ´i sáº½ chia sáº» cÃ¡ch thiáº¿t káº¿ há»‡ thá»‘ng AI báº±ng ANS ODHUB Ä‘Æ°á»£c tÃ­ch há»£p vá»›i cÃ´ng nghá»‡ Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y trÃªn há»‡ thá»‘ng chá»§ (ANSCloud) trÃªn kÃªnh Youtube cá»§a ANSCENTER.",,,,,
"cÃ¡c Anh/Chá»‹/ báº¡n cho mÃ¬nh há»i : trong Q-learning, khi nÃ o mÃ¬nh sáº½ dá»«ng viá»‡c train, cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘Ã¡nh giÃ¡ káº¿t quáº£ training cá»§a Q learning khÃ´ng
Xin cÃ¡m Æ¡n","cÃ¡c Anh/Chá»‹/ báº¡n cho mÃ¬nh há»i : trong Q-learning, khi nÃ o mÃ¬nh sáº½ dá»«ng viá»‡c train, cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘Ã¡nh giÃ¡ káº¿t quáº£ training cá»§a Q learning khÃ´ng Xin cÃ¡m Æ¡n",,,,,
"KÃNH CHÃ€O TUáº¦N Má»šI CÃC BÃC! NHIá»€U ANH EM KHI LÃ€M CÃC BÃ€I TOÃN PHÃ‚N Lá»šP VÃ€ Sáº¼ Gáº¶P PHáº¢I IMBALANCED DATA. EM CHIA Sáºº VÃ€I TIP Äá»‚ ANH EM Xá»¬ LÃ CÃI MÃ“N KHÃ™ KHOáº°M NÃ€Y.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em má»›i há»c cÃ³ hÆ°á»›ng tham kháº£o!",KÃNH CHÃ€O TUáº¦N Má»šI CÃC BÃC! NHIá»€U ANH EM KHI LÃ€M CÃC BÃ€I TOÃN PHÃ‚N Lá»šP VÃ€ Sáº¼ Gáº¶P PHáº¢I IMBALANCED DATA. EM CHIA Sáºº VÃ€I TIP Äá»‚ ANH EM Xá»¬ LÃ CÃI MÃ“N KHÃ™ KHOáº°M NÃ€Y. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em má»›i há»c cÃ³ hÆ°á»›ng tham kháº£o!,,,,,
CÃ¹ng thá»­ tÃ¬m hiá»ƒu vÃ  viáº¿t AI tá»± Ä‘á»™ng tÃ´ mÃ u cho áº£nh Ä‘en tráº¯ng :),CÃ¹ng thá»­ tÃ¬m hiá»ƒu vÃ  viáº¿t AI tá»± Ä‘á»™ng tÃ´ mÃ u cho áº£nh Ä‘en tráº¯ng :),,,,,
"Em chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang cÃ³ má»™t váº¥n Ä‘á» nhÆ° sau: Kiá»ƒm tra chÃ­nh táº£ má»™t cÃ¢u mÃ  ngÆ°á»i dÃ¹ng nháº­p vÃ o, sau Ä‘Ã³ Ä‘á» xuáº¥t ra cÃ¢u má»›i náº¿u nhÆ° cÃ¢u cá»§a ngÆ°á»i dÃ¹ng sai chÃ­nh táº£. NhÆ° google áº¥y áº¡.
BÃ i toÃ¡n cá»§a em lÃ  á»Ÿ pháº¡m vi trong thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, vÃ­ dá»¥ nhÆ° ngÆ°á»i dÃ¹ng nháº­p sai tÃªn sáº£n pháº©m trÃªn thanh search thÃ¬ mÃ¬nh sáº½ Ä‘á» xuáº¥t sá»­a láº¡i tá»« Ä‘Ã³ cho há». Hiá»‡n táº¡i cÃ¡ch tiáº¿p cáº­n cá»§a em lÃ  táº¡o táº­p tá»« Ä‘iá»ƒn riÃªng vá» TMDT báº±ng cÃ¡ch cÃ o dá»¯ liá»‡u tá»« tiki. Sau Ä‘Ã³ sá»­ dá»¥ng SymSpell Ä‘á»ƒ sá»­a tá»« áº¡.
Anh chá»‹ cÃ³ thá»ƒ cho em há»i thÃªm vá» cÃ¡c cÃ¡ch tiáº¿p cáº­n khÃ¡c hay cáº£i tiáº¿n cho bÃ i toÃ¡n vÃ  cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o thá»±c táº¿ Ä‘Æ°á»£c khÃ´ng áº¡.
Em xin cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang cÃ³ má»™t váº¥n Ä‘á» nhÆ° sau: Kiá»ƒm tra chÃ­nh táº£ má»™t cÃ¢u mÃ  ngÆ°á»i dÃ¹ng nháº­p vÃ o, sau Ä‘Ã³ Ä‘á» xuáº¥t ra cÃ¢u má»›i náº¿u nhÆ° cÃ¢u cá»§a ngÆ°á»i dÃ¹ng sai chÃ­nh táº£. NhÆ° google áº¥y áº¡. BÃ i toÃ¡n cá»§a em lÃ  á»Ÿ pháº¡m vi trong thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, vÃ­ dá»¥ nhÆ° ngÆ°á»i dÃ¹ng nháº­p sai tÃªn sáº£n pháº©m trÃªn thanh search thÃ¬ mÃ¬nh sáº½ Ä‘á» xuáº¥t sá»­a láº¡i tá»« Ä‘Ã³ cho há». Hiá»‡n táº¡i cÃ¡ch tiáº¿p cáº­n cá»§a em lÃ  táº¡o táº­p tá»« Ä‘iá»ƒn riÃªng vá» TMDT báº±ng cÃ¡ch cÃ o dá»¯ liá»‡u tá»« tiki. Sau Ä‘Ã³ sá»­ dá»¥ng SymSpell Ä‘á»ƒ sá»­a tá»« áº¡. Anh chá»‹ cÃ³ thá»ƒ cho em há»i thÃªm vá» cÃ¡c cÃ¡ch tiáº¿p cáº­n khÃ¡c hay cáº£i tiáº¿n cho bÃ i toÃ¡n vÃ  cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o thá»±c táº¿ Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"TÃŒM NGÆ¯á»œI CÃ™NG Há»ŒC ML CÆ  Báº¢N
MÃ¬nh cÃ³ kinh nghiá»‡m lÃ m NLP (há»“i chÆ°a cÃ³ deep learning) vÃ  code nhiá»u nÄƒm, giá» muá»‘n há»c cÆ¡ báº£n vá» ML vÃ  tá»± cÃ i Ä‘áº·t cÃ¡c giáº£i thuáº­t tá»« Ä‘áº§u. 

Tuá»™c  muá»‘n tÃ¬m ngÆ°á»i giá»i toÃ¡n + muá»‘n há»c code Ä‘á»ƒ Ä‘á»“ng hÃ nh vÃ¬  quen code rá»“i, cá»© nhÃ¬n tháº¥y cÃ´ng thá»©c toÃ¡n lÃ  buá»“n ngá»§, nÃªn cáº§n 01 Ä‘á»“ng Ä‘á»™i diá»…n giáº£i cÃ´ng thá»©c toÃ¡n báº±ng vÄƒn nÃ³i hoáº·c dáº¡ng giáº£i thuáº­t. BÃ¹ láº¡i thÃ¬ Tuá»™c cÃ³ ráº¥t nhiá»u kinh nghiá»‡m code, tá»« backend, front-end, mobile apps ... CÃ³ thá»ƒ trá»£ giÃºp báº¡n á»Ÿ máº£ng thá»±c chiáº¿n.

NgoÃ i ra Tuá»™c cÅ©ng muá»‘n tÃ¬m 01 báº¡n cÃ³ kinh nghiá»‡m láº­p trÃ¬nh há»‡ thá»‘ng (low-level) Ä‘á»ƒ tá»‘i Æ°u hÃ³a khi triá»ƒn khai á»©ng dá»¥ng. TrÆ°á»›c máº¯t lÃ  ná»n Web thÃ´ng qua web-assembly, Ä‘á»ƒ mÃ¬nh cÃ³ ngay nhá»¯ng app / demo trá»±c quan, sinh Ä‘á»™ng.

Chi tiáº¿t táº¡i https://github.com/telexyz/ml4coders","TÃŒM NGÆ¯á»œI CÃ™NG Há»ŒC ML CÆ  Báº¢N MÃ¬nh cÃ³ kinh nghiá»‡m lÃ m NLP (há»“i chÆ°a cÃ³ deep learning) vÃ  code nhiá»u nÄƒm, giá» muá»‘n há»c cÆ¡ báº£n vá» ML vÃ  tá»± cÃ i Ä‘áº·t cÃ¡c giáº£i thuáº­t tá»« Ä‘áº§u. Tuá»™c muá»‘n tÃ¬m ngÆ°á»i giá»i toÃ¡n + muá»‘n há»c code Ä‘á»ƒ Ä‘á»“ng hÃ nh vÃ¬ quen code rá»“i, cá»© nhÃ¬n tháº¥y cÃ´ng thá»©c toÃ¡n lÃ  buá»“n ngá»§, nÃªn cáº§n 01 Ä‘á»“ng Ä‘á»™i diá»…n giáº£i cÃ´ng thá»©c toÃ¡n báº±ng vÄƒn nÃ³i hoáº·c dáº¡ng giáº£i thuáº­t. BÃ¹ láº¡i thÃ¬ Tuá»™c cÃ³ ráº¥t nhiá»u kinh nghiá»‡m code, tá»« backend, front-end, mobile apps ... CÃ³ thá»ƒ trá»£ giÃºp báº¡n á»Ÿ máº£ng thá»±c chiáº¿n. NgoÃ i ra Tuá»™c cÅ©ng muá»‘n tÃ¬m 01 báº¡n cÃ³ kinh nghiá»‡m láº­p trÃ¬nh há»‡ thá»‘ng (low-level) Ä‘á»ƒ tá»‘i Æ°u hÃ³a khi triá»ƒn khai á»©ng dá»¥ng. TrÆ°á»›c máº¯t lÃ  ná»n Web thÃ´ng qua web-assembly, Ä‘á»ƒ mÃ¬nh cÃ³ ngay nhá»¯ng app / demo trá»±c quan, sinh Ä‘á»™ng. Chi tiáº¿t táº¡i https://github.com/telexyz/ml4coders",,,,,
cÃ¡c báº¡n lÆ°u link github tÃ i liá»‡u vá» ToÃ¡n há»c giÃºp hiá»ƒu sÃ¢u vá» machine learning,cÃ¡c báº¡n lÆ°u link github tÃ i liá»‡u vá» ToÃ¡n há»c giÃºp hiá»ƒu sÃ¢u vá» machine learning,,,,,
"#Sharing
Chia sáº» vá» quan Ä‘iá»ƒm ""Khá»Ÿi nghiá»‡p"" Ä‘áº¿n tá»« Chief AI Officer cá»§a FPT Software. Báº¡n nghÄ© khá»Ÿi nghiá»‡p vá» AI táº¡i Viá»‡t Nam khÃ³ hay dá»…?","Chia sáº» vá» quan Ä‘iá»ƒm ""Khá»Ÿi nghiá»‡p"" Ä‘áº¿n tá»« Chief AI Officer cá»§a FPT Software. Báº¡n nghÄ© khá»Ÿi nghiá»‡p vá» AI táº¡i Viá»‡t Nam khÃ³ hay dá»…?",#Sharing,,,,
"Má»i cÃ¡c báº¡n tham dá»± cuá»™c thi Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c backbones SOTA hiá»‡n nay.
[Cuá»™c thi thÃ¡ng 2-2022: Dog vs Cat classification]
I. Giá»›i thiá»‡u chung:
Hiá»‡n táº¡i cÃ³ ráº¥t nhiá»u cÃ¡c backbones khÃ¡c nhau Ä‘Æ°á»£c á»©ng dá»¥ng trong cÃ¡c tÃ¡c vá»¥ cá»§a thá»‹ giÃ¡c mÃ¡y tÃ­nh. Cuá»™c thi nÃ y nháº±m táº¡o Ä‘iá»u kiá»‡n Ä‘á»ƒ báº¡n á»©ng dá»¥ng nhá»¯ng backbone nÃ y vÃ o Ä‘iá»u kiá»‡n thá»±c tiá»…n Ä‘á»ƒ kiá»ƒm tra má»©c Ä‘á»™ hiá»‡u quáº£ cá»§a chÃºng nhÆ° tháº¿ nÃ o Ä‘á»‘i vá»›i dá»¯ liá»‡u kÃ­ch thÆ°á»›c nhá».
II. Má»¥c tiÃªu cá»§a cuá»™c thi: PhÃ¢n loáº¡i áº£nh chÃ³ vÃ  mÃ¨o trong Ä‘Ã³ táº­p huáº¥n luyá»‡n gá»“m 25.000 hÃ¬nh áº£nh cÃ³ nhÃ£n vÃ  táº­p kiá»ƒm tra gá»“m 8.000 hÃ¬nh áº£nh chÆ°a cÃ³ nhÃ£n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xáº¿p háº¡ng.
III. CÃ¡c gá»£i Ã½:
Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n theo Data Centric vÃ  Model Centric cho cuá»™c thi nÃ y:
1. Data Centric: Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n augmentation nhÆ° Rotation, Random Crop, Scale, Bright Contrast, Mixup, CutMix, Label Smoothing,â€¦
2. Model Centric:
2.1. Thay Ä‘á»•i kiáº¿n trÃºc: CÃ³ ráº¥t nhiá»u backbone cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong cuá»™c thi nÃ y:
- CÃ¡c kiáº¿n trÃºc CNN: EfficientNet, ConvNeXt, ResNet, ResNext, MobileNet, AlexNet, InceptionNet, DenseNet,â€¦
- CÃ¡c kiáº¿n trÃºc há» Transformer: ViT, DeiT, CoAtNet, SwinTransformer, MobileViT
- CÃ¡c kiáº¿n trÃºc khÃ¡c: MLP-Mixer, PatchConvNet, Neural Architecture Search,â€¦
LÆ°u Ã½ khÃ´ng pháº£i mÃ´ hÃ¬nh kÃ­ch thÆ°á»›c cÃ ng lá»›n cÃ ng tá»‘t bá»Ÿi thÆ°á»ng dá»… dáº«n tá»›i overfitting.
2.2. Thay Ä‘á»•i phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n:
- Sá»­ dá»¥ng Transfer Learning
- Sá»­ dá»¥ng Knowledge Distillation
- Thay Ä‘á»•i chiáº¿n lÆ°á»£c Optimization
- Thá»­ nghiá»‡m cÃ¡c Loss function khÃ¡c nhau
VÃ¬ dá»¯ liá»‡u cá»§a cuá»™c thi tÆ°Æ¡ng Ä‘á»‘i nhá» nÃªn táº¡o Ä‘iá»u kiá»‡n cho ai cÅ©ng cÃ³ thá»ƒ tham gia, ká»ƒ cáº£ khÃ´ng cÃ³ GPU. CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng google colab hoáº·c kaggle GPU Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.
IV. Thá»i háº¡n cuá»™c thi:
Cuá»™c thi Ä‘Æ°á»£c báº¯t Ä‘áº§u vÃ o 22:22 22.22 ngÃ y 22/2/2022. Káº¿t thÃºc vÃ o ngÃ y 22/3/2022
V. CÃ¡c thÃ´ng tin chi tiáº¿t cuá»™c thi xem táº¡i:
https://www.kaggle.com/c/dog-vs-cat-classification/overview
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng vá»›i cÃ¡c Ã½ tÆ°á»Ÿng táº¡i cuá»™c thi nÃ y.","Má»i cÃ¡c báº¡n tham dá»± cuá»™c thi Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c backbones SOTA hiá»‡n nay. [Cuá»™c thi thÃ¡ng 2-2022: Dog vs Cat classification] I. Giá»›i thiá»‡u chung: Hiá»‡n táº¡i cÃ³ ráº¥t nhiá»u cÃ¡c backbones khÃ¡c nhau Ä‘Æ°á»£c á»©ng dá»¥ng trong cÃ¡c tÃ¡c vá»¥ cá»§a thá»‹ giÃ¡c mÃ¡y tÃ­nh. Cuá»™c thi nÃ y nháº±m táº¡o Ä‘iá»u kiá»‡n Ä‘á»ƒ báº¡n á»©ng dá»¥ng nhá»¯ng backbone nÃ y vÃ o Ä‘iá»u kiá»‡n thá»±c tiá»…n Ä‘á»ƒ kiá»ƒm tra má»©c Ä‘á»™ hiá»‡u quáº£ cá»§a chÃºng nhÆ° tháº¿ nÃ o Ä‘á»‘i vá»›i dá»¯ liá»‡u kÃ­ch thÆ°á»›c nhá». II. Má»¥c tiÃªu cá»§a cuá»™c thi: PhÃ¢n loáº¡i áº£nh chÃ³ vÃ  mÃ¨o trong Ä‘Ã³ táº­p huáº¥n luyá»‡n gá»“m 25.000 hÃ¬nh áº£nh cÃ³ nhÃ£n vÃ  táº­p kiá»ƒm tra gá»“m 8.000 hÃ¬nh áº£nh chÆ°a cÃ³ nhÃ£n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xáº¿p háº¡ng. III. CÃ¡c gá»£i Ã½: Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n theo Data Centric vÃ  Model Centric cho cuá»™c thi nÃ y: 1. Data Centric: Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n augmentation nhÆ° Rotation, Random Crop, Scale, Bright Contrast, Mixup, CutMix, Label Smoothing,â€¦ 2. Model Centric: 2.1. Thay Ä‘á»•i kiáº¿n trÃºc: CÃ³ ráº¥t nhiá»u backbone cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong cuá»™c thi nÃ y: - CÃ¡c kiáº¿n trÃºc CNN: EfficientNet, ConvNeXt, ResNet, ResNext, MobileNet, AlexNet, InceptionNet, DenseNet,â€¦ - CÃ¡c kiáº¿n trÃºc há» Transformer: ViT, DeiT, CoAtNet, SwinTransformer, MobileViT - CÃ¡c kiáº¿n trÃºc khÃ¡c: MLP-Mixer, PatchConvNet, Neural Architecture Search,â€¦ LÆ°u Ã½ khÃ´ng pháº£i mÃ´ hÃ¬nh kÃ­ch thÆ°á»›c cÃ ng lá»›n cÃ ng tá»‘t bá»Ÿi thÆ°á»ng dá»… dáº«n tá»›i overfitting. 2.2. Thay Ä‘á»•i phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n: - Sá»­ dá»¥ng Transfer Learning - Sá»­ dá»¥ng Knowledge Distillation - Thay Ä‘á»•i chiáº¿n lÆ°á»£c Optimization - Thá»­ nghiá»‡m cÃ¡c Loss function khÃ¡c nhau VÃ¬ dá»¯ liá»‡u cá»§a cuá»™c thi tÆ°Æ¡ng Ä‘á»‘i nhá» nÃªn táº¡o Ä‘iá»u kiá»‡n cho ai cÅ©ng cÃ³ thá»ƒ tham gia, ká»ƒ cáº£ khÃ´ng cÃ³ GPU. CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng google colab hoáº·c kaggle GPU Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. IV. Thá»i háº¡n cuá»™c thi: Cuá»™c thi Ä‘Æ°á»£c báº¯t Ä‘áº§u vÃ o 22:22 22.22 ngÃ y 22/2/2022. Káº¿t thÃºc vÃ o ngÃ y 22/3/2022 V. CÃ¡c thÃ´ng tin chi tiáº¿t cuá»™c thi xem táº¡i: https://www.kaggle.com/c/dog-vs-cat-classification/overview ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng vá»›i cÃ¡c Ã½ tÆ°á»Ÿng táº¡i cuá»™c thi nÃ y.",,,,,
"Hi má»i ngÆ°á»i,
Äá»£t trÆ°á»›c mÃ¬nh tháº¥y báº¡n nÃ o Ä‘Ã³ up solution cá»§a cuá»™c thi RSNA-MICCAI Brain Tumor Radiogenomic Classification
https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/code
mÃ  mÃ¬nh tÃ¬m mÃ£i khÃ´ng tháº¥y . Ai cÃ²n giá»¯ link khÃ´ng, cho mÃ¬nh xin láº¡i vá»›i.
Cáº£m Æ¡n cáº£ nhÃ ","Hi má»i ngÆ°á»i, Äá»£t trÆ°á»›c mÃ¬nh tháº¥y báº¡n nÃ o Ä‘Ã³ up solution cá»§a cuá»™c thi RSNA-MICCAI Brain Tumor Radiogenomic Classification https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/code mÃ  mÃ¬nh tÃ¬m mÃ£i khÃ´ng tháº¥y . Ai cÃ²n giá»¯ link khÃ´ng, cho mÃ¬nh xin láº¡i vá»›i. Cáº£m Æ¡n cáº£ nhÃ ",,,,,
"Em chÃ o má»i ngÆ°á»i,Anh em trong group Ä‘Ã£ cÃ³ ai lÃ m viá»‡c vá»›i Clova AI chÆ°a áº¡ (Ä‘Ã£ tá»± thá»±c hiá»‡n training cho táº­p dá»¯ liá»‡u riÃªng), náº¿u Ä‘Ã£ lÃ m xin hÃ£y comment hoáº·c cho em thÃ´ng tin liÃªn láº¡c. Em xin phÃ©p Ä‘Æ°á»£c liÃªn há»‡ cÃ  phÃª cÃ  phÃ¡o Ä‘á»ƒ há»c há»i má»™t chÃºt áº¡!Hoáº·c náº¿u Ä‘Æ°á»ng xÃ¡ xa xÃ´i thÃ¬ em xin Ä‘Æ°á»£c inbox há»i cÅ©ng Ä‘Æ°á»£c áº¡.Em Ä‘Ã£ thá»±c hiá»‡n cháº¡y cÃ¡c demo vÃ  tháº¥y con Clova nÃ y ngon nháº¥t trong cÃ¡c con OCR mÃ  em Ä‘Ã£ thá»­, em cÅ©ng Ä‘ang gáº·p váº¥n Ä‘á» lÃ  khÃ´ng Ä‘á»c Ä‘Æ°á»£c sá»‘ tháº» ngÃ¢n hÃ ng cá»§a Viá»‡t Nam (dáº­p ná»•i). DÃ¹ng Yolo vÃ  tensorflow trainig thÃ¬ Ä‘á»‘i tÆ°á»£ng bÃ© quÃ¡ nÃªn khÃ´ng nháº­n Ä‘Æ°á»£c (loss khi training tensorflow luÃ´n luÃ´n > 1.5, chÃ¡n khÃ´ng buá»“n test)Link: https://github.com/clovaai/deep-text-recognition-benchmarkDemo: https://demo.ocr.clova.ai/Em cÃ¡m Æ¡n!Skype: tran.van.tho.tinb","Em chÃ o má»i ngÆ°á»i,Anh em trong group Ä‘Ã£ cÃ³ ai lÃ m viá»‡c vá»›i Clova AI chÆ°a áº¡ (Ä‘Ã£ tá»± thá»±c hiá»‡n training cho táº­p dá»¯ liá»‡u riÃªng), náº¿u Ä‘Ã£ lÃ m xin hÃ£y comment hoáº·c cho em thÃ´ng tin liÃªn láº¡c. Em xin phÃ©p Ä‘Æ°á»£c liÃªn há»‡ cÃ  phÃª cÃ  phÃ¡o Ä‘á»ƒ há»c há»i má»™t chÃºt áº¡!Hoáº·c náº¿u Ä‘Æ°á»ng xÃ¡ xa xÃ´i thÃ¬ em xin Ä‘Æ°á»£c inbox há»i cÅ©ng Ä‘Æ°á»£c áº¡.Em Ä‘Ã£ thá»±c hiá»‡n cháº¡y cÃ¡c demo vÃ  tháº¥y con Clova nÃ y ngon nháº¥t trong cÃ¡c con OCR mÃ  em Ä‘Ã£ thá»­, em cÅ©ng Ä‘ang gáº·p váº¥n Ä‘á» lÃ  khÃ´ng Ä‘á»c Ä‘Æ°á»£c sá»‘ tháº» ngÃ¢n hÃ ng cá»§a Viá»‡t Nam (dáº­p ná»•i). DÃ¹ng Yolo vÃ  tensorflow trainig thÃ¬ Ä‘á»‘i tÆ°á»£ng bÃ© quÃ¡ nÃªn khÃ´ng nháº­n Ä‘Æ°á»£c (loss khi training tensorflow luÃ´n luÃ´n > 1.5, chÃ¡n khÃ´ng buá»“n test)Link: https://github.com/clovaai/deep-text-recognition-benchmarkDemo: https://demo.ocr.clova.ai/Em cÃ¡m Æ¡n!Skype: tran.van.tho.tinb",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c trong Group ML CÆ¡ báº£n,
HÃ´m nay em Ä‘ang thá»­ lÃ m vá» mÃ³n nÃ y nÃªn em xin máº¡nh dáº¡n chia sáº» video clip vá» viá»‡c Ä‘iá»u khiá»ƒn game báº±ng Mediapipe Pose vÃ  Pyautogui.
MÃ³n nÃ y láº­p trÃ¬nh cho cÃ¡c bÃ© chÆ¡i Ä‘á»ƒ tÄƒng cÆ°á»ng váº­n Ä‘á»™ng khÃ¡ hay vÃ  há»¯u Ã­ch!
Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c. ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!","KÃ­nh chÃ o cÃ¡c bÃ¡c trong Group ML CÆ¡ báº£n, HÃ´m nay em Ä‘ang thá»­ lÃ m vá» mÃ³n nÃ y nÃªn em xin máº¡nh dáº¡n chia sáº» video clip vá» viá»‡c Ä‘iá»u khiá»ƒn game báº±ng Mediapipe Pose vÃ  Pyautogui. MÃ³n nÃ y láº­p trÃ¬nh cho cÃ¡c bÃ© chÆ¡i Ä‘á»ƒ tÄƒng cÆ°á»ng váº­n Ä‘á»™ng khÃ¡ hay vÃ  há»¯u Ã­ch! Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c. ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!",,,,,
"Hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» nháº­n diá»‡n tÃ© ngÃ£ á»Ÿ ngÆ°á»i, má»i ngÆ°á»i cÃ³ tÃ i liá»‡u tham kháº£o hoáº·c video hÆ°á»›ng dáº«n cho em xin vá»›i áº¡, Em cáº£m Æ¡n !","Hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» nháº­n diá»‡n tÃ© ngÃ£ á»Ÿ ngÆ°á»i, má»i ngÆ°á»i cÃ³ tÃ i liá»‡u tham kháº£o hoáº·c video hÆ°á»›ng dáº«n cho em xin vá»›i áº¡, Em cáº£m Æ¡n !",,,,,
"Hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» nháº­n diá»‡n tÃ© ngÃ£ á»Ÿ ngÆ°á»i, má»i ngÆ°á»i cÃ³ tÃ i liá»‡u tham kháº£o hoáº·c video hÆ°á»›ng dáº«n cho em xin vá»›i áº¡, Em cáº£m Æ¡n áº¡ !","Hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» nháº­n diá»‡n tÃ© ngÃ£ á»Ÿ ngÆ°á»i, má»i ngÆ°á»i cÃ³ tÃ i liá»‡u tham kháº£o hoáº·c video hÆ°á»›ng dáº«n cho em xin vá»›i áº¡, Em cáº£m Æ¡n áº¡ !",,,,,
"ChÃ o cáº£ nhÃ !
Chia sáº» vá»›i má»i ngÆ°á»i má»™t bÃ i viáº¿t Ä‘ang Ä‘Æ°á»£c khÃ¡ nhiá»u quan tÃ¢m trÃªn reddit vá» Machine Learning. MÃ¬nh máº¡o muá»™i dá»‹ch vÃ  share cho anh em. Mong má»i ngÆ°á»i sáº½ tháº¥y thÃº vá»‹ ğŸ˜ƒ",ChÃ o cáº£ nhÃ ! Chia sáº» vá»›i má»i ngÆ°á»i má»™t bÃ i viáº¿t Ä‘ang Ä‘Æ°á»£c khÃ¡ nhiá»u quan tÃ¢m trÃªn reddit vá» Machine Learning. MÃ¬nh máº¡o muá»™i dá»‹ch vÃ  share cho anh em. Mong má»i ngÆ°á»i sáº½ tháº¥y thÃº vá»‹,,,,,
"#há»iÄ‘Ã¡p
#reinforcementlearning
Em chÃ o cÃ¡c anh, chá»‹. Hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» reinforcement learning vÃ  tháº¯c máº¯c vá» cÃ¡ch Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ thuáº­t toÃ¡n nÃ y. VÃ­ dá»¥ bÃ i toÃ¡n tÃ¬m kho bÃ¡u : Thuáº­t toÃ¡n sáº½ tÃ¬m ra Ä‘Æ°á»ng Ä‘i Ä‘Æ°á»›c kho bÃ¡u nhanh nháº¥t vÃ  Ä‘i qua Ã­t báº«y nháº¥t, nhÆ°ng sá»‘ Ä‘iá»ƒm kho bÃ¡u, báº«y lÃ  do mÃ¬nh quy Ä‘á»‹nh. Váº­y thÃ¬ ta Ä‘Ã¡nh giÃ¡ thuáº­t toÃ¡n nÃ y tá»‘i Æ°u hay khÃ´ng dá»±a trÃªn tiÃªu chÃ­ nÃ o áº¡, cÃ¡ch chá»n há»‡ sá»‘ gamma vÃ  Ä‘iá»ƒm thÆ°á»Ÿng, mÃ´i trÆ°á»ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ phÃ¹ há»£p vá»›i bÃ i toÃ n, khi sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n khÃ¡c nhau Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n thÃ¬ lÃ m sao biáº¿t Ä‘Æ°á»£c thuáº­t toÃ¡n nÃ o tá»‘t hÆ¡n. Mong má»i ngÆ°á»i giÃºp em giáº£i Ä‘Ã¡p tháº¯c máº¯c. Em cáº£m Æ¡n nhiá»u
(áº£nh minh há»a)","Em chÃ o cÃ¡c anh, chá»‹. Hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» reinforcement learning vÃ  tháº¯c máº¯c vá» cÃ¡ch Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ thuáº­t toÃ¡n nÃ y. VÃ­ dá»¥ bÃ i toÃ¡n tÃ¬m kho bÃ¡u : Thuáº­t toÃ¡n sáº½ tÃ¬m ra Ä‘Æ°á»ng Ä‘i Ä‘Æ°á»›c kho bÃ¡u nhanh nháº¥t vÃ  Ä‘i qua Ã­t báº«y nháº¥t, nhÆ°ng sá»‘ Ä‘iá»ƒm kho bÃ¡u, báº«y lÃ  do mÃ¬nh quy Ä‘á»‹nh. Váº­y thÃ¬ ta Ä‘Ã¡nh giÃ¡ thuáº­t toÃ¡n nÃ y tá»‘i Æ°u hay khÃ´ng dá»±a trÃªn tiÃªu chÃ­ nÃ o áº¡, cÃ¡ch chá»n há»‡ sá»‘ gamma vÃ  Ä‘iá»ƒm thÆ°á»Ÿng, mÃ´i trÆ°á»ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ phÃ¹ há»£p vá»›i bÃ i toÃ n, khi sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n khÃ¡c nhau Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n thÃ¬ lÃ m sao biáº¿t Ä‘Æ°á»£c thuáº­t toÃ¡n nÃ o tá»‘t hÆ¡n. Mong má»i ngÆ°á»i giÃºp em giáº£i Ä‘Ã¡p tháº¯c máº¯c. Em cáº£m Æ¡n nhiá»u (áº£nh minh há»a)",#há»iÄ‘Ã¡p	#reinforcementlearning,,,,
"Xin chÃ o má»i ngÆ°á»i !
BÃªn mÃ¬nh Ä‘ang phÃ¡t triá»ƒn android mobile app nháº­n diá»‡n chá»¯ (7 segment) real-time qua camera. Ai Ä‘Ã£ lÃ m rá»“i cho mÃ¬nh há»i cÃ³ thÆ° viá»‡n nÃ o cÃ³ sáºµn khÃ´ng áº¡? Hay cÃ³ model nÃ o tÆ°Æ¡ng tá»± Ä‘á»ƒ train.",Xin chÃ o má»i ngÆ°á»i ! BÃªn mÃ¬nh Ä‘ang phÃ¡t triá»ƒn android mobile app nháº­n diá»‡n chá»¯ (7 segment) real-time qua camera. Ai Ä‘Ã£ lÃ m rá»“i cho mÃ¬nh há»i cÃ³ thÆ° viá»‡n nÃ o cÃ³ sáºµn khÃ´ng áº¡? Hay cÃ³ model nÃ o tÆ°Æ¡ng tá»± Ä‘á»ƒ train.,,,,,
"HÃ´m qua mÃ¬nh cÃ³ tháº£o luáº­n má»™t chÃºt vá» chá»§ Ä‘á» dá»‹ch thuáº­t ngá»¯ á»Ÿ post cá»§a anh KhÃ¡nh. CÃ³ nhiá»u thá»© mÃ¬nh nghÄ© nhÆ°ng khÃ´ng tiá»‡n chia sáº» trong pháº¡m vi cá»§a pháº§n bÃ¬nh luáº­n, nÃªn hÃ´m nay mÃ¬nh blog má»™t bÃ i vá» chá»§ Ä‘á» nÃ y.","HÃ´m qua mÃ¬nh cÃ³ tháº£o luáº­n má»™t chÃºt vá» chá»§ Ä‘á» dá»‹ch thuáº­t ngá»¯ á»Ÿ post cá»§a anh KhÃ¡nh. CÃ³ nhiá»u thá»© mÃ¬nh nghÄ© nhÆ°ng khÃ´ng tiá»‡n chia sáº» trong pháº¡m vi cá»§a pháº§n bÃ¬nh luáº­n, nÃªn hÃ´m nay mÃ¬nh blog má»™t bÃ i vá» chá»§ Ä‘á» nÃ y.",,,,,
"Xin chÃ o má»i ngÆ°á»i !
Em chÆ°a biáº¿t nhiá»u vá» code nÃªn cÃ³ tÃ¬m hiá»ƒu qua Teachable Machine cá»§a Google vÃ  cÅ©ng train Ä‘Æ°á»£c model.
Hiá»‡n em tháº¥y á»Ÿ pháº§n Tensorflow.js code snippets Javascript nÃ³ chá»‰ cÃ³ code máº«u dÃ¹ng Webcam Ä‘á»ƒ lÃ m nguá»“n Ä‘áº§u vÃ o hÃ¬nh áº£nh.
Em muá»‘n sá»­a láº¡i khi báº¥m Start thÃ¬ chá»n files tá»« mÃ¡y tÃ­nh thÃ¬ sá»­a lÃ m sao áº¡? Má»i ngÆ°á»i cÃ³ code máº«u hoáº·c sá»­a giÃºp em Ä‘oáº¡n áº¥y em gá»Ÿi Ã­t cf áº¡.
Em xin cáº£m Æ¡n !",Xin chÃ o má»i ngÆ°á»i ! Em chÆ°a biáº¿t nhiá»u vá» code nÃªn cÃ³ tÃ¬m hiá»ƒu qua Teachable Machine cá»§a Google vÃ  cÅ©ng train Ä‘Æ°á»£c model. Hiá»‡n em tháº¥y á»Ÿ pháº§n Tensorflow.js code snippets Javascript nÃ³ chá»‰ cÃ³ code máº«u dÃ¹ng Webcam Ä‘á»ƒ lÃ m nguá»“n Ä‘áº§u vÃ o hÃ¬nh áº£nh. Em muá»‘n sá»­a láº¡i khi báº¥m Start thÃ¬ chá»n files tá»« mÃ¡y tÃ­nh thÃ¬ sá»­a lÃ m sao áº¡? Má»i ngÆ°á»i cÃ³ code máº«u hoáº·c sá»­a giÃºp em Ä‘oáº¡n áº¥y em gá»Ÿi Ã­t cf áº¡. Em xin cáº£m Æ¡n !,,,,,
"CS W182 / 282A at UC Berkeley | Designing, Visualizing, and Understanding Deep Neural Networks
Design principles and best practices: design motifs that work well in particular domains, structure optimization and parameter optimization.
Visualizing deep networks. Exploring the training and use of deep networks with visualization tools.
Understanding deep networks. Methods with formal guarantees: generative and adversarial models, tensor factorization.
[Course Link]
https://youtu.be/ghOgcYuBMmw","CS W182 / 282A at UC Berkeley | Designing, Visualizing, and Understanding Deep Neural Networks Design principles and best practices: design motifs that work well in particular domains, structure optimization and parameter optimization. Visualizing deep networks. Exploring the training and use of deep networks with visualization tools. Understanding deep networks. Methods with formal guarantees: generative and adversarial models, tensor factorization. [Course Link] https://youtu.be/ghOgcYuBMmw",,,,,
"#AI_share
ChÃ o cáº£ nhÃ !
Share vá»›i má»i ngÆ°á»i library C++ Machine learning build tá»« scratch. Cá»¥ thá»ƒ hÆ¡n thÃ¬ thÆ° viá»‡n nÃ y gá»“m hÆ¡n 13k dÃ²ng code tráº£i dÃ i nhiá»u topic tá»« thá»‘ng kÃª, Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh, phÃ¢n tÃ­ch sá»‘ vÃ  táº¥t nhiÃªn, há»c mÃ¡y vÃ  deep learning.
Happy learning!
https://github.com/novak-99/MLPP","ChÃ o cáº£ nhÃ ! Share vá»›i má»i ngÆ°á»i library C++ Machine learning build tá»« scratch. Cá»¥ thá»ƒ hÆ¡n thÃ¬ thÆ° viá»‡n nÃ y gá»“m hÆ¡n 13k dÃ²ng code tráº£i dÃ i nhiá»u topic tá»« thá»‘ng kÃª, Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh, phÃ¢n tÃ­ch sá»‘ vÃ  táº¥t nhiÃªn, há»c mÃ¡y vÃ  deep learning. Happy learning! https://github.com/novak-99/MLPP",#AI_share,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2020 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2020 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» khÃ¡ nhiá»u vá» Graph Neural Network liÃªn quan tá»›i bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh. CÃ¢u há»i Ä‘áº·t ra ráº±ng liá»‡u GNNs cÃ³ thá»ƒ giáº£i quyáº¿t quyáº¿t bÃ i toÃ¡n nhÆ° object detection hay object verification hay khÃ´ng? TÃ¬nh cá», mÃ¬nh tháº¥y cÃ³ codebase nÃ y táº­p há»£p cÃ¡c chá»§ Ä‘á»ƒ liÃªn quan giá»¯a GNNs ~ object detection/verification táº¡i Ä‘Ã¢y chia sáº» khÃ¡ nhiá»u vá» Graph Neural Network liÃªn quan tá»›i bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh. CÃ¢u há»i Ä‘áº·t ra ráº±ng liá»‡u GNNs cÃ³ thá»ƒ giáº£i quyáº¿t quyáº¿t bÃ i toÃ¡n nhÆ° object detection hay object verification hay khÃ´ng? TÃ¬nh cá», mÃ¬nh tháº¥y cÃ³ codebase nÃ y táº­p há»£p cÃ¡c chá»§ Ä‘á»ƒ liÃªn quan giá»¯a GNNs ~ object detection/verification táº¡i Ä‘Ã¢y https://github.com/Thinklab-SJTU/ThinkMatch
CÆ¡ báº£n Ã½ tÆ°á»Ÿng hiá»‡n nay cho chá»§ Ä‘á» nÃ y lÃ  há» dÃ¹ng CNN Ä‘á»ƒ táº¡o input data, rá»“i Ä‘Æ°a vÃ o GNNs.
Ps. Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» má»™t sá»‘ bÃ i viáº¿t vá» GNN~ Object classification, Ã tÆ°á»Ÿng tiáº¿p cáº­n cá»§a mÃ¬nh cÃ³ khÃ¡c biá»‡t lÃ  chuyá»ƒn tháº³ng input data lÃ  dáº¡ng áº£nh thÃ nh Graph-structured data cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n bÃ i toÃ¡n Graph classification (qua GNN models)","Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» khÃ¡ nhiá»u vá» Graph Neural Network liÃªn quan tá»›i bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh. CÃ¢u há»i Ä‘áº·t ra ráº±ng liá»‡u GNNs cÃ³ thá»ƒ giáº£i quyáº¿t quyáº¿t bÃ i toÃ¡n nhÆ° object detection hay object verification hay khÃ´ng? TÃ¬nh cá», mÃ¬nh tháº¥y cÃ³ codebase nÃ y táº­p há»£p cÃ¡c chá»§ Ä‘á»ƒ liÃªn quan giá»¯a GNNs ~ object detection/verification táº¡i Ä‘Ã¢y chia sáº» khÃ¡ nhiá»u vá» Graph Neural Network liÃªn quan tá»›i bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh. CÃ¢u há»i Ä‘áº·t ra ráº±ng liá»‡u GNNs cÃ³ thá»ƒ giáº£i quyáº¿t quyáº¿t bÃ i toÃ¡n nhÆ° object detection hay object verification hay khÃ´ng? TÃ¬nh cá», mÃ¬nh tháº¥y cÃ³ codebase nÃ y táº­p há»£p cÃ¡c chá»§ Ä‘á»ƒ liÃªn quan giá»¯a GNNs ~ object detection/verification táº¡i Ä‘Ã¢y https://github.com/Thinklab-SJTU/ThinkMatch CÆ¡ báº£n Ã½ tÆ°á»Ÿng hiá»‡n nay cho chá»§ Ä‘á» nÃ y lÃ  há» dÃ¹ng CNN Ä‘á»ƒ táº¡o input data, rá»“i Ä‘Æ°a vÃ o GNNs. Ps. Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» má»™t sá»‘ bÃ i viáº¿t vá» GNN~ Object classification, Ã tÆ°á»Ÿng tiáº¿p cáº­n cá»§a mÃ¬nh cÃ³ khÃ¡c biá»‡t lÃ  chuyá»ƒn tháº³ng input data lÃ  dáº¡ng áº£nh thÃ nh Graph-structured data cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n bÃ i toÃ¡n Graph classification (qua GNN models)",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, chÃ o anh em, hÃ´m nay em Ä‘ang há»c pháº§n LSTM nÃªn em máº¡nh dáº¡n lÃ m video tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng Mediapipe Pose kÃ¨m vá»›i LSTM Model Ä‘á»ƒ nháº­n diá»‡n hÃ nh vi con ngÆ°á»i.
Hi vá»ng mang láº¡i nhá»¯ng kiáº¿n thá»©c bá»• Ã­ch cho anh em má»›i há»c áº¡.","KÃ­nh chÃ o cÃ¡c bÃ¡c, chÃ o anh em, hÃ´m nay em Ä‘ang há»c pháº§n LSTM nÃªn em máº¡nh dáº¡n lÃ m video tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng Mediapipe Pose kÃ¨m vá»›i LSTM Model Ä‘á»ƒ nháº­n diá»‡n hÃ nh vi con ngÆ°á»i. Hi vá»ng mang láº¡i nhá»¯ng kiáº¿n thá»©c bá»• Ã­ch cho anh em má»›i há»c áº¡.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡,
Má»i ngÆ°á»i cho e há»i má»™t chÃºt lÃ  Ä‘á»‘i vá»›i cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng chuá»—i dÃ¹ng deep learning ( VÃ­ dá»¥ bÃ i toÃ¡n nháº­n dáº¡ng ngÆ°á»i Ä‘ang thá»±c hiá»‡n hÃ nh Ä‘á»™ng , thÃ¬ Ä‘áº§u vÃ o lÃ  1 chuá»—i hÃ nh Ä‘Ã´ng ), thÃ¬ mÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº§u vÃ o nhÆ° tháº¿ nÃ o áº¡. VÃ¬ yÃªu cáº§u Ä‘áº§u vÃ o cá»§a máº¡ng thÃ¬ táº¥t cáº£ cÃ¡c chuá»—i pháº£i cÃ¹ng input, trong khi Ä‘Ã³, má»—i hÃ nh Ä‘á»™ng cÃ³ thá»ƒ diá»…n ra nhanh cháº­m khÃ¡c nhau.
VÃ¬ váº­y, theo má»i ngÆ°á»i thÃ¬ cÃ¡ch xá»­ lÃ½ Ä‘áº§u vÃ o nhÆ° tháº¿ nÃ o thÃ¬ sáº½ hiá»‡u quáº£ nháº¥t áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","Em chÃ o má»i ngÆ°á»i áº¡, Má»i ngÆ°á»i cho e há»i má»™t chÃºt lÃ  Ä‘á»‘i vá»›i cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng chuá»—i dÃ¹ng deep learning ( VÃ­ dá»¥ bÃ i toÃ¡n nháº­n dáº¡ng ngÆ°á»i Ä‘ang thá»±c hiá»‡n hÃ nh Ä‘á»™ng , thÃ¬ Ä‘áº§u vÃ o lÃ  1 chuá»—i hÃ nh Ä‘Ã´ng ), thÃ¬ mÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº§u vÃ o nhÆ° tháº¿ nÃ o áº¡. VÃ¬ yÃªu cáº§u Ä‘áº§u vÃ o cá»§a máº¡ng thÃ¬ táº¥t cáº£ cÃ¡c chuá»—i pháº£i cÃ¹ng input, trong khi Ä‘Ã³, má»—i hÃ nh Ä‘á»™ng cÃ³ thá»ƒ diá»…n ra nhanh cháº­m khÃ¡c nhau. VÃ¬ váº­y, theo má»i ngÆ°á»i thÃ¬ cÃ¡ch xá»­ lÃ½ Ä‘áº§u vÃ o nhÆ° tháº¿ nÃ o thÃ¬ sáº½ hiá»‡u quáº£ nháº¥t áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"Em xin chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i toÃ¡n Speaker Diarization (phÃ¢n cá»±c ngÆ°á»i nÃ³i trong má»™t Ä‘oáº¡n audio) vá»›i tiáº¿ng Viá»‡t. Vá» mÃ´ hÃ¬nh thÃ¬ qua tÃ¬m hiá»ƒu em Ä‘ang thá»­ theo hai hÆ°á»›ng lÃ  pyannote.audio vÃ  uis-rnn cá»§a Google. Cáº£ 2 mÃ´ hÃ¬nh Ä‘á»u cÃ³ pretrained cho tiáº¿ng Anh nhÆ°ng khi em thá»­ nghiá»‡m cho tiáº¿ng Viá»‡t thÃ¬ láº¡i khÃ´ng tá»‘t. CÃ²n dá»¯ liá»‡u cho tiáº¿ng Viá»‡t thÃ¬ em Ä‘Ã£ tÃ¬m ráº¥t lÃ¢u nhÆ°ng váº«n khÃ´ng tháº¥y.
Má»i ngÆ°á»i cho em há»i lÃ  hiá»‡n táº¡i ai Ä‘Ã£ cÃ³ bá»™ dá»¯ liá»‡u cho bÃ i toÃ¡n nÃ y vá»›i giá»ng nÃ³i tiáº¿ng Viá»‡t chÆ°a áº¡?
VÃ  náº¿u trong nhÃ³m Ä‘Ã£ cÃ³ ai tá»«ng lÃ m bÃ i toÃ¡n nÃ y rá»“i thÃ¬ cÃ³ thá»ƒ cho em xin lá»i khuyÃªn vá» cÃ¡ch chá»n mÃ´ hÃ¬nh cÅ©ng nhÆ° huáº¥n luyá»‡n Ä‘Æ°á»£c khÃ´ng áº¡ ? Em cáº£m Æ¡n",Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i toÃ¡n Speaker Diarization (phÃ¢n cá»±c ngÆ°á»i nÃ³i trong má»™t Ä‘oáº¡n audio) vá»›i tiáº¿ng Viá»‡t. Vá» mÃ´ hÃ¬nh thÃ¬ qua tÃ¬m hiá»ƒu em Ä‘ang thá»­ theo hai hÆ°á»›ng lÃ  pyannote.audio vÃ  uis-rnn cá»§a Google. Cáº£ 2 mÃ´ hÃ¬nh Ä‘á»u cÃ³ pretrained cho tiáº¿ng Anh nhÆ°ng khi em thá»­ nghiá»‡m cho tiáº¿ng Viá»‡t thÃ¬ láº¡i khÃ´ng tá»‘t. CÃ²n dá»¯ liá»‡u cho tiáº¿ng Viá»‡t thÃ¬ em Ä‘Ã£ tÃ¬m ráº¥t lÃ¢u nhÆ°ng váº«n khÃ´ng tháº¥y. Má»i ngÆ°á»i cho em há»i lÃ  hiá»‡n táº¡i ai Ä‘Ã£ cÃ³ bá»™ dá»¯ liá»‡u cho bÃ i toÃ¡n nÃ y vá»›i giá»ng nÃ³i tiáº¿ng Viá»‡t chÆ°a áº¡? VÃ  náº¿u trong nhÃ³m Ä‘Ã£ cÃ³ ai tá»«ng lÃ m bÃ i toÃ¡n nÃ y rá»“i thÃ¬ cÃ³ thá»ƒ cho em xin lá»i khuyÃªn vá» cÃ¡ch chá»n mÃ´ hÃ¬nh cÅ©ng nhÆ° huáº¥n luyá»‡n Ä‘Æ°á»£c khÃ´ng áº¡ ? Em cáº£m Æ¡n,,,,,
"Anh em save Github kho tÃ ng cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn báº±ng python, java, C vÃ  ráº¥t nhiá»u ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c","Anh em save Github kho tÃ ng cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn báº±ng python, java, C vÃ  ráº¥t nhiá»u ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c",,,,,
"NhÆ° váº­y lÃ  cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c chia sáº» cÃ´ng khai. ChÃºng tÃ´i sáº½ tÃ¬m kiáº¿m chá»§ nhÃ¢n cá»§a file nÃ y vÃ  cÃ³ giáº£i phÃ¡p phÃ¡p lÃ½ phÃ¹ há»£p.
CÃ¡c báº¡n cÃ³ thá»ƒ á»§ng há»™ sÃ¡ch báº£n quyá»n táº¡i https://handson-ml.mlbvn.org/.",NhÆ° váº­y lÃ  cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c chia sáº» cÃ´ng khai. ChÃºng tÃ´i sáº½ tÃ¬m kiáº¿m chá»§ nhÃ¢n cá»§a file nÃ y vÃ  cÃ³ giáº£i phÃ¡p phÃ¡p lÃ½ phÃ¹ há»£p. CÃ¡c báº¡n cÃ³ thá»ƒ á»§ng há»™ sÃ¡ch báº£n quyá»n táº¡i https://handson-ml.mlbvn.org/.,,,,,
"em chÃ o anh chá»‹ áº¡, lá»i Ä‘áº§u tiÃªn em xin chÃºc anh chá»‹ vÃ  gia Ä‘Ã¬nh nÄƒm má»›i sá»©c khá»e, may máº¯n vÃ  thÃ nh cÃ´ng.
Hiá»‡n em má»›i báº¯t Ä‘áº§u há»c táº­p máº£ng data/ai (gÃ  má»), nÃªn cÃ³ 1 vÃ i cÃ¢u há»i mong anh chá»‹ tráº£ lá»i vÃ  Ä‘á»‹nh hÆ°á»›ng giÃºp:
1. Em Ä‘ang phÃ¢n vÃ¢n giá»¯a Data Sience vÃ  AI Engineer, anh cÃ³ thá»ƒ cho em biáº¿t sá»± khÃ¡c biá»‡t giá»¯a 2 ngÃ nh nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? Em Ä‘áº·c biá»‡t yÃªu thÃ­ch vá» thuáº­t toÃ¡n, model vÃ  cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» mÃ  cáº£ 2 Ä‘á»u cÃ³
2. Dá»±a theo kinh nghiá»‡m vÃ  hiá»ƒu biáº¿t cá»§a anh chá»‹, anh chá»‹ cÃ³ thá»ƒ chá»‰ Ä‘iá»ƒm cho em 1 vÃ i cÃ´ng ty phÃ¹ há»£p Ä‘Æ°á»£c khÃ´ng áº¡? Em chÃº trá»ng hÆ¡n pháº§n phÃ¡t triá»ƒn lÃ¢u dÃ i, há»c Ä‘Æ°á»£c gÃ¬, Ä‘Æ°á»ng phÃ¡t triá»ƒn sau nÃ y, Ä‘áº·c biá»‡t em cáº§n mentor Ä‘á»ƒ chá»‰ Ä‘Æ°á»ng
3. Em cáº§n nhá»¯ng gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c ngÆ°á»¡ng yÃªu cáº§u cá»§a cÃ¡c cÃ´ng ty, Ã­t nháº¥t lÃ  vá»‹ trÃ­ fresher? Hiá»‡n táº¡i em Ä‘ang theo há»c khÃ³a AI Engineer cá»§a IBM (Ä‘Ã£ Ä‘Æ°á»£c 50%), sau Ä‘Ã³ em dá»± Ä‘á»‹nh há»c thÃªm khÃ³a Data Sience cá»§a IBM vÃ  khÃ³a chuyÃªn sÃ¢u vá» toÃ¡n hÆ¡n cá»§a Stanford","em chÃ o anh chá»‹ áº¡, lá»i Ä‘áº§u tiÃªn em xin chÃºc anh chá»‹ vÃ  gia Ä‘Ã¬nh nÄƒm má»›i sá»©c khá»e, may máº¯n vÃ  thÃ nh cÃ´ng. Hiá»‡n em má»›i báº¯t Ä‘áº§u há»c táº­p máº£ng data/ai (gÃ  má»), nÃªn cÃ³ 1 vÃ i cÃ¢u há»i mong anh chá»‹ tráº£ lá»i vÃ  Ä‘á»‹nh hÆ°á»›ng giÃºp: 1. Em Ä‘ang phÃ¢n vÃ¢n giá»¯a Data Sience vÃ  AI Engineer, anh cÃ³ thá»ƒ cho em biáº¿t sá»± khÃ¡c biá»‡t giá»¯a 2 ngÃ nh nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? Em Ä‘áº·c biá»‡t yÃªu thÃ­ch vá» thuáº­t toÃ¡n, model vÃ  cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» mÃ  cáº£ 2 Ä‘á»u cÃ³ 2. Dá»±a theo kinh nghiá»‡m vÃ  hiá»ƒu biáº¿t cá»§a anh chá»‹, anh chá»‹ cÃ³ thá»ƒ chá»‰ Ä‘iá»ƒm cho em 1 vÃ i cÃ´ng ty phÃ¹ há»£p Ä‘Æ°á»£c khÃ´ng áº¡? Em chÃº trá»ng hÆ¡n pháº§n phÃ¡t triá»ƒn lÃ¢u dÃ i, há»c Ä‘Æ°á»£c gÃ¬, Ä‘Æ°á»ng phÃ¡t triá»ƒn sau nÃ y, Ä‘áº·c biá»‡t em cáº§n mentor Ä‘á»ƒ chá»‰ Ä‘Æ°á»ng 3. Em cáº§n nhá»¯ng gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c ngÆ°á»¡ng yÃªu cáº§u cá»§a cÃ¡c cÃ´ng ty, Ã­t nháº¥t lÃ  vá»‹ trÃ­ fresher? Hiá»‡n táº¡i em Ä‘ang theo há»c khÃ³a AI Engineer cá»§a IBM (Ä‘Ã£ Ä‘Æ°á»£c 50%), sau Ä‘Ã³ em dá»± Ä‘á»‹nh há»c thÃªm khÃ³a Data Sience cá»§a IBM vÃ  khÃ³a chuyÃªn sÃ¢u vá» toÃ¡n hÆ¡n cá»§a Stanford",,,,,
"Em chÃ o má»i ngÆ°á»i, cho em há»i trong mÃ´ hÃ¬nh Transformers gá»‘c thÃ¬ pháº§n Multihead-attention Ä‘Æ°á»£c tÃ­nh toÃ¡n nhÆ° tháº¿ nÃ o váº­y áº¡. em Ä‘Ã£ tham kháº£o má»™t sá»‘ nguá»“n vÃ  hiá»ƒu nhÆ° sau nhÆ°ng chÆ°a biáº¿t Ä‘Ãºng hay sai mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡:
CÃ¡ch hiá»ƒu 1:
BÆ°á»›c 1: Cho input embeeding (5x512) Ä‘i qua 1 Linear vÃ  thu Ä‘Æ°á»£c 3 ma tráº­n Q, K, V (512 x 512)
BÆ°á»›c 2: Chia nhá» Q, K, V thÃ nh 8 pháº§n (theo cá»™t) rá»“i tÃ­nh self-attention cho tá»«ng pháº§n Ä‘Ã³ vÃ  cuá»‘i cÃ¹ng concat chÃºng táº¡o Ä‘Æ°á»£c má»™t ma tráº­n Z
BÆ°á»›c 3: Cho Z qua Linear Ä‘á»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ cuá»‘i cÃ¹ng (5x512)
CÃ¡ch hiá»ƒu 2:
BÆ°á»›c 1: Cho input embeeding (5x512) Ä‘i qua 1 Linear vÃ  thu Ä‘Æ°á»£c 3 ma tráº­n Q, K, V (512 x 512)
BÆ°á»›c 2: Tiáº¿p tá»¥c cho Q, K, V qua 8 Linear tá»©c má»—i láº§n sáº½ thu Ä‘Æ°á»£c má»™t cáº·p 3 ma tráº­n vÃ  tÃ­nh self-attention cho 3 cáº·p ma tráº­n nÃ y vÃ  output sáº½ ra Ä‘Æ°á»£c 8 cáº·p 512 x 64, rá»“i cuá»‘i cÃ¹ng concate chÃºng Ä‘á»ƒ Ä‘Æ°á»£c Z (512x512)
BÆ°á»›c 3: Cho Z qua Linear Ä‘á»ƒ thu Ä‘Æ°á»£c output lÃ  (5x512)
Ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡, em xin chÃ¢n thÃ nh cáº£m Æ¡n!","Em chÃ o má»i ngÆ°á»i, cho em há»i trong mÃ´ hÃ¬nh Transformers gá»‘c thÃ¬ pháº§n Multihead-attention Ä‘Æ°á»£c tÃ­nh toÃ¡n nhÆ° tháº¿ nÃ o váº­y áº¡. em Ä‘Ã£ tham kháº£o má»™t sá»‘ nguá»“n vÃ  hiá»ƒu nhÆ° sau nhÆ°ng chÆ°a biáº¿t Ä‘Ãºng hay sai mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡: CÃ¡ch hiá»ƒu 1: BÆ°á»›c 1: Cho input embeeding (5x512) Ä‘i qua 1 Linear vÃ  thu Ä‘Æ°á»£c 3 ma tráº­n Q, K, V (512 x 512) BÆ°á»›c 2: Chia nhá» Q, K, V thÃ nh 8 pháº§n (theo cá»™t) rá»“i tÃ­nh self-attention cho tá»«ng pháº§n Ä‘Ã³ vÃ  cuá»‘i cÃ¹ng concat chÃºng táº¡o Ä‘Æ°á»£c má»™t ma tráº­n Z BÆ°á»›c 3: Cho Z qua Linear Ä‘á»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ cuá»‘i cÃ¹ng (5x512) CÃ¡ch hiá»ƒu 2: BÆ°á»›c 1: Cho input embeeding (5x512) Ä‘i qua 1 Linear vÃ  thu Ä‘Æ°á»£c 3 ma tráº­n Q, K, V (512 x 512) BÆ°á»›c 2: Tiáº¿p tá»¥c cho Q, K, V qua 8 Linear tá»©c má»—i láº§n sáº½ thu Ä‘Æ°á»£c má»™t cáº·p 3 ma tráº­n vÃ  tÃ­nh self-attention cho 3 cáº·p ma tráº­n nÃ y vÃ  output sáº½ ra Ä‘Æ°á»£c 8 cáº·p 512 x 64, rá»“i cuá»‘i cÃ¹ng concate chÃºng Ä‘á»ƒ Ä‘Æ°á»£c Z (512x512) BÆ°á»›c 3: Cho Z qua Linear Ä‘á»ƒ thu Ä‘Æ°á»£c output lÃ  (5x512) Ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡, em xin chÃ¢n thÃ nh cáº£m Æ¡n!",,,,,
"[GauGAN2 - Nvidia Canvas]
Báº¡n Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng váº½ hoáº·c Ä‘Æ¡n giáº£n lÃ  nhá»¯ng khá»‘i hÃ¬nh nhÆ°ng láº¡i muá»‘n cÃ³ má»™t bá»©c tranh hoÃ n chá»‰nh? pháº§n má»m Nvidia Canvas chÃ­nh lÃ  lá»±a chá»n cho báº¡n.
Gáº§n Ä‘Ã¢y Nvidia Canvas cho ra máº¯t máº¡ng GauGAN2 vá»›i áº£nh sinh ra tÄƒng 4 láº§n Ä‘á»™ phÃ¢n giáº£i so vá»›i cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã¢y. Canvas giÃºp báº¡n biáº¿n nhá»¯ng nÃ©t váº½ vá» nÆ°á»›c, cá», tuyáº¿t, nÃºi,... Ä‘Æ°á»£c hÃ²a quyá»‡n vá»›i nhau thÃ nh áº£nh phong cáº£nh tá»± nhiÃªn. HÆ¡n tháº¿ ná»¯a thÃ¬ pháº§n má»m Canvas Ä‘ang miá»…n phÃ­ nÃªn má»i ngÆ°á»i cÃ³ thá»ƒ táº£i vá» dÃ¹ng thá»­.
Pháº§n má»m Canvas: https://www.nvidia.com/en-us/studio/canvas/
Youtube: https://www.youtube.com/watch?v=wKztRskmsig
Post: https://blogs.nvidia.com/blog/2022/01/04/studio-canvas-update-gaugan2-ces/","[GauGAN2 - Nvidia Canvas] Báº¡n Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng váº½ hoáº·c Ä‘Æ¡n giáº£n lÃ  nhá»¯ng khá»‘i hÃ¬nh nhÆ°ng láº¡i muá»‘n cÃ³ má»™t bá»©c tranh hoÃ n chá»‰nh? pháº§n má»m Nvidia Canvas chÃ­nh lÃ  lá»±a chá»n cho báº¡n. Gáº§n Ä‘Ã¢y Nvidia Canvas cho ra máº¯t máº¡ng GauGAN2 vá»›i áº£nh sinh ra tÄƒng 4 láº§n Ä‘á»™ phÃ¢n giáº£i so vá»›i cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã¢y. Canvas giÃºp báº¡n biáº¿n nhá»¯ng nÃ©t váº½ vá» nÆ°á»›c, cá», tuyáº¿t, nÃºi,... Ä‘Æ°á»£c hÃ²a quyá»‡n vá»›i nhau thÃ nh áº£nh phong cáº£nh tá»± nhiÃªn. HÆ¡n tháº¿ ná»¯a thÃ¬ pháº§n má»m Canvas Ä‘ang miá»…n phÃ­ nÃªn má»i ngÆ°á»i cÃ³ thá»ƒ táº£i vá» dÃ¹ng thá»­. Pháº§n má»m Canvas: https://www.nvidia.com/en-us/studio/canvas/ Youtube: https://www.youtube.com/watch?v=wKztRskmsig Post: https://blogs.nvidia.com/blog/2022/01/04/studio-canvas-update-gaugan2-ces/",,,,,
"xin chÃ o má»i ngÆ°á»i, mÃ¬nh muá»‘n há»i má»i ngÆ°á»i má»™t sá»‘ sÃ¡ch hoáº·c nguá»“n há»c vÃ  thá»±c hÃ nh vá» OCR hay, mong má»i ngÆ°á»i chá»‰ giÃºp áº¡, tks má»i ngÆ°á»i","xin chÃ o má»i ngÆ°á»i, mÃ¬nh muá»‘n há»i má»i ngÆ°á»i má»™t sá»‘ sÃ¡ch hoáº·c nguá»“n há»c vÃ  thá»±c hÃ nh vá» OCR hay, mong má»i ngÆ°á»i chá»‰ giÃºp áº¡, tks má»i ngÆ°á»i",,,,,
"MÃ¬nh má»›i há»c ML nÃªn cÃ²n it kinh nghiá»‡m, mong cÃ¡c báº¡n chá»‰ giÃºp. MÃ¬nh cÃ³ 1 model regresssion ( 50% train, 25% test va 25% validation. ) Loss va val_loss ra nhÆ° váº­y vÃ  RMSE gáº§n ~ 0.01. NhÆ° váº­y lÃ  sao nhá»‰. Cáº£m Æ¡n cÃ¡c báº¡n","MÃ¬nh má»›i há»c ML nÃªn cÃ²n it kinh nghiá»‡m, mong cÃ¡c báº¡n chá»‰ giÃºp. MÃ¬nh cÃ³ 1 model regresssion ( 50% train, 25% test va 25% validation. ) Loss va val_loss ra nhÆ° váº­y vÃ  RMSE gáº§n ~ 0.01. NhÆ° váº­y lÃ  sao nhá»‰. Cáº£m Æ¡n cÃ¡c báº¡n",,,,,
"TÃ¬m giÃ¡ trá»‹ mong Ä‘á»£i (expected value) vÃ  sai sá»‘ (variance)
Hiá»‡n táº¡i, mÃ¬nh cÃ³ T = {t1, t2, t3, t4, t5} = {10.5, 10.6, 17.2, 21.0, 26.1}. MÃ¬nh muá»‘n tÃ¬m expected value <T> vÃ  variance cho Ä‘áº¡i lÆ°á»£ng T.
VÃ¬ mÃ¬nh amature vá» Machine Learning nÃªn ráº¥t mong cÃ¡c báº¡n hÆ°á»¡ng dáº«n giÃºp mÃ¬nh. MÃ¬nh cÃ³ má»™t vÃ i tháº¯c máº¯c sau:
1/ GiÃ¡ trá»‹ trung bÃ¬nh vÃ  sai sá»‘ tÃ­nh theo <T> = 1/5 * sum(ti) vÃ  varT = sqrt(dt1^2+dt2^2 +.... dt5^2) nÃ³ khÃ¡c tháº¿ nÃ o so vá»›i giÃ¡ trá»‹ tÃ­nh theo Mote-Carlo approximation?
2/ Náº¿u mÃ¬nh tÃ­nh theo Monte-Carlo approximation thÃ¬ mÃ¬nh cÃ³ thá»ƒ tÃ­nh nhÆ° tháº¿ nÃ o áº¡?
3/ Náº¿u mÃ¬nh giáº£ sá»­ T cÃ³ giÃ¡ trá»‹ trong vÃ¹ng T = [tmin, tmax] = [10.5, 26.1], thÃ¬ mÃ¬nh cÃ³ thá»ƒ tÃ­nh giÃ¡ trá»‹ expected vÃ  var theo Gaussian distribution pháº£i khÃ´ng áº¡?
MÃ¬nh ráº¥t mong sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c báº¡n. MÃ¬nh cáº£m Æ¡n cÃ¡c báº¡n.
ChÃºc cÃ¡c báº¡n sang nÄƒm má»›i nhiá»u sá»©c khá»e, tÃ i lá»™c, may máº¯n vÃ  bÃ¬nh an nhÃ©!","TÃ¬m giÃ¡ trá»‹ mong Ä‘á»£i (expected value) vÃ  sai sá»‘ (variance) Hiá»‡n táº¡i, mÃ¬nh cÃ³ T = {t1, t2, t3, t4, t5} = {10.5, 10.6, 17.2, 21.0, 26.1}. MÃ¬nh muá»‘n tÃ¬m expected value <T> vÃ  variance cho Ä‘áº¡i lÆ°á»£ng T. VÃ¬ mÃ¬nh amature vá» Machine Learning nÃªn ráº¥t mong cÃ¡c báº¡n hÆ°á»¡ng dáº«n giÃºp mÃ¬nh. MÃ¬nh cÃ³ má»™t vÃ i tháº¯c máº¯c sau: 1/ GiÃ¡ trá»‹ trung bÃ¬nh vÃ  sai sá»‘ tÃ­nh theo <T> = 1/5 * sum(ti) vÃ  varT = sqrt(dt1^2+dt2^2 +.... dt5^2) nÃ³ khÃ¡c tháº¿ nÃ o so vá»›i giÃ¡ trá»‹ tÃ­nh theo Mote-Carlo approximation? 2/ Náº¿u mÃ¬nh tÃ­nh theo Monte-Carlo approximation thÃ¬ mÃ¬nh cÃ³ thá»ƒ tÃ­nh nhÆ° tháº¿ nÃ o áº¡? 3/ Náº¿u mÃ¬nh giáº£ sá»­ T cÃ³ giÃ¡ trá»‹ trong vÃ¹ng T = [tmin, tmax] = [10.5, 26.1], thÃ¬ mÃ¬nh cÃ³ thá»ƒ tÃ­nh giÃ¡ trá»‹ expected vÃ  var theo Gaussian distribution pháº£i khÃ´ng áº¡? MÃ¬nh ráº¥t mong sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c báº¡n. MÃ¬nh cáº£m Æ¡n cÃ¡c báº¡n. ChÃºc cÃ¡c báº¡n sang nÄƒm má»›i nhiá»u sá»©c khá»e, tÃ i lá»™c, may máº¯n vÃ  bÃ¬nh an nhÃ©!",,,,,
"Khai bÃºt Ä‘áº§u XuÃ¢n vá»›i bÃ i giá»›i thiá»‡u (cá»§a Chris Hughes) vá» thÆ° viá»‡n TIMM (cho cÃ¡c báº¡n lÃ m computer vision báº±ng PyTorch) vá»›i >16k sao. Theo quan Ä‘iá»ƒm cá»§a mÃ¬nh TIMM lÃ  thÆ° viá»‡n Máº NH NHáº¤T trong lÄ©nh vá»±c computer vision, cÃ³ ngÆ°á»i cÃ²n so sÃ¡nh nÃ³ lÃ  HuggingFace cá»§a CV.
NÄƒm má»›i chÃºc cÃ¡c báº¡n gáº·t hÃ¡i Ä‘Æ°á»£c nhiá»u thÃ nh cÃ´ng trong cÃ´ng viá»‡c.","Khai bÃºt Ä‘áº§u XuÃ¢n vá»›i bÃ i giá»›i thiá»‡u (cá»§a Chris Hughes) vá» thÆ° viá»‡n TIMM (cho cÃ¡c báº¡n lÃ m computer vision báº±ng PyTorch) vá»›i >16k sao. Theo quan Ä‘iá»ƒm cá»§a mÃ¬nh TIMM lÃ  thÆ° viá»‡n Máº NH NHáº¤T trong lÄ©nh vá»±c computer vision, cÃ³ ngÆ°á»i cÃ²n so sÃ¡nh nÃ³ lÃ  HuggingFace cá»§a CV. NÄƒm má»›i chÃºc cÃ¡c báº¡n gáº·t hÃ¡i Ä‘Æ°á»£c nhiá»u thÃ nh cÃ´ng trong cÃ´ng viá»‡c.",,,,,
"ChÃºc má»«ng nÄƒm má»›i ACE MLCB nhÃ©. ChÃºc Loss cá»§a ACE ko nhÆ° trong hÃ¬nh nhÃ© :)).
PS. WANDB ""hiá»ƒm ghá»›m"", tháº¥y trÆ°á»›c Ä‘Æ°á»£c ""tÆ°Æ¡ng lai"" vÃ  Ä‘áº·t cÃ¡i tÃªn exp lÃ  ""tough-universe"" há»£p v~ (LoL).","ChÃºc má»«ng nÄƒm má»›i ACE MLCB nhÃ©. ChÃºc Loss cá»§a ACE ko nhÆ° trong hÃ¬nh nhÃ© :)). PS. WANDB ""hiá»ƒm ghá»›m"", tháº¥y trÆ°á»›c Ä‘Æ°á»£c ""tÆ°Æ¡ng lai"" vÃ  Ä‘áº·t cÃ¡i tÃªn exp lÃ  ""tough-universe"" há»£p v~ (LoL).",,,,,
"#chiase
NhÃ¢n dá»‹p nÄƒm má»›i mÃ¬nh xin gá»­i lá»i chÃºc tá»›i toÃ n thá»ƒ má»i ngÆ°á»i trong nhÃ³m má»i Ä‘iá»u tá»‘t Ä‘áº¹p nháº¥t.
MÃ¬nh má»›i viáº¿t 1 bÃ i vá» chá»§ Ä‘á» crawl dá»¯ liá»‡u cÃ¡c trang web vá»›i ná»™i dung Ä‘Æ°á»£c táº¡o bá»Ÿi javascript sá»­ dá»¥ng thÆ° viá»‡n chromedp cá»§a golang, Ä‘Ã¢y lÃ  1 thÆ° viá»‡n cÃ²n má»›i Ä‘á»‘i vá»›i má»i ngÆ°á»i. má»¥c tiÃªu lÃ  vÆ°á»£t qua bÆ°á»›c Ä‘Äƒng nháº­p cá»§a 2 trang web viá»‡c lÃ m itviec, vietnamworks vÃ  google vÃ  bÃ³c tÃ¡ch pháº§n dá»¯ liá»‡u bá»‹ áº©n Ä‘i khi chÆ°a Ä‘Äƒng nháº­p.
Hi vá»ng bÃ i viáº¿t nÃ y má»i ngÆ°á»i sáº½ cÃ³ thÃªm 1 lá»±a chá»n ná»¯a Ä‘á»ƒ crawl web cÃ³ javascript ğŸ˜ğŸ˜ğŸ˜","NhÃ¢n dá»‹p nÄƒm má»›i mÃ¬nh xin gá»­i lá»i chÃºc tá»›i toÃ n thá»ƒ má»i ngÆ°á»i trong nhÃ³m má»i Ä‘iá»u tá»‘t Ä‘áº¹p nháº¥t. MÃ¬nh má»›i viáº¿t 1 bÃ i vá» chá»§ Ä‘á» crawl dá»¯ liá»‡u cÃ¡c trang web vá»›i ná»™i dung Ä‘Æ°á»£c táº¡o bá»Ÿi javascript sá»­ dá»¥ng thÆ° viá»‡n chromedp cá»§a golang, Ä‘Ã¢y lÃ  1 thÆ° viá»‡n cÃ²n má»›i Ä‘á»‘i vá»›i má»i ngÆ°á»i. má»¥c tiÃªu lÃ  vÆ°á»£t qua bÆ°á»›c Ä‘Äƒng nháº­p cá»§a 2 trang web viá»‡c lÃ m itviec, vietnamworks vÃ  google vÃ  bÃ³c tÃ¡ch pháº§n dá»¯ liá»‡u bá»‹ áº©n Ä‘i khi chÆ°a Ä‘Äƒng nháº­p. Hi vá»ng bÃ i viáº¿t nÃ y má»i ngÆ°á»i sáº½ cÃ³ thÃªm 1 lá»±a chá»n ná»¯a Ä‘á»ƒ crawl web cÃ³ javascript",#chiase,,,,
"CÃ³ báº¡n nÃ o lÃ  SAS user khÃ´ng? MÃ¬nh cÃ³ má»™t vÃ i code free Ä‘á»ƒ há»c vÃ  thi láº¥y chá»©ng chá»‰ SAS Certification cho Data Science Program, háº¡n Ä‘áº¿n 12/2022. ÄÃ¢y lÃ  prize cá»§a mÃ¬nh khi thi competition, báº¡n nÃ o cáº§n thÃ¬ mÃ¬nh táº·ng láº¡i vÃ¬ mÃ¬nh khÃ´ng cÃ³ nhu cáº§u sá»­ dá»¥ng. Certification bao gá»“m:
Data Curation Professional
Advanced Analytics Professional
AI & Machine Learning Professional 
Link tham kháº£o: https://www.sas.com/en_us/training/academy-data-science.html
VÃ¬ SAS khÃ´ng phá»• biáº¿n nÃªn náº¿u báº¡n nÃ o thá»±c sá»± cáº§n thÃ¬ liÃªn há»‡ mÃ¬nh. ","CÃ³ báº¡n nÃ o lÃ  SAS user khÃ´ng? MÃ¬nh cÃ³ má»™t vÃ i code free Ä‘á»ƒ há»c vÃ  thi láº¥y chá»©ng chá»‰ SAS Certification cho Data Science Program, háº¡n Ä‘áº¿n 12/2022. ÄÃ¢y lÃ  prize cá»§a mÃ¬nh khi thi competition, báº¡n nÃ o cáº§n thÃ¬ mÃ¬nh táº·ng láº¡i vÃ¬ mÃ¬nh khÃ´ng cÃ³ nhu cáº§u sá»­ dá»¥ng. Certification bao gá»“m: Data Curation Professional Advanced Analytics Professional AI & Machine Learning Professional Link tham kháº£o: https://www.sas.com/en_us/training/academy-data-science.html VÃ¬ SAS khÃ´ng phá»• biáº¿n nÃªn náº¿u báº¡n nÃ o thá»±c sá»± cáº§n thÃ¬ liÃªn há»‡ mÃ¬nh.",,,,,
"Em chÃ o má»i ngÆ°á»i, báº£n cháº¥t cá»§a bá»©c áº£nh nÃ y lÃ  gÃ¬ áº¡?? Em biáº¿t Ä‘Æ°á»£c sÆ¡ sÆ¡ nhiÃªu Ä‘Ã¢y:
 L1 vÃ  L2 lÃ  mÃ´ hÃ¬nh Lasso Regression vÃ  Ridge Regression giÃºp trÃ¡nh hiá»‡n tÆ°á»£ng overfitting. 
HÃ m Loss cá»§a L1:  loss = error(y, y^) + lamda*sum(abs(cÃ¡c theta))
HÃ m Loss cá»§a L2:  loss = error(y, y^) + lamda*sum(square(cÃ¡c theta))
LÆ°á»£ng cá»™ng thÃªm thÃ¬ gá»i lÃ  penalty. Em ráº¥t muá»‘n biáº¿t táº¡i sao L1 láº¡i lÃ  hÃ¬nh thoi áº¡","Em chÃ o má»i ngÆ°á»i, báº£n cháº¥t cá»§a bá»©c áº£nh nÃ y lÃ  gÃ¬ áº¡?? Em biáº¿t Ä‘Æ°á»£c sÆ¡ sÆ¡ nhiÃªu Ä‘Ã¢y: L1 vÃ  L2 lÃ  mÃ´ hÃ¬nh Lasso Regression vÃ  Ridge Regression giÃºp trÃ¡nh hiá»‡n tÆ°á»£ng overfitting. HÃ m Loss cá»§a L1: loss = error(y, y^) + lamda*sum(abs(cÃ¡c theta)) HÃ m Loss cá»§a L2: loss = error(y, y^) + lamda*sum(square(cÃ¡c theta)) LÆ°á»£ng cá»™ng thÃªm thÃ¬ gá»i lÃ  penalty. Em ráº¥t muá»‘n biáº¿t táº¡i sao L1 láº¡i lÃ  hÃ¬nh thoi áº¡",,,,,
"ChÃ o má»i ngÆ°á»i ...trong quÃ¡ trÃ¬nh build má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i thÃ¬ em cÃ³ gáº·p váº¥n Ä‘á» sau.
Khi trainning thÃ¬ em tÃ­nh accuracy Ä‘Æ°á»£c 73%
CÃ²n khi testting trÃªn chÃ­nh táº­p vá»«a train thÃ¬ khi trong code cá»§a em cÃ³ model.eval() thÃ¬ accuracy Ä‘áº¡t 39%.
CÃ²n khi khÃ´ng cÃ³ model.eval()
thÃ¬ accuracy láº¡i Ä‘áº¡t 72% bÃ¡m sÃ¡t 73% lÃºc trainning.
Má»i ngÆ°á»i cho em há»i lÃ  táº¡i sao váº­y áº¡ . Em cáº£m Æ¡n má»i ngÆ°á»i",ChÃ o má»i ngÆ°á»i ...trong quÃ¡ trÃ¬nh build má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i thÃ¬ em cÃ³ gáº·p váº¥n Ä‘á» sau. Khi trainning thÃ¬ em tÃ­nh accuracy Ä‘Æ°á»£c 73% CÃ²n khi testting trÃªn chÃ­nh táº­p vá»«a train thÃ¬ khi trong code cá»§a em cÃ³ model.eval() thÃ¬ accuracy Ä‘áº¡t 39%. CÃ²n khi khÃ´ng cÃ³ model.eval() thÃ¬ accuracy láº¡i Ä‘áº¡t 72% bÃ¡m sÃ¡t 73% lÃºc trainning. Má»i ngÆ°á»i cho em há»i lÃ  táº¡i sao váº­y áº¡ . Em cáº£m Æ¡n má»i ngÆ°á»i,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u em máº¡nh dáº¡n chia sáº» cÃ¹ng anh em bÃ i vá» Model Quantization giÃºp model cháº¡y ngon hÆ¡n trÃªn cÃ¡c thiáº¿t bá»‹ Pi, Jetson Nano...
NÄƒm cÅ© sáº¯p qua, nÄƒm má»›i sáº¯p Ä‘áº¿n. ChÃºc cÃ¡c bÃ¡c má»™t nÄƒm thÃ nh cÃ´ng vÃ  háº¡nh phÃºc!","KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u em máº¡nh dáº¡n chia sáº» cÃ¹ng anh em bÃ i vá» Model Quantization giÃºp model cháº¡y ngon hÆ¡n trÃªn cÃ¡c thiáº¿t bá»‹ Pi, Jetson Nano... NÄƒm cÅ© sáº¯p qua, nÄƒm má»›i sáº¯p Ä‘áº¿n. ChÃºc cÃ¡c bÃ¡c má»™t nÄƒm thÃ nh cÃ´ng vÃ  háº¡nh phÃºc!",,,,,
"Trang machinelearningcoban bá»‹ lá»—i sao em dÃ¹ng Ä‘t vÃ´ ok mÃ  pc thÃ¬ Ä‘á»©t, bÃ¡o lá»—i em google chá»‰ lÃ  clear Ssl, delete cookies caches rá»“i nhÆ°ng váº«n váº­y.","Trang machinelearningcoban bá»‹ lá»—i sao em dÃ¹ng Ä‘t vÃ´ ok mÃ  pc thÃ¬ Ä‘á»©t, bÃ¡o lá»—i em google chá»‰ lÃ  clear Ssl, delete cookies caches rá»“i nhÆ°ng váº«n váº­y.",,,,,
"Má»i ngÆ°á»i Æ¡i, máº¥y hÃ´m nay em khÃ´ng vÃ o Ä‘Æ°á»£c website Machine Learning CÆ¡ Báº£n ná»¯a áº¡.
KhÃ´ng biáº¿t cÃ³ ai gáº·p tÃ¬nh tráº¡ng giá»‘ng em khÃ´ng, hÃ¬nh nhÆ° thÃ´ng bÃ¡o lÃ  Ä‘Ã£ chuyá»ƒn sang trang má»›i hoáº·c trang nÃ y khÃ´ng tá»“n táº¡i @@
Em cáº£m Æ¡n cáº£ nhÃ  áº¡!","Má»i ngÆ°á»i Æ¡i, máº¥y hÃ´m nay em khÃ´ng vÃ o Ä‘Æ°á»£c website Machine Learning CÆ¡ Báº£n ná»¯a áº¡. KhÃ´ng biáº¿t cÃ³ ai gáº·p tÃ¬nh tráº¡ng giá»‘ng em khÃ´ng, hÃ¬nh nhÆ° thÃ´ng bÃ¡o lÃ  Ä‘Ã£ chuyá»ƒn sang trang má»›i hoáº·c trang nÃ y khÃ´ng tá»“n táº¡i @@ Em cáº£m Æ¡n cáº£ nhÃ  áº¡!",,,,,
"Má»i ngÆ°á»i cho em há»i con Macbook M1 pro cÃ³ train model nhanh hÆ¡n Colab free khÃ´ng áº¡? Em Ä‘á»‹nh mua má»™t con laptop Ä‘á»ƒ lÃ m viá»‡c, má»i ngÆ°á»i cho em lá»i khuyÃªn nhÃ©! NgÃ¢n sÃ¡ch khÃ´ng quan trá»ng vÃ¬ cÃ³ ngÆ°á»i tÃ i trá»£ mua cho em áº¡. Cáº£m Æ¡n má»i ngÆ°á»i!","Má»i ngÆ°á»i cho em há»i con Macbook M1 pro cÃ³ train model nhanh hÆ¡n Colab free khÃ´ng áº¡? Em Ä‘á»‹nh mua má»™t con laptop Ä‘á»ƒ lÃ m viá»‡c, má»i ngÆ°á»i cho em lá»i khuyÃªn nhÃ©! NgÃ¢n sÃ¡ch khÃ´ng quan trá»ng vÃ¬ cÃ³ ngÆ°á»i tÃ i trá»£ mua cho em áº¡. Cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"Äi lang thang trÃªn máº¡ng gáº·p Ä‘Æ°á»£c má»™t nguá»“n tá»•ng há»£p hÆ¡n 800 khoÃ¡ há»c miá»…n phÃ­ vá» Computer Science, Data Science & Machine Learning, ... cÃ³ váº» khÃ¡ hay, cÃ¡c báº¡n lÆ°u láº¡i Ä‘á»ƒ tham kháº£o dáº§n dáº§n nhÃ©.
https://github.com/Developer-Y/cs-video-courses
P/S: Nhiá»u quÃ¡ Ä‘Ã´i khi cÅ©ng khÃ´ng tá»‘t, nhÆ°ng thÃ´i ká»‡ cá»© sÆ°u táº§m vá» Ä‘Ã£ ğŸ˜›","Äi lang thang trÃªn máº¡ng gáº·p Ä‘Æ°á»£c má»™t nguá»“n tá»•ng há»£p hÆ¡n 800 khoÃ¡ há»c miá»…n phÃ­ vá» Computer Science, Data Science & Machine Learning, ... cÃ³ váº» khÃ¡ hay, cÃ¡c báº¡n lÆ°u láº¡i Ä‘á»ƒ tham kháº£o dáº§n dáº§n nhÃ©. https://github.com/Developer-Y/cs-video-courses P/S: Nhiá»u quÃ¡ Ä‘Ã´i khi cÅ©ng khÃ´ng tá»‘t, nhÆ°ng thÃ´i ká»‡ cá»© sÆ°u táº§m vá» Ä‘Ã£",,,,,
"ChÃ o cáº£ nhÃ ,
MÃ¬nh má»›i lÃ m Ã­t video chia sáº» vá» Machine Learning, ráº¥t mong má»i ngÆ°á»i Ä‘Ã³ng Ã½ kiáº¿n Ä‘á»ƒ cÃ¡c video tiáº¿p theo hoÃ n thiá»‡n tá»‘t hÆ¡n:
https://www.youtube.com/playlist?list=PLWBrqglnjNl17CA7H7RGr9uHAbDKbwRKq
Cáº£m Æ¡n cáº£ nhÃ  nhiá»u","ChÃ o cáº£ nhÃ , MÃ¬nh má»›i lÃ m Ã­t video chia sáº» vá» Machine Learning, ráº¥t mong má»i ngÆ°á»i Ä‘Ã³ng Ã½ kiáº¿n Ä‘á»ƒ cÃ¡c video tiáº¿p theo hoÃ n thiá»‡n tá»‘t hÆ¡n: https://www.youtube.com/playlist?list=PLWBrqglnjNl17CA7H7RGr9uHAbDKbwRKq Cáº£m Æ¡n cáº£ nhÃ  nhiá»u",,,,,
BÃ i viáº¿t vá» dá»± bÃ¡o â€œtÆ°Æ¡ng laiâ€ GNNs trong nÄƒm 2022 cá»§a M. Bronstein vÃ  VeliÄkoviÄ‡. BÃ i dÃ i tá»›i 44 phÃºt Ä‘á»c nhÆ°ng Ä‘Ã¡ng Ä‘á»c,BÃ i viáº¿t vá» dá»± bÃ¡o â€œtÆ°Æ¡ng laiâ€ GNNs trong nÄƒm 2022 cá»§a M. Bronstein vÃ  VeliÄkoviÄ‡. BÃ i dÃ i tá»›i 44 phÃºt Ä‘á»c nhÆ°ng Ä‘Ã¡ng Ä‘á»c,,,,,
"[Label Studio â€“ 7.4k star*]
Label Studio lÃ  gÃ¬?
Label Studio lÃ  má»™t cÃ´ng cá»¥ label dá»¯ liá»‡u mÃ£ nguá»“n má»Ÿ. NÃ³ cho phÃ©p báº¡n gÃ¡n nhÃ£n cÃ¡c loáº¡i dá»¯ liá»‡u nhÆ° Ã¢m thanh, hÃ¬nh áº£nh, vÄƒn báº£n, video vÃ  chuá»—i thá»i gian vá»›i giao diá»‡n ngÆ°á»i dÃ¹ng Ä‘Æ¡n giáº£n, dá»… hiá»ƒu vÃ  dá»… dÃ ng xuáº¥t sang cÃ¡c Ä‘á»‹nh dáº¡ng mÃ´ hÃ¬nh khÃ¡c nhau.
Äáº·c biá»‡t, báº¡n cÃ³ thá»ƒ thiáº¿t láº­p mÃ´ hÃ¬nh Machine Learning vá»›i Label Studio hay tÃ­ch há»£p Label Studio vá»›i cÃ¡c cÃ´ng cá»¥ hiá»‡n cÃ³ cá»§a báº¡n.
Chi tiáº¿t má»i ngÆ°á»i xem thÃªm á»Ÿ Ä‘Ã¢y:
Web: https://labelstud.io/
Github: https://github.com/heartexlabs/label-studio","[Label Studio â€“ 7.4k star*] Label Studio lÃ  gÃ¬? Label Studio lÃ  má»™t cÃ´ng cá»¥ label dá»¯ liá»‡u mÃ£ nguá»“n má»Ÿ. NÃ³ cho phÃ©p báº¡n gÃ¡n nhÃ£n cÃ¡c loáº¡i dá»¯ liá»‡u nhÆ° Ã¢m thanh, hÃ¬nh áº£nh, vÄƒn báº£n, video vÃ  chuá»—i thá»i gian vá»›i giao diá»‡n ngÆ°á»i dÃ¹ng Ä‘Æ¡n giáº£n, dá»… hiá»ƒu vÃ  dá»… dÃ ng xuáº¥t sang cÃ¡c Ä‘á»‹nh dáº¡ng mÃ´ hÃ¬nh khÃ¡c nhau. Äáº·c biá»‡t, báº¡n cÃ³ thá»ƒ thiáº¿t láº­p mÃ´ hÃ¬nh Machine Learning vá»›i Label Studio hay tÃ­ch há»£p Label Studio vá»›i cÃ¡c cÃ´ng cá»¥ hiá»‡n cÃ³ cá»§a báº¡n. Chi tiáº¿t má»i ngÆ°á»i xem thÃªm á»Ÿ Ä‘Ã¢y: Web: https://labelstud.io/ Github: https://github.com/heartexlabs/label-studio",,,,,
"Em chÃ o má»i ngÆ°á»i, em Ä‘ang thá»±c hiá»‡n so sÃ¡nh cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh em phÃ¡t triá»ƒn vá»›i cÃ¡c mÃ´ hÃ¬nh tá»« 1 sá»‘ bÃ i bÃ¡o khÃ¡c nhau. Äá»ƒ so sÃ¡nh cháº¥t lÆ°á»£ng, em xÃ¢y dá»±ng cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau, trong má»—i táº­p dá»¯ liá»‡u Ä‘á»u cÃ³ training set, validation set vÃ  test set. Em cho mÃ´ hÃ¬nh cá»§a em há»c trÃªn training set sau Ä‘Ã³ cho early stopping vá»›i validation set rá»“i evaluate trÃªn test set Ä‘á»ƒ thu Ä‘Æ°á»£c cÃ¡c Ä‘á»™ Ä‘o cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh. Vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c, em cÅ©ng láº·p láº¡i quy trÃ¬nh trÃªn, nhÆ°ng cÃ³ 1 mÃ´ hÃ¬nh train ráº¥t lÃ¢u, tuy nhiÃªn láº¡i cÃ³ file weight cá»§a mÃ´ hÃ¬nh khi train vá»›i táº­p dá»¯ liá»‡u trong bÃ i bÃ¡o gá»‘c. Äá»ƒ tiáº¿t kiá»‡m thÃ¬ em cÃ³ nÃªn sá»­ dá»¥ng file weight Ä‘Ã³ Ä‘á»ƒ load luÃ´n mÃ´ hÃ¬nh rá»“i Ä‘Ã¡nh giÃ¡ trÃªn táº­p test em Ä‘Ã£ xÃ¢y dá»±ng khÃ´ng áº¡? Em nghÄ© em cÃ³ cÃ¢u tráº£ lá»i lÃ  ráº¥t cÃ³ thá»ƒ lÃ  khÃ´ng, vÃ¬ cÃ³ thá»ƒ file weight cho mÃ´ hÃ¬nh tá»« bÃ i bÃ¡o Ä‘Ã³ chá»‰ thá»ƒ hiá»‡n ráº±ng mÃ´ hÃ¬nh cÃ³ thá»ƒ fit ráº¥t tá»‘t vá»›i training set trong bÃ i bÃ¡o Ä‘Ã³ chá»© náº¿u Ä‘Ã¡nh giÃ¡ luÃ´n trÃªn test set mÃ  em xÃ¢y dá»±ng thÃ¬ cÃ³ thá»ƒ láº¡i ráº¥t kÃ©m. Em tháº¥y ráº±ng trong cÃ¡c bÃ i bÃ¡o, ngÆ°á»i ta thÆ°á»ng train vÃ  test cÃ¡c mÃ´ hÃ¬nh trÃªn cÃ¹ng táº­p dá»¯ liá»‡u (cáº£ training vÃ  test set), liá»‡u cÃ²n cÃ³ nhá»¯ng cÃ¡ch nÃ o hay cÃ¡ch khÃ¡c em vá»«a nÃªu ra liÃªn quan Ä‘áº¿n load pretrained model cÃ³ há»£p lÃ½ khÃ´ng áº¡. (á»Ÿ Ä‘Ã¢y em chá»‰ há»i so sÃ¡nh vá» performance metrics nhÆ° accuracy, f1-score, auroc, auprc giá»¯a cÃ¡c mÃ´ hÃ¬nh áº¡). Em cáº£m Æ¡n má»i ngÆ°á»i.

PS: áº¢nh em láº¥y mang tÃ­nh cháº¥t minh há»a áº¡","Em chÃ o má»i ngÆ°á»i, em Ä‘ang thá»±c hiá»‡n so sÃ¡nh cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh em phÃ¡t triá»ƒn vá»›i cÃ¡c mÃ´ hÃ¬nh tá»« 1 sá»‘ bÃ i bÃ¡o khÃ¡c nhau. Äá»ƒ so sÃ¡nh cháº¥t lÆ°á»£ng, em xÃ¢y dá»±ng cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau, trong má»—i táº­p dá»¯ liá»‡u Ä‘á»u cÃ³ training set, validation set vÃ  test set. Em cho mÃ´ hÃ¬nh cá»§a em há»c trÃªn training set sau Ä‘Ã³ cho early stopping vá»›i validation set rá»“i evaluate trÃªn test set Ä‘á»ƒ thu Ä‘Æ°á»£c cÃ¡c Ä‘á»™ Ä‘o cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh. Vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c, em cÅ©ng láº·p láº¡i quy trÃ¬nh trÃªn, nhÆ°ng cÃ³ 1 mÃ´ hÃ¬nh train ráº¥t lÃ¢u, tuy nhiÃªn láº¡i cÃ³ file weight cá»§a mÃ´ hÃ¬nh khi train vá»›i táº­p dá»¯ liá»‡u trong bÃ i bÃ¡o gá»‘c. Äá»ƒ tiáº¿t kiá»‡m thÃ¬ em cÃ³ nÃªn sá»­ dá»¥ng file weight Ä‘Ã³ Ä‘á»ƒ load luÃ´n mÃ´ hÃ¬nh rá»“i Ä‘Ã¡nh giÃ¡ trÃªn táº­p test em Ä‘Ã£ xÃ¢y dá»±ng khÃ´ng áº¡? Em nghÄ© em cÃ³ cÃ¢u tráº£ lá»i lÃ  ráº¥t cÃ³ thá»ƒ lÃ  khÃ´ng, vÃ¬ cÃ³ thá»ƒ file weight cho mÃ´ hÃ¬nh tá»« bÃ i bÃ¡o Ä‘Ã³ chá»‰ thá»ƒ hiá»‡n ráº±ng mÃ´ hÃ¬nh cÃ³ thá»ƒ fit ráº¥t tá»‘t vá»›i training set trong bÃ i bÃ¡o Ä‘Ã³ chá»© náº¿u Ä‘Ã¡nh giÃ¡ luÃ´n trÃªn test set mÃ  em xÃ¢y dá»±ng thÃ¬ cÃ³ thá»ƒ láº¡i ráº¥t kÃ©m. Em tháº¥y ráº±ng trong cÃ¡c bÃ i bÃ¡o, ngÆ°á»i ta thÆ°á»ng train vÃ  test cÃ¡c mÃ´ hÃ¬nh trÃªn cÃ¹ng táº­p dá»¯ liá»‡u (cáº£ training vÃ  test set), liá»‡u cÃ²n cÃ³ nhá»¯ng cÃ¡ch nÃ o hay cÃ¡ch khÃ¡c em vá»«a nÃªu ra liÃªn quan Ä‘áº¿n load pretrained model cÃ³ há»£p lÃ½ khÃ´ng áº¡. (á»Ÿ Ä‘Ã¢y em chá»‰ há»i so sÃ¡nh vá» performance metrics nhÆ° accuracy, f1-score, auroc, auprc giá»¯a cÃ¡c mÃ´ hÃ¬nh áº¡). Em cáº£m Æ¡n má»i ngÆ°á»i. PS: áº¢nh em láº¥y mang tÃ­nh cháº¥t minh há»a áº¡",,,,,
"Trong lÃºc nghiÃªn cá»©u vá» represention learning, mÃ¬nh cÃ³ phÃ¡t hiá»‡n ra phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh cho feature visualization nhÆ° bÃªn dÆ°á»›i vÃ  Ä‘áº¡t Ä‘Æ°á»£c perfomance tá»‘t hÆ¡n baseline. Theo hÃ¬nh thÃ¬ feature cá»§a mÃ¬nh more uniformity. Káº¿t quáº£ thá»±c nghiá»‡m cho performance tá»‘t hÆ¡n. NhÆ°ng dáº¡ng phÃ¢n phá»‘i features nhÆ° nÃ y cÃ³ tÃ¡c dá»¥ng gÃ¬ tá»›i downstream tasks. MÃ¬nh khÃ´ng thá»ƒ lÃ½ giáº£i sÃ¢u Ä‘Æ°á»£c. Xin phÃ©p má»i ngÆ°á»i chá»‰ báº£o thÃªm áº¡?","Trong lÃºc nghiÃªn cá»©u vá» represention learning, mÃ¬nh cÃ³ phÃ¡t hiá»‡n ra phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh cho feature visualization nhÆ° bÃªn dÆ°á»›i vÃ  Ä‘áº¡t Ä‘Æ°á»£c perfomance tá»‘t hÆ¡n baseline. Theo hÃ¬nh thÃ¬ feature cá»§a mÃ¬nh more uniformity. Káº¿t quáº£ thá»±c nghiá»‡m cho performance tá»‘t hÆ¡n. NhÆ°ng dáº¡ng phÃ¢n phá»‘i features nhÆ° nÃ y cÃ³ tÃ¡c dá»¥ng gÃ¬ tá»›i downstream tasks. MÃ¬nh khÃ´ng thá»ƒ lÃ½ giáº£i sÃ¢u Ä‘Æ°á»£c. Xin phÃ©p má»i ngÆ°á»i chá»‰ báº£o thÃªm áº¡?",,,,,
"em xin chÃ o má»i ngÆ°á»i, em cÃ³ chÃºt tháº¯c máº¯c pháº§n nÃ y (áº£nh bÃªn dÆ°á»›i) khi Ä‘á»c cuá»‘n hands-on ML.
cá»¥ thá»ƒ lÃ  tÃ¡c giáº£ cÃ³ nÃ³i: giáº£ sá»­ xÃ¡c suáº¥t tung Ä‘á»“ng xu cÃ³ máº·t ngá»­a lÃ  51%, máº·t sáº¥p lÃ  49%. Náº¿u tung 1000 láº§n thÃ¬ sáº½ cÃ³ khoáº£ng 510 máº·t ngá»­a vÃ  490 máº·t sáº¥p. VÃ  sau cÃ ng nhiá»u láº§n tung thÃ¬ xÃ¡c suáº¥t Ä‘á»ƒ máº·t ngá»­a cÃ ng tÄƒng (10000 láº§n lÃ  97%) nhÆ°ng trÃªn Ä‘á»“ thá»‹ thÃ¬ biá»ƒu diá»…n k Ä‘Ãºng láº¯m. em Ä‘ang chÆ°a hiá»ƒu rÃµ pháº§n nÃ y, ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡, em cáº£m Æ¡n áº¡!","em xin chÃ o má»i ngÆ°á»i, em cÃ³ chÃºt tháº¯c máº¯c pháº§n nÃ y (áº£nh bÃªn dÆ°á»›i) khi Ä‘á»c cuá»‘n hands-on ML. cá»¥ thá»ƒ lÃ  tÃ¡c giáº£ cÃ³ nÃ³i: giáº£ sá»­ xÃ¡c suáº¥t tung Ä‘á»“ng xu cÃ³ máº·t ngá»­a lÃ  51%, máº·t sáº¥p lÃ  49%. Náº¿u tung 1000 láº§n thÃ¬ sáº½ cÃ³ khoáº£ng 510 máº·t ngá»­a vÃ  490 máº·t sáº¥p. VÃ  sau cÃ ng nhiá»u láº§n tung thÃ¬ xÃ¡c suáº¥t Ä‘á»ƒ máº·t ngá»­a cÃ ng tÄƒng (10000 láº§n lÃ  97%) nhÆ°ng trÃªn Ä‘á»“ thá»‹ thÃ¬ biá»ƒu diá»…n k Ä‘Ãºng láº¯m. em Ä‘ang chÆ°a hiá»ƒu rÃµ pháº§n nÃ y, ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡, em cáº£m Æ¡n áº¡!",,,,,
"[SHARING - MACHINE LEARNING IN QUANTITATIVE TRADING PROJECT]
Hello má»i ngÆ°á»i, mÃ¬nh cÃ³ nghiÃªn cá»©u Machine Learning trong Trading khÃ¡ lÃ¢u vÃ  cÃ³ lÃ m 1 project Ä‘á»ƒ á»©ng dá»¥ng Machine Learning trong quy trÃ¬nh nghiÃªn cá»©u trÃªn 1 thá»‹ trÆ°á»ng thá»±c táº¿. Quy trÃ¬nh trong project sáº½ cÃ³ nhiá»u bÆ°á»›c tá»« Data Cleaning, Feature Engineering, Machine Learning modeling, Alpha Factor Analysis, Porfolio Optimization vÃ  Backtesting. Tá»« Ä‘Ã³ cÃ¡c báº¡n cÃ³ thá»ƒ tá»± phÃ¡t triá»ƒn, xÃ¢y dá»±ng chiáº¿n lÆ°á»£c cho riÃªng mÃ¬nh. Náº¿u báº¡n nÃ o cÃ³ há»©ng thÃº muá»‘n tÃ¬m hiá»ƒu thÃªm thÃ¬ cÃ³ thá»ƒ liÃªn há»‡ mÃ¬nh nhÃ©.","[SHARING - MACHINE LEARNING IN QUANTITATIVE TRADING PROJECT] Hello má»i ngÆ°á»i, mÃ¬nh cÃ³ nghiÃªn cá»©u Machine Learning trong Trading khÃ¡ lÃ¢u vÃ  cÃ³ lÃ m 1 project Ä‘á»ƒ á»©ng dá»¥ng Machine Learning trong quy trÃ¬nh nghiÃªn cá»©u trÃªn 1 thá»‹ trÆ°á»ng thá»±c táº¿. Quy trÃ¬nh trong project sáº½ cÃ³ nhiá»u bÆ°á»›c tá»« Data Cleaning, Feature Engineering, Machine Learning modeling, Alpha Factor Analysis, Porfolio Optimization vÃ  Backtesting. Tá»« Ä‘Ã³ cÃ¡c báº¡n cÃ³ thá»ƒ tá»± phÃ¡t triá»ƒn, xÃ¢y dá»±ng chiáº¿n lÆ°á»£c cho riÃªng mÃ¬nh. Náº¿u báº¡n nÃ o cÃ³ há»©ng thÃº muá»‘n tÃ¬m hiá»ƒu thÃªm thÃ¬ cÃ³ thá»ƒ liÃªn há»‡ mÃ¬nh nhÃ©.",,,,,
"Em chÃ o mn áº¡. Em má»›i tÃ¬m hiá»ƒu vá» machine learning. Trong b10 logistic regression trÃªn blog machine learning cÆ¡ báº£n https://machinelearningcoban.com/2017/01/27/logisticregression/
em cÃ³ tháº¥y anh Tiá»‡p khi code láº¡i thuáº­t toÃ¡n, em tháº¥y anh sá»­ dá»¥ng mix_id data vÃ  tá»‘i Æ°u hÃ m máº¥t mÃ¡t cho tá»«ng Ä‘iá»ƒm 1. Em cÃ³ thá»­ thay báº±ng hÃ m máº¥t mÃ¡t cá»§a trung bÃ¬nh tá»•ng cÃ¡c data (vd tá»•ng máº¥t mÃ¡t cá»§a m data rá»“i chia cho m), vá» báº£n cháº¥t em cáº£m giÃ¡c khÃ´ng sai khÃ¡c nhau láº¯m, cÅ©ng cÃ³ nhá»¯ng tÃ i liá»‡u viáº¿t hÃ m máº¥t mÃ¡t dÆ°á»›i dáº¡ng nÃ y nhÆ°ng káº¿t quáº£ thá»­ cá»§a em láº¡i ra khÃ´ng tá»‘t ná»¯a áº¡. Váº­y khÃ´ng biáº¿t lá»—i lÃ  á»Ÿ Ä‘Ã¢u, mong má»i ngÆ°á»i chá»‰ dáº«n áº¡. Em cáº£m Æ¡n.","Em chÃ o mn áº¡. Em má»›i tÃ¬m hiá»ƒu vá» machine learning. Trong b10 logistic regression trÃªn blog machine learning cÆ¡ báº£n https://machinelearningcoban.com/2017/01/27/logisticregression/ em cÃ³ tháº¥y anh Tiá»‡p khi code láº¡i thuáº­t toÃ¡n, em tháº¥y anh sá»­ dá»¥ng mix_id data vÃ  tá»‘i Æ°u hÃ m máº¥t mÃ¡t cho tá»«ng Ä‘iá»ƒm 1. Em cÃ³ thá»­ thay báº±ng hÃ m máº¥t mÃ¡t cá»§a trung bÃ¬nh tá»•ng cÃ¡c data (vd tá»•ng máº¥t mÃ¡t cá»§a m data rá»“i chia cho m), vá» báº£n cháº¥t em cáº£m giÃ¡c khÃ´ng sai khÃ¡c nhau láº¯m, cÅ©ng cÃ³ nhá»¯ng tÃ i liá»‡u viáº¿t hÃ m máº¥t mÃ¡t dÆ°á»›i dáº¡ng nÃ y nhÆ°ng káº¿t quáº£ thá»­ cá»§a em láº¡i ra khÃ´ng tá»‘t ná»¯a áº¡. Váº­y khÃ´ng biáº¿t lá»—i lÃ  á»Ÿ Ä‘Ã¢u, mong má»i ngÆ°á»i chá»‰ dáº«n áº¡. Em cáº£m Æ¡n.",,,,,
"[CoAtNet - Marrying convolution and attention for all data sizes]
Transformer Ä‘ang Ä‘áº¡t Ä‘Æ°á»£c sá»± quan tÃ¢m Ä‘Ã¡ng ká»ƒ trong Computer Vision nhÆ°ng váº«n chÆ°a hoÃ n toÃ n vÆ°á»£t qua Ä‘Æ°á»£c cÃ¡c kiáº¿n trÃºc CNN tá»‘t nháº¥t. Gáº§n Ä‘Ã¢y trong bÃ i bÃ¡o CoAtNet cá»§a nhÃ³m tÃ¡c giáº£ ná»•i tiáº¿ng Ä‘áº¿n tá»« google lÃ  anh Quá»‘c LÃª vÃ  Mingxing Tan Ä‘Ã£ Ä‘Æ°a ra má»™t sá»± káº¿t há»£p giá»¯a Convolution vá»›i Attention. ÄÃ¢y lÃ  má»™t Ã½ tÆ°á»Ÿng Ä‘Æ¡n giáº£n nhÆ°ng Ä‘á»™c Ä‘Ã¡o mÃ  mÃ¬nh bá»‹ háº¥p dáº«n vÃ  cáº£m tháº¥y thÃº vá»‹. Hiá»‡n táº¡i thÃ¬ mÃ´ hÃ¬nh tá»‘t nháº¥t cá»§a kiáº¿n trÃºc nÃ y lÃ  CoAtNet-7 Ä‘ang xáº¿p top 1 trÃªn Leader Board cá»§a ImageNet, bá» xa ConvNeXt, EfficientNetV2-L vÃ  ViT:
https://paperswithcode.com/sota/image-classification-on-imagenet
MÃ¬nh cÅ©ng dÃ nh thá»i gian phÃ¢n tÃ­ch vÃ  implement láº¡i mÃ´ hÃ¬nh nÃ y gáº§n Ä‘Ã¢y vÃ  hÃ´m nay muá»‘n review láº¡i nhá»¯ng Ã½ chÃ­nh cá»§a paper tá»›i má»i ngÆ°á»i. Qua Ä‘Ã³, má»i ngÆ°á»i cÃ³ thá»ƒ cÃ³ thÃªm Ã½ tÆ°á»Ÿng má»›i trong research cÅ©ng nhÆ° apply vÃ o cÃ¡c project cá»§a cÃ´ng ty,
1. Capture má»™t vÃ i tÃ­nh cháº¥t quan trá»ng cá»§a CNN vÃ  Transformer.
1.1. TÃ­nh cháº¥t cá»§a CNN:
- Translation Equivariance: Sá»± dá»‹ch chuyá»ƒn cá»§a má»™t váº­t thá»ƒ trÃªn áº£nh Ä‘áº§u vÃ o so vá»›i Ä‘áº§u ra lÃ  báº¥t biáº¿n trÃªn má»™t máº¡ng CNN. Nhá» tÃ­nh cháº¥t nÃ y mÃ  CNN cÃ³ thá»ƒ há»c tá»‘t hÆ¡n vá»›i Ã­t dá»¯ liá»‡u thÃ´ng qua Augumentation.
- Local Receptive Field: CÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c CNN tá»•ng há»£p lÃ  dá»±a trÃªn cÃ¡c local region cá»§a áº£nh vÃ  nhá»¯ng Ä‘áº·c trÆ°ng nÃ y cÃ³ sá»± biáº¿n Ä‘á»•i theo Ä‘á»™ sÃ¢u. á» nhá»¯ng level Ä‘áº§u lÃ  nhá»¯ng Ä‘áº·c trÆ°ng báº­c tháº¥p mang tÃ­nh phá»• biáº¿n nhÆ° cÃ¡c nÃ©t dá»c, ngang, chÃ©o vÃ  Ä‘Æ°á»£c tá»•ng há»£p thÃ nh nhá»¯ng Ä‘áº·c trÆ°ng báº­c cao giÃºp nháº­n diá»‡n class á»Ÿ nhá»¯ng layer sÃ¢u hÆ¡n.
1.2. CÃ¡c tÃ­nh cháº¥t cá»§a Transformer:
- Global context: Transformer ban Ä‘áº§u Ä‘Æ°á»£c xÃ¢y dá»±ng lÃ  cho sequential data cháº³ng háº¡n nhÆ° text data vá»›i core building block lÃ  Multi-head Attention. Nhá» Ä‘Ã³ nÃ³ cÃ³ kháº£ nÄƒng trÃ­ch xuáº¥t thÃ´ng tin global context ráº¥t tá»‘t. Má»™t feature token há»c Ä‘Æ°á»£c tá»« máº¡ng lÃ  Ä‘Æ°á»£c tá»•ng há»£p tá»« toÃ n bá»™ cÃ¡c patches trÃªn áº£nh.
- Global Receptive Field: Transformer hoáº¡t Ä‘á»™ng nhÆ° má»™t Global Receptive Field trong khi CNN hoáº¡t Ä‘á»™ng dá»±a trÃªn Local Receptive Field. TÃ­nh cháº¥t nÃ y khiáº¿n Transformer cÃ³ xu hÆ°á»›ng dá»… gáº·p pháº£i overfitting vÃ¬ dá»¯ liá»‡u cá»§a báº¡n khi thá»±c hiá»‡n cÃ¡c Hard Augmentation nhÆ° Rotation vá»›i gÃ³c lá»›n, Random Shuffling, CutMix thÃ¬ Transformer váº«n cÃ³ thá»ƒ nháº­n ra Ä‘Æ°á»£c. ÄÃ³ cÅ©ng lÃ  nguyÃªn nhÃ¢n khiáº¿n Transformer sáº½ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n so vá»›i CNN khi huáº¥n luyá»‡n trÃªn cÃ¡c bá»™ dá»¯ liá»‡u kÃ­ch thÆ°á»›c cá»±c lá»›n (lÃªn tá»›i vÃ i trÄƒm triá»‡u images) nhÆ° ImageNet-21K, JFT-300M nhÆ°ng láº¡i kÃ©m hÆ¡n trÃªn ImageNet-1K (chá»‰ 1 triá»‡u images).
- Layerâ€™s Features Similarity: CÃ¡c Ä‘áº·c trÆ°ng mÃ  Transformer há»c Ä‘Æ°á»£c cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a first layer vÃ  last layer, trong khi CNN thÃ¬ khÃ¡c biá»‡t máº¡nh giá»¯a chÃºng.
3. Ã tÆ°á»Ÿng cá»§a bÃ i bÃ¡o:
Káº¿t há»£p Ä‘á»“ng thá»i cáº£ Convolution vÃ  Attention trong cÃ¹ng má»™t block vÃ  stack chÃºng trong má»™t end-to-end network. Khi Ã¡p dá»¥ng kiáº¿n trÃºc Transformer cÃ³ thá»ƒ khiáº¿n cho sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh tÄƒng lÃªn ráº¥t lá»›n. NhÆ° váº­y chi phÃ­ tÃ­nh toÃ¡n sáº½ Ä‘Æ°á»£c cÃ¢n nháº¯c trong thiáº¿t káº¿ cá»§a kiáº¿n trÃºc nÃ y. Má»™t sá»‘ Ä‘iá»u chá»‰nh Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n:
â€¢ Downsampling Ä‘á»ƒ giáº£m thiá»ƒu parameters.
â€¢ Háº¡n cháº¿ Attention trong Transformer vá» local region.
â€¢ Thay tháº¿ GeLU báº±ng ReLU activation hoáº·c bá» bá»›t cÃ¡c Non-Linear Activation Ä‘á»ƒ giáº£m thiá»ƒu chi phÃ­ tÃ­nh toÃ¡n.
Kiáº¿n trÃºc cuá»‘i cÃ¹ng: á» nhá»¯ng layers Ä‘áº§u lÃ  máº¡ng CNN cÃ³ tÃ¡c dá»¥ng trÃ­ch lá»c Ä‘áº·c trÆ°ng trÃªn local receptive field, nhá»¯ng layer cuá»‘i cÃ¹ng sá»­ dá»¥ng attention + feed forward.
[Conv(3,3)] x 2 â†’ [Conv(1,1) +DConv(3,3)+Conv(1,1)] x L1â†’ [Conv(1,1) +DConv(3,3)+Conv(1,1)] x L2 â†’ [Rel-Attention + FFN] x L3 â†’ [Rel-Attention + FFN] x L4 â†’ Global Poolâ†’FC â†’ Output
4. Káº¿t quáº£:
- Nhá» sá»± káº¿t há»£p vá»›i CNN mÃ  trÃªn nhá»¯ng bá»™ dá»¯ liá»‡u kÃ­ch thÆ°á»›c nhá» cÃ³ thá»ƒ vÆ°á»£t qua SOTA model lÃ  ViT.
- Má»©c Ä‘á»™ cáº¡nh tranh so vá»›i cÃ¡c based CNN network cÃ³ cÃ¹ng kÃ­ch cá»¡ nhÆ° EfficientNet-V2, NFNets.
- VÆ°á»£t xa há» cÃ¡c kiáº¿n trÃºc attentions based Nets.
5. Suy nghÄ© cá»§a tÃ´i:
CoAtNet Ä‘Ã£ phÃ¡ vá»¡ cÃ¡c quan niá»‡m truyá»n thá»‘ng khi huáº¥n luyá»‡n cÃ¡c kiáº¿n trÃºc Transformer based trÃªn dá»¯ liá»‡u image Ä‘Ã³ lÃ  cáº§n dá»¯ liá»‡u lá»›n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c SOTA. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a quan trá»ng trong cÃ¡c dá»± Ã¡n thá»±c tiá»…n vÃ¬ khÃ´ng pháº£i khi nÃ o chÃºng ta cÅ©ng Ä‘á»§ vÃ i chá»¥c hay tháº­m chÃ­ vÃ i trÄƒm triá»‡u áº£nh Ä‘á»ƒ huáº¥n luyá»‡n. VÃ­ dá»¥ nhÆ° vá»›i dá»¯ liá»‡u tá»‘n kÃ©m chi phÃ­ gÃ¡n nhÃ£n nhÆ° xá»­ lÃ½ áº£nh y táº¿ cháº³ng háº¡n. Ã tÆ°á»Ÿng thiáº¿t káº¿ nhá»¯ng block káº¿t há»£p cáº£ Convolution vÃ  Attention cÃ³ thá»ƒ phÃ¹ há»£p vá»›i dá»¯ liá»‡u dáº¡ng hÃ¬nh áº£nh trong tÆ°Æ¡ng lai, thá»© mÃ  yÃªu cáº§u sá»± liÃªn káº¿t khÃ´ng gian 2 chiá»u cháº·t cháº½ hÆ¡n so vá»›i trÃªn vÄƒn báº£n.","[CoAtNet - Marrying convolution and attention for all data sizes] Transformer Ä‘ang Ä‘áº¡t Ä‘Æ°á»£c sá»± quan tÃ¢m Ä‘Ã¡ng ká»ƒ trong Computer Vision nhÆ°ng váº«n chÆ°a hoÃ n toÃ n vÆ°á»£t qua Ä‘Æ°á»£c cÃ¡c kiáº¿n trÃºc CNN tá»‘t nháº¥t. Gáº§n Ä‘Ã¢y trong bÃ i bÃ¡o CoAtNet cá»§a nhÃ³m tÃ¡c giáº£ ná»•i tiáº¿ng Ä‘áº¿n tá»« google lÃ  anh Quá»‘c LÃª vÃ  Mingxing Tan Ä‘Ã£ Ä‘Æ°a ra má»™t sá»± káº¿t há»£p giá»¯a Convolution vá»›i Attention. ÄÃ¢y lÃ  má»™t Ã½ tÆ°á»Ÿng Ä‘Æ¡n giáº£n nhÆ°ng Ä‘á»™c Ä‘Ã¡o mÃ  mÃ¬nh bá»‹ háº¥p dáº«n vÃ  cáº£m tháº¥y thÃº vá»‹. Hiá»‡n táº¡i thÃ¬ mÃ´ hÃ¬nh tá»‘t nháº¥t cá»§a kiáº¿n trÃºc nÃ y lÃ  CoAtNet-7 Ä‘ang xáº¿p top 1 trÃªn Leader Board cá»§a ImageNet, bá» xa ConvNeXt, EfficientNetV2-L vÃ  ViT: https://paperswithcode.com/sota/image-classification-on-imagenet MÃ¬nh cÅ©ng dÃ nh thá»i gian phÃ¢n tÃ­ch vÃ  implement láº¡i mÃ´ hÃ¬nh nÃ y gáº§n Ä‘Ã¢y vÃ  hÃ´m nay muá»‘n review láº¡i nhá»¯ng Ã½ chÃ­nh cá»§a paper tá»›i má»i ngÆ°á»i. Qua Ä‘Ã³, má»i ngÆ°á»i cÃ³ thá»ƒ cÃ³ thÃªm Ã½ tÆ°á»Ÿng má»›i trong research cÅ©ng nhÆ° apply vÃ o cÃ¡c project cá»§a cÃ´ng ty, 1. Capture má»™t vÃ i tÃ­nh cháº¥t quan trá»ng cá»§a CNN vÃ  Transformer. 1.1. TÃ­nh cháº¥t cá»§a CNN: - Translation Equivariance: Sá»± dá»‹ch chuyá»ƒn cá»§a má»™t váº­t thá»ƒ trÃªn áº£nh Ä‘áº§u vÃ o so vá»›i Ä‘áº§u ra lÃ  báº¥t biáº¿n trÃªn má»™t máº¡ng CNN. Nhá» tÃ­nh cháº¥t nÃ y mÃ  CNN cÃ³ thá»ƒ há»c tá»‘t hÆ¡n vá»›i Ã­t dá»¯ liá»‡u thÃ´ng qua Augumentation. - Local Receptive Field: CÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c CNN tá»•ng há»£p lÃ  dá»±a trÃªn cÃ¡c local region cá»§a áº£nh vÃ  nhá»¯ng Ä‘áº·c trÆ°ng nÃ y cÃ³ sá»± biáº¿n Ä‘á»•i theo Ä‘á»™ sÃ¢u. á» nhá»¯ng level Ä‘áº§u lÃ  nhá»¯ng Ä‘áº·c trÆ°ng báº­c tháº¥p mang tÃ­nh phá»• biáº¿n nhÆ° cÃ¡c nÃ©t dá»c, ngang, chÃ©o vÃ  Ä‘Æ°á»£c tá»•ng há»£p thÃ nh nhá»¯ng Ä‘áº·c trÆ°ng báº­c cao giÃºp nháº­n diá»‡n class á»Ÿ nhá»¯ng layer sÃ¢u hÆ¡n. 1.2. CÃ¡c tÃ­nh cháº¥t cá»§a Transformer: - Global context: Transformer ban Ä‘áº§u Ä‘Æ°á»£c xÃ¢y dá»±ng lÃ  cho sequential data cháº³ng háº¡n nhÆ° text data vá»›i core building block lÃ  Multi-head Attention. Nhá» Ä‘Ã³ nÃ³ cÃ³ kháº£ nÄƒng trÃ­ch xuáº¥t thÃ´ng tin global context ráº¥t tá»‘t. Má»™t feature token há»c Ä‘Æ°á»£c tá»« máº¡ng lÃ  Ä‘Æ°á»£c tá»•ng há»£p tá»« toÃ n bá»™ cÃ¡c patches trÃªn áº£nh. - Global Receptive Field: Transformer hoáº¡t Ä‘á»™ng nhÆ° má»™t Global Receptive Field trong khi CNN hoáº¡t Ä‘á»™ng dá»±a trÃªn Local Receptive Field. TÃ­nh cháº¥t nÃ y khiáº¿n Transformer cÃ³ xu hÆ°á»›ng dá»… gáº·p pháº£i overfitting vÃ¬ dá»¯ liá»‡u cá»§a báº¡n khi thá»±c hiá»‡n cÃ¡c Hard Augmentation nhÆ° Rotation vá»›i gÃ³c lá»›n, Random Shuffling, CutMix thÃ¬ Transformer váº«n cÃ³ thá»ƒ nháº­n ra Ä‘Æ°á»£c. ÄÃ³ cÅ©ng lÃ  nguyÃªn nhÃ¢n khiáº¿n Transformer sáº½ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n so vá»›i CNN khi huáº¥n luyá»‡n trÃªn cÃ¡c bá»™ dá»¯ liá»‡u kÃ­ch thÆ°á»›c cá»±c lá»›n (lÃªn tá»›i vÃ i trÄƒm triá»‡u images) nhÆ° ImageNet-21K, JFT-300M nhÆ°ng láº¡i kÃ©m hÆ¡n trÃªn ImageNet-1K (chá»‰ 1 triá»‡u images). - Layerâ€™s Features Similarity: CÃ¡c Ä‘áº·c trÆ°ng mÃ  Transformer há»c Ä‘Æ°á»£c cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a first layer vÃ  last layer, trong khi CNN thÃ¬ khÃ¡c biá»‡t máº¡nh giá»¯a chÃºng. 3. Ã tÆ°á»Ÿng cá»§a bÃ i bÃ¡o: Káº¿t há»£p Ä‘á»“ng thá»i cáº£ Convolution vÃ  Attention trong cÃ¹ng má»™t block vÃ  stack chÃºng trong má»™t end-to-end network. Khi Ã¡p dá»¥ng kiáº¿n trÃºc Transformer cÃ³ thá»ƒ khiáº¿n cho sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh tÄƒng lÃªn ráº¥t lá»›n. NhÆ° váº­y chi phÃ­ tÃ­nh toÃ¡n sáº½ Ä‘Æ°á»£c cÃ¢n nháº¯c trong thiáº¿t káº¿ cá»§a kiáº¿n trÃºc nÃ y. Má»™t sá»‘ Ä‘iá»u chá»‰nh Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n: â€¢ Downsampling Ä‘á»ƒ giáº£m thiá»ƒu parameters. â€¢ Háº¡n cháº¿ Attention trong Transformer vá» local region. â€¢ Thay tháº¿ GeLU báº±ng ReLU activation hoáº·c bá» bá»›t cÃ¡c Non-Linear Activation Ä‘á»ƒ giáº£m thiá»ƒu chi phÃ­ tÃ­nh toÃ¡n. Kiáº¿n trÃºc cuá»‘i cÃ¹ng: á» nhá»¯ng layers Ä‘áº§u lÃ  máº¡ng CNN cÃ³ tÃ¡c dá»¥ng trÃ­ch lá»c Ä‘áº·c trÆ°ng trÃªn local receptive field, nhá»¯ng layer cuá»‘i cÃ¹ng sá»­ dá»¥ng attention + feed forward. [Conv(3,3)] x 2 â†’ [Conv(1,1) +DConv(3,3)+Conv(1,1)] x L1â†’ [Conv(1,1) +DConv(3,3)+Conv(1,1)] x L2 â†’ [Rel-Attention + FFN] x L3 â†’ [Rel-Attention + FFN] x L4 â†’ Global Poolâ†’FC â†’ Output 4. Káº¿t quáº£: - Nhá» sá»± káº¿t há»£p vá»›i CNN mÃ  trÃªn nhá»¯ng bá»™ dá»¯ liá»‡u kÃ­ch thÆ°á»›c nhá» cÃ³ thá»ƒ vÆ°á»£t qua SOTA model lÃ  ViT. - Má»©c Ä‘á»™ cáº¡nh tranh so vá»›i cÃ¡c based CNN network cÃ³ cÃ¹ng kÃ­ch cá»¡ nhÆ° EfficientNet-V2, NFNets. - VÆ°á»£t xa há» cÃ¡c kiáº¿n trÃºc attentions based Nets. 5. Suy nghÄ© cá»§a tÃ´i: CoAtNet Ä‘Ã£ phÃ¡ vá»¡ cÃ¡c quan niá»‡m truyá»n thá»‘ng khi huáº¥n luyá»‡n cÃ¡c kiáº¿n trÃºc Transformer based trÃªn dá»¯ liá»‡u image Ä‘Ã³ lÃ  cáº§n dá»¯ liá»‡u lá»›n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c SOTA. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a quan trá»ng trong cÃ¡c dá»± Ã¡n thá»±c tiá»…n vÃ¬ khÃ´ng pháº£i khi nÃ o chÃºng ta cÅ©ng Ä‘á»§ vÃ i chá»¥c hay tháº­m chÃ­ vÃ i trÄƒm triá»‡u áº£nh Ä‘á»ƒ huáº¥n luyá»‡n. VÃ­ dá»¥ nhÆ° vá»›i dá»¯ liá»‡u tá»‘n kÃ©m chi phÃ­ gÃ¡n nhÃ£n nhÆ° xá»­ lÃ½ áº£nh y táº¿ cháº³ng háº¡n. Ã tÆ°á»Ÿng thiáº¿t káº¿ nhá»¯ng block káº¿t há»£p cáº£ Convolution vÃ  Attention cÃ³ thá»ƒ phÃ¹ há»£p vá»›i dá»¯ liá»‡u dáº¡ng hÃ¬nh áº£nh trong tÆ°Æ¡ng lai, thá»© mÃ  yÃªu cáº§u sá»± liÃªn káº¿t khÃ´ng gian 2 chiá»u cháº·t cháº½ hÆ¡n so vá»›i trÃªn vÄƒn báº£n.",,,,,
"[Label Studio â€“ 7.4k star*]
Label Studio lÃ  gÃ¬?
Label Studio lÃ  má»™t cÃ´ng cá»¥ label dá»¯ liá»‡u mÃ£ nguá»“n má»Ÿ. NÃ³ cho phÃ©p báº¡n gÃ¡n nhÃ£n cÃ¡c loáº¡i dá»¯ liá»‡u nhÆ° Ã¢m thanh, hÃ¬nh áº£nh, vÄƒn báº£n, video vÃ  chuá»—i thá»i gian vá»›i giao diá»‡n ngÆ°á»i dÃ¹ng Ä‘Æ¡n giáº£n, dá»… hiá»ƒu vÃ  dá»… dÃ ng xuáº¥t sang cÃ¡c Ä‘á»‹nh dáº¡ng mÃ´ hÃ¬nh khÃ¡c nhau.
Äáº·c biá»‡t, báº¡n cÃ³ thá»ƒ thiáº¿t láº­p mÃ´ hÃ¬nh Machine Learning vá»›i Label Studio hay tÃ­ch há»£p Label Studio vá»›i cÃ¡c cÃ´ng cá»¥ hiá»‡n cÃ³ cá»§a báº¡n.
Chi tiáº¿t má»i ngÆ°á»i xem thÃªm á»Ÿ Ä‘Ã¢y:
Web: https://labelstud.io/
Github: https://github.com/heartexlabs/label-studio","[Label Studio â€“ 7.4k star*] Label Studio lÃ  gÃ¬? Label Studio lÃ  má»™t cÃ´ng cá»¥ label dá»¯ liá»‡u mÃ£ nguá»“n má»Ÿ. NÃ³ cho phÃ©p báº¡n gÃ¡n nhÃ£n cÃ¡c loáº¡i dá»¯ liá»‡u nhÆ° Ã¢m thanh, hÃ¬nh áº£nh, vÄƒn báº£n, video vÃ  chuá»—i thá»i gian vá»›i giao diá»‡n ngÆ°á»i dÃ¹ng Ä‘Æ¡n giáº£n, dá»… hiá»ƒu vÃ  dá»… dÃ ng xuáº¥t sang cÃ¡c Ä‘á»‹nh dáº¡ng mÃ´ hÃ¬nh khÃ¡c nhau. Äáº·c biá»‡t, báº¡n cÃ³ thá»ƒ thiáº¿t láº­p mÃ´ hÃ¬nh Machine Learning vá»›i Label Studio hay tÃ­ch há»£p Label Studio vá»›i cÃ¡c cÃ´ng cá»¥ hiá»‡n cÃ³ cá»§a báº¡n. Chi tiáº¿t má»i ngÆ°á»i xem thÃªm á»Ÿ Ä‘Ã¢y: Web: https://labelstud.io/ Github: https://github.com/heartexlabs/label-studio",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, nhÃ¢n cÃ³ báº¡n há»i vá» xá»­ lÃ½ Image Message trong Chatbot nÃªn em xin máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ  luÃ´n.
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c cÃ¡ch Ä‘á»c áº£nh, Ä‘Æ°a qua model vÃ  tráº£ lá»i ngÆ°á»i dÃ¹ng.","KÃ­nh chÃ o cÃ¡c bÃ¡c, nhÃ¢n cÃ³ báº¡n há»i vá» xá»­ lÃ½ Image Message trong Chatbot nÃªn em xin máº¡nh dáº¡n chia sáº» cÃ¹ng cáº£ nhÃ  luÃ´n. Hi vá»ng giÃºp Ä‘Æ°á»£c anh em má»›i há»c cÃ¡ch Ä‘á»c áº£nh, Ä‘Æ°a qua model vÃ  tráº£ lá»i ngÆ°á»i dÃ¹ng.",,,,,
A weird Italian method to do programming,A weird Italian method to do programming,,,,,
"[AI News â€“ ConvNeXt]
Convolution is not dead: A ConvNet for the 2020s
Nhá»¯ng nÄƒm 2020, nháº­n dáº¡ng hÃ¬nh áº£nh báº¯t Ä‘áº§u bÃ¹ng ná»• vá»›i sá»± ra Ä‘á»i cá»§a Vision Transformers (ViT) nhanh chÃ³ng thay tháº¿ ConvNet, trá»Ÿ thÃ nh mÃ´ hÃ¬nh phÃ¢n loáº¡i hÃ¬nh áº£nh hiá»‡n Ä‘áº¡i nháº¥t.
Tuy nhiÃªn gáº§n Ä‘Ã¢y, má»™t nhÃ³m nghiÃªn cá»©u Ä‘Ã£ khÃ¡m phÃ¡ ra má»™t nhÃ³m cÃ¡c mÃ´ hÃ¬nh ConvNet thuáº§n tÃºy gá»i chung lÃ  ConvNeXt. ConvNeXt Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« cÃ¡c ConvNet tiÃªu chuáº©n, vÆ°á»£t trá»™i so vá»›i Transformers vá» Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng má»Ÿ rá»™ng, Ä‘áº¡t top 1 cá»§a Imagenet, vÆ°á»£t trá»™i hÆ¡n Swin Transformers vá» COCO detection vÃ  ADE20K segmentation nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c tÃ­nh Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ cá»§a ConvNets tiÃªu chuáº©n.
Code Pytorch triá»ƒn khai cá»§a ConvNeXt Ä‘Ã£ Ä‘Æ°á»£c Facebookresearch public.
Má»i ngÆ°á»i tham kháº£o thÃªm á»Ÿ Ä‘Ã¢y:
Paper: https://arxiv.org/abs/2201.03545
Github: https://github.com/facebookresearch/ConvNeXt
Youtube: https://www.youtube.com/watch?v=WvKsMI4Iemk","[AI News â€“ ConvNeXt] Convolution is not dead: A ConvNet for the 2020s Nhá»¯ng nÄƒm 2020, nháº­n dáº¡ng hÃ¬nh áº£nh báº¯t Ä‘áº§u bÃ¹ng ná»• vá»›i sá»± ra Ä‘á»i cá»§a Vision Transformers (ViT) nhanh chÃ³ng thay tháº¿ ConvNet, trá»Ÿ thÃ nh mÃ´ hÃ¬nh phÃ¢n loáº¡i hÃ¬nh áº£nh hiá»‡n Ä‘áº¡i nháº¥t. Tuy nhiÃªn gáº§n Ä‘Ã¢y, má»™t nhÃ³m nghiÃªn cá»©u Ä‘Ã£ khÃ¡m phÃ¡ ra má»™t nhÃ³m cÃ¡c mÃ´ hÃ¬nh ConvNet thuáº§n tÃºy gá»i chung lÃ  ConvNeXt. ConvNeXt Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« cÃ¡c ConvNet tiÃªu chuáº©n, vÆ°á»£t trá»™i so vá»›i Transformers vá» Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng má»Ÿ rá»™ng, Ä‘áº¡t top 1 cá»§a Imagenet, vÆ°á»£t trá»™i hÆ¡n Swin Transformers vá» COCO detection vÃ  ADE20K segmentation nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c tÃ­nh Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ cá»§a ConvNets tiÃªu chuáº©n. Code Pytorch triá»ƒn khai cá»§a ConvNeXt Ä‘Ã£ Ä‘Æ°á»£c Facebookresearch public. Má»i ngÆ°á»i tham kháº£o thÃªm á»Ÿ Ä‘Ã¢y: Paper: https://arxiv.org/abs/2201.03545 Github: https://github.com/facebookresearch/ConvNeXt Youtube: https://www.youtube.com/watch?v=WvKsMI4Iemk",,,,,
"ChÃ o mng!
Em Ä‘ang táº­p tÃ nh Deep Learning. Cá»¥ thá»ƒ em Ä‘ang code láº¡i U-Net vá»›i bá»™ dataset cÃ¡c táº¿ bÃ o. Em nháº­n tháº¥y Ä‘Ã¢y khÃ´ng pháº£i lÃ  bÃ i toÃ¡n phÃ¢n loáº¡i bÃ¬nh thÆ°á»ng nÃªn khÃ´ng thá»ƒ dÃ¹ng cÃ¡c loss function bth.
Cá»¥ thá»ƒ label cÃ³ 95% pixel thuá»™c class 1 (tráº¯ng) vÃ  5% thuá»™c class 0 (Ä‘en).
Náº¿u output layer lÃ  'Táº¥t cáº£ cÃ¡c pixel thuá»™c class 1' thÃ¬ accury lÃ  95%.
Mng Ä‘Ã£ tá»«ng lÃ m bÃ i toÃ¡n nÃ y Ä‘á» xuáº¥t cho em loss function phÃ¹ há»£p vá»›i áº¡.",ChÃ o mng! Em Ä‘ang táº­p tÃ nh Deep Learning. Cá»¥ thá»ƒ em Ä‘ang code láº¡i U-Net vá»›i bá»™ dataset cÃ¡c táº¿ bÃ o. Em nháº­n tháº¥y Ä‘Ã¢y khÃ´ng pháº£i lÃ  bÃ i toÃ¡n phÃ¢n loáº¡i bÃ¬nh thÆ°á»ng nÃªn khÃ´ng thá»ƒ dÃ¹ng cÃ¡c loss function bth. Cá»¥ thá»ƒ label cÃ³ 95% pixel thuá»™c class 1 (tráº¯ng) vÃ  5% thuá»™c class 0 (Ä‘en). Náº¿u output layer lÃ  'Táº¥t cáº£ cÃ¡c pixel thuá»™c class 1' thÃ¬ accury lÃ  95%. Mng Ä‘Ã£ tá»«ng lÃ m bÃ i toÃ¡n nÃ y Ä‘á» xuáº¥t cho em loss function phÃ¹ há»£p vá»›i áº¡.,,,,,
Má»™t thÆ° viá»‡n má»›i cÃ´ng bá»‘ giÃºp viá»‡c train models nhanh hÆ¡n ráº¥t nhiá»u mÃ  khÃ´ng lÃ m giáº£m accuracy quÃ¡ nhiá»u,Má»™t thÆ° viá»‡n má»›i cÃ´ng bá»‘ giÃºp viá»‡c train models nhanh hÆ¡n ráº¥t nhiá»u mÃ  khÃ´ng lÃ m giáº£m accuracy quÃ¡ nhiá»u,,,,,
"Petar VeliÄkoviÄ‡ lÃ  ngÃ´i sao Ä‘ang lÃªn trong lÄ©nh vá»±c nghiÃªn cá»©u Graph Neural Networks. Hiá»‡n anh Ä‘ang lÃ m viá»‡c táº¡i DeepMind. DÆ°á»›i Ä‘Ã¢y lÃ  bÃ i giáº£ng giá»›i thiá»‡u vá» GNN kÃ¨m theo bÃ i táº­p trong colab. LÆ°u Ã½: láº§n nÃ y code sá»­ dá»¥ng TensorFlow
BÃ i giáº£ng trÃªn YouTube táº¡i Ä‘Ã¢y â†’ goo.gle/3rt4l1B",Petar VeliÄkoviÄ‡ lÃ  ngÃ´i sao Ä‘ang lÃªn trong lÄ©nh vá»±c nghiÃªn cá»©u Graph Neural Networks. Hiá»‡n anh Ä‘ang lÃ m viá»‡c táº¡i DeepMind. DÆ°á»›i Ä‘Ã¢y lÃ  bÃ i giáº£ng giá»›i thiá»‡u vá» GNN kÃ¨m theo bÃ i táº­p trong colab. LÆ°u Ã½: láº§n nÃ y code sá»­ dá»¥ng TensorFlow BÃ i giáº£ng trÃªn YouTube táº¡i Ä‘Ã¢y â†’ goo.gle/3rt4l1B,,,,,
"[SHARING - DOCKER FOR MACHINE LEARNING / DATA SCIENCE PROJECT]
Hello má»i ngÆ°á»i, tuy nhá»¯ng cÃ´ng viá»‡c liÃªn quan tá»›i Develop & Operation thÆ°á»ng sáº½ cho team DevOps phá»¥ trÃ¡ch nhÆ°ng á»Ÿ má»™t vÃ i cÃ´ng ty váº«n yÃªu cáº§u AI engineer vÃ  Data Scientist pháº£i biáº¿t nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n vá» Docker Ä‘á»ƒ deploy project. 
Trong quÃ¡ trÃ¬nh tá»± há»c vá» Docker, mÃ¬nh tháº¥y ráº¥t Ã­t tÃ i liá»‡u hÆ°á»›ng dáº«n Docker dÃ nh riÃªng cho Data Scientist, nÃªn trong quÃ¡ trÃ¬nh vá»«a há»c vá»«a lÃ m mÃ¬nh cÃ³ record láº¡i Ä‘á»ƒ cÃ¡c báº¡n bÃªn AI / DS cÃ³ thá»ƒ tiáº¿p cáº­n Docker 1 cÃ¡ch dá»… dÃ ng. 

link-github:  https://github.com/DatacollectorVN/Docker-Tutorial

p/s 1: MÃ¬nh sáº½ liÃªn tá»¥c update nhá»¯ng mini project tiáº¿p vá» Docker lÃªn repo. 
p/s 2: NÃ y cÅ©ng chá»‰ lÃ  quÃ¡ trÃ¬nh mÃ¬nh vá»«a lÃ m vá»«a há»c vÃ  record láº¡i nÃªn sáº½ cÃ³ chá»— mÃ¬nh hiá»ƒu sai, ráº¥t mong nháº­n Ä‘Æ°á»£c feedback cá»§a má»i ngÆ°á»i.","[SHARING - DOCKER FOR MACHINE LEARNING / DATA SCIENCE PROJECT] Hello má»i ngÆ°á»i, tuy nhá»¯ng cÃ´ng viá»‡c liÃªn quan tá»›i Develop & Operation thÆ°á»ng sáº½ cho team DevOps phá»¥ trÃ¡ch nhÆ°ng á»Ÿ má»™t vÃ i cÃ´ng ty váº«n yÃªu cáº§u AI engineer vÃ  Data Scientist pháº£i biáº¿t nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n vá» Docker Ä‘á»ƒ deploy project. Trong quÃ¡ trÃ¬nh tá»± há»c vá» Docker, mÃ¬nh tháº¥y ráº¥t Ã­t tÃ i liá»‡u hÆ°á»›ng dáº«n Docker dÃ nh riÃªng cho Data Scientist, nÃªn trong quÃ¡ trÃ¬nh vá»«a há»c vá»«a lÃ m mÃ¬nh cÃ³ record láº¡i Ä‘á»ƒ cÃ¡c báº¡n bÃªn AI / DS cÃ³ thá»ƒ tiáº¿p cáº­n Docker 1 cÃ¡ch dá»… dÃ ng. link-github: https://github.com/DatacollectorVN/Docker-Tutorial p/s 1: MÃ¬nh sáº½ liÃªn tá»¥c update nhá»¯ng mini project tiáº¿p vá» Docker lÃªn repo. p/s 2: NÃ y cÅ©ng chá»‰ lÃ  quÃ¡ trÃ¬nh mÃ¬nh vá»«a lÃ m vá»«a há»c vÃ  record láº¡i nÃªn sáº½ cÃ³ chá»— mÃ¬nh hiá»ƒu sai, ráº¥t mong nháº­n Ä‘Æ°á»£c feedback cá»§a má»i ngÆ°á»i.",,,,,
"Em chÃ o mn áº¡, mn ai cÃ³ kinh nghiá»‡m giÃºp e vá»›iğŸ˜„
MÃ´ hÃ¬nh CNN cá»§a e gáº·p pháº£i hiá»‡n tÆ°á»£ng lÃ  luÃ´n dá»± Ä‘oÃ¡n táº¥t cáº£ cÃ¡c class vÃ o má»™t class duy nháº¥t. Tá»©c lÃ  náº¿u e train nháº­n diá»‡n 5 class thÃ¬ mÃ´ hÃ¬nh luÃ´n dá»± Ä‘oÃ¡n nÃ³ lÃ  class 1.
- E Ä‘Ã£ kiá»ƒm tra vÃ  cháº¯c cháº¯n viá»‡c load dá»¯ liá»‡u, tiá»n xá»­ lÃ­ dá»¯ liá»‡u lÃ  Ä‘Ãºng, nhÃ£n vÃ  dá»¯ liá»‡u cÅ©ng Ä‘Ã£ tÆ°Æ¡ng á»©ng
- hÃ m loss e chá»n lÃ  categorical_crossentropy
- layer Dense cuá»‘i cÃ¹ng Ä‘Ã£ Ä‘Ãºng sá»‘ unit Ä‘áº§u ra (activation function lÃ  softmax)
- e cÅ©ng Ä‘Ã£ thá»­ 1 sá»‘ loáº¡i khá»Ÿi táº¡o khÃ¡c nhau vÃ  cÃ¡c activation function khÃ¡c nhau á»Ÿ cÃ¡c layer Ä‘á»ƒ cháº¯c cháº¯n k pháº£i do viá»‡c khá»Ÿi táº¡o ban Ä‘áº§u (hoáº·c do dying ReLU,..)
-learning rate e cÅ©ng Ä‘Ã£ thá»­ nhá»¯ng giÃ¡ trá»‹ tá»« ráº¥t nhá» cho Ä‘áº¿n ráº¥t lá»›n (1e-1 Ä‘áº¿n 1e-9) Ä‘á»ƒ Ä‘áº£m báº£o k pháº£i do váº¥n Ä‘á» lá»±a chá»n lr ğŸ˜
- sá»‘ lÆ°á»£ng data cá»§a má»—i class lÃ  nhÆ° nhau
- bonus thÃªm lÃ  náº¿u e giá»¯ nguyÃªn Ä‘áº§u ra lÃ  5 units (phÃ¢n loáº¡i 5 class) vÃ  chá»‰ cho mÃ´ hÃ¬nh há»c dá»¯ liá»‡u cá»§a má»™t class báº¥t kÃ¬ 1,3,5,..) thÃ¬ mÃ´ hÃ¬nh láº¡i dá»± Ä‘oÃ¡n Ä‘Ãºng
- e cÅ©ng Ä‘Ã£ thá»­ thay Ä‘á»•i batch_size vÃ  thuáº­t toÃ¡n tá»‘i Æ°u (Adam, SGD) nhÆ°ng káº¿t quáº£ váº«n k khÃ¡c
- framework e sá»­ dá»¥ng lÃ  keras
- mÃ´ hÃ¬nh nÃ y lÃ  e tham kháº£o vÃ  tÃ¡c giáº£ cá»§a mÃ´ hÃ¬nh Ä‘Ã£ cháº¡y Ä‘c nÃ³ vá»›i cÃ¹ng bá»™ dá»¯ liá»‡u (sá»‘ class nhiá»u hÆ¡n) vÃ  cho káº¿t quáº£ tá»‘t (e cÃ³ mail há»i tÃ¡c giáº£ nhÆ°ng chÆ°a Ä‘c reply :)))
ğŸ˜”E check cáº£ tuáº§n nay mÃ  chÆ°a thÃ nh cÃ´ng rá»“i áº¡. E cáº£m Æ¡n mn nhiá»u","Em chÃ o mn áº¡, mn ai cÃ³ kinh nghiá»‡m giÃºp e vá»›i MÃ´ hÃ¬nh CNN cá»§a e gáº·p pháº£i hiá»‡n tÆ°á»£ng lÃ  luÃ´n dá»± Ä‘oÃ¡n táº¥t cáº£ cÃ¡c class vÃ o má»™t class duy nháº¥t. Tá»©c lÃ  náº¿u e train nháº­n diá»‡n 5 class thÃ¬ mÃ´ hÃ¬nh luÃ´n dá»± Ä‘oÃ¡n nÃ³ lÃ  class 1. - E Ä‘Ã£ kiá»ƒm tra vÃ  cháº¯c cháº¯n viá»‡c load dá»¯ liá»‡u, tiá»n xá»­ lÃ­ dá»¯ liá»‡u lÃ  Ä‘Ãºng, nhÃ£n vÃ  dá»¯ liá»‡u cÅ©ng Ä‘Ã£ tÆ°Æ¡ng á»©ng - hÃ m loss e chá»n lÃ  categorical_crossentropy - layer Dense cuá»‘i cÃ¹ng Ä‘Ã£ Ä‘Ãºng sá»‘ unit Ä‘áº§u ra (activation function lÃ  softmax) - e cÅ©ng Ä‘Ã£ thá»­ 1 sá»‘ loáº¡i khá»Ÿi táº¡o khÃ¡c nhau vÃ  cÃ¡c activation function khÃ¡c nhau á»Ÿ cÃ¡c layer Ä‘á»ƒ cháº¯c cháº¯n k pháº£i do viá»‡c khá»Ÿi táº¡o ban Ä‘áº§u (hoáº·c do dying ReLU,..) -learning rate e cÅ©ng Ä‘Ã£ thá»­ nhá»¯ng giÃ¡ trá»‹ tá»« ráº¥t nhá» cho Ä‘áº¿n ráº¥t lá»›n (1e-1 Ä‘áº¿n 1e-9) Ä‘á»ƒ Ä‘áº£m báº£o k pháº£i do váº¥n Ä‘á» lá»±a chá»n lr - sá»‘ lÆ°á»£ng data cá»§a má»—i class lÃ  nhÆ° nhau - bonus thÃªm lÃ  náº¿u e giá»¯ nguyÃªn Ä‘áº§u ra lÃ  5 units (phÃ¢n loáº¡i 5 class) vÃ  chá»‰ cho mÃ´ hÃ¬nh há»c dá»¯ liá»‡u cá»§a má»™t class báº¥t kÃ¬ 1,3,5,..) thÃ¬ mÃ´ hÃ¬nh láº¡i dá»± Ä‘oÃ¡n Ä‘Ãºng - e cÅ©ng Ä‘Ã£ thá»­ thay Ä‘á»•i batch_size vÃ  thuáº­t toÃ¡n tá»‘i Æ°u (Adam, SGD) nhÆ°ng káº¿t quáº£ váº«n k khÃ¡c - framework e sá»­ dá»¥ng lÃ  keras - mÃ´ hÃ¬nh nÃ y lÃ  e tham kháº£o vÃ  tÃ¡c giáº£ cá»§a mÃ´ hÃ¬nh Ä‘Ã£ cháº¡y Ä‘c nÃ³ vá»›i cÃ¹ng bá»™ dá»¯ liá»‡u (sá»‘ class nhiá»u hÆ¡n) vÃ  cho káº¿t quáº£ tá»‘t (e cÃ³ mail há»i tÃ¡c giáº£ nhÆ°ng chÆ°a Ä‘c reply :))) E check cáº£ tuáº§n nay mÃ  chÆ°a thÃ nh cÃ´ng rá»“i áº¡. E cáº£m Æ¡n mn nhiá»u",,,,,
"CÃ³ ai lÃ m á»Ÿ Google cho e há»i vá»›i :D
LÃ m tháº¿ nÃ o Ä‘á»ƒ google lens phÃ¢n biá»‡t Ä‘Æ°á»£c khi nÃ o query_image lÃ  má»™t object, 1 loáº¡i animal, hay má»™t landmark nÃ o Ä‘Ã³? CÃ³ pháº£i Google dÃ¹ng google graph knowledge hay domain classification Ä‘á»ƒ lÃ m viá»‡c nÃ y?","CÃ³ ai lÃ m á»Ÿ Google cho e há»i vá»›i :D LÃ m tháº¿ nÃ o Ä‘á»ƒ google lens phÃ¢n biá»‡t Ä‘Æ°á»£c khi nÃ o query_image lÃ  má»™t object, 1 loáº¡i animal, hay má»™t landmark nÃ o Ä‘Ã³? CÃ³ pháº£i Google dÃ¹ng google graph knowledge hay domain classification Ä‘á»ƒ lÃ m viá»‡c nÃ y?",,,,,
"Em chÃ o má»i ngÆ°á»i,
Em lÃ  sv nÄƒm nháº¥t ngÃ nh khmt, em muá»‘n há»i lÃ  há»c ML nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡, Ä‘Ã£ cÃ³ báº¡n trong group há»i nÃªn báº¯t Ä‘áº§u ntn rá»“i nhÆ°ng cÃ¢u tráº£ lá»i lÃ  há»c cÃ¡c mÃ´n giáº£i tÃ­ch, dstt, xstk nhÆ°ng chÆ°a ai nÃ³i vá» viá»‡c sau khi há»c nhá»¯ng ná»n táº£ng Ä‘Ã³ thÃ¬ nÃªn tiáº¿p tá»¥c há»c gÃ¬ áº¡ nÃªn em muá»‘n há»i
Sau khi mÃ¬nh há»c cÃ¡c mÃ´n vá» toÃ¡n rá»“i thÃ¬ mÃ¬nh nÃªn kiáº¿m nguá»“n tÃ i liá»‡u nÃ o Ä‘á»ƒ há»c tiáº¿p áº¡
Em cáº£m Æ¡n mng","Em chÃ o má»i ngÆ°á»i, Em lÃ  sv nÄƒm nháº¥t ngÃ nh khmt, em muá»‘n há»i lÃ  há»c ML nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡, Ä‘Ã£ cÃ³ báº¡n trong group há»i nÃªn báº¯t Ä‘áº§u ntn rá»“i nhÆ°ng cÃ¢u tráº£ lá»i lÃ  há»c cÃ¡c mÃ´n giáº£i tÃ­ch, dstt, xstk nhÆ°ng chÆ°a ai nÃ³i vá» viá»‡c sau khi há»c nhá»¯ng ná»n táº£ng Ä‘Ã³ thÃ¬ nÃªn tiáº¿p tá»¥c há»c gÃ¬ áº¡ nÃªn em muá»‘n há»i Sau khi mÃ¬nh há»c cÃ¡c mÃ´n vá» toÃ¡n rá»“i thÃ¬ mÃ¬nh nÃªn kiáº¿m nguá»“n tÃ i liá»‡u nÃ o Ä‘á»ƒ há»c tiáº¿p áº¡ Em cáº£m Æ¡n mng",,,,,
"ChÃ o cÃ¡c anh cÃ¡c chá»‹, cháº£ lÃ  em Ä‘ang cÃ³ 1 bá»™ dá»¯ liá»‡u áº£nh vá»›i 2 class vÃ  em Ä‘ang muá»‘n sá»­ dá»¥ng t-sne Ä‘á»ƒ phÃ¢n tÃ­ch, xem 2 class cÃ³ khÃ¡c nhau quÃ¡ khÃ´ng; nhÆ°ng em váº«n chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nÃªn má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em cÃ¡c bÆ°á»›c lÃ m Ä‘Æ°á»£c khÃ´ng áº¡?
Em cáº£m Æ¡n","ChÃ o cÃ¡c anh cÃ¡c chá»‹, cháº£ lÃ  em Ä‘ang cÃ³ 1 bá»™ dá»¯ liá»‡u áº£nh vá»›i 2 class vÃ  em Ä‘ang muá»‘n sá»­ dá»¥ng t-sne Ä‘á»ƒ phÃ¢n tÃ­ch, xem 2 class cÃ³ khÃ¡c nhau quÃ¡ khÃ´ng; nhÆ°ng em váº«n chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nÃªn má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em cÃ¡c bÆ°á»›c lÃ m Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n",,,,,
#hyperparameters,,#hyperparameters,,,,
"Em chÃ o má»i ngÆ°á»i ,tháº§y Ä‘Æ°a cho slide thuáº­t toÃ¡n kmeans vÃ  cho bÃ i táº­p nÃ y áº¡, em chÆ°a biáº¿t cÃ¡ch giáº£i quyáº¿t tháº¿ nÃ o má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em nhÆ° tháº¿ nÃ o vá»›i áº¡. Em cáº£m Æ¡n
PhÃ¢n cá»¥m dá»¯ liá»‡u vá»›i báº£ng dá»¯ liá»‡u dÆ°á»›i Ä‘Ã¢y","Em chÃ o má»i ngÆ°á»i ,tháº§y Ä‘Æ°a cho slide thuáº­t toÃ¡n kmeans vÃ  cho bÃ i táº­p nÃ y áº¡, em chÆ°a biáº¿t cÃ¡ch giáº£i quyáº¿t tháº¿ nÃ o má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em nhÆ° tháº¿ nÃ o vá»›i áº¡. Em cáº£m Æ¡n PhÃ¢n cá»¥m dá»¯ liá»‡u vá»›i báº£ng dá»¯ liá»‡u dÆ°á»›i Ä‘Ã¢y",,,,,
"Xin chÃ o má»i ngÆ°á»i, em hiá»‡n Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u vÃª sá»‘ ca nhiá»…m Covid háº±ng ngÃ y vÃ  táº­p dá»¯ liá»‡u tá»•ng sá»‘ lÆ°á»£t tiÃªm váº¯c xin tá»« trÆ°á»›c Ä‘áº¿n nay háº±ng ngÃ y. Em muá»‘n tÃ¬m má»‘i quan há»‡ giá»¯a hai táº­p dá»¯ liá»‡u trÃªn Ä‘á»ƒ mÃ´ táº£ sá»± áº£nh hÆ°á»Ÿng cá»§a sá»‘ lÆ°á»£t tiÃªm váº¯c xin Ä‘áº¿n sá»‘ ca nhiá»…m, má»i ngÆ°á»i cho em há»i cÃ³ bá»™ Ä‘o hay mÃ´ hÃ¬nh nÃ o Ä‘á»ƒ diá»…n Ä‘áº¡t má»‘i quan há»‡ trÃªn khÃ´ng áº¡, em xin cáº£m Æ¡n.","Xin chÃ o má»i ngÆ°á»i, em hiá»‡n Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u vÃª sá»‘ ca nhiá»…m Covid háº±ng ngÃ y vÃ  táº­p dá»¯ liá»‡u tá»•ng sá»‘ lÆ°á»£t tiÃªm váº¯c xin tá»« trÆ°á»›c Ä‘áº¿n nay háº±ng ngÃ y. Em muá»‘n tÃ¬m má»‘i quan há»‡ giá»¯a hai táº­p dá»¯ liá»‡u trÃªn Ä‘á»ƒ mÃ´ táº£ sá»± áº£nh hÆ°á»Ÿng cá»§a sá»‘ lÆ°á»£t tiÃªm váº¯c xin Ä‘áº¿n sá»‘ ca nhiá»…m, má»i ngÆ°á»i cho em há»i cÃ³ bá»™ Ä‘o hay mÃ´ hÃ¬nh nÃ o Ä‘á»ƒ diá»…n Ä‘áº¡t má»‘i quan há»‡ trÃªn khÃ´ng áº¡, em xin cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, em má»›i chá»‰ báº¯t Ä‘áº§u há»c vá» ML vÃ  Ä‘ang thá»­ lÃ m 1 project deepfake vá» nÃ³. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em há»i, em Ä‘ang tham kháº£o tÃ i liá»‡u trÃªn git trong file model.th. CÃ³ pháº£i file nÃ y Ä‘Ã£ Ä‘Æ°á»£c train rá»“i khÃ´ng áº¡(hÃ¬nh bÃªn pháº£i lÃ  file em má»Ÿ báº±ng notepad)? Em cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c mÃ´ hÃ¬nh gá»‘c cá»§a file nÃ y Ä‘á»ƒ mÃ¬nh tá»± train khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, em má»›i chá»‰ báº¯t Ä‘áº§u há»c vá» ML vÃ  Ä‘ang thá»­ lÃ m 1 project deepfake vá» nÃ³. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em há»i, em Ä‘ang tham kháº£o tÃ i liá»‡u trÃªn git trong file model.th. CÃ³ pháº£i file nÃ y Ä‘Ã£ Ä‘Æ°á»£c train rá»“i khÃ´ng áº¡(hÃ¬nh bÃªn pháº£i lÃ  file em má»Ÿ báº±ng notepad)? Em cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c mÃ´ hÃ¬nh gá»‘c cá»§a file nÃ y Ä‘á»ƒ mÃ¬nh tá»± train khÃ´ng áº¡?",,,,,
"[MaSSP 2022 TUYá»‚N MENTORS]
Ra Ä‘á»i tá»« nÄƒm 2016, tráº£i qua 6 nÄƒm hoáº¡t Ä‘á»™ng, MaSSP luÃ´n tá»± hÃ o lÃ  má»™t trong nhá»¯ng tráº¡i hÃ¨ Ä‘Æ°á»£c yÃªu thÃ­ch nháº¥t dÃ nh cho cÃ¡c báº¡n tráº» yÃªu khoa há»c. Äá»ƒ táº¡o nÃªn thÃ nh cÃ´ng cá»§a MaSSP ngÃ y hÃ´m nay, khÃ´ng thá»ƒ thiáº¿u vai trÃ² cá»§a cÃ¡c mentor - nhá»¯ng ngÆ°á»i trá»±c tiáº¿p giáº£ng dáº¡y, truyá»n Ä‘am mÃª khoa há»c cho cÃ¡c báº¡n há»c sinh. Há» chÃ­nh lÃ  nhá»¯ng ngá»n háº£i Ä‘Äƒng, soi sÃ¡ng vÃ  dáº«n Ä‘Æ°á»ng cho nhá»¯ng con thuyá»n bÄƒng ra biá»ƒn lá»›n.
Äá»‘i vá»›i tráº¡i hÃ¨ nÄƒm nay, BTC MaSSP 2022 chÃ­nh thá»©c thÃ´ng bÃ¡o tuyá»ƒn mentor Ä‘á»‘i vá»›i 2 mÃ´n há»c: Data Science vÃ  Architecture.
Chi tiáº¿t Ä‘Æ¡n á»©ng tuyá»ƒn vÃ  JD cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n truy cáº­p bÃ i viáº¿t phÃ­a dÆ°á»›i áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i!","[MaSSP 2022 TUYá»‚N MENTORS] Ra Ä‘á»i tá»« nÄƒm 2016, tráº£i qua 6 nÄƒm hoáº¡t Ä‘á»™ng, MaSSP luÃ´n tá»± hÃ o lÃ  má»™t trong nhá»¯ng tráº¡i hÃ¨ Ä‘Æ°á»£c yÃªu thÃ­ch nháº¥t dÃ nh cho cÃ¡c báº¡n tráº» yÃªu khoa há»c. Äá»ƒ táº¡o nÃªn thÃ nh cÃ´ng cá»§a MaSSP ngÃ y hÃ´m nay, khÃ´ng thá»ƒ thiáº¿u vai trÃ² cá»§a cÃ¡c mentor - nhá»¯ng ngÆ°á»i trá»±c tiáº¿p giáº£ng dáº¡y, truyá»n Ä‘am mÃª khoa há»c cho cÃ¡c báº¡n há»c sinh. Há» chÃ­nh lÃ  nhá»¯ng ngá»n háº£i Ä‘Äƒng, soi sÃ¡ng vÃ  dáº«n Ä‘Æ°á»ng cho nhá»¯ng con thuyá»n bÄƒng ra biá»ƒn lá»›n. Äá»‘i vá»›i tráº¡i hÃ¨ nÄƒm nay, BTC MaSSP 2022 chÃ­nh thá»©c thÃ´ng bÃ¡o tuyá»ƒn mentor Ä‘á»‘i vá»›i 2 mÃ´n há»c: Data Science vÃ  Architecture. Chi tiáº¿t Ä‘Æ¡n á»©ng tuyá»ƒn vÃ  JD cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n truy cáº­p bÃ i viáº¿t phÃ­a dÆ°á»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"ChÃ o cÃ¡c anh chá»‹, em hiá»‡n Ä‘ang báº¯t Ä‘áº§u nghiÃªn cá»©u vá» Text mining Ä‘Ã¡nh giÃ¡ sá»± thÃ nh cÃ´ng cá»§a cÃ¡c Tiá»n áº£o thÃ´ng qua cÃ¡c Whitepaper (Em chá»‰ lÃ m phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p). Em cÃ³ tÃ¬m hiá»ƒu nhÆ°ng tháº¥y cÃ³ khÃ¡ Ã­t cÃ¡c tÃ i liá»‡u liÃªn quan. Em khÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o Ä‘Ã£ vÃ  Ä‘ang nghiÃªn cá»©u máº£ng nÃ y cÃ³ thá»ƒ cho em liÃªn há»‡ Ä‘á»ƒ há»c há»i khÃ´ng áº¡? Em xin cáº£m Æ¡n áº¡!","ChÃ o cÃ¡c anh chá»‹, em hiá»‡n Ä‘ang báº¯t Ä‘áº§u nghiÃªn cá»©u vá» Text mining Ä‘Ã¡nh giÃ¡ sá»± thÃ nh cÃ´ng cá»§a cÃ¡c Tiá»n áº£o thÃ´ng qua cÃ¡c Whitepaper (Em chá»‰ lÃ m phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p). Em cÃ³ tÃ¬m hiá»ƒu nhÆ°ng tháº¥y cÃ³ khÃ¡ Ã­t cÃ¡c tÃ i liá»‡u liÃªn quan. Em khÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o Ä‘Ã£ vÃ  Ä‘ang nghiÃªn cá»©u máº£ng nÃ y cÃ³ thá»ƒ cho em liÃªn há»‡ Ä‘á»ƒ há»c há»i khÃ´ng áº¡? Em xin cáº£m Æ¡n áº¡!",,,,,
"[Face Anti-Spoofing][Dataset]

Báº¡n nÃ o nghiÃªn cá»©u vá» Face Anti-Spoofing hoáº·c cÃ¡c topic liÃªn quan cÃ³ thá»ƒ tham kháº£o bá»™ dataset má»›i nÃ y (CelebA-Spoof). Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn dataset CelebA ( giá»›i thiá»‡u trong ""Deep Learning Face Attributes in the Wild""; ICCV 2015)

CelebA-Spoof bao gá»“m 625,000++ áº£nh cá»§a 10 000 ngÆ°á»i. Hy vá»ng sáº½ lÃ  nguá»“n dá»¯ liá»‡u tá»‘t cho cÃ¡c báº¡n tham kháº£o vÃ  nghiÃªn cá»©u.

Link Google Drive: https://drive.google.com/drive/folders/1OW_1bawO79pRqdVEVmBzp8HSxdSwln_Z

Link paper: ""CelebA-Spoof: Large-Scale Face Anti-Spoofing Dataset with Rich Annotations""; ECCV 2020
 https://arxiv.org/pdf/2007.12342.pdf","[Face Anti-Spoofing][Dataset] Báº¡n nÃ o nghiÃªn cá»©u vá» Face Anti-Spoofing hoáº·c cÃ¡c topic liÃªn quan cÃ³ thá»ƒ tham kháº£o bá»™ dataset má»›i nÃ y (CelebA-Spoof). Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn dataset CelebA ( giá»›i thiá»‡u trong ""Deep Learning Face Attributes in the Wild""; ICCV 2015) CelebA-Spoof bao gá»“m 625,000++ áº£nh cá»§a 10 000 ngÆ°á»i. Hy vá»ng sáº½ lÃ  nguá»“n dá»¯ liá»‡u tá»‘t cho cÃ¡c báº¡n tham kháº£o vÃ  nghiÃªn cá»©u. Link Google Drive: https://drive.google.com/drive/folders/1OW_1bawO79pRqdVEVmBzp8HSxdSwln_Z Link paper: ""CelebA-Spoof: Large-Scale Face Anti-Spoofing Dataset with Rich Annotations""; ECCV 2020 https://arxiv.org/pdf/2007.12342.pdf",,,,,
"#PCA
Em chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang cÃ³ bÃ i táº­p vá» tÃ¬m PC1 vÃ  variance nhÆ° hÃ¬nh dÆ°á»›i vá»›i covariance cho trÆ°á»›c khÃ´ng biáº¿t lÃ  Ä‘á» cÃ³ nháº§m láº«n gÃ¬ khÃ´ng, viá»‡c tÃ¬m variance thÃ¬ khÃ´ng cÃ³ gÃ¬ Ä‘áº·c biá»‡t nhÆ°ng vá»›i viá»‡c tÃ­nh PC1 thÃ¬ em ko tÃ¬m ra giáº£i phÃ¡p nÃ o tá»‘t Ä‘Æ°á»£c khi khÃ´ng cÃ³ features matrix cÃ³ ai cÃ³ giáº£i phÃ¡p nÃ o giÃºp em khÃ´ng áº¡ ? em xin cáº£m Æ¡n má»i ngÆ°á»i giÃºp Ä‘á»¡","Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang cÃ³ bÃ i táº­p vá» tÃ¬m PC1 vÃ  variance nhÆ° hÃ¬nh dÆ°á»›i vá»›i covariance cho trÆ°á»›c khÃ´ng biáº¿t lÃ  Ä‘á» cÃ³ nháº§m láº«n gÃ¬ khÃ´ng, viá»‡c tÃ¬m variance thÃ¬ khÃ´ng cÃ³ gÃ¬ Ä‘áº·c biá»‡t nhÆ°ng vá»›i viá»‡c tÃ­nh PC1 thÃ¬ em ko tÃ¬m ra giáº£i phÃ¡p nÃ o tá»‘t Ä‘Æ°á»£c khi khÃ´ng cÃ³ features matrix cÃ³ ai cÃ³ giáº£i phÃ¡p nÃ o giÃºp em khÃ´ng áº¡ ? em xin cáº£m Æ¡n má»i ngÆ°á»i giÃºp Ä‘á»¡",#PCA,,,,
"ChÃ o buá»•i tá»‘i cÃ¡c bÃ¡c! HÃ´m nay em Ä‘á»•i mÃ³n tÃ¬m hiá»ƒu vá» DevOps nÃªn máº¡nh dáº¡n giá»›i thiá»‡u vá»›i anh em má»™t chÃºt vá» DevOps pipeline dÃ¹ng Ä‘á»ƒ triá»ƒn khai vá»›i cÃ¡c baid toÃ¡n Python , ML . Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em má»›i há»c.","ChÃ o buá»•i tá»‘i cÃ¡c bÃ¡c! HÃ´m nay em Ä‘á»•i mÃ³n tÃ¬m hiá»ƒu vá» DevOps nÃªn máº¡nh dáº¡n giá»›i thiá»‡u vá»›i anh em má»™t chÃºt vá» DevOps pipeline dÃ¹ng Ä‘á»ƒ triá»ƒn khai vá»›i cÃ¡c baid toÃ¡n Python , ML . Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c anh em má»›i há»c.",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» Attention áº¡. Tuy nhiÃªn thÃ¬ cÃ³ má»™t chá»— em tháº¯c máº¯c lÃ  bÆ°á»›c tÃ¬m sá»± tÆ°Æ¡ng quan . VÃ­ dá»¥ nhÆ° trong cÃ¢u "" I study at school"" thÃ¬ viá»‡c xÃ©t sá»± tÆ°Æ¡ng quan giá»¯a nhá»¯ng tá»« trong cÃ¢u rá»“i Ä‘Ã¡nh trá»ng sá»‘ cao dá»±a theo tiÃªu chÃ­ nÃ o váº­y áº¡? HÆ¡n ná»¯a, em muá»‘n hiá»ƒu rÃµ Ã½ nghÄ©a cá»§a cÃ¡c ma tráº­n Q,K,V lÃ  gÃ¬ áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n !!!","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» Attention áº¡. Tuy nhiÃªn thÃ¬ cÃ³ má»™t chá»— em tháº¯c máº¯c lÃ  bÆ°á»›c tÃ¬m sá»± tÆ°Æ¡ng quan . VÃ­ dá»¥ nhÆ° trong cÃ¢u "" I study at school"" thÃ¬ viá»‡c xÃ©t sá»± tÆ°Æ¡ng quan giá»¯a nhá»¯ng tá»« trong cÃ¢u rá»“i Ä‘Ã¡nh trá»ng sá»‘ cao dá»±a theo tiÃªu chÃ­ nÃ o váº­y áº¡? HÆ¡n ná»¯a, em muá»‘n hiá»ƒu rÃµ Ã½ nghÄ©a cá»§a cÃ¡c ma tráº­n Q,K,V lÃ  gÃ¬ áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n !!!",,,,,
"Khi nÃ o nÃªn há»c Machine Learning ???
Em chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang lÃ  SV nÄƒm 1 ngÃ nh KHMT.
á» kÃ¬ Ä‘áº§u tiÃªn thÃ¬ em cÃ³ há»c á»Ÿ trÆ°á»ng vá» Intro Python, Intro C, giáº£i tÃ­ch 1 vÃ  Program Design - Abstraction (Java) + giáº£i tÃ­ch 2 (sem 2 nÄƒm 1)
Em cÃ³ thá»­ Ä‘á»c qua 1 sá»‘ tÃ i liá»‡u vá» Machine Learning nhÆ° quyá»ƒn ML Yearning nhÆ°ng em tháº¥y nÃ³ khÃ¡ náº·ng vá»›i ná»n táº£ng hiá»‡n táº¡i em há»c.
Cho em há»i cÃ¡c anh chá»‹ Ä‘Ã£ há»c Deep Learning, Machine Learning vÃ  AI thÃ¬ thÆ°á»ng pathway cá»§a anh chá»‹ lÃ  tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p thu hiá»‡u quáº£ há»c pháº§n nÃ y khÃ´ng. CÅ©ng nhÆ° trong 3 cÃ¡i trÃªn thÃ¬ nÃªn tiáº¿p cáº­n máº£ng nÃ o Ä‘áº§u tiÃªn.
Náº¿u Ä‘Æ°á»£c anh chá»‹ cÃ³ thá»ƒ recommend em vÃ i tÃ i liá»‡u thÃ­ch há»£p cho beginner Ä‘á»ƒ tÃ¬m hiá»ƒu khÃ´ng?
Em cáº£m Æ¡n.","Khi nÃ o nÃªn há»c Machine Learning ??? Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang lÃ  SV nÄƒm 1 ngÃ nh KHMT. á» kÃ¬ Ä‘áº§u tiÃªn thÃ¬ em cÃ³ há»c á»Ÿ trÆ°á»ng vá» Intro Python, Intro C, giáº£i tÃ­ch 1 vÃ  Program Design - Abstraction (Java) + giáº£i tÃ­ch 2 (sem 2 nÄƒm 1) Em cÃ³ thá»­ Ä‘á»c qua 1 sá»‘ tÃ i liá»‡u vá» Machine Learning nhÆ° quyá»ƒn ML Yearning nhÆ°ng em tháº¥y nÃ³ khÃ¡ náº·ng vá»›i ná»n táº£ng hiá»‡n táº¡i em há»c. Cho em há»i cÃ¡c anh chá»‹ Ä‘Ã£ há»c Deep Learning, Machine Learning vÃ  AI thÃ¬ thÆ°á»ng pathway cá»§a anh chá»‹ lÃ  tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p thu hiá»‡u quáº£ há»c pháº§n nÃ y khÃ´ng. CÅ©ng nhÆ° trong 3 cÃ¡i trÃªn thÃ¬ nÃªn tiáº¿p cáº­n máº£ng nÃ o Ä‘áº§u tiÃªn. Náº¿u Ä‘Æ°á»£c anh chá»‹ cÃ³ thá»ƒ recommend em vÃ i tÃ i liá»‡u thÃ­ch há»£p cho beginner Ä‘á»ƒ tÃ¬m hiá»ƒu khÃ´ng? Em cáº£m Æ¡n.",,,,,
"Hi má»i ngÆ°á»i,
Em Ä‘ang tháº¯c máº¯c lÃ  sau khi cÃ³ 1 spam filtering model rá»“i thÃ¬ lÃ m sao Ä‘á»ƒ integrate nÃ³ vá»›i mailbox áº¡ (google mail,..)? Em search google khÃ´ng ra Ä‘Æ°á»£c gÃ¬ cÃ³ Ã­ch láº¯m nÃªn mong má»i ngÆ°á»i giÃºp Ä‘á»¡","Hi má»i ngÆ°á»i, Em Ä‘ang tháº¯c máº¯c lÃ  sau khi cÃ³ 1 spam filtering model rá»“i thÃ¬ lÃ m sao Ä‘á»ƒ integrate nÃ³ vá»›i mailbox áº¡ (google mail,..)? Em search google khÃ´ng ra Ä‘Æ°á»£c gÃ¬ cÃ³ Ã­ch láº¯m nÃªn mong má»i ngÆ°á»i giÃºp Ä‘á»¡",,,,,
"IEEE WCCI 2022 Competition on Meta-learning from Learning Curves is now open
PRIZES: $1,000
Closing date: February 10
Keywords: AutoML, Meta-learning, Reinforcement Learning, Learning Curves
---------------------
Dear Meta-learning Enthusiasts,
Following the great success of the NeurIPS 2021 meta-learning challenge, we are organizing a new challenge on meta-learning from learning curves.
Opening: January 6
End: February 10
More information on our page: https://metalearning.chalearn.org/
The organizing team
---------------------
Medium article:
https://medium.com/@hungnm.vnu/meta-learning-from-learning-curves-ieee-wcci-2022-competition-5e1932742644","IEEE WCCI 2022 Competition on Meta-learning from Learning Curves is now open PRIZES: $1,000 Closing date: February 10 Keywords: AutoML, Meta-learning, Reinforcement Learning, Learning Curves --------------------- Dear Meta-learning Enthusiasts, Following the great success of the NeurIPS 2021 meta-learning challenge, we are organizing a new challenge on meta-learning from learning curves. Opening: January 6 End: February 10 More information on our page: https://metalearning.chalearn.org/ The organizing team --------------------- Medium article: https://medium.com/@hungnm.vnu/meta-learning-from-learning-curves-ieee-wcci-2022-competition-5e1932742644",,,,,
"Team Train4Ever xin chia sáº» solution Ä‘á»©ng thá»© 7 (gold medal) trong cuá»™c thi Sartorius Cell Instance Segmentation. ÄÃ¢y lÃ  má»™t cuá»™c thi vá» instance segmentation - cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ¹ng dÃ¹ cÃ¹ng 1 class cÅ©ng sáº½ Ä‘Æ°á»£c phÃ¢n biá»‡t vá»›i nhau.
Giáº£i thÃ­ch solution: https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/298002
Code: https://github.com/gallegi/T4E_Sartorius_Cell_InstanceSegmentation
Mong Ä‘Æ°á»£c há»c há»i tá»« gÃ³p Ã½ cá»§a má»i ngÆ°á»i.
Special thanks to teammates: KhÃ¡nh VÅ© Duy Nháº­t TrÆ°á»ng BÃ¹i ÄÃ m Trá»ng TuyÃªn",Team Train4Ever xin chia sáº» solution Ä‘á»©ng thá»© 7 (gold medal) trong cuá»™c thi Sartorius Cell Instance Segmentation. ÄÃ¢y lÃ  má»™t cuá»™c thi vá» instance segmentation - cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ¹ng dÃ¹ cÃ¹ng 1 class cÅ©ng sáº½ Ä‘Æ°á»£c phÃ¢n biá»‡t vá»›i nhau. Giáº£i thÃ­ch solution: https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/298002 Code: https://github.com/gallegi/T4E_Sartorius_Cell_InstanceSegmentation Mong Ä‘Æ°á»£c há»c há»i tá»« gÃ³p Ã½ cá»§a má»i ngÆ°á»i. Special thanks to teammates: KhÃ¡nh VÅ© Duy Nháº­t TrÆ°á»ng BÃ¹i ÄÃ m Trá»ng TuyÃªn,,,,,
"ChÃ o cÃ¡c báº¡n trong forum, mÃ¬nh Ä‘ang lÃ m má»™t project nhá» vá» Ä‘iá»ƒm danh nhÃ¢n viÃªn trong cÃ´ng ty báº±ng khuÃ´n máº·t, Ã½ tÆ°á»Ÿng lÃ  quÃ©t camera Ä‘á»ƒ detect khuÃ´n máº·t (face localization) rá»“i decode khuÃ´n máº·t Ä‘Ã³ báº±ng má»™t máº¡ng CNN, so sÃ¡nh vá»›i DB Ä‘á»ƒ xem Ä‘Ã³ lÃ  ai (face recognition). Pháº§n face recognition táº¡m thá»i á»•n, nhÆ°ng pháº§n face detection thÃ¬ chá»‰ nháº­n dang Ä‘Æ°á»£c khi khuÃ´n máº·t Ä‘á»‘i diá»‡n camera, náº¿u xoay Ä‘i cÃ¡c hÆ°á»›ng hoáº·c bá»‹ che máº¥t má»™t pháº§n thÃ¬ fail (mÃ¬nh Ä‘Ã£ test vá»›i HOG vÃ  HAAR). CÃ¡c cao nhÃ¢n ai cÃ³ kinh nghiá»‡m vá»¥ face detection nÃ y lÃ m Æ¡n giÃºp mÃ¬nh vá»›i. Xin cáº£m Æ¡n!
Edit: MÃ¬nh cÃ³ tÃ¬m Ä‘Æ°á»£c má»™t paper cá»§a Yahoo khÃ¡ hay https://arxiv.org/pdf/1502.02766.pdf nhÆ°ng khÃ´ng tháº¥y implementation cá»§a nÃ³.","ChÃ o cÃ¡c báº¡n trong forum, mÃ¬nh Ä‘ang lÃ m má»™t project nhá» vá» Ä‘iá»ƒm danh nhÃ¢n viÃªn trong cÃ´ng ty báº±ng khuÃ´n máº·t, Ã½ tÆ°á»Ÿng lÃ  quÃ©t camera Ä‘á»ƒ detect khuÃ´n máº·t (face localization) rá»“i decode khuÃ´n máº·t Ä‘Ã³ báº±ng má»™t máº¡ng CNN, so sÃ¡nh vá»›i DB Ä‘á»ƒ xem Ä‘Ã³ lÃ  ai (face recognition). Pháº§n face recognition táº¡m thá»i á»•n, nhÆ°ng pháº§n face detection thÃ¬ chá»‰ nháº­n dang Ä‘Æ°á»£c khi khuÃ´n máº·t Ä‘á»‘i diá»‡n camera, náº¿u xoay Ä‘i cÃ¡c hÆ°á»›ng hoáº·c bá»‹ che máº¥t má»™t pháº§n thÃ¬ fail (mÃ¬nh Ä‘Ã£ test vá»›i HOG vÃ  HAAR). CÃ¡c cao nhÃ¢n ai cÃ³ kinh nghiá»‡m vá»¥ face detection nÃ y lÃ m Æ¡n giÃºp mÃ¬nh vá»›i. Xin cáº£m Æ¡n! Edit: MÃ¬nh cÃ³ tÃ¬m Ä‘Æ°á»£c má»™t paper cá»§a Yahoo khÃ¡ hay https://arxiv.org/pdf/1502.02766.pdf nhÆ°ng khÃ´ng tháº¥y implementation cá»§a nÃ³.",,,,,
"Loáº¡t bÃ i giáº£ng trong há»c kÃ¬ mÃ¹a thu 2021 cá»§a ÄH Stanford vá» Graph Neural Networks, kÃ¨m cáº£ slides, vÃ  Colab.","Loáº¡t bÃ i giáº£ng trong há»c kÃ¬ mÃ¹a thu 2021 cá»§a ÄH Stanford vá» Graph Neural Networks, kÃ¨m cáº£ slides, vÃ  Colab.",,,,,
"ChÃ o mn, cho mÃ¬nh há»i trong nhÃ³m cÃ³ ai lÃ m hÆ°á»›ng nghiÃªn cá»©u vá» normalizing flow, invertiable neural network khÃ´ng? Cho mÃ¬nh pm há»i 1 sá»‘ thá»© Ä‘Æ°á»£c khÃ´ng áº¡.","ChÃ o mn, cho mÃ¬nh há»i trong nhÃ³m cÃ³ ai lÃ m hÆ°á»›ng nghiÃªn cá»©u vá» normalizing flow, invertiable neural network khÃ´ng? Cho mÃ¬nh pm há»i 1 sá»‘ thá»© Ä‘Æ°á»£c khÃ´ng áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i áº¡,
Hiá»‡n em Ä‘ang Ä‘á»c quyá»ƒn ESL, Ä‘á»c Ä‘áº¿n trang 74, 75 thÃ¬ tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p Ä‘áº¿n khÃ¡i niá»‡m L1 arc length trong context cá»§a Lasso Regression vÃ  LAR. ThÃ¬ em Ä‘ang chÆ°a hiá»ƒu khÃ¡i niá»‡m cá»§a L1 arc length cÃ³ Ã½ nghÄ©a lÃ  gÃ¬, em Ä‘ang phá»ng Ä‘oÃ¡n nÃ³ lÃ  Ä‘á»™ dÃ i Ä‘Æ°á»ng biÃªn trÃªn miá»n cá»§a beta dÆ°á»›i rÃ ng buá»™c ||beta||1 <= t, vÃ  má»—i L1 arc length sáº½ tÆ°Æ¡ng á»©ng vá»›i 1 giÃ¡ trá»‹ t, vÃ  má»—i giÃ¡ trá»‹ t láº¡i tÆ°Æ¡ng á»©ng vá»›i má»™t solution cá»§a beta; hay nÃ³i cÃ¡ch khÃ¡c thÃ¬ profile cá»§a beta lÃ  má»™t hÃ m cá»§a L1 arc length. NhÆ°ng hiá»ƒu nhÆ° váº­y cÃ³ váº» chá»‰ make sense vá»›i Lasso, cÃ²n vá»›i LAR thÃ¬ khÃ´ng cÃ³ rÃ ng buá»™c t nÃ o lÃªn ||beta||1, em Ä‘ang nghÄ© khi Ä‘Ã³ chÆ°a cháº¯c profile cá»§a beta Ä‘Ã£ lÃ  má»™t hÃ m cá»§a L1 arc length. Em khÃ´ng biáº¿t mÃ¬nh cÃ³ hiá»ƒu sai chá»— nÃ o khÃ´ng, hi vá»ng má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡.
SÃ¡ch cÃ³ thá»ƒ truy cáº­p táº¡i: https://hastie.su.domains/Papers/ESLII.pdf","ChÃ o má»i ngÆ°á»i áº¡, Hiá»‡n em Ä‘ang Ä‘á»c quyá»ƒn ESL, Ä‘á»c Ä‘áº¿n trang 74, 75 thÃ¬ tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p Ä‘áº¿n khÃ¡i niá»‡m L1 arc length trong context cá»§a Lasso Regression vÃ  LAR. ThÃ¬ em Ä‘ang chÆ°a hiá»ƒu khÃ¡i niá»‡m cá»§a L1 arc length cÃ³ Ã½ nghÄ©a lÃ  gÃ¬, em Ä‘ang phá»ng Ä‘oÃ¡n nÃ³ lÃ  Ä‘á»™ dÃ i Ä‘Æ°á»ng biÃªn trÃªn miá»n cá»§a beta dÆ°á»›i rÃ ng buá»™c ||beta||1 <= t, vÃ  má»—i L1 arc length sáº½ tÆ°Æ¡ng á»©ng vá»›i 1 giÃ¡ trá»‹ t, vÃ  má»—i giÃ¡ trá»‹ t láº¡i tÆ°Æ¡ng á»©ng vá»›i má»™t solution cá»§a beta; hay nÃ³i cÃ¡ch khÃ¡c thÃ¬ profile cá»§a beta lÃ  má»™t hÃ m cá»§a L1 arc length. NhÆ°ng hiá»ƒu nhÆ° váº­y cÃ³ váº» chá»‰ make sense vá»›i Lasso, cÃ²n vá»›i LAR thÃ¬ khÃ´ng cÃ³ rÃ ng buá»™c t nÃ o lÃªn ||beta||1, em Ä‘ang nghÄ© khi Ä‘Ã³ chÆ°a cháº¯c profile cá»§a beta Ä‘Ã£ lÃ  má»™t hÃ m cá»§a L1 arc length. Em khÃ´ng biáº¿t mÃ¬nh cÃ³ hiá»ƒu sai chá»— nÃ o khÃ´ng, hi vá»ng má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡. SÃ¡ch cÃ³ thá»ƒ truy cáº­p táº¡i: https://hastie.su.domains/Papers/ESLII.pdf",,,,,
"#Ask #Attention
ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» Attention áº¡. Tuy nhiÃªn thÃ¬ cÃ³ má»™t chá»— em tháº¯c máº¯c lÃ  bÆ°á»›c tÃ¬m sá»± tÆ°Æ¡ng quan . VÃ­ dá»¥ nhÆ° trong cÃ¢u "" I study at school"" thÃ¬ viá»‡c xÃ©t sá»± tÆ°Æ¡ng quan giá»¯a nhá»¯ng tá»« trong cÃ¢u rá»“i Ä‘Ã¡nh trá»ng sá»‘ cao dá»±a theo tiÃªu chÃ­ nÃ o váº­y áº¡?
HÆ¡n ná»¯a, em muá»‘n hiá»ƒu rÃµ Ã½ nghÄ©a cá»§a Query,Key,Value lÃ  gÃ¬ áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n !!!","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» Attention áº¡. Tuy nhiÃªn thÃ¬ cÃ³ má»™t chá»— em tháº¯c máº¯c lÃ  bÆ°á»›c tÃ¬m sá»± tÆ°Æ¡ng quan . VÃ­ dá»¥ nhÆ° trong cÃ¢u "" I study at school"" thÃ¬ viá»‡c xÃ©t sá»± tÆ°Æ¡ng quan giá»¯a nhá»¯ng tá»« trong cÃ¢u rá»“i Ä‘Ã¡nh trá»ng sá»‘ cao dá»±a theo tiÃªu chÃ­ nÃ o váº­y áº¡? HÆ¡n ná»¯a, em muá»‘n hiá»ƒu rÃµ Ã½ nghÄ©a cá»§a Query,Key,Value lÃ  gÃ¬ áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n !!!",#Ask	#Attention,,,,
Em Ä‘ang tÃ¬m hiá»ƒu vá» nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng vÃ  gáº·p váº¥n Ä‘á» vá» bá»™ dá»¯ liá»‡u áº¡. Má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ lÃ m qua cho em há»i lÃ  cÃ³ bá»™ dá»¯ liá»‡u nháº­n diá»‡n khuÃ´n máº·t nÃ o mÃ  Ä‘á»§ tá»‘t Ä‘á»ƒ sá»­ dá»¥ng cho nháº­n diá»‡n vÃ  cho viá»‡c tÃ¡ch lá»— tai (sá»­ dá»¥ng ear detection) (em cáº§n thÃ´ng tin nÃ y áº¡). Em cáº£m Æ¡n.,Em Ä‘ang tÃ¬m hiá»ƒu vá» nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng vÃ  gáº·p váº¥n Ä‘á» vá» bá»™ dá»¯ liá»‡u áº¡. Má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ lÃ m qua cho em há»i lÃ  cÃ³ bá»™ dá»¯ liá»‡u nháº­n diá»‡n khuÃ´n máº·t nÃ o mÃ  Ä‘á»§ tá»‘t Ä‘á»ƒ sá»­ dá»¥ng cho nháº­n diá»‡n vÃ  cho viá»‡c tÃ¡ch lá»— tai (sá»­ dá»¥ng ear detection) (em cáº§n thÃ´ng tin nÃ y áº¡). Em cáº£m Æ¡n.,,,,,
"Xin chÃ o má»i ngÆ°á»i.
Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m Ä‘á» tÃ i vá» fact verification. MÃ¬nh cÃ³ tÃ¬m tool vá» reverse image search - tá»« áº£nh, tÃ¬m website chá»©a áº£nh Ä‘Ã³ Ä‘á»ƒ thu vá» toÃ n bá»™ thÃ´ng tin trÃªn trang web. MÃ¬nh cÃ³ tÃ¬m tháº¥y Google Reverse Image Search, nhÆ°ng hiá»‡n táº¡i API nÃ y Ä‘Ã£ ngÆ°ng. MÃ¬nh cÃ³ tÃ¬m tháº¥y SerpAPI nhÆ°ng phÃ­ cá»§a SerpAPI hÆ¡i Ä‘áº¯t. MÃ¬nh muá»‘n há»i cÃ³ báº¡n nÃ o cÃ³ biáº¿t tool hay code github nÃ o há»— trá»£ váº¥n Ä‘á» nÃ y khÃ´ng áº¡.
MÃ¬nh xin cáº£m Æ¡n áº¡.","Xin chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m Ä‘á» tÃ i vá» fact verification. MÃ¬nh cÃ³ tÃ¬m tool vá» reverse image search - tá»« áº£nh, tÃ¬m website chá»©a áº£nh Ä‘Ã³ Ä‘á»ƒ thu vá» toÃ n bá»™ thÃ´ng tin trÃªn trang web. MÃ¬nh cÃ³ tÃ¬m tháº¥y Google Reverse Image Search, nhÆ°ng hiá»‡n táº¡i API nÃ y Ä‘Ã£ ngÆ°ng. MÃ¬nh cÃ³ tÃ¬m tháº¥y SerpAPI nhÆ°ng phÃ­ cá»§a SerpAPI hÆ¡i Ä‘áº¯t. MÃ¬nh muá»‘n há»i cÃ³ báº¡n nÃ o cÃ³ biáº¿t tool hay code github nÃ o há»— trá»£ váº¥n Ä‘á» nÃ y khÃ´ng áº¡. MÃ¬nh xin cáº£m Æ¡n áº¡.",,,,,
"ChÃ o mn, em Ä‘ang Ä‘á»c 1 blog post vá» language model GPT-3. Trong pháº§n limitation á»Ÿ áº£nh dÆ°á»›i cÃ³ ghi ""GPT-3 lÃ  model autoregressive, khÃ´ng pháº£i bi-direct nhÆ° BERT, váº­y nÃªn phÃ¹ há»£p vá»›i cÃ¡c task ""in-context"" learning-based hÆ¡n lÃ  cÃ¡c task cáº§n fine tuning model""
Em Ä‘ang khÃ´ng hiá»ƒu cÃ¢u nÃ y, ""in-context"" learning-based lÃ  tháº¿ nÃ o, má»™t sá»‘ task vÃ­ dá»¥ vÃ  táº¡i sao model autoregressive láº¡i phÃ¹ há»£p vá»›i nÃ³.
Mong mn giáº£i Ä‘Ã¡p giÃºp áº¡, em cáº£m Æ¡n.
Link bÃ i viáº¿t:
https://www.springboard.com/blog/ai-machine-learning/machine-learning-gpt-3-open-ai/","ChÃ o mn, em Ä‘ang Ä‘á»c 1 blog post vá» language model GPT-3. Trong pháº§n limitation á»Ÿ áº£nh dÆ°á»›i cÃ³ ghi ""GPT-3 lÃ  model autoregressive, khÃ´ng pháº£i bi-direct nhÆ° BERT, váº­y nÃªn phÃ¹ há»£p vá»›i cÃ¡c task ""in-context"" learning-based hÆ¡n lÃ  cÃ¡c task cáº§n fine tuning model"" Em Ä‘ang khÃ´ng hiá»ƒu cÃ¢u nÃ y, ""in-context"" learning-based lÃ  tháº¿ nÃ o, má»™t sá»‘ task vÃ­ dá»¥ vÃ  táº¡i sao model autoregressive láº¡i phÃ¹ há»£p vá»›i nÃ³. Mong mn giáº£i Ä‘Ã¡p giÃºp áº¡, em cáº£m Æ¡n. Link bÃ i viáº¿t: https://www.springboard.com/blog/ai-machine-learning/machine-learning-gpt-3-open-ai/",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em Ä‘ang lÃ m project bÃ i toÃ¡n nháº­n diá»‡n hÃ nh Ä‘á»™ng cá»§a ngÆ°á»i dá»±a trÃªn thÃ´ng tin khung xÆ°Æ¡ng. Em Ä‘Ã£ lÃ m xong bÆ°á»›c training model Ä‘á»ƒ nháº­n dáº¡ng hÃ nh Ä‘á»™ng.
Model em sá»­ dá»¥ng lÃ  máº¡ng GCN, Ä‘áº§u vÃ o cá»§a máº¡ng lÃ  chuá»—i chá»‰ thá»±c hiá»‡n 1 hÃ nh Ä‘á»™ng ( vÃ­ dá»¥ hÃ nh Ä‘á»™ng writing thÃ¬ sáº½ Ä‘Æ°a vÃ o máº¡ng lÃ  chuá»—i frame khung xÆ°Æ¡ng thá»±c hiá»‡n hÃ nh Ä‘á»™ng writing).
BÃ¢y giá», em muá»‘n cÃ³ thá»ƒ nháº­n dáº¡ng chuá»—i thá»±c hiá»‡n gá»“m nhiá»u hÃ nh Ä‘á»™ng trong video thá»±c ( nhÆ° video bÃªn dÆ°á»›i ), Ã½ tÆ°á»Ÿng cá»§a em lÃ  cÃ³ thá»ƒ sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t Ä‘á»ƒ Ã¡p model vÃ o. Tuy nhiÃªn, cÃ³ má»™t váº¥n Ä‘á» lÃ  trong pháº§n training model Ä‘Ã³ em khÃ´ng thá»±c hiá»‡n training vá»›i chuá»—i Ä‘áº§u vÃ o cÃ³ nhÃ£n lÃ  no action. MÃ  trong video thá»±c táº¿, thÃ¬ cÃ³ thá»ƒ ngÆ°á»i thá»±c hiá»‡n cÃ³ nhá»¯ng quÃ£ng nghá»‰ ( no action) á»Ÿ nhá»¯ng thá»i Ä‘iá»ƒm báº¥t kÃ¬.
VÃ¬ váº­y, em cÃ³ má»™t cÃ¢u há»i má»i ngÆ°á»i giáº£i Ä‘Ã¡p, Ä‘Ã³ lÃ  lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ phÃ¢n tÃ¡ch Ä‘Æ°á»£c giá»¯a cÃ¡c hÃ nh Ä‘á»™ng vá»›i nhá»¯ng quÃ£ng no-action khÃ´ng áº¡ ( Em ko cÃ³ dá»¯ liá»‡u no action Ä‘á»ƒ training). Liá»‡u mÃ¬nh cÃ³ thá»ƒ dá»±a trÃªn rule-based vá»›i chuá»—i Ä‘áº§u vÃ o Ä‘á»ƒ phÃ¡t hiá»‡n no-action ko áº¡, hay báº¯t buá»™c pháº£i kiáº¿m dá»¯ liá»‡u no action áº¡.
Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m project bÃ i toÃ¡n nháº­n diá»‡n hÃ nh Ä‘á»™ng cá»§a ngÆ°á»i dá»±a trÃªn thÃ´ng tin khung xÆ°Æ¡ng. Em Ä‘Ã£ lÃ m xong bÆ°á»›c training model Ä‘á»ƒ nháº­n dáº¡ng hÃ nh Ä‘á»™ng. Model em sá»­ dá»¥ng lÃ  máº¡ng GCN, Ä‘áº§u vÃ o cá»§a máº¡ng lÃ  chuá»—i chá»‰ thá»±c hiá»‡n 1 hÃ nh Ä‘á»™ng ( vÃ­ dá»¥ hÃ nh Ä‘á»™ng writing thÃ¬ sáº½ Ä‘Æ°a vÃ o máº¡ng lÃ  chuá»—i frame khung xÆ°Æ¡ng thá»±c hiá»‡n hÃ nh Ä‘á»™ng writing). BÃ¢y giá», em muá»‘n cÃ³ thá»ƒ nháº­n dáº¡ng chuá»—i thá»±c hiá»‡n gá»“m nhiá»u hÃ nh Ä‘á»™ng trong video thá»±c ( nhÆ° video bÃªn dÆ°á»›i ), Ã½ tÆ°á»Ÿng cá»§a em lÃ  cÃ³ thá»ƒ sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t Ä‘á»ƒ Ã¡p model vÃ o. Tuy nhiÃªn, cÃ³ má»™t váº¥n Ä‘á» lÃ  trong pháº§n training model Ä‘Ã³ em khÃ´ng thá»±c hiá»‡n training vá»›i chuá»—i Ä‘áº§u vÃ o cÃ³ nhÃ£n lÃ  no action. MÃ  trong video thá»±c táº¿, thÃ¬ cÃ³ thá»ƒ ngÆ°á»i thá»±c hiá»‡n cÃ³ nhá»¯ng quÃ£ng nghá»‰ ( no action) á»Ÿ nhá»¯ng thá»i Ä‘iá»ƒm báº¥t kÃ¬. VÃ¬ váº­y, em cÃ³ má»™t cÃ¢u há»i má»i ngÆ°á»i giáº£i Ä‘Ã¡p, Ä‘Ã³ lÃ  lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ phÃ¢n tÃ¡ch Ä‘Æ°á»£c giá»¯a cÃ¡c hÃ nh Ä‘á»™ng vá»›i nhá»¯ng quÃ£ng no-action khÃ´ng áº¡ ( Em ko cÃ³ dá»¯ liá»‡u no action Ä‘á»ƒ training). Liá»‡u mÃ¬nh cÃ³ thá»ƒ dá»±a trÃªn rule-based vá»›i chuá»—i Ä‘áº§u vÃ o Ä‘á»ƒ phÃ¡t hiá»‡n no-action ko áº¡, hay báº¯t buá»™c pháº£i kiáº¿m dá»¯ liá»‡u no action áº¡. Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘áº¿n tá»« team NTBN bao gá»“m 1 thÃ nh viÃªn lÃ  mÃ¬nh Nguyá»…n Nháº­t HoÃ ng. MÃ¬nh xin chia sáº» solution mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng Ä‘á»ƒ giÃ nh Ä‘Æ°á»£c top 1 private test táº¡i Zalo AI Challenge 2021 task 5k compliance. MÃ¬nh cáº£m tháº¥y ráº¥t may máº¯n khi Ä‘áº¡t Ä‘Æ°á»£c top1 nÃ y, Ä‘iá»ƒm máº¥u chá»‘t cÃ³ láº½ lÃ  do viá»‡c lá»±a chá»n mÃ´ hÃ¬nh vÃ  tuning tham sá»‘.
Giáº£i phÃ¡p cá»§a mÃ¬nh bao gá»“m :
1. Chuáº©n bá»‹ dá»¯ liá»‡u
Sá»­ dá»¥ng yolov5x Ä‘á»ƒ detect person, sá»­a nhÃ£n nhá»¯ng bá»©c hÃ¬nh cÃ³ lÆ°á»£ng ngÆ°á»i <=1 nhÆ°ng cÃ³ nhÃ£n distance lÃ  0.
Stratified CV 5-fold
2. Huáº¥n luyá»‡n
MÃ´ hÃ¬nh mÃ¬nh sá»­ dá»¥ng lÃ  Swin Transformer large 193M parameter.
Optimizer: AdamW ( weight_decay= 1e-5).
Image size: 384x384.
Training 20 epochs cÃ³ early stopping.
Augmentation: Color jitter, random erasing, mixup, cutmix, and random augment from timm.
MÃ¬nh táº­p trung vÃ o tuning cÃ¡c tham sá»‘ drop path rate, base learning rate, warmup learning rate vÃ  min learning rate.
ToÃ n bá»™ cÃ¡c tham sá»‘ cÃ³ trong file config vÃ  trong file bash cháº¡y huáº¥n luyá»‡n tá»«ng fold.
3. Dá»± Ä‘oÃ¡n
Vá»›i mask vÃ  distance mÃ¬nh tÃ­nh trung bÃ¬nh káº¿t cá»§a cá»§a 5 folds.
Káº¿t quáº£ dá»± Ä‘oÃ¡n 5K lÃ  káº¿t há»£p mask vÃ  distance vá»›i ngÆ°á»¡ng mask lÃ  0.5 vÃ  ngÆ°á»¡ng distance lÃ  0.44
ToÃ n bá»™ source code tá»« clean data Ä‘áº¿n train vÃ  inference mÃ¬nh Ä‘Ã£ Ä‘á»ƒ háº¿t trong repo Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘áº¿n tá»« team NTBN bao gá»“m 1 thÃ nh viÃªn lÃ  mÃ¬nh Nguyá»…n Nháº­t HoÃ ng. MÃ¬nh xin chia sáº» solution mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng Ä‘á»ƒ giÃ nh Ä‘Æ°á»£c top 1 private test táº¡i Zalo AI Challenge 2021 task 5k compliance. MÃ¬nh cáº£m tháº¥y ráº¥t may máº¯n khi Ä‘áº¡t Ä‘Æ°á»£c top1 nÃ y, Ä‘iá»ƒm máº¥u chá»‘t cÃ³ láº½ lÃ  do viá»‡c lá»±a chá»n mÃ´ hÃ¬nh vÃ  tuning tham sá»‘. Giáº£i phÃ¡p cá»§a mÃ¬nh bao gá»“m : 1. Chuáº©n bá»‹ dá»¯ liá»‡u Sá»­ dá»¥ng yolov5x Ä‘á»ƒ detect person, sá»­a nhÃ£n nhá»¯ng bá»©c hÃ¬nh cÃ³ lÆ°á»£ng ngÆ°á»i <=1 nhÆ°ng cÃ³ nhÃ£n distance lÃ  0. Stratified CV 5-fold 2. Huáº¥n luyá»‡n MÃ´ hÃ¬nh mÃ¬nh sá»­ dá»¥ng lÃ  Swin Transformer large 193M parameter. Optimizer: AdamW ( weight_decay= 1e-5). Image size: 384x384. Training 20 epochs cÃ³ early stopping. Augmentation: Color jitter, random erasing, mixup, cutmix, and random augment from timm. MÃ¬nh táº­p trung vÃ o tuning cÃ¡c tham sá»‘ drop path rate, base learning rate, warmup learning rate vÃ  min learning rate. ToÃ n bá»™ cÃ¡c tham sá»‘ cÃ³ trong file config vÃ  trong file bash cháº¡y huáº¥n luyá»‡n tá»«ng fold. 3. Dá»± Ä‘oÃ¡n Vá»›i mask vÃ  distance mÃ¬nh tÃ­nh trung bÃ¬nh káº¿t cá»§a cá»§a 5 folds. Káº¿t quáº£ dá»± Ä‘oÃ¡n 5K lÃ  káº¿t há»£p mask vÃ  distance vá»›i ngÆ°á»¡ng mask lÃ  0.5 vÃ  ngÆ°á»¡ng distance lÃ  0.44 ToÃ n bá»™ source code tá»« clean data Ä‘áº¿n train vÃ  inference mÃ¬nh Ä‘Ã£ Ä‘á»ƒ háº¿t trong repo Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.",,,,,
"Em chÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cÃ³ ai Ä‘ang dÃ¹ng colab pro+ mÃ  Ä‘á»£t dáº¡o nÃ y allocate chá»‰ Ä‘Æ°á»£c P100 hay T4 khÃ´ng áº¡, em tá»« lÃºc mua Ä‘áº¿n giá» chÆ°a allocate V100 hay A100 mÃ  chá»‰ Ä‘Æ°á»£c 2 mÃ¡y trÃªn. Em muá»‘n thuÃª GPU mÃ  cÃ³ thá»ƒ thá»­ nghiá»‡m lÃ m Ä‘Æ°á»£c vÃ i tuáº§n, má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ dá»‹ch vá»¥ má»i ngÆ°á»i Ä‘ang dÃ¹ng tháº¥y tá»‘t khÃ´ng áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Em chÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cÃ³ ai Ä‘ang dÃ¹ng colab pro+ mÃ  Ä‘á»£t dáº¡o nÃ y allocate chá»‰ Ä‘Æ°á»£c P100 hay T4 khÃ´ng áº¡, em tá»« lÃºc mua Ä‘áº¿n giá» chÆ°a allocate V100 hay A100 mÃ  chá»‰ Ä‘Æ°á»£c 2 mÃ¡y trÃªn. Em muá»‘n thuÃª GPU mÃ  cÃ³ thá»ƒ thá»­ nghiá»‡m lÃ m Ä‘Æ°á»£c vÃ i tuáº§n, má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ dá»‹ch vá»¥ má»i ngÆ°á»i Ä‘ang dÃ¹ng tháº¥y tá»‘t khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"Mn cho e há»i chÃºt vá»›i áº¡! CÃ³ ai Ä‘Ã£ tá»«ng lÃ m viá»‡c vá»›i bá»™ dataset NTU-60/120 chÆ°a áº¡? VÃ¬ bá»™ nÃ y quÃ¡ lá»›n nÃªn e k táº£i vá» Ä‘á»ƒ training Ä‘c, mn cÃ³ biáº¿t link nÃ o chá»©a subset cá»§a bá»™ nÃ y hoáº·c cÃ³ cÃ¡ch nÃ o láº¥y 1 pháº§n nhá» cá»§a nÃ³ k áº¡?
Em cáº£m Æ¡n mn nhiá»u â¤ï¸","Mn cho e há»i chÃºt vá»›i áº¡! CÃ³ ai Ä‘Ã£ tá»«ng lÃ m viá»‡c vá»›i bá»™ dataset NTU-60/120 chÆ°a áº¡? VÃ¬ bá»™ nÃ y quÃ¡ lá»›n nÃªn e k táº£i vá» Ä‘á»ƒ training Ä‘c, mn cÃ³ biáº¿t link nÃ o chá»©a subset cá»§a bá»™ nÃ y hoáº·c cÃ³ cÃ¡ch nÃ o láº¥y 1 pháº§n nhá» cá»§a nÃ³ k áº¡? Em cáº£m Æ¡n mn nhiá»u",,,,,
"MÃ¬nh má»›i publish 1 bÃ i vá» trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« hÃ³a Ä‘Æ¡n. Ã tÆ°á»Ÿng khÃ¡ Ä‘Æ¡n giáº£n vÃ  dá»… dÃ ng reproduce, dá»±a trÃªn thÃ´ng tin vá» tá»« khÃ³a cho cÃ¡c trÆ°á»ng dá»¯ liá»‡u (vÃ­ dá»¥: invoice number, invoice date,...), kiá»ƒu dá»¯ liá»‡u cÃ³ cáº¥u trÃºc (date, phone number, VAT number,...), entities (NER, ORG, LOC), address (sá»­ dá»¥ng thÆ° viá»‡n libpostal), vÃ  vá»‹ trÃ­ tÆ°Æ¡ng quan giá»¯a cÃ¡c blocks. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o trÃªn link nÃ y:
https://authors.elsevier.com/c/1eJ-o3I06IZDW7
Link Ä‘á»c vÃ  download miá»…n phÃ­ cho Ä‘áº¿n 16/02/2022.","MÃ¬nh má»›i publish 1 bÃ i vá» trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« hÃ³a Ä‘Æ¡n. Ã tÆ°á»Ÿng khÃ¡ Ä‘Æ¡n giáº£n vÃ  dá»… dÃ ng reproduce, dá»±a trÃªn thÃ´ng tin vá» tá»« khÃ³a cho cÃ¡c trÆ°á»ng dá»¯ liá»‡u (vÃ­ dá»¥: invoice number, invoice date,...), kiá»ƒu dá»¯ liá»‡u cÃ³ cáº¥u trÃºc (date, phone number, VAT number,...), entities (NER, ORG, LOC), address (sá»­ dá»¥ng thÆ° viá»‡n libpostal), vÃ  vá»‹ trÃ­ tÆ°Æ¡ng quan giá»¯a cÃ¡c blocks. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o trÃªn link nÃ y: https://authors.elsevier.com/c/1eJ-o3I06IZDW7 Link Ä‘á»c vÃ  download miá»…n phÃ­ cho Ä‘áº¿n 16/02/2022.",,,,,
"Are you working on/interesting in multi-agent learning with strategic agents? Please consider submitting your work to our workshop at AAMAS 2022:
https://minbiaohan.github.io/LSA/index.html
Important dates:
Paper Submission deadline: 30 January 2022
Notification of Acceptance: 27 February 2022
More details on the website.",Are you working on/interesting in multi-agent learning with strategic agents? Please consider submitting your work to our workshop at AAMAS 2022: https://minbiaohan.github.io/LSA/index.html Important dates: Paper Submission deadline: 30 January 2022 Notification of Acceptance: 27 February 2022 More details on the website.,,,,,
"MÃ¬nh cÃ³ tá»•ng há»£p má»™t repository cÃ¡c trang research paper ML, DL, AI, Data; vá» task, datasets, idea, state-of-the-art dÃ nh cho nhá»¯ng báº¡n má»›i báº¯t Ä‘áº§u (mÃ¬nh cÅ©ng váº­y) tÃ¬m kiáº¿m cÃ¡c nguá»“n tÃ i liá»‡u cháº¥t lÆ°á»£ng. Hi vá»ng má»i ngÆ°á»i sáº½ thÃ­ch vÃ  chÃºc má»«ng nÄƒm má»›i anh Tiá»‡p vÃ  má»i ngÆ°á»i trong group MLCB!
Note: Má»i ngÆ°á»i recommend research site thÃ¬ comment á»Ÿ dÆ°á»›i Ä‘á»ƒ mÃ¬nh add vÃ o nhÃ©, cÃ¡m Æ¡n má»i ngÆ°á»i !","MÃ¬nh cÃ³ tá»•ng há»£p má»™t repository cÃ¡c trang research paper ML, DL, AI, Data; vá» task, datasets, idea, state-of-the-art dÃ nh cho nhá»¯ng báº¡n má»›i báº¯t Ä‘áº§u (mÃ¬nh cÅ©ng váº­y) tÃ¬m kiáº¿m cÃ¡c nguá»“n tÃ i liá»‡u cháº¥t lÆ°á»£ng. Hi vá»ng má»i ngÆ°á»i sáº½ thÃ­ch vÃ  chÃºc má»«ng nÄƒm má»›i anh Tiá»‡p vÃ  má»i ngÆ°á»i trong group MLCB! Note: Má»i ngÆ°á»i recommend research site thÃ¬ comment á»Ÿ dÆ°á»›i Ä‘á»ƒ mÃ¬nh add vÃ o nhÃ©, cÃ¡m Æ¡n má»i ngÆ°á»i !",,,,,
Em xin chÃ o tháº§y cÃ´ vÃ  má»i ngÆ°á»i áº¡! Em cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n phÃ¢n cá»¥m K-means vÃ  tÃ¬m cÃ¡ch **THÃŠM RÃ€NG BUá»˜C ÄÆ¯á»œNG KÃNH Cá»¤M** vÃ o! Má»i ngÆ°á»i náº¿u ai biáº¿t thÃ¬ cho em xin gá»£i Ã½ Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n ráº¥t nhiá»u áº¡!,Em xin chÃ o tháº§y cÃ´ vÃ  má»i ngÆ°á»i áº¡! Em cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n phÃ¢n cá»¥m K-means vÃ  tÃ¬m cÃ¡ch **THÃŠM RÃ€NG BUá»˜C ÄÆ¯á»œNG KÃNH Cá»¤M** vÃ o! Má»i ngÆ°á»i náº¿u ai biáº¿t thÃ¬ cho em xin gá»£i Ã½ Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n ráº¥t nhiá»u áº¡!,,,,,
"#ask #pandas
Em cÃ³ má»™t báº£ng pandas 1 cÃ³ cÃ¡c dá»¯ liá»‡u bá»‹ trÃ¹ng, vÃ  muá»‘n biáº¿n Ä‘á»•i nÃ³ thÃ nh báº£ng 2 (nhÆ° hÃ¬nh minh hoáº¡). Em cÃ³ thá»­ dÃ¹ng cÃ¡c hÃ m groupby nhÆ°ng khÃ´ng nhÆ° mong muá»‘n. Em cÅ©ng nghÄ© Ä‘áº¿n viá»‡c define má»™t hÃ m xá»­ lÃ½ rá»“i apply cho nÃ³ nhÆ°ng váº«n chÆ°a biáº¿t xá»­ lÃ½ tháº¿ nÃ o. Hy vá»ng má»i ngÆ°á»i gá»£i Ã½ hÆ°á»›ng Ä‘i hoáº·c cho em vÃ i keyword Ä‘á»ƒ xá»­ lÃ½ váº¥n Ä‘á» nÃ y áº¡.
Link notebook vÃ  data bÃªn dÆ°á»›i náº¿u má»i ngÆ°á»i muá»‘n xem ká»¹ hÆ¡n:
Notebook: https://github.com/Brian-Doan/movie-rs/blob/main/movie_rs.ipynb
Data: https://drive.google.com/drive/folders/1V6IO3GX4lPKDrnVZ2v1KnTHdmbjeQQVX?usp=sharing","Em cÃ³ má»™t báº£ng pandas 1 cÃ³ cÃ¡c dá»¯ liá»‡u bá»‹ trÃ¹ng, vÃ  muá»‘n biáº¿n Ä‘á»•i nÃ³ thÃ nh báº£ng 2 (nhÆ° hÃ¬nh minh hoáº¡). Em cÃ³ thá»­ dÃ¹ng cÃ¡c hÃ m groupby nhÆ°ng khÃ´ng nhÆ° mong muá»‘n. Em cÅ©ng nghÄ© Ä‘áº¿n viá»‡c define má»™t hÃ m xá»­ lÃ½ rá»“i apply cho nÃ³ nhÆ°ng váº«n chÆ°a biáº¿t xá»­ lÃ½ tháº¿ nÃ o. Hy vá»ng má»i ngÆ°á»i gá»£i Ã½ hÆ°á»›ng Ä‘i hoáº·c cho em vÃ i keyword Ä‘á»ƒ xá»­ lÃ½ váº¥n Ä‘á» nÃ y áº¡. Link notebook vÃ  data bÃªn dÆ°á»›i náº¿u má»i ngÆ°á»i muá»‘n xem ká»¹ hÆ¡n: Notebook: https://github.com/Brian-Doan/movie-rs/blob/main/movie_rs.ipynb Data: https://drive.google.com/drive/folders/1V6IO3GX4lPKDrnVZ2v1KnTHdmbjeQQVX?usp=sharing",#ask	#pandas,,,,
"[Deep Learning List Reading]
Äá»c sÃ¡ch lÃ  má»™t trong nhá»¯ng cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ hiá»ƒu ná»n táº£ng cá»§a Machine Learning vÃ  Deep Learning. ThÃ´ng qua sÃ¡ch cÃ³ thá»ƒ cung cáº¥p cho báº¡n sá»± hiá»ƒu biáº¿t lÃ½ thuyáº¿t cáº§n thiáº¿t Ä‘á»ƒ giÃºp báº¡n há»c cÃ¡c khÃ¡i niá»‡m má»›i nhanh hÆ¡n trong tÆ°Æ¡ng lai. BÃªn dÆ°á»›i lÃ  danh sÃ¡ch tuyá»ƒn chá»n nhá»¯ng cuá»‘n sÃ¡ch vá» Deep Learning nÄƒm 2021 dÃ nh cho beginner cá»§a admin. Xin Ä‘Æ°á»£c chia sáº» tá»›i báº¡n Ä‘á»c:
1. AI and Machine Learning for Coders: TÃ¡c giáº£ Laurence Moroney, hiá»‡n Ä‘ang lÃ m viá»‡c táº¡i google. Cuá»‘n nÃ y Ä‘Æ°á»£c forewarded bá»Ÿi Andrew Ng
https://www.oreilly.com/library/view/ai-and-machine/9781492078180/
2. Deep Learning with Python, Second Edition: Cuá»‘n nÃ y cá»§a FranÃ§ois Chollet, cha Ä‘áº» cá»§a tensorflow-keras.
https://www.manning.com/books/deep-learning-with-python-second-edition
3. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition: Cuá»‘n nÃ y cá»§a AurÃ©lien GÃ©ron, Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ lÃ  má»™t trong nhá»¯ng cuá»‘n sÃ¡ch hay nháº¥t vá» Machine Learning. Pháº§n I Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch ra báº£n Tiáº¿ng Viá»‡t bá»Ÿi nhÃ³m dá»‹ch thuáº­t Machine Learning CÆ¡ báº£n.
https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/
4. Deep Learning: Cuá»‘n sÃ¡ch gá»‘i Ä‘áº§u cá»§a bao tháº¿ há»‡ sinh viÃªn vá» Deep Learning cá»§a ba tÃ¡c giáº£ Ian Goodfellow, Yoshua Bengio and Aaron Courville. Äá»ƒ thÃºc Ä‘áº©y sá»± phÃ¡t triá»ƒn cá»™ng Ä‘á»“ng, báº£n ebook cá»§a cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c tÃ¡c giáº£ public. SÃ¡ch hiá»‡n Ä‘Ã£ cÃ³ báº£n dá»‹ch tiáº¿ng Viá»‡t cá»§a nhÃ³m DLBOOKVN.
https://www.deeplearningbook.org/
5. Neural Networks and Deep Learning: Cuá»‘n nÃ y cá»§a â€ªMichael Nielsen, má»™t nhÃ  nghiÃªn cá»©u ná»•i tiáº¿ng vá» AI. Cuá»‘n nÃ y trÃ¬nh bÃ y khÃ¡ sÃ¢u vá» lÃ½ thuyáº¿t giá»‘ng nhÆ° cuá»‘n Deep Learning.
http://neuralnetworksanddeeplearning.com/
6. Learning TensorFlow.js: Cuá»‘n nÃ y Ä‘Æ°á»£c viáº¿t bá»Ÿi Gant Laborde vÃ  Ä‘Æ°á»£c forewarded bá»Ÿi Laurence Moroney, tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch thá»© nháº¥t.
https://www.oreilly.com/library/view/learning-tensorflowjs/9781492090786/
7. Deep Learning with JavaScript: ÄÆ°á»£c viáº¿t bá»Ÿi nhÃ³m tÃ¡c giáº£ Shanqing Cai, Stanley Bileschi, Eric D. Nielsen with Francois Chollet nháº±m hÆ°á»›ng dáº«n cÃ¡ch phÃ¡t triá»ƒn cÃ¡c á»©ng dá»¥ng Deep Learning trÃªn javascript. PhÃ¹ há»£p vá»›i web developer muá»‘n á»©ng dá»¥ng thÃªm AI.
https://www.manning.com/books/deep-learning-with-javascript
8. Natural Language Processing with Transformers: Náº¿u muá»‘n há»c vá» cÃ¡c á»©ng dá»¥ng trong NLP vÃ  kiáº¿n trÃºc Transformers thÃ¬ Ä‘Ã¢y lÃ  cuá»‘n sÃ¡ch háº¿t sá»©c tuyá»‡t vá»i.
https://www.oreilly.com/library/view/natural-language-processing/9781098103231/
----------------------------------------------------------------------------
Nháº±m cá»§ng cá»‘ kiáº¿n thá»©c vá» Deep Learning, báº¡n Ä‘á»c cÃ³ thá»ƒ Ä‘Äƒng kÃ­ course 3 - Deep Learning khai giáº£ng 16/1/2021 theo Ä‘Æ°á»ng link: https://forms.gle/HveenGg54Gc8yj238","[Deep Learning List Reading] Äá»c sÃ¡ch lÃ  má»™t trong nhá»¯ng cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ hiá»ƒu ná»n táº£ng cá»§a Machine Learning vÃ  Deep Learning. ThÃ´ng qua sÃ¡ch cÃ³ thá»ƒ cung cáº¥p cho báº¡n sá»± hiá»ƒu biáº¿t lÃ½ thuyáº¿t cáº§n thiáº¿t Ä‘á»ƒ giÃºp báº¡n há»c cÃ¡c khÃ¡i niá»‡m má»›i nhanh hÆ¡n trong tÆ°Æ¡ng lai. BÃªn dÆ°á»›i lÃ  danh sÃ¡ch tuyá»ƒn chá»n nhá»¯ng cuá»‘n sÃ¡ch vá» Deep Learning nÄƒm 2021 dÃ nh cho beginner cá»§a admin. Xin Ä‘Æ°á»£c chia sáº» tá»›i báº¡n Ä‘á»c: 1. AI and Machine Learning for Coders: TÃ¡c giáº£ Laurence Moroney, hiá»‡n Ä‘ang lÃ m viá»‡c táº¡i google. Cuá»‘n nÃ y Ä‘Æ°á»£c forewarded bá»Ÿi Andrew Ng https://www.oreilly.com/library/view/ai-and-machine/9781492078180/ 2. Deep Learning with Python, Second Edition: Cuá»‘n nÃ y cá»§a FranÃ§ois Chollet, cha Ä‘áº» cá»§a tensorflow-keras. https://www.manning.com/books/deep-learning-with-python-second-edition 3. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition: Cuá»‘n nÃ y cá»§a AurÃ©lien GÃ©ron, Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ lÃ  má»™t trong nhá»¯ng cuá»‘n sÃ¡ch hay nháº¥t vá» Machine Learning. Pháº§n I Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch ra báº£n Tiáº¿ng Viá»‡t bá»Ÿi nhÃ³m dá»‹ch thuáº­t Machine Learning CÆ¡ báº£n. https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ 4. Deep Learning: Cuá»‘n sÃ¡ch gá»‘i Ä‘áº§u cá»§a bao tháº¿ há»‡ sinh viÃªn vá» Deep Learning cá»§a ba tÃ¡c giáº£ Ian Goodfellow, Yoshua Bengio and Aaron Courville. Äá»ƒ thÃºc Ä‘áº©y sá»± phÃ¡t triá»ƒn cá»™ng Ä‘á»“ng, báº£n ebook cá»§a cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c tÃ¡c giáº£ public. SÃ¡ch hiá»‡n Ä‘Ã£ cÃ³ báº£n dá»‹ch tiáº¿ng Viá»‡t cá»§a nhÃ³m DLBOOKVN. https://www.deeplearningbook.org/ 5. Neural Networks and Deep Learning: Cuá»‘n nÃ y cá»§a â€ªMichael Nielsen, má»™t nhÃ  nghiÃªn cá»©u ná»•i tiáº¿ng vá» AI. Cuá»‘n nÃ y trÃ¬nh bÃ y khÃ¡ sÃ¢u vá» lÃ½ thuyáº¿t giá»‘ng nhÆ° cuá»‘n Deep Learning. http://neuralnetworksanddeeplearning.com/ 6. Learning TensorFlow.js: Cuá»‘n nÃ y Ä‘Æ°á»£c viáº¿t bá»Ÿi Gant Laborde vÃ  Ä‘Æ°á»£c forewarded bá»Ÿi Laurence Moroney, tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch thá»© nháº¥t. https://www.oreilly.com/library/view/learning-tensorflowjs/9781492090786/ 7. Deep Learning with JavaScript: ÄÆ°á»£c viáº¿t bá»Ÿi nhÃ³m tÃ¡c giáº£ Shanqing Cai, Stanley Bileschi, Eric D. Nielsen with Francois Chollet nháº±m hÆ°á»›ng dáº«n cÃ¡ch phÃ¡t triá»ƒn cÃ¡c á»©ng dá»¥ng Deep Learning trÃªn javascript. PhÃ¹ há»£p vá»›i web developer muá»‘n á»©ng dá»¥ng thÃªm AI. https://www.manning.com/books/deep-learning-with-javascript 8. Natural Language Processing with Transformers: Náº¿u muá»‘n há»c vá» cÃ¡c á»©ng dá»¥ng trong NLP vÃ  kiáº¿n trÃºc Transformers thÃ¬ Ä‘Ã¢y lÃ  cuá»‘n sÃ¡ch háº¿t sá»©c tuyá»‡t vá»i. https://www.oreilly.com/library/view/natural-language-processing/9781098103231/ ---------------------------------------------------------------------------- Nháº±m cá»§ng cá»‘ kiáº¿n thá»©c vá» Deep Learning, báº¡n Ä‘á»c cÃ³ thá»ƒ Ä‘Äƒng kÃ­ course 3 - Deep Learning khai giáº£ng 16/1/2021 theo Ä‘Æ°á»ng link: https://forms.gle/HveenGg54Gc8yj238",,,,,
Bookmarked.,Bookmarked.,,,,,
"chÃ o má»i ngÆ°á»i, em muá»‘n há»c video khÃ³a cs231n cá»§a nÄƒm 2020 hoáº·c 2021 thÃ¬ kiáº¿m á»Ÿ Ä‘Ã¢u Ä‘Æ°á»£c áº¡, em tÃ¬m trÃªn google tháº¥y toÃ n video tá»« nÄƒm 2017","chÃ o má»i ngÆ°á»i, em muá»‘n há»c video khÃ³a cs231n cá»§a nÄƒm 2020 hoáº·c 2021 thÃ¬ kiáº¿m á»Ÿ Ä‘Ã¢u Ä‘Æ°á»£c áº¡, em tÃ¬m trÃªn google tháº¥y toÃ n video tá»« nÄƒm 2017",,,,,
"ÄÃ¢y lÃ  bÃ i viáº¿t thÃº vá»‹ vá» tá»•ng káº¿t nhá»¯ng thÃ nh tá»±u vá» nghiÃªn cá»©u Graph Neural Networks trong nÄƒm 2021 cÅ©ng nhÆ° dá»± Ä‘oÃ¡n xu tháº¿ vá» GNN trong nÄƒm 2022 https://towardsdatascience.com/graph-ml-in-2022-where-are-we-now-f7f8242599e0
Trong bÃ i viáº¿t nÃ y cÃ³ cÃ¢u tráº£ lá»i cá»§a má»™t sá»‘ báº¡n há»i vá» Ä‘á»™ sÃ¢u, Ä‘á»™ rá»™ng khi thiáº¿t káº¿ GNNs mÃ  trong bÃ i giáº£ng táº¡i Viá»‡n ToÃ¡n Cao cáº¥p cá»§a Gs Nguyá»…n HÃ¹ng SÆ¡n vÃ o ngÃ y 30/12/2021. CÃ³ má»™t sá»‘ nghiÃªn cá»©u chá»‰ ra ráº±ng GNNs chá»‰ cáº§n tá»« 2-4 layers lÃ  á»•n, cÃ ng nhiá»u layers cÃ ng lÃ m giáº£m hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh.
Vá»›i kinh nghiá»‡m cÃ¡ nhÃ¢n, viá»‡c train GNNs khÃ´ng cáº§n quÃ¡ quan tÃ¢m tá»›i viá»‡c tinh chá»‰nh hyperparameters. MÃ¬nh tháº¥y GNNs sáº½ há»™i tá»¥ tá»‘t vá»›i hÃ m ADAM, Learning rate ~0.001 (khÃ´ng cáº§n Learning scheduler). MÃ¬nh thá»­ dÃ¹ng má»™t sá»‘ hÃ m Optimizer khÃ¡c káº¿t há»£p cÃ¹ng vá»›i scheduler thÃ¬ models ráº¥t khÃ³ há»™i tá»¥!
Má»™t trong nhá»¯ng khÃ³ khÄƒn ná»¯a mÃ  cÃ³ má»™t sá»‘ báº¡n cÃ³ há»i riÃªng Ä‘Ã³ lÃ  nháº­n diá»‡n Ä‘Ãºng dáº¡ng bÃ i toÃ¡n nhÆ° (sub)Graph classification, node classification, link prediction,â€¦. Tá»« Ä‘Ã³ má»›i chuáº©n bá»‹ Ä‘Ãºng dáº¡ng dá»¯ liá»‡u, build Ä‘Ãºng models, viáº¿t Ä‘Ãºng hÃ m train loop, chá»n Ä‘Ãºng phÆ°Æ¡ng phÃ¡p metrics trong quÃ¡ trÃ¬nh training vÃ  testing phases. Gáº§n Ä‘Ã¢y, MÃ¬nh biáº¿t cÃ³ 1 bÃ i bÃ¡o ráº¥t ráº¥t â€œtá»‘tâ€ nhÆ°ng bá»‹ retracted chá»‰ vÃ¬ máº¯c sai láº§m vá» nháº­n dáº¡ng bÃ i toÃ¡n. Ráº¥t tiáº¿c cho nhÃ³m nghiÃªn cá»©u tiÃªn phong Ä‘Ã³!
ChÃºc cÃ¡c báº¡n nÄƒm má»›i bÃ¬nh an vÃ  Ä‘áº¡t Ä‘Æ°á»£c nhiá»u thÃ nh tá»±u","ÄÃ¢y lÃ  bÃ i viáº¿t thÃº vá»‹ vá» tá»•ng káº¿t nhá»¯ng thÃ nh tá»±u vá» nghiÃªn cá»©u Graph Neural Networks trong nÄƒm 2021 cÅ©ng nhÆ° dá»± Ä‘oÃ¡n xu tháº¿ vá» GNN trong nÄƒm 2022 https://towardsdatascience.com/graph-ml-in-2022-where-are-we-now-f7f8242599e0 Trong bÃ i viáº¿t nÃ y cÃ³ cÃ¢u tráº£ lá»i cá»§a má»™t sá»‘ báº¡n há»i vá» Ä‘á»™ sÃ¢u, Ä‘á»™ rá»™ng khi thiáº¿t káº¿ GNNs mÃ  trong bÃ i giáº£ng táº¡i Viá»‡n ToÃ¡n Cao cáº¥p cá»§a Gs Nguyá»…n HÃ¹ng SÆ¡n vÃ o ngÃ y 30/12/2021. CÃ³ má»™t sá»‘ nghiÃªn cá»©u chá»‰ ra ráº±ng GNNs chá»‰ cáº§n tá»« 2-4 layers lÃ  á»•n, cÃ ng nhiá»u layers cÃ ng lÃ m giáº£m hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh. Vá»›i kinh nghiá»‡m cÃ¡ nhÃ¢n, viá»‡c train GNNs khÃ´ng cáº§n quÃ¡ quan tÃ¢m tá»›i viá»‡c tinh chá»‰nh hyperparameters. MÃ¬nh tháº¥y GNNs sáº½ há»™i tá»¥ tá»‘t vá»›i hÃ m ADAM, Learning rate ~0.001 (khÃ´ng cáº§n Learning scheduler). MÃ¬nh thá»­ dÃ¹ng má»™t sá»‘ hÃ m Optimizer khÃ¡c káº¿t há»£p cÃ¹ng vá»›i scheduler thÃ¬ models ráº¥t khÃ³ há»™i tá»¥! Má»™t trong nhá»¯ng khÃ³ khÄƒn ná»¯a mÃ  cÃ³ má»™t sá»‘ báº¡n cÃ³ há»i riÃªng Ä‘Ã³ lÃ  nháº­n diá»‡n Ä‘Ãºng dáº¡ng bÃ i toÃ¡n nhÆ° (sub)Graph classification, node classification, link prediction,â€¦. Tá»« Ä‘Ã³ má»›i chuáº©n bá»‹ Ä‘Ãºng dáº¡ng dá»¯ liá»‡u, build Ä‘Ãºng models, viáº¿t Ä‘Ãºng hÃ m train loop, chá»n Ä‘Ãºng phÆ°Æ¡ng phÃ¡p metrics trong quÃ¡ trÃ¬nh training vÃ  testing phases. Gáº§n Ä‘Ã¢y, MÃ¬nh biáº¿t cÃ³ 1 bÃ i bÃ¡o ráº¥t ráº¥t â€œtá»‘tâ€ nhÆ°ng bá»‹ retracted chá»‰ vÃ¬ máº¯c sai láº§m vá» nháº­n dáº¡ng bÃ i toÃ¡n. Ráº¥t tiáº¿c cho nhÃ³m nghiÃªn cá»©u tiÃªn phong Ä‘Ã³! ChÃºc cÃ¡c báº¡n nÄƒm má»›i bÃ¬nh an vÃ  Ä‘áº¡t Ä‘Æ°á»£c nhiá»u thÃ nh tá»±u",,,,,
"em xin chÃ o tháº§y cÃ´ vÃ  má»i ngÆ°á»i áº¡. má»i ngÆ°á»i cho em há»i ai Ä‘Ã£ tá»«ng train yolov4 trÃªn colab mÃ  gáº·p hiá»‡n tÆ°á»£ng khoáº£ng táº§m cá»© sau 1500 epochs thÃ¬ loss nÃ³ bá»‹ vá» -nan táº¥t nhÆ° tháº¿ nÃ y chÆ°a áº¡. em Ä‘Ã£ thá»­ vÃ i bá»™ datasets format cá»§a yolo vÃ  tham kháº£o má»™t sá»‘ trang nhÆ° miai vÃ  lÃ m theo giá»‘ng y há»‡t mÃ  k Ä‘c áº¡. ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡!
link folder em train á»Ÿ Ä‘Ã¢y áº¡: https://drive.google.com/drive/folders/1YGNi2xa1DEYt6Vl2alEyaLkbgcZQsegj?usp=sharing
#yolov4 #objectdetection",em xin chÃ o tháº§y cÃ´ vÃ  má»i ngÆ°á»i áº¡. má»i ngÆ°á»i cho em há»i ai Ä‘Ã£ tá»«ng train yolov4 trÃªn colab mÃ  gáº·p hiá»‡n tÆ°á»£ng khoáº£ng táº§m cá»© sau 1500 epochs thÃ¬ loss nÃ³ bá»‹ vá» -nan táº¥t nhÆ° tháº¿ nÃ y chÆ°a áº¡. em Ä‘Ã£ thá»­ vÃ i bá»™ datasets format cá»§a yolo vÃ  tham kháº£o má»™t sá»‘ trang nhÆ° miai vÃ  lÃ m theo giá»‘ng y há»‡t mÃ  k Ä‘c áº¡. ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡! link folder em train á»Ÿ Ä‘Ã¢y áº¡: https://drive.google.com/drive/folders/1YGNi2xa1DEYt6Vl2alEyaLkbgcZQsegj?usp=sharing,#yolov4	#objectdetection,,,,
"Báº£n dich cuá»‘n sÃ¡ch há»c sÃ¢u Ä‘Ã£ má»Ÿ Ä‘á»ƒ cÃ¡c báº¡n pre-order. ChÃºng tÃ´i dá»± Ä‘á»‹nh chá»‰ in khoáº£ng 500-1000 cuá»‘n, tÃ¹y vÃ o sá»‘ lÆ°á»£ng Ä‘áº·t trÆ°á»›c mÃ  chÃºng tÃ´i nháº­n Ä‘Æ°á»£c. Do Ä‘Ã³, Ä‘á»ƒ Ä‘áº£m báº£o báº¡n cÃ³ Ä‘Æ°á»£c má»™t phiÃªn báº£n cá»§a cuá»‘n sÃ¡ch, hÃ£y nhanh chÃ¢n Ä‘áº·t hÃ ng. GiÃ¡ chá»‰ cÃ³ 349.000 cho cuá»‘n sÃ¡ch 650 trang.","Báº£n dich cuá»‘n sÃ¡ch há»c sÃ¢u Ä‘Ã£ má»Ÿ Ä‘á»ƒ cÃ¡c báº¡n pre-order. ChÃºng tÃ´i dá»± Ä‘á»‹nh chá»‰ in khoáº£ng 500-1000 cuá»‘n, tÃ¹y vÃ o sá»‘ lÆ°á»£ng Ä‘áº·t trÆ°á»›c mÃ  chÃºng tÃ´i nháº­n Ä‘Æ°á»£c. Do Ä‘Ã³, Ä‘á»ƒ Ä‘áº£m báº£o báº¡n cÃ³ Ä‘Æ°á»£c má»™t phiÃªn báº£n cá»§a cuá»‘n sÃ¡ch, hÃ£y nhanh chÃ¢n Ä‘áº·t hÃ ng. GiÃ¡ chá»‰ cÃ³ 349.000 cho cuá»‘n sÃ¡ch 650 trang.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, trÆ°á»›c em lÃ m máº¥y bÃ i train YOLO cÃ¡c phiÃªn báº£n rá»“i. Láº§n nÃ y mÃ¬nh Ä‘ang há»c pháº§n SSD nÃªn máº¡nh dÃ n lÃ m clip chia sáº» cÃ¹ng cÃ¡c báº¡n má»›i há»c.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n Ä‘ang há»c pháº§n nÃ y áº¡!","KÃ­nh chÃ o cÃ¡c bÃ¡c, trÆ°á»›c em lÃ m máº¥y bÃ i train YOLO cÃ¡c phiÃªn báº£n rá»“i. Láº§n nÃ y mÃ¬nh Ä‘ang há»c pháº§n SSD nÃªn máº¡nh dÃ n lÃ m clip chia sáº» cÃ¹ng cÃ¡c báº¡n má»›i há»c. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n Ä‘ang há»c pháº§n nÃ y áº¡!",,,,,
"ChÃ o cÃ¡c báº¡n,
ChÃºng mÃ¬nh Ä‘áº¿n tá»« team 3PU - 3 PhD Students in USA. Sau Ä‘Ã¢y chÃºng mÃ¬nh xin chia sáº» solution cá»§a chÃºng mÃ¬nh cho task Legal Text Retrieval (Top 1 Public Leaderboard - Top 1 Private Leaderboard)
Ã tÆ°á»Ÿng: Xáº¿p háº¡ng Ä‘iá»ƒm sá»‘ cho cÃ¡c cÃ¢u trong legal corpus, Ä‘Ã¡nh giÃ¡ Ä‘á»™ giá»‘ng nhau dá»±a trÃªn cosine similarity score
Training:
Step 1: Fine-tuning masked language models dá»±a vÃ o corpus mÃ  ban tá»• chá»©c cung cáº¥p. á» Ä‘Ã¢y, corpus sáº½ bao gá»“m cÃ¡c Ä‘iá»u luáº­t + cÃ¡c cÃ¢u há»i trong training questions vÃ  public test questions. Settings sáº½ nhÆ° sau:
Model 1: Vibert base
Model 2: PhoBert Large
Model 3: PhoBert Large + Condenser
Model 4: PhoBert Large + Co-condenser.
Step 2: Training Sentence Transformer + Contrastive loss. Positive samples lÃ  cÃ¡c cÃ¢u tráº£ lá»i tá»« training data, negative sample lÃ  top-k cÃ¢u tráº£ lá»i tá»« BM25. Sau Ä‘Ã¢y lÃ  setting cho cÃ¡c mÃ´ hÃ¬nh
Model 1: ViBert base - negative sentence pairs: Top 50 sentences tá»« BM 25.
Model 2: PhoBert Large - negative sentence pairs : Top 20 sentences tá»« BM 25
Model 3: PhoBert Large + Condenser - negative sentence pairs: top 20 sentences tá»« BM 25
Model 4: PhoBert Large + Co-condenser - negative sentence pairs: top 20 sentences tá»« BM 25
Step 3: Hard negative mining: DÃ¹ng 4 models trÃªn dá»± Ä‘oÃ¡n top 20 cáº·p trong training data cÃ³ cos-sim scores cao nháº¥t cho tá»«ng model. Sau Ä‘Ã³ lÆ°u láº¡i cÃ¡c cáº·p cÃ¢u nÃ y Ä‘á»ƒ training tiáº¿p round 2 cho sentence transformer.
Step 4: Training Sentence Transformer + contrastive loss tá»« dá»¯ liá»‡u Ä‘Æ°á»£c sinh ra á»Ÿ step 3.
Step 5: Ensemble 4 x Sentence Transformer + BM25 cho tá»«ng cÃ¢u há»i :
MÃ¬nh sáº½ dÃ¹ng 4 models ST Ä‘á»ƒ tÃ­nh cosine similarity scores cá»§a tá»«ng cÃ¢u há»i vá»›i táº¥t cáº£ cÃ¡c cÃ¢u cÃ³ trong legal corpus.
Weighted Ensemble 4 x Sentence Transformer:
bert_score = âˆ‘ w_i * cos_sim_model_i
Bm_25_score = bm25 score cá»§a tá»«ng cÃ¢u há»i
Final score = Bm_25_score * bert_score
Pick cÃ¡c cÃ¢u cÃ³ cosine similarity score trong khoáº£ng [max_score - 2.6, max_score]
Post-processing:
Loáº¡i bá» 1 sá»‘ trÆ°á»ng há»£p sai Ä‘iá»u luáº­t nd-, nÄ‘-cp (chá»¯ Ä‘ á»Ÿ 1 dáº¡ng kÃ­ tá»± khÃ¡c), nd-cp -> nd-cp
09/2014/ttlt-btp-tandtc-vksndtc -> 09/2014/ttlt-btp-tandtc-vksndtc-btc.
Chá»‰ láº¥y tá»‘i Ä‘a 5 cÃ¢u trong khoáº£ng [max_score - 2.6, max_score].
Source-code Ä‘Æ°á»£c public táº¡i: https://github.com/CuongNN218/zalo_ltr_2021
LÃª Tuáº¥n DÅ©ng
P/s: mÃ¬nh sáº½ sá»­a chÃº thÃ­ch chi tiáº¿t hÆ¡n trong thá»i gian tá»›i.","ChÃ o cÃ¡c báº¡n, ChÃºng mÃ¬nh Ä‘áº¿n tá»« team 3PU - 3 PhD Students in USA. Sau Ä‘Ã¢y chÃºng mÃ¬nh xin chia sáº» solution cá»§a chÃºng mÃ¬nh cho task Legal Text Retrieval (Top 1 Public Leaderboard - Top 1 Private Leaderboard) Ã tÆ°á»Ÿng: Xáº¿p háº¡ng Ä‘iá»ƒm sá»‘ cho cÃ¡c cÃ¢u trong legal corpus, Ä‘Ã¡nh giÃ¡ Ä‘á»™ giá»‘ng nhau dá»±a trÃªn cosine similarity score Training: Step 1: Fine-tuning masked language models dá»±a vÃ o corpus mÃ  ban tá»• chá»©c cung cáº¥p. á» Ä‘Ã¢y, corpus sáº½ bao gá»“m cÃ¡c Ä‘iá»u luáº­t + cÃ¡c cÃ¢u há»i trong training questions vÃ  public test questions. Settings sáº½ nhÆ° sau: Model 1: Vibert base Model 2: PhoBert Large Model 3: PhoBert Large + Condenser Model 4: PhoBert Large + Co-condenser. Step 2: Training Sentence Transformer + Contrastive loss. Positive samples lÃ  cÃ¡c cÃ¢u tráº£ lá»i tá»« training data, negative sample lÃ  top-k cÃ¢u tráº£ lá»i tá»« BM25. Sau Ä‘Ã¢y lÃ  setting cho cÃ¡c mÃ´ hÃ¬nh Model 1: ViBert base - negative sentence pairs: Top 50 sentences tá»« BM 25. Model 2: PhoBert Large - negative sentence pairs : Top 20 sentences tá»« BM 25 Model 3: PhoBert Large + Condenser - negative sentence pairs: top 20 sentences tá»« BM 25 Model 4: PhoBert Large + Co-condenser - negative sentence pairs: top 20 sentences tá»« BM 25 Step 3: Hard negative mining: DÃ¹ng 4 models trÃªn dá»± Ä‘oÃ¡n top 20 cáº·p trong training data cÃ³ cos-sim scores cao nháº¥t cho tá»«ng model. Sau Ä‘Ã³ lÆ°u láº¡i cÃ¡c cáº·p cÃ¢u nÃ y Ä‘á»ƒ training tiáº¿p round 2 cho sentence transformer. Step 4: Training Sentence Transformer + contrastive loss tá»« dá»¯ liá»‡u Ä‘Æ°á»£c sinh ra á»Ÿ step 3. Step 5: Ensemble 4 x Sentence Transformer + BM25 cho tá»«ng cÃ¢u há»i : MÃ¬nh sáº½ dÃ¹ng 4 models ST Ä‘á»ƒ tÃ­nh cosine similarity scores cá»§a tá»«ng cÃ¢u há»i vá»›i táº¥t cáº£ cÃ¡c cÃ¢u cÃ³ trong legal corpus. Weighted Ensemble 4 x Sentence Transformer: bert_score = âˆ‘ w_i * cos_sim_model_i Bm_25_score = bm25 score cá»§a tá»«ng cÃ¢u há»i Final score = Bm_25_score * bert_score Pick cÃ¡c cÃ¢u cÃ³ cosine similarity score trong khoáº£ng [max_score - 2.6, max_score] Post-processing: Loáº¡i bá» 1 sá»‘ trÆ°á»ng há»£p sai Ä‘iá»u luáº­t nd-, nÄ‘-cp (chá»¯ Ä‘ á»Ÿ 1 dáº¡ng kÃ­ tá»± khÃ¡c), nd-cp -> nd-cp 09/2014/ttlt-btp-tandtc-vksndtc -> 09/2014/ttlt-btp-tandtc-vksndtc-btc. Chá»‰ láº¥y tá»‘i Ä‘a 5 cÃ¢u trong khoáº£ng [max_score - 2.6, max_score]. Source-code Ä‘Æ°á»£c public táº¡i: https://github.com/CuongNN218/zalo_ltr_2021 LÃª Tuáº¥n DÅ©ng P/s: mÃ¬nh sáº½ sá»­a chÃº thÃ­ch chi tiáº¿t hÆ¡n trong thá»i gian tá»›i.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c! Anh em ta nhiá»u khi train xong model, phÃ¢n tÃ­ch xong má»™t váº¥n Ä‘á» vá» data vÃ  muá»‘n share cho ngÆ°á»i khÃ¡c sá»­ dá»¥ng thÃ¬ sáº½ pháº£i biáº¿t FrontEnd, BackEnd Ä‘á»ƒ dev ra má»™t trang web.
BÃ¢y giá» thÃ¬ vá»›i Streamlit, anh em khÃ´ng cáº§n pháº£i váº¥t váº£ ná»­a, dá»±ng lÃªn trang web chá»‰ trong 1 phÃºt mÃ  thÃ´i.
NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» nÃ y nÃªn mÃ¬nh máº¡nh dáº¡n lÃ m video chia sáº», hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n!","KÃ­nh chÃ o cÃ¡c bÃ¡c! Anh em ta nhiá»u khi train xong model, phÃ¢n tÃ­ch xong má»™t váº¥n Ä‘á» vá» data vÃ  muá»‘n share cho ngÆ°á»i khÃ¡c sá»­ dá»¥ng thÃ¬ sáº½ pháº£i biáº¿t FrontEnd, BackEnd Ä‘á»ƒ dev ra má»™t trang web. BÃ¢y giá» thÃ¬ vá»›i Streamlit, anh em khÃ´ng cáº§n pháº£i váº¥t váº£ ná»­a, dá»±ng lÃªn trang web chá»‰ trong 1 phÃºt mÃ  thÃ´i. NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» nÃ y nÃªn mÃ¬nh máº¡nh dáº¡n lÃ m video chia sáº», hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n!",,,,,
"Em chÃ o má»i ngÆ°á»i trong nhÃ³m
Hiá»‡n táº¡i em cÃ³ Ä‘ang lÃ m 1 bÃ i toÃ¡n , yÃªu cáº§u Ä‘áº·t ra lÃ  pháº£i crawl Ä‘Æ°á»£c tá»‘i thiá»ƒu 500mb data , má»i ngÆ°á»i cÃ³ thá»ƒ cho em biáº¿t 1 vÃ i nguá»“n Ä‘Æ°á»£c khÃ´ng áº¡ . Em cáº£m Æ¡n má»i ngÆ°á»i","Em chÃ o má»i ngÆ°á»i trong nhÃ³m Hiá»‡n táº¡i em cÃ³ Ä‘ang lÃ m 1 bÃ i toÃ¡n , yÃªu cáº§u Ä‘áº·t ra lÃ  pháº£i crawl Ä‘Æ°á»£c tá»‘i thiá»ƒu 500mb data , má»i ngÆ°á»i cÃ³ thá»ƒ cho em biáº¿t 1 vÃ i nguá»“n Ä‘Æ°á»£c khÃ´ng áº¡ . Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
Dáº¡ em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang lÃ m project vá» chatbot. HÆ°á»›ng cá»§a em Ä‘ang Ä‘i lÃ  dÃ¹ng cÃ¡c model pre train trÃªn Hugging Face nhÆ° dialogpt. Liá»‡u em fine tuning cÃ³ sá»­ dá»¥ng cho tiáº¿ng viá»‡t Ä‘Æ°á»£c khÃ´ng áº¡. Xin má»i ngÆ°á»i cho Ã½ kiáº¿n. Em tháº¥y trÃªn máº¡ng chÆ°a cÃ³ code lÃ m nÃ y nÃªn hÆ¡i lo!!!!,Dáº¡ em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n em Ä‘ang lÃ m project vá» chatbot. HÆ°á»›ng cá»§a em Ä‘ang Ä‘i lÃ  dÃ¹ng cÃ¡c model pre train trÃªn Hugging Face nhÆ° dialogpt. Liá»‡u em fine tuning cÃ³ sá»­ dá»¥ng cho tiáº¿ng viá»‡t Ä‘Æ°á»£c khÃ´ng áº¡. Xin má»i ngÆ°á»i cho Ã½ kiáº¿n. Em tháº¥y trÃªn máº¡ng chÆ°a cÃ³ code lÃ m nÃ y nÃªn hÆ¡i lo!!!!,,,,,
"ChÃºc má»«ng Blog MLCB Ä‘Æ°á»£c 5 tuá»•i (theo giá» Má»¹). Khi táº¡o commit Ä‘áº§u tiÃªn vÃ o repo https://github.com/tiepvupsu/tiepvupsu.github.io, mÃ¬nh khÃ´ng thá»ƒ ngá» láº¡i Ä‘i cÃ¹ng MLCB xa Ä‘áº¿n tháº¿. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ gÃ³p pháº§n duy trÃ¬ cá»™ng Ä‘á»“ng nÃ y.","ChÃºc má»«ng Blog MLCB Ä‘Æ°á»£c 5 tuá»•i (theo giá» Má»¹). Khi táº¡o commit Ä‘áº§u tiÃªn vÃ o repo https://github.com/tiepvupsu/tiepvupsu.github.io, mÃ¬nh khÃ´ng thá»ƒ ngá» láº¡i Ä‘i cÃ¹ng MLCB xa Ä‘áº¿n tháº¿. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ gÃ³p pháº§n duy trÃ¬ cá»™ng Ä‘á»“ng nÃ y.",,,,,
MÃ¬nh thá»­ nghiá»‡m cho thÃ nh viÃªn Ä‘Äƒng bÃ i áº©n danh. CÃ¡c báº¡n cÃ³ thá»ƒ thoáº£i mÃ¡i Ä‘áº·t cÃ¢u há»i mÃ  khÃ´ng sá»£ bá»‹ Ä‘Ã¡nh giÃ¡. Táº¥t nhiÃªn cÃ¡c cÃ¢u há»i váº«n pháº£i theo ná»™i quy cá»§a nhÃ³m.,MÃ¬nh thá»­ nghiá»‡m cho thÃ nh viÃªn Ä‘Äƒng bÃ i áº©n danh. CÃ¡c báº¡n cÃ³ thá»ƒ thoáº£i mÃ¡i Ä‘áº·t cÃ¢u há»i mÃ  khÃ´ng sá»£ bá»‹ Ä‘Ã¡nh giÃ¡. Táº¥t nhiÃªn cÃ¡c cÃ¢u há»i váº«n pháº£i theo ná»™i quy cá»§a nhÃ³m.,,,,,
"ChÃ o má»i ngÆ°á»i!
Em Ä‘ang thá»±c hiá»‡n má»™t Ä‘á»“ Ã¡n nhá» vÃ  muá»‘n sá»­ dá»¥ng Keras Ä‘á»ƒ tÄƒng cÆ°á»ng dá»¯ liá»‡u cho táº­p dá»¯ liá»‡u cá»§a mÃ¬nh.
Má»i ngÆ°á»i cÃ³ thá»ƒ cho em há»i táº¡i sao em thá»±c hiá»‡n nhÆ° Ä‘oáº¡n code dÆ°á»›i nhÆ°ng chá»‰ xuáº¥t hiá»‡n káº¿t quáº£ lÃ  ""Found 10 images belonging to 2 classes."" nhÆ°ng khÃ´ng tháº¥y cÃ¡c áº£nh má»›i Ä‘Æ°á»£c táº¡o ra lÃ  vÃ¬ sao áº¡?","ChÃ o má»i ngÆ°á»i! Em Ä‘ang thá»±c hiá»‡n má»™t Ä‘á»“ Ã¡n nhá» vÃ  muá»‘n sá»­ dá»¥ng Keras Ä‘á»ƒ tÄƒng cÆ°á»ng dá»¯ liá»‡u cho táº­p dá»¯ liá»‡u cá»§a mÃ¬nh. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em há»i táº¡i sao em thá»±c hiá»‡n nhÆ° Ä‘oáº¡n code dÆ°á»›i nhÆ°ng chá»‰ xuáº¥t hiá»‡n káº¿t quáº£ lÃ  ""Found 10 images belonging to 2 classes."" nhÆ°ng khÃ´ng tháº¥y cÃ¡c áº£nh má»›i Ä‘Æ°á»£c táº¡o ra lÃ  vÃ¬ sao áº¡?",,,,,
"Xin chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» Logical Analysis of Data (LAD). Má»¥c Ä‘Ã­ch cá»§a em lÃ  sá»­ dá»¥ng LAD Ä‘á»ƒ generate cÃ¡c patterns trong tÃ­n hiá»‡u
dao Ä‘á»™ng. Em cÃ³ Ä‘á»c bÃ¡o vÃ  tÃ¬m hiá»ƒu thÃ¬ cÃ³ Ä‘Æ°á»£c biáº¿t Ä‘áº¿n cbmLAD software nhÆ°ng má»i thÃ´ng tin ráº¥t háº¡n cháº¿. Em Ä‘ang chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch xÃ¢y dá»±ng mÃ´ hÃ¬nh vÃ  phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ implement LAD vá»›i python hay C++.
Em ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡.
Em cáº£m Æ¡n!","Xin chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» Logical Analysis of Data (LAD). Má»¥c Ä‘Ã­ch cá»§a em lÃ  sá»­ dá»¥ng LAD Ä‘á»ƒ generate cÃ¡c patterns trong tÃ­n hiá»‡u dao Ä‘á»™ng. Em cÃ³ Ä‘á»c bÃ¡o vÃ  tÃ¬m hiá»ƒu thÃ¬ cÃ³ Ä‘Æ°á»£c biáº¿t Ä‘áº¿n cbmLAD software nhÆ°ng má»i thÃ´ng tin ráº¥t háº¡n cháº¿. Em Ä‘ang chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch xÃ¢y dá»±ng mÃ´ hÃ¬nh vÃ  phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ implement LAD vá»›i python hay C++. Em ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡. Em cáº£m Æ¡n!",,,,,
"Em xin chÃ o cáº£ nhÃ , cho em há»i má»™t chÃºt vá» dá»‹ch mÃ¡y trong NLP
Em cÃ³ lÃ m theo phÆ°Æ¡ng phÃ¡p nÃªu trong bÃ i bÃ¡o nÃ y https://aclanthology.org/2020.acl-main.144, vÃ  Ã¡p dá»¥ng vá»›i cáº·p ngÃ´n ngá»¯ Anh-Viá»‡t, thÃ¬ tháº¥y káº¿t quáº£ cÃ³ chÃºt cáº£i tiáº¿n, tuy nhiÃªn em khÃ´ng hiá»ƒu táº¡i sao nÃ³ láº¡i tá»‘t hÆ¡n.
Cá»¥ thá»ƒ: BÃ i bÃ¡o nÃ y nÃ³i vá» viá»‡c edit ngá»¯ liá»‡u trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»‹ch mÃ¡y
- Dá»¯ liá»‡u ban Ä‘áº§u => huáº¥n luyá»‡n => mÃ´ hÃ¬nh Base
- Dá»¯ liá»‡u ban Ä‘áº§u => edit => huáº¥n luyá»‡n => mÃ´ hÃ¬nh X
Khi test: mÃ´ hÃ¬nh X cho ra Ä‘iá»ƒm BLEU tá»‘t hÆ¡n vá»›i mÃ´ hÃ¬nh Base.
Trong quÃ¡ trÃ¬nh edit, ngá»¯ liá»‡u bá»‹ sá»­a láº¡i chÃºt xÃ­u, cá»¥ thá»ƒ lÃ  cÃ¢u nguá»“n sáº½ Ä‘Æ°á»£c ná»‘i vá»›i 1 cÃ¢u Ä‘Ã­ch náº¿u thoáº£ Ä‘iá»u kiá»‡n cho trÆ°á»›c (xem áº£nh sáº½ rÃµ hÆ¡n)
Anh/chá»‹ nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giáº£i thÃ­ch cho em biáº¿t táº¡i sao trong quÃ¡ trÃ¬nh edit, viá»‡c ghÃ©p ná»‘i cÃ¢u theo kiá»ƒu cá»§a tÃ¡c giáº£ Ä‘a pháº§n láº¡i giÃºp mÃ´ hÃ¬nh cá»§a mÃ¬nh Ä‘Æ°á»£c tá»‘t hÆ¡n nhá»‰?
Em cáº£m Æ¡n nhiá»u áº¡
#NLP","Em xin chÃ o cáº£ nhÃ , cho em há»i má»™t chÃºt vá» dá»‹ch mÃ¡y trong NLP Em cÃ³ lÃ m theo phÆ°Æ¡ng phÃ¡p nÃªu trong bÃ i bÃ¡o nÃ y https://aclanthology.org/2020.acl-main.144, vÃ  Ã¡p dá»¥ng vá»›i cáº·p ngÃ´n ngá»¯ Anh-Viá»‡t, thÃ¬ tháº¥y káº¿t quáº£ cÃ³ chÃºt cáº£i tiáº¿n, tuy nhiÃªn em khÃ´ng hiá»ƒu táº¡i sao nÃ³ láº¡i tá»‘t hÆ¡n. Cá»¥ thá»ƒ: BÃ i bÃ¡o nÃ y nÃ³i vá» viá»‡c edit ngá»¯ liá»‡u trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»‹ch mÃ¡y - Dá»¯ liá»‡u ban Ä‘áº§u => huáº¥n luyá»‡n => mÃ´ hÃ¬nh Base - Dá»¯ liá»‡u ban Ä‘áº§u => edit => huáº¥n luyá»‡n => mÃ´ hÃ¬nh X Khi test: mÃ´ hÃ¬nh X cho ra Ä‘iá»ƒm BLEU tá»‘t hÆ¡n vá»›i mÃ´ hÃ¬nh Base. Trong quÃ¡ trÃ¬nh edit, ngá»¯ liá»‡u bá»‹ sá»­a láº¡i chÃºt xÃ­u, cá»¥ thá»ƒ lÃ  cÃ¢u nguá»“n sáº½ Ä‘Æ°á»£c ná»‘i vá»›i 1 cÃ¢u Ä‘Ã­ch náº¿u thoáº£ Ä‘iá»u kiá»‡n cho trÆ°á»›c (xem áº£nh sáº½ rÃµ hÆ¡n) Anh/chá»‹ nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giáº£i thÃ­ch cho em biáº¿t táº¡i sao trong quÃ¡ trÃ¬nh edit, viá»‡c ghÃ©p ná»‘i cÃ¢u theo kiá»ƒu cá»§a tÃ¡c giáº£ Ä‘a pháº§n láº¡i giÃºp mÃ´ hÃ¬nh cá»§a mÃ¬nh Ä‘Æ°á»£c tá»‘t hÆ¡n nhá»‰? Em cáº£m Æ¡n nhiá»u áº¡",#NLP,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang Ä‘á»c má»™t sá»‘ tÃ i liá»‡u vá» phÃ¢n rÃ£ ma tráº­n vÃ  gáº·p má»™t trÆ°á»ng há»£p mÃ  em chÆ°a rÃµ láº¯m, ""the eigenvectors of a discrete line are the cosine and sinusoidal functions"" -> Ã½ nÃ³i á»Ÿ Ä‘Ã¢y lÃ  ""cÃ¡c vector riÃªng cá»§a má»™t Ä‘Æ°á»ng rá»i ráº¡c lÃ  hÃ m cos/sin"". CÃ¡c cao thá»§ cÃ³ thá»ƒ chá»‰ giÃ¡o giÃºp em vÃ¬ sao láº¡i nhÆ° váº­y Ä‘Æ°á»£c khÃ´ng áº¡","ChÃ o má»i ngÆ°á»i, em Ä‘ang Ä‘á»c má»™t sá»‘ tÃ i liá»‡u vá» phÃ¢n rÃ£ ma tráº­n vÃ  gáº·p má»™t trÆ°á»ng há»£p mÃ  em chÆ°a rÃµ láº¯m, ""the eigenvectors of a discrete line are the cosine and sinusoidal functions"" -> Ã½ nÃ³i á»Ÿ Ä‘Ã¢y lÃ  ""cÃ¡c vector riÃªng cá»§a má»™t Ä‘Æ°á»ng rá»i ráº¡c lÃ  hÃ m cos/sin"". CÃ¡c cao thá»§ cÃ³ thá»ƒ chá»‰ giÃ¡o giÃºp em vÃ¬ sao láº¡i nhÆ° váº­y Ä‘Æ°á»£c khÃ´ng áº¡",,,,,
"xin chÃ o má»i ngÆ°á»i áº¡, cho em há»i trong group mÃ¬nh cÃ³ ai tá»«ng Ä‘á»c qua 2 cuá»‘n nÃ y chÆ°a cÃ³ thá»ƒ cho em chÃºt review Ä‘Æ°á»£c khÃ´ng áº¡, vÃ  nÃªn chá»n cuá»‘n nÃ o áº¡. má»¥c tiÃªu em hÆ°á»›ng tá»›i lÃ  Engineering áº¡. em cÅ©ng cÃ³ má»™t chÃºt kinh nghiá»‡m vá» ML rá»“i nhÆ°ng muá»‘n Ä‘á»c láº¡i Ä‘á»ƒ hiá»ƒu sÃ¢u hÆ¡n máº·t toÃ¡n há»c vÃ  phÃ¢n xÃ¡c suáº¥t thá»‘ng kÃª áº¡. cáº£m Æ¡n má»i ngÆ°á»i áº¡!","xin chÃ o má»i ngÆ°á»i áº¡, cho em há»i trong group mÃ¬nh cÃ³ ai tá»«ng Ä‘á»c qua 2 cuá»‘n nÃ y chÆ°a cÃ³ thá»ƒ cho em chÃºt review Ä‘Æ°á»£c khÃ´ng áº¡, vÃ  nÃªn chá»n cuá»‘n nÃ o áº¡. má»¥c tiÃªu em hÆ°á»›ng tá»›i lÃ  Engineering áº¡. em cÅ©ng cÃ³ má»™t chÃºt kinh nghiá»‡m vá» ML rá»“i nhÆ°ng muá»‘n Ä‘á»c láº¡i Ä‘á»ƒ hiá»ƒu sÃ¢u hÆ¡n máº·t toÃ¡n há»c vÃ  phÃ¢n xÃ¡c suáº¥t thá»‘ng kÃª áº¡. cáº£m Æ¡n má»i ngÆ°á»i áº¡!",,,,,
"Newbie_pytorch_samecode_same_data_difference_result
ae cho mÃ¬nh há»i chÃºt mÃ¬nh cÃ³ model há»c tá»‘t á»Ÿ local nhÆ°ng lÃªn colab pro thÃ¬ khÃ´ng há»c Ä‘Æ°á»£c gÃ¬ lÃ  hiá»‡n tÆ°á»£ng gÃ¬ nhá»‰?
Edit: mng cÃ³ giáº£i phÃ¡p kháº¯c phá»¥c khÃ´ng?
https://stackoverflow.com/questions/66446056/different-results-on-google-colab-than-local",Newbie_pytorch_samecode_same_data_difference_result ae cho mÃ¬nh há»i chÃºt mÃ¬nh cÃ³ model há»c tá»‘t á»Ÿ local nhÆ°ng lÃªn colab pro thÃ¬ khÃ´ng há»c Ä‘Æ°á»£c gÃ¬ lÃ  hiá»‡n tÆ°á»£ng gÃ¬ nhá»‰? Edit: mng cÃ³ giáº£i phÃ¡p kháº¯c phá»¥c khÃ´ng? https://stackoverflow.com/questions/66446056/different-results-on-google-colab-than-local,,,,,
"Xin chÃ o cáº£ nhÃ , cho em há»i má»™t chÃºt vá» Dá»‹ch mÃ¡y.
Em cÃ³ lÃ m theo phÆ°Æ¡ng phÃ¡p nÃªu trong bÃ i bÃ¡o nÃ y https://aclanthology.org/2020.acl-main.144, vÃ  Ã¡p dá»¥ng vá»›i cáº·p ngÃ´n ngá»¯ Anh-Viá»‡t, thÃ¬ tháº¥y káº¿t quáº£ cÃ³ chÃºt cáº£i tiáº¿n, tuy nhiÃªn em khÃ´ng hiá»ƒu táº¡i sao nÃ³ láº¡i tá»‘t hÆ¡n.
Cá»¥ thá»ƒ: BÃ i bÃ¡o nÃ y nÃ³i vá» viá»‡c edit ngá»¯ liá»‡u trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»‹ch mÃ¡y
- Dá»¯ liá»‡u ban Ä‘áº§u => huáº¥n luyá»‡n => mÃ´ hÃ¬nh Base
- Dá»¯ liá»‡u ban Ä‘áº§u => edit => huáº¥n luyá»‡n => mÃ´ hÃ¬nh X
Khi test: mÃ´ hÃ¬nh X cho ra Ä‘iá»ƒm BLEU tá»‘t hÆ¡n vá»›i mÃ´ hÃ¬nh Base.
Trong quÃ¡ trÃ¬nh edit, ngá»¯ liá»‡u bá»‹ sá»­a láº¡i chÃºt xÃ­u, cá»¥ thá»ƒ lÃ  cÃ¢u nguá»“n sáº½ Ä‘Æ°á»£c ná»‘i vá»›i 1 cÃ¢u Ä‘Ã­ch náº¿u thoáº£ Ä‘iá»u kiá»‡n cho trÆ°á»›c (xem áº£nh sáº½ rÃµ hÆ¡n)
Báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giáº£i thÃ­ch cho mÃ¬nh biáº¿t táº¡i sao trong quÃ¡ trÃ¬nh edit, viá»‡c ghÃ©p ná»‘i cÃ¢u theo kiá»ƒu cá»§a tÃ¡c giáº£ Ä‘a pháº§n láº¡i giÃºp mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»‘t hÆ¡n nhá»‰?
LÆ°u Ã½: quÃ¡ trÃ¬nh edit thÃ¬ em cÃ³ dÃ¹ng SBERT Ä‘á»ƒ so sÃ¡nh vá»›i SIF cá»§a bÃ i bÃ¡o gá»‘c, nhÆ°ng viá»‡c nÃ y khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¢u há»i Ä‘Æ°a ra.","Xin chÃ o cáº£ nhÃ , cho em há»i má»™t chÃºt vá» Dá»‹ch mÃ¡y. Em cÃ³ lÃ m theo phÆ°Æ¡ng phÃ¡p nÃªu trong bÃ i bÃ¡o nÃ y https://aclanthology.org/2020.acl-main.144, vÃ  Ã¡p dá»¥ng vá»›i cáº·p ngÃ´n ngá»¯ Anh-Viá»‡t, thÃ¬ tháº¥y káº¿t quáº£ cÃ³ chÃºt cáº£i tiáº¿n, tuy nhiÃªn em khÃ´ng hiá»ƒu táº¡i sao nÃ³ láº¡i tá»‘t hÆ¡n. Cá»¥ thá»ƒ: BÃ i bÃ¡o nÃ y nÃ³i vá» viá»‡c edit ngá»¯ liá»‡u trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»‹ch mÃ¡y - Dá»¯ liá»‡u ban Ä‘áº§u => huáº¥n luyá»‡n => mÃ´ hÃ¬nh Base - Dá»¯ liá»‡u ban Ä‘áº§u => edit => huáº¥n luyá»‡n => mÃ´ hÃ¬nh X Khi test: mÃ´ hÃ¬nh X cho ra Ä‘iá»ƒm BLEU tá»‘t hÆ¡n vá»›i mÃ´ hÃ¬nh Base. Trong quÃ¡ trÃ¬nh edit, ngá»¯ liá»‡u bá»‹ sá»­a láº¡i chÃºt xÃ­u, cá»¥ thá»ƒ lÃ  cÃ¢u nguá»“n sáº½ Ä‘Æ°á»£c ná»‘i vá»›i 1 cÃ¢u Ä‘Ã­ch náº¿u thoáº£ Ä‘iá»u kiá»‡n cho trÆ°á»›c (xem áº£nh sáº½ rÃµ hÆ¡n) Báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ giáº£i thÃ­ch cho mÃ¬nh biáº¿t táº¡i sao trong quÃ¡ trÃ¬nh edit, viá»‡c ghÃ©p ná»‘i cÃ¢u theo kiá»ƒu cá»§a tÃ¡c giáº£ Ä‘a pháº§n láº¡i giÃºp mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»‘t hÆ¡n nhá»‰? LÆ°u Ã½: quÃ¡ trÃ¬nh edit thÃ¬ em cÃ³ dÃ¹ng SBERT Ä‘á»ƒ so sÃ¡nh vá»›i SIF cá»§a bÃ i bÃ¡o gá»‘c, nhÆ°ng viá»‡c nÃ y khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¢u há»i Ä‘Æ°a ra.",,,,,
"cÃ³ anh chá»‹ hay báº¡n nÃ o cÃ³ kinh nghiá»‡m cáº¯t áº£nh trong video cÃ³ thá»ƒ cho em (mÃ¬nh) cÃ¡ch cáº¯t áº£nh sao cho Ä‘áº£m báº£o Ä‘Æ°á»£c khÃ´ng bá» sÃ³t object vÃ¬ video thÃ¬ cÃ³ lÃºc ngÆ°á»i quay sáº½ cÃ³ Ä‘oáº¡n quay nhanh vÃ  cÃ³ Ä‘oáº¡n quay cháº­m, náº¿u cáº¯t thá»§ cÃ´ng cá»© 20 frame rá»“i cáº¯t thÃ¬ lÃºc Ä‘oáº¡n ngÆ°á»i quay lia mÃ¡y thÃ¬ sáº½ bá»‹ sÃ³t frame mÃ¬nh cáº§n . nhÆ°ng váº«n Ä‘áº£m báº£o Ä‘Æ°á»£c khÃ´ng cáº¯t quÃ¡ nhiá»u frame nhá»‰. em(mÃ¬nh) cáº£m Æ¡n áº¡ .","cÃ³ anh chá»‹ hay báº¡n nÃ o cÃ³ kinh nghiá»‡m cáº¯t áº£nh trong video cÃ³ thá»ƒ cho em (mÃ¬nh) cÃ¡ch cáº¯t áº£nh sao cho Ä‘áº£m báº£o Ä‘Æ°á»£c khÃ´ng bá» sÃ³t object vÃ¬ video thÃ¬ cÃ³ lÃºc ngÆ°á»i quay sáº½ cÃ³ Ä‘oáº¡n quay nhanh vÃ  cÃ³ Ä‘oáº¡n quay cháº­m, náº¿u cáº¯t thá»§ cÃ´ng cá»© 20 frame rá»“i cáº¯t thÃ¬ lÃºc Ä‘oáº¡n ngÆ°á»i quay lia mÃ¡y thÃ¬ sáº½ bá»‹ sÃ³t frame mÃ¬nh cáº§n . nhÆ°ng váº«n Ä‘áº£m báº£o Ä‘Æ°á»£c khÃ´ng cáº¯t quÃ¡ nhiá»u frame nhá»‰. em(mÃ¬nh) cáº£m Æ¡n áº¡ .",,,,,
"ChÃ o má»i ngÆ°á»i, 

MÃ¬nh Ä‘áº¿n tá»« team BÆ¡ cuá»™c thi Zalo AI - Legal text (top 3 public test) Ä‘á»£t vá»«a rá»“i.  Code má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o á»Ÿ Ä‘Ã¢y:
https://github.com/phuongnm-bkhn/legal_text_retrieval

NhÃ¬n chung, phÆ°Æ¡ng phÃ¡p khÃ¡ Ä‘Æ¡n giáº£n: 
B1: sinh negative samples dá»±a trÃªn Ä‘iá»ƒm cosine cá»§a tfidf, vÃ  bm25 score 
B2: fine-tune pretrained PhoBERT model (+ NlpHUST model) 

-- 
ps: cáº£m Æ¡n vÃ¬ sá»± Ä‘Ã³ng gÃ³p cá»§a  Äá»— ÄÃ¬nh TrÆ°á»ng vÃ  lab cá»§a mÃ¬nh á»Ÿ JAIST: ""NGUYEN lab""
https://www.jaist.ac.jp/is/labs/nguyen-lab/home/","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘áº¿n tá»« team BÆ¡ cuá»™c thi Zalo AI - Legal text (top 3 public test) Ä‘á»£t vá»«a rá»“i. Code má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o á»Ÿ Ä‘Ã¢y: https://github.com/phuongnm-bkhn/legal_text_retrieval NhÃ¬n chung, phÆ°Æ¡ng phÃ¡p khÃ¡ Ä‘Æ¡n giáº£n: B1: sinh negative samples dá»±a trÃªn Ä‘iá»ƒm cosine cá»§a tfidf, vÃ  bm25 score B2: fine-tune pretrained PhoBERT model (+ NlpHUST model) -- ps: cáº£m Æ¡n vÃ¬ sá»± Ä‘Ã³ng gÃ³p cá»§a Äá»— ÄÃ¬nh TrÆ°á»ng vÃ  lab cá»§a mÃ¬nh á»Ÿ JAIST: ""NGUYEN lab"" https://www.jaist.ac.jp/is/labs/nguyen-lab/home/",,,,,
anh chá»‹ trong nhÃ³m cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ cho em keyword vÃ  source code vá» model cÃ³ thá»ƒ chá»n ra Ä‘Æ°á»£c frame tá»‘t nháº¥t khi Ä‘Æ°a vÃ o táº­p áº£nh hoáº·c 1 video ngáº¯n kiá»ƒu nhÆ° áº£nh dÆ°á»›i khÃ´ng áº¡. em cáº£m Æ¡n áº¡,anh chá»‹ trong nhÃ³m cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ cho em keyword vÃ  source code vá» model cÃ³ thá»ƒ chá»n ra Ä‘Æ°á»£c frame tá»‘t nháº¥t khi Ä‘Æ°a vÃ o táº­p áº£nh hoáº·c 1 video ngáº¯n kiá»ƒu nhÆ° áº£nh dÆ°á»›i khÃ´ng áº¡. em cáº£m Æ¡n áº¡,,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn Ä‘Ã£ ra trÆ°á»ng 1 nÄƒm, hiá»‡n Ä‘ang Ä‘i lÃ m táº¡i má»™t cÃ´ng ty vá» AI, ML. Em cÃ³ dá»± Ä‘á»‹nh há»c lÃªn tháº¡c sÄ© ngÃ nh Khoa há»c mÃ¡y tÃ­nh vÃ¬ em tháº¥y ngÃ nh nÃ y liÃªn quan nháº¥t tá»›i AI, ML. NhÆ°ng em chÆ°a biáº¿t nÃªn há»c trÆ°á»ng nÃ o tá»‘t, há»c phÃ­ vÃ  thá»i gian há»c ra sao nÃªn muá»‘n xin cÃ¡c anh chá»‹ Ä‘i trÆ°á»›c lá»i khuyÃªn áº¡.
Em chá»‰ cÃ³ thá»ƒ há»c á»Ÿ HÃ  Ná»™i vÃ¬ váº«n cÃ²n há»£p Ä‘á»“ng lÃ m viá»‡c táº¡i cÃ´ng ty. Em cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn Ä‘Ã£ ra trÆ°á»ng 1 nÄƒm, hiá»‡n Ä‘ang Ä‘i lÃ m táº¡i má»™t cÃ´ng ty vá» AI, ML. Em cÃ³ dá»± Ä‘á»‹nh há»c lÃªn tháº¡c sÄ© ngÃ nh Khoa há»c mÃ¡y tÃ­nh vÃ¬ em tháº¥y ngÃ nh nÃ y liÃªn quan nháº¥t tá»›i AI, ML. NhÆ°ng em chÆ°a biáº¿t nÃªn há»c trÆ°á»ng nÃ o tá»‘t, há»c phÃ­ vÃ  thá»i gian há»c ra sao nÃªn muá»‘n xin cÃ¡c anh chá»‹ Ä‘i trÆ°á»›c lá»i khuyÃªn áº¡. Em chá»‰ cÃ³ thá»ƒ há»c á»Ÿ HÃ  Ná»™i vÃ¬ váº«n cÃ²n há»£p Ä‘á»“ng lÃ m viá»‡c táº¡i cÃ´ng ty. Em cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m má»™t website Airbnb vÃ  Ä‘ang muá»‘n tÃ­ch há»£p mÃ¡y há»c vÃ o web nhÆ° lÃ  lÃ  mf má»™t há»‡ thá»‘ng gá»£i Ã½ , há»‡ thá»‘ng tÃ¬m kiáº¿m tá»‘t hÆ¡n vÃ  há»‡ thá»‘ng phÃ¢n loáº¡i bÃ¬nh luáº­n nhÆ°ng do láº§n Ä‘áº§u lÃ m website vÃ  khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nÃªn mong má»i ngÆ°á»i giÃºp em gá»£i Ã½ vá»›i áº¡.
Website Ä‘Æ°á»£c xÃ¢y dá»±ng Backend bá»›i Nodejs Expressjs , Database lÃ  Mongodb vÃ  em cÃ³ dÃ¹ng Graphql Ä‘á»ƒ cho Client gá»i Api tÆ°Æ¡ng tÃ¡c vá»›i Server áº¡. Em cÅ©ng cÃ³ kiáº¿n thá»©c vá» mÃ¡y há»c vÃ  Python áº¡ nhÆ°ng chá»‰ dá»«ng á»Ÿ má»©c cÆ¡ báº£n, vÃ  hÆ¡i Ä‘Æ¡n giáº£n áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c","ChÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m má»™t website Airbnb vÃ  Ä‘ang muá»‘n tÃ­ch há»£p mÃ¡y há»c vÃ o web nhÆ° lÃ  lÃ  mf má»™t há»‡ thá»‘ng gá»£i Ã½ , há»‡ thá»‘ng tÃ¬m kiáº¿m tá»‘t hÆ¡n vÃ  há»‡ thá»‘ng phÃ¢n loáº¡i bÃ¬nh luáº­n nhÆ°ng do láº§n Ä‘áº§u lÃ m website vÃ  khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nÃªn mong má»i ngÆ°á»i giÃºp em gá»£i Ã½ vá»›i áº¡. Website Ä‘Æ°á»£c xÃ¢y dá»±ng Backend bá»›i Nodejs Expressjs , Database lÃ  Mongodb vÃ  em cÃ³ dÃ¹ng Graphql Ä‘á»ƒ cho Client gá»i Api tÆ°Æ¡ng tÃ¡c vá»›i Server áº¡. Em cÅ©ng cÃ³ kiáº¿n thá»©c vá» mÃ¡y há»c vÃ  Python áº¡ nhÆ°ng chá»‰ dá»«ng á»Ÿ má»©c cÆ¡ báº£n, vÃ  hÆ¡i Ä‘Æ¡n giáº£n áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c",,,,,
Join cuá»™c thi Ä‘á»ƒ cÃ¹ng nhau xÃ¢y dá»±ng mÃ´ hÃ¬nh auto trading cho thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam nÃ o cÃ¡c báº¡n.,Join cuá»™c thi Ä‘á»ƒ cÃ¹ng nhau xÃ¢y dá»±ng mÃ´ hÃ¬nh auto trading cho thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam nÃ o cÃ¡c báº¡n.,,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i vá» cÃ¡ch deploy má»™t project Python vá»›i áº¡.
Em Ä‘Ã£ hoÃ n thiá»‡n viá»‡c training má»™t model, vÃ  cÅ©ng Ä‘Ã£ viáº¿t code xá»­ lÃ½ logic (láº¥y input, xá»­ lÃ½ output, call API Ä‘áº¿n server, ...) nhÆ°ng táº¥t cáº£ Ä‘á»u sá»­ dá»¥ng Python. Giá» em muá»‘n Ä‘Ã³ng gÃ³i project kÃ¨m vá»›i cÃ¡c dependencies vÃ  Ä‘Æ°a lÃªn má»™t mÃ¡y chá»§ sá»­ dá»¥ng há»‡ Ä‘iá»u hÃ nh Windows thÃ¬ sá»­ dá»¥ng cÃ¡ch nÃ o lÃ  tá»‘t nháº¥t áº¡?
Em Ä‘Ã£ cÃ³ tÃ¬m hiá»ƒu qua Docker nhÆ°ng Docker há»— trá»£ khÃ´ng tá»‘t vá»›i há»‡ Ä‘iá»u hÃ nh Windows náº¿u muá»‘n sá»­ dá»¥ng GPU.","Má»i ngÆ°á»i Æ¡i cho em há»i vá» cÃ¡ch deploy má»™t project Python vá»›i áº¡. Em Ä‘Ã£ hoÃ n thiá»‡n viá»‡c training má»™t model, vÃ  cÅ©ng Ä‘Ã£ viáº¿t code xá»­ lÃ½ logic (láº¥y input, xá»­ lÃ½ output, call API Ä‘áº¿n server, ...) nhÆ°ng táº¥t cáº£ Ä‘á»u sá»­ dá»¥ng Python. Giá» em muá»‘n Ä‘Ã³ng gÃ³i project kÃ¨m vá»›i cÃ¡c dependencies vÃ  Ä‘Æ°a lÃªn má»™t mÃ¡y chá»§ sá»­ dá»¥ng há»‡ Ä‘iá»u hÃ nh Windows thÃ¬ sá»­ dá»¥ng cÃ¡ch nÃ o lÃ  tá»‘t nháº¥t áº¡? Em Ä‘Ã£ cÃ³ tÃ¬m hiá»ƒu qua Docker nhÆ°ng Docker há»— trá»£ khÃ´ng tá»‘t vá»›i há»‡ Ä‘iá»u hÃ nh Windows náº¿u muá»‘n sá»­ dá»¥ng GPU.",,,,,
"ChÃ o má»i ngÆ°á»i em cÃ³ tham gia Zalo AI challenge task NLP nhÆ°ng káº¿t quáº£ ráº¥t tháº¥p, khÃ´ng biáº¿t anh/chá»‹ tham gia cÃ³ thá»ƒ chia sáº» solution Ä‘á»ƒ em tham kháº£o vÃ  nghiÃªn cá»©u Ä‘Æ°á»£c khÃ´ng, em cáº£m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i em cÃ³ tham gia Zalo AI challenge task NLP nhÆ°ng káº¿t quáº£ ráº¥t tháº¥p, khÃ´ng biáº¿t anh/chá»‹ tham gia cÃ³ thá»ƒ chia sáº» solution Ä‘á»ƒ em tham kháº£o vÃ  nghiÃªn cá»©u Ä‘Æ°á»£c khÃ´ng, em cáº£m Æ¡n áº¡",,,,,
Má»i ngÆ°á»i cho em há»i vá» pháº§n cÃ i Ä‘áº·t cá»§a thuáº­t toÃ¡n ID3 trong BÃ i 34: Decision Trees (1): Iterative Dichotomiser 3 cá»§a anh Tiá»‡p trÃªn web Machine Learning CÆ¡ Báº£n. Chá»— nÃ y táº¡i sao láº¡i kiá»ƒm tra Ä‘iá»u kiá»‡n node.entropy < self.min_gain áº¡? Ã nghÄ©a cá»§a bÆ°á»›c kiá»ƒm tra nÃ y lÃ  gÃ¬? Em cáº£m Æ¡n áº¡!,Má»i ngÆ°á»i cho em há»i vá» pháº§n cÃ i Ä‘áº·t cá»§a thuáº­t toÃ¡n ID3 trong BÃ i 34: Decision Trees (1): Iterative Dichotomiser 3 cá»§a anh Tiá»‡p trÃªn web Machine Learning CÆ¡ Báº£n. Chá»— nÃ y táº¡i sao láº¡i kiá»ƒm tra Ä‘iá»u kiá»‡n node.entropy < self.min_gain áº¡? Ã nghÄ©a cá»§a bÆ°á»›c kiá»ƒm tra nÃ y lÃ  gÃ¬? Em cáº£m Æ¡n áº¡!,,,,,
"ChÃ o cáº£ nhÃ . HÃ´m qua em cÃ³ lÃ m má»™t clip vá» train model trÃªn GPU cÃ¹a Mac M1. HÃ´m nay em xin giá»›i thiá»‡u má»™t clip vá» train model trÃªn GPU cá»§a Mac Intel.
Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n Ä‘ang há»c áº¡!",ChÃ o cáº£ nhÃ . HÃ´m qua em cÃ³ lÃ m má»™t clip vá» train model trÃªn GPU cÃ¹a Mac M1. HÃ´m nay em xin giá»›i thiá»‡u má»™t clip vá» train model trÃªn GPU cá»§a Mac Intel. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n Ä‘ang há»c áº¡!,,,,,
"ChÃ o má»i ngÆ°á»i áº¡,
Em muá»‘n Ä‘Æ°a má»™t model classification Ã¢m thanh lÃªn Ä‘iá»‡n thoáº¡i android qua android studio áº¡, khÃ´ng biáº¿t ai Ä‘Ã£ lÃ m rá»“i thÃ¬ cÃ³ thá»ƒ cho em xin kinh nghiá»‡m khÃ´ng áº¡ nhÆ° lÃ  dÃ¹ng framework gi áº¡. Em cÃ¡m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i áº¡, Em muá»‘n Ä‘Æ°a má»™t model classification Ã¢m thanh lÃªn Ä‘iá»‡n thoáº¡i android qua android studio áº¡, khÃ´ng biáº¿t ai Ä‘Ã£ lÃ m rá»“i thÃ¬ cÃ³ thá»ƒ cho em xin kinh nghiá»‡m khÃ´ng áº¡ nhÆ° lÃ  dÃ¹ng framework gi áº¡. Em cÃ¡m Æ¡n áº¡",,,,,
"Hi m.n, a Tiá»‡p,
Tá»‘i qua e vá»«a xem xong video cá»§a a Mark, cÃ³ tÃ¬m hiá»ƒu xem thÃ¬ tháº¥y cÃ³ nÃ³i sá»­ dá»¥ng detectron( object detection) vÃ  alphapose( pose estimation).
Cho e há»i ngoÃ i 2 algorithms Ä‘Ã³ ra, thÃ¬ cÃ²n cÃ³ thuáº­t toÃ¡n nÃ o khÃ¡c trong PJ nÃ y ko áº¡!
E cáº£m Æ¡n áº¡!","Hi m.n, a Tiá»‡p, Tá»‘i qua e vá»«a xem xong video cá»§a a Mark, cÃ³ tÃ¬m hiá»ƒu xem thÃ¬ tháº¥y cÃ³ nÃ³i sá»­ dá»¥ng detectron( object detection) vÃ  alphapose( pose estimation). Cho e há»i ngoÃ i 2 algorithms Ä‘Ã³ ra, thÃ¬ cÃ²n cÃ³ thuáº­t toÃ¡n nÃ o khÃ¡c trong PJ nÃ y ko áº¡! E cáº£m Æ¡n áº¡!",,,,,
"Em cÃ³ tÃ¬m hiá»ƒu má»™t bÃ i bÃ¡o Ä‘á»ƒ bÃ¡o cÃ¡o thÃ¬ em khÃ´ng hiá»ƒu máº¥y con sá»‘ trong hÃ¬nh .104,6,9
CÃ¡c chá»‰ sá»‘ alt.atheism ... lÃ  gÃ¬ áº¡.
CÃ¡c sá»‘ á»Ÿ Ä‘Æ°á»ng chÃ©o cÃ ng cao thÃ¬ tÃ­nh chÃ­nh xÃ¡c cÃ ng Ä‘Ãºng áº¡.
Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡","Em cÃ³ tÃ¬m hiá»ƒu má»™t bÃ i bÃ¡o Ä‘á»ƒ bÃ¡o cÃ¡o thÃ¬ em khÃ´ng hiá»ƒu máº¥y con sá»‘ trong hÃ¬nh .104,6,9 CÃ¡c chá»‰ sá»‘ alt.atheism ... lÃ  gÃ¬ áº¡. CÃ¡c sá»‘ á»Ÿ Ä‘Æ°á»ng chÃ©o cÃ ng cao thÃ¬ tÃ­nh chÃ­nh xÃ¡c cÃ ng Ä‘Ãºng áº¡. Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡",,,,,
"xin phÃ©p má»i ngÆ°á»i em má»›i há»c vá» spark cho em há»i má»™t xÃ­u áº¡
Ä‘á» bÃ i lÃ  cho má»™t list vÃ  nÃ³ sáº½ sá»­ lÃ½ tÃ­nh toÃ¡n Ä‘á»ƒ cá»™ng cÃ¡c sá»‘ bÃªn trong list Ä‘Ã³
trong video máº«u em tháº¥y Ä‘Æ°á»£c há» cá»™ng 2 sá»‘ Ä‘áº§u, sá»‘ thá»© 3 sáº½ Ä‘Æ°á»£c gÃ¡n vÃ o hÃ ng chá» Ä‘á»ƒ tiáº¿p tá»¥c cá»™ng trong bÆ°á»›c tiáº¿p theo
trong code thá»±c táº¿ em cháº¡y thÃ¬ em láº¡i tháº¥y ráº±ng nÃ³ gá»™p cÃ¡c cáº·p 2 sá»‘ liÃªn tiáº¿p vÃ  cá»™ng Ä‘Ãºng theo tiÃªu chÃ­ parallelize chá»© khÃ´ng tuáº§n tá»±
code giá»‘ng nhau 100% vÃ  2 phiÃªn báº£n spark lÃ  3.0.1 vÃ  3.0.3
váº­y khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch cho em táº¡i sao Ä‘Æ°á»£c khÃ´ng áº¡
Ä‘oáº¡n em tháº¯c máº¯c á»Ÿ cuá»‘i áº¡ chá»— cÃ³ 2 hÃ ng sá»‘","xin phÃ©p má»i ngÆ°á»i em má»›i há»c vá» spark cho em há»i má»™t xÃ­u áº¡ Ä‘á» bÃ i lÃ  cho má»™t list vÃ  nÃ³ sáº½ sá»­ lÃ½ tÃ­nh toÃ¡n Ä‘á»ƒ cá»™ng cÃ¡c sá»‘ bÃªn trong list Ä‘Ã³ trong video máº«u em tháº¥y Ä‘Æ°á»£c há» cá»™ng 2 sá»‘ Ä‘áº§u, sá»‘ thá»© 3 sáº½ Ä‘Æ°á»£c gÃ¡n vÃ o hÃ ng chá» Ä‘á»ƒ tiáº¿p tá»¥c cá»™ng trong bÆ°á»›c tiáº¿p theo trong code thá»±c táº¿ em cháº¡y thÃ¬ em láº¡i tháº¥y ráº±ng nÃ³ gá»™p cÃ¡c cáº·p 2 sá»‘ liÃªn tiáº¿p vÃ  cá»™ng Ä‘Ãºng theo tiÃªu chÃ­ parallelize chá»© khÃ´ng tuáº§n tá»± code giá»‘ng nhau 100% vÃ  2 phiÃªn báº£n spark lÃ  3.0.1 vÃ  3.0.3 váº­y khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch cho em táº¡i sao Ä‘Æ°á»£c khÃ´ng áº¡ Ä‘oáº¡n em tháº¯c máº¯c á»Ÿ cuá»‘i áº¡ chá»— cÃ³ 2 hÃ ng sá»‘",,"#math, #Q&A",,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡ch train model Tensorflow/Keras trÃªn Macbook Pro M1. Em máº¡nh dáº¡n lÃ m clip Ä‘á»ƒ chia sáº» cÃ¹ng cÃ¡c báº¡n Ä‘ang vÆ°á»›ng pháº§n nÃ y.
Xin cáº£m Æ¡n cÃ¡c bÃ¡c Ä‘Ã£ xem vÃ  á»§ng há»™.","KÃ­nh chÃ o cÃ¡c bÃ¡c, em cÃ³ Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡ch train model Tensorflow/Keras trÃªn Macbook Pro M1. Em máº¡nh dáº¡n lÃ m clip Ä‘á»ƒ chia sáº» cÃ¹ng cÃ¡c báº¡n Ä‘ang vÆ°á»›ng pháº§n nÃ y. Xin cáº£m Æ¡n cÃ¡c bÃ¡c Ä‘Ã£ xem vÃ  á»§ng há»™.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Em hiá»‡n Ä‘ang lÃ m 1 project cuá»‘i kÃ¬ vá» nháº­n dáº¡ng hÃ nh Ä‘á»™ng dÃ¹ng thÃ´ng tin khung xÆ°Æ¡ng ( DÃ™ng openpose hoáº·c mediapipe Ä‘á»ƒ detect khung xÆ°Æ¡ng cá»§a ngÆ°á»i rá»“i nháº­n dáº¡ng), output mong muá»‘n cá»§a e lÃ  ra Ä‘Æ°á»£c 1 video mÃ  cÃ³ thá»ƒ nháº­n dáº¡ng Ä‘Æ°á»£c hÃ nh Ä‘á»™ng trong video gá»“m nhiá»u hÃ nh Ä‘á»™ng nhÆ° trong video e gá»­i.
HIá»‡n táº¡i e lÃ m xong hÆ°á»›ng vá» nháº­n dáº¡ng rá»“i ( tá»©c lÃ  cÃ³ 1 chuá»—i khung xÆ°Æ¡ng gá»“m thÃ´ng tin cá»§a 1 hÃ nh Ä‘á»™ng -> train model Ä‘á»ƒ nháº­n dáº¡ng ra hÃ nh Ä‘á»™ng Ä‘Ã³) .
E cÃ³ tháº¯c máº¯c mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p Ä‘Ã³ lÃ  BÃ¢y giá» mÃ¬nh Ã¡p dá»¥ng model Ä‘Ã³ vÃ o video gá»“m nhiá»u hÃ nh Ä‘á»™ng diá»…n ra thÃ¬ mÃ¬nh cÃ³ thá»ƒ Ã¡p dá»¥ng algorithm nÃ o, flow nháº­n dáº¡ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ nháº­n dáº¡ng chuá»—i nhiá»u hÃ nh Ä‘á»™ng Ä‘Ã³ khÃ´ng áº¡ ( vÃ¬ model trÆ°á»›c Ä‘Ã³ lÃ  chá»‰ dÃ¹ng vá»›i tá»«ng hÃ nh Ä‘á»™ng ).
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i","Em chÃ o má»i ngÆ°á»i áº¡. Em hiá»‡n Ä‘ang lÃ m 1 project cuá»‘i kÃ¬ vá» nháº­n dáº¡ng hÃ nh Ä‘á»™ng dÃ¹ng thÃ´ng tin khung xÆ°Æ¡ng ( DÃ™ng openpose hoáº·c mediapipe Ä‘á»ƒ detect khung xÆ°Æ¡ng cá»§a ngÆ°á»i rá»“i nháº­n dáº¡ng), output mong muá»‘n cá»§a e lÃ  ra Ä‘Æ°á»£c 1 video mÃ  cÃ³ thá»ƒ nháº­n dáº¡ng Ä‘Æ°á»£c hÃ nh Ä‘á»™ng trong video gá»“m nhiá»u hÃ nh Ä‘á»™ng nhÆ° trong video e gá»­i. HIá»‡n táº¡i e lÃ m xong hÆ°á»›ng vá» nháº­n dáº¡ng rá»“i ( tá»©c lÃ  cÃ³ 1 chuá»—i khung xÆ°Æ¡ng gá»“m thÃ´ng tin cá»§a 1 hÃ nh Ä‘á»™ng -> train model Ä‘á»ƒ nháº­n dáº¡ng ra hÃ nh Ä‘á»™ng Ä‘Ã³) . E cÃ³ tháº¯c máº¯c mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p Ä‘Ã³ lÃ  BÃ¢y giá» mÃ¬nh Ã¡p dá»¥ng model Ä‘Ã³ vÃ o video gá»“m nhiá»u hÃ nh Ä‘á»™ng diá»…n ra thÃ¬ mÃ¬nh cÃ³ thá»ƒ Ã¡p dá»¥ng algorithm nÃ o, flow nháº­n dáº¡ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ nháº­n dáº¡ng chuá»—i nhiá»u hÃ nh Ä‘á»™ng Ä‘Ã³ khÃ´ng áº¡ ( vÃ¬ model trÆ°á»›c Ä‘Ã³ lÃ  chá»‰ dÃ¹ng vá»›i tá»«ng hÃ nh Ä‘á»™ng ). Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"[ML] Xin há»i cáº£ nhÃ  vá» blog MLCB bÃ i vá» MNIST, em cÃ³ cháº¡y `pip install python-mnist` thÃ nh cÃ´ng, nhÆ°ng sau Ä‘Ã³ `from mnist import MNIST` thÃ¬ bá»‹ bÃ¡o lá»—i lÃ  `cannot import name 'MNIST' from 'mnist'`. Em cháº¡y trÃªn ipynb thÃ¬ bÃ¡o lÃ  `ERROR: No matching distribution found for python-mnist` Xin há»i ai Ä‘Ã£ há»c pháº§n Ä‘áº¥y rá»“i mÃ  cháº¡y Ä‘Æ°á»£c thÃ¬ chá»‰ dáº«n giÃºp mÃ¬nh vá»›i.","[ML] Xin há»i cáº£ nhÃ  vá» blog MLCB bÃ i vá» MNIST, em cÃ³ cháº¡y `pip install python-mnist` thÃ nh cÃ´ng, nhÆ°ng sau Ä‘Ã³ `from mnist import MNIST` thÃ¬ bá»‹ bÃ¡o lá»—i lÃ  `cannot import name 'MNIST' from 'mnist'`. Em cháº¡y trÃªn ipynb thÃ¬ bÃ¡o lÃ  `ERROR: No matching distribution found for python-mnist` Xin há»i ai Ä‘Ã£ há»c pháº§n Ä‘áº¥y rá»“i mÃ  cháº¡y Ä‘Æ°á»£c thÃ¬ chá»‰ dáº«n giÃºp mÃ¬nh vá»›i.",,,,,
"Cho em chÃ o cÃ¡c anh cÃ¡c chá»‹ tháº§y cÃ´ áº¡, em Ä‘ang lÃ m bÃ i vÃ  cÃ³ pháº§n nghiÃªn cá»©u vá» dÃ¹ng ML dá»¯ Ä‘oÃ¡n timeseries thÃ¬ theo nhÆ° model em cÃ³ cÃ¡c Ä‘iá»ƒm mÃ  data trong model tÄƒng vá»t nhÆ° nÃ y thÃ¬ em loáº¡i bá» khá»i data Ä‘á»ƒ khi validate con sá»‘ nÃ³ sáº½ Ä‘áº¹p hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡ ?, vÃ  cho em há»i vá»›i mÃ´ hÃ¬nh nhÆ° nÃ y mÃ¬nh nÃªn cháº¡y model nÃ o Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘i Æ°u em Ä‘Ã£ cháº¡y thá»­ FBProphet, Arima, Sarima sai sá»‘ RMSE khÃ¡ lá»›n cÃ²n MAPE thÃ¬ dÆ°á»›i <7% áº¡ ! Em cÃ¡m Æ¡n nhiá»u áº¡.","Cho em chÃ o cÃ¡c anh cÃ¡c chá»‹ tháº§y cÃ´ áº¡, em Ä‘ang lÃ m bÃ i vÃ  cÃ³ pháº§n nghiÃªn cá»©u vá» dÃ¹ng ML dá»¯ Ä‘oÃ¡n timeseries thÃ¬ theo nhÆ° model em cÃ³ cÃ¡c Ä‘iá»ƒm mÃ  data trong model tÄƒng vá»t nhÆ° nÃ y thÃ¬ em loáº¡i bá» khá»i data Ä‘á»ƒ khi validate con sá»‘ nÃ³ sáº½ Ä‘áº¹p hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡ ?, vÃ  cho em há»i vá»›i mÃ´ hÃ¬nh nhÆ° nÃ y mÃ¬nh nÃªn cháº¡y model nÃ o Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘i Æ°u em Ä‘Ã£ cháº¡y thá»­ FBProphet, Arima, Sarima sai sá»‘ RMSE khÃ¡ lá»›n cÃ²n MAPE thÃ¬ dÆ°á»›i <7% áº¡ ! Em cÃ¡m Æ¡n nhiá»u áº¡.",,,,,
"Dáº¡ má»i ngÆ°á»i cho em há»i vá» Ã½ nghÄ©a má»™t sá»‘ metric trong face recognition vá»›i áº¡.
TAR@10^-6 FAR
Pháº§n identification
false negative identification rate (FNIR) vÃ  false positive identification rate (FPIR) Ä‘Ã¡nh giÃ¡ trÃªn Open-set face identification
Em cáº£m Æ¡n.",Dáº¡ má»i ngÆ°á»i cho em há»i vá» Ã½ nghÄ©a má»™t sá»‘ metric trong face recognition vá»›i áº¡. TAR@10^-6 FAR Pháº§n identification false negative identification rate (FNIR) vÃ  false positive identification rate (FPIR) Ä‘Ã¡nh giÃ¡ trÃªn Open-set face identification Em cáº£m Æ¡n.,,,,,
"EM chÃ o anh chá»‹ vÃ  tháº§y cÃ´ áº¡.
Em Ä‘ang Ä‘á»c bÃ i 26 cÃ³ chá»— Ä‘Ã¢y, chá»— sá»‘ ""2"" em tÃ´ vÃ ng Ã½ áº¡. Anh chá»‹ cÃ³ thá»ƒ cho em há»i sá»‘ 2 á»Ÿ Ä‘Ã¢y cÃ³ Ã½ nghÄ©a gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡ ;<<","EM chÃ o anh chá»‹ vÃ  tháº§y cÃ´ áº¡. Em Ä‘ang Ä‘á»c bÃ i 26 cÃ³ chá»— Ä‘Ã¢y, chá»— sá»‘ ""2"" em tÃ´ vÃ ng Ã½ áº¡. Anh chá»‹ cÃ³ thá»ƒ cho em há»i sá»‘ 2 á»Ÿ Ä‘Ã¢y cÃ³ Ã½ nghÄ©a gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡ ;<<",,,,,
"Tiá»‡p cho mÃ¬nh chia sáº» lá»›p há»c online miá»…n phÃ­ vá» oundation of Machine Learning, Data Science (dáº¡y báº±ng Tiáº¿ng Viá»‡t) cho cÃ¡c báº¡n quan tÃ¢m nhÃ© (ThÃ´ng tin Ä‘áº§y Ä‘á»§ cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c trong page mÃ  mÃ¬nh Ä‘Ã­nh kÃ¨m phÃ­a dÆ°á»›i). Thá»i gian sá»›m nháº¥t mÃ¬nh tÃ­nh tá»• chá»©c lá»›p há»c lÃ  vÃ o hÃ¨ nÄƒm sau. Náº¿u cÃ¡c báº¡n cÅ©ng muá»‘n tham gia vÃ o quÃ¡ trÃ¬nh giáº£ng dáº¡y (soáº¡n lectures, etc.) thÃ¬ chÃºng mÃ¬nh cÃ³ thá»ƒ tháº£o luáº­n thÃªm.","Tiá»‡p cho mÃ¬nh chia sáº» lá»›p há»c online miá»…n phÃ­ vá» oundation of Machine Learning, Data Science (dáº¡y báº±ng Tiáº¿ng Viá»‡t) cho cÃ¡c báº¡n quan tÃ¢m nhÃ© (ThÃ´ng tin Ä‘áº§y Ä‘á»§ cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c trong page mÃ  mÃ¬nh Ä‘Ã­nh kÃ¨m phÃ­a dÆ°á»›i). Thá»i gian sá»›m nháº¥t mÃ¬nh tÃ­nh tá»• chá»©c lá»›p há»c lÃ  vÃ o hÃ¨ nÄƒm sau. Náº¿u cÃ¡c báº¡n cÅ©ng muá»‘n tham gia vÃ o quÃ¡ trÃ¬nh giáº£ng dáº¡y (soáº¡n lectures, etc.) thÃ¬ chÃºng mÃ¬nh cÃ³ thá»ƒ tháº£o luáº­n thÃªm.",,,,,
"MÃ¬nh xin chia sáº» tiáº¿p part 2 tá»« bÃ i viáº¿t tuáº§n trÆ°á»›c. Trong bÃ i nÃ y mÃ¬nh xin gá»£i Ã½ chá»§ quan cÃ¡c váº¥n Ä‘á» sau:
1. Con Ä‘Æ°á»ng há»c Machine Learning bÃ i báº£n dá»±a vÃ o chÆ°Æ¡ng trÃ¬nh Master Data Science á»Ÿ trÆ°á»ng Aalto (Ngá»“i á»Ÿ nhÃ  tá»± há»c nhÆ°ng kiáº¿n thá»©c váº«n ngang vá»›i trÃ¬nh Ä‘á»™ Master Pháº§n Lan-EU)
2. Lá»™ trÃ¬nh há»c Data Science Ä‘á»ƒ Ã¡p dá»¥ng vÃ o Marketing, Logistics-Supply chain cho cÃ¡c báº¡n cÃ³ background kinh táº¿
3. Xu hÆ°á»›ng tuyá»ƒn dá»¥ng vÃ  ngÃ nh mÅ©i nhá»n cá»§a Pháº§n Lan (Ä‘Ãºng hÆ¡n lÃ  miá»n nam Pháº§n Lan: Helsinki, Espoo, Turku)
4. Chia sáº» nguá»“n há»c Data Science vá»›i giÃ¡ 0 Ä‘á»“ng cho táº¥t cáº£ má»i ngÆ°á»i vá»›i tiÃªu chuáº©n Pháº§n Lan (1 trong nhÆ°ng ná»n giÃ¡o dá»¥c tá»‘t nháº¥t tháº¿ giá»›i)
Ráº¥t mong Ä‘Æ°á»£c nháº­n nhiá»u sá»± Ä‘Ã³ng gÃ³p Ã½ kiáº¿n cá»§a cÃ¡c báº¡n. MÃ¬nh xin cÃ¡m Æ¡n!","MÃ¬nh xin chia sáº» tiáº¿p part 2 tá»« bÃ i viáº¿t tuáº§n trÆ°á»›c. Trong bÃ i nÃ y mÃ¬nh xin gá»£i Ã½ chá»§ quan cÃ¡c váº¥n Ä‘á» sau: 1. Con Ä‘Æ°á»ng há»c Machine Learning bÃ i báº£n dá»±a vÃ o chÆ°Æ¡ng trÃ¬nh Master Data Science á»Ÿ trÆ°á»ng Aalto (Ngá»“i á»Ÿ nhÃ  tá»± há»c nhÆ°ng kiáº¿n thá»©c váº«n ngang vá»›i trÃ¬nh Ä‘á»™ Master Pháº§n Lan-EU) 2. Lá»™ trÃ¬nh há»c Data Science Ä‘á»ƒ Ã¡p dá»¥ng vÃ o Marketing, Logistics-Supply chain cho cÃ¡c báº¡n cÃ³ background kinh táº¿ 3. Xu hÆ°á»›ng tuyá»ƒn dá»¥ng vÃ  ngÃ nh mÅ©i nhá»n cá»§a Pháº§n Lan (Ä‘Ãºng hÆ¡n lÃ  miá»n nam Pháº§n Lan: Helsinki, Espoo, Turku) 4. Chia sáº» nguá»“n há»c Data Science vá»›i giÃ¡ 0 Ä‘á»“ng cho táº¥t cáº£ má»i ngÆ°á»i vá»›i tiÃªu chuáº©n Pháº§n Lan (1 trong nhÆ°ng ná»n giÃ¡o dá»¥c tá»‘t nháº¥t tháº¿ giá»›i) Ráº¥t mong Ä‘Æ°á»£c nháº­n nhiá»u sá»± Ä‘Ã³ng gÃ³p Ã½ kiáº¿n cá»§a cÃ¡c báº¡n. MÃ¬nh xin cÃ¡m Æ¡n!",,,,,
"MÃ¬nh Ä‘ang lÃ m 1 task vá» read captcha, mÃ¬nh cÃ³ xem cÃ¡c project trÃªn git thÃ¬ cÃ¡c data train Ä‘á»u thuá»™c cÃ¹ng 1 type. nhÆ°ng cty mÃ¬nh hiá»‡n táº¡i muá»‘n gá»™p nhiá»u type láº¡i vá»›i nhau kiá»ƒu lÃ  bá» báº¥t ká»³ hÃ¬nh captcha nÃ o vÃ o cÅ©ng pháº£i nháº­n diá»‡n Ä‘Æ°á»£c chá»¯ . hiá»‡n táº¡i mÃ¬nh váº«n chÆ°a cÃ³ solution cá»¥ thá»ƒ cho trÆ°á»ng há»£p nÃ y mong má»i ngÆ°á»i cho mÃ¬nh má»™t sá»‘ idea,cÃ³ project hay paper nÃ o Ä‘Ã£ work nhÆ° váº­y thÃ¬ cÃ ng tá»‘t. MÃ¬nh xin cáº£m Æ¡n. mÃ¬nh cÃ³ kÃ¨m theo 1 sá»‘ hÃ¬nh áº£nh Ä‘á»ƒ mn xem cÃ¡c type capcha khÃ¡c nhau .","MÃ¬nh Ä‘ang lÃ m 1 task vá» read captcha, mÃ¬nh cÃ³ xem cÃ¡c project trÃªn git thÃ¬ cÃ¡c data train Ä‘á»u thuá»™c cÃ¹ng 1 type. nhÆ°ng cty mÃ¬nh hiá»‡n táº¡i muá»‘n gá»™p nhiá»u type láº¡i vá»›i nhau kiá»ƒu lÃ  bá» báº¥t ká»³ hÃ¬nh captcha nÃ o vÃ o cÅ©ng pháº£i nháº­n diá»‡n Ä‘Æ°á»£c chá»¯ . hiá»‡n táº¡i mÃ¬nh váº«n chÆ°a cÃ³ solution cá»¥ thá»ƒ cho trÆ°á»ng há»£p nÃ y mong má»i ngÆ°á»i cho mÃ¬nh má»™t sá»‘ idea,cÃ³ project hay paper nÃ o Ä‘Ã£ work nhÆ° váº­y thÃ¬ cÃ ng tá»‘t. MÃ¬nh xin cáº£m Æ¡n. mÃ¬nh cÃ³ kÃ¨m theo 1 sá»‘ hÃ¬nh áº£nh Ä‘á»ƒ mn xem cÃ¡c type capcha khÃ¡c nhau .",,,,,
"CÃ¡c báº¡n há»c sinh cÃ³ thá»ƒ Ä‘Äƒng kÃ½ nhanh [1] Ä‘á»ƒ nháº­n Ä‘c book miá»…n phÃ­ tá»« tÃ¡c giáº£ nhÃ©.
[1] https://docs.google.com/forms/d/10T3Ty9klzsQTPqEy76WhCps0yeAyv3ZmH0VynjmsMVo/viewform?edit_requested=true",CÃ¡c báº¡n há»c sinh cÃ³ thá»ƒ Ä‘Äƒng kÃ½ nhanh [1] Ä‘á»ƒ nháº­n Ä‘c book miá»…n phÃ­ tá»« tÃ¡c giáº£ nhÃ©. [1] https://docs.google.com/forms/d/10T3Ty9klzsQTPqEy76WhCps0yeAyv3ZmH0VynjmsMVo/viewform?edit_requested=true,,,,,
"[Income classification solution sharing]
Income classification lÃ  má»™t cuá»™c thi liÃªn quan tá»›i phÃ¢n loáº¡i trÃªn dá»¯ liá»‡u dáº¡ng báº£ng. Má»¥c tiÃªu Ä‘Ã³ lÃ  dá»±a vÃ o thÃ´ng tin liÃªn quan tá»›i cÃ´ng dÃ¢n, báº¡n hÃ£y giÃºp chÃ­nh phá»§ dá»± Ä‘oÃ¡n xem thu nháº­p cá»§a cÃ´ng dÃ¢n Ä‘Ã³ cÃ³ vÆ°á»£t quÃ¡ 50k USD hay khÃ´ng. á» sá»± kiá»‡n Data Quest sáº¯p tá»›i Ä‘Ã¢y chÃºng ta hÃ£y cÃ¹ng nhau theo dÃµi nhá»¯ng chia sáº» tá»« cÃ¡c báº¡n thÃ­ sinh Ä‘Ã£ Ä‘áº¡t giáº£i vá» cÃ¡c kÄ© thuáº­t há»¯u Ã­ch Ä‘Ã£ Ä‘Æ°á»£c cÃ¡c báº¡n Ã¡p dá»¥ng nhÆ° tháº¿ nÃ o.
----------------------------------------
Income classification is a competition relating to a classification task on the tabular dataset. The target is to use the citizen information, you help the government make a prediction whether a citizen has an annual income is greater than 50k USD? In the next Data Quest meeting, you have a chance to catch up on delicate solution sharing from the winners via bellow meeting:
Meeting room: Income Classification Solution Sharing
Friday, December 17 Â· 7:30 â€“ 8:30pm
Google Meet joining info
Video call link: https://meet.google.com/oyv-qmdk-ftp","[Income classification solution sharing] Income classification lÃ  má»™t cuá»™c thi liÃªn quan tá»›i phÃ¢n loáº¡i trÃªn dá»¯ liá»‡u dáº¡ng báº£ng. Má»¥c tiÃªu Ä‘Ã³ lÃ  dá»±a vÃ o thÃ´ng tin liÃªn quan tá»›i cÃ´ng dÃ¢n, báº¡n hÃ£y giÃºp chÃ­nh phá»§ dá»± Ä‘oÃ¡n xem thu nháº­p cá»§a cÃ´ng dÃ¢n Ä‘Ã³ cÃ³ vÆ°á»£t quÃ¡ 50k USD hay khÃ´ng. á» sá»± kiá»‡n Data Quest sáº¯p tá»›i Ä‘Ã¢y chÃºng ta hÃ£y cÃ¹ng nhau theo dÃµi nhá»¯ng chia sáº» tá»« cÃ¡c báº¡n thÃ­ sinh Ä‘Ã£ Ä‘áº¡t giáº£i vá» cÃ¡c kÄ© thuáº­t há»¯u Ã­ch Ä‘Ã£ Ä‘Æ°á»£c cÃ¡c báº¡n Ã¡p dá»¥ng nhÆ° tháº¿ nÃ o. ---------------------------------------- Income classification is a competition relating to a classification task on the tabular dataset. The target is to use the citizen information, you help the government make a prediction whether a citizen has an annual income is greater than 50k USD? In the next Data Quest meeting, you have a chance to catch up on delicate solution sharing from the winners via bellow meeting: Meeting room: Income Classification Solution Sharing Friday, December 17 Â· 7:30 â€“ 8:30pm Google Meet joining info Video call link: https://meet.google.com/oyv-qmdk-ftp",,,,,
"ChÃ o anh/chá»‹/cÃ¡c báº¡n
Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t Ä‘á»“ Ã¡n vá» nháº­n diá»‡n biá»ƒn sá»‘ xe mÃ¡y Viá»‡t Nam (biá»ƒn sá»‘ 2 dÃ²ng) do em tÃ¬m hiá»ƒu vá» Machine Learning má»›i Ä‘Ã¢y thÃ´i nÃªn cÃ³ má»™t chÃºt khÃ³ khÄƒn nÃªn ráº¥t cáº§n cÃ¡c anh/chá»‹/cÃ¡c báº¡n giÃºp Ä‘á»¡.
Theo nhá»¯ng gÃ¬ em tÃ¬m hiá»ƒu vá» nhá»¯ng viá»‡c cáº§n lÃ m lÃ  preprocess áº£nh trÆ°á»›c (chuyá»ƒn áº£nh xÃ¡m, nhá»‹ phÃ¢n hÃ³a áº£nh thÃ nh áº£nh tráº¯ng Ä‘en) sau Ä‘Ã³ sáº½ lá»c táº¥t cáº£ cÃ¡c contours trong áº£nh vÃ  nháº­n diá»‡n biá»ƒn sá»‘ báº±ng contours cÃ³ 4 cáº¡nh vÃ  cÃ³ diá»‡n tÃ­ch lá»›n nháº¥t trong áº£nh. NhÆ°ng khi xÃ¡c Ä‘á»‹nh contours thÃ¬ em cÃ³ má»™t chÃºt khÃ³ khÄƒn do cÃ³ má»™t vÃ i biá»ƒn sá»‘ xe viá»n bÃªn ngoÃ i ngÆ°á»i ta sáº½ viá»n má»™t lá»›p kim loáº¡i (hÃ¬nh 1a) hoáº·c cÃ³ viá»n Ä‘en nhÆ°ng bá»‹ Ã¡nh sÃ¡ng chiáº¿u vÃ o lÃ m Ä‘Æ°á»ng viá»n bá»‹ chÃ¡ (hÃ¬nh 2a) khiáº¿n cho Ä‘Æ°á»ng viá»n khÃ´ng rÃµ nÃ©t hoáº·c khÃ´ng nháº­n tháº¥y Ä‘Æ°á»ng viá»n lÃ m cho quÃ¡ trÃ¬nh lá»c contours gáº·p chÃºt khÃ³ khÄƒn, cÃ¡c contours sáº½ bá»‹ Ä‘á»©t khÃºc nÃªn khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c contours báº±ng phÆ°Æ¡ng phÃ¡p nháº­n diá»‡n contours 4 cáº¡nh cÃ³ diá»‡n tÃ­ch lá»›n nháº¥t (hÃ¬nh contours bá»‹ Ä‘á»©t khÃºc: hÃ¬nh 1b, 2b).CÃ²n cÃ¡c hÃ¬nh cÃ³ Ä‘Æ°á»ng viá»n Ä‘en rÃµ vÃ  khÃ´ng bá»‹ Ã¡nh sÃ¡ng pháº£n chiáº¿u nhÆ° váº§y thÃ¬ em Ä‘Ã£ nháº­n diá»‡n Ä‘Æ°á»£c (hÃ¬nh 3).
Anh/chá»‹/cÃ¡c báº¡n cho em há»i lÃ  cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c trÆ°á»ng há»£p nÃ y(lÃ m cho contour Ä‘Æ°á»ng viá»n biá»ƒn sá»‘ nÃ³ liá»n máº¡ch) khÃ´ng áº¡?
Em xin cáº£m Æ¡n!","ChÃ o anh/chá»‹/cÃ¡c báº¡n Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t Ä‘á»“ Ã¡n vá» nháº­n diá»‡n biá»ƒn sá»‘ xe mÃ¡y Viá»‡t Nam (biá»ƒn sá»‘ 2 dÃ²ng) do em tÃ¬m hiá»ƒu vá» Machine Learning má»›i Ä‘Ã¢y thÃ´i nÃªn cÃ³ má»™t chÃºt khÃ³ khÄƒn nÃªn ráº¥t cáº§n cÃ¡c anh/chá»‹/cÃ¡c báº¡n giÃºp Ä‘á»¡. Theo nhá»¯ng gÃ¬ em tÃ¬m hiá»ƒu vá» nhá»¯ng viá»‡c cáº§n lÃ m lÃ  preprocess áº£nh trÆ°á»›c (chuyá»ƒn áº£nh xÃ¡m, nhá»‹ phÃ¢n hÃ³a áº£nh thÃ nh áº£nh tráº¯ng Ä‘en) sau Ä‘Ã³ sáº½ lá»c táº¥t cáº£ cÃ¡c contours trong áº£nh vÃ  nháº­n diá»‡n biá»ƒn sá»‘ báº±ng contours cÃ³ 4 cáº¡nh vÃ  cÃ³ diá»‡n tÃ­ch lá»›n nháº¥t trong áº£nh. NhÆ°ng khi xÃ¡c Ä‘á»‹nh contours thÃ¬ em cÃ³ má»™t chÃºt khÃ³ khÄƒn do cÃ³ má»™t vÃ i biá»ƒn sá»‘ xe viá»n bÃªn ngoÃ i ngÆ°á»i ta sáº½ viá»n má»™t lá»›p kim loáº¡i (hÃ¬nh 1a) hoáº·c cÃ³ viá»n Ä‘en nhÆ°ng bá»‹ Ã¡nh sÃ¡ng chiáº¿u vÃ o lÃ m Ä‘Æ°á»ng viá»n bá»‹ chÃ¡ (hÃ¬nh 2a) khiáº¿n cho Ä‘Æ°á»ng viá»n khÃ´ng rÃµ nÃ©t hoáº·c khÃ´ng nháº­n tháº¥y Ä‘Æ°á»ng viá»n lÃ m cho quÃ¡ trÃ¬nh lá»c contours gáº·p chÃºt khÃ³ khÄƒn, cÃ¡c contours sáº½ bá»‹ Ä‘á»©t khÃºc nÃªn khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c contours báº±ng phÆ°Æ¡ng phÃ¡p nháº­n diá»‡n contours 4 cáº¡nh cÃ³ diá»‡n tÃ­ch lá»›n nháº¥t (hÃ¬nh contours bá»‹ Ä‘á»©t khÃºc: hÃ¬nh 1b, 2b).CÃ²n cÃ¡c hÃ¬nh cÃ³ Ä‘Æ°á»ng viá»n Ä‘en rÃµ vÃ  khÃ´ng bá»‹ Ã¡nh sÃ¡ng pháº£n chiáº¿u nhÆ° váº§y thÃ¬ em Ä‘Ã£ nháº­n diá»‡n Ä‘Æ°á»£c (hÃ¬nh 3). Anh/chá»‹/cÃ¡c báº¡n cho em há»i lÃ  cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c trÆ°á»ng há»£p nÃ y(lÃ m cho contour Ä‘Æ°á»ng viá»n biá»ƒn sá»‘ nÃ³ liá»n máº¡ch) khÃ´ng áº¡? Em xin cáº£m Æ¡n!",,,,,
"ChÃ o má»i ngÆ°á»i. Hiá»‡n mÃ¬nh Ä‘ang gáº·p má»™t bÃ i toÃ¡n nhÆ° nÃ y. Mong chá»‰ dáº«n hoáº·c gá»£i Ã½ hÆ°á»›ng Ä‘i ,giáº£i phÃ¡p tá»« má»i ngÆ°á»i. MÃ¬nh cáº£m Æ¡n trÆ°á»›c.
BÃ i toÃ¡n cÃ³ input lÃ  tÃªn sáº£n pháº©m trÃªn trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­(tiáº¿ng Anh). Output lÃ  cÃ¡c tags cá»§a sáº£n pháº©m Ä‘Ã³. VÃ­ dá»¥ nhÆ° brand, category, cho nam hay ná»¯, â€¦
Data hiá»‡n mÃ¬nh Ä‘ang cÃ³ khoáº£ng hÆ¡n 10k rows mÃ¬nh tá»± gÃ¡n nhÃ£n.","ChÃ o má»i ngÆ°á»i. Hiá»‡n mÃ¬nh Ä‘ang gáº·p má»™t bÃ i toÃ¡n nhÆ° nÃ y. Mong chá»‰ dáº«n hoáº·c gá»£i Ã½ hÆ°á»›ng Ä‘i ,giáº£i phÃ¡p tá»« má»i ngÆ°á»i. MÃ¬nh cáº£m Æ¡n trÆ°á»›c. BÃ i toÃ¡n cÃ³ input lÃ  tÃªn sáº£n pháº©m trÃªn trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­(tiáº¿ng Anh). Output lÃ  cÃ¡c tags cá»§a sáº£n pháº©m Ä‘Ã³. VÃ­ dá»¥ nhÆ° brand, category, cho nam hay ná»¯, â€¦ Data hiá»‡n mÃ¬nh Ä‘ang cÃ³ khoáº£ng hÆ¡n 10k rows mÃ¬nh tá»± gÃ¡n nhÃ£n.",,,,,
"Dáº¡ thÆ°a anh chá»‹ áº¡, em hÆ¡i khÃ´ng hiá»ƒu chá»— Ä‘oáº¡n bÃ´i vÃ ng Ã½ áº¡.
Viá»‡c biá»ƒu diá»…n ma tráº­n A dÆ°á»›i dáº¡ng Ä‘Ã³ em tháº¥y láº¡ quÃ¡ ğŸ˜¢
Vá»›i cáº£ tá»« ""phá»¥ thuá»™c"" mang hÃ m Ã½ gÃ¬ váº­y áº¡
Em xin cáº£m Æ¡n.","Dáº¡ thÆ°a anh chá»‹ áº¡, em hÆ¡i khÃ´ng hiá»ƒu chá»— Ä‘oáº¡n bÃ´i vÃ ng Ã½ áº¡. Viá»‡c biá»ƒu diá»…n ma tráº­n A dÆ°á»›i dáº¡ng Ä‘Ã³ em tháº¥y láº¡ quÃ¡ Vá»›i cáº£ tá»« ""phá»¥ thuá»™c"" mang hÃ m Ã½ gÃ¬ váº­y áº¡ Em xin cáº£m Æ¡n.",,,,,
Em chÃ o ac trong nhÃ³m. Hiá»‡n em xin ac trong nhÃ³m tÆ° váº¥n giÃºp em cÃ¡c keyword liÃªn quan Ä‘áº¿n IOT vÃ  ML. Hoáº·c xin vÃ i lá»i khuyÃªn cá»§a ac áº¡.,Em chÃ o ac trong nhÃ³m. Hiá»‡n em xin ac trong nhÃ³m tÆ° váº¥n giÃºp em cÃ¡c keyword liÃªn quan Ä‘áº¿n IOT vÃ  ML. Hoáº·c xin vÃ i lá»i khuyÃªn cá»§a ac áº¡.,,,,,
"ChÃ o má»i ngÆ°á»i, vá»«a qua team SDSV_AICR cá»§a mÃ¬nh Ä‘Ã£ Ä‘áº¡t top 1 chung cuá»™c cuá»™c thi MC-OCR táº¡i há»™i tháº£o RIVF 2021. MÃ¬nh cÃ³ chia sáº» láº¡i toÃ n bá»™ quÃ¡ trÃ¬nh giáº£i quyáº¿t 2 tasks (1) Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng hÃ³a Ä‘Æ¡n vÃ  (2) trÃ­ch xuáº¥t thÃ´ng tin hÃ³a Ä‘Æ¡n trÃªn github https://github.com/ndcuong91/MC_OCR . Má»i ngÆ°á»i tham kháº£o vÃ  gÃ³p Ã½ nhÃ© :D","ChÃ o má»i ngÆ°á»i, vá»«a qua team SDSV_AICR cá»§a mÃ¬nh Ä‘Ã£ Ä‘áº¡t top 1 chung cuá»™c cuá»™c thi MC-OCR táº¡i há»™i tháº£o RIVF 2021. MÃ¬nh cÃ³ chia sáº» láº¡i toÃ n bá»™ quÃ¡ trÃ¬nh giáº£i quyáº¿t 2 tasks (1) Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng hÃ³a Ä‘Æ¡n vÃ  (2) trÃ­ch xuáº¥t thÃ´ng tin hÃ³a Ä‘Æ¡n trÃªn github https://github.com/ndcuong91/MC_OCR . Má»i ngÆ°á»i tham kháº£o vÃ  gÃ³p Ã½ nhÃ© :D",,,,,
"Gáº§n Ä‘Ã¢y, phÆ°Æ¡ng phÃ¡p score matching cÃ³ má»™t bÆ°á»›c Ä‘á»™t phÃ¡ khi sá»­ dá»¥ng Ã½ tÆ°á»Ÿng tÃ¬nh cá» giá»‘ng vá»›i mÃ´ hÃ¬nh diffusion, Ä‘Æ°a ra káº¿t quáº£ kháº£ quan cho mÃ´ hÃ¬nh sinh. TÆ°Æ¡ng tá»± nhÆ° váº­y, mÃ´ hÃ¬nh diffusion cÅ©ng Ä‘Æ°a ra káº¿t quáº£ xáº¥p xá»‰ cÃ¡c mÃ´ hÃ¬nh kiá»ƒu GAN khi sá»­ dá»¥ng Ã½ tÆ°á»Ÿng cá»§a denoise score matching. Hai mÃ´ hÃ¬nh nÃ y sau Ä‘Ã³ Ä‘Ã£ Ä‘Æ°á»£c tá»•ng quÃ¡t hÃ³a tá»« gÃ³c nhÃ¬n phÆ°Æ¡ng trÃ¬nh vi phÃ¢n ngáº«u nhiÃªn, trá»Ÿ thÃ nh SOTA cho sinh dá»¯ liá»‡u áº£nh. MÃ¬nh cÃ³ ghi chÃ©p láº¡i má»™t chÃºt vá» cÃ¡c mÃ´ hÃ¬nh trÃªn, mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» hÆ°á»›ng Ä‘i má»›i nÃ y.","Gáº§n Ä‘Ã¢y, phÆ°Æ¡ng phÃ¡p score matching cÃ³ má»™t bÆ°á»›c Ä‘á»™t phÃ¡ khi sá»­ dá»¥ng Ã½ tÆ°á»Ÿng tÃ¬nh cá» giá»‘ng vá»›i mÃ´ hÃ¬nh diffusion, Ä‘Æ°a ra káº¿t quáº£ kháº£ quan cho mÃ´ hÃ¬nh sinh. TÆ°Æ¡ng tá»± nhÆ° váº­y, mÃ´ hÃ¬nh diffusion cÅ©ng Ä‘Æ°a ra káº¿t quáº£ xáº¥p xá»‰ cÃ¡c mÃ´ hÃ¬nh kiá»ƒu GAN khi sá»­ dá»¥ng Ã½ tÆ°á»Ÿng cá»§a denoise score matching. Hai mÃ´ hÃ¬nh nÃ y sau Ä‘Ã³ Ä‘Ã£ Ä‘Æ°á»£c tá»•ng quÃ¡t hÃ³a tá»« gÃ³c nhÃ¬n phÆ°Æ¡ng trÃ¬nh vi phÃ¢n ngáº«u nhiÃªn, trá»Ÿ thÃ nh SOTA cho sinh dá»¯ liá»‡u áº£nh. MÃ¬nh cÃ³ ghi chÃ©p láº¡i má»™t chÃºt vá» cÃ¡c mÃ´ hÃ¬nh trÃªn, mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» hÆ°á»›ng Ä‘i má»›i nÃ y.",,,,,
"[ğ—¢ğ—£ğ—˜ğ—¡ ğ—¦ğ—¢ğ—¨ğ—¥ğ—–ğ—˜ ğ——ğ—”ğ—§ğ—”] DANeS - Bá»˜ Dá»® LIá»†U Má» Gá»’M 500,000 BÃ€I BÃO ÄIá»†N Tá»¬ TIáº¾NG VIá»†T
DANeS lÃ  má»™t bá»™ dá»¯ liá»‡u má»Ÿ vá» vÄƒn báº£n, gá»“m ~ 500.000 bÃ i bÃ¡o Ä‘iá»‡n tá»­ tiáº¿ng Viá»‡t. CÃ¡c bÃ i bÃ¡o sáº½ bao gá»“m tiÃªu Ä‘á», URL, mÃ´ táº£ tá»•ng quan tá»«ng bÃ i bÃ¡o vÃ  Ä‘Æ°á»£c dÃ¡n nhÃ£n tÃ­ch cá»±c/tiÃªu cá»±c/trung tÃ­nh dá»±a trÃªn ná»™i dung tiÃªu Ä‘á».
ğ—§ğ—¿ğ—®Ì£ğ—»ğ—´ ğ˜ğ—µğ—®Ìğ—¶: DANeS hiá»‡n váº«n Ä‘ang trong quÃ¡ trÃ¬nh dÃ¡n nhÃ£n vÃ  ráº¥t cáº§n sá»± tham gia máº¡nh máº½ tá»« cá»™ng Ä‘á»“ng. Link Github sáº½ lÃ  nÆ¡i cáº­p nháº­t dá»¯ liá»‡u thÃ´ vÃ  Ä‘Ã£ Ä‘Æ°á»£c dÃ¡n nhÃ£n tá»« https://tool.dataset.vn/projects/752/details. Táº§n suáº¥t cáº­p nháº­t dá»± kiáº¿n sáº½ lÃ  1 thÃ¡ng/láº§n.
ğ—•ğ—®Ì‰ğ—» ğ—¾ğ˜‚ğ˜†ğ—²Ì‚Ì€ğ—»: Dá»¯ liá»‡u lÃ  tÃªn cÃ¡c bÃ i bÃ¡o thuá»™c vá» tÃ¡c giáº£ Ä‘Ã£ Ä‘áº·t cho bÃ i bÃ¡o cá»§a mÃ¬nh. CÃ¡c dá»¯ liá»‡u phÃ¡i sinh tá»« pháº§n má»m https://tool.dataset.vn Ä‘Æ°á»£c cáº¥p phÃ©p bá»Ÿi giáº¥y CC-BY. Pháº§n mÃ£ nguá»“n má»Ÿ cho mÃ´ hÃ¬nh há»c mÃ¡y thuá»™c báº£n quyá»n MIT.
-------------------
â€» ToÃ n bá»™ dá»¯ liá»‡u thÃ´ sáº½ Ä‘Æ°á»£c cÃ´ng khai táº¡i Ä‘á»‹a chá»‰ sau:
https://github.com/dataset-vn/DANeS
â€» Äá»ƒ nháº­n dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c dÃ¡n nhÃ£n má»›i nháº¥t, báº¡n vui lÃ²ng thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
BÆ°á»›c 1: Truy cáº­p bá»™ dá»¯ liá»‡u qua Ä‘Æ°á»ng link dÆ°á»›i Ä‘Ã¢y:
ğŸ“¥ Link: https://tool.dataset.vn/projects/752/details
BÆ°á»›c 2: áº¤n â€œTham giaâ€ dá»± Ã¡n vÃ  Ä‘á»£i quáº£n trá»‹ viÃªn duyá»‡t yÃªu cáº§u cá»§a báº¡n.
BÆ°á»›c 3: Táº£i vÃ  sá»­ dá»¥ng má»™t pháº§n kho dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c dÃ¡n nhÃ£n bá»Ÿi DATASET.
-------------------
ğŸ“Œ Vá» ğ——ğ—”ğ—§ğ—”ğ—¦ğ—˜ğ—§ .ğ—ğ—¦ğ—–: https://www.facebook.com/dataset.vn
Sá»© má»‡nh cá»§a DATASET lÃ  trá»Ÿ thÃ nh ná»n táº£ng dá»¯ liá»‡u ""nguá»“n lá»±c cá»™ng Ä‘á»“ng"" tiÃªn phong táº¡i Viá»‡t Nam, há»— trá»£ cÃ¡c cÃ¡ nhÃ¢n, tá»• chá»©c trong viá»‡c á»©ng dá»¥ng khoa há»c dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n cá»§a xÃ£ há»™i. Vá»›i ná»n táº£ng pháº§n má»m máº¡nh máº½ vÃ  cá»™ng Ä‘á»“ng xá»­ lÃ½ dá»¯ liá»‡u Ä‘Ã´ng Ä‘áº£o, DATASET mong muá»‘n Ä‘Æ°a Ä‘áº¿n cho Ä‘á»‘i tÃ¡c má»™t giáº£i phÃ¡p toÃ n diá»‡n vÃ  cháº¥t lÆ°á»£ng, phÃ¹ há»£p vá»›i Ä‘áº·c thÃ¹ cá»§a thá»‹ trÆ°á»ng cÃ´ng nghá»‡ Viá»‡t Nam vÃ  tháº¿ giá»›i.
ğŸ“Œ Vá» ğ—”ğ—œğ—© ğ—šğ—¿ğ—¼ğ˜‚ğ—½: https://www.facebook.com/aivgroup.jsc/
AIV Group hÆ°á»›ng Ä‘áº¿n viá»‡c á»©ng dá»¥ng nhá»¯ng tiáº¿n bá»™ vá» cÃ´ng nghá»‡, Ä‘áº·c biá»‡t lÃ  TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI), Äiá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y (Cloud Computing), Dá»¯ liá»‡u lá»›n (Big Data) Ä‘á»ƒ sá»‘ hoÃ¡, hiá»‡n Ä‘áº¡i hoÃ¡ cÃ¡c quy trÃ¬nh sáº£n xuáº¥t vÃ  tiÃªu thá»¥ thÃ´ng tin Ä‘Ã£ tá»“n táº¡i lÃ¢u Ä‘á»i trong xÃ£ há»™i Viá»‡t Nam, Ä‘á»“ng thá»i gÃ³p pháº§n giáº£i quyáº¿t nhá»¯ng váº¥n Ä‘á» má»›i phÃ¡t sinh trong lÄ©nh vá»±c truyá»n thÃ´ng do máº·t trÃ¡i cá»§a cÃ´ng nghá»‡ nhÆ°: váº¥n náº¡n tin giáº£, hÃ¬nh áº£nh, video Ä‘Æ°á»£c cáº¯t ghÃ©p tá»± Ä‘á»™ngâ€¦
Nguá»“n: Dataset.vn - Data Crowdsourcing Platform
_______
THÃ”NG TIN LIÃŠN Há»†:
DATASET .JSC
Táº§ng 3, Golden Land Building, Sá»‘ 275 Nguyá»…n TrÃ£i, Thanh XuÃ¢n, HÃ  Ná»™i
ğŸ“ SÄT: 0984420826
ğŸ“ Facebook: https://www.facebook.com/dataset.vn
ğŸ“ Email: info@dataset.vn
ğŸ“ Website: dataset.vn","[ ] DANeS - Bá»˜ Dá»® LIá»†U Má» Gá»’M 500,000 BÃ€I BÃO ÄIá»†N Tá»¬ TIáº¾NG VIá»†T DANeS lÃ  má»™t bá»™ dá»¯ liá»‡u má»Ÿ vá» vÄƒn báº£n, gá»“m ~ 500.000 bÃ i bÃ¡o Ä‘iá»‡n tá»­ tiáº¿ng Viá»‡t. CÃ¡c bÃ i bÃ¡o sáº½ bao gá»“m tiÃªu Ä‘á», URL, mÃ´ táº£ tá»•ng quan tá»«ng bÃ i bÃ¡o vÃ  Ä‘Æ°á»£c dÃ¡n nhÃ£n tÃ­ch cá»±c/tiÃªu cá»±c/trung tÃ­nh dá»±a trÃªn ná»™i dung tiÃªu Ä‘á». Ì£ Ì: DANeS hiá»‡n váº«n Ä‘ang trong quÃ¡ trÃ¬nh dÃ¡n nhÃ£n vÃ  ráº¥t cáº§n sá»± tham gia máº¡nh máº½ tá»« cá»™ng Ä‘á»“ng. Link Github sáº½ lÃ  nÆ¡i cáº­p nháº­t dá»¯ liá»‡u thÃ´ vÃ  Ä‘Ã£ Ä‘Æ°á»£c dÃ¡n nhÃ£n tá»« https://tool.dataset.vn/projects/752/details. Táº§n suáº¥t cáº­p nháº­t dá»± kiáº¿n sáº½ lÃ  1 thÃ¡ng/láº§n. Ì‰ Ì‚Ì€: Dá»¯ liá»‡u lÃ  tÃªn cÃ¡c bÃ i bÃ¡o thuá»™c vá» tÃ¡c giáº£ Ä‘Ã£ Ä‘áº·t cho bÃ i bÃ¡o cá»§a mÃ¬nh. CÃ¡c dá»¯ liá»‡u phÃ¡i sinh tá»« pháº§n má»m https://tool.dataset.vn Ä‘Æ°á»£c cáº¥p phÃ©p bá»Ÿi giáº¥y CC-BY. Pháº§n mÃ£ nguá»“n má»Ÿ cho mÃ´ hÃ¬nh há»c mÃ¡y thuá»™c báº£n quyá»n MIT. ------------------- â€» ToÃ n bá»™ dá»¯ liá»‡u thÃ´ sáº½ Ä‘Æ°á»£c cÃ´ng khai táº¡i Ä‘á»‹a chá»‰ sau: https://github.com/dataset-vn/DANeS â€» Äá»ƒ nháº­n dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c dÃ¡n nhÃ£n má»›i nháº¥t, báº¡n vui lÃ²ng thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau: BÆ°á»›c 1: Truy cáº­p bá»™ dá»¯ liá»‡u qua Ä‘Æ°á»ng link dÆ°á»›i Ä‘Ã¢y: Link: https://tool.dataset.vn/projects/752/details BÆ°á»›c 2: áº¤n â€œTham giaâ€ dá»± Ã¡n vÃ  Ä‘á»£i quáº£n trá»‹ viÃªn duyá»‡t yÃªu cáº§u cá»§a báº¡n. BÆ°á»›c 3: Táº£i vÃ  sá»­ dá»¥ng má»™t pháº§n kho dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c dÃ¡n nhÃ£n bá»Ÿi DATASET. ------------------- Vá» .: https://www.facebook.com/dataset.vn Sá»© má»‡nh cá»§a DATASET lÃ  trá»Ÿ thÃ nh ná»n táº£ng dá»¯ liá»‡u ""nguá»“n lá»±c cá»™ng Ä‘á»“ng"" tiÃªn phong táº¡i Viá»‡t Nam, há»— trá»£ cÃ¡c cÃ¡ nhÃ¢n, tá»• chá»©c trong viá»‡c á»©ng dá»¥ng khoa há»c dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n cá»§a xÃ£ há»™i. Vá»›i ná»n táº£ng pháº§n má»m máº¡nh máº½ vÃ  cá»™ng Ä‘á»“ng xá»­ lÃ½ dá»¯ liá»‡u Ä‘Ã´ng Ä‘áº£o, DATASET mong muá»‘n Ä‘Æ°a Ä‘áº¿n cho Ä‘á»‘i tÃ¡c má»™t giáº£i phÃ¡p toÃ n diá»‡n vÃ  cháº¥t lÆ°á»£ng, phÃ¹ há»£p vá»›i Ä‘áº·c thÃ¹ cá»§a thá»‹ trÆ°á»ng cÃ´ng nghá»‡ Viá»‡t Nam vÃ  tháº¿ giá»›i. Vá» : https://www.facebook.com/aivgroup.jsc/ AIV Group hÆ°á»›ng Ä‘áº¿n viá»‡c á»©ng dá»¥ng nhá»¯ng tiáº¿n bá»™ vá» cÃ´ng nghá»‡, Ä‘áº·c biá»‡t lÃ  TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI), Äiá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y (Cloud Computing), Dá»¯ liá»‡u lá»›n (Big Data) Ä‘á»ƒ sá»‘ hoÃ¡, hiá»‡n Ä‘áº¡i hoÃ¡ cÃ¡c quy trÃ¬nh sáº£n xuáº¥t vÃ  tiÃªu thá»¥ thÃ´ng tin Ä‘Ã£ tá»“n táº¡i lÃ¢u Ä‘á»i trong xÃ£ há»™i Viá»‡t Nam, Ä‘á»“ng thá»i gÃ³p pháº§n giáº£i quyáº¿t nhá»¯ng váº¥n Ä‘á» má»›i phÃ¡t sinh trong lÄ©nh vá»±c truyá»n thÃ´ng do máº·t trÃ¡i cá»§a cÃ´ng nghá»‡ nhÆ°: váº¥n náº¡n tin giáº£, hÃ¬nh áº£nh, video Ä‘Æ°á»£c cáº¯t ghÃ©p tá»± Ä‘á»™ngâ€¦ Nguá»“n: Dataset.vn - Data Crowdsourcing Platform _______ THÃ”NG TIN LIÃŠN Há»†: DATASET .JSC Táº§ng 3, Golden Land Building, Sá»‘ 275 Nguyá»…n TrÃ£i, Thanh XuÃ¢n, HÃ  Ná»™i SÄT: 0984420826 Facebook: https://www.facebook.com/dataset.vn Email: info@dataset.vn Website: dataset.vn",,,,,
"[PCA - Principle Component Analysis]
CÃ¡c model Machine Learning Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u lá»›n thÆ°á»ng khÃ¡ tá»‘n kÃ©m vá» chi phÃ­ phÃ­ huáº¥n luyá»‡n vÃ  Ä‘Ã´i khi hay xáº£y ra hiá»‡n tÆ°á»£ng overfitting do quÃ¡ nhiá»u biáº¿n Ä‘áº§u vÃ o. PCA lÃ  thuáº­t toÃ¡n cho phÃ©p giáº£m chiá»u dá»¯ liá»‡u tá»« khÃ´ng gian cao chiá»u xuá»‘ng khÃ´ng gian tháº¥p chiá»u mÃ  váº«n giá»¯ Ä‘Æ°á»£c nhá»¯ng Ä‘áº·c tÃ­nh tá»‘t cá»§a dá»¯ liá»‡u gá»‘c thÃ´ng qua phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch suy biáº¿n. PhÆ°Æ¡ng phÃ¡p PCA lÃ  mÃ´t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p cÃ³ tÃ­nh á»©ng dá»¥ng cao trong Machine Learning nhÆ° giáº£m chiá»u dá»¯ liá»‡u, nÃ©n áº£nh, visualize phÃ¢n bá»‘ cá»§a dá»¯ liá»‡u trong khÃ´ng gian 2D, 3D.
CÃ¹ng tÃ¬m hiá»ƒu vá» phÆ°Æ¡ng phÃ¡p PCA trong chÆ°Æ¡ng tiáº¿p theo cá»§a Machine Learning Algorithm to Practice.
-----------------------------------------------------------------------------
Machine Learning models trained on big data are often quite expensive in terms of training costs, and sometimes overfitting can occur due to too many input variables. PCA is an algorithm that allows to reduce the data dimensionality from high-dimensional space to low-dimensional space while preserving the good components of the original data through Singular Decomposition Analysis method. The PCA method is one of the highly applicable methods in Machine Learning such as data dimensionality reduction, image compression, and visualization of the distribution of data in 2D and 3D space. Let learn about PCA theory in the next chapter of Machine Learning Algorithms to Practices book.
https://phamdinhkhanh.github.io/deep.../ch_ml/index_PCA.html","[PCA - Principle Component Analysis] CÃ¡c model Machine Learning Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u lá»›n thÆ°á»ng khÃ¡ tá»‘n kÃ©m vá» chi phÃ­ phÃ­ huáº¥n luyá»‡n vÃ  Ä‘Ã´i khi hay xáº£y ra hiá»‡n tÆ°á»£ng overfitting do quÃ¡ nhiá»u biáº¿n Ä‘áº§u vÃ o. PCA lÃ  thuáº­t toÃ¡n cho phÃ©p giáº£m chiá»u dá»¯ liá»‡u tá»« khÃ´ng gian cao chiá»u xuá»‘ng khÃ´ng gian tháº¥p chiá»u mÃ  váº«n giá»¯ Ä‘Æ°á»£c nhá»¯ng Ä‘áº·c tÃ­nh tá»‘t cá»§a dá»¯ liá»‡u gá»‘c thÃ´ng qua phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch suy biáº¿n. PhÆ°Æ¡ng phÃ¡p PCA lÃ  mÃ´t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p cÃ³ tÃ­nh á»©ng dá»¥ng cao trong Machine Learning nhÆ° giáº£m chiá»u dá»¯ liá»‡u, nÃ©n áº£nh, visualize phÃ¢n bá»‘ cá»§a dá»¯ liá»‡u trong khÃ´ng gian 2D, 3D. CÃ¹ng tÃ¬m hiá»ƒu vá» phÆ°Æ¡ng phÃ¡p PCA trong chÆ°Æ¡ng tiáº¿p theo cá»§a Machine Learning Algorithm to Practice. ----------------------------------------------------------------------------- Machine Learning models trained on big data are often quite expensive in terms of training costs, and sometimes overfitting can occur due to too many input variables. PCA is an algorithm that allows to reduce the data dimensionality from high-dimensional space to low-dimensional space while preserving the good components of the original data through Singular Decomposition Analysis method. The PCA method is one of the highly applicable methods in Machine Learning such as data dimensionality reduction, image compression, and visualization of the distribution of data in 2D and 3D space. Let learn about PCA theory in the next chapter of Machine Learning Algorithms to Practices book. https://phamdinhkhanh.github.io/deep.../ch_ml/index_PCA.html",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang phÃ¡t triá»ƒn á»©ng dá»¥ng xá»­ lÃ½ áº£nh trÃªn C# vÃ  Ä‘ang gáº·p bÃ i toÃ¡n OCR cho dá»¯ liá»‡u nhÆ° Ä‘Ã­nh kÃ¨m. Hiá»‡n táº¡i Ä‘ang sá»§ dá»¥ng opencv - tesseract nhÆ°ng chá»‰ cho káº¿t quáº£ tá»‘t nháº¥t lÃ  154623/,69300) vÃ  16407,5/.69300). Ko biáº¿t trÃªn C# cÃ³ thÆ° viá»‡n open-source nÃ o cho káº¿t quáº£ tá»‘t hÆ¡n ko má»i ngÆ°á»i?","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang phÃ¡t triá»ƒn á»©ng dá»¥ng xá»­ lÃ½ áº£nh trÃªn C# vÃ  Ä‘ang gáº·p bÃ i toÃ¡n OCR cho dá»¯ liá»‡u nhÆ° Ä‘Ã­nh kÃ¨m. Hiá»‡n táº¡i Ä‘ang sá»§ dá»¥ng opencv - tesseract nhÆ°ng chá»‰ cho káº¿t quáº£ tá»‘t nháº¥t lÃ  154623/,69300) vÃ  16407,5/.69300). Ko biáº¿t trÃªn C# cÃ³ thÆ° viá»‡n open-source nÃ o cho káº¿t quáº£ tá»‘t hÆ¡n ko má»i ngÆ°á»i?",,,,,
"Dáº¡ cho e há»i vá»›i áº¡. Trong thuáº­t toÃ¡n K-means, vÃ­ dá»¥ náº¿u khoáº£ng cÃ¡ch cá»§a 1 con gÃ  vá»›i 1 con vá»‹t vá»›i trung tÃ¢m cÃ¹ng =4 thÃ¬ cÃ¡i nhÃ³m Ä‘Ã³ chá»n con nÃ o váº­y áº¡?
Em xin cáº£m Æ¡n","Dáº¡ cho e há»i vá»›i áº¡. Trong thuáº­t toÃ¡n K-means, vÃ­ dá»¥ náº¿u khoáº£ng cÃ¡ch cá»§a 1 con gÃ  vá»›i 1 con vá»‹t vá»›i trung tÃ¢m cÃ¹ng =4 thÃ¬ cÃ¡i nhÃ³m Ä‘Ã³ chá»n con nÃ o váº­y áº¡? Em xin cáº£m Æ¡n",,,,,
Tiá»‡p cho mÃ¬nh chia sáº» thÃªm má»™t follow-up post hÃ´m kia dÃ nh cho cÃ¡c báº¡n cÃ³ sá»± quan tÃ¢m vá» há»c tiáº¿n sÄ© cÃ¡c ngÃ nh liÃªn quan AI nhÃ©. Má»™t Ä‘iá»u mÃ  Viá»‡t Nam mÃ¬nh cÃ²n thiáº¿u lÃ  má»™t cá»™ng Ä‘á»“ng vá»¯ng máº¡nh cÃ¡c chuyÃªn gia chuyÃªn sÃ¢u vá» AI máº·c dÃ¹ chÃºng ta khÃ´ng há» thiáº¿u ká»¹ sÆ° giá»i. Hy vá»ng bÃ i post sáº½ mang má»™t sá»‘ thÃ´ng tin cáº§n thiáº¿t cho cÃ¡c báº¡n.,Tiá»‡p cho mÃ¬nh chia sáº» thÃªm má»™t follow-up post hÃ´m kia dÃ nh cho cÃ¡c báº¡n cÃ³ sá»± quan tÃ¢m vá» há»c tiáº¿n sÄ© cÃ¡c ngÃ nh liÃªn quan AI nhÃ©. Má»™t Ä‘iá»u mÃ  Viá»‡t Nam mÃ¬nh cÃ²n thiáº¿u lÃ  má»™t cá»™ng Ä‘á»“ng vá»¯ng máº¡nh cÃ¡c chuyÃªn gia chuyÃªn sÃ¢u vá» AI máº·c dÃ¹ chÃºng ta khÃ´ng há» thiáº¿u ká»¹ sÆ° giá»i. Hy vá»ng bÃ i post sáº½ mang má»™t sá»‘ thÃ´ng tin cáº§n thiáº¿t cho cÃ¡c báº¡n.,,,,,
"CÃ³ láº½ Ä‘Ã¢y lÃ  post sau vá» GNN trong tÃ¡c vá»¥ phÃ¢n loáº¡i áº£nh trong y há»c (vÃ¬ trÃ¡nh lÃ m phiá»n admins vÃ  cá»™ng Ä‘á»“ng pháº£i nghe mÃ£i 1 cÃ¢u chuyá»‡n.
Trong 2 Stt trÆ°á»›c Ä‘Ã¢y vá» bÃ i toÃ¡n phÃ¢n loáº¡i (1) lao phá»•i tá»« áº£nh X-quang táº¡i Ä‘Ã¢y
(https://www.facebook.com/groups/machinelearningcoban/permalink/1354190071705063/)
vÃ  (2) áº£nh Optical Coherence Tomography táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/permalink/1351401011983969/), káº¿t quáº£ ráº¥t kháº£ quan.
Trong post nÃ y mÃ¬nh muá»‘n kiá»ƒm tra xem GNN liá»‡u cÃ³ hoáº¡t Ä‘á»™ng tá»‘t trÃªn dá»¯ liá»‡u Ã¢m thanh trong y há»c hay khÃ´ng (dá»¯ liá»‡u Ã¢m thanh cÃ³ Ä‘áº·c tÃ­nh theo chuá»—i thá»i gian, vÃ  thÆ°á»ng Ä‘Æ°á»£c chuyá»ƒn thÃ nh dáº¡ng áº£nh cho bÃ i toÃ¡n phÃ¢n loáº¡i).
Má»™t dá»± Ã¡n Ä‘iá»ƒn hÃ¬nh khÃ¡c lÃ  phÃ¢n loáº¡i tiáº¿ng ho cá»§a bá»‡nh nhÃ¢n Covid-19 Ä‘Ã£ káº¿t thÃºc táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/1264976217251463), nhÆ°ng káº¿t quáº£ impractical, hay chÃ­ Ã­t Ä‘i xa hÆ¡n vá» máº·t nghiÃªn cá»©u, khi minhd Ä‘Æ°á»£c biáº¿t lÃ  Accuracy trÃªn private test set cá»§a nhÃ  tá»• chá»©c chá»‰ hÆ¡n giÃ¡ trá»‹ random má»™t chÃºt (>70%).
Dá»¯ liá»‡u cá»§a nghiÃªn cá»©u nÃ y ráº¥t ráº¥t khÃ³ náº¿u tiáº¿p cáº­n theo hÆ°á»›ng Machine Learning (SVM, XBoost,...), Deep Learning (xá»­ lÃ­ giÃ¡n tiáº¿p thÃ´ng qua xá»­ lÃ­ áº£nh vá»›i CNN & Transformer, hay hÆ°á»›ng xá»­ lÃ­ Ã¢m thanh thuáº§n tÃºy). Khi mÃ¬nh review pháº§n Related Works, khÃ´ng cÃ³ nghiÃªn cá»©u Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ cÃ³ thá»ƒ nghÄ© tá»›i viá»‡c practical trong thá»±c táº¿!
Váº­y nÃªn mÃ¬nh sáº½ demo hÆ°á»›ng tiáº¿p cáº­n GNN trong phÃ¢n loáº¡i Ã¢m thanh vá»›i dá»¯ liá»‡u cá»§a bÃ i bÃ¡o cÃ³ tÃªn ""A Respiratory Sound Database for the Development of Automated Classification"" táº¡i Ä‘Ã¢y (https://sci-hub.se/10.1007/978-981-10-7419-6_6), dá»¯ liá»‡u má»Ÿ táº¡i Ä‘Ã¢y (https://bhichallenge.med.auth.gr/). Dá»¯ liá»‡u nÃ y phÃ¢n loáº¡i tiáº¿ng nghe phá»•i cá»§a bá»‡nh nhÃ¢n, vÃ  khi review tÃ i liá»‡u thÃ¬ task nÃ y ráº¥t ráº¥t khÃ³, chá»‰ Ä‘áº¡t accuracy ~80% mÃ  thÃ´i. Tuy nhiÃªn náº¿u dÃ¹ng GNN, bÃ i toÃ¡n Ä‘Æ°á»£c giáº£i quyáº¿t triá»‡t Ä‘á»ƒ, Ã­t nháº¥t trong pháº¡m vi dá»¯ liá»‡u nÃ y. Tá»« Ä‘Ã³, nÃ³ má»Ÿ ra hÆ°á»›ng má»›i ráº¥t triá»ƒn vá»ng. CÃ¡c báº¡n cÃ³ thá»ƒ xem chi tiáº¿t káº¿t quáº£ á»Ÿ hÃ¬nh bÃªn dÆ°á»›i!","CÃ³ láº½ Ä‘Ã¢y lÃ  post sau vá» GNN trong tÃ¡c vá»¥ phÃ¢n loáº¡i áº£nh trong y há»c (vÃ¬ trÃ¡nh lÃ m phiá»n admins vÃ  cá»™ng Ä‘á»“ng pháº£i nghe mÃ£i 1 cÃ¢u chuyá»‡n. Trong 2 Stt trÆ°á»›c Ä‘Ã¢y vá» bÃ i toÃ¡n phÃ¢n loáº¡i (1) lao phá»•i tá»« áº£nh X-quang táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/permalink/1354190071705063/) vÃ  (2) áº£nh Optical Coherence Tomography táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/machinelearningcoban/permalink/1351401011983969/), káº¿t quáº£ ráº¥t kháº£ quan. Trong post nÃ y mÃ¬nh muá»‘n kiá»ƒm tra xem GNN liá»‡u cÃ³ hoáº¡t Ä‘á»™ng tá»‘t trÃªn dá»¯ liá»‡u Ã¢m thanh trong y há»c hay khÃ´ng (dá»¯ liá»‡u Ã¢m thanh cÃ³ Ä‘áº·c tÃ­nh theo chuá»—i thá»i gian, vÃ  thÆ°á»ng Ä‘Æ°á»£c chuyá»ƒn thÃ nh dáº¡ng áº£nh cho bÃ i toÃ¡n phÃ¢n loáº¡i). Má»™t dá»± Ã¡n Ä‘iá»ƒn hÃ¬nh khÃ¡c lÃ  phÃ¢n loáº¡i tiáº¿ng ho cá»§a bá»‡nh nhÃ¢n Covid-19 Ä‘Ã£ káº¿t thÃºc táº¡i Ä‘Ã¢y (https://www.facebook.com/groups/1264976217251463), nhÆ°ng káº¿t quáº£ impractical, hay chÃ­ Ã­t Ä‘i xa hÆ¡n vá» máº·t nghiÃªn cá»©u, khi minhd Ä‘Æ°á»£c biáº¿t lÃ  Accuracy trÃªn private test set cá»§a nhÃ  tá»• chá»©c chá»‰ hÆ¡n giÃ¡ trá»‹ random má»™t chÃºt (>70%). Dá»¯ liá»‡u cá»§a nghiÃªn cá»©u nÃ y ráº¥t ráº¥t khÃ³ náº¿u tiáº¿p cáº­n theo hÆ°á»›ng Machine Learning (SVM, XBoost,...), Deep Learning (xá»­ lÃ­ giÃ¡n tiáº¿p thÃ´ng qua xá»­ lÃ­ áº£nh vá»›i CNN & Transformer, hay hÆ°á»›ng xá»­ lÃ­ Ã¢m thanh thuáº§n tÃºy). Khi mÃ¬nh review pháº§n Related Works, khÃ´ng cÃ³ nghiÃªn cá»©u Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ cÃ³ thá»ƒ nghÄ© tá»›i viá»‡c practical trong thá»±c táº¿! Váº­y nÃªn mÃ¬nh sáº½ demo hÆ°á»›ng tiáº¿p cáº­n GNN trong phÃ¢n loáº¡i Ã¢m thanh vá»›i dá»¯ liá»‡u cá»§a bÃ i bÃ¡o cÃ³ tÃªn ""A Respiratory Sound Database for the Development of Automated Classification"" táº¡i Ä‘Ã¢y (https://sci-hub.se/10.1007/978-981-10-7419-6_6), dá»¯ liá»‡u má»Ÿ táº¡i Ä‘Ã¢y (https://bhichallenge.med.auth.gr/). Dá»¯ liá»‡u nÃ y phÃ¢n loáº¡i tiáº¿ng nghe phá»•i cá»§a bá»‡nh nhÃ¢n, vÃ  khi review tÃ i liá»‡u thÃ¬ task nÃ y ráº¥t ráº¥t khÃ³, chá»‰ Ä‘áº¡t accuracy ~80% mÃ  thÃ´i. Tuy nhiÃªn náº¿u dÃ¹ng GNN, bÃ i toÃ¡n Ä‘Æ°á»£c giáº£i quyáº¿t triá»‡t Ä‘á»ƒ, Ã­t nháº¥t trong pháº¡m vi dá»¯ liá»‡u nÃ y. Tá»« Ä‘Ã³, nÃ³ má»Ÿ ra hÆ°á»›ng má»›i ráº¥t triá»ƒn vá»ng. CÃ¡c báº¡n cÃ³ thá»ƒ xem chi tiáº¿t káº¿t quáº£ á»Ÿ hÃ¬nh bÃªn dÆ°á»›i!",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh tÃ¬m cÃ¡ch cháº¡y yolov5 trÃªn jetson nano,.. Ä‘Ã£ convert sang file yolov5.trt , khi cháº¡y code Ä‘á»ƒ load model theo link : https://github.com/.../SemanticSeg.../tutorial-runtime.ipynb thÃ¬ bá»‹ lá»—i nhÆ° hÃ¬nh bÃªn dÆ°á»›i (trong quÃ¡ trÃ¬nh convert cÃ³ thÃ´ng bÃ¡o plugin successed)
(tensorrt 8.0.1.6)
Má»i ngÆ°á»i nÃ o cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ detect object cá»¥ thá»ƒ sau khi Ä‘Ã£ xuáº¥t Ä‘Æ°á»£c file .trt khÃ´ng áº¡ ?
Mong Ä‘Æ°á»£c má»i ngÆ°á»i há»— trá»£.
MÃ¬nh cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, MÃ¬nh tÃ¬m cÃ¡ch cháº¡y yolov5 trÃªn jetson nano,.. Ä‘Ã£ convert sang file yolov5.trt , khi cháº¡y code Ä‘á»ƒ load model theo link : https://github.com/.../SemanticSeg.../tutorial-runtime.ipynb thÃ¬ bá»‹ lá»—i nhÆ° hÃ¬nh bÃªn dÆ°á»›i (trong quÃ¡ trÃ¬nh convert cÃ³ thÃ´ng bÃ¡o plugin successed) (tensorrt 8.0.1.6) Má»i ngÆ°á»i nÃ o cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ detect object cá»¥ thá»ƒ sau khi Ä‘Ã£ xuáº¥t Ä‘Æ°á»£c file .trt khÃ´ng áº¡ ? Mong Ä‘Æ°á»£c má»i ngÆ°á»i há»— trá»£. MÃ¬nh cáº£m Æ¡n.",,,,,
"ChaÌ€o m.n aÌ£!
M,n ai Ä‘aÌƒ tÆ°Ì€ng triÃªÌ‰n khai mÃ´Ì£t mÃ´ hiÌ€nh CV pytorch nhÆ° Mask RCNN, Faster RCNN, ... trÃªn Netframework cuÌ‰a C# chÆ°a aÌ£. CoÌ thÃªÌ‰ cho em xin git tham khaÌ‰o hoÄƒÌ£c hÆ°Æ¡Ìng triÃªÌ‰n khai Ä‘Æ°Æ¡Ì£c khÃ´ng!
Thanks m.n!","ChaÌ€o m.n aÌ£! M,n ai Ä‘aÌƒ tÆ°Ì€ng triÃªÌ‰n khai mÃ´Ì£t mÃ´ hiÌ€nh CV pytorch nhÆ° Mask RCNN, Faster RCNN, ... trÃªn Netframework cuÌ‰a C# chÆ°a aÌ£. CoÌ thÃªÌ‰ cho em xin git tham khaÌ‰o hoÄƒÌ£c hÆ°Æ¡Ìng triÃªÌ‰n khai Ä‘Æ°Æ¡Ì£c khÃ´ng! Thanks m.n!",,,,,
"Cho em há»i em Ä‘Ã£ cÃ i GPU cho tensorflow nhÆ°ng khi train thÃ¬ tá»‘c Ä‘á»™ váº«n khÃ´ng cáº£i thiá»‡n dÃ¹ng vram cá»§a gpu full
Em dÃ¹ng :
Tensorflow 2.7
CUDA toolkit 11.2
Cudnn 8.1
Ä‘Ã£ set path Ä‘áº§y Ä‘á»§ rá»“i áº¡.
Em ngÆ°á»i cho em giáº£i phÃ¡p kháº¯c phá»¥c vá»›i áº¡, em cáº£m Æ¡n","Cho em há»i em Ä‘Ã£ cÃ i GPU cho tensorflow nhÆ°ng khi train thÃ¬ tá»‘c Ä‘á»™ váº«n khÃ´ng cáº£i thiá»‡n dÃ¹ng vram cá»§a gpu full Em dÃ¹ng : Tensorflow 2.7 CUDA toolkit 11.2 Cudnn 8.1 Ä‘Ã£ set path Ä‘áº§y Ä‘á»§ rá»“i áº¡. Em ngÆ°á»i cho em giáº£i phÃ¡p kháº¯c phá»¥c vá»›i áº¡, em cáº£m Æ¡n",,,,,
"Em chÃ o má»i ngÆ°á»i. Em Ä‘ang thiáº¿t káº¿ má»™t model Ä‘á»ƒ táº¡o hÃ nh Ä‘á»™ng cho bot trong game Ä‘áº·t bom Ä‘á»‘i khÃ¡ng. Äáº§u vÃ o cá»§a model em dá»± Ä‘á»‹nh sáº½ lÃ  má»™t ma tráº­n map game mÃ  má»—i pháº§n tá»­ trong ma tráº­n cÃ³ thá»ƒ lÃ  cÃ¡c váº­t cáº£n hoáº·c vá»‹ trÃ­ cá»§a cÃ¡c bomb, Ä‘á»‘i thá»§, bonus,.... Model sáº½ cÃ³ nhiá»‡m vá»¥ xá»­ lÃ½ cÃ¡c Ä‘áº§u vÃ o vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cho bot trong 5 hÃ nh Ä‘á»™ng sau: Up, Down, Left, Right, Set Bomb. Má»i ngÆ°á»i cho em Ã½ kiáº¿n vá» viá»‡c chá»n model Ä‘á»ƒ thá»±c hiá»‡n yÃªu cáº§u Ä‘Ã³, CÃ¡ch tá»• chá»©c vÃ  gáº¯n nhÃ£n dá»¯ liá»‡u. Em Ä‘á»‹nh xÃ¢y dá»±ng model MLP vá»›i Ä‘áº§u vÃ o lÃ  cÃ¡c map Ä‘Æ°á»£c flattening thÃ nh cÃ¡c vector shape(d, 1) vÃ  Ä‘áº§u ra lÃ  5 classifier nhÆ° mÃ´ táº£ á»Ÿ trÃªn, hoáº·c model CNN xá»­ lÃ½ cÃ¡c ma tráº­n map Ä‘áº§u vÃ o báº±ng cÃ¡c táº§ng tÃ­ch cháº­p Ä‘á»ƒ há»c Ä‘Æ°á»£c ká»¹ hÆ¡n cÃ¡c Ä‘áº·c trÆ°ng cá»§a map, cÃ²n classifier váº«n nhÆ° MLP vá»›i Ä‘áº§u ra 5 lá»›p.
Em cÃ¡m Æ¡n báº¥t ká»³ Ä‘Ã³ng gÃ³p nÃ o cá»§a má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i. Em Ä‘ang thiáº¿t káº¿ má»™t model Ä‘á»ƒ táº¡o hÃ nh Ä‘á»™ng cho bot trong game Ä‘áº·t bom Ä‘á»‘i khÃ¡ng. Äáº§u vÃ o cá»§a model em dá»± Ä‘á»‹nh sáº½ lÃ  má»™t ma tráº­n map game mÃ  má»—i pháº§n tá»­ trong ma tráº­n cÃ³ thá»ƒ lÃ  cÃ¡c váº­t cáº£n hoáº·c vá»‹ trÃ­ cá»§a cÃ¡c bomb, Ä‘á»‘i thá»§, bonus,.... Model sáº½ cÃ³ nhiá»‡m vá»¥ xá»­ lÃ½ cÃ¡c Ä‘áº§u vÃ o vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cho bot trong 5 hÃ nh Ä‘á»™ng sau: Up, Down, Left, Right, Set Bomb. Má»i ngÆ°á»i cho em Ã½ kiáº¿n vá» viá»‡c chá»n model Ä‘á»ƒ thá»±c hiá»‡n yÃªu cáº§u Ä‘Ã³, CÃ¡ch tá»• chá»©c vÃ  gáº¯n nhÃ£n dá»¯ liá»‡u. Em Ä‘á»‹nh xÃ¢y dá»±ng model MLP vá»›i Ä‘áº§u vÃ o lÃ  cÃ¡c map Ä‘Æ°á»£c flattening thÃ nh cÃ¡c vector shape(d, 1) vÃ  Ä‘áº§u ra lÃ  5 classifier nhÆ° mÃ´ táº£ á»Ÿ trÃªn, hoáº·c model CNN xá»­ lÃ½ cÃ¡c ma tráº­n map Ä‘áº§u vÃ o báº±ng cÃ¡c táº§ng tÃ­ch cháº­p Ä‘á»ƒ há»c Ä‘Æ°á»£c ká»¹ hÆ¡n cÃ¡c Ä‘áº·c trÆ°ng cá»§a map, cÃ²n classifier váº«n nhÆ° MLP vá»›i Ä‘áº§u ra 5 lá»›p. Em cÃ¡m Æ¡n báº¥t ká»³ Ä‘Ã³ng gÃ³p nÃ o cá»§a má»i ngÆ°á»i.",,,,,
"Quá»¹ Äá»•i má»›i SÃ¡ng táº¡o Vingroup (VINIF) sáº½ chÃ­nh thá»©c cÃ´ng bá»‘ danh sÃ¡ch cÃ¡c dá»± Ã¡n nghiÃªn cá»©u Khoa há»c - CÃ´ng nghá»‡ Ä‘Æ°á»£c nháº­n tÃ i trá»£ nÄƒm 2021. LÃ  nÄƒm thá»© ba triá»ƒn khai, chÆ°Æ¡ng trÃ¬nh Ä‘Ã£ thu hÃºt sá»‘ lÆ°á»£ng ká»· lá»¥c vá»›i 211 há»“ sÆ¡ Ä‘á» xuáº¥t, tá»« Ä‘Ã³, tiáº¿n hÃ nh tháº©m Ä‘á»‹nh kháº¯t khe vÃ  ká»¹ lÆ°á»¡ng Ä‘á»ƒ chá»n ra 20 dá»± Ã¡n tiÃªu biá»ƒu.
Táº¡i sá»± kiá»‡n, Quá»¹ VINIF cÅ©ng sáº½ sÆ¡ káº¿t hai nÄƒm hoáº¡t Ä‘á»™ng cá»§a ChÆ°Æ¡ng trÃ¬nh TÃ i trá»£ Dá»± Ã¡n Khoa há»c - CÃ´ng nghá»‡.
HÃ£y cÃ¹ng Ä‘Ã³n Ä‘á»£i nhá»¯ng nhÃ³m nghiÃªn cá»©u Ä‘Æ°á»£c nháº­n tÃ i trá»£ nÄƒm nay, Ä‘á»“ng thá»i, cÃ¹ng VINIF Ä‘iá»ƒm láº¡i nhá»¯ng cá»™t má»‘c Ä‘Ã¡ng nhá»› trÃªn cháº·ng Ä‘Æ°á»ng Ä‘á»“ng hÃ nh cÃ¹ng cÃ¡c nhÃ  khoa há»c Viá»‡t.
#VINIF #KHCN","Quá»¹ Äá»•i má»›i SÃ¡ng táº¡o Vingroup (VINIF) sáº½ chÃ­nh thá»©c cÃ´ng bá»‘ danh sÃ¡ch cÃ¡c dá»± Ã¡n nghiÃªn cá»©u Khoa há»c - CÃ´ng nghá»‡ Ä‘Æ°á»£c nháº­n tÃ i trá»£ nÄƒm 2021. LÃ  nÄƒm thá»© ba triá»ƒn khai, chÆ°Æ¡ng trÃ¬nh Ä‘Ã£ thu hÃºt sá»‘ lÆ°á»£ng ká»· lá»¥c vá»›i 211 há»“ sÆ¡ Ä‘á» xuáº¥t, tá»« Ä‘Ã³, tiáº¿n hÃ nh tháº©m Ä‘á»‹nh kháº¯t khe vÃ  ká»¹ lÆ°á»¡ng Ä‘á»ƒ chá»n ra 20 dá»± Ã¡n tiÃªu biá»ƒu. Táº¡i sá»± kiá»‡n, Quá»¹ VINIF cÅ©ng sáº½ sÆ¡ káº¿t hai nÄƒm hoáº¡t Ä‘á»™ng cá»§a ChÆ°Æ¡ng trÃ¬nh TÃ i trá»£ Dá»± Ã¡n Khoa há»c - CÃ´ng nghá»‡. HÃ£y cÃ¹ng Ä‘Ã³n Ä‘á»£i nhá»¯ng nhÃ³m nghiÃªn cá»©u Ä‘Æ°á»£c nháº­n tÃ i trá»£ nÄƒm nay, Ä‘á»“ng thá»i, cÃ¹ng VINIF Ä‘iá»ƒm láº¡i nhá»¯ng cá»™t má»‘c Ä‘Ã¡ng nhá»› trÃªn cháº·ng Ä‘Æ°á»ng Ä‘á»“ng hÃ nh cÃ¹ng cÃ¡c nhÃ  khoa há»c Viá»‡t.",#VINIF	#KHCN,,,,
Dáº¡ em chÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cho em há»i cÃ³ ai trong Ä‘Ã¢y biáº¿t web chÆ°a dataset cá»§a áº£nh UAV mÃ  vá» cÃ¢y hoa khÃ´ng áº¡. Ai biáº¿t xin chá»‰ dÃ¹m em vá»›i áº¡. Em xin cáº£m Æ¡n!,Dáº¡ em chÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cho em há»i cÃ³ ai trong Ä‘Ã¢y biáº¿t web chÆ°a dataset cá»§a áº£nh UAV mÃ  vá» cÃ¢y hoa khÃ´ng áº¡. Ai biáº¿t xin chá»‰ dÃ¹m em vá»›i áº¡. Em xin cáº£m Æ¡n!,,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ Ä‘Äƒng má»™t sá»‘ threads vá» Graph Neural Networks, trong Ä‘Ã³ cÃ³ viá»‡c á»©ng dá»¥ng GNN trong phÃ¢n loáº¡i áº£nh y há»c táº¡i Ä‘Ã¢y https://www.facebook.com/groups/machinelearningcoban/?multi_permalinks=1351401011983969&comment_id=1351448025312601&notif_id=1638517817496670&notif_t=feedback_reaction_generic&ref=notif
VÃ¬ káº¿t quáº£ too good to be true nÃªn mÃ¬nh nghi ngá», do Ä‘Ã³ cÃ³ lÃ m thÃªm bÃ i toÃ¡n phÃ¢n loáº¡i bá»‡nh lao phá»•i dá»±a trÃªn áº£nh X quang vÃ¹ng ngá»±c dá»±a trÃªn bÃ i bÃ¡o cá»§a nhÃ³m mÃ¬nh: ""Detection of tuberculosis from chest X-ray images: Boosting the performance with vision transformer and transfer learning"" vÃ  source code táº¡i Ä‘Ã¢y: https://github.com/linhduongtuan/Tuberculosis_ChestXray_Classifier.
Káº¿t quáº£ dá»±a trÃªn GNN cho bÃ i toÃ¡n phÃ¢n loáº¡i Lao phá»•i (Turberculosis) vs áº£nh khÃ´ng viÃªm phá»•i vs áº£nh viÃªm phá»•i do tÃ¡c nhÃ¢n khÃ¡c, ráº¥t kháº£ quan vÃ  vÆ°á»£t qua nghiÃªn cá»©u mÃ¬nh Ä‘Ã£ cÃ´ng bá»‘ trÆ°á»›c Ä‘Ã¢y. CÃ¡i hay cá»§a GNN lÃ  nÃ³ cÃ³ thá»ƒ kháº¯c phá»¥c viá»‡c lá»‡ch (imbalance) cá»§a dataset ráº¥t tá»‘t!
Tá»›i giá» mÃ¬nh cÃ³ thá»ƒ tÆ°Æ¡ng Ä‘á»‘i tá»± tin nÃ³i ráº±ng GNN cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh y há»c sáº½ lÃ  hÆ°á»›ng Ä‘i má»›i, giáº£i quyáº¿t nhá»¯ng khÃ³ khÄƒn trÆ°á»›c Ä‘Ã¢y mÃ  CNNs hay Transformers chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c!
PROTIP: Viá»‡c build GNN models khÃ´ng cÃ³ gÃ¬ khÃ³ khÄƒn, nhÆ°ng quÃ¡ trÃ¬nh tiá»n xá»­ lÃ­ áº£nh vá»›i edge detection rá»“i chuyá»ƒn nÃ³ thÃ nh Graph data lÃ  má»™t thÃ¡ch thá»©c!
TIP 1: QuÃ¡ trÃ¬nh train GNN models ráº¥t Ä‘Æ¡n giáº£n vÃ  tá»‘n Ã­t tÃ i nguyÃªn, hoÃ n toÃ n cÃ³ thá»ƒ dÃ¹ng Colab Free hay tháº­m trÃ­ dÃ¹ng CPU
TIP 2: Viá»‡c settings hyperparameters Ä‘á»ƒ tÃ¬m Ä‘iá»ƒm tá»‘i Æ°u cÅ©ng ráº¥t Ä‘Æ¡n giáº£n, cÃ ng phá»©c táº¡p hÃ³a viá»‡c thiáº¿t láº­p tham sá»‘, cÃ ng cho káº¿t quáº£ khÃ´ng nhÆ° mong muá»‘n!
Táº¡m káº¿t: GNNs cÃ³ láº½ lÃ  tÆ°Æ¡ng lai cá»§a nhiá»u lÄ©nh vá»±c, Ä‘áº·c biá»‡t trong computational Biology/Chemistry/Physics/etc","Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ Ä‘Äƒng má»™t sá»‘ threads vá» Graph Neural Networks, trong Ä‘Ã³ cÃ³ viá»‡c á»©ng dá»¥ng GNN trong phÃ¢n loáº¡i áº£nh y há»c táº¡i Ä‘Ã¢y https://www.facebook.com/groups/machinelearningcoban/?multi_permalinks=1351401011983969&comment_id=1351448025312601&notif_id=1638517817496670&notif_t=feedback_reaction_generic&ref=notif VÃ¬ káº¿t quáº£ too good to be true nÃªn mÃ¬nh nghi ngá», do Ä‘Ã³ cÃ³ lÃ m thÃªm bÃ i toÃ¡n phÃ¢n loáº¡i bá»‡nh lao phá»•i dá»±a trÃªn áº£nh X quang vÃ¹ng ngá»±c dá»±a trÃªn bÃ i bÃ¡o cá»§a nhÃ³m mÃ¬nh: ""Detection of tuberculosis from chest X-ray images: Boosting the performance with vision transformer and transfer learning"" vÃ  source code táº¡i Ä‘Ã¢y: https://github.com/linhduongtuan/Tuberculosis_ChestXray_Classifier. Káº¿t quáº£ dá»±a trÃªn GNN cho bÃ i toÃ¡n phÃ¢n loáº¡i Lao phá»•i (Turberculosis) vs áº£nh khÃ´ng viÃªm phá»•i vs áº£nh viÃªm phá»•i do tÃ¡c nhÃ¢n khÃ¡c, ráº¥t kháº£ quan vÃ  vÆ°á»£t qua nghiÃªn cá»©u mÃ¬nh Ä‘Ã£ cÃ´ng bá»‘ trÆ°á»›c Ä‘Ã¢y. CÃ¡i hay cá»§a GNN lÃ  nÃ³ cÃ³ thá»ƒ kháº¯c phá»¥c viá»‡c lá»‡ch (imbalance) cá»§a dataset ráº¥t tá»‘t! Tá»›i giá» mÃ¬nh cÃ³ thá»ƒ tÆ°Æ¡ng Ä‘á»‘i tá»± tin nÃ³i ráº±ng GNN cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh y há»c sáº½ lÃ  hÆ°á»›ng Ä‘i má»›i, giáº£i quyáº¿t nhá»¯ng khÃ³ khÄƒn trÆ°á»›c Ä‘Ã¢y mÃ  CNNs hay Transformers chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c! PROTIP: Viá»‡c build GNN models khÃ´ng cÃ³ gÃ¬ khÃ³ khÄƒn, nhÆ°ng quÃ¡ trÃ¬nh tiá»n xá»­ lÃ­ áº£nh vá»›i edge detection rá»“i chuyá»ƒn nÃ³ thÃ nh Graph data lÃ  má»™t thÃ¡ch thá»©c! TIP 1: QuÃ¡ trÃ¬nh train GNN models ráº¥t Ä‘Æ¡n giáº£n vÃ  tá»‘n Ã­t tÃ i nguyÃªn, hoÃ n toÃ n cÃ³ thá»ƒ dÃ¹ng Colab Free hay tháº­m trÃ­ dÃ¹ng CPU TIP 2: Viá»‡c settings hyperparameters Ä‘á»ƒ tÃ¬m Ä‘iá»ƒm tá»‘i Æ°u cÅ©ng ráº¥t Ä‘Æ¡n giáº£n, cÃ ng phá»©c táº¡p hÃ³a viá»‡c thiáº¿t láº­p tham sá»‘, cÃ ng cho káº¿t quáº£ khÃ´ng nhÆ° mong muá»‘n! Táº¡m káº¿t: GNNs cÃ³ láº½ lÃ  tÆ°Æ¡ng lai cá»§a nhiá»u lÄ©nh vá»±c, Ä‘áº·c biá»‡t trong computational Biology/Chemistry/Physics/etc",,,,,
"Ráº¥t vui khi Ä‘Æ°á»£c giá»›i thiá»‡u hÆ°á»›ng tiáº¿p cáº­n má»›i cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh y há»c.
TrÆ°á»›c Ä‘Ã¢y, bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh chá»§ yáº¿u dá»±a vÃ o kiáº¿n trÃºc máº¡ng CNNs. Trong 2 nÄƒm qua, viá»‡c á»©ng dá»¥ng kiáº¿n trÃºc Attention/Transformers vÃ o bÃ i toÃ¡n xá»­ lÃ­ áº£nh cÅ©ng Ä‘Æ°á»£c cá»™ng Ä‘á»“ng quá»‘c táº¿ Ä‘áº·c biá»‡t quan tÃ¢m.
Tuy nhiÃªn, trong vÃ²ng 5 nÄƒm qua, kiáº¿n trÃºc Graph Neural Networks (GNN) ngÃ y má»™t phÃ¡t triá»ƒn vÃ  cÃ³ nhá»¯ng á»©ng dá»¥ng há»¯u Ã­ch vÃ o dá»¯ liá»‡u khÃ¡c nhau.
CÃ¢u há»i Ä‘áº·t ra lÃ  liá»‡u GNNs cÃ³ thá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh trong y há»c Ä‘Æ°á»£c khÃ´ng? Tháº­t may, vá»›i má»™t sá»‘ thÃ­ nghiá»‡m Ä‘á»™c láº­p mÃ¬nh lÃ m, GNNs Ä‘á»™ng cá»±c kÃ¬ hiá»‡u quáº£ cho bÃ i toÃ¡n phÃ¢n loáº¡i cÃ¡c áº£nh y khoa khÃ¡c nhau nhÆ° Chest X-ray, Optical Coherence Tomography (OCT), Mammography,...
Sau Ä‘Ã¢y lÃ  káº¿t quáº£ mÃ¬nh muá»‘n giá»›i thiá»‡u viá»‡c dÃ¹ng GNN Ä‘á»ƒ phÃ¢n loáº¡i áº£nh OCT táº¡i bÃ i bÃ¡o ""Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning"" (https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867418301545%3Fshowall%3Dtrue) , dataset táº¡i Ä‘Ã¢y https://data.mendeley.com/datasets/rscbjbr9sj/3. CÃ³ 1 lÆ°u Ã½ ráº±ng, náº¿u dataset nÃ y vá»›i phiÃªn báº£n 1 vÃ  2, cÃ¡c models vá»›i kiáº¿n trÃºc CNNs hoáº¡t Ä‘á»™ng ráº¥t ráº¥t tá»‘t vá»›i accuracy trÃªn test set > 99%. Tuy nhiÃªn vá»›i dataset phiÃªn báº£n 3 nhÆ° trong Ä‘Æ°á»ng dáº«n trÃªn, mÃ¬nh Ä‘Ã£ thá»­ cáº£ CNNs vÃ  transformers thÃ¬ accuracy trÃªn test set <96%, Ä‘iá»u nÃ y khiáº¿n mÃ¬nh khÃ¡ tháº¥t vá»ng!!!
Má»™t Ä‘iá»u thÃº vá»‹ ná»¯a vá»›i GNNs lÃ  tá»•ng thá»i gian tiá»n xá»­ lÃ­ áº£nh, vÃ  huáº¥n luyá»‡n chá»‰ táº§m 10h so vá»›i vÃ i ngÃ y náº¿u dÃ¹ng CNNs hay Transformers! MÃ  thá»i gian huáº¥n luyá»‡n models chá»‰ chiáº¿m 10 phÃºt trÃªn RTX 3090, vÃ  models há»™i tá»¥ ráº¥t ráº¥t nhanh á»Ÿ ngay nhá»¯ng chu kÃ¬ huáº¥n luyá»‡n Ä‘áº§u tiÃªn. ThÃªm vÃ o Ä‘Ã³, pháº§n lá»›n thá»i gian cÃ²n láº¡i lÃ  Ä‘á»ƒ biáº¿n áº£nh thÃ nh dáº¡ng Graph data (mÃ¬nh dÃ¹ng 1 Xeon E5 2680v4 vá»›i 64G RAM). LÆ°u Ã½, Ä‘á»ƒ xá»­ lÃ­ sá»‘ áº£nh trÃªn, báº¡n sáº½ bá»‹ trÃ n RAM, nhÆ°ng giáº£i phÃ¡p kháº¯c phá»¥c lÃ  tÄƒng dung lÆ°á»£ng phÃ¢n vÃ¹ng SWAP cá»§a á»• cá»©ng trong há»‡ Ä‘iá»u hÃ nh Ubuntu lÃªn >100G sáº½ an toÃ n! Káº¿t quáº£ cuá»‘i cÃ¹ng accuracy trÃªn táº¥t cáº£ cÃ¡c táº­p nhÆ° training, validation vÃ  Ä‘áº·c biá»‡t lÃ  test set Ä‘á»u HOÃ€N Háº¢O!!!
Ráº¥t mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n chia sáº», Ä‘Ã³ng gÃ³p, náº¿u cÃ³ há»£p tÃ¡c nghiÃªn cá»©u thÃ¬ cÃ ng tá»‘t!","Ráº¥t vui khi Ä‘Æ°á»£c giá»›i thiá»‡u hÆ°á»›ng tiáº¿p cáº­n má»›i cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh y há»c. TrÆ°á»›c Ä‘Ã¢y, bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh chá»§ yáº¿u dá»±a vÃ o kiáº¿n trÃºc máº¡ng CNNs. Trong 2 nÄƒm qua, viá»‡c á»©ng dá»¥ng kiáº¿n trÃºc Attention/Transformers vÃ o bÃ i toÃ¡n xá»­ lÃ­ áº£nh cÅ©ng Ä‘Æ°á»£c cá»™ng Ä‘á»“ng quá»‘c táº¿ Ä‘áº·c biá»‡t quan tÃ¢m. Tuy nhiÃªn, trong vÃ²ng 5 nÄƒm qua, kiáº¿n trÃºc Graph Neural Networks (GNN) ngÃ y má»™t phÃ¡t triá»ƒn vÃ  cÃ³ nhá»¯ng á»©ng dá»¥ng há»¯u Ã­ch vÃ o dá»¯ liá»‡u khÃ¡c nhau. CÃ¢u há»i Ä‘áº·t ra lÃ  liá»‡u GNNs cÃ³ thá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh trong y há»c Ä‘Æ°á»£c khÃ´ng? Tháº­t may, vá»›i má»™t sá»‘ thÃ­ nghiá»‡m Ä‘á»™c láº­p mÃ¬nh lÃ m, GNNs Ä‘á»™ng cá»±c kÃ¬ hiá»‡u quáº£ cho bÃ i toÃ¡n phÃ¢n loáº¡i cÃ¡c áº£nh y khoa khÃ¡c nhau nhÆ° Chest X-ray, Optical Coherence Tomography (OCT), Mammography,... Sau Ä‘Ã¢y lÃ  káº¿t quáº£ mÃ¬nh muá»‘n giá»›i thiá»‡u viá»‡c dÃ¹ng GNN Ä‘á»ƒ phÃ¢n loáº¡i áº£nh OCT táº¡i bÃ i bÃ¡o ""Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning"" (https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867418301545%3Fshowall%3Dtrue) , dataset táº¡i Ä‘Ã¢y https://data.mendeley.com/datasets/rscbjbr9sj/3. CÃ³ 1 lÆ°u Ã½ ráº±ng, náº¿u dataset nÃ y vá»›i phiÃªn báº£n 1 vÃ  2, cÃ¡c models vá»›i kiáº¿n trÃºc CNNs hoáº¡t Ä‘á»™ng ráº¥t ráº¥t tá»‘t vá»›i accuracy trÃªn test set > 99%. Tuy nhiÃªn vá»›i dataset phiÃªn báº£n 3 nhÆ° trong Ä‘Æ°á»ng dáº«n trÃªn, mÃ¬nh Ä‘Ã£ thá»­ cáº£ CNNs vÃ  transformers thÃ¬ accuracy trÃªn test set <96%, Ä‘iá»u nÃ y khiáº¿n mÃ¬nh khÃ¡ tháº¥t vá»ng!!! Má»™t Ä‘iá»u thÃº vá»‹ ná»¯a vá»›i GNNs lÃ  tá»•ng thá»i gian tiá»n xá»­ lÃ­ áº£nh, vÃ  huáº¥n luyá»‡n chá»‰ táº§m 10h so vá»›i vÃ i ngÃ y náº¿u dÃ¹ng CNNs hay Transformers! MÃ  thá»i gian huáº¥n luyá»‡n models chá»‰ chiáº¿m 10 phÃºt trÃªn RTX 3090, vÃ  models há»™i tá»¥ ráº¥t ráº¥t nhanh á»Ÿ ngay nhá»¯ng chu kÃ¬ huáº¥n luyá»‡n Ä‘áº§u tiÃªn. ThÃªm vÃ o Ä‘Ã³, pháº§n lá»›n thá»i gian cÃ²n láº¡i lÃ  Ä‘á»ƒ biáº¿n áº£nh thÃ nh dáº¡ng Graph data (mÃ¬nh dÃ¹ng 1 Xeon E5 2680v4 vá»›i 64G RAM). LÆ°u Ã½, Ä‘á»ƒ xá»­ lÃ­ sá»‘ áº£nh trÃªn, báº¡n sáº½ bá»‹ trÃ n RAM, nhÆ°ng giáº£i phÃ¡p kháº¯c phá»¥c lÃ  tÄƒng dung lÆ°á»£ng phÃ¢n vÃ¹ng SWAP cá»§a á»• cá»©ng trong há»‡ Ä‘iá»u hÃ nh Ubuntu lÃªn >100G sáº½ an toÃ n! Káº¿t quáº£ cuá»‘i cÃ¹ng accuracy trÃªn táº¥t cáº£ cÃ¡c táº­p nhÆ° training, validation vÃ  Ä‘áº·c biá»‡t lÃ  test set Ä‘á»u HOÃ€N Háº¢O!!! Ráº¥t mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n chia sáº», Ä‘Ã³ng gÃ³p, náº¿u cÃ³ há»£p tÃ¡c nghiÃªn cá»©u thÃ¬ cÃ ng tá»‘t!",,,,,
"Xin máº¿n chÃ o cÃ¡c anh chá»‹,
Em Ä‘ang tá»± há»c phÃ¢n tÃ­ch dá»¯ liá»‡u, hiá»‡n em cÃ³ má»™t váº¥n Ä‘á» liÃªn quan Ä‘áº¿n káº¿t há»£p beeswarm plot vÃ  boxplot. 
Call beswarm thÃ¬ bÃ¬nh thÆ°á»ng khÃ´ng cÃ³ gÃ¬ (HÃ¬nh cháº¥m xanh), sau Ä‘Ã³ em tiáº¿p tá»¥c call boxplot  thÃ¬ káº¿t quáº£ mong muá»‘n lÃ  cÃ¡i hÃ¬nh cÃ³  beeswarm plot vÃ  boxplot.
NhÆ°ng hiá»‡n táº¡i error xáº£y ra khi em thÃªm parameter ""add = T"", parameter nÃ y cho phÃ©p chÃºng ta káº¿t há»£p boxplot vá»›i current plot. Error: ""Error in xypolygon(xx, yy, lty = ""blank"", col = boxfill[i]): plot.new has not been called yet""
Em Ä‘Ã£ thá»­ tÃ¬m kiáº¿m trÃªn gg vá» lá»—i nÃ y nhÆ°ng chÆ°a cÃ³ nhiá»u thÃ´ng tin láº¯m vÃ  em cÅ©ng Ä‘ang Ä‘Äƒng lÃªn stackoverfollow
https://stackoverflow.com/questions/70277890/beewarm-boxplot-plot-new-has-not-been-called-yet
Trong quÃ¡ trÃ¬nh chá» Ä‘á»£i cÃ¡c anh chá»‹ há»— trá»£ em sáº½ cá»‘ gáº¯ng tÃ¬m kiáº¿m thÃªm thÃ´ng tin vá» lá»—i nÃ y.
Xin lá»—i vÃ¬ sá»± báº¥t tiá»‡n
Máº¿n chÃ o cÃ¡c anh chá»‹.","Xin máº¿n chÃ o cÃ¡c anh chá»‹, Em Ä‘ang tá»± há»c phÃ¢n tÃ­ch dá»¯ liá»‡u, hiá»‡n em cÃ³ má»™t váº¥n Ä‘á» liÃªn quan Ä‘áº¿n káº¿t há»£p beeswarm plot vÃ  boxplot. Call beswarm thÃ¬ bÃ¬nh thÆ°á»ng khÃ´ng cÃ³ gÃ¬ (HÃ¬nh cháº¥m xanh), sau Ä‘Ã³ em tiáº¿p tá»¥c call boxplot thÃ¬ káº¿t quáº£ mong muá»‘n lÃ  cÃ¡i hÃ¬nh cÃ³ beeswarm plot vÃ  boxplot. NhÆ°ng hiá»‡n táº¡i error xáº£y ra khi em thÃªm parameter ""add = T"", parameter nÃ y cho phÃ©p chÃºng ta káº¿t há»£p boxplot vá»›i current plot. Error: ""Error in xypolygon(xx, yy, lty = ""blank"", col = boxfill[i]): plot.new has not been called yet"" Em Ä‘Ã£ thá»­ tÃ¬m kiáº¿m trÃªn gg vá» lá»—i nÃ y nhÆ°ng chÆ°a cÃ³ nhiá»u thÃ´ng tin láº¯m vÃ  em cÅ©ng Ä‘ang Ä‘Äƒng lÃªn stackoverfollow https://stackoverflow.com/questions/70277890/beewarm-boxplot-plot-new-has-not-been-called-yet Trong quÃ¡ trÃ¬nh chá» Ä‘á»£i cÃ¡c anh chá»‹ há»— trá»£ em sáº½ cá»‘ gáº¯ng tÃ¬m kiáº¿m thÃªm thÃ´ng tin vá» lá»—i nÃ y. Xin lá»—i vÃ¬ sá»± báº¥t tiá»‡n Máº¿n chÃ o cÃ¡c anh chá»‹.",,,,,
"HÆ°á»›ng dáº«n Edge AI vá»›i TensorFlow Lite vÃ  Raspberry Pi
ChÃ o má»i ngÆ°á»i! MÃ¬nh má»›i Ä‘Äƒng 1 video series trÃªn kÃªnh YouTube cá»§a TensorFlow vá»›i 4 video vá» object detection model trÃªn Raspberry Pi báº±ng TensorFlow Lite. Model nÃ y cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nhÆ°ng váº«n cháº¡y khÃ¡ nhanh (Ä‘áº¡t khoáº£ng 6 fps) trÃªn CPU cá»§a Raspberry Pi 4. CÃ¡c video nÃ y bao gá»“m Ä‘áº§y Ä‘á»§ cÃ¡c use case báº¡n thÆ°á»ng gáº·p khi deploy Edge AI:
1. Download model Ä‘Ã£ train sáºµn tá»« TensorFlow Hub vÃ  tÃ­ch há»£p ngay vÃ o app
2. Tá»± train model trÃªn táº­p dá»¯ liá»‡u cá»§a mÃ¬nh Ä‘á»ƒ phá»¥c vá»¥ nhá»¯ng á»©ng dá»¥ng mÃ  pretrained models khÃ´ng Ä‘Ã¡p á»©ng Ä‘Æ°á»£c.
3. Chá»n kiáº¿n trÃºc mÃ´ hÃ¬nh (model architecture) nÃ o Ä‘á»ƒ phÃ¹ há»£p vá»›i nhu cáº§u cá»§a tá»«ng á»©ng dá»¥ng.
4. TÄƒng tá»‘c Ä‘á»™ cháº¡y mÃ´ hÃ¬nh báº±ng cÃ¡ch dÃ¹ng Coral Egde TPU.

Link Ä‘á»ƒ xem trÃªn YouTube: goo.gle/3dtM4dU

Náº¿u má»i ngÆ°á»i tháº¥y há»¯u Ã­ch thÃ¬ mÃ¬nh sáº½ lÃ m thÃªm báº£n tiáº¿ng Viá»‡t ná»¯a nhÃ©. Náº¿u cÃ¡c báº¡n muá»‘n cÃ³ tutorial gÃ¬ vá» Edge AI thÃ¬ comment láº¡i Ä‘á»ƒ mÃ¬nh sáº½ tiáº¿p tá»¥c lÃ m cÃ¡c video má»›i trong tÆ°Æ¡ng lai. :)",HÆ°á»›ng dáº«n Edge AI vá»›i TensorFlow Lite vÃ  Raspberry Pi ChÃ o má»i ngÆ°á»i! MÃ¬nh má»›i Ä‘Äƒng 1 video series trÃªn kÃªnh YouTube cá»§a TensorFlow vá»›i 4 video vá» object detection model trÃªn Raspberry Pi báº±ng TensorFlow Lite. Model nÃ y cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nhÆ°ng váº«n cháº¡y khÃ¡ nhanh (Ä‘áº¡t khoáº£ng 6 fps) trÃªn CPU cá»§a Raspberry Pi 4. CÃ¡c video nÃ y bao gá»“m Ä‘áº§y Ä‘á»§ cÃ¡c use case báº¡n thÆ°á»ng gáº·p khi deploy Edge AI: 1. Download model Ä‘Ã£ train sáºµn tá»« TensorFlow Hub vÃ  tÃ­ch há»£p ngay vÃ o app 2. Tá»± train model trÃªn táº­p dá»¯ liá»‡u cá»§a mÃ¬nh Ä‘á»ƒ phá»¥c vá»¥ nhá»¯ng á»©ng dá»¥ng mÃ  pretrained models khÃ´ng Ä‘Ã¡p á»©ng Ä‘Æ°á»£c. 3. Chá»n kiáº¿n trÃºc mÃ´ hÃ¬nh (model architecture) nÃ o Ä‘á»ƒ phÃ¹ há»£p vá»›i nhu cáº§u cá»§a tá»«ng á»©ng dá»¥ng. 4. TÄƒng tá»‘c Ä‘á»™ cháº¡y mÃ´ hÃ¬nh báº±ng cÃ¡ch dÃ¹ng Coral Egde TPU. Link Ä‘á»ƒ xem trÃªn YouTube: goo.gle/3dtM4dU Náº¿u má»i ngÆ°á»i tháº¥y há»¯u Ã­ch thÃ¬ mÃ¬nh sáº½ lÃ m thÃªm báº£n tiáº¿ng Viá»‡t ná»¯a nhÃ©. Náº¿u cÃ¡c báº¡n muá»‘n cÃ³ tutorial gÃ¬ vá» Edge AI thÃ¬ comment láº¡i Ä‘á»ƒ mÃ¬nh sáº½ tiáº¿p tá»¥c lÃ m cÃ¡c video má»›i trong tÆ°Æ¡ng lai. :),,,,,
"Follow-up tháº£o luáº­n cá»§a mÃ¬nh vá»›i anh Long trong post trÆ°á»›c, Ä‘á»ƒ gáº¯n káº¿t cá»™ng Ä‘á»“ng AI Viá»‡t Nam hÆ¡n, má»™t trong cÃ¡c káº¿ hoáº¡ch sáº¯p tá»›i lÃ  tá»• chá»©c má»™t web seminar thuáº§n Viá»‡t vá» cÃ¡c chá»§ Ä‘á» bÃªn khoa há»c dá»¯ liá»‡u, há»c mÃ¡y, thá»‘ng kÃª, vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o. NgÃ´n ngá»¯ cá»§a seminar sáº½ hoÃ n toÃ n lÃ  tiáº¿ng Viá»‡t (máº·c dÃ¹ slides cÃ³ thá»ƒ lÃ  tiáº¿ng Anh) Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi dá»… dÃ ng hÆ¡n. CÃ¡c speakers sáº½ ráº¥t Ä‘a dáº¡ng, tá»« cÃ¡c báº¡n Ä‘ang há»c nhá»¯ng nÄƒm cuá»‘i á»Ÿ Ä‘áº¡i há»c, cÃ¡c báº¡n Ä‘ang lÃ m ngoÃ i industry, cÃ¡c sinh viÃªn cao há»c, cÃ¡c nhÃ  nghiÃªn cá»©u á»Ÿ cÃ¡c industry lab, hay cÃ¡c giÃ¡o sÆ° Ä‘áº¡i há»c.
ThÃ´ng tin vá» má»—i seminar sáº½ Ä‘Æ°á»£c cáº­p nháº­t táº¡i cÃ¡c pages/ blogs Ä‘á»ƒ cho má»i ngÆ°á»i tiá»‡n theo dÃµi.","Follow-up tháº£o luáº­n cá»§a mÃ¬nh vá»›i anh Long trong post trÆ°á»›c, Ä‘á»ƒ gáº¯n káº¿t cá»™ng Ä‘á»“ng AI Viá»‡t Nam hÆ¡n, má»™t trong cÃ¡c káº¿ hoáº¡ch sáº¯p tá»›i lÃ  tá»• chá»©c má»™t web seminar thuáº§n Viá»‡t vá» cÃ¡c chá»§ Ä‘á» bÃªn khoa há»c dá»¯ liá»‡u, há»c mÃ¡y, thá»‘ng kÃª, vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o. NgÃ´n ngá»¯ cá»§a seminar sáº½ hoÃ n toÃ n lÃ  tiáº¿ng Viá»‡t (máº·c dÃ¹ slides cÃ³ thá»ƒ lÃ  tiáº¿ng Anh) Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi dá»… dÃ ng hÆ¡n. CÃ¡c speakers sáº½ ráº¥t Ä‘a dáº¡ng, tá»« cÃ¡c báº¡n Ä‘ang há»c nhá»¯ng nÄƒm cuá»‘i á»Ÿ Ä‘áº¡i há»c, cÃ¡c báº¡n Ä‘ang lÃ m ngoÃ i industry, cÃ¡c sinh viÃªn cao há»c, cÃ¡c nhÃ  nghiÃªn cá»©u á»Ÿ cÃ¡c industry lab, hay cÃ¡c giÃ¡o sÆ° Ä‘áº¡i há»c. ThÃ´ng tin vá» má»—i seminar sáº½ Ä‘Æ°á»£c cáº­p nháº­t táº¡i cÃ¡c pages/ blogs Ä‘á»ƒ cho má»i ngÆ°á»i tiá»‡n theo dÃµi.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
HIá»‡n táº¡i em cÃ³ lÃ m má»™t Ä‘á» tÃ i vá» nháº­n dáº¡ng hÃ nh Ä‘á»™ng dá»±a trÃªn thÃ´ng tin khung xÆ°Æ¡ng ( lÃ  táº­p 20-25 khá»›p xÆ°Æ¡ng theo thá»i gian thu Ä‘Æ°á»£c tá»« kinect). VÃ¬ trÆ°á»›c Ä‘Ã³ pháº§n model cÃ³ báº¡n lÃ m rá»“i, tuy nhiÃªn, pháº§n model Ä‘á»ƒ nháº­n dáº¡ng thÃ¬ Ä‘áº§u vÃ o lÃ  cÃ¡c Ä‘oáº¡n hÃ nh Ä‘á»™ng Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ¡ch sáºµn tá»« bá»™ CSDL, cho vÃ o model Ä‘á»ƒ suy ra nhÃ£n hoáº¡t Ä‘á»™ng,
Tuy nhiÃªn, vá»›i chuá»—i video khung xÆ°Æ¡ng thá»±c hiá»‡n liÃªn tá»¥c nhiá»u hÃ nh Ä‘á»™ng thÃ¬ cáº§n bÃ i toÃ¡n phÃ¢n Ä‘oáº¡n/phÃ¢n vÃ¹ng (segment) hÃ nh Ä‘á»™ng trÆ°á»›c áº¡, em Ä‘Ã£ thá»­ má»™t sá»‘ cÃ¡ch nhÆ° cá»­a sá»• trÆ°á»£t, hoáº·c dÃ¹ng biá»ƒu Ä‘á»“ nÄƒng lÆ°á»£ng short time energy, nhÆ°ng váº«n khÃ´ng hiá»‡u quáº£ láº¯m. Váº­y má»i ngÆ°á»i ai Ä‘Ã£ lÃ m vá» hÆ°á»›ng phÃ¢n Ä‘oáº¡n hÃ nh Ä‘á»™ng dá»±a trÃªn khung xÆ°Æ¡ng cÃ³ thá»ƒ suggest cho e 1 sá»‘ keyword, phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ cÃ³ thá»ƒ tá»± Ä‘á»™ng phÃ¢n Ä‘oáº¡n Ä‘Æ°á»£c khÃ´ng áº¡ ( phá»¥c vá»¥ cho online action recognition).
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i áº¡. HIá»‡n táº¡i em cÃ³ lÃ m má»™t Ä‘á» tÃ i vá» nháº­n dáº¡ng hÃ nh Ä‘á»™ng dá»±a trÃªn thÃ´ng tin khung xÆ°Æ¡ng ( lÃ  táº­p 20-25 khá»›p xÆ°Æ¡ng theo thá»i gian thu Ä‘Æ°á»£c tá»« kinect). VÃ¬ trÆ°á»›c Ä‘Ã³ pháº§n model cÃ³ báº¡n lÃ m rá»“i, tuy nhiÃªn, pháº§n model Ä‘á»ƒ nháº­n dáº¡ng thÃ¬ Ä‘áº§u vÃ o lÃ  cÃ¡c Ä‘oáº¡n hÃ nh Ä‘á»™ng Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ¡ch sáºµn tá»« bá»™ CSDL, cho vÃ o model Ä‘á»ƒ suy ra nhÃ£n hoáº¡t Ä‘á»™ng, Tuy nhiÃªn, vá»›i chuá»—i video khung xÆ°Æ¡ng thá»±c hiá»‡n liÃªn tá»¥c nhiá»u hÃ nh Ä‘á»™ng thÃ¬ cáº§n bÃ i toÃ¡n phÃ¢n Ä‘oáº¡n/phÃ¢n vÃ¹ng (segment) hÃ nh Ä‘á»™ng trÆ°á»›c áº¡, em Ä‘Ã£ thá»­ má»™t sá»‘ cÃ¡ch nhÆ° cá»­a sá»• trÆ°á»£t, hoáº·c dÃ¹ng biá»ƒu Ä‘á»“ nÄƒng lÆ°á»£ng short time energy, nhÆ°ng váº«n khÃ´ng hiá»‡u quáº£ láº¯m. Váº­y má»i ngÆ°á»i ai Ä‘Ã£ lÃ m vá» hÆ°á»›ng phÃ¢n Ä‘oáº¡n hÃ nh Ä‘á»™ng dá»±a trÃªn khung xÆ°Æ¡ng cÃ³ thá»ƒ suggest cho e 1 sá»‘ keyword, phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ cÃ³ thá»ƒ tá»± Ä‘á»™ng phÃ¢n Ä‘oáº¡n Ä‘Æ°á»£c khÃ´ng áº¡ ( phá»¥c vá»¥ cho online action recognition). Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
#transformer,,#transformer,,,,
"Em chÃ o má»i ngÆ°á»i. Mn cho em há»i lÃ  bÃ i phÃ¢n tÃ¡ch 2 giá»ng nÃ³i lá»“ng vÃ o nhau trong 1 báº£n ghi Ã¢m dÃ¹ng Association rule trong Unsupervised learning Ä‘Æ°á»£c khÃ´ng áº¡?
Cá»¥ thá»ƒ lÃ  cÃ¡i vÃ­ dá»¥ tá»« 5h30s cá»§a bÃ i nÃ y áº¡
https://www.youtube.com/watch?v=CCoQ49NASQ8&t=53s
Má»i ngÆ°á»i giÃºp em vá»›i. Em xin cáº£m Æ¡n nhiá»u!",Em chÃ o má»i ngÆ°á»i. Mn cho em há»i lÃ  bÃ i phÃ¢n tÃ¡ch 2 giá»ng nÃ³i lá»“ng vÃ o nhau trong 1 báº£n ghi Ã¢m dÃ¹ng Association rule trong Unsupervised learning Ä‘Æ°á»£c khÃ´ng áº¡? Cá»¥ thá»ƒ lÃ  cÃ¡i vÃ­ dá»¥ tá»« 5h30s cá»§a bÃ i nÃ y áº¡ https://www.youtube.com/watch?v=CCoQ49NASQ8&t=53s Má»i ngÆ°á»i giÃºp em vá»›i. Em xin cáº£m Æ¡n nhiá»u!,,,,,
DÃ nh cho nhá»¯ng ai quan tÃ¢m Ä‘áº¿n báº£n dá»‹ch sÃ¡ch Deep Learning áº¡.,DÃ nh cho nhá»¯ng ai quan tÃ¢m Ä‘áº¿n báº£n dá»‹ch sÃ¡ch Deep Learning áº¡.,,,,,
"Em xin chÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ  sinh viÃªn nÄƒm 3 ngÃ nh Äiá»‡n tá»­ Viá»…n thÃ´ng. Em cÃ³ Ä‘á»‹nh hÆ°á»›ng theo ngÃ nh Data Science sau khi ra trÆ°á»ng. KhÃ´ng biáº¿t trong group cá»§a mÃ¬nh cÃ³ anh chá»‹ nÃ o cÅ©ng background Äiá»‡n tá»­ Viá»…n thÃ´ng mÃ  Ä‘i lÃ m vá» Data Science khÃ´ng áº¡, em ráº¥t mong Ä‘Æ°á»£c tham kháº£o lá»™ trÃ¬nh tá»± há»c cá»§a cÃ¡c anh chá»‹ áº¡.
NgoÃ i ra, cÃ¡c anh chá»‹ cÃ³ thá»ƒ cho em xin gá»£i Ã½ vá» cÃ¡c Ä‘á» tÃ i cÃ³ á»©ng dá»¥ng Data Science mÃ  em cÃ³ thá»ƒ chá»n Ä‘á»ƒ lÃ m cho Äá»“ Ã¡n cÅ©ng nhÆ° Luáº­n vÄƒn tá»‘t nghiá»‡p ngÃ nh Äiá»‡n tá»­ Viá»…n thÃ´ng khÃ´ng áº¡?
Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.","Em xin chÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ  sinh viÃªn nÄƒm 3 ngÃ nh Äiá»‡n tá»­ Viá»…n thÃ´ng. Em cÃ³ Ä‘á»‹nh hÆ°á»›ng theo ngÃ nh Data Science sau khi ra trÆ°á»ng. KhÃ´ng biáº¿t trong group cá»§a mÃ¬nh cÃ³ anh chá»‹ nÃ o cÅ©ng background Äiá»‡n tá»­ Viá»…n thÃ´ng mÃ  Ä‘i lÃ m vá» Data Science khÃ´ng áº¡, em ráº¥t mong Ä‘Æ°á»£c tham kháº£o lá»™ trÃ¬nh tá»± há»c cá»§a cÃ¡c anh chá»‹ áº¡. NgoÃ i ra, cÃ¡c anh chá»‹ cÃ³ thá»ƒ cho em xin gá»£i Ã½ vá» cÃ¡c Ä‘á» tÃ i cÃ³ á»©ng dá»¥ng Data Science mÃ  em cÃ³ thá»ƒ chá»n Ä‘á»ƒ lÃ m cho Äá»“ Ã¡n cÅ©ng nhÆ° Luáº­n vÄƒn tá»‘t nghiá»‡p ngÃ nh Äiá»‡n tá»­ Viá»…n thÃ´ng khÃ´ng áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.",,,,,
Má»i cÃ¡c báº¡n tham kháº£o. Admin cá»§a trang nÃ y ráº¥t xá»‹n nhÃ©.,Má»i cÃ¡c báº¡n tham kháº£o. Admin cá»§a trang nÃ y ráº¥t xá»‹n nhÃ©.,,,,,
"ÄÃ£ bao giá» báº¡n tá»± há»i AI lÃ  gÃ¬ vÃ  táº¡i sao láº¡i bÃ¹ng ná»• trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y? AI mang láº¡i giÃ¡ trá»‹ nhÆ° tháº¿ nÃ o cho doanh nghiá»‡p? Machine Learning vÃ  Deep Learning lÃ  gÃ¬? ...
Äá»ƒ tráº£ lá»i cho nhá»¯ng cÃ¢u há»i nÃ y, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o bÃ i tá»•ng há»£p ráº¥t hay cá»§a McKinsey dÆ°á»›i Ä‘Ã¢y.","ÄÃ£ bao giá» báº¡n tá»± há»i AI lÃ  gÃ¬ vÃ  táº¡i sao láº¡i bÃ¹ng ná»• trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y? AI mang láº¡i giÃ¡ trá»‹ nhÆ° tháº¿ nÃ o cho doanh nghiá»‡p? Machine Learning vÃ  Deep Learning lÃ  gÃ¬? ... Äá»ƒ tráº£ lá»i cho nhá»¯ng cÃ¢u há»i nÃ y, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o bÃ i tá»•ng há»£p ráº¥t hay cá»§a McKinsey dÆ°á»›i Ä‘Ã¢y.",,,,,
"Má»i ngÆ°á»i cho em há»i, náº¿u má»™t thuáº­t toÃ¡n machine learning mÃ  cho ra káº¿t quáº£ cÃ³ ma tráº­n confusion vá»›i % cao tháº¿ nÃ y thÃ¬ mÃ´ hÃ¬nh Ä‘Ã³ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ train tá»‘t ko áº¡.? hay lÃ  rÆ¡i vÃ  trÆ°á»ng há»£p overfit áº¡. E xin cáº£m Æ¡n.","Má»i ngÆ°á»i cho em há»i, náº¿u má»™t thuáº­t toÃ¡n machine learning mÃ  cho ra káº¿t quáº£ cÃ³ ma tráº­n confusion vá»›i % cao tháº¿ nÃ y thÃ¬ mÃ´ hÃ¬nh Ä‘Ã³ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ train tá»‘t ko áº¡.? hay lÃ  rÆ¡i vÃ  trÆ°á»ng há»£p overfit áº¡. E xin cáº£m Æ¡n.",,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u vá» cÃ¡c gÃ³i cÆ°á»›c viá»…n thÃ´ng (data, thoáº¡i, sms, hoáº·c há»—n há»£p) vÃ  doanh thu, sá»‘ lÆ°á»£ng bÃ¡n Ä‘Æ°á»£c cá»§a tá»«ng loáº¡i gÃ³i cÆ°á»›c táº¡i cÃ¡c vÃ¹ng trong cáº£ nÆ°á»›c (tá»‰nh/TP, quáº­n/huyá»‡n, miá»n). Má»—i gÃ³i cÆ°á»›c thÆ°á»ng Ä‘Æ°á»£c triÃªn khai trong má»™t khoáº£ng thá»i gian nÃ o Ä‘Ã³ (vÃ­ dá»¥: gÃ³i cÆ°á»›c A triá»ƒn khai tá»« 1/2021 - 6/2021,...).
Hiá»‡n mÃ¬nh muá»‘n sá»­ dá»¥ng táº­p dá»¯ liá»‡u nÃ y Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n lÃ  khi cÃ´ng ty Ä‘Æ°a ra má»™t gÃ³i cÆ°á»›c thÃ¬ nÃªn táº­p trung triá»ƒn khai á»Ÿ thá»‹ trÆ°á»ng (tá»‰nh/huyá»‡n/vÃ¹ng) nÃ o lÃ  phÃ¹ há»£p nháº¥t dá»±a vÃ o cÃ¡c sá»‘ liá»‡u cá»§a cÃ¡c gÃ³i cÆ°á»›c Ä‘Ã£ triá»ƒn khai trÆ°á»›c Ä‘Ã³. MÃ¬nh nghÄ© Ä‘Ã¢y lÃ  bÃ i toÃ¡n há»“i quy nhÆ°ng mÃ¬nh chÆ°a cÃ³ kinh nghiá»‡m Ä‘á»‘i vá»›i bÃ i toÃ¡n nÃ y nÃªn chÆ°a biáº¿t nÃªn sá»­ dá»¥ng giáº£i thuáº­t nÃ o cho phÃ¹ há»£p hoáº·c tá»« khÃ³a Ä‘á»ƒ tÃ¬m tÃ i liá»‡u tham kháº£o. VÃ¬ váº­y mÃ¬nh post lÃªn Ä‘Ã¢y Ä‘á»ƒ nhá» cÃ¡c báº¡n, cÃ¡c anh chá»‹ cho lá»i khuyÃªn giÃºp vá» giáº£i thuáº­t thÃ­ch há»£p cho bÃ i toÃ¡n nÃ y hoáº·c tá»« khÃ³a Ä‘á»ƒ tÃ¬m kiáº¿m thÃªm.
Xin cáº£m Æ¡n. :)","ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u vá» cÃ¡c gÃ³i cÆ°á»›c viá»…n thÃ´ng (data, thoáº¡i, sms, hoáº·c há»—n há»£p) vÃ  doanh thu, sá»‘ lÆ°á»£ng bÃ¡n Ä‘Æ°á»£c cá»§a tá»«ng loáº¡i gÃ³i cÆ°á»›c táº¡i cÃ¡c vÃ¹ng trong cáº£ nÆ°á»›c (tá»‰nh/TP, quáº­n/huyá»‡n, miá»n). Má»—i gÃ³i cÆ°á»›c thÆ°á»ng Ä‘Æ°á»£c triÃªn khai trong má»™t khoáº£ng thá»i gian nÃ o Ä‘Ã³ (vÃ­ dá»¥: gÃ³i cÆ°á»›c A triá»ƒn khai tá»« 1/2021 - 6/2021,...). Hiá»‡n mÃ¬nh muá»‘n sá»­ dá»¥ng táº­p dá»¯ liá»‡u nÃ y Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n lÃ  khi cÃ´ng ty Ä‘Æ°a ra má»™t gÃ³i cÆ°á»›c thÃ¬ nÃªn táº­p trung triá»ƒn khai á»Ÿ thá»‹ trÆ°á»ng (tá»‰nh/huyá»‡n/vÃ¹ng) nÃ o lÃ  phÃ¹ há»£p nháº¥t dá»±a vÃ o cÃ¡c sá»‘ liá»‡u cá»§a cÃ¡c gÃ³i cÆ°á»›c Ä‘Ã£ triá»ƒn khai trÆ°á»›c Ä‘Ã³. MÃ¬nh nghÄ© Ä‘Ã¢y lÃ  bÃ i toÃ¡n há»“i quy nhÆ°ng mÃ¬nh chÆ°a cÃ³ kinh nghiá»‡m Ä‘á»‘i vá»›i bÃ i toÃ¡n nÃ y nÃªn chÆ°a biáº¿t nÃªn sá»­ dá»¥ng giáº£i thuáº­t nÃ o cho phÃ¹ há»£p hoáº·c tá»« khÃ³a Ä‘á»ƒ tÃ¬m tÃ i liá»‡u tham kháº£o. VÃ¬ váº­y mÃ¬nh post lÃªn Ä‘Ã¢y Ä‘á»ƒ nhá» cÃ¡c báº¡n, cÃ¡c anh chá»‹ cho lá»i khuyÃªn giÃºp vá» giáº£i thuáº­t thÃ­ch há»£p cho bÃ i toÃ¡n nÃ y hoáº·c tá»« khÃ³a Ä‘á»ƒ tÃ¬m kiáº¿m thÃªm. Xin cáº£m Æ¡n. :)",,,,,
"Xin chÃ o má»i ngÆ°á»i ^^ HÃ´m nay mÃ¬nh ráº¥t pháº¥n khÃ­ch khi giá»›i thiá»‡u vá»›i nhá»¯ng anh em bÃ i bÃ¡o Nature Scientific Report (h5-index 200 rank #26 citation in Google Scholar) cá»§a mÃ¬nh vá»›i tá»±a Ä‘á» ""Self-controlling Photonic-on-Chip Networks With Deep Reinforcement Learning "" thuá»™c nhÃ¡nh con cá»§a Nature family, má»™t hÃ£ng cÃ´ng bá»‘ bÃ¡o lá»›n nháº¥t trÃªn tháº¿ giá»›i vá» khoa há»c. BÃ i bÃ¡o táº­p trung viá»‡c tÃ¬m ra cáº¥u trÃºc máº¡ng quang tá»­ má»›i vÃ  tá»‘i Æ°u cÃ¡c yáº¿u tá»‘ váº­t lÃ½ sao cho transmission loss, power consumption, routing time giá»¯a cÃ¡c ná»‘t quang lÃ  nhá» nháº¥t báº±ng viá»‡c sá»­ dá»¥ng giáº£i thuáº­t Reinforcement Learning má»›i do nhÃ³m Ä‘á» xuáº¥t Ä‘Ã³ lÃ  Multi Sample Discovery. Hi vá»ng anh em nÃ o cÃ³ thá»i gian cÃ³ thá»ƒ tÃ¬m hiá»ƒu =))
BÃ i bÃ¡o Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi quá»¹ #VinIF vÃ  thuá»™c nhÃ³m nghiÃªn cá»©u cá»§a PTIT, VinAi Research, StonyBrook University USA.
Link here : https://www.nature.com/articles/s41598-021-02583-7?fbclid=IwAR3ZFoDelt9-lQhuaL-a4grt-cMfMcSYV72_ZVwdPTFK_LOrz1whASNZAtM","Xin chÃ o má»i ngÆ°á»i ^^ HÃ´m nay mÃ¬nh ráº¥t pháº¥n khÃ­ch khi giá»›i thiá»‡u vá»›i nhá»¯ng anh em bÃ i bÃ¡o Nature Scientific Report (h5-index 200 rank citation in Google Scholar) cá»§a mÃ¬nh vá»›i tá»±a Ä‘á» ""Self-controlling Photonic-on-Chip Networks With Deep Reinforcement Learning "" thuá»™c nhÃ¡nh con cá»§a Nature family, má»™t hÃ£ng cÃ´ng bá»‘ bÃ¡o lá»›n nháº¥t trÃªn tháº¿ giá»›i vá» khoa há»c. BÃ i bÃ¡o táº­p trung viá»‡c tÃ¬m ra cáº¥u trÃºc máº¡ng quang tá»­ má»›i vÃ  tá»‘i Æ°u cÃ¡c yáº¿u tá»‘ váº­t lÃ½ sao cho transmission loss, power consumption, routing time giá»¯a cÃ¡c ná»‘t quang lÃ  nhá» nháº¥t báº±ng viá»‡c sá»­ dá»¥ng giáº£i thuáº­t Reinforcement Learning má»›i do nhÃ³m Ä‘á» xuáº¥t Ä‘Ã³ lÃ  Multi Sample Discovery. Hi vá»ng anh em nÃ o cÃ³ thá»i gian cÃ³ thá»ƒ tÃ¬m hiá»ƒu =)) BÃ i bÃ¡o Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi quá»¹ vÃ  thuá»™c nhÃ³m nghiÃªn cá»©u cá»§a PTIT, VinAi Research, StonyBrook University USA. Link here : https://www.nature.com/articles/s41598-021-02583-7?fbclid=IwAR3ZFoDelt9-lQhuaL-a4grt-cMfMcSYV72_ZVwdPTFK_LOrz1whASNZAtM",#26	#VinIF,,,,
"Xin chÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cho mÃ¬nh muá»‘n xin review vá» 2 cuá»‘n nÃ y, mÃ¬nh tháº¯c máº¯c lÃ  nÃªn Ä‘á»c cuá»‘n nÃ o (do 2 cuá»‘n khÃ¡ dÃ i nÃªn mÃ¬nh tÃ­nh Ä‘á»c má»™t trong hai). MÃ¬nh lÃ m chá»§ yáº¿u bÃªn Deep Learning nÃªn nhu cáº§u mÃ¬nh thiÃªn vá» hÆ°á»›ng Ä‘á»c Ä‘á»ƒ hiá»ƒu hÆ¡n vá» toÃ¡n vÃ  cÃ¡c thuáº­t toÃ¡n ML trÆ°á»›c Ä‘Ã¢y hÆ¡n.
Náº¿u Ä‘Æ°á»£c mong má»i ngÆ°á»i giá»›i thiá»‡u mÃ¬nh má»™t sá»‘ sÃ¡ch vá» Statistic nÃ³i vá» toÃ¡n nhiá»u vÃ  cÃ´ng thá»©c Ä‘á»c dá»… hiá»ƒu má»™t xÃ­u (MÃ¬nh cÃ³ Ä‘á»c All of Statistics A Concise Course in Statistical Inference, nhÆ°ng tá»›i táº§m chÆ°Æ¡ng 16 lÃ  mÃ¬nh Ä‘á»c báº¯t Ä‘áº§u tháº¥y mÆ¡ há»“).
MÃ¬nh xin cÃ¡m Æ¡n má»i ngÆ°á»i.","Xin chÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cho mÃ¬nh muá»‘n xin review vá» 2 cuá»‘n nÃ y, mÃ¬nh tháº¯c máº¯c lÃ  nÃªn Ä‘á»c cuá»‘n nÃ o (do 2 cuá»‘n khÃ¡ dÃ i nÃªn mÃ¬nh tÃ­nh Ä‘á»c má»™t trong hai). MÃ¬nh lÃ m chá»§ yáº¿u bÃªn Deep Learning nÃªn nhu cáº§u mÃ¬nh thiÃªn vá» hÆ°á»›ng Ä‘á»c Ä‘á»ƒ hiá»ƒu hÆ¡n vá» toÃ¡n vÃ  cÃ¡c thuáº­t toÃ¡n ML trÆ°á»›c Ä‘Ã¢y hÆ¡n. Náº¿u Ä‘Æ°á»£c mong má»i ngÆ°á»i giá»›i thiá»‡u mÃ¬nh má»™t sá»‘ sÃ¡ch vá» Statistic nÃ³i vá» toÃ¡n nhiá»u vÃ  cÃ´ng thá»©c Ä‘á»c dá»… hiá»ƒu má»™t xÃ­u (MÃ¬nh cÃ³ Ä‘á»c All of Statistics A Concise Course in Statistical Inference, nhÆ°ng tá»›i táº§m chÆ°Æ¡ng 16 lÃ  mÃ¬nh Ä‘á»c báº¯t Ä‘áº§u tháº¥y mÆ¡ há»“). MÃ¬nh xin cÃ¡m Æ¡n má»i ngÆ°á»i.",,,,,
"Má»™t trong nhá»¯ng á»©ng dá»¥ng hay vÃ  thÃº vá»‹ nháº¥t trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y lÃ  Neural Style Transfer.
Nhá» cÃ³ á»©ng dá»¥ng nÃ y, chÃºng ta cÃ³ thá»ƒ mÃ´ phá»ng phong cÃ¡ch nghá»‡ thuáº­t cá»§a nhá»¯ng hoáº¡ sÄ© huyá»n thoáº¡i nhÆ° Picasso, Van Gogh hay cá»§a báº¥t ká»³ má»™t hoáº¡ sÄ© nÃ o khÃ¡c.
Trong bÃ i hÃ´m nay, hÃ£y cÅ©ng tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c vá» Neural Style Transfer vÃ  cÃ¡ch Ã¡p dá»¥ng nÃ³ Ä‘á»ƒ há»“i sinh nhá»¯ng phong cÃ¡ch há»™i hoáº¡ ná»•i tiáº¿ng trÃªn tháº¿ giá»›i.","Má»™t trong nhá»¯ng á»©ng dá»¥ng hay vÃ  thÃº vá»‹ nháº¥t trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y lÃ  Neural Style Transfer. Nhá» cÃ³ á»©ng dá»¥ng nÃ y, chÃºng ta cÃ³ thá»ƒ mÃ´ phá»ng phong cÃ¡ch nghá»‡ thuáº­t cá»§a nhá»¯ng hoáº¡ sÄ© huyá»n thoáº¡i nhÆ° Picasso, Van Gogh hay cá»§a báº¥t ká»³ má»™t hoáº¡ sÄ© nÃ o khÃ¡c. Trong bÃ i hÃ´m nay, hÃ£y cÅ©ng tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c vá» Neural Style Transfer vÃ  cÃ¡ch Ã¡p dá»¥ng nÃ³ Ä‘á»ƒ há»“i sinh nhá»¯ng phong cÃ¡ch há»™i hoáº¡ ná»•i tiáº¿ng trÃªn tháº¿ giá»›i.",,,,,
"Xin chÃ o má»i ngÆ°á»i,
Em Ä‘ang tÃ¬m hiá»ƒu vá» Non-Subsampled Shearlet Transform.
Em Ä‘á»c cÃ´ng thá»©c nÃ y mÃ  khÃ´ng hiá»ƒu cÃ¡ch tinh toÃ¡n ma tráº­n sau Ä‘á»ƒ láº¥y Ä‘Æ°á»£c output ğŸ™
CÃ¡c anh trong nhÃ³m Ä‘Ã£ lÃ m pháº§n nÃ y cho em há»i cÃ¡ch tÃ­nh toÃ¡n trÃªn ma tráº­n Ä‘á»ƒ láº¥y Ä‘Æ°á»£c output hoáº·c cho em xin tÃ i liá»‡u pháº§n nÃ y tiáº¿ng Viá»‡t áº¡.
Em xin cáº£m Æ¡n má»i ngÆ°á»i","Xin chÃ o má»i ngÆ°á»i, Em Ä‘ang tÃ¬m hiá»ƒu vá» Non-Subsampled Shearlet Transform. Em Ä‘á»c cÃ´ng thá»©c nÃ y mÃ  khÃ´ng hiá»ƒu cÃ¡ch tinh toÃ¡n ma tráº­n sau Ä‘á»ƒ láº¥y Ä‘Æ°á»£c output CÃ¡c anh trong nhÃ³m Ä‘Ã£ lÃ m pháº§n nÃ y cho em há»i cÃ¡ch tÃ­nh toÃ¡n trÃªn ma tráº­n Ä‘á»ƒ láº¥y Ä‘Æ°á»£c output hoáº·c cho em xin tÃ i liá»‡u pháº§n nÃ y tiáº¿ng Viá»‡t áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Tháº¥y nhiá»u báº¡n tráº» hay khÃ³c khi há»i, mÃ¬nh má»›i thÃªm ná»™i quy nÃ y.","Tháº¥y nhiá»u báº¡n tráº» hay khÃ³c khi há»i, mÃ¬nh má»›i thÃªm ná»™i quy nÃ y.",,,,,
"Xin chÃ o má»i ngÆ°á»i.
Em Ä‘ang thá»±c hiá»‡n bÃ i toÃ¡n há»“i quy vá»›i máº¡ng 2 lá»›p áº©n. Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh thÃ¬ muá»‘n Ä‘Ã¡nh giÃ¡ táº§m quan trá»ng cá»§a cÃ¡c biáº¿n Ä‘áº§u vÃ o báº±ng thuáº­t toÃ¡n garson vÃ  thuáº­t toÃ¡n trá»ng sá»‘ káº¿t ná»‘i(CW). Em Ä‘á»c má»™t sá»‘ tÃ i liá»‡u hÆ°á»›ng dáº«n thÃ¬ tháº¥y 2 thuáº­t toÃ¡n nÃ y hÆ°á»›ng dáº«n cho máº¡ng cÃ³ má»™t lá»›p áº©n. nÃªn khÃ´ng biáº¿t vá»›i sá»‘ lá»›p áº©n lá»›n hÆ¡n 2 thÃ¬ 2 thuáº­t toÃ¡n nÃ y cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c khÃ´ng?. Náº¿u Ä‘Æ°á»£c nhá» má»i ngÆ°á»i chá»‰ dáº«n giÃºp em vá»›i. em má»›i há»c vá» vá» Machine Learning chÆ°a biáº¿t nhiá»u mong má»i ngÆ°á»i giÃºp Ä‘á»¡ nhiá»u.",Xin chÃ o má»i ngÆ°á»i. Em Ä‘ang thá»±c hiá»‡n bÃ i toÃ¡n há»“i quy vá»›i máº¡ng 2 lá»›p áº©n. Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh thÃ¬ muá»‘n Ä‘Ã¡nh giÃ¡ táº§m quan trá»ng cá»§a cÃ¡c biáº¿n Ä‘áº§u vÃ o báº±ng thuáº­t toÃ¡n garson vÃ  thuáº­t toÃ¡n trá»ng sá»‘ káº¿t ná»‘i(CW). Em Ä‘á»c má»™t sá»‘ tÃ i liá»‡u hÆ°á»›ng dáº«n thÃ¬ tháº¥y 2 thuáº­t toÃ¡n nÃ y hÆ°á»›ng dáº«n cho máº¡ng cÃ³ má»™t lá»›p áº©n. nÃªn khÃ´ng biáº¿t vá»›i sá»‘ lá»›p áº©n lá»›n hÆ¡n 2 thÃ¬ 2 thuáº­t toÃ¡n nÃ y cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c khÃ´ng?. Náº¿u Ä‘Æ°á»£c nhá» má»i ngÆ°á»i chá»‰ dáº«n giÃºp em vá»›i. em má»›i há»c vá» vá» Machine Learning chÆ°a biáº¿t nhiá»u mong má»i ngÆ°á»i giÃºp Ä‘á»¡ nhiá»u.,,,,,
"Cho mÃ¬nh há»i báº¡n nÃ o biáº¿t trong Tensorrt thÃ¬ cÃ³ ba Ä‘á»‹nh dáº¡ng file lÃ  : .trt , .engine vÃ  .plan. Váº­y chÃºng khÃ¡c nhau tháº¿ nÃ o? ai biáº¿t chá»‰ giÃ¹m nhÃ©. Cáº£m Æ¡n nhiá»u","Cho mÃ¬nh há»i báº¡n nÃ o biáº¿t trong Tensorrt thÃ¬ cÃ³ ba Ä‘á»‹nh dáº¡ng file lÃ  : .trt , .engine vÃ  .plan. Váº­y chÃºng khÃ¡c nhau tháº¿ nÃ o? ai biáº¿t chá»‰ giÃ¹m nhÃ©. Cáº£m Æ¡n nhiá»u",,,,,
"hello ae
mÃ¬nh tÃ¬m tháº¥y cheatsheet tá»•ng há»£p vá» AI, NN, ML, DL vÃ  Big Data khÃ¡ hay vÃ  xá»‹n xÃ² nÃªn share cho mn cÃ¹ng tÃ¬m hiá»ƒu ğŸ˜
nguá»“n: LearnDataScience","hello ae mÃ¬nh tÃ¬m tháº¥y cheatsheet tá»•ng há»£p vá» AI, NN, ML, DL vÃ  Big Data khÃ¡ hay vÃ  xá»‹n xÃ² nÃªn share cho mn cÃ¹ng tÃ¬m hiá»ƒu nguá»“n: LearnDataScience",,,,,
"CÃ³ ai Ä‘Ã£ tá»«ng gáº·p lá»—i nÃ y khi dÃ¹ng shap Ä‘á»ƒ phÃ¢n tÃ­ch feature chÆ°a áº¡, search mÃ£i k ra :(","CÃ³ ai Ä‘Ã£ tá»«ng gáº·p lá»—i nÃ y khi dÃ¹ng shap Ä‘á»ƒ phÃ¢n tÃ­ch feature chÆ°a áº¡, search mÃ£i k ra :(",,,,,
"#aivivn #timeseries

AIviVN xin trÃ¢n trá»ng thÃ´ng bÃ¡o cuá»™c thi thá»© tÆ°. Má»™t cuá»™c thi vá» time series vÃ  cÃ³ tá»•ng giáº£i thÆ°á»Ÿng lÃ  15 triá»‡u Ä‘á»“ng.

Cáº£m Æ¡n má»™t cÃ´ng ty giáº¥u tÃªn Ä‘Ã£ cung cáº¥p dá»¯ liá»‡u vÃ  giáº£i thÆ°á»Ÿng cho cuá»™c thi :).
https://www.aivivn.com/contests/4",AIviVN xin trÃ¢n trá»ng thÃ´ng bÃ¡o cuá»™c thi thá»© tÆ°. Má»™t cuá»™c thi vá» time series vÃ  cÃ³ tá»•ng giáº£i thÆ°á»Ÿng lÃ  15 triá»‡u Ä‘á»“ng. Cáº£m Æ¡n má»™t cÃ´ng ty giáº¥u tÃªn Ä‘Ã£ cung cáº¥p dá»¯ liá»‡u vÃ  giáº£i thÆ°á»Ÿng cho cuá»™c thi :). https://www.aivivn.com/contests/4,#aivivn	#timeseries,,,,
"ğŸ”»[ğ‘ğğ ğ¢ğ¬ğ­ğ«ğšğ­ğ¢ğ¨ğ§ ğğ©ğğ§] ğƒğ€ğ“ğ€-ğ‚ğ„ğğ“ğ‘ğˆğ‚ ğ†ğ ğğ€ğ‚ğŠ ğ“ğ ğğ€ğ’ğˆğ‚ğ’ â€¼ï¸
TECH INNOVATORS #5: Gáº¶P Gá»  Bá»˜ Ã“C THIÃŠN TÃ€I DEEP LEARNING- ANDREW NG
Andrew Ng - NgÆ°á»i Ä‘Æ°á»£c xem lÃ  thiÃªn tÃ i Deep Learning, má»™t trong ngÆ°á»i Ä‘i Ä‘áº§u trong lÄ©nh vá»±c TrÃ­ tuá»‡ nhÃ¢n táº¡o. Ã”ng lÃ  Co-founder cá»§a Google Brains & Coursera vÃ  sÃ¡ng láº­p cá»§a Landing Ai.
NgoÃ i ra, sá»± kiá»‡n cÃ³ sá»± hiá»‡n diá»‡n cá»§a:
- Tháº¡c sÄ© Khoa há»c mÃ¡y tÃ­nh Huyen Chip - Giáº£ng viÃªn kiÃªm nhiá»‡m táº¡i Äáº¡i há»c Stanford, Hoa Ká»³ & Top 5 trong danh sÃ¡ch Top Voices vá» lÄ©nh vá»±c Khoa há»c Dá»¯ liá»‡u vÃ  TrÃ­ ThÃ´ng minh NhÃ¢n táº¡o do LinkedIn bÃ¬nh chá»n nÄƒm 2020
-  Ms. Lynn He - ChuyÃªn gia AI quá»‘c táº¿ táº¡i Deeplearning.AI & Cá»±u Applied Machine Learning Intensive táº¡i Google, Hoa Ká»³
ğŸ“Œ Báº¡n sáº½ nháº­n Ä‘Æ°á»£c gÃ¬ khi tham gia Tech Innovators #5
- Andrew Ng, Huyen Chip vÃ  Lynn He tháº£o luáº­n vá» nhá»¯ng bÃ i toÃ¡n Data, cÃ¡ch tiáº¿p cáº­n Data-centric, Data Automation trong cÃ¢u chuyá»‡n cÃ´ng nghá»‡.
Táº¡i sao chÃºng ta nÃªn trá»Ÿ láº¡i vá»›i ná»n táº£ng Data cá»‘t lÃµi? Liá»‡u báº¡n Ä‘ang chá»‰ quan tÃ¢m Ä‘áº¿n viá»‡c phÃ¡c tháº£o mÃ´ hÃ¬nh AI & Machine Learning mÃ  quÃªn Ä‘i nhá»¯ng yáº¿u tá»‘ cá»‘t lÃµi táº¡o ra má»™t ""kiáº¿n trÃºc kiÃªn cá»‘""? 
Data-centric lÃ  hÆ°á»›ng tiáº¿p cáº­n táº­p trung má»™t kiáº¿n trÃºc nÆ¡i dá»¯ liá»‡u lÃ  tÃ i sáº£n cá»‘t lÃµi vÃ  lÃ¢u dÃ i. Vá»›i Data-centric model, mÃ´ hÃ¬nh dá»¯ liá»‡u lÃ  ná»n mÃ³ng Ä‘áº§u tiÃªn trong viá»‡c triá»ƒn khai báº¥t ká»³ á»©ng dá»¥ng hay AI model nÃ o vÃ  sáº½ yáº¿u tá»‘ tá»“n táº¡i vÃ  cÃ³ giÃ¡ trá»‹ lÃ¢u dÃ i.
âœï¸ ÄÄƒng kÃ½ tham dá»± vÃ  Ä‘áº·t cÃ¢u há»i cho khÃ¡ch má»i táº¡i link: https://bit.ly/Register_TechInnovators5
ÄÄƒng kÃ½ vÃ  Ä‘áº·t cÃ¢u há»i ngay , Ä‘á»ƒ cÃ³ cÆ¡ há»™i trá»Ÿ thÃ nh ngÆ°á»i trá»±c tiáº¿p trÃ² chuyá»‡n cÃ¹ng nhá»¯ng bá»™ Ã³c thiÃªn tÃ i ngÃ nh Ai.","[ ] - â€¼ TECH INNOVATORS Gáº¶P Gá»  Bá»˜ Ã“C THIÃŠN TÃ€I DEEP LEARNING- ANDREW NG Andrew Ng - NgÆ°á»i Ä‘Æ°á»£c xem lÃ  thiÃªn tÃ i Deep Learning, má»™t trong ngÆ°á»i Ä‘i Ä‘áº§u trong lÄ©nh vá»±c TrÃ­ tuá»‡ nhÃ¢n táº¡o. Ã”ng lÃ  Co-founder cá»§a Google Brains & Coursera vÃ  sÃ¡ng láº­p cá»§a Landing Ai. NgoÃ i ra, sá»± kiá»‡n cÃ³ sá»± hiá»‡n diá»‡n cá»§a: - Tháº¡c sÄ© Khoa há»c mÃ¡y tÃ­nh Huyen Chip - Giáº£ng viÃªn kiÃªm nhiá»‡m táº¡i Äáº¡i há»c Stanford, Hoa Ká»³ & Top 5 trong danh sÃ¡ch Top Voices vá» lÄ©nh vá»±c Khoa há»c Dá»¯ liá»‡u vÃ  TrÃ­ ThÃ´ng minh NhÃ¢n táº¡o do LinkedIn bÃ¬nh chá»n nÄƒm 2020 - Ms. Lynn He - ChuyÃªn gia AI quá»‘c táº¿ táº¡i Deeplearning.AI & Cá»±u Applied Machine Learning Intensive táº¡i Google, Hoa Ká»³ Báº¡n sáº½ nháº­n Ä‘Æ°á»£c gÃ¬ khi tham gia Tech Innovators - Andrew Ng, Huyen Chip vÃ  Lynn He tháº£o luáº­n vá» nhá»¯ng bÃ i toÃ¡n Data, cÃ¡ch tiáº¿p cáº­n Data-centric, Data Automation trong cÃ¢u chuyá»‡n cÃ´ng nghá»‡. Táº¡i sao chÃºng ta nÃªn trá»Ÿ láº¡i vá»›i ná»n táº£ng Data cá»‘t lÃµi? Liá»‡u báº¡n Ä‘ang chá»‰ quan tÃ¢m Ä‘áº¿n viá»‡c phÃ¡c tháº£o mÃ´ hÃ¬nh AI & Machine Learning mÃ  quÃªn Ä‘i nhá»¯ng yáº¿u tá»‘ cá»‘t lÃµi táº¡o ra má»™t ""kiáº¿n trÃºc kiÃªn cá»‘""? Data-centric lÃ  hÆ°á»›ng tiáº¿p cáº­n táº­p trung má»™t kiáº¿n trÃºc nÆ¡i dá»¯ liá»‡u lÃ  tÃ i sáº£n cá»‘t lÃµi vÃ  lÃ¢u dÃ i. Vá»›i Data-centric model, mÃ´ hÃ¬nh dá»¯ liá»‡u lÃ  ná»n mÃ³ng Ä‘áº§u tiÃªn trong viá»‡c triá»ƒn khai báº¥t ká»³ á»©ng dá»¥ng hay AI model nÃ o vÃ  sáº½ yáº¿u tá»‘ tá»“n táº¡i vÃ  cÃ³ giÃ¡ trá»‹ lÃ¢u dÃ i. ÄÄƒng kÃ½ tham dá»± vÃ  Ä‘áº·t cÃ¢u há»i cho khÃ¡ch má»i táº¡i link: https://bit.ly/Register_TechInnovators5 ÄÄƒng kÃ½ vÃ  Ä‘áº·t cÃ¢u há»i ngay , Ä‘á»ƒ cÃ³ cÆ¡ há»™i trá»Ÿ thÃ nh ngÆ°á»i trá»±c tiáº¿p trÃ² chuyá»‡n cÃ¹ng nhá»¯ng bá»™ Ã³c thiÃªn tÃ i ngÃ nh Ai.",#5:	#5,,,,
"Em xin chÃ o má»i ngÆ°á»i, em Ä‘ang cháº¡y SVM Multiclass Classification cho má»™t bá»™ data vá» cáº£m biáº¿n khÃ­. Em muá»‘n váº½ cÃ¡c Ä‘Æ°á»ng support vector sau khi cháº¡y ra káº¿t quáº£. Cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ váº½ khÃ´ng váº­y áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i.
Nguá»“n áº£nh : https://github.com/cran/gensvm","Em xin chÃ o má»i ngÆ°á»i, em Ä‘ang cháº¡y SVM Multiclass Classification cho má»™t bá»™ data vá» cáº£m biáº¿n khÃ­. Em muá»‘n váº½ cÃ¡c Ä‘Æ°á»ng support vector sau khi cháº¡y ra káº¿t quáº£. Cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ váº½ khÃ´ng váº­y áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i. Nguá»“n áº£nh : https://github.com/cran/gensvm",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 11/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.",,,,,
"Em xin chÃ o má»i ngÆ°á»i, em hiá»‡n chá»‰ má»›i Ä‘ang táº­p tÃ nh vá» Machine Learning. Em cÃ³ má»™t cÃ¢u há»i liÃªn quan Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u cho 1 project ML lÃ :
Táº¡i sao khi xÃ¢y dá»±ng má»™t dá»± Ã¡n Machine Learning chÃºng ta láº¡i cáº§n pháº£i cÃ³ má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u, cÃ³ pháº£i mÃ¡y sáº½ há»c báº±ng cÃ¡ch nhÃ¬n vÃ o táº­p cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ rÃºt ra Ä‘Æ°á»£c kinh nghiá»‡m vÃ  tá»« Ä‘Ã³ training Ä‘Æ°á»£c model khÃ´ng áº¡?
Náº¿u cÆ¡ sá»Ÿ dá»¯ liá»‡u chÃºng ta sá»­ dá»¥ng lÃ  cÃ¡c áº£nh thang xÃ¡m nhÆ°ng Ä‘áº§u vÃ o chÃºng ta Ä‘Æ°a vÃ´ há»‡ thá»‘ng ML lÃ  áº£nh mÃ u (cÃ³ Ä‘á»™ sÃ¡ng tá»‘i khÃ¡c vá»›i CSDL) thÃ¬ chÃºng ta cáº§n pháº£i kháº¯c phá»¥c tháº¿ nÃ o?
Em xin cáº£m Æ¡n cÃ¡c anh chá»‹ áº¡!","Em xin chÃ o má»i ngÆ°á»i, em hiá»‡n chá»‰ má»›i Ä‘ang táº­p tÃ nh vá» Machine Learning. Em cÃ³ má»™t cÃ¢u há»i liÃªn quan Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u cho 1 project ML lÃ : Táº¡i sao khi xÃ¢y dá»±ng má»™t dá»± Ã¡n Machine Learning chÃºng ta láº¡i cáº§n pháº£i cÃ³ má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u, cÃ³ pháº£i mÃ¡y sáº½ há»c báº±ng cÃ¡ch nhÃ¬n vÃ o táº­p cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ rÃºt ra Ä‘Æ°á»£c kinh nghiá»‡m vÃ  tá»« Ä‘Ã³ training Ä‘Æ°á»£c model khÃ´ng áº¡? Náº¿u cÆ¡ sá»Ÿ dá»¯ liá»‡u chÃºng ta sá»­ dá»¥ng lÃ  cÃ¡c áº£nh thang xÃ¡m nhÆ°ng Ä‘áº§u vÃ o chÃºng ta Ä‘Æ°a vÃ´ há»‡ thá»‘ng ML lÃ  áº£nh mÃ u (cÃ³ Ä‘á»™ sÃ¡ng tá»‘i khÃ¡c vá»›i CSDL) thÃ¬ chÃºng ta cáº§n pháº£i kháº¯c phá»¥c tháº¿ nÃ o? Em xin cáº£m Æ¡n cÃ¡c anh chá»‹ áº¡!",,,,,
"CÃ³ anh em nÃ o tá»± Ã¡p dá»¥ng ML/DL vÃ o á»©ng dá»¥ng thá»±c táº¿ cho mÃ¬nh xin Ã­t kinh nghiá»‡m vá»›i, hiá»‡n táº¡i BE mÃ¬nh cÃ³ php8, FE thÃ¬ lÃ  reactjs, mobile lÃ  React native.
Muá»‘n Ã¡p dá»¥ng ML vÃ o dá»± Ã¡n (giáº£ sá»­ 1 tÃ­nh nÄƒng nÃ o Ä‘Ã³) thÃ¬ nÃªn dÃ¹ng cÃ¡ch nÃ o kháº£ thi váº­y áº¡ ?
1 - build model.h5 á»Ÿ local rá»“i dÃ¹ng tensorflowjs Ä‘á»ƒ load lÃªn/predict
2 - dá»±ng thÃªm server python Ä‘á»ƒ xá»­ lÃ½
3 - phÆ°Æ¡ng Ã¡n khÃ¡c","CÃ³ anh em nÃ o tá»± Ã¡p dá»¥ng ML/DL vÃ o á»©ng dá»¥ng thá»±c táº¿ cho mÃ¬nh xin Ã­t kinh nghiá»‡m vá»›i, hiá»‡n táº¡i BE mÃ¬nh cÃ³ php8, FE thÃ¬ lÃ  reactjs, mobile lÃ  React native. Muá»‘n Ã¡p dá»¥ng ML vÃ o dá»± Ã¡n (giáº£ sá»­ 1 tÃ­nh nÄƒng nÃ o Ä‘Ã³) thÃ¬ nÃªn dÃ¹ng cÃ¡ch nÃ o kháº£ thi váº­y áº¡ ? 1 - build model.h5 á»Ÿ local rá»“i dÃ¹ng tensorflowjs Ä‘á»ƒ load lÃªn/predict 2 - dá»±ng thÃªm server python Ä‘á»ƒ xá»­ lÃ½ 3 - phÆ°Æ¡ng Ã¡n khÃ¡c",,,,,
"ChÃ o má»i ngÆ°á»i.
Em Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch giáº£i quyáº¿t bÃ i toÃ¡n tá»‘i Æ°u theo cÃ¡ch maximum a posterior cho thuáº­t toÃ¡n Naive Bayes Classifier. Em muá»‘n há»i ráº±ng hÃ m prior (biáº¿n Ä‘á»•i tá»« posterior) cá»§a phÆ°Æ¡ng phÃ¡p MAP) vÃ  hÃ m prior cá»§a hÃ m má»¥c tiÃªu Naive Bayes cÃ³ giá»‘ng nhau khÃ´ng áº¡?
Em cáº£m Æ¡n áº¡.",ChÃ o má»i ngÆ°á»i. Em Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch giáº£i quyáº¿t bÃ i toÃ¡n tá»‘i Æ°u theo cÃ¡ch maximum a posterior cho thuáº­t toÃ¡n Naive Bayes Classifier. Em muá»‘n há»i ráº±ng hÃ m prior (biáº¿n Ä‘á»•i tá»« posterior) cá»§a phÆ°Æ¡ng phÃ¡p MAP) vÃ  hÃ m prior cá»§a hÃ m má»¥c tiÃªu Naive Bayes cÃ³ giá»‘ng nhau khÃ´ng áº¡? Em cáº£m Æ¡n áº¡.,,,,,
"ChÃ o ace,
MÃ´ hÃ¬nh cá»§a mÃ¬nh sau khi Ä‘Ã¡nh giÃ¡ thÃ¬ trÃªn táº­p test lá»—i bÃ© hÆ¡n táº­p train, accuracy táº­p test cÅ©ng tá»‘t hÆ¡n nhÆ° hÃ¬nh. Váº­y mÃ¬nh cáº§n Ä‘iá»u chá»‰nh gÃ¬ ko áº¡? CÃ¹ng bá»™ dá»¯ liá»‡u nÃ y, cÃ¡c mÃ´ hÃ¬nh khÃ¡c cá»§a mÃ¬nh Ä‘á»u tháº¥y trÃªn test ko tá»‘t báº±ng train áº¡.
CÃ¡m Æ¡n mn!","ChÃ o ace, MÃ´ hÃ¬nh cá»§a mÃ¬nh sau khi Ä‘Ã¡nh giÃ¡ thÃ¬ trÃªn táº­p test lá»—i bÃ© hÆ¡n táº­p train, accuracy táº­p test cÅ©ng tá»‘t hÆ¡n nhÆ° hÃ¬nh. Váº­y mÃ¬nh cáº§n Ä‘iá»u chá»‰nh gÃ¬ ko áº¡? CÃ¹ng bá»™ dá»¯ liá»‡u nÃ y, cÃ¡c mÃ´ hÃ¬nh khÃ¡c cá»§a mÃ¬nh Ä‘á»u tháº¥y trÃªn test ko tá»‘t báº±ng train áº¡. CÃ¡m Æ¡n mn!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh hiá»‡n táº¡i Ä‘ang lÃ m vá» bÃ i toÃ¡n liÃªn quan tá»›i gene expression. MÃ¬nh váº«n Ä‘ang tháº¯c máº¯c lÃ  dá»¯ liá»‡u vá» bÃ i toÃ¡n nÃ y thÃ¬ mÃ¬nh nÃªn tiáº¿p cáº­n theo microarray hay lÃ  rna-seq? Äá»‘i vá»›i rna-seq thÃ¬ file dá»¯ liá»‡u mÃ¬nh thu Ä‘Æ°á»£c lÃ  fastq hay lÃ  file cuá»‘i cÃ¹ng Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  chuáº©n hÃ³a rá»“i nhá»‰? Mong mn ai cÃ³ kinh nghiá»‡m giáº£i Ä‘Ã¡p giÃºp mÃ¬nh.","ChÃ o má»i ngÆ°á»i, mÃ¬nh hiá»‡n táº¡i Ä‘ang lÃ m vá» bÃ i toÃ¡n liÃªn quan tá»›i gene expression. MÃ¬nh váº«n Ä‘ang tháº¯c máº¯c lÃ  dá»¯ liá»‡u vá» bÃ i toÃ¡n nÃ y thÃ¬ mÃ¬nh nÃªn tiáº¿p cáº­n theo microarray hay lÃ  rna-seq? Äá»‘i vá»›i rna-seq thÃ¬ file dá»¯ liá»‡u mÃ¬nh thu Ä‘Æ°á»£c lÃ  fastq hay lÃ  file cuá»‘i cÃ¹ng Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  chuáº©n hÃ³a rá»“i nhá»‰? Mong mn ai cÃ³ kinh nghiá»‡m giáº£i Ä‘Ã¡p giÃºp mÃ¬nh.",,,,,
"ğŸ’¥ğŸ’¥ TECH INNOVATORS #5: DATA-CENTRIC GO BACK TO BASICS.
â° Thá»i gian: 9h30-11h00 ngÃ y 02/12/2021 táº¡i Fanpage FPT Software.
âœï¸ ÄÄƒng kÃ½ ngay vÃ  Ä‘áº·t cÃ¢u há»i dÃ nh cho cÃ¡c diá»…n giáº£ cá»§a TECH INNOVATORS: GO BACK TO BASICS: https://bit.ly/Register_TechInnovators5
ğŸ‘¥ Sá»± kiá»‡n cÃ³ sá»± gÃ³p máº·t cá»§a:
- Prof. ANDREW NG - nhÃ  khoa há»c mÃ¡y tÃ­nh vÃ  doanh nhÃ¢n cÃ´ng nghá»‡ ngÆ°á»i Má»¹ hoáº¡t Ä‘á»™ng trong lÄ©nh vá»±c há»c mÃ¡y vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o. Ã”ng lÃ  nhÃ  Ä‘á»“ng sÃ¡ng láº­p kiÃªm ngÆ°á»i Ä‘á»©ng Ä‘áº§u Google Brain. Andrew Ng Ä‘Æ°á»£c má»‡nh danh lÃ  ngÆ°á»i cÃ³ bá»™ Ã³c thiÃªn tÃ i vá» Deep learning vÃ  ngÆ°á»i táº¡o nÃªn Ä‘á»™t phÃ¡ vá»›i Data-Centric, dá»¯ liá»‡u Ä‘Æ°á»£c Ã´ng Ä‘Ã¡nh giÃ¡ lÃ  nguá»“n thá»©c Äƒn cho AI.
Andrew Ng cÅ©ng lÃ  má»™t trong nhá»¯ng nhÃ  khoa há»c mÃ¡y tÃ­nh ná»•i tiáº¿ng Ä‘Æ°á»£c giá»›i phÃ¡t triá»ƒn AI vÃ´ cÃ¹ng kÃ­nh ná»ƒ. Táº¡p chÃ­ TIME tá»«ng vinh danh Andrew lÃ  má»™t trong 100 ngÆ°á»i cÃ³ áº£nh hÆ°á»Ÿng nháº¥t nÄƒm 2012.
- Nguyá»…n Thá»‹ KhÃ¡nh Huyá»n (HUYEN CHIP) - Tháº¡c sÄ© ngÃ nh khoa há»c mÃ¡y tÃ­nh táº¡i Äáº¡i há»c Stanford, Ä‘á»©ng thá»© 5 trong danh sÃ¡ch Top Voices vá» lÄ©nh vá»±c Khoa há»c Dá»¯ liá»‡u vÃ  TrÃ­ ThÃ´ng minh NhÃ¢n táº¡o do LinkedIn bÃ¬nh chá»n nÄƒm 2020.
Tá»«ng cÃ³ kinh nghiá»‡m lÃ m viá»‡c táº¡i cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ ná»•i tiáº¿ng nhÆ° Netflix, NVIDIA; hay Ä‘áº£m nhiá»‡m vá»‹ trÃ­ Ká»¹ sÆ° Machine Learning táº¡i Snorkel AI. Hiá»‡n táº¡i, Huyen Chip Ä‘ang lÃ  giáº£ng viÃªn kiÃªm nhiá»‡m táº¡i Äáº¡i há»c Stanford, Má»¹.
- LYNN HE - ChuyÃªn gia AI quá»‘c táº¿, Ä‘á»“ng thá»i Ä‘áº£m nháº­n vá»‹ trÃ­ chuyÃªn gia ká»¹ thuáº­t táº¡i Deeplearning.ai. Lynn He láº§n Ä‘áº§u tiÃªn tiáº¿p xÃºc vá»›i AI thÃ´ng qua má»™t chÆ°Æ¡ng trÃ¬nh há»c mÃ¡y á»©ng dá»¥ng chuyÃªn sÃ¢u táº¡i Google vÃ  ká»ƒ tá»« Ä‘Ã³, chá»‹ Ä‘Ã£ thá»±c hiá»‡n nghiÃªn cá»©u AI vá» cÃ¡c chá»§ Ä‘á» phÃ¡t hiá»‡n cÃ¡c mÃ´ tÃ­p trong bá»™ dá»¯ liá»‡u há»™i há»a cho Ä‘áº¿n quy Ä‘á»‹nh vÃ  chÃ­nh sÃ¡ch.","TECH INNOVATORS DATA-CENTRIC GO BACK TO BASICS. â° Thá»i gian: 9h30-11h00 ngÃ y 02/12/2021 táº¡i Fanpage FPT Software. ÄÄƒng kÃ½ ngay vÃ  Ä‘áº·t cÃ¢u há»i dÃ nh cho cÃ¡c diá»…n giáº£ cá»§a TECH INNOVATORS: GO BACK TO BASICS: https://bit.ly/Register_TechInnovators5 Sá»± kiá»‡n cÃ³ sá»± gÃ³p máº·t cá»§a: - Prof. ANDREW NG - nhÃ  khoa há»c mÃ¡y tÃ­nh vÃ  doanh nhÃ¢n cÃ´ng nghá»‡ ngÆ°á»i Má»¹ hoáº¡t Ä‘á»™ng trong lÄ©nh vá»±c há»c mÃ¡y vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o. Ã”ng lÃ  nhÃ  Ä‘á»“ng sÃ¡ng láº­p kiÃªm ngÆ°á»i Ä‘á»©ng Ä‘áº§u Google Brain. Andrew Ng Ä‘Æ°á»£c má»‡nh danh lÃ  ngÆ°á»i cÃ³ bá»™ Ã³c thiÃªn tÃ i vá» Deep learning vÃ  ngÆ°á»i táº¡o nÃªn Ä‘á»™t phÃ¡ vá»›i Data-Centric, dá»¯ liá»‡u Ä‘Æ°á»£c Ã´ng Ä‘Ã¡nh giÃ¡ lÃ  nguá»“n thá»©c Äƒn cho AI. Andrew Ng cÅ©ng lÃ  má»™t trong nhá»¯ng nhÃ  khoa há»c mÃ¡y tÃ­nh ná»•i tiáº¿ng Ä‘Æ°á»£c giá»›i phÃ¡t triá»ƒn AI vÃ´ cÃ¹ng kÃ­nh ná»ƒ. Táº¡p chÃ­ TIME tá»«ng vinh danh Andrew lÃ  má»™t trong 100 ngÆ°á»i cÃ³ áº£nh hÆ°á»Ÿng nháº¥t nÄƒm 2012. - Nguyá»…n Thá»‹ KhÃ¡nh Huyá»n (HUYEN CHIP) - Tháº¡c sÄ© ngÃ nh khoa há»c mÃ¡y tÃ­nh táº¡i Äáº¡i há»c Stanford, Ä‘á»©ng thá»© 5 trong danh sÃ¡ch Top Voices vá» lÄ©nh vá»±c Khoa há»c Dá»¯ liá»‡u vÃ  TrÃ­ ThÃ´ng minh NhÃ¢n táº¡o do LinkedIn bÃ¬nh chá»n nÄƒm 2020. Tá»«ng cÃ³ kinh nghiá»‡m lÃ m viá»‡c táº¡i cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ ná»•i tiáº¿ng nhÆ° Netflix, NVIDIA; hay Ä‘áº£m nhiá»‡m vá»‹ trÃ­ Ká»¹ sÆ° Machine Learning táº¡i Snorkel AI. Hiá»‡n táº¡i, Huyen Chip Ä‘ang lÃ  giáº£ng viÃªn kiÃªm nhiá»‡m táº¡i Äáº¡i há»c Stanford, Má»¹. - LYNN HE - ChuyÃªn gia AI quá»‘c táº¿, Ä‘á»“ng thá»i Ä‘áº£m nháº­n vá»‹ trÃ­ chuyÃªn gia ká»¹ thuáº­t táº¡i Deeplearning.ai. Lynn He láº§n Ä‘áº§u tiÃªn tiáº¿p xÃºc vá»›i AI thÃ´ng qua má»™t chÆ°Æ¡ng trÃ¬nh há»c mÃ¡y á»©ng dá»¥ng chuyÃªn sÃ¢u táº¡i Google vÃ  ká»ƒ tá»« Ä‘Ã³, chá»‹ Ä‘Ã£ thá»±c hiá»‡n nghiÃªn cá»©u AI vá» cÃ¡c chá»§ Ä‘á» phÃ¡t hiá»‡n cÃ¡c mÃ´ tÃ­p trong bá»™ dá»¯ liá»‡u há»™i há»a cho Ä‘áº¿n quy Ä‘á»‹nh vÃ  chÃ­nh sÃ¡ch.",#5:,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m viá»‡c vá»›i dataset cá»§a em lÃ  1 large numpy array 3D kÃ­ch thÆ°á»›c (11187, 2000, 1024) (cÃ³ thá»ƒ coi má»—i data point hay sample trong dataset lÃ  1 ma tráº­n kÃ­ch thÆ°á»›c 2000x1024). Äá»ƒ cÃ³ thá»ƒ load dá»¯ liá»‡u vÃ o mÃ´ hÃ¬nh, em ghi numpy array dataset trÃªn ra file HDF5 rá»“i thá»±c hiá»‡n Ä‘á»c vÃ o táº¡o ra 1 HDF5 Dataset object, sau Ä‘Ã³ táº¡o 1 generator function Ä‘á»ƒ cÃ³ thá»ƒ iterate qua HDF5 dataset object nhÆ° trÃªn, cuá»‘i cÃ¹ng pass vÃ o tf.data input pipeline bá»Ÿi tf.data.Dataset.from_generator. Sau Ä‘Ã³ cÃ³ thá»ƒ fetch vÃ o trong functional API model mÃ  em Ä‘Ã£ khá»Ÿi táº¡o cho mÃ´ hÃ¬nh vá»›i method fit. Tuy nhiÃªn trong quÃ¡ trÃ¬nh lÃ m, em Ä‘á»ƒ Ã½ tháº¥y 1 sá»‘ Ä‘iá»u em muá»‘n há»i má»i ngÆ°á»iarray dataset trÃªn ra file HDF5 rá»“i thá»±c hiá»‡n Ä‘á»c vÃ o táº¡o ra 1 HDF5 Dataset object, sau Ä‘Ã³ táº¡o 1 generator function Ä‘á»ƒ cÃ³ thá»ƒ iterate qua HDF5 dataset object nhÆ° trÃªn, cuá»‘i cÃ¹ng pass vÃ o tf.data input pipeline bá»Ÿi tf.data.Dataset.from_generator. Sau Ä‘Ã³ cÃ³ thá»ƒ fetch vÃ o trong functional API model mÃ  em Ä‘Ã£ khá»Ÿi táº¡o cho mÃ´ hÃ¬nh vá»›i method fit. Em Ä‘ang train trong colab Pro+ vá»›i V100 cháº¿ Ä‘á»™ High-RAM.Tuy nhiÃªn trong quÃ¡ trÃ¬nh lÃ m, em Ä‘á»ƒ Ã½ tháº¥y 1 sá»‘ Ä‘iá»u em muá»‘n há»i má»i ngÆ°á»i
1. Em cÃ³ thá»­ viáº¿t training custom loop vá»›i GradientTape Ä‘á»ƒ lÃ m phÃ©p so sÃ¡nh vá»›i method fit cá»§a functional, cÃ³ váº» nhÆ° training custom loop cháº­m hÆ¡n vÃ  káº¿t quáº£ khÃ´ng giá»‘ng so vá»›i method fit. MÃ  em tra má»™t sá»‘ káº¿t quáº£ thÃ¬ tháº¥y method fit built-in cá»§a tensorflow khÃ¡ cháº­m nÃªn má»›i Ä‘i viáº¿t training custom loop. Váº­y nÃªn dÃ¹ng method fit hay implement subclass model vá»›i GradientTape Ä‘á»ƒ cáº£i thiá»‡n tá»‘c Ä‘á»™ áº¡ (em Ä‘Ã£ cÃ³ set cÃ¡c NVIDIA GPU flags cho tá»‘i Æ°u tá»‘c Ä‘á»™)
2. Hard-disk cá»§a Colab cÃ³ tÄƒng lÃªn khÃ¡ nhiá»u khi em train mÃ´ hÃ¬nh, tÄƒng vÃ i chá»¥c Gb Disk tuy nhiÃªn váº«n train Ä‘Æ°á»£c mÃ´ hÃ¬nh. Em cÃ³ tra thá»­ nhÆ°ng chÆ°a ra Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y áº¡, má»i ngÆ°á»i cÃ³ ai gáº·p váº¥n Ä‘á» nÃ y khÃ´ng áº¡.
3. Äá»‘i vá»›i dá»¯ liá»‡u kÃ­ch thÆ°á»›c ráº¥t lá»›n, em biáº¿t lÃ  nÃªn táº¡o generator cho dá»¯ liá»‡u, vÃ  Ä‘á»ƒ cÃ³ thá»ƒ chuáº©n bá»‹ tá»‘t quÃ¡ trÃ¬nh input data cho model thÃ¬ vá»›i tensorflow há» recommed tf.data input pipeline. á» Ä‘Ã¢y Ä‘á»ƒ pass generator function em táº¡o cho dá»¯ liá»‡u (táº¡o iterator cho tá»«ng Ä‘iá»ƒm dá»¯ liá»‡u rá»“i next qua tá»«ng iterator) vÃ o tf.data thÃ¬ em dÃ¹ng tf.data.Dataset.from_generator tuy nhiÃªn method láº¡i Ä‘Æ°á»£c nÃ³i trong docs cá»§a tensorflow lÃ  nÃªn háº¡n cháº¿ sá»­ dá»¥ng vÃ  cÃ³ tá»‘c Ä‘á»™ khÃ¡ cháº­m Ä‘á»c dá»¯ liá»‡u. Váº­y thÃ¬ Ä‘á»ƒ pass generator vÃ o Ä‘Æ°á»£c tf.data input pipeline thÃ¬ hoáº·c fetch vÃ o mÃ´ hÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£ thÃ¬ nÃªn dÃ¹ng gÃ¬ áº¡
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tá»›i Ä‘Ã¢y, 3 cÃ¢u há»i cá»§a em khÃ¡ dÃ i tuy nhiÃªn em cÅ©ng cá»‘ gáº¯ng diá»…n Ä‘áº¡t concise nháº¥t cÃ³ thá»ƒ context vÃ  problem cá»§a em. Em xin cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m viá»‡c vá»›i dataset cá»§a em lÃ  1 large numpy array 3D kÃ­ch thÆ°á»›c (11187, 2000, 1024) (cÃ³ thá»ƒ coi má»—i data point hay sample trong dataset lÃ  1 ma tráº­n kÃ­ch thÆ°á»›c 2000x1024). Äá»ƒ cÃ³ thá»ƒ load dá»¯ liá»‡u vÃ o mÃ´ hÃ¬nh, em ghi numpy array dataset trÃªn ra file HDF5 rá»“i thá»±c hiá»‡n Ä‘á»c vÃ o táº¡o ra 1 HDF5 Dataset object, sau Ä‘Ã³ táº¡o 1 generator function Ä‘á»ƒ cÃ³ thá»ƒ iterate qua HDF5 dataset object nhÆ° trÃªn, cuá»‘i cÃ¹ng pass vÃ o tf.data input pipeline bá»Ÿi tf.data.Dataset.from_generator. Sau Ä‘Ã³ cÃ³ thá»ƒ fetch vÃ o trong functional API model mÃ  em Ä‘Ã£ khá»Ÿi táº¡o cho mÃ´ hÃ¬nh vá»›i method fit. Tuy nhiÃªn trong quÃ¡ trÃ¬nh lÃ m, em Ä‘á»ƒ Ã½ tháº¥y 1 sá»‘ Ä‘iá»u em muá»‘n há»i má»i ngÆ°á»iarray dataset trÃªn ra file HDF5 rá»“i thá»±c hiá»‡n Ä‘á»c vÃ o táº¡o ra 1 HDF5 Dataset object, sau Ä‘Ã³ táº¡o 1 generator function Ä‘á»ƒ cÃ³ thá»ƒ iterate qua HDF5 dataset object nhÆ° trÃªn, cuá»‘i cÃ¹ng pass vÃ o tf.data input pipeline bá»Ÿi tf.data.Dataset.from_generator. Sau Ä‘Ã³ cÃ³ thá»ƒ fetch vÃ o trong functional API model mÃ  em Ä‘Ã£ khá»Ÿi táº¡o cho mÃ´ hÃ¬nh vá»›i method fit. Em Ä‘ang train trong colab Pro+ vá»›i V100 cháº¿ Ä‘á»™ High-RAM.Tuy nhiÃªn trong quÃ¡ trÃ¬nh lÃ m, em Ä‘á»ƒ Ã½ tháº¥y 1 sá»‘ Ä‘iá»u em muá»‘n há»i má»i ngÆ°á»i 1. Em cÃ³ thá»­ viáº¿t training custom loop vá»›i GradientTape Ä‘á»ƒ lÃ m phÃ©p so sÃ¡nh vá»›i method fit cá»§a functional, cÃ³ váº» nhÆ° training custom loop cháº­m hÆ¡n vÃ  káº¿t quáº£ khÃ´ng giá»‘ng so vá»›i method fit. MÃ  em tra má»™t sá»‘ káº¿t quáº£ thÃ¬ tháº¥y method fit built-in cá»§a tensorflow khÃ¡ cháº­m nÃªn má»›i Ä‘i viáº¿t training custom loop. Váº­y nÃªn dÃ¹ng method fit hay implement subclass model vá»›i GradientTape Ä‘á»ƒ cáº£i thiá»‡n tá»‘c Ä‘á»™ áº¡ (em Ä‘Ã£ cÃ³ set cÃ¡c NVIDIA GPU flags cho tá»‘i Æ°u tá»‘c Ä‘á»™) 2. Hard-disk cá»§a Colab cÃ³ tÄƒng lÃªn khÃ¡ nhiá»u khi em train mÃ´ hÃ¬nh, tÄƒng vÃ i chá»¥c Gb Disk tuy nhiÃªn váº«n train Ä‘Æ°á»£c mÃ´ hÃ¬nh. Em cÃ³ tra thá»­ nhÆ°ng chÆ°a ra Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y áº¡, má»i ngÆ°á»i cÃ³ ai gáº·p váº¥n Ä‘á» nÃ y khÃ´ng áº¡. 3. Äá»‘i vá»›i dá»¯ liá»‡u kÃ­ch thÆ°á»›c ráº¥t lá»›n, em biáº¿t lÃ  nÃªn táº¡o generator cho dá»¯ liá»‡u, vÃ  Ä‘á»ƒ cÃ³ thá»ƒ chuáº©n bá»‹ tá»‘t quÃ¡ trÃ¬nh input data cho model thÃ¬ vá»›i tensorflow há» recommed tf.data input pipeline. á» Ä‘Ã¢y Ä‘á»ƒ pass generator function em táº¡o cho dá»¯ liá»‡u (táº¡o iterator cho tá»«ng Ä‘iá»ƒm dá»¯ liá»‡u rá»“i next qua tá»«ng iterator) vÃ o tf.data thÃ¬ em dÃ¹ng tf.data.Dataset.from_generator tuy nhiÃªn method láº¡i Ä‘Æ°á»£c nÃ³i trong docs cá»§a tensorflow lÃ  nÃªn háº¡n cháº¿ sá»­ dá»¥ng vÃ  cÃ³ tá»‘c Ä‘á»™ khÃ¡ cháº­m Ä‘á»c dá»¯ liá»‡u. Váº­y thÃ¬ Ä‘á»ƒ pass generator vÃ o Ä‘Æ°á»£c tf.data input pipeline thÃ¬ hoáº·c fetch vÃ o mÃ´ hÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£ thÃ¬ nÃªn dÃ¹ng gÃ¬ áº¡ Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tá»›i Ä‘Ã¢y, 3 cÃ¢u há»i cá»§a em khÃ¡ dÃ i tuy nhiÃªn em cÅ©ng cá»‘ gáº¯ng diá»…n Ä‘áº¡t concise nháº¥t cÃ³ thá»ƒ context vÃ  problem cá»§a em. Em xin cáº£m Æ¡n áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i
Em Ä‘ang nghiÃªn cá»©u phÃ¢n loáº¡i, phÃ¢n cá»¥m khÃ¡ch hÃ ng báº±ng cÃ¡c thuáº­t toÃ¡n há»c khÃ´ng giÃ¡m sÃ¡t FCM vÃ  PFCM vá»›i káº¿t quáº£ dá»¯ liá»‡u cá»§a thuáº­t toÃ¡n RFM. Sau khi cháº¡y phÃ¢n cá»¥m Ä‘Æ°á»£c khÃ¡ch hÃ ng vá»›i 2 thuáº­t toÃ¡n FCM vÃ  PFCM xong rá»“i. NhÆ°ng em khÃ´ng biáº¿t lÃ m sao Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c thuáº­t toÃ¡n FCM vÃ  PFCM cÃ¡i nÃ o tá»‘t hÆ¡n. Em cÃ³ xem 1 sá»‘ cÃ¡ch Ä‘Ã¡nh giÃ¡ khi cháº¡y qua cÃ¡c thuáº­t toÃ¡n chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ nhÆ° PC or XB, mÃ  em láº¡i Ä‘ang khÃ´ng náº¯m rÃµ Ä‘Æ°á»£c cÃ¡ch Ä‘Ã¡nh giÃ¡ cá»§a nÃ³. NÃªn em mong muá»‘n cÃ³ cao nhÃ¢n nÃ o trong group nghiÃªn cá»©u máº£ng nÃ y truyá»n Ä‘áº¡o giÃºp em. Em sáº½ cáº£m Æ¡n vÃ  háº­u táº¡ áº¡","ChÃ o má»i ngÆ°á»i Em Ä‘ang nghiÃªn cá»©u phÃ¢n loáº¡i, phÃ¢n cá»¥m khÃ¡ch hÃ ng báº±ng cÃ¡c thuáº­t toÃ¡n há»c khÃ´ng giÃ¡m sÃ¡t FCM vÃ  PFCM vá»›i káº¿t quáº£ dá»¯ liá»‡u cá»§a thuáº­t toÃ¡n RFM. Sau khi cháº¡y phÃ¢n cá»¥m Ä‘Æ°á»£c khÃ¡ch hÃ ng vá»›i 2 thuáº­t toÃ¡n FCM vÃ  PFCM xong rá»“i. NhÆ°ng em khÃ´ng biáº¿t lÃ m sao Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c thuáº­t toÃ¡n FCM vÃ  PFCM cÃ¡i nÃ o tá»‘t hÆ¡n. Em cÃ³ xem 1 sá»‘ cÃ¡ch Ä‘Ã¡nh giÃ¡ khi cháº¡y qua cÃ¡c thuáº­t toÃ¡n chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ nhÆ° PC or XB, mÃ  em láº¡i Ä‘ang khÃ´ng náº¯m rÃµ Ä‘Æ°á»£c cÃ¡ch Ä‘Ã¡nh giÃ¡ cá»§a nÃ³. NÃªn em mong muá»‘n cÃ³ cao nhÃ¢n nÃ o trong group nghiÃªn cá»©u máº£ng nÃ y truyá»n Ä‘áº¡o giÃºp em. Em sáº½ cáº£m Æ¡n vÃ  háº­u táº¡ áº¡",,,,,
"Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang giáº£i quyáº¿t má»™t bÃ i toÃ¡n liÃªn quan Ä‘áº¿n tÃ­nh khoáº£ng cÃ¡ch giá»¯a ngÆ°á»i vá»›i ngÆ°á»i, dá»±a trÃªn input cÃ³ gÃ³c chá»¥p lÃ  gÃ³c ngang. VÃ¬ lÃ  gÃ³c ngang nÃªn sáº½ khÃ³ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khoáº£ng cÃ¡ch, nÃªn em muá»‘n báº±ng lÃ m cÃ¡ch nÃ o Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh nÃ y sang gÃ³c chá»¥p tá»« trÃªn xuá»‘ng (top-view), output khÃ´ng pháº£i lÃ  má»™t hÃ¬nh áº£nh mÃ  lÃ  táº­p há»£p Ä‘iá»ƒm trÃªn Ä‘á»“ thá»‹, má»—i Ä‘iá»ƒm Ä‘áº¡i diá»‡n cho má»™t cÃ¡ thá»ƒ ngÆ°á»i.
Äá»ƒ giáº£i thÃ­ch rÃµ rÃ ng hÆ¡n thÃ¬ váº¥n Ä‘á» cá»§a em gáº§n giá»‘ng nhÆ° cÃ´ng nghá»‡ GOAL LINE trong bÃ³ng Ä‘Ã¡, má»i ngÆ°á»i cÃ³ thá»ƒ xem Ä‘oáº¡n tá»« 2:41 -> 2:45 (https://youtu.be/plu8zxhU3Cw?t=161). Trong video thÃ¬ má»i ngÆ°á»i tháº¥y camera sáº½ chuyá»ƒn tá»« gÃ³c chá»¥p ngang sang gÃ³c chá»¥p tá»« trÃªn xuá»‘ng.
Má»¥c Ä‘Ã­ch em lÃ m váº­y lÃ  bá»Ÿi vÃ¬ em muá»‘n Ã¡p dá»¥ng DBSCAN clustering Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n giÃ£n cÃ¡ch xÃ£ há»™i, nhÆ°ng láº¡i gáº·p pháº£i váº¥n Ä‘á» pháº£i phÃ¢n biá»‡t Ä‘Æ°á»£c nhá»¯ng ngÆ°á»i á»Ÿ gáº§n camera vÃ  nhá»¯ng ngÆ°á»i á»Ÿ xa camera.
Em cÃ³ má»™t cÃ¡ch lÃ m khÃ¡ ""ngÃ´ nghÃª"" vÃ  khÃ´ng máº¥y hiá»‡u quáº£: VÃ¬ lÃ  gÃ³c chá»¥p ngang nÃªn hoÃ n toÃ n xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a ngÆ°á»i Ä‘Ã³ theo trá»¥c Ox, cÃ²n chiá»u dá»c thÃ¬ em sáº½ detect human head vÃ  tÃ­nh diá»‡n tÃ­ch cá»§a bounding box, náº¿u diá»‡n tÃ­ch cÃ ng nhá» nghÄ©a lÃ  ngÆ°á»i Ä‘Ã³ Ä‘ang á»Ÿ xa camera, nÃªn giÃ¡ trá»‹ trÃªn trá»¥c Oy sáº½ lá»›n.
KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ nÃ o hÆ¡n khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n!

p.s: 
Trong hÃ¬nh 1 lÃ  em sá»­ dá»¥ng pre-trained model trÃªn máº¡ng nÃªn detect human head cÃ²n xÃ³t ""1 cÃ¡i Ä‘áº§u"" khÃ´ng detect Ä‘Æ°á»£c (cÃ³ thá»ƒ táº­p dataset khÃ´ng cÃ³ nhiá»u hÃ¬nh Ä‘eo kháº©u trang)
HÃ¬nh 2 lÃ  káº¿t quáº£ mÃ  em xá»­ lÃ½ nhÆ°ng váº«n cÃ²n chÆ°a chÃ­nh xÃ¡c.","Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang giáº£i quyáº¿t má»™t bÃ i toÃ¡n liÃªn quan Ä‘áº¿n tÃ­nh khoáº£ng cÃ¡ch giá»¯a ngÆ°á»i vá»›i ngÆ°á»i, dá»±a trÃªn input cÃ³ gÃ³c chá»¥p lÃ  gÃ³c ngang. VÃ¬ lÃ  gÃ³c ngang nÃªn sáº½ khÃ³ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khoáº£ng cÃ¡ch, nÃªn em muá»‘n báº±ng lÃ m cÃ¡ch nÃ o Ä‘Ã³ Ä‘á»ƒ cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh nÃ y sang gÃ³c chá»¥p tá»« trÃªn xuá»‘ng (top-view), output khÃ´ng pháº£i lÃ  má»™t hÃ¬nh áº£nh mÃ  lÃ  táº­p há»£p Ä‘iá»ƒm trÃªn Ä‘á»“ thá»‹, má»—i Ä‘iá»ƒm Ä‘áº¡i diá»‡n cho má»™t cÃ¡ thá»ƒ ngÆ°á»i. Äá»ƒ giáº£i thÃ­ch rÃµ rÃ ng hÆ¡n thÃ¬ váº¥n Ä‘á» cá»§a em gáº§n giá»‘ng nhÆ° cÃ´ng nghá»‡ GOAL LINE trong bÃ³ng Ä‘Ã¡, má»i ngÆ°á»i cÃ³ thá»ƒ xem Ä‘oáº¡n tá»« 2:41 -> 2:45 (https://youtu.be/plu8zxhU3Cw?t=161). Trong video thÃ¬ má»i ngÆ°á»i tháº¥y camera sáº½ chuyá»ƒn tá»« gÃ³c chá»¥p ngang sang gÃ³c chá»¥p tá»« trÃªn xuá»‘ng. Má»¥c Ä‘Ã­ch em lÃ m váº­y lÃ  bá»Ÿi vÃ¬ em muá»‘n Ã¡p dá»¥ng DBSCAN clustering Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n giÃ£n cÃ¡ch xÃ£ há»™i, nhÆ°ng láº¡i gáº·p pháº£i váº¥n Ä‘á» pháº£i phÃ¢n biá»‡t Ä‘Æ°á»£c nhá»¯ng ngÆ°á»i á»Ÿ gáº§n camera vÃ  nhá»¯ng ngÆ°á»i á»Ÿ xa camera. Em cÃ³ má»™t cÃ¡ch lÃ m khÃ¡ ""ngÃ´ nghÃª"" vÃ  khÃ´ng máº¥y hiá»‡u quáº£: VÃ¬ lÃ  gÃ³c chá»¥p ngang nÃªn hoÃ n toÃ n xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a ngÆ°á»i Ä‘Ã³ theo trá»¥c Ox, cÃ²n chiá»u dá»c thÃ¬ em sáº½ detect human head vÃ  tÃ­nh diá»‡n tÃ­ch cá»§a bounding box, náº¿u diá»‡n tÃ­ch cÃ ng nhá» nghÄ©a lÃ  ngÆ°á»i Ä‘Ã³ Ä‘ang á»Ÿ xa camera, nÃªn giÃ¡ trá»‹ trÃªn trá»¥c Oy sáº½ lá»›n. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ nÃ o hÆ¡n khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n! p.s: Trong hÃ¬nh 1 lÃ  em sá»­ dá»¥ng pre-trained model trÃªn máº¡ng nÃªn detect human head cÃ²n xÃ³t ""1 cÃ¡i Ä‘áº§u"" khÃ´ng detect Ä‘Æ°á»£c (cÃ³ thá»ƒ táº­p dataset khÃ´ng cÃ³ nhiá»u hÃ¬nh Ä‘eo kháº©u trang) HÃ¬nh 2 lÃ  káº¿t quáº£ mÃ  em xá»­ lÃ½ nhÆ°ng váº«n cÃ²n chÆ°a chÃ­nh xÃ¡c.",,,,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m bÃ i toÃ¡n liÃªn quan tá»›i chá»‰nh sá»­a áº£nh vÃ  muá»‘n thá»­ cÃ¡c encoder khÃ¡c ngoÃ i StyleGAN, e4e vÃ  ALAE. VÃ¬ em tháº¥y StyleGAN encode lÃ¢u quÃ¡ :< cÃ²n 2 cÃ¡i cÃ²n láº¡i thÃ¬ reconstructred image khaÌc khaÌ nhiÃªÌ€u so vÆ¡Ìi input. Mong anh chá»‹ chia sáº» thÃªm cÃ¡c hÆ°á»›ng khÃ¡c áº¡. Náº¿u k thÃ¬ em cÃ³ thá»ƒ lÃ m gÃ¬ Ä‘á»ƒ cáº£i thiá»‡n káº¿t quáº£ tá»« 3 encoder kia Ä‘Æ°á»£c áº¡.
Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m bÃ i toÃ¡n liÃªn quan tá»›i chá»‰nh sá»­a áº£nh vÃ  muá»‘n thá»­ cÃ¡c encoder khÃ¡c ngoÃ i StyleGAN, e4e vÃ  ALAE. VÃ¬ em tháº¥y StyleGAN encode lÃ¢u quÃ¡ :< cÃ²n 2 cÃ¡i cÃ²n láº¡i thÃ¬ reconstructred image khaÌc khaÌ nhiÃªÌ€u so vÆ¡Ìi input. Mong anh chá»‹ chia sáº» thÃªm cÃ¡c hÆ°á»›ng khÃ¡c áº¡. Náº¿u k thÃ¬ em cÃ³ thá»ƒ lÃ m gÃ¬ Ä‘á»ƒ cáº£i thiá»‡n káº¿t quáº£ tá»« 3 encoder kia Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n áº¡.",,,,,
"[Há»i Ä‘Ã¡p]
#bigdata
chÃ o má»i ngÆ°á»i, em Ä‘Äƒng bÃ i khÃ´ng liÃªn quan Ä‘áº¿n ML, nhÆ°ng liÃªn quan Ä‘áº¿n viá»‡c xÃ¢y dá»±ng vÃ  quáº£n lÃ½ data, theo em cÅ©ng khÃ¡ thÃº vá»‹, mong Ä‘Æ°á»£c má»i ngÆ°á»i cho lá»i khuyÃªn áº¡.
1. háº±ng ngÃ y em nháº­n Ä‘Æ°á»£c data dÆ°á»›i dáº¡ng ""static table"" nhÆ° hÃ¬nh dÆ°á»›i, vá»›i dáº¡ng key-value lÃ  name-code. NhÆ°ng cÃ³ ngÃ y code tÆ°Æ¡ng á»©ng cá»§a name sáº½ thay Ä‘á»•i.
Em mong muá»‘n tÃ¬m cÃ¡ch xÃ¢y dá»±ng má»™t ""dynamic table"" nhÆ° tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ dá»… dÃ ng tÃ¬m code cÅ©, code má»›i, vÃ  thá»i gian thay Ä‘á»•i má»™t cÃ¡ch hiá»‡u quáº£ trong trÆ°á»ng há»£p dá»¯ liá»‡u lá»›n áº¡.
2. Em Ä‘ang tÃ¬m giáº£i phÃ¡p Ä‘á»ƒ cÃ³ thá»ƒ quáº£n lÃ½ cÃ¡c data phi cáº¥u trÃºc vÃ  Ä‘áº·c biá»‡t (vÃ­ dá»¥ nhÆ° tai náº¡n thá»‹ trÆ°á»ng, tin tá»©c, ngoáº¡i lá»‡ trong giao dá»‹ch, nhá»¯ng thay Ä‘á»•i trong quy Ä‘á»‹nh, ...).
Em cáº§n lÃ m sao Ä‘á»ƒ tÃ­ch há»£p nhá»¯ng data phi cáº¥u trÃºc nhÆ° trÃªn vá»›i nhá»¯ng data bÃ¬nh thÆ°á»ng cho má»¥c Ä‘Ã­ch phÃ¢n tÃ­ch dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£ nháº¥t.
Tháº­t sá»± em khÃ´ng pháº£i lÃ  ngÆ°á»i lÃ m database, nÃªn gáº·p váº¥n Ä‘á» cÃ³ chÃºt lÃºng tÃºng. Mong Ä‘Æ°á»£c má»i ngÆ°á»i Ä‘Ã³ng gÃ³p vÃ  cho lá»i khuyÃªn, em trÃ¢n trá»ng cáº£m Æ¡n áº¡.","[Há»i Ä‘Ã¡p] chÃ o má»i ngÆ°á»i, em Ä‘Äƒng bÃ i khÃ´ng liÃªn quan Ä‘áº¿n ML, nhÆ°ng liÃªn quan Ä‘áº¿n viá»‡c xÃ¢y dá»±ng vÃ  quáº£n lÃ½ data, theo em cÅ©ng khÃ¡ thÃº vá»‹, mong Ä‘Æ°á»£c má»i ngÆ°á»i cho lá»i khuyÃªn áº¡. 1. háº±ng ngÃ y em nháº­n Ä‘Æ°á»£c data dÆ°á»›i dáº¡ng ""static table"" nhÆ° hÃ¬nh dÆ°á»›i, vá»›i dáº¡ng key-value lÃ  name-code. NhÆ°ng cÃ³ ngÃ y code tÆ°Æ¡ng á»©ng cá»§a name sáº½ thay Ä‘á»•i. Em mong muá»‘n tÃ¬m cÃ¡ch xÃ¢y dá»±ng má»™t ""dynamic table"" nhÆ° tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ dá»… dÃ ng tÃ¬m code cÅ©, code má»›i, vÃ  thá»i gian thay Ä‘á»•i má»™t cÃ¡ch hiá»‡u quáº£ trong trÆ°á»ng há»£p dá»¯ liá»‡u lá»›n áº¡. 2. Em Ä‘ang tÃ¬m giáº£i phÃ¡p Ä‘á»ƒ cÃ³ thá»ƒ quáº£n lÃ½ cÃ¡c data phi cáº¥u trÃºc vÃ  Ä‘áº·c biá»‡t (vÃ­ dá»¥ nhÆ° tai náº¡n thá»‹ trÆ°á»ng, tin tá»©c, ngoáº¡i lá»‡ trong giao dá»‹ch, nhá»¯ng thay Ä‘á»•i trong quy Ä‘á»‹nh, ...). Em cáº§n lÃ m sao Ä‘á»ƒ tÃ­ch há»£p nhá»¯ng data phi cáº¥u trÃºc nhÆ° trÃªn vá»›i nhá»¯ng data bÃ¬nh thÆ°á»ng cho má»¥c Ä‘Ã­ch phÃ¢n tÃ­ch dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£ nháº¥t. Tháº­t sá»± em khÃ´ng pháº£i lÃ  ngÆ°á»i lÃ m database, nÃªn gáº·p váº¥n Ä‘á» cÃ³ chÃºt lÃºng tÃºng. Mong Ä‘Æ°á»£c má»i ngÆ°á»i Ä‘Ã³ng gÃ³p vÃ  cho lá»i khuyÃªn, em trÃ¢n trá»ng cáº£m Æ¡n áº¡.",#bigdata,,,,
"ChÃ o má»i ngÆ°á»i:
Em cÃ³ bÃ i toÃ¡n sau nhÆ°ng chÆ°a biáº¿t cÃ¡ch Ã¡p dá»¥ng giáº£i thuáº­t recommendation: content base,
collaborative filtering tháº¿ nÃ o, mong ngÆ°á»i cho em hÆ°á»›ng Ä‘i.
BÃ i toÃ¡n cá»§a em lÃ  cáº§n tÃ¬m ngÆ°á»i cho dá»± Ã¡n. Má»—i dá»± Ã¡n cÃ³ cÃ¡c yÃªu cáº§u vá» role,
vá» ká»¹ nÄƒng. Má»—i nhÃ¢n viÃªn cÃ³ skill, expected skill cÃ³ level, role cÃ³ level, hobby,
softskill vÃ  má»™t vÃ i thÃ´ng tin cÆ¡ báº£n ná»¯a.
Hiá»‡n táº¡i em khÃ´ng biáº¿t cÃ¡ch xÃ¢y dá»±ng feature tháº¿ nÃ o.
Mong má»i ngÆ°á»i giÃºp Ä‘á»¡, em cÃ¡m Æ¡n
Em bá»• sung thÃªm: hiá»‡n táº¡i, em nghÄ© cÃ³ thá»ƒ mÃ´ hÃ¬nh cÃ¡c dá»¯ liá»‡u cá»§a em thiÃªu dáº¡ng vector Ä‘áº¡i diá»‡n cho má»—i nhÃ¢n viÃªn nhÆ° sau,
em cÃ³ 91 skill, em táº¡o 1 vector skill 91 chiá»u, 1 vector role cÃ³ 10 chiá»u, má»™t vector vá» level giÃ¡ trá»‹ (tá»« 0 - 9) táº¡i vÃ­ trá»‹ cÃ³ skill .., cá»© nhÆ° váº­y Ä‘áº¿n háº¿t thÃ´ng tin vá» ká»¹ nÄƒng mÃªm,
sá»Ÿ thÃ­ch Ä‘á»ƒ mÃ£ hÃ³a, xong rá»“i lÃ m tháº¿ nÃ o Ä‘á»ƒ liÃªn há»‡ vá»›i káº¿t quáº£ lÃ  phÃ¢n vÃ o project nÃ o thÃ¬ em chÆ°a nghÄ© ra, em suy nghÄ© tÆ° tÆ°á»Ÿng tá»« bÃ i toÃ¡n recommendation cá»§a movie imdb.","ChÃ o má»i ngÆ°á»i: Em cÃ³ bÃ i toÃ¡n sau nhÆ°ng chÆ°a biáº¿t cÃ¡ch Ã¡p dá»¥ng giáº£i thuáº­t recommendation: content base, collaborative filtering tháº¿ nÃ o, mong ngÆ°á»i cho em hÆ°á»›ng Ä‘i. BÃ i toÃ¡n cá»§a em lÃ  cáº§n tÃ¬m ngÆ°á»i cho dá»± Ã¡n. Má»—i dá»± Ã¡n cÃ³ cÃ¡c yÃªu cáº§u vá» role, vá» ká»¹ nÄƒng. Má»—i nhÃ¢n viÃªn cÃ³ skill, expected skill cÃ³ level, role cÃ³ level, hobby, softskill vÃ  má»™t vÃ i thÃ´ng tin cÆ¡ báº£n ná»¯a. Hiá»‡n táº¡i em khÃ´ng biáº¿t cÃ¡ch xÃ¢y dá»±ng feature tháº¿ nÃ o. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡, em cÃ¡m Æ¡n Em bá»• sung thÃªm: hiá»‡n táº¡i, em nghÄ© cÃ³ thá»ƒ mÃ´ hÃ¬nh cÃ¡c dá»¯ liá»‡u cá»§a em thiÃªu dáº¡ng vector Ä‘áº¡i diá»‡n cho má»—i nhÃ¢n viÃªn nhÆ° sau, em cÃ³ 91 skill, em táº¡o 1 vector skill 91 chiá»u, 1 vector role cÃ³ 10 chiá»u, má»™t vector vá» level giÃ¡ trá»‹ (tá»« 0 - 9) táº¡i vÃ­ trá»‹ cÃ³ skill .., cá»© nhÆ° váº­y Ä‘áº¿n háº¿t thÃ´ng tin vá» ká»¹ nÄƒng mÃªm, sá»Ÿ thÃ­ch Ä‘á»ƒ mÃ£ hÃ³a, xong rá»“i lÃ m tháº¿ nÃ o Ä‘á»ƒ liÃªn há»‡ vá»›i káº¿t quáº£ lÃ  phÃ¢n vÃ o project nÃ o thÃ¬ em chÆ°a nghÄ© ra, em suy nghÄ© tÆ° tÆ°á»Ÿng tá»« bÃ i toÃ¡n recommendation cá»§a movie imdb.",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh cÃ³ tháº¯c máº¯c lÃ  cÃ¡i model LSTM mÃ¬nh train trÃªn Python rá»“i lÆ°u thÃ nh file .h5 nhÆ°ng chuyá»ƒn qua MATLAB thÃ¬ import khÃ´ng Ä‘Æ°á»£c cÃ¡c layer LSTM (cÃ¡c layer khÃ¡c nhÆ° dense hoáº·c dropout thÃ¬ Ä‘Æ°á»£c). CÃ³ báº¡n nÃ o gáº·p váº¥n Ä‘á» tÆ°Æ¡ng tá»± khÃ´ng?","ChÃ o má»i ngÆ°á»i, MÃ¬nh cÃ³ tháº¯c máº¯c lÃ  cÃ¡i model LSTM mÃ¬nh train trÃªn Python rá»“i lÆ°u thÃ nh file .h5 nhÆ°ng chuyá»ƒn qua MATLAB thÃ¬ import khÃ´ng Ä‘Æ°á»£c cÃ¡c layer LSTM (cÃ¡c layer khÃ¡c nhÆ° dense hoáº·c dropout thÃ¬ Ä‘Æ°á»£c). CÃ³ báº¡n nÃ o gáº·p váº¥n Ä‘á» tÆ°Æ¡ng tá»± khÃ´ng?",,,,,
"Em chÃ o anh chá»‹ vÃ  má»i ngÆ°á»i áº¡. Em lÃ  sinh viÃªn nÄƒm nháº¥t, tháº§y cÃ³ cho nhÃ³m em lÃ m vá» Ä‘á» tÃ i nÃ y (mÃ´n Äáº¡i sá»‘ tuyáº¿n tÃ­nh) áº¡. Anh chá»‹ cÃ³ thá»ƒ cho em xin Ã­t tÃ i liá»‡u vá» Ä‘á» tÃ i nÃ y khÃ´ng áº¡ ^^. Em xin chÃ¢n thÃ nh cáº£m Æ¡n
p/s: em há»c Äiá»‡n Ä‘iá»‡n tá»­ vá»›i láº¡i chÆ°a biáº¿t nhiá»u vá» code. khÃ´ng biáº¿t cÃ³ lÃ m ká»‹p Ä‘á» tÃ i nÃ y trong 2 tuáº§n tá»›i khÃ´ng ná»¯a áº¡ ğŸ˜¢ğŸ˜¢","Em chÃ o anh chá»‹ vÃ  má»i ngÆ°á»i áº¡. Em lÃ  sinh viÃªn nÄƒm nháº¥t, tháº§y cÃ³ cho nhÃ³m em lÃ m vá» Ä‘á» tÃ i nÃ y (mÃ´n Äáº¡i sá»‘ tuyáº¿n tÃ­nh) áº¡. Anh chá»‹ cÃ³ thá»ƒ cho em xin Ã­t tÃ i liá»‡u vá» Ä‘á» tÃ i nÃ y khÃ´ng áº¡ ^^. Em xin chÃ¢n thÃ nh cáº£m Æ¡n p/s: em há»c Äiá»‡n Ä‘iá»‡n tá»­ vá»›i láº¡i chÆ°a biáº¿t nhiá»u vá» code. khÃ´ng biáº¿t cÃ³ lÃ m ká»‹p Ä‘á» tÃ i nÃ y trong 2 tuáº§n tá»›i khÃ´ng ná»¯a áº¡",,,,,
"Hi everyone, I'm pleased to share with you a Machine learning course for begineer with relaxing background music. This provide a new way to enjoy your self-education journey. This playlist will be updated daily with new relaxing parts. Thank you and enjoy!","Hi everyone, I'm pleased to share with you a Machine learning course for begineer with relaxing background music. This provide a new way to enjoy your self-education journey. This playlist will be updated daily with new relaxing parts. Thank you and enjoy!",,,,,
"#newbie
Em chÃ o má»i ngÆ°á»i. Em cÃ³ má»™t cÃ¢u há»i cáº§n má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp. Trong lÃºc huáº¥n luyá»‡n MLP, Em cÃ³ sá»­ dá»¥ng mini-batch trong SGD Ä‘á»ƒ cáº­p nháº­t cÃ¡c trá»ng sá»‘ vÃ  bias. Giáº£ sá»­ ta cÃ³ Má»˜T hÃ m phi tuyáº¿n Ã¡p dá»¥ng cho tá»«ng minibatch má»—i lÃºc. Viá»‡c nÃ y sáº½ dáº«n Ä‘áº¿n nhá»¯ng váº¥n Ä‘á» gÃ¬ áº¡?
VÃ¬ khi em sá»­ dá»¥ng mini-batch thÃ¬ hiá»‡u quáº£ cá»§a huáº¥n luyá»‡n khÃ´ng tÄƒng lÃªn bao nhiÃªu so vá»›i khi thá»±c hiá»‡n vá»›i toÃ n bá»™ dá»¯ liá»‡u.
Dá»¯ liá»‡u cá»§a em lÃ  dá»¯ liá»‡u táº¡o giáº£ Ä‘á»‹nh vá»›i C lá»›p cÃ¹ng phÃ¢n phá»‘i gauss.","Em chÃ o má»i ngÆ°á»i. Em cÃ³ má»™t cÃ¢u há»i cáº§n má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp. Trong lÃºc huáº¥n luyá»‡n MLP, Em cÃ³ sá»­ dá»¥ng mini-batch trong SGD Ä‘á»ƒ cáº­p nháº­t cÃ¡c trá»ng sá»‘ vÃ  bias. Giáº£ sá»­ ta cÃ³ Má»˜T hÃ m phi tuyáº¿n Ã¡p dá»¥ng cho tá»«ng minibatch má»—i lÃºc. Viá»‡c nÃ y sáº½ dáº«n Ä‘áº¿n nhá»¯ng váº¥n Ä‘á» gÃ¬ áº¡? VÃ¬ khi em sá»­ dá»¥ng mini-batch thÃ¬ hiá»‡u quáº£ cá»§a huáº¥n luyá»‡n khÃ´ng tÄƒng lÃªn bao nhiÃªu so vá»›i khi thá»±c hiá»‡n vá»›i toÃ n bá»™ dá»¯ liá»‡u. Dá»¯ liá»‡u cá»§a em lÃ  dá»¯ liá»‡u táº¡o giáº£ Ä‘á»‹nh vá»›i C lá»›p cÃ¹ng phÃ¢n phá»‘i gauss.",#newbie,,,,
"Hi má»i ngÆ°á»i, má»i ngÆ°á»i cho em xin cÃ¡c dá»± Ã¡n Machine Learning hoáº·c Deep Learning liÃªn quan Ä‘áº¿n Marketing vá»›i áº¡!

Em cáº£m Æ¡n â˜ºï¸","Hi má»i ngÆ°á»i, má»i ngÆ°á»i cho em xin cÃ¡c dá»± Ã¡n Machine Learning hoáº·c Deep Learning liÃªn quan Ä‘áº¿n Marketing vá»›i áº¡! Em cáº£m Æ¡n",,,,,
"Em chÃ o má»i ngÆ°á»i. Em Ä‘áº¡ng tÃ­nh ROC_AUC vá»›i ACCURACY nhÆ°ng nÃ³ cÃ³ 1 vÃ i batch bá»‹ lá»‡ch nhÆ° bÃªn dÆ°á»›i. Vá»›i trÆ°á»ng há»£p nÃ y thÃ¬ pháº£i xá»­ lÃ½ nhÆ° tháº¿ nÃ o áº¡? Má»i ngÆ°á»i cho em há»i thÃªm lÃ  cÃ³ hÆ°á»›ng dáº«n nÃ o tÃ­nh tay cÃ¡i ROC_AUC khÃ´ng, cÃ³ vÃ­ dá»¥ cÃ ng tá»‘t áº¡. Em xin cáº£m Æ¡n!","Em chÃ o má»i ngÆ°á»i. Em Ä‘áº¡ng tÃ­nh ROC_AUC vá»›i ACCURACY nhÆ°ng nÃ³ cÃ³ 1 vÃ i batch bá»‹ lá»‡ch nhÆ° bÃªn dÆ°á»›i. Vá»›i trÆ°á»ng há»£p nÃ y thÃ¬ pháº£i xá»­ lÃ½ nhÆ° tháº¿ nÃ o áº¡? Má»i ngÆ°á»i cho em há»i thÃªm lÃ  cÃ³ hÆ°á»›ng dáº«n nÃ o tÃ­nh tay cÃ¡i ROC_AUC khÃ´ng, cÃ³ vÃ­ dá»¥ cÃ ng tá»‘t áº¡. Em xin cáº£m Æ¡n!",,,,,
"Em Ä‘ang cÃ³ má»™t sá»‘ tháº¯c máº¯c vá» pháº§n Linear discriminant analysis (LDA) trong cuá»‘n sÃ¡ch ML cÆ¡ báº£n. Mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ giáº£i thÃ¡p tháº¯c máº¯c cá»§a cÃ¡c anh chá»‹ trong nhÃ³m áº¡.
1. VÃ­ dá»¥ táº­p dá»¯ liá»‡u gá»“m 2 lá»›p (xanh vÃ  Ä‘á») thÃ¬ thuáº­t toÃ¡n LDA sáº½ tÃ¬m má»™t Ä‘Æ°á»ng tháº³ng Ä‘á»ƒ khi chiáº¿u cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u lÃªn thÃ¬ sáº½ Ä‘Æ°á»£c cÃ¡c hÃ¬nh chiáº¿u cá»§a 2 lá»›p nÃ y phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh (linearly separable), nhÆ° váº­y hÃ¬nh chiáº¿u cá»§a cÃ¡c Ä‘iá»ƒm náº±m trÃªn Ä‘Æ°á»ng tháº³ng nÃ y váº«n thuá»™c khÃ´ng gian 2 chiá»u ban Ä‘áº§u. NhÆ°ng khi sá»­ dá»¥ng thÆ° viá»‡n sklearn Ä‘á»ƒ fit dá»¯ liá»‡u vÃ  transform táº­p X thÃ¬ káº¿t quáº£ chá»‰ lÃ  cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u 1 chiá»u - Ä‘iá»u nÃ y Ä‘Ãºng vá»›i lÃ½ thuyáº¿t anh Tiá»‡p viáº¿t ráº±ng chiá»u cá»§a ko gian má»›i luÃ´n <= C-1 (C lÃ  sá»‘ class). Váº­y cÃ³ má»‘i liÃªn há»‡ nÃ o giá»¯a cÃ¡c hÃ¬nh chiáº¿u vÃ  káº¿t quáº£ transform bÃªn dÆ°á»›i nhÆ° em vá»«a trÃ¬nh bÃ y áº¡.
2. ma tráº­n w tÃ¬m Ä‘Æ°á»£c á»Ÿ Ä‘Ã¢y lÃ  má»™t bá»™ há»‡ sá»‘ biá»ƒu diá»…n cho má»™t Ä‘Æ°á»ng tháº³ng hay nÃ³ lÃ  1 Ä‘iá»ƒm thuá»™c Ä‘Æ°á»ng tháº³ng tÃ¬m Ä‘Æ°á»£c áº¡.
Em cáº£m Æ¡n vÃ  ráº¥t muá»‘n Ä‘Æ°á»£c giáº£i Ä‘Ã¡p tháº¯c máº¯c.","Em Ä‘ang cÃ³ má»™t sá»‘ tháº¯c máº¯c vá» pháº§n Linear discriminant analysis (LDA) trong cuá»‘n sÃ¡ch ML cÆ¡ báº£n. Mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ giáº£i thÃ¡p tháº¯c máº¯c cá»§a cÃ¡c anh chá»‹ trong nhÃ³m áº¡. 1. VÃ­ dá»¥ táº­p dá»¯ liá»‡u gá»“m 2 lá»›p (xanh vÃ  Ä‘á») thÃ¬ thuáº­t toÃ¡n LDA sáº½ tÃ¬m má»™t Ä‘Æ°á»ng tháº³ng Ä‘á»ƒ khi chiáº¿u cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u lÃªn thÃ¬ sáº½ Ä‘Æ°á»£c cÃ¡c hÃ¬nh chiáº¿u cá»§a 2 lá»›p nÃ y phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh (linearly separable), nhÆ° váº­y hÃ¬nh chiáº¿u cá»§a cÃ¡c Ä‘iá»ƒm náº±m trÃªn Ä‘Æ°á»ng tháº³ng nÃ y váº«n thuá»™c khÃ´ng gian 2 chiá»u ban Ä‘áº§u. NhÆ°ng khi sá»­ dá»¥ng thÆ° viá»‡n sklearn Ä‘á»ƒ fit dá»¯ liá»‡u vÃ  transform táº­p X thÃ¬ káº¿t quáº£ chá»‰ lÃ  cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u 1 chiá»u - Ä‘iá»u nÃ y Ä‘Ãºng vá»›i lÃ½ thuyáº¿t anh Tiá»‡p viáº¿t ráº±ng chiá»u cá»§a ko gian má»›i luÃ´n <= C-1 (C lÃ  sá»‘ class). Váº­y cÃ³ má»‘i liÃªn há»‡ nÃ o giá»¯a cÃ¡c hÃ¬nh chiáº¿u vÃ  káº¿t quáº£ transform bÃªn dÆ°á»›i nhÆ° em vá»«a trÃ¬nh bÃ y áº¡. 2. ma tráº­n w tÃ¬m Ä‘Æ°á»£c á»Ÿ Ä‘Ã¢y lÃ  má»™t bá»™ há»‡ sá»‘ biá»ƒu diá»…n cho má»™t Ä‘Æ°á»ng tháº³ng hay nÃ³ lÃ  1 Ä‘iá»ƒm thuá»™c Ä‘Æ°á»ng tháº³ng tÃ¬m Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n vÃ  ráº¥t muá»‘n Ä‘Æ°á»£c giáº£i Ä‘Ã¡p tháº¯c máº¯c.",,,,,
"Em chÃ o mng, hiá»‡n táº¡i em muá»‘n tÃ¬m hiá»ƒu vá» á»©ng dá»¥ng cá»§a PCA trong há»“i quy tuyáº¿n tÃ­nh em muá»‘n tham kháº£o Ã½ kiáº¿n vÃ  xin má»™t sá»‘ tÃ i liá»‡u liÃªn quan Ä‘Æ°á»£c khÃ´ng. Em cÃ¡m Æ¡n ^^","Em chÃ o mng, hiá»‡n táº¡i em muá»‘n tÃ¬m hiá»ƒu vá» á»©ng dá»¥ng cá»§a PCA trong há»“i quy tuyáº¿n tÃ­nh em muá»‘n tham kháº£o Ã½ kiáº¿n vÃ  xin má»™t sá»‘ tÃ i liá»‡u liÃªn quan Ä‘Æ°á»£c khÃ´ng. Em cÃ¡m Æ¡n ^^",,,,,
"Em chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn Ä‘ang lÃ m Ä‘á» tÃ i vá» ""Sá»­a lá»—i chÃ­nh táº£ tiáº¿ng Viá»‡t"" cÃ³ xÃ©t Ä‘áº¿n ngá»¯ cáº£nh cá»§a tá»« trong cÃ¢u. Em Ä‘Ã£ cháº¡y thá»­ nghiá»‡m vá»›i SerpAPI cá»§a google, SymSpell (cáº§n bá»™ tá»« Ä‘iá»ƒn táº§n suáº¥t bigram nhÆ°ng mÃ  em chÆ°a tÃ¬m Ä‘Æ°á»£c), XLMRoBERTa vÃ  Hierarchical Transformer Encoders for Vietnamese Spelling Correction (https://arxiv.org/abs/2105.13578), em cÅ©ng tham kháº£o BARTpho (em lÃ m theo mÃ´ táº£ vÃ  cháº¡y trÃªn Google Colab nhÆ°ng váº«n khÃ´ng hiá»ƒu sao lÃ  trong AutoTokenizer láº¡i khÃ´ng tÃ¬m tháº¥y BartphoTokenizer). Em cÃ³ cÃ¢u há»i muá»‘n tham kháº£o Ã½ kiáº¿n cá»§a má»i ngÆ°á»i:
Em cÃ³ gáº·p lá»—i chÃ­nh táº£ trong cÃ¢u ""vi pháº¡m náº¿u klho 6ng tá»‘ giÃ¡c"". Trong Ä‘Ã³ ""klho 6ng"" lÃ  tá»« mong muá»‘n sá»­a lá»—i chÃ­nh táº£ thÃ nh tá»« ""khÃ´ng"". Em cÃ³ sá»­ dá»¥ng nhá»¯ng cÃ´ng cá»¥ nÃªu trÃªn vÃ  theo nhÆ° em tÃ¬m hiá»ƒu vÃ  cháº¡y thá»­ nghiá»‡m thÃ¬ há» phÃ¡t hiá»‡n vÃ  correction cho tá»«ng tá»« ""klho"" vÃ  ""6ng"". CÃ¢u há»i cá»§a em lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xá»­ lÃ½ cho váº¥n Ä‘á» nÃ y chÆ°a áº¡, hay cÃ³ thá»ƒ gá»£i Ã½ cho em hÆ°á»›ng Ä‘á»ƒ xá»­ lÃ½ Ä‘Æ°á»£c khÃ´ng áº¡?
P/s: Em cÅ©ng muá»‘n xin má»i ngÆ°á»i thÃªm tÃ i liá»‡u tham kháº£o cá»§a má»i ngÆ°á»i vá» váº¥n Ä‘á» ""Sá»­a lá»—i chÃ­nh táº£ tiáº¿ng Viá»‡t""
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian!","Em chÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn Ä‘ang lÃ m Ä‘á» tÃ i vá» ""Sá»­a lá»—i chÃ­nh táº£ tiáº¿ng Viá»‡t"" cÃ³ xÃ©t Ä‘áº¿n ngá»¯ cáº£nh cá»§a tá»« trong cÃ¢u. Em Ä‘Ã£ cháº¡y thá»­ nghiá»‡m vá»›i SerpAPI cá»§a google, SymSpell (cáº§n bá»™ tá»« Ä‘iá»ƒn táº§n suáº¥t bigram nhÆ°ng mÃ  em chÆ°a tÃ¬m Ä‘Æ°á»£c), XLMRoBERTa vÃ  Hierarchical Transformer Encoders for Vietnamese Spelling Correction (https://arxiv.org/abs/2105.13578), em cÅ©ng tham kháº£o BARTpho (em lÃ m theo mÃ´ táº£ vÃ  cháº¡y trÃªn Google Colab nhÆ°ng váº«n khÃ´ng hiá»ƒu sao lÃ  trong AutoTokenizer láº¡i khÃ´ng tÃ¬m tháº¥y BartphoTokenizer). Em cÃ³ cÃ¢u há»i muá»‘n tham kháº£o Ã½ kiáº¿n cá»§a má»i ngÆ°á»i: Em cÃ³ gáº·p lá»—i chÃ­nh táº£ trong cÃ¢u ""vi pháº¡m náº¿u klho 6ng tá»‘ giÃ¡c"". Trong Ä‘Ã³ ""klho 6ng"" lÃ  tá»« mong muá»‘n sá»­a lá»—i chÃ­nh táº£ thÃ nh tá»« ""khÃ´ng"". Em cÃ³ sá»­ dá»¥ng nhá»¯ng cÃ´ng cá»¥ nÃªu trÃªn vÃ  theo nhÆ° em tÃ¬m hiá»ƒu vÃ  cháº¡y thá»­ nghiá»‡m thÃ¬ há» phÃ¡t hiá»‡n vÃ  correction cho tá»«ng tá»« ""klho"" vÃ  ""6ng"". CÃ¢u há»i cá»§a em lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xá»­ lÃ½ cho váº¥n Ä‘á» nÃ y chÆ°a áº¡, hay cÃ³ thá»ƒ gá»£i Ã½ cho em hÆ°á»›ng Ä‘á»ƒ xá»­ lÃ½ Ä‘Æ°á»£c khÃ´ng áº¡? P/s: Em cÅ©ng muá»‘n xin má»i ngÆ°á»i thÃªm tÃ i liá»‡u tham kháº£o cá»§a má»i ngÆ°á»i vá» váº¥n Ä‘á» ""Sá»­a lá»—i chÃ­nh táº£ tiáº¿ng Viá»‡t"" Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian!",,,,,
ChÃ o má»i ngÆ°á»i. E cÃ³ cÃ¢u há»i nhÆ° sau. Hnay e cÃ³ tÃ¬m hiá»ƒu vá» khÃ¡i niá»‡m lÃ  Tied bias vÃ  Untied bias dÃ¹ng Ä‘á»ƒ add bias cho CNN. NhÆ°ng thá»±c sá»± chÆ°a hiá»ƒu rÃµ láº¯m. Ai cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp e Ä‘Æ°á»£c khÃ´ng áº¡.,ChÃ o má»i ngÆ°á»i. E cÃ³ cÃ¢u há»i nhÆ° sau. Hnay e cÃ³ tÃ¬m hiá»ƒu vá» khÃ¡i niá»‡m lÃ  Tied bias vÃ  Untied bias dÃ¹ng Ä‘á»ƒ add bias cho CNN. NhÆ°ng thá»±c sá»± chÆ°a hiá»ƒu rÃµ láº¯m. Ai cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp e Ä‘Æ°á»£c khÃ´ng áº¡.,,,,,
"Hi everyone, há»“i 2018, FPT AI public 1 dataset speech 30 giá» Ä‘Ã£ qua xá»­ lÃ½, giá» mÃ¬nh tÃ¬m láº¡i khÃ´ng tháº¥y Ä‘Ã¢u ná»¯a. Trong nhÃ³m ai cÃ²n lÆ°u cho mÃ¬nh xin láº¡i vá»›i. Many thanks","Hi everyone, há»“i 2018, FPT AI public 1 dataset speech 30 giá» Ä‘Ã£ qua xá»­ lÃ½, giá» mÃ¬nh tÃ¬m láº¡i khÃ´ng tháº¥y Ä‘Ã¢u ná»¯a. Trong nhÃ³m ai cÃ²n lÆ°u cho mÃ¬nh xin láº¡i vá»›i. Many thanks",,,,,
"Hiá»‡n nay, viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng cÃ ng ngÃ y cÃ ng trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n.
HÃ£y cÃ¹ng thá»­ tÃ¬m hiá»ƒu cÃ¡c bÆ°á»›c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh Object Detection cho má»™t Ä‘á»‘i tÆ°á»£ng má»›i (gáº¥u trÃºc) dá»±a trÃªn YOLOv5 trong bÃ i hÃ´m nay.
P/S: bÃ i hÆ°á»›ng dáº«n cÃ³ kÃ¨m theo Google Colab Notebook Ä‘á»ƒ tiá»‡n cho viá»‡c tham kháº£o ğŸ™‚","Hiá»‡n nay, viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng cÃ ng ngÃ y cÃ ng trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. HÃ£y cÃ¹ng thá»­ tÃ¬m hiá»ƒu cÃ¡c bÆ°á»›c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh Object Detection cho má»™t Ä‘á»‘i tÆ°á»£ng má»›i (gáº¥u trÃºc) dá»±a trÃªn YOLOv5 trong bÃ i hÃ´m nay. P/S: bÃ i hÆ°á»›ng dáº«n cÃ³ kÃ¨m theo Google Colab Notebook Ä‘á»ƒ tiá»‡n cho viá»‡c tham kháº£o",,,,,
ChÃ o má»i ngÆ°á»i. Cho em há»i khÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai trong forum mÃ¬nh Ä‘Ã£ tá»«ng thÃ nh cÃ´ng trong viá»‡c convert model resnet tá»« Pytorch sang TensorRT chÆ°a áº¡?,ChÃ o má»i ngÆ°á»i. Cho em há»i khÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai trong forum mÃ¬nh Ä‘Ã£ tá»«ng thÃ nh cÃ´ng trong viá»‡c convert model resnet tá»« Pytorch sang TensorRT chÆ°a áº¡?,,,,,
"Má»i ngÆ°á»i cho em há»i lÃ  khi clone má»™t dá»± Ã¡n tá»« github vá» mÃ  dá»± Ã¡n Ä‘áº¥y sá»­ dá»¥ng tensorflow 1x, mÃ¬nh nÃªn Æ°u tiÃªn sá»­ dá»¥ng luÃ´n tensorflow 1x nhÆ° cá»§a tÃ¡c giáº£ vÃ  bá»• sung thÃªm cÃ¡c tÃ­nh nÄƒng Ä‘á»ƒ phÃ¹ há»£p vá»›i bÃ i toÃ¡n cá»§a mÃ¬nh hay lÃ  sá»­ dá»¥ng tensorflow phiÃªn báº£n má»›i nháº¥t áº¡. Em Ä‘Ã£ sá»­ dá»¥ng tensorflow 2.6.0 thay cho phiÃªn báº£n tensorflow 1x nhÆ°ng pháº£i sá»­a láº¡i ráº¥t nhiá»u trong mÃ£ nguá»“n áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡","Má»i ngÆ°á»i cho em há»i lÃ  khi clone má»™t dá»± Ã¡n tá»« github vá» mÃ  dá»± Ã¡n Ä‘áº¥y sá»­ dá»¥ng tensorflow 1x, mÃ¬nh nÃªn Æ°u tiÃªn sá»­ dá»¥ng luÃ´n tensorflow 1x nhÆ° cá»§a tÃ¡c giáº£ vÃ  bá»• sung thÃªm cÃ¡c tÃ­nh nÄƒng Ä‘á»ƒ phÃ¹ há»£p vá»›i bÃ i toÃ¡n cá»§a mÃ¬nh hay lÃ  sá»­ dá»¥ng tensorflow phiÃªn báº£n má»›i nháº¥t áº¡. Em Ä‘Ã£ sá»­ dá»¥ng tensorflow 2.6.0 thay cho phiÃªn báº£n tensorflow 1x nhÆ°ng pháº£i sá»­a láº¡i ráº¥t nhiá»u trong mÃ£ nguá»“n áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,,,
Dáº¡ em chÃ o má»i ngÆ°á»i. E Ä‘ang tÃ¬m hiá»ƒu vá» R studio. Anh/chá»‹ cÃ³ thá»ƒ giÃºp em phÃ¢n nhá» dá»¯ liá»‡u trong táº­p training thÃ nh 2 táº­p con vá»›i áº¡. (Kiá»ƒu nhÆ° chia nhiá»u lá»›p tá»« bá»™ dá»¯ liá»‡u ban Ä‘áº§u). Em cáº£m Æ¡n áº¡,Dáº¡ em chÃ o má»i ngÆ°á»i. E Ä‘ang tÃ¬m hiá»ƒu vá» R studio. Anh/chá»‹ cÃ³ thá»ƒ giÃºp em phÃ¢n nhá» dá»¯ liá»‡u trong táº­p training thÃ nh 2 táº­p con vá»›i áº¡. (Kiá»ƒu nhÆ° chia nhiá»u lá»›p tá»« bá»™ dá»¯ liá»‡u ban Ä‘áº§u). Em cáº£m Æ¡n áº¡,,,,,
"ChÃ o cáº£ nhÃ , em xin tá»•ng káº¿t quÃ¡ trÃ¬nh lÃ m OCR báº±ng Tesseract vÃ  nháº­n Ä‘Æ°á»£c káº¿t quáº£ ko tá»‘t ah. Em Ä‘Ã£ thá»­ nháº­ n dáº¡ng tiáº¿ng Viá»‡t báº±ng cáº£ bá»™ font train sáºµn cá»§a VietOCR, font train riÃªng cua em nhÆ°ng táº¥t cáº£ Ä‘á»u nháº­n khÃ´ng thÃ nh cÃ´ng.
BÃ¡c nÃ o lÃ m mÃ³n nÃ y cho em há»i :
CÃ³ pháº£i em cÃ³ váº¥n Ä‘á» vá» threshold khÃ´ng ah? Chá»© em ko nghÄ© Tesseract nháº­n ngu nhÆ° tháº¿.
CÃ³ bÃ¡c nÃ o cÃ³ phÆ°Æ¡ng Ã¡n OCR nÃ o ngon hÆ¡n cho em cÃ¡i keyword em search Ä‘Æ°á»£c khÃ´ng ah?
Em Ä‘Ã£ cÃ i cÃ¡i CTC-OCR nhÆ°ng khÃ´ng thÃ nh cÃ´ng ah.
áº¢nh minh há»a: LÃ  áº£nh cÃ³ liÃªn quan, áº£nh 1 lÃ  áº£nh em trÃ­ch xuáº¥t tá»« áº£nh gá»‘c, chuyá»ƒn sang grayscale. áº¢nh 2 lÃ  em Ã¡p threshold Ä‘á»ƒ láº¥y chá»¯ ah.

// Em Ä‘Ã£ xÃ³a bÃ i cÅ© Ä‘á»ƒ trÃ¡nh loÃ£ng diá»…n Ä‘Ã n. ","ChÃ o cáº£ nhÃ , em xin tá»•ng káº¿t quÃ¡ trÃ¬nh lÃ m OCR báº±ng Tesseract vÃ  nháº­n Ä‘Æ°á»£c káº¿t quáº£ ko tá»‘t ah. Em Ä‘Ã£ thá»­ nháº­ n dáº¡ng tiáº¿ng Viá»‡t báº±ng cáº£ bá»™ font train sáºµn cá»§a VietOCR, font train riÃªng cua em nhÆ°ng táº¥t cáº£ Ä‘á»u nháº­n khÃ´ng thÃ nh cÃ´ng. BÃ¡c nÃ o lÃ m mÃ³n nÃ y cho em há»i : CÃ³ pháº£i em cÃ³ váº¥n Ä‘á» vá» threshold khÃ´ng ah? Chá»© em ko nghÄ© Tesseract nháº­n ngu nhÆ° tháº¿. CÃ³ bÃ¡c nÃ o cÃ³ phÆ°Æ¡ng Ã¡n OCR nÃ o ngon hÆ¡n cho em cÃ¡i keyword em search Ä‘Æ°á»£c khÃ´ng ah? Em Ä‘Ã£ cÃ i cÃ¡i CTC-OCR nhÆ°ng khÃ´ng thÃ nh cÃ´ng ah. áº¢nh minh há»a: LÃ  áº£nh cÃ³ liÃªn quan, áº£nh 1 lÃ  áº£nh em trÃ­ch xuáº¥t tá»« áº£nh gá»‘c, chuyá»ƒn sang grayscale. áº¢nh 2 lÃ  em Ã¡p threshold Ä‘á»ƒ láº¥y chá»¯ ah. // Em Ä‘Ã£ xÃ³a bÃ i cÅ© Ä‘á»ƒ trÃ¡nh loÃ£ng diá»…n Ä‘Ã n.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n nhÃ³m em Ä‘ang tÃ¬m hiá»ƒu vá» nháº­n dáº¡ng phÆ°Æ¡ng ngá»¯ tiáº¿ng Viá»‡t thÃ¬ biáº¿t Ä‘Æ°á»£c má»™t bá»™ dá»¯ liá»‡u tÃªn VDSPEC nhÆ°ng tÃ¬m ráº¥t nhiá»u nÆ¡i trÃªn máº¡ng nhÆ°ng khÃ´ng cÃ³. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m vá» bá»™ dá»¯ liá»‡u hoáº·c Ä‘Ã£ tÃ¬m hiá»ƒu cÃ³ thá»ƒ cho em xin thÃªm thÃ´ng tin. Cáº£m Æ¡n má»i ngÆ°á»i trÆ°á»›c. ğŸ˜","ChÃ o má»i ngÆ°á»i, hiá»‡n nhÃ³m em Ä‘ang tÃ¬m hiá»ƒu vá» nháº­n dáº¡ng phÆ°Æ¡ng ngá»¯ tiáº¿ng Viá»‡t thÃ¬ biáº¿t Ä‘Æ°á»£c má»™t bá»™ dá»¯ liá»‡u tÃªn VDSPEC nhÆ°ng tÃ¬m ráº¥t nhiá»u nÆ¡i trÃªn máº¡ng nhÆ°ng khÃ´ng cÃ³. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m vá» bá»™ dá»¯ liá»‡u hoáº·c Ä‘Ã£ tÃ¬m hiá»ƒu cÃ³ thá»ƒ cho em xin thÃªm thÃ´ng tin. Cáº£m Æ¡n má»i ngÆ°á»i trÆ°á»›c.",,,,,
"ChÃ o ace,
MÃ¬nh cÃ³ táº­p train vÃ  test Ä‘Ã£ chia sáºµn, há»c dÃ¹ng MLP há»“i quy. Giá» muá»‘n váº½ train loss vÃ  test loss. Trong sklearn cÃ³ hÆ°á»›ng dáº«n, nhÆ°ng chá»‰ Ã¡p dá»¥ng vá»›i train_test_split chá»© mÃ¬nh chÆ°a tÃ¬m Ä‘Æ°á»£c váº½ test loss vá»›i táº­p test riÃªng.
Xin cÃ¡c cao nhÃ¢n giÃºp Ä‘á»¡, mÃ¬nh cÃ¡m Æ¡n!","ChÃ o ace, MÃ¬nh cÃ³ táº­p train vÃ  test Ä‘Ã£ chia sáºµn, há»c dÃ¹ng MLP há»“i quy. Giá» muá»‘n váº½ train loss vÃ  test loss. Trong sklearn cÃ³ hÆ°á»›ng dáº«n, nhÆ°ng chá»‰ Ã¡p dá»¥ng vá»›i train_test_split chá»© mÃ¬nh chÆ°a tÃ¬m Ä‘Æ°á»£c váº½ test loss vá»›i táº­p test riÃªng. Xin cÃ¡c cao nhÃ¢n giÃºp Ä‘á»¡, mÃ¬nh cÃ¡m Æ¡n!",,,,,
"BÃ i khÃ´ng liÃªn quan Ä‘áº¿n machine learning mÃ  liÃªn quan Ä‘áº¿n cÃ¡ch Ä‘áº·t cÃ¢u há»i Ä‘áº·c biá»‡t khi nháº¯n tin riÃªng.
CÃ¡c báº¡n Ä‘á»«ng Ä‘áº·t cÃ¢u há»i â€œcÃ³ ai biáº¿t cÃ¡i x nÃ y khÃ´ng em há»iâ€ trÃªn group hoáº·c nháº¯n riÃªng mÃ¬nh há»i â€œanh Æ¡i em há»i cÃ¡i nÃ y Ä‘Æ°á»£c khÃ´ngâ€. NÃªn tÃ´n trá»ng thá»i gian cá»§a chÃ­nh mÃ¬nh vÃ  ngÆ°á»i Ä‘Æ°á»£c há»i, trá»« khi cÃ³ chuyá»‡n tháº§m kÃ­n.","BÃ i khÃ´ng liÃªn quan Ä‘áº¿n machine learning mÃ  liÃªn quan Ä‘áº¿n cÃ¡ch Ä‘áº·t cÃ¢u há»i Ä‘áº·c biá»‡t khi nháº¯n tin riÃªng. CÃ¡c báº¡n Ä‘á»«ng Ä‘áº·t cÃ¢u há»i â€œcÃ³ ai biáº¿t cÃ¡i x nÃ y khÃ´ng em há»iâ€ trÃªn group hoáº·c nháº¯n riÃªng mÃ¬nh há»i â€œanh Æ¡i em há»i cÃ¡i nÃ y Ä‘Æ°á»£c khÃ´ngâ€. NÃªn tÃ´n trá»ng thá»i gian cá»§a chÃ­nh mÃ¬nh vÃ  ngÆ°á»i Ä‘Æ°á»£c há»i, t rá»« khi cÃ³ chuyá»‡n tháº§m kÃ­n.",,,,,
ÄÃ¢y lÃ  buá»•i nÃ³i chuyá»‡n cá»§a mÃ¬nh ngÃ y má»›i Ä‘Ã¢y liÃªn quan Ä‘áº¿n dá»¯ liá»‡u vÃ  cÃ¡c cÃ´ng viá»‡c liÃªn quan. Hy vá»ng cÃ³ Ã­ch cho nhiá»u báº¡n.,ÄÃ¢y lÃ  buá»•i nÃ³i chuyá»‡n cá»§a mÃ¬nh ngÃ y má»›i Ä‘Ã¢y liÃªn quan Ä‘áº¿n dá»¯ liá»‡u vÃ  cÃ¡c cÃ´ng viá»‡c liÃªn quan. Hy vá»ng cÃ³ Ã­ch cho nhiá»u báº¡n.,,,,,
"ChÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c Ä‘áº¿n pháº§n chatbot Rasa káº¿t ná»‘i vá»›i Zalo nÃªn máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng cÃ¡c báº¡n má»›i há»c há»i vá» chatbot.
Mong giÃºp Ä‘Æ°á»£c má»i ngÆ°á»i chÃºt Ã­t. Xin cáº£m Æ¡n cáº£ nhÃ !",ChÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c Ä‘áº¿n pháº§n chatbot Rasa káº¿t ná»‘i vá»›i Zalo nÃªn máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng cÃ¡c báº¡n má»›i há»c há»i vá» chatbot. Mong giÃºp Ä‘Æ°á»£c má»i ngÆ°á»i chÃºt Ã­t. Xin cáº£m Æ¡n cáº£ nhÃ !,,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang nghiÃªn cá»©u vá» speech to text nhÆ°ng Ä‘ang gáº·p váº¥n Ä‘á» vá» data
MÃ¬nh cÃ³ tÃ¬m hiá»ƒu vá» bá»™ dá»¯ liá»‡u VDSPEC trong paper ""Automatic identification of Vietnamese speech"" cá»§a TS. Pháº¡m Ngá»c HÆ°ng.
KhÃ´ng biáº¿t má»i ngÆ°á»i trong group cÃ³ ai biáº¿t cÃ¡ch Ä‘á»ƒ xin bá»™ dá»¯ liá»‡u nÃ y khÃ´ng áº¡
thanks all !!!","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang nghiÃªn cá»©u vá» speech to text nhÆ°ng Ä‘ang gáº·p váº¥n Ä‘á» vá» data MÃ¬nh cÃ³ tÃ¬m hiá»ƒu vá» bá»™ dá»¯ liá»‡u VDSPEC trong paper ""Automatic identification of Vietnamese speech"" cá»§a TS. Pháº¡m Ngá»c HÆ°ng. KhÃ´ng biáº¿t má»i ngÆ°á»i trong group cÃ³ ai biáº¿t cÃ¡ch Ä‘á»ƒ xin bá»™ dá»¯ liá»‡u nÃ y khÃ´ng áº¡ thanks all !!!",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Má»i ngÆ°á»i cho em há»i trong nhÃ³m Ä‘Ã£ tá»«ng cÃ³ ai viáº¿t mail Ä‘á»ƒ xin code cá»§a má»™t bÃ i bÃ¡o nÃ o Ä‘Ã³ chÆ°a áº¡. Náº¿u cÃ³ má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin Ã­t kinh nghiá»‡m vÃ  vÄƒn máº«u khÃ´ng áº¡, vÃ  xÃ¡c suáº¥t thÃ nh cÃ´ng lÃ  bao nhiÃªu áº¡. Do pháº§n Ä‘á» tÃ i cá»§a e thÃ¬ tháº¥y chá»‰ cÃ³ má»™t sá»‘ Ã­t paper chá»© khÃ´ng nhiá»u.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i áº¡ Má»i ngÆ°á»i cho em há»i trong nhÃ³m Ä‘Ã£ tá»«ng cÃ³ ai viáº¿t mail Ä‘á»ƒ xin code cá»§a má»™t bÃ i bÃ¡o nÃ o Ä‘Ã³ chÆ°a áº¡. Náº¿u cÃ³ má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin Ã­t kinh nghiá»‡m vÃ  vÄƒn máº«u khÃ´ng áº¡, vÃ  xÃ¡c suáº¥t thÃ nh cÃ´ng lÃ  bao nhiÃªu áº¡. Do pháº§n Ä‘á» tÃ i cá»§a e thÃ¬ tháº¥y chá»‰ cÃ³ má»™t sá»‘ Ã­t paper chá»© khÃ´ng nhiá»u. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"CÃ¢u há»i vá» thiáº¿t káº¿ há»‡ thá»‘ng human detection (surveillance camera) trong cÃ´ng ty.
ChÃ o cáº£ nhÃ , em Ä‘ang cáº§n xá»­ lÃ½ bÃ i toÃ¡n human detection (object detection) sá»­ dá»¥ng cÃ´ng nghá»‡ xá»­ lÃ½ áº£nh object detection (yolo, ssd, rcnn, ...). á» trong pháº¡m vi cÃ¡c phÃ²ng cá»§a tÃ²a nhÃ  cÃ´ng ty (phÃ²ng há»p, phÃ²ng Äƒn, phÃ²ng sinh hoáº¡t, hÃ nh lang,...). YÃªu cáº§u chÃ­nh xÃ¡c khÃ´ng cáº§n tuyá»‡t Ä‘á»‘i, chá»‰ cáº§n Æ°á»›c lÆ°á»£ng máº­t Ä‘á»™ ngÆ°á»i trong cÃ¡c khung giá» hÃ nh chÃ­nh.
BÃ i toÃ¡n cá»§a em liÃªn quan Ä‘áº¿n viá»‡c engineer cÃ¡c model vÃ  thiáº¿t káº¿ há»‡ thá»‘ng phÃ¹ há»£p Ä‘á»ƒ deploy, do chÆ°a cÃ³ kinh nghiá»‡m vÃ  google thÃ¬ quÃ¡ nhiá»u thÃ´ng tin nÃªn em muá»‘n há»i kinh nghiá»‡m trong group cá»§a mÃ¬nh.
Giá»¯a edge (jetson, ncs2, coral,...), on-premise server (mÃ¡y chá»§ tá»± mua) vÃ  public server (aws, gcp, azure,...) thÃ¬ giÃ¡ cáº£ nhÆ° tháº¿ nÃ o vÃ  lá»±a chá»n nÃ o lÃ  há»£p lÃ½ cho há»‡ thá»‘ng nhá», vá»«a, lá»›n?
Náº¿u team chÆ°a cÃ³ kinh nghiá»‡m thÃ¬ nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u? Em Ä‘á»‹nh sáº½ sá»­ dá»¥ng free public cloud Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ trÆ°á»›c khi quyáº¿t Ä‘á»‹nh Ä‘áº§u tÆ° nhÆ°ng sá»£ khÃ´ng kiá»ƒm soÃ¡t Ä‘Æ°á»£c do khÃ´ng cÃ³ kinh nghiá»‡m sáº½ bá»‹ charge phÃ­.
Cáº£m Æ¡n anh Tiá»‡p Ä‘Ã£ duyá»‡t bÃ i.
#objectdetection #yolo #GPU #deeplearning #systemengineer","CÃ¢u há»i vá» thiáº¿t káº¿ há»‡ thá»‘ng human detection (surveillance camera) trong cÃ´ng ty. ChÃ o cáº£ nhÃ , em Ä‘ang cáº§n xá»­ lÃ½ bÃ i toÃ¡n human detection (object detection) sá»­ dá»¥ng cÃ´ng nghá»‡ xá»­ lÃ½ áº£nh object detection (yolo, ssd, rcnn, ...). á» trong pháº¡m vi cÃ¡c phÃ²ng cá»§a tÃ²a nhÃ  cÃ´ng ty (phÃ²ng há»p, phÃ²ng Äƒn, phÃ²ng sinh hoáº¡t, hÃ nh lang,...). YÃªu cáº§u chÃ­nh xÃ¡c khÃ´ng cáº§n tuyá»‡t Ä‘á»‘i, chá»‰ cáº§n Æ°á»›c lÆ°á»£ng máº­t Ä‘á»™ ngÆ°á»i trong cÃ¡c khung giá» hÃ nh chÃ­nh. BÃ i toÃ¡n cá»§a em liÃªn quan Ä‘áº¿n viá»‡c engineer cÃ¡c model vÃ  thiáº¿t káº¿ há»‡ thá»‘ng phÃ¹ há»£p Ä‘á»ƒ deploy, do chÆ°a cÃ³ kinh nghiá»‡m vÃ  google thÃ¬ quÃ¡ nhiá»u thÃ´ng tin nÃªn em muá»‘n há»i kinh nghiá»‡m trong group cá»§a mÃ¬nh. Giá»¯a edge (jetson, ncs2, coral,...), on-premise server (mÃ¡y chá»§ tá»± mua) vÃ  public server (aws, gcp, azure,...) thÃ¬ giÃ¡ cáº£ nhÆ° tháº¿ nÃ o vÃ  lá»±a chá»n nÃ o lÃ  há»£p lÃ½ cho há»‡ thá»‘ng nhá», vá»«a, lá»›n? Náº¿u team chÆ°a cÃ³ kinh nghiá»‡m thÃ¬ nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u? Em Ä‘á»‹nh sáº½ sá»­ dá»¥ng free public cloud Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ trÆ°á»›c khi quyáº¿t Ä‘á»‹nh Ä‘áº§u tÆ° nhÆ°ng sá»£ khÃ´ng kiá»ƒm soÃ¡t Ä‘Æ°á»£c do khÃ´ng cÃ³ kinh nghiá»‡m sáº½ bá»‹ charge phÃ­. Cáº£m Æ¡n anh Tiá»‡p Ä‘Ã£ duyá»‡t bÃ i.",#objectdetection	#yolo	#GPU	#deeplearning	#systemengineer,,,,
"NgÃ y mai mÃ¬nh cÃ¹ng cÃ¡c chuyÃªn gia bÃªn FSOFT AI chia sáº» vá»›i cÃ¡c báº¡n vá» cÃ´ng viá»‡c vÃ  cÃ¡c ká»¹ nÄƒng cáº§n thiáº¿t trong ngÃ nh dá»¯ liá»‡u.
Má»i cÃ¡c báº¡n tham gia vÃ  Ä‘áº·t cÃ¢u há»i.
CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm thÃ´ng tin trong post gá»‘c.",NgÃ y mai mÃ¬nh cÃ¹ng cÃ¡c chuyÃªn gia bÃªn FSOFT AI chia sáº» vá»›i cÃ¡c báº¡n vá» cÃ´ng viá»‡c vÃ  cÃ¡c ká»¹ nÄƒng cáº§n thiáº¿t trong ngÃ nh dá»¯ liá»‡u. Má»i cÃ¡c báº¡n tham gia vÃ  Ä‘áº·t cÃ¢u há»i. CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm thÃ´ng tin trong post gá»‘c.,,,,,
"CÃ³ láº½ trong forum Machine Learning CÆ¡ báº£n cÃ³ nhiá»u ngÆ°á»i quan tÃ¢m tá»›i Graph Neural Networks vÃ  cÃ¡c á»©ng dá»¥ng cá»§a nÃ³. TrÃªn thá»±c táº¿ cÃ³ nhiá»u bÃ i toÃ¡n khÃ´ng thá»ƒ giáº£i tá»‘t náº¿u dÃ¹ng cÃ¡c models nhÆ° CNN, RNN, LSTM, hay Transformers. Do váº­y GNN vÃ  cÃ¡c biáº¿n thá»ƒ cá»§a nÃ³ cÃ³ thá»ƒ sáº½ lÃ  giáº£i phÃ¡p! Tiá»‡n Ä‘Ã¢y mÃ¬nh tháº¥y cÃ³ bÃ i giá»›i thiá»‡u tá»•ng quan khÃ¡ thÃº vá»‹ vá» GNN táº¡i Ä‘Ã¢y https://distill.pub/2021/gnn-intro/. Hi vá»ng nÃ³ giÃºp Ã­ch vá»›i má»i ngÆ°á»i khi má»Ÿ rá»™ng kiáº¿n thá»©c. Náº¿u báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ tham kháº£o Codebase cÃ³ tÃªn DGL, nÃ³ há»— trá»£ cho cáº£ TensorFlow, PyTorch vÃ  MXNet, nhÆ°ng chÆ°a tháº¥y há»— trá»£ JAX. HÆ°á»›ng dáº«n sá»­ dá»¥ng DGL táº¡i Ä‘Ã¢y https://docs.dgl.ai/tutorials/blitz/index.html. BÃªn cáº¡nh thÆ° viá»‡n DGL, cÃ²n 2 thÆ° viá»‡n khÃ¡c lÃ  torch-geometric, vÃ  cÃ³ láº§n mÃ¬nh giá»›i thiá»‡u thÆ° viá»‡n torchdrug (do nhÃ³m NC á»Ÿ MILA viáº¿t).","CÃ³ láº½ trong forum Machine Learning CÆ¡ báº£n cÃ³ nhiá»u ngÆ°á»i quan tÃ¢m tá»›i Graph Neural Networks vÃ  cÃ¡c á»©ng dá»¥ng cá»§a nÃ³. TrÃªn thá»±c táº¿ cÃ³ nhiá»u bÃ i toÃ¡n khÃ´ng thá»ƒ giáº£i tá»‘t náº¿u dÃ¹ng cÃ¡c models nhÆ° CNN, RNN, LSTM, hay Transformers. Do váº­y GNN vÃ  cÃ¡c biáº¿n thá»ƒ cá»§a nÃ³ cÃ³ thá»ƒ sáº½ lÃ  giáº£i phÃ¡p! Tiá»‡n Ä‘Ã¢y mÃ¬nh tháº¥y cÃ³ bÃ i giá»›i thiá»‡u tá»•ng quan khÃ¡ thÃº vá»‹ vá» GNN táº¡i Ä‘Ã¢y https://distill.pub/2021/gnn-intro/. Hi vá»ng nÃ³ giÃºp Ã­ch vá»›i má»i ngÆ°á»i khi má»Ÿ rá»™ng kiáº¿n thá»©c. Náº¿u báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ tham kháº£o Codebase cÃ³ tÃªn DGL, nÃ³ há»— trá»£ cho cáº£ TensorFlow, PyTorch vÃ  MXNet, nhÆ°ng chÆ°a tháº¥y há»— trá»£ JAX. HÆ°á»›ng dáº«n sá»­ dá»¥ng DGL táº¡i Ä‘Ã¢y https://docs.dgl.ai/tutorials/blitz/index.html. BÃªn cáº¡nh thÆ° viá»‡n DGL, cÃ²n 2 thÆ° viá»‡n khÃ¡c lÃ  torch-geometric, vÃ  cÃ³ láº§n mÃ¬nh giá»›i thiá»‡u thÆ° viá»‡n torchdrug (do nhÃ³m NC á»Ÿ MILA viáº¿t).",,,,,
"ChÃ o cÃ¡c ace,
Em dÃ¹ng MLPClassifier, khi thay Ä‘á»•i cÃ¡c tham sá»‘ Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u, thÃ¬ cÃ³ hiá»‡n thÃ´ng bÃ¡o: ""The optimization hasn't converged yet"". DÃ¹ váº­y, AUC vÃ  AUPR tá»‘t hÆ¡n khi ko hiá»‡n thÃ´ng bÃ¡o Ä‘Ã³.
Cho em há»i lÃ  trÆ°á»ng há»£p nÃ o thÃ¬ thÃ¬ tá»‘t hÆ¡n áº¡, theo káº¿t quáº£ AUC vÃ  AUPR hay sao áº¡?
Em cÃ¡m Æ¡n mn!","ChÃ o cÃ¡c ace, Em dÃ¹ng MLPClassifier, khi thay Ä‘á»•i cÃ¡c tham sá»‘ Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u, thÃ¬ cÃ³ hiá»‡n thÃ´ng bÃ¡o: ""The optimization hasn't converged yet"". DÃ¹ váº­y, AUC vÃ  AUPR tá»‘t hÆ¡n khi ko hiá»‡n thÃ´ng bÃ¡o Ä‘Ã³. Cho em há»i lÃ  trÆ°á»ng há»£p nÃ o thÃ¬ thÃ¬ tá»‘t hÆ¡n áº¡, theo káº¿t quáº£ AUC vÃ  AUPR hay sao áº¡? Em cÃ¡m Æ¡n mn!",,,,,
"Dáº¡ em chÃ o táº¥t cáº£ má»i ngÆ°á»i áº¡ , hiá»‡n táº¡i em Ä‘ang gáº·p 1 sá»‘ váº¥n Ä‘á» trong lÃºc cÃ i Ä‘áº·t thÆ° viá»‡n Tensorflow , khi cÃ i xong thÃ¬ em import vÃ o nÃ³ bÃ¡o ra lá»—i nhÆ° váº­y . Em Ä‘Ã£ thá»±c hiá»‡n fix báº±ng cÃ¡ch cÃ i Ä‘áº·t CUDA toolkit ,vv nhÆ°ng khi cÃ i CUDA toolkit thÃ¬ nÃ³ láº¡i Fail . MÃ¡y em hiá»‡n táº¡i chá»‰ cÃ³ 1 Card Onboard cá»§a Intel . KhÃ´ng biáº¿t khi cÃ i cÃ¡i thÆ° viá»‡n nÃ y nÃ³ cÃ³ cáº§n yÃªu cáº§u Card rá»i hay nhÆ° tháº¿ nÃ o khÃ´ng , em cÅ©ng má»›i Ä‘ang tÃ¬m hiá»ƒu nÃªn cáº§n sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i , cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kháº¯c phá»¥c , hoáº·c bÃ¢y giá» em nÃªn báº¯t Ä‘áº§u cÃ i láº¡i tá»« Ä‘Ã¢u áº¡ ? Em xin chÃ¢n thÃ nh cáº£m Æ¡n.","Dáº¡ em chÃ o táº¥t cáº£ má»i ngÆ°á»i áº¡ , hiá»‡n táº¡i em Ä‘ang gáº·p 1 sá»‘ váº¥n Ä‘á» trong lÃºc cÃ i Ä‘áº·t thÆ° viá»‡n Tensorflow , khi cÃ i xong thÃ¬ em import vÃ o nÃ³ bÃ¡o ra lá»—i nhÆ° váº­y . Em Ä‘Ã£ thá»±c hiá»‡n fix báº±ng cÃ¡ch cÃ i Ä‘áº·t CUDA toolkit ,vv nhÆ°ng khi cÃ i CUDA toolkit thÃ¬ nÃ³ láº¡i Fail . MÃ¡y em hiá»‡n táº¡i chá»‰ cÃ³ 1 Card Onboard cá»§a Intel . KhÃ´ng biáº¿t khi cÃ i cÃ¡i thÆ° viá»‡n nÃ y nÃ³ cÃ³ cáº§n yÃªu cáº§u Card rá»i hay nhÆ° tháº¿ nÃ o khÃ´ng , em cÅ©ng má»›i Ä‘ang tÃ¬m hiá»ƒu nÃªn cáº§n sá»± giÃºp Ä‘á»¡ cá»§a má»i ngÆ°á»i , cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kháº¯c phá»¥c , hoáº·c bÃ¢y giá» em nÃªn báº¯t Ä‘áº§u cÃ i láº¡i tá»« Ä‘Ã¢u áº¡ ? Em xin chÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
,nan,,,,,
"Xin chÃ o cÃ¡c báº¡n trong group.
MÃ¬nh Ä‘ang cÃ³ bÃ i toÃ¡n lÃ  thÃ´ng qua images Ä‘á»ƒ nháº­n diá»‡n phÃ¢n loáº¡i cÃ¡c biá»ƒn bÃ¡o giao thÃ´ng vÃ  cÃ³ thá»ƒ bÆ°á»›c tiáº¿p theo lÃ  nháº­n Ä‘á»‹nh xem cÃ¡c biá»ƒn bÃ¡o Ä‘Ã³ cÃ²n Ä‘áº¡t yÃªu cáº§u sá»­ dá»¥ng hay khÃ´ng. VÃ­ dá»¥ nhÆ° Ä‘á»™ tÆ°Æ¡ng pháº£n cÃ³ Ä‘á»§ khÃ´ng, hÃ¬nh dáº¡ng cÃ³ bá»‹ biáº¿n dáº¡ng hay khÃ´ng.,,,. MÃ¬nh chÆ°a cÃ³ kinh nghiá»‡m vá» lÄ©nh vá»±c nÃ y láº¯m ráº¥t mong má»i ngÆ°á»i chá»‰ dáº«n cho nguá»“n (cáº£ data vÃ  code/solution) Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ tham kháº£o. MÃ¬nh dÃ¹ng python.
TrÃ¢n trá»ng cáº£m Æ¡n vÃ  chÃºc má»i ngÆ°á»i má»™t tuáº§n vui váº».","Xin chÃ o cÃ¡c báº¡n trong group. MÃ¬nh Ä‘ang cÃ³ bÃ i toÃ¡n lÃ  thÃ´ng qua images Ä‘á»ƒ nháº­n diá»‡n phÃ¢n loáº¡i cÃ¡c biá»ƒn bÃ¡o giao thÃ´ng vÃ  cÃ³ thá»ƒ bÆ°á»›c tiáº¿p theo lÃ  nháº­n Ä‘á»‹nh xem cÃ¡c biá»ƒn bÃ¡o Ä‘Ã³ cÃ²n Ä‘áº¡t yÃªu cáº§u sá»­ dá»¥ng hay khÃ´ng. VÃ­ dá»¥ nhÆ° Ä‘á»™ tÆ°Æ¡ng pháº£n cÃ³ Ä‘á»§ khÃ´ng, hÃ¬nh dáº¡ng cÃ³ bá»‹ biáº¿n dáº¡ng hay khÃ´ng.,,,. MÃ¬nh chÆ°a cÃ³ kinh nghiá»‡m vá» lÄ©nh vá»±c nÃ y láº¯m ráº¥t mong má»i ngÆ°á»i chá»‰ dáº«n cho nguá»“n (cáº£ data vÃ  code/solution) Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ tham kháº£o. MÃ¬nh dÃ¹ng python. TrÃ¢n trá»ng cáº£m Æ¡n vÃ  chÃºc má»i ngÆ°á»i má»™t tuáº§n vui váº».",,,,,
"[Data Quest 3 - Advanced Labeling Technology]
â˜‘ï¸MÃ¬nh xin chia sáº» vá»›i cÃ¡c báº¡n video vÃ  cÃ¡c tÃ i liá»‡u mÃ  mÃ¬nh thá»±c hiá»‡n tuáº§n trÆ°á»›c trong mini-seminar Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi ban admin TowardDataScience vá» cÃ¡c kÄ© thuáº­t gÃ¡n nhÃ£n hiá»‡n Ä‘áº¡i trong huáº¥n luyá»‡n nhá»¯ng mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t trong há»c mÃ¡y. ÄÃ¢y lÃ  nhá»¯ng kiáº¿n thá»©c mÃ¬nh Ä‘Ã£ tá»•ng há»£p trong quÃ¡ trÃ¬nh Ä‘á»c cÃ¡c papers, blogs vÃ  theo dÃµi cÃ¡c kÃªnh khoa há»c liÃªn quan.
â˜‘ï¸Ná»™i dung chÃ­nh cá»§a buá»•i thuyáº¿t trÃ¬nh hÆ°á»›ng tá»›i ba kÄ© thuáº­t chÃ­nh giÃºp táº­n dá»¥ng nguá»“n tÃ i nguyÃªn vá» dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c gÃ¡n nhÃ£n nháº±m cá»§ng cá»‘ tÃ­nh robust cho mÃ´ hÃ¬nh. Bao gá»“m nhá»¯ng phÆ°Æ¡ng phÃ¡p sau:
1. Semi-supervised Learning: Huáº¥n luyá»‡n mÃ´ hÃ¬nh káº¿t há»£p giá»¯a há»c cÃ³ giÃ¡m sÃ¡t vÃ  khÃ´ng giÃ¡m sÃ¡t.
2. Active Learning: KÄ© thuáº­t lá»±a chá»n máº«u thÃ´ng minh cho dá»± Ã¡n há»c mÃ¡y.
3. Weak Supervision: á»¨ng dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p chuyÃªn gia vÃ  cÃ¡c mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t yáº¿u trong gÃ¡n nhÃ£n tá»± Ä‘á»™ng. VÃ­ dá»¥ demo trÃªn phÃ¢n loáº¡i ná»™i dung tá»« Snorkel AI startup.
â˜‘ï¸Äá»ƒ thuáº­n tiá»‡n cho cÃ¡c báº¡n tháº¥y Ä‘Æ°á»£c hiá»‡u quáº£ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trong viá»‡c cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh, mÃ¬nh cung cáº¥p thÃªm nhá»¯ng notebooks thá»±c hÃ nh tÆ°Æ¡ng á»©ng vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau. Hi vá»ng ráº±ng nhá»¯ng ná»™i dung tá»« buá»•i mini-seminar sáº½ mang láº¡i thÃ´ng tin há»¯u Ã­ch vÃ  gÃ³p pháº§n xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI Viá»‡t Nam vá»¯ng máº¡nh hÆ¡n.
â˜‘ï¸TÃ i liá»‡u:
- Slide: https://docs.google.com/presentation/d/1MYztes2PGiBmzYdcoeBrvLbIxRPorD4nLp-shw1K32c/edit?usp=sharing
- Active Learning:
https://colab.research.google.com/drive/1m3K9-_u468O9hA_4S-uTbbafiXAPxt86?usp=sharing
- Weak Supervision:
https://colab.research.google.com/drive/1uwO-hkIohAj0D9hgpw0S8bAS6mLACxD_?usp=sharing
- Link video:
https://www.youtube.com/watch?v=EB1gCJ6zMz4","[Data Quest 3 - Advanced Labeling Technology] MÃ¬nh xin chia sáº» vá»›i cÃ¡c báº¡n video vÃ  cÃ¡c tÃ i liá»‡u mÃ  mÃ¬nh thá»±c hiá»‡n tuáº§n trÆ°á»›c trong mini-seminar Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi ban admin TowardDataScience vá» cÃ¡c kÄ© thuáº­t gÃ¡n nhÃ£n hiá»‡n Ä‘áº¡i trong huáº¥n luyá»‡n nhá»¯ng mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t trong há»c mÃ¡y. ÄÃ¢y lÃ  nhá»¯ng kiáº¿n thá»©c mÃ¬nh Ä‘Ã£ tá»•ng há»£p trong quÃ¡ trÃ¬nh Ä‘á»c cÃ¡c papers, blogs vÃ  theo dÃµi cÃ¡c kÃªnh khoa há»c liÃªn quan. Ná»™i dung chÃ­nh cá»§a buá»•i thuyáº¿t trÃ¬nh hÆ°á»›ng tá»›i ba kÄ© thuáº­t chÃ­nh giÃºp táº­n dá»¥ng nguá»“n tÃ i nguyÃªn vá» dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c gÃ¡n nhÃ£n nháº±m cá»§ng cá»‘ tÃ­nh robust cho mÃ´ hÃ¬nh. Bao gá»“m nhá»¯ng phÆ°Æ¡ng phÃ¡p sau: 1. Semi-supervised Learning: Huáº¥n luyá»‡n mÃ´ hÃ¬nh káº¿t há»£p giá»¯a há»c cÃ³ giÃ¡m sÃ¡t vÃ  khÃ´ng giÃ¡m sÃ¡t. 2. Active Learning: KÄ© thuáº­t lá»±a chá»n máº«u thÃ´ng minh cho dá»± Ã¡n há»c mÃ¡y. 3. Weak Supervision: á»¨ng dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p chuyÃªn gia vÃ  cÃ¡c mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t yáº¿u trong gÃ¡n nhÃ£n tá»± Ä‘á»™ng. VÃ­ dá»¥ demo trÃªn phÃ¢n loáº¡i ná»™i dung tá»« Snorkel AI startup. Äá»ƒ thuáº­n tiá»‡n cho cÃ¡c báº¡n tháº¥y Ä‘Æ°á»£c hiá»‡u quáº£ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trong viá»‡c cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh, mÃ¬nh cung cáº¥p thÃªm nhá»¯ng notebooks thá»±c hÃ nh tÆ°Æ¡ng á»©ng vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau. Hi vá»ng ráº±ng nhá»¯ng ná»™i dung tá»« buá»•i mini-seminar sáº½ mang láº¡i thÃ´ng tin há»¯u Ã­ch vÃ  gÃ³p pháº§n xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI Viá»‡t Nam vá»¯ng máº¡nh hÆ¡n. TÃ i liá»‡u: - Slide: https://docs.google.com/presentation/d/1MYztes2PGiBmzYdcoeBrvLbIxRPorD4nLp-shw1K32c/edit?usp=sharing - Active Learning: https://colab.research.google.com/drive/1m3K9-_u468O9hA_4S-uTbbafiXAPxt86?usp=sharing - Weak Supervision: https://colab.research.google.com/drive/1uwO-hkIohAj0D9hgpw0S8bAS6mLACxD_?usp=sharing - Link video: https://www.youtube.com/watch?v=EB1gCJ6zMz4",,,,,
"MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» phÃ¢n loáº¡i váº£i dá»±a trÃªn áº£nh quang phá»•. Anh chá»‹ nÃ o cÃ³ biáº¿t loáº¡i mÃ¡y quang phá»• nÃ o dÃ¹ng Ä‘á»ƒ phÃ¢n tÃ­ch cáº¥u trÃºc, loáº¡i váº­t liá»‡u cá»§a váº£i, nhá» chá»‰ giÃºp.
Xin cáº£m Æ¡n.","MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» phÃ¢n loáº¡i váº£i dá»±a trÃªn áº£nh quang phá»•. Anh chá»‹ nÃ o cÃ³ biáº¿t loáº¡i mÃ¡y quang phá»• nÃ o dÃ¹ng Ä‘á»ƒ phÃ¢n tÃ­ch cáº¥u trÃºc, loáº¡i váº­t liá»‡u cá»§a váº£i, nhá» chá»‰ giÃºp. Xin cáº£m Æ¡n.",,,,,
"Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project kiá»ƒm tra sáº£n pháº©m bá»‹ cáº¥m hay ko dá»±a vÃ o tÃªn cá»§a nÃ³. ThÃ¬ Ä‘ang gáº·p 1 sá»‘ khÃ³ khÄƒn vá»›i nhá»¯ng case nhÆ° sau.
vd gun lÃ  cáº¥m chicken ko cáº¥m.
input lÃ  gun chicken chicken chicken chicken chicken chicken => thÃ¬ nÃ³ sáº½ detect ra lÃ  ko cáº¥m vá»›i confident score lÃ  0.97 NhÆ°ng cÃ´ng ty láº¡i muá»‘n nhá»¯ng case nÃ y thÃ¬ pháº£i ra lÃ  cáº¥m dÃ¹ chá»‰ cÃ³ 1 chá»¯ sÃºng trong nhiá»u chá»¯ bÃ¬nh thÆ°á»ng. VÃ  cÃ´ng ty cho em 1 list words nhá»¯ng tá»« nÃªn tÄƒng áº£nh hÆ°á»Ÿng cá»§a nÃ³ lÃªn model.
ThÃ¬ hiá»‡n táº¡i em ko biáº¿t key word hay phÆ°Æ¡ng hÆ°á»›ng gÃ¬ Ä‘á»ƒ lÃ m . Má»i ngÆ°á»i cho em vÃ i solutions hay keyword vá»›i :3. Cáº£m Æ¡n mn",Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project kiá»ƒm tra sáº£n pháº©m bá»‹ cáº¥m hay ko dá»±a vÃ o tÃªn cá»§a nÃ³. ThÃ¬ Ä‘ang gáº·p 1 sá»‘ khÃ³ khÄƒn vá»›i nhá»¯ng case nhÆ° sau. vd gun lÃ  cáº¥m chicken ko cáº¥m. input lÃ  gun chicken chicken chicken chicken chicken chicken => thÃ¬ nÃ³ sáº½ detect ra lÃ  ko cáº¥m vá»›i confident score lÃ  0.97 NhÆ°ng cÃ´ng ty láº¡i muá»‘n nhá»¯ng case nÃ y thÃ¬ pháº£i ra lÃ  cáº¥m dÃ¹ chá»‰ cÃ³ 1 chá»¯ sÃºng trong nhiá»u chá»¯ bÃ¬nh thÆ°á»ng. VÃ  cÃ´ng ty cho em 1 list words nhá»¯ng tá»« nÃªn tÄƒng áº£nh hÆ°á»Ÿng cá»§a nÃ³ lÃªn model. ThÃ¬ hiá»‡n táº¡i em ko biáº¿t key word hay phÆ°Æ¡ng hÆ°á»›ng gÃ¬ Ä‘á»ƒ lÃ m . Má»i ngÆ°á»i cho em vÃ i solutions hay keyword vá»›i :3. Cáº£m Æ¡n mn,,,,,
"YOLO (You Only Look Once) lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh ná»•i tiáº¿ng nháº¥t trong Object Detection (phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng)
Ká»ƒ tá»« khi ra máº¯t, phiÃªn báº£n YOLO nÃ o cÅ©ng cho tháº¥y sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ (Ä‘áº·c biá»‡t lÃ  vá» máº·t tá»‘c Ä‘á»™) so vá»›i cÃ¡c mÃ´ hÃ¬nh tá»‘t nháº¥t thá»i Ä‘iá»ƒm Ä‘Ã³.
HÃ£y cÃ¹ng tÃ¬m hiá»ƒu má»™t chÃºt vá» YOLO vÃ  cÃ¡ch Ã¡p dá»¥ng mÃ´ hÃ¬nh nÃ y cho bÃ i toÃ¡n Object Detection vá»›i thÆ° viá»‡n OpenCV trong bÃ i hÃ´m nay.","YOLO (You Only Look Once) lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh ná»•i tiáº¿ng nháº¥t trong Object Detection (phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng) Ká»ƒ tá»« khi ra máº¯t, phiÃªn báº£n YOLO nÃ o cÅ©ng cho tháº¥y sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ (Ä‘áº·c biá»‡t lÃ  vá» máº·t tá»‘c Ä‘á»™) so vá»›i cÃ¡c mÃ´ hÃ¬nh tá»‘t nháº¥t thá»i Ä‘iá»ƒm Ä‘Ã³. HÃ£y cÃ¹ng tÃ¬m hiá»ƒu má»™t chÃºt vá» YOLO vÃ  cÃ¡ch Ã¡p dá»¥ng mÃ´ hÃ¬nh nÃ y cho bÃ i toÃ¡n Object Detection vá»›i thÆ° viá»‡n OpenCV trong bÃ i hÃ´m nay.",,,,,
"[AI Sharing]
Do cÃ³ nhiá»u báº¡n má»›i tham gia cuá»™c thi cÅ©ng nhÆ° Ã­t cÃ³ kinh nghiá»‡m lÃ m vá» AI, nÃªn mÃ¬nh cÃ³ viáº¿t hÆ°á»›ng dáº«n má»™t sá»‘ kÄ© thuáº­t xá»­ lÃ½ dá»¯ liá»‡u cho cuá»™c thi Data-Centric Competition 2021 (https://datacomp.io/trang-chu) cho cÃ¡c báº¡n má»›i tÃ¬m hiá»ƒu tham kháº£o.
https://nttuan8.com/huong-dan-cuoc-thi-data-centric-ai-competition-2021/
ChÃºc cÃ¡c báº¡n tham gia cuá»™c thi Ä‘áº¡t káº¿t quáº£ tá»‘t.","[AI Sharing] Do cÃ³ nhiá»u báº¡n má»›i tham gia cuá»™c thi cÅ©ng nhÆ° Ã­t cÃ³ kinh nghiá»‡m lÃ m vá» AI, nÃªn mÃ¬nh cÃ³ viáº¿t hÆ°á»›ng dáº«n má»™t sá»‘ kÄ© thuáº­t xá»­ lÃ½ dá»¯ liá»‡u cho cuá»™c thi Data-Centric Competition 2021 (https://datacomp.io/trang-chu) cho cÃ¡c báº¡n má»›i tÃ¬m hiá»ƒu tham kháº£o. https://nttuan8.com/huong-dan-cuoc-thi-data-centric-ai-competition-2021/ ChÃºc cÃ¡c báº¡n tham gia cuá»™c thi Ä‘áº¡t káº¿t quáº£ tá»‘t.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, má»i ngÆ°á»i cho em há»i em cÃ³ cháº¡y lá»‡nh pip install kafka-python sau Ä‘Ã³ em cháº¡y lá»‡nh ""from kafka import KafkaProducer"" thÃ¬ bá»‹ bÃ¡o lá»—i nhÆ° hÃ¬nh. Má»i ngÆ°á»i cÃ³ ai gáº·p lá»—i nÃ y khÃ´ng áº¡.","Em chÃ o má»i ngÆ°á»i áº¡, má»i ngÆ°á»i cho em há»i em cÃ³ cháº¡y lá»‡nh pip install kafka-python sau Ä‘Ã³ em cháº¡y lá»‡nh ""from kafka import KafkaProducer"" thÃ¬ bá»‹ bÃ¡o lá»—i nhÆ° hÃ¬nh. Má»i ngÆ°á»i cÃ³ ai gáº·p lá»—i nÃ y khÃ´ng áº¡.",,,,,
Má»i ngÆ°á»i cho em há»i sao forum cá»§a machinelearningcoban khÃ´ng cÃ²n vÃ o Ä‘Æ°á»£c ná»¯a áº¡. Em cáº£m Æ¡n.,Má»i ngÆ°á»i cho em há»i sao forum cá»§a machinelearningcoban khÃ´ng cÃ²n vÃ o Ä‘Æ°á»£c ná»¯a áº¡. Em cáº£m Æ¡n.,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c vá» pháº§n xá»­ lÃ½ bá»™ nhá»› khi train model Ä‘á»ƒ trÃ¡nh trÃ n. CÅ©ng khÃ´ng phá»‰a kiáº¿n thá»©c gÃ¬ quÃ¡ khÃ³ nhÆ°ng nhiá»u báº¡n chÆ°a biáº¿t nÃªn hay bá»‹ trÃ n bá»™ nhá»› khi train.
Nay em máº¡nh dáº¡n lÃ m bÃ i chia sáº» mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie.
Mong ad duyá»‡t bÃ i!",KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c vá» pháº§n xá»­ lÃ½ bá»™ nhá»› khi train model Ä‘á»ƒ trÃ¡nh trÃ n. CÅ©ng khÃ´ng phá»‰a kiáº¿n thá»©c gÃ¬ quÃ¡ khÃ³ nhÆ°ng nhiá»u báº¡n chÆ°a biáº¿t nÃªn hay bá»‹ trÃ n bá»™ nhá»› khi train. Nay em máº¡nh dáº¡n lÃ m bÃ i chia sáº» mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie. Mong ad duyá»‡t bÃ i!,,,,,
"Gáº§n Ä‘Ã¢y, Kaggle cÃ´ng bá»‘ báº£n kháº£o sÃ¡t vá» Data Science & Machine Learning vá»›i má»™t sá»‘ thÃ´ng tin khÃ¡ thÃº vá»‹ nhÆ° má»©c lÆ°Æ¡ng trÃ¬nh Ä‘á»™ há»c váº¥n, thuáº­t toÃ¡n vÃ  cÃ¡c ná»n táº£ng phá»• biáº¿n, ...
CÃ¡c báº¡n cÃ¹ng tham kháº£o nhÃ© ğŸ™‚","Gáº§n Ä‘Ã¢y, Kaggle cÃ´ng bá»‘ báº£n kháº£o sÃ¡t vá» Data Science & Machine Learning vá»›i má»™t sá»‘ thÃ´ng tin khÃ¡ thÃº vá»‹ nhÆ° má»©c lÆ°Æ¡ng trÃ¬nh Ä‘á»™ há»c váº¥n, thuáº­t toÃ¡n vÃ  cÃ¡c ná»n táº£ng phá»• biáº¿n, ... CÃ¡c báº¡n cÃ¹ng tham kháº£o nhÃ©",,,,,
Hello má»i ngÆ°á»i! MÃ¬nh Ä‘ang cÃ³ project cáº§n phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng Text to Speech dÃ¹ng model MaryTTS. Má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ tá»«ng train thÃ nh cÃ´ng chÆ°a áº¡? CÃ³ thá»ƒ cho mÃ¬nh há»i kinh nghiá»‡m vá»›i Ä‘c ko áº¡? MÃ¬nh xin cáº£m Æ¡n trÆ°á»›c.,Hello má»i ngÆ°á»i! MÃ¬nh Ä‘ang cÃ³ project cáº§n phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng Text to Speech dÃ¹ng model MaryTTS. Má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ tá»«ng train thÃ nh cÃ´ng chÆ°a áº¡? CÃ³ thá»ƒ cho mÃ¬nh há»i kinh nghiá»‡m vá»›i Ä‘c ko áº¡? MÃ¬nh xin cáº£m Æ¡n trÆ°á»›c.,,,,,
"Em Ä‘ang cháº¡y FCENet, bounding box tráº£ vá» dáº¡ng nhÆ° nÃ y áº¡. Má»i ngÆ°á»i cho em há»i dáº¡ng nhÆ° nÃ y tÃªn gá»i lÃ  gÃ¬? VÃ  em muá»‘n convert sang dáº¡ng tá»© giÃ¡c thÃ¬ cÃ¡ch nÃ o hiá»‡u quáº£ nháº¥t áº¡? Em Ä‘á»‹nh láº¥y xmin, ymin, xmax, ymax.
Em cáº£m Æ¡n.","Em Ä‘ang cháº¡y FCENet, bounding box tráº£ vá» dáº¡ng nhÆ° nÃ y áº¡. Má»i ngÆ°á»i cho em há»i dáº¡ng nhÆ° nÃ y tÃªn gá»i lÃ  gÃ¬? VÃ  em muá»‘n convert sang dáº¡ng tá»© giÃ¡c thÃ¬ cÃ¡ch nÃ o hiá»‡u quáº£ nháº¥t áº¡? Em Ä‘á»‹nh láº¥y xmin, ymin, xmax, ymax. Em cáº£m Æ¡n.",,,,,
"Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang cáº§n 1 open API vá» nháº­n diá»‡n Ä‘á»™ng váº­t, quÃ©t hÃ¬nh Ä‘á»™ng váº­t sáº½ láº¥y Ä‘Æ°á»£c thÃ´ng sá»‘ loÃ i váº­t Ä‘Ã³. Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ³ API nÃ o nhÆ° tháº¿ khÃ´ng áº¡?","Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang cáº§n 1 open API vá» nháº­n diá»‡n Ä‘á»™ng váº­t, quÃ©t hÃ¬nh Ä‘á»™ng váº­t sáº½ láº¥y Ä‘Æ°á»£c thÃ´ng sá»‘ loÃ i váº­t Ä‘Ã³. Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ³ API nÃ o nhÆ° tháº¿ khÃ´ng áº¡?",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ 1 bÃ i toÃ¡n vá»›i input lÃ  2 báº£n tin, bÃ i bÃ¡o tiáº¿ng Viá»‡t. Output sáº½ in ra nhá»¯ng Ä‘oáº¡n, nhá»¯ng cÃ¢u tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a, rá»“i Ä‘Ã¡nh giÃ¡ tá»•ng quÃ¡t Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a 2 báº£n tin Ä‘Ã³. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin lá»™ trÃ¬nh tÃ¬m hiá»ƒu & triá»ƒn khai bÃ i toÃ¡n vá»›i áº¡. Em xin cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ 1 bÃ i toÃ¡n vá»›i input lÃ  2 báº£n tin, bÃ i bÃ¡o tiáº¿ng Viá»‡t. Output sáº½ in ra nhá»¯ng Ä‘oáº¡n, nhá»¯ng cÃ¢u tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a, rá»“i Ä‘Ã¡nh giÃ¡ tá»•ng quÃ¡t Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a 2 báº£n tin Ä‘Ã³. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin lá»™ trÃ¬nh tÃ¬m hiá»ƒu & triá»ƒn khai bÃ i toÃ¡n vá»›i áº¡. Em xin cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i. MÃ¬nh chia sáº» sá»± kiá»‡n háº±ng nÄƒm tá»« The Global Partnership on Artificial Intelligence (https://gpai.ai/): https://gpai.paris/site/program.
Trong Ä‘Ã³ cÃ³ sá»± tham gia cá»§a Francis Bach, Yoshua Bengio, ... , vÃ  Tá»•ng Thá»‘ng PhÃ¡p Macron.","ChÃ o má»i ngÆ°á»i. MÃ¬nh chia sáº» sá»± kiá»‡n háº±ng nÄƒm tá»« The Global Partnership on Artificial Intelligence (https://gpai.ai/): https://gpai.paris/site/program. Trong Ä‘Ã³ cÃ³ sá»± tham gia cá»§a Francis Bach, Yoshua Bengio, ... , vÃ  Tá»•ng Thá»‘ng PhÃ¡p Macron.",,,,,
"Cho miÌ€nh hoÌ‰i miÌ€nh muÃ´Ìn so saÌnh tÆ°Ì€ coÌ kÃªÌt quaÌ‰ gÃ¢Ì€n giÃ´Ìng viÌ duÌ£: input laÌ€ ""cn gaÌ€"", thiÌ€ seÌƒ Ä‘oaÌn ra Ä‘Æ°Æ¡Ì£c tÆ°Ì€ ""con gaÌ€"" tÆ°Ì€ Database. ThiÌ€ miÌ€nh xaÌ€i thuÃ¢Ì£t toaÌn naÌ€o trÃªn sagemaker cuÌ‰a AWS Ä‘Æ°Æ¡Ì£c aÌ£?","Cho miÌ€nh hoÌ‰i miÌ€nh muÃ´Ìn so saÌnh tÆ°Ì€ coÌ kÃªÌt quaÌ‰ gÃ¢Ì€n giÃ´Ìng viÌ duÌ£: input laÌ€ ""cn gaÌ€"", thiÌ€ seÌƒ Ä‘oaÌn ra Ä‘Æ°Æ¡Ì£c tÆ°Ì€ ""con gaÌ€"" tÆ°Ì€ Database. ThiÌ€ miÌ€nh xaÌ€i thuÃ¢Ì£t toaÌn naÌ€o trÃªn sagemaker cuÌ‰a AWS Ä‘Æ°Æ¡Ì£c aÌ£?",,,,,
"chÃ o mn
em Ä‘ang lÃ m Ä‘á»“ Ã¡n khai phÃ¡ dá»¯ liá»‡u dÃ¹ng cÃ´ng cá»¥ ELKI( báº¥t Ä‘áº¯c dÄ© má»›i chá»n ELKI thÃ´i áº¡) mn ai biáº¿t dÃ¹ng cÃ´ng cá»¥ nÃ y giÃºp em vá»›i áº¡
em cáº£m Æ¡n mn nhiá»u
em báº¥t lá»±c quÃ¡ áº¡",chÃ o mn em Ä‘ang lÃ m Ä‘á»“ Ã¡n khai phÃ¡ dá»¯ liá»‡u dÃ¹ng cÃ´ng cá»¥ ELKI( báº¥t Ä‘áº¯c dÄ© má»›i chá»n ELKI thÃ´i áº¡) mn ai biáº¿t dÃ¹ng cÃ´ng cá»¥ nÃ y giÃºp em vá»›i áº¡ em cáº£m Æ¡n mn nhiá»u em báº¥t lá»±c quÃ¡ áº¡,,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡, cho phÃ©p em há»i má»i ngÆ°á»i cÃ³ link blogger ngÆ°á»i Viá»‡t vá» Machine Learning, Deep Learning, Data Science khÃ´ng áº¡? Náº¿u cÃ³ thÃ¬ cho em xin vá»›i áº¡, em cáº£m Æ¡n.","Xin chÃ o má»i ngÆ°á»i áº¡, cho phÃ©p em há»i má»i ngÆ°á»i cÃ³ link blogger ngÆ°á»i Viá»‡t vá» Machine Learning, Deep Learning, Data Science khÃ´ng áº¡? Náº¿u cÃ³ thÃ¬ cho em xin vá»›i áº¡, em cáº£m Æ¡n.",,,,,
"Knowledge distillation, thuáº­t toÃ¡n há»¯u Ã­ch cháº¯t lá»c thÃ´ng tin nháº±m cáº£i thiá»‡n hiá»‡u suáº¥t cÃ¡c models nhá».","Knowledge distillation, thuáº­t toÃ¡n há»¯u Ã­ch cháº¯t lá»c thÃ´ng tin nháº±m cáº£i thiá»‡n hiá»‡u suáº¥t cÃ¡c models nhá».",,,,,
"ğŸ”»[ğ‘ğğ ğ¢ğ¬ğ­ğ«ğšğ­ğ¢ğ¨ğ§ ğğ©ğğ§] ğƒğ€ğ“ğ€-ğ‚ğ„ğğ“ğ‘ğˆğ‚ ğ€ğˆ ğ‚ğğŒğğ„ğ“ğˆğ“ğˆğğ â€¼ï¸
ğŸ‘‰Link: http://datacomp.io/
Are you ready to challenge your skills in #AI and #MachineLearning? DataComp is a Data-Centric AI competition hosted in #Vietnam for the first time.
Data scientists, Data analysts, Data engineers, IT students, Developers or anyone working in the field of #ArtificialIntelligence and #DataScience is welcome to join!
â™¦ï¸Find more info here and stay tuned for further updates!","[ ] - â€¼ Link: http://datacomp.io/ Are you ready to challenge your skills in and DataComp is a Data-Centric AI competition hosted in for the first time. Data scientists, Data analysts, Data engineers, IT students, Developers or anyone working in the field of and is welcome to join! Find more info here and stay tuned for further updates!",#AI	#MachineLearning?	#Vietnam	#ArtificialIntelligence	#DataScience,,,,
"[LÃ½ thuyáº¿t vanilla Transformer]
ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ tháº¯c máº¯c vá» Transformer cá»§a 'Attention is all you need', mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
ÄÃ£ cÃ³ ráº¥t nhiá»u nguá»“n giáº£i thÃ­ch cáº¥u trÃºc kiáº¿n trÃºc Transformer nhÆ°ng cÃ³ váº» chÆ°a nhiá»u nguá»“n nÃ³i chi tiáº¿t vá» cÃ¡ch thÃ´ng tin truyá»n trong máº¡ng.
1/ Transformer khÃ´ng recurrent á»Ÿ pháº§n encoding, nhÆ°ng recurrent (theo nghÄ©a lÃ  Ä‘áº§u ra ná»‘i trá»Ÿ láº¡i Ä‘áº§u vÃ o) á»Ÿ pháº§n decoding; Ä‘á»ƒ cho ra output á»Ÿ vá»‹ trÃ­ t_i thÃ¬ sublayer encode-decode attention cáº§n thá»±c hiá»‡n attention vá»›i cÃ¡c hidden vector á»Ÿ pháº§n encoding cÃ¹ng vá»›i nhá»¯ng output trÆ°á»›c vá»‹ trÃ­ t_i náº¿u lÃ  layer dÆ°á»›i cÃ¹ng, hoáº·c cÃ¹ng vá»›i nhá»¯ng hidden representation cá»§a output trÆ°á»›c vá»‹ trÃ­ t_i náº¿u lÃ  layer á»Ÿ giá»¯a vÃ  trÃªn cÃ¹ng. Báº£n thÃ¢n sublayer encode-decode cÅ©ng pháº£i thá»±c hiá»‡n masked attention. Nhá»¯ng Ä‘iá»u trÃªn lÃ  Ä‘Ãºng khÃ´ng áº¡?
2/ Sublayer masked multihead attention cÃ³ nghÄ©a lÃ  hidden representation cá»§a output á»Ÿ vá»‹ trÃ­ i Ä‘Æ°á»£c sinh ra theo cÃ¡ch lÃ  output Ä‘Ã³ chá»‰ Ä‘Æ°á»£c phÃ©p attend tá»›i cÃ¡c output trÆ°á»›c vá»‹ trÃ­ i. ÄÃºng khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i.","[LÃ½ thuyáº¿t vanilla Transformer] ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ tháº¯c máº¯c vá» Transformer cá»§a 'Attention is all you need', mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p. ÄÃ£ cÃ³ ráº¥t nhiá»u nguá»“n giáº£i thÃ­ch cáº¥u trÃºc kiáº¿n trÃºc Transformer nhÆ°ng cÃ³ váº» chÆ°a nhiá»u nguá»“n nÃ³i chi tiáº¿t vá» cÃ¡ch thÃ´ng tin truyá»n trong máº¡ng. 1/ Transformer khÃ´ng recurrent á»Ÿ pháº§n encoding, nhÆ°ng recurrent (theo nghÄ©a lÃ  Ä‘áº§u ra ná»‘i trá»Ÿ láº¡i Ä‘áº§u vÃ o) á»Ÿ pháº§n decoding; Ä‘á»ƒ cho ra output á»Ÿ vá»‹ trÃ­ t_i thÃ¬ sublayer encode-decode attention cáº§n thá»±c hiá»‡n attention vá»›i cÃ¡c hidden vector á»Ÿ pháº§n encoding cÃ¹ng vá»›i nhá»¯ng output trÆ°á»›c vá»‹ trÃ­ t_i náº¿u lÃ  layer dÆ°á»›i cÃ¹ng, hoáº·c cÃ¹ng vá»›i nhá»¯ng hidden representation cá»§a output trÆ°á»›c vá»‹ trÃ­ t_i náº¿u lÃ  layer á»Ÿ giá»¯a vÃ  trÃªn cÃ¹ng. Báº£n thÃ¢n sublayer encode-decode cÅ©ng pháº£i thá»±c hiá»‡n masked attention. Nhá»¯ng Ä‘iá»u trÃªn lÃ  Ä‘Ãºng khÃ´ng áº¡? 2/ Sublayer masked multihead attention cÃ³ nghÄ©a lÃ  hidden representation cá»§a output á»Ÿ vá»‹ trÃ­ i Ä‘Æ°á»£c sinh ra theo cÃ¡ch lÃ  output Ä‘Ã³ chá»‰ Ä‘Æ°á»£c phÃ©p attend tá»›i cÃ¡c output trÆ°á»›c vá»‹ trÃ­ i. ÄÃºng khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Hi má»i ngÆ°á»i, em má»›i vá»«a há»c xong foundation Machine Learning nhÆ°ng váº«n cÃ²n hÆ¡i rá»‘i. Em cáº£m tháº¥y há»c xong thÃ¬ láº¡i quÃªn máº¥t, chÆ°a káº¿t ná»‘i Ä‘Æ°á»£c kiáº¿n thá»©c. Anh chá»‹ cÃ³ tips nÃ o cho em xin Ä‘á»ƒ há»c tá»‘t ngÃ nh há»c nÃ y khÃ´ng áº¡?
Em cáº£m Æ¡n","Hi má»i ngÆ°á»i, em má»›i vá»«a há»c xong foundation Machine Learning nhÆ°ng váº«n cÃ²n hÆ¡i rá»‘i. Em cáº£m tháº¥y há»c xong thÃ¬ láº¡i quÃªn máº¥t, chÆ°a káº¿t ná»‘i Ä‘Æ°á»£c kiáº¿n thá»©c. Anh chá»‹ cÃ³ tips nÃ o cho em xin Ä‘á»ƒ há»c tá»‘t ngÃ nh há»c nÃ y khÃ´ng áº¡? Em cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i, em má»›i tÃ¬m hiá»ƒu vá» ML. Mn cho e Ã½ tÆ°á»Ÿng Ä‘á»ƒ lÃ m 3 bÃ i nÃ y ntn áº¡. E Ä‘á»c sÃ¡ch nhÆ°ng k biáº¿t cÃ¡ch Ã¡p dá»¥ng vÃ o bÃ i cá»¥ thá»ƒ ntn. BÃ i 2 em lÃ m nhÆ° dÆ°á»›i thÃ¬ cÃ³ Ä‘Ãºng ko áº¡. Em cáº£m Æ¡n mn trÆ°á»›c","ChÃ o má»i ngÆ°á»i, em má»›i tÃ¬m hiá»ƒu vá» ML. Mn cho e Ã½ tÆ°á»Ÿng Ä‘á»ƒ lÃ m 3 bÃ i nÃ y ntn áº¡. E Ä‘á»c sÃ¡ch nhÆ°ng k biáº¿t cÃ¡ch Ã¡p dá»¥ng vÃ o bÃ i cá»¥ thá»ƒ ntn. BÃ i 2 em lÃ m nhÆ° dÆ°á»›i thÃ¬ cÃ³ Ä‘Ãºng ko áº¡. Em cáº£m Æ¡n mn trÆ°á»›c",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n nhÃ¢n dáº¡ng danh tÃ­nh ngÆ°á»i Ä‘eo kháº©u trang, mn cÃ³ tÃ i liá»‡u tham kháº£o vá» máº£ng nÃ y cÃ³ thá»ƒ chia sáº» cho mÃ¬nh vá»›i. MÃ¬nh cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n nhÃ¢n dáº¡ng danh tÃ­nh ngÆ°á»i Ä‘eo kháº©u trang, mn cÃ³ tÃ i liá»‡u tham kháº£o vá» máº£ng nÃ y cÃ³ thá»ƒ chia sáº» cho mÃ¬nh vá»›i. MÃ¬nh cáº£m Æ¡n",,,,,
"Hi anh em, há»™i nghá»‹ GTC21 cá»§a NVIDIA diá»…n ra tá»« 08-11 thÃ¡ng 11 nÄƒm 2021 lÃ  1 trong nhá»¯ng há»™i nghá»‹ lá»›n nháº¥t vá» AI cho cÃ¡c developer lÃ m sáº£n pháº©m AI. Táº¡i há»™i nghá»‹ nÃ y, bÃªn mÃ¬nh cÃ³ 1 bÃ i trÃ¬nh bÃ y liÃªn quan Ä‘áº¿n DeepStream do team VNPT vÃ  NVIDIA cÃ¹ng tá»‘i Æ°u trong thá»i gian qua cho sáº£n pháº©m https://smartvision.vnpt.vn/vi bÃªn mÃ¬nh, do anh Thanh Ha Cao trÃ¬nh bÃ y:
https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog?search=A31423&ncid=so-face-570512&fbclid=IwAR1rLJ0cgl-BT8LuJihVIjKjV1QkninTH1QjkzqWSp1y6vga2FzKVvzJzNY&tab.catalogtabfields=1600209910618001TWM3#cid=gtcnov21_so-face_en-sg
Anh em lÃ m sáº£n pháº©m cÃ¹ng Ä‘Äƒng kÃ½ vÃ  Ä‘áº·c biá»‡t cáº­p nháº­t Keynote cá»§a AI Product nÄƒm 2021 lÃ  gÃ¬, cÅ©ng nhÆ° xu hÆ°á»›ng sáº¯p tá»›i nhÃ©.
Link sá»± kiá»‡n:
https://www.facebook.com/NVIDIA.AP/photos/a.464775900561063/1473195036385806
https://twitter.com/NVIDIAAP/status/1450695790872211459
https://www.linkedin.com/feed/update/urn:li:activity:6856461472671891457/","Hi anh em, há»™i nghá»‹ GTC21 cá»§a NVIDIA diá»…n ra tá»« 08-11 thÃ¡ng 11 nÄƒm 2021 lÃ  1 trong nhá»¯ng há»™i nghá»‹ lá»›n nháº¥t vá» AI cho cÃ¡c developer lÃ m sáº£n pháº©m AI. Táº¡i há»™i nghá»‹ nÃ y, bÃªn mÃ¬nh cÃ³ 1 bÃ i trÃ¬nh bÃ y liÃªn quan Ä‘áº¿n DeepStream do team VNPT vÃ  NVIDIA cÃ¹ng tá»‘i Æ°u trong thá»i gian qua cho sáº£n pháº©m https://smartvision.vnpt.vn/vi bÃªn mÃ¬nh, do anh Thanh Ha Cao trÃ¬nh bÃ y: https://events.rainfocus.com/widget/nvidia/nvidiagtc/sessioncatalog?search=A31423&ncid=so-face-570512&fbclid=IwAR1rLJ0cgl-BT8LuJihVIjKjV1QkninTH1QjkzqWSp1y6vga2FzKVvzJzNY&tab.catalogtabfields=1600209910618001TWM3#cid=gtcnov21_so-face_en-sg Anh em lÃ m sáº£n pháº©m cÃ¹ng Ä‘Äƒng kÃ½ vÃ  Ä‘áº·c biá»‡t cáº­p nháº­t Keynote cá»§a AI Product nÄƒm 2021 lÃ  gÃ¬, cÅ©ng nhÆ° xu hÆ°á»›ng sáº¯p tá»›i nhÃ©. Link sá»± kiá»‡n: https://www.facebook.com/NVIDIA.AP/photos/a.464775900561063/1473195036385806 https://twitter.com/NVIDIAAP/status/1450695790872211459 https://www.linkedin.com/feed/update/urn:li:activity:6856461472671891457/",,,,,
Má»i cÃ¡c báº¡n tham dá»± cuá»™c thi phÃ¢n loáº¡i thu nháº­p do TowarDataScience tá»• chá»©c. ÄÃ¢y lÃ  cuá»™c thi ráº¥t phÃ¹ há»£p vá»›i cÃ¡c báº¡n sinh viÃªn Æ°a thá»­ thÃ¡ch vÃ  Ä‘am mÃª vá»›i lÄ©nh vá»±c Khoa há»c Dá»¯ liá»‡u.,Má»i cÃ¡c báº¡n tham dá»± cuá»™c thi phÃ¢n loáº¡i thu nháº­p do TowarDataScience tá»• chá»©c. ÄÃ¢y lÃ  cuá»™c thi ráº¥t phÃ¹ há»£p vá»›i cÃ¡c báº¡n sinh viÃªn Æ°a thá»­ thÃ¡ch vÃ  Ä‘am mÃª vá»›i lÄ©nh vá»±c Khoa há»c Dá»¯ liá»‡u.,,,,,
"Hello má»i ngÆ°á»i, lÃ¢u rá»“i mÃ¬nh má»›i viáº¿t bÃ i chia sáº» vá» Deep Learning. Láº§n nÃ y lÃ  vá» Deep Learning vÃ  Data Privacy vá»›i Federated Learning, má»™t lÄ©nh vá»±c mÃ  mÃ¬nh Ä‘ang nghiÃªn cá»©u. BÃ i viáº¿t báº±ng Tiáº¿ng Anh vÃ¬ mÃ¬nh muá»‘n Ã½ tÆ°á»Ÿng nÃ y tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i nhiá»u ngÆ°á»i hÆ¡n. Tuy nhiÃªn mÃ¬nh cÅ©ng viáº¿t theo hÆ°á»›ng Ä‘Æ¡n giáº£n dá»… hiá»ƒu Ä‘á»ƒ nhá»¯ng ai khÃ´ng cÃ³ ná»n táº£ng ká»¹ thuáº­t hay há»c thuáº­t cÅ©ng Ä‘á»c Ä‘Æ°á»£c. Hi vá»ng bÃ i viáº¿t cÃ³ thá»ƒ cung cáº¥p thÃªm kiáº¿n thá»©c cho má»i ngÆ°á»i.","Hello má»i ngÆ°á»i, lÃ¢u rá»“i mÃ¬nh má»›i viáº¿t bÃ i chia sáº» vá» Deep Learning. Láº§n nÃ y lÃ  vá» Deep Learning vÃ  Data Privacy vá»›i Federated Learning, má»™t lÄ©nh vá»±c mÃ  mÃ¬nh Ä‘ang nghiÃªn cá»©u. BÃ i viáº¿t báº±ng Tiáº¿ng Anh vÃ¬ mÃ¬nh muá»‘n Ã½ tÆ°á»Ÿng nÃ y tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i nhiá»u ngÆ°á»i hÆ¡n. Tuy nhiÃªn mÃ¬nh cÅ©ng viáº¿t theo hÆ°á»›ng Ä‘Æ¡n giáº£n dá»… hiá»ƒu Ä‘á»ƒ nhá»¯ng ai khÃ´ng cÃ³ ná»n táº£ng ká»¹ thuáº­t hay há»c thuáº­t cÅ©ng Ä‘á»c Ä‘Æ°á»£c. Hi vá»ng bÃ i viáº¿t cÃ³ thá»ƒ cung cáº¥p thÃªm kiáº¿n thá»©c cho má»i ngÆ°á»i.",,,,,
Máº¥y anh chá»‹ Æ¡i cho em há»i ai cÃ³ tÃ i liá»‡u gÃ¬ vá» viá»‡c á»¨ng dá»¥ng cá»§a phÃ¢n tÃ­ch SVD Ä‘á»ƒ khá»­ nhiá»…u Ã¢m thanh ko áº¡. Em tÃ¬m trÃªn GG hoÃ i mÃ  khÃ´ng tháº¥y ğŸ˜­ğŸ˜­,Máº¥y anh chá»‹ Æ¡i cho em há»i ai cÃ³ tÃ i liá»‡u gÃ¬ vá» viá»‡c á»¨ng dá»¥ng cá»§a phÃ¢n tÃ­ch SVD Ä‘á»ƒ khá»­ nhiá»…u Ã¢m thanh ko áº¡. Em tÃ¬m trÃªn GG hoÃ i mÃ  khÃ´ng tháº¥y,,,,,
"ChÃ o má»i ngÆ°á»i em má»›i tÃ¬m hiá»ƒu nghiÃªn cá»©u vá» music recommendation system vÃ  em Ä‘ang Ä‘i vÃ o pháº§n collaborative filtering dá»±a trÃªn mÃ´ hÃ¬nh Ä‘á»“ thá»‹ , Ä‘áº¿n pháº§n nÃ y em Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c UZ nhÆ° hÃ¬nh bÃªn dÆ°á»›i , má»i ngÆ°á»i cho em há»i tiáº¿p theo muá»‘n tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m gá»£i Ã½ cho ngÆ°á»i dÃ¹ng vÃ  hoÃ n thÃ nh bÃ i toÃ¡n thÃ¬ em nÃªn lÃ m nhá»¯ng gÃ¬ ná»¯a áº¡, em cÃ¡m Æ¡n.
nguá»“n https://portal.ptit.edu.vn/saudaihoc/wp-content/uploads/2020/02/LA_%C4%90%E1%BB%97-Th%E1%BB%8B-Li%C3%AAn.pdf","ChÃ o má»i ngÆ°á»i em má»›i tÃ¬m hiá»ƒu nghiÃªn cá»©u vá» music recommendation system vÃ  em Ä‘ang Ä‘i vÃ o pháº§n collaborative filtering dá»±a trÃªn mÃ´ hÃ¬nh Ä‘á»“ thá»‹ , Ä‘áº¿n pháº§n nÃ y em Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c UZ nhÆ° hÃ¬nh bÃªn dÆ°á»›i , má»i ngÆ°á»i cho em há»i tiáº¿p theo muá»‘n tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m gá»£i Ã½ cho ngÆ°á»i dÃ¹ng vÃ  hoÃ n thÃ nh bÃ i toÃ¡n thÃ¬ em nÃªn lÃ m nhá»¯ng gÃ¬ ná»¯a áº¡, em cÃ¡m Æ¡n. nguá»“n https://portal.ptit.edu.vn/saudaihoc/wp-content/uploads/2020/02/LA_%C4%90%E1%BB%97-Th%E1%BB%8B-Li%C3%AAn.pdf",,,,,
"Object Detection (phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng) lÃ  má»™t trong nhá»¯ng cÃ´ng nghá»‡ trong thá»‹ giÃ¡c mÃ¡y tÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng phá»• biáº¿n nháº¥t cho Ä‘áº¿n nay.
Khi nháº¯c Ä‘áº¿n Object Detection dá»±a trÃªn Deep Learning, kháº£ nÄƒng cao lÃ  báº¡n sáº½ báº¯t gáº·p má»™t trong nhá»¯ng â€œhá»â€ phÆ°Æ¡ng phÃ¡p nhÆ° RCNN, SSD, YOLO ...
BÃ i hÃ´m nay sáº½ giá»›i thiá»‡u Ä‘áº¿n cÃ¡c báº¡n vá» phÆ°Æ¡ng phÃ¡p SSD vÃ  cÃ¡ch Ã¡p dá»¥ng má»™t mÃ´ hÃ¬nh thuá»™c â€œhá»â€ phÆ°Æ¡ng phÃ¡p nÃ y.","Object Detection (phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng) lÃ  má»™t trong nhá»¯ng cÃ´ng nghá»‡ trong thá»‹ giÃ¡c mÃ¡y tÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng phá»• biáº¿n nháº¥t cho Ä‘áº¿n nay. Khi nháº¯c Ä‘áº¿n Object Detection dá»±a trÃªn Deep Learning, kháº£ nÄƒng cao lÃ  báº¡n sáº½ báº¯t gáº·p má»™t trong nhá»¯ng â€œhá»â€ phÆ°Æ¡ng phÃ¡p nhÆ° RCNN, SSD, YOLO ... BÃ i hÃ´m nay sáº½ giá»›i thiá»‡u Ä‘áº¿n cÃ¡c báº¡n vá» phÆ°Æ¡ng phÃ¡p SSD vÃ  cÃ¡ch Ã¡p dá»¥ng má»™t mÃ´ hÃ¬nh thuá»™c â€œhá»â€ phÆ°Æ¡ng phÃ¡p nÃ y.",,,,,
"ChÃ o má»i ngÆ°á»i, sau má»™t thá»i gian lÃ m viá»‡c vá»›i bÃ i toÃ¡n Chatbot mÃ¬nh cÃ³ tá»•ng há»£p má»™t sá»‘ hiá»ƒu biáº¿t cÆ¡ báº£n vá» Chatbot trong bÃ i viáº¿t Ä‘Ã­nh kÃ¨m bÃªn dÆ°á»›i. Má»™t lÃ  Ä‘á»ƒ há»‡ thá»‘ng láº¡i kiáº¿n thá»©c, hai lÃ  muá»‘n chia sáº» vá»›i nhá»¯ng ai Ä‘ang quan tÃ¢m tá»›i bÃ i toÃ¡n nÃ y. Hi vá»ng nÃ³ sáº½ giÃºp báº¡n Ä‘á»c cÃ³ má»™t cÃ¡i nhÃ¬n toÃ n cáº£nh vá» Chatbot vÃ  tiáº¿p cáº­n nhanh hÆ¡n vá»›i bÃ i toÃ¡n nÃ y.
https://viblo.asia/p/tong-quan-ve-chatbot-yMnKMByaZ7P
ChÃºc cáº£ nhÃ  cuá»‘i tuáº§n vui váº» áº¡ ğŸ˜ŠğŸ˜ŠğŸ˜Š","ChÃ o má»i ngÆ°á»i, sau má»™t thá»i gian lÃ m viá»‡c vá»›i bÃ i toÃ¡n Chatbot mÃ¬nh cÃ³ tá»•ng há»£p má»™t sá»‘ hiá»ƒu biáº¿t cÆ¡ báº£n vá» Chatbot trong bÃ i viáº¿t Ä‘Ã­nh kÃ¨m bÃªn dÆ°á»›i. Má»™t lÃ  Ä‘á»ƒ há»‡ thá»‘ng láº¡i kiáº¿n thá»©c, hai lÃ  muá»‘n chia sáº» vá»›i nhá»¯ng ai Ä‘ang quan tÃ¢m tá»›i bÃ i toÃ¡n nÃ y. Hi vá»ng nÃ³ sáº½ giÃºp báº¡n Ä‘á»c cÃ³ má»™t cÃ¡i nhÃ¬n toÃ n cáº£nh vá» Chatbot vÃ  tiáº¿p cáº­n nhanh hÆ¡n vá»›i bÃ i toÃ¡n nÃ y. https://viblo.asia/p/tong-quan-ve-chatbot-yMnKMByaZ7P ChÃºc cáº£ nhÃ  cuá»‘i tuáº§n vui váº» áº¡",,,,,
"Xin chÃ o cÃ¡c tiá»n bá»‘i áº¡, em nÄƒm nay sinh viÃªn nÄƒm 1 chuyÃªn ngÃ nh TrÃ­ tuá»‡ nhÃ¢n táº¡o. Em Ä‘Ã£ cÃ³ ná»n táº£ng vá» Python vÃ  cÅ©ng cÃ³ tÃ¬m hiá»ƒu vÃ  há»c theo khoÃ¡ há»c huyá»n thoáº¡i cá»§a tháº§y Andrew Ng vÃ  tÃ¬m hiá»ƒu má»™t sá»‘ roadmap nhÆ°ng hÆ¡i mÃ´ng lung. CÃ¡c tiá»n bá»‘i cho em xin Ã­t lá»i khuyÃªn vá»›i áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i ğŸ™","Xin chÃ o cÃ¡c tiá»n bá»‘i áº¡, em nÄƒm nay sinh viÃªn nÄƒm 1 chuyÃªn ngÃ nh TrÃ­ tuá»‡ nhÃ¢n táº¡o. Em Ä‘Ã£ cÃ³ ná»n táº£ng vá» Python vÃ  cÅ©ng cÃ³ tÃ¬m hiá»ƒu vÃ  há»c theo khoÃ¡ há»c huyá»n thoáº¡i cá»§a tháº§y Andrew Ng vÃ  tÃ¬m hiá»ƒu má»™t sá»‘ roadmap nhÆ°ng hÆ¡i mÃ´ng lung. CÃ¡c tiá»n bá»‘i cho em xin Ã­t lá»i khuyÃªn vá»›i áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Dáº¡o nÃ y facebook vaf group cÃ³ quÃ¡ nhiá»u comment spam nháº£m nhÃ­.
CÃ¡c báº¡n cÃ³ cao kiáº¿n gÃ¬ háº¡n cháº¿ viá»‡c nÃ y khÃ´ng?",Dáº¡o nÃ y facebook vaf group cÃ³ quÃ¡ nhiá»u comment spam nháº£m nhÃ­. CÃ¡c báº¡n cÃ³ cao kiáº¿n gÃ¬ háº¡n cháº¿ viá»‡c nÃ y khÃ´ng?,,,,,
"Em chÃ o má»i ngÆ°á»i, em Ä‘ang muá»‘n sá»­ dá»¥ng BERT pretrained model Ä‘á»ƒ batch encode cho dataset cá»§a em gá»“m 2500 sentences, má»—i sentences cÃ³ Ä‘á»™ dÃ i dao Ä‘á»™ng trong khoáº£ng 1000-2000 words. Má»i ngÆ°á»i cho em há»i nÃªn Ä‘á»ƒ batch_size kÃ­ch thÆ°á»›c nhÆ° tháº¿ nÃ o áº¡, em Ä‘á»ƒ batch_size 8 mÃ  Ä‘Ã£ háº¿t sáº¡ch RAM rá»“i áº¡. Em khÃ´ng biáº¿t cÃ³ nÃªn mua Colab Pro+ Ä‘á»ƒ tÄƒng thÃªm RAM khÃ´ng áº¡. Em Ä‘ang dÃ¹ng GPU P100 á»Ÿ cháº¿ Ä‘á»™ High-RAM 25GB trÃªn colab. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.
ChÃº thÃ­ch: sentence cá»§a em á»Ÿ Ä‘Ã¢y lÃ  protein sequence áº¡, má»—i protein sequence gá»“m 1000-2000 words, vÃ  word á»Ÿ Ä‘Ã¢y thÃ¬ lÃ  letter áº¡.","Em chÃ o má»i ngÆ°á»i, em Ä‘ang muá»‘n sá»­ dá»¥ng BERT pretrained model Ä‘á»ƒ batch encode cho dataset cá»§a em gá»“m 2500 sentences, má»—i sentences cÃ³ Ä‘á»™ dÃ i dao Ä‘á»™ng trong khoáº£ng 1000-2000 words. Má»i ngÆ°á»i cho em há»i nÃªn Ä‘á»ƒ batch_size kÃ­ch thÆ°á»›c nhÆ° tháº¿ nÃ o áº¡, em Ä‘á»ƒ batch_size 8 mÃ  Ä‘Ã£ háº¿t sáº¡ch RAM rá»“i áº¡. Em khÃ´ng biáº¿t cÃ³ nÃªn mua Colab Pro+ Ä‘á»ƒ tÄƒng thÃªm RAM khÃ´ng áº¡. Em Ä‘ang dÃ¹ng GPU P100 á»Ÿ cháº¿ Ä‘á»™ High-RAM 25GB trÃªn colab. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡. ChÃº thÃ­ch: sentence cá»§a em á»Ÿ Ä‘Ã¢y lÃ  protein sequence áº¡, má»—i protein sequence gá»“m 1000-2000 words, vÃ  word á»Ÿ Ä‘Ã¢y thÃ¬ lÃ  letter áº¡.",,,,,
"MÃ¬nh cáº§n giáº£i má»™t sá»‘ bÃ i toÃ¡n tá»‘i Æ°u dáº¡ng Ä‘Æ¡n giáº£n nhÆ°: TÃ¬m x trong má»™t danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng cho trÆ°á»›c, sao f(x) >= giÃ¡ trá»‹ tá»‘i thiá»ƒu vÃ  g(x) lÃ  min... KhÃ´ng rÃµ dáº¡ng váº¥n Ä‘á» nÃ y nÃ y thÃ¬ cÃ³ thÆ° viá»‡n nÃ o cá»§a python cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c vÃ  sá»­ dá»¥ng nÃ³ Ä‘Æ¡n giáº£n khÃ´ng cÃ¡c báº¡n? CÃ¡m Æ¡n.","MÃ¬nh cáº§n giáº£i má»™t sá»‘ bÃ i toÃ¡n tá»‘i Æ°u dáº¡ng Ä‘Æ¡n giáº£n nhÆ°: TÃ¬m x trong má»™t danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng cho trÆ°á»›c, sao f(x) >= giÃ¡ trá»‹ tá»‘i thiá»ƒu vÃ  g(x) lÃ  min... KhÃ´ng rÃµ dáº¡ng váº¥n Ä‘á» nÃ y nÃ y thÃ¬ cÃ³ thÆ° viá»‡n nÃ o cá»§a python cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c vÃ  sá»­ dá»¥ng nÃ³ Ä‘Æ¡n giáº£n khÃ´ng cÃ¡c báº¡n? CÃ¡m Æ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i. Em Ä‘ng giáº£i bÃ i toÃ¡n vá» embedding cho amino acid cá»§a trÃ¬nh tá»± protein (váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ tÆ°Æ¡ng tá»± nhÆ° trong NLP á»Ÿ chá»— amino acid lÃ  word, protein lÃ  sentence, Ä‘Ã¢y lÃ  bÃ i toÃ¡n word embedding). Em Ä‘Ã£ tÃ¬m mÃ´ hÃ¬nh pre-trained BERT cho amino acid (https://huggingface.co/Rostlab/prot_bert).
Vá»›i mÃ´ hÃ¬nh pretrained nÃ y, cÃ³ thá»ƒ sinh ra cÃ¡c contextual embedding cho amino acid á»Ÿ trong má»—i trÃ¬nh tá»± protein. á» Ä‘Ã¢y, em cáº§n encode cho tÃ¢p dá»¯ liá»‡u cá»§a mÃ¬nh gá»“m nhiá»u trÃ¬nh tá»± protein (khoáº£ng 2500). Tuy nhiÃªn, káº¿t quáº£ náº¿u em encode Ä‘á»“ng thá»i toÃ n bá»™ cáº£ táº­p dá»¯ liá»‡u nÃ y cá»§a mÃ¬nh, thÃ¬ cáº§n pháº£i allocate tensor cÃ³ kÃ­ch thÆ°á»›c lá»›n (2500, 2000, 1024). 2500 lÃ  sá»‘ trÃ¬nh tá»± protein em cÃ³ tÆ°Æ¡ng á»©ng vá»›i 2500 sentences; 2000 lÃ  chiá»u dÃ i cá»§a má»™t trÃ¬nh tá»± sau khi Ä‘Ã£ Ä‘Æ°á»£c padding, tÆ°Æ¡ng á»©ng vá»›i sá»‘ amino acid hay sá»‘ tá»« trong má»™t sentence; 1024 lÃ  vector cá»™t embedding cho má»—i amino acid.
Em gáº·p lá»—i OOM (trÃ n bá»™ nhá»› GPU) khi mÃ´ hÃ¬nh muá»‘n encode thÃ¬ pháº£i allocate tensor nÃ y. Em biáº¿t cÃ³ giáº£i phÃ¡p lÃ  encoding cho batch cá»§a cÃ¡c trÃ¬nh tá»±, thÃ¬ em chÆ°a rÃµ láº¯m sáº½ lÃ m nhÆ° tháº¿ nÃ o, nhÆ°ng em cÃ³ phá»ng Ä‘oÃ¡n ráº±ng ta chia táº­p dá»¯ liá»‡u thÃ nh cÃ¡c batch nhá» cá»§a cÃ¡c trÃ¬nh tá»± rá»“i tá»« pretrained tokenizer gá»i ra encode_batch_plus cho tá»«ng batch trÃ¬nh tá»± ra Ä‘Æ°á»£c input_ids cho tá»«ng batch, sau Ä‘Ã³ dÃ¹ng má»›i pretrained model Ä‘á»ƒ láº¥y ra embedding cho cÃ¡c trÃ¬nh tá»± trong má»—i batch. Em nghÄ© tháº¿ Ä‘Ã£ há»£p lÃ½ chÆ°a áº¡, náº¿u em hiá»ƒu cÃ³ pháº§n nÃ o sai hoáº·c chÆ°a Ä‘Ãºng thÃ¬ anh chá»‹ vÃ  má»i ngÆ°á»i cÃ³ thá»ƒ chá»‰ giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Em chÃ o má»i ngÆ°á»i. Em Ä‘ng giáº£i bÃ i toÃ¡n vá» embedding cho amino acid cá»§a trÃ¬nh tá»± protein (váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ tÆ°Æ¡ng tá»± nhÆ° trong NLP á»Ÿ chá»— amino acid lÃ  word, protein lÃ  sentence, Ä‘Ã¢y lÃ  bÃ i toÃ¡n word embedding). Em Ä‘Ã£ tÃ¬m mÃ´ hÃ¬nh pre-trained BERT cho amino acid (https://huggingface.co/Rostlab/prot_bert). Vá»›i mÃ´ hÃ¬nh pretrained nÃ y, cÃ³ thá»ƒ sinh ra cÃ¡c contextual embedding cho amino acid á»Ÿ trong má»—i trÃ¬nh tá»± protein. á» Ä‘Ã¢y, em cáº§n encode cho tÃ¢p dá»¯ liá»‡u cá»§a mÃ¬nh gá»“m nhiá»u trÃ¬nh tá»± protein (khoáº£ng 2500). Tuy nhiÃªn, káº¿t quáº£ náº¿u em encode Ä‘á»“ng thá»i toÃ n bá»™ cáº£ táº­p dá»¯ liá»‡u nÃ y cá»§a mÃ¬nh, thÃ¬ cáº§n pháº£i allocate tensor cÃ³ kÃ­ch thÆ°á»›c lá»›n (2500, 2000, 1024). 2500 lÃ  sá»‘ trÃ¬nh tá»± protein em cÃ³ tÆ°Æ¡ng á»©ng vá»›i 2500 sentences; 2000 lÃ  chiá»u dÃ i cá»§a má»™t trÃ¬nh tá»± sau khi Ä‘Ã£ Ä‘Æ°á»£c padding, tÆ°Æ¡ng á»©ng vá»›i sá»‘ amino acid hay sá»‘ tá»« trong má»™t sentence; 1024 lÃ  vector cá»™t embedding cho má»—i amino acid. Em gáº·p lá»—i OOM (trÃ n bá»™ nhá»› GPU) khi mÃ´ hÃ¬nh muá»‘n encode thÃ¬ pháº£i allocate tensor nÃ y. Em biáº¿t cÃ³ giáº£i phÃ¡p lÃ  encoding cho batch cá»§a cÃ¡c trÃ¬nh tá»±, thÃ¬ em chÆ°a rÃµ láº¯m sáº½ lÃ m nhÆ° tháº¿ nÃ o, nhÆ°ng em cÃ³ phá»ng Ä‘oÃ¡n ráº±ng ta chia táº­p dá»¯ liá»‡u thÃ nh cÃ¡c batch nhá» cá»§a cÃ¡c trÃ¬nh tá»± rá»“i tá»« pretrained tokenizer gá»i ra encode_batch_plus cho tá»«ng batch trÃ¬nh tá»± ra Ä‘Æ°á»£c input_ids cho tá»«ng batch, sau Ä‘Ã³ dÃ¹ng má»›i pretrained model Ä‘á»ƒ láº¥y ra embedding cho cÃ¡c trÃ¬nh tá»± trong má»—i batch. Em nghÄ© tháº¿ Ä‘Ã£ há»£p lÃ½ chÆ°a áº¡, náº¿u em hiá»ƒu cÃ³ pháº§n nÃ o sai hoáº·c chÆ°a Ä‘Ãºng thÃ¬ anh chá»‹ vÃ  má»i ngÆ°á»i cÃ³ thá»ƒ chá»‰ giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang xÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n tuá»•i vÃ  giá»›i tÃ­nh. NhÆ°ng trong quÃ¡ trÃ¬nh train thÃ¬ acc_train vÃ  loss_train thay Ä‘á»•i khÃ¡ á»•n, nhÆ°ng em váº«n chÆ°a hiá»ƒu acc_val vÃ  loss_val vÃ¬ sau lÃºc Ä‘áº§u thay Ä‘á»•i tá»‘t nhÆ°ng sau Ä‘Ã³ thÃ¬ khÃ´ng cÃ²n á»•n Ä‘á»‹nh ná»¯a.
Nhá» má»i ngÆ°á»i giáº£i thÃ­ch há»™ em lÃ  do mÃ´ hÃ¬nh chÆ°a phÃ¹ há»£p hay nhá»¯ng tham sá»‘ chÆ°a phÃ¹ há»£p. Em sá»­ dá»¥ng pre-train mÃ´ hÃ¬nh alexnet.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang xÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n tuá»•i vÃ  giá»›i tÃ­nh. NhÆ°ng trong quÃ¡ trÃ¬nh train thÃ¬ acc_train vÃ  loss_train thay Ä‘á»•i khÃ¡ á»•n, nhÆ°ng em váº«n chÆ°a hiá»ƒu acc_val vÃ  loss_val vÃ¬ sau lÃºc Ä‘áº§u thay Ä‘á»•i tá»‘t nhÆ°ng sau Ä‘Ã³ thÃ¬ khÃ´ng cÃ²n á»•n Ä‘á»‹nh ná»¯a. Nhá» má»i ngÆ°á»i giáº£i thÃ­ch há»™ em lÃ  do mÃ´ hÃ¬nh chÆ°a phÃ¹ há»£p hay nhá»¯ng tham sá»‘ chÆ°a phÃ¹ há»£p. Em sá»­ dá»¥ng pre-train mÃ´ hÃ¬nh alexnet.",,,,,
"ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i, hiÃªÌ£n taÌ£i em Ä‘ang laÌ€m Ä‘Ã´Ì€ aÌn vÃªÌ€ nhÃ¢Ì£n daÌ£ng Ä‘Ã´Ì€ baÌ‰o hÃ´Ì£ cuÌ‰a cÃ´ng nhÃ¢n trong nhaÌ€ maÌy ( coÌ mÄƒÌ£c khÃ´ng mÄƒÌ£c, chuÌ‰ yÃªÌu laÌ€ noÌn vaÌ€ aÌo ) thiÌ€ khÃ´ng biÃªÌt coÌ dataset naÌ€o coÌ sÄƒÌ‰n khÃ´ng aÌ£, em Ä‘ang laÌ€m caÌch thuÌ‰ cÃ´ng taÌ‰i vÃªÌ€ tÆ°Ì€ng tÃ¢Ìm thÃ¢Ìy noÌ hÆ¡i lÃ¢u, em caÌ‰m Æ¡n !","ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i, hiÃªÌ£n taÌ£i em Ä‘ang laÌ€m Ä‘Ã´Ì€ aÌn vÃªÌ€ nhÃ¢Ì£n daÌ£ng Ä‘Ã´Ì€ baÌ‰o hÃ´Ì£ cuÌ‰a cÃ´ng nhÃ¢n trong nhaÌ€ maÌy ( coÌ mÄƒÌ£c khÃ´ng mÄƒÌ£c, chuÌ‰ yÃªÌu laÌ€ noÌn vaÌ€ aÌo ) thiÌ€ khÃ´ng biÃªÌt coÌ dataset naÌ€o coÌ sÄƒÌ‰n khÃ´ng aÌ£, em Ä‘ang laÌ€m caÌch thuÌ‰ cÃ´ng taÌ‰i vÃªÌ€ tÆ°Ì€ng tÃ¢Ìm thÃ¢Ìy noÌ hÆ¡i lÃ¢u, em caÌ‰m Æ¡n !",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Má»i ngÆ°á»i cho e há»i, em cÃ³ má»™t Ä‘oáº¡n dá»¯ liá»‡u khiá»ƒu nhÆ° hÃ¬nh, bÃ¢y giá» cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o cÃ³ thá»ƒ phÃ¢n nÃ³ ra thÃ nh cÃ¡c Ä‘oáº¡n Ä‘Æ°á»£c khÃ´ng áº¡ ( pháº§n Ä‘Ã¡nh dáº¥u bÃªn dÆ°á»›i lÃ  anotation sáºµn, bÃ¢y giá» em muá»‘n cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o mÃ  cÃ³ thá»ƒ tá»± Ä‘á»™ng phÃ¢n Ä‘oáº¡n áº¡)
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","Em chÃ o má»i ngÆ°á»i áº¡. Má»i ngÆ°á»i cho e há»i, em cÃ³ má»™t Ä‘oáº¡n dá»¯ liá»‡u khiá»ƒu nhÆ° hÃ¬nh, bÃ¢y giá» cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o cÃ³ thá»ƒ phÃ¢n nÃ³ ra thÃ nh cÃ¡c Ä‘oáº¡n Ä‘Æ°á»£c khÃ´ng áº¡ ( pháº§n Ä‘Ã¡nh dáº¥u bÃªn dÆ°á»›i lÃ  anotation sáºµn, bÃ¢y giá» em muá»‘n cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o mÃ  cÃ³ thá»ƒ tá»± Ä‘á»™ng phÃ¢n Ä‘oáº¡n áº¡) Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"[Há»c sÃ¢u trong y sinh: drug-target affinity (dta), drug-cellline response (dcr)]
[Tl-dr: Sá»­ dá»¥ng kiáº¿n trÃºc 'khÃ´ng há»£p lÃ½' nhÆ°ng káº¿t quáº£ váº«n tá»‘t?]
MÃ¬nh cÃ³ Ä‘á»c má»™t sá»‘ paper vá» chá»§ Ä‘á» dta, dcr vÃ  tháº¥y cÃ³ má»™t sá»‘ trong Ä‘Ã³ dÃ¹ng kiáº¿n trÃºc khÃ´ng há»£p lÃ½ nhÆ°ng váº«n cho káº¿t quáº£ vÆ°á»£t SOTA, vÆ°á»£t random forest vá»›i SVM.
VÃ­ dá»¥:
+/DeepH-DTA (https://ieeexplore.ieee.org/document/9197589): dÃ¹ng CNN vá»›i dá»¯ liá»‡u dáº¡ng tf-idf, dÃ¹ng CNN lai RNN nhÆ°ng (nhiá»u kháº£ nÄƒng) tháº­t ra láº¡i lÃ  RNN?
+/DeepGS (https://arxiv.org/abs/2003.13902) (mÃ¬nh chá»‰ tÃ¬m tháº¥y lÆ°u trÃªn arxiv, chÆ°a tháº¥y á»Ÿ táº¡p chÃ­ khÃ¡c):DÃ¹ng CNN vá»›i kernel trÆ°á»£t trÃªn chiá»u channel/feature?
+/CDRscan (https://www.nature.com/articles/s41598-018-27214-6): DÃ¹ng tanh lÃ m activation cho lá»›p ffnn cuá»‘i cÃ¹ng trong khi tÃ¡c vá»¥ lÃ  há»“i quy? (Tháº­t ra mÃ´ hÃ¬nh cá»§a há» gá»“m 5 mÃ´ hÃ¬nh con, Ä‘áº§u ra mÃ´ hÃ¬nh báº±ng trung bÃ¬nh Ä‘áº§u ra cá»§a 5 mÃ´ hÃ¬nh con, mÃ´ hÃ¬nh tanh chá»‰ lÃ  1 trong 5 mÃ´ hÃ¬nh con Ä‘Ã³, 4 mÃ´ hÃ¬nh cÃ²n láº¡i thÃ¬ khÃ´ng cÃ³ activation á»Ÿ cuá»‘i nhÆ° bÃ¬nh thÆ°á»ng) GhÃ©p input hoáº·c hidden representation cá»§a thuá»‘c vá»›i cell line trÆ°á»›c khi cho vÃ o CNN, tá»©c dÃ¹ng chung má»™t kernel cho thuá»‘c vÃ  cell line?
Váº­y káº¿t quáº£ tá»‘t lÃ  do mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n, nhiá»u param hÆ¡n, train trÃªn pháº§n cá»©ng tá»‘t hÆ¡n báº¥t ká»ƒ mÃ´ hÃ¬nh hay cÃ³ lá»i giáº£i thÃ­ch há»£p lÃ½ cho nhá»¯ng lá»±a chá»n nÃ y? Nhá»¯ng bÃ i toÃ¡n á»Ÿ domain khÃ¡c cÃ³ tá»«ng sá»­ dá»¥ng nhá»¯ng ká»¹ thá»¥aat trÃªn hay khÃ´ng?
Em cáº£m Æ¡n má»i ngÆ°á»i.","[Há»c sÃ¢u trong y sinh: drug-target affinity (dta), drug-cellline response (dcr)] [Tl-dr: Sá»­ dá»¥ng kiáº¿n trÃºc 'khÃ´ng há»£p lÃ½' nhÆ°ng káº¿t quáº£ váº«n tá»‘t?] MÃ¬nh cÃ³ Ä‘á»c má»™t sá»‘ paper vá» chá»§ Ä‘á» dta, dcr vÃ  tháº¥y cÃ³ má»™t sá»‘ trong Ä‘Ã³ dÃ¹ng kiáº¿n trÃºc khÃ´ng há»£p lÃ½ nhÆ°ng váº«n cho káº¿t quáº£ vÆ°á»£t SOTA, vÆ°á»£t random forest vá»›i SVM. VÃ­ dá»¥: +/DeepH-DTA (https://ieeexplore.ieee.org/document/9197589): dÃ¹ng CNN vá»›i dá»¯ liá»‡u dáº¡ng tf-idf, dÃ¹ng CNN lai RNN nhÆ°ng (nhiá»u kháº£ nÄƒng) tháº­t ra láº¡i lÃ  RNN? +/DeepGS (https://arxiv.org/abs/2003.13902) (mÃ¬nh chá»‰ tÃ¬m tháº¥y lÆ°u trÃªn arxiv, chÆ°a tháº¥y á»Ÿ táº¡p chÃ­ khÃ¡c):DÃ¹ng CNN vá»›i kernel trÆ°á»£t trÃªn chiá»u channel/feature? +/CDRscan (https://www.nature.com/articles/s41598-018-27214-6): DÃ¹ng tanh lÃ m activation cho lá»›p ffnn cuá»‘i cÃ¹ng trong khi tÃ¡c vá»¥ lÃ  há»“i quy? (Tháº­t ra mÃ´ hÃ¬nh cá»§a há» gá»“m 5 mÃ´ hÃ¬nh con, Ä‘áº§u ra mÃ´ hÃ¬nh báº±ng trung bÃ¬nh Ä‘áº§u ra cá»§a 5 mÃ´ hÃ¬nh con, mÃ´ hÃ¬nh tanh chá»‰ lÃ  1 trong 5 mÃ´ hÃ¬nh con Ä‘Ã³, 4 mÃ´ hÃ¬nh cÃ²n láº¡i thÃ¬ khÃ´ng cÃ³ activation á»Ÿ cuá»‘i nhÆ° bÃ¬nh thÆ°á»ng) GhÃ©p input hoáº·c hidden representation cá»§a thuá»‘c vá»›i cell line trÆ°á»›c khi cho vÃ o CNN, tá»©c dÃ¹ng chung má»™t kernel cho thuá»‘c vÃ  cell line? Váº­y káº¿t quáº£ tá»‘t lÃ  do mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n, nhiá»u param hÆ¡n, train trÃªn pháº§n cá»©ng tá»‘t hÆ¡n báº¥t ká»ƒ mÃ´ hÃ¬nh hay cÃ³ lá»i giáº£i thÃ­ch há»£p lÃ½ cho nhá»¯ng lá»±a chá»n nÃ y? Nhá»¯ng bÃ i toÃ¡n á»Ÿ domain khÃ¡c cÃ³ tá»«ng sá»­ dá»¥ng nhá»¯ng ká»¹ thá»¥aat trÃªn hay khÃ´ng? Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Má»™t há»‡ thá»‘ng camera giÃ¡m sÃ¡t á»Ÿ Quáº¿ DÆ°Æ¡ng, Trung Quá»‘c chá»‰ máº¥t 7 phÃºt Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vá»‹ trÃ­ má»™t phÃ³ng viÃªn dá»±a vÃ o áº£nh khuÃ´n máº·t cá»§a há». ÄÃ¢y lÃ  káº¿t quáº£ cá»§a má»™t máº¡ng lÆ°á»›i camera quy mÃ´ lá»›n cÃ¹ng vá»›i cÃ´ng nghá»‡ nháº­n dáº¡ng khuÃ´n máº·t (Face Recognition).
HÃ£y cÃ¹ng mÃ¬nh tÃ¬m hiá»ƒu xem cÃ´ng nghá»‡ nÃ y lÃ  gÃ¬, hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o vÃ  thá»±c hÃ nh vá»›i má»™t vÃ­ dá»¥ nho nhá» á»Ÿ cuá»‘i bÃ i nha.","Má»™t há»‡ thá»‘ng camera giÃ¡m sÃ¡t á»Ÿ Quáº¿ DÆ°Æ¡ng, Trung Quá»‘c chá»‰ máº¥t 7 phÃºt Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vá»‹ trÃ­ má»™t phÃ³ng viÃªn dá»±a vÃ o áº£nh khuÃ´n máº·t cá»§a há». ÄÃ¢y lÃ  káº¿t quáº£ cá»§a má»™t máº¡ng lÆ°á»›i camera quy mÃ´ lá»›n cÃ¹ng vá»›i cÃ´ng nghá»‡ nháº­n dáº¡ng khuÃ´n máº·t (Face Recognition). HÃ£y cÃ¹ng mÃ¬nh tÃ¬m hiá»ƒu xem cÃ´ng nghá»‡ nÃ y lÃ  gÃ¬, hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o vÃ  thá»±c hÃ nh vá»›i má»™t vÃ­ dá»¥ nho nhá» á»Ÿ cuá»‘i bÃ i nha.",,,,,
"Em dáº¡o nÃ y Ä‘ang tÃ¬m hiá»ƒu vá» Search vÃ  Recommender System. Hiá»‡n táº¡i em Ä‘ang Ä‘á»c cuá»‘n Deep Learning for Search nhÆ°ng cÃ³ váº» sÃ¡ch khÃ´ng cover nhiá»u material vá» nhá»¯ng transformers model má»›i láº¯m. KhÃ´ng biáº¿t trong group cÃ³ ai build hay lÃ m nhiá»u vá» Search vá»›i Recommender System cÃ³ thá»ƒ giÃºp point em Ä‘áº¿n má»™t sá»‘ material Ä‘Æ°á»£c khÃ´ng áº¡
Em cáº£m Æ¡n mng nhiá»u !",Em dáº¡o nÃ y Ä‘ang tÃ¬m hiá»ƒu vá» Search vÃ  Recommender System. Hiá»‡n táº¡i em Ä‘ang Ä‘á»c cuá»‘n Deep Learning for Search nhÆ°ng cÃ³ váº» sÃ¡ch khÃ´ng cover nhiá»u material vá» nhá»¯ng transformers model má»›i láº¯m. KhÃ´ng biáº¿t trong group cÃ³ ai build hay lÃ m nhiá»u vá» Search vá»›i Recommender System cÃ³ thá»ƒ giÃºp point em Ä‘áº¿n má»™t sá»‘ material Ä‘Æ°á»£c khÃ´ng áº¡ Em cáº£m Æ¡n mng nhiá»u !,,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» má»™t sá»‘ thÃ´ng tin vá» Graph Neural Networks (GNN) cÅ©ng nhÆ° thÆ° viá»‡n/codebases nhÆ° torch_geometric, dlg, vÃ  torchdrug. MÃ¬nh cÅ©ng má»›i nháº­n Ä‘Æ°á»£c new letter tá»« trang paperswithcode vá» xu hÆ°á»›ng nghiÃªn cá»©u vá» GNN. GNNs Ä‘ang cÃ³ nhá»¯ng tiáº¿n bá»™ ráº¥t nhanh vá» viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n vá»›i dá»¯ liá»‡u phá»©c há»£p. Äáº·c biá»‡t, GNN gáº§n Ä‘Ã¢y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n cáº¥u trÃºc phÃ¢n tá»­ proteins báº­c 3 vÃ  4. Viá»‡c nÃ y cÃ³ Ã½ nghÄ©a quan trá»ng trong viá»‡c tÃ¬m ra cÃ¡c cháº¥t má»›i cÃ³ kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c sinh há»c á»Ÿ má»©c Ä‘á»™ phÃ¢n tá»­ vÃ  táº¿ bÃ o.
ÄÃ¢y lÃ  link tá»›i bÃ i https://paperswithcode.com/newsletter/19/","Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» má»™t sá»‘ thÃ´ng tin vá» Graph Neural Networks (GNN) cÅ©ng nhÆ° thÆ° viá»‡n/codebases nhÆ° torch_geometric, dlg, vÃ  torchdrug. MÃ¬nh cÅ©ng má»›i nháº­n Ä‘Æ°á»£c new letter tá»« trang paperswithcode vá» xu hÆ°á»›ng nghiÃªn cá»©u vá» GNN. GNNs Ä‘ang cÃ³ nhá»¯ng tiáº¿n bá»™ ráº¥t nhanh vá» viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n vá»›i dá»¯ liá»‡u phá»©c há»£p. Äáº·c biá»‡t, GNN gáº§n Ä‘Ã¢y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n cáº¥u trÃºc phÃ¢n tá»­ proteins báº­c 3 vÃ  4. Viá»‡c nÃ y cÃ³ Ã½ nghÄ©a quan trá»ng trong viá»‡c tÃ¬m ra cÃ¡c cháº¥t má»›i cÃ³ kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c sinh há»c á»Ÿ má»©c Ä‘á»™ phÃ¢n tá»­ vÃ  táº¿ bÃ o. ÄÃ¢y lÃ  link tá»›i bÃ i https://paperswithcode.com/newsletter/19/",,,,,
"Em chÃ o má»i ngÆ°á»i. Em viáº¿t post nÃ y vá»›i nguyá»‡n vá»ng xin má»i ngÆ°á»i giÃºp em Ä‘á»‹nh hÆ°á»›ng viá»‡c há»c hiá»ƒu vÃ  xÃ¢y dá»±ng model sao cho hiá»‡u quáº£ áº¡.
Em lÃ  sinh viÃªn kinh táº¿ má»›i tá»‘t nghiá»‡p. CÃ³ sáºµn má»™t chÃºt vá»‘n liáº¿ng Ä‘Ã£ phÃ¢n tÃ­ch dá»¯ liá»‡u khi thi nghiÃªn cá»©u khoa há»c á»Ÿ trÆ°á»ng vÃ  kháº£ nÄƒng tiáº¿p thu toÃ¡n cáº¥p 3 á»•n nÃªn em Ä‘Ã£ tÃ¬m hiá»ƒu vÃ  muá»‘n Ä‘i theo con Ä‘Æ°á»ng DA. Trong quÃ¡ trÃ¬nh há»c, em cÃ³ tiáº¿p cáº­n Python vÃ  táº­p tÃ nh xÃ¢y dá»±ng cÃ¡c model. Ban Ä‘áº§u, lÃ m theo cÃ¡c dÃ²ng code vÃ  xÃ¢y ra Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh phá»• biáº¿n nhÆ° Linear regression, Logistics regression khiáº¿n em hÃ o há»©ng vÃ´ cÃ¹ng vÃ  oai vÃ´ cÃ¹ng khi tÆ°á»Ÿng nhÆ° mÃ¬nh Ä‘Ã£ bÆ°á»›c má»™t chÃ¢n vÃ o tháº¿ giá»›i machine learning Ä‘áº¿n nÆ¡i rá»“i.
NhÆ°ng cÃ ng há»c thÃ¬ em láº¡i cÃ ng hoang mang vÃ  má»‡t má»i. Váº¥n Ä‘á» chÃ­nh Ä‘Ã³ lÃ , cÃ¡c mÃ´ hÃ¬nh, thuáº­t toÃ¡n trong Python quÃ¡ bao la vÃ  rá»™ng lá»›n. Má»—i khi em tiáº¿p cáº­n má»™t mÃ´ hÃ¬nh nÃ o Ä‘Ã³, thÃ¬ em search trÃªn máº¡ng láº¡i cÃ³ vÃ´ sá»‘ trang nÃ³i vá» nÃ³. CÃ¡c hÃ m, phÆ°Æ¡ng trÃ¬nh chi chÃ­t em cá»© Ä‘á»c hoÃ i nhÆ°ng cÅ©ng khÃ´ng hiá»ƒu áº¡ (vÃ­ dá»¥ nhÆ° expectation maximization) KÃ¨m theo cÃ¡i kiáº¿n thá»©c chá»§ Ä‘áº¡o láº¡i cÃ³ cáº£ 1 Ä‘á»‘ng kiáº¿n thá»©c bÃªn lá» má»›i toanh khÃ¡c Ä‘Æ°á»£c chÃªm vÃ o khi tÃ¡c giáº£ giáº£i thÃ­ch thuáº­t toÃ¡n. Search cÃ ng nhiá»u trang thÃ¬ má»—i trang láº¡i nÃ³i khÃ¡c Ä‘i 1 tÃ­. Äáº¿n lÃºc hiá»ƒu rá»“i thÃ¬ viá»‡c tÃ¬m máº«u code Ä‘á»ƒ lÃ m khiáº¿n em hoang mang táº­p 2 khi má»—i tÃ¡c giáº£ há» láº¡i code theo 1 kiá»ƒu khÃ¡c nhau.
Khi há»c kinh táº¿ á»Ÿ Ä‘áº¡i há»c thÃ¬ em cÃ³ Ä‘Æ°á»£c tiáº¿p xÃºc vá»›i kinh táº¿ lÆ°á»£ng, xstk nhÆ°ng chá»‰ dá»«ng láº¡i á»Ÿ viá»‡c hiá»ƒu cÃ¡i nÃ y Ã¡p dá»¥ng cho trÆ°á»ng há»£p nÃ o rá»“i cá»© tháº¿ Ã¡p dá»¥ng luÃ´n chá»© khÃ´ng Ä‘Æ°á»£c há»c sÃ¢u, Ä‘Ã o sÃ¢u Ä‘á»ƒ hiá»ƒu váº¥n Ä‘á». ChÃ­nh vÃ¬ tháº¿ nhiá»u kiáº¿n thá»©c há»c xong dá»… dÃ ng rÆ¡i vÃ o quÃªn lÃ£ng. VÃ¬ váº­y, hiá»‡n nay em cáº£m tháº¥y viá»‡c há»c má»™t sá»‘ model vÃ  hiá»ƒu, náº¯m Ä‘Æ°á»£c rÃµ nhá»¯ng váº¥n Ä‘á» liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t, thá»‘ng kÃª trá»Ÿ thÃ nh trá»Ÿ ngáº¡i Ä‘á»‘i vá»›i em khi Ä‘á»c tÃ i liá»‡u vá» machine learning.
Em hi vá»ng náº¿u má»i ngÆ°á»i Ä‘á»c Ä‘áº¿n Ä‘Ã¢y thÃ¬ cÃ³ thá»ƒ cho em xin Ä‘á»‹nh hÆ°á»›ng há»c Ä‘Æ°á»£c khÃ´ng áº¡? DÆ°á»›i Ä‘Ã¢y lÃ  1 sá»‘ cÃ¢u há»i cá»§a em
- Kiáº¿n thá»©c bá»• trá»£ nÃ o vá» toÃ¡n cáº§n táº­p trung khi DA lÃ m machine learning?
- SÃ¡ch nÃ o nÃªn Ä‘á»c? Course nÃ o nÃªn há»c?
- Khi anh chá»‹ tiáº¿p xÃºc vá»›i 1 bÃ i toÃ¡n, anh chá»‹ váº¡ch ra hÆ°á»›ng Ä‘i Ä‘á»ƒ giáº£i quyáº¿t nÃ³ nhÆ° tháº¿ nÃ o? Khi anh chá»‹ tÃ¬m hiá»ƒu vÃ  tháº¥y nhiá»u cÃ¡ch viáº¿t code quÃ¡ thÃ¬ anh chá»‹ sáº½ lÃ m gÃ¬?
Em vÃ´ cÃ¹ng biáº¿t Æ¡n náº¿u anh chá»‹ giÃºp Ä‘á»¡ em Ä‘á»‹nh hÆ°á»›ng tá»‘t hÆ¡n áº¡. ChÃºc anh chá»‹ má»™t tuáº§n lÃ m viá»‡c nhiá»u niá»m vui vÃ  Ã½ nghÄ©a.","Em chÃ o má»i ngÆ°á»i. Em viáº¿t post nÃ y vá»›i nguyá»‡n vá»ng xin má»i ngÆ°á»i giÃºp em Ä‘á»‹nh hÆ°á»›ng viá»‡c há»c hiá»ƒu vÃ  xÃ¢y dá»±ng model sao cho hiá»‡u quáº£ áº¡. Em lÃ  sinh viÃªn kinh táº¿ má»›i tá»‘t nghiá»‡p. CÃ³ sáºµn má»™t chÃºt vá»‘n liáº¿ng Ä‘Ã£ phÃ¢n tÃ­ch dá»¯ liá»‡u khi thi nghiÃªn cá»©u khoa há»c á»Ÿ trÆ°á»ng vÃ  kháº£ nÄƒng tiáº¿p thu toÃ¡n cáº¥p 3 á»•n nÃªn em Ä‘Ã£ tÃ¬m hiá»ƒu vÃ  muá»‘n Ä‘i theo con Ä‘Æ°á»ng DA. Trong quÃ¡ trÃ¬nh há»c, em cÃ³ tiáº¿p cáº­n Python vÃ  táº­p tÃ nh xÃ¢y dá»±ng cÃ¡c model. Ban Ä‘áº§u, lÃ m theo cÃ¡c dÃ²ng code vÃ  xÃ¢y ra Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh phá»• biáº¿n nhÆ° Linear regression, Logistics regression khiáº¿n em hÃ o há»©ng vÃ´ cÃ¹ng vÃ  oai vÃ´ cÃ¹ng khi tÆ°á»Ÿng nhÆ° mÃ¬nh Ä‘Ã£ bÆ°á»›c má»™t chÃ¢n vÃ o tháº¿ giá»›i machine learning Ä‘áº¿n nÆ¡i rá»“i. NhÆ°ng cÃ ng há»c thÃ¬ em láº¡i cÃ ng hoang mang vÃ  má»‡t má»i. Váº¥n Ä‘á» chÃ­nh Ä‘Ã³ lÃ , cÃ¡c mÃ´ hÃ¬nh, thuáº­t toÃ¡n trong Python quÃ¡ bao la vÃ  rá»™ng lá»›n. Má»—i khi em tiáº¿p cáº­n má»™t mÃ´ hÃ¬nh nÃ o Ä‘Ã³, thÃ¬ em search trÃªn máº¡ng láº¡i cÃ³ vÃ´ sá»‘ trang nÃ³i vá» nÃ³. CÃ¡c hÃ m, phÆ°Æ¡ng trÃ¬nh chi chÃ­t em cá»© Ä‘á»c hoÃ i nhÆ°ng cÅ©ng khÃ´ng hiá»ƒu áº¡ (vÃ­ dá»¥ nhÆ° expectation maximization) KÃ¨m theo cÃ¡i kiáº¿n thá»©c chá»§ Ä‘áº¡o láº¡i cÃ³ cáº£ 1 Ä‘á»‘ng kiáº¿n thá»©c bÃªn lá» má»›i toanh khÃ¡c Ä‘Æ°á»£c chÃªm vÃ o khi tÃ¡c giáº£ giáº£i thÃ­ch thuáº­t toÃ¡n. Search cÃ ng nhiá»u trang thÃ¬ má»—i trang láº¡i nÃ³i khÃ¡c Ä‘i 1 tÃ­. Äáº¿n lÃºc hiá»ƒu rá»“i thÃ¬ viá»‡c tÃ¬m máº«u code Ä‘á»ƒ lÃ m khiáº¿n em hoang mang táº­p 2 khi má»—i tÃ¡c giáº£ há» láº¡i code theo 1 kiá»ƒu khÃ¡c nhau. Khi há»c kinh táº¿ á»Ÿ Ä‘áº¡i há»c thÃ¬ em cÃ³ Ä‘Æ°á»£c tiáº¿p xÃºc vá»›i kinh táº¿ lÆ°á»£ng, xstk nhÆ°ng chá»‰ dá»«ng láº¡i á»Ÿ viá»‡c hiá»ƒu cÃ¡i nÃ y Ã¡p dá»¥ng cho trÆ°á»ng há»£p nÃ o rá»“i cá»© tháº¿ Ã¡p dá»¥ng luÃ´n chá»© khÃ´ng Ä‘Æ°á»£c há»c sÃ¢u, Ä‘Ã o sÃ¢u Ä‘á»ƒ hiá»ƒu váº¥n Ä‘á». ChÃ­nh vÃ¬ tháº¿ nhiá»u kiáº¿n thá»©c há»c xong dá»… dÃ ng rÆ¡i vÃ o quÃªn lÃ£ng. VÃ¬ váº­y, hiá»‡n nay em cáº£m tháº¥y viá»‡c há»c má»™t sá»‘ model vÃ  hiá»ƒu, náº¯m Ä‘Æ°á»£c rÃµ nhá»¯ng váº¥n Ä‘á» liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t, thá»‘ng kÃª trá»Ÿ thÃ nh trá»Ÿ ngáº¡i Ä‘á»‘i vá»›i em khi Ä‘á»c tÃ i liá»‡u vá» machine learning. Em hi vá»ng náº¿u má»i ngÆ°á»i Ä‘á»c Ä‘áº¿n Ä‘Ã¢y thÃ¬ cÃ³ thá»ƒ cho em xin Ä‘á»‹nh hÆ°á»›ng há»c Ä‘Æ°á»£c khÃ´ng áº¡? DÆ°á»›i Ä‘Ã¢y lÃ  1 sá»‘ cÃ¢u há»i cá»§a em - Kiáº¿n thá»©c bá»• trá»£ nÃ o vá» toÃ¡n cáº§n táº­p trung khi DA lÃ m machine learning? - SÃ¡ch nÃ o nÃªn Ä‘á»c? Course nÃ o nÃªn há»c? - Khi anh chá»‹ tiáº¿p xÃºc vá»›i 1 bÃ i toÃ¡n, anh chá»‹ váº¡ch ra hÆ°á»›ng Ä‘i Ä‘á»ƒ giáº£i quyáº¿t nÃ³ nhÆ° tháº¿ nÃ o? Khi anh chá»‹ tÃ¬m hiá»ƒu vÃ  tháº¥y nhiá»u cÃ¡ch viáº¿t code quÃ¡ thÃ¬ anh chá»‹ sáº½ lÃ m gÃ¬? Em vÃ´ cÃ¹ng biáº¿t Æ¡n náº¿u anh chá»‹ giÃºp Ä‘á»¡ em Ä‘á»‹nh hÆ°á»›ng tá»‘t hÆ¡n áº¡. ChÃºc anh chá»‹ má»™t tuáº§n lÃ m viá»‡c nhiá»u niá»m vui vÃ  Ã½ nghÄ©a.",,,,,
"Em chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n áº¡! Hiá»‡n táº¡i em Ä‘ang lÃ m chuyÃªn Ä‘á» tá»‘t nghiá»‡p vá» thuáº­t toÃ¡n phÃ¢n cá»¥m K-means báº±ng Python áº¡, bá»™ dá»¯ liá»‡u cá»§a e gá»“m 2000 khÃ¡ch hÃ ng vay vá»‘n cá»§a 1 ngÃ¢n hÃ ng, em Ä‘Ã£ phÃ¢n cá»¥m chá»n K vÃ  phÃ¢n cá»¥m 1 2 3... cho tá»«ng khÃ¡ch hÃ ng rá»“i áº¡. Tuy nhiÃªn sau khi em ná»™p thÃ¬ tháº§y cÃ³ yÃªu cáº§u em phÃ¢n tá»«ng khÃ¡ch hÃ ng ra gá»“m 9 loáº¡i tá»« AAA Ä‘áº¿n C ( AAA, BB,...C lÃ  xáº¿p háº¡ng tÃ­n dá»¥ng) nhÆ°ng em khÃ´ng biáº¿t pháº£i lÃ m sao, anh chá»‹ nÃ o biáº¿t cÃ³ thá»ƒ tÆ° váº¥n giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n áº¡!ğŸ˜","Em chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n áº¡! Hiá»‡n táº¡i em Ä‘ang lÃ m chuyÃªn Ä‘á» tá»‘t nghiá»‡p vá» thuáº­t toÃ¡n phÃ¢n cá»¥m K-means báº±ng Python áº¡, bá»™ dá»¯ liá»‡u cá»§a e gá»“m 2000 khÃ¡ch hÃ ng vay vá»‘n cá»§a 1 ngÃ¢n hÃ ng, em Ä‘Ã£ phÃ¢n cá»¥m chá»n K vÃ  phÃ¢n cá»¥m 1 2 3... cho tá»«ng khÃ¡ch hÃ ng rá»“i áº¡. Tuy nhiÃªn sau khi em ná»™p thÃ¬ tháº§y cÃ³ yÃªu cáº§u em phÃ¢n tá»«ng khÃ¡ch hÃ ng ra gá»“m 9 loáº¡i tá»« AAA Ä‘áº¿n C ( AAA, BB,...C lÃ  xáº¿p háº¡ng tÃ­n dá»¥ng) nhÆ°ng em khÃ´ng biáº¿t pháº£i lÃ m sao, anh chá»‹ nÃ o biáº¿t cÃ³ thá»ƒ tÆ° váº¥n giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n áº¡!",,,,,
"Dear all,
Iâ€™m looking for a talented PhD candidate to work with me on theoretical Artificial Intelligence. I work mostly at the intersection of theoretical reinforcement learning, multiagent systems, and game theory. In particular, Iâ€™m mainly interested in the following topics: multi-agent learning with strategic agents, fairness and truthfulness in multi-agent learning, and learning with structured data.
If you are interested in any of these topics, donâ€™t hesitate to contact me. 
Details: 
Deadline for applications: January 31, 2022.
Application decisions: Decisions will be announced in March 2022.
Eligibility: Scholarships are open to Home, EU, and international applicants.

A few words about Warwick and its CS department: 
The Computer Science Department at Warwick is ranked 1st in the UK for scientific output and 2nd overall in the latest UK Research Excellence Framework. The PhD scholarship will give you the opportunity to join a leading Computer Science department, and pursue academic excellence in your chosen area of Computer Science: Artificial Intelligence, Applied Computing, Data Science, Human Centred Computing, Security, Systems, or Theory. In addition, Warwick a university is constantly ranked in top 70-80 of the world in the major rankings.

You can find more details about the application here:
https://warwick.ac.uk/fac/sci/dcs/research/doctoralstudies/fundingadvice/
You can also check my departmental web page for more of my lab/research interest:
https://warwick.ac.uk/fac/sci/dcs/people/long_tran-thanh/","Dear all, Iâ€™m looking for a talented PhD candidate to work with me on theoretical Artificial Intelligence. I work mostly at the intersection of theoretical reinforcement learning, multiagent systems, and game theory. In particular, Iâ€™m mainly interested in the following topics: multi-agent learning with strategic agents, fairness and truthfulness in multi-agent learning, and learning with structured data. If you are interested in any of these topics, donâ€™t hesitate to contact me. Details: Deadline for applications: January 31, 2022. Application decisions: Decisions will be announced in March 2022. Eligibility: Scholarships are open to Home, EU, and international applicants. A few words about Warwick and its CS department: The Computer Science Department at Warwick is ranked 1st in the UK for scientific output and 2nd overall in the latest UK Research Excellence Framework. The PhD scholarship will give you the opportunity to join a leading Computer Science department, and pursue academic excellence in your chosen area of Computer Science: Artificial Intelligence, Applied Computing, Data Science, Human Centred Computing, Security, Systems, or Theory. In addition, Warwick a university is constantly ranked in top 70-80 of the world in the major rankings. You can find more details about the application here: https://warwick.ac.uk/fac/sci/dcs/research/doctoralstudies/fundingadvice/ You can also check my departmental web page for more of my lab/research interest: https://warwick.ac.uk/fac/sci/dcs/people/long_tran-thanh/",,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ vÃ i chá»— chÆ°a hiá»ƒu rÃµ vá» Transfer learning, mong má»i ngÆ°á»i chá»‰ dáº¡y!

VÃ­ dá»¥ em Ä‘ang lÃ m vá»›i pretrain weight VGG16 (base network).
Model cá»§a em cÃ³ dáº¡ng: VGG16 (bá» cÃ¡c layer fully connected á»Ÿ cuá»‘i) + kiáº¿n trÃºc riÃªng cá»§a mÃ¬nh
Flow: sau khi truyá»n pretrain weight vÃ o base network, nháº­p input vÃ o, qua Ä‘Æ°á»£c base network sáº½ cho output lÃ  cÃ¡c feature tá»‘t, rá»“i má»›i Ä‘Æ°a vÃ´ kiáº¿n trÃºc riÃªng.
1) Em tháº¥y trÃªn máº¡ng, khi dÃ¹ng láº¡i base network ngÆ°á»i ta bá» Ä‘i lá»›p Fully connected Ä‘á»ƒ lÃ m gÃ¬ váº­y? (Em nghÄ© lÃ  há» chá»‰ muá»‘n dá»«ng láº¡i á»Ÿ layer conv cuá»‘i nháº±m láº¥y Ä‘Æ°á»£c higher level feature tá»‘t)
2) Náº¿u em bá» randomly vÃ i node thÃ¬ pre-weight váº«n load Ä‘Æ°á»£c nhÆ°ng theo em 100% feature á»Ÿ cuá»‘i base network sáº½ ra khÃ¡c mong Ä‘á»£i?
3) CÃ³ ngÆ°á»i nÃ³i: cÃ¡c layer conv2D á»Ÿ cuá»‘i VGG16 má»›i trÃ­ch xuáº¥t cÃ¡c feature high level. Váº­y náº¿u chá»‰ chá»«a vÃ i layer cuá»‘i cá»§a VGG16 láº¡i lÃ m base network thÃ´i thÃ¬ sáº½ váº«n tá»‘t? (theo em, quan Ä‘iá»ƒm nÃ y sai, vÃ¬ feature pháº£i Ä‘Æ°á»£c rÃºt trÃ­ch theo tá»«ng layer má»›i Ä‘áº¿n Ä‘Æ°á»£c high level feature)
4) Váº­y, viá»‡c thay Ä‘á»•i cáº¥u trÃºc trong base network + load pretrain weight cÃ³ kháº£ thi khÃ´ng ?
5) ThÃ´ng thÆ°á»ng ,khi nÃ o mÃ¬nh má»›i freeze pháº§n pretrain-weight vÃ  chá»‰ cáº­p nháº­t weight á»Ÿ khÃºc sau? VÃ  khi nÃ o mÃ¬nh má»›i load pretrain-weight Ä‘á»ƒ nháº±m má»¥c Ä‘Ã­ch khá»Ÿi táº¡o + train láº¡i toÃ n bá»™ model?

Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c!
#transferlearning","ChÃ o má»i ngÆ°á»i, em cÃ³ vÃ i chá»— chÆ°a hiá»ƒu rÃµ vá» Transfer learning, mong má»i ngÆ°á»i chá»‰ dáº¡y! VÃ­ dá»¥ em Ä‘ang lÃ m vá»›i pretrain weight VGG16 (base network). Model cá»§a em cÃ³ dáº¡ng: VGG16 (bá» cÃ¡c layer fully connected á»Ÿ cuá»‘i) + kiáº¿n trÃºc riÃªng cá»§a mÃ¬nh Flow: sau khi truyá»n pretrain weight vÃ o base network, nháº­p input vÃ o, qua Ä‘Æ°á»£c base network sáº½ cho output lÃ  cÃ¡c feature tá»‘t, rá»“i má»›i Ä‘Æ°a vÃ´ kiáº¿n trÃºc riÃªng. 1) Em tháº¥y trÃªn máº¡ng, khi dÃ¹ng láº¡i base network ngÆ°á»i ta bá» Ä‘i lá»›p Fully connected Ä‘á»ƒ lÃ m gÃ¬ váº­y? (Em nghÄ© lÃ  há» chá»‰ muá»‘n dá»«ng láº¡i á»Ÿ layer conv cuá»‘i nháº±m láº¥y Ä‘Æ°á»£c higher level feature tá»‘t) 2) Náº¿u em bá» randomly vÃ i node thÃ¬ pre-weight váº«n load Ä‘Æ°á»£c nhÆ°ng theo em 100% feature á»Ÿ cuá»‘i base network sáº½ ra khÃ¡c mong Ä‘á»£i? 3) CÃ³ ngÆ°á»i nÃ³i: cÃ¡c layer conv2D á»Ÿ cuá»‘i VGG16 má»›i trÃ­ch xuáº¥t cÃ¡c feature high level. Váº­y náº¿u chá»‰ chá»«a vÃ i layer cuá»‘i cá»§a VGG16 láº¡i lÃ m base network thÃ´i thÃ¬ sáº½ váº«n tá»‘t? (theo em, quan Ä‘iá»ƒm nÃ y sai, vÃ¬ feature pháº£i Ä‘Æ°á»£c rÃºt trÃ­ch theo tá»«ng layer má»›i Ä‘áº¿n Ä‘Æ°á»£c high level feature) 4) Váº­y, viá»‡c thay Ä‘á»•i cáº¥u trÃºc trong base network + load pretrain weight cÃ³ kháº£ thi khÃ´ng ? 5) ThÃ´ng thÆ°á»ng ,khi nÃ o mÃ¬nh má»›i freeze pháº§n pretrain-weight vÃ  chá»‰ cáº­p nháº­t weight á»Ÿ khÃºc sau? VÃ  khi nÃ o mÃ¬nh má»›i load pretrain-weight Ä‘á»ƒ nháº±m má»¥c Ä‘Ã­ch khá»Ÿi táº¡o + train láº¡i toÃ n bá»™ model? Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c!",#transferlearning,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 10/2020 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 10/2020 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang thá»±c hiá»‡n 1 Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá» detect chim trong bá»™ data lÃ  cÃ¡c video quay Ä‘Æ°á»£c trÃªn cÃ¡c cÃ¡nh Ä‘á»“ng. Váº¥n Ä‘á» em gáº·p pháº£i lÃ  object quÃ¡ nhá» chá»‰ khoáº£ng 3-6 pixels. Em cÃ³ sá»­ dá»¥ng YOLOv4 káº¿t quáº£ detect Ä‘Æ°á»£c khÃ¡ tá»‘t cÃ¡c objects chÃ­nh, nhÆ°ng cÃ²n False Negative khÃ¡ cao. Em thá»­ káº¿t há»£p MobileNet Ä‘á»ƒ classify láº¡i thÃ¬ object chÃ­nh bá»‹ phÃ¢n loáº¡i sai khÃ¡ nhiá»u dáº«n Ä‘áº¿n F1-score khÃ´ng cÃ²n cao nhÆ° ban Ä‘áº§u ná»¯a. Má»i ngÆ°á»i cÃ³ biá»‡n phÃ¡p nÃ o khÃ¡c phá»¥c Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y khÃ´ng áº¡? Em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, em Ä‘ang thá»±c hiá»‡n 1 Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá» detect chim trong bá»™ data lÃ  cÃ¡c video quay Ä‘Æ°á»£c trÃªn cÃ¡c cÃ¡nh Ä‘á»“ng. Váº¥n Ä‘á» em gáº·p pháº£i lÃ  object quÃ¡ nhá» chá»‰ khoáº£ng 3-6 pixels. Em cÃ³ sá»­ dá»¥ng YOLOv4 káº¿t quáº£ detect Ä‘Æ°á»£c khÃ¡ tá»‘t cÃ¡c objects chÃ­nh, nhÆ°ng cÃ²n False Negative khÃ¡ cao. Em thá»­ káº¿t há»£p MobileNet Ä‘á»ƒ classify láº¡i thÃ¬ object chÃ­nh bá»‹ phÃ¢n loáº¡i sai khÃ¡ nhiá»u dáº«n Ä‘áº¿n F1-score khÃ´ng cÃ²n cao nhÆ° ban Ä‘áº§u ná»¯a. Má»i ngÆ°á»i cÃ³ biá»‡n phÃ¡p nÃ o khÃ¡c phá»¥c Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y khÃ´ng áº¡? Em xin cáº£m Æ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i. Em cÃ³ 1 tháº¯c máº¯c vá» viá»‡c sinh cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thÃ´ng qua PhÃ¢n phá»‘i chuáº©n nhiá»u chiá»u , ma tráº­n hiá»‡p phÆ°Æ¡ng sai ná»­a xÃ¡c Ä‘á»‹nh dÆ°Æ¡ng tá»± chá»n, Ä‘iá»ƒm ká»³ vá»ng tá»± chá»n. Em muá»‘n há»i lÃ  nguyÃªn lÃ½ lÃ m cÃ¡ch nÃ o mÃ  chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ sinh Ä‘Æ°á»£c dá»¯ liá»‡u thÃ´ng qua 3 yáº¿u tá»‘ Ä‘áº¥y. Em cÃ³ go definition cá»§a 1 hÃ m numpy.random.multivariate_normal(mean, covariace matrix, N) Ä‘á»ƒ tÃ¬m hiá»ƒu nhÆ°ng khÃ´ng tÃ¬m tháº¥y implements thá»±c sá»± mÃ  chá»‰ biáº¿t Ä‘Æ°á»£c lÃ  nÃ³ tráº£ vá» 1 list cÃ¡c Ä‘iá»ƒm cÃ³ dimention giá»‘ng mean. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em. Em cÃ¡m Æ¡n.","Em chÃ o má»i ngÆ°á»i. Em cÃ³ 1 tháº¯c máº¯c vá» viá»‡c sinh cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thÃ´ng qua PhÃ¢n phá»‘i chuáº©n nhiá»u chiá»u , ma tráº­n hiá»‡p phÆ°Æ¡ng sai ná»­a xÃ¡c Ä‘á»‹nh dÆ°Æ¡ng tá»± chá»n, Ä‘iá»ƒm ká»³ vá»ng tá»± chá»n. Em muá»‘n há»i lÃ  nguyÃªn lÃ½ lÃ m cÃ¡ch nÃ o mÃ  chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ sinh Ä‘Æ°á»£c dá»¯ liá»‡u thÃ´ng qua 3 yáº¿u tá»‘ Ä‘áº¥y. Em cÃ³ go definition cá»§a 1 hÃ m numpy.random.multivariate_normal(mean, covariace matrix, N) Ä‘á»ƒ tÃ¬m hiá»ƒu nhÆ°ng khÃ´ng tÃ¬m tháº¥y implements thá»±c sá»± mÃ  chá»‰ biáº¿t Ä‘Æ°á»£c lÃ  nÃ³ tráº£ vá» 1 list cÃ¡c Ä‘iá»ƒm cÃ³ dimention giá»‘ng mean. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em. Em cÃ¡m Æ¡n.",,,,,
"Xin chÃ o cÃ¡c báº¡n, cho mÃ¬nh há»i, mÃ¬nh sá»­ dá»¥ng sklearn train data, khi train mÃ¬nh cÃ³ sá»­ dá»¥ng hÃ m StandardScaler().fit_transform(x) Ä‘á»ƒ chuáº©n hÃ³a dá»¯ liá»‡u (dá»¯ liá»‡u 70k row). VÃ¢y khi mÃ¬nh cáº§n predict() 1 dÃ²ng dá»¯ liá»‡u, thÃ¬ cÃ³ cáº§n pháº£i sá»­ dá»¥ng StandardScaler().fit_transform(x) Ä‘á»ƒ chuáº©n hÃ³a nÃ³ trÆ°á»›c khi predict(0 ko?","Xin chÃ o cÃ¡c báº¡n, cho mÃ¬nh há»i, mÃ¬nh sá»­ dá»¥ng sklearn train data, khi train mÃ¬nh cÃ³ sá»­ dá»¥ng hÃ m StandardScaler().fit_transform(x) Ä‘á»ƒ chuáº©n hÃ³a dá»¯ liá»‡u (dá»¯ liá»‡u 70k row). VÃ¢y khi mÃ¬nh cáº§n predict() 1 dÃ²ng dá»¯ liá»‡u, thÃ¬ cÃ³ cáº§n pháº£i sá»­ dá»¥ng StandardScaler().fit_transform(x) Ä‘á»ƒ chuáº©n hÃ³a nÃ³ trÆ°á»›c khi predict(0 ko?",,,,,
"Em xin lÃ m phiá»n má»i ngÆ°á»i 1 chÃºt áº¡. Em Ä‘ang tÃ¬m hiá»ƒu vá» 1 con camera an ninh dá»±a trÃªn viá»‡c phÃ¢n tÃ­ch hÃ nh Ä‘á»™ng rá»“i tá»« Ä‘Ã³ Ä‘Æ°a ra dá»± Ä‘oÃ¡n lÃ  hÃ nh Ä‘á»™ng Ä‘Ã³ nÃ³ cÃ³ kháº£ nghi khÃ´ng. Hiá»‡n táº¡i thÃ¬ em Ä‘Ã£ cÃ³ thá»ƒ nháº­n diá»‡n vÃ  váº½ nhá»¯ng hÃ nh Ä‘á»™ng Ä‘Ã³ dÆ°á»›i dáº¡ng 2d, nhÆ°ng mÃ  em váº«n chÆ°a biáº¿t lÃ m sao Ä‘á»ƒ mÃ¡y tÃ­nh cÃ³ thá»ƒ phÃ¢n tÃ­ch vÃ  Ä‘Æ°a ra káº¿t luáº­n lÃ  hÃ nh Ä‘á»™ng Ä‘Ã³ cÃ³ nguy hiá»ƒm khÃ´ng. VÃ¬ tháº¿ nÃªn e lÃªn Ä‘Ã¢y Ä‘á»ƒ xin má»i ngÆ°á»i nhá»¯ng Ã½ kiáº¿n, gá»£i Ã½ cÅ©ng nhÆ° lÃ  hÆ°á»›ng dáº«n lÃ m sao Ä‘á»ƒ ğ¦ğšÌğ² ğ­ğ¢Ìğ§ğ¡ ğœğ¨Ì ğ­ğ¡ğÌ‚Ì‰ ğ©ğ¡ğšÌ‚ğ§ ğ­ğ¢Ìğœğ¡ ğ¯ğšÌ€ Ä‘ğ®Ì›ğš ğ«ğš ğğ®Ì›Ì£ Ä‘ğ¨ğšÌğ§ ğ¯ğÌ‚Ì€ ğ¦ğ®Ì›Ìğœ Ä‘ğ¨Ì£Ì‚ ğ§ğ ğ®ğ² ğ¡ğ¢ğÌ‚Ì‰ğ¦ ğœğ®Ì‰ğš ğ¡ğšÌ€ğ§ğ¡ Ä‘ğ¨Ì£Ì‚ğ§ğ  áº¡.
Em xin cáº£m Æ¡n áº¡.","Em xin lÃ m phiá»n má»i ngÆ°á»i 1 chÃºt áº¡. Em Ä‘ang tÃ¬m hiá»ƒu vá» 1 con camera an ninh dá»±a trÃªn viá»‡c phÃ¢n tÃ­ch hÃ nh Ä‘á»™ng rá»“i tá»« Ä‘Ã³ Ä‘Æ°a ra dá»± Ä‘oÃ¡n lÃ  hÃ nh Ä‘á»™ng Ä‘Ã³ nÃ³ cÃ³ kháº£ nghi khÃ´ng. Hiá»‡n táº¡i thÃ¬ em Ä‘Ã£ cÃ³ thá»ƒ nháº­n diá»‡n vÃ  váº½ nhá»¯ng hÃ nh Ä‘á»™ng Ä‘Ã³ dÆ°á»›i dáº¡ng 2d, nhÆ°ng mÃ  em váº«n chÆ°a biáº¿t lÃ m sao Ä‘á»ƒ mÃ¡y tÃ­nh cÃ³ thá»ƒ phÃ¢n tÃ­ch vÃ  Ä‘Æ°a ra káº¿t luáº­n lÃ  hÃ nh Ä‘á»™ng Ä‘Ã³ cÃ³ nguy hiá»ƒm khÃ´ng. VÃ¬ tháº¿ nÃªn e lÃªn Ä‘Ã¢y Ä‘á»ƒ xin má»i ngÆ°á»i nhá»¯ng Ã½ kiáº¿n, gá»£i Ã½ cÅ©ng nhÆ° lÃ  hÆ°á»›ng dáº«n lÃ m sao Ä‘á»ƒ Ì Ì Ì Ì‚Ì‰ Ì‚ Ì Ì€ Ä‘Ì› Ì›Ì£ Ä‘Ì Ì‚Ì€ Ì›Ì Ä‘Ì£Ì‚ Ì‚Ì‰ Ì‰ Ì€ Ä‘Ì£Ì‚ áº¡. Em xin cáº£m Æ¡n áº¡.",,,,,
"Em chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang muá»‘n há»c thÃªm khÃ³a há»c Ä‘á»ƒ nÃ¢ng cao kiáº¿n thá»©c vá» NLP vÃ  computer vision, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t vÃ i gá»£i Ã½ Ä‘Æ°á»£c khÃ´ng áº¡. KhÃ³a há»c nÃ o cÃ³ certificate cÃ ng tá»‘t áº¡ :D","Em chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang muá»‘n há»c thÃªm khÃ³a há»c Ä‘á»ƒ nÃ¢ng cao kiáº¿n thá»©c vá» NLP vÃ  computer vision, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t vÃ i gá»£i Ã½ Ä‘Æ°á»£c khÃ´ng áº¡. KhÃ³a há»c nÃ o cÃ³ certificate cÃ ng tá»‘t áº¡ :D",,,,,
"em xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i bá»n em lÃ  sinh viÃªn vÃ  Ä‘ang cÃ³ hÆ°á»›ng lÃ m bÃ i toÃ¡n vá» nháº­n dáº¡ng khuÃ´n máº·t + Ä‘iá»ƒm danh trÃªn camera. hiá»‡n táº¡i bÆ°á»›c chá»n camera bá»n em Ä‘ang gáº·p khÃ³ khÄƒn vÃ¬ kinh nghiá»‡m vá» camera sao cho phÃ¹ há»£p cÃ²n thiáº¿u. vÃ¬ váº­y em mong  má»i ngÆ°á»i ai Ä‘Ã£ cÃ³ kinh nghiá»‡m hoáº·c tá»«ng lÃ m bÃ i toÃ¡n liÃªn quan cÃ³ thá»ƒ gá»£i Ã½ cho bá»n em cÃ¡c loáº¡i camera cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c khÃ´ng áº¡
yÃªu cáº§u vá»›i camera: cÃ³ thá»ƒ káº¿t ná»‘i vÃ  implement code Ä‘Æ°á»£c trÃªn bá»™ xá»­ lÃ­ cá»§a camera, cÃ³ thá»ƒ truyá»n data vá» server Ä‘á»ƒ á»©ng dá»¥ng thÃªm trÃªn mÃ´i trÆ°á»ng web.
mong ad duyá»‡t bÃ i, cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡!","em xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i bá»n em lÃ  sinh viÃªn vÃ  Ä‘ang cÃ³ hÆ°á»›ng lÃ m bÃ i toÃ¡n vá» nháº­n dáº¡ng khuÃ´n máº·t + Ä‘iá»ƒm danh trÃªn camera. hiá»‡n táº¡i bÆ°á»›c chá»n camera bá»n em Ä‘ang gáº·p khÃ³ khÄƒn vÃ¬ kinh nghiá»‡m vá» camera sao cho phÃ¹ há»£p cÃ²n thiáº¿u. vÃ¬ váº­y em mong má»i ngÆ°á»i ai Ä‘Ã£ cÃ³ kinh nghiá»‡m hoáº·c tá»«ng lÃ m bÃ i toÃ¡n liÃªn quan cÃ³ thá»ƒ gá»£i Ã½ cho bá»n em cÃ¡c loáº¡i camera cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c khÃ´ng áº¡ yÃªu cáº§u vá»›i camera: cÃ³ thá»ƒ káº¿t ná»‘i vÃ  implement code Ä‘Æ°á»£c trÃªn bá»™ xá»­ lÃ­ cá»§a camera, cÃ³ thá»ƒ truyá»n data vá» server Ä‘á»ƒ á»©ng dá»¥ng thÃªm trÃªn mÃ´i trÆ°á»ng web. mong ad duyá»‡t bÃ i, cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡!",,,,,
"Xin chÃ o má»i ngÆ°á»i, e cÃ³ tháº¯c máº¯c lÃ  náº¿u e Ä‘á»‹nh hÆ°á»›ng chuyÃªn sÃ¢u vá» data science thÃ¬ cÃ³ cáº§n há»c sÃ¢u vÃ o cÃ¡c máº£ng cá»§a A, ML, DL khÃ´ng áº¡. sÃ¢u á»Ÿ Ä‘Ã¢y lÃ  cÃ³ thá»ƒ built Ä‘c model DL from scratch luÃ´n áº¡. Hay lÃ  chá»‰ cáº§n tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc vÃ  biáº¿t cÃ¡ch sá»­ dá»¥ng cÃ¡c pre-train model thÃ´i áº¡. Thank mn Ä‘Ã£ Ä‘á»c.","Xin chÃ o má»i ngÆ°á»i, e cÃ³ tháº¯c máº¯c lÃ  náº¿u e Ä‘á»‹nh hÆ°á»›ng chuyÃªn sÃ¢u vá» data science thÃ¬ cÃ³ cáº§n há»c sÃ¢u vÃ o cÃ¡c máº£ng cá»§a A, ML, DL khÃ´ng áº¡. sÃ¢u á»Ÿ Ä‘Ã¢y lÃ  cÃ³ thá»ƒ built Ä‘c model DL from scratch luÃ´n áº¡. Hay lÃ  chá»‰ cáº§n tÃ¬m hiá»ƒu vá» kiáº¿n trÃºc vÃ  biáº¿t cÃ¡ch sá»­ dá»¥ng cÃ¡c pre-train model thÃ´i áº¡. Thank mn Ä‘Ã£ Ä‘á»c.",,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang dÃ¹ng mÃ´ hÃ¬nh sinh áº£nh Glow model vÃ  em cÃ³ xem code sá»­ dá»¥ng pytorch nÃ y, cÃ³ Ä‘oáº¡n code nÃ y em chÆ°a hiá»ƒu ngÆ°á»i ta muá»‘n lÃ m gÃ¬ áº¡. áº¢nh á»Ÿ Ä‘Ã¢y ngÆ°á»i ta sá»­ dá»¥ng lÃ  á»Ÿ táº­p Celeba dataset kÃ­ch cá»¡ (3,64,64). n_bits = 5 vÃ  n_bins = 2 mÅ© 5.
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang dÃ¹ng mÃ´ hÃ¬nh sinh áº£nh Glow model vÃ  em cÃ³ xem code sá»­ dá»¥ng pytorch nÃ y, cÃ³ Ä‘oáº¡n code nÃ y em chÆ°a hiá»ƒu ngÆ°á»i ta muá»‘n lÃ m gÃ¬ áº¡. áº¢nh á»Ÿ Ä‘Ã¢y ngÆ°á»i ta sá»­ dá»¥ng lÃ  á»Ÿ táº­p Celeba dataset kÃ­ch cá»¡ (3,64,64). n_bits = 5 vÃ  n_bins = 2 mÅ© 5. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"MÃ¬nh cÃ³ má»™t thÃº vui khÃ¡ vÃ´ bá»• lÃ  ngá»“i tá»± code láº¡i cÃ¡c thuáº­t toÃ¡n. TÆ°Æ¡ng Ä‘á»‘i máº¥t thá»i gian hÃ¬nh dung cáº¥u trÃºc dá»¯ liá»‡u vÃ  giáº£i thuáº­t rá»“i gá»¡ rá»‘i. MÃ¬nh lÃ m báº£o vá»‡ nÃªn thá»i gian cÅ©ng nhiá»u.
BÃ¹ láº¡i, sau khi ra káº¿t quáº£ cÅ©ng tháº¥y hay hay, hiá»ƒu ra má»™t sá»‘ Ä‘iá»u mÃ  khÃ´ng thá»ƒ hiá»ƒu náº¿u chá»‰ Ä‘á»c sÃ¡ch hay cháº¡y láº¡i code cá»§a cao thá»§ khÃ¡c.
MÃ¬nh máº¥t Ä‘Ãºng má»™t ngÃ y Ä‘á»ƒ code láº¡i thuáº­t toÃ¡n K-Means clustering (khÃ´ng tham kháº£o code trÃªn máº¡ng nhÃ©).
Sau Ä‘Ã³ váº½ Ä‘Æ°á»ng bao quanh cÃ¡c cluster sau khi phÃ¢n chia tháº¥y má»™t Ä‘áº·c Ä‘iá»ƒm cÃ¡c Ä‘Æ°á»ng bao má»—i cluster khÃ´ng giao nhau.
Mai nghá»‹ch tiáº¿p Matplotlib animation Ä‘á»ƒ hoáº¡t hÃ¬nh tá»«ng bÆ°á»›c cháº¡y má»™t xem tháº¿ nÃ o.
Má»i thuáº­t toÃ¡n phá»©c táº¡p khi visualize trong khÃ´ng gian 2-3 chiá»u trá»Ÿ nÃªn ráº¥t Ä‘áº¹p. MÃ¬nh lÃ  fan cá»§a Youtube channel 3Blue1Brown.
Animation xong sáº½ viáº¿t bÃ i hÆ°á»›ng dáº«n nhÃ©","MÃ¬nh cÃ³ má»™t thÃº vui khÃ¡ vÃ´ bá»• lÃ  ngá»“i tá»± code láº¡i cÃ¡c thuáº­t toÃ¡n. TÆ°Æ¡ng Ä‘á»‘i máº¥t thá»i gian hÃ¬nh dung cáº¥u trÃºc dá»¯ liá»‡u vÃ  giáº£i thuáº­t rá»“i gá»¡ rá»‘i. MÃ¬nh lÃ m báº£o vá»‡ nÃªn thá»i gian cÅ©ng nhiá»u. BÃ¹ láº¡i, sau khi ra káº¿t quáº£ cÅ©ng tháº¥y hay hay, hiá»ƒu ra má»™t sá»‘ Ä‘iá»u mÃ  khÃ´ng thá»ƒ hiá»ƒu náº¿u chá»‰ Ä‘á»c sÃ¡ch hay cháº¡y láº¡i code cá»§a cao thá»§ khÃ¡c. MÃ¬nh máº¥t Ä‘Ãºng má»™t ngÃ y Ä‘á»ƒ code láº¡i thuáº­t toÃ¡n K-Means clustering (khÃ´ng tham kháº£o code trÃªn máº¡ng nhÃ©). Sau Ä‘Ã³ váº½ Ä‘Æ°á»ng bao quanh cÃ¡c cluster sau khi phÃ¢n chia tháº¥y má»™t Ä‘áº·c Ä‘iá»ƒm cÃ¡c Ä‘Æ°á»ng bao má»—i cluster khÃ´ng giao nhau. Mai nghá»‹ch tiáº¿p Matplotlib animation Ä‘á»ƒ hoáº¡t hÃ¬nh tá»«ng bÆ°á»›c cháº¡y má»™t xem tháº¿ nÃ o. Má»i thuáº­t toÃ¡n phá»©c táº¡p khi visualize trong khÃ´ng gian 2-3 chiá»u trá»Ÿ nÃªn ráº¥t Ä‘áº¹p. MÃ¬nh lÃ  fan cá»§a Youtube channel 3Blue1Brown. Animation xong sáº½ viáº¿t bÃ i hÆ°á»›ng dáº«n nhÃ©",,,,,
"Em chÃ o m.n, m.n cho em há»i mÃ¡y em cáº¥u hÃ¬nh tháº¥p yáº¿u táº£i sql hiá»‡n ra lá»—i ntn ( ká»ƒ cáº£ 2008, 2012 ) thÃ¬ lÃ m ntn Ä‘á»ƒ kháº¯c phá»¥c áº¡? E xin cáº£m Æ¡n","Em chÃ o m.n, m.n cho em há»i mÃ¡y em cáº¥u hÃ¬nh tháº¥p yáº¿u táº£i sql hiá»‡n ra lá»—i ntn ( ká»ƒ cáº£ 2008, 2012 ) thÃ¬ lÃ m ntn Ä‘á»ƒ kháº¯c phá»¥c áº¡? E xin cáº£m Æ¡n",,,,,
"[Video Meeting Data Question]
MÃ¬nh xin chia sáº» tá»›i cÃ¡c báº¡n buá»•i meeting Data Question Ä‘Æ°á»£c tá»• chá»©c nháº±m há»— trá»£ cÃ¡c báº¡n giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» liÃªn quan tá»›i mÃ´ hÃ¬nh, dá»¯ kiá»‡u vÃ  cÃ¡c kÄ© nÄƒng nghá» nghiá»‡p cáº§n thiáº¿t trong ngÃ nh AI vÃ  Machine Learning. CÃ¡c ná»™i dung chÃ­nh bao gá»“m:
- Nhá»¯ng kiáº¿n thá»©c vÃ  kÄ© nÄƒng cáº§n trang bá»‹ Ä‘á»ƒ theo há»c ngÃ nh Data Science Ä‘á»‘i vá»›i ngÆ°á»i muá»‘n chuyá»ƒn ngÃ nh?
- Knowledge Domain cÃ³ thá»±c sá»± cáº§n thiáº¿t? LÃ m tháº¿ nÃ o Ä‘á»ƒ trang bá»‹ kiáº¿n thá»©c vá» Business Ä‘á»‘i vá»›i sinh viÃªn khá»‘i IT?
- Kinh nghiá»‡m vá» lá»±a chá»n Data Augmentation vÃ  thá»±c nghiá»‡m mÃ´ hÃ¬nh?
- ÄÃ¢u lÃ  phÆ°Æ¡ng phÃ¡p handle missing data phÃ¹ há»£p?
- CÃ¡c tools gÃ¡n nhÃ£n hiá»‡u quáº£ cho bÃ i toÃ¡n NER annotation.
- NÃ¢ng cao hiá»‡u suáº¥t trÃ­ch lá»c ná»™i dung cho bÃ i toÃ¡n OCR.
- Kinh nghiá»‡m vá» con Ä‘Æ°á»ng hÆ°á»›ng tá»›i AI Engineer.
TowardDataScience xin cáº£m Æ¡n sá»± tham gia cá»§a khÃ¡ch má»i Nguyá»…n Viá»‡t Anh vÃ  cÃ¡c báº¡n Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c má»™t sá»± kiá»‡n thÃ nh cÃ´ng.
CÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi video buá»•i meeting bÃªn dÆ°á»›i:
https://www.youtube.com/watch?v=SNoOwtfjbQo
Náº¿u báº¡n tháº¥y ná»™i dung video há»¯u Ã­ch, vui lÃ²ng chia sáº» video tá»›i báº¡n bÃ¨ vÃ  Ä‘á»«ng quÃªn cho mÃ¬nh má»™t like video.
-------------------------------------
P/S: Buá»•i meeting tiáº¿p theo sáº½ Ä‘Æ°á»£c tá»• chá»©c vÃ o thá»© 4 ngÃ y 3/11/2021 tá»« 19:30-20:30 PM vá» chá»§ Ä‘á» ""Metrics Selection in Machine Learning"". Má»i cÃ¡c báº¡n tham dá»± vÃ  Ä‘áº·t cÃ¢u há»i táº¡i link:
https://meet.google.com/yjs-xudp-vpb","[Video Meeting Data Question] MÃ¬nh xin chia sáº» tá»›i cÃ¡c báº¡n buá»•i meeting Data Question Ä‘Æ°á»£c tá»• chá»©c nháº±m há»— trá»£ cÃ¡c báº¡n giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» liÃªn quan tá»›i mÃ´ hÃ¬nh, dá»¯ kiá»‡u vÃ  cÃ¡c kÄ© nÄƒng nghá» nghiá»‡p cáº§n thiáº¿t trong ngÃ nh AI vÃ  Machine Learning. CÃ¡c ná»™i dung chÃ­nh bao gá»“m: - Nhá»¯ng kiáº¿n thá»©c vÃ  kÄ© nÄƒng cáº§n trang bá»‹ Ä‘á»ƒ theo há»c ngÃ nh Data Science Ä‘á»‘i vá»›i ngÆ°á»i muá»‘n chuyá»ƒn ngÃ nh? - Knowledge Domain cÃ³ thá»±c sá»± cáº§n thiáº¿t? LÃ m tháº¿ nÃ o Ä‘á»ƒ trang bá»‹ kiáº¿n thá»©c vá» Business Ä‘á»‘i vá»›i sinh viÃªn khá»‘i IT? - Kinh nghiá»‡m vá» lá»±a chá»n Data Augmentation vÃ  thá»±c nghiá»‡m mÃ´ hÃ¬nh? - ÄÃ¢u lÃ  phÆ°Æ¡ng phÃ¡p handle missing data phÃ¹ há»£p? - CÃ¡c tools gÃ¡n nhÃ£n hiá»‡u quáº£ cho bÃ i toÃ¡n NER annotation. - NÃ¢ng cao hiá»‡u suáº¥t trÃ­ch lá»c ná»™i dung cho bÃ i toÃ¡n OCR. - Kinh nghiá»‡m vá» con Ä‘Æ°á»ng hÆ°á»›ng tá»›i AI Engineer. TowardDataScience xin cáº£m Æ¡n sá»± tham gia cá»§a khÃ¡ch má»i Nguyá»…n Viá»‡t Anh vÃ  cÃ¡c báº¡n Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c má»™t sá»± kiá»‡n thÃ nh cÃ´ng. CÃ¡c báº¡n cÃ³ thá»ƒ theo dÃµi video buá»•i meeting bÃªn dÆ°á»›i: https://www.youtube.com/watch?v=SNoOwtfjbQo Náº¿u báº¡n tháº¥y ná»™i dung video há»¯u Ã­ch, vui lÃ²ng chia sáº» video tá»›i báº¡n bÃ¨ vÃ  Ä‘á»«ng quÃªn cho mÃ¬nh má»™t like video. ------------------------------------- P/S: Buá»•i meeting tiáº¿p theo sáº½ Ä‘Æ°á»£c tá»• chá»©c vÃ o thá»© 4 ngÃ y 3/11/2021 tá»« 19:30-20:30 PM vá» chá»§ Ä‘á» ""Metrics Selection in Machine Learning"". Má»i cÃ¡c báº¡n tham dá»± vÃ  Ä‘áº·t cÃ¢u há»i táº¡i link: https://meet.google.com/yjs-xudp-vpb",,,,,
"Hiá»‡n táº¡i mÃ¬nh Ä‘ang theo há»c tháº¡c sÄ© ngÃ nh ML theo hÆ°á»›ng nghiÃªn cá»©u NLP vá»›i Ä‘á» tÃ i lÃ  Fake news detection. MÃ¬nh Ä‘Æ°á»£c giÃ¡o sÆ° ra yÃªu cáº§u nghiÃªn cá»©u vá» má»™t chá»§ Ä‘á» vá» Fake news detection Ä‘á»ƒ publish paper. MÃ¬nh nghÄ© ráº±ng Ä‘á»ƒ publish paper thÃ¬ cáº§n pháº£i nghÄ© ra má»™t cÃ¡i gÃ¬ Ä‘Ã³ má»›i, nhÆ°ng thá»±c sá»± mÃ¬nh Ä‘á»c ráº¥t nhiá»u paper thÃ¬ tháº¥y háº§u nhÆ° giá»›i khoa há»c Ä‘Ã£ lÃ m háº¿t rá»“i nÃªn khÃ´ng biáº¿t pháº£i lÃ m gÃ¬. KhÃ´ng biáº¿t anh/chá»‹/báº¡n bÃ¨ nÃ o cÃ³ kinh nghiá»‡m vá» máº£ng nÃ y cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn áº¡.
MÃ¬nh tháº­t sá»± cáº£m Æ¡n","Hiá»‡n táº¡i mÃ¬nh Ä‘ang theo há»c tháº¡c sÄ© ngÃ nh ML theo hÆ°á»›ng nghiÃªn cá»©u NLP vá»›i Ä‘á» tÃ i lÃ  Fake news detection. MÃ¬nh Ä‘Æ°á»£c giÃ¡o sÆ° ra yÃªu cáº§u nghiÃªn cá»©u vá» má»™t chá»§ Ä‘á» vá» Fake news detection Ä‘á»ƒ publish paper. MÃ¬nh nghÄ© ráº±ng Ä‘á»ƒ publish paper thÃ¬ cáº§n pháº£i nghÄ© ra má»™t cÃ¡i gÃ¬ Ä‘Ã³ má»›i, nhÆ°ng thá»±c sá»± mÃ¬nh Ä‘á»c ráº¥t nhiá»u paper thÃ¬ tháº¥y háº§u nhÆ° giá»›i khoa há»c Ä‘Ã£ lÃ m háº¿t rá»“i nÃªn khÃ´ng biáº¿t pháº£i lÃ m gÃ¬. KhÃ´ng biáº¿t anh/chá»‹/báº¡n bÃ¨ nÃ o cÃ³ kinh nghiá»‡m vá» máº£ng nÃ y cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn áº¡. MÃ¬nh tháº­t sá»± cáº£m Æ¡n",,,,,
Xin chia sáº» vá»›i cÃ¡c báº¡n má»™t repo vá» SQL do mÃ¬nh tá»•ng há»£p tá»« quÃ¡ trÃ¬nh lÃ m viá»‡c.,Xin chia sáº» vá»›i cÃ¡c báº¡n má»™t repo vá» SQL do mÃ¬nh tá»•ng há»£p tá»« quÃ¡ trÃ¬nh lÃ m viá»‡c.,,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 10/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 10/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.",,,,,
"ChÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i Ä‘ang lÃ m dá»± Ã¡n cho ngÆ°á»i mÃ¹ vÃ  em muá»‘n cÃ³ chá»©c nÄƒng cáº£nh bÃ¡o va cháº¡m, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin Ã½ kiáº¿n lÃ m sao Ä‘á»ƒ lÃ m khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i Ä‘ang lÃ m dá»± Ã¡n cho ngÆ°á»i mÃ¹ vÃ  em muá»‘n cÃ³ chá»©c nÄƒng cáº£nh bÃ¡o va cháº¡m, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin Ã½ kiáº¿n lÃ m sao Ä‘á»ƒ lÃ m khÃ´ng áº¡?",,,,,
"Cuá»‘n kinh Ä‘iá»ƒn mÃ  bÃ¡c Tiá»‡p khuyáº¿n khÃ­ch cÃ¡c báº¡n Ä‘á»c hiá»‡n Ä‘Ã£ sáº¯p ra báº£n má»›i. Báº£n xem trÆ°á»›c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ táº¡i https://probml.github.io/pml-book/book1.html
Em Ä‘Ã£ xem (lÆ°á»›t) báº£n cÅ© vÃ  tháº¥y nÃ³ cÅ©ng dá»… hiá»ƒu nhÆ°ng khÃ¡ kÄ© vá» toÃ¡n, ngÃ´n ngá»¯ ML hÆ¡i cá»•. BÃ¡c nÃ o xem báº£n má»›i xong cho ae cÃ¡i review ná»¯a cÃ ng tá»‘t. Thanks cÃ¡c bÃ¡c","Cuá»‘n kinh Ä‘iá»ƒn mÃ  bÃ¡c Tiá»‡p khuyáº¿n khÃ­ch cÃ¡c báº¡n Ä‘á»c hiá»‡n Ä‘Ã£ sáº¯p ra báº£n má»›i. Báº£n xem trÆ°á»›c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ táº¡i https://probml.github.io/pml-book/book1.html Em Ä‘Ã£ xem (lÆ°á»›t) báº£n cÅ© vÃ  tháº¥y nÃ³ cÅ©ng dá»… hiá»ƒu nhÆ°ng khÃ¡ kÄ© vá» toÃ¡n, ngÃ´n ngá»¯ ML hÆ¡i cá»•. BÃ¡c nÃ o xem báº£n má»›i xong cho ae cÃ¡i review ná»¯a cÃ ng tá»‘t. Thanks cÃ¡c bÃ¡c",,,,,
"CÃ³ báº¡n gáº§n Ä‘Ã¢y há»i báº£n mÃ u cá»§a cuá»‘n ""Machine Learning cÆ¡ báº£n"", mÃ¬nh khÃ´ng nhá»› báº¡n há»i á»Ÿ Ä‘Ã¢u nÃªn Ä‘Äƒng lÃªn Ä‘Ã¢y cho má»i ngÆ°á»i cÃ¹ng download náº¿u cáº§n.
https://github.com/tiepvupsu/ebookMLCB/blob/master/book_ML_color.pdf
ÄÃ¢y lÃ  báº£n trÆ°á»›c khi ra sÃ¡ch giáº¥y vá»›i nhiá»u tá»« khoÃ¡ váº«n Ä‘á»ƒ tiáº¿ng Anh vÃ  vÄƒn phong chÆ°a Ä‘Æ°á»£c chá»‰nh. Sau Ä‘Ã³ bÃªn biÃªn táº­p sÃ¡ch cá»§a NXB yÃªu cáº§u sá»­a láº¡i ráº¥t nhiá»u vÄƒn váº» vÃ  tá»« khoÃ¡ sang tiáº¿ng Viá»‡t.
KhÃ´ng ngá» báº£n mÃ u chÆ°a qua biÃªn táº­p (tá»« NXB) láº¡i Ä‘Æ°á»£c Ä‘Ã³n nháº­n nhiá»u hÆ¡n.","CÃ³ báº¡n gáº§n Ä‘Ã¢y há»i báº£n mÃ u cá»§a cuá»‘n ""Machine Learning cÆ¡ báº£n"", mÃ¬nh khÃ´ng nhá»› báº¡n há»i á»Ÿ Ä‘Ã¢u nÃªn Ä‘Äƒng lÃªn Ä‘Ã¢y cho má»i ngÆ°á»i cÃ¹ng download náº¿u cáº§n. https://github.com/tiepvupsu/ebookMLCB/blob/master/book_ML_color.pdf ÄÃ¢y lÃ  báº£n trÆ°á»›c khi ra sÃ¡ch giáº¥y vá»›i nhiá»u tá»« khoÃ¡ váº«n Ä‘á»ƒ tiáº¿ng Anh vÃ  vÄƒn phong chÆ°a Ä‘Æ°á»£c chá»‰nh. Sau Ä‘Ã³ bÃªn biÃªn táº­p sÃ¡ch cá»§a NXB yÃªu cáº§u sá»­a láº¡i ráº¥t nhiá»u vÄƒn váº» vÃ  tá»« khoÃ¡ sang tiáº¿ng Viá»‡t. KhÃ´ng ngá» báº£n mÃ u chÆ°a qua biÃªn táº­p (tá»« NXB) láº¡i Ä‘Æ°á»£c Ä‘Ã³n nháº­n nhiá»u hÆ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i,
Em Ä‘ang Ä‘á»c má»™t sá»‘ nghiÃªn cá»©u vá» PhÆ°Æ¡ng phÃ¡p Gradient vá»›i mÃ´ hÃ¬nh Inexact Oracle cá»§a Nesterov vÃ  Devolder. Trong Ä‘Ã³, khi tÃ¡c giáº£ Ä‘Æ°a ra Ä‘á»“ thá»‹ vá» sai sá»‘ giá»¯a giÃ¡ trá»‹ hÃ m f(yk) vÃ  giÃ¡ trá»‹ min y* ( nhÆ° trong hÃ¬nh váº½) em khÃ´ng biáº¿t tÃ¡c giáº£ Ä‘Ã£ tÃ­nh giÃ¡ trá»‹ Ä‘Ã³ nhá» cÃ´ng thá»©c nÃ o hay kinh nghiá»‡m Ä‘á»ƒ tÃ­nh tá»« Ä‘Ã¢u ra? Bá»Ÿi vÃ¬ y* thÃ¬ mÃ¬nh khÃ´ng biáº¿t. Mong ace nÃ o tá»«ng nghiÃªn cá»©u qua cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em vá»›i áº¡.
Em xin cÃ¡m Æ¡n nhiá»u.","Em chÃ o má»i ngÆ°á»i, Em Ä‘ang Ä‘á»c má»™t sá»‘ nghiÃªn cá»©u vá» PhÆ°Æ¡ng phÃ¡p Gradient vá»›i mÃ´ hÃ¬nh Inexact Oracle cá»§a Nesterov vÃ  Devolder. Trong Ä‘Ã³, khi tÃ¡c giáº£ Ä‘Æ°a ra Ä‘á»“ thá»‹ vá» sai sá»‘ giá»¯a giÃ¡ trá»‹ hÃ m f(yk) vÃ  giÃ¡ trá»‹ min y* ( nhÆ° trong hÃ¬nh váº½) em khÃ´ng biáº¿t tÃ¡c giáº£ Ä‘Ã£ tÃ­nh giÃ¡ trá»‹ Ä‘Ã³ nhá» cÃ´ng thá»©c nÃ o hay kinh nghiá»‡m Ä‘á»ƒ tÃ­nh tá»« Ä‘Ã¢u ra? Bá»Ÿi vÃ¬ y* thÃ¬ mÃ¬nh khÃ´ng biáº¿t. Mong ace nÃ o tá»«ng nghiÃªn cá»©u qua cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em vá»›i áº¡. Em xin cÃ¡m Æ¡n nhiá»u.",,,,,
Má»™t cÃ¡ch biá»ƒu diá»…n quÃ¡ trÃ¬nh Ä‘Ã o táº¡o máº¡ng neural nhÃ¢n táº¡o cho má»i ngÆ°á»i,Má»™t cÃ¡ch biá»ƒu diá»…n quÃ¡ trÃ¬nh Ä‘Ã o táº¡o máº¡ng neural nhÃ¢n táº¡o cho má»i ngÆ°á»i,,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» time series vÃ  cÃ³ vÃ i tháº¯c máº¯c sau, nhá» má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em.
Trong 2 chuá»—i time series, lÃ m sao mÃ¬nh biáº¿t chuá»—i nÃ o thay Ä‘á»•i sáº½ kÃ©o theo thay Ä‘á»•i cá»§a chuá»—i cÃ²n láº¡i? Em cÃ³ thá»­ dÃ¹ng Granger causality test nhÆ°ng mÃ  cÃ³ váº» káº¿t quáº£ nÃ³ ra khÃ´ng há»£p lÃ½ trÃªn dataset cá»§a em (kiá»ƒu káº¿t quáº£ nÃ³ vÃ´ lÃ½ vÃ  mÃ¬nh biáº¿t vÃ´ lÃ½ dá»±a theo kinh nghiá»‡m), vÃ  em cÃ³ Ä‘á»c tÃ i liá»‡u thÃ¬ cÃ¡i Granger causality test nÃ y cÅ©ng khÃ´ng cháº¯c thá»ƒ hiá»‡n Ä‘Æ°á»£c má»‘i quan há»‡ nhÃ¢n quáº£ thá»±c sá»± giá»¯a 2 chuá»—i. Váº­y cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘Ã¡ng tin hÆ¡n Ä‘á»ƒ biáº¿t chuá»—i nÃ o thay Ä‘á»•i sáº½ kÃ©o theo thay Ä‘á»•i cá»§a chuá»—i cÃ²n láº¡i vÃ  thay Ä‘á»•i nhÆ° tháº¿ nÃ o (vÃ­ dá»¥ chuá»—i 2 giáº£m thÃ¬ chuá»—i 1 tÄƒng hoáº·c chuá»—i 1 tÄƒng thÃ¬ chuá»—i 2 cÅ©ng tÄƒng) khÃ´ng áº¡? 
 CÃ³ trÆ°á»ng há»£p nÃ o mÃ  trong khoáº£ng thá»i gian (t_1; t_2) chuá»—i nÃ y khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n chuá»—i kia (chuá»—i nÃ y thay Ä‘á»•i khÃ´ng kÃ©o theo sá»± thay Ä‘á»•i cá»§a chuá»—i kia) mÃ  Ä‘áº¿n khoáº£ng thá»i gian (t_1â€™; t_2â€™) thÃ¬ má»›i báº¯t Ä‘áº§u áº£nh hÆ°á»Ÿng khÃ´ng áº¡? VÃ  lÃ m sao mÃ¬nh kiá»ƒm tra Ä‘Æ°á»£c Ä‘iá»u nÃ y?
VÃ­ dá»¥ bÃ¢y giá» mÃ¬nh cÃ³ nhiá»u hÆ¡n 2 chuá»—i,  báº±ng cÃ¡ch nÃ o Ä‘Ã³, mÃ¬nh biáº¿t chuá»—i s_1 thay Ä‘á»•i kÃ©o theo s_2 thay Ä‘á»•i, s_2  kÃ©o theo s_3,â€¦ , s_(n-1) kÃ©o theo s_n, váº­y mÃ¬nh cÃ³ thá»ƒ káº¿t luáº­n chuá»—i s_1 thay Ä‘á»•i sáº½ kÃ©o theo s_n thay Ä‘á»•i Ä‘Æ°á»£c khÃ´ng?
VÃ­ dá»¥ trong hÃ¬nh nÃ y, á»Ÿ giai Ä‘oáº¡n sau 2009 má»™t xÃ­u, cÃ¡c chuá»—i nÃ y háº§u nhÆ° Ä‘á»u Ä‘i xuá»‘ng, váº­y cÃ³ cÃ¡ch nÃ o mÃ¬nh xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c chuá»—i nÃ o sáº½ thay Ä‘á»•i Ä‘áº§u tiÃªn (bá»‹ Ä‘i xuá»‘ng Ä‘áº§u tiÃªn) vÃ  thá»© tá»± cÃ¡c chuá»—i sau Ä‘Ã³ cÅ©ng bá»‹ Ä‘i xuá»‘ng khÃ´ng áº¡? 
LiÃªn quan Ä‘áº¿n cÃ¢u 4, khi cÃ¡c chuá»—i nÃ y khÃ´ng Ä‘á»“ng loáº¡t Ä‘i xuá»‘ng cÃ¹ng lÃºc, mÃ  sáº½ chÃªnh nhau má»™t khoáº£ng thá»i gian, váº­y cÃ³ cÃ¡ch nÃ o xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khoáº£ng thá»i gian chÃªnh nhau nÃ y giá»¯a cÃ¡c chuá»—i khÃ´ng áº¡?
Nhá» má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em, em cáº£m Æ¡n nhiá»u áº¡.","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» time series vÃ  cÃ³ vÃ i tháº¯c máº¯c sau, nhá» má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em. Trong 2 chuá»—i time series, lÃ m sao mÃ¬nh biáº¿t chuá»—i nÃ o thay Ä‘á»•i sáº½ kÃ©o theo thay Ä‘á»•i cá»§a chuá»—i cÃ²n láº¡i? Em cÃ³ thá»­ dÃ¹ng Granger causality test nhÆ°ng mÃ  cÃ³ váº» káº¿t quáº£ nÃ³ ra khÃ´ng há»£p lÃ½ trÃªn dataset cá»§a em (kiá»ƒu káº¿t quáº£ nÃ³ vÃ´ lÃ½ vÃ  mÃ¬nh biáº¿t vÃ´ lÃ½ dá»±a theo kinh nghiá»‡m), vÃ  em cÃ³ Ä‘á»c tÃ i liá»‡u thÃ¬ cÃ¡i Granger causality test nÃ y cÅ©ng khÃ´ng cháº¯c thá»ƒ hiá»‡n Ä‘Æ°á»£c má»‘i quan há»‡ nhÃ¢n quáº£ thá»±c sá»± giá»¯a 2 chuá»—i. Váº­y cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘Ã¡ng tin hÆ¡n Ä‘á»ƒ biáº¿t chuá»—i nÃ o thay Ä‘á»•i sáº½ kÃ©o theo thay Ä‘á»•i cá»§a chuá»—i cÃ²n láº¡i vÃ  thay Ä‘á»•i nhÆ° tháº¿ nÃ o (vÃ­ dá»¥ chuá»—i 2 giáº£m thÃ¬ chuá»—i 1 tÄƒng hoáº·c chuá»—i 1 tÄƒng thÃ¬ chuá»—i 2 cÅ©ng tÄƒng) khÃ´ng áº¡? CÃ³ trÆ°á»ng há»£p nÃ o mÃ  trong khoáº£ng thá»i gian (t_1; t_2) chuá»—i nÃ y khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n chuá»—i kia (chuá»—i nÃ y thay Ä‘á»•i khÃ´ng kÃ©o theo sá»± thay Ä‘á»•i cá»§a chuá»—i kia) mÃ  Ä‘áº¿n khoáº£ng thá»i gian (t_1â€™; t_2â€™) thÃ¬ má»›i báº¯t Ä‘áº§u áº£nh hÆ°á»Ÿng khÃ´ng áº¡? VÃ  lÃ m sao mÃ¬nh kiá»ƒm tra Ä‘Æ°á»£c Ä‘iá»u nÃ y? VÃ­ dá»¥ bÃ¢y giá» mÃ¬nh cÃ³ nhiá»u hÆ¡n 2 chuá»—i, báº±ng cÃ¡ch nÃ o Ä‘Ã³, mÃ¬nh biáº¿t chuá»—i s_1 thay Ä‘á»•i kÃ©o theo s_2 thay Ä‘á»•i, s_2 kÃ©o theo s_3,â€¦ , s_(n-1) kÃ©o theo s_n, váº­y mÃ¬nh cÃ³ thá»ƒ káº¿t luáº­n chuá»—i s_1 thay Ä‘á»•i sáº½ kÃ©o theo s_n thay Ä‘á»•i Ä‘Æ°á»£c khÃ´ng? VÃ­ dá»¥ trong hÃ¬nh nÃ y, á»Ÿ giai Ä‘oáº¡n sau 2009 má»™t xÃ­u, cÃ¡c chuá»—i nÃ y háº§u nhÆ° Ä‘á»u Ä‘i xuá»‘ng, váº­y cÃ³ cÃ¡ch nÃ o mÃ¬nh xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c chuá»—i nÃ o sáº½ thay Ä‘á»•i Ä‘áº§u tiÃªn (bá»‹ Ä‘i xuá»‘ng Ä‘áº§u tiÃªn) vÃ  thá»© tá»± cÃ¡c chuá»—i sau Ä‘Ã³ cÅ©ng bá»‹ Ä‘i xuá»‘ng khÃ´ng áº¡? LiÃªn quan Ä‘áº¿n cÃ¢u 4, khi cÃ¡c chuá»—i nÃ y khÃ´ng Ä‘á»“ng loáº¡t Ä‘i xuá»‘ng cÃ¹ng lÃºc, mÃ  sáº½ chÃªnh nhau má»™t khoáº£ng thá»i gian, váº­y cÃ³ cÃ¡ch nÃ o xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khoáº£ng thá»i gian chÃªnh nhau nÃ y giá»¯a cÃ¡c chuá»—i khÃ´ng áº¡? Nhá» má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em, em cáº£m Æ¡n nhiá»u áº¡.",,,,,
MÃ¬nh Ä‘ang muá»‘n Ã¡p dá»¥ng walk forward validation cho decision tree. Má»—i má»™t train/test split sáº½ cho ra má»™t decision tree. Hiá»‡n táº¡i mÃ¬nh chÆ°a biáº¿t cÃ¡ch tá»•ng há»£p cÃ¡c decision tree dá»ƒ cho ra quyáº¿t Ä‘á»‹nh tá»‘t nháº¥t vÃ  nhanh nháº¥t. CÃ¡c báº¡n/anh/chá»‹ cÃ³ hÆ°á»›ng giáº£i quyáº¿t hoáº·c thuáº­t toÃ¡n nÃ o thÃ¬ Ä‘á» xuáº¥t giÃºp mÃ¬nh vá»›i áº¡!,MÃ¬nh Ä‘ang muá»‘n Ã¡p dá»¥ng walk forward validation cho decision tree. Má»—i má»™t train/test split sáº½ cho ra má»™t decision tree. Hiá»‡n táº¡i mÃ¬nh chÆ°a biáº¿t cÃ¡ch tá»•ng há»£p cÃ¡c decision tree dá»ƒ cho ra quyáº¿t Ä‘á»‹nh tá»‘t nháº¥t vÃ  nhanh nháº¥t. CÃ¡c báº¡n/anh/chá»‹ cÃ³ hÆ°á»›ng giáº£i quyáº¿t hoáº·c thuáº­t toÃ¡n nÃ o thÃ¬ Ä‘á» xuáº¥t giÃºp mÃ¬nh vá»›i áº¡!,,,,,
CÃ¡c ace cho mÃ¬nh há»i cÃ¡ch Ä‘á»ƒ colab ko bá»‹ dá»«ng láº¡i náº¿u ko tÆ°Æ¡ng tÃ¡c trong 90p áº¡. CÃ¡m Æ¡n mn.,CÃ¡c ace cho mÃ¬nh há»i cÃ¡ch Ä‘á»ƒ colab ko bá»‹ dá»«ng láº¡i náº¿u ko tÆ°Æ¡ng tÃ¡c trong 90p áº¡. CÃ¡m Æ¡n mn.,,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh cÃ³ bÃ i toÃ¡n nhÆ° sau nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp nÃªn dÃ¹ng mÃ´ hÃ¬nh nÃ o cho phÃ¹ há»£p.
6 cháº¥m trÃ²n xanh cÃ³ tá»a Ä‘á»™ (x1,y1) ...(x6,y6)
CÃ¡c Ä‘iá»ƒm Ä‘Æ°á»£c Ä‘Ã¡nh sá»‘ P1...P6 ( nhÆ° hÃ¬nh váº½)
Sá»‘ lÆ°á»£ng: 1000 máº«u
vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i giá»¯a cÃ¡c cháº¥m trÃ²n thay Ä‘á»•i khÃ´ng nhiá»u
BÃ i toÃ¡n:
1. Input: tá»a Ä‘á»™ 6 Ä‘iá»ƒm báº¥t kÃ¬; Output: phÃ¢n loáº¡i vÃ o 6 group (P1..P6)
2. Input: tá»a Ä‘á»™ 4 Ä‘iá»ƒm, Output: phÃ¢n loáº¡i vÃ o 4 group tá»« Ä‘Ã³ tÃ¬m ra vá»‹ trÃ­ 2 Ä‘iá»ƒm cÃ²n thiáº¿u
3. Input: tá»a Ä‘á»™ 8 Ä‘iá»ƒm, Output: phÃ¢n loáº¡i vÃ o 6 group (P1..P6), cÃ³ group sáº½ cÃ³ nhiá»u hÆ¡n 2 Ä‘iá»ƒm
báº¡n nÃ o cÃ³ giáº£i phÃ¡p hay, mÃ¬nh xin phÃ©p cáº£m Æ¡n vÃ  háº­u táº¡.
Edit1:
CÃ¡i mÃ¬nh bÄƒn khoÄƒn khi dÃ¹ng Kmeans lÃ  vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i giá»¯a cÃ¡c Ä‘iá»ƒm thay Ä‘á»•i Ã½ nhÆ°ng cáº£ cá»¥m 6 Ä‘iá»ƒm trong máº·t pháº³ng thÃ¬ thay Ä‘á»•i nhiá»u
ChÃ­nh vÃ¬ tháº¿ mÃ¬nh Ä‘á»‹nh tÃ­nh trung bÃ¬nh cá»™ng cá»§a cÃ¡c Ä‘iá»ƒm, má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ bá» Ä‘i offset giá»¯a cÃ¡c cá»¥m 6 Ä‘iá»ƒm.
Tuy nhiÃªn, cÃ¡ch nÃ y fail khi Ä‘áº§u vÃ o khÃ´ng Ä‘á»§, ( vÃ­ dá»¥ thiáº¿u Ä‘iá»ƒm 1 vÃ  4) sáº½ lÃ m trung bÃ¬nh cá»™ng giá»¯a cÃ¡c Ä‘iá»ƒm bá»‹ máº¥t.","ChÃ o má»i ngÆ°á»i, MÃ¬nh cÃ³ bÃ i toÃ¡n nhÆ° sau nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp nÃªn dÃ¹ng mÃ´ hÃ¬nh nÃ o cho phÃ¹ há»£p. 6 cháº¥m trÃ²n xanh cÃ³ tá»a Ä‘á»™ (x1,y1) ...(x6,y6) CÃ¡c Ä‘iá»ƒm Ä‘Æ°á»£c Ä‘Ã¡nh sá»‘ P1...P6 ( nhÆ° hÃ¬nh váº½) Sá»‘ lÆ°á»£ng: 1000 máº«u vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i giá»¯a cÃ¡c cháº¥m trÃ²n thay Ä‘á»•i khÃ´ng nhiá»u BÃ i toÃ¡n: 1. Input: tá»a Ä‘á»™ 6 Ä‘iá»ƒm báº¥t kÃ¬; Output: phÃ¢n loáº¡i vÃ o 6 group (P1..P6) 2. Input: tá»a Ä‘á»™ 4 Ä‘iá»ƒm, Output: phÃ¢n loáº¡i vÃ o 4 group tá»« Ä‘Ã³ tÃ¬m ra vá»‹ trÃ­ 2 Ä‘iá»ƒm cÃ²n thiáº¿u 3. Input: tá»a Ä‘á»™ 8 Ä‘iá»ƒm, Output: phÃ¢n loáº¡i vÃ o 6 group (P1..P6), cÃ³ group sáº½ cÃ³ nhiá»u hÆ¡n 2 Ä‘iá»ƒm báº¡n nÃ o cÃ³ giáº£i phÃ¡p hay, mÃ¬nh xin phÃ©p cáº£m Æ¡n vÃ  háº­u táº¡. Edit1: CÃ¡i mÃ¬nh bÄƒn khoÄƒn khi dÃ¹ng Kmeans lÃ  vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i giá»¯a cÃ¡c Ä‘iá»ƒm thay Ä‘á»•i Ã½ nhÆ°ng cáº£ cá»¥m 6 Ä‘iá»ƒm trong máº·t pháº³ng thÃ¬ thay Ä‘á»•i nhiá»u ChÃ­nh vÃ¬ tháº¿ mÃ¬nh Ä‘á»‹nh tÃ­nh trung bÃ¬nh cá»™ng cá»§a cÃ¡c Ä‘iá»ƒm, má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ bá» Ä‘i offset giá»¯a cÃ¡c cá»¥m 6 Ä‘iá»ƒm. Tuy nhiÃªn, cÃ¡ch nÃ y fail khi Ä‘áº§u vÃ o khÃ´ng Ä‘á»§, ( vÃ­ dá»¥ thiáº¿u Ä‘iá»ƒm 1 vÃ  4) sáº½ lÃ m trung bÃ¬nh cá»™ng giá»¯a cÃ¡c Ä‘iá»ƒm bá»‹ máº¥t.",,,,,
"Má»i ngÆ°á»i thÃ´ng nÃ£o há»™ mÃ¬nh cÃ¡i váº¥n Ä‘á» nÃ y vá»›i.
MÃ¬nh mÃ´ táº£ project mÃ´n há»c face recognition mÃ  mÃ¬nh Ä‘ang lÃ m chÃºt xÃ­u
MÃ¬nh detect faces, láº¥y landmarks, tÃ­nh distance giá»¯a cÃ¡c landmark vÃ  Ã¡p dá»¥ng K-nn classifier (ORC), DÃ¹ng train_test_split Ä‘á»ƒ tÃ¡ch láº¥y train vÃ  test
sau khi fit mÃ¬nh láº¥y matching_score = clf.predict_proba(X_test)
mÃ¬nh tÃ­nh genius score vÃ  impostor score Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“, tÃ¬m D-prime, cÅ©ng nhÆ° tÃ¬m ra EER
má»i thá»© ok háº¿t rá»“i, vÃ  trong project cÃ³ yÃªu cáº§u 1 váº¥n Ä‘á» nhÆ° hÃ¬nh
Thá»±c sá»± Ä‘á»c trÃªn máº¡ng ráº¥t mong lung vÃ  khÃ³ hiá»ƒu, Ä‘áº¡i khÃ¡i cÃ¡i nÃ y lÃ  sao váº­y má»i ngÆ°á»i Æ¡i... ngay cáº£ resource cung cáº¥p chá»‰ ghi Ä‘Ãºng definition cá»§a pháº§n nÃ y... mÃ¬nh ko hiá»ƒu vÃ  cÅ©ng ko biáº¿t pháº£i Ã¡p dá»¥ng vÃ o project mÃ¬nh Ä‘ang lÃ m kiá»ƒu gÃ¬ ná»­a hjx.
Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn Ä‘Æ°á»£c khÃ´ng.
Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","Má»i ngÆ°á»i thÃ´ng nÃ£o há»™ mÃ¬nh cÃ¡i váº¥n Ä‘á» nÃ y vá»›i. MÃ¬nh mÃ´ táº£ project mÃ´n há»c face recognition mÃ  mÃ¬nh Ä‘ang lÃ m chÃºt xÃ­u MÃ¬nh detect faces, láº¥y landmarks, tÃ­nh distance giá»¯a cÃ¡c landmark vÃ  Ã¡p dá»¥ng K-nn classifier (ORC), DÃ¹ng train_test_split Ä‘á»ƒ tÃ¡ch láº¥y train vÃ  test sau khi fit mÃ¬nh láº¥y matching_score = clf.predict_proba(X_test) mÃ¬nh tÃ­nh genius score vÃ  impostor score Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“, tÃ¬m D-prime, cÅ©ng nhÆ° tÃ¬m ra EER má»i thá»© ok háº¿t rá»“i, vÃ  trong project cÃ³ yÃªu cáº§u 1 váº¥n Ä‘á» nhÆ° hÃ¬nh Thá»±c sá»± Ä‘á»c trÃªn máº¡ng ráº¥t mong lung vÃ  khÃ³ hiá»ƒu, Ä‘áº¡i khÃ¡i cÃ¡i nÃ y lÃ  sao váº­y má»i ngÆ°á»i Æ¡i... ngay cáº£ resource cung cáº¥p chá»‰ ghi Ä‘Ãºng definition cá»§a pháº§n nÃ y... mÃ¬nh ko hiá»ƒu vÃ  cÅ©ng ko biáº¿t pháº£i Ã¡p dá»¥ng vÃ o project mÃ¬nh Ä‘ang lÃ m kiá»ƒu gÃ¬ ná»­a hjx. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn Ä‘Æ°á»£c khÃ´ng. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
em Ä‘Ã£ táº£i 1 bá»™ dataset chá»©a áº£nh x-quang covid vÃ  non-covid á»Ÿ phá»•i. Em cÅ©ng load Ä‘Æ°á»£c dá»¯ liá»‡u vÃ  chuáº©n hÃ³a dá»¯ liá»‡u. NhÆ°ng em cÃ³ váº¥n Ä‘á» á»Ÿ chá»— mÃ´ hÃ¬nh huáº¥n luyá»‡n. Em tÃ¬m tháº¥y trÃªn máº¡ng vá» keras senquential. pháº§n táº¡o cÃ¡c lá»›p ( layer) em váº«n chÆ°a hiá»ƒu Ä‘Æ°á»£c. em Ä‘Ã£ thá»­ tÃ¬m trÃªn trang cá»§a keras vá» nÃ³. Mong má»i ngÆ°á»i giÃºp em hiá»ƒu dc nÃ³ vÃ  lÃ m sao e cÃ³ thá»ƒ sá»­ dá»¥ng nÃ³ Ä‘á»ƒ phÃ¢n loáº¡i covid vÃ  noncovid. Cáº£m Æ¡n má»i ngÆ°á»i,em Ä‘Ã£ táº£i 1 bá»™ dataset chá»©a áº£nh x-quang covid vÃ  non-covid á»Ÿ phá»•i. Em cÅ©ng load Ä‘Æ°á»£c dá»¯ liá»‡u vÃ  chuáº©n hÃ³a dá»¯ liá»‡u. NhÆ°ng em cÃ³ váº¥n Ä‘á» á»Ÿ chá»— mÃ´ hÃ¬nh huáº¥n luyá»‡n. Em tÃ¬m tháº¥y trÃªn máº¡ng vá» keras senquential. pháº§n táº¡o cÃ¡c lá»›p ( layer) em váº«n chÆ°a hiá»ƒu Ä‘Æ°á»£c. em Ä‘Ã£ thá»­ tÃ¬m trÃªn trang cá»§a keras vá» nÃ³. Mong má»i ngÆ°á»i giÃºp em hiá»ƒu dc nÃ³ vÃ  lÃ m sao e cÃ³ thá»ƒ sá»­ dá»¥ng nÃ³ Ä‘á»ƒ phÃ¢n loáº¡i covid vÃ  noncovid. Cáº£m Æ¡n má»i ngÆ°á»i,,,,,
"Má»™t thÆ° viá»‡n hay cho bÃ i toÃ¡n OCR giÃºp chuyá»ƒn cÃ´ng thá»©c toÃ¡n thÃ nh dáº¡ng text (tá»« áº£nh cÃ´ng thá»©c trong file PDF/LaTex).
https://github.com/lukas-blecher/LaTeX-OCR",Má»™t thÆ° viá»‡n hay cho bÃ i toÃ¡n OCR giÃºp chuyá»ƒn cÃ´ng thá»©c toÃ¡n thÃ nh dáº¡ng text (tá»« áº£nh cÃ´ng thá»©c trong file PDF/LaTex). https://github.com/lukas-blecher/LaTeX-OCR,,,,,
"[Wav2vec 2.0 fairseq pretrained model]:
ChÃ o má»i ngÆ°á»i. Em Ä‘ang cáº§n pretrained model cá»§a wav2vec 2.0 báº±ng Tensorflow hay Pytorch Ä‘á»u Ä‘c áº¡, nhÆ°ng táº§m dÆ°á»›i 100M params (tÆ°Æ¡ng Ä‘Æ°Æ¡ng base model) vÃ  Ä‘c train trÃªn nhiá»u ngÃ´n ngá»¯ (cÃ³ tiáº¿ng Viá»‡t, Äá»©c, áº¢ Ráº­p thÃ¬ tá»‘t quÃ¡).
Fairseq thÃ¬ cÃ³ XLSR large model Ä‘c train ~50 ngÃ´n ngá»¯ nhÆ°ng táº­n 300M params nÃªn mÃ¡y lab e náº¡p ko ná»•i (8 GPU 2080 Ti).
Má»i ngÆ°á»i ai cÃ³ thÃ¬ cho em xin vá»›i áº¡. Em cá»§m Æ¡n ráº¥t nhÃ¬u áº¡.
https://github.com/pytorch/fairseq/blob/main/examples/wav2vec/README.md","[Wav2vec 2.0 fairseq pretrained model]: ChÃ o má»i ngÆ°á»i. Em Ä‘ang cáº§n pretrained model cá»§a wav2vec 2.0 báº±ng Tensorflow hay Pytorch Ä‘á»u Ä‘c áº¡, nhÆ°ng táº§m dÆ°á»›i 100M params (tÆ°Æ¡ng Ä‘Æ°Æ¡ng base model) vÃ  Ä‘c train trÃªn nhiá»u ngÃ´n ngá»¯ (cÃ³ tiáº¿ng Viá»‡t, Äá»©c, áº¢ Ráº­p thÃ¬ tá»‘t quÃ¡). Fairseq thÃ¬ cÃ³ XLSR large model Ä‘c train ~50 ngÃ´n ngá»¯ nhÆ°ng táº­n 300M params nÃªn mÃ¡y lab e náº¡p ko ná»•i (8 GPU 2080 Ti). Má»i ngÆ°á»i ai cÃ³ thÃ¬ cho em xin vá»›i áº¡. Em cá»§m Æ¡n ráº¥t nhÃ¬u áº¡. https://github.com/pytorch/fairseq/blob/main/examples/wav2vec/README.md",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin mÃ´ táº£ vá» cÃ´ng viá»‡c cá»§a má»™t Machine Learning Engineering vÃ  má»™t Sample Project cá»§a má»™t mÃ´ hÃ¬nh Machine Learning vá»›i ngÆ°á»i Ä‘i lÃ m vá»›i áº¡! Em cáº£m Æ¡n áº¡","Em chÃ o má»i ngÆ°á»i áº¡, Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin mÃ´ táº£ vá» cÃ´ng viá»‡c cá»§a má»™t Machine Learning Engineering vÃ  má»™t Sample Project cá»§a má»™t mÃ´ hÃ¬nh Machine Learning vá»›i ngÆ°á»i Ä‘i lÃ m vá»›i áº¡! Em cáº£m Æ¡n áº¡",,,,,
"[AI SHARING]
Chia sáº» vá»›i cÃ¡c báº¡n cÃ¡ch chá»n lá»c paper phÃ¹ há»£p giÃºp Ä‘á»c nhanh hiá»ƒu sÃ¢u hÆ¡n kÃ¨m cÃ¡c tool, tips giÃºp Ã­ch cho viá»‡c Ä‘á»c paper.","[AI SHARING] Chia sáº» vá»›i cÃ¡c báº¡n cÃ¡ch chá»n lá»c paper phÃ¹ há»£p giÃºp Ä‘á»c nhanh hiá»ƒu sÃ¢u hÆ¡n kÃ¨m cÃ¡c tool, tips giÃºp Ã­ch cho viá»‡c Ä‘á»c paper.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh hiá»‡n Ä‘ang trainning má»™t model, vá»›i lÆ°á»£ng data 128Gb, nhÆ°ng thÆ°á»ng bá»‹ crash do quÃ¡ RAM (lÃ  lÃ  120GB). KhÃ´ng biáº¿t cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o áº¡? Ráº¥t cÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡","ChÃ o má»i ngÆ°á»i, mÃ¬nh hiá»‡n Ä‘ang trainning má»™t model, vá»›i lÆ°á»£ng data 128Gb, nhÆ°ng thÆ°á»ng bá»‹ crash do quÃ¡ RAM (lÃ  lÃ  120GB). KhÃ´ng biáº¿t cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o áº¡? Ráº¥t cÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em má»›i há»c vá» pháº§n nÃ y nÃªn máº¡nh dáº¡n lÃ m video chia sáº» cho cÃ¡c báº¡n má»›i há»c.
Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, em má»›i há»c vá» pháº§n nÃ y nÃªn máº¡nh dáº¡n lÃ m video chia sáº» cho cÃ¡c báº¡n má»›i há»c. Mong ad duyá»‡t bÃ i!",,,,,
"Hello ae, team mÃ¬nh cÃ³ viáº¿t pipeline cho bÃ i toÃ¡n tracking, cÃ¡c báº¡n tham kháº£o vÃ  Ä‘Ã³ng gÃ³p Ã½ kiáº¿n giÃºp mÃ¬nh vá»›i áº¡. MÃ¬nh má»›i táº­p viáº¿t nÃªn mong má»i ngÆ°á»i gÃ³p Ã½ nhiá»u. Cáº£m Æ¡n má»i ngÆ°á»i","Hello ae, team mÃ¬nh cÃ³ viáº¿t pipeline cho bÃ i toÃ¡n tracking, cÃ¡c báº¡n tham kháº£o vÃ  Ä‘Ã³ng gÃ³p Ã½ kiáº¿n giÃºp mÃ¬nh vá»›i áº¡. MÃ¬nh má»›i táº­p viáº¿t nÃªn mong má»i ngÆ°á»i gÃ³p Ã½ nhiá»u. Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Hi má»i ngÆ°á»i, em lÃ  newbie Ä‘ang cáº§n hÆ°á»›ng xá»­ lÃ½ cho má»™t bÃ i toÃ¡n lÃ : tá»« má»™t bá»©c áº£nh Ä‘áº§u vÃ o cÃ³ thá»ƒ váº½ láº¡i Ä‘Æ°á»£c má»™t bá»©c áº£nh tÆ°Æ¡ng tá»±. Má»¥c Ä‘Ã­ch lÃ  sau nÃ y tá»« má»™t Ä‘oáº¡n text em cÃ³ thá»ƒ render ra Ä‘Æ°á»£c bá»©c áº£nh cÃ³ ná»™i dung gáº§n giá»‘ng vs text. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem áº¡","Hi má»i ngÆ°á»i, em lÃ  newbie Ä‘ang cáº§n hÆ°á»›ng xá»­ lÃ½ cho má»™t bÃ i toÃ¡n lÃ : tá»« má»™t bá»©c áº£nh Ä‘áº§u vÃ o cÃ³ thá»ƒ váº½ láº¡i Ä‘Æ°á»£c má»™t bá»©c áº£nh tÆ°Æ¡ng tá»±. Má»¥c Ä‘Ã­ch lÃ  sau nÃ y tá»« má»™t Ä‘oáº¡n text em cÃ³ thá»ƒ render ra Ä‘Æ°á»£c bá»©c áº£nh cÃ³ ná»™i dung gáº§n giá»‘ng vs text. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem áº¡",,,,,
"[Data-centric AI Competition]
Cuá»™c thi láº§n nÃ y Ä‘Æ°á»£c táº­p trung vÃ o viá»‡c xá»­ lÃ½ dá»¯ liá»‡u, mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c giá»¯ cá»‘ Ä‘á»‹nh cho táº¥t cáº£ cÃ¡c Ä‘á»™i chÆ¡i.
BÃ i toÃ¡n cá»§a cuá»™c thi lÃ  nháº­n diá»‡n váº­t thá»ƒ (object detection) vá»›i 3 lá»›p lÃ  máº·t Ä‘eo kháº©u trang, máº·t khÃ´ng Ä‘eo kháº©u trang vÃ  máº·t Ä‘eo kháº©u trang khÃ´ng Ä‘Ãºng cÃ¡ch.
CÃ¡c báº¡n chÆ¡i sáº½ Ä‘Æ°á»£c cáº¥p 1000 áº£nh training, 100 áº£nh public test, 1 pretrained model vÃ  code Ä‘á»ƒ train. Sau Ä‘Ã³ cÃ¡c báº¡n xá»­ lÃ½, augment vÃ  cÃ³ thá»ƒ ná»™p láº¡i tá»‘i Ä‘a lÃ  3000 áº£nh Ä‘á»ƒ ban tá»• chá»©c cháº¥m Ä‘iá»ƒm.
Chi tiáº¿t vá» cuá»™c thi á»Ÿ Ä‘Ã¢y: https://datacomp.io/trang-chu
Video giá»›i thiá»‡u vá» cuá»™c thi á»Ÿ Ä‘Ã¢y: https://www.youtube.com/watch?v=E8CG06a9sQI
Group chÃ­nh thá»©c cá»§a cuá»™c thi: https://www.facebook.com/groups/966726683795290
Ps: Giáº£i thÆ°á»Ÿng thÃ¬ nhÆ° trong hÃ¬nh, cÃ²n chá» gÃ¬ ná»¯a cÃ¡c báº¡n Æ¡iiiii","[Data-centric AI Competition] Cuá»™c thi láº§n nÃ y Ä‘Æ°á»£c táº­p trung vÃ o viá»‡c xá»­ lÃ½ dá»¯ liá»‡u, mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c giá»¯ cá»‘ Ä‘á»‹nh cho táº¥t cáº£ cÃ¡c Ä‘á»™i chÆ¡i. BÃ i toÃ¡n cá»§a cuá»™c thi lÃ  nháº­n diá»‡n váº­t thá»ƒ (object detection) vá»›i 3 lá»›p lÃ  máº·t Ä‘eo kháº©u trang, máº·t khÃ´ng Ä‘eo kháº©u trang vÃ  máº·t Ä‘eo kháº©u trang khÃ´ng Ä‘Ãºng cÃ¡ch. CÃ¡c báº¡n chÆ¡i sáº½ Ä‘Æ°á»£c cáº¥p 1000 áº£nh training, 100 áº£nh public test, 1 pretrained model vÃ  code Ä‘á»ƒ train. Sau Ä‘Ã³ cÃ¡c báº¡n xá»­ lÃ½, augment vÃ  cÃ³ thá»ƒ ná»™p láº¡i tá»‘i Ä‘a lÃ  3000 áº£nh Ä‘á»ƒ ban tá»• chá»©c cháº¥m Ä‘iá»ƒm. Chi tiáº¿t vá» cuá»™c thi á»Ÿ Ä‘Ã¢y: https://datacomp.io/trang-chu Video giá»›i thiá»‡u vá» cuá»™c thi á»Ÿ Ä‘Ã¢y: https://www.youtube.com/watch?v=E8CG06a9sQI Group chÃ­nh thá»©c cá»§a cuá»™c thi: https://www.facebook.com/groups/966726683795290 Ps: Giáº£i thÆ°á»Ÿng thÃ¬ nhÆ° trong hÃ¬nh, cÃ²n chá» gÃ¬ ná»¯a cÃ¡c báº¡n Æ¡iiiii",,,,,
"Em muá»‘n há»i chÃºt vá» Data Camp. Giá» Ä‘ang cÃ³ deal 129 Euro cho Premium Plan, liá»‡u cÃ³ giÃ¡ nÃ o pháº£i chÄƒng hÆ¡n khÃ´ng áº¡?
ÄÆ°Æ¡ng nhiÃªn lÃ  Ä‘á»ƒ há»c thÃ¬ em hok tiáº¿c bá» ra 129 Euro Ä‘á»ƒ há»c, nhÆ°ng sinh viÃªn thÃ¬ cá»© cÃ ng pháº£i chÄƒng hÆ¡n má»™t chÃºt thÃ¬ cÃ ng tá»‘t.
NÃªn cÃ³ anh chá»‹ nÃ o cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o ráº» hÆ¡n, hay cÃ¡ch nÃ o ráº» hÆ¡n thÃ¬ cÃ³ thá»ƒ chia sáº» cho em vá»›i áº¡!
Náº¿u khÃ´ng thÃ¬ em cÅ©ng sáºµn sÃ ng mua 129 Euro cho 1 nÄƒm thÃ´i! ğŸ˜…","Em muá»‘n há»i chÃºt vá» Data Camp. Giá» Ä‘ang cÃ³ deal 129 Euro cho Premium Plan, liá»‡u cÃ³ giÃ¡ nÃ o pháº£i chÄƒng hÆ¡n khÃ´ng áº¡? ÄÆ°Æ¡ng nhiÃªn lÃ  Ä‘á»ƒ há»c thÃ¬ em hok tiáº¿c bá» ra 129 Euro Ä‘á»ƒ há»c, nhÆ°ng sinh viÃªn thÃ¬ cá»© cÃ ng pháº£i chÄƒng hÆ¡n má»™t chÃºt thÃ¬ cÃ ng tá»‘t. NÃªn cÃ³ anh chá»‹ nÃ o cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o ráº» hÆ¡n, hay cÃ¡ch nÃ o ráº» hÆ¡n thÃ¬ cÃ³ thá»ƒ chia sáº» cho em vá»›i áº¡! Náº¿u khÃ´ng thÃ¬ em cÅ©ng sáºµn sÃ ng mua 129 Euro cho 1 nÄƒm thÃ´i!",,,,,
"https://github.com/mrharicot/monodepth
cho mÃ¬nh há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ sá»­ dá»¥ng model nÃ y trong java. MÃ¬nh Ä‘ang lÃ m app android cáº§n sá»­ dá»¥ng nÃ³.",https://github.com/mrharicot/monodepth cho mÃ¬nh há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ sá»­ dá»¥ng model nÃ y trong java. MÃ¬nh Ä‘ang lÃ m app android cáº§n sá»­ dá»¥ng nÃ³.,,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i máº¡nh khá»e vÃ  bÃ¬nh an.",,,,,
"VinAI NLP workshop 2021: www.vinai.io/NLPworkshop2021
MÃ¬nh xin Ä‘Æ°á»£c má»i má»i ngÆ°á»i tham dá»± VinAI NLP workshop 2021 (online workshop), vÃ o sÃ¡ng thá»© 6 tuáº§n sau (9:00 AM â€“ 12:15 PM, 29/10/2021).
ChÆ°Æ¡ng trÃ¬nh workshop cÃ³ bao gá»“m má»™t sá»‘ nghiÃªn cá»©u liÃªn quan Ä‘áº¿n xá»­ lÃ½ ngÃ´n ngá»¯ tiáº¿ng Viá»‡t. Hi vá»ng Ä‘Æ°á»£c má»i ngÆ°á»i tham gia vÃ  cÃ¹ng tháº£o luáº­n.
ÄÄƒng kÃ½ miá»…n phÃ­ Ä‘á»ƒ tham gia workshop táº¡i: https://forms.gle/AuXe5JVXr3PbYWQe8","VinAI NLP workshop 2021: www.vinai.io/NLPworkshop2021 MÃ¬nh xin Ä‘Æ°á»£c má»i má»i ngÆ°á»i tham dá»± VinAI NLP workshop 2021 (online workshop), vÃ o sÃ¡ng thá»© 6 tuáº§n sau (9:00 AM â€“ 12:15 PM, 29/10/2021). ChÆ°Æ¡ng trÃ¬nh workshop cÃ³ bao gá»“m má»™t sá»‘ nghiÃªn cá»©u liÃªn quan Ä‘áº¿n xá»­ lÃ½ ngÃ´n ngá»¯ tiáº¿ng Viá»‡t. Hi vá»ng Ä‘Æ°á»£c má»i ngÆ°á»i tham gia vÃ  cÃ¹ng tháº£o luáº­n. ÄÄƒng kÃ½ miá»…n phÃ­ Ä‘á»ƒ tham gia workshop táº¡i: https://forms.gle/AuXe5JVXr3PbYWQe8",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i bÃªn em Ä‘ang muá»‘n mua thiáº¿t bá»‹ pháº§n cá»©ng Ä‘á»ƒ nghiÃªn cá»©u bÃ i toÃ¡n Pose Estimation cho 1 chuá»—i cá»­a hÃ ng. Hiá»‡n táº¡i cÃ³ cÄƒn cá»© nÃ o Ä‘á»ƒ tÃ­nh Ä‘Æ°á»£c nÃªn mua pháº§n cá»©ng nhÆ° tháº¿ nÃ o (GPU, CPU, RAM, ...) Ä‘á»ƒ Ä‘áº£m báº£o tá»‘c Ä‘á»™ xá»­ lÃ½ khi nghiÃªn cá»©u bÃ i toÃ¡n khÃ´ng má»i ngÆ°á»i, cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u :D","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i bÃªn em Ä‘ang muá»‘n mua thiáº¿t bá»‹ pháº§n cá»©ng Ä‘á»ƒ nghiÃªn cá»©u bÃ i toÃ¡n Pose Estimation cho 1 chuá»—i cá»­a hÃ ng. Hiá»‡n táº¡i cÃ³ cÄƒn cá»© nÃ o Ä‘á»ƒ tÃ­nh Ä‘Æ°á»£c nÃªn mua pháº§n cá»©ng nhÆ° tháº¿ nÃ o (GPU, CPU, RAM, ...) Ä‘á»ƒ Ä‘áº£m báº£o tá»‘c Ä‘á»™ xá»­ lÃ½ khi nghiÃªn cá»©u bÃ i toÃ¡n khÃ´ng má»i ngÆ°á»i, cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u :D",,,,,
"Em Ä‘Æ°á»£c giao cÃ´ng viá»‡c lÃ  nghiÃªn cá»©u á»©ng dá»¥ng Deep Learning Ä‘á»ƒ bÃ³c tÃ¡ch Ä‘Æ°á»£c Ä‘á»‹a chá»‰ táº¡i Viá»‡t Nam:
VÃ­ dá»¥: Sá»‘ nhÃ  AA, ThÃ´n BB, XÃ£ CC, Huyá»‡n DD, Tá»‰nh EE
Hoáº·c, Sn AA, Ä‘Æ°á»ng bb, qCC, tpDD
---
Má»¥c Ä‘Ã­ch lÃ  bÃ³c tÃ¡ch Ä‘Æ°á»£c thÃ´ng tin Ä‘á»‹a chá»‰, vÃ  Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c.
Em Ä‘ang láº¡c lá»‘i giá»¯a biá»ƒn tÃ i liá»‡u ...
CÃ¡c bÃ¡c cÃ³ tÃ i liá»‡u hoáº·c lá»™ trÃ¬nh cá»¥ thá»ƒ, hoáº·c lá»›p há»c ONLINE or OFFILNE cháº¥t lÆ°á»£ng k áº¡? Em xin tÆ° váº¥n cá»§a cÃ¡c bÃ¡c. Em cáº§n há»c gáº¥p trong khoáº£ng 3 thÃ¡ng tá»›i áº¡.
Em cÃ³ thá»ƒ láº­p trÃ¬nh python cÆ¡ báº£n, tiáº¿ng anh Ä‘á»c hiá»ƒu.
--
Mong cÃ¡c cao nhÃ¢n má»Ÿ lá»‘i áº¡ :((","Em Ä‘Æ°á»£c giao cÃ´ng viá»‡c lÃ  nghiÃªn cá»©u á»©ng dá»¥ng Deep Learning Ä‘á»ƒ bÃ³c tÃ¡ch Ä‘Æ°á»£c Ä‘á»‹a chá»‰ táº¡i Viá»‡t Nam: VÃ­ dá»¥: Sá»‘ nhÃ  AA, ThÃ´n BB, XÃ£ CC, Huyá»‡n DD, Tá»‰nh EE Hoáº·c, Sn AA, Ä‘Æ°á»ng bb, qCC, tpDD --- Má»¥c Ä‘Ã­ch lÃ  bÃ³c tÃ¡ch Ä‘Æ°á»£c thÃ´ng tin Ä‘á»‹a chá»‰, vÃ  Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c. Em Ä‘ang láº¡c lá»‘i giá»¯a biá»ƒn tÃ i liá»‡u ... CÃ¡c bÃ¡c cÃ³ tÃ i liá»‡u hoáº·c lá»™ trÃ¬nh cá»¥ thá»ƒ, hoáº·c lá»›p há»c ONLINE or OFFILNE cháº¥t lÆ°á»£ng k áº¡? Em xin tÆ° váº¥n cá»§a cÃ¡c bÃ¡c. Em cáº§n há»c gáº¥p trong khoáº£ng 3 thÃ¡ng tá»›i áº¡. Em cÃ³ thá»ƒ láº­p trÃ¬nh python cÆ¡ báº£n, tiáº¿ng anh Ä‘á»c hiá»ƒu. -- Mong cÃ¡c cao nhÃ¢n má»Ÿ lá»‘i áº¡ :((",,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» ká»¹ thuáº­t Hierarchical Temporal Memory Ä‘á»ƒ nháº­n dáº¡ng báº¥t thÆ°á»ng trong dá»¯ liá»‡u. Báº¡n nÃ o Ä‘Ã£ tá»«ng nghiÃªn cá»©u vá» cÃ¡i nÃ y vui lÃ²ng hÆ°á»›ng dáº«n hay chá»‰ mÃ¬nh nÆ¡i Ä‘á»ƒ tÃ¬m hiá»ƒu ká»¹ hÆ¡n.
Xin cáº£m Æ¡n","ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» ká»¹ thuáº­t Hierarchical Temporal Memory Ä‘á»ƒ nháº­n dáº¡ng báº¥t thÆ°á»ng trong dá»¯ liá»‡u. Báº¡n nÃ o Ä‘Ã£ tá»«ng nghiÃªn cá»©u vá» cÃ¡i nÃ y vui lÃ²ng hÆ°á»›ng dáº«n hay chá»‰ mÃ¬nh nÆ¡i Ä‘á»ƒ tÃ¬m hiá»ƒu ká»¹ hÆ¡n. Xin cáº£m Æ¡n",,,,,
"Hello má»i ngÆ°á»i, má»i ngÆ°á»i tÆ° váº¥n vÃ  hÆ°á»›ng dáº«n giÃºp mÃ¬nh vá»›i nha.
Project face_recognition cá»§a mÃ¬nh cÃ³ dataset hÃ¬nh cá»§a tá»«ng ngÆ°á»i.
Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ add landmarks cho háº§u háº¿t cÃ¡c hÃ¬nh vÃ  hÃ m tráº£ vá» X vÃ  y, X(array list cá»§a táº¥t cáº£ cÃ¡c hÃ¬nh, y lÃ  location cá»§a hÃ¬nh)
MÃ¬nh dÃ¹ng classifier cá»§a sklearn.neighbors.KNeighborsClassifier
BÃ¢y giá» mÃ¬nh Ä‘ang bÃ­ á»Ÿ chá»— ko biáº¿t apply tháº¿ nÃ o cho cáº£ template vÃ  query.
VÃ  sau khi apply xong sáº½ lÃ m tháº¿ nÃ o Ä‘á»ƒ so sÃ¡nh giá»¯a cáº£ 2 pháº§n template vÃ  query Ä‘á»ƒ xem nÃ³ cÃ³ match hay khÃ´ng.
Ã€ cÃ²n ná»­a, mÃ¬nh Ä‘á»c sÃ¡ch theo thá»±c táº¿ thÃ¬ K-NN thÃ¬ dÃ¹ng cÃ¡c feature nhÆ° mÃ u da, khoáº£ng cÃ¡ch Ä‘á»ƒ tÃ­nh toÃ¡n thÃ¬ lÃ m sao mÃ¬nh biáº¿t sáº½ dÃ¹ng gÃ¬ vÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ apply áº¡
MÃ¬nh Ä‘Ã£ thá»­ phÆ°Æ¡ng phÃ¡p dÃ¹ng library: face_recognition vÃ  xuáº¥t thÃ nh cÃ´ng áº£nh cÃ³ tÃªn cá»§a ngÆ°á»i trong áº£nh, nhÆ°ng phÆ°Æ¡ng phÃ¡p nÃ y ko mang láº¡i hiá»‡u quáº£ nghiÃªn cá»©u nÃªn mÃ¬nh chuyá»ƒn sang dÃ¹ng cÃ¡i nÃ y nhÆ°ng Ä‘ang bá»‹ bÃ­ táº¡i Ä‘Ã¢y. Mong má»i ngÆ°á»i tá»«ng lÃ m qua cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn vÃ  giÃºp mÃ¬nh giáº£i Ä‘Ã¡p tháº¯c máº¯c.
Cáº£m Æ¡n nhiá»u áº¡","Hello má»i ngÆ°á»i, má»i ngÆ°á»i tÆ° váº¥n vÃ  hÆ°á»›ng dáº«n giÃºp mÃ¬nh vá»›i nha. Project face_recognition cá»§a mÃ¬nh cÃ³ dataset hÃ¬nh cá»§a tá»«ng ngÆ°á»i. Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ add landmarks cho háº§u háº¿t cÃ¡c hÃ¬nh vÃ  hÃ m tráº£ vá» X vÃ  y, X(array list cá»§a táº¥t cáº£ cÃ¡c hÃ¬nh, y lÃ  location cá»§a hÃ¬nh) MÃ¬nh dÃ¹ng classifier cá»§a sklearn.neighbors.KNeighborsClassifier BÃ¢y giá» mÃ¬nh Ä‘ang bÃ­ á»Ÿ chá»— ko biáº¿t apply tháº¿ nÃ o cho cáº£ template vÃ  query. VÃ  sau khi apply xong sáº½ lÃ m tháº¿ nÃ o Ä‘á»ƒ so sÃ¡nh giá»¯a cáº£ 2 pháº§n template vÃ  query Ä‘á»ƒ xem nÃ³ cÃ³ match hay khÃ´ng. Ã€ cÃ²n ná»­a, mÃ¬nh Ä‘á»c sÃ¡ch theo thá»±c táº¿ thÃ¬ K-NN thÃ¬ dÃ¹ng cÃ¡c feature nhÆ° mÃ u da, khoáº£ng cÃ¡ch Ä‘á»ƒ tÃ­nh toÃ¡n thÃ¬ lÃ m sao mÃ¬nh biáº¿t sáº½ dÃ¹ng gÃ¬ vÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ apply áº¡ MÃ¬nh Ä‘Ã£ thá»­ phÆ°Æ¡ng phÃ¡p dÃ¹ng library: face_recognition vÃ  xuáº¥t thÃ nh cÃ´ng áº£nh cÃ³ tÃªn cá»§a ngÆ°á»i trong áº£nh, nhÆ°ng phÆ°Æ¡ng phÃ¡p nÃ y ko mang láº¡i hiá»‡u quáº£ nghiÃªn cá»©u nÃªn mÃ¬nh chuyá»ƒn sang dÃ¹ng cÃ¡i nÃ y nhÆ°ng Ä‘ang bá»‹ bÃ­ táº¡i Ä‘Ã¢y. Mong má»i ngÆ°á»i tá»«ng lÃ m qua cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn vÃ  giÃºp mÃ¬nh giáº£i Ä‘Ã¡p tháº¯c máº¯c. Cáº£m Æ¡n nhiá»u áº¡",,,,,
"Xin chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i mÃ¬nh Ä‘ang nghiÃªn cá»©u bÃ i toÃ¡n eKYC cho cÃ´ng ty, cÃ³ trÃ­ch xuáº¥t OCR vÃ  nháº­n diá»‡n CMT/ CÄƒn cÆ°á»›c giáº£ máº¡o. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh xin keyword cho bÃ i toÃ¡n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡?","Xin chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i mÃ¬nh Ä‘ang nghiÃªn cá»©u bÃ i toÃ¡n eKYC cho cÃ´ng ty, cÃ³ trÃ­ch xuáº¥t OCR vÃ  nháº­n diá»‡n CMT/ CÄƒn cÆ°á»›c giáº£ máº¡o. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh xin keyword cho bÃ i toÃ¡n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"Báº¡n nÃ o hÆ°á»›ng dáº«n mÃ¬nh bÃ i nÃ y dc ko áº¡.
MÃ¬nh chá»‰ lÃ m dc 1 input 1 output. NhÆ°ng Ä‘á» bÃ i yÃªu cáº§u 1 input 2 output (vÃ  chá»‰ dc sá»­ dá»¥ng 1 hÃ m Ä‘á»ƒ tÃ­nh ra cáº£ chiá»u cao vá»›i tuá»•i).",Báº¡n nÃ o hÆ°á»›ng dáº«n mÃ¬nh bÃ i nÃ y dc ko áº¡. MÃ¬nh chá»‰ lÃ m dc 1 input 1 output. NhÆ°ng Ä‘á» bÃ i yÃªu cáº§u 1 input 2 output (vÃ  chá»‰ dc sá»­ dá»¥ng 1 hÃ m Ä‘á»ƒ tÃ­nh ra cáº£ chiá»u cao vá»›i tuá»•i).,,,,,
"Má»i ngÆ°á»i cho em há»i áº¡:
Em má»›i hoc ML, em Ä‘ang muá»‘n tÃ¬m há»‡ sá»‘ K vÃ  T cá»§a phÆ°Æ¡ng trÃ¬nh sau khi biáº¿t cÃ¡c Ä‘iá»ƒm (x,y) thÃ¬ sáº½ xá»­ lÃ½ bÃ i toÃ¡n nhÆ° tháº¿ nÃ o áº¡
Tks má»i ngÆ°á»i","Má»i ngÆ°á»i cho em há»i áº¡: Em má»›i hoc ML, em Ä‘ang muá»‘n tÃ¬m há»‡ sá»‘ K vÃ  T cá»§a phÆ°Æ¡ng trÃ¬nh sau khi biáº¿t cÃ¡c Ä‘iá»ƒm (x,y) thÃ¬ sáº½ xá»­ lÃ½ bÃ i toÃ¡n nhÆ° tháº¿ nÃ o áº¡ Tks má»i ngÆ°á»i",,,,,
"Anh chá»‹ cÃ³ ai Ä‘Ã£ tÃ¬m hiá»ƒu vá» ""diffusion"" so vá»›i knn nhÆ° áº£nh dÆ°á»›i rá»“i cÃ³ thá»ƒ giáº£i thÃ­ch giÃ¹m em Ã½ tÆ°á»Ÿng thá»±c hiá»‡n cá»§a nÃ³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n
https://arxiv.org/pdf/1811.10907.pdf","Anh chá»‹ cÃ³ ai Ä‘Ã£ tÃ¬m hiá»ƒu vá» ""diffusion"" so vá»›i knn nhÆ° áº£nh dÆ°á»›i rá»“i cÃ³ thá»ƒ giáº£i thÃ­ch giÃ¹m em Ã½ tÆ°á»Ÿng thá»±c hiá»‡n cá»§a nÃ³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n https://arxiv.org/pdf/1811.10907.pdf",,,,,
"Má»i ngÆ°á»i cÃ³ thá»ƒ tÆ° váº¥n cho mÃ¬nh Ä‘ang lÃ m project face_recognition
MÃ¬nh nháº­n dc dataset cÃ³ nhiá»u subfolder, má»—i cÃ¡i lÃ  43 táº¥m hÃ¬nh cá»§a má»™t ngÆ°á»i Ä‘á»™ phÃ¢n giáº£i cao vÃ  nhiá»u gÃ³c máº·t khÃ¡c nhau
....
Project nÃ y thá»±c sá»± má»Ÿ vÃ  mÃ¬nh chÆ°a tá»«ng code kiá»ƒu dÃ¹ng opencv hay Ä‘áº¡i loáº¡i nhÆ° váº­y bao giá» nÃªn ráº¥t lÃ  khÃ³ hiá»ƒu
TÃ¬m trÃªn máº¡ng thÃ¬ nÃ³ cá»© webcam thui Ã . CÃ²n mÃ¬nh thá»­ sá»­a webcam thÃ nh Ä‘á»c file áº£nh nhÆ°ng vÃ­ dá»¥ trÃªn máº¡nh sá»­ dá»¥ng face_recognition library mÃ¬nh truyá»n vÃ o bÃ¡o lá»—i tÃ¨ le... nghiÃªn cá»©u cáº£ tuáº§n nay háº§u nhÆ° báº¿ táº¯t
Ban Ä‘áº§u káº¿ hoáº¡ch cá»§a mÃ¬nh lÃ  :
Trong Ä‘á»‘ng dataset Ä‘Ã³ chá»n 1 vÃ i hÃ¬nh Ä‘á»ƒ test cÃ²n láº¡i sáº½ láº¥y train, dÃ¹ng KNN Ä‘á»ƒ classifier
Hiá»‡n táº¡i thÃ¬ trÃ´i dáº¡t báº¿n bá» nÃ o luÃ´n rá»“i bá»Ÿi vÃ¬ káº¿ hoáº¡ch lÃ  má»™t chuyá»‡n mÃ  Ä‘á»¥ng vÃ o code láº¡i ko dc nhÆ° Ã½ ...
Má»i ngá»«oi cÃ³ ai tá»«ng lÃ m hoáº·c cÃ³ source nÃ o hÆ°u Ã­ch chia sáº½ mÃ¬nh vá»›i nha
MÃ¬nh biáº¿t project nÃ y research lÃ  chÃ­nh nhÆ°ng náº¿u code ko cháº¡y thÃ¬ lÃ m sao nÃ¢ng cáº¥p lÃªn Ä‘Ã¢y hjx hjx","Má»i ngÆ°á»i cÃ³ thá»ƒ tÆ° váº¥n cho mÃ¬nh Ä‘ang lÃ m project face_recognition MÃ¬nh nháº­n dc dataset cÃ³ nhiá»u subfolder, má»—i cÃ¡i lÃ  43 táº¥m hÃ¬nh cá»§a má»™t ngÆ°á»i Ä‘á»™ phÃ¢n giáº£i cao vÃ  nhiá»u gÃ³c máº·t khÃ¡c nhau .... Project nÃ y thá»±c sá»± má»Ÿ vÃ  mÃ¬nh chÆ°a tá»«ng code kiá»ƒu dÃ¹ng opencv hay Ä‘áº¡i loáº¡i nhÆ° váº­y bao giá» nÃªn ráº¥t lÃ  khÃ³ hiá»ƒu TÃ¬m trÃªn máº¡ng thÃ¬ nÃ³ cá»© webcam thui Ã . CÃ²n mÃ¬nh thá»­ sá»­a webcam thÃ nh Ä‘á»c file áº£nh nhÆ°ng vÃ­ dá»¥ trÃªn máº¡nh sá»­ dá»¥ng face_recognition library mÃ¬nh truyá»n vÃ o bÃ¡o lá»—i tÃ¨ le... nghiÃªn cá»©u cáº£ tuáº§n nay háº§u nhÆ° báº¿ táº¯t Ban Ä‘áº§u káº¿ hoáº¡ch cá»§a mÃ¬nh lÃ  : Trong Ä‘á»‘ng dataset Ä‘Ã³ chá»n 1 vÃ i hÃ¬nh Ä‘á»ƒ test cÃ²n láº¡i sáº½ láº¥y train, dÃ¹ng KNN Ä‘á»ƒ classifier Hiá»‡n táº¡i thÃ¬ trÃ´i dáº¡t báº¿n bá» nÃ o luÃ´n rá»“i bá»Ÿi vÃ¬ káº¿ hoáº¡ch lÃ  má»™t chuyá»‡n mÃ  Ä‘á»¥ng vÃ o code láº¡i ko dc nhÆ° Ã½ ... Má»i ngá»«oi cÃ³ ai tá»«ng lÃ m hoáº·c cÃ³ source nÃ o hÆ°u Ã­ch chia sáº½ mÃ¬nh vá»›i nha MÃ¬nh biáº¿t project nÃ y research lÃ  chÃ­nh nhÆ°ng náº¿u code ko cháº¡y thÃ¬ lÃ m sao nÃ¢ng cáº¥p lÃªn Ä‘Ã¢y hjx hjx",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» Domain Adaptation/Domain Generalization tá»« nhá»¯ng bÆ°á»›c Ä‘áº§u tiÃªn (Ä‘á»‹nh nghÄ©a, lÃ­ thuyáº¿t, á»©ng dá»¥ng,...). Mn ai Ä‘Ã£ tá»«ng nghiÃªn cá»©u vá» pháº§n nÃ y cÃ³ thá»ƒ cho em xin tÃ i liá»‡u hoáº·c nÆ¡i cÃ³ thá»ƒ tÃ¬m kiáº¿m tÃ i liá»‡u Ä‘c k áº¡? VÃ¬ e tÃ¬m trÃªn internet vá» nÃ³ thÃ¬ káº¿t quáº£ ra khÃ¡ mÆ¡ há»“. E cáº£m Æ¡n mn áº¡!","Em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» Domain Adaptation/Domain Generalization tá»« nhá»¯ng bÆ°á»›c Ä‘áº§u tiÃªn (Ä‘á»‹nh nghÄ©a, lÃ­ thuyáº¿t, á»©ng dá»¥ng,...). Mn ai Ä‘Ã£ tá»«ng nghiÃªn cá»©u vá» pháº§n nÃ y cÃ³ thá»ƒ cho em xin tÃ i liá»‡u hoáº·c nÆ¡i cÃ³ thá»ƒ tÃ¬m kiáº¿m tÃ i liá»‡u Ä‘c k áº¡? VÃ¬ e tÃ¬m trÃªn internet vá» nÃ³ thÃ¬ káº¿t quáº£ ra khÃ¡ mÆ¡ há»“. E cáº£m Æ¡n mn áº¡!",,,,,
All backbones in one package,All backbones in one package,,,,,
,nan,,,,,
"Xin chÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t trong Ä‘Ã¢y cÃ³ ai cÃ³ bá»™ dá»¯ liá»‡u VSLP 2016 hay 2018 cho NER khÃ´ng áº¡ ? Náº¿u cÃ³ báº¡n cÃ³ thá»ƒ chia sáº» cho mÃ¬nh khÃ´ng ? MÃ¬nh cáº£m Æ¡n áº¡.","Xin chÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t trong Ä‘Ã¢y cÃ³ ai cÃ³ bá»™ dá»¯ liá»‡u VSLP 2016 hay 2018 cho NER khÃ´ng áº¡ ? Náº¿u cÃ³ báº¡n cÃ³ thá»ƒ chia sáº» cho mÃ¬nh khÃ´ng ? MÃ¬nh cáº£m Æ¡n áº¡.",,,,,
"Do Ä‘Æ°á»£c má»™t sá»‘ báº¡n, anh chá»‹ trong gruop khuyáº¿n khÃ­ch chia sáº», mÃ¬nh xin Ä‘áº¡i diá»‡n cho team Train4Ever mÃ¬nh xin Ä‘Æ°á»£c tÃ³m táº¯t solution Ä‘á»©ng vá»‹ trÃ­ thá»© 6 trong cuá»™c thi RSNA-MICCAI Brain Tumor Radiogenomic Classification. Máº·c dÃ¹ khÃ´ng phá»§ nháº­n yáº¿u tá»‘ may máº¯n trong cÃ¡c cuá»™c thi shake up lá»›n nhÆ° nÃ y, tuy nhiÃªn bá»n mÃ¬nh cÅ©ng Ä‘Ã£ chuáº©n bá»‹ trÆ°á»›c vÃ  cá»‘ gáº¯ng tÃ¬m ra giáº£i phÃ¡p cÃ¢n báº±ng nháº¥t giá»¯a validation score vÃ  public score, thá»±c táº¿ 2 submission Ä‘Æ°á»£c lá»±a chá»n lÃ  2 submission cÃ³ káº¿t quáº£ private tá»‘t nháº¥t. Hi vá»ng cÃ³ thá»ƒ há»c há»i tá»« nhá»¯ng gÃ³p Ã½ cá»§a cÃ¡c báº¡n.
BÃ i toÃ¡n: PhÃ¢n loáº¡i xem khá»‘i u nÃ£o cÃ³ chá»©a má»™t Ä‘oáº¡n gene gá»i lÃ  MGMT promoter methylation hay khÃ´ng, data sá»­ dá»¥ng lÃ  áº£nh cá»™ng hÆ°á»Ÿng tá»« MRI. Má»¥c tiÃªu lÃ  cÃ³ thá»ƒ Ä‘Æ°a ra chuáº©n Ä‘oÃ¡n mÃ  khÃ´ng cáº§n thá»±c hiá»‡n giáº£i pháº«u (invasive diagnose).
Giáº£i phÃ¡p cá»§a nhÃ³m gá»“m 2 stage training vÃ  infer. CÃ¡c model Ä‘á»u nháº­n vÃ o input lÃ  áº£nh 2D (bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ tiáº¿p cáº­n theo hÆ°á»›ng 3D).
Stage 1 train model segmentation trÃªn bá»™ dá»¯ liá»‡u cá»§a track Segmentation khá»‘i u (track Segmentation Ä‘Æ°á»£c tá»• chá»©c song song cá»§a BTC, track trÃªn Kaggle lÃ  classification). Model stage 1 Ä‘Æ°a ra mask Ä‘Ã¡nh dáº¥u vá»‹ trÃ­ khá»‘i u. Äiá»u nÃ y lÃ  quan trá»ng Ä‘á»ƒ giÃºp model focus vÃ o nhá»¯ng vá»‹ trÃ­ quan trá»ng (khá»‘i u) Ä‘á»ƒ giáº£m bias vÃ o nhÆ°ng feature khÃ¡c Ä‘á»‘i vá»›i bÃ i toÃ¡n Ã­t dá»¯ liá»‡u nhÆ° váº­y.
Stage 2 train sequence model LSTM vá»›i input lÃ  1 chuá»—i cÃ¡c áº£nh 3 kÃªnh (1 kÃªnh áº£nh gá»‘c vÃ  2 kÃªnh cÃ²n láº¡i lÃ  2 loáº¡i mask do model segmentation dá»± Ä‘oÃ¡n ra). Chuá»—i áº£nh input tuáº§n tá»± theo vá»‹ trÃ­ khi scan nÃ£o bá»™. Model sá»­ dá»¥ng backbone CNN extract cÃ¡c embedding sau Ä‘Ã³ Ä‘Æ°a cÃ¡c time step vÃ o Bidirectional LSTM rá»“i Ä‘áº¿n lá»›p classification.
Chi tiáº¿t solution vÃ  káº¿t quáº£ cÃ³ thá»ƒ xem trong:
Github: https://github.com/gallegi/T4E_MICCAI_BrainTumor
Kaggle discussion: https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/discussion/280402
Nháº­t TrÆ°á»ng BÃ¹i KhÃ¡nh VÅ© Duy Tuyen Dam","Do Ä‘Æ°á»£c má»™t sá»‘ báº¡n, anh chá»‹ trong gruop khuyáº¿n khÃ­ch chia sáº», mÃ¬nh xin Ä‘áº¡i diá»‡n cho team Train4Ever mÃ¬nh xin Ä‘Æ°á»£c tÃ³m táº¯t solution Ä‘á»©ng vá»‹ trÃ­ thá»© 6 trong cuá»™c thi RSNA-MICCAI Brain Tumor Radiogenomic Classification. Máº·c dÃ¹ khÃ´ng phá»§ nháº­n yáº¿u tá»‘ may máº¯n trong cÃ¡c cuá»™c thi shake up lá»›n nhÆ° nÃ y, tuy nhiÃªn bá»n mÃ¬nh cÅ©ng Ä‘Ã£ chuáº©n bá»‹ trÆ°á»›c vÃ  cá»‘ gáº¯ng tÃ¬m ra giáº£i phÃ¡p cÃ¢n báº±ng nháº¥t giá»¯a validation score vÃ  public score, thá»±c táº¿ 2 submission Ä‘Æ°á»£c lá»±a chá»n lÃ  2 submission cÃ³ káº¿t quáº£ private tá»‘t nháº¥t. Hi vá»ng cÃ³ thá»ƒ há»c há»i tá»« nhá»¯ng gÃ³p Ã½ cá»§a cÃ¡c báº¡n. BÃ i toÃ¡n: PhÃ¢n loáº¡i xem khá»‘i u nÃ£o cÃ³ chá»©a má»™t Ä‘oáº¡n gene gá»i lÃ  MGMT promoter methylation hay khÃ´ng, data sá»­ dá»¥ng lÃ  áº£nh cá»™ng hÆ°á»Ÿng tá»« MRI. Má»¥c tiÃªu lÃ  cÃ³ thá»ƒ Ä‘Æ°a ra chuáº©n Ä‘oÃ¡n mÃ  khÃ´ng cáº§n thá»±c hiá»‡n giáº£i pháº«u (invasive diagnose). Giáº£i phÃ¡p cá»§a nhÃ³m gá»“m 2 stage training vÃ  infer. CÃ¡c model Ä‘á»u nháº­n vÃ o input lÃ  áº£nh 2D (bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ tiáº¿p cáº­n theo hÆ°á»›ng 3D). Stage 1 train model segmentation trÃªn bá»™ dá»¯ liá»‡u cá»§a track Segmentation khá»‘i u (track Segmentation Ä‘Æ°á»£c tá»• chá»©c song song cá»§a BTC, track trÃªn Kaggle lÃ  classification). Model stage 1 Ä‘Æ°a ra mask Ä‘Ã¡nh dáº¥u vá»‹ trÃ­ khá»‘i u. Äiá»u nÃ y lÃ  quan trá»ng Ä‘á»ƒ giÃºp model focus vÃ o nhá»¯ng vá»‹ trÃ­ quan trá»ng (khá»‘i u) Ä‘á»ƒ giáº£m bias vÃ o nhÆ°ng feature khÃ¡c Ä‘á»‘i vá»›i bÃ i toÃ¡n Ã­t dá»¯ liá»‡u nhÆ° váº­y. Stage 2 train sequence model LSTM vá»›i input lÃ  1 chuá»—i cÃ¡c áº£nh 3 kÃªnh (1 kÃªnh áº£nh gá»‘c vÃ  2 kÃªnh cÃ²n láº¡i lÃ  2 loáº¡i mask do model segmentation dá»± Ä‘oÃ¡n ra). Chuá»—i áº£nh input tuáº§n tá»± theo vá»‹ trÃ­ khi scan nÃ£o bá»™. Model sá»­ dá»¥ng backbone CNN extract cÃ¡c embedding sau Ä‘Ã³ Ä‘Æ°a cÃ¡c time step vÃ o Bidirectional LSTM rá»“i Ä‘áº¿n lá»›p classification. Chi tiáº¿t solution vÃ  káº¿t quáº£ cÃ³ thá»ƒ xem trong: Github: https://github.com/gallegi/T4E_MICCAI_BrainTumor Kaggle discussion: https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/discussion/280402 Nháº­t TrÆ°á»ng BÃ¹i KhÃ¡nh VÅ© Duy Tuyen Dam",,,,,
"Huáº¥n luyá»‡n models vá»›i low numberical Precision giÃºp khÃ´ng nhá»¯ng duy trÃ¬ Ä‘Æ°á»£c hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh mÃ  cÃ²n giÃºp GIáº¢M:
a) kÃ­ch cá»¡ mÃ´ hÃ¬nh
b) dung lÆ°á»£ng bá»™ nhá»› VRAM trÃªn GPU hay TPU
c) nÄƒng lÆ°á»£ng tiÃªu thá»¥
Chi tiáº¿t xem trong Ä‘Æ°á»ng dáº«n bÃªn dÆ°á»›i
âœ¨ Low Numerical Precision in PyTorch âœ¨
Most DL models are single-precision floats by default.
Lower numerical precision - while reasonably maintaining accuracy - reduces:
a) model size
b) memory required
c) power consumed",Huáº¥n luyá»‡n models vá»›i low numberical Precision giÃºp khÃ´ng nhá»¯ng duy trÃ¬ Ä‘Æ°á»£c hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh mÃ  cÃ²n giÃºp GIáº¢M: a) kÃ­ch cá»¡ mÃ´ hÃ¬nh b) dung lÆ°á»£ng bá»™ nhá»› VRAM trÃªn GPU hay TPU c) nÄƒng lÆ°á»£ng tiÃªu thá»¥ Chi tiáº¿t xem trong Ä‘Æ°á»ng dáº«n bÃªn dÆ°á»›i Low Numerical Precision in PyTorch Most DL models are single-precision floats by default. Lower numerical precision - while reasonably maintaining accuracy - reduces: a) model size b) memory required c) power consumed,,,,,
"cho em há»i vá»›i áº¡, em cÃ³ lÆ°u con model cá»§a em vá» dang checkpoint nhÆ°ng h em muá»‘n mÃ³c nÃ³ ra Ä‘á»ƒ xÃ i thÃ¬ em dÃ¹ng hÃ m gÃ¬ áº¡ :'( tutorial trÃªn máº¡ng toÃ n saveweight vá»›i loadweight nhÆ°ng em ko xÃ i Ä‘c áº¡","cho em há»i vá»›i áº¡, em cÃ³ lÆ°u con model cá»§a em vá» dang checkpoint nhÆ°ng h em muá»‘n mÃ³c nÃ³ ra Ä‘á»ƒ xÃ i thÃ¬ em dÃ¹ng hÃ m gÃ¬ áº¡ :'( tutorial trÃªn máº¡ng toÃ n saveweight vá»›i loadweight nhÆ°ng em ko xÃ i Ä‘c áº¡",,,,,
"Cho em há»i vá» False Positive áº¡. Em Ä‘ang lÃ m vá» template matching. Náº¿u khi thá»±c hiá»‡n matching vá»›i káº¿t quáº£ 0<IOU<Threshold thÃ¬ Ä‘Ã³ lÃ  FP pháº£i khÃ´ng áº¡. NhÆ°ng trÆ°á»ng há»£p nÃ³ matching má»™t wrong object, tá»©c IOU = 0 thÃ¬ cÃ³ pháº£i cÅ©ng tÃ­nh lÃ  1 FP khÃ´ng áº¡? Náº¿u Ä‘Ãºng tháº¿ thÃ¬ Precision cá»§a nÃ³ chÃ­nh báº±ng pháº§n trÄƒm successful matching vá»›i má»™t threshold cho trÆ°á»›c Ä‘Ãºng khÃ´ng áº¡?","Cho em há»i vá» False Positive áº¡. Em Ä‘ang lÃ m vá» template matching. Náº¿u khi thá»±c hiá»‡n matching vá»›i káº¿t quáº£ 0<IOU<Threshold thÃ¬ Ä‘Ã³ lÃ  FP pháº£i khÃ´ng áº¡. NhÆ°ng trÆ°á»ng há»£p nÃ³ matching má»™t wrong object, tá»©c IOU = 0 thÃ¬ cÃ³ pháº£i cÅ©ng tÃ­nh lÃ  1 FP khÃ´ng áº¡? Náº¿u Ä‘Ãºng tháº¿ thÃ¬ Precision cá»§a nÃ³ chÃ­nh báº±ng pháº§n trÄƒm successful matching vá»›i má»™t threshold cho trÆ°á»›c Ä‘Ãºng khÃ´ng áº¡?",,,,,
ChÃºc má»«ng ngÃ y phá»¥ ná»¯ Viá»‡t Nam 20/10,ChÃºc má»«ng ngÃ y phá»¥ ná»¯ Viá»‡t Nam 20/10,,,,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang cÃ³ má»™t Ä‘á» tÃ i ML vá» hÃ nh vi báº¥t thÆ°á»ng cá»§a ngÆ°á»i trong nhÃ , tá»« Ä‘Ã³ xÃ¡c Ä‘á»‹nh tai náº¡n. Cho em há»i lÃ  cÃ³ ai cÃ³ táº­p data, cÃ³ thá»ƒ cho em tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡, hoáº·c em cÃ³ thá»ƒ kiáº¿m á»Ÿ Ä‘Ã¢u? Em cáº£m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i. Em Ä‘ang cÃ³ má»™t Ä‘á» tÃ i ML vá» hÃ nh vi báº¥t thÆ°á»ng cá»§a ngÆ°á»i trong nhÃ , tá»« Ä‘Ã³ xÃ¡c Ä‘á»‹nh tai náº¡n. Cho em há»i lÃ  cÃ³ ai cÃ³ táº­p data, cÃ³ thá»ƒ cho em tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡, hoáº·c em cÃ³ thá»ƒ kiáº¿m á»Ÿ Ä‘Ã¢u? Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m Ä‘á» tÃ i vá» khai phÃ¡ dá»¯ liá»‡u trong thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­. Em Ä‘ang cáº§n tÃ¬m táº­p dá»¯ liá»‡u bao gá»“m thÃ´ng tin hÃ nh vi khÃ¡ch hÃ ng (click xem sáº£n pháº©m, thÃªm giá» hÃ ng, mua,...) vÃ  Ä‘Ã¡nh giÃ¡ cá»§a há» vá» sáº£n pháº©m.
HiÃªn táº¡i thÃ¬ em chá»‰ tÃ¬m Ä‘Æ°á»£c táº­p dá»¯ liá»‡u riÃªng vá» 2 loáº¡i thÃ´ng tin trÃªn. Má»i ngÆ°á»i cÃ³ biáº¿t táº­p dá»¯ liá»‡u nÃ o cÃ³ cáº£ 2 thÃ´ng tin trÃªn thÃ¬ cho em xin vá»›i áº¡! Em cÃ³ tÃ¬m trÃªn nhiá»u nguá»“n nhÆ°ng chÆ°a tháº¥y.
Em xin cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m Ä‘á» tÃ i vá» khai phÃ¡ dá»¯ liá»‡u trong thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­. Em Ä‘ang cáº§n tÃ¬m táº­p dá»¯ liá»‡u bao gá»“m thÃ´ng tin hÃ nh vi khÃ¡ch hÃ ng (click xem sáº£n pháº©m, thÃªm giá» hÃ ng, mua,...) vÃ  Ä‘Ã¡nh giÃ¡ cá»§a há» vá» sáº£n pháº©m. HiÃªn táº¡i thÃ¬ em chá»‰ tÃ¬m Ä‘Æ°á»£c táº­p dá»¯ liá»‡u riÃªng vá» 2 loáº¡i thÃ´ng tin trÃªn. Má»i ngÆ°á»i cÃ³ biáº¿t táº­p dá»¯ liá»‡u nÃ o cÃ³ cáº£ 2 thÃ´ng tin trÃªn thÃ¬ cho em xin vá»›i áº¡! Em cÃ³ tÃ¬m trÃªn nhiá»u nguá»“n nhÆ°ng chÆ°a tháº¥y. Em xin cáº£m Æ¡n!",,,,,
"Anh chá»‹ cho em há»i váº¥n Ä‘á» nÃ y vá»›i áº¡. Em Ä‘ang lÃ m bÃ i táº­p Face Regconite, em dÃ¹ng network GoogleNet, sao khi detect face, em cáº¯t hÃ¬nh Ä‘á»ƒ lÃ m input cho model googlenet, xong em output ra class (tÃªn ngÆ°á»i) vÃ  chÃ¨n chá»¯ {tÃªn ngÆ°á»i} vÃ o rectangle, nhÆ°ng náº¿u lÃ  ngÆ°á»i láº¡ chÆ°a Ä‘Æ°á»£c train thÃ¬ module ra output sai áº¡. Cho em há»i cÃ³ cÃ¡ch nÃ o khi báº¯t áº£nh ngÆ°á»i mÃ  chÆ°a Ä‘Æ°á»£c train thÃ¬ model cho ra class ""unknown"" khÃ´ng áº¡, em xÃ i Dense - softmax.
Em cáº£m Æ¡n áº¡.","Anh chá»‹ cho em há»i váº¥n Ä‘á» nÃ y vá»›i áº¡. Em Ä‘ang lÃ m bÃ i táº­p Face Regconite, em dÃ¹ng network GoogleNet, sao khi detect face, em cáº¯t hÃ¬nh Ä‘á»ƒ lÃ m input cho model googlenet, xong em output ra class (tÃªn ngÆ°á»i) vÃ  chÃ¨n chá»¯ {tÃªn ngÆ°á»i} vÃ o rectangle, nhÆ°ng náº¿u lÃ  ngÆ°á»i láº¡ chÆ°a Ä‘Æ°á»£c train thÃ¬ module ra output sai áº¡. Cho em há»i cÃ³ cÃ¡ch nÃ o khi báº¯t áº£nh ngÆ°á»i mÃ  chÆ°a Ä‘Æ°á»£c train thÃ¬ model cho ra class ""unknown"" khÃ´ng áº¡, em xÃ i Dense - softmax. Em cáº£m Æ¡n áº¡.",,,,,
,nan,,,,,
"Mn cÃ³ ai Ä‘Ã£ tá»«ng tÃ¬m hiá»ƒu vá» query expansion trong bÃ i toÃ¡n information retrieval cá»¥ thá»ƒ lÃ  ""alpha weighted query expansion"" . thÃ¬ cÃ³ thá»ƒ tÃ³m lÆ°á»£c cÃ¡ch thá»±c hiá»‡n giÃºp e vá»›i Ä‘k ko áº¡. E Ä‘á»c vÃ o paper nhÆ°ng khÃ´ng hiá»ƒu láº¯m áº¡ . em cáº£m Æ¡n mn","Mn cÃ³ ai Ä‘Ã£ tá»«ng tÃ¬m hiá»ƒu vá» query expansion trong bÃ i toÃ¡n information retrieval cá»¥ thá»ƒ lÃ  ""alpha weighted query expansion"" . thÃ¬ cÃ³ thá»ƒ tÃ³m lÆ°á»£c cÃ¡ch thá»±c hiá»‡n giÃºp e vá»›i Ä‘k ko áº¡. E Ä‘á»c vÃ o paper nhÆ°ng khÃ´ng hiá»ƒu láº¯m áº¡ . em cáº£m Æ¡n mn",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡ !
Em má»›i Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i Machine Learning.
VÃ  em Ä‘ang há»c báº£n má»m cá»§a cuá»‘n Machine Learning cá»§a tÃ¡c giáº£ VÅ© Há»¯u Tiá»‡p áº¡.
ThÃ¬ em cÃ³ tháº¥y chÆ°Æ¡ng Ä‘áº§u cá»§a cÃ³ nÃ³i vá» cÃ¡c kiáº¿n thá»©c toÃ¡n cáº§n thiáº¿t.
Em cÅ©ng hÆ¡i tháº¯c máº¯c áº¡. VÃ¬ em nghÄ© lÃ m Ä‘Æ°á»£c bÃ i chÆ°a cháº¯c Ä‘Ã£ hiá»ƒu váº¥n Ä‘á» Ä‘Ã³ lÃ  gÃ¬.
VÃ¬ giáº£ sá»­ náº¿u Ä‘á»ƒ lÃ m bÃ i Ä‘á»ƒ thi thÃ¬ em nÃªn máº¡ng há»c Ä‘i há»c láº¡i cÃ¡i thuáº­t toÃ¡n ngÆ°á»i ta hay lÃ m rá»“i lÃ m theo lÃ  Ä‘Æ°á»£c áº¡. Váº­y má»i ngÆ°á»i cho em há»i lÃ  há»c toÃ¡n nhÆ° nÃ o lÃ  Ä‘Ãºng Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i Machine Learning áº¡? Em cáº£m Æ¡n !",Em chÃ o má»i ngÆ°á»i áº¡ ! Em má»›i Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i Machine Learning. VÃ  em Ä‘ang há»c báº£n má»m cá»§a cuá»‘n Machine Learning cá»§a tÃ¡c giáº£ VÅ© Há»¯u Tiá»‡p áº¡. ThÃ¬ em cÃ³ tháº¥y chÆ°Æ¡ng Ä‘áº§u cá»§a cÃ³ nÃ³i vá» cÃ¡c kiáº¿n thá»©c toÃ¡n cáº§n thiáº¿t. Em cÅ©ng hÆ¡i tháº¯c máº¯c áº¡. VÃ¬ em nghÄ© lÃ m Ä‘Æ°á»£c bÃ i chÆ°a cháº¯c Ä‘Ã£ hiá»ƒu váº¥n Ä‘á» Ä‘Ã³ lÃ  gÃ¬. VÃ¬ giáº£ sá»­ náº¿u Ä‘á»ƒ lÃ m bÃ i Ä‘á»ƒ thi thÃ¬ em nÃªn máº¡ng há»c Ä‘i há»c láº¡i cÃ¡i thuáº­t toÃ¡n ngÆ°á»i ta hay lÃ m rá»“i lÃ m theo lÃ  Ä‘Æ°á»£c áº¡. Váº­y má»i ngÆ°á»i cho em há»i lÃ  há»c toÃ¡n nhÆ° nÃ o lÃ  Ä‘Ãºng Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i Machine Learning áº¡? Em cáº£m Æ¡n !,,,,,
"ChÃºc má»«ng 2 Ä‘á»™i Viá»‡t Nam Ä‘áº¡t thá»© háº¡ng cao (háº¡ng má»¥c nháº­n tiá»n thÆ°á»Ÿng) trong cuá»™c thi ""RSNA-MICCAI Brain Tumor Radiogenomic Classification"". BÃ i thi nÃ y lÃ  mÃ´t minh chá»©ng cho hiá»‡n tÆ°á»£ng Overfitting náº·ng. ÄÃ¢y lÃ  láº§n thá»© 2 mÃ¬nh chá»©ng kiáº¿n hiá»‡n tÆ°á»£ng nÃ y sau cuá»™c thi phÃ¢n loáº¡i Casava diseases. CÃ¡c báº¡n cÃ³ thá»ƒ xem hinh bÃªn dÆ°á»›i, báº¡n Minh Phan Ä‘Ã£ leo 595 báº­c tá»« public leaderboard so vá»›i private leaderboard. TÆ°Æ¡ng tá»± nhÃ³m Train4Ever cÅ©ng leo 429 báº­c. NgÆ°á»i vá» nháº¥t trong má»¥c private leaderboard cÃ²n leo >1000 báº­c. Tiáº¿t lá»™ thÃªm, mÃ¬nh cÅ©ng thá»­ bÃ i nÃ y, káº¿t quáº£ trÃªn validation set cá»§a mÃ¬nh Ä‘áº¡t ~0.69, nÃªn tháº¥y cÃ³ váº» khÃ´ng Äƒn thua nÃªn tá»« bá», khÃ´ng submit káº¿t quáº£! MÃ¬nh nghÄ© sáº½ cÃ³ nhiá»u ngÆ°á»i ráº¥t báº¥t ngá» khi nháº­n giáº£i á»Ÿ cuá»™c thi nÃ y","ChÃºc má»«ng 2 Ä‘á»™i Viá»‡t Nam Ä‘áº¡t thá»© háº¡ng cao (háº¡ng má»¥c nháº­n tiá»n thÆ°á»Ÿng) trong cuá»™c thi ""RSNA-MICCAI Brain Tumor Radiogenomic Classification"". BÃ i thi nÃ y lÃ  mÃ´t minh chá»©ng cho hiá»‡n tÆ°á»£ng Overfitting náº·ng. ÄÃ¢y lÃ  láº§n thá»© 2 mÃ¬nh chá»©ng kiáº¿n hiá»‡n tÆ°á»£ng nÃ y sau cuá»™c thi phÃ¢n loáº¡i Casava diseases. CÃ¡c báº¡n cÃ³ thá»ƒ xem hinh bÃªn dÆ°á»›i, báº¡n Minh Phan Ä‘Ã£ leo 595 báº­c tá»« public leaderboard so vá»›i private leaderboard. TÆ°Æ¡ng tá»± nhÃ³m Train4Ever cÅ©ng leo 429 báº­c. NgÆ°á»i vá» nháº¥t trong má»¥c private leaderboard cÃ²n leo >1000 báº­c. Tiáº¿t lá»™ thÃªm, mÃ¬nh cÅ©ng thá»­ bÃ i nÃ y, káº¿t quáº£ trÃªn validation set cá»§a mÃ¬nh Ä‘áº¡t ~0.69, nÃªn tháº¥y cÃ³ váº» khÃ´ng Äƒn thua nÃªn tá»« bá», khÃ´ng submit káº¿t quáº£! MÃ¬nh nghÄ© sáº½ cÃ³ nhiá»u ngÆ°á»i ráº¥t báº¥t ngá» khi nháº­n giáº£i á»Ÿ cuá»™c thi nÃ y",,,,,
"MÃ¬nh chÆ°a biáº¿t gÃ¬ vá» machine learning. Hiá»‡n táº¡i mÃ¬nh Ä‘ang dÃ¹ng api google vision nháº­n diá»‡n text tá»« hÃ¬nh áº£nh chá»¥p vÃ  so sÃ¡nh text nÃ y vá»›i DB giá»‘ng nhau thÃ¬ tráº£ vá» káº¿t quáº£.
BÃ¢y giá» mÃ¬nh muá»‘n Ã¡p dá»¥ng machine learning vÃ o thÃ¬ tÃ¬m hiá»ƒu vÃ  há»c nhÆ° nÃ o áº¡. MÃ¬nh cÃ³ xin account cá»§a Aws tá»« cÃ´ng ty.",MÃ¬nh chÆ°a biáº¿t gÃ¬ vá» machine learning. Hiá»‡n táº¡i mÃ¬nh Ä‘ang dÃ¹ng api google vision nháº­n diá»‡n text tá»« hÃ¬nh áº£nh chá»¥p vÃ  so sÃ¡nh text nÃ y vá»›i DB giá»‘ng nhau thÃ¬ tráº£ vá» káº¿t quáº£. BÃ¢y giá» mÃ¬nh muá»‘n Ã¡p dá»¥ng machine learning vÃ o thÃ¬ tÃ¬m hiá»ƒu vÃ  há»c nhÆ° nÃ o áº¡. MÃ¬nh cÃ³ xin account cá»§a Aws tá»« cÃ´ng ty.,,,,,
"ChÃ o má»i ngÆ°á»i áº¡, mÃ¬nh cÃ³ 2 tháº¯c máº¯c nÃ y muá»‘n nhá» giáº£i Ä‘Ã¡p:
1/ DÃ¹ng kiáº¿n trÃºc CNN nháº­n Ä‘áº§u vÃ o lÃ  vector tf-idf?
Thá»±c ra khÃ´ng háº³n lÃ  tf-idf. 2 paper 'peptide frequency' vÃ  'deeph-dta' thiáº¿t káº¿ má»™t biá»ƒu diá»…n cho dá»¯ liá»‡u chuá»—i amino acid, gá»i lÃ  peptide frequency of word frequency, nhÆ°ng nÃ³ cÅ©ng tÆ°Æ¡ng Ä‘á»“ng vá»›i tf-idf thÃ´i. VÃ  'peptide frequency' Ä‘á» xuáº¥t dÃ¹ng kiáº¿n trÃºc 1D-CNN Ä‘á»ƒ há»c má»™t embedding cho Ä‘á»‘i tÆ°á»£ng protein mÃ  chuá»—i amino acid Ä‘Ã³ biá»ƒu diá»…n, cÃ²n 'deeph-dta' thÃ¬ dÃ¹ng DenseNet. NhÆ°ng mÃ¬nh lÃ  táº¡i sao láº¡i dÃ¹ng kiáº¿n trÃºc CNN cho dá»¯ liá»‡u kiá»ƒu tf-idf, vÃ¬ biá»ƒu diá»…n tf-idf Ä‘Ã£ lÃ m máº¥t Ä‘i quan há»‡ lÃ¢n cáº­n cá»§a cÃ¡c tá»« rá»“i?
2/ DÃ¹ng kiáº¿n trÃºc ConvLSTM cho Ä‘áº§u vÃ o lÃ  chuá»—i vector?
'deeph-dta' xá»­ lÃ½ dá»¯ liá»‡u chuá»—i SMILES (1 kiá»ƒu chuá»—i biá»ƒu diá»…n cho phÃ¢n tá»­ hoÃ¡ há»c) theo kiá»ƒu: cho chuá»—i Ä‘i qua lá»›p embedding trÆ°á»›c khi vÃ o cÃ¡c lá»›p ConvLSTM. Äiá»u mÃ¬nh khÃ´ng hiá»ƒu lÃ : sau khi qua lá»›p embedding, má»—i chuá»—i kÃ½ tá»± sáº½ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 1 chuá»—i vector (vai trÃ² nhÆ° má»™t feature vector cho má»™t Ä‘á»‘i tÆ°á»£ng tá»« cá»§a chuá»—i); cÃ²n ConvLSTM, náº¿u lÃ  phiÃªn báº£n Ã­t chiá»u nháº¥t, ConvLSTM1D thÃ¬ Ä‘áº§u vÃ o cá»§a nÃ³ cÃ³ hÃ¬nh dáº¡ng (batch, length, row, channel). Váº­y náº¿u cho chuá»—i embedding vÃ o ConvLSTM thÃ¬ hoáº·c pháº£i coi length=1 (tháº¿ thÃ¬ dÃ¹ng kiáº¿n trÃºc lai RNN lÃ  vÃ´ nghÄ©a) hoáº·c pháº£i coi channel=1 (khÃ´ng há»£p lÃ½ khi lá»›p embedding trÆ°á»›c Ä‘Ã³ Ä‘Ã£ embed má»—i tá»« thÃ nh 1 vector nhiá»u chiá»u) hoáº·c pháº£i coi row=1 (cÅ©ng khÃ´ng há»£p lÃ½, giá»‘ng nhÆ° dÃ¹ng CNN cho áº£nh luÃ´n cao 1 pixel hay rá»™ng 1 pixel váº­y).
Link 'peptide frequency': https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7147459/
'deeph-dta':https://ieeexplore.ieee.org/document/9197589
MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.","ChÃ o má»i ngÆ°á»i áº¡, mÃ¬nh cÃ³ 2 tháº¯c máº¯c nÃ y muá»‘n nhá» giáº£i Ä‘Ã¡p: 1/ DÃ¹ng kiáº¿n trÃºc CNN nháº­n Ä‘áº§u vÃ o lÃ  vector tf-idf? Thá»±c ra khÃ´ng háº³n lÃ  tf-idf. 2 paper 'peptide frequency' vÃ  'deeph-dta' thiáº¿t káº¿ má»™t biá»ƒu diá»…n cho dá»¯ liá»‡u chuá»—i amino acid, gá»i lÃ  peptide frequency of word frequency, nhÆ°ng nÃ³ cÅ©ng tÆ°Æ¡ng Ä‘á»“ng vá»›i tf-idf thÃ´i. VÃ  'peptide frequency' Ä‘á» xuáº¥t dÃ¹ng kiáº¿n trÃºc 1D-CNN Ä‘á»ƒ há»c má»™t embedding cho Ä‘á»‘i tÆ°á»£ng protein mÃ  chuá»—i amino acid Ä‘Ã³ biá»ƒu diá»…n, cÃ²n 'deeph-dta' thÃ¬ dÃ¹ng DenseNet. NhÆ°ng mÃ¬nh lÃ  táº¡i sao láº¡i dÃ¹ng kiáº¿n trÃºc CNN cho dá»¯ liá»‡u kiá»ƒu tf-idf, vÃ¬ biá»ƒu diá»…n tf-idf Ä‘Ã£ lÃ m máº¥t Ä‘i quan há»‡ lÃ¢n cáº­n cá»§a cÃ¡c tá»« rá»“i? 2/ DÃ¹ng kiáº¿n trÃºc ConvLSTM cho Ä‘áº§u vÃ o lÃ  chuá»—i vector? 'deeph-dta' xá»­ lÃ½ dá»¯ liá»‡u chuá»—i SMILES (1 kiá»ƒu chuá»—i biá»ƒu diá»…n cho phÃ¢n tá»­ hoÃ¡ há»c) theo kiá»ƒu: cho chuá»—i Ä‘i qua lá»›p embedding trÆ°á»›c khi vÃ o cÃ¡c lá»›p ConvLSTM. Äiá»u mÃ¬nh khÃ´ng hiá»ƒu lÃ : sau khi qua lá»›p embedding, má»—i chuá»—i kÃ½ tá»± sáº½ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 1 chuá»—i vector (vai trÃ² nhÆ° má»™t feature vector cho má»™t Ä‘á»‘i tÆ°á»£ng tá»« cá»§a chuá»—i); cÃ²n ConvLSTM, náº¿u lÃ  phiÃªn báº£n Ã­t chiá»u nháº¥t, ConvLSTM1D thÃ¬ Ä‘áº§u vÃ o cá»§a nÃ³ cÃ³ hÃ¬nh dáº¡ng (batch, length, row, channel). Váº­y náº¿u cho chuá»—i embedding vÃ o ConvLSTM thÃ¬ hoáº·c pháº£i coi length=1 (tháº¿ thÃ¬ dÃ¹ng kiáº¿n trÃºc lai RNN lÃ  vÃ´ nghÄ©a) hoáº·c pháº£i coi channel=1 (khÃ´ng há»£p lÃ½ khi lá»›p embedding trÆ°á»›c Ä‘Ã³ Ä‘Ã£ embed má»—i tá»« thÃ nh 1 vector nhiá»u chiá»u) hoáº·c pháº£i coi row=1 (cÅ©ng khÃ´ng há»£p lÃ½, giá»‘ng nhÆ° dÃ¹ng CNN cho áº£nh luÃ´n cao 1 pixel hay rá»™ng 1 pixel váº­y). Link 'peptide frequency': https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7147459/ 'deeph-dta':https://ieeexplore.ieee.org/document/9197589 MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
,nan,,,,,
"[AI Share â€“ Distribution is all you need]
Náº¿u nhÆ° trong Deep learning nÃ³i chung, hay NLP, CV nÃ³i riÃªng thÃ¬ â€œAttention is all you needâ€ . Váº­y trong toÃ¡n há»c thÃ¬ sao ? CÃ¢u tráº£ lá»i lÃ  â€œDistribution is all You Needâ€. Tháº­t ra cÃ¢u tráº£ lá»i chá»‰ nÃ³i lÃªn cÃ¡c phÃ¢n phá»‘i lÃ  má»™t pháº§n ráº¥t quan trá»ng vÃ  khÃ´ng thá»ƒ thiáº¿u trong toÃ¡n, chá»© Ä‘á»ƒ há»c tá»‘t toÃ¡n cÃ²n cáº§n há»c nhiá»u thá»© ná»¯a ğŸ˜€. â€œDistribution is all You Needâ€ lÃ  má»™t hÆ°á»›ng dáº«n cÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t cÆ¡ báº£n vÃ  hay Ä‘Æ°á»£c dÃ¹ng nhiá»u nháº¥t cho nhá»¯ng ngÆ°á»i nghiÃªn cá»©u vá» Deep Learning.
áº¢nh Ä‘áº§u tiÃªn lÃ  overview vá» cÃ¡c phÃ¢n phá»‘i vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c phÃ¢n phá»‘i vá»›i nhau, cÃ¡c áº£nh sau lÃ  áº£nh minh há»a tá»«ng phÃ¢n phá»‘i).","[AI Share â€“ Distribution is all you need] Náº¿u nhÆ° trong Deep learning nÃ³i chung, hay NLP, CV nÃ³i riÃªng thÃ¬ â€œAttention is all you needâ€ . Váº­y trong toÃ¡n há»c thÃ¬ sao ? CÃ¢u tráº£ lá»i lÃ  â€œDistribution is all You Needâ€. Tháº­t ra cÃ¢u tráº£ lá»i chá»‰ nÃ³i lÃªn cÃ¡c phÃ¢n phá»‘i lÃ  má»™t pháº§n ráº¥t quan trá»ng vÃ  khÃ´ng thá»ƒ thiáº¿u trong toÃ¡n, chá»© Ä‘á»ƒ há»c tá»‘t toÃ¡n cÃ²n cáº§n há»c nhiá»u thá»© ná»¯a . â€œDistribution is all You Needâ€ lÃ  má»™t hÆ°á»›ng dáº«n cÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t cÆ¡ báº£n vÃ  hay Ä‘Æ°á»£c dÃ¹ng nhiá»u nháº¥t cho nhá»¯ng ngÆ°á»i nghiÃªn cá»©u vá» Deep Learning. áº¢nh Ä‘áº§u tiÃªn lÃ  overview vá» cÃ¡c phÃ¢n phá»‘i vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c phÃ¢n phá»‘i vá»›i nhau, cÃ¡c áº£nh sau lÃ  áº£nh minh há»a tá»«ng phÃ¢n phá»‘i).",,,,,
"Em chÃ o cÃ¡c anh áº¡, em hiá»‡n Ä‘ang lÃ m 1 bÃ i táº­p vá» code nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng, em cÅ©ng tham kháº£o trÃªn máº¡ng vÃ  copy cháº¯p vÃ¡ Ä‘á»§ kiá»ƒu vÃ  hÃ´m trÆ°á»›c code cháº¡y ngon cÃ¡c kiá»ƒu nhÆ°ng giá» sau 3 tuáº§n em vÃ o láº¡i thÃ¬ bá»—ng cÃ³ lá»—i nhÆ° nÃ y em tÃ¬m cáº£ ngÃ y nay trÃªn google mÃ  khÃ´ng cÃ³ cÃ¡ch giáº£i quyáº¿t, mÃ  háº¡n bÃ i táº­p tá»›i nÆ¡i rá»“i áº¡,
cÃ¡c anh cÃ¡c chÃº xem giÃºp em vá»›i áº¡, model train thÃ¬ cháº¡y ook rá»“i nay em lÃ m file test thÃ¬ tá»± nhiÃªn bá»‹ lá»—i tháº¿ nÃ y
file á»Ÿ Ä‘Ã¢y áº¡, cÃ¡c anh giÃºp em vá»›i áº¡ em cáº£m Æ¡n nhiá»u áº¡
Dáº¡ em xin lá»—i khÃ´ng trÃ¬nh bÃ y rÃµ rÃ ng, em lÃ  dáº«n há»c bÃªn oto Ä‘ang lÃ m nckh khÃ´ng pháº£i dÃ¢n dev nÃªn kiáº¿n thá»©c vá» cÃ¡i nÃ y khÃ¡ ngu ngÆ¡.
em cáº£m Æ¡n cÃ¡c anh Ä‘Ã£ gÃ³p Ã½ áº¡
https://drive.google.com/file/d/1RxNm5bK5RgEJuw2OMLJV8zwO0HTGjEQ4/view?usp=sharing","Em chÃ o cÃ¡c anh áº¡, em hiá»‡n Ä‘ang lÃ m 1 bÃ i táº­p vá» code nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng, em cÅ©ng tham kháº£o trÃªn máº¡ng vÃ  copy cháº¯p vÃ¡ Ä‘á»§ kiá»ƒu vÃ  hÃ´m trÆ°á»›c code cháº¡y ngon cÃ¡c kiá»ƒu nhÆ°ng giá» sau 3 tuáº§n em vÃ o láº¡i thÃ¬ bá»—ng cÃ³ lá»—i nhÆ° nÃ y em tÃ¬m cáº£ ngÃ y nay trÃªn google mÃ  khÃ´ng cÃ³ cÃ¡ch giáº£i quyáº¿t, mÃ  háº¡n bÃ i táº­p tá»›i nÆ¡i rá»“i áº¡, cÃ¡c anh cÃ¡c chÃº xem giÃºp em vá»›i áº¡, model train thÃ¬ cháº¡y ook rá»“i nay em lÃ m file test thÃ¬ tá»± nhiÃªn bá»‹ lá»—i tháº¿ nÃ y file á»Ÿ Ä‘Ã¢y áº¡, cÃ¡c anh giÃºp em vá»›i áº¡ em cáº£m Æ¡n nhiá»u áº¡ Dáº¡ em xin lá»—i khÃ´ng trÃ¬nh bÃ y rÃµ rÃ ng, em lÃ  dáº«n há»c bÃªn oto Ä‘ang lÃ m nckh khÃ´ng pháº£i dÃ¢n dev nÃªn kiáº¿n thá»©c vá» cÃ¡i nÃ y khÃ¡ ngu ngÆ¡. em cáº£m Æ¡n cÃ¡c anh Ä‘Ã£ gÃ³p Ã½ áº¡ https://drive.google.com/file/d/1RxNm5bK5RgEJuw2OMLJV8zwO0HTGjEQ4/view?usp=sharing",,,,,
"CHINH PHá»¤C Äá»ˆNH CAO Dá»® LIá»†U CÃ™NG DATA-CENTRIC AI COMPETITION   

Vá»›i tá»•ng giÃ¡ trá»‹ giáº£i thÆ°á»Ÿng lÃªn Ä‘áº¿n 500,000,000 VND - Data-Centric AI Competition lÃ  cuá»™c thi Ä‘áº§u tiÃªn táº¡i Viá»‡t Nam táº­p trung vÃ o viá»‡c xá»­ lÃ½ dá»¯ liá»‡u vÃ  láº¥y dá»¯ liá»‡u lÃ m trung tÃ¢m. 

ğŸ‘‰ÄÄƒng kÃ½ ngay: https://datacomp.io/ 
â° Thá»i gian Ä‘Äƒng kÃ½ vÃ  ná»™p dá»¯ liá»‡u: 15/10/2021 - 22/12/2021
 Má»™t cuá»™c thi hoÃ n toÃ n má»›i máº», mang tÃ­nh Ä‘á»™t phÃ¡t vÃ  khÃ¡c biá»‡t so vá»›i táº¥t cáº£ cÃ¡c cuá»™c thi model-centric trÆ°á»›c Ä‘Ã¢y, há»©a háº¹n sáº½ lÃ  sÃ¢n chÆ¡i Ä‘em Ä‘áº¿n nhá»¯ng tráº£i nghiá»‡m chÆ°a tá»«ng cÃ³ dÃ nh cho cÃ¡c thÃ­ sinh Ä‘am mÃª ngÃ nh Dá»¯ liá»‡u
Lá»‹ch trÃ¬nh cuá»™c thi: 
â° Thá»i gian cÃ´ng bá»‘ dá»¯ liá»‡u & mÃ£ nguá»“n: 22/10/2021
â° Cháº¥m Ä‘iá»ƒm: 23/12/2021 - 27/12/2021
â° Trao giáº£i: 29/12/2021
DATACOMP - JOIN TO TAKE AN AMBITION TO THE TOP
---------
ğŸŒWebsite: http://datacomp.io/ 
ğŸ¯Group cuá»™c thi: https://bit.ly/datacomp-group 
ğŸ“©Email: support.ailab@fsoft.com.vn 
#DataCentricAICompetition #Datacomp2021 #FPTSoftware #FSOFTAILab #iRender","CHINH PHá»¤C Äá»ˆNH CAO Dá»® LIá»†U CÃ™NG DATA-CENTRIC AI COMPETITION Vá»›i tá»•ng giÃ¡ trá»‹ giáº£i thÆ°á»Ÿng lÃªn Ä‘áº¿n 500,000,000 VND - Data-Centric AI Competition lÃ  cuá»™c thi Ä‘áº§u tiÃªn táº¡i Viá»‡t Nam táº­p trung vÃ o viá»‡c xá»­ lÃ½ dá»¯ liá»‡u vÃ  láº¥y dá»¯ liá»‡u lÃ m trung tÃ¢m. ÄÄƒng kÃ½ ngay: https://datacomp.io/ â° Thá»i gian Ä‘Äƒng kÃ½ vÃ  ná»™p dá»¯ liá»‡u: 15/10/2021 - 22/12/2021 Má»™t cuá»™c thi hoÃ n toÃ n má»›i máº», mang tÃ­nh Ä‘á»™t phÃ¡t vÃ  khÃ¡c biá»‡t so vá»›i táº¥t cáº£ cÃ¡c cuá»™c thi model-centric trÆ°á»›c Ä‘Ã¢y, há»©a háº¹n sáº½ lÃ  sÃ¢n chÆ¡i Ä‘em Ä‘áº¿n nhá»¯ng tráº£i nghiá»‡m chÆ°a tá»«ng cÃ³ dÃ nh cho cÃ¡c thÃ­ sinh Ä‘am mÃª ngÃ nh Dá»¯ liá»‡u Lá»‹ch trÃ¬nh cuá»™c thi: â° Thá»i gian cÃ´ng bá»‘ dá»¯ liá»‡u & mÃ£ nguá»“n: 22/10/2021 â° Cháº¥m Ä‘iá»ƒm: 23/12/2021 - 27/12/2021 â° Trao giáº£i: 29/12/2021 DATACOMP - JOIN TO TAKE AN AMBITION TO THE TOP --------- Website: http://datacomp.io/ Group cuá»™c thi: https://bit.ly/datacomp-group Email: support.ailab@fsoft.com.vn",#DataCentricAICompetition	#Datacomp2021	#FPTSoftware	#FSOFTAILab	#iRender,,,,
"CÃ¡c báº¡n cho mÃ¬nh há»i, cÃ³ ngÆ°á»i nÃ³ há»c pháº£i há»c theo lá»™ trÃ¬nh ML => AI => Deep Learning. VÃ  pháº£i tá»‘n cá»¡ 100 triá»‡u cho 1 sever. Nghe hoang mang quÃ¡. CÃ¡c báº¡n ai cÃ³ kinh nghiá»‡m chá»‰ mÃ¬nh vá»›i, MÃ¬nh Ä‘á»™i Æ¡n","CÃ¡c báº¡n cho mÃ¬nh há»i, cÃ³ ngÆ°á»i nÃ³ há»c pháº£i há»c theo lá»™ trÃ¬nh ML => AI => Deep Learning. VÃ  pháº£i tá»‘n cá»¡ 100 triá»‡u cho 1 sever. Nghe hoang mang quÃ¡. CÃ¡c báº¡n ai cÃ³ kinh nghiá»‡m chá»‰ mÃ¬nh vá»›i, MÃ¬nh Ä‘á»™i Æ¡n",,,,,
Em chÃ o cÃ¡c anh trong group. Em má»›i báº¯t Ä‘áº§u vá»›i ML áº¡. Em cÃ³ Ä‘á»c trong sÃ¡ch cá»§a anh VÅ© Há»¯u Tiá»‡p cÃ³ pháº§n Gradient cá»§a trace(AX) nhÆ° má»¥c 2.4.6 trong hÃ¬nh vÃ  tháº¥y tá»•ng chá»— 2.15 hÃ¬nh nhÆ° cÃ³ lá»—i nhá» theo em khai triá»ƒn ra thÃ¬ nÃ³ nhÆ° ct bÃªn pháº£i. KhÃ´ng biáº¿t do em biáº¿n Ä‘á»•i sai hay do sÃ¡ch bá»‹ Ä‘Ã¡nh nháº§m áº¡. Mong cÃ¡c anh xem giÃºp em.,Em chÃ o cÃ¡c anh trong group. Em má»›i báº¯t Ä‘áº§u vá»›i ML áº¡. Em cÃ³ Ä‘á»c trong sÃ¡ch cá»§a anh VÅ© Há»¯u Tiá»‡p cÃ³ pháº§n Gradient cá»§a trace(AX) nhÆ° má»¥c 2.4.6 trong hÃ¬nh vÃ  tháº¥y tá»•ng chá»— 2.15 hÃ¬nh nhÆ° cÃ³ lá»—i nhá» theo em khai triá»ƒn ra thÃ¬ nÃ³ nhÆ° ct bÃªn pháº£i. KhÃ´ng biáº¿t do em biáº¿n Ä‘á»•i sai hay do sÃ¡ch bá»‹ Ä‘Ã¡nh nháº§m áº¡. Mong cÃ¡c anh xem giÃºp em.,,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t tháº¯c máº¯c nhÆ° sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡.
Hiá»‡n táº¡i em Ä‘ang muá»‘n train má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i vá»›i loss function Ä‘Æ°á»£c define nhÆ° hÃ¬nh bÃªn dÆ°á»›i. Má»¥c tiÃªu lÃ  bÃªn cáº¡nh viá»‡c minimize Cross-Entropy function, em cÃ²n muá»‘n kiá»ƒm soÃ¡t sá»± thay Ä‘á»•i trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh. Cá»¥ thá»ƒ lÃ  khÃ´ng muá»‘n trá»ng sá»‘ Ä‘Æ°á»£c update táº¡i epoch hiá»‡n táº¡i thay Ä‘á»•i quÃ¡ nhiá»u so vá»›i trá»ng sá»‘ táº¡i epoch trÆ°á»›c Ä‘Ã³.
Em Ä‘ang máº¯c káº¹t á»Ÿ chá»• define L2-norm cá»§a ""w"" vÃ  ""w_t"" (chá»• khoanh Ä‘á») trong Tensorflow. Hi vá»ng Ä‘Æ°á»£c má»i ngÆ°á»i trong group giÃºp Ä‘á»¡. Em xin cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t tháº¯c máº¯c nhÆ° sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡. Hiá»‡n táº¡i em Ä‘ang muá»‘n train má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i vá»›i loss function Ä‘Æ°á»£c define nhÆ° hÃ¬nh bÃªn dÆ°á»›i. Má»¥c tiÃªu lÃ  bÃªn cáº¡nh viá»‡c minimize Cross-Entropy function, em cÃ²n muá»‘n kiá»ƒm soÃ¡t sá»± thay Ä‘á»•i trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh. Cá»¥ thá»ƒ lÃ  khÃ´ng muá»‘n trá»ng sá»‘ Ä‘Æ°á»£c update táº¡i epoch hiá»‡n táº¡i thay Ä‘á»•i quÃ¡ nhiá»u so vá»›i trá»ng sá»‘ táº¡i epoch trÆ°á»›c Ä‘Ã³. Em Ä‘ang máº¯c káº¹t á»Ÿ chá»• define L2-norm cá»§a ""w"" vÃ  ""w_t"" (chá»• khoanh Ä‘á») trong Tensorflow. Hi vá»ng Ä‘Æ°á»£c má»i ngÆ°á»i trong group giÃºp Ä‘á»¡. Em xin cáº£m Æ¡n áº¡.",,,,,
"[XÃ¡c Ä‘á»‹nh Ä‘iá»ƒm/Locating Seed Placements/Segmentation]
ChÃ o cÃ¡c báº¡n,
mÃ¬nh Ä‘ang lÃ m vá» Ä‘á» tÃ i tÃ¬m Ä‘iá»ƒm lÃªn máº§m cÃ¢y dá»±a vÃ o dá»¯ liá»‡u áº£nh. MÃ¬nh hi vá»ng lÃ  nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a cÃ¡c báº¡n. MÃ¬nh dÃ¹ng hÃ¬nh minh hoáº¡ dÆ°á»›i vÃ  trÃ¬nh bÃ y váº¥n Ä‘á» qua cÃ¡c Ä‘áº·c Ä‘iá»ƒm dÆ°á»›i Ä‘Ã¢y.
1. HÃ¬nh trong dá»¯ liá»‡u lÃ  hÃ¬nh Ä‘Æ°á»£c chá»¥p tá»« trÃªn xuá»‘ng (HÃ¬nh [1] chá»‰ lÃ  minh hoáº¡ vá» viá»‡c cÃ¢y máº§m, hÃ¬nh chá»¥p tá»« má»™t phÃ­a)
2. Má»¥c tiÃªu: tÃ­nh cÃ¡c Ä‘iá»ƒm máº§m cÃ¢y
3. Váº¥n Ä‘á» Ä‘ang gáº·p pháº£i (hÃ¬nh [2]): ngá»n lÃ¡ vÃ  pháº§n gá»‘c khÃ´ng Ä‘Æ°á»£c phÃ¢n biá»‡t vÃ o má»™t sá»‘ trÆ°á»ng há»£p. MÃ´ hÃ¬nh mÃ¡y há»c hiá»‡n táº¡i dá»± Ä‘oÃ¡n Ä‘iá»ƒm ""ngá»n lÃ¡"" cÅ©ng lÃ  má»™t Ä‘iá»ƒm máº§m cÃ¢y.
CÃ¡c báº¡n Ä‘Ã£ tá»«ng lÃ m Ä‘á» tÃ i tÆ°Æ¡ng tá»± cÃ³ thá»ƒ cho mÃ¬nh má»™t vÃ i tá»« khoÃ¡ Ä‘Æ°á»£c khÃ´ng áº¡? CÃ¡c báº¡n cÃ³ gá»£i Ã½ cho mÃ¬nh Ã½ tÆ°á»Ÿng lÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¢n biá»‡t tá»‘t hÆ¡n pháº§n ngá»n lÃ¡ vÃ  pháº§n gá»‘c (chá»— tháº­t sá»± lÃªn máº§m cÃ¢y)?
MÃ¬nh cáº£m Æ¡n cÃ¡c báº¡n ráº¥t nhiá»u! â˜˜","[XÃ¡c Ä‘á»‹nh Ä‘iá»ƒm/Locating Seed Placements/Segmentation] ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang lÃ m vá» Ä‘á» tÃ i tÃ¬m Ä‘iá»ƒm lÃªn máº§m cÃ¢y dá»±a vÃ o dá»¯ liá»‡u áº£nh. MÃ¬nh hi vá»ng lÃ  nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a cÃ¡c báº¡n. MÃ¬nh dÃ¹ng hÃ¬nh minh hoáº¡ dÆ°á»›i vÃ  trÃ¬nh bÃ y váº¥n Ä‘á» qua cÃ¡c Ä‘áº·c Ä‘iá»ƒm dÆ°á»›i Ä‘Ã¢y. 1. HÃ¬nh trong dá»¯ liá»‡u lÃ  hÃ¬nh Ä‘Æ°á»£c chá»¥p tá»« trÃªn xuá»‘ng (HÃ¬nh [1] chá»‰ lÃ  minh hoáº¡ vá» viá»‡c cÃ¢y máº§m, hÃ¬nh chá»¥p tá»« má»™t phÃ­a) 2. Má»¥c tiÃªu: tÃ­nh cÃ¡c Ä‘iá»ƒm máº§m cÃ¢y 3. Váº¥n Ä‘á» Ä‘ang gáº·p pháº£i (hÃ¬nh [2]): ngá»n lÃ¡ vÃ  pháº§n gá»‘c khÃ´ng Ä‘Æ°á»£c phÃ¢n biá»‡t vÃ o má»™t sá»‘ trÆ°á»ng há»£p. MÃ´ hÃ¬nh mÃ¡y há»c hiá»‡n táº¡i dá»± Ä‘oÃ¡n Ä‘iá»ƒm ""ngá»n lÃ¡"" cÅ©ng lÃ  má»™t Ä‘iá»ƒm máº§m cÃ¢y. CÃ¡c báº¡n Ä‘Ã£ tá»«ng lÃ m Ä‘á» tÃ i tÆ°Æ¡ng tá»± cÃ³ thá»ƒ cho mÃ¬nh má»™t vÃ i tá»« khoÃ¡ Ä‘Æ°á»£c khÃ´ng áº¡? CÃ¡c báº¡n cÃ³ gá»£i Ã½ cho mÃ¬nh Ã½ tÆ°á»Ÿng lÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¢n biá»‡t tá»‘t hÆ¡n pháº§n ngá»n lÃ¡ vÃ  pháº§n gá»‘c (chá»— tháº­t sá»± lÃªn máº§m cÃ¢y)? MÃ¬nh cáº£m Æ¡n cÃ¡c báº¡n ráº¥t nhiá»u!",,,,,
,nan,,,,,
"[AI News - State of AI Report 2021]
ChÃºng ta Ä‘Ã£ tháº¥y AI ngÃ y cÃ ng trá»Ÿ nÃªn quan trá»ng Ä‘á»ƒ táº¡o ra nhá»¯ng Ä‘á»™t phÃ¡ má»›i trong má»i thá»©. â€œState of AI Reportâ€ nÄƒm nay Ä‘Ã£ lÃ  nÄƒm thá»© 4, Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi Nathan Benaich vÃ  Ian Hogarth, phÃ¢n tÃ­ch nhá»¯ng diá»…n biáº¿n Ä‘Ã¡ng chÃº Ã½ nháº¥t trong AI, Ä‘áº·c biá»‡t lÃ  nhá»¯ng Ä‘á»™t phÃ¡ trong NLP, CV vÃ  Sinh há»c trong má»™t nÄƒm qua.
BÃ¡o cÃ¡o nÄƒm nay Ä‘áº·c biá»‡t xem xÃ©t sá»± ná»•i báº­t cá»§a Transformer tá»« lÄ©nh vá»±c NLP, CV, tháº­m chÃ­ cáº£ dá»± Ä‘oÃ¡n cáº¥u trÃºc protein trong Sinh há»c. BÃ¡o cÃ¡o cÅ©ng lÃ m sÃ¡ng tá» má»™t thá»i Ä‘iá»ƒm quan trá»ng trong lÄ©nh vá»±c sinh há»c, khi mÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n AI Ä‘áº§u tiÃªn Ä‘Ã£ Ä‘Æ°a sinh há»c Ä‘i nhÆ° vÅ© bÃ£o, cÃ³ tiá»m nÄƒng thay Ä‘á»•i trong khÃ¡m phÃ¡ thuá»‘c vÃ  chÄƒm sÃ³c sá»©c khá»e.","[AI News - State of AI Report 2021] ChÃºng ta Ä‘Ã£ tháº¥y AI ngÃ y cÃ ng trá»Ÿ nÃªn quan trá»ng Ä‘á»ƒ táº¡o ra nhá»¯ng Ä‘á»™t phÃ¡ má»›i trong má»i thá»©. â€œState of AI Reportâ€ nÄƒm nay Ä‘Ã£ lÃ  nÄƒm thá»© 4, Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi Nathan Benaich vÃ  Ian Hogarth, phÃ¢n tÃ­ch nhá»¯ng diá»…n biáº¿n Ä‘Ã¡ng chÃº Ã½ nháº¥t trong AI, Ä‘áº·c biá»‡t lÃ  nhá»¯ng Ä‘á»™t phÃ¡ trong NLP, CV vÃ  Sinh há»c trong má»™t nÄƒm qua. BÃ¡o cÃ¡o nÄƒm nay Ä‘áº·c biá»‡t xem xÃ©t sá»± ná»•i báº­t cá»§a Transformer tá»« lÄ©nh vá»±c NLP, CV, tháº­m chÃ­ cáº£ dá»± Ä‘oÃ¡n cáº¥u trÃºc protein trong Sinh há»c. BÃ¡o cÃ¡o cÅ©ng lÃ m sÃ¡ng tá» má»™t thá»i Ä‘iá»ƒm quan trá»ng trong lÄ©nh vá»±c sinh há»c, khi mÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n AI Ä‘áº§u tiÃªn Ä‘Ã£ Ä‘Æ°a sinh há»c Ä‘i nhÆ° vÅ© bÃ£o, cÃ³ tiá»m nÄƒng thay Ä‘á»•i trong khÃ¡m phÃ¡ thuá»‘c vÃ  chÄƒm sÃ³c sá»©c khá»e.",,,,,
Má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o triá»ƒn khai thuáº­t toÃ¡n Levenberg-Marquardt (LM) Ä‘á»ƒ training NN model báº±ng pytorch khÃ´ng áº¡ ? Em tháº¥y torch khÃ´ng cÃ³ há»— trá»£ optimizer nÃ y. Em xin cáº£m Æ¡n áº¡,Má»i ngÆ°á»i cho em há»i cÃ³ cÃ¡ch nÃ o triá»ƒn khai thuáº­t toÃ¡n Levenberg-Marquardt (LM) Ä‘á»ƒ training NN model báº±ng pytorch khÃ´ng áº¡ ? Em tháº¥y torch khÃ´ng cÃ³ há»— trá»£ optimizer nÃ y. Em xin cáº£m Æ¡n áº¡,,,,,
"Xin chÃ o má»i ngÆ°á»i, em lÃ  newbie tÃ¬m hiá»ƒu vá» ML, hiá»‡n táº¡i Ä‘ang há»c toÃ¡n ML trong cuá»‘n ML cÆ¡ báº£n pháº§n Gradient Decent cho hÃ m nhiá»u biáº¿n thÃ¬ em tháº¥y cÃ³ 2 váº¥n Ä‘á»:
* Táº¡i sao trong hÃ m myGD láº¡i cÃ³ grad ? Ã½ nghÄ©a cá»§a nÃ³ lÃ  gÃ¬ áº¡ ?
* Em Ä‘Ã£ copy láº¡i code trong sÃ¡ch nhÆ°ng káº¿t quáº£ hoÃ n toÃ n khÃ¡c so vá»›i trong sÃ¡ch vÃ  khÃ´ng Ä‘Ãºng.
Mong má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em hiá»ƒu rÃµ hÆ¡n vá» cÃ¡c váº¥n Ä‘á» nÃ y, em xin cáº£m Æ¡n áº¡ !","Xin chÃ o má»i ngÆ°á»i, em lÃ  newbie tÃ¬m hiá»ƒu vá» ML, hiá»‡n táº¡i Ä‘ang há»c toÃ¡n ML trong cuá»‘n ML cÆ¡ báº£n pháº§n Gradient Decent cho hÃ m nhiá»u biáº¿n thÃ¬ em tháº¥y cÃ³ 2 váº¥n Ä‘á»: * Táº¡i sao trong hÃ m myGD láº¡i cÃ³ grad ? Ã½ nghÄ©a cá»§a nÃ³ lÃ  gÃ¬ áº¡ ? * Em Ä‘Ã£ copy láº¡i code trong sÃ¡ch nhÆ°ng káº¿t quáº£ hoÃ n toÃ n khÃ¡c so vá»›i trong sÃ¡ch vÃ  khÃ´ng Ä‘Ãºng. Mong má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em hiá»ƒu rÃµ hÆ¡n vá» cÃ¡c váº¥n Ä‘á» nÃ y, em xin cáº£m Æ¡n áº¡ !",,,,,
"mn giÃºp e vá»›i áº¡, cÃ³ cÃ¡ch nÃ o cÃ³ thá»ƒ sá»­ dá»¥ng model resnet101 trÃªn keras 2.1.2 khÃ´ng áº¡. vÃ¬ version nÃ y em import nhÆ°ng khÃ´ng Ä‘Æ°á»£c. nÃ³ sáº½ bÃ¡o lá»—i module 'keras.applications' has no attribute ResNet101 . hoáº·c cÃ³ cÃ¡ch nÃ o cÃ³ thá»ƒ sá»­ dá»¥ng nÃ³ vs weight imagenet mÃ  khÃ´ng cáº§n pháº£i cÃ i láº¡i version khÃ´ng áº¡. em cáº£m Æ¡n mn","mn giÃºp e vá»›i áº¡, cÃ³ cÃ¡ch nÃ o cÃ³ thá»ƒ sá»­ dá»¥ng model resnet101 trÃªn keras 2.1.2 khÃ´ng áº¡. vÃ¬ version nÃ y em import nhÆ°ng khÃ´ng Ä‘Æ°á»£c. nÃ³ sáº½ bÃ¡o lá»—i module 'keras.applications' has no attribute ResNet101 . hoáº·c cÃ³ cÃ¡ch nÃ o cÃ³ thá»ƒ sá»­ dá»¥ng nÃ³ vs weight imagenet mÃ  khÃ´ng cáº§n pháº£i cÃ i láº¡i version khÃ´ng áº¡. em cáº£m Æ¡n mn",,,,,
ChÃ o cÃ¡c ac trong nhÃ³m.Em Ä‘ang lÃ m bÃ i vá» Nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng sá»­ dá»¥ng máº¡ng Neural Convolution CNN.Em cháº¡y 2 file Main vÃ  Test.File Main em cháº¡y thÃ nh cÃ´ng vÃ  lÆ°u dáº¡ng h5.cÃ²n file Test em bá»‹ lá»—i dÃ²ng 93 mong Ä‘Æ°á»£c ac trong nhÃ³m giÃºp Ä‘á»¡ áº¡,ChÃ o cÃ¡c ac trong nhÃ³m.Em Ä‘ang lÃ m bÃ i vá» Nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng sá»­ dá»¥ng máº¡ng Neural Convolution CNN.Em cháº¡y 2 file Main vÃ  Test.File Main em cháº¡y thÃ nh cÃ´ng vÃ  lÆ°u dáº¡ng h5.cÃ²n file Test em bá»‹ lá»—i dÃ²ng 93 mong Ä‘Æ°á»£c ac trong nhÃ³m giÃºp Ä‘á»¡ áº¡,,,,,
"Giáº£i trÃ­, thÆ° giÃ£n 1 chÃºt vá»›i Kaggle vÃ  Kagglers. Dá»¯ liá»‡u thu tháº­p vÃ o ngÃ y 4/10/2021 vá» top-100, top-1000 kagglers vÃ  phÃ¢n bá»‘ cÃ¡c top kagglers theo Quá»‘c gia (Viá»‡t Nam cÃ³ 6/100 vÃ  21/1000), náº¿u theo cÃ´ng ty thÃ¬ Zalo cÅ©ng gÃ³p vui vá»›i 2 ngÆ°á»i. ThÃº vá»‹ hÆ¡n ná»¯a lÃ  so vá»›i nÄƒm 2016, thÃ¬ sá»‘ ngÆ°á»i Viá»‡t tham gia Kaggle gia tÄƒng Ä‘Ã¡ng ká»ƒ vÃ  cÃ³ thÃ nh tÃ­ch tá»‘t. Tuy nhiÃªn, náº¿u so vá»›i cÃ¹ng thá»i gian ká»ƒ trÃªn, ta cÃ²n thua xa Nháº­t Báº£n! Hi vá»ng, trong thá»i gian tá»›i cÃ¡c DA/DE/DS á»Ÿ Viá»‡t Nam sáº½ cÃ³ tham gia tÃ­ch cá»±c hÆ¡n vÃ  cÃ³ thÃ nh tÃ­ch cao hÆ¡n ná»¯a. Dataset cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ Ä‘Ã¢y https://www.kaggle.com/hdsk38/comp-top-1000-data
Credit: https://www.kaggle.com/hdsk38/top-1000-users-in-2021-by-country-and-more","Giáº£i trÃ­, thÆ° giÃ£n 1 chÃºt vá»›i Kaggle vÃ  Kagglers. Dá»¯ liá»‡u thu tháº­p vÃ o ngÃ y 4/10/2021 vá» top-100, top-1000 kagglers vÃ  phÃ¢n bá»‘ cÃ¡c top kagglers theo Quá»‘c gia (Viá»‡t Nam cÃ³ 6/100 vÃ  21/1000), náº¿u theo cÃ´ng ty thÃ¬ Zalo cÅ©ng gÃ³p vui vá»›i 2 ngÆ°á»i. ThÃº vá»‹ hÆ¡n ná»¯a lÃ  so vá»›i nÄƒm 2016, thÃ¬ sá»‘ ngÆ°á»i Viá»‡t tham gia Kaggle gia tÄƒng Ä‘Ã¡ng ká»ƒ vÃ  cÃ³ thÃ nh tÃ­ch tá»‘t. Tuy nhiÃªn, náº¿u so vá»›i cÃ¹ng thá»i gian ká»ƒ trÃªn, ta cÃ²n thua xa Nháº­t Báº£n! Hi vá»ng, trong thá»i gian tá»›i cÃ¡c DA/DE/DS á»Ÿ Viá»‡t Nam sáº½ cÃ³ tham gia tÃ­ch cá»±c hÆ¡n vÃ  cÃ³ thÃ nh tÃ­ch cao hÆ¡n ná»¯a. Dataset cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ Ä‘Ã¢y https://www.kaggle.com/hdsk38/comp-top-1000-data Credit: https://www.kaggle.com/hdsk38/top-1000-users-in-2021-by-country-and-more",,,,,
"xin chÃ o mn, hiá»‡n táº¡i em cÃ³ 1 cÃ¢u há»i cÆ¡ báº£n mÃ  em khÃ´ng hiá»ƒu nÃªn muá»‘n há»i mn áº¡. NhÆ° mn cÃ³ thá»ƒ tháº¥y á»Ÿ hÃ¬nh dÆ°á»›i khi em apply convolution transpose cho tensor á»Ÿ side (batch, height, width, channels) vá»›i padding = same cho conv2dTranspose trong keras thÃ¬ height vÃ  width cá»§a image k Ä‘á»•i áº¡. Em muá»‘n há»i lÃ  lÃ m sao Ä‘á»ƒ padding tÆ°Æ¡ng tá»± nhÆ° váº­y cho torch tensor Ä‘á»ƒ khi forward qua layer conv2dTranspose cá»§a torch thÃ¬ height vÃ  width cá»§a tensor váº«n khÃ´ng Ä‘á»•i áº¡","xin chÃ o mn, hiá»‡n táº¡i em cÃ³ 1 cÃ¢u há»i cÆ¡ báº£n mÃ  em khÃ´ng hiá»ƒu nÃªn muá»‘n há»i mn áº¡. NhÆ° mn cÃ³ thá»ƒ tháº¥y á»Ÿ hÃ¬nh dÆ°á»›i khi em apply convolution transpose cho tensor á»Ÿ side (batch, height, width, channels) vá»›i padding = same cho conv2dTranspose trong keras thÃ¬ height vÃ  width cá»§a image k Ä‘á»•i áº¡. Em muá»‘n há»i lÃ  lÃ m sao Ä‘á»ƒ padding tÆ°Æ¡ng tá»± nhÆ° váº­y cho torch tensor Ä‘á»ƒ khi forward qua layer conv2dTranspose cá»§a torch thÃ¬ height vÃ  width cá»§a tensor váº«n khÃ´ng Ä‘á»•i áº¡",,,,,
Má»i ngÆ°á»i ai cÃ³ tÃ i liá»‡u gÃ¬ vá» build mÃ´ hÃ¬nh cho xG metrics trong tráº­n bÃ³ng Ä‘Ã¡ ko? MÃ¬nh chá»‰ web scrape Ä‘c stat Ä‘Ã£ cÃ³ sáºµn nhÆ° dÆ°á»›i Ä‘Ã¢y. K biáº¿t xG Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  predict nhÆ° tháº¿ nÃ o,Má»i ngÆ°á»i ai cÃ³ tÃ i liá»‡u gÃ¬ vá» build mÃ´ hÃ¬nh cho xG metrics trong tráº­n bÃ³ng Ä‘Ã¡ ko? MÃ¬nh chá»‰ web scrape Ä‘c stat Ä‘Ã£ cÃ³ sáºµn nhÆ° dÆ°á»›i Ä‘Ã¢y. K biáº¿t xG Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  predict nhÆ° tháº¿ nÃ o,,,,,
"Xin chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n Automatic License Plate Recognition (ALPR) cá»¥ thá»ƒ lÃ  mÃ´ hÃ¬nh WPOD-NET á»Ÿ bÃ i bÃ¡o License Plate Detection and Recognition in Unconstrained Scenarios(https://bit.ly/2X2Q6Fw). Em gáº·p khÃ³ khÄƒn vÃ  chÆ°a hiá»ƒu láº¯m vá» hÃ m loss cá»§a tÃ¡c giáº£ Ä‘Æ°a ra áº¡.
Theo em hiá»ƒu lÃ  hÃ m loss cá»§a tÃ¡c giáº£ Ä‘Æ°a ra bao gá»“m 2 pháº§n:
- Pháº§n thá»© nháº¥t lÃ  Ä‘á»ƒ tÃ­nh toÃ¡n Ä‘á»™ sai lá»‡ch giá»¯a 4 Ä‘iá»ƒm gÃ³c cá»§a biá»ƒn sá»‘ thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n thÃ¬ tÃ¡c giáº£ Ä‘Æ°a ra transformation(hÃ m T) Ä‘á»ƒ chuyá»ƒn Ä‘á»•i 4 Ä‘iá»ƒm q_i vá» 4 Ä‘iá»ƒm má»›i cÃ³ thá»ƒ so sÃ¡nh Ä‘Æ°á»£c vá»›i 4 Ä‘iá»ƒm thá»±c táº¿ Ä‘Ã£ Ä‘Æ°á»£c labeled vÃ  Ä‘á»ƒ phÃ¹ há»£p vá»›i Ä‘á»™ phÃ¢n giáº£i Ä‘áº§u ra cá»§a máº¡ng thÃ¬ 4 Ä‘iá»ƒm thá»±c táº¿ cÅ©ng Ä‘Æ°á»£c re-scaled láº¡i qua normalization function(hÃ m A).
- Pháº§n thá»© hai thÃ¬ em hiá»ƒu hÃ m nÃ y giáº£i quyáº¿t váº¥n Ä‘á» liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t cÃ³/khÃ´ng cÃ³ Ä‘á»‘i tÆ°á»£ng.
Em chá»‰ hiá»ƒu Ã½ tÆ°á»Ÿng chÃ­nh cá»§a tá»«ng hÃ m nhÆ°ng chÆ°a hiá»ƒu ká»¹ Ã½ nghÄ©a biá»ƒu thá»©c toÃ¡n vÃ  táº¡i sao tÃ¡c giáº£ cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c biá»ƒu thá»©c hÃ m nhÆ° váº­y. Anh chá»‹ nÃ o biáº¿t cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em hoáº·c cho em má»™t vÃ i keywords vÃ  tÃ i liá»‡u Ä‘á»ƒ em tÃ¬m hiá»ƒu thÃªm Ä‘Æ°á»£c khÃ´ng áº¡. Em cÅ©ng chá»‰ má»›i báº­p báº¹ bÆ°á»›c chÃ¢n vÃ o máº£ng nÃ y mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ :'(
Em cáº£m Æ¡n.",Xin chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n Automatic License Plate Recognition (ALPR) cá»¥ thá»ƒ lÃ  mÃ´ hÃ¬nh WPOD-NET á»Ÿ bÃ i bÃ¡o License Plate Detection and Recognition in Unconstrained Scenarios(https://bit.ly/2X2Q6Fw). Em gáº·p khÃ³ khÄƒn vÃ  chÆ°a hiá»ƒu láº¯m vá» hÃ m loss cá»§a tÃ¡c giáº£ Ä‘Æ°a ra áº¡. Theo em hiá»ƒu lÃ  hÃ m loss cá»§a tÃ¡c giáº£ Ä‘Æ°a ra bao gá»“m 2 pháº§n: - Pháº§n thá»© nháº¥t lÃ  Ä‘á»ƒ tÃ­nh toÃ¡n Ä‘á»™ sai lá»‡ch giá»¯a 4 Ä‘iá»ƒm gÃ³c cá»§a biá»ƒn sá»‘ thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n thÃ¬ tÃ¡c giáº£ Ä‘Æ°a ra transformation(hÃ m T) Ä‘á»ƒ chuyá»ƒn Ä‘á»•i 4 Ä‘iá»ƒm q_i vá» 4 Ä‘iá»ƒm má»›i cÃ³ thá»ƒ so sÃ¡nh Ä‘Æ°á»£c vá»›i 4 Ä‘iá»ƒm thá»±c táº¿ Ä‘Ã£ Ä‘Æ°á»£c labeled vÃ  Ä‘á»ƒ phÃ¹ há»£p vá»›i Ä‘á»™ phÃ¢n giáº£i Ä‘áº§u ra cá»§a máº¡ng thÃ¬ 4 Ä‘iá»ƒm thá»±c táº¿ cÅ©ng Ä‘Æ°á»£c re-scaled láº¡i qua normalization function(hÃ m A). - Pháº§n thá»© hai thÃ¬ em hiá»ƒu hÃ m nÃ y giáº£i quyáº¿t váº¥n Ä‘á» liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t cÃ³/khÃ´ng cÃ³ Ä‘á»‘i tÆ°á»£ng. Em chá»‰ hiá»ƒu Ã½ tÆ°á»Ÿng chÃ­nh cá»§a tá»«ng hÃ m nhÆ°ng chÆ°a hiá»ƒu ká»¹ Ã½ nghÄ©a biá»ƒu thá»©c toÃ¡n vÃ  táº¡i sao tÃ¡c giáº£ cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c biá»ƒu thá»©c hÃ m nhÆ° váº­y. Anh chá»‹ nÃ o biáº¿t cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em hoáº·c cho em má»™t vÃ i keywords vÃ  tÃ i liá»‡u Ä‘á»ƒ em tÃ¬m hiá»ƒu thÃªm Ä‘Æ°á»£c khÃ´ng áº¡. Em cÅ©ng chá»‰ má»›i báº­p báº¹ bÆ°á»›c chÃ¢n vÃ o máº£ng nÃ y mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ :'( Em cáº£m Æ¡n.,,,,,
e chÃ o mn. em lÃ  newbie vÃ  Ä‘ang tÃ¬m hiá»ƒu vá» truy xuáº¥t hÃ¬nh áº£nh. mn cho em há»i ai Ä‘Ã£ tá»«ng implement RMAC theo bÃ i bÃ¡o nÃ y https://arxiv.org/pdf/1511.05879.pdf vÃ  ra káº¿t quáº£ Ä‘á»™ chÃ­nh xÃ¡c gáº§n giá»‘ng vá»›i table 1 trong paper táº¡i L=3 chÆ°a áº¡. hoáº·c cÃ³ code nÃ o imlement cho ra káº¿t quáº£ gáº§n nhÆ° váº­y ko áº¡. vÃ¬ e dÃ¹ng cÃ¡c code source sáºµn test Ä‘á»u cho ra káº¿t quáº£ tháº¥p hÆ¡n ráº¥t nhiá»u (49% so vá»›i cÃ´ng bá»‘ 66%) . bacbone sá»­ dá»¥ng lÃ  vgg16 áº¡. em cáº£m Æ¡n áº¡.,e chÃ o mn. em lÃ  newbie vÃ  Ä‘ang tÃ¬m hiá»ƒu vá» truy xuáº¥t hÃ¬nh áº£nh. mn cho em há»i ai Ä‘Ã£ tá»«ng implement RMAC theo bÃ i bÃ¡o nÃ y https://arxiv.org/pdf/1511.05879.pdf vÃ  ra káº¿t quáº£ Ä‘á»™ chÃ­nh xÃ¡c gáº§n giá»‘ng vá»›i table 1 trong paper táº¡i L=3 chÆ°a áº¡. hoáº·c cÃ³ code nÃ o imlement cho ra káº¿t quáº£ gáº§n nhÆ° váº­y ko áº¡. vÃ¬ e dÃ¹ng cÃ¡c code source sáºµn test Ä‘á»u cho ra káº¿t quáº£ tháº¥p hÆ¡n ráº¥t nhiá»u (49% so vá»›i cÃ´ng bá»‘ 66%) . bacbone sá»­ dá»¥ng lÃ  vgg16 áº¡. em cáº£m Æ¡n áº¡.,,,,,
"[Matrix multiplication viewpoint]
Náº¿u báº¡n Ä‘Ã£ há»c qua toÃ¡n cao cáº¥p rá»“i thÃ¬ cháº¯c báº¡n khÃ´ng láº¡ gÃ¬ phÃ©p nhÃ¢n hai ma tráº­n vá»›i quy táº¯c: ""hÃ ng nhÃ¢n cá»™t"". Tuy nhiÃªn cÃ¡ch nhÃ¢n ma tráº­n nÃ y chá»‰ Ä‘á»ƒ tÃ­nh toÃ¡n thÃ´i, phÃ©p nhÃ¢n ma tráº­n cÃ²n cÃ³ nhiá»u cÃ¡ch nhÃ¬n khÃ¡c nhau vÃ  cÃ³ cÃ¡c á»©ng dá»¥ng khÃ¡c nhau. VÃ­ dá»¥: nhÃ¢n theo hÃ ng, theo cá»™t, hay cáº£ hÃ ng vÃ  cá»™t. Biáº¿t vÃ  hiá»ƒu cÃ¡c cÃ¡ch nhÃ¢n ma tráº­n khÃ¡c nhau giÃºp má»i ngÆ°á»i hiá»ƒu báº£n cháº¥t váº¥n Ä‘á» hÆ¡n.
1. NhÃ¢n dáº¡ng cá»™t: NÃ³ liÃªn quan hÃ ng loáº¡t cÃ¡c tÃ­nh cháº¥t vá» sau cá»§a ma tráº­n nhÆ° Ä‘á»™c láº­p tuyáº¿n tÃ­nh, rank,...
2. NhÃ¢n dáº¡ng hÃ ng: ChÃ­nh lÃ  biáº¿n Ä‘á»•i vá» dáº¡ng Gaussian elimination.
3. Dáº¡ng hÃ ng nhÃ¢n cá»™t: NhÆ° khi khai triá»ƒn Singular Value Decomposition (SVD) vÃ  tÃ­nh ma tráº­n xáº¥p xá»‰.","[Matrix multiplication viewpoint] Náº¿u báº¡n Ä‘Ã£ há»c qua toÃ¡n cao cáº¥p rá»“i thÃ¬ cháº¯c báº¡n khÃ´ng láº¡ gÃ¬ phÃ©p nhÃ¢n hai ma tráº­n vá»›i quy táº¯c: ""hÃ ng nhÃ¢n cá»™t"". Tuy nhiÃªn cÃ¡ch nhÃ¢n ma tráº­n nÃ y chá»‰ Ä‘á»ƒ tÃ­nh toÃ¡n thÃ´i, phÃ©p nhÃ¢n ma tráº­n cÃ²n cÃ³ nhiá»u cÃ¡ch nhÃ¬n khÃ¡c nhau vÃ  cÃ³ cÃ¡c á»©ng dá»¥ng khÃ¡c nhau. VÃ­ dá»¥: nhÃ¢n theo hÃ ng, theo cá»™t, hay cáº£ hÃ ng vÃ  cá»™t. Biáº¿t vÃ  hiá»ƒu cÃ¡c cÃ¡ch nhÃ¢n ma tráº­n khÃ¡c nhau giÃºp má»i ngÆ°á»i hiá»ƒu báº£n cháº¥t váº¥n Ä‘á» hÆ¡n. 1. NhÃ¢n dáº¡ng cá»™t: NÃ³ liÃªn quan hÃ ng loáº¡t cÃ¡c tÃ­nh cháº¥t vá» sau cá»§a ma tráº­n nhÆ° Ä‘á»™c láº­p tuyáº¿n tÃ­nh, rank,... 2. NhÃ¢n dáº¡ng hÃ ng: ChÃ­nh lÃ  biáº¿n Ä‘á»•i vá» dáº¡ng Gaussian elimination. 3. Dáº¡ng hÃ ng nhÃ¢n cá»™t: NhÆ° khi khai triá»ƒn Singular Value Decomposition (SVD) vÃ  tÃ­nh ma tráº­n xáº¥p xá»‰.",,,,,
"Xin chÃ o má»i ngÆ°á»i. Em cÃ³ 1 Ä‘oáº¡n code Ä‘Æ¡n giáº£n nhÆ° tháº¿ nÃ y ( trÃªn áº£nh ) , em cháº¡y test trÃªn 2 mÃ¡y
- mÃ¡y sá»‘ 1 : mÃ¡y ryzen 2600x ( 6 core 12 thread, xung 3.4ghz ) , há»‡ Ä‘iá»u hÃ nh ubuntu
-mÃ¡y sá»‘ 2 : mÃ¡y xeon dual 2678v3 ( 24 core 48 thread , xung 2.4ghz . há»‡ Ä‘iá»u hÃ nh window 10
Cáº£ 2 mÃ¡y Ä‘á»u cÃ i thÆ° viá»‡n qua pip vÃ  pytorch báº£n chá»‰ cpu
. Äoáº¡n code trÃªn ráº¥t Ä‘Æ¡n giáº£n ko lÃ m gÃ¬ phá»©c táº¡p nhÆ°ng khi cháº¡y trÃªn xe mÃ¡y xeon thÃ¬ ngá»‘n táº­n 33% cpu ( 33% cpu cá»§a all core tá»©c ngá»‘n táº­n 8 core cpu ) , trong khi cháº¡y mÃ¡y ryzen chá»‰ 1,2% cpu ( gáº§n nhÆ° khÃ´ng tá»‘n gÃ¬ ).
Khi em debug thÃ¬ tháº¥y dÃ²ng code img = img.float() lÃ  Ä‘oáº¡n code cháº¡y ngá»‘n cpu á»Ÿ con xeon kia.
NgoÃ i Ä‘oáº¡n code test á»Ÿ trÃªn thÃ¬ em cÃ²n compare giá»¯a time inference cá»§a 1 model cá»±c nhá», vÃ  cÅ©ng tÃ¬nh tráº¡ng trÃªn ( mÃ¡y ryzen ngá»“n cpu cá»±c Ã­t cÃ²n xeon cá»±c cao , cpu ngá»‘n gáº¥p vÃ i chá»¥c láº§n so vá»›i ryzen )
NÃªn em xin há»i má»i ngÆ°á»i cÃ³ pháº£i lÃ  pytorch ko tá»‘i Æ°u trÃªn mÃ¡y dual xeon hay bug hay gÃ¬ áº¡... ? vÃ  em xin cÃ¡ch kháº¯c phá»¥c áº¡ ?
Em xin cáº£m Æ¡n .","Xin chÃ o má»i ngÆ°á»i. Em cÃ³ 1 Ä‘oáº¡n code Ä‘Æ¡n giáº£n nhÆ° tháº¿ nÃ y ( trÃªn áº£nh ) , em cháº¡y test trÃªn 2 mÃ¡y - mÃ¡y sá»‘ 1 : mÃ¡y ryzen 2600x ( 6 core 12 thread, xung 3.4ghz ) , há»‡ Ä‘iá»u hÃ nh ubuntu -mÃ¡y sá»‘ 2 : mÃ¡y xeon dual 2678v3 ( 24 core 48 thread , xung 2.4ghz . há»‡ Ä‘iá»u hÃ nh window 10 Cáº£ 2 mÃ¡y Ä‘á»u cÃ i thÆ° viá»‡n qua pip vÃ  pytorch báº£n chá»‰ cpu . Äoáº¡n code trÃªn ráº¥t Ä‘Æ¡n giáº£n ko lÃ m gÃ¬ phá»©c táº¡p nhÆ°ng khi cháº¡y trÃªn xe mÃ¡y xeon thÃ¬ ngá»‘n táº­n 33% cpu ( 33% cpu cá»§a all core tá»©c ngá»‘n táº­n 8 core cpu ) , trong khi cháº¡y mÃ¡y ryzen chá»‰ 1,2% cpu ( gáº§n nhÆ° khÃ´ng tá»‘n gÃ¬ ). Khi em debug thÃ¬ tháº¥y dÃ²ng code img = img.float() lÃ  Ä‘oáº¡n code cháº¡y ngá»‘n cpu á»Ÿ con xeon kia. NgoÃ i Ä‘oáº¡n code test á»Ÿ trÃªn thÃ¬ em cÃ²n compare giá»¯a time inference cá»§a 1 model cá»±c nhá», vÃ  cÅ©ng tÃ¬nh tráº¡ng trÃªn ( mÃ¡y ryzen ngá»“n cpu cá»±c Ã­t cÃ²n xeon cá»±c cao , cpu ngá»‘n gáº¥p vÃ i chá»¥c láº§n so vá»›i ryzen ) NÃªn em xin há»i má»i ngÆ°á»i cÃ³ pháº£i lÃ  pytorch ko tá»‘i Æ°u trÃªn mÃ¡y dual xeon hay bug hay gÃ¬ áº¡... ? vÃ  em xin cÃ¡ch kháº¯c phá»¥c áº¡ ? Em xin cáº£m Æ¡n .",,,,,
"ChÃºng ta thÆ°á»ng train models vá»›i 32-bit optimization, hay mixed 16-bit vá»›i 32-bit optimization, hay cÃ²n gá»i lÃ  Half (mixed) precision (vá»›i cÃ¡c GPUs dÃ²ng 20XX trá»Ÿ lÃªn). Náº¿u dÃ¹ng Pytorch-lightning, mÃ¬nh biáº¿t cÃ³ thá»ƒ set Ä‘á»ƒ train chá»‰ vá»›i 16-bit mÃ  thÃ´i. Gáº§n Ä‘Ã¢y cÃ³ má»™t sá»‘ nghiÃªn cá»©u táº­p trung vÃ o train models vá»›i chá»‰ 8-bit (quantization) optimization mÃ  khÃ´ng lÃ m giáº£m prediction performance cá»§a cÃ¡c models. BÃªn cáº¡nh Ä‘Ã³, lá»£i Ã­ch cá»§a viá»‡c train models vá»›i giÃºp tiáº¿t kiá»‡m tÃ i nguyÃªn tÃ­nh toÃ¡n vÃ  cÃ³ thá»ƒ triá»ƒn khai cÃ¡c models trÃªn cÃ¡c thiáº¿t bá»‹ di Ä‘á»™ng. ÄÃ¢y lÃ  bÃ i bÃ¡o vá» chá»§ Ä‘á» nÃ y cÃ³ tÃªn ""8-BIT OPTIMIZERS VIA BLOCK-WISE QUANTIZATION"" táº¡i Ä‘Ã¢y https://arxiv.org/pdf/2110.02861.pdf. Há» cÅ©ng chia sáº½ source code vá»›i thÆ° viá»‡n cÃ³ tÃªn bitsandbytes táº¡i Ä‘Ã¢y https://github.com/facebookresearch/bitsandbytes","ChÃºng ta thÆ°á»ng train models vá»›i 32-bit optimization, hay mixed 16-bit vá»›i 32-bit optimization, hay cÃ²n gá»i lÃ  Half (mixed) precision (vá»›i cÃ¡c GPUs dÃ²ng 20XX trá»Ÿ lÃªn). Náº¿u dÃ¹ng Pytorch-lightning, mÃ¬nh biáº¿t cÃ³ thá»ƒ set Ä‘á»ƒ train chá»‰ vá»›i 16-bit mÃ  thÃ´i. Gáº§n Ä‘Ã¢y cÃ³ má»™t sá»‘ nghiÃªn cá»©u táº­p trung vÃ o train models vá»›i chá»‰ 8-bit (quantization) optimization mÃ  khÃ´ng lÃ m giáº£m prediction performance cá»§a cÃ¡c models. BÃªn cáº¡nh Ä‘Ã³, lá»£i Ã­ch cá»§a viá»‡c train models vá»›i giÃºp tiáº¿t kiá»‡m tÃ i nguyÃªn tÃ­nh toÃ¡n vÃ  cÃ³ thá»ƒ triá»ƒn khai cÃ¡c models trÃªn cÃ¡c thiáº¿t bá»‹ di Ä‘á»™ng. ÄÃ¢y lÃ  bÃ i bÃ¡o vá» chá»§ Ä‘á» nÃ y cÃ³ tÃªn ""8-BIT OPTIMIZERS VIA BLOCK-WISE QUANTIZATION"" táº¡i Ä‘Ã¢y https://arxiv.org/pdf/2110.02861.pdf. Há» cÅ©ng chia sáº½ source code vá»›i thÆ° viá»‡n cÃ³ tÃªn bitsandbytes táº¡i Ä‘Ã¢y https://github.com/facebookresearch/bitsandbytes",,,,,
"Trong formum, cÃ³ anh chá»‹ nÃ o cÃ³ kháº£ nÄƒng viáº¿t code máº¡nh Ä‘á»ƒ training (lÆ°u Ã½ lÃ  code má»›i, chá»© khÃ´ng pháº£i dáº¡ng bÃ i toÃ¡n chá»‰ cháº¡y thÆ° viá»‡n rá»“i ra káº¿t quáº£ training) khÃ´ng? Hiá»‡n mÃ¬nh Ä‘ang phÃ¡t triá»ƒn nhiá»u thuáº­t toÃ¡n má»›i vá» machine learning (thÃ´ng qua cÃ¡c ká»¹ thuáº­t sÃ¢u cá»§a giáº£i tÃ­ch tá»‘i Æ°u), nhÆ°ng mÃ¬nh láº¡i khÃ´ng code Ä‘Æ°á»£c do MÃ¬nh lÃ m toÃ¡n cÆ¡ báº£n, vÃ  khÃ´ng cÃ³ thá»i gian tÃ¬m hiá»ƒu láº­p trÃ¬nh. MÃ¬nh hy vá»ng cÃ¡c anh chá»‹ em cÃ³ kháº£ nÄƒng code máº¡nh máº½ tham gia há»£p tÃ¡c nghiÃªn cá»©u, publish paper in high level trong lÄ©nh vá»±c deep learning.","Trong formum, cÃ³ anh chá»‹ nÃ o cÃ³ kháº£ nÄƒng viáº¿t code máº¡nh Ä‘á»ƒ training (lÆ°u Ã½ lÃ  code má»›i, chá»© khÃ´ng pháº£i dáº¡ng bÃ i toÃ¡n chá»‰ cháº¡y thÆ° viá»‡n rá»“i ra káº¿t quáº£ training) khÃ´ng? Hiá»‡n mÃ¬nh Ä‘ang phÃ¡t triá»ƒn nhiá»u thuáº­t toÃ¡n má»›i vá» machine learning (thÃ´ng qua cÃ¡c ká»¹ thuáº­t sÃ¢u cá»§a giáº£i tÃ­ch tá»‘i Æ°u), nhÆ°ng mÃ¬nh láº¡i khÃ´ng code Ä‘Æ°á»£c do MÃ¬nh lÃ m toÃ¡n cÆ¡ báº£n, vÃ  khÃ´ng cÃ³ thá»i gian tÃ¬m hiá»ƒu láº­p trÃ¬nh. MÃ¬nh hy vá»ng cÃ¡c anh chá»‹ em cÃ³ kháº£ nÄƒng code máº¡nh máº½ tham gia há»£p tÃ¡c nghiÃªn cá»©u, publish paper in high level trong lÄ©nh vá»±c deep learning.",,,,,
"ChÃ o má»i ng, e má»›i báº¯t Ä‘áº§u lÃ m quen python vÃ  machine learning, Ä‘ang thá»±c hÃ nh vidu trÃªn blog cá»§a anh Tiá»‡p nhÆ°ng Ä‘áº¿n khÃºc nÃ y Ä‘ang bá»‹ vÆ°á»›ng, chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c, mong Ä‘Æ°á»£c má»i ng giÃºp Ä‘á»¡ áº¡
Em cáº£m Æ¡n nhiá»u áº¡","ChÃ o má»i ng, e má»›i báº¯t Ä‘áº§u lÃ m quen python vÃ  machine learning, Ä‘ang thá»±c hÃ nh vidu trÃªn blog cá»§a anh Tiá»‡p nhÆ°ng Ä‘áº¿n khÃºc nÃ y Ä‘ang bá»‹ vÆ°á»›ng, chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c, mong Ä‘Æ°á»£c má»i ng giÃºp Ä‘á»¡ áº¡ Em cáº£m Æ¡n nhiá»u áº¡",,,,,
"mn cho em há»i tÃ­ vá»›i áº¡
Em muá»‘n sampling cÃ¡i phÃ¢n khá»‘i dirichlet tá»« hÃ¬nh bÃªn dÆ°á»›i. Em cÃ³ sample tá»« gamma cá»§a numpy vá»›i size lÃ  (1000, 6) cho die (xÃºc xáº¯c). Sample Ä‘Æ°á»£c Vk rá»“i thÃ¬ tÃ­nh theta_k nhÆ° bÃªn dÆ°á»›i cÃ³ Ä‘Ãºng ko áº¡ vÃ¬ chá»— chia cho tá»•ng Ä‘Ã³ pháº£i lÃ  chia cho tá»•ng 1000 sá»‘ trong phÃ¢n khá»‘i chá»© nhá»‰ ?
Em cáº£m Æ¡n áº¡","mn cho em há»i tÃ­ vá»›i áº¡ Em muá»‘n sampling cÃ¡i phÃ¢n khá»‘i dirichlet tá»« hÃ¬nh bÃªn dÆ°á»›i. Em cÃ³ sample tá»« gamma cá»§a numpy vá»›i size lÃ  (1000, 6) cho die (xÃºc xáº¯c). Sample Ä‘Æ°á»£c Vk rá»“i thÃ¬ tÃ­nh theta_k nhÆ° bÃªn dÆ°á»›i cÃ³ Ä‘Ãºng ko áº¡ vÃ¬ chá»— chia cho tá»•ng Ä‘Ã³ pháº£i lÃ  chia cho tá»•ng 1000 sá»‘ trong phÃ¢n khá»‘i chá»© nhá»‰ ? Em cáº£m Æ¡n áº¡",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em Ä‘ang muá»‘n táº¡o mask (nhÆ° hÃ¬nh bÃªn dÆ°á»›i áº¡). Má»¥c Ä‘Ã­ch Ä‘á»ƒ táº¡o ra training data cho Unet model áº¡. áº¢nh bÃªn trÃ¡i lÃ  hÃ¬nh áº£nh gá»‘c vÃ  bÃªn pháº£i lÃ  mask cá»§a nÃ³ áº¡ , nhÆ°ng em chÆ°a biáº¿t táº¡o mask cá»§a hÃ¬nh áº£nh nhÆ° nÃ o. Anh chá»‹ nÃ o Ä‘Ã£ lÃ m gÃ¡n dÃ¡n nhÃ£n hÃ¬nh áº£nh hay táº¡o mask cho hÃ¬nh áº£nh kiá»ƒu giá»‘ng hÃ¬nh bÃªn dÆ°á»›i cÃ³ thá»ƒ cho sáº» cho em 1 sá»‘ kinh nghiá»‡m hoáº·c cÃ´ng cá»¥ Ä‘á»ƒ lÃ m Ä‘iá»u Ä‘Ã³ khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang muá»‘n táº¡o mask (nhÆ° hÃ¬nh bÃªn dÆ°á»›i áº¡). Má»¥c Ä‘Ã­ch Ä‘á»ƒ táº¡o ra training data cho Unet model áº¡. áº¢nh bÃªn trÃ¡i lÃ  hÃ¬nh áº£nh gá»‘c vÃ  bÃªn pháº£i lÃ  mask cá»§a nÃ³ áº¡ , nhÆ°ng em chÆ°a biáº¿t táº¡o mask cá»§a hÃ¬nh áº£nh nhÆ° nÃ o. Anh chá»‹ nÃ o Ä‘Ã£ lÃ m gÃ¡n dÃ¡n nhÃ£n hÃ¬nh áº£nh hay táº¡o mask cho hÃ¬nh áº£nh kiá»ƒu giá»‘ng hÃ¬nh bÃªn dÆ°á»›i cÃ³ thá»ƒ cho sáº» cho em 1 sá»‘ kinh nghiá»‡m hoáº·c cÃ´ng cá»¥ Ä‘á»ƒ lÃ m Ä‘iá»u Ä‘Ã³ khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"Vietnamese sentence embedding using PhoBERT & Sentence Transformers

Xin chÃ o cáº£ nhÃ ,
Em xin Ä‘Æ°á»£c chia sáº» vá»›i má»i ngÆ°á»i má»™t sáº£n pháº©m cá»§a nhÃ³m em lÃ m vá» sentence embeddings, theo phÆ°Æ¡ng phÃ¡p cá»§a paper nÃ y [1], sá»­ dá»¥ng pre-trained model PhoBERT [2].
PhÆ°Æ¡ng phÃ¡p sentence embeddings nÃ y cÃ³ tÃ­nh cháº¥t: (i) cÃ³ thá»ƒ dÃ¹ng cosine distance Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a cá»§a cÃ¡c cÃ¢u; Ã¡p dá»¥ng Ä‘á»ƒ phÃ¢n nhÃ³m cÃ¢u theo ngá»¯ nghÄ©a (semantic clustering), há»‡ thá»‘ng truy váº¥n thÃ´ng tin theo ngá»¯ nghÄ©a (information retrieval), ... (ii) cÃ³ thá»ƒ sá»­ dá»¥ng nhÆ° pre-trained trong transfer learning.

Source code vÃ  cháº¡y thá»­ trÃªn colab táº¡i [3], [4].

ChÃºc cáº£ nhÃ  má»™t ngÃ y tÆ°Æ¡i Ä‘áº¹p :D

[1]: https://www.aclweb.org/anthology/D19-1410.pdf
[2]: https://github.com/VinAIResearch/PhoBERT
[3]: https://github.com/Datami555/sentence-transformers
[4]: https://colab.research.google.com/drive/1IHIYxV7COaMr6GrfWWb-I4TwT706scYi?usp=sharing

https://www.youtube.com/watch?v=7d--8leiZgA
 â€” vá»›i Trua Nguyen.","Vietnamese sentence embedding using PhoBERT & Sentence Transformers Xin chÃ o cáº£ nhÃ , Em xin Ä‘Æ°á»£c chia sáº» vá»›i má»i ngÆ°á»i má»™t sáº£n pháº©m cá»§a nhÃ³m em lÃ m vá» sentence embeddings, theo phÆ°Æ¡ng phÃ¡p cá»§a paper nÃ y [1], sá»­ dá»¥ng pre-trained model PhoBERT [2]. PhÆ°Æ¡ng phÃ¡p sentence embeddings nÃ y cÃ³ tÃ­nh cháº¥t: (i) cÃ³ thá»ƒ dÃ¹ng cosine distance Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a cá»§a cÃ¡c cÃ¢u; Ã¡p dá»¥ng Ä‘á»ƒ phÃ¢n nhÃ³m cÃ¢u theo ngá»¯ nghÄ©a (semantic clustering), há»‡ thá»‘ng truy váº¥n thÃ´ng tin theo ngá»¯ nghÄ©a (information retrieval), ... (ii) cÃ³ thá»ƒ sá»­ dá»¥ng nhÆ° pre-trained trong transfer learning. Source code vÃ  cháº¡y thá»­ trÃªn colab táº¡i [3], [4]. ChÃºc cáº£ nhÃ  má»™t ngÃ y tÆ°Æ¡i Ä‘áº¹p :D [1]: https://www.aclweb.org/anthology/D19-1410.pdf [2]: https://github.com/VinAIResearch/PhoBERT [3]: https://github.com/Datami555/sentence-transformers [4]: https://colab.research.google.com/drive/1IHIYxV7COaMr6GrfWWb-I4TwT706scYi?usp=sharing https://www.youtube.com/watch?v=7d--8leiZgA â€” vá»›i Trua Nguyen.",,,,,
"Hello má»i ngÆ°á»i,
CÃ³ bÃ¡c nÃ o Ä‘Ã£ lÃ m vá»›i tÃ³m táº¯t Ä‘a vÄƒn báº£n chÆ°a áº¡, kiá»ƒu nhÆ°: cÃ³ 5 bÃ i viáº¿t khÃ¡c nhau cÃ¹ng má»™t chá»§ Ä‘á». Minh sáº½ táº¡o ra 1 Ä‘oáº¡n vÄƒn báº£n tá»•ng há»£p Ã½ cá»§a 5 vÄƒn báº£n trÃªn áº¡. E cÃ³ Ä‘á»c Ä‘Æ°á»£c tÃ i liá»‡u dÆ°á»›i Ä‘Ã¢y
Thank ace","Hello má»i ngÆ°á»i, CÃ³ bÃ¡c nÃ o Ä‘Ã£ lÃ m vá»›i tÃ³m táº¯t Ä‘a vÄƒn báº£n chÆ°a áº¡, kiá»ƒu nhÆ°: cÃ³ 5 bÃ i viáº¿t khÃ¡c nhau cÃ¹ng má»™t chá»§ Ä‘á». Minh sáº½ táº¡o ra 1 Ä‘oáº¡n vÄƒn báº£n tá»•ng há»£p Ã½ cá»§a 5 vÄƒn báº£n trÃªn áº¡. E cÃ³ Ä‘á»c Ä‘Æ°á»£c tÃ i liá»‡u dÆ°á»›i Ä‘Ã¢y Thank ace",,,,,
"Em chÃ o má»i ngÆ°á»i, em má»›i Ä‘Äƒng kÃ½ colab pro 1 thÃ¡ng 10$ thá»­, em tháº¥y má»™t sá»‘ Ä‘iá»ƒm nhÆ° sau mÃ  em muá»‘n há»i má»i ngÆ°á»i chÃºt áº¡, vÃ  anh chá»‹ em nÃ o dÃ¹ng colab pro+ cÅ©ng cho em há»i thÃªm áº¡, náº¿u Ä‘Ã¡ng tiá»n thÃ¬ em cÅ©ng muá»‘n bá» tiá»n ra thá»­ nghiá»‡m cho mÃ´ hÃ¬nh em Ä‘ang quan tÃ¢m áº¡.
1. Em tháº¥y ráº±ng hÃ¬nh nhÆ° colab pro khÃ´ng cho phÃ©p cháº¡y cÃ¹ng lÃºc 2 phiÃªn sá»­ dá»¥ng GPU, khÃ´ng rÃµ lÃ  colab pro+ cÃ³ cho phÃ©p Ä‘iá»u Ä‘Ã³ khÃ´ng áº¡?
2. Em Ä‘ang train vá»›i batch_size = 256, vÃ  50 epochs, 5 fold cross validation thÃ¬ Ä‘Ã£ máº¥t khoáº£ng hÆ¡n 6 tiáº¿ng, mÃ  em muá»‘n cÃ³ thá»ƒ nhanh hÆ¡n (vÃ¬ em cáº§n khoáº£ng Ä‘áº¿n 15 láº§n cháº¡y nhÆ° váº­y) thÃ¬ khÃ´ng rÃµ colab pro+ cÃ³ thá»±c sá»± Ä‘Ã¡ng hÆ¡n khÃ´ng, hiá»‡n táº¡i phiÃªn mÃ  em train á»Ÿ phÃ­a trÃªn trÃªn colab pro em Ä‘ang connect tá»›i dÃ¹ng GPU P100, mÃ  em Ä‘á»c Ä‘Æ°á»£c lÃ  colab pro+ dÃ¹ng V100 tháº­m chÃ­ A100 khÃ´ng rÃµ Ä‘Ãºng hay khÃ´ng vÃ  tá»‘c Ä‘á»™ cÃ³ nhanh hÆ¡n háº³n khÃ´ng?
3. Em cÅ©ng gáº·p trá»¥c tráº·c vá»›i chuyá»‡n disconnect phiÃªn colab, em Ä‘Ã£ thá»­ dÃ¹ng JavaScript Ä‘á»ƒ cháº¡y Ä‘oáº¡n code trÃªn console Ä‘á»ƒ liÃªn tá»¥c báº¥m vÃ o vá»‹ trÃ­ nÃºt connect. Em cÃ³ thá»­ nghiá»‡m, táº¯t cá»­a sá»• Ä‘Ã³ Ä‘i, hoáº·c táº¯t trÃ¬nh duyá»‡t Ä‘i, má»Ÿ ra thÃ¬ nÃ³ váº«n Ä‘ang train (nhÆ° váº­y cÃ³ tÃ­nh lÃ  cháº¡y trong ná»n khÃ´ng?), nhÆ°ng tá»‘i qua khi gáº­p mÃ¡y Ä‘i ngá»§ thÃ¬ cÃ³ váº» nÃ³ Ä‘Ã£ dá»«ng láº¡i, thá»i gian em Æ°á»›c lÆ°á»£ng tá»« khi báº¯t Ä‘áº§u train Ä‘áº¿n khi dá»«ng láº¡i khoáº£ng hÆ¡n 6 tiáº¿ng. Em khÃ´ng rÃµ lÃ  colab pro+ cÃ³ cháº¿ Ä‘á»™ cháº¡y trong ná»n thÃ¬ cÃ³ cáº§n thiáº¿t hay khÃ´ng náº¿u nhÆ° em táº¯t trÃ¬nh duyá»‡t hay táº¯t mÃ¡y Ä‘i, liá»‡u nÃ³ váº«n tiáº¿p tá»¥c cháº¡y?
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c, Ä‘Ã¢y lÃ  3 cÃ¢u há»i khÃ¡ dÃ i. Em má»›i lÃ m nÃªn nhiá»u bá»¡ ngá»¡, cÅ©ng Ä‘Ã£ tra cá»©u, giá» em muá»‘n tham kháº£o Ã½ kiáº¿n má»i ngÆ°á»i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.","Em chÃ o má»i ngÆ°á»i, em má»›i Ä‘Äƒng kÃ½ colab pro 1 thÃ¡ng 10$ thá»­, em tháº¥y má»™t sá»‘ Ä‘iá»ƒm nhÆ° sau mÃ  em muá»‘n há»i má»i ngÆ°á»i chÃºt áº¡, vÃ  anh chá»‹ em nÃ o dÃ¹ng colab pro+ cÅ©ng cho em há»i thÃªm áº¡, náº¿u Ä‘Ã¡ng tiá»n thÃ¬ em cÅ©ng muá»‘n bá» tiá»n ra thá»­ nghiá»‡m cho mÃ´ hÃ¬nh em Ä‘ang quan tÃ¢m áº¡. 1. Em tháº¥y ráº±ng hÃ¬nh nhÆ° colab pro khÃ´ng cho phÃ©p cháº¡y cÃ¹ng lÃºc 2 phiÃªn sá»­ dá»¥ng GPU, khÃ´ng rÃµ lÃ  colab pro+ cÃ³ cho phÃ©p Ä‘iá»u Ä‘Ã³ khÃ´ng áº¡? 2. Em Ä‘ang train vá»›i batch_size = 256, vÃ  50 epochs, 5 fold cross validation thÃ¬ Ä‘Ã£ máº¥t khoáº£ng hÆ¡n 6 tiáº¿ng, mÃ  em muá»‘n cÃ³ thá»ƒ nhanh hÆ¡n (vÃ¬ em cáº§n khoáº£ng Ä‘áº¿n 15 láº§n cháº¡y nhÆ° váº­y) thÃ¬ khÃ´ng rÃµ colab pro+ cÃ³ thá»±c sá»± Ä‘Ã¡ng hÆ¡n khÃ´ng, hiá»‡n táº¡i phiÃªn mÃ  em train á»Ÿ phÃ­a trÃªn trÃªn colab pro em Ä‘ang connect tá»›i dÃ¹ng GPU P100, mÃ  em Ä‘á»c Ä‘Æ°á»£c lÃ  colab pro+ dÃ¹ng V100 tháº­m chÃ­ A100 khÃ´ng rÃµ Ä‘Ãºng hay khÃ´ng vÃ  tá»‘c Ä‘á»™ cÃ³ nhanh hÆ¡n háº³n khÃ´ng? 3. Em cÅ©ng gáº·p trá»¥c tráº·c vá»›i chuyá»‡n disconnect phiÃªn colab, em Ä‘Ã£ thá»­ dÃ¹ng JavaScript Ä‘á»ƒ cháº¡y Ä‘oáº¡n code trÃªn console Ä‘á»ƒ liÃªn tá»¥c báº¥m vÃ o vá»‹ trÃ­ nÃºt connect. Em cÃ³ thá»­ nghiá»‡m, táº¯t cá»­a sá»• Ä‘Ã³ Ä‘i, hoáº·c táº¯t trÃ¬nh duyá»‡t Ä‘i, má»Ÿ ra thÃ¬ nÃ³ váº«n Ä‘ang train (nhÆ° váº­y cÃ³ tÃ­nh lÃ  cháº¡y trong ná»n khÃ´ng?), nhÆ°ng tá»‘i qua khi gáº­p mÃ¡y Ä‘i ngá»§ thÃ¬ cÃ³ váº» nÃ³ Ä‘Ã£ dá»«ng láº¡i, thá»i gian em Æ°á»›c lÆ°á»£ng tá»« khi báº¯t Ä‘áº§u train Ä‘áº¿n khi dá»«ng láº¡i khoáº£ng hÆ¡n 6 tiáº¿ng. Em khÃ´ng rÃµ lÃ  colab pro+ cÃ³ cháº¿ Ä‘á»™ cháº¡y trong ná»n thÃ¬ cÃ³ cáº§n thiáº¿t hay khÃ´ng náº¿u nhÆ° em táº¯t trÃ¬nh duyá»‡t hay táº¯t mÃ¡y Ä‘i, liá»‡u nÃ³ váº«n tiáº¿p tá»¥c cháº¡y? Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c, Ä‘Ã¢y lÃ  3 cÃ¢u há»i khÃ¡ dÃ i. Em má»›i lÃ m nÃªn nhiá»u bá»¡ ngá»¡, cÅ©ng Ä‘Ã£ tra cá»©u, giá» em muá»‘n tham kháº£o Ã½ kiáº¿n má»i ngÆ°á»i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.",,,,,
"KÃ­nh chÃ o cáº£ nhÃ . Em Ä‘ang há»c Ä‘áº¿n pháº§n gÃ¡n nhÃ£n dá»¯ liá»‡u nÃªn máº¡nh dáº¡n lÃ m bÃ i chia sáº». Hi vá»ng bÃ i viáº¿t sáº½ giÃºp Ä‘Æ°á»£c nhá»¯ng bÆ°á»›c cÆ¡ báº£n nháº¥t cho cÃ¡c báº¡n má»›i há»c.
Mong admin duyá»‡t bÃ i!",KÃ­nh chÃ o cáº£ nhÃ . Em Ä‘ang há»c Ä‘áº¿n pháº§n gÃ¡n nhÃ£n dá»¯ liá»‡u nÃªn máº¡nh dáº¡n lÃ m bÃ i chia sáº». Hi vá»ng bÃ i viáº¿t sáº½ giÃºp Ä‘Æ°á»£c nhá»¯ng bÆ°á»›c cÆ¡ báº£n nháº¥t cho cÃ¡c báº¡n má»›i há»c. Mong admin duyá»‡t bÃ i!,,,,,
"#pytorch, Má»i ngÆ°á»i cho em há»i lÃ  táº¡i sao khi em dÃ¹ng torch.nn.Sequential Ä‘á»ƒ táº¡o custom layers thÃ¬ khi mÃ¬nh forward nÃ³ láº¡i lá»—i áº¡ : do hiá»‡n khi em táº¡o láº¡i block code tÆ°Æ¡ng tá»± bÃªn ngoÃ i váº«n dÃ¹ng attribute forward Ä‘Æ°á»£c áº¡",Má»i ngÆ°á»i cho em há»i lÃ  táº¡i sao khi em dÃ¹ng torch.nn.Sequential Ä‘á»ƒ táº¡o custom layers thÃ¬ khi mÃ¬nh forward nÃ³ láº¡i lá»—i áº¡ : do hiá»‡n khi em táº¡o láº¡i block code tÆ°Æ¡ng tá»± bÃªn ngoÃ i váº«n dÃ¹ng attribute forward Ä‘Æ°á»£c áº¡,"#pytorch,",,,,
"#imagemorphing
Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang pháº£i tá»± nghiÃªn cá»©u vÃ  lÃ m viá»‡c vá»›i image morphing algorithms nÃªn tháº¥y khÃ¡ mÃ´ng lung. CÃ³ anh chá»‹ vÃ  cÃ¡c báº¡n lÃ m vá» pháº©n nÃ y khÃ´ng áº¡, cho e xin contact Ä‘á»ƒ em há»c táº­p vá»›i áº¡.
Em cáº£m Æ¡n áº¡ ^^","Em chÃ o má»i ngÆ°á»i áº¡, em Ä‘ang pháº£i tá»± nghiÃªn cá»©u vÃ  lÃ m viá»‡c vá»›i image morphing algorithms nÃªn tháº¥y khÃ¡ mÃ´ng lung. CÃ³ anh chá»‹ vÃ  cÃ¡c báº¡n lÃ m vá» pháº©n nÃ y khÃ´ng áº¡, cho e xin contact Ä‘á»ƒ em há»c táº­p vá»›i áº¡. Em cáº£m Æ¡n áº¡ ^^",#imagemorphing,,,,
"[Há»i vá» Topic Modelling]
MoÌ£i ngÆ°Æ¡Ì€i cho miÌ€nh hoÌ‰i laÌ€ nÃªn sÆ°Ì‰ duÌ£ng LDA model biÌ€nh thÆ°Æ¡Ì€ng hay laÌ€ LDA Mallet, viÌ€ miÌ€nh Ä‘oÌ£c nhiÃªÌ€u tutorial Ä‘ÃªÌ€u noÌi laÌ€ LDA Mallet cho hiÃªÌ£u quaÌ‰ tÃ´Ìt hÆ¡n.
BaÌ€i toaÌn cuÌ‰a miÌ€nh laÌ€ Content-based Recommendation vaÌ€ thÆ° viÃªÌ£n sÆ°Ì‰ duÌ£ng laÌ€ Gensim","[Há»i vá» Topic Modelling] MoÌ£i ngÆ°Æ¡Ì€i cho miÌ€nh hoÌ‰i laÌ€ nÃªn sÆ°Ì‰ duÌ£ng LDA model biÌ€nh thÆ°Æ¡Ì€ng hay laÌ€ LDA Mallet, viÌ€ miÌ€nh Ä‘oÌ£c nhiÃªÌ€u tutorial Ä‘ÃªÌ€u noÌi laÌ€ LDA Mallet cho hiÃªÌ£u quaÌ‰ tÃ´Ìt hÆ¡n. BaÌ€i toaÌn cuÌ‰a miÌ€nh laÌ€ Content-based Recommendation vaÌ€ thÆ° viÃªÌ£n sÆ°Ì‰ duÌ£ng laÌ€ Gensim",,,,,
"Há»i vá» features extraction trong CNN
Má»i ngÆ°á»i cho em há»i chÃºt, trong CNN, lá»›p classification layer cuá»‘i cÃ¹ng, mÃ¬nh cÃ³ cáº§n pháº£i Ä‘á»‹nh nghÄ©a rÃµ rÃ ng cho cÃ¡c class Ä‘á»ƒ cÃ¡c filter cÃ³ thá»ƒ Ä‘Æ°á»£c cáº­p nháº­t, hay lá»›p classification chá»‰ nháº±m má»¥c Ä‘Ã­ch táº¡o task cho CNN, cÃ²n pháº§n filter sáº½ Ä‘Æ°á»£c cáº­p nháº­t dá»±a theo dá»¯ liá»‡u Ä‘áº§u vÃ o?
á»Ÿ trong notebook nÃ y
https://www.kaggle.com/eryash15/handwritten-signature-feature-extraction/notebook
em tháº¥y Ä‘áº§u vÃ o Ä‘á»‹nh nghÄ©a cho dá»¯ liá»‡u chá»¯ chá»‰ gá»“m 2 nhÃ£n 1 vÃ  0, cho toÃ n bá»™ chá»¯ kÃ½ giáº£ vÃ  tháº­t, nhÆ°ng theo em hiá»ƒu thÃ¬ nhÃ£n 0 sáº½ á»©ng vá»›i chá»¯ kÃ½ tháº­t, 1 lÃ  giáº£, thÃ¬ toÃ n bá»™ cÃ¡c nhÃ£n cho chá»¯ kÃ½ cá»§a user 1 sáº½ lÃ  0 vÃ  táº¥t cáº£ user cÃ²n láº¡i + chá»¯ kÃ½ giáº£ sáº½ lÃ  1
Em cáº£m Æ¡n","Há»i vá» features extraction trong CNN Má»i ngÆ°á»i cho em há»i chÃºt, trong CNN, lá»›p classification layer cuá»‘i cÃ¹ng, mÃ¬nh cÃ³ cáº§n pháº£i Ä‘á»‹nh nghÄ©a rÃµ rÃ ng cho cÃ¡c class Ä‘á»ƒ cÃ¡c filter cÃ³ thá»ƒ Ä‘Æ°á»£c cáº­p nháº­t, hay lá»›p classification chá»‰ nháº±m má»¥c Ä‘Ã­ch táº¡o task cho CNN, cÃ²n pháº§n filter sáº½ Ä‘Æ°á»£c cáº­p nháº­t dá»±a theo dá»¯ liá»‡u Ä‘áº§u vÃ o? á»Ÿ trong notebook nÃ y https://www.kaggle.com/eryash15/handwritten-signature-feature-extraction/notebook em tháº¥y Ä‘áº§u vÃ o Ä‘á»‹nh nghÄ©a cho dá»¯ liá»‡u chá»¯ chá»‰ gá»“m 2 nhÃ£n 1 vÃ  0, cho toÃ n bá»™ chá»¯ kÃ½ giáº£ vÃ  tháº­t, nhÆ°ng theo em hiá»ƒu thÃ¬ nhÃ£n 0 sáº½ á»©ng vá»›i chá»¯ kÃ½ tháº­t, 1 lÃ  giáº£, thÃ¬ toÃ n bá»™ cÃ¡c nhÃ£n cho chá»¯ kÃ½ cá»§a user 1 sáº½ lÃ  0 vÃ  táº¥t cáº£ user cÃ²n láº¡i + chá»¯ kÃ½ giáº£ sáº½ lÃ  1 Em cáº£m Æ¡n",,,,,
"[ GÃ³c xin trá»£ giÃºp ] Em xin chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n áº¡
Hiá»‡n táº¡i em Ä‘ang nháº­p mÃ´n lÃ m Ä‘á» tÃ i liÃªn quan tá»›i Machine learning ""Sá»­ dá»¥ng camera vision check lá»—i á»Ÿ mÃ n hÃ¬nh Ä‘iá»‡n thoáº¡i( scratch- lá»—i xÆ°á»›c , alien - lá»—i dá»‹ váº­t , Bubble - lá»—i bÃ³ng khÃ­ bá» máº·t ) "" tuy nhiÃªn hiá»‡n táº¡i tÃ i liá»‡u data áº£nh á»Ÿ 3 lá»—i trÃªn em tÃ¬m hiá»ƒu váº«n khÃ´ng cÃ³ nhiá»u dá»¯ liá»‡u áº£nh. Mong a chá»‹ nÃ o cÃ³ :
1.Data áº£nh nhá»¯ng lá»—i trÃªn, thÃ¬ cho em xin tham kháº£o Ä‘á»ƒ em train áº£nh vá»›i ;((((
2 Cá»™ng vá»›i hÆ°á»›ng check tá»«ng lá»—i vá»›i áº¡ . HÆ°á»›ng em Ä‘Æ°a ra cÃ²n mÃ´ng lung quÃ¡ .
Em Ä‘ang suy nghÄ© hÆ°á»›ng nÃ y :
Chá»¥p áº£nh sample khÃ´ng cÃ³ dá»‹ váº­t/ bá»t khÃ­/ xÆ°á»›c tiá»n xá»­ lÃ½ áº£nh gá»‘c
CÃ¡c ná»™i dung tiá»n xá»­ lÃ½ bao gá»“m:
- Chuyá»ƒn Ä‘á»•i áº£nh thÃ nh áº£nh xÃ¡m( áº£nh chá»¥p bá»Ÿi camera Basler lÃ  áº£nh xÃ¡m)
- Tiáº¿n hÃ nh lá»c nhiá»…u cÃ¡c Ä‘áº·c tÃ­nh cá»§a hÃ¬nh áº£nh sá»­ dá»¥ng bá»™ lá»c Median( lá»c muá»‘i tiÃªu), Gaussian( lá»c cÃ¡c nhiá»…u nhiá»u hÃ¬nh dáº¡ng)
- ÄÄƒng kÃ½ ngoáº¡i lá»‡ cÃ¡c tá»a Ä‘á»™ lá»— chÃ¢n khÃ´ng, váº¿t xÆ°á»›c cá»‘ Ä‘á»‹nh báº±ng thuáº­t toÃ¡n tÃ¬m biÃªn Canny
BÆ°á»›c 2: ÄÄƒng kÃ½ ngoáº¡i lá»‡ cho cÃ¡c Ä‘áº·c tÃ­nh hÃ¬nh áº£nh sáºµn cÃ³.
BÆ°á»›c 3: Chá»¥p hÃ¬nh áº£nh live, tiá»n xá»­ lÃ½ áº£nhâ€¦
Sau khi chá»¥p áº£nh live viá»‡c Ä‘áº§u tiÃªn ta cáº§n lÃ  pháº£i tiá»n xá»­ lÃ½ áº£nh live tÆ°Æ¡ng tá»± nhÆ° áº£nh gá»‘c:
- Chuyá»ƒn Ä‘á»•i áº£nh thÃ nh áº£nh xÃ¡m
- Tiáº¿n hÃ nh lá»c nhiá»…u, lá»c biÃªn cÃ¡c Ä‘áº·c tÃ­nh cá»§a hÃ¬nh áº£nh sá»­ dá»¥ng bá»™ lá»c Median
- ÄÄƒng kÃ½ ngoáº¡i lá»‡ cÃ¡c tá»a Ä‘á»™ lá»— chÃ¢n khÃ´ng, váº¿t xÆ°á»›c cá»‘ Ä‘á»‹nh báº±ng thuáº­t toÃ¡n tÃ¬m biÃªn Candy
Sau Ä‘Ã³ ta cáº§n, xÃ¡c nháº­n láº¡i vÃ¹ng ROI( read of image) cá»§a áº£nh live do trong quÃ¡ trÃ¬nh chá»¥p thÃ¬ áº£nh bá»‹ xoay má»™t gÃ³c ráº¥t nhá», gÃ³c lá»‡c nÃ y cÃ³ thá»ƒ lÃ m sai lá»‡ch cÃ¡c giÃ¡ trá»‹ tÃ­nh toÃ¡n.
BÆ°á»›c 4: Xá»­ lÃ½ áº£nh dÃ¹ng giáº£i thuáº­t Template matching vÃ  Subtract Background.
BÆ°á»›c 5: ÄÆ°a ra cÃ¡c Ä‘iá»ƒm nghi ngá» dá»‹ váº­t/bá»t khÃ­/xÆ°á»›c
So sÃ¡nh cÃ¡c tá»a Ä‘á»™ cá»§a cÃ¡c Ä‘áº·c tÃ­nh thu Ä‘Æ°á»£c trÃªn áº£nh live vÃ  áº£nh gá»‘c Ä‘á»ƒ tÃ¬m ra cÃ¡c tá»a Ä‘á»™ Ä‘áº·c tÃ­nh khÃ¡c nhau.
CÃ¡c tá»a Ä‘á»™ thu Ä‘Æ°á»£c chÃ­nh lÃ  cÃ¡c nghi ngá» dá»‹ váº­t/bá»t khÃ­/xÆ°á»›c
BÆ°á»›c 6: PhÃ¡t cáº£nh bÃ¡o( Alarm) tá»« thiáº¿t bá»‹ - Confirm
Mong a chá»‹ giÃºp Ä‘á»¡ em. Em xin cáº£m Æ¡n","[ GÃ³c xin trá»£ giÃºp ] Em xin chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n áº¡ Hiá»‡n táº¡i em Ä‘ang nháº­p mÃ´n lÃ m Ä‘á» tÃ i liÃªn quan tá»›i Machine learning ""Sá»­ dá»¥ng camera vision check lá»—i á»Ÿ mÃ n hÃ¬nh Ä‘iá»‡n thoáº¡i( scratch- lá»—i xÆ°á»›c , alien - lá»—i dá»‹ váº­t , Bubble - lá»—i bÃ³ng khÃ­ bá» máº·t ) "" tuy nhiÃªn hiá»‡n táº¡i tÃ i liá»‡u data áº£nh á»Ÿ 3 lá»—i trÃªn em tÃ¬m hiá»ƒu váº«n khÃ´ng cÃ³ nhiá»u dá»¯ liá»‡u áº£nh. Mong a chá»‹ nÃ o cÃ³ : 1.Data áº£nh nhá»¯ng lá»—i trÃªn, thÃ¬ cho em xin tham kháº£o Ä‘á»ƒ em train áº£nh vá»›i ;(((( 2 Cá»™ng vá»›i hÆ°á»›ng check tá»«ng lá»—i vá»›i áº¡ . HÆ°á»›ng em Ä‘Æ°a ra cÃ²n mÃ´ng lung quÃ¡ . Em Ä‘ang suy nghÄ© hÆ°á»›ng nÃ y : Chá»¥p áº£nh sample khÃ´ng cÃ³ dá»‹ váº­t/ bá»t khÃ­/ xÆ°á»›c tiá»n xá»­ lÃ½ áº£nh gá»‘c CÃ¡c ná»™i dung tiá»n xá»­ lÃ½ bao gá»“m: - Chuyá»ƒn Ä‘á»•i áº£nh thÃ nh áº£nh xÃ¡m( áº£nh chá»¥p bá»Ÿi camera Basler lÃ  áº£nh xÃ¡m) - Tiáº¿n hÃ nh lá»c nhiá»…u cÃ¡c Ä‘áº·c tÃ­nh cá»§a hÃ¬nh áº£nh sá»­ dá»¥ng bá»™ lá»c Median( lá»c muá»‘i tiÃªu), Gaussian( lá»c cÃ¡c nhiá»…u nhiá»u hÃ¬nh dáº¡ng) - ÄÄƒng kÃ½ ngoáº¡i lá»‡ cÃ¡c tá»a Ä‘á»™ lá»— chÃ¢n khÃ´ng, váº¿t xÆ°á»›c cá»‘ Ä‘á»‹nh báº±ng thuáº­t toÃ¡n tÃ¬m biÃªn Canny BÆ°á»›c 2: ÄÄƒng kÃ½ ngoáº¡i lá»‡ cho cÃ¡c Ä‘áº·c tÃ­nh hÃ¬nh áº£nh sáºµn cÃ³. BÆ°á»›c 3: Chá»¥p hÃ¬nh áº£nh live, tiá»n xá»­ lÃ½ áº£nhâ€¦ Sau khi chá»¥p áº£nh live viá»‡c Ä‘áº§u tiÃªn ta cáº§n lÃ  pháº£i tiá»n xá»­ lÃ½ áº£nh live tÆ°Æ¡ng tá»± nhÆ° áº£nh gá»‘c: - Chuyá»ƒn Ä‘á»•i áº£nh thÃ nh áº£nh xÃ¡m - Tiáº¿n hÃ nh lá»c nhiá»…u, lá»c biÃªn cÃ¡c Ä‘áº·c tÃ­nh cá»§a hÃ¬nh áº£nh sá»­ dá»¥ng bá»™ lá»c Median - ÄÄƒng kÃ½ ngoáº¡i lá»‡ cÃ¡c tá»a Ä‘á»™ lá»— chÃ¢n khÃ´ng, váº¿t xÆ°á»›c cá»‘ Ä‘á»‹nh báº±ng thuáº­t toÃ¡n tÃ¬m biÃªn Candy Sau Ä‘Ã³ ta cáº§n, xÃ¡c nháº­n láº¡i vÃ¹ng ROI( read of image) cá»§a áº£nh live do trong quÃ¡ trÃ¬nh chá»¥p thÃ¬ áº£nh bá»‹ xoay má»™t gÃ³c ráº¥t nhá», gÃ³c lá»‡c nÃ y cÃ³ thá»ƒ lÃ m sai lá»‡ch cÃ¡c giÃ¡ trá»‹ tÃ­nh toÃ¡n. BÆ°á»›c 4: Xá»­ lÃ½ áº£nh dÃ¹ng giáº£i thuáº­t Template matching vÃ  Subtract Background. BÆ°á»›c 5: ÄÆ°a ra cÃ¡c Ä‘iá»ƒm nghi ngá» dá»‹ váº­t/bá»t khÃ­/xÆ°á»›c So sÃ¡nh cÃ¡c tá»a Ä‘á»™ cá»§a cÃ¡c Ä‘áº·c tÃ­nh thu Ä‘Æ°á»£c trÃªn áº£nh live vÃ  áº£nh gá»‘c Ä‘á»ƒ tÃ¬m ra cÃ¡c tá»a Ä‘á»™ Ä‘áº·c tÃ­nh khÃ¡c nhau. CÃ¡c tá»a Ä‘á»™ thu Ä‘Æ°á»£c chÃ­nh lÃ  cÃ¡c nghi ngá» dá»‹ váº­t/bá»t khÃ­/xÆ°á»›c BÆ°á»›c 6: PhÃ¡t cáº£nh bÃ¡o( Alarm) tá»« thiáº¿t bá»‹ - Confirm Mong a chá»‹ giÃºp Ä‘á»¡ em. Em xin cáº£m Æ¡n",,,,,
"Váº«n lÃ  ResNet50 nhÆ°ng vá»›i kÄ© thuáº­t training vÃ  cÃ¡c thiáº¿t láº­p Hyperparameters khÃ¡c nhau (nhÆ° hÃ m loss, thay vÃ¬ dÃ¹ng SGD thÃ¬ dÃ¹ng LAMB, káº¿t há»£p vá»›i Repeat Augmentation + BCE,...) mÃ  khÃ´ng cáº§n thÃªm data hay distillation learning Ä‘Ã£ giÃºp model nÃ y Ä‘áº¡t accuracy lÃªn tá»›i 80.4% trÃªn táº­p dá»¯ liá»‡u ImageNet. BÃ i bÃ¡o xem táº¡i Ä‘Ã¢y:","Váº«n lÃ  ResNet50 nhÆ°ng vá»›i kÄ© thuáº­t training vÃ  cÃ¡c thiáº¿t láº­p Hyperparameters khÃ¡c nhau (nhÆ° hÃ m loss, thay vÃ¬ dÃ¹ng SGD thÃ¬ dÃ¹ng LAMB, káº¿t há»£p vá»›i Repeat Augmentation + BCE,...) mÃ  khÃ´ng cáº§n thÃªm data hay distillation learning Ä‘Ã£ giÃºp model nÃ y Ä‘áº¡t accuracy lÃªn tá»›i 80.4% trÃªn táº­p dá»¯ liá»‡u ImageNet. BÃ i bÃ¡o xem táº¡i Ä‘Ã¢y:",,,,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ  Ä‘ang lÃ  má»™t Software Engineer vá»›i má»™t background vá» Computer Science vá»¯ng vÃ  understand sÆ¡ vá» component cá»§a má»™t data systems vÃ  machine learning. Em muá»‘n há»c thÃªm vá» Data Science concepts (A/B testing, make business data-driven decision,..) vÃ  kiá»ƒu work process thÃ¬ nÃªn há»c á»Ÿ Ä‘Ã¢u áº¡.
Em search course trÃªn máº¡ng thÃ¬ nhiá»u lÃºc nÃ³ bá»‹ loÃ£ng vá»›i Python vá»›i R cÃ¡c thá»©. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai há»c course nÃ o cÃ³ component vá» cÃ¡i nÃ y tá»‘t cÃ³ thá»ƒ giá»›i thiá»‡u khÃ´ng áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡ !","ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ  Ä‘ang lÃ  má»™t Software Engineer vá»›i má»™t background vá» Computer Science vá»¯ng vÃ  understand sÆ¡ vá» component cá»§a má»™t data systems vÃ  machine learning. Em muá»‘n há»c thÃªm vá» Data Science concepts (A/B testing, make business data-driven decision,..) vÃ  kiá»ƒu work process thÃ¬ nÃªn há»c á»Ÿ Ä‘Ã¢u áº¡. Em search course trÃªn máº¡ng thÃ¬ nhiá»u lÃºc nÃ³ bá»‹ loÃ£ng vá»›i Python vá»›i R cÃ¡c thá»©. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai há»c course nÃ o cÃ³ component vá» cÃ¡i nÃ y tá»‘t cÃ³ thá»ƒ giá»›i thiá»‡u khÃ´ng áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡ !",,,,,
"[Há»i vá» Linear Regression] #discution #ML #LR
Em Ä‘ang tÃ¬m hiá»ƒu Linear Regression thÃ¬ cÃ³ 2 váº¥n Ä‘á» khi em test code :
BÃ i toÃ¡n: Dá»± Ä‘oÃ¡n thu nháº­p bÃ¬nh quÃ¢n Ä‘áº§u ngÆ°á»i canada theo nÄƒm dÃ¹ng Linear Regression.
Dataset: dá»¯ liá»‡u tá»« nÄƒm 1970 -> 2016 vá»›i thu nháº­p bÃ¬nh quÃ¢n tÆ°Æ¡ng á»©ng.
1. áº¢nh 1
Khi model Ä‘Ã£ fit thÃ¬ em dá»± bÃ¡o ngÆ°á»£c nÄƒm 1970 hoáº·c nÄƒm sau Ä‘Ã³ thÃ¬ ra giÃ¡ trá»‹ Ã¢m.
Theo cÃ¡ch hiá»ƒu cá»§a em thÃ¬ vá»›i model Ä‘Ã£ Ä‘Æ°á»£c train thÃ¬ nÄƒm 1970 pháº£i ra giÃ¡ trá»‹ dÆ°Æ¡ng cÃ³ thá»ƒ khÃ¡c giÃ¡ trá»‹ gá»‘c chá»© sao láº¡i Ã¢m Ä‘Æ°á»£c?
2. áº¢nh 2
Biá»ƒu Ä‘á»“ biá»ƒu diá»…n cÃ³ cÃ¡i 1e7 em khÃ´ng hiá»ƒu sao láº¡i váº­y, vÃ  táº¡i sao nÃ³ khÃ´ng ra Ä‘Æ°á»ng tháº³ng vÃ  cÃ¡c Ä‘iá»ƒm á»Ÿ gáº§n xung quanh thay vÃ¬ Ä‘i ngang nhÆ° bÃªn dÆ°á»›i hÃ¬nh.
Em kÃ¬ vá»ng nÃ³ giá»‘ng áº£nh 3 áº¡ Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ Ä‘á»‘i chiáº¿u model vá»›i dá»¯ liá»‡u (áº£nh nÃ y á»Ÿ bá»™ dá»¯ liá»‡u khÃ¡c - giÃ¡ nhÃ  theo diá»‡n tÃ­ch).
Em Ä‘á»ƒ file code á»Ÿ Ä‘Ã¢y áº¡
https://drive.google.com/drive/folders/1SysK4Le8Xg_Y0rnrEbONfLlqvnsVVvks?usp=sharing","[Há»i vá» Linear Regression] Em Ä‘ang tÃ¬m hiá»ƒu Linear Regression thÃ¬ cÃ³ 2 váº¥n Ä‘á» khi em test code : BÃ i toÃ¡n: Dá»± Ä‘oÃ¡n thu nháº­p bÃ¬nh quÃ¢n Ä‘áº§u ngÆ°á»i canada theo nÄƒm dÃ¹ng Linear Regression. Dataset: dá»¯ liá»‡u tá»« nÄƒm 1970 -> 2016 vá»›i thu nháº­p bÃ¬nh quÃ¢n tÆ°Æ¡ng á»©ng. 1. áº¢nh 1 Khi model Ä‘Ã£ fit thÃ¬ em dá»± bÃ¡o ngÆ°á»£c nÄƒm 1970 hoáº·c nÄƒm sau Ä‘Ã³ thÃ¬ ra giÃ¡ trá»‹ Ã¢m. Theo cÃ¡ch hiá»ƒu cá»§a em thÃ¬ vá»›i model Ä‘Ã£ Ä‘Æ°á»£c train thÃ¬ nÄƒm 1970 pháº£i ra giÃ¡ trá»‹ dÆ°Æ¡ng cÃ³ thá»ƒ khÃ¡c giÃ¡ trá»‹ gá»‘c chá»© sao láº¡i Ã¢m Ä‘Æ°á»£c? 2. áº¢nh 2 Biá»ƒu Ä‘á»“ biá»ƒu diá»…n cÃ³ cÃ¡i 1e7 em khÃ´ng hiá»ƒu sao láº¡i váº­y, vÃ  táº¡i sao nÃ³ khÃ´ng ra Ä‘Æ°á»ng tháº³ng vÃ  cÃ¡c Ä‘iá»ƒm á»Ÿ gáº§n xung quanh thay vÃ¬ Ä‘i ngang nhÆ° bÃªn dÆ°á»›i hÃ¬nh. Em kÃ¬ vá»ng nÃ³ giá»‘ng áº£nh 3 áº¡ Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ Ä‘á»‘i chiáº¿u model vá»›i dá»¯ liá»‡u (áº£nh nÃ y á»Ÿ bá»™ dá»¯ liá»‡u khÃ¡c - giÃ¡ nhÃ  theo diá»‡n tÃ­ch). Em Ä‘á»ƒ file code á»Ÿ Ä‘Ã¢y áº¡ https://drive.google.com/drive/folders/1SysK4Le8Xg_Y0rnrEbONfLlqvnsVVvks?usp=sharing",#discution	#ML	#LR,,,,
"ChÃ o má»i ngÆ°á»i!!
MÃ¬nh hiá»‡n Ä‘ang lÃ  sinh viÃªn nÄƒm 3 ngÃ nh Khoa há»c MÃ¡y tÃ­nh. MÃ¬nh cÃ³ background tÆ°Æ¡ng Ä‘á»‘i vá» toÃ¡n (Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh, giáº£i tÃ­ch vÃ  xÃ¡c suáº¥t thá»‘ng kÃª). Thá»i gian qua mÃ¬nh há»c vá» toÃ¡n vÃ  machine learning cÆ¡ báº£n vÃ  táº­p tÃ nh tÃ¬m hiá»ƒu vá» cÃ¡c model cÅ©ng nhÆ° á»©ng dá»¥ng Ä‘á»ƒ tÃ¬m hÆ°á»›ng Ä‘i cá»¥ thá»ƒ. MÃ¬nh nháº­n tháº¥y báº£n thÃ¢n thÃ­ch Ä‘i theo hÆ°á»›ng xá»­ lÃ½ áº£nh (image processing vÃ  computer vision) vÃ  Ä‘ang báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» ná»n táº£ng vÃ  cÃ¡c kiáº¿n thá»©c cÄƒn báº£n cá»§a xá»­ lÃ½ áº£nh (image processing). MÃ¬nh khÃ¡ chÃº trá»ng vÃ o viá»‡c há»c cÃ¡c kiáº¿n thá»©c ná»n táº£ng khi tiáº¿p cáº­n má»™t váº¥n Ä‘á» nÃ o Ä‘Ã³. MÃ¬nh Ä‘ang Ä‘á»c cuá»‘n DIP cá»§a Rafael C. Gonzalez and Richard E. Woods vÃ  káº¿t há»£p tÃ¬m hiá»ƒu má»™t sá»‘ nguá»“n online, nhÆ° khÃ³a fundamentals trÃªn Coursera... Äiá»u mÃ  mÃ¬nh tháº¥y Ä‘Æ°á»£c sau má»™t khoáº£ng thá»i gian tÃ¬m hiá»ƒu lÃ  image processing lÃ  má»™t chá»§ Ä‘á» khÃ³ vÃ  sáº½ máº¥t nhiá»u thá»i gian, bÃªn cáº¡nh Ä‘Ã³, á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i mÃ¬nh gáº·p pháº£i nhiá»u khÃ³ khÄƒn trong viá»‡c Ä‘á»c cÃ¡c kiáº¿n thá»©c vá» frequency domain trong xá»­ lÃ½ áº£nh, cÃ³ nhiá»u thuáº­t ngá»¯ mÃ  mÃ¬nh chÆ°a nghe qua. VÃ  cÃ¡ nhÃ¢n mÃ¬nh cáº£m tháº¥y nhá»¯ng nguá»“n tÃ i liá»‡u mÃ  mÃ¬nh Ä‘ang tiáº¿p cáº­n cÅ©ng khÃ´ng phÃ¹ há»£p cho beginner nhÆ° mÃ¬nh láº¯m, nÃªn mÃ¬nh khÃ¡ phÃ¢n vÃ¢n khÃ´ng biáº¿t cÃ³ nÃªn tiáº¿p tá»¥c Ä‘Ã o sÃ¢u vÃ o cÃ¡c kiáº¿n thá»©c ná»n táº£ng hay khÃ´ng, nhÆ° vá» signal processing cháº³ng háº¡n. Anh/chá»‹/báº¡n nÃ o Ä‘i trÆ°á»›c cÃ³ kinh nghiá»‡m trong chá»§ Ä‘á» nÃ y cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn vá»›i áº¡, náº¿u cÃ³ thá»ƒ thÃ¬ cho mÃ¬nh má»™t sá»‘ gá»£i Ã½ vá» cÃ¡c nguá»“n tÃ i liá»‡u mÃ  mÃ¬nh cÃ³ thá»ƒ tham kháº£o.
MÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i!! MÃ¬nh hiá»‡n Ä‘ang lÃ  sinh viÃªn nÄƒm 3 ngÃ nh Khoa há»c MÃ¡y tÃ­nh. MÃ¬nh cÃ³ background tÆ°Æ¡ng Ä‘á»‘i vá» toÃ¡n (Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh, giáº£i tÃ­ch vÃ  xÃ¡c suáº¥t thá»‘ng kÃª). Thá»i gian qua mÃ¬nh há»c vá» toÃ¡n vÃ  machine learning cÆ¡ báº£n vÃ  táº­p tÃ nh tÃ¬m hiá»ƒu vá» cÃ¡c model cÅ©ng nhÆ° á»©ng dá»¥ng Ä‘á»ƒ tÃ¬m hÆ°á»›ng Ä‘i cá»¥ thá»ƒ. MÃ¬nh nháº­n tháº¥y báº£n thÃ¢n thÃ­ch Ä‘i theo hÆ°á»›ng xá»­ lÃ½ áº£nh (image processing vÃ  computer vision) vÃ  Ä‘ang báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» ná»n táº£ng vÃ  cÃ¡c kiáº¿n thá»©c cÄƒn báº£n cá»§a xá»­ lÃ½ áº£nh (image processing). MÃ¬nh khÃ¡ chÃº trá»ng vÃ o viá»‡c há»c cÃ¡c kiáº¿n thá»©c ná»n táº£ng khi tiáº¿p cáº­n má»™t váº¥n Ä‘á» nÃ o Ä‘Ã³. MÃ¬nh Ä‘ang Ä‘á»c cuá»‘n DIP cá»§a Rafael C. Gonzalez and Richard E. Woods vÃ  káº¿t há»£p tÃ¬m hiá»ƒu má»™t sá»‘ nguá»“n online, nhÆ° khÃ³a fundamentals trÃªn Coursera... Äiá»u mÃ  mÃ¬nh tháº¥y Ä‘Æ°á»£c sau má»™t khoáº£ng thá»i gian tÃ¬m hiá»ƒu lÃ  image processing lÃ  má»™t chá»§ Ä‘á» khÃ³ vÃ  sáº½ máº¥t nhiá»u thá»i gian, bÃªn cáº¡nh Ä‘Ã³, á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i mÃ¬nh gáº·p pháº£i nhiá»u khÃ³ khÄƒn trong viá»‡c Ä‘á»c cÃ¡c kiáº¿n thá»©c vá» frequency domain trong xá»­ lÃ½ áº£nh, cÃ³ nhiá»u thuáº­t ngá»¯ mÃ  mÃ¬nh chÆ°a nghe qua. VÃ  cÃ¡ nhÃ¢n mÃ¬nh cáº£m tháº¥y nhá»¯ng nguá»“n tÃ i liá»‡u mÃ  mÃ¬nh Ä‘ang tiáº¿p cáº­n cÅ©ng khÃ´ng phÃ¹ há»£p cho beginner nhÆ° mÃ¬nh láº¯m, nÃªn mÃ¬nh khÃ¡ phÃ¢n vÃ¢n khÃ´ng biáº¿t cÃ³ nÃªn tiáº¿p tá»¥c Ä‘Ã o sÃ¢u vÃ o cÃ¡c kiáº¿n thá»©c ná»n táº£ng hay khÃ´ng, nhÆ° vá» signal processing cháº³ng háº¡n. Anh/chá»‹/báº¡n nÃ o Ä‘i trÆ°á»›c cÃ³ kinh nghiá»‡m trong chá»§ Ä‘á» nÃ y cÃ³ thá»ƒ cho mÃ¬nh lá»i khuyÃªn vá»›i áº¡, náº¿u cÃ³ thá»ƒ thÃ¬ cho mÃ¬nh má»™t sá»‘ gá»£i Ã½ vá» cÃ¡c nguá»“n tÃ i liá»‡u mÃ  mÃ¬nh cÃ³ thá»ƒ tham kháº£o. MÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n!",,,,,
"Dá»± Ã¡n dá»‹ch JupyterLab sang tiáº¿ng viá»‡t.
ChÃ o cÃ¡c báº¡n, trong group cháº¯c háº³n cÃ¡c báº¡n Ä‘Ã£ quen vá»›i viá»‡c sá»­ dá»¥ng JupyterLab. Giao diá»‡n hiá»‡n táº¡i báº±ng tiáº¿ng anh khÃ´ng gÃ¢y khÃ³ khÄƒn gÃ¬ trong viá»‡c sá»­ dá»¥ng nhÆ°ng Ä‘á»ƒ má»Ÿ rá»™ng Ä‘á»‘i tÆ°á»£ng ngÆ°á»i dÃ¹ng, nháº¥t lÃ  cho viá»‡c sá»­ dá»¥ng JupyterLab trong trÆ°á»ng há»c, hiá»‡n táº¡i JupyterLab Ä‘Ã£ há»— trá»£ cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau thÃ´ng qua há»‡ thá»‘ng dá»‹ch dá»±a trÃªn cá»™ng Ä‘á»“ng táº¡i trang https://crowdin.com/project/jupyterlab.
Hiá»‡n táº¡i báº£n dá»‹ch tiáº¿ng Viá»‡t Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng nhÆ°ng má»›i chá»‰ Ä‘Æ°á»£c 1% do ráº¥t thiáº¿u ngÆ°á»i dá»‹ch. VÃ¬ váº­y mÃ¬nh muá»‘n chia sáº» post nÃ y Ä‘á»ƒ mong cÃ¡c báº¡n cÃ¹ng chung tay táº¡o ra 1 phiÃªn báº£n JupyterLab Viá»‡t hÃ³a.
Äá»ƒ tham gia dá»± Ã¡n, cÃ¡c báº¡n cáº§n Ä‘Äƒng nháº­p vÃ o crowdin (qua tÃ i khoáº£n google, github...) vÃ  Ä‘Äƒng kÃ­ tham gia dá»± Ã¡n JupyterLab, sau khi dc xÃ©t duyá»‡n thÃ¬ báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u dá»‹ch, chi tiáº¿t nhÆ° trong cÃ¡c áº£nh phÃ­a dÆ°á»›i.
GÃ³i ngÃ´n ngá»¯ tiáº¿ng viá»‡t cho JupyterLab Ä‘Ã£ cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ i Ä‘áº·t báº±ng pip:
pip install jupyterlab-language-pack-vi-VN
Hi vá»ng tiáº¿ng Viá»‡t sáº½ nhanh chÃ³ng lÃ  ngÃ´n ngá»¯ tiáº¿p theo Ä‘Æ°á»£c dá»‹ch hoÃ n chá»‰nh trong JupyterLab.","Dá»± Ã¡n dá»‹ch JupyterLab sang tiáº¿ng viá»‡t. ChÃ o cÃ¡c báº¡n, trong group cháº¯c háº³n cÃ¡c báº¡n Ä‘Ã£ quen vá»›i viá»‡c sá»­ dá»¥ng JupyterLab. Giao diá»‡n hiá»‡n táº¡i báº±ng tiáº¿ng anh khÃ´ng gÃ¢y khÃ³ khÄƒn gÃ¬ trong viá»‡c sá»­ dá»¥ng nhÆ°ng Ä‘á»ƒ má»Ÿ rá»™ng Ä‘á»‘i tÆ°á»£ng ngÆ°á»i dÃ¹ng, nháº¥t lÃ  cho viá»‡c sá»­ dá»¥ng JupyterLab trong trÆ°á»ng há»c, hiá»‡n táº¡i JupyterLab Ä‘Ã£ há»— trá»£ cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau thÃ´ng qua há»‡ thá»‘ng dá»‹ch dá»±a trÃªn cá»™ng Ä‘á»“ng táº¡i trang https://crowdin.com/project/jupyterlab. Hiá»‡n táº¡i báº£n dá»‹ch tiáº¿ng Viá»‡t Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng nhÆ°ng má»›i chá»‰ Ä‘Æ°á»£c 1% do ráº¥t thiáº¿u ngÆ°á»i dá»‹ch. VÃ¬ váº­y mÃ¬nh muá»‘n chia sáº» post nÃ y Ä‘á»ƒ mong cÃ¡c báº¡n cÃ¹ng chung tay táº¡o ra 1 phiÃªn báº£n JupyterLab Viá»‡t hÃ³a. Äá»ƒ tham gia dá»± Ã¡n, cÃ¡c báº¡n cáº§n Ä‘Äƒng nháº­p vÃ o crowdin (qua tÃ i khoáº£n google, github...) vÃ  Ä‘Äƒng kÃ­ tham gia dá»± Ã¡n JupyterLab, sau khi dc xÃ©t duyá»‡n thÃ¬ báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u dá»‹ch, chi tiáº¿t nhÆ° trong cÃ¡c áº£nh phÃ­a dÆ°á»›i. GÃ³i ngÃ´n ngá»¯ tiáº¿ng viá»‡t cho JupyterLab Ä‘Ã£ cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ i Ä‘áº·t báº±ng pip: pip install jupyterlab-language-pack-vi-VN Hi vá»ng tiáº¿ng Viá»‡t sáº½ nhanh chÃ³ng lÃ  ngÃ´n ngá»¯ tiáº¿p theo Ä‘Æ°á»£c dá»‹ch hoÃ n chá»‰nh trong JupyterLab.",,,,,
"ChÃ o m.n
E Ä‘ang tÃ¬m hiá»ƒu vá» Machine learning pháº§n Feauture selection, thÃ¬ e tháº¥y cÃ³ ráº¥t Ã­t tÃ i liá»‡u, sÃ¡ch hay bÃ i giáº£ng chi tiáº¿t vá» pháº§n nÃ y. Ae cÃ³ ai cÃ³ tÃ i liá»‡u vá» pháº§n nÃ y khÃ´ng cho em xin thÃ´ng tin tham kháº£o vá»›i, náº¿u cÃ³ ebook thÃ¬ cÃ ng tá»‘t áº¡. E xin cáº£m Æ¡n.
*áº¢nh lÃ  1 cuá»‘n e tÃ¬m hiá»ƒu vá» pháº§n nÃ y nhÆ°ng khÃ´ng cÃ³ ebook áº¡.","ChÃ o m.n E Ä‘ang tÃ¬m hiá»ƒu vá» Machine learning pháº§n Feauture selection, thÃ¬ e tháº¥y cÃ³ ráº¥t Ã­t tÃ i liá»‡u, sÃ¡ch hay bÃ i giáº£ng chi tiáº¿t vá» pháº§n nÃ y. Ae cÃ³ ai cÃ³ tÃ i liá»‡u vá» pháº§n nÃ y khÃ´ng cho em xin thÃ´ng tin tham kháº£o vá»›i, náº¿u cÃ³ ebook thÃ¬ cÃ ng tá»‘t áº¡. E xin cáº£m Æ¡n. *áº¢nh lÃ  1 cuá»‘n e tÃ¬m hiá»ƒu vá» pháº§n nÃ y nhÆ°ng khÃ´ng cÃ³ ebook áº¡.",,,,,
"ThÃ´ng bÃ¡o thÃªm quyá»n táº£i vá» cho Ä‘á»™c giáº£ Ä‘Ã£ mua ebook """"Thá»±c hÃ nh Há»c MÃ¡y vá»›i Scikit-Learn, Keras & TensorFlow - Táº­p 1"".
https://handson-ml.mlbvn.org/
Sau khi cÃ¢n nháº¯c cÃ¡c Ä‘iá»u khoáº£n há»£p Ä‘á»“ng vá»›i O'Reilly, nhÃ³m dá»‹ch Ä‘Ã£ quyáº¿t Ä‘á»‹nh cho phÃ©p Ä‘á»™c giáº£ táº£i báº£n pdf vá» Ä‘á»c tá»« thiáº¿t bá»‹ cÃ¡ nhÃ¢n thay vÃ¬ Ä‘á»c trÃªn trÃ¬nh duyá»‡t nhÆ° trÆ°á»›c Ä‘Ã¢y. Viá»‡c nÃ y hy vá»ng giÃºp Ä‘á»™c giáº£ cÃ³ tráº£i nghiá»‡m Ä‘á»c sÃ¡ch tá»‘t hÆ¡n.
Äá»ƒ Ä‘áº£m báº£o hÆ¡n, nhÃ³m Ä‘Ã£ thÃªm má»™t sá»‘ biá»‡n phÃ¡p giÃºp truy xuáº¥t nguá»“n gá»‘c phÃ¡t tÃ¡n náº¿u cÃ³ sá»± chia sáº» trÃ n lan. Hy vá»ng cÃ¡c báº¡n tÃ´n trá»ng báº£n quyá»n Ä‘á»ƒ chÃºng ta cÃ³ cÆ¡ há»™i tiáº¿p tá»¥c lÃ m viá»‡c vá»›i O'Reilly trong cÃ¡c dá»± Ã¡n sau.","ThÃ´ng bÃ¡o thÃªm quyá»n táº£i vá» cho Ä‘á»™c giáº£ Ä‘Ã£ mua ebook """"Thá»±c hÃ nh Há»c MÃ¡y vá»›i Scikit-Learn, Keras & TensorFlow - Táº­p 1"". https://handson-ml.mlbvn.org/ Sau khi cÃ¢n nháº¯c cÃ¡c Ä‘iá»u khoáº£n há»£p Ä‘á»“ng vá»›i O'Reilly, nhÃ³m dá»‹ch Ä‘Ã£ quyáº¿t Ä‘á»‹nh cho phÃ©p Ä‘á»™c giáº£ táº£i báº£n pdf vá» Ä‘á»c tá»« thiáº¿t bá»‹ cÃ¡ nhÃ¢n thay vÃ¬ Ä‘á»c trÃªn trÃ¬nh duyá»‡t nhÆ° trÆ°á»›c Ä‘Ã¢y. Viá»‡c nÃ y hy vá»ng giÃºp Ä‘á»™c giáº£ cÃ³ tráº£i nghiá»‡m Ä‘á»c sÃ¡ch tá»‘t hÆ¡n. Äá»ƒ Ä‘áº£m báº£o hÆ¡n, nhÃ³m Ä‘Ã£ thÃªm má»™t sá»‘ biá»‡n phÃ¡p giÃºp truy xuáº¥t nguá»“n gá»‘c phÃ¡t tÃ¡n náº¿u cÃ³ sá»± chia sáº» trÃ n lan. Hy vá»ng cÃ¡c báº¡n tÃ´n trá»ng báº£n quyá»n Ä‘á»ƒ chÃºng ta cÃ³ cÆ¡ há»™i tiáº¿p tá»¥c lÃ m viá»‡c vá»›i O'Reilly trong cÃ¡c dá»± Ã¡n sau.",,,,,
"ChÃ o má»i ngÆ°á»i áº¡!
Má»i ngÆ°á»i trong nhÃ³m Ä‘Ã£ ai thá»­ triá»ƒn khai má»™t mÃ´ hÃ¬nh CV (Fast R-CNN, Faster R-CNN, Mask R-CNN) trÃªn C# (.Net framework) cho bÃ i toÃ¡n detection, Segmentation,... chÆ°a áº¡!
CÃ³ thá»ƒ cho em xin tÃ i liá»‡u, git tham kháº£o Ä‘Æ°á»£c khÃ´ng?
Hiá»‡n em cÃ³ tÃ¬m vÃ  lÃ m thá»­ Ä‘c mÃ´ hÃ¬nh theo Git nÃ y (""https://github.com/halanch599/EmguCVDemoV4.x.x.git"") nhÆ°ng khi lÃ m thá»­ trÃªn . Net framework 4.6-4.8 thÃ¬ ko Ä‘Æ°á»£c há»— trá»£ emgu.CV.runtime.
Thanks m.n!","ChÃ o má»i ngÆ°á»i áº¡! Má»i ngÆ°á»i trong nhÃ³m Ä‘Ã£ ai thá»­ triá»ƒn khai má»™t mÃ´ hÃ¬nh CV (Fast R-CNN, Faster R-CNN, Mask R-CNN) trÃªn C# (.Net framework) cho bÃ i toÃ¡n detection, Segmentation,... chÆ°a áº¡! CÃ³ thá»ƒ cho em xin tÃ i liá»‡u, git tham kháº£o Ä‘Æ°á»£c khÃ´ng? Hiá»‡n em cÃ³ tÃ¬m vÃ  lÃ m thá»­ Ä‘c mÃ´ hÃ¬nh theo Git nÃ y (""https://github.com/halanch599/EmguCVDemoV4.x.x.git"") nhÆ°ng khi lÃ m thá»­ trÃªn . Net framework 4.6-4.8 thÃ¬ ko Ä‘Æ°á»£c há»— trá»£ emgu.CV.runtime. Thanks m.n!",,,,,
"ChÃ o cÃ¡c ace trong group. Má»i ngÆ°á»i cho e há»i cÃ³ bá»™ data vá» tá»« Ä‘á»“ng nghÄ©a trong tiáº¿ng viá»‡t khÃ´ng áº¡. VÃ­ dá»¥: Äƒn cÆ¡m -> xÆ¡i cÆ¡m, bá»‘ trÃ­ -> sáº¯p xáº¿p
Cáº£m Æ¡n ace nhiá»u","ChÃ o cÃ¡c ace trong group. Má»i ngÆ°á»i cho e há»i cÃ³ bá»™ data vá» tá»« Ä‘á»“ng nghÄ©a trong tiáº¿ng viá»‡t khÃ´ng áº¡. VÃ­ dá»¥: Äƒn cÆ¡m -> xÆ¡i cÆ¡m, bá»‘ trÃ­ -> sáº¯p xáº¿p Cáº£m Æ¡n ace nhiá»u",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh lÃ  web developer level middle. MÃ¬nh cáº£m tháº¥y khÃ¡ Ä‘am mÃª vá»›i computer vision nÃªn Ä‘Ã£ tÃ¬m hiá»ƒu khÃ¡ nhiá»u. Giá» mÃ¬nh Ä‘Ã£ pass tensorflow certificate, má»i ngÆ°á»i cho mÃ¬nh xin lá»i khuyÃªn cÃ³ nÃªn chuyá»ƒn sang Machine learning luÃ´n k áº¡. Liá»‡u nháº­p cuá»™c muá»™n cÃ³ bá»‹ Ä‘Ã¡nh giÃ¡ tháº¥p hÆ¡n nhá»¯ng báº¡n tráº» Ä‘i tá»« Ä‘áº§u ko áº¡.
Xin láº¯ng nghe Ã½ kiáº¿n tá»« má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh lÃ  web developer level middle. MÃ¬nh cáº£m tháº¥y khÃ¡ Ä‘am mÃª vá»›i computer vision nÃªn Ä‘Ã£ tÃ¬m hiá»ƒu khÃ¡ nhiá»u. Giá» mÃ¬nh Ä‘Ã£ pass tensorflow certificate, má»i ngÆ°á»i cho mÃ¬nh xin lá»i khuyÃªn cÃ³ nÃªn chuyá»ƒn sang Machine learning luÃ´n k áº¡. Liá»‡u nháº­p cuá»™c muá»™n cÃ³ bá»‹ Ä‘Ã¡nh giÃ¡ tháº¥p hÆ¡n nhá»¯ng báº¡n tráº» Ä‘i tá»« Ä‘áº§u ko áº¡. Xin láº¯ng nghe Ã½ kiáº¿n tá»« má»i ngÆ°á»i.",,,,,
"Cuá»‘i tuáº§n ...nháº¡t tÃ½. CÃ¡c báº¡n cÃ³ tháº¥y ML giá»‘ng vá»›i HÃ³a há»c khÃ´ng? TÃ­nh suy luáº­n, suy diá»…n khÃ´ng cao nhÆ° Váº­t lÃ½. Vá»›i HÃ³a há»c hay ML báº¡n hoáº·c lÃ  láº¥y cÃ´ng thá»©c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ rá»“i cháº¿ thÃ nh pháº©m cÃ³ Ã­ch nhÆ° mÃ³n Äƒn, phÃ¢n bÃ³n, thuá»‘c Ä‘á»™c; hoáº·c lÃ  báº¡n ngá»“i phÃ²ng thÃ­ nghiá»‡m trá»™n cháº¥t ná», thay tá»· lá»‡ kia, thÃªm chÃºt xÃºc tÃ¡c láº¡, ...vÃ  rá»“i, náº¿u may máº¯n thÃ¬ BÃ™M, báº¡n cÃ³ má»™t cÃ´ng trÃ¬nh Ä‘á»ƒ Ä‘á»i.
CÃ³ Ä‘Ãºng váº­y ko nhá»‰? Hay lÃ  do mÃ¬nh dá»‘t mÃ´n hÃ³a (dÃ¹ lÃ  trÃ² cÆ°ng cá»§a cÃ´).","Cuá»‘i tuáº§n ...nháº¡t tÃ½. CÃ¡c báº¡n cÃ³ tháº¥y ML giá»‘ng vá»›i HÃ³a há»c khÃ´ng? TÃ­nh suy luáº­n, suy diá»…n khÃ´ng cao nhÆ° Váº­t lÃ½. Vá»›i HÃ³a há»c hay ML báº¡n hoáº·c lÃ  láº¥y cÃ´ng thá»©c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ rá»“i cháº¿ thÃ nh pháº©m cÃ³ Ã­ch nhÆ° mÃ³n Äƒn, phÃ¢n bÃ³n, thuá»‘c Ä‘á»™c; hoáº·c lÃ  báº¡n ngá»“i phÃ²ng thÃ­ nghiá»‡m trá»™n cháº¥t ná», thay tá»· lá»‡ kia, thÃªm chÃºt xÃºc tÃ¡c láº¡, ...vÃ  rá»“i, náº¿u may máº¯n thÃ¬ BÃ™M, báº¡n cÃ³ má»™t cÃ´ng trÃ¬nh Ä‘á»ƒ Ä‘á»i. CÃ³ Ä‘Ãºng váº­y ko nhá»‰? Hay lÃ  do mÃ¬nh dá»‘t mÃ´n hÃ³a (dÃ¹ lÃ  trÃ² cÆ°ng cá»§a cÃ´).",,,,,
"Xin trá»£ giÃºp vá» DBSCAN cluster.
MÃ¬nh Ä‘ang cáº§n dÃ¹ng Dbscan cluster Ä‘á»ƒ lá»c dá»¯ liá»‡u trÃ¹ng láº·p. Cáº§n dá»±a vÃ o biáº¿n toáº¡ Ä‘á»™ (lat/lon) vÃ  thá»i gian (timestamp) Ä‘á»ƒ phÃ¢n cá»¥m. Do mÃ¬nh má»›i nghiÃªn cá»©u vá» cluster nÃªn chÆ°a biáº¿t cÃ¡ch phÃ¢n cá»¥m vá»›i dá»¯ liá»‡u nhiá»u biáº¿n. Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m nhÆ° sau:
- BÆ°á»›c 1: phÃ¢n cá»¥m vá»›i biáº¿n toáº¡ Ä‘á»™ (lat/lon)
- BÆ°á»›c 2: dá»±a trÃªn tá»«ng cá»¥m Ä‘Ã£ gom á»Ÿ B1, tiáº¿p tá»¥c phÃ¢n cá»¥m vá»›i dá»¯ liá»‡u biáº¿n thá»i gian
Tá»©c lÃ  mÃ¬nh Ä‘ang lÃ m 2 láº§n cluster liÃªn tá»¥c.
MÃ¬nh xin nhá» trá»£ giÃºp 2 váº¥n Ä‘á» sau:
1- LÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¢n cá»¥m trong cÃ¹ng 1 láº§n vá»›i cáº£ bá»™ dá»¯ liá»‡u? CÃ¡c biáº¿n cÃ³ tÃ­nh cháº¥t khÃ¡c nhau thÃ¬ pháº£i lÃ m sao? VÃ¬ há»‡ sá»‘ epsilon sáº½ khÃ¡c nhau. Vd hiá»‡n táº¡i mÃ¬nh chá»n epsilon báº±ng 2miles vá»›i B1 vÃ  30 phÃºt vá»›i B2. Náº¿u gá»™p chung láº¡i thÃ¬ chá»n epsilon ntn? Liá»‡u cÃ³ cáº§n transform data vá» má»™t dáº¡ng chung gÃ¬ Ä‘Ã³ (má»™t vÃ i vÃ­ dá»¥ mÃ¬nh Ä‘á»c tháº¥y dÃ¹ng StandardScaler). á» Ä‘Ã¢y mÃ¬nh cáº§n thiáº¿t pháº£i dÃ¹ng cáº£ 2 biáº¿n lat/lon vÃ  time Ä‘á»ƒ phÃ¢n cá»¥m. MÃ¬nh chá»‰ lÃ  chÆ°a biáº¿t dÃ¹ng cÃ¡ch nÃ o Ä‘á»ƒ lÃ m trong 1 láº§n mÃ  k cáº§n chia 2 bÆ°á»›c nhÆ° trÃªn.
2- Trong tÆ°Æ¡ng lai mÃ¬nh cÃ³ thá»ƒ cáº§n add thÃªm biáº¿n tÃªn Ä‘Æ°á»ng (dá»¯ liá»‡u string) vÃ o Ä‘á»ƒ tiáº¿p tá»¥c phÃ¢n cá»¥m, váº­y cÃ³ pháº£i láº¡i phá»©c táº¡p hÆ¡n nhiá»u khÃ´ng? VÃ  cÃ³ pháº£i dá»¯ liá»‡u string nÃ y cáº§n biáº¿n Ä‘á»•i thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ cháº¡y phÃ¢n cá»¥m?
Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u.","Xin trá»£ giÃºp vá» DBSCAN cluster. MÃ¬nh Ä‘ang cáº§n dÃ¹ng Dbscan cluster Ä‘á»ƒ lá»c dá»¯ liá»‡u trÃ¹ng láº·p. Cáº§n dá»±a vÃ o biáº¿n toáº¡ Ä‘á»™ (lat/lon) vÃ  thá»i gian (timestamp) Ä‘á»ƒ phÃ¢n cá»¥m. Do mÃ¬nh má»›i nghiÃªn cá»©u vá» cluster nÃªn chÆ°a biáº¿t cÃ¡ch phÃ¢n cá»¥m vá»›i dá»¯ liá»‡u nhiá»u biáº¿n. Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m nhÆ° sau: - BÆ°á»›c 1: phÃ¢n cá»¥m vá»›i biáº¿n toáº¡ Ä‘á»™ (lat/lon) - BÆ°á»›c 2: dá»±a trÃªn tá»«ng cá»¥m Ä‘Ã£ gom á»Ÿ B1, tiáº¿p tá»¥c phÃ¢n cá»¥m vá»›i dá»¯ liá»‡u biáº¿n thá»i gian Tá»©c lÃ  mÃ¬nh Ä‘ang lÃ m 2 láº§n cluster liÃªn tá»¥c. MÃ¬nh xin nhá» trá»£ giÃºp 2 váº¥n Ä‘á» sau: 1- LÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¢n cá»¥m trong cÃ¹ng 1 láº§n vá»›i cáº£ bá»™ dá»¯ liá»‡u? CÃ¡c biáº¿n cÃ³ tÃ­nh cháº¥t khÃ¡c nhau thÃ¬ pháº£i lÃ m sao? VÃ¬ há»‡ sá»‘ epsilon sáº½ khÃ¡c nhau. Vd hiá»‡n táº¡i mÃ¬nh chá»n epsilon báº±ng 2miles vá»›i B1 vÃ  30 phÃºt vá»›i B2. Náº¿u gá»™p chung láº¡i thÃ¬ chá»n epsilon ntn? Liá»‡u cÃ³ cáº§n transform data vá» má»™t dáº¡ng chung gÃ¬ Ä‘Ã³ (má»™t vÃ i vÃ­ dá»¥ mÃ¬nh Ä‘á»c tháº¥y dÃ¹ng StandardScaler). á» Ä‘Ã¢y mÃ¬nh cáº§n thiáº¿t pháº£i dÃ¹ng cáº£ 2 biáº¿n lat/lon vÃ  time Ä‘á»ƒ phÃ¢n cá»¥m. MÃ¬nh chá»‰ lÃ  chÆ°a biáº¿t dÃ¹ng cÃ¡ch nÃ o Ä‘á»ƒ lÃ m trong 1 láº§n mÃ  k cáº§n chia 2 bÆ°á»›c nhÆ° trÃªn. 2- Trong tÆ°Æ¡ng lai mÃ¬nh cÃ³ thá»ƒ cáº§n add thÃªm biáº¿n tÃªn Ä‘Æ°á»ng (dá»¯ liá»‡u string) vÃ o Ä‘á»ƒ tiáº¿p tá»¥c phÃ¢n cá»¥m, váº­y cÃ³ pháº£i láº¡i phá»©c táº¡p hÆ¡n nhiá»u khÃ´ng? VÃ  cÃ³ pháº£i dá»¯ liá»‡u string nÃ y cáº§n biáº¿n Ä‘á»•i thÃ nh dáº¡ng sá»‘ Ä‘á»ƒ cháº¡y phÃ¢n cá»¥m? Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 4/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 4/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"Em chÃ o má»i ngÆ°á»i, em má»›i dÃ¹ng thá»­ dá»‹ch vá»¥ bÃªn iRender, em thuÃª 1 con GPU RTX-3090, VRAM 24Gb, CPU Xeon-2245, RAM 64Gb . Khi em create image, em cÃ³ chá»n image type lÃ  pre-install software vÃ  chá»n lÃ  conda vÃ¬ em nghÄ© lÃ  em cÃ³ thá»ƒ sá»­ dá»¥ng conda Ä‘á»ƒ táº¡o mÃ´i trÆ°á»ng má»›i thá»a mÃ£n tensorflow-gpu vá»›i cÃ¢u lá»‡nh conda create --name <tÃªn mÃ´i trÆ°á»ng mÃ¬nh Ä‘áº·t> tensorflow-gpu, thÃ¬ nÃ³ tá»± Ä‘á»™ng install giÃºp em má»™t loáº¡t cÃ¡c package trong Ä‘Ã³ cÃ³ cudatoolkit ver 10.1, cudnn ver 7.6.5, tensorflow-base vÃ  tensorflow-gpu ver 2.4. QuÃ¡ trÃ¬nh trÃªn setup máº¥t khoáº£ng 7'. Em muá»‘n há»i má»i ngÆ°á»i má»™t chÃºt áº¡
QuÃ¡ trÃ¬nh setup mÃ´i trÆ°á»ng tensorflow-gpu trÃªn táº§m Ä‘Ã³ cÃ³ pháº£i lÃ  lÃ¢u khÃ´ng áº¡? Náº¿u cÃ³ thá»ƒ cáº£i thiá»‡n thÃ¬ em nÃªn chá»n pre-install cho image type cÃ³ nÃªn lÃ  conda khÃ´ng áº¡? VÃ¬ em tháº¥y ráº±ng cÃ³ cÃ¡c software khÃ¡c nhÆ° há» cho cáº£ CUDA 11.0, cuDNN 8.0.5, hoáº·c tensorflow 2.4? Em nghÄ© lÃ  mÃ¬nh chá»n conda thÃ¬ mÃ¬nh cÃ³ thá»ƒ dá»… dÃ ng install nhá»¯ng tháº±ng chÆ°a cÃ³ nhÆ° tensorflow, CUDA, cuDNN, khÃ´ng biáº¿t ráº±ng chá»n pre-install khÃ¡c thÃ¬ thuáº­n lá»£i hÆ¡n khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡!","Em chÃ o má»i ngÆ°á»i, em má»›i dÃ¹ng thá»­ dá»‹ch vá»¥ bÃªn iRender, em thuÃª 1 con GPU RTX-3090, VRAM 24Gb, CPU Xeon-2245, RAM 64Gb . Khi em create image, em cÃ³ chá»n image type lÃ  pre-install software vÃ  chá»n lÃ  conda vÃ¬ em nghÄ© lÃ  em cÃ³ thá»ƒ sá»­ dá»¥ng conda Ä‘á»ƒ táº¡o mÃ´i trÆ°á»ng má»›i thá»a mÃ£n tensorflow-gpu vá»›i cÃ¢u lá»‡nh conda create --name <tÃªn mÃ´i trÆ°á»ng mÃ¬nh Ä‘áº·t> tensorflow-gpu, thÃ¬ nÃ³ tá»± Ä‘á»™ng install giÃºp em má»™t loáº¡t cÃ¡c package trong Ä‘Ã³ cÃ³ cudatoolkit ver 10.1, cudnn ver 7.6.5, tensorflow-base vÃ  tensorflow-gpu ver 2.4. QuÃ¡ trÃ¬nh trÃªn setup máº¥t khoáº£ng 7'. Em muá»‘n há»i má»i ngÆ°á»i má»™t chÃºt áº¡ QuÃ¡ trÃ¬nh setup mÃ´i trÆ°á»ng tensorflow-gpu trÃªn táº§m Ä‘Ã³ cÃ³ pháº£i lÃ  lÃ¢u khÃ´ng áº¡? Náº¿u cÃ³ thá»ƒ cáº£i thiá»‡n thÃ¬ em nÃªn chá»n pre-install cho image type cÃ³ nÃªn lÃ  conda khÃ´ng áº¡? VÃ¬ em tháº¥y ráº±ng cÃ³ cÃ¡c software khÃ¡c nhÆ° há» cho cáº£ CUDA 11.0, cuDNN 8.0.5, hoáº·c tensorflow 2.4? Em nghÄ© lÃ  mÃ¬nh chá»n conda thÃ¬ mÃ¬nh cÃ³ thá»ƒ dá»… dÃ ng install nhá»¯ng tháº±ng chÆ°a cÃ³ nhÆ° tensorflow, CUDA, cuDNN, khÃ´ng biáº¿t ráº±ng chá»n pre-install khÃ¡c thÃ¬ thuáº­n lá»£i hÆ¡n khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡!",,,,,
From three little pigs to ...,From three little pigs to ...,,,,,
"Hi cáº£ nhÃ . MÃ¬nh xin chia sáº» problem solutions cá»§a Stanford's CS229 (2019, 2020), bao gá»“m cáº£ bt code vÃ  bt viáº¿t (latex). PhiÃªn báº£n solutions nÃ y phÃ¹ há»£p vá»›i phiÃªn báº£n gáº§n Ä‘Ã¢y nháº¥t Ä‘Æ°á»£c chia sáº» trÃªn youtube cá»§a khÃ³a nÃ y (Summer 2019). MÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng viáº¿t tÆ°Æ¡ng Ä‘á»‘i chi tiáº¿t, hi vá»ng nÃ³ sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n tá»± há»c.","Hi cáº£ nhÃ . MÃ¬nh xin chia sáº» problem solutions cá»§a Stanford's CS229 (2019, 2020), bao gá»“m cáº£ bt code vÃ  bt viáº¿t (latex). PhiÃªn báº£n solutions nÃ y phÃ¹ há»£p vá»›i phiÃªn báº£n gáº§n Ä‘Ã¢y nháº¥t Ä‘Æ°á»£c chia sáº» trÃªn youtube cá»§a khÃ³a nÃ y (Summer 2019). MÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng viáº¿t tÆ°Æ¡ng Ä‘á»‘i chi tiáº¿t, hi vá»ng nÃ³ sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n tá»± há»c.",,,,,
"Dear anh em,
MÃ¬nh tham diá»…n Ä‘Ã n khÃ¡ lÃ¢u, hÃ´m nay máº¡n phÃ©p xin anh em 1 phÃºt:
MÃ¬nh Ä‘áº¿n tá»« Trung tÃ¢m SÃ¡ng Táº¡o, VNPT: https://icenter.ai/en (120 members, team core lÃ  Ä‘á»™i KÄ© SÆ° TÃ i NÄƒng K52 BKHN), mÃ¬nh vá» nÆ°á»›c sau 8 nÄƒm á»Ÿ Nháº­t vÃ  Ä‘ang giá»¯ vá»‹ trÃ­ Product Leads má»™t sá»‘ sáº£n pháº©m AI (Computer Vision, NLP, Speech, Bigdata):
https://ekyc.vnpt.vn/en
https://smartvision.vnpt.vn/en
https://smartvoice.vnpt.vn
https://smartbot.vnpt.vn/en
https://vnface.vnpt.vn/en
https://smartrpa.vnpt.vn/en
https://vnsocial.vnpt.vn
Má»—i sáº£n pháº©m hiá»‡n táº¡i Ä‘á»u trÃªn dÆ°á»›i vÃ i triá»‡u requests AI xá»­ lÃ½ má»—i ngÃ y, Ä‘a sá»‘ Ä‘á»u cháº¡y docker trÃªn ná»n K8S, cung cáº¥p dÆ°á»›i dáº¡ng SAAS hoáº·c Onpremise. Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng lá»›n vÃ  tiáº¿p tá»¥c tÄƒng dáº§n.
Tuy nhiÃªn Ä‘á»ƒ chinh phá»¥c thá»‹ trÆ°á»ng trong nÆ°á»›c vÃ  hÆ°á»›ng ra quá»‘c táº¿, sáº£n pháº©m Ä‘Ã²i há»i pháº£i tá»‘i Æ°u cáº£i thiá»‡n liÃªn tá»¥c. Hiá»‡n táº¡i bÃªn mÃ¬nh cÅ©ng Ä‘ang hoÃ n thiá»‡n há»‡ thá»‘ng MLOps (https://ml-ops.org/). VÃ  Ä‘áº·c biá»‡t Ä‘ang thai nghÃ©n má»™t sáº£n pháº©m AI káº¿t há»£p táº¥t cáº£ cÃ¡c lÄ©nh vá»±c Ä‘ang cÃ³.
Ráº¥t mong cÃ¡c anh em cÃ³ cÃ¹ng chÃ­ hÆ°á»›ng lÃ m AI Product join cÃ¹ng Ä‘á»ƒ cÃ¹ng nhau chinh phá»¥c cÃ¡c thá»­ thÃ¡ch. BÃªn mÃ¬nh Ä‘ang open ráº¥t nhiá»u vá»‹ trÃ­ AI Researcher, AI Engineer, Data Engineer, Software Engineer, Devops, BA, PM, Tester, UI/UX... vÃ  Ä‘áº·c biá»‡t mong muá»‘n Ä‘á»“ng hÃ nh cÃ¹ng cÃ¡c báº¡n váº«n Ä‘ang lÃ  sinh viÃªn cÃ¡c trÆ°á»ng Ä‘áº¡i há»c qua chÆ°Æ¡ng trÃ¬nh Fresher.
Anh em cÃ³ thá»ƒ apply táº¡i https://icenter.ai/en nhÃ©.
==============
MÃ¬nh chia sáº» thÃªm 1 chÃºt vá» nhá»¯ng cÃ¢u chuyá»‡n thÃº vá»‹ tá»« phÃ­a KhÃ¡ch hÃ ng trong khi lÃ m sáº£n pháº©m AI:
""Anh nhÃ¬n rÃµ tháº¿ nÃ y, nghe rÃµ tháº¿ nÃ y mÃ  AI cá»§a chÃº khÃ´ng xá»­ lÃ½ chÃ­nh xÃ¡c Ä‘Æ°á»£c lÃ  nhÆ° nÃ o? AI pháº£i hÆ¡n ngÆ°á»i chá»©. AI nÃ y Ä‘Ã£ cÃ³ Deep Learning chÆ°a, hay váº«n chá»‰ Machine Learning? Trong vÃ²ng 1-2 ngÃ y, bá»• sung thÃªm tÃ­nh nÄƒng nÃ y cho AI Ä‘Æ°á»£c khÃ´ng?""
""Em cÃ³ thá»ƒ cung cáº¥p 1 há»‡ thá»‘ng onpremise mÃ  anh tá»± tay training model hay khÃ´ng? BÃªn anh cÃ³ GPU khÃ´ng áº¡? KhÃ´ng cÃ³ em Ã . BÃªn anh cÃ³ team Ä‘Ã¡nh nhÃ£n khÃ´ng áº¡? ÄÃ¡nh nhÃ£n lÃ  gÃ¬ váº­y em?â€
""Äá»™ chÃ­nh xÃ¡c lÃ  99.9%, tá»©c lÃ  10000 máº«u sai máº¥t 10 máº«u rá»“i, váº­y ai sáº½ tráº£ tiá»n cho anh vá»›i 10 máº«u nÃ y?""
Khi lÃ m sáº£n pháº©m, nhiá»u khi 99% cÃ´ng sá»©c táº­p trung vÃ o pháº§n non-AI Ä‘á»ƒ 1% AI cÃ³ thá»ƒ phÃ¡t huy sá»©c máº¡nh. VÃ¬ váº­y, Ä‘á»ƒ cÃ³ má»™t sáº£n pháº©m AI thÃ nh cÃ´ng cáº§n ráº¥t nhiá»u yáº¿u tá»‘. ChÃºng ta luÃ´n pháº£i á»Ÿ trong má»™t tÆ° tháº¿ vá»«a láº¯ng nghe, vá»«a há»c há»i, vá»«a cáº£i thiá»‡n, vá»«a chinh phá»¥c khÃ¡ch hÃ ng tá»«ng ngÃ y. NÃ³i chung ráº¥t váº¥t váº£, khÃ´ng há» dá»… dÃ ng má»™t chÃºt nÃ o.
Trong quÃ¡ trÃ¬nh tuyá»ƒn dá»¥ng, náº¿u cÃ³ váº¥n Ä‘á» gÃ¬ thÃ¬ anh em PM mÃ¬nh theo Ä‘á»‹a chá»‰ Email lethaihung89@vnpt.vn nhÃ©. TrÃªn tá»±a Ä‘á» cá»§a email anh em ghi rÃµ ""[Career]..."" Ä‘á»ƒ mÃ¬nh khÃ´ng bá» sÃ³t báº¥t cá»© email nÃ o.
CÃ¡m Æ¡n anh em Ä‘Ã£ Ä‘á»c vÃ  chia sáº».","Dear anh em, MÃ¬nh tham diá»…n Ä‘Ã n khÃ¡ lÃ¢u, hÃ´m nay máº¡n phÃ©p xin anh em 1 phÃºt: MÃ¬nh Ä‘áº¿n tá»« Trung tÃ¢m SÃ¡ng Táº¡o, VNPT: https://icenter.ai/en (120 members, team core lÃ  Ä‘á»™i KÄ© SÆ° TÃ i NÄƒng K52 BKHN), mÃ¬nh vá» nÆ°á»›c sau 8 nÄƒm á»Ÿ Nháº­t vÃ  Ä‘ang giá»¯ vá»‹ trÃ­ Product Leads má»™t sá»‘ sáº£n pháº©m AI (Computer Vision, NLP, Speech, Bigdata): https://ekyc.vnpt.vn/en https://smartvision.vnpt.vn/en https://smartvoice.vnpt.vn https://smartbot.vnpt.vn/en https://vnface.vnpt.vn/en https://smartrpa.vnpt.vn/en https://vnsocial.vnpt.vn Má»—i sáº£n pháº©m hiá»‡n táº¡i Ä‘á»u trÃªn dÆ°á»›i vÃ i triá»‡u requests AI xá»­ lÃ½ má»—i ngÃ y, Ä‘a sá»‘ Ä‘á»u cháº¡y docker trÃªn ná»n K8S, cung cáº¥p dÆ°á»›i dáº¡ng SAAS hoáº·c Onpremise. Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng lá»›n vÃ  tiáº¿p tá»¥c tÄƒng dáº§n. Tuy nhiÃªn Ä‘á»ƒ chinh phá»¥c thá»‹ trÆ°á»ng trong nÆ°á»›c vÃ  hÆ°á»›ng ra quá»‘c táº¿, sáº£n pháº©m Ä‘Ã²i há»i pháº£i tá»‘i Æ°u cáº£i thiá»‡n liÃªn tá»¥c. Hiá»‡n táº¡i bÃªn mÃ¬nh cÅ©ng Ä‘ang hoÃ n thiá»‡n há»‡ thá»‘ng MLOps (https://ml-ops.org/). VÃ  Ä‘áº·c biá»‡t Ä‘ang thai nghÃ©n má»™t sáº£n pháº©m AI káº¿t há»£p táº¥t cáº£ cÃ¡c lÄ©nh vá»±c Ä‘ang cÃ³. Ráº¥t mong cÃ¡c anh em cÃ³ cÃ¹ng chÃ­ hÆ°á»›ng lÃ m AI Product join cÃ¹ng Ä‘á»ƒ cÃ¹ng nhau chinh phá»¥c cÃ¡c thá»­ thÃ¡ch. BÃªn mÃ¬nh Ä‘ang open ráº¥t nhiá»u vá»‹ trÃ­ AI Researcher, AI Engineer, Data Engineer, Software Engineer, Devops, BA, PM, Tester, UI/UX... vÃ  Ä‘áº·c biá»‡t mong muá»‘n Ä‘á»“ng hÃ nh cÃ¹ng cÃ¡c báº¡n váº«n Ä‘ang lÃ  sinh viÃªn cÃ¡c trÆ°á»ng Ä‘áº¡i há»c qua chÆ°Æ¡ng trÃ¬nh Fresher. Anh em cÃ³ thá»ƒ apply táº¡i https://icenter.ai/en nhÃ©. ============== MÃ¬nh chia sáº» thÃªm 1 chÃºt vá» nhá»¯ng cÃ¢u chuyá»‡n thÃº vá»‹ tá»« phÃ­a KhÃ¡ch hÃ ng trong khi lÃ m sáº£n pháº©m AI: ""Anh nhÃ¬n rÃµ tháº¿ nÃ y, nghe rÃµ tháº¿ nÃ y mÃ  AI cá»§a chÃº khÃ´ng xá»­ lÃ½ chÃ­nh xÃ¡c Ä‘Æ°á»£c lÃ  nhÆ° nÃ o? AI pháº£i hÆ¡n ngÆ°á»i chá»©. AI nÃ y Ä‘Ã£ cÃ³ Deep Learning chÆ°a, hay váº«n chá»‰ Machine Learning? Trong vÃ²ng 1-2 ngÃ y, bá»• sung thÃªm tÃ­nh nÄƒng nÃ y cho AI Ä‘Æ°á»£c khÃ´ng?"" ""Em cÃ³ thá»ƒ cung cáº¥p 1 há»‡ thá»‘ng onpremise mÃ  anh tá»± tay training model hay khÃ´ng? BÃªn anh cÃ³ GPU khÃ´ng áº¡? KhÃ´ng cÃ³ em Ã . BÃªn anh cÃ³ team Ä‘Ã¡nh nhÃ£n khÃ´ng áº¡? ÄÃ¡nh nhÃ£n lÃ  gÃ¬ váº­y em?â€ ""Äá»™ chÃ­nh xÃ¡c lÃ  99.9%, tá»©c lÃ  10000 máº«u sai máº¥t 10 máº«u rá»“i, váº­y ai sáº½ tráº£ tiá»n cho anh vá»›i 10 máº«u nÃ y?"" Khi lÃ m sáº£n pháº©m, nhiá»u khi 99% cÃ´ng sá»©c táº­p trung vÃ o pháº§n non-AI Ä‘á»ƒ 1% AI cÃ³ thá»ƒ phÃ¡t huy sá»©c máº¡nh. VÃ¬ váº­y, Ä‘á»ƒ cÃ³ má»™t sáº£n pháº©m AI thÃ nh cÃ´ng cáº§n ráº¥t nhiá»u yáº¿u tá»‘. ChÃºng ta luÃ´n pháº£i á»Ÿ trong má»™t tÆ° tháº¿ vá»«a láº¯ng nghe, vá»«a há»c há»i, vá»«a cáº£i thiá»‡n, vá»«a chinh phá»¥c khÃ¡ch hÃ ng tá»«ng ngÃ y. NÃ³i chung ráº¥t váº¥t váº£, khÃ´ng há» dá»… dÃ ng má»™t chÃºt nÃ o. Trong quÃ¡ trÃ¬nh tuyá»ƒn dá»¥ng, náº¿u cÃ³ váº¥n Ä‘á» gÃ¬ thÃ¬ anh em PM mÃ¬nh theo Ä‘á»‹a chá»‰ Email lethaihung89@vnpt.vn nhÃ©. TrÃªn tá»±a Ä‘á» cá»§a email anh em ghi rÃµ ""[Career]..."" Ä‘á»ƒ mÃ¬nh khÃ´ng bá» sÃ³t báº¥t cá»© email nÃ o. CÃ¡m Æ¡n anh em Ä‘Ã£ Ä‘á»c vÃ  chia sáº».",,,,,
"Má»i ngÆ°á»i cho em há»i, em cÃ³ capture mÃ n hÃ¬nh vá»›i opencv (capture cá»­a sá»• zoom meeting) nhÆ°ng hÃ¬nh áº£nh capture khÃ´ng cÃ³ real time nhÆ° trÃªn cá»­a sá»•. CÃ³ cÃ¡ch nÃ o xá»­ lÃ½ khÃ´ng áº¡. Vá»›i láº¡i cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ phÃ¢n biá»‡t 1 áº£nh tÄ©nh vÃ  1 áº£nh Ä‘á»™ng khÃ´ng áº¡.
Em cÃ¡m Æ¡n má»i ngÆ°á»i","Má»i ngÆ°á»i cho em há»i, em cÃ³ capture mÃ n hÃ¬nh vá»›i opencv (capture cá»­a sá»• zoom meeting) nhÆ°ng hÃ¬nh áº£nh capture khÃ´ng cÃ³ real time nhÆ° trÃªn cá»­a sá»•. CÃ³ cÃ¡ch nÃ o xá»­ lÃ½ khÃ´ng áº¡. Vá»›i láº¡i cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ phÃ¢n biá»‡t 1 áº£nh tÄ©nh vÃ  1 áº£nh Ä‘á»™ng khÃ´ng áº¡. Em cÃ¡m Æ¡n má»i ngÆ°á»i",,,,,
"Dáº¡ em xin chÃ o anh chá»‹. Nay em cÃ³ má»™t váº¥n Ä‘á» Ä‘ang bá»‹ bÃ­, mong anh chá»‹ chá»‰ dáº¡y em.
Em Ä‘ang nghiÃªn cá»©u vá» Hidden Markov Model vÃ  thuáº­t toÃ¡n Baum Welch. Thuáº­t toÃ¡n thÃ¬ hiá»‡n táº¡i em Ä‘Ã£ code xong rá»“i, vÃ  em Ä‘Ã£ thá»­ cÃ¡c cÃ¡ch implement khÃ¡c nhau, Ä‘á»ƒ trÃ¡nh bá»‹ lá»—i code. NhÆ°ng em Ä‘ang gáº·p váº¥n Ä‘á» vá»›i viá»‡c há»™i tá»¥ vÃ  káº¿t quáº£ cá»§a thuáº­t toÃ¡n. Cá»¥ thá»ƒ lÃ  khi em khá»Ÿi táº¡o cÃ¡c ma tráº­n init probability (PI), transition probability (A) vÃ  emission probability ( B ) khÃ¡c nhau thÃ¬ sau 100 láº§n láº·p thuáº­t toÃ¡n Baum Welch cá»§a em Ä‘á»u Ä‘Æ°a ra 3 bá»™ PI, A, B khÃ¡c nhau. Ká»ƒ cáº£ em Ä‘Ã£ thá»­ cho cháº¡y vÃ´ háº¡n vÃ  chá»‰ dá»«ng khi norm 2 cá»§a PI, A, B vá»›i bá»™ PI, A, B cÅ© cÃ³ sai sá»‘ dÆ°á»›i 1e-6 nhÆ°ng cÃ³ váº» khá»Ÿi táº¡o khÃ¡c nhau cÅ©ng Ä‘Æ°a ra cÃ¡c káº¿t quáº£ cá»§a PI, A, B Ä‘á»u khÃ¡c nhau.
Em xin há»i lÃ  cÃ³ cÃ¡ch nÃ o biáº¿t bá»™ PI, A, B khá»Ÿi táº¡o hiá»‡n táº¡i lÃ  tá»‘t nháº¥t khÃ´ng vÃ  tiÃªu chÃ­ Ä‘á»ƒ há»™i tá»¥ cho thuáº­t toÃ¡n Baum Welch lÃ  gÃ¬ hay chá»‰ cáº§n cháº¡y Ä‘Ãºng 100 láº§n lÃ  Ä‘Æ°á»£c.
Em xin cáº£m Æ¡n anh chá»‹ trÆ°á»›c áº¡.","Dáº¡ em xin chÃ o anh chá»‹. Nay em cÃ³ má»™t váº¥n Ä‘á» Ä‘ang bá»‹ bÃ­, mong anh chá»‹ chá»‰ dáº¡y em. Em Ä‘ang nghiÃªn cá»©u vá» Hidden Markov Model vÃ  thuáº­t toÃ¡n Baum Welch. Thuáº­t toÃ¡n thÃ¬ hiá»‡n táº¡i em Ä‘Ã£ code xong rá»“i, vÃ  em Ä‘Ã£ thá»­ cÃ¡c cÃ¡ch implement khÃ¡c nhau, Ä‘á»ƒ trÃ¡nh bá»‹ lá»—i code. NhÆ°ng em Ä‘ang gáº·p váº¥n Ä‘á» vá»›i viá»‡c há»™i tá»¥ vÃ  káº¿t quáº£ cá»§a thuáº­t toÃ¡n. Cá»¥ thá»ƒ lÃ  khi em khá»Ÿi táº¡o cÃ¡c ma tráº­n init probability (PI), transition probability (A) vÃ  emission probability ( B ) khÃ¡c nhau thÃ¬ sau 100 láº§n láº·p thuáº­t toÃ¡n Baum Welch cá»§a em Ä‘á»u Ä‘Æ°a ra 3 bá»™ PI, A, B khÃ¡c nhau. Ká»ƒ cáº£ em Ä‘Ã£ thá»­ cho cháº¡y vÃ´ háº¡n vÃ  chá»‰ dá»«ng khi norm 2 cá»§a PI, A, B vá»›i bá»™ PI, A, B cÅ© cÃ³ sai sá»‘ dÆ°á»›i 1e-6 nhÆ°ng cÃ³ váº» khá»Ÿi táº¡o khÃ¡c nhau cÅ©ng Ä‘Æ°a ra cÃ¡c káº¿t quáº£ cá»§a PI, A, B Ä‘á»u khÃ¡c nhau. Em xin há»i lÃ  cÃ³ cÃ¡ch nÃ o biáº¿t bá»™ PI, A, B khá»Ÿi táº¡o hiá»‡n táº¡i lÃ  tá»‘t nháº¥t khÃ´ng vÃ  tiÃªu chÃ­ Ä‘á»ƒ há»™i tá»¥ cho thuáº­t toÃ¡n Baum Welch lÃ  gÃ¬ hay chá»‰ cáº§n cháº¡y Ä‘Ãºng 100 láº§n lÃ  Ä‘Æ°á»£c. Em xin cáº£m Æ¡n anh chá»‹ trÆ°á»›c áº¡.",,,,,
"Em chÃ o cÃ¡c ac.
Láº§n trÆ°á»›c em cÃ³ Ä‘Äƒng bÃ i vÃ  Ä‘Æ°á»£c cÃ¡c ac hÆ°á»›ng dáº«n cÃ³ thá»ƒ cÃ i tool cá»§a anh Viet Anh Tran
https://github.com/coinForRich/coin-for-rich?fbclid=IwAR3fWKHQHJOovIHljjSqILS14IKKLI_ti3mdag4ZLHpyjqsgwT8T8fN2J0U#quickstart
Em Ä‘Ã£ thá»±c hiá»‡n, cháº¡y ra Ä‘Æ°á»£c biá»ƒu Ä‘á»“ náº¿n nhÆ° hÃ¬nh 1. NhÆ°ng káº¿t quáº£ hiá»‡n em cáº§n lÃ  báº£ng biá»ƒu thá»‹ thá»i gian thá»±c, high, low... (hÃ¬nh 2) mÃ  e ko biáº¿t lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ nhÆ° váº­y. Mong cÃ¡c ac cÃ³ thá»ƒ xem qua vÃ  há»— trá»£ giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡.
Em xin cáº£m Æ¡n ráº¥t nhiá»u!!!","Em chÃ o cÃ¡c ac. Láº§n trÆ°á»›c em cÃ³ Ä‘Äƒng bÃ i vÃ  Ä‘Æ°á»£c cÃ¡c ac hÆ°á»›ng dáº«n cÃ³ thá»ƒ cÃ i tool cá»§a anh Viet Anh Tran https://github.com/coinForRich/coin-for-rich?fbclid=IwAR3fWKHQHJOovIHljjSqILS14IKKLI_ti3mdag4ZLHpyjqsgwT8T8fN2J0U#quickstart Em Ä‘Ã£ thá»±c hiá»‡n, cháº¡y ra Ä‘Æ°á»£c biá»ƒu Ä‘á»“ náº¿n nhÆ° hÃ¬nh 1. NhÆ°ng káº¿t quáº£ hiá»‡n em cáº§n lÃ  báº£ng biá»ƒu thá»‹ thá»i gian thá»±c, high, low... (hÃ¬nh 2) mÃ  e ko biáº¿t lÃ m tháº¿ nÃ o Ä‘á»ƒ cÃ³ thá»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ nhÆ° váº­y. Mong cÃ¡c ac cÃ³ thá»ƒ xem qua vÃ  há»— trá»£ giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n ráº¥t nhiá»u!!!",,,,,
"Em chÃ o má»i ngÆ°á»i, em cÃ³ má»™t tháº¯c máº¯c nhá».
Má»i ngÆ°á»i cho em há»i báº£n dá»‹ch cuá»‘n sÃ¡ch cá»§a Ian Goodfellow cá»§a dá»± Ã¡n https://dlbookvn.gitlab.io/deeplearning/ cÃ²n available hay public khÃ´ng áº¡, vÃ  náº¿u available thÃ¬ muá»‘n truy cáº­p vÃ o thÃ¬ em cÃ³ thá»ƒ lÃ m nhÆ° tháº¿ nÃ o áº¡, em cáº£m Æ¡n má»i ngÆ°á»i.","Em chÃ o má»i ngÆ°á»i, em cÃ³ má»™t tháº¯c máº¯c nhá». Má»i ngÆ°á»i cho em há»i báº£n dá»‹ch cuá»‘n sÃ¡ch cá»§a Ian Goodfellow cá»§a dá»± Ã¡n https://dlbookvn.gitlab.io/deeplearning/ cÃ²n available hay public khÃ´ng áº¡, vÃ  náº¿u available thÃ¬ muá»‘n truy cáº­p vÃ o thÃ¬ em cÃ³ thá»ƒ lÃ m nhÆ° tháº¿ nÃ o áº¡, em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"ChÃ o má»i ngÆ°á»i! TÃ´i tÃªn lÃ  Sergey Ä‘ang lÃ m viá»‡c quáº£n lÃ½ Search Platform á»Ÿ TIKI. ÄÃ¢y lÃ  1 bÃ i viáº¿t chia sáº» phÆ°Æ¡ng phÃ¡p A/B testing cá»§a Tiki Search. BÃ i nÃ y sáº½ giá»›i thiá»‡u cÃ¡c báº¡n vá»›i nhá»¯ng phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ káº¿t quáº£ A/B test vÃ  nhá»¯ng metric nhÆ° sensitivity vÃ  false positive rate Ä‘á»ƒ chá»n 1 phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t vá»›i domain riÃªng cá»§a cÃ¡c báº¡n.
Má»i má»i ngÆ°á»i Ä‘á»c bÃ i vÃ  giao lÆ°u feedback vá»›i. :)",ChÃ o má»i ngÆ°á»i! TÃ´i tÃªn lÃ  Sergey Ä‘ang lÃ m viá»‡c quáº£n lÃ½ Search Platform á»Ÿ TIKI. ÄÃ¢y lÃ  1 bÃ i viáº¿t chia sáº» phÆ°Æ¡ng phÃ¡p A/B testing cá»§a Tiki Search. BÃ i nÃ y sáº½ giá»›i thiá»‡u cÃ¡c báº¡n vá»›i nhá»¯ng phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ káº¿t quáº£ A/B test vÃ  nhá»¯ng metric nhÆ° sensitivity vÃ  false positive rate Ä‘á»ƒ chá»n 1 phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t vá»›i domain riÃªng cá»§a cÃ¡c báº¡n. Má»i má»i ngÆ°á»i Ä‘á»c bÃ i vÃ  giao lÆ°u feedback vá»›i. :),,,,,
"Dáº¡ em chÃ o cÃ¡c Anh/ Chá»‹
Em Ä‘ang lÃ m vá» há»‡ thá»‘ng tÆ° váº¥n khoÃ¡ há»c dá»±a trÃªn skill thiáº¿u. Em cÃ³ má»™t vÃ i tháº¯c máº¯c mong nháº­n Ä‘Æ°á»£c sá»± chá»‰ dáº¡y tá»« anh/ Chá»‹
Äáº§u tiÃªn: Em cÃ³ táº­p cÃ¡c ká»¹ nÄƒng Ä‘Æ°á»£c Ä‘Ã¡nh theo trá»ng sá»‘ (trá»ng sá»‘ thá»ƒ hiá»‡n má»©c Ä‘á»™ quan trá»ng) vd, Python:5, C#:3, R:1 (thÃ¬ python quan trá»ng nháº¥t). em tÃ­nh sum_weight (tá»•ng trá»ng sá»‘ á»©ng vá»›i cÃ¡c skill trong khoÃ¡ há»c). Num_Tech_Remain lÃ  cÃ¡c skill cÃ²n láº¡i mÃ  khoÃ¡ há»c cung cáº¥p.
Em sáº½ lá»±a nhá»¯ng khoÃ¡ há»c chá»©a nhá»¯ng skill thiáº¿u (má»™t khoÃ¡ há»c cÃ³ thá»ƒ cung cáº¥p 1 hoáº·c nhiá»u skill thiáº¿u). Äá»ƒ chá»n 1 khoÃ¡ há»c tÆ° váº¥n, em dá»±a trÃªn cÃ¡c tiÃªu chÃ­ nhÆ°: Æ°u tiÃªn duyá»‡t skill quan trá»ng, khoÃ¡ há»c nÃ o cung cáº¥p nhiá»u skill, Ä‘á»™ rating khoÃ¡ há»c cao, sá»‘ ngÆ°á»i há»c khoÃ¡ há»c Ä‘Ã³ nhiá»u (nhÆ°ng em gáº·p trÆ°á»ng há»£p rating cao nhÆ°ng sá»‘ ngÆ°á»i há»c láº¡i tháº¥p), ngÆ°á»i há»c cÃ³ thá»ƒ chá»n há»c cÃ¡c course trong má»™t thá»i gian nÃ o Ä‘Ã³ (vd 3 thÃ¡ng) hoáº·c náº±m trong khoáº£ng chi phÃ­ cÃ³ thá»ƒ bá» ra (5 triá»‡u).
Em Ä‘ang phÃ¢n vÃ¢n khÃ´ng biáº¿t mÃ¬nh nÃªn Ä‘á» ra cÃ´ng thá»©c nÃ o Ä‘á»ƒ cÃ³ sá»± chá»n lá»±a course tÆ° váº¥n phÃ¹ há»£p. Em ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± chá»‰ dáº¡y tá»« anh/ chá»‹.","Dáº¡ em chÃ o cÃ¡c Anh/ Chá»‹ Em Ä‘ang lÃ m vá» há»‡ thá»‘ng tÆ° váº¥n khoÃ¡ há»c dá»±a trÃªn skill thiáº¿u. Em cÃ³ má»™t vÃ i tháº¯c máº¯c mong nháº­n Ä‘Æ°á»£c sá»± chá»‰ dáº¡y tá»« anh/ Chá»‹ Äáº§u tiÃªn: Em cÃ³ táº­p cÃ¡c ká»¹ nÄƒng Ä‘Æ°á»£c Ä‘Ã¡nh theo trá»ng sá»‘ (trá»ng sá»‘ thá»ƒ hiá»‡n má»©c Ä‘á»™ quan trá»ng) vd, Python:5, C#:3, R:1 (thÃ¬ python quan trá»ng nháº¥t). em tÃ­nh sum_weight (tá»•ng trá»ng sá»‘ á»©ng vá»›i cÃ¡c skill trong khoÃ¡ há»c). Num_Tech_Remain lÃ  cÃ¡c skill cÃ²n láº¡i mÃ  khoÃ¡ há»c cung cáº¥p. Em sáº½ lá»±a nhá»¯ng khoÃ¡ há»c chá»©a nhá»¯ng skill thiáº¿u (má»™t khoÃ¡ há»c cÃ³ thá»ƒ cung cáº¥p 1 hoáº·c nhiá»u skill thiáº¿u). Äá»ƒ chá»n 1 khoÃ¡ há»c tÆ° váº¥n, em dá»±a trÃªn cÃ¡c tiÃªu chÃ­ nhÆ°: Æ°u tiÃªn duyá»‡t skill quan trá»ng, khoÃ¡ há»c nÃ o cung cáº¥p nhiá»u skill, Ä‘á»™ rating khoÃ¡ há»c cao, sá»‘ ngÆ°á»i há»c khoÃ¡ há»c Ä‘Ã³ nhiá»u (nhÆ°ng em gáº·p trÆ°á»ng há»£p rating cao nhÆ°ng sá»‘ ngÆ°á»i há»c láº¡i tháº¥p), ngÆ°á»i há»c cÃ³ thá»ƒ chá»n há»c cÃ¡c course trong má»™t thá»i gian nÃ o Ä‘Ã³ (vd 3 thÃ¡ng) hoáº·c náº±m trong khoáº£ng chi phÃ­ cÃ³ thá»ƒ bá» ra (5 triá»‡u). Em Ä‘ang phÃ¢n vÃ¢n khÃ´ng biáº¿t mÃ¬nh nÃªn Ä‘á» ra cÃ´ng thá»©c nÃ o Ä‘á»ƒ cÃ³ sá»± chá»n lá»±a course tÆ° váº¥n phÃ¹ há»£p. Em ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± chá»‰ dáº¡y tá»« anh/ chá»‹.",,,,,
"CÃ³ thÆ° viá»‡n nÃ o train dataset cho há»“i quy phi tuyáº¿n váº­y mn?
Em cáº£m Æ¡n",CÃ³ thÆ° viá»‡n nÃ o train dataset cho há»“i quy phi tuyáº¿n váº­y mn? Em cáº£m Æ¡n,,,,,
"#NLP
MÃ¬nh khÃ´ng pháº£i dÃ¢n AI hay NLP nhÆ°ng hiá»‡n táº¡i, mÃ¬nh Ä‘ang cáº§n lÃ m má»™t bá»™ lá»c tá»« ngá»¯ thÃ´ tá»¥c trong Tiáº¿ng Viá»‡t, theo hÆ°á»›ng sáº½ loáº¡i bá» comment Ä‘Ã³ náº¿u nÃ³ cÃ³ Ã½ nghÄ©a thÃ´ tá»¥c vÃ­ dá»¥ ""MÃ y bá»‹ Ä‘iÃªn Ã "" lÃ  cÃ¢u cáº§n loáº¡i bá» trong khi ""TÃ´i thÃ­ch cÃ¡i nÃ y phÃ¡t Ä‘iÃªn"" thÃ¬ giá»¯ láº¡i, ai cÃ³ giáº£i phÃ¡p hay hÆ°á»›ng Ä‘i gÃ¬ thÃ¬ cho mÃ¬nh biáº¿t vá»›i áº¡, mÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i.","MÃ¬nh khÃ´ng pháº£i dÃ¢n AI hay NLP nhÆ°ng hiá»‡n táº¡i, mÃ¬nh Ä‘ang cáº§n lÃ m má»™t bá»™ lá»c tá»« ngá»¯ thÃ´ tá»¥c trong Tiáº¿ng Viá»‡t, theo hÆ°á»›ng sáº½ loáº¡i bá» comment Ä‘Ã³ náº¿u nÃ³ cÃ³ Ã½ nghÄ©a thÃ´ tá»¥c vÃ­ dá»¥ ""MÃ y bá»‹ Ä‘iÃªn Ã "" lÃ  cÃ¢u cáº§n loáº¡i bá» trong khi ""TÃ´i thÃ­ch cÃ¡i nÃ y phÃ¡t Ä‘iÃªn"" thÃ¬ giá»¯ láº¡i, ai cÃ³ giáº£i phÃ¡p hay hÆ°á»›ng Ä‘i gÃ¬ thÃ¬ cho mÃ¬nh biáº¿t vá»›i áº¡, mÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i.",#NLP,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 2/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 2/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"anh chá»‹ cho e há»i ngu nÃ y vá»›i áº¡?
Do láº§n Ä‘áº§u e dÃ¹ng Ä‘áº¿n train model nÃªn e ko rÃµ mong anh chá»‹ giÃºp Ä‘á»¡ áº¡.
TÃ¬nh hÃ¬nh lÃ  e Ä‘ang lÃ m 1 á»©ng dá»¥ng hoáº·c 1 web dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u. E cÃ³ láº¥y Ä‘Æ°á»£c dá»¯ liá»‡u cá»• phiáº¿u cá»§a nhiá»u cÃ´ng ty khÃ¡c nhau, má»—i cty lÃ  1 file csv. Váº­y má»—i má»™t cÃ´ng ty e pháº£i Ä‘á»c tá»«ng file csv, vÃ  cÅ©ng pháº£i gá»i hÃ m train cho tá»«ng file riÃªng luÃ´n hay sao áº¡?
VÃ  náº¿u khi Ä‘Ã£ train xong thÃ¬ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh sá»­ dá»¥ng cho á»©ng dá»¥ng mÃ¬nh áº¡. E cáº£m Æ¡n áº¡.","anh chá»‹ cho e há»i ngu nÃ y vá»›i áº¡? Do láº§n Ä‘áº§u e dÃ¹ng Ä‘áº¿n train model nÃªn e ko rÃµ mong anh chá»‹ giÃºp Ä‘á»¡ áº¡. TÃ¬nh hÃ¬nh lÃ  e Ä‘ang lÃ m 1 á»©ng dá»¥ng hoáº·c 1 web dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u. E cÃ³ láº¥y Ä‘Æ°á»£c dá»¯ liá»‡u cá»• phiáº¿u cá»§a nhiá»u cÃ´ng ty khÃ¡c nhau, má»—i cty lÃ  1 file csv. Váº­y má»—i má»™t cÃ´ng ty e pháº£i Ä‘á»c tá»«ng file csv, vÃ  cÅ©ng pháº£i gá»i hÃ m train cho tá»«ng file riÃªng luÃ´n hay sao áº¡? VÃ  náº¿u khi Ä‘Ã£ train xong thÃ¬ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh sá»­ dá»¥ng cho á»©ng dá»¥ng mÃ¬nh áº¡. E cáº£m Æ¡n áº¡.",,,,,
"Share cÃ´ng cá»¥ - á»©ng dá»¥ng thu tháº­p dá»¯ liá»‡u cryptocurrencies - dÃ nh cho cÃ¡c báº¡n muá»‘n phÃ¢n tÃ­ch dá»¯ liá»‡u thá»i gian thá»±c/dá»¯ liá»‡u time series: https://github.com/coinForRich/coin-for-rich (cÃ¡i tÃªn lÃ  mÃ¬nh vÃ  Vuong Hoai Nam há»©ng lÃªn nghÄ© ra lÃºc Ä‘áº§u vÃ  giá» khÃ´ng Ä‘á»•i Ä‘Æ°á»£c ğŸ˜‚)
CÃ¡c tÃ­nh nÄƒng ná»•i báº­t:
â˜‘ï¸ Fully containerized nhá» Docker Compose
â˜‘ï¸ KÃ©o dá»¯ liá»‡u thá»i gian thá»±c tá»« websockets vÃ  dá»¯ liá»‡u lá»‹ch sá»­ tá»« REST APIs cá»§a 3 sÃ n: Binance, Bitfinex vÃ  Bittrex
â˜‘ï¸ Database cho dá»¯ liá»‡u kÃ©o vá» Ä‘Æ°á»£c auto dá»±ng schema ngay tá»« Ä‘áº§u vÃ  sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng
â˜‘ï¸ á»¨ng dá»¥ng cÃ³ cÃ¡c Ä‘áº§u API ná»‘i ra tá»« Postgresql, Redis, web (websocket + REST API), giÃºp báº¡n cÃ³ thá»ƒ dá»… dÃ ng xÃ¢y dá»±ng á»©ng dá»¥ng phÃ¢n tÃ­ch dá»¯ liá»‡u cá»§a riÃªng báº¡n
â˜‘ï¸ Biá»ƒu Ä‘á»“ náº¿n hiá»ƒn thá»‹ giÃ¡ thá»i gian thá»±c theo tá»«ng phÃºt hoáº·c tá»«ng khoáº£ng thá»i gian Ä‘Æ°á»£c Ä‘á»‹nh sáºµn
â˜‘ï¸ Äá»“ng thá»i cÅ©ng nhá» Docker Compose, báº¡n cÃ³ thá»ƒ tuá»³ chá»‰nh á»©ng dá»¥ng theo Ã½ mÃ¬nh vÃ  cháº¡y láº¡i ngay trÃªn database Ä‘Ã£ Ä‘Æ°á»£c kÃ©o","Share cÃ´ng cá»¥ - á»©ng dá»¥ng thu tháº­p dá»¯ liá»‡u cryptocurrencies - dÃ nh cho cÃ¡c báº¡n muá»‘n phÃ¢n tÃ­ch dá»¯ liá»‡u thá»i gian thá»±c/dá»¯ liá»‡u time series: https://github.com/coinForRich/coin-for-rich (cÃ¡i tÃªn lÃ  mÃ¬nh vÃ  Vuong Hoai Nam há»©ng lÃªn nghÄ© ra lÃºc Ä‘áº§u vÃ  giá» khÃ´ng Ä‘á»•i Ä‘Æ°á»£c ) CÃ¡c tÃ­nh nÄƒng ná»•i báº­t: Fully containerized nhá» Docker Compose KÃ©o dá»¯ liá»‡u thá»i gian thá»±c tá»« websockets vÃ  dá»¯ liá»‡u lá»‹ch sá»­ tá»« REST APIs cá»§a 3 sÃ n: Binance, Bitfinex vÃ  Bittrex Database cho dá»¯ liá»‡u kÃ©o vá» Ä‘Æ°á»£c auto dá»±ng schema ngay tá»« Ä‘áº§u vÃ  sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng á»¨ng dá»¥ng cÃ³ cÃ¡c Ä‘áº§u API ná»‘i ra tá»« Postgresql, Redis, web (websocket + REST API), giÃºp báº¡n cÃ³ thá»ƒ dá»… dÃ ng xÃ¢y dá»±ng á»©ng dá»¥ng phÃ¢n tÃ­ch dá»¯ liá»‡u cá»§a riÃªng báº¡n Biá»ƒu Ä‘á»“ náº¿n hiá»ƒn thá»‹ giÃ¡ thá»i gian thá»±c theo tá»«ng phÃºt hoáº·c tá»«ng khoáº£ng thá»i gian Ä‘Æ°á»£c Ä‘á»‹nh sáºµn Äá»“ng thá»i cÅ©ng nhá» Docker Compose, báº¡n cÃ³ thá»ƒ tuá»³ chá»‰nh á»©ng dá»¥ng theo Ã½ mÃ¬nh vÃ  cháº¡y láº¡i ngay trÃªn database Ä‘Ã£ Ä‘Æ°á»£c kÃ©o",,,,,
"Xin chÃ o táº¥t cáº£ má»i ngÆ°á»i. MÃ¬nh cÃ³ 1 cÃ¢u há»i liÃªn quan Ä‘áº¿n DS role.
Introduce background cá»§a mÃ¬nh 1 chÃºt:
- MÃ¬nh cÃ³ kinh nghiá»‡m lÃ m vá» ML Ä‘Æ°á»£c 3-5 nÄƒm.
- LÃ m chá»§ yáº¿u vá» NLP.
Gáº§n Ä‘Ã¢y mÃ¬nh muá»‘n Ä‘i sÃ¢u hÆ¡n vá» tháº¿ giá»›i ML Ä‘á»ƒ hiá»ƒu báº£n cháº¥t cá»§a data vÃ  láº¥y insight tá»« data.
MÃ¬nh nghÄ© hÆ°á»›ng vá» lÃ¢u dÃ i náº¿u mÃ¬nh Ä‘i vá» DS sáº½ phÃ¹ há»£p. NÃªn mÃ¬nh muá»‘n há»i trÃªn thá»±c táº¿, cÃ¡c báº¡n DS lÃ m viá»‡c á»Ÿ cÃ´ng ty thÃ¬ cÃ³ Ä‘á»¥ng nhiá»u vá»:
- CÃ³ Ã¡p dá»¥ng Statistic / Math Ä‘á»ƒ hiá»ƒu vá» data hay khÃ´ng.
- CÃ´ng viá»‡c thÆ°á»ng nháº­t lÃ m lÃ  gÃ¬?
- DS cÃ³ Ä‘á»¥ng nhiá»u vá» ML vÃ  dÃ¹ng ML Ä‘á»ƒ mining insight hay k.
MÃ¬nh ráº¥t mÃ¹ má» vá» cÃ´ng viá»‡c thá»±c táº¿ cá»§a DS role, ráº¥t mong cÃ¡c báº¡n cÃ³ thá»ƒ chia sáº» vá» gÃ³c nhÃ¬n cho váº¥n Ä‘á» nÃ y.
MÃ¬nh xin cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c bÃ i nÃ y. Thanks","Xin chÃ o táº¥t cáº£ má»i ngÆ°á»i. MÃ¬nh cÃ³ 1 cÃ¢u há»i liÃªn quan Ä‘áº¿n DS role. Introduce background cá»§a mÃ¬nh 1 chÃºt: - MÃ¬nh cÃ³ kinh nghiá»‡m lÃ m vá» ML Ä‘Æ°á»£c 3-5 nÄƒm. - LÃ m chá»§ yáº¿u vá» NLP. Gáº§n Ä‘Ã¢y mÃ¬nh muá»‘n Ä‘i sÃ¢u hÆ¡n vá» tháº¿ giá»›i ML Ä‘á»ƒ hiá»ƒu báº£n cháº¥t cá»§a data vÃ  láº¥y insight tá»« data. MÃ¬nh nghÄ© hÆ°á»›ng vá» lÃ¢u dÃ i náº¿u mÃ¬nh Ä‘i vá» DS sáº½ phÃ¹ há»£p. NÃªn mÃ¬nh muá»‘n há»i trÃªn thá»±c táº¿, cÃ¡c báº¡n DS lÃ m viá»‡c á»Ÿ cÃ´ng ty thÃ¬ cÃ³ Ä‘á»¥ng nhiá»u vá»: - CÃ³ Ã¡p dá»¥ng Statistic / Math Ä‘á»ƒ hiá»ƒu vá» data hay khÃ´ng. - CÃ´ng viá»‡c thÆ°á»ng nháº­t lÃ m lÃ  gÃ¬? - DS cÃ³ Ä‘á»¥ng nhiá»u vá» ML vÃ  dÃ¹ng ML Ä‘á»ƒ mining insight hay k. MÃ¬nh ráº¥t mÃ¹ má» vá» cÃ´ng viá»‡c thá»±c táº¿ cá»§a DS role, ráº¥t mong cÃ¡c báº¡n cÃ³ thá»ƒ chia sáº» vá» gÃ³c nhÃ¬n cho váº¥n Ä‘á» nÃ y. MÃ¬nh xin cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c bÃ i nÃ y. Thanks",,,,,
"ChÃ o má»i ngÆ°á»i!
Má»i ngÆ°á»i trong nhÃ³m Ä‘Ã£ ai thá»­ chuyá»ƒn thÃ nh cÃ´ng model weight cá»§a pytorch (.pth) qua model cá»§a TF (.pb) chÆ°a áº¡. CÃ³ thá»ƒ cho em xin git hÆ°á»›ng dáº«n hoáº·c notebook tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡!
Em Ä‘Ã£ thá»­ covert báº±ng https://github.com/kalaspuffar/onnx-convert-example vÃ  https://quq99.github.io/blog/2019-08/onnx-convert-trained-pytorch-model-to-tensorflow-model/ nhÆ°ng khÃ´ng Ä‘c áº¡!
Thanks m,n!
Model e train vá»›i pre detectron2 : https://github.com/facebookresearch","ChÃ o má»i ngÆ°á»i! Má»i ngÆ°á»i trong nhÃ³m Ä‘Ã£ ai thá»­ chuyá»ƒn thÃ nh cÃ´ng model weight cá»§a pytorch (.pth) qua model cá»§a TF (.pb) chÆ°a áº¡. CÃ³ thá»ƒ cho em xin git hÆ°á»›ng dáº«n hoáº·c notebook tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡! Em Ä‘Ã£ thá»­ covert báº±ng https://github.com/kalaspuffar/onnx-convert-example vÃ  https://quq99.github.io/blog/2019-08/onnx-convert-trained-pytorch-model-to-tensorflow-model/ nhÆ°ng khÃ´ng Ä‘c áº¡! Thanks m,n! Model e train vá»›i pre detectron2 : https://github.com/facebookresearch",,,,,
Free event to learn more about data-centric AI tomorrow (with Alex Ratner & Andrew Ng),Free event to learn more about data-centric AI tomorrow (with Alex Ratner & Andrew Ng),,,,,
"ChÃ o má»i ngÆ°á»i
Em hiá»‡n Ä‘ang nghiÃªn cá»©u vá» Ä‘á» tÃ i Social Recommendation sá»­ dá»¥ng Graph Neural Network. Anh chá»‹ nÃ o cÃ³ tá»«ng nghiÃªn cá»©u vá» Ä‘á» tÃ i nÃ y cÃ³ thá»ƒ cho em xin nguá»“n tÃ i liá»‡u tham kháº£o vá»›i áº¡. Em cáº£m Æ¡n",ChÃ o má»i ngÆ°á»i Em hiá»‡n Ä‘ang nghiÃªn cá»©u vá» Ä‘á» tÃ i Social Recommendation sá»­ dá»¥ng Graph Neural Network. Anh chá»‹ nÃ o cÃ³ tá»«ng nghiÃªn cá»©u vá» Ä‘á» tÃ i nÃ y cÃ³ thá»ƒ cho em xin nguá»“n tÃ i liá»‡u tham kháº£o vá»›i áº¡. Em cáº£m Æ¡n,,,,,
"Trong bÃ i bÃ¡o nÃ y (https://arxiv.org/pdf/2004.03844.pdf) há» chá»‰ ra ráº±ng chÃºng ta cÃ³ thá»ƒ bá» bá»›t má»™t sá»‘ layers cá»§a model bert mÃ  káº¿t quáº£ váº«n cÃ²n cháº¥p nháº­n Ä‘Æ°á»£c. Æ¯u Ä‘iá»ƒm lÃ  háº¡n cháº¿ Ä‘Æ°á»£c thá»i gian train trÃªn cÃ¡c GPU.
Cho mÃ¬nh há»i: Náº¿u muá»‘n drop bá»›t má»™t sá»‘ layers cá»§a bert nhÆ° trong bÃ i bÃ¡o thÃ¬ pháº£i lÃ m nhÆ° tháº¿ nÃ o trong code pháº§n model?
MÃ¬nh cáº§n cháº¡y thá»­ viá»‡c train cÃ³ Ä‘Ãºng lÃ  nhanh hÆ¡n vÃ  dung lÆ°á»£ng save checkpoint cá»§a bert sáº½ giáº£m khÃ´ng?
Xin cáº£m Æ¡n.",Trong bÃ i bÃ¡o nÃ y (https://arxiv.org/pdf/2004.03844.pdf) há» chá»‰ ra ráº±ng chÃºng ta cÃ³ thá»ƒ bá» bá»›t má»™t sá»‘ layers cá»§a model bert mÃ  káº¿t quáº£ váº«n cÃ²n cháº¥p nháº­n Ä‘Æ°á»£c. Æ¯u Ä‘iá»ƒm lÃ  háº¡n cháº¿ Ä‘Æ°á»£c thá»i gian train trÃªn cÃ¡c GPU. Cho mÃ¬nh há»i: Náº¿u muá»‘n drop bá»›t má»™t sá»‘ layers cá»§a bert nhÆ° trong bÃ i bÃ¡o thÃ¬ pháº£i lÃ m nhÆ° tháº¿ nÃ o trong code pháº§n model? MÃ¬nh cáº§n cháº¡y thá»­ viá»‡c train cÃ³ Ä‘Ãºng lÃ  nhanh hÆ¡n vÃ  dung lÆ°á»£ng save checkpoint cá»§a bert sáº½ giáº£m khÃ´ng? Xin cáº£m Æ¡n.,,,,,
"Em chÃ o má»i ngÆ°á»i, em má»›i há»c vá» NLP.
Hiá»‡n táº¡i em Ä‘ang cÃ³ má»™t váº¥n Ä‘á» nhÆ° sau: lÃ m sao Ä‘á»ƒ kiá»ƒm tra má»™t tá»« tiáº¿ng viá»‡t Ä‘ang viáº¿t Ä‘Ãºng chÃ­nh táº£ áº¡?
CÃ¡c anh chá»‹ cÃ³ thá»ƒ giÃºp em Ä‘Æ°a ra Ã½ tÆ°á»Ÿng, hoáº·c cÃ¡c tÃ i liá»‡u liÃªn quan Ä‘áº¿n nÃ³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cÅ©ng Ä‘Ã£ tÃ¬m kiáº¿m rá»“i mÃ  chÆ°a ra.
Em xin cáº£m Æ¡n áº¡!","Em chÃ o má»i ngÆ°á»i, em má»›i há»c vá» NLP. Hiá»‡n táº¡i em Ä‘ang cÃ³ má»™t váº¥n Ä‘á» nhÆ° sau: lÃ m sao Ä‘á»ƒ kiá»ƒm tra má»™t tá»« tiáº¿ng viá»‡t Ä‘ang viáº¿t Ä‘Ãºng chÃ­nh táº£ áº¡? CÃ¡c anh chá»‹ cÃ³ thá»ƒ giÃºp em Ä‘Æ°a ra Ã½ tÆ°á»Ÿng, hoáº·c cÃ¡c tÃ i liá»‡u liÃªn quan Ä‘áº¿n nÃ³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cÅ©ng Ä‘Ã£ tÃ¬m kiáº¿m rá»“i mÃ  chÆ°a ra. Em xin cáº£m Æ¡n áº¡!",,,,,
"Xin chÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c Ä‘áº¿n pháº§n Unet vÃ  sá»­ dá»¥ng thÆ° viá»‡n Ä‘á»ƒ lÃ m má»™t sá»‘ bÃ i toÃ¡n nÃªn máº¡nh dáº¡n lÃ m video chia sáº» mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c áº¡.
Mong admin duyá»‡t bÃ i!",Xin chÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c Ä‘áº¿n pháº§n Unet vÃ  sá»­ dá»¥ng thÆ° viá»‡n Ä‘á»ƒ lÃ m má»™t sá»‘ bÃ i toÃ¡n nÃªn máº¡nh dáº¡n lÃ m video chia sáº» mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c áº¡. Mong admin duyá»‡t bÃ i!,,,,,
NhÆ¡Ì€ sÆ°Ì£ giuÌp Ä‘Æ¡Ìƒ nhiÃªÌ£t tiÌ€nh cuÌ‰a anh em trong nhoÌm team miÌ€nh Ä‘aÌƒ hoaÌ€n thaÌ€nh dÆ°Ì£ aÌn Ä‘oÌ£c thÃ´ng tin chÆ°Ìng minh thÆ°. caÌm Æ¡n anh em rÃ¢Ìt nhiÃªÌ€u nheÌ:,NhÆ¡Ì€ sÆ°Ì£ giuÌp Ä‘Æ¡Ìƒ nhiÃªÌ£t tiÌ€nh cuÌ‰a anh em trong nhoÌm team miÌ€nh Ä‘aÌƒ hoaÌ€n thaÌ€nh dÆ°Ì£ aÌn Ä‘oÌ£c thÃ´ng tin chÆ°Ìng minh thÆ°. caÌm Æ¡n anh em rÃ¢Ìt nhiÃªÌ€u nheÌ:,,,,,
dáº¡ do lÃ  em Ä‘ang há»c mÃ´n Big data táº¡i trÆ°á»ng em cháº¡y mÃ´ hÃ¬nh dá»± bÃ¡o bá»‡nh tim báº±ng Azure ML studio. Mng cho em há»i lÃ  ra Ä‘iá»ƒm Skewness vÃ  Kurtosis ntn lÃ  bá»‹ lá»‡ch dá»¯ liá»‡u r fk áº¡? E nÃªn Transform hay Normalize data hay lÃ  gÃ¬ á»Ÿ bÆ°á»›c tiáº¿p theo Ä‘á»ƒ xá»­ lÃ­ dá»¯ liá»‡u áº¡? Do e má»›i sá»­ dá»¥ng láº§n Ä‘áº§u hong biáº¿t j mong anh/ chá»‹ giÃºp Ä‘á»¡ áº¡ em cáº£m Æ¡n nhiá»u áº¡ ğŸ˜­ğŸ’—,dáº¡ do lÃ  em Ä‘ang há»c mÃ´n Big data táº¡i trÆ°á»ng em cháº¡y mÃ´ hÃ¬nh dá»± bÃ¡o bá»‡nh tim báº±ng Azure ML studio. Mng cho em há»i lÃ  ra Ä‘iá»ƒm Skewness vÃ  Kurtosis ntn lÃ  bá»‹ lá»‡ch dá»¯ liá»‡u r fk áº¡? E nÃªn Transform hay Normalize data hay lÃ  gÃ¬ á»Ÿ bÆ°á»›c tiáº¿p theo Ä‘á»ƒ xá»­ lÃ­ dá»¯ liá»‡u áº¡? Do e má»›i sá»­ dá»¥ng láº§n Ä‘áº§u hong biáº¿t j mong anh/ chá»‹ giÃºp Ä‘á»¡ áº¡ em cáº£m Æ¡n nhiá»u áº¡,,,,,
"Xin chÃ o má»i ngÆ°á»i!
Em lÃ  sinh viÃªn ngÃ nh oto hiá»‡n Ä‘ang lÃ m nghiÃªn cá»©u vá» pháº§n á»©ng dá»¥ng Ai Ä‘á»ƒ láº­p trÃ¬nh pháº§n má»n tá»± lÃ¡i cho oto.
VÃ¬ tá»± tÃ¬m hiá»ƒu nÃªn khÃ¡ lÃ  loay hoay pháº§n code, nÃ y em gáº·p lá»—i nhÆ° nÃ y mong anh chá»‹ chá»‰ giÃºp em vá»›i áº¡.
em cÃ³ tÃ¬m hiá»ƒu thÃ¬ trÃªn máº¡ng ngÆ°á»i ta báº£o cÃ i vá» tensorflow 1.14 vÃ  em lÃ m theo chay Ä‘Æ°á»£c nhÆ°ng Ä‘áº¿n pháº§n load gpu thÃ¬ nÃ³ láº¡i kÃªu ko cÃ³ cudu 10.0.
anh chá»‹ cho em há»i em pháº£i lÃ m gÃ¬ Ä‘á»ƒ sá»­a code nÃ y em dÃ¢n ngoÃ i ngÃ nh kiáº¿n thá»©c hÆ¡i háº¡n háº¹p.
code nÃ y lÃ  vá» self driving cá»§a udacity.
anh chá»‹ nÃ o Ä‘Ã£ lÃ m dá»± Ã¡n kiá»ƒu nÃ y rá»“i cho em xin file code vá»›i cho em káº¿t báº¡n há»i 1 sá»‘ Ä‘iá»u áº¡, em cáº£m Æ¡n má»i ngÆ°á»i
from tensorflow.contrib.layers import flatten","Xin chÃ o má»i ngÆ°á»i! Em lÃ  sinh viÃªn ngÃ nh oto hiá»‡n Ä‘ang lÃ m nghiÃªn cá»©u vá» pháº§n á»©ng dá»¥ng Ai Ä‘á»ƒ láº­p trÃ¬nh pháº§n má»n tá»± lÃ¡i cho oto. VÃ¬ tá»± tÃ¬m hiá»ƒu nÃªn khÃ¡ lÃ  loay hoay pháº§n code, nÃ y em gáº·p lá»—i nhÆ° nÃ y mong anh chá»‹ chá»‰ giÃºp em vá»›i áº¡. em cÃ³ tÃ¬m hiá»ƒu thÃ¬ trÃªn máº¡ng ngÆ°á»i ta báº£o cÃ i vá» tensorflow 1.14 vÃ  em lÃ m theo chay Ä‘Æ°á»£c nhÆ°ng Ä‘áº¿n pháº§n load gpu thÃ¬ nÃ³ láº¡i kÃªu ko cÃ³ cudu 10.0. anh chá»‹ cho em há»i em pháº£i lÃ m gÃ¬ Ä‘á»ƒ sá»­a code nÃ y em dÃ¢n ngoÃ i ngÃ nh kiáº¿n thá»©c hÆ¡i háº¡n háº¹p. code nÃ y lÃ  vá» self driving cá»§a udacity. anh chá»‹ nÃ o Ä‘Ã£ lÃ m dá»± Ã¡n kiá»ƒu nÃ y rá»“i cho em xin file code vá»›i cho em káº¿t báº¡n há»i 1 sá»‘ Ä‘iá»u áº¡, em cáº£m Æ¡n má»i ngÆ°á»i from tensorflow.contrib.layers import flatten",,,,,
"em Ä‘ang dÃ¹ng ubuntu20.04. Hiá»‡n táº¡i em Ä‘ang cháº¡y 1 source code dÃ¹ng python3.6 vÃ  opencv ver 4.1.1.26, nhÆ°ng em khÃ´ng thá»ƒ install version nÃ y. em Ä‘ang Ä‘Ã£ thá»­ dÃ¹ng pip vÃ  curl nhÆ°ng Ä‘á»u k Ä‘c. em cÃ³ cÃ¢u há»i :
1. CÃ³ pháº£i do version pip e Ä‘ang dÃ¹ng nÃ³ k há»— trá»£ install opencv2 ver 4.1.1.26 khÃ´ng. Náº¿u Ä‘Ãºng thÃ¬ cÃ i pip ver nÃ o ( em k tÃ¬m Ä‘c trÃªn gg).
2. mE má»›i há»c vÃ  sá»­ dá»¥ng trÃªn ubuntu, em cÃ³ install nhiá»u version cá»§a 1 thÆ° viá»‡n thÃ¬, má»—i khi e cháº¡y lá»‡nh python3.6, 3.7 hay 3.8 thÃ¬ nÃ³ sáº½ link Ä‘i Ä‘Ã¢u, link vá»›i thÆ° viá»‡n ntn ?","em Ä‘ang dÃ¹ng ubuntu20.04. Hiá»‡n táº¡i em Ä‘ang cháº¡y 1 source code dÃ¹ng python3.6 vÃ  opencv ver 4.1.1.26, nhÆ°ng em khÃ´ng thá»ƒ install version nÃ y. em Ä‘ang Ä‘Ã£ thá»­ dÃ¹ng pip vÃ  curl nhÆ°ng Ä‘á»u k Ä‘c. em cÃ³ cÃ¢u há»i : 1. CÃ³ pháº£i do version pip e Ä‘ang dÃ¹ng nÃ³ k há»— trá»£ install opencv2 ver 4.1.1.26 khÃ´ng. Náº¿u Ä‘Ãºng thÃ¬ cÃ i pip ver nÃ o ( em k tÃ¬m Ä‘c trÃªn gg). 2. mE má»›i há»c vÃ  sá»­ dá»¥ng trÃªn ubuntu, em cÃ³ install nhiá»u version cá»§a 1 thÆ° viá»‡n thÃ¬, má»—i khi e cháº¡y lá»‡nh python3.6, 3.7 hay 3.8 thÃ¬ nÃ³ sáº½ link Ä‘i Ä‘Ã¢u, link vá»›i thÆ° viá»‡n ntn ?",,,,,
"MÃ¬nh ráº¥t mong sá»± há»— trá»£ cá»§a cÃ¡c báº¡n.
MÃ¬nh cÃ³ má»™t Ä‘á»“ thá»‹ vá»›i ráº¥t nhiá»u Ä‘iá»ƒm. NhÆ°ng mÃ¬nh chá»‰ muá»‘n tÃ¬m phÆ°Æ¡ng trÃ¬nh cá»§a hÃ m xáº¥p xá»‰ vá»›i báº­c nhá» nhÆ° 3, báº­c 5, hay báº­c 7,... CÃ³ má»™t thÆ° viá»‡n Python hay má»™t chÆ°Æ¡ng trÃ¬nh á»©ng dá»¥ng nÃ o khÃ¡c cÅ©ng Ä‘Æ°á»£c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°a ra káº¿t quáº£ cá»§a hÃ m gáº§n Ä‘Ãºng nÃ y khÃ´ng? Cáº£m Æ¡n cÃ¡c báº¡n.","MÃ¬nh ráº¥t mong sá»± há»— trá»£ cá»§a cÃ¡c báº¡n. MÃ¬nh cÃ³ má»™t Ä‘á»“ thá»‹ vá»›i ráº¥t nhiá»u Ä‘iá»ƒm. NhÆ°ng mÃ¬nh chá»‰ muá»‘n tÃ¬m phÆ°Æ¡ng trÃ¬nh cá»§a hÃ m xáº¥p xá»‰ vá»›i báº­c nhá» nhÆ° 3, báº­c 5, hay báº­c 7,... CÃ³ má»™t thÆ° viá»‡n Python hay má»™t chÆ°Æ¡ng trÃ¬nh á»©ng dá»¥ng nÃ o khÃ¡c cÅ©ng Ä‘Æ°á»£c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°a ra káº¿t quáº£ cá»§a hÃ m gáº§n Ä‘Ãºng nÃ y khÃ´ng? Cáº£m Æ¡n cÃ¡c báº¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang xÃ¢y dá»±ng 1 model dá»±a trÃªn mÃ´ hÃ¬nh PointNet :https://arxiv.org/pdf/1612.00593.pdf . NhÆ°ng á»Ÿ Ä‘oáº¡n, concatenate local feature vÃ  global feature nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y. Em khÃ´ng thá»ƒ concatenate (n,64) vÃ  (none, 1024) Ä‘Æ°á»£c. Xin há»i má»i ngÆ°á»i, cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ concatenate chÃºng vá»›i nhau khÃ´ng, hay em Ä‘Ã£ hiá»ƒu sai váº¥n Ä‘á»? Ráº¥t cÃ¡m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i, em Ä‘ang xÃ¢y dá»±ng 1 model dá»±a trÃªn mÃ´ hÃ¬nh PointNet :https://arxiv.org/pdf/1612.00593.pdf . NhÆ°ng á»Ÿ Ä‘oáº¡n, concatenate local feature vÃ  global feature nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y. Em khÃ´ng thá»ƒ concatenate (n,64) vÃ  (none, 1024) Ä‘Æ°á»£c. Xin há»i má»i ngÆ°á»i, cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ concatenate chÃºng vá»›i nhau khÃ´ng, hay em Ä‘Ã£ hiá»ƒu sai váº¥n Ä‘á»? Ráº¥t cÃ¡m Æ¡n má»i ngÆ°á»i",,,,,
"Em cÃ³ cÃ¢u há»i nÃ y cáº§n má»i ngÆ°á»i há»— trá»£ áº¡. Hiá»‡n em Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u ráº¥t lá»›n, lÃ  áº£nh cá»§a cÃ¡c nhÃ¢n viÃªn á»Ÿ cty, em Ä‘Ã£ training xong vÃ  cÃ³ file káº¿t quáº£ model. NhÆ°ng vÃ¬ nhÃ¢n sá»± cá»§a cty luÃ´n thay Ä‘á»•i nÃªn má»i ngÆ°á»i tÆ° váº¥n giÃºp e xem cÃ³ technique vÃ  keyword nÃ o Ä‘á»ƒ khi dá»¯ liá»‡u thay Ä‘á»•i (tÄƒng lÃªn hoáº·c giáº£m Ä‘i ) thÃ¬ mk khÃ´ng pháº£i training láº¡i cáº£ model mÃ  váº«n nháº­n diá»‡n Ä‘Æ°á»£c data má»›i hoáº·c k nháº­n diá»‡n data Ä‘Ã£ bá» Ä‘i Ä‘Æ°á»£c khÃ´ng áº¡?Em cáº£m Æ¡n áº¡.","Em cÃ³ cÃ¢u há»i nÃ y cáº§n má»i ngÆ°á»i há»— trá»£ áº¡. Hiá»‡n em Ä‘ang cÃ³ má»™t táº­p dá»¯ liá»‡u ráº¥t lá»›n, lÃ  áº£nh cá»§a cÃ¡c nhÃ¢n viÃªn á»Ÿ cty, em Ä‘Ã£ training xong vÃ  cÃ³ file káº¿t quáº£ model. NhÆ°ng vÃ¬ nhÃ¢n sá»± cá»§a cty luÃ´n thay Ä‘á»•i nÃªn má»i ngÆ°á»i tÆ° váº¥n giÃºp e xem cÃ³ technique vÃ  keyword nÃ o Ä‘á»ƒ khi dá»¯ liá»‡u thay Ä‘á»•i (tÄƒng lÃªn hoáº·c giáº£m Ä‘i ) thÃ¬ mk khÃ´ng pháº£i training láº¡i cáº£ model mÃ  váº«n nháº­n diá»‡n Ä‘Æ°á»£c data má»›i hoáº·c k nháº­n diá»‡n data Ä‘Ã£ bá» Ä‘i Ä‘Æ°á»£c khÃ´ng áº¡?Em cáº£m Æ¡n áº¡.",,,,,
"[Newbie]
Em chÃ o cÃ¡c anh chá»‹. E vá»«a bÆ°á»›c vÃ  viá»‡c tÃ¬m hiá»ƒu Machine learning Ä‘á»ƒ dá»± bÃ¡o tiá»n Ä‘iá»‡n tá»­.
Em cÃ³ tháº¥y bÃ i cá»§a a Viet Anh Tran share vá» cÃ´ng cá»¥ thu tháº­p dá»¯ liá»‡u cryptocurriencies. Em cÃ³ Ä‘á»c vÃ  tÃ¬m hiá»ƒu, cÅ©ng Ä‘Ã£ cÃ i Ä‘áº·t Docker. NhÆ°ng do kiáº¿n thá»©c háº¡n háº¹p thiáº¿u sÃ³t nÃªn e khÃ´ng hiá»ƒu láº¯m, tá»« khi báº¯t Ä‘áº§u á»Ÿ bÆ°á»›c dÆ°á»›i hÃ¬nh. Em khÃ´ng biáº¿t anh chá»‹ nÃ o Ä‘Ã£ thá»±c hiá»‡n cÃ³ thá»ƒ há»— trá»£ giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡!
Mong cÃ¡c anh chá»‹ nÃ³i dá»… dá»… hiá»ƒu giÃºp em áº¡, e cÃ²n má»›i nen e chÆ°a biáº¿t nhiá»u, em xin cáº£m Æ¡n nhiá»u áº¡!
Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i!
https://github.com/coinForRich/coin-for-rich#inside-the-app","[Newbie] Em chÃ o cÃ¡c anh chá»‹. E vá»«a bÆ°á»›c vÃ  viá»‡c tÃ¬m hiá»ƒu Machine learning Ä‘á»ƒ dá»± bÃ¡o tiá»n Ä‘iá»‡n tá»­. Em cÃ³ tháº¥y bÃ i cá»§a a Viet Anh Tran share vá» cÃ´ng cá»¥ thu tháº­p dá»¯ liá»‡u cryptocurriencies. Em cÃ³ Ä‘á»c vÃ  tÃ¬m hiá»ƒu, cÅ©ng Ä‘Ã£ cÃ i Ä‘áº·t Docker. NhÆ°ng do kiáº¿n thá»©c háº¡n háº¹p thiáº¿u sÃ³t nÃªn e khÃ´ng hiá»ƒu láº¯m, tá»« khi báº¯t Ä‘áº§u á»Ÿ bÆ°á»›c dÆ°á»›i hÃ¬nh. Em khÃ´ng biáº¿t anh chá»‹ nÃ o Ä‘Ã£ thá»±c hiá»‡n cÃ³ thá»ƒ há»— trá»£ giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡! Mong cÃ¡c anh chá»‹ nÃ³i dá»… dá»… hiá»ƒu giÃºp em áº¡, e cÃ²n má»›i nen e chÆ°a biáº¿t nhiá»u, em xin cáº£m Æ¡n nhiá»u áº¡! Cáº£m Æ¡n admin Ä‘Ã£ duyá»‡t bÃ i! https://github.com/coinForRich/coin-for-rich#inside-the-app",,,,,
"Cheatsheets lÃ  cÃ¡ch ghi nhá»› nhá»¯ng gÃ¬ cÆ¡ báº£n vÃ  quan trá»ng Ä‘á»ƒ tra cá»©u. Nay mÃ¬nh tÃ¬nh cÆ¡ tháº¥y cÃ³ ngÆ°á»i tá»•ng há»£p Ä‘Æ°á»£c má»™t loáº¡t cÃ¡c Cheatsheets, nÃªn mÃ¬nh chia sáº» láº¡i táº¡i Ä‘Ã¢y Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o https://bit.ly/3m5aRcf. NÃ³ bao gá»“m ráº¥t nhiá»u ná»™i dung, tá»« Linux; tá»›i Git; tá»›i 1 sá»‘ ngÃ´n ngá»¯ láº­p trÃ¬nh (R, Python, Scala,...); cho tá»›i cÃ¡c thÆ° viá»‡n cÆ¡ báº£n nhÆ° Numpy, Pandas,... cho khoa há»c dá»¯ liá»‡u; toÃ¡n xÃ¡c suáº¥t thá»‘ng kÃª; Docker & Kurbenetes; AI nhÆ° NLP; vÃ  quay láº¡i vá»›i Excel;...
Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i","Cheatsheets lÃ  cÃ¡ch ghi nhá»› nhá»¯ng gÃ¬ cÆ¡ báº£n vÃ  quan trá»ng Ä‘á»ƒ tra cá»©u. Nay mÃ¬nh tÃ¬nh cÆ¡ tháº¥y cÃ³ ngÆ°á»i tá»•ng há»£p Ä‘Æ°á»£c má»™t loáº¡t cÃ¡c Cheatsheets, nÃªn mÃ¬nh chia sáº» láº¡i táº¡i Ä‘Ã¢y Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o https://bit.ly/3m5aRcf. NÃ³ bao gá»“m ráº¥t nhiá»u ná»™i dung, tá»« Linux; tá»›i Git; tá»›i 1 sá»‘ ngÃ´n ngá»¯ láº­p trÃ¬nh (R, Python, Scala,...); cho tá»›i cÃ¡c thÆ° viá»‡n cÆ¡ báº£n nhÆ° Numpy, Pandas,... cho khoa há»c dá»¯ liá»‡u; toÃ¡n xÃ¡c suáº¥t thá»‘ng kÃª; Docker & Kurbenetes; AI nhÆ° NLP; vÃ  quay láº¡i vá»›i Excel;... Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i",,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  newbie áº¡. Má»i ngÆ°á»i cho em há»i nhá»¯ng thuáº­t toÃ¡n nhÆ° linear , logistic, softmax regressionâ€¦ cÃ³ tÃ¡c dá»¥ng ntn áº¡? VÃ¬ em tháº¥y mÃ¬nh chá»‰ lÃ m viá»‡c vá»›i máº¡ng neural vÃ  em cÅ©ng chÆ°a tháº¥y á»©ng dá»¥ng cá»§a cÃ¡c thuáº­t toÃ¡n áº¥y. Mong má»i ngÆ°á»i chá»‰ báº£o áº¡!","ChÃ o má»i ngÆ°á»i, em lÃ  newbie áº¡. Má»i ngÆ°á»i cho em há»i nhá»¯ng thuáº­t toÃ¡n nhÆ° linear , logistic, softmax regressionâ€¦ cÃ³ tÃ¡c dá»¥ng ntn áº¡? VÃ¬ em tháº¥y mÃ¬nh chá»‰ lÃ m viá»‡c vá»›i máº¡ng neural vÃ  em cÅ©ng chÆ°a tháº¥y á»©ng dá»¥ng cá»§a cÃ¡c thuáº­t toÃ¡n áº¥y. Mong má»i ngÆ°á»i chá»‰ báº£o áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang viáº¿t bÃ i bÃ¡o cÃ¡o vá» má»™t sá»‘ thuáº­t toÃ¡n há»c mÃ¡y: support vector máº¡chine, logistic regession, vÃ  random forest. Em muá»‘n tÃ¬m má»™t sá»‘ tÃ i liá»‡u (sÃ¡ch) Ä‘á»ƒ cÃ³ thá»ƒ dÃ¹ng tham kháº£o cho bÃ i bÃ¡o cÃ¡o cá»§a em.
Hy vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp giÃ¹m em.","ChÃ o má»i ngÆ°á»i, em Ä‘ang viáº¿t bÃ i bÃ¡o cÃ¡o vá» má»™t sá»‘ thuáº­t toÃ¡n há»c mÃ¡y: support vector máº¡chine, logistic regession, vÃ  random forest. Em muá»‘n tÃ¬m má»™t sá»‘ tÃ i liá»‡u (sÃ¡ch) Ä‘á»ƒ cÃ³ thá»ƒ dÃ¹ng tham kháº£o cho bÃ i bÃ¡o cÃ¡o cá»§a em. Hy vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp giÃ¹m em.",,,,,
"ChÃ o má»i ngÆ°á»i!
Em Ä‘ang train1 model mask rcnn vá»›i detectron2 báº±ng colab.
Pháº§n train cá»§a em Ä‘ang bá»‹ lá»—i nÃ y vÃ  em Ä‘Ã£ thá»­ má»™t sá»‘ cÃ¡ch trÃªn gg, stack, nhÆ°ng váº«n khÃ´ng kháº¯c phá»¥c Ä‘Æ°á»£c!
m.n cÃ³ thá»ƒ cho em xin phÆ°Æ¡ng Ã¡n kháº¯c phá»¥c Ä‘Æ°á»£c khÃ´ng áº¡!
Thanks m.n!
Colab: https://drive.google.com/file/d/1OB30sShdrIYQ4kDuE-S7moAUEdhvT6gF/view?usp=sharing","ChÃ o má»i ngÆ°á»i! Em Ä‘ang train1 model mask rcnn vá»›i detectron2 báº±ng colab. Pháº§n train cá»§a em Ä‘ang bá»‹ lá»—i nÃ y vÃ  em Ä‘Ã£ thá»­ má»™t sá»‘ cÃ¡ch trÃªn gg, stack, nhÆ°ng váº«n khÃ´ng kháº¯c phá»¥c Ä‘Æ°á»£c! m.n cÃ³ thá»ƒ cho em xin phÆ°Æ¡ng Ã¡n kháº¯c phá»¥c Ä‘Æ°á»£c khÃ´ng áº¡! Thanks m.n! Colab: https://drive.google.com/file/d/1OB30sShdrIYQ4kDuE-S7moAUEdhvT6gF/view?usp=sharing",,,,,
"Xin chÃ o má»i ngÆ°á»i!
Em cÃ³ má»™t tháº¯c máº¯c lÃ  táº¡i sao ngÆ°á»i ta láº¡i nÃ³i 3D UNet nÃ³ too complex khi so sÃ¡nh vá»›i 2D UNET trong khi No. parameters cá»§a 3D UNET lÃ  16.21 (x10^3) vÃ  2D UNet lÃ  31.38 (x10^3). Em khÃ´ng biáº¿t liá»‡u cÃ³ pháº£i lÃ  khi má»i ngÆ°á»i mentioned complex á»Ÿ Ä‘Ã¢y lÃ  time complexity (FLOPs)?
Em cáº£m Æ¡n Admin Ä‘Ã£ duyá»‡t bÃ i áº¡.",Xin chÃ o má»i ngÆ°á»i! Em cÃ³ má»™t tháº¯c máº¯c lÃ  táº¡i sao ngÆ°á»i ta láº¡i nÃ³i 3D UNet nÃ³ too complex khi so sÃ¡nh vá»›i 2D UNET trong khi No. parameters cá»§a 3D UNET lÃ  16.21 (x10^3) vÃ  2D UNet lÃ  31.38 (x10^3). Em khÃ´ng biáº¿t liá»‡u cÃ³ pháº£i lÃ  khi má»i ngÆ°á»i mentioned complex á»Ÿ Ä‘Ã¢y lÃ  time complexity (FLOPs)? Em cáº£m Æ¡n Admin Ä‘Ã£ duyá»‡t bÃ i áº¡.,,,,,
"Nhi Ä‘ang dá»±ng má»™t ML cho assessor property cho má»™t tiá»ƒu bang cá»§a Má»¹ ( chá»‰ lÃ  dá»± Ã¡n cÃ¡ nhÃ¢n, Nhi táº£i dataset trÃªn data.gov vá»)
NhÆ°ng lÃºc táº¡o histogram cho má»—i numerical attribute thÃ¬ cÃ³ má»™t sá»‘ biá»ƒu Ä‘á»“ chá»‰ xuáº¥t hiá»‡n 1 cá»™t. VÃ­ dá»¥ nhÆ° â€œSALE PRICEâ€ vÃ  â€œLAND VALâ€ máº·c dÃ¹ trong excel hiá»‡n giÃ¡ trá»‹ tá»« 0-1,000,000 nhÆ°ng lÃºc lÃ m biá»ƒu Ä‘á»“ cÅ©ng hiá»‡n 1 cá»™t duy nháº¥t.
CÃ³ ai cÃ³ biáº¿t lÃ­ do táº¡i sao khÃ´ng áº¡?
Thanks.
P/s: do mÃ¬nh há»c á»Ÿ nÆ°á»›c ngoÃ i, nÃªn cÃ³ máº¥y tá»« Nhi ko biáº¿t tiáº¿ng Viá»‡t.","Nhi Ä‘ang dá»±ng má»™t ML cho assessor property cho má»™t tiá»ƒu bang cá»§a Má»¹ ( chá»‰ lÃ  dá»± Ã¡n cÃ¡ nhÃ¢n, Nhi táº£i dataset trÃªn data.gov vá») NhÆ°ng lÃºc táº¡o histogram cho má»—i numerical attribute thÃ¬ cÃ³ má»™t sá»‘ biá»ƒu Ä‘á»“ chá»‰ xuáº¥t hiá»‡n 1 cá»™t. VÃ­ dá»¥ nhÆ° â€œSALE PRICEâ€ vÃ  â€œLAND VALâ€ máº·c dÃ¹ trong excel hiá»‡n giÃ¡ trá»‹ tá»« 0-1,000,000 nhÆ°ng lÃºc lÃ m biá»ƒu Ä‘á»“ cÅ©ng hiá»‡n 1 cá»™t duy nháº¥t. CÃ³ ai cÃ³ biáº¿t lÃ­ do táº¡i sao khÃ´ng áº¡? Thanks. P/s: do mÃ¬nh há»c á»Ÿ nÆ°á»›c ngoÃ i, nÃªn cÃ³ máº¥y tá»« Nhi ko biáº¿t tiáº¿ng Viá»‡t.",,,,,
"Em muá»‘n há»i cÃ¡ch xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c khi Ä‘Æ°a vÃ o model. Em cÃ³ bÃ i toÃ¡n vá» CV. Má»™t folder cÃ³ dáº¡ng nhÆ° bÃªn dÆ°á»›i, bÃªn trong cÃ¡c folder 111 vÃ  112 lÃ  hÃ¬nh áº£nh vÃ  label Ä‘Æ°á»£c chia theo tÃªn cá»§a folder chá»©a nÃ³, vÃ­ dá»¥ hÃ¬nh trong folder '18/112/abc.jpg' thÃ¬ cÃ³ label lÃ  18 vÃ  112(18 lÃ  tuá»•i, 112 lÃ  giá»›i tÃ­nh). Em Ä‘ang xá»­ dá»¥ng thÆ° viá»‡n OS cá»§a python Ä‘á»ƒ xá»­ lÃ½ nhÆ°ng tháº¥y ráº¥t cá»“ng ká»nh, cÃ³ cÃ´ng cá»¥ nÃ o khÃ¡c hiá»‡u quáº£ hÆ¡n khÃ´ng áº¡?","Em muá»‘n há»i cÃ¡ch xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c khi Ä‘Æ°a vÃ o model. Em cÃ³ bÃ i toÃ¡n vá» CV. Má»™t folder cÃ³ dáº¡ng nhÆ° bÃªn dÆ°á»›i, bÃªn trong cÃ¡c folder 111 vÃ  112 lÃ  hÃ¬nh áº£nh vÃ  label Ä‘Æ°á»£c chia theo tÃªn cá»§a folder chá»©a nÃ³, vÃ­ dá»¥ hÃ¬nh trong folder '18/112/abc.jpg' thÃ¬ cÃ³ label lÃ  18 vÃ  112(18 lÃ  tuá»•i, 112 lÃ  giá»›i tÃ­nh). Em Ä‘ang xá»­ dá»¥ng thÆ° viá»‡n OS cá»§a python Ä‘á»ƒ xá»­ lÃ½ nhÆ°ng tháº¥y ráº¥t cá»“ng ká»nh, cÃ³ cÃ´ng cá»¥ nÃ o khÃ¡c hiá»‡u quáº£ hÆ¡n khÃ´ng áº¡?",,,,,
"[GÃ³c newbie]
ChÃ o mn. MÃ¬nh cÃ³ má»™t tháº¯c máº¯c nhá». MÃ¬nh Ä‘ang lÃ m dá»± Ã¡n vá» NLP. MÃ¬nh Ä‘ang cáº§n 1 ML model dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i share 1 máº©u tin tá»©c nÃ o Ä‘Ã³ trÃªn máº¡ng xÃ£ há»™i. BÃ i toÃ¡n cÃ³ X lÃ  1 máº©u tin (mÃ¬nh Ä‘Ã£ chuyá»ƒn thÃ nh bag-of-word), Y lÃ  sá»‘ ngÆ°á»i chia sáº» máº©u tin Ä‘Ã³ (Y lÃ  sá»‘ tá»± nhiÃªn lá»›n hÆ¡n 0)
MÃ¬nh Ä‘Ã£ cÃ³ dataset rá»“i nhÆ°ng Ä‘ang khÃ´ng biáº¿t sá»­ dá»¥ng model nÃ o Ä‘á»ƒ cÃ³ thá»ƒ train Ä‘Æ°á»£c bÃ i toÃ¡n nÃ y. KhÃ´ng biáº¿t mn cÃ³ thá»ƒ gá»£i Ã½ giÃºp mÃ¬nh Ä‘Æ°á»£c k áº¡
MÃ¬nh cáº£m Æ¡n mn","[GÃ³c newbie] ChÃ o mn. MÃ¬nh cÃ³ má»™t tháº¯c máº¯c nhá». MÃ¬nh Ä‘ang lÃ m dá»± Ã¡n vá» NLP. MÃ¬nh Ä‘ang cáº§n 1 ML model dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i share 1 máº©u tin tá»©c nÃ o Ä‘Ã³ trÃªn máº¡ng xÃ£ há»™i. BÃ i toÃ¡n cÃ³ X lÃ  1 máº©u tin (mÃ¬nh Ä‘Ã£ chuyá»ƒn thÃ nh bag-of-word), Y lÃ  sá»‘ ngÆ°á»i chia sáº» máº©u tin Ä‘Ã³ (Y lÃ  sá»‘ tá»± nhiÃªn lá»›n hÆ¡n 0) MÃ¬nh Ä‘Ã£ cÃ³ dataset rá»“i nhÆ°ng Ä‘ang khÃ´ng biáº¿t sá»­ dá»¥ng model nÃ o Ä‘á»ƒ cÃ³ thá»ƒ train Ä‘Æ°á»£c bÃ i toÃ¡n nÃ y. KhÃ´ng biáº¿t mn cÃ³ thá»ƒ gá»£i Ã½ giÃºp mÃ¬nh Ä‘Æ°á»£c k áº¡ MÃ¬nh cáº£m Æ¡n mn",,,,,
"""Primer: Searching for Efficient Transformers for Language Modeling"" lÃ  bÃ i bÃ¡o má»›i nháº¥t cá»§a Google Brain (link táº¡i Ä‘Ã¢y: https://arxiv.org/pdf/2109.08668.pdf; source code táº¡i Ä‘Ã¢y: https://github.com/google-research/google-research/tree/master/primer).
Má»™t sá»‘ cáº£i tiáº¿n cá»§a Primer (má»™t biáº¿n thá»ƒ cÃ¡i tiáº¿n cá»§a kiáº¿n trÃºc Transformer) so vá»›i cÃ¡c káº¿t quáº£ trÆ°á»›c Ä‘Ã¢y:
1/ Train nhanh 3-4 láº§n so vá»›i Transformer nhÆ° T5 vÃ  GPT-3XL cho tÃ¡c vá»¥ xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn;
2/ Sá»­ dá»¥ng hÃ m activation cÃ³ tÃªn squared ReLU
3/ Bá»• sung kiáº¿n truc depthwise convs phÃ­a sau Q, K, V projection heads trong self-attention","""Primer: Searching for Efficient Transformers for Language Modeling"" lÃ  bÃ i bÃ¡o má»›i nháº¥t cá»§a Google Brain (link táº¡i Ä‘Ã¢y: https://arxiv.org/pdf/2109.08668.pdf; source code táº¡i Ä‘Ã¢y: https://github.com/google-research/google-research/tree/master/primer). Má»™t sá»‘ cáº£i tiáº¿n cá»§a Primer (má»™t biáº¿n thá»ƒ cÃ¡i tiáº¿n cá»§a kiáº¿n trÃºc Transformer) so vá»›i cÃ¡c káº¿t quáº£ trÆ°á»›c Ä‘Ã¢y: 1/ Train nhanh 3-4 láº§n so vá»›i Transformer nhÆ° T5 vÃ  GPT-3XL cho tÃ¡c vá»¥ xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn; 2/ Sá»­ dá»¥ng hÃ m activation cÃ³ tÃªn squared ReLU 3/ Bá»• sung kiáº¿n truc depthwise convs phÃ­a sau Q, K, V projection heads trong self-attention",,,,,
"Má»™t cÃ¡ch dáº«n dáº¯t Cross-Entropy Loss dá»… hiá»ƒu, Ä‘áº·c biá»‡t dÃ nh cho dÃ¢n ""lÆ°á»i"" ngÃ³ láº¡i toÃ¡n, mÃ  váº«n dá»… hiá»ƒu.
Náº¿u cÃ¡c báº¡n Ä‘á»c vá» pháº§n Cross-Entropy (CE) trong cÃ¡c tÃ i liá»‡u ML, sáº½ gáº·p ráº¥t nhiá»u cÃ¡c dáº«n dáº¯t tá»« Entropy trong LÃ½ thuyáº¿t thÃ´ng tin (vÃ  tháº­m chÃ­ tá»« Váº­t lÃ½), vá»›i cÃ´ng thá»©c mÃ  nhá»¯ng ngÆ°á»i lÃ¢u khÃ´ng Ä‘á»¥ng láº¡i toÃ¡n sáº½ ráº¥t KHÃ“ HÃŒNH DUNG, tá»©c lÃ  táº¡i sao ngÆ°á»i ta láº¡i ""mÃ³c"" Ä‘Ã¢u ra cÃ¡i thá»© CE Ä‘au Ä‘áº§u nÃ y.
MÃ¬nh báº¯t gáº·p cÃ¡ch Dáº«n Dáº¯t trong khÃ³a Pytorch, tháº¥y nÃ³ Dá»… Tiáº¿p Nháº­n, chia sáº» vá»›i cÃ¡c báº¡n. Xin hÃ£y lÆ°á»›t thá»© tá»± tá»«ng Photo theo thá»© tá»± Ä‘á»ƒ hiá»ƒu.
PS: Ä‘Ã¢y lÃ  cáº£m nháº­n riÃªng mÃ¬nh khi há»c ML, nÃªn cÃ³ thá»ƒ khÃ´ng Ä‘Ãºng vá»›i cÃ¡c báº¡n. NgoÃ i ra mÃ¬nh trÃ¬nh bÃ y ko Ä‘Æ°á»£c chuáº©n táº¯c cho láº¯m, cÃ¡c báº¡n bá» qua.","Má»™t cÃ¡ch dáº«n dáº¯t Cross-Entropy Loss dá»… hiá»ƒu, Ä‘áº·c biá»‡t dÃ nh cho dÃ¢n ""lÆ°á»i"" ngÃ³ láº¡i toÃ¡n, mÃ  váº«n dá»… hiá»ƒu. Náº¿u cÃ¡c báº¡n Ä‘á»c vá» pháº§n Cross-Entropy (CE) trong cÃ¡c tÃ i liá»‡u ML, sáº½ gáº·p ráº¥t nhiá»u cÃ¡c dáº«n dáº¯t tá»« Entropy trong LÃ½ thuyáº¿t thÃ´ng tin (vÃ  tháº­m chÃ­ tá»« Váº­t lÃ½), vá»›i cÃ´ng thá»©c mÃ  nhá»¯ng ngÆ°á»i lÃ¢u khÃ´ng Ä‘á»¥ng láº¡i toÃ¡n sáº½ ráº¥t KHÃ“ HÃŒNH DUNG, tá»©c lÃ  táº¡i sao ngÆ°á»i ta láº¡i ""mÃ³c"" Ä‘Ã¢u ra cÃ¡i thá»© CE Ä‘au Ä‘áº§u nÃ y. MÃ¬nh báº¯t gáº·p cÃ¡ch Dáº«n Dáº¯t trong khÃ³a Pytorch, tháº¥y nÃ³ Dá»… Tiáº¿p Nháº­n, chia sáº» vá»›i cÃ¡c báº¡n. Xin hÃ£y lÆ°á»›t thá»© tá»± tá»«ng Photo theo thá»© tá»± Ä‘á»ƒ hiá»ƒu. PS: Ä‘Ã¢y lÃ  cáº£m nháº­n riÃªng mÃ¬nh khi há»c ML, nÃªn cÃ³ thá»ƒ khÃ´ng Ä‘Ãºng vá»›i cÃ¡c báº¡n. NgoÃ i ra mÃ¬nh trÃ¬nh bÃ y ko Ä‘Æ°á»£c chuáº©n táº¯c cho láº¯m, cÃ¡c báº¡n bá» qua.",,,,,
Hiá»‡n mÃ¬nh Ä‘ang lÃ m speech recognition trÃªn collab. MÃ¬nh Ä‘ang lÃ m Ä‘áº¿n chuyá»ƒn file wav sang csv. ÄÃ¢y lÃ  code open source mÃ¬nh láº¥y tá»« github nhÆ°ng lÃºc mÃ¬nh import file wav vÃ  convert ra thÃ¬ chá»‰ ra toÃ n lÃ  dÃ£y sá»‘ mÃ  khÃ´ng cÃ³ tá»«. CÃ³ thá»ƒ chá»‰ giÃºp mÃ¬nh lÃ  mÃ¬nh sai á»Ÿ Ä‘Ã¢u khÃ´ng. MÃ¬nh cÃ¡m Æ¡n!,Hiá»‡n mÃ¬nh Ä‘ang lÃ m speech recognition trÃªn collab. MÃ¬nh Ä‘ang lÃ m Ä‘áº¿n chuyá»ƒn file wav sang csv. ÄÃ¢y lÃ  code open source mÃ¬nh láº¥y tá»« github nhÆ°ng lÃºc mÃ¬nh import file wav vÃ  convert ra thÃ¬ chá»‰ ra toÃ n lÃ  dÃ£y sá»‘ mÃ  khÃ´ng cÃ³ tá»«. CÃ³ thá»ƒ chá»‰ giÃºp mÃ¬nh lÃ  mÃ¬nh sai á»Ÿ Ä‘Ã¢u khÃ´ng. MÃ¬nh cÃ¡m Æ¡n!,,,,,
"Äá»ƒ giá»¯ gÃ¬n sá»± trong sÃ¡ng cho tiáº¿ng viá»‡t mÃ¬nh xin cáº¯t bá»›t má»™t sá»‘ khÃºc khÃ´ng Ä‘Æ°á»£c trong sÃ¡ng vÃ  chá»‰ giá»¯ láº¡i Ã½ chÃ­nh. CÃ¡m Æ¡n má»i ngÆ°á»i.
CÃ³ ai Ä‘Ã£ tá»«ng tiáº¿p xÃºc vá»›i People Analytics chÆ°a áº¡? Cá»¥ thá»ƒ lÃ  mÃ¬nh sáº½ cÃ³ nhá»¯ng hÆ°á»›ng Ä‘i tháº¿ nÃ o?
VÃ  cÃ¡m Æ¡n chia sáº» cá»§a báº¡n HoÃ ng bÃªn dÆ°á»›i áº¡.",Äá»ƒ giá»¯ gÃ¬n sá»± trong sÃ¡ng cho tiáº¿ng viá»‡t mÃ¬nh xin cáº¯t bá»›t má»™t sá»‘ khÃºc khÃ´ng Ä‘Æ°á»£c trong sÃ¡ng vÃ  chá»‰ giá»¯ láº¡i Ã½ chÃ­nh. CÃ¡m Æ¡n má»i ngÆ°á»i. CÃ³ ai Ä‘Ã£ tá»«ng tiáº¿p xÃºc vá»›i People Analytics chÆ°a áº¡? Cá»¥ thá»ƒ lÃ  mÃ¬nh sáº½ cÃ³ nhá»¯ng hÆ°á»›ng Ä‘i tháº¿ nÃ o? VÃ  cÃ¡m Æ¡n chia sáº» cá»§a báº¡n HoÃ ng bÃªn dÆ°á»›i áº¡.,,,,,
a/c cho e há»i cÃ¡ch crawl dá»¯ liá»‡u cá»• phiáº¿u Viá»‡t Nam vá»›i áº¡. E cáº£m Æ¡n áº¡!,a/c cho e há»i cÃ¡ch crawl dá»¯ liá»‡u cá»• phiáº¿u Viá»‡t Nam vá»›i áº¡. E cáº£m Æ¡n áº¡!,,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» framework tensorflow vÃ¬ tháº§y hÆ°á»›ng dáº«n cá»§a em gá»£i Ã½ nÃªn há»c vÃ  sá»­ dá»¥ng cho academic, hiá»‡n táº¡i em Ä‘ang lÃ m khÃ³a luáº­n Ä‘áº¡i há»c nÃªn cÃ³ quan tÃ¢m vá» sá»­ dá»¥ng framework nÃ y cho nghiÃªn cá»©u. TrÆ°á»›c giá» em váº«n build, train vÃ  evaluate model vá»›i keras. Em cÃ³ lÃªn máº¡ng tÃ¬m hiá»ƒu thÃ¬ cÅ©ng náº¯m Ä‘Æ°á»£c má»™t sá»‘ Æ°u Ä‘iá»ƒm cá»§a tensorflow so vá»›i keras vá» thá»i gian cháº¡y, xÃ¢y dá»±ng nhá»¯ng model vá»›i performance cao, dataset lá»›n, nhÆ°ng nhÆ°á»£c Ä‘iá»ƒm lÃ  khÃ³ implement, debug. Hiá»‡n táº¡i, cÃ¡i em Ä‘ang muá»‘n lÃ m lÃ  implement láº¡i má»™t architecture tá»« 1 paper viáº¿t láº¡i dÆ°á»›i dáº¡ng tensorflow, sau Ä‘Ã³ train vÃ  evaluate trÃªn dataset cÅ©ng tá»« paper xem cÃ³ thá»ƒ reproduce Ä‘Æ°á»£c performance metrics gáº§n giá»‘ng paper khÃ´ng. Má»¥c Ä‘Ã­ch cuá»‘i cÃ¹ng lÃ  lÃ m sao Ä‘Ã³, em cÃ³ thá»ƒ modify láº¡i code cho architecture, thÃªm new data cho dataset cÅ©, hoáº·c tunning cÃ¡c hyperparameters á»Ÿ cÃ¡c module trong model Ä‘á»ƒ lÃ m sao cho perfomance metrics cáº£i thiá»‡n, time vÃ  space resource Ä‘Æ°á»£c rÃºt ngáº¯n. Em cÃ³ hai cÃ¢u há»i:
Má»i ngÆ°á»i cÃ³ thá»ƒ cho em Ã½ kiáº¿n vá» váº¥n Ä‘á» mÃ  em trÃ¬nh bÃ y cÃ¡ch tiáº¿p cáº­n Ä‘á»ƒ xÃ¢y dá»±ng model tá»‘t hÆ¡n hoáº·c báº±ng mÃ  em cáº£i thiá»‡n tá»« paper Ä‘Æ°á»£c khÃ´ng áº¡?
Má»i ngÆ°á»i cÃ³ biáº¿t sá»­ dá»¥ng trick Ä‘á»ƒ chuyá»ƒn code tá»« keras sang thuáº§n tensorflow khÃ´ng áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» framework tensorflow vÃ¬ tháº§y hÆ°á»›ng dáº«n cá»§a em gá»£i Ã½ nÃªn há»c vÃ  sá»­ dá»¥ng cho academic, hiá»‡n táº¡i em Ä‘ang lÃ m khÃ³a luáº­n Ä‘áº¡i há»c nÃªn cÃ³ quan tÃ¢m vá» sá»­ dá»¥ng framework nÃ y cho nghiÃªn cá»©u. TrÆ°á»›c giá» em váº«n build, train vÃ  evaluate model vá»›i keras. Em cÃ³ lÃªn máº¡ng tÃ¬m hiá»ƒu thÃ¬ cÅ©ng náº¯m Ä‘Æ°á»£c má»™t sá»‘ Æ°u Ä‘iá»ƒm cá»§a tensorflow so vá»›i keras vá» thá»i gian cháº¡y, xÃ¢y dá»±ng nhá»¯ng model vá»›i performance cao, dataset lá»›n, nhÆ°ng nhÆ°á»£c Ä‘iá»ƒm lÃ  khÃ³ implement, debug. Hiá»‡n táº¡i, cÃ¡i em Ä‘ang muá»‘n lÃ m lÃ  implement láº¡i má»™t architecture tá»« 1 paper viáº¿t láº¡i dÆ°á»›i dáº¡ng tensorflow, sau Ä‘Ã³ train vÃ  evaluate trÃªn dataset cÅ©ng tá»« paper xem cÃ³ thá»ƒ reproduce Ä‘Æ°á»£c performance metrics gáº§n giá»‘ng paper khÃ´ng. Má»¥c Ä‘Ã­ch cuá»‘i cÃ¹ng lÃ  lÃ m sao Ä‘Ã³, em cÃ³ thá»ƒ modify láº¡i code cho architecture, thÃªm new data cho dataset cÅ©, hoáº·c tunning cÃ¡c hyperparameters á»Ÿ cÃ¡c module trong model Ä‘á»ƒ lÃ m sao cho perfomance metrics cáº£i thiá»‡n, time vÃ  space resource Ä‘Æ°á»£c rÃºt ngáº¯n. Em cÃ³ hai cÃ¢u há»i: Má»i ngÆ°á»i cÃ³ thá»ƒ cho em Ã½ kiáº¿n vá» váº¥n Ä‘á» mÃ  em trÃ¬nh bÃ y cÃ¡ch tiáº¿p cáº­n Ä‘á»ƒ xÃ¢y dá»±ng model tá»‘t hÆ¡n hoáº·c báº±ng mÃ  em cáº£i thiá»‡n tá»« paper Ä‘Æ°á»£c khÃ´ng áº¡? Má»i ngÆ°á»i cÃ³ biáº¿t sá»­ dá»¥ng trick Ä‘á»ƒ chuyá»ƒn code tá»« keras sang thuáº§n tensorflow khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡",,,,,
"Data leakage trong machine learning
ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m 1 project vá» dá»¯ liá»‡u dáº¡ng báº£ng. Viá»‡c phÃ¢n chia táº­p dá»¯ liá»‡u cá»§a e nhÆ° sau: láº¥y 450k dá»¯ liá»‡u cho train_val set (thá»±c hiá»‡n CV 5 fold), 150k cho local test set. VÃ  hiá»‡n táº¡i e Ä‘ang phÃ¢n vÃ¢n 2 strategies:
DÃ¹ng quantile transform Ä‘á»ƒ Ä‘Æ°a train-val vá» Gaussian distribution, sau Ä‘Ã³ trong quÃ¡ trÃ¬nh kfold, thá»±c hiá»‡n min-max scaler Ä‘á»ƒ chuáº©n hÃ³a dá»¯ liá»‡u, bá» outlier
Trong quÃ¡ trÃ¬nh kfold, thá»±c hiá»‡n cáº£ quantile transform vÃ  min-max scaler, táº¥t nhiÃªn lÃ  fit trÃªn táº­p train vÃ  transform trÃªn táº­p validation. 
Vá»›i [1], data leakage xáº£y ra khi thá»±c hiá»‡n transform trÆ°á»›c khi chia fold. Vá»›i [2], sáº½ khÃ´ng cÃ³ rá»§i ro do data leakage gÃ¢y ra. NhÆ°ng  khi so sÃ¡nh trÃªn cáº£ CV vÃ  local test set, loss cá»§a [2] tháº¥p hÆ¡n [1], váº­y em sai á»Ÿ Ä‘Ã¢u áº¡, vÃ  theo a/c thÃ¬ cÃ¡ch nÃ o tá»‘t hÆ¡n","Data leakage trong machine learning ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m 1 project vá» dá»¯ liá»‡u dáº¡ng báº£ng. Viá»‡c phÃ¢n chia táº­p dá»¯ liá»‡u cá»§a e nhÆ° sau: láº¥y 450k dá»¯ liá»‡u cho train_val set (thá»±c hiá»‡n CV 5 fold), 150k cho local test set. VÃ  hiá»‡n táº¡i e Ä‘ang phÃ¢n vÃ¢n 2 strategies: DÃ¹ng quantile transform Ä‘á»ƒ Ä‘Æ°a train-val vá» Gaussian distribution, sau Ä‘Ã³ trong quÃ¡ trÃ¬nh kfold, thá»±c hiá»‡n min-max scaler Ä‘á»ƒ chuáº©n hÃ³a dá»¯ liá»‡u, bá» outlier Trong quÃ¡ trÃ¬nh kfold, thá»±c hiá»‡n cáº£ quantile transform vÃ  min-max scaler, táº¥t nhiÃªn lÃ  fit trÃªn táº­p train vÃ  transform trÃªn táº­p validation. Vá»›i [1], data leakage xáº£y ra khi thá»±c hiá»‡n transform trÆ°á»›c khi chia fold. Vá»›i [2], sáº½ khÃ´ng cÃ³ rá»§i ro do data leakage gÃ¢y ra. NhÆ°ng khi so sÃ¡nh trÃªn cáº£ CV vÃ  local test set, loss cá»§a [2] tháº¥p hÆ¡n [1], váº­y em sai á»Ÿ Ä‘Ã¢u áº¡, vÃ  theo a/c thÃ¬ cÃ¡ch nÃ o tá»‘t hÆ¡n",,,,,
"Xin chÃ o cÃ¡c báº¡n mÃ¬nh lÃ  Nguyá»…n HÆ°ng Quang Kháº£i, sinh viÃªn nÄƒm 4 khoa ToÃ¡n á»¨ng Dá»¥ng trÆ°á»ng ÄH Quá»‘c Táº¿ - ÄHQG TPHCM.

HÃ´m nay trong bÃ i viáº¿t medium mÃ¬nh Ä‘Æ°a Ä‘áº¿n cÃ¡c báº¡n, chá»§ Ä‘á» mÃ¬nh viáº¿t lÃ  vá» Natural Language Processing. Trong bÃ i viáº¿t nÃ y :
MÃ¬nh Ä‘Ã£ cáº­p nháº­t Ä‘áº§y Ä‘á»§ cÃ¡c bÆ°á»›c cÆ¡ báº£n Ä‘á»ƒ xá»­ lÃ½ text data
Fitting cÃ¡c mÃ´ hÃ¬nh ML 
Sá»­ dá»¥ng Ensemble Model Ä‘á»ƒ káº¿t há»£p sá»©c máº¡nh cÃ¡c ML models
MÃ¬nh Ä‘Ã£ á»©ng dá»¥ng cÃ¡c kÄ© thuáº­t trÃªn Ä‘á»ƒ sá»­ dá»¥ng vÃ o project phÃ¢n loáº¡i review khen/chÃª cá»§a nhÃ  hÃ ng 

BÃ i viáº¿t nÃ y mÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng viáº¿t dá»… hiá»ƒu, chi tiáº¿t, vÃ  nhá»¯ng ngÆ°á»i beginners trong lÄ©nh vá»±c NLP Ä‘á»u cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c 

Hi vá»ng bÃ i viáº¿t nÃ y cÃ³ Ã­ch cho cÃ¡c báº¡n, vÃ  Ä‘á»«ng quÃªn share/like vÃ  clap hands trÃªn medium Ä‘á»ƒ á»§ng há»™ mÃ¬nh ná»¯a nha !!!!

https://medium.com/@liangnguyen612/sentiment-analysis-in-python-81-accuracy-ab5d694b7ef8","Xin chÃ o cÃ¡c báº¡n mÃ¬nh lÃ  Nguyá»…n HÆ°ng Quang Kháº£i, sinh viÃªn nÄƒm 4 khoa ToÃ¡n á»¨ng Dá»¥ng trÆ°á»ng ÄH Quá»‘c Táº¿ - ÄHQG TPHCM. HÃ´m nay trong bÃ i viáº¿t medium mÃ¬nh Ä‘Æ°a Ä‘áº¿n cÃ¡c báº¡n, chá»§ Ä‘á» mÃ¬nh viáº¿t lÃ  vá» Natural Language Processing. Trong bÃ i viáº¿t nÃ y : MÃ¬nh Ä‘Ã£ cáº­p nháº­t Ä‘áº§y Ä‘á»§ cÃ¡c bÆ°á»›c cÆ¡ báº£n Ä‘á»ƒ xá»­ lÃ½ text data Fitting cÃ¡c mÃ´ hÃ¬nh ML Sá»­ dá»¥ng Ensemble Model Ä‘á»ƒ káº¿t há»£p sá»©c máº¡nh cÃ¡c ML models MÃ¬nh Ä‘Ã£ á»©ng dá»¥ng cÃ¡c kÄ© thuáº­t trÃªn Ä‘á»ƒ sá»­ dá»¥ng vÃ o project phÃ¢n loáº¡i review khen/chÃª cá»§a nhÃ  hÃ ng BÃ i viáº¿t nÃ y mÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng viáº¿t dá»… hiá»ƒu, chi tiáº¿t, vÃ  nhá»¯ng ngÆ°á»i beginners trong lÄ©nh vá»±c NLP Ä‘á»u cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c Hi vá»ng bÃ i viáº¿t nÃ y cÃ³ Ã­ch cho cÃ¡c báº¡n, vÃ  Ä‘á»«ng quÃªn share/like vÃ  clap hands trÃªn medium Ä‘á»ƒ á»§ng há»™ mÃ¬nh ná»¯a nha !!!! https://medium.com/@liangnguyen612/sentiment-analysis-in-python-81-accuracy-ab5d694b7ef8",,,,,
#book,,#book,,,,
"NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu váº¥n Ä‘á» nÃ y, em máº¡nh dáº¡n gá»­i tá»›i anh em newbie má»™t bÃ i toÃ¡n má»›i vá» CBIR - Content-based Image Retrieval.
ChÃº Ã½: ÄÃ¢y lÃ  á»Ÿ dáº¡ng cÆ¡ báº£n nháº¥t, Ä‘á»ƒ anh em newbie hiá»ƒu váº¥n Ä‘á». Äá»ƒ dÃ¹ng thá»±c táº¿ cÃ²n pháº£i nghiÃªn cá»©u nhiá»u ná»¯a. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie!
Mong ad duyá»‡t bÃ i!","NhÃ¢n dá»‹p Ä‘ang tÃ¬m hiá»ƒu váº¥n Ä‘á» nÃ y, em máº¡nh dáº¡n gá»­i tá»›i anh em newbie má»™t bÃ i toÃ¡n má»›i vá» CBIR - Content-based Image Retrieval. ChÃº Ã½: ÄÃ¢y lÃ  á»Ÿ dáº¡ng cÆ¡ báº£n nháº¥t, Ä‘á»ƒ anh em newbie hiá»ƒu váº¥n Ä‘á». Äá»ƒ dÃ¹ng thá»±c táº¿ cÃ²n pháº£i nghiÃªn cá»©u nhiá»u ná»¯a. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie! Mong ad duyá»‡t bÃ i!",,,,,
"ChÃ o mn, em lÃ  sv má»›i báº­p báº½ há»c vá» AI trÃªn trÆ°á»ng, em má»›i há»c Ä‘c 2 buá»•i nhÆ°ng pháº£i dky BTL. Em Ä‘á»‹nh lÃ m vá» cÃ¡i dá»± bÃ¡o thá»i tiáº¿t hoáº·c dá»± bÃ¡o cÃ¡i gÃ¬ Ä‘Ã³ thÃ¬ a/c trong nhÃ³m cÃ³ ai cÃ³ tÃ i liá»‡u há»¯u Ã­ch khÃ´ng cho em tham kháº£o vá»›i ah","ChÃ o mn, em lÃ  sv má»›i báº­p báº½ há»c vá» AI trÃªn trÆ°á»ng, em má»›i há»c Ä‘c 2 buá»•i nhÆ°ng pháº£i dky BTL. Em Ä‘á»‹nh lÃ m vá» cÃ¡i dá»± bÃ¡o thá»i tiáº¿t hoáº·c dá»± bÃ¡o cÃ¡i gÃ¬ Ä‘Ã³ thÃ¬ a/c trong nhÃ³m cÃ³ ai cÃ³ tÃ i liá»‡u há»¯u Ã­ch khÃ´ng cho em tham kháº£o vá»›i ah",,,,,
"Deep learning for computer vision with python, Adrian Rosebrock
https://drive.google.com/uc?export=download&id=1H33SjUAYMzfwD8PM3UR1pHiCij4pB2KZ","Deep learning for computer vision with python, Adrian Rosebrock https://drive.google.com/uc?export=download&id=1H33SjUAYMzfwD8PM3UR1pHiCij4pB2KZ",,,,,
Minh xin chia seÌ‰ laÌ£i phÃ¢Ì€n thuyÃªÌt triÌ€nh vaÌ€ triÌ€nh baÌ€y cuÌ‰a caÌc Ä‘Ã´Ì£i thi TOP 3 cuÃ´Ì£c thi AICOVIDVN 115M Challenge.,Minh xin chia seÌ‰ laÌ£i phÃ¢Ì€n thuyÃªÌt triÌ€nh vaÌ€ triÌ€nh baÌ€y cuÌ‰a caÌc Ä‘Ã´Ì£i thi TOP 3 cuÃ´Ì£c thi AICOVIDVN 115M Challenge.,,,,,
"Má»i ngÆ°á»i cho em há»i, dataset nhÆ° nÃ o thÃ¬ thÃ­ch há»£p Ä‘á»ƒ train model tacotron2 áº¡, em cÃ³ theo 1 bÃ i trÃªn viblo táº£i file mp3 truyá»‡n ma nhÆ°ng output khÃ¡ fail áº¡. tks","Má»i ngÆ°á»i cho em há»i, dataset nhÆ° nÃ o thÃ¬ thÃ­ch há»£p Ä‘á»ƒ train model tacotron2 áº¡, em cÃ³ theo 1 bÃ i trÃªn viblo táº£i file mp3 truyá»‡n ma nhÆ°ng output khÃ¡ fail áº¡. tks",,,,,
"Thá»i gian gáº§n Ä‘Ã¢y mÃ¬nh dÃ nh chÃºt thá»i gian Ä‘á»ƒ phÃ¡t triá»ƒn thÆ° viá»‡n TabML cho dá»¯ liá»‡u dáº¡ng báº£ng. Chá»§ yáº¿u lÃ  trau Ä‘á»“i thÃªm kiáº¿n thá»©c láº­p trÃ¬nh cÅ©ng nhÆ° cáº­p nháº­t cÃ¡c thÆ° viá»‡n ML liÃªn quan.
https://github.com/tiepvupsu/tabml
ThÆ° viá»‡n TabML nÃ y cÃ³ má»™t sá»‘ chá»©c nÄƒng ná»•i báº­t:
1. CÃ³ má»™t há»‡ thá»‘ng quáº£n lÃ½ Ä‘áº·c trÆ°ng riÃªng vá»›i má»—i Ä‘áº·c trÆ°ng Ä‘Æ°á»£c quáº£n lÃ½ trong má»™t class. Sá»± phá»¥ thuá»™c giá»¯a cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c lÆ°u trong má»™t file config dáº¡ng protobuf. Viá»‡c nÃ y giÃºp viá»‡c quáº£n lÃ½ dá»… dÃ ng hÆ¡n.
2. Má»—i experiment Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi má»™t file config dÆ°á»›i dáº¡ng má»™t protobuf. NgÆ°á»i dÃ¹ng chá»‰ cáº§n chá»‰ Ä‘á»‹nh loáº¡i mÃ´ hÃ¬nh, nhÃ£n, Ä‘áº·c trÆ°ng. Config, log huáº¥n luyá»‡n vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»± Ä‘á»™ng lÆ°u láº¡i Ä‘á»ƒ sá»­ dá»¥ng vá» sau.
3. Há»— trá»£ phÃ¢n tÃ­ch mÃ´ hÃ¬nh trÃªn nhiá»u háº¡ng má»¥c cá»§a dá»¯ liá»‡u vá»›i nhiá»u metrics. Há»— trá»£ hiá»ƒn thá»‹ feature importance ngay trong log.
4. TÃ­ch há»£p vá»›i MLflow Ä‘á»ƒ quáº£n lÃ½ tá»«ng thÃ­ nghiá»‡m.
5. Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh xong, ngÆ°á»i dÃ¹ng chá»‰ cáº§n Ä‘Æ°a dá»¯ liá»‡u thÃ´ chÆ°a qua xá»­ lÃ½ vÃ o. Pipeline sáº½ tá»± Ä‘á»™ng sinh Ä‘áº·c trÆ°ng tÆ°Æ¡ng á»©ng Ä‘á»ƒ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n.
6. ...
ThÆ° viá»‡n nÃ y trÆ°á»›c Ä‘Ã¢y mÃ¬nh vÃ  má»™t nhÃ³m ká»¹ sÆ° á»Ÿ VNPT phÃ¡t triá»ƒn ná»™i bá»™ cho má»™t cuá»™c thi trÃªn Kaggle vÃ  dÃ nh thá»© háº¡ng cao. Hiá»‡n táº¡i mÃ¬nh muá»‘n phÃ¡t triá»ƒn thÃªm vÃ  ráº¥t mong cÃ³ thÃªm nhiá»u ngÆ°á»i dÃ¹ng cÃ¹ng gÃ³p Ã½.
CÃ³ má»™t sá»± kiá»‡n thÃºc Ä‘áº©y mÃ¬nh tÃ¡ch riÃªng bá»™ quáº£n lÃ½ Ä‘áº·c trÆ°ng (FeatureManager) ra khá»i pipeline huáº¥n luyá»‡n. MÃ¬nh tham gia má»™t dá»± Ã¡n cÃ³ hai nhÃ³m data science vÃ  data engineer lÃ m viá»‡c gáº§n nhÆ° Ä‘á»™c láº­p. NhÃ³m DS lÃ m má»i thá»© trÃªn notebook vÃ  pandas cÃ³ káº¿t quáº£ ok. NhÃ³m nÃ y táº¡o ra khoáº£ng hÆ¡n 100 Ä‘áº·c trÆ°ng phá»¥ thuá»™c chá»“ng chÃ©o vÃ  cáº­p nháº­t liÃªn tá»¥c. NhÃ³m DE **nhÃ¬n** code Ä‘Ã³ vÃ  chuyá»ƒn sang pyspark cháº¡y vá»›i dá»¯ liá»‡u lá»›n. Káº¿t quáº£ lÃ  hai mÃ´ hinh cháº¡y khÃ¡c háº³n nhau máº·c dÃ¹ *máº¯t thÆ°á»ng* khÃ´ng phÃ¡t hiá»ƒn ra Ä‘iá»ƒm khÃ¡c biá»‡t. MÃ¬nh Ä‘Ã£ nghÄ© ngay Ä‘áº¿n viá»‡c pháº£i tÃ¡ch tá»«ng feature ra vÃ  tÃ­nh toÃ¡n theo hai cÃ¡ch pandas vÃ  pyspark rá»“i táº¡o unit test so sÃ¡nh káº¿t quáº£ sau tá»«ng bÆ°á»›c. Sau Ä‘Ã³ thÃ¬ pháº§n FeatureManger trong thÆ° viá»‡n nÃ y ra Ä‘á»i.","Thá»i gian gáº§n Ä‘Ã¢y mÃ¬nh dÃ nh chÃºt thá»i gian Ä‘á»ƒ phÃ¡t triá»ƒn thÆ° viá»‡n TabML cho dá»¯ liá»‡u dáº¡ng báº£ng. Chá»§ yáº¿u lÃ  trau Ä‘á»“i thÃªm kiáº¿n thá»©c láº­p trÃ¬nh cÅ©ng nhÆ° cáº­p nháº­t cÃ¡c thÆ° viá»‡n ML liÃªn quan. https://github.com/tiepvupsu/tabml ThÆ° viá»‡n TabML nÃ y cÃ³ má»™t sá»‘ chá»©c nÄƒng ná»•i báº­t: 1. CÃ³ má»™t há»‡ thá»‘ng quáº£n lÃ½ Ä‘áº·c trÆ°ng riÃªng vá»›i má»—i Ä‘áº·c trÆ°ng Ä‘Æ°á»£c quáº£n lÃ½ trong má»™t class. Sá»± phá»¥ thuá»™c giá»¯a cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c lÆ°u trong má»™t file config dáº¡ng protobuf. Viá»‡c nÃ y giÃºp viá»‡c quáº£n lÃ½ dá»… dÃ ng hÆ¡n. 2. Má»—i experiment Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi má»™t file config dÆ°á»›i dáº¡ng má»™t protobuf. NgÆ°á»i dÃ¹ng chá»‰ cáº§n chá»‰ Ä‘á»‹nh loáº¡i mÃ´ hÃ¬nh, nhÃ£n, Ä‘áº·c trÆ°ng. Config, log huáº¥n luyá»‡n vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»± Ä‘á»™ng lÆ°u láº¡i Ä‘á»ƒ sá»­ dá»¥ng vá» sau. 3. Há»— trá»£ phÃ¢n tÃ­ch mÃ´ hÃ¬nh trÃªn nhiá»u háº¡ng má»¥c cá»§a dá»¯ liá»‡u vá»›i nhiá»u metrics. Há»— trá»£ hiá»ƒn thá»‹ feature importance ngay trong log. 4. TÃ­ch há»£p vá»›i MLflow Ä‘á»ƒ quáº£n lÃ½ tá»«ng thÃ­ nghiá»‡m. 5. Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh xong, ngÆ°á»i dÃ¹ng chá»‰ cáº§n Ä‘Æ°a dá»¯ liá»‡u thÃ´ chÆ°a qua xá»­ lÃ½ vÃ o. Pipeline sáº½ tá»± Ä‘á»™ng sinh Ä‘áº·c trÆ°ng tÆ°Æ¡ng á»©ng Ä‘á»ƒ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n. 6. ... ThÆ° viá»‡n nÃ y trÆ°á»›c Ä‘Ã¢y mÃ¬nh vÃ  má»™t nhÃ³m ká»¹ sÆ° á»Ÿ VNPT phÃ¡t triá»ƒn ná»™i bá»™ cho má»™t cuá»™c thi trÃªn Kaggle vÃ  dÃ nh thá»© háº¡ng cao. Hiá»‡n táº¡i mÃ¬nh muá»‘n phÃ¡t triá»ƒn thÃªm vÃ  ráº¥t mong cÃ³ thÃªm nhiá»u ngÆ°á»i dÃ¹ng cÃ¹ng gÃ³p Ã½. CÃ³ má»™t sá»± kiá»‡n thÃºc Ä‘áº©y mÃ¬nh tÃ¡ch riÃªng bá»™ quáº£n lÃ½ Ä‘áº·c trÆ°ng (FeatureManager) ra khá»i pipeline huáº¥n luyá»‡n. MÃ¬nh tham gia má»™t dá»± Ã¡n cÃ³ hai nhÃ³m data science vÃ  data engineer lÃ m viá»‡c gáº§n nhÆ° Ä‘á»™c láº­p. NhÃ³m DS lÃ m má»i thá»© trÃªn notebook vÃ  pandas cÃ³ káº¿t quáº£ ok. NhÃ³m nÃ y táº¡o ra khoáº£ng hÆ¡n 100 Ä‘áº·c trÆ°ng phá»¥ thuá»™c chá»“ng chÃ©o vÃ  cáº­p nháº­t liÃªn tá»¥c. NhÃ³m DE **nhÃ¬n** code Ä‘Ã³ vÃ  chuyá»ƒn sang pyspark cháº¡y vá»›i dá»¯ liá»‡u lá»›n. Káº¿t quáº£ lÃ  hai mÃ´ hinh cháº¡y khÃ¡c háº³n nhau máº·c dÃ¹ *máº¯t thÆ°á»ng* khÃ´ng phÃ¡t hiá»ƒn ra Ä‘iá»ƒm khÃ¡c biá»‡t. MÃ¬nh Ä‘Ã£ nghÄ© ngay Ä‘áº¿n viá»‡c pháº£i tÃ¡ch tá»«ng feature ra vÃ  tÃ­nh toÃ¡n theo hai cÃ¡ch pandas vÃ  pyspark rá»“i táº¡o unit test so sÃ¡nh káº¿t quáº£ sau tá»«ng bÆ°á»›c. Sau Ä‘Ã³ thÃ¬ pháº§n FeatureManger trong thÆ° viá»‡n nÃ y ra Ä‘á»i.",,,,,
"Anh chá»‹ em vui lÃ²ng chá»‰ phÆ°Æ¡ng hÆ°á»›ng bÃ i toÃ¡n optimization nÃ y giÃºp mÃ¬nh vá»›i.
Giáº£ sá»­ cÃ³ N ngÆ°á»i Ä‘ang cáº§n Ä‘Æ°á»£c phÃ¢n phÃ¡t quÃ , vÃ  cÃ³ V má»©c quÃ  khÃ¡ nhau vá»›i giÃ¡ trá»‹ tá»« tháº¥p Ä‘áº¿n cao (ká»ƒ cáº£ giÃ¡ trá»‹ báº±ng 0, tá»©c lÃ  khÃ´ng phÃ¡t quÃ ). Má»—i ngÆ°á»i chá»‰ Ä‘Æ°á»£c nháº­n 1 mÃ³n quÃ  hoáº·c ko cÃ³ quÃ . VÃ  mÃ¬nh cÃ³ dá»¯ liá»‡u kháº£o sÃ¡t vá» má»©c Ä‘á»™ niá»m vui dÆ°á»›i dáº¡ng matrix P[n][v] (0<=p<=1) cá»§a má»—i ngÆ°á»i thá»© n Ä‘á»‘i vá»›i tá»«ng mÃ³n quÃ  v.
LÃ m sao Ä‘á»ƒ formulate bÃ i toÃ¡n Ä‘á»ƒ maximize tá»•ng niá»m vui, trong khi giá»›i háº¡n tá»•ng giÃ¡ trá»‹ quÃ ? Náº¿u Ä‘Æ°á»£c nÃ³i cho mÃ¬nh cÃ¡ch formulate dÆ°á»›i dáº¡ng matrix nhÃ©. Hoáº·c cho mÃ¬nh má»™t sá»‘ keywords Ä‘á»ƒ tÃ¬m hiá»ƒu dáº¡ng bÃ i toÃ¡n nÃ y.
Cáº£m Æ¡n cáº£ nhÃ .","Anh chá»‹ em vui lÃ²ng chá»‰ phÆ°Æ¡ng hÆ°á»›ng bÃ i toÃ¡n optimization nÃ y giÃºp mÃ¬nh vá»›i. Giáº£ sá»­ cÃ³ N ngÆ°á»i Ä‘ang cáº§n Ä‘Æ°á»£c phÃ¢n phÃ¡t quÃ , vÃ  cÃ³ V má»©c quÃ  khÃ¡ nhau vá»›i giÃ¡ trá»‹ tá»« tháº¥p Ä‘áº¿n cao (ká»ƒ cáº£ giÃ¡ trá»‹ báº±ng 0, tá»©c lÃ  khÃ´ng phÃ¡t quÃ ). Má»—i ngÆ°á»i chá»‰ Ä‘Æ°á»£c nháº­n 1 mÃ³n quÃ  hoáº·c ko cÃ³ quÃ . VÃ  mÃ¬nh cÃ³ dá»¯ liá»‡u kháº£o sÃ¡t vá» má»©c Ä‘á»™ niá»m vui dÆ°á»›i dáº¡ng matrix P[n][v] (0<=p<=1) cá»§a má»—i ngÆ°á»i thá»© n Ä‘á»‘i vá»›i tá»«ng mÃ³n quÃ  v. LÃ m sao Ä‘á»ƒ formulate bÃ i toÃ¡n Ä‘á»ƒ maximize tá»•ng niá»m vui, trong khi giá»›i háº¡n tá»•ng giÃ¡ trá»‹ quÃ ? Náº¿u Ä‘Æ°á»£c nÃ³i cho mÃ¬nh cÃ¡ch formulate dÆ°á»›i dáº¡ng matrix nhÃ©. Hoáº·c cho mÃ¬nh má»™t sá»‘ keywords Ä‘á»ƒ tÃ¬m hiá»ƒu dáº¡ng bÃ i toÃ¡n nÃ y. Cáº£m Æ¡n cáº£ nhÃ .",,,,,
"CÃ¢u há»i vá» viá»‡c xÃ¢y dá»±ng Ä‘áº·c trÆ°ng cho dá»¯ liá»‡u dáº¡ng báº£ng.
LÃ m viá»‡c vá»›i dá»¯ liá»‡u dáº¡ng báº£ng thÃ¬ pháº§n táº¡o Ä‘áº·c trÆ°ng thÆ°á»ng quan trá»ng hÆ¡n pháº§n xÃ¢y dá»±ng mÃ´ hÃ¬nh. Tuy nhiÃªn xÃ¢y dá»±ng Ä‘áº·c trÆ°ng thÆ°á»ng cÃ³ ráº¥t nhiá»u bÆ°á»›c nhá» láº» tá»‰ má»‰:
1. Má»—i Ä‘áº·c trÆ°ng Ä‘Æ°á»£c xá»­ lÃ½ (clean, impute) má»™t cÃ¡ch khÃ¡c nhau.
2. Nhiá»u Ä‘áº·c trÆ°ng phá»¥ thuá»™c nhau, vÃ­ dá»¥ tá»« dá»¯ liá»‡u tuá»•i á»Ÿ dáº¡ng numerical cÃ³ thá»ƒ chuyá»ƒn vá» dáº¡ng categorical dáº¡ng ""tráº» em"", ""thanh niÃªn"", ""trung niÃªn"", ""ngÆ°á»i giÃ "".
3. CÃ¡ch xÃ¢y dá»±ng Ä‘áº·c trÆ°ng cÃ³ thá»ƒ thay Ä‘á»•i vá»›i cÃ¡c tham sá»‘ khÃ¡c nhau. VÃ­ dá»¥ cÃ¡c boundary Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhÃ³m tuá»•i.
4. Dá»¯ liá»‡u lá»›n vÃ  khÃ´ng muá»‘n tÃ­nh toÃ¡n láº¡i toÃ n bá»™ Ä‘áº·c trÆ°ng mÃ  chá»‰ muá»‘n cáº­p nháº­t má»™t sá»‘. Khi cáº­p nháº­t (sá»­a, xÃ³a) má»™t Ä‘áº·c trÆ°ng thÃ¬ cÅ©ng pháº£i cáº­p nháº­t cÃ¡c Ä‘áº·c trÆ°ng khÃ¡c phá»¥ thuá»™c vÃ o nÃ³.
5. Team lá»›n, má»—i thÃ nh viÃªn cÃ³ thá»ƒ táº­p trung vÃ o má»™t nhÃ³m Ä‘áº·c trÆ°ng khÃ¡c nhau vÃ  lÃ m Ä‘á»“ng thá»i. LÃ m thá»ƒ nÃ o Ä‘á»ƒ háº¡n cháº¿ code conflict.
...
ThÆ°á»ng thÃ¬ mÃ¬nh tháº¥y cÃ¡c project máº«u lÃ m cÃ¡c bÆ°á»›c nÃ y má»™t cÃ¡ch tá»± do gá»“m nhiá»u bÆ°á»›c xá»­ lÃ½ pandas trÃ n lan dáº«n Ä‘áº¿n khÃ³ quáº£n lÃ½. MÃ¬nh khÃ´ng nghÄ© Ä‘Ã¢y lÃ  lá»±a chá»n tá»‘t trong production.
CÃ¡c báº¡n thÆ°á»ng dÃ¹ng tool nÃ o Ä‘á»ƒ quáº£n lÃ½ nhá»¯ng tÃ¡c vá»‹ nÃ y?","CÃ¢u há»i vá» viá»‡c xÃ¢y dá»±ng Ä‘áº·c trÆ°ng cho dá»¯ liá»‡u dáº¡ng báº£ng. LÃ m viá»‡c vá»›i dá»¯ liá»‡u dáº¡ng báº£ng thÃ¬ pháº§n táº¡o Ä‘áº·c trÆ°ng thÆ°á»ng quan trá»ng hÆ¡n pháº§n xÃ¢y dá»±ng mÃ´ hÃ¬nh. Tuy nhiÃªn xÃ¢y dá»±ng Ä‘áº·c trÆ°ng thÆ°á»ng cÃ³ ráº¥t nhiá»u bÆ°á»›c nhá» láº» tá»‰ má»‰: 1. Má»—i Ä‘áº·c trÆ°ng Ä‘Æ°á»£c xá»­ lÃ½ (clean, impute) má»™t cÃ¡ch khÃ¡c nhau. 2. Nhiá»u Ä‘áº·c trÆ°ng phá»¥ thuá»™c nhau, vÃ­ dá»¥ tá»« dá»¯ liá»‡u tuá»•i á»Ÿ dáº¡ng numerical cÃ³ thá»ƒ chuyá»ƒn vá» dáº¡ng categorical dáº¡ng ""tráº» em"", ""thanh niÃªn"", ""trung niÃªn"", ""ngÆ°á»i giÃ "". 3. CÃ¡ch xÃ¢y dá»±ng Ä‘áº·c trÆ°ng cÃ³ thá»ƒ thay Ä‘á»•i vá»›i cÃ¡c tham sá»‘ khÃ¡c nhau. VÃ­ dá»¥ cÃ¡c boundary Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhÃ³m tuá»•i. 4. Dá»¯ liá»‡u lá»›n vÃ  khÃ´ng muá»‘n tÃ­nh toÃ¡n láº¡i toÃ n bá»™ Ä‘áº·c trÆ°ng mÃ  chá»‰ muá»‘n cáº­p nháº­t má»™t sá»‘. Khi cáº­p nháº­t (sá»­a, xÃ³a) má»™t Ä‘áº·c trÆ°ng thÃ¬ cÅ©ng pháº£i cáº­p nháº­t cÃ¡c Ä‘áº·c trÆ°ng khÃ¡c phá»¥ thuá»™c vÃ o nÃ³. 5. Team lá»›n, má»—i thÃ nh viÃªn cÃ³ thá»ƒ táº­p trung vÃ o má»™t nhÃ³m Ä‘áº·c trÆ°ng khÃ¡c nhau vÃ  lÃ m Ä‘á»“ng thá»i. LÃ m thá»ƒ nÃ o Ä‘á»ƒ háº¡n cháº¿ code conflict. ... ThÆ°á»ng thÃ¬ mÃ¬nh tháº¥y cÃ¡c project máº«u lÃ m cÃ¡c bÆ°á»›c nÃ y má»™t cÃ¡ch tá»± do gá»“m nhiá»u bÆ°á»›c xá»­ lÃ½ pandas trÃ n lan dáº«n Ä‘áº¿n khÃ³ quáº£n lÃ½. MÃ¬nh khÃ´ng nghÄ© Ä‘Ã¢y lÃ  lá»±a chá»n tá»‘t trong production. CÃ¡c báº¡n thÆ°á»ng dÃ¹ng tool nÃ o Ä‘á»ƒ quáº£n lÃ½ nhá»¯ng tÃ¡c vá»‹ nÃ y?",,,,,
vnquant package version 0.0.3,vnquant package version 0.0.3,,,,,
"ChaÌ€o caÌc baÌ£n!
Xin chia seÌ‰ vÆ¡Ìi caÌc masters Catboost mÃ´Ì£t traÌ‰i nghiÃªÌ£m khÃ´ng biÃªÌt nÃªn goÌ£i tÃªn nhÆ° thÃªÌ naÌ€o. NÃªÌu ai Ä‘oÌ Ä‘aÌƒ gÄƒÌ£p trÆ°Æ¡Ì€ng hÆ¡Ì£p tÆ°Æ¡ng tÆ°Ì£ thiÌ€ maÌch miÌ€nh caÌch giaÌ‰i quyÃªÌt vÆ¡Ìi nheÌ. Xin caÌ‰m Æ¡n trÆ°Æ¡Ìc rÃ¢Ìt nhiÃªÌ€u.
SÃ´Ì laÌ€ miÌ€nh coÌ duÌ€ng Catboost cho baÌ€i toaÌn phÃ¢n loaÌ£i nhiÌ£ phÃ¢n. ÄÃ¢Ì€u vaÌ€o coÌ khoaÌ‰ng 11k Ä‘iÃªÌ‰m dÆ°Ìƒ liÃªÌ£u vÆ¡Ìi 31 fields: 29 float + 2 categorical. MiÌ€nh train model vÆ¡Ìi toaÌ€n bÃ´Ì£ tham sÃ´Ì Ä‘ÃªÌ‰ Æ¡Ì‰ mÄƒÌ£c Ä‘iÌ£nh, chiÌ‰ caÌ€i Ä‘ÄƒÌ£t random_state vaÌ€ chiÌ‰ Ä‘iÌ£nh index cuÌ‰a categorical features. KÃªÌt quaÌ‰ khÃ´ng cao lÄƒÌm nhÆ°ng chÃ¢Ìp nhÃ¢Ì£n Ä‘Æ°Æ¡Ì£c. MiÌ€nh coÌ thÆ°Ì‰ trÃªn maÌy vÆ¡Ìi CPU i7 vaÌ€ i5, thÃ¢Ìy kÃªÌt quaÌ‰ dÆ°Ì£ Ä‘oaÌn probability giÃ´Ìng nhau, chiÌ‰ khaÌc nhau cÆ¡Ìƒ 10^-16, nghiÌƒ chÄƒÌc do tiÌnh toaÌn giÌ€ Ä‘oÌ. TÆ¡Ìi khi chaÌ£y trÃªn CPU Xeon, hoÄƒÌ£c AMD thiÌ€ taÌ hoÌ‰a kÃªÌt quaÌ‰ sai lÃªÌ£ch rÃ¢Ìt nhiÃªÌ€u, khÃ´ng biÃªÌt chuyÃªÌ£n giÌ€ Ä‘aÌƒ xaÌ‰y ra, mÄƒÌ£c duÌ€ mÃ´i trÆ°Æ¡Ì€ng caÌ€i Ä‘ÄƒÌ£t y chang nhau. TÆ°Ìc laÌ€ khÃ´ng taÌi lÃ¢Ì£p kÃªÌt quaÌ‰ Ä‘Æ°Æ¡Ì£c. MiÌ€nh coÌ tham khaÌ‰o github cuÌ‰a Catboost thiÌ€ Ä‘Æ°Æ¡Ì£c gÆ¡Ì£i yÌ haÌƒy disable caÌi AVX2 branch vaÌ€ build laÌ£i CatBooost tÆ°Ì€ source code C++.
CaÌi naÌ€y nÃªÌu laÌ€m trong cuÌ€ng Ä‘Ã´Ì£i nhoÌm thiÌ€ khÃ´ng sao, nhÆ°ng nÃªÌu triÃªÌ‰n khai cho khaÌch haÌ€ng vaÌ€ hoÌ£ nÃ¢ng cÃ¢Ìp phÃ¢Ì€n cÆ°Ìng, thay Ä‘Ã´Ì‰i hÃªÌ£ Ä‘iÃªÌ€u haÌ€nh thiÌ€ chÄƒÌc laÌ€ coÌ chuyÃªÌ£n. VÃ¢Ì£y nÃªn miÌ€nh khÃ´ng Ä‘i theo caÌch naÌ€y maÌ€ tiÌ€m caÌch thay Ä‘Ã´Ì‰i caÌc hyper-parameters. TÆ¡Ìi Ä‘Ã¢y thiÌ€ kÃªÌt quaÌ‰ coÌ thÃªÌ‰ hoÌ€m hoÌ€m taÌi lÃ¢Ì£p Ä‘Æ°Æ¡Ì£c bÄƒÌ€ng caÌch tÄƒng chiÃªÌ€u sÃ¢u cuÌ‰a cÃ¢y (depth) tÆ°Ì€ mÄƒÌ£c Ä‘iÌ£nh 6 lÃªn 8 (hoÄƒÌ£c lÆ¡Ìn hÆ¡n) vaÌ€ giaÌ‰m tiÌ‰ sÃ´Ì colsample_bylevel/rms xuÃ´Ìng 0.5 (vaÌ€ thÃ¢Ìp hÆ¡n) (tÆ°Æ¡ng Ä‘Æ°Æ¡ng viÃªÌ£c khÃ´ng lÃ¢Ìy nhiÃªÌ€u hÆ¡n nÆ°Ì‰a sÃ´Ì cÃ´Ì£t mÃ´Ìƒi lÃ¢Ì€n build tree tiÃªÌp theo). CaÌch thÆ°Ì nhÃ¢Ìt thiÌ€ biÌ£ overfit trÃªn tÃ¢Ì£p train, caÌch thÆ°Ì 2 thiÌ€ khÃ´ng.
ThÃ¢Ì£t sÆ°Ì£ laÌ€ cuÌƒng chÆ°a Ä‘oaÌn Ä‘Æ°Æ¡Ì£c chuyÃªÌ£n giÌ€ Ä‘aÌƒ xaÌ‰y ra vÆ¡Ìi caÌc con chip vaÌ€ tÃ¢Ì£p lÃªÌ£nh hÆ°Æ¡Ìng dÃ¢Ìƒn (AVX) cuÌ‰a noÌ. HoÄƒÌ£c chuyÃªÌ£n giÌ€ Ä‘oÌ Ä‘aÌƒ xaÌ‰y ra vÆ¡Ìi dÆ°Ìƒ liÃªÌ£u Ä‘Ã¢Ì€u vaÌ€o. NhÆ°ng chÄƒÌc khÃ´ng quy chuÌ£p cho dÆ°Ìƒ liÃªÌ£u Ä‘Æ°Æ¡Ì£c, viÌ€ dÆ°Ìƒ liÃªÌ£u coÌ aÌ‰nh hÆ°Æ¡Ì‰ng xÃ¢Ìu thiÌ€ cuÌƒng xÃ¢Ìu nhÆ° nhau vÆ¡Ìi caÌc con chip chÆ°Ì?","ChaÌ€o caÌc baÌ£n! Xin chia seÌ‰ vÆ¡Ìi caÌc masters Catboost mÃ´Ì£t traÌ‰i nghiÃªÌ£m khÃ´ng biÃªÌt nÃªn goÌ£i tÃªn nhÆ° thÃªÌ naÌ€o. NÃªÌu ai Ä‘oÌ Ä‘aÌƒ gÄƒÌ£p trÆ°Æ¡Ì€ng hÆ¡Ì£p tÆ°Æ¡ng tÆ°Ì£ thiÌ€ maÌch miÌ€nh caÌch giaÌ‰i quyÃªÌt vÆ¡Ìi nheÌ. Xin caÌ‰m Æ¡n trÆ°Æ¡Ìc rÃ¢Ìt nhiÃªÌ€u. SÃ´Ì laÌ€ miÌ€nh coÌ duÌ€ng Catboost cho baÌ€i toaÌn phÃ¢n loaÌ£i nhiÌ£ phÃ¢n. ÄÃ¢Ì€u vaÌ€o coÌ khoaÌ‰ng 11k Ä‘iÃªÌ‰m dÆ°Ìƒ liÃªÌ£u vÆ¡Ìi 31 fields: 29 float + 2 categorical. MiÌ€nh train model vÆ¡Ìi toaÌ€n bÃ´Ì£ tham sÃ´Ì Ä‘ÃªÌ‰ Æ¡Ì‰ mÄƒÌ£c Ä‘iÌ£nh, chiÌ‰ caÌ€i Ä‘ÄƒÌ£t random_state vaÌ€ chiÌ‰ Ä‘iÌ£nh index cuÌ‰a categorical features. KÃªÌt quaÌ‰ khÃ´ng cao lÄƒÌm nhÆ°ng chÃ¢Ìp nhÃ¢Ì£n Ä‘Æ°Æ¡Ì£c. MiÌ€nh coÌ thÆ°Ì‰ trÃªn maÌy vÆ¡Ìi CPU i7 vaÌ€ i5, thÃ¢Ìy kÃªÌt quaÌ‰ dÆ°Ì£ Ä‘oaÌn probability giÃ´Ìng nhau, chiÌ‰ khaÌc nhau cÆ¡Ìƒ 10^-16, nghiÌƒ chÄƒÌc do tiÌnh toaÌn giÌ€ Ä‘oÌ. TÆ¡Ìi khi chaÌ£y trÃªn CPU Xeon, hoÄƒÌ£c AMD thiÌ€ taÌ hoÌ‰a kÃªÌt quaÌ‰ sai lÃªÌ£ch rÃ¢Ìt nhiÃªÌ€u, khÃ´ng biÃªÌt chuyÃªÌ£n giÌ€ Ä‘aÌƒ xaÌ‰y ra, mÄƒÌ£c duÌ€ mÃ´i trÆ°Æ¡Ì€ng caÌ€i Ä‘ÄƒÌ£t y chang nhau. TÆ°Ìc laÌ€ khÃ´ng taÌi lÃ¢Ì£p kÃªÌt quaÌ‰ Ä‘Æ°Æ¡Ì£c. MiÌ€nh coÌ tham khaÌ‰o github cuÌ‰a Catboost thiÌ€ Ä‘Æ°Æ¡Ì£c gÆ¡Ì£i yÌ haÌƒy disable caÌi AVX2 branch vaÌ€ build laÌ£i CatBooost tÆ°Ì€ source code C++. CaÌi naÌ€y nÃªÌu laÌ€m trong cuÌ€ng Ä‘Ã´Ì£i nhoÌm thiÌ€ khÃ´ng sao, nhÆ°ng nÃªÌu triÃªÌ‰n khai cho khaÌch haÌ€ng vaÌ€ hoÌ£ nÃ¢ng cÃ¢Ìp phÃ¢Ì€n cÆ°Ìng, thay Ä‘Ã´Ì‰i hÃªÌ£ Ä‘iÃªÌ€u haÌ€nh thiÌ€ chÄƒÌc laÌ€ coÌ chuyÃªÌ£n. VÃ¢Ì£y nÃªn miÌ€nh khÃ´ng Ä‘i theo caÌch naÌ€y maÌ€ tiÌ€m caÌch thay Ä‘Ã´Ì‰i caÌc hyper-parameters. TÆ¡Ìi Ä‘Ã¢y thiÌ€ kÃªÌt quaÌ‰ coÌ thÃªÌ‰ hoÌ€m hoÌ€m taÌi lÃ¢Ì£p Ä‘Æ°Æ¡Ì£c bÄƒÌ€ng caÌch tÄƒng chiÃªÌ€u sÃ¢u cuÌ‰a cÃ¢y (depth) tÆ°Ì€ mÄƒÌ£c Ä‘iÌ£nh 6 lÃªn 8 (hoÄƒÌ£c lÆ¡Ìn hÆ¡n) vaÌ€ giaÌ‰m tiÌ‰ sÃ´Ì colsample_bylevel/rms xuÃ´Ìng 0.5 (vaÌ€ thÃ¢Ìp hÆ¡n) (tÆ°Æ¡ng Ä‘Æ°Æ¡ng viÃªÌ£c khÃ´ng lÃ¢Ìy nhiÃªÌ€u hÆ¡n nÆ°Ì‰a sÃ´Ì cÃ´Ì£t mÃ´Ìƒi lÃ¢Ì€n build tree tiÃªÌp theo). CaÌch thÆ°Ì nhÃ¢Ìt thiÌ€ biÌ£ overfit trÃªn tÃ¢Ì£p train, caÌch thÆ°Ì 2 thiÌ€ khÃ´ng. ThÃ¢Ì£t sÆ°Ì£ laÌ€ cuÌƒng chÆ°a Ä‘oaÌn Ä‘Æ°Æ¡Ì£c chuyÃªÌ£n giÌ€ Ä‘aÌƒ xaÌ‰y ra vÆ¡Ìi caÌc con chip vaÌ€ tÃ¢Ì£p lÃªÌ£nh hÆ°Æ¡Ìng dÃ¢Ìƒn (AVX) cuÌ‰a noÌ. HoÄƒÌ£c chuyÃªÌ£n giÌ€ Ä‘oÌ Ä‘aÌƒ xaÌ‰y ra vÆ¡Ìi dÆ°Ìƒ liÃªÌ£u Ä‘Ã¢Ì€u vaÌ€o. NhÆ°ng chÄƒÌc khÃ´ng quy chuÌ£p cho dÆ°Ìƒ liÃªÌ£u Ä‘Æ°Æ¡Ì£c, viÌ€ dÆ°Ìƒ liÃªÌ£u coÌ aÌ‰nh hÆ°Æ¡Ì‰ng xÃ¢Ìu thiÌ€ cuÌƒng xÃ¢Ìu nhÆ° nhau vÆ¡Ìi caÌc con chip chÆ°Ì?",,,,,
"Hi má»i ngÆ°á»i,
Em Ä‘Æ°á»£c supervisor yÃªu cáº§u há»c Tensorflow vÃ  Unet Ä‘á»ƒ Ä‘á»c hiá»ƒu code, reproduce vÃ  lÃ m má»™t sá»‘ bÃ i toÃ¡n Ä‘Æ¡n giáº£n áº¡ nhÆ°ng em chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡. Em cÃ³ biáº¿t má»™t chÃºt vá» Machine learning áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ recommend cho em má»™t sá»‘ courses Ä‘á»ƒ há»c cÃ¡i nÃ y khÃ´ng áº¡?","Hi má»i ngÆ°á»i, Em Ä‘Æ°á»£c supervisor yÃªu cáº§u há»c Tensorflow vÃ  Unet Ä‘á»ƒ Ä‘á»c hiá»ƒu code, reproduce vÃ  lÃ m má»™t sá»‘ bÃ i toÃ¡n Ä‘Æ¡n giáº£n áº¡ nhÆ°ng em chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡. Em cÃ³ biáº¿t má»™t chÃºt vá» Machine learning áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ recommend cho em má»™t sá»‘ courses Ä‘á»ƒ há»c cÃ¡i nÃ y khÃ´ng áº¡?",,,,,
"ChÃ o má»i ngÆ°á»i
Hiá»‡n táº¡i mÃ¬nh lÃ  du há»c sinh á»Ÿ Ãšc, dá»± Ä‘á»‹nh 1 lÃ  Ä‘i lÃ m 2 lÃ  Ä‘Äƒng kÃ½ há»c master of AI
MÃ¬nh muá»‘n há»i theo kinh nghiá»‡m cÃ¡c bÃ¡c á»Ÿ Ä‘Ã¢y thÃ¬ AI cÃ³ thá»ƒ tá»± há»c Ä‘Æ°á»£c ko?
VÃ¬ mÃ¬nh ráº¥t muá»‘n há»c AI mÃ  náº¿u Ä‘i lÃ m vÃ  Ä‘i há»c trong trÆ°á»ng cÃ¹ng 1 lÃºc chá»‰ sá»£ há»c ko Ä‘áº¿n nÆ¡i mÃ  tá»‘n tiá»n","ChÃ o má»i ngÆ°á»i Hiá»‡n táº¡i mÃ¬nh lÃ  du há»c sinh á»Ÿ Ãšc, dá»± Ä‘á»‹nh 1 lÃ  Ä‘i lÃ m 2 lÃ  Ä‘Äƒng kÃ½ há»c master of AI MÃ¬nh muá»‘n há»i theo kinh nghiá»‡m cÃ¡c bÃ¡c á»Ÿ Ä‘Ã¢y thÃ¬ AI cÃ³ thá»ƒ tá»± há»c Ä‘Æ°á»£c ko? VÃ¬ mÃ¬nh ráº¥t muá»‘n há»c AI mÃ  náº¿u Ä‘i lÃ m vÃ  Ä‘i há»c trong trÆ°á»ng cÃ¹ng 1 lÃºc chá»‰ sá»£ há»c ko Ä‘áº¿n nÆ¡i mÃ  tá»‘n tiá»n",,,,,
"On-device ML Ä‘ang lÃ  xu tháº¿. NgÆ°á»i dÃ¹ng sáº½ cÃ³ nhiá»u quyá»n riÃªng tÆ° hÆ¡n khi dá»¯ liá»‡u cá»§a há» khÃ´ng chuyá»ƒn qua chuyá»ƒn láº¡i tá»›i cloud. BÃ¹ láº¡i, há» sáº½ gÃ¡nh chi phÃ­ tÃ­nh toÃ¡n cho cÃ¡c mÃ´ hÃ¬nh ML báº±ng cÃ¡ch mua cÃ¡c thiáº¿t bá»‹ há»— trá»£ tá»‘t cÃ¡c tÃ­nh toÃ¡n liÃªn quan tá»›i ML.","On-device ML Ä‘ang lÃ  xu tháº¿. NgÆ°á»i dÃ¹ng sáº½ cÃ³ nhiá»u quyá»n riÃªng tÆ° hÆ¡n khi dá»¯ liá»‡u cá»§a há» khÃ´ng chuyá»ƒn qua chuyá»ƒn láº¡i tá»›i cloud. BÃ¹ láº¡i, há» sáº½ gÃ¡nh chi phÃ­ tÃ­nh toÃ¡n cho cÃ¡c mÃ´ hÃ¬nh ML báº±ng cÃ¡ch mua cÃ¡c thiáº¿t bá»‹ há»— trá»£ tá»‘t cÃ¡c tÃ­nh toÃ¡n liÃªn quan tá»›i ML.",,,,,
"Xin chÃ o má»i ngÆ°á»i, em muá»‘n lÃ m 1 project vá» Machine learning lÃ  ""phÃ¢n loáº¡i tÃ¬nh tráº¡ng cá»§a bá»‡nh nhÃ¢n máº¯c covid-19, sau Ä‘Ã³ Ä‘Æ°a ra giáº£i phÃ¡p chá»¯a bÃªnh há»£p lÃ­"". Em cÅ©ng má»›i báº¯t Ä‘áº§u há»c ML nÃªn khÃ´ng rÃµ rÃ ng láº¯m, má»i ngÆ°á»i cho em há»i lÃ  cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c dataset vá» covid á»Ÿ Ä‘Ã¢u váº­y áº¡. Em cáº£m Æ¡n nhiá»u ğŸ¥°ğŸ¥°","Xin chÃ o má»i ngÆ°á»i, em muá»‘n lÃ m 1 project vá» Machine learning lÃ  ""phÃ¢n loáº¡i tÃ¬nh tráº¡ng cá»§a bá»‡nh nhÃ¢n máº¯c covid-19, sau Ä‘Ã³ Ä‘Æ°a ra giáº£i phÃ¡p chá»¯a bÃªnh há»£p lÃ­"". Em cÅ©ng má»›i báº¯t Ä‘áº§u há»c ML nÃªn khÃ´ng rÃµ rÃ ng láº¯m, má»i ngÆ°á»i cho em há»i lÃ  cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c dataset vá» covid á»Ÿ Ä‘Ã¢u váº­y áº¡. Em cáº£m Æ¡n nhiá»u",,,,,
"[AI Share â€“ Machine Learning Cheat Sheet]
Má»™t cheat sheet vá» Machine Learning chá»‰ dÃ i 5 trang táº­p trung vÃ o cÃ¡c thuáº­t toÃ¡n phá»• biáº¿n nháº¥t. Cheat sheet tÃ³m táº¯t cÃ¡c thuáº­t toÃ¡n Machine Learning, cÃ¡c Æ°u Ä‘iá»ƒm vÃ  cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng. Cheat sheet nÃ y Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« cuá»‘n sÃ¡ch vÃ  cÃ¡c bÃ i viáº¿t hay nháº¥t cá»§a MachineLearningMastery vÃ  HackingNote.","[AI Share â€“ Machine Learning Cheat Sheet] Má»™t cheat sheet vá» Machine Learning chá»‰ dÃ i 5 trang táº­p trung vÃ o cÃ¡c thuáº­t toÃ¡n phá»• biáº¿n nháº¥t. Cheat sheet tÃ³m táº¯t cÃ¡c thuáº­t toÃ¡n Machine Learning, cÃ¡c Æ°u Ä‘iá»ƒm vÃ  cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng. Cheat sheet nÃ y Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« cuá»‘n sÃ¡ch vÃ  cÃ¡c bÃ i viáº¿t hay nháº¥t cá»§a MachineLearningMastery vÃ  HackingNote.",,,,,
"ChÃ o anh em, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Object Tracking cho Ä‘iá»‡n thoáº¡i Android.
NhÆ°ng mÃ¬nh tháº¥y chá»‰ cÃ³ sá»­ dá»¥ng Ä‘Æ°á»£c trÃªn mÃ¡y tÃ­nh nhÃºng hoáº·c mÃ¡y tÃ­nh.
Báº¡n nÃ o biáº¿t vÃ­ dá»¥ nÃ o mÃ  cÃ³ thá»ƒ dÃ¹ng Object Tracking trÃªn Ä‘iá»‡n thoáº¡i Android thÃ¬ cho mÃ¬nh xin Ä‘á»ƒ há»c há»i.
Cáº£m Æ¡n,","ChÃ o anh em, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Object Tracking cho Ä‘iá»‡n thoáº¡i Android. NhÆ°ng mÃ¬nh tháº¥y chá»‰ cÃ³ sá»­ dá»¥ng Ä‘Æ°á»£c trÃªn mÃ¡y tÃ­nh nhÃºng hoáº·c mÃ¡y tÃ­nh. Báº¡n nÃ o biáº¿t vÃ­ dá»¥ nÃ o mÃ  cÃ³ thá»ƒ dÃ¹ng Object Tracking trÃªn Ä‘iá»‡n thoáº¡i Android thÃ¬ cho mÃ¬nh xin Ä‘á»ƒ há»c há»i. Cáº£m Æ¡n,",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 3/2021 vÃ o trong comment cá»§a post nÃ y.
Hoáº·c https://forum.machinelearningcoban.com/c/jobs-events
ChÃºc cÃ¡c báº¡n thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 3/2021 vÃ o trong comment cá»§a post nÃ y. Hoáº·c https://forum.machinelearningcoban.com/c/jobs-events ChÃºc cÃ¡c báº¡n thÃ¡ng má»›i vui váº».",,,,,
"ChÃ o cÃ¡c anh chá»‹, em Ä‘ang lÃ m má»™t task liÃªn quan Ä‘áº¿n viá»‡c thu tháº­p táº¥t cáº£ cÃ¡c Ä‘á»‹a Ä‘iá»ƒm cÃ´ng cá»™ng táº¡i Viá»‡t Nam, sau Ä‘Ã³ nhÃ³m chÃºng láº¡i thÃ nh cÃ¡c má»¥c (bá»‡nh viá»‡n, trÆ°á»ng há»c, nhÃ  hÃ ng,...).
Em Ä‘ang tÃ­nh sá»­ dá»¥ng dá»¯ liá»‡u báº£n Ä‘á»“ tá»« OpenStreetMap Ä‘á»ƒ lÃ m viá»‡c nÃ y. Anh chá»‹ cho em há»i cÃ³ cÃ¡ch nÃ o giáº£i quyáº¿t váº¥n Ä‘á» nÃ y tá»‘t hÆ¡n khÃ´ng áº¡?","ChÃ o cÃ¡c anh chá»‹, em Ä‘ang lÃ m má»™t task liÃªn quan Ä‘áº¿n viá»‡c thu tháº­p táº¥t cáº£ cÃ¡c Ä‘á»‹a Ä‘iá»ƒm cÃ´ng cá»™ng táº¡i Viá»‡t Nam, sau Ä‘Ã³ nhÃ³m chÃºng láº¡i thÃ nh cÃ¡c má»¥c (bá»‡nh viá»‡n, trÆ°á»ng há»c, nhÃ  hÃ ng,...). Em Ä‘ang tÃ­nh sá»­ dá»¥ng dá»¯ liá»‡u báº£n Ä‘á»“ tá»« OpenStreetMap Ä‘á»ƒ lÃ m viá»‡c nÃ y. Anh chá»‹ cho em há»i cÃ³ cÃ¡ch nÃ o giáº£i quyáº¿t váº¥n Ä‘á» nÃ y tá»‘t hÆ¡n khÃ´ng áº¡?",,,,,
"Hi má»i ngÆ°á»i, Ä‘á»£t nghá»‰ lá»… 2/9 nÃ y mÃ¬nh cÃ³ thá»­ lÃ m 1 project cÃ¡ nhÃ¢n nho nhá» mÃ  khÃ¡c vá»›i nhá»¯ng domain mÃ¬nh lÃ m háº±ng ngÃ y, lÃ  thá»­ train 1 model speech separation. Nháº­n Ä‘áº§u vÃ o lÃ  1 mixed speech cá»§a 2 ngÆ°á»i, output model tráº£ ra lÃ  2 separated speech cua 2 ngÆ°á»i Ä‘Ã³.
Ban Ä‘áº§u search google thÃ¬ mÃ¬nh tháº¥y cÃ³ ráº¥t nhiá»u nhá»¯ng phÆ°Æ¡ng phÃ¡p khÃ¡c nhau, vÃ  Ä‘a sá»‘ lÃ  khÃ¡ phá»©c táº¡p Ä‘á»ƒ cÃ³ thá»ƒ quickly implement vÃ  cÃ³ Ä‘Æ°á»£c feeling vá» bÃ i toÃ¡n. CÃ³ paper thÃ¬ yÃªu cáº§u táº­p data Ä‘áº¿n vÃ i trÄƒm GB, cÃ³ paper thÃ¬ idea chÆ°a Ä‘á»§ chi tiáº¿t Ä‘á»ƒ mÃ¬nh hiá»‡n thá»±c, cÃ³ nhá»¯ng paper máº·c dÃ¹ Ä‘Ã£ cÃ³ implementation trÃªn github nhÆ°ng nhiá»u ngÆ°á»i váº«n khÃ´ng thá»ƒ train ra Ä‘Æ°á»£c káº¿t quáº£ tá»‘t.
Sau 4 ngÃ y, mÃ¬nh cÃ³ thá»­ Ä‘á»c 1 sá»‘ paper vÃ  chá»n ra táº­p data Ä‘Æ¡n giáº£n nháº¥t, nhá»¯ng idea Ä‘Æ¡n giáº£n nháº¥t, sÆ¡ khai nháº¥t Ä‘á»ƒ thá»­ implement vÃ  train thá»­. Qua 1 qua trinh experiment thÃ¬ cÅ©ng train Ä‘Æ°á»£c 1 model cÃ³ káº¿t quáº£ cÅ©ng táº¡m cháº¥p nháº­n Ä‘Æ°á»£c.
MÃ¬nh muá»‘n share link github bÃªn dÆ°á»›i cho máº¥y báº¡n nÃ o muá»‘n thá»­ train nhÃ©. Cho mÃ¬nh 1 star náº¿u máº¥y báº¡n cáº£m tháº¥y há»¯u Ã­ch.
Thá»i gian training model táº§m 2-3 HOURS vá»›i 1 normal GPU","Hi má»i ngÆ°á»i, Ä‘á»£t nghá»‰ lá»… 2/9 nÃ y mÃ¬nh cÃ³ thá»­ lÃ m 1 project cÃ¡ nhÃ¢n nho nhá» mÃ  khÃ¡c vá»›i nhá»¯ng domain mÃ¬nh lÃ m háº±ng ngÃ y, lÃ  thá»­ train 1 model speech separation. Nháº­n Ä‘áº§u vÃ o lÃ  1 mixed speech cá»§a 2 ngÆ°á»i, output model tráº£ ra lÃ  2 separated speech cua 2 ngÆ°á»i Ä‘Ã³. Ban Ä‘áº§u search google thÃ¬ mÃ¬nh tháº¥y cÃ³ ráº¥t nhiá»u nhá»¯ng phÆ°Æ¡ng phÃ¡p khÃ¡c nhau, vÃ  Ä‘a sá»‘ lÃ  khÃ¡ phá»©c táº¡p Ä‘á»ƒ cÃ³ thá»ƒ quickly implement vÃ  cÃ³ Ä‘Æ°á»£c feeling vá» bÃ i toÃ¡n. CÃ³ paper thÃ¬ yÃªu cáº§u táº­p data Ä‘áº¿n vÃ i trÄƒm GB, cÃ³ paper thÃ¬ idea chÆ°a Ä‘á»§ chi tiáº¿t Ä‘á»ƒ mÃ¬nh hiá»‡n thá»±c, cÃ³ nhá»¯ng paper máº·c dÃ¹ Ä‘Ã£ cÃ³ implementation trÃªn github nhÆ°ng nhiá»u ngÆ°á»i váº«n khÃ´ng thá»ƒ train ra Ä‘Æ°á»£c káº¿t quáº£ tá»‘t. Sau 4 ngÃ y, mÃ¬nh cÃ³ thá»­ Ä‘á»c 1 sá»‘ paper vÃ  chá»n ra táº­p data Ä‘Æ¡n giáº£n nháº¥t, nhá»¯ng idea Ä‘Æ¡n giáº£n nháº¥t, sÆ¡ khai nháº¥t Ä‘á»ƒ thá»­ implement vÃ  train thá»­. Qua 1 qua trinh experiment thÃ¬ cÅ©ng train Ä‘Æ°á»£c 1 model cÃ³ káº¿t quáº£ cÅ©ng táº¡m cháº¥p nháº­n Ä‘Æ°á»£c. MÃ¬nh muá»‘n share link github bÃªn dÆ°á»›i cho máº¥y báº¡n nÃ o muá»‘n thá»­ train nhÃ©. Cho mÃ¬nh 1 star náº¿u máº¥y báº¡n cáº£m tháº¥y há»¯u Ã­ch. Thá»i gian training model táº§m 2-3 HOURS vá»›i 1 normal GPU",,,,,
"ChÃ o cÃ¡c anh, chá»‹, em trong grp
MÃ¬nh Ä‘ang lÃ m 1 á»©ng dá»¥ng liÃªn quan Ä‘áº¿n dá»± Ä‘oÃ¡n hiá»ƒn thá»‹ thÃ´ng sá»‘ ca bá»‡nh trong dá»‹ch covid 19 táº¡i Viá»‡t Nam theo tá»‰nh.
MÃ¬nh tÃ¬m trÃªn máº¡ng mÃ  khÃ´ng cÃ³ nguá»“n nÃ o cÃ³ bá»™ data theo ngÃ y cáº£ (trang cá»§a bá»™ y táº¿ chá»‰ cÃ³ thá»ƒ láº¥y sá»‘ liá»‡u 1 ngÃ y hiá»‡n táº¡i).
Anh, chá»‹, em nÃ o cÃ³ biáº¿t nguá»“n nÃ o thÃ¬ cho mÃ¬nh xin thÃ´ng tin vá»›i.","ChÃ o cÃ¡c anh, chá»‹, em trong grp MÃ¬nh Ä‘ang lÃ m 1 á»©ng dá»¥ng liÃªn quan Ä‘áº¿n dá»± Ä‘oÃ¡n hiá»ƒn thá»‹ thÃ´ng sá»‘ ca bá»‡nh trong dá»‹ch covid 19 táº¡i Viá»‡t Nam theo tá»‰nh. MÃ¬nh tÃ¬m trÃªn máº¡ng mÃ  khÃ´ng cÃ³ nguá»“n nÃ o cÃ³ bá»™ data theo ngÃ y cáº£ (trang cá»§a bá»™ y táº¿ chá»‰ cÃ³ thá»ƒ láº¥y sá»‘ liá»‡u 1 ngÃ y hiá»‡n táº¡i). Anh, chá»‹, em nÃ o cÃ³ biáº¿t nguá»“n nÃ o thÃ¬ cho mÃ¬nh xin thÃ´ng tin vá»›i.",,,,,
"CÃ¡c bÃ¡c cho em há»i sao em load thÆ° viá»‡n mnist mÃ  láº§n nÃ o n cÅ©ng ghi lÃ  khÃ´ng tÃ¬m Ä‘Æ°á»£c nhá»‰ , trong khi em táº£i 4 file cá»§a mnist trÃªn trang chá»§ cá»§a há» rá»“i giáº£i nÃ©n vÃ  Ä‘em vÃ o thÆ° má»¥c mnist kia rá»“i . em thá»­ Ä‘i thá»­ láº¡i mÃ  khÃ´ng Ä‘Æ°á»£c","CÃ¡c bÃ¡c cho em há»i sao em load thÆ° viá»‡n mnist mÃ  láº§n nÃ o n cÅ©ng ghi lÃ  khÃ´ng tÃ¬m Ä‘Æ°á»£c nhá»‰ , trong khi em táº£i 4 file cá»§a mnist trÃªn trang chá»§ cá»§a há» rá»“i giáº£i nÃ©n vÃ  Ä‘em vÃ o thÆ° má»¥c mnist kia rá»“i . em thá»­ Ä‘i thá»­ láº¡i mÃ  khÃ´ng Ä‘Æ°á»£c",,,,,
Em má»›i há»c ML trÃªn blog cá»§a anh Tiá»‡p. Python khÃ´ng load Ä‘Æ°Æ¡c dá»¯ liá»‡u MNIST vÃ  cá»© bÃ¡o lá»—i nhÆ° dÆ°á»›i. má»i ngÆ°á»i cho em há»i cÃ¡ch kháº¯c phá»¥c vá»›i áº¡. em loay hoay cáº£ ngÃ y hÃ´m qua mÃ  váº«n chÆ°a fix Ä‘c. dÆ°á»›i Ä‘Ã¢y cÃ³ cáº£ áº£nh thÆ° muc em lÆ°u data áº¡,Em má»›i há»c ML trÃªn blog cá»§a anh Tiá»‡p. Python khÃ´ng load Ä‘Æ°Æ¡c dá»¯ liá»‡u MNIST vÃ  cá»© bÃ¡o lá»—i nhÆ° dÆ°á»›i. má»i ngÆ°á»i cho em há»i cÃ¡ch kháº¯c phá»¥c vá»›i áº¡. em loay hoay cáº£ ngÃ y hÃ´m qua mÃ  váº«n chÆ°a fix Ä‘c. dÆ°á»›i Ä‘Ã¢y cÃ³ cáº£ áº£nh thÆ° muc em lÆ°u data áº¡,,,,,
Má»i ngÆ°á»i giáº£i thÃ­ch cho mÃ¬nh mÃ¡y dÃ²ng Ä‘á» á»Ÿ dÆ°á»›i vs. Help meğŸ˜,Má»i ngÆ°á»i giáº£i thÃ­ch cho mÃ¬nh mÃ¡y dÃ²ng Ä‘á» á»Ÿ dÆ°á»›i vs. Help me,,,,,
"[AI Share]
Top 50 Machine Learning Interview Questions & Answers (2021)
Má»i ngÆ°á»i lÆ°u láº¡i Ä‘á»ƒ Ã´n nhÃ© <3.
Link pdf: https://drive.google.com/file/d/1-U8JC2KtAD-ryHO8BuaaZ9VRT9qOE6E_/view?usp=sharing
Nguá»“n: https://www.guru99.com/machine-learning-interview-questions.html",[AI Share] Top 50 Machine Learning Interview Questions & Answers (2021) Má»i ngÆ°á»i lÆ°u láº¡i Ä‘á»ƒ Ã´n nhÃ© <3. Link pdf: https://drive.google.com/file/d/1-U8JC2KtAD-ryHO8BuaaZ9VRT9qOE6E_/view?usp=sharing Nguá»“n: https://www.guru99.com/machine-learning-interview-questions.html,,,,,
Link hay cho báº¡n há»c AI vÃ  Robot,Link hay cho báº¡n há»c AI vÃ  Robot,,,,,
"Khi Newbie cÅ©ng táº­p tÃ nh XGBoost. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c má»™t chÃºt cÆ¡ báº£n nháº¥t vá» mÃ³n nÃ y.
Nghá»‰ 2/9 mÃ  láº¡i dÃ­nh Dá»‹ch COVID nÃªn tranh thá»§ gá»­i Ä‘áº¿n anh em video vá» XGBooot. Thuáº­t toÃ¡n tháº§n thÃ¡nh ráº¥t hay dÃ nh chiáº¿n tháº¯ng trong cÃ¡c cuá»™c thi vá» AI, gáº§n Ä‘Ã¢y nháº¥t lÃ  Cuá»™c thi cháº©n Ä‘oÃ¡n tiáº¿ng ho mÃ¹a COVID.
Mong admin duyá»‡t bÃ i!","Khi Newbie cÅ©ng táº­p tÃ nh XGBoost. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c má»™t chÃºt cÆ¡ báº£n nháº¥t vá» mÃ³n nÃ y. Nghá»‰ 2/9 mÃ  láº¡i dÃ­nh Dá»‹ch COVID nÃªn tranh thá»§ gá»­i Ä‘áº¿n anh em video vá» XGBooot. Thuáº­t toÃ¡n tháº§n thÃ¡nh ráº¥t hay dÃ nh chiáº¿n tháº¯ng trong cÃ¡c cuá»™c thi vá» AI, gáº§n Ä‘Ã¢y nháº¥t lÃ  Cuá»™c thi cháº©n Ä‘oÃ¡n tiáº¿ng ho mÃ¹a COVID. Mong admin duyá»‡t bÃ i!",,,,,
"Cáº§n giÃºp Ä‘á»¡ Ä‘á»ƒ lÆ°u láº¡i giá»ng nÃ³i cá»§a Ã´ng em
Ã”ng em giá» yáº¿u láº¯m rá»“i, cháº¯c chá»‰ cÃ²n sá»‘ng Ä‘Æ°á»£c vÃ i nÄƒm ná»¯a thÃ´i lÃ  tá»‘t láº¯m rá»“i. Em khÃ´ng biáº¿t cÃ³ cÃ¡ch nÃ o dÃ¹ng DL Ä‘á»ƒ cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i giá»ng nÃ³i cá»§a Ã´ng em thÃ nh trá»£ lÃ½ áº£o Ä‘Æ°á»£c khÃ´ng nhá»‰ má»i ngÆ°á»i? Háº§u háº¿t cÃ¡c projectem lÃ m Ä‘á»u vá» CV nÃªn em khÃ´ng biáº¿t gÃ¬ vá» NLP vá»›i audio áº¡.
Náº¿u má»i ngÆ°á»i k giÃºp Ä‘Æ°á»£c lÃ m Æ¡n khÃ´ng tháº£ emoji haha áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","Cáº§n giÃºp Ä‘á»¡ Ä‘á»ƒ lÆ°u láº¡i giá»ng nÃ³i cá»§a Ã´ng em Ã”ng em giá» yáº¿u láº¯m rá»“i, cháº¯c chá»‰ cÃ²n sá»‘ng Ä‘Æ°á»£c vÃ i nÄƒm ná»¯a thÃ´i lÃ  tá»‘t láº¯m rá»“i. Em khÃ´ng biáº¿t cÃ³ cÃ¡ch nÃ o dÃ¹ng DL Ä‘á»ƒ cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i giá»ng nÃ³i cá»§a Ã´ng em thÃ nh trá»£ lÃ½ áº£o Ä‘Æ°á»£c khÃ´ng nhá»‰ má»i ngÆ°á»i? Háº§u háº¿t cÃ¡c projectem lÃ m Ä‘á»u vá» CV nÃªn em khÃ´ng biáº¿t gÃ¬ vá» NLP vá»›i audio áº¡. Náº¿u má»i ngÆ°á»i k giÃºp Ä‘Æ°á»£c lÃ m Æ¡n khÃ´ng tháº£ emoji haha áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
"ChÃ o má»i ngÆ°á»i!
Em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n
Dá»± Ä‘oÃ¡n ra má»™t khoáº£ng giÃ¡ trá»‹ tá»« A -> B (vÃ­ dá»¥ 80->130, 99-100...), cÃ¡c khoáº£ng nÃ y cÃ³ biÃªn Ä‘á»™ khÃ´ng cá»‘ Ä‘á»‹nh.
CÃ¡c label sáº½ lÃ  cÃ¡c cá»¥m dá»¯ liá»‡u cÃ³ cÃ¡c kháº£ng báº±ng nhau (vÃ­ dá»¥ nhÆ° 0-100, 101-200, 201-300) CÃ¡c cá»¥m nÃ y cá»‘ Ä‘á»‹nh, Ä‘Ã£ cÃ³ tá»« trÆ°á»›c, (chá»‰ cÃ³ 3 cá»¥m)
VÃ¬ tháº¿ nÃªn má»™t giÃ¡ trá»‹ X sáº½ cÃ³ thá»ƒ nháº­n nhiá»u Y (Theo vÃ­ dá»¥ thÃ¬ máº«u dá»¯ liá»‡u cho ra KQ 80-130 sáº½ náº±m trong 2 khoáº£ng lÃ  0-100 vÃ  101-200)
BÃ¢y giá» cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ tin cáº­y cá»§a model khÃ´ng áº¡. VÃ­ dá»¥ nhÆ° náº±m trÃªn khoáº£ng má»™t lÃ  20, náº±m khoáº£ng 2 lÃ  30 thÃ¬ khoáº£ng 2 sáº½ cÃ³ Ä‘á»™ tin cáº­y cao hÆ¡n.
Em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i! Em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n Dá»± Ä‘oÃ¡n ra má»™t khoáº£ng giÃ¡ trá»‹ tá»« A -> B (vÃ­ dá»¥ 80->130, 99-100...), cÃ¡c khoáº£ng nÃ y cÃ³ biÃªn Ä‘á»™ khÃ´ng cá»‘ Ä‘á»‹nh. CÃ¡c label sáº½ lÃ  cÃ¡c cá»¥m dá»¯ liá»‡u cÃ³ cÃ¡c kháº£ng báº±ng nhau (vÃ­ dá»¥ nhÆ° 0-100, 101-200, 201-300) CÃ¡c cá»¥m nÃ y cá»‘ Ä‘á»‹nh, Ä‘Ã£ cÃ³ tá»« trÆ°á»›c, (chá»‰ cÃ³ 3 cá»¥m) VÃ¬ tháº¿ nÃªn má»™t giÃ¡ trá»‹ X sáº½ cÃ³ thá»ƒ nháº­n nhiá»u Y (Theo vÃ­ dá»¥ thÃ¬ máº«u dá»¯ liá»‡u cho ra KQ 80-130 sáº½ náº±m trong 2 khoáº£ng lÃ  0-100 vÃ  101-200) BÃ¢y giá» cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ tin cáº­y cá»§a model khÃ´ng áº¡. VÃ­ dá»¥ nhÆ° náº±m trÃªn khoáº£ng má»™t lÃ  20, náº±m khoáº£ng 2 lÃ  30 thÃ¬ khoáº£ng 2 sáº½ cÃ³ Ä‘á»™ tin cáº­y cao hÆ¡n. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
FYI!,FYI!,,,,,
"Dear anh chá»‹,
Em má»›i tÃ¬m hiá»ƒu vá». Ml vá»›i phÆ°Æ¡ng phÃ¡p random-forest, decision tree. CÃ³ má»™t sá»‘ thÃ´ng sá»‘ nhÆ° Max_Depth,Max_Features, Min_samples_split, Random_state em ko rÃµ. Nhá» anh chá»‹ giáº£i thÃ­ch giÃºp em vá»›i áº¡. Náº¿u kÃ¨o vÃ­ dá»¥ thÃ¬ tá»‘t áº¡.
Em xin cáº£m Æ¡n","Dear anh chá»‹, Em má»›i tÃ¬m hiá»ƒu vá». Ml vá»›i phÆ°Æ¡ng phÃ¡p random-forest, decision tree. CÃ³ má»™t sá»‘ thÃ´ng sá»‘ nhÆ° Max_Depth,Max_Features, Min_samples_split, Random_state em ko rÃµ. Nhá» anh chá»‹ giáº£i thÃ­ch giÃºp em vá»›i áº¡. Náº¿u kÃ¨o vÃ­ dá»¥ thÃ¬ tá»‘t áº¡. Em xin cáº£m Æ¡n",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em cÃ³ há»c vá» CNN thÃ¬ hiá»ƒu tÃ­ch cháº­p lÃ  trÆ°á»£t má»™t kernel Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn trÃªn áº£nh input Ä‘áº§u vÃ o. NhÆ°ng em Ä‘á»c 1 bÃ i bÃ¡o thÃ¬ há» giáº£i thÃ­ch 1 phÃ©p tÃ­ch cháº­p 2D bao gá»“m 2 bÆ°á»›c nhÆ° hÃ¬nh mÃ  em khÃ´ng hiá»ƒu sampling vá»›i Grid R trong áº£nh lÃ  nhÆ° tháº¿ nÃ o cho Ä‘Ãºng. Ráº¥t mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i",Em chÃ o má»i ngÆ°á»i áº¡ Em cÃ³ há»c vá» CNN thÃ¬ hiá»ƒu tÃ­ch cháº­p lÃ  trÆ°á»£t má»™t kernel Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn trÃªn áº£nh input Ä‘áº§u vÃ o. NhÆ°ng em Ä‘á»c 1 bÃ i bÃ¡o thÃ¬ há» giáº£i thÃ­ch 1 phÃ©p tÃ­ch cháº­p 2D bao gá»“m 2 bÆ°á»›c nhÆ° hÃ¬nh mÃ  em khÃ´ng hiá»ƒu sampling vá»›i Grid R trong áº£nh lÃ  nhÆ° tháº¿ nÃ o cho Ä‘Ãºng. Ráº¥t mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i,,,,,
"Em chÃ o anh/chá»‹.
Hiá»‡n táº¡i em Ä‘ang muá»‘n mÃ´ phá»ng láº¡i káº¿t quáº£ thÃ­ nghiá»‡m cá»§a má»™t paper vá» Federated Learning káº¿t há»£p vá»›i má»™t chÃºt Meta Learning. Tháº§y em cÃ³ yÃªu cáº§u pháº£i Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c cáº¥u hÃ¬nh mÃ¡y dÃ¹ng trong training (RAM, disk, GPU, CPU) mÃ  em thÃ¬ chÆ°a lÃ m viá»‡c nÃ y bao giá» :<. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m vá» lÄ©nh vá»±c nÃ y cÃ³ thá»ƒ cho em lá»i khuyÃªn vá» viá»‡c mÃ¬nh sáº½ estimate nhÆ° tháº¿ nÃ o Ä‘Æ°á»£c khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.
Link paper: https://arxiv.org/abs/1802.07876
HÃ¬nh Ä‘Ã­nh kÃ¨m lÃ  ká»‹ch thÆ°á»›c dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¹ng trong paper.","Em chÃ o anh/chá»‹. Hiá»‡n táº¡i em Ä‘ang muá»‘n mÃ´ phá»ng láº¡i káº¿t quáº£ thÃ­ nghiá»‡m cá»§a má»™t paper vá» Federated Learning káº¿t há»£p vá»›i má»™t chÃºt Meta Learning. Tháº§y em cÃ³ yÃªu cáº§u pháº£i Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c cáº¥u hÃ¬nh mÃ¡y dÃ¹ng trong training (RAM, disk, GPU, CPU) mÃ  em thÃ¬ chÆ°a lÃ m viá»‡c nÃ y bao giá» :<. Má»i ngÆ°á»i cÃ³ kinh nghiá»‡m vá» lÄ©nh vá»±c nÃ y cÃ³ thá»ƒ cho em lá»i khuyÃªn vá» viá»‡c mÃ¬nh sáº½ estimate nhÆ° tháº¿ nÃ o Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡. Link paper: https://arxiv.org/abs/1802.07876 HÃ¬nh Ä‘Ã­nh kÃ¨m lÃ  ká»‹ch thÆ°á»›c dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¹ng trong paper.",,,,,
"Hi, chÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ mong muá»‘n build má»™t model Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng má»™t Ä‘oáº¡n tÃ­n hiá»‡u PPG Ä‘Æ°a vÃ o dá»±a trÃªn data MIMIC (má»—i sample lÃ  má»™t chuá»—i tÃ­n hiá»‡u timeseries gá»“m nhiá»u chu kÃ¬ cÃ³ cáº£ tÃ­n hiá»‡u tá»‘t vÃ  xáº¥u). ThÃ¬ cho mÃ¬nh há»i cÃ³ cÃ¡ch nÃ o theo hÆ°á»›ng unsuperivised learning cho bÃ i toÃ¡n nÃ y khÃ´ng nhá»‰! MÃ¬nh cáº£m Æ¡n nhiá»u áº¡!","Hi, chÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ mong muá»‘n build má»™t model Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng má»™t Ä‘oáº¡n tÃ­n hiá»‡u PPG Ä‘Æ°a vÃ o dá»±a trÃªn data MIMIC (má»—i sample lÃ  má»™t chuá»—i tÃ­n hiá»‡u timeseries gá»“m nhiá»u chu kÃ¬ cÃ³ cáº£ tÃ­n hiá»‡u tá»‘t vÃ  xáº¥u). ThÃ¬ cho mÃ¬nh há»i cÃ³ cÃ¡ch nÃ o theo hÆ°á»›ng unsuperivised learning cho bÃ i toÃ¡n nÃ y khÃ´ng nhá»‰! MÃ¬nh cáº£m Æ¡n nhiá»u áº¡!",,,,,
"#bayesian_neural_network
ChÃ o má»i ngÆ°á»i
Em Ä‘ang tÃ¬m hiá»ƒu vá» Bayesian neural networks, Ä‘Ã¢y lÃ  pháº§n keras implementation (https://keras.io/examples/keras_recipes/bayesian_neural_networks/) nhÆ°ng Ä‘ang tháº¯c máº¯c chá»— prior vÃ  posterior (á»Ÿ má»¥c 2 : Experiment 2: Bayesian neural network (BNN) ) nhÆ° trÃªn hÃ¬nh.
Em khÃ´ng hiá»ƒu 2 tham sá»‘ kernel_size vÃ  bias_size á»Ÿ Ä‘Ã¢y lÃ  gÃ¬ vÃ  tá»« Ä‘Ã¢u ra. Pháº§n gá»i prior vÃ  posterior á»Ÿ hÃ m create_bnn_model em cÅ©ng khÃ´ng hiá»ƒu.
Mong má»i ngÆ°á»i giáº£i thÃ­ch. Em cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i Em Ä‘ang tÃ¬m hiá»ƒu vá» Bayesian neural networks, Ä‘Ã¢y lÃ  pháº§n keras implementation (https://keras.io/examples/keras_recipes/bayesian_neural_networks/) nhÆ°ng Ä‘ang tháº¯c máº¯c chá»— prior vÃ  posterior (á»Ÿ má»¥c 2 : Experiment 2: Bayesian neural network (BNN) ) nhÆ° trÃªn hÃ¬nh. Em khÃ´ng hiá»ƒu 2 tham sá»‘ kernel_size vÃ  bias_size á»Ÿ Ä‘Ã¢y lÃ  gÃ¬ vÃ  tá»« Ä‘Ã¢u ra. Pháº§n gá»i prior vÃ  posterior á»Ÿ hÃ m create_bnn_model em cÅ©ng khÃ´ng hiá»ƒu. Mong má»i ngÆ°á»i giáº£i thÃ­ch. Em cáº£m Æ¡n.",#bayesian_neural_network,,,,
"xin phÃ©p cÃ¡c a/c/e, mÃ¬nh hiá»‡n táº¡i Ä‘ang há»c vá» machine learing vÃ  cÃ³ 1 sá»‘ tháº¯c máº¯c
hiá»‡n táº¡i cÃ¡c cÃ´ng ty cá»§a viá»‡t nam lÃ m vá» AI há» láº¥y datasource dÃ nh cho ngÆ°á»i viá»‡t á»Ÿ Ä‘Ã¢u áº¡ ? vÃ  giÃ¡ cáº£ ra sao áº¡ ?
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c cÃ¡i cÃ¢u há»i hÆ¡i ngu ngá»‘c nÃ y :<","xin phÃ©p cÃ¡c a/c/e, mÃ¬nh hiá»‡n táº¡i Ä‘ang há»c vá» machine learing vÃ  cÃ³ 1 sá»‘ tháº¯c máº¯c hiá»‡n táº¡i cÃ¡c cÃ´ng ty cá»§a viá»‡t nam lÃ m vá» AI há» láº¥y datasource dÃ nh cho ngÆ°á»i viá»‡t á»Ÿ Ä‘Ã¢u áº¡ ? vÃ  giÃ¡ cáº£ ra sao áº¡ ? Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c cÃ¡i cÃ¢u há»i hÆ¡i ngu ngá»‘c nÃ y :<",,,,,
Hiá»‡n mÃ¬nh Ä‘ang lÃ m vá» speech recognition sá»­ dá»¥ng deepspeech Ä‘á»ƒ train. MÃ¬nh Ä‘Ã£ train Ä‘Æ°á»£c nhá»¯ng file máº«u giá» mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch Ä‘á»ƒ Ä‘Æ°a data lÃªn Ä‘á»ƒ train. Cho mÃ¬nh há»i lÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ generate ra cÃ¡c file train.csv dev.csv vÃ  test.csv tá»« data mÃ¬nh thu Ã¢m tá»« file wav Ä‘á»ƒ train váº­y. MÃ¬nh lÃ m trÃªn colab.,Hiá»‡n mÃ¬nh Ä‘ang lÃ m vá» speech recognition sá»­ dá»¥ng deepspeech Ä‘á»ƒ train. MÃ¬nh Ä‘Ã£ train Ä‘Æ°á»£c nhá»¯ng file máº«u giá» mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch Ä‘á»ƒ Ä‘Æ°a data lÃªn Ä‘á»ƒ train. Cho mÃ¬nh há»i lÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ generate ra cÃ¡c file train.csv dev.csv vÃ  test.csv tá»« data mÃ¬nh thu Ã¢m tá»« file wav Ä‘á»ƒ train váº­y. MÃ¬nh lÃ m trÃªn colab.,,,,,
"Em chÃ o má»i ngÆ°á»i em lÃ  newbie áº¡, em Ä‘ang duÌ€ng detecto Ä‘ÃªÌ‰ laÌ€m thÆ°Ì‰ baÌ€i toaÌ€n obj detect. khi em trainning xong chaÌ£y test luÃ´n thiÌ€ khÃ´ng baÌo lÃ´Ìƒi giÌ€ caÌ‰ nhÆ°Ìƒng khi load model Ä‘aÌƒ lÆ°u lÃªn Ä‘ÃªÌ‰ chaÌ£y thiÌ€ laÌ£i lÃ´Ìƒi nhÆ° hiÌ€nh dÆ°Æ¡Ìi ai biÃªÌt chiÌ‰ em vÆ¡Ìi","Em chÃ o má»i ngÆ°á»i em lÃ  newbie áº¡, em Ä‘ang duÌ€ng detecto Ä‘ÃªÌ‰ laÌ€m thÆ°Ì‰ baÌ€i toaÌ€n obj detect. khi em trainning xong chaÌ£y test luÃ´n thiÌ€ khÃ´ng baÌo lÃ´Ìƒi giÌ€ caÌ‰ nhÆ°Ìƒng khi load model Ä‘aÌƒ lÆ°u lÃªn Ä‘ÃªÌ‰ chaÌ£y thiÌ€ laÌ£i lÃ´Ìƒi nhÆ° hiÌ€nh dÆ°Æ¡Ìi ai biÃªÌt chiÌ‰ em vÆ¡Ìi",,,,,
"[AI há»c Boxing]
Trong nhá»¯ng trÃ² chÆ¡i Ä‘á»‘i khÃ¡ng 1 vs 1 nhÆ° boxing thÃ¬ cÃ¡c váº­n Ä‘á»™ng viÃªn cáº§n di chuyá»ƒn linh hoáº¡t vÃ  cÃ³ cÃ¡c chiáº¿n thuáº­t khÃ¡c nhau trong tráº­n Ä‘áº¥u. Trong nghiÃªn cá»©u nÃ y, tÃ¡c giáº£ sá»­ dá»¥ng Reinforcement Learning Ä‘á»ƒ giáº£ láº­p tráº­n Ä‘áº¥u cá»§a 2 váº­n Ä‘á»™ng viÃªn báº±ng cÃ¡ch cho mÃ¡y há»c cÃ¡c kÄ© nÄƒng cÆ¡ báº£n, sau Ä‘Ã³ cÃ¡c chiáº¿n thuáº­t nÃ¢ng cao.","[AI há»c Boxing] Trong nhá»¯ng trÃ² chÆ¡i Ä‘á»‘i khÃ¡ng 1 vs 1 nhÆ° boxing thÃ¬ cÃ¡c váº­n Ä‘á»™ng viÃªn cáº§n di chuyá»ƒn linh hoáº¡t vÃ  cÃ³ cÃ¡c chiáº¿n thuáº­t khÃ¡c nhau trong tráº­n Ä‘áº¥u. Trong nghiÃªn cá»©u nÃ y, tÃ¡c giáº£ sá»­ dá»¥ng Reinforcement Learning Ä‘á»ƒ giáº£ láº­p tráº­n Ä‘áº¥u cá»§a 2 váº­n Ä‘á»™ng viÃªn báº±ng cÃ¡ch cho mÃ¡y há»c cÃ¡c kÄ© nÄƒng cÆ¡ báº£n, sau Ä‘Ã³ cÃ¡c chiáº¿n thuáº­t nÃ¢ng cao.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 7/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 7/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Bert vÃ  PhoBert, khÃ´ng biáº¿t cÃ³ ai Ä‘Ã£ run code vá» PhoBert trÃªn Windows rá»“i cÃ³ thá»ƒ share cho mÃ¬nh tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡.
Thanks má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Bert vÃ  PhoBert, khÃ´ng biáº¿t cÃ³ ai Ä‘Ã£ run code vá» PhoBert trÃªn Windows rá»“i cÃ³ thá»ƒ share cho mÃ¬nh tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Thanks má»i ngÆ°á»i.",,,,,
"Hi má»i ngÆ°á»i,
Em cÃ³ 1 bá»™ data tÃªn ngÆ°á»i ( tÃªn tháº­t theo chá»©ng minh thÆ°),
Em muá»‘n lÃ m 1 model chá»‰ dá»±a trÃªn bá»™ dá»¯ liá»‡u trÃªn Ä‘á»ƒ phÃ¢n loáº¡i 1 táº­p má»›i nhÆ° sau:
VÃ­ dá»¥: cÃ³ 1 tÃªn má»›i model sáº½ phÃ¢n loáº¡i nÃ³ lÃ  tÃªn tháº­t hoáº·c tÃªn fake.
Em cÃ³ tÃ¬m hiá»ƒu Ä‘Ã¢y lÃ  model kiá»ƒu one class classification, bÃ i toÃ¡n cá»§a em lÃ  dÃ¹ng dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  text vÃ  chá»‰ cÃ³ label cho 1 class( tÃªn tháº­t)? KhÃ´ng biáº¿t cÃ³ Ä‘Ãºng k? NgoÃ i ra e cÃ³ tháº¥y máº¥y phÆ°Æ¡ng phÃ¡p nhÆ° GAN hay autoencoder thÃ¬ cÃ³ Ã¡p dá»¥ng gÃ¬ Ä‘Æ°á»£c trÆ°á»ng há»£p nÃ y khÃ´ng?
KhÃ´ng biáº¿t lÃ  bÃ i toÃ¡n nÃ y cÃ³ kháº£ thi khÃ´ng, vÃ  Ä‘Ã£ cÃ³ anh nÃ o tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» tÆ°Æ¡ng tá»± chÆ°a cho e 1 sá»‘ nguá»“n tham kháº£o vá»›i áº¡.
Ps: ( em cÃ³ thá»ƒ thÃªm 1 sá»‘ biáº¿n khÃ¡c nhÆ° dÃ¢n tá»™c gÃ¬, quÃª quÃ¡n )
CÃ¡m Æ¡n admin accept post.","Hi má»i ngÆ°á»i, Em cÃ³ 1 bá»™ data tÃªn ngÆ°á»i ( tÃªn tháº­t theo chá»©ng minh thÆ°), Em muá»‘n lÃ m 1 model chá»‰ dá»±a trÃªn bá»™ dá»¯ liá»‡u trÃªn Ä‘á»ƒ phÃ¢n loáº¡i 1 táº­p má»›i nhÆ° sau: VÃ­ dá»¥: cÃ³ 1 tÃªn má»›i model sáº½ phÃ¢n loáº¡i nÃ³ lÃ  tÃªn tháº­t hoáº·c tÃªn fake. Em cÃ³ tÃ¬m hiá»ƒu Ä‘Ã¢y lÃ  model kiá»ƒu one class classification, bÃ i toÃ¡n cá»§a em lÃ  dÃ¹ng dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  text vÃ  chá»‰ cÃ³ label cho 1 class( tÃªn tháº­t)? KhÃ´ng biáº¿t cÃ³ Ä‘Ãºng k? NgoÃ i ra e cÃ³ tháº¥y máº¥y phÆ°Æ¡ng phÃ¡p nhÆ° GAN hay autoencoder thÃ¬ cÃ³ Ã¡p dá»¥ng gÃ¬ Ä‘Æ°á»£c trÆ°á»ng há»£p nÃ y khÃ´ng? KhÃ´ng biáº¿t lÃ  bÃ i toÃ¡n nÃ y cÃ³ kháº£ thi khÃ´ng, vÃ  Ä‘Ã£ cÃ³ anh nÃ o tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» tÆ°Æ¡ng tá»± chÆ°a cho e 1 sá»‘ nguá»“n tham kháº£o vá»›i áº¡. Ps: ( em cÃ³ thá»ƒ thÃªm 1 sá»‘ biáº¿n khÃ¡c nhÆ° dÃ¢n tá»™c gÃ¬, quÃª quÃ¡n ) CÃ¡m Æ¡n admin accept post.",,,,,
"ChÃ o má»i ngÆ°á»i,
Minh cÃ³ viáº¿t má»™t bÃ i blog hÆ°á»›ng dáº«n vá» cÃ¡ch xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»c mÃ¡y sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ nhÆ° Label Studio, Cometml, DVC, Kubeflow, KFServing, Docker, Kubernetes, Pytorch, AWS,â€¦ theo hÆ°á»›ng thá»±c hÃ nh step-by-step. Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ viáº¿t Ä‘Æ°á»£c 6 bÃ i, cÃ¡c bÃ i tiáº¿p theo sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau.
Hi vá»ng sáº½ giÃºp nhá»¯ng báº¡n nÃ o Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»c mÃ¡y má»™t chÃºt nÃ o Ä‘Ã³.
Blog: https://thanhhau097.github.io/mlpipeline/
Github repo: https://github.com/thanhhau097/mlpipeline
Äá»«ng quÃªn nháº¥n Star cho GitHub repo náº¿u cáº£m tháº¥y cÃ³ Ã­ch nhÃ© ! :D","ChÃ o má»i ngÆ°á»i, Minh cÃ³ viáº¿t má»™t bÃ i blog hÆ°á»›ng dáº«n vá» cÃ¡ch xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»c mÃ¡y sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ nhÆ° Label Studio, Cometml, DVC, Kubeflow, KFServing, Docker, Kubernetes, Pytorch, AWS,â€¦ theo hÆ°á»›ng thá»±c hÃ nh step-by-step. Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ viáº¿t Ä‘Æ°á»£c 6 bÃ i, cÃ¡c bÃ i tiáº¿p theo sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau. Hi vá»ng sáº½ giÃºp nhá»¯ng báº¡n nÃ o Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»c mÃ¡y má»™t chÃºt nÃ o Ä‘Ã³. Blog: https://thanhhau097.github.io/mlpipeline/ Github repo: https://github.com/thanhhau097/mlpipeline Äá»«ng quÃªn nháº¥n Star cho GitHub repo náº¿u cáº£m tháº¥y cÃ³ Ã­ch nhÃ© ! :D",,,,,
"Em chÃ o cÃ¡c anh/chá»‹/ báº¡n trong group áº¡.
Em cÃ³ má»™t chÃºt cÃ¢u há»i vá» chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o kÄ© sÆ° AI cá»§a Vingroup, do chÆ°Æ¡ng trÃ¬nh nÃ y khÃ¡ má»›i (theo em biáº¿t thÃ¬ má»›i tá»• chá»©c nÄƒm 2020 nÃªn má»›i cÃ³ 1 hoáº·c 2 Ä‘á»£t cÃ¡c há»c viÃªn).
Em cÃ³ Ä‘Æ°á»£c thÆ° giá»›i thiá»‡u cá»§a má»™t researcher trong Vin nÃªn muá»‘n tÃ¬m hiá»ƒu vÃ¬ tháº¥y chÆ°Æ¡ng trÃ¬nh khÃ¡ háº¥p dáº«n Ä‘á»ƒ tráº£i nghiá»‡m vÃ  há»c há»i, khÃ´ng biáº¿t cÃ³ anh/chá»‹/báº¡n nÃ o trong group Ä‘Ã£ tá»«ng tráº£i nghiá»‡m cÃ³ thá»ƒ comment cho em há»i má»™t sá»‘ váº¥n Ä‘á» Ä‘Æ°á»£c khÃ´ng áº¡? (CÃ¡c vÃ²ng tuyá»ƒn chá»n, nghÄ©a vá»¥ sau khi Ä‘Æ°á»£c Ä‘Ã o táº¡o, chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o,â€¦)
Em cÃ¡m Æ¡n áº¡.","Em chÃ o cÃ¡c anh/chá»‹/ báº¡n trong group áº¡. Em cÃ³ má»™t chÃºt cÃ¢u há»i vá» chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o kÄ© sÆ° AI cá»§a Vingroup, do chÆ°Æ¡ng trÃ¬nh nÃ y khÃ¡ má»›i (theo em biáº¿t thÃ¬ má»›i tá»• chá»©c nÄƒm 2020 nÃªn má»›i cÃ³ 1 hoáº·c 2 Ä‘á»£t cÃ¡c há»c viÃªn). Em cÃ³ Ä‘Æ°á»£c thÆ° giá»›i thiá»‡u cá»§a má»™t researcher trong Vin nÃªn muá»‘n tÃ¬m hiá»ƒu vÃ¬ tháº¥y chÆ°Æ¡ng trÃ¬nh khÃ¡ háº¥p dáº«n Ä‘á»ƒ tráº£i nghiá»‡m vÃ  há»c há»i, khÃ´ng biáº¿t cÃ³ anh/chá»‹/báº¡n nÃ o trong group Ä‘Ã£ tá»«ng tráº£i nghiá»‡m cÃ³ thá»ƒ comment cho em há»i má»™t sá»‘ váº¥n Ä‘á» Ä‘Æ°á»£c khÃ´ng áº¡? (CÃ¡c vÃ²ng tuyá»ƒn chá»n, nghÄ©a vá»¥ sau khi Ä‘Æ°á»£c Ä‘Ã o táº¡o, chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o,â€¦) Em cÃ¡m Æ¡n áº¡.",,,,,
Em chÃ o má»i ngÆ°á»i em lÃ  newbie áº¡. Hiá»‡n nay em Ä‘ang há»c vá» Linear Regression trong Ä‘Ã³ cÃ³ pháº§n train dá»¯ liá»‡u báº±ng Gradient Descent. Do data lÃ m bÃ i Lab quÃ¡ lá»›n dáº«n Ä‘áº¿n tÃ¬m cÃ¡c trá»ng sá»‘ khÃ¡ lÃ¢u. LÃ m trÃªn Colab 5 Ä‘áº¿n 6h thÃ¬ bá»‹ disconnect. Má»i ngÆ°á»i cÃ²n biáº¿t phÆ°Æ¡ng phÃ¡p nÃ o cháº¡y online nhÆ° Google Colab mÃ  treo Ä‘Æ°á»£c lÃ¢u khÃ´ng áº¡. Xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡,Em chÃ o má»i ngÆ°á»i em lÃ  newbie áº¡. Hiá»‡n nay em Ä‘ang há»c vá» Linear Regression trong Ä‘Ã³ cÃ³ pháº§n train dá»¯ liá»‡u báº±ng Gradient Descent. Do data lÃ m bÃ i Lab quÃ¡ lá»›n dáº«n Ä‘áº¿n tÃ¬m cÃ¡c trá»ng sá»‘ khÃ¡ lÃ¢u. LÃ m trÃªn Colab 5 Ä‘áº¿n 6h thÃ¬ bá»‹ disconnect. Má»i ngÆ°á»i cÃ²n biáº¿t phÆ°Æ¡ng phÃ¡p nÃ o cháº¡y online nhÆ° Google Colab mÃ  treo Ä‘Æ°á»£c lÃ¢u khÃ´ng áº¡. Xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡,,,,,
"Má»i ngÆ°á»i cho em há»i lÃ  em má»›i báº¯t Ä‘áº§u vá»›i ML, em Ä‘ang thá»­ train má»™t model giá»‘ng MNIST cÃ³ 15k examples, tá»‰ lá»‡ train:val:test lÃ  60:30:10 (Chinese MNIST - https://www.kaggle.com/fedesoriano/chinese-mnist-digit-recognizer).
Em Ä‘ang gáº·p váº¥n Ä‘á» lÃ  em Ä‘Ã£ thá»­ (mÃ²) nhiá»u model khÃ¡c nhau, tá»« cÃ³ Ã­t layer Ä‘áº¿n nhiá»u layer, tá»« Ã­t node (20) Ä‘áº¿n nhiá»u node (500), vÃ  em cÅ©ng Ä‘Ã£ thá»­ dÃ¹ng regularization nhÆ°ng Ä‘á»u gáº·p tÃ¬nh tráº¡ng lÃ  cuá»‘i cÃ¹ng training loss ráº¥t tháº¥p, nhÆ°ng validation loss láº¡i bá»‹ tiá»‡m cáº­n á»Ÿ má»™t má»©c nÃ o Ä‘Ã³ (cÃ³ trÆ°á»ng há»£p cÃ²n tÄƒng láº¡i). Dá»¯ liá»‡u cá»§a em Ä‘Ã£ Ä‘Æ°á»£c scale vá» [0, 1].
Cho em há»i Ä‘Ã¢y cÃ³ pháº£i lÃ  overfitting khÃ´ng, vÃ  mÃ¬nh nÃªn xá»­ lÃ½ nhÆ° tháº¿ nÃ o áº¡? (trá»« sá»­ dá»¥ng cÃ¡c network phá»©c táº¡p hÆ¡n nhÆ° CNN vÃ¬ em chÆ°a há»c Ä‘áº¿n).
Vá»›i cÃ¡c thÃ´ng sá»‘ trong hÃ¬nh dÆ°á»›i Ä‘Ã¢y thÃ¬ cuá»‘i cÃ¹ng accuracy cá»§a (train, validate, test) = (0.99, 0.76, 0.758).","Má»i ngÆ°á»i cho em há»i lÃ  em má»›i báº¯t Ä‘áº§u vá»›i ML, em Ä‘ang thá»­ train má»™t model giá»‘ng MNIST cÃ³ 15k examples, tá»‰ lá»‡ train:val:test lÃ  60:30:10 (Chinese MNIST - https://www.kaggle.com/fedesoriano/chinese-mnist-digit-recognizer). Em Ä‘ang gáº·p váº¥n Ä‘á» lÃ  em Ä‘Ã£ thá»­ (mÃ²) nhiá»u model khÃ¡c nhau, tá»« cÃ³ Ã­t layer Ä‘áº¿n nhiá»u layer, tá»« Ã­t node (20) Ä‘áº¿n nhiá»u node (500), vÃ  em cÅ©ng Ä‘Ã£ thá»­ dÃ¹ng regularization nhÆ°ng Ä‘á»u gáº·p tÃ¬nh tráº¡ng lÃ  cuá»‘i cÃ¹ng training loss ráº¥t tháº¥p, nhÆ°ng validation loss láº¡i bá»‹ tiá»‡m cáº­n á»Ÿ má»™t má»©c nÃ o Ä‘Ã³ (cÃ³ trÆ°á»ng há»£p cÃ²n tÄƒng láº¡i). Dá»¯ liá»‡u cá»§a em Ä‘Ã£ Ä‘Æ°á»£c scale vá» [0, 1]. Cho em há»i Ä‘Ã¢y cÃ³ pháº£i lÃ  overfitting khÃ´ng, vÃ  mÃ¬nh nÃªn xá»­ lÃ½ nhÆ° tháº¿ nÃ o áº¡? (trá»« sá»­ dá»¥ng cÃ¡c network phá»©c táº¡p hÆ¡n nhÆ° CNN vÃ¬ em chÆ°a há»c Ä‘áº¿n). Vá»›i cÃ¡c thÃ´ng sá»‘ trong hÃ¬nh dÆ°á»›i Ä‘Ã¢y thÃ¬ cuá»‘i cÃ¹ng accuracy cá»§a (train, validate, test) = (0.99, 0.76, 0.758).",,,,,
https://www.facebook.com/1602089060038379/posts/3037091456538125/,https://www.facebook.com/1602089060038379/posts/3037091456538125/,,,,,
"Há»£p tÃ¡c lÃ m nháº­n diá»‡n khuÃ´n máº·t Ä‘eo kháº©u trang.
Hiá»‡n táº¡i bÃªn mÃ¬nh Ä‘ang cÃ³ nhu cáº§u giáº£i quyáº¿t bÃ i toÃ¡n face recognition nhÆ°ng Ä‘eo kháº©u trang.
áº¢nh chá»¥p máº·t chÃ­nh diá»‡n, Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng trong phÃ²ng.
Cáº£ nhÃ  ai cÃ³ kinh nghiá»‡m trong máº£ng nÃ y muá»‘n há»£p tÃ¡c khÃ´ng áº¡.","Há»£p tÃ¡c lÃ m nháº­n diá»‡n khuÃ´n máº·t Ä‘eo kháº©u trang. Hiá»‡n táº¡i bÃªn mÃ¬nh Ä‘ang cÃ³ nhu cáº§u giáº£i quyáº¿t bÃ i toÃ¡n face recognition nhÆ°ng Ä‘eo kháº©u trang. áº¢nh chá»¥p máº·t chÃ­nh diá»‡n, Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng trong phÃ²ng. Cáº£ nhÃ  ai cÃ³ kinh nghiá»‡m trong máº£ng nÃ y muá»‘n há»£p tÃ¡c khÃ´ng áº¡.",,,,,
"Cuá»‘n ""Thá»±c hÃ nh Há»c mÃ¡y vá»›i Scikit-learn, Keras & TensorFlow"" máº·c dÃ¹ khÃ´ng miá»…n phÃ­, nhá»¯ng bÃ i táº­p á»Ÿ dáº¡ng notebook hoÃ n toÃ n má»Ÿ cho cá»™ng Ä‘á»“ng. CÃ¡c báº¡n quan tÃ¢m cÃ³ thá»ƒ tham kháº£o táº¡i
https://github.com/mlbvn/handson-ml2-vn
NhÃ³m cÅ©ng Ä‘Ã£ dá»‹ch cÃ¡c notebok nÃ y ra tiáº¿ng Viá»‡t. ""Star"" github repo náº¿u báº¡n tháº¥y há»¯u Ã­ch.
===
Nhá»¯ng notebook nÃ y hoÃ n toÃ n cÃ³ thá»ƒ cháº¡y Ä‘Æ°á»£c trÃªn mÃ´i trÆ°á»ng Google colab hoáº·c Kaggle kernel, cÃ¡c báº¡n cÃ³ thá»ƒ cháº¡y trá»±c tiáº¿p trÃªn trÃ¬nh duyá»‡t mÃ  khÃ´ng cáº§n táº£i vá» hay cÃ i Ä‘áº·t thÆ° viá»‡n liÃªn quan.","Cuá»‘n ""Thá»±c hÃ nh Há»c mÃ¡y vá»›i Scikit-learn, Keras & TensorFlow"" máº·c dÃ¹ khÃ´ng miá»…n phÃ­, nhá»¯ng bÃ i táº­p á»Ÿ dáº¡ng notebook hoÃ n toÃ n má»Ÿ cho cá»™ng Ä‘á»“ng. CÃ¡c báº¡n quan tÃ¢m cÃ³ thá»ƒ tham kháº£o táº¡i https://github.com/mlbvn/handson-ml2-vn NhÃ³m cÅ©ng Ä‘Ã£ dá»‹ch cÃ¡c notebok nÃ y ra tiáº¿ng Viá»‡t. ""Star"" github repo náº¿u báº¡n tháº¥y há»¯u Ã­ch. === Nhá»¯ng notebook nÃ y hoÃ n toÃ n cÃ³ thá»ƒ cháº¡y Ä‘Æ°á»£c trÃªn mÃ´i trÆ°á»ng Google colab hoáº·c Kaggle kernel, cÃ¡c báº¡n cÃ³ thá»ƒ cháº¡y trá»±c tiáº¿p trÃªn trÃ¬nh duyá»‡t mÃ  khÃ´ng cáº§n táº£i vá» hay cÃ i Ä‘áº·t thÆ° viá»‡n liÃªn quan.",,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i vá» logic python khi mÃ  loop sao cho khÃ´ng bá»‹ Index error vá»›i
Táº¡i sao trong 2 loop nÃ y nÃ³ bá»‹ out of index Ä‘Æ°á»£c nhá»‰ khi mÃ  Ä‘áº¿n element cuá»‘i cÃ¹ng cá»§a loop
Náº¿u index báº¯t Ä‘áº§u = 0 , thÃ¬ maximum value cá»§a index nÃ³ chá»‰ lÃ  giÃ¡ trá»‹ cá»§a ctr_x * ctr_y thÃ´i chá»©","Má»i ngÆ°á»i Æ¡i cho em há»i vá» logic python khi mÃ  loop sao cho khÃ´ng bá»‹ Index error vá»›i Táº¡i sao trong 2 loop nÃ y nÃ³ bá»‹ out of index Ä‘Æ°á»£c nhá»‰ khi mÃ  Ä‘áº¿n element cuá»‘i cÃ¹ng cá»§a loop Náº¿u index báº¯t Ä‘áº§u = 0 , thÃ¬ maximum value cá»§a index nÃ³ chá»‰ lÃ  giÃ¡ trá»‹ cá»§a ctr_x * ctr_y thÃ´i chá»©",,,,,
"JUPYTER-NOTEBOOK
ChÃ o cÃ¡c bÃ¡c áº¡,
Hiá»‡n táº¡i thÃ¬ em cÃ³ gáº·p trÆ°á»ng há»£p tháº¿ nÃ y, UI notebook cá»§a em ráº¥t khÃ¡c so vá»›i thÃ´ng thÆ°á»ng. CÃ³ bÃ¡c nÃ o Ä‘Ã£ tá»«ng gáº·p UI nÃ o nhÆ° nÃ y chÆ°a áº¡? Em hiá»‡n tá»‹a Ä‘ang dÃ¹ng Ubuntu 20.04, vÃ  Jupyter-notebook nÃ y lÃ  máº·c Ä‘á»‹nh trong mÃ¡y cá»§a em, em chÆ°a cÃ i nhÆ°ng váº«n cÃ³. BÃ¢y giá» em Ä‘ang tÃ­nh xÃ³a Ä‘á»ƒ cÃ i láº¡i xem sao chá»© UI nhÆ° nÃ y thiáº¿u ráº¥t nhiá»u tÃ­nh nÄƒng áº¡.
Em cáº£m Æ¡n cÃ¡c bÃ¡c","JUPYTER-NOTEBOOK ChÃ o cÃ¡c bÃ¡c áº¡, Hiá»‡n táº¡i thÃ¬ em cÃ³ gáº·p trÆ°á»ng há»£p tháº¿ nÃ y, UI notebook cá»§a em ráº¥t khÃ¡c so vá»›i thÃ´ng thÆ°á»ng. CÃ³ bÃ¡c nÃ o Ä‘Ã£ tá»«ng gáº·p UI nÃ o nhÆ° nÃ y chÆ°a áº¡? Em hiá»‡n tá»‹a Ä‘ang dÃ¹ng Ubuntu 20.04, vÃ  Jupyter-notebook nÃ y lÃ  máº·c Ä‘á»‹nh trong mÃ¡y cá»§a em, em chÆ°a cÃ i nhÆ°ng váº«n cÃ³. BÃ¢y giá» em Ä‘ang tÃ­nh xÃ³a Ä‘á»ƒ cÃ i láº¡i xem sao chá»© UI nhÆ° nÃ y thiáº¿u ráº¥t nhiá»u tÃ­nh nÄƒng áº¡. Em cáº£m Æ¡n cÃ¡c bÃ¡c",,,,,
"ChÃ o mn, cho mÃ¬nh há»i trong python cÃ³ sáºµn thÆ° viá»‡n giáº£i quyáº¿t Singular Value Thresholding (SVT) ko áº¡?","ChÃ o mn, cho mÃ¬nh há»i trong python cÃ³ sáºµn thÆ° viá»‡n giáº£i quyáº¿t Singular Value Thresholding (SVT) ko áº¡?",,,,,
"ChÃ o cÃ¡c anh em, khÃ´ng biáº¿t cÃ³ anh em nÃ o cÃ³ bá»™ dataset vá» áº£nh selfie khÃ´ng áº¡? Hay Ä‘Ã£ tá»«ng crawl data image tá»« facebook, instagram,... cÃ³ thá»ƒ hÆ°á»›ng dáº«n cho em hoáº·c share em bá»™ cÃ¡c anh tá»«ng crawl trÃªn cÃ¡c ná»n tÃ ng Ä‘Æ°á»£c khÃ´ng áº¡?","ChÃ o cÃ¡c anh em, khÃ´ng biáº¿t cÃ³ anh em nÃ o cÃ³ bá»™ dataset vá» áº£nh selfie khÃ´ng áº¡? Hay Ä‘Ã£ tá»«ng crawl data image tá»« facebook, instagram,... cÃ³ thá»ƒ hÆ°á»›ng dáº«n cho em hoáº·c share em bá»™ cÃ¡c anh tá»«ng crawl trÃªn cÃ¡c ná»n tÃ ng Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"ğ‹ğ¢ğ¯ğğ¬ğ­ğ«ğğšğ¦ ğ’ğ®Ì›Ì£ ğ¤ğ¢ğÌ£Ì‚ğ§ ğğ ğšÌ€ğ² ğ¡ğ¨Ì£Ì‚ğ¢ ğ‚ğ¨Ì‚ğ§ğ  ğ§ğ ğ¡ğÌ£Ì‚ ğ€ğˆ ğ­ğ«ğ¨ğ§ğ  ğ¤ğ¡ğ®ğ¨Ì‚ğ§ ğ¤ğ¡ğ¨Ì‚Ì‰ ğˆğ‰ğ‚ğ€ğˆ ğŸğŸğŸğŸ â€“ há»™i nghá»‹ quá»‘c táº¿ lá»›n nháº¥t tháº¿ giá»›i vá» trÃ­ tuá»‡ nhÃ¢n táº¡o cÃ³ lá»‹ch sá»­ Ä‘Ã£ 52 nÄƒm (tá»« 1969) diá»…n ra hÃ´m nay, 25/08/2021.
CÃ¹ng láº¯ng nghe nhá»¯ng thÃ´ng tin vÃ  kiáº¿n thá»©c cáº­p nháº­t nháº¥t vá» á»©ng dá»¥ng thá»±c tiá»…n vÃ  cÃ¡c tÃ¡c Ä‘á»™ng xÃ£ há»™i cá»§a AI tá»« cÃ¡c doanh nhÃ¢n vÃ  nhÃ  khoa há»c Ä‘áº¿n tá»« nhá»¯ng táº­p Ä‘oÃ n cÃ´ng nghá»‡ hÃ ng Ä‘áº§u tháº¿ giá»›i nhÆ° IBM, Sony, Fujitsu, Baidu, Sea, JD,â€¦
VÃ  chá»©ng kiáº¿n trÃ­ tuá»‡ Viá»‡t Ä‘Æ°á»£c tÃ´n vinh táº¡i NgÃ y há»™i vá»›i lá»… trao giáº£i ACM SIGAI Industry Award 2021 cho sáº£n pháº©m DrAidTM cho Cháº©n Ä‘oÃ¡n hÃ¬nh áº£nh cá»§a CÃ´ng ty VinBrain (thuá»™c Táº­p Ä‘oÃ n Vingroup) â€“ giáº£i thÆ°á»Ÿng danh giÃ¡ trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Æ°á»£c trao hÃ ng nÄƒm cho duy nháº¥t má»™t sáº£n pháº©m á»©ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o xuáº¥t sáº¯c nháº¥t â™¥ï¸","Ì›Ì£ Ì£Ì‚ Ì€ Ì£Ì‚ Ì‚ Ì£Ì‚ Ì‚ Ì‚Ì‰ â€“ há»™i nghá»‹ quá»‘c táº¿ lá»›n nháº¥t tháº¿ giá»›i vá» trÃ­ tuá»‡ nhÃ¢n táº¡o cÃ³ lá»‹ch sá»­ Ä‘Ã£ 52 nÄƒm (tá»« 1969) diá»…n ra hÃ´m nay, 25/08/2021. CÃ¹ng láº¯ng nghe nhá»¯ng thÃ´ng tin vÃ  kiáº¿n thá»©c cáº­p nháº­t nháº¥t vá» á»©ng dá»¥ng thá»±c tiá»…n vÃ  cÃ¡c tÃ¡c Ä‘á»™ng xÃ£ há»™i cá»§a AI tá»« cÃ¡c doanh nhÃ¢n vÃ  nhÃ  khoa há»c Ä‘áº¿n tá»« nhá»¯ng táº­p Ä‘oÃ n cÃ´ng nghá»‡ hÃ ng Ä‘áº§u tháº¿ giá»›i nhÆ° IBM, Sony, Fujitsu, Baidu, Sea, JD,â€¦ VÃ  chá»©ng kiáº¿n trÃ­ tuá»‡ Viá»‡t Ä‘Æ°á»£c tÃ´n vinh táº¡i NgÃ y há»™i vá»›i lá»… trao giáº£i ACM SIGAI Industry Award 2021 cho sáº£n pháº©m DrAidTM cho Cháº©n Ä‘oÃ¡n hÃ¬nh áº£nh cá»§a CÃ´ng ty VinBrain (thuá»™c Táº­p Ä‘oÃ n Vingroup) â€“ giáº£i thÆ°á»Ÿng danh giÃ¡ trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Æ°á»£c trao hÃ ng nÄƒm cho duy nháº¥t má»™t sáº£n pháº©m á»©ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o xuáº¥t sáº¯c nháº¥t",,,,,
"xin phÃ©p Admin
MÃ¬nh xin chia sáº» tá»›i má»i ngÆ°á»i dá»± Ã¡n ""MÃY Láº¤Y MáºªU COVID"" do ASMTechG nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn, hi vá»ng má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng hay hÃ£y thá»±c hiá»‡n vÃ¬ cá»™ng Ä‘á»“ng áº¡!
https://fb.watch/7B_daTgFgT/","xin phÃ©p Admin MÃ¬nh xin chia sáº» tá»›i má»i ngÆ°á»i dá»± Ã¡n ""MÃY Láº¤Y MáºªU COVID"" do ASMTechG nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn, hi vá»ng má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng hay hÃ£y thá»±c hiá»‡n vÃ¬ cá»™ng Ä‘á»“ng áº¡! https://fb.watch/7B_daTgFgT/",,,,,
"Xin chÃ o má»i ngÆ°á»i.
Em vá»«a cÃ³ Ã½ tÆ°á»Ÿng cho má»™t Ä‘á» tÃ i tá»‘t nghiá»‡p táº¡i trÆ°á»ng.
Äá» tÃ i: xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»— trá»£ há»c táº­p, giÃºp há»c sinh á»Ÿ trÆ°á»ng trung há»c phá»• thÃ´ng lÃ m bÃ i táº­p.
Má»™t chatbox cÃ³ tÃ­ch há»£p AI Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ gá»£i Ã½ cÃ¢u tráº£ lá»i cho há»c sinh náº¿u há»c sinh khÃ´ng biáº¿t hoáº·c tráº£ lá»i sai.
Em hy vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t sá»‘ trang web vá»›i cÃ¡c tÃ­nh nÄƒng nhÆ° trÃªn Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm. CÅ©ng nhÆ° cÃ¡c bÃ i bÃ¡o hoáº·c ká»¹ thuáº­t Ä‘á»ƒ hiá»‡n thá»±c topic.
Ráº¥t cáº£m Æ¡n má»i ngÆ°á»i.
ChÃºc má»i ngÆ°á»i nhiá»u sá»©c khá»e.","Xin chÃ o má»i ngÆ°á»i. Em vá»«a cÃ³ Ã½ tÆ°á»Ÿng cho má»™t Ä‘á» tÃ i tá»‘t nghiá»‡p táº¡i trÆ°á»ng. Äá» tÃ i: xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»— trá»£ há»c táº­p, giÃºp há»c sinh á»Ÿ trÆ°á»ng trung há»c phá»• thÃ´ng lÃ m bÃ i táº­p. Má»™t chatbox cÃ³ tÃ­ch há»£p AI Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ gá»£i Ã½ cÃ¢u tráº£ lá»i cho há»c sinh náº¿u há»c sinh khÃ´ng biáº¿t hoáº·c tráº£ lá»i sai. Em hy vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t sá»‘ trang web vá»›i cÃ¡c tÃ­nh nÄƒng nhÆ° trÃªn Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm. CÅ©ng nhÆ° cÃ¡c bÃ i bÃ¡o hoáº·c ká»¹ thuáº­t Ä‘á»ƒ hiá»‡n thá»±c topic. Ráº¥t cáº£m Æ¡n má»i ngÆ°á»i. ChÃºc má»i ngÆ°á»i nhiá»u sá»©c khá»e.",,,,,
"Em chÃ o anh, chá»‹ vÃ  cÃ¡c báº¡n. Em Ä‘ang gáº·p 1 bÃ i toÃ¡n muá»‘n nhá» anh chá»‹ ai cÃ³ kinh nghiá»‡m thÃ¬ chia sáº» giÃºp em phÆ°Æ¡ng Ã¡n:

Hiá»‡n táº¡i em Ä‘ang cÃ³ 1 file weight náº·ng 256mb (em train dÃ¹ng yolov4), em muá»‘n deploy lÃªn device Ä‘á»ƒ cháº¡y realtime. MÃ  file nÃ y náº·ng quÃ¡ nÃªn e muá»‘n há»i cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n Ä‘Ã£ ai cÃ³ kinh nghiá»‡m xá»­ lÃ½ váº¥n Ä‘á» nÃ y chÆ°a áº¡? 

Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡!","Em chÃ o anh, chá»‹ vÃ  cÃ¡c báº¡n. Em Ä‘ang gáº·p 1 bÃ i toÃ¡n muá»‘n nhá» anh chá»‹ ai cÃ³ kinh nghiá»‡m thÃ¬ chia sáº» giÃºp em phÆ°Æ¡ng Ã¡n: Hiá»‡n táº¡i em Ä‘ang cÃ³ 1 file weight náº·ng 256mb (em train dÃ¹ng yolov4), em muá»‘n deploy lÃªn device Ä‘á»ƒ cháº¡y realtime. MÃ  file nÃ y náº·ng quÃ¡ nÃªn e muá»‘n há»i cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n Ä‘Ã£ ai cÃ³ kinh nghiá»‡m xá»­ lÃ½ váº¥n Ä‘á» nÃ y chÆ°a áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u áº¡!",,,,,
"ChÃ o cÃ¡c bÃ¡c! Náº±m vÃ¹ng trong group Ä‘Ã£ lÃ¢u nÃªn em xin Ä‘Ã³ng gÃ³p má»™t bÃ i blog nhá» vá» chá»§ Ä‘á»ƒ ""Kiá»ƒm thá»­ há»‡ thá»‘ng Machine Learning"". CÃ¡c bÃ¡c tháº¥y hay thÃ¬ tÃ­ch cá»±c like vÃ  share Ä‘á»ƒ á»§ng há»™ em vá»›i áº¡ :D.
ChÃºc cÃ¡c bÃ¡c má»™t tuáº§n lÃ m viá»‡c hiá»‡u quáº£!","ChÃ o cÃ¡c bÃ¡c! Náº±m vÃ¹ng trong group Ä‘Ã£ lÃ¢u nÃªn em xin Ä‘Ã³ng gÃ³p má»™t bÃ i blog nhá» vá» chá»§ Ä‘á»ƒ ""Kiá»ƒm thá»­ há»‡ thá»‘ng Machine Learning"". CÃ¡c bÃ¡c tháº¥y hay thÃ¬ tÃ­ch cá»±c like vÃ  share Ä‘á»ƒ á»§ng há»™ em vá»›i áº¡ :D. ChÃºc cÃ¡c bÃ¡c má»™t tuáº§n lÃ m viá»‡c hiá»‡u quáº£!",,,,,
"Má»i ngÆ°á»i cho em há»i vá» káº¿t quáº£ sau khi training thÃ¬ biá»ƒu diá»…n nhÆ° tháº¿ nÃ o vá»›i áº¡. cá»¥ thá»ƒ lÃ  bÃ i BÃ i 13: Softmax Regression cá»§a tháº§y Tiá»‡p(link á»Ÿ dÆ°á»›i) thÃ¬ em tháº¥y Ä‘Ã£ ra ma tráº­n weights thÃ¬ sau Ä‘áº¥y em khÃ´ng biáº¿t biá»ƒu diá»…n nhÆ° tháº¿ nÃ o áº¡
https://machinelearningcoban.com/2017/02/17/softmax/#-vi-du-voi-python",Má»i ngÆ°á»i cho em há»i vá» káº¿t quáº£ sau khi training thÃ¬ biá»ƒu diá»…n nhÆ° tháº¿ nÃ o vá»›i áº¡. cá»¥ thá»ƒ lÃ  bÃ i BÃ i 13: Softmax Regression cá»§a tháº§y Tiá»‡p(link á»Ÿ dÆ°á»›i) thÃ¬ em tháº¥y Ä‘Ã£ ra ma tráº­n weights thÃ¬ sau Ä‘áº¥y em khÃ´ng biáº¿t biá»ƒu diá»…n nhÆ° tháº¿ nÃ o áº¡ https://machinelearningcoban.com/2017/02/17/softmax/#-vi-du-voi-python,,,,,
"ChÃ o cáº£ nhÃ ,
MÃ¬nh Ä‘ang Ä‘o size gÆ°Æ¡ng máº·t cá»§a 1 ngÆ°á»i (ceo) trong áº£nh vÃ  size chá»¯ kÃ½ cá»§a ceo, trong bÃ¡o cÃ¡o tÃ i chÃ­nh.
Hiá»‡n mÃ¬nh Ä‘ang lÃ m báº±ng tay, mÃ¬nh cÃ³ gáº§n 100,000 reports nÃªn khÃ´ng biáº¿t khi nÃ o mÃ¬nh má»›i lÃ m xong mÃ  thá»i gian dá»± Ã¡n sáº¯p káº¿t thÃºc.
CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ code Ä‘á»ƒ giáº£i quyáº¿t cho nhanh khÃ´ng áº¡?","ChÃ o cáº£ nhÃ , MÃ¬nh Ä‘ang Ä‘o size gÆ°Æ¡ng máº·t cá»§a 1 ngÆ°á»i (ceo) trong áº£nh vÃ  size chá»¯ kÃ½ cá»§a ceo, trong bÃ¡o cÃ¡o tÃ i chÃ­nh. Hiá»‡n mÃ¬nh Ä‘ang lÃ m báº±ng tay, mÃ¬nh cÃ³ gáº§n 100,000 reports nÃªn khÃ´ng biáº¿t khi nÃ o mÃ¬nh má»›i lÃ m xong mÃ  thá»i gian dá»± Ã¡n sáº¯p káº¿t thÃºc. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ code Ä‘á»ƒ giáº£i quyáº¿t cho nhanh khÃ´ng áº¡?",,,,,
"CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ lÃ m tá»± Ä‘á»™ng thay vÃ¬ lÃ m tay, khi mÃ¬nh muá»‘n Ä‘o tá»· lá»‡ dÃ i/rá»™ng khuÃ´n máº·t trong áº£nh vÃ  size chá»¯ kÃ½ khÃ´ng áº¡?","CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ lÃ m tá»± Ä‘á»™ng thay vÃ¬ lÃ m tay, khi mÃ¬nh muá»‘n Ä‘o tá»· lá»‡ dÃ i/rá»™ng khuÃ´n máº·t trong áº£nh vÃ  size chá»¯ kÃ½ khÃ´ng áº¡?",,,,,
"FACEBOOK FELLOWSHIP PROGRAM
SUPPORTING PHD STUDENTS ENGAGED IN INNOVATIVE RESEARCH
The Facebook Fellowship is a global program designed to encourage and support promising doctoral students who are engaged in innovative and relevant research in areas related to computer science and engineering at an accredited university.
The program is open to students in any year of their PhD study. We also encourage people of diverse backgrounds and experiences to apply, especially those from traditionally under-represented minority groups. Applications are evaluated based on the strength of the studentâ€™s research statement, publication record, and recommendation letters.
Winners of the Fellowship are entitled to receive two years of paid tuition and fees, a $42,000 annual stipend to cover living and conference travel costs, a paid visit to Facebook headquarters for the annual Fellowship Summit, and various opportunities to engage with Facebook researchers.
APPLY NOW: https://research.fb.com/fellowship/","FACEBOOK FELLOWSHIP PROGRAM SUPPORTING PHD STUDENTS ENGAGED IN INNOVATIVE RESEARCH The Facebook Fellowship is a global program designed to encourage and support promising doctoral students who are engaged in innovative and relevant research in areas related to computer science and engineering at an accredited university. The program is open to students in any year of their PhD study. We also encourage people of diverse backgrounds and experiences to apply, especially those from traditionally under-represented minority groups. Applications are evaluated based on the strength of the studentâ€™s research statement, publication record, and recommendation letters. Winners of the Fellowship are entitled to receive two years of paid tuition and fees, a $42,000 annual stipend to cover living and conference travel costs, a paid visit to Facebook headquarters for the annual Fellowship Summit, and various opportunities to engage with Facebook researchers. APPLY NOW: https://research.fb.com/fellowship/",,,,,
"[Palm Detection]
ChÃ o mn, em nghiÃªn cá»©u lÃ m dá»± Ã¡n mÃ´n há»c vá» Palm Detection, nháº­n diá»‡n lÃ²ng bÃ n tay, tÃ­ch há»£p ML & DSP nhÆ°ng bá»‹ fail, káº¿t quáº£ khÃ´ng nháº­n diá»‡n tá»‘t, nhá» máº¥y anh cÃ³ kinh nghiá»‡m xem code, chá»‰ hÆ°á»›ng giáº£i quyáº¿t giÃºp em vá»›i áº¡
Lá»—i káº¿t quáº£: cÃ¹ng tay thÃ¬ nháº­n diá»‡n cÃ¹ng ngÆ°á»i, nhma so vá»›i ground truth thÃ¬ sai ngÆ°á»i, dÃ¹ em Ä‘á»•i model cÃ¡c thá»­, vÃ  thá»­ training theo nhiá»u kiá»ƒu, thÃ¬ káº¿t quáº£ sai váº«n giá»‘ng nhau ğŸ™
TLTK: em lÃ m theo cÃ¡i mindset cá»§a bÃ i ni mÃ  káº¿t quáº£ khÃ´ng tá»‘t
https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3
Em gá»­i kÃ¨m mÃ£ nguá»“n dá»± Ã¡n, náº¿u cÃ³ anh/tháº§y kinh nghiá»‡m cÃ³ thá»i gian cÃ³ thá»ƒ xem qua vÃ  chá»‰ lá»—i váº¥n Ä‘á» giÃºp em vs áº¡. Em cáº£m Æ¡n nhiá»u
https://colab.research.google.com/drive/1-7Ca3_LxpQOkdGhaezrznf9wwjM68nuV
https://drive.google.com/drive/folders/13t6aeG3WFmMGjDinnkgDf4BFsu00SdKs
!!bÃªn dÆ°á»›i lÃ  áº£nh káº¿t quáº£ sau khi thá»­ train áº¡","[Palm Detection] ChÃ o mn, em nghiÃªn cá»©u lÃ m dá»± Ã¡n mÃ´n há»c vá» Palm Detection, nháº­n diá»‡n lÃ²ng bÃ n tay, tÃ­ch há»£p ML & DSP nhÆ°ng bá»‹ fail, káº¿t quáº£ khÃ´ng nháº­n diá»‡n tá»‘t, nhá» máº¥y anh cÃ³ kinh nghiá»‡m xem code, chá»‰ hÆ°á»›ng giáº£i quyáº¿t giÃºp em vá»›i áº¡ Lá»—i káº¿t quáº£: cÃ¹ng tay thÃ¬ nháº­n diá»‡n cÃ¹ng ngÆ°á»i, nhma so vá»›i ground truth thÃ¬ sai ngÆ°á»i, dÃ¹ em Ä‘á»•i model cÃ¡c thá»­, vÃ  thá»­ training theo nhiá»u kiá»ƒu, thÃ¬ káº¿t quáº£ sai váº«n giá»‘ng nhau TLTK: em lÃ m theo cÃ¡i mindset cá»§a bÃ i ni mÃ  káº¿t quáº£ khÃ´ng tá»‘t https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3 Em gá»­i kÃ¨m mÃ£ nguá»“n dá»± Ã¡n, náº¿u cÃ³ anh/tháº§y kinh nghiá»‡m cÃ³ thá»i gian cÃ³ thá»ƒ xem qua vÃ  chá»‰ lá»—i váº¥n Ä‘á» giÃºp em vs áº¡. Em cáº£m Æ¡n nhiá»u https://colab.research.google.com/drive/1-7Ca3_LxpQOkdGhaezrznf9wwjM68nuV https://drive.google.com/drive/folders/13t6aeG3WFmMGjDinnkgDf4BFsu00SdKs !!bÃªn dÆ°á»›i lÃ  áº£nh káº¿t quáº£ sau khi thá»­ train áº¡",,,,,
"[ VIDEO THUáº¬T TOÃN MPP TRONG PHÃ‚N Bá» DANH Má»¤C Äáº¦U TÆ¯]
Hello cÃ¡c báº¡n, mÃ¬nh tÃªn lÃ  Nguyá»…n HÆ°ng Quang Kháº£i, sinh viÃªn K18, khoa ToÃ¡n á»¨ng Dá»¥ng trÆ°á»ng ÄH Quá»‘c Táº¿ TPHCM. Trong bÃ i viáº¿t kÃ¬ trÆ°á»›c, mÃ¬nh Ä‘Ã£ cÃ³ giá»›i thiá»‡u vá»›i cÃ¡c báº¡n vá» blog cá»§a mÃ¬nh trÃªn medium. HÃ´m nay mÃ¬nh xin Ä‘Äƒng video thuyáº¿t trÃ¬nh cá»§a nhÃ³m nghiÃªn cá»©u cá»§a mÃ¬nh, á»©ng dá»¥ng toÃ¡n trong thá»‹ trÆ°á»ng tÃ i chÃ­nh. ÄÃ¢y lÃ  bÃ i thuyáº¿t trÃ¬nh cá»§a nhÃ³m mÃ¬nh táº¡i chung káº¿t kÃ¬ thi Olympic Kinh Táº¿ LÆ°á»£ng ToÃ n Quá»‘c 2021. Äá» tÃ i nÃ y, Ä‘Æ°á»£c sá»± hÆ°á»›ng dáº«n trá»±c tiáº¿p cá»§a Tiáº¿n SÄ© Táº¡ Quá»‘c Báº£o
Má»¥c Ä‘Ã­ch cá»§a video nÃ y, lÃ  mÃ¬nh muá»‘n cho má»i ngÆ°á»i tháº¥y, á»©ng dá»¥ng cá»§a toÃ¡n vÃ o thá»‹ trÆ°á»ng tÃ i chÃ­nh lÃ  ra sao. Tá»« Ä‘Ã³ táº¡o cáº£m há»©ng Ä‘á»ƒ cho cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘Ã o sÃ¢u nghiÃªn cá»©u máº£ng Financial Mathematics
Äá» tÃ i cá»§a tá»¥i mÃ¬nh giáº£i quyáº¿t bÃ i toÃ¡n tá»‘i Æ°u hoÃ¡ danh má»¥c Ä‘áº§u tÆ°. NÃ³i cho dá»… hiá»ƒu, lÃ  giáº£ sá»­ cÃ¡c báº¡n cÃ³ 1 tá»· , thÃ¬ mÃ¬nh nÃªn láº¥y bao nhiá»u tiá»n trong 1 tá»· Ä‘Ã³ Ä‘á»ƒ Ä‘áº§u tÆ° vÃ o vÃ ng, vÃ o chá»©ng khoÃ¡n, hay vÃ o BÄS. ChÃºng ta nÃªn phÃ¢n bá»‘ tÃ i sáº£n Ä‘áº§u tÆ° Ä‘Ã³ lÃ m sao Ä‘á»ƒ xÃ¡c suáº¥t lá»i trong tÆ°Æ¡ng lai lÃ  cao nháº¥t cÃ³ thá»ƒ?
Thuáº­t toÃ¡n cá»§a tá»¥i mÃ¬nh hay á»Ÿ chá»—, khi Ä‘áº§u tÆ° vÃ o thá»‹ trÆ°á»ng Viá»‡t Nam, thÃ¬ kháº£ nÄƒng sinh lá»i ráº¥t cao, mÃ´ hÃ¬nh thÃ¬ ráº¥t dá»… dÃ¹ng. Chá»‰ trong vÃ²ng 2-3 phÃºt lÃ  cÃ³ thá»ƒ dÃ¹ng ngay, vÃ  Ä‘áº§u tÆ° luÃ´n vÃ o ngÃ y mai
Ná»™i dung cá»§a video bao gá»“m:
Pháº§n thuyáº¿t trÃ¬nh : Kháº£i (tá»« phÃºt 0:0 Ä‘áº¿n phÃºt 14:24) , VÅ© ( tá»« phÃºt 14:25 Ä‘áº¿n 26:00)
Pháº§n tráº£ lá»i cÃ¢u há»i vÃ  tranh luáº­n vá»›i BGK : tá»« phÃºt 26:01 Ä‘áº¿n phÃºt 46:00 ( pháº§n nÃ y khÃ¡ gÃ¢y cáº¥n)
Pháº§n káº¿t qá»§a cá»§a nhÃ³m: 46:00 Ä‘áº¿n háº¿t
NgÆ°á»i chá»§ toáº¡ cá»§a kÃ¬ thi lÃ  tiáº¿n sÄ© VÃµ TrÃ­ ThÃ nh ( Viá»‡n trÆ°á»Ÿng Viá»‡n NghiÃªn cá»©u chiáº¿n lÆ°á»£c thÆ°Æ¡ng hiá»‡u vÃ  cáº¡nh tranh,nguyÃªn cá»‘ váº¥n kinh táº¿ cá»§a thá»§ tÆ°á»›ng Nguyá»…n Táº¥n DÅ©ng )
NhÃ³m nghiÃªn cá»©u sinh Ä‘á» tÃ i bao gá»“m:
- Huá»³nh Táº¥n VÅ©
- Há»“ Há»¯u BÃ¬nh
- Nguyá»…n Ngá»c Phá»¥ng
- Nguyá»…n HÆ°ng Quang Kháº£i
- Tráº§n HoÃ ng Phi
DÆ°á»›i sá»± hÆ°á»›ng dáº«n trá»±c tiáº¿p Ä‘áº¿n tá»« Tiáº¿n SÄ© Táº¡ Quá»‘c Báº£o
Hi vá»ng video nÃ y sáº½ táº¡o nguá»“n cáº£m há»©ng gÃ¬ Ä‘Ã³ cho cÃ¡c báº¡n, giÃºp Ä‘áº©y máº¡nh hÆ¡n máº£ng nghiÃªn cá»©u Financial Mathematics táº¡i Viá»‡t Nam.","[ VIDEO THUáº¬T TOÃN MPP TRONG PHÃ‚N Bá» DANH Má»¤C Äáº¦U TÆ¯] Hello cÃ¡c báº¡n, mÃ¬nh tÃªn lÃ  Nguyá»…n HÆ°ng Quang Kháº£i, sinh viÃªn K18, khoa ToÃ¡n á»¨ng Dá»¥ng trÆ°á»ng ÄH Quá»‘c Táº¿ TPHCM. Trong bÃ i viáº¿t kÃ¬ trÆ°á»›c, mÃ¬nh Ä‘Ã£ cÃ³ giá»›i thiá»‡u vá»›i cÃ¡c báº¡n vá» blog cá»§a mÃ¬nh trÃªn medium. HÃ´m nay mÃ¬nh xin Ä‘Äƒng video thuyáº¿t trÃ¬nh cá»§a nhÃ³m nghiÃªn cá»©u cá»§a mÃ¬nh, á»©ng dá»¥ng toÃ¡n trong thá»‹ trÆ°á»ng tÃ i chÃ­nh. ÄÃ¢y lÃ  bÃ i thuyáº¿t trÃ¬nh cá»§a nhÃ³m mÃ¬nh táº¡i chung káº¿t kÃ¬ thi Olympic Kinh Táº¿ LÆ°á»£ng ToÃ n Quá»‘c 2021. Äá» tÃ i nÃ y, Ä‘Æ°á»£c sá»± hÆ°á»›ng dáº«n trá»±c tiáº¿p cá»§a Tiáº¿n SÄ© Táº¡ Quá»‘c Báº£o Má»¥c Ä‘Ã­ch cá»§a video nÃ y, lÃ  mÃ¬nh muá»‘n cho má»i ngÆ°á»i tháº¥y, á»©ng dá»¥ng cá»§a toÃ¡n vÃ o thá»‹ trÆ°á»ng tÃ i chÃ­nh lÃ  ra sao. Tá»« Ä‘Ã³ táº¡o cáº£m há»©ng Ä‘á»ƒ cho cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘Ã o sÃ¢u nghiÃªn cá»©u máº£ng Financial Mathematics Äá» tÃ i cá»§a tá»¥i mÃ¬nh giáº£i quyáº¿t bÃ i toÃ¡n tá»‘i Æ°u hoÃ¡ danh má»¥c Ä‘áº§u tÆ°. NÃ³i cho dá»… hiá»ƒu, lÃ  giáº£ sá»­ cÃ¡c báº¡n cÃ³ 1 tá»· , thÃ¬ mÃ¬nh nÃªn láº¥y bao nhiá»u tiá»n trong 1 tá»· Ä‘Ã³ Ä‘á»ƒ Ä‘áº§u tÆ° vÃ o vÃ ng, vÃ o chá»©ng khoÃ¡n, hay vÃ o BÄS. ChÃºng ta nÃªn phÃ¢n bá»‘ tÃ i sáº£n Ä‘áº§u tÆ° Ä‘Ã³ lÃ m sao Ä‘á»ƒ xÃ¡c suáº¥t lá»i trong tÆ°Æ¡ng lai lÃ  cao nháº¥t cÃ³ thá»ƒ? Thuáº­t toÃ¡n cá»§a tá»¥i mÃ¬nh hay á»Ÿ chá»—, khi Ä‘áº§u tÆ° vÃ o thá»‹ trÆ°á»ng Viá»‡t Nam, thÃ¬ kháº£ nÄƒng sinh lá»i ráº¥t cao, mÃ´ hÃ¬nh thÃ¬ ráº¥t dá»… dÃ¹ng. Chá»‰ trong vÃ²ng 2-3 phÃºt lÃ  cÃ³ thá»ƒ dÃ¹ng ngay, vÃ  Ä‘áº§u tÆ° luÃ´n vÃ o ngÃ y mai Ná»™i dung cá»§a video bao gá»“m: Pháº§n thuyáº¿t trÃ¬nh : Kháº£i (tá»« phÃºt 0:0 Ä‘áº¿n phÃºt 14:24) , VÅ© ( tá»« phÃºt 14:25 Ä‘áº¿n 26:00) Pháº§n tráº£ lá»i cÃ¢u há»i vÃ  tranh luáº­n vá»›i BGK : tá»« phÃºt 26:01 Ä‘áº¿n phÃºt 46:00 ( pháº§n nÃ y khÃ¡ gÃ¢y cáº¥n) Pháº§n káº¿t qá»§a cá»§a nhÃ³m: 46:00 Ä‘áº¿n háº¿t NgÆ°á»i chá»§ toáº¡ cá»§a kÃ¬ thi lÃ  tiáº¿n sÄ© VÃµ TrÃ­ ThÃ nh ( Viá»‡n trÆ°á»Ÿng Viá»‡n NghiÃªn cá»©u chiáº¿n lÆ°á»£c thÆ°Æ¡ng hiá»‡u vÃ  cáº¡nh tranh,nguyÃªn cá»‘ váº¥n kinh táº¿ cá»§a thá»§ tÆ°á»›ng Nguyá»…n Táº¥n DÅ©ng ) NhÃ³m nghiÃªn cá»©u sinh Ä‘á» tÃ i bao gá»“m: - Huá»³nh Táº¥n VÅ© - Há»“ Há»¯u BÃ¬nh - Nguyá»…n Ngá»c Phá»¥ng - Nguyá»…n HÆ°ng Quang Kháº£i - Tráº§n HoÃ ng Phi DÆ°á»›i sá»± hÆ°á»›ng dáº«n trá»±c tiáº¿p Ä‘áº¿n tá»« Tiáº¿n SÄ© Táº¡ Quá»‘c Báº£o Hi vá»ng video nÃ y sáº½ táº¡o nguá»“n cáº£m há»©ng gÃ¬ Ä‘Ã³ cho cÃ¡c báº¡n, giÃºp Ä‘áº©y máº¡nh hÆ¡n máº£ng nghiÃªn cá»©u Financial Mathematics táº¡i Viá»‡t Nam.",,,,,
"[PhÃ¢n loáº¡i áº£nh CT vá» brain tumor]
Em chÃ o cáº£ nhÃ , em lÃ  newbie má»›i tÃ¬m hiá»ƒu vá» máº£ng Deep learning má»™t thá»i gian, hiá»‡n em Ä‘ang lÃ m project vá» phÃ¢n loáº¡i áº£nh CT vá» brain tumor.
CÃ³ má»™t sá»‘ váº¥n Ä‘á» em chÆ°a cÃ³ kinh nghiá»‡m, nÃªn em máº¡nh dáº¡n viáº¿t lÃªn Ä‘Ã¢y ráº¥t mong cÃ³ cÆ¡ há»™i trao Ä‘á»•i vá»›i cÃ¡c anh chá»‹ áº¡.
Em cÃ³ má»™t táº­p dá»¯ liá»‡u khoáº£ng 30 áº£nh CT lÃ  tumor vÃ  70 áº£nh non tumor. Em Ä‘Ã£ thá»­ ráº¥t nhiá»u cÃ¡ch khÃ¡c nhau Ä‘á»ƒ phÃ¢n loáº¡i táº­p dá»¯ liá»‡u nÃ y.
â€”> CÃ¡ch 1: dÃ¹ng gÃ³i lá»‡nh Pyradiomics Ä‘á»ƒ chiáº¿t xuáº¥t cÃ¡c features tá»« hÃ¬nh áº£nh, rá»“i dÃ¹ng cÃ¡c thuáº­t toÃ¡n Machine learning Ä‘á»ƒ phÃ¢n loáº¡i áº£nh. Em cÅ©ng káº¿t há»£p vá»›i cÃ¡c cÃ¡ch Ä‘á»ƒ cÃ¢n báº±ng táº­p dá»¯ liá»‡u (SMOTE, Random oversampling) nhÆ°ng káº¿t quáº£ ko Ä‘c kháº£ quan láº¯m.
â€”> CÃ¡ch 2: XÃ¢y dá»±ng mÃ´ hÃ¬nh 3D-CNN káº¿t há»£p vá»›i vá»›i má»™t sá»‘ phÆ°Æ¡ng phÃ¡p data augmentation vÃ  cÃ¢n báº±ng dá»¯ liá»‡u. Káº¿t quáº£ lÃ  do táº­p dá»¯ liá»‡u cÃ²n quÃ¡ nhá» nÃªn dáº«n Ä‘áº¿n overfitting.
Em Ä‘ang muá»‘n thá»­ dÃ¹ng thÃªm transfer learning, nhÆ°ng váº¥n Ä‘á» lÃ  Ä‘á»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c cÃ¡c pretrained model thÃ¬ em pháº£i Ä‘Æ°a dá»¯ liá»‡u vá» size áº£nh mÃ  cÃ¡c model nÃ y Ä‘Ã£ Ä‘c train. Em Ä‘ang cÃ³ má»™t sá»‘ tháº¯c máº¯c lÃ :
1. PhÆ°Æ¡ng phÃ¡p nÃ o lÃ  tá»‘t nháº¥t Ä‘á»ƒ xá»­ lÃ½ áº£nh CT vÃ  Ä‘Æ°a vá» cÃ¹ng size áº£nh input cá»§a cÃ¡c pretrain model mÃ  giá»¯ Ä‘Æ°á»£c nhiá»u nháº¥t thÃ´ng tin cá»§a áº£nh.
2. Äá»‘i vá»›i táº­p dá»¯ liá»‡u nhá» nhÆ° váº­y, theo kinh nghiá»‡m cá»§a anh chá»‹ thÃ¬ nÃªn dÃ¹ng pretrained model nÃ o thÃ¬ phÃ¹ há»£p áº¡.
3. Em Ä‘ang nghÄ© Ä‘áº¿n viá»‡c dÃ¹ng phÆ°Æ¡ng phÃ¡p Variational Autoencoder (2D vÃ  3D-CNN) Ä‘á»ƒ phÃ¢n loáº¡i áº£nh, em má»›i Ä‘á»c tÃ i liá»‡u vá» phÆ°Æ¡ng phÃ¡p nÃ y nhÆ°ng em cÅ©ng chÆ°a rÃµ láº¯m, cÃ³ pháº£i lÃ  mÃ¬nh sáº½ Ã¡p dá»¥ng cÃ¡c machine learning models Ä‘á»ƒ phÃ¢n loáº¡i samples Ä‘Æ°á»£c sinh ra trong latent space khÃ´ng áº¡, hay lÃ  mÃ¬nh sáº½ dÃ¹ng output cá»§a layer (táº¡o ra \mu vÃ  \Sigma trong hÃ¬nh bÃªn dÆ°á»›i) nhÆ° input cá»§a má»™t vÃ i fully connected layer má»›i Ä‘á»ƒ phÃ¢n loáº¡i áº£nh. (Gáº§n giá»‘ng nhÆ° phÆ°Æ¡ng phÃ¡p fine tuning trong transfer learning). CÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m vá» máº£ng nÃ y cho em xin thÃªm tÆ° váº¥n vá»›i áº¡. Em cÃ¡m Æ¡n nhiá»u <3","[PhÃ¢n loáº¡i áº£nh CT vá» brain tumor] Em chÃ o cáº£ nhÃ , em lÃ  newbie má»›i tÃ¬m hiá»ƒu vá» máº£ng Deep learning má»™t thá»i gian, hiá»‡n em Ä‘ang lÃ m project vá» phÃ¢n loáº¡i áº£nh CT vá» brain tumor. CÃ³ má»™t sá»‘ váº¥n Ä‘á» em chÆ°a cÃ³ kinh nghiá»‡m, nÃªn em máº¡nh dáº¡n viáº¿t lÃªn Ä‘Ã¢y ráº¥t mong cÃ³ cÆ¡ há»™i trao Ä‘á»•i vá»›i cÃ¡c anh chá»‹ áº¡. Em cÃ³ má»™t táº­p dá»¯ liá»‡u khoáº£ng 30 áº£nh CT lÃ  tumor vÃ  70 áº£nh non tumor. Em Ä‘Ã£ thá»­ ráº¥t nhiá»u cÃ¡ch khÃ¡c nhau Ä‘á»ƒ phÃ¢n loáº¡i táº­p dá»¯ liá»‡u nÃ y. â€”> CÃ¡ch 1: dÃ¹ng gÃ³i lá»‡nh Pyradiomics Ä‘á»ƒ chiáº¿t xuáº¥t cÃ¡c features tá»« hÃ¬nh áº£nh, rá»“i dÃ¹ng cÃ¡c thuáº­t toÃ¡n Machine learning Ä‘á»ƒ phÃ¢n loáº¡i áº£nh. Em cÅ©ng káº¿t há»£p vá»›i cÃ¡c cÃ¡ch Ä‘á»ƒ cÃ¢n báº±ng táº­p dá»¯ liá»‡u (SMOTE, Random oversampling) nhÆ°ng káº¿t quáº£ ko Ä‘c kháº£ quan láº¯m. â€”> CÃ¡ch 2: XÃ¢y dá»±ng mÃ´ hÃ¬nh 3D-CNN káº¿t há»£p vá»›i vá»›i má»™t sá»‘ phÆ°Æ¡ng phÃ¡p data augmentation vÃ  cÃ¢n báº±ng dá»¯ liá»‡u. Káº¿t quáº£ lÃ  do táº­p dá»¯ liá»‡u cÃ²n quÃ¡ nhá» nÃªn dáº«n Ä‘áº¿n overfitting. Em Ä‘ang muá»‘n thá»­ dÃ¹ng thÃªm transfer learning, nhÆ°ng váº¥n Ä‘á» lÃ  Ä‘á»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c cÃ¡c pretrained model thÃ¬ em pháº£i Ä‘Æ°a dá»¯ liá»‡u vá» size áº£nh mÃ  cÃ¡c model nÃ y Ä‘Ã£ Ä‘c train. Em Ä‘ang cÃ³ má»™t sá»‘ tháº¯c máº¯c lÃ : 1. PhÆ°Æ¡ng phÃ¡p nÃ o lÃ  tá»‘t nháº¥t Ä‘á»ƒ xá»­ lÃ½ áº£nh CT vÃ  Ä‘Æ°a vá» cÃ¹ng size áº£nh input cá»§a cÃ¡c pretrain model mÃ  giá»¯ Ä‘Æ°á»£c nhiá»u nháº¥t thÃ´ng tin cá»§a áº£nh. 2. Äá»‘i vá»›i táº­p dá»¯ liá»‡u nhá» nhÆ° váº­y, theo kinh nghiá»‡m cá»§a anh chá»‹ thÃ¬ nÃªn dÃ¹ng pretrained model nÃ o thÃ¬ phÃ¹ há»£p áº¡. 3. Em Ä‘ang nghÄ© Ä‘áº¿n viá»‡c dÃ¹ng phÆ°Æ¡ng phÃ¡p Variational Autoencoder (2D vÃ  3D-CNN) Ä‘á»ƒ phÃ¢n loáº¡i áº£nh, em má»›i Ä‘á»c tÃ i liá»‡u vá» phÆ°Æ¡ng phÃ¡p nÃ y nhÆ°ng em cÅ©ng chÆ°a rÃµ láº¯m, cÃ³ pháº£i lÃ  mÃ¬nh sáº½ Ã¡p dá»¥ng cÃ¡c machine learning models Ä‘á»ƒ phÃ¢n loáº¡i samples Ä‘Æ°á»£c sinh ra trong latent space khÃ´ng áº¡, hay lÃ  mÃ¬nh sáº½ dÃ¹ng output cá»§a layer (táº¡o ra \mu vÃ  \Sigma trong hÃ¬nh bÃªn dÆ°á»›i) nhÆ° input cá»§a má»™t vÃ i fully connected layer má»›i Ä‘á»ƒ phÃ¢n loáº¡i áº£nh. (Gáº§n giá»‘ng nhÆ° phÆ°Æ¡ng phÃ¡p fine tuning trong transfer learning). CÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m vá» máº£ng nÃ y cho em xin thÃªm tÆ° váº¥n vá»›i áº¡. Em cÃ¡m Æ¡n nhiá»u <3",,,,,
"NhÃ³m vá»«a upload báº£n Ä‘á»c thá»­ á»Ÿ Ä‘Ã¢y https://drive.google.com/file/d/1y-jjYf_KNPS2DNqjqUmcZjhwUTmEqBKQ/view
Tá»‘i nay giá» VN cÃ¡c báº¡n order sá»›m sáº½ nháº­n Ä‘Æ°á»£c ebook qua email nhÃ©.",NhÃ³m vá»«a upload báº£n Ä‘á»c thá»­ á»Ÿ Ä‘Ã¢y https://drive.google.com/file/d/1y-jjYf_KNPS2DNqjqUmcZjhwUTmEqBKQ/view Tá»‘i nay giá» VN cÃ¡c báº¡n order sá»›m sáº½ nháº­n Ä‘Æ°á»£c ebook qua email nhÃ©.,,,,,
"ChÃ­nh thá»©c phÃ¡t hÃ nh ebook (pdf) ""Thá»±c hÃ nh Há»c mÃ¡y vá»›i Scikit-Learn, Keas & TensorFlow"" (Hands-On Machine Learning with Scikit-Learn and TensorFlow).
https://handson-ml.mlbvn.org/
Cáº£m Æ¡n cÃ¡c báº¡n trong nhÃ³m dá»‹ch Ä‘Ã£ lÃ m viá»‡c chÄƒm chá»‰ tá»« Ä‘áº§u nÄƒm Ä‘á»ƒ ra báº£n dá»‹ch Táº­p 1 nÃ y. Cáº£m Æ¡n FUNiX Ä‘Ã£ há»— trá»£ nhiá»‡t tÃ¬nh lÃ m viá»‡c vá»›i cÃ¡c nhÃ  xuáº¥t báº£n Ä‘á»ƒ chÃºng tÃ´i hoÃ n thiá»‡n cuá»‘n sÃ¡ch nÃ y.
Táº­p hai dá»± kiáº¿n ra máº¯t vÃ o Ä‘áº§u nÄƒm 2022.
===
CÃ¡c báº¡n cÃ³ cÃ¢u há»i thÃ¬ gá»­i vá» handson-ml@mlbvn.org. MÃ¬nh khÃ´ng phá»¥ trÃ¡ch tráº£ lá»i cÃ¢u há»i cá»§a cuá»‘n nÃ y nhÃ©, mÃ¬nh khÃ´ng tráº£ lá»i tin nháº¯n cÃ¡c báº¡n Ä‘Æ°á»£c Ä‘Ã¢u.","ChÃ­nh thá»©c phÃ¡t hÃ nh ebook (pdf) ""Thá»±c hÃ nh Há»c mÃ¡y vá»›i Scikit-Learn, Keas & TensorFlow"" (Hands-On Machine Learning with Scikit-Learn and TensorFlow). https://handson-ml.mlbvn.org/ Cáº£m Æ¡n cÃ¡c báº¡n trong nhÃ³m dá»‹ch Ä‘Ã£ lÃ m viá»‡c chÄƒm chá»‰ tá»« Ä‘áº§u nÄƒm Ä‘á»ƒ ra báº£n dá»‹ch Táº­p 1 nÃ y. Cáº£m Æ¡n FUNiX Ä‘Ã£ há»— trá»£ nhiá»‡t tÃ¬nh lÃ m viá»‡c vá»›i cÃ¡c nhÃ  xuáº¥t báº£n Ä‘á»ƒ chÃºng tÃ´i hoÃ n thiá»‡n cuá»‘n sÃ¡ch nÃ y. Táº­p hai dá»± kiáº¿n ra máº¯t vÃ o Ä‘áº§u nÄƒm 2022. === CÃ¡c báº¡n cÃ³ cÃ¢u há»i thÃ¬ gá»­i vá» handson-ml@mlbvn.org. MÃ¬nh khÃ´ng phá»¥ trÃ¡ch tráº£ lá»i cÃ¢u há»i cá»§a cuá»‘n nÃ y nhÃ©, mÃ¬nh khÃ´ng tráº£ lá»i tin nháº¯n cÃ¡c báº¡n Ä‘Æ°á»£c Ä‘Ã¢u.",,,,,
,nan,,,,,
"ChÃ o má»i ngÆ°á»i, 
Em Ä‘ang há»c ngÃ nh sinh há»c, khÃ³a luáº­n tá»‘t nghiá»‡p cá»§a em lÃ  vá» xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ dá»± Ä‘oÃ¡n liá»‡u hai protein cÃ³ tÆ°Æ¡ng tÃ¡c vá»›i nhau khÃ´ng dá»±a vÃ o Ä‘áº§u vÃ o lÃ  cÃ¡c trÃ¬nh tá»± chuá»—i amino acid (cáº¥u trÃºc báº­c 1 cá»§a protein). Em cÃ³ Ä‘á»c vÃ  tham kháº£o má»™t sá»‘ bÃ i bÃ¡o vá» chá»§ Ä‘á» nÃ y trong Ä‘Ã³ em tháº¥y cÃ³ bÃ i bÃ¡o https://academic.oup.com/bioinformatics/article/35/14/i305/5529260 Ä‘Æ°a ra mÃ´ hÃ¬nh cÃ³ tÃªn lÃ  PIPR lÃ  state of the art nÄƒm 2019 vÃ  https://www.biorxiv.org/content/10.1101/2021.01.22.427866v1 má»›i Ä‘Ã¢y nÄƒm 2021 Ä‘Æ°a ra mÃ´ hÃ¬nh cÃ³ tÃªn lÃ  D-SCRIPT cÃ³ váº» nhá»‰nh hÆ¡n mÃ´ hÃ¬nh PIPR khi sá»­ dá»¥ng training trÃªn dá»¯ liá»‡u kÃ­ch thÆ°á»›c nhá» hÆ¡n vÃ  cÃ³ kháº£ nÄƒng generalize vá»›i cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c (má»Ÿ rá»™ng kháº£ nÄƒng dá»± Ä‘oÃ¡n cho cÃ¡c sinh váº­t khÃ¡c). Em Ä‘ang gáº·p má»™t sá»‘ váº¥n Ä‘á» muá»‘n Ä‘Æ°á»£c tráº£ lá»i
MÃ´ hÃ¬nh cá»§a em cÃ³ nÃªn follow máº¥y bÃ i bÃ¡o Ä‘Ã£ xÃ¢y dá»±ng mÃ´ hÃ¬nh state of the art khÃ´ng vÃ  náº¿u follow thÃ¬ lÃ  follow má»™t mÃ´ hÃ¬nh trong 1 bÃ i bÃ¡o chÄƒng? 
Sau khi em Ä‘Ã£ follow thÃ¬ Ä‘iá»ƒm gÃ¬ sáº½ táº¡o nÃªn cháº¥t riÃªng trong khÃ³a luáº­n cá»§a em vÃ¬ em Ä‘Ã£ follow nÃ³, thá»±c sá»± thÃ¬ em sáº½ cáº§n lÃ m gÃ¬ vá»›i kiáº¿n trÃºc em Ä‘Ã£ lá»±a chá»n, cÃ³ láº½ em nÃªn tunning cÃ¡c module trong kiáº¿n trÃºc chÄƒng, hay curate láº¡i dá»¯ liá»‡u hay sá»­ dá»¥ng cÃ¡c regularization cho mÃ´ hÃ¬nh nháº±m Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c performance metrics tháº­m chÃ­ cÃ²n tá»‘t hÆ¡n mÃ´ hÃ¬nh state of the art trong bÃ i bÃ¡o gá»‘c?
Liá»‡u cÃ³ kiáº¿n trÃºc hay loáº¡i mÃ´ hÃ¬nh nÃ o lÃ  ráº¥t thÃ­ch há»£p cho tiáº¿p cáº­n bÃ i toÃ¡n nÃ y á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i, hÃ´m ná» em cÃ³ Ä‘á»c Ä‘Æ°á»£c sá»­ dá»¥ng mÃ´ hÃ¬nh GNN thÃ¬ ráº¥t tiá»‡n vÃ¬ cÃ¡c protein báº£n cháº¥t chÃ­nh lÃ  cÃ¡c Ä‘á»‰nh trong má»™t Ä‘á»“ thá»‹ tÆ°Æ¡ng tÃ¡c, Ä‘á»“ thá»‹ trao Ä‘á»•i cháº¥t, con Ä‘Æ°á»ng tÃ­n hiá»‡u, trao Ä‘á»•i cháº¥t? Liá»‡u cÃ³ hÆ°á»›ng tiáº¿p cáº­n nÃ o mÃ  má»i ngÆ°á»i nghÄ© lÃ  phÃ¹ há»£p hÆ¡n khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang há»c ngÃ nh sinh há»c, khÃ³a luáº­n tá»‘t nghiá»‡p cá»§a em lÃ  vá» xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ dá»± Ä‘oÃ¡n liá»‡u hai protein cÃ³ tÆ°Æ¡ng tÃ¡c vá»›i nhau khÃ´ng dá»±a vÃ o Ä‘áº§u vÃ o lÃ  cÃ¡c trÃ¬nh tá»± chuá»—i amino acid (cáº¥u trÃºc báº­c 1 cá»§a protein). Em cÃ³ Ä‘á»c vÃ  tham kháº£o má»™t sá»‘ bÃ i bÃ¡o vá» chá»§ Ä‘á» nÃ y trong Ä‘Ã³ em tháº¥y cÃ³ bÃ i bÃ¡o https://academic.oup.com/bioinformatics/article/35/14/i305/5529260 Ä‘Æ°a ra mÃ´ hÃ¬nh cÃ³ tÃªn lÃ  PIPR lÃ  state of the art nÄƒm 2019 vÃ  https://www.biorxiv.org/content/10.1101/2021.01.22.427866v1 má»›i Ä‘Ã¢y nÄƒm 2021 Ä‘Æ°a ra mÃ´ hÃ¬nh cÃ³ tÃªn lÃ  D-SCRIPT cÃ³ váº» nhá»‰nh hÆ¡n mÃ´ hÃ¬nh PIPR khi sá»­ dá»¥ng training trÃªn dá»¯ liá»‡u kÃ­ch thÆ°á»›c nhá» hÆ¡n vÃ  cÃ³ kháº£ nÄƒng generalize vá»›i cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c (má»Ÿ rá»™ng kháº£ nÄƒng dá»± Ä‘oÃ¡n cho cÃ¡c sinh váº­t khÃ¡c). Em Ä‘ang gáº·p má»™t sá»‘ váº¥n Ä‘á» muá»‘n Ä‘Æ°á»£c tráº£ lá»i MÃ´ hÃ¬nh cá»§a em cÃ³ nÃªn follow máº¥y bÃ i bÃ¡o Ä‘Ã£ xÃ¢y dá»±ng mÃ´ hÃ¬nh state of the art khÃ´ng vÃ  náº¿u follow thÃ¬ lÃ  follow má»™t mÃ´ hÃ¬nh trong 1 bÃ i bÃ¡o chÄƒng? Sau khi em Ä‘Ã£ follow thÃ¬ Ä‘iá»ƒm gÃ¬ sáº½ táº¡o nÃªn cháº¥t riÃªng trong khÃ³a luáº­n cá»§a em vÃ¬ em Ä‘Ã£ follow nÃ³, thá»±c sá»± thÃ¬ em sáº½ cáº§n lÃ m gÃ¬ vá»›i kiáº¿n trÃºc em Ä‘Ã£ lá»±a chá»n, cÃ³ láº½ em nÃªn tunning cÃ¡c module trong kiáº¿n trÃºc chÄƒng, hay curate láº¡i dá»¯ liá»‡u hay sá»­ dá»¥ng cÃ¡c regularization cho mÃ´ hÃ¬nh nháº±m Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c performance metrics tháº­m chÃ­ cÃ²n tá»‘t hÆ¡n mÃ´ hÃ¬nh state of the art trong bÃ i bÃ¡o gá»‘c? Liá»‡u cÃ³ kiáº¿n trÃºc hay loáº¡i mÃ´ hÃ¬nh nÃ o lÃ  ráº¥t thÃ­ch há»£p cho tiáº¿p cáº­n bÃ i toÃ¡n nÃ y á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i, hÃ´m ná» em cÃ³ Ä‘á»c Ä‘Æ°á»£c sá»­ dá»¥ng mÃ´ hÃ¬nh GNN thÃ¬ ráº¥t tiá»‡n vÃ¬ cÃ¡c protein báº£n cháº¥t chÃ­nh lÃ  cÃ¡c Ä‘á»‰nh trong má»™t Ä‘á»“ thá»‹ tÆ°Æ¡ng tÃ¡c, Ä‘á»“ thá»‹ trao Ä‘á»•i cháº¥t, con Ä‘Æ°á»ng tÃ­n hiá»‡u, trao Ä‘á»•i cháº¥t? Liá»‡u cÃ³ hÆ°á»›ng tiáº¿p cáº­n nÃ o mÃ  má»i ngÆ°á»i nghÄ© lÃ  phÃ¹ há»£p hÆ¡n khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"Sau khi giá»›i thiá»‡u CoPilot bá»Ÿi GitHub vÃ  Codex bá»Ÿi OpenAI, tá»›i lÆ°á»£t Google Brain cÃ´ng bá»‘ bÃ i bÃ¡o má»›i nháº¥t vá» chá»§ Ä‘á» tÆ°Æ¡ng tá»± táº¡i Ä‘Ã¢y https://arxiv.org/abs/2108.07732. Káº¿t quáº£ chÃ­nh lÃ  há» sá»­ dá»¥ng cÃ¡c models ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ ""viáº¿t"" cÃ¡c chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh, chÆ°Æ¡ng trÃ¬nh thá»±c thi, giáº£i cÃ¡c bÃ o toÃ¡n, há»™i thoáº¡i vá»›i ngÆ°á»i Ä‘á»ƒ tinh chá»‰nh code. MÃ´ hÃ¬nh há» bÃ¡o cÃ¡o cÃ³ thá»ƒ giáº£i chÃ­nh xÃ¡c 60% cÃ¡c chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh vÃ  81% cÃ¡c bÃ i toÃ¡n nhÆ° hÃ¬nh vÃ­ dá»¥ bÃªn dÆ°á»›i","Sau khi giá»›i thiá»‡u CoPilot bá»Ÿi GitHub vÃ  Codex bá»Ÿi OpenAI, tá»›i lÆ°á»£t Google Brain cÃ´ng bá»‘ bÃ i bÃ¡o má»›i nháº¥t vá» chá»§ Ä‘á» tÆ°Æ¡ng tá»± táº¡i Ä‘Ã¢y https://arxiv.org/abs/2108.07732. Káº¿t quáº£ chÃ­nh lÃ  há» sá»­ dá»¥ng cÃ¡c models ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ ""viáº¿t"" cÃ¡c chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh, chÆ°Æ¡ng trÃ¬nh thá»±c thi, giáº£i cÃ¡c bÃ o toÃ¡n, há»™i thoáº¡i vá»›i ngÆ°á»i Ä‘á»ƒ tinh chá»‰nh code. MÃ´ hÃ¬nh há» bÃ¡o cÃ¡o cÃ³ thá»ƒ giáº£i chÃ­nh xÃ¡c 60% cÃ¡c chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh vÃ  81% cÃ¡c bÃ i toÃ¡n nhÆ° hÃ¬nh vÃ­ dá»¥ bÃªn dÆ°á»›i",,,,,
"MÃ¬nh vá»«a chiáº¿n tháº¯ng cuá»™c thi SIIM-FISABIO-RSNA COVID-19 Detection cá»§a Kaggle.
https://www.kaggle.com/c/siim-covid19-detection/leaderboard
Cuá»™c thi nÃ y lÃ  sá»± káº¿t há»£p cá»§a 2 task classification vÃ  detection.
Source code cá»§a mÃ¬nh dÃ¹ng Ä‘á»ƒ chiáº¿n tháº¯ng cuá»™c thi nÃ y: https://github.com/dungnb1333/SIIM-COVID19-Detection
Má»i má»i ngÆ°á»i tham kháº£o.",MÃ¬nh vá»«a chiáº¿n tháº¯ng cuá»™c thi SIIM-FISABIO-RSNA COVID-19 Detection cá»§a Kaggle. https://www.kaggle.com/c/siim-covid19-detection/leaderboard Cuá»™c thi nÃ y lÃ  sá»± káº¿t há»£p cá»§a 2 task classification vÃ  detection. Source code cá»§a mÃ¬nh dÃ¹ng Ä‘á»ƒ chiáº¿n tháº¯ng cuá»™c thi nÃ y: https://github.com/dungnb1333/SIIM-COVID19-Detection Má»i má»i ngÆ°á»i tham kháº£o.,,,,,
"Khi train Yolo trÃªn colab. LÃ m tháº¿ nÃ o Ä‘á»ƒ ra Ä‘Æ°á»£c biá»ƒu Ä‘á»“ Loss - mAP tháº¿ nÃ y cÃ¡c bÃ¡c nhá»‰.
E Ä‘Ã£ thÃªm lá»‡nh -map nhÆ° á»Ÿ dÆ°á»›i rá»“i mÃ  váº«n khÃ´ng tÃ¬m tháº¥y file áº£nh Ä‘Ã¢u:
! ./darknet detector train obj.data yolov3-tiny_obj.cfg yolov3-tiny.conv.15 -map
---------
Solved: Báº­t Opencv=1 lÃªn sáº½ xuáº¥t hiá»‡n file chart.png",Khi train Yolo trÃªn colab. LÃ m tháº¿ nÃ o Ä‘á»ƒ ra Ä‘Æ°á»£c biá»ƒu Ä‘á»“ Loss - mAP tháº¿ nÃ y cÃ¡c bÃ¡c nhá»‰. E Ä‘Ã£ thÃªm lá»‡nh -map nhÆ° á»Ÿ dÆ°á»›i rá»“i mÃ  váº«n khÃ´ng tÃ¬m tháº¥y file áº£nh Ä‘Ã¢u: ! ./darknet detector train obj.data yolov3-tiny_obj.cfg yolov3-tiny.conv.15 -map --------- Solved: Báº­t Opencv=1 lÃªn sáº½ xuáº¥t hiá»‡n file chart.png,,,,,
"ChÃ o má»i ngÆ°á»i
E Ä‘ang lÃ m 1 dá»± Ã¡n cÃ¡ nhÃ¢n nhá» Ä‘á»ƒ tÃ¬m hiá»ƒu vá» NLP( tiáº¿ng anh ). Ã tÆ°á»Ÿng cá»§a e lÃ  giáº£i quyáº¿t váº¥n Ä‘á» tÃ¬m tÃªn phim dá»±a trÃªn nhá»¯ng mÃ´ táº£ cá»§a user.
Giáº£i phÃ¡p em Ä‘ang váº¡ch ra lÃ  táº¡o ra 1 bá»™ lá»c gá»“m nhiá»u yáº¿u tá»‘ khÃ¡c nhau nhÆ°ng quan trá»ng nháº¥t váº«n lÃ  ngÆ°á»i dÃ¹ng viáº¿t 1 Ä‘oáº¡n description mÃ´ táº£ vá» phim cáº§n tÃ¬m. Input lÃ  dáº¡ng text vÃ  thÆ°á»ng dao Ä‘á»™ng tá»« 5-15 cÃ¢u. Äá»ƒ truy váº¥n ra tÃªn phim cáº§n tÃ¬m thÃ¬ model sáº½ so sÃ¡nh giá»¯a Ä‘oáº¡n description nháº­p vÃ o vÃ  dataset gá»“m cÃ¡c Ä‘oáº¡n plot cá»§a wikipedia mÃ´ táº£ ráº¥t chi tiáº¿t vá» cá»‘t truyá»‡n cá»§a 3000 phim ( dao Ä‘á»™ng tá»« 60-70 cÃ¢u ) Ä‘á»ƒ tÃ¬m ra Ä‘iá»ƒm text similarity cao nháº¥t sau Ä‘Ã³ Ä‘á» xuáº¥t cÃ¡c phim phÃ¹ há»£p vá»›i miÃªu táº£ nháº¥t. 1 sá»‘ techniques e cÃ³ search ra lÃ  TF-IDF, word2vec sau Ä‘Ã³ dÃ¹ng consine similarity Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm.
NhÆ°ng váº¥n Ä‘á» lÃ  sá»± chÃªnh lá»‡ch giá»¯a Ä‘á»™ dÃ i giá»¯a input vÃ  data, cÃ¡c chi tiáº¿t cá»§a input cÅ©ng náº±m ráº£i rÃ¡c trong Ä‘oáº¡n plot, nhÃ¢n váº­t trong input cÅ©ng Ä‘á»©ng ngÃ´i thá»© 3 thay vÃ¬ trong plot lÃ  cÃ³ tÃªn riÃªng rÃµ rÃ ng,...
Cho e há»i lÃ  cÃ³ nhá»¯ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n trÃªn ( cÃ³ thá»ƒ dÃ¹ng text summarize lÃªn data plot Ä‘á»ƒ rÃºt ngáº¯n plot Ä‘Æ°á»£c khÃ´ng áº¡ )
#NLP","ChÃ o má»i ngÆ°á»i E Ä‘ang lÃ m 1 dá»± Ã¡n cÃ¡ nhÃ¢n nhá» Ä‘á»ƒ tÃ¬m hiá»ƒu vá» NLP( tiáº¿ng anh ). Ã tÆ°á»Ÿng cá»§a e lÃ  giáº£i quyáº¿t váº¥n Ä‘á» tÃ¬m tÃªn phim dá»±a trÃªn nhá»¯ng mÃ´ táº£ cá»§a user. Giáº£i phÃ¡p em Ä‘ang váº¡ch ra lÃ  táº¡o ra 1 bá»™ lá»c gá»“m nhiá»u yáº¿u tá»‘ khÃ¡c nhau nhÆ°ng quan trá»ng nháº¥t váº«n lÃ  ngÆ°á»i dÃ¹ng viáº¿t 1 Ä‘oáº¡n description mÃ´ táº£ vá» phim cáº§n tÃ¬m. Input lÃ  dáº¡ng text vÃ  thÆ°á»ng dao Ä‘á»™ng tá»« 5-15 cÃ¢u. Äá»ƒ truy váº¥n ra tÃªn phim cáº§n tÃ¬m thÃ¬ model sáº½ so sÃ¡nh giá»¯a Ä‘oáº¡n description nháº­p vÃ o vÃ  dataset gá»“m cÃ¡c Ä‘oáº¡n plot cá»§a wikipedia mÃ´ táº£ ráº¥t chi tiáº¿t vá» cá»‘t truyá»‡n cá»§a 3000 phim ( dao Ä‘á»™ng tá»« 60-70 cÃ¢u ) Ä‘á»ƒ tÃ¬m ra Ä‘iá»ƒm text similarity cao nháº¥t sau Ä‘Ã³ Ä‘á» xuáº¥t cÃ¡c phim phÃ¹ há»£p vá»›i miÃªu táº£ nháº¥t. 1 sá»‘ techniques e cÃ³ search ra lÃ  TF-IDF, word2vec sau Ä‘Ã³ dÃ¹ng consine similarity Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm. NhÆ°ng váº¥n Ä‘á» lÃ  sá»± chÃªnh lá»‡ch giá»¯a Ä‘á»™ dÃ i giá»¯a input vÃ  data, cÃ¡c chi tiáº¿t cá»§a input cÅ©ng náº±m ráº£i rÃ¡c trong Ä‘oáº¡n plot, nhÃ¢n váº­t trong input cÅ©ng Ä‘á»©ng ngÃ´i thá»© 3 thay vÃ¬ trong plot lÃ  cÃ³ tÃªn riÃªng rÃµ rÃ ng,... Cho e há»i lÃ  cÃ³ nhá»¯ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n trÃªn ( cÃ³ thá»ƒ dÃ¹ng text summarize lÃªn data plot Ä‘á»ƒ rÃºt ngáº¯n plot Ä‘Æ°á»£c khÃ´ng áº¡ )",#NLP,,,,
"DaÌ£o caÌc khoÌa trÃªn udemy vÆ¡Ìi coursera thiÌ€ thÃ¢Ìy caÌi naÌ€y trÃ´ng ""ngon laÌ€nh nhÃ¢Ìt"". CoÌ baÌc naÌ€o hoÌ£c rÃ´Ì€i cho miÌ€nh hoÌ‰i Certificate cuÌ‰a 5 course naÌ€y coÌ Ä‘aÌng Ä‘Ã´Ì€ng tiÃªÌ€n baÌt gaÌ£o ko aÌ£. Thanks ae","DaÌ£o caÌc khoÌa trÃªn udemy vÆ¡Ìi coursera thiÌ€ thÃ¢Ìy caÌi naÌ€y trÃ´ng ""ngon laÌ€nh nhÃ¢Ìt"". CoÌ baÌc naÌ€o hoÌ£c rÃ´Ì€i cho miÌ€nh hoÌ‰i Certificate cuÌ‰a 5 course naÌ€y coÌ Ä‘aÌng Ä‘Ã´Ì€ng tiÃªÌ€n baÌt gaÌ£o ko aÌ£. Thanks ae",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em Ä‘ang tÃ¬m hiá»ƒu vá» máº¡ng neural Bayes , Ä‘á»c slide Ä‘áº¿n Ä‘oáº¡n dáº¥u tÃ­ch phÃ¢n nÃ y mÃ  e khÃ´ng hiá»ƒu láº¯m. Má»i ngÆ°á»i cho e há»i Ã½ nghÄ©a cá»§a cÃ´ng thá»©c cÃ³ dáº¥u tÃ­ch phÃ¢n trong hÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡
Em cáº£m Æ¡n moij ngÆ°á»i nhiá»u","Em chÃ o má»i ngÆ°á»i áº¡ Em Ä‘ang tÃ¬m hiá»ƒu vá» máº¡ng neural Bayes , Ä‘á»c slide Ä‘áº¿n Ä‘oáº¡n dáº¥u tÃ­ch phÃ¢n nÃ y mÃ  e khÃ´ng hiá»ƒu láº¯m. Má»i ngÆ°á»i cho e há»i Ã½ nghÄ©a cá»§a cÃ´ng thá»©c cÃ³ dáº¥u tÃ­ch phÃ¢n trong hÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡ Em cáº£m Æ¡n moij ngÆ°á»i nhiá»u",,,,,
"Em Ä‘ang build 1 model translate Eng-Vi vÃ  em dÃ¹ng open-NMT khÃ´ng biáº¿t má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng lÃ m vá» translate rá»“i cho em há»i 1 chÃºt vá» preprocess , encoder vÃ  decoder tiáº¿ng viá»‡t má»i ngÆ°á»i thÆ°á»ng lÃ m tháº¿ nÃ o ?","Em Ä‘ang build 1 model translate Eng-Vi vÃ  em dÃ¹ng open-NMT khÃ´ng biáº¿t má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng lÃ m vá» translate rá»“i cho em há»i 1 chÃºt vá» preprocess , encoder vÃ  decoder tiáº¿ng viá»‡t má»i ngÆ°á»i thÆ°á»ng lÃ m tháº¿ nÃ o ?",,,,,
"DeepMind ra máº¯t PonderNet- thuÃ¢t toÃ¡n AI má»›i cho phÃ©p suy nghÄ© ká»¹ trÆ°á»›c khi tráº£ lá»i, thÃ´ng tin chi tiáº¿t táº¡i paper dÆ°á»›i","DeepMind ra máº¯t PonderNet- thuÃ¢t toÃ¡n AI má»›i cho phÃ©p suy nghÄ© ká»¹ trÆ°á»›c khi tráº£ lá»i, thÃ´ng tin chi tiáº¿t táº¡i paper dÆ°á»›i",,,,,
"ThÃ¡ng trÆ°á»›c mÃ¬nh cÃ³ Ä‘Äƒng post nÃ y thÃ´ng bÃ¡o trong thÃ¡ng 7 sáº½ cÃ³ ebook nhÆ°ng ráº¥t tiáº¿c nhÃ³m dá»‹ch khÃ´ng lÃ m ká»‹p xong thá»§ tá»¥c.
CÃ´ng viá»‡c biÃªn táº­p Ä‘Ã£ hoÃ n chá»‰nh, hiá»‡n giá» chá»‰ Ä‘ang chá» giáº¥y phÃ©p xuáº¥t báº£n vÃ  phÃ¡t hÃ nh. Hy vá»ng má»i thá»§ tá»¥c xong trong thÃ¡ng 8.
TÃ¬nh hÃ¬nh shipper khan hiáº¿m nÃªn giáº¥y phÃ©p xuáº¥t báº£n sáº½ vá» muá»™n má»™t chÃºt. Ráº¥t may lÃ  nhÃ³m Ä‘Ã£ chá»n lÃ m ebook ngay tá»« Ä‘áº§u, náº¿u lÃ m sÃ¡ch giáº¥y giá» cÃ³ láº½ ráº¥t khÃ³ chuyá»ƒn phÃ¡t.","ThÃ¡ng trÆ°á»›c mÃ¬nh cÃ³ Ä‘Äƒng post nÃ y thÃ´ng bÃ¡o trong thÃ¡ng 7 sáº½ cÃ³ ebook nhÆ°ng ráº¥t tiáº¿c nhÃ³m dá»‹ch khÃ´ng lÃ m ká»‹p xong thá»§ tá»¥c. CÃ´ng viá»‡c biÃªn táº­p Ä‘Ã£ hoÃ n chá»‰nh, hiá»‡n giá» chá»‰ Ä‘ang chá» giáº¥y phÃ©p xuáº¥t báº£n vÃ  phÃ¡t hÃ nh. Hy vá»ng má»i thá»§ tá»¥c xong trong thÃ¡ng 8. TÃ¬nh hÃ¬nh shipper khan hiáº¿m nÃªn giáº¥y phÃ©p xuáº¥t báº£n sáº½ vá» muá»™n má»™t chÃºt. Ráº¥t may lÃ  nhÃ³m Ä‘Ã£ chá»n lÃ m ebook ngay tá»« Ä‘áº§u, náº¿u lÃ m sÃ¡ch giáº¥y giá» cÃ³ láº½ ráº¥t khÃ³ chuyá»ƒn phÃ¡t.",,,,,
"https://play.google.com/store/apps/details?id=com.app_cnx.image2sketch
Chia sáº» vá»›i má»i ngÆ°á»i dá»± Ã¡n triá»ƒn khai model GAN lÃªn thiáº¿t bá»‹ di Ä‘á»™ng cháº¡y offline trÃªn thiáº¿t bá»‹ di Ä‘á»™ng khÃ´ng cáº§m server. Model GAN nÃ y cÃ³ nhiá»‡m vá»¥ chuyá»ƒn Ä‘á»•i tá»« anh thÆ°á»ng sang dáº¡ng sketch style ráº¥t mong Ä‘Æ°á»£c sá»± gÃ³p Ã½ cá»§a má»i ngÆ°á»i vá» dá»± Ã¡n.",https://play.google.com/store/apps/details?id=com.app_cnx.image2sketch Chia sáº» vá»›i má»i ngÆ°á»i dá»± Ã¡n triá»ƒn khai model GAN lÃªn thiáº¿t bá»‹ di Ä‘á»™ng cháº¡y offline trÃªn thiáº¿t bá»‹ di Ä‘á»™ng khÃ´ng cáº§m server. Model GAN nÃ y cÃ³ nhiá»‡m vá»¥ chuyá»ƒn Ä‘á»•i tá»« anh thÆ°á»ng sang dáº¡ng sketch style ráº¥t mong Ä‘Æ°á»£c sá»± gÃ³p Ã½ cá»§a má»i ngÆ°á»i vá» dá»± Ã¡n.,,,,,
"Há»i vá» ngÃ´n ngá»¯ R.
.
á» Ä‘Ã¢y cÃ³ má»™t Ä‘oáº¡n code R, Ä‘ang query dá»¯ liá»‡u trong má»™t file excel bÃªn ngoÃ i.
MÃ¬nh ko hiá»ƒu cÃº phÃ¡p á»Ÿ trong pháº§n gáº¡ch dÆ°á»›i, nhÆ°ng cÅ©ng ko biáº¿t pháº£i search tá»« khÃ³a gÃ¬ Ä‘á»ƒ tham kháº£o.
Má»i ngÆ°á»i ai biáº¿t cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘oáº¡n code giÃºp mÃ¬nh hoáº·c cho mÃ¬nh Tá»ª KHÃ“A Ä‘á»ƒ search vá»›i.
.
Thanks :D
(HÃ¬nh 1: code, HÃ¬nh 2: file excel 192_CO1007.xlsx)","Há»i vá» ngÃ´n ngá»¯ R. . á» Ä‘Ã¢y cÃ³ má»™t Ä‘oáº¡n code R, Ä‘ang query dá»¯ liá»‡u trong má»™t file excel bÃªn ngoÃ i. MÃ¬nh ko hiá»ƒu cÃº phÃ¡p á»Ÿ trong pháº§n gáº¡ch dÆ°á»›i, nhÆ°ng cÅ©ng ko biáº¿t pháº£i search tá»« khÃ³a gÃ¬ Ä‘á»ƒ tham kháº£o. Má»i ngÆ°á»i ai biáº¿t cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘oáº¡n code giÃºp mÃ¬nh hoáº·c cho mÃ¬nh Tá»ª KHÃ“A Ä‘á»ƒ search vá»›i. . Thanks :D (HÃ¬nh 1: code, HÃ¬nh 2: file excel 192_CO1007.xlsx)",,,,,
"Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n pháº§n tiáº¿p theo cá»§a cuá»‘n ""Machine Learning vá»›i dá»¯ liá»‡u dáº¡ng báº£ng"":
https://machinelearningcoban.com/tabml_book/ch_recommendation_system/introduction.html
MÃ¬nh viáº¿t láº¡i pháº§n ""Há»‡ thá»‘ng gá»£i Ã½"" cá»§a ""Machine Learning cÆ¡ báº£n"" vá»›i nhá»¯ng gÃ³c nhÃ¬n thá»±c táº¿ hÆ¡n vÃ  Ã­t náº·ng vá» toÃ¡n. MÃ¬nh cÅ©ng bá»• sung pháº§n ""Factorization Machine"" khÃ¡ thÃº vá»‹ khi cÃ¡c dá»¯ liá»‡u bÃªn lá» vá» ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m cÃ³ thá»ƒ Ä‘Æ°á»£c táº­n dá»¥ng. Váº¥n Ä‘á» ""khá»Ÿi Ä‘áº§u láº¡nh"" (cold-start problem) cÅ©ng Ä‘Æ°á»£c Ä‘á» cáº­p cÃ¹ng vá»›i má»™t vÃ i ká»¹ thuáº­t kháº¯c phá»¥c.
ChÃºc má»i ngÆ°á»i an toÃ n trong mÃ¹a dá»‹ch!","Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n pháº§n tiáº¿p theo cá»§a cuá»‘n ""Machine Learning vá»›i dá»¯ liá»‡u dáº¡ng báº£ng"": https://machinelearningcoban.com/tabml_book/ch_recommendation_system/introduction.html MÃ¬nh viáº¿t láº¡i pháº§n ""Há»‡ thá»‘ng gá»£i Ã½"" cá»§a ""Machine Learning cÆ¡ báº£n"" vá»›i nhá»¯ng gÃ³c nhÃ¬n thá»±c táº¿ hÆ¡n vÃ  Ã­t náº·ng vá» toÃ¡n. MÃ¬nh cÅ©ng bá»• sung pháº§n ""Factorization Machine"" khÃ¡ thÃº vá»‹ khi cÃ¡c dá»¯ liá»‡u bÃªn lá» vá» ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m cÃ³ thá»ƒ Ä‘Æ°á»£c táº­n dá»¥ng. Váº¥n Ä‘á» ""khá»Ÿi Ä‘áº§u láº¡nh"" (cold-start problem) cÅ©ng Ä‘Æ°á»£c Ä‘á» cáº­p cÃ¹ng vá»›i má»™t vÃ i ká»¹ thuáº­t kháº¯c phá»¥c. ChÃºc má»i ngÆ°á»i an toÃ n trong mÃ¹a dá»‹ch!",,,,,
"Em chÃ o anh chá»‹ áº¡,
Hiá»‡n táº¡i em má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» thá»‹ giÃ¡c mÃ¡y tÃ­nh nÃªn cÃ³ má»™t sá»‘ cÃ¢u há»i muá»‘n há»c há»i thÃªm áº¡:
LÃ m sao nÃ©n áº£nh tá»« Ä‘á»‹nh dáº¡ng png, jpg hoáº·c báº¥t cá»© Ä‘á»‹nh dáº¡ng áº£nh nÃ o vÃ o mÃ¡y má»™t cÃ¡ch tá»‘i Æ°u. Em cÃ³ tham kháº£o má»™t táº­p dá»¯ liá»‡u CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) thÃ¬ tháº¥y file chá»‰ cÃ³ 163MB thÃ´i mÃ  lÆ°u Ä‘Æ°á»£c háºµn 60000 áº£nh. Em khÃ´ng biáº¿t cÃ³ cÃ¡ch nÃ o lÆ°u áº£nh tá»‘i Æ°u vá»«a giáº£m Ä‘Æ°á»£c dung lÆ°á»£ng mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin áº£nh trÆ°á»›c khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh mÃ¡y há»c khÃ´ng áº¡?
LÃ m sao Ä‘á»ƒ so sÃ¡nh má»™t danh sÃ¡ch áº£nh vÃ  má»™t danh sÃ¡ch áº£nh khÃ¡c cÃ³ cÃ¡c áº£nh nÃ o trong táº­p nÃ y gáº§n giá»‘ng vá»›i táº­p kia trong thá»i gian nhanh nháº¥t mÃ  vá»«a tiáº¿t kiá»‡m bá»™ nhá»› nháº¥t (VÃ­ dá»¥ cÃ³ táº­p A bao gá»“m 1,7 triá»‡u hÃ¬nh, vÃ  táº­p B cÃ³ 10k hÃ¬nh thÃ¬ lÃ m sao mÃ¬nh cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c cÃ¡c áº£nh trong táº­p B giá»‘ng trong táº­p A má»™t cÃ¡ch nhanh nháº¥t, em hy vá»ng cÃ³ giáº£i phÃ¡p nÃ o Ä‘Ã³ tÃ¬m trong 30 phÃºt). Hiá»‡n táº¡i em Ä‘ang lÃ m báº±ng cÃ¡ch lÆ°u áº£nh dÆ°á»›i dáº¡ng vector vÃ  so sÃ¡nh cosine similarity cá»§a tá»«ng áº£nh trong táº­p B vá»›i danh sÃ¡ch áº£nh trong táº­p A nhÆ°ng kÃ­ch thÆ°á»›c Ä‘á»ƒ lÆ°u vector áº£nh trong táº­p A quÃ¡ lá»›n, lÃªn Ä‘áº¿n cáº£ trÄƒm GB vÃ  thá»i gian so sÃ¡nh cÅ©ng ráº¥t lÃ¢u.
Em cÅ©ng má»›i tÃ¬m hiá»ƒu vá» thá»‹ giÃ¡c mÃ¡y tÃ­nh nÃªn hy vá»ng Ä‘Æ°á»£c há»c há»i tá»« má»i ngÆ°á»i. Em cáº£m Æ¡n ráº¥t nhiá»u áº¡.","Em chÃ o anh chá»‹ áº¡, Hiá»‡n táº¡i em má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» thá»‹ giÃ¡c mÃ¡y tÃ­nh nÃªn cÃ³ má»™t sá»‘ cÃ¢u há»i muá»‘n há»c há»i thÃªm áº¡: LÃ m sao nÃ©n áº£nh tá»« Ä‘á»‹nh dáº¡ng png, jpg hoáº·c báº¥t cá»© Ä‘á»‹nh dáº¡ng áº£nh nÃ o vÃ o mÃ¡y má»™t cÃ¡ch tá»‘i Æ°u. Em cÃ³ tham kháº£o má»™t táº­p dá»¯ liá»‡u CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) thÃ¬ tháº¥y file chá»‰ cÃ³ 163MB thÃ´i mÃ  lÆ°u Ä‘Æ°á»£c háºµn 60000 áº£nh. Em khÃ´ng biáº¿t cÃ³ cÃ¡ch nÃ o lÆ°u áº£nh tá»‘i Æ°u vá»«a giáº£m Ä‘Æ°á»£c dung lÆ°á»£ng mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin áº£nh trÆ°á»›c khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh mÃ¡y há»c khÃ´ng áº¡? LÃ m sao Ä‘á»ƒ so sÃ¡nh má»™t danh sÃ¡ch áº£nh vÃ  má»™t danh sÃ¡ch áº£nh khÃ¡c cÃ³ cÃ¡c áº£nh nÃ o trong táº­p nÃ y gáº§n giá»‘ng vá»›i táº­p kia trong thá»i gian nhanh nháº¥t mÃ  vá»«a tiáº¿t kiá»‡m bá»™ nhá»› nháº¥t (VÃ­ dá»¥ cÃ³ táº­p A bao gá»“m 1,7 triá»‡u hÃ¬nh, vÃ  táº­p B cÃ³ 10k hÃ¬nh thÃ¬ lÃ m sao mÃ¬nh cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c cÃ¡c áº£nh trong táº­p B giá»‘ng trong táº­p A má»™t cÃ¡ch nhanh nháº¥t, em hy vá»ng cÃ³ giáº£i phÃ¡p nÃ o Ä‘Ã³ tÃ¬m trong 30 phÃºt). Hiá»‡n táº¡i em Ä‘ang lÃ m báº±ng cÃ¡ch lÆ°u áº£nh dÆ°á»›i dáº¡ng vector vÃ  so sÃ¡nh cosine similarity cá»§a tá»«ng áº£nh trong táº­p B vá»›i danh sÃ¡ch áº£nh trong táº­p A nhÆ°ng kÃ­ch thÆ°á»›c Ä‘á»ƒ lÆ°u vector áº£nh trong táº­p A quÃ¡ lá»›n, lÃªn Ä‘áº¿n cáº£ trÄƒm GB vÃ  thá»i gian so sÃ¡nh cÅ©ng ráº¥t lÃ¢u. Em cÅ©ng má»›i tÃ¬m hiá»ƒu vá» thá»‹ giÃ¡c mÃ¡y tÃ­nh nÃªn hy vá»ng Ä‘Æ°á»£c há»c há»i tá»« má»i ngÆ°á»i. Em cáº£m Æ¡n ráº¥t nhiá»u áº¡.",,,,,
"[Há»I]
Má»i ngÆ°á»i cho mÃ¬nh há»i á»Ÿ hÃ m computeSVD á»Ÿ pyspark  tráº£ vá» V lÃ  n*k 
cÃ²n á»Ÿ hÃ m scipy.sparse.linalg.svds  tráº£ vá» Vt lÃ   k*n 
mÃ¬nh chÆ°a hiá»ƒu láº¯m mong cao nhÃ¢n giáº£i Ä‘Ã¡p giÃºp mÃ¬nh vá»›i áº¡",[Há»I] Má»i ngÆ°á»i cho mÃ¬nh há»i á»Ÿ hÃ m computeSVD á»Ÿ pyspark tráº£ vá» V lÃ  n*k cÃ²n á»Ÿ hÃ m scipy.sparse.linalg.svds tráº£ vá» Vt lÃ  k*n mÃ¬nh chÆ°a hiá»ƒu láº¯m mong cao nhÃ¢n giáº£i Ä‘Ã¡p giÃºp mÃ¬nh vá»›i áº¡,,,,,
"Má»i ngÆ°á»i cho em lÃ  vá» pháº§n Information Retrieval and Web Search thÃ¬ kiáº¿n thá»©c nÃ y cÃ³ giÃºp em lÃ m Ä‘Æ°á»£c khi search 1 sáº£n pháº©m nÃ y trÃªn web rá»“i sáº½ tá»± Ä‘á»“ng tÃ¬m cÃ¡c sáº£n pháº©m liÃªn quan khÃ´ng áº¡ ?
(Em Ä‘ang tÃ¬m hiá»ƒu vá» pháº§n nÃ y Ä‘á»ƒ Ã¡p dá»¥ng vÃ o phÃ¡t triá»ƒn web mÃ  khÃ´ng biáº¿t cÃ³ Ä‘Ãºng pháº§n kiáº¿n thá»©c nÃ y bÃªn AI khÃ´ng)",Má»i ngÆ°á»i cho em lÃ  vá» pháº§n Information Retrieval and Web Search thÃ¬ kiáº¿n thá»©c nÃ y cÃ³ giÃºp em lÃ m Ä‘Æ°á»£c khi search 1 sáº£n pháº©m nÃ y trÃªn web rá»“i sáº½ tá»± Ä‘á»“ng tÃ¬m cÃ¡c sáº£n pháº©m liÃªn quan khÃ´ng áº¡ ? (Em Ä‘ang tÃ¬m hiá»ƒu vá» pháº§n nÃ y Ä‘á»ƒ Ã¡p dá»¥ng vÃ o phÃ¡t triá»ƒn web mÃ  khÃ´ng biáº¿t cÃ³ Ä‘Ãºng pháº§n kiáº¿n thá»©c nÃ y bÃªn AI khÃ´ng),,,,,
#FeatureEngineering,,#FeatureEngineering,,,,
,nan,,,,,
"Cao nhÃ¢n tá»«ng build docker sá»­ dá»¥ng GPU vÃ  CUDA cho em há»i, lÃ  em cháº¡y docker vá»›i --gpus nhÆ°ng bá»‹ ERROR: ""docker: Error response from daemon: could not select device driver """" with capabilities: [[gpu]]."" lÃ  táº¡i sao nhá»‰.
Em Ä‘Ã£ cÃ i cuda toolkit trÃªn Root. VÃ  trÃªn User cá»§a em thÃ¬ Ä‘ang sá»­ dá»¥ng docker rootless.
Mong cÃ¡c cao nhÃ¢n chá»‰ lá»‘i. Em xin cÃ¡m Æ¡n.","Cao nhÃ¢n tá»«ng build docker sá»­ dá»¥ng GPU vÃ  CUDA cho em há»i, lÃ  em cháº¡y docker vá»›i --gpus nhÆ°ng bá»‹ ERROR: ""docker: Error response from daemon: could not select device driver """" with capabilities: [[gpu]]."" lÃ  táº¡i sao nhá»‰. Em Ä‘Ã£ cÃ i cuda toolkit trÃªn Root. VÃ  trÃªn User cá»§a em thÃ¬ Ä‘ang sá»­ dá»¥ng docker rootless. Mong cÃ¡c cao nhÃ¢n chá»‰ lá»‘i. Em xin cÃ¡m Æ¡n.",,,,,
"Hi mn, cho e há»i chÃºt vá» project structure áº¡, em Ä‘Ã£ search trong group r mÃ  hÃ¬nh nhÆ° chÆ°a tháº¥y cÃ³ ai nháº¯c tá»›i. HÃ´m nay e clone 1 sá»‘ winner solution á»Ÿ kaggle vá» thÃ¬ tháº¥y má»™t sá»‘ váº¥n Ä‘á» chÆ°a hiá»ƒu vá» project structure (do e k pháº£i dÃ¢n Software vÃ  quen vá»›i code trÃªn notebook):
1. Má»i ngÆ°á»i tá»• chá»©c cÃ¢y thÆ° má»¥c nhÆ° tháº¿ nÃ o?
2. E tháº¥y há» Ä‘a pháº§n dÃ¹ng argparse, má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ truyá»n tham sá»‘ trong lÃºc cháº¡y trÃªn terminal luÃ´n Ä‘Ãºng k áº¡ ??
3. File config chá»©a hyperparameter lÃ  dáº¡ng json, má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ thuáº­n tiá»‡n trong lÃºc cháº¡y Ä‘Ãºng k áº¡??
Thanks","Hi mn, cho e há»i chÃºt vá» project structure áº¡, em Ä‘Ã£ search trong group r mÃ  hÃ¬nh nhÆ° chÆ°a tháº¥y cÃ³ ai nháº¯c tá»›i. HÃ´m nay e clone 1 sá»‘ winner solution á»Ÿ kaggle vá» thÃ¬ tháº¥y má»™t sá»‘ váº¥n Ä‘á» chÆ°a hiá»ƒu vá» project structure (do e k pháº£i dÃ¢n Software vÃ  quen vá»›i code trÃªn notebook): 1. Má»i ngÆ°á»i tá»• chá»©c cÃ¢y thÆ° má»¥c nhÆ° tháº¿ nÃ o? 2. E tháº¥y há» Ä‘a pháº§n dÃ¹ng argparse, má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ truyá»n tham sá»‘ trong lÃºc cháº¡y trÃªn terminal luÃ´n Ä‘Ãºng k áº¡ ?? 3. File config chá»©a hyperparameter lÃ  dáº¡ng json, má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ thuáº­n tiá»‡n trong lÃºc cháº¡y Ä‘Ãºng k áº¡?? Thanks",,,,,
"[AI Share - Deep Learning Visuals]
Hiá»‡n nay, viá»‡c sá»­ dá»¥ng cÃ¡c hÃ¬nh áº£nh trá»±c quan giÃºp cho viá»‡c truyá»n táº£i ná»™i dung khi thuyáº¿t trÃ¬nh trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n.
Deep Learing Visuals chá»©a hÆ¡n 200 hÃ¬nh áº£nh trá»±c quan vá» cÃ¡c kiáº¿n trÃºc vÃ  cÃ¡c lá»›p phá»• biáº¿n nháº¥t trong deep learning. Má»i ngÆ°á»i cÃ³ thá»ƒ sá»­ dá»¥ng miá»…n phÃ­ trong cÃ¡c bÃ i Ä‘Äƒng, slide, paper hoáº·c luáº­n vÄƒn, Ä‘á»“ Ã¡n cá»§a riÃªng mÃ¬nh.","[AI Share - Deep Learning Visuals] Hiá»‡n nay, viá»‡c sá»­ dá»¥ng cÃ¡c hÃ¬nh áº£nh trá»±c quan giÃºp cho viá»‡c truyá»n táº£i ná»™i dung khi thuyáº¿t trÃ¬nh trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. Deep Learing Visuals chá»©a hÆ¡n 200 hÃ¬nh áº£nh trá»±c quan vá» cÃ¡c kiáº¿n trÃºc vÃ  cÃ¡c lá»›p phá»• biáº¿n nháº¥t trong deep learning. Má»i ngÆ°á»i cÃ³ thá»ƒ sá»­ dá»¥ng miá»…n phÃ­ trong cÃ¡c bÃ i Ä‘Äƒng, slide, paper hoáº·c luáº­n vÄƒn, Ä‘á»“ Ã¡n cá»§a riÃªng mÃ¬nh.",,,,,
"ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i, em Ä‘ang laÌ€m 1 face recognization project. Theo nhÆ° em tiÌ€m hiÃªÌ‰u thiÌ€ baÌ€i toaÌn Ä‘Æ°Æ¡Ì£c chia laÌ€m 2 baÌ€i toaÌn con laÌ€:
1. Face detection
2. Classification face
ÄÃ´Ìi vÆ¡Ìi baÌ€i toaÌn 1, coÌ nhiÃªÌ€u phÆ°Æ¡ng phaÌp nhÆ° sÆ°Ì‰ duÌ£ng HoG hoÄƒÌ£c LBP Ä‘ÃªÌ‰ detect ra vuÌ€ng coÌ chÆ°Ìa khuÃ´n mÄƒÌ£t. NhÆ°ng caÌch naÌ€y Ä‘em laÌ£i Ä‘Ã´Ì£ chiÌnh xaÌc khÃ´ng cao trong caÌc trÆ°Æ¡Ì€ng hÆ¡Ì£p (mÄƒÌ£t nghiÃªng, khuÃ´n mÄƒÌ£t coÌ rÃ¢u, Ä‘eo kiÌnh, ....), nhÆ°ng thÆ¡Ì€i gian tiÌnh toaÌn nhanh. ChiÌnh viÌ€ thÃªÌ em chuyÃªÌ‰n sang tiÌ€m hiÃªÌ‰u vÃªÌ€ Deep learning, em coÌ caÌ€i Ä‘ÄƒÌ£t 2 thuÃ¢Ì£t toaÌn dnn_face_detector cuÌ‰a thÆ° viÃªÌ£n dlib vaÌ€ face_detector_cafee cuÌ‰a thÆ° viÃªÌ£n opencv. 2 ThuÃ¢Ì£t toaÌn naÌ€y vÃªÌ€ Ä‘Ã´Ì£ chiÌnh xaÌc thiÌ€ tÃ´Ìt trong caÌc trÆ°Æ¡Ì€ng hÆ¡Ì£p maÌ€ Hog vaÌ€ LBP khÃ´ng giaÌ‰i quyÃªÌt Ä‘Æ°Æ¡Ì£c. NhÆ°ng Ä‘Ã´Ì‰i laÌ£i thiÌ€ thÆ¡Ì€i gian tiÌnh toaÌn (nhÃ¢Ìt laÌ€ sÆ°Ì‰ duÌ£ng dnn_face_detetor cuÌ‰a dlib, 5 Ä‘ÃªÌn 6 giÃ¢y cho mÃ´Ìƒi aÌ‰nh). Do vÃ¢Ì£y em muÃ´Ìn tham khaÌ‰o moÌ£i ngÆ°Æ¡Ì€i:
1. CoÌ giaÌ‰i phaÌp naÌ€o sÆ°Ì‰ duÌ£ng mang deep Ä‘ÃªÌ‰ real-time proccess?
2. Sau khi detect Ä‘Æ°Æ¡Ì£c face em coÌ nÃªn sÆ°Ì‰ duÌ£ng caÌc thuÃ¢Ì£t toaÌn phÃ¢n lÆ¡Ìp (classification) cÃ´Ì‰ Ä‘iÃªÌ‰n nhÆ° (SVM, kNN...) Ä‘ÃªÌ‰ sÆ°Ì‰ duÌ£ng cho phase face recognize khÃ´ng?
3. MuÌ£c tiÃªu cuÃ´Ìi cuÌ€ng cuÌ‰a em laÌ€, viÌ€ GPU coÌ giaÌ quaÌ Ä‘ÄƒÌt vaÌ€ Ä‘Ã´Ìi khi khÃ´ng phuÌ€ hÆ¡Ì£p vÆ¡Ìi caÌc maÌy tiÌnh nhoÌ‰ nhÆ° Ras Pi. NhÆ°ng vÃ¢Ìƒn mong muÃ´Ìn Ä‘Ã´Ì£ chiÌnh xaÌc nhÃ¢Ì£n daÌ£ng Æ¡Ì‰ mÆ°Ìc tÃ´Ìt. VaÌ€ baÌ€i toaÌn cuÌ‰a em laÌ€ aÌp duÌ£ng cho dÆ°Ìƒ liÃªÌ£u camera chÆ°Ì khÃ´ng phaÌ‰i aÌ‰nh Ä‘Æ¡n.
CaÌm Æ¡n moÌ£i ngÆ°Æ¡Ì€i nhiÃªÌ€u!","ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i, em Ä‘ang laÌ€m 1 face recognization project. Theo nhÆ° em tiÌ€m hiÃªÌ‰u thiÌ€ baÌ€i toaÌn Ä‘Æ°Æ¡Ì£c chia laÌ€m 2 baÌ€i toaÌn con laÌ€: 1. Face detection 2. Classification face ÄÃ´Ìi vÆ¡Ìi baÌ€i toaÌn 1, coÌ nhiÃªÌ€u phÆ°Æ¡ng phaÌp nhÆ° sÆ°Ì‰ duÌ£ng HoG hoÄƒÌ£c LBP Ä‘ÃªÌ‰ detect ra vuÌ€ng coÌ chÆ°Ìa khuÃ´n mÄƒÌ£t. NhÆ°ng caÌch naÌ€y Ä‘em laÌ£i Ä‘Ã´Ì£ chiÌnh xaÌc khÃ´ng cao trong caÌc trÆ°Æ¡Ì€ng hÆ¡Ì£p (mÄƒÌ£t nghiÃªng, khuÃ´n mÄƒÌ£t coÌ rÃ¢u, Ä‘eo kiÌnh, ....), nhÆ°ng thÆ¡Ì€i gian tiÌnh toaÌn nhanh. ChiÌnh viÌ€ thÃªÌ em chuyÃªÌ‰n sang tiÌ€m hiÃªÌ‰u vÃªÌ€ Deep learning, em coÌ caÌ€i Ä‘ÄƒÌ£t 2 thuÃ¢Ì£t toaÌn dnn_face_detector cuÌ‰a thÆ° viÃªÌ£n dlib vaÌ€ face_detector_cafee cuÌ‰a thÆ° viÃªÌ£n opencv. 2 ThuÃ¢Ì£t toaÌn naÌ€y vÃªÌ€ Ä‘Ã´Ì£ chiÌnh xaÌc thiÌ€ tÃ´Ìt trong caÌc trÆ°Æ¡Ì€ng hÆ¡Ì£p maÌ€ Hog vaÌ€ LBP khÃ´ng giaÌ‰i quyÃªÌt Ä‘Æ°Æ¡Ì£c. NhÆ°ng Ä‘Ã´Ì‰i laÌ£i thiÌ€ thÆ¡Ì€i gian tiÌnh toaÌn (nhÃ¢Ìt laÌ€ sÆ°Ì‰ duÌ£ng dnn_face_detetor cuÌ‰a dlib, 5 Ä‘ÃªÌn 6 giÃ¢y cho mÃ´Ìƒi aÌ‰nh). Do vÃ¢Ì£y em muÃ´Ìn tham khaÌ‰o moÌ£i ngÆ°Æ¡Ì€i: 1. CoÌ giaÌ‰i phaÌp naÌ€o sÆ°Ì‰ duÌ£ng mang deep Ä‘ÃªÌ‰ real-time proccess? 2. Sau khi detect Ä‘Æ°Æ¡Ì£c face em coÌ nÃªn sÆ°Ì‰ duÌ£ng caÌc thuÃ¢Ì£t toaÌn phÃ¢n lÆ¡Ìp (classification) cÃ´Ì‰ Ä‘iÃªÌ‰n nhÆ° (SVM, kNN...) Ä‘ÃªÌ‰ sÆ°Ì‰ duÌ£ng cho phase face recognize khÃ´ng? 3. MuÌ£c tiÃªu cuÃ´Ìi cuÌ€ng cuÌ‰a em laÌ€, viÌ€ GPU coÌ giaÌ quaÌ Ä‘ÄƒÌt vaÌ€ Ä‘Ã´Ìi khi khÃ´ng phuÌ€ hÆ¡Ì£p vÆ¡Ìi caÌc maÌy tiÌnh nhoÌ‰ nhÆ° Ras Pi. NhÆ°ng vÃ¢Ìƒn mong muÃ´Ìn Ä‘Ã´Ì£ chiÌnh xaÌc nhÃ¢Ì£n daÌ£ng Æ¡Ì‰ mÆ°Ìc tÃ´Ìt. VaÌ€ baÌ€i toaÌn cuÌ‰a em laÌ€ aÌp duÌ£ng cho dÆ°Ìƒ liÃªÌ£u camera chÆ°Ì khÃ´ng phaÌ‰i aÌ‰nh Ä‘Æ¡n. CaÌm Æ¡n moÌ£i ngÆ°Æ¡Ì€i nhiÃªÌ€u!",,,,,
"Hiá»‡n nay mÃ¬nh cÃ³ Ä‘á»c 1 sá»‘ bÃ i viáº¿t vá» maximum likelihood.
VÃ  tháº¥y cÃ¡ch giáº£i lÃ  láº¥y Ä‘áº¡o hÃ m cá»§a likelihood vÃ  giáº£i phuÆ¡ng trÃ¬nh Ä‘áº¡o hÃ m báº±ng 0.
NhÆ°ng mÃ¬nh nhá»› Ä‘áº¡o hÃ m báº±ng 0 thÃ¬ hoÃ n toÃ n cÃ³ thá»ƒ lÃ  cá»±c tiá»ƒu hoáº·c lÃ  cá»±c Ä‘áº¡i (cÃ²n phá»¥ thuá»™c vÃ o Ä‘áº¡o hÃ m báº­c 2 cá»§a hÃ m sá»‘).
Tuy nhiÃªn mÃ¬nh tháº¥y toÃ n bá»™ cÃ¡c tÃ i liá»‡u mÃ¬nh Ä‘á»c qua Ä‘á»u tháº¥y tÃ¬m max báº±ng phuÆ¡ng phÃ¡p nÃ y.
KhÃ´ng biáº¿t tÆ° duy cá»§a mÃ¬nh cÃ³ bá»‹ sai á»Ÿ Ä‘iá»ƒm nÃ o khÃ´ng, má»i ngÆ°Ã²i gÃ³p Ã½ cho mÃ¬nh vá»›i áº¡","Hiá»‡n nay mÃ¬nh cÃ³ Ä‘á»c 1 sá»‘ bÃ i viáº¿t vá» maximum likelihood. VÃ  tháº¥y cÃ¡ch giáº£i lÃ  láº¥y Ä‘áº¡o hÃ m cá»§a likelihood vÃ  giáº£i phuÆ¡ng trÃ¬nh Ä‘áº¡o hÃ m báº±ng 0. NhÆ°ng mÃ¬nh nhá»› Ä‘áº¡o hÃ m báº±ng 0 thÃ¬ hoÃ n toÃ n cÃ³ thá»ƒ lÃ  cá»±c tiá»ƒu hoáº·c lÃ  cá»±c Ä‘áº¡i (cÃ²n phá»¥ thuá»™c vÃ o Ä‘áº¡o hÃ m báº­c 2 cá»§a hÃ m sá»‘). Tuy nhiÃªn mÃ¬nh tháº¥y toÃ n bá»™ cÃ¡c tÃ i liá»‡u mÃ¬nh Ä‘á»c qua Ä‘á»u tháº¥y tÃ¬m max báº±ng phuÆ¡ng phÃ¡p nÃ y. KhÃ´ng biáº¿t tÆ° duy cá»§a mÃ¬nh cÃ³ bá»‹ sai á»Ÿ Ä‘iá»ƒm nÃ o khÃ´ng, má»i ngÆ°Ã²i gÃ³p Ã½ cho mÃ¬nh vá»›i áº¡",,,,,
"ChÃ o má»i ngÆ°á»i ğŸ˜
Em má»›i báº¯t Ä‘áº§u há»c ML vÃ  Ä‘ang lÃ m táº­p lÃ m project cÆ¡ báº£n.
Hiá»‡n em Ä‘ang muá»‘n deploy ML model vá»›i app nhÆ°ng Ä‘a pháº§n cÃ¡c khoÃ¡ dáº¡y trÃªn máº¡ng chá»‰ dáº¡y connect app vá»›i ML model Ä‘Ã£ Ä‘c train rá»“i chá»© khÃ´ng chá»‰ náº¿u cÃ³ thÃªm data má»›i thÃ¬ pháº£i train tiáº¿p lÃ m sao.
VÃ­ dá»¥ nhÆ° video dÆ°á»›i Ä‘Ã¢y áº¡. Náº¿u em add thÃªm data Ä‘á»ƒ táº¡o má»™t class má»›i nhÆ° váº­y thÃ¬ lÃ m sao Ä‘á»ƒ retrain model vá»›i new data áº¡.
Anh chá»‹ nÃ o cÃ³ thá»ƒ chia sáº» kinh nghiá»‡m hoáº·c khoÃ¡ há»c nÃ o cho em tham kháº£o khÃ´ng áº¡. Em cáº£m Æ¡n nhiá»u.",ChÃ o má»i ngÆ°á»i Em má»›i báº¯t Ä‘áº§u há»c ML vÃ  Ä‘ang lÃ m táº­p lÃ m project cÆ¡ báº£n. Hiá»‡n em Ä‘ang muá»‘n deploy ML model vá»›i app nhÆ°ng Ä‘a pháº§n cÃ¡c khoÃ¡ dáº¡y trÃªn máº¡ng chá»‰ dáº¡y connect app vá»›i ML model Ä‘Ã£ Ä‘c train rá»“i chá»© khÃ´ng chá»‰ náº¿u cÃ³ thÃªm data má»›i thÃ¬ pháº£i train tiáº¿p lÃ m sao. VÃ­ dá»¥ nhÆ° video dÆ°á»›i Ä‘Ã¢y áº¡. Náº¿u em add thÃªm data Ä‘á»ƒ táº¡o má»™t class má»›i nhÆ° váº­y thÃ¬ lÃ m sao Ä‘á»ƒ retrain model vá»›i new data áº¡. Anh chá»‹ nÃ o cÃ³ thá»ƒ chia sáº» kinh nghiá»‡m hoáº·c khoÃ¡ há»c nÃ o cho em tham kháº£o khÃ´ng áº¡. Em cáº£m Æ¡n nhiá»u.,,,,,
"[AI Share]
DeepLearning-500-questions lÃ  má»™t bá»™ sÆ°u táº­p cÃ¡c cÃ¢u há»i tá»« cÃ¡c cuá»™c phá»ng váº¥n dÃ nh cho cÃ¡c kÄ© sÆ° AI Ä‘Æ°á»£c má»™t sá»‘ tiáº¿n sÄ© Trung Quá»‘c biÃªn táº­p láº¡i thÃ nh sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c hÆ¡n 45k sao trÃªn github. Ná»™i dung cuá»‘n sÃ¡ch nÃ y dá»±a trÃªn nhá»¯ng kiáº¿n thá»©c Ä‘Æ°á»£c Ä‘Ãºc káº¿t trong quÃ¡ trÃ¬nh há»c hÃ ng ngÃ y vÃ  cÃ¡c bÃ i thi viáº¿t, cÃ¢u há»i phá»ng váº¥n thÆ°á»ng gáº·p cá»§a cÃ¡c cÃ´ng ty lá»›n. Tuy nhiÃªn, sÃ¡ch nÃ y Ä‘Æ°á»£c viáº¿t báº±ng tiáº¿ng Trung Quá»‘c. Gáº§n Ä‘Ã¢y, cÃ¡c cÃ¢u há»i nÃ y má»›i cÃ³ version tiáº¿ng anh trÃªn github vá»›i 4 pháº§n chÃ­nh sau:
ChÆ°Æ¡ng 1: Mathematial Basis
ChÆ°Æ¡ng 2: Machine Learning Foundation
ChÆ°Æ¡ng 3: Deep Learning Foundation
ChÆ°Æ¡ng 4: Classis Network","[AI Share] DeepLearning-500-questions lÃ  má»™t bá»™ sÆ°u táº­p cÃ¡c cÃ¢u há»i tá»« cÃ¡c cuá»™c phá»ng váº¥n dÃ nh cho cÃ¡c kÄ© sÆ° AI Ä‘Æ°á»£c má»™t sá»‘ tiáº¿n sÄ© Trung Quá»‘c biÃªn táº­p láº¡i thÃ nh sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c hÆ¡n 45k sao trÃªn github. Ná»™i dung cuá»‘n sÃ¡ch nÃ y dá»±a trÃªn nhá»¯ng kiáº¿n thá»©c Ä‘Æ°á»£c Ä‘Ãºc káº¿t trong quÃ¡ trÃ¬nh há»c hÃ ng ngÃ y vÃ  cÃ¡c bÃ i thi viáº¿t, cÃ¢u há»i phá»ng váº¥n thÆ°á»ng gáº·p cá»§a cÃ¡c cÃ´ng ty lá»›n. Tuy nhiÃªn, sÃ¡ch nÃ y Ä‘Æ°á»£c viáº¿t báº±ng tiáº¿ng Trung Quá»‘c. Gáº§n Ä‘Ã¢y, cÃ¡c cÃ¢u há»i nÃ y má»›i cÃ³ version tiáº¿ng anh trÃªn github vá»›i 4 pháº§n chÃ­nh sau: ChÆ°Æ¡ng 1: Mathematial Basis ChÆ°Æ¡ng 2: Machine Learning Foundation ChÆ°Æ¡ng 3: Deep Learning Foundation ChÆ°Æ¡ng 4: Classis Network",,,,,
"em chÃ o má»i ngÆ°á»i áº¡. E Ä‘ang gáº·p 1 chÃºt váº¥n Ä‘á» mong má»i ng giáº£i Ä‘Ã¡p. E cÃ³ train mobilenet v2 cÃ³ sá»­ dá»¥ng pretrain vá»›i imagenet cho bá»™ dá»¯ liá»‡u riÃªng cá»§a em. Khi e train báº±ng keras thÃ¬ káº¿t quáº£ tá»‘t nhÆ°ng khi e chuyá»ƒn qua Pytorch thÃ¬ káº¿t quáº£ láº¡i tá»‡ Ä‘i ráº¥t nhiá»u, ngay chu kÃ¬ Ä‘áº§u thÃ¬ cÅ©ng Ä‘Ã£ overffit nhÆ° má»i ng cÃ³ thá»ƒ tháº¥y dÆ°á»›i hÃ¬nh( dá»¯ liá»‡u, loss function, optimizer,... Ä‘á»u giá»‘ng nhau, mode cÃ³ khÃ¡c 1 chÃºt tham sá»‘ á»Ÿ pháº§n batchnorm). E cÅ©ng Ä‘Ã£ thá»­ Ä‘iá»u chá»‰nh cÃ¡c hyperparameters rá»“i nhÆ°ng váº«n k cáº£i thiá»‡n Ä‘c nhiá»u. Ko biáº¿t lÃ­ do lÃ  do Ä‘Ã¢u áº¡","em chÃ o má»i ngÆ°á»i áº¡. E Ä‘ang gáº·p 1 chÃºt váº¥n Ä‘á» mong má»i ng giáº£i Ä‘Ã¡p. E cÃ³ train mobilenet v2 cÃ³ sá»­ dá»¥ng pretrain vá»›i imagenet cho bá»™ dá»¯ liá»‡u riÃªng cá»§a em. Khi e train báº±ng keras thÃ¬ káº¿t quáº£ tá»‘t nhÆ°ng khi e chuyá»ƒn qua Pytorch thÃ¬ káº¿t quáº£ láº¡i tá»‡ Ä‘i ráº¥t nhiá»u, ngay chu kÃ¬ Ä‘áº§u thÃ¬ cÅ©ng Ä‘Ã£ overffit nhÆ° má»i ng cÃ³ thá»ƒ tháº¥y dÆ°á»›i hÃ¬nh( dá»¯ liá»‡u, loss function, optimizer,... Ä‘á»u giá»‘ng nhau, mode cÃ³ khÃ¡c 1 chÃºt tham sá»‘ á»Ÿ pháº§n batchnorm). E cÅ©ng Ä‘Ã£ thá»­ Ä‘iá»u chá»‰nh cÃ¡c hyperparameters rá»“i nhÆ°ng váº«n k cáº£i thiá»‡n Ä‘c nhiá»u. Ko biáº¿t lÃ­ do lÃ  do Ä‘Ã¢u áº¡",,,,,
"ChÃ o cÃ¡c anh chá»‹, cháº£ lÃ  em Ä‘ang theo course Machine Learning cá»§a tháº§y Andrew Ng, tá»›i pháº§n Logistic Regression. Em cÃ³ Ä‘á»c cáº£ blog cá»§a anh Tiá»‡p Ä‘á»ƒ bá»• trá»£, cÅ©ng nhÆ° hiá»ƒu rÃµ thÃªm.
NhÆ° data cá»§a anh Tiá»‡p trong pháº§n Logistic Regression, cÃ³ thá»ƒ tháº¥y giÃ¡ trá»‹ khÃ¡ nhá», khi Ä‘Ã³ giáº£ sá»­ theta = 1, tÃ­nh sigmoid(X dot theta) sáº½ trong Ä‘oáº¡n (0, 1). NÃªn khÃ´ng cáº§n thiáº¿t pháº£i rescale.
NhÆ°ng vá»›i dá»¯ liá»‡u cá»§a tháº§y Andrew, thÃ¬ khÃ¡ lá»›n, do Ä‘Ã³ theta = [[1], [1], [1]], sigmoid(X dot theta) sáº½ == 1 hoáº·c 0. Váº­y sáº½ khÃ´ng tÃ¬m Ä‘Æ°á»£c loss, vÃ¬ khÃ´ng tÃ­nh Ä‘Æ°á»£c log(0). NhÆ°ng trong bÃ i ko há» yÃªu cáº§u rescale, cÅ©ng nhÆ° theta khá»Ÿi táº¡o lÃ  [[0], [0], [0]].
Váº­y cÃ³ Ä‘Ãºng lÃ  trong trÆ°á»ng há»£p nÃ y, vá»›i dá»¯ liá»‡u cá»§a tháº§y Andrew Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c loss, cÅ©ng nhÆ° tÃ¬m Ä‘Æ°á»£c theta má»™t cÃ¡ch thuáº­t lá»£i báº±ng gradient descent, ta cáº§n pháº£i rescale? Hay lÃ  em nháº§m láº«n, hoáº·c cÃ³ lá»— há»•ng kiáº¿n thá»©c nÃ o Ä‘Ã³ áº¡?
Em xin cáº£m Æ¡n ğŸ¤—ğŸ¤—ğŸ¤—
ps: em submit bÃ i, thÃ¬ Ä‘Æ°á»£c pass. MÃ  khi code láº¡i báº±ng python thÃ¬ láº¡i vÆ°á»›ng á»Ÿ loss function vÃ  gradient descent khÃ´ng há»™i tá»¥, nÃªn hÆ¡i hoang mang.
ps2: cÃ²n Ä‘Ã¢y lÃ  khi em rescale, má»i thá»© cÃ³ váº» ráº¥t á»•n Ã¡p https://github.com/tdbui1209/machine_learning_andrew_ng/blob/main/python/ex2/logistic_regression.ipynb","ChÃ o cÃ¡c anh chá»‹, cháº£ lÃ  em Ä‘ang theo course Machine Learning cá»§a tháº§y Andrew Ng, tá»›i pháº§n Logistic Regression. Em cÃ³ Ä‘á»c cáº£ blog cá»§a anh Tiá»‡p Ä‘á»ƒ bá»• trá»£, cÅ©ng nhÆ° hiá»ƒu rÃµ thÃªm. NhÆ° data cá»§a anh Tiá»‡p trong pháº§n Logistic Regression, cÃ³ thá»ƒ tháº¥y giÃ¡ trá»‹ khÃ¡ nhá», khi Ä‘Ã³ giáº£ sá»­ theta = 1, tÃ­nh sigmoid(X dot theta) sáº½ trong Ä‘oáº¡n (0, 1). NÃªn khÃ´ng cáº§n thiáº¿t pháº£i rescale. NhÆ°ng vá»›i dá»¯ liá»‡u cá»§a tháº§y Andrew, thÃ¬ khÃ¡ lá»›n, do Ä‘Ã³ theta = [[1], [1], [1]], sigmoid(X dot theta) sáº½ == 1 hoáº·c 0. Váº­y sáº½ khÃ´ng tÃ¬m Ä‘Æ°á»£c loss, vÃ¬ khÃ´ng tÃ­nh Ä‘Æ°á»£c log(0). NhÆ°ng trong bÃ i ko há» yÃªu cáº§u rescale, cÅ©ng nhÆ° theta khá»Ÿi táº¡o lÃ  [[0], [0], [0]]. Váº­y cÃ³ Ä‘Ãºng lÃ  trong trÆ°á»ng há»£p nÃ y, vá»›i dá»¯ liá»‡u cá»§a tháº§y Andrew Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c loss, cÅ©ng nhÆ° tÃ¬m Ä‘Æ°á»£c theta má»™t cÃ¡ch thuáº­t lá»£i báº±ng gradient descent, ta cáº§n pháº£i rescale? Hay lÃ  em nháº§m láº«n, hoáº·c cÃ³ lá»— há»•ng kiáº¿n thá»©c nÃ o Ä‘Ã³ áº¡? Em xin cáº£m Æ¡n ps: em submit bÃ i, thÃ¬ Ä‘Æ°á»£c pass. MÃ  khi code láº¡i báº±ng python thÃ¬ láº¡i vÆ°á»›ng á»Ÿ loss function vÃ  gradient descent khÃ´ng há»™i tá»¥, nÃªn hÆ¡i hoang mang. ps2: cÃ²n Ä‘Ã¢y lÃ  khi em rescale, má»i thá»© cÃ³ váº» ráº¥t á»•n Ã¡p https://github.com/tdbui1209/machine_learning_andrew_ng/blob/main/python/ex2/logistic_regression.ipynb",,,,,
,nan,,,,,
"Em/mÃ¬nh chÃ o cáº£ nhÃ ,
Em Ä‘ang lÃ m má»™t Ä‘á» tÃ i vá» tone cá»§a conversation giá»¯a CEOs vÃ  analysts. Em cáº§n thu tháº­p transcript buá»•i nÃ³i chuyá»‡n (1 firm 1 láº§n vÃ o q4) cá»§a S&P 500 firms qua 20 nÄƒm ~10,000 transcripts. Sau Ä‘Ã³ em tÃ¡ch má»—i transcript ra thÃ nh ná»™i dung cá»§a CEOs vs analysts. Ná»™i dung transcript giá»‘ng link sau áº¡.
LÃ m cÃ¡ch nÃ o thÃ¬ tá»‘t hÆ¡n áº¡?
(1)download cÃ¡c transcript dÆ°á»›i dáº¡ng txt rá»“i kÃªu python tÃ¡ch ra ná»™i dung cá»§a CEOs vs analysts
(2)lÆ°u link website cá»§a cÃ¡c transcript rá»“i kÃªu python Ä‘á»c vÃ  tÃ¡ch ra ná»™i dung cá»§a CEOs vs analysts","Em/mÃ¬nh chÃ o cáº£ nhÃ , Em Ä‘ang lÃ m má»™t Ä‘á» tÃ i vá» tone cá»§a conversation giá»¯a CEOs vÃ  analysts. Em cáº§n thu tháº­p transcript buá»•i nÃ³i chuyá»‡n (1 firm 1 láº§n vÃ o q4) cá»§a S&P 500 firms qua 20 nÄƒm ~10,000 transcripts. Sau Ä‘Ã³ em tÃ¡ch má»—i transcript ra thÃ nh ná»™i dung cá»§a CEOs vs analysts. Ná»™i dung transcript giá»‘ng link sau áº¡. LÃ m cÃ¡ch nÃ o thÃ¬ tá»‘t hÆ¡n áº¡? (1)download cÃ¡c transcript dÆ°á»›i dáº¡ng txt rá»“i kÃªu python tÃ¡ch ra ná»™i dung cá»§a CEOs vs analysts (2)lÆ°u link website cá»§a cÃ¡c transcript rá»“i kÃªu python Ä‘á»c vÃ  tÃ¡ch ra ná»™i dung cá»§a CEOs vs analysts",,,,,
"ChÃ o cáº£ nhÃ , gáº§n Ä‘Ã¢y do trend Tranformer trong Computer Vision mÃ  em Ä‘Ã£ tÃ¬m tÃ²i vÃ  Ä‘á»c Ä‘Æ°á»£c má»™t bÃ i bÃ¡o ráº¥t hay bÃªn Object Detection Ä‘Ã³ lÃ  DETR vÃ  tháº¥y Ä‘á»ƒ lÃ  DETR ko cáº§n NMS post-processing. Ai lÃ m vá» Object Detection thÃ¬ cug Ã­t nhÃ¬u ráº¥t khÃ³ chá»‹u vá» NMS ğŸ˜… nhÆ°ng tháº±ng DETR nÃ y thÃ¬ láº¡i cháº£ cáº§n NMs lun @@. Em má»›i tÃ¬m há»‰u vá» Transformer thui nÃªn cug chÆ°a há»‰u láº¯m. NÃªn cÃ³ cao thá»§ nÃ o cÃ³ thá»ƒ giáº£i Ä‘Ã¡p giÃºp táº¡i sao DETR khÃ¡c gÃ¬ so vs cÃ¡c detector cÅ© nhÆ° YOLO, SSD mÃ  nÃ³ cÃ³ thá»ƒ lÃ m Ä‘c nhÆ° váº­y? Em cáº£m Æ¡n áº¡","ChÃ o cáº£ nhÃ , gáº§n Ä‘Ã¢y do trend Tranformer trong Computer Vision mÃ  em Ä‘Ã£ tÃ¬m tÃ²i vÃ  Ä‘á»c Ä‘Æ°á»£c má»™t bÃ i bÃ¡o ráº¥t hay bÃªn Object Detection Ä‘Ã³ lÃ  DETR vÃ  tháº¥y Ä‘á»ƒ lÃ  DETR ko cáº§n NMS post-processing. Ai lÃ m vá» Object Detection thÃ¬ cug Ã­t nhÃ¬u ráº¥t khÃ³ chá»‹u vá» NMS nhÆ°ng tháº±ng DETR nÃ y thÃ¬ láº¡i cháº£ cáº§n NMs lun @@. Em má»›i tÃ¬m há»‰u vá» Transformer thui nÃªn cug chÆ°a há»‰u láº¯m. NÃªn cÃ³ cao thá»§ nÃ o cÃ³ thá»ƒ giáº£i Ä‘Ã¡p giÃºp táº¡i sao DETR khÃ¡c gÃ¬ so vs cÃ¡c detector cÅ© nhÆ° YOLO, SSD mÃ  nÃ³ cÃ³ thá»ƒ lÃ m Ä‘c nhÆ° váº­y? Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c mÃ´ hÃ¬nh há»c trÃªn dá»¯ liá»‡u Ä‘á»“ thá»‹ thÃ¬ gáº·p tháº¯c máº¯c vá»›i toÃ¡n tá»­ global max pooling. MÃ¬nh cÃ³ tÃ¬m Ä‘c cÃ´ng thá»©c nÃ y cho cÃ¡c lá»›p pooling (h_i^K lÃ  kÃ½ hiá»‡u cho hidden representation cá»§a nÃºt i sau lá»›p graph convolutional cuá»‘i cÃ¹ng - lá»›p thá»© K). mean vÃ  sum thÃ¬ cÃ³ thá»ƒ ngáº§m hiá»ƒu cÃ²n max thÃ¬ Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ° tháº¿ nÃ o nhá»‰? Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c mÃ´ hÃ¬nh há»c trÃªn dá»¯ liá»‡u Ä‘á»“ thá»‹ thÃ¬ gáº·p tháº¯c máº¯c vá»›i toÃ¡n tá»­ global max pooling. MÃ¬nh cÃ³ tÃ¬m Ä‘c cÃ´ng thá»©c nÃ y cho cÃ¡c lá»›p pooling (h_i^K lÃ  kÃ½ hiá»‡u cho hidden representation cá»§a nÃºt i sau lá»›p graph convolutional cuá»‘i cÃ¹ng - lá»›p thá»© K). mean vÃ  sum thÃ¬ cÃ³ thá»ƒ ngáº§m hiá»ƒu cÃ²n max thÃ¬ Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ° tháº¿ nÃ o nhá»‰? Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡",,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i vá» Tensorboard.
Em cÃ³ má»™t file model.pb, em muá»‘n hiá»ƒn thá»‹ model graph trÃªn Tensorboard. Em Ä‘Ã£ sá»­ dá»¥ng import_pb_to_tensorboard.py á»Ÿ Ä‘Ã¢y https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/import_pb_to_tensorboard.py nhÆ°ng khi sá»­ dá»¥ng Tensorboard thÃ¬ chá»‰ xuáº¥t graph nhÆ° áº£nh dÆ°á»›i.
Má»i ngÆ°á»i chá»‰ em cÃ¡ch fix vá»›i, hoáº·c cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ³ thá»ƒ nhÃ¬n Ä‘Æ°á»£c cÃ¡c layers á»Ÿ trong má»™t model tensorflow thÃ¬ cÃ³ thá»ƒ giÃºp em vá»›i. ","Má»i ngÆ°á»i Æ¡i cho em há»i vá» Tensorboard. Em cÃ³ má»™t file model.pb, em muá»‘n hiá»ƒn thá»‹ model graph trÃªn Tensorboard. Em Ä‘Ã£ sá»­ dá»¥ng import_pb_to_tensorboard.py á»Ÿ Ä‘Ã¢y https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/import_pb_to_tensorboard.py nhÆ°ng khi sá»­ dá»¥ng Tensorboard thÃ¬ chá»‰ xuáº¥t graph nhÆ° áº£nh dÆ°á»›i. Má»i ngÆ°á»i chá»‰ em cÃ¡ch fix vá»›i, hoáº·c cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ³ thá»ƒ nhÃ¬n Ä‘Æ°á»£c cÃ¡c layers á»Ÿ trong má»™t model tensorflow thÃ¬ cÃ³ thá»ƒ giÃºp em vá»›i.",,,,,
"Em chÃ o anh chá»‹. Em Ä‘ang lÃ m bÆ°á»›c augment cho cÃ¡c text dáº¡ng áº£nh nhÆ°ng bá»‹ vÆ°á»›ng pháº§n táº¡o shadow cho text (nhÆ° HÃ¬nh 1) vÃ  báº» cong chá»¯ (Ä‘Æ¡n giáº£n nhÆ° hÃ¬nh parabol thÃ´i nhÆ° HÃ¬nh 2) áº¡. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡, Ä‘Æ¡n giáº£n báº±ng xá»­ lÃ½ áº£nh thuáº§n vá»›i opencv cÃ ng tá»‘t áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","Em chÃ o anh chá»‹. Em Ä‘ang lÃ m bÆ°á»›c augment cho cÃ¡c text dáº¡ng áº£nh nhÆ°ng bá»‹ vÆ°á»›ng pháº§n táº¡o shadow cho text (nhÆ° HÃ¬nh 1) vÃ  báº» cong chá»¯ (Ä‘Æ¡n giáº£n nhÆ° hÃ¬nh parabol thÃ´i nhÆ° HÃ¬nh 2) áº¡. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡, Ä‘Æ¡n giáº£n báº±ng xá»­ lÃ½ áº£nh thuáº§n vá»›i opencv cÃ ng tá»‘t áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"FYI: Awesome Document Understanding
https://github.com/tstanislawek/awesome-document-understanding",FYI: Awesome Document Understanding https://github.com/tstanislawek/awesome-document-understanding,,,,,
"Má»i ngÆ°á»i cho em há»i lÃ  trong bÃ i 12 Ä‘áº¿n Ä‘oáº¡n nháº­n diá»‡n nam ná»¯. em Ä‘ang khÃ´ng biáº¿t lÃ  biáº¿n total_imgs tÃ¡c giáº£ dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬ áº¡. theo em nghÄ© Ä‘áº¥y lÃ  tá»•ng sá»‘ chiá»u táº¥t cáº£ cÃ¡c áº£nh nhÆ°ng mÃ  shape cá»§a nÃ³ láº¡i lÃ  (700, 19800). tá»•ng áº£nh chá»‰ lÃ  25 táº¥m. tá»©c lÃ  shape cá»§a nÃ³ pháº£i lÃ  (25,19800) hoáº·c (1,495,000) chá»© áº¡? mong má»i ngÆ°á»i Ä‘Ã³ng gÃ³p Ã½ kiáº¿n áº¡ em cáº£m Æ¡n. hoáº·c ai cÃ³ thá»i gian ráº£nh cÃ³ thá»ƒ hÆ°á»›ng dáº«n e bÃ i nÃ y vá»›i áº¡.
link bÃ i viáº¿t : https://machinelearningcoban.com/2017/02/11/binaryclassifiers/","Má»i ngÆ°á»i cho em há»i lÃ  trong bÃ i 12 Ä‘áº¿n Ä‘oáº¡n nháº­n diá»‡n nam ná»¯. em Ä‘ang khÃ´ng biáº¿t lÃ  biáº¿n total_imgs tÃ¡c giáº£ dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬ áº¡. theo em nghÄ© Ä‘áº¥y lÃ  tá»•ng sá»‘ chiá»u táº¥t cáº£ cÃ¡c áº£nh nhÆ°ng mÃ  shape cá»§a nÃ³ láº¡i lÃ  (700, 19800). tá»•ng áº£nh chá»‰ lÃ  25 táº¥m. tá»©c lÃ  shape cá»§a nÃ³ pháº£i lÃ  (25,19800) hoáº·c (1,495,000) chá»© áº¡? mong má»i ngÆ°á»i Ä‘Ã³ng gÃ³p Ã½ kiáº¿n áº¡ em cáº£m Æ¡n. hoáº·c ai cÃ³ thá»i gian ráº£nh cÃ³ thá»ƒ hÆ°á»›ng dáº«n e bÃ i nÃ y vá»›i áº¡. link bÃ i viáº¿t : https://machinelearningcoban.com/2017/02/11/binaryclassifiers/",,,,,
"Má»i ngÆ°á»i Æ¡i cho mÃ¬nh há»i náº¿u mÃ¬nh dÃ¹ng pytorch vÃ  torch vision Ä‘á»ƒ train Faster R-CNN: náº¿u mÃ¬nh cÃ³ pretrained backbone sáºµn rá»“i thÃ¬ cÃ³ cÃ¡ch nÃ o chá»‰ train RPN cá»§a Faster R-CNN khÃ´ng nhá»‰. CÃ³ pass paramater vÃ o create model cá»§a torch vision hay mÃ¬nh thay Ä‘á»•i á»Ÿ train() nhá»‰
Create model():
Create your backbone from timm
backbone = timm.create_model(
""resnet50"",
pretrained=True,
num_classes=0, # remove fc layers
global_pool="""" #remove fc layers
)
#add ""out_channels"" variable to the backbone because FasterRCNN use it
backbone.out_channels = backbone.feature_info[-1][""num_chs""]
anchor_generator = AnchorGenerator(
sizes=((16, 32, 64, 128, 256),), aspect_ratios=((0.25, 0.5, 1.0, 2.0),)
)
roi_pooler = torchvision.ops.MultiScaleRoIAlign(
featmap_names=[""0""], output_size=7, sampling_ratio=2
)
fastercnn_model = FasterRCNN(
backbone=backbone,
num_classes=1000,
rpn_anchor_generator=anchor_generator,
box_roi_pool=roi_pooler,
)","Má»i ngÆ°á»i Æ¡i cho mÃ¬nh há»i náº¿u mÃ¬nh dÃ¹ng pytorch vÃ  torch vision Ä‘á»ƒ train Faster R-CNN: náº¿u mÃ¬nh cÃ³ pretrained backbone sáºµn rá»“i thÃ¬ cÃ³ cÃ¡ch nÃ o chá»‰ train RPN cá»§a Faster R-CNN khÃ´ng nhá»‰. CÃ³ pass paramater vÃ o create model cá»§a torch vision hay mÃ¬nh thay Ä‘á»•i á»Ÿ train() nhá»‰ Create model(): Create your backbone from timm backbone = timm.create_model( ""resnet50"", pretrained=True, num_classes=0, # remove fc layers global_pool="""" fc layers ) ""out_channels"" variable to the backbone because FasterRCNN use it backbone.out_channels = backbone.feature_info[-1][""num_chs""] anchor_generator = AnchorGenerator( sizes=((16, 32, 64, 128, 256),), aspect_ratios=((0.25, 0.5, 1.0, 2.0),) ) roi_pooler = torchvision.ops.MultiScaleRoIAlign( featmap_names=[""0""], output_size=7, sampling_ratio=2 ) fastercnn_model = FasterRCNN( backbone=backbone, num_classes=1000, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler, )",#remove	#add,,,,
"Em chÃ o anh chá»‹ trong group,
Em sinh Ä‘ang viÃªn nÄƒm 3, ká»³ tá»›i bÃªn trÆ°á»ng em cÃ³ chÆ°Æ¡ng trÃ¬nh thá»±c táº­p 4 thÃ¡ng, nÃªn em Ä‘ang tÃ¬m má»™t cÃ´ng ty hoáº·c má»™t trung tÃ¢m Ä‘Ã o táº¡o Ä‘á»ƒ Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i máº£ng machine learning nÃ y.
Em báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» machine learning Ä‘Æ°á»£c hÆ¡n 1 thÃ¡ng nay, em báº¯t Ä‘áº§u há»c láº¡i toÃ¡n, thuáº­t toÃ¡n vÃ  tÃ¬m hiá»ƒu má»™t sá»‘ model cÆ¡ báº£n trÃªn blog anh Tiá»‡p vÃ  má»™t sá»‘ nguá»“n khÃ¡c. Em cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» thuáº­t toÃ¡n, database, ngÃ´n ngá»¯ láº­p trÃ¬nh (java, python vÃ  má»™t chÃºt vá» C#).
Anh chá»‹ cho em xin Ã½ kiáº¿n em nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u Ä‘á»ƒ Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i máº£ng machine learning nÃ y ngoÃ i thá»±c táº¿ áº¡?
Em cáº£m Æ¡n Anh chá»‹ trong group.","Em chÃ o anh chá»‹ trong group, Em sinh Ä‘ang viÃªn nÄƒm 3, ká»³ tá»›i bÃªn trÆ°á»ng em cÃ³ chÆ°Æ¡ng trÃ¬nh thá»±c táº­p 4 thÃ¡ng, nÃªn em Ä‘ang tÃ¬m má»™t cÃ´ng ty hoáº·c má»™t trung tÃ¢m Ä‘Ã o táº¡o Ä‘á»ƒ Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i máº£ng machine learning nÃ y. Em báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» machine learning Ä‘Æ°á»£c hÆ¡n 1 thÃ¡ng nay, em báº¯t Ä‘áº§u há»c láº¡i toÃ¡n, thuáº­t toÃ¡n vÃ  tÃ¬m hiá»ƒu má»™t sá»‘ model cÆ¡ báº£n trÃªn blog anh Tiá»‡p vÃ  má»™t sá»‘ nguá»“n khÃ¡c. Em cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» thuáº­t toÃ¡n, database, ngÃ´n ngá»¯ láº­p trÃ¬nh (java, python vÃ  má»™t chÃºt vá» C#). Anh chá»‹ cho em xin Ã½ kiáº¿n em nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u Ä‘á»ƒ Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i máº£ng machine learning nÃ y ngoÃ i thá»±c táº¿ áº¡? Em cáº£m Æ¡n Anh chá»‹ trong group.",,,,,
"Hi mng ah
Hiá»‡n táº¡i e cÃ³ Ä‘ang research vá» active learning method thÃ¬ liá»‡u mng cÃ³ thá»ƒ cho e 1 vÃ i cuá»‘n sÃ¡ch thá»±c sá»± cháº¥t lÆ°á»£ng vá» method nÃ y hay nhá»¯ng bÃ i viáº¿t cháº¥t lÆ°á»£ng áº¡.E cÃ³ Ä‘ang gáº·p chÃºt váº¥n Ä‘á» lÃ  apply active learning táº¡i iteration thá»© 2 ko cÃ³ cáº£i thiá»‡n so vá»›i iteration 1 thÃ¬ liá»‡u váº¥n Ä‘á» cÃ³ pháº£i do bá»™ unlabelled data chÆ°a Ä‘á»§ lá»›n vÃ  Ä‘a dáº¡ng hay cÃ³ hÆ°á»›ng Ä‘i nÃ o Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á»ƒ nÃ y ko áº¡a.Ã€ vá»›i cáº£ phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ Ä‘Æ°a ra bá»™ validation data cÃ³ thá»ƒ Ä‘á»§ tá»‘t Ä‘á»ƒ eval Ä‘c Ä‘á»™ hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p nÃ y áº¡.
Tks mng nhiá»u áº¡aa ğŸ™",Hi mng ah Hiá»‡n táº¡i e cÃ³ Ä‘ang research vá» active learning method thÃ¬ liá»‡u mng cÃ³ thá»ƒ cho e 1 vÃ i cuá»‘n sÃ¡ch thá»±c sá»± cháº¥t lÆ°á»£ng vá» method nÃ y hay nhá»¯ng bÃ i viáº¿t cháº¥t lÆ°á»£ng áº¡.E cÃ³ Ä‘ang gáº·p chÃºt váº¥n Ä‘á» lÃ  apply active learning táº¡i iteration thá»© 2 ko cÃ³ cáº£i thiá»‡n so vá»›i iteration 1 thÃ¬ liá»‡u váº¥n Ä‘á» cÃ³ pháº£i do bá»™ unlabelled data chÆ°a Ä‘á»§ lá»›n vÃ  Ä‘a dáº¡ng hay cÃ³ hÆ°á»›ng Ä‘i nÃ o Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á»ƒ nÃ y ko áº¡a.Ã€ vá»›i cáº£ phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ Ä‘Æ°a ra bá»™ validation data cÃ³ thá»ƒ Ä‘á»§ tá»‘t Ä‘á»ƒ eval Ä‘c Ä‘á»™ hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p nÃ y áº¡. Tks mng nhiá»u áº¡aa,,,,,
"ChÃ o má»i ngÆ°á»i, cho mÃ¬nh há»i lÃ  cÃ³ ai á»Ÿ Viá»‡t Nam mua colab pro chÆ°a áº¡? DÃ¹ng cÃ³ á»•n khÃ´ng ah? Do Ä‘áº¿n Ä‘oáº¡n nháº­p zipcode thÃ¬ mÃ¬nh Ä‘á»ƒ HCM thÃ¬ nÃ³ khÃ´ng cho, theo cÃ¢u tráº£ lá»i nÃ y thÃ¬ ngÆ°á»i ta cÃ³ thá»ƒ fake zipcode Ä‘Æ°á»£c. NhÆ°ng mÃ¬nh sá»£ ngÆ°á»i ta phÃ¡t hiá»‡n thÃ¬ ngÆ°á»i ta khÃ³a tÃ i khoáº£n luÃ´n quÃ¡!
https://stackoverflow.com/questions/60240863/i-am-from-pakistan-can-i-buy-google-colab-pro-for-experiments?fbclid=IwAR1sxzuR8N0ZJfrbfWs2N8nu07AiLZYLaDRyRj4lalEXbFWuJz_FDEmad3U","ChÃ o má»i ngÆ°á»i, cho mÃ¬nh há»i lÃ  cÃ³ ai á»Ÿ Viá»‡t Nam mua colab pro chÆ°a áº¡? DÃ¹ng cÃ³ á»•n khÃ´ng ah? Do Ä‘áº¿n Ä‘oáº¡n nháº­p zipcode thÃ¬ mÃ¬nh Ä‘á»ƒ HCM thÃ¬ nÃ³ khÃ´ng cho, theo cÃ¢u tráº£ lá»i nÃ y thÃ¬ ngÆ°á»i ta cÃ³ thá»ƒ fake zipcode Ä‘Æ°á»£c. NhÆ°ng mÃ¬nh sá»£ ngÆ°á»i ta phÃ¡t hiá»‡n thÃ¬ ngÆ°á»i ta khÃ³a tÃ i khoáº£n luÃ´n quÃ¡! https://stackoverflow.com/questions/60240863/i-am-from-pakistan-can-i-buy-google-colab-pro-for-experiments?fbclid=IwAR1sxzuR8N0ZJfrbfWs2N8nu07AiLZYLaDRyRj4lalEXbFWuJz_FDEmad3U",,,,,
má»i ngÆ°á»i Æ¡i cÃ³ ai cÃ³ thá»ƒ giÃºp em cÃ¢u há»i vá» reinforcement learning vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. Em khÃ´ng hiá»ƒu cÃ¡i intermediate reward lÃ  gÃ¬ Ã½ áº¡ :(,má»i ngÆ°á»i Æ¡i cÃ³ ai cÃ³ thá»ƒ giÃºp em cÃ¢u há»i vá» reinforcement learning vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. Em khÃ´ng hiá»ƒu cÃ¡i intermediate reward lÃ  gÃ¬ Ã½ áº¡ :(,,,,,
"BÃ­ áº©n Ä‘áº±ng sau giáº£i thuáº­t SGD. Liá»‡u weight decay, BN, dropout... cÃ³ thá»±c sá»± quÃ¡ quan trá»ng khi SGD cho ráº±ng tá»± tÃ´i cÅ©ng biáº¿t cÃ¡ch xá»­ lÃ½ rá»“i?","BÃ­ áº©n Ä‘áº±ng sau giáº£i thuáº­t SGD. Liá»‡u weight decay, BN, dropout... cÃ³ thá»±c sá»± quÃ¡ quan trá»ng khi SGD cho ráº±ng tá»± tÃ´i cÅ©ng biáº¿t cÃ¡ch xá»­ lÃ½ rá»“i?",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Trong nhÃ³m Ä‘Ã£ cÃ³ ai tá»«ng lÃ m vá» RNN-LSTM rá»“i cho em xin tÃ i liá»‡u mÃ  dá»… hiá»ƒu vá» máº·t toÃ¡n há»c má»™t chÃºt rá»“i cho e xin vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",Em chÃ o má»i ngÆ°á»i áº¡ Trong nhÃ³m Ä‘Ã£ cÃ³ ai tá»«ng lÃ m vá» RNN-LSTM rá»“i cho em xin tÃ i liá»‡u mÃ  dá»… hiá»ƒu vá» máº·t toÃ¡n há»c má»™t chÃºt rá»“i cho e xin vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u,,"#deep_learning, #Q&A, #math",,,
"[Vá» cÃ¡ch chia train/validate/test cho bÃ i toÃ¡n Churn prediction] Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ m sao Ä‘á»ƒ chia train/validate/test há»£p lÃ­ cho bÃ i toÃ¡n churn prediction Ä‘á»ƒ tranh bá»‹ tÃ¬nh huá»‘ng data leakage/nháº¥t lÃ  trong time series. Cá»¥ thá»ƒ, mÃ¬nh muá»‘n dá»± Ä‘oÃ¡n kháº£ nÄƒng khÃ¡ch nghá»‰ chÆ¡i vá»›i dá»‹ch vá»¥ bÃªn mÃ¬nh trong 3 thÃ¡ng tiáº¿p theo. Dá»¯ liá»‡u cá»§a mÃ¬nh cÃ³ tá»« nÄƒm 2018 trá»Ÿ Ä‘i. VÃ  táº­p feature Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch láº¥y hÃ nh vi cá»§a khÃ¡ch hÃ ng trong 12 thÃ¡ng trá»Ÿ vá» trÆ°á»›c tá»« thá»i Ä‘iá»ƒm Ä‘Æ°a ra mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n, label lÃ  nhÃ£n 0/1 khÃ¡ch hÃ ng cÃ³ rá»i Ä‘i trong 3 thÃ¡ng tá»« thá»i Ä‘iá»ƒm Ä‘Æ°a ra dá»± Ä‘oÃ¡n hay khÃ´ng. MÃ¬nh cÃ³ tÃ¬m trÃªn cÃ¡c forum nÆ°á»›c ngoÃ i nhÆ°ng khÃ´ng tháº¥y há» Ä‘á» cáº­p cÃ¡ch lÃ m viá»‡c nÃ y há»£p lÃ­.","[Vá» cÃ¡ch chia train/validate/test cho bÃ i toÃ¡n Churn prediction] Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ m sao Ä‘á»ƒ chia train/validate/test há»£p lÃ­ cho bÃ i toÃ¡n churn prediction Ä‘á»ƒ tranh bá»‹ tÃ¬nh huá»‘ng data leakage/nháº¥t lÃ  trong time series. Cá»¥ thá»ƒ, mÃ¬nh muá»‘n dá»± Ä‘oÃ¡n kháº£ nÄƒng khÃ¡ch nghá»‰ chÆ¡i vá»›i dá»‹ch vá»¥ bÃªn mÃ¬nh trong 3 thÃ¡ng tiáº¿p theo. Dá»¯ liá»‡u cá»§a mÃ¬nh cÃ³ tá»« nÄƒm 2018 trá»Ÿ Ä‘i. VÃ  táº­p feature Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch láº¥y hÃ nh vi cá»§a khÃ¡ch hÃ ng trong 12 thÃ¡ng trá»Ÿ vá» trÆ°á»›c tá»« thá»i Ä‘iá»ƒm Ä‘Æ°a ra mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n, label lÃ  nhÃ£n 0/1 khÃ¡ch hÃ ng cÃ³ rá»i Ä‘i trong 3 thÃ¡ng tá»« thá»i Ä‘iá»ƒm Ä‘Æ°a ra dá»± Ä‘oÃ¡n hay khÃ´ng. MÃ¬nh cÃ³ tÃ¬m trÃªn cÃ¡c forum nÆ°á»›c ngoÃ i nhÆ°ng khÃ´ng tháº¥y há» Ä‘á» cáº­p cÃ¡ch lÃ m viá»‡c nÃ y há»£p lÃ­.",,,,,
"Nháº­p mÃ´n Há»c mÃ¡y vÃ  Khai phÃ¡ dá»¯ liá»‡u do tháº§y ThÃ¢n Quang KhoÃ¡t, Viá»‡n CNTT&TT, BKHN giáº£ng day. BÃ i giáº£ng cung cáº¥p nhá»¯ng khÃ¡i niá»‡m tá»« cÄƒn báº£n Ä‘áº¿n chuyÃªn sÃ¢u, phÃ¹ há»£p vá»›i nhá»¯ng ngÆ°á»i muá»‘n tÃ¬m hiá»ƒu lÄ©nh vá»±c nÃ y má»™t cÃ¡ch bÃ i báº£n mÃ  chÆ°a cÃ³ nhiá»u kiáº¿n thá»©c. Xin má»i cÃ¡c báº¡n sinh viÃªn quan tÃ¢m vÃ o tÃ¬m hiá»ƒu.","Nháº­p mÃ´n Há»c mÃ¡y vÃ  Khai phÃ¡ dá»¯ liá»‡u do tháº§y ThÃ¢n Quang KhoÃ¡t, Viá»‡n CNTT&TT, BKHN giáº£ng day. BÃ i giáº£ng cung cáº¥p nhá»¯ng khÃ¡i niá»‡m tá»« cÄƒn báº£n Ä‘áº¿n chuyÃªn sÃ¢u, phÃ¹ há»£p vá»›i nhá»¯ng ngÆ°á»i muá»‘n tÃ¬m hiá»ƒu lÄ©nh vá»±c nÃ y má»™t cÃ¡ch bÃ i báº£n mÃ  chÆ°a cÃ³ nhiá»u kiáº¿n thá»©c. Xin má»i cÃ¡c báº¡n sinh viÃªn quan tÃ¢m vÃ o tÃ¬m hiá»ƒu.",,,,,
"Má»i ngÆ°á»i cho em há»i vá»›i áº¡, em Ä‘ang viáº¿t má»™t API gá»i lÃªn server Ä‘á»ƒ huáº¥n luyá»‡n model trÃªn Ä‘Ã³, tuy nhiÃªn vÃ¬ xá»­ lÃ½ Ä‘á»“ng bá»™ nÃªn phÃ­a client cá»© quay liÃªn tá»¥c Ä‘áº¿n khi nÃ o server cháº¡y xong hÃ m training ra model, gá»­i káº¿t quáº£ láº¡i má»›i thÃ´i
CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ server gá»­i vá» client message má»—i láº§n training Ä‘Æ°á»£c 1 epoch khÃ´ng áº¡?
Em cáº£m Æ¡n áº¡","Má»i ngÆ°á»i cho em há»i vá»›i áº¡, em Ä‘ang viáº¿t má»™t API gá»i lÃªn server Ä‘á»ƒ huáº¥n luyá»‡n model trÃªn Ä‘Ã³, tuy nhiÃªn vÃ¬ xá»­ lÃ½ Ä‘á»“ng bá»™ nÃªn phÃ­a client cá»© quay liÃªn tá»¥c Ä‘áº¿n khi nÃ o server cháº¡y xong hÃ m training ra model, gá»­i káº¿t quáº£ láº¡i má»›i thÃ´i CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ server gá»­i vá» client message má»—i láº§n training Ä‘Æ°á»£c 1 epoch khÃ´ng áº¡? Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i,
Hiá»‡n nay cÃ³ ráº¥t nhiá»u báº¡n tráº» Ä‘áº·t chÃ¢n vÃ o lÄ©nh vá»±c AI/ML/DL. CÃ¡c bÃ i bÃ¡o cÅ©ng nÃ³i ráº±ng lÄ©nh vá»±c nÃ y má»›i nÃªn ráº¥t cáº§n nhiá»u nguá»“n nhÃ¢n lá»±c.
NhÆ°ng thá»±c táº¿ mÃ¬nh dáº¡o trÃªn cÃ¡c nhÃ³m vÃ  trang web viá»‡c lÃ m thÃ¬ tháº¥y nhá»¯ng cÃ´ng viá»‡c liÃªn quan tháº­t sá»± khÃ´ng nhiá»u so vá»›i cÃ¡c lÄ©nh vá»±c khÃ¡c. Äáº·c biá»‡t cÃ¡c cÃ´ng viá»‡c dÃ nh cho nhá»¯ng ngÆ°á»i má»›i ra trÆ°á»ng chÆ°a cÃ³ kinh nghiá»‡m thÃ¬ cÃ ng hiáº¿m hÆ¡n ná»¯a. VÃ¬ váº­y báº¡n pháº£i thá»±c sá»± giá»i thÃ¬ má»›i cáº¡nh tranh vÃ  cÃ³ viá»‡c lÃ m Ä‘Æ°á»£c.
Thá»±c táº¿ nÃ y lÃ  lÃ½ do chÃ­nh khiáº¿n mÃ¬nh phÃ¢n vÃ¢n cÃ³ nÃªn tiáº¿p tá»¥c theo con Ä‘Æ°á»ng nÃ y hay khÃ´ng. MÃ¬nh viáº¿t bÃ i nÃ y lÃ  mong muá»‘n Ä‘Æ°á»£c cÃ¡c anh chá»‹/ cÃ¡c báº¡n chia sáº» kinh nghiá»‡m vÃ  tÆ° váº¥n giÃºp mÃ¬nh cÅ©ng nhÆ° cÃ¡c báº¡n cÃ³ cÃ¹ng hoÃ n cáº£nh vá» cÆ¡ há»™i viá»‡c lÃ m vÃ  kÄ© nÄƒng cáº§n cÃ³ Ä‘á»ƒ theo Ä‘uá»•i lÄ©nh vá»±c nÃ y áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, Hiá»‡n nay cÃ³ ráº¥t nhiá»u báº¡n tráº» Ä‘áº·t chÃ¢n vÃ o lÄ©nh vá»±c AI/ML/DL. CÃ¡c bÃ i bÃ¡o cÅ©ng nÃ³i ráº±ng lÄ©nh vá»±c nÃ y má»›i nÃªn ráº¥t cáº§n nhiá»u nguá»“n nhÃ¢n lá»±c. NhÆ°ng thá»±c táº¿ mÃ¬nh dáº¡o trÃªn cÃ¡c nhÃ³m vÃ  trang web viá»‡c lÃ m thÃ¬ tháº¥y nhá»¯ng cÃ´ng viá»‡c liÃªn quan tháº­t sá»± khÃ´ng nhiá»u so vá»›i cÃ¡c lÄ©nh vá»±c khÃ¡c. Äáº·c biá»‡t cÃ¡c cÃ´ng viá»‡c dÃ nh cho nhá»¯ng ngÆ°á»i má»›i ra trÆ°á»ng chÆ°a cÃ³ kinh nghiá»‡m thÃ¬ cÃ ng hiáº¿m hÆ¡n ná»¯a. VÃ¬ váº­y báº¡n pháº£i thá»±c sá»± giá»i thÃ¬ má»›i cáº¡nh tranh vÃ  cÃ³ viá»‡c lÃ m Ä‘Æ°á»£c. Thá»±c táº¿ nÃ y lÃ  lÃ½ do chÃ­nh khiáº¿n mÃ¬nh phÃ¢n vÃ¢n cÃ³ nÃªn tiáº¿p tá»¥c theo con Ä‘Æ°á»ng nÃ y hay khÃ´ng. MÃ¬nh viáº¿t bÃ i nÃ y lÃ  mong muá»‘n Ä‘Æ°á»£c cÃ¡c anh chá»‹/ cÃ¡c báº¡n chia sáº» kinh nghiá»‡m vÃ  tÆ° váº¥n giÃºp mÃ¬nh cÅ©ng nhÆ° cÃ¡c báº¡n cÃ³ cÃ¹ng hoÃ n cáº£nh vá» cÆ¡ há»™i viá»‡c lÃ m vÃ  kÄ© nÄƒng cáº§n cÃ³ Ä‘á»ƒ theo Ä‘uá»•i lÄ©nh vá»±c nÃ y áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
Xin cho mÃ¬nh Ä‘Æ°á»£c há»i: Khi thá»±c hiá»‡n quÃ¡ trÃ¬nh data visualization bá»™ sá»‘ liá»‡u Iris thÃ¬ mÃ¬nh tháº¥y SepalWidth cÃ³ outliers. NhÆ°ng trong cÃ¡c giáº£i thuáº­t vÃ­ dá»¥ cáº£ vá» ML láº«n DL Ä‘á»‘i vá»›i bá»™ sá»‘ liá»‡u nÃ y Ä‘Æ°á»£c trÃ¬nh bÃ y trÃªn internet mÃ¬nh khÃ´ng tháº¥y cÃ³ má»™t chá»— nÃ o vá» viá»‡c data preprocessing Ä‘á»ƒ xá»­ lÃ½ cÃ¡c outliers nÃ y. Má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp mÃ¬nh táº¡i sao láº¡i nhÆ° váº­y khÃ´ng áº¡? Xin cáº£m Æ¡n cÃ¡c Ã½ kiáº¿n gÃ³p Ã½ cá»§a cÃ¡c báº¡n.,Xin cho mÃ¬nh Ä‘Æ°á»£c há»i: Khi thá»±c hiá»‡n quÃ¡ trÃ¬nh data visualization bá»™ sá»‘ liá»‡u Iris thÃ¬ mÃ¬nh tháº¥y SepalWidth cÃ³ outliers. NhÆ°ng trong cÃ¡c giáº£i thuáº­t vÃ­ dá»¥ cáº£ vá» ML láº«n DL Ä‘á»‘i vá»›i bá»™ sá»‘ liá»‡u nÃ y Ä‘Æ°á»£c trÃ¬nh bÃ y trÃªn internet mÃ¬nh khÃ´ng tháº¥y cÃ³ má»™t chá»— nÃ o vá» viá»‡c data preprocessing Ä‘á»ƒ xá»­ lÃ½ cÃ¡c outliers nÃ y. Má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp mÃ¬nh táº¡i sao láº¡i nhÆ° váº­y khÃ´ng áº¡? Xin cáº£m Æ¡n cÃ¡c Ã½ kiáº¿n gÃ³p Ã½ cá»§a cÃ¡c báº¡n.,,,,,
"CÃ¡c chá»‹ em yÃªu cÃ´ng nghá»‡ Æ¡i, trong thá»i gian giÃ£n cÃ¡ch xÃ£ há»™i cÄƒng tháº³ng nÃ y, hÃ£y cÃ¹ng Women Techmakers Hanoi (thuá»™c Google Developers Group - GDG HÃ  Ná»™i) lan tá»a nhá»¯ng Ä‘iá»u tÃ­ch cá»±c vÃ  truyá»n cáº£m há»©ng cho nhau báº±ng cÃ¡ch tham gia sá»± kiá»‡n online cá»±c hay ho mang tÃªn: Women Techmakers Hanoi x Sutunam: Her Tech Story.
Her tech story lÃ  sá»± kiá»‡n dÃ nh cho táº¥t cáº£ cÃ¡c báº¡n ná»¯ yÃªu thÃ­ch cÃ´ng nghá»‡ vÃ  Ä‘ang lÃ m trong lÄ©nh vá»±c nÃ y cÃ³ cÆ¡ há»™i chia sáº» nhá»¯ng cÃ¢u chuyá»‡n thÃº vá»‹ cá»§a riÃªng mÃ¬nh trong quÃ¡ trÃ¬nh há»c táº­p vÃ  lÃ m viá»‡c.
Sau khi nháº­n bÃ i viáº¿t cá»§a báº¡n, chÃºng mÃ¬nh sáº½ tá»•ng há»£p vÃ  Ä‘Äƒng táº¥t cáº£ cÃ¡c bÃ i viáº¿t lÃªn trang Facebook cá»§a sá»± kiá»‡n tá»« ngÃ y 13/08/2021.
Äá»ƒ khuyáº¿n khÃ­ch nhá»¯ng cÃ¢u chuyá»‡n Ä‘Æ°á»£c lan tá»a má»™t cÃ¡ch rá»™ng rÃ£i, chÃºng mÃ¬nh Ä‘Ã£ chuáº©n bá»‹ ğŸ® ğ—´ğ—¶ğ—®Ì‰ğ—¶ ğ˜ğ—µğ˜‚Ì›ğ—¼Ì›Ì‰ğ—»ğ—´ ğ—°ğ—µğ—¼ ğŸ® ğ—¯ğ—®Ì€ğ—¶ ğ˜ƒğ—¶ğ—²Ì‚Ìğ˜ ğ˜ğ—¿ğ˜‚ğ˜†ğ—²Ì‚Ì€ğ—» ğ—°ğ—®Ì‰ğ—º ğ—µğ˜‚Ì›Ìğ—»ğ—´ ğ—»ğ—µğ—®Ì‚Ìğ˜:
ğŸ†ğ— ğ—¼Ì‚Ìƒğ—¶ ğ—´ğ—¼Ìğ—¶ ğ—´ğ—¶ğ—®Ì‰ğ—¶ ğ˜ğ—µğ˜‚Ì›ğ—¼Ì›Ì‰ğ—»ğ—´ ğ—´ğ—¼Ì‚Ì€ğ—º:
- 1 nÄƒm há»c tiáº¿ng Anh miá»…n phÃ­ trÃªn ELSA speak hoáº·c tÃ i trá»£ 100% chi phÃ­ Ä‘á»ƒ thi láº¥y chá»©ng chá»‰ cÃ´ng nghá»‡ mÃ  cÃ´ng ty Ä‘á»‘i tÃ¡c sá»­ dá»¥ng. (TÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 3,000,000 VND trá»Ÿ lÃªn)
- BÃ i thi Ä‘Æ°á»£c featured trÃªn má»i kÃªnh social cá»§a cÃ´ng ty Ä‘á»‘i tÃ¡c (Facebook, Linkedin, Twitter) cÅ©ng nhÆ° trang blog cÃ´ng nghá»‡ chÃ­nh thá»©c, trang viá»‡c lÃ m
- 1 ngÃ y tham gia tráº£i nghiá»‡m vÄƒn hÃ³a trá»±c tiáº¿p táº¡i cÃ´ng ty Ä‘á»‘i tÃ¡c.
- Giáº¥y chá»©ng nháº­n Ä‘áº¡t giáº£i tá»« cÃ´ng ty Ä‘á»‘i tÃ¡c
- 1 set quÃ  táº·ng ká»· niá»‡m tá»« cÃ´ng ty Ä‘á»‘i tÃ¡c
- 1 set quÃ  táº·ng ká»· niá»‡m tá»« Women Techmakers Hanoi
NgoÃ i 2 giáº£i thÆ°á»Ÿng trÃªn, chÃºng mÃ¬nh cÃ²n cÃ³ nhá»¯ng báº¥t ngá» thÃº vá»‹ khÃ¡c cho báº¡n trong suá»‘t hÃ nh trÃ¬nh Her Tech Story. HÃ£y báº¥m theo dÃµi sá»± kiá»‡n Ä‘á»ƒ nháº­n nhá»¯ng thÃ´ng bÃ¡o má»›i nháº¥t tá»« chÃºng mÃ¬nh nhÃ©! ğŸ˜ŠğŸ˜Š
---------
Gá»­i bÃ i viáº¿t thÃ´ng qua Link: https://forms.gle/YfBqmZdMxtU9qSoBA
Link sá»± kiá»‡n:
https://www.facebook.com/events/346238727029341
Má»i thÃ´ng tin thÃªm, tháº¯c máº¯c, vui lÃ²ng inbox page hoáº·c liÃªn láº¡c:
Ms. KhÃ¡nh Linh: 0976682295","CÃ¡c chá»‹ em yÃªu cÃ´ng nghá»‡ Æ¡i, trong thá»i gian giÃ£n cÃ¡ch xÃ£ há»™i cÄƒng tháº³ng nÃ y, hÃ£y cÃ¹ng Women Techmakers Hanoi (thuá»™c Google Developers Group - GDG HÃ  Ná»™i) lan tá»a nhá»¯ng Ä‘iá»u tÃ­ch cá»±c vÃ  truyá»n cáº£m há»©ng cho nhau báº±ng cÃ¡ch tham gia sá»± kiá»‡n online cá»±c hay ho mang tÃªn: Women Techmakers Hanoi x Sutunam: Her Tech Story. Her tech story lÃ  sá»± kiá»‡n dÃ nh cho táº¥t cáº£ cÃ¡c báº¡n ná»¯ yÃªu thÃ­ch cÃ´ng nghá»‡ vÃ  Ä‘ang lÃ m trong lÄ©nh vá»±c nÃ y cÃ³ cÆ¡ há»™i chia sáº» nhá»¯ng cÃ¢u chuyá»‡n thÃº vá»‹ cá»§a riÃªng mÃ¬nh trong quÃ¡ trÃ¬nh há»c táº­p vÃ  lÃ m viá»‡c. Sau khi nháº­n bÃ i viáº¿t cá»§a báº¡n, chÃºng mÃ¬nh sáº½ tá»•ng há»£p vÃ  Ä‘Äƒng táº¥t cáº£ cÃ¡c bÃ i viáº¿t lÃªn trang Facebook cá»§a sá»± kiá»‡n tá»« ngÃ y 13/08/2021. Äá»ƒ khuyáº¿n khÃ­ch nhá»¯ng cÃ¢u chuyá»‡n Ä‘Æ°á»£c lan tá»a má»™t cÃ¡ch rá»™ng rÃ£i, chÃºng mÃ¬nh Ä‘Ã£ chuáº©n bá»‹ Ì‰ Ì›Ì›Ì‰ Ì€ Ì‚Ì Ì‚Ì€ Ì‰ Ì›Ì Ì‚Ì: Ì‚Ìƒ Ì Ì‰ Ì›Ì›Ì‰ Ì‚Ì€: - 1 nÄƒm há»c tiáº¿ng Anh miá»…n phÃ­ trÃªn ELSA speak hoáº·c tÃ i trá»£ 100% chi phÃ­ Ä‘á»ƒ thi láº¥y chá»©ng chá»‰ cÃ´ng nghá»‡ mÃ  cÃ´ng ty Ä‘á»‘i tÃ¡c sá»­ dá»¥ng. (TÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 3,000,000 VND trá»Ÿ lÃªn) - BÃ i thi Ä‘Æ°á»£c featured trÃªn má»i kÃªnh social cá»§a cÃ´ng ty Ä‘á»‘i tÃ¡c (Facebook, Linkedin, Twitter) cÅ©ng nhÆ° trang blog cÃ´ng nghá»‡ chÃ­nh thá»©c, trang viá»‡c lÃ m - 1 ngÃ y tham gia tráº£i nghiá»‡m vÄƒn hÃ³a trá»±c tiáº¿p táº¡i cÃ´ng ty Ä‘á»‘i tÃ¡c. - Giáº¥y chá»©ng nháº­n Ä‘áº¡t giáº£i tá»« cÃ´ng ty Ä‘á»‘i tÃ¡c - 1 set quÃ  táº·ng ká»· niá»‡m tá»« cÃ´ng ty Ä‘á»‘i tÃ¡c - 1 set quÃ  táº·ng ká»· niá»‡m tá»« Women Techmakers Hanoi NgoÃ i 2 giáº£i thÆ°á»Ÿng trÃªn, chÃºng mÃ¬nh cÃ²n cÃ³ nhá»¯ng báº¥t ngá» thÃº vá»‹ khÃ¡c cho báº¡n trong suá»‘t hÃ nh trÃ¬nh Her Tech Story. HÃ£y báº¥m theo dÃµi sá»± kiá»‡n Ä‘á»ƒ nháº­n nhá»¯ng thÃ´ng bÃ¡o má»›i nháº¥t tá»« chÃºng mÃ¬nh nhÃ©! --------- Gá»­i bÃ i viáº¿t thÃ´ng qua Link: https://forms.gle/YfBqmZdMxtU9qSoBA Link sá»± kiá»‡n: https://www.facebook.com/events/346238727029341 Má»i thÃ´ng tin thÃªm, tháº¯c máº¯c, vui lÃ²ng inbox page hoáº·c liÃªn láº¡c: Ms. KhÃ¡nh Linh: 0976682295",,,,,
Cuá»‘n sÃ¡ch nÃ y sáº½ ra máº¯t dÆ°á»›i dáº¡ng ebook trong thÃ¡ng 7.,Cuá»‘n sÃ¡ch nÃ y sáº½ ra máº¯t dÆ°á»›i dáº¡ng ebook trong thÃ¡ng 7.,,,,,
Hiá»‡n mÃ¬nh Ä‘ang lÃ m theo hÆ°á»›ng dáº«n sá»­ dá»¥ng deepspeech Ä‘á»ƒ lÃ m NLP vÃ  mÃ¬nh lÃ m trÃªn gg colab nhÆ°ng khi mÃ¬nh lÃ m tá»›i hÆ°á»›ng dáº«n pre-train model Ä‘oáº¡n docker file thÃ¬ bá»‹ lá»—i nhÆ° váº§y cÃ¡c bÃ¡c cÃ³ ai biáº¿t cÃ¡ch fix khÃ´ng giÃºp mÃ¬nh vá»›i áº¡ğŸ˜¢,Hiá»‡n mÃ¬nh Ä‘ang lÃ m theo hÆ°á»›ng dáº«n sá»­ dá»¥ng deepspeech Ä‘á»ƒ lÃ m NLP vÃ  mÃ¬nh lÃ m trÃªn gg colab nhÆ°ng khi mÃ¬nh lÃ m tá»›i hÆ°á»›ng dáº«n pre-train model Ä‘oáº¡n docker file thÃ¬ bá»‹ lá»—i nhÆ° váº§y cÃ¡c bÃ¡c cÃ³ ai biáº¿t cÃ¡ch fix khÃ´ng giÃºp mÃ¬nh vá»›i áº¡,,,,,
"Em lÃ  newbie má»›i tÃ¬m hiá»ƒu DL áº¡. Em cÅ©ng táº­p tÃ nh Ä‘Æ°á»£c vÃ i model cÆ¡ báº£n, em muá»‘n há»i :
Náº¿u dÃ¹ng classifi model Ä‘á»ƒ quyáº¿t Ä‘á»‹nh viá»‡c xuá»‘ng tay trong cá»• phiáº¿u dá»±a vÃ o nhá»¯ng data nÃ o( dáº¥u hiá»‡u) Ä‘á»ƒ hiá»‡u quáº£ cao nháº¥t áº¡.
Náº¿u classifi model k hiá»‡u quáº£ thÃ¬ nÃªn dÃ¹ng model nÃ o?","Em lÃ  newbie má»›i tÃ¬m hiá»ƒu DL áº¡. Em cÅ©ng táº­p tÃ nh Ä‘Æ°á»£c vÃ i model cÆ¡ báº£n, em muá»‘n há»i : Náº¿u dÃ¹ng classifi model Ä‘á»ƒ quyáº¿t Ä‘á»‹nh viá»‡c xuá»‘ng tay trong cá»• phiáº¿u dá»±a vÃ o nhá»¯ng data nÃ o( dáº¥u hiá»‡u) Ä‘á»ƒ hiá»‡u quáº£ cao nháº¥t áº¡. Náº¿u classifi model k hiá»‡u quáº£ thÃ¬ nÃªn dÃ¹ng model nÃ o?",,,,,
Má»i ngÆ°á»i Ä‘Ã£ ai mua Ä‘á»c cuá»‘n nÃ y chÆ°a áº¡? Em lÃ  ngÆ°á»i má»›i thÃ¬ nÃªn Ä‘á»c cuá»‘n nÃ o áº¡?,Má»i ngÆ°á»i Ä‘Ã£ ai mua Ä‘á»c cuá»‘n nÃ y chÆ°a áº¡? Em lÃ  ngÆ°á»i má»›i thÃ¬ nÃªn Ä‘á»c cuá»‘n nÃ o áº¡?,,,,,
"Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» dá»‹ch thá»§ ngá»¯ tiáº¿ng Viá»‡t sang speech(video->text->speech), mn cho em há»i khÃ´ng biáº¿t VN cÃ³ dataset thá»§ ngá»¯ nhÆ° ASL khÃ´ng áº¡? em cáº£m Æ¡n mn!!","Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» dá»‹ch thá»§ ngá»¯ tiáº¿ng Viá»‡t sang speech(video->text->speech), mn cho em há»i khÃ´ng biáº¿t VN cÃ³ dataset thá»§ ngá»¯ nhÆ° ASL khÃ´ng áº¡? em cáº£m Æ¡n mn!!",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ 1 váº¥n Ä‘á» chÆ°a Ä‘Æ°á»£c thÃ´ng suá»‘t vÃ  khÃ´ng biáº¿t mÃ¬nh hiá»ƒu Ä‘Ãºng vá» Anchor Box trong YOLO khÃ´ng, mong anh chá»‹ xÃ¡c nháº­n giÃºp em.
Theo em hiá»ƒu lÃ  anchor box lÃ  nhá»¯ng box cÃ³ kÃ­ch thÆ°á»›c Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c (cÃ³ thá»ƒ dÃ¹ng k-mean Ä‘á»ƒ xÃ¡c Ä‘á»‹nh).
VÃ­ dá»¥ mÃ´ hÃ¬nh sá»­ dá»¥ng 5 anchor boxes, thÃ¬ y dá»± Ä‘oÃ¡n (hay cÃ²n gá»i lÃ  y hat) cá»§a 1 grid cell lÃ  5*(5 + c) pháº§n tá»­, giÃ¡ trá»‹ y thá»±c táº¿ cá»§a tá»«ng grid cell Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh dá»±a trÃªn ground truth cá»§a áº£nh vÃ  káº¿t há»£p vá»›i cÃ¡c anchor boxes Ä‘á»ƒ sáº¯p xáº¿p thÃ nh 1 vector y cÃ³ kÃ­ch thÆ°á»›c lÃ  5*(5 + c) pháº£i k áº¡, vÃ­ dá»¥ grid cell thá»© i cÃ³ 1 object cÃ³ kÃ­ch thÆ°á»›c á»©ng vá»›i anchor box thá»© 4, thÃ¬ tháº¿ giÃ¡ trá»‹ label object Ä‘Ã³ vÃ o box thá»© 4 cá»§a y, cÃ²n cÃ¡c thÃ´ng sá»‘ cÃ¡c boxes cÃ²n láº¡i trong y lÃ  cÃ³ pc = 0 lÃ  Ä‘Æ°á»£c. VÃ  anchor box chá»‰ há»— trá»£ trong quÃ¡ trÃ¬nh training, cÃ²n quÃ¡ trÃ¬nh test thÃ¬ k liÃªn quan Ä‘áº¿n anchor box.
Em cÅ©ng Ä‘á»c nhiá»u tÃ i liá»‡u rá»“i nhÆ°ng khÃ´ng biáº¿t em cÃ³ hiá»ƒu sai khÃ´ng, mong anh chá»‹ xÃ¡c nháº­n giÃºp em vá»›i, hoáº·c cho em xin documents vá» anchor box vá»›i áº¡. Em cáº£m Æ¡n ráº¥t nhiá»u.","ChÃ o má»i ngÆ°á»i, em Ä‘ang cÃ³ 1 váº¥n Ä‘á» chÆ°a Ä‘Æ°á»£c thÃ´ng suá»‘t vÃ  khÃ´ng biáº¿t mÃ¬nh hiá»ƒu Ä‘Ãºng vá» Anchor Box trong YOLO khÃ´ng, mong anh chá»‹ xÃ¡c nháº­n giÃºp em. Theo em hiá»ƒu lÃ  anchor box lÃ  nhá»¯ng box cÃ³ kÃ­ch thÆ°á»›c Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c (cÃ³ thá»ƒ dÃ¹ng k-mean Ä‘á»ƒ xÃ¡c Ä‘á»‹nh). VÃ­ dá»¥ mÃ´ hÃ¬nh sá»­ dá»¥ng 5 anchor boxes, thÃ¬ y dá»± Ä‘oÃ¡n (hay cÃ²n gá»i lÃ  y hat) cá»§a 1 grid cell lÃ  5*(5 + c) pháº§n tá»­, giÃ¡ trá»‹ y thá»±c táº¿ cá»§a tá»«ng grid cell Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh dá»±a trÃªn ground truth cá»§a áº£nh vÃ  káº¿t há»£p vá»›i cÃ¡c anchor boxes Ä‘á»ƒ sáº¯p xáº¿p thÃ nh 1 vector y cÃ³ kÃ­ch thÆ°á»›c lÃ  5*(5 + c) pháº£i k áº¡, vÃ­ dá»¥ grid cell thá»© i cÃ³ 1 object cÃ³ kÃ­ch thÆ°á»›c á»©ng vá»›i anchor box thá»© 4, thÃ¬ tháº¿ giÃ¡ trá»‹ label object Ä‘Ã³ vÃ o box thá»© 4 cá»§a y, cÃ²n cÃ¡c thÃ´ng sá»‘ cÃ¡c boxes cÃ²n láº¡i trong y lÃ  cÃ³ pc = 0 lÃ  Ä‘Æ°á»£c. VÃ  anchor box chá»‰ há»— trá»£ trong quÃ¡ trÃ¬nh training, cÃ²n quÃ¡ trÃ¬nh test thÃ¬ k liÃªn quan Ä‘áº¿n anchor box. Em cÅ©ng Ä‘á»c nhiá»u tÃ i liá»‡u rá»“i nhÆ°ng khÃ´ng biáº¿t em cÃ³ hiá»ƒu sai khÃ´ng, mong anh chá»‹ xÃ¡c nháº­n giÃºp em vá»›i, hoáº·c cho em xin documents vá» anchor box vá»›i áº¡. Em cáº£m Æ¡n ráº¥t nhiá»u.",,,,,
"[Dá»± Ã¡n AI lÃ m thÆ¡ lá»¥c bÃ¡t ]
Nháº±m phÃ¡t triá»ƒn thÆ¡ lá»¥c bÃ¡t, dá»± Ã¡n â€œailamthoâ€ Ä‘ang Ä‘Æ°á»£c FPT Software AI Lab há»— trá»£ phÃ¡t triá»ƒn giÃºp sinh thÆ¡ lá»¥c bÃ¡t tá»± Ä‘á»™ng nhá» trÃ­ tuá»‡ nhÃ¢n táº¡o. Khá»Ÿi nguá»“n lÃ  chá»‰ lÃ  má»™t project cuá»‘i ká»³ táº¡i AI for Everyone (AI4E) vá»›i sá»± háº¡n cháº¿ vá» dá»¯ liá»‡u cÅ©ng nhÆ° ká»¹ thuáº­t thá»±c hiá»‡n, Ä‘áº¿n nay chÃºng tÃ´i Ä‘Ã£ cÃ³ báº£n release beta cho cá»™ng Ä‘á»“ng kiá»ƒm thá»­ vÃ  Ä‘Ã³ng gÃ³p bao gá»“m cÃ¡c tÃ­nh nÄƒng ná»•i báº­t sau Ä‘Ã¢y:
1. Gá»£i Ã½ lÃ m thÆ¡: Khi ngÆ°á»i dÃ¹ng lÃ m thÆ¡, AI sáº½ Ä‘Æ°a ra cÃ¡c option gá»£i Ã½ Ä‘á»ƒ hoÃ n thiá»‡n cÃ¢u thÆ¡ hiá»‡n táº¡i, tá»« Ä‘Ã³ sáº½ giÃºp ngÆ°á»i dÃ¹ng hoÃ n thiá»‡n bÃ i thÆ¡ dá»… hÆ¡n.
2. Sinh thÆ¡ tá»± Ä‘á»™ng tá»« má»™t tá»«/cá»¥m tá»« cho trÆ°á»›c: NgÆ°á»i dÃ¹ng nháº­p má»™t tá»«/cá»¥m tá»« (tá»‘i Ä‘a 6 tá»«), AI sáº½ sinh ra bÃ i thÆ¡ lá»¥c bÃ¡t hoÃ n thiá»‡n.
3. Sinh thÆ¡ theo chá»§ Ä‘á»: NgÆ°á»i dÃ¹ng chá»n má»™t trong cÃ¡c chá»§ Ä‘á» cÃ³ trong danh sÃ¡ch vÃ  nháº­p má»™t vÃ i tá»« má»Ÿ Ä‘áº§u AI sáº½ sinh ra bÃ i thÆ¡ trÃªn ná»n chá»§ Ä‘á» áº¥y.
4. Äá»‘i thÆ¡: ngÆ°á»i dÃ¹ng nháº­p má»™t cÃ¢u thÆ¡, AI sáº½ Ä‘á»‘i láº¡i má»™t cÃ¢u thÆ¡.
Chi tiáº¿t vá» sáº£n pháº©m má»i ngÆ°á»i xem á»Ÿ Ä‘Ã¢y: https://ailamtho.com/.","[Dá»± Ã¡n AI lÃ m thÆ¡ lá»¥c bÃ¡t ] Nháº±m phÃ¡t triá»ƒn thÆ¡ lá»¥c bÃ¡t, dá»± Ã¡n â€œailamthoâ€ Ä‘ang Ä‘Æ°á»£c FPT Software AI Lab há»— trá»£ phÃ¡t triá»ƒn giÃºp sinh thÆ¡ lá»¥c bÃ¡t tá»± Ä‘á»™ng nhá» trÃ­ tuá»‡ nhÃ¢n táº¡o. Khá»Ÿi nguá»“n lÃ  chá»‰ lÃ  má»™t project cuá»‘i ká»³ táº¡i AI for Everyone (AI4E) vá»›i sá»± háº¡n cháº¿ vá» dá»¯ liá»‡u cÅ©ng nhÆ° ká»¹ thuáº­t thá»±c hiá»‡n, Ä‘áº¿n nay chÃºng tÃ´i Ä‘Ã£ cÃ³ báº£n release beta cho cá»™ng Ä‘á»“ng kiá»ƒm thá»­ vÃ  Ä‘Ã³ng gÃ³p bao gá»“m cÃ¡c tÃ­nh nÄƒng ná»•i báº­t sau Ä‘Ã¢y: 1. Gá»£i Ã½ lÃ m thÆ¡: Khi ngÆ°á»i dÃ¹ng lÃ m thÆ¡, AI sáº½ Ä‘Æ°a ra cÃ¡c option gá»£i Ã½ Ä‘á»ƒ hoÃ n thiá»‡n cÃ¢u thÆ¡ hiá»‡n táº¡i, tá»« Ä‘Ã³ sáº½ giÃºp ngÆ°á»i dÃ¹ng hoÃ n thiá»‡n bÃ i thÆ¡ dá»… hÆ¡n. 2. Sinh thÆ¡ tá»± Ä‘á»™ng tá»« má»™t tá»«/cá»¥m tá»« cho trÆ°á»›c: NgÆ°á»i dÃ¹ng nháº­p má»™t tá»«/cá»¥m tá»« (tá»‘i Ä‘a 6 tá»«), AI sáº½ sinh ra bÃ i thÆ¡ lá»¥c bÃ¡t hoÃ n thiá»‡n. 3. Sinh thÆ¡ theo chá»§ Ä‘á»: NgÆ°á»i dÃ¹ng chá»n má»™t trong cÃ¡c chá»§ Ä‘á» cÃ³ trong danh sÃ¡ch vÃ  nháº­p má»™t vÃ i tá»« má»Ÿ Ä‘áº§u AI sáº½ sinh ra bÃ i thÆ¡ trÃªn ná»n chá»§ Ä‘á» áº¥y. 4. Äá»‘i thÆ¡: ngÆ°á»i dÃ¹ng nháº­p má»™t cÃ¢u thÆ¡, AI sáº½ Ä‘á»‘i láº¡i má»™t cÃ¢u thÆ¡. Chi tiáº¿t vá» sáº£n pháº©m má»i ngÆ°á»i xem á»Ÿ Ä‘Ã¢y: https://ailamtho.com/.",,,,,
Chia sáº» Ä‘áº¿n cÃ¡c báº¡n cÃ´ng cá»¥ táº¡o lá»™ trÃ¬nh há»c Machine learning chuyÃªn biá»‡t phÃ¹ há»£p vá»›i nÄƒng lá»±c cá»§a tá»«ng ngÆ°á»i ^^,Chia sáº» Ä‘áº¿n cÃ¡c báº¡n cÃ´ng cá»¥ táº¡o lá»™ trÃ¬nh há»c Machine learning chuyÃªn biá»‡t phÃ¹ há»£p vá»›i nÄƒng lá»±c cá»§a tá»«ng ngÆ°á»i ^^,,,,,
Má»™t comment cá»§a KhÃ¡nh ÄÃ¬nh Pháº¡m Ä‘ang nháº­n Ä‘Æ°á»£c ráº¥t nhiá»u quan tÃ¢m. MÃ¬nh táº¡o má»™t thread riÃªng Ä‘á»ƒ má»i ngÆ°á»i tháº£o luáº­n.,Má»™t comment cá»§a KhÃ¡nh ÄÃ¬nh Pháº¡m Ä‘ang nháº­n Ä‘Æ°á»£c ráº¥t nhiá»u quan tÃ¢m. MÃ¬nh táº¡o má»™t thread riÃªng Ä‘á»ƒ má»i ngÆ°á»i tháº£o luáº­n.,,,,,
"Playlist giá»›i thiá»‡u vá» Colab cho báº¡n nÃ o má»›i dÃ¹ng. Ná»™i dung bao gá»“m: Ä‘á»‹nh dáº¡ng vÄƒn báº£n, lÆ°u vÃ  má»Ÿ file trong Colab, command line, tÆ°Æ¡ng tÃ¡c vá»›i google drive, xuáº¥t notebook sang html, latex, pdf,....","Playlist giá»›i thiá»‡u vá» Colab cho báº¡n nÃ o má»›i dÃ¹ng. Ná»™i dung bao gá»“m: Ä‘á»‹nh dáº¡ng vÄƒn báº£n, lÆ°u vÃ  má»Ÿ file trong Colab, command line, tÆ°Æ¡ng tÃ¡c vá»›i google drive, xuáº¥t notebook sang html, latex, pdf,....",,,,,
"Má»™t bÃ i viáº¿t nho nhá» phÃ¢n tÃ­ch cÃ¡c khÃ­a cáº¡nh giá»¯a suy diá»…n Frequentist vÃ  Bayesian. Sá»± khÃ¡c biá»‡t giá»¯a MLE vÃ  MAP vÃ  á»©ng dá»¥ng cá»§a cÃ´ng thá»©c Bayes trong mÃ´ hÃ¬nh Naive Bayes. Mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a báº¡n Ä‘á»c theo Ä‘á»‹a chá»‰ bÃªn dÆ°á»›i Ä‘á»ƒ hoÃ n thiá»‡n thÃªm ná»™i dung:
email: aikhanhblog@gmail.com
facebook: https://www.facebook.com/langnhin.anhtrang/
VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n. Fighting!",Má»™t bÃ i viáº¿t nho nhá» phÃ¢n tÃ­ch cÃ¡c khÃ­a cáº¡nh giá»¯a suy diá»…n Frequentist vÃ  Bayesian. Sá»± khÃ¡c biá»‡t giá»¯a MLE vÃ  MAP vÃ  á»©ng dá»¥ng cá»§a cÃ´ng thá»©c Bayes trong mÃ´ hÃ¬nh Naive Bayes. Mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a báº¡n Ä‘á»c theo Ä‘á»‹a chá»‰ bÃªn dÆ°á»›i Ä‘á»ƒ hoÃ n thiá»‡n thÃªm ná»™i dung: email: aikhanhblog@gmail.com facebook: https://www.facebook.com/langnhin.anhtrang/ VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n. Fighting!,,,,,
"[Há»i vá» tÃ i liá»‡u]
ChÃ o má»i ngÆ°á»i, em cÃ³ dá»± Ä‘á»‹nh há»c theo hÆ°á»›ng research nhiá»u hÆ¡n lÃ  engineer nÃªn em muá»‘n há»i lÃ  ngoÃ i khÃ³a há»c cá»§a tháº§y Andrew Ng, má»i ngÆ°á»i cho em xin thÃªm vÃ i khÃ³a khÃ¡c vá» ML, DL mÃ  há» dáº¡y sÃ¢u vÃ o lÃ½ thuyáº¿t chá»© ko táº­p trung vÃ o sáº£n pháº©m thá»±c táº¿ vá»›i áº¡.
Vá»›i láº¡i theo kinh nghiá»‡m má»i ngÆ°á»i thÃ¬ Ä‘á»ƒ há»c tá»‘t theo hÆ°á»›ng research, thÃ¬ em cÃ³ nÃªn há»c nhiá»u khÃ³a vá» lÃ½ thuyáº¿t hÆ¡n khÃ´ng hay chá»‰ cáº§n náº¯m Ä‘Æ°á»£c khÃ³a cá»§a Andrew Ng vÃ  sÃ¡ch cá»§a anh Tiá»‡p lÃ  Ä‘á»§, vÃ  dÃ nh thá»i gian Ä‘Ã³ Ä‘á»ƒ táº­p trung vÃ o cÃ¡i khÃ¡c áº¡?
Em chÆ°a cÃ³ nhiá»u kinh nghiá»‡m nÃªn náº¿u cÃ¢u há»i cá»§a em cÃ³ gÃ¬ sai sÃ³t mong má»i ngÆ°á»i bá» qua vÃ  chá»‰ báº£o em áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","[Há»i vá» tÃ i liá»‡u] ChÃ o má»i ngÆ°á»i, em cÃ³ dá»± Ä‘á»‹nh há»c theo hÆ°á»›ng research nhiá»u hÆ¡n lÃ  engineer nÃªn em muá»‘n há»i lÃ  ngoÃ i khÃ³a há»c cá»§a tháº§y Andrew Ng, má»i ngÆ°á»i cho em xin thÃªm vÃ i khÃ³a khÃ¡c vá» ML, DL mÃ  há» dáº¡y sÃ¢u vÃ o lÃ½ thuyáº¿t chá»© ko táº­p trung vÃ o sáº£n pháº©m thá»±c táº¿ vá»›i áº¡. Vá»›i láº¡i theo kinh nghiá»‡m má»i ngÆ°á»i thÃ¬ Ä‘á»ƒ há»c tá»‘t theo hÆ°á»›ng research, thÃ¬ em cÃ³ nÃªn há»c nhiá»u khÃ³a vá» lÃ½ thuyáº¿t hÆ¡n khÃ´ng hay chá»‰ cáº§n náº¯m Ä‘Æ°á»£c khÃ³a cá»§a Andrew Ng vÃ  sÃ¡ch cá»§a anh Tiá»‡p lÃ  Ä‘á»§, vÃ  dÃ nh thá»i gian Ä‘Ã³ Ä‘á»ƒ táº­p trung vÃ o cÃ¡i khÃ¡c áº¡? Em chÆ°a cÃ³ nhiá»u kinh nghiá»‡m nÃªn náº¿u cÃ¢u há»i cá»§a em cÃ³ gÃ¬ sai sÃ³t mong má»i ngÆ°á»i bá» qua vÃ  chá»‰ báº£o em áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
"Má»i ngÆ°á»i cho em há»i váº½ cÃ¡i bounding box quanh text nhÆ° nÃ y lÃ  mÃ¬nh dÃ¹ng thuáº­t toÃ¡n gÃ¬ áº¡?
Em cÃ³ nghe nÃ³i Ä‘áº¿n EAST, EAST lÃ  mÃ¬nh gá»i model cá»§a tÃ¡c giáº£ rá»“i dÃ¹ng, ko cáº§n tráº£i qua quÃ¡ trÃ¬nh train Ä‘Ãºng ko áº¡? Tháº¿ em muá»‘n báº¯t Ä‘áº§u xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh, tráº£i qua quÃ¡ trÃ¬nh train má»›i dá»± Ä‘oÃ¡n Ä‘Æ°á»£c, thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á» xuáº¥t cho em vÃ i thuáº­t toÃ¡n vÃ  keyword Ä‘Æ°á»£c ko áº¡?
Em cáº£m Æ¡n mn.
PS: Náº¿u cÃ³ há»i ngu gÃ¬ mong má»i ngÆ°á»i chá»‰ báº£o, Ä‘á»«ng chá»­i em nhÃ©!!","Má»i ngÆ°á»i cho em há»i váº½ cÃ¡i bounding box quanh text nhÆ° nÃ y lÃ  mÃ¬nh dÃ¹ng thuáº­t toÃ¡n gÃ¬ áº¡? Em cÃ³ nghe nÃ³i Ä‘áº¿n EAST, EAST lÃ  mÃ¬nh gá»i model cá»§a tÃ¡c giáº£ rá»“i dÃ¹ng, ko cáº§n tráº£i qua quÃ¡ trÃ¬nh train Ä‘Ãºng ko áº¡? Tháº¿ em muá»‘n báº¯t Ä‘áº§u xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh, tráº£i qua quÃ¡ trÃ¬nh train má»›i dá»± Ä‘oÃ¡n Ä‘Æ°á»£c, thÃ¬ má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á» xuáº¥t cho em vÃ i thuáº­t toÃ¡n vÃ  keyword Ä‘Æ°á»£c ko áº¡? Em cáº£m Æ¡n mn. PS: Náº¿u cÃ³ há»i ngu gÃ¬ mong má»i ngÆ°á»i chá»‰ báº£o, Ä‘á»«ng chá»­i em nhÃ©!!",,,,,
"em chÃ o má»i ngÆ°á»i, má»i ngÆ°á»i tháº¥y cÃ¡i nÃ o suy nghÄ© logic nhiá»u hÆ¡n áº¡?","em chÃ o má»i ngÆ°á»i, má»i ngÆ°á»i tháº¥y cÃ¡i nÃ o suy nghÄ© logic nhiá»u hÆ¡n áº¡?",,,,,
"KhÃ³a há»c tá»« University of Michigan:
https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r
NgÆ°á»i dáº¡y khÃ³a nÃ y cÅ©ng chÃ­nh lÃ  má»™t trong nhá»¯ng ngÆ°á»i dáº¡y khÃ³a CS231n cá»§a Standford ngÃ y xÆ°a :3",KhÃ³a há»c tá»« University of Michigan: https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r NgÆ°á»i dáº¡y khÃ³a nÃ y cÅ©ng chÃ­nh lÃ  má»™t trong nhá»¯ng ngÆ°á»i dáº¡y khÃ³a CS231n cá»§a Standford ngÃ y xÆ°a :3,,,,,
"má»i ngÆ°á»i cho em há»i cÃ¡c á»©ng dá»¥ng thay Ä‘á»•i cÃ¡c bá»™ pháº­n trÃªn máº·t ngÆ°á»i báº±ng bá»™ pháº­n con váº­t thÃ¬ há» dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ áº¡?
em cÃ¡m Æ¡n áº¡",má»i ngÆ°á»i cho em há»i cÃ¡c á»©ng dá»¥ng thay Ä‘á»•i cÃ¡c bá»™ pháº­n trÃªn máº·t ngÆ°á»i báº±ng bá»™ pháº­n con váº­t thÃ¬ há» dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ áº¡? em cÃ¡m Æ¡n áº¡,,,,,
"PyScrappy in Python
PyScrappy is an amazing Python library that can be used to collect data from websites like Flipkart, Alibaba, Snapdeal, Instagram, YouTube, Google, Yahoo, Bing, Wikipedia, and Yahoo Finance. It covers all the functions that you can easily use to collect data from websites in just a few lines of code. If you find it difficult to collect data and prepare it in the form of a DataFrame to use the collected data for further analysis then PyScrappy is for you as from collecting data to storing it to a DataFrame it does it all in just a few lines of code.","PyScrappy in Python PyScrappy is an amazing Python library that can be used to collect data from websites like Flipkart, Alibaba, Snapdeal, Instagram, YouTube, Google, Yahoo, Bing, Wikipedia, and Yahoo Finance. It covers all the functions that you can easily use to collect data from websites in just a few lines of code. If you find it difficult to collect data and prepare it in the form of a DataFrame to use the collected data for further analysis then PyScrappy is for you as from collecting data to storing it to a DataFrame it does it all in just a few lines of code.",,,,,
Gáº§n Ä‘Ã¢y cÃ³ má»™t sá»‘ tháº£o luáº­n khÃ¡ sÃ´i ná»•i vá» váº¥n Ä‘á» overfitting. Hy vá»ng bÃ i viáº¿t sau cá»§a Trung tÃ¢m BK.AI sáº½ giá»›i thiá»‡u thÃªm cho cÃ¡c báº¡n sinh viÃªn má»™t sá»‘ gÃ³c nhÃ¬n má»›i hiá»‡n Ä‘áº¡i vá» há»c mÃ¡y nÃ³i chung vÃ  máº¡ng nÆ¡-ron nÃ³i riÃªng.,Gáº§n Ä‘Ã¢y cÃ³ má»™t sá»‘ tháº£o luáº­n khÃ¡ sÃ´i ná»•i vá» váº¥n Ä‘á» overfitting. Hy vá»ng bÃ i viáº¿t sau cá»§a Trung tÃ¢m BK.AI sáº½ giá»›i thiá»‡u thÃªm cho cÃ¡c báº¡n sinh viÃªn má»™t sá»‘ gÃ³c nhÃ¬n má»›i hiá»‡n Ä‘áº¡i vá» há»c mÃ¡y nÃ³i chung vÃ  máº¡ng nÆ¡-ron nÃ³i riÃªng.,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡ !
Em Ä‘ang tÃ¬m hiá»ƒu vá» toolbox ANN trÃªn matlab
Em khÃ´ng hiá»ƒu vá» cÃ¡c giÃ¡ trá»‹ báº£ng nÃ y áº¡ vÃ  hiá»‡u chá»‰nh nÃ³ nhÆ° tháº¿ nÃ o Ä‘á»ƒ mÃ´ hÃ¬nh tá»‘t áº¡
VÃ  cÃ¡i "" goal "" cÃ³ pháº£i learning rate ko áº¡ , e tháº¥y tÄƒng lÃªn thÃ¬ mÃ´ hÃ¬nh khÃ¡ tá»‘t áº¡ ?
EM cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp áº¡","Em chÃ o má»i ngÆ°á»i áº¡ ! Em Ä‘ang tÃ¬m hiá»ƒu vá» toolbox ANN trÃªn matlab Em khÃ´ng hiá»ƒu vá» cÃ¡c giÃ¡ trá»‹ báº£ng nÃ y áº¡ vÃ  hiá»‡u chá»‰nh nÃ³ nhÆ° tháº¿ nÃ o Ä‘á»ƒ mÃ´ hÃ¬nh tá»‘t áº¡ VÃ  cÃ¡i "" goal "" cÃ³ pháº£i learning rate ko áº¡ , e tháº¥y tÄƒng lÃªn thÃ¬ mÃ´ hÃ¬nh khÃ¡ tá»‘t áº¡ ? EM cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp áº¡",,,,,
"HÃ´m trÆ°á»›c team mÃ¬nh cÃ¹ng Nguyá»…n QuÃ¡n Anh Minh vá»«a win cuá»™c thi Coleridge Initiative - Show US the Data cá»§a Kaggle. ÄÃ¢y lÃ  bÃ i toÃ¡n text extraction nhÆ°ng cÃ³ 1 sá»‘ Ä‘iá»ƒm Ä‘áº·c biá»‡t lÃ  lÆ°á»£ng unique label cá»±c ká»³ khan hiáº¿m vÃ  buá»™c pháº£i dá»±a vÃ o context xung quanh Ä‘á»ƒ trÃ­ch láº¥y ná»™i dung.
Team mÃ¬nh Ä‘Ã£ Ä‘Æ°a ra 2 solution hoÃ n toÃ n khÃ¡c nhau nhÆ°ng Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng tÆ°Æ¡ng Ä‘á»‘i xÃªm xÃªm, náº±m á»Ÿ táº§m top 1 - top 3 private leaderboard.
ÄÃ¢y lÃ  solution cá»§a Minh dÃ¹ng metric learning https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/248253
CÃ²n Ä‘Ã¢y lÃ  version cá»§a mÃ¬nh dÃ¹ng Causal Language Model
https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/248251
Má»i má»i ngÆ°á»i tham kháº£o.","HÃ´m trÆ°á»›c team mÃ¬nh cÃ¹ng Nguyá»…n QuÃ¡n Anh Minh vá»«a win cuá»™c thi Coleridge Initiative - Show US the Data cá»§a Kaggle. ÄÃ¢y lÃ  bÃ i toÃ¡n text extraction nhÆ°ng cÃ³ 1 sá»‘ Ä‘iá»ƒm Ä‘áº·c biá»‡t lÃ  lÆ°á»£ng unique label cá»±c ká»³ khan hiáº¿m vÃ  buá»™c pháº£i dá»±a vÃ o context xung quanh Ä‘á»ƒ trÃ­ch láº¥y ná»™i dung. Team mÃ¬nh Ä‘Ã£ Ä‘Æ°a ra 2 solution hoÃ n toÃ n khÃ¡c nhau nhÆ°ng Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng tÆ°Æ¡ng Ä‘á»‘i xÃªm xÃªm, náº±m á»Ÿ táº§m top 1 - top 3 private leaderboard. ÄÃ¢y lÃ  solution cá»§a Minh dÃ¹ng metric learning https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/248253 CÃ²n Ä‘Ã¢y lÃ  version cá»§a mÃ¬nh dÃ¹ng Causal Language Model https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/discussion/248251 Má»i má»i ngÆ°á»i tham kháº£o.",,,,,
"Cáº£ nhÃ  cho mÃ¬nh há»i má»™t chÃºt. MÃ¬nh cáº§n OCR sá»‘ lÆ°á»£ng lá»›n check (sÃ©c ngÃ¢n hÃ ng) Tiáº¿ng Anh cáº£ chá»¯ in vÃ  chá»¯ viáº¿t tay. Theo kinh nghiá»‡m cá»§a cÃ¡c báº¡n, Python libraries nÃ o dÃ¹ng tá»‘t? Báº¡n thÃ­ch vÃ  khÃ´ng thÃ­ch Ä‘iá»ƒm gÃ¬ nháº¥t?
Cáº£m Æ¡n cáº£ nhÃ  nhiá»u nhÃ©!","Cáº£ nhÃ  cho mÃ¬nh há»i má»™t chÃºt. MÃ¬nh cáº§n OCR sá»‘ lÆ°á»£ng lá»›n check (sÃ©c ngÃ¢n hÃ ng) Tiáº¿ng Anh cáº£ chá»¯ in vÃ  chá»¯ viáº¿t tay. Theo kinh nghiá»‡m cá»§a cÃ¡c báº¡n, Python libraries nÃ o dÃ¹ng tá»‘t? Báº¡n thÃ­ch vÃ  khÃ´ng thÃ­ch Ä‘iá»ƒm gÃ¬ nháº¥t? Cáº£m Æ¡n cáº£ nhÃ  nhiá»u nhÃ©!",,,,,
Cho mÃ¬nh há»i lÃ  mÃ¬nh muá»‘n sá»­ dá»¥ng deepspeech model Ä‘á»ƒ train NLP. MÃ¬nh má»›i tÃ¬m hiá»ƒu nÃªn chÆ°a rÃ nh láº¯m cho mÃ¬nh há»i mÃ¡y mÃ¬nh khÃ´ng cÃ³ gpu thÃ¬ cÃ³ cÃ¡ch nÃ o train trÃªn gooogle collab hay train khÃ´ng cáº§n gpu khÃ´ng cÃ¡c bÃ¡c. MÃ¬nh cáº£m Æ¡n!,Cho mÃ¬nh há»i lÃ  mÃ¬nh muá»‘n sá»­ dá»¥ng deepspeech model Ä‘á»ƒ train NLP. MÃ¬nh má»›i tÃ¬m hiá»ƒu nÃªn chÆ°a rÃ nh láº¯m cho mÃ¬nh há»i mÃ¡y mÃ¬nh khÃ´ng cÃ³ gpu thÃ¬ cÃ³ cÃ¡ch nÃ o train trÃªn gooogle collab hay train khÃ´ng cáº§n gpu khÃ´ng cÃ¡c bÃ¡c. MÃ¬nh cáº£m Æ¡n!,,,,,
"ChÃ o má»i ngÆ°á»i!
Em má»›i há»c vá» ML vÃ  Ä‘ang xÃ¢y dá»±ng cho mÃ¬nh mÃ´ hÃ¬nh há»c mÃ¡y Ä‘áº§u tiÃªn lÃ  mÃ´ hÃ¬nh Naive Bayes. VÃ  em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ viá»‡c, láº¥y log cá»§a hÃ m Gaussian Naive Bayes.
Má»i ngÆ°á»i cho em há»i lÃ  vá»›i vÃ­ dá»¥ cá»¥ thá»ƒ bÃªn dÆ°á»›i, thi khi láº¥y log, hÃ m P(a|x) sáº½ Ä‘Æ°á»£c triá»ƒn khai nhÆ° tháº¿ nÃ o ? Em láº¥y log rá»“i Ã¡p dá»¥ng theo cÃ´ng thá»©c log thÃ¬ cÃ³ váº» sai vÃ¬ mÃ´ hÃ¬nh cá»§a em bá»‹ Overfitting.
Cáº£m Æ¡n má»i ngÆ°á»i.
Edit: GiÃ¡ trá»‹ cá»§a cÃ¡c xÃ¡c suáº¥t tÃ­nh ra ráº¥t nhá» em nÃªn láº¥y log Ä‘á»ƒ dá»… tÃ­nh toÃ¡n.","ChÃ o má»i ngÆ°á»i! Em má»›i há»c vá» ML vÃ  Ä‘ang xÃ¢y dá»±ng cho mÃ¬nh mÃ´ hÃ¬nh há»c mÃ¡y Ä‘áº§u tiÃªn lÃ  mÃ´ hÃ¬nh Naive Bayes. VÃ  em Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ viá»‡c, láº¥y log cá»§a hÃ m Gaussian Naive Bayes. Má»i ngÆ°á»i cho em há»i lÃ  vá»›i vÃ­ dá»¥ cá»¥ thá»ƒ bÃªn dÆ°á»›i, thi khi láº¥y log, hÃ m P(a|x) sáº½ Ä‘Æ°á»£c triá»ƒn khai nhÆ° tháº¿ nÃ o ? Em láº¥y log rá»“i Ã¡p dá»¥ng theo cÃ´ng thá»©c log thÃ¬ cÃ³ váº» sai vÃ¬ mÃ´ hÃ¬nh cá»§a em bá»‹ Overfitting. Cáº£m Æ¡n má»i ngÆ°á»i. Edit: GiÃ¡ trá»‹ cá»§a cÃ¡c xÃ¡c suáº¥t tÃ­nh ra ráº¥t nhá» em nÃªn láº¥y log Ä‘á»ƒ dá»… tÃ­nh toÃ¡n.",,,,,
"Dá»± Ã¡n Ä‘ang á»Ÿ giai Ä‘oáº¡n gáº¥p rÃºt, ráº¥t mong AE cÃ¹ng Ä‘Ã³ng gÃ³p dá»¯ liá»‡u. Äáº·c biá»‡t, náº¿u cÃ¡c báº¡n biáº¿t ai cÃ³ F0, mong cÃ¡c báº¡n gá»­i link website Ä‘á»ƒ cÃ¡c báº¡n áº¥y giÃºp sá»©c chá»‘ng dá»‹ch. 

CÃ¡c lá»£i Ã­ch cá»§a viá»‡c Ä‘Ã³ng gÃ³p nhÆ° sau:
Náº¿u báº¡n Ä‘ang khoáº» máº¡nh, hÃ£y ho hÃ ng ngÃ y Ä‘á»ƒ Ä‘Æ°á»£c há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ báº¥t thÆ°á»ng qua tiáº¿ng ho, dá»±a vÃ o dá»¯ liá»‡u tiáº¿ng ho hÃ ng ngÃ y cá»§a báº¡n. Há»‡ thá»‘ng Ä‘ang Ä‘Æ°á»£c hoÃ n thiá»‡n, nhÆ°ng cÃ¡c báº¡n Ä‘Ã£ cÃ³ thá»ƒ record dá»¯ liá»‡u ngay bÃ¢y giá».
Náº¿u báº¡n cÃ³ F0, hÃ£y *QuyÃªn gÃ³p tiáº¿ng ho* Ä‘á»ƒ há»‡ thá»‘ng chuáº©n Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n cho ngÆ°á»i Viá»‡t, giÃºp khoanh vÃ¹ng á»• dá»‹ch tá»‘t hÆ¡n, vÃ  giÃºp nhá»¯ng ai Ä‘ang nghi ngá» mÃ¬nh cÃ³ COVID cÃ³ cÄƒn cá»© tá»‘t hÆ¡n Ä‘á»ƒ tÄƒng giÃ£n cÃ¡ch xÃ£ há»™i má»™t cÃ¡ch chá»§ Ä‘á»™ng.

Äá»ƒ quyÃªn gÃ³p tiáº¿ng ho, cÃ¡c báº¡n vui lÃ²ng truy cáº­p website: https://tiengho.aicovidvn.org. ","Dá»± Ã¡n Ä‘ang á»Ÿ giai Ä‘oáº¡n gáº¥p rÃºt, ráº¥t mong AE cÃ¹ng Ä‘Ã³ng gÃ³p dá»¯ liá»‡u. Äáº·c biá»‡t, náº¿u cÃ¡c báº¡n biáº¿t ai cÃ³ F0, mong cÃ¡c báº¡n gá»­i link website Ä‘á»ƒ cÃ¡c báº¡n áº¥y giÃºp sá»©c chá»‘ng dá»‹ch. CÃ¡c lá»£i Ã­ch cá»§a viá»‡c Ä‘Ã³ng gÃ³p nhÆ° sau: Náº¿u báº¡n Ä‘ang khoáº» máº¡nh, hÃ£y ho hÃ ng ngÃ y Ä‘á»ƒ Ä‘Æ°á»£c há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ báº¥t thÆ°á»ng qua tiáº¿ng ho, dá»±a vÃ o dá»¯ liá»‡u tiáº¿ng ho hÃ ng ngÃ y cá»§a báº¡n. Há»‡ thá»‘ng Ä‘ang Ä‘Æ°á»£c hoÃ n thiá»‡n, nhÆ°ng cÃ¡c báº¡n Ä‘Ã£ cÃ³ thá»ƒ record dá»¯ liá»‡u ngay bÃ¢y giá». Náº¿u báº¡n cÃ³ F0, hÃ£y *QuyÃªn gÃ³p tiáº¿ng ho* Ä‘á»ƒ há»‡ thá»‘ng chuáº©n Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n cho ngÆ°á»i Viá»‡t, giÃºp khoanh vÃ¹ng á»• dá»‹ch tá»‘t hÆ¡n, vÃ  giÃºp nhá»¯ng ai Ä‘ang nghi ngá» mÃ¬nh cÃ³ COVID cÃ³ cÄƒn cá»© tá»‘t hÆ¡n Ä‘á»ƒ tÄƒng giÃ£n cÃ¡ch xÃ£ há»™i má»™t cÃ¡ch chá»§ Ä‘á»™ng. Äá»ƒ quyÃªn gÃ³p tiáº¿ng ho, cÃ¡c báº¡n vui lÃ²ng truy cáº­p website: https://tiengho.aicovidvn.org.",,,,,
Cho em há»i má»™t váº¥n Ä‘á» vá» cÃ i Ä‘áº·t cuda 10.0 trÃªn nÃªn giáº£ láº­p ubuntu 18.04.5. GPU cá»§a em lÃ  gtx 950 nhÆ°ng khi cÃ i driver cá»§a GPu driver láº¡i cáº­p nháº­t lÃªn Ä‘áº¿n 470 vÃ  khÃ´ng cÃ³ driver 410 Ä‘á»ƒ cháº¡y cuda 10.0 nÃªn. Khi em cÃ i cuda 10.0 tá»« file táº£i vá» thÃ¬ cháº¡y nvidia-smi khÃ´ng nháº­n nÃªn khÃ´ng cÃ i Ä‘Æ°á»£c tensorflow. CÃ³ ai biáº¿t cÃ¡ch fix lá»—i nÃ y khÃ´ng chá»‰ em vá»›i áº¡. Em cáº£m Æ¡n!,Cho em há»i má»™t váº¥n Ä‘á» vá» cÃ i Ä‘áº·t cuda 10.0 trÃªn nÃªn giáº£ láº­p ubuntu 18.04.5. GPU cá»§a em lÃ  gtx 950 nhÆ°ng khi cÃ i driver cá»§a GPu driver láº¡i cáº­p nháº­t lÃªn Ä‘áº¿n 470 vÃ  khÃ´ng cÃ³ driver 410 Ä‘á»ƒ cháº¡y cuda 10.0 nÃªn. Khi em cÃ i cuda 10.0 tá»« file táº£i vá» thÃ¬ cháº¡y nvidia-smi khÃ´ng nháº­n nÃªn khÃ´ng cÃ i Ä‘Æ°á»£c tensorflow. CÃ³ ai biáº¿t cÃ¡ch fix lá»—i nÃ y khÃ´ng chá»‰ em vá»›i áº¡. Em cáº£m Æ¡n!,,,,,
"Em chÃ o má»i ngÆ°á»i. Hiá»‡n em Ä‘ang muá»‘n tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n nháº­n dáº¡ng tiáº¿ng nÃ³i (ASR), em cÃ³ Ä‘á»c má»™t sá»‘ sÃ¡ch nhÆ° HTK book, LVSR, vÃ  Ä‘á»c docs cá»§a kaldi nhÆ°ng khÃ³ quÃ¡ :(. Em muá»‘n tÃ¬m má»™t ngÆ°á»i gia sÆ° cÃ³ kinh nghiá»‡m build model asr báº±ng kaldi hÆ°á»›ng dáº«n em áº¡. Em xin lá»—i náº¿u bÃ i Ä‘Äƒng cá»§a em vi pháº¡m ná»™i quy cá»§a nhÃ³m. Em cáº£m Æ¡n áº¡","Em chÃ o má»i ngÆ°á»i. Hiá»‡n em Ä‘ang muá»‘n tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n nháº­n dáº¡ng tiáº¿ng nÃ³i (ASR), em cÃ³ Ä‘á»c má»™t sá»‘ sÃ¡ch nhÆ° HTK book, LVSR, vÃ  Ä‘á»c docs cá»§a kaldi nhÆ°ng khÃ³ quÃ¡ :(. Em muá»‘n tÃ¬m má»™t ngÆ°á»i gia sÆ° cÃ³ kinh nghiá»‡m build model asr báº±ng kaldi hÆ°á»›ng dáº«n em áº¡. Em xin lá»—i náº¿u bÃ i Ä‘Äƒng cá»§a em vi pháº¡m ná»™i quy cá»§a nhÃ³m. Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o cÃ¡c báº¡n, cÃ¡c anh chá»‹! Xin tá»± giá»›i thiá»‡u mÃ¬nh lÃ  sinh viÃªn nÄƒm cuá»‘i á»Ÿ Pháº§n Lan.
MÃ¬nh vá»«a nháº­n 1 Ä‘á» tÃ i vá» dá»¯ liá»‡u tá»« giÃ¡o viÃªn. YÃªu cáº§u Ä‘á» bÃ i xÃ¢y dá»±ng 1 há»‡ thá»‘ng front-end vÃ  back-end cho data visualization. Platform cÃ³ thá»ƒ sáº½ má»Ÿ rá»™ng, thÃªm tÃ­nh nÄƒng trong tuÆ¡ng lai. Data sáº½ láº¥y tá»« trang http://pxnet2.stat.fi/PXWeb/pxweb/en/StatFin/.
Vá» chi tiáº¿t há»‡ thá»‘ng sáº½ pháº£i tÃ­nh toÃ¡n raw data thu tháº­p Ä‘uá»£c tá»« web trÃªn, sau Ä‘áº¥y ""computed data"" cÃ³ thá»ƒ lÆ°u/cached trÃªn database. Front end thÃ¬ pháº£i cÃ³ ""interactive visualization"", cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c library cÃ³ sáºµn nhÆ° react-vis hoáº·c d3.js
NgÃ´n ngá»¯ thÃ¬ tuá»³ chá»n cho cáº£ front-end vÃ  back-end. Pháº§n front-end cÃ³ thá»ƒ lÃ m tá»‘i giáº£n khÃ´ng cáº§n Ä‘áº§y Ä‘á»§ chi tiáº¿t, chá»‰ cáº§n hiá»ƒn thá»‹ dá»¯ liá»‡u vÃ  tuÆ¡ng tÃ¡c lÃ  Ä‘uá»£c.
MÃ¬nh Ä‘Äƒng lÃªn Ä‘á»ƒ xin lá»i khuyÃªn vÃ  gá»£i Ã½ vá» kinh nghiá»‡m xÃ¢y dá»±ng má»™t há»‡ thá»‘ng nhÆ° trÃªn. Ã tuá»Ÿng cá»§a mÃ¬nh sáº½ lÃ  dÃ¹ng D3.js cho front-end vÃ  typescript + node.js cho backend. NhÆ°ng Javascript k pháº£i tháº¿ máº¡nh cá»§a mÃ¬nh nÃªn mÃ¬nh nÃªn mÃ¬nh há»i cÃ³ thá»ƒ hoÃ n thÃ nh yÃªu cáº§u báº±ng Python Ä‘uá»£c khÃ´ng? MÃ¬nh cÃ³ google vÃ  tháº¥y Dash + plotly nhÆ°ng k biáº¿t náº¿u dÃ¹ng Dash vÃ  plotly thÃ¬ sau nÃ y má»Ÿ rá»™ng platform sáº½ nhÆ° tháº¿ nÃ o? Mong cÃ¡c cao nhÃ¢n cho mÃ¬nh xin Ã½ kiáº¿n áº¡ !
MÃ¬nh cáº£m on!","ChÃ o cÃ¡c báº¡n, cÃ¡c anh chá»‹! Xin tá»± giá»›i thiá»‡u mÃ¬nh lÃ  sinh viÃªn nÄƒm cuá»‘i á»Ÿ Pháº§n Lan. MÃ¬nh vá»«a nháº­n 1 Ä‘á» tÃ i vá» dá»¯ liá»‡u tá»« giÃ¡o viÃªn. YÃªu cáº§u Ä‘á» bÃ i xÃ¢y dá»±ng 1 há»‡ thá»‘ng front-end vÃ  back-end cho data visualization. Platform cÃ³ thá»ƒ sáº½ má»Ÿ rá»™ng, thÃªm tÃ­nh nÄƒng trong tuÆ¡ng lai. Data sáº½ láº¥y tá»« trang http://pxnet2.stat.fi/PXWeb/pxweb/en/StatFin/. Vá» chi tiáº¿t há»‡ thá»‘ng sáº½ pháº£i tÃ­nh toÃ¡n raw data thu tháº­p Ä‘uá»£c tá»« web trÃªn, sau Ä‘áº¥y ""computed data"" cÃ³ thá»ƒ lÆ°u/cached trÃªn database. Front end thÃ¬ pháº£i cÃ³ ""interactive visualization"", cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c library cÃ³ sáºµn nhÆ° react-vis hoáº·c d3.js NgÃ´n ngá»¯ thÃ¬ tuá»³ chá»n cho cáº£ front-end vÃ  back-end. Pháº§n front-end cÃ³ thá»ƒ lÃ m tá»‘i giáº£n khÃ´ng cáº§n Ä‘áº§y Ä‘á»§ chi tiáº¿t, chá»‰ cáº§n hiá»ƒn thá»‹ dá»¯ liá»‡u vÃ  tuÆ¡ng tÃ¡c lÃ  Ä‘uá»£c. MÃ¬nh Ä‘Äƒng lÃªn Ä‘á»ƒ xin lá»i khuyÃªn vÃ  gá»£i Ã½ vá» kinh nghiá»‡m xÃ¢y dá»±ng má»™t há»‡ thá»‘ng nhÆ° trÃªn. Ã tuá»Ÿng cá»§a mÃ¬nh sáº½ lÃ  dÃ¹ng D3.js cho front-end vÃ  typescript + node.js cho backend. NhÆ°ng Javascript k pháº£i tháº¿ máº¡nh cá»§a mÃ¬nh nÃªn mÃ¬nh nÃªn mÃ¬nh há»i cÃ³ thá»ƒ hoÃ n thÃ nh yÃªu cáº§u báº±ng Python Ä‘uá»£c khÃ´ng? MÃ¬nh cÃ³ google vÃ  tháº¥y Dash + plotly nhÆ°ng k biáº¿t náº¿u dÃ¹ng Dash vÃ  plotly thÃ¬ sau nÃ y má»Ÿ rá»™ng platform sáº½ nhÆ° tháº¿ nÃ o? Mong cÃ¡c cao nhÃ¢n cho mÃ¬nh xin Ã½ kiáº¿n áº¡ ! MÃ¬nh cáº£m on!",,,,,
"Xin chÃ o má»i ngÆ°á»i.
Em cÃ³ há»©ng thÃº vÃ  theo há»c máº£ng ml vÃ  ds. Em Ä‘Ã£ Ä‘á»c sÃ¡ch cá»§a a Tiá»‡p vÃ  náº¯m kha khÃ¡ tá»‘t kiáº¿n thá»©c trong sÃ¡ch. Em cÅ©ng Ä‘Ã£ há»c mÃ´n ml á»Ÿ Ä‘áº¡i há»c nhÆ°ng khÃ´ng hiá»‡u quáº£ láº¯m, cÃ´ng thÃªm tÃ¬nh hÃ¬nh dá»‹ch bá»‡nh nhÆ° hiá»‡n táº¡i cÅ©ng lÃ m em khÃ´ng thá»ƒ trá»±c tiáº¿p tham kháº£o tá»« tháº§y cÃ´.
Hiá»‡n táº¡i em Ä‘ang vÃ´ cÃ¹ng mÃ´ng lung khÃ´ng biáº¿t cáº§n há»c thÃªm gÃ¬, thá»±c hÃ nh ra sao hay tiáº¿p tá»¥c nhÆ° nÃ o. VÃ¬ váº­y em hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t hÆ°á»›ng dáº«n hoáº·c lá»™ trÃ¬nh thá»±c sá»± cá»¥ thá»ƒ.
Em khÃ´ng cÃ³ gÃ¬ ngoÃ i thá»i gian áº¡.","Xin chÃ o má»i ngÆ°á»i. Em cÃ³ há»©ng thÃº vÃ  theo há»c máº£ng ml vÃ  ds. Em Ä‘Ã£ Ä‘á»c sÃ¡ch cá»§a a Tiá»‡p vÃ  náº¯m kha khÃ¡ tá»‘t kiáº¿n thá»©c trong sÃ¡ch. Em cÅ©ng Ä‘Ã£ há»c mÃ´n ml á»Ÿ Ä‘áº¡i há»c nhÆ°ng khÃ´ng hiá»‡u quáº£ láº¯m, cÃ´ng thÃªm tÃ¬nh hÃ¬nh dá»‹ch bá»‡nh nhÆ° hiá»‡n táº¡i cÅ©ng lÃ m em khÃ´ng thá»ƒ trá»±c tiáº¿p tham kháº£o tá»« tháº§y cÃ´. Hiá»‡n táº¡i em Ä‘ang vÃ´ cÃ¹ng mÃ´ng lung khÃ´ng biáº¿t cáº§n há»c thÃªm gÃ¬, thá»±c hÃ nh ra sao hay tiáº¿p tá»¥c nhÆ° nÃ o. VÃ¬ váº­y em hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ cho em má»™t hÆ°á»›ng dáº«n hoáº·c lá»™ trÃ¬nh thá»±c sá»± cá»¥ thá»ƒ. Em khÃ´ng cÃ³ gÃ¬ ngoÃ i thá»i gian áº¡.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em má»›i tÃ¬m hiá»ƒu vá» ANN vÃ  biáº¿t matlab cÃ³ nntool há»— trá»£ mÃ´ hÃ¬nh ANN . Khi em cháº¡y thá»­ mÃ´ hÃ¬nh thÃ¬ Ä‘Æ°á»£c káº¿t quáº£ nhÆ° nÃ y .
Má»i ngÆ°á»i cho em há»i giÃ¡ trá»‹ R trong regression cÃ³ pháº£i coefficient of determination khÃ´ng áº¡ ?",Em chÃ o má»i ngÆ°á»i áº¡ Em má»›i tÃ¬m hiá»ƒu vá» ANN vÃ  biáº¿t matlab cÃ³ nntool há»— trá»£ mÃ´ hÃ¬nh ANN . Khi em cháº¡y thá»­ mÃ´ hÃ¬nh thÃ¬ Ä‘Æ°á»£c káº¿t quáº£ nhÆ° nÃ y . Má»i ngÆ°á»i cho em há»i giÃ¡ trá»‹ R trong regression cÃ³ pháº£i coefficient of determination khÃ´ng áº¡ ?,,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh cÃ³ gáº·p 1 bÃ i toÃ¡n liÃªn quan Ä‘áº¿n tÃ­nh xÃ¡c suáº¥t nhÆ°ng giáº£i khÃ´ng ra, nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ :(
---
Our hero - Maga is going to make a new contest for making the best teams. He is really excited about it. There will be S students in the contest. First N students in the final standings will be awarded.
He has a list( favourite students list ) what contains the best students in informatics Olympiad. His favorite students list contains M students. Though he is excited about the contest, he will enjoy it only if at least K of students from his favourite students list are awarded. He is wondering what are the chances of that happening. He needs your help. Tell him the probability that he will enjoy. It is known that each student has equal chance of being awarded.
Input:
First line of input contains a single integer T, the number of test cases. In the next T lines, you are given 4 separated integers, S, N, M and K.
Output:
For each test case, output the required probability with 6 digits after floating point.
Constraints:
1 <= T <= 100
1 <= S <= 1000
1 <= N <= S
1 <= M <= S
0 <= K <= M
SAMPLE INPUT
3
10 10 5 3
10 4 6 4
3 2 2 1
SAMPLE OUTPUT
1.000000
0.071429
1.000000","ChÃ o má»i ngÆ°á»i, MÃ¬nh cÃ³ gáº·p 1 bÃ i toÃ¡n liÃªn quan Ä‘áº¿n tÃ­nh xÃ¡c suáº¥t nhÆ°ng giáº£i khÃ´ng ra, nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ :( --- Our hero - Maga is going to make a new contest for making the best teams. He is really excited about it. There will be S students in the contest. First N students in the final standings will be awarded. He has a list( favourite students list ) what contains the best students in informatics Olympiad. His favorite students list contains M students. Though he is excited about the contest, he will enjoy it only if at least K of students from his favourite students list are awarded. He is wondering what are the chances of that happening. He needs your help. Tell him the probability that he will enjoy. It is known that each student has equal chance of being awarded. Input: First line of input contains a single integer T, the number of test cases. In the next T lines, you are given 4 separated integers, S, N, M and K. Output: For each test case, output the required probability with 6 digits after floating point. Constraints: 1 <= T <= 100 1 <= S <= 1000 1 <= N <= S 1 <= M <= S 0 <= K <= M SAMPLE INPUT 3 10 10 5 3 10 4 6 4 3 2 2 1 SAMPLE OUTPUT 1.000000 0.071429 1.000000",,,,,
"BÃ i viáº¿t má»›i toanh cá»§a mÃ¬nh trÃªn medium. ÄÃ¢y lÃ  bÃ i thá»© nÄƒm cá»§a mÃ¬nh liÃªn quan Ä‘áº¿n Machine Learning. Blog cá»§a mÃ¬nh chuyÃªn viáº¿t vá» machine learning vÃ  á»©ng dá»¥ng khÃ¡c nhau cá»§a nÃ³ trong tÃ i chÃ­nh, marketing, sá»©c khoáº»,..
Giá»›i thiá»‡u chÃºt vá» báº£n thÃ¢n, mÃ¬nh tÃªn lÃ  Nguyá»…n HÆ°ng Quang Kháº£i sinh viÃªn nÄƒm 3 khoa toÃ¡n á»¨ng dá»¥ng ÄH Quá»‘c Táº¿ TPHCM. Hiá»‡n nay mÃ¬nh Ä‘ang lÃ  Quantitative Analyst Intern táº¡i Quá»¹ Ä‘áº§u tÆ° VietQuant. Background cá»§a mÃ¬nh lÃ  mÃ¬nh Ä‘Ã£ tá»«ng Ä‘Æ°á»£c 1 HCV ToÃ¡n Há»c KhÃ´ng biÃªn Giá»›i táº¡i Bulgaria, Giáº£i Ba HSG ToÃ¡n Quá»‘c Gia VMO, 2 HCV Olympic 30/4 vÃ  lÃ  top 8 há»c sinh Ä‘áº¡i diá»‡n Viá»‡t Nam tham dá»± tráº¡i hÃ¨ Khoa há»c ChÃ¢u Ã 2018 táº¡i Indonesia.
Trong bÃ i Ä‘Äƒng nÃ y, mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh machine learning Ä‘á»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng giÃºp xÃ¡c Ä‘á»‹nh vÃ  theo dÃµi cÃ¡c nguy cÆ¡ máº¯c bá»‡nh tim.
Äiá»u Ä‘áº·c biá»‡t lÃ  , trong bÃ i viáº¿t nÃ y, thay vÃ¬ táº­p trung vÃ o viá»‡c fitting machine learning model, mÃ¬nh sáº½ nháº¥n máº¡nh nhiá»u hÆ¡n vÃ o bÆ°á»›c feature engineering.
PhÆ°Æ¡ng phÃ¡p feature engineering cá»§a mÃ¬nh trong bÃ i nÃ y khÃ¡ Ä‘Æ¡n giáº£n, nhÆ°ng hiá»‡u quáº£ vÃ  cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c nhiá»u cho cÃ¡c project machine learning khÃ¡c nhau
Theo Ã½ kiáº¿n cá»§a mÃ¬nh, feature engineering lÃ  bÆ°á»›c quan trá»ng nháº¥t trong machine learning. Feature engineering tá»‘t khÃ´ng chá»‰ giÃºp nÃ¢ng cao hiá»‡u suáº¥t dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh mÃ  cÃ²n giÃºp chÃºng ta cÃ³ Ä‘Æ°á»£c nhá»¯ng hiá»ƒu biáº¿t cÃ³ giÃ¡ trá»‹ tá»« dá»¯ liá»‡u.
LÆ°u Ã½: Project nÃ y mÃ¬nh chá»‰ láº¥y ra lÃ m vÃ­ dá»¥ cho phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh. Äá»ƒ Ä‘áº£m bÃ¡o Ä‘Ãºng tiÃªu chuáº©n an toÃ n khi á»©ng dá»¥ng thá»±c táº¿, bÃ i viáº¿t dÆ°á»›i Ä‘Ã¢y khÃ´ng Ä‘á»§.
MÃ¹a hÃ¨ dá»‹ch covid nÃ y, mÃ¬nh sáº½ Ä‘áº©y máº¡nh viá»‡c viáº¿t bÃ i vá» machine learning/deep learning nhiá»u hÆ¡n trÃªn blog medium cá»§a mÃ¬nh. Nhá»¯ng báº¡n nÃ o cÃ³ quan tÃ¢m, cÃ³ thá»ƒ liÃªn há»‡ trá»±c tiáº¿p vá»›i mÃ¬nh, Ä‘á»ƒ mÃ¬nh sáº½ cÃ³ nhiá»u bÃ i viáº¿t hÆ¡n theo Ä‘Ãºng nhu cáº§u cá»§a cÃ¡c báº¡n. HÆ¡n ná»¯a mÃ¬nh cÅ©ng muá»‘n má»Ÿ rá»™ng hÆ¡n networking cá»§a mÃ¬nh hÆ¡n.
Hi vá»ng cÃ¡c báº¡n thÃ­ch bÃ i viáº¿t nÃ y cá»§a mÃ¬nh, vÃ  Ä‘á»«ng quÃªn like/share Ä‘á»ƒ á»§ng há»™ mÃ¬nh","BÃ i viáº¿t má»›i toanh cá»§a mÃ¬nh trÃªn medium. ÄÃ¢y lÃ  bÃ i thá»© nÄƒm cá»§a mÃ¬nh liÃªn quan Ä‘áº¿n Machine Learning. Blog cá»§a mÃ¬nh chuyÃªn viáº¿t vá» machine learning vÃ  á»©ng dá»¥ng khÃ¡c nhau cá»§a nÃ³ trong tÃ i chÃ­nh, marketing, sá»©c khoáº»,.. Giá»›i thiá»‡u chÃºt vá» báº£n thÃ¢n, mÃ¬nh tÃªn lÃ  Nguyá»…n HÆ°ng Quang Kháº£i sinh viÃªn nÄƒm 3 khoa toÃ¡n á»¨ng dá»¥ng ÄH Quá»‘c Táº¿ TPHCM. Hiá»‡n nay mÃ¬nh Ä‘ang lÃ  Quantitative Analyst Intern táº¡i Quá»¹ Ä‘áº§u tÆ° VietQuant. Background cá»§a mÃ¬nh lÃ  mÃ¬nh Ä‘Ã£ tá»«ng Ä‘Æ°á»£c 1 HCV ToÃ¡n Há»c KhÃ´ng biÃªn Giá»›i táº¡i Bulgaria, Giáº£i Ba HSG ToÃ¡n Quá»‘c Gia VMO, 2 HCV Olympic 30/4 vÃ  lÃ  top 8 há»c sinh Ä‘áº¡i diá»‡n Viá»‡t Nam tham dá»± tráº¡i hÃ¨ Khoa há»c ChÃ¢u Ã 2018 táº¡i Indonesia. Trong bÃ i Ä‘Äƒng nÃ y, mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh machine learning Ä‘á»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng giÃºp xÃ¡c Ä‘á»‹nh vÃ  theo dÃµi cÃ¡c nguy cÆ¡ máº¯c bá»‡nh tim. Äiá»u Ä‘áº·c biá»‡t lÃ  , trong bÃ i viáº¿t nÃ y, thay vÃ¬ táº­p trung vÃ o viá»‡c fitting machine learning model, mÃ¬nh sáº½ nháº¥n máº¡nh nhiá»u hÆ¡n vÃ o bÆ°á»›c feature engineering. PhÆ°Æ¡ng phÃ¡p feature engineering cá»§a mÃ¬nh trong bÃ i nÃ y khÃ¡ Ä‘Æ¡n giáº£n, nhÆ°ng hiá»‡u quáº£ vÃ  cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c nhiá»u cho cÃ¡c project machine learning khÃ¡c nhau Theo Ã½ kiáº¿n cá»§a mÃ¬nh, feature engineering lÃ  bÆ°á»›c quan trá»ng nháº¥t trong machine learning. Feature engineering tá»‘t khÃ´ng chá»‰ giÃºp nÃ¢ng cao hiá»‡u suáº¥t dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh mÃ  cÃ²n giÃºp chÃºng ta cÃ³ Ä‘Æ°á»£c nhá»¯ng hiá»ƒu biáº¿t cÃ³ giÃ¡ trá»‹ tá»« dá»¯ liá»‡u. LÆ°u Ã½: Project nÃ y mÃ¬nh chá»‰ láº¥y ra lÃ m vÃ­ dá»¥ cho phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh. Äá»ƒ Ä‘áº£m bÃ¡o Ä‘Ãºng tiÃªu chuáº©n an toÃ n khi á»©ng dá»¥ng thá»±c táº¿, bÃ i viáº¿t dÆ°á»›i Ä‘Ã¢y khÃ´ng Ä‘á»§. MÃ¹a hÃ¨ dá»‹ch covid nÃ y, mÃ¬nh sáº½ Ä‘áº©y máº¡nh viá»‡c viáº¿t bÃ i vá» machine learning/deep learning nhiá»u hÆ¡n trÃªn blog medium cá»§a mÃ¬nh. Nhá»¯ng báº¡n nÃ o cÃ³ quan tÃ¢m, cÃ³ thá»ƒ liÃªn há»‡ trá»±c tiáº¿p vá»›i mÃ¬nh, Ä‘á»ƒ mÃ¬nh sáº½ cÃ³ nhiá»u bÃ i viáº¿t hÆ¡n theo Ä‘Ãºng nhu cáº§u cá»§a cÃ¡c báº¡n. HÆ¡n ná»¯a mÃ¬nh cÅ©ng muá»‘n má»Ÿ rá»™ng hÆ¡n networking cá»§a mÃ¬nh hÆ¡n. Hi vá»ng cÃ¡c báº¡n thÃ­ch bÃ i viáº¿t nÃ y cá»§a mÃ¬nh, vÃ  Ä‘á»«ng quÃªn like/share Ä‘á»ƒ á»§ng há»™ mÃ¬nh",,,,,
"ChÃ o cÃ¡c anh chá»‹,
Táº­p dá»¯ liá»‡u cá»§a em gá»“m 3 pháº§n: train, validation, test. Káº¿t quáº£ train vÃ  validation cho káº¿t quáº£ tá»‘t trÃªn cáº£ AUC vÃ  AUPR nhÆ°ng trÃªn táº­p test thÃ¬ AUPR cá»±c tháº¥p.
Táº­p train+validation cÃ³ kÃ­ch thÆ°á»›c bÃ© hÆ¡n nhiá»u so vá»›i táº­p test. (CÃ¡i nÃ y em ko thá»ƒ thay Ä‘á»•i vÃ¬ yÃªu cáº§u cá»§a bÃ i nÃ³ tháº¿ rá»“i áº¡).
NhÆ° váº­y váº¥n Ä‘á» lÃ  do kÃ­ch thÆ°á»›c hay bá»‹ overfitting rá»“i áº¡?
Em cÃ¡m Æ¡n má»i ngÆ°á»i!","ChÃ o cÃ¡c anh chá»‹, Táº­p dá»¯ liá»‡u cá»§a em gá»“m 3 pháº§n: train, validation, test. Káº¿t quáº£ train vÃ  validation cho káº¿t quáº£ tá»‘t trÃªn cáº£ AUC vÃ  AUPR nhÆ°ng trÃªn táº­p test thÃ¬ AUPR cá»±c tháº¥p. Táº­p train+validation cÃ³ kÃ­ch thÆ°á»›c bÃ© hÆ¡n nhiá»u so vá»›i táº­p test. (CÃ¡i nÃ y em ko thá»ƒ thay Ä‘á»•i vÃ¬ yÃªu cáº§u cá»§a bÃ i nÃ³ tháº¿ rá»“i áº¡). NhÆ° váº­y váº¥n Ä‘á» lÃ  do kÃ­ch thÆ°á»›c hay bá»‹ overfitting rá»“i áº¡? Em cÃ¡m Æ¡n má»i ngÆ°á»i!",,,,,
"ChÃ o cÃ¡c tiá»n bá»‘i áº¡, em bÃªn software má»›i chuyá»ƒn sang bÃªn aiml tÃ¬m hiá»ƒu. VÃ¬ em muá»‘n thá»i gian Ä‘áº§u Ä‘i nhanh nÃªn em mong muá»‘n tÃ¬m má»™t ngÆ°á»i tháº§y cÃ³ thá»ƒ dáº¡y em nhá»¯ng thuáº­t toÃ¡n nhÆ° em cÃ³ nÃ³i bÃªn dÆ°á»›i (song hÃ nh vá»›i viá»‡c Ä‘Æ°á»£c dáº¡y thÃ¬ em cÅ©ng sáº½ tá»± tÃ¬m hiá»ƒu Ä‘á»ƒ há»i chá»© khÃ´ng phÃ³ thÃ¡c háº¿t vÃ o ngÆ°á»i dáº¡y). KhÃ´ng chá»‰ thuáº­t toÃ¡n, em cÅ©ng muá»‘n Ä‘Æ°á»£c hÆ°á»›ng dáº«n cÃ¡c bÆ°á»›c ngoÃ i nhÆ° data handling. NgoÃ i ra em cÅ©ng muá»‘n Ä‘Æ°á»£c chá»‰ giÃ¡o tips and tricks khi sá»­ dá»¥ng nhá»¯ng thÆ° viá»‡n há»— trá»£. Anh chá»‹ nÃ o cÃ³ nhu cáº§u kiáº¿m thÃªm cÃ³ thá»ƒ cmt em sáº½ chá»§ Ä‘á»™ng ib áº¡. Em cáº£m Æ¡n mn nhiá»u áº¡ â¤.
P/s: vÃ¬ em mong muá»‘n Ä‘i sÃ¢u báº£n cháº¥t nÃªn em mong muá»‘n tÃ¬m Ä‘Æ°á»£c ai cÃ³ thá»ƒ giáº£i thÃ­ch cho em vá» máº·t báº£n cháº¥t toÃ¡n há»c chá»© khÃ´ng chá»‰ lÃ  code áº¡.","ChÃ o cÃ¡c tiá»n bá»‘i áº¡, em bÃªn software má»›i chuyá»ƒn sang bÃªn aiml tÃ¬m hiá»ƒu. VÃ¬ em muá»‘n thá»i gian Ä‘áº§u Ä‘i nhanh nÃªn em mong muá»‘n tÃ¬m má»™t ngÆ°á»i tháº§y cÃ³ thá»ƒ dáº¡y em nhá»¯ng thuáº­t toÃ¡n nhÆ° em cÃ³ nÃ³i bÃªn dÆ°á»›i (song hÃ nh vá»›i viá»‡c Ä‘Æ°á»£c dáº¡y thÃ¬ em cÅ©ng sáº½ tá»± tÃ¬m hiá»ƒu Ä‘á»ƒ há»i chá»© khÃ´ng phÃ³ thÃ¡c háº¿t vÃ o ngÆ°á»i dáº¡y). KhÃ´ng chá»‰ thuáº­t toÃ¡n, em cÅ©ng muá»‘n Ä‘Æ°á»£c hÆ°á»›ng dáº«n cÃ¡c bÆ°á»›c ngoÃ i nhÆ° data handling. NgoÃ i ra em cÅ©ng muá»‘n Ä‘Æ°á»£c chá»‰ giÃ¡o tips and tricks khi sá»­ dá»¥ng nhá»¯ng thÆ° viá»‡n há»— trá»£. Anh chá»‹ nÃ o cÃ³ nhu cáº§u kiáº¿m thÃªm cÃ³ thá»ƒ cmt em sáº½ chá»§ Ä‘á»™ng ib áº¡. Em cáº£m Æ¡n mn nhiá»u áº¡ . P/s: vÃ¬ em mong muá»‘n Ä‘i sÃ¢u báº£n cháº¥t nÃªn em mong muá»‘n tÃ¬m Ä‘Æ°á»£c ai cÃ³ thá»ƒ giáº£i thÃ­ch cho em vá» máº·t báº£n cháº¥t toÃ¡n há»c chá»© khÃ´ng chá»‰ lÃ  code áº¡.",,,,,
"mÃ¬nh Ä‘ang dÃ¹ng k-NN Ä‘á»ƒ phÃ¢n loáº¡i táº­p dá»¯ liá»‡u animals gá»“m dog, cat vÃ  pandas. Trong file knn.py mÃ¬nh import má»™t sá»‘ class tá»« cÃ¡c subpackage. KhÃ´ng biáº¿t mÃ¬nh sai chá»— nÃ o mÃ  khi run thÃ¬ bÃ¡o lá»—i module not found. MÃ¬nh kÃ¨m theo cáº¥u trÃºc thÆ° má»¥c project Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o.","mÃ¬nh Ä‘ang dÃ¹ng k-NN Ä‘á»ƒ phÃ¢n loáº¡i táº­p dá»¯ liá»‡u animals gá»“m dog, cat vÃ  pandas. Trong file knn.py mÃ¬nh import má»™t sá»‘ class tá»« cÃ¡c subpackage. KhÃ´ng biáº¿t mÃ¬nh sai chá»— nÃ o mÃ  khi run thÃ¬ bÃ¡o lá»—i module not found. MÃ¬nh kÃ¨m theo cáº¥u trÃºc thÆ° má»¥c project Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o.",,,,,
Cuá»‘i cÃ¹ng AlphaFold2 sau 5 nÄƒm nghiÃªn cá»©u cá»§a DeepMind Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o website cá»§a EMBL-EBI. CÃ¡c báº¡n nÃ o quan tÃ¢m tá»›i tin sinh cÃ³ thá»ƒ xem táº¡i Ä‘Ã¢y,Cuá»‘i cÃ¹ng AlphaFold2 sau 5 nÄƒm nghiÃªn cá»©u cá»§a DeepMind Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o website cá»§a EMBL-EBI. CÃ¡c báº¡n nÃ o quan tÃ¢m tá»›i tin sinh cÃ³ thá»ƒ xem táº¡i Ä‘Ã¢y,,,,,
"ChÃ o má»i ngÆ°á»i!
Em Ä‘ang tÃ¬m hiá»ƒu vá» Convolutional NN vÃ  cÃ³ Ä‘á»c vá» máº¥y loáº¡i kiáº¿n trÃºc. Em tháº¥y má»™t sá»‘ kiáº¿n trÃºc cÃ³ dÃ¹ng Depthwise Separable Convolution (SepConv2D) vá»›i má»¥c Ä‘Ã­ch giáº£m khá»‘i lÆ°á»£ng tÃ­nh toÃ¡n vÃ  tham sá»‘ (chá»§ yáº¿u lÃ  kiáº¿n trÃºc cho thiáº¿t bá»‹ cÃ³ háº¡n cháº¿).
Váº­y táº¡i sao cÃ¡c mÃ´ hÃ¬nh váº«n dÃ¹ng Conv2D truyá»n thá»‘ng? CÃ³ thá»ƒ dÃ¹ng SepConv2D thay tháº¿ khÃ´ng?
Em cáº£m Æ¡n!",ChÃ o má»i ngÆ°á»i! Em Ä‘ang tÃ¬m hiá»ƒu vá» Convolutional NN vÃ  cÃ³ Ä‘á»c vá» máº¥y loáº¡i kiáº¿n trÃºc. Em tháº¥y má»™t sá»‘ kiáº¿n trÃºc cÃ³ dÃ¹ng Depthwise Separable Convolution (SepConv2D) vá»›i má»¥c Ä‘Ã­ch giáº£m khá»‘i lÆ°á»£ng tÃ­nh toÃ¡n vÃ  tham sá»‘ (chá»§ yáº¿u lÃ  kiáº¿n trÃºc cho thiáº¿t bá»‹ cÃ³ háº¡n cháº¿). Váº­y táº¡i sao cÃ¡c mÃ´ hÃ¬nh váº«n dÃ¹ng Conv2D truyá»n thá»‘ng? CÃ³ thá»ƒ dÃ¹ng SepConv2D thay tháº¿ khÃ´ng? Em cáº£m Æ¡n!,,,,,
"Báº¡n nÃ o cÃ³ há»c qua Há»c bá»•ng "" FUNiX AI Connect with Cohost.AI"" hay Ä‘Ã£ há»c qua khoÃ¡ Machine Learing cá»§a FUNiX chÆ°a?
Cho mÃ¬nh xin review vá»›i","Báº¡n nÃ o cÃ³ há»c qua Há»c bá»•ng "" FUNiX AI Connect with Cohost.AI"" hay Ä‘Ã£ há»c qua khoÃ¡ Machine Learing cá»§a FUNiX chÆ°a? Cho mÃ¬nh xin review vá»›i",,,,,
"Klq láº¯m Ä‘áº¿n ml, xin phÃ©p ad.
MÃ¬nh muá»‘n há»i lÃ  ""vÃ´ sá»‘ nghiá»‡m"" trong tiáº¿ng anh thÃ¬ nÃ³i sao áº¡? VÃ­ dá»¥ nhÆ° phÆ°Æ¡ng trÃ¬nh nÃ y cÃ³ vÃ´ sá»‘ nghiá»‡m. Cáº£m Æ¡n má»i ngÆ°á»i","Klq láº¯m Ä‘áº¿n ml, xin phÃ©p ad. MÃ¬nh muá»‘n há»i lÃ  ""vÃ´ sá»‘ nghiá»‡m"" trong tiáº¿ng anh thÃ¬ nÃ³i sao áº¡? VÃ­ dá»¥ nhÆ° phÆ°Æ¡ng trÃ¬nh nÃ y cÃ³ vÃ´ sá»‘ nghiá»‡m. Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"[Chia sáº» kiáº¿n thá»©c]
Trong Machine Learning, má»—i váº¥n Ä‘á» cá»¥ thá»ƒ luÃ´n cáº§n nhá»¯ng Ä‘áº·c trÆ°ng quan trá»ng phÃ¹ há»£p nháº¥t, cháº³ng háº¡n cÃ¡c tÃ¡c vá»¥ ML tuy cÃ³ thá»ƒ giá»‘ng nhau trong bÃ i toÃ¡n phÃ¢n loáº¡i thÆ° rÃ¡c, phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay... nhÆ°ng cÃ¡c Ä‘áº·c trÆ°ng cáº§n Ä‘Æ°á»£c trÃ­ch xuáº¥t trong má»—i ká»‹ch báº£n sáº½ ráº¥t khÃ¡c nhau.
VÃ¬ váº­y, Feature Engineering (xá»­ lÃ½ Ä‘áº·c trÆ°ng) vá»«a lÃ  nghá»‡ thuáº­t, vá»«a lÃ  bá»™ mÃ´n khoa há»c khiáº¿n cÃ¡c Data Scientist thÆ°á»ng dÃ nh 70% thá»i gian Ä‘á»ƒ chuáº©n bá»‹ dá»¯ liá»‡u trÆ°á»›c khi xÃ¢y dá»±ng mÃ´ hÃ¬nh.
CÃ¹ng tÃ¬m hiá»ƒu táº§m quan trá»ng cá»§a Feature Engineering, tÃ¡c Ä‘á»™ng tá»« cÃ¡c Ä‘áº·c trÆ°ng nÃ y Ä‘áº¿n model + vÃ­ dá»¥ thá»±c táº¿ cho cÃ¢u há»i ""Bao nhiÃªu features thÃ¬ Ä‘á»§ tá»‘t cho 1 model?"" qua chia sáº» cá»§a Ms. TrÃ¢n Thiá»u (Research Engineer táº¡i Trusting Social): https://bit.ly/ml2101_featureengineering
Nguá»“n bÃ i gá»‘c: https://www.facebook.com/vefacademy/posts/1018251165586293
#featureengineering #machinelearning #datascience #AI","[Chia sáº» kiáº¿n thá»©c] Trong Machine Learning, má»—i váº¥n Ä‘á» cá»¥ thá»ƒ luÃ´n cáº§n nhá»¯ng Ä‘áº·c trÆ°ng quan trá»ng phÃ¹ há»£p nháº¥t, cháº³ng háº¡n cÃ¡c tÃ¡c vá»¥ ML tuy cÃ³ thá»ƒ giá»‘ng nhau trong bÃ i toÃ¡n phÃ¢n loáº¡i thÆ° rÃ¡c, phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay... nhÆ°ng cÃ¡c Ä‘áº·c trÆ°ng cáº§n Ä‘Æ°á»£c trÃ­ch xuáº¥t trong má»—i ká»‹ch báº£n sáº½ ráº¥t khÃ¡c nhau. VÃ¬ váº­y, Feature Engineering (xá»­ lÃ½ Ä‘áº·c trÆ°ng) vá»«a lÃ  nghá»‡ thuáº­t, vá»«a lÃ  bá»™ mÃ´n khoa há»c khiáº¿n cÃ¡c Data Scientist thÆ°á»ng dÃ nh 70% thá»i gian Ä‘á»ƒ chuáº©n bá»‹ dá»¯ liá»‡u trÆ°á»›c khi xÃ¢y dá»±ng mÃ´ hÃ¬nh. CÃ¹ng tÃ¬m hiá»ƒu táº§m quan trá»ng cá»§a Feature Engineering, tÃ¡c Ä‘á»™ng tá»« cÃ¡c Ä‘áº·c trÆ°ng nÃ y Ä‘áº¿n model + vÃ­ dá»¥ thá»±c táº¿ cho cÃ¢u há»i ""Bao nhiÃªu features thÃ¬ Ä‘á»§ tá»‘t cho 1 model?"" qua chia sáº» cá»§a Ms. TrÃ¢n Thiá»u (Research Engineer táº¡i Trusting Social): https://bit.ly/ml2101_featureengineering Nguá»“n bÃ i gá»‘c: https://www.facebook.com/vefacademy/posts/1018251165586293",#featureengineering	#machinelearning	#datascience	#AI,,,,
"ChÃ o anh chá»‹, em má»›i tÃ¬m hiá»ƒu vá» Deep learning vÃ  cÃ³ chÃºt tháº¯c máº¯c chÃºt áº¡!
Vá»›i táº­p dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm thá»­, em cÃ³ label data báº±ng cÃ¡ch dÃ¹ng flow_from_dictionary, nhÆ°ng khi train cho káº¿t quáº£ chá»‰ khoáº£ng ~ 70% á»Ÿ táº­p test. CÃ²n khi em label báº±ng cÃ¡ch load háº¿t áº£nh, mÃ£ hÃ³a one-hot rá»“i chia báº±ng train_test_split thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c láº¡i cao hÆ¡n háº³n (khoáº£ng 98%). Em khÃ´ng biáº¿t táº¡i sao láº¡i cÃ³ sá»± khÃ¡c nhau nÃ y, má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡?","ChÃ o anh chá»‹, em má»›i tÃ¬m hiá»ƒu vá» Deep learning vÃ  cÃ³ chÃºt tháº¯c máº¯c chÃºt áº¡! Vá»›i táº­p dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm thá»­, em cÃ³ label data báº±ng cÃ¡ch dÃ¹ng flow_from_dictionary, nhÆ°ng khi train cho káº¿t quáº£ chá»‰ khoáº£ng ~ 70% á»Ÿ táº­p test. CÃ²n khi em label báº±ng cÃ¡ch load háº¿t áº£nh, mÃ£ hÃ³a one-hot rá»“i chia báº±ng train_test_split thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c láº¡i cao hÆ¡n háº³n (khoáº£ng 98%). Em khÃ´ng biáº¿t táº¡i sao láº¡i cÃ³ sá»± khÃ¡c nhau nÃ y, má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em Ä‘Æ°á»£c khÃ´ng áº¡?",,,,,
"[AI News - Course 100% free]
Deep Learning with PyTorch by Microsoft ğŸ”¥ğŸ”¥.
Microsoft há»£p tÃ¡c vá»›i PyTorch Ä‘á»ƒ cung cáº¥p má»™t khÃ³a há»c cÆ¡ báº£n vá» PyTorch HOÃ€N TOÃ€N MIá»„N PHÃ. Wow, Ä‘iá»u nÃ y tháº­t sá»± quÃ¡ tuyá»‡t vá»i ğŸ˜
CÃ¡c chá»§ Ä‘á» bao gá»“m:
* Introduction to Pytorch
* Computer Vision with PyTorch
* NLP with PyTorch
* Audio Classification with PyTorch
KhÃ³a há»c thiáº¿t káº¿ Ä‘á»ƒ báº¡n cÃ³ thá»ƒ viáº¿t code trá»±c tiáº¿p trÃªn web mÃ  khÃ´ng cáº§n cÃ i Ä‘áº·t hay táº£i vá» báº¥t cá»© thá»© gÃ¬.
Viá»‡c cá»§a báº¡n chá»‰ lÃ  sáº¯p xáº¿p thá»i gian Ä‘á»ƒ há»c ^^.
Tuy nhiÃªn khÃ³a há»c yÃªu cáº§u báº¡n pháº£i cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» Python, Machine Learning vÃ  cÃ¡ch sá»­ dá»¥ng cÆ¡ báº£n Jupyter Notebooks.","[AI News - Course 100% free] Deep Learning with PyTorch by Microsoft . Microsoft há»£p tÃ¡c vá»›i PyTorch Ä‘á»ƒ cung cáº¥p má»™t khÃ³a há»c cÆ¡ báº£n vá» PyTorch HOÃ€N TOÃ€N MIá»„N PHÃ. Wow, Ä‘iá»u nÃ y tháº­t sá»± quÃ¡ tuyá»‡t vá»i CÃ¡c chá»§ Ä‘á» bao gá»“m: * Introduction to Pytorch * Computer Vision with PyTorch * NLP with PyTorch * Audio Classification with PyTorch KhÃ³a há»c thiáº¿t káº¿ Ä‘á»ƒ báº¡n cÃ³ thá»ƒ viáº¿t code trá»±c tiáº¿p trÃªn web mÃ  khÃ´ng cáº§n cÃ i Ä‘áº·t hay táº£i vá» báº¥t cá»© thá»© gÃ¬. Viá»‡c cá»§a báº¡n chá»‰ lÃ  sáº¯p xáº¿p thá»i gian Ä‘á»ƒ há»c ^^. Tuy nhiÃªn khÃ³a há»c yÃªu cáº§u báº¡n pháº£i cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» Python, Machine Learning vÃ  cÃ¡ch sá»­ dá»¥ng cÆ¡ báº£n Jupyter Notebooks.",,,,,
,nan,,,,,
"CÃ¢u há»i vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh
Em chÃ o má»i ngÆ°Ã²i áº¡. Chuyá»‡n lÃ  em Ä‘ang há»c vá» linear algebra, cá»¥ thá»ƒ lÃ  pháº§n inner product (tÃ­ch vÃ´ hÆ°á»›ng). Em Ä‘Æ°á»£c biáº¿t lÃ  vá»›i 2 vector u,v thuá»™c sá»‘ thá»±c R thÃ¬
<u,v> = tá»•ng tÃ­ch cÃ¡c pháº§n tá»­ 2 vector // <u,v> = u1.v1 + u2.v2 + ... + un.vn //
NhÆ°ng Ä‘á»‘i vá»›i 2 vector u,v thuá»™c sá»‘ phá»©c C thÃ¬
<u,v> = u1*.v1 + u2*.v2 +... + un*.vn vá»›i u* lÃ  sá»‘ phá»©c liÃªn há»£p cá»§a u
Em cÃ³ tháº¯c máº¯c lÃ  táº¡i sao pháº£i lÃ  <u,v> vá»›i u,v thuá»™c C pháº£i dÃ¹ng u* thay vÃ¬ u nhÆ° cá»§a u,v thuá»™c R áº¡.
Em xin cáº£m Æ¡n.","CÃ¢u há»i vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh Em chÃ o má»i ngÆ°Ã²i áº¡. Chuyá»‡n lÃ  em Ä‘ang há»c vá» linear algebra, cá»¥ thá»ƒ lÃ  pháº§n inner product (tÃ­ch vÃ´ hÆ°á»›ng). Em Ä‘Æ°á»£c biáº¿t lÃ  vá»›i 2 vector u,v thuá»™c sá»‘ thá»±c R thÃ¬ <u,v> = tá»•ng tÃ­ch cÃ¡c pháº§n tá»­ 2 vector // <u,v> = u1.v1 + u2.v2 + ... + un.vn // NhÆ°ng Ä‘á»‘i vá»›i 2 vector u,v thuá»™c sá»‘ phá»©c C thÃ¬ <u,v> = u1*.v1 + u2*.v2 +... + un*.vn vá»›i u* lÃ  sá»‘ phá»©c liÃªn há»£p cá»§a u Em cÃ³ tháº¯c máº¯c lÃ  táº¡i sao pháº£i lÃ  <u,v> vá»›i u,v thuá»™c C pháº£i dÃ¹ng u* thay vÃ¬ u nhÆ° cá»§a u,v thuá»™c R áº¡. Em xin cáº£m Æ¡n.",,"#Q&A, #math",,,
"Em xin chÃ o cÃ¡c anh chá»‹ áº¡, em cÃ³ Ä‘ang thá»­ vÃ i cÃ¡i giáº£i thuáº­t khÃ¡c nhau lÃªn dataset cá»§a em. Em cÃ³ thá»­ dÃ¹ng sgd, sgd_momentum, rmsprop vÃ  adam. Theo em Ä‘Æ°á»£c biáº¿t thÃ¬ sgd_momentum sáº½ há»™i tá»¥ nhanh hÆ¡n vÃ  cáº£i thiá»‡n káº¿t quáº£ so vá»›i sgd thuáº§n tÃºy. NhÆ°ng theo nhÆ° trong hÃ¬nh thÃ¬ model dÃ¹ng sgd_momentum ko há»c Ä‘c gÃ¬ cáº£, trong khi sgd há»c Ä‘Æ°á»£c tÆ°Æ¡ng Ä‘á»‘i, vÃ  em Ä‘ang tháº¯c máº¯c cÃ³ bao giá» chuyá»‡n nÃ y xáº£y ra ko? Em xin cáº£m Æ¡n áº¡.","Em xin chÃ o cÃ¡c anh chá»‹ áº¡, em cÃ³ Ä‘ang thá»­ vÃ i cÃ¡i giáº£i thuáº­t khÃ¡c nhau lÃªn dataset cá»§a em. Em cÃ³ thá»­ dÃ¹ng sgd, sgd_momentum, rmsprop vÃ  adam. Theo em Ä‘Æ°á»£c biáº¿t thÃ¬ sgd_momentum sáº½ há»™i tá»¥ nhanh hÆ¡n vÃ  cáº£i thiá»‡n káº¿t quáº£ so vá»›i sgd thuáº§n tÃºy. NhÆ°ng theo nhÆ° trong hÃ¬nh thÃ¬ model dÃ¹ng sgd_momentum ko há»c Ä‘c gÃ¬ cáº£, trong khi sgd há»c Ä‘Æ°á»£c tÆ°Æ¡ng Ä‘á»‘i, vÃ  em Ä‘ang tháº¯c máº¯c cÃ³ bao giá» chuyá»‡n nÃ y xáº£y ra ko? Em xin cáº£m Æ¡n áº¡.",,,,,
"ChÃ o mn, cho mÃ¬nh há»i liÃªn quan Ä‘áº¿n pháº§n cá»©ng.
Anh Chá»‹ Em Ä‘ang dÃ¹ng GPU nÃ o Ä‘á»ƒ train ML vÃ  AI.
ï¿¼ï¿¼1. ThuÃª mÃ¡y Ä‘á»ƒ train khÃ´ng quan tÃ¢m Ä‘áº¿n GPU nÃ o miá»…n sao train Ä‘Æ°á»£c.
2. ThuÃª mÃ¡y nhÆ°ng GPU lÃ : ...
3. CÃ´ng ty/ cÃ¡ nhÃ¢n tá»± trang bá»‹ vá»›i GPU lÃ : ...
4. DÃ¹ng free Google Colab vÃ  service free khÃ¡c.
Anh chá»‹ Ä‘ang thuÃª bÃªn nÃ o: Gcloud, Aws, Azure hay 1 bÃªn cung cáº¥p dá»‹ch vá»¥ nÃ o. ÄÆ¡n giÃ¡/hour lÃ  bao nhiÃªu.
Xin cáº£m Æ¡n ace.
#gpu #k80","ChÃ o mn, cho mÃ¬nh há»i liÃªn quan Ä‘áº¿n pháº§n cá»©ng. Anh Chá»‹ Em Ä‘ang dÃ¹ng GPU nÃ o Ä‘á»ƒ train ML vÃ  AI. 1. ThuÃª mÃ¡y Ä‘á»ƒ train khÃ´ng quan tÃ¢m Ä‘áº¿n GPU nÃ o miá»…n sao train Ä‘Æ°á»£c. 2. ThuÃª mÃ¡y nhÆ°ng GPU lÃ : ... 3. CÃ´ng ty/ cÃ¡ nhÃ¢n tá»± trang bá»‹ vá»›i GPU lÃ : ... 4. DÃ¹ng free Google Colab vÃ  service free khÃ¡c. Anh chá»‹ Ä‘ang thuÃª bÃªn nÃ o: Gcloud, Aws, Azure hay 1 bÃªn cung cáº¥p dá»‹ch vá»¥ nÃ o. ÄÆ¡n giÃ¡/hour lÃ  bao nhiÃªu. Xin cáº£m Æ¡n ace.",#gpu	#k80,,,,
"NhÃ³m lÃ m viá»‡c cá»§a tÃ´i vá»«a cÃ³ má»™t bÃ i trÃªn Elsevier Expert Systems with Applications (ESWA), má»™t táº­p san khÃ¡ tá»‘t trong lÄ©nh vá»±c Artificial Intelligence, Computer Science. ESWA Ä‘Æ°á»£c xáº¿p háº¡ng SCImago Q1, vá»›i IF=5.452. BÃ i bÃ¡o trÃ¬nh bÃ y á»©ng dá»¥ng Deep Learning trong cháº©n Ä‘oÃ¡n bá»‡nh lao phá»•i, sá»­ dá»¥ng Vision Transformer vÃ  Transfer Learning. Hiá»‡n nay bÃ i Ä‘ang trong giai Ä‘oáº¡n Ä‘Æ°á»£c Elsevier cho táº£i miá»…n phÃ­ á»Ÿ Ä‘á»‹a chá»‰ Share Link sau: https://authors.elsevier.com/a/1dPVb3PiGTH-6F. TrÃ¢n trá»ng má»i cÃ¡c báº¡n quan tÃ¢m ghÃ© qua xem cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i.","NhÃ³m lÃ m viá»‡c cá»§a tÃ´i vá»«a cÃ³ má»™t bÃ i trÃªn Elsevier Expert Systems with Applications (ESWA), má»™t táº­p san khÃ¡ tá»‘t trong lÄ©nh vá»±c Artificial Intelligence, Computer Science. ESWA Ä‘Æ°á»£c xáº¿p háº¡ng SCImago Q1, vá»›i IF=5.452. BÃ i bÃ¡o trÃ¬nh bÃ y á»©ng dá»¥ng Deep Learning trong cháº©n Ä‘oÃ¡n bá»‡nh lao phá»•i, sá»­ dá»¥ng Vision Transformer vÃ  Transfer Learning. Hiá»‡n nay bÃ i Ä‘ang trong giai Ä‘oáº¡n Ä‘Æ°á»£c Elsevier cho táº£i miá»…n phÃ­ á»Ÿ Ä‘á»‹a chá»‰ Share Link sau: https://authors.elsevier.com/a/1dPVb3PiGTH-6F. TrÃ¢n trá»ng má»i cÃ¡c báº¡n quan tÃ¢m ghÃ© qua xem cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i.",,,,,
"[AI Share - Cheat Sheets]
Tá»•ng há»£p má»™t sá»‘ cheat sheets VIP cá»§a cÃ¡c khÃ³a khá»c Stanford
1. CS 221: Artificial Intelligence
2. CS 229: Machine Learning
3. CS 230: Deep Learning",[AI Share - Cheat Sheets] Tá»•ng há»£p má»™t sá»‘ cheat sheets VIP cá»§a cÃ¡c khÃ³a khá»c Stanford 1. CS 221: Artificial Intelligence 2. CS 229: Machine Learning 3. CS 230: Deep Learning,,,,,
"Cho em/mÃ¬nh há»i vá» split command cá»§a python
txt = ""Thanks for letting me in here. The -- are you guys seeing any strange order patterns as far as like double ordering or any kind of panic inventory rebuild? Anything -- I mean, I would imagine you'd probably see it in transportation and electronics, kind of perhaps equally in transportation and electronics of all the segments. But I'll just leave it at that. Anything on the ordering patterns that's unusual.""
ThÃ¬ mÃ¬nh nÃªn dÃ¹ng lá»‡nh nhÆ° nÃ o Ä‘á»ƒ tÃ¡ch ra tá»«ng individual words áº¡?","Cho em/mÃ¬nh há»i vá» split command cá»§a python txt = ""Thanks for letting me in here. The -- are you guys seeing any strange order patterns as far as like double ordering or any kind of panic inventory rebuild? Anything -- I mean, I would imagine you'd probably see it in transportation and electronics, kind of perhaps equally in transportation and electronics of all the segments. But I'll just leave it at that. Anything on the ordering patterns that's unusual."" ThÃ¬ mÃ¬nh nÃªn dÃ¹ng lá»‡nh nhÆ° nÃ o Ä‘á»ƒ tÃ¡ch ra tá»«ng individual words áº¡?",,,,,
CÃ³ Anh/Chá»‹/Em nÃ o trong group Ä‘Æ°á»£c cáº¥p quyá»n truy cáº­p vÃ o GPT-3 chÆ°a nhá»‰? Ráº¥t cáº§n chá»‰ giÃ¡o vÃ  kinh nghiá»‡m Ä‘á»ƒ láº¥y licence. Thanks,CÃ³ Anh/Chá»‹/Em nÃ o trong group Ä‘Æ°á»£c cáº¥p quyá»n truy cáº­p vÃ o GPT-3 chÆ°a nhá»‰? Ráº¥t cáº§n chá»‰ giÃ¡o vÃ  kinh nghiá»‡m Ä‘á»ƒ láº¥y licence. Thanks,,,,,
"ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i
Cho miÌ€nh hoÌ‰i nÃªÌu miÌ€nh coÌ data maÌ€ feature thuÃ´Ì£c daÌ£ng list , giÃ´Ìng trong hiÌ€nh, Æ¡Ì‰ Ä‘Ã¢y feature laÌ€ interest. NÃªÌu gÄƒÌ£p trÆ°Æ¡Ì€ng hÆ¡Ì£p vÃ¢Ì£y thÆ°Æ¡Ì€ng moÌ£i ngÆ°Æ¡Ì€i xÆ°Ì‰ lyÌ sao Ä‘ÃªÌ‰ build ML Model (ex:logistic regression, random forest...)
BaÌ£n naÌ€o coÌ kinh nghiÃªm xin chia seÌ‰
MiÌ€nh caÌ‰m Æ¡n","ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i Cho miÌ€nh hoÌ‰i nÃªÌu miÌ€nh coÌ data maÌ€ feature thuÃ´Ì£c daÌ£ng list , giÃ´Ìng trong hiÌ€nh, Æ¡Ì‰ Ä‘Ã¢y feature laÌ€ interest. NÃªÌu gÄƒÌ£p trÆ°Æ¡Ì€ng hÆ¡Ì£p vÃ¢Ì£y thÆ°Æ¡Ì€ng moÌ£i ngÆ°Æ¡Ì€i xÆ°Ì‰ lyÌ sao Ä‘ÃªÌ‰ build ML Model (ex:logistic regression, random forest...) BaÌ£n naÌ€o coÌ kinh nghiÃªm xin chia seÌ‰ MiÌ€nh caÌ‰m Æ¡n",,,,,
"Há»i vá» Overfitting trong Decision Tree.
Em má»›i tÃ¬m hiá»ƒu vÃ  thá»±c hiá»‡n thuáº­t toÃ¡n Decision Tree trÃªn má»™t bá»™ dá»¯ liá»‡u. Em cÃ³ search vÃ  tÃ¬m hiá»ƒu thÃ´ng tin trÃªn Google vá» cÃ¡c cÃ¡ch trÃ¡nh overfitting vÃ  Ä‘Ã£ sá»­ dá»¥ng 2 cÃ¡ch : háº¡n cháº¿ Ä‘á»™ sÃ¢u cá»§a cÃ¢y vÃ  post purning:
Háº¡n cháº¿ Ä‘á»™ sÃ¢u thÃ¬ em cÃ³ search trÃªn sklearn cÃ³ chá»‰ cÃ¡ch chá»n Ä‘á»™ sÃ¢u cÃ¢y phÃ¹ há»£p. NhÆ° hÃ¬nh dÆ°á»›i em chá»n max_depth=8
post purning: em cÃ³ váº½ Ä‘á»“ thá»‹ vá» viá»‡c thay Ä‘á»•i thÃ´ng sá»‘ ccp_alpha so vá»›i Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p training vÃ  táº­p test, nhÆ°ng em khÃ´ng biáº¿t chá»n Ä‘iá»ƒm giÃ¡ trá»‹ tá»‘i Æ°u cpp_alpha, theo nhÆ° em cÃ³ tÃ¬m hiá»ƒu thÃ¬ ngÆ°á»i ta thÆ°á»ng chá»n Ä‘iá»ƒm á»Ÿ vá»‹ trÃ­ cÃ³ accuracy_score cao nháº¥t, em chá»n táº¡i Ä‘iá»ƒm cao nháº¥t thÃ¬ táº¡i Ä‘Ã³ max_depth=12(Ä‘á»™ sÃ¢u khi cÃ¢y chia Ä‘áº¿n má»©c cÃ¡c lÃ¡ trá»Ÿ nÃªn tinh khiáº¿t nháº¥t) vÃ  em tháº¥y Ä‘á»™ chÃ­nh xÃ¡c cá»§a training set cÅ©ng khÃ¡ cao.
HÃ¬nh váº½ em cÃ³ Ä‘á»ƒ á»Ÿ dÆ°á»›i áº¡. Mong má»i ngÆ°á»i cho em nháº­n xÃ©t vÃ  chá»‰ em cÃ¡ch chá»n thÃ´ng sá»‘ phÃ¹ há»£p. Em cáº£m Æ¡n má»i ngÆ°á»i.","Há»i vá» Overfitting trong Decision Tree. Em má»›i tÃ¬m hiá»ƒu vÃ  thá»±c hiá»‡n thuáº­t toÃ¡n Decision Tree trÃªn má»™t bá»™ dá»¯ liá»‡u. Em cÃ³ search vÃ  tÃ¬m hiá»ƒu thÃ´ng tin trÃªn Google vá» cÃ¡c cÃ¡ch trÃ¡nh overfitting vÃ  Ä‘Ã£ sá»­ dá»¥ng 2 cÃ¡ch : háº¡n cháº¿ Ä‘á»™ sÃ¢u cá»§a cÃ¢y vÃ  post purning: Háº¡n cháº¿ Ä‘á»™ sÃ¢u thÃ¬ em cÃ³ search trÃªn sklearn cÃ³ chá»‰ cÃ¡ch chá»n Ä‘á»™ sÃ¢u cÃ¢y phÃ¹ há»£p. NhÆ° hÃ¬nh dÆ°á»›i em chá»n max_depth=8 post purning: em cÃ³ váº½ Ä‘á»“ thá»‹ vá» viá»‡c thay Ä‘á»•i thÃ´ng sá»‘ ccp_alpha so vá»›i Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p training vÃ  táº­p test, nhÆ°ng em khÃ´ng biáº¿t chá»n Ä‘iá»ƒm giÃ¡ trá»‹ tá»‘i Æ°u cpp_alpha, theo nhÆ° em cÃ³ tÃ¬m hiá»ƒu thÃ¬ ngÆ°á»i ta thÆ°á»ng chá»n Ä‘iá»ƒm á»Ÿ vá»‹ trÃ­ cÃ³ accuracy_score cao nháº¥t, em chá»n táº¡i Ä‘iá»ƒm cao nháº¥t thÃ¬ táº¡i Ä‘Ã³ max_depth=12(Ä‘á»™ sÃ¢u khi cÃ¢y chia Ä‘áº¿n má»©c cÃ¡c lÃ¡ trá»Ÿ nÃªn tinh khiáº¿t nháº¥t) vÃ  em tháº¥y Ä‘á»™ chÃ­nh xÃ¡c cá»§a training set cÅ©ng khÃ¡ cao. HÃ¬nh váº½ em cÃ³ Ä‘á»ƒ á»Ÿ dÆ°á»›i áº¡. Mong má»i ngÆ°á»i cho em nháº­n xÃ©t vÃ  chá»‰ em cÃ¡ch chá»n thÃ´ng sá»‘ phÃ¹ há»£p. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Má»i cÃ¡c báº¡n Ä‘á»c thá»­ bÃ i viáº¿t vá» thuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh cá»§a cuá»‘n machine learning algorithms to practice, Ä‘Ã¢y lÃ  cuá»‘n sÃ¡ch mÃ  mÃ¬nh Ä‘ang viáº¿t Ä‘á»ƒ á»§ng há»™ cá»™ng Ä‘á»“ng miá»…n phÃ­, vÃ  Ä‘Æ°a thÃªm cÃ¡c gÃ³p Ã½ Ä‘á»ƒ sÃ¡ch hoÃ n thiá»‡n hÆ¡n.","Má»i cÃ¡c báº¡n Ä‘á»c thá»­ bÃ i viáº¿t vá» thuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh cá»§a cuá»‘n machine learning algorithms to practice, Ä‘Ã¢y lÃ  cuá»‘n sÃ¡ch mÃ  mÃ¬nh Ä‘ang viáº¿t Ä‘á»ƒ á»§ng há»™ cá»™ng Ä‘á»“ng miá»…n phÃ­, vÃ  Ä‘Æ°a thÃªm cÃ¡c gÃ³p Ã½ Ä‘á»ƒ sÃ¡ch hoÃ n thiá»‡n hÆ¡n.",,"#math, #sharing, #machine_learning",,,
Cho em há»i cÃ¢u nÃ y vá»›i áº¡. Em cáº£m Æ¡n áº¡.,Cho em há»i cÃ¢u nÃ y vá»›i áº¡. Em cáº£m Æ¡n áº¡.,,,,,
moi huong dan hay cho cac ban nao muon xay dung mot kubernetes cluster voi raspberry de train cac model hay chay cac api container,moi huong dan hay cho cac ban nao muon xay dung mot kubernetes cluster voi raspberry de train cac model hay chay cac api container,,,,,
"Xin chÃ o mn, e train resnet34, náº¿u nhÆ° dÃ¹ng Ä‘oáº¡n init dÆ°á»›i thÃ¬ model há»™i tá»¥ ráº¥t cháº­m, cÃ²n náº¿u k dÃ¹ng thÃ¬ model há»™i tá»¥ ráº¥t nhanh (loss giáº£m nhanh vÃ  acc tÄƒng nhanh sau 1 vÃ i epoch Ä‘áº§u), mn giáº£i thÃ­ch giÃ¹m e tháº¿ lÃ  nhÆ° tháº¿ nÃ o vÃ  pháº£i dÃ¹ng nhÆ° tháº¿ nÃ o cho Ä‘Ãºng áº¡??
Em cáº£m Æ¡n","Xin chÃ o mn, e train resnet34, náº¿u nhÆ° dÃ¹ng Ä‘oáº¡n init dÆ°á»›i thÃ¬ model há»™i tá»¥ ráº¥t cháº­m, cÃ²n náº¿u k dÃ¹ng thÃ¬ model há»™i tá»¥ ráº¥t nhanh (loss giáº£m nhanh vÃ  acc tÄƒng nhanh sau 1 vÃ i epoch Ä‘áº§u), mn giáº£i thÃ­ch giÃ¹m e tháº¿ lÃ  nhÆ° tháº¿ nÃ o vÃ  pháº£i dÃ¹ng nhÆ° tháº¿ nÃ o cho Ä‘Ãºng áº¡?? Em cáº£m Æ¡n",,,,,
"Introduction to TorchShard
A Lightweight Library for Scaling-up the Training
#Pytorch #Facebookai
Author: Kaiyu Yue, Incoming Ph.D. Student at the Computer Science Department of the University of Maryland, College Park
TorchShard is a lightweight engine for slicing a PyTorch tensor into parallel shards. It can reduce GPU memory and scale up the training when the model has massive linear layers (e.g., BERT and GPT) or huge classes (millions). It has the same API design as PyTorch. In this blog, we will introduce TorchShard and illustrate how to adopt it in our projects.
https://medium.com/pytorch/torchshard-a31fcbfdc354","Introduction to TorchShard A Lightweight Library for Scaling-up the Training Author: Kaiyu Yue, Incoming Ph.D. Student at the Computer Science Department of the University of Maryland, College Park TorchShard is a lightweight engine for slicing a PyTorch tensor into parallel shards. It can reduce GPU memory and scale up the training when the model has massive linear layers (e.g., BERT and GPT) or huge classes (millions). It has the same API design as PyTorch. In this blog, we will introduce TorchShard and illustrate how to adopt it in our projects. https://medium.com/pytorch/torchshard-a31fcbfdc354",#Pytorch	#Facebookai,,,,
"Mn Æ¡i cho e há»i náº¿u trÃªn báº±ng GPU thÃ¬ khi validate hoáº·c test ko dÃ¹ng gpu cÃ³ Ä‘Æ°á»£c khÃ´ng áº¡
E dÃ¹ng pytorch áº¡",Mn Æ¡i cho e há»i náº¿u trÃªn báº±ng GPU thÃ¬ khi validate hoáº·c test ko dÃ¹ng gpu cÃ³ Ä‘Æ°á»£c khÃ´ng áº¡ E dÃ¹ng pytorch áº¡,,,,,
"Há»i vá» bÃ i toÃ¡n OCR - Understanding document
ChÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cho em há»i:
Em Ä‘ang lÃ m má»™t bÃ i toÃ¡n vá» understanding document thÃ¬ em cÃ³ sá»­ dá»¥ng dá»‹ch vá»¥ OCR cá»§a Amazon Web Service Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c thÃ´ng tin trong áº£nh, nhÆ°ng mÃ  AWS pháº§n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho tiáº¿ng viá»‡t lÃ m khÃ´ng Ä‘Æ°á»£c tá»‘t, nÃªn má»™t sá»‘ kÃ½ tá»± nháº­n dáº¡ng bá»‹ sai. Káº¿t quáº£ tráº£ vá» cá»§a AWS lÃ  má»™t file json, gá»“m cÃ¡c Ä‘oáº¡n kÃ½ tá»± nháº­n dáº¡ng Ä‘Æ°á»£c.
Sau khi qua pháº§n xá»­ lÃ½ OCR, thÃ¬ em chuáº©n hÃ³a cÃ¡c Ä‘oáº¡n kÃ½ tá»± nÃ y vá» cÃ¡c thuá»™c tÃ­nh lÆ°u trá»¯ trÃªn database, vÃ­ dá»¥ nhÆ° Ä‘á»‹a chá»‰ vá» Ä‘á»‹a chá»‰. Tuy nhiÃªn, vÃ¬ khÃ´ng biáº¿t Ä‘oáº¡n kÃ½ tá»± Ä‘Ã³ á»Ÿ thuá»™c vÃ o thuá»™c tÃ­nh nÃ o, thÃ¬ em cÃ³ tiáº¿p cáº­n báº±ng cÃ¡ch sá»­ dá»¥ng if else Ä‘á»ƒ Ä‘Æ°a vá» Ä‘Ãºng thuá»™c tÃ­nh trong database. CÃ¡ch nÃ y thÃ¬ hÆ¡i cá»§ chuá»‘i.
Má»Ÿ rá»™ng ra, giáº£ sá»­ nhÆ° em muá»‘n tiáº¿p cáº­n bÃ i toÃ¡n trÃªn nhiá»u tÃ i liá»‡u dáº¡ng nhÆ° áº£nh bÃªn dÆ°á»›i, nghÄ©a lÃ  má»—i nÆ¡i cÃ³ kiá»ƒu tÃ i liá»‡u khÃ¡c nhau thÃ¬ nÃªn tiáº¿p cáº­n vÃ  xá»­ lÃ½ nhÆ° tháº¿ nÃ o Ä‘á»ƒ tá»•ng quÃ¡t hÃ³a bÃ i toÃ¡n lÃªn vÃ  pháº£i Ä‘á»¡ xá»­ lÃ½ báº±ng tay nhÆ° build má»™t mÃ´ hÃ¬nh rieng cho tá»«ng tÃ i liá»‡u áº¡ ?
Anh chá»‹ nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m xá»­ lÃ½ qua bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ chia sáº» cho em biáº¿t cÃ¡ch má»i ngÆ°á»i tiáº¿p cáº­n khÃ´ng ?
Em xin cáº£m Æ¡n.
áº¢nh dÆ°á»›i lÃ  minh há»a cho bÃ i toÃ¡n cá»§a em áº¡.","Há»i vá» bÃ i toÃ¡n OCR - Understanding document ChÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cho em há»i: Em Ä‘ang lÃ m má»™t bÃ i toÃ¡n vá» understanding document thÃ¬ em cÃ³ sá»­ dá»¥ng dá»‹ch vá»¥ OCR cá»§a Amazon Web Service Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c thÃ´ng tin trong áº£nh, nhÆ°ng mÃ  AWS pháº§n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho tiáº¿ng viá»‡t lÃ m khÃ´ng Ä‘Æ°á»£c tá»‘t, nÃªn má»™t sá»‘ kÃ½ tá»± nháº­n dáº¡ng bá»‹ sai. Káº¿t quáº£ tráº£ vá» cá»§a AWS lÃ  má»™t file json, gá»“m cÃ¡c Ä‘oáº¡n kÃ½ tá»± nháº­n dáº¡ng Ä‘Æ°á»£c. Sau khi qua pháº§n xá»­ lÃ½ OCR, thÃ¬ em chuáº©n hÃ³a cÃ¡c Ä‘oáº¡n kÃ½ tá»± nÃ y vá» cÃ¡c thuá»™c tÃ­nh lÆ°u trá»¯ trÃªn database, vÃ­ dá»¥ nhÆ° Ä‘á»‹a chá»‰ vá» Ä‘á»‹a chá»‰. Tuy nhiÃªn, vÃ¬ khÃ´ng biáº¿t Ä‘oáº¡n kÃ½ tá»± Ä‘Ã³ á»Ÿ thuá»™c vÃ o thuá»™c tÃ­nh nÃ o, thÃ¬ em cÃ³ tiáº¿p cáº­n báº±ng cÃ¡ch sá»­ dá»¥ng if else Ä‘á»ƒ Ä‘Æ°a vá» Ä‘Ãºng thuá»™c tÃ­nh trong database. CÃ¡ch nÃ y thÃ¬ hÆ¡i cá»§ chuá»‘i. Má»Ÿ rá»™ng ra, giáº£ sá»­ nhÆ° em muá»‘n tiáº¿p cáº­n bÃ i toÃ¡n trÃªn nhiá»u tÃ i liá»‡u dáº¡ng nhÆ° áº£nh bÃªn dÆ°á»›i, nghÄ©a lÃ  má»—i nÆ¡i cÃ³ kiá»ƒu tÃ i liá»‡u khÃ¡c nhau thÃ¬ nÃªn tiáº¿p cáº­n vÃ  xá»­ lÃ½ nhÆ° tháº¿ nÃ o Ä‘á»ƒ tá»•ng quÃ¡t hÃ³a bÃ i toÃ¡n lÃªn vÃ  pháº£i Ä‘á»¡ xá»­ lÃ½ báº±ng tay nhÆ° build má»™t mÃ´ hÃ¬nh rieng cho tá»«ng tÃ i liá»‡u áº¡ ? Anh chá»‹ nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m xá»­ lÃ½ qua bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ chia sáº» cho em biáº¿t cÃ¡ch má»i ngÆ°á»i tiáº¿p cáº­n khÃ´ng ? Em xin cáº£m Æ¡n. áº¢nh dÆ°á»›i lÃ  minh há»a cho bÃ i toÃ¡n cá»§a em áº¡.",,,,,
"Em chÃ o má»i ngÆ°á»i! E Ä‘ang code 1 model vá»›i 2 Ä‘áº§u vÃ o, 1 Ä‘áº§u vÃ o lÃ  áº£nh, 1 Ä‘áº§u vÃ o lÃ  cÃ¡c sá»‘. NhÆ°ng khi em cho cháº¡y thÃ¬ bá»‹ Ä‘á»©ng á»Ÿ Ä‘oáº¡n nÃ y vÃ  k cháº¡y tiáº¿p ná»¯a, k biáº¿t cÃ³ pháº£i do cÃ¡ch e load data Ä‘ang cÃ³ váº¥n Ä‘á» hay do model e viáº¿t Ä‘ang lá»—i, mong mn giÃºp e áº¡. Em cáº£m Æ¡n nhiá»u <3
(e dÃ¹ng keras nÃªn cÃ³ váº» nhÆ° load data kiá»ƒu multiple inputs hÆ¡i khÃ³ khÄƒn, xem trÃªn máº¡ng e tháº¥y ng ta chuyá»ƒn vá» dict rá»“i dÃ¹ng dataset.from_generator, chi tiáº¿t hÆ¡n á»Ÿ comment)","Em chÃ o má»i ngÆ°á»i! E Ä‘ang code 1 model vá»›i 2 Ä‘áº§u vÃ o, 1 Ä‘áº§u vÃ o lÃ  áº£nh, 1 Ä‘áº§u vÃ o lÃ  cÃ¡c sá»‘. NhÆ°ng khi em cho cháº¡y thÃ¬ bá»‹ Ä‘á»©ng á»Ÿ Ä‘oáº¡n nÃ y vÃ  k cháº¡y tiáº¿p ná»¯a, k biáº¿t cÃ³ pháº£i do cÃ¡ch e load data Ä‘ang cÃ³ váº¥n Ä‘á» hay do model e viáº¿t Ä‘ang lá»—i, mong mn giÃºp e áº¡. Em cáº£m Æ¡n nhiá»u <3 (e dÃ¹ng keras nÃªn cÃ³ váº» nhÆ° load data kiá»ƒu multiple inputs hÆ¡i khÃ³ khÄƒn, xem trÃªn máº¡ng e tháº¥y ng ta chuyá»ƒn vá» dict rá»“i dÃ¹ng dataset.from_generator, chi tiáº¿t hÆ¡n á»Ÿ comment)",,,,,
"Em chÃ o anh chá»‹ áº¡!
Hiá»‡n em Ä‘ang cÃ³ tháº¯c máº¯c khi dÃ¹ng thÆ° viá»‡n spacy áº¡. NhÆ° hÃ¬nh bÃªn dÆ°á»›i khi em dÃ¹ng char_span thÃ¬ ba chá»¯ Ä‘áº§u lÃ  ""Cáº§n"", ""bÃ¡n"", ""nhanh"" thÃ¬ cÃ³ thá»ƒ báº¯t Ä‘Æ°á»£c, nhÆ°ng tá»« Ä‘Ã³ vá» phÃ­a sau char_span luÃ´n return vá» None. Máº·c dÃ¹ index em Ä‘á»u Ä‘Ãºng nhÆ° s[14:17] lÃ  ""cÄƒn"", vÃ  s[18:20] lÃ  há»™, nhÆ°ng dÃ¹ng char_span vá»›i index Ä‘Ã³ thÃ¬ return lÃ  None. KhÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o gáº·p qua chÆ°a áº¡?
Em cáº£m Æ¡n áº¡.
#NLP","Em chÃ o anh chá»‹ áº¡! Hiá»‡n em Ä‘ang cÃ³ tháº¯c máº¯c khi dÃ¹ng thÆ° viá»‡n spacy áº¡. NhÆ° hÃ¬nh bÃªn dÆ°á»›i khi em dÃ¹ng char_span thÃ¬ ba chá»¯ Ä‘áº§u lÃ  ""Cáº§n"", ""bÃ¡n"", ""nhanh"" thÃ¬ cÃ³ thá»ƒ báº¯t Ä‘Æ°á»£c, nhÆ°ng tá»« Ä‘Ã³ vá» phÃ­a sau char_span luÃ´n return vá» None. Máº·c dÃ¹ index em Ä‘á»u Ä‘Ãºng nhÆ° s[14:17] lÃ  ""cÄƒn"", vÃ  s[18:20] lÃ  há»™, nhÆ°ng dÃ¹ng char_span vá»›i index Ä‘Ã³ thÃ¬ return lÃ  None. KhÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o gáº·p qua chÆ°a áº¡? Em cáº£m Æ¡n áº¡.",#NLP,,,,
"CÃ¡ch Ä‘Ã¢y 12h Ä‘á»“ng há»“ (lÃºc nÃ y 13:30 ngÃ y 16 thÃ¡ng 7 nÄƒm 2021, giá» GMT+7), cÃ³ 2 cÃ´ng bá»‘ ráº¥t quan trá»ng vá» viá»‡c á»©ng dá»¥ng AI trong viá»‡c predict 3D structures cá»§a cÃ¡c phÃ¢n tá»­ proteins.
1/ CÃ´ng bá»‘ thá»© nháº¥t cá»§a DeepMind trÃªn Nature: Highly accurate protein structure prediction with AlphaFold (https://www.nature.com/articles/s41586-021-03819-2); vá»›i model cÃ³ tÃªn lÃ  AlphaFold vÃ  Source code viáº¿t trÃªn JAX táº¡i Ä‘Ã¢y https://github.com/deepmind/alphafold
2/ VÃ  nghiÃªn cá»©u khÃ¡c Ä‘áº¿n tá»« MÄ© vá»›i bÃ i Ä‘Äƒng trÃªn táº­p san AAAS: Accurate prediction of protein structures and interactions using a three-track neural network (https://science.sciencemag.org/content/early/2021/07/14/science.abj8754); vá»›i model cÃ³ tÃªn RoseTTAFold vÃ  source code viáº¿t báº±ng PyTorch cÃ´ng bá»‘ táº¡i Ä‘Ã¢y: https://github.com/RosettaCommons/RoseTTAFold
Vá»›i nhá»¯ng thÃ nh tá»±u liÃªn ngÃ nh, hi vá»ng chÃºng ta sáº½ chá»©ng kiáº¿n nhiá»u Ä‘á»™t phÃ¡ trong cáº£ khoa há»c mÃ¡y tÃ­nh vÃ  sinh y há»c.","CÃ¡ch Ä‘Ã¢y 12h Ä‘á»“ng há»“ (lÃºc nÃ y 13:30 ngÃ y 16 thÃ¡ng 7 nÄƒm 2021, giá» GMT+7), cÃ³ 2 cÃ´ng bá»‘ ráº¥t quan trá»ng vá» viá»‡c á»©ng dá»¥ng AI trong viá»‡c predict 3D structures cá»§a cÃ¡c phÃ¢n tá»­ proteins. 1/ CÃ´ng bá»‘ thá»© nháº¥t cá»§a DeepMind trÃªn Nature: Highly accurate protein structure prediction with AlphaFold (https://www.nature.com/articles/s41586-021-03819-2); vá»›i model cÃ³ tÃªn lÃ  AlphaFold vÃ  Source code viáº¿t trÃªn JAX táº¡i Ä‘Ã¢y https://github.com/deepmind/alphafold 2/ VÃ  nghiÃªn cá»©u khÃ¡c Ä‘áº¿n tá»« MÄ© vá»›i bÃ i Ä‘Äƒng trÃªn táº­p san AAAS: Accurate prediction of protein structures and interactions using a three-track neural network (https://science.sciencemag.org/content/early/2021/07/14/science.abj8754); vá»›i model cÃ³ tÃªn RoseTTAFold vÃ  source code viáº¿t báº±ng PyTorch cÃ´ng bá»‘ táº¡i Ä‘Ã¢y: https://github.com/RosettaCommons/RoseTTAFold Vá»›i nhá»¯ng thÃ nh tá»±u liÃªn ngÃ nh, hi vá»ng chÃºng ta sáº½ chá»©ng kiáº¿n nhiá»u Ä‘á»™t phÃ¡ trong cáº£ khoa há»c mÃ¡y tÃ­nh vÃ  sinh y há»c.",,,,,
"ChÃ o cÃ¡c anh/chá»‹. Em cÃ³ má»™t tháº¯c máº¯c khÃ¡ cÆ¡ báº£n vá» feature scaling báº±ng normalization trong linear regression Ä‘a biáº¿n vá»›i gradient descent. 
Hiá»‡n táº¡i em Ä‘ang há»c course ML cá»§a GS Andrew Ng vÃ  tá»›i Ä‘Æ°á»£c tuáº§n 2 rá»“i (implement cÃ¡c hÃ m cho gradient descent).
Váº¥n Ä‘á» em Ä‘ang gáº·p hiá»‡n táº¡i lÃ  náº¿u nhÆ° em khÃ´ng normalize táº­p dá»¯ liá»‡u thÃ¬ GD cÃ³ thá»ƒ converge nhÆ° bÃ¬nh thÆ°á»ng, cÃ²n náº¿u nhÆ° em cÃ³ normalize thÃ¬ GD láº¡i khÃ´ng thá»ƒ converge Ä‘Æ°á»£c. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  váº¥n Ä‘á» náº±m á»Ÿ hÃ m featureNormalize, nhÆ°ng em láº¡i khÃ´ng hiá»ƒu Ä‘Æ°á»£c lÃ  nÃ³ sai á»Ÿ Ä‘Ã¢u áº¡.
Em cÃ³ Ä‘Ã­nh kÃ¨m 2 Ä‘á»“ thá»‹ biá»ƒu diá»…n giÃ¡ trá»‹ cost function sau má»—i iteration cho 2 trÆ°á»ng há»£p cÃ³ vÃ  khÃ´ng cÃ³ normalization áº¡.
ÄÃ¢y lÃ  code cá»§a em: https://github.com/hungngocphat01/MachineLearning-AndrewNg-Coursera/tree/master/ex1-octave","ChÃ o cÃ¡c anh/chá»‹. Em cÃ³ má»™t tháº¯c máº¯c khÃ¡ cÆ¡ báº£n vá» feature scaling báº±ng normalization trong linear regression Ä‘a biáº¿n vá»›i gradient descent. Hiá»‡n táº¡i em Ä‘ang há»c course ML cá»§a GS Andrew Ng vÃ  tá»›i Ä‘Æ°á»£c tuáº§n 2 rá»“i (implement cÃ¡c hÃ m cho gradient descent). Váº¥n Ä‘á» em Ä‘ang gáº·p hiá»‡n táº¡i lÃ  náº¿u nhÆ° em khÃ´ng normalize táº­p dá»¯ liá»‡u thÃ¬ GD cÃ³ thá»ƒ converge nhÆ° bÃ¬nh thÆ°á»ng, cÃ²n náº¿u nhÆ° em cÃ³ normalize thÃ¬ GD láº¡i khÃ´ng thá»ƒ converge Ä‘Æ°á»£c. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  váº¥n Ä‘á» náº±m á»Ÿ hÃ m featureNormalize, nhÆ°ng em láº¡i khÃ´ng hiá»ƒu Ä‘Æ°á»£c lÃ  nÃ³ sai á»Ÿ Ä‘Ã¢u áº¡. Em cÃ³ Ä‘Ã­nh kÃ¨m 2 Ä‘á»“ thá»‹ biá»ƒu diá»…n giÃ¡ trá»‹ cost function sau má»—i iteration cho 2 trÆ°á»ng há»£p cÃ³ vÃ  khÃ´ng cÃ³ normalization áº¡. ÄÃ¢y lÃ  code cá»§a em: https://github.com/hungngocphat01/MachineLearning-AndrewNg-Coursera/tree/master/ex1-octave",,,,,
"Há»i vá» bÃ i toÃ¡n Regression.
Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang thá»±c hiá»‡n má»™t bÃ i toÃ¡n kháº£o sÃ¡t, dá»±a vÃ o sá»‘ liá»‡u Ä‘áº§u vÃ o Ä‘á»ƒ xÃ¢y dá»±ng nÃªn má»™t hÃ m sá»‘.
- Em Ä‘ang tháº¯c máº¯c lÃ  trong Machine Learning mÃ¬nh cÃ²n dáº¡ng hÃ m há»“i quy nÃ o ngoÃ i há»“i quy tuyáº¿n tÃ­nh, phi tuyáº¿n khÃ´ng áº¡.
- NgoÃ i phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a trÆ°á»›c khi huáº¥n luyá»‡n Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c thÃ¬ cÃ²n phÆ°Æ¡ng phÃ¡p nÃ o khÃ´ng áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i!","Há»i vá» bÃ i toÃ¡n Regression. Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang thá»±c hiá»‡n má»™t bÃ i toÃ¡n kháº£o sÃ¡t, dá»±a vÃ o sá»‘ liá»‡u Ä‘áº§u vÃ o Ä‘á»ƒ xÃ¢y dá»±ng nÃªn má»™t hÃ m sá»‘. - Em Ä‘ang tháº¯c máº¯c lÃ  trong Machine Learning mÃ¬nh cÃ²n dáº¡ng hÃ m há»“i quy nÃ o ngoÃ i há»“i quy tuyáº¿n tÃ­nh, phi tuyáº¿n khÃ´ng áº¡. - NgoÃ i phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a trÆ°á»›c khi huáº¥n luyá»‡n Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c thÃ¬ cÃ²n phÆ°Æ¡ng phÃ¡p nÃ o khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 5/2021 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 5/2021 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
Thong tin tao tu dong qua AI cua Bao Lao Dong,Thong tin tao tu dong qua AI cua Bao Lao Dong,,,,,
"Lá»œI KÃŠU Gá»ŒI GÃ“P 5000 TIáº¾NG HO, GIÃšP A.I. PHÃT HIá»†N Sá»šM NGÆ¯á»œI Máº®C COVID
HÃ£y giÃºp cÃ¡c chuyÃªn gia chia sáº» thÃ´ng Ä‘iá»‡p nÃ y!
NgÆ°á»i dÃ¢n Viá»‡t Nam thuá»™c Ä‘á»‘i tÆ°á»£ng F0-F1-F2-F3 thu Ã¢m theo cÃº phÃ¡p:
1. TÃ´i tin mÃ¬nh lÃ  F...
2. (ho 4-5 tiáº¿ng)
gá»­i vÃ o NhÃ³m Zalo cá»•ng tiáº¿p nháº­n dá»¯ liá»‡u: bit.ly/dulieutiengho
Con ngÆ°á»i cÃ³ thá»ƒ khÃ´ng phÃ¡t hiá»‡n ra mÃ¬nh máº¯c Covid cho Ä‘áº¿n khi cÃ³ triá»‡u chá»©ng nhÆ° ho, sá»‘tâ€¦ hay táº­n Ä‘áº¿n khi Ä‘Æ°á»£c xÃ©t nghiá»‡m bá»Ÿi cÆ¡ quan y táº¿. NhÆ°ng cÃ´ng nghá»‡ A.I cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³.
NghiÃªn cá»©u tá»« Äáº¡i há»c MIT cho biáº¿t khi virus má»›i xÃ¢m nháº­p cÆ¡ thá»ƒ chÃºng chÆ°a xÃ¢m nháº­p Ä‘á»§ sÃ¢u Ä‘á»ƒ táº¡o ra cÃ¡c triá»‡u chá»©ng nhÆ° sá»‘t hay ho nhÆ°ng Ä‘Ã£ gÃ¢y ra nhá»¯ng tá»•n thÆ°Æ¡ng nhá» vÃ  nháº¹ trong phá»•i. Khi Ä‘Æ°á»£c yÃªu cáº§u cá»‘ tÃ¬nh ho, phÃ¢n tÃ­ch tiáº¿ng ho nÃ y cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c sá»± hiá»‡n diá»‡n cá»§a virus. Thuáº­t toÃ¡n trÃ­ tuá»‡ nhÃ¢n táº¡o sáº½ nghe hÃ ng ngÃ n máº«u tiáº¿ng ho, qua Ä‘Ã³, phÃ¢n tÃ­ch vÃ  lá»c Ä‘Æ°á»£c nhá»¯ng tÃ­n hiá»‡u mÃ  tai ngÆ°á»i khÃ´ng nghe khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c, vá»›i tá»· lá»‡ chÃ­nh xÃ¡c lÃªn Ä‘áº¿n 97% (chá»‰ sá»‘ AUC, theo bÃ¡o cÃ¡o cá»§a MIT).
Suá»‘t 2 thÃ¡ng qua, hÆ¡n 1000 chuyÃªn gia cÃ´ng nghá»‡, chuyÃªn gia y táº¿ vÃ  cÃ¡c TNV cá»§a dá»± Ã¡n AICOVIDVN Ä‘Ã£ xÃ¢y dá»±ng ra má»™t Giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  huáº¥n luyá»‡n chÃº AI nÃ y nháº­n diá»‡n tiáº¿ng ho. Hiá»‡n tá»‰ lá»‡ phÃ¡t hiá»‡n Ä‘Ãºng Ä‘Ã£ lÃªn Ä‘áº¿n 90%.
AICOVIDVN kÃªu gá»i bÃ  con cáº£ nÆ°á»›c, nhá»¯ng ai cÃ³ ngÆ°á»i thÃ¢n báº¡n bÃ¨ khÃ´ng may náº±m trong diá»‡n F0-F1-F2-F3, hÃ£y Ä‘Ã³ng gÃ³p â€œtiáº¿ng ho"" cá»§a mÃ¬nh, Ä‘á»ƒ dá»± Ã¡n nhanh chÃ³ng Ä‘áº¡t Ä‘Æ°á»£c thÃªm tá»‘i thiá»ƒu 5000 tiáº¿ng ho, náº¡p vÃ o tiáº¿p tá»¥c hoÃ n thiá»‡n há»‡ thá»‘ng. LÆ°á»£ng dá»¯ liá»‡u cÃ ng nhiá»u, AI Engine cÃ³ thá»ƒ cháº©n Ä‘oÃ¡n thÃ´ng minh hÆ¡n, ká»³ vá»ng Ä‘á»™ chÃ­nh xÃ¡c trÃªn 90%.
Sau khi hoÃ n thÃ nh bá»™ dá»¯ liá»‡u vÃ  Ä‘Ã o táº¡o, AI Engine Ä‘Æ°á»£c dá»± Ã¡n liÃªn há»‡, chuyá»ƒn giao cho Ban chá»‰ Ä‘áº¡o Quá»‘c gia PhÃ²ng chá»‘ng dá»‹ch Covid-19 nháº±m phá»¥c vá»¥ cÃ´ng tÃ¡c cháº©n Ä‘oÃ¡n qua Robocall trÃªn toÃ n quá»‘c.
CÃ´ng cá»¥ nÃ y ra Ä‘á»i cÃ³ thá»ƒ giÃºp phÃ¡t hiá»‡n Ä‘Æ°á»£c ca bá»‡nh á»Ÿ nhiá»u giai Ä‘oáº¡n khÃ¡c nhau, ká»ƒ cáº£ khi chÆ°a cÃ³ triá»‡u chá»©ng. Tá»« Ä‘Ã³ tÃ¬m ra nhá»¯ng ngÆ°á»i cÃ³ virus Ä‘ang cÃ²n láº«n trong cá»™ng Ä‘á»“ng, giÃºp nhanh chÃ³ng khoanh vÃ¹ng dá»‹ch, giáº£m táº£i cho y bÃ¡c sÄ© vÃ  cÃ¡c cÃ¡n bá»™ tuyáº¿n Ä‘áº§u.
HÃ£y chia sáº» ná»™i dung nÃ y!
---
Cá» Váº¤N & Báº¢O TRá»¢ Dá»° ÃN
Anh Tráº§n Anh DÅ©ng, Founder & CEO, MOG Group
Anh ÄÃ o XuÃ¢n HoÃ ng, Founder & CEO, Monkey Junior
Anh HÃ¹ng Tráº§n, Founder & CTO, GotIt
Anh Lá»£i LÆ°u, Founder & CEO, Kyber Network
Anh NhÃ¢n Nguyá»…n, Angel Investor
Anh Nguyá»…n HoÃ nh Tiáº¿n, CEO, Seedcom
Anh Thá»©c VÅ©, Founder & CEO, OhmniLabs
Anh Pháº¡m Minh Tuáº¥n, Chairman, TFI Group
NHÃ‚N Sá»° ÄIá»€U PHá»I
Tiáº¿n sÄ© VÅ© XuÃ¢n SÆ¡n - Postdoctoral Fellow @ UMU, Co-founder of DopikAI Lab & AIHUB.VN
Tiáº¿n sÄ© VÅ© Há»¯u Tiá»‡p - Machine Learning Engineer at Google, founder of MLCB.
Tiáº¿n sÄ© Harry Nguyen - Asst. Prof. ÄH Glasgow, Co-founder of AIHUB.VN
NguyÃªÌƒn ThuÌ€y Trinh, AI Researcher
Anh LÃª CÃ´ng ThÃ nh - Chairman & CEO at InfoRe Technology; Co-Founder/Producer at Dataset.vn
Tiáº¿n sÄ© Pháº¡m Minh Tuáº¥n - Chairman, TFI Group
Anh HÆ°ng LÃª, Äiá»u phá»‘i Dá»± Ã¡n
Chá»‹ Trang BÃ¹i, Äiá»u phá»‘i Äá»‘i ngoáº¡i
Chá»‹ Thu HÃ , Äiá»u phá»‘i Marketing
Chá»‹ Báº¡ch DÆ°Æ¡ng, Äiá»u phá»‘i Truyá»n thÃ´ng
CÃ¹ng hÃ ng ngÃ n cÃ¡n bá»™, chuyÃªn gia Ä‘ang tÃ¬nh nguyá»‡n Ä‘Ã³ng gÃ³p cho dá»± Ã¡n
Trang thÃ´ng tin chÃ­nh thá»©c
Báº£n giá»›i thiá»‡u dá»± Ã¡n AICOVIDVN bit.ly/aicovidvn0
Fanpage https://www.facebook.com/aicovn
Group: https://www.facebook.com/groups/1264976217251463
 â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  Tiep VuHuu.","Lá»œI KÃŠU Gá»ŒI GÃ“P 5000 TIáº¾NG HO, GIÃšP A.I. PHÃT HIá»†N Sá»šM NGÆ¯á»œI Máº®C COVID HÃ£y giÃºp cÃ¡c chuyÃªn gia chia sáº» thÃ´ng Ä‘iá»‡p nÃ y! NgÆ°á»i dÃ¢n Viá»‡t Nam thuá»™c Ä‘á»‘i tÆ°á»£ng F0-F1-F2-F3 thu Ã¢m theo cÃº phÃ¡p: 1. TÃ´i tin mÃ¬nh lÃ  F... 2. (ho 4-5 tiáº¿ng) gá»­i vÃ o NhÃ³m Zalo cá»•ng tiáº¿p nháº­n dá»¯ liá»‡u: bit.ly/dulieutiengho Con ngÆ°á»i cÃ³ thá»ƒ khÃ´ng phÃ¡t hiá»‡n ra mÃ¬nh máº¯c Covid cho Ä‘áº¿n khi cÃ³ triá»‡u chá»©ng nhÆ° ho, sá»‘tâ€¦ hay táº­n Ä‘áº¿n khi Ä‘Æ°á»£c xÃ©t nghiá»‡m bá»Ÿi cÆ¡ quan y táº¿. NhÆ°ng cÃ´ng nghá»‡ A.I cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³. NghiÃªn cá»©u tá»« Äáº¡i há»c MIT cho biáº¿t khi virus má»›i xÃ¢m nháº­p cÆ¡ thá»ƒ chÃºng chÆ°a xÃ¢m nháº­p Ä‘á»§ sÃ¢u Ä‘á»ƒ táº¡o ra cÃ¡c triá»‡u chá»©ng nhÆ° sá»‘t hay ho nhÆ°ng Ä‘Ã£ gÃ¢y ra nhá»¯ng tá»•n thÆ°Æ¡ng nhá» vÃ  nháº¹ trong phá»•i. Khi Ä‘Æ°á»£c yÃªu cáº§u cá»‘ tÃ¬nh ho, phÃ¢n tÃ­ch tiáº¿ng ho nÃ y cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c sá»± hiá»‡n diá»‡n cá»§a virus. Thuáº­t toÃ¡n trÃ­ tuá»‡ nhÃ¢n táº¡o sáº½ nghe hÃ ng ngÃ n máº«u tiáº¿ng ho, qua Ä‘Ã³, phÃ¢n tÃ­ch vÃ  lá»c Ä‘Æ°á»£c nhá»¯ng tÃ­n hiá»‡u mÃ  tai ngÆ°á»i khÃ´ng nghe khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c, vá»›i tá»· lá»‡ chÃ­nh xÃ¡c lÃªn Ä‘áº¿n 97% (chá»‰ sá»‘ AUC, theo bÃ¡o cÃ¡o cá»§a MIT). Suá»‘t 2 thÃ¡ng qua, hÆ¡n 1000 chuyÃªn gia cÃ´ng nghá»‡, chuyÃªn gia y táº¿ vÃ  cÃ¡c TNV cá»§a dá»± Ã¡n AICOVIDVN Ä‘Ã£ xÃ¢y dá»±ng ra má»™t Giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  huáº¥n luyá»‡n chÃº AI nÃ y nháº­n diá»‡n tiáº¿ng ho. Hiá»‡n tá»‰ lá»‡ phÃ¡t hiá»‡n Ä‘Ãºng Ä‘Ã£ lÃªn Ä‘áº¿n 90%. AICOVIDVN kÃªu gá»i bÃ  con cáº£ nÆ°á»›c, nhá»¯ng ai cÃ³ ngÆ°á»i thÃ¢n báº¡n bÃ¨ khÃ´ng may náº±m trong diá»‡n F0-F1-F2-F3, hÃ£y Ä‘Ã³ng gÃ³p â€œtiáº¿ng ho"" cá»§a mÃ¬nh, Ä‘á»ƒ dá»± Ã¡n nhanh chÃ³ng Ä‘áº¡t Ä‘Æ°á»£c thÃªm tá»‘i thiá»ƒu 5000 tiáº¿ng ho, náº¡p vÃ o tiáº¿p tá»¥c hoÃ n thiá»‡n há»‡ thá»‘ng. LÆ°á»£ng dá»¯ liá»‡u cÃ ng nhiá»u, AI Engine cÃ³ thá»ƒ cháº©n Ä‘oÃ¡n thÃ´ng minh hÆ¡n, ká»³ vá»ng Ä‘á»™ chÃ­nh xÃ¡c trÃªn 90%. Sau khi hoÃ n thÃ nh bá»™ dá»¯ liá»‡u vÃ  Ä‘Ã o táº¡o, AI Engine Ä‘Æ°á»£c dá»± Ã¡n liÃªn há»‡, chuyá»ƒn giao cho Ban chá»‰ Ä‘áº¡o Quá»‘c gia PhÃ²ng chá»‘ng dá»‹ch Covid-19 nháº±m phá»¥c vá»¥ cÃ´ng tÃ¡c cháº©n Ä‘oÃ¡n qua Robocall trÃªn toÃ n quá»‘c. CÃ´ng cá»¥ nÃ y ra Ä‘á»i cÃ³ thá»ƒ giÃºp phÃ¡t hiá»‡n Ä‘Æ°á»£c ca bá»‡nh á»Ÿ nhiá»u giai Ä‘oáº¡n khÃ¡c nhau, ká»ƒ cáº£ khi chÆ°a cÃ³ triá»‡u chá»©ng. Tá»« Ä‘Ã³ tÃ¬m ra nhá»¯ng ngÆ°á»i cÃ³ virus Ä‘ang cÃ²n láº«n trong cá»™ng Ä‘á»“ng, giÃºp nhanh chÃ³ng khoanh vÃ¹ng dá»‹ch, giáº£m táº£i cho y bÃ¡c sÄ© vÃ  cÃ¡c cÃ¡n bá»™ tuyáº¿n Ä‘áº§u. HÃ£y chia sáº» ná»™i dung nÃ y! --- Cá» Váº¤N & Báº¢O TRá»¢ Dá»° ÃN Anh Tráº§n Anh DÅ©ng, Founder & CEO, MOG Group Anh ÄÃ o XuÃ¢n HoÃ ng, Founder & CEO, Monkey Junior Anh HÃ¹ng Tráº§n, Founder & CTO, GotIt Anh Lá»£i LÆ°u, Founder & CEO, Kyber Network Anh NhÃ¢n Nguyá»…n, Angel Investor Anh Nguyá»…n HoÃ nh Tiáº¿n, CEO, Seedcom Anh Thá»©c VÅ©, Founder & CEO, OhmniLabs Anh Pháº¡m Minh Tuáº¥n, Chairman, TFI Group NHÃ‚N Sá»° ÄIá»€U PHá»I Tiáº¿n sÄ© VÅ© XuÃ¢n SÆ¡n - Postdoctoral Fellow @ UMU, Co-founder of DopikAI Lab & AIHUB.VN Tiáº¿n sÄ© VÅ© Há»¯u Tiá»‡p - Machine Learning Engineer at Google, founder of MLCB. Tiáº¿n sÄ© Harry Nguyen - Asst. Prof. ÄH Glasgow, Co-founder of AIHUB.VN NguyÃªÌƒn ThuÌ€y Trinh, AI Researcher Anh LÃª CÃ´ng ThÃ nh - Chairman & CEO at InfoRe Technology; Co-Founder/Producer at Dataset.vn Tiáº¿n sÄ© Pháº¡m Minh Tuáº¥n - Chairman, TFI Group Anh HÆ°ng LÃª, Äiá»u phá»‘i Dá»± Ã¡n Chá»‹ Trang BÃ¹i, Äiá»u phá»‘i Äá»‘i ngoáº¡i Chá»‹ Thu HÃ , Äiá»u phá»‘i Marketing Chá»‹ Báº¡ch DÆ°Æ¡ng, Äiá»u phá»‘i Truyá»n thÃ´ng CÃ¹ng hÃ ng ngÃ n cÃ¡n bá»™, chuyÃªn gia Ä‘ang tÃ¬nh nguyá»‡n Ä‘Ã³ng gÃ³p cho dá»± Ã¡n Trang thÃ´ng tin chÃ­nh thá»©c Báº£n giá»›i thiá»‡u dá»± Ã¡n AICOVIDVN bit.ly/aicovidvn0 Fanpage https://www.facebook.com/aicovn Group: https://www.facebook.com/groups/1264976217251463 â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  Tiep VuHuu.",,,,,
"Here is an implementation for QuickDraw - an online game developed by Google, combined with AirGesture - a simple gesture recognition application, written in Tensorflow
Source code: https://github.com/uvipen/QuickDraw-AirGesture-tensorflow
Demo: https://youtu.be/DkvMheb_iMc
QuickDraw lÃ  1 bá»™ dataset vá» drawings ráº¥t ná»•i tiáº¿ng cá»§a Google, Ä‘Æ°á»£c thu tháº­p dá»±a trÃªn báº£n váº½ tay cá»§a hÆ¡n 15 triá»‡u ngÆ°á»i. ÄÃ¢y cÅ©ng Ä‘á»“ng thá»i lÃ  tÃªn 1 game online Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi Google dá»±a trÃªn bá»™ dataset nÃ y. CÃ¡ nhÃ¢n mÃ¬nh Ä‘Ã¡nh giÃ¡ Ä‘Ã¢y lÃ  1 bá»™ dataset ráº¥t thÃº vá»‹, vÃ  phÃ¹ há»£p vá»›i nhá»¯ng ngÆ°á»i má»›i tÃ¬m hiá»ƒu vá» AI cÅ©ng nhÆ° nhá»¯ng ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m lÃ¢u nÄƒm. ÄÃ¢y lÃ  project cÃ¡ nhÃ¢n cá»§a mÃ¬nh, sá»­ dá»¥ng 1 pháº§n nhá» trong bá»™ dataset, káº¿t há»£p vá»›i 1 á»©ng dá»¥ng nháº­n dáº¡ng cá»­ chá»‰ (gesture recognition) Ä‘á»ƒ táº¡o ra 1 app cho phÃ©p ngÆ°á»i dÃ¹ng váº½ 1 object báº¥t kÃ¬, vÃ  AI model sáº½ dá»± Ä‘oÃ¡n object Ä‘Æ°á»£c váº½ lÃ  gÃ¬. Let's enjoy my QuickDraw + AirGesture app","Here is an implementation for QuickDraw - an online game developed by Google, combined with AirGesture - a simple gesture recognition application, written in Tensorflow Source code: https://github.com/uvipen/QuickDraw-AirGesture-tensorflow Demo: https://youtu.be/DkvMheb_iMc QuickDraw lÃ  1 bá»™ dataset vá» drawings ráº¥t ná»•i tiáº¿ng cá»§a Google, Ä‘Æ°á»£c thu tháº­p dá»±a trÃªn báº£n váº½ tay cá»§a hÆ¡n 15 triá»‡u ngÆ°á»i. ÄÃ¢y cÅ©ng Ä‘á»“ng thá»i lÃ  tÃªn 1 game online Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi Google dá»±a trÃªn bá»™ dataset nÃ y. CÃ¡ nhÃ¢n mÃ¬nh Ä‘Ã¡nh giÃ¡ Ä‘Ã¢y lÃ  1 bá»™ dataset ráº¥t thÃº vá»‹, vÃ  phÃ¹ há»£p vá»›i nhá»¯ng ngÆ°á»i má»›i tÃ¬m hiá»ƒu vá» AI cÅ©ng nhÆ° nhá»¯ng ngÆ°á»i Ä‘Ã£ cÃ³ kinh nghiá»‡m lÃ¢u nÄƒm. ÄÃ¢y lÃ  project cÃ¡ nhÃ¢n cá»§a mÃ¬nh, sá»­ dá»¥ng 1 pháº§n nhá» trong bá»™ dataset, káº¿t há»£p vá»›i 1 á»©ng dá»¥ng nháº­n dáº¡ng cá»­ chá»‰ (gesture recognition) Ä‘á»ƒ táº¡o ra 1 app cho phÃ©p ngÆ°á»i dÃ¹ng váº½ 1 object báº¥t kÃ¬, vÃ  AI model sáº½ dá»± Ä‘oÃ¡n object Ä‘Æ°á»£c váº½ lÃ  gÃ¬. Let's enjoy my QuickDraw + AirGesture app",,,,,
"Hi má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» nhÆ° sau.
MÃ¬nh cÃ³ data tá»« 3 nguá»“n khÃ¡c nhau (A, B, C). Má»—i nguá»“n Ä‘Æ°á»£c lÆ°u trong 1 table riÃªng. Má»—i dÃ²ng á»Ÿ má»—i table tÆ°Æ¡ng á»©ng vá»›i 1 user, tuy nhiÃªn khÃ´ng pháº£i lÃºc nÃ o cÅ©ng cÃ³ Ä‘á»§ dá»¯ liá»‡u cho cÃ¡c cá»™t trong table. VÃ­ dá»¥ nhÆ° á»Ÿ báº£ng A chá»‰ cÃ³ thÃ´ng tin vá» cÃ´ng ty, tÃªn, vá»‹ trÃ­ vÃ  email.
CÃ¢u há»i cá»§a mÃ¬nh lÃ  vá»›i 1 user vÃ­ dá»¥ nhÆ° Samuels Jobs trong hÃ¬nh, cÃ³ Ä‘áº¿n 3 báº£ng cÃ¹ng lÆ°u thÃ´ng tin vá» ngÆ°á»i nÃ y, lÃ m sao Ä‘á»ƒ gá»™p thÃ´ng tin tá»« 3 nÆ¡i vá», Ä‘áº·c biá»‡t lÃ  khi tÃªn ngÆ°á»i Ä‘Ã³ khÃ´ng Ä‘Æ°á»£c ghi Ä‘áº§y Ä‘á»§ (Sam J. hay Sam Jobs táº¥t cáº£ Ä‘á»u lÃ  1 ngÆ°á»i Samuels Jobs)
Cáº£m Æ¡n má»i ngÆ°á»i.","Hi má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» nhÆ° sau. MÃ¬nh cÃ³ data tá»« 3 nguá»“n khÃ¡c nhau (A, B, C). Má»—i nguá»“n Ä‘Æ°á»£c lÆ°u trong 1 table riÃªng. Má»—i dÃ²ng á»Ÿ má»—i table tÆ°Æ¡ng á»©ng vá»›i 1 user, tuy nhiÃªn khÃ´ng pháº£i lÃºc nÃ o cÅ©ng cÃ³ Ä‘á»§ dá»¯ liá»‡u cho cÃ¡c cá»™t trong table. VÃ­ dá»¥ nhÆ° á»Ÿ báº£ng A chá»‰ cÃ³ thÃ´ng tin vá» cÃ´ng ty, tÃªn, vá»‹ trÃ­ vÃ  email. CÃ¢u há»i cá»§a mÃ¬nh lÃ  vá»›i 1 user vÃ­ dá»¥ nhÆ° Samuels Jobs trong hÃ¬nh, cÃ³ Ä‘áº¿n 3 báº£ng cÃ¹ng lÆ°u thÃ´ng tin vá» ngÆ°á»i nÃ y, lÃ m sao Ä‘á»ƒ gá»™p thÃ´ng tin tá»« 3 nÆ¡i vá», Ä‘áº·c biá»‡t lÃ  khi tÃªn ngÆ°á»i Ä‘Ã³ khÃ´ng Ä‘Æ°á»£c ghi Ä‘áº§y Ä‘á»§ (Sam J. hay Sam Jobs táº¥t cáº£ Ä‘á»u lÃ  1 ngÆ°á»i Samuels Jobs) Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"#hoidap
TÃ¬nh cá» lÆ°á»›t tháº¥y video nÃ y, má»i ngÆ°á»i cÃ³ hÆ°á»›ng tiáº¿p cáº­n hay doc gÃ¬ liÃªn quan Ä‘áº¿n bÃ i toÃ¡n kiá»ƒu AI singer nÃ y khÃ´ng áº¡?
Ai giáº£i thÃ­ch cho em vá» cÃ¡ch train cho loáº¡i bÃ i toÃ¡n nÃ y nhÆ° nÃ o Ä‘Æ°á»£c khÃ´ng áº¡?
Em xin cáº£m Æ¡n!","TÃ¬nh cá» lÆ°á»›t tháº¥y video nÃ y, má»i ngÆ°á»i cÃ³ hÆ°á»›ng tiáº¿p cáº­n hay doc gÃ¬ liÃªn quan Ä‘áº¿n bÃ i toÃ¡n kiá»ƒu AI singer nÃ y khÃ´ng áº¡? Ai giáº£i thÃ­ch cho em vá» cÃ¡ch train cho loáº¡i bÃ i toÃ¡n nÃ y nhÆ° nÃ o Ä‘Æ°á»£c khÃ´ng áº¡? Em xin cáº£m Æ¡n!",#hoidap,,,,
"BÃ i giáº£ng cá»§a MIT cho nhá»¯ng báº¡n muá»‘n nghiÃªn cá»©u á»©ng dá»¥ng ML/DL/AI vÃ o trong y há»c. https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-notes/index.htm
Ps1. Xin lÆ°u Ã½, domain chuyÃªn ngÃ nh lÃ  ráº¥t ráº¥t quan trá»ng. HÃ´m trÆ°á»›c cÃ³ má»™t bÃ¡c sÄ© challenge vá» Ä‘á»‹nh nghÄ©a ho/cough khi cÃ¡c báº¡n trong cá»™ng Ä‘á»“ng muá»‘n lÃ m á»©ng dá»¥ng AI cho cháº©n Ä‘oÃ¡n Covid tá»« tiáº¿ng ho.
Ps2. CÃ¡c nghiÃªn cá»©u á»©ng dá»¥ng trong y há»c cáº§n Ä‘Æ°á»£c thiáº¿t káº¿ nghiÃªn cá»©u ráº¥t ráº¥t nghiÃªm ngáº·t Ä‘á»ƒ thu vÃ  gÃ¡n nhÃ£n dá»¯ liá»‡u theo tiÃªu chuáº©n cá»§a tá»«ng hiá»‡p há»™i chuyÃªn ngÃ nh. Cháº¯c cháº¯n cÃ¡c báº¡n cÅ©ng ai â€œgarbage in, garbage outâ€","BÃ i giáº£ng cá»§a MIT cho nhá»¯ng báº¡n muá»‘n nghiÃªn cá»©u á»©ng dá»¥ng ML/DL/AI vÃ o trong y há»c. https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-notes/index.htm Ps1. Xin lÆ°u Ã½, domain chuyÃªn ngÃ nh lÃ  ráº¥t ráº¥t quan trá»ng. HÃ´m trÆ°á»›c cÃ³ má»™t bÃ¡c sÄ© challenge vá» Ä‘á»‹nh nghÄ©a ho/cough khi cÃ¡c báº¡n trong cá»™ng Ä‘á»“ng muá»‘n lÃ m á»©ng dá»¥ng AI cho cháº©n Ä‘oÃ¡n Covid tá»« tiáº¿ng ho. Ps2. CÃ¡c nghiÃªn cá»©u á»©ng dá»¥ng trong y há»c cáº§n Ä‘Æ°á»£c thiáº¿t káº¿ nghiÃªn cá»©u ráº¥t ráº¥t nghiÃªm ngáº·t Ä‘á»ƒ thu vÃ  gÃ¡n nhÃ£n dá»¯ liá»‡u theo tiÃªu chuáº©n cá»§a tá»«ng hiá»‡p há»™i chuyÃªn ngÃ nh. Cháº¯c cháº¯n cÃ¡c báº¡n cÅ©ng ai â€œgarbage in, garbage outâ€",,,,,
Mn cÃ³ thá»ƒ giáº£i thÃ­ch cÃ´ng dá»¥ng cá»§a tf.keras.layers.GlobalAveragePooling2D() giÃºp mÃ¬nh vs? Äá»c tÃ i liá»‡u mÃ  ko hiá»ƒu nÃ³ lÃ m cÃ¡i j? PhÃ¢n biá»‡t loss 'categorical_crossentropy' vs 'sparse_categorical_crossentropy',Mn cÃ³ thá»ƒ giáº£i thÃ­ch cÃ´ng dá»¥ng cá»§a tf.keras.layers.GlobalAveragePooling2D() giÃºp mÃ¬nh vs? Äá»c tÃ i liá»‡u mÃ  ko hiá»ƒu nÃ³ lÃ m cÃ¡i j? PhÃ¢n biá»‡t loss 'categorical_crossentropy' vs 'sparse_categorical_crossentropy',,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c! Em Ä‘ang há»c vá» model Auto Encoder nÃªn cÃ³ lÃ m má»™t bÃ i Fraud Detection. Em cÅ©ng lÃ m clip Ä‘á»ƒ cÃ¡c báº¡n má»›i há»c tham kháº£o thÃªm. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n!
Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o vÃ  admin duyá»‡t bÃ i áº¡!",KÃ­nh chÃ o cÃ¡c bÃ¡c! Em Ä‘ang há»c vá» model Auto Encoder nÃªn cÃ³ lÃ m má»™t bÃ i Fraud Detection. Em cÅ©ng lÃ m clip Ä‘á»ƒ cÃ¡c báº¡n má»›i há»c tham kháº£o thÃªm. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n! Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o vÃ  admin duyá»‡t bÃ i áº¡!,,,,,
"Dáº¡ em chÃ o anh chá»‹ vÃ  má»i ngÆ°á»i. Em Ä‘ang lÃ  sinh viÃªn, sáº¯p phÃ¢n chuyÃªn ngÃ nh, em dá»± Ä‘á»‹nh sáº½ chá»n CS vÃ  ML nÃªn cÃ³ tham kháº£o má»™t sá»‘ tÃ i liá»‡u vÃ  khÃ³a há»c free trÃªn máº¡ng tá»« Coursera, Geeks tá»›i Freecodecamp nhÆ°ng khÃ´ng biáº¿t Ä‘Ã¢u lÃ  phÃ¹ há»£p. NÃªn em xin phÃ©p cÃ¡c tiá»n bá»‘i Ä‘i trÆ°á»›c cho em há»i lÃ  má»›i báº¯t Ä‘áº§u thÃ¬ Ä‘á»c tÃ i liá»‡u hay há»c trang nÃ o vÃ  cÃ³ thá»ƒ cho em 1 roadmap Ä‘á»ƒ tham kháº£o khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c áº¡.","Dáº¡ em chÃ o anh chá»‹ vÃ  má»i ngÆ°á»i. Em Ä‘ang lÃ  sinh viÃªn, sáº¯p phÃ¢n chuyÃªn ngÃ nh, em dá»± Ä‘á»‹nh sáº½ chá»n CS vÃ  ML nÃªn cÃ³ tham kháº£o má»™t sá»‘ tÃ i liá»‡u vÃ  khÃ³a há»c free trÃªn máº¡ng tá»« Coursera, Geeks tá»›i Freecodecamp nhÆ°ng khÃ´ng biáº¿t Ä‘Ã¢u lÃ  phÃ¹ há»£p. NÃªn em xin phÃ©p cÃ¡c tiá»n bá»‘i Ä‘i trÆ°á»›c cho em há»i lÃ  má»›i báº¯t Ä‘áº§u thÃ¬ Ä‘á»c tÃ i liá»‡u hay há»c trang nÃ o vÃ  cÃ³ thá»ƒ cho em 1 roadmap Ä‘á»ƒ tham kháº£o khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c áº¡.",,,,,
#NLP Em chÃ o má»i ngÆ°á»i áº¡. CÃ³ cao nhÃ¢n nÃ o Ä‘Ã£ lÃ m vá» trÃ­ch xuáº¥t thuáº­t ngá»¯ trong vÄƒn báº£n tiáº¿ng viá»‡t rá»“i cho em xin Ã­t kinh nghiá»‡m áº¡. Trong suy nghÄ© cá»§a em thÃ¬ Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c thuáº­t ngá»¯ thÃ¬ mÃ¬nh cáº§n cÃ³ bá»™ data tiáº¿ng viá»‡t chá»©a thuáº­t ngá»¯ phÃ¢n theo cÃ¡c chuyÃªn ngÃ nh lÃ¬nh vá»±c Ä‘Ãºng k áº¡? nhÆ°ng em tÃ¬m k tháº¥y. Hay ai cÃ³ cÃ¡ch nÃ o khÃ¡c chá»‰ em vá»›i áº¡. Em cáº£m Æ¡n,Em chÃ o má»i ngÆ°á»i áº¡. CÃ³ cao nhÃ¢n nÃ o Ä‘Ã£ lÃ m vá» trÃ­ch xuáº¥t thuáº­t ngá»¯ trong vÄƒn báº£n tiáº¿ng viá»‡t rá»“i cho em xin Ã­t kinh nghiá»‡m áº¡. Trong suy nghÄ© cá»§a em thÃ¬ Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c thuáº­t ngá»¯ thÃ¬ mÃ¬nh cáº§n cÃ³ bá»™ data tiáº¿ng viá»‡t chá»©a thuáº­t ngá»¯ phÃ¢n theo cÃ¡c chuyÃªn ngÃ nh lÃ¬nh vá»±c Ä‘Ãºng k áº¡? nhÆ°ng em tÃ¬m k tháº¥y. Hay ai cÃ³ cÃ¡ch nÃ o khÃ¡c chá»‰ em vá»›i áº¡. Em cáº£m Æ¡n,#NLP,,,,
"Mn cho em há»i váº¥n Ä‘á» nÃ y vá»›i áº¡.
1. Chuyá»‡n lÃ  em nghe tháº§y em nÃ³i lÃ  chá»‰ cÃ³ ngÃ´n ngá»¯ C má»›i cháº¡y Ä‘Ã¡p á»©ng thá»i gian thá»±c Ä‘Æ°á»£c, váº­y trong Machine Learning sau mÃ¬nh khÃ´ng dÃ¹ng ngÃ´n ngá»¯ C Ä‘á»ƒ lÃ m mÃ  láº¡i dÃ¹ng Python áº¡. Do náº¿u dÃ¹ng Python thÃ¬ khi cho vÃ o thá»±c táº¿ thÃ¬ nÃ³ ko nhanh báº±ng C dc. Mong mn thÃ´ng cáº£m náº¿u cÃ¢u há»i cÃ³ hÆ¡i ngá»‘c áº¡.
2. Theo mn thÃ¬ dÃ¹ng trÃ¬nh biÃªn dá»‹ch nÃ o lÃ  tá»‘t nháº¥t vÃ  náº¿u sá»­ dá»¥ng Google Colab thÃ¬ cÃ³ á»•n k áº¡. Em cáº£m Æ¡n mn nhiá»u.","Mn cho em há»i váº¥n Ä‘á» nÃ y vá»›i áº¡. 1. Chuyá»‡n lÃ  em nghe tháº§y em nÃ³i lÃ  chá»‰ cÃ³ ngÃ´n ngá»¯ C má»›i cháº¡y Ä‘Ã¡p á»©ng thá»i gian thá»±c Ä‘Æ°á»£c, váº­y trong Machine Learning sau mÃ¬nh khÃ´ng dÃ¹ng ngÃ´n ngá»¯ C Ä‘á»ƒ lÃ m mÃ  láº¡i dÃ¹ng Python áº¡. Do náº¿u dÃ¹ng Python thÃ¬ khi cho vÃ o thá»±c táº¿ thÃ¬ nÃ³ ko nhanh báº±ng C dc. Mong mn thÃ´ng cáº£m náº¿u cÃ¢u há»i cÃ³ hÆ¡i ngá»‘c áº¡. 2. Theo mn thÃ¬ dÃ¹ng trÃ¬nh biÃªn dá»‹ch nÃ o lÃ  tá»‘t nháº¥t vÃ  náº¿u sá»­ dá»¥ng Google Colab thÃ¬ cÃ³ á»•n k áº¡. Em cáº£m Æ¡n mn nhiá»u.",,,,,
"chÃ o cÃ¡c bÃ¡c áº¡, e Ä‘ang há»c vá» Gradient Descent vÃ  cÃ³ má»™t chÃºt tháº¯c máº¯c nhá»:
táº¡i sao khoáº£ng delta thay Ä‘á»•i giá»¯a X(t) vÃ  X(T+1) láº¡i báº±ng Ä‘áº¡o hÃ m cá»§a hÃ m lr*f'(X(t)) áº¡?
báº£n cháº¥t thuáº­t toÃ¡n thÃ¬ hiá»ƒu nhÆ°ng Ä‘iá»ƒm nÃ y e váº«n chÆ°a thÃ´ng áº¡. Em cáº£m Æ¡n","chÃ o cÃ¡c bÃ¡c áº¡, e Ä‘ang há»c vá» Gradient Descent vÃ  cÃ³ má»™t chÃºt tháº¯c máº¯c nhá»: táº¡i sao khoáº£ng delta thay Ä‘á»•i giá»¯a X(t) vÃ  X(T+1) láº¡i báº±ng Ä‘áº¡o hÃ m cá»§a hÃ m lr*f'(X(t)) áº¡? báº£n cháº¥t thuáº­t toÃ¡n thÃ¬ hiá»ƒu nhÆ°ng Ä‘iá»ƒm nÃ y e váº«n chÆ°a thÃ´ng áº¡. Em cáº£m Æ¡n",,"#Q&A, #math",,,
"ChÃ o ace
MÃ¬nh má»›i há»c RL, nÃªn nhá» ace gÃ³p Ã½ giÃºp mÃ´ hÃ¬nh sau. MÃ¬nh cÃ³ 4 UAVs káº¿t ná»‘i vá»›i mobiles dÆ°á»›i máº·t Ä‘áº¥t cho video streaming. cÃ¡c users nÃ y di chuyá»ƒn ngáº«u nhiÃªn. Vá»›i mÃ´ hÃ¬nh nÃ y thÃ¬ mÃ¬nh nÃªn dÃ¹ng mÃ´ hÃ¬nh deep learning nÃ o phÃ¹ há»£p Ä‘á»ƒ Ä‘iá»u khiá»ƒn UAVs?
Xin chÃ¢n thÃ nh cáº£m Æ¡n","ChÃ o ace MÃ¬nh má»›i há»c RL, nÃªn nhá» ace gÃ³p Ã½ giÃºp mÃ´ hÃ¬nh sau. MÃ¬nh cÃ³ 4 UAVs káº¿t ná»‘i vá»›i mobiles dÆ°á»›i máº·t Ä‘áº¥t cho video streaming. cÃ¡c users nÃ y di chuyá»ƒn ngáº«u nhiÃªn. Vá»›i mÃ´ hÃ¬nh nÃ y thÃ¬ mÃ¬nh nÃªn dÃ¹ng mÃ´ hÃ¬nh deep learning nÃ o phÃ¹ há»£p Ä‘á»ƒ Ä‘iá»u khiá»ƒn UAVs? Xin chÃ¢n thÃ nh cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em muá»‘n xÃ³a vÃ¹ng mÃ u Ä‘á» vÃ  ná»‘i trá»±c tiáº¿p theo mÅ©i tÃªn máº§u xanh thÃ¬ cÃ³ cÃ¡ch nÃ o khÃ´ng áº¡. Em Ä‘Ã£ thá»­ nhiá»u cÃ¡ch mÃ  chÆ°a Ä‘Æ°á»£c áº¡, mong má»i ngÆ°á»i giÃºp Ä‘á»¡.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em muá»‘n xÃ³a vÃ¹ng mÃ u Ä‘á» vÃ  ná»‘i trá»±c tiáº¿p theo mÅ©i tÃªn máº§u xanh thÃ¬ cÃ³ cÃ¡ch nÃ o khÃ´ng áº¡. Em Ä‘Ã£ thá»­ nhiá»u cÃ¡ch mÃ  chÆ°a Ä‘Æ°á»£c áº¡, mong má»i ngÆ°á»i giÃºp Ä‘á»¡.",,,,,
"[HOT EVENT] Tá»”NG Káº¾T GIAI ÄOáº N 1 VÃ€ THUYáº¾T TRÃŒNH GIáº¢I PHÃP TRÃ TUá»† NHÃ‚N Táº O (AI): PHÃT HIá»†N COVID QUA TIáº¾NG HO Vá»šI GIáº¢I THÆ¯á»NG LÃŠN Tá»šI 115 TRIá»†U Äá»’NG ğŸ“£ğŸ“£ğŸ“£
ğŸ•™ Thá»i gian: 20:00-22:00 - Thá»© NÄƒm, 08 thÃ¡ng 7 2021 (giá» Viá»‡t Nam)
â˜‘ï¸ HÃ¬nh thá»©c: Livestream trá»±c tiáº¿p
â˜‘ï¸ Link tham gia vÃ o há»™i tháº£o trá»±c tuyáº¿n: https://zoom.us/j/96842982383
Tráº£i qua gáº§n 2 tuáº§n thá»­ thÃ¡ch, hÆ¡n 200 Ä‘á»™i thi cá»§a dá»± Ã¡n lÃ  nhá»¯ng chuyÃªn gia AI trÃªn kháº¯p Viá»‡t Nam cÃ¹ng vá»›i sá»± Ä‘á»“ng hÃ nh cá»§a nhiá»u Anh/Chá»‹ lÃ  quáº£n lÃ½ cáº¥p cao cá»§a cÃ¡c CÃ´ng ty/táº­p Ä‘oÃ n cÃ´ng nghá»‡ lá»›n Ä‘Ã£ báº¯t Ä‘áº§u hoÃ n thÃ nh cuá»™c Ä‘ua trong giai Ä‘oáº¡n 1 cá»§a dá»± Ã¡n - Giai Ä‘oáº¡n khá»Ÿi Ä‘á»™ng. Dá»± Ã¡n sáº½ cÃ³ má»™t buá»•i tá»•ng káº¿t vÃ  thuyáº¿t trÃ¬nh cÃ¡c giáº£i phÃ¡t cá»§a thÃ­ sinh trong tá»‘i nay (8/7/2021) vá»›i sá»± Ä‘á»“ng hÃ nh cÃ¹ng Ä‘á»™i ngÅ© BGK cá»±c ""HOT"" trong giá»›i cÃ´ng nghá»‡:
1, Tiáº¿n sÄ© Pháº¡m Minh Tuáº¥n - Chairman, TFI Group
2, Tiáº¿n sÄ© VÅ© XuÃ¢n SÆ¡n - Postdoctoral Fellow @ UMU, Co-founder of DopikAI Lab & AIHUB.VN
3, Tiáº¿n sÄ© VÅ© Há»¯u Tiá»‡p - Machine Learning Engineer at Google, founder of MLCB.
4, Anh LÃª CÃ´ng ThÃ nh - Chairman & CEO at InfoRe Technology; Co-Founder/Producer at Dataset.vn
5, Tiáº¿n sÄ© Harry Nguyen - Asst. Prof. ÄH Glasgow, Co-founder of AIHUB.VN
ğŸ‘‰Giá»›i thiá»‡u vá» cuá»™c thi SÃ¡ng táº¡o giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡o (AI): Nháº­n dáº¡ng Covid qua tiáº¿ng ho
""AI Covid"" lÃ  dá»± Ã¡n cá»™ng Ä‘á»“ng vá»›i má»¥c tiÃªu lÃ m ra Ä‘Æ°á»£c giáº£i phÃ¡p TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI) Ä‘á»ƒ cÃ³ thá»ƒ phÃ¡t hiá»‡n Covid 19 thÃ´ng qua tiáº¿ng ho. Cuá»™c thi Ä‘Æ°á»£c chÃ­nh thá»©c phÃ¡t Ä‘á»™ng trong khuÃ´n khá»• chÆ°Æ¡ng trÃ¬nh Táº­p huáº¥n â€œÄá»™i hÃ¬nh tÃ¬nh nguyá»‡n sá»‘â€ vÃ  â€œCÃ¢u láº¡c bá»™ Ä‘á»•i má»›i sÃ¡ng táº¡o Giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡oâ€ do ThÃ nh Ä‘oÃ n, Há»™i Sinh viÃªn thÃ nh phá»‘ HÃ  Ná»™i phá»‘i há»£p tá»• chá»©c vá»›i sá»± Ä‘Ã³ng gÃ³p cá»§a hÆ¡n 200 chuyÃªn gia AI vÃ  cÃ¡c anh/chá»‹ lÃ  quáº£n lÃ½ cáº¥p cao cá»§a cÃ¡c cÃ´ng ty, táº­p Ä‘oÃ n lá»›n táº¡i Viá»‡t Nam.
Cuá»™c thi ""SÃ¡ng táº¡o giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) - Nháº­n dáº¡ng Covid qua tiáº¿ng ho"" Ä‘Æ°á»£c tá»• chá»©c vá»›i sá»± tham gia cá»§a hÆ¡n 200 Ä‘á»™i thi vá»›i cÆ¡ cáº¥u giáº£i thÆ°á»Ÿng lÃªn tá»›i 115 triá»‡u Ä‘á»“ng vÃ  chia lÃ m 2 giai Ä‘oáº¡n:
â˜‘ï¸ Giai Ä‘oáº¡n Khá»Ÿi Ä‘á»™ng( 22/06/2021 - 01/07/2021)
â˜‘ï¸ Giai Ä‘oáº¡n vá» Ä‘Ã­ch( 19/07/2021 - 20/08/2021)
Trong giai Ä‘oáº¡n nÃ y, cÃ¡c Ä‘á»™i thi sáº½ Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i nhiá»u dá»¯ liá»‡u thá»±c táº¿ Ä‘Æ°á»£c thu tháº­p táº¡i Viá»‡t Nam vÃ  cÃ¡c nÆ°á»›c lÃ¢n cáº­n Ä‘á»ƒ AI sáº½ cÃ³ káº¿t quáº£ Ä‘Æ°á»£c chÃ­nh xÃ¡c nháº¥t
ğŸ‘‰ CÃ¡c Ä‘á»™i cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm thÃ´ng tin vÃ  Ä‘Äƒng kÃ½ tham gia giai Ä‘oáº¡n 2 táº¡i:
â˜‘ï¸ Website cá»§a cuá»™c thi: https://www.covid.aihub.vn/
â˜‘ï¸ Fanpage cá»§a dá»± Ã¡n: https://www.facebook.com/aicovn
 â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  4 ngÆ°á»i khÃ¡c.","[HOT EVENT] Tá»”NG Káº¾T GIAI ÄOáº N 1 VÃ€ THUYáº¾T TRÃŒNH GIáº¢I PHÃP TRÃ TUá»† NHÃ‚N Táº O (AI): PHÃT HIá»†N COVID QUA TIáº¾NG HO Vá»šI GIáº¢I THÆ¯á»NG LÃŠN Tá»šI 115 TRIá»†U Äá»’NG Thá»i gian: 20:00-22:00 - Thá»© NÄƒm, 08 thÃ¡ng 7 2021 (giá» Viá»‡t Nam) HÃ¬nh thá»©c: Livestream trá»±c tiáº¿p Link tham gia vÃ o há»™i tháº£o trá»±c tuyáº¿n: https://zoom.us/j/96842982383 Tráº£i qua gáº§n 2 tuáº§n thá»­ thÃ¡ch, hÆ¡n 200 Ä‘á»™i thi cá»§a dá»± Ã¡n lÃ  nhá»¯ng chuyÃªn gia AI trÃªn kháº¯p Viá»‡t Nam cÃ¹ng vá»›i sá»± Ä‘á»“ng hÃ nh cá»§a nhiá»u Anh/Chá»‹ lÃ  quáº£n lÃ½ cáº¥p cao cá»§a cÃ¡c CÃ´ng ty/táº­p Ä‘oÃ n cÃ´ng nghá»‡ lá»›n Ä‘Ã£ báº¯t Ä‘áº§u hoÃ n thÃ nh cuá»™c Ä‘ua trong giai Ä‘oáº¡n 1 cá»§a dá»± Ã¡n - Giai Ä‘oáº¡n khá»Ÿi Ä‘á»™ng. Dá»± Ã¡n sáº½ cÃ³ má»™t buá»•i tá»•ng káº¿t vÃ  thuyáº¿t trÃ¬nh cÃ¡c giáº£i phÃ¡t cá»§a thÃ­ sinh trong tá»‘i nay (8/7/2021) vá»›i sá»± Ä‘á»“ng hÃ nh cÃ¹ng Ä‘á»™i ngÅ© BGK cá»±c ""HOT"" trong giá»›i cÃ´ng nghá»‡: 1, Tiáº¿n sÄ© Pháº¡m Minh Tuáº¥n - Chairman, TFI Group 2, Tiáº¿n sÄ© VÅ© XuÃ¢n SÆ¡n - Postdoctoral Fellow @ UMU, Co-founder of DopikAI Lab & AIHUB.VN 3, Tiáº¿n sÄ© VÅ© Há»¯u Tiá»‡p - Machine Learning Engineer at Google, founder of MLCB. 4, Anh LÃª CÃ´ng ThÃ nh - Chairman & CEO at InfoRe Technology; Co-Founder/Producer at Dataset.vn 5, Tiáº¿n sÄ© Harry Nguyen - Asst. Prof. ÄH Glasgow, Co-founder of AIHUB.VN Giá»›i thiá»‡u vá» cuá»™c thi SÃ¡ng táº¡o giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡o (AI): Nháº­n dáº¡ng Covid qua tiáº¿ng ho ""AI Covid"" lÃ  dá»± Ã¡n cá»™ng Ä‘á»“ng vá»›i má»¥c tiÃªu lÃ m ra Ä‘Æ°á»£c giáº£i phÃ¡p TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI) Ä‘á»ƒ cÃ³ thá»ƒ phÃ¡t hiá»‡n Covid 19 thÃ´ng qua tiáº¿ng ho. Cuá»™c thi Ä‘Æ°á»£c chÃ­nh thá»©c phÃ¡t Ä‘á»™ng trong khuÃ´n khá»• chÆ°Æ¡ng trÃ¬nh Táº­p huáº¥n â€œÄá»™i hÃ¬nh tÃ¬nh nguyá»‡n sá»‘â€ vÃ  â€œCÃ¢u láº¡c bá»™ Ä‘á»•i má»›i sÃ¡ng táº¡o Giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡oâ€ do ThÃ nh Ä‘oÃ n, Há»™i Sinh viÃªn thÃ nh phá»‘ HÃ  Ná»™i phá»‘i há»£p tá»• chá»©c vá»›i sá»± Ä‘Ã³ng gÃ³p cá»§a hÆ¡n 200 chuyÃªn gia AI vÃ  cÃ¡c anh/chá»‹ lÃ  quáº£n lÃ½ cáº¥p cao cá»§a cÃ¡c cÃ´ng ty, táº­p Ä‘oÃ n lá»›n táº¡i Viá»‡t Nam. Cuá»™c thi ""SÃ¡ng táº¡o giáº£i phÃ¡p trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) - Nháº­n dáº¡ng Covid qua tiáº¿ng ho"" Ä‘Æ°á»£c tá»• chá»©c vá»›i sá»± tham gia cá»§a hÆ¡n 200 Ä‘á»™i thi vá»›i cÆ¡ cáº¥u giáº£i thÆ°á»Ÿng lÃªn tá»›i 115 triá»‡u Ä‘á»“ng vÃ  chia lÃ m 2 giai Ä‘oáº¡n: Giai Ä‘oáº¡n Khá»Ÿi Ä‘á»™ng( 22/06/2021 - 01/07/2021) Giai Ä‘oáº¡n vá» Ä‘Ã­ch( 19/07/2021 - 20/08/2021) Trong giai Ä‘oáº¡n nÃ y, cÃ¡c Ä‘á»™i thi sáº½ Ä‘Æ°á»£c tiáº¿p cáº­n vá»›i nhiá»u dá»¯ liá»‡u thá»±c táº¿ Ä‘Æ°á»£c thu tháº­p táº¡i Viá»‡t Nam vÃ  cÃ¡c nÆ°á»›c lÃ¢n cáº­n Ä‘á»ƒ AI sáº½ cÃ³ káº¿t quáº£ Ä‘Æ°á»£c chÃ­nh xÃ¡c nháº¥t CÃ¡c Ä‘á»™i cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm thÃ´ng tin vÃ  Ä‘Äƒng kÃ½ tham gia giai Ä‘oáº¡n 2 táº¡i: Website cá»§a cuá»™c thi: https://www.covid.aihub.vn/ Fanpage cá»§a dá»± Ã¡n: https://www.facebook.com/aicovn â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  4 ngÆ°á»i khÃ¡c.",,,,,
"[AICovidVN-115M Challenge] Tá»•ng káº¿t vÃ  Thuyáº¿t trÃ¬nh giáº£i phÃ¡p - Giai Ä‘oáº¡n Khá»Ÿi Ä‘á»™ng
Sá»± kiá»‡n Trao giáº£i vÃ  Tá»•ng káº¿t vá» Giai Ä‘oáº¡n Khá»Ÿi Ä‘á»™ng cá»§a cuá»™c thi AICovidVN-115 Challenge
Top Ä‘á»™i thi sáº½ trÃ¬nh bÃ y giáº£i phÃ¡p cá»§a mÃ¬nh qua viá»‡c thuyáº¿t trÃ¬nh vÃ  há»i Ä‘Ã¡p.",[AICovidVN-115M Challenge] Tá»•ng káº¿t vÃ  Thuyáº¿t trÃ¬nh giáº£i phÃ¡p - Giai Ä‘oáº¡n Khá»Ÿi Ä‘á»™ng Sá»± kiá»‡n Trao giáº£i vÃ  Tá»•ng káº¿t vá» Giai Ä‘oáº¡n Khá»Ÿi Ä‘á»™ng cá»§a cuá»™c thi AICovidVN-115 Challenge Top Ä‘á»™i thi sáº½ trÃ¬nh bÃ y giáº£i phÃ¡p cá»§a mÃ¬nh qua viá»‡c thuyáº¿t trÃ¬nh vÃ  há»i Ä‘Ã¡p.,,,,,
"ChÃ o má»i ngÆ°á»i!
hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u Ä‘á»ƒ Ä‘á»c giÃ¡ trá»‹ date thÃ¹ng nhÆ° trong áº£nh. cÃ¡c a cho em giáº£i phÃ¡p Ä‘á»c nhanh vÃ  chÃ­nh xÃ¡c Ä‘Æ°á»£c khÃ´ng áº¡",ChÃ o má»i ngÆ°á»i! hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u Ä‘á»ƒ Ä‘á»c giÃ¡ trá»‹ date thÃ¹ng nhÆ° trong áº£nh. cÃ¡c a cho em giáº£i phÃ¡p Ä‘á»c nhanh vÃ  chÃ­nh xÃ¡c Ä‘Æ°á»£c khÃ´ng áº¡,,,,,
"Em cÃ³ background bÃªn Tá»± Ä‘á»™ng hÃ³a. NhÆ°ng trong chÆ°Æ¡ng trÃ¬nh thá»±c táº­p á»Ÿ bÃªn cÃ´ng ty, há» cho em 1 project vá» Machine learning in Computer Vision. Cho em há»i lÃ  Ä‘á»ƒ há»c vá» ML máº£ng nÃ y thÃ¬ em nÃªn Ä‘á»c tÃ i liá»‡u nÃ o áº¡?","Em cÃ³ background bÃªn Tá»± Ä‘á»™ng hÃ³a. NhÆ°ng trong chÆ°Æ¡ng trÃ¬nh thá»±c táº­p á»Ÿ bÃªn cÃ´ng ty, há» cho em 1 project vá» Machine learning in Computer Vision. Cho em há»i lÃ  Ä‘á»ƒ há»c vá» ML máº£ng nÃ y thÃ¬ em nÃªn Ä‘á»c tÃ i liá»‡u nÃ o áº¡?",,,,,
"ChÃ o ace, mÃ¬nh cÃ³ bÃ i toÃ¡n nhÆ° sau:
BÃ i toÃ¡n phÃ¢n lá»›p cá»§a mÃ¬nh vá»›i 5430 pháº§n tá»­ thuá»™c táº­p dÆ°Æ¡ng, vÃ  184155 pháº§n tá»­ Ã¢m, sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng lÃ  878, vá»›i 2 cÃ¡ch tiáº¿p cáº­n: 
Train trÃªn táº­p gá»“m 5430 pháº§n tá»­ dÆ°Æ¡ng vÃ  5430x2 pháº§n tá»­ Ã¢m, sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng lÃ  878.
Train trÃªn toÃ n bá»™ 5430 pháº§n tá»­ dÆ°Æ¡ng vÃ  184155 pháº§n tá»­ Ã¢m, nhÆ°ng sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng rÃºt láº¡i cÃ²n 100.
Theo 2 cÃ¡ch trÃªn thÃ¬ liá»‡u mÃ¬nh cÃ³ dá»± Ä‘oÃ¡n káº¿t quáº£ theo cÃ¡ch nÃ o lÃ  kháº£ thi hÆ¡n, náº¿u mÃ¬nh chÆ°a báº¯t tay vÃ o train áº¡.
Xin má»i ngÆ°á»i chá»‰ giÃ¡o. MÃ¬nh cÃ¡m Æ¡n áº¡!","ChÃ o ace, mÃ¬nh cÃ³ bÃ i toÃ¡n nhÆ° sau: BÃ i toÃ¡n phÃ¢n lá»›p cá»§a mÃ¬nh vá»›i 5430 pháº§n tá»­ thuá»™c táº­p dÆ°Æ¡ng, vÃ  184155 pháº§n tá»­ Ã¢m, sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng lÃ  878, vá»›i 2 cÃ¡ch tiáº¿p cáº­n: Train trÃªn táº­p gá»“m 5430 pháº§n tá»­ dÆ°Æ¡ng vÃ  5430x2 pháº§n tá»­ Ã¢m, sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng lÃ  878. Train trÃªn toÃ n bá»™ 5430 pháº§n tá»­ dÆ°Æ¡ng vÃ  184155 pháº§n tá»­ Ã¢m, nhÆ°ng sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng rÃºt láº¡i cÃ²n 100. Theo 2 cÃ¡ch trÃªn thÃ¬ liá»‡u mÃ¬nh cÃ³ dá»± Ä‘oÃ¡n káº¿t quáº£ theo cÃ¡ch nÃ o lÃ  kháº£ thi hÆ¡n, náº¿u mÃ¬nh chÆ°a báº¯t tay vÃ o train áº¡. Xin má»i ngÆ°á»i chá»‰ giÃ¡o. MÃ¬nh cÃ¡m Æ¡n áº¡!",,,,,
"Em chÃ o má»i ngÆ°á»i.
Em xin phÃ©p Ä‘Æ°á»£c há»i má»™t cÃ¢u liÃªn quan Ä‘áº¿n training model trÃªn GPU cá»§a server. Giáº£ sá»­ server cá»§a em cÃ³ 4 con GPU, em muá»‘n training trÃªn con GPU vá»›i device_id = 3 thÃ¬ mÃ¬nh cáº§n lÃ m gÃ¬ áº¡. Em Ä‘Ã£ set eCUDA_VISIBLE_DEVICES=""3"" vÃ  CUDAPlace(3) cá»§a paddle nhÆ°ng khi train nÃ³ chá»‰ dÃ¹ng device = 0 nhÆ° hÃ¬nh áº¡.
Ráº¥t mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡, em cáº£m Æ¡n má»i ngÆ°á»i","Em chÃ o má»i ngÆ°á»i. Em xin phÃ©p Ä‘Æ°á»£c há»i má»™t cÃ¢u liÃªn quan Ä‘áº¿n training model trÃªn GPU cá»§a server. Giáº£ sá»­ server cá»§a em cÃ³ 4 con GPU, em muá»‘n training trÃªn con GPU vá»›i device_id = 3 thÃ¬ mÃ¬nh cáº§n lÃ m gÃ¬ áº¡. Em Ä‘Ã£ set eCUDA_VISIBLE_DEVICES=""3"" vÃ  CUDAPlace(3) cá»§a paddle nhÆ°ng khi train nÃ³ chá»‰ dÃ¹ng device = 0 nhÆ° hÃ¬nh áº¡. Ráº¥t mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡, em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
Má»™t bÃ i viáº¿t nho nhá» vá» SVM. Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p tá»« má»i ngÆ°á»i Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n.,Má»™t bÃ i viáº¿t nho nhá» vá» SVM. Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p tá»« má»i ngÆ°á»i Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n.,,,,,
"ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m má»™t project vá» nháº­n dáº¡ng máº·t ngÆ°á»i (face recognition) dÃ¹ng opencv vÃ  Dlib. MÃ¬nh cÃ³ má»™t Card NVIDIA Tesla K80. MÃ¬nh muá»‘n sá»­ dá»¥ng GPU nÃ y thÃ¬ mÃ¬nh Ä‘á»c tÃ i liá»‡u lÃ  pháº£i cÃ i CUDA Toolkit vÃ  CuDNN.
TrÃªn group mÃ¬nh cÃ³ báº¡n nÃ o Ä‘Ã£ cÃ i CUDA vÃ  CuDNN trÃªn window chÆ°a vÃ  pháº£i set up nhÆ° tháº¿ nÃ o Ä‘á»ƒ dlib dÃ¹ng Ä‘Æ°á»£c GPU?
MÃ¬nh nháº­n Ä‘Æ°á»£c pháº£n há»“i cá»§a cÃ¡c báº¡n. Thanks!",ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m má»™t project vá» nháº­n dáº¡ng máº·t ngÆ°á»i (face recognition) dÃ¹ng opencv vÃ  Dlib. MÃ¬nh cÃ³ má»™t Card NVIDIA Tesla K80. MÃ¬nh muá»‘n sá»­ dá»¥ng GPU nÃ y thÃ¬ mÃ¬nh Ä‘á»c tÃ i liá»‡u lÃ  pháº£i cÃ i CUDA Toolkit vÃ  CuDNN. TrÃªn group mÃ¬nh cÃ³ báº¡n nÃ o Ä‘Ã£ cÃ i CUDA vÃ  CuDNN trÃªn window chÆ°a vÃ  pháº£i set up nhÆ° tháº¿ nÃ o Ä‘á»ƒ dlib dÃ¹ng Ä‘Æ°á»£c GPU? MÃ¬nh nháº­n Ä‘Æ°á»£c pháº£n há»“i cá»§a cÃ¡c báº¡n. Thanks!,,,,,
"ThÃ´ng bÃ¡o dá»«ng trang web AIviVN.com.
Ká»ƒ tá»« khi thÃ nh láº­p AIviVN.com -- trang web tá»• chá»©c cÃ¡c cuá»™c thi há»c mÃ¡y, chÃºng tÃ´i ráº¥t vui khi nháº­n Ä‘Æ°á»£c sá»± á»§ng há»™ vá» dá»¯ liá»‡u, kinh phÃ­ duy trÃ¬ tá»« cÃ¡c doanh nghiá»‡p vÃ  sá»± á»§ng há»™ tá»« cÃ¡c Ä‘á»™i tham gia cÃ¡c cuá»™c thi. ChÃºng tÃ´i hy vá»ng AIviVN.com Ä‘Ã£ pháº§n nÃ o mang láº¡i nhá»¯ng giÃ¡ trá»‹ nháº¥t Ä‘á»‹nh cho cá»™ng Ä‘á»“ng.
Thá»i gian gáº§n Ä‘Ã¢y, vÃ¬ nhá»¯ng giá»›i háº¡n cá»§a nguá»“n dá»¯ liá»‡u vÃ  nguá»“n lá»±c duy trÃ¬ trang web, chÃºng tÃ´i Ä‘Ã£ cÃ¢n nháº¯c vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘Ã³ng cá»­a AIviVN.com Ä‘á»ƒ táº­p trung nguá»“n lá»±c vÃ o cÃ¡c dá»± Ã¡n khÃ¡c cÃ³ Ä‘á»™ Æ°u tiÃªn cao hÆ¡n. Viá»‡c nÃ y khÃ´ng áº£nh hÆ°á»Ÿng tá»›i cÃ¡c dá»± Ã¡n sá»­ dá»¥ng tÃªn miá»n con, cuá»‘n sÃ¡ch ""Äáº¯m mÃ¬nh vÃ o há»c sÃ¢u"" (d2l.aivivn.com) váº«n sáº½ Ä‘Æ°á»£c duy trÃ¬.
NhÃ¢n tiá»‡n Ä‘Ã¢y, tÃ´i xin giá»›i thiá»‡u trang thay tháº¿ https://aihub.vn/ vá»›i má»™t sá»‘ cuá»™c thi khÃ¡c Ä‘ang diá»…n ra, bao gá»“m AICovidVN 115M. Trang nÃ y Ä‘Æ°á»£c duy trÃ¬ bá»Ÿi VLSP vá»›i anh VÅ© XuÃ¢n SÆ¡n lÃ m Ä‘áº¡i diá»‡n.
Cáº£m Æ¡n sá»± á»§ng há»™ AIviVN cá»§a cá»™ng Ä‘á»“ng trong thá»i gian AIviVN tá»“n táº¡i.","ThÃ´ng bÃ¡o dá»«ng trang web AIviVN.com. Ká»ƒ tá»« khi thÃ nh láº­p AIviVN.com -- trang web tá»• chá»©c cÃ¡c cuá»™c thi há»c mÃ¡y, chÃºng tÃ´i ráº¥t vui khi nháº­n Ä‘Æ°á»£c sá»± á»§ng há»™ vá» dá»¯ liá»‡u, kinh phÃ­ duy trÃ¬ tá»« cÃ¡c doanh nghiá»‡p vÃ  sá»± á»§ng há»™ tá»« cÃ¡c Ä‘á»™i tham gia cÃ¡c cuá»™c thi. ChÃºng tÃ´i hy vá»ng AIviVN.com Ä‘Ã£ pháº§n nÃ o mang láº¡i nhá»¯ng giÃ¡ trá»‹ nháº¥t Ä‘á»‹nh cho cá»™ng Ä‘á»“ng. Thá»i gian gáº§n Ä‘Ã¢y, vÃ¬ nhá»¯ng giá»›i háº¡n cá»§a nguá»“n dá»¯ liá»‡u vÃ  nguá»“n lá»±c duy trÃ¬ trang web, chÃºng tÃ´i Ä‘Ã£ cÃ¢n nháº¯c vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘Ã³ng cá»­a AIviVN.com Ä‘á»ƒ táº­p trung nguá»“n lá»±c vÃ o cÃ¡c dá»± Ã¡n khÃ¡c cÃ³ Ä‘á»™ Æ°u tiÃªn cao hÆ¡n. Viá»‡c nÃ y khÃ´ng áº£nh hÆ°á»Ÿng tá»›i cÃ¡c dá»± Ã¡n sá»­ dá»¥ng tÃªn miá»n con, cuá»‘n sÃ¡ch ""Äáº¯m mÃ¬nh vÃ o há»c sÃ¢u"" (d2l.aivivn.com) váº«n sáº½ Ä‘Æ°á»£c duy trÃ¬. NhÃ¢n tiá»‡n Ä‘Ã¢y, tÃ´i xin giá»›i thiá»‡u trang thay tháº¿ https://aihub.vn/ vá»›i má»™t sá»‘ cuá»™c thi khÃ¡c Ä‘ang diá»…n ra, bao gá»“m AICovidVN 115M. Trang nÃ y Ä‘Æ°á»£c duy trÃ¬ bá»Ÿi VLSP vá»›i anh VÅ© XuÃ¢n SÆ¡n lÃ m Ä‘áº¡i diá»‡n. Cáº£m Æ¡n sá»± á»§ng há»™ AIviVN cá»§a cá»™ng Ä‘á»“ng trong thá»i gian AIviVN tá»“n táº¡i.",,,,,
"ChÃ o má»i ngÆ°á»i. VÃ­ dá»¥ trong cÃ´ng ty mÃ¬nh Ä‘Ã£ cÃ³ má»™t model Ä‘ang váº­n hÃ nh trÃªn production cho má»™t task nÃ o Ä‘Ã³. BÃ¢y giá» mÃ¬nh triá»ƒn khai má»™t model má»›i vá»›i má»¥c Ä‘Ã­ch nÃ¢ng cao performance so vá»›i model cÅ©. ThÃ¬ lÃ m sao test Ä‘Æ°á»£c hiá»‡u qá»§a cá»§a model má»›i so vá»›i model cÅ© Ä‘á»ƒ thuyáº¿t phá»¥c sáº¿p triá»ƒn khai má»i ngÆ°á»i nhá»‰.
Cáº£m Æ¡n má»i ngÆ°á»i.",ChÃ o má»i ngÆ°á»i. VÃ­ dá»¥ trong cÃ´ng ty mÃ¬nh Ä‘Ã£ cÃ³ má»™t model Ä‘ang váº­n hÃ nh trÃªn production cho má»™t task nÃ o Ä‘Ã³. BÃ¢y giá» mÃ¬nh triá»ƒn khai má»™t model má»›i vá»›i má»¥c Ä‘Ã­ch nÃ¢ng cao performance so vá»›i model cÅ©. ThÃ¬ lÃ m sao test Ä‘Æ°á»£c hiá»‡u qá»§a cá»§a model má»›i so vá»›i model cÅ© Ä‘á»ƒ thuyáº¿t phá»¥c sáº¿p triá»ƒn khai má»i ngÆ°á»i nhá»‰. Cáº£m Æ¡n má»i ngÆ°á»i.,,,,,
"Gáº§n Ä‘Ã¢y JAX ná»•i lÃªn nhÆ° má»™t framework Ä‘Æ°á»£c sá»­ dá»¥ng trong nghiÃªn cá»©u má»›i nháº¥t cá»§a Google Brain vÃ  DeepMind. VÃ  cÃ¡c API há»— trá»£ Ä‘ang dáº§n chiáº¿m Ä‘Æ°á»£c vá»‹ trÃ­ cho JAX lÃ  Flax vÃ  Haiku. JAX há»— trá»£ tá»‘t vá»›i GPUs vÃ  TPUs nÃªn cháº¯c sáº½ cÃ³ tÆ°Æ¡ng lai há»©a háº¹n.
DÆ°á»›i Ä‘Ã¢y lÃ  hÆ°á»›ng dáº«n sá»­ dá»¥ng JAX Ä‘Ã³ HuggingFace giá»›i thiá»‡u
YouTube:
https://youtu.be/__eG63ZP_5g?t=1545
Slides:
https://docs.google.com/presentation/d/1d8gTywMi32kA1qigOMRF2MjVdyM9e2BV7p878NPMzII/
Notebook:
https://colab.research.google.com/drive/1NV3kQAMGo4e47XkXHGvKHkpy0aJ8-Vxg",Gáº§n Ä‘Ã¢y JAX ná»•i lÃªn nhÆ° má»™t framework Ä‘Æ°á»£c sá»­ dá»¥ng trong nghiÃªn cá»©u má»›i nháº¥t cá»§a Google Brain vÃ  DeepMind. VÃ  cÃ¡c API há»— trá»£ Ä‘ang dáº§n chiáº¿m Ä‘Æ°á»£c vá»‹ trÃ­ cho JAX lÃ  Flax vÃ  Haiku. JAX há»— trá»£ tá»‘t vá»›i GPUs vÃ  TPUs nÃªn cháº¯c sáº½ cÃ³ tÆ°Æ¡ng lai há»©a háº¹n. DÆ°á»›i Ä‘Ã¢y lÃ  hÆ°á»›ng dáº«n sá»­ dá»¥ng JAX Ä‘Ã³ HuggingFace giá»›i thiá»‡u YouTube: https://youtu.be/__eG63ZP_5g?t=1545 Slides: https://docs.google.com/presentation/d/1d8gTywMi32kA1qigOMRF2MjVdyM9e2BV7p878NPMzII/ Notebook: https://colab.research.google.com/drive/1NV3kQAMGo4e47XkXHGvKHkpy0aJ8-Vxg,,,,,
"ChÃ o cÃ¡c báº¡n,
MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n xÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘oÃ¡n hÃ nh vi (Ä‘i, Ä‘á»©ng, náº±m...vv) cá»§a bÃ² dá»±a trÃªn dá»¯ liá»‡u cáº£m biáº¿n 3d sensors (accelerometer vÃ  gyroscope). Dá»¯ liá»‡u gÃ¡n nhÃ£n tá»« 10 con bÃ², mÃ¬nh láº¥y dá»¯ liá»‡u tá»« 5 con xong rá»“i chia thÃ nh 10 pháº§n, 3 pháº§n Ä‘á»ƒ test, 7 pháº§n Ä‘á»ƒ train. MÃ´ hÃ¬nh sau khi train thÃ¬ test (1 láº§n) trÃªn 3 pháº§n test Ä‘Ã³ thÃ¬ cho ra accuracy 87.35% (Ä‘Æ°á»£c xem lÃ  tá»‘t vÃ¬ cÃ³ 1 vÃ i hÃ nh vi dá»… bá»‹ confusing nhÆ° Ä‘á»©ng vÃ  náº±m). MÃ´ hÃ¬nh Ä‘Ã³ sau khi test trÃªn dá»¯ liá»‡u cá»§a má»™t con bÃ² khÃ¡c (khÃ´ng náº±m trong 5 con Ä‘Æ°á»£c train kia) thÃ¬ cho ra accuracy tháº¥p lÃ  58%.
Nháº­n Ä‘á»‹nh cá»§a mÃ¬nh lÃ  ""Dá»¯ liá»‡u training tá»« 5 con bÃ² kia chÆ°a Ä‘á»§ mang tÃ­nh Ä‘áº¡i diá»‡n, mÃ¬nh cáº§n pháº£i thÃªm dá»¯ liá»‡u cáº£m biáº¿n tá»« 1 vÃ i con khÃ¡c ná»¯a""?!
CÃ¡c báº¡n cho mÃ¬nh há»i nháº­n Ä‘á»‹nh nhÆ° váº­y Ä‘Ã£ Ä‘Ãºng chÆ°a, vÃ  cÃ²n cÃ³ thá»ƒ cÃ³ nhá»¯ng váº¥n Ä‘á» gÃ¬ nÃ o khÃ¡c ná»¯a?
Cáº£m Æ¡n cÃ¡c báº¡n!","ChÃ o cÃ¡c báº¡n, MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n xÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘oÃ¡n hÃ nh vi (Ä‘i, Ä‘á»©ng, náº±m...vv) cá»§a bÃ² dá»±a trÃªn dá»¯ liá»‡u cáº£m biáº¿n 3d sensors (accelerometer vÃ  gyroscope). Dá»¯ liá»‡u gÃ¡n nhÃ£n tá»« 10 con bÃ², mÃ¬nh láº¥y dá»¯ liá»‡u tá»« 5 con xong rá»“i chia thÃ nh 10 pháº§n, 3 pháº§n Ä‘á»ƒ test, 7 pháº§n Ä‘á»ƒ train. MÃ´ hÃ¬nh sau khi train thÃ¬ test (1 láº§n) trÃªn 3 pháº§n test Ä‘Ã³ thÃ¬ cho ra accuracy 87.35% (Ä‘Æ°á»£c xem lÃ  tá»‘t vÃ¬ cÃ³ 1 vÃ i hÃ nh vi dá»… bá»‹ confusing nhÆ° Ä‘á»©ng vÃ  náº±m). MÃ´ hÃ¬nh Ä‘Ã³ sau khi test trÃªn dá»¯ liá»‡u cá»§a má»™t con bÃ² khÃ¡c (khÃ´ng náº±m trong 5 con Ä‘Æ°á»£c train kia) thÃ¬ cho ra accuracy tháº¥p lÃ  58%. Nháº­n Ä‘á»‹nh cá»§a mÃ¬nh lÃ  "" Dá»¯ liá»‡u training tá»« 5 con bÃ² kia chÆ°a Ä‘á»§ mang tÃ­nh Ä‘áº¡i diá»‡n, mÃ¬nh cáº§n pháº£i thÃªm dá»¯ liá»‡u cáº£m biáº¿n tá»« 1 vÃ i con khÃ¡c ná»¯a""?! CÃ¡c báº¡n cho mÃ¬nh há»i nháº­n Ä‘á»‹nh nhÆ° váº­y Ä‘Ã£ Ä‘Ãºng chÆ°a, vÃ  cÃ²n cÃ³ thá»ƒ cÃ³ nhá»¯ng váº¥n Ä‘á» gÃ¬ nÃ o khÃ¡c ná»¯a? Cáº£m Æ¡n cÃ¡c báº¡n!",,,,,
"[AI Share - GitHub Copilot]
Tháº­t lÃ  tuyá»‡t vá»i! ğŸ˜ğŸ˜
GitHub cÃ¹ng vá»›i OpenAI vá»«a phÃ¡t hÃ nh má»™t há»‡ thá»‘ng AI má»›i â€œGithub Copilot: Your AI pair programmerâ€ .
Vá»›i GitHub Copilot, báº¡n cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c gá»£i Ã½ chocáº£ dÃ²ng code hoáº·c toÃ n bá»™ hÃ m mÃ  báº¡n Ä‘á»‹nh viáº¿t, giÃºp báº¡n viáº¿t code tá»‘t hÆ¡n vÃ  nhanh hÆ¡n. ThÃªm vÃ o Ä‘Ã³, GitHub Copilot hoáº¡t Ä‘á»™ng vá»›i nhiá»u frameworks vÃ  nhiá»u ngÃ´n ngá»¯ nhÆ°ng Ä‘áº·c biá»‡t tá»‘t vá»›i Python, JavaScript, TypeScript, Ruby vÃ  Go.
Báº¡n cÃ³ thá»ƒ xem trÆ°á»›c má»™t sá»‘ kÄ© thuáº­t vÃ  Ä‘Äƒng kÃ­ trÆ°á»›c á»Ÿ Ä‘Ã¢y: https://copilot.github.com/","[AI Share - GitHub Copilot] Tháº­t lÃ  tuyá»‡t vá»i! GitHub cÃ¹ng vá»›i OpenAI vá»«a phÃ¡t hÃ nh má»™t há»‡ thá»‘ng AI má»›i â€œGithub Copilot: Your AI pair programmerâ€ . Vá»›i GitHub Copilot, báº¡n cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c gá»£i Ã½ chocáº£ dÃ²ng code hoáº·c toÃ n bá»™ hÃ m mÃ  báº¡n Ä‘á»‹nh viáº¿t, giÃºp báº¡n viáº¿t code tá»‘t hÆ¡n vÃ  nhanh hÆ¡n. ThÃªm vÃ o Ä‘Ã³, GitHub Copilot hoáº¡t Ä‘á»™ng vá»›i nhiá»u frameworks vÃ  nhiá»u ngÃ´n ngá»¯ nhÆ°ng Ä‘áº·c biá»‡t tá»‘t vá»›i Python, JavaScript, TypeScript, Ruby vÃ  Go. Báº¡n cÃ³ thá»ƒ xem trÆ°á»›c má»™t sá»‘ kÄ© thuáº­t vÃ  Ä‘Äƒng kÃ­ trÆ°á»›c á»Ÿ Ä‘Ã¢y: https://copilot.github.com/",,,,,
"CÃ¡c anh chá»‹ cho em há»i má»™t chÃºt vá»›i áº¡.
Em cÃ³ tÃ¬m hiá»ƒu recommender system, vÃ  biáº¿t ráº±ng content-based filtering lÃ  sá»­ dá»¥ng nhá»¯ng item tÆ°Æ¡ng tá»± item mÃ  user Ä‘Ã£ Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½, khÃ´ng cáº§n Ä‘áº¿n Ä‘Ã¡nh giÃ¡ cá»§a cÃ¡c user khÃ¡c. Váº­y náº¿u em sá»­ dá»¥ng kÄ© thuáº­t cá»§a content-based (TFIDF vÃ  consine similarity) Ä‘á»ƒ tÃ¬m ra cÃ¡c user cÃ³ Ä‘áº·c Ä‘iá»ƒm (tuá»•i, giá»›i tÃ­nh, nghá» nghiá»‡p,...) tÆ°Æ¡ng tá»± vá»›i má»™t user cá»¥ thá»ƒ (input) thÃ¬ cÃ¡ch lÃ m nhÆ° váº­y cÃ³ Ä‘Æ°á»£c gá»i lÃ  content-based filtering ná»¯a khÃ´ng áº¡?
Em cáº£m Æ¡n áº¡ :D","CÃ¡c anh chá»‹ cho em há»i má»™t chÃºt vá»›i áº¡. Em cÃ³ tÃ¬m hiá»ƒu recommender system, vÃ  biáº¿t ráº±ng content-based filtering lÃ  sá»­ dá»¥ng nhá»¯ng item tÆ°Æ¡ng tá»± item mÃ  user Ä‘Ã£ Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½, khÃ´ng cáº§n Ä‘áº¿n Ä‘Ã¡nh giÃ¡ cá»§a cÃ¡c user khÃ¡c. Váº­y náº¿u em sá»­ dá»¥ng kÄ© thuáº­t cá»§a content-based (TFIDF vÃ  consine similarity) Ä‘á»ƒ tÃ¬m ra cÃ¡c user cÃ³ Ä‘áº·c Ä‘iá»ƒm (tuá»•i, giá»›i tÃ­nh, nghá» nghiá»‡p,...) tÆ°Æ¡ng tá»± vá»›i má»™t user cá»¥ thá»ƒ (input) thÃ¬ cÃ¡ch lÃ m nhÆ° váº­y cÃ³ Ä‘Æ°á»£c gá»i lÃ  content-based filtering ná»¯a khÃ´ng áº¡? Em cáº£m Æ¡n áº¡ :D",,,,,
Hi má»i ngÆ°á»i. MÃ¬nh muá»‘n tÃ¬m sÃ¡ch hay nguá»“n Ä‘á»c vá» deploy model to production. Ai cÃ³ biáº¿t tÃªn sÃ¡ch hay nguá»“n nÃ o hay cÃ³ thá»ƒ giá»›i thiá»‡u Ä‘Æ°á»£c khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u,Hi má»i ngÆ°á»i. MÃ¬nh muá»‘n tÃ¬m sÃ¡ch hay nguá»“n Ä‘á»c vá» deploy model to production. Ai cÃ³ biáº¿t tÃªn sÃ¡ch hay nguá»“n nÃ o hay cÃ³ thá»ƒ giá»›i thiá»‡u Ä‘Æ°á»£c khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u,,,,,
"Dictionary-guided Scene Text Recognition
This might be an useful resource for future research & applications on scene text recognition, especially for Vietnamese. Our work is also accepted to CVPR 2021.
In this work, we present an approach to train and use scene text recognition models by exploiting multiple clues from a language reference. Current scene text recognition methods have used lexicons to improve recognition performance, but their naive approach of simply casting the output into a dictionary word based purely on the edit distance has many limitations. We introduce here a novel approach to incorporate a dictionary in both the training and inference stage of a scene text recognition system. We use the dictionary to generate a list of possible outcomes and find the one that is most compatible with the visual appearance of the text. The proposed method leads to a robust scene text recognition model, which is better at handling ambiguous cases encountered in the wild, and improves the overall performance of a state-of-the-art scene text spotting framework. Our work suggests that incorporating language prior is a potential approach to advance scene text detection and recognition methods. Besides, we contribute a challenging scene text dataset for Vietnamese, where some characters are equivocal in the visual form due to accent symbols. This dataset will serve as a challenging benchmark for measuring the applicability and robustness of scene text detection and recognition algorithms.
If you want to learn more about our research, you can check the video: https://youtu.be/0Cq4CBBSJII
Our paper: https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.html
Code and dataset: https://github.com/VinAIResearch/dict-guided","Dictionary-guided Scene Text Recognition This might be an useful resource for future research & applications on scene text recognition, especially for Vietnamese. Our work is also accepted to CVPR 2021. In this work, we present an approach to train and use scene text recognition models by exploiting multiple clues from a language reference. Current scene text recognition methods have used lexicons to improve recognition performance, but their naive approach of simply casting the output into a dictionary word based purely on the edit distance has many limitations. We introduce here a novel approach to incorporate a dictionary in both the training and inference stage of a scene text recognition system. We use the dictionary to generate a list of possible outcomes and find the one that is most compatible with the visual appearance of the text. The proposed method leads to a robust scene text recognition model, which is better at handling ambiguous cases encountered in the wild, and improves the overall performance of a state-of-the-art scene text spotting framework. Our work suggests that incorporating language prior is a potential approach to advance scene text detection and recognition methods. Besides, we contribute a challenging scene text dataset for Vietnamese, where some characters are equivocal in the visual form due to accent symbols. This dataset will serve as a challenging benchmark for measuring the applicability and robustness of scene text detection and recognition algorithms. If you want to learn more about our research, you can check the video: https://youtu.be/0Cq4CBBSJII Our paper: https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.html Code and dataset: https://github.com/VinAIResearch/dict-guided",,,,,
,nan,,,,,
"ChÃ o má»i ngÆ°á»i,hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» yolo.
Em muá»‘n há»i lÃ  trong yolov2 ngÆ°á»i ta cÃ³ báº£o cÃ³ sá»± cáº£i tiáº¿n lÃ  dÃ¹ng anchor box.
Em cÃ³ Ä‘á»c Ä‘Æ°á»£c lÃ  anchor box lÃ  má»™t bounding box cÆ¡ sá»Ÿ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh bounding box bao quanh váº­t thá»ƒ. Theo em hiá»ƒu lÃ  trong yolov1 má»—i grid cell sáº½ dá»± Ä‘oÃ¡n bounding box vÃ  sá»‘ Ä‘iá»ƒm tin cáº­y= giÃ¡ trá»‹ prediction box so vá»›i ground-truth box. Váº­y thÃªm anchor box cá»¥ thá»ƒ lÃ  gÃ¬ vÃ  cÃ³ tÃ¡c dá»¥ng gÃ¬  áº¡ ? Em váº«n chÆ°a hiá»ƒu rÃµ anchor box  nÃ³ lÃ  gÃ¬ vÃ  cÃ³ Ä‘iá»ƒm máº¡nh gÃ¬ hÆ¡n?
Em newbie mong má»i ngÆ°á»i thÃ´ng nÃ£o.","ChÃ o má»i ngÆ°á»i,hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu vá» yolo. Em muá»‘n há»i lÃ  trong yolov2 ngÆ°á»i ta cÃ³ báº£o cÃ³ sá»± cáº£i tiáº¿n lÃ  dÃ¹ng anchor box. Em cÃ³ Ä‘á»c Ä‘Æ°á»£c lÃ  anchor box lÃ  má»™t bounding box cÆ¡ sá»Ÿ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh bounding box bao quanh váº­t thá»ƒ. Theo em hiá»ƒu lÃ  trong yolov1 má»—i grid cell sáº½ dá»± Ä‘oÃ¡n bounding box vÃ  sá»‘ Ä‘iá»ƒm tin cáº­y= giÃ¡ trá»‹ prediction box so vá»›i ground-truth box. Váº­y thÃªm anchor box cá»¥ thá»ƒ lÃ  gÃ¬ vÃ  cÃ³ tÃ¡c dá»¥ng gÃ¬ áº¡ ? Em váº«n chÆ°a hiá»ƒu rÃµ anchor box nÃ³ lÃ  gÃ¬ vÃ  cÃ³ Ä‘iá»ƒm máº¡nh gÃ¬ hÆ¡n? Em newbie mong má»i ngÆ°á»i thÃ´ng nÃ£o.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n Local Outlier Factor trong bÃ i toÃ¡n Classification vÃ  cÃ³ vÃ i chá»— khÃ´ng hiá»ƒu nÃªn mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡.
https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html
Theo Ä‘á»‹nh nghÄ©a cá»§a sklearn: ""Unsupervised Outlier Detection using Local Outlier Factor ""
1. CÃ¡i ""Unsupervised"" á»Ÿ Ä‘Ã¢y em cÃ³ thá»ƒ hiá»ƒu lÃ  chá»‰ cÃ³ thá»ƒ fit hÃ m LocalOutlierFactor trÃªn dá»¯ liá»‡u khÃ´ng cÃ³ label hay tháº¿ nÃ o áº¡?
VÃ­ dá»¥ dataset cá»§a em cÃ³ 2000 dÃ²ng (cÃ³ label), em muá»‘n kiá»ƒm tra xem trong 2000 dÃ²ng nÃ y cÃ³ nhá»¯ng dÃ²ng nÃ o lÃ  outlier (cho contamination = 0.1, novelty=False) váº­y thÃ¬ em sáº½ fit cÃ¡i hÃ m LocalOutlierFactor trÃªn dataset Ä‘Ã£ loáº¡i bá» label hay trÃªn toÃ n bá»™ dataset ban Ä‘áº§u (cÃ³ label) váº­y áº¡?
2. CÃ¢u há»i thá»© hai lÃ  mÃ¬nh pháº£i chia riÃªng ra hai táº­p train vÃ  test, sau Ä‘Ã³ fit hÃ m LocalOutlierFactor (novelty=False) trÃªn má»—i táº­p train thÃ´i, sau khi loáº¡i bá» cÃ¡c outlier trÃªn táº­p train mÃ¬nh dÃ¹ng táº­p train nÃ y Ä‘á»ƒ sá»­ dá»¥ng sau Ä‘Ã³ (cháº¡y cÃ¡c model phÃ¢n loáº¡i,... sau Ä‘Ã³ dÃ¹ng model nÃ y Ä‘á»ƒ dá»± Ä‘oÃ¡n trÃªn táº­p test) hay lÃ  mÃ¬nh khÃ´ng cáº§n chia riÃªng ra táº­p train vÃ  test váº­y áº¡?
3. Tham sá»‘ 'novelty' náº¿u mÃ¬nh cho báº±ng False thÃ¬ nÃ³ detect ra cÃ¡c outlier, cho báº±ng True thÃ¬ nÃ³ detect ra cÃ¡c Ä‘iá»ƒm má»›i (?) vÃ  chá»‰ sá»­ dá»¥ng cho novelty = True trÃªn má»—i táº­p test, em khÃ´ng hiá»ƒu lÃ  náº¿u cho novelty = True thÃ¬ cÃ¡c Ä‘iá»ƒm nÃ³ detect ra cÃ³ Ã½ nghÄ©a gÃ¬ vÃ  cÃ¡c Ä‘iá»ƒm nÃ y sáº½ Ä‘Æ°á»£c dÃ¹ng cho má»¥c Ä‘Ã­ch gÃ¬ áº¡?
4. LiÃªn quan Ä‘áº¿n cÃ¢u há»i sá»‘ (1), náº¿u trong 2000 dÃ²ng nÃ y mÃ¬nh bá» ra 200 dÃ²ng mÃ¬nh cho lÃ  outlier, sau Ä‘Ã³ mÃ¬nh chá»‰ dÃ¹ng 1800 dÃ²ng cÃ²n láº¡i Ä‘á»ƒ sá»­ dá»¥ng thÃ¬ cÃ¡ch lÃ m nÃ y cÃ³ Ä‘Ãºng khÃ´ng áº¡?
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c vÃ  mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n Local Outlier Factor trong bÃ i toÃ¡n Classification vÃ  cÃ³ vÃ i chá»— khÃ´ng hiá»ƒu nÃªn mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html Theo Ä‘á»‹nh nghÄ©a cá»§a sklearn: ""Unsupervised Outlier Detection using Local Outlier Factor "" 1. CÃ¡i ""Unsupervised"" á»Ÿ Ä‘Ã¢y em cÃ³ thá»ƒ hiá»ƒu lÃ  chá»‰ cÃ³ thá»ƒ fit hÃ m LocalOutlierFactor trÃªn dá»¯ liá»‡u khÃ´ng cÃ³ label hay tháº¿ nÃ o áº¡? VÃ­ dá»¥ dataset cá»§a em cÃ³ 2000 dÃ²ng (cÃ³ label), em muá»‘n kiá»ƒm tra xem trong 2000 dÃ²ng nÃ y cÃ³ nhá»¯ng dÃ²ng nÃ o lÃ  outlier (cho contamination = 0.1, novelty=False) váº­y thÃ¬ em sáº½ fit cÃ¡i hÃ m LocalOutlierFactor trÃªn dataset Ä‘Ã£ loáº¡i bá» label hay trÃªn toÃ n bá»™ dataset ban Ä‘áº§u (cÃ³ label) váº­y áº¡? 2. CÃ¢u há»i thá»© hai lÃ  mÃ¬nh pháº£i chia riÃªng ra hai táº­p train vÃ  test, sau Ä‘Ã³ fit hÃ m LocalOutlierFactor (novelty=False) trÃªn má»—i táº­p train thÃ´i, sau khi loáº¡i bá» cÃ¡c outlier trÃªn táº­p train mÃ¬nh dÃ¹ng táº­p train nÃ y Ä‘á»ƒ sá»­ dá»¥ng sau Ä‘Ã³ (cháº¡y cÃ¡c model phÃ¢n loáº¡i,... sau Ä‘Ã³ dÃ¹ng model nÃ y Ä‘á»ƒ dá»± Ä‘oÃ¡n trÃªn táº­p test) hay lÃ  mÃ¬nh khÃ´ng cáº§n chia riÃªng ra táº­p train vÃ  test váº­y áº¡? 3. Tham sá»‘ 'novelty' náº¿u mÃ¬nh cho báº±ng False thÃ¬ nÃ³ detect ra cÃ¡c outlier, cho báº±ng True thÃ¬ nÃ³ detect ra cÃ¡c Ä‘iá»ƒm má»›i (?) vÃ  chá»‰ sá»­ dá»¥ng cho novelty = True trÃªn má»—i táº­p test, em khÃ´ng hiá»ƒu lÃ  náº¿u cho novelty = True thÃ¬ cÃ¡c Ä‘iá»ƒm nÃ³ detect ra cÃ³ Ã½ nghÄ©a gÃ¬ vÃ  cÃ¡c Ä‘iá»ƒm nÃ y sáº½ Ä‘Æ°á»£c dÃ¹ng cho má»¥c Ä‘Ã­ch gÃ¬ áº¡? 4. LiÃªn quan Ä‘áº¿n cÃ¢u há»i sá»‘ (1), náº¿u trong 2000 dÃ²ng nÃ y mÃ¬nh bá» ra 200 dÃ²ng mÃ¬nh cho lÃ  outlier, sau Ä‘Ã³ mÃ¬nh chá»‰ dÃ¹ng 1800 dÃ²ng cÃ²n láº¡i Ä‘á»ƒ sá»­ dá»¥ng thÃ¬ cÃ¡ch lÃ m nÃ y cÃ³ Ä‘Ãºng khÃ´ng áº¡? Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c vÃ  mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em áº¡.",,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i váº­t to cá»¡ bao nhiÃªu thÃ¬ detect train cÃ³ hiá»‡u quáº£ nhá»‰, em Ä‘á»c cÃ³ source báº£o lÃ  Ã­t nháº¥t pháº£i 20% thÃ¬ má»›i recognition Ä‘Æ°á»£c [1]. Object cá»§a em toÃ n táº§m nÃ y hhoáº·c nhá» hÆ¡n cá»¡ 50x50px trong áº£nh 1000x1000, thÃ¬ cÃ³ nÃªn chia nhá» áº£nh ra ná»¯a khÃ´ng .
Ai cÃ³ kinh nghiá»‡m preprocessing áº£nh gá»£i Ã½ cho em cÃ³ nÃªn equalize Ã¡nh sÃ¡ng ná»¯a khÃ´ng hay chuyá»ƒn sang tráº¯ng Ä‘en Ä‘á»ƒ Ä‘áº¡t hiá»ƒu quáº£ hÆ¡n khÃ´ng nhá»‰
https://openaccess.thecvf.com/content_CVPRW_2019/papers/UAVision/Unel_The_Power_of_Tiling_for_Small_Object_Detection_CVPRW_2019_paper.pdf","Má»i ngÆ°á»i Æ¡i cho em há»i váº­t to cá»¡ bao nhiÃªu thÃ¬ detect train cÃ³ hiá»‡u quáº£ nhá»‰, em Ä‘á»c cÃ³ source báº£o lÃ  Ã­t nháº¥t pháº£i 20% thÃ¬ má»›i recognition Ä‘Æ°á»£c [1]. Object cá»§a em toÃ n táº§m nÃ y hhoáº·c nhá» hÆ¡n cá»¡ 50x50px trong áº£nh 1000x1000, thÃ¬ cÃ³ nÃªn chia nhá» áº£nh ra ná»¯a khÃ´ng . Ai cÃ³ kinh nghiá»‡m preprocessing áº£nh gá»£i Ã½ cho em cÃ³ nÃªn equalize Ã¡nh sÃ¡ng ná»¯a khÃ´ng hay chuyá»ƒn sang tráº¯ng Ä‘en Ä‘á»ƒ Ä‘áº¡t hiá»ƒu quáº£ hÆ¡n khÃ´ng nhá»‰ https://openaccess.thecvf.com/content_CVPRW_2019/papers/UAVision/Unel_The_Power_of_Tiling_for_Small_Object_Detection_CVPRW_2019_paper.pdf",,,,,
"Hello má»i ngÆ°á»i, sáº¯p tá»›i em cÃ³ dá»± Ä‘á»‹nh Ä‘i thá»±c táº­p vá» lÄ©nh vá»±c deep learning. Cho em há»i cÃ¡c anh/chá»‹ Ä‘i trÆ°á»›c lÃ  trong thá»±c táº¿ cÃ¡c doanh nghiá»‡p hiá»‡n nÃ y há» dÃ¹ng pretrained models nhiá»u hÆ¡n hay lÃ  custom models (tá»©c models tá»± lÃ m) nhiá»u hÆ¡n áº¡?
p/s: bá»©c áº£nh mang tÃ­nh cháº¥t vui nhá»™n :v
#DeepLearning","Hello má»i ngÆ°á»i, sáº¯p tá»›i em cÃ³ dá»± Ä‘á»‹nh Ä‘i thá»±c táº­p vá» lÄ©nh vá»±c deep learning. Cho em há»i cÃ¡c anh/chá»‹ Ä‘i trÆ°á»›c lÃ  trong thá»±c táº¿ cÃ¡c doanh nghiá»‡p hiá»‡n nÃ y há» dÃ¹ng pretrained models nhiá»u hÆ¡n hay lÃ  custom models (tá»©c models tá»± lÃ m) nhiá»u hÆ¡n áº¡? p/s: bá»©c áº£nh mang tÃ­nh cháº¥t vui nhá»™n :v",#DeepLearning,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, em muá»‘n há»i lÃ  cÃ³ ai biáº¿t sá»­ dá»¥ng mÃ£ hoÃ¡ homomorphic trong há»‡ thá»‘ng ML Ä‘á»ƒ báº£o máº­t dá»¯ liá»‡u khÃ´ng áº¡?
Em Ä‘Ã£ Ä‘á»c thÃ¬ tháº¥y ráº±ng nÃ³ cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n, mÃ´ hÃ¬nh nháº­n diá»‡n khuÃ´n máº·t (máº«u vÃ  káº¿t quáº£ Ä‘á»u Ä‘Æ°á»£c mÃ£ hoÃ¡). NgoÃ i ra thÃ¬ cÃ²n cÃ³ thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh nÃ o khÃ¡c khÃ´ng áº¡?
Em cáº£m Æ¡n áº¡!","Em chÃ o má»i ngÆ°á»i áº¡, em muá»‘n há»i lÃ  cÃ³ ai biáº¿t sá»­ dá»¥ng mÃ£ hoÃ¡ homomorphic trong há»‡ thá»‘ng ML Ä‘á»ƒ báº£o máº­t dá»¯ liá»‡u khÃ´ng áº¡? Em Ä‘Ã£ Ä‘á»c thÃ¬ tháº¥y ráº±ng nÃ³ cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n, mÃ´ hÃ¬nh nháº­n diá»‡n khuÃ´n máº·t (máº«u vÃ  káº¿t quáº£ Ä‘á»u Ä‘Æ°á»£c mÃ£ hoÃ¡). NgoÃ i ra thÃ¬ cÃ²n cÃ³ thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh nÃ o khÃ¡c khÃ´ng áº¡? Em cáº£m Æ¡n áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i, Em lÃ  ngÆ°á»i má»›i há»c vá» ML. Em cÅ©ng Ä‘Ã£ tham kháº£o qua list bÃ i giáº£ng cá»§a Andrew Ng vÃ  tháº¥y cÅ©ng hiá»ƒu Ä‘c chÃºt. NhÆ°ng khi bÆ°á»›c vÃ o thá»±c táº¿ code thÃ¬ tháº¥y cÃ²n thiáº¿u ráº¥t nhiá»u kinh nghiá»‡m. Em cÃ³ 2 cÃ¢u há»i :
LÃ  ngÆ°á»i tá»± há»c nÃªn ráº¥t mong má»i ngÆ°á»i cho Ã½ kiáº¿n vá» lá»™ trÃ¬nh  há»c hay phÆ°Æ¡ng phÃ¡p há»c Ä‘á»ƒ tiáº¿p cáº­n vá»›i ngÃ nh nÃ y (chÃ­nh).
Em Ä‘ang muá»‘n xÃ¢y dá»±ng model siamese, pháº§n xá»­ lÃ½ áº£nh Ä‘á»ƒ táº¡o vector thÃ¬ em Ä‘ang muá»‘n sá»­ dá»¥ng model cá»§a ngÆ°á»i ta Ä‘Ã£ train rá»“i. em chá»‰ train cÃ¡c lá»›p khi so sÃ¡nh sá»± khÃ¡c biáº¿t giá»¯a 2 bá»©c áº£nh vÃ  giá»¯ nguyÃªn weight cá»§a lá»›p xá»­ lÃ½ áº£nh. Em cÅ©ng nháº·t ra Ä‘Æ°á»£c vÃ i source code nhÆ°ng khÃ´ng biáº¿t sá»­ dá»¥ng. Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em Ã½ nghÄ©a cÃ¡c file trÃªn vÃ  cÃ¡ch sá»­ dá»¥ng.","ChÃ o má»i ngÆ°á»i, Em lÃ  ngÆ°á»i má»›i há»c vá» ML. Em cÅ©ng Ä‘Ã£ tham kháº£o qua list bÃ i giáº£ng cá»§a Andrew Ng vÃ  tháº¥y cÅ©ng hiá»ƒu Ä‘c chÃºt. NhÆ°ng khi bÆ°á»›c vÃ o thá»±c táº¿ code thÃ¬ tháº¥y cÃ²n thiáº¿u ráº¥t nhiá»u kinh nghiá»‡m. Em cÃ³ 2 cÃ¢u há»i : LÃ  ngÆ°á»i tá»± há»c nÃªn ráº¥t mong má»i ngÆ°á»i cho Ã½ kiáº¿n vá» lá»™ trÃ¬nh há»c hay phÆ°Æ¡ng phÃ¡p há»c Ä‘á»ƒ tiáº¿p cáº­n vá»›i ngÃ nh nÃ y (chÃ­nh). Em Ä‘ang muá»‘n xÃ¢y dá»±ng model siamese, pháº§n xá»­ lÃ½ áº£nh Ä‘á»ƒ táº¡o vector thÃ¬ em Ä‘ang muá»‘n sá»­ dá»¥ng model cá»§a ngÆ°á»i ta Ä‘Ã£ train rá»“i. em chá»‰ train cÃ¡c lá»›p khi so sÃ¡nh sá»± khÃ¡c biáº¿t giá»¯a 2 bá»©c áº£nh vÃ  giá»¯ nguyÃªn weight cá»§a lá»›p xá»­ lÃ½ áº£nh. Em cÅ©ng nháº·t ra Ä‘Æ°á»£c vÃ i source code nhÆ°ng khÃ´ng biáº¿t sá»­ dá»¥ng. Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em Ã½ nghÄ©a cÃ¡c file trÃªn vÃ  cÃ¡ch sá»­ dá»¥ng.",,,,,
"One-way ANOVA cho feature selection.
ChÃ o má»i ngÆ°á»i, e cÃ³ má»™t chÃºt tháº¯c máº¯c vá» viá»‡c chá»n feature. Dataset cá»§a em gá»“m 10 nummerical features (cÃ³ mean vÃ  std gáº§n giá»‘ng nhau, cá»¥ thá»ƒ lÃ  0.5 vÃ  0.38) vÃ  categorial target. ANOVA giáº£ sá»­ data lÃ  normal distribution. Sau khi thá»±c hiá»‡n normalize features, e sá»­ dá»¥ng ANOVA cho feature selection thÃ¬ ra Ä‘Æ°á»£c táº­p features nhÆ° e muá»‘n. Tuy nhiÃªn khi e tham kháº£o cÃ¡c example khÃ¡c ngÆ°á»i ta lÃ m, thÃ¬ khÃ´ng tháº¥y bÆ°á»›c normalize data. Em muá»‘n há»i lÃ 
(1) Khi nháº¯c tá»›i normalize data cho ANOVA, nghÄ©a lÃ  normalize trÃªn features hay normalize trÃªn target
(2) CÃ³ cáº§n thiáº¿t pháº£i normalize data trÆ°á»›c khi dÃ¹ng one way ANOVA cho feature selection khÃ´ng
Em xin cÃ¡m Æ¡n","One-way ANOVA cho feature selection. ChÃ o má»i ngÆ°á»i, e cÃ³ má»™t chÃºt tháº¯c máº¯c vá» viá»‡c chá»n feature. Dataset cá»§a em gá»“m 10 nummerical features (cÃ³ mean vÃ  std gáº§n giá»‘ng nhau, cá»¥ thá»ƒ lÃ  0.5 vÃ  0.38) vÃ  categorial target. ANOVA giáº£ sá»­ data lÃ  normal distribution. Sau khi thá»±c hiá»‡n normalize features, e sá»­ dá»¥ng ANOVA cho feature selection thÃ¬ ra Ä‘Æ°á»£c táº­p features nhÆ° e muá»‘n. Tuy nhiÃªn khi e tham kháº£o cÃ¡c example khÃ¡c ngÆ°á»i ta lÃ m, thÃ¬ khÃ´ng tháº¥y bÆ°á»›c normalize data. Em muá»‘n há»i lÃ  (1) Khi nháº¯c tá»›i normalize data cho ANOVA, nghÄ©a lÃ  normalize trÃªn features hay normalize trÃªn target (2) CÃ³ cáº§n thiáº¿t pháº£i normalize data trÆ°á»›c khi dÃ¹ng one way ANOVA cho feature selection khÃ´ng Em xin cÃ¡m Æ¡n",,,,,
"Hi má»i ngÆ°á»i,
Em lÃ  thÃ nh viÃªn má»›i táº­p tÃ nh vá» Machine Learning. Em cÃ³ 1 cÃ¢u há»i liÃªn quan Ä‘áº¿n ""learning rate"" trong thuáº­t toÃ¡n gradient descent nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡.
Theo em tÃ¬m hiá»ƒu Ä‘Æ°á»£c thÃ¬ cÃ³ nhiá»u cÃ¡ch thay Ä‘á»•i learning rate nÃ y Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c giÃ¡ trá»‹ tá»‘i Æ°u nháº¥t (nhÆ° á»Ÿ áº£nh dÆ°á»›i). Em Ä‘ang suy nghÄ© liá»‡u learning rate nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c há»c ""stochastic"" Ä‘Æ°á»£c khÃ´ng? NghÄ©a lÃ , em sáº½ gÃ¡n má»™t phÃ¢n phá»‘i cá»¥ thá»ƒ cho nÃ³, Ä‘á»‘i vá»›i má»—i vÃ²ng láº·p giÃ¡ trá»‹ nÃ y sáº½ thay Ä‘á»•i má»™t cÃ¡ch ngáº«u nhiÃªn tuá»³ thuá»™c vÃ o cÃ¡i phÃ¢n phá»‘i cá»§a nÃ³. Em Ä‘Ã£ tÃ¬m nhÆ°ng hiá»‡n táº¡i cÅ©ng chÆ°a ra research article nÃ o vá» cÃ¡i nÃ y áº¡, em hiá»‡n táº¡i Ä‘ang muá»‘n nghiÃªn cá»©u thÃªm vá» thuáº­t toÃ¡n nhiá»u hÆ¡n. Mong má»i ngÆ°á»i chá»‰ giÃ¡o áº¡. Many thanks!
https://en.wikipedia.org/wiki/Learning_rate","Hi má»i ngÆ°á»i, Em lÃ  thÃ nh viÃªn má»›i táº­p tÃ nh vá» Machine Learning. Em cÃ³ 1 cÃ¢u há»i liÃªn quan Ä‘áº¿n ""learning rate"" trong thuáº­t toÃ¡n gradient descent nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡. Theo em tÃ¬m hiá»ƒu Ä‘Æ°á»£c thÃ¬ cÃ³ nhiá»u cÃ¡ch thay Ä‘á»•i learning rate nÃ y Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c giÃ¡ trá»‹ tá»‘i Æ°u nháº¥t (nhÆ° á»Ÿ áº£nh dÆ°á»›i). Em Ä‘ang suy nghÄ© liá»‡u learning rate nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c há»c ""stochastic"" Ä‘Æ°á»£c khÃ´ng? NghÄ©a lÃ , em sáº½ gÃ¡n má»™t phÃ¢n phá»‘i cá»¥ thá»ƒ cho nÃ³, Ä‘á»‘i vá»›i má»—i vÃ²ng láº·p giÃ¡ trá»‹ nÃ y sáº½ thay Ä‘á»•i má»™t cÃ¡ch ngáº«u nhiÃªn tuá»³ thuá»™c vÃ o cÃ¡i phÃ¢n phá»‘i cá»§a nÃ³. Em Ä‘Ã£ tÃ¬m nhÆ°ng hiá»‡n táº¡i cÅ©ng chÆ°a ra research article nÃ o vá» cÃ¡i nÃ y áº¡, em hiá»‡n táº¡i Ä‘ang muá»‘n nghiÃªn cá»©u thÃªm vá» thuáº­t toÃ¡n nhiá»u hÆ¡n. Mong má»i ngÆ°á»i chá»‰ giÃ¡o áº¡. Many thanks! https://en.wikipedia.org/wiki/Learning_rate",,,,,
"ChÃ o cÃ¡c báº¡n.
MÃ¬nh má»›i tÃ¬m hiá»ƒu vá» deep learning.
MÃ¬nh cÃ³ má»™t cÃ¢u há»i lÃ  vs optimizer lÃ  GSD, thÃ¬ máº·c Ä‘á»‹nh batch size lÃ  1, má»—i láº§n update weight vÃ  bias chá»‰ lá»±a chá»n ngáº«u nhiÃªn 1 input Ä‘áº§u vÃ o Ä‘á»ƒ tÃ­nh.
Khi training vá»›i hÃ m fit, ko Ä‘áº·t batch size , thÃ¬ máº·c Ä‘á»‹nh batch size lÃ  32.
Giáº£ sá»­ dlieu training lÃ  120 thÃ¬ sáº½ tÃ­nh toÃ¡n tháº¿ nÃ o Ä‘á»ƒ update weights vÃ  bias áº¡? Batch size =32 sáº½ áº£nh hÆ°á»Ÿng tá»›i viá»‡c training vs optimize lÃ  SGD nhÆ° tháº¿ nÃ o áº¡?
MÃ¬nh xin cáº£m Æ¡n .","ChÃ o cÃ¡c báº¡n. MÃ¬nh má»›i tÃ¬m hiá»ƒu vá» deep learning. MÃ¬nh cÃ³ má»™t cÃ¢u há»i lÃ  vs optimizer lÃ  GSD, thÃ¬ máº·c Ä‘á»‹nh batch size lÃ  1, má»—i láº§n update weight vÃ  bias chá»‰ lá»±a chá»n ngáº«u nhiÃªn 1 input Ä‘áº§u vÃ o Ä‘á»ƒ tÃ­nh. Khi training vá»›i hÃ m fit, ko Ä‘áº·t batch size , thÃ¬ máº·c Ä‘á»‹nh batch size lÃ  32. Giáº£ sá»­ dlieu training lÃ  120 thÃ¬ sáº½ tÃ­nh toÃ¡n tháº¿ nÃ o Ä‘á»ƒ update weights vÃ  bias áº¡? Batch size =32 sáº½ áº£nh hÆ°á»Ÿng tá»›i viá»‡c training vs optimize lÃ  SGD nhÆ° tháº¿ nÃ o áº¡? MÃ¬nh xin cáº£m Æ¡n .",,,,,
"ChÃ o má»i ngÆ°á»i,
TrÃªn trang Facebook cá»§a Amazon Web Services Ä‘ang cÃ³ chia sáº» cá»§a Suman Debnath, Principal Developer Advocate vá» Machine Learning, vÃ  Amazon SageMaker. Má»i ngÆ°á»i cÃ³ thá»ƒ tham dá»± buá»•i live vÃ  Ä‘áº·t cÃ¢u há»i trá»±c tiáº¿p cho diá»…n giáº£ :)
https://www.facebook.com/watch/live/?v=827355334869097","ChÃ o má»i ngÆ°á»i, TrÃªn trang Facebook cá»§a Amazon Web Services Ä‘ang cÃ³ chia sáº» cá»§a Suman Debnath, Principal Developer Advocate vá» Machine Learning, vÃ  Amazon SageMaker. Má»i ngÆ°á»i cÃ³ thá»ƒ tham dá»± buá»•i live vÃ  Ä‘áº·t cÃ¢u há»i trá»±c tiáº¿p cho diá»…n giáº£ :) https://www.facebook.com/watch/live/?v=827355334869097",,,,,
"[Nhá» cá»™ng Ä‘á»“ng chung tay share giÃºp]
Báº¡n hay ngÆ°á»i thÃ¢n cá»§a báº¡n lÃ  F1 hay F0?
Máº·c dÃ¹ Ä‘ang ráº¥t lo láº¯ng cho sá»©c khá»e báº£n thÃ¢n hay ngÆ°á»i thÃ¢n, nhÆ°ng náº¿u cÃ³ thá»ƒ, báº¡n hÃ£y chung sá»©c vá»›i gáº§n 200 chuyÃªn gia trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) Ä‘ang tham gia phÃ¡t triá»ƒn giáº£i phÃ¡p â€œNháº­n dáº¡ng Covid-19 qua tiáº¿ng ho""
Báº±ng cÃ¡ch ghi Ã¢m tiáº¿ng ho cá»§a báº¡n hay ngÆ°á»i thÃ¢n báº¡n
Tá»« Ä‘áº§u thÃ¡ng 6.2021, gáº§n 200 chuyÃªn gia trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) Ä‘ang miá»‡t mÃ i tham gia phÃ¡t triá»ƒn giáº£i phÃ¡p â€œNháº­n dáº¡ng Covid-19 qua tiáº¿ng ho"" do dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN tá»• chá»©c. Má»¥c tiÃªu lÃ  xÃ¢y dá»±ng giáº£i phÃ¡p AI, Ä‘á»ƒ cÃ¡c cÆ¡ quan chá»©c nÄƒng sÃ ng lá»c nhanh Covid-19 trÃªn diá»‡n rá»™ng, thÃ´ng qua há»‡ thá»‘ng Callbot - gá»i Ä‘iá»‡n tá»± Ä‘á»™ng cho hÃ ng ngÃ n ngÆ°á»i má»™t lÃºc vÃ  Ä‘á» nghá»‹ ho ghi láº¡i tiáº¿ng ho qua cuá»™c gá»i. Äáº¡i há»c MIT (Má»¹) Ä‘Ã£ cÃ´ng bá»‘ giáº£i phÃ¡p tÆ°Æ¡ng tá»± vá»›i Ä‘á»™ chÃ­nh xÃ¡c lÃªn Ä‘áº¿n 97% (chá»‰ sá»‘ AUC), vÃ  Ä‘ang tiáº¿n hÃ nh thá»§ tá»¥c xin FDA cáº¥p phÃ©p. Cho tá»›i nay, cÃ¡c Ä‘á»™i tham gia cuá»™c thi táº¡i Viá»‡t Nam Ä‘Ã£ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t lÃ  90%, tuy nhiÃªn vÃ¬ cÃ¡c máº«u tiáº¿ng ho Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n AI cÃ²n Ã­t, vÃ  Ä‘a sá»‘ khÃ´ng pháº£i dá»¯ liá»‡u cá»§a ngÆ°á»i Viá»‡t, nÃªn cÃ¡c giáº£i phÃ¡p cÃ³ thá»ƒ chÆ°a sá»­ dá»¥ng Ä‘Æ°á»£c á»Ÿ Viá»‡t Nam.
Sá»‘ ca nhiá»…m COVID-19 má»›i táº¡i Viá»‡t Nam gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘áº¡t má»©c ká»· lá»¥c hÆ¡n 700 ca má»—i ngÃ y, vÃ  cÃ³ nguy cÆ¡ bÃ¹ng phÃ¡t diá»‡n rá»™ng á»Ÿ má»™t sá»‘ tá»‰nh thÃ nh. Cáº£ nÆ°á»›c Ä‘ang gá»“ng háº¿t sá»©c Ä‘á»ƒ chá»‘ng dá»‹ch, vÃ  má»™t trong nhá»¯ng hÃ¬nh áº£nh cáº£m Ä‘á»™ng thÆ°á»ng tháº¥y nháº¥t lÃ  cÃ¡c y bÃ¡c sÄ© máº·c Ä‘á»“ báº£o há»™ kÃ­n mÃ­t, giá»¯a trá»i náº¯ng 40 Ä‘á»™, Ä‘á»ƒ láº¥y máº«u xÃ©t nghiá»‡m cho hÃ ng ngÃ n ngÆ°á»i. Liá»‡u cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ¡c y bÃ¡c sÄ© Ä‘á»¡ váº¥t váº£ hÆ¡n? Giáº£i phÃ¡p nÃ y, náº¿u dÃ¹ chá»‰ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c chÆ°a cao, nhÆ°ng cÅ©ng cÃ³ thá»ƒ giÃºp Ã­ch Ä‘Æ°á»£c pháº§n nÃ o trong cuá»™c chiáº¿n chá»‘ng dá»‹ch. CÃ¡c nhÃ³m Ä‘áº¡t giáº£i trong cuá»™c thi cam káº¿t chuyá»ƒn giao giáº£i phÃ¡p cho Ban chá»‰ Ä‘áº¡o quá»‘c gia phÃ²ng chá»‘ng Covid-19 Ä‘á»ƒ triá»ƒn khai sÃ ng lá»c trÃªn diá»‡n rá»™ng. NhÃ³m tÃ¡c giáº£ cÃ³ thá»ƒ sá»­ dá»¥ng giáº£i phÃ¡p vÃ o má»¥c Ä‘Ã­ch khÃ¡c tÃ¹y nhu cáº§u.
Máº·c dÃ¹ Ä‘ang ráº¥t lo láº¯ng cho sá»©c khá»e báº£n thÃ¢n, nhÆ°ng náº¿u cÃ³ thá»ƒ, báº¡n hÃ£y chung sá»©c báº±ng cÃ¡ch sau:
1. Ngay bÃ¢y giá»: Ghi Ã¢m tiáº¿ng ho cá»§a báº¡n
- VÃ o FB Fanpage cá»§a dá»± Ã¡n: https://bit.ly/aicovidvn2
- Nháº¥n nÃºt â€œSend Messageâ€
- Nháº¥n nÃºt (+) bÃªn trÃ¡i
- Nháº¥n nÃºt ghi Ã¢m
- Ho 4 tiáº¿ng, cháº­m rÃ£i, cÃ¡ch nhau 1 chÃºt
2. Khi cÃ³ káº¿t quáº£ xÃ©t nghiá»‡m: BÃ¡o káº¿t quáº£
- CÅ©ng vÃ o Fanpage trÃªn
- Nháº¥n nÃºt â€œSend Messageâ€
- Nháº¯n tin: â€œÃ‚m tÃ­nhâ€ hoáº·c â€œDÆ°Æ¡ng tÃ­nhâ€
Má»™t sá»‘ Ä‘Æ°á»ng link khÃ¡c:
FB Group cá»§a dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVn: bit.ly/aicovidvn
 â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  4 ngÆ°á»i khÃ¡c.","[Nhá» cá»™ng Ä‘á»“ng chung tay share giÃºp] Báº¡n hay ngÆ°á»i thÃ¢n cá»§a báº¡n lÃ  F1 hay F0? Máº·c dÃ¹ Ä‘ang ráº¥t lo láº¯ng cho sá»©c khá»e báº£n thÃ¢n hay ngÆ°á»i thÃ¢n, nhÆ°ng náº¿u cÃ³ thá»ƒ, báº¡n hÃ£y chung sá»©c vá»›i gáº§n 200 chuyÃªn gia trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) Ä‘ang tham gia phÃ¡t triá»ƒn giáº£i phÃ¡p â€œNháº­n dáº¡ng Covid-19 qua tiáº¿ng ho"" Báº±ng cÃ¡ch ghi Ã¢m tiáº¿ng ho cá»§a báº¡n hay ngÆ°á»i thÃ¢n báº¡n Tá»« Ä‘áº§u thÃ¡ng 6.2021, gáº§n 200 chuyÃªn gia trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) Ä‘ang miá»‡t mÃ i tham gia phÃ¡t triá»ƒn giáº£i phÃ¡p â€œNháº­n dáº¡ng Covid-19 qua tiáº¿ng ho"" do dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN tá»• chá»©c. Má»¥c tiÃªu lÃ  xÃ¢y dá»±ng giáº£i phÃ¡p AI, Ä‘á»ƒ cÃ¡c cÆ¡ quan chá»©c nÄƒng sÃ ng lá»c nhanh Covid-19 trÃªn diá»‡n rá»™ng, thÃ´ng qua há»‡ thá»‘ng Callbot - gá»i Ä‘iá»‡n tá»± Ä‘á»™ng cho hÃ ng ngÃ n ngÆ°á»i má»™t lÃºc vÃ  Ä‘á» nghá»‹ ho ghi láº¡i tiáº¿ng ho qua cuá»™c gá»i. Äáº¡i há»c MIT (Má»¹) Ä‘Ã£ cÃ´ng bá»‘ giáº£i phÃ¡p tÆ°Æ¡ng tá»± vá»›i Ä‘á»™ chÃ­nh xÃ¡c lÃªn Ä‘áº¿n 97% (chá»‰ sá»‘ AUC), vÃ  Ä‘ang tiáº¿n hÃ nh thá»§ tá»¥c xin FDA cáº¥p phÃ©p. Cho tá»›i nay, cÃ¡c Ä‘á»™i tham gia cuá»™c thi táº¡i Viá»‡t Nam Ä‘Ã£ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t lÃ  90%, tuy nhiÃªn vÃ¬ cÃ¡c máº«u tiáº¿ng ho Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n AI cÃ²n Ã­t, vÃ  Ä‘a sá»‘ khÃ´ng pháº£i dá»¯ liá»‡u cá»§a ngÆ°á»i Viá»‡t, nÃªn cÃ¡c giáº£i phÃ¡p cÃ³ thá»ƒ chÆ°a sá»­ dá»¥ng Ä‘Æ°á»£c á»Ÿ Viá»‡t Nam. Sá»‘ ca nhiá»…m COVID-19 má»›i táº¡i Viá»‡t Nam gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘áº¡t má»©c ká»· lá»¥c hÆ¡n 700 ca má»—i ngÃ y, vÃ  cÃ³ nguy cÆ¡ bÃ¹ng phÃ¡t diá»‡n rá»™ng á»Ÿ má»™t sá»‘ tá»‰nh thÃ nh. Cáº£ nÆ°á»›c Ä‘ang gá»“ng háº¿t sá»©c Ä‘á»ƒ chá»‘ng dá»‹ch, vÃ  má»™t trong nhá»¯ng hÃ¬nh áº£nh cáº£m Ä‘á»™ng thÆ°á»ng tháº¥y nháº¥t lÃ  cÃ¡c y bÃ¡c sÄ© máº·c Ä‘á»“ báº£o há»™ kÃ­n mÃ­t, giá»¯a trá»i náº¯ng 40 Ä‘á»™, Ä‘á»ƒ láº¥y máº«u xÃ©t nghiá»‡m cho hÃ ng ngÃ n ngÆ°á»i. Liá»‡u cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ¡c y bÃ¡c sÄ© Ä‘á»¡ váº¥t váº£ hÆ¡n? Giáº£i phÃ¡p nÃ y, náº¿u dÃ¹ chá»‰ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c chÆ°a cao, nhÆ°ng cÅ©ng cÃ³ thá»ƒ giÃºp Ã­ch Ä‘Æ°á»£c pháº§n nÃ o trong cuá»™c chiáº¿n chá»‘ng dá»‹ch. CÃ¡c nhÃ³m Ä‘áº¡t giáº£i trong cuá»™c thi cam káº¿t chuyá»ƒn giao giáº£i phÃ¡p cho Ban chá»‰ Ä‘áº¡o quá»‘c gia phÃ²ng chá»‘ng Covid-19 Ä‘á»ƒ triá»ƒn khai sÃ ng lá»c trÃªn diá»‡n rá»™ng. NhÃ³m tÃ¡c giáº£ cÃ³ thá»ƒ sá»­ dá»¥ng giáº£i phÃ¡p vÃ o má»¥c Ä‘Ã­ch khÃ¡c tÃ¹y nhu cáº§u. Máº·c dÃ¹ Ä‘ang ráº¥t lo láº¯ng cho sá»©c khá»e báº£n thÃ¢n, nhÆ°ng náº¿u cÃ³ thá»ƒ, báº¡n hÃ£y chung sá»©c báº±ng cÃ¡ch sau: 1. Ngay bÃ¢y giá»: Ghi Ã¢m tiáº¿ng ho cá»§a báº¡n - VÃ o FB Fanpage cá»§a dá»± Ã¡n: https://bit.ly/aicovidvn2 - Nháº¥n nÃºt â€œSend Messageâ€ - Nháº¥n nÃºt (+) bÃªn trÃ¡i - Nháº¥n nÃºt ghi Ã¢m - Ho 4 tiáº¿ng, cháº­m rÃ£i, cÃ¡ch nhau 1 chÃºt 2. Khi cÃ³ káº¿t quáº£ xÃ©t nghiá»‡m: BÃ¡o káº¿t quáº£ - CÅ©ng vÃ o Fanpage trÃªn - Nháº¥n nÃºt â€œSend Messageâ€ - Nháº¯n tin: â€œÃ‚m tÃ­nhâ€ hoáº·c â€œDÆ°Æ¡ng tÃ­nhâ€ Má»™t sá»‘ Ä‘Æ°á»ng link khÃ¡c: FB Group cá»§a dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVn: bit.ly/aicovidvn â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  4 ngÆ°á»i khÃ¡c.",,,,,
"ChÃ o cÃ¡c anh chá»‹ áº¡. Em lÃ  newbie machine learning áº¡. Em má»›i há»c Ä‘Æ°á»£c chÆ°a lÃ¢u mÃ  hÃ´m nay tháº§y em ra bÃ i nÃ y, em khÃ´ng biáº¿t pháº£i giáº£i quyáº¿t tháº¿ nÃ o áº¡. Em mong cÃ¡c anh chá»‹ nhiá»u kinh nghiá»‡m cÃ³ thá»ƒ help em hÆ°á»›ng giáº£i quyáº¿t vá»›i áº¡. Táº¡i vÃ¬ em Ä‘á»c cÃ¡c vÃ­ dá»¥, cÃ¡c dá»¯ liá»‡u training Ä‘á»u á»Ÿ dáº¡ng sá»‘ áº¡. CÃ²n bÃ i tháº§y em ra thÃ¬ ráº¥t nhiá»u dá»¯ liá»‡u khÃ´ng Ä‘Æ¡n thuáº§n lÃ  sá»‘ ( em khÃ´ng biáº¿t nÃ³ cÃ³ áº£nh hÆ°á»Ÿng gÃ¬ khÃ´ng áº¡), nÃªn em khÃ´ng biáº¿t pháº£i gÃ¡n nhÃ£n hay xá»­ lÃ½ tháº¿ nÃ o áº¡.
BÃ i toÃ¡n Ä‘áº·t ra lÃ  vá»›i táº­p dá»¯ liá»‡u (giá»‘ng trong hÃ¬nh em áº¡), hÃ£y Ä‘Æ°a ra dá»± bÃ¡o thá»i tiáº¿t ngÃ y mai áº¡. Em cáº£m Æ¡n áº¡. CÃ³ cÃ¡ch nÃ o Ä‘Æ¡n giáº£n nháº¥t vÃ  dá»… hiá»‡u nháº¥t cÃ ng tá»‘t áº¡.","ChÃ o cÃ¡c anh chá»‹ áº¡. Em lÃ  newbie machine learning áº¡. Em má»›i há»c Ä‘Æ°á»£c chÆ°a lÃ¢u mÃ  hÃ´m nay tháº§y em ra bÃ i nÃ y, em khÃ´ng biáº¿t pháº£i giáº£i quyáº¿t tháº¿ nÃ o áº¡. Em mong cÃ¡c anh chá»‹ nhiá»u kinh nghiá»‡m cÃ³ thá»ƒ help em hÆ°á»›ng giáº£i quyáº¿t vá»›i áº¡. Táº¡i vÃ¬ em Ä‘á»c cÃ¡c vÃ­ dá»¥, cÃ¡c dá»¯ liá»‡u training Ä‘á»u á»Ÿ dáº¡ng sá»‘ áº¡. CÃ²n bÃ i tháº§y em ra thÃ¬ ráº¥t nhiá»u dá»¯ liá»‡u khÃ´ng Ä‘Æ¡n thuáº§n lÃ  sá»‘ ( em khÃ´ng biáº¿t nÃ³ cÃ³ áº£nh hÆ°á»Ÿng gÃ¬ khÃ´ng áº¡), nÃªn em khÃ´ng biáº¿t pháº£i gÃ¡n nhÃ£n hay xá»­ lÃ½ tháº¿ nÃ o áº¡. BÃ i toÃ¡n Ä‘áº·t ra lÃ  vá»›i táº­p dá»¯ liá»‡u (giá»‘ng trong hÃ¬nh em áº¡), hÃ£y Ä‘Æ°a ra dá»± bÃ¡o thá»i tiáº¿t ngÃ y mai áº¡. Em cáº£m Æ¡n áº¡. CÃ³ cÃ¡ch nÃ o Ä‘Æ¡n giáº£n nháº¥t vÃ  dá»… hiá»‡u nháº¥t cÃ ng tá»‘t áº¡.",,,,,
"[Deep Learning Project]
MÃ¬nh chia sáº» má»™t sá»‘ project cá»§a cÃ¡c báº¡n há»c sinh khÃ³a Deep Learning.
1. Nháº­n diá»‡n viá»‡c Ä‘eo kháº©u trang nháº±m phÃ³ng chá»‘ng covid.
2. TrÃ­ch xuáº¥t thÃ´ng tin tráº­n Ä‘áº¥u bÃ³ng Ä‘Ã¡ nhÆ°: tÃªn hai Ä‘á»™i, tá»‰ sá»‘, cáº§u
thá»§ ghi bÃ n,...
3. Há»‡ thá»‘ng cháº¥m thi tráº¯c nghiá»‡m tá»± Ä‘á»™ng.
4. Khoanh vÃ¹ng khÃ­ quáº£n vÃ  nhÃ¡nh pháº¿ quáº£n chÃ­nh trong áº£nh CT.","[Deep Learning Project] MÃ¬nh chia sáº» má»™t sá»‘ project cá»§a cÃ¡c báº¡n há»c sinh khÃ³a Deep Learning. 1. Nháº­n diá»‡n viá»‡c Ä‘eo kháº©u trang nháº±m phÃ³ng chá»‘ng covid. 2. TrÃ­ch xuáº¥t thÃ´ng tin tráº­n Ä‘áº¥u bÃ³ng Ä‘Ã¡ nhÆ°: tÃªn hai Ä‘á»™i, tá»‰ sá»‘, cáº§u thá»§ ghi bÃ n,... 3. Há»‡ thá»‘ng cháº¥m thi tráº¯c nghiá»‡m tá»± Ä‘á»™ng. 4. Khoanh vÃ¹ng khÃ­ quáº£n vÃ  nhÃ¡nh pháº¿ quáº£n chÃ­nh trong áº£nh CT.",,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  activation cÃ³ 'linear' áº¡, sao mÃ¬nh vÃ o activation cá»§a Keras thÃ¬ láº¡i khÃ´ng tháº¥y gÃ¬ cáº£?
https://machinelearningcoban.com/2018/07/06/deeplearning/","Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  activation cÃ³ 'linear' áº¡, sao mÃ¬nh vÃ o activation cá»§a Keras thÃ¬ láº¡i khÃ´ng tháº¥y gÃ¬ cáº£? https://machinelearningcoban.com/2018/07/06/deeplearning/",,,,,
"[Chia sáº»] 5 nguá»“n dataset há»¯u Ã­ch cho cÃ¡c dá»± Ã¡n Machine Learning.
Tháº¥y cÃ³ 2 cÃ¡i dá»± Ã¡n vá» Y táº¿ lÃ  ADNI vá»›i AICovid khÃ¡ thÃº vá»‹. Hy vá»ng Ä‘Æ°á»£c cáº­p nháº­t thÃªm vá» tÃ¬nh hÃ¬nh 2 dá»± Ã¡n nÃ y.
#machinelearning #datascience #datasets #ADNI #VSAB #aicovid #Spotify #BigFivetest",[Chia sáº»] 5 nguá»“n dataset há»¯u Ã­ch cho cÃ¡c dá»± Ã¡n Machine Learning. Tháº¥y cÃ³ 2 cÃ¡i dá»± Ã¡n vá» Y táº¿ lÃ  ADNI vá»›i AICovid khÃ¡ thÃº vá»‹. Hy vá»ng Ä‘Æ°á»£c cáº­p nháº­t thÃªm vá» tÃ¬nh hÃ¬nh 2 dá»± Ã¡n nÃ y.,#machinelearning	#datascience	#datasets	#ADNI	#VSAB	#aicovid	#Spotify	#BigFivetest,,,,
"#quyhoachtuyentinh #LinearProgramming

Hi cÃ¡c a chá»‹. E Ä‘ang tÃ¬m hiá»ƒu vá» má»™t sá»‘ váº¥n Ä‘á» liÃªn quan Ä‘áº¿n tá»‘i Æ°u tuyáº¿n tÃ­nh, cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y lÃ  quy hoáº¡ch tuyáº¿n tÃ­nh, Ä‘á»ƒ tiá»‡n hÆ¡n cho viá»‡c thá»­ nghiá»‡m vÃ  há»c táº­p, em muá»‘n xin gá»£i Ã½ má»™t sá»‘ thÆ° viá»‡n tá»‘i Æ°u tuyáº¿n tÃ­nh Ä‘á»ƒ cháº¡y cÃ¡c vÃ­ dá»¥ má»™t cÃ¡ch trá»±c quan, vá»›i cÃ¡c tham sá»‘ Ä‘á»ƒ giáº£i bÃ i toÃ¡n dÆ°á»›i Ä‘Ã¢y (nhÆ° hÃ¬nh váº½) gá»“m: 
+ HÃ m má»¥c tiÃªu ( tuyáº¿n tÃ­nh ) 
+ RÃ ng buá»™c lá»ng ( < hoáº·c = ) 
+ RÃ ng buá»™c cháº·t ( = )
+ Táº­p Ä‘iá»u kiá»‡n cháº·n cá»§a biáº¿n 

Hiá»‡n táº¡i thÃ¬ em cÃ³ sá»­ dá»¥ng thÆ° viá»‡n linprog cá»§a  scipy.optimize  Ä‘á»ƒ cháº¡y vÃ­ dá»¥, nhÆ°ng táº§m 70 biáº¿n trá»Ÿ lÃªn lÃ  khÃ´ng hoáº¡t Ä‘á»™ng nhÆ° Ã½, vÃ¬ váº­y, e muá»‘n há»i cÃ¡c a chá»‹ cÃ³ kinh nghiá»‡m vá» cÃ¡i nÃ y: CÃ³ thÆ° viá»‡n nÃ o thay tháº¿ thÆ° viá»‡n trÃªn khÃ´ng, vá»›i cáº£ nhanh 1 chÃºt Ä‘á»ƒ cháº¡y Ä‘Æ°á»£c táº§m 200+ biáº¿n trá»Ÿ lÃªn áº¡. 
E xin cáº£m Æ¡n.  ","Hi cÃ¡c a chá»‹. E Ä‘ang tÃ¬m hiá»ƒu vá» má»™t sá»‘ váº¥n Ä‘á» liÃªn quan Ä‘áº¿n tá»‘i Æ°u tuyáº¿n tÃ­nh, cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y lÃ  quy hoáº¡ch tuyáº¿n tÃ­nh, Ä‘á»ƒ tiá»‡n hÆ¡n cho viá»‡c thá»­ nghiá»‡m vÃ  há»c táº­p, em muá»‘n xin gá»£i Ã½ má»™t sá»‘ thÆ° viá»‡n tá»‘i Æ°u tuyáº¿n tÃ­nh Ä‘á»ƒ cháº¡y cÃ¡c vÃ­ dá»¥ má»™t cÃ¡ch trá»±c quan, vá»›i cÃ¡c tham sá»‘ Ä‘á»ƒ giáº£i bÃ i toÃ¡n dÆ°á»›i Ä‘Ã¢y (nhÆ° hÃ¬nh váº½) gá»“m: + HÃ m má»¥c tiÃªu ( tuyáº¿n tÃ­nh ) + RÃ ng buá»™c lá»ng ( < hoáº·c = ) + RÃ ng buá»™c cháº·t ( = ) + Táº­p Ä‘iá»u kiá»‡n cháº·n cá»§a biáº¿n Hiá»‡n táº¡i thÃ¬ em cÃ³ sá»­ dá»¥ng thÆ° viá»‡n linprog cá»§a scipy.optimize Ä‘á»ƒ cháº¡y vÃ­ dá»¥, nhÆ°ng táº§m 70 biáº¿n trá»Ÿ lÃªn lÃ  khÃ´ng hoáº¡t Ä‘á»™ng nhÆ° Ã½, vÃ¬ váº­y, e muá»‘n há»i cÃ¡c a chá»‹ cÃ³ kinh nghiá»‡m vá» cÃ¡i nÃ y: CÃ³ thÆ° viá»‡n nÃ o thay tháº¿ thÆ° viá»‡n trÃªn khÃ´ng, vá»›i cáº£ nhanh 1 chÃºt Ä‘á»ƒ cháº¡y Ä‘Æ°á»£c táº§m 200+ biáº¿n trá»Ÿ lÃªn áº¡. E xin cáº£m Æ¡n.",#quyhoachtuyentinh	#LinearProgramming,"#math, #Q&A",,,
Má»i ngÆ°á»i cho mÃ¬nh há»i hai tá»« precision vÃ  recall thÃ¬ thuáº­t ngá»¯ tiáº¿ng Viá»‡t lÃ  gÃ¬ nhá»‰?,Má»i ngÆ°á»i cho mÃ¬nh há»i hai tá»« precision vÃ  recall thÃ¬ thuáº­t ngá»¯ tiáº¿ng Viá»‡t lÃ  gÃ¬ nhá»‰?,,,,,
Hy vá»ng bÃ i viáº¿t vá» káº¿t ná»‘i táº¯t sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n sinh viÃªn Ä‘ang lÃ m quen vá»›i há»c sÃ¢u,Hy vá»ng bÃ i viáº¿t vá» káº¿t ná»‘i táº¯t sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n sinh viÃªn Ä‘ang lÃ m quen vá»›i há»c sÃ¢u,,,,,
https://youtu.be/Boj9eD0Wug8,https://youtu.be/Boj9eD0Wug8,,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang train model nháº­n diá»‡n áº£nh chÃ³ mÃ¨o, em cÃ³ Ä‘á»c má»™t vÃ i notebook trÃªn kaggle thÃ¬ ngÆ°á»i ta cÃ³ sá»­ dá»¥ng thÃªm callback. Cá»¥ thá»ƒ nhÆ° giáº£m learning rate, rá»“i earlystop.... Em thÃ¬ bá» pháº§n callback Ä‘i vÃ  em cÅ©ng cÃ³ generator data thÃªm thÃ¬ Ä‘Æ°á»£c hÃ¬nh nhÆ° á»Ÿ dÆ°á»›i. Em tháº¥y hÃ¬nh nhÆ° á»Ÿ dÆ°á»›i thÃ¬ nhÆ° epoch Ä‘áº§u hÆ¡i bá»‹ lÃªn xuá»‘ng quÃ¡ nhiá»u vá» sau thÃ¬ cÃ³ Ä‘á»¡ hÆ¡n chÃºt. Váº­y thÃ¬ training model nhÆ° váº­y cÃ³ pháº£i lÃ  quÃ¡ xáº¥u hay xáº¥u gÃ¬ khÃ´ng áº¡. MÃ¬nh cáº§n cáº£i thiá»‡n gÃ¬ ngoÃ i callback... (model em cÅ©ng Ä‘Ã£ dÃ¹ng drop out cÃ¡c thá»©, em chá»‰ dÃ¹ng thÃ´i chá»© chÆ°a hiá»ƒu pháº£i chá»‰nh sá»­a ra sao). Mong má»i ngÆ°á»i gÃ³p Ã½ giÃºp em áº¡.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang train model nháº­n diá»‡n áº£nh chÃ³ mÃ¨o, em cÃ³ Ä‘á»c má»™t vÃ i notebook trÃªn kaggle thÃ¬ ngÆ°á»i ta cÃ³ sá»­ dá»¥ng thÃªm callback. Cá»¥ thá»ƒ nhÆ° giáº£m learning rate, rá»“i earlystop.... Em thÃ¬ bá» pháº§n callback Ä‘i vÃ  em cÅ©ng cÃ³ generator data thÃªm thÃ¬ Ä‘Æ°á»£c hÃ¬nh nhÆ° á»Ÿ dÆ°á»›i. Em tháº¥y hÃ¬nh nhÆ° á»Ÿ dÆ°á»›i thÃ¬ nhÆ° epoch Ä‘áº§u hÆ¡i bá»‹ lÃªn xuá»‘ng quÃ¡ nhiá»u vá» sau thÃ¬ cÃ³ Ä‘á»¡ hÆ¡n chÃºt. Váº­y thÃ¬ training model nhÆ° váº­y cÃ³ pháº£i lÃ  quÃ¡ xáº¥u hay xáº¥u gÃ¬ khÃ´ng áº¡. MÃ¬nh cáº§n cáº£i thiá»‡n gÃ¬ ngoÃ i callback... (model em cÅ©ng Ä‘Ã£ dÃ¹ng drop out cÃ¡c thá»©, em chá»‰ dÃ¹ng thÃ´i chá»© chÆ°a hiá»ƒu pháº£i chá»‰nh sá»­a ra sao). Mong má»i ngÆ°á»i gÃ³p Ã½ giÃºp em áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
"[YOLOv3-Deep learning-Computer vision] ChÃ o má»i ngÆ°á»i, MÃ¬nh xin giá»›i thiá»‡u má»™t bá»™ cÃ´ng cá»¥ cá»§a Intel, cho phÃ©p chÃºng ta triá»ƒn khai nhanh cÃ¡c á»©ng dá»¥ng hoáº·c xá»­ lÃ­ cÃ¡c váº¥n Ä‘á» liÃªn quan tá»›i thá»‹ giÃ¡c mÃ¡y tÃ­nh(Computer vision) vá»›i hiá»‡u suáº¥t cao trÃªn cÃ¡c pháº§n cá»©ng cá»§a Intel nhÆ° CPU, GPU, VPUs, FPGA.... Sá»­ dá»¥ng nÃ³ chÃºng ta thá»ƒ cháº¡y mÃ´ hÃ¬nh Object detection vá»›i Ä‘áº§u vÃ o lÃ  Video trÃªn CPU vÃ  cho káº¿t quáº£ khÃ¡ tá»‘t.
Chi tiáº¿t táº¡i: https://ptitdeveloper.com/blog/openvino-toi-uu-hoa-hieu-suat-model-darknet-yolov3/","[YOLOv3-Deep learning-Computer vision] ChÃ o má»i ngÆ°á»i, MÃ¬nh xin giá»›i thiá»‡u má»™t bá»™ cÃ´ng cá»¥ cá»§a Intel, cho phÃ©p chÃºng ta triá»ƒn khai nhanh cÃ¡c á»©ng dá»¥ng hoáº·c xá»­ lÃ­ cÃ¡c váº¥n Ä‘á» liÃªn quan tá»›i thá»‹ giÃ¡c mÃ¡y tÃ­nh(Computer vision) vá»›i hiá»‡u suáº¥t cao trÃªn cÃ¡c pháº§n cá»©ng cá»§a Intel nhÆ° CPU, GPU, VPUs, FPGA.... Sá»­ dá»¥ng nÃ³ chÃºng ta thá»ƒ cháº¡y mÃ´ hÃ¬nh Object detection vá»›i Ä‘áº§u vÃ o lÃ  Video trÃªn CPU vÃ  cho káº¿t quáº£ khÃ¡ tá»‘t. Chi tiáº¿t táº¡i: https://ptitdeveloper.com/blog/openvino-toi-uu-hoa-hieu-suat-model-darknet-yolov3/",,,,,
"ChÃ o má»i ngÆ°á»i,
Em má»›i táº­p tÃ nh há»c vá» ML vÃ  DL, hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh vá»›i Cifar100, em cÃ³ follow theo má»™t bÃ i hÆ°á»›ng dáº«n trÃªn máº¡ng cÃ³ yÃªu cáº§u custom data generator class (cá»¥ thá»ƒ nhÆ° á»Ÿ dÆ°á»›i hÃ¬nh áº¡). VÃ i thÃ¡ng trÆ°á»›c em cháº¡y thÃ¬ khÃ´ng hiá»‡n thÃ´ng bÃ¡o lá»—i gÃ¬, Ä‘áº¿n hÃ´m nay cháº¡y láº¡i khi fit vÃ o model thÃ¬ nÃ³ láº¡i cÃ³ lá»—i nhÆ° trong hÃ¬nh áº¡ :(((
Má»i ngÆ°á»i ai biáº¿t cÃ¡ch fix cÃ³ thá»ƒ giÃºp em vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.","ChÃ o má»i ngÆ°á»i, Em má»›i táº­p tÃ nh há»c vá» ML vÃ  DL, hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh vá»›i Cifar100, em cÃ³ follow theo má»™t bÃ i hÆ°á»›ng dáº«n trÃªn máº¡ng cÃ³ yÃªu cáº§u custom data generator class (cá»¥ thá»ƒ nhÆ° á»Ÿ dÆ°á»›i hÃ¬nh áº¡). VÃ i thÃ¡ng trÆ°á»›c em cháº¡y thÃ¬ khÃ´ng hiá»‡n thÃ´ng bÃ¡o lá»—i gÃ¬, Ä‘áº¿n hÃ´m nay cháº¡y láº¡i khi fit vÃ o model thÃ¬ nÃ³ láº¡i cÃ³ lá»—i nhÆ° trong hÃ¬nh áº¡ :((( Má»i ngÆ°á»i ai biáº¿t cÃ¡ch fix cÃ³ thá»ƒ giÃºp em vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.",,,,,
"[HELP] LÃ m sao chuyá»ƒn tiáº¿ng Viá»‡t mÃ£ unicode sang utf-8 trÃªn python3?
Hiá»‡n táº¡i em Ä‘ang gáº·p khÃ³ khÄƒn khi muá»‘n chuyá»ƒn Ä‘á»•i tá»« unicode sang utf-8, vÃ  em cÅ©ng hÆ¡i tháº¯c máº¯c lÃ  tá»« unicode chuyá»ƒn sang utf-8 thÃ¬ cÃ³ Ä‘áº¿n 2 dáº¡ng, em xin mÃ´ táº£ bÃ i toÃ¡n cá»§a em:
Input: má»™t chuá»—i (vÃ­ dá»¥: xin chÃ o má»i ngÆ°á»i)
Output: chuá»—i dáº¡ng utf-8 (xin chÃƒ o mÃ¡Â»ï¿½i ngÃ†Â°Ã¡Â»ï¿½i)
Hiá»‡n táº¡i em Ä‘Ã£ thá»­ hÃ m encode nhÆ°ng káº¿t quáº£ nháº­n Ä‘Æ°á»£c lÃ  dÆ°á»›i dáº¡ng utf-8 mÃ  em muá»‘n. Káº¿t quáº£ em ra tá»« vÃ­ dá»¥ trÃªn lÃ : \x78\x69\x6e \x63\x68\xc3\xa0\x6f \x6d\xe1\xbb\x8d\x69 \x6e\x67\xc6\xb0\xe1\xbb\x9d\x69
Hy vá»ng Ä‘Æ°á»£c má»i anh chá»‹, vÃ  má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","[HELP] LÃ m sao chuyá»ƒn tiáº¿ng Viá»‡t mÃ£ unicode sang utf-8 trÃªn python3? Hiá»‡n táº¡i em Ä‘ang gáº·p khÃ³ khÄƒn khi muá»‘n chuyá»ƒn Ä‘á»•i tá»« unicode sang utf-8, vÃ  em cÅ©ng hÆ¡i tháº¯c máº¯c lÃ  tá»« unicode chuyá»ƒn sang utf-8 thÃ¬ cÃ³ Ä‘áº¿n 2 dáº¡ng, em xin mÃ´ táº£ bÃ i toÃ¡n cá»§a em: Input: má»™t chuá»—i (vÃ­ dá»¥: xin chÃ o má»i ngÆ°á»i) Output: chuá»—i dáº¡ng utf-8 (xin chÃƒ o mÃ¡Â»i ngÃ†Â°Ã¡Â»i) Hiá»‡n táº¡i em Ä‘Ã£ thá»­ hÃ m encode nhÆ°ng káº¿t quáº£ nháº­n Ä‘Æ°á»£c lÃ  dÆ°á»›i dáº¡ng utf-8 mÃ  em muá»‘n. Káº¿t quáº£ em ra tá»« vÃ­ dá»¥ trÃªn lÃ : \x78\x69\x6e \x63\x68\xc3\xa0\x6f \x6d\xe1\xbb\x8d\x69 \x6e\x67\xc6\xb0\xe1\xbb\x9d\x69 Hy vá»ng Ä‘Æ°á»£c má»i anh chá»‹, vÃ  má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"ChÃ o má»i ngÆ°á»i áº¡
E Ä‘ang lÃ m 1 pháº§n vá» tÃ­nh toÃ¡n thá»i gian váº­t xuáº¥t hiá»‡n sau khi detect+ track báº±ng Yolo. Em Ä‘Ã£ detect Ä‘Æ°á»£c vÃ  cÃ³ ID cá»§a tá»«ng object. E test thá»­ vá»›i 1 file video. Video detect cá»§a e Ä‘Æ°á»£c khoáº£ng 1.5 FPS.
E tÃ­nh thá»i gian báº±ng cÃ¡ch xÃ©t theo tá»«ng frame, náº¿u váº­t xuáº¥t hiá»‡n thÃ¬ e sáº½ dÃ¹ng time_now() Ä‘á»ƒ thu Ä‘Æ°á»£c thá»i gian láº§n Ä‘áº§u váº­t xuáº¥t hiá»‡n.
Tuy nhiÃªn, cÃ³ 1 váº¥n Ä‘á» nhÆ° sau áº¡:
E giáº£ sá»­ 1 váº­t xuáº¥t hiá»‡n á»Ÿ frame 1. E dÃ¹ng hÃ m time_now Ä‘á»ƒ báº¯t Ä‘Æ°á»£c thá»i gian nÃ³ xuáº¥t hiá»‡n láº§n Ä‘áº§u (time_start) . Giáº£ sá»­ nÃ³ xuáº¥t hiá»‡n Ä‘áº¿n frame 70, thÃ¬ e tÃ­nh thá»i gian tá»“n táº¡i báº±ng time_now() - thá»i gian nÃ³ báº¯t Ä‘áº§u xuáº¥t hiÃªn ( time_now - time_start ). VÃ  e thu Ä‘Æ°á»£c káº¿t quáº£ nÃ³ tá»“n táº¡i lÃ  80s ( do FPS detect cá»§a e khoáº£ng 1.5 FPS, váº­t xuáº¥t hiá»‡n tá»« frame 0 Ä‘áº¿n frame 70), e tháº¥y khÃ¡ há»£p lÃ½
NhÆ°ng thá»±c táº¿ lÃ  trong video real time thÃ¬ váº­t Ä‘Ã³ chá»‰ tá»“n táº¡i 3-4 s
Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº¯t Ä‘Æ°á»£c Ä‘Ãºng thá»i gian váº­t xuáº¥t hiá»‡n trong file video ban Ä‘áº§u ko áº¡. E bá»‹ vÆ°á»›ng Ä‘oáº¡n nÃ y mÃ  chÆ°a tÃ¬m Ä‘Æ°á»£c solution. Ráº¥t mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u","ChÃ o má»i ngÆ°á»i áº¡ E Ä‘ang lÃ m 1 pháº§n vá» tÃ­nh toÃ¡n thá»i gian váº­t xuáº¥t hiá»‡n sau khi detect+ track báº±ng Yolo. Em Ä‘Ã£ detect Ä‘Æ°á»£c vÃ  cÃ³ ID cá»§a tá»«ng object. E test thá»­ vá»›i 1 file video. Video detect cá»§a e Ä‘Æ°á»£c khoáº£ng 1.5 FPS. E tÃ­nh thá»i gian báº±ng cÃ¡ch xÃ©t theo tá»«ng frame, náº¿u váº­t xuáº¥t hiá»‡n thÃ¬ e sáº½ dÃ¹ng time_now() Ä‘á»ƒ thu Ä‘Æ°á»£c thá»i gian láº§n Ä‘áº§u váº­t xuáº¥t hiá»‡n. Tuy nhiÃªn, cÃ³ 1 váº¥n Ä‘á» nhÆ° sau áº¡: E giáº£ sá»­ 1 váº­t xuáº¥t hiá»‡n á»Ÿ frame 1. E dÃ¹ng hÃ m time_now Ä‘á»ƒ báº¯t Ä‘Æ°á»£c thá»i gian nÃ³ xuáº¥t hiá»‡n láº§n Ä‘áº§u (time_start) . Giáº£ sá»­ nÃ³ xuáº¥t hiá»‡n Ä‘áº¿n frame 70, thÃ¬ e tÃ­nh thá»i gian tá»“n táº¡i báº±ng time_now() - thá»i gian nÃ³ báº¯t Ä‘áº§u xuáº¥t hiÃªn ( time_now - time_start ). VÃ  e thu Ä‘Æ°á»£c káº¿t quáº£ nÃ³ tá»“n táº¡i lÃ  80s ( do FPS detect cá»§a e khoáº£ng 1.5 FPS, váº­t xuáº¥t hiá»‡n tá»« frame 0 Ä‘áº¿n frame 70), e tháº¥y khÃ¡ há»£p lÃ½ NhÆ°ng thá»±c táº¿ lÃ  trong video real time thÃ¬ váº­t Ä‘Ã³ chá»‰ tá»“n táº¡i 3-4 s Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº¯t Ä‘Æ°á»£c Ä‘Ãºng thá»i gian váº­t xuáº¥t hiá»‡n trong file video ban Ä‘áº§u ko áº¡. E bá»‹ vÆ°á»›ng Ä‘oáº¡n nÃ y mÃ  chÆ°a tÃ¬m Ä‘Æ°á»£c solution. Ráº¥t mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u",,,,,
"Anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u thuáº­t ngá»¯ chuyÃªn ngÃ nh vá» AI, NLP, PhoBert, Pretrainâ€¦ Tiáº¿ng anh â€” > Viá»‡t cho mÃ¬nh xin nhÃ©. Äa táº¡.","Anh chá»‹ nÃ o cÃ³ tÃ i liá»‡u thuáº­t ngá»¯ chuyÃªn ngÃ nh vá» AI, NLP, PhoBert, Pretrainâ€¦ Tiáº¿ng anh â€” > Viá»‡t cho mÃ¬nh xin nhÃ©. Äa táº¡.",,,,,
"Em chÃ o anh/chá»‹ áº¡,
Em cÅ©ng lÃ  má»™t sinh viÃªn má»›i ra trÆ°á»ng Ä‘Æ°á»£c 2 nÄƒm vÃ  Ä‘i lÃ m vá» dá»¯ liá»‡u (chá»§ yáº¿u lÃ  lÃ m data science, phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh mÃ¡y há»c). NhÆ°ng em váº«n cÃ²n bÄƒn khoÄƒn vá» cÃ¢u há»i Ä‘á»‹nh hÆ°á»›ng cá»§a báº£n thÃ¢n trong 5 nÄƒm tá»›i, 10 nÄƒm tá»›i Ä‘á»‘i vá»›i cÃ´ng viá»‡c hiá»‡n táº¡i nhÆ° tháº¿ nÃ o?
Em cÅ©ng cÃ³ tá»± tráº£ lá»i cho báº£n thÃ¢n trÆ°á»›c:
DÃ nh 2 nÄƒm tiáº¿p theo Ä‘á»ƒ lÃ m tháº­t nhiá»u phÃ¢n tÃ­ch dá»¯ liá»‡u, phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c Ä‘á»ƒ tháº­t sá»± giá»i vá» ngÃ nh nÃ y
á» 2 nÄƒm tiáº¿p theo, em mong muá»‘n Ä‘Æ°á»£c lÃªn lÃ m team lead Ä‘á»ƒ cÃ³ thá»ƒ triá»ƒn khai nhiá»u dá»± Ã¡n, vÃ  Ä‘á»“ng thá»i há»c cÃ¡ch lÃ m viá»‡c vá»›i con ngÆ°á»i, tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c thÃ nh viÃªn trong team Ä‘á»ƒ Ä‘áº¡t má»¥c tiÃªu chung cá»§a sáº£n pháº©m
á» 3 nÄƒm tiáº¿p theo ná»¯a, em mong muá»‘n Ä‘Æ°á»£c lÃ m PM vá» data (cÃ³ thuáº­t ngá»¯ gá»i lÃ  Data Guru), má»¥c Ä‘Ã­ch cá»§a em lÃ  Ä‘Æ°á»£c lÃ m viá»‡c vá»›i cÃ¡c phÃ²ng ban khÃ¡c nhÆ° marketing, finance, IT, UI/UX Ä‘á»ƒ há»c cÃ¡ch xÃ¢y dá»±ng sáº£n pháº©m cho ngÆ°á»i dÃ¹ng
VÃ  á»Ÿ 4 nÄƒm tiáº¿p theo, em sáº½ há»c cÃ¡ch tá»± phÃ¡t triá»ƒn á»©ng dá»¥ng phá»¥c vá»¥ cÃ¡c nhu cáº§u vá» xá»­ lÃ½ dá»¯ liá»‡u, xÃ¢y dá»±ng mÃ´ hÃ¬nh mÃ¡y há»c Ä‘á»ƒ phá»¥c vá»¥ nhu cáº§u cá»§a cÃ¡c doanh nghiá»‡p.
KhÃ´ng biáº¿t anh/chá»‹ nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m trong ngÃ nh cÃ³ thá»ƒ gÃ³p Ã½ con Ä‘Æ°á»ng em Ä‘i cÃ³ kháº£ thi hay khÃ´ng? VÃ  khÃ´ng biáº¿t anh chá»‹ Ä‘Ã£ Ä‘i má»™t con Ä‘Æ°á»ng nhÆ° tháº¿ nÃ o khi lÃ m vá» dá»¯ liá»‡u, cÃ³ thá»ƒ chia sáº» vá»›i em Ä‘á»ƒ em há»c thÃªm Ä‘Æ°á»£c khÃ´ng áº¡?
Em cáº£m Æ¡n anh/chá»‹ ráº¥t nhiá»u, chÃºc má»i ngÆ°á»i giá»¯ sá»©c khá»e tháº­t tá»‘t trong thá»i gian chá»‘ng dá»‹ch áº¡","Em chÃ o anh/chá»‹ áº¡, Em cÅ©ng lÃ  má»™t sinh viÃªn má»›i ra trÆ°á»ng Ä‘Æ°á»£c 2 nÄƒm vÃ  Ä‘i lÃ m vá» dá»¯ liá»‡u (chá»§ yáº¿u lÃ  lÃ m data science, phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh mÃ¡y há»c). NhÆ°ng em váº«n cÃ²n bÄƒn khoÄƒn vá» cÃ¢u há»i Ä‘á»‹nh hÆ°á»›ng cá»§a báº£n thÃ¢n trong 5 nÄƒm tá»›i, 10 nÄƒm tá»›i Ä‘á»‘i vá»›i cÃ´ng viá»‡c hiá»‡n táº¡i nhÆ° tháº¿ nÃ o? Em cÅ©ng cÃ³ tá»± tráº£ lá»i cho báº£n thÃ¢n trÆ°á»›c: DÃ nh 2 nÄƒm tiáº¿p theo Ä‘á»ƒ lÃ m tháº­t nhiá»u phÃ¢n tÃ­ch dá»¯ liá»‡u, phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c Ä‘á»ƒ tháº­t sá»± giá»i vá» ngÃ nh nÃ y á» 2 nÄƒm tiáº¿p theo, em mong muá»‘n Ä‘Æ°á»£c lÃªn lÃ m team lead Ä‘á»ƒ cÃ³ thá»ƒ triá»ƒn khai nhiá»u dá»± Ã¡n, vÃ  Ä‘á»“ng thá»i há»c cÃ¡ch lÃ m viá»‡c vá»›i con ngÆ°á»i, tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c thÃ nh viÃªn trong team Ä‘á»ƒ Ä‘áº¡t má»¥c tiÃªu chung cá»§a sáº£n pháº©m á» 3 nÄƒm tiáº¿p theo ná»¯a, em mong muá»‘n Ä‘Æ°á»£c lÃ m PM vá» data (cÃ³ thuáº­t ngá»¯ gá»i lÃ  Data Guru), má»¥c Ä‘Ã­ch cá»§a em lÃ  Ä‘Æ°á»£c lÃ m viá»‡c vá»›i cÃ¡c phÃ²ng ban khÃ¡c nhÆ° marketing, finance, IT, UI/UX Ä‘á»ƒ há»c cÃ¡ch xÃ¢y dá»±ng sáº£n pháº©m cho ngÆ°á»i dÃ¹ng VÃ  á»Ÿ 4 nÄƒm tiáº¿p theo, em sáº½ há»c cÃ¡ch tá»± phÃ¡t triá»ƒn á»©ng dá»¥ng phá»¥c vá»¥ cÃ¡c nhu cáº§u vá» xá»­ lÃ½ dá»¯ liá»‡u, xÃ¢y dá»±ng mÃ´ hÃ¬nh mÃ¡y há»c Ä‘á»ƒ phá»¥c vá»¥ nhu cáº§u cá»§a cÃ¡c doanh nghiá»‡p. KhÃ´ng biáº¿t anh/chá»‹ nÃ o Ä‘Ã£ cÃ³ kinh nghiá»‡m trong ngÃ nh cÃ³ thá»ƒ gÃ³p Ã½ con Ä‘Æ°á»ng em Ä‘i cÃ³ kháº£ thi hay khÃ´ng? VÃ  khÃ´ng biáº¿t anh chá»‹ Ä‘Ã£ Ä‘i má»™t con Ä‘Æ°á»ng nhÆ° tháº¿ nÃ o khi lÃ m vá» dá»¯ liá»‡u, cÃ³ thá»ƒ chia sáº» vá»›i em Ä‘á»ƒ em há»c thÃªm Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n anh/chá»‹ ráº¥t nhiá»u, chÃºc má»i ngÆ°á»i giá»¯ sá»©c khá»e tháº­t tá»‘t trong thá»i gian chá»‘ng dá»‹ch áº¡",,,,,
Xin phÃ©o chia sáº» cÃ¹ng má»i ngÆ°á»i há»™i tháº£o vá» xÃ¢y dá»±ng mÃ´ hÃ¬nh AI trong xá»­ lÃ½ áº£nh y táº¿ vÃ  xá»­ lÃ½ bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n,Xin phÃ©o chia sáº» cÃ¹ng má»i ngÆ°á»i há»™i tháº£o vá» xÃ¢y dá»±ng mÃ´ hÃ¬nh AI trong xá»­ lÃ½ áº£nh y táº¿ vÃ  xá»­ lÃ½ bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n,,,,,
"Chia sáº» vá»›i cÃ¡c báº¡n káº¿t quáº£ má»›i cá»§a HANET Ai Camera trong thÃ¡ng 2/2021, nháº­n diá»‡n cÃ¹ng lÃºc 3-5 ngÆ°á»i Ä‘eo kháº©u trang, Ä‘i cÃ¹ng nhau. Äeo kÃ­nh Ä‘en, vÃ  Ä‘Äƒng kÃ½ hÃ¬nh áº£nh khÃ¡ch hÃ ng, nhÃ¢n viÃªn ngay trÃªn á»©ng dá»¥ng HANET Connect.
Tá»‰ lá»‡ nháº­n diá»‡n chÃ­nh xÃ¡c 99.9%, cam káº¿t 1.000 ngÆ°á»i khÃ´ng nháº­n sai 1 ngÆ°á»i, ( Nháº­n sai tá»« ngÆ°á»i A sang ngÆ°á»i B )
Nháº­n diá»‡n khuÃ´n máº·t ngay trÃªn camera dá»±a vÃ o NPU tÃ­ch há»£p trong camera vÃ  lÆ°u Ä‘Æ°á»£c 50.000 khuÃ´n máº·t.
Welcome anh em káº¿t ná»‘i API Ä‘á»ƒ phÃ¡t triá»ƒn giáº£i phÃ¡p cá»§a riÃªng mÃ¬nh
API document: https://developers.hanet.ai/document
Tham kháº£o thÃªm vá» sáº£n pháº©m: https://hanet.com/hanet-ai-camera-/","Chia sáº» vá»›i cÃ¡c báº¡n káº¿t quáº£ má»›i cá»§a HANET Ai Camera trong thÃ¡ng 2/2021, nháº­n diá»‡n cÃ¹ng lÃºc 3-5 ngÆ°á»i Ä‘eo kháº©u trang, Ä‘i cÃ¹ng nhau. Äeo kÃ­nh Ä‘en, vÃ  Ä‘Äƒng kÃ½ hÃ¬nh áº£nh khÃ¡ch hÃ ng, nhÃ¢n viÃªn ngay trÃªn á»©ng dá»¥ng HANET Connect. Tá»‰ lá»‡ nháº­n diá»‡n chÃ­nh xÃ¡c 99.9%, cam káº¿t 1.000 ngÆ°á»i khÃ´ng nháº­n sai 1 ngÆ°á»i, ( Nháº­n sai tá»« ngÆ°á»i A sang ngÆ°á»i B ) Nháº­n diá»‡n khuÃ´n máº·t ngay trÃªn camera dá»±a vÃ o NPU tÃ­ch há»£p trong camera vÃ  lÆ°u Ä‘Æ°á»£c 50.000 khuÃ´n máº·t. Welcome anh em káº¿t ná»‘i API Ä‘á»ƒ phÃ¡t triá»ƒn giáº£i phÃ¡p cá»§a riÃªng mÃ¬nh API document: https://developers.hanet.ai/document Tham kháº£o thÃªm vá» sáº£n pháº©m: https://hanet.com/hanet-ai-camera-/",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, Em má»›i táº­p tÃ nh há»c ML chÃºt, xong cÃ³ deadline tháº¿ nÃ y mÃ  em cáº§n váº½ biá»ƒu Ä‘á»“ há»c táº­p cá»§a chÆ°Æ¡ng trÃ¬nh,Háº§u nhÆ° em tháº¥y mn cháº¡y báº±ng chÆ°Æ¡ng trÃ¬nh spyder trÃªn window thÃ¬ dá»… Ä‘á»ƒ bÃ´i Ä‘en code rá»“i cháº¡y, nÃªn má»—i láº§n cháº¡y biá»ƒu Ä‘á»“ ko pháº£i training láº¡i. Em cháº¡y vscode nÃ³ cá»© cháº¡y tá»« trÃªn xuá»‘ng dÆ°Ã³i thÃ´i, bÃ¡c nÃ o cÃ³ cÃ¡ch cho vscode nÃ³ cháº¡y ra biá»ƒu Ä‘á»“ há»c táº­p keras giÃºp em vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. :( em dÃ¢n network qua áº¡. Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i áº¡, Em má»›i táº­p tÃ nh há»c ML chÃºt, xong cÃ³ deadline tháº¿ nÃ y mÃ  em cáº§n váº½ biá»ƒu Ä‘á»“ há»c táº­p cá»§a chÆ°Æ¡ng trÃ¬nh,Háº§u nhÆ° em tháº¥y mn cháº¡y báº±ng chÆ°Æ¡ng trÃ¬nh spyder trÃªn window thÃ¬ dá»… Ä‘á»ƒ bÃ´i Ä‘en code rá»“i cháº¡y, nÃªn má»—i láº§n cháº¡y biá»ƒu Ä‘á»“ ko pháº£i training láº¡i. Em cháº¡y vscode nÃ³ cá»© cháº¡y tá»« trÃªn xuá»‘ng dÆ°Ã³i thÃ´i, bÃ¡c nÃ o cÃ³ cÃ¡ch cho vscode nÃ³ cháº¡y ra biá»ƒu Ä‘á»“ há»c táº­p keras giÃºp em vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. :( em dÃ¢n network qua áº¡. Em cáº£m Æ¡n áº¡.",,,,,
"[Nhá» cá»™ng Ä‘á»“ng cÃ¹ng chung tay share]
CUá»˜C THI SÃNG Táº O GIáº¢I PHÃP TRÃ TUá»† NHÃ‚N Táº O (AI)
NHáº¬N Dáº NG COVID QUA TIáº¾NG HO
GIáº¢I THÆ¯á»NG 115 TRIá»†U Äá»’NG
ThÃ¡ng 6/2021, sá»‘ ca nhiá»…m COVID-19 má»›i táº¡i Viá»‡t Nam Ä‘áº¡t má»©c ká»· lá»¥c 400-500 ca má»—i ngÃ y, vÃ  cÃ³ nguy cÆ¡ bÃ¹ng phÃ¡t diá»‡n rá»™ng á»Ÿ má»™t sá»‘ tá»‰nh thÃ nh. Cáº£ nÆ°á»›c Ä‘ang gá»“ng háº¿t sá»©c Ä‘á»ƒ chá»‘ng dá»‹ch, vÃ  má»™t trong nhá»¯ng hÃ¬nh áº£nh thÆ°á»ng tháº¥y nháº¥t lÃ  cÃ¡c y bÃ¡c sÄ© máº·c Ä‘á»“ báº£o há»™ kÃ­n mÃ­t, giá»¯a trá»i náº¯ng 40 Ä‘á»™, Ä‘á»ƒ láº¥y máº«u xÃ©t nghiá»‡m cho hÃ ng ngÃ n ngÆ°á»i. Liá»‡u cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ thá»±c hiá»‡n viá»‡c nÃ y hiá»‡u quáº£ hÆ¡n? CÃ¡c nhÃ  nghiÃªn cá»©u trÃªn tháº¿ giá»›i Ä‘Ã£ chá»‰ ra ráº±ng cÃ³ thá»ƒ phÃ¡t hiá»‡n COVID-19 qua tiáº¿ng ho, qua Ä‘iá»‡n thoáº¡i di Ä‘á»™ng báº±ng trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vá»›i Ä‘á»™ chÃ­nh xÃ¡c trÃªn 90%.
Hiá»‡n nay TPHCM Ä‘Ã£ triá»ƒn khai há»‡ thá»‘ng Callbot, qua Ä‘Ã³ AI tá»± Ä‘á»™ng gá»i Ä‘iá»‡n cho hÃ ng triá»‡u ngÆ°á»i dÃ¢n, vÃ  Ä‘áº·t cÃ¢u há»i cho há» Ä‘á»ƒ há» tá»± khai bÃ¡o triá»‡u chá»©ng COVID-19. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a ráº¥t lá»›n trong viá»‡c sÃ ng lá»c nhanh nhá»¯ng ngÆ°á»i cáº§n xÃ©t nghiá»‡m ká»¹ hÆ¡n, vÃ  khoanh vÃ¹ng cÃ¡c á»• dá»‹ch ká»‹p thá»i. Tuy nhiÃªn há»‡ thá»‘ng hiá»‡n nay váº«n cáº§n ngÆ°á»i dÃ¢n tá»± khai bÃ¡o triá»‡u chá»©ng, trong khi nhiá»u ngÆ°á»i máº¯c COVID-19 nhÆ°ng chÆ°a cÃ³ biá»ƒu hiá»‡n bá»‡nh. Äá»ƒ tiáº¿p tá»¥c nÃ¢ng cao hiá»‡u quáº£, dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN tá»• chá»©c cuá»™c thi â€œAICV-115M Challengeâ€ kÃªu gá»i cá»™ng Ä‘á»“ng tham gia xÃ¢y dá»±ng cÃ¡c giáº£i phÃ¡p AI Ä‘á»ƒ thu Ã¢m tiáº¿ng ho cá»§a ngÆ°á»i dÃ¢n qua tá»•ng Ä‘Ã i Ä‘iá»‡n thoáº¡i, rá»“i Ä‘Æ°a ra cháº©n Ä‘oÃ¡n COVID-19 sÆ¡ bá»™. Tá»•ng giáº£i thÆ°á»Ÿng cuá»™c thi trá»‹ giÃ¡ 115 triá»‡u VND do má»™t nhÃ³m startup founders Ä‘Ã³ng gÃ³p.
CÃ¡c nhÃ³m Ä‘áº¡t giáº£i cam káº¿t chuyá»ƒn giao giáº£i phÃ¡p cho Ban chá»‰ Ä‘áº¡o quá»‘c gia phÃ²ng chá»‘ng Covid-19 Ä‘á»ƒ triá»ƒn khai sÃ ng lá»c trÃªn diá»‡n rá»™ng. NhÃ³m tÃ¡c giáº£ cÃ³ thá»ƒ sá»­ dá»¥ng giáº£i phÃ¡p vÃ o má»¥c Ä‘Ã­ch khÃ¡c tÃ¹y nhu cáº§u.
ÄÄƒng kÃ½: www.Covid.AIHub.vn
FB Group: bit.ly/aicovidvn","[Nhá» cá»™ng Ä‘á»“ng cÃ¹ng chung tay share] CUá»˜C THI SÃNG Táº O GIáº¢I PHÃP TRÃ TUá»† NHÃ‚N Táº O (AI) NHáº¬N Dáº NG COVID QUA TIáº¾NG HO GIáº¢I THÆ¯á»NG 115 TRIá»†U Äá»’NG ThÃ¡ng 6/2021, sá»‘ ca nhiá»…m COVID-19 má»›i táº¡i Viá»‡t Nam Ä‘áº¡t má»©c ká»· lá»¥c 400-500 ca má»—i ngÃ y, vÃ  cÃ³ nguy cÆ¡ bÃ¹ng phÃ¡t diá»‡n rá»™ng á»Ÿ má»™t sá»‘ tá»‰nh thÃ nh. Cáº£ nÆ°á»›c Ä‘ang gá»“ng háº¿t sá»©c Ä‘á»ƒ chá»‘ng dá»‹ch, vÃ  má»™t trong nhá»¯ng hÃ¬nh áº£nh thÆ°á»ng tháº¥y nháº¥t lÃ  cÃ¡c y bÃ¡c sÄ© máº·c Ä‘á»“ báº£o há»™ kÃ­n mÃ­t, giá»¯a trá»i náº¯ng 40 Ä‘á»™, Ä‘á»ƒ láº¥y máº«u xÃ©t nghiá»‡m cho hÃ ng ngÃ n ngÆ°á»i. Liá»‡u cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ thá»±c hiá»‡n viá»‡c nÃ y hiá»‡u quáº£ hÆ¡n? CÃ¡c nhÃ  nghiÃªn cá»©u trÃªn tháº¿ giá»›i Ä‘Ã£ chá»‰ ra ráº±ng cÃ³ thá»ƒ phÃ¡t hiá»‡n COVID-19 qua tiáº¿ng ho, qua Ä‘iá»‡n thoáº¡i di Ä‘á»™ng báº±ng trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vá»›i Ä‘á»™ chÃ­nh xÃ¡c trÃªn 90%. Hiá»‡n nay TPHCM Ä‘Ã£ triá»ƒn khai há»‡ thá»‘ng Callbot, qua Ä‘Ã³ AI tá»± Ä‘á»™ng gá»i Ä‘iá»‡n cho hÃ ng triá»‡u ngÆ°á»i dÃ¢n, vÃ  Ä‘áº·t cÃ¢u há»i cho há» Ä‘á»ƒ há» tá»± khai bÃ¡o triá»‡u chá»©ng COVID-19. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a ráº¥t lá»›n trong viá»‡c sÃ ng lá»c nhanh nhá»¯ng ngÆ°á»i cáº§n xÃ©t nghiá»‡m ká»¹ hÆ¡n, vÃ  khoanh vÃ¹ng cÃ¡c á»• dá»‹ch ká»‹p thá»i. Tuy nhiÃªn há»‡ thá»‘ng hiá»‡n nay váº«n cáº§n ngÆ°á»i dÃ¢n tá»± khai bÃ¡o triá»‡u chá»©ng, trong khi nhiá»u ngÆ°á»i máº¯c COVID-19 nhÆ°ng chÆ°a cÃ³ biá»ƒu hiá»‡n bá»‡nh. Äá»ƒ tiáº¿p tá»¥c nÃ¢ng cao hiá»‡u quáº£, dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN tá»• chá»©c cuá»™c thi â€œAICV-115M Challengeâ€ kÃªu gá»i cá»™ng Ä‘á»“ng tham gia xÃ¢y dá»±ng cÃ¡c giáº£i phÃ¡p AI Ä‘á»ƒ thu Ã¢m tiáº¿ng ho cá»§a ngÆ°á»i dÃ¢n qua tá»•ng Ä‘Ã i Ä‘iá»‡n thoáº¡i, rá»“i Ä‘Æ°a ra cháº©n Ä‘oÃ¡n COVID-19 sÆ¡ bá»™. Tá»•ng giáº£i thÆ°á»Ÿng cuá»™c thi trá»‹ giÃ¡ 115 triá»‡u VND do má»™t nhÃ³m startup founders Ä‘Ã³ng gÃ³p. CÃ¡c nhÃ³m Ä‘áº¡t giáº£i cam káº¿t chuyá»ƒn giao giáº£i phÃ¡p cho Ban chá»‰ Ä‘áº¡o quá»‘c gia phÃ²ng chá»‘ng Covid-19 Ä‘á»ƒ triá»ƒn khai sÃ ng lá»c trÃªn diá»‡n rá»™ng. NhÃ³m tÃ¡c giáº£ cÃ³ thá»ƒ sá»­ dá»¥ng giáº£i phÃ¡p vÃ o má»¥c Ä‘Ã­ch khÃ¡c tÃ¹y nhu cáº§u. ÄÄƒng kÃ½: www.Covid.AIHub.vn FB Group: bit.ly/aicovidvn",,,,,
"Trong group cÃ³ ai lÃ m vá»›i thÆ° viá»‡n pyrender trÃªn mÃ´i trÆ°á»ng windows mÃ  gáº·p lá»—i nÃ y chÆ°a áº¡? Google cÃ¡i lá»—i mÃ  khÃ´ng ra.
MÃ¬nh Ä‘ang cháº¡y code dÃ¹ng pyrender Ä‘á»ƒ visualize 3d model. ThÃ¬ lÃºc import thÆ° viá»‡n Ä‘Ã£ bá»‹ lá»—i rá»“i.
import pyrender",Trong group cÃ³ ai lÃ m vá»›i thÆ° viá»‡n pyrender trÃªn mÃ´i trÆ°á»ng windows mÃ  gáº·p lá»—i nÃ y chÆ°a áº¡? Google cÃ¡i lá»—i mÃ  khÃ´ng ra. MÃ¬nh Ä‘ang cháº¡y code dÃ¹ng pyrender Ä‘á»ƒ visualize 3d model. ThÃ¬ lÃºc import thÆ° viá»‡n Ä‘Ã£ bá»‹ lá»—i rá»“i. import pyrender,,,,,
"ChÃ o buá»•i sÃ¡ng táº¥t cáº£ má»i ngÆ°á»i
Em Ä‘ang thá»±c hiá»‡n bÃ i toÃ¡n phÃ¢n loáº¡i 2 mÃ£ sáº£n pháº©m.
Sau khi em detect vÃ¹ng Ä‘áº·c trÆ°ng cá»§a 2 sáº£n pháº©m Ä‘Ã³. ThÃ¬ Ä‘Ã£ in ra káº¿t quáº£ tá»«ng bounding box á»©ng vá»›i má»—i items. ThÃ¬ cÃ³ tá»•ng cá»™ng lÃ  54 items. VÃ  show lÃªn mÃ n hÃ¬nh cÅ©ng 54 bounding box.
BÆ°á»›c tiáº¿p theo, em in boxes ra thÃ¬ e tháº¥y nÃ³ lá»›n hÆ¡n 54. NÃªn khi Ã¡p dá»¥ng thuáº­t toÃ¡n Hough Circles vÃ o thÃ¬ lÃºc váº½ Ä‘Æ°á»ng trÃ²n lÃªn thÃ¬ cÃ³ nhá»¯ng items nÃ³ bá»‹ láº·p láº¡i.
Em Ä‘Ã£ thá»­ set láº¡i ngÆ°á»¡ng cá»§a NMS mÃ  nÃ³ váº«n khÃ´ng háº¡n cháº¿ Ä‘Æ°á»£c bao nhiÃªu.
Má»i ngÆ°á»i trong nhÃ³m ai Ä‘Ã£ tá»«ng lÃ m nhá»¯ng bÃ i toÃ¡n tÆ°Æ¡ng tá»± cÅ©ng nhÆ° cÃ³ hÆ°á»›ng giáº£i quyáº¿t cÃ³ thá»ƒ hÆ°á»›ng dáº«n giÃºp em vá»›i Ä‘Æ°á»£c khÃ´ng áº¡?
HÃ¬nh áº£nh minh há»a em show á»Ÿ dÆ°á»›i cmt nha má»i ngÆ°á»i
Em xin cÃ¡m Æ¡n má»i ngÆ°á»i!!!","ChÃ o buá»•i sÃ¡ng táº¥t cáº£ má»i ngÆ°á»i Em Ä‘ang thá»±c hiá»‡n bÃ i toÃ¡n phÃ¢n loáº¡i 2 mÃ£ sáº£n pháº©m. Sau khi em detect vÃ¹ng Ä‘áº·c trÆ°ng cá»§a 2 sáº£n pháº©m Ä‘Ã³. ThÃ¬ Ä‘Ã£ in ra káº¿t quáº£ tá»«ng bounding box á»©ng vá»›i má»—i items. ThÃ¬ cÃ³ tá»•ng cá»™ng lÃ  54 items. VÃ  show lÃªn mÃ n hÃ¬nh cÅ©ng 54 bounding box. BÆ°á»›c tiáº¿p theo, em in boxes ra thÃ¬ e tháº¥y nÃ³ lá»›n hÆ¡n 54. NÃªn khi Ã¡p dá»¥ng thuáº­t toÃ¡n Hough Circles vÃ o thÃ¬ lÃºc váº½ Ä‘Æ°á»ng trÃ²n lÃªn thÃ¬ cÃ³ nhá»¯ng items nÃ³ bá»‹ láº·p láº¡i. Em Ä‘Ã£ thá»­ set láº¡i ngÆ°á»¡ng cá»§a NMS mÃ  nÃ³ váº«n khÃ´ng háº¡n cháº¿ Ä‘Æ°á»£c bao nhiÃªu. Má»i ngÆ°á»i trong nhÃ³m ai Ä‘Ã£ tá»«ng lÃ m nhá»¯ng bÃ i toÃ¡n tÆ°Æ¡ng tá»± cÅ©ng nhÆ° cÃ³ hÆ°á»›ng giáº£i quyáº¿t cÃ³ thá»ƒ hÆ°á»›ng dáº«n giÃºp em vá»›i Ä‘Æ°á»£c khÃ´ng áº¡? HÃ¬nh áº£nh minh há»a em show á»Ÿ dÆ°á»›i cmt nha má»i ngÆ°á»i Em xin cÃ¡m Æ¡n má»i ngÆ°á»i!!!",,,,,
"Em lÃ  sinh viÃªn vÃ  Ä‘ang há»c mÃ´n cÆ¡ sá»Ÿ AI.
Anh/chá»‹ cÃ³ thá»ƒ cho em há»i Ä‘oáº¡n code dÆ°á»›i thÃ¬ 2 lá»›p áº©n sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡ vÃ  mÃ´ hÃ¬nh nÃ y cÃ³ sá»­ dá»¥ng ká»¹ thuáº­t tá»‘i Æ°u hÃ³a khÃ´ng áº¡?
A/c nÃ o biáº¿t cÃ³ thá»ƒ chá»‰ cho em vá»›i áº¡.",Em lÃ  sinh viÃªn vÃ  Ä‘ang há»c mÃ´n cÆ¡ sá»Ÿ AI. Anh/chá»‹ cÃ³ thá»ƒ cho em há»i Ä‘oáº¡n code dÆ°á»›i thÃ¬ 2 lá»›p áº©n sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t gÃ¬ Ä‘Æ°á»£c khÃ´ng áº¡ vÃ  mÃ´ hÃ¬nh nÃ y cÃ³ sá»­ dá»¥ng ká»¹ thuáº­t tá»‘i Æ°u hÃ³a khÃ´ng áº¡? A/c nÃ o biáº¿t cÃ³ thá»ƒ chá»‰ cho em vá»›i áº¡.,,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn dá»¥ng, sá»± kiá»‡n, tuyá»ƒn sinh thÃ¡ng 11 dÆ°á»›i comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n má»™t thÃ¡ng vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn dá»¥ng, sá»± kiá»‡n, tuyá»ƒn sinh thÃ¡ng 11 dÆ°á»›i comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n má»™t thÃ¡ng vui váº».",,,,,
"Dáº¡ xin chÃ o má»i ngÆ°á»i, e tv má»›i vÃ´ nhÃ³m nhá» mn giÃºp bÃ i táº­p nÃ y hoáº·c cÃ³ tÃ i liá»‡u tham kháº£o cho e xin vá»›i áº¡, cÃ¡m Æ¡n ad vÃ  má»i ngÆ°á»i nhiá»u","Dáº¡ xin chÃ o má»i ngÆ°á»i, e tv má»›i vÃ´ nhÃ³m nhá» mn giÃºp bÃ i táº­p nÃ y hoáº·c cÃ³ tÃ i liá»‡u tham kháº£o cho e xin vá»›i áº¡, cÃ¡m Æ¡n ad vÃ  má»i ngÆ°á»i nhiá»u",,,,,
Em cÃ³ tháº¯c máº¯c lÃ  vá»›i chá»©ng chá»‰ Tensorflow thÃ¬ Ä‘Ã£ Ä‘á»§ kháº£ nÄƒng Ä‘i lÃ m chÆ°a áº¡. Mong cÃ¡c bÃ¡c giáº£i Ä‘Ã¡p giÃºp em,Em cÃ³ tháº¯c máº¯c lÃ  vá»›i chá»©ng chá»‰ Tensorflow thÃ¬ Ä‘Ã£ Ä‘á»§ kháº£ nÄƒng Ä‘i lÃ m chÆ°a áº¡. Mong cÃ¡c bÃ¡c giáº£i Ä‘Ã¡p giÃºp em,,,,,
"Xin phÃ©p chia sáº» cÃ¹ng má»i ngÆ°á»i workshop vá» AI trong lÄ©nh vá»±c Xá»­ lÃ½ áº£nh y táº¿. Hy vá»ng chÆ°Æ¡ng trÃ¬nh sáº½ mang Ä‘áº¿n nhiá»u kiáº¿n thá»©c há»¯u Ã­ch dÃ nh cho cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n há»c mÃ¡y vÃ  Ä‘ang tÃ¬m kiáº¿m cÃ¡c nguá»“n dá»¯ liá»‡u má»Ÿ, cÃ´ng cá»¥ phá»¥c vá»¥ viá»‡c Ä‘Ã o táº¡o mÃ´ hÃ¬nh.
-------------
ğŸ“¢ WORKSHOP â€œAI TRONG Xá»¬ LÃ áº¢NH Y Táº¾ - KINH NGHIá»†M PHÃT TRIá»‚N THUáº¬T TOÃN & XÃ‚Y Dá»°NG CÃC Bá»˜ Dá»® LIá»†U CHUáº¨N HÃ“Aâ€
Trong vÃ²ng 3 - 5 nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y, cÃ¡c thuáº­t toÃ¡n trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Ã£ mang Ä‘áº¿n nhá»¯ng tiáº¿n bá»™ Ä‘á»™t phÃ¡ trong phÃ¢n tÃ­ch vÃ  xá»­ lÃ½ áº£nh y táº¿, gÃ³p pháº§n Ä‘áº¯c lá»±c giÃºp cÃ¡c bÃ¡c sÄ© Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c, cháº©n Ä‘oÃ¡n sá»›m cÃ¡c báº¥t thÆ°á»ng, hÆ°á»›ng tá»›i sÃ ng lá»c trÃªn diá»‡n rá»™ng má»™t sá»‘ bá»‡nh lÃ½ nguy hiá»ƒm. Tuy nhiÃªn, cÃ¹ng vá»›i cÆ¡ há»™i, á»©ng dá»¥ng AI trong xá»­ lÃ½ hÃ¬nh áº£nh y táº¿ cÅ©ng Ä‘ang pháº£i Ä‘á»‘i diá»‡n vá»›i khÃ´ng Ã­t thÃ¡ch thá»©c, cháº³ng háº¡n nhÆ°:
Thiáº¿u cÃ¡c bá»™ dá»¯ liá»‡u chuáº©n hÃ³a, cÃ³ dÃ¡n nhÃ£n bá»Ÿi bÃ¡c sÄ© cháº©n Ä‘oÃ¡n hÃ¬nh áº£nh.
Kháº£ nÄƒng diá»…n giáº£i cá»§a cÃ¡c mÃ´ hÃ¬nh AI cÃ²n háº¡n cháº¿
Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¡t triá»ƒn vÃ  tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh AI, dá»±a trÃªn cÃ¡c bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n vÃ  Ä‘áº¡t chuáº©n?
CÃ¢u tráº£ lá»i sáº½ cÃ³ trong workshop â€œAI trong xá»­ lÃ½ áº£nh y táº¿ - Kinh nghiá»‡m phÃ¡t triá»ƒn thuáº­t toÃ¡n vÃ  xÃ¢y dá»±ng cÃ¡c bá»™ dá»¯ liá»‡u chuáº©n hÃ³aâ€. Táº¡i Ä‘Ã¢y, cÃ¡c chuyÃªn gia, ká»¹ sÆ° cÃ´ng nghá»‡ cá»§a Trung tÃ¢m Xá»­ lÃ½ áº£nh y táº¿, VinBigdata, nhá»¯ng ngÆ°á»i trá»±c tiáº¿p tham gia phÃ¡t triá»ƒn sáº£n pháº©m VinDr, sáº½ láº§n lÆ°á»£t trÃ¬nh bÃ y:
1ï¸âƒ£ Quy trÃ¬nh tá»•ng quan vá» phÃ¡t triá»ƒn AI trong Xá»­ lÃ½ áº£nh y táº¿ - TS. Pháº¡m Huy Hiá»‡u, ChuyÃªn gia nghiÃªn cá»©u Thá»‹ giÃ¡c mÃ¡y tÃ­nh, Trung tÃ¢m Xá»­ lÃ½ áº£nh y táº¿, VinBigdata.
TS. Hiá»‡u Ä‘Ã£ nháº­n báº±ng tiáº¿n sÄ© táº¡i Viá»‡n Äáº¡i há»c Toulouse, PhÃ¡p; lÃ  tÃ¡c giáº£ cá»§a hÆ¡n 20 bÃ i bÃ¡o khoa há»c trÃªn cÃ¡c táº¡p chÃ­ vÃ  há»™i nghá»‹ quá»‘c táº¿ (Citations = 251; H-index = 8 ), trong Ä‘Ã³ cÃ³ cÃ¡c táº¡p chÃ­ vÃ  há»™i nghá»‹ lá»›n nhÆ° Computer Vision and Image Understanding (CVIU), Neurocomputing, MICCAI, MIDL.
2ï¸âƒ£ Kinh nghiá»‡m phÃ¡t triá»ƒn thuáº­t toÃ¡n & Xá»­ lÃ½ dá»¯ liá»‡u - Ká»¹ sÆ° AI Nguyá»…n BÃ¡ DÅ©ng, TrÆ°á»Ÿng nhÃ³m PhÃ¢n tÃ­ch áº£nh y táº¿, Trung tÃ¢m Xá»­ lÃ½ áº£nh y táº¿, VinBigdata; Kaggle Competitions Grandmaster.
3ï¸âƒ£ Há»‡ thá»‘ng VinDr Lab vÃ  CÃ¡c bá»™ dá»¯ liá»‡u chuáº©n hÃ³a chia sáº» cho cá»™ng Ä‘á»“ng - Ká»¹ sÆ° AI Nguyá»…n Trung NghÄ©a. Huy chÆ°Æ¡ng Báº¡c cÃ¡c cuá»™c thi PhÃ¡t hiá»‡n xuáº¥t huyáº¿t ná»™i sá» Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi Hiá»‡p há»™i Xâ€‘quang Báº¯c Má»¹ - RSNA, PhÃ¢n Ä‘oáº¡n khÃ­ mÃ ng phá»•i SIIM-ACR...
ğŸ“ Náº¿u Ä‘ang quan tÃ¢m Ä‘áº¿n viá»‡c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y, Ä‘áº·c biá»‡t trong lÄ©nh vá»±c xá»­ lÃ½ áº£nh y táº¿, Ä‘á»“ng thá»i, tÃ¬m kiáº¿m cÃ¡c nguá»“n dá»¯ liá»‡u vÃ  cÃ´ng cá»¥ phá»¥c vá»¥ viá»‡c tá»‘i Æ°u hÃ³a thuáº­t toÃ¡n, thÃ¬ báº¡n Ä‘á»«ng bá» lá»¡ workshop tá»›i Ä‘Ã¢y cá»§a VinBigdata:
Thá»i gian: tá»« 15h00 â€“ 17h00 ngÃ y 25/6/2021
Workshop Ä‘Æ°á»£c livestream trÃªn Fanpage VinBigdata","Xin phÃ©p chia sáº» cÃ¹ng má»i ngÆ°á»i workshop vá» AI trong lÄ©nh vá»±c Xá»­ lÃ½ áº£nh y táº¿. Hy vá»ng chÆ°Æ¡ng trÃ¬nh sáº½ mang Ä‘áº¿n nhiá»u kiáº¿n thá»©c há»¯u Ã­ch dÃ nh cho cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n há»c mÃ¡y vÃ  Ä‘ang tÃ¬m kiáº¿m cÃ¡c nguá»“n dá»¯ liá»‡u má»Ÿ, cÃ´ng cá»¥ phá»¥c vá»¥ viá»‡c Ä‘Ã o táº¡o mÃ´ hÃ¬nh. ------------- WORKSHOP â€œAI TRONG Xá»¬ LÃ áº¢NH Y Táº¾ - KINH NGHIá»†M PHÃT TRIá»‚N THUáº¬T TOÃN & XÃ‚Y Dá»°NG CÃC Bá»˜ Dá»® LIá»†U CHUáº¨N HÃ“Aâ€ Trong vÃ²ng 3 - 5 nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y, cÃ¡c thuáº­t toÃ¡n trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘Ã£ mang Ä‘áº¿n nhá»¯ng tiáº¿n bá»™ Ä‘á»™t phÃ¡ trong phÃ¢n tÃ­ch vÃ  xá»­ lÃ½ áº£nh y táº¿, gÃ³p pháº§n Ä‘áº¯c lá»±c giÃºp cÃ¡c bÃ¡c sÄ© Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c, cháº©n Ä‘oÃ¡n sá»›m cÃ¡c báº¥t thÆ°á»ng, hÆ°á»›ng tá»›i sÃ ng lá»c trÃªn diá»‡n rá»™ng má»™t sá»‘ bá»‡nh lÃ½ nguy hiá»ƒm. Tuy nhiÃªn, cÃ¹ng vá»›i cÆ¡ há»™i, á»©ng dá»¥ng AI trong xá»­ lÃ½ hÃ¬nh áº£nh y táº¿ cÅ©ng Ä‘ang pháº£i Ä‘á»‘i diá»‡n vá»›i khÃ´ng Ã­t thÃ¡ch thá»©c, cháº³ng háº¡n nhÆ°: Thiáº¿u cÃ¡c bá»™ dá»¯ liá»‡u chuáº©n hÃ³a, cÃ³ dÃ¡n nhÃ£n bá»Ÿi bÃ¡c sÄ© cháº©n Ä‘oÃ¡n hÃ¬nh áº£nh. Kháº£ nÄƒng diá»…n giáº£i cá»§a cÃ¡c mÃ´ hÃ¬nh AI cÃ²n háº¡n cháº¿ Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¡t triá»ƒn vÃ  tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh AI, dá»±a trÃªn cÃ¡c bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n vÃ  Ä‘áº¡t chuáº©n? CÃ¢u tráº£ lá»i sáº½ cÃ³ trong workshop â€œAI trong xá»­ lÃ½ áº£nh y táº¿ - Kinh nghiá»‡m phÃ¡t triá»ƒn thuáº­t toÃ¡n vÃ  xÃ¢y dá»±ng cÃ¡c bá»™ dá»¯ liá»‡u chuáº©n hÃ³aâ€. Táº¡i Ä‘Ã¢y, cÃ¡c chuyÃªn gia, ká»¹ sÆ° cÃ´ng nghá»‡ cá»§a Trung tÃ¢m Xá»­ lÃ½ áº£nh y táº¿, VinBigdata, nhá»¯ng ngÆ°á»i trá»±c tiáº¿p tham gia phÃ¡t triá»ƒn sáº£n pháº©m VinDr, sáº½ láº§n lÆ°á»£t trÃ¬nh bÃ y: 1âƒ£ Quy trÃ¬nh tá»•ng quan vá» phÃ¡t triá»ƒn AI trong Xá»­ lÃ½ áº£nh y táº¿ - TS. Pháº¡m Huy Hiá»‡u, ChuyÃªn gia nghiÃªn cá»©u Thá»‹ giÃ¡c mÃ¡y tÃ­nh, Trung tÃ¢m Xá»­ lÃ½ áº£nh y táº¿, VinBigdata. TS. Hiá»‡u Ä‘Ã£ nháº­n báº±ng tiáº¿n sÄ© táº¡i Viá»‡n Äáº¡i há»c Toulouse, PhÃ¡p; lÃ  tÃ¡c giáº£ cá»§a hÆ¡n 20 bÃ i bÃ¡o khoa há»c trÃªn cÃ¡c táº¡p chÃ­ vÃ  há»™i nghá»‹ quá»‘c táº¿ (Citations = 251; H-index = 8 ), trong Ä‘Ã³ cÃ³ cÃ¡c táº¡p chÃ­ vÃ  há»™i nghá»‹ lá»›n nhÆ° Computer Vision and Image Understanding (CVIU), Neurocomputing, MICCAI, MIDL. 2âƒ£ Kinh nghiá»‡m phÃ¡t triá»ƒn thuáº­t toÃ¡n & Xá»­ lÃ½ dá»¯ liá»‡u - Ká»¹ sÆ° AI Nguyá»…n BÃ¡ DÅ©ng, TrÆ°á»Ÿng nhÃ³m PhÃ¢n tÃ­ch áº£nh y táº¿, Trung tÃ¢m Xá»­ lÃ½ áº£nh y táº¿, VinBigdata; Kaggle Competitions Grandmaster. 3âƒ£ Há»‡ thá»‘ng VinDr Lab vÃ  CÃ¡c bá»™ dá»¯ liá»‡u chuáº©n hÃ³a chia sáº» cho cá»™ng Ä‘á»“ng - Ká»¹ sÆ° AI Nguyá»…n Trung NghÄ©a. Huy chÆ°Æ¡ng Báº¡c cÃ¡c cuá»™c thi PhÃ¡t hiá»‡n xuáº¥t huyáº¿t ná»™i sá» Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi Hiá»‡p há»™i Xâ€‘quang Báº¯c Má»¹ - RSNA, PhÃ¢n Ä‘oáº¡n khÃ­ mÃ ng phá»•i SIIM-ACR... Náº¿u Ä‘ang quan tÃ¢m Ä‘áº¿n viá»‡c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y, Ä‘áº·c biá»‡t trong lÄ©nh vá»±c xá»­ lÃ½ áº£nh y táº¿, Ä‘á»“ng thá»i, tÃ¬m kiáº¿m cÃ¡c nguá»“n dá»¯ liá»‡u vÃ  cÃ´ng cá»¥ phá»¥c vá»¥ viá»‡c tá»‘i Æ°u hÃ³a thuáº­t toÃ¡n, thÃ¬ báº¡n Ä‘á»«ng bá» lá»¡ workshop tá»›i Ä‘Ã¢y cá»§a VinBigdata: Thá»i gian: tá»« 15h00 â€“ 17h00 ngÃ y 25/6/2021 Workshop Ä‘Æ°á»£c livestream trÃªn Fanpage VinBigdata",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2020 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 12/2020 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"hi báº¡n Tiá»‡p vÃ  cÃ¡c báº¡n. MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» GAN vÃ  pix2pix theo bÃ i bÃ¡o https://arxiv.org/pdf/1611.07004.pdf vÃ  https://github.com/znxlwm/pytorch-pix2pix/blob/master/pytorch_pix2pix.py . MÃ¬nh cÃ³ má»™t tháº¯c máº¯c nhá» nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡.
trong má»™t step Ä‘Æ°á»£c chia lÃ m 2 bÆ°á»›c, bÆ°á»›c train D (discriminator) vÃ  bÆ°á»›c train G (generator). Táº¡i sai khi train D ngÆ°á»i ta khÃ´ng frezze G (G.requires_grad(false)) vÃ  khi train G ngÆ°á»i ta khÃ´ng frezze D (G.requires_grad(false)).
MÃ¬nh xem code tháº¥y cÃ³ set riÃªng optimizer cho G riÃªng G_optimizer = optim.Adam(G.parameters(), D riÃªng D_optimizer = optim.Adam(D.parameters()), nÃªn khi gá»i D_optimizer.step() hoáº·c G_optimizer.step() thÃ¬ chá»‰ update weight trÃªn D vÃ  trÃªn G Ä‘á»™c láº­p,
nÃªn code cháº¡y váº¥n Ä‘Ãºng.
NhÆ°ng táº¡i sao há» khÃ´ng freeze G (Khi train D) vá»›i freeze D (khi train G) Ä‘á»ƒ Ä‘á»¡ pháº£i tÃ­nh grad Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ train?
CÃ¡m Æ¡n ad Ä‘Ã£ duyá»‡t bÃ i
Ps: Sau khi tháº£o luáº­n vá»›i báº¡n Thuáº­n Nguyá»…n mÃ¬nh cÃ³ viáº¿t má»™t cÃ¡i test nho nhá» táº¡i lÃ  má»™t model gá»“m hai linear f1 vÃ  f1, hÃ m optimer chá»‰ láº¥y params á»Ÿ f1 thÃ¬ khi set f2.requires_grad_(False) hay f2.requires_grad_(True) thÃ¬ Ä‘á»u ra cÃ¹ng má»™t káº¿t quáº£. HÃ m backwards váº«n truyá»n vá» f1 theo chain rule. NÃªn mÃ¬nh váº«n tháº¯c máº¯c chá»— Ä‘Ã³
CÃ¡c báº¡n cÃ³ thá»ƒ xem code vÃ  result táº¡i Ä‘Ã¢y https://pastebin.com/hE51GkKU","hi báº¡n Tiá»‡p vÃ  cÃ¡c báº¡n. MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» GAN vÃ  pix2pix theo bÃ i bÃ¡o https://arxiv.org/pdf/1611.07004.pdf vÃ  https://github.com/znxlwm/pytorch-pix2pix/blob/master/pytorch_pix2pix.py . MÃ¬nh cÃ³ má»™t tháº¯c máº¯c nhá» nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡. trong má»™t step Ä‘Æ°á»£c chia lÃ m 2 bÆ°á»›c, bÆ°á»›c train D (discriminator) vÃ  bÆ°á»›c train G (generator). Táº¡i sai khi train D ngÆ°á»i ta khÃ´ng frezze G (G.requires_grad(false)) vÃ  khi train G ngÆ°á»i ta khÃ´ng frezze D (G.requires_grad(false)). MÃ¬nh xem code tháº¥y cÃ³ set riÃªng optimizer cho G riÃªng G_optimizer = optim.Adam(G.parameters(), D riÃªng D_optimizer = optim.Adam(D.parameters()), nÃªn khi gá»i D_optimizer.step() hoáº·c G_optimizer.step() thÃ¬ chá»‰ update weight trÃªn D vÃ  trÃªn G Ä‘á»™c láº­p, nÃªn code cháº¡y váº¥n Ä‘Ãºng. NhÆ°ng táº¡i sao há» khÃ´ng freeze G (Khi train D) vá»›i freeze D (khi train G) Ä‘á»ƒ Ä‘á»¡ pháº£i tÃ­nh grad Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ train? CÃ¡m Æ¡n ad Ä‘Ã£ duyá»‡t bÃ i Ps: Sau khi tháº£o luáº­n vá»›i báº¡n Thuáº­n Nguyá»…n mÃ¬nh cÃ³ viáº¿t má»™t cÃ¡i test nho nhá» táº¡i lÃ  má»™t model gá»“m hai linear f1 vÃ  f1, hÃ m optimer chá»‰ láº¥y params á»Ÿ f1 thÃ¬ khi set f2.requires_grad_(False) hay f2.requires_grad_(True) thÃ¬ Ä‘á»u ra cÃ¹ng má»™t káº¿t quáº£. HÃ m backwards váº«n truyá»n vá» f1 theo chain rule. NÃªn mÃ¬nh váº«n tháº¯c máº¯c chá»— Ä‘Ã³ CÃ¡c báº¡n cÃ³ thá»ƒ xem code vÃ  result táº¡i Ä‘Ã¢y https://pastebin.com/hE51GkKU",,,,,
"[AI Share - Datasets]
Má»™t sá»‘ nguá»“n Ä‘á»ƒ tÃ¬m dataset vá» machine learning, data science, AI.
1. Google Datasets:
Link : https://datasetsearch.research.google.com/
2. Papers with Code Datasets.
Link : https://paperswithcode.com/datasets
3. Kaggle Dataset
Link: https://www.kaggle.com/datasets
4. Big Bag NLP Datasets
Link: https://index.quantumstat.com/#/
5. Hugging Face Datasets
Link: https://huggingface.co/dataset
6. UCI Machine Learning
Link: https://archive.ics.uci.edu/ml/index.php
7. Amazin Datasets (Open Data on AWS)
Link: https:/aws.amazon.com/opendata/
8. Awesome Public Datasets
Link: https://github.com/awesomedata/awesome-public-datasets
9. Azure public datasets
Link: https://docs.microsoft.com/en-us/azure/azure-sql/public-data-sets
10. Carnegie Mellon University
Link: https://guides.library.cmu.edu/az.php
11. .gov Datasets
Link: https://data.gov.au/
https://data.gov.in/
https://data.gov.sg/
https://data.europa.eu/data/datasets?locale=en&minScoring=0
______________________","[AI Share - Datasets] Má»™t sá»‘ nguá»“n Ä‘á»ƒ tÃ¬m dataset vá» machine learning, data science, AI. 1. Google Datasets: Link : https://datasetsearch.research.google.com/ 2. Papers with Code Datasets. Link : https://paperswithcode.com/datasets 3. Kaggle Dataset Link: https://www.kaggle.com/datasets 4. Big Bag NLP Datasets Link: https://index.quantumstat.com/#/ 5. Hugging Face Datasets Link: https://huggingface.co/dataset 6. UCI Machine Learning Link: https://archive.ics.uci.edu/ml/index.php 7. Amazin Datasets (Open Data on AWS) Link: https:/aws.amazon.com/opendata/ 8. Awesome Public Datasets Link: https://github.com/awesomedata/awesome-public-datasets 9. Azure public datasets Link: https://docs.microsoft.com/en-us/azure/azure-sql/public-data-sets 10. Carnegie Mellon University Link: https://guides.library.cmu.edu/az.php 11. .gov Datasets Link: https://data.gov.au/ https://data.gov.in/ https://data.gov.sg/ https://data.europa.eu/data/datasets?locale=en&minScoring=0 ______________________",,,,,
"ChÃ o cáº£ nhÃ ,
MÃ¬nh muá»‘n dÃ¹ng Python Ä‘á»ƒ lÃ m text analysis. Cá»¥ thá»ƒ lÃ  trong conference call, analysts sáº½ Ä‘áº·t cÃ¢u há»i cho CEO vÃ  há» cÃ³ thá»ƒ Ä‘iá»u chá»‰nh tone cá»§a cÃ¢u há»i tÃ¹y theo CEO. MÃ¬nh sáº½ dÃ¹ng transcripts cá»§a conference Ä‘á»ƒ Ä‘o lÆ°á»ng tone cá»§a cÃ¢u há»i.
TrÃ¬nh Ä‘á»™ Python cá»§a mÃ¬nh cÃ²n á»Ÿ má»©c basic, muá»‘n dÃ¹ng text analysis thÃ¬ mÃ¬nh nÃªn báº¯t Ä‘áº§u nhÆ° tháº¿ nÃ o áº¡?","ChÃ o cáº£ nhÃ , MÃ¬nh muá»‘n dÃ¹ng Python Ä‘á»ƒ lÃ m text analysis. Cá»¥ thá»ƒ lÃ  trong conference call, analysts sáº½ Ä‘áº·t cÃ¢u há»i cho CEO vÃ  há» cÃ³ thá»ƒ Ä‘iá»u chá»‰nh tone cá»§a cÃ¢u há»i tÃ¹y theo CEO. MÃ¬nh sáº½ dÃ¹ng transcripts cá»§a conference Ä‘á»ƒ Ä‘o lÆ°á»ng tone cá»§a cÃ¢u há»i. TrÃ¬nh Ä‘á»™ Python cá»§a mÃ¬nh cÃ²n á»Ÿ má»©c basic, muá»‘n dÃ¹ng text analysis thÃ¬ mÃ¬nh nÃªn báº¯t Ä‘áº§u nhÆ° tháº¿ nÃ o áº¡?",,,,,
"[Há»i vá» cÃ¡ch chá»n K tá»‘i Æ°u cho KNN] Cho mÃ¬nh há»i chÃºt vá» cÃ¡ch chá»n K trong KNN , mÃ¬nh cÃ³ lÃ m 1 bÃ i táº­p nhá» vá» nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay vÃ  mÃ¬nh chá»n KNN cho dá»… cÃ i Ä‘áº·t thÃ¬ mÃ¬nh tháº¥y lÃ  mÃ¬nh thá»­ K láº§n lÆ°á»£t lÃ  3,6,7...11 thÃ¬ kiá»ƒm tra tháº¥y cÃ¡c trá»ng sá»‘ tÆ°Æ¡ng Ä‘á»‘i rÃµ rÃ ng thÃ¬ láº¥y K, Váº­y thÃ¬ ngoÃ i phÆ°Æ¡ng phÃ¡p Ä‘Ã³ thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ chá»n K sao cho Ä‘áº¡t hiá»ƒu quáº£ cao nháº¥t khÃ´ng nhá»‰. Code mÃ¬nh sá»­ dá»¥ng thuáº§n Go vÃ  KNN","[Há»i vá» cÃ¡ch chá»n K tá»‘i Æ°u cho KNN] Cho mÃ¬nh há»i chÃºt vá» cÃ¡ch chá»n K trong KNN , mÃ¬nh cÃ³ lÃ m 1 bÃ i táº­p nhá» vá» nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay vÃ  mÃ¬nh chá»n KNN cho dá»… cÃ i Ä‘áº·t thÃ¬ mÃ¬nh tháº¥y lÃ  mÃ¬nh thá»­ K láº§n lÆ°á»£t lÃ  3,6,7...11 thÃ¬ kiá»ƒm tra tháº¥y cÃ¡c trá»ng sá»‘ tÆ°Æ¡ng Ä‘á»‘i rÃµ rÃ ng thÃ¬ láº¥y K, Váº­y thÃ¬ ngoÃ i phÆ°Æ¡ng phÃ¡p Ä‘Ã³ thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ chá»n K sao cho Ä‘áº¡t hiá»ƒu quáº£ cao nháº¥t khÃ´ng nhá»‰. Code mÃ¬nh sá»­ dá»¥ng thuáº§n Go vÃ  KNN",,,,,
"CÃ¡c bÃ¡c giÃºp vá»›i áº¡
Em cÃ i jupyter toÃ n bá»‹ lá»—i nÃ y thÃ¬ kháº¯c phá»¥c sao áº¡ :(",CÃ¡c bÃ¡c giÃºp vá»›i áº¡ Em cÃ i jupyter toÃ n bá»‹ lá»—i nÃ y thÃ¬ kháº¯c phá»¥c sao áº¡ :(,,,,,
"OPEN CALL: Dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN
Cáº§n cá»™ng Ä‘á»“ng AI gÃ³p sá»©c chá»‘ng Covid! XÃ¢y AI Engine Ä‘á»ƒ cháº©n Ä‘oÃ¡n nhanh Covid qua tiáº¿ng ho, qua Ä‘iá»‡n thoáº¡i
Hiá»‡n nay TPHCM Ä‘Ã£ triá»ƒn khai nhanh há»‡ thá»‘ng Robocall, qua Ä‘Ã³ AI tá»± Ä‘á»™ng gá»i Ä‘iá»‡n cho hÃ ng triá»‡u ngÆ°á»i dÃ¢n, vÃ  Ä‘áº·t cÃ¢u há»i cho há» Ä‘á»ƒ há» tá»± khai bÃ¡o triá»‡u chá»©ng Covid. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a ráº¥t lá»›n trong viá»‡c sÃ ng lá»c nhanh nhá»¯ng ngÆ°á»i cáº§n xÃ©t nghiá»‡m ká»¹ hÆ¡n, vÃ  khoanh vÃ¹ng cÃ¡c á»• dá»‹ch ká»‹p thá»i.
Tuy nhiÃªn há»‡ thá»‘ng hiá»‡n nay cáº§n ngÆ°á»i dÃ¢n tá»± khai bÃ¡o triá»‡u chá»©ng, trong khi nhiá»u ngÆ°á»i máº¯c Covid nhÆ°ng chÆ°a cÃ³ triá»‡u chá»©ng.
Äá»ƒ tiáº¿p tá»¥c nÃ¢ng cao hiá»‡u quáº£, vÃ  triá»ƒn khai diá»‡n rá»™ng á»Ÿ TPHCM vÃ  cÃ¡c tá»‰nh thÃ nh khÃ¡c, chÃºng ta cáº§n xÃ¢y dá»±ng thÃªm AI Engine Ä‘á»ƒ Ä‘á» nghá»‹ ngÆ°á»i dÃ¢n ho vÃ o Ä‘iá»‡n thoáº¡i, rá»“i tá»± Ä‘á»™ng cháº©n Ä‘oÃ¡n Covid sÆ¡ bá»™.
CÃ¡c tÃ i nguyÃªn Ä‘Ã£ cÃ³:
1. Dataset má»Ÿ: 1700 máº«u ghi Ã¢m tiáº¿ng ho cá»§a ngÆ°á»i dÆ°Æ¡ng tÃ­nh, (tá»« Thá»¥y sÄ© vÃ  áº¤n Ä‘á»™) vÃ  nhiá»u máº«u Ã¢m tÃ­nh, cÃ³ dÃ¡n nhÃ£n. Tuy nhiÃªn cÃ²n nhiá»u táº¡p Ã¢m vÃ  váº¥n Ä‘á» vá»›i thÃ´ng tin nhÃ£n cáº§n xá»­ lÃ½.
https://bit.ly/3uQrdb1
2. BÃ¡o bÃ¡o khoa há»c cá»§a MIT Ä‘Ã£ cÃ´ng bá»‘, theo Ä‘Ã³ há» Ä‘Ã£ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c 98.5% vá»›i bÃ i toÃ¡n nÃ y (vá»›i 2600 máº«u dÆ°Æ¡ng tÃ­nh), Ä‘áº·c biá»‡t lÃ  Ä‘á»™ chÃ­nh xÃ¡c 100% vá»›i cÃ¡c cÃ¡ nhÃ¢n chÆ°a cÃ³ triá»‡u chá»©ng (viá»‡c xÃ©t nghiá»‡m ngÆ°á»i chÆ°a cÃ³ triá»‡u chá»©ng lÃ  quan trá»ng nháº¥t vá»›i bÃ i toÃ¡n nÃ y)
https://bit.ly/3fNsgE4
3. Má»™t sá»‘ datasets khÃ¡c
https://bit.ly/3chCQRU
4. Há»‡ thá»‘ng Robocall Ä‘Ã£ triá»ƒn khai táº¡i TPHCM, sáºµn sÃ ng láº¯p thÃªm AI Engine cháº©n Ä‘oÃ¡n tiáº¿ng ho
https://bit.ly/3uShXTD
5. Facebook cá»§a nhÃ³m dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN, Ä‘á»ƒ cÃ¹ng trao Ä‘á»•i chuyÃªn mÃ´n bit.ly/aicovidvn
HÃ¬nh thá»©c tham gia:
1. Tham gia nhÃ³m tháº£o luáº­n cá»§a dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN (bit.ly/aicovidvn)
2. TÃ¹y Ã½ sá»­ dá»¥ng cÃ¡c open datasets Ä‘Æ°á»£c chia sáº» trong group hoáº·c cÃ¡c nÆ¡i khÃ¡c
3. XÃ¢y dá»±ng AI Enging cháº©n Ä‘oÃ¡n Covid qua tiáº¿ng ho, Ä‘á»™ chÃ­nh xÃ¡c ká»³ vá»ng 90%+
4,. Há»— trá»£, giá»›i thiá»‡u Ä‘áº§u má»‘i cÆ¡ quan chá»©c nÄƒng Ä‘á»ƒ ghi Ã¢m thÃªm máº«u tiáº¿ng ho cá»§a ngÆ°á»i dÆ°Æ¡ng tÃ­nh (cÃ³ triá»‡u chá»©ng, chÆ°a cÃ³ triá»‡u chá»©ng) qua Ä‘iá»‡n thoáº¡i. Cáº§n khoáº£ng 1000 máº«u, nhÆ°ng cÃ ng nhiá»u cÃ ng tá»‘t.
5. Káº¿t há»£p vá»›i team ngÆ°á»i khiáº¿m thá»‹ Ä‘á»ƒ phá»‘i há»£p cháº©n Ä‘oÃ¡n vÃ²ng 2 qua viá»‡c nghe báº±ng tai (Ä‘ang Ä‘Æ°á»£c training song song)
6. Chuyá»ƒn giao AI Engine cho Ban chá»‰ Ä‘áº¡o quá»‘c gia phÃ²ng chá»‘ng dá»‹ch covid 19 Ä‘á»ƒ phá»¥c vá»¥ cÃ´ng tÃ¡c cháº©n Ä‘oÃ¡n qua Robocall diá»‡n rá»™ng
7. TÃ¹y Ã½ sá»­ dá»¥ng káº¿t quáº£ vÃ o cÃ¡c má»¥c Ä‘Ã­ch khÃ¡c. VÃ­ dá»¥: tÆ° xÃ¢y dá»±ng mobile app cháº©n Ä‘oÃ¡n Covid qua tiáº¿ng ho cho cÃ¡ nhÃ¢n Ä‘á»ƒ thÆ°Æ¡ng máº¡i hÃ³a, hoáº·c chuyá»ƒn giao má»™t pháº§n hoáº·c táº¥t cáº£ há»‡ thá»‘ng cho Ban chá»‰ Ä‘áº¡o quá»‘c gia, hoáº·c cÃ´ng bá»‘ mÃ£ nguá»“n vÃ  dá»¯ liá»‡u má»Ÿ phá»¥c vá»¥ cá»™ng Ä‘á»“ng, tÃ¹y theo mong muá»‘n.
CÃ¡c doanh nghiá»‡p, nhÃ³m, cÃ¡ nhÃ¢n cÃ³ nhu cáº§u tham gia hoáº¡t Ä‘á»™ng cá»™ng Ä‘á»“ng nÃ y xin má»i tham gia Facebook Group cá»§a nhÃ³m: bit.ly/aicovidvn
Nhá» anh chá»‹ em tag giÃºp nhá»¯ng ai cÃ³ thá»ƒ tham gia hoáº·c há»— trá»£ thu tháº­p tiáº¿ng ho nhÃ©.
 â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  Pham Minh Tuan.","OPEN CALL: Dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN Cáº§n cá»™ng Ä‘á»“ng AI gÃ³p sá»©c chá»‘ng Covid! XÃ¢y AI Engine Ä‘á»ƒ cháº©n Ä‘oÃ¡n nhanh Covid qua tiáº¿ng ho, qua Ä‘iá»‡n thoáº¡i Hiá»‡n nay TPHCM Ä‘Ã£ triá»ƒn khai nhanh há»‡ thá»‘ng Robocall, qua Ä‘Ã³ AI tá»± Ä‘á»™ng gá»i Ä‘iá»‡n cho hÃ ng triá»‡u ngÆ°á»i dÃ¢n, vÃ  Ä‘áº·t cÃ¢u há»i cho há» Ä‘á»ƒ há» tá»± khai bÃ¡o triá»‡u chá»©ng Covid. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a ráº¥t lá»›n trong viá»‡c sÃ ng lá»c nhanh nhá»¯ng ngÆ°á»i cáº§n xÃ©t nghiá»‡m ká»¹ hÆ¡n, vÃ  khoanh vÃ¹ng cÃ¡c á»• dá»‹ch ká»‹p thá»i. Tuy nhiÃªn há»‡ thá»‘ng hiá»‡n nay cáº§n ngÆ°á»i dÃ¢n tá»± khai bÃ¡o triá»‡u chá»©ng, trong khi nhiá»u ngÆ°á»i máº¯c Covid nhÆ°ng chÆ°a cÃ³ triá»‡u chá»©ng. Äá»ƒ tiáº¿p tá»¥c nÃ¢ng cao hiá»‡u quáº£, vÃ  triá»ƒn khai diá»‡n rá»™ng á»Ÿ TPHCM vÃ  cÃ¡c tá»‰nh thÃ nh khÃ¡c, chÃºng ta cáº§n xÃ¢y dá»±ng thÃªm AI Engine Ä‘á»ƒ Ä‘á» nghá»‹ ngÆ°á»i dÃ¢n ho vÃ o Ä‘iá»‡n thoáº¡i, rá»“i tá»± Ä‘á»™ng cháº©n Ä‘oÃ¡n Covid sÆ¡ bá»™. CÃ¡c tÃ i nguyÃªn Ä‘Ã£ cÃ³: 1. Dataset má»Ÿ: 1700 máº«u ghi Ã¢m tiáº¿ng ho cá»§a ngÆ°á»i dÆ°Æ¡ng tÃ­nh, (tá»« Thá»¥y sÄ© vÃ  áº¤n Ä‘á»™) vÃ  nhiá»u máº«u Ã¢m tÃ­nh, cÃ³ dÃ¡n nhÃ£n. Tuy nhiÃªn cÃ²n nhiá»u táº¡p Ã¢m vÃ  váº¥n Ä‘á» vá»›i thÃ´ng tin nhÃ£n cáº§n xá»­ lÃ½. https://bit.ly/3uQrdb1 2. BÃ¡o bÃ¡o khoa há»c cá»§a MIT Ä‘Ã£ cÃ´ng bá»‘, theo Ä‘Ã³ há» Ä‘Ã£ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c 98.5% vá»›i bÃ i toÃ¡n nÃ y (vá»›i 2600 máº«u dÆ°Æ¡ng tÃ­nh), Ä‘áº·c biá»‡t lÃ  Ä‘á»™ chÃ­nh xÃ¡c 100% vá»›i cÃ¡c cÃ¡ nhÃ¢n chÆ°a cÃ³ triá»‡u chá»©ng (viá»‡c xÃ©t nghiá»‡m ngÆ°á»i chÆ°a cÃ³ triá»‡u chá»©ng lÃ  quan trá»ng nháº¥t vá»›i bÃ i toÃ¡n nÃ y) https://bit.ly/3fNsgE4 3. Má»™t sá»‘ datasets khÃ¡c https://bit.ly/3chCQRU 4. Há»‡ thá»‘ng Robocall Ä‘Ã£ triá»ƒn khai táº¡i TPHCM, sáºµn sÃ ng láº¯p thÃªm AI Engine cháº©n Ä‘oÃ¡n tiáº¿ng ho https://bit.ly/3uShXTD 5. Facebook cá»§a nhÃ³m dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN, Ä‘á»ƒ cÃ¹ng trao Ä‘á»•i chuyÃªn mÃ´n bit.ly/aicovidvn HÃ¬nh thá»©c tham gia: 1. Tham gia nhÃ³m tháº£o luáº­n cá»§a dá»± Ã¡n cá»™ng Ä‘á»“ng AICovidVN (bit.ly/aicovidvn) 2. TÃ¹y Ã½ sá»­ dá»¥ng cÃ¡c open datasets Ä‘Æ°á»£c chia sáº» trong group hoáº·c cÃ¡c nÆ¡i khÃ¡c 3. XÃ¢y dá»±ng AI Enging cháº©n Ä‘oÃ¡n Covid qua tiáº¿ng ho, Ä‘á»™ chÃ­nh xÃ¡c ká»³ vá»ng 90%+ 4,. Há»— trá»£, giá»›i thiá»‡u Ä‘áº§u má»‘i cÆ¡ quan chá»©c nÄƒng Ä‘á»ƒ ghi Ã¢m thÃªm máº«u tiáº¿ng ho cá»§a ngÆ°á»i dÆ°Æ¡ng tÃ­nh (cÃ³ triá»‡u chá»©ng, chÆ°a cÃ³ triá»‡u chá»©ng) qua Ä‘iá»‡n thoáº¡i. Cáº§n khoáº£ng 1000 máº«u, nhÆ°ng cÃ ng nhiá»u cÃ ng tá»‘t. 5. Káº¿t há»£p vá»›i team ngÆ°á»i khiáº¿m thá»‹ Ä‘á»ƒ phá»‘i há»£p cháº©n Ä‘oÃ¡n vÃ²ng 2 qua viá»‡c nghe báº±ng tai (Ä‘ang Ä‘Æ°á»£c training song song) 6. Chuyá»ƒn giao AI Engine cho Ban chá»‰ Ä‘áº¡o quá»‘c gia phÃ²ng chá»‘ng dá»‹ch covid 19 Ä‘á»ƒ phá»¥c vá»¥ cÃ´ng tÃ¡c cháº©n Ä‘oÃ¡n qua Robocall diá»‡n rá»™ng 7. TÃ¹y Ã½ sá»­ dá»¥ng káº¿t quáº£ vÃ o cÃ¡c má»¥c Ä‘Ã­ch khÃ¡c. VÃ­ dá»¥: tÆ° xÃ¢y dá»±ng mobile app cháº©n Ä‘oÃ¡n Covid qua tiáº¿ng ho cho cÃ¡ nhÃ¢n Ä‘á»ƒ thÆ°Æ¡ng máº¡i hÃ³a, hoáº·c chuyá»ƒn giao má»™t pháº§n hoáº·c táº¥t cáº£ há»‡ thá»‘ng cho Ban chá»‰ Ä‘áº¡o quá»‘c gia, hoáº·c cÃ´ng bá»‘ mÃ£ nguá»“n vÃ  dá»¯ liá»‡u má»Ÿ phá»¥c vá»¥ cá»™ng Ä‘á»“ng, tÃ¹y theo mong muá»‘n. CÃ¡c doanh nghiá»‡p, nhÃ³m, cÃ¡ nhÃ¢n cÃ³ nhu cáº§u tham gia hoáº¡t Ä‘á»™ng cá»™ng Ä‘á»“ng nÃ y xin má»i tham gia Facebook Group cá»§a nhÃ³m: bit.ly/aicovidvn Nhá» anh chá»‹ em tag giÃºp nhá»¯ng ai cÃ³ thá»ƒ tham gia hoáº·c há»— trá»£ thu tháº­p tiáº¿ng ho nhÃ©. â€” vá»›i LÃª CÃ´ng ThÃ nh vÃ  Pham Minh Tuan.",,,,,
"#Há»iÄ‘Ã¡p
Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n áº¡.
Hiá»‡n táº¡i em cÃ³ khoáº£ng 1000 máº«u form vá» hÃ³a Ä‘Æ¡n nhÆ° tháº¿ nÃ y. ChÃºng Ä‘Æ°á»£c Ä‘á»u Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng dÆ°á»›i dáº¡ng text.
Hiá»‡n táº¡i em muá»‘n chuyá»ƒn chÃºng sang dáº¡ng file excel Ä‘á»ƒ thá»‘ng kÃª ngÆ°á»i dÃ¹ng.
Má»i ngÆ°á»i cho em xin má»™t sá»‘ phÆ°Æ¡ng phÃ¡p hoáº·c code tham kháº£o Ä‘á»ƒ xá»­ lÃ½ pháº§n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? Kiá»ƒu em muá»‘n trÃ­ch xuáº¥t Há» vÃ  TÃªn, sá»‘ Ä‘iá»‡n thoáº¡i, GÃ­a tiá»n, Äá»‹a chá»‰,... ra áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n áº¡. Hiá»‡n táº¡i em cÃ³ khoáº£ng 1000 máº«u form vá» hÃ³a Ä‘Æ¡n nhÆ° tháº¿ nÃ y. ChÃºng Ä‘Æ°á»£c Ä‘á»u Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng dÆ°á»›i dáº¡ng text. Hiá»‡n táº¡i em muá»‘n chuyá»ƒn chÃºng sang dáº¡ng file excel Ä‘á»ƒ thá»‘ng kÃª ngÆ°á»i dÃ¹ng. Má»i ngÆ°á»i cho em xin má»™t sá»‘ phÆ°Æ¡ng phÃ¡p hoáº·c code tham kháº£o Ä‘á»ƒ xá»­ lÃ½ pháº§n nÃ y Ä‘Æ°á»£c khÃ´ng áº¡? Kiá»ƒu em muá»‘n trÃ­ch xuáº¥t Há» vÃ  TÃªn, sá»‘ Ä‘iá»‡n thoáº¡i, GÃ­a tiá»n, Äá»‹a chá»‰,... ra áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.",#Há»iÄ‘Ã¡p,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡.
Model bÃªn dÆ°á»›i tá»« má»™t bÃ i bÃ¡o SOTA. Há» ko ghi rÃµ cÃ¡c tham sá»‘ c model, vÃ  cÅ©ng nhÆ° khá»‘i mÃ u vÃ ng (AC - Attention Condenser). Em cÃ³ Ä‘á»c ká»¹ cÃ¡c paper cá»§a há», vÃ  Ä‘oÃ¡n, thÃ¬ tháº¥y khÃ¡ giá»‘ng cÆ¡ cháº¿ Auto Encode/ Decoder. Tuy nhiÃªn, há» láº¡i ghi 2 tham sá»‘ (VAE thÃ¬ input = output), nÃªn em chÆ°a biáº¿t liá»‡u cÆ¡ cháº¿ nÃ y báº±ng vá»›i layer nÃ o áº¡ . Hiá»‡n táº¡i em implement chÆ°a cÃ³ AC layer thÃ¬ sá»‘ tham sá»‘ Ä‘Ã£ gáº§n báº±ng model trong paper, nÃªn em nghÄ© AV layer lÃ  tá»• há»£p cá»§a nhá»¯ng layer Ä‘Æ¡n giáº£n. (2 tham sá»‘ Ä‘Ã³, em váº«n chÆ°a biáº¿t tÆ°Æ¡ng á»©ng vá»›i gÃ¬ áº¡).
Ráº¥t mong Ä‘Æ°á»£c brainstorming cÃ¹ng má»i ngÆ°á»i áº¡.
Attention Condenser
https://arxiv.org/abs/2104.14623","Xin chÃ o má»i ngÆ°á»i áº¡. Model bÃªn dÆ°á»›i tá»« má»™t bÃ i bÃ¡o SOTA. Há» ko ghi rÃµ cÃ¡c tham sá»‘ c model, vÃ  cÅ©ng nhÆ° khá»‘i mÃ u vÃ ng (AC - Attention Condenser). Em cÃ³ Ä‘á»c ká»¹ cÃ¡c paper cá»§a há», vÃ  Ä‘oÃ¡n, thÃ¬ tháº¥y khÃ¡ giá»‘ng cÆ¡ cháº¿ Auto Encode/ Decoder. Tuy nhiÃªn, há» láº¡i ghi 2 tham sá»‘ (VAE thÃ¬ input = output), nÃªn em chÆ°a biáº¿t liá»‡u cÆ¡ cháº¿ nÃ y báº±ng vá»›i layer nÃ o áº¡ . Hiá»‡n táº¡i em implement chÆ°a cÃ³ AC layer thÃ¬ sá»‘ tham sá»‘ Ä‘Ã£ gáº§n báº±ng model trong paper, nÃªn em nghÄ© AV layer lÃ  tá»• há»£p cá»§a nhá»¯ng layer Ä‘Æ¡n giáº£n. (2 tham sá»‘ Ä‘Ã³, em váº«n chÆ°a biáº¿t tÆ°Æ¡ng á»©ng vá»›i gÃ¬ áº¡). Ráº¥t mong Ä‘Æ°á»£c brainstorming cÃ¹ng má»i ngÆ°á»i áº¡. Attention Condenser https://arxiv.org/abs/2104.14623",,,,,
"GOOGLE CLOUD VISION API
Google Cloud Vision API lÃ  má»™t cÃ´ng cá»¥ ráº¥t máº¡nh cÃ³ thá»ƒ mang Ä‘áº¿n cho cuá»™c sá»‘ng cÃ¡c kháº£ nÄƒng á»©ng dá»¥ng vÃ´ táº­n khi káº¿t há»£p vá»›i thÆ° viá»‡n Python. Vision API lÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã o táº¡o trÆ°á»›c cá»§a Google, giÃºp phÃ¡t hiá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng, nháº­n dáº¡ng khuÃ´n máº·t, nháº­n dáº¡ng hÃ¬nh áº£nh, phÃ¢n loáº¡i, gÃ¡n nhÃ£n vÃ  trÃ­ch xuáº¥t vÄƒn báº£n cá»§a vÄƒn báº£n in hoáº·c hÃ¬nh áº£nh chá»¯ viáº¿t tay. NgoÃ i cÃ¡c tÃ­nh nÄƒng trÃªn, Vision API cÃ²n má»™t tÃ­nh nÄƒng ráº¥t thá»±c táº¿ vÃ  thÃº vá»‹ Ä‘Ã³ lÃ  cho phÃ©p báº¡n phÃ¡t hiá»‡n ná»™i dung khÃ´ng lÃ nh máº¡nh cá»§a hÃ¬nh áº£nh. Vision API cho phÃ©p cÃ¡c nhÃ  phÃ¡t triá»ƒn tÃ­ch há»£p cÃ¡c tÃ­nh nÄƒng thÃº vá»‹ vÃ o cÃ¡c á»©ng dá»¥ng dá»… dÃ ng.
Váº­y Google Cloud Vision API há»— trá»£ Machine Learning báº±ng cÃ¡c tÃ­nh nÄƒng gÃ¬?
ğŸ”°Hiá»ƒn thá»‹ thÃ´ng tin cÃ¡c thuá»™c tÃ­nh cá»§a hÃ¬nh áº£nh
ğŸ”°PhÃ¡t hiá»‡n khuÃ´n máº·t
ğŸ”°PhÃ¡t hiá»‡n nhÃ£n
ğŸ”°Nháº­n dáº¡ng kÃ½ tá»± quang há»c
ğŸ”°PhÃ¡t hiá»‡n Web
ğŸ”°PhÃ¡t hiá»‡n nhiá»u Ä‘á»‘i tÆ°á»£ng
ğŸ”°PhÃ¡t hiá»‡n ná»™i dung khÃ´ng an toÃ n
Nhá»¯ng thÃ´ng tin trÃªn hi vá»ng giÃºp Ã­ch cho cÃ¡c báº¡n vá» cÃ¡c kháº£ nÄƒng mÃ  Google Vision API trÃªn ná»n táº£ng GCP cÃ³ thá»ƒ há»— trá»£ Ä‘Æ°á»£c.
Tham kháº£o cÃ¡ch trÃ¬nh diá»…n Google Cloud Vision API vá»›i Python qua Blog chia sáº» kiáº¿n thá»©c Google Cloud: https://blog.cloud-ace.vn/.../trinh-dien-google-cloud.../
ğŸ‘‰Cloud Ace - Google Cloud Training Partner
#googlecloudtraining #cloudacevietnam","GOOGLE CLOUD VISION API Google Cloud Vision API lÃ  má»™t cÃ´ng cá»¥ ráº¥t máº¡nh cÃ³ thá»ƒ mang Ä‘áº¿n cho cuá»™c sá»‘ng cÃ¡c kháº£ nÄƒng á»©ng dá»¥ng vÃ´ táº­n khi káº¿t há»£p vá»›i thÆ° viá»‡n Python. Vision API lÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã o táº¡o trÆ°á»›c cá»§a Google, giÃºp phÃ¡t hiá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng, nháº­n dáº¡ng khuÃ´n máº·t, nháº­n dáº¡ng hÃ¬nh áº£nh, phÃ¢n loáº¡i, gÃ¡n nhÃ£n vÃ  trÃ­ch xuáº¥t vÄƒn báº£n cá»§a vÄƒn báº£n in hoáº·c hÃ¬nh áº£nh chá»¯ viáº¿t tay. NgoÃ i cÃ¡c tÃ­nh nÄƒng trÃªn, Vision API cÃ²n má»™t tÃ­nh nÄƒng ráº¥t thá»±c táº¿ vÃ  thÃº vá»‹ Ä‘Ã³ lÃ  cho phÃ©p báº¡n phÃ¡t hiá»‡n ná»™i dung khÃ´ng lÃ nh máº¡nh cá»§a hÃ¬nh áº£nh. Vision API cho phÃ©p cÃ¡c nhÃ  phÃ¡t triá»ƒn tÃ­ch há»£p cÃ¡c tÃ­nh nÄƒng thÃº vá»‹ vÃ o cÃ¡c á»©ng dá»¥ng dá»… dÃ ng. Váº­y Google Cloud Vision API há»— trá»£ Machine Learning báº±ng cÃ¡c tÃ­nh nÄƒng gÃ¬? Hiá»ƒn thá»‹ thÃ´ng tin cÃ¡c thuá»™c tÃ­nh cá»§a hÃ¬nh áº£nh PhÃ¡t hiá»‡n khuÃ´n máº·t PhÃ¡t hiá»‡n nhÃ£n Nháº­n dáº¡ng kÃ½ tá»± quang há»c PhÃ¡t hiá»‡n Web PhÃ¡t hiá»‡n nhiá»u Ä‘á»‘i tÆ°á»£ng PhÃ¡t hiá»‡n ná»™i dung khÃ´ng an toÃ n Nhá»¯ng thÃ´ng tin trÃªn hi vá»ng giÃºp Ã­ch cho cÃ¡c báº¡n vá» cÃ¡c kháº£ nÄƒng mÃ  Google Vision API trÃªn ná»n táº£ng GCP cÃ³ thá»ƒ há»— trá»£ Ä‘Æ°á»£c. Tham kháº£o cÃ¡ch trÃ¬nh diá»…n Google Cloud Vision API vá»›i Python qua Blog chia sáº» kiáº¿n thá»©c Google Cloud: https://blog.cloud-ace.vn/.../trinh-dien-google-cloud.../ Cloud Ace - Google Cloud Training Partner",#googlecloudtraining	#cloudacevietnam,,,,
"Em xin chÃ o táº¥t cáº£ má»i ngÆ°á»i, em lÃ  newbie ML, hiá»‡n Ä‘ang lÃ m Ä‘á»“ Ã¡n liÃªn quan Ä‘áº¿n há»c GiÃ¡m sÃ¡t ( thuáº­t toÃ¡n bradley-terry ) Ä‘á»ƒ dá»± Ä‘oÃ¡n win-loss cá»§a ngÆ°á»i chÆ¡i cá» nÃ o Ä‘Ã³ nhÆ°ng váº«n chÆ°a Ä‘á»‹nh hÃ¬nh rÃµ báº¯t Ä‘áº§u tá»« Ä‘áº§u, tá»«ng bÆ°á»›c nhÆ° tháº¿ nÃ o, vá»›i láº¡i viá»‡c tÃ¬m táº­p dá»¯ liá»‡u cÅ©ng háº¡n háº¹p ( Ä‘Ã£ search tÃ¬m nhÆ°ng khÃ´ng cÃ³ nhiá»u ).
Em ráº¥t mong má»i ngÆ°á»i chá»‰ Ä‘iá»ƒm, hÆ°á»›ng dáº«n! Em cáº£m Æ¡n nhiá»u","Em xin chÃ o táº¥t cáº£ má»i ngÆ°á»i, em lÃ  newbie ML, hiá»‡n Ä‘ang lÃ m Ä‘á»“ Ã¡n liÃªn quan Ä‘áº¿n há»c GiÃ¡m sÃ¡t ( thuáº­t toÃ¡n bradley-terry ) Ä‘á»ƒ dá»± Ä‘oÃ¡n win-loss cá»§a ngÆ°á»i chÆ¡i cá» nÃ o Ä‘Ã³ nhÆ°ng váº«n chÆ°a Ä‘á»‹nh hÃ¬nh rÃµ báº¯t Ä‘áº§u tá»« Ä‘áº§u, tá»«ng bÆ°á»›c nhÆ° tháº¿ nÃ o, vá»›i láº¡i viá»‡c tÃ¬m táº­p dá»¯ liá»‡u cÅ©ng háº¡n háº¹p ( Ä‘Ã£ search tÃ¬m nhÆ°ng khÃ´ng cÃ³ nhiá»u ). Em ráº¥t mong má»i ngÆ°á»i chá»‰ Ä‘iá»ƒm, hÆ°á»›ng dáº«n! Em cáº£m Æ¡n nhiá»u",,,,,
"Nhiá»u báº¡n cÃ³ thá»ƒ Ä‘Ã£ biáº¿t vá» máº¡ng nÆ¡-ron nhÆ°ng khÃ´ng pháº£i ai cÅ©ng tÃ¬m hiá»ƒu ká»¹ vá» tÃ­nh cháº¥t bá» máº·t hÃ m má»¥c tiÃªu cá»§a chÃºng. BÃ i viáº¿t má»Ÿ Ä‘áº§u trong chuá»—i cÃ¡c bÃ i viáº¿t vá» AI cá»§a Trung tÃ¢m nghiÃªn cá»©u BK.AI, Äáº¡i há»c BÃ¡ch khoa HÃ  Ná»™i hy vá»ng mang Ä‘áº¿n cho cÃ¡c báº¡n má»™t sá»‘ kiáº¿n thá»©c ban Ä‘áº§u vá» lÄ©nh vá»±c thÃº vá»‹ nÃ y.","Nhiá»u báº¡n cÃ³ thá»ƒ Ä‘Ã£ biáº¿t vá» máº¡ng nÆ¡-ron nhÆ°ng khÃ´ng pháº£i ai cÅ©ng tÃ¬m hiá»ƒu ká»¹ vá» tÃ­nh cháº¥t bá» máº·t hÃ m má»¥c tiÃªu cá»§a chÃºng. BÃ i viáº¿t má»Ÿ Ä‘áº§u trong chuá»—i cÃ¡c bÃ i viáº¿t vá» AI cá»§a Trung tÃ¢m nghiÃªn cá»©u BK.AI, Äáº¡i há»c BÃ¡ch khoa HÃ  Ná»™i hy vá»ng mang Ä‘áº¿n cho cÃ¡c báº¡n má»™t sá»‘ kiáº¿n thá»©c ban Ä‘áº§u vá» lÄ©nh vá»±c thÃº vá»‹ nÃ y.",,,,,
"Mn cho em há»i nÃ y vá»›i áº¡. Em Ä‘á»c trÃªn máº¡ng thÃ¬ hÃ m 'Resize' chá»‰ cÃ³ tÃ¡c dá»¥ng thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh, em ko tháº¥y cÃ³ tÃ¡c dá»¥ng chuáº©n hÃ³a giÃ¡ trá»‹ áº£nh vá» khoáº£ng 0-1. NhÆ°ng sau trong Ä‘Ã¢y hÃ m 'Resize' láº¡i chuáº©n hÃ³a Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n mn nhiá»u.","Mn cho em há»i nÃ y vá»›i áº¡. Em Ä‘á»c trÃªn máº¡ng thÃ¬ hÃ m 'Resize' chá»‰ cÃ³ tÃ¡c dá»¥ng thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh, em ko tháº¥y cÃ³ tÃ¡c dá»¥ng chuáº©n hÃ³a giÃ¡ trá»‹ áº£nh vá» khoáº£ng 0-1. NhÆ°ng sau trong Ä‘Ã¢y hÃ m 'Resize' láº¡i chuáº©n hÃ³a Ä‘Æ°á»£c áº¡. Em cáº£m Æ¡n mn nhiá»u.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Má»Œi ngÆ°á»i cho e há»i vai trÃ² cá»§a tham sá»‘ C vá»›i cost function á»Ÿ trong cÃ¢u 3 trong thuáº­t toÃ¡n SVM vá»›i áº¡. E tÃ¬m hiá»ƒu thÃ¬ nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tham sá»‘ 1/lamda trong regularlization cá»§a logistic regression. VÃ  khi nÃ o thÃ¬ thuáº­t toÃ¡n SVM Bá»‹ overfit vÃ  cáº§n Ä‘iá»u chá»‰nh C nhÆ° nÃ o áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.
Náº¿u ai cÃ³ tÃ i liá»‡u liÃªn quan Ä‘áº¿n cÃ¢u há»i cÃ³ thá»ƒ cho e xin link Ä‘c ko áº¡.
Em xin cáº£m Æ¡n má»i ngÆ°á»i",Em chÃ o má»i ngÆ°á»i áº¡. Má»Œi ngÆ°á»i cho e há»i vai trÃ² cá»§a tham sá»‘ C vá»›i cost function á»Ÿ trong cÃ¢u 3 trong thuáº­t toÃ¡n SVM vá»›i áº¡. E tÃ¬m hiá»ƒu thÃ¬ nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tham sá»‘ 1/lamda trong regularlization cá»§a logistic regression. VÃ  khi nÃ o thÃ¬ thuáº­t toÃ¡n SVM Bá»‹ overfit vÃ  cáº§n Ä‘iá»u chá»‰nh C nhÆ° nÃ o áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i. Náº¿u ai cÃ³ tÃ i liá»‡u liÃªn quan Ä‘áº¿n cÃ¢u há»i cÃ³ thá»ƒ cho e xin link Ä‘c ko áº¡. Em xin cáº£m Æ¡n má»i ngÆ°á»i,,,,,
Hi all. Má»i ngÆ°á»i cÃ³ thá»ƒ share cÃ¡ch Ä‘á»c bÃ i bÃ¡o khoa há»c hay Ä‘Æ¡n giáº£n hÆ¡n lÃ  má»™t bÃ i viáº¿t hay vá» Ml má»™t cÃ¡ch hiá»‡u quáº£ Ä‘Æ°á»£c khÃ´ng áº¡. CÃ¡ch cá»§a em lÃ  láº¥y giáº¥y viáº¿t ra ghi tÃ³m táº¯t láº¡i má»™t vÃ i Ã½ nhÆ°ng em cáº£m tháº¥y cÃ¡ch Ä‘á»c cá»§a mÃ¬nh khÃ´ng hiá»‡u quáº£ vÃ  e cÅ©ng tháº¥y khÃ¡ tá»‘n thá»i gian áº¡.,Hi all. Má»i ngÆ°á»i cÃ³ thá»ƒ share cÃ¡ch Ä‘á»c bÃ i bÃ¡o khoa há»c hay Ä‘Æ¡n giáº£n hÆ¡n lÃ  má»™t bÃ i viáº¿t hay vá» Ml má»™t cÃ¡ch hiá»‡u quáº£ Ä‘Æ°á»£c khÃ´ng áº¡. CÃ¡ch cá»§a em lÃ  láº¥y giáº¥y viáº¿t ra ghi tÃ³m táº¯t láº¡i má»™t vÃ i Ã½ nhÆ°ng em cáº£m tháº¥y cÃ¡ch Ä‘á»c cá»§a mÃ¬nh khÃ´ng hiá»‡u quáº£ vÃ  e cÅ©ng tháº¥y khÃ¡ tá»‘n thá»i gian áº¡.,,,,,
"[AI Share â€“ Hugging Face course]
Hugging Face lÃ  má»™t cÃ¡i tÃªn khÃ¡ quen thuá»™c trong NLP. Gáº§n Ä‘Ã¢y, nhÃ³m Hugging Face Ä‘Ã£ phÃ¡t hÃ nh khÃ³a há»c miá»…n phÃ­ vá» NLP vá»›i thÆ° viá»‡n Hugging Face. KhÃ³a há»c nÃ y táº­p trung vÃ o cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n vá» NLP báº±ng cÃ¡ch sá»­ dá»¥ng Hugging Face. Máº·c dÃ¹ khÃ³a há»c hÆ°á»›ng tá»›i nhá»¯ng ngÆ°á»i má»›i báº¯t Ä‘áº§u, nhÆ°ng nÃ³ cÅ©ng sáº½ há»¯u Ã­ch cho nhá»¯ng ngÆ°á»i Ä‘Ã£ cÃ³ kiáº¿n thá»©c cÆ¡ báº£n cÅ©ng nhÆ° cÃ¡c chuyÃªn gia NLP theo má»™t cÃ¡ch nÃ o Ä‘Ã³. Ná»™i dung gá»“m 4 pháº§n chÃ­nh lÃ  Transformers, Datasets, Tokenizers vÃ  Accelerate.
1. Transformers lÃ  thÆ° viá»‡n cung cáº¥p hÃ ng nghÃ¬n mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã o táº¡o trÆ°á»›c nhÆ° BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet,â€¦, Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ trÃªn vÄƒn báº£n nhÆ° phÃ¢n loáº¡i, trÃ­ch xuáº¥t thÃ´ng tin, tráº£ lá»i cÃ¢u há»i, tÃ³m táº¯t,â€¦
2. Tokenizers chuyá»ƒn Ä‘á»•i Ä‘áº§u vÃ o vÄƒn báº£n thÃ nh dá»¯ liá»‡u sá»‘.
3. Datasets lÃ  má»™t thÆ° viá»‡n cÃ³ thá»ƒ dá»… dÃ ng chia sáº» vÃ  truy cáº­p cÃ¡c táº­p dá»¯ liá»‡u cÅ©ng nhÆ° cÃ¡c Ä‘á»™ Ä‘o Ä‘Ã¡nh giÃ¡ trong NLP
4. Accelerate cho phÃ©p Ä‘Ã o táº¡o phÃ¢n tÃ¡n cÃ¡c mÃ´ hÃ¬nh Pytorch trÃªn nhiá»u GPU hoáº·c TPU.","[AI Share â€“ Hugging Face course] Hugging Face lÃ  má»™t cÃ¡i tÃªn khÃ¡ quen thuá»™c trong NLP. Gáº§n Ä‘Ã¢y, nhÃ³m Hugging Face Ä‘Ã£ phÃ¡t hÃ nh khÃ³a há»c miá»…n phÃ­ vá» NLP vá»›i thÆ° viá»‡n Hugging Face. KhÃ³a há»c nÃ y táº­p trung vÃ o cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n vá» NLP báº±ng cÃ¡ch sá»­ dá»¥ng Hugging Face. Máº·c dÃ¹ khÃ³a há»c hÆ°á»›ng tá»›i nhá»¯ng ngÆ°á»i má»›i báº¯t Ä‘áº§u, nhÆ°ng nÃ³ cÅ©ng sáº½ há»¯u Ã­ch cho nhá»¯ng ngÆ°á»i Ä‘Ã£ cÃ³ kiáº¿n thá»©c cÆ¡ báº£n cÅ©ng nhÆ° cÃ¡c chuyÃªn gia NLP theo má»™t cÃ¡ch nÃ o Ä‘Ã³. Ná»™i dung gá»“m 4 pháº§n chÃ­nh lÃ  Transformers, Datasets, Tokenizers vÃ  Accelerate. 1. Transformers lÃ  thÆ° viá»‡n cung cáº¥p hÃ ng nghÃ¬n mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã o táº¡o trÆ°á»›c nhÆ° BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet,â€¦, Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ trÃªn vÄƒn báº£n nhÆ° phÃ¢n loáº¡i, trÃ­ch xuáº¥t thÃ´ng tin, tráº£ lá»i cÃ¢u há»i, tÃ³m táº¯t,â€¦ 2. Tokenizers chuyá»ƒn Ä‘á»•i Ä‘áº§u vÃ o vÄƒn báº£n thÃ nh dá»¯ liá»‡u sá»‘. 3. Datasets lÃ  má»™t thÆ° viá»‡n cÃ³ thá»ƒ dá»… dÃ ng chia sáº» vÃ  truy cáº­p cÃ¡c táº­p dá»¯ liá»‡u cÅ©ng nhÆ° cÃ¡c Ä‘á»™ Ä‘o Ä‘Ã¡nh giÃ¡ trong NLP 4. Accelerate cho phÃ©p Ä‘Ã o táº¡o phÃ¢n tÃ¡n cÃ¡c mÃ´ hÃ¬nh Pytorch trÃªn nhiá»u GPU hoáº·c TPU.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡
Em cÃ³ má»™t cÃ¢u há»i vá» ML mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡. Em tháº¥y thÃ¬ linear regression thÃ¬ cÃ³ thá»ƒ dÃ¹ng á»Ÿ local minimum nhÆ°ng ko biáº¿t logistic thÃ¬ ntn. Em cáº£m Æ¡n má»i ngÆ°á»i",Em chÃ o má»i ngÆ°á»i áº¡ Em cÃ³ má»™t cÃ¢u há»i vá» ML mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡. Em tháº¥y thÃ¬ linear regression thÃ¬ cÃ³ thá»ƒ dÃ¹ng á»Ÿ local minimum nhÆ°ng ko biáº¿t logistic thÃ¬ ntn. Em cáº£m Æ¡n má»i ngÆ°á»i,,,,,
"MÃ¬nh tÃ¬nh cá» tÃ¬m tháº¥y 1 notebook khÃ¡ hay giáº£i thÃ­ch tá»« Tensor, Filters, Strides, Padding, MaxPooling, Computational Grap, AutoGrad, cÅ©ng nhÆ° má»™t sá»‘ module trong bÃ i toÃ¡n Computer Vision cho PyTorch. VÃ  má»™t Ä‘iá»u thÃº vá»‹, cÃ¡c báº¡n lÃ m á»©ng dá»¥ng hay nghiÃªn cá»©u Ä‘á»u Ä‘áº·c biá»‡t quan tÃ¢m lÃ  hiá»‡n tÆ°á»£ng Underfitting >< Overfitting, á»Ÿ notebook nÃ y cÅ©ng giáº£i thÃ­ch ráº¥t trá»±c quan. Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i. https://colab.research.google.com/github/pranjalchaubey/Deep-Learning-Notes/blob/master/PyTorch%20Image%20Classification%20in%202020/Image_Classification_practice.ipynb?fbclid=IwAR3fNr9HFt7l9q5w7VMdIBNTof6oBMZjzZVKLE2MT7UrBRI5k_DPDVHcA28#scrollTo=el1NUdaz0HrE","MÃ¬nh tÃ¬nh cá» tÃ¬m tháº¥y 1 notebook khÃ¡ hay giáº£i thÃ­ch tá»« Tensor, Filters, Strides, Padding, MaxPooling, Computational Grap, AutoGrad, cÅ©ng nhÆ° má»™t sá»‘ module trong bÃ i toÃ¡n Computer Vision cho PyTorch. VÃ  má»™t Ä‘iá»u thÃº vá»‹, cÃ¡c báº¡n lÃ m á»©ng dá»¥ng hay nghiÃªn cá»©u Ä‘á»u Ä‘áº·c biá»‡t quan tÃ¢m lÃ  hiá»‡n tÆ°á»£ng Underfitting >< Overfitting, á»Ÿ notebook nÃ y cÅ©ng giáº£i thÃ­ch ráº¥t trá»±c quan. Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i. https://colab.research.google.com/github/pranjalchaubey/Deep-Learning-Notes/blob/master/PyTorch%20Image%20Classification%20in%202020/Image_Classification_practice.ipynb?fbclid=IwAR3fNr9HFt7l9q5w7VMdIBNTof6oBMZjzZVKLE2MT7UrBRI5k_DPDVHcA28#scrollTo=el1NUdaz0HrE",,,,,
#Logistic #Classification,,#Logistic	#Classification,,,,
"Em gá»­i má»i ngÆ°á»i clip thá»© 3 em lÃ m vá» Statistics áº¡.
Hi vá»ng giÃºp má»i ngÆ°á»i review láº¡i kiáº¿n thá»©c tá»‘t hÆ¡n.",Em gá»­i má»i ngÆ°á»i clip thá»© 3 em lÃ m vá» Statistics áº¡. Hi vá»ng giÃºp má»i ngÆ°á»i review láº¡i kiáº¿n thá»©c tá»‘t hÆ¡n.,,,,,
Cho cÃ¡c báº¡n muá»‘n nghiÃªn cá»©u sÃ¢u vá» lÃ½ thuyáº¿t deep learning.,Cho cÃ¡c báº¡n muá»‘n nghiÃªn cá»©u sÃ¢u vá» lÃ½ thuyáº¿t deep learning.,,,,,
"ChÃ o má»i ngÆ°á»i!
Má»i ngÆ°á»i cho em há»i 1 chÃºt lÃ  Náº¿u so sÃ¡nh Faster R-CNN vá»›i Mask-RCNN vÃ  Yolo thÃ¬ cÃ³ Ä‘iá»ƒm gÃ¬ khÃ¡c biá»‡t khÃ´ng áº¡!
theo nhÆ° em tÃ¬m hiá»ƒu thÃ¬ Mask-RCNN vá»›i Yolo Ä‘á»u káº¿ thá»«a tá»« Faster-RCNN vÃ  Ä‘á»u tráº£ vá» lÃ  bounding boxes vÃ  label cá»§a Ä‘á»‘i tÆ°á»£ng. váº­y YOLO khÃ¡c gÃ¬ so vá»›i Mask-RCNN.
Em má»›i tÃ¬m hiá»ƒu , mong m,n chá»‰ giÃºp áº¡!
Thanks m.n!","ChÃ o má»i ngÆ°á»i! Má»i ngÆ°á»i cho em há»i 1 chÃºt lÃ  Náº¿u so sÃ¡nh Faster R-CNN vá»›i Mask-RCNN vÃ  Yolo thÃ¬ cÃ³ Ä‘iá»ƒm gÃ¬ khÃ¡c biá»‡t khÃ´ng áº¡! theo nhÆ° em tÃ¬m hiá»ƒu thÃ¬ Mask-RCNN vá»›i Yolo Ä‘á»u káº¿ thá»«a tá»« Faster-RCNN vÃ  Ä‘á»u tráº£ vá» lÃ  bounding boxes vÃ  label cá»§a Ä‘á»‘i tÆ°á»£ng. váº­y YOLO khÃ¡c gÃ¬ so vá»›i Mask-RCNN. Em má»›i tÃ¬m hiá»ƒu , mong m,n chá»‰ giÃºp áº¡! Thanks m.n!",,,,,
"Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t má»¥c nhá» tiáº¿p theo cá»§a cuá»‘n sÃ¡ch ""Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng"". Pháº§n nÃ y giá»›i thiá»‡u ban Ä‘áº§u vá» viá»‡c xÃ¢y dá»±ng embedding cho dá»¯ liá»‡u dáº¡ng háº¡ng má»¥c. MÃ¬nh cÅ©ng cÃ³ giáº£i thÃ­ch cÆ¡ báº£n vá» word2vec vÃ  cÃ¡ch Ã¡p dá»¥ng Ã½ tÆ°á»Ÿng tÆ°Æ¡ng tá»± Ä‘á»ƒ xÃ¢y dá»±ng embedding cho cÃ¡c sáº£n pháº©m dá»±a trÃªn thá»© tá»± cá»§a chÃºng trong cÃ¡c Ä‘Æ¡n hÃ ng.
Cuá»‘n sÃ¡ch sáº½ cÃ²n nhiá»u pháº§n khÃ¡c mÃ  embedding sáº½ Ä‘Æ°á»£c Ã¡p dá»¥ng. Embedding lÃ  cÃ¡ch ráº¥t phá»• biáº¿n giÃºp cáº£i thiá»‡n cháº¥t lÆ°á»£ng cÃ¡c mÃ´ hÃ¬nh deep learning cho dá»¯ liá»‡u dáº¡ng báº£ng.
Embedding:","Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t má»¥c nhá» tiáº¿p theo cá»§a cuá»‘n sÃ¡ch ""Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng"". Pháº§n nÃ y giá»›i thiá»‡u ban Ä‘áº§u vá» viá»‡c xÃ¢y dá»±ng embedding cho dá»¯ liá»‡u dáº¡ng háº¡ng má»¥c. MÃ¬nh cÅ©ng cÃ³ giáº£i thÃ­ch cÆ¡ báº£n vá» word2vec vÃ  cÃ¡ch Ã¡p dá»¥ng Ã½ tÆ°á»Ÿng tÆ°Æ¡ng tá»± Ä‘á»ƒ xÃ¢y dá»±ng embedding cho cÃ¡c sáº£n pháº©m dá»±a trÃªn thá»© tá»± cá»§a chÃºng trong cÃ¡c Ä‘Æ¡n hÃ ng. Cuá»‘n sÃ¡ch sáº½ cÃ²n nhiá»u pháº§n khÃ¡c mÃ  embedding sáº½ Ä‘Æ°á»£c Ã¡p dá»¥ng. Embedding lÃ  cÃ¡ch ráº¥t phá»• biáº¿n giÃºp cáº£i thiá»‡n cháº¥t lÆ°á»£ng cÃ¡c mÃ´ hÃ¬nh deep learning cho dá»¯ liá»‡u dáº¡ng báº£ng. Embedding:",,,,,
Mn cho em há»i lÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a thuáº­t toÃ¡n khoáº£ng bao nhiÃªu % trá»Ÿ lÃªn thÃ¬ Ä‘Æ°á»£c cháº¥p nháº­n áº¡. VÃ­ dá»¥ nhÆ° 40% thÃ¬ cÃ³ hy vá»ng Ä‘Æ°á»£c cháº¥p nháº­n khÃ´ng áº¡. Em cáº£m Æ¡n mn nhiá»u.,Mn cho em há»i lÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a thuáº­t toÃ¡n khoáº£ng bao nhiÃªu % trá»Ÿ lÃªn thÃ¬ Ä‘Æ°á»£c cháº¥p nháº­n áº¡. VÃ­ dá»¥ nhÆ° 40% thÃ¬ cÃ³ hy vá»ng Ä‘Æ°á»£c cháº¥p nháº­n khÃ´ng áº¡. Em cáº£m Æ¡n mn nhiá»u.,,,,,
DÃ¹ Ä‘Ã£ cá»‘ gáº¯ng nhÆ°ng váº«n viáº¿t chÆ°a hay. Mong cÃ¡c báº¡n nháº­n xÃ©t Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n.,DÃ¹ Ä‘Ã£ cá»‘ gáº¯ng nhÆ°ng váº«n viáº¿t chÆ°a hay. Mong cÃ¡c báº¡n nháº­n xÃ©t Ä‘á»ƒ hoÃ n thiá»‡n hÆ¡n.,,,,,
,nan,,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 01/2021 vÃ o trong comment cá»§a post nÃ y.
Hoáº·c https://forum.machinelearningcoban.com/c/jobs-events
ChÃºc cÃ¡c báº¡n nÄƒm má»›i máº¡nh khoáº» vÃ  nhiá»u thÃ nh cÃ´ng!","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 01/2021 vÃ o trong comment cá»§a post nÃ y. Hoáº·c https://forum.machinelearningcoban.com/c/jobs-events ChÃºc cÃ¡c báº¡n nÄƒm má»›i máº¡nh khoáº» vÃ  nhiá»u thÃ nh cÃ´ng!",,,,,
"Láº¡i lÃ  em Ä‘Ã¢y áº¡, cÃ¢u há»i náº±m trong áº£nh 1 áº¡, vÃ  cÃ¢u tráº£ lá»i cá»§a em náº±m trong áº£nh 2, xin há»i má»i ngÆ°á»i lÃ  em Ä‘Ã£ lÃ m Ä‘Ãºng chÆ°a áº¡, em xin cáº£m Æ¡n áº¡!","Láº¡i lÃ  em Ä‘Ã¢y áº¡, cÃ¢u há»i náº±m trong áº£nh 1 áº¡, vÃ  cÃ¢u tráº£ lá»i cá»§a em náº±m trong áº£nh 2, xin há»i má»i ngÆ°á»i lÃ  em Ä‘Ã£ lÃ m Ä‘Ãºng chÆ°a áº¡, em xin cáº£m Æ¡n áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m estimate distance vÃ  Ä‘ang khÃ´ng cÃ³ solutions cho bÃ i toÃ¡n. Má»i ngÆ°á»i ai Ä‘Ã£ lÃ m qua vá» bÃ i toÃ¡n nÃ y cho e xin Ã­t kinh nghiá»‡m Ä‘Æ°á»£c khÃ´ng áº¡ ?
Em chÃ¢n thÃ nh cáº£m Æ¡n !","ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m estimate distance vÃ  Ä‘ang khÃ´ng cÃ³ solutions cho bÃ i toÃ¡n. Má»i ngÆ°á»i ai Ä‘Ã£ lÃ m qua vá» bÃ i toÃ¡n nÃ y cho e xin Ã­t kinh nghiá»‡m Ä‘Æ°á»£c khÃ´ng áº¡ ? Em chÃ¢n thÃ nh cáº£m Æ¡n !",,,,,
"Em Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡i recommendation engine theo link nÃ y cá»§a Code Heroku. á» trong clip lÃ  recommendation engine theo kiá»ƒu item-item collaborative filtering.
https://youtu.be/3ecNC-So0r4
Em muá»‘n há»i má»i ngÆ°á»i nÃ y vá» tÃ­nh toÃ¡n 1 chÃºt, lÃ :
HÃ¬nh 1: á» Ä‘oáº¡n nÃ y, tá»« dataset cho trÆ°á»›c, sau khi tÃ­nh cosine tá»«ng Ä‘áº¡i lÆ°á»£ng 2 hÃ ng ngang dá»c, chÃºng ta cÃ³ Ä‘Æ°á»£c similarities tá»«ng cáº·p.
HÃ¬nh 2: khi cÃ³ Ä‘Æ°á»£c similarities tá»«ng cáº·p, chÃºng ta nháº­p vÃ´ Ä‘Ã¡nh giÃ¡ cá»§a 1 ngÆ°á»i dÃ¹ng báº¥t kÃ¬, nhÆ° á»Ÿ Ä‘Ã¢y cÃ³ 1 ngÆ°á»i dÃ¹ng Ä‘Ã¡nh giÃ¡ bá»™ phim romantic3 lÃ  1 sao.
LÃ m sao Ä‘á»ƒ tá»« ma tráº­n nhÆ° hÃ¬nh 1 mÃ  nÃ³ thÃ nh 6 dÃ²ng ngáº¯n gá»n nhÆ° á»Ÿ hÃ¬nh 2 váº­y áº¡? Em xem cÃ´ng thá»©c trÃªn code mÃ  khÃ´ng hiá»ƒu
Em cáº£m Æ¡n anh chá»‹ em Ä‘Ã£ xem bÃ i áº¡.
Cáº¬P NHáº¬T: Em/MÃ¬nh Ä‘Ã£ hiá»ƒu. ÄÃ³ lÃ  chá»n cá»™t dá»c hoáº·c hÃ ng ngang cá»§a romantic3 Ä‘á»u Ä‘Æ°á»£c, vÃ¬ sá»‘ cá»§a cá»™t vÃ  dÃ²ng giá»‘ng nhau. Sau Ä‘Ã³ nhÃ¢n tá»«ng sá»‘ cho (rating-2.5, 2.5 nÃ y lÃ  mean, cÃ¡c báº¡n coi clip sáº½ hiá»ƒu, khoáº£ng phÃºt thá»© 23 24). Sau Ä‘Ã³ sáº¯p xáº¿p láº¡i theo thá»© tá»± giáº£m dáº§n, ta Ä‘Æ°á»£c hÃ¬nh 2.","Em Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡i recommendation engine theo link nÃ y cá»§a Code Heroku. á» trong clip lÃ  recommendation engine theo kiá»ƒu item-item collaborative filtering. https://youtu.be/3ecNC-So0r4 Em muá»‘n há»i má»i ngÆ°á»i nÃ y vá» tÃ­nh toÃ¡n 1 chÃºt, lÃ : HÃ¬nh 1: á» Ä‘oáº¡n nÃ y, tá»« dataset cho trÆ°á»›c, sau khi tÃ­nh cosine tá»«ng Ä‘áº¡i lÆ°á»£ng 2 hÃ ng ngang dá»c, chÃºng ta cÃ³ Ä‘Æ°á»£c similarities tá»«ng cáº·p. HÃ¬nh 2: khi cÃ³ Ä‘Æ°á»£c similarities tá»«ng cáº·p, chÃºng ta nháº­p vÃ´ Ä‘Ã¡nh giÃ¡ cá»§a 1 ngÆ°á»i dÃ¹ng báº¥t kÃ¬, nhÆ° á»Ÿ Ä‘Ã¢y cÃ³ 1 ngÆ°á»i dÃ¹ng Ä‘Ã¡nh giÃ¡ bá»™ phim romantic3 lÃ  1 sao. LÃ m sao Ä‘á»ƒ tá»« ma tráº­n nhÆ° hÃ¬nh 1 mÃ  nÃ³ thÃ nh 6 dÃ²ng ngáº¯n gá»n nhÆ° á»Ÿ hÃ¬nh 2 váº­y áº¡? Em xem cÃ´ng thá»©c trÃªn code mÃ  khÃ´ng hiá»ƒu Em cáº£m Æ¡n anh chá»‹ em Ä‘Ã£ xem bÃ i áº¡. Cáº¬P NHáº¬T: Em/MÃ¬nh Ä‘Ã£ hiá»ƒu. ÄÃ³ lÃ  chá»n cá»™t dá»c hoáº·c hÃ ng ngang cá»§a romantic3 Ä‘á»u Ä‘Æ°á»£c, vÃ¬ sá»‘ cá»§a cá»™t vÃ  dÃ²ng giá»‘ng nhau. Sau Ä‘Ã³ nhÃ¢n tá»«ng sá»‘ cho (rating-2.5, 2.5 nÃ y lÃ  mean, cÃ¡c báº¡n coi clip sáº½ hiá»ƒu, khoáº£ng phÃºt thá»© 23 24). Sau Ä‘Ã³ sáº¯p xáº¿p láº¡i theo thá»© tá»± giáº£m dáº§n, ta Ä‘Æ°á»£c hÃ¬nh 2.",,,,,
"ChÃ o má»i ngÆ°á»i
Em cÃ³ má»™t cÃ¢u há»i vá» KL divergence giá»¯a hai multivariate normal distribution áº¡.
Em cÃ³ 2 multivariate normal distribution lÃ  prior vÃ  posterior. Em dÃ¹ng PCA Ä‘á»ƒ giáº£m dimension (64 xuá»‘ng 3) vÃ  nhÃ¬n trá»±c quan 2 distribution nÃ y áº¡ (hÃ¬nh Ä‘Ã­nh kÃ¨m, xanh: posterior distribution, Ä‘á»: prior distribution). Theo hÃ¬nh áº£nh, 2 distribution nÃ y ráº¥t khÃ¡c nhau vÃ¬ mean cá»§a chÃºng tÃ¡ch biá»‡t hoÃ n toÃ n.
Tuy nhiÃªn, khi em Ã¡p dá»¥ng KL divergence cho 2 distribution nÃ y (dÃ¹ng multivariate distribution gá»‘c chá»© khÃ´ng pháº£i tá»« PCA), thÃ¬ káº¿t quáº£ lÃ  khoáº£ng 0.17, nghÄ©a lÃ  2 distribution nÃ y láº¡i ""giá»‘ng"" nhau.

CÃ¢u há»i: cÃ³ nÃªn Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cá»§a 2 multivariate distribution thÃ´ng qua visualization tá»« PCA thÃ¬ khÃ´ng?

Cáº£m Æ¡n má»i ngÆ°á»i áº¡","ChÃ o má»i ngÆ°á»i Em cÃ³ má»™t cÃ¢u há»i vá» KL divergence giá»¯a hai multivariate normal distribution áº¡. Em cÃ³ 2 multivariate normal distribution lÃ  prior vÃ  posterior. Em dÃ¹ng PCA Ä‘á»ƒ giáº£m dimension (64 xuá»‘ng 3) vÃ  nhÃ¬n trá»±c quan 2 distribution nÃ y áº¡ (hÃ¬nh Ä‘Ã­nh kÃ¨m, xanh: posterior distribution, Ä‘á»: prior distribution). Theo hÃ¬nh áº£nh, 2 distribution nÃ y ráº¥t khÃ¡c nhau vÃ¬ mean cá»§a chÃºng tÃ¡ch biá»‡t hoÃ n toÃ n. Tuy nhiÃªn, khi em Ã¡p dá»¥ng KL divergence cho 2 distribution nÃ y (dÃ¹ng multivariate distribution gá»‘c chá»© khÃ´ng pháº£i tá»« PCA), thÃ¬ káº¿t quáº£ lÃ  khoáº£ng 0.17, nghÄ©a lÃ  2 distribution nÃ y láº¡i ""giá»‘ng"" nhau. CÃ¢u há»i: cÃ³ nÃªn Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cá»§a 2 multivariate distribution thÃ´ng qua visualization tá»« PCA thÃ¬ khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡ .
Em má»›i báº¯t Ä‘áº§u nghiÃªn cá»©u vá» AI vÃ  cÃ³ má»™t bÃ i toÃ¡n cáº§n má»i ngÆ°á»i giÃºp Ä‘á»¡ Ä‘á»ƒ tÃ¬m ra hÆ°á»›ng giáº£i quyáº¿t áº¡:
BÃ i toÃ¡n Ä‘áº·t ra lÃ  tá»« má»™t áº£nh Ä‘áº§u vÃ o lÃ  áº£nh má»™t vá»‹ trÃ­ hay tá»a Ä‘á»™ trÃªn báº£n Ä‘á»“ ( áº£nh google map) Ä‘á»ƒ phÃ¡t hiá»‡n ra Ä‘Æ°á»ng Ä‘i trong bá»©c áº£nh Ä‘Ã³ nhÆ° hÃ¬nh dÆ°á»›i áº¡. Má»i ngÆ°á»i cÃ³ thuáº­t toÃ¡n hay code nÃ o liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ cho em xin Ä‘Æ°á»£c khÃ´ng áº¡. Em cÅ©ng cá»‘ gáº¯ng tÃ¬m kiáº¿m nhiá»u nhÆ°ng khÃ´ng ra Ä‘Æ°á»£c hÆ°á»›ng giáº£i quyáº¿t, mÃ´ng má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.","Em chÃ o má»i ngÆ°á»i áº¡ . Em má»›i báº¯t Ä‘áº§u nghiÃªn cá»©u vá» AI vÃ  cÃ³ má»™t bÃ i toÃ¡n cáº§n má»i ngÆ°á»i giÃºp Ä‘á»¡ Ä‘á»ƒ tÃ¬m ra hÆ°á»›ng giáº£i quyáº¿t áº¡: BÃ i toÃ¡n Ä‘áº·t ra lÃ  tá»« má»™t áº£nh Ä‘áº§u vÃ o lÃ  áº£nh má»™t vá»‹ trÃ­ hay tá»a Ä‘á»™ trÃªn báº£n Ä‘á»“ ( áº£nh google map) Ä‘á»ƒ phÃ¡t hiá»‡n ra Ä‘Æ°á»ng Ä‘i trong bá»©c áº£nh Ä‘Ã³ nhÆ° hÃ¬nh dÆ°á»›i áº¡. Má»i ngÆ°á»i cÃ³ thuáº­t toÃ¡n hay code nÃ o liÃªn quan Ä‘áº¿n váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ cho em xin Ä‘Æ°á»£c khÃ´ng áº¡. Em cÅ©ng cá»‘ gáº¯ng tÃ¬m kiáº¿m nhiá»u nhÆ°ng khÃ´ng ra Ä‘Æ°á»£c hÆ°á»›ng giáº£i quyáº¿t, mÃ´ng má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.",,,,,
"Em chÃ o mn. Mn chá»‰ giÃºp em váº¥n Ä‘á» nÃ y vá»›i áº¡. Chuyá»‡n lÃ  em dÃ¹ng thuáº­t toÃ¡n Random Forest trong Sklearn Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n. NhÆ°ng ngoÃ i 'n_estimators' ra thÃ¬ cÃ¡c 'tÃ­nh cháº¥t' kia em Ä‘á»c (cáº£ thuáº­t toÃ¡n Random Forest vÃ  cÃ¡c giáº£i thÃ­ch trong Sklearn) nhÆ°ng ko hiá»ƒu nÃ³ sáº½ cÃ³ tÃ¡c dá»¥ng gÃ¬ vÃ  Ä‘iá»u chá»‰nh ra sau Ä‘á»ƒ thuáº­t toÃ¡n Ä‘Æ°á»£c tá»‘t nháº¥t áº¡. Mn cho em há»i lÃ  trong thuáº­t toÃ¡n cá»§a em nÃªn thÃªm 'tÃ­nh cháº¥t' nÃ o vÃ o vÃ  giÃ¡ trá»‹ cá»§a nÃ³ nhÆ° tháº¿ náº¡o áº¡. E cáº£m Æ¡n mn nhiá»u.
Ps : NÃªn dÃ¹ng GridSearchCV Ä‘á»ƒ tÃ¬m siÃªu tham sá»‘ trong thuáº­t toÃ¡n nÃ y ko áº¡.",Em chÃ o mn. Mn chá»‰ giÃºp em váº¥n Ä‘á» nÃ y vá»›i áº¡. Chuyá»‡n lÃ  em dÃ¹ng thuáº­t toÃ¡n Random Forest trong Sklearn Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n. NhÆ°ng ngoÃ i 'n_estimators' ra thÃ¬ cÃ¡c 'tÃ­nh cháº¥t' kia em Ä‘á»c (cáº£ thuáº­t toÃ¡n Random Forest vÃ  cÃ¡c giáº£i thÃ­ch trong Sklearn) nhÆ°ng ko hiá»ƒu nÃ³ sáº½ cÃ³ tÃ¡c dá»¥ng gÃ¬ vÃ  Ä‘iá»u chá»‰nh ra sau Ä‘á»ƒ thuáº­t toÃ¡n Ä‘Æ°á»£c tá»‘t nháº¥t áº¡. Mn cho em há»i lÃ  trong thuáº­t toÃ¡n cá»§a em nÃªn thÃªm 'tÃ­nh cháº¥t' nÃ o vÃ o vÃ  giÃ¡ trá»‹ cá»§a nÃ³ nhÆ° tháº¿ náº¡o áº¡. E cáº£m Æ¡n mn nhiá»u. Ps : NÃªn dÃ¹ng GridSearchCV Ä‘á»ƒ tÃ¬m siÃªu tham sá»‘ trong thuáº­t toÃ¡n nÃ y ko áº¡.,,,,,
"Help!
Em cáº§n má»i ngÆ°á»i giÃºp Ä‘á»¡ vá» bÃ i táº­p nhÆ° sau áº¡:
Answer the following questions with a little Python programming.
First of all, load the faces dataset and prepare a 5-class subset using the following code.
from sklearn.datasets import fetch_olivetti_faces
from sklearn.ensemble import RandomForestClassifier
# Load the faces dataset
data = fetch_olivetti_faces()
X, y = data.data, data.target
mask = y < 5 # Limit to 5 classes
X = X[mask]
y = y[mask]
(1) [10 points] Let's use the RandomForest classifier and find out the optimal number of estimators (decision trees) from { 1000, 1500, 2000, 2500, 3000 } in terms of the OOB error. Make sure to use the default parameter setting and random_state=0 of RandomForestClassifier in scikit-learn to obtain the determinstic result.
(2) [10 points] Use the optimal number of estimators obtained in Q4-1. Then, investigate the pixel (i.e., feature) importance trained by the model. List the coordinates of the three most important pixels in an image. The upper-left corner is (0, 0), and the lower-right corner is (63, 63). That is, you need to provide three 2-dimensional coordinates (i.e., (row, col) where 0 â‰¤ row, col â‰¤ 63).
Äá»ƒ giáº£i cÃ¢u 1, em Ä‘Ã£ cháº¡y code nhÆ° sau vÃ  cho káº¿t quáº£ á»Ÿ hÃ¬nh (1) áº¡, tá»« Ä‘Ã³ káº¿t luáº­n optimal number of estimators is 2000 áº¡.
Äá»ƒ giáº£i cÃ¢u 2, Em cháº¡y code nhÆ° hÃ¬nh 2, nhÆ°ng Ä‘áº¿n Ä‘oáº¡n tÃ¬m 3 Ä‘iá»ƒm quan trá»ng nháº¥t vÃ  tá»a Ä‘á»™ cá»§a nÃ³ em khÃ´ng lÃ m Ä‘Æ°á»£c áº¡.
Nhá» má»i ngÆ°á»i xem giÃºp em áº¡, nhá»¯ng bÆ°á»›c em lÃ m Ä‘Ã£ Ä‘ugns chÆ°a áº¡, vÃ  cÃ¢u 2 lÃ m tháº¿ nÃ o áº¡. ÄÃ¢y lÃ  bÃ i kiá»ƒm tra cá»§a em, vÃ  Ä‘Æ°á»£c phÃ©p há»i ngÆ°á»i khÃ¡c áº¡. VÃ¬ chuyÃªn ngÃ nh cá»§a em lÃ  chuyÃªn ngÃ nh khÃ¡c nÃªn em khÃ¡c khÃ³ khÄƒn khi há»c vá» ML áº¡
Em xin cáº£m Æ¡n áº¡","Help! Em cáº§n má»i ngÆ°á»i giÃºp Ä‘á»¡ vá» bÃ i táº­p nhÆ° sau áº¡: Answer the following questions with a little Python programming. First of all, load the faces dataset and prepare a 5-class subset using the following code. from sklearn.datasets import fetch_olivetti_faces from sklearn.ensemble import RandomForestClassifier # Load the faces dataset data = fetch_olivetti_faces() X, y = data.data, data.target mask = y < 5 # Limit to 5 classes X = X[mask] y = y[mask] (1) [10 points] Let's use the RandomForest classifier and find out the optimal number of estimators (decision trees) from { 1000, 1500, 2000, 2500, 3000 } in terms of the OOB error. Make sure to use the default parameter setting and random_state=0 of RandomForestClassifier in scikit-learn to obtain the determinstic result. (2) [10 points] Use the optimal number of estimators obtained in Q4-1. Then, investigate the pixel (i.e., feature) importance trained by the model. List the coordinates of the three most important pixels in an image. The upper-left corner is (0, 0), and the lower-right corner is (63, 63). That is, you need to provide three 2-dimensional coordinates (i.e., (row, col) where 0 â‰¤ row, col â‰¤ 63). Äá»ƒ giáº£i cÃ¢u 1, em Ä‘Ã£ cháº¡y code nhÆ° sau vÃ  cho káº¿t quáº£ á»Ÿ hÃ¬nh (1) áº¡, tá»« Ä‘Ã³ káº¿t luáº­n optimal number of estimators is 2000 áº¡. Äá»ƒ giáº£i cÃ¢u 2, Em cháº¡y code nhÆ° hÃ¬nh 2, nhÆ°ng Ä‘áº¿n Ä‘oáº¡n tÃ¬m 3 Ä‘iá»ƒm quan trá»ng nháº¥t vÃ  tá»a Ä‘á»™ cá»§a nÃ³ em khÃ´ng lÃ m Ä‘Æ°á»£c áº¡. Nhá» má»i ngÆ°á»i xem giÃºp em áº¡, nhá»¯ng bÆ°á»›c em lÃ m Ä‘Ã£ Ä‘ugns chÆ°a áº¡, vÃ  cÃ¢u 2 lÃ m tháº¿ nÃ o áº¡. ÄÃ¢y lÃ  bÃ i kiá»ƒm tra cá»§a em, vÃ  Ä‘Æ°á»£c phÃ©p há»i ngÆ°á»i khÃ¡c áº¡. VÃ¬ chuyÃªn ngÃ nh cá»§a em lÃ  chuyÃªn ngÃ nh khÃ¡c nÃªn em khÃ¡c khÃ³ khÄƒn khi há»c vá» ML áº¡ Em xin cáº£m Æ¡n áº¡",,,,,
"[AI Share]
Pytorch lÃ  má»™t thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng cho Computer Vision vÃ  NLP.
TrÆ°á»›c Ä‘Ã¢y, Pytorch thÆ°á»ng chá»‰ Ä‘Æ°á»£c dÃ¹ng cho nghiÃªn cá»©u, nhÆ°ng gáº§n Ä‘Ã¢y Pytorch cÅ©ng phÃ¡t triá»ƒn Ä‘á»ƒ há»— trá»£ triá»ƒn khai sáº£n pháº©m.
Má»›i Ä‘Ã¢y, Facebook má»›i ra má»™t bÃ i viáº¿t vá» viá»‡c chuyá»ƒn táº¥t cáº£ cÃ¡c há»‡ thá»‘ng AI cá»§a há» sang Pytorch. Sau hÆ¡n 1 nÄƒm di chuyá»ƒn, cÃ³ hÆ¡n 1.700 mÃ´ hÃ¬nh dá»±a trÃªn Pytorch á»Ÿ Facebook vÃ  93% mÃ´ hÃ¬nh má»›i vá» phÃ¢n tÃ­ch ná»™i dung trÃªn Facebook cÅ©ng lÃ  Pytorch.
CÃ³ thá»ƒ tháº¥y Pytorch lÃ  má»™t trong nhá»¯ng Deep Learning framework tá»‘t nháº¥t hiá»‡n táº¡i, cho cáº£ lÃ m nghiÃªn cá»©u láº«n phÃ¡t triá»ƒn sáº£n pháº©m.
TÃ¬nh cá» tháº¥y repos hÆ°á»›ng dáº«n Pytorch hÆ¡n 20k sao trÃªn Github. Repos nÃ y dÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u há»c Pytorch. Háº§u háº¿t cÃ¡c file chá»‰ chá»©a Ã­t hÆ¡n 30 dÃ²ng code, Ä‘Æ¡n giáº£n vÃ  dá»… hiá»ƒu. CÃ³ cÃ¡c má»©c Ä‘á»™ Ä‘á»ƒ há»c Ä‘i tá»« dá»… Ä‘áº¿n khÃ³: CÆ¡ báº£n, Trung bÃ¬nh, NÃ¢ng cao.
Github: https://github.com/yunjey/pytorch-tutorial
NgoÃ i ra má»i ngÆ°á»i cÃ³ thá»ƒ theo dÃµi series vá» Pytorch báº±ng tiáº¿ng viá»‡t cá»§a mÃ¬nh Ä‘ang viáº¿t á»Ÿ Ä‘Ã¢y https://nttuan8.com/category/pytorch/
Äá»c thÃªm: https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/","[AI Share] Pytorch lÃ  má»™t thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng cho Computer Vision vÃ  NLP. TrÆ°á»›c Ä‘Ã¢y, Pytorch thÆ°á»ng chá»‰ Ä‘Æ°á»£c dÃ¹ng cho nghiÃªn cá»©u, nhÆ°ng gáº§n Ä‘Ã¢y Pytorch cÅ©ng phÃ¡t triá»ƒn Ä‘á»ƒ há»— trá»£ triá»ƒn khai sáº£n pháº©m. Má»›i Ä‘Ã¢y, Facebook má»›i ra má»™t bÃ i viáº¿t vá» viá»‡c chuyá»ƒn táº¥t cáº£ cÃ¡c há»‡ thá»‘ng AI cá»§a há» sang Pytorch. Sau hÆ¡n 1 nÄƒm di chuyá»ƒn, cÃ³ hÆ¡n 1.700 mÃ´ hÃ¬nh dá»±a trÃªn Pytorch á»Ÿ Facebook vÃ  93% mÃ´ hÃ¬nh má»›i vá» phÃ¢n tÃ­ch ná»™i dung trÃªn Facebook cÅ©ng lÃ  Pytorch. CÃ³ thá»ƒ tháº¥y Pytorch lÃ  má»™t trong nhá»¯ng Deep Learning framework tá»‘t nháº¥t hiá»‡n táº¡i, cho cáº£ lÃ m nghiÃªn cá»©u láº«n phÃ¡t triá»ƒn sáº£n pháº©m. TÃ¬nh cá» tháº¥y repos hÆ°á»›ng dáº«n Pytorch hÆ¡n 20k sao trÃªn Github. Repos nÃ y dÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u há»c Pytorch. Háº§u háº¿t cÃ¡c file chá»‰ chá»©a Ã­t hÆ¡n 30 dÃ²ng code, Ä‘Æ¡n giáº£n vÃ  dá»… hiá»ƒu. CÃ³ cÃ¡c má»©c Ä‘á»™ Ä‘á»ƒ há»c Ä‘i tá»« dá»… Ä‘áº¿n khÃ³: CÆ¡ báº£n, Trung bÃ¬nh, NÃ¢ng cao. Github: https://github.com/yunjey/pytorch-tutorial NgoÃ i ra má»i ngÆ°á»i cÃ³ thá»ƒ theo dÃµi series vá» Pytorch báº±ng tiáº¿ng viá»‡t cá»§a mÃ¬nh Ä‘ang viáº¿t á»Ÿ Ä‘Ã¢y https://nttuan8.com/category/pytorch/ Äá»c thÃªm: https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/",,,,,
"#sharing
KhÃ´ng biáº¿t cÃ³ báº¡n nÃ o Ä‘Ã£ share link khÃ³a há»c Machine Learning nÃ y cá»§a Stanford trÃªn Ä‘Ã¢y chÆ°a nhá»‰? Náº¿u cÃ³ thÃ¬ bá» qua post nÃ y nhÃ©. Stanford vá»«a cáº­p nháº­t má»›i kiáº¿n thá»©c khÃ³a há»c CS229 nÃ y vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ xem online cÅ©ng nhÆ° download táº¥t cáº£ cÃ¡c lecture notes.",KhÃ´ng biáº¿t cÃ³ báº¡n nÃ o Ä‘Ã£ share link khÃ³a há»c Machine Learning nÃ y cá»§a Stanford trÃªn Ä‘Ã¢y chÆ°a nhá»‰? Náº¿u cÃ³ thÃ¬ bá» qua post nÃ y nhÃ©. Stanford vá»«a cáº­p nháº­t má»›i kiáº¿n thá»©c khÃ³a há»c CS229 nÃ y vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ xem online cÅ©ng nhÆ° download táº¥t cáº£ cÃ¡c lecture notes.,#sharing,,,,
"Xin phÃ©p admin.
MÃ¬nh cÃ³ 1 dá»± Ã¡n cá»§a khÃ¡ch hÃ ng, yÃªu cáº§u Ä‘á»c file scan, lÃ  Ä‘Ã¡p Ã¡n thi tráº¯c nghiá»‡m nhÆ° hÃ¬nh dÆ°á»›i vÃ  trÃ­ch xuáº¥t thÃ´ng tin :
4 Ã´ vuÃ´ng dÃ¹ng Ä‘á»ƒ Ä‘á»‹nh vá»‹ tá» tráº¯c nghiá»‡m, khi scan cÃ³ thá»ƒ tá» tráº¯c nghiá»‡m sáº½ bá»‹ nghiÃªng so vá»›i áº£nh.
Sá»‘ bÃ¡o danh á»Ÿ gÃ³c trÃªn bÃªn pháº£i.
CÃ¡c Ä‘Ã¡p Ã¡n chá»‰ cÃ³ Ä‘Ãºng hoáº·c sai, trÆ°á»ng há»£p sai thÃ¬ há»c sinh sáº½ Ä‘Ã¡nh chá»¯ X vÃ o trong Ã´ vuÃ´ng. VÃ¬ cÃ¢u há»i cÃ³ thá»ƒ dÃ i hoáº·c ngáº¯n nÃªn Ä‘Ã¡p Ã¡n sáº½ náº±m ráº£i rÃ¡c trÃªn tá» Ä‘Ã¡p Ã¡n, khÃ´ng cÃ³ vá»‹ trÃ­ cá»‘ Ä‘á»‹nh (chá»‰ biáº¿t lÃ  sáº½ cÃ³ 2 cá»™t cÃ¡c cÃ¢u há»i).
MÃ¬nh cÅ©ng má»›i há»c AI, chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u, mong cÃ¡c báº¡n cho mÃ¬nh 1 vÃ i solutions hoáº·c tá»« khoÃ¡ Ä‘á»ƒ mÃ¬nh search vá»›i.
Thanks.","Xin phÃ©p admin. MÃ¬nh cÃ³ 1 dá»± Ã¡n cá»§a khÃ¡ch hÃ ng, yÃªu cáº§u Ä‘á»c file scan, lÃ  Ä‘Ã¡p Ã¡n thi tráº¯c nghiá»‡m nhÆ° hÃ¬nh dÆ°á»›i vÃ  trÃ­ch xuáº¥t thÃ´ng tin : 4 Ã´ vuÃ´ng dÃ¹ng Ä‘á»ƒ Ä‘á»‹nh vá»‹ tá» tráº¯c nghiá»‡m, khi scan cÃ³ thá»ƒ tá» tráº¯c nghiá»‡m sáº½ bá»‹ nghiÃªng so vá»›i áº£nh. Sá»‘ bÃ¡o danh á»Ÿ gÃ³c trÃªn bÃªn pháº£i. CÃ¡c Ä‘Ã¡p Ã¡n chá»‰ cÃ³ Ä‘Ãºng hoáº·c sai, trÆ°á»ng há»£p sai thÃ¬ há»c sinh sáº½ Ä‘Ã¡nh chá»¯ X vÃ o trong Ã´ vuÃ´ng. VÃ¬ cÃ¢u há»i cÃ³ thá»ƒ dÃ i hoáº·c ngáº¯n nÃªn Ä‘Ã¡p Ã¡n sáº½ náº±m ráº£i rÃ¡c trÃªn tá» Ä‘Ã¡p Ã¡n, khÃ´ng cÃ³ vá»‹ trÃ­ cá»‘ Ä‘á»‹nh (chá»‰ biáº¿t lÃ  sáº½ cÃ³ 2 cá»™t cÃ¡c cÃ¢u há»i). MÃ¬nh cÅ©ng má»›i há»c AI, chÆ°a biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u, mong cÃ¡c báº¡n cho mÃ¬nh 1 vÃ i solutions hoáº·c tá»« khoÃ¡ Ä‘á»ƒ mÃ¬nh search vá»›i. Thanks.",,,,,
"Xin chÃ o má»i ngÆ°á»i,
MÃ¬nh cÃ³ má»™t váº¥n Ä‘á» muá»‘n tháº£o luáº­n Ä‘á»ƒ tiáº¿p thu thÃªm cÃ¡c gÃ³c nhÃ¬n khÃ¡c nhau.
BÃ i toÃ¡n cá»§a mÃ¬nh lÃ  so sÃ¡nh sá»± giá»‘ng nhau trÃªn máº·t Ã½ nghÄ©a cá»§a hai vÄƒn báº£n, Ã½ nghÄ©a á»Ÿ Ä‘Ã¢y lÃ  má»™t khÃ¡i niá»‡m rá»™ng. NÃ³ cÃ³ thá»ƒ lÃ  hai vÄƒn báº£n nÃ³i cÃ¹ng vá» má»™t chá»§ Ä‘á», hoáº·c chia sáº» nhá»¯ng Ã½ tÆ°á»Ÿng giá»‘ng nhau.
Váº¥n Ä‘á» nÃ y mÃ¬nh nháº­n tháº¥y sau má»™t thá»i gian ngá»™ nháº­n ráº±ng cá»© viá»‡c dÃ¹ng Sentence-BERT lÃ  tá»‘t nháº¥t rá»“i. LÃ½ do mÃ¬nh nháº­n ra lÃ  vÃ¬ khi Ä‘á»ƒ Ã½ ká»¹ hÆ¡n cÃ¡i vÄƒn báº£n mÃ¬nh tÃ¬m ra lÃ  giá»‘ng nháº¥t, á»Ÿ nhá»¯ng Ä‘oáº¡n giá»¯a hoáº·c káº¿t bÃ i thÃ¬ nÃ³ cháº£ cÃ²n liÃªn quan gÃ¬ Ä‘áº¿n vÄƒn báº£n tÃ¬m kiáº¿m. VÃ  nguyÃªn nhÃ¢n lÃ  vÃ¬ Sentence-BERT hoáº·c BERT chá»‰ nháº­n vÃ o 512 tokens, nghÄ©a lÃ  pháº§n Ä‘áº§u vÄƒn báº£n.
Váº­y cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘á»ƒ táº¡o embedding vector á»Ÿ cáº¥p vÄƒn báº£n khÃ´ng?
Sau khi tÃ¬m kiáº¿m mÃ¬nh tháº¥y cÃ³ Ã­t nháº¥t lÃ  2 hÆ°á»›ng chÃ­nh sau
1. Trung bÃ¬nh cá»™ng cÃ¡c embedding vectors á»Ÿ cáº¥p nhá» hÆ¡n, vÃ­ dá»¥ word-level hay sentence-level. MÃ¬nh Ä‘Ã£ thÃ­ nghiá»‡m vÃ  thÃº vá»‹ lÃ  káº¿t quáº£ tá»‡ hÆ¡n viá»‡c dÃ¹ng trá»±c tiáº¿p Sentence-BERT.
2. Váº«n lÃ  trung bÃ¬nh cá»™ng, nhÆ°ng trong quÃ¡ trÃ¬nh nÃ y sáº½ cÃ³ sá»± tham gia cá»§a má»™t training task khÃ¡c Ä‘á»ƒ Ä‘áº£m báº£o viá»‡c tá»•ng há»£p cÃ¡c vectors láº¡i cÃ³ thá»ƒ Ä‘áº¡i diá»‡n cho má»™t vÄƒn báº£n. VÃ­ dá»¥, Doc2VecC [1], hoáº·c dÃ¹ng GLU Covolution blocks [2], hoáº·c má»™t nghiÃªn cá»©u ráº¥t má»›i cá»§a Google á»Ÿ Ä‘Ã¢y [3].
CÃ¢u há»i tháº£o luáº­n cá»§a mÃ¬nh lÃ :
1. LÃ½ giáº£i khoa há»c nÃ o cÃ³ thá»ƒ giáº£i thÃ­ch viá»‡c trung bÃ¬nh cá»™ng Ä‘Æ¡n thuáº§n cÃ¡c embedding vectors cá»§a cáº¥p nhá» hÆ¡n khÃ´ng thá»ƒ Ä‘áº¡i diá»‡n cho má»™t vÄƒn báº£n Ä‘Æ°á»£c.
2. MÃ¬nh khÃ´ng tÃ¬m tháº¥y má»™t mÃ´ hÃ¬nh nÃ o Ä‘Ã£ Ä‘Æ°á»£c trained vÃ  published theo hÆ°á»›ng 2 dá»±a trÃªn BERT hoáº·c Transformer-based model nÃ³i chung. Báº¡n nÃ o cÃ³ thÃ´ng tin thÃ¬ chia sáº» vá»›i mÃ¬nh nhÃ©.
3. Náº¿u cÃ³ giáº£i phÃ¡p nÃ o khÃ¡c ngoÃ i 2 hÆ°á»›ng mÃ¬nh Ä‘á» cáº­p thÃ¬ cÅ©ng xin má»i ngÆ°á»i chia sáº».
[1] https://arxiv.org/pdf/1707.02377.pdf
[2] https://arxiv.org/pdf/1711.04168.pdf
[3] https://arxiv.org/pdf/2004.12297.pdf","Xin chÃ o má»i ngÆ°á»i, MÃ¬nh cÃ³ má»™t váº¥n Ä‘á» muá»‘n tháº£o luáº­n Ä‘á»ƒ tiáº¿p thu thÃªm cÃ¡c gÃ³c nhÃ¬n khÃ¡c nhau. BÃ i toÃ¡n cá»§a mÃ¬nh lÃ  so sÃ¡nh sá»± giá»‘ng nhau trÃªn máº·t Ã½ nghÄ©a cá»§a hai vÄƒn báº£n, Ã½ nghÄ©a á»Ÿ Ä‘Ã¢y lÃ  má»™t khÃ¡i niá»‡m rá»™ng. NÃ³ cÃ³ thá»ƒ lÃ  hai vÄƒn báº£n nÃ³i cÃ¹ng vá» má»™t chá»§ Ä‘á», hoáº·c chia sáº» nhá»¯ng Ã½ tÆ°á»Ÿng giá»‘ng nhau. Váº¥n Ä‘á» nÃ y mÃ¬nh nháº­n tháº¥y sau má»™t thá»i gian ngá»™ nháº­n ráº±ng cá»© viá»‡c dÃ¹ng Sentence-BERT lÃ  tá»‘t nháº¥t rá»“i. LÃ½ do mÃ¬nh nháº­n ra lÃ  vÃ¬ khi Ä‘á»ƒ Ã½ ká»¹ hÆ¡n cÃ¡i vÄƒn báº£n mÃ¬nh tÃ¬m ra lÃ  giá»‘ng nháº¥t, á»Ÿ nhá»¯ng Ä‘oáº¡n giá»¯a hoáº·c káº¿t bÃ i thÃ¬ nÃ³ cháº£ cÃ²n liÃªn quan gÃ¬ Ä‘áº¿n vÄƒn báº£n tÃ¬m kiáº¿m. VÃ  nguyÃªn nhÃ¢n lÃ  vÃ¬ Sentence-BERT hoáº·c BERT chá»‰ nháº­n vÃ o 512 tokens, nghÄ©a lÃ  pháº§n Ä‘áº§u vÄƒn báº£n. Váº­y cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘á»ƒ táº¡o embedding vector á»Ÿ cáº¥p vÄƒn báº£n khÃ´ng? Sau khi tÃ¬m kiáº¿m mÃ¬nh tháº¥y cÃ³ Ã­t nháº¥t lÃ  2 hÆ°á»›ng chÃ­nh sau 1. Trung bÃ¬nh cá»™ng cÃ¡c embedding vectors á»Ÿ cáº¥p nhá» hÆ¡n, vÃ­ dá»¥ word-level hay sentence-level. MÃ¬nh Ä‘Ã£ thÃ­ nghiá»‡m vÃ  thÃº vá»‹ lÃ  káº¿t quáº£ tá»‡ hÆ¡n viá»‡c dÃ¹ng trá»±c tiáº¿p Sentence-BERT. 2. Váº«n lÃ  trung bÃ¬nh cá»™ng, nhÆ°ng trong quÃ¡ trÃ¬nh nÃ y sáº½ cÃ³ sá»± tham gia cá»§a má»™t training task khÃ¡c Ä‘á»ƒ Ä‘áº£m báº£o viá»‡c tá»•ng há»£p cÃ¡c vectors láº¡i cÃ³ thá»ƒ Ä‘áº¡i diá»‡n cho má»™t vÄƒn báº£n. VÃ­ dá»¥, Doc2VecC [1], hoáº·c dÃ¹ng GLU Covolution blocks [2], hoáº·c má»™t nghiÃªn cá»©u ráº¥t má»›i cá»§a Google á»Ÿ Ä‘Ã¢y [3]. CÃ¢u há»i tháº£o luáº­n cá»§a mÃ¬nh lÃ : 1. LÃ½ giáº£i khoa há»c nÃ o cÃ³ thá»ƒ giáº£i thÃ­ch viá»‡c trung bÃ¬nh cá»™ng Ä‘Æ¡n thuáº§n cÃ¡c embedding vectors cá»§a cáº¥p nhá» hÆ¡n khÃ´ng thá»ƒ Ä‘áº¡i diá»‡n cho má»™t vÄƒn báº£n Ä‘Æ°á»£c. 2. MÃ¬nh khÃ´ng tÃ¬m tháº¥y má»™t mÃ´ hÃ¬nh nÃ o Ä‘Ã£ Ä‘Æ°á»£c trained vÃ  published theo hÆ°á»›ng 2 dá»±a trÃªn BERT hoáº·c Transformer-based model nÃ³i chung. Báº¡n nÃ o cÃ³ thÃ´ng tin thÃ¬ chia sáº» vá»›i mÃ¬nh nhÃ©. 3. Náº¿u cÃ³ giáº£i phÃ¡p nÃ o khÃ¡c ngoÃ i 2 hÆ°á»›ng mÃ¬nh Ä‘á» cáº­p thÃ¬ cÅ©ng xin má»i ngÆ°á»i chia sáº». [1] https://arxiv.org/pdf/1707.02377.pdf [2] https://arxiv.org/pdf/1711.04168.pdf [3] https://arxiv.org/pdf/2004.12297.pdf",,,,,
"xin phÃ©p Admin
MÃ¬nh Ä‘ang muá»‘n láº­p team nghiÃªn cá»©u vÃ  lÃ m chá»§ cÃ´ng nghá»‡ nháº­n dáº¡ng giá»ng nÃ³i, ae nÃ o Ä‘ang nghiÃªn cá»©u vÃ  cÃ³ kiáº¿n thá»©c vá» pháº§n nÃ y rá»“i cÃ³ thá»ƒ thÃ¬ cÃ¹ng nhau nghiÃªn cá»©u cho ra ngÃ´ ra khoai nhÃ© ae. Inbox cho mÃ¬nh náº¿u báº¡n nÃ o muá»‘n tham gia NC hoáº·c cÃ³ team rá»“i thÃ¬ cho mk tham gia cÃ¹ng nhÃ©, cáº£m Æ¡n mn.","xin phÃ©p Admin MÃ¬nh Ä‘ang muá»‘n láº­p team nghiÃªn cá»©u vÃ  lÃ m chá»§ cÃ´ng nghá»‡ nháº­n dáº¡ng giá»ng nÃ³i, ae nÃ o Ä‘ang nghiÃªn cá»©u vÃ  cÃ³ kiáº¿n thá»©c vá» pháº§n nÃ y rá»“i cÃ³ thá»ƒ thÃ¬ cÃ¹ng nhau nghiÃªn cá»©u cho ra ngÃ´ ra khoai nhÃ© ae. Inbox cho mÃ¬nh náº¿u báº¡n nÃ o muá»‘n tham gia NC hoáº·c cÃ³ team rá»“i thÃ¬ cho mk tham gia cÃ¹ng nhÃ©, cáº£m Æ¡n mn.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡ !
Em láº§n Ä‘áº§u Ä‘Æ°á»£c biáº¿t Ä‘áº¿n AI áº¡
Em muá»‘n há»i má»i ngÆ°á»i nhÆ° tháº¿ nÃ y áº¡ :
- Dá»¯ liá»‡u cá»§a em lÃ  : input : 13 x 205 , target lÃ  5 x 205
Em cÃ³ thá»ƒ dá»± Ä‘oÃ¡n output báº±ng linear regression ko áº¡ ?
VÃ  em cÃ³ thá»ƒ chia target ra tá»«ng 5 cÃ¡i riÃªng láº» Ä‘á»ƒ dá»± Ä‘oÃ¡n ko áº¡
VÃ  anh chá»‹ cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em cÃ¡ch váº½ 2 biá»ƒu Ä‘á»“ nÃ y ko áº¡ ?
Em cáº£m Æ¡n nhiá»u áº¡","Em chÃ o má»i ngÆ°á»i áº¡ ! Em láº§n Ä‘áº§u Ä‘Æ°á»£c biáº¿t Ä‘áº¿n AI áº¡ Em muá»‘n há»i má»i ngÆ°á»i nhÆ° tháº¿ nÃ y áº¡ : - Dá»¯ liá»‡u cá»§a em lÃ  : input : 13 x 205 , target lÃ  5 x 205 Em cÃ³ thá»ƒ dá»± Ä‘oÃ¡n output báº±ng linear regression ko áº¡ ? VÃ  em cÃ³ thá»ƒ chia target ra tá»«ng 5 cÃ¡i riÃªng láº» Ä‘á»ƒ dá»± Ä‘oÃ¡n ko áº¡ VÃ  anh chá»‹ cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em cÃ¡ch váº½ 2 biá»ƒu Ä‘á»“ nÃ y ko áº¡ ? Em cáº£m Æ¡n nhiá»u áº¡",,,,,
"Má»™t báº¡n nhá» Ä‘Äƒng há»™. MÃ¬nh chÆ°a download vá» xem nÃªn khÃ´ng chá»‹u trÃ¡ch nhiá»‡m vá» ná»™i dung nhÃ© :).
""Ad Æ¡i, Udacity cÃ³ chÆ°Æ¡ng trÃ¬nh Machine Learning Nanodegree. Video bÃ i giáº£ng thÃ¬ Ä‘á»u cÃ³ trÃªn youtube nhÆ°ng ko cÃ³ playlist. Em Ä‘Ã£ tá»•ng há»£p táº¥t cáº£ video theo chá»§ Ä‘á» Ä‘c dáº¡y, Ä‘áº£m báº£o Ä‘Ãºng 100% vÃ¬ e Ä‘Ã£ enroll khoÃ¡ nÃ y. E muá»‘n share vÃ o group nhÆ°ng ko muá»‘n lá»™ tÃªn áº¡ :)) cÃ³ gÃ¬ ad share giÃºp e vá»›i. Bá»™ video nÃ y cÃ³ váº» ""legal"" vÃ¬ dÃ¹ sao táº¥t cáº£ video Ä‘á»u náº±m trÃªn youtube Ã½. CÃ³ gÃ¬ ad xem xÃ©t rá»“i up há»™ e náº¿u cÃ³ thá»ƒ áº¡.""","Má»™t báº¡n nhá» Ä‘Äƒng há»™. MÃ¬nh chÆ°a download vá» xem nÃªn khÃ´ng chá»‹u trÃ¡ch nhiá»‡m vá» ná»™i dung nhÃ© :). ""Ad Æ¡i, Udacity cÃ³ chÆ°Æ¡ng trÃ¬nh Machine Learning Nanodegree. Video bÃ i giáº£ng thÃ¬ Ä‘á»u cÃ³ trÃªn youtube nhÆ°ng ko cÃ³ playlist. Em Ä‘Ã£ tá»•ng há»£p táº¥t cáº£ video theo chá»§ Ä‘á» Ä‘c dáº¡y, Ä‘áº£m báº£o Ä‘Ãºng 100% vÃ¬ e Ä‘Ã£ enroll khoÃ¡ nÃ y. E muá»‘n share vÃ o group nhÆ°ng ko muá»‘n lá»™ tÃªn áº¡ :)) cÃ³ gÃ¬ ad share giÃºp e vá»›i. Bá»™ video nÃ y cÃ³ váº» ""legal"" vÃ¬ dÃ¹ sao táº¥t cáº£ video Ä‘á»u náº±m trÃªn youtube Ã½. CÃ³ gÃ¬ ad xem xÃ©t rá»“i up há»™ e náº¿u cÃ³ thá»ƒ áº¡.""",,,,,
"#Question
Nhá» mn chá»‰ giÃºp mÃ¬nh hÆ°á»›ng Ä‘i cho cÃ¡ch kiá»ƒm tra áº£nh trÃ¹ng vá»›i.
MÃ¬nh cÃ³ file áº£nh cáº§n so sÃ¡nh bÃªn pháº£i do khÃ¡ch chá»¥p, Ä‘Ã´i khi áº£nh bá»‹ crop, bá»‹ thá»«a hoáº·c khÃ¡ch dÃ¹ng Ä‘t chá»¥p láº¡i mÃ n mÃ¡y tÃ­nh. Trong khi áº£nh gá»‘c bÃªn trÃ¡i.
Má»¥c Ä‘Ã­ch lÃ  khi khÃ¡ch gá»­i hÃ¬nh sang thÃ¬ tráº£ vá» nÃ³ tÆ°Æ¡ng tá»± áº£nh nÃ o trong library.
CÃ¡m Æ¡n cÃ¡c bÃ¡c.","Nhá» mn chá»‰ giÃºp mÃ¬nh hÆ°á»›ng Ä‘i cho cÃ¡ch kiá»ƒm tra áº£nh trÃ¹ng vá»›i. MÃ¬nh cÃ³ file áº£nh cáº§n so sÃ¡nh bÃªn pháº£i do khÃ¡ch chá»¥p, Ä‘Ã´i khi áº£nh bá»‹ crop, bá»‹ thá»«a hoáº·c khÃ¡ch dÃ¹ng Ä‘t chá»¥p láº¡i mÃ n mÃ¡y tÃ­nh. Trong khi áº£nh gá»‘c bÃªn trÃ¡i. Má»¥c Ä‘Ã­ch lÃ  khi khÃ¡ch gá»­i hÃ¬nh sang thÃ¬ tráº£ vá» nÃ³ tÆ°Æ¡ng tá»± áº£nh nÃ o trong library. CÃ¡m Æ¡n cÃ¡c bÃ¡c.",#Question,,,,
,nan,,,,,
"Hello má»i ngÆ°á»i, em Ä‘ang cÃ³ má»™t chÃºt tháº¯c máº¯c vá» neural network Ä‘Ã³ lÃ : trong bÃ i toÃ¡n binary classification thÃ¬ mÃ¬nh cÃ³ thá»ƒ dÃ¹ng 1 output hoáº·c 2 output Ä‘Ãºng ko áº¡?, 2 cÃ¡ch trÃªn sáº½ khÃ¡c nhau ntn?. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em 1 sá»‘ key-words vá» váº¥n Ä‘á» nÃ y Ä‘á»ƒ search dc ko áº¡, em Ä‘Ã£ thá»­ search nhÆ°ng tiáº¿c lÃ  káº¿t quáº£ nháº­n vá» chÆ°a dc mong muá»‘n láº¯m :((
Thank má»i ngÆ°á»i nhiá»u áº¡!!!
#ML #DL #NN","Hello má»i ngÆ°á»i, em Ä‘ang cÃ³ má»™t chÃºt tháº¯c máº¯c vá» neural network Ä‘Ã³ lÃ : trong bÃ i toÃ¡n binary classification thÃ¬ mÃ¬nh cÃ³ thá»ƒ dÃ¹ng 1 output hoáº·c 2 output Ä‘Ãºng ko áº¡?, 2 cÃ¡ch trÃªn sáº½ khÃ¡c nhau ntn?. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em 1 sá»‘ key-words vá» váº¥n Ä‘á» nÃ y Ä‘á»ƒ search dc ko áº¡, em Ä‘Ã£ thá»­ search nhÆ°ng tiáº¿c lÃ  káº¿t quáº£ nháº­n vá» chÆ°a dc mong muá»‘n láº¯m :(( Thank má»i ngÆ°á»i nhiá»u áº¡!!!",#ML	#DL	#NN,,,,
"Má»i ngÆ°á»i cho em há»i, cÃ³ cÃ¡ch nÃ o tÃ¬m Ä‘Æ°á»£c thÃ´ng tin cÃ¡c nhÃ  mÃ¡y/ cÃ´ng ty cÃ³ lÆ°á»£ng tiÃªu thá»¥ Ä‘iá»‡n cao khÃ´ng áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin!","Má»i ngÆ°á»i cho em há»i, cÃ³ cÃ¡ch nÃ o tÃ¬m Ä‘Æ°á»£c thÃ´ng tin cÃ¡c nhÃ  mÃ¡y/ cÃ´ng ty cÃ³ lÆ°á»£ng tiÃªu thá»¥ Ä‘iá»‡n cao khÃ´ng áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin!",,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i ngoÃ i sá»­ dá»¥ng CLAHE Ä‘á»ƒ equalize histogram cá»§a áº£nh thÃ¬ má»i ngÆ°á»i cÃ²n dÃ¹ng cÃ¡i gÃ¬ ná»¯a khÃ´ng nhá»‰, em chÆ°a biáº¿t pháº£i preprocess áº£nh ntn ná»¯a táº¡i dataset cá»§a em Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng ráº¥t khÃ¡c nhau","Má»i ngÆ°á»i Æ¡i cho em há»i ngoÃ i sá»­ dá»¥ng CLAHE Ä‘á»ƒ equalize histogram cá»§a áº£nh thÃ¬ má»i ngÆ°á»i cÃ²n dÃ¹ng cÃ¡i gÃ¬ ná»¯a khÃ´ng nhá»‰, em chÆ°a biáº¿t pháº£i preprocess áº£nh ntn ná»¯a táº¡i dataset cá»§a em Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng ráº¥t khÃ¡c nhau",,,,,
Xin phÃ©p chia sáº» cÃ¹ng má»i ngÆ°á»i bÃ i giáº£ng vá» á»¨ng dá»¥ng cá»§a AI vÃ  Data Science trong giáº£i mÃ£ gen áº¡.,Xin phÃ©p chia sáº» cÃ¹ng má»i ngÆ°á»i bÃ i giáº£ng vá» á»¨ng dá»¥ng cá»§a AI vÃ  Data Science trong giáº£i mÃ£ gen áº¡.,,,,,
"ChÃ o má»i ngÆ°á»i mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n nhÆ° tháº¿ nÃ y
Äáº§u vÃ o lÃ  nhá»¯ng táº¥m áº£nh lá»›n khoang 10.000 x 1024,
Cáº§n kiá»ƒm tra bá»™ pháº­n bÃªn trong cÃ³ bá»‹ hÆ° khÃ´ng kÃ­ch thÆ°á»›c khoang 300 x 200ï¿¼
MÃ¬nh Ä‘Ã£ thá»­ vá»›i yolo5, detectron, káº¿t quáº£ dÆ°á»›i nÄƒm mÆ°Æ¡i pháº§n trÄƒmï¿¼ lÃ  Ä‘Ãºng.
Xin há»i trong trÆ°á»ng há»£p nÃ y má»i ngÆ°á»i sáº½ lÃ m gÃ¬ï¿¼? Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u
ï¿¼","ChÃ o má»i ngÆ°á»i mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n nhÆ° tháº¿ nÃ y Äáº§u vÃ o lÃ  nhá»¯ng táº¥m áº£nh lá»›n khoang 10.000 x 1024, Cáº§n kiá»ƒm tra bá»™ pháº­n bÃªn trong cÃ³ bá»‹ hÆ° khÃ´ng kÃ­ch thÆ°á»›c khoang 300 x 200 MÃ¬nh Ä‘Ã£ thá»­ vá»›i yolo5, detectron, káº¿t quáº£ dÆ°á»›i nÄƒm mÆ°Æ¡i pháº§n trÄƒm lÃ  Ä‘Ãºng. Xin há»i trong trÆ°á»ng há»£p nÃ y má»i ngÆ°á»i sáº½ lÃ m gÃ¬? Cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u",,,,,
"[ACNE SCAN - á»¨NG Dá»¤NG DI Äá»˜NG CHÄ‚M SÃ“C DA ÃP Dá»¤NG AI Äáº¦U TIÃŠN Táº I VIá»†T NAM .... CÃ“ MÃ€U Há»’NG.]
ChÃ o má»i ngÆ°á»i,
ChÃºng mÃ¬nh lÃ  TNT Team - sinh viÃªn nÄƒm 4 ngÃ nh Khoa há»c MÃ¡y tÃ­nh vÃ  tá»¥i mÃ¬nh muá»‘n giá»›i thiá»‡u Ä‘áº¿n má»i ngÆ°á»i á»©ng dá»¥ng Ä‘iá»‡n thoáº¡i ACNE SCAN Ã¡p dá»¥ng cÃ´ng nghá»‡ TrÃ­ tuá»‡ nhÃ¢n táº¡o giÃºp báº¡n:
ÄÃ¡nh giÃ¡ tÃ¬nh tráº¡ng da máº·t trÃªn thang 4 má»©c Ä‘á»™ thÃ´ng qua cÃ¡c loáº¡i má»¥n gáº·p pháº£i.
Gá»£i Ã½ sáº£n pháº©m chÄƒm sÃ³c da theo Ä‘á»™ yÃªu thÃ­ch ngÆ°á»i dÃ¹ng trong há»‡ thá»‘ng.
Gá»£i Ã½ lá»™ trÃ¬nh chÄƒm sÃ³c da
Theo dÃµi tÃ¬nh tráº¡ng da máº·t qua Nháº­t kÃ½ da máº·t
BÃ¡o thá»©c viá»‡c sá»­ dá»¥ng sáº£n pháº©m chÄƒm sÃ³c da
Äá»ƒ cÃ³ thá»ƒ táº£i á»©ng dá»¥ng vÃ  tráº£i nghiá»‡m:
Báº¡n vÃ o CH play vÃ  tÃ¬m kiáº¿m tá»« khÃ³a Acne Scan hoáº·c nháº¥n vÃ o Ä‘Æ°á»ng link: https://play.google.com/store/apps/details?id=tntteam.detectacne
Thá»±c hiá»‡n viá»‡c táº£i á»©ng dá»¥ng Acne Scan vÃ o mÃ¡y
ÄÄƒng kÃ½ tÃ i khoáº£n vÃ  báº¯t Ä‘áº§u tráº£i nghiá»‡m á»©ng dá»¥ng
ChÃºng mÃ¬nh tin ráº±ng á»©ng dá»¥ng sáº½ giÃºp viá»‡c chÄƒm sÃ³c da trá»Ÿ nÃªn dá»… dÃ ng vÃ  tiá»‡n lá»£i hÆ¡n ngay táº¡i nhÃ . Sáº£n pháº©m nÃ y cÅ©ng chÃ­nh lÃ  luáº­n vÄƒn tá»‘t nghiá»‡p cá»§a nhÃ³m mÃ¬nh, hÃ¬nh cá»§a cÃ¡c báº¡n Ä‘Æ°á»£c lÆ°u trá»¯ báº£o máº­t chá»‰ nháº±m má»¥c Ä‘Ã­ch cáº£i thiá»‡n model chá»© khÃ´ng nháº±m má»¥c Ä‘Ã­ch thÆ°Æ¡ng máº¡i.
LÃ  má»™t trong nhá»¯ng group cÃ³ tiáº¿ng vá» AI/á»¨ng dá»¥ng Ä‘iá»‡n thoáº¡i/CÃ´ng nghá»‡, mÃ¬nh hy vá»ng cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘Ã³ng gÃ³p Ã½ kiáº¿n vá» Ä‘á»™ chÃ­nh xÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i má»¥n hay gá»£i Ã½ sáº£n pháº©m cá»§a nhÃ³m/cÃ¡c tÃ­nh nÄƒng sáº£n pháº©m. Má»i Ã½ kiáº¿n Ä‘Ã³ng gÃ³p cá»§a cÃ¡c báº¡n sáº½ gÃ³p pháº§n hoÃ n thiá»‡n sáº£n pháº©m hÆ¡n áº¡.
Hiá»‡n táº¡i á»©ng dá»¥ng Ä‘ang cÃ³ máº·t trÃªn CH play dÃ nh cho cÃ¡c thiáº¿t bá»‹ Android vá»›i phiÃªn báº£n 2.1.0. 
Äá»ƒ gÃ³p Ã½ cho tá»¥i mÃ¬nh sau khi sá»­ dá»¥ng á»©ng dá»¥ng, báº¡n cÃ³ thá»ƒ Ä‘iá»n form kháº£o sÃ¡t bÃªn dÆ°á»›i:
https://tinyurl.com/feedback-tntacnescan
Trong quÃ¡ trÃ¬nh sá»­ dá»¥ng á»©ng dá»¥ng, náº¿u báº¡n gáº·p báº¥t cá»© váº¥n Ä‘á» gÃ¬, báº¡n cÃ³ thá»ƒ inbox mÃ¬nh qua facebook cÃ¡ nhÃ¢n hoáº·c gá»­i mail vÃ o há»™p thÆ° tntteam.hcmut@gmail.com.
ChÃºng mÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n vÃ  hy vá»ng nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ cá»§a má»i ngÆ°á»i <3","[ACNE SCAN - á»¨NG Dá»¤NG DI Äá»˜NG CHÄ‚M SÃ“C DA ÃP Dá»¤NG AI Äáº¦U TIÃŠN Táº I VIá»†T NAM .... CÃ“ MÃ€U Há»’NG.] ChÃ o má»i ngÆ°á»i, ChÃºng mÃ¬nh lÃ  TNT Team - sinh viÃªn nÄƒm 4 ngÃ nh Khoa há»c MÃ¡y tÃ­nh vÃ  tá»¥i mÃ¬nh muá»‘n giá»›i thiá»‡u Ä‘áº¿n má»i ngÆ°á»i á»©ng dá»¥ng Ä‘iá»‡n thoáº¡i ACNE SCAN Ã¡p dá»¥ng cÃ´ng nghá»‡ TrÃ­ tuá»‡ nhÃ¢n táº¡o giÃºp báº¡n: ÄÃ¡nh giÃ¡ tÃ¬nh tráº¡ng da máº·t trÃªn thang 4 má»©c Ä‘á»™ thÃ´ng qua cÃ¡c loáº¡i má»¥n gáº·p pháº£i. Gá»£i Ã½ sáº£n pháº©m chÄƒm sÃ³c da theo Ä‘á»™ yÃªu thÃ­ch ngÆ°á»i dÃ¹ng trong há»‡ thá»‘ng. Gá»£i Ã½ lá»™ trÃ¬nh chÄƒm sÃ³c da Theo dÃµi tÃ¬nh tráº¡ng da máº·t qua Nháº­t kÃ½ da máº·t BÃ¡o thá»©c viá»‡c sá»­ dá»¥ng sáº£n pháº©m chÄƒm sÃ³c da Äá»ƒ cÃ³ thá»ƒ táº£i á»©ng dá»¥ng vÃ  tráº£i nghiá»‡m: Báº¡n vÃ o CH play vÃ  tÃ¬m kiáº¿m tá»« khÃ³a Acne Scan hoáº·c nháº¥n vÃ o Ä‘Æ°á»ng link: https://play.google.com/store/apps/details?id=tntteam.detectacne Thá»±c hiá»‡n viá»‡c táº£i á»©ng dá»¥ng Acne Scan vÃ o mÃ¡y ÄÄƒng kÃ½ tÃ i khoáº£n vÃ  báº¯t Ä‘áº§u tráº£i nghiá»‡m á»©ng dá»¥ng ChÃºng mÃ¬nh tin ráº±ng á»©ng dá»¥ng sáº½ giÃºp viá»‡c chÄƒm sÃ³c da trá»Ÿ nÃªn dá»… dÃ ng vÃ  tiá»‡n lá»£i hÆ¡n ngay táº¡i nhÃ . Sáº£n pháº©m nÃ y cÅ©ng chÃ­nh lÃ  luáº­n vÄƒn tá»‘t nghiá»‡p cá»§a nhÃ³m mÃ¬nh, hÃ¬nh cá»§a cÃ¡c báº¡n Ä‘Æ°á»£c lÆ°u trá»¯ báº£o máº­t chá»‰ nháº±m má»¥c Ä‘Ã­ch cáº£i thiá»‡n model chá»© khÃ´ng nháº±m má»¥c Ä‘Ã­ch thÆ°Æ¡ng máº¡i. LÃ  má»™t trong nhá»¯ng group cÃ³ tiáº¿ng vá» AI/á»¨ng dá»¥ng Ä‘iá»‡n thoáº¡i/CÃ´ng nghá»‡, mÃ¬nh hy vá»ng cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘Ã³ng gÃ³p Ã½ kiáº¿n vá» Ä‘á»™ chÃ­nh xÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i má»¥n hay gá»£i Ã½ sáº£n pháº©m cá»§a nhÃ³m/cÃ¡c tÃ­nh nÄƒng sáº£n pháº©m. Má»i Ã½ kiáº¿n Ä‘Ã³ng gÃ³p cá»§a cÃ¡c báº¡n sáº½ gÃ³p pháº§n hoÃ n thiá»‡n sáº£n pháº©m hÆ¡n áº¡. Hiá»‡n táº¡i á»©ng dá»¥ng Ä‘ang cÃ³ máº·t trÃªn CH play dÃ nh cho cÃ¡c thiáº¿t bá»‹ Android vá»›i phiÃªn báº£n 2.1.0. Äá»ƒ gÃ³p Ã½ cho tá»¥i mÃ¬nh sau khi sá»­ dá»¥ng á»©ng dá»¥ng, báº¡n cÃ³ thá»ƒ Ä‘iá»n form kháº£o sÃ¡t bÃªn dÆ°á»›i: https://tinyurl.com/feedback-tntacnescan Trong quÃ¡ trÃ¬nh sá»­ dá»¥ng á»©ng dá»¥ng, náº¿u báº¡n gáº·p báº¥t cá»© váº¥n Ä‘á» gÃ¬, báº¡n cÃ³ thá»ƒ inbox mÃ¬nh qua facebook cÃ¡ nhÃ¢n hoáº·c gá»­i mail vÃ o há»™p thÆ° tntteam.hcmut@gmail.com. ChÃºng mÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n vÃ  hy vá»ng nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ cá»§a má»i ngÆ°á»i <3",,,,,
"MÃ¬nh xin Ä‘Æ°á»£c chia sáº» vá»›i má»i ngÆ°á»i trong nhÃ³m vá» chÆ°Æ¡ng trÃ¬nh Æ°Æ¡m táº¡o Lab2Market. ÄÃ¢y lÃ  1 chÆ°Æ¡ng trÃ¬nh há»¯u Ã­ch, Ä‘á»“ng hÃ nh vÃ  há»— trá»£ cÃ¡c nhÃ³m nghiÃªn cá»©u, sÃ¡ng cháº¿ cÃ´ng nghá»‡ cÃ³ thá»ƒ hoÃ n thiá»‡n, Ä‘Æ°a sáº£n pháº©m phÃ¡t minh cá»§a mÃ¬nh ra thá»‹ trÆ°á»ng.
VÃ o lÃºc 15h thá»© 6 hÃ ng tuáº§n, Lab2Market cÃ³ tá»• chá»©c buá»•i Ä‘á»‘i thoáº¡i trá»±c tuyáº¿n trÃªn facebook nháº±m giáº£i Ä‘Ã¡p tháº¯c máº¯c tháº¯c máº¯c vá» chÆ°Æ¡ng trÃ¬nh. Tham gia vÃ o sá»± kiá»‡n, má»i ngÆ°á»i sáº½ cÃ³ cÆ¡ há»™i tÆ°Æ¡ng tÃ¡c cÃ¹ng nhá»¯ng vá»‹ mentor dÃ y dáº¡n kinh nghiá»‡m trÃªn Ä‘a lÄ©nh vá»±c vÃ  láº¯ng nghe nhá»¯ng chia sáº» kinh nghiá»‡m qÃºy bÃ¡u cá»§a há». ğŸŒŸğŸŒŸ","MÃ¬nh xin Ä‘Æ°á»£c chia sáº» vá»›i má»i ngÆ°á»i trong nhÃ³m vá» chÆ°Æ¡ng trÃ¬nh Æ°Æ¡m táº¡o Lab2Market. ÄÃ¢y lÃ  1 chÆ°Æ¡ng trÃ¬nh há»¯u Ã­ch, Ä‘á»“ng hÃ nh vÃ  há»— trá»£ cÃ¡c nhÃ³m nghiÃªn cá»©u, sÃ¡ng cháº¿ cÃ´ng nghá»‡ cÃ³ thá»ƒ hoÃ n thiá»‡n, Ä‘Æ°a sáº£n pháº©m phÃ¡t minh cá»§a mÃ¬nh ra thá»‹ trÆ°á»ng. VÃ o lÃºc 15h thá»© 6 hÃ ng tuáº§n, Lab2Market cÃ³ tá»• chá»©c buá»•i Ä‘á»‘i thoáº¡i trá»±c tuyáº¿n trÃªn facebook nháº±m giáº£i Ä‘Ã¡p tháº¯c máº¯c tháº¯c máº¯c vá» chÆ°Æ¡ng trÃ¬nh. Tham gia vÃ o sá»± kiá»‡n, má»i ngÆ°á»i sáº½ cÃ³ cÆ¡ há»™i tÆ°Æ¡ng tÃ¡c cÃ¹ng nhá»¯ng vá»‹ mentor dÃ y dáº¡n kinh nghiá»‡m trÃªn Ä‘a lÄ©nh vá»±c vÃ  láº¯ng nghe nhá»¯ng chia sáº» kinh nghiá»‡m qÃºy bÃ¡u cá»§a há».",,,,,
Em chÃ o má»i ngÆ°á»i. Hiá»‡n VinAI Ä‘ang cÃ³ 1 workshop trÃ¬nh bÃ y vá» nhá»¯ng papers Ä‘Æ°á»£c published táº¡i CVPR 2021. Má»i má»i ngÆ°á»i tham gia áº¡.,Em chÃ o má»i ngÆ°á»i. Hiá»‡n VinAI Ä‘ang cÃ³ 1 workshop trÃ¬nh bÃ y vá» nhá»¯ng papers Ä‘Æ°á»£c published táº¡i CVPR 2021. Má»i má»i ngÆ°á»i tham gia áº¡.,,,,,
"Xin chÃ o anh chá»‹, cÃ³ anh chá»‹ nÃ o sá»­ dá»¥ng label generated from Class Attention Map (CAM) (nhÆ° hÃ¬nh dÆ°á»›i) chÆ°a áº¡? Em Ä‘ang lÃ m bÃ i toÃ¡n: brain vessel segmentation (vessel tree - small & complex shape), anh chá»‹ tháº¥y cÃ³ make sense trong trÆ°á»ng há»£p nÃ y náº¿u e dÃ¹ng CAM Ä‘á»ƒ generated labels ko áº¡? Em cáº£m Æ¡n!
Em cáº£m Æ¡n Anh/Chá»‹ Admin Ä‘Ã£ duyá»‡t bÃ i áº¡","Xin chÃ o anh chá»‹, cÃ³ anh chá»‹ nÃ o sá»­ dá»¥ng label generated from Class Attention Map (CAM) (nhÆ° hÃ¬nh dÆ°á»›i) chÆ°a áº¡? Em Ä‘ang lÃ m bÃ i toÃ¡n: brain vessel segmentation (vessel tree - small & complex shape), anh chá»‹ tháº¥y cÃ³ make sense trong trÆ°á»ng há»£p nÃ y náº¿u e dÃ¹ng CAM Ä‘á»ƒ generated labels ko áº¡? Em cáº£m Æ¡n! Em cáº£m Æ¡n Anh/Chá»‹ Admin Ä‘Ã£ duyá»‡t bÃ i áº¡",,,,,
"MÃ¬nh cÃ³ cÃ¢u há»i nhá» muá»‘n há»i má»i ngÆ°á»i.
ÄÃ³ lÃ  táº¡i sao ngÆ°á»i ta hay dÃ¹ng BatchNorm vá»›i CNN vÃ  LayerNorm vá»›i RNN áº¡? Advantages vÃ  Disadvantages cá»§a hai loáº¡i nÃ y lÃ  gÃ¬?",MÃ¬nh cÃ³ cÃ¢u há»i nhá» muá»‘n há»i má»i ngÆ°á»i. ÄÃ³ lÃ  táº¡i sao ngÆ°á»i ta hay dÃ¹ng BatchNorm vá»›i CNN vÃ  LayerNorm vá»›i RNN áº¡? Advantages vÃ  Disadvantages cá»§a hai loáº¡i nÃ y lÃ  gÃ¬?,,,,,
Má»™t bÃ i viáº¿t nho nhá» cá»§a mÃ¬nh vá» overfitting vÃ  underfitting. Mong nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« quÃ­ báº¡n vÃ  cÃ¡c vá»‹ Ä‘á»ƒ Ä‘Æ°á»£c hoÃ n thiá»‡n hÆ¡n.,Má»™t bÃ i viáº¿t nho nhá» cá»§a mÃ¬nh vá» overfitting vÃ  underfitting. Mong nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« quÃ­ báº¡n vÃ  cÃ¡c vá»‹ Ä‘á»ƒ Ä‘Æ°á»£c hoÃ n thiá»‡n hÆ¡n.,,,,,
"ChÃ o má»i ngÆ°á»i,
Em muá»‘n tÃ¬m mua sÃ¡ch ML cÆ¡ báº£n mÃ  khÃ´ng cÃ²n tháº¥y bÃ¡n ná»¯a. Váº­y anh/chá»‹ nÃ o cÃ³ sÃ¡ch mÃ  Ä‘ang khÃ´ng dÃ¹ng cÃ³ thá»ƒ pass láº¡i cho em Ä‘Æ°á»£c khÃ´ng áº¡? em cáº£m Æ¡n nhiá»u","ChÃ o má»i ngÆ°á»i, Em muá»‘n tÃ¬m mua sÃ¡ch ML cÆ¡ báº£n mÃ  khÃ´ng cÃ²n tháº¥y bÃ¡n ná»¯a. Váº­y anh/chá»‹ nÃ o cÃ³ sÃ¡ch mÃ  Ä‘ang khÃ´ng dÃ¹ng cÃ³ thá»ƒ pass láº¡i cho em Ä‘Æ°á»£c khÃ´ng áº¡? em cáº£m Æ¡n nhiá»u",,,,,
"CoAtNet: sá»± káº¿t há»£p giá»¯a 2 kiáº¿n trÃºc Convolution vÃ  Attention cho táº¥t cáº£ cÃ¡c dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau.
Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng SoTA trÃªn cÃ¡c ná»n táº£ng tÃ­nh toÃ¡n vÃ  cÃ¡c datasets khÃ¡c nhau.
Accuracy Ä‘áº¡t Ä‘Æ°á»£c lÃ  88.56% top-1 ImageNet, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i ViT-huge nhÆ°ng cáº§n Ã­t hÆ¡n 23 láº§n data so vá»›i ViT-huge
BÃ i bÃ¡o vá»«a má»›i Ä‘Äƒng táº¡i Ä‘Ã¢y
https://arxiv.org/abs/2106.04803","CoAtNet: sá»± káº¿t há»£p giá»¯a 2 kiáº¿n trÃºc Convolution vÃ  Attention cho táº¥t cáº£ cÃ¡c dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng SoTA trÃªn cÃ¡c ná»n táº£ng tÃ­nh toÃ¡n vÃ  cÃ¡c datasets khÃ¡c nhau. Accuracy Ä‘áº¡t Ä‘Æ°á»£c lÃ  88.56% top-1 ImageNet, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i ViT-huge nhÆ°ng cáº§n Ã­t hÆ¡n 23 láº§n data so vá»›i ViT-huge BÃ i bÃ¡o vá»«a má»›i Ä‘Äƒng táº¡i Ä‘Ã¢y https://arxiv.org/abs/2106.04803",,,,,
"VÃ o trang cá»§a tá»•ng cá»¥c thá»‘ng kÃª xem sá»‘ liá»‡u cá»§a Viá»‡t Nam tháº¥y má»™t bÃ i tá»•ng káº¿t dÃ i ráº¥t nhiá»u chá»¯ vÃ  sá»‘ mÃ  khÃ´ng cÃ³ láº¥y má»™t cÃ¡i biá»ƒu Ä‘á»“.
CÃ¡c báº¡n trong group thá»­ láº¥y dá»¯ liá»‡u trong bÃ¡o cÃ¡o nÃ y Ä‘á»ƒ váº½ cÃ¡c biá»ƒu Ä‘á»“ minh há»a xem.
===================================
Cáº­p nháº­t: File infographic Ä‘Æ°á»£c cung cáº¥p á»Ÿ thanh bÃªn pháº£i cá»§a trang https://www.gso.gov.vn/wp-content/uploads/2020/12/T12.2020-Trang-41-46.pdf. CÃ¡c biá»ƒu Ä‘á»“ khÃ¡ Ä‘áº¹p, hÆ¡i tiáº¿c lÃ  chÃºng khÃ´ng Ä‘Æ°á»£c gÃ¡n kÃ¨m vÃ o ná»™i dung web Ä‘á»ƒ ngÆ°á»i Ä‘á»c dá»… theo dÃµi.","VÃ o trang cá»§a tá»•ng cá»¥c thá»‘ng kÃª xem sá»‘ liá»‡u cá»§a Viá»‡t Nam tháº¥y má»™t bÃ i tá»•ng káº¿t dÃ i ráº¥t nhiá»u chá»¯ vÃ  sá»‘ mÃ  khÃ´ng cÃ³ láº¥y má»™t cÃ¡i biá»ƒu Ä‘á»“. CÃ¡c báº¡n trong group thá»­ láº¥y dá»¯ liá»‡u trong bÃ¡o cÃ¡o nÃ y Ä‘á»ƒ váº½ cÃ¡c biá»ƒu Ä‘á»“ minh há»a xem. =================================== Cáº­p nháº­t: File infographic Ä‘Æ°á»£c cung cáº¥p á»Ÿ thanh bÃªn pháº£i cá»§a trang https://www.gso.gov.vn/wp-content/uploads/2020/12/T12.2020-Trang-41-46.pdf. CÃ¡c biá»ƒu Ä‘á»“ khÃ¡ Ä‘áº¹p, hÆ¡i tiáº¿c lÃ  chÃºng khÃ´ng Ä‘Æ°á»£c gÃ¡n kÃ¨m vÃ o ná»™i dung web Ä‘á»ƒ ngÆ°á»i Ä‘á»c dá»… theo dÃµi.",,,,,
"Em má»›i báº¯t Ä‘áº§u há»c ML, cÃ³ má»™t tháº¯c máº¯c nhá» vá» Batch Norm mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp. 
Theo em hiá»ƒu thÃ¬ má»¥c Ä‘Ã­ch cá»§a BN lÃ  shift giÃ¡ trá»‹ vá» zero mean vá»›i scale variance lÃ  1. Váº­y táº¡i sao sau khi Ä‘Ã£ shift/scale rá»“i láº¡i pháº£i recover láº¡i láº§n ná»¯a vá»›i gamma vÃ  beta? Cháº³ng pháº£i nhÆ° váº­y giÃ¡ trá»‹ sau Ä‘Ã³ sáº½ báº±ng chÃ­nh xÃ¡c vá»›i giÃ¡ trá»‹ trÆ°á»›c khi normalize sao (nghÄ©a lÃ  máº¥t Ä‘i tÃ­nh cháº¥t mean=0, variance=1)?
Vá»›i tanh function thÃ¬ giÃ¡ trá»‹ Ä‘Ã£ náº±m trong khoáº£ng zero-mean vÃ  variance lÃ  1 rá»“i thÃ¬ cÃ³ cáº§n dÃ¹ng BN khÃ´ng náº¿u mÃ¬nh Ä‘áº£m báº£o Ä‘Æ°á»£c dá»¯ liá»‡u khÃ´ng rÆ¡i vÃ o vÃ¹ng bÃ£o hÃ²a?
Em cÃ¡m Æ¡n áº¡!","Em má»›i báº¯t Ä‘áº§u há»c ML, cÃ³ má»™t tháº¯c máº¯c nhá» vá» Batch Norm mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp. Theo em hiá»ƒu thÃ¬ má»¥c Ä‘Ã­ch cá»§a BN lÃ  shift giÃ¡ trá»‹ vá» zero mean vá»›i scale variance lÃ  1. Váº­y táº¡i sao sau khi Ä‘Ã£ shift/scale rá»“i láº¡i pháº£i recover láº¡i láº§n ná»¯a vá»›i gamma vÃ  beta? Cháº³ng pháº£i nhÆ° váº­y giÃ¡ trá»‹ sau Ä‘Ã³ sáº½ báº±ng chÃ­nh xÃ¡c vá»›i giÃ¡ trá»‹ trÆ°á»›c khi normalize sao (nghÄ©a lÃ  máº¥t Ä‘i tÃ­nh cháº¥t mean=0, variance=1)? Vá»›i tanh function thÃ¬ giÃ¡ trá»‹ Ä‘Ã£ náº±m trong khoáº£ng zero-mean vÃ  variance lÃ  1 rá»“i thÃ¬ cÃ³ cáº§n dÃ¹ng BN khÃ´ng náº¿u mÃ¬nh Ä‘áº£m báº£o Ä‘Æ°á»£c dá»¯ liá»‡u khÃ´ng rÆ¡i vÃ o vÃ¹ng bÃ£o hÃ²a? Em cÃ¡m Æ¡n áº¡!",,,,,
"Dáº¡ em chÃ o má»i ngÆ°á»i, cho em há»i lÃ  táº¡i sao fine-tune vá»›i higher resolution láº¡i tá»‘t hÆ¡n váº­y áº¡. Náº¿u theo nhÆ° bÃ i bÃ¡o thÃ¬ fine-tune vá»›i higher resolution sáº½ dáº«n tá»›i position embedding cá»§a pre-train vÃ´ nghÄ©a váº­y sao láº¡i nÃ³i fine-tune vá»›i higher resolution láº¡i tá»‘t hÆ¡n","Dáº¡ em chÃ o má»i ngÆ°á»i, cho em há»i lÃ  táº¡i sao fine-tune vá»›i higher resolution láº¡i tá»‘t hÆ¡n váº­y áº¡. Náº¿u theo nhÆ° bÃ i bÃ¡o thÃ¬ fine-tune vá»›i higher resolution sáº½ dáº«n tá»›i position embedding cá»§a pre-train vÃ´ nghÄ©a váº­y sao láº¡i nÃ³i fine-tune vá»›i higher resolution láº¡i tá»‘t hÆ¡n",,,,,
E chÃ o mn . Mn cho em há»i vá» sá»‘ trials trong tuner hyperband vá»›i áº¡. E muá»‘n há»i lÃ  cÃ¡i hyperband nÃ y nÃ³ tÃ­nh sá»‘ trials theo cÃ´ng thá»©c nÃ o hay nÃ³ ngáº«u nhiÃªn áº¡ ? E muá»‘n Ä‘ang muá»‘n giáº£m sá»‘ trial nhÆ°ng chÆ°a biáº¿t lÃ m cÃ¡ch nÃ o áº¡. E cáº£m Æ¡n mn áº¡! ÄÃ¢y lÃ  bÃ i vá» hyperband áº¡! https://keras-team.github.io/keras-tuner/documentation/tuners/?fbclid=IwAR3j2ifKd0qCWn2GyeI2PJ8gEk-JBYn__hotkh4_AGBJ9pqNyU2cY9mjlDY,E chÃ o mn . Mn cho em há»i vá» sá»‘ trials trong tuner hyperband vá»›i áº¡. E muá»‘n há»i lÃ  cÃ¡i hyperband nÃ y nÃ³ tÃ­nh sá»‘ trials theo cÃ´ng thá»©c nÃ o hay nÃ³ ngáº«u nhiÃªn áº¡ ? E muá»‘n Ä‘ang muá»‘n giáº£m sá»‘ trial nhÆ°ng chÆ°a biáº¿t lÃ m cÃ¡ch nÃ o áº¡. E cáº£m Æ¡n mn áº¡! ÄÃ¢y lÃ  bÃ i vá» hyperband áº¡! https://keras-team.github.io/keras-tuner/documentation/tuners/?fbclid=IwAR3j2ifKd0qCWn2GyeI2PJ8gEk-JBYn__hotkh4_AGBJ9pqNyU2cY9mjlDY,,,,,
"má»™t sá»‘ trang web hay tá»› note láº¡i ngÃ y trÆ°á»›c mÃ  cÃ³ thá»ƒ sáº½ cÃ³ Ã­ch vá»›i má»™t trong sá»‘ cÃ¡c báº¡n.
have a nice reading :)
https://hosjiu.gitlab.io/personal-blog/2020/11/03/DeepBlogs/",má»™t sá»‘ trang web hay tá»› note láº¡i ngÃ y trÆ°á»›c mÃ  cÃ³ thá»ƒ sáº½ cÃ³ Ã­ch vá»›i má»™t trong sá»‘ cÃ¡c báº¡n. have a nice reading :) https://hosjiu.gitlab.io/personal-blog/2020/11/03/DeepBlogs/,,,,,
"#ViT #VisionTransformer
Em chÃ o má»i ngÆ°á»i. Trong bÃ i ViT, em cÃ³ tháº¥y tÃ¡c giáº£ sá»­ dá»¥ng thÃªm 1 thÃ nh pháº§n x_class Ä‘á»ƒ Ä‘áº¡i diá»‡n cho áº£nh Ä‘áº§u vÃ o vÃ  phá»¥c vá»¥ má»¥c Ä‘Ã­ch phÃ¢n loáº¡i (áº£nh 1). Má»i ngÆ°á»i cho em há»i táº¡i sao cáº§n thÃªm thÃ nh pháº§n Ä‘Ã³ vá»›i áº¡. VÃ  khi Ä‘Ã³ cÃ¡c thÃ nh pháº§n cÃ²n láº¡i (x_p^1, x_p^2, ...) nhÆ° trong áº£nh 2 Ä‘Ã³ng vai trÃ² gÃ¬ váº­y áº¡. Bá»Ÿi vÃ¬ ViT Ä‘Æ°á»£c sá»­ dá»¥ng trong TransUNet (áº£nh 3), z khÃ´ng cáº§n bá»• sung thÃ nh pháº§n x_class vÃ  báº£n thÃ¢n z lÃºc Ä‘Ã³ Ä‘Æ°á»£c coi lÃ  Ä‘áº¡i diá»‡n cá»§a áº£nh Ä‘áº§u vÃ o luÃ´n.
Xin lá»—i má»i ngÆ°á»i vÃ¬ cÃ¢u cÃº lá»§ng cá»§ng.","Em chÃ o má»i ngÆ°á»i. Trong bÃ i ViT, em cÃ³ tháº¥y tÃ¡c giáº£ sá»­ dá»¥ng thÃªm 1 thÃ nh pháº§n x_class Ä‘á»ƒ Ä‘áº¡i diá»‡n cho áº£nh Ä‘áº§u vÃ o vÃ  phá»¥c vá»¥ má»¥c Ä‘Ã­ch phÃ¢n loáº¡i (áº£nh 1). Má»i ngÆ°á»i cho em há»i táº¡i sao cáº§n thÃªm thÃ nh pháº§n Ä‘Ã³ vá»›i áº¡. VÃ  khi Ä‘Ã³ cÃ¡c thÃ nh pháº§n cÃ²n láº¡i (x_p^1, x_p^2, ...) nhÆ° trong áº£nh 2 Ä‘Ã³ng vai trÃ² gÃ¬ váº­y áº¡. Bá»Ÿi vÃ¬ ViT Ä‘Æ°á»£c sá»­ dá»¥ng trong TransUNet (áº£nh 3), z khÃ´ng cáº§n bá»• sung thÃ nh pháº§n x_class vÃ  báº£n thÃ¢n z lÃºc Ä‘Ã³ Ä‘Æ°á»£c coi lÃ  Ä‘áº¡i diá»‡n cá»§a áº£nh Ä‘áº§u vÃ o luÃ´n. Xin lá»—i má»i ngÆ°á»i vÃ¬ cÃ¢u cÃº lá»§ng cá»§ng.",#ViT	#VisionTransformer,,,,
"ÄÃ¢y lÃ  sÆ¡ Ä‘á»“ NN trong word2vec.
W (hidden layer weight) sáº½ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ lÃ m vector cho cÃ¡i tá»« mÃ  mÃ¬nh muá»‘n embed.
Cho em há»i lÃ  táº¡i sao mÃ¬nh láº¡i khÃ´ng dÃ¹ng Wâ€™ (output layer weight)?",ÄÃ¢y lÃ  sÆ¡ Ä‘á»“ NN trong word2vec. W (hidden layer weight) sáº½ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ lÃ m vector cho cÃ¡i tá»« mÃ  mÃ¬nh muá»‘n embed. Cho em há»i lÃ  táº¡i sao mÃ¬nh láº¡i khÃ´ng dÃ¹ng Wâ€™ (output layer weight)?,,,,,
"Má»i ngÆ°á»i giÃºp em vá»›i áº¡
em má»›i há»c máº£ng nháº­n diá»‡n khuÃ´n máº·t dungf thÆ° viá»‡n face-reconigtion vÃ  bÃ¡o lá»—i chÆ°a cÃ i tool C++ trong lÃºc buil dlib
mÃ  trong VS code thÃ¬ e cÃ³ rá»“i
mn cÃ³ thá»ƒ giÃºp em khÃ´ng áº¡",Má»i ngÆ°á»i giÃºp em vá»›i áº¡ em má»›i há»c máº£ng nháº­n diá»‡n khuÃ´n máº·t dungf thÆ° viá»‡n face-reconigtion vÃ  bÃ¡o lá»—i chÆ°a cÃ i tool C++ trong lÃºc buil dlib mÃ  trong VS code thÃ¬ e cÃ³ rá»“i mn cÃ³ thá»ƒ giÃºp em khÃ´ng áº¡,,,,,
FYI:,FYI:,,,,,
"em chÃ o má»i ngÆ°á»i, em cÃ³ tháº¯c máº¯c vá» báº£n cháº¥t neural net lÃ  gÃ¬ vÃ  nÃ³ Ä‘Ã£ lÃ m gÃ¬ Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c hÃ m f fit vá»›i data. em tÃ¬m hiá»ƒu thÃ¬ Ä‘Æ°á»£c biáº¿t lÃ  báº£n cháº¥t hidden layer lÃ  viá»‡c Ã¡nh xáº¡ sang má»™t chiá»u khÃ´ng gian má»›i vÃ  vá»›i viá»‡c dÃ¹ng cho bÃ i toÃ¡n phÃ¢n lá»›p thÃ¬ má»—i node trong layer nÃ y lÃ  1 siÃªu pháº³ng phÃ¢n vÃ¹ng khÃ´ng gian layer nÃ y thÃ nh 2 ná»­a khÃ´ng gian. váº­y vá»›i bÃ i toÃ¡n xor thÃ¬ em hÃ¬nh dung khÃ´ng gian má»›i nhÆ° áº£nh bÃªn dÆ°á»›i, váº­y thÃ¬ em muá»‘n hiá»ƒu lÃ  cÃ¡i siÃªu pháº³ng phÃ¢n tÃ¡ch dá»¯ liá»‡u vá»›i 2 Ä‘Æ°á»ng tháº³ng trong bÃ i viáº¿t https://machinelearningcoban.com/2017/02/24/mlp/ cá»§a anh Tiá»‡p cÃ³ quan há»‡ gÃ¬ (liá»‡u cÃ¡c hiá»ƒu cá»§a em Ä‘Ã£ Ä‘Ãºng chÆ°a ?). vÃ  viá»‡c tÃ­nh tá»•ng cÃ¡c Ä‘Æ°á»ng vÃ o má»™t node vd w1x1+w2x2+w3x3 +... sau Ä‘Ã³ activate rá»“i láº¡i thá»±c hiá»‡n nhiá»u tá»•ng dáº¡ng nhÆ° nÃ y qua cÃ¡c layer thÃ¬ nÃ³ Ä‘Ã£ lÃ m kiá»ƒu gÃ¬ Ä‘á»ƒ thÃ nh 1 Ä‘Æ°á»ng phÃ¢n tÃ¡ch dá»¯ liá»‡u cuá»‘i cÃ¹ng ( liá»‡u cÃ³ pháº£i viá»‡c tÃ­nh toÃ¡n lá»“ng cÃ¡c Ä‘Æ°á»ng nÃ y vÃ  acivate nonliner nhiá»u láº§n Ä‘Ã£ táº¡o ra má»™t há»“i quy Ä‘a biáº¿n khÃ´ng áº¡) mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em, em cáº£m Æ¡n.","em chÃ o má»i ngÆ°á»i, em cÃ³ tháº¯c máº¯c vá» báº£n cháº¥t neural net lÃ  gÃ¬ vÃ  nÃ³ Ä‘Ã£ lÃ m gÃ¬ Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c hÃ m f fit vá»›i data. em tÃ¬m hiá»ƒu thÃ¬ Ä‘Æ°á»£c biáº¿t lÃ  báº£n cháº¥t hidden layer lÃ  viá»‡c Ã¡nh xáº¡ sang má»™t chiá»u khÃ´ng gian má»›i vÃ  vá»›i viá»‡c dÃ¹ng cho bÃ i toÃ¡n phÃ¢n lá»›p thÃ¬ má»—i node trong layer nÃ y lÃ  1 siÃªu pháº³ng phÃ¢n vÃ¹ng khÃ´ng gian layer nÃ y thÃ nh 2 ná»­a khÃ´ng gian. váº­y vá»›i bÃ i toÃ¡n xor thÃ¬ em hÃ¬nh dung khÃ´ng gian má»›i nhÆ° áº£nh bÃªn dÆ°á»›i, váº­y thÃ¬ em muá»‘n hiá»ƒu lÃ  cÃ¡i siÃªu pháº³ng phÃ¢n tÃ¡ch dá»¯ liá»‡u vá»›i 2 Ä‘Æ°á»ng tháº³ng trong bÃ i viáº¿t https://machinelearningcoban.com/2017/02/24/mlp/ cá»§a anh Tiá»‡p cÃ³ quan há»‡ gÃ¬ (liá»‡u cÃ¡c hiá»ƒu cá»§a em Ä‘Ã£ Ä‘Ãºng chÆ°a ?). vÃ  viá»‡c tÃ­nh tá»•ng cÃ¡c Ä‘Æ°á»ng vÃ o má»™t node vd w1x1+w2x2+w3x3 +... sau Ä‘Ã³ activate rá»“i láº¡i thá»±c hiá»‡n nhiá»u tá»•ng dáº¡ng nhÆ° nÃ y qua cÃ¡c layer thÃ¬ nÃ³ Ä‘Ã£ lÃ m kiá»ƒu gÃ¬ Ä‘á»ƒ thÃ nh 1 Ä‘Æ°á»ng phÃ¢n tÃ¡ch dá»¯ liá»‡u cuá»‘i cÃ¹ng ( liá»‡u cÃ³ pháº£i viá»‡c tÃ­nh toÃ¡n lá»“ng cÃ¡c Ä‘Æ°á»ng nÃ y vÃ  acivate nonliner nhiá»u láº§n Ä‘Ã£ táº¡o ra má»™t há»“i quy Ä‘a biáº¿n khÃ´ng áº¡) mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em, em cáº£m Æ¡n.",,,,,
"Mn cho em há»i cÃ¢u nÃ y hÆ¡i ngá»‘c áº¡. Chuyá»‡n lÃ  em má»›i báº¯t Ä‘áº§u há»c Machine Learning (má»›i á»Ÿ má»©c lÃ­ thuyáº¿t thÃ´i áº¡), hiá»‡n giá» em muá»‘n lÃ m má»™t dá»± Ã¡n Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng thá»±c hÃ nh. NhÆ°ng do cÃ²n tay mÆ¡ nÃªn em lÃªn Github vÃ  táº£i má»™t sá»‘ dá»± Ã¡n vá» Ä‘á»ƒ tá»« Ä‘Ã³ táº­p lÃ m quen dáº§n. NhÆ°ng em cháº¡y code thÃ¬ bá»‹ vÆ°á»›ng chá»— lá»—i nhÆ° trong áº£nh ( lá»—i khÃ´ng cÃ³ táº­p tin hoáº·c thÆ° má»¥c ). Hiá»‡n táº¡i, em Ä‘Ã£ cÃ³ Ä‘Æ°á»£c Folder cá»§a cáº§n thÃªm cá»§a Project Ä‘Ã³ nhÆ°ng lÃ m cÃ¡ch nÃ o Ä‘á»ƒ thÃªm vÃ o Google Colab Ä‘á»ƒ tá»« Ä‘Ã³ cháº¡y code áº¡. Em cáº£m Æ¡n mn nhiá»u.","Mn cho em há»i cÃ¢u nÃ y hÆ¡i ngá»‘c áº¡. Chuyá»‡n lÃ  em má»›i báº¯t Ä‘áº§u há»c Machine Learning (má»›i á»Ÿ má»©c lÃ­ thuyáº¿t thÃ´i áº¡), hiá»‡n giá» em muá»‘n lÃ m má»™t dá»± Ã¡n Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng thá»±c hÃ nh. NhÆ°ng do cÃ²n tay mÆ¡ nÃªn em lÃªn Github vÃ  táº£i má»™t sá»‘ dá»± Ã¡n vá» Ä‘á»ƒ tá»« Ä‘Ã³ táº­p lÃ m quen dáº§n. NhÆ°ng em cháº¡y code thÃ¬ bá»‹ vÆ°á»›ng chá»— lá»—i nhÆ° trong áº£nh ( lá»—i khÃ´ng cÃ³ táº­p tin hoáº·c thÆ° má»¥c ). Hiá»‡n táº¡i, em Ä‘Ã£ cÃ³ Ä‘Æ°á»£c Folder cá»§a cáº§n thÃªm cá»§a Project Ä‘Ã³ nhÆ°ng lÃ m cÃ¡ch nÃ o Ä‘á»ƒ thÃªm vÃ o Google Colab Ä‘á»ƒ tá»« Ä‘Ã³ cháº¡y code áº¡. Em cáº£m Æ¡n mn nhiá»u.",,,,,
"Xin phÃ©p má»i ngÆ°á»i áº¡, cÃ³ thá»ƒ khÃ´ng liÃªn quan Ä‘áº¿n ML láº¯m
VÃ­ dá»¥ nhÆ° em muá»‘n lÃ m 1 app tÃ­nh giÃ¡ nhÃ  cho thuÃª. Em cÃ³ Ä‘Æ°á»£c data nhÆ° diá»‡n tÃ­ch, sá»‘ phÃ²ng ngá»§, vá»‹ trÃ­ cÃ¡ch trung tÃ¢m vÃ  giÃ¡ cho thuÃª
Náº¿u khÃ´ng pháº£i Ä‘á»¥ng Ä‘áº¿n code thÃ¬ cÃ³ vba hay plugins cho exel hoáº·c app bÃªn thá»© 3 cÃ³ thá»ƒ xá»­ lÃ­ sá»‘ liá»‡u nhÆ° nÃ y nhá»‰?","Xin phÃ©p má»i ngÆ°á»i áº¡, cÃ³ thá»ƒ khÃ´ng liÃªn quan Ä‘áº¿n ML láº¯m VÃ­ dá»¥ nhÆ° em muá»‘n lÃ m 1 app tÃ­nh giÃ¡ nhÃ  cho thuÃª. Em cÃ³ Ä‘Æ°á»£c data nhÆ° diá»‡n tÃ­ch, sá»‘ phÃ²ng ngá»§, vá»‹ trÃ­ cÃ¡ch trung tÃ¢m vÃ  giÃ¡ cho thuÃª Náº¿u khÃ´ng pháº£i Ä‘á»¥ng Ä‘áº¿n code thÃ¬ cÃ³ vba hay plugins cho exel hoáº·c app bÃªn thá»© 3 cÃ³ thá»ƒ xá»­ lÃ­ sá»‘ liá»‡u nhÆ° nÃ y nhá»‰?",,,,,
"Em chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m thuáº­t toÃ¡n Wiener Filter (image restoration) vÃ  cÃ³ má»™t váº¥n Ä‘á» lÃ  chia 1 sá»‘ phá»©c (tá»­ sá»‘) cho má»™t sá»‘ thá»±c(R) trong openCV
HÆ°á»›ng lÃ m cá»§a em lÃ  split sá»‘ phá»©c Ä‘Ã³ ra lÃ m 2 channel[0] vÃ  channel[1] rá»“i sau Ä‘Ã³ dÃ¹ng hÃ m divide Ä‘á»ƒ chia 2 channel Ä‘Ã³ cho sá»‘ thá»±c R, rá»“i cá»™ng 2 káº¿t quáº£ Ä‘Ã³ láº¡i vá»›i nhau. KhÃ´ng biáº¿t ráº±ng em Ä‘ang Ä‘i cÃ³ Ä‘Ãºng hÆ°á»›ng khÃ´ng áº¡? Anh chá»‹ em nÃ o biáº¿t thÃ¬ chá»‰ em vá»›i áº¡
Em cÃ¡m Æ¡n
#WienerFilter #ComplexNumber","Em chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m thuáº­t toÃ¡n Wiener Filter (image restoration) vÃ  cÃ³ má»™t váº¥n Ä‘á» lÃ  chia 1 sá»‘ phá»©c (tá»­ sá»‘) cho má»™t sá»‘ thá»±c(R) trong openCV HÆ°á»›ng lÃ m cá»§a em lÃ  split sá»‘ phá»©c Ä‘Ã³ ra lÃ m 2 channel[0] vÃ  channel[1] rá»“i sau Ä‘Ã³ dÃ¹ng hÃ m divide Ä‘á»ƒ chia 2 channel Ä‘Ã³ cho sá»‘ thá»±c R, rá»“i cá»™ng 2 káº¿t quáº£ Ä‘Ã³ láº¡i vá»›i nhau. KhÃ´ng biáº¿t ráº±ng em Ä‘ang Ä‘i cÃ³ Ä‘Ãºng hÆ°á»›ng khÃ´ng áº¡? Anh chá»‹ em nÃ o biáº¿t thÃ¬ chá»‰ em vá»›i áº¡ Em cÃ¡m Æ¡n",#WienerFilter	#ComplexNumber,,,,
"Xin phÃ©p Ä‘Æ°á»£c chia sáº» thÃ´ng tin khoÃ¡ há»c láº­p trÃ¬nh Scratch/Python ONLINE Miá»…n PhÃ­ tá»« STEAM for Vietnam dÃ nh
ğŸ‘‰ğŸ‘‰Link Ä‘Äƒng kÃ½: https://bit.ly/3x1HOKc
STEAM for Vietnam Ä‘Ã£ chÃ­nh thá»©c trá»Ÿ láº¡i vá»›i Summer Coding Bootcamp 2021, hÃ£y tham gia há»c láº­p trÃ¬nh hoÃ n toÃ n MIá»„N PHÃ cÃ¹ng cÃ¡c chuyÃªn gia cÃ´ng nghá»‡ hÃ ng Ä‘áº§u tá»« Google, Microsoft, Chan Zuckerberg Initiative, Twitter, Amazon vÃ  30,000 há»c sinh ngÆ°á»i Viá»‡t táº¡i 30 quá»‘c gia.
âœ…CS 001- Nháº­p mÃ´n vá» TÆ° duy MÃ¡y tÃ­nh vÃ  NgÃ´n ngá»¯ Láº­p trÃ¬nh Scratch.
âœ…CS 101 - Nháº­p mÃ´n Khoa há»c MÃ¡y tÃ­nh vá»›i Python
Hai khoÃ¡ há»c dá»± kiáº¿n sáº½ diá»…n ra theo hÃ¬nh thá»©c livestream trá»±c tuyáº¿n vÃ o sÃ¡ng Chá»§ nháº­t hÃ ng tuáº§n, báº¯t Ä‘áº§u tá»« ngÃ y 27/6/2021.
ğŸ‰ğŸ‰ÄÆ¡n Ä‘Äƒng kÃ½ sáº½ Ä‘Ã³ng vÃ o ngÃ y 20/6/2021, cÃ¡c phá»¥ huynh hÃ£y nhanh tay ná»™p nhÃ© áº¡.","Xin phÃ©p Ä‘Æ°á»£c chia sáº» thÃ´ng tin khoÃ¡ há»c láº­p trÃ¬nh Scratch/Python ONLINE Miá»…n PhÃ­ tá»« STEAM for Vietnam dÃ nh Link Ä‘Äƒng kÃ½: https://bit.ly/3x1HOKc STEAM for Vietnam Ä‘Ã£ chÃ­nh thá»©c trá»Ÿ láº¡i vá»›i Summer Coding Bootcamp 2021, hÃ£y tham gia há»c láº­p trÃ¬nh hoÃ n toÃ n MIá»„N PHÃ cÃ¹ng cÃ¡c chuyÃªn gia cÃ´ng nghá»‡ hÃ ng Ä‘áº§u tá»« Google, Microsoft, Chan Zuckerberg Initiative, Twitter, Amazon vÃ  30,000 há»c sinh ngÆ°á»i Viá»‡t táº¡i 30 quá»‘c gia. CS 001- Nháº­p mÃ´n vá» TÆ° duy MÃ¡y tÃ­nh vÃ  NgÃ´n ngá»¯ Láº­p trÃ¬nh Scratch. CS 101 - Nháº­p mÃ´n Khoa há»c MÃ¡y tÃ­nh vá»›i Python Hai khoÃ¡ há»c dá»± kiáº¿n sáº½ diá»…n ra theo hÃ¬nh thá»©c livestream trá»±c tuyáº¿n vÃ o sÃ¡ng Chá»§ nháº­t hÃ ng tuáº§n, báº¯t Ä‘áº§u tá»« ngÃ y 27/6/2021. ÄÆ¡n Ä‘Äƒng kÃ½ sáº½ Ä‘Ã³ng vÃ o ngÃ y 20/6/2021, cÃ¡c phá»¥ huynh hÃ£y nhanh tay ná»™p nhÃ© áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  dev chÃ­nh trong dá»± Ã¡n Vietstock scraper mÃ  báº¡n Khanh Pham cÃ³ Ä‘Äƒng trong nhÃ³m á»Ÿ bÃ i nÃ y: https://www.facebook.com/groups/machinelearningcoban/permalink/1229553207502084/
Ban Ä‘áº§u project nÃ y chá»‰ Ä‘á»ƒ phá»¥c vá»¥ viá»‡c nghiÃªn cá»©u cá»§a bá»n mÃ¬nh, nÃªn code vÃ  trÃ¬nh bÃ y cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c chá»‰nh chu láº¯m. Äá»“ng thá»i, cÃ¡ch sá»­ dá»¥ng nhÃ¬n cÃ³ váº» hÆ¡i phá»©c táº¡p nÃªn náº¿u cÃ³ nhiá»u ngÆ°á»i quan tÃ¢m thÃ¬ mÃ¬nh cÃ³ thá»ƒ viáº¿t nhanh má»™t hÆ°á»›ng dáº«n báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ dá»… tiáº¿p cáº­n hÆ¡n.
Vá» quy mÃ´, mÃ¬nh tháº¥y trÃªn Vietstock cÃ³ khoáº£ng 3000 mÃ£ chá»©ng khoÃ¡n vÃ  khoáº£ng 10 Ä‘áº§u API khÃ¡c nhau (thÃ´ng tin tÃ i chÃ­nh, thÃ´ng tin chá»§ sá»Ÿ há»¯u, cáº¥u thÃ nh doanh nghiá»‡p, Ä‘Æ°á»ng dáº«n kÃ©o cÃ¡c tÃ i liá»‡u dÆ°á»›i dáº¡ng PDF, etc.) vÃ  con scraper nÃ y technically hoÃ n toÃ n cÃ³ thá»ƒ kÃ©o háº¿t chá»— thÃ´ng tin Ä‘Ã³ (giáº£ Ä‘á»‹nh lÃ  báº¡n khÃ´ng bá»‹ cháº·n). Tuy nhiÃªn, hiá»‡n táº¡i mÃ¬nh má»›i chá»‰ code hoÃ n thiá»‡n cho Ä‘áº§u API vá» thÃ´ng tin tÃ i chÃ­nh thÃ´i. Náº¿u cÃ³ nhiá»u ngÆ°á»i quan tÃ¢m vá» cÃ¡c Ä‘áº§u API khÃ¡c, project nÃ y cÃ³ thá»ƒ sáº½ tiáº¿p tá»¥c Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ kÃ©o Ä‘Æ°á»£c nhiá»u thá»© hÆ¡n.
Vá» tá»‘c Ä‘á»™ kÃ©o, vÃ¬ sá»­ dá»¥ng scrapy nÃªn con scraper nÃ y cÃ³ tá»‘c Ä‘á»™ khÃ¡ á»•n cho viá»‡c kÃ©o diá»‡n rá»™ng vÃ  sá»­ dá»¥ng proxy cÃ¹ng lÃºc. Tuy nhiÃªn, mÃ¬nh khuyáº¿n cÃ¡o má»i ngÆ°á»i chá»‰ nÃªn kÃ©o nhá»¯ng mÃ£, hoáº·c ngÃ nh mÃ  cÃ¡c báº¡n quan tÃ¢m, Ä‘á»ƒ trÃ¡nh lÃ m quÃ¡ táº£i server cá»§a Vietstock.
Cáº£m Æ¡n má»i ngÆ°á»i!","ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  dev chÃ­nh trong dá»± Ã¡n Vietstock scraper mÃ  báº¡n Khanh Pham cÃ³ Ä‘Äƒng trong nhÃ³m á»Ÿ bÃ i nÃ y: https://www.facebook.com/groups/machinelearningcoban/permalink/1229553207502084/ Ban Ä‘áº§u project nÃ y chá»‰ Ä‘á»ƒ phá»¥c vá»¥ viá»‡c nghiÃªn cá»©u cá»§a bá»n mÃ¬nh, nÃªn code vÃ  trÃ¬nh bÃ y cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c chá»‰nh chu láº¯m. Äá»“ng thá»i, cÃ¡ch sá»­ dá»¥ng nhÃ¬n cÃ³ váº» hÆ¡i phá»©c táº¡p nÃªn náº¿u cÃ³ nhiá»u ngÆ°á»i quan tÃ¢m thÃ¬ mÃ¬nh cÃ³ thá»ƒ viáº¿t nhanh má»™t hÆ°á»›ng dáº«n báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ dá»… tiáº¿p cáº­n hÆ¡n. Vá» quy mÃ´, mÃ¬nh tháº¥y trÃªn Vietstock cÃ³ khoáº£ng 3000 mÃ£ chá»©ng khoÃ¡n vÃ  khoáº£ng 10 Ä‘áº§u API khÃ¡c nhau (thÃ´ng tin tÃ i chÃ­nh, thÃ´ng tin chá»§ sá»Ÿ há»¯u, cáº¥u thÃ nh doanh nghiá»‡p, Ä‘Æ°á»ng dáº«n kÃ©o cÃ¡c tÃ i liá»‡u dÆ°á»›i dáº¡ng PDF, etc.) vÃ  con scraper nÃ y technically hoÃ n toÃ n cÃ³ thá»ƒ kÃ©o háº¿t chá»— thÃ´ng tin Ä‘Ã³ (giáº£ Ä‘á»‹nh lÃ  báº¡n khÃ´ng bá»‹ cháº·n). Tuy nhiÃªn, hiá»‡n táº¡i mÃ¬nh má»›i chá»‰ code hoÃ n thiá»‡n cho Ä‘áº§u API vá» thÃ´ng tin tÃ i chÃ­nh thÃ´i. Náº¿u cÃ³ nhiá»u ngÆ°á»i quan tÃ¢m vá» cÃ¡c Ä‘áº§u API khÃ¡c, project nÃ y cÃ³ thá»ƒ sáº½ tiáº¿p tá»¥c Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ kÃ©o Ä‘Æ°á»£c nhiá»u thá»© hÆ¡n. Vá» tá»‘c Ä‘á»™ kÃ©o, vÃ¬ sá»­ dá»¥ng scrapy nÃªn con scraper nÃ y cÃ³ tá»‘c Ä‘á»™ khÃ¡ á»•n cho viá»‡c kÃ©o diá»‡n rá»™ng vÃ  sá»­ dá»¥ng proxy cÃ¹ng lÃºc. Tuy nhiÃªn, mÃ¬nh khuyáº¿n cÃ¡o má»i ngÆ°á»i chá»‰ nÃªn kÃ©o nhá»¯ng mÃ£, hoáº·c ngÃ nh mÃ  cÃ¡c báº¡n quan tÃ¢m, Ä‘á»ƒ trÃ¡nh lÃ m quÃ¡ táº£i server cá»§a Vietstock. Cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"ChÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cÃ³ ai tá»«ng train deeplab tá»« tensorflow sau Ä‘Ã³ visualize lÃªn thÃ¬ áº£nh predict toÃ n Ä‘en khÃ´ng áº¡? Em cÃ³ dÃ¹ng deeplab trÃªn tensorflow Ä‘á»ƒ train thÃ¬ bá»‹ váº­y. Má»i ngÆ°á»i cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c khÃ´ng áº¡?
Link deeplab:
https://github.com/tensorflow/models/tree/master/research/deeplab
Link data cá»§a em:
https://drive.google.com/drive/folders/1OG6RmoXijCgxYAILyw3dVDdDshjRCHJi?usp=sharing","ChÃ o má»i ngÆ°á»i, má»i ngÆ°á»i cÃ³ ai tá»«ng train deeplab tá»« tensorflow sau Ä‘Ã³ visualize lÃªn thÃ¬ áº£nh predict toÃ n Ä‘en khÃ´ng áº¡? Em cÃ³ dÃ¹ng deeplab trÃªn tensorflow Ä‘á»ƒ train thÃ¬ bá»‹ váº­y. Má»i ngÆ°á»i cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c khÃ´ng áº¡? Link deeplab: https://github.com/tensorflow/models/tree/master/research/deeplab Link data cá»§a em: https://drive.google.com/drive/folders/1OG6RmoXijCgxYAILyw3dVDdDshjRCHJi?usp=sharing",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m vá» sentence classification vá»›i G-MLP. Tuy nhiÃªn theo source code (https://github.com/lucidrains/g-mlp-pytorch) thÃ¬ á»Ÿ pháº§n G-MLP láº¡i táº¡o ra embedding cho tá»«ng word trong sentence.
Do em cÃ²n khÃ¡ má»›i vá»›i NLP nÃªn em muá»‘n há»i má»i ngÆ°á»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ táº¡o ra sentence embedding Ä‘á»ƒ classification khÃ´ng áº¡? Em tháº¥y trong paper cÅ©ng cÃ³ káº¿t quáº£ trÃªn SST-2 nÃªn em muá»‘n há»i tÃ¡c giáº£ Ä‘Ã£ táº¡o sentence embedding Ä‘á»ƒ classification báº±ng cÃ¡ch nÃ o áº¡?
Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.",Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m vá» sentence classification vá»›i G-MLP. Tuy nhiÃªn theo source code (https://github.com/lucidrains/g-mlp-pytorch) thÃ¬ á»Ÿ pháº§n G-MLP láº¡i táº¡o ra embedding cho tá»«ng word trong sentence. Do em cÃ²n khÃ¡ má»›i vá»›i NLP nÃªn em muá»‘n há»i má»i ngÆ°á»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ táº¡o ra sentence embedding Ä‘á»ƒ classification khÃ´ng áº¡? Em tháº¥y trong paper cÅ©ng cÃ³ káº¿t quáº£ trÃªn SST-2 nÃªn em muá»‘n há»i tÃ¡c giáº£ Ä‘Ã£ táº¡o sentence embedding Ä‘á»ƒ classification báº±ng cÃ¡ch nÃ o áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.,,,,,
"ChÃ o má»i ngÆ°á»i.
Em cÃ³ má»™t tháº¯c máº¯c sau mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
Em Ä‘ang tÃ¬m hiá»ƒu vá» Deep metric learning, qua má»™t thá»i gian tÃ¬m hiá»ƒu thÃ¬ em biáº¿t Ä‘Æ°á»£c ráº±ng Deep metric learning Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i quyáº¿t má»™t sá»‘ váº¥n Ä‘á» trong sofmax function nhÆ° sau:
1/ Khi dá»¯ liá»‡u cÃ³ quÃ¡ nhiá»u classes.
 - VÃ­ dá»¥ trong bÃ i toÃ¡n nháº­n diá»‡n khuÃ´n máº·t, pháº£i phÃ¢n loáº¡i khÃ¡ nhiá»u khuÃ´n máº·t khÃ¡c nhau (cÃ³ thá»ƒ lÃ  100 hoáº·c 1000 classes)
2/ Khi sá»‘ dá»¯ liá»‡u trong má»—i class lÃ  háº¡n cháº¿.
3/ CÃ³ thá»ƒ khÃ´ng cáº§n train láº¡i toÃ n bá»™ mÃ´ hÃ¬nh khi cÃ³ dá»¯ liá»‡u thuá»™c class má»›i ( class khÃ´ng náº±m trong bá»™ dá»¯ liá»‡u Ä‘Ã£ train).

Em cÃ³ má»™t tháº¯c máº¯c lÃ  lÃ m sao Deep metric learning cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c nhá»¯ng váº¥n Ä‘á» trÃªn áº¡? hoáº·c cÃ³ tÃ i liá»‡u nÃ o giáº£i thÃ­ch mong anh chá»‹ chia sáº». Em cáº£m Æ¡n ráº¥t nhiá»u áº¡.
Má»™t bÃ i viáº¿t mÃ  em Ä‘á»c gáº§n Ä‘Ã¢y: https://towardsdatascience.com/deep-metric-learning-76fa0a5a415f","ChÃ o má»i ngÆ°á»i. Em cÃ³ má»™t tháº¯c máº¯c sau mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p. Em Ä‘ang tÃ¬m hiá»ƒu vá» Deep metric learning, qua má»™t thá»i gian tÃ¬m hiá»ƒu thÃ¬ em biáº¿t Ä‘Æ°á»£c ráº±ng Deep metric learning Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i quyáº¿t má»™t sá»‘ váº¥n Ä‘á» trong sofmax function nhÆ° sau: 1/ Khi dá»¯ liá»‡u cÃ³ quÃ¡ nhiá»u classes. - VÃ­ dá»¥ trong bÃ i toÃ¡n nháº­n diá»‡n khuÃ´n máº·t, pháº£i phÃ¢n loáº¡i khÃ¡ nhiá»u khuÃ´n máº·t khÃ¡c nhau (cÃ³ thá»ƒ lÃ  100 hoáº·c 1000 classes) 2/ Khi sá»‘ dá»¯ liá»‡u trong má»—i class lÃ  háº¡n cháº¿. 3/ CÃ³ thá»ƒ khÃ´ng cáº§n train láº¡i toÃ n bá»™ mÃ´ hÃ¬nh khi cÃ³ dá»¯ liá»‡u thuá»™c class má»›i ( class khÃ´ng náº±m trong bá»™ dá»¯ liá»‡u Ä‘Ã£ train). Em cÃ³ má»™t tháº¯c máº¯c lÃ  lÃ m sao Deep metric learning cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c nhá»¯ng váº¥n Ä‘á» trÃªn áº¡? hoáº·c cÃ³ tÃ i liá»‡u nÃ o giáº£i thÃ­ch mong anh chá»‹ chia sáº». Em cáº£m Æ¡n ráº¥t nhiá»u áº¡. Má»™t bÃ i viáº¿t mÃ  em Ä‘á»c gáº§n Ä‘Ã¢y: https://towardsdatascience.com/deep-metric-learning-76fa0a5a415f",,,,,
Em muá»‘n há»i má»™t chÃºt vá» Hybrid Architecture Ä‘Æ°á»£c nháº¯c tá»›i trong ViT (Vision Transformer). á» Ä‘Ã¢y theo em Ä‘á»c lÃ  image sáº½ Ä‘Æ°á»£c Ä‘Æ°a vÃ o CNN trÆ°á»›c Ä‘á»ƒ extract feature map. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  sao áº¡ táº¡i vÃ¬ trong ViT thÃ¬ pháº£i chia áº£nh input ra thÃ nh tá»«ng patch nhá» váº­y thÃ¬ Hybrid Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° tháº¿ nÃ o áº¡. Em cáº£m Æ¡n.,Em muá»‘n há»i má»™t chÃºt vá» Hybrid Architecture Ä‘Æ°á»£c nháº¯c tá»›i trong ViT (Vision Transformer). á» Ä‘Ã¢y theo em Ä‘á»c lÃ  image sáº½ Ä‘Æ°á»£c Ä‘Æ°a vÃ o CNN trÆ°á»›c Ä‘á»ƒ extract feature map. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  sao áº¡ táº¡i vÃ¬ trong ViT thÃ¬ pháº£i chia áº£nh input ra thÃ nh tá»«ng patch nhá» váº­y thÃ¬ Hybrid Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° tháº¿ nÃ o áº¡. Em cáº£m Æ¡n.,,,,,
"Trong mÃ´ hÃ¬nh content base Recommendation System cho 1 trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, cá»¥ thá»ƒ lÃ  mÃ¬nh lÃ m vá» kinh doanh Ä‘iá»‡n thoáº¡i, laptop thÃ¬ má»i ngÆ°á»i nghÄ© lÃºc training mÃ´ hÃ¬nh mÃ¬nh cÃ³ nÃªn cho cÃ¡i mÃ´ táº£ sáº£n pháº©m nhÆ° hÃ¬nh vÃ o Ä‘á»ƒ training khÃ´ng má»i ngÆ°á»i? Má»i ngÆ°á»i tháº¥y cÃ¡i thÃ´ng tin nÃ y cÃ³ há»¯u Ã­ch cho viá»‡c training khÃ´ng?
Táº¡i hÃ´m nay mÃ¬nh import dá»¯ liá»‡u má»›i, nghi lÃ  do cÃ¡i ná»™i dung nÃ y nÃ³ trÃ ng giang quÃ¡ nÃªn lÃºc cháº¡y nÃ³ bá»‹ lá»—i out of range luÃ´n nÃªn mÃ¬nh sá»£ quÃ¡.","Trong mÃ´ hÃ¬nh content base Recommendation System cho 1 trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, cá»¥ thá»ƒ lÃ  mÃ¬nh lÃ m vá» kinh doanh Ä‘iá»‡n thoáº¡i, laptop thÃ¬ má»i ngÆ°á»i nghÄ© lÃºc training mÃ´ hÃ¬nh mÃ¬nh cÃ³ nÃªn cho cÃ¡i mÃ´ táº£ sáº£n pháº©m nhÆ° hÃ¬nh vÃ o Ä‘á»ƒ training khÃ´ng má»i ngÆ°á»i? Má»i ngÆ°á»i tháº¥y cÃ¡i thÃ´ng tin nÃ y cÃ³ há»¯u Ã­ch cho viá»‡c training khÃ´ng? Táº¡i hÃ´m nay mÃ¬nh import dá»¯ liá»‡u má»›i, nghi lÃ  do cÃ¡i ná»™i dung nÃ y nÃ³ trÃ ng giang quÃ¡ nÃªn lÃºc cháº¡y nÃ³ bá»‹ lá»—i out of range luÃ´n nÃªn mÃ¬nh sá»£ quÃ¡.",,,,,
"[ASK] OVERFITTING TRONG TRANSFER LEARNING 
ChÃ o cÃ¡c anh/chá»‹,
NhÆ° em Ä‘Æ°á»£c há»c, overfitting lÃ  hiá»‡n tÆ°á»£ng dá»¯ liá»‡u training quÃ¡ nhá» vÃ  khÃ´ng Ä‘á»§ Ä‘á»ƒ khÃ¡i quÃ¡t hÃ³a cho nhá»¯ng dá»¯ liá»‡u má»›i; do Ä‘Ã³ thuáº­t toÃ¡n Ä‘Ã£ quÃ¡ fit vÃ o training set, khiáº¿n thá»±c táº¿ sá»­ dá»¥ng (metrics Ä‘o trÃªn test set) ráº¥t kÃ©m.
Em Ä‘ang thá»­ nghiá»‡m fine-tune má»™t pretrained model Ä‘Ã£ Ä‘Æ°á»£c train trÃªn táº­p dá»¯ liá»‡u ráº¥t lá»›n vá»›i 1 task gáº§n vá»›i task mÃ  em mong muá»‘n. Cá»¥ thá»ƒ, em thÃªm 1 linear layer vá»›i Ä‘áº§u ra softmax vÃ o cuá»‘i, sau Ä‘Ã³ trÃªn model má»›i end-to-end vá»›i learning rate nhá».
Táº­p dá»¯ liá»‡u dÃ nh cho fine-tune cá»§a em khÃ´ng lá»›n, chá»‰ khoáº£ng 4000 examples.
Káº¿t quáº£: khi láº¥y weight á»Ÿ epoch cÃ³ val loss tháº¥p nháº¥t, metrics Ä‘o Ä‘Æ°á»£c trÃªn táº­p test khÃ¡ tá»‘t. Tuy nhiÃªn hiá»‡n tÆ°á»£ng giá»‘ng nhÆ° overfitting Ä‘Ã£ xáº£y ra: chá»‰ sau khoáº£ng 3 epoch, val loss báº¯t Ä‘áº§u tÄƒng trong khi train loss váº«n tiáº¿p tá»¥c giáº£m.
CÃ¢u há»i cá»§a em lÃ :
Liá»‡u hiá»‡n tÆ°á»£ng trÃªn Ä‘Ã¢y cÃ³ pháº£i lÃ  overfitting?
Náº¿u Ä‘Ãºng, táº¡i sao láº¡i cÃ³ hiá»‡n tÆ°á»£ng trÃªn? Bá»Ÿi pretrained model Ä‘Ã£ Ä‘Æ°á»£c train trÃªn táº­p dá»¯ liá»‡u ráº¥t lá»›n, hoÃ n toÃ n Ä‘á»§ kháº£ nÄƒng generalize trong pháº¡m vi cÃ¡c task cÃ³ liÃªn quan. Váº­y overfitting Ä‘áº¿n tá»« Ä‘Ã¢u?
Em cÃ³ thá»­ freeze háº¿t pháº§n pretrained, káº¿t quáº£ thu Ä‘Æ°á»£c trÃªn test set kÃ©m Ä‘i, vÃ  hiá»‡n tÆ°á»£ng trÃªn váº«n xáº£y ra. NÃ³i model overfit do má»—i layer cuá»‘i cÃ³ váº» khÃ´ng thá»a Ä‘Ã¡ng láº¯m.
Ráº¥t mong cÃ¡c anh chá»‹ giáº£i thÃ­ch giÃºp em cÃ¡c cÃ¢u há»i trÃªn. Náº¿u cÃ³ tÃ i liá»‡u nÃ o nghiÃªn cá»©u vá» hiá»‡n tÆ°á»£ng nÃ y vÃ  cÃ¡ch kháº¯c phá»¥c ná»¯a thÃ¬ cÃ ng tá»‘t áº¡.
Em xin cáº£m Æ¡n!","[ASK] OVERFITTING TRONG TRANSFER LEARNING ChÃ o cÃ¡c anh/chá»‹, NhÆ° em Ä‘Æ°á»£c há»c, overfitting lÃ  hiá»‡n tÆ°á»£ng dá»¯ liá»‡u training quÃ¡ nhá» vÃ  khÃ´ng Ä‘á»§ Ä‘á»ƒ khÃ¡i quÃ¡t hÃ³a cho nhá»¯ng dá»¯ liá»‡u má»›i; do Ä‘Ã³ thuáº­t toÃ¡n Ä‘Ã£ quÃ¡ fit vÃ o training set, khiáº¿n thá»±c táº¿ sá»­ dá»¥ng (metrics Ä‘o trÃªn test set) ráº¥t kÃ©m. Em Ä‘ang thá»­ nghiá»‡m fine-tune má»™t pretrained model Ä‘Ã£ Ä‘Æ°á»£c train trÃªn táº­p dá»¯ liá»‡u ráº¥t lá»›n vá»›i 1 task gáº§n vá»›i task mÃ  em mong muá»‘n. Cá»¥ thá»ƒ, em thÃªm 1 linear layer vá»›i Ä‘áº§u ra softmax vÃ o cuá»‘i, sau Ä‘Ã³ trÃªn model má»›i end-to-end vá»›i learning rate nhá». Táº­p dá»¯ liá»‡u dÃ nh cho fine-tune cá»§a em khÃ´ng lá»›n, chá»‰ khoáº£ng 4000 examples. Káº¿t quáº£: khi láº¥y weight á»Ÿ epoch cÃ³ val loss tháº¥p nháº¥t, metrics Ä‘o Ä‘Æ°á»£c trÃªn táº­p test khÃ¡ tá»‘t. Tuy nhiÃªn hiá»‡n tÆ°á»£ng giá»‘ng nhÆ° overfitting Ä‘Ã£ xáº£y ra: chá»‰ sau khoáº£ng 3 epoch, val loss báº¯t Ä‘áº§u tÄƒng trong khi train loss váº«n tiáº¿p tá»¥c giáº£m. CÃ¢u há»i cá»§a em lÃ : Liá»‡u hiá»‡n tÆ°á»£ng trÃªn Ä‘Ã¢y cÃ³ pháº£i lÃ  overfitting? Náº¿u Ä‘Ãºng, táº¡i sao láº¡i cÃ³ hiá»‡n tÆ°á»£ng trÃªn? Bá»Ÿi pretrained model Ä‘Ã£ Ä‘Æ°á»£c train trÃªn táº­p dá»¯ liá»‡u ráº¥t lá»›n, hoÃ n toÃ n Ä‘á»§ kháº£ nÄƒng generalize trong pháº¡m vi cÃ¡c task cÃ³ liÃªn quan. Váº­y overfitting Ä‘áº¿n tá»« Ä‘Ã¢u? Em cÃ³ thá»­ freeze háº¿t pháº§n pretrained, káº¿t quáº£ thu Ä‘Æ°á»£c trÃªn test set kÃ©m Ä‘i, vÃ  hiá»‡n tÆ°á»£ng trÃªn váº«n xáº£y ra. NÃ³i model overfit do má»—i layer cuá»‘i cÃ³ váº» khÃ´ng thá»a Ä‘Ã¡ng láº¯m. Ráº¥t mong cÃ¡c anh chá»‹ giáº£i thÃ­ch giÃºp em cÃ¡c cÃ¢u há»i trÃªn. Náº¿u cÃ³ tÃ i liá»‡u nÃ o nghiÃªn cá»©u vá» hiá»‡n tÆ°á»£ng nÃ y vÃ  cÃ¡ch kháº¯c phá»¥c ná»¯a thÃ¬ cÃ ng tá»‘t áº¡. Em xin cáº£m Æ¡n!",,,,,
"E chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i e Ä‘ang lÃ m bÃ i táº­p nháº­n dáº¡ng hÃ nh Ä‘á»™ng sd cáº£m biáº¿n Android báº±ng LSTM. E Ä‘Ã£ xuáº¥t model frozen.pb, nhÆ°ng khi Ä‘Æ°a vÃ o android thÃ¬ em bá»‹ lá»—i nÃ y. A/c nÃ o Ä‘Ã£ tá»«ng bá»‹ lá»—i nÃ y cho em cÃ¡ch kháº¯c phá»¥c áº¡ ! Em xin cáº£m Æ¡n","E chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i e Ä‘ang lÃ m bÃ i táº­p nháº­n dáº¡ng hÃ nh Ä‘á»™ng sd cáº£m biáº¿n Android báº±ng LSTM. E Ä‘Ã£ xuáº¥t model frozen.pb, nhÆ°ng khi Ä‘Æ°a vÃ o android thÃ¬ em bá»‹ lá»—i nÃ y. A/c nÃ o Ä‘Ã£ tá»«ng bá»‹ lá»—i nÃ y cho em cÃ¡ch kháº¯c phá»¥c áº¡ ! Em xin cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i,
HÃ´m trÆ°á»›c anh Khanh Blog cÃ³ há»i vá» project nÃ o crawl dá»¯ liá»‡u vá» tÃ i chÃ­nh á»Ÿ Viá»‡t Nam, em cÃ³ nhá»› Ä‘áº¿n má»™t dá»‹p báº¡n Viet Anh Tran va em cÃ³ lÃ m.
Em muá»‘n share public repo cá»§a báº¡n em Ä‘á»ƒ cho anh chá»‹ cÃ³ thá»ƒ sá»­ dá»¥ng. And shout out to my friend!","ChÃ o má»i ngÆ°á»i, HÃ´m trÆ°á»›c anh Khanh Blog cÃ³ há»i vá» project nÃ o crawl dá»¯ liá»‡u vá» tÃ i chÃ­nh á»Ÿ Viá»‡t Nam, em cÃ³ nhá»› Ä‘áº¿n má»™t dá»‹p báº¡n Viet Anh Tran va em cÃ³ lÃ m. Em muá»‘n share public repo cá»§a báº¡n em Ä‘á»ƒ cho anh chá»‹ cÃ³ thá»ƒ sá»­ dá»¥ng. And shout out to my friend!",,,,,
"ChaÌ€o moÌ£i nguÌ›oÌ›Ì€i,
Phoenix Team cuÌ‰a FUNiX xin chia seÌ‰ voÌ›Ìi caÌc baÌ£n source code cuÌ‰a nhoÌm oÌ›Ì‰ FPT Edu Hackathon 2021 Challenge.
NhoÌm coÌ tham khaÌ‰o yÌ tuÌ›oÌ›Ì‰ng tuÌ›Ì€ RANZCR CLiP - Catheter and Line Position Challenge treÌ‚n neÌ‚Ì€n taÌ‰ng Kaggle Ä‘eÌ‚Ì‰ xaÌ‚y duÌ›Ì£ng moÌ£Ì‚t uÌ›Ìng duÌ£ng coÌ theÌ‚Ì‰ giuÌp caÌc baÌc siÌƒ kieÌ‚Ì‰m tra tiÌ€nh traÌ£ng oÌ‚Ìng thoÌ›Ì‰ cuÌ‰a caÌc beÌ£Ì‚nh nhaÌ‚n nhanh hoÌ›n, chiÌnh xaÌc hoÌ›n vaÌ€ hieÌ£Ì‚u quaÌ‰ hoÌ›n.
Source code goÌ‚Ì€m 2 phaÌ‚Ì€n chiÌnh: Model vaÌ€ backend. PhaÌ‚Ì€n model, nhoÌm coÌ tham khaÌ‰o best solutions cuÌ‰a caÌc solution trong 20 baÌ£n top Ä‘aÌ‚Ì€u cuÌ‰a Kaggle Challenge:
https://github.com/thaiminhpv/Doctor-Cyclop-Hackathon-2021
PhaÌ‚Ì€n backend, nhoÌm coÌ suÌ›Ì‰ duÌ£ng moÌ£Ì‚t soÌ‚Ì coÌ‚ng ngheÌ£Ì‚: MeteorJS 2.1, NodeJS 12, MongoDB 4.2, AWS S3.
https://github.com/DAN3002/Doctors-Cyclop-Webapp
Web apps coÌ moÌ£Ì‚t soÌ‚Ì thieÌ‚Ìt keÌ‚Ì vaÌ€ tiÌnh naÌ†ng moÌ›Ì‰ roÌ£Ì‚ng Ä‘eÌ‚Ì‰ huÌ›oÌ›Ìng nguÌ›oÌ›Ì€i duÌ€ng apps (caÌc baÌc siÌƒ vaÌ€ chuyeÌ‚n gia) coÌ theÌ‚Ì‰:
TaÌ£Ì‚p trung chuÌ yÌ hoÌ›n vaÌ€o caÌc cases nguy hieÌ‚Ì‰m truÌ›oÌ›Ìc.
CoÌ baÌ‰ng phaÌ‚n tiÌch Ä‘aÌnh giaÌ moÌ£Ì‚t soÌ‚Ì thoÌ‚ng soÌ‚Ì coÌ› baÌ‰n, giuÌp iÌch cho vieÌ£Ì‚c phaÌ‚n tiÌch vaÌ€ Ä‘aÌnh giaÌ nhanh chuaÌ‚Ì‰n Ä‘oaÌn caÌ nhaÌ‚n cuÌ‰a miÌ€nh vaÌ€ xu huÌ›oÌ›Ìng chuaÌ‚Ì‰n Ä‘oaÌn chung.
NgoaÌ€i ra, app coÌ coÌ› cheÌ‚Ì relabel vaÌ€ phaÌ‚n caÌ‚Ìp triÌ€nh Ä‘oÌ£Ì‚ (thaÌ€nh 2 muÌ›Ìc, chuyeÌ‚n vieÌ‚n vaÌ€ chuyeÌ‚n gia), hoÌ‚Ìƒ troÌ›Ì£ vieÌ£Ì‚c Ä‘uÌ›a ra chuaÌ‚Ì‰n Ä‘oaÌn chiÌnh xaÌc hoÌ›n trong caÌc truÌ›oÌ›Ì€ng hoÌ›Ì£p nghi ngoÌ›Ì€.
BaÌ‰n demo cuÌ‰a nhoÌm coÌ€n xa moÌ›Ìi Ä‘aÌ£t Ä‘eÌ‚Ìn Ä‘uÌ›oÌ›Ì£c moÌ£Ì‚t saÌ‰n phaÌ‚Ì‰m AI hoaÌ€n chiÌ‰nh, nhuÌ›ng miÌ€nh nghiÌƒ seÌƒ laÌ€ moÌ£Ì‚t taÌ€i lieÌ£Ì‚u huÌ›Ìƒu iÌch cho caÌc baÌ£n sinh vieÌ‚n muoÌ‚Ìn voÌ£c vaÌ£ch tiÌ€m hieÌ‚Ì‰u veÌ‚Ì€ AI vaÌ€ MLOps.
ÄeÌ‚Ì‰ hieÌ‚Ì‰u roÌƒ hoÌ›n veÌ‚Ì€ app, caÌc baÌ£n coÌ theÌ‚Ì‰ xem video thuyeÌ‚Ìt triÌ€nh veÌ‚Ì€ app cuÌ‰a nhoÌm oÌ›Ì‰ Ä‘aÌ‚y:
https://www.youtube.com/watch?v=6-ee4TkQDLg
MoÌ£Ì‚t soÌ‚Ì huÌ›oÌ›Ìng phaÌt trieÌ‚Ì‰n tieÌ‚Ìp theo cuÌ‰a nhoÌm (caÌ‰ nhoÌm seÌƒ team up vaÌ€ tieÌ‚Ìp tuÌ£c hoaÌ€n thieÌ£Ì‚n sau kyÌ€ thi THPT quoÌ‚Ìc gia):
TiÌch hoÌ›Ì£p phaÌ‚Ì€n re-training vaÌ€o noÌ‚Ìi tieÌ‚Ìp voÌ›Ìi relabeling, giuÌp apps coÌ theÌ‚Ì‰ tuÌ›Ì£ Ä‘oÌ£Ì‚ng caÌ£Ì‚p nhaÌ£Ì‚t laÌ£i model moÌ£Ì‚t caÌch nhanh choÌng vaÌ€ hieÌ£Ì‚u quaÌ‰ hoÌ›n.
TiÌ€m hieÌ‚Ì‰u vaÌ€ Ä‘uÌ›a theÌ‚m caÌc phaÌ‚n tiÌch coÌ iÌch hoÌ›n voÌ›Ìi caÌc baÌc siÌƒ vaÌ€o apps.
CoÌ coÌ› cheÌ‚Ì luÌ›u truÌ›Ìƒ vaÌ€ baÌ‰o maÌ£Ì‚t duÌ›Ìƒ lieÌ£Ì‚u toÌ‚Ìt hoÌ›n (tiÌch hoÌ›Ì£p theÌ‚m smart contract vaÌ€o).
â€¦
NhoÌm goÌ‚Ì€m 4 thaÌ€nh vieÌ‚n ÄÃ¬nh Anh Nguyá»…n Linh Phuong Pháº¡m VÅ© ThÃ¡i Minh laÌ€ caÌc baÌ£n hoÌ£c sinh caÌ‚Ìp 3, hieÌ£Ì‚n taÌ£i Ä‘ang hoÌ£c taÌ£i FUNiX . CaÌc baÌ£n coÌ caÌ‚u hoÌ‰i hay thaÌ†Ìc maÌ†Ìc giÌ€ cuÌ›Ì Ä‘aÌ£Ì†t caÌ‚u hoÌ‰i duÌ›oÌ›Ìi topic naÌ€y hoaÌ£Ì†c trong phaÌ‚Ì€n â€œissueâ€ cuÌ‰a git, chuÌng miÌ€nh seÌƒ coÌ‚Ì gaÌ†Ìng traÌ‰ loÌ›Ì€i heÌ‚Ìt caÌc thaÌ†Ìc maÌ†Ìc.
Ha Na Nguyen
P/S: Trung taÌ‚m nghieÌ‚n cuÌ›Ìu vaÌ€ uÌ›Ìng duÌ£ng AI - QAI (FPT Software Quy NhoÌ›n) Ä‘ang trao chuÌ›oÌ›ng triÌ€nh hoÌ£c boÌ‚Ì‰ng Machine Learning vaÌ€ Data Science daÌ€nh cho 200 hoÌ£c vieÌ‚n voÌ›Ìi cam keÌ‚Ìt coÌ‚ng vieÌ£Ì‚c Ä‘aÌ‚Ì€u ra voÌ›Ìi muÌ›Ìc luÌ›oÌ›ng vaÌ€ Ä‘aÌƒi ngoÌ£Ì‚ haÌ‚Ìp daÌ‚Ìƒn. ToaÌ€n boÌ£Ì‚ chuÌ›oÌ›ng triÌ€nh hoÌ£c boÌ‚Ì‰ng voÌ›Ìi QAI seÌƒ Ä‘uÌ›oÌ›Ì£c phuÌ£ traÌch boÌ›Ì‰i Ä‘oÌ£Ì‚i nguÌƒ mentor kinh nghieÌ£Ì‚m tuÌ›Ì€ Funix. CaÌc baÌ£n quan taÌ‚m coÌ theÌ‚Ì‰ thuÌ›Ì‰ suÌ›Ìc ngay taÌ£i Ä‘uÌ›oÌ›Ì€ng link naÌ€y nheÌ:
https://forms.gle/UFZMWBfPqtjYnKtQA
ÄaÌ†ng kyÌ ngay Ä‘eÌ‚Ì‰ troÌ›Ì‰ thaÌ€nh nhuÌ›Ìƒng uÌ›Ìng vieÌ‚n AI taÌ€i naÌ†ng trong thoÌ›Ì€i gian soÌ›Ìm nhaÌ‚Ìt!","ChaÌ€o moÌ£i nguÌ›oÌ›Ì€i, Phoenix Team cuÌ‰a FUNiX xin chia seÌ‰ voÌ›Ìi caÌc baÌ£n source code cuÌ‰a nhoÌm oÌ›Ì‰ FPT Edu Hackathon 2021 Challenge. NhoÌm coÌ tham khaÌ‰o yÌ tuÌ›oÌ›Ì‰ng tuÌ›Ì€ RANZCR CLiP - Catheter and Line Position Challenge treÌ‚n neÌ‚Ì€n taÌ‰ng Kaggle Ä‘eÌ‚Ì‰ xaÌ‚y duÌ›Ì£ng moÌ£Ì‚t uÌ›Ìng duÌ£ng coÌ theÌ‚Ì‰ giuÌp caÌc baÌc siÌƒ kieÌ‚Ì‰m tra tiÌ€nh traÌ£ng oÌ‚Ìng thoÌ›Ì‰ cuÌ‰a caÌc beÌ£Ì‚nh nhaÌ‚n nhanh hoÌ›n, chiÌnh xaÌc hoÌ›n vaÌ€ hieÌ£Ì‚u quaÌ‰ hoÌ›n. Source code goÌ‚Ì€m 2 phaÌ‚Ì€n chiÌnh: Model vaÌ€ backend. PhaÌ‚Ì€n model, nhoÌm coÌ tham khaÌ‰o best solutions cuÌ‰a caÌc solution trong 20 baÌ£n top Ä‘aÌ‚Ì€u cuÌ‰a Kaggle Challenge: https://github.com/thaiminhpv/Doctor-Cyclop-Hackathon-2021 PhaÌ‚Ì€n backend, nhoÌm coÌ suÌ›Ì‰ duÌ£ng moÌ£Ì‚t soÌ‚Ì coÌ‚ng ngheÌ£Ì‚: MeteorJS 2.1, NodeJS 12, MongoDB 4.2, AWS S3. https://github.com/DAN3002/Doctors-Cyclop-Webapp Web apps coÌ moÌ£Ì‚t soÌ‚Ì thieÌ‚Ìt keÌ‚Ì vaÌ€ tiÌnh naÌ†ng moÌ›Ì‰ roÌ£Ì‚ng Ä‘eÌ‚Ì‰ huÌ›oÌ›Ìng nguÌ›oÌ›Ì€i duÌ€ng apps (caÌc baÌc siÌƒ vaÌ€ chuyeÌ‚n gia) coÌ theÌ‚Ì‰: TaÌ£Ì‚p trung chuÌ yÌ hoÌ›n vaÌ€o caÌc cases nguy hieÌ‚Ì‰m truÌ›oÌ›Ìc. CoÌ baÌ‰ng phaÌ‚n tiÌch Ä‘aÌnh giaÌ moÌ£Ì‚t soÌ‚Ì thoÌ‚ng soÌ‚Ì coÌ› baÌ‰n, giuÌp iÌch cho vieÌ£Ì‚c phaÌ‚n tiÌch vaÌ€ Ä‘aÌnh giaÌ nhanh chuaÌ‚Ì‰n Ä‘oaÌn caÌ nhaÌ‚n cuÌ‰a miÌ€nh vaÌ€ xu huÌ›oÌ›Ìng chuaÌ‚Ì‰n Ä‘oaÌn chung. NgoaÌ€i ra, app coÌ coÌ› cheÌ‚Ì relabel vaÌ€ phaÌ‚n caÌ‚Ìp triÌ€nh Ä‘oÌ£Ì‚ (thaÌ€nh 2 muÌ›Ìc, chuyeÌ‚n vieÌ‚n vaÌ€ chuyeÌ‚n gia), hoÌ‚Ìƒ troÌ›Ì£ vieÌ£Ì‚c Ä‘uÌ›a ra chuaÌ‚Ì‰n Ä‘oaÌn chiÌnh xaÌc hoÌ›n trong caÌc truÌ›oÌ›Ì€ng hoÌ›Ì£p nghi ngoÌ›Ì€. BaÌ‰n demo cuÌ‰a nhoÌm coÌ€n xa moÌ›Ìi Ä‘aÌ£t Ä‘eÌ‚Ìn Ä‘uÌ›oÌ›Ì£c moÌ£Ì‚t saÌ‰n phaÌ‚Ì‰m AI hoaÌ€n chiÌ‰nh, nhuÌ›ng miÌ€nh nghiÌƒ seÌƒ laÌ€ moÌ£Ì‚t taÌ€i lieÌ£Ì‚u huÌ›Ìƒu iÌch cho caÌc baÌ£n sinh vieÌ‚n muoÌ‚Ìn voÌ£c vaÌ£ch tiÌ€m hieÌ‚Ì‰u veÌ‚Ì€ AI vaÌ€ MLOps. ÄeÌ‚Ì‰ hieÌ‚Ì‰u roÌƒ hoÌ›n veÌ‚Ì€ app, caÌc baÌ£n coÌ theÌ‚Ì‰ xem video thuyeÌ‚Ìt triÌ€nh veÌ‚Ì€ app cuÌ‰a nhoÌm oÌ›Ì‰ Ä‘aÌ‚y: https://www.youtube.com/watch?v=6-ee4TkQDLg MoÌ£Ì‚t soÌ‚Ì huÌ›oÌ›Ìng phaÌt trieÌ‚Ì‰n tieÌ‚Ìp theo cuÌ‰a nhoÌm (caÌ‰ nhoÌm seÌƒ team up vaÌ€ tieÌ‚Ìp tuÌ£c hoaÌ€n thieÌ£Ì‚n sau kyÌ€ thi THPT quoÌ‚Ìc gia): TiÌch hoÌ›Ì£p phaÌ‚Ì€n re-training vaÌ€o noÌ‚Ìi tieÌ‚Ìp voÌ›Ìi relabeling, giuÌp apps coÌ theÌ‚Ì‰ tuÌ›Ì£ Ä‘oÌ£Ì‚ng caÌ£Ì‚p nhaÌ£Ì‚t laÌ£i model moÌ£Ì‚t caÌch nhanh choÌng vaÌ€ hieÌ£Ì‚u quaÌ‰ hoÌ›n. TiÌ€m hieÌ‚Ì‰u vaÌ€ Ä‘uÌ›a theÌ‚m caÌc phaÌ‚n tiÌch coÌ iÌch hoÌ›n voÌ›Ìi caÌc baÌc siÌƒ vaÌ€o apps. CoÌ coÌ› cheÌ‚Ì luÌ›u truÌ›Ìƒ vaÌ€ baÌ‰o maÌ£Ì‚t duÌ›Ìƒ lieÌ£Ì‚u toÌ‚Ìt hoÌ›n (tiÌch hoÌ›Ì£p theÌ‚m smart contract vaÌ€o). â€¦ NhoÌm goÌ‚Ì€m 4 thaÌ€nh vieÌ‚n ÄÃ¬nh Anh Nguyá»…n Linh Phuong Pháº¡m VÅ© ThÃ¡i Minh laÌ€ caÌc baÌ£n hoÌ£c sinh caÌ‚Ìp 3, hieÌ£Ì‚n taÌ£i Ä‘ang hoÌ£c taÌ£i FUNiX . CaÌc baÌ£n coÌ caÌ‚u hoÌ‰i hay thaÌ†Ìc maÌ†Ìc giÌ€ cuÌ›Ì Ä‘aÌ£Ì†t caÌ‚u hoÌ‰i duÌ›oÌ›Ìi topic naÌ€y hoaÌ£Ì†c trong phaÌ‚Ì€n â€œissueâ€ cuÌ‰a git, chuÌng miÌ€nh seÌƒ coÌ‚Ì gaÌ†Ìng traÌ‰ loÌ›Ì€i heÌ‚Ìt caÌc thaÌ†Ìc maÌ†Ìc. Ha Na Nguyen P/S: Trung taÌ‚m nghieÌ‚n cuÌ›Ìu vaÌ€ uÌ›Ìng duÌ£ng AI - QAI (FPT Software Quy NhoÌ›n) Ä‘ang trao chuÌ›oÌ›ng triÌ€nh hoÌ£c boÌ‚Ì‰ng Machine Learning vaÌ€ Data Science daÌ€nh cho 200 hoÌ£c vieÌ‚n voÌ›Ìi cam keÌ‚Ìt coÌ‚ng vieÌ£Ì‚c Ä‘aÌ‚Ì€u ra voÌ›Ìi muÌ›Ìc luÌ›oÌ›ng vaÌ€ Ä‘aÌƒi ngoÌ£Ì‚ haÌ‚Ìp daÌ‚Ìƒn. ToaÌ€n boÌ£Ì‚ chuÌ›oÌ›ng triÌ€nh hoÌ£c boÌ‚Ì‰ng voÌ›Ìi QAI seÌƒ Ä‘uÌ›oÌ›Ì£c phuÌ£ traÌch boÌ›Ì‰i Ä‘oÌ£Ì‚i nguÌƒ mentor kinh nghieÌ£Ì‚m tuÌ›Ì€ Funix. CaÌc baÌ£n quan taÌ‚m coÌ theÌ‚Ì‰ thuÌ›Ì‰ suÌ›Ìc ngay taÌ£i Ä‘uÌ›oÌ›Ì€ng link naÌ€y nheÌ: https://forms.gle/UFZMWBfPqtjYnKtQA ÄaÌ†ng kyÌ ngay Ä‘eÌ‚Ì‰ troÌ›Ì‰ thaÌ€nh nhuÌ›Ìƒng uÌ›Ìng vieÌ‚n AI taÌ€i naÌ†ng trong thoÌ›Ì€i gian soÌ›Ìm nhaÌ‚Ìt!",,,,,
"#Checkpoint #deploy 

Hi moÌ£i ngÆ°Æ¡Ì€i, 
HiÃªÌ£n taÌ£i em Ä‘ang deploy mÃ´Ì£t backend server - ( ÄaÌ£i khaÌi laÌ€ push source code lÃªn git hub). Trong Ä‘oÌ, source em coÌ lÆ°u trÆ°Ìƒ 1 "" checkpoint.pth"" ( push lÃªn bÄƒÌ€ng git lfs ). 
VÃ¢Ìn Ä‘ÃªÌ€ xaÌ‰y ra khi code goÌ£i:
 model.load_state_dict(""Ä‘Æ°Æ¡Ì€ng dÃ¢Ìƒn tÆ¡Ìi checkpoint.pth trong github"")
XuÃ¢Ìt hiÃªÌ£n lÃ´Ìƒi :
UnpicklingError at / : invalid load key, 'v'.
Em coÌ tiÌ€m hiÃªÌ‰u vaÌ€ coÌ thÃªÌ‰ hiÃªÌ‰u laÌ€ git lfs seÌƒ down mÃ´Ì£t file neÌn vÃªÌ€ khi ta truy cÃ¢Ì£p file large tÆ°Ì€ code => load_state_dict lÃ´Ìƒi.
Em vÃ¢Ìƒn chÆ°a tiÌ€m ra hÆ°Æ¡Ìng giaÌ‰i quyÃªÌt. mong moÌ£i ngÆ°Æ¡Ì€i nÃªÌu xÆ°Ì‰ lyÌ Ä‘Æ°Æ¡Ì£c mong giuÌp em vÆ¡Ìi aÌ£!

ChuÌc group sÆ°Ìc khoÌ‰e muÌ€a covid! 
CaÌ‰m Æ¡n mn!","Hi moÌ£i ngÆ°Æ¡Ì€i, HiÃªÌ£n taÌ£i em Ä‘ang deploy mÃ´Ì£t backend server - ( ÄaÌ£i khaÌi laÌ€ push source code lÃªn git hub). Trong Ä‘oÌ, source em coÌ lÆ°u trÆ°Ìƒ 1 "" checkpoint.pth"" ( push lÃªn bÄƒÌ€ng git lfs ). VÃ¢Ìn Ä‘ÃªÌ€ xaÌ‰y ra khi code goÌ£i: model.load_state_dict(""Ä‘Æ°Æ¡Ì€ng dÃ¢Ìƒn tÆ¡Ìi checkpoint.pth trong github"") XuÃ¢Ìt hiÃªÌ£n lÃ´Ìƒi : UnpicklingError at / : invalid load key, 'v'. Em coÌ tiÌ€m hiÃªÌ‰u vaÌ€ coÌ thÃªÌ‰ hiÃªÌ‰u laÌ€ git lfs seÌƒ down mÃ´Ì£t file neÌn vÃªÌ€ khi ta truy cÃ¢Ì£p file large tÆ°Ì€ code => load_state_dict lÃ´Ìƒi. Em vÃ¢Ìƒn chÆ°a tiÌ€m ra hÆ°Æ¡Ìng giaÌ‰i quyÃªÌt. mong moÌ£i ngÆ°Æ¡Ì€i nÃªÌu xÆ°Ì‰ lyÌ Ä‘Æ°Æ¡Ì£c mong giuÌp em vÆ¡Ìi aÌ£! ChuÌc group sÆ°Ìc khoÌ‰e muÌ€a covid! CaÌ‰m Æ¡n mn!",#Checkpoint	#deploy,,,,
"TraDeS - Track to Detect and Segment lÃ  1 paper Ä‘Æ°á»£c accept táº¡i CVPR nÄƒm nay, thuá»™c lÄ©nh vá»±c Mutilple Object Tracking. Hiá»‡n TraDeS Ä‘ang Ä‘á»©ng top 2  trÃªn Paperwithcode vá»›i 2 bá»™ dá»¯ liá»‡u MOT16 vÃ  MOT17. 
Sau 1 thá»i gian Ä‘á»c vÃ  tÃ¬m hiá»ƒu, mÃ¬nh cÃ³ viáº¿t 1 bÃ i phÃ¢n tÃ­ch nhá», nÃªu ra nhá»¯ng tÆ° tÆ°á»Ÿng vÃ  cáº£i tiáº¿n ná»•i báº­t cá»§a TraDeS. Hi vá»ng bÃ i viáº¿t há»¯u Ã­ch vá»›i mn ^^
TraDeS giá»›i thiá»‡u má»™t Tracking-conditioned-Detection end-to-end máº¡nh máº½, cho phÃ©p sá»­ dá»¥ng cÃ¡c káº¿t quáº£ tracking Ä‘á»ƒ cáº£i thiá»‡n performance cá»§a detection, Ä‘á»“ng thá»i cÅ©ng tÄƒng hiá»‡u quáº£ tracking (TÆ°Æ¡ng tá»± CenterTrack nhÆ°ng máº¡nh máº½ hÆ¡n) .
TraDeS Ä‘Æ°a ra hÆ°á»›ng tiáº¿p cáº­n má»›i, sá»­ dá»¥ng Cost Volume giÃºp Ä‘áº£m báº£o viá»‡c trainning Ä‘á»“ng thá»i re-id embedding vÃ  detection mÃ  khÃ´ng bá»‹ conflict (Chi tiáº¿t Ä‘á»c pháº§n CVA).
TraDeS trÃ¬nh bÃ y vá» MFW, má»™t module cho phÃ©p lan truyá»n cÃ¡c feature trong quÃ¡ khá»© Ä‘á»ƒ tÄƒng cÆ°á»ng cÃ¡c feature hiá»‡n táº¡i.
TraDeS sá»­ dá»¥ng data association vá»›i 2 pha, cho phÃ©p theo dÃµi ngáº¯n háº¡n vÃ  dÃ i háº¡n, giÃºp giáº£m IDSWs.
Source code cá»§a TraDeS Ä‘Æ°á»£c base vÃ  chá»‰nh sá»­a tá»« source code cá»§a CenterTrack: https://github.com/JialianW/TraDeS
Paper: https://arxiv.org/pdf/2103.08808v1.pdf

Chi tiáº¿t hÆ¡n, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm á»Ÿ link bÃ i viáº¿t bÃªn dÆ°á»›i ...
https://viblo.asia/p/centernet-centertrack-trades-tu-object-detection-den-multiple-object-tracking-jvEla9Molkw#comment-rLZDmzOx3lk","TraDeS - Track to Detect and Segment lÃ  1 paper Ä‘Æ°á»£c accept táº¡i CVPR nÄƒm nay, thuá»™c lÄ©nh vá»±c Mutilple Object Tracking. Hiá»‡n TraDeS Ä‘ang Ä‘á»©ng top 2 trÃªn Paperwithcode vá»›i 2 bá»™ dá»¯ liá»‡u MOT16 vÃ  MOT17. Sau 1 thá»i gian Ä‘á»c vÃ  tÃ¬m hiá»ƒu, mÃ¬nh cÃ³ viáº¿t 1 bÃ i phÃ¢n tÃ­ch nhá», nÃªu ra nhá»¯ng tÆ° tÆ°á»Ÿng vÃ  cáº£i tiáº¿n ná»•i báº­t cá»§a TraDeS. Hi vá»ng bÃ i viáº¿t há»¯u Ã­ch vá»›i mn ^^ TraDeS giá»›i thiá»‡u má»™t Tracking-conditioned-Detection end-to-end máº¡nh máº½, cho phÃ©p sá»­ dá»¥ng cÃ¡c káº¿t quáº£ tracking Ä‘á»ƒ cáº£i thiá»‡n performance cá»§a detection, Ä‘á»“ng thá»i cÅ©ng tÄƒng hiá»‡u quáº£ tracking (TÆ°Æ¡ng tá»± CenterTrack nhÆ°ng máº¡nh máº½ hÆ¡n) . TraDeS Ä‘Æ°a ra hÆ°á»›ng tiáº¿p cáº­n má»›i, sá»­ dá»¥ng Cost Volume giÃºp Ä‘áº£m báº£o viá»‡c trainning Ä‘á»“ng thá»i re-id embedding vÃ  detection mÃ  khÃ´ng bá»‹ conflict (Chi tiáº¿t Ä‘á»c pháº§n CVA). TraDeS trÃ¬nh bÃ y vá» MFW, má»™t module cho phÃ©p lan truyá»n cÃ¡c feature trong quÃ¡ khá»© Ä‘á»ƒ tÄƒng cÆ°á»ng cÃ¡c feature hiá»‡n táº¡i. TraDeS sá»­ dá»¥ng data association vá»›i 2 pha, cho phÃ©p theo dÃµi ngáº¯n háº¡n vÃ  dÃ i háº¡n, giÃºp giáº£m IDSWs. Source code cá»§a TraDeS Ä‘Æ°á»£c base vÃ  chá»‰nh sá»­a tá»« source code cá»§a CenterTrack: https://github.com/JialianW/TraDeS Paper: https://arxiv.org/pdf/2103.08808v1.pdf Chi tiáº¿t hÆ¡n, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm á»Ÿ link bÃ i viáº¿t bÃªn dÆ°á»›i ... https://viblo.asia/p/centernet-centertrack-trades-tu-object-detection-den-multiple-object-tracking-jvEla9Molkw#comment-rLZDmzOx3lk",,,,,
"ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang cÃ³ dá»± Ä‘á»‹nh lÃ m má»™t á»©ng dá»¥ng cho phÃ©p táº£i 1 Ä‘oáº¡n text lÃªn vÃ  convert sang thÃ nh 1 file áº£nh giá»‘ng nhÆ° chá»¯ viáº¿t tay vá»›i ná»™i dung tá»« Ä‘oáº¡n text Ä‘Ã³. BÃ¡c nÃ o Ä‘Ã£ lÃ m cÃ¡i tÆ°Æ¡ng tá»± nÃ y cÃ³ thá»ƒ cho em xin má»™t Ã­t tá»« khoÃ¡ hoáº·c giáº£i phÃ¡p Ä‘á»ƒ nghiÃªn cá»©u áº¡.
VÃ­ dá»¥:
â€œNáº¿u báº¡n khÃ´ng thá»ƒ sÃ¡ng táº¡o thÃ¬ hÃ£y thá»­ báº¯t chÆ°á»›c theo ngÆ°á»i khÃ¡câ€¦..â€ sáº½ convert thÃ nh áº£nh nhÆ° sau
Ps. CÃ¡c bÃ¡c Ä‘á»«ng xui em táº¡o font chá»¯ rá»“i Ã¡nh xáº¡ 1:1 sang áº¡. CÃ¡i output em muá»‘n trÃ´ng nÃ³ pháº£i tá»± nhiÃªn - con ngÆ°á»i khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c( cÃ¡c chá»¯ cÃ¡i khÃ¡c nhau nhÆ° viáº¿t tay). Ã lÃ  má»—i má»™t láº§n generate tá»« má»™t input láº¡i cho ra 2 output khÃ¡c nhau, lÃ  tá»« thuáº­t toÃ¡n váº½ ra chá»¯ cÃ¡i chá»© khÃ´ng pháº£i láº¥y chá»¯ cÃ¡i cÃ³ sáºµn rá»“i láº¥y ra ghÃ©p vÃ o vá»›i nhau. Tuy nhiÃªn váº«n pháº£i nháº­n ra lÃ  nÃ©t chá»¯ cá»§a cÃ¹ng 1 ngÆ°á»i áº¡.","ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang cÃ³ dá»± Ä‘á»‹nh lÃ m má»™t á»©ng dá»¥ng cho phÃ©p táº£i 1 Ä‘oáº¡n text lÃªn vÃ  convert sang thÃ nh 1 file áº£nh giá»‘ng nhÆ° chá»¯ viáº¿t tay vá»›i ná»™i dung tá»« Ä‘oáº¡n text Ä‘Ã³. BÃ¡c nÃ o Ä‘Ã£ lÃ m cÃ¡i tÆ°Æ¡ng tá»± nÃ y cÃ³ thá»ƒ cho em xin má»™t Ã­t tá»« khoÃ¡ hoáº·c giáº£i phÃ¡p Ä‘á»ƒ nghiÃªn cá»©u áº¡. VÃ­ dá»¥: â€œNáº¿u báº¡n khÃ´ng thá»ƒ sÃ¡ng táº¡o thÃ¬ hÃ£y thá»­ báº¯t chÆ°á»›c theo ngÆ°á»i khÃ¡câ€¦..â€ sáº½ convert thÃ nh áº£nh nhÆ° sau Ps. CÃ¡c bÃ¡c Ä‘á»«ng xui em táº¡o font chá»¯ rá»“i Ã¡nh xáº¡ 1:1 sang áº¡. CÃ¡i output em muá»‘n trÃ´ng nÃ³ pháº£i tá»± nhiÃªn - con ngÆ°á»i khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c( cÃ¡c chá»¯ cÃ¡i khÃ¡c nhau nhÆ° viáº¿t tay). Ã lÃ  má»—i má»™t láº§n generate tá»« má»™t input láº¡i cho ra 2 output khÃ¡c nhau, lÃ  tá»« thuáº­t toÃ¡n váº½ ra chá»¯ cÃ¡i chá»© khÃ´ng pháº£i láº¥y chá»¯ cÃ¡i cÃ³ sáºµn rá»“i láº¥y ra ghÃ©p vÃ o vá»›i nhau. Tuy nhiÃªn váº«n pháº£i nháº­n ra lÃ  nÃ©t chá»¯ cá»§a cÃ¹ng 1 ngÆ°á»i áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i, chuyá»‡n lÃ  em muá»‘n tham kháº£o thá»­ Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» cÃ¢u há»i sau:
VÃ­ dá»¥ em cÃ³ bÃ i toÃ¡n Human detection dÃ¹ng backbone CNN,
TH1: Data cá»§a em lÃ  cÃ¡c bá»©c áº£nh cÃ³ ngÆ°á»i xa khoáº£ng 50m -> model A
TH2: Data cá»§a em lÃ  cÃ¡c bá»©c áº£nh cÃ³ ngÆ°á»i xa khoáº£ng 100m -> model B
CÃ¢u há»i:
1) Náº¿u láº¥y A inference trÃªn data B vÃ  ngÆ°á»£c láº¡i B inference trÃªn data A thÃ¬ sao? (performance, accuracy)
2) Náº¿u em muá»‘n cÃ³ 1 model adapt Ä‘Æ°á»£c cáº£ 2 loáº¡i data trÃªn thÃ¬ cÃ³ pháº£i em cáº§n:
+ Gá»™p 2 loáº¡i data (khÃ´ng cáº§n tÄƒng thÃªm)
+ Giáº£m sá»‘ layer Ä‘á»ƒ hÃ m sá»‘ cáº§n tÃ¬m generalizer hÆ¡n?
Cáº£m Æ¡n má»i ngÆ°á»i.
(Em Ä‘Ã£ tham kháº£o má»™t sá»‘ Ã½ kiáº¿n nhÆ°ng em muá»‘n Ä‘Æ°á»£c nghe chia sáº» thÃªm áº¡!)","ChÃ o má»i ngÆ°á»i, chuyá»‡n lÃ  em muá»‘n tham kháº£o thá»­ Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» cÃ¢u há»i sau: VÃ­ dá»¥ em cÃ³ bÃ i toÃ¡n Human detection dÃ¹ng backbone CNN, TH1: Data cá»§a em lÃ  cÃ¡c bá»©c áº£nh cÃ³ ngÆ°á»i xa khoáº£ng 50m -> model A TH2: Data cá»§a em lÃ  cÃ¡c bá»©c áº£nh cÃ³ ngÆ°á»i xa khoáº£ng 100m -> model B CÃ¢u há»i: 1) Náº¿u láº¥y A inference trÃªn data B vÃ  ngÆ°á»£c láº¡i B inference trÃªn data A thÃ¬ sao? (performance, accuracy) 2) Náº¿u em muá»‘n cÃ³ 1 model adapt Ä‘Æ°á»£c cáº£ 2 loáº¡i data trÃªn thÃ¬ cÃ³ pháº£i em cáº§n: + Gá»™p 2 loáº¡i data (khÃ´ng cáº§n tÄƒng thÃªm) + Giáº£m sá»‘ layer Ä‘á»ƒ hÃ m sá»‘ cáº§n tÃ¬m generalizer hÆ¡n? Cáº£m Æ¡n má»i ngÆ°á»i. (Em Ä‘Ã£ tham kháº£o má»™t sá»‘ Ã½ kiáº¿n nhÆ°ng em muá»‘n Ä‘Æ°á»£c nghe chia sáº» thÃªm áº¡!)",,,,,
"ChÃ o cÃ¡c bÃ¡c,
KhÃ´ng biáº¿t cÃ³ bÃ¡c nÃ o gáº·p issue giá»‘ng em khÃ´ng :(
Em cáº§n nhÃºng 1 model sá»­ dá»¥ng cÃ¡c layer cá»§a tensorflow2 trÃªn pháº§n cá»©ng cá»§a Xilinx. Tuy nhiÃªn bá»n Vitis AI cá»§a Xilinx chá»‰ support háº¡n cháº¿ má»™t sá»‘ layers cá»§a tensorflow ( Page 62-63 cá»§a Guide nÃ y: https://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_3/ug1414-vitis-ai.pdf)
Váº­y cÃ³ cÃ¡ch nÃ o táº¡o ra layer má»›i (Ä‘Æ°á»£c tensorflow2 support) dá»±a trÃªn viá»‡c tá»• há»£p cÃ¡c layer Ä‘Æ°á»£c Vitis support ko áº¡?
VÃ­ dá»¥: Trong model cá»§a em cÃ³ GlobalMaxPool2D, nhÆ°ng Vitis ko há»— trá»£, thÃ¬ cÃ³ thá»ƒ tá»• há»£p ra layer trÃªn báº±ng cÃ¡c layer mÃ  Vitis support ko áº¡?
HÃ¬nh dÆ°á»›i lÃ  list cÃ¡c layers mÃ  Vitis suport trÃªn tersorflow2 áº¡.
Cáº£m Æ¡n cÃ¡c bÃ¡c áº¡!
#Replace_layers
#Xilinx
#Vai_q_tensorflow2","ChÃ o cÃ¡c bÃ¡c, KhÃ´ng biáº¿t cÃ³ bÃ¡c nÃ o gáº·p issue giá»‘ng em khÃ´ng :( Em cáº§n nhÃºng 1 model sá»­ dá»¥ng cÃ¡c layer cá»§a tensorflow2 trÃªn pháº§n cá»©ng cá»§a Xilinx. Tuy nhiÃªn bá»n Vitis AI cá»§a Xilinx chá»‰ support háº¡n cháº¿ má»™t sá»‘ layers cá»§a tensorflow ( Page 62-63 cá»§a Guide nÃ y: https://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_3/ug1414-vitis-ai.pdf) Váº­y cÃ³ cÃ¡ch nÃ o táº¡o ra layer má»›i (Ä‘Æ°á»£c tensorflow2 support) dá»±a trÃªn viá»‡c tá»• há»£p cÃ¡c layer Ä‘Æ°á»£c Vitis support ko áº¡? VÃ­ dá»¥: Trong model cá»§a em cÃ³ GlobalMaxPool2D, nhÆ°ng Vitis ko há»— trá»£, thÃ¬ cÃ³ thá»ƒ tá»• há»£p ra layer trÃªn báº±ng cÃ¡c layer mÃ  Vitis support ko áº¡? HÃ¬nh dÆ°á»›i lÃ  list cÃ¡c layers mÃ  Vitis suport trÃªn tersorflow2 áº¡. Cáº£m Æ¡n cÃ¡c bÃ¡c áº¡!",#Replace_layers	#Xilinx	#Vai_q_tensorflow2,,,,
"ChÃ o cÃ¡c bÃ¡c em Ä‘ang cÃ³ má»™t tháº¯c máº¯c: CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ YOLO v3,4,5 nháº­n diá»‡n trá»±c tiáº¿p realtime vá»›i Ä‘áº§u vÃ o tá»« mÃ n hÃ¬nh mÃ¡y tÃ­nh nhÆ° Ä‘á»‘i vá»›i webcam khÃ´ng. á» Ä‘Ã¢y em tháº¥y má»™t chÆ°Æ¡ng trÃ¬nh ghi mÃ n hÃ¬nh nhÆ°ng khÃ´ng rÃµ chuyá»ƒn lÃ m Ä‘áº§u vÃ o ntn mong cÃ¡c bÃ¡c giÃºp Ä‘á»¡.(https://stackoverflow.com/questions/8074595/screen-recorder-in-python)","ChÃ o cÃ¡c bÃ¡c em Ä‘ang cÃ³ má»™t tháº¯c máº¯c: CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ YOLO v3,4,5 nháº­n diá»‡n trá»±c tiáº¿p realtime vá»›i Ä‘áº§u vÃ o tá»« mÃ n hÃ¬nh mÃ¡y tÃ­nh nhÆ° Ä‘á»‘i vá»›i webcam khÃ´ng. á» Ä‘Ã¢y em tháº¥y má»™t chÆ°Æ¡ng trÃ¬nh ghi mÃ n hÃ¬nh nhÆ°ng khÃ´ng rÃµ chuyá»ƒn lÃ m Ä‘áº§u vÃ o ntn mong cÃ¡c bÃ¡c giÃºp Ä‘á»¡.(https://stackoverflow.com/questions/8074595/screen-recorder-in-python)",,,,,
"AWS Machine Learning Scholarship Program

AWS and Udacity are collaborating to educate developers of all skill levels on machine learning concepts. We invite students 18 years of age or older who are interested in expanding their machine learning skills and expertise to enroll in the AWS Machine Learning Scholarship Program. The goal for this program is to up-level machine learning skills to all, and to cultivate the next generation of ML leaders across the world, with a focus on underrepresented groups. Through its We Power Tech Program, AWS collaborates with professional organizations that are leading initiatives to increase the diversity and talent in technical roles, including organizations like Girls In Tech and the National Society of Black Engineers.

The scholarship is open to all for registration starting May 26, 2021, and your learning will begin on June 28, 2021. Participants will have up to 3.5 months to complete the AWS Machine Learning Foundations Course. The course covers the fundamentals of machine learning, steps in machine learning process, basics of computer vision, reinforcement learning, generative AI, software engineering best practices for data science, and how to build your own python package. The foundations course is intended to help developers of all skill levels get started with machine learning.

At the end of the AWS Machine Learning Foundations Course, learners will take an assessment from which top performers will be selected for one of 425 follow-up scholarships to one of Udacityâ€™s most popular and recently refreshed Nanodegree programs: The AWS Machine Learning Engineer Nanodegree program.
Link : https://www.udacity.com/scholarships/aws-machine-learning-scholarship-program
#machinelearning #scholarship","AWS Machine Learning Scholarship Program AWS and Udacity are collaborating to educate developers of all skill levels on machine learning concepts. We invite students 18 years of age or older who are interested in expanding their machine learning skills and expertise to enroll in the AWS Machine Learning Scholarship Program. The goal for this program is to up-level machine learning skills to all, and to cultivate the next generation of ML leaders across the world, with a focus on underrepresented groups. Through its We Power Tech Program, AWS collaborates with professional organizations that are leading initiatives to increase the diversity and talent in technical roles, including organizations like Girls In Tech and the National Society of Black Engineers. The scholarship is open to all for registration starting May 26, 2021, and your learning will begin on June 28, 2021. Participants will have up to 3.5 months to complete the AWS Machine Learning Foundations Course. The course covers the fundamentals of machine learning, steps in machine learning process, basics of computer vision, reinforcement learning, generative AI, software engineering best practices for data science, and how to build your own python package. The foundations course is intended to help developers of all skill levels get started with machine learning. At the end of the AWS Machine Learning Foundations Course, learners will take an assessment from which top performers will be selected for one of 425 follow-up scholarships to one of Udacityâ€™s most popular and recently refreshed Nanodegree programs: The AWS Machine Learning Engineer Nanodegree program. Link : https://www.udacity.com/scholarships/aws-machine-learning-scholarship-program",#machinelearning	#scholarship,,,,
"ChÃ o má»i ngÆ°á»i
MÃ¬nh Ä‘á»‹nh dÃ¹ng mÃ´ hÃ¬nh ResNet50 cÃ¹ng vá»›i pretrained weights tá»« ImageNet Ä‘á»ƒ transfer learning bá»™ dá»¯ liá»‡u cá»§a mÃ¬nh. MÃ¬nh cÃ³ sá»­a pháº§n Top_layers Ä‘á»ƒ cho phÃ¹ há»£p vá»›i bÃ i toÃ¡n cá»§a mÃ¬nh.
LÃ¢u nay mÃ¬nh váº«n sá»­ dá»¥ng vÃ  cháº¡y bÃ¬nh thÆ°á»ng nhÆ°ng vÃ i hÃ´m gáº§n Ä‘Ã¢y nÃ³ bá»‹ lá»—i nhÆ° á»Ÿ dÆ°á»›i. M.n xem vÃ  giÃºp mÃ¬nh sá»­a vá»›i áº¡
Cáº£m Æ¡n m.n",ChÃ o má»i ngÆ°á»i MÃ¬nh Ä‘á»‹nh dÃ¹ng mÃ´ hÃ¬nh ResNet50 cÃ¹ng vá»›i pretrained weights tá»« ImageNet Ä‘á»ƒ transfer learning bá»™ dá»¯ liá»‡u cá»§a mÃ¬nh. MÃ¬nh cÃ³ sá»­a pháº§n Top_layers Ä‘á»ƒ cho phÃ¹ há»£p vá»›i bÃ i toÃ¡n cá»§a mÃ¬nh. LÃ¢u nay mÃ¬nh váº«n sá»­ dá»¥ng vÃ  cháº¡y bÃ¬nh thÆ°á»ng nhÆ°ng vÃ i hÃ´m gáº§n Ä‘Ã¢y nÃ³ bá»‹ lá»—i nhÆ° á»Ÿ dÆ°á»›i. M.n xem vÃ  giÃºp mÃ¬nh sá»­a vá»›i áº¡ Cáº£m Æ¡n m.n,,,,,
"ChÃ o mn. Hiá»‡n táº¡i mÃ¬nh Ä‘ang sá»­ dá»¥ng thÆ° viá»‡n face_recognition Ä‘á»ƒ lÃ m 1 project real time attendance nho nhá». nhÆ°ng tháº¥y hÃ m face_encodings cá»§a nÃ³ Ä‘ang quÃ¡ cháº­m khiáº¿n cho viá»‡c stream lÃªn camera nÃ³ bá»‹ giáº­t.
CÃ³ ai Ä‘Ã£ tá»«ng dÃ¹ng thÆ° viá»‡n nÃ y vÃ  fix Ä‘Æ°á»£c issue Ä‘áº¥y cho em xin Ã½ tÆ°á»Ÿng vá»›i. Thanks mn",ChÃ o mn. Hiá»‡n táº¡i mÃ¬nh Ä‘ang sá»­ dá»¥ng thÆ° viá»‡n face_recognition Ä‘á»ƒ lÃ m 1 project real time attendance nho nhá». nhÆ°ng tháº¥y hÃ m face_encodings cá»§a nÃ³ Ä‘ang quÃ¡ cháº­m khiáº¿n cho viá»‡c stream lÃªn camera nÃ³ bá»‹ giáº­t. CÃ³ ai Ä‘Ã£ tá»«ng dÃ¹ng thÆ° viá»‡n nÃ y vÃ  fix Ä‘Æ°á»£c issue Ä‘áº¥y cho em xin Ã½ tÆ°á»Ÿng vá»›i. Thanks mn,,,,,
"ChÃ o má»i ngÆ°á»i,
Em cÃ³ váº¥n Ä‘á» mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
Em Ä‘ang cáº§n train model nhÆ°ng dá»¯ liá»‡u bá»‹ imbalance (chÃªnh lá»‡ch khoáº£ng 10 láº§n)
Máº·c dÃ¹ tÃ¬m hiá»ƒu trÃªn máº¡ng, biáº¿t Ä‘Æ°á»£c imbalance data cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ train. NhÆ°ng náº¿u dá»¯ liá»‡u cá»§a label Ã­t nháº¥t Ä‘á»§ lá»›n thÃ¬ mÃ´ hÃ¬nh cÃ³ há»c Ä‘Æ°á»£c Ä‘áº·c trÆ°ng mÃ  khÃ´ng bá»‹ bias khÃ´ng áº¡?
Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, Em cÃ³ váº¥n Ä‘á» mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p. Em Ä‘ang cáº§n train model nhÆ°ng dá»¯ liá»‡u bá»‹ imbalance (chÃªnh lá»‡ch khoáº£ng 10 láº§n) Máº·c dÃ¹ tÃ¬m hiá»ƒu trÃªn máº¡ng, biáº¿t Ä‘Æ°á»£c imbalance data cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ train. NhÆ°ng náº¿u dá»¯ liá»‡u cá»§a label Ã­t nháº¥t Ä‘á»§ lá»›n thÃ¬ mÃ´ hÃ¬nh cÃ³ há»c Ä‘Æ°á»£c Ä‘áº·c trÆ°ng mÃ  khÃ´ng bá»‹ bias khÃ´ng áº¡? Em cáº£m Æ¡n áº¡.",,,,,
"Em chÃ o má»i ngÆ°á»i
Hiá»‡n em Ä‘ang train má»™t model Neural  Network vá» classification nhÆ°ng gáº·p váº¥n Ä‘á» nhÆ° sau:
cost function khÃ´ng thá»ƒ giáº£m xuá»‘ng dÆ°á»›i 0.64 dÃ¹ em Ä‘Ã£ thá»­ nhiá»u learning_rate hay tÄƒng epoch
VÃ¬ cost sai nÃªn káº¿t quáº£ táº¥t cáº£ predict Ä‘á»u lÃ  0
hÃ¬nh áº£nh trÃªn lÃ  em Ä‘ang cháº¡y trÃªn data cat or non-cat Ã½ áº¡.
Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á» xuáº¥t giÃºp em cÃ¡ch Ä‘á»ƒ sá»­a tÃ¬nh tráº¡ng nÃ y khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u, chÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº».","Em chÃ o má»i ngÆ°á»i Hiá»‡n em Ä‘ang train má»™t model Neural Network vá» classification nhÆ°ng gáº·p váº¥n Ä‘á» nhÆ° sau: cost function khÃ´ng thá»ƒ giáº£m xuá»‘ng dÆ°á»›i 0.64 dÃ¹ em Ä‘Ã£ thá»­ nhiá»u learning_rate hay tÄƒng epoch VÃ¬ cost sai nÃªn káº¿t quáº£ táº¥t cáº£ predict Ä‘á»u lÃ  0 hÃ¬nh áº£nh trÃªn lÃ  em Ä‘ang cháº¡y trÃªn data cat or non-cat Ã½ áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á» xuáº¥t giÃºp em cÃ¡ch Ä‘á»ƒ sá»­a tÃ¬nh tráº¡ng nÃ y khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u, chÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº».",,,,,
Pytorch vÃ  Tensorflow. Ae tháº¥y nÃ o hay hÆ¡n áº¡?,Pytorch vÃ  Tensorflow. Ae tháº¥y nÃ o hay hÆ¡n áº¡?,,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang cáº§n táº£i dataset tá»« baidu, nhÆ°ng hiá»‡n em khÃ´ng cÃ³ tÃ i khoáº£n. Em Ä‘Ã£ thá»­ cÃ¡ch tÃ¬m Ä‘Æ°á»£c trÃªn google nhÆ°ng Ä‘á»u khÃ´ng Ä‘Æ°á»£c...
CÃ³ cao nhÃ¢n nÃ o giÃºp em vá»›i áº¡.","ChÃ o má»i ngÆ°á»i, em Ä‘ang cáº§n táº£i dataset tá»« baidu, nhÆ°ng hiá»‡n em khÃ´ng cÃ³ tÃ i khoáº£n. Em Ä‘Ã£ thá»­ cÃ¡ch tÃ¬m Ä‘Æ°á»£c trÃªn google nhÆ°ng Ä‘á»u khÃ´ng Ä‘Æ°á»£c... CÃ³ cao nhÃ¢n nÃ o giÃºp em vá»›i áº¡.",,,,,
"Improved YOLOv4 (Scaled-YOLOv4 and YOLOR) is still better than: PP-YOLOv2, YOLOv5, EfficientDet, SWIN Transformers: paperswithcode.com/sota/real-timeâ€¦
Scaled-YOLOv4 (accepted to CVPR'21) arxiv.org/abs/2011.08036
github.com/WongKinYiu/Scaâ€¦
YOLOR arxiv.org/abs/2105.04206
https://github.com/WongKinYiu/yolor","Improved YOLOv4 (Scaled-YOLOv4 and YOLOR) is still better than: PP-YOLOv2, YOLOv5, EfficientDet, SWIN Transformers: paperswithcode.com/sota/real-timeâ€¦ Scaled-YOLOv4 (accepted to CVPR'21) arxiv.org/abs/2011.08036 github.com/WongKinYiu/Scaâ€¦ YOLOR arxiv.org/abs/2105.04206 https://github.com/WongKinYiu/yolor",,,,,
"ChÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang xá»­ lÃ­ má»™t bÃ i toÃ¡n vá»›i Ä‘áº§u vÃ o lÃ  cÃ¡c vector sá»‘ thá»±c vá»›i sá»‘ chiá»u cá»±c lá»›n (vÃ i chá»¥c ngÃ n - vÃ i trÄƒm ngÃ n chiá»u). Do dá»¯ liá»‡u Ã­t nÃªn em muá»‘n lÃ m data augmentation thÃªm nhÆ°ng chÆ°a biáº¿t augment tháº¿ nÃ o vá»›i dá»¯ liá»‡u vector. Mong má»i ngÆ°á»i cÃ³ cÃ¡ch augment nÃ o hiá»‡u quáº£ cÃ³ thá»ƒ gá»£i Ã½ cho em.
Em cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang xá»­ lÃ­ má»™t bÃ i toÃ¡n vá»›i Ä‘áº§u vÃ o lÃ  cÃ¡c vector sá»‘ thá»±c vá»›i sá»‘ chiá»u cá»±c lá»›n (vÃ i chá»¥c ngÃ n - vÃ i trÄƒm ngÃ n chiá»u). Do dá»¯ liá»‡u Ã­t nÃªn em muá»‘n lÃ m data augmentation thÃªm nhÆ°ng chÆ°a biáº¿t augment tháº¿ nÃ o vá»›i dá»¯ liá»‡u vector. Mong má»i ngÆ°á»i cÃ³ cÃ¡ch augment nÃ o hiá»‡u quáº£ cÃ³ thá»ƒ gá»£i Ã½ cho em. Em cáº£m Æ¡n!",,,,,
Giá»i thiá»‡u cÃ¡c báº¡n kinh nghiá»‡m xin internship NVIDIA,Giá»i thiá»‡u cÃ¡c báº¡n kinh nghiá»‡m xin internship NVIDIA,,,,,
"[AI Share â€“ AI Expert Roadmap]
AI Expert Roadmap (Lá»™ trÃ¬nh chuyÃªn gia vá» AI) cá»§a cÃ´ng ty khá»Ÿi nghiá»‡p Äá»©c hÆ¡n 10.000 sao trÃªn GitHub.",[AI Share â€“ AI Expert Roadmap] AI Expert Roadmap (Lá»™ trÃ¬nh chuyÃªn gia vá» AI) cá»§a cÃ´ng ty khá»Ÿi nghiá»‡p Äá»©c hÆ¡n 10.000 sao trÃªn GitHub.,,,,,
"ChÃ o m.n. Hiá»‡n em Ä‘ang vá»c váº¡ch vá» project Ã´ tÃ´ tá»± lÃ¡i vÃ  mÃ´ phá»ng trÃªn pháº§n má»m giáº£ láº­p. Em Ä‘Ã£ láº¥y data vá», xá»­ lÃ­ vÃ  xÃ¢y dá»±ng Sequential model. NhÆ°ng Ä‘áº¿n khi em thá»±c hiá»‡n train vá»›i 10 epoch, sá»‘ lÆ°á»£ng máº«u má»—i epoch lÃ  1000 thÃ¬ mÃ¡y chá»‰ train Ä‘Æ°á»£c epoch Ä‘áº§u tiÃªn. Sau Ä‘Ã³ Ä‘á»©ng hÃ¬nh vÃ  khÃ´ng train tiáº¿p ná»¯a áº¡ :'(
CÃ³ ai Ä‘Ã£ gáº·p tÃ¬nh tráº¡ng tÆ°Æ¡ng tá»± hay tháº¥y em cÃ³ sai thÃ¬ chá»‰ giÃºp em :( . Cáº£m Æ¡n m.n.","ChÃ o m.n. Hiá»‡n em Ä‘ang vá»c váº¡ch vá» project Ã´ tÃ´ tá»± lÃ¡i vÃ  mÃ´ phá»ng trÃªn pháº§n má»m giáº£ láº­p. Em Ä‘Ã£ láº¥y data vá», xá»­ lÃ­ vÃ  xÃ¢y dá»±ng Sequential model. NhÆ°ng Ä‘áº¿n khi em thá»±c hiá»‡n train vá»›i 10 epoch, sá»‘ lÆ°á»£ng máº«u má»—i epoch lÃ  1000 thÃ¬ mÃ¡y chá»‰ train Ä‘Æ°á»£c epoch Ä‘áº§u tiÃªn. Sau Ä‘Ã³ Ä‘á»©ng hÃ¬nh vÃ  khÃ´ng train tiáº¿p ná»¯a áº¡ :'( CÃ³ ai Ä‘Ã£ gáº·p tÃ¬nh tráº¡ng tÆ°Æ¡ng tá»± hay tháº¥y em cÃ³ sai thÃ¬ chá»‰ giÃºp em :( . Cáº£m Æ¡n m.n.",,,,,
"[Person Reidentification]
CÃ¢u 1: Trong bÃ i toÃ¡n nÃ y dá»±a trÃªn resnet50,
(https://arxiv.org/pdf/1903.07071v3.pdf)
Ã nghÄ©a cá»§a identity loss lÃ  Ä‘á»ƒ lÃ m gÃ¬ váº­y áº¡? CÃ³ khi nÃ o vÃ¬ ID loss nÃ y mÃ  dáº«n Ä‘áº¿n viá»‡c overfitting theo cÃ¡c ID bÃªn trong dataset (train) khÃ´ng nhá»‰?
CÃ¢u 2: Táº¡i sao ngÆ°á»i ta láº¡i xem bÃ i toÃ¡n person re identification nhÆ° 1 bÃ i image retrieval váº­y áº¡? MÃ¬nh nghÄ©, tuy hai bÃ i toÃ¡n cÃ³ pháº§n liÃªn quan vá»›i nhau. NhÆ°ng vá» máº·t á»©ng dá»¥ng khÃ¡c nÃªn nÃ³ pháº£i hÆ¡i khÃ¡c nhau nhiá»u Ä‘iá»ƒm chá»© áº¡? MÃ¬nh Ä‘á»c cÃ¡c bÃ i survey thÃ¬ há» thÆ°á»ng coi 1 bÃ i person-reid láº¡i nhÆ° lÃ  má»™t bÃ i image retrieval(IR), rá»“i sau Ä‘Ã³ Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p IR vÃ o Person ReID. Má»™t trong nhá»¯ng Ä‘iá»ƒm mÃ¬nh tháº¥y lÃ : Image retrieval (Known number of Identities, offline, large dataset), while Person reID (unknow identity may appear, smaller dataset (few cameras), online).
Ps: Mong tÃ¬m Ä‘Æ°á»£c cÃ¡c báº¡n Ä‘ang lÃ m vá» bÃ i toÃ¡n nÃ y Ä‘á»ƒ há»c há»i thÃªm áº¡.","[Person Reidentification] CÃ¢u 1: Trong bÃ i toÃ¡n nÃ y dá»±a trÃªn resnet50, (https://arxiv.org/pdf/1903.07071v3.pdf) Ã nghÄ©a cá»§a identity loss lÃ  Ä‘á»ƒ lÃ m gÃ¬ váº­y áº¡? CÃ³ khi nÃ o vÃ¬ ID loss nÃ y mÃ  dáº«n Ä‘áº¿n viá»‡c overfitting theo cÃ¡c ID bÃªn trong dataset (train) khÃ´ng nhá»‰? CÃ¢u 2: Táº¡i sao ngÆ°á»i ta láº¡i xem bÃ i toÃ¡n person re identification nhÆ° 1 bÃ i image retrieval váº­y áº¡? MÃ¬nh nghÄ©, tuy hai bÃ i toÃ¡n cÃ³ pháº§n liÃªn quan vá»›i nhau. NhÆ°ng vá» máº·t á»©ng dá»¥ng khÃ¡c nÃªn nÃ³ pháº£i hÆ¡i khÃ¡c nhau nhiá»u Ä‘iá»ƒm chá»© áº¡? MÃ¬nh Ä‘á»c cÃ¡c bÃ i survey thÃ¬ há» thÆ°á»ng coi 1 bÃ i person-reid láº¡i nhÆ° lÃ  má»™t bÃ i image retrieval(IR), rá»“i sau Ä‘Ã³ Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p IR vÃ o Person ReID. Má»™t trong nhá»¯ng Ä‘iá»ƒm mÃ¬nh tháº¥y lÃ : Image retrieval (Known number of Identities, offline, large dataset), while Person reID (unknow identity may appear, smaller dataset (few cameras), online). Ps: Mong tÃ¬m Ä‘Æ°á»£c cÃ¡c báº¡n Ä‘ang lÃ m vá» bÃ i toÃ¡n nÃ y Ä‘á»ƒ há»c há»i thÃªm áº¡.",,,,,
Trang web TMÄT cá»§a mÃ¬nh mÃ¬nh cÃ³ dÃ¹ng giáº£i thuáº­t lá»c cá»™ng tÃ¡c vÃ  lá»c dá»±a trÃªn ná»™i dung cho nhá»¯ng pháº§n khÃ¡c nhau cá»§a trang. Giá» náº¿u mÃ¬nh Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh thÃ¬ mÃ¬nh sáº½ dá»±a vÃ o tiÃªu chÃ­ nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem mÃ´ hÃ¬nh cÃ³ hoáº¡t Ä‘á»™ng tá»‘t khÃ´ng váº­y má»i ngÆ°á»i?,Trang web TMÄT cá»§a mÃ¬nh mÃ¬nh cÃ³ dÃ¹ng giáº£i thuáº­t lá»c cá»™ng tÃ¡c vÃ  lá»c dá»±a trÃªn ná»™i dung cho nhá»¯ng pháº§n khÃ¡c nhau cá»§a trang. Giá» náº¿u mÃ¬nh Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh thÃ¬ mÃ¬nh sáº½ dá»±a vÃ o tiÃªu chÃ­ nÃ o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem mÃ´ hÃ¬nh cÃ³ hoáº¡t Ä‘á»™ng tá»‘t khÃ´ng váº­y má»i ngÆ°á»i?,,,,,
"ChÃ o mn, hiá»‡n táº¡i e Ä‘ang train mÃ´ hÃ¬nh yolov5, Ã¡p dá»¥ng 10 fold cross validation. Ã cá»§a e lÃ  train mÃ´ hÃ¬nh 10 láº§n, má»—i láº§n 10 epochs, Ä‘á»ƒ chá»n ra mÃ´ hÃ¬nh cÃ³ káº¿t quáº£ tá»‘t nháº¥t vÃ  dÃ¹ng toÃ n bá»™ dá»¯ liá»‡u Ä‘á»ƒ train dá»±a theo mÃ´ hÃ¬nh Ä‘Ã³ Ä‘á»ƒ cho ra káº¿t quáº£ cuá»‘i cÃ¹ng. MÃ  tháº§y hÆ°á»›ng dáº«n cá»§a e khÃ´ng Ä‘á»“ng Ã½ vá»›i hÆ°á»›ng Ä‘Ã³, tháº§y báº£o hÃ£y dÃ¹ng káº¿t quáº£ trung bÃ¬nh. Váº­y thÃ¬ mn cho e há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÃ­nh trung bÃ¬nh cá»§a 10 mÃ´ hÃ¬nh nhÆ° cÃ¡ch mÃ  tháº§y e báº£o khÃ´ng áº¡? Thanks mn.","ChÃ o mn, hiá»‡n táº¡i e Ä‘ang train mÃ´ hÃ¬nh yolov5, Ã¡p dá»¥ng 10 fold cross validation. Ã cá»§a e lÃ  train mÃ´ hÃ¬nh 10 láº§n, má»—i láº§n 10 epochs, Ä‘á»ƒ chá»n ra mÃ´ hÃ¬nh cÃ³ káº¿t quáº£ tá»‘t nháº¥t vÃ  dÃ¹ng toÃ n bá»™ dá»¯ liá»‡u Ä‘á»ƒ train dá»±a theo mÃ´ hÃ¬nh Ä‘Ã³ Ä‘á»ƒ cho ra káº¿t quáº£ cuá»‘i cÃ¹ng. MÃ  tháº§y hÆ°á»›ng dáº«n cá»§a e khÃ´ng Ä‘á»“ng Ã½ vá»›i hÆ°á»›ng Ä‘Ã³, tháº§y báº£o hÃ£y dÃ¹ng káº¿t quáº£ trung bÃ¬nh. Váº­y thÃ¬ mn cho e há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÃ­nh trung bÃ¬nh cá»§a 10 mÃ´ hÃ¬nh nhÆ° cÃ¡ch mÃ  tháº§y e báº£o khÃ´ng áº¡? Thanks mn.",,,,,
"Facebook AI team officially announced PyTorchVideo today!
a deep learning library for video understanding. PyTorchVideo is dedicated for both research and productization in the video domain.

For more details, please check out:
The github repo: https://lnkd.in/gJaTQbJ
The PyTorchVideo website with tutorials: https://pytorchvideo.org/
Facebook AI blog post: https://lnkd.in/gxWzADG

#deeplearning #computervision #opensource","Facebook AI team officially announced PyTorchVideo today! a deep learning library for video understanding. PyTorchVideo is dedicated for both research and productization in the video domain. For more details, please check out: The github repo: https://lnkd.in/gJaTQbJ The PyTorchVideo website with tutorials: https://pytorchvideo.org/ Facebook AI blog post: https://lnkd.in/gxWzADG",#deeplearning	#computervision	#opensource,,,,
"[AI Share]
KhÃ³a há»c : The Missing Semester of Your CS Education ( KÃ¬ Há»c Bá»‹ Thiáº¿u Cá»§a GiÃ¡o TrÃ¬nh Khoa Há»c MÃ¡y TÃ­nh)
â€œGiáº£ng Ä‘Æ°á»ng truyá»n thá»‘ng dáº¡y má»i ngÆ°á»i vá» cÃ¡c váº¥n Ä‘á» chuyÃªn ngÃ nh Khoa Há»c MÃ¡y TÃ­nh cao cáº¥p tá»« há»‡ Ä‘iá»u hÃ nh Ä‘áº¿n há»c mÃ¡y. Tuy nhiÃªn cÃ³ má»™t chá»§ Ä‘á» ráº¥t quan trá»ng nhÆ°ng láº¡i hay bá»‹ bá» rÆ¡i Ä‘á»ƒ sinh viÃªn tá»± mÃ y mÃ², Ä‘Ã³ lÃ  kháº£ nÄƒng sá»­ dá»¥ng cÃ´ng cá»¥ cá»§a há». ChÃºng tÃ´i sáº½ dáº¡y báº¡n cÃ¡ch lÃ m chá»§ command-line, sá»­ dá»¥ng má»™t trÃ¬nh biÃªn dá»‹ch mÃ£ nguá»“n (text editor) háº¿t kháº£ nÄƒng cá»§a nÃ³, vÃ´ vÃ n cÃ¡c chá»©c nÄƒng â€œxá»‹n xÃ²â€ cá»§a trÃ¬nh quáº£n lÃ½ phiÃªn báº£n (version control systems), vÃ  hÆ¡n tháº¿ ná»¯a.
Æ¯á»›c chá»«ng sinh viÃªn sáº½ dÃ nh ra hÃ ng trÄƒm giá» Ä‘á»ƒ sá»­ dá»¥ng nhá»¯ng cÃ´ng cá»¥ nÃ³i trÃªn trong suá»‘t thá»i gian ngá»“i trÃªn giáº£ng Ä‘Æ°á»ng (vÃ  hÃ ng ngÃ n giá» khi Ä‘i lÃ m). VÃ¬ váº­y, viá»‡c Ä‘áº£m báº£o cho há» sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ nÃ y â€œnhanh, gá»n, láº¹â€ lÃ  má»™t Ä‘iá»u vÃ´ cÃ¹ng há»£p lÃ½. LÃ m chá»§ hoÃ n toÃ n Ä‘Æ°á»£c nhá»¯ng cÃ´ng cá»¥ nÃ y khÃ´ng nhá»¯ng cho phÃ©p báº¡n tiáº¿t kiá»‡m thá»i gian thao tÃ¡c theo Ã½ mÃ¬nh, mÃ  cÃ²n cho phÃ©p báº¡n xá»­ lÃ½ nhá»¯ng váº¥n Ä‘á» phá»©c táº¡p, khÃ´ng tÆ°á»Ÿng.â€
Äá»ƒ pháº§n nÃ o háº¡n cháº¿ nhá»¯ng thiáº¿u sÃ³t trÃªn, KhÃ³a há»c â€œThe Missing Semester of Your CS Educationâ€ sáº½ cung cáº¥p nhá»¯ng kiáº¿n thá»©c cáº§n thiáº¿t cho má»™t nhÃ  khoa há»c mÃ¡y tÃ­nh, nhÃ  láº­p trÃ¬nh. KhÃ³a há»c nÃ y vá»«a thá»±c táº¿ láº¡i vá»«a cho phÃ©p báº¡n thá»±c hÃ nh cÃ¡c cÃ´ng cá»¥, ká»¹ thuáº­t mÃ  báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng ngay láº­p tá»©c vÃ o ráº¥t nhiá»u trÆ°á»ng há»£p báº¡n sáº½ gáº·p trong tÆ°Æ¡ng lai.
Link : https://missing.csail.mit.edu/
Link tiáº¿ng viá»‡t : https://missing-semester-vn.github.io/
Youtube: https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J
_____________________________
Náº¿u gáº·p khÃ³ khÄƒn trong viá»‡c há»c cÃ¡c kiáº¿n thá»©c ná»n táº£ng lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o, Ä‘á»«ng quÃªn cÃ¡c khÃ³a há»c bá»• Ã­ch cá»§a AI4E nhÃ©. KhÃ³a há»c Deep Learning cÆ¡ báº£n online sáº½ Ä‘Æ°á»£c khai giáº£ng vÃ o 19h ngÃ y 5/6 nhÃ©. Nhanh tay inbox page Ä‘á»ƒ Ä‘Æ°á»£c tham gia lá»›p há»c bá»• Ã­ch nÃ y nhÃ©.","[AI Share] KhÃ³a há»c : The Missing Semester of Your CS Education ( KÃ¬ Há»c Bá»‹ Thiáº¿u Cá»§a GiÃ¡o TrÃ¬nh Khoa Há»c MÃ¡y TÃ­nh) â€œGiáº£ng Ä‘Æ°á»ng truyá»n thá»‘ng dáº¡y má»i ngÆ°á»i vá» cÃ¡c váº¥n Ä‘á» chuyÃªn ngÃ nh Khoa Há»c MÃ¡y TÃ­nh cao cáº¥p tá»« há»‡ Ä‘iá»u hÃ nh Ä‘áº¿n há»c mÃ¡y. Tuy nhiÃªn cÃ³ má»™t chá»§ Ä‘á» ráº¥t quan trá»ng nhÆ°ng láº¡i hay bá»‹ bá» rÆ¡i Ä‘á»ƒ sinh viÃªn tá»± mÃ y mÃ², Ä‘Ã³ lÃ  kháº£ nÄƒng sá»­ dá»¥ng cÃ´ng cá»¥ cá»§a há». ChÃºng tÃ´i sáº½ dáº¡y báº¡n cÃ¡ch lÃ m chá»§ command-line, sá»­ dá»¥ng má»™t trÃ¬nh biÃªn dá»‹ch mÃ£ nguá»“n (text editor) háº¿t kháº£ nÄƒng cá»§a nÃ³, vÃ´ vÃ n cÃ¡c chá»©c nÄƒng â€œxá»‹n xÃ²â€ cá»§a trÃ¬nh quáº£n lÃ½ phiÃªn báº£n (version control systems), vÃ  hÆ¡n tháº¿ ná»¯a. Æ¯á»›c chá»«ng sinh viÃªn sáº½ dÃ nh ra hÃ ng trÄƒm giá» Ä‘á»ƒ sá»­ dá»¥ng nhá»¯ng cÃ´ng cá»¥ nÃ³i trÃªn trong suá»‘t thá»i gian ngá»“i trÃªn giáº£ng Ä‘Æ°á»ng (vÃ  hÃ ng ngÃ n giá» khi Ä‘i lÃ m). VÃ¬ váº­y, viá»‡c Ä‘áº£m báº£o cho há» sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ nÃ y â€œnhanh, gá»n, láº¹â€ lÃ  má»™t Ä‘iá»u vÃ´ cÃ¹ng há»£p lÃ½. LÃ m chá»§ hoÃ n toÃ n Ä‘Æ°á»£c nhá»¯ng cÃ´ng cá»¥ nÃ y khÃ´ng nhá»¯ng cho phÃ©p báº¡n tiáº¿t kiá»‡m thá»i gian thao tÃ¡c theo Ã½ mÃ¬nh, mÃ  cÃ²n cho phÃ©p báº¡n xá»­ lÃ½ nhá»¯ng váº¥n Ä‘á» phá»©c táº¡p, khÃ´ng tÆ°á»Ÿng.â€ Äá»ƒ pháº§n nÃ o háº¡n cháº¿ nhá»¯ng thiáº¿u sÃ³t trÃªn, KhÃ³a há»c â€œThe Missing Semester of Your CS Educationâ€ sáº½ cung cáº¥p nhá»¯ng kiáº¿n thá»©c cáº§n thiáº¿t cho má»™t nhÃ  khoa há»c mÃ¡y tÃ­nh, nhÃ  láº­p trÃ¬nh. KhÃ³a há»c nÃ y vá»«a thá»±c táº¿ láº¡i vá»«a cho phÃ©p báº¡n thá»±c hÃ nh cÃ¡c cÃ´ng cá»¥, ká»¹ thuáº­t mÃ  báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng ngay láº­p tá»©c vÃ o ráº¥t nhiá»u trÆ°á»ng há»£p báº¡n sáº½ gáº·p trong tÆ°Æ¡ng lai. Link : https://missing.csail.mit.edu/ Link tiáº¿ng viá»‡t : https://missing-semester-vn.github.io/ Youtube: https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J _____________________________ Náº¿u gáº·p khÃ³ khÄƒn trong viá»‡c há»c cÃ¡c kiáº¿n thá»©c ná»n táº£ng lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o, Ä‘á»«ng quÃªn cÃ¡c khÃ³a há»c bá»• Ã­ch cá»§a AI4E nhÃ©. KhÃ³a há»c Deep Learning cÆ¡ báº£n online sáº½ Ä‘Æ°á»£c khai giáº£ng vÃ o 19h ngÃ y 5/6 nhÃ©. Nhanh tay inbox page Ä‘á»ƒ Ä‘Æ°á»£c tham gia lá»›p há»c bá»• Ã­ch nÃ y nhÃ©.",,,,,
"CÃ¡ch Ä‘Ã¢y khoáº£ng hÆ¡n 1 thÃ¡ng mÃ¬nh cÃ³ viáº¿t 1 chÃºt vá» Siamese Networks, hÃ´m nay Ä‘á»c paper tháº¥y cÃ³ nhÃ³m nghiÃªn cá»©u cá»§a Amazon cÃ´ng bá»‘ bÃ i vá» SiamMOT: Siamese Multi-Object tracking táº¡i Ä‘Ã¢y https://www.amazon.science/publications/siammot-siamese-multi-object-tracking.
Code cá»§a há» táº¡i Ä‘Ã¢y: https://github.com/amazon-research/siam-mot
Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i cÃ¡c báº¡n lÃ m computer vision.","CÃ¡ch Ä‘Ã¢y khoáº£ng hÆ¡n 1 thÃ¡ng mÃ¬nh cÃ³ viáº¿t 1 chÃºt vá» Siamese Networks, hÃ´m nay Ä‘á»c paper tháº¥y cÃ³ nhÃ³m nghiÃªn cá»©u cá»§a Amazon cÃ´ng bá»‘ bÃ i vá» SiamMOT: Siamese Multi-Object tracking táº¡i Ä‘Ã¢y https://www.amazon.science/publications/siammot-siamese-multi-object-tracking. Code cá»§a há» táº¡i Ä‘Ã¢y: https://github.com/amazon-research/siam-mot Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i cÃ¡c báº¡n lÃ m computer vision.",,,,,
"[Multi-class sementic segmentation]
ChÃ o má»i ngÆ°á»i,
E hiá»‡n Ä‘ang lÃ m má»™t bÃ i táº­p vá» phÃ¢n vÃ¹ng áº£nh vá»›i 5 class. E Ä‘ang implement Unet Ä‘á»ƒ lÃ m quen, output cá»§a e nháº­n Ä‘Æ°á»£c lÃ  má»™t tensor kÃ­ch thÆ°á»›c lÃ  (5,256,256). Em muá»‘n imshow output thÃ¬ pháº£i lÃ m nhÆ° tháº¿ nÃ o áº¡.
Em cáº£m Æ¡n áº¡","[Multi-class sementic segmentation] ChÃ o má»i ngÆ°á»i, E hiá»‡n Ä‘ang lÃ m má»™t bÃ i táº­p vá» phÃ¢n vÃ¹ng áº£nh vá»›i 5 class. E Ä‘ang implement Unet Ä‘á»ƒ lÃ m quen, output cá»§a e nháº­n Ä‘Æ°á»£c lÃ  má»™t tensor kÃ­ch thÆ°á»›c lÃ  (5,256,256). Em muá»‘n imshow output thÃ¬ pháº£i lÃ m nhÆ° tháº¿ nÃ o áº¡. Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ hai cÃ¢u há»i vá» kiáº¿n trÃºc LSTM, mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡
1/ CÃ¡c weight vÃ  bias lÃ  khÃ¡c nhau giá»¯a cÃ¡c cell/unit hay dÃ¹ng chung cho cáº£ 1 LSTM layer? CÃ¢u há»i tÆ°Æ¡ng tá»± vá»›i GRU.
2/ Hiá»‡n nay cÃ³ thÆ° viá»‡n nÃ o implement kiáº¿n trÃºc Convolutional Bidirectional LSTM khÃ´ng áº¡? Em Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c Ã­t nháº¥t 1 cÃ i Ä‘áº·t trÃªn Githubn nhÆ°ng khÃ´ng cÃ³ documentation, Ã­t nháº¥t lÃ  vá» kÃ­ch cá»¡ cÃ¡c tensor, kÃ­ch cÆ¡ Ä‘áº§u ra.","ChÃ o má»i ngÆ°á»i, em cÃ³ hai cÃ¢u há»i vá» kiáº¿n trÃºc LSTM, mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡ 1/ CÃ¡c weight vÃ  bias lÃ  khÃ¡c nhau giá»¯a cÃ¡c cell/unit hay dÃ¹ng chung cho cáº£ 1 LSTM layer? CÃ¢u há»i tÆ°Æ¡ng tá»± vá»›i GRU. 2/ Hiá»‡n nay cÃ³ thÆ° viá»‡n nÃ o implement kiáº¿n trÃºc Convolutional Bidirectional LSTM khÃ´ng áº¡? Em Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c Ã­t nháº¥t 1 cÃ i Ä‘áº·t trÃªn Githubn nhÆ°ng khÃ´ng cÃ³ documentation, Ã­t nháº¥t lÃ  vá» kÃ­ch cá»¡ cÃ¡c tensor, kÃ­ch cÆ¡ Ä‘áº§u ra.",,,,,
"[TÃ¬m nguá»“n/ sÃ¡ch há»c cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n]
Hi cáº£ nhÃ , e cÅ©ng má»›i há»c tá»« Ä‘áº§u xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  xÃ¢y cÃ¡c model phÃ¢n loáº¡i báº±ng R/ Python. Em lÃ  dÃ¢n tÃ i chÃ­nh nháº£y ngang nÃªn e mong Ä‘Æ°á»£c chia sáº» cÃ¡c cuá»‘n sÃ¡ch hoáº·c link há»c cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n nhÆ° vector, máº£ng, chiá»u ....
Em cÃ¡m Æ¡n cÃ¡c anh chá»‹ áº¡.","[TÃ¬m nguá»“n/ sÃ¡ch há»c cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n] Hi cáº£ nhÃ , e cÅ©ng má»›i há»c tá»« Ä‘áº§u xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  xÃ¢y cÃ¡c model phÃ¢n loáº¡i báº±ng R/ Python. Em lÃ  dÃ¢n tÃ i chÃ­nh nháº£y ngang nÃªn e mong Ä‘Æ°á»£c chia sáº» cÃ¡c cuá»‘n sÃ¡ch hoáº·c link há»c cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n nhÆ° vector, máº£ng, chiá»u .... Em cÃ¡m Æ¡n cÃ¡c anh chá»‹ áº¡.",,,,,
"ThÃ¡ng tÆ° nÃ y cÃ³ láº½ khÃ´ng cÃ³ nhiá»u sá»± kiá»‡n, nhÆ°ng cÃ³ láº½ váº«n nhiá»u cÃ´ng ty tuyá»ƒn nhÃ¢n viÃªn lÃ m tá»« xa. CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng cÃ¡c thÃ´ng tin liÃªn quan tá»›i sá»± kiá»‡n, tuyá»ƒn dá»¥ng, tuyá»ƒn sinh trong post nÃ y.
ChÃºc cÃ¡c báº¡n há»c thÃªm Ä‘Æ°á»£c nhiá»u thá»© trong thá»i gian á»Ÿ nhÃ  nÃ y.","ThÃ¡ng tÆ° nÃ y cÃ³ láº½ khÃ´ng cÃ³ nhiá»u sá»± kiá»‡n, nhÆ°ng cÃ³ láº½ váº«n nhiá»u cÃ´ng ty tuyá»ƒn nhÃ¢n viÃªn lÃ m tá»« xa. CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng cÃ¡c thÃ´ng tin liÃªn quan tá»›i sá»± kiá»‡n, tuyá»ƒn dá»¥ng, tuyá»ƒn sinh trong post nÃ y. ChÃºc cÃ¡c báº¡n há»c thÃªm Ä‘Æ°á»£c nhiá»u thá»© trong thá»i gian á»Ÿ nhÃ  nÃ y.",,,,,
"Há»i vá» lá»—i Average Precision = -1 vÃ  Average Recall = -1 khi huáº¥n luyá»‡n mÃ´ hÃ¬nh SSD MobileNet bÃ i toÃ¡n Object Detection
ChÃ o má»i ngÆ°á»i. Trong khi huáº¥n luyá»‡n mÃ´ hÃ¬nh SSD MobileNet cho bÃ i toÃ¡n Object Detection em gáº·p má»™t sá»‘ lá»—i sau xin Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡.
Em xin nÃ³i qua vá» mÃ´i trÆ°á»ng mÃ¬nh sá»­ dá»¥ng
Train trÃªn Google Colab
Tensorflow version 1
MÃ´ hÃ¬nh SSD MobileNet v2
File tfrecord: Em gÃ¡n nhÃ£n báº±ng LabelImg vÃ  dÃ¹ng App RobotFlow Ä‘á»ƒ chuyá»ƒn thÃ nh tfrecord
LÃºc trÆ°á»›c em chuyá»ƒn Ä‘á»•i file tfrecord trÃªn RobotFlow vÃ  train mÃ´ hÃ¬nh thÃ¬ cÃ¡c chá»‰ sá»‘ AP vÃ  AR khÃ´ng cÃ³ bá»‹ trá»« -1 nhÆ° trong áº£nh, chá»‰ trá»« má»™t sá»‘ Ä‘á»‘i tÆ°á»£ng khÃ´ng cÃ³ kÃ­ch thÆ°á»›c area = small nhÆ° trong mÃ´ hÃ¬nh thÃ¬ má»›i báº±ng -1. NgoÃ i ra thÃ¬ lÃºc train cÃ¡c chá»‰ sá»‘ áº¥y ban Ä‘áº§u lÃ  báº±ng 0 háº¿t.
Tuy nhiÃªn, sau khi em tÄƒng cÆ°á»ng thÃªm dá»¯ liá»‡u vÃ  chuyá»ƒn Ä‘á»•i láº¡i thÃ nh file tfrecord thÃ¬ xáº£y ra hiá»‡n tÆ°á»£ng AP vÃ  AR = -1. Em Ä‘Ã£ kiá»ƒm tra cáº©n tháº­n file configure cá»§a SSD MobileNet vÃ  cÃ¡c cÃ i Ä‘áº·t khÃ¡c, tháº­m chÃ­ lÃ  thay báº±ng file tfrecord trÆ°á»›c Ä‘Ã³ thÃ¬ mÃ´ hÃ¬nh Ä‘á»u cháº¡y bÃ¬nh thÆ°á»ng. NhÆ°ng Ä‘á»‘i vá»›i file tfrecord sau khi tÄƒng cÆ°á»ng dá»¯ liá»‡u thÃ¬ xáº£y ra hiá»‡n tÆ°á»£ng nhÆ° trÃªn.
Cho em há»i lÃ  cÃ³ anh/chá»‹ nÃ o Ä‘Ã£ tá»«ng bá»‹ trÆ°á»ng há»£p nhÆ° trÃªn, cÃ³ thá»ƒ cho em biáº¿t lÃ½ do táº¡i sao vÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o khÃ´ng áº¡ ?
Em xin cáº£m Æ¡n.
File code trÃªn colab má»i ngÆ°á»i cÃ³ thá»ƒ xem táº¡i Ä‘Ã¢y áº¡: https://colab.research.google.com/drive/1VuBM2yoF8PMNp6z-571LtV8nExnDlEF_?usp=sharing&fbclid=IwAR2PqVW82-LYnSZF9L0Q42I4iIaxfJiztqH3qcqIj8r-AbTA9e9JeMb6-l8
áº¢nh bÃªn dÆ°á»›i lÃ  lá»—i:
#ObjectDetection #ComputerVision #AveragePrecision","Há»i vá» lá»—i Average Precision = -1 vÃ  Average Recall = -1 khi huáº¥n luyá»‡n mÃ´ hÃ¬nh SSD MobileNet bÃ i toÃ¡n Object Detection ChÃ o má»i ngÆ°á»i. Trong khi huáº¥n luyá»‡n mÃ´ hÃ¬nh SSD MobileNet cho bÃ i toÃ¡n Object Detection em gáº·p má»™t sá»‘ lá»—i sau xin Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡. Em xin nÃ³i qua vá» mÃ´i trÆ°á»ng mÃ¬nh sá»­ dá»¥ng Train trÃªn Google Colab Tensorflow version 1 MÃ´ hÃ¬nh SSD MobileNet v2 File tfrecord: Em gÃ¡n nhÃ£n báº±ng LabelImg vÃ  dÃ¹ng App RobotFlow Ä‘á»ƒ chuyá»ƒn thÃ nh tfrecord LÃºc trÆ°á»›c em chuyá»ƒn Ä‘á»•i file tfrecord trÃªn RobotFlow vÃ  train mÃ´ hÃ¬nh thÃ¬ cÃ¡c chá»‰ sá»‘ AP vÃ  AR khÃ´ng cÃ³ bá»‹ trá»« -1 nhÆ° trong áº£nh, chá»‰ trá»« má»™t sá»‘ Ä‘á»‘i tÆ°á»£ng khÃ´ng cÃ³ kÃ­ch thÆ°á»›c area = small nhÆ° trong mÃ´ hÃ¬nh thÃ¬ má»›i báº±ng -1. NgoÃ i ra thÃ¬ lÃºc train cÃ¡c chá»‰ sá»‘ áº¥y ban Ä‘áº§u lÃ  báº±ng 0 háº¿t. Tuy nhiÃªn, sau khi em tÄƒng cÆ°á»ng thÃªm dá»¯ liá»‡u vÃ  chuyá»ƒn Ä‘á»•i láº¡i thÃ nh file tfrecord thÃ¬ xáº£y ra hiá»‡n tÆ°á»£ng AP vÃ  AR = -1. Em Ä‘Ã£ kiá»ƒm tra cáº©n tháº­n file configure cá»§a SSD MobileNet vÃ  cÃ¡c cÃ i Ä‘áº·t khÃ¡c, tháº­m chÃ­ lÃ  thay báº±ng file tfrecord trÆ°á»›c Ä‘Ã³ thÃ¬ mÃ´ hÃ¬nh Ä‘á»u cháº¡y bÃ¬nh thÆ°á»ng. NhÆ°ng Ä‘á»‘i vá»›i file tfrecord sau khi tÄƒng cÆ°á»ng dá»¯ liá»‡u thÃ¬ xáº£y ra hiá»‡n tÆ°á»£ng nhÆ° trÃªn. Cho em há»i lÃ  cÃ³ anh/chá»‹ nÃ o Ä‘Ã£ tá»«ng bá»‹ trÆ°á»ng há»£p nhÆ° trÃªn, cÃ³ thá»ƒ cho em biáº¿t lÃ½ do táº¡i sao vÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o khÃ´ng áº¡ ? Em xin cáº£m Æ¡n. File code trÃªn colab má»i ngÆ°á»i cÃ³ thá»ƒ xem táº¡i Ä‘Ã¢y áº¡: https://colab.research.google.com/drive/1VuBM2yoF8PMNp6z-571LtV8nExnDlEF_?usp=sharing&fbclid=IwAR2PqVW82-LYnSZF9L0Q42I4iIaxfJiztqH3qcqIj8r-AbTA9e9JeMb6-l8 áº¢nh bÃªn dÆ°á»›i lÃ  lá»—i:",#ObjectDetection	#ComputerVision	#AveragePrecision,,,,
"ChÃ o má»i ngÆ°á»i, em muá»‘n há»i vá» key idea cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p word embedding nhÆ°: Word2Vec, GloVe, CoVe, ELMo, BERT, GPT áº¡. Äiá»ƒm giá»‘ng vÃ  khÃ¡c nhau cÆ¡ báº£n giá»¯a cÃ¡c pp nÃ y lÃ  gÃ¬ áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i, em muá»‘n há»i vá» key idea cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p word embedding nhÆ°: Word2Vec, GloVe, CoVe, ELMo, BERT, GPT áº¡. Äiá»ƒm giá»‘ng vÃ  khÃ¡c nhau cÆ¡ báº£n giá»¯a cÃ¡c pp nÃ y lÃ  gÃ¬ áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"ChÃ o anh em trong há»™i nhÃ³m.
Cháº£ lÃ  mÃ¬nh muá»‘n cÃ i Ä‘áº·t Ubuntu 20.04LTS lÃªn mÃ¡y tÃ­nh cháº¡y chip Ryzen 7 5800H Ä‘á»ƒ lÃ m viá»‡c vá» Deep learning (Computer vision, ...) thÃ¬ á»Ÿ Ä‘Ã¢y cÃ³ ai cÃ i ubuntu vÃ  lÃ m AI trÃªn mÃ¡y cháº¡y chip AMD chÆ°a, cÃ³ pháº£i chÃº Ã½ gÃ¬ ko hay lÃ  cÃ³ háº¡n cháº¿ gÃ¬ ko so vá»›i chip intel. MÃ¬nh cáº£m Æ¡n <3","ChÃ o anh em trong há»™i nhÃ³m. Cháº£ lÃ  mÃ¬nh muá»‘n cÃ i Ä‘áº·t Ubuntu 20.04LTS lÃªn mÃ¡y tÃ­nh cháº¡y chip Ryzen 7 5800H Ä‘á»ƒ lÃ m viá»‡c vá» Deep learning (Computer vision, ...) thÃ¬ á»Ÿ Ä‘Ã¢y cÃ³ ai cÃ i ubuntu vÃ  lÃ m AI trÃªn mÃ¡y cháº¡y chip AMD chÆ°a, cÃ³ pháº£i chÃº Ã½ gÃ¬ ko hay lÃ  cÃ³ háº¡n cháº¿ gÃ¬ ko so vá»›i chip intel. MÃ¬nh cáº£m Æ¡n <3",,,,,
"MÃ¬nh muá»‘n lÃ m NMF (Non-negative matrix factorization) má»™t ma tráº­n lá»›n vá»›i 200.000 dÃ²ng. Laptop cá»§a mÃ¬nh khÃ´ng Ä‘á»§ máº¡nh nÃªn máº¥t ráº¥t nhiá»u thá»i gian vÃ  xÃ³t mÃ¡y.
Mn cho há»i cÃ³ dá»‹ch vá»¥ nÃ o cho thuáº¿ mÃ¡y máº¡nh (nhiá»u RAM vÃ  CPU máº¡nh) khÃ´ng ak?
Cáº£m Æ¡n mn nhiá»u nhÃ© :v",MÃ¬nh muá»‘n lÃ m NMF (Non-negative matrix factorization) má»™t ma tráº­n lá»›n vá»›i 200.000 dÃ²ng. Laptop cá»§a mÃ¬nh khÃ´ng Ä‘á»§ máº¡nh nÃªn máº¥t ráº¥t nhiá»u thá»i gian vÃ  xÃ³t mÃ¡y. Mn cho há»i cÃ³ dá»‹ch vá»¥ nÃ o cho thuáº¿ mÃ¡y máº¡nh (nhiá»u RAM vÃ  CPU máº¡nh) khÃ´ng ak? Cáº£m Æ¡n mn nhiá»u nhÃ© :v,,,,,
"xin phÃ©p admin
- Xin chÃ o ae, hÃ´m nay mÃ¬nh chia sáº» tá»›i ae pháº§n má»m dá»± Ä‘oÃ¡n bá»‡nh vÃ  lá»±a chá»n phÃ²ng khÃ¡m trong bá»‡nh viá»‡n. Cháº¯c háº³n Ä‘Ã¢y cÅ©ng lÃ  má»™t á»©ng dá»¥ng mÃ  nhiá»u ae Ä‘ang tÃ¬m, nghiÃªn cá»©u vÃ  á»©ng dá»¥ng. Pháº§n má»m nÃ y Ä‘Æ°á»£c ae #ASM trÆ°á»›c kia tá»«ng lÃ m cho bá»‡nh viá»‡n lÃ m vÃ  chia sáº» láº¡i vá»›i ae, mong lÃ  sáº½ giÃºp Ä‘Æ°á»£c cho ae Ä‘ang cáº§n mÃ  chÆ°a cÃ³ hÆ°á»›ng nghiÃªn cá»©u nhÃ©!","xin phÃ©p admin - Xin chÃ o ae, hÃ´m nay mÃ¬nh chia sáº» tá»›i ae pháº§n má»m dá»± Ä‘oÃ¡n bá»‡nh vÃ  lá»±a chá»n phÃ²ng khÃ¡m trong bá»‡nh viá»‡n. Cháº¯c háº³n Ä‘Ã¢y cÅ©ng lÃ  má»™t á»©ng dá»¥ng mÃ  nhiá»u ae Ä‘ang tÃ¬m, nghiÃªn cá»©u vÃ  á»©ng dá»¥ng. Pháº§n má»m nÃ y Ä‘Æ°á»£c ae trÆ°á»›c kia tá»«ng lÃ m cho bá»‡nh viá»‡n lÃ m vÃ  chia sáº» láº¡i vá»›i ae, mong lÃ  sáº½ giÃºp Ä‘Æ°á»£c cho ae Ä‘ang cáº§n mÃ  chÆ°a cÃ³ hÆ°á»›ng nghiÃªn cá»©u nhÃ©!",#ASM,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i tá»¥i em Ä‘ang lÃ m kháº£o sÃ¡t vá» Ä‘á»™ hiá»‡u quáº£ cá»§a nhá»¯ng mÃ´ hÃ¬nh xoÃ¡ vÃ  táº¡o áº£nh khÃ¡c nhau.
Náº¿u má»i ngÆ°á»i cÃ³ thá»i gian thÃ¬ cÃ³ thá»ƒ tham gia kháº£o sÃ¡t vÃ i phÃºt Ä‘Æ°á»£c khÃ´ng áº¡.
Em cáº£m Æ¡n
https://docs.google.com/forms/d/e/1FAIpQLSf5Z0sDgoDBEaWzBY7WJDDK5SyWFkPWClkocKqKsT5UoKwFiw/viewform?vc=0&c=0&w=1&flr=0&fbzx=5178650705536400224&fbclid=IwAR2rai7I93AfMTV2us7SyfnAl0bYFdipwksAGq2qHlYkXAvLuDTqTq-ElcI","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i tá»¥i em Ä‘ang lÃ m kháº£o sÃ¡t vá» Ä‘á»™ hiá»‡u quáº£ cá»§a nhá»¯ng mÃ´ hÃ¬nh xoÃ¡ vÃ  táº¡o áº£nh khÃ¡c nhau. Náº¿u má»i ngÆ°á»i cÃ³ thá»i gian thÃ¬ cÃ³ thá»ƒ tham gia kháº£o sÃ¡t vÃ i phÃºt Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n https://docs.google.com/forms/d/e/1FAIpQLSf5Z0sDgoDBEaWzBY7WJDDK5SyWFkPWClkocKqKsT5UoKwFiw/viewform?vc=0&c=0&w=1&flr=0&fbzx=5178650705536400224&fbclid=IwAR2rai7I93AfMTV2us7SyfnAl0bYFdipwksAGq2qHlYkXAvLuDTqTq-ElcI",,,,,
"[CHIA Sáºº] OBJECT DETECTION TRÃŠN MOBILE
Táº¡i Google I/O tuáº§n trÆ°á»›c, mÃ¬nh má»›i release má»™t tutorial series hÆ°á»›ng dáº«n cÃ¡ch train model object detection trÃªn dá»¯ liá»‡u má»›i vÃ  deploy trÃªn mobile app má»™t cÃ¡ch ráº¥t Ä‘Æ¡n giáº£n. Model dÃ¹ng á»Ÿ Ä‘Ã¢y lÃ  EfficientDet-Lite. EfficientDet lÃ  model táº¡o ra báº±ng ká»¹ thuáº­t Neural Architecture Search, vÃ  Ä‘áº¡t state-of-the-art cho object detection. CÃ²n EfficientDet-Lite lÃ  phiÃªn báº£n cá»§a EfficientDet Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hoÃ¡ cho mobile vÃ  thiáº¿t bá»‹ IoT. Tutorial nÃ y dÃ¹ng TensorFlow Lite Model Maker vÃ  Task Library lÃ  hai thÆ° viá»‡n giÃºp train vÃ  deploy model trÃªn mobile chá»‰ báº±ng vÃ i dÃ²ng code :)

Hy vá»ng cÃ¡c tutorial nÃ y sáº½ cÃ³ Ã­ch cho nhiá»u báº¡n. :D

https://www.youtube.com/watch?v=sK2c66xqFDk","[CHIA Sáºº] OBJECT DETECTION TRÃŠN MOBILE Táº¡i Google I/O tuáº§n trÆ°á»›c, mÃ¬nh má»›i release má»™t tutorial series hÆ°á»›ng dáº«n cÃ¡ch train model object detection trÃªn dá»¯ liá»‡u má»›i vÃ  deploy trÃªn mobile app má»™t cÃ¡ch ráº¥t Ä‘Æ¡n giáº£n. Model dÃ¹ng á»Ÿ Ä‘Ã¢y lÃ  EfficientDet-Lite. EfficientDet lÃ  model táº¡o ra báº±ng ká»¹ thuáº­t Neural Architecture Search, vÃ  Ä‘áº¡t state-of-the-art cho object detection. CÃ²n EfficientDet-Lite lÃ  phiÃªn báº£n cá»§a EfficientDet Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hoÃ¡ cho mobile vÃ  thiáº¿t bá»‹ IoT. Tutorial nÃ y dÃ¹ng TensorFlow Lite Model Maker vÃ  Task Library lÃ  hai thÆ° viá»‡n giÃºp train vÃ  deploy model trÃªn mobile chá»‰ báº±ng vÃ i dÃ²ng code :) Hy vá»ng cÃ¡c tutorial nÃ y sáº½ cÃ³ Ã­ch cho nhiá»u báº¡n. :D https://www.youtube.com/watch?v=sK2c66xqFDk",,,,,
"ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ lÃ m Try-on AR App ko áº¡? Em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» xÃ¢y dá»±ng AR App trÃªn iOS, em cÃ³ tham kháº£o MakeML Nails Segmentation vÃ  dÃ¹ng deeplab Ä‘á»ƒ train thÃ¬ Ä‘Æ°á»£c káº¿t quáº£ nhÆ° hÃ¬nh, em muá»‘n há»i lÃ  mÃ¬nh muá»‘n lÃ m chá»©c nÄƒng Ä‘á»•i kiá»ƒu mÃ³ng thÃ¬ mÃ¬nh cáº§n lÃ m nhÆ° nÃ o áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i!
Link em tham kháº£o:
https://makeml.app/nails-segmentation-tutorial","ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai Ä‘Ã£ lÃ m Try-on AR App ko áº¡? Em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» xÃ¢y dá»±ng AR App trÃªn iOS, em cÃ³ tham kháº£o MakeML Nails Segmentation vÃ  dÃ¹ng deeplab Ä‘á»ƒ train thÃ¬ Ä‘Æ°á»£c káº¿t quáº£ nhÆ° hÃ¬nh, em muá»‘n há»i lÃ  mÃ¬nh muá»‘n lÃ m chá»©c nÄƒng Ä‘á»•i kiá»ƒu mÃ³ng thÃ¬ mÃ¬nh cáº§n lÃ m nhÆ° nÃ o áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i! Link em tham kháº£o: https://makeml.app/nails-segmentation-tutorial",,,,,
"Xin chÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i Ä‘ang cÃ³ váº¥n Ä‘á» chÆ°a hiá»ƒu khi thá»­ nghiá»‡m mÃ´ hÃ¬nh, mong má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p.
Chuyá»‡n lÃ  em sá»­ dá»¥ng hÃ m DynamicUnet tá»« thÆ° viá»‡n fastai Ä‘á»ƒ build 1 cÃ¡i Unet tá»« má»™t cÃ¡i backbone (á»Ÿ Ä‘Ã¢y em dÃ¹ng backbone ResNet). Má»i thá»© diá»…n ra tá»‘t Ä‘áº¹p, tuy nhiÃªn trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m mÃ´ hÃ¬nh em láº¡i khÃ´ng biáº¿t táº¡i sao mÃ´ hÃ¬nh váº«n cÃ³ thá»ƒ lÃ m viá»‡c vá»›i nhá»¯ng áº£nh cÃ³ kÃ­ch thÆ°á»›c khÃ¡c vá»›i áº£nh lÃºc em khá»Ÿi táº¡o (256x256). DÆ°á»›i Ä‘Ã¢y lÃ  demo cho viá»‡c káº¿t quáº£ Ä‘áº§u ra váº«n Ä‘Æ°á»£c tÃ­nh ráº¥t bÃ¬nh thÆ°á»ng dÃ¹ kÃ­ch thÆ°á»›c khÃ´ng Ä‘Ãºng nhÆ° kÃ­ch thÆ°á»›c ban Ä‘áº§u.
Link Doc DynamicUnet: https://docs.fast.ai/vision.models.unet.html","Xin chÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i Ä‘ang cÃ³ váº¥n Ä‘á» chÆ°a hiá»ƒu khi thá»­ nghiá»‡m mÃ´ hÃ¬nh, mong má»i ngÆ°á»i cÃ³ thá»ƒ giáº£i Ä‘Ã¡p. Chuyá»‡n lÃ  em sá»­ dá»¥ng hÃ m DynamicUnet tá»« thÆ° viá»‡n fastai Ä‘á»ƒ build 1 cÃ¡i Unet tá»« má»™t cÃ¡i backbone (á»Ÿ Ä‘Ã¢y em dÃ¹ng backbone ResNet). Má»i thá»© diá»…n ra tá»‘t Ä‘áº¹p, tuy nhiÃªn trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m mÃ´ hÃ¬nh em láº¡i khÃ´ng biáº¿t táº¡i sao mÃ´ hÃ¬nh váº«n cÃ³ thá»ƒ lÃ m viá»‡c vá»›i nhá»¯ng áº£nh cÃ³ kÃ­ch thÆ°á»›c khÃ¡c vá»›i áº£nh lÃºc em khá»Ÿi táº¡o (256x256). DÆ°á»›i Ä‘Ã¢y lÃ  demo cho viá»‡c káº¿t quáº£ Ä‘áº§u ra váº«n Ä‘Æ°á»£c tÃ­nh ráº¥t bÃ¬nh thÆ°á»ng dÃ¹ kÃ­ch thÆ°á»›c khÃ´ng Ä‘Ãºng nhÆ° kÃ­ch thÆ°á»›c ban Ä‘áº§u. Link Doc DynamicUnet: https://docs.fast.ai/vision.models.unet.html",,,,,
"[Pytorch series]
BÃ i 6: LÆ°u vÃ  load model trong Pytorch.
Nhá»¯ng bÃ i trÆ°á»›c mÃ¬nh Ä‘Ã£ há»c cÃ¡ch xÃ¢y dá»±ng vÃ  train deep learning model báº±ng Pytorch. Tuy nhiÃªn, khi train xong model mÃ¬nh cáº§n lÆ°u Ä‘Æ°á»£c model Ä‘Ã£ train, Ä‘á»ƒ sau cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n hoáº·c tiáº¿p tá»¥c train mÃ  khÃ´ng cáº§n train láº¡i tá»« Ä‘áº§u. BÃ i nÃ y mÃ¬nh sáº½ hÆ°á»›ng dáº«n lÆ°u vÃ  load model trong Pytorch.
https://nttuan8.com/bai-6-luu-va-load-model-trong-pytorch/","[Pytorch series] BÃ i 6: LÆ°u vÃ  load model trong Pytorch. Nhá»¯ng bÃ i trÆ°á»›c mÃ¬nh Ä‘Ã£ há»c cÃ¡ch xÃ¢y dá»±ng vÃ  train deep learning model báº±ng Pytorch. Tuy nhiÃªn, khi train xong model mÃ¬nh cáº§n lÆ°u Ä‘Æ°á»£c model Ä‘Ã£ train, Ä‘á»ƒ sau cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n hoáº·c tiáº¿p tá»¥c train mÃ  khÃ´ng cáº§n train láº¡i tá»« Ä‘áº§u. BÃ i nÃ y mÃ¬nh sáº½ hÆ°á»›ng dáº«n lÆ°u vÃ  load model trong Pytorch. https://nttuan8.com/bai-6-luu-va-load-model-trong-pytorch/",,,,,
Anh chá»‹ cÃ³ thá»ƒ cho em há»i lÃ  táº¡i sao trong Shuffle Unit thÃ¬ Group Convolution Ä‘áº§u tiÃªn láº¡i dÃ¹ng 1/4 channels khÃ´ng áº¡. Em xin cáº£m Æ¡n.,Anh chá»‹ cÃ³ thá»ƒ cho em há»i lÃ  táº¡i sao trong Shuffle Unit thÃ¬ Group Convolution Ä‘áº§u tiÃªn láº¡i dÃ¹ng 1/4 channels khÃ´ng áº¡. Em xin cáº£m Æ¡n.,,,,,
"Em chÃ o anh/chá»‹/báº¡n. ChÃºc má»i ngÆ°á»i buá»•i tá»‘i vui váº». 
Em Ä‘ang cÃ³ gáº·p váº¥n Ä‘á» nÃ y mÃ  chÆ°a giáº£i Ä‘Æ°á»£c sau 3 tá»‘i suy nghÄ©. 
Em Ä‘Äƒng lÃªn Ä‘Ã¢y Ä‘á»ƒ xin má»i ngÆ°á»i keyword Ä‘á»ƒ em tÃ¬m hÆ°á»›ng em lÃ m áº¡. 
(Em Ä‘Ã£ thá»­ dÃ¹ng quy hoáº¡ch tuyáº¿n tÃ­nh Ä‘á»ƒ giáº£i nhÆ°ng cÃ³ váº» khÃ´ng Äƒn thua)
Äá» bÃ i báº±ng lá»i:
Cho 4 biáº¿n A - B - C - D, biáº¿t:
- Sá»‘ lÆ°á»£ng: sá»‘ Ä‘Æ¡n vá»‹ max cá»§a tá»«ng biáº¿n (VD: cÃ³ 735 Ä‘Æ¡n vá»‹ cá»§a biáº¿n A trong kho).
- Sá»‘ tiá»n/tá»«ng biáº¿n: giÃ¡ cá»§a biáº¿n (VD: má»—i Ä‘Æ¡n vá»‹ biáº¿n A cÃ³ giÃ¡ 5000 => tá»•ng giÃ¡ trá»‹ cá»§a biáº¿n A trong kho = 5000*735= 3675000)
1. TÃ¬m % giáº£m sá»‘ tiá»n/tá»«ng biáº¿n (giÃ¡) Ä‘á»ƒ cÃ³ thá»ƒ ""bÃ¡n"" Ä‘c sá»‘ lÆ°á»£ng tá»•ng ABCD nhiá»u nháº¥t vá»›i giÃ¡ trá»‹ tá»•ng khÃ´ng quÃ¡ 10.000.000 vÃ  tá»•ng % giáº£m giÃ¡ lÃ  <= 15%
2. TÃ¬m % giáº£m sá»‘ tiá»n/tá»«ng biáº¿n (giÃ¡) Ä‘á»ƒ cÃ³ thá»ƒ ""bÃ¡n Ä‘Æ°á»£c sá»‘ lÆ°á»£ng tá»•ng ABCD nhiá»u nháº¥t vá»›i giÃ¡ trá»‹ tá»•ng tháº¥p nháº¥t vÃ  tá»•ng % giáº£m giÃ¡ lÃ  <= 15%
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian giÃºp em ráº¥t nhiá»u áº¡!","Em chÃ o anh/chá»‹/báº¡n. ChÃºc má»i ngÆ°á»i buá»•i tá»‘i vui váº». Em Ä‘ang cÃ³ gáº·p váº¥n Ä‘á» nÃ y mÃ  chÆ°a giáº£i Ä‘Æ°á»£c sau 3 tá»‘i suy nghÄ©. Em Ä‘Äƒng lÃªn Ä‘Ã¢y Ä‘á»ƒ xin má»i ngÆ°á»i keyword Ä‘á»ƒ em tÃ¬m hÆ°á»›ng em lÃ m áº¡. (Em Ä‘Ã£ thá»­ dÃ¹ng quy hoáº¡ch tuyáº¿n tÃ­nh Ä‘á»ƒ giáº£i nhÆ°ng cÃ³ váº» khÃ´ng Äƒn thua) Äá» bÃ i báº±ng lá»i: Cho 4 biáº¿n A - B - C - D, biáº¿t: - Sá»‘ lÆ°á»£ng: sá»‘ Ä‘Æ¡n vá»‹ max cá»§a tá»«ng biáº¿n (VD: cÃ³ 735 Ä‘Æ¡n vá»‹ cá»§a biáº¿n A trong kho). - Sá»‘ tiá»n/tá»«ng biáº¿n: giÃ¡ cá»§a biáº¿n (VD: má»—i Ä‘Æ¡n vá»‹ biáº¿n A cÃ³ giÃ¡ 5000 => tá»•ng giÃ¡ trá»‹ cá»§a biáº¿n A trong kho = 5000*735= 3675000) 1. TÃ¬m % giáº£m sá»‘ tiá»n/tá»«ng biáº¿n (giÃ¡) Ä‘á»ƒ cÃ³ thá»ƒ ""bÃ¡n"" Ä‘c sá»‘ lÆ°á»£ng tá»•ng ABCD nhiá»u nháº¥t vá»›i giÃ¡ trá»‹ tá»•ng khÃ´ng quÃ¡ 10.000.000 vÃ  tá»•ng % giáº£m giÃ¡ lÃ  <= 15% 2. TÃ¬m % giáº£m sá»‘ tiá»n/tá»«ng biáº¿n (giÃ¡) Ä‘á»ƒ cÃ³ thá»ƒ ""bÃ¡n Ä‘Æ°á»£c sá»‘ lÆ°á»£ng tá»•ng ABCD nhiá»u nháº¥t vá»›i giÃ¡ trá»‹ tá»•ng tháº¥p nháº¥t vÃ  tá»•ng % giáº£m giÃ¡ lÃ  <= 15% Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ dÃ nh thá»i gian giÃºp em ráº¥t nhiá»u áº¡!",,"#Q&A, #math",,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh vá»«a tá»‘t nghiá»‡p Ä‘áº¡i há»c vÃ  cÃ³ gáº§n 1 nÄƒm lÃ m viá»‡c trong phÃ²ng nghiÃªn cá»©u cá»§a trÆ°á»ng (chuyÃªn vá» Natural Language Processing). TrÆ°á»ng mÃ¬nh thÃ¬ khÃ´ng máº¡nh vá» máº£ng Deep Learning (chá»‰ cÃ³ há»c Master vÃ  PhD má»›i cÃ³ nhá»¯ng lá»›p chuyÃªn sÃ¢u), kiáº¿n thá»©c chung mÃ¬nh cÃ³ Ä‘Æ°á»£c lÃ  qua 2 lá»›p Data Science 1 vÃ  2 cá»§a trÆ°á»ng, cÃ²n láº¡i háº§u nhÆ° lÃ  mÃ¬nh tá»± há»c, há»i tháº§y mÃ¬nh, vÃ  kinh nghiá»‡m mÃ¬nh cÃ³ Ä‘Æ°á»£c do lÃ m trong phÃ²ng lab cá»§a trÆ°á»ng. MÃ¬nh cÃ³ thá»­ ná»™p Ä‘Æ¡n xin viá»‡c qua 1 sá»‘ cÃ´ng ty nhÆ°ng háº§u nhÆ° toÃ n bá»‹ tá»« chá»‘i máº·c dÃ¹ mÃ¬nh tháº¥y resume vÃ  skills cá»§a mÃ¬nh match Ä‘a sá»‘ nhá»¯ng yÃªu cáº§u cá»§a cÃ´ng ty.
MÃ¬nh muá»‘n tÃ¬m cÃ´ng viá»‡c á»Ÿ vá»‹ trÃ­ NLP developer hoáº·c NLP Engineering. CÃ¡c báº¡n Ä‘Ã£ vÃ  Ä‘ang lÃ m viá»‡c á»Ÿ vá»‹ trÃ­ nÃ y hoáº·c tÆ°Æ¡ng tá»± cÃ³ thá»ƒ tÆ° váº¥n cho mÃ¬nh nhá»¯ng ká»¹ nÄƒng vÃ  kiáº¿n thá»©c nÃ o mÃ¬nh cáº§n bá»• sung Ä‘á»ƒ cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c cÃ´ng viá»‡c á»Ÿ máº£ng NLP vá»›i báº±ng Ä‘áº¡i há»c Ä‘Æ°á»£c khÃ´ng áº¡? MÃ¬nh Ä‘ang sá»‘ng á»Ÿ bang Texas, thÃ nh phá»‘ Houston áº¡.
MÃ¬nh sáº½ gá»Ÿi kÃ¨m resume cá»§a mÃ¬nh. Xin cÃ¡m Æ¡n cÃ¡c báº¡n.
ChÃºc má»™t ngÃ y tá»‘t lÃ nh","ChÃ o cÃ¡c báº¡n, mÃ¬nh vá»«a tá»‘t nghiá»‡p Ä‘áº¡i há»c vÃ  cÃ³ gáº§n 1 nÄƒm lÃ m viá»‡c trong phÃ²ng nghiÃªn cá»©u cá»§a trÆ°á»ng (chuyÃªn vá» Natural Language Processing). TrÆ°á»ng mÃ¬nh thÃ¬ khÃ´ng máº¡nh vá» máº£ng Deep Learning (chá»‰ cÃ³ há»c Master vÃ  PhD má»›i cÃ³ nhá»¯ng lá»›p chuyÃªn sÃ¢u), kiáº¿n thá»©c chung mÃ¬nh cÃ³ Ä‘Æ°á»£c lÃ  qua 2 lá»›p Data Science 1 vÃ  2 cá»§a trÆ°á»ng, cÃ²n láº¡i háº§u nhÆ° lÃ  mÃ¬nh tá»± há»c, há»i tháº§y mÃ¬nh, vÃ  kinh nghiá»‡m mÃ¬nh cÃ³ Ä‘Æ°á»£c do lÃ m trong phÃ²ng lab cá»§a trÆ°á»ng. MÃ¬nh cÃ³ thá»­ ná»™p Ä‘Æ¡n xin viá»‡c qua 1 sá»‘ cÃ´ng ty nhÆ°ng háº§u nhÆ° toÃ n bá»‹ tá»« chá»‘i máº·c dÃ¹ mÃ¬nh tháº¥y resume vÃ  skills cá»§a mÃ¬nh match Ä‘a sá»‘ nhá»¯ng yÃªu cáº§u cá»§a cÃ´ng ty. MÃ¬nh muá»‘n tÃ¬m cÃ´ng viá»‡c á»Ÿ vá»‹ trÃ­ NLP developer hoáº·c NLP Engineering. CÃ¡c báº¡n Ä‘Ã£ vÃ  Ä‘ang lÃ m viá»‡c á»Ÿ vá»‹ trÃ­ nÃ y hoáº·c tÆ°Æ¡ng tá»± cÃ³ thá»ƒ tÆ° váº¥n cho mÃ¬nh nhá»¯ng ká»¹ nÄƒng vÃ  kiáº¿n thá»©c nÃ o mÃ¬nh cáº§n bá»• sung Ä‘á»ƒ cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c cÃ´ng viá»‡c á»Ÿ máº£ng NLP vá»›i báº±ng Ä‘áº¡i há»c Ä‘Æ°á»£c khÃ´ng áº¡? MÃ¬nh Ä‘ang sá»‘ng á»Ÿ bang Texas, thÃ nh phá»‘ Houston áº¡. MÃ¬nh sáº½ gá»Ÿi kÃ¨m resume cá»§a mÃ¬nh. Xin cÃ¡m Æ¡n cÃ¡c báº¡n. ChÃºc má»™t ngÃ y tá»‘t lÃ nh",,,,,
"Xin chÃ o má»i ngÆ°á»i,
Em Ä‘ang dá»± Ä‘á»‹nh lÃ m project vá» bÃ i toÃ¡n Machine Reading Comprehension trÃªn ngÃ´n ngá»¯ tiáº¿ng Viá»‡t. Vá» dataset thÃ¬ em dá»± Ä‘á»‹nh sá»­ dá»¥ng bá»™ corpus news, vá»›i liÃªn há»‡ xin bá»™ UIT-ViQuAD cá»§a tháº§y Kiá»‡t.
CÃ²n vá» mÃ´ hÃ¬nh, hÆ°á»›ng tiáº¿p cáº­n vá»›i cÅ©ng nhÆ° tÃ i liá»‡u tham kháº£o cáº£ MRC trÃªn tiáº¿ng Anh hay tiáº¿ng Viá»‡t, e cÅ©ng cÃ³ Ä‘á»c qua 1 sá»‘, nhÆ°ng váº«n muá»‘n nhá» má»i ngÆ°á»i chia sáº» 1 sá»‘ tÃ i liá»‡u, hÆ°á»›ng dáº«n thÃªm Ä‘á»ƒ em nghiÃªn cá»©u Ä‘i Ä‘Ãºng hÆ°á»›ng hÆ¡n.
Cáº£m Æ¡n má»i ngÆ°á»i :)","Xin chÃ o má»i ngÆ°á»i, Em Ä‘ang dá»± Ä‘á»‹nh lÃ m project vá» bÃ i toÃ¡n Machine Reading Comprehension trÃªn ngÃ´n ngá»¯ tiáº¿ng Viá»‡t. Vá» dataset thÃ¬ em dá»± Ä‘á»‹nh sá»­ dá»¥ng bá»™ corpus news, vá»›i liÃªn há»‡ xin bá»™ UIT-ViQuAD cá»§a tháº§y Kiá»‡t. CÃ²n vá» mÃ´ hÃ¬nh, hÆ°á»›ng tiáº¿p cáº­n vá»›i cÅ©ng nhÆ° tÃ i liá»‡u tham kháº£o cáº£ MRC trÃªn tiáº¿ng Anh hay tiáº¿ng Viá»‡t, e cÅ©ng cÃ³ Ä‘á»c qua 1 sá»‘, nhÆ°ng váº«n muá»‘n nhá» má»i ngÆ°á»i chia sáº» 1 sá»‘ tÃ i liá»‡u, hÆ°á»›ng dáº«n thÃªm Ä‘á»ƒ em nghiÃªn cá»©u Ä‘i Ä‘Ãºng hÆ°á»›ng hÆ¡n. Cáº£m Æ¡n má»i ngÆ°á»i :)",,,,,
"MÃ¬nh cÃ³ 2 cÃ¢u há»i ngu mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡, vá» demography problem.
1. Tá»‰ lá»‡ Nam ná»¯ lÃ  9:1. Khi trÃ¬nh bÃ y vá»›i ngÆ°á»i khÃ´ng biáº¿t gÃ¬ vá» cÃ¡c metrics nhÆ° F1-score thÃ¬ má»i ngÆ°á»i hay dÃ¹ng metric nÃ o, chá»© log loss thÃ¬ khÃ´ng thá»ƒ mang Ä‘i trÃ¬nh bÃ y Ä‘Æ°á»£c.
2 Vá» Ä‘á»™ tuá»•i. Giáº£ sá»­ mÃ¬nh chia lÃ m 4 nhÃ³m 18-, 18-30, 30-40, 40+. Náº¿u dá»± Ä‘oÃ¡n nhÃ³m 18-30 sai thÃ nh 30-40 thÃ¬ loss sáº½ tháº¥p hÆ¡n dá»± Ä‘oÃ¡n nhÃ³m dÆ°á»›i 18 thÃ nh cÃ¡c nhÃ³m khÃ¡c, vÃ¬ khi dá»± Ä‘oÃ¡n 18- thÃ nh nhÃ³m cao hÆ¡n, cÃ³ thá»ƒ bá»‹ gá»£i Ã½ phim porn cho lá»©a tuá»•i vá»‹ thÃ nh niÃªn. Má»i ngÆ°á»i sáº½ Ä‘á»‹nh nghÄ©a loss function cho model tháº¿ nÃ o áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c ğŸ¤—ğŸ¤—","MÃ¬nh cÃ³ 2 cÃ¢u há»i ngu mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡, vá» demography problem. 1. Tá»‰ lá»‡ Nam ná»¯ lÃ  9:1. Khi trÃ¬nh bÃ y vá»›i ngÆ°á»i khÃ´ng biáº¿t gÃ¬ vá» cÃ¡c metrics nhÆ° F1-score thÃ¬ má»i ngÆ°á»i hay dÃ¹ng metric nÃ o, chá»© log loss thÃ¬ khÃ´ng thá»ƒ mang Ä‘i trÃ¬nh bÃ y Ä‘Æ°á»£c. 2 Vá» Ä‘á»™ tuá»•i. Giáº£ sá»­ mÃ¬nh chia lÃ m 4 nhÃ³m 18-, 18-30, 30-40, 40+. Náº¿u dá»± Ä‘oÃ¡n nhÃ³m 18-30 sai thÃ nh 30-40 thÃ¬ loss sáº½ tháº¥p hÆ¡n dá»± Ä‘oÃ¡n nhÃ³m dÆ°á»›i 18 thÃ nh cÃ¡c nhÃ³m khÃ¡c, vÃ¬ khi dá»± Ä‘oÃ¡n 18- thÃ nh nhÃ³m cao hÆ¡n, cÃ³ thá»ƒ bá»‹ gá»£i Ã½ phim porn cho lá»©a tuá»•i vá»‹ thÃ nh niÃªn. Má»i ngÆ°á»i sáº½ Ä‘á»‹nh nghÄ©a loss function cho model tháº¿ nÃ o áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c",,,,,
"Xin chÃ o cÃ¡c anh chá»‹,
Trong quÃ¡ trÃ¬nh há»c mÃ´n Äáº¡i sá»‘, tháº§y dáº¡y cá»§a em cÃ³ Ä‘áº·t cÃ¢u há»i: :""Má»¥c Ä‘Ã­ch/LÃ­ do cá»§a viá»‡c Ã¡p dá»¥ng thuáº­t toÃ¡n PCA vÃ o ma tráº­n?"". Theo em nghÄ© thÃ¬ do táº§m quan trá»ng cá»§a ma tráº­n, Ä‘a sá»‘ dá»¯ liá»‡u Ä‘á»u Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi nÃ³ vÃ  ma tráº­n lÃ  cÃ´ng cá»¥ toÃ¡n há»c há»¯u Ã­ch trong Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh. KhÃ´ng biáº¿t suy nghÄ© cá»§a em Ä‘Ãºng chÆ°a áº¡? Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§ tá»« cÃ¡c anh chá»‹.
Em xin cáº£m Æ¡n.","Xin chÃ o cÃ¡c anh chá»‹, Trong quÃ¡ trÃ¬nh há»c mÃ´n Äáº¡i sá»‘, tháº§y dáº¡y cá»§a em cÃ³ Ä‘áº·t cÃ¢u há»i: :""Má»¥c Ä‘Ã­ch/LÃ­ do cá»§a viá»‡c Ã¡p dá»¥ng thuáº­t toÃ¡n PCA vÃ o ma tráº­n?"". Theo em nghÄ© thÃ¬ do táº§m quan trá»ng cá»§a ma tráº­n, Ä‘a sá»‘ dá»¯ liá»‡u Ä‘á»u Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi nÃ³ vÃ  ma tráº­n lÃ  cÃ´ng cá»¥ toÃ¡n há»c há»¯u Ã­ch trong Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh. KhÃ´ng biáº¿t suy nghÄ© cá»§a em Ä‘Ãºng chÆ°a áº¡? Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§ tá»« cÃ¡c anh chá»‹. Em xin cáº£m Æ¡n.",,"#Q&A, #math",,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu cÆ¡ cháº¿ multihead self attention cá»§a Transformer vÃ  cÃ³ má»™t sá»‘ tháº¯c máº¯c:
- MÃ¬nh tham kháº£o trÃªn blog http://jalammar.github.io/illustrated-transformer/ thÃ¬ hiá»ƒu ráº±ng, vá»›i má»—i head thá»© i, Ä‘á»ƒ táº¡o ra ba ma tráº­n Qi, Ki, Vi tÆ°Æ¡ng á»©ng thÃ¬ ta cáº§n nhÃ¢n embedding cá»§a tá»« ban Ä‘áº§u vá»›i cÃ¡c ma tráº­n Wqi, Wki vÃ  Wvi tÆ°Æ¡ng á»©ng.
- Tuy nhiÃªn, trong paper chÃ­nh https://arxiv.org/pdf/1706.03762.pdf thÃ¬ mÃ¬nh tháº¥y tÃ¡c giáº£ cÃ³ chiáº¿u Q, K, V qua má»™t hÃ m Linear, cá»¥ thá»ƒ nhÆ° áº£nh phÃ­a dÆ°á»›i. Chá»— nÃ y mÃ¬nh hÆ¡i confused má»™t chÃºt, khÃ´ng biáº¿t Q, K, V á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c tÃ­nh tháº¿ nÃ o, vÃ  mÃ¬nh cáº£m giÃ¡c nÃ³ hÆ¡i khÃ¡c so vá»›i blog mÃ¬nh Ä‘á»c á»Ÿ trÃªn.
Ráº¥t mong Ä‘Æ°á»£c cÃ¡c cao thá»§ chá»‰ giÃ¡o áº¡, many thanks ğŸ™‚","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu cÆ¡ cháº¿ multihead self attention cá»§a Transformer vÃ  cÃ³ má»™t sá»‘ tháº¯c máº¯c: - MÃ¬nh tham kháº£o trÃªn blog http://jalammar.github.io/illustrated-transformer/ thÃ¬ hiá»ƒu ráº±ng, vá»›i má»—i head thá»© i, Ä‘á»ƒ táº¡o ra ba ma tráº­n Qi, Ki, Vi tÆ°Æ¡ng á»©ng thÃ¬ ta cáº§n nhÃ¢n embedding cá»§a tá»« ban Ä‘áº§u vá»›i cÃ¡c ma tráº­n Wqi, Wki vÃ  Wvi tÆ°Æ¡ng á»©ng. - Tuy nhiÃªn, trong paper chÃ­nh https://arxiv.org/pdf/1706.03762.pdf thÃ¬ mÃ¬nh tháº¥y tÃ¡c giáº£ cÃ³ chiáº¿u Q, K, V qua má»™t hÃ m Linear, cá»¥ thá»ƒ nhÆ° áº£nh phÃ­a dÆ°á»›i. Chá»— nÃ y mÃ¬nh hÆ¡i confused má»™t chÃºt, khÃ´ng biáº¿t Q, K, V á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c tÃ­nh tháº¿ nÃ o, vÃ  mÃ¬nh cáº£m giÃ¡c nÃ³ hÆ¡i khÃ¡c so vá»›i blog mÃ¬nh Ä‘á»c á»Ÿ trÃªn. Ráº¥t mong Ä‘Æ°á»£c cÃ¡c cao thá»§ chá»‰ giÃ¡o áº¡, many thanks",,,,,
"ChÃ o má»i ngÆ°á»i, cho em há»i má»™t chÃºt vá» hÃ m cross-entropy loss trong hÃ¬nh dÆ°á»›i áº¡. CÃ³ tÃ i liá»‡u gÃ¬ giáº£i thÃ­ch rÃµ rÃ ng khÃ´ng áº¡, em chÆ°a rÃµ rÃ ng vá» chá»— "" hypothesis h with respect to a distribution D""? Em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, cho em há»i má»™t chÃºt vá» hÃ m cross-entropy loss trong hÃ¬nh dÆ°á»›i áº¡. CÃ³ tÃ i liá»‡u gÃ¬ giáº£i thÃ­ch rÃµ rÃ ng khÃ´ng áº¡, em chÆ°a rÃµ rÃ ng vá» chá»— "" hypothesis h with respect to a distribution D""? Em xin cáº£m Æ¡n.",,,,,
"Em xin chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em cÃ³ lÃ m Ä‘á» tÃ i vá» so sÃ¡nh image vÃ  caption thÃ´ng qua embedding. Em cÃ³ lÃ m theo phÆ°Æ¡ng phÃ¡p nhÆ° hÃ¬nh dÆ°á»›i, tuy nhiÃªn do lá»±a chá»n max score nÃªn em tÃ­nh tÃ¡ch 2 bÆ°á»›c FNN thÃ nh 2 neural network riÃªng biá»‡t (Do caption thÃ¬ cá»‘ Ä‘á»‹nh 2 caption nhÆ°ng bounding box trong image thÃ¬ cÃ³ thá»ƒ cÃ³ ráº¥t nhiá»u).
Em muá»‘n há»i lÃ  khi em tÃ­nh loss theo (S_rand - S_match) thÃ¬ lÃºc backward thÃ¬ liá»‡u loss cÃ³ Ã¡p dá»¥ng cho cáº£ 2 neural network khÃ´ng vÃ  liá»‡u lÃ m váº­y thÃ¬ cÃ³ sai logic dáº«n tá»›i viá»‡c model khÃ´ng há»™i tá»¥ khÃ´ng áº¡?
Em xin cáº£m Æ¡n áº¡.","Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em cÃ³ lÃ m Ä‘á» tÃ i vá» so sÃ¡nh image vÃ  caption thÃ´ng qua embedding. Em cÃ³ lÃ m theo phÆ°Æ¡ng phÃ¡p nhÆ° hÃ¬nh dÆ°á»›i, tuy nhiÃªn do lá»±a chá»n max score nÃªn em tÃ­nh tÃ¡ch 2 bÆ°á»›c FNN thÃ nh 2 neural network riÃªng biá»‡t (Do caption thÃ¬ cá»‘ Ä‘á»‹nh 2 caption nhÆ°ng bounding box trong image thÃ¬ cÃ³ thá»ƒ cÃ³ ráº¥t nhiá»u). Em muá»‘n há»i lÃ  khi em tÃ­nh loss theo (S_rand - S_match) thÃ¬ lÃºc backward thÃ¬ liá»‡u loss cÃ³ Ã¡p dá»¥ng cho cáº£ 2 neural network khÃ´ng vÃ  liá»‡u lÃ m váº­y thÃ¬ cÃ³ sai logic dáº«n tá»›i viá»‡c model khÃ´ng há»™i tá»¥ khÃ´ng áº¡? Em xin cáº£m Æ¡n áº¡.",,,,,
"[AI Share]
Roadmap vÃ  keyword vá» Natural Language Processing (NLP) dÃ nh cho sinh viÃªn Ä‘ang bÄƒn khoÄƒn khÃ´ng biáº¿t há»c gÃ¬ =))
Bao gá»“m Probability & Statistics, Machine Learning, Text Mining, Natural Language Processing.
Chi tiáº¿t: https://github.com/graykode/nlp-roadmap
___________________________
Náº¿u gáº·p khÃ³ khÄƒn trong viá»‡c há»c cÃ¡c kiáº¿n thá»©c ná»n táº£ng lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o, Ä‘á»«ng quÃªn cÃ¡c khÃ³a há»c bá»• Ã­ch cá»§a AI4E nhÃ©. KhÃ³a há»c Deep Learning cÆ¡ báº£n online sáº½ Ä‘Æ°á»£c khai giáº£ng vÃ o 19h ngÃ y 5/6 nhÃ©. Nhanh tay inbox page Ä‘á»ƒ Ä‘Æ°á»£c tham gia lá»›p há»c bá»• Ã­ch nÃ y nhÃ©.","[AI Share] Roadmap vÃ  keyword vá» Natural Language Processing (NLP) dÃ nh cho sinh viÃªn Ä‘ang bÄƒn khoÄƒn khÃ´ng biáº¿t há»c gÃ¬ =)) Bao gá»“m Probability & Statistics, Machine Learning, Text Mining, Natural Language Processing. Chi tiáº¿t: https://github.com/graykode/nlp-roadmap ___________________________ Náº¿u gáº·p khÃ³ khÄƒn trong viá»‡c há»c cÃ¡c kiáº¿n thá»©c ná»n táº£ng lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o, Ä‘á»«ng quÃªn cÃ¡c khÃ³a há»c bá»• Ã­ch cá»§a AI4E nhÃ©. KhÃ³a há»c Deep Learning cÆ¡ báº£n online sáº½ Ä‘Æ°á»£c khai giáº£ng vÃ o 19h ngÃ y 5/6 nhÃ©. Nhanh tay inbox page Ä‘á»ƒ Ä‘Æ°á»£c tham gia lá»›p há»c bá»• Ã­ch nÃ y nhÃ©.",,,,,
"Chia sáº» vá» AIcargo: má»™t app phá»¥c vá»¥host & chia sáº» AI models
ChÃ o cÃ¡c anh chá»‹ em trÃªn diá»…n Ä‘Ã n,
MÃ¬nh vÃ  cÃ¡c Ä‘á»“ng nghiá»‡p á»Ÿ Aitomatic Inc hiá»‡n Ä‘ang xÃ¢y dá»±ng má»™t framework & toolchain cho viá»‡c táº¡o cÃ¡c full-stack AI Apps. Trong bÆ°á»›c Ä‘áº§u cá»§a lá»™ trÃ¬nh nÃ y, bá»n mÃ¬nh vá»«a táº¡o ra má»™t cÃ¡i cÃ´ng cá»¥ miá»…n phÃ­ tÃªn lÃ  AIcargo Ä‘á»ƒ giÃºp cÃ¡c báº¡n lÃ m DS/AI dá»… dÃ ng host cÃ¡c models trÃªn cloud vÃ  chia sáº» vá»›i nhá»¯ng ngÆ°á»i khÃ¡c cho nhá»¯ng má»¥c Ä‘Ã­ch nhÆ° lÃ  interactive testing, cloud-based inference API hay lÃ  lÃ m há»“ sÆ¡ tuyá»ƒn dá»¥ng.
Bá»n mÃ¬nh vá»«a lÃ m xong báº£n beta, trÆ°á»›c háº¿t lÃ  há»— trá»£ use case phá»• biáº¿n nháº¥t lÃ  Image Classification. Trong cÃ¡c releases thá»i gian tá»›i Ä‘Ã¢y thÃ¬ sáº½ tiáº¿p tá»¥c há»— trá»£ cÃ¡c models thÃ´ng dá»¥ng khÃ¡c nhÆ° NLP, Time Series, Forecasting, Anomaly Detection...
Admin cho phÃ©p mÃ¬nh chia sáº» cÃ´ng cá»¥ AIcargo nÃ y á»Ÿ Ä‘Ã¢y Ä‘á»ƒ cá»™ng Ä‘á»“ng cÃ¹ng biáº¿t Ä‘á»ƒ cÃ³ thá»ƒ thá»­ sá»­ dá»¥ng vÃ  pháº£n há»“i Ã½ kiáº¿n láº¡i cho mÃ¬nh nhÃ©!
Thanks má»i ngÆ°á»i nhiá»u!","Chia sáº» vá» AIcargo: má»™t app phá»¥c vá»¥ host & chia sáº» AI models ChÃ o cÃ¡c anh chá»‹ em trÃªn diá»…n Ä‘Ã n, MÃ¬nh vÃ  cÃ¡c Ä‘á»“ng nghiá»‡p á»Ÿ Aitomatic Inc hiá»‡n Ä‘ang xÃ¢y dá»±ng má»™t framework & toolchain cho viá»‡c táº¡o cÃ¡c full-stack AI Apps. Trong bÆ°á»›c Ä‘áº§u cá»§a lá»™ trÃ¬nh nÃ y, bá»n mÃ¬nh vá»«a táº¡o ra má»™t cÃ¡i cÃ´ng cá»¥ miá»…n phÃ­ tÃªn lÃ  AIcargo Ä‘á»ƒ giÃºp cÃ¡c báº¡n lÃ m DS/AI dá»… dÃ ng host cÃ¡c models trÃªn cloud vÃ  chia sáº» vá»›i nhá»¯ng ngÆ°á»i khÃ¡c cho nhá»¯ng má»¥c Ä‘Ã­ch nhÆ° lÃ  interactive testing, cloud-based inference API hay lÃ  lÃ m há»“ sÆ¡ tuyá»ƒn dá»¥ng. Bá»n mÃ¬nh vá»«a lÃ m xong báº£n beta, trÆ°á»›c háº¿t lÃ  há»— trá»£ use case phá»• biáº¿n nháº¥t lÃ  Image Classification. Trong cÃ¡c releases thá»i gian tá»›i Ä‘Ã¢y thÃ¬ sáº½ tiáº¿p tá»¥c há»— trá»£ cÃ¡c models thÃ´ng dá»¥ng khÃ¡c nhÆ° NLP, Time Series, Forecasting, Anomaly Detection... Admin cho phÃ©p mÃ¬nh chia sáº» cÃ´ng cá»¥ AIcargo nÃ y á»Ÿ Ä‘Ã¢y Ä‘á»ƒ cá»™ng Ä‘á»“ng cÃ¹ng biáº¿t Ä‘á»ƒ cÃ³ thá»ƒ thá»­ sá»­ dá»¥ng vÃ  pháº£n há»“i Ã½ kiáº¿n láº¡i cho mÃ¬nh nhÃ©! Thanks má»i ngÆ°á»i nhiá»u!",,,,,
RepVGG lÃ  má»™t cáº£i tiáº¿n cá»§a mÃ´ hÃ¬nh khÃ¡ ná»•i tiáº¿ng Ä‘Ã£ ra Ä‘á»i khÃ¡ lÃ¢u lÃ  VGG. MÃ¬nh cÅ©ng Ä‘Ã£ thá»­ dÃ¹ng mÃ´ hÃ¬nh nÃ y lÃ m backbone trong má»™t vÃ i bÃ i toÃ¡n vÃ  thu Ä‘Æ°á»£c má»™t sá»‘ káº¿t quáº£ tá»‘t hÆ¡n ráº¥t nhiá»u so vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ  mÃ¬nh tá»«ng sá»­ dá»¥ng. Gáº§n Ä‘Ã¢y mÃ¬nh cÅ©ng cÃ³ viáº¿t má»™t bÃ i tÃ¬m hiá»ƒu má»™t chÃºt vá» mÃ´ hÃ¬nh nÃ y vÃ  chia sáº» cho má»i ngÆ°á»i. Hy vá»ng bÃ i viáº¿t sáº½ giÃºp Ã­ch nhiá»u cho cÃ¡c báº¡n trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu mÃ´ hÃ¬nh nÃ y áº¡. :),RepVGG lÃ  má»™t cáº£i tiáº¿n cá»§a mÃ´ hÃ¬nh khÃ¡ ná»•i tiáº¿ng Ä‘Ã£ ra Ä‘á»i khÃ¡ lÃ¢u lÃ  VGG. MÃ¬nh cÅ©ng Ä‘Ã£ thá»­ dÃ¹ng mÃ´ hÃ¬nh nÃ y lÃ m backbone trong má»™t vÃ i bÃ i toÃ¡n vÃ  thu Ä‘Æ°á»£c má»™t sá»‘ káº¿t quáº£ tá»‘t hÆ¡n ráº¥t nhiá»u so vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ  mÃ¬nh tá»«ng sá»­ dá»¥ng. Gáº§n Ä‘Ã¢y mÃ¬nh cÅ©ng cÃ³ viáº¿t má»™t bÃ i tÃ¬m hiá»ƒu má»™t chÃºt vá» mÃ´ hÃ¬nh nÃ y vÃ  chia sáº» cho má»i ngÆ°á»i. Hy vá»ng bÃ i viáº¿t sáº½ giÃºp Ã­ch nhiá»u cho cÃ¡c báº¡n trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu mÃ´ hÃ¬nh nÃ y áº¡. :),,,,,
#visualization,,#visualization,,,,
"[Há»i Ä‘Ã¡p/TÆ° váº¥n] Xin lá»i khuyÃªn tá»« anh/chá»‹ Ä‘i trÆ°á»›c
[ÄÃ£ edit]
Em xin chÃ o cÃ¡c anh/chá»‹/báº¡n.
Em vá»«a tá»‘t nghiá»‡p Ä‘h ngÃ nh khmt vÃ  Ä‘ang muá»‘n tiáº¿n lÃªn tháº¡c sÄ©. Em cÃ³ tham kháº£o Ä‘Æ°á»£c chÆ°Æ¡ng trÃ¬nh Data Science professional cá»§a AIT - káº¿t há»£p vá»›i Ä‘áº¡i há»c SET (link bÃªn dÆ°á»›i áº¡) vá»›i há»c phÃ­ 15k$ (~350tr vnÄ‘) vÃ  há»c chá»‰ trong 1 nÄƒm.
KhÃ´ng biáº¿t cÃ³ anh/chá»‹ nÃ o Ä‘i trÆ°á»›c Ä‘Ã£ tá»«ng há»c hay biáº¿t vá» ctr nÃ y cÃ³ thá»ƒ cho lá»i khuyÃªn (vá» cháº¥t lÆ°á»£ng, uy tÃ­n, cÆ¡ há»™i sau há»c,...) giÃºp e Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n.
Link khÃ³a há»c:","[Há»i Ä‘Ã¡p/TÆ° váº¥n] Xin lá»i khuyÃªn tá»« anh/chá»‹ Ä‘i trÆ°á»›c [ÄÃ£ edit] Em xin chÃ o cÃ¡c anh/chá»‹/báº¡n. Em vá»«a tá»‘t nghiá»‡p Ä‘h ngÃ nh khmt vÃ  Ä‘ang muá»‘n tiáº¿n lÃªn tháº¡c sÄ©. Em cÃ³ tham kháº£o Ä‘Æ°á»£c chÆ°Æ¡ng trÃ¬nh Data Science professional cá»§a AIT - káº¿t há»£p vá»›i Ä‘áº¡i há»c SET (link bÃªn dÆ°á»›i áº¡) vá»›i há»c phÃ­ 15k$ (~350tr vnÄ‘) vÃ  há»c chá»‰ trong 1 nÄƒm. KhÃ´ng biáº¿t cÃ³ anh/chá»‹ nÃ o Ä‘i trÆ°á»›c Ä‘Ã£ tá»«ng há»c hay biáº¿t vá» ctr nÃ y cÃ³ thá»ƒ cho lá»i khuyÃªn (vá» cháº¥t lÆ°á»£ng, uy tÃ­n, cÆ¡ há»™i sau há»c,...) giÃºp e Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n. Link khÃ³a há»c:",,,,,
GiÃ¡o sÆ° cá»±c máº¡nh nhÃ© cÃ¡c báº¡n.,GiÃ¡o sÆ° cá»±c máº¡nh nhÃ© cÃ¡c báº¡n.,,,,,
"ChÃ o má»i ngÆ°á»i, tÃ¬nh hÃ¬nh lÃ  mÃ¬nh vá»«a nghiÃªn cá»©u vá» kiá»ƒu dá»¯ liá»‡u trong ngÃ´n ngá»¯ C++ vÃ  python. MÃ¬nh post lÃªn Ä‘Ã¢y nháº±m má»¥c Ä‘Ã­ch chia sáº» cÅ©ng nhÆ° mong nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ náº¿u mÃ¬nh cÃ³ nghiÃªn cá»©u sai.
KÃ­ch thÆ°á»›c cá»§a cÃ¡c kiá»ƒu dá»¯ liá»‡u phá»• biáº¿n trong C++:
sizeof(int) and sizeof(float) is 4 bytes
sizeof(double) is 8 bytes
sizeof(pointer) is 4 or 8 bytes
KÃ­ch thÆ°á»›c cá»§a cÃ¡c kiá»ƒu dá»¯ liá»‡u phá»• biáº¿n trong Python2:
sizeof(int), sizeof(float) is 8 bytes
Trong python2 vÃ  python3, double coi nhÆ° float
NhÆ°ng thá»±c táº¿ náº¿u báº¡n gÃµ cÃº phÃ¡p sys.getsizeof() thÃ¬ sáº½ nháº­n vá» giÃ¡ trá»‹: 16 bytes (kÃ­ch thÆ°á»›c kiá»ƒu cÆ¡ báº£n cá»§a python2) + kÃ­ch thÆ°á»›c kiá»ƒu dá»¯ liá»‡u (cÃ³ thá»ƒ má»Ÿ rá»™ng náº¿u vÆ°á»£t quÃ¡ range: +8, + 16, ...)
Trong python3
sizeof(int) is 4 bytes, náº¿u vÆ°á»£t quÃ¡ range sáº½ má»Ÿ rá»™ng ( +4, +8, ...)
Náº¿u báº¡n gÃµ cÃº phÃ¡p sys.getsizeof() thÃ¬ sáº½ nháº­n vá» giÃ¡ trá»‹: 24 bytes (kÃ­ch thÆ°á»›c kiá»ƒu cÆ¡ báº£n cá»§a python2) + kÃ­ch thÆ°á»›c kiá»ƒu dá»¯ liá»‡u
Äáº·t biá»‡t: sá»‘ 0 vÃ  sá»‘ ""float"" cÃ³ getsizeof() lÃ  24 + 0 (Ngay táº¡i Ä‘Ã¢y náº¿u cÃ³ ngÆ°á»i há»i mÃ¬nh kiá»ƒu float trong python3 cÃ³ kÃ­ch thÆ°á»›c bao nhiÃªu tháº­t sá»± mÃ¬nh khÃ´ng biáº¿t cÃ¢u tráº£ lá»i).

Cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, tÃ¬nh hÃ¬nh lÃ  mÃ¬nh vá»«a nghiÃªn cá»©u vá» kiá»ƒu dá»¯ liá»‡u trong ngÃ´n ngá»¯ C++ vÃ  python. MÃ¬nh post lÃªn Ä‘Ã¢y nháº±m má»¥c Ä‘Ã­ch chia sáº» cÅ©ng nhÆ° mong nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ náº¿u mÃ¬nh cÃ³ nghiÃªn cá»©u sai. KÃ­ch thÆ°á»›c cá»§a cÃ¡c kiá»ƒu dá»¯ liá»‡u phá»• biáº¿n trong C++: sizeof(int) and sizeof(float) is 4 bytes sizeof(double) is 8 bytes sizeof(pointer) is 4 or 8 bytes KÃ­ch thÆ°á»›c cá»§a cÃ¡c kiá»ƒu dá»¯ liá»‡u phá»• biáº¿n trong Python2: sizeof(int), sizeof(float) is 8 bytes Trong python2 vÃ  python3, double coi nhÆ° float NhÆ°ng thá»±c táº¿ náº¿u báº¡n gÃµ cÃº phÃ¡p sys.getsizeof() thÃ¬ sáº½ nháº­n vá» giÃ¡ trá»‹: 16 bytes (kÃ­ch thÆ°á»›c kiá»ƒu cÆ¡ báº£n cá»§a python2) + kÃ­ch thÆ°á»›c kiá»ƒu dá»¯ liá»‡u (cÃ³ thá»ƒ má»Ÿ rá»™ng náº¿u vÆ°á»£t quÃ¡ range: +8, + 16, ...) Trong python3 sizeof(int) is 4 bytes, náº¿u vÆ°á»£t quÃ¡ range sáº½ má»Ÿ rá»™ng ( +4, +8, ...) Náº¿u báº¡n gÃµ cÃº phÃ¡p sys.getsizeof() thÃ¬ sáº½ nháº­n vá» giÃ¡ trá»‹: 24 bytes (kÃ­ch thÆ°á»›c kiá»ƒu cÆ¡ báº£n cá»§a python2) + kÃ­ch thÆ°á»›c kiá»ƒu dá»¯ liá»‡u Äáº·t biá»‡t: sá»‘ 0 vÃ  sá»‘ ""float"" cÃ³ getsizeof() lÃ  24 + 0 (Ngay táº¡i Ä‘Ã¢y náº¿u cÃ³ ngÆ°á»i há»i mÃ¬nh kiá»ƒu float trong python3 cÃ³ kÃ­ch thÆ°á»›c bao nhiÃªu tháº­t sá»± mÃ¬nh khÃ´ng biáº¿t cÃ¢u tráº£ lá»i). Cáº£m Æ¡n.",,,,,
"CÃ´ng bá»‘ má»›i vá» model má»›i (cÃ³ láº½ cÃ¡ch Ä‘Ã¢y vÃ i giá») sá»­ dá»¥ng kiáº¿n trÃºc Multi-layer Perceptron cá»§a Google Brain, vá»›i tÃªn gá»i lÃ  gMLP (vá»›i g á»Ÿ Ä‘Ã¢y ngá»¥ Ã½ MLP with gating). Hay á»Ÿ chá»— cÃ¡c models má»›i trong bÃ i bÃ¡o hoáº¡t Ä‘á»™ng tá»‘t cÃ¹ng 1 lÃºc cáº£ vá»›i tÃ¡c vá»¥ xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn (Natural Language Processing), vÃ  cáº£ vá»›i xá»­ lÃ­ áº£nh (Computer Vision).
Kiáº¿n trÃºc cÆ¡ báº£n gMLP xem hÃ¬nh bÃªn dÆ°á»›i
BÃ i bÃ¡o táº¡i Ä‘Ã¢y: https://arxiv.org/pdf/2105.08050.pdf","CÃ´ng bá»‘ má»›i vá» model má»›i (cÃ³ láº½ cÃ¡ch Ä‘Ã¢y vÃ i giá») sá»­ dá»¥ng kiáº¿n trÃºc Multi-layer Perceptron cá»§a Google Brain, vá»›i tÃªn gá»i lÃ  gMLP (vá»›i g á»Ÿ Ä‘Ã¢y ngá»¥ Ã½ MLP with gating). Hay á»Ÿ chá»— cÃ¡c models má»›i trong bÃ i bÃ¡o hoáº¡t Ä‘á»™ng tá»‘t cÃ¹ng 1 lÃºc cáº£ vá»›i tÃ¡c vá»¥ xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn (Natural Language Processing), vÃ  cáº£ vá»›i xá»­ lÃ­ áº£nh (Computer Vision). Kiáº¿n trÃºc cÆ¡ báº£n gMLP xem hÃ¬nh bÃªn dÆ°á»›i BÃ i bÃ¡o táº¡i Ä‘Ã¢y: https://arxiv.org/pdf/2105.08050.pdf",,,,,
"Nay mÃ¬nh máº¥t ngá»§, dáº­y Ä‘á»c sÃ¡ch tháº¥y trÃ¹ng há»£p ngáº«u nhiÃªn...
Tháº¥y page 230, chÆ°Æ¡ng 5, sÃ¡ch Pattern Recognition and Machine Learning, Bishop, 2006 cÃ³ viáº¿t:
""Another generalization of the network architecture is to include skip-layer connections, each of which is associated with a corresponding adaptive parameter. For instance, in a two-layer network these would go directly from inputs to outputs""
Cháº³ng pháº£i trÃ¹ng Ã½ tÆ°á»Ÿng skip-layer connection cá»§a Resnet, 2015 (https://arxiv.org/pdf/1512.03385.pdf) Ä‘Ã¬nh Ä‘Ã¡m Æ°. Nhiá»u lÃºc cÃ¡i gÃ¬ má»›i vÃ  ráº¥t Ä‘á»™t phÃ¡ Ä‘áº¿n tá»« nhá»¯ng gÃ¬ Ä‘Æ¡n giáº£n.
LÃºc mÃ¬nh search áº£nh cho post ra 1 bÃ i bÃ¡o: ""All new ideas are made of old ideas"" (https://www.management-issues.com/opinion/4678/all-new-ideas-are-made-of-old-ideas/), má»i ngÆ°á»i Ä‘á»c thÃªm =))","Nay mÃ¬nh máº¥t ngá»§, dáº­y Ä‘á»c sÃ¡ch tháº¥y trÃ¹ng há»£p ngáº«u nhiÃªn... Tháº¥y page 230, chÆ°Æ¡ng 5, sÃ¡ch Pattern Recognition and Machine Learning, Bishop, 2006 cÃ³ viáº¿t: ""Another generalization of the network architecture is to include skip-layer connections, each of which is associated with a corresponding adaptive parameter. For instance, in a two-layer network these would go directly from inputs to outputs"" Cháº³ng pháº£i trÃ¹ng Ã½ tÆ°á»Ÿng skip-layer connection cá»§a Resnet, 2015 (https://arxiv.org/pdf/1512.03385.pdf) Ä‘Ã¬nh Ä‘Ã¡m Æ°. Nhiá»u lÃºc cÃ¡i gÃ¬ má»›i vÃ  ráº¥t Ä‘á»™t phÃ¡ Ä‘áº¿n tá»« nhá»¯ng gÃ¬ Ä‘Æ¡n giáº£n. LÃºc mÃ¬nh search áº£nh cho post ra 1 bÃ i bÃ¡o: ""All new ideas are made of old ideas"" (https://www.management-issues.com/opinion/4678/all-new-ideas-are-made-of-old-ideas/), má»i ngÆ°á»i Ä‘á»c thÃªm =))",,,,,
"Xin hÆ°á»›ng Ä‘i theo AI cho ngÆ°á»i Ä‘Ã£ Ä‘i lÃ m.
Hello mng.
MÃ¬nh Ä‘Ã£ ra trÆ°á»ng vÃ  cÅ©ng khÃ¡ thÃ­ch AI. Trong thá»i gian sinh viÃªn cÅ©ng cÃ³ Ä‘i theo tháº§y lÃ m 1 vÃ i dá»± Ã¡n vá» DL, AI.
Tuy nhiÃªn hiá»‡n táº¡i mÃ¬nh khÃ´ng biáº¿t pháº£i tiáº¿p tá»¥c sao ná»¯a, vÃ¬ nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n mÃ¬nh nghÄ© mÃ¬nh Ä‘Ã£ hiá»ƒu vÃ  Ã¡p dá»¥ng Ä‘Æ°á»£c rá»“i. Hiá»‡n táº¡i mÃ¬nh cÅ©ng chá»‰ loanh quanh Ä‘á»c paper rá»“i code theo, Ä‘iá»u nÃ y lÃ m mÃ¬nh cáº£m giÃ¡c khÃ´ng lÃ m mÃ¬nh tÄƒng trÃ¬nh Ä‘á»™ lÃªn Ä‘Æ°á»£c vÃ  nÃ³ khÃ´ng cho mÃ¬nh tháº¥y mÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c cá»™t má»‘c nÃ o cáº£.
VÃ¬ ngÃ y xÆ°a Ã­t nháº¥t cÃ²n cÃ³ giáº£ng viÃªn nÃ³i cho mÃ¬nh lÃ  chá»— nÃ y e lÃ m Ä‘Ãºng, chá»— nÃ y e lÃ m chÆ°a Ä‘Ãºng ...
Váº­y khÃ´ng biáº¿t trong forum cÃ³ ai Ä‘ang trong tÃ¬nh tráº¡ng giá»‘ng em khÃ´ng áº¡. VÃ  cÃ³ thá»ƒ cho e xin lá»i khuyÃªn trong trÆ°á»ng há»£p nÃ y Ä‘Æ°á»£c vá»›i.","Xin hÆ°á»›ng Ä‘i theo AI cho ngÆ°á»i Ä‘Ã£ Ä‘i lÃ m. Hello mng. MÃ¬nh Ä‘Ã£ ra trÆ°á»ng vÃ  cÅ©ng khÃ¡ thÃ­ch AI. Trong thá»i gian sinh viÃªn cÅ©ng cÃ³ Ä‘i theo tháº§y lÃ m 1 vÃ i dá»± Ã¡n vá» DL, AI. Tuy nhiÃªn hiá»‡n táº¡i mÃ¬nh khÃ´ng biáº¿t pháº£i tiáº¿p tá»¥c sao ná»¯a, vÃ¬ nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n mÃ¬nh nghÄ© mÃ¬nh Ä‘Ã£ hiá»ƒu vÃ  Ã¡p dá»¥ng Ä‘Æ°á»£c rá»“i. Hiá»‡n táº¡i mÃ¬nh cÅ©ng chá»‰ loanh quanh Ä‘á»c paper rá»“i code theo, Ä‘iá»u nÃ y lÃ m mÃ¬nh cáº£m giÃ¡c khÃ´ng lÃ m mÃ¬nh tÄƒng trÃ¬nh Ä‘á»™ lÃªn Ä‘Æ°á»£c vÃ  nÃ³ khÃ´ng cho mÃ¬nh tháº¥y mÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c cá»™t má»‘c nÃ o cáº£. VÃ¬ ngÃ y xÆ°a Ã­t nháº¥t cÃ²n cÃ³ giáº£ng viÃªn nÃ³i cho mÃ¬nh lÃ  chá»— nÃ y e lÃ m Ä‘Ãºng, chá»— nÃ y e lÃ m chÆ°a Ä‘Ãºng ... Váº­y khÃ´ng biáº¿t trong forum cÃ³ ai Ä‘ang trong tÃ¬nh tráº¡ng giá»‘ng em khÃ´ng áº¡. VÃ  cÃ³ thá»ƒ cho e xin lá»i khuyÃªn trong trÆ°á»ng há»£p nÃ y Ä‘Æ°á»£c vá»›i.",,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i, máº¥y methods gáº§n Ä‘Ã¢y nhÆ° lÃ  Mixer-MLP hay cÅ© hÆ¡n tÃ­ lÃ  Vision Transformer thÆ°á»ng cáº§n nhiá»u data hÆ¡n lÃ  CNN bá»Ÿi inductive bias. Vá»›i custom dataset cá»§a má»i ngÆ°á»i dÃ¹ng thÃ¬ táº§m bao nhiÃªu áº£nh thÃ¬ má»i ngÆ°á»i tháº¥y hiá»‡u quáº£ cá»§a Vision ngang báº±ng CNN nhá»‰?","Má»i ngÆ°á»i Æ¡i cho em há»i, máº¥y methods gáº§n Ä‘Ã¢y nhÆ° lÃ  Mixer-MLP hay cÅ© hÆ¡n tÃ­ lÃ  Vision Transformer thÆ°á»ng cáº§n nhiá»u data hÆ¡n lÃ  CNN bá»Ÿi inductive bias. Vá»›i custom dataset cá»§a má»i ngÆ°á»i dÃ¹ng thÃ¬ táº§m bao nhiÃªu áº£nh thÃ¬ má»i ngÆ°á»i tháº¥y hiá»‡u quáº£ cá»§a Vision ngang báº±ng CNN nhá»‰?",,,,,
"[Há»i Ä‘Ã¡p/TÆ° váº¥n] ChÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘Ã£ hoÃ n thÃ nh khoÃ¡ há»c Python cÆ¡ báº£n vÃ  cÅ©ng nhÆ° hoÃ n táº¥t nÄƒm nháº¥t (major cá»§a em lÃ  CS) táº¡i trÆ°á»ng em, nÃªn em Ä‘ang Ä‘ang Ä‘áº·t cho báº£n thÃ¢n nhá»¯ng cÃ¢u há»i mÃ¬nh nÃªn lÃ m gÃ¬ tiáº¿p Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ Ä‘áº§y Ä‘á»§ kiáº¿n thá»©c vÃ  báº¯t Ä‘áº§u theo Ä‘uá»•i lÄ©nh vá»±c Machine Learning, vÃ  cÅ©ng nhÆ° nÃªn khá»Ÿi Ä‘áº§u tá»± lÃ m nhá»¯ng projects dáº¡ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ lÃ m Ä‘áº¹p CV/resume cá»§a báº£n thÃ¢n.
Em xin cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡ em.","[Há»i Ä‘Ã¡p/TÆ° váº¥n] ChÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘Ã£ hoÃ n thÃ nh khoÃ¡ há»c Python cÆ¡ báº£n vÃ  cÅ©ng nhÆ° hoÃ n táº¥t nÄƒm nháº¥t (major cá»§a em lÃ  CS) táº¡i trÆ°á»ng em, nÃªn em Ä‘ang Ä‘ang Ä‘áº·t cho báº£n thÃ¢n nhá»¯ng cÃ¢u há»i mÃ¬nh nÃªn lÃ m gÃ¬ tiáº¿p Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ Ä‘áº§y Ä‘á»§ kiáº¿n thá»©c vÃ  báº¯t Ä‘áº§u theo Ä‘uá»•i lÄ©nh vá»±c Machine Learning, vÃ  cÅ©ng nhÆ° nÃªn khá»Ÿi Ä‘áº§u tá»± lÃ m nhá»¯ng projects dáº¡ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ lÃ m Ä‘áº¹p CV/resume cá»§a báº£n thÃ¢n. Em xin cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡ em.",,,,,
"Hello má»i ngÆ°á»i, cho em há»i ai cÃ³ kinh nghiá»‡m vá» features scaling thÃ¬: anh/chá»‹ thÆ°á»ng dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o giá»¯a ""MinMaxScaler"" vÃ  ""StandardScaler"", trong thá»±c táº¿ cÃ´ng viá»‡c hiá»‡n nay ngÆ°á»i ta thÆ°á»ng dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o vÃ  táº¡i sao áº¡. Em Ä‘Ã£ tÃ¬m nhiá»u tÃ i liá»‡u nÃ³i vá» 2 phÆ°Æ¡ng phÃ¡p nÃ y nhÆ°ng chá»§ yáº¿u Ä‘á»u lÃ  Ä‘á»‹nh nghÄ©a vÃ  Ã­t giáº£i thÃ­ch khi nÃ o nÃªn sá»­ dá»¥ng pp nÃ o...Em cáº£m Æ¡n anh/chá»‹ ráº¥t nhiá»u áº¡!!!!
#ML #Preprocessing #FeatureScaling","Hello má»i ngÆ°á»i, cho em há»i ai cÃ³ kinh nghiá»‡m vá» features scaling thÃ¬: anh/chá»‹ thÆ°á»ng dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o giá»¯a ""MinMaxScaler"" vÃ  ""StandardScaler"", trong thá»±c táº¿ cÃ´ng viá»‡c hiá»‡n nay ngÆ°á»i ta thÆ°á»ng dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o vÃ  táº¡i sao áº¡. Em Ä‘Ã£ tÃ¬m nhiá»u tÃ i liá»‡u nÃ³i vá» 2 phÆ°Æ¡ng phÃ¡p nÃ y nhÆ°ng chá»§ yáº¿u Ä‘á»u lÃ  Ä‘á»‹nh nghÄ©a vÃ  Ã­t giáº£i thÃ­ch khi nÃ o nÃªn sá»­ dá»¥ng pp nÃ o...Em cáº£m Æ¡n anh/chá»‹ ráº¥t nhiá»u áº¡!!!!",#ML	#Preprocessing	#FeatureScaling,,,,
"Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang nghiÃªn cá»©u mÃ´ hÃ¬nh ARIMA. Em chÆ°a hiá»ƒu kÄ© vá» phÆ°Æ¡ng phÃ¡p xÃ¡c Ä‘á»‹nh há»‡ sá»‘ PACF. Theo em biáº¿t thÃ¬ há»‡ sá»‘ PACF thá»ƒ hiá»‡n má»‘i quan há»‡ giá»¯a chuá»—i hiá»‡n táº¡i vá»›i chuá»—i trá»… (k). NhÆ°ng sao trong cÃ´ng thá»©c, ta láº¡i quan tÃ¢m Ä‘áº¿n chuá»—i trá»… cá»§a Ä‘á»™ trá»… k váº­y áº¡.?
Em cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang nghiÃªn cá»©u mÃ´ hÃ¬nh ARIMA. Em chÆ°a hiá»ƒu kÄ© vá» phÆ°Æ¡ng phÃ¡p xÃ¡c Ä‘á»‹nh há»‡ sá»‘ PACF. Theo em biáº¿t thÃ¬ há»‡ sá»‘ PACF thá»ƒ hiá»‡n má»‘i quan há»‡ giá»¯a chuá»—i hiá»‡n táº¡i vá»›i chuá»—i trá»… (k). NhÆ°ng sao trong cÃ´ng thá»©c, ta láº¡i quan tÃ¢m Ä‘áº¿n chuá»—i trá»… cá»§a Ä‘á»™ trá»… k váº­y áº¡.? Em cáº£m Æ¡n áº¡.",,,,,
"Standford cÃ³ khÃ³a nÃ y cÃ³ váº» má»›i
CS221: Artificial Intelligence: Principles and Techniques
Stanford / Autumn 2019-2020
https://stanford-cs221.github.io/autumn2019/#schedule
video trÃªn youtube:
https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX
NgoÃ i ra mÃ¬nh cÃ²n liá»‡t kÃª thÃªm nhiá»u khÃ³a khÃ¡c vá» ML vÃ  láº­p trinh á»Ÿ Ä‘Ã¢y náº¿u báº¡n nÃ o cáº§n
http://ellienguyen.style/StatML/data_science_resource.html
TÃ­nh ra Stanford cÅ©ng cÃ³ khÃ¡ nhiá»u khÃ³a online",Standford cÃ³ khÃ³a nÃ y cÃ³ váº» má»›i CS221: Artificial Intelligence: Principles and Techniques Stanford / Autumn 2019-2020 https://stanford-cs221.github.io/autumn2019/#schedule video trÃªn youtube: https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX NgoÃ i ra mÃ¬nh cÃ²n liá»‡t kÃª thÃªm nhiá»u khÃ³a khÃ¡c vá» ML vÃ  láº­p trinh á»Ÿ Ä‘Ã¢y náº¿u báº¡n nÃ o cáº§n http://ellienguyen.style/StatML/data_science_resource.html TÃ­nh ra Stanford cÅ©ng cÃ³ khÃ¡ nhiá»u khÃ³a online,,,,,
"em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» nháº­n diá»‡n khuÃ´n máº·t cÃ³ má»™t sá»‘ cÃ¢u há»i mong mng giáº£i thÃ­ch giÃºp em áº¡:
em Ä‘ang Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p one shot learning Ä‘á»ƒ nháº­n diá»‡n. theo bÃ i viáº¿t cá»§a anh tháº¯ng (https://www.miai.vn/.../face-recog-2-0-nhan-dien-khuon.../) em tháº¥y cÃ³ sá»­ dá»¥ng SVM Ä‘á»ƒ trÃ­ch xuáº¥t vector tá»« data. náº¿u em sá»­ dá»¥ng Data Augumentation Ä‘á»ƒ táº¡o ra nhiá»u áº£nh má»›i tá»« 1 áº£nh gá»‘c rá»“i sá»­ dá»¥ng SVM thÃ¬ cÃ²n Ä‘Æ°á»£c gá»i lÃ  one shot learning ná»¯a khÃ´ng áº¡?
hiá»‡n em Ä‘ang dÃ¹ng pretrained model á»Ÿ Ä‘Ã¢y (https://github.com/iwantooxxoox/Keras-OpenFace). em muá»‘n train láº¡i báº±ng dataset vn_celeb cá»§a bÃªn Sun* Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c khi nháº­n diá»‡n máº·t ngÆ°á»i Viá»‡t. em cÃ³ Ã¡p dá»¥ng theo blog nÃ y (https://phamdinhkhanh.github.io/2020/03/21/faceNet.html...) nhÆ°ng hiá»‡n Ä‘ang bá»‹ lá»—i nhÆ° áº£nh. em cÃ³ thá»­ xÃ³a ""stratify=""y_labels"" thÃ¬ Ä‘áº¿n lÃºc train loss bÃ¡o lÃ  NAN. khi Ã¡p dá»¥ng dataset mÃ  khÃ´ng tÃ¡ch máº·t thÃ¬ láº¡i cháº¡y bÃ¬nh thÆ°á»ng. lá»—i nÃ y cÃ³ cÃ¡ch kháº¯c phá»¥c nÃ o áº¡?
em dá»± tÃ­nh sáº½ deploy project lÃªn raspberry pi. em cÃ³ 2 lá»±a chá»n camera lÃ  picamera hoáº·c lÃ  camera usb. cho em há»i lÃ  náº¿u sá»­ dá»¥ng cam usb thÃ¬ cÃ³ Ä‘á»™ trá»… hay cháº­m hÆ¡n lÃ  picam cáº¯m trá»±c tiáº¿p lÃªn mobo khÃ´ng áº¡?
em cáº£m Æ¡n áº¡.","em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» nháº­n diá»‡n khuÃ´n máº·t cÃ³ má»™t sá»‘ cÃ¢u há»i mong mng giáº£i thÃ­ch giÃºp em áº¡: em Ä‘ang Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p one shot learning Ä‘á»ƒ nháº­n diá»‡n. theo bÃ i viáº¿t cá»§a anh tháº¯ng (https://www.miai.vn/.../face-recog-2-0-nhan-dien-khuon.../) em tháº¥y cÃ³ sá»­ dá»¥ng SVM Ä‘á»ƒ trÃ­ch xuáº¥t vector tá»« data. náº¿u em sá»­ dá»¥ng Data Augumentation Ä‘á»ƒ táº¡o ra nhiá»u áº£nh má»›i tá»« 1 áº£nh gá»‘c rá»“i sá»­ dá»¥ng SVM thÃ¬ cÃ²n Ä‘Æ°á»£c gá»i lÃ  one shot learning ná»¯a khÃ´ng áº¡? hiá»‡n em Ä‘ang dÃ¹ng pretrained model á»Ÿ Ä‘Ã¢y (https://github.com/iwantooxxoox/Keras-OpenFace). em muá»‘n train láº¡i báº±ng dataset vn_celeb cá»§a bÃªn Sun* Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c khi nháº­n diá»‡n máº·t ngÆ°á»i Viá»‡t. em cÃ³ Ã¡p dá»¥ng theo blog nÃ y (https://phamdinhkhanh.github.io/2020/03/21/faceNet.html...) nhÆ°ng hiá»‡n Ä‘ang bá»‹ lá»—i nhÆ° áº£nh. em cÃ³ thá»­ xÃ³a ""stratify=""y_labels"" thÃ¬ Ä‘áº¿n lÃºc train loss bÃ¡o lÃ  NAN. khi Ã¡p dá»¥ng dataset mÃ  khÃ´ng tÃ¡ch máº·t thÃ¬ láº¡i cháº¡y bÃ¬nh thÆ°á»ng. lá»—i nÃ y cÃ³ cÃ¡ch kháº¯c phá»¥c nÃ o áº¡? em dá»± tÃ­nh sáº½ deploy project lÃªn raspberry pi. em cÃ³ 2 lá»±a chá»n camera lÃ  picamera hoáº·c lÃ  camera usb. cho em há»i lÃ  náº¿u sá»­ dá»¥ng cam usb thÃ¬ cÃ³ Ä‘á»™ trá»… hay cháº­m hÆ¡n lÃ  picam cáº¯m trá»±c tiáº¿p lÃªn mobo khÃ´ng áº¡? em cáº£m Æ¡n áº¡.",,,,,
"Cho mÃ¬nh há»i lÃ  trong giáº£i thuáº­t content-base recommendation system lÃºc mÃ¬nh chuyá»ƒn dá»¯ liá»‡u sang TFIDF thÃ¬ thÃ´ng tin mÃ´ táº£ cá»§a sáº£n pháº©m mÃ¬nh cÃ³ cáº§n ghi tiÃªu Ä‘á» cá»§a nÃ³ vÃ´ luÃ´n khÃ´ng má»i ngÆ°á»i? VÃ­ dá»¥ mÃ¬nh Ä‘áº·c táº£ sáº£n pháº©m nhÆ° sau:
RAM: 8 GB
Bá»™ nhá»› trong: 64 GB
LÃºc mÃ¬nh convert sang TFIDF mÃ¬nh cÃ³ nÃªn láº¥y háº¿t luÃ´n thÃ´ng tin (tá»©c lÃ  bao gá»“m cáº£ tiÃªu Ä‘á» lÃ  RAM, bá»™ nhá»› trong) khÃ´ng hay chá»‰ cáº§n láº¥y giÃ¡ trá»‹ cá»§a nÃ³ lÃ  8 GB vÃ  64 GB lÃ  Ä‘Æ°á»£c?
Táº¡i má»—i sáº£n pháº©m nhiá»u khi Ä‘áº·c táº£ thÃ´ng tin khÃ¡c nhau nÃªn mÃ¬nh khÃ´ng rÃµ láº¯m. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡.","Cho mÃ¬nh há»i lÃ  trong giáº£i thuáº­t content-base recommendation system lÃºc mÃ¬nh chuyá»ƒn dá»¯ liá»‡u sang TFIDF thÃ¬ thÃ´ng tin mÃ´ táº£ cá»§a sáº£n pháº©m mÃ¬nh cÃ³ cáº§n ghi tiÃªu Ä‘á» cá»§a nÃ³ vÃ´ luÃ´n khÃ´ng má»i ngÆ°á»i? VÃ­ dá»¥ mÃ¬nh Ä‘áº·c táº£ sáº£n pháº©m nhÆ° sau: RAM: 8 GB Bá»™ nhá»› trong: 64 GB LÃºc mÃ¬nh convert sang TFIDF mÃ¬nh cÃ³ nÃªn láº¥y háº¿t luÃ´n thÃ´ng tin (tá»©c lÃ  bao gá»“m cáº£ tiÃªu Ä‘á» lÃ  RAM, bá»™ nhá»› trong) khÃ´ng hay chá»‰ cáº§n láº¥y giÃ¡ trá»‹ cá»§a nÃ³ lÃ  8 GB vÃ  64 GB lÃ  Ä‘Æ°á»£c? Táº¡i má»—i sáº£n pháº©m nhiá»u khi Ä‘áº·c táº£ thÃ´ng tin khÃ¡c nhau nÃªn mÃ¬nh khÃ´ng rÃµ láº¯m. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡.",,,,,
Read papers with me,Read papers with me,,,,,
"[TÃŒM MENTOR]
Em chÃ o anh/chá»‹
Em Ä‘ang cáº§n há»c cÃ¡ch deploy model machine learning báº±ng Python hoáº·c R, nÃªn náº¿u cÃ³ ai dáº¡y kÃ¨m Ä‘Æ°á»£c thÃ¬ liÃªn há»‡ vá»›i áº¡. TrÆ°á»›c em há»c kinh táº¿ vÃ  hiá»‡n Ä‘ang lÃ m fresher DS.
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c.","[TÃŒM MENTOR] Em chÃ o anh/chá»‹ Em Ä‘ang cáº§n há»c cÃ¡ch deploy model machine learning báº±ng Python hoáº·c R, nÃªn náº¿u cÃ³ ai dáº¡y kÃ¨m Ä‘Æ°á»£c thÃ¬ liÃªn há»‡ vá»›i áº¡. TrÆ°á»›c em há»c kinh táº¿ vÃ  hiá»‡n Ä‘ang lÃ m fresher DS. Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c.",,,,,
"Em chÃ o cÃ¡c anh/chá»‹
Hiá»‡n táº¡i em Ä‘ang máº¯c váº¥n Ä‘á» nÃ y, anh/chá»‹ cho em há»i vá»›i áº¡. Em cháº¡y thuáº­t toÃ¡n DBscan vá»›i bá»™ dá»¯ liá»‡u 260 triá»‡u dÃ²ng. Tuy nhiÃªn vÃ¬ dá»¯ liá»‡u quÃ¡ lá»›n lÃ m cho R khÃ´ng Ä‘á»§ bá»™ nhá»›. Váº­y cÃ³ cÃ¡ch nÃ o xá»­ lÃ½ váº¥n Ä‘á» nÃ y k áº¡? Chuyá»ƒn qua cháº¡y trÃªn python hay cháº¡y song song báº±ng cÃ¡ch sá»­ dá»¥ng Microsoft R Open cÃ³ Ä‘Æ°á»£c k áº¡?","Em chÃ o cÃ¡c anh/chá»‹ Hiá»‡n táº¡i em Ä‘ang máº¯c váº¥n Ä‘á» nÃ y, anh/chá»‹ cho em há»i vá»›i áº¡. Em cháº¡y thuáº­t toÃ¡n DBscan vá»›i bá»™ dá»¯ liá»‡u 260 triá»‡u dÃ²ng. Tuy nhiÃªn vÃ¬ dá»¯ liá»‡u quÃ¡ lá»›n lÃ m cho R khÃ´ng Ä‘á»§ bá»™ nhá»›. Váº­y cÃ³ cÃ¡ch nÃ o xá»­ lÃ½ váº¥n Ä‘á» nÃ y k áº¡? Chuyá»ƒn qua cháº¡y trÃªn python hay cháº¡y song song báº±ng cÃ¡ch sá»­ dá»¥ng Microsoft R Open cÃ³ Ä‘Æ°á»£c k áº¡?",,,,,
"Xin chÃ o má»i ngÆ°á»i em cÃ³ má»™t cÃ¢u há»i vá» chá»§ Ä‘á» voice-reidentification vá»›i deep learning. BÃ¬nh thÆ°á»ng thÃ¬ task liÃªn quan Ä‘áº¿n voice sáº½ cÃ³ 2 dáº¡ng nhÆ° sau:
voice identification: NgÆ°á»i dÃ¹ng nháº­n diá»‡n lÃ  ngÆ°á»i A vÃ  há»‡ thá»‘ng sáº½ kiá»ƒm tra xem giá»ng nÃ³i cÃ³ Ä‘Ãºng vá»›i template ngÆ°á»i A Ä‘Ã£ cÃ³ sáºµn khÃ´ng.
voice recognition: NgÆ°á»i dÃ¹ng nÃ³i vÃ o vÃ  há»‡ thá»‘ng kiá»ƒm tra input vá»›i táº¥t cáº£ nhá»¯ng máº«u Ä‘Ã£ Ä‘Æ°á»£c train trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ xem giá»‘ng ai nháº¥t. 
Tuy nhiÃªn hiá»‡n táº¡i em cÃ³ 1 task hÆ¡i khÃ¡c má»™t chÃºt, sau khi train 1 model DL vá»›i táº­p training (voice recording) cÃ³ label. Em sáº½ pháº£i evaluate trÃªn má»™t test set vÃ  xÃ¡c Ä‘á»‹nh hai voice recording cÃ³ thuá»™c cÃ¹ng má»™t ngÆ°á»i khÃ´ng (i.e., Ä‘Æ°a ra má»™t distance matrix). Tuy nhiÃªn em Ä‘Æ°á»£c biáº¿t trÆ°á»›c lÃ  toÃ n bá»™ dá»¯ liá»‡u trong test set sáº½ khÃ´ng thuá»™c vá» má»™t ai trong training set cáº£. Em Ä‘ang thá»­ nghiá»‡m vá»›i Siamese neural network tuy nhiÃªn váº«n chÆ°a thá»±c sá»± thÃ nh cÃ´ng. NÃªn em lÃªn Ä‘Ã¢y há»i vá» Ä‘á»‹nh hÆ°á»›ng, tÃ i liá»‡u, hay keyword mÃ  em nÃªn nhÃ¬n vÃ o.
Em cáº£m Æ¡n.","Xin chÃ o má»i ngÆ°á»i em cÃ³ má»™t cÃ¢u há»i vá» chá»§ Ä‘á» voice-reidentification vá»›i deep learning. BÃ¬nh thÆ°á»ng thÃ¬ task liÃªn quan Ä‘áº¿n voice sáº½ cÃ³ 2 dáº¡ng nhÆ° sau: voice identification: NgÆ°á»i dÃ¹ng nháº­n diá»‡n lÃ  ngÆ°á»i A vÃ  há»‡ thá»‘ng sáº½ kiá»ƒm tra xem giá»ng nÃ³i cÃ³ Ä‘Ãºng vá»›i template ngÆ°á»i A Ä‘Ã£ cÃ³ sáºµn khÃ´ng. voice recognition: NgÆ°á»i dÃ¹ng nÃ³i vÃ o vÃ  há»‡ thá»‘ng kiá»ƒm tra input vá»›i táº¥t cáº£ nhá»¯ng máº«u Ä‘Ã£ Ä‘Æ°á»£c train trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ xem giá»‘ng ai nháº¥t. Tuy nhiÃªn hiá»‡n táº¡i em cÃ³ 1 task hÆ¡i khÃ¡c má»™t chÃºt, sau khi train 1 model DL vá»›i táº­p training (voice recording) cÃ³ label. Em sáº½ pháº£i evaluate trÃªn má»™t test set vÃ  xÃ¡c Ä‘á»‹nh hai voice recording cÃ³ thuá»™c cÃ¹ng má»™t ngÆ°á»i khÃ´ng (i.e., Ä‘Æ°a ra má»™t distance matrix). Tuy nhiÃªn em Ä‘Æ°á»£c biáº¿t trÆ°á»›c lÃ  toÃ n bá»™ dá»¯ liá»‡u trong test set sáº½ khÃ´ng thuá»™c vá» má»™t ai trong training set cáº£. Em Ä‘ang thá»­ nghiá»‡m vá»›i Siamese neural network tuy nhiÃªn váº«n chÆ°a thá»±c sá»± thÃ nh cÃ´ng. NÃªn em lÃªn Ä‘Ã¢y há»i vá» Ä‘á»‹nh hÆ°á»›ng, tÃ i liá»‡u, hay keyword mÃ  em nÃªn nhÃ¬n vÃ o. Em cáº£m Æ¡n.",,,,,
"App nÃ y bá»n mÃ¬nh dÃ¹ng thÆ° viá»‡n VietOCR cá»§a anh Quoc Pham.
Cáº£m Æ¡n anh Quoc Pham vÃ¬ thÆ° viá»‡n ráº¥t tuyá»‡t vá»i nÃ y.
Hiá»‡n táº¡i cáº§n cáº£i thiá»‡n thÃªm á»Ÿ pháº§n chá»¯ viáº¿t tay.
CÃ¡c báº¡n cÃ³ thá»ƒ cho bá»n mÃ¬nh xin gá»£i Ã½ máº£ng nháº­n dáº¡ng chá»¯ viáº¿t tay tiáº¿ng Viá»‡t Ä‘Æ°á»£c khÃ´ng áº¡?",App nÃ y bá»n mÃ¬nh dÃ¹ng thÆ° viá»‡n VietOCR cá»§a anh Quoc Pham. Cáº£m Æ¡n anh Quoc Pham vÃ¬ thÆ° viá»‡n ráº¥t tuyá»‡t vá»i nÃ y. Hiá»‡n táº¡i cáº§n cáº£i thiá»‡n thÃªm á»Ÿ pháº§n chá»¯ viáº¿t tay. CÃ¡c báº¡n cÃ³ thá»ƒ cho bá»n mÃ¬nh xin gá»£i Ã½ máº£ng nháº­n dáº¡ng chá»¯ viáº¿t tay tiáº¿ng Viá»‡t Ä‘Æ°á»£c khÃ´ng áº¡?,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang táº­p nghiÃªn cá»©u vá» Reinforcement Learning nÃªn em máº¡nh dáº¡n lÃ m clip chia sáº», cÃ¹ng nhau tÃ¬m hiá»ƒu vá» Reinforcement Learning vá»›i bÃ i toÃ¡n TÃ¬m hiá»ƒu vÃ  dáº¡y mÃ¡y tÃ­nh chÆ¡i game vá»›i Q - Learning.
Hi vá»ng mÃ³n má»›i nÃ y sáº½ mang láº¡i há»©ng khá»Ÿi cho anh em má»›i há»c!
Cáº£m Æ¡n cÃ¡c bÃ¡c vÃ  cáº£m Æ¡n admin duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang táº­p nghiÃªn cá»©u vá» Reinforcement Learning nÃªn em máº¡nh dáº¡n lÃ m clip chia sáº», cÃ¹ng nhau tÃ¬m hiá»ƒu vá» Reinforcement Learning vá»›i bÃ i toÃ¡n TÃ¬m hiá»ƒu vÃ  dáº¡y mÃ¡y tÃ­nh chÆ¡i game vá»›i Q - Learning. Hi vá»ng mÃ³n má»›i nÃ y sáº½ mang láº¡i há»©ng khá»Ÿi cho anh em má»›i há»c! Cáº£m Æ¡n cÃ¡c bÃ¡c vÃ  cáº£m Æ¡n admin duyá»‡t bÃ i!",,,,,
"cho mÃ¬nh há»i má»™t chÃºt lÃ  trong lÃ½ thuyáº¿t machinelearning cÆ¡ báº£n thÃ¬ pháº§n recommendation System thÃ¬ theo lÃ½ thuyáº¿t lÃ  pháº£i cÃ³ user Ä‘Ã¡nh giÃ¡ cho cÃ¡c bá»™ phim rá»“i ta dÃ¹ng Ridge Ä‘á»ƒ tÃ­nh w, b, Ä‘Ã²i há»i pháº£i cÃ³ giÃ¡ trá»‹ rating. NhÆ°ng náº¿u Ã¡p dá»¥ng trong cÆ¡ sá»Ÿ dá»¯ liá»‡u khÃ¡c lÃ  gá»£i Ã½ cÃ¡c sáº£n pháº©m tÆ°Æ¡ng tá»± thÃ¬ ta láº¡i khÃ´ng cÃ³ rating nÃ y thÃ¬ cÃ³ pháº£i lÃ  ta sáº½ convert cÃ¡c thÃ´ng tin cá»§a tá»«ng hÃ ng dá»¯ liá»‡u sang TFIDF Ä‘á»ƒ ra Vector Ä‘áº·c trÆ°ng, sau Ä‘Ã³ sáº½ Ã¡p dá»¥ng hÃ m cosin Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng tá»± Ä‘Æ°á»£c khÃ´ng má»i ngÆ°á»i?","cho mÃ¬nh há»i má»™t chÃºt lÃ  trong lÃ½ thuyáº¿t machinelearning cÆ¡ báº£n thÃ¬ pháº§n recommendation System thÃ¬ theo lÃ½ thuyáº¿t lÃ  pháº£i cÃ³ user Ä‘Ã¡nh giÃ¡ cho cÃ¡c bá»™ phim rá»“i ta dÃ¹ng Ridge Ä‘á»ƒ tÃ­nh w, b, Ä‘Ã²i há»i pháº£i cÃ³ giÃ¡ trá»‹ rating. NhÆ°ng náº¿u Ã¡p dá»¥ng trong cÆ¡ sá»Ÿ dá»¯ liá»‡u khÃ¡c lÃ  gá»£i Ã½ cÃ¡c sáº£n pháº©m tÆ°Æ¡ng tá»± thÃ¬ ta láº¡i khÃ´ng cÃ³ rating nÃ y thÃ¬ cÃ³ pháº£i lÃ  ta sáº½ convert cÃ¡c thÃ´ng tin cá»§a tá»«ng hÃ ng dá»¯ liá»‡u sang TFIDF Ä‘á»ƒ ra Vector Ä‘áº·c trÆ°ng, sau Ä‘Ã³ sáº½ Ã¡p dá»¥ng hÃ m cosin Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng tá»± Ä‘Æ°á»£c khÃ´ng má»i ngÆ°á»i?",,,,,
#information_theory,,#information_theory,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang train yolov5 cÃ³ 4 classes, káº¿t quáº£ cofusion matrix nhÆ° váº§y, nhÆ°ng em khÃ´ng hiá»ƒu giÃ¡ trá»‹ cá»§a cá»™t Back Ground FP, táº¡i sao tá»•ng giÃ¡ trá»‹ FP cá»§a 4 classes cá»§a em pháº£i luÃ´n báº±ng 1. CÃ³ anh/chá»‹ nÃ o giÃºp em tháº¯c máº¯c nÃ y vá»›i, em k biáº¿t em lÃ m sai gÃ¬ ná»¯a","ChÃ o má»i ngÆ°á»i, em Ä‘ang train yolov5 cÃ³ 4 classes, káº¿t quáº£ cofusion matrix nhÆ° váº§y, nhÆ°ng em khÃ´ng hiá»ƒu giÃ¡ trá»‹ cá»§a cá»™t Back Ground FP, táº¡i sao tá»•ng giÃ¡ trá»‹ FP cá»§a 4 classes cá»§a em pháº£i luÃ´n báº±ng 1. CÃ³ anh/chá»‹ nÃ o giÃºp em tháº¯c máº¯c nÃ y vá»›i, em k biáº¿t em lÃ m sai gÃ¬ ná»¯a",,,,,
"TÃ¬m Ä‘á»‘i tÃ¡c thÆ°Æ¡ng máº¡i hoÃ¡ sáº£n pháº©m phÃ¢n loáº¡i tÃ¬nh tráº¡ng táº¿ bÃ o mao máº¡ch vÃµng máº¡c máº¯t.
NhÆ° 1 stt trÆ°á»›c mÃ¬nh cÃ³ demo má»™t sá»‘ káº¿t quáº£ vá» bÃ i toÃ¡n Retinal Optical Coherence Tomography (BÃ i bÃ¡o gá»‘c á»Ÿ Ä‘Ã¢y: https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5; vá»›i dataset táº¡i Ä‘Ã¢y https://data.mendeley.com/datasets/rscbjbr9sj/2)
VÃ  má»›i thÃ¡ng trÆ°á»›c, bÃªn Äá»©c há» Ä‘ang triá»ƒn khai dá»± Ã¡n Opthalmo-AI, theo mÃ¬nh ráº¥t nhiá»u Ã½ nghÄ©a. CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃ´ng cÃ¡o bÃ¡o chÃ­ cá»§a dá»± Ã¡n táº¡i Ä‘Ã¢y https://www.dfki.de/en/web/news/detail/News/ohthalmo-ai-started/?fbclid=IwAR3ffeDlV5EJ7iNRBXoZ_Q8RVrbBbxULSbwxMw-fApYvNluwbYaSZ8Qa4Qw
Káº¿t quáº£ cá»§a mÃ¬nh láº·p láº¡i thÃ­ nghiá»‡m cá»§a há» vá»›i model cá»§a riÃªng mÃ¬nh Ä‘áº¡t káº¿t quáº£ vÆ°á»£t trá»™i, cÃ¡c báº¡n xem hÃ¬nh 1.
Tuy nhiÃªn bÃ i bÃ¡o cÃ³ váº¥n Ä‘á» vá» thiáº¿t káº¿ thÃ­ nghiá»‡m dáº«n tá»›i hiá»‡n tÆ°á»£ng overfiting (cÃ¡c báº¡n cÃ³ thá»ƒ xem Fig. 3 trong bÃ i), nÃªn mÃ¬nh nghi ngá» cÃ³ váº¥n Ä‘á». Káº¿t quáº£ mÃ¬nh phÃ¡t hiá»‡n ra hiá»‡n tÆ°á»£ng trÃ¹ng láº·p dá»¯ liá»‡u á»Ÿ test set. MÃ¬nh Ä‘Ã£ xá»­ lÃ­ vÃ  cho ra huáº¥n luyá»‡n vá»›i model máº¡nh hÆ¡n (model nÃ y mÃ¬nh chÆ°a fine-tune nhÃ© vÃ  náº¿u emsemble nhiá»u models cÃ³ thá»ƒ sáº½ cho káº¿t quáº£ tá»‘t hÆ¡n) vÃ  cho ra káº¿t quáº£ nhÆ° hÃ¬nh 2.
Váº­y báº¡n/cÃ´ng ti nÃ o cÃ³ há»©ng thÃº vÃ  cÃ³ kháº£ nÄƒng thÆ°Æ¡ng máº¡i hoÃ¡ cÃ³ thá»ƒ liÃªn láº¡c vá»›i mÃ¬nh Ä‘á»ƒ tháº£o luáº­n váº¥n Ä‘á» vÃ  giáº£i quyáº¿t váº¥n Ä‘á» nÃ y cho ngÆ°á»i Viá»‡t vÃ  Viá»‡t Nam. ÄÃ³ lÃ  mong muá»‘n lá»›n nháº¥t cá»§a mÃ¬nh!","TÃ¬m Ä‘á»‘i tÃ¡c thÆ°Æ¡ng máº¡i hoÃ¡ sáº£n pháº©m phÃ¢n loáº¡i tÃ¬nh tráº¡ng táº¿ bÃ o mao máº¡ch vÃµng máº¡c máº¯t. NhÆ° 1 stt trÆ°á»›c mÃ¬nh cÃ³ demo má»™t sá»‘ káº¿t quáº£ vá» bÃ i toÃ¡n Retinal Optical Coherence Tomography (BÃ i bÃ¡o gá»‘c á»Ÿ Ä‘Ã¢y: https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5; vá»›i dataset táº¡i Ä‘Ã¢y https://data.mendeley.com/datasets/rscbjbr9sj/2) VÃ  má»›i thÃ¡ng trÆ°á»›c, bÃªn Äá»©c há» Ä‘ang triá»ƒn khai dá»± Ã¡n Opthalmo-AI, theo mÃ¬nh ráº¥t nhiá»u Ã½ nghÄ©a. CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃ´ng cÃ¡o bÃ¡o chÃ­ cá»§a dá»± Ã¡n táº¡i Ä‘Ã¢y https://www.dfki.de/en/web/news/detail/News/ohthalmo-ai-started/?fbclid=IwAR3ffeDlV5EJ7iNRBXoZ_Q8RVrbBbxULSbwxMw-fApYvNluwbYaSZ8Qa4Qw Káº¿t quáº£ cá»§a mÃ¬nh láº·p láº¡i thÃ­ nghiá»‡m cá»§a há» vá»›i model cá»§a riÃªng mÃ¬nh Ä‘áº¡t káº¿t quáº£ vÆ°á»£t trá»™i, cÃ¡c báº¡n xem hÃ¬nh 1. Tuy nhiÃªn bÃ i bÃ¡o cÃ³ váº¥n Ä‘á» vá» thiáº¿t káº¿ thÃ­ nghiá»‡m dáº«n tá»›i hiá»‡n tÆ°á»£ng overfiting (cÃ¡c báº¡n cÃ³ thá»ƒ xem Fig. 3 trong bÃ i), nÃªn mÃ¬nh nghi ngá» cÃ³ váº¥n Ä‘á». Káº¿t quáº£ mÃ¬nh phÃ¡t hiá»‡n ra hiá»‡n tÆ°á»£ng trÃ¹ng láº·p dá»¯ liá»‡u á»Ÿ test set. MÃ¬nh Ä‘Ã£ xá»­ lÃ­ vÃ  cho ra huáº¥n luyá»‡n vá»›i model máº¡nh hÆ¡n (model nÃ y mÃ¬nh chÆ°a fine-tune nhÃ© vÃ  náº¿u emsemble nhiá»u models cÃ³ thá»ƒ sáº½ cho káº¿t quáº£ tá»‘t hÆ¡n) vÃ  cho ra káº¿t quáº£ nhÆ° hÃ¬nh 2. Váº­y báº¡n/cÃ´ng ti nÃ o cÃ³ há»©ng thÃº vÃ  cÃ³ kháº£ nÄƒng thÆ°Æ¡ng máº¡i hoÃ¡ cÃ³ thá»ƒ liÃªn láº¡c vá»›i mÃ¬nh Ä‘á»ƒ tháº£o luáº­n váº¥n Ä‘á» vÃ  giáº£i quyáº¿t váº¥n Ä‘á» nÃ y cho ngÆ°á»i Viá»‡t vÃ  Viá»‡t Nam. ÄÃ³ lÃ  mong muá»‘n lá»›n nháº¥t cá»§a mÃ¬nh!",,,,,
"ChÃ o má»i ngÆ°á»i,
Khi tÃ¬m hiá»ƒu vá» tool GoogleTest thÃ¬ em mÃ² ra Ä‘Æ°á»£c cuá»‘n nÃ y.
Em nghÄ© lÃ m á»©ng dá»¥ng vá» AI thÃ¬ váº«n thuá»™c vá» phÃ¡t triá»ƒn pháº§n má»m nÃªn chia sáº» nÃ³ lÃªn Ä‘Ã¢y.
Má»i ngÆ°á»i cÃ³ thá»ƒ truy cáº­p file PDF miá»…n phÃ­ táº¡i https://abseil.io/resources/swe_at_google.2.pdf
List of errata https://www.oreilly.com/catalog/errata.csp?isbn=0636920296423","ChÃ o má»i ngÆ°á»i, Khi tÃ¬m hiá»ƒu vá» tool GoogleTest thÃ¬ em mÃ² ra Ä‘Æ°á»£c cuá»‘n nÃ y. Em nghÄ© lÃ m á»©ng dá»¥ng vá» AI thÃ¬ váº«n thuá»™c vá» phÃ¡t triá»ƒn pháº§n má»m nÃªn chia sáº» nÃ³ lÃªn Ä‘Ã¢y. Má»i ngÆ°á»i cÃ³ thá»ƒ truy cáº­p file PDF miá»…n phÃ­ táº¡i https://abseil.io/resources/swe_at_google.2.pdf List of errata https://www.oreilly.com/catalog/errata.csp?isbn=0636920296423",,,,,
"[Weight Initializers]
Xin chÃ o cÃ¡c báº¡n, mÃ¬nh hiá»‡n táº¡i Ä‘ang train má»™t model chá»§ yáº¿u dÃ¹ng ReLU activation á»Ÿ cÃ¡c layer Ä‘áº§u. Trong quÃ¡ trÃ¬nh train mÃ´ hÃ¬nh, do dÃ¹ng Glorot, nÃªn mÃ´ hÃ¬nh khÃ´ng Ä‘áº¡t Ä‘á»™ á»•n Ä‘á»‹nh cao nÃªn Ä‘Ã£ chuyá»ƒn sang dÃ¹ng He initializers.
Tuy nhiÃªn, trong khi nghiÃªn cá»©u (Ä‘á»c bÃ i bÃ¡o), search GG - DataExchange, StackOverflow cÃ¡c kiá»ƒu, mÃ¬nh váº«n khÃ´ng hiá»ƒu ná»•i táº¡i sao láº¡i cÃ³ sá»± phÃ¢n biá»‡t giá»¯a normal vÃ  uniform (vá»›i há»‡ sá»‘ standard deviation cÃ¡ch biá»‡t lÃ  cÄƒn 3). Liá»‡u train báº±ng normal sáº½ khÃ¡c so vá»›i uniform hay chÃºng chá»‰ táº¡o nÃªn sá»± Ä‘a dáº¡ng trong initializers khi train thÃ´i?.
Minh xin cáº£m Æ¡n cÃ¡c báº¡n","[Weight Initializers] Xin chÃ o cÃ¡c báº¡n, mÃ¬nh hiá»‡n táº¡i Ä‘ang train má»™t model chá»§ yáº¿u dÃ¹ng ReLU activation á»Ÿ cÃ¡c layer Ä‘áº§u. Trong quÃ¡ trÃ¬nh train mÃ´ hÃ¬nh, do dÃ¹ng Glorot, nÃªn mÃ´ hÃ¬nh khÃ´ng Ä‘áº¡t Ä‘á»™ á»•n Ä‘á»‹nh cao nÃªn Ä‘Ã£ chuyá»ƒn sang dÃ¹ng He initializers. Tuy nhiÃªn, trong khi nghiÃªn cá»©u (Ä‘á»c bÃ i bÃ¡o), search GG - DataExchange, StackOverflow cÃ¡c kiá»ƒu, mÃ¬nh váº«n khÃ´ng hiá»ƒu ná»•i táº¡i sao láº¡i cÃ³ sá»± phÃ¢n biá»‡t giá»¯a normal vÃ  uniform (vá»›i há»‡ sá»‘ standard deviation cÃ¡ch biá»‡t lÃ  cÄƒn 3). Liá»‡u train báº±ng normal sáº½ khÃ¡c so vá»›i uniform hay chÃºng chá»‰ táº¡o nÃªn sá»± Ä‘a dáº¡ng trong initializers khi train thÃ´i?. Minh xin cáº£m Æ¡n cÃ¡c báº¡n",,,,,
"[License plate detection]
ChÃ o cÃ¡c báº¡n, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n nháº­n diá»‡n biá»ƒn sá»‘ xe do thiáº¿u data nÃªn biá»ƒn sá»‘ vÃ ng vÃ  xanh cho kq ko tá»‘t láº¯m. VÃ¬ váº¥n Ä‘á» bussiness vÃ  framework mÃ¬nh Ä‘ang sá»­ dá»¥ng nÃªn ko thá»ƒ grayscale Ä‘Æ°á»£c. NÃªn mÃ¬nh cáº§n thu tháº­p thÃªm data. Hiá»‡n táº¡i mÃ¬nh search trÃªn máº¡ng má»›i cÃ³ dataset green parking. Báº¡n nÃ o cÃ³ náº¿u bÃ¡n Ä‘Æ°á»£c thÃ¬ ib mÃ¬nh nhÃ©, mÃ¬nh cÃ³ thá»ƒ mua.
Xin cáº£m Æ¡n","[License plate detection] ChÃ o cÃ¡c báº¡n, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n nháº­n diá»‡n biá»ƒn sá»‘ xe do thiáº¿u data nÃªn biá»ƒn sá»‘ vÃ ng vÃ  xanh cho kq ko tá»‘t láº¯m. VÃ¬ váº¥n Ä‘á» bussiness vÃ  framework mÃ¬nh Ä‘ang sá»­ dá»¥ng nÃªn ko thá»ƒ grayscale Ä‘Æ°á»£c. NÃªn mÃ¬nh cáº§n thu tháº­p thÃªm data. Hiá»‡n táº¡i mÃ¬nh search trÃªn máº¡ng má»›i cÃ³ dataset green parking. Báº¡n nÃ o cÃ³ náº¿u bÃ¡n Ä‘Æ°á»£c thÃ¬ ib mÃ¬nh nhÃ©, mÃ¬nh cÃ³ thá»ƒ mua. Xin cáº£m Æ¡n",,,,,
TrÆ°á»ng há»£p high bias vÃ  high variance thÃ¬ xem lÃ  vá»«a overfitting vá»«a underfitting hay khÃ´ng overfiting khÃ´ng underfitting má»i ngÆ°á»i nhá»‰.,TrÆ°á»ng há»£p high bias vÃ  high variance thÃ¬ xem lÃ  vá»«a overfitting vá»«a underfitting hay khÃ´ng overfiting khÃ´ng underfitting má»i ngÆ°á»i nhá»‰.,,,,,
"EfficientNet_V2 chÃ­nh thá»©c ra máº¯t báº£n cáº­p nháº­t táº¡i Ä‘Ã¢y: https://arxiv.org/pdf/2104.00298v2.pdf
VÃ  code cho TensorFlow táº¡i Ä‘Ã¢y: https://github.com/google/automl/tree/master/efficientnetv2
VÃ i giá» ná»¯a cÃ³ thá»ƒ cÃ³ code cho Pytorch táº¡i codebase TIMM táº¡i Ä‘Ã¢y https://github.com/rwightman/pytorch-image-models",EfficientNet_V2 chÃ­nh thá»©c ra máº¯t báº£n cáº­p nháº­t táº¡i Ä‘Ã¢y: https://arxiv.org/pdf/2104.00298v2.pdf VÃ  code cho TensorFlow táº¡i Ä‘Ã¢y: https://github.com/google/automl/tree/master/efficientnetv2 VÃ i giá» ná»¯a cÃ³ thá»ƒ cÃ³ code cho Pytorch táº¡i codebase TIMM táº¡i Ä‘Ã¢y https://github.com/rwightman/pytorch-image-models,,,,,
"ChÃ o mn! E cÃ³ lÃ m 1 dá»± Ã¡n vá» xá»­ lÃ½ áº£nh. Äáº§u vÃ o áº£nh dung lÆ°á»£ng lá»›n (khoáº£ng 5000-10000 pixels hoáº·c hÆ¡n). KhÃ´ng thá»ƒ Ä‘á»ƒ nguyÃªn áº£nh nhÆ° tháº¿ Ä‘á»ƒ lÃ m do dung lÆ°á»£ng lá»›n tÃ­nh toÃ¡n ráº¥t lÃ¢u mÃ  cÅ©ng khÃ´ng thá»ƒ resize áº£nh vÃ¬ sáº½ máº¥t ná»™i dung cá»§a áº£nh. Mn cho e há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ thá»±c hiá»‡n bÃ i toÃ¡n nÃ y vá»›i áº¡.
Em cáº£m Æ¡n!",ChÃ o mn! E cÃ³ lÃ m 1 dá»± Ã¡n vá» xá»­ lÃ½ áº£nh. Äáº§u vÃ o áº£nh dung lÆ°á»£ng lá»›n (khoáº£ng 5000-10000 pixels hoáº·c hÆ¡n). KhÃ´ng thá»ƒ Ä‘á»ƒ nguyÃªn áº£nh nhÆ° tháº¿ Ä‘á»ƒ lÃ m do dung lÆ°á»£ng lá»›n tÃ­nh toÃ¡n ráº¥t lÃ¢u mÃ  cÅ©ng khÃ´ng thá»ƒ resize áº£nh vÃ¬ sáº½ máº¥t ná»™i dung cá»§a áº£nh. Mn cho e há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ thá»±c hiá»‡n bÃ i toÃ¡n nÃ y vá»›i áº¡. Em cáº£m Æ¡n!,,,,,
"ChÃ o cÃ¡c bÃ¡c, em má»›i nghiÃªn cá»©u vá» phÃ©p biáº¿n Ä‘á»•i wavelet vÃ  wavelet coherence, Ä‘á» tÃ i cá»§a em lÃ  phÃ¢n tÃ­ch yáº¿u tá»‘ thá»i tiáº¿t nhÆ° nhiá»‡t Ä‘á»™ cÃ³ liÃªn quan Ä‘áº¿n sá»‘ ca máº¯c bá»‡nh trong khoáº£ng thá»i gian tá»« 1998 - 2011 hay khÃ´ng, táº­p dá»¯ liá»‡u Ä‘áº§u vÃ o , cá»¥ thá»ƒ lÃ  thá»i tiáº¿t vÃ  sá»‘ ca máº¯c bá»‡nh táº¡i má»™t Ä‘á»‹a phÆ°Æ¡ng trong khoáº£ng thá»i gian 1998 - 2011 , trong bÆ°á»›c tiá»n xá»­ lÃ½ dá»¯ liá»‡u, em cÃ³ chuáº©n hÃ³a vá» -1 Ä‘áº¿n 1 á»Ÿ cáº£ 2 táº­p dá»¯ liá»‡u sau Ä‘Ã³ dÃ¹ng thÆ° viá»‡n biwavelet Ä‘á»ƒ biáº¿n Ä‘á»•i, cá»¥ thá»ƒ lÃ  sá»­ dá»¥ng hÃ m wtc vá»›i cÃ¡c thÃ´ng sá»‘ Ä‘áº§u ra nhÆ° hÃ¬nh, em chá»n sig.level lÃ  0.95 vÃ  sig.test = 0 tá»©c X^2. Káº¿t quáº£ thu Ä‘Æ°á»£c ma tráº­n signif vá»›i 90% chá»‰ sá»‘ < 0.95 vÃ  10% chá»‰ sá»‘ > 0.95, nay em muá»‘n nhá» cÃ¡c bÃ¡c giÃºp 2 váº¥n Ä‘á» vá»›i áº¡.
CÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ã½ nghÄ©a thá»‘ng káº¿ báº±ng ma tráº­n signif hay khÃ´ng? Náº¿u cÃ³ thÃ¬ Ä‘Ã¡nh giÃ¡ nhÆ° tháº¿ nÃ o Ä‘á»ƒ ra má»™t chá»‰ sá»‘ P-value cuá»‘i cÃ¹ng thui áº¡ ?
Em muá»‘n sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p kiá»ƒm thá»­ Granger Cause Test vá»›i káº¿t quáº£ cá»§a hÃ m wavelet coherence Ä‘Ã³ thÃ¬ pháº£i lÃ m tháº¿ nÃ o, em cÃ³ xem qua thÆ° viá»‡n vars vá»›i VAR model vÃ  hÃ m causality nhÆ°ng Ä‘áº§u vÃ o chá»‰ lÃ  tÃ­n hiá»‡u 1D , em khÃ´ng biáº¿t pháº£i sá»­ dá»¥ng nhÆ° tháº¿ nÃ o vÃ o bÃ i toÃ¡n cá»§a mÃ¬nh, mong cÃ¡c bÃ¡c cÃ³ thá»ƒ giÃºp em vá»›i áº¡ ?
Do em tá»± há»c vÃ  kiáº¿n thá»©c cÃ²n ráº¥t háº¡n háº¹p , cÃ³ Ä‘iá»u gÃ¬ sai xÃ³t mong cÃ¡c bÃ¡c cÃ³ thá»ƒ thÃ´ng cáº£m giÃºp em sá»¯a chá»¯a vá»›i áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i !","ChÃ o cÃ¡c bÃ¡c, em má»›i nghiÃªn cá»©u vá» phÃ©p biáº¿n Ä‘á»•i wavelet vÃ  wavelet coherence, Ä‘á» tÃ i cá»§a em lÃ  phÃ¢n tÃ­ch yáº¿u tá»‘ thá»i tiáº¿t nhÆ° nhiá»‡t Ä‘á»™ cÃ³ liÃªn quan Ä‘áº¿n sá»‘ ca máº¯c bá»‡nh trong khoáº£ng thá»i gian tá»« 1998 - 2011 hay khÃ´ng, táº­p dá»¯ liá»‡u Ä‘áº§u vÃ o , cá»¥ thá»ƒ lÃ  thá»i tiáº¿t vÃ  sá»‘ ca máº¯c bá»‡nh táº¡i má»™t Ä‘á»‹a phÆ°Æ¡ng trong khoáº£ng thá»i gian 1998 - 2011 , trong bÆ°á»›c tiá»n xá»­ lÃ½ dá»¯ liá»‡u, em cÃ³ chuáº©n hÃ³a vá» -1 Ä‘áº¿n 1 á»Ÿ cáº£ 2 táº­p dá»¯ liá»‡u sau Ä‘Ã³ dÃ¹ng thÆ° viá»‡n biwavelet Ä‘á»ƒ biáº¿n Ä‘á»•i, cá»¥ thá»ƒ lÃ  sá»­ dá»¥ng hÃ m wtc vá»›i cÃ¡c thÃ´ng sá»‘ Ä‘áº§u ra nhÆ° hÃ¬nh, em chá»n sig.level lÃ  0.95 vÃ  sig.test = 0 tá»©c X^2. Káº¿t quáº£ thu Ä‘Æ°á»£c ma tráº­n signif vá»›i 90% chá»‰ sá»‘ < 0.95 vÃ  10% chá»‰ sá»‘ > 0.95, nay em muá»‘n nhá» cÃ¡c bÃ¡c giÃºp 2 váº¥n Ä‘á» vá»›i áº¡. CÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ã½ nghÄ©a thá»‘ng káº¿ báº±ng ma tráº­n signif hay khÃ´ng? Náº¿u cÃ³ thÃ¬ Ä‘Ã¡nh giÃ¡ nhÆ° tháº¿ nÃ o Ä‘á»ƒ ra má»™t chá»‰ sá»‘ P-value cuá»‘i cÃ¹ng thui áº¡ ? Em muá»‘n sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p kiá»ƒm thá»­ Granger Cause Test vá»›i káº¿t quáº£ cá»§a hÃ m wavelet coherence Ä‘Ã³ thÃ¬ pháº£i lÃ m tháº¿ nÃ o, em cÃ³ xem qua thÆ° viá»‡n vars vá»›i VAR model vÃ  hÃ m causality nhÆ°ng Ä‘áº§u vÃ o chá»‰ lÃ  tÃ­n hiá»‡u 1D , em khÃ´ng biáº¿t pháº£i sá»­ dá»¥ng nhÆ° tháº¿ nÃ o vÃ o bÃ i toÃ¡n cá»§a mÃ¬nh, mong cÃ¡c bÃ¡c cÃ³ thá»ƒ giÃºp em vá»›i áº¡ ? Do em tá»± há»c vÃ  kiáº¿n thá»©c cÃ²n ráº¥t háº¡n háº¹p , cÃ³ Ä‘iá»u gÃ¬ sai xÃ³t mong cÃ¡c bÃ¡c cÃ³ thá»ƒ thÃ´ng cáº£m giÃºp em sá»¯a chá»¯a vá»›i áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n má»i ngÆ°á»i !",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n SVM. Má»i ngÆ°á»i hÃ£y chá»‰ cho em nhá»¯ng bÃ i giáº£ng hoáº·c nhá»¯ng tÃ i liá»‡u cháº¥t lÆ°á»£ng vá»›i áº¡.
Em cáº£m Æ¡n thiá»‡t nhiá»u","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» thuáº­t toÃ¡n SVM. Má»i ngÆ°á»i hÃ£y chá»‰ cho em nhá»¯ng bÃ i giáº£ng hoáº·c nhá»¯ng tÃ i liá»‡u cháº¥t lÆ°á»£ng vá»›i áº¡. Em cáº£m Æ¡n thiá»‡t nhiá»u",,,,,
"ChÃ o má»i ngÆ°á»i, em chá»‰ má»›i Ä‘ang tÃ¬m hiá»ƒu vá» Machine Learning.
Em muá»‘n há»i vá» máº¡ng EfficientNet, theo em tÃ¬m hiá»ƒu thÃ¬ máº¡ng EfficientNet-B0 bao gá»“m tá»•ng cá»™ng 237 layers. Tuy nhiÃªn trong bÃ i bÃ¡o nÃ y, báº£ng káº¿t quáº£ thá»­ nghiá»‡m chá»‰ ghi cÃ³ 18 layers. Váº­y 18 layers Ä‘Ã³ bao gá»“m nhá»¯ng layer nÃ o áº¡?
Äá» tÃ i em Ä‘ang nghiÃªn cá»©u lÃ  thÃªm bá»›t lá»›p layer Ä‘á»ƒ tá»‘i Æ°u hÃ³a nháº­n dáº¡ng trong bÃ i toÃ¡n nháº­n dáº¡ng mÃ³n Äƒn. Mong anh chá»‹ giÃºp Ä‘á»¡ vÃ  chá»‰ cho em nhá»¯ng Ä‘á» tÃ i tÆ°Æ¡ng quan.
Link bÃ i bÃ¡o: https://www.researchgate.net/publication/339798572_Automated_fruit_recognition_using_EfficientNet_and_MixNet","ChÃ o má»i ngÆ°á»i, em chá»‰ má»›i Ä‘ang tÃ¬m hiá»ƒu vá» Machine Learning. Em muá»‘n há»i vá» máº¡ng EfficientNet, theo em tÃ¬m hiá»ƒu thÃ¬ máº¡ng EfficientNet-B0 bao gá»“m tá»•ng cá»™ng 237 layers. Tuy nhiÃªn trong bÃ i bÃ¡o nÃ y, báº£ng káº¿t quáº£ thá»­ nghiá»‡m chá»‰ ghi cÃ³ 18 layers. Váº­y 18 layers Ä‘Ã³ bao gá»“m nhá»¯ng layer nÃ o áº¡? Äá» tÃ i em Ä‘ang nghiÃªn cá»©u lÃ  thÃªm bá»›t lá»›p layer Ä‘á»ƒ tá»‘i Æ°u hÃ³a nháº­n dáº¡ng trong bÃ i toÃ¡n nháº­n dáº¡ng mÃ³n Äƒn. Mong anh chá»‹ giÃºp Ä‘á»¡ vÃ  chá»‰ cho em nhá»¯ng Ä‘á» tÃ i tÆ°Æ¡ng quan. Link bÃ i bÃ¡o: https://www.researchgate.net/publication/339798572_Automated_fruit_recognition_using_EfficientNet_and_MixNet",,,,,
ChÃ o anh chá»‹ em Ä‘ang dÃ¹ng mobinet Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh phÃ¢n loáº¡i áº£nh trÃªn thiáº¿t bá»‹ di Ä‘á»™ng. KhÃ´ng biáº¿t cÃ³ loáº¡i mÃ´ hÃ¬nh nÃ o cÅ©ng cÃ³ má»¥c Ä‘Ã­ch táº¡o ra Ä‘á»ƒ cháº¡y trÃªn thiáº¿t bá»‹ di Ä‘á»™ng giá»‘ng mobilenet khÃ´ng áº¡.,ChÃ o anh chá»‹ em Ä‘ang dÃ¹ng mobinet Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh phÃ¢n loáº¡i áº£nh trÃªn thiáº¿t bá»‹ di Ä‘á»™ng. KhÃ´ng biáº¿t cÃ³ loáº¡i mÃ´ hÃ¬nh nÃ o cÅ©ng cÃ³ má»¥c Ä‘Ã­ch táº¡o ra Ä‘á»ƒ cháº¡y trÃªn thiáº¿t bá»‹ di Ä‘á»™ng giá»‘ng mobilenet khÃ´ng áº¡.,,,,,
"Numpy, ML algorithms to practice","Numpy, ML algorithms to practice",,,,,
"*GÃ³c xin dá»¯ liá»‡u.
Em Ä‘ang lÃ m bÃ i toÃ¡n liÃªn quan tá»›i nháº­n diá»‡n khuÃ´n máº·t nÃªn muá»‘n há»i cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m ai cÃ³ bá»™ dá»¯ liá»‡u khuÃ´n máº·t hoáº·c link cho em xin vá»›i áº¡ (dá»¯ liá»‡u cho khu vá»±c chÃ¢u Ã hay Viá»‡t Nam thÃ¬ cÃ ng tá»‘t áº¡). Em xin chÃ¢n thÃ nh cáº£m Æ¡n.",*GÃ³c xin dá»¯ liá»‡u. Em Ä‘ang lÃ m bÃ i toÃ¡n liÃªn quan tá»›i nháº­n diá»‡n khuÃ´n máº·t nÃªn muá»‘n há»i cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n trong nhÃ³m ai cÃ³ bá»™ dá»¯ liá»‡u khuÃ´n máº·t hoáº·c link cho em xin vá»›i áº¡ (dá»¯ liá»‡u cho khu vá»±c chÃ¢u Ã hay Viá»‡t Nam thÃ¬ cÃ ng tá»‘t áº¡). Em xin chÃ¢n thÃ nh cáº£m Æ¡n.,,,,,
"Xin chÃ o cÃ¡c bÃ¡c, hÃ´m nay em máº¡nh dáº¡n chia sáº» cÃ¡ch train RepVGG vá»›i dá»¯ liá»‡u riÃªng theo cáº£ 2 hÃ¬nh thá»©c lÃ  train tá»« Ä‘áº§u vÃ  transfer learning.
Em cÃ³ tÃ¬m kiáº¿m trÃªn máº¡ng thÃ¬ nhiá»u bÃ i giá»›i thiá»‡u vá» RepVGG nhÆ°ng cÃ¡c bÃ i hÆ°á»›ng dáº«n train vÃ  transfer learning thÃ¬ cÃ²n Ã­t nÃªn em viáº¿t bÃ i nÃ y Ä‘á»ƒ guide cÃ¡c báº¡n má»›i há»c thÃ´i áº¡. Náº¿u cÃ³ sai sÃ³t mong cÃ¡c cao thá»§ Ä‘i qua bá» quÃ¡!","Xin chÃ o cÃ¡c bÃ¡c, hÃ´m nay em máº¡nh dáº¡n chia sáº» cÃ¡ch train RepVGG vá»›i dá»¯ liá»‡u riÃªng theo cáº£ 2 hÃ¬nh thá»©c lÃ  train tá»« Ä‘áº§u vÃ  transfer learning. Em cÃ³ tÃ¬m kiáº¿m trÃªn máº¡ng thÃ¬ nhiá»u bÃ i giá»›i thiá»‡u vá» RepVGG nhÆ°ng cÃ¡c bÃ i hÆ°á»›ng dáº«n train vÃ  transfer learning thÃ¬ cÃ²n Ã­t nÃªn em viáº¿t bÃ i nÃ y Ä‘á»ƒ guide cÃ¡c báº¡n má»›i há»c thÃ´i áº¡. Náº¿u cÃ³ sai sÃ³t mong cÃ¡c cao thá»§ Ä‘i qua bá» quÃ¡!",,,,,
"Hello má»i ngÆ°á»i, em Ä‘ang há»c Ä‘áº¿n pháº§n Features Selection, cá»¥ thá»ƒ hÆ¡n lÃ  em dÃ¹ng RFE Ä‘á»ƒ lá»±a chá»n features. CÃ¢u há»i Ä‘áº·t ra lÃ  má»i ngÆ°á»i thÆ°á»ng chá»n model nÃ o Ä‘á»ƒ lÃ m parameter Ä‘áº§u vÃ o cho RFE (náº¿u má»i ngÆ°á»i Ä‘Ã£ biáº¿t vá» RFE thÃ¬ RFE báº£n cháº¥t sáº½ sá»­ dá»¥ng 1 model nÃ o Ä‘Ã³). NgoÃ i ra trong thá»±c táº¿ ngÆ°á»i ta thÆ°á»ng dÃ¹ng selectKbest hay RFE nhiá»u hÆ¡n áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u!!!!","Hello má»i ngÆ°á»i, em Ä‘ang há»c Ä‘áº¿n pháº§n Features Selection, cá»¥ thá»ƒ hÆ¡n lÃ  em dÃ¹ng RFE Ä‘á»ƒ lá»±a chá»n features. CÃ¢u há»i Ä‘áº·t ra lÃ  má»i ngÆ°á»i thÆ°á»ng chá»n model nÃ o Ä‘á»ƒ lÃ m parameter Ä‘áº§u vÃ o cho RFE (náº¿u má»i ngÆ°á»i Ä‘Ã£ biáº¿t vá» RFE thÃ¬ RFE báº£n cháº¥t sáº½ sá»­ dá»¥ng 1 model nÃ o Ä‘Ã³). NgoÃ i ra trong thá»±c táº¿ ngÆ°á»i ta thÆ°á»ng dÃ¹ng selectKbest hay RFE nhiá»u hÆ¡n áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u!!!!",,,,,
"Trong lÃºc cá»™ng Ä‘á»“ng Ä‘ang há»“ há»Ÿi chuyá»ƒn sang dÃ¹ng Transformer vÃ o Computer Vision thÃ¬ Hugging Face cÅ©ng khÃ´ng thá»ƒ Ä‘á»©ng ngoÃ i cuá»™c chÆ¡i Ä‘Æ°á»£c. Trong báº£n release má»›i nháº¥t 4.6.0, Hugging Face cÅ©ng chÃ­nh thá»©c há»— trá»£ model cho ViT, DeiT vÃ  CLIP (Ä‘á»§ 3 model cá»§a 3 Ã´ng lá»›n, Ä‘á»¡ ganh tá»‹): https://github.com/huggingface/transformers/releases/tag/v4.6.0
Anh chá»‹ em tha há»“ vÃ o nghá»‹ch ğŸ˜Š","Trong lÃºc cá»™ng Ä‘á»“ng Ä‘ang há»“ há»Ÿi chuyá»ƒn sang dÃ¹ng Transformer vÃ o Computer Vision thÃ¬ Hugging Face cÅ©ng khÃ´ng thá»ƒ Ä‘á»©ng ngoÃ i cuá»™c chÆ¡i Ä‘Æ°á»£c. Trong báº£n release má»›i nháº¥t 4.6.0, Hugging Face cÅ©ng chÃ­nh thá»©c há»— trá»£ model cho ViT, DeiT vÃ  CLIP (Ä‘á»§ 3 model cá»§a 3 Ã´ng lá»›n, Ä‘á»¡ ganh tá»‹): https://github.com/huggingface/transformers/releases/tag/v4.6.0 Anh chá»‹ em tha há»“ vÃ o nghá»‹ch",,,,,
"#book #Deep_Learning #Computer_Vision 
Hiá»‡n táº¡i mÃ¬nh cÃ³ full bá»™ sÃ¡ch:
** Deep Learning for Computer Vision with Python by Adrian Rosebrock gá»“m 3 quyá»ƒn:
+Starter Bundle 
+Practictioner Bundle 
+ImageNet Bundle 
** Practical Python and OpenCV + Case Studies by Adrian Rosebrock (2 quyá»ƒn)
**Raspberry Pi for Computer Vision by Adrian Rosebrock 1 quyá»ƒn Hobbyist Bundle 
Tá»•ng bá»™ nÃ y mÃ¬nh mua hÆ¡i bá»‹ máº¯c nhÆ°ng siÃªu hay, thuáº§n thá»¥c cÃ³ thá»ƒ Ä‘i lÃ m tá»‘t.
Báº¡n nÃ o cÃ³ nhu cáº§u nhÆ°ng khÃ´ng cÃ³ Ä‘iá»u kiá»‡n, muá»‘n pass láº¡i vá»›i giÃ¡ Æ°u Ä‘Ã£i thÃ¬ inbox mÃ¬nh ha.
MÃ¬nh pass láº¡i Full bá»™ trÃªn dao Ä‘á»™ng 100-150$
Cáº£m Æ¡n cÃ¡c báº¡n quan tÃ¢m.
Mong ad duyá»‡t bÃ i","Hiá»‡n táº¡i mÃ¬nh cÃ³ full bá»™ sÃ¡ch: ** Deep Learning for Computer Vision with Python by Adrian Rosebrock gá»“m 3 quyá»ƒn: +Starter Bundle +Practictioner Bundle +ImageNet Bundle ** Practical Python and OpenCV + Case Studies by Adrian Rosebrock (2 quyá»ƒn) **Raspberry Pi for Computer Vision by Adrian Rosebrock 1 quyá»ƒn Hobbyist Bundle Tá»•ng bá»™ nÃ y mÃ¬nh mua hÆ¡i bá»‹ máº¯c nhÆ°ng siÃªu hay, thuáº§n thá»¥c cÃ³ thá»ƒ Ä‘i lÃ m tá»‘t. Báº¡n nÃ o cÃ³ nhu cáº§u nhÆ°ng khÃ´ng cÃ³ Ä‘iá»u kiá»‡n, muá»‘n pass láº¡i vá»›i giÃ¡ Æ°u Ä‘Ã£i thÃ¬ inbox mÃ¬nh ha. MÃ¬nh pass láº¡i Full bá»™ trÃªn dao Ä‘á»™ng 100-150$ Cáº£m Æ¡n cÃ¡c báº¡n quan tÃ¢m. Mong ad duyá»‡t bÃ i",#book	#Deep_Learning	#Computer_Vision,,,,
"[Deeplearning.AI]Machine Learning Engineering for Production (MLOps) Specialization

https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops
About this Specialization

#Coursera #MLOps 

The Machine Learning Engineering for Production Specialization covers how to conceptualize, build, and maintain integrated systems that continuously operate in production. In striking contrast with standard machine learning modeling, production systems need to handle relentless evolving data. Moreover, the production system must run non-stop at the minimum cost while producing the maximum performance. In this Specialization, you will learn how to use well-established tools and methodologies for doing all of this effectively and efficiently.

Applied Learning Project
By the end, you'll be ready to

â€¢ Design an ML production system end-to-end: project scoping, data needs, modeling strategies, and deployment requirements
â€¢ Establish a model baseline, address concept drift, and prototype how to develop, deploy, and continuously improve a productionized ML application
â€¢ Build data pipelines by gathering, cleaning, and validating datasets
â€¢ Implement feature engineering, transformation, and selection with TensorFlow Extended
â€¢ Establish data lifecycle by leveraging data lineage and provenance metadata tools and follow data evolution with enterprise data schemas
â€¢ Apply techniques to manage modeling resources and best serve offline/online inference requests
â€¢ Use analytics to address model fairness, explainability issues, and mitigate bottlenecks

â€¢ Deliver deployment pipelines for model serving that require different infrastructures
â€¢ Apply best practices and progressive delivery techniques to maintain a continuously operating production system","[Deeplearning.AI]Machine Learning Engineering for Production (MLOps) Specialization https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops About this Specialization The Machine Learning Engineering for Production Specialization covers how to conceptualize, build, and maintain integrated systems that continuously operate in production. In striking contrast with standard machine learning modeling, production systems need to handle relentless evolving data. Moreover, the production system must run non-stop at the minimum cost while producing the maximum performance. In this Specialization, you will learn how to use well-established tools and methodologies for doing all of this effectively and efficiently. Applied Learning Project By the end, you'll be ready to â€¢ Design an ML production system end-to-end: project scoping, data needs, modeling strategies, and deployment requirements â€¢ Establish a model baseline, address concept drift, and prototype how to develop, deploy, and continuously improve a productionized ML application â€¢ Build data pipelines by gathering, cleaning, and validating datasets â€¢ Implement feature engineering, transformation, and selection with TensorFlow Extended â€¢ Establish data lifecycle by leveraging data lineage and provenance metadata tools and follow data evolution with enterprise data schemas â€¢ Apply techniques to manage modeling resources and best serve offline/online inference requests â€¢ Use analytics to address model fairness, explainability issues, and mitigate bottlenecks â€¢ Deliver deployment pipelines for model serving that require different infrastructures â€¢ Apply best practices and progressive delivery techniques to maintain a continuously operating production system",#Coursera	#MLOps,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, dáº¡o nÃ y em cÃ³ nghe tháº¥y cÃ³ RepVGG hay quÃ¡ nÃªn cÅ©ng tÃ¬m hiá»ƒu qua. Tuy nhiÃªn do model má»›i cÅ©ng Ã­t tÃ i liá»‡u vÃ  Ä‘a pháº§n viáº¿t há»c thuáº­t quÃ¡ nÃªn em máº¡nh dáº¡n viáº¿t bÃ i nÃ y chia sáº» cÃ¹ng cÃ¡c báº¡n vá» cÃ¡ch hiá»ƒu sÆ¡ qua vá» RepVGG vÃ  á»©ng dá»¥ng thá»±c táº¿ train vÃ  inference luÃ´n.
Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie vÃ  mong admin duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, dáº¡o nÃ y em cÃ³ nghe tháº¥y cÃ³ RepVGG hay quÃ¡ nÃªn cÅ©ng tÃ¬m hiá»ƒu qua. Tuy nhiÃªn do model má»›i cÅ©ng Ã­t tÃ i liá»‡u vÃ  Ä‘a pháº§n viáº¿t há»c thuáº­t quÃ¡ nÃªn em máº¡nh dáº¡n viáº¿t bÃ i nÃ y chia sáº» cÃ¹ng cÃ¡c báº¡n vá» cÃ¡ch hiá»ƒu sÆ¡ qua vá» RepVGG vÃ  á»©ng dá»¥ng thá»±c táº¿ train vÃ  inference luÃ´n. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie vÃ  mong admin duyá»‡t bÃ i!",,,,,
"ChÃ o cÃ¡c ace,
Cho em há»i cÃ³ cÃ¡ch nÃ o má»—i láº§n cháº¡y colab, ko pháº£i cÃ i láº¡i cÃ¡c thÆ° viá»‡n ko áº¡. Em cÃ i pip install torch_sparse, torch_scatter cÃ¡c kiá»ƒu, cá»© má»—i láº§n cháº¡y lÃ  colab báº¯t cÃ i láº¡i, mÃ  má»—i láº§n cÃ i khÃ¡ lÃ¢u.
Xin cÃ¡c ace chá»‰ giÃ¡o, em xin cÃ¡m Æ¡n!","ChÃ o cÃ¡c ace, Cho em há»i cÃ³ cÃ¡ch nÃ o má»—i láº§n cháº¡y colab, ko pháº£i cÃ i láº¡i cÃ¡c thÆ° viá»‡n ko áº¡. Em cÃ i pip install torch_sparse, torch_scatter cÃ¡c kiá»ƒu, cá»© má»—i láº§n cháº¡y lÃ  colab báº¯t cÃ i láº¡i, mÃ  má»—i láº§n cÃ i khÃ¡ lÃ¢u. Xin cÃ¡c ace chá»‰ giÃ¡o, em xin cÃ¡m Æ¡n!",,,,,
"MÃ¬nh Ä‘ang lÃ m dá»± Ã¡n vá» AI, cÅ©ng má»›i tÃ¬m hiá»ƒu thÃ´i nÃªn cÃ²n chÆ°a rÃ nh láº¯m, mong má»i ngÆ°á»i giÃºp Ä‘á»¡.
MÃ¬nh Ä‘ang tÃ¬m má»™t API hay toolkit Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u tiáº¿ng Viá»‡t (gáº¯n label, ...), tÆ°Æ¡ng tá»± nhÆ° Watson Natural Language Understanding hay Azure Text Analytics cháº³ng háº¡n.
Ai biáº¿t API nÃ o hay cho tiáº¿ng Viá»‡t chá»‰ cho mÃ¬nh vá»›i. Watson, Azure, Google Cloud thÃ¬ háº§u háº¿t khÃ´ng há»— trá»£ tiáº¿ng Viá»‡t.
Cáº£m Æ¡n má»i ngÆ°á»i.","MÃ¬nh Ä‘ang lÃ m dá»± Ã¡n vá» AI, cÅ©ng má»›i tÃ¬m hiá»ƒu thÃ´i nÃªn cÃ²n chÆ°a rÃ nh láº¯m, mong má»i ngÆ°á»i giÃºp Ä‘á»¡. MÃ¬nh Ä‘ang tÃ¬m má»™t API hay toolkit Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u tiáº¿ng Viá»‡t (gáº¯n label, ...), tÆ°Æ¡ng tá»± nhÆ° Watson Natural Language Understanding hay Azure Text Analytics cháº³ng háº¡n. Ai biáº¿t API nÃ o hay cho tiáº¿ng Viá»‡t chá»‰ cho mÃ¬nh vá»›i. Watson, Azure, Google Cloud thÃ¬ háº§u háº¿t khÃ´ng há»— trá»£ tiáº¿ng Viá»‡t. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
CÃ¹ng chung tay xÃ¢y dá»±ng vnquant package,CÃ¹ng chung tay xÃ¢y dá»±ng vnquant package,,,,,
"Xin chÃ o má»i ngÆ°á»i, em Ä‘ang cáº§n muá»‘n tÃ­nh log-likelihood cá»§a classifier given data. Em tÃ­nh nhÆ° nÃ y cÃ³ Ä‘Ãºng khÃ´ng áº¡? log-likelihood = sum(log probability (c | x_i)) = sum(log(probs) = sum(log(c.predict_proba(x_i))). Em xin cáº£m Æ¡n","Xin chÃ o má»i ngÆ°á»i, em Ä‘ang cáº§n muá»‘n tÃ­nh log-likelihood cá»§a classifier given data. Em tÃ­nh nhÆ° nÃ y cÃ³ Ä‘Ãºng khÃ´ng áº¡? log-likelihood = sum(log probability (c | x_i)) = sum(log(probs) = sum(log(c.predict_proba(x_i))). Em xin cáº£m Æ¡n",,"#math, #Q&A",,,
"ChÃ o má»i ngÆ°á»i áº¡,
Vá»«a qua mÃ¬nh cÃ³ lÃ m 1 bÃ i thá»±c hÃ nh vá» tÃ´ áº£nh tráº¯ng Ä‘en. MÃ¬nh cÃ³ tham kháº£o qua paper nÃ y: https://arxiv.org/pdf/1611.07004.pdf
MÃ¬nh cÅ©ng Ä‘Ã£ cÃ³ káº¿t quáº£ khÃ¡ tá»‘t rá»“i. Tuy nhiÃªn cÃ³ vÃ i Ä‘iá»u mÃ¬nh chÆ°a thá»±c sá»± hiá»ƒu khi hiá»‡n thá»±c model trong paper vÃ  lÃ m mÃ¬nh hÆ¡i khÃ³ chá»‹u vÃ  váº«n cÃ²n bÄƒn khoan. NÃªn mong má»i ngÆ°á»i ai tá»«ng lÃ m qua cÃ¡i nÃ y giÃºp mÃ¬nh chÃºt giáº£i Ä‘Ã¡p áº¡
1. táº¡i sao trong cÃ¡c task colorize image láº¡i dÃ¹ng khÃ´ng gian mÃ u Lab thay vÃ¬ dÃ¹ng RGB
2. trong patch gan, máº¡ng discriminator cÃ³ cáº§n má»™t táº§ng cuá»‘i lÃ  táº§ng sigmoid sau khi qua táº§ng tÃ­ch cháº­p khÃ´ng? Táº¡i tháº¥y má»™t sá»‘ nÆ¡i implement thÃ¬ cÃ³ nÆ¡i cÃ³, cÃ³ nÆ¡i khÃ´ng, mÃ  Ä‘a sá»‘ tháº¥y lÃ  khÃ´ng.
MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i áº¡, Vá»«a qua mÃ¬nh cÃ³ lÃ m 1 bÃ i thá»±c hÃ nh vá» tÃ´ áº£nh tráº¯ng Ä‘en. MÃ¬nh cÃ³ tham kháº£o qua paper nÃ y: https://arxiv.org/pdf/1611.07004.pdf MÃ¬nh cÅ©ng Ä‘Ã£ cÃ³ káº¿t quáº£ khÃ¡ tá»‘t rá»“i. Tuy nhiÃªn cÃ³ vÃ i Ä‘iá»u mÃ¬nh chÆ°a thá»±c sá»± hiá»ƒu khi hiá»‡n thá»±c model trong paper vÃ  lÃ m mÃ¬nh hÆ¡i khÃ³ chá»‹u vÃ  váº«n cÃ²n bÄƒn khoan. NÃªn mong má»i ngÆ°á»i ai tá»«ng lÃ m qua cÃ¡i nÃ y giÃºp mÃ¬nh chÃºt giáº£i Ä‘Ã¡p áº¡ 1. táº¡i sao trong cÃ¡c task colorize image láº¡i dÃ¹ng khÃ´ng gian mÃ u Lab thay vÃ¬ dÃ¹ng RGB 2. trong patch gan, máº¡ng discriminator cÃ³ cáº§n má»™t táº§ng cuá»‘i lÃ  táº§ng sigmoid sau khi qua táº§ng tÃ­ch cháº­p khÃ´ng? Táº¡i tháº¥y má»™t sá»‘ nÆ¡i implement thÃ¬ cÃ³ nÆ¡i cÃ³, cÃ³ nÆ¡i khÃ´ng, mÃ  Ä‘a sá»‘ tháº¥y lÃ  khÃ´ng. MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, em má»›i Ä‘á»c vá» DL vÃ  lÃ m vá» phÃ¢n Ä‘oáº¡n áº£nh (instance segmentation vs semantic segmentation) má»¥c Ä‘Ã­ch phÃ¢n Ä‘oáº¡n áº£nh y táº¿ greyscale . ThÃ¬ cÃ³ 3 thuáº­t toÃ¡n em cáº§n chá»n vÃ  Ä‘Æ°a ra Æ°u nhÆ°á»£c cá»§a FCN, Mark R-CNN, Unet : ThÃ¬ cÃ³ váº¥n Ä‘á» lÃ  em hiá»ƒu lÃ  FCN vÃ  Unet cÃ¹ng lÃ  downsampling rá»“i láº¡i upshampling lÃªn, thÃ¬ khÃ¡c nhau chá»— nÃ o ( vá» tÃ­nh cháº¥t, thá»i gian xá»­ lÃ½, cháº¥t lÆ°á»£ng ), ... VÃ  sao mark r-cnn thÃ¬ em ko tháº¥y Ä‘á» cáº­p Ä‘áº¿n Ä‘á»ƒ xá»­ lÃ½ áº£nh y táº¿ áº¡ . Em lÃ m bÃªn y táº¿ nÃªn kiáº¿n thá»©c háº¹p mong cÃ¡c bÃ¡c thÃ´ng cáº£m áº¡ . :( Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i áº¡, em má»›i Ä‘á»c vá» DL vÃ  lÃ m vá» phÃ¢n Ä‘oáº¡n áº£nh (instance segmentation vs semantic segmentation) má»¥c Ä‘Ã­ch phÃ¢n Ä‘oáº¡n áº£nh y táº¿ greyscale . ThÃ¬ cÃ³ 3 thuáº­t toÃ¡n em cáº§n chá»n vÃ  Ä‘Æ°a ra Æ°u nhÆ°á»£c cá»§a FCN, Mark R-CNN, Unet : ThÃ¬ cÃ³ váº¥n Ä‘á» lÃ  em hiá»ƒu lÃ  FCN vÃ  Unet cÃ¹ng lÃ  downsampling rá»“i láº¡i upshampling lÃªn, thÃ¬ khÃ¡c nhau chá»— nÃ o ( vá» tÃ­nh cháº¥t, thá»i gian xá»­ lÃ½, cháº¥t lÆ°á»£ng ), ... VÃ  sao mark r-cnn thÃ¬ em ko tháº¥y Ä‘á» cáº­p Ä‘áº¿n Ä‘á»ƒ xá»­ lÃ½ áº£nh y táº¿ áº¡ . Em lÃ m bÃªn y táº¿ nÃªn kiáº¿n thá»©c háº¹p mong cÃ¡c bÃ¡c thÃ´ng cáº£m áº¡ . :( Em cáº£m Æ¡n áº¡.",,,,,
"HÃ´m nay, em/mÃ¬nh ngá»“i lÆ°á»›t drive xem cÃ³ gÃ¬ Ä‘á»ƒ xÃ³a cho nháº¹ thÃ¬ phÃ¡t hiá»‡n ra cÃ³ Ã­t tÃ i liá»‡u mÃ  lÃ¢u nay bá» quÃªn máº¥t. Thá»i cÃ²n tráº» khá»e, mÃ¬nh vÃ  vÃ i báº¡n á»Ÿ lab cÃ³ research vá» Transfer style vÃ  cÃ³ note láº¡i Ã½ chÃ­nh cá»§a 1 sá»‘ paper ná»•i tiáº¿ng. Há»“i Ä‘Ã³ em/mÃ¬nh nhá»› lÃ  Ä‘á»c cÃ¡c paper nÃ y ráº¥t khÃ³ hiá»ƒu nhÆ°ng lÃºc note ra thÃ¬ tháº¥y ráº¥t Ä‘Æ¡n giáº£n. Hy vá»ng tÃ i liá»‡u nÃ y giÃºp Ã­ch cho cÃ¡c báº¡n Ä‘ang quan tÃ¢m vá» bÃ i toÃ¡n Image to Image, GAN,vv... Ä‘áº·c biá»‡t lÃ  cÃ¡c báº¡n Ä‘ang lÃ m Ä‘á»“ Ã¡n nhÆ° em/mÃ¬nh.
https://www.overleaf.com/read/zmtsjybppmnc
https://docs.google.com/document/d/1Eiu3-B7-wX7klu0ECDwu0QIwSiFSqZ7XfUGHVHBnxDQ/edit?usp=sharing","HÃ´m nay, em/mÃ¬nh ngá»“i lÆ°á»›t drive xem cÃ³ gÃ¬ Ä‘á»ƒ xÃ³a cho nháº¹ thÃ¬ phÃ¡t hiá»‡n ra cÃ³ Ã­t tÃ i liá»‡u mÃ  lÃ¢u nay bá» quÃªn máº¥t. Thá»i cÃ²n tráº» khá»e, mÃ¬nh vÃ  vÃ i báº¡n á»Ÿ lab cÃ³ research vá» Transfer style vÃ  cÃ³ note láº¡i Ã½ chÃ­nh cá»§a 1 sá»‘ paper ná»•i tiáº¿ng. Há»“i Ä‘Ã³ em/mÃ¬nh nhá»› lÃ  Ä‘á»c cÃ¡c paper nÃ y ráº¥t khÃ³ hiá»ƒu nhÆ°ng lÃºc note ra thÃ¬ tháº¥y ráº¥t Ä‘Æ¡n giáº£n. Hy vá»ng tÃ i liá»‡u nÃ y giÃºp Ã­ch cho cÃ¡c báº¡n Ä‘ang quan tÃ¢m vá» bÃ i toÃ¡n Image to Image, GAN,vv... Ä‘áº·c biá»‡t lÃ  cÃ¡c báº¡n Ä‘ang lÃ m Ä‘á»“ Ã¡n nhÆ° em/mÃ¬nh. https://www.overleaf.com/read/zmtsjybppmnc https://docs.google.com/document/d/1Eiu3-B7-wX7klu0ECDwu0QIwSiFSqZ7XfUGHVHBnxDQ/edit?usp=sharing",,,,,
"Em chÃ o mn áº¡,
Em cÃ³ cÃ¢u há»i vá» Layer Normailzation áº¡. E tháº¥y trong má»™t sá»‘ kiáº¿n trÃºc cÃ³ LayerNorm thÃ¬ Ä‘Ã´i ng ta sáº½ set learnable parameter = False. Em ko biáº¿t khi nÃ o thÃ¬ nÃªn set True hay False áº¡ ?
Cáº£m Æ¡n mn","Em chÃ o mn áº¡, Em cÃ³ cÃ¢u há»i vá» Layer Normailzation áº¡. E tháº¥y trong má»™t sá»‘ kiáº¿n trÃºc cÃ³ LayerNorm thÃ¬ Ä‘Ã´i ng ta sáº½ set learnable parameter = False. Em ko biáº¿t khi nÃ o thÃ¬ nÃªn set True hay False áº¡ ? Cáº£m Æ¡n mn",,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡
Em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n Multi Label Text/Sentence classification nháº±m categorize feature áº¡.
VÃ­ dá»¥:
'new lazy load technique for better performance.' => performance
'- Added: Youtube (or custom) video player in the ""Text Plus Image Vertical"" section;.' => social media
...
Hiá»‡n táº¡i em cÃ³ khoáº£ng 96 categories vÃ  data set gá»“m > 4000 entries. Tuy nhiÃªn kháº£ nÄƒng predict thÃ¬ chÆ°a Ä‘Æ°á»£c nhÆ° em mong muá»‘n.
CÃ³ bÃ¡c nÃ o Ä‘Ã£ tá»«ng cÃ³ kinh nghiá»‡m trong máº£ng nÃ y cÃ³ thá»ƒ gá»£i Ã½ cho em Ä‘Æ°á»£c khÃ´ng áº¡. Hiá»‡n em Ä‘ang dÃ¹ng TFIDF, BOW.
Em xin thÃ´ng tin thÃªm lÃ  má»™t sá»‘ category/label xuáº¥t hiá»‡n ráº¥t nhiá»u. Distribution khÃ´ng Ä‘Æ°á»£c Ä‘á»u láº¯m
áº¢nh phÃ­a dÆ°á»›i lÃ  má»™t vÃ­ dá»¥ sai tÃ¨ le
Cáº£m Æ¡n cÃ¡c bÃ¡c áº¡","Xin chÃ o má»i ngÆ°á»i áº¡ Em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n Multi Label Text/Sentence classification nháº±m categorize feature áº¡. VÃ­ dá»¥: 'new lazy load technique for better performance.' => performance '- Added: Youtube (or custom) video player in the ""Text Plus Image Vertical"" section;.' => social media ... Hiá»‡n táº¡i em cÃ³ khoáº£ng 96 categories vÃ  data set gá»“m > 4000 entries. Tuy nhiÃªn kháº£ nÄƒng predict thÃ¬ chÆ°a Ä‘Æ°á»£c nhÆ° em mong muá»‘n. CÃ³ bÃ¡c nÃ o Ä‘Ã£ tá»«ng cÃ³ kinh nghiá»‡m trong máº£ng nÃ y cÃ³ thá»ƒ gá»£i Ã½ cho em Ä‘Æ°á»£c khÃ´ng áº¡. Hiá»‡n em Ä‘ang dÃ¹ng TFIDF, BOW. Em xin thÃ´ng tin thÃªm lÃ  má»™t sá»‘ category/label xuáº¥t hiá»‡n ráº¥t nhiá»u. Distribution khÃ´ng Ä‘Æ°á»£c Ä‘á»u láº¯m áº¢nh phÃ­a dÆ°á»›i lÃ  má»™t vÃ­ dá»¥ sai tÃ¨ le Cáº£m Æ¡n cÃ¡c bÃ¡c áº¡",,,,,
"ToÃ¡n - vÃ¢ng váº«n lÃ  nÃ³ thÃ´i. Ngá»“i miá»‡t mÃ i dáº¡o kháº¯p cÃ¡c clips trÃªn youtube Ä‘á»ƒ hiá»ƒu hÆ¡n vá» PCA vÃ  LDA thÃ¬ phÃ¡t hiá»‡n ra Ä‘Æ°á»£c chanel cá»§a bÃ¡c Luis Serrano cÃ³ cÃ¡ch giáº£i thÃ­ch vÃ  visualize cá»±c ká»³ dá»… hiá»ƒu nÃªn mÃ¬nh cÅ©ng tÃ² mÃ² tÃ¬m profile cá»§a bÃ¡c nÃ y trÃªn Linken: 
BÃ¡c nÃ y tá»«ng tá»‘t nghiá»‡p tiáº¿n sÄ© vá» ToÃ¡n á»Ÿ University of Michigan
Machine Learning Engineer á»Ÿ Google
Head of content: AI, Data Science, Machine learning cá»§a Udacity
Lead Artificial Intelligence Educator cá»§a Apple
Äang lÃ  Quantum AI Research Scientist 
Láº¡i cÃ³ thÃªm má»™t kÃªnh tin cáº­y Ä‘á»ƒ cÃ¡c anh em máº§n mÃ² vá» toÃ¡n.","ToÃ¡n - vÃ¢ng váº«n lÃ  nÃ³ thÃ´i. Ngá»“i miá»‡t mÃ i dáº¡o kháº¯p cÃ¡c clips trÃªn youtube Ä‘á»ƒ hiá»ƒu hÆ¡n vá» PCA vÃ  LDA thÃ¬ phÃ¡t hiá»‡n ra Ä‘Æ°á»£c chanel cá»§a bÃ¡c Luis Serrano cÃ³ cÃ¡ch giáº£i thÃ­ch vÃ  visualize cá»±c ká»³ dá»… hiá»ƒu nÃªn mÃ¬nh cÅ©ng tÃ² mÃ² tÃ¬m profile cá»§a bÃ¡c nÃ y trÃªn Linken: BÃ¡c nÃ y tá»«ng tá»‘t nghiá»‡p tiáº¿n sÄ© vá» ToÃ¡n á»Ÿ University of Michigan Machine Learning Engineer á»Ÿ Google Head of content: AI, Data Science, Machine learning cá»§a Udacity Lead Artificial Intelligence Educator cá»§a Apple Äang lÃ  Quantum AI Research Scientist Láº¡i cÃ³ thÃªm má»™t kÃªnh tin cáº­y Ä‘á»ƒ cÃ¡c anh em máº§n mÃ² vá» toÃ¡n.",,,,,
"ChÃ o cÃ¡c báº¡n,
Hiá»‡n nhÃ³m dá»‹ch cuá»‘n ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition""(https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) Ä‘Ã£ gáº§n hoÃ n thiá»‡n ná»­a Ä‘áº§u cá»§a cuá»‘n sÃ¡ch. ChÃºng tÃ´i Ä‘Ã£ quyáº¿t Ä‘á»‹nh gá»­i Ä‘áº¿n báº¡n Ä‘á»c ná»­a Ä‘áº§u cá»§a cuá»‘n sÃ¡ch vá» ná»n táº£ng Machine Learning vÃ  thÆ° viá»‡n Scikit-Learn trÆ°á»›c khi tiáº¿p tá»¥c dá»‹ch ná»­a sau vá» Keras vÃ  Tensorflow.
ÄÃ¢y lÃ  má»™t cuá»‘n sÃ¡ch cá»±c hay cáº£ vá» lÃ½ thuyáº¿t Machine Learning láº«n code thá»±c táº¿ ráº¥t bÃ i báº£n. Tuy nhiÃªn, vÃ¬ váº¥n Ä‘á» báº£n quyá»n, chÃºng tÃ´i khÃ´ng thá»ƒ chia sáº» rá»™ng rÃ£i cuá»‘n sÃ¡ch nÃ y trong cá»™ng Ä‘á»“ng nhÆ° hai cuá»‘n sÃ¡ch trÆ°á»›c Ä‘Æ°á»£c mÃ  cáº§n phÃ¢n phá»‘i dÆ°á»›i dáº¡ng thÆ°Æ¡ng máº¡i (vá»›i giÃ¡ dá»± kiáº¿n sáº½ ráº» hÆ¡n nhiá»u so vá»›i báº£n gá»‘c tiáº¿ng Anh). Hiá»‡n nhÃ³m Ä‘ang gáº·p khÃ³ khÄƒn vá» viá»‡c tÃ¬m ná»n táº£ng há»— trá»£ tá»‘t viá»‡c háº¡n cháº¿ chia sáº» file pdf. Cháº³ng háº¡n, má»™t ná»n táº£ng cho phÃ©p háº¡n cháº¿ sá»‘ lÆ°á»£ng thiáº¿t bá»‹ cÃ³ thá»ƒ Ä‘á»c Ä‘Æ°á»£c vá»›i má»—i tÃ i khoáº£n.
Náº¿u báº¡n nÃ o cÃ³ thÃ´ng tin vá» má»™t ná»n táº£ng tÆ°Æ¡ng tá»± thÃ¬ ping mÃ¬nh nhÃ©. Cáº£m Æ¡n cÃ¡c báº¡n.
====
Update sau khi cÃ³ báº¡n há»i vá» hai cuá»‘n trÆ°á»›c:
Cuá»‘n 1: https://github.com/mlbvn/ml-yearning-vn
Cuá»‘n 2: https://d2l.aivivn.com/","ChÃ o cÃ¡c báº¡n, Hiá»‡n nhÃ³m dá»‹ch cuá»‘n ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition""(https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) Ä‘Ã£ gáº§n hoÃ n thiá»‡n ná»­a Ä‘áº§u cá»§a cuá»‘n sÃ¡ch. ChÃºng tÃ´i Ä‘Ã£ quyáº¿t Ä‘á»‹nh gá»­i Ä‘áº¿n báº¡n Ä‘á»c ná»­a Ä‘áº§u cá»§a cuá»‘n sÃ¡ch vá» ná»n táº£ng Machine Learning vÃ  thÆ° viá»‡n Scikit-Learn trÆ°á»›c khi tiáº¿p tá»¥c dá»‹ch ná»­a sau vá» Keras vÃ  Tensorflow. ÄÃ¢y lÃ  má»™t cuá»‘n sÃ¡ch cá»±c hay cáº£ vá» lÃ½ thuyáº¿t Machine Learning láº«n code thá»±c táº¿ ráº¥t bÃ i báº£n. Tuy nhiÃªn, vÃ¬ váº¥n Ä‘á» báº£n quyá»n, chÃºng tÃ´i khÃ´ng thá»ƒ chia sáº» rá»™ng rÃ£i cuá»‘n sÃ¡ch nÃ y trong cá»™ng Ä‘á»“ng nhÆ° hai cuá»‘n sÃ¡ch trÆ°á»›c Ä‘Æ°á»£c mÃ  cáº§n phÃ¢n phá»‘i dÆ°á»›i dáº¡ng thÆ°Æ¡ng máº¡i (vá»›i giÃ¡ dá»± kiáº¿n sáº½ ráº» hÆ¡n nhiá»u so vá»›i báº£n gá»‘c tiáº¿ng Anh). Hiá»‡n nhÃ³m Ä‘ang gáº·p khÃ³ khÄƒn vá» viá»‡c tÃ¬m ná»n táº£ng há»— trá»£ tá»‘t viá»‡c háº¡n cháº¿ chia sáº» file pdf. Cháº³ng háº¡n, má»™t ná»n táº£ng cho phÃ©p háº¡n cháº¿ sá»‘ lÆ°á»£ng thiáº¿t bá»‹ cÃ³ thá»ƒ Ä‘á»c Ä‘Æ°á»£c vá»›i má»—i tÃ i khoáº£n. Náº¿u báº¡n nÃ o cÃ³ thÃ´ng tin vá» má»™t ná»n táº£ng tÆ°Æ¡ng tá»± thÃ¬ ping mÃ¬nh nhÃ©. Cáº£m Æ¡n cÃ¡c báº¡n. ==== Update sau khi cÃ³ báº¡n há»i vá» hai cuá»‘n trÆ°á»›c: Cuá»‘n 1: https://github.com/mlbvn/ml-yearning-vn Cuá»‘n 2: https://d2l.aivivn.com/",,,,,
"ChÃ o mn, mÃ´ hÃ¬nh há»c cá»§a mÃ¬nh nháº­n Ä‘Æ°á»£c AUC táº¡m á»•n nhÆ°ng AUPR quÃ¡ tháº¥p. Xin giÃºp mÃ¬nh nguyÃªn nhÃ¢n (MÃ¬nh nghÄ© lÃ  do dá»¯ liá»‡u) vÃ  gÃ³p Ã½ giÃºp mÃ¬nh hÆ°á»›ng xá»­ lÃ½.
CÃ¡m Æ¡n mn.","ChÃ o mn, mÃ´ hÃ¬nh há»c cá»§a mÃ¬nh nháº­n Ä‘Æ°á»£c AUC táº¡m á»•n nhÆ°ng AUPR quÃ¡ tháº¥p. Xin giÃºp mÃ¬nh nguyÃªn nhÃ¢n (MÃ¬nh nghÄ© lÃ  do dá»¯ liá»‡u) vÃ  gÃ³p Ã½ giÃºp mÃ¬nh hÆ°á»›ng xá»­ lÃ½. CÃ¡m Æ¡n mn.",,,,,
"mn cho em há»i, sau chá»— Ä‘Ã¡nh dáº¥u trong áº£nh láº¡i thÃªm [0] áº¡. Em cáº£m Æ¡n mn nhiá»u.","mn cho em há»i, sau chá»— Ä‘Ã¡nh dáº¥u trong áº£nh láº¡i thÃªm [0] áº¡. Em cáº£m Æ¡n mn nhiá»u.",,,,,
"Trong vÃ²ng 6 thÃ¡ng gáº§n Ä‘Ã¢y, lÄ©nh vá»±c Computer Vision cÃ³ nhá»¯ng bÆ°á»›c Ä‘á»™t phÃ¡ nháº¥t Ä‘á»‹nh, tá»« viá»‡c triá»ƒn khai kiáº¿n trÃºc Attention/Transformers, cho tá»›i loáº¡i bá» lá»›p BatchNormalization, vÃ  rá»“i quay láº¡i vá»›i kiáº¿n trÃºc CNN vá»›i SOTA lÃ  EfficientNetV2.
ChÆ°a dá»«ng láº¡i á»Ÿ Ä‘Ã¢y, ngÃ y 4/5/2021, nhÃ³m Google Brain á»Ÿ Zurich vÃ  Berlin cÃ´ng bá»‘ SOTA má»›i, dá»±a vÃ o kiáº¿n trÃºc MLP (Multi-Layer Perceptron). Models vá»›i tÃªn gá»i lÃ  MLP-Mixer hoÃ n toÃ n khÃ´ng sá»­ dá»¥ng kiáº¿n trÃºc Convolution hay Transformer nhÆ° trÆ°á»›c. VÃ  nhÃ³m tÃ¡c giáº£ hi vá»ng bÃ i bÃ¡o nÃ y lÃ  viÃªn gáº¡ch Ä‘áº§u tiÃªn cho nhá»¯ng bÆ°á»›c Ä‘i tiáº¿p theo.
BÃ i bÃ¡o táº¡i Ä‘Ã¢y: https://arxiv.org/abs/2105.01601
Original Code Ä‘Æ°á»£c viáº¿t trÃªn JAX vÃ  Linen táº¡i Ä‘Ã¢y: https://github.com/google-research/vision_transformer/tree/linen
VÃ  ráº¥t nhanh chÃ³ng nÃ³ Ä‘Æ°á»£c port sang Pytorch táº¡i Ä‘Ã¢y:
https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/mlp_mixer.py
Ps. KhÃ´ng biáº¿t bÃªn TensorFlow cÃ³ codebases nÃ o táº­p há»£p nhanh chÃ³ng, chÃ­nh xÃ¡c, tháº­m trÃ­ huáº¥n luyá»‡n láº¡i vá»›i káº¿t quáº£ cÃ²n tá»‘t hÆ¡n nhÆ° codebase cá»§a anh Ross Wrightman Ä‘Ã£ lÃ m cho framework PyTorch hay khÃ´ng?","Trong vÃ²ng 6 thÃ¡ng gáº§n Ä‘Ã¢y, lÄ©nh vá»±c Computer Vision cÃ³ nhá»¯ng bÆ°á»›c Ä‘á»™t phÃ¡ nháº¥t Ä‘á»‹nh, tá»« viá»‡c triá»ƒn khai kiáº¿n trÃºc Attention/Transformers, cho tá»›i loáº¡i bá» lá»›p BatchNormalization, vÃ  rá»“i quay láº¡i vá»›i kiáº¿n trÃºc CNN vá»›i SOTA lÃ  EfficientNetV2. ChÆ°a dá»«ng láº¡i á»Ÿ Ä‘Ã¢y, ngÃ y 4/5/2021, nhÃ³m Google Brain á»Ÿ Zurich vÃ  Berlin cÃ´ng bá»‘ SOTA má»›i, dá»±a vÃ o kiáº¿n trÃºc MLP (Multi-Layer Perceptron). Models vá»›i tÃªn gá»i lÃ  MLP-Mixer hoÃ n toÃ n khÃ´ng sá»­ dá»¥ng kiáº¿n trÃºc Convolution hay Transformer nhÆ° trÆ°á»›c. VÃ  nhÃ³m tÃ¡c giáº£ hi vá»ng bÃ i bÃ¡o nÃ y lÃ  viÃªn gáº¡ch Ä‘áº§u tiÃªn cho nhá»¯ng bÆ°á»›c Ä‘i tiáº¿p theo. BÃ i bÃ¡o táº¡i Ä‘Ã¢y: https://arxiv.org/abs/2105.01601 Original Code Ä‘Æ°á»£c viáº¿t trÃªn JAX vÃ  Linen táº¡i Ä‘Ã¢y: https://github.com/google-research/vision_transformer/tree/linen VÃ  ráº¥t nhanh chÃ³ng nÃ³ Ä‘Æ°á»£c port sang Pytorch táº¡i Ä‘Ã¢y: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/mlp_mixer.py Ps. KhÃ´ng biáº¿t bÃªn TensorFlow cÃ³ codebases nÃ o táº­p há»£p nhanh chÃ³ng, chÃ­nh xÃ¡c, tháº­m trÃ­ huáº¥n luyá»‡n láº¡i vá»›i káº¿t quáº£ cÃ²n tá»‘t hÆ¡n nhÆ° codebase cá»§a anh Ross Wrightman Ä‘Ã£ lÃ m cho framework PyTorch hay khÃ´ng?",,,,,
"KÃ­nh chÃ o cáº£ nhÃ . Äá»£t rá»“i cÃ³ má»™t sá»‘ báº¡n há»i vá» cÃ¡ch tiáº¿p cáº­n má»™t website Ä‘á»ƒ crawl dá»¯ liá»‡u, cÃ¡ch lÆ°u trá»¯ thÃ´ng tin vÃ  visualize dá»¯ liá»‡u. Em cÃ¹ng khÃ´ng pro láº¯m nhá»¯ng cÃ³ lÃ m qua nÃªn lÃ m cÃ¡i clip guide cho cÃ¡c báº¡n má»›i há»c.
Pháº§n phÃ¢n tÃ­ch cÃ²n Ã­t do chá»‰ muá»‘n nháº¯n nhá»§ cÃ¡c báº¡n Ä‘á»«ng tin vÃ o soi cáº§u, bÃ¡o sá»‘ mÃ  máº¥t tiá»n :D
Mong admin duyá»‡t bÃ i vÃ  mong cÃ¡c bÃ¡c chá»‰ giÃ¡o!","KÃ­nh chÃ o cáº£ nhÃ . Äá»£t rá»“i cÃ³ má»™t sá»‘ báº¡n há»i vá» cÃ¡ch tiáº¿p cáº­n má»™t website Ä‘á»ƒ crawl dá»¯ liá»‡u, cÃ¡ch lÆ°u trá»¯ thÃ´ng tin vÃ  visualize dá»¯ liá»‡u. Em cÃ¹ng khÃ´ng pro láº¯m nhá»¯ng cÃ³ lÃ m qua nÃªn lÃ m cÃ¡i clip guide cho cÃ¡c báº¡n má»›i há»c. Pháº§n phÃ¢n tÃ­ch cÃ²n Ã­t do chá»‰ muá»‘n nháº¯n nhá»§ cÃ¡c báº¡n Ä‘á»«ng tin vÃ o soi cáº§u, bÃ¡o sá»‘ mÃ  máº¥t tiá»n :D Mong admin duyá»‡t bÃ i vÃ  mong cÃ¡c bÃ¡c chá»‰ giÃ¡o!",,,,,
Cho mÃ¬nh há»i xÃ­u lÃ  má»i ngÆ°á»i cÃ³ ai tá»«ng Ã¡p dá»¥ng xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho con chatbot cá»§a facebook chÆ°a cÃ³ thá»ƒ cho mÃ¬nh xin tÃ i liá»‡u tham kháº£o vá»›i áº¡?,Cho mÃ¬nh há»i xÃ­u lÃ  má»i ngÆ°á»i cÃ³ ai tá»«ng Ã¡p dá»¥ng xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho con chatbot cá»§a facebook chÆ°a cÃ³ thá»ƒ cho mÃ¬nh xin tÃ i liá»‡u tham kháº£o vá»›i áº¡?,,,,,
#probability,,#probability,,,,
"#food_dataset
Hi group,
Má»i ngÆ°á»i cÃ³ nguá»“n data nÃ o vá» nutrition food ( tiáº¿ng anh hoáº·c tiáº¿ng Viá»‡t )Ä‘Ã£ Ä‘Æ°á»£c label cho em xin vá»›i áº¡ !
(Dáº¡ng csv, khÃ´ng pháº£i dáº¡ng image).
Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡ !","Hi group, Má»i ngÆ°á»i cÃ³ nguá»“n data nÃ o vá» nutrition food ( tiáº¿ng anh hoáº·c tiáº¿ng Viá»‡t )Ä‘Ã£ Ä‘Æ°á»£c label cho em xin vá»›i áº¡ ! (Dáº¡ng csv, khÃ´ng pháº£i dáº¡ng image). Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡ !",#food_dataset,,,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m bÃ i toÃ¡n Anomaly Detection báº±ng cÃ¡ch xá»­ lÃ½ gÃ³i tin https header. GÃ³i tin ban Ä‘áº§u cÃ³ dáº¡ng file .pcap vÃ  em muá»‘n chuyá»ƒn sang file .csv Ä‘á»ƒ cháº¡y thuáº­t toÃ¡n. Em muá»‘n há»i má»i ngÆ°á»i cÃ³ tool nÃ o Ä‘á»ƒ cÃ³ thá»ƒ lÃ m viá»‡c nÃ y (bao gá»“m viá»‡c cÃ³ thá»ƒ lá»±a chá»n cÃ¡c trÆ°á»ng mong muá»‘n) má»™t cÃ¡ch dá»… dÃ ng khÃ´ng áº¡. Em xin cáº£m Æ¡n.
// Em dÃ¹ng Wireshark Ä‘á»ƒ export ra file .csv thÃ¬ nÃ³ bá»‹ tháº¿ nÃ y (cá»™t info)",ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m bÃ i toÃ¡n Anomaly Detection báº±ng cÃ¡ch xá»­ lÃ½ gÃ³i tin https header. GÃ³i tin ban Ä‘áº§u cÃ³ dáº¡ng file .pcap vÃ  em muá»‘n chuyá»ƒn sang file .csv Ä‘á»ƒ cháº¡y thuáº­t toÃ¡n. Em muá»‘n há»i má»i ngÆ°á»i cÃ³ tool nÃ o Ä‘á»ƒ cÃ³ thá»ƒ lÃ m viá»‡c nÃ y (bao gá»“m viá»‡c cÃ³ thá»ƒ lá»±a chá»n cÃ¡c trÆ°á»ng mong muá»‘n) má»™t cÃ¡ch dá»… dÃ ng khÃ´ng áº¡. Em xin cáº£m Æ¡n. // Em dÃ¹ng Wireshark Ä‘á»ƒ export ra file .csv thÃ¬ nÃ³ bá»‹ tháº¿ nÃ y (cá»™t info),,,,,
"Xin chÃ o má»i ngÆ°á»i. Cho mÃ¬nh há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ i tensorflow gpu trÃªn CPU khÃ´ng cÃ³ AVX/SSE4.1 mÃ  khÃ´ng cáº§n pháº£i dÃ¹ng Bazel khÃ´ng? MÃ¬nh pháº£i cÃ i trÃªn server trÆ°á»ng mÃ  há» khÃ´ng cho cÃ i thÃªm báº¥t cá»© pháº§n má»m nÃ o khÃ¡c.
Specs cá»§a mÃ¡y
Ubuntu 18.04
CUDA 10.0.130
GPU Titan X
CPU Quadcore AMD Opteron(tm) 2376
Python 3.6 hoáº·c 3.8
Xin cáº£m Æ¡n.",Xin chÃ o má»i ngÆ°á»i. Cho mÃ¬nh há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ cÃ i tensorflow gpu trÃªn CPU khÃ´ng cÃ³ AVX/SSE4.1 mÃ  khÃ´ng cáº§n pháº£i dÃ¹ng Bazel khÃ´ng? MÃ¬nh pháº£i cÃ i trÃªn server trÆ°á»ng mÃ  há» khÃ´ng cho cÃ i thÃªm báº¥t cá»© pháº§n má»m nÃ o khÃ¡c. Specs cá»§a mÃ¡y Ubuntu 18.04 CUDA 10.0.130 GPU Titan X CPU Quadcore AMD Opteron(tm) 2376 Python 3.6 hoáº·c 3.8 Xin cáº£m Æ¡n.,,,,,
"xin chÃ o má»i ngÆ°á»i mÃ¬nh cÃ³ train mÃ´ hÃ¬nh dá»‹ch mÃ¡y vi-en (seq2seq), mÃ¬nh Ä‘ang bá»‹ sai nhiá»u hoáº·c khÃ´ng nháº­n ra á»Ÿ pháº§n danh tá»« riÃªng. á»Ÿ pháº§n decoder nÃ³ nÃ³ dá»‹ch luÃ´n tÃªn danh tá»« riÃªng. Ai cÃ³ kinh nghiá»‡m hay ká»¹ thuáº­t nÃ o hay Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y truyá»n cho em Ã­t kinh nghiá»‡m. Em xin cáº£m Æ¡n","xin chÃ o má»i ngÆ°á»i mÃ¬nh cÃ³ train mÃ´ hÃ¬nh dá»‹ch mÃ¡y vi-en (seq2seq), mÃ¬nh Ä‘ang bá»‹ sai nhiá»u hoáº·c khÃ´ng nháº­n ra á»Ÿ pháº§n danh tá»« riÃªng. á»Ÿ pháº§n decoder nÃ³ nÃ³ dá»‹ch luÃ´n tÃªn danh tá»« riÃªng. Ai cÃ³ kinh nghiá»‡m hay ká»¹ thuáº­t nÃ o hay Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y truyá»n cho em Ã­t kinh nghiá»‡m. Em xin cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n giá» mÃ¬nh Ä‘ang gáº·p má»™t váº¥n Ä‘á» khi Ä‘áº©y model lÃªn GPU cá»§a mobile sá»­ dá»¥ng Tensorflow lite vÃ  NNAPI. Tuy nhiÃªn cÃ³ má»™t váº¥n Ä‘á» Ä‘Ã³ lÃ  khi cháº¡y tensorlfow lite dÃ¹ng NNAPI thÃ¬ táº¥t cáº£ cÃ¡c tensor pháº£i lÃ  fixed shape hay static shape. BÃ i toÃ¡n mÃ¬nh lÃ m vá» tiáº¿ng nÃ³i vÃ  Ä‘á»™ dÃ i audio Ä‘áº§u ra phá»¥ thuá»™c ráº¥t nhiá»u vÃ o Ä‘áº§u vÃ o, nÃªn viá»‡c sá»­ dá»¥ng tensor vá»›i fixed length Ä‘á»ƒ biá»ƒu diá»…n lÃ  khÃ´ng kháº£ thi vÃ  tá»‘n kÃ©m trong tÃ­nh toÃ¡n (pháº£i tÃ­nh toÃ¡n thá»«a nhiá»u).
Báº¡n nÃ o trong nhÃ³m cÃ³ kinh nghiá»‡m hoáº·c giáº£i phÃ¡p cÃ³ thá»ƒ chia sáº» vá»›i bá»n mÃ¬nh thÃ¬ tá»‘t quÃ¡ áº¡.
#TensorflowLite #NNAPI #MOBILE #GPU","ChÃ o má»i ngÆ°á»i, hiá»‡n giá» mÃ¬nh Ä‘ang gáº·p má»™t váº¥n Ä‘á» khi Ä‘áº©y model lÃªn GPU cá»§a mobile sá»­ dá»¥ng Tensorflow lite vÃ  NNAPI. Tuy nhiÃªn cÃ³ má»™t váº¥n Ä‘á» Ä‘Ã³ lÃ  khi cháº¡y tensorlfow lite dÃ¹ng NNAPI thÃ¬ táº¥t cáº£ cÃ¡c tensor pháº£i lÃ  fixed shape hay static shape. BÃ i toÃ¡n mÃ¬nh lÃ m vá» tiáº¿ng nÃ³i vÃ  Ä‘á»™ dÃ i audio Ä‘áº§u ra phá»¥ thuá»™c ráº¥t nhiá»u vÃ o Ä‘áº§u vÃ o, nÃªn viá»‡c sá»­ dá»¥ng tensor vá»›i fixed length Ä‘á»ƒ biá»ƒu diá»…n lÃ  khÃ´ng kháº£ thi vÃ  tá»‘n kÃ©m trong tÃ­nh toÃ¡n (pháº£i tÃ­nh toÃ¡n thá»«a nhiá»u). Báº¡n nÃ o trong nhÃ³m cÃ³ kinh nghiá»‡m hoáº·c giáº£i phÃ¡p cÃ³ thá»ƒ chia sáº» vá»›i bá»n mÃ¬nh thÃ¬ tá»‘t quÃ¡ áº¡.",#TensorflowLite	#NNAPI	#MOBILE	#GPU,,,,
"Machine Reasoning, Video Understanding, and Human Activity Recognition are super interesting, super hot research topics in AI right now.
https://paperswithcode.com/area/reasoning
https://paperswithcode.com/task/video-understanding
https://paperswithcode.com/task/activity-recognition
And prof. Vuong Le at Deakin Uni is an expert in these topics https://vuongle2.github.io
CÃ¡c báº¡n tráº» nhá»› Ä‘Äƒng kÃ½ theo link bÃªn dÆ°á»›i vÃ  book lá»‹ch: 17h00 Thá»© 5 ngÃ y 13/5/2021 Ä‘á»ƒ nghe giÃ¡o sÆ° chia sáº».
BK.AI: lÃ m Æ¡n giÃºp puplic live stream cho cá»™ng Ä‘á»“ng Ä‘c theo dÃµi, xin cáº£m Æ¡n!
https://www.facebook.com/109718987882944/posts/128407072680802/
#AI4VN #DeepReasoning #VisualUnderstanding #ActivityRecognition","Machine Reasoning, Video Understanding, and Human Activity Recognition are super interesting, super hot research topics in AI right now. https://paperswithcode.com/area/reasoning https://paperswithcode.com/task/video-understanding https://paperswithcode.com/task/activity-recognition And prof. Vuong Le at Deakin Uni is an expert in these topics https://vuongle2.github.io CÃ¡c báº¡n tráº» nhá»› Ä‘Äƒng kÃ½ theo link bÃªn dÆ°á»›i vÃ  book lá»‹ch: 17h00 Thá»© 5 ngÃ y 13/5/2021 Ä‘á»ƒ nghe giÃ¡o sÆ° chia sáº». BK.AI: lÃ m Æ¡n giÃºp puplic live stream cho cá»™ng Ä‘á»“ng Ä‘c theo dÃµi, xin cáº£m Æ¡n! https://www.facebook.com/109718987882944/posts/128407072680802/",#AI4VN	#DeepReasoning	#VisualUnderstanding	#ActivityRecognition,,,,
Xá»­ lÃ½ dá»¯ liá»‡u trÃªn pandas,Xá»­ lÃ½ dá»¯ liá»‡u trÃªn pandas,,,,,
"[HELP][LÃ€M SAO NHáº¬N DIá»†N ÄÆ¯á»¢C NHá»®NG TÃŠN Báº¤T THÆ¯á»œNG Tá»ª Táº¬P Dá»® LIá»†U]
Em chÃ o anh/chá»‹, hiá»‡n táº¡i em Ä‘ang lÃ m má»™t bÃ i toÃ¡n lÃ  lÃ m sao nháº­n diá»‡n Ä‘Æ°á»£c Ä‘Ã¢u lÃ  cá»¥m tÃªn báº¥t thÆ°á»ng.
Input: hÆ¡n 20 triá»‡u tÃªn Ä‘áº·t cho tÃ i khoáº£n cÃ¡ nhÃ¢n (vÃ­ dá»¥ tÃ i khoáº£n cá»§a em lÃ  Binh Le, vÃ  sáº½ cÃ³ nhá»¯ng tÃªn tÃ i khoáº£n cÃ³ dáº¡ng báº¥t ká»³ nhÆ° aemiiDaniela, 706807470KhanhTuanPhatTonHai, yq243tc9 thÃ¬ 3 tÃªn cuá»‘i cÃ¹ng Ä‘Æ°á»£c xem lÃ  báº¥t thÆ°á»ng vÃ  tÃªn bÃ¬nh thÆ°á»ng cÃ³ thá»ƒ lÃ  Há»“ng Hoa, NguyÃªn HÃ , Huy Nguyá»…n)
Output: PhÃ¢n ra Ä‘Æ°á»£c cá»¥m dá»¯ liá»‡u tÃªn vÃ  xÃ¡c Ä‘á»‹nh Ä‘Ã¢u lÃ  cá»¥m tÃªn báº¥t thÆ°á»ng
Hy vá»ng Ä‘Æ°á»£c anh/chá»‹ chia sáº» kinh nghiá»‡m hoáº·c hÆ°á»›ng Ä‘i Ä‘á»ƒ giáº£i quyáº¿t tá»‘t bÃ i toÃ¡n áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","[HELP][LÃ€M SAO NHáº¬N DIá»†N ÄÆ¯á»¢C NHá»®NG TÃŠN Báº¤T THÆ¯á»œNG Tá»ª Táº¬P Dá»® LIá»†U] Em chÃ o anh/chá»‹, hiá»‡n táº¡i em Ä‘ang lÃ m má»™t bÃ i toÃ¡n lÃ  lÃ m sao nháº­n diá»‡n Ä‘Æ°á»£c Ä‘Ã¢u lÃ  cá»¥m tÃªn báº¥t thÆ°á»ng. Input: hÆ¡n 20 triá»‡u tÃªn Ä‘áº·t cho tÃ i khoáº£n cÃ¡ nhÃ¢n (vÃ­ dá»¥ tÃ i khoáº£n cá»§a em lÃ  Binh Le, vÃ  sáº½ cÃ³ nhá»¯ng tÃªn tÃ i khoáº£n cÃ³ dáº¡ng báº¥t ká»³ nhÆ° aemiiDaniela, 706807470KhanhTuanPhatTonHai, yq243tc9 thÃ¬ 3 tÃªn cuá»‘i cÃ¹ng Ä‘Æ°á»£c xem lÃ  báº¥t thÆ°á»ng vÃ  tÃªn bÃ¬nh thÆ°á»ng cÃ³ thá»ƒ lÃ  Há»“ng Hoa, NguyÃªn HÃ , Huy Nguyá»…n) Output: PhÃ¢n ra Ä‘Æ°á»£c cá»¥m dá»¯ liá»‡u tÃªn vÃ  xÃ¡c Ä‘á»‹nh Ä‘Ã¢u lÃ  cá»¥m tÃªn báº¥t thÆ°á»ng Hy vá»ng Ä‘Æ°á»£c anh/chá»‹ chia sáº» kinh nghiá»‡m hoáº·c hÆ°á»›ng Ä‘i Ä‘á»ƒ giáº£i quyáº¿t tá»‘t bÃ i toÃ¡n áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"App nÃ y team mÃ¬nh dÃ¹ng U2NET Ä‘á»ƒ tÃ¡ch ná»n.
Má»i ngÆ°á»i tháº¥y cÃ²n cÃ³ model nÃ o á»•n hÆ¡n thÃ¬ gá»£i Ã½ giÃºp bá»n mÃ¬nh vá»›i áº¡.
Cáº£m Æ¡n cáº£ nhÃ  nhiá»u áº¡!",App nÃ y team mÃ¬nh dÃ¹ng U2NET Ä‘á»ƒ tÃ¡ch ná»n. Má»i ngÆ°á»i tháº¥y cÃ²n cÃ³ model nÃ o á»•n hÆ¡n thÃ¬ gá»£i Ã½ giÃºp bá»n mÃ¬nh vá»›i áº¡. Cáº£m Æ¡n cáº£ nhÃ  nhiá»u áº¡!,,,,,
"Vá»›i nhá»¯ng bÆ°á»›c tiáº¿n vÆ°á»£t báº­c cá»§a lÄ©nh vá»±c computer science Ä‘Ã£ giÃºp chÃºng ta giáº£i quyáº¿t Ä‘Æ°á»£c nhiá»u bÃ i toÃ¡n vá»›i dá»¯ liá»‡u dáº¡ng áº£nh, dáº¡ng ngÃ´n ngá»¯, dáº¡ng trÃ¬nh tá»± (nhÆ° trÃ¬nh tá»± DNA hay protein), dáº¡ng cáº¥u trÃºc (nhÆ° cáº¥u trÃºc báº­c 3 - 4 cá»§a phÃ¢n tá»­ protein), hay nhÆ° tÃ¬m kiáº¿m thuá»‘c má»›i (á»©ng dá»¥ng GAN vÃ  Reinforcement Learning). Tuy nhiÃªn, dá»¯ liá»‡u sinh y há»c thÆ°á»ng lÃ  cÃ¡c quan sÃ¡t Ä‘Æ¡n láº» vÃ  Ä‘Æ°á»£c ghi dÆ°á»›i dáº¡ng báº£ng (tabular) do Ä‘Ã³ ngoÃ i phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª truyá»n thá»‘ng, cho tá»›i cÃ¡c model GLM hay phÆ°Æ¡ng phÃ¡p má»›i hÆ¡n liÃªn quan tá»›i Machine Learning (vÃ­ dá»¥ XgBoost, KNN, SMV,...). Váº­y cÃ³ ai há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ á»©ng dá»¥ng Deep Learning vÃ o viá»‡c xá»­ lÃ­ dá»¯ liá»‡u dáº¡ng báº£ng nÃ y trong lÄ©nh vá»±c sinh y hay khÃ´ng???
Ráº¥t may máº¯n, chÃºng ta cÃ³ Framework PyTorch_Tabular cÃ³ thá»ƒ xá»­ lÃ­ vá»›i váº¥n Ä‘á» nÃ y! Hiá»‡n táº¡i framework nÃ y cÃ³ xÃ¢y dá»±ng sáºµn má»™t sá»‘ models nhÆ°: CategoryEmbeddingModel [1]; NODEModel [2]; TabNet [3]; AutoInt [4]; vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ tuy biáº¿n models cá»§a mÃ¬nh thÃ´ng qua thiáº¿t láº­p Configuration.
[1] https://arxiv.org/pdf/2104.13638.pdf
[2] https://arxiv.org/abs/1909.06312
[3] https://arxiv.org/pdf/1908.07442.pdf
[4] https://arxiv.org/abs/1810.11921
Source code cá»§a PyTorch_Tabular táº¡i Ä‘Ã¢y: https://github.com/manujosephv/pytorch_tabular","Vá»›i nhá»¯ng bÆ°á»›c tiáº¿n vÆ°á»£t báº­c cá»§a lÄ©nh vá»±c computer science Ä‘Ã£ giÃºp chÃºng ta giáº£i quyáº¿t Ä‘Æ°á»£c nhiá»u bÃ i toÃ¡n vá»›i dá»¯ liá»‡u dáº¡ng áº£nh, dáº¡ng ngÃ´n ngá»¯, dáº¡ng trÃ¬nh tá»± (nhÆ° trÃ¬nh tá»± DNA hay protein), dáº¡ng cáº¥u trÃºc (nhÆ° cáº¥u trÃºc báº­c 3 - 4 cá»§a phÃ¢n tá»­ protein), hay nhÆ° tÃ¬m kiáº¿m thuá»‘c má»›i (á»©ng dá»¥ng GAN vÃ  Reinforcement Learning). Tuy nhiÃªn, dá»¯ liá»‡u sinh y há»c thÆ°á»ng lÃ  cÃ¡c quan sÃ¡t Ä‘Æ¡n láº» vÃ  Ä‘Æ°á»£c ghi dÆ°á»›i dáº¡ng báº£ng (tabular) do Ä‘Ã³ ngoÃ i phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª truyá»n thá»‘ng, cho tá»›i cÃ¡c model GLM hay phÆ°Æ¡ng phÃ¡p má»›i hÆ¡n liÃªn quan tá»›i Machine Learning (vÃ­ dá»¥ XgBoost, KNN, SMV,...). Váº­y cÃ³ ai há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ á»©ng dá»¥ng Deep Learning vÃ o viá»‡c xá»­ lÃ­ dá»¯ liá»‡u dáº¡ng báº£ng nÃ y trong lÄ©nh vá»±c sinh y hay khÃ´ng??? Ráº¥t may máº¯n, chÃºng ta cÃ³ Framework PyTorch_Tabular cÃ³ thá»ƒ xá»­ lÃ­ vá»›i váº¥n Ä‘á» nÃ y! Hiá»‡n táº¡i framework nÃ y cÃ³ xÃ¢y dá»±ng sáºµn má»™t sá»‘ models nhÆ°: CategoryEmbeddingModel [1]; NODEModel [2]; TabNet [3]; AutoInt [4]; vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ tuy biáº¿n models cá»§a mÃ¬nh thÃ´ng qua thiáº¿t láº­p Configuration. [1] https://arxiv.org/pdf/2104.13638.pdf [2] https://arxiv.org/abs/1909.06312 [3] https://arxiv.org/pdf/1908.07442.pdf [4] https://arxiv.org/abs/1810.11921 Source code cá»§a PyTorch_Tabular táº¡i Ä‘Ã¢y: https://github.com/manujosephv/pytorch_tabular",,,,,
"Xin chÃ o má»i ngÆ°á»i, MÃ¬nh lÃ  new member, base cá»§a mÃ¬nh lÃ  javascript mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» computer vision cá»¥ thá»ƒ lÃ  object detection(yolov1). MÃ¬nh chá»n yolo v1 vÃ¬ nÃ³ dá»… hiá»ƒu, Ã­t khÃ¡i niá»‡m nÃ¢ng cao vÃ  tá»‘c Ä‘á»™ khÃ¡ nhanh. NgÃ´n ngá»¯/ library mÃ¬nh sá»­ dá»¥ng Ä‘á»ƒ tiáº¿p cáº­n lÃ  js/tensorflowjs. CÃ³ khÃ¡ nhiá»u bÃ i hÆ°á»›ng dáº«n vá» Yolov1 vÃ  cáº£ code demo nhÆ°ng chá»‰ trÃªn python, mÃ¬nh cÅ©ng Ä‘á»u Ä‘Ã£ xem vÃ  láº¥y Ä‘Ã³ lÃ m cÆ¡ sá»Ÿ Ä‘á»ƒ hoÃ n thiá»‡n phiÃªn báº£n trÃªn js cá»§a mÃ¬nh.
Thuáº­n lá»£i: viáº¿t trÃªn ngÃ´n ngá»¯ mÃ¬nh Ä‘Ã£ cÃ³ kinh nghiá»‡m nÃªn dá»… dÃ ng debug, tá»‘c Ä‘á»™ viáº¿t cÅ©ng nhanh hÆ¡n, hiá»ƒu nhá»¯ng gÃ¬ mÃ¬nh viáº¿t hÆ¡n.
KhÃ³ khÄƒn: Gáº·p nhiá»u váº¥n Ä‘á» má»›i khi sá»­ dá»¥ng tensorflow (convert pretrained model hay bá»‹ lá»—i, nhiá»u vÃ­ dá»¥ python khÃ³ Ã¡p dá»¥ng do khÃ¡c thÆ° viá»‡n...).
Háº§u háº¿t khÃ³ khÄƒn mÃ¬nh Ä‘Ã£ giáº£i Ä‘Æ°á»£c nhÆ°ng cÃ²n má»™t sá»‘ váº¥n Ä‘á» chÃ­nh sau Ä‘Ã¢y cáº§n nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡:
1, Há»‡ sá»‘ lambda mÃ¬nh chÆ°a biáº¿t cÃ¢n báº±ng do mÃ¬nh dÃ¹ng model cÃ³ input 512,512 vÃ  output 16x16x30(S=16) nÃªn mÃ¬nh tháº¥y lambda cho S=7 khÃ´ng phÃ¹ há»£p vá»›i mÃ´ hÃ¬nh cá»§a mÃ¬nh. Train xong Pobj bá»‹ kÃ©o xuá»‘ng gáº§n 0(mÃ¬nh Ä‘oÃ¡n lÃ  do imbalance data positive vÃ  negative). => lÃ m tháº¿ nÃ o Ä‘á»ƒ chá»n lambda náº¿u S thay Ä‘á»•i ?
2, mÃ¬nh xem má»™t sá»‘ vÃ­ dá»¥ trÃªn máº¡ng há» sá»­ dá»¥ng active function leaky relu cho output, Ä‘iá»u nÃ y khiáº¿n cÃ¡c xÃ¡c suáº¥t Pobj, Pnoobj, Pclass sáº½ cÃ³ thá»ƒ >1, tháº¿ nÃªn lÃºc mÃ¬nh show káº¿t quáº£ ra xÃ¡c xuáº¥t >1.0(tá»©c lÃ  > 100%) nhÃ¬n nÃ³ sai sai.
3, MÃ¬nh tá»± viáº¿t lossfunction theo Ã½ hiá»ƒu cá»§a mÃ¬nh dá»±a vÃ o cÃ´ng thá»©c trong paper vÃ  tham kháº£o code python trÃªn máº¡ng, má»i ngÆ°á»i review giÃºp mÃ¬nh vá»›i.
--- 1 vÃ i thÃ´ng tin bá»• sung vá» model cá»§a mÃ¬nh:
Extract feature : resnet50 (convert sang layer model js),
Input: 512,512,3 Output: 16x16x30 TrainVal: Voc2007","Xin chÃ o má»i ngÆ°á»i, MÃ¬nh lÃ  new member, base cá»§a mÃ¬nh lÃ  javascript mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» computer vision cá»¥ thá»ƒ lÃ  object detection(yolov1). MÃ¬nh chá»n yolo v1 vÃ¬ nÃ³ dá»… hiá»ƒu, Ã­t khÃ¡i niá»‡m nÃ¢ng cao vÃ  tá»‘c Ä‘á»™ khÃ¡ nhanh. NgÃ´n ngá»¯/ library mÃ¬nh sá»­ dá»¥ng Ä‘á»ƒ tiáº¿p cáº­n lÃ  js/tensorflowjs. CÃ³ khÃ¡ nhiá»u bÃ i hÆ°á»›ng dáº«n vá» Yolov1 vÃ  cáº£ code demo nhÆ°ng chá»‰ trÃªn python, mÃ¬nh cÅ©ng Ä‘á»u Ä‘Ã£ xem vÃ  láº¥y Ä‘Ã³ lÃ m cÆ¡ sá»Ÿ Ä‘á»ƒ hoÃ n thiá»‡n phiÃªn báº£n trÃªn js cá»§a mÃ¬nh. Thuáº­n lá»£i: viáº¿t trÃªn ngÃ´n ngá»¯ mÃ¬nh Ä‘Ã£ cÃ³ kinh nghiá»‡m nÃªn dá»… dÃ ng debug, tá»‘c Ä‘á»™ viáº¿t cÅ©ng nhanh hÆ¡n, hiá»ƒu nhá»¯ng gÃ¬ mÃ¬nh viáº¿t hÆ¡n. KhÃ³ khÄƒn: Gáº·p nhiá»u váº¥n Ä‘á» má»›i khi sá»­ dá»¥ng tensorflow (convert pretrained model hay bá»‹ lá»—i, nhiá»u vÃ­ dá»¥ python khÃ³ Ã¡p dá»¥ng do khÃ¡c thÆ° viá»‡n...). Háº§u háº¿t khÃ³ khÄƒn mÃ¬nh Ä‘Ã£ giáº£i Ä‘Æ°á»£c nhÆ°ng cÃ²n má»™t sá»‘ váº¥n Ä‘á» chÃ­nh sau Ä‘Ã¢y cáº§n nhá» má»i ngÆ°á»i giÃºp Ä‘á»¡: 1, Há»‡ sá»‘ lambda mÃ¬nh chÆ°a biáº¿t cÃ¢n báº±ng do mÃ¬nh dÃ¹ng model cÃ³ input 512,512 vÃ  output 16x16x30(S=16) nÃªn mÃ¬nh tháº¥y lambda cho S=7 khÃ´ng phÃ¹ há»£p vá»›i mÃ´ hÃ¬nh cá»§a mÃ¬nh. Train xong Pobj bá»‹ kÃ©o xuá»‘ng gáº§n 0(mÃ¬nh Ä‘oÃ¡n lÃ  do imbalance data positive vÃ  negative). => lÃ m tháº¿ nÃ o Ä‘á»ƒ chá»n lambda náº¿u S thay Ä‘á»•i ? 2, mÃ¬nh xem má»™t sá»‘ vÃ­ dá»¥ trÃªn máº¡ng há» sá»­ dá»¥ng active function leaky relu cho output, Ä‘iá»u nÃ y khiáº¿n cÃ¡c xÃ¡c suáº¥t Pobj, Pnoobj, Pclass sáº½ cÃ³ thá»ƒ >1, tháº¿ nÃªn lÃºc mÃ¬nh show káº¿t quáº£ ra xÃ¡c xuáº¥t >1.0(tá»©c lÃ  > 100%) nhÃ¬n nÃ³ sai sai. 3, MÃ¬nh tá»± viáº¿t lossfunction theo Ã½ hiá»ƒu cá»§a mÃ¬nh dá»±a vÃ o cÃ´ng thá»©c trong paper vÃ  tham kháº£o code python trÃªn máº¡ng, má»i ngÆ°á»i review giÃºp mÃ¬nh vá»›i. --- 1 vÃ i thÃ´ng tin bá»• sung vá» model cá»§a mÃ¬nh: Extract feature : resnet50 (convert sang layer model js), Input: 512,512,3 Output: 16x16x30 TrainVal: Voc2007",,,,,
"Tá»‰ lá»‡ máº¯c bá»‡nh Ä‘Ã¡i thÃ¡o Ä‘Æ°á»ng ngÃ y má»™t tÄƒng cao, Æ°á»›c tÃ­nh cso 442 triá»‡u ngÆ°á»i máº¯c trÃªn toÃ n Tháº¿ giá»›i vÃ o nÄƒm 2014 [1]. ÄÃ¡i thÃ¡o Ä‘Æ°á»ng lÃ  nguyÃªn nhÃ¢n suy tháº­n, tá»•n thÆ°Æ¡ng tháº§n kinh vÃ  tá»•n thÆ°Æ¡ng Ä‘Ã¡y máº¯t.
BÃªn cáº¡nh Ä‘Ã³, viá»‡c phÃ¡t hiá»‡n sá»›m vÃ  Ä‘iá»u trá»‹ ká»‹p thá»i cÃ³ thá»ƒ ngÄƒn thoÃ¡i hÃ³a Ä‘iá»ƒm vÃ ng dáº«n tá»›i mÃ¹ lÃ²a á»Ÿ ngÆ°á»i cao tuá»•i
Äá» phÃ¡t hiá»‡n cÃ¡c bá»‡nh nÃ y, kÄ© thuáº­t chá»¥p áº£nh optical coherence tomography (OCT) thÆ°á»ng xuyÃªn Ä‘Æ°á»£c sá»­ dá»¥ng trong ngÃ nh nhÃ£n khoa [2]. Vá» cÆ¡ báº£n, cÃ¡c áº£nh OCT nÃ y Ä‘Æ°á»£c phÃ¢n loáº¡i vÃ o 4 lá»›p lÃ  choroidal neovascularization (CNV), DME, drusen, vÃ  bÃ¬nh thÆ°á»ng.
Viá»‡c á»©ng dá»¥ng Deep Learning vÃ o viá»‡c há»— trá»£ bÃ¡c sÄ© phÃ¢n loáº¡i áº£nh OCT nÃ y sáº½ cÃ³ Ã½ nghÄ©a quan trá»ng trong bá»‘i cáº£nh nÆ°á»›c ta khi tá»‰ lá»‡ giÃ  hÃ³a cá»§a dÃ¢n sá»‘ diá»…n ra nhanh, tá»‰ lá»‡ bá»‡nh nhÃ¢n máº¯c Ä‘Ã¡i thÃ¡o Ä‘Æ°á»ng tÄƒng cao, vÃ  Ä‘áº·c biá»‡t lÃ  tÃ¬nh tráº¡ng thiáº¿u bÃ¡c sÄ© Ä‘Æ°á»£c Ä‘Ã o táº¡o chuyÃªn sÃ¢u. ChÃ­nh vÃ¬ váº­y, tÃ´i nghÄ© Viá»‡t Nam nÃªn Ä‘áº§u tÆ° máº¡nh máº½ vÃ o nghiÃªn cá»©u vÃ  á»©ng dá»¥ng DL trong nhiá»u lÄ©nh vá»±c cá»§a cuá»™c sá»‘ng cÅ©ng nhÆ° y há»c.
Káº¿t quáº£ nÃ y cá»§a tÃ´i vÆ°á»£t xa káº¿t quáº£ bÃ i bÃ¡o gá»‘c Ä‘Äƒng trÃªn táº¡p chÃ­ chuyÃªn ngÃ nh ráº¥t ráº¥t Ä‘á»‰nh lÃ  Cell. Theo nhÆ° káº¿t quáº£ Ä‘á»‘i chá»©ng vá»›i cÃ¡c bÃ¡c sÄ© chuyÃªn khoa giÃ u kinh nghiá»‡m thÃ¬ káº¿t quáº£ cá»§a chÃºng tÃ´i vÆ°á»£t qua 5/6 chuyÃªn gia. CÃ³ 1 chuyÃªn gia cháº©n Ä‘oÃ¡n tá»‘t hÆ¡n káº¿t quáº£ nÃ y, bÃ¡c sÄ© nÃ y sai 3 áº£nh trÃªn tá»•ng 1000 áº£nh. CÃ²n nhÆ° confusion matrix cá»§a tÃ´i, cÃ¡c báº¡n tháº¥y model dá»± bÃ¡o sai 6 áº£nh/1000 áº£nh cá»§a táº­p test set.
Tuy nhiÃªn, Ä‘Ã¢y lÃ  thÃ­ nghiá»‡m nhanh (chÆ°a finetune) nÃªn tÃ´i tin, káº¿t quáº£ cá»§a mÃ¬nh sáº½ cÃ²n cáº£i thiá»‡n náº¿u finetune Ä‘á»§ tá»‘t!!!!
BÃ i bÃ¡o gá»‘c Ä‘Äƒng trong top-tier chuyÃªn ngÃ nh táº¡i Ä‘Ã¢y:https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5
Dá»¯ liá»‡u táº¡i Ä‘Ã¢y: Data: https://data.mendeley.com/datasets/rscbjbr9sj/2 hoáº·c https://www.kaggle.com/paultimothymooney/kermany2018
[1] Chan M. Global report on diabetes. World Health Organ. 2014;58:1â€“88.
https://doi.org/10.1128/AAC.03728-14.
[2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7082944/pdf/12886_2020_Article_1382.pdf
Ps. Do khÃ´ng cÃ³ nhiá»u kiáº¿n thá»©c vá» nhÃ£n khoa nÃªn tÃ´i khÃ´ng dÃ¡m dá»‹ch má»™t sá»‘ thuáº­t ngá»¯ chuyÃªn ngÃ nh, mong cÃ¡c báº¡n thÃ´ng cáº£m!","Tá»‰ lá»‡ máº¯c bá»‡nh Ä‘Ã¡i thÃ¡o Ä‘Æ°á»ng ngÃ y má»™t tÄƒng cao, Æ°á»›c tÃ­nh cso 442 triá»‡u ngÆ°á»i máº¯c trÃªn toÃ n Tháº¿ giá»›i vÃ o nÄƒm 2014 [1]. ÄÃ¡i thÃ¡o Ä‘Æ°á»ng lÃ  nguyÃªn nhÃ¢n suy tháº­n, tá»•n thÆ°Æ¡ng tháº§n kinh vÃ  tá»•n thÆ°Æ¡ng Ä‘Ã¡y máº¯t. BÃªn cáº¡nh Ä‘Ã³, viá»‡c phÃ¡t hiá»‡n sá»›m vÃ  Ä‘iá»u trá»‹ ká»‹p thá»i cÃ³ thá»ƒ ngÄƒn thoÃ¡i hÃ³a Ä‘iá»ƒm vÃ ng dáº«n tá»›i mÃ¹ lÃ²a á»Ÿ ngÆ°á»i cao tuá»•i Äá» phÃ¡t hiá»‡n cÃ¡c bá»‡nh nÃ y, kÄ© thuáº­t chá»¥p áº£nh optical coherence tomography (OCT) thÆ°á»ng xuyÃªn Ä‘Æ°á»£c sá»­ dá»¥ng trong ngÃ nh nhÃ£n khoa [2]. Vá» cÆ¡ báº£n, cÃ¡c áº£nh OCT nÃ y Ä‘Æ°á»£c phÃ¢n loáº¡i vÃ o 4 lá»›p lÃ  choroidal neovascularization (CNV), DME, drusen, vÃ  bÃ¬nh thÆ°á»ng. Viá»‡c á»©ng dá»¥ng Deep Learning vÃ o viá»‡c há»— trá»£ bÃ¡c sÄ© phÃ¢n loáº¡i áº£nh OCT nÃ y sáº½ cÃ³ Ã½ nghÄ©a quan trá»ng trong bá»‘i cáº£nh nÆ°á»›c ta khi tá»‰ lá»‡ giÃ  hÃ³a cá»§a dÃ¢n sá»‘ diá»…n ra nhanh, tá»‰ lá»‡ bá»‡nh nhÃ¢n máº¯c Ä‘Ã¡i thÃ¡o Ä‘Æ°á»ng tÄƒng cao, vÃ  Ä‘áº·c biá»‡t lÃ  tÃ¬nh tráº¡ng thiáº¿u bÃ¡c sÄ© Ä‘Æ°á»£c Ä‘Ã o táº¡o chuyÃªn sÃ¢u. ChÃ­nh vÃ¬ váº­y, tÃ´i nghÄ© Viá»‡t Nam nÃªn Ä‘áº§u tÆ° máº¡nh máº½ vÃ o nghiÃªn cá»©u vÃ  á»©ng dá»¥ng DL trong nhiá»u lÄ©nh vá»±c cá»§a cuá»™c sá»‘ng cÅ©ng nhÆ° y há»c. Káº¿t quáº£ nÃ y cá»§a tÃ´i vÆ°á»£t xa káº¿t quáº£ bÃ i bÃ¡o gá»‘c Ä‘Äƒng trÃªn táº¡p chÃ­ chuyÃªn ngÃ nh ráº¥t ráº¥t Ä‘á»‰nh lÃ  Cell. Theo nhÆ° káº¿t quáº£ Ä‘á»‘i chá»©ng vá»›i cÃ¡c bÃ¡c sÄ© chuyÃªn khoa giÃ u kinh nghiá»‡m thÃ¬ káº¿t quáº£ cá»§a chÃºng tÃ´i vÆ°á»£t qua 5/6 chuyÃªn gia. CÃ³ 1 chuyÃªn gia cháº©n Ä‘oÃ¡n tá»‘t hÆ¡n káº¿t quáº£ nÃ y, bÃ¡c sÄ© nÃ y sai 3 áº£nh trÃªn tá»•ng 1000 áº£nh. CÃ²n nhÆ° confusion matrix cá»§a tÃ´i, cÃ¡c báº¡n tháº¥y model dá»± bÃ¡o sai 6 áº£nh/1000 áº£nh cá»§a táº­p test set. Tuy nhiÃªn, Ä‘Ã¢y lÃ  thÃ­ nghiá»‡m nhanh (chÆ°a finetune) nÃªn tÃ´i tin, káº¿t quáº£ cá»§a mÃ¬nh sáº½ cÃ²n cáº£i thiá»‡n náº¿u finetune Ä‘á»§ tá»‘t!!!! BÃ i bÃ¡o gá»‘c Ä‘Äƒng trong top-tier chuyÃªn ngÃ nh táº¡i Ä‘Ã¢y:https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5 Dá»¯ liá»‡u táº¡i Ä‘Ã¢y: Data: https://data.mendeley.com/datasets/rscbjbr9sj/2 hoáº·c https://www.kaggle.com/paultimothymooney/kermany2018 [1] Chan M. Global report on diabetes. World Health Organ. 2014;58:1â€“88. https://doi.org/10.1128/AAC.03728-14. [2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7082944/pdf/12886_2020_Article_1382.pdf Ps. Do khÃ´ng cÃ³ nhiá»u kiáº¿n thá»©c vá» nhÃ£n khoa nÃªn tÃ´i khÃ´ng dÃ¡m dá»‹ch má»™t sá»‘ thuáº­t ngá»¯ chuyÃªn ngÃ nh, mong cÃ¡c báº¡n thÃ´ng cáº£m!",,,,,
Hi Má»i NgÆ°á»i. Em Ä‘ang cáº§n build bá»™ PC há»c machine learning. Táº§m 30tr. KhÃ´ng biáº¿t cÃ³ ai cÃ³ thá»ƒ tÆ° váº¥n giÃºp Em Ä‘Æ°á»£c khÃ´ng áº¡?,Hi Má»i NgÆ°á»i. Em Ä‘ang cáº§n build bá»™ PC há»c machine learning. Táº§m 30tr. KhÃ´ng biáº¿t cÃ³ ai cÃ³ thá»ƒ tÆ° váº¥n giÃºp Em Ä‘Æ°á»£c khÃ´ng áº¡?,,,,,
"Xin phÃ©p admin
Sau thá»i má»™t thá»i gian ""máº¥t tÃ­ch"", hÃ´m nay má»›i lÃ m Ä‘k má»™t video vá» Há»† THá»NG Gá»¢I Ã (Recommender System) vÃ  Ä‘Ã£ Up lÃªn Youtube cho ae xem. Hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n Ä‘ang nghiÃªn cá»©u vá» nÃ³!
- QuÃªn lÃ  cÃ²n nhiá»u video khÃ¡c vá» má»™t sá»‘ bÃ i hÆ°á»›ng dáº«n vá» AI, ae chÆ°a xem cÃ³ thá»ƒ tÃ¬m xem trong má»¥c video biáº¿t Ä‘Ã¢u cÃ³ má»¥c ae cáº§n
- Mong Ä‘Æ°á»£c cÃ¡c cao nhÃ¢n thÃ´ng tháº¡o cÃ¡c thá»© chá»‰ báº£o thÃªm áº¡!
https://www.youtube.com/watch?v=HFsgbLLAVq0","Xin phÃ©p admin Sau thá»i má»™t thá»i gian ""máº¥t tÃ­ch"", hÃ´m nay má»›i lÃ m Ä‘k má»™t video vá» Há»† THá»NG Gá»¢I Ã (Recommender System) vÃ  Ä‘Ã£ Up lÃªn Youtube cho ae xem. Hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n Ä‘ang nghiÃªn cá»©u vá» nÃ³! - QuÃªn lÃ  cÃ²n nhiá»u video khÃ¡c vá» má»™t sá»‘ bÃ i hÆ°á»›ng dáº«n vá» AI, ae chÆ°a xem cÃ³ thá»ƒ tÃ¬m xem trong má»¥c video biáº¿t Ä‘Ã¢u cÃ³ má»¥c ae cáº§n - Mong Ä‘Æ°á»£c cÃ¡c cao nhÃ¢n thÃ´ng tháº¡o cÃ¡c thá»© chá»‰ báº£o thÃªm áº¡! https://www.youtube.com/watch?v=HFsgbLLAVq0",,,,,
,nan,,,,,
"[AI News â€“ GAN Application]
StyleMapGAN: Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing ( CVPR 21)
StyleMapGAN Ä‘á» xuáº¥t má»™t biá»ƒu diá»…n má»›i cá»§a khÃ´ng gian áº©n dá»±a trÃªn stylemap. Ã tÆ°á»Ÿng lÃ  thay vÃ¬ há»c cÃ¡ch biá»ƒu diá»…n áº©n dá»±a trÃªn vectÆ¡, StyleMapGAN sá»­ dá»¥ng má»™t tensor vá»›i cÃ¡c kÃ­ch thÆ°á»›c khÃ´ng gian rÃµ rÃ ng. Khi Ä‘Ã³, biá»ƒu diá»…n nÃ y Ä‘Æ°á»£c sáº½ chá»©a thÃ´ng tin tá»« cÃ¡c kÃ­ch thÆ°á»›c khÃ´ng gian Ä‘Ã³, do váº­y GAN dá»… dÃ ng encode Ä‘áº·c trÆ°ng cá»¥c bá»™ cá»§a hÃ¬nh áº£nh vÃ o khÃ´ng gian áº©n.
PhÆ°Æ¡ng phÃ¡p nÃ y cho phÃ©p chá»‰nh sá»­a cÃ¡c vÃ¹ng cá»¥ thá»ƒ cá»§a hÃ¬nh áº£nh. Äáº·c biá»‡t, táº¥t cáº£ chá»‰nh sá»­a Ä‘Æ°á»£c thá»±c hiá»‡n trong thá»i gian thá»±c.","[AI News â€“ GAN Application] StyleMapGAN: Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing ( CVPR 21) StyleMapGAN Ä‘á» xuáº¥t má»™t biá»ƒu diá»…n má»›i cá»§a khÃ´ng gian áº©n dá»±a trÃªn stylemap. Ã tÆ°á»Ÿng lÃ  thay vÃ¬ há»c cÃ¡ch biá»ƒu diá»…n áº©n dá»±a trÃªn vectÆ¡, StyleMapGAN sá»­ dá»¥ng má»™t tensor vá»›i cÃ¡c kÃ­ch thÆ°á»›c khÃ´ng gian rÃµ rÃ ng. Khi Ä‘Ã³, biá»ƒu diá»…n nÃ y Ä‘Æ°á»£c sáº½ chá»©a thÃ´ng tin tá»« cÃ¡c kÃ­ch thÆ°á»›c khÃ´ng gian Ä‘Ã³, do váº­y GAN dá»… dÃ ng encode Ä‘áº·c trÆ°ng cá»¥c bá»™ cá»§a hÃ¬nh áº£nh vÃ o khÃ´ng gian áº©n. PhÆ°Æ¡ng phÃ¡p nÃ y cho phÃ©p chá»‰nh sá»­a cÃ¡c vÃ¹ng cá»¥ thá»ƒ cá»§a hÃ¬nh áº£nh. Äáº·c biá»‡t, táº¥t cáº£ chá»‰nh sá»­a Ä‘Æ°á»£c thá»±c hiá»‡n trong thá»i gian thá»±c.",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n em má»›i Ä‘ang tÃ¬m hiá»ƒu vá» CNN unet Ä‘á»ƒ phÃ¢n Ä‘oáº¡n áº£nh CT phá»•i, thÃ¬ hiá»‡n táº¡i em Ä‘ang tÃ¬m data, thÃ¬ bá»‹ vÆ°á»›ng nhÆ° chá»‰ tháº¥y data kiá»ƒu nÃ y. áº¢nh input file tif nÃ³ bá»‹ thÃ nh tháº¿ kia mÃ  ko pháº£i áº£nh gá»‘c khi chá»¥p áº¡, khÃ´ng biáº¿t lÃ  mÃ¡y má»Ÿ tif bá»‹ tháº¿ hay lÃ  data train sáºµn tháº¿ áº¡. Mong mn giÃºp Ä‘á»¡ áº¡, em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i áº¡, hiá»‡n em má»›i Ä‘ang tÃ¬m hiá»ƒu vá» CNN unet Ä‘á»ƒ phÃ¢n Ä‘oáº¡n áº£nh CT phá»•i, thÃ¬ hiá»‡n táº¡i em Ä‘ang tÃ¬m data, thÃ¬ bá»‹ vÆ°á»›ng nhÆ° chá»‰ tháº¥y data kiá»ƒu nÃ y. áº¢nh input file tif nÃ³ bá»‹ thÃ nh tháº¿ kia mÃ  ko pháº£i áº£nh gá»‘c khi chá»¥p áº¡, khÃ´ng biáº¿t lÃ  mÃ¡y má»Ÿ tif bá»‹ tháº¿ hay lÃ  data train sáºµn tháº¿ áº¡. Mong mn giÃºp Ä‘á»¡ áº¡, em cáº£m Æ¡n áº¡.",,,,,
"[HELP][Feature Engineering Ä‘á»‘i vá»›i dá»¯ liá»‡u dáº¡ng text cho Tiáº¿ng Viá»‡t]
Em chÃ o anh chá»‹,
KhÃ´ng biáº¿t anh chá»‹ nÃ o cÃ³ kinh nghiá»‡m lÃ m feature engineering Ä‘á»‘i vá»›i dá»¯ liá»‡u vá» name, status, feed (dá»¯ liá»‡u dáº¡ng text) chÆ°a áº¡.
Dá»¯ liá»‡u name cá»§a em thÆ°á»ng cÃ³ dáº¡ng nhÆ° khÃ´ng viáº¿t hoa, má»™t chuá»—i kÃ½ tá»± báº¥t ká»³, tÃªn má»™t chá»¯, hoáº·c lÃ  tÃªn tiáº¿ng viá»‡t (vÃ­ dá»¥: Abcdefghik, E, bi kha, Äan Äan,... vÃ  cÃ²n nhiá»u dáº¡ng ná»¯a)
CÃ²n dá»¯ liá»‡u status, feed thÃ¬ giá»‘ng nhÆ° trÃªn Facebook, feed thÃ¬ thÆ°á»ng cÃ³ text hoáº·c cÃ³ cáº£ text vÃ  hÃ¬nh, status lÃ  má»™t Ä‘oáº¡n text ngáº¯n
Hy vá»ng Ä‘Æ°á»£c anh chá»‹ chia sáº» kinh nghiá»‡m áº¡, em cáº£m Æ¡n ráº¥t nhiá»u vÃ  chÃºc má»i ngÆ°á»i ngÃ y má»›i lÃ m viá»‡c tháº­t hiá»‡u quáº£ áº¡.","[HELP][Feature Engineering Ä‘á»‘i vá»›i dá»¯ liá»‡u dáº¡ng text cho Tiáº¿ng Viá»‡t] Em chÃ o anh chá»‹, KhÃ´ng biáº¿t anh chá»‹ nÃ o cÃ³ kinh nghiá»‡m lÃ m feature engineering Ä‘á»‘i vá»›i dá»¯ liá»‡u vá» name, status, feed (dá»¯ liá»‡u dáº¡ng text) chÆ°a áº¡. Dá»¯ liá»‡u name cá»§a em thÆ°á»ng cÃ³ dáº¡ng nhÆ° khÃ´ng viáº¿t hoa, má»™t chuá»—i kÃ½ tá»± báº¥t ká»³, tÃªn má»™t chá»¯, hoáº·c lÃ  tÃªn tiáº¿ng viá»‡t (vÃ­ dá»¥: Abcdefghik, E, bi kha, Äan Äan,... vÃ  cÃ²n nhiá»u dáº¡ng ná»¯a) CÃ²n dá»¯ liá»‡u status, feed thÃ¬ giá»‘ng nhÆ° trÃªn Facebook, feed thÃ¬ thÆ°á»ng cÃ³ text hoáº·c cÃ³ cáº£ text vÃ  hÃ¬nh, status lÃ  má»™t Ä‘oáº¡n text ngáº¯n Hy vá»ng Ä‘Æ°á»£c anh chá»‹ chia sáº» kinh nghiá»‡m áº¡, em cáº£m Æ¡n ráº¥t nhiá»u vÃ  chÃºc má»i ngÆ°á»i ngÃ y má»›i lÃ m viá»‡c tháº­t hiá»‡u quáº£ áº¡.",,,,,
"Lego generator
Source code: https://github.com/uvipen/Lego-generator
Demo: https://youtu.be/uz8A1pq8CAw
ÄÃ¢y lÃ  mini project cá»§a mÃ¬nh á»©ng dá»¥ng Computer Vision Ä‘á»ƒ convert áº£nh hoáº·c video báº¥t kÃ¬ thÃ nh output Ä‘Æ°á»£c táº¡o thÃ nh bá»Ÿi cÃ¡c khá»‘i lego. Code cá»§a mÃ¬nh ráº¥t ngáº¯n vÃ  Ä‘Æ¡n giáº£n. Mong Ä‘Æ°á»£c nháº­n gÃ³p Ã½ tá»« má»i ngÆ°á»i. MÃ¬nh xin cáº£m Æ¡n",Lego generator Source code: https://github.com/uvipen/Lego-generator Demo: https://youtu.be/uz8A1pq8CAw ÄÃ¢y lÃ  mini project cá»§a mÃ¬nh á»©ng dá»¥ng Computer Vision Ä‘á»ƒ convert áº£nh hoáº·c video báº¥t kÃ¬ thÃ nh output Ä‘Æ°á»£c táº¡o thÃ nh bá»Ÿi cÃ¡c khá»‘i lego. Code cá»§a mÃ¬nh ráº¥t ngáº¯n vÃ  Ä‘Æ¡n giáº£n. Mong Ä‘Æ°á»£c nháº­n gÃ³p Ã½ tá»« má»i ngÆ°á»i. MÃ¬nh xin cáº£m Æ¡n,,,,,
#python #datatype,,#python	#datatype,,,,
"[AI Share - Interview]
Báº¡n lÃ  ngÆ°á»i má»›i báº¯t Ä‘áº§u hay lÃ  má»™t chuyÃªn gia Ä‘ang tÃ¬m kiáº¿m con Ä‘Æ°á»ng Ä‘á»ƒ trá»Ÿ thÃ nh Data Scientist?
HÃ£y theo dÃµi series 30 ngÃ y chuáº©n bá»‹ cÃ¡c cÃ¢u há»i Ä‘á»ƒ phá»ng váº¥n Data Science.
Repos nÃ y chá»©a 30 file tÆ°Æ¡ng á»©ng vá»›i 30 ngÃ y Ã´n táº­p. Má»—i file sáº½ cÃ³ má»™t bá»™ cÃ¢u há»i riÃªng nhÃ© ^^.
Má»i ngÆ°á»i táº£i vá» vÃ  Ã´n táº­p á»Ÿ Ä‘Ã¢y nhÃ©:
https://github.com/iNeuronai/interview-question-data-science-",[AI Share - Interview] Báº¡n lÃ  ngÆ°á»i má»›i báº¯t Ä‘áº§u hay lÃ  má»™t chuyÃªn gia Ä‘ang tÃ¬m kiáº¿m con Ä‘Æ°á»ng Ä‘á»ƒ trá»Ÿ thÃ nh Data Scientist? HÃ£y theo dÃµi series 30 ngÃ y chuáº©n bá»‹ cÃ¡c cÃ¢u há»i Ä‘á»ƒ phá»ng váº¥n Data Science. Repos nÃ y chá»©a 30 file tÆ°Æ¡ng á»©ng vá»›i 30 ngÃ y Ã´n táº­p. Má»—i file sáº½ cÃ³ má»™t bá»™ cÃ¢u há»i riÃªng nhÃ© ^^. Má»i ngÆ°á»i táº£i vá» vÃ  Ã´n táº­p á»Ÿ Ä‘Ã¢y nhÃ©: https://github.com/iNeuronai/interview-question-data-science-,,,,,
"Cho mÃ¬nh há»i vÃ i Ã½ nha má»i ngÆ°á»i.
MÃ¬nh Ä‘ang lÃ m recommendation system cho 1 trang E-C, trong lÃºc lÃ m cÃ³ xáº£y ra trÆ°á»ng há»£p lÃ  náº¿u ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Äƒng nháº­p, tá»©c Ä‘Ã£ cÃ³ thÃ´ng tin ngÆ°á»i dÃ¹ng thÃ¬ sáº½ dÃ¹ng lá»c cá»™ng tÃ¡c Ä‘á»ƒ recommend sp cho ngÆ°á»i dÃ¹ng nÃ y. Tuy nhiÃªn náº¿u ngÆ°Æ¡i dÃ¹ng má»›i táº¡o tÃ i khoáº£n, tá»©c lÃ  trÆ°á»›c Ä‘Ã¢y chÆ°a tá»«ng xem sáº£n pháº©m nÃ o cáº£ thÃ¬ mÃ¬nh sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘á»ƒ gá»£i Ã½ háº£ má»i ngÆ°á»i?
Vá»›i láº¡i náº¿u ngÆ°á»i dÃ¹ng khÃ´ng Ä‘Äƒng nháº­p thÃ¬ ta cÃ³ thá»ƒ recommend báº±ng nhá»¯ng sp cÃ³ sá»‘ lÆ°á»£t xem nhiá»u nháº¥t, tuy nhiÃªn nÃ³ khÃ´ng dÃ­nh gÃ¬ tá»›i ML, váº­y Ä‘á»ƒ cÃ³ thá»ƒ dÃ¹ng thuáº­t toÃ¡n ML thÃ¬ ta sáº½ gá»£i Ã½ theo cÃ¡ch nÃ o giá» má»i ngÆ°á»i Æ¡i?
CÃ³ gÃ¬ giÃºp mÃ¬nh vá»›i, :(((.","Cho mÃ¬nh há»i vÃ i Ã½ nha má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m recommendation system cho 1 trang E-C, trong lÃºc lÃ m cÃ³ xáº£y ra trÆ°á»ng há»£p lÃ  náº¿u ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Äƒng nháº­p, tá»©c Ä‘Ã£ cÃ³ thÃ´ng tin ngÆ°á»i dÃ¹ng thÃ¬ sáº½ dÃ¹ng lá»c cá»™ng tÃ¡c Ä‘á»ƒ recommend sp cho ngÆ°á»i dÃ¹ng nÃ y. Tuy nhiÃªn náº¿u ngÆ°Æ¡i dÃ¹ng má»›i táº¡o tÃ i khoáº£n, tá»©c lÃ  trÆ°á»›c Ä‘Ã¢y chÆ°a tá»«ng xem sáº£n pháº©m nÃ o cáº£ thÃ¬ mÃ¬nh sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘á»ƒ gá»£i Ã½ háº£ má»i ngÆ°á»i? Vá»›i láº¡i náº¿u ngÆ°á»i dÃ¹ng khÃ´ng Ä‘Äƒng nháº­p thÃ¬ ta cÃ³ thá»ƒ recommend báº±ng nhá»¯ng sp cÃ³ sá»‘ lÆ°á»£t xem nhiá»u nháº¥t, tuy nhiÃªn nÃ³ khÃ´ng dÃ­nh gÃ¬ tá»›i ML, váº­y Ä‘á»ƒ cÃ³ thá»ƒ dÃ¹ng thuáº­t toÃ¡n ML thÃ¬ ta sáº½ gá»£i Ã½ theo cÃ¡ch nÃ o giá» má»i ngÆ°á»i Æ¡i? CÃ³ gÃ¬ giÃºp mÃ¬nh vá»›i, :(((.",,,,,
"Hello má»i ngÆ°á»i, em má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» ML Ä‘Æ°á»£c 1 thÃ¡ng nÃ y. Äáº¿n pháº§n PCA, em cÃ³ má»™t tháº¯c máº¯c lÃ  má»i ngÆ°á»i thÆ°á»ng apply PCA cho toÃ n bá»™ táº­p data (entire data), hay lÃ  apply cho duy nháº¥t táº­p training data (fit_transform), sau Ä‘Ã³ láº¥y mÃ´ hÃ¬nh PCA há»c Ä‘Æ°á»£c tá»« táº­p train Ä‘á»ƒ transform táº­p test áº¡? Ã€ má»i ngÆ°á»i cÃ³ thá»ƒ chá»‰ ra Ä‘iá»ƒm khÃ¡c biá»‡t cá»§a 2 cÃ¡ch trÃªn dc ko áº¡. Em cáº£m Æ¡n ráº¥t nhiá»u áº¡!!!!
P/s: em cÃ³ tham kháº£o (xem trá»™m :v) 1 sá»‘ project cá»§a á»•ng mentor cá»§a em thÃ¬: cÃ³ lÃºc á»•ng apply tháº³ng, cÃ³ lÃºc á»•ng chia ra rá»“i má»›i apply...Mong ad duyá»‡t áº¡!!","Hello má»i ngÆ°á»i, em má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» ML Ä‘Æ°á»£c 1 thÃ¡ng nÃ y. Äáº¿n pháº§n PCA, em cÃ³ má»™t tháº¯c máº¯c lÃ  má»i ngÆ°á»i thÆ°á»ng apply PCA cho toÃ n bá»™ táº­p data (entire data), hay lÃ  apply cho duy nháº¥t táº­p training data (fit_transform), sau Ä‘Ã³ láº¥y mÃ´ hÃ¬nh PCA há»c Ä‘Æ°á»£c tá»« táº­p train Ä‘á»ƒ transform táº­p test áº¡? Ã€ má»i ngÆ°á»i cÃ³ thá»ƒ chá»‰ ra Ä‘iá»ƒm khÃ¡c biá»‡t cá»§a 2 cÃ¡ch trÃªn dc ko áº¡. Em cáº£m Æ¡n ráº¥t nhiá»u áº¡!!!! P/s: em cÃ³ tham kháº£o (xem trá»™m :v) 1 sá»‘ project cá»§a á»•ng mentor cá»§a em thÃ¬: cÃ³ lÃºc á»•ng apply tháº³ng, cÃ³ lÃºc á»•ng chia ra rá»“i má»›i apply...Mong ad duyá»‡t áº¡!!",,,,,
Mn giáº£i thÃ­ch giÃºp em Ä‘oáº¡n in Ä‘áº­m dÆ°á»›i Ä‘Ã¢y vá»›i áº¡. Em Ä‘á»c hoÃ i mÃ  khÃ´ng thÃ´ng ná»•i. Em cáº£m Æ¡n mn nhiá»u.,Mn giáº£i thÃ­ch giÃºp em Ä‘oáº¡n in Ä‘áº­m dÆ°á»›i Ä‘Ã¢y vá»›i áº¡. Em Ä‘á»c hoÃ i mÃ  khÃ´ng thÃ´ng ná»•i. Em cáº£m Æ¡n mn nhiá»u.,,,,,
Chia sáº» sÃ¡ch vá» python for data science,Chia sáº» sÃ¡ch vá» python for data science,,,,,
Má»™t sá»‘ cÃ¢u lá»‡nh cÆ¡ báº£n trong Linux mÃ  cÃ¡c báº¡n nÃªn biáº¿t,Má»™t sá»‘ cÃ¢u lá»‡nh cÆ¡ báº£n trong Linux mÃ  cÃ¡c báº¡n nÃªn biáº¿t,,,,,
"ChÃ o má»i ngÆ°á»i.
Em hiá»‡n Ä‘ang táº­p xÃ¢y dá»±ng cÃ¡i giao diá»‡n Ä‘iá»n khiá»ƒn UAV (mÃ´ hÃ¬nh vui thÃ´i) dá»±a trÃªn tham kháº£o cá»§a viettel, cÃ¡c bÃ¡c cho em há»i cÃ³ ai biáº¿t cÃ¡ch váº½ cÃ¡i la bÃ n báº±ng python Ä‘Æ°a vÃ´ khÃ´ng váº­y áº¡, sá»£t gu gá»“ toÃ n tháº¥y lÃ  váº½ trÃªn thiáº¿t bá»‹ adruno cÃ¡i nÃ y thÃ¬ em chá»‹u.
Thank má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i. Em hiá»‡n Ä‘ang táº­p xÃ¢y dá»±ng cÃ¡i giao diá»‡n Ä‘iá»n khiá»ƒn UAV (mÃ´ hÃ¬nh vui thÃ´i) dá»±a trÃªn tham kháº£o cá»§a viettel, cÃ¡c bÃ¡c cho em há»i cÃ³ ai biáº¿t cÃ¡ch váº½ cÃ¡i la bÃ n báº±ng python Ä‘Æ°a vÃ´ khÃ´ng váº­y áº¡, sá»£t gu gá»“ toÃ n tháº¥y lÃ  váº½ trÃªn thiáº¿t bá»‹ adruno cÃ¡i nÃ y thÃ¬ em chá»‹u. Thank má»i ngÆ°á»i.",,,,,
"anh chá»‹ cho e há»i chÃºt vá»›i áº¡.
em cÃ³ má»™t táº­p data Ä‘Ã£ segment vÃ¹ng tay, hiá»‡n táº¡i e muá»‘n classify cÃ¡c hÃ nh Ä‘á»™ng trong táº­p nÃ y. nhÆ°ng khi e train thÃ¬ xuáº¥t hiá»‡n lá»—i nÃ y áº¡? áº£nh segment lÃ  áº£nh cÃ³ mÃ u (cháº¡y vá»›i cÃ¡c bá»™ data khÃ¡c k segment thÃ¬ váº«n Ä‘c).
Em cáº£m Æ¡n a chá»‹ áº¡!","anh chá»‹ cho e há»i chÃºt vá»›i áº¡. em cÃ³ má»™t táº­p data Ä‘Ã£ segment vÃ¹ng tay, hiá»‡n táº¡i e muá»‘n classify cÃ¡c hÃ nh Ä‘á»™ng trong táº­p nÃ y. nhÆ°ng khi e train thÃ¬ xuáº¥t hiá»‡n lá»—i nÃ y áº¡? áº£nh segment lÃ  áº£nh cÃ³ mÃ u (cháº¡y vá»›i cÃ¡c bá»™ data khÃ¡c k segment thÃ¬ váº«n Ä‘c). Em cáº£m Æ¡n a chá»‹ áº¡!",,,,,
"Má»i ngÆ°á»i Æ¡i, cho em há»i lÃ  em cÃ³ 1 file Json theo CoCo format vá»›i folder áº£nh, váº­y cÃ³ cÃ¡ch library nÃ o Ä‘á»ƒ Ä‘á»c file json rá»“i visualize lÃªn áº£nh Ä‘á»ƒ em check xem annotations Ä‘Ãºng khÃ´ng nhá»‰?","Má»i ngÆ°á»i Æ¡i, cho em há»i lÃ  em cÃ³ 1 file Json theo CoCo format vá»›i folder áº£nh, váº­y cÃ³ cÃ¡ch library nÃ o Ä‘á»ƒ Ä‘á»c file json rá»“i visualize lÃªn áº£nh Ä‘á»ƒ em check xem annotations Ä‘Ãºng khÃ´ng nhá»‰?",,,,,
Em xin lÃªn tiáº¿p clip sá»‘ 2 cá»§a series vá» Stats áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ á»§ng há»™ clip sá»‘ 1 cá»§a em.,Em xin lÃªn tiáº¿p clip sá»‘ 2 cá»§a series vá» Stats áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ á»§ng há»™ clip sá»‘ 1 cá»§a em.,,,,,
"ChÃ o cÃ¡c báº¡n. MÃ¬nh Ä‘ang nghiÃªn cá»©u vá» bÃ i toÃ¡n binary classification trÃªn dá»¯ liá»‡u 1 chiá»u (Univariate data), hiá»‡n táº¡i mÃ¬nh Ä‘ang sá»­ dá»¥ng meanshift Ä‘á»ƒ nháº­n dáº¡ng vÃ¬ dá»¯ liá»‡u cÃ³ Ä‘áº·c Ä‘iá»ƒm khÃ´ng Ä‘Æ°á»£c gÃ¡n nhÃ£n trÆ°á»›c, káº¿t quáº£ tÆ°Æ¡ng Ä‘á»‘i tá»‘t. CÃ¡c báº¡n vui lÃ²ng cho mÃ¬nh há»i ngoÃ i ra mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ o khÃ¡c Ä‘á»ƒ phÃ¢n loáº¡i Ä‘Æ°á»£c khÃ´ng ?
Xin cáº£m Æ¡n ráº¥t nhiá»u.","ChÃ o cÃ¡c báº¡n. MÃ¬nh Ä‘ang nghiÃªn cá»©u vá» bÃ i toÃ¡n binary classification trÃªn dá»¯ liá»‡u 1 chiá»u (Univariate data), hiá»‡n táº¡i mÃ¬nh Ä‘ang sá»­ dá»¥ng meanshift Ä‘á»ƒ nháº­n dáº¡ng vÃ¬ dá»¯ liá»‡u cÃ³ Ä‘áº·c Ä‘iá»ƒm khÃ´ng Ä‘Æ°á»£c gÃ¡n nhÃ£n trÆ°á»›c, káº¿t quáº£ tÆ°Æ¡ng Ä‘á»‘i tá»‘t. CÃ¡c báº¡n vui lÃ²ng cho mÃ¬nh há»i ngoÃ i ra mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ o khÃ¡c Ä‘á»ƒ phÃ¢n loáº¡i Ä‘Æ°á»£c khÃ´ng ? Xin cáº£m Æ¡n ráº¥t nhiá»u.",,,,,
"[AI Share]
Meta-learning lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u ná»›i ná»•i vÃ  phÃ¡t triá»ƒn nhanh chÃ³ng trong AI.
DÆ°á»›i Ä‘Ã¢y mÃ  má»™t sá»‘ hÆ°á»›ng dáº«n vá» lÄ©nh vá»±c Meta-learning bao gá»“m cÆ¡ sá»Ÿ toÃ¡n há»c vÃ  cÃ¡c á»©ng dá»¥ng cá»§a nÃ³ trong AAAI 2021.",[AI Share] Meta-learning lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u ná»›i ná»•i vÃ  phÃ¡t triá»ƒn nhanh chÃ³ng trong AI. DÆ°á»›i Ä‘Ã¢y mÃ  má»™t sá»‘ hÆ°á»›ng dáº«n vá» lÄ©nh vá»±c Meta-learning bao gá»“m cÆ¡ sá»Ÿ toÃ¡n há»c vÃ  cÃ¡c á»©ng dá»¥ng cá»§a nÃ³ trong AAAI 2021.,,,,,
"ChÃ o mn, cho em há»i viá»‡c sá»­ dá»¥ng dataset Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u cho mÃ´ hÃ¬nh báº±ng Bayes Optimization (sá»­ dá»¥ng cross validation cho hÃ m má»¥c tiÃªu), sau Ä‘Ã³ sá»­ dá»¥ng Repeated Cross Validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»›i bá»™ tham sá»‘ tá»‘i Æ°u tÃ¬m Ä‘Æ°á»£c cÅ©ng trÃªn dataset nhÆ° tháº¿ nÃ y lÃ  Ä‘Ãºng hay sai áº¡.","ChÃ o mn, cho em há»i viá»‡c sá»­ dá»¥ng dataset Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u cho mÃ´ hÃ¬nh báº±ng Bayes Optimization (sá»­ dá»¥ng cross validation cho hÃ m má»¥c tiÃªu), sau Ä‘Ã³ sá»­ dá»¥ng Repeated Cross Validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»›i bá»™ tham sá»‘ tá»‘i Æ°u tÃ¬m Ä‘Æ°á»£c cÅ©ng trÃªn dataset nhÆ° tháº¿ nÃ y lÃ  Ä‘Ãºng hay sai áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i. Em cÃ³ má»™t tháº¯c máº¯c sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡.
Em cÃ³ 2 neural netwroks cÃ³ cáº¥u trÃºc nhÆ° nhau, cÃ³ cÃ¹ng sá»‘ lÆ°á»£ng parameters, nhÆ°ng vÃ¬ Ä‘Æ°á»£c train trÃªn 2 bá»™ data set khÃ¡c nhau nÃªn bá»™ trá»ng sá»‘ cá»§a má»—i model lÃ  khÃ¡c nhau. Cho em há»i lÃ  lÃ m sao Ä‘á»ƒ tÃ­nh Ä‘Æ°á»£c má»©c Ä‘á»™ giá»‘ng nhau ( similarity ) cá»§a 2 models nÃ y áº¡.
Em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i. Em cÃ³ má»™t tháº¯c máº¯c sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡. Em cÃ³ 2 neural netwroks cÃ³ cáº¥u trÃºc nhÆ° nhau, cÃ³ cÃ¹ng sá»‘ lÆ°á»£ng parameters, nhÆ°ng vÃ¬ Ä‘Æ°á»£c train trÃªn 2 bá»™ data set khÃ¡c nhau nÃªn bá»™ trá»ng sá»‘ cá»§a má»—i model lÃ  khÃ¡c nhau. Cho em há»i lÃ  lÃ m sao Ä‘á»ƒ tÃ­nh Ä‘Æ°á»£c má»©c Ä‘á»™ giá»‘ng nhau ( similarity ) cá»§a 2 models nÃ y áº¡. Em xin cáº£m Æ¡n.",,,,,
"ChÃ o mn áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project quáº£n lÃ½ cháº¥m cÃ´ng theo mÃ´ hÃ¬nh client angular, server lÃ  spring boot. CÃ³ 1 pháº§n em Ä‘ang vÆ°á»›ng lÃ  táº¡o áº£nh model nhÃ¢n viÃªn báº±ng opencv cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ em cÃ³ thá»ƒ call tá»« angular Ä‘áº¿n python Ä‘á»ƒ má»Ÿ camera vÃ  táº¡o model khÃ´ng áº¡?
Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","ChÃ o mn áº¡. Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project quáº£n lÃ½ cháº¥m cÃ´ng theo mÃ´ hÃ¬nh client angular, server lÃ  spring boot. CÃ³ 1 pháº§n em Ä‘ang vÆ°á»›ng lÃ  táº¡o áº£nh model nhÃ¢n viÃªn báº±ng opencv cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ em cÃ³ thá»ƒ call tá»« angular Ä‘áº¿n python Ä‘á»ƒ má»Ÿ camera vÃ  táº¡o model khÃ´ng áº¡? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"ChÃ o má»i ngÆ°á»i,
Má»i ngÆ°á»i cho em há»i, trong mÃ´ hÃ¬nh transformer thÃ¬ encoder pass key vÃ  value tá»« encoder sang decoder. NgoÃ i 2 matrix trÃªn thÃ¬ cÃ³ pass giÃ¡ trá»‹ z nhÆ° hÃ¬nh phÃ­a dÆ°á»›i sang decoder ko áº¡ (Náº¿u pass thÃ¬ nÃ³ sáº½ sá»­ dá»¥ng nhÆ° tháº¿ nÃ o á»Ÿ decoder cÃ³ pháº£i nÃ³ dc concat vá»›i input á»Ÿ encoder ko áº¡, cÃ²n náº¿u ko thÃ¬ mÃ¬nh tÃ­nh giÃ¡ trá»‹ nÃ y lÃ m gÃ¬ áº¡).
CÃ²n má»™t cÃ¢u há»i ná»¯a lÃ . 2 giÃ¡ trá»‹ key vÃ  value tá»« encoder Ä‘i vÃ o Multi head attention cÃ²n query thÃ¬ e ko tháº¥y áº¡. E tháº¥y dáº¥u mÅ©i tÃªn tá»« masked multi head attention Ä‘i lÃªn nhÆ°ng ko biáº¿t nÃ³ lÃ  cÃ¡i gÃ¬, cÃ³ pháº£i lÃ  vector query e Ä‘Ã£ nÃ³i ko áº¡.
Mong má»i ngÆ°á»i giÃºp Ä‘á»¡ em cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, Má»i ngÆ°á»i cho em há»i, trong mÃ´ hÃ¬nh transformer thÃ¬ encoder pass key vÃ  value tá»« encoder sang decoder. NgoÃ i 2 matrix trÃªn thÃ¬ cÃ³ pass giÃ¡ trá»‹ z nhÆ° hÃ¬nh phÃ­a dÆ°á»›i sang decoder ko áº¡ (Náº¿u pass thÃ¬ nÃ³ sáº½ sá»­ dá»¥ng nhÆ° tháº¿ nÃ o á»Ÿ decoder cÃ³ pháº£i nÃ³ dc concat vá»›i input á»Ÿ encoder ko áº¡, cÃ²n náº¿u ko thÃ¬ mÃ¬nh tÃ­nh giÃ¡ trá»‹ nÃ y lÃ m gÃ¬ áº¡). CÃ²n má»™t cÃ¢u há»i ná»¯a lÃ . 2 giÃ¡ trá»‹ key vÃ  value tá»« encoder Ä‘i vÃ o Multi head attention cÃ²n query thÃ¬ e ko tháº¥y áº¡. E tháº¥y dáº¥u mÅ©i tÃªn tá»« masked multi head attention Ä‘i lÃªn nhÆ°ng ko biáº¿t nÃ³ lÃ  cÃ¡i gÃ¬, cÃ³ pháº£i lÃ  vector query e Ä‘Ã£ nÃ³i ko áº¡. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡ em cáº£m Æ¡n",,,,,
"DaÌ£ em mÆ¡Ìi tiÌ€m hiÃªÌ‰u vÃªÌ€ machine learning, moÌ£i ngÆ°Æ¡Ì€i cho em hoÌ‰i maÌy em duÌ€ng RTX 1650 thiÌ€ miÌ€nh nÃªn chaÌ£y trÃªn maÌy hay duÌ€ng colab aÌ£, vaÌ€ nÃªÌu chaÌ£y trÃªn maÌy thiÌ€ cho em xin hÆ°Æ¡Ìng Ä‘ÃªÌ€ caÌi tf + gpu vÆ¡Ìi aÌ£. tks mn","DaÌ£ em mÆ¡Ìi tiÌ€m hiÃªÌ‰u vÃªÌ€ machine learning, moÌ£i ngÆ°Æ¡Ì€i cho em hoÌ‰i maÌy em duÌ€ng RTX 1650 thiÌ€ miÌ€nh nÃªn chaÌ£y trÃªn maÌy hay duÌ€ng colab aÌ£, vaÌ€ nÃªÌu chaÌ£y trÃªn maÌy thiÌ€ cho em xin hÆ°Æ¡Ìng Ä‘ÃªÌ€ caÌi tf + gpu vÆ¡Ìi aÌ£. tks mn",,,,,
"ChÃ o mn, em Ä‘ang báº¯t Ä‘áº§u Ä‘á»c vá» graph neural net áº¡
Em Ä‘ang thá»±c hÃ nh phÃ¢n loáº¡i node cho data dáº¡ng báº£ng. Em muá»‘n táº¡o node features rá»“i xÃ¢y dá»±ng liÃªn káº¿t giá»¯a chÃºng Ä‘ee build graph trÆ°á»›c khi feed vÃ o GNN thÃ¬ e tÃ­nh simmilarity giá»¯a cÃ¡c sample rá»“i chá»n edge theo Ä‘Ã³ cÃ³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n","ChÃ o mn, em Ä‘ang báº¯t Ä‘áº§u Ä‘á»c vá» graph neural net áº¡ Em Ä‘ang thá»±c hÃ nh phÃ¢n loáº¡i node cho data dáº¡ng báº£ng. Em muá»‘n táº¡o node features rá»“i xÃ¢y dá»±ng liÃªn káº¿t giá»¯a chÃºng Ä‘ee build graph trÆ°á»›c khi feed vÃ o GNN thÃ¬ e tÃ­nh simmilarity giá»¯a cÃ¡c sample rá»“i chá»n edge theo Ä‘Ã³ cÃ³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n",,,,,
"Xin chÃ o má»i ngÆ°á»i!
Hiá»‡n táº¡i cÃ´ng ty em Ä‘ang cÃ³ nhu cáº§u build server váº­t lÃ½ Ä‘á»ƒ tiáº¿t kiá»‡m chi phÃ­ cho quÃ¡ trÃ¬nh research, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t sá»‘ cáº¥u hÃ¬nh mÃ¡y táº§m trung(khoáº£ng 120-150tr) vÃ  má»™t vÃ i cÆ¡ sá»Ÿ build mÃ¡y server uy tÃ­n vá»›i áº¡
Em xin cáº£m Æ¡n!
P/s: VÃ¬ cÃ´ng viá»‡c lÃ m khÃ¡ nhiá»u task vá» training GAN model nÃªn e dá»± tÃ­nh sáº½ dÃ¹ng card T4.","Xin chÃ o má»i ngÆ°á»i! Hiá»‡n táº¡i cÃ´ng ty em Ä‘ang cÃ³ nhu cáº§u build server váº­t lÃ½ Ä‘á»ƒ tiáº¿t kiá»‡m chi phÃ­ cho quÃ¡ trÃ¬nh research, má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t sá»‘ cáº¥u hÃ¬nh mÃ¡y táº§m trung(khoáº£ng 120-150tr) vÃ  má»™t vÃ i cÆ¡ sá»Ÿ build mÃ¡y server uy tÃ­n vá»›i áº¡ Em xin cáº£m Æ¡n! P/s: VÃ¬ cÃ´ng viá»‡c lÃ m khÃ¡ nhiá»u task vá» training GAN model nÃªn e dá»± tÃ­nh sáº½ dÃ¹ng card T4.",,,,,
"Anh chá»‹ Æ¡i cho em há»i lÃ  trÃªn Mac M1 chÆ°a há»— trá»£ cÃ¡c thÆ° viá»‡n nhÆ° lÃ  numpy, pandas pháº£i khÃ´ng áº¡ ? Em cáº£m Æ¡n","Anh chá»‹ Æ¡i cho em há»i lÃ  trÃªn Mac M1 chÆ°a há»— trá»£ cÃ¡c thÆ° viá»‡n nhÆ° lÃ  numpy, pandas pháº£i khÃ´ng áº¡ ? Em cáº£m Æ¡n",,,,,
"Mn cho em há»i, sau tá»« phÆ°Æ¡ng trÃ¬nh trÃªn láº¡i cÃ³ thá»ƒ viáº¿t láº¡i Ä‘Æ°á»£c nhÆ° phÆ°Æ¡ng trÃ¬nh dÆ°á»›i áº¡. Hai phÆ°Æ¡ng trÃ¬nh cÃ³ Ã½ nghÄ©a khÃ¡c nhau mÃ  ( má»™t cÃ¡i sau vÃ  má»™t cÃ¡i trÆ°á»›c ). Em cáº£m Æ¡n mn nhiá»u.","Mn cho em há»i, sau tá»« phÆ°Æ¡ng trÃ¬nh trÃªn láº¡i cÃ³ thá»ƒ viáº¿t láº¡i Ä‘Æ°á»£c nhÆ° phÆ°Æ¡ng trÃ¬nh dÆ°á»›i áº¡. Hai phÆ°Æ¡ng trÃ¬nh cÃ³ Ã½ nghÄ©a khÃ¡c nhau mÃ  ( má»™t cÃ¡i sau vÃ  má»™t cÃ¡i trÆ°á»›c ). Em cáº£m Æ¡n mn nhiá»u.",,,,,
"ChÃ o má»i ngÆ°á»i áº¡
Em Ä‘ang lÃ m vá» Ä‘á» tÃ i nháº­n dáº¡ng hÃ nh Ä‘á»™ng thá»i gian thá»±c, em sá»­ dá»¥ng MobileNetV2 Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng vÃ  LSTM Ä‘á» phÃ¢n lá»›p Ä‘áº¿n giai Ä‘oáº¡n training, test trÃªn dataset thÃ¬ dá»± Ä‘oÃ¡n Ä‘Ãºng Ä‘áº¿n trÃªn 90% nhÆ°ng khi test real time vá»›i webcam thÃ¬ dá»± Ä‘oÃ¡n chÆ°a Ä‘Æ°á»£c chÃ­nh xÃ¡c. Dataset em sá»­ dá»¥ng lÃ  KARD vÃ  thu tháº­p thÃªm má»™t sá»‘ hÃ nh Ä‘á»™ng khÃ´ng cÃ³ trong dataset (3 hÃ nh Ä‘á»™ng trong KARD vÃ  3 hÃ nh Ä‘á»™ng tá»± thu tháº­p thÃªm). Em training vá»›i 100 láº§n láº·p thÃ¬ Ä‘Æ°á»£c sá»‘ liá»‡u nhÆ° hÃ¬nh. Má»i ngÆ°á»i phÃ¢n tÃ­ch giÃºp em mÃ´ hÃ¬nh há»c nhÆ° váº­y lÃ  cÃ³ á»•n chÆ°a, náº¿u chÆ°a á»•n thÃ¬ pháº£i láº·p thÃªm khoáº£ng bao nhiÃªu láº§n ná»¯a. Em cáº£m Æ¡n áº¡!
Nguá»“n tham kháº£o: https://github.com/peachman05/action-recognition-tutorial#dataset","ChÃ o má»i ngÆ°á»i áº¡ Em Ä‘ang lÃ m vá» Ä‘á» tÃ i nháº­n dáº¡ng hÃ nh Ä‘á»™ng thá»i gian thá»±c, em sá»­ dá»¥ng MobileNetV2 Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng vÃ  LSTM Ä‘á» phÃ¢n lá»›p Ä‘áº¿n giai Ä‘oáº¡n training, test trÃªn dataset thÃ¬ dá»± Ä‘oÃ¡n Ä‘Ãºng Ä‘áº¿n trÃªn 90% nhÆ°ng khi test real time vá»›i webcam thÃ¬ dá»± Ä‘oÃ¡n chÆ°a Ä‘Æ°á»£c chÃ­nh xÃ¡c. Dataset em sá»­ dá»¥ng lÃ  KARD vÃ  thu tháº­p thÃªm má»™t sá»‘ hÃ nh Ä‘á»™ng khÃ´ng cÃ³ trong dataset (3 hÃ nh Ä‘á»™ng trong KARD vÃ  3 hÃ nh Ä‘á»™ng tá»± thu tháº­p thÃªm). Em training vá»›i 100 láº§n láº·p thÃ¬ Ä‘Æ°á»£c sá»‘ liá»‡u nhÆ° hÃ¬nh. Má»i ngÆ°á»i phÃ¢n tÃ­ch giÃºp em mÃ´ hÃ¬nh há»c nhÆ° váº­y lÃ  cÃ³ á»•n chÆ°a, náº¿u chÆ°a á»•n thÃ¬ pháº£i láº·p thÃªm khoáº£ng bao nhiÃªu láº§n ná»¯a. Em cáº£m Æ¡n áº¡! Nguá»“n tham kháº£o: https://github.com/peachman05/action-recognition-tutorial#dataset",,,,,
"https://www.kaggle.com/c/mercari-price-suggestion-challenge
ÄÃ¢y lÃ  má»™t bÃ i táº­p dá»± Ä‘oÃ¡n giÃ¡ báº±ng há»“i quy, cho em há»i lÃ  viá»‡c log cá»§a price tuÃ¢n theo normal distribution cÃ³ áº£nh hÆ°á»Ÿng tháº¿ nÃ o Ä‘áº¿n viá»‡c giáº£i bÃ i toÃ¡n váº­y áº¡?","https://www.kaggle.com/c/mercari-price-suggestion-challenge ÄÃ¢y lÃ  má»™t bÃ i táº­p dá»± Ä‘oÃ¡n giÃ¡ báº±ng há»“i quy, cho em há»i lÃ  viá»‡c log cá»§a price tuÃ¢n theo normal distribution cÃ³ áº£nh hÆ°á»Ÿng tháº¿ nÃ o Ä‘áº¿n viá»‡c giáº£i bÃ i toÃ¡n váº­y áº¡?",,,,,
"[TÃ­ch phÃ¢n riemann vÃ  Ä‘á»‹nh lÃ½ fubini - ÄÃ³ng gÃ³p Minh PhÆ°Æ¡ng]
TÃ­ch phÃ¢n riemann cÃ³ nhiá»u á»©ng dá»¥ng trong giáº£i tÃ­ch. NÃ³ cho phÃ©p ta tÃ­nh xáº¥p xá»‰ cá»§a háº§u háº¿t cÃ¡c tÃ­ch phÃ¢n mÃ  lá»i giáº£i thÃ´ng thÆ°á»ng khÃ³ tÃ¬m kiáº¿m.
CÃ²n Ä‘á»‹nh lÃ½ Fubini thÃ¬ quÃ¡ quen thuá»™c vá»›i nhá»¯ng bÃ i toÃ¡n tÃ¬m tÃ­ch phÃ¢n nhiá»u chiá»u.
CÃ¹ng tÃ¬m hiá»ƒu vá» nhá»¯ng khÃ¡i niá»‡m giáº£i tÃ­ch cÆ¡ báº£n nÃ y qua bÃ i viáº¿t cá»§a tÃ¡c giáº£ Minh PhÆ°Æ¡ng trong ""Machine Learning Alogrithms to Practice"".
---------------------------------------------------------------
Vá»›i má»¥c tiÃªu ""VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n"". Báº¡n cÃ³ thá»ƒ tham gia dá»± Ã¡n viáº¿t sÃ¡ch cá»™ng Ä‘á»“ng cá»§a cuá»‘n ""Machine Learning Algorithms to Practice"" táº¡i:
https://www.facebook.com/groups/167567421900114","[TÃ­ch phÃ¢n riemann vÃ  Ä‘á»‹nh lÃ½ fubini - ÄÃ³ng gÃ³p Minh PhÆ°Æ¡ng] TÃ­ch phÃ¢n riemann cÃ³ nhiá»u á»©ng dá»¥ng trong giáº£i tÃ­ch. NÃ³ cho phÃ©p ta tÃ­nh xáº¥p xá»‰ cá»§a háº§u háº¿t cÃ¡c tÃ­ch phÃ¢n mÃ  lá»i giáº£i thÃ´ng thÆ°á»ng khÃ³ tÃ¬m kiáº¿m. CÃ²n Ä‘á»‹nh lÃ½ Fubini thÃ¬ quÃ¡ quen thuá»™c vá»›i nhá»¯ng bÃ i toÃ¡n tÃ¬m tÃ­ch phÃ¢n nhiá»u chiá»u. CÃ¹ng tÃ¬m hiá»ƒu vá» nhá»¯ng khÃ¡i niá»‡m giáº£i tÃ­ch cÆ¡ báº£n nÃ y qua bÃ i viáº¿t cá»§a tÃ¡c giáº£ Minh PhÆ°Æ¡ng trong ""Machine Learning Alogrithms to Practice"". --------------------------------------------------------------- Vá»›i má»¥c tiÃªu ""VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n"". Báº¡n cÃ³ thá»ƒ tham gia dá»± Ã¡n viáº¿t sÃ¡ch cá»™ng Ä‘á»“ng cá»§a cuá»‘n ""Machine Learning Algorithms to Practice"" táº¡i: https://www.facebook.com/groups/167567421900114",,,,,
"ChÃ o má»i ngÆ°á»i.
MÃ¬nh tháº¯c máº¯c trong bÃ i toÃ¡n Segmantic segmentation, khi huáº¥n luyá»‡n mÃ¬nh lá»±a chá»n 1 kÃ­ch thÆ°á»›c áº£nh cá»‘ Ä‘á»‹nh sá»­ dá»¥ng random crop Ä‘á»ƒ cÃ³ thá»ƒ huáº¥n luyá»‡n theo batches. NhÆ°ng khi test, áº£nh Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  cÃ³ thá»ƒ lá»›n hÆ¡n nhiá»u so vá»›i lÃºc training liá»‡u cÃ³ áº£nh hÆ°á»Ÿng tá»›i Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh? Mn cÃ³ thá»ƒ giá»›i thiá»‡u cho mÃ¬nh chiáº¿n lÆ°á»£c khi huáº¥n luyá»‡n segmantic segmentation model khi dá»¯ liá»‡u áº£nh cÃ³ kÃ­ch thÆ°á»›c báº¥t kÃ¬ k áº¡?","ChÃ o má»i ngÆ°á»i. MÃ¬nh tháº¯c máº¯c trong bÃ i toÃ¡n Segmantic segmentation, khi huáº¥n luyá»‡n mÃ¬nh lá»±a chá»n 1 kÃ­ch thÆ°á»›c áº£nh cá»‘ Ä‘á»‹nh sá»­ dá»¥ng random crop Ä‘á»ƒ cÃ³ thá»ƒ huáº¥n luyá»‡n theo batches. NhÆ°ng khi test, áº£nh Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  cÃ³ thá»ƒ lá»›n hÆ¡n nhiá»u so vá»›i lÃºc training liá»‡u cÃ³ áº£nh hÆ°á»Ÿng tá»›i Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh? Mn cÃ³ thá»ƒ giá»›i thiá»‡u cho mÃ¬nh chiáº¿n lÆ°á»£c khi huáº¥n luyá»‡n segmantic segmentation model khi dá»¯ liá»‡u áº£nh cÃ³ kÃ­ch thÆ°á»›c báº¥t kÃ¬ k áº¡?",,,,,
"[Xin phÃ©p Admin]
Em xin phÃ©p gá»­i tá»›i cÃ¡c anh chá»‹, cÃ¡c báº¡n trong group bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c VinBigdata xÃ¢y dá»±ng Ä‘á»ƒ há»— trá»£ VLSP tá»• chá»©c ASR challenge 2020, dá»± kiáº¿n Ä‘Æ°á»£c tá»• chá»©c trong thÃ¡ng 12 á»Ÿ HÃ  Ná»™i táº¡i: https://slp.vinbigdata.org/
Cá»¥ thá»ƒ, 100 giá» dá»¯ liá»‡u tiáº¿ng nÃ³i Ä‘Ã£ cÃ³ gÃ¡n nhÃ£n sáº½ Ä‘Æ°á»£c dÃ¹ng lÃ m dá»¯ liá»‡u huáº¥n luyá»‡n (training dataset), giÃºp cÃ¡c Ä‘á»™i tráº» phÃ¡t triá»ƒn mÃ´ hÃ¬nh ASR (Tá»± Ä‘á»™ng nháº­n dáº¡ng tiáº¿ng nÃ³i) cho tiáº¿ng Viá»‡t. Káº¿t quáº£ cá»§a mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ bá»Ÿi Word error rate (WER) - thang Ä‘o quá»‘c táº¿ Ä‘á»‘i vá»›i há»‡ thá»‘ng nháº­n dáº¡ng tiáº¿ng nÃ³i vÃ  dá»‹ch mÃ¡y. BÃªn cáº¡nh bá»™ dá»¯ liá»‡u dÃ nh cho ASR, VinBigdata cÅ©ng chia sáº» 01 bá»™ dá»¯ liá»‡u dÃ nh cho Machine Translation táº¡i link trÃªn.","[Xin phÃ©p Admin] Em xin phÃ©p gá»­i tá»›i cÃ¡c anh chá»‹, cÃ¡c báº¡n trong group bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c VinBigdata xÃ¢y dá»±ng Ä‘á»ƒ há»— trá»£ VLSP tá»• chá»©c ASR challenge 2020, dá»± kiáº¿n Ä‘Æ°á»£c tá»• chá»©c trong thÃ¡ng 12 á»Ÿ HÃ  Ná»™i táº¡i: https://slp.vinbigdata.org/ Cá»¥ thá»ƒ, 100 giá» dá»¯ liá»‡u tiáº¿ng nÃ³i Ä‘Ã£ cÃ³ gÃ¡n nhÃ£n sáº½ Ä‘Æ°á»£c dÃ¹ng lÃ m dá»¯ liá»‡u huáº¥n luyá»‡n (training dataset), giÃºp cÃ¡c Ä‘á»™i tráº» phÃ¡t triá»ƒn mÃ´ hÃ¬nh ASR (Tá»± Ä‘á»™ng nháº­n dáº¡ng tiáº¿ng nÃ³i) cho tiáº¿ng Viá»‡t. Káº¿t quáº£ cá»§a mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ bá»Ÿi Word error rate (WER) - thang Ä‘o quá»‘c táº¿ Ä‘á»‘i vá»›i há»‡ thá»‘ng nháº­n dáº¡ng tiáº¿ng nÃ³i vÃ  dá»‹ch mÃ¡y. BÃªn cáº¡nh bá»™ dá»¯ liá»‡u dÃ nh cho ASR, VinBigdata cÅ©ng chia sáº» 01 bá»™ dá»¯ liá»‡u dÃ nh cho Machine Translation táº¡i link trÃªn.",,,,,
"Má»i ngÆ°á»i cho em há»i, em dÃ¹ng email trÆ°á»ng Ä‘á»ƒ há»c free cÃ¡c khÃ³a há»c trÃªn coursera thÃ¬ sau khi hoÃ n thÃ nh em cÃ³ nháº­n Ä‘Æ°á»£c Cerf khÃ´ng áº¡? Giá»¯a khÃ³a data science cá»§a ibm trÃªn coursera vá»›i data science trÃªn udemy (hiá»‡n Ä‘ang giáº£m giÃ¡ cÃ²n 12 Ä‘Ã´) thÃ¬ em nÃªn chá»n há»c khÃ³a nÃ o áº¡? Em cáº£m Æ¡n","Má»i ngÆ°á»i cho em há»i, em dÃ¹ng email trÆ°á»ng Ä‘á»ƒ há»c free cÃ¡c khÃ³a há»c trÃªn coursera thÃ¬ sau khi hoÃ n thÃ nh em cÃ³ nháº­n Ä‘Æ°á»£c Cerf khÃ´ng áº¡? Giá»¯a khÃ³a data science cá»§a ibm trÃªn coursera vá»›i data science trÃªn udemy (hiá»‡n Ä‘ang giáº£m giÃ¡ cÃ²n 12 Ä‘Ã´) thÃ¬ em nÃªn chá»n há»c khÃ³a nÃ o áº¡? Em cáº£m Æ¡n",,,,,
"#xin_viec #xin_hoc_tap
Em xin chÃ o má»i ngÆ°á»i.
Em má»›i chuyá»ƒn tá»« kinh táº¿ sang ML. Anh chá»‹ nÃ o cÃ³ lÃ m dá»± Ã¡n cáº§n ngÆ°á»i há»— trá»£ thÃ¬ cÃ³ thá»ƒ cho em tham gia Ä‘á»ƒ há»c há»i thÃªm kinh nghiá»‡m Ä‘Æ°á»£c khÃ´ng áº¡?
Em náº¯m kiáº¿n thá»©c cÄƒn báº£n vá» má»™t sá»‘ thuáº­t toÃ¡n regression, neural network, svm, thÆ° viá»‡n opencv tensorflow","Em xin chÃ o má»i ngÆ°á»i. Em má»›i chuyá»ƒn tá»« kinh táº¿ sang ML. Anh chá»‹ nÃ o cÃ³ lÃ m dá»± Ã¡n cáº§n ngÆ°á»i há»— trá»£ thÃ¬ cÃ³ thá»ƒ cho em tham gia Ä‘á»ƒ há»c há»i thÃªm kinh nghiá»‡m Ä‘Æ°á»£c khÃ´ng áº¡? Em náº¯m kiáº¿n thá»©c cÄƒn báº£n vá» má»™t sá»‘ thuáº­t toÃ¡n regression, neural network, svm, thÆ° viá»‡n opencv tensorflow",#xin_viec	#xin_hoc_tap,,,,
"Mn cho em há»i cÃ¢u nÃ y hÆ¡i ngá»‘c xÃ­u, 1e-3 báº¥m trong mÃ¡y tÃ­nh nhÆ° tháº¿ nÃ o Ä‘á»ƒ ra Ä‘c 0.001 áº¡. TrÆ°á»›c em cÃ³ tÃ¬m Ä‘Æ°á»£c trang nÃ³i vá» nhá»¯ng kÃ­ hiá»‡u nÃ y nhÆ°ng h tÃ¬m láº¡i khÃ´ng tháº¥y ná»¯a. Em cáº£m Æ¡n mn nhiá»u.","Mn cho em há»i cÃ¢u nÃ y hÆ¡i ngá»‘c xÃ­u, 1e-3 báº¥m trong mÃ¡y tÃ­nh nhÆ° tháº¿ nÃ o Ä‘á»ƒ ra Ä‘c 0.001 áº¡. TrÆ°á»›c em cÃ³ tÃ¬m Ä‘Æ°á»£c trang nÃ³i vá» nhá»¯ng kÃ­ hiá»‡u nÃ y nhÆ°ng h tÃ¬m láº¡i khÃ´ng tháº¥y ná»¯a. Em cáº£m Æ¡n mn nhiá»u.",,,,,
"MÃ¬nh sá»­ dá»¥ng yolo train Ä‘Æ°á»£c model náº·ng táº§m 250Mb, nhÆ°ng khi deploy lÃªn server cÃ³ cáº¥u hÃ¬nh RAM 2GB, CPU AMD EPYC 7571 (nhÆ° trong hÃ¬nh), thÃ¬ cÃ³ váº» server bá»‹ quÃ¡ táº£i dáº«n tá»›i ko detect Ä‘Æ°á»£c. KhÃ´ng biáº¿t nhÆ° váº­y lÃ  cÃ³ gÃ¬ báº¥t thÆ°á»ng khÃ´ng nhá»‰. Náº¿u do cáº¥u hÃ¬nh server yáº¿u thÃ¬ nÃªn nÃ¢ng cáº¥p lÃªn cáº¥u hÃ¬nh nhÆ° tháº¿ nÃ o thÃ¬ phÃ¹ há»£p nhá»‰. Má»i ngÆ°á»i tÆ° váº¥n giÃºp mÃ¬nh giáº£i phÃ¡p xá»­ lÃ½ váº¥n Ä‘á» nÃ y vá»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","MÃ¬nh sá»­ dá»¥ng yolo train Ä‘Æ°á»£c model náº·ng táº§m 250Mb, nhÆ°ng khi deploy lÃªn server cÃ³ cáº¥u hÃ¬nh RAM 2GB, CPU AMD EPYC 7571 (nhÆ° trong hÃ¬nh), thÃ¬ cÃ³ váº» server bá»‹ quÃ¡ táº£i dáº«n tá»›i ko detect Ä‘Æ°á»£c. KhÃ´ng biáº¿t nhÆ° váº­y lÃ  cÃ³ gÃ¬ báº¥t thÆ°á»ng khÃ´ng nhá»‰. Náº¿u do cáº¥u hÃ¬nh server yáº¿u thÃ¬ nÃªn nÃ¢ng cáº¥p lÃªn cáº¥u hÃ¬nh nhÆ° tháº¿ nÃ o thÃ¬ phÃ¹ há»£p nhá»‰. Má»i ngÆ°á»i tÆ° váº¥n giÃºp mÃ¬nh giáº£i phÃ¡p xá»­ lÃ½ váº¥n Ä‘á» nÃ y vá»›i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. HÃ´m trÆ°á»›c cÃ³ báº¡n trÃªn Group há»i vá» váº¥n Ä‘á» nÃ y nÃªn em lÃ m thá»­. á»Ÿ Ä‘Ã¢y em chá»‰ lÃ m cÆ¡ báº£n vá»›i OpenCV chá»© ko cÃ³ GAN gÃ¬ háº¿t áº¡.
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng! Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie vÃ  mong admin duyá»‡t bÃ i!",KÃ­nh chÃ o cÃ¡c bÃ¡c. HÃ´m trÆ°á»›c cÃ³ báº¡n trÃªn Group há»i vá» váº¥n Ä‘á» nÃ y nÃªn em lÃ m thá»­. á»Ÿ Ä‘Ã¢y em chá»‰ lÃ m cÆ¡ báº£n vá»›i OpenCV chá»© ko cÃ³ GAN gÃ¬ háº¿t áº¡. ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng! Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie vÃ  mong admin duyá»‡t bÃ i!,,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh má»›i train xong 1 classification model efficientnetv2, cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ láº¯p nÃ³ vÃ o cÃ¡i rcnn architecture Ä‘á»ƒ thÃ nh object detection khÃ´ng nhá»‰.
Trong trÆ°á»ng há»£p Ä‘áº¥y thÃ¬ cÃ¡i classification model cá»§a mÃ¬nh cÃ³ pháº£i lÃ  backbone khÃ´ng?
Náº¿u lÃ  pytorch thÃ¬ tá»‘t quÃ¢ nhÆ°ng cÃ³ resource gÃ¬ mÃ¬nh Ä‘á»c háº¿t :)
Cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i, MÃ¬nh má»›i train xong 1 classification model efficientnetv2, cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ láº¯p nÃ³ vÃ o cÃ¡i rcnn architecture Ä‘á»ƒ thÃ nh object detection khÃ´ng nhá»‰. Trong trÆ°á»ng há»£p Ä‘áº¥y thÃ¬ cÃ¡i classification model cá»§a mÃ¬nh cÃ³ pháº£i lÃ  backbone khÃ´ng? Náº¿u lÃ  pytorch thÃ¬ tá»‘t quÃ¢ nhÆ°ng cÃ³ resource gÃ¬ mÃ¬nh Ä‘á»c háº¿t :) Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Chia sáº» Ä‘áº¿n báº¡n 02 phÆ°Æ¡ng phÃ¡p Reinforcement Learning do Google AI phÃ¡t triá»ƒn, giÃºp á»©ng dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n Robot Ä‘a tÃ¡c vá»¥: MT-Opt vÃ  Actionable Models.
MT-Opt sá»­ dá»¥ng dá»¯ liá»‡u, trials vÃ  errors cÃ³ sáºµn trong há»‡ thá»‘ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c Q-function, tá»« Ä‘Ã³ robot thá»±c hiá»‡n theo.
Actionable Models nháº­n cáº¥u hÃ¬nh má»¥c tiÃªu cho trÆ°á»›c, sau Ä‘Ã³ láº¥y vÃ  phÃ¢n loáº¡i dá»¯ liá»‡u má»™t cÃ¡ch tá»‘i Æ°u nháº¥t hÃ²ng Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu.
CÃ¹ng tham kháº£o bÃ i viáº¿t do Google AI Blog Ä‘Äƒng táº£i, cÃ¡c video giá»›i thiá»‡u 02 phÆ°Æ¡ng phÃ¡p vÃ  paper cá»§a dá»± Ã¡n nhÃ©.
#GoogleAI #ReinforcementLearning #AI #VEFAcademy","Chia sáº» Ä‘áº¿n báº¡n 02 phÆ°Æ¡ng phÃ¡p Reinforcement Learning do Google AI phÃ¡t triá»ƒn, giÃºp á»©ng dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n Robot Ä‘a tÃ¡c vá»¥: MT-Opt vÃ  Actionable Models. MT-Opt sá»­ dá»¥ng dá»¯ liá»‡u, trials vÃ  errors cÃ³ sáºµn trong há»‡ thá»‘ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c Q-function, tá»« Ä‘Ã³ robot thá»±c hiá»‡n theo. Actionable Models nháº­n cáº¥u hÃ¬nh má»¥c tiÃªu cho trÆ°á»›c, sau Ä‘Ã³ láº¥y vÃ  phÃ¢n loáº¡i dá»¯ liá»‡u má»™t cÃ¡ch tá»‘i Æ°u nháº¥t hÃ²ng Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu. CÃ¹ng tham kháº£o bÃ i viáº¿t do Google AI Blog Ä‘Äƒng táº£i, cÃ¡c video giá»›i thiá»‡u 02 phÆ°Æ¡ng phÃ¡p vÃ  paper cá»§a dá»± Ã¡n nhÃ©.",#GoogleAI	#ReinforcementLearning	#AI	#VEFAcademy,,,,
"Hiá»‡n táº¡i, em Ä‘ang lÃ m project nháº­n diá»‡n biá»ƒn sá»‘ xe. Em cáº§n 400 áº£nh Ä‘Ã£ Ä‘Ã¡nh nhÃ£n. Anh chá»‹ cÃ³ thá»ƒ cho em xin datasets Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n áº¡!","Hiá»‡n táº¡i, em Ä‘ang lÃ m project nháº­n diá»‡n biá»ƒn sá»‘ xe. Em cáº§n 400 áº£nh Ä‘Ã£ Ä‘Ã¡nh nhÃ£n. Anh chá»‹ cÃ³ thá»ƒ cho em xin datasets Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n áº¡!",,,,,
"Em cÃ³ code thá»­ bÃ i toÃ¡n trong paper Meta Pseudo Labels mÃ  khÃ´ng biáº¿t cÃ³ Ä‘Ãºng khÃ´ng áº¡. Má»i ngÆ°á»i coi thá»­ dÃ¹m em vá»›i cho em Ã½ kiáº¿n vá»›i áº¡. Táº¡i e cÃ³ lÃ m vÃ  test trÃªn táº­p TwoMoon dataset chá»‰ Ä‘Æ°á»£c khoáº£ng 86% vÃ  nÃ³ chÃ­nh xÃ¡c giá»‘ng nhÆ° trong paper áº¡. HÃ¬nh Ä‘áº§u lÃ  Notation, hÃ¬nh thá»© 2 lÃ  algorithm trong paper vÃ  hÃ¬nh thá»© 3 lÃ  code cá»§a em áº¡. VÃ¬ dá»¯ liá»‡u cá»§a em dáº¡ng báº£ng (2 cá»™t: má»™t lÃ  tá»a Ä‘á»™ x, hai lÃ  tá»a Ä‘á»™ y ) nÃªn em khÃ´ng dÃ¹ng UDA áº¡.","Em cÃ³ code thá»­ bÃ i toÃ¡n trong paper Meta Pseudo Labels mÃ  khÃ´ng biáº¿t cÃ³ Ä‘Ãºng khÃ´ng áº¡. Má»i ngÆ°á»i coi thá»­ dÃ¹m em vá»›i cho em Ã½ kiáº¿n vá»›i áº¡. Táº¡i e cÃ³ lÃ m vÃ  test trÃªn táº­p TwoMoon dataset chá»‰ Ä‘Æ°á»£c khoáº£ng 86% vÃ  nÃ³ chÃ­nh xÃ¡c giá»‘ng nhÆ° trong paper áº¡. HÃ¬nh Ä‘áº§u lÃ  Notation, hÃ¬nh thá»© 2 lÃ  algorithm trong paper vÃ  hÃ¬nh thá»© 3 lÃ  code cá»§a em áº¡. VÃ¬ dá»¯ liá»‡u cá»§a em dáº¡ng báº£ng (2 cá»™t: má»™t lÃ  tá»a Ä‘á»™ x, hai lÃ  tá»a Ä‘á»™ y ) nÃªn em khÃ´ng dÃ¹ng UDA áº¡.",,,,,
"Xin chÃ o cáº£ nhÃ , VietAI muá»‘n gá»­i Ä‘áº¿n má»i ngÆ°á»i code/data Ä‘á»ƒ train state-of-the-art Vietnamese translation systems https://github.com/vietai/sat. Äi xa hÆ¡n ná»¯a, VietAI muá»‘n kÃªu gá»i cá»™ng Ä‘á»“ng cÃ¹ng chung tay Ä‘á»ƒ build the best resources for Vietnamese translations for everyone to use. Má»i ngÆ°á»i cÃ³ thá»ƒ contribute dÆ°á»›i nhiá»u hÃ¬nh thá»©c:
a. Code: build better models, e.g., using PyTorch Fairseq or advanced architecture such as Funnel Transformer. VietAI has access to Google Cloud TPUv3 cho báº¡n nÃ o tÃ¢m huyáº¿t :)
b. Data: contribute data in various domains, e.g., medicine, arts, etc., or challenging examples like idioms, slangs (""thÃ­ch thÃ¬ chiá»u"").
c. Better demo: Hiá»‡n táº¡i VietAI cÃ³ demo https://demo.vietai.org/, tuy nhiÃªn chÆ°a scale well va cÃ²n thiáº¿u nhiá»u features Ä‘á»ƒ make it more useful to everyone. Ráº¥t cáº§n support tá»« cÃ¡c báº¡n cÃ³ experience vá» web developments & UI/UX design.
Äá»ƒ tÃ¬m hiá»ƒu thÃªm thÃ´ng tin, cÃ¡c báº¡n cÃ³ thá»ƒ comment á»Ÿ Ä‘Ã¢y; inbox cho Trieu H. Trinh Chinh Ngo (technical), Phan Báº¡ch XuÃ¢n An (logistics); or volunteer at VietAI (link in the post below).
CÃ¡m Æ¡n cáº£ nhÃ !","Xin chÃ o cáº£ nhÃ , VietAI muá»‘n gá»­i Ä‘áº¿n má»i ngÆ°á»i code/data Ä‘á»ƒ train state-of-the-art Vietnamese translation systems https://github.com/vietai/sat. Äi xa hÆ¡n ná»¯a, VietAI muá»‘n kÃªu gá»i cá»™ng Ä‘á»“ng cÃ¹ng chung tay Ä‘á»ƒ build the best resources for Vietnamese translations for everyone to use. Má»i ngÆ°á»i cÃ³ thá»ƒ contribute dÆ°á»›i nhiá»u hÃ¬nh thá»©c: a. Code: build better models, e.g., using PyTorch Fairseq or advanced architecture such as Funnel Transformer. VietAI has access to Google Cloud TPUv3 cho báº¡n nÃ o tÃ¢m huyáº¿t :) b. Data: contribute data in various domains, e.g., medicine, arts, etc., or challenging examples like idioms, slangs (""thÃ­ch thÃ¬ chiá»u""). c. Better demo: Hiá»‡n táº¡i VietAI cÃ³ demo https://demo.vietai.org/, tuy nhiÃªn chÆ°a scale well va cÃ²n thiáº¿u nhiá»u features Ä‘á»ƒ make it more useful to everyone. Ráº¥t cáº§n support tá»« cÃ¡c báº¡n cÃ³ experience vá» web developments & UI/UX design. Äá»ƒ tÃ¬m hiá»ƒu thÃªm thÃ´ng tin, cÃ¡c báº¡n cÃ³ thá»ƒ comment á»Ÿ Ä‘Ã¢y; inbox cho Trieu H. Trinh Chinh Ngo (technical), Phan Báº¡ch XuÃ¢n An (logistics); or volunteer at VietAI (link in the post below). CÃ¡m Æ¡n cáº£ nhÃ !",,,,,
"CÃ³ bÃ¡c nÃ o lÃ m data dáº¡ng text cho em há»i tiáº¿ng viá»‡t thÃ¬ mÃ¬nh xá»­ lÃ½ kiá»ƒu gÃ¬ nhá»‰, nhÆ° tiáº¿ng anh cÃ³ cÃ¡c pp nhÆ° loáº¡i punct, loáº¡i stopword, stem rá»“i lemmatize cÃ²n tiáº¿ng viá»‡t mÃ¬nh gáº§n nhÆ° chá»‰ cÃ³ loáº¡i nhá»¯ng tá»« vÃ´ nghÄ©a thÃ¬ pháº£i?","CÃ³ bÃ¡c nÃ o lÃ m data dáº¡ng text cho em há»i tiáº¿ng viá»‡t thÃ¬ mÃ¬nh xá»­ lÃ½ kiá»ƒu gÃ¬ nhá»‰, nhÆ° tiáº¿ng anh cÃ³ cÃ¡c pp nhÆ° loáº¡i punct, loáº¡i stopword, stem rá»“i lemmatize cÃ²n tiáº¿ng viá»‡t mÃ¬nh gáº§n nhÆ° chá»‰ cÃ³ loáº¡i nhá»¯ng tá»« vÃ´ nghÄ©a thÃ¬ pháº£i?",,,,,
"Cho em há»i vá» sá»‘ feature map mÃ¬nh sáº½ nháº­n Ä‘Æ°á»£c sau conv layer
TrÆ°á»ng há»£p nÃ o trong 2 trÆ°á»ng há»£p sau má»›i lÃ  Ä‘Ãºng:
-TH1: 1 Image -> Conv(64 filters) -> 64 feature maps -> Conv(32 filters) -> 64*32 = 2048 feature maps
-TH2: 1 Image -> Conv(64 filters) -> 64 feature maps -> Conv(32 filters) -> 32 feature maps
Náº¿u trÆ°á»ng há»£p 2 lÃ  Ä‘Ãºng thÃ¬ cho em há»i chuyá»‡n gÃ¬ Ä‘Ã£ xáº£y ra á»Ÿ conv layer sá»‘ 2 Ä‘á»ƒ tá»« 64 nÃ³ biáº¿n thÃ nh 32?",Cho em há»i vá» sá»‘ feature map mÃ¬nh sáº½ nháº­n Ä‘Æ°á»£c sau conv layer TrÆ°á»ng há»£p nÃ o trong 2 trÆ°á»ng há»£p sau má»›i lÃ  Ä‘Ãºng: -TH1: 1 Image -> Conv(64 filters) -> 64 feature maps -> Conv(32 filters) -> 64*32 = 2048 feature maps -TH2: 1 Image -> Conv(64 filters) -> 64 feature maps -> Conv(32 filters) -> 32 feature maps Náº¿u trÆ°á»ng há»£p 2 lÃ  Ä‘Ãºng thÃ¬ cho em há»i chuyá»‡n gÃ¬ Ä‘Ã£ xáº£y ra á»Ÿ conv layer sá»‘ 2 Ä‘á»ƒ tá»« 64 nÃ³ biáº¿n thÃ nh 32?,,,,,
"ChÃ o cÃ¡c báº¡n. Jupyter cÃ³ vai trÃ² ráº¥t lá»›n trong (1) giáº£ng dáº¡y online; (2) phÃ¢n tÃ­ch dá»¯ liá»‡u trá»±c quan; (3) sá»­ dá»¥ng trÃªn colab/kaggle vá»›i GPU/TPU cá»§a server; (4) tuy Ã­t quan trá»ng hÆ¡n nhÆ°ng nÃ³ lÃ  cÃ´ng cá»¥ debug. HÃ´m nay mÃ¬nh sáº½ chia sáº» vá»›i cÃ¡c báº¡n cÃ¡ch mÃ¬nh táº¡o jupyterlab trong docker nvidia/cuda + nvidia/pytorch
# BÆ°á»›c 1. Khá»Ÿi táº¡o docker: $ sudo chmod 666 /var/run/docker.sock
# BÆ°á»›c 2. Kiá»ƒm tra docker: $ docker run hello-world
# BÆ°á»›c 3: Táº¡o file Dockerfile nhÆ° sau vá»›i cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  lÆ°u vÃ o thÆ° má»¥c cá»§a báº¡n
""""""
FROM nvcr.io/nvidia/pytorch:21.03-py3
WORKDIR /workspace
#RUN pip install --upgrade pip
ENV CUDA_VERSION=11.1
EXPOSE 8888
RUN pip3 install jupyterlab &&\
pip3 install git+https://github.com/rwightman/pytorch-image-models.git &&\
pip3 install pandas &&\
pip3 install matplotlib &&\
pip3 install seaborn &&\
pip3 install scikit-learn &&\
pip3 install scikit-plot &&\
pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
iile
""""""
# BÆ°á»›c 4: cd tá»›i thÆ° má»¥c chá»©a file Dockerfile
# BÆ°á»›c 5: check docker images: $ docker images
# BÆ°á»›c 6: Build image: $ docker build -f /path/to/Dockerfile -t <name_of_image> . # VD: jupyterlab docker build -f Dockerfile -t jupyter .
# BÆ°á»›c 7: Kiá»ƒm tra xem cÃ³ image jupyter táº¡o ra hay khÃ´ng: $ docker images
# BÆ°á»›c 8: Mount docker image
docker run --gpus all -it --ipc=host -p 8888:8888 -v ""/home/ten_may_tinh_cua_ban/Downloads/Notebooks:/Notebooks"" jupyter
# BÆ°á»›c 9: Run jupyter lab on local host
root@imageid:/workspace# jupyter lab
# BÆ°á»›c 10: click link http://localhost:8888/ or paste the link vÃ o trÃ¬nh duyá»‡t cá»§a báº¡n
# BÆ°á»›c 11: Sau Ä‘Ã³ copy vÃ  dÃ¡n tonken vÃ o token window,
#VÃ­ dá»¥ cÃ³ 1 token: http://hostname:8888/?token=188a8eab606f81b23f9ecf24b933bef21f6c00c2230c6c62;
# copy (token/password) like this: 188a8eab606f81b23f9ecf24b933bef21f6c00c2230c6c62
#paste the token into a window and perform your notebook!!!
#BÃ¢y giá» thÃ¬ báº¡n Ä‘Ã£ táº¡o thÃ nh cÃ´ng 1 jupyterlab, báº¡n cÃ³ thá»ƒ tá»± há»c/ phÃ¢n tÃ­ch code trÃªn jupyter. Hy vá»ng bÃ i viáº¿t Ä‘em láº¡i kiáº¿n thá»©c vÃ  giÃºp Ã­ch cho cÃ¡c báº¡n trong há»c táº­p vÃ  cÃ´ng viá»‡c. MÃ¬nh xin cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi.
ps: trong bÃ i tá»›i mÃ¬nh sáº½ táº¡o dockhub, háº¹n gáº·p láº¡i cÃ¡c báº¡n trong bÃ i sau. ChÃºc cÃ¡c báº¡n cÃ³ 1 tuáº§n tháº­t Ã½ nghÄ©a.","ChÃ o cÃ¡c báº¡n. Jupyter cÃ³ vai trÃ² ráº¥t lá»›n trong (1) giáº£ng dáº¡y online; (2) phÃ¢n tÃ­ch dá»¯ liá»‡u trá»±c quan; (3) sá»­ dá»¥ng trÃªn colab/kaggle vá»›i GPU/TPU cá»§a server; (4) tuy Ã­t quan trá»ng hÆ¡n nhÆ°ng nÃ³ lÃ  cÃ´ng cá»¥ debug. HÃ´m nay mÃ¬nh sáº½ chia sáº» vá»›i cÃ¡c báº¡n cÃ¡ch mÃ¬nh táº¡o jupyterlab trong docker nvidia/cuda + nvidia/pytorch # BÆ°á»›c 1. Khá»Ÿi táº¡o docker: $ sudo chmod 666 /var/run/docker.sock # BÆ°á»›c 2. Kiá»ƒm tra docker: $ docker run hello-world # BÆ°á»›c 3: Táº¡o file Dockerfile nhÆ° sau vá»›i cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  lÆ°u vÃ o thÆ° má»¥c cá»§a báº¡n """""" FROM nvcr.io/nvidia/pytorch:21.03-py3 WORKDIR /workspace pip install --upgrade pip ENV CUDA_VERSION=11.1 EXPOSE 8888 RUN pip3 install jupyterlab &&\ pip3 install git+https://github.com/rwightman/pytorch-image-models.git &&\ pip3 install pandas &&\ pip3 install matplotlib &&\ pip3 install seaborn &&\ pip3 install scikit-learn &&\ pip3 install scikit-plot &&\ pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html iile """""" # BÆ°á»›c 4: cd tá»›i thÆ° má»¥c chá»©a file Dockerfile # BÆ°á»›c 5: check docker images: $ docker images # BÆ°á»›c 6: Build image: $ docker build -f /path/to/Dockerfile -t <name_of_image> . # VD: jupyterlab docker build -f Dockerfile -t jupyter . # BÆ°á»›c 7: Kiá»ƒm tra xem cÃ³ image jupyter táº¡o ra hay khÃ´ng: $ docker images # BÆ°á»›c 8: Mount docker image docker run --gpus all -it --ipc=host -p 8888:8888 -v ""/home/ten_may_tinh_cua_ban/Downloads/Notebooks:/Notebooks"" jupyter # BÆ°á»›c 9: Run jupyter lab on local host root@imageid:/workspace# jupyter lab # BÆ°á»›c 10: click link http://localhost:8888/ or paste the link vÃ o trÃ¬nh duyá»‡t cá»§a báº¡n # BÆ°á»›c 11: Sau Ä‘Ã³ copy vÃ  dÃ¡n tonken vÃ o token window, dá»¥ cÃ³ 1 token: http://hostname:8888/?token=188a8eab606f81b23f9ecf24b933bef21f6c00c2230c6c62; # copy (token/password) like this: 188a8eab606f81b23f9ecf24b933bef21f6c00c2230c6c62 the token into a window and perform your notebook!!! giá» thÃ¬ báº¡n Ä‘Ã£ táº¡o thÃ nh cÃ´ng 1 jupyterlab, báº¡n cÃ³ thá»ƒ tá»± há»c/ phÃ¢n tÃ­ch code trÃªn jupyter. Hy vá»ng bÃ i viáº¿t Ä‘em láº¡i kiáº¿n thá»©c vÃ  giÃºp Ã­ch cho cÃ¡c báº¡n trong há»c táº­p vÃ  cÃ´ng viá»‡c. MÃ¬nh xin cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. ps: trong bÃ i tá»›i mÃ¬nh sáº½ táº¡o dockhub, háº¹n gáº·p láº¡i cÃ¡c báº¡n trong bÃ i sau. ChÃºc cÃ¡c báº¡n cÃ³ 1 tuáº§n tháº­t Ã½ nghÄ©a.",#RUN	#VÃ­	#paste	#BÃ¢y,,,,
"Tá»« dá»¯ liá»‡u lá»›n Ä‘áº¿n dá»¯ liá»‡u tá»‘t: Prof. Andrew Ng kÃªu gá»i cá»™ng Ä‘á»“ng ML táº­p trung vÃ o dá»¯ liá»‡u hÆ¡n so vá»›i model
Hiá»‡n nay, cÃ¡c thÃ nh tá»±u trong lÄ©nh vá»±c ML Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn theo xu hÆ°á»›ng táº£i xuá»‘ng cÃ¡c model vÃ  cá»‘ gáº¯ng cáº£i thiá»‡n káº¿t quáº£ trÃªn cÃ¡c táº­p dataset tiÃªu chuáº©n. Pháº§n lá»›n thá»i gian, má»i ngÆ°á»i Ä‘ang sá»­ dá»¥ng cho viá»‡c cáº£i thiá»‡n code, model hoáº·c cÃ¡c thuáº­t toÃ¡n. Prof. Andrew Ng cho ráº±ng â€œTrong ráº¥t nhiá»u bÃ i toÃ¡n, tÃ´i nháº­n ra ráº±ng sáº½ ráº¥t há»¯u Ã­ch náº¿u chÃºng ta hÆ°á»›ng tÆ° duy vá» viá»‡c khÃ´ng chá»‰ cáº£i thiá»‡n mÃ£ mÃ  cÃ²n cáº§n cáº£i thiá»‡n dá»¯ liá»‡u theo má»™t cÃ¡ch há»‡ thá»‘ng hÆ¡n.
Thá»i gian gáº§n Ä‘Ã¢y, Prof. Andrew Ng Ä‘Ã£ thu hÃºt cá»™ng Ä‘á»“ng ML vÃ o MLOps, má»™t lÄ©nh vá»±c giÃºp giáº£i quyáº¿t viá»‡c xÃ¢y dá»±ng vÃ  triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh ML má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng hÆ¡n. Prof. Andrew Ng Ä‘Æ°a ra quan Ä‘iá»ƒm vá» viá»‡c tÄƒng tá»‘c viá»‡c phÃ¡t triá»ƒn cÃ¡c há»‡ thá»‘ng há»c mÃ¡y náº¿u chÃºng ta táº­p trung nhiá»u hÆ¡n vÃ o dá»¯ liá»‡u so vá»›i viá»‡c láº¥y mÃ´ hÃ¬nh lÃ m trung tÃ¢m. Pháº§n má»m truyá»n thá»‘ng chá»‰ Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch Ä‘oáº¡n mÃ£, trong khi cÃ¡c há»‡ thá»‘ng AI Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch sá»­ dá»¥ng cáº£ mÃ£ (mÃ´ hÃ¬nh + thuáº­t toÃ¡nâ€) vÃ  dá»¯ liá»‡u. â€œKhi cÃ³ má»™t há»‡ thá»‘ng AI lÃ m viá»‡c chÆ°a thá»±c sá»± tá»‘t, má»i ngÆ°á»i â€“ theo báº£n nÄƒng sáº½ cáº¯m Ä‘áº§u vÃ o viá»‡c cáº£i thiá»‡n cÃ¡c Ä‘oáº¡n mÃ£. Äá»‘i vá»›i cÃ¡c á»©ng dá»¥ng thá»±c táº¿, táº­p trung vÃ o viá»‡c cáº£i thiá»‡n dá»¯ liá»‡u sáº½ hiá»‡u quáº£ hÆ¡nâ€.
Prof. Andrew Ng cho ráº±ng tiáº¿n bá»™ trong ML Ä‘ang Ä‘Æ°á»£c thÃºc Ä‘áº©y báº±ng cÃ¡c ná»— lá»±c cáº£i thiá»‡n benchmark trÃªn cÃ¡c bá»™ dá»¯ liá»‡u chuáº©n. Thá»±c táº¿ phá»• biáº¿n lÃ  cÃ¡c researchers thÆ°á»ng giá»¯ cá»‘ Ä‘á»‹nh dá»¯ liá»‡u vÃ  táº­p trung vÃ o viá»‡c cáº£i thiá»‡n mÃ£. Tuy nhiÃªn, vá»›i cÃ¡c táº­p dá»¯ liá»‡u khiÃªm tá»‘n, Ã´ng cho ráº±ng cÃ¡c team sáº½ Ä‘áº¡t Ä‘Æ°á»£c tiáº¿n bá»™ nhanh hÆ¡n náº¿u chÃºng ta cÃ³ dá»¯ liá»‡u tá»‘t hÆ¡n.
NgÆ°á»i ta thÆ°á»ng truyá»n tai nhau ráº±ng 80% cá»§a 1 ML project lÃ  lÃ m sáº¡ch dá»¯ liá»‡u. Prof. Andrew Ä‘áº·t ra cÃ¢u há»i, ráº±ng náº¿u 80% thá»i gian lÃ  chuáº©n bá»‹ dá»¯ liá»‡u thÃ¬ táº¡i sao chÃºng ta láº¡i khÃ´ng Ä‘áº£m báº£o ráº±ng cháº¥t lÆ°á»£ng dá»¯ liá»‡u lÃ  yáº¿u tá»‘ quan trá»ng hÃ ng Ä‘áº§u cho 1 ML project? DÆ°á»ng nhÆ° khÃ´ng ai quan tÃ¢m Ä‘áº¿n Ä‘iá»u nÃ y. LÆ°á»›t qua arxiv, chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng tháº¥y cÃ¡c xu hÆ°á»›ng nghiÃªn cá»©u ML nÃ o Ä‘ang lÃ  â€œtrendyâ€. CÃ³ má»™t sá»± cáº¡nh tranh Ä‘iÃªn cuá»“ng trong viá»‡c Ä‘Æ°a ra cÃ¡c SOTA. Náº¿u Google cÃ³ BERT thÃ¬ OpenAI cÃ³ GPT-3. Tuy nhiÃªn, nhá»¯ng model â€œkhá»•ng lungâ€ nÃ y chá»‰ chiáº¿m 20% trong cÃ¡c váº¥n Ä‘á» thá»±c sá»± cáº§n giáº£i quyáº¿t. Má»™t model tá»‘t á»Ÿ cÃ¡c bÃ i toÃ¡n thá»±c táº¿ luÃ´n luÃ´n cÃ³ hÃ¬nh bÃ³ng cá»§a má»™t táº­p training data cháº¥t lÆ°á»£ng. Má»i ngÆ°á»i giá» ai cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng ngay cÃ¡c pretrained model hay cÃ¡c API má»™t cÃ¡ch dá»… dÃ ng.
Má»™t cÃ´ng ty internet cÃ³ thá»ƒ cÃ³ hÃ ng triá»‡u user data trong 1 ngÃ y bÃ¬nh thÆ°á»ng. NhÆ°ng hÃ£y tÆ°á»Ÿng tÆ°á»£ng vá» viá»‡c triá»ƒn khai AI cho má»™t mÃ´i trÆ°á»ng khÃ¡c, cháº³ng háº¡n nhÆ° nÃ´ng nghiá»‡p hoáº·c chÄƒm sÃ³c sá»©c khá»e, nhá»¯ng nÆ¡i khÃ´ng bao giá» cÃ³ Ä‘á»§ dá»¯ liá»‡u. Báº¡n khÃ´ng thá»ƒ mong chá» cÃ³ má»™t triá»‡u mÃ¡y kÃ©o hay má»™t triá»‡u áº£nh chá»¥p xquang! Trong khi cÃ¡c táº­p dá»¯ liá»‡u nhá» hÆ¡n gáº·p nhiá»u váº¥n Ä‘á» vá»›i outlier vÃ  noisy data, khá»‘i lÆ°á»£ng dá»¯ liá»‡u lá»›n hÆ¡n láº¡i gáº·p váº¥n Ä‘á» trong viá»‡c gÃ¡n nhÃ£n. LÃ m tháº¿ nÃ o Ä‘á»ƒ tiáº¿p cáº­n vÃ  há»£p tÃ¡c Ä‘Æ°á»£c vá»›i cÃ¡c chuyÃªn gia trong cÃ¡ch chuyÃªn ngÃ nh háº¹p cÅ©ng lÃ  má»™t trong cÃ¡c nÃºt tháº¯t cá»• chai Ä‘á»ƒ thu tháº­p Ä‘Æ°á»£c cÃ¡c táº­p dá»¯ liá»‡u lá»›n vá»›i cháº¥t lÆ°á»£ng gÃ¡n nhÃ£n cao. Theo cÃ¡c chuyÃªn gia, chÆ°a kiá»ƒm Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡c táº­p dá»¯ liá»‡u lÃ  má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n khi triá»ƒn khai cÃ¡c giáº£i phÃ¡p há»c mÃ¡y tá»« phÃ²ng thÃ­ nghiá»‡m ra sáº£n pháº©m thá»±c táº¿.
VÃ¬ váº­y, Prof. Andrew cÃ³ Ä‘Æ°a ra má»™t sá»‘ Ä‘á» xuáº¥t giÃºp triá»ƒn khai ML má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n:
Nhiá»‡m vá»¥ quan trá»ng nháº¥t cá»§a MLOps chÃ­nh lÃ  cung cáº¥p dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao.
ChÃ¬a khÃ³a á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  tÃ­nh nháº¥t quÃ¡n cá»§a label â€“ lÃ m tháº¿ nÃ o Ä‘á»ƒ kiá»ƒm tra vÃ  giÃºp cho viá»‡c gÃ¡n nhÃ£n cá»§a cÃ¡c Ä‘á»™i gÃ¡n nhÃ£n Ä‘Æ°á»£c nháº¥t quÃ¡n.
Cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»¯ liá»‡u trÃªn basic model > cháº¡y theo cÃ¡c SOTA model vá»›i dá»¯ liá»‡u kÃ©m cháº¥t lÆ°á»£ng.
Trong trÆ°á»ng há»£p cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh training, hÃ£y láº¥y dá»¯ liá»‡u lÃ m trung tÃ¢m.
Khi lÃ m viá»‡c vá»›i cÃ¡c táº­p dá»¯ liá»‡u nhá», cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ nÃ¢ng cao cháº¥t lÆ°á»£ng dá»¯ liá»‡u Ä‘Ã³ng vai trÃ² quan trá»ng.
Ã”ng muá»‘n phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ MLOps giÃºp táº¡o ra cÃ¡c bá»™ dá»¯ liá»‡u vÃ  há»‡ thá»‘ng AI tá»‘t hÆ¡n trong tÆ°Æ¡ng lai mÃ  khÃ´ng chá»‰ dá»±a vÃ o cÃ¡c ká»¹ sÆ° Ä‘á»ƒ tÃ¬m ra cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ cáº£i thiá»‡n táº­p dá»¯ liá»‡u. CÃ³ váº» nhÆ° MLOps sáº½ lÃ  má»™t lÄ©nh vá»±c má»›i vÃ  ráº¥t triá»ƒn vá»ng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n vá» dá»¯ liá»‡u.
ÄÃ¢y lÃ  má»™t báº£n lÆ°á»£c dá»‹ch cá»§a mÃ¬nh, cÃ¡c báº¡n cÃ³ thá»ƒ xem báº£n dá»‹ch gá»‘c á»Ÿ Ä‘Ã¢y:
https://analyticsindiamag.com/big-data-to-good-data.../
Tuáº§n trÆ°á»›c, Prof. Andrew Ng cÅ©ng cÃ³ 1 buá»•i streaming dÃ i 1 tiáº¿ng vá» chá»§ Ä‘á» nÃ y, cÃ¡c báº¡n quan tÃ¢m hÆ¡n cÃ³ thá»ƒ xem video á»Ÿ Ä‘Ã¢y:
https://www.youtube.com/watch?v=06-AZXmwHjo
Translator: Ha Na Nguyen
P/s: Hiá»‡n táº¡i Trung tÃ¢m nghiÃªn cá»©u vÃ  á»©ng dá»¥ng AI - QAI (FPT Software Quy NhÆ¡n) giá»›i thiá»‡u chÆ°Æ¡ng trÃ¬nh há»c bá»•ng Machine Learning vÃ  Data Science dÃ nh cho 200 há»c viÃªn vá»›i má»©c lÆ°Æ¡ng vÃ  Ä‘Ã£i ngá»™ háº¥p dáº«n nháº¥t thá»‹ trÆ°á»ng, ngay táº¡i FPT Software Quy NhÆ¡n.
ÄÄƒng kÃ½ Ä‘á»ƒ trá»Ÿ thÃ nh á»©ng viÃªn tiá»m nÄƒng
https://forms.gle/UFZMWBfPqtjYnKtQA","Tá»« dá»¯ liá»‡u lá»›n Ä‘áº¿n dá»¯ liá»‡u tá»‘t: Prof. Andrew Ng kÃªu gá»i cá»™ng Ä‘á»“ng ML táº­p trung vÃ o dá»¯ liá»‡u hÆ¡n so vá»›i model Hiá»‡n nay, cÃ¡c thÃ nh tá»±u trong lÄ©nh vá»±c ML Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn theo xu hÆ°á»›ng táº£i xuá»‘ng cÃ¡c model vÃ  cá»‘ gáº¯ng cáº£i thiá»‡n káº¿t quáº£ trÃªn cÃ¡c táº­p dataset tiÃªu chuáº©n. Pháº§n lá»›n thá»i gian, má»i ngÆ°á»i Ä‘ang sá»­ dá»¥ng cho viá»‡c cáº£i thiá»‡n code, model hoáº·c cÃ¡c thuáº­t toÃ¡n. Prof. Andrew Ng cho ráº±ng â€œTrong ráº¥t nhiá»u bÃ i toÃ¡n, tÃ´i nháº­n ra ráº±ng sáº½ ráº¥t há»¯u Ã­ch náº¿u chÃºng ta hÆ°á»›ng tÆ° duy vá» viá»‡c khÃ´ng chá»‰ cáº£i thiá»‡n mÃ£ mÃ  cÃ²n cáº§n cáº£i thiá»‡n dá»¯ liá»‡u theo má»™t cÃ¡ch há»‡ thá»‘ng hÆ¡n. Thá»i gian gáº§n Ä‘Ã¢y, Prof. Andrew Ng Ä‘Ã£ thu hÃºt cá»™ng Ä‘á»“ng ML vÃ o MLOps, má»™t lÄ©nh vá»±c giÃºp giáº£i quyáº¿t viá»‡c xÃ¢y dá»±ng vÃ  triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh ML má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng hÆ¡n. Prof. Andrew Ng Ä‘Æ°a ra quan Ä‘iá»ƒm vá» viá»‡c tÄƒng tá»‘c viá»‡c phÃ¡t triá»ƒn cÃ¡c há»‡ thá»‘ng há»c mÃ¡y náº¿u chÃºng ta táº­p trung nhiá»u hÆ¡n vÃ o dá»¯ liá»‡u so vá»›i viá»‡c láº¥y mÃ´ hÃ¬nh lÃ m trung tÃ¢m. Pháº§n má»m truyá»n thá»‘ng chá»‰ Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch Ä‘oáº¡n mÃ£, trong khi cÃ¡c há»‡ thá»‘ng AI Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch sá»­ dá»¥ng cáº£ mÃ£ (mÃ´ hÃ¬nh + thuáº­t toÃ¡nâ€) vÃ  dá»¯ liá»‡u. â€œKhi cÃ³ má»™t há»‡ thá»‘ng AI lÃ m viá»‡c chÆ°a thá»±c sá»± tá»‘t, má»i ngÆ°á»i â€“ theo báº£n nÄƒng sáº½ cáº¯m Ä‘áº§u vÃ o viá»‡c cáº£i thiá»‡n cÃ¡c Ä‘oáº¡n mÃ£. Äá»‘i vá»›i cÃ¡c á»©ng dá»¥ng thá»±c táº¿, táº­p trung vÃ o viá»‡c cáº£i thiá»‡n dá»¯ liá»‡u sáº½ hiá»‡u quáº£ hÆ¡nâ€. Prof. Andrew Ng cho ráº±ng tiáº¿n bá»™ trong ML Ä‘ang Ä‘Æ°á»£c thÃºc Ä‘áº©y báº±ng cÃ¡c ná»— lá»±c cáº£i thiá»‡n benchmark trÃªn cÃ¡c bá»™ dá»¯ liá»‡u chuáº©n. Thá»±c táº¿ phá»• biáº¿n lÃ  cÃ¡c researchers thÆ°á»ng giá»¯ cá»‘ Ä‘á»‹nh dá»¯ liá»‡u vÃ  táº­p trung vÃ o viá»‡c cáº£i thiá»‡n mÃ£. Tuy nhiÃªn, vá»›i cÃ¡c táº­p dá»¯ liá»‡u khiÃªm tá»‘n, Ã´ng cho ráº±ng cÃ¡c team sáº½ Ä‘áº¡t Ä‘Æ°á»£c tiáº¿n bá»™ nhanh hÆ¡n náº¿u chÃºng ta cÃ³ dá»¯ liá»‡u tá»‘t hÆ¡n. NgÆ°á»i ta thÆ°á»ng truyá»n tai nhau ráº±ng 80% cá»§a 1 ML project lÃ  lÃ m sáº¡ch dá»¯ liá»‡u. Prof. Andrew Ä‘áº·t ra cÃ¢u há»i, ráº±ng náº¿u 80% thá»i gian lÃ  chuáº©n bá»‹ dá»¯ liá»‡u thÃ¬ táº¡i sao chÃºng ta láº¡i khÃ´ng Ä‘áº£m báº£o ráº±ng cháº¥t lÆ°á»£ng dá»¯ liá»‡u lÃ  yáº¿u tá»‘ quan trá»ng hÃ ng Ä‘áº§u cho 1 ML project? DÆ°á»ng nhÆ° khÃ´ng ai quan tÃ¢m Ä‘áº¿n Ä‘iá»u nÃ y. LÆ°á»›t qua arxiv, chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng tháº¥y cÃ¡c xu hÆ°á»›ng nghiÃªn cá»©u ML nÃ o Ä‘ang lÃ  â€œtrendyâ€. CÃ³ má»™t sá»± cáº¡nh tranh Ä‘iÃªn cuá»“ng trong viá»‡c Ä‘Æ°a ra cÃ¡c SOTA. Náº¿u Google cÃ³ BERT thÃ¬ OpenAI cÃ³ GPT-3. Tuy nhiÃªn, nhá»¯ng model â€œkhá»•ng lungâ€ nÃ y chá»‰ chiáº¿m 20% trong cÃ¡c váº¥n Ä‘á» thá»±c sá»± cáº§n giáº£i quyáº¿t. Má»™t model tá»‘t á»Ÿ cÃ¡c bÃ i toÃ¡n thá»±c táº¿ luÃ´n luÃ´n cÃ³ hÃ¬nh bÃ³ng cá»§a má»™t táº­p training data cháº¥t lÆ°á»£ng. Má»i ngÆ°á»i giá» ai cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng ngay cÃ¡c pretrained model hay cÃ¡c API má»™t cÃ¡ch dá»… dÃ ng. Má»™t cÃ´ng ty internet cÃ³ thá»ƒ cÃ³ hÃ ng triá»‡u user data trong 1 ngÃ y bÃ¬nh thÆ°á»ng. NhÆ°ng hÃ£y tÆ°á»Ÿng tÆ°á»£ng vá» viá»‡c triá»ƒn khai AI cho má»™t mÃ´i trÆ°á»ng khÃ¡c, cháº³ng háº¡n nhÆ° nÃ´ng nghiá»‡p hoáº·c chÄƒm sÃ³c sá»©c khá»e, nhá»¯ng nÆ¡i khÃ´ng bao giá» cÃ³ Ä‘á»§ dá»¯ liá»‡u. Báº¡n khÃ´ng thá»ƒ mong chá» cÃ³ má»™t triá»‡u mÃ¡y kÃ©o hay má»™t triá»‡u áº£nh chá»¥p xquang! Trong khi cÃ¡c táº­p dá»¯ liá»‡u nhá» hÆ¡n gáº·p nhiá»u váº¥n Ä‘á» vá»›i outlier vÃ  noisy data, khá»‘i lÆ°á»£ng dá»¯ liá»‡u lá»›n hÆ¡n láº¡i gáº·p váº¥n Ä‘á» trong viá»‡c gÃ¡n nhÃ£n. LÃ m tháº¿ nÃ o Ä‘á»ƒ tiáº¿p cáº­n vÃ  há»£p tÃ¡c Ä‘Æ°á»£c vá»›i cÃ¡c chuyÃªn gia trong cÃ¡ch chuyÃªn ngÃ nh háº¹p cÅ©ng lÃ  má»™t trong cÃ¡c nÃºt tháº¯t cá»• chai Ä‘á»ƒ thu tháº­p Ä‘Æ°á»£c cÃ¡c táº­p dá»¯ liá»‡u lá»›n vá»›i cháº¥t lÆ°á»£ng gÃ¡n nhÃ£n cao. Theo cÃ¡c chuyÃªn gia, chÆ°a kiá»ƒm Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡c táº­p dá»¯ liá»‡u lÃ  má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n khi triá»ƒn khai cÃ¡c giáº£i phÃ¡p há»c mÃ¡y tá»« phÃ²ng thÃ­ nghiá»‡m ra sáº£n pháº©m thá»±c táº¿. VÃ¬ váº­y, Prof. Andrew cÃ³ Ä‘Æ°a ra má»™t sá»‘ Ä‘á» xuáº¥t giÃºp triá»ƒn khai ML má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n: Nhiá»‡m vá»¥ quan trá»ng nháº¥t cá»§a MLOps chÃ­nh lÃ  cung cáº¥p dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao. ChÃ¬a khÃ³a á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  tÃ­nh nháº¥t quÃ¡n cá»§a label â€“ lÃ m tháº¿ nÃ o Ä‘á»ƒ kiá»ƒm tra vÃ  giÃºp cho viá»‡c gÃ¡n nhÃ£n cá»§a cÃ¡c Ä‘á»™i gÃ¡n nhÃ£n Ä‘Æ°á»£c nháº¥t quÃ¡n. Cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»¯ liá»‡u trÃªn basic model > cháº¡y theo cÃ¡c SOTA model vá»›i dá»¯ liá»‡u kÃ©m cháº¥t lÆ°á»£ng. Trong trÆ°á»ng há»£p cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh training, hÃ£y láº¥y dá»¯ liá»‡u lÃ m trung tÃ¢m. Khi lÃ m viá»‡c vá»›i cÃ¡c táº­p dá»¯ liá»‡u nhá», cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ nÃ¢ng cao cháº¥t lÆ°á»£ng dá»¯ liá»‡u Ä‘Ã³ng vai trÃ² quan trá»ng. Ã”ng muá»‘n phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ MLOps giÃºp táº¡o ra cÃ¡c bá»™ dá»¯ liá»‡u vÃ  há»‡ thá»‘ng AI tá»‘t hÆ¡n trong tÆ°Æ¡ng lai mÃ  khÃ´ng chá»‰ dá»±a vÃ o cÃ¡c ká»¹ sÆ° Ä‘á»ƒ tÃ¬m ra cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ cáº£i thiá»‡n táº­p dá»¯ liá»‡u. CÃ³ váº» nhÆ° MLOps sáº½ lÃ  má»™t lÄ©nh vá»±c má»›i vÃ  ráº¥t triá»ƒn vá»ng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n vá» dá»¯ liá»‡u. ÄÃ¢y lÃ  má»™t báº£n lÆ°á»£c dá»‹ch cá»§a mÃ¬nh, cÃ¡c báº¡n cÃ³ thá»ƒ xem báº£n dá»‹ch gá»‘c á»Ÿ Ä‘Ã¢y: https://analyticsindiamag.com/big-data-to-good-data.../ Tuáº§n trÆ°á»›c, Prof. Andrew Ng cÅ©ng cÃ³ 1 buá»•i streaming dÃ i 1 tiáº¿ng vá» chá»§ Ä‘á» nÃ y, cÃ¡c báº¡n quan tÃ¢m hÆ¡n cÃ³ thá»ƒ xem video á»Ÿ Ä‘Ã¢y: https://www.youtube.com/watch?v=06-AZXmwHjo Translator: Ha Na Nguyen P/s: Hiá»‡n táº¡i Trung tÃ¢m nghiÃªn cá»©u vÃ  á»©ng dá»¥ng AI - QAI (FPT Software Quy NhÆ¡n) giá»›i thiá»‡u chÆ°Æ¡ng trÃ¬nh há»c bá»•ng Machine Learning vÃ  Data Science dÃ nh cho 200 há»c viÃªn vá»›i má»©c lÆ°Æ¡ng vÃ  Ä‘Ã£i ngá»™ háº¥p dáº«n nháº¥t thá»‹ trÆ°á»ng, ngay táº¡i FPT Software Quy NhÆ¡n. ÄÄƒng kÃ½ Ä‘á»ƒ trá»Ÿ thÃ nh á»©ng viÃªn tiá»m nÄƒng https://forms.gle/UFZMWBfPqtjYnKtQA",,,,,
"[AI Share]
Tá»•ng há»£p cÃ¡c cheat sheats cho ngÆ°á»i má»›i há»c vá» Data Science Ä‘á»ƒ dá»… dÃ ng tÃ¬m hiá»ƒu vÃ  tra cá»©u.
HÃ´m trÆ°á»›c AI4E Ä‘Ã£ chia sáº» cÃ¡c cheat sheets vá» Python basic, sklearn, numpy, pandas. HÃ´m nay AI4E sáº½ chia sáº» thÃªm má»™t sá»‘ cheat sheets nÃ¢ng cao hÆ¡n.
â€¢ Data Science for Business Learders: tá»•ng quan vá» Khoa há»c dá»¯ liá»‡u, cÃ¡ch xÃ¢y dá»±ng team vÃ  cÃ¡c bÆ°á»›c phá»• biáº¿n trong workflow khoa há»c dá»¯ liá»‡u
â€¢ Data Manipulation ( Thao tÃ¡c vá»›i dá»¯ liá»‡u)
- Pandas Data Wrangling Cheat Sheet
â€¢ Data Visualization ( Trá»±c quan hÃ³a dá»¯ liá»‡u)
- Matplotlib Cheat Sheet
- Seaborn Cheat Sheet
- Bokeh Cheat Sheet
â€¢ Scipy : thÆ° viá»‡n há»— trá»£ cÃ¡c phÃ©p toÃ¡n trong Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh ( vÃ­ dá»¥ ma tráº­n)
- Scipy Linear Algebra Cheat Sheet
â€¢ Keras : thÆ° viá»‡n Deep Learning
- Keras Cheat Sheet
â€¢ spaCy : thÆ° viá»‡n NLP ( cÃ¡ch load model, xá»­ lÃ­ text,â€¦)
â€¢ Importing data ( má»™t sá»‘ cÃ¡ch láº¥y dá»¯ liá»‡u tá»« cÃ¡c tá»‡p txt, csv, cÃ¡c tá»‡p táº¡o ra tá»« Excel, Matlab hoáº·c SQL)
â€¢ IDE :
- Jupyter Notebook Cheat Sheet","[AI Share] Tá»•ng há»£p cÃ¡c cheat sheats cho ngÆ°á»i má»›i há»c vá» Data Science Ä‘á»ƒ dá»… dÃ ng tÃ¬m hiá»ƒu vÃ  tra cá»©u. HÃ´m trÆ°á»›c AI4E Ä‘Ã£ chia sáº» cÃ¡c cheat sheets vá» Python basic, sklearn, numpy, pandas. HÃ´m nay AI4E sáº½ chia sáº» thÃªm má»™t sá»‘ cheat sheets nÃ¢ng cao hÆ¡n. â€¢ Data Science for Business Learders: tá»•ng quan vá» Khoa há»c dá»¯ liá»‡u, cÃ¡ch xÃ¢y dá»±ng team vÃ  cÃ¡c bÆ°á»›c phá»• biáº¿n trong workflow khoa há»c dá»¯ liá»‡u â€¢ Data Manipulation ( Thao tÃ¡c vá»›i dá»¯ liá»‡u) - Pandas Data Wrangling Cheat Sheet â€¢ Data Visualization ( Trá»±c quan hÃ³a dá»¯ liá»‡u) - Matplotlib Cheat Sheet - Seaborn Cheat Sheet - Bokeh Cheat Sheet â€¢ Scipy : thÆ° viá»‡n há»— trá»£ cÃ¡c phÃ©p toÃ¡n trong Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh ( vÃ­ dá»¥ ma tráº­n) - Scipy Linear Algebra Cheat Sheet â€¢ Keras : thÆ° viá»‡n Deep Learning - Keras Cheat Sheet â€¢ spaCy : thÆ° viá»‡n NLP ( cÃ¡ch load model, xá»­ lÃ­ text,â€¦) â€¢ Importing data ( má»™t sá»‘ cÃ¡ch láº¥y dá»¯ liá»‡u tá»« cÃ¡c tá»‡p txt, csv, cÃ¡c tá»‡p táº¡o ra tá»« Excel, Matlab hoáº·c SQL) â€¢ IDE : - Jupyter Notebook Cheat Sheet",,,,,
"Cuá»‘n ""Machine Learning vá»›i dá»¯ liá»‡u dáº¡ng báº£ng"" Ä‘Ã£ cÃ³ thÃªm má»™t vÃ i má»¥c má»›i vá» lÃ m sáº¡ch dá»¯ liá»‡u vÃ  cÃ¡c ká»¹ thuáº­t xÃ¢y dá»±ng Ä‘áº·c trÆ°ng cho dá»¯ liá»‡u dáº¡ng háº¡ng má»¥c. Má»i cÃ¡c báº¡n Ä‘á»c vÃ  Ä‘Ã¡nh giÃ¡.","Cuá»‘n ""Machine Learning vá»›i dá»¯ liá»‡u dáº¡ng báº£ng"" Ä‘Ã£ cÃ³ thÃªm má»™t vÃ i má»¥c má»›i vá» lÃ m sáº¡ch dá»¯ liá»‡u vÃ  cÃ¡c ká»¹ thuáº­t xÃ¢y dá»±ng Ä‘áº·c trÆ°ng cho dá»¯ liá»‡u dáº¡ng háº¡ng má»¥c. Má»i cÃ¡c báº¡n Ä‘á»c vÃ  Ä‘Ã¡nh giÃ¡.",,,,,
"Xin chÃ o má»i ngÆ°á»i!
Hiá»‡n táº¡i em Ä‘ang cáº§n bá»™ dataset Megaface nguyÃªn báº£n mÃ  web dÆ°á»›i Ä‘Ã¢y há» khÃ´ng cÃ²n cho download ná»¯a.
http://megaface.cs.washington.edu/
Má»i ngÆ°á»i náº¿u ai down rá»“i thÃ¬ share cho em vá»›i áº¡.
Em cáº£m Æ¡n áº¡.",Xin chÃ o má»i ngÆ°á»i! Hiá»‡n táº¡i em Ä‘ang cáº§n bá»™ dataset Megaface nguyÃªn báº£n mÃ  web dÆ°á»›i Ä‘Ã¢y há» khÃ´ng cÃ²n cho download ná»¯a. http://megaface.cs.washington.edu/ Má»i ngÆ°á»i náº¿u ai down rá»“i thÃ¬ share cho em vá»›i áº¡. Em cáº£m Æ¡n áº¡.,,,,,
"[Series Pytorch]
BÃ i 5: Transfer Learning trong Pytorch
BÃ i nÃ y mÃ¬nh sáº½ hÆ°á»›ng dáº«n sá»­ dá»¥ng transfer learning trong Pytorch. Pháº§n Ä‘áº§u mÃ¬nh sáº½ hÆ°á»›ng dáº«n sá»­ dá»¥ng pre-trained model Ä‘á»ƒ dá»± Ä‘oÃ¡n, pháº§n sau mÃ¬nh sáº½ hÆ°á»›ng dáº«n fine-tune pre-trained model.","[Series Pytorch] BÃ i 5: Transfer Learning trong Pytorch BÃ i nÃ y mÃ¬nh sáº½ hÆ°á»›ng dáº«n sá»­ dá»¥ng transfer learning trong Pytorch. Pháº§n Ä‘áº§u mÃ¬nh sáº½ hÆ°á»›ng dáº«n sá»­ dá»¥ng pre-trained model Ä‘á»ƒ dá»± Ä‘oÃ¡n, pháº§n sau mÃ¬nh sáº½ hÆ°á»›ng dáº«n fine-tune pre-trained model.",,,,,
"Sau khi tÃ¬m hiá»ƒu vá» máº¡ng NÆ¡-ron nhÃ¢n táº¡o trong dá»± bÃ¡o Time-Series Anh chá»‹ cho em há»i má»™t sá»‘ cÃ¢u há»i e Ä‘ang tháº¯c máº¯c vá»›i áº¡.
1) Æ¯u Ä‘iá»ƒm cá»§a máº¡ng NÆ¡-ron (cá»¥ thá»ƒ lÃ  máº¡ng RNN LSTM, GRU) trong dá»± bÃ¡o dá»¯ liá»‡u time-series ?
2) NhÆ°á»£c Ä‘iá»ƒm cá»§a máº¡ng nÆ¡-ron nÃ³i chung vÃ  nhÆ°á»£c Ä‘iá»ƒm cá»§a RNN, LSTM, GRU nÃ³i riÃªng.
3) Máº¡ng NÆ¡-ron cÃ³ gÃ¬ tá»‘t hÆ¡n khi lÃ m viá»‡c vá»›i time-series so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p machine learning khÃ¡c ( cÃ³ 12 phÆ°Æ¡ng phÃ¡p khÃ¡c nhau)
Ráº¥t mong cÃ¡c anh chá»‹ giÃºp em vá»›i áº¡.","Sau khi tÃ¬m hiá»ƒu vá» máº¡ng NÆ¡-ron nhÃ¢n táº¡o trong dá»± bÃ¡o Time-Series Anh chá»‹ cho em há»i má»™t sá»‘ cÃ¢u há»i e Ä‘ang tháº¯c máº¯c vá»›i áº¡. 1) Æ¯u Ä‘iá»ƒm cá»§a máº¡ng NÆ¡-ron (cá»¥ thá»ƒ lÃ  máº¡ng RNN LSTM, GRU) trong dá»± bÃ¡o dá»¯ liá»‡u time-series ? 2) NhÆ°á»£c Ä‘iá»ƒm cá»§a máº¡ng nÆ¡-ron nÃ³i chung vÃ  nhÆ°á»£c Ä‘iá»ƒm cá»§a RNN, LSTM, GRU nÃ³i riÃªng. 3) Máº¡ng NÆ¡-ron cÃ³ gÃ¬ tá»‘t hÆ¡n khi lÃ m viá»‡c vá»›i time-series so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p machine learning khÃ¡c ( cÃ³ 12 phÆ°Æ¡ng phÃ¡p khÃ¡c nhau) Ráº¥t mong cÃ¡c anh chá»‹ giÃºp em vá»›i áº¡.",,,,,
Mn cho em há»i cÃ³ cÃ¡ch nÃ o táº£i bá»™ dá»¯ liá»‡u MNIST ná»¯a ko áº¡. Em lÃªn trang chá»§ nhÆ°ng bá»‹ lá»—i nhÆ° nÃ y. Em cáº£m Æ¡n mn nhiá»u.,Mn cho em há»i cÃ³ cÃ¡ch nÃ o táº£i bá»™ dá»¯ liá»‡u MNIST ná»¯a ko áº¡. Em lÃªn trang chá»§ nhÆ°ng bá»‹ lá»—i nhÆ° nÃ y. Em cáº£m Æ¡n mn nhiá»u.,,,,,
#Book,,#Book,,,,
"Dear all, trÆ°á»›c Ä‘Ã³ cÃ³ Ä‘á»c bÃ i cá»§a anh Tuáº¥n Linh vá» docker, hiá»‡n táº¡i mÃ¬nh cÅ©ng má»›i tÃ¬m hiá»ƒu vá» docker. HÃ´m nay mÃ¬nh xin chia sáº» vá»›i cÃ¡c báº¡n cÃ¡ch cÃ i docker (thay vÃ¬ cÃ i pytorch vÃ  cuda-toolkit cho GPU) , cÃ i nvidia-docker vÃ  cÃ¡ch huáº¥n luyá»‡n model phÃ¢n loáº¡i chÃ³/mÃ¨o bÃªn trong docker nividia/pytorch:21.03-py3
#BÆ°á»›c 1. CÃ i docker theo hÆ°á»›ng dáº«n táº¡i Ä‘Ã¢y
https://linuxhint.com/install_configure_docker_ubuntu/
#BÆ°á»›c 2: pull images from NIVIDIA CHO PYTORCH
$ docker pull nvcr.io/nvidia/pytorch:21.03-py3
#BÆ°á»›c 3: PULL nvidia/cuda:11.1-base images (maybe cuda:10.0; cuda:11.0, ect)
$ docker pull nvidia/cuda:11.0-base #for lastest image
$ nvidia-smi
# BÆ°á»›c 4: kiá»ƒm tra cÃ¡c images
$ docker images
# BÆ°á»›c 5: táº£i, giáº£i nÃ©n 1 repo trÃªn github.com, Ä‘á»‹a chá»‰ táº¡i Ä‘Ã¢y: https://github.com/ardamavi/Dog-Cat-Classifier. Sau Ä‘Ã³, chá»‰nh láº¡i tÃªn folder thÃ nh dogcat, chá»‰nh Ä‘Æ°á»ng dáº«n trong file train.py (dÃ²ng 22 data_dir=""/dogcat/data_dir/ vÃ  táº¡i dÃ²ng 246 torch.save(checkpoint, '/dogcat/mod_densenet.pth')
# BÆ°á»›c 6: táº£i, giáº£i nÃ©n dataset tá»« Ä‘Ã¢y: https://www.kaggle.com/tongpython/cat-and-dog
# LÆ°u Ã½ chuyá»ƒn folder ra thÃ nh dáº¡ng data_dir chá»©a 2 táº­p train vÃ  test sets (trong má»—i folder train vÃ  test sets chá»©a 2 folders lÃ  dog vÃ  cat). Sau Ä‘Ã³ chuyá»ƒn toÃ n bá»™ folder data_dir nÃ y vÃ o trong folder dogcat Ä‘á»ƒ tiá»‡n cho viá»‡c mount workspace.
# BÆ°á»›c 7: mount folder dogcat chá»©a code vÃ  dataset vÃ o trong docker image lÃ  pytorch/nvidia:21.03-py3
$ docker run -it --rm --ipc=host -v /home/ten_may_cua_ban/Downloads/dogcat:/dogcat -v /home/ten_may_cua_ban/dogcat nvcr.io/nvidia/pytorch:21.03-py3
# lÆ°u Ã½: vÃ¬ lÃºc nÃ y folder Ä‘Æ°á»£c mount giá»‘ng nhÆ° ""root"" hay cÃ²n Ä‘Æ°á»£c gá»i lÃ  workspace nÃªn táº¥t cáº£ má»i thá»© Ä‘á»u báº¯t Ä‘áº§u Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  /dogcat/ (nÃ³ tÆ°Æ¡ng tá»± nhÆ° /home/ trong Ubuntu)
# BÆ°á»›c 8: Run repo
root@imageid:/workspace# python /dogcat/train.py
Váº­y lÃ  chÃºng ta Ä‘Ã£ hoÃ n táº¥t cÃ¡c bÆ°á»›c cÆ¡ báº£n Ä‘á»ƒ báº¯t Ä‘áº§u khÃ¡m phÃ¡ sÃ¢u hÆ¡n vá» docker. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i viáº¿t. ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº».","Dear all, trÆ°á»›c Ä‘Ã³ cÃ³ Ä‘á»c bÃ i cá»§a anh Tuáº¥n Linh vá» docker, hiá»‡n táº¡i mÃ¬nh cÅ©ng má»›i tÃ¬m hiá»ƒu vá» docker. HÃ´m nay mÃ¬nh xin chia sáº» vá»›i cÃ¡c báº¡n cÃ¡ch cÃ i docker (thay vÃ¬ cÃ i pytorch vÃ  cuda-toolkit cho GPU) , cÃ i nvidia-docker vÃ  cÃ¡ch huáº¥n luyá»‡n model phÃ¢n loáº¡i chÃ³/mÃ¨o bÃªn trong docker nividia/pytorch:21.03-py3 1. CÃ i docker theo hÆ°á»›ng dáº«n táº¡i Ä‘Ã¢y https://linuxhint.com/install_configure_docker_ubuntu/ 2: pull images from NIVIDIA CHO PYTORCH $ docker pull nvcr.io/nvidia/pytorch:21.03-py3 3: PULL nvidia/cuda:11.1-base images (maybe cuda:10.0; cuda:11.0, ect) $ docker pull nvidia/cuda:11.0-base lastest image $ nvidia-smi # BÆ°á»›c 4: kiá»ƒm tra cÃ¡c images $ docker images # BÆ°á»›c 5: táº£i, giáº£i nÃ©n 1 repo trÃªn github.com, Ä‘á»‹a chá»‰ táº¡i Ä‘Ã¢y: https://github.com/ardamavi/Dog-Cat-Classifier. Sau Ä‘Ã³, chá»‰nh láº¡i tÃªn folder thÃ nh dogcat, chá»‰nh Ä‘Æ°á»ng dáº«n trong file train.py (dÃ²ng 22 data_dir=""/dogcat/data_dir/ vÃ  táº¡i dÃ²ng 246 torch.save(checkpoint, '/dogcat/mod_densenet.pth') # BÆ°á»›c 6: táº£i, giáº£i nÃ©n dataset tá»« Ä‘Ã¢y: https://www.kaggle.com/tongpython/cat-and-dog # LÆ°u Ã½ chuyá»ƒn folder ra thÃ nh dáº¡ng data_dir chá»©a 2 táº­p train vÃ  test sets (trong má»—i folder train vÃ  test sets chá»©a 2 folders lÃ  dog vÃ  cat). Sau Ä‘Ã³ chuyá»ƒn toÃ n bá»™ folder data_dir nÃ y vÃ o trong folder dogcat Ä‘á»ƒ tiá»‡n cho viá»‡c mount workspace. # BÆ°á»›c 7: mount folder dogcat chá»©a code vÃ  dataset vÃ o trong docker image lÃ  pytorch/nvidia:21.03-py3 $ docker run -it --rm --ipc=host -v /home/ten_may_cua_ban/Downloads/dogcat:/dogcat -v /home/ten_may_cua_ban/dogcat nvcr.io/nvidia/pytorch:21.03-py3 # lÆ°u Ã½: vÃ¬ lÃºc nÃ y folder Ä‘Æ°á»£c mount giá»‘ng nhÆ° ""root"" hay cÃ²n Ä‘Æ°á»£c gá»i lÃ  workspace nÃªn táº¥t cáº£ má»i thá»© Ä‘á»u báº¯t Ä‘áº§u Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  /dogcat/ (nÃ³ tÆ°Æ¡ng tá»± nhÆ° /home/ trong Ubuntu) # BÆ°á»›c 8: Run repo root@imageid:/workspace# python /dogcat/train.py Váº­y lÃ  chÃºng ta Ä‘Ã£ hoÃ n táº¥t cÃ¡c bÆ°á»›c cÆ¡ báº£n Ä‘á»ƒ báº¯t Ä‘áº§u khÃ¡m phÃ¡ sÃ¢u hÆ¡n vá» docker. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i viáº¿t. ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº».",#BÆ°á»›c	#BÆ°á»›c	#BÆ°á»›c	#for,,,,
"Xin chÃ o cÃ¡c anh/chá»‹/báº¡n,
Em xin giá»›i thiá»‡u clip Ä‘áº§u tiÃªn trong playlist em tÃ­nh lÃ m vá» thá»‘ng kÃª áº¡. Do báº£n thÃ¢n Ä‘i lÃ m vÃ  Ä‘i há»c em tháº¥y thá»‘ng kÃª lÃ  má»™t mÃ´n khÃ³ vÃ  ná»n táº£ng cho nhiá»u thá»©, tuy nhiÃªn theo em biáº¿t thÃ¬ cÃ²n Ã­t ngÆ°á»i lÃ m clip vá» máº£ng nÃ y, nÃªn em quyáº¿t tÃ¢m thá»­ áº¡. VÃ¬ báº£n thÃ¢n em cÃ²n Ä‘ang trau dá»“i máº£ng nÃ y nÃªn sai sÃ³t lÃ  khÃ³ trÃ¡nh, náº¿u em cÃ³ truyá»n táº£i kiáº¿n thá»©c nÃ o sai mong cÃ¡c anh chá»‹ gÃ³p Ã½ giÃºp em.
Playlist nÃ y em sáº½ lÃ m theo cÃ¡c má»¥c lÃ½ thuyáº¿t, bÃ i táº­p thá»‘ng kÃª bÃ¬nh thÆ°á»ng, code. Ná»™i dung vÃ  Ã½ tÆ°á»Ÿng em tham kháº£o tá»« nhiá»u nguá»“n, cÃ¡c anh chá»‹ cáº§n há»c gáº¥p cÃ³ thá»ƒ tham kháº£o: Penn state university Statistic online, kÃªnh youtube StatQuest.
Em xin cáº£m Æ¡n áº¡.","Xin chÃ o cÃ¡c anh/chá»‹/báº¡n, Em xin giá»›i thiá»‡u clip Ä‘áº§u tiÃªn trong playlist em tÃ­nh lÃ m vá» thá»‘ng kÃª áº¡. Do báº£n thÃ¢n Ä‘i lÃ m vÃ  Ä‘i há»c em tháº¥y thá»‘ng kÃª lÃ  má»™t mÃ´n khÃ³ vÃ  ná»n táº£ng cho nhiá»u thá»©, tuy nhiÃªn theo em biáº¿t thÃ¬ cÃ²n Ã­t ngÆ°á»i lÃ m clip vá» máº£ng nÃ y, nÃªn em quyáº¿t tÃ¢m thá»­ áº¡. VÃ¬ báº£n thÃ¢n em cÃ²n Ä‘ang trau dá»“i máº£ng nÃ y nÃªn sai sÃ³t lÃ  khÃ³ trÃ¡nh, náº¿u em cÃ³ truyá»n táº£i kiáº¿n thá»©c nÃ o sai mong cÃ¡c anh chá»‹ gÃ³p Ã½ giÃºp em. Playlist nÃ y em sáº½ lÃ m theo cÃ¡c má»¥c lÃ½ thuyáº¿t, bÃ i táº­p thá»‘ng kÃª bÃ¬nh thÆ°á»ng, code. Ná»™i dung vÃ  Ã½ tÆ°á»Ÿng em tham kháº£o tá»« nhiá»u nguá»“n, cÃ¡c anh chá»‹ cáº§n há»c gáº¥p cÃ³ thá»ƒ tham kháº£o: Penn state university Statistic online, kÃªnh youtube StatQuest. Em xin cáº£m Æ¡n áº¡.",,,,,
"Cháº¯c cháº¯n cÃ¡c báº¡n á»Ÿ Ä‘Ã¢y ráº¥t quen thuá»™c vá»›i 1 sá»‘ cÃ´ng cá»¥ Ä‘á»ƒ táº¡o mÃ´i trÆ°á»ng lÃ m viá»‡c nhÆ° dÃ¹ng conda, pipenv, hay docker (táº¡m gá»i tháº¿ Ä‘i). MÃ¬nh cÃ³ suy nghÄ© vá» viá»‡c viáº¿t 1 sá»‘ bÃ i vá» tráº£i nghiá»‡m thá»±c táº¿ cá»§a mÃ¬nh trong viá»‡c sá»­ dá»¥ng docker! CÃ³ láº½ Ä‘á»ƒ hiá»ƒu docker, cÃ¡c báº¡n cÃ³ thá»ƒ dá»… dÃ ng google vÃ  sáº½ nháº­n Ä‘Æ°á»£c cÃ¢u giáº£i thÃ­ch lÃ  giá»‘ng ""mÃ´i trÆ°á»ng/env"", container, mÃ¡y áº£o/virtual machine, nhÆ°ng mÃ¬nh tháº¥y nÃ³ lÃ  1 áº£nh/image cÃ³ váº» há»£p lÃ­ nháº¥t. Táº¡i sao láº¡i lÃ  1 áº£nh???? Báº¡n thá»­ hÃ¬nh dung 1 chÃºt, báº¡n cÃ³ táº¥m áº£nh chá»¥p chung vá»›i Ä‘áº¡i gia Ä‘Ã¬nh cá»§a báº¡n 10 nÄƒm vá» trÆ°á»›c: gá»“m Ã´ng, bÃ , cha, máº¹, anh, chá»‹, em, con, chÃ¡u. Táº¥t nhiÃªn, vÃ¬ lÃ  thÃ nh viÃªn trong gia Ä‘Ã¬nh nÃªn Ä‘á»u ""phá»¥ thuá»™c"" vÃ o nhau. CÃ¢u há»i Ä‘áº·t ra lÃ  lÃ m sao báº¡n quay vá» Ä‘Æ°á»£c quÃ¡ khá»© 10 nÄƒm vá» trÆ°á»›c vá»›i Ä‘Ãºng bá»‘i cáº£nh Ä‘Ã³, cÃ³ láº½ cáº§n cá»— mÃ¡y thá»i gian cá»§a Doremon rá»“i. Quay láº¡i cÃ¢u chuyá»‡n thá»±c táº¿, lÃ  báº¡n cÃ³ 1 dá»± Ã¡n ráº¥t ráº¥t thÃ nh cÃ´ngcÃ¡ch Ä‘Ã¢y 5 nÄƒm, vá»›i cÃ¡c báº£n tensorflow alpha, pandas beta, numpy gamma,... táº¥t cáº£ Ä‘á»u lÃ  dependencies packages, chÆ°a ká»ƒ pháº§n cá»©ng lÃºc Ä‘Ã³. Nay dá»¯ liá»‡u nhiá»u hÆ¡n, khÃ¡ch hÃ ng muá»‘n báº¡n huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh Ä‘á»ƒ nÃ¢ng cao tráº£i nghiá»‡m khÃ¡ch hÃ ng. CÃ³ 2 cÃ¡ch, (1) lÃ  quay vá» tuá»•i thÆ¡ 5 nÄƒm trÆ°á»›c vá»›i cÃ¡c packages alpha, beta,... cÃ¢u há»i Ä‘áº·t ra lÃ  lÃ m sao cÃ i Ä‘Æ°á»£c Ä‘Ãºng cÃ¡c packages dependencies Ä‘Ã³; (2) viáº¿t láº¡i code, mÃ  codebase ráº¥t lá»›n, tiÃªu tá»‘n nguá»“n lá»±c kinh khá»§ng!. Váº­y hÆ°á»›ng giáº£i quyáº¿t lÃ  gÃ¬???? CÃ¢u tráº£ lá»i lÃ  docker image! Váº­y Docker image lÃ  gÃ¬? Táº¡i sao docker image láº¡i giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» trÃªn?,... mÃ¬nh sáº½ Ä‘á»ƒ thá»i gian Ä‘á»ƒ chÃºng ta cÃ¹ng tháº£o luáº­n trÆ°á»›c khi Ä‘i tá»›i nhá»¯ng cÃ¢u tráº£ lá»i","Cháº¯c cháº¯n cÃ¡c báº¡n á»Ÿ Ä‘Ã¢y ráº¥t quen thuá»™c vá»›i 1 sá»‘ cÃ´ng cá»¥ Ä‘á»ƒ táº¡o mÃ´i trÆ°á»ng lÃ m viá»‡c nhÆ° dÃ¹ng conda, pipenv, hay docker (táº¡m gá»i tháº¿ Ä‘i). MÃ¬nh cÃ³ suy nghÄ© vá» viá»‡c viáº¿t 1 sá»‘ bÃ i vá» tráº£i nghiá»‡m thá»±c táº¿ cá»§a mÃ¬nh trong viá»‡c sá»­ dá»¥ng docker! CÃ³ láº½ Ä‘á»ƒ hiá»ƒu docker, cÃ¡c báº¡n cÃ³ thá»ƒ dá»… dÃ ng google vÃ  sáº½ nháº­n Ä‘Æ°á»£c cÃ¢u giáº£i thÃ­ch lÃ  giá»‘ng ""mÃ´i trÆ°á»ng/env"", container, mÃ¡y áº£o/virtual machine, nhÆ°ng mÃ¬nh tháº¥y nÃ³ lÃ  1 áº£nh/image cÃ³ váº» há»£p lÃ­ nháº¥t. Táº¡i sao láº¡i lÃ  1 áº£nh???? Báº¡n thá»­ hÃ¬nh dung 1 chÃºt, báº¡n cÃ³ táº¥m áº£nh chá»¥p chung vá»›i Ä‘áº¡i gia Ä‘Ã¬nh cá»§a báº¡n 10 nÄƒm vá» trÆ°á»›c: gá»“m Ã´ng, bÃ , cha, máº¹, anh, chá»‹, em, con, chÃ¡u. Táº¥t nhiÃªn, vÃ¬ lÃ  thÃ nh viÃªn trong gia Ä‘Ã¬nh nÃªn Ä‘á»u ""phá»¥ thuá»™c"" vÃ o nhau. CÃ¢u há»i Ä‘áº·t ra lÃ  lÃ m sao báº¡n quay vá» Ä‘Æ°á»£c quÃ¡ khá»© 10 nÄƒm vá» trÆ°á»›c vá»›i Ä‘Ãºng bá»‘i cáº£nh Ä‘Ã³, cÃ³ láº½ cáº§n cá»— mÃ¡y thá»i gian cá»§a Doremon rá»“i. Quay láº¡i cÃ¢u chuyá»‡n thá»±c táº¿, lÃ  báº¡n cÃ³ 1 dá»± Ã¡n ráº¥t ráº¥t thÃ nh cÃ´ngcÃ¡ch Ä‘Ã¢y 5 nÄƒm, vá»›i cÃ¡c báº£n tensorflow alpha, pandas beta, numpy gamma,... táº¥t cáº£ Ä‘á»u lÃ  dependencies packages, chÆ°a ká»ƒ pháº§n cá»©ng lÃºc Ä‘Ã³. Nay dá»¯ liá»‡u nhiá»u hÆ¡n, khÃ¡ch hÃ ng muá»‘n báº¡n huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh Ä‘á»ƒ nÃ¢ng cao tráº£i nghiá»‡m khÃ¡ch hÃ ng. CÃ³ 2 cÃ¡ch, (1) lÃ  quay vá» tuá»•i thÆ¡ 5 nÄƒm trÆ°á»›c vá»›i cÃ¡c packages alpha, beta,... cÃ¢u há»i Ä‘áº·t ra lÃ  lÃ m sao cÃ i Ä‘Æ°á»£c Ä‘Ãºng cÃ¡c packages dependencies Ä‘Ã³; (2) viáº¿t láº¡i code, mÃ  codebase ráº¥t lá»›n, tiÃªu tá»‘n nguá»“n lá»±c kinh khá»§ng!. Váº­y hÆ°á»›ng giáº£i quyáº¿t lÃ  gÃ¬???? CÃ¢u tráº£ lá»i lÃ  docker image! Váº­y Docker image lÃ  gÃ¬? Táº¡i sao docker image láº¡i giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» trÃªn?,... mÃ¬nh sáº½ Ä‘á»ƒ thá»i gian Ä‘á»ƒ chÃºng ta cÃ¹ng tháº£o luáº­n trÆ°á»›c khi Ä‘i tá»›i nhá»¯ng cÃ¢u tráº£ lá»i",,,,,
,nan,,,,,
"CÃ³ ai Ä‘Ã£ train models sá»­ dá»¥ng docker cá»§a NVIDIA hay chÆ°a cho mÃ¬nh há»i 1 chÃºt! MÃ¬nh Ä‘Ã£ pull, attach images, train models ngon lÃ nh, nhÆ°ng chá»‰ cÃ³ Ä‘iá»u tÃ¬m mÃ£i khÃ´ng tháº¥y trained weights Ä‘Ã¢u cáº£, dÃ¹ message thÃ´ng bÃ¡o lÃ  Ä‘Ã£ saved. MÃ¬nh sá»­ dá»¥ng Ubuntu 20.04, docker ngc 21.03. Cáº£m Æ¡n trÆ°á»›c cÃ¡c báº¡n nhÃ©!","CÃ³ ai Ä‘Ã£ train models sá»­ dá»¥ng docker cá»§a NVIDIA hay chÆ°a cho mÃ¬nh há»i 1 chÃºt! MÃ¬nh Ä‘Ã£ pull, attach images, train models ngon lÃ nh, nhÆ°ng chá»‰ cÃ³ Ä‘iá»u tÃ¬m mÃ£i khÃ´ng tháº¥y trained weights Ä‘Ã¢u cáº£, dÃ¹ message thÃ´ng bÃ¡o lÃ  Ä‘Ã£ saved. MÃ¬nh sá»­ dá»¥ng Ubuntu 20.04, docker ngc 21.03. Cáº£m Æ¡n trÆ°á»›c cÃ¡c báº¡n nhÃ©!",,,,,
Chi sáº» vá»›i má»i ngÆ°á»i lá»—i Ethics khi lÃ m nghiÃªn cá»©u cá»§a University of Minnesota.,Chi sáº» vá»›i má»i ngÆ°á»i lá»—i Ethics khi lÃ m nghiÃªn cá»©u cá»§a University of Minnesota.,,,,,
"Xin chÃ o má»i ngÆ°á»i.
MÃ¬nh cÃ³ má»™t tháº¯c máº¯c tá»« sÃ¡ng tá»›i giá» cáº§n má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp áº¡.
Cháº£ lÃ  lÃºc sÃ¡ng tháº§y mÃ¬nh vá»«a nÃ³i vá» Æ°u Ä‘iá»ƒm cá»§a VGG so vá»›i máº¡ng khÃ¡c lÃ  dÃ¹ng hai kernel 3x3 thay vÃ¬ 5x5 Ä‘á»ƒ tiáº¿t kiá»‡m tham sá»‘ cá»§a máº¡ng. NÃªn mÃ¬nh náº£y sinh má»™t cÃ¢u há»i nhÆ° sau:
NhÆ° hÃ¬nh 1 (kiáº¿n trÃºc máº¡ng VGG), sá»‘ lÆ°á»£ng tham sá»‘ (bá» qua bias) cá»§a hai khá»‘i convolution 3x3 (lÃ  64 khá»‘i 3x3x3 vÃ  64 khá»‘i 3x3x64) láº§n lÆ°á»£t lÃ  3x3x3x64 + 3x3x64x64 = 38K params. NgÆ°á»£c láº¡i náº¿u dÃ¹ng má»™t láº§n kernel 5x5 (nghÄ©a lÃ  khá»‘i 64 khá»‘i 5x5x3) thÃ¬ chá»‰ lÃ  5x5x3x64 = 4.8K params. Output cá»§a cáº£ hai cÃ¡ch convolution trÃªn Ä‘á»u báº±ng 224x224x64 (giáº£ sá»­ cÃ³ padding). Váº­y cÃ³ thá»±c sá»± lÃ  sá»‘ tham sá»‘ Ä‘Ã£ Ä‘Æ°á»£c giáº£m khi dÃ¹ng kernel 3x3 thay vÃ¬ 5x5 hay khÃ´ng?
MÃ¬nh cÅ©ng Ä‘Ã£ thá»­ suy nghÄ© theo Ã½ cá»§a tháº§y lÃ : sá»­ dá»¥ng hai kernel 3x3 nghÄ©a lÃ  2x(3x3x3x64) thay vÃ¬ 5x5x3x64. Tuy nhiÃªn náº¿u nhÃ¢n tÃ­ch cháº­p theo kiá»ƒu 2x(3x3x3x64) thÃ¬ nÃ³ sáº½ nhÃ¢n nhÆ° tháº¿ nÃ o? Dá»±a vÃ o hÃ¬nh 2 (cÃ¡ch nhÃ¢n convolution 3D), náº¿u nhÃ¢n láº§n lÆ°á»£t tá»«ng khá»‘i convolution 3x3x3x64 thÃ¬ output láº§n nhÃ¢n Ä‘áº§u tiÃªn lÃ  224x244x64, cÃ²n output láº§n nhÃ¢n thá»© hai khÃ´ng tÃ­nh Ä‘Æ°á»£c vÃ¬ depth khÃ¡c nhau (64 vÃ  3).
Did I misunderstand something??? :(
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c.","Xin chÃ o má»i ngÆ°á»i. MÃ¬nh cÃ³ má»™t tháº¯c máº¯c tá»« sÃ¡ng tá»›i giá» cáº§n má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp áº¡. Cháº£ lÃ  lÃºc sÃ¡ng tháº§y mÃ¬nh vá»«a nÃ³i vá» Æ°u Ä‘iá»ƒm cá»§a VGG so vá»›i máº¡ng khÃ¡c lÃ  dÃ¹ng hai kernel 3x3 thay vÃ¬ 5x5 Ä‘á»ƒ tiáº¿t kiá»‡m tham sá»‘ cá»§a máº¡ng. NÃªn mÃ¬nh náº£y sinh má»™t cÃ¢u há»i nhÆ° sau: NhÆ° hÃ¬nh 1 (kiáº¿n trÃºc máº¡ng VGG), sá»‘ lÆ°á»£ng tham sá»‘ (bá» qua bias) cá»§a hai khá»‘i convolution 3x3 (lÃ  64 khá»‘i 3x3x3 vÃ  64 khá»‘i 3x3x64) láº§n lÆ°á»£t lÃ  3x3x3x64 + 3x3x64x64 = 38K params. NgÆ°á»£c láº¡i náº¿u dÃ¹ng má»™t láº§n kernel 5x5 (nghÄ©a lÃ  khá»‘i 64 khá»‘i 5x5x3) thÃ¬ chá»‰ lÃ  5x5x3x64 = 4.8K params. Output cá»§a cáº£ hai cÃ¡ch convolution trÃªn Ä‘á»u báº±ng 224x224x64 (giáº£ sá»­ cÃ³ padding). Váº­y cÃ³ thá»±c sá»± lÃ  sá»‘ tham sá»‘ Ä‘Ã£ Ä‘Æ°á»£c giáº£m khi dÃ¹ng kernel 3x3 thay vÃ¬ 5x5 hay khÃ´ng? MÃ¬nh cÅ©ng Ä‘Ã£ thá»­ suy nghÄ© theo Ã½ cá»§a tháº§y lÃ : sá»­ dá»¥ng hai kernel 3x3 nghÄ©a lÃ  2x(3x3x3x64) thay vÃ¬ 5x5x3x64. Tuy nhiÃªn náº¿u nhÃ¢n tÃ­ch cháº­p theo kiá»ƒu 2x(3x3x3x64) thÃ¬ nÃ³ sáº½ nhÃ¢n nhÆ° tháº¿ nÃ o? Dá»±a vÃ o hÃ¬nh 2 (cÃ¡ch nhÃ¢n convolution 3D), náº¿u nhÃ¢n láº§n lÆ°á»£t tá»«ng khá»‘i convolution 3x3x3x64 thÃ¬ output láº§n nhÃ¢n Ä‘áº§u tiÃªn lÃ  224x244x64, cÃ²n output láº§n nhÃ¢n thá»© hai khÃ´ng tÃ­nh Ä‘Æ°á»£c vÃ¬ depth khÃ¡c nhau (64 vÃ  3). Did I misunderstand something??? :( Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c.",,,,,
"ğŸ‰ F8 Refresh Hackathon Registration is open! ğŸ‰
ğŸ‘‡ Register for this year's F8 Hackathon at the link below:
 https://fb.me/F8-Refresh-Hackathon-Registration 
F8 has always brought together an incredible community of people who are building, innovating, and looking for whatâ€™s next. Over the past year, developers have been enabling businesses of all sizes to adapt and accelerate their digital transformation.
Weâ€™re drawing inspiration from F8â€™s early days and bringing the conference back to its roots: a place to celebrate, inspire and help developers grow. Weâ€™re excited to introduce a new virtual event format, F8 Refresh. ğŸŒâœ¨
F8 Refresh will feature the latest product tools to help you build across our family of apps, as well as technical deep-dive sessions, demos â€“ all with the goal of enabling your growth. Join us at the F8 Refresh: Hackathon for prizes, bragging rights, and more as you show off your skills to help make the world a better place.
We'll be welcoming global developers and creators to build immersive AR and AI solutions for the chance to win up to USD$100,000 in cash prizes.
Running online from May 3-10, participants in the F8 Refresh Hackathon will form teams with fellow innovators and choose between two product challenge areas - Spark AR and Wit.ai - while receiving special access to resources and experts.
Register now to be among the first to receive specific details on the challenges as soon as they're released on May 3!
#F8 #F8Refresh #Hackathon  #BuildwithFacebook","F8 Refresh Hackathon Registration is open! Register for this year's F8 Hackathon at the link below: https://fb.me/F8-Refresh-Hackathon-Registration F8 has always brought together an incredible community of people who are building, innovating, and looking for whatâ€™s next. Over the past year, developers have been enabling businesses of all sizes to adapt and accelerate their digital transformation. Weâ€™re drawing inspiration from F8â€™s early days and bringing the conference back to its roots: a place to celebrate, inspire and help developers grow. Weâ€™re excited to introduce a new virtual event format, F8 Refresh. F8 Refresh will feature the latest product tools to help you build across our family of apps, as well as technical deep-dive sessions, demos â€“ all with the goal of enabling your growth. Join us at the F8 Refresh: Hackathon for prizes, bragging rights, and more as you show off your skills to help make the world a better place. We'll be welcoming global developers and creators to build immersive AR and AI solutions for the chance to win up to USD$100,000 in cash prizes. Running online from May 3-10, participants in the F8 Refresh Hackathon will form teams with fellow innovators and choose between two product challenge areas - Spark AR and Wit.ai - while receiving special access to resources and experts. Register now to be among the first to receive specific details on the challenges as soon as they're released on May 3!",#F8	#F8Refresh	#Hackathon	#BuildwithFacebook,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Äá»£t rá»“i em tÃ¬m hiá»ƒu vá» Principal Component Analysis (PCA) mÃ  Ä‘á»c máº¥y bÃ i trÃªn máº¡ng khÃ³ hiá»ƒu vÃ  nhiá»u toÃ¡n quÃ¡ (cháº¯c do trÃ¬nh cÃ²n non) nÃªn em máº¡nh dáº¡n viáº¿t bÃ i nÃ y chia sáº» cÃ¹ng cáº£ nhÃ  mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c.
Mong admin duyá»‡t bÃ i vÃ  mong nháº­n Ä‘Æ°á»£c chá»‰ giÃ¡o cá»§a cÃ¡c bÃ¡c!",KÃ­nh chÃ o cÃ¡c bÃ¡c. Äá»£t rá»“i em tÃ¬m hiá»ƒu vá» Principal Component Analysis (PCA) mÃ  Ä‘á»c máº¥y bÃ i trÃªn máº¡ng khÃ³ hiá»ƒu vÃ  nhiá»u toÃ¡n quÃ¡ (cháº¯c do trÃ¬nh cÃ²n non) nÃªn em máº¡nh dáº¡n viáº¿t bÃ i nÃ y chia sáº» cÃ¹ng cáº£ nhÃ  mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c. Mong admin duyá»‡t bÃ i vÃ  mong nháº­n Ä‘Æ°á»£c chá»‰ giÃ¡o cá»§a cÃ¡c bÃ¡c!,,,,,
"Xin chÃ o má»i ngÆ°á»i!
Hiá»‡n táº¡i em Ä‘ang cáº§n bá»™ dataset Megaface nguyÃªn báº£n mÃ  web dÆ°á»›i Ä‘Ã¢y há» khÃ´ng cÃ²n cho download ná»¯a.
http://megaface.cs.washington.edu/
Má»i ngÆ°á»i náº¿u ai cÃ³ thÃ¬ cho em xin vá»›i áº¡.
Em cáº£m Æ¡n áº¡.",Xin chÃ o má»i ngÆ°á»i! Hiá»‡n táº¡i em Ä‘ang cáº§n bá»™ dataset Megaface nguyÃªn báº£n mÃ  web dÆ°á»›i Ä‘Ã¢y há» khÃ´ng cÃ²n cho download ná»¯a. http://megaface.cs.washington.edu/ Má»i ngÆ°á»i náº¿u ai cÃ³ thÃ¬ cho em xin vá»›i áº¡. Em cáº£m Æ¡n áº¡.,,,,,
"LÃ€M SAO TÃŒM ABNORMAL Tá»ª Dá»® LIá»†U CHUá»–I THá»œI GIAN (TIME SERIES)
Em chÃ o anh/chá»‹,
Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t bÃ i toÃ¡n lÃ m sao phÃ¡t hiá»‡n abnormal tá»« dá»¯ liá»‡u chuá»—i thá»i gian (time series). VÃ  em cÃ³ tham kháº£o bÃ i phÃ­a dÆ°á»›i thÃ¬ má»›i biáº¿t lÃ  mÃ¬nh cáº§n lÃ m qua cÃ¡c pháº§n nhÆ°: Trend, Seasonality, Cycle vÃ  Irregular remainder.
KhÃ´ng biáº¿t anh/chá»‹ nÃ o Ä‘Ã£ tá»«ng há»c qua cÃ³ thá»ƒ giá»›i thiÃªu em project nÃ o ná»•i báº­t Ä‘á»ƒ em lÃ m vÃ  há»c nhanh Ä‘á»ƒ giáº£i bÃ i toÃ¡n tÃ¬m abnormal tá»« dá»¯ liá»‡u time series Ä‘Æ°á»£c khÃ´ng áº¡? Em cÅ©ng chá»‰ má»›i lÃ m dá»¯ liá»‡u gáº§n Ä‘Ã¢y, nÃªn hy vá»ng Ä‘Æ°á»£c há»c há»i tá»« má»i ngÆ°á»i nhiá»u áº¡.
Em cáº£m Æ¡n anh/chá»‹ ráº¥t nhiá»u.
BÃ i tham kháº£o:","LÃ€M SAO TÃŒM ABNORMAL Tá»ª Dá»® LIá»†U CHUá»–I THá»œI GIAN (TIME SERIES) Em chÃ o anh/chá»‹, Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t bÃ i toÃ¡n lÃ m sao phÃ¡t hiá»‡n abnormal tá»« dá»¯ liá»‡u chuá»—i thá»i gian (time series). VÃ  em cÃ³ tham kháº£o bÃ i phÃ­a dÆ°á»›i thÃ¬ má»›i biáº¿t lÃ  mÃ¬nh cáº§n lÃ m qua cÃ¡c pháº§n nhÆ°: Trend, Seasonality, Cycle vÃ  Irregular remainder. KhÃ´ng biáº¿t anh/chá»‹ nÃ o Ä‘Ã£ tá»«ng há»c qua cÃ³ thá»ƒ giá»›i thiÃªu em project nÃ o ná»•i báº­t Ä‘á»ƒ em lÃ m vÃ  há»c nhanh Ä‘á»ƒ giáº£i bÃ i toÃ¡n tÃ¬m abnormal tá»« dá»¯ liá»‡u time series Ä‘Æ°á»£c khÃ´ng áº¡? Em cÅ©ng chá»‰ má»›i lÃ m dá»¯ liá»‡u gáº§n Ä‘Ã¢y, nÃªn hy vá»ng Ä‘Æ°á»£c há»c há»i tá»« má»i ngÆ°á»i nhiá»u áº¡. Em cáº£m Æ¡n anh/chá»‹ ráº¥t nhiá»u. BÃ i tham kháº£o:",,,,,
"Má»i ngÆ°á»i Æ¡i, cho em há»i lÃ  giÃ¡ trá»‹ cá»§a tá»«ng pháº§n tá»­ trong ma tráº­n kernel channel 3x3 trong hÃ¬nh Ä‘Æ°á»£c táº¡o ra theo quy táº¯c nÃ o áº¡.
Em Ä‘ang xÃ i máº¡ng VGG11 pretrained cá»§a pytorch trÃªn táº­p ImageNet Ä‘á»ƒ nháº­n diá»‡n váº­t thá»ƒ thÃ¬ nhá»¯ng giÃ¡ trá»‹ cá»§a kernel nÃ y cÃ³ pháº£i Ä‘Ã£ Ä‘Æ°á»£c quy Ä‘á»‹nh sáºµn khÃ´ng áº¡? Náº¿u cÃ³ thÃ¬ em cÃ³ thá»ƒ xem á»Ÿ Ä‘Ã¢u áº¡?","Má»i ngÆ°á»i Æ¡i, cho em há»i lÃ  giÃ¡ trá»‹ cá»§a tá»«ng pháº§n tá»­ trong ma tráº­n kernel channel 3x3 trong hÃ¬nh Ä‘Æ°á»£c táº¡o ra theo quy táº¯c nÃ o áº¡. Em Ä‘ang xÃ i máº¡ng VGG11 pretrained cá»§a pytorch trÃªn táº­p ImageNet Ä‘á»ƒ nháº­n diá»‡n váº­t thá»ƒ thÃ¬ nhá»¯ng giÃ¡ trá»‹ cá»§a kernel nÃ y cÃ³ pháº£i Ä‘Ã£ Ä‘Æ°á»£c quy Ä‘á»‹nh sáºµn khÃ´ng áº¡? Náº¿u cÃ³ thÃ¬ em cÃ³ thá»ƒ xem á»Ÿ Ä‘Ã¢u áº¡?",,,,,
"[Giá»›i thiá»‡u sÃ¡ch]
Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n 2 quyá»ƒn MIT Press vá»«a chuyá»ƒn sang giáº¥y phÃ©p CC BY-NC-ND 4.0 cho phÃ©p táº£i vá» miá»…n phÃ­.
1) Algorithms for Optimization: https://algorithmsbook.com/optimization/ (Mykel J. Kochenderfer, Tim A. Wheeler)
2) Algorithms for Decision Making: https://algorithmsbook.com/ (Mykel J. Kochenderfer, Tim A. Wheeler, Kyle H. Wray)
Hai quyá»ƒn Ä‘á»u Ä‘i song song lÃ½ thuyáº¿t vÃ  thá»±c hÃ nh (cÃ³ mÃ£ nguá»“n Julia kÃ¨m theo), bá»‘ cá»¥c sÃ¡ch rÃµ rÃ ng, vÃ­ dá»¥ cÃ³ kÃ¨m nhiá»u minh há»a.
Quyá»ƒn Algorithms for Optimization giá»›i thiá»‡u nhiá»u phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u trong cÃ¡c bÃ i toÃ¡n khÃ¡c nhau. Nhá»¯ng chá»§ Ä‘á» trong quyá»ƒn nÃ y ráº¥t rá»™ng, má»—i bÃ i toÃ¡n Ä‘á»u Ä‘Æ°á»£c Ä‘áº·t váº¥n Ä‘á» ká»¹ lÆ°á»¡ng, tá»« nhá»¯ng bÃ i cÃ³ thá»ƒ lÃ m má»™t Ã­t phÃ¢n tÃ­ch Ä‘á»ƒ giáº£i Ä‘Æ°á»£c, Ä‘áº¿n nhá»¯ng bÃ i cáº§n tÃ­ yáº¿u tá»‘ ngáº«u nhiÃªn Ä‘á»ƒ tÃ¬m má»™t chÃºt may máº¯n, hay cÃ¡c bÃ i tá»‘i Æ°u cÃ³ rÃ ng buá»™c Ä‘Æ¡n giáº£n, tá»‘i Æ°u Ä‘a má»¥c tiÃªu, vÃ  cÃ¡c nhÃ³m phÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng hÃ m thay tháº¿ Ä‘á»ƒ chá»‰ dáº«n cho quÃ¡ trÃ¬nh tá»‘i Æ°u... vÃ  cÃ¡c chá»§ Ä‘á» nÃ¢ng cao nhÆ° tá»‘i Æ°u hÃ m má»¥c tiÃªu phi táº¥t Ä‘á»‹nh, tá»‘i Æ°u cÃ¡c bÃ i khÃ´ng rÃµ sá»‘ biáº¿n biá»ƒn diá»…n (vÃ­ dá»¥ cáº¥u trÃºc), vÃ  cÃ¡c bÃ i toÃ¡n thiáº¿t káº¿ cÃ¡c há»‡ thá»‘ng Ä‘a lÄ©nh vá»±c (multi-disciplinary) .
Quyá»ƒn Algorithms for Decision Making táº­p trung thiÃªn vá» cÃ¡c bÃ i toÃ¡n láº­p káº¿ hoáº¡ch vÃ  há»c tÄƒng cÆ°á»ng Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n ra quyáº¿t Ä‘á»‹nh trong má»™t tháº¿ giá»›i khÃ´ng cháº¯c cháº¯n.
Hy vá»ng hai quyá»ƒn sáº½ há»¯u Ã­ch vá»›i báº¡n Ä‘á»c!","[Giá»›i thiá»‡u sÃ¡ch] Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n 2 quyá»ƒn MIT Press vá»«a chuyá»ƒn sang giáº¥y phÃ©p CC BY-NC-ND 4.0 cho phÃ©p táº£i vá» miá»…n phÃ­. 1) Algorithms for Optimization: https://algorithmsbook.com/optimization/ (Mykel J. Kochenderfer, Tim A. Wheeler) 2) Algorithms for Decision Making: https://algorithmsbook.com/ (Mykel J. Kochenderfer, Tim A. Wheeler, Kyle H. Wray) Hai quyá»ƒn Ä‘á»u Ä‘i song song lÃ½ thuyáº¿t vÃ  thá»±c hÃ nh (cÃ³ mÃ£ nguá»“n Julia kÃ¨m theo), bá»‘ cá»¥c sÃ¡ch rÃµ rÃ ng, vÃ­ dá»¥ cÃ³ kÃ¨m nhiá»u minh há»a. Quyá»ƒn Algorithms for Optimization giá»›i thiá»‡u nhiá»u phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u trong cÃ¡c bÃ i toÃ¡n khÃ¡c nhau. Nhá»¯ng chá»§ Ä‘á» trong quyá»ƒn nÃ y ráº¥t rá»™ng, má»—i bÃ i toÃ¡n Ä‘á»u Ä‘Æ°á»£c Ä‘áº·t váº¥n Ä‘á» ká»¹ lÆ°á»¡ng, tá»« nhá»¯ng bÃ i cÃ³ thá»ƒ lÃ m má»™t Ã­t phÃ¢n tÃ­ch Ä‘á»ƒ giáº£i Ä‘Æ°á»£c, Ä‘áº¿n nhá»¯ng bÃ i cáº§n tÃ­ yáº¿u tá»‘ ngáº«u nhiÃªn Ä‘á»ƒ tÃ¬m má»™t chÃºt may máº¯n, hay cÃ¡c bÃ i tá»‘i Æ°u cÃ³ rÃ ng buá»™c Ä‘Æ¡n giáº£n, tá»‘i Æ°u Ä‘a má»¥c tiÃªu, vÃ  cÃ¡c nhÃ³m phÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng hÃ m thay tháº¿ Ä‘á»ƒ chá»‰ dáº«n cho quÃ¡ trÃ¬nh tá»‘i Æ°u... vÃ  cÃ¡c chá»§ Ä‘á» nÃ¢ng cao nhÆ° tá»‘i Æ°u hÃ m má»¥c tiÃªu phi táº¥t Ä‘á»‹nh, tá»‘i Æ°u cÃ¡c bÃ i khÃ´ng rÃµ sá»‘ biáº¿n biá»ƒn diá»…n (vÃ­ dá»¥ cáº¥u trÃºc), vÃ  cÃ¡c bÃ i toÃ¡n thiáº¿t káº¿ cÃ¡c há»‡ thá»‘ng Ä‘a lÄ©nh vá»±c (multi-disciplinary) . Quyá»ƒn Algorithms for Decision Making táº­p trung thiÃªn vá» cÃ¡c bÃ i toÃ¡n láº­p káº¿ hoáº¡ch vÃ  há»c tÄƒng cÆ°á»ng Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n ra quyáº¿t Ä‘á»‹nh trong má»™t tháº¿ giá»›i khÃ´ng cháº¯c cháº¯n. Hy vá»ng hai quyá»ƒn sáº½ há»¯u Ã­ch vá»›i báº¡n Ä‘á»c!",,,,,
"Má»i ngÆ°á»i cho em há»i tÃ½ áº¡. Em cÃ³ 1 Ä‘oáº¡n video em muá»‘n xá»­ lÃ­ detection cá»¥ thá»ƒ yolov5 áº¡. Em muá»‘n lÃ  táº­n dá»¥ng tá»‘i Ä‘a tÃ i nguyÃªn Ä‘á»ƒ xá»­ lÃ­ nhanh nháº¥t cÃ³ thá»ƒ. Em thá»­ Ä‘a luá»“ng thÃ¬ tháº¥y káº¿t quáº£ nÃ³ chÆ°a tá»‘t láº¯m, hiá»‡n táº¡i em xá»­ lÃ­ lÃ  cho tiá»n xá»­ lÃ­ 1 thá»ƒ xong cho batch áº£nh vÃ o model thÃ¬ cÃ¡i bÆ°á»›c tiá»n xá»­ lÃ­ nÃ³ khÃ¡ cháº­m. Váº­y cho em há»i lÃ  viá»‡c tiá»n xá»­ lÃ­ cpu cÃ³ thá»ƒ song song Ä‘Æ°á»£c khÃ´ng vÃ  cÃ³ cÃ¡ch nÃ o xá»­ lÃ­ bÃ i toÃ¡n nÃ y khÃ´ng áº¡. VÃ¬ em tháº¥y chÆ°a táº­n dá»¥ng háº¿t tÃ i nguyÃªn mÃ  cáº§n pháº£i Æ°u tiÃªn tá»‘c Ä‘á»™ xá»­ lÃ½","Má»i ngÆ°á»i cho em há»i tÃ½ áº¡. Em cÃ³ 1 Ä‘oáº¡n video em muá»‘n xá»­ lÃ­ detection cá»¥ thá»ƒ yolov5 áº¡. Em muá»‘n lÃ  táº­n dá»¥ng tá»‘i Ä‘a tÃ i nguyÃªn Ä‘á»ƒ xá»­ lÃ­ nhanh nháº¥t cÃ³ thá»ƒ. Em thá»­ Ä‘a luá»“ng thÃ¬ tháº¥y káº¿t quáº£ nÃ³ chÆ°a tá»‘t láº¯m, hiá»‡n táº¡i em xá»­ lÃ­ lÃ  cho tiá»n xá»­ lÃ­ 1 thá»ƒ xong cho batch áº£nh vÃ o model thÃ¬ cÃ¡i bÆ°á»›c tiá»n xá»­ lÃ­ nÃ³ khÃ¡ cháº­m. Váº­y cho em há»i lÃ  viá»‡c tiá»n xá»­ lÃ­ cpu cÃ³ thá»ƒ song song Ä‘Æ°á»£c khÃ´ng vÃ  cÃ³ cÃ¡ch nÃ o xá»­ lÃ­ bÃ i toÃ¡n nÃ y khÃ´ng áº¡. VÃ¬ em tháº¥y chÆ°a táº­n dá»¥ng háº¿t tÃ i nguyÃªn mÃ  cáº§n pháº£i Æ°u tiÃªn tá»‘c Ä‘á»™ xá»­ lÃ½",,,,,
"Em chÃ o má»i ngÆ°á»i.
Hiá»‡n táº¡i em cÃ³ Ä‘ang thá»±c hiá»‡n trainning mÃ´ hÃ¬nh. Tuy nhiÃªn em gáº·p váº¥n Ä‘á» khi config lÃªn colab thÃ¬ code Ä‘Ã´i khi cháº¡y sai lÃ m loss (MSE) tÄƒng cao (nhÆ° trong hÃ¬nh 1). Sau Ä‘Ã³ em khá»Ÿi Ä‘á»™ng láº¡i toÃ n bá»™ thÃ¬ Ä‘Ã´i lÃºc láº¡i cháº¡y Ä‘Ãºng (loss MSE giáº£m hÃ¬nh 2). Khi train trÃªn mÃ¡y á»Ÿ local thÃ¬ khÃ´ng gáº·p lá»—i hÃ m loss tÄƒng quÃ¡ cao.
Em Ä‘Ã£ config ramdon seed Ä‘á»ƒ reproducible vÃ  consistency version packages.
Má»i ngÆ°á»i cÃ³ ai biáº¿t lÃ½ do táº¡i sao vÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° nÃ o hay khÃ´ng áº¡.
Em cáº£m Æ¡n.",Em chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em cÃ³ Ä‘ang thá»±c hiá»‡n trainning mÃ´ hÃ¬nh. Tuy nhiÃªn em gáº·p váº¥n Ä‘á» khi config lÃªn colab thÃ¬ code Ä‘Ã´i khi cháº¡y sai lÃ m loss (MSE) tÄƒng cao (nhÆ° trong hÃ¬nh 1). Sau Ä‘Ã³ em khá»Ÿi Ä‘á»™ng láº¡i toÃ n bá»™ thÃ¬ Ä‘Ã´i lÃºc láº¡i cháº¡y Ä‘Ãºng (loss MSE giáº£m hÃ¬nh 2). Khi train trÃªn mÃ¡y á»Ÿ local thÃ¬ khÃ´ng gáº·p lá»—i hÃ m loss tÄƒng quÃ¡ cao. Em Ä‘Ã£ config ramdon seed Ä‘á»ƒ reproducible vÃ  consistency version packages. Má»i ngÆ°á»i cÃ³ ai biáº¿t lÃ½ do táº¡i sao vÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° nÃ o hay khÃ´ng áº¡. Em cáº£m Æ¡n.,,,,,
"Khoa CNTT Äáº¡i há»c Äáº¡i Nam FIT-DNU sáº½ cÃ³ 05 postdoctoral fellowships toÃ n thá»i gian cho niÃªn há»c 2021-2022, báº¯t Ä‘áº§u tá»« thÃ¡ng 9/2021. Hoc bá»•ng cÃ³ thá»ƒ gia háº¡n tá»‘i Ä‘a 3 nÄƒm, náº¿u á»©ng viÃªn Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u chuyÃªn mÃ´n. á»¨ng viÃªn Ä‘Æ°á»£c chá»n cÃ³ thá»ƒ tuá»³ Ã½ chá»n Ä‘á» tÃ i, hoáº·c lÃ m viá»‡c dÆ°á»›i sá»± hÆ°á»›ng dáº«n cá»§a cÃ¡c giÃ¡o sÆ° hÃ ng Ä‘áº§u lÃ  cá»‘ váº¥n khoa há»c cá»§a FIT-DNU, Ä‘Æ°á»£c khuyáº¿n khÃ­ch tham gia giáº£ng dáº¡y vÃ  cÃ³ thá»ƒ Ä‘Äƒng kÃ½ Äá» tÃ i nghiÃªn cá»©u sau tiáº¿n sÄ© tá»›i $50.000. Trong thá»i gian nghiÃªn cá»©u sau TS, á»©ng viÃªn cÃ³ thá»ƒ Ä‘i nghiÃªn cá»©u nÆ°á»›c ngoÃ i vá»›i sá»± cháº¥p thuáº­n cá»§a Khoa khÃ´ng quÃ¡ 3 thÃ¡ng.
á»¨ng viÃªn pháº£i báº£o vá»‡ luáº­n Ã¡n Tiáº¿n sÄ© trong hoáº·c ngoÃ i nÆ°á»›c, sau 1/1/2017 hoáº·c Ä‘Ã£ ná»™p luáº­n Ã¡n Tiáº¿n sÄ© trÆ°á»›c 1/6/2021. Há»“ sÆ¡ Ä‘Äƒng kÃ½ gá»“m:
- Luáº­n Ã¡n TS
- CV
- Káº¿ hoáº¡ch nghiÃªn cá»©u
- 2 thÆ° giá»›i thiá»‡u
Gá»­i vá» Prof. Aiviet Nguyen, Dean FIT-DNU fit@dainam.edu.vn.","Khoa CNTT Äáº¡i há»c Äáº¡i Nam FIT-DNU sáº½ cÃ³ 05 postdoctoral fellowships toÃ n thá»i gian cho niÃªn há»c 2021-2022, báº¯t Ä‘áº§u tá»« thÃ¡ng 9/2021. Hoc bá»•ng cÃ³ thá»ƒ gia háº¡n tá»‘i Ä‘a 3 nÄƒm, náº¿u á»©ng viÃªn Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u chuyÃªn mÃ´n. á»¨ng viÃªn Ä‘Æ°á»£c chá»n cÃ³ thá»ƒ tuá»³ Ã½ chá»n Ä‘á» tÃ i, hoáº·c lÃ m viá»‡c dÆ°á»›i sá»± hÆ°á»›ng dáº«n cá»§a cÃ¡c giÃ¡o sÆ° hÃ ng Ä‘áº§u lÃ  cá»‘ váº¥n khoa há»c cá»§a FIT-DNU, Ä‘Æ°á»£c khuyáº¿n khÃ­ch tham gia giáº£ng dáº¡y vÃ  cÃ³ thá»ƒ Ä‘Äƒng kÃ½ Äá» tÃ i nghiÃªn cá»©u sau tiáº¿n sÄ© tá»›i $50.000. Trong thá»i gian nghiÃªn cá»©u sau TS, á»©ng viÃªn cÃ³ thá»ƒ Ä‘i nghiÃªn cá»©u nÆ°á»›c ngoÃ i vá»›i sá»± cháº¥p thuáº­n cá»§a Khoa khÃ´ng quÃ¡ 3 thÃ¡ng. á»¨ng viÃªn pháº£i báº£o vá»‡ luáº­n Ã¡n Tiáº¿n sÄ© trong hoáº·c ngoÃ i nÆ°á»›c, sau 1/1/2017 hoáº·c Ä‘Ã£ ná»™p luáº­n Ã¡n Tiáº¿n sÄ© trÆ°á»›c 1/6/2021. Há»“ sÆ¡ Ä‘Äƒng kÃ½ gá»“m: - Luáº­n Ã¡n TS - CV - Káº¿ hoáº¡ch nghiÃªn cá»©u - 2 thÆ° giá»›i thiá»‡u Gá»­i vá» Prof. Aiviet Nguyen, Dean FIT-DNU fit@dainam.edu.vn.",,,,,
"Chao moi nguoi,
Minh muon hoi: cac ban xai computer tower gi cho data science projects?
Minh dag nghi se mua: computer tower ma co 16gbs, 512 ssd, nvida card, icore 9 or AMD rayzen 7 or 9 processor.
Cac ban cho minh y kien nhe.
Cam on. :)","Chao moi nguoi, Minh muon hoi: cac ban xai computer tower gi cho data science projects? Minh dag nghi se mua: computer tower ma co 16gbs, 512 ssd, nvida card, icore 9 or AMD rayzen 7 or 9 processor. Cac ban cho minh y kien nhe. Cam on. :)",,,,,
"Hellu má»i ngÆ°á»i áº¡
Em Ä‘ang cÃ i Ä‘áº·t rasa chatbot vá»›i má»™t vÃ i chá»©c nÄƒng cÆ¡ báº£n
trong Ä‘Ã³ cÃ³ dÃ¹ng api -> trÃ­ch thÃ´ng tin
Em Ä‘ang test trÃªn mess cá»§a fb thÃ¬ nÃ³ khÃ´ng work vÃ  bÃ¡o lá»—i, nÃ³ Ä‘Ã£ cháº¡y(káº¿t ná»‘i Ä‘Æ°á»£c vá»›i fb) nhÆ°ng chá»©c nÄƒng cÃ³ action dÃ¹ng api thÃ¬ bÃ¡o nhÆ° bÃªn dÆ°á»›i
Wrong fb secret! Make sure this matches the secret in your facebook app settings
Em test trÃªn local thÃ¬ ok, vÃ  cháº¡y ráº¥t bÃ¬nh thÆ°á»ng vá»›i cÃ¡c action
Náº¿u ai biáº¿t hÆ°Æ¡ng kháº¯c phá»¥c thÃ¬ chá»‰ em vá»›i áº¡.
Em cÃ³ mÃ´ táº£ chi tiáº¿t hÆ¡n tá»«ng áº£nh á»Ÿ pháº§n bÃ¬nh luáº­n. má»—i áº£nh","Hellu má»i ngÆ°á»i áº¡ Em Ä‘ang cÃ i Ä‘áº·t rasa chatbot vá»›i má»™t vÃ i chá»©c nÄƒng cÆ¡ báº£n trong Ä‘Ã³ cÃ³ dÃ¹ng api -> trÃ­ch thÃ´ng tin Em Ä‘ang test trÃªn mess cá»§a fb thÃ¬ nÃ³ khÃ´ng work vÃ  bÃ¡o lá»—i, nÃ³ Ä‘Ã£ cháº¡y(káº¿t ná»‘i Ä‘Æ°á»£c vá»›i fb) nhÆ°ng chá»©c nÄƒng cÃ³ action dÃ¹ng api thÃ¬ bÃ¡o nhÆ° bÃªn dÆ°á»›i Wrong fb secret! Make sure this matches the secret in your facebook app settings Em test trÃªn local thÃ¬ ok, vÃ  cháº¡y ráº¥t bÃ¬nh thÆ°á»ng vá»›i cÃ¡c action Náº¿u ai biáº¿t hÆ°Æ¡ng kháº¯c phá»¥c thÃ¬ chá»‰ em vá»›i áº¡. Em cÃ³ mÃ´ táº£ chi tiáº¿t hÆ¡n tá»«ng áº£nh á»Ÿ pháº§n bÃ¬nh luáº­n. má»—i áº£nh",,,,,
Cho em há»i vá» lá»c feature theo Predictive Power Score mÃ¬nh nÃªn lá»c thá»§ cÃ´ng tá»« ma tráº­n tráº£ vá» hay cÃ³ cÃ¡ch nÃ o lá»c tá»± Ä‘á»™ng khÃ´ng áº¡? VÃ  cÃ³ thá»ƒ káº¿t há»£p vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Ã¡nh giÃ¡ khÃ¡c há»— trá»£ khÃ´ng áº¡? Em cáº£m Æ¡n.,Cho em há»i vá» lá»c feature theo Predictive Power Score mÃ¬nh nÃªn lá»c thá»§ cÃ´ng tá»« ma tráº­n tráº£ vá» hay cÃ³ cÃ¡ch nÃ o lá»c tá»± Ä‘á»™ng khÃ´ng áº¡? VÃ  cÃ³ thá»ƒ káº¿t há»£p vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Ã¡nh giÃ¡ khÃ¡c há»— trá»£ khÃ´ng áº¡? Em cáº£m Æ¡n.,,,,,
#Pytorch #ComputerVision,,#Pytorch	#ComputerVision,,,,
#Pytorch #ComputerVision,,#Pytorch	#ComputerVision,,,,
"á»¨ng dá»¥ng DL/AI trong y há»c máº·c dÃ¹ cÃ³ ráº¥t nhiá»u tiá»m nÄƒng nhÆ°ng Ä‘i kÃ¨m vá»›i Ä‘Ã³ lÃ  nhiá»u rá»§i ro/báº¥t Ä‘á»‹nh vÃ  khoáº£ng trá»‘ng vá» phÃ¡p lÃ­. Tuy nhiÃªn trong thá»i Ä‘áº¡i dá»‹ch Covid-19 diá»…n ra gÃ¢y bao tá»•n tháº¥t vá» ngÆ°á»i vÃ  cá»§a, cÅ©ng nhÆ° tÃ¬nh hÃ¬nh bá»‡nh lao phá»•i luÃ´n lÃ  gÃ¡nh náº·ng bá»‡nh táº­t ráº¥t lá»›n cho nhá»¯ng nÆ°á»›c cÃ³ tá»‰ lá»‡ lÆ°u hÃ nh dá»‹ch lao phá»•i cao nhÆ° á»Ÿ Viá»‡t Nam, chÃºng tÃ´i, nhÃ³m nghiÃªn cá»©u Äáº¡i há»c Duy TÃ¢n, xin chung tay gÃ³p sá»©c Ä‘áº©y lÃ¹i dá»‹ch bá»‡nh nÃ³i trÃªn báº±ng viá»‡c á»©ng dá»¥ng AI trong cÃ´ng tÃ¡c cháº©n Ä‘oÃ¡n cÃ¡c bá»‡nh nÃ y qua film X Quang vÃ  computed tomography qua á»©ng dá»¥ng http://co2c.duytan.edu.vn/. CÃ¡c báº¡n cÃ³ xem thÃªm thÃ´ng tin bÃ¡o chÃ­ táº¡i Ä‘Ã¢y https://m.thanhnien.vn/giao-duc/dh-duy-tan-phat-trien-ung-dung-phat-hien-covid-19-qua-xu-ly-phim-xquang-ct-1367959.html?zarsrc=1303&utm_source=zalo&utm_medium=zalo&utm_campaign=zalo","á»¨ng dá»¥ng DL/AI trong y há»c máº·c dÃ¹ cÃ³ ráº¥t nhiá»u tiá»m nÄƒng nhÆ°ng Ä‘i kÃ¨m vá»›i Ä‘Ã³ lÃ  nhiá»u rá»§i ro/báº¥t Ä‘á»‹nh vÃ  khoáº£ng trá»‘ng vá» phÃ¡p lÃ­. Tuy nhiÃªn trong thá»i Ä‘áº¡i dá»‹ch Covid-19 diá»…n ra gÃ¢y bao tá»•n tháº¥t vá» ngÆ°á»i vÃ  cá»§a, cÅ©ng nhÆ° tÃ¬nh hÃ¬nh bá»‡nh lao phá»•i luÃ´n lÃ  gÃ¡nh náº·ng bá»‡nh táº­t ráº¥t lá»›n cho nhá»¯ng nÆ°á»›c cÃ³ tá»‰ lá»‡ lÆ°u hÃ nh dá»‹ch lao phá»•i cao nhÆ° á»Ÿ Viá»‡t Nam, chÃºng tÃ´i, nhÃ³m nghiÃªn cá»©u Äáº¡i há»c Duy TÃ¢n, xin chung tay gÃ³p sá»©c Ä‘áº©y lÃ¹i dá»‹ch bá»‡nh nÃ³i trÃªn báº±ng viá»‡c á»©ng dá»¥ng AI trong cÃ´ng tÃ¡c cháº©n Ä‘oÃ¡n cÃ¡c bá»‡nh nÃ y qua film X Quang vÃ  computed tomography qua á»©ng dá»¥ng http://co2c.duytan.edu.vn/. CÃ¡c báº¡n cÃ³ xem thÃªm thÃ´ng tin bÃ¡o chÃ­ táº¡i Ä‘Ã¢y https://m.thanhnien.vn/giao-duc/dh-duy-tan-phat-trien-ung-dung-phat-hien-covid-19-qua-xu-ly-phim-xquang-ct-1367959.html?zarsrc=1303&utm_source=zalo&utm_medium=zalo&utm_campaign=zalo",,,,,
"[ChÆ°Æ¡ng 2: Giáº£i tÃ­ch - Machine Learning Algorithms to Practice ]
CÃ¹ng Ã´n láº¡i cÃ¡c khÃ¡i niá»‡m giáº£i tÃ­ch cÆ¡ báº£n trong machine learning thÃ´ng qua chÆ°Æ¡ng 2, báº£n MVP cá»§a cuá»‘n ""Machine Learning Algorithms to Practice"".
â˜‘ï¸ Táº¡i chÆ°Æ¡ng nÃ y báº¡n sáº½ lÃ m quen vá»›i cÃ¡c khÃ¡i niá»‡m vá» Ä‘áº¡o hÃ m, gradient descent.
â˜‘ï¸ CÃ¡c nguyÃªn táº¯c tÃ­nh vi phÃ¢n.
â˜‘ï¸ Khai triá»ƒn Taylor, Ä‘á»‹nh lÃ½ Fermat.
â˜‘ï¸ Lan truyá»n thuáº­n, lan truyá»n ngÆ°á»£c.
Ná»™i dung Ä‘Æ°á»£c tÃ³m lÆ°á»£c Ä‘á»ƒ Ä‘Æ¡n giáº£n, dá»… hiá»ƒu cho ngÆ°á»i Ä‘á»c vÃ  kÃ¨m theo bÃ i táº­p thá»±c hÃ nh.
------------------------------------------------------------------------------------
Vá»›i má»¥c tiÃªu ""VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n"". Báº¡n cÃ³ thá»ƒ tham gia dá»± Ã¡n viáº¿t sÃ¡ch cá»™ng Ä‘á»“ng cá»§a cuá»‘n ""Machine Learning Algorithms to Practice"" táº¡i:
https://www.facebook.com/groups/167567421900114
https://phamdinhkhanh.github.io/deepai-book/ch_calculus/appendix_calculus.html","[ChÆ°Æ¡ng 2: Giáº£i tÃ­ch - Machine Learning Algorithms to Practice ] CÃ¹ng Ã´n láº¡i cÃ¡c khÃ¡i niá»‡m giáº£i tÃ­ch cÆ¡ báº£n trong machine learning thÃ´ng qua chÆ°Æ¡ng 2, báº£n MVP cá»§a cuá»‘n ""Machine Learning Algorithms to Practice"". Táº¡i chÆ°Æ¡ng nÃ y báº¡n sáº½ lÃ m quen vá»›i cÃ¡c khÃ¡i niá»‡m vá» Ä‘áº¡o hÃ m, gradient descent. CÃ¡c nguyÃªn táº¯c tÃ­nh vi phÃ¢n. Khai triá»ƒn Taylor, Ä‘á»‹nh lÃ½ Fermat. Lan truyá»n thuáº­n, lan truyá»n ngÆ°á»£c. Ná»™i dung Ä‘Æ°á»£c tÃ³m lÆ°á»£c Ä‘á»ƒ Ä‘Æ¡n giáº£n, dá»… hiá»ƒu cho ngÆ°á»i Ä‘á»c vÃ  kÃ¨m theo bÃ i táº­p thá»±c hÃ nh. ------------------------------------------------------------------------------------ Vá»›i má»¥c tiÃªu ""VÃ¬ má»™t cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh hÆ¡n"". Báº¡n cÃ³ thá»ƒ tham gia dá»± Ã¡n viáº¿t sÃ¡ch cá»™ng Ä‘á»“ng cá»§a cuá»‘n ""Machine Learning Algorithms to Practice"" táº¡i: https://www.facebook.com/groups/167567421900114 https://phamdinhkhanh.github.io/deepai-book/ch_calculus/appendix_calculus.html",,"#sharing, #math, #machine_learning",,,
"#hoidap
ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang lÃ m project vá» facial recognition. HÆ°á»›ng em chá»n lÃ  sá»­ dá»¥ng pretrained model insightface. Sau khi face detection, face alignment em sáº½ láº¥y vector embedding, sau Ä‘Ã³ tÃ¬m vector trung bÃ¬nh cho tá»«ng class, tÃ¬m ngÆ°á»¡ng phÃ¢n loáº¡i theo distance euclidean vÃ  detect unknown. Em lÃ m trÃªn táº­p dataset khoáº£ng 5 ngÆ°á»i má»—i ngÆ°á»i táº§m 20 áº£nh. Káº¿t quáº£ cho ra Ä‘Æ°á»£c khÃ¡ lÃ  ok tuy nhiÃªn váº«n bá»‹ sai Ä‘Ã´i khi.
Hiá»‡n em Ä‘ang cáº£i thiá»‡n model báº±ng cÃ¡ch thÃªm data augmentation vá»›i noise, rotation, etc... vÃ  dÃ¹ng tÃ­nh siamese net. Do lÆ°á»£ng data Ã­t nÃªn em tÃ­nh dÃ¹ng siamese net nhÆ°ng thay vÃ¬ lÃ  hÃ¬nh Ä‘áº§u vÃ o thÃ¬ em sáº½ truyá»n vector embedding thay vÃ¬ model cnn share weight thÃ¬ em sáº½ dÃ¹ng model fully connected share weight Ä‘á»ƒ táº¡o ra vector Ä‘á»ƒ tÃ­nh similarity score.
Mong má»i ngÆ°á»i cho em Ã½ kiáº¿n vá» viá»‡c thay cnn báº±ng lá»›p fully connected cÅ©ng nhÆ° gá»£i Ã½ giÃºp em hÆ°á»›ng nÃ o Ä‘Ã³ Ä‘á»ƒ phÃ¡t triá»ƒn thÃªm. Em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang lÃ m project vá» facial recognition. HÆ°á»›ng em chá»n lÃ  sá»­ dá»¥ng pretrained model insightface. Sau khi face detection, face alignment em sáº½ láº¥y vector embedding, sau Ä‘Ã³ tÃ¬m vector trung bÃ¬nh cho tá»«ng class, tÃ¬m ngÆ°á»¡ng phÃ¢n loáº¡i theo distance euclidean vÃ  detect unknown. Em lÃ m trÃªn táº­p dataset khoáº£ng 5 ngÆ°á»i má»—i ngÆ°á»i táº§m 20 áº£nh. Káº¿t quáº£ cho ra Ä‘Æ°á»£c khÃ¡ lÃ  ok tuy nhiÃªn váº«n bá»‹ sai Ä‘Ã´i khi. Hiá»‡n em Ä‘ang cáº£i thiá»‡n model báº±ng cÃ¡ch thÃªm data augmentation vá»›i noise, rotation, etc... vÃ  dÃ¹ng tÃ­nh siamese net. Do lÆ°á»£ng data Ã­t nÃªn em tÃ­nh dÃ¹ng siamese net nhÆ°ng thay vÃ¬ lÃ  hÃ¬nh Ä‘áº§u vÃ o thÃ¬ em sáº½ truyá»n vector embedding thay vÃ¬ model cnn share weight thÃ¬ em sáº½ dÃ¹ng model fully connected share weight Ä‘á»ƒ táº¡o ra vector Ä‘á»ƒ tÃ­nh similarity score. Mong má»i ngÆ°á»i cho em Ã½ kiáº¿n vá» viá»‡c thay cnn báº±ng lá»›p fully connected cÅ©ng nhÆ° gá»£i Ã½ giÃºp em hÆ°á»›ng nÃ o Ä‘Ã³ Ä‘á»ƒ phÃ¡t triá»ƒn thÃªm. Em xin cáº£m Æ¡n.",#hoidap,,,,
"Em chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» mÃ´ hÃ¬nh dá»± bÃ¡o chuá»—i thá»i gian, sau khi em Ä‘á»c blog cá»§a anh KhÃ¡nh vÃ  1 sá»‘ bÃ i viáº¿t cá»§a nÆ°á»›c ngoÃ i em cÃ³ vÃ i cÃ¢u há»i tháº¯c máº¯c mong cÃ¡c cao nhÃ¢n giÃºp em áº¡:
1. Trong mÃ´ hÃ¬nh arima thÃ¬ nhiá»…u tráº¯ng lÃ  thÃ nh pháº§n báº¯t buá»™c pháº£i cÃ³ ko áº¡. Em cÃ³ tham kháº£o vÃ i bÃ i viáº¿t, thÃ¬ chuá»—i nhiá»…u tráº¯ng ráº¥t khÃ³ dá»± Ä‘oÃ¡n. NhÆ°ng sau khi sai pháº§n dá»¯ liá»‡u (Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh á»•n Ä‘á»‹nh) thÃ¬ xuáº¥t hiá»‡n while noise (mÃ´ hÃ¬nh MA kháº¯c phá»¥c váº¥n Ä‘á» nÃ y). Äá»ƒ chá»n tham sá»‘ cho MA, xem xÃ©t biá»ƒu Ä‘á»“ ACF váº­y mÃ¬nh láº¥y giÃ¡ trá»‹ lag Ä‘áº§u tiÃªn vá» 0, nghÄ©a lÃ  tá»« giÃ¡ trá»‹ mÃ  chuá»—i nhiá»…u tráº¯ng báº¯t Ä‘áº§u xuáº¥t hiá»‡n Ä‘Ãºng ko áº¡.
2. Táº¡i sao mÃ´ hÃ¬nh dá»± bÃ¡o cáº§n dá»¯ liá»‡u ko cÃ³ sá»± tÆ°Æ¡ng quan (cÃ¡c ria cá»§a ACF náº±m trong khoáº£ng =0) áº¡.
3. Táº¡i sao biá»ƒu Ä‘á»“ PACF Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tham sá»‘ cho AR láº¡i loáº¡i bá» cÃ¡c thá»i Ä‘iá»ƒm giá»¯a áº¡. Em hiá»ƒu lÃ  nÃ³ chá»‰ láº¥y cÃ¡c thá»i Ä‘iá»ƒm cÃ³ tÃ¡c Ä‘á»™ng máº¡nh Ä‘áº¿n giÃ¡ thá»i Ä‘iá»‡m cáº§n dá»± Ä‘oÃ¡n, nhÆ°ng táº¡i sao ko sá»­ dá»¥ng nhiá»u thá»i Ä‘iá»ƒm Ä‘á»ƒ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n áº¡.
Dáº¡ em cáº£m Æ¡n ad.","Em chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» mÃ´ hÃ¬nh dá»± bÃ¡o chuá»—i thá»i gian, sau khi em Ä‘á»c blog cá»§a anh KhÃ¡nh vÃ  1 sá»‘ bÃ i viáº¿t cá»§a nÆ°á»›c ngoÃ i em cÃ³ vÃ i cÃ¢u há»i tháº¯c máº¯c mong cÃ¡c cao nhÃ¢n giÃºp em áº¡: 1. Trong mÃ´ hÃ¬nh arima thÃ¬ nhiá»…u tráº¯ng lÃ  thÃ nh pháº§n báº¯t buá»™c pháº£i cÃ³ ko áº¡. Em cÃ³ tham kháº£o vÃ i bÃ i viáº¿t, thÃ¬ chuá»—i nhiá»…u tráº¯ng ráº¥t khÃ³ dá»± Ä‘oÃ¡n. NhÆ°ng sau khi sai pháº§n dá»¯ liá»‡u (Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh á»•n Ä‘á»‹nh) thÃ¬ xuáº¥t hiá»‡n while noise (mÃ´ hÃ¬nh MA kháº¯c phá»¥c váº¥n Ä‘á» nÃ y). Äá»ƒ chá»n tham sá»‘ cho MA, xem xÃ©t biá»ƒu Ä‘á»“ ACF váº­y mÃ¬nh láº¥y giÃ¡ trá»‹ lag Ä‘áº§u tiÃªn vá» 0, nghÄ©a lÃ  tá»« giÃ¡ trá»‹ mÃ  chuá»—i nhiá»…u tráº¯ng báº¯t Ä‘áº§u xuáº¥t hiá»‡n Ä‘Ãºng ko áº¡. 2. Táº¡i sao mÃ´ hÃ¬nh dá»± bÃ¡o cáº§n dá»¯ liá»‡u ko cÃ³ sá»± tÆ°Æ¡ng quan (cÃ¡c ria cá»§a ACF náº±m trong khoáº£ng =0) áº¡. 3. Táº¡i sao biá»ƒu Ä‘á»“ PACF Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tham sá»‘ cho AR láº¡i loáº¡i bá» cÃ¡c thá»i Ä‘iá»ƒm giá»¯a áº¡. Em hiá»ƒu lÃ  nÃ³ chá»‰ láº¥y cÃ¡c thá»i Ä‘iá»ƒm cÃ³ tÃ¡c Ä‘á»™ng máº¡nh Ä‘áº¿n giÃ¡ thá»i Ä‘iá»‡m cáº§n dá»± Ä‘oÃ¡n, nhÆ°ng táº¡i sao ko sá»­ dá»¥ng nhiá»u thá»i Ä‘iá»ƒm Ä‘á»ƒ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n áº¡. Dáº¡ em cáº£m Æ¡n ad.",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2020 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 8/2020 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"Gentle reminder: Production ML conf live TODAY
https://www.facebook.com/curiousAI/posts/2387205408090381",Gentle reminder: Production ML conf live TODAY https://www.facebook.com/curiousAI/posts/2387205408090381,,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m kiáº¿m dá»¯ liá»‡u Ä‘á»ƒ thá»­ nghiá»‡m bÃ i toÃ¡n tÃ¬m kiáº¿m vÄƒn báº£n (tiáº¿ng Anh) nhÆ°ng váº«n chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u, váº­y anh chá»‹ biáº¿t cÃ³ thá»ƒ share giÃºp Ä‘Æ°á»£c khÃ´ng áº¡. 
YÃªu cáº§u: táº­p dá»¯ liá»‡u vÄƒn báº£n (pdf hoáº·c txt Ä‘á»u Ä‘Æ°á»£c), 100 file, má»—i file cÃ³ Ä‘á»™ dÃ i xáº¥p xá»‰ 10 trang (náº¿u Ã­t hÆ¡n nhÆ°ng khÃ´ng Ä‘Ã¡ng ká»ƒ cÅ©ng Ä‘Æ°á»£c).  
ps: mÃ¬nh Ä‘Ã£ thá»­ tÃ¬m kiáº¿m datasets trÃªn máº¡ng nhÆ°ng cÃ¡c file cÃ³ Ä‘á»™ dÃ i khÃ¡ ngáº¯n. :( Xin cáº£m Æ¡n.","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m kiáº¿m dá»¯ liá»‡u Ä‘á»ƒ thá»­ nghiá»‡m bÃ i toÃ¡n tÃ¬m kiáº¿m vÄƒn báº£n (tiáº¿ng Anh) nhÆ°ng váº«n chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u, váº­y anh chá»‹ biáº¿t cÃ³ thá»ƒ share giÃºp Ä‘Æ°á»£c khÃ´ng áº¡. YÃªu cáº§u: táº­p dá»¯ liá»‡u vÄƒn báº£n (pdf hoáº·c txt Ä‘á»u Ä‘Æ°á»£c), 100 file, má»—i file cÃ³ Ä‘á»™ dÃ i xáº¥p xá»‰ 10 trang (náº¿u Ã­t hÆ¡n nhÆ°ng khÃ´ng Ä‘Ã¡ng ká»ƒ cÅ©ng Ä‘Æ°á»£c). ps: mÃ¬nh Ä‘Ã£ thá»­ tÃ¬m kiáº¿m datasets trÃªn máº¡ng nhÆ°ng cÃ¡c file cÃ³ Ä‘á»™ dÃ i khÃ¡ ngáº¯n. :( Xin cáº£m Æ¡n.",,,,,
"ChÃ o cÃ¡c anh chá»‹, em cÃ³ base lÃ  IT Android App má»›i báº» ngang sang con Ä‘Æ°á»ng nÃ y vÃ¬ tháº¥y khÃ¡ lÃ  thÃ­ch thÃº.
Em cÃ³ má»™t váº¥n Ä‘á» lÃ  lÃºc Ä‘i apply intern hoáº·c trainee thÃ¬ háº§u nhÆ° bá»‹ fail ráº¥t náº·ng. ÄÆ°á»£c má»™t anh báº£o lÃ  nÃªn lÃ m má»™t vÃ i project Ä‘Ã£ bá» vÃ o CV rá»“i háº³n Ä‘i apply láº¡i. Em cÃ³ google qua nhÆ°ng ko biáº¿t lÃ  do keyword chÆ°a Ä‘Ãºng hay tháº¿ nÃ o nÃªn ko cÃ³ káº¿t quáº£ nhÆ° mong muá»‘n. Em viáº¿t post nÃ y nhá» cÃ¡c anh chá»‹ tÆ° váº¥n xem lÃ  Ä‘i kiáº¿m thÃ´ng tin/gá»£i Ã½ vá» cÃ¡c project mÃ¬nh cÃ³ thá»ƒ lÃ m á»Ÿ Ä‘Ã¢u, trang web nÃ o áº¡.","ChÃ o cÃ¡c anh chá»‹, em cÃ³ base lÃ  IT Android App má»›i báº» ngang sang con Ä‘Æ°á»ng nÃ y vÃ¬ tháº¥y khÃ¡ lÃ  thÃ­ch thÃº. Em cÃ³ má»™t váº¥n Ä‘á» lÃ  lÃºc Ä‘i apply intern hoáº·c trainee thÃ¬ háº§u nhÆ° bá»‹ fail ráº¥t náº·ng. ÄÆ°á»£c má»™t anh báº£o lÃ  nÃªn lÃ m má»™t vÃ i project Ä‘Ã£ bá» vÃ o CV rá»“i háº³n Ä‘i apply láº¡i. Em cÃ³ google qua nhÆ°ng ko biáº¿t lÃ  do keyword chÆ°a Ä‘Ãºng hay tháº¿ nÃ o nÃªn ko cÃ³ káº¿t quáº£ nhÆ° mong muá»‘n. Em viáº¿t post nÃ y nhá» cÃ¡c anh chá»‹ tÆ° váº¥n xem lÃ  Ä‘i kiáº¿m thÃ´ng tin/gá»£i Ã½ vá» cÃ¡c project mÃ¬nh cÃ³ thá»ƒ lÃ m á»Ÿ Ä‘Ã¢u, trang web nÃ o áº¡.",,,,,
,nan,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, cho phÃ©p em xin há»i báº±ng tiáº¿ng Anh bá»Ÿi em sá»£ em há»i tiáº¿ng Viá»‡t khÃ´ng bá»‹ rÃµ Ã½ lÃ m Æ¡n khÃ´ng nÃ©m Ä‘Ã¡ áº¡
Ultimately, what is the practicality of image classification?
Wouldn't the goal of image classification in the end overlap with image recognition since in real life scenarios, you would not likely to have a perfectly cropped image of an animal/object/human to put through the model.
This question might seem so basic you would think I'm trolling but I'm not. If the image isn't well cropped and get put through the program after the deployment of model, wouldn't it need to be detected that there is an object in the picture first before classifier can work?
Say that you train a model with 99% accuracy with input shape of (3, 224, 224), for the model to work in real life after deployment, would you need to cut up an input images to multiple square image with RGB mode and feed it through the algorithm for it to work as a classifier?","Em chÃ o má»i ngÆ°á»i áº¡, cho phÃ©p em xin há»i báº±ng tiáº¿ng Anh bá»Ÿi em sá»£ em há»i tiáº¿ng Viá»‡t khÃ´ng bá»‹ rÃµ Ã½ lÃ m Æ¡n khÃ´ng nÃ©m Ä‘Ã¡ áº¡ Ultimately, what is the practicality of image classification? Wouldn't the goal of image classification in the end overlap with image recognition since in real life scenarios, you would not likely to have a perfectly cropped image of an animal/object/human to put through the model. This question might seem so basic you would think I'm trolling but I'm not. If the image isn't well cropped and get put through the program after the deployment of model, wouldn't it need to be detected that there is an object in the picture first before classifier can work? Say that you train a model with 99% accuracy with input shape of (3, 224, 224), for the model to work in real life after deployment, would you need to cut up an input images to multiple square image with RGB mode and feed it through the algorithm for it to work as a classifier?",,,,,
"SAT - Styled Augmented Translation released! (better than Google Translate on some test sets & keep improving)
Here is state-of-the-art Neural Machine Translation model for Vietnamese community project made by VietAI Alumni (Chinh Ngo) & Google Advisor (Trieu Trinh). Special thanks to invaluable guidances from VietAI advisors Thang Luong, Thu Nguyen, and Phat Hoang on the project development, Dung Le for Web support, and An Tong for the Artwork Design.
TEST SET 1
Input:
Edward chose his words carefully. ""It is a great honor, honey, and I'm sure it's not one they would offer lightly. They must have had good reason for choosing you."" He hesitated. ""We have to think about this very carefully. About what it would do to our lives.""
Google Translate:
Edward lá»±a chá»n lá»i nÃ³i cá»§a mÃ¬nh má»™t cÃ¡ch cáº©n tháº­n. ""ÄÃ³ lÃ  má»™t vinh dá»± lá»›n, em yÃªu, vÃ  anh cháº¯c cháº¯n Ä‘Ã³ khÃ´ng pháº£i lÃ  má»™t vinh dá»± mÃ  há» sáº½ Ä‘Æ°a ra má»™t cÃ¡ch nháº¹ nhÃ ng. Há» pháº£i cÃ³ lÃ½ do chÃ­nh Ä‘Ã¡ng Ä‘á»ƒ chá»n báº¡n."" Anh ngáº­p ngá»«ng. ""ChÃºng tÃ´i pháº£i suy nghÄ© vá» Ä‘iá»u nÃ y ráº¥t cáº©n tháº­n. Vá» nhá»¯ng gÃ¬ nÃ³ sáº½ lÃ m cho cuá»™c sá»‘ng cá»§a chÃºng tÃ´i.""
Our model:
Edward cáº©n tháº­n lá»±a chá»n tá»« ngá»¯ cá»§a mÃ¬nh. ""ÄÃ³ lÃ  má»™t vinh dá»± lá»›n lao, con yÃªu, vÃ  bá»‘ cháº¯c cháº¯n ráº±ng Ä‘Ã³ khÃ´ng pháº£i lÃ  thá»© mÃ  há» sáº½ Ä‘á» nghá»‹ má»™t cÃ¡ch nháº¹ nhÃ ng. Há» háº³n pháº£i cÃ³ lÃ½ do chÃ­nh Ä‘Ã¡ng Ä‘á»ƒ chá»n con."" Anh ngáº­p ngá»«ng. ""ChÃºng ta pháº£i suy nghÄ© tháº­t cáº©n tháº­n vá» Ä‘iá»u nÃ y. Vá» nhá»¯ng gÃ¬ nÃ³ sáº½ lÃ m vá»›i cuá»™c sá»‘ng cá»§a chÃºng ta.""
Blog: https://blog.vietai.org/sat/
Try it out: https://demo.vietai.org/","SAT - Styled Augmented Translation released! (better than Google Translate on some test sets & keep improving) Here is state-of-the-art Neural Machine Translation model for Vietnamese community project made by VietAI Alumni (Chinh Ngo) & Google Advisor (Trieu Trinh). Special thanks to invaluable guidances from VietAI advisors Thang Luong, Thu Nguyen, and Phat Hoang on the project development, Dung Le for Web support, and An Tong for the Artwork Design. TEST SET 1 Input: Edward chose his words carefully. ""It is a great honor, honey, and I'm sure it's not one they would offer lightly. They must have had good reason for choosing you."" He hesitated. ""We have to think about this very carefully. About what it would do to our lives."" Google Translate: Edward lá»±a chá»n lá»i nÃ³i cá»§a mÃ¬nh má»™t cÃ¡ch cáº©n tháº­n. ""ÄÃ³ lÃ  má»™t vinh dá»± lá»›n, em yÃªu, vÃ  anh cháº¯c cháº¯n Ä‘Ã³ khÃ´ng pháº£i lÃ  má»™t vinh dá»± mÃ  há» sáº½ Ä‘Æ°a ra má»™t cÃ¡ch nháº¹ nhÃ ng. Há» pháº£i cÃ³ lÃ½ do chÃ­nh Ä‘Ã¡ng Ä‘á»ƒ chá»n báº¡n."" Anh ngáº­p ngá»«ng. ""ChÃºng tÃ´i pháº£i suy nghÄ© vá» Ä‘iá»u nÃ y ráº¥t cáº©n tháº­n. Vá» nhá»¯ng gÃ¬ nÃ³ sáº½ lÃ m cho cuá»™c sá»‘ng cá»§a chÃºng tÃ´i."" Our model: Edward cáº©n tháº­n lá»±a chá»n tá»« ngá»¯ cá»§a mÃ¬nh. ""ÄÃ³ lÃ  má»™t vinh dá»± lá»›n lao, con yÃªu, vÃ  bá»‘ cháº¯c cháº¯n ráº±ng Ä‘Ã³ khÃ´ng pháº£i lÃ  thá»© mÃ  há» sáº½ Ä‘á» nghá»‹ má»™t cÃ¡ch nháº¹ nhÃ ng. Há» háº³n pháº£i cÃ³ lÃ½ do chÃ­nh Ä‘Ã¡ng Ä‘á»ƒ chá»n con."" Anh ngáº­p ngá»«ng. ""ChÃºng ta pháº£i suy nghÄ© tháº­t cáº©n tháº­n vá» Ä‘iá»u nÃ y. Vá» nhá»¯ng gÃ¬ nÃ³ sáº½ lÃ m vá»›i cuá»™c sá»‘ng cá»§a chÃºng ta."" Blog: https://blog.vietai.org/sat/ Try it out: https://demo.vietai.org/",,,,,
"Cho em há»i trong paper Meta Pseudo Labels (https://arxiv.org/abs/2003.10580) á»Ÿ pháº§n A. Táº¡i sao tÃ¡c giáº£ láº¡i ghi cÃ¢u ""In expectation, the student's ... "" (cÃ¢u khoanh Ä‘á» áº¡). Cá»¥ thá»ƒ lÃ :
- Táº¡i sao láº¡i cÃ³ expectation áº¡ ?
- Táº¡i sao láº¡i cÃ³ Ä‘áº¡o hÃ m theo learning rate áº¡?
Dáº¡ em xin cáº£m Æ¡n má»i ngÆ°á»i.","Cho em há»i trong paper Meta Pseudo Labels (https://arxiv.org/abs/2003.10580) á»Ÿ pháº§n A. Táº¡i sao tÃ¡c giáº£ láº¡i ghi cÃ¢u ""In expectation, the student's ... "" (cÃ¢u khoanh Ä‘á» áº¡). Cá»¥ thá»ƒ lÃ : - Táº¡i sao láº¡i cÃ³ expectation áº¡ ? - Táº¡i sao láº¡i cÃ³ Ä‘áº¡o hÃ m theo learning rate áº¡? Dáº¡ em xin cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Dá»± Ã¡n cá»§a NVIDIA cho viá»‡c sá»­ dá»¥ng CUDA (há»— trá»£ tÃ­nh toÃ¡n trÃªn GPU) tÄƒng tá»‘c xá»­ lÃ­ dá»¯ liá»‡u dáº¡ng báº£ng gá»i lÃ  RAPID vá»›i package cudf. Theo thÃ´ng tin chÃ­nh thá»©c tá»« RAPID, cudf cho tá»‘c Ä‘á»™ tÃ­nh toÃ¡n nhanh hÆ¡n 35 láº§n so vá»›i PANDAS vÃ  Scikit-learn, hai packages ráº¥t phá»• biáº¿n vá»›i viá»‡c cÃ¡c báº¡n lÃ m viá»‡c vá»›i dá»¯ liá»‡u dáº¡ng báº£ng vÃ  Machine Learning, hiÃªn má»›i chá»‰ há»— trá»£ tÃ­nh toÃ¡n trÃªn CPU. NgoÃ i Python ra, cudf cÃ²n há»— trá»£ ráº¥t cho cáº£ Java. Tutorials cÅ©ng khÃ¡ háº¥p dáº«n, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y:","Dá»± Ã¡n cá»§a NVIDIA cho viá»‡c sá»­ dá»¥ng CUDA (há»— trá»£ tÃ­nh toÃ¡n trÃªn GPU) tÄƒng tá»‘c xá»­ lÃ­ dá»¯ liá»‡u dáº¡ng báº£ng gá»i lÃ  RAPID vá»›i package cudf. Theo thÃ´ng tin chÃ­nh thá»©c tá»« RAPID, cudf cho tá»‘c Ä‘á»™ tÃ­nh toÃ¡n nhanh hÆ¡n 35 láº§n so vá»›i PANDAS vÃ  Scikit-learn, hai packages ráº¥t phá»• biáº¿n vá»›i viá»‡c cÃ¡c báº¡n lÃ m viá»‡c vá»›i dá»¯ liá»‡u dáº¡ng báº£ng vÃ  Machine Learning, hiÃªn má»›i chá»‰ há»— trá»£ tÃ­nh toÃ¡n trÃªn CPU. NgoÃ i Python ra, cudf cÃ²n há»— trá»£ ráº¥t cho cáº£ Java. Tutorials cÅ©ng khÃ¡ háº¥p dáº«n, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y:",,,,,
"Sharing:
CÃ¡ch thá»©c Jukebox training model Ä‘á»ƒ sÃ¡ng tÃ¡c Ã¢m nháº¡c, Ä‘áº·c biá»‡t lÃ  nguá»“n data Ä‘áº§u vÃ o, khÃ¡ thÃº vá»‹. Ráº¥t trÃ´ng chá» vÃ o tÆ°Æ¡ng lai cá»§a dá»± Ã¡n nÃ y.
#AI #jukebox #machinelearning #VEFAcademy","Sharing: CÃ¡ch thá»©c Jukebox training model Ä‘á»ƒ sÃ¡ng tÃ¡c Ã¢m nháº¡c, Ä‘áº·c biá»‡t lÃ  nguá»“n data Ä‘áº§u vÃ o, khÃ¡ thÃº vá»‹. Ráº¥t trÃ´ng chá» vÃ o tÆ°Æ¡ng lai cá»§a dá»± Ã¡n nÃ y.",#AI	#jukebox	#machinelearning	#VEFAcademy,,,,
Cho mÃ¬nh há»i lÃ  trong group cÃ³ ai lÃ m vá» nháº­n dáº¡ng chá»¯ kÃ½ (tá»« áº£nh hoáº·c trong file pdf) khÃ´ng nhá»‰?,Cho mÃ¬nh há»i lÃ  trong group cÃ³ ai lÃ m vá» nháº­n dáº¡ng chá»¯ kÃ½ (tá»« áº£nh hoáº·c trong file pdf) khÃ´ng nhá»‰?,,,,,
"Dáº¡ em chÃ o cÃ¡c anh/chá»‹ áº¡.
Em cÃ³ má»™t tháº¯c máº¯c mong Ä‘Æ°á»£c cÃ¡c anh/chá»‹ giáº£i Ä‘Ã¡p giÃºp em vá»›i áº¡. ÄÃ³ lÃ  viá»‡c cÃ¡c ná»n táº£ng máº¡ng xÃ£ há»™i sá»­ dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o phÃ¢n tÃ­ch dá»¯ liá»‡u tÃ¬m kiáº¿m cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ Ä‘á» xuáº¥t quáº£ng cÃ¡o sáº½ mang láº¡i nhá»¯ng lá»£i Ã­ch váº­y áº¡? VÃ  viá»‡c nÃ y cÃ³ xÃ¢m pháº¡m Ä‘áº¿n thÃ´ng tin cÃ¡ nhÃ¢n cá»§a ngÆ°á»i dÃ¹ng khÃ´ng áº¡?",Dáº¡ em chÃ o cÃ¡c anh/chá»‹ áº¡. Em cÃ³ má»™t tháº¯c máº¯c mong Ä‘Æ°á»£c cÃ¡c anh/chá»‹ giáº£i Ä‘Ã¡p giÃºp em vá»›i áº¡. ÄÃ³ lÃ  viá»‡c cÃ¡c ná»n táº£ng máº¡ng xÃ£ há»™i sá»­ dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o phÃ¢n tÃ­ch dá»¯ liá»‡u tÃ¬m kiáº¿m cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ Ä‘á» xuáº¥t quáº£ng cÃ¡o sáº½ mang láº¡i nhá»¯ng lá»£i Ã­ch váº­y áº¡? VÃ  viá»‡c nÃ y cÃ³ xÃ¢m pháº¡m Ä‘áº¿n thÃ´ng tin cÃ¡ nhÃ¢n cá»§a ngÆ°á»i dÃ¹ng khÃ´ng áº¡?,,,,,
"Hi má»i ngÆ°á»i, hiá»‡n mÃ¬nh cÃ³ má»™t dá»± Ã¡n sá»­ dá»¥ng Telematics data. Má»™t trong nhá»¯ng objective cá»§a dá»± Ã¡n lÃ  phÃ¢n tÃ­ch áº£nh hÆ°á»Ÿng cá»§a tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng xung quanh Ä‘áº¿n driving behavior. VÃ¬ lÃ½ do báº£o máº­t mÃ¬nh khÃ´ng thá»ƒ share data lÃªn Ä‘Ã¢y Ä‘Æ°á»£c, nhÆ°ng Ä‘áº¡i khÃ¡i trÃ´ng nhÆ° sau:
trip_id: uuid of a trip
driver_id: uuid of a driver
timestamp_start: when trip started
timestamp_end: when trip stopped
gps_lat: gps coordinate
gps_long: gps coordinate
events: telematics captured event (breaking, acceleration, speeding, distraction)
timestamp_event: when event happened
road_type: highway, primary, secondary, etc
speed_limit
...
Target variable lÃ  counts(event) per trip. MÃ¬nh Ä‘ang nghÄ© lÃ  sá»­ dá»¥ng ANOVA Ä‘á»ƒ test xem cÃ³ sá»± khÃ¡c biá»‡t nÃ o giá»¯a cÃ¡c road_type (for example) hay khÃ´ng. NhÆ°ng nhá»¯ng events nÃ y á»Ÿ má»™t timestamp nháº¥t Ä‘á»‹nh (cung Ä‘Æ°á»ng nháº¥t Ä‘á»‹nh) cÅ©ng khÃ´ng pháº£i lÃ  independent. Tháº¿ thÃ¬ trong trÆ°á»ng há»£p nÃ y statistical test nÃ o lÃ  thÃ­ch há»£p nháº¥t? CÃ³ báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ cho Ã­t feedback khÃ´ng áº¡. MÃ¬nh cÃ¡m Æ¡n","Hi má»i ngÆ°á»i, hiá»‡n mÃ¬nh cÃ³ má»™t dá»± Ã¡n sá»­ dá»¥ng Telematics data. Má»™t trong nhá»¯ng objective cá»§a dá»± Ã¡n lÃ  phÃ¢n tÃ­ch áº£nh hÆ°á»Ÿng cá»§a tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng xung quanh Ä‘áº¿n driving behavior. VÃ¬ lÃ½ do báº£o máº­t mÃ¬nh khÃ´ng thá»ƒ share data lÃªn Ä‘Ã¢y Ä‘Æ°á»£c, nhÆ°ng Ä‘áº¡i khÃ¡i trÃ´ng nhÆ° sau: trip_id: uuid of a trip driver_id: uuid of a driver timestamp_start: when trip started timestamp_end: when trip stopped gps_lat: gps coordinate gps_long: gps coordinate events: telematics captured event (breaking, acceleration, speeding, distraction) timestamp_event: when event happened road_type: highway, primary, secondary, etc speed_limit ... Target variable lÃ  counts(event) per trip. MÃ¬nh Ä‘ang nghÄ© lÃ  sá»­ dá»¥ng ANOVA Ä‘á»ƒ test xem cÃ³ sá»± khÃ¡c biá»‡t nÃ o giá»¯a cÃ¡c road_type (for example) hay khÃ´ng. NhÆ°ng nhá»¯ng events nÃ y á»Ÿ má»™t timestamp nháº¥t Ä‘á»‹nh (cung Ä‘Æ°á»ng nháº¥t Ä‘á»‹nh) cÅ©ng khÃ´ng pháº£i lÃ  independent. Tháº¿ thÃ¬ trong trÆ°á»ng há»£p nÃ y statistical test nÃ o lÃ  thÃ­ch há»£p nháº¥t? CÃ³ báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ cho Ã­t feedback khÃ´ng áº¡. MÃ¬nh cÃ¡m Æ¡n",,,,,
,nan,,,,,
"GiÃ¡o sÆ° Mehdi Bennis, IEEE Fellow (big name), tá»« University of Oulu, Pháº§n Lan, Ä‘ang tÃ¬m cÃ¡c báº¡n PhD students vÃ  Posdoc ngÆ°á»i Viá»‡t giá»i vá» machine learning (lÃ½ thuyáº¿t vÃ  thá»±c nghiá»‡m) Ä‘á»ƒ join team cá»§a bÃ¡c. BÃ¡c vá»«a má»›i kiáº¿m Ä‘Æ°á»£c fund, muá»‘n lÃ m research vá»
Machine learning for Edge Networks/Fog Networks
Edge Networks/Fog Networks for Machine Learning
Äá»‘i vá»›i PhD students, bÃ¡c yÃªu cáº§u Ä‘iá»ƒm cao (GPA) vÃ  Ä‘Ã£ cÃ³ publications, bÃ¡c ok luÃ´n vá»›i há»™i nghá»‹ trong nÆ°á»›c cá»§a VN, tuy nhiÃªn bÃ¡c khÃ´ng rush trong viá»‡c tÃ¬m sinh viÃªn, miá»…n lÃ  nÄƒng lá»±c tá»‘t.
Äá»‘i vá»›i Posdoc, bÃ¡c mong tÃ¬m researcher ngÆ°á»i Viá»‡t cÃ³ publications trÃªn top-tier journals/conferences.
Náº¿u cáº§n biáº¿t thÃªm thÃ´ng tin thÃ¬ cÃ³ thá»ƒ liÃªn há»‡ trá»±c tiáº¿p vá»›i bÃ¡c mehdi dot bennis at oulu dot fi hoáº·c lÃ  email mÃ¬nh thinhdinh at ieee dot org","GiÃ¡o sÆ° Mehdi Bennis, IEEE Fellow (big name), tá»« University of Oulu, Pháº§n Lan, Ä‘ang tÃ¬m cÃ¡c báº¡n PhD students vÃ  Posdoc ngÆ°á»i Viá»‡t giá»i vá» machine learning (lÃ½ thuyáº¿t vÃ  thá»±c nghiá»‡m) Ä‘á»ƒ join team cá»§a bÃ¡c. BÃ¡c vá»«a má»›i kiáº¿m Ä‘Æ°á»£c fund, muá»‘n lÃ m research vá» Machine learning for Edge Networks/Fog Networks Edge Networks/Fog Networks for Machine Learning Äá»‘i vá»›i PhD students, bÃ¡c yÃªu cáº§u Ä‘iá»ƒm cao (GPA) vÃ  Ä‘Ã£ cÃ³ publications, bÃ¡c ok luÃ´n vá»›i há»™i nghá»‹ trong nÆ°á»›c cá»§a VN, tuy nhiÃªn bÃ¡c khÃ´ng rush trong viá»‡c tÃ¬m sinh viÃªn, miá»…n lÃ  nÄƒng lá»±c tá»‘t. Äá»‘i vá»›i Posdoc, bÃ¡c mong tÃ¬m researcher ngÆ°á»i Viá»‡t cÃ³ publications trÃªn top-tier journals/conferences. Náº¿u cáº§n biáº¿t thÃªm thÃ´ng tin thÃ¬ cÃ³ thá»ƒ liÃªn há»‡ trá»±c tiáº¿p vá»›i bÃ¡c mehdi dot bennis at oulu dot fi hoáº·c lÃ  email mÃ¬nh thinhdinh at ieee dot org",,,,,
"[ MACHINE LEARNING 2 MONTHS ]
Xin chÃ o má»i ngÆ°á»i ğŸ˜„. ÄÃ¢y lÃ  má»™t dá»± Ã¡n nho nhá» mÃ¬nh Ä‘Ã£ muá»‘n thá»±c hiá»‡n tá»« ráº¥t lÃ¢u vÃ  quyáº¿t tÃ¢m sáº½ lÃ m trong vÃ²ng 2 thÃ¡ng tá»›i.
Má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ há»c, cá»§ng cá»‘ nhá»¯ng gÃ¬ mÃ¬nh sáº½ há»c trong thá»i gian sáº¯p tá»›i vÃ  chia sáº» cho má»i ngÆ°á»i, cá»™ng Ä‘á»“ng, nhá»¯ng báº¡n Ä‘ang vÃ  muá»‘n tÃ¬m hiá»ƒu lÄ©nh vá»±c nÃ y cÃ¹ng vá»›i mÃ¬nh. á» Ä‘Ã¢y mÃ¬nh sáº½ tÃ³m táº¯t láº¡i nhá»¯ng gÃ¬ mÃ¬nh hiá»ƒu qua pháº§n lÃ½ thuyáº¿t vÃ  cÃ³ cáº£ pháº§n code cho tá»«ng pháº§n Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o vÃ  Ä‘Ã³ng gÃ³p Ã½ kiáº¿n Ä‘á»ƒ mÃ¬nh cáº£i thiá»‡n thÃªm. MÃ¬nh Ä‘áº·t giá»›i háº¡n 2 thÃ¡ng Ä‘á»ƒ táº¡o Ã¡p lá»±c thá»i gian cho báº£n thÃ¢n vÃ¬ mÃ¬nh muá»‘n hoÃ n thÃ nh trong má»™t khoáº£ng thá»i gian khÃ´ng quÃ¡ ngáº¯n cÅ©ng khÃ´ng pháº£i quÃ¡ dÃ i vá»«a Ä‘á»§ Ä‘á»ƒ cÃ³ má»™t ná»n táº£ng tá»‘t.
MÃ¬nh sáº½ cáº­p thÆ°á»ng xuyÃªn tiáº¿n Ä‘á»™ ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ vÃ  á»§ng há»™ trong thá»i gian sáº¯p tá»›i. ğŸ˜ƒ","[ MACHINE LEARNING 2 MONTHS ] Xin chÃ o má»i ngÆ°á»i . ÄÃ¢y lÃ  má»™t dá»± Ã¡n nho nhá» mÃ¬nh Ä‘Ã£ muá»‘n thá»±c hiá»‡n tá»« ráº¥t lÃ¢u vÃ  quyáº¿t tÃ¢m sáº½ lÃ m trong vÃ²ng 2 thÃ¡ng tá»›i. Má»¥c Ä‘Ã­ch lÃ  Ä‘á»ƒ há»c, cá»§ng cá»‘ nhá»¯ng gÃ¬ mÃ¬nh sáº½ há»c trong thá»i gian sáº¯p tá»›i vÃ  chia sáº» cho má»i ngÆ°á»i, cá»™ng Ä‘á»“ng, nhá»¯ng báº¡n Ä‘ang vÃ  muá»‘n tÃ¬m hiá»ƒu lÄ©nh vá»±c nÃ y cÃ¹ng vá»›i mÃ¬nh. á» Ä‘Ã¢y mÃ¬nh sáº½ tÃ³m táº¯t láº¡i nhá»¯ng gÃ¬ mÃ¬nh hiá»ƒu qua pháº§n lÃ½ thuyáº¿t vÃ  cÃ³ cáº£ pháº§n code cho tá»«ng pháº§n Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o vÃ  Ä‘Ã³ng gÃ³p Ã½ kiáº¿n Ä‘á»ƒ mÃ¬nh cáº£i thiá»‡n thÃªm. MÃ¬nh Ä‘áº·t giá»›i háº¡n 2 thÃ¡ng Ä‘á»ƒ táº¡o Ã¡p lá»±c thá»i gian cho báº£n thÃ¢n vÃ¬ mÃ¬nh muá»‘n hoÃ n thÃ nh trong má»™t khoáº£ng thá»i gian khÃ´ng quÃ¡ ngáº¯n cÅ©ng khÃ´ng pháº£i quÃ¡ dÃ i vá»«a Ä‘á»§ Ä‘á»ƒ cÃ³ má»™t ná»n táº£ng tá»‘t. MÃ¬nh sáº½ cáº­p thÆ°á»ng xuyÃªn tiáº¿n Ä‘á»™ ráº¥t mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ vÃ  á»§ng há»™ trong thá»i gian sáº¯p tá»›i.",,,,,
má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  náº¿u dÃ¹ng giáº£i thuáº­t lá»c cá»™ng tÃ¡c thÃ¬ cÃ³ khi nÃ o xáº£y ra tÃ¬nh tráº¡ng lÃ  náº¿u má»™t ngÆ°á»i dÃ¹ng chÆ°a bÃ¬nh chá»n cho sáº£n pháº©m nÃ o thÃ¬ ta sáº½ khÃ´ng gá»£i Ã½ Ä‘Æ°á»£c sáº£n pháº©m mÃ  cÃ³ thá»ƒ ngÆ°á»i dÃ¹ng Ä‘Ã³ sáº½ thÃ­ch khÃ´ng má»i ngÆ°á»i?,má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  náº¿u dÃ¹ng giáº£i thuáº­t lá»c cá»™ng tÃ¡c thÃ¬ cÃ³ khi nÃ o xáº£y ra tÃ¬nh tráº¡ng lÃ  náº¿u má»™t ngÆ°á»i dÃ¹ng chÆ°a bÃ¬nh chá»n cho sáº£n pháº©m nÃ o thÃ¬ ta sáº½ khÃ´ng gá»£i Ã½ Ä‘Æ°á»£c sáº£n pháº©m mÃ  cÃ³ thá»ƒ ngÆ°á»i dÃ¹ng Ä‘Ã³ sáº½ thÃ­ch khÃ´ng má»i ngÆ°á»i?,,,,,
"ChÃ o má»i ngÆ°á»i,
Bá»¯a trÆ°á»›c mÃ¬nh tháº¥y cÃ³ má»™t bÃ i chia sáº» khÃ¡ hay vá» stacking. VÃ¬ stacking cÅ©ng lÃ  má»™t dáº¡ng ensemble, nÃªn hÃ´m nay mÃ¬nh xin giá»›i thiá»‡u thÃªm vá» project mÃ¬nh Ä‘ang lÃ m, trong Ä‘Ã³ náº¿u khÃ´ng cÃ³ ensemble thÃ¬ khÃ´ng thá»ƒ dÃ¹ng Ä‘Æ°á»£c.
BÃ i toÃ¡n á»Ÿ Ä‘Ã¢y lÃ  khi thiáº¿t káº¿ má»™t máº«u xe Ã´ tÃ´ má»›i (cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y lÃ  3 hÃ£ng mÃ  mÃ¬nh dÃ¹ng data: Renault, BMW, Volvo), cÃ¡c ká»¹ sÆ° cÃ³ ráº¥t nhiá»u option: Ä‘Ã¨n sáº½ Ä‘áº·t á»Ÿ Ä‘Ã¢u, loa, camera, sensor, â€¦. Má»—i thiáº¿t bá»‹ sáº½ pháº£i káº¿t ná»‘i vÃ o má»™t bá»™ xá»­ lÃ½ (ECU - Electronic Control Unit). CÃ³ khoáº£ng hÆ¡n 100 ECU cho má»™t chiáº¿c xe, Ä‘á»ƒ xá»­ lÃ½ khoáº£ng vÃ i ngÃ n function. Nhá»¯ng ECU nÃ y sáº½ giao tiáº¿p vá»›i nhau vÃ  táº¡o ra data stream. YÃªu cáº§u tiÃªn quyáº¿t lÃ  khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ stream nÃ o trá»… deadline (vÃ¬ váº­y ngÃ nh nÃ y gá»i lÃ  real-time system, nghÄ©a lÃ  Ä‘Ãºng thá»i gian). Má»™t network khÃ´ng cÃ³ stream nÃ o trá»… deadline lÃ  má»™t feasible network.
Quy trÃ¬nh lÃ  cÃ¡c ká»¹ sÆ° pháº£i dá»±a vÃ o kinh nghiá»‡m Ä‘á»ƒ chá»n ra má»™t vÃ i network, kiá»ƒm tra xem cÃ³ feasible hay khÃ´ng vÃ  Ä‘Æ°a lÃªn cho cáº¥p trÃªn duyá»‡t. Láº·p Ä‘i láº·p láº¡i nhÆ° váº­y khoáº£ng vÃ i thÃ¡ng thÃ¬ xong pháº§n thiáº¿t káº¿ communication network cho má»™t máº«u xe.
Váº¥n Ä‘á» lÃ  cÃ³ hÃ ng triá»‡u network cÃ³ thá»ƒ cÃ³. Náº¿u chá»‰ dá»±a vÃ o kinh nghiá»‡m thÃ¬ sáº½ bá» lá»¡ ráº¥t nhiá»u network tá»‘t hÆ¡n. Náº¿u cÃ³ thá»ƒ kiá»ƒm tra 1 triá»‡u network coi thá»­ cÃ³ feasible hay khÃ´ng thÃ¬ hay biáº¿t máº¥y. Viá»‡c Ä‘Ã³ khÃ´ng kháº£ thi vá»›i cÃ´ng nghá»‡ hiá»‡n táº¡i (Æ°á»›c tÃ­nh máº¥t vÃ i tuáº§n lÃ  Ã­t nháº¥t).
Giáº£i phÃ¡p mÃ¬nh Ä‘Æ°a ra lÃ  dÃ¹ng Deep Learning Ä‘á»ƒ dá»± Ä‘oÃ¡n xem network nÃ o lÃ  feasible. Cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y lÃ  mÃ¬nh dÃ¹ng Graph Neural Network (GNN) Ä‘á»ƒ encode cÃ¡c real-time network nÃ y vÃ  dÃ¹ng khoáº£ng 10.000 network cÃ³ label Ä‘á»ƒ train. Sau nÃ y thÃ¬ mÃ¬nh tÄƒng lÃªn thÃ nh 20.000 labelled network vÃ  cá»™ng thÃªm má»™t chÃºt cáº£i tiáº¿n vá»›i máº¡ng GNN.
NhÆ°ng Ä‘á»i khÃ´ng nhÆ° lÃ  mÆ¡. Trong cÃ¡c bÃ i toÃ¡n cÃ´ng nghiá»‡p, cÃ¡i quan trá»ng nháº¥t vá»›i ML khÃ´ng pháº£i lÃ  training data, mÃ  lÃ  testing data. MÃ¬nh nháº¯c láº¡i nhÃ©: testing data lÃ  cÃ¡i quan trá»ng sá»‘ má»™t, vÃ¬ Ä‘Ã³ chÃ­nh lÃ  cÃ¡i thá»±c táº¿. MÃ¬nh cÃ³ thá»ƒ train vá»›i báº¥t kÃ¬ data nÃ o mÃ¬nh thÃ­ch, nhÆ°ng cÃ¡c hÃ£ng xe chá»‰ Ä‘Æ°a ra má»™t sá»‘ network cá»§a há» vÃ  mÃ¬nh khÃ´ng thá»ƒ hi vá»ng gÃ¬ thÃªm. Tá»•ng cá»™ng mÃ¬nh cÃ³ Ä‘Æ°á»£c 13 testing network. Vá»›i má»—i testing network mÃ¬nh táº¡o ra 1000 sample (giá»¯ nguyÃªn topology nhÆ°ng thay Ä‘á»•i data stream), vÃ  táº¥t nhiÃªn pháº£i report Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng testing network má»™t.
Ãc má»™ng á»Ÿ Ä‘Ã¢y lÃ  mÃ¬nh cÃ³ train tá»‘t tá»›i Ä‘Ã¢u thÃ¬ má»™t model GNN cÅ©ng chá»‰ cÃ³ thá»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao vá»›i vÃ i testing network nhÆ°ng khÃ´ng pháº£i lÃ  táº¥t cáº£. Äiá»u nÃ y ráº¥t thá»±c táº¿, mÃ¬nh hi vá»ng gÃ¬ má»™t GNN model cÃ³ thá»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao á»Ÿ táº¥t cáº£ má»i topology nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m? Giáº£i phÃ¡p? Ensemble. MÃ¬nh sáº½ táº¡o ra 32 GNN model, initialized weight khÃ¡c nhau, vÃ  train hoÃ n toÃ n nhÆ° nhau (Ä‘iá»u nÃ y tiáº¿t kiá»‡m ráº¥t nhiá»u cÃ´ng sá»©c khi code nhÆ° mÃ¬nh sáº½ nÃ³i sau Ä‘Ã¢y). 32 GNN model nÃ y sáº½ dá»± Ä‘oÃ¡n Ä‘á»™c láº­p vá»›i nhau, vÃ  vá»›i má»—i network mÃ¬nh chá»‰ cáº§n láº¥y theo Ã½ kiáº¿n sá»‘ Ä‘Ã´ng (majority voting) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh lÃ  network cÃ³ feasible hay khÃ´ng. Vá»›i lÃ½ thuyáº¿t nhÆ° váº­y, mÃ¬nh Ä‘Ã£ xÃ­ 32 cÃ¡i GPU V100 tá»« HPC cá»§a trÆ°á»ng vÃ  lÃ m Ä‘i lÃ m láº¡i. á» Ä‘Ã¢y viá»‡c training cÃ¡c model giá»‘ng nhau giÃºp cho mÃ¬nh khÃ´ng cáº§n pháº£i code thÃªm gÃ¬ cáº£, chá»‰ viá»‡c Ä‘á»ƒ cho cÃ¡c GPU hoáº¡t Ä‘á»™ng song song.
Káº¿t quáº£ cuá»‘i cÃ¹ng (nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m) lÃ  ensemble giÃºp cho Ä‘á»™ chÃ­nh xÃ¡c cá»§a báº¥t kÃ¬ testing network nÃ o Ä‘á»u náº±m trong khoáº£ng 80-90%. Sau nÃ y mÃ¬nh Ä‘Ã£ cáº£i tiáº¿n Ä‘á»ƒ tÄƒng lÃªn 85-95%. Ensemble cá»§a 32 GNN model nhanh hÆ¡n phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ khoáº£ng vÃ i ngÃ n láº§n lÃ  Ã­t nháº¥t. Náº¿u khÃ´ng cÃ³ ensemble thÃ¬ mÃ¬nh cÅ©ng khÃ´ng nghÄ© ra Ä‘Æ°á»£c cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ kiá»ƒm soÃ¡t Ä‘á»™ tin cáº­y cá»§a máº¡ng GNN trong bÃ i toÃ¡n cá»§a mÃ¬nh.
ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ vá»›i ensemble cho cÃ¡c báº¡n tham kháº£o khi dÃ¹ng ML trong cÃ´ng nghiá»‡p. Hi vá»ng cÃ¡c báº¡n cÃ³ thÃªm má»™t gÃ³c nhÃ¬n ná»¯a vá» ML nÃ³i chung. ChÃº Ã½ lÃ  hÃ¬nh cÃ¡c hÃ¬nh áº£nh Ä‘Ã­nh kÃ¨m cÃ³ báº£n quyá»n vÃ  khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng náº¿u khÃ´ng Ä‘Æ°á»£c cáº¥p phÃ©p.
Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m.","ChÃ o má»i ngÆ°á»i, Bá»¯a trÆ°á»›c mÃ¬nh tháº¥y cÃ³ má»™t bÃ i chia sáº» khÃ¡ hay vá» stacking. VÃ¬ stacking cÅ©ng lÃ  má»™t dáº¡ng ensemble, nÃªn hÃ´m nay mÃ¬nh xin giá»›i thiá»‡u thÃªm vá» project mÃ¬nh Ä‘ang lÃ m, trong Ä‘Ã³ náº¿u khÃ´ng cÃ³ ensemble thÃ¬ khÃ´ng thá»ƒ dÃ¹ng Ä‘Æ°á»£c. BÃ i toÃ¡n á»Ÿ Ä‘Ã¢y lÃ  khi thiáº¿t káº¿ má»™t máº«u xe Ã´ tÃ´ má»›i (cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y lÃ  3 hÃ£ng mÃ  mÃ¬nh dÃ¹ng data: Renault, BMW, Volvo), cÃ¡c ká»¹ sÆ° cÃ³ ráº¥t nhiá»u option: Ä‘Ã¨n sáº½ Ä‘áº·t á»Ÿ Ä‘Ã¢u, loa, camera, sensor, â€¦. Má»—i thiáº¿t bá»‹ sáº½ pháº£i káº¿t ná»‘i vÃ o má»™t bá»™ xá»­ lÃ½ (ECU - Electronic Control Unit). CÃ³ khoáº£ng hÆ¡n 100 ECU cho má»™t chiáº¿c xe, Ä‘á»ƒ xá»­ lÃ½ khoáº£ng vÃ i ngÃ n function. Nhá»¯ng ECU nÃ y sáº½ giao tiáº¿p vá»›i nhau vÃ  táº¡o ra data stream. YÃªu cáº§u tiÃªn quyáº¿t lÃ  khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ stream nÃ o trá»… deadline (vÃ¬ váº­y ngÃ nh nÃ y gá»i lÃ  real-time system, nghÄ©a lÃ  Ä‘Ãºng thá»i gian). Má»™t network khÃ´ng cÃ³ stream nÃ o trá»… deadline lÃ  má»™t feasible network. Quy trÃ¬nh lÃ  cÃ¡c ká»¹ sÆ° pháº£i dá»±a vÃ o kinh nghiá»‡m Ä‘á»ƒ chá»n ra má»™t vÃ i network, kiá»ƒm tra xem cÃ³ feasible hay khÃ´ng vÃ  Ä‘Æ°a lÃªn cho cáº¥p trÃªn duyá»‡t. Láº·p Ä‘i láº·p láº¡i nhÆ° váº­y khoáº£ng vÃ i thÃ¡ng thÃ¬ xong pháº§n thiáº¿t káº¿ communication network cho má»™t máº«u xe. Váº¥n Ä‘á» lÃ  cÃ³ hÃ ng triá»‡u network cÃ³ thá»ƒ cÃ³. Náº¿u chá»‰ dá»±a vÃ o kinh nghiá»‡m thÃ¬ sáº½ bá» lá»¡ ráº¥t nhiá»u network tá»‘t hÆ¡n. Náº¿u cÃ³ thá»ƒ kiá»ƒm tra 1 triá»‡u network coi thá»­ cÃ³ feasible hay khÃ´ng thÃ¬ hay biáº¿t máº¥y. Viá»‡c Ä‘Ã³ khÃ´ng kháº£ thi vá»›i cÃ´ng nghá»‡ hiá»‡n táº¡i (Æ°á»›c tÃ­nh máº¥t vÃ i tuáº§n lÃ  Ã­t nháº¥t). Giáº£i phÃ¡p mÃ¬nh Ä‘Æ°a ra lÃ  dÃ¹ng Deep Learning Ä‘á»ƒ dá»± Ä‘oÃ¡n xem network nÃ o lÃ  feasible. Cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y lÃ  mÃ¬nh dÃ¹ng Graph Neural Network (GNN) Ä‘á»ƒ encode cÃ¡c real-time network nÃ y vÃ  dÃ¹ng khoáº£ng 10.000 network cÃ³ label Ä‘á»ƒ train. Sau nÃ y thÃ¬ mÃ¬nh tÄƒng lÃªn thÃ nh 20.000 labelled network vÃ  cá»™ng thÃªm má»™t chÃºt cáº£i tiáº¿n vá»›i máº¡ng GNN. NhÆ°ng Ä‘á»i khÃ´ng nhÆ° lÃ  mÆ¡. Trong cÃ¡c bÃ i toÃ¡n cÃ´ng nghiá»‡p, cÃ¡i quan trá»ng nháº¥t vá»›i ML khÃ´ng pháº£i lÃ  training data, mÃ  lÃ  testing data. MÃ¬nh nháº¯c láº¡i nhÃ©: testing data lÃ  cÃ¡i quan trá»ng sá»‘ má»™t, vÃ¬ Ä‘Ã³ chÃ­nh lÃ  cÃ¡i thá»±c táº¿. MÃ¬nh cÃ³ thá»ƒ train vá»›i báº¥t kÃ¬ data nÃ o mÃ¬nh thÃ­ch, nhÆ°ng cÃ¡c hÃ£ng xe chá»‰ Ä‘Æ°a ra má»™t sá»‘ network cá»§a há» vÃ  mÃ¬nh khÃ´ng thá»ƒ hi vá»ng gÃ¬ thÃªm. Tá»•ng cá»™ng mÃ¬nh cÃ³ Ä‘Æ°á»£c 13 testing network. Vá»›i má»—i testing network mÃ¬nh táº¡o ra 1000 sample (giá»¯ nguyÃªn topology nhÆ°ng thay Ä‘á»•i data stream), vÃ  táº¥t nhiÃªn pháº£i report Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng testing network má»™t. Ãc má»™ng á»Ÿ Ä‘Ã¢y lÃ  mÃ¬nh cÃ³ train tá»‘t tá»›i Ä‘Ã¢u thÃ¬ má»™t model GNN cÅ©ng chá»‰ cÃ³ thá»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao vá»›i vÃ i testing network nhÆ°ng khÃ´ng pháº£i lÃ  táº¥t cáº£. Äiá»u nÃ y ráº¥t thá»±c táº¿, mÃ¬nh hi vá»ng gÃ¬ má»™t GNN model cÃ³ thá»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao á»Ÿ táº¥t cáº£ má»i topology nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m? Giáº£i phÃ¡p? Ensemble. MÃ¬nh sáº½ táº¡o ra 32 GNN model, initialized weight khÃ¡c nhau, vÃ  train hoÃ n toÃ n nhÆ° nhau (Ä‘iá»u nÃ y tiáº¿t kiá»‡m ráº¥t nhiá»u cÃ´ng sá»©c khi code nhÆ° mÃ¬nh sáº½ nÃ³i sau Ä‘Ã¢y). 32 GNN model nÃ y sáº½ dá»± Ä‘oÃ¡n Ä‘á»™c láº­p vá»›i nhau, vÃ  vá»›i má»—i network mÃ¬nh chá»‰ cáº§n láº¥y theo Ã½ kiáº¿n sá»‘ Ä‘Ã´ng (majority voting) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh lÃ  network cÃ³ feasible hay khÃ´ng. Vá»›i lÃ½ thuyáº¿t nhÆ° váº­y, mÃ¬nh Ä‘Ã£ xÃ­ 32 cÃ¡i GPU V100 tá»« HPC cá»§a trÆ°á»ng vÃ  lÃ m Ä‘i lÃ m láº¡i. á» Ä‘Ã¢y viá»‡c training cÃ¡c model giá»‘ng nhau giÃºp cho mÃ¬nh khÃ´ng cáº§n pháº£i code thÃªm gÃ¬ cáº£, chá»‰ viá»‡c Ä‘á»ƒ cho cÃ¡c GPU hoáº¡t Ä‘á»™ng song song. Káº¿t quáº£ cuá»‘i cÃ¹ng (nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m) lÃ  ensemble giÃºp cho Ä‘á»™ chÃ­nh xÃ¡c cá»§a báº¥t kÃ¬ testing network nÃ o Ä‘á»u náº±m trong khoáº£ng 80-90%. Sau nÃ y mÃ¬nh Ä‘Ã£ cáº£i tiáº¿n Ä‘á»ƒ tÄƒng lÃªn 85-95%. Ensemble cá»§a 32 GNN model nhanh hÆ¡n phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ khoáº£ng vÃ i ngÃ n láº§n lÃ  Ã­t nháº¥t. Náº¿u khÃ´ng cÃ³ ensemble thÃ¬ mÃ¬nh cÅ©ng khÃ´ng nghÄ© ra Ä‘Æ°á»£c cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ kiá»ƒm soÃ¡t Ä‘á»™ tin cáº­y cá»§a máº¡ng GNN trong bÃ i toÃ¡n cá»§a mÃ¬nh. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ vá»›i ensemble cho cÃ¡c báº¡n tham kháº£o khi dÃ¹ng ML trong cÃ´ng nghiá»‡p. Hi vá»ng cÃ¡c báº¡n cÃ³ thÃªm má»™t gÃ³c nhÃ¬n ná»¯a vá» ML nÃ³i chung. ChÃº Ã½ lÃ  hÃ¬nh cÃ¡c hÃ¬nh áº£nh Ä‘Ã­nh kÃ¨m cÃ³ báº£n quyá»n vÃ  khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng náº¿u khÃ´ng Ä‘Æ°á»£c cáº¥p phÃ©p. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m.",,,,,
MÃ¬nh Ä‘ang cáº§n tÃ¬m cá»™ng tÃ¡c viÃªn Ä‘á»ƒ cÃ¹ng viáº¿t cuá»‘n Machine Learning Algorithms to Practice.,MÃ¬nh Ä‘ang cáº§n tÃ¬m cá»™ng tÃ¡c viÃªn Ä‘á»ƒ cÃ¹ng viáº¿t cuá»‘n Machine Learning Algorithms to Practice.,,,,,
[CÃ¡ch Ä‘Ã³ng gÃ³p cho sÃ¡ch Machine Learning Algorithms to Practice],[CÃ¡ch Ä‘Ã³ng gÃ³p cho sÃ¡ch Machine Learning Algorithms to Practice],,,,,
"LÃ m sao chuyá»ƒn 1 cÃ¢u thÃ nh 1 vector theo dáº¡ng word2vec nhá»‰ cÃ¡c bÃ¡c, em tháº¥y trÃªn máº¡ng thÃ¬ nÃ³ dÃ¹ng cÃ¡ch lÃ  word tokenize ra mean sum cÃ¡c vector tá»« láº¡i nhÆ°ng cÃ¡ch Ä‘Ã³ liá»‡u cÃ³ kháº£ quan khÃ´ng nhá»‰ ?","LÃ m sao chuyá»ƒn 1 cÃ¢u thÃ nh 1 vector theo dáº¡ng word2vec nhá»‰ cÃ¡c bÃ¡c, em tháº¥y trÃªn máº¡ng thÃ¬ nÃ³ dÃ¹ng cÃ¡ch lÃ  word tokenize ra mean sum cÃ¡c vector tá»« láº¡i nhÆ°ng cÃ¡ch Ä‘Ã³ liá»‡u cÃ³ kháº£ quan khÃ´ng nhá»‰ ?",,,,,
"#relax
Máº¥t gá»‘c toÃ¡n Ä‘áº¿n nÆ¡i rá»“i cÃ¡c Ã´ng áº¡",Máº¥t gá»‘c toÃ¡n Ä‘áº¿n nÆ¡i rá»“i cÃ¡c Ã´ng áº¡,#relax,,,,
"CÃ¡ch Ä‘Ã¢y khÃ´ng lÃ¢u, Google Brain Ä‘Ã£ public mÃ£ nguá»“n vÃ   papers chi tiáº¿t vá» EfficientNetV2 - má»™t phiÃªn báº£n ""hoÃ n thiá»‡n vÃ  tá»‘i Æ°u"" hÆ¡n cá»§a EfficientNet, mÃ´ hÃ¬nh CNN Ä‘ang thá»‘ng trá»‹ trong cÃ¡c báº£ng xáº¿p háº¡ng SOTA á»Ÿ cÃ¡c háº¡ng má»¥c vÃ  challenge khÃ¡c nhau vá» computer vision trong 2 nÄƒm gáº§n Ä‘Ã¢y. 
Má»™t sá»‘ Ä‘iá»ƒm Ä‘Ã¡ng chÃº Ã½ cá»§a EfficientNet V2 so vá»›i V1:
1 cáº¥u trÃºc layer má»›i so vá»›i V1: Fused-MBConv.
Sá»­ dá»¥ng NAS (1 máº£ng mÃ  anh Quá»‘c LÃª Ä‘Ã£ cÃ³ ráº¥t nhiá»u publications) vÃ  scaling Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™ vÃ  hiá»‡u quáº£ cá»§a viá»‡c training. 
Sá»­ dá»¥ng adaptively adjusts regularization (káº¿t há»£p Dropout, RandAugment vÃ  Mixup) vá»›i cÃ¡c network vÃ  input size khÃ¡c nhau.
So sÃ¡nh vá»›i EfficientNetB5, V2s nhanh hÆ¡n 12 %, Ã­t params hÆ¡n 17% vÃ  cÃ³ sá»‘ lÆ°á»£ng FLOP tÃ­nh toÃ¡n Ã­t hÆ¡n 12%. Äá»‘i vá»›i cÃ¡c máº¡ng lá»›n hÆ¡n, tá»‘c Ä‘á»™ tÃ­nh toÃ¡n vÃ  sá»‘ lÆ°á»£ng params cÃ ng thá»ƒ hiá»‡n rÃµ sá»± tá»‘i Æ°u. Kiáº¿n thá»©c EfficientNetV2-L bá» xa SOTA hiá»‡n táº¡i (NFNet-F4) cho táº­p ImageNet 21k táº­n 0.9% (86.8 vs 85.9), vá»›i sá»‘ lÆ°á»£ng params chá»‰ báº±ng 1/3 vÃ  sá»‘ lÆ°á»£ng FLOP tháº­m chÃ­ khÃ´ng báº±ng 1/4!
Äá»ƒ tÃ¬m hiá»ƒu ká»¹ hÆ¡n vá» EfficientNet, cÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu chi tiáº¿t á»Ÿ cÃ¡c bÃ i viáº¿t/video sao:
Official paper: https://arxiv.org/pdf/2104.00298.pdf
Video giáº£i thÃ­ch chi tiáº¿t vá» paper: https://www.youtube.com/watch?v=CTsSrOKSPNo
Source code cá»§a nhÃ³m tÃ¡c giáº£ papers: https://github.com/google/automl/efficientnetv2
Source code Pytorch Ä‘Ã£ tÃ­ch há»£p EfficentNetV2: https://github.com/rwightman/pytorch-image-models
  P/s: Hiá»‡n táº¡i Trung tÃ¢m nghiÃªn cá»©u vÃ  á»©ng dá»¥ng AI - QAI (FPT Software Quy NhÆ¡n) giá»›i thiá»‡u chÆ°Æ¡ng trÃ¬nh há»c bá»•ng Machine Learning vÃ  Data Science dÃ nh cho 200 há»c viÃªn vá»›i cam káº¿t cÃ´ng viá»‡c Ä‘áº§u ra vá»›i má»©c lÆ°Æ¡ng vÃ  Ä‘Ã£i ngá»™ háº¥p dáº«n nháº¥t thá»‹ trÆ°á»ng, ngay táº¡i FPT Software Quy NhÆ¡n.
 ÄÄƒng kÃ½ ngay Ä‘á»ƒ trá»Ÿ thÃ nh nhá»¯ng á»©ng viÃªn tiá»m nÄƒng 
https://forms.gle/UFZMWBfPqtjYnKtQA","CÃ¡ch Ä‘Ã¢y khÃ´ng lÃ¢u, Google Brain Ä‘Ã£ public mÃ£ nguá»“n vÃ  papers chi tiáº¿t vá» EfficientNetV2 - má»™t phiÃªn báº£n ""hoÃ n thiá»‡n vÃ  tá»‘i Æ°u"" hÆ¡n cá»§a EfficientNet, mÃ´ hÃ¬nh CNN Ä‘ang thá»‘ng trá»‹ trong cÃ¡c báº£ng xáº¿p háº¡ng SOTA á»Ÿ cÃ¡c háº¡ng má»¥c vÃ  challenge khÃ¡c nhau vá» computer vision trong 2 nÄƒm gáº§n Ä‘Ã¢y. Má»™t sá»‘ Ä‘iá»ƒm Ä‘Ã¡ng chÃº Ã½ cá»§a EfficientNet V2 so vá»›i V1: 1 cáº¥u trÃºc layer má»›i so vá»›i V1: Fused-MBConv. Sá»­ dá»¥ng NAS (1 máº£ng mÃ  anh Quá»‘c LÃª Ä‘Ã£ cÃ³ ráº¥t nhiá»u publications) vÃ  scaling Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™ vÃ  hiá»‡u quáº£ cá»§a viá»‡c training. Sá»­ dá»¥ng adaptively adjusts regularization (káº¿t há»£p Dropout, RandAugment vÃ  Mixup) vá»›i cÃ¡c network vÃ  input size khÃ¡c nhau. So sÃ¡nh vá»›i EfficientNetB5, V2s nhanh hÆ¡n 12 %, Ã­t params hÆ¡n 17% vÃ  cÃ³ sá»‘ lÆ°á»£ng FLOP tÃ­nh toÃ¡n Ã­t hÆ¡n 12%. Äá»‘i vá»›i cÃ¡c máº¡ng lá»›n hÆ¡n, tá»‘c Ä‘á»™ tÃ­nh toÃ¡n vÃ  sá»‘ lÆ°á»£ng params cÃ ng thá»ƒ hiá»‡n rÃµ sá»± tá»‘i Æ°u. Kiáº¿n thá»©c EfficientNetV2-L bá» xa SOTA hiá»‡n táº¡i (NFNet-F4) cho táº­p ImageNet 21k táº­n 0.9% (86.8 vs 85.9), vá»›i sá»‘ lÆ°á»£ng params chá»‰ báº±ng 1/3 vÃ  sá»‘ lÆ°á»£ng FLOP tháº­m chÃ­ khÃ´ng báº±ng 1/4! Äá»ƒ tÃ¬m hiá»ƒu ká»¹ hÆ¡n vá» EfficientNet, cÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu chi tiáº¿t á»Ÿ cÃ¡c bÃ i viáº¿t/video sao: Official paper: https://arxiv.org/pdf/2104.00298.pdf Video giáº£i thÃ­ch chi tiáº¿t vá» paper: https://www.youtube.com/watch?v=CTsSrOKSPNo Source code cá»§a nhÃ³m tÃ¡c giáº£ papers: https://github.com/google/automl/efficientnetv2 Source code Pytorch Ä‘Ã£ tÃ­ch há»£p EfficentNetV2: https://github.com/rwightman/pytorch-image-models P/s: Hiá»‡n táº¡i Trung tÃ¢m nghiÃªn cá»©u vÃ  á»©ng dá»¥ng AI - QAI (FPT Software Quy NhÆ¡n) giá»›i thiá»‡u chÆ°Æ¡ng trÃ¬nh há»c bá»•ng Machine Learning vÃ  Data Science dÃ nh cho 200 há»c viÃªn vá»›i cam káº¿t cÃ´ng viá»‡c Ä‘áº§u ra vá»›i má»©c lÆ°Æ¡ng vÃ  Ä‘Ã£i ngá»™ háº¥p dáº«n nháº¥t thá»‹ trÆ°á»ng, ngay táº¡i FPT Software Quy NhÆ¡n. ÄÄƒng kÃ½ ngay Ä‘á»ƒ trá»Ÿ thÃ nh nhá»¯ng á»©ng viÃªn tiá»m nÄƒng https://forms.gle/UFZMWBfPqtjYnKtQA",,,,,
Huggingface má»›i giá»›i thiá»‡u package accelerate giÃºp viá»‡c viáº¿t training loop sá»­ dá»¥ng nhiá»u GPUs vÃ  TPUs vá»›i framework Pytorch trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y https://t.co/12l2JYZL0w. ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº»,Huggingface má»›i giá»›i thiá»‡u package accelerate giÃºp viá»‡c viáº¿t training loop sá»­ dá»¥ng nhiá»u GPUs vÃ  TPUs vá»›i framework Pytorch trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y https://t.co/12l2JYZL0w. ChÃºc cÃ¡c báº¡n cuá»‘i tuáº§n vui váº»,,,,,
"LIGHTLY IS A COMPUTER VISION FRAMEWORK FOR SELF-SUPERVISED LEARNING.
Lightly offers features like:
modular framework
support for multi-gpu training using PyTorch Lightning
easy to use and written in a PyTorch like style
supports custom backbone models for self-supervised pre-training
Link github: https://github.com/lightly-ai/lightly",LIGHTLY IS A COMPUTER VISION FRAMEWORK FOR SELF-SUPERVISED LEARNING. Lightly offers features like: modular framework support for multi-gpu training using PyTorch Lightning easy to use and written in a PyTorch like style supports custom backbone models for self-supervised pre-training Link github: https://github.com/lightly-ai/lightly,,,,,
"Xin phÃ©p Admin duyá»‡t giÃºp
#xulyanh ná»n táº£ng tiáº¿p cáº­n Computer Vision",Xin phÃ©p Admin duyá»‡t giÃºp ná»n táº£ng tiáº¿p cáº­n Computer Vision,#xulyanh,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i xÃ­u vá»›i. Trong mÃ´ hÃ¬nh colaborative filter hÃ´m nay mÃ¬nh xem lÃ½ thuyáº¿t Ä‘á»ƒ lÃ m thÃ¬ tháº¥y pháº§n nÃ y ta sáº½ chia movielen ra lÃ m 2 pháº§n training vÃ  testing, náº¿u mÃ¬nh lÃ m nhÆ° váº­y thÃ¬ khi Ã¡p dá»¥ng vá»›i bÃ i toÃ¡n thá»±c táº¿ nhÆ° lÃ  gá»£i Ã½ sáº£n pháº©m cho má»™t ngÆ°á»i dÃ¹ng nÃ o Ä‘Ã³ thÃ¬ mÃ¬nh pháº£i training nhÆ° tháº¿ nÃ o váº­y má»i ngÆ°á»i, cÃ³ pháº£i lÃ  mÃ¬nh sáº½ training toÃ n bá»™ Database thÃ´ng tin ngÆ°á»i dÃ¹ng, lÃºc recommend mÃ¬nh sáº½ láº¥y dá»¯ liá»‡u cá»§a ngÆ°á»i dÃ¹ng Ä‘Ã³ vÃ  tÃ­nh rá»“i xuáº¥t káº¿t quáº£ pháº£i khÃ´ng mn?","Má»i ngÆ°á»i cho mÃ¬nh há»i xÃ­u vá»›i. Trong mÃ´ hÃ¬nh colaborative filter hÃ´m nay mÃ¬nh xem lÃ½ thuyáº¿t Ä‘á»ƒ lÃ m thÃ¬ tháº¥y pháº§n nÃ y ta sáº½ chia movielen ra lÃ m 2 pháº§n training vÃ  testing, náº¿u mÃ¬nh lÃ m nhÆ° váº­y thÃ¬ khi Ã¡p dá»¥ng vá»›i bÃ i toÃ¡n thá»±c táº¿ nhÆ° lÃ  gá»£i Ã½ sáº£n pháº©m cho má»™t ngÆ°á»i dÃ¹ng nÃ o Ä‘Ã³ thÃ¬ mÃ¬nh pháº£i training nhÆ° tháº¿ nÃ o váº­y má»i ngÆ°á»i, cÃ³ pháº£i lÃ  mÃ¬nh sáº½ training toÃ n bá»™ Database thÃ´ng tin ngÆ°á»i dÃ¹ng, lÃºc recommend mÃ¬nh sáº½ láº¥y dá»¯ liá»‡u cá»§a ngÆ°á»i dÃ¹ng Ä‘Ã³ vÃ  tÃ­nh rá»“i xuáº¥t káº¿t quáº£ pháº£i khÃ´ng mn?",,,,,
"Nhá» cÃ¡c bÃ¡c báº¯t máº¡ch cho em vá»›i:
Em Ä‘ang lÃ m theo 1 tut Facenet cá»§a anh Pháº¡m ÄÃ¬nh KhÃ¡nh. Äáº¿n Ä‘oáº¡n loadmodel vÃ o hÃ m thÃ¬ bá»‹ lá»—i "" Unsupported Lua Type"" nhÆ° nÃ y.
Kiáº¿n thá»©c vá» framework cá»§a em cÃ²n háº¡n cháº¿ nÃªn khÃ´ng hiá»ƒu lá»—i nÃ y lÃ  gÃ¬. Nhá» cÃ¡c bÃ¡c tÆ° váº¥n cho em lÃ m sao Ä‘á»ƒ giáº£i quyáº¿t cÃ¡i nÃ y vá»›i áº¡.","Nhá» cÃ¡c bÃ¡c báº¯t máº¡ch cho em vá»›i: Em Ä‘ang lÃ m theo 1 tut Facenet cá»§a anh Pháº¡m ÄÃ¬nh KhÃ¡nh. Äáº¿n Ä‘oáº¡n loadmodel vÃ o hÃ m thÃ¬ bá»‹ lá»—i "" Unsupported Lua Type"" nhÆ° nÃ y. Kiáº¿n thá»©c vá» framework cá»§a em cÃ²n háº¡n cháº¿ nÃªn khÃ´ng hiá»ƒu lá»—i nÃ y lÃ  gÃ¬. Nhá» cÃ¡c bÃ¡c tÆ° váº¥n cho em lÃ m sao Ä‘á»ƒ giáº£i quyáº¿t cÃ¡i nÃ y vá»›i áº¡.",,,,,
DÃ nh cho cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n xin viá»‡c trong ngÃ nh Data Science vÃ  Machine Learning. ÄÃ¢y lÃ  trang web tá»•ng há»£p cÃ¢u há»i phá»•ng váº¥n (chá»§ yáº¿u táº¡i Má»¹). Báº¡n cÃ³ thá»ƒ há»c khoÃ¡ Machine Learning Design táº¡i dÃ¢y.,DÃ nh cho cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n xin viá»‡c trong ngÃ nh Data Science vÃ  Machine Learning. ÄÃ¢y lÃ  trang web tá»•ng há»£p cÃ¢u há»i phá»•ng váº¥n (chá»§ yáº¿u táº¡i Má»¹). Báº¡n cÃ³ thá»ƒ há»c khoÃ¡ Machine Learning Design táº¡i dÃ¢y.,,,,,
"Hi má»i ngÆ°á»i, 

Cho e há»i xÃ­u lÃ  vá»›i dá»¯ liá»‡u lÃ  AUDIO, thÃ¬ cÃ³ nhá»¯ng bÃ i toÃ¡n gÃ¬ trong machine learning vá»›i áº¡ + hÆ°á»›ng giáº£i quáº¿t áº¡ . E thÃ¬ chá»‰ tÃ¬m Ä‘Æ°á»£c 2 bÃ i toÃ¡n cho dá»¯ liÃªu  audio lÃ  :

BÃ i toÃ¡n classification audio --> cÃ¡i nÃ y dÃ¹ng extraction features, rá»“i dÃ¹ng má»™t model classification Ä‘á»ƒ phÃ¢n loáº¡i thui áº¡
BÃ i toÃ¡n speech to text vÃ  text to speech ---> DÃ¹ng Fourier Transform Ä‘á»ƒ tÃ­nh toÃ¡n features MFFC (Mel frequency Cepstrum)  rá»“i Ä‘Æ°a features nÃ y vÃ o má»™t model.
  ","Hi má»i ngÆ°á»i, Cho e há»i xÃ­u lÃ  vá»›i dá»¯ liá»‡u lÃ  AUDIO, thÃ¬ cÃ³ nhá»¯ng bÃ i toÃ¡n gÃ¬ trong machine learning vá»›i áº¡ + hÆ°á»›ng giáº£i quáº¿t áº¡ . E thÃ¬ chá»‰ tÃ¬m Ä‘Æ°á»£c 2 bÃ i toÃ¡n cho dá»¯ liÃªu audio lÃ  : BÃ i toÃ¡n classification audio --> cÃ¡i nÃ y dÃ¹ng extraction features, rá»“i dÃ¹ng má»™t model classification Ä‘á»ƒ phÃ¢n loáº¡i thui áº¡ BÃ i toÃ¡n speech to text vÃ  text to speech ---> DÃ¹ng Fourier Transform Ä‘á»ƒ tÃ­nh toÃ¡n features MFFC (Mel frequency Cepstrum) rá»“i Ä‘Æ°a features nÃ y vÃ o má»™t model.",,,,,
"#dataset_food
Hi group, hiá»‡n giá» mÃ¬nh Ä‘ang tÃ¬m 1 bá»™ dataset liÃªn quan Ä‘áº¿n thá»±c pháº©m gá»“m cÃ¡c thÃ´ng tin :
TÃªn thá»±c pháº©m + thÃ nh pháº§n chÃ­nh sáº£n pháº©m + thÃ nh pháº§n dinh dÆ°á»¡ng sáº£n pháº©m (ngoÃ i tÃªn sáº£n pháº©m,cÃ³ thá»ƒ chá»‰ cáº§n thÃªm 1 trong 2 yáº¿u tá»‘ cÃ²n láº¡i)
Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ tá»«u cá»™ng Ä‘á»“ng. Thanks","Hi group, hiá»‡n giá» mÃ¬nh Ä‘ang tÃ¬m 1 bá»™ dataset liÃªn quan Ä‘áº¿n thá»±c pháº©m gá»“m cÃ¡c thÃ´ng tin : TÃªn thá»±c pháº©m + thÃ nh pháº§n chÃ­nh sáº£n pháº©m + thÃ nh pháº§n dinh dÆ°á»¡ng sáº£n pháº©m (ngoÃ i tÃªn sáº£n pháº©m,cÃ³ thá»ƒ chá»‰ cáº§n thÃªm 1 trong 2 yáº¿u tá»‘ cÃ²n láº¡i) Ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± giÃºp Ä‘á»¡ tá»«u cá»™ng Ä‘á»“ng. Thanks",#dataset_food,,,,
"Cho e há»i chÃºt áº¡
Vá»›i MFCC dáº¡ng vec tÆ¡ 2 chiá»u (n há»‡ sá»‘ x sá»‘ frame) thÃ¬ sá»­ dá»¥ng KNN nhÆ° tháº¿ nÃ o Ä‘á»ƒ phÃ¢n loáº¡i áº¡.E cÃ¡m Æ¡n mn",Cho e há»i chÃºt áº¡ Vá»›i MFCC dáº¡ng vec tÆ¡ 2 chiá»u (n há»‡ sá»‘ x sá»‘ frame) thÃ¬ sá»­ dá»¥ng KNN nhÆ° tháº¿ nÃ o Ä‘á»ƒ phÃ¢n loáº¡i áº¡.E cÃ¡m Æ¡n mn,,,,,
"NhÃ¢n dá»‹p cuá»‘n sÃ¡ch Deep Learning cá»§a Ian Goodfellow, Yoshua Bengio vÃ  Aaron Courville Ä‘Æ°á»£c dá»‹ch ra tiáº¿ng viá»‡t.
CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm loáº¡t bÃ i cá»§a hadrienj. NÃ³ á»©ng vá»›i chÆ°Æ¡ng 2 cá»§a cuá»‘n sÃ¡ch vÃ  giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m thÃ´ng qua coding trÃªn python vá»›i numpy.
â€œEverything became much clearer when I started writing code.â€ NÃªn theo mÃ¬nh vá»«a Ä‘á»c vá»«a code sáº½ dá»… hiá»ƒu hÆ¡n. :D","NhÃ¢n dá»‹p cuá»‘n sÃ¡ch Deep Learning cá»§a Ian Goodfellow, Yoshua Bengio vÃ  Aaron Courville Ä‘Æ°á»£c dá»‹ch ra tiáº¿ng viá»‡t. CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm loáº¡t bÃ i cá»§a hadrienj. NÃ³ á»©ng vá»›i chÆ°Æ¡ng 2 cá»§a cuá»‘n sÃ¡ch vÃ  giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m thÃ´ng qua coding trÃªn python vá»›i numpy. â€œEverything became much clearer when I started writing code.â€ NÃªn theo mÃ¬nh vá»«a Ä‘á»c vá»«a code sáº½ dá»… hiá»ƒu hÆ¡n. :D",,,,,
"[VIDEO: HÆ¯á»šNG DáºªN THÃ€NH THáº O NUMPY Tá»ª A Äáº¾N Z]
Xin chÃ o cáº£ nhÃ , vá»›i mong muá»‘n giÃºp cÃ¡c báº¡n cÃ³ má»™t ná»n táº£ng vá»¯ng cháº¯c trong quÃ¡ trÃ¬nh há»c vá» Machine Learning vÃ  Data Science, nhÃ³m mÃ¬nh cÃ³ lÃ m video ""HÆ°á»›ng Dáº«n ThÃ nh Tháº¡o NumPy tá»« A Ä‘áº¿n Z"".
NumPy (Numeric Python) lÃ  má»™t thÆ° viá»‡n toÃ¡n há»c máº¡nh máº½ cá»§a Python, cho phÃ©p lÃ m viá»‡c hiá»‡u quáº£ trÃªn cÃ¡c Cáº¥u TrÃºc Dá»¯ Liá»‡u thÆ°á»ng dÃ¹ng trong Machine Learning nhÆ°: Vector, Ma tráº­n vÃ  Máº£ng, Ä‘áº·c biá»‡t vá»›i nhá»¯ng máº£ng Ä‘a chiá»u (tensors) vá»›i tá»‘c Ä‘á»™ xá»­ lÃ½ nhanh hÆ¡n nhiá»u láº§n so vá»›i â€œcore Pythonâ€ Ä‘Æ¡n thuáº§n.
Chá»‰ 1ï¸âƒ£ video Duy Nháº¥t, cÃ¡c báº¡n cÃ³ thá»ƒ hiá»ƒu vÃ  náº¯m rÃµ Ä‘Æ°á»£c vá» máº£ng NumPy 1 chiá»u vÃ  Ä‘a chiá»u cÅ©ng nhÆ° cÃ¡ch sá»­ dá»¥ng vÃ  tra cá»©u cÃ¡c hÃ m sáºµn cÃ³ (built-in) thÃ´ng dá»¥ng trong NumPy nhÆ°: Random, Sort, Statistics vÃ  Linear Algebra.
Cáº£m Æ¡n má»i ngÆ°á»i vÃ  Admin Ä‘Ã£ duyá»‡t bÃ i !
Link: https://www.youtube.com/watch?v=1eSmR2EJjYM","[VIDEO: HÆ¯á»šNG DáºªN THÃ€NH THáº O NUMPY Tá»ª A Äáº¾N Z] Xin chÃ o cáº£ nhÃ , vá»›i mong muá»‘n giÃºp cÃ¡c báº¡n cÃ³ má»™t ná»n táº£ng vá»¯ng cháº¯c trong quÃ¡ trÃ¬nh há»c vá» Machine Learning vÃ  Data Science, nhÃ³m mÃ¬nh cÃ³ lÃ m video ""HÆ°á»›ng Dáº«n ThÃ nh Tháº¡o NumPy tá»« A Ä‘áº¿n Z"". NumPy (Numeric Python) lÃ  má»™t thÆ° viá»‡n toÃ¡n há»c máº¡nh máº½ cá»§a Python, cho phÃ©p lÃ m viá»‡c hiá»‡u quáº£ trÃªn cÃ¡c Cáº¥u TrÃºc Dá»¯ Liá»‡u thÆ°á»ng dÃ¹ng trong Machine Learning nhÆ°: Vector, Ma tráº­n vÃ  Máº£ng, Ä‘áº·c biá»‡t vá»›i nhá»¯ng máº£ng Ä‘a chiá»u (tensors) vá»›i tá»‘c Ä‘á»™ xá»­ lÃ½ nhanh hÆ¡n nhiá»u láº§n so vá»›i â€œcore Pythonâ€ Ä‘Æ¡n thuáº§n. Chá»‰ 1âƒ£ video Duy Nháº¥t, cÃ¡c báº¡n cÃ³ thá»ƒ hiá»ƒu vÃ  náº¯m rÃµ Ä‘Æ°á»£c vá» máº£ng NumPy 1 chiá»u vÃ  Ä‘a chiá»u cÅ©ng nhÆ° cÃ¡ch sá»­ dá»¥ng vÃ  tra cá»©u cÃ¡c hÃ m sáºµn cÃ³ (built-in) thÃ´ng dá»¥ng trong NumPy nhÆ°: Random, Sort, Statistics vÃ  Linear Algebra. Cáº£m Æ¡n má»i ngÆ°á»i vÃ  Admin Ä‘Ã£ duyá»‡t bÃ i ! Link: https://www.youtube.com/watch?v=1eSmR2EJjYM",,,,,
"ChÃ o a/c. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em biáº¿t má»™t vÃ i cá»™ng Ä‘á»“ng trao Ä‘á»•i vá» há»c thuáº­t trong lÄ©nh vá»±c ML á»Ÿ cÃ¡c nÆ°á»›c khÃ¡c mÃ  anh/chá»‹ Ä‘ang follow Ä‘Æ°á»£c khÃ´ng áº¡. Em ráº¥t vui vÃ¬ nÆ°á»›c mÃ¬nh cÃ³ group nÃ y phÃ¡t triá»ƒn ráº¥t nhanh vÃ  trá»Ÿ thÃ nh nÆ¡i chia sáº», dáº«n dáº¯t cho nhá»¯ng ngÆ°á»i má»›i nhÆ° em. NÃªn em cÃ³ tháº¯c máº¯c lÃ  cÃ¡c nÆ°á»›c khÃ¡c Ä‘i trÆ°á»›c vá» máº£ng nÃ y cháº¯c háº³n lÃ  cÅ©ng cÃ³ cá»™ng Ä‘á»“ng cÅ©ng máº¡nh cháº³ng kÃ©m. MÃ  e tÃ¬m mÃ£i cháº³ng tháº¥y nÃªn mong nháº­n Ä‘Æ°á»£c giáº£i Ä‘Ã¡p cá»§a má»i ngÆ°á»i áº¡ :D Cáº£m Æ¡n ráº¥t nhiá»u áº¡!","ChÃ o a/c. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em biáº¿t má»™t vÃ i cá»™ng Ä‘á»“ng trao Ä‘á»•i vá» há»c thuáº­t trong lÄ©nh vá»±c ML á»Ÿ cÃ¡c nÆ°á»›c khÃ¡c mÃ  anh/chá»‹ Ä‘ang follow Ä‘Æ°á»£c khÃ´ng áº¡. Em ráº¥t vui vÃ¬ nÆ°á»›c mÃ¬nh cÃ³ group nÃ y phÃ¡t triá»ƒn ráº¥t nhanh vÃ  trá»Ÿ thÃ nh nÆ¡i chia sáº», dáº«n dáº¯t cho nhá»¯ng ngÆ°á»i má»›i nhÆ° em. NÃªn em cÃ³ tháº¯c máº¯c lÃ  cÃ¡c nÆ°á»›c khÃ¡c Ä‘i trÆ°á»›c vá» máº£ng nÃ y cháº¯c háº³n lÃ  cÅ©ng cÃ³ cá»™ng Ä‘á»“ng cÅ©ng máº¡nh cháº³ng kÃ©m. MÃ  e tÃ¬m mÃ£i cháº³ng tháº¥y nÃªn mong nháº­n Ä‘Æ°á»£c giáº£i Ä‘Ã¡p cá»§a má»i ngÆ°á»i áº¡ :D Cáº£m Æ¡n ráº¥t nhiá»u áº¡!",,,,,
"NhÃ³m mÃ¬nh vá»«a hoÃ n thÃ nh má»™t nghiÃªn cá»©u trong paper COVID-19 named entity recognition for Vietnamese (https://arxiv.org/abs/2104.03879) vÃ  release bá»™ dá»¯ liá»‡u PhoNER cho Tiáº¿ng Viá»‡t trong domain COVID-19.
Báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ download corpus tá»«: https://github.com/VinAIResearch/PhoNER_COVID19",NhÃ³m mÃ¬nh vá»«a hoÃ n thÃ nh má»™t nghiÃªn cá»©u trong paper COVID-19 named entity recognition for Vietnamese (https://arxiv.org/abs/2104.03879) vÃ  release bá»™ dá»¯ liá»‡u PhoNER cho Tiáº¿ng Viá»‡t trong domain COVID-19. Báº¡n nÃ o quan tÃ¢m cÃ³ thá»ƒ download corpus tá»«: https://github.com/VinAIResearch/PhoNER_COVID19,,,,,
"[AI News]
Thay tháº¿ background lÃ  má»™t nhiá»‡m vá»¥ ná»•i báº­t trong lÄ©nh vá»±c video, táº¡o ra cÃ¡c hiá»‡u á»©ng Ä‘áº·c biá»‡t vÃ  phÃ¡t trá»±c tiáº¿p. Trong thá»i kÃ¬ dá»‹ch covid, viá»‡c há»c online hay lÃ m viá»‡c tá»« xa trá»Ÿ nÃªn phá»• biáº¿n hÆ¡n bao giá» háº¿t. CÃ³ thá»ƒ dá»… dÃ ng tháº¥y trong cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ há»c trá»±c tuyáº¿n hay lÃ m viá»‡c tá»« xa nhÆ° Zoom vÃ  Google Meets, viá»‡c thay tháº¿ background Ä‘Æ°á»£c sá»­ dá»¥ng khi nhiá»u há»™i nghá»‹, cuá»™c há»p yÃªu cáº§u background. NgoÃ i ra, viá»‡c thay tháº¿ background cÃ³ thá»ƒ dá»­ dá»¥ng Ä‘á»ƒ giáº£i trÃ­ táº¡o ra cÃ¡c video Ä‘áº¹p hÆ¡n.
BackgroundMattingV2 lÃ  má»™t kÄ© thuáº­t thay tháº¿ background cÃ³ Ä‘á»™ phÃ¢n giáº£i cao theo thá»i gian thá»±c Ä‘áº§u tiÃªn mÃ  cÃ³ káº¿t quáº£ hiá»‡n Ä‘Ã i á»Ÿ cháº¿ Ä‘á»™ 4K lÃ  30fps vÃ  cháº¿ Ä‘á»™ HD lÃ  60fps.","[AI News] Thay tháº¿ background lÃ  má»™t nhiá»‡m vá»¥ ná»•i báº­t trong lÄ©nh vá»±c video, táº¡o ra cÃ¡c hiá»‡u á»©ng Ä‘áº·c biá»‡t vÃ  phÃ¡t trá»±c tiáº¿p. Trong thá»i kÃ¬ dá»‹ch covid, viá»‡c há»c online hay lÃ m viá»‡c tá»« xa trá»Ÿ nÃªn phá»• biáº¿n hÆ¡n bao giá» háº¿t. CÃ³ thá»ƒ dá»… dÃ ng tháº¥y trong cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ há»c trá»±c tuyáº¿n hay lÃ m viá»‡c tá»« xa nhÆ° Zoom vÃ  Google Meets, viá»‡c thay tháº¿ background Ä‘Æ°á»£c sá»­ dá»¥ng khi nhiá»u há»™i nghá»‹, cuá»™c há»p yÃªu cáº§u background. NgoÃ i ra, viá»‡c thay tháº¿ background cÃ³ thá»ƒ dá»­ dá»¥ng Ä‘á»ƒ giáº£i trÃ­ táº¡o ra cÃ¡c video Ä‘áº¹p hÆ¡n. BackgroundMattingV2 lÃ  má»™t kÄ© thuáº­t thay tháº¿ background cÃ³ Ä‘á»™ phÃ¢n giáº£i cao theo thá»i gian thá»±c Ä‘áº§u tiÃªn mÃ  cÃ³ káº¿t quáº£ hiá»‡n Ä‘Ã i á»Ÿ cháº¿ Ä‘á»™ 4K lÃ  30fps vÃ  cháº¿ Ä‘á»™ HD lÃ  60fps.",,,,,
"[AI Share]
NgÆ°á»i ta thÆ°á»ng nÃ³i â€œ Há»c pháº£i Ä‘i Ä‘Ã´i vá»›i hÃ nhâ€, hÃ´m nay AI4E sáº½ share má»™t nguá»“n tÃ i liá»‡u hay Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ vá»«a há»c vá»«a thá»±c hÃ nh code^^.
Repo nÃ y tá»•ng há»£p hÆ¡n 500 project vá» AI, Machine Learning, Deep Learning, Computer Vision, NLP. Äáº·c biá»‡t, cÃ¡c project nÃ y cÃ³ code Ä‘i kÃ¨m ^^.
HÃ£y chá»n cÃ¡c project vá» topic mÃ  mÃ¬nh quan tÃ¢m Ä‘á»ƒ há»c há»i thÃªm nhÃ©^^","[AI Share] NgÆ°á»i ta thÆ°á»ng nÃ³i â€œ Há»c pháº£i Ä‘i Ä‘Ã´i vá»›i hÃ nhâ€, hÃ´m nay AI4E sáº½ share má»™t nguá»“n tÃ i liá»‡u hay Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ vá»«a há»c vá»«a thá»±c hÃ nh code^^. Repo nÃ y tá»•ng há»£p hÆ¡n 500 project vá» AI, Machine Learning, Deep Learning, Computer Vision, NLP. Äáº·c biá»‡t, cÃ¡c project nÃ y cÃ³ code Ä‘i kÃ¨m ^^. HÃ£y chá»n cÃ¡c project vá» topic mÃ  mÃ¬nh quan tÃ¢m Ä‘á»ƒ há»c há»i thÃªm nhÃ©^^",,,,,
"ChÃ o má»i ngÆ°á»i,
HÃ´m ná» cÃ³ bÃ i há»i vá» ensemble khÃ¡ hot vÃ  cÃ³ nhiá»u Ã½ kiáº¿n tranh luáº­n trÃªn 2 topic chÃ­nh:
- CÃ³ nÃªn gá»™p cÃ¡c model cÃ³ variance lá»›n láº¡i vá»›i nhau hay khÃ´ng
- Quy luáº­t cá»§a sá»‘ lá»›n cÃ³ áº£nh hÆ°á»Ÿng tháº¿ nÃ o Ä‘áº¿n káº¿t quáº£ cá»§a ensemble
TrÆ°á»›c khi tráº£ lá»i thÃ¬ mÃ¬nh cÃ³ trÃ¬nh bÃ y test cá»§a mÃ¬nh trÃªn cÃ¡c táº­p nhÆ° sau.
- Cho má»™t model vá»›i accuracy lÃ  x = 0.51 (gá»i lÃ  weak model) cháº¡y 1000 láº§n, tÃ­nh accuracy trung bÃ¬nh (TEST 1)
- Cho má»™t táº­p cÃ¡c weak model á»Ÿ trÃªn vá»›i cÃ¡c size khÃ¡c nhau (10, 50, 100, 500, 1000), tÃ­nh major vote vÃ  tÃ­nh accuracy trung bÃ¬nh cá»§a 1000 run. Test nÃ y Ä‘á»ƒ xem sá»‘ lÆ°á»£ng model áº£nh hÆ°á»Ÿng tháº¿ nÃ o Ä‘áº¿n accuracy cá»§a model (TEST 2)
- Cho má»™t táº­p cÃ¡c model vá»›i size lÃ  10, cháº¡y vá»›i cÃ¡c model cÃ³ acc vari khÃ¡c nhau xoay quanh ngÆ°á»¡ng kÃ¬ vá»ng 0.75 vá»›i cÃ¡c vari (0, 0.05, 0.1, 0.2), i.e, 10 models vá»›i vari tá»« -0.2 Ä‘áº¿n 0.2; Ä‘á»ƒ xem káº¿t quáº£ ra sao. (TEST 3)
Sau Ä‘Ã¢y lÃ  káº¿t quáº£:
TEST 1
Accuracy of one model: 0.524
TEST 2
Accuracy of 10 models with 0.00 vari: 0.633
Accuracy of 50 models with 0.00 vari: 0.609
Accuracy of 100 models with 0.00 vari: 0.623
Accuracy of 500 models with 0.00 vari: 0.683
Accuracy of 1000 models with 0.00 vari: 0.769
TEST 3
Accuracy of one model: 0.749
Accuracy of 10 models with +-0.00 vari: 0.982
Accuracy of 10 models with +-0.05 vari: 0.972
Accuracy of 10 models with +-0.10 vari: 0.985
Accuracy of 10 models with +-0.20 vari: 0.998
NhÆ° váº­y rÃµ rÃ ng lÃ  stacking cÃ ng nhiá»u model Ä‘á»™c láº­p vá»›i nhau láº¡i thÃ¬ káº¿t quáº£ cÃ ng tá»‘t, vÃ  variance lá»›n cÅ©ng khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ nhiá»u láº¯m.
Code á»Ÿ Ä‘Ã¢y: https://gitlab.com/andy143/ensemble-test/-/tree/master
Giáº£i thÃ­ch cá»§a mÃ¬nh náº±m á»Ÿ comment do viáº¿t ná»¯a thÃ¬ thÃ nh wall-of-text","ChÃ o má»i ngÆ°á»i, HÃ´m ná» cÃ³ bÃ i há»i vá» ensemble khÃ¡ hot vÃ  cÃ³ nhiá»u Ã½ kiáº¿n tranh luáº­n trÃªn 2 topic chÃ­nh: - CÃ³ nÃªn gá»™p cÃ¡c model cÃ³ variance lá»›n láº¡i vá»›i nhau hay khÃ´ng - Quy luáº­t cá»§a sá»‘ lá»›n cÃ³ áº£nh hÆ°á»Ÿng tháº¿ nÃ o Ä‘áº¿n káº¿t quáº£ cá»§a ensemble TrÆ°á»›c khi tráº£ lá»i thÃ¬ mÃ¬nh cÃ³ trÃ¬nh bÃ y test cá»§a mÃ¬nh trÃªn cÃ¡c táº­p nhÆ° sau. - Cho má»™t model vá»›i accuracy lÃ  x = 0.51 (gá»i lÃ  weak model) cháº¡y 1000 láº§n, tÃ­nh accuracy trung bÃ¬nh (TEST 1) - Cho má»™t táº­p cÃ¡c weak model á»Ÿ trÃªn vá»›i cÃ¡c size khÃ¡c nhau (10, 50, 100, 500, 1000), tÃ­nh major vote vÃ  tÃ­nh accuracy trung bÃ¬nh cá»§a 1000 run. Test nÃ y Ä‘á»ƒ xem sá»‘ lÆ°á»£ng model áº£nh hÆ°á»Ÿng tháº¿ nÃ o Ä‘áº¿n accuracy cá»§a model (TEST 2) - Cho má»™t táº­p cÃ¡c model vá»›i size lÃ  10, cháº¡y vá»›i cÃ¡c model cÃ³ acc vari khÃ¡c nhau xoay quanh ngÆ°á»¡ng kÃ¬ vá»ng 0.75 vá»›i cÃ¡c vari (0, 0.05, 0.1, 0.2), i.e, 10 models vá»›i vari tá»« -0.2 Ä‘áº¿n 0.2; Ä‘á»ƒ xem káº¿t quáº£ ra sao. (TEST 3) Sau Ä‘Ã¢y lÃ  káº¿t quáº£: TEST 1 Accuracy of one model: 0.524 TEST 2 Accuracy of 10 models with 0.00 vari: 0.633 Accuracy of 50 models with 0.00 vari: 0.609 Accuracy of 100 models with 0.00 vari: 0.623 Accuracy of 500 models with 0.00 vari: 0.683 Accuracy of 1000 models with 0.00 vari: 0.769 TEST 3 Accuracy of one model: 0.749 Accuracy of 10 models with +-0.00 vari: 0.982 Accuracy of 10 models with +-0.05 vari: 0.972 Accuracy of 10 models with +-0.10 vari: 0.985 Accuracy of 10 models with +-0.20 vari: 0.998 NhÆ° váº­y rÃµ rÃ ng lÃ  stacking cÃ ng nhiá»u model Ä‘á»™c láº­p vá»›i nhau láº¡i thÃ¬ káº¿t quáº£ cÃ ng tá»‘t, vÃ  variance lá»›n cÅ©ng khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ nhiá»u láº¯m. Code á»Ÿ Ä‘Ã¢y: https://gitlab.com/andy143/ensemble-test/-/tree/master Giáº£i thÃ­ch cá»§a mÃ¬nh náº±m á»Ÿ comment do viáº¿t ná»¯a thÃ¬ thÃ nh wall-of-text",,,,,
"MÃ¬nh train yolov4 , trong lÃºc Ä‘ang train thÃ¬ colab thÃ´ng bÃ¡o nhÆ° nÃ y
/bin/bash: line 1: 269 Killed ./darknet detector train obj.data cfg/yolo4/custom-4corner.cfg backup/custom-4corner_last.weights -dont_show -map &> backup/training_4_corner.log
MÃ¬nh cÃ³ search thá»­ nhÆ°ng ko tháº¥y ai gáº·p lá»—i nÃ y cáº£
CÃ³ báº¡n nÃ o gáº·p lá»—i tÆ°Æ¡ng tá»± chá»‰ mÃ¬nh Ä‘c khÃ´ng áº¡","MÃ¬nh train yolov4 , trong lÃºc Ä‘ang train thÃ¬ colab thÃ´ng bÃ¡o nhÆ° nÃ y /bin/bash: line 1: 269 Killed ./darknet detector train obj.data cfg/yolo4/custom-4corner.cfg backup/custom-4corner_last.weights -dont_show -map &> backup/training_4_corner.log MÃ¬nh cÃ³ search thá»­ nhÆ°ng ko tháº¥y ai gáº·p lá»—i nÃ y cáº£ CÃ³ báº¡n nÃ o gáº·p lá»—i tÆ°Æ¡ng tá»± chá»‰ mÃ¬nh Ä‘c khÃ´ng áº¡",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡. Má»i ngÆ°á»i cho em há»i lÃ  hiá»‡n táº¡i em Ä‘ang cáº§n má»™t bá»™ dataset giÃ¡ chá»©ng khoÃ¡n cá»§a cÃ¡c cty á»Ÿ Viá»‡t Nam thÃ¬ cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c á»Ÿ Ä‘Ã¢u , náº¿u khÃ´ng cÃ³ thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ crawl Ä‘Æ°á»£c dá»¯ liá»‡u vá» chá»©ng khoÃ¡n khÃ´ng áº¡?Em cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i áº¡. Má»i ngÆ°á»i cho em há»i lÃ  hiá»‡n táº¡i em Ä‘ang cáº§n má»™t bá»™ dataset giÃ¡ chá»©ng khoÃ¡n cá»§a cÃ¡c cty á»Ÿ Viá»‡t Nam thÃ¬ cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c á»Ÿ Ä‘Ã¢u , náº¿u khÃ´ng cÃ³ thÃ¬ cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ crawl Ä‘Æ°á»£c dá»¯ liá»‡u vá» chá»©ng khoÃ¡n khÃ´ng áº¡?Em cáº£m Æ¡n áº¡.",,,,,
"Cho mÃ¬nh há»i á»Ÿ Ä‘Ã¢y cÃ³ báº¡n nÃ o cháº¡y thá»­ yolov4 Pytorch tá»« link https://github.com/Tianxiaomo/pytorch-YOLOv4 mÃ  Ä‘áº¡t dc KQ real-time trÃªn 30fps ko áº¡? MÃ¬nh cháº¡y á»Ÿ 1 mÃ¡y Win cÃ i conda GPU 6GB vÃ  1 mÃ¡y Linux card 8GB thÃ¬ á»Ÿ mÃ¡y cháº¡y Win Ä‘áº¡t dc khoáº£ng 17fps (load video tá»« HDD) vÃ  trÃªn mÃ¡y Linux (dÃ¹ng SSD) Ä‘áº¡t dc 20fps vá»›i Ä‘iá»u kiá»‡n ko imshow hÃ¬nh báº±ng opencv, mÃ¬nh Ä‘ang xÃ©t trÃªn mÃ´i trÆ°á»ng Python dÃ¹ng Pytorch thÃ´i áº¡, ko xÃ©t Ä‘áº¿n viá»‡c cháº¡y C/C++. CÃ³ pháº£i Pytorch tá»‘i Æ°u ko tá»‘t Ä‘á»ƒ Ä‘áº¡t real-time hay ko? code mÃ¬nh dÃ¹ng cá»§a tÃ¡c giáº£, chá»‰ chá»‰nh sá»­a Ä‘á»ƒ Ä‘á»c video tá»« mÃ¡y thay vÃ¬ Ä‘á»c 1 áº£nh Ä‘Æ¡n vÃ  chÆ°a xÃ©t Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c. CÅ©ng Ä‘Ã£ cá»‘ gáº¯ng tra google vÃ  Ä‘á»c issue cá»§a nÃ³ nhÆ°ng ko tÃ¬m dc cÃ¢u tráº£ lá»i. XIn cáº£m Æ¡n","Cho mÃ¬nh há»i á»Ÿ Ä‘Ã¢y cÃ³ báº¡n nÃ o cháº¡y thá»­ yolov4 Pytorch tá»« link https://github.com/Tianxiaomo/pytorch-YOLOv4 mÃ  Ä‘áº¡t dc KQ real-time trÃªn 30fps ko áº¡? MÃ¬nh cháº¡y á»Ÿ 1 mÃ¡y Win cÃ i conda GPU 6GB vÃ  1 mÃ¡y Linux card 8GB thÃ¬ á»Ÿ mÃ¡y cháº¡y Win Ä‘áº¡t dc khoáº£ng 17fps (load video tá»« HDD) vÃ  trÃªn mÃ¡y Linux (dÃ¹ng SSD) Ä‘áº¡t dc 20fps vá»›i Ä‘iá»u kiá»‡n ko imshow hÃ¬nh báº±ng opencv, mÃ¬nh Ä‘ang xÃ©t trÃªn mÃ´i trÆ°á»ng Python dÃ¹ng Pytorch thÃ´i áº¡, ko xÃ©t Ä‘áº¿n viá»‡c cháº¡y C/C++. CÃ³ pháº£i Pytorch tá»‘i Æ°u ko tá»‘t Ä‘á»ƒ Ä‘áº¡t real-time hay ko? code mÃ¬nh dÃ¹ng cá»§a tÃ¡c giáº£, chá»‰ chá»‰nh sá»­a Ä‘á»ƒ Ä‘á»c video tá»« mÃ¡y thay vÃ¬ Ä‘á»c 1 áº£nh Ä‘Æ¡n vÃ  chÆ°a xÃ©t Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c. CÅ©ng Ä‘Ã£ cá»‘ gáº¯ng tra google vÃ  Ä‘á»c issue cá»§a nÃ³ nhÆ°ng ko tÃ¬m dc cÃ¢u tráº£ lá»i. XIn cáº£m Æ¡n",,,,,
"Em xin chÃ o má»i ngÆ°á»i áº¡. á» trong cÃ´ng thá»©c tÃ­nh conditional distribution cá»§a multivariate gaussian em tháº¥y cÃ³ cÃ´ng thá»©c nhÆ° hÃ¬nh 1, sau má»™t lÃºc tÃ¬m trÃªn máº¡ng thÃ¬ em tháº¥y cÃ³ chá»©ng minh nhÆ° hÃ¬nh. NhÆ°ng hiá»‡n táº¡i em váº«n khÃ´ng hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a Conditional Part vÃ  Marginal Part áº¡. Trong pháº§n chá»©ng minh khÃ¡c em váº«n khÃ´ng hiá»ƒu Ã½ nghÄ©a cá»¥ thá»ƒ cá»§a E2 is exactly the exponent of the distribution áº¡. Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em, em xin cáº£m Æ¡n áº¡.
Link chá»©ng minh: https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution
https://github.com/carlhenrikek/COMS30007/blob/2018/Lectures/gaussianidentities.pdf","Em xin chÃ o má»i ngÆ°á»i áº¡. á» trong cÃ´ng thá»©c tÃ­nh conditional distribution cá»§a multivariate gaussian em tháº¥y cÃ³ cÃ´ng thá»©c nhÆ° hÃ¬nh 1, sau má»™t lÃºc tÃ¬m trÃªn máº¡ng thÃ¬ em tháº¥y cÃ³ chá»©ng minh nhÆ° hÃ¬nh. NhÆ°ng hiá»‡n táº¡i em váº«n khÃ´ng hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a Conditional Part vÃ  Marginal Part áº¡. Trong pháº§n chá»©ng minh khÃ¡c em váº«n khÃ´ng hiá»ƒu Ã½ nghÄ©a cá»¥ thá»ƒ cá»§a E2 is exactly the exponent of the distribution áº¡. Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em, em xin cáº£m Æ¡n áº¡. Link chá»©ng minh: https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution https://github.com/carlhenrikek/COMS30007/blob/2018/Lectures/gaussianidentities.pdf",,"#math, #Q&A",,,
"Máº¥y khi cÃ³ cÆ¡ há»™i thá»­ sá»©c, kiáº¿m tiá»n made in VN, má»i cÃ¡c báº¡n cÃ¹ng tham gia :)","Máº¥y khi cÃ³ cÆ¡ há»™i thá»­ sá»©c, kiáº¿m tiá»n made in VN, má»i cÃ¡c báº¡n cÃ¹ng tham gia :)",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh vá»«a Ä‘i pv á»Ÿ má»™t cÃ´ng ty AI lá»›n á»Ÿ HCM. LÃºc pv, anh pv cÃ³ há»i mÃ¬nh vá» stacking vÃ  luáº­t sá»‘ lá»›n. MÃ¬nh tráº£ lá»i lÃ  giÃ¡ trá»‹ trung bÃ¬nh cá»§a kÃ¬ vá»ng (predicted value) cá»§a cÃ¡c model báº±ng giÃ¡ trá»‹ kÃ¬ vá»ng thá»±c (ground truth value), Ä‘iá»u kiá»‡n lÃ  cÃ¡c model cÃ³ Ä‘á»™ chÃ­nh xÃ¡c tÆ°Æ¡ng tá»± nhau vÃ  lá»›n hÆ¡n baseline model (khÃ´ng nÃªn stack 2 model cÃ³ Ä‘á»™ chÃ­nh xÃ¡c 99% vÃ  70% láº¡i vá»›i nhau).
Anh pv cho ráº±ng mÃ¬nh thiáº¿u Ä‘iá»u kiá»‡n variance nhá», anh dáº«n chá»©ng ráº±ng náº¿u ground truth value báº±ng 0 thÃ¬ stack 2 model cÃ³ predicted value lÃ  1 vÃ  -1 sáº½ tá»‘t hÆ¡n viá»‡c stack 2 model cÃ³ predicted value lÃ  8 vÃ  -8.
Theo mÃ¬nh thÃ¬ náº¿u Ä‘á»™ chÃ­nh xÃ¡c cá»§a 4 model khÃ´ng quÃ¡ khÃ¡c biá»‡t vÃ  cÃ³ Ä‘á»™ chÃ­nh xÃ¡c lá»›n hÆ¡n baseline model thÃ¬ váº«n cÃ³ thá»ƒ stack cáº£ 4 model láº¡i. Xin Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» váº¥n Ä‘á» nÃ y.","ChÃ o má»i ngÆ°á»i, MÃ¬nh vá»«a Ä‘i pv á»Ÿ má»™t cÃ´ng ty AI lá»›n á»Ÿ HCM. LÃºc pv, anh pv cÃ³ há»i mÃ¬nh vá» stacking vÃ  luáº­t sá»‘ lá»›n. MÃ¬nh tráº£ lá»i lÃ  giÃ¡ trá»‹ trung bÃ¬nh cá»§a kÃ¬ vá»ng (predicted value) cá»§a cÃ¡c model báº±ng giÃ¡ trá»‹ kÃ¬ vá»ng thá»±c (ground truth value), Ä‘iá»u kiá»‡n lÃ  cÃ¡c model cÃ³ Ä‘á»™ chÃ­nh xÃ¡c tÆ°Æ¡ng tá»± nhau vÃ  lá»›n hÆ¡n baseline model (khÃ´ng nÃªn stack 2 model cÃ³ Ä‘á»™ chÃ­nh xÃ¡c 99% vÃ  70% láº¡i vá»›i nhau). Anh pv cho ráº±ng mÃ¬nh thiáº¿u Ä‘iá»u kiá»‡n variance nhá», anh dáº«n chá»©ng ráº±ng náº¿u ground truth value báº±ng 0 thÃ¬ stack 2 model cÃ³ predicted value lÃ  1 vÃ  -1 sáº½ tá»‘t hÆ¡n viá»‡c stack 2 model cÃ³ predicted value lÃ  8 vÃ  -8. Theo mÃ¬nh thÃ¬ náº¿u Ä‘á»™ chÃ­nh xÃ¡c cá»§a 4 model khÃ´ng quÃ¡ khÃ¡c biá»‡t vÃ  cÃ³ Ä‘á»™ chÃ­nh xÃ¡c lá»›n hÆ¡n baseline model thÃ¬ váº«n cÃ³ thá»ƒ stack cáº£ 4 model láº¡i. Xin Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» váº¥n Ä‘á» nÃ y.",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang lÃ m Ä‘á» tÃ i vá» nháº­n diá»‡n biá»ƒn sá»‘ xe Viá»‡t Nam, cÃ³ ai cÃ³ táº­p áº£nh cá»§a xe oto ra vÃ o bÃ£i giá»¯ xe khÃ´ng áº¡. Cho mÃ¬nh xin vá»›i!
Cáº£m Æ¡n !!","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang lÃ m Ä‘á» tÃ i vá» nháº­n diá»‡n biá»ƒn sá»‘ xe Viá»‡t Nam, cÃ³ ai cÃ³ táº­p áº£nh cá»§a xe oto ra vÃ o bÃ£i giá»¯ xe khÃ´ng áº¡. Cho mÃ¬nh xin vá»›i! Cáº£m Æ¡n !!",,,,,
"We're excited to share with you all a NLU dataset for Vietnamese intent detection and slot filling: https://github.com/VinAIResearch/JointIDSF
See details in our paper: https://arxiv.org/abs/2104.02021",We're excited to share with you all a NLU dataset for Vietnamese intent detection and slot filling: https://github.com/VinAIResearch/JointIDSF See details in our paper: https://arxiv.org/abs/2104.02021,,,,,
"Hi má»i ngÆ°á»i !!!
Má»i ngÆ°á»i trong groupe cÃ³ ai cÃ³ kinh nghiá»‡m modelling vá»›i y khÃ´ng pháº£i lÃ  normally distributed chÆ°a nhá»‰?
Mon y Ã©tant continue, et il y a beaucoup de point d'accumulation (centralisation autour d'une valeur). En gros, Ã§a ressemble Ã  y = 0 (90% des cas), ou y varie et peut Ãªtre trÃ¨s extrÃªme
VÃ­ dá»¥ trong trÆ°á»ng há»£p cá»§a  lÃ  y = -1 (90%) hoáº·c y liÃªn tá»¥c, vÃ  cÃ³ nhá»¯ng giÃ¡ trá»‹ ráº¥t lá»›n
MÃ¬nh chá»‰ má»›i test thá»­ linear regression trÃªn y nÃ y, thÃ¬ káº¿t quáº£ khÃ´ng ngáº¡c nhiÃªn lÃ  ráº¥t tá»‡, R2 gáº§n nhÆ° 0 :'(
MÃ¬nh cÅ©ng Ä‘Ã£ thá»­ log-transformation, nhÆ°ng mÃ  káº¿t quáº£ cÅ©ng khÃ´ng khÃ¡ hÆ¡n
CÃ³ ai tá»«ng gáº·p trÆ°á»ng há»£p nÃ y chÆ°a nhá»‰? Hoáº·c náº¿u má»i ngÆ°á»i cÃ³ ideas gÃ¬ ko?
CÃ¡m Æ¡n cáº£ nhÃ  Ä‘Ã£ Ä‘á»c bÃ i !","Hi má»i ngÆ°á»i !!! Má»i ngÆ°á»i trong groupe cÃ³ ai cÃ³ kinh nghiá»‡m modelling vá»›i y khÃ´ng pháº£i lÃ  normally distributed chÆ°a nhá»‰? Mon y Ã©tant continue, et il y a beaucoup de point d'accumulation (centralisation autour d'une valeur). En gros, Ã§a ressemble Ã  y = 0 (90% des cas), ou y varie et peut Ãªtre trÃ¨s extrÃªme VÃ­ dá»¥ trong trÆ°á»ng há»£p cá»§a lÃ  y = -1 (90%) hoáº·c y liÃªn tá»¥c, vÃ  cÃ³ nhá»¯ng giÃ¡ trá»‹ ráº¥t lá»›n MÃ¬nh chá»‰ má»›i test thá»­ linear regression trÃªn y nÃ y, thÃ¬ káº¿t quáº£ khÃ´ng ngáº¡c nhiÃªn lÃ  ráº¥t tá»‡, R2 gáº§n nhÆ° 0 :'( MÃ¬nh cÅ©ng Ä‘Ã£ thá»­ log-transformation, nhÆ°ng mÃ  káº¿t quáº£ cÅ©ng khÃ´ng khÃ¡ hÆ¡n CÃ³ ai tá»«ng gáº·p trÆ°á»ng há»£p nÃ y chÆ°a nhá»‰? Hoáº·c náº¿u má»i ngÆ°á»i cÃ³ ideas gÃ¬ ko? CÃ¡m Æ¡n cáº£ nhÃ  Ä‘Ã£ Ä‘á»c bÃ i !",,,,,
"ChÃ o má»i ngÆ°á»i!
Hiá»‡n táº¡i em cÃ³ 1 dá»± Ã¡n nhÆ°ng mÃ  Ä‘ang bÃ­ á»Ÿ 1 sá»‘ pháº§n. Hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em khai sÃ¡ng.
Äá» tÃ i lÃ  vá» ""Password behavior"", app cá»§a tá»¥i em cÃ³ thá»ƒ táº¡o 1 password dá»±a trÃªn nhá»¯ng thÃ³i quen cá»§a ngÆ°á»i dÃ¹ng. Hiá»‡n táº¡i thÃ¬ cÃ³ 2 hÆ°á»›ng: 1 lÃ  xÃ¢y dá»±ng 1 cÃ¡i báº£ng cÃ¢u há»i rá»“i dá»±a trÃªn cÃ¢u tráº£ lá»i lÃ m 1 password má»›i, 2 lÃ  dá»±a trÃªn nhá»¯ng gÃ¬ ngÆ°á»i dÃ¹ng nháº­p (trong trÃ¬nh duyá»‡t etc,...) xong láº¥y máº¥y cÃ¡i thÃ³i quen Ä‘Ã³ táº¡o thÃ nh password (cÃ¡ch nÃ y thÃ¬ em chÆ°a hÃ¬nh dung Ä‘Æ°á»£c lÃ m tháº¿ nÃ o).
Pháº§n quan trá»ng lÃ  app pháº£i Ã¡p dá»¥ng machine learning. MÃ  theo nhÆ° em trÃ¬nh bÃ y hÆ°á»›ng 1 á»Ÿ trÃªn thÃ¬ em chá»‰ nghÄ© Ä‘Ã³ lÃ  hash cÃ¢u tráº£ lá»i rá»“i ngáº«u nhiÃªn tá»•ng há»£p láº¡i thÃ nh 1 tá»• há»£p password má»›i thÃ´i. Chá»© nÃ³ khÃ´ng cÃ³ Ã¡p dá»¥ng machinelearning hay cá»¥ thá»ƒ lÃ  training 1 cÃ¡i dataset nÃ o háº¿t.
Má»i ngÆ°á»i giÃºp em chá»‰ ra vá»›i náº¿u nhÆ° Ã¡p dá»¥ng machinelearning (sá»­ dá»¥ng dataset) cho Ä‘á» bÃ i nÃ y dÃ¹ng 2 hÆ°á»›ng trÃªn thÃ¬ sá»­ dá»¥ng nhÆ° tháº¿ nÃ o áº¡!
Xin cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i! Hiá»‡n táº¡i em cÃ³ 1 dá»± Ã¡n nhÆ°ng mÃ  Ä‘ang bÃ­ á»Ÿ 1 sá»‘ pháº§n. Hi vá»ng má»i ngÆ°á»i cÃ³ thá»ƒ giÃºp em khai sÃ¡ng. Äá» tÃ i lÃ  vá» ""Password behavior"", app cá»§a tá»¥i em cÃ³ thá»ƒ táº¡o 1 password dá»±a trÃªn nhá»¯ng thÃ³i quen cá»§a ngÆ°á»i dÃ¹ng. Hiá»‡n táº¡i thÃ¬ cÃ³ 2 hÆ°á»›ng: 1 lÃ  xÃ¢y dá»±ng 1 cÃ¡i báº£ng cÃ¢u há»i rá»“i dá»±a trÃªn cÃ¢u tráº£ lá»i lÃ m 1 password má»›i, 2 lÃ  dá»±a trÃªn nhá»¯ng gÃ¬ ngÆ°á»i dÃ¹ng nháº­p (trong trÃ¬nh duyá»‡t etc,...) xong láº¥y máº¥y cÃ¡i thÃ³i quen Ä‘Ã³ táº¡o thÃ nh password (cÃ¡ch nÃ y thÃ¬ em chÆ°a hÃ¬nh dung Ä‘Æ°á»£c lÃ m tháº¿ nÃ o). Pháº§n quan trá»ng lÃ  app pháº£i Ã¡p dá»¥ng machine learning. MÃ  theo nhÆ° em trÃ¬nh bÃ y hÆ°á»›ng 1 á»Ÿ trÃªn thÃ¬ em chá»‰ nghÄ© Ä‘Ã³ lÃ  hash cÃ¢u tráº£ lá»i rá»“i ngáº«u nhiÃªn tá»•ng há»£p láº¡i thÃ nh 1 tá»• há»£p password má»›i thÃ´i. Chá»© nÃ³ khÃ´ng cÃ³ Ã¡p dá»¥ng machinelearning hay cá»¥ thá»ƒ lÃ  training 1 cÃ¡i dataset nÃ o háº¿t. Má»i ngÆ°á»i giÃºp em chá»‰ ra vá»›i náº¿u nhÆ° Ã¡p dá»¥ng machinelearning (sá»­ dá»¥ng dataset) cho Ä‘á» bÃ i nÃ y dÃ¹ng 2 hÆ°á»›ng trÃªn thÃ¬ sá»­ dá»¥ng nhÆ° tháº¿ nÃ o áº¡! Xin cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"MÃ¬nh Ä‘ang lÃ m project giá»‘ng nhÆ° Jarvis, kiá»ƒu Voice Bot Assistant, nhÆ°ng Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ váº¥n Ä‘á» frontend (theo kiá»ƒu real time chá»© k cáº§n click) KhÃ´ng biáº¿t báº¡n nÃ o Ä‘Ã£ cÃ³ solutions vá» frontend cho pháº§n nÃ y chÆ°a? Cho mÃ¬nh xin gá»£i Ã½, mÃ¬nh cÃ³ tÃ¬m tháº¥y má»™t vÃ i chá»— nhÆ° Web Speech API, frontend of Rasa mÃ  váº«n chÆ°a thá»±c hiá»‡n Ä‘Æ°á»£c vÃ¬ cÃ³ váº» nhÆ° cáº§n pháº£i dÃ¹ng javasripts hay react js. Náº¿u cÃ³ template, hoáº·c no-code thÃ¬ tá»‘t quÃ¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.","MÃ¬nh Ä‘ang lÃ m project giá»‘ng nhÆ° Jarvis, kiá»ƒu Voice Bot Assistant, nhÆ°ng Ä‘ang gáº·p khÃ³ khÄƒn á»Ÿ váº¥n Ä‘á» frontend (theo kiá»ƒu real time chá»© k cáº§n click) KhÃ´ng biáº¿t báº¡n nÃ o Ä‘Ã£ cÃ³ solutions vá» frontend cho pháº§n nÃ y chÆ°a? Cho mÃ¬nh xin gá»£i Ã½, mÃ¬nh cÃ³ tÃ¬m tháº¥y má»™t vÃ i chá»— nhÆ° Web Speech API, frontend of Rasa mÃ  váº«n chÆ°a thá»±c hiá»‡n Ä‘Æ°á»£c vÃ¬ cÃ³ váº» nhÆ° cáº§n pháº£i dÃ¹ng javasripts hay react js. Náº¿u cÃ³ template, hoáº·c no-code thÃ¬ tá»‘t quÃ¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ quan tÃ¢m.",,,,,
NgoÃ i Kaggle lÃ  nÆ¡i cÃ³ nhiá»u open dataset ra thÃ¬ paperwiththecodes má»›i má»Ÿ ra thÃªm pháº§n lÆ°u trá»¯ dataset. Hiá»‡n trang nÃ y Ä‘ang lÆ°u gáº§n 4000 datasets Ä‘á»§ cÃ¡c chá»§ Ä‘á» táº¡i Ä‘Ã¢y,NgoÃ i Kaggle lÃ  nÆ¡i cÃ³ nhiá»u open dataset ra thÃ¬ paperwiththecodes má»›i má»Ÿ ra thÃªm pháº§n lÆ°u trá»¯ dataset. Hiá»‡n trang nÃ y Ä‘ang lÆ°u gáº§n 4000 datasets Ä‘á»§ cÃ¡c chá»§ Ä‘á» táº¡i Ä‘Ã¢y,,,,,
"Classification on very skewed data
Má»i ngÆ°á»i Æ¡i cho em há»i náº¿u dataset cá»§a e bá»‹ lá»‡ch ntn thÃ¬ augmentation cÃ³ giÃºp dc nhiá»u k áº¡
Dataset
~175,000 entry
52 classes","Classification on very skewed data Má»i ngÆ°á»i Æ¡i cho em há»i náº¿u dataset cá»§a e bá»‹ lá»‡ch ntn thÃ¬ augmentation cÃ³ giÃºp dc nhiá»u k áº¡ Dataset ~175,000 entry 52 classes",,,,,
Má»i ngÆ°á»i Æ¡i cho em há»i cÃ³ ai dÃ¹ng timm cho classification task chÆ°a áº¡ cho em há»i lÃ  náº¿u muá»‘n tá»± build model má»›i custom dataset thÃ¬ pháº£i lÃ m ntn áº¡,Má»i ngÆ°á»i Æ¡i cho em há»i cÃ³ ai dÃ¹ng timm cho classification task chÆ°a áº¡ cho em há»i lÃ  náº¿u muá»‘n tá»± build model má»›i custom dataset thÃ¬ pháº£i lÃ m ntn áº¡,,,,,
"ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» ğŸ˜.
Má»i ngÆ°á»i cho e há»i vá»›i áº¡:
Má»i ngÆ°á»i Ä‘Ã£ á»©ng dá»¥ng cÃ¡c bÃ i toÃ¡n NLP cho doanh nghiá»‡p cá»§a mÃ¬nh nhÆ° tháº¿ nÃ o áº¡?",ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» . Má»i ngÆ°á»i cho e há»i vá»›i áº¡: Má»i ngÆ°á»i Ä‘Ã£ á»©ng dá»¥ng cÃ¡c bÃ i toÃ¡n NLP cho doanh nghiá»‡p cá»§a mÃ¬nh nhÆ° tháº¿ nÃ o áº¡?,,,,,
"Hi má»i ngÆ°á»i!
Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project vá» nháº­n diá»‡n, Ä‘iá»u khiá»ƒn báº±ng giá»ng nÃ³i (Speech recognition and voice control). sá»­ dá»¥ng ngÃ´n ngá»¯ C++ C#
M.n cÃ³ tÃ i liá»‡u, Ä‘á»“ Ã¡n ... vá» Ä‘á» tÃ i nÃ y cÃ³ thá»ƒ cho em xin tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡!
CÃ³ tÃ i liá»‡u vá» nháº­n dáº¡ng vÃ  Ä‘iá»u khiá»ƒn báº±ng tiáº¿ng viá»‡t thÃ¬ cÃ ng tá»‘t áº¡!
Thanks m.n !","Hi má»i ngÆ°á»i! Hiá»‡n táº¡i em Ä‘ang lÃ m 1 project vá» nháº­n diá»‡n, Ä‘iá»u khiá»ƒn báº±ng giá»ng nÃ³i (Speech recognition and voice control). sá»­ dá»¥ng ngÃ´n ngá»¯ C++ C# M.n cÃ³ tÃ i liá»‡u, Ä‘á»“ Ã¡n ... vá» Ä‘á» tÃ i nÃ y cÃ³ thá»ƒ cho em xin tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡! CÃ³ tÃ i liá»‡u vá» nháº­n dáº¡ng vÃ  Ä‘iá»u khiá»ƒn báº±ng tiáº¿ng viá»‡t thÃ¬ cÃ ng tá»‘t áº¡! Thanks m.n !",,,,,
"ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i táº­p vá» xÃ¢y dá»±ng má»™t há»‡ thá»‘ng nháº­n dáº¡ng vÃ  tÃ¬m kiáº¿m hÃ¬nh áº£nh vá»›i Ä‘áº§u vÃ o lÃ  1 file áº£nh sá»¯a tÆ°Æ¡i má»›i, Ä‘áº§u ra lÃ  má»™t vÃ i file áº£nh trong CSDL cÃ³ ná»™i dung giá»‘ng nháº¥t hoáº·c chá»©a ná»™i dung cá»§a áº£nh Ä‘áº§u vÃ o. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t vÃ i Ã½ tÆ°á»Ÿng vá»›i áº¡. Em cáº£m Æ¡n!","ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang lÃ m bÃ i táº­p vá» xÃ¢y dá»±ng má»™t há»‡ thá»‘ng nháº­n dáº¡ng vÃ  tÃ¬m kiáº¿m hÃ¬nh áº£nh vá»›i Ä‘áº§u vÃ o lÃ  1 file áº£nh sá»¯a tÆ°Æ¡i má»›i, Ä‘áº§u ra lÃ  má»™t vÃ i file áº£nh trong CSDL cÃ³ ná»™i dung giá»‘ng nháº¥t hoáº·c chá»©a ná»™i dung cá»§a áº£nh Ä‘áº§u vÃ o. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin má»™t vÃ i Ã½ tÆ°á»Ÿng vá»›i áº¡. Em cáº£m Æ¡n!",,,,,
á» Ä‘Ã¢y cÃ³ ai Ä‘Ã£ sá»­ dá»¥ng Datarobot chÆ°a áº¡? Theo nhÆ° cÃ¡i video demo nÃ y thÃ¬ nÃ³ giÃºp mÃ¬nh tá»± Ä‘á»™ng hoÃ¡ data cleaning vÃ  parameter tuning. MÃ¬nh Ä‘Ã¡nh giÃ¡ lÃ  nÃ³ sáº½ giÃºp mÃ¬nh hoÃ n thÃ nh cÃ´ng viá»‡c nhanh hÆ¡n 90% so vá»›i mÃ¬nh tá»± lÃ m (thá»±c sá»± mÃ¬nh Ä‘ang lÃ m data analyst cÃ³ Ã¡p dá»¥ng machine learning chá»© khÃ´ng dÃ¡m nháº­n lÃ  data scientist). Ai dÃ¹ng rá»“i thÃ¬ cho mÃ¬nh xin review vÃ  subscription fee vá»›i.,á» Ä‘Ã¢y cÃ³ ai Ä‘Ã£ sá»­ dá»¥ng Datarobot chÆ°a áº¡? Theo nhÆ° cÃ¡i video demo nÃ y thÃ¬ nÃ³ giÃºp mÃ¬nh tá»± Ä‘á»™ng hoÃ¡ data cleaning vÃ  parameter tuning. MÃ¬nh Ä‘Ã¡nh giÃ¡ lÃ  nÃ³ sáº½ giÃºp mÃ¬nh hoÃ n thÃ nh cÃ´ng viá»‡c nhanh hÆ¡n 90% so vá»›i mÃ¬nh tá»± lÃ m (thá»±c sá»± mÃ¬nh Ä‘ang lÃ m data analyst cÃ³ Ã¡p dá»¥ng machine learning chá»© khÃ´ng dÃ¡m nháº­n lÃ  data scientist). Ai dÃ¹ng rá»“i thÃ¬ cho mÃ¬nh xin review vÃ  subscription fee vá»›i.,,,,,
,nan,,,,,
"[Object Detection][Faster RCNN]
ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m 1 project liÃªn quan Ä‘áº¿n object detection, cá»¥ thá»ƒ lÃ  vá» steel defect detection vÃ  thÃ´ng qua táº­p NEU-DET dataset cá»§a Northeastern University. Cá»¥ thá»ƒ thÃ¬ Ä‘Ã¢y lÃ  táº­p data set vá» steel defection Ä‘Ã£ cÃ³ Ä‘á»§ label vÃ  boxes cá»¥ thá»ƒ cho tá»«ng áº£nh trÃªn data thÃ´ng qua 1 file xml. Hiá»‡n táº¡i thÃ¬ mÃ¬nh cÃ³ Ä‘á»c qua 1 vÃ i papers Ä‘á»ƒ xá»­ lÃ½ cho viá»‡c detect defection, mÃ¬nh cÃ³ Ä‘á»c qua 1 paper (https://ieeexplore.ieee.org/document/8709818) nÃ y vÃ  cÃ³ dÃ¹ng cÃ¡ch láº¥y cÃ¡c feature cá»§a áº£nh thÃ´ng qua cÃ¡c stage outputs cá»§a resnet vÃ  Ä‘Æ°a nÃ³ qua 1 ROIPooling Ä‘á»ƒ train, song song vá»›i viá»‡c Ä‘Ã³ thÃ¬ cÃ³ Ã¡p dá»¥ng cáº£ RPN. VÃ¬ tháº¿ theo Ã½ hiá»ƒu cá»§a mÃ¬nh thÃ¬ nÃ³ khÃ¡ giá»‘ng vá»›i cÃ¡ch tiáº¿p cáº­n cá»§a Faster RCNN. MÃ¬nh Ä‘Ã£ Ä‘i thá»­ implement Faster RCNN cho data set kia trÆ°á»›c thÃ´ng qua viá»‡c code láº¡i theo repo nÃ y (https://github.com/kentaroy47/frcnn-from-scratch-with-keras) Ä‘á»ƒ thá»­ xem solution nÃ y cÃ³ hiá»‡u quáº£ khÃ´ng nhÆ°ng mÃ  mÃ¬nh Ä‘ang bá»‹ gáº·p 1 sá»‘ váº¥n Ä‘á» liÃªn quan Ä‘áº¿n RPN, cá»¥ thá»ƒ lÃ  á»Ÿ bÆ°á»›c training, sau khi train xong RPN model vÃ  predict thÃ¬ mÃ¬nh tháº¥y sá»‘ number of rois sau khi predict sáº½ lÃ  dynamic (vÃ­ dá»¥: [(1, 1, 7), (1, 1, 48)] hoáº·c [(1, 2, 7), (1, 2, 48)] ), vÃ¬ káº¿t quáº£ cá»§a RPN model prediction sáº½ Ä‘Æ°á»£c dÃ¹ng lÃ m output data cho classifier model sau Ä‘Ã³ Ä‘á»ƒ Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng, nhÆ°ng vÃ¬ output layer cá»§a classifier model Ä‘Æ°á»£c fix shape (vÃ­ dá»¥: 6 classes - classify layer: (1, 4, 7), locate layer: (1, 4, 24)). VÃ¬ y_train truyá»n vÃ o cÃ³ shape lÃ  dynamic nÃªn sáº½ xáº£y ra lá»—i khÃ´ng matching vá»›i output layer cá»§a model. VÃ¬ 1 pháº§n mÃ¬nh cÅ©ng lÃ  ngÆ°á»i má»›i vá» lÄ©nh vá»±c nÃ y nÃªn chÆ°a cÃ³ kinh nghiá»‡m xá»­ lÃ½ váº¥n Ä‘á» nÃ y. Váº­y cÃ³ ai trong group Ä‘Ã£ tá»«ng implement theo repo trÃªn hoáº·c xá»­ lÃ½ 1 váº¥n Ä‘á» liÃªn quan Ä‘áº¿n váº¥n Ä‘á» mÃ¬nh Ä‘ang gáº·p thÃ¬ cÃ³ thá»ƒ giÃºp mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡?
MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i!","[Object Detection][Faster RCNN] ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m 1 project liÃªn quan Ä‘áº¿n object detection, cá»¥ thá»ƒ lÃ  vá» steel defect detection vÃ  thÃ´ng qua táº­p NEU-DET dataset cá»§a Northeastern University. Cá»¥ thá»ƒ thÃ¬ Ä‘Ã¢y lÃ  táº­p data set vá» steel defection Ä‘Ã£ cÃ³ Ä‘á»§ label vÃ  boxes cá»¥ thá»ƒ cho tá»«ng áº£nh trÃªn data thÃ´ng qua 1 file xml. Hiá»‡n táº¡i thÃ¬ mÃ¬nh cÃ³ Ä‘á»c qua 1 vÃ i papers Ä‘á»ƒ xá»­ lÃ½ cho viá»‡c detect defection, mÃ¬nh cÃ³ Ä‘á»c qua 1 paper (https://ieeexplore.ieee.org/document/8709818) nÃ y vÃ  cÃ³ dÃ¹ng cÃ¡ch láº¥y cÃ¡c feature cá»§a áº£nh thÃ´ng qua cÃ¡c stage outputs cá»§a resnet vÃ  Ä‘Æ°a nÃ³ qua 1 ROIPooling Ä‘á»ƒ train, song song vá»›i viá»‡c Ä‘Ã³ thÃ¬ cÃ³ Ã¡p dá»¥ng cáº£ RPN. VÃ¬ tháº¿ theo Ã½ hiá»ƒu cá»§a mÃ¬nh thÃ¬ nÃ³ khÃ¡ giá»‘ng vá»›i cÃ¡ch tiáº¿p cáº­n cá»§a Faster RCNN. MÃ¬nh Ä‘Ã£ Ä‘i thá»­ implement Faster RCNN cho data set kia trÆ°á»›c thÃ´ng qua viá»‡c code láº¡i theo repo nÃ y (https://github.com/kentaroy47/frcnn-from-scratch-with-keras) Ä‘á»ƒ thá»­ xem solution nÃ y cÃ³ hiá»‡u quáº£ khÃ´ng nhÆ°ng mÃ  mÃ¬nh Ä‘ang bá»‹ gáº·p 1 sá»‘ váº¥n Ä‘á» liÃªn quan Ä‘áº¿n RPN, cá»¥ thá»ƒ lÃ  á»Ÿ bÆ°á»›c training, sau khi train xong RPN model vÃ  predict thÃ¬ mÃ¬nh tháº¥y sá»‘ number of rois sau khi predict sáº½ lÃ  dynamic (vÃ­ dá»¥: [(1, 1, 7), (1, 1, 48)] hoáº·c [(1, 2, 7), (1, 2, 48)] ), vÃ¬ káº¿t quáº£ cá»§a RPN model prediction sáº½ Ä‘Æ°á»£c dÃ¹ng lÃ m output data cho classifier model sau Ä‘Ã³ Ä‘á»ƒ Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng, nhÆ°ng vÃ¬ output layer cá»§a classifier model Ä‘Æ°á»£c fix shape (vÃ­ dá»¥: 6 classes - classify layer: (1, 4, 7), locate layer: (1, 4, 24)). VÃ¬ y_train truyá»n vÃ o cÃ³ shape lÃ  dynamic nÃªn sáº½ xáº£y ra lá»—i khÃ´ng matching vá»›i output layer cá»§a model. VÃ¬ 1 pháº§n mÃ¬nh cÅ©ng lÃ  ngÆ°á»i má»›i vá» lÄ©nh vá»±c nÃ y nÃªn chÆ°a cÃ³ kinh nghiá»‡m xá»­ lÃ½ váº¥n Ä‘á» nÃ y. Váº­y cÃ³ ai trong group Ä‘Ã£ tá»«ng implement theo repo trÃªn hoáº·c xá»­ lÃ½ 1 váº¥n Ä‘á» liÃªn quan Ä‘áº¿n váº¥n Ä‘á» mÃ¬nh Ä‘ang gáº·p thÃ¬ cÃ³ thá»ƒ giÃºp mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡? MÃ¬nh xin cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"ÄIá»€U GÃŒ ÄÃƒ Xáº¢Y RA Vá»šI KHUÃ”N Máº¶T á» Gáº¦N CAM HÆ N?
ChÃ o m.n, gáº§n Ä‘Ã¢y em cÃ³ lÃ m má»™t bÃ¬a toÃ¡n phÃ¢n loáº¡i Máº·t cÃ³ Ä‘eo kháº©u trang hay khÃ´ng. CÃ³ má»™t issue lÃ m em ráº¥t khÃ³ giáº£i thÃ­ch nhÆ° nÃ y:
Em sá»­ dá»¥ng má»™t model vá»›i vÃ i lá»›p conv nhÆ° áº£nh dÆ°á»›i, loss vÃ  acc trÃªn val Ä‘á»u cho káº¿t quáº£ khÃ¡ kháº£ quan. Káº¿t quáº£ test trá»±c tiáº¿p trÃªn webcam khÃ¡ tá»‘t, trá»« viá»‡c khi Ä‘Æ°a máº·t sÃ¡t vÃ o webcam thÃ¬ nÃ³ phÃ¢n loáº¡i sai (hÃ¬nh dÆ°á»›i). Trong khi Ä‘á»ƒ á»Ÿ khoáº£ng cÃ¡ch vá»«a pháº£i, cÃ¡ch khoáº£ng 30cm so vá»›i cam, thÃ¬ láº¡i phÃ¢n loáº¡i Ä‘Ãºng. Váº«n dá»¯ liá»‡u Ä‘áº¥y, t transfer sang MobileNet thÃ¬ láº¡i ko cÃ³ hiá»‡n tÆ°á»£ng nÃ y ná»¯a.
áº¢nh trong cá»­a sá»• 'face' lÃ  cÃ¡i máº·t Ä‘Ã£ Ä‘c detect xong crop, resize trÆ°á»›c khi cho vÃ o mÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘á»ƒ predict, cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ Ä‘á»u giá»‘ng vá»›i dá»¯ liá»‡u táº­p training.
Äiá»u gÃ¬ xáº£y ra vá»›i cÃ¡i máº·t á»Ÿ gáº§n cam váº­y áº¡?","ÄIá»€U GÃŒ ÄÃƒ Xáº¢Y RA Vá»šI KHUÃ”N Máº¶T á» Gáº¦N CAM HÆ N? ChÃ o m.n, gáº§n Ä‘Ã¢y em cÃ³ lÃ m má»™t bÃ¬a toÃ¡n phÃ¢n loáº¡i Máº·t cÃ³ Ä‘eo kháº©u trang hay khÃ´ng. CÃ³ má»™t issue lÃ m em ráº¥t khÃ³ giáº£i thÃ­ch nhÆ° nÃ y: Em sá»­ dá»¥ng má»™t model vá»›i vÃ i lá»›p conv nhÆ° áº£nh dÆ°á»›i, loss vÃ  acc trÃªn val Ä‘á»u cho káº¿t quáº£ khÃ¡ kháº£ quan. Káº¿t quáº£ test trá»±c tiáº¿p trÃªn webcam khÃ¡ tá»‘t, trá»« viá»‡c khi Ä‘Æ°a máº·t sÃ¡t vÃ o webcam thÃ¬ nÃ³ phÃ¢n loáº¡i sai (hÃ¬nh dÆ°á»›i). Trong khi Ä‘á»ƒ á»Ÿ khoáº£ng cÃ¡ch vá»«a pháº£i, cÃ¡ch khoáº£ng 30cm so vá»›i cam, thÃ¬ láº¡i phÃ¢n loáº¡i Ä‘Ãºng. Váº«n dá»¯ liá»‡u Ä‘áº¥y, t transfer sang MobileNet thÃ¬ láº¡i ko cÃ³ hiá»‡n tÆ°á»£ng nÃ y ná»¯a. áº¢nh trong cá»­a sá»• 'face' lÃ  cÃ¡i máº·t Ä‘Ã£ Ä‘c detect xong crop, resize trÆ°á»›c khi cho vÃ o mÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘á»ƒ predict, cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ Ä‘á»u giá»‘ng vá»›i dá»¯ liá»‡u táº­p training. Äiá»u gÃ¬ xáº£y ra vá»›i cÃ¡i máº·t á»Ÿ gáº§n cam váº­y áº¡?",,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ táº¡o má»™t model lÃ m vÃ­ dá»¥ nhÆ° hÃ¬nh dÆ°á»›i.
Sau khi cháº¡y loss.backward() thÃ¬ em cÃ³ in ra grad cá»§a model.w thÃ¬ nÃ³ hiá»‡n lÃ  None trong khi em Ä‘ang cáº§n update model.w trong quÃ¡ trÃ¬nh train. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡","ChÃ o má»i ngÆ°á»i, em cÃ³ táº¡o má»™t model lÃ m vÃ­ dá»¥ nhÆ° hÃ¬nh dÆ°á»›i. Sau khi cháº¡y loss.backward() thÃ¬ em cÃ³ in ra grad cá»§a model.w thÃ¬ nÃ³ hiá»‡n lÃ  None trong khi em Ä‘ang cáº§n update model.w trong quÃ¡ trÃ¬nh train. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡",,,,,
"Scaled-YOLOv4
https://arxiv.org/abs/2011.08036",Scaled-YOLOv4 https://arxiv.org/abs/2011.08036,,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t váº¥n Ä‘á» mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
Cá»¥ thá»ƒ nhÆ° sau:
Em cÃ³ má»™t máº¡ng sá»­ dá»¥ng cÃ¡c Convolution Layer. Sau khi train xong thu Ä‘Æ°á»£c cÃ¡c kernel tensor Z. Sau khi prune model thÃ¬ thu Ä‘Æ°á»£c cÃ¡c weight_mask G ( gá»“m cÃ¡c giÃ¡ trá»‹ nhá»‹ phÃ¢n 0,1 --> 1 biá»ƒu thá»‹ giÃ¡ trá»‹ táº¡i index Ä‘Ã³ tÆ°Æ¡ng á»©ng trong Z Ä‘Æ°á»£c giá»¯ láº¡i ).
LÃºc nÃ y kernel tensor trá»Ÿ thÃ nh Z*G. Trong paper em Ä‘á»c Ä‘Æ°á»£c thÃ¬ ngÆ°á»i cÃ³ báº£o nguyÃªn vÄƒn nhÆ° tháº¿ nÃ y : 'Due to the existance of ğ‘®, only important parameters are optimized, while pruned parameters keep unchanged because no gradients are created for them' 
Tá»©c lÃ :  vÃ¬ sá»± tá»“n táº¡i cá»§a G, chá»‰ cÃ¡c tham sá»‘ quan trá»ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a, trong khi cÃ¡c tham sá»‘ bá»‹ cáº¯t tá»‰a Ä‘Æ°á»£c giá»¯ nguyÃªn vÃ¬ khÃ´ng cÃ³ gradient Ä‘Æ°á»£c táº¡o ra bá»Ÿi chÃºng ""
Em ngá»“i suy nghÄ© váº«n chÆ°a lÃ m sao chá»©ng mÃ¬nh Ä‘Æ°á»£c luáº­n Ä‘iá»ƒm nÃ y cá»§a paper. Tá»©c lÃ  chá»©ng minh viá»‡c má»™t parameters cÃ³ giÃ¡ trá»‹ báº±ng 0 thÃ¬ sáº½ khÃ´ng cÃ³ gradient Ä‘Æ°á»£c táº¡o ra cho nÃ³.  Trong paper ngÆ°á»i ta dÃ¹ng activation function lÃ  ReLu
 Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡, em xin cáº£m Æ¡n
Nguá»“n paper: https://arxiv.org/abs/2009.13724 ( HÃ¬nh áº£nh á»Ÿ dÆ°á»›i náº±m á»Ÿ Stage 3 trang 5 /11 )","ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t váº¥n Ä‘á» mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p. Cá»¥ thá»ƒ nhÆ° sau: Em cÃ³ má»™t máº¡ng sá»­ dá»¥ng cÃ¡c Convolution Layer. Sau khi train xong thu Ä‘Æ°á»£c cÃ¡c kernel tensor Z. Sau khi prune model thÃ¬ thu Ä‘Æ°á»£c cÃ¡c weight_mask G ( gá»“m cÃ¡c giÃ¡ trá»‹ nhá»‹ phÃ¢n 0,1 --> 1 biá»ƒu thá»‹ giÃ¡ trá»‹ táº¡i index Ä‘Ã³ tÆ°Æ¡ng á»©ng trong Z Ä‘Æ°á»£c giá»¯ láº¡i ). LÃºc nÃ y kernel tensor trá»Ÿ thÃ nh Z*G. Trong paper em Ä‘á»c Ä‘Æ°á»£c thÃ¬ ngÆ°á»i cÃ³ báº£o nguyÃªn vÄƒn nhÆ° tháº¿ nÃ y : 'Due to the existance of , only important parameters are optimized, while pruned parameters keep unchanged because no gradients are created for them' Tá»©c lÃ : vÃ¬ sá»± tá»“n táº¡i cá»§a G, chá»‰ cÃ¡c tham sá»‘ quan trá»ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a, trong khi cÃ¡c tham sá»‘ bá»‹ cáº¯t tá»‰a Ä‘Æ°á»£c giá»¯ nguyÃªn vÃ¬ khÃ´ng cÃ³ gradient Ä‘Æ°á»£c táº¡o ra bá»Ÿi chÃºng "" Em ngá»“i suy nghÄ© váº«n chÆ°a lÃ m sao chá»©ng mÃ¬nh Ä‘Æ°á»£c luáº­n Ä‘iá»ƒm nÃ y cá»§a paper. Tá»©c lÃ  chá»©ng minh viá»‡c má»™t parameters cÃ³ giÃ¡ trá»‹ báº±ng 0 thÃ¬ sáº½ khÃ´ng cÃ³ gradient Ä‘Æ°á»£c táº¡o ra cho nÃ³. Trong paper ngÆ°á»i ta dÃ¹ng activation function lÃ  ReLu Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡, em xin cáº£m Æ¡n Nguá»“n paper: https://arxiv.org/abs/2009.13724 ( HÃ¬nh áº£nh á»Ÿ dÆ°á»›i náº±m á»Ÿ Stage 3 trang 5 /11 )",,,,,
"MoÌ£i ngÆ°Æ¡Ì€i cho miÌ€nh hoÌ‰i mÃ´Ì£t chuÌt vÃªÌ€ thÆ° viÃªÌ£n vaex. MiÌ€nh coÌ thÆ°Ì‰ tiÌ€m hiÃªÌ‰u thiÌ€ thÃ¢Ìy vaex xÆ°Ì‰ liÌ data cÆ°Ì£c nhanh so vÆ¡Ìi pandas, nhÆ°ng khi laÌ€m trÃªn Colab thiÌ€ khÃ´ng biÃªÌt sai Æ¡Ì‰ Ä‘Ã¢u maÌ€ thÃ¢Ìy noÌ vÃ¢Ìƒn chÃ¢Ì£m ngang vÆ¡Ìi pandas. CoÌ ai Ä‘aÌƒ gÄƒÌ£p trÆ°Æ¡Ì€ng hÆ¡Ì£p naÌ€y thiÌ€ coÌ thÃªÌ‰ giaÌ‰i thiÌch cho miÌ€nh Ä‘Æ°Æ¡Ì£c khÃ´ng aÌ£.","MoÌ£i ngÆ°Æ¡Ì€i cho miÌ€nh hoÌ‰i mÃ´Ì£t chuÌt vÃªÌ€ thÆ° viÃªÌ£n vaex. MiÌ€nh coÌ thÆ°Ì‰ tiÌ€m hiÃªÌ‰u thiÌ€ thÃ¢Ìy vaex xÆ°Ì‰ liÌ data cÆ°Ì£c nhanh so vÆ¡Ìi pandas, nhÆ°ng khi laÌ€m trÃªn Colab thiÌ€ khÃ´ng biÃªÌt sai Æ¡Ì‰ Ä‘Ã¢u maÌ€ thÃ¢Ìy noÌ vÃ¢Ìƒn chÃ¢Ì£m ngang vÆ¡Ìi pandas. CoÌ ai Ä‘aÌƒ gÄƒÌ£p trÆ°Æ¡Ì€ng hÆ¡Ì£p naÌ€y thiÌ€ coÌ thÃªÌ‰ giaÌ‰i thiÌch cho miÌ€nh Ä‘Æ°Æ¡Ì£c khÃ´ng aÌ£.",,,,,
"má»i ngÆ°á»i cho em há»i vá»›i Ä‘Ã£ cÃ³ ai gáº·p trÆ°á»ng há»£p nhÆ° tháº¿ nÃ y chÆ°a áº¡
trÆ°á»›c em xÃ i anaconda 3.8.5 em cÃ i tensorflow nÃ³ khÃ´ng nháº­n báº¯t buá»™c háº¡ vá» báº£n 3.7.x má»›i nháº­n tensorflow
vá» 3.7.x thÃ¬ em install láº¡i cv2 thÃ¬ nÃ³ tá»± Ä‘á»™ng install opencv 3.4.1 nhÆ° hÃ¬nh
sau Ä‘Ã³ em cÃ i MTCNN thÃ¬ MTCNN láº¡i update opencv tá»« 3.4.1 lÃªn 4.1.1
nhÆ°ng khi update opencv lÃªn 4.1.1 thÃ¬ opencv láº¡i bá»‹ lá»—i vÃ  em uninstall Ä‘i cÃ i láº¡i 3.4.1 thÃ¬ bÃ¬nh thÆ°á»ng nhÆ°ng láº¡i máº¥t MTCNN
ai cÃ³ kinh nghiá»‡m xá»­ lÃ½ cÃ¡i nÃ y cho em xin hÆ°á»›ng Ä‘i áº¡",má»i ngÆ°á»i cho em há»i vá»›i Ä‘Ã£ cÃ³ ai gáº·p trÆ°á»ng há»£p nhÆ° tháº¿ nÃ y chÆ°a áº¡ trÆ°á»›c em xÃ i anaconda 3.8.5 em cÃ i tensorflow nÃ³ khÃ´ng nháº­n báº¯t buá»™c háº¡ vá» báº£n 3.7.x má»›i nháº­n tensorflow vá» 3.7.x thÃ¬ em install láº¡i cv2 thÃ¬ nÃ³ tá»± Ä‘á»™ng install opencv 3.4.1 nhÆ° hÃ¬nh sau Ä‘Ã³ em cÃ i MTCNN thÃ¬ MTCNN láº¡i update opencv tá»« 3.4.1 lÃªn 4.1.1 nhÆ°ng khi update opencv lÃªn 4.1.1 thÃ¬ opencv láº¡i bá»‹ lá»—i vÃ  em uninstall Ä‘i cÃ i láº¡i 3.4.1 thÃ¬ bÃ¬nh thÆ°á»ng nhÆ°ng láº¡i máº¥t MTCNN ai cÃ³ kinh nghiá»‡m xá»­ lÃ½ cÃ¡i nÃ y cho em xin hÆ°á»›ng Ä‘i áº¡,,,,,
CÃ³ ai biáº¿t dÃ²ng y táº¡i sao láº¡i nhÆ° váº­y khÃ´ng!. Vá»›i láº¡i mÃ¬nh Ä‘ang bá»‹ lá»—i á»Ÿ dÃ²ng Ä‘Ã³,CÃ³ ai biáº¿t dÃ²ng y táº¡i sao láº¡i nhÆ° váº­y khÃ´ng!. Vá»›i láº¡i mÃ¬nh Ä‘ang bá»‹ lá»—i á»Ÿ dÃ²ng Ä‘Ã³,,,,,
"ChÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cho em há»i pro/con cá»§a azure machine learning vá»›i google cloud AI cho enterprise vá»›i áº¡?
Anh/chá»‹ cÃ³ biáº¿t thÃ´ng tin gÃ¬ hay Ä‘Ã£ sá»­ dá»¥ng qua thÃ¬ em mong má»i ngÆ°á»i chia sáº» cho em Ä‘Æ°á»£c hiá»ƒu thÃªm. Em cáº£m Æ¡n!",ChÃ o má»i ngÆ°á»i. Má»i ngÆ°á»i cho em há»i pro/con cá»§a azure machine learning vá»›i google cloud AI cho enterprise vá»›i áº¡? Anh/chá»‹ cÃ³ biáº¿t thÃ´ng tin gÃ¬ hay Ä‘Ã£ sá»­ dá»¥ng qua thÃ¬ em mong má»i ngÆ°á»i chia sáº» cho em Ä‘Æ°á»£c hiá»ƒu thÃªm. Em cáº£m Æ¡n!,,,,,
"GIGO (Garbage In, Garbage Out) is a popular concept in Computer Science expressing the idea that the product created from materials of low quality will also be low quality. Specifically for Data Science, bad data input can generate inaccurate insights leading to wrong decision making. For this reason, it is critical to monitor and maintain Data Quality to make sure the data meets certain standards for specific business use-cases.
To the best of my knowledge, however, there is no widely-used, industry-standard and generically built Data Quality framework from which organisations can adopt for any of their specific applications and therefore the big questions are always ""How should we do it?"", ""How to define high-quality data?"".
In this article, I will dictate the definition of Data Quality and its dimensions. I will explain the high-level implementation and the process of Data Quality Management as well as teams' responsibilities for managing Data Quality.
#datascience #data #dataquality #dataqualitymanagement #garbageingarbageout #bigdata #dataanalytics #insight #agile #ai #business #machinelearning #artificialintelligence #analytics","GIGO (Garbage In, Garbage Out) is a popular concept in Computer Science expressing the idea that the product created from materials of low quality will also be low quality. Specifically for Data Science, bad data input can generate inaccurate insights leading to wrong decision making. For this reason, it is critical to monitor and maintain Data Quality to make sure the data meets certain standards for specific business use-cases. To the best of my knowledge, however, there is no widely-used, industry-standard and generically built Data Quality framework from which organisations can adopt for any of their specific applications and therefore the big questions are always ""How should we do it?"", ""How to define high-quality data?"". In this article, I will dictate the definition of Data Quality and its dimensions. I will explain the high-level implementation and the process of Data Quality Management as well as teams' responsibilities for managing Data Quality.",#datascience	#data	#dataquality	#dataqualitymanagement	#garbageingarbageout	#bigdata	#dataanalytics	#insight	#agile	#ai	#business	#machinelearning	#artificialintelligence	#analytics,,,,
"Máº·c dÃ¹ tÃ¬nh tráº¡ng khan hiáº¿m GPU Ä‘ang diá»…n ra ráº¥t tráº§m trá»ng. Máº¥y thÃ¡ng trÆ°á»›c mÃ¬nh Ä‘Ã£ bÃ¡n Ä‘i 2 con 1080Ti sau khi cÃ³ 1 con 3090, sau láº¡i bÃ¡n tiáº¿p Ä‘i 1 con 1060 6G thÃ¬ má»›i phÃ¡t hiá»‡n ra (1) anh Elon Musk (cÃ³ láº½ qua phÃ¡t biá»ƒu) vÃ  (2) tÃ¬nh tráº¡ng báº¥t á»•n kinh táº¿ --> bitcoin lÃªn ngÃ´i, cÃ¹ng vá»›i tÃ¬nh tráº¡ng khan hiáº¿m linh kiá»‡n Ä‘iá»‡n tá»­ nÃ³i chung do (3) Ä‘áº¡i dá»‹ch Covid-19 vÃ  cÃ¡c xung Ä‘á»™t chÃ­nh trá»‹. NgÆ°á»£c láº¡i vá»›i cÃ¢u chuyá»‡n trÃªn thÃ¬ cÃ¡c SOTA models ngÃ y cÃ ng yÃªu cáº§u nÄƒng lá»±c tÃ­nh toÃ¡n ráº¥t cao. HÃ´m qua, trÃªn diá»…n Ä‘Ã n mÃ¬nh tháº¥y má»™t sá»‘ guru cÃ³ bÃ n luáº­n vá» cÃ¡ch há» build há»‡ thá»‘ng mÃ¡y tÃ­nh Ä‘á»ƒ lÃ m viá»‡c. TrÆ°á»›c Ä‘Ã¢y, cÃ³ thá»ƒ chÃºng ta Ä‘Ã£ biáº¿t tá»›i blog cá»§a anh Tim Dettmers (táº¡i Ä‘Ã¢y https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/), nhÆ°ng hÆ°á»›ng dáº«n nÃ y khÃ¡ out-of-date. Do váº­y mÃ¬nh tháº¥y cÃ¡ch anh Emil Wallner cÃ³ viáº¿t bÃ i khÃ¡ hay hÆ°á»›ng dáº«n build mÃ¡y cho 3 nhÃ³m Ä‘á»‘i tÆ°á»£ng, lÃ  ngÆ°á»i dÃ¹ng Ä‘Æ¡n láº» (consumer), ngÆ°á»i dÃ¹ng ""chuyÃªn nghiá»‡p"" (proconsumer), vÃ  doanh nghiá»‡p (enterprise) táº¡i Ä‘Ã¢y: https://www.emilwallner.com/p/ml-rig.
Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i.
CÃ²n cÃ¡ nhÃ¢n mÃ¬nh cÃ³ cÃ¡ch khÃ¡c ráº¥t ráº» vá»›i viá»‡c chá»‰ dÃ nh tiá»n cho GPUs mÃ  thÃ´i!!! Táº¥t nhiÃªn, mÃ¬nh khÃ´ng Ä‘o benchmark nhÆ° há», nhÆ°ng qua tráº£i nghiá»‡m thá»±c táº¿ tá»« nhá»¯ng láº§n nÃ¢ng cáº¥p thÃ¬ tháº¥y khÃ¡ hÃ i lÃ²ng vá»›i há»‡ thá»‘ng hiá»‡n táº¡i!","Máº·c dÃ¹ tÃ¬nh tráº¡ng khan hiáº¿m GPU Ä‘ang diá»…n ra ráº¥t tráº§m trá»ng. Máº¥y thÃ¡ng trÆ°á»›c mÃ¬nh Ä‘Ã£ bÃ¡n Ä‘i 2 con 1080Ti sau khi cÃ³ 1 con 3090, sau láº¡i bÃ¡n tiáº¿p Ä‘i 1 con 1060 6G thÃ¬ má»›i phÃ¡t hiá»‡n ra (1) anh Elon Musk (cÃ³ láº½ qua phÃ¡t biá»ƒu) vÃ  (2) tÃ¬nh tráº¡ng báº¥t á»•n kinh táº¿ --> bitcoin lÃªn ngÃ´i, cÃ¹ng vá»›i tÃ¬nh tráº¡ng khan hiáº¿m linh kiá»‡n Ä‘iá»‡n tá»­ nÃ³i chung do (3) Ä‘áº¡i dá»‹ch Covid-19 vÃ  cÃ¡c xung Ä‘á»™t chÃ­nh trá»‹. NgÆ°á»£c láº¡i vá»›i cÃ¢u chuyá»‡n trÃªn thÃ¬ cÃ¡c SOTA models ngÃ y cÃ ng yÃªu cáº§u nÄƒng lá»±c tÃ­nh toÃ¡n ráº¥t cao. HÃ´m qua, trÃªn diá»…n Ä‘Ã n mÃ¬nh tháº¥y má»™t sá»‘ guru cÃ³ bÃ n luáº­n vá» cÃ¡ch há» build há»‡ thá»‘ng mÃ¡y tÃ­nh Ä‘á»ƒ lÃ m viá»‡c. TrÆ°á»›c Ä‘Ã¢y, cÃ³ thá»ƒ chÃºng ta Ä‘Ã£ biáº¿t tá»›i blog cá»§a anh Tim Dettmers (táº¡i Ä‘Ã¢y https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/), nhÆ°ng hÆ°á»›ng dáº«n nÃ y khÃ¡ out-of-date. Do váº­y mÃ¬nh tháº¥y cÃ¡ch anh Emil Wallner cÃ³ viáº¿t bÃ i khÃ¡ hay hÆ°á»›ng dáº«n build mÃ¡y cho 3 nhÃ³m Ä‘á»‘i tÆ°á»£ng, lÃ  ngÆ°á»i dÃ¹ng Ä‘Æ¡n láº» (consumer), ngÆ°á»i dÃ¹ng ""chuyÃªn nghiá»‡p"" (proconsumer), vÃ  doanh nghiá»‡p (enterprise) táº¡i Ä‘Ã¢y: https://www.emilwallner.com/p/ml-rig. Hi vá»ng nÃ³ há»¯u Ã­ch vá»›i má»i ngÆ°á»i. CÃ²n cÃ¡ nhÃ¢n mÃ¬nh cÃ³ cÃ¡ch khÃ¡c ráº¥t ráº» vá»›i viá»‡c chá»‰ dÃ nh tiá»n cho GPUs mÃ  thÃ´i!!! Táº¥t nhiÃªn, mÃ¬nh khÃ´ng Ä‘o benchmark nhÆ° há», nhÆ°ng qua tráº£i nghiá»‡m thá»±c táº¿ tá»« nhá»¯ng láº§n nÃ¢ng cáº¥p thÃ¬ tháº¥y khÃ¡ hÃ i lÃ²ng vá»›i há»‡ thá»‘ng hiá»‡n táº¡i!",,,,,
"chÃ o mng, mk má»›i há»c nhá»©ng Ä‘áº¿n pháº§n maximum likelihood ko hiá»ƒu rÃµ, ko biáº¿t likelihood khÃ¡c vs xÃ¡c suáº¥t nhÆ° tháº¿ nÃ o v áº¡,","chÃ o mng, mk má»›i há»c nhá»©ng Ä‘áº¿n pháº§n maximum likelihood ko hiá»ƒu rÃµ, ko biáº¿t likelihood khÃ¡c vs xÃ¡c suáº¥t nhÆ° tháº¿ nÃ o v áº¡,",,"#Q&A, #math",,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, do Ä‘iá»u kiá»‡n mÃ¡y mÃ³c khÃ´ng cÃ³ GPU nÃªn em tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng luÃ´n GPU nÃ y Ä‘á»ƒ inference nháº±m tÄƒng tá»‘c Ä‘á»™ nháº­n diá»‡n realtime qua webcam.
HÃ´m nay tranh thá»§ lÃ m clip share cÃ¹ng cÃ¡c báº¡n má»›i há»c. Mong ad duyá»‡t bÃ i!
ChÃºc anh em thÃ nh cÃ´ng!","KÃ­nh chÃ o cÃ¡c bÃ¡c, do Ä‘iá»u kiá»‡n mÃ¡y mÃ³c khÃ´ng cÃ³ GPU nÃªn em tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng luÃ´n GPU nÃ y Ä‘á»ƒ inference nháº±m tÄƒng tá»‘c Ä‘á»™ nháº­n diá»‡n realtime qua webcam. HÃ´m nay tranh thá»§ lÃ m clip share cÃ¹ng cÃ¡c báº¡n má»›i há»c. Mong ad duyá»‡t bÃ i! ChÃºc anh em thÃ nh cÃ´ng!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  newbie, muá»‘n tÃ¬m hiá»ƒu vÃ  há»c Ä‘á»ƒ lÃ m má»™t sá»‘ á»©ng dá»¥ng vá» reinforcement learning, mong má»i ngÆ°á»i chia sáº» giÃºp mÃ¬nh má»™t sá»‘ course vá»«a dáº¡y lÃ½ thuyáº¿t vá»«a code theo Ä‘á»ƒ mÃ¬nh thá»±c hÃ nh luÃ´n áº¡, mÃ¬nh cÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u nhiá»u áº¡","ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  newbie, muá»‘n tÃ¬m hiá»ƒu vÃ  há»c Ä‘á»ƒ lÃ m má»™t sá»‘ á»©ng dá»¥ng vá» reinforcement learning, mong má»i ngÆ°á»i chia sáº» giÃºp mÃ¬nh má»™t sá»‘ course vá»«a dáº¡y lÃ½ thuyáº¿t vá»«a code theo Ä‘á»ƒ mÃ¬nh thá»±c hÃ nh luÃ´n áº¡, mÃ¬nh cÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u nhiá»u áº¡",,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t váº¥n Ä‘á» liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t mong má»i ngÆ°á»i giÃºp Ä‘á»¡.
Má»™t nhÃ  Ä‘áº§u tÆ° Ä‘i tham váº¥n hai chuyÃªn gia tÃ i chÃ­nh vá» viá»‡c tÄƒng giáº£m giÃ¡ cá»• phiáº¿u cá»§a cÃ´ng ty S( chá»‰ cáº§n biáº¿t tÄƒng hay giáº£m). ChuyÃªn gia thá»© nháº¥t vá»›i xÃ¡c suáº¥t dá»± Ä‘oÃ¡n Ä‘Ãºng lÃ  60%, cho má»™t quyáº¿t Ä‘á»‹nh nhÆ°ng khÃ´ng cho ngÆ°á»i Ä‘á»c biáº¿t. Láº¡i tiáº¿p tá»¥c gá»i giÃ¡o sÆ°, giÃ¡o sÆ° cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n Ä‘Ãºng lÃªn Ä‘áº¿n 90% trong nhá»¯ng láº§n trÆ°á»›c Ä‘Ã³, vÃ  láº§n nÃ y cho káº¿t quáº£ giá»‘ng anh chuyÃªn gia. NhÃ  Ä‘áº§u tÆ° tháº¯c máº¯c khÃ´ng biáº¿t kháº£ nÄƒng 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng lÃ  bao nhiÃªu pháº§n trÄƒm?
Theo suy nghÄ© cá»§a em thÃ¬ Ä‘Ã¢y lÃ  bÃ i toÃ¡n xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n vÃ¬ Ä‘á» bÃ i lÃ  2 ngÆ°á»i Ä‘Ã£ cÃ³ cÃ¹ng 1 káº¿t quáº£ dá»± Ä‘oÃ¡n trÆ°á»›c Ä‘Ã³, váº­y nÃªn hai ngÆ°á»i cÃ¹ng Ä‘Ãºng hoáº·c cÃ¹ng sai, khÃ´ng cÃ³ th ngÆ°á»i 1 Ä‘Ãºng mÃ  ngÆ°á»i 2 sai. Váº­y nÃªn xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng:
(xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng) / (xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng + xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n sai)
= (0.9*0.6)/(0.9*0.6 + 0.1*0.4)
= 93.1%
KhÃ´ng biáº¿t lÃ  cÃ¡ch lÃ­ giáº£i nhÆ° váº­y cÃ³ há»£p lÃ­ khÃ´ng? mong má»i ngÆ°á»i cho Ã½ kiáº¿n. Em cáº£m Æ¡n mn.","ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t váº¥n Ä‘á» liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t mong má»i ngÆ°á»i giÃºp Ä‘á»¡. Má»™t nhÃ  Ä‘áº§u tÆ° Ä‘i tham váº¥n hai chuyÃªn gia tÃ i chÃ­nh vá» viá»‡c tÄƒng giáº£m giÃ¡ cá»• phiáº¿u cá»§a cÃ´ng ty S( chá»‰ cáº§n biáº¿t tÄƒng hay giáº£m). ChuyÃªn gia thá»© nháº¥t vá»›i xÃ¡c suáº¥t dá»± Ä‘oÃ¡n Ä‘Ãºng lÃ  60%, cho má»™t quyáº¿t Ä‘á»‹nh nhÆ°ng khÃ´ng cho ngÆ°á»i Ä‘á»c biáº¿t. Láº¡i tiáº¿p tá»¥c gá»i giÃ¡o sÆ°, giÃ¡o sÆ° cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n Ä‘Ãºng lÃªn Ä‘áº¿n 90% trong nhá»¯ng láº§n trÆ°á»›c Ä‘Ã³, vÃ  láº§n nÃ y cho káº¿t quáº£ giá»‘ng anh chuyÃªn gia. NhÃ  Ä‘áº§u tÆ° tháº¯c máº¯c khÃ´ng biáº¿t kháº£ nÄƒng 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng lÃ  bao nhiÃªu pháº§n trÄƒm? Theo suy nghÄ© cá»§a em thÃ¬ Ä‘Ã¢y lÃ  bÃ i toÃ¡n xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n vÃ¬ Ä‘á» bÃ i lÃ  2 ngÆ°á»i Ä‘Ã£ cÃ³ cÃ¹ng 1 káº¿t quáº£ dá»± Ä‘oÃ¡n trÆ°á»›c Ä‘Ã³, váº­y nÃªn hai ngÆ°á»i cÃ¹ng Ä‘Ãºng hoáº·c cÃ¹ng sai, khÃ´ng cÃ³ th ngÆ°á»i 1 Ä‘Ãºng mÃ  ngÆ°á»i 2 sai. Váº­y nÃªn xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng: (xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng) / (xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n Ä‘Ãºng + xÃ¡c suáº¥t 2 ngÆ°á»i cÃ¹ng dá»± Ä‘oÃ¡n sai) = (0.9*0.6)/(0.9*0.6 + 0.1*0.4) = 93.1% KhÃ´ng biáº¿t lÃ  cÃ¡ch lÃ­ giáº£i nhÆ° váº­y cÃ³ há»£p lÃ­ khÃ´ng? mong má»i ngÆ°á»i cho Ã½ kiáº¿n. Em cáº£m Æ¡n mn.",,,"#Q&A, #math",,
"Ná»™i quy Forum:
1. NgÃ´n ngá»¯ trong Forum Báº®T BUá»˜C lÃ  tiáº¿ng Viá»‡t cÃ³ dáº¥u hoáº·c tiáº¿ng Anh.
2. TÃ¬m kiáº¿m trÆ°á»›c khi Ä‘áº·t cÃ¢u há»i. CÃ³ thá»ƒ tÃ¬m kiáº¿m tá»« cÃ¡c nguá»“n khÃ¡c hoáº·c trong Forum, cá»™t bÃªn trÃ¡i cÃ³ box ""Search this group"", cá»™t bÃªn pháº£i cÃ³ cÃ¡c topics khÃ¡c nhau.
3. Suy nghÄ© ká»¹ trÆ°á»›c khi há»i. Cá»‘ gáº¯ng diá»…n Ä‘áº¡t cÃ¢u há»i má»™t cÃ¡ch máº¡ch láº¡c Ä‘á»ƒ ngÆ°á»i Ä‘á»c cÃ³ thá»ƒ hiá»ƒu báº¡n há»i gÃ¬.
4. Khi post bÃ i, báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch sá»­ dá»¥ng hashtags. Má»™t sá»‘ hashtags thÃ´ng dá»¥ng: #python, #tensorfow, #caffe, #objectdetection, #nlp, #jupyter_notebook,... Báº¡n cÅ©ng cÃ³ thá»ƒ add topics cho má»—i cÃ¢u há»i.
5. Vá»›i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n code, báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch debug trÆ°á»›c khi há»i (náº¿u báº¡n khÃ´ng biáº¿t debug lÃ  gÃ¬, vui lÃ²ng xem láº¡i Äiá»u 2). Khi há»i cáº§n Ä‘Æ°a code, error vÃ  dÃ²ng lá»‡nh xáº£y ra error Ä‘Ã³. KÃ¨m theo Ä‘Ã³ lÃ  viá»‡c báº¡n Ä‘Ã£ thá»­ cÃ¡c giáº£i phÃ¡p nÃ o vÃ  cÃ¡c lá»—i Ä‘i kÃ¨m.
6. Code nÃªn Ä‘Æ°á»£c Ä‘Æ°a lÃªn cÃ¡c trang cho phÃ©p xem code online vá»›i highlight cho tá»«ng loáº¡i ngÃ´n ngá»¯. Má»™t vÃ i vÃ­ dá»¥: github, ideone, ...
7. CÃ¡c thÃ nh viÃªn trong Forum cáº§n tÃ´n trá»ng láº«n nhau, sá»­ dá»¥ng ngÃ´n ngá»¯ lá»‹ch sá»±, chuáº©n má»±c. ThÃ nh viÃªn sá»­ dá»¥ng ngÃ´n ngá»¯ báº¥t lá»‹ch sá»±, thiáº¿u tÃ´n trá»ng ngÆ°á»i khÃ¡c sáº½ bá»‹ xoÃ¡ vÄ©nh viá»…n khá»i Forum.
8. CÃ¡c comment spam sáº½ bá»‹ xoÃ¡ vÃ  thÃ nh viÃªn sáº½ bá»‹ xoÃ¡ khá»i group. Comment chá»‰ cÃ³ cÃ¡c dáº¥u cháº¥m (.) sáº½ bá»‹ coi lÃ  spam. Náº¿u báº¡n muá»‘n follow má»™t post, báº¡n cÃ³ thá»ƒ chá»n cháº¿ Ä‘á»™ ""Turn on notifications for this post"".
9. CÃ¡c post khÃ´ng Ä‘Æ°á»£c approve cÃ³ thá»ƒ do má»™t trong cÃ¡c lÃ½ do:
* spam,
* cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n Forum,
* diá»…n Ä‘áº¡t khÃ³ hiá»ƒu (ká»ƒ cáº£ viá»‡c viáº¿t tiáº¿ng Viá»‡t khÃ´ng dáº¥u)
* cÃ¢u há»i láº·p
* cÃ¡c ná»™i dung vi pháº¡m báº£n quyá»n.
10. Admins cÃ³ thá»ƒ xoÃ¡ báº¥t cá»© bÃ i hoáº·c bÃ¬nh luáº­n nÃ o mÃ  khÃ´ng cáº§n giáº£i thÃ­ch. CÃ¡c bÃ i/bÃ¬nh luáº­n bá»‹ 3 report trá»Ÿ lÃªn cÅ©ng sáº½ bá»‹ xoÃ¡.
-------------------------
Tiáº¿p tá»¥c cáº­p nháº­t. Má»i cÃ¡c báº¡n bá»• sung.","Ná»™i quy Forum: 1. NgÃ´n ngá»¯ trong Forum Báº®T BUá»˜C lÃ  tiáº¿ng Viá»‡t cÃ³ dáº¥u hoáº·c tiáº¿ng Anh. 2. TÃ¬m kiáº¿m trÆ°á»›c khi Ä‘áº·t cÃ¢u há»i. CÃ³ thá»ƒ tÃ¬m kiáº¿m tá»« cÃ¡c nguá»“n khÃ¡c hoáº·c trong Forum, cá»™t bÃªn trÃ¡i cÃ³ box ""Search this group"", cá»™t bÃªn pháº£i cÃ³ cÃ¡c topics khÃ¡c nhau. 3. Suy nghÄ© ká»¹ trÆ°á»›c khi há»i. Cá»‘ gáº¯ng diá»…n Ä‘áº¡t cÃ¢u há»i má»™t cÃ¡ch máº¡ch láº¡c Ä‘á»ƒ ngÆ°á»i Ä‘á»c cÃ³ thá»ƒ hiá»ƒu báº¡n há»i gÃ¬. 4. Khi post bÃ i, báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch sá»­ dá»¥ng hashtags. Má»™t sá»‘ hashtags thÃ´ng dá»¥ng: Báº¡n cÅ©ng cÃ³ thá»ƒ add topics cho má»—i cÃ¢u há»i. 5. Vá»›i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n code, báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch debug trÆ°á»›c khi há»i (náº¿u báº¡n khÃ´ng biáº¿t debug lÃ  gÃ¬, vui lÃ²ng xem láº¡i Äiá»u 2). Khi há»i cáº§n Ä‘Æ°a code, error vÃ  dÃ²ng lá»‡nh xáº£y ra error Ä‘Ã³. KÃ¨m theo Ä‘Ã³ lÃ  viá»‡c báº¡n Ä‘Ã£ thá»­ cÃ¡c giáº£i phÃ¡p nÃ o vÃ  cÃ¡c lá»—i Ä‘i kÃ¨m. 6. Code nÃªn Ä‘Æ°á»£c Ä‘Æ°a lÃªn cÃ¡c trang cho phÃ©p xem code online vá»›i highlight cho tá»«ng loáº¡i ngÃ´n ngá»¯. Má»™t vÃ i vÃ­ dá»¥: github, ideone, ... 7. CÃ¡c thÃ nh viÃªn trong Forum cáº§n tÃ´n trá»ng láº«n nhau, sá»­ dá»¥ng ngÃ´n ngá»¯ lá»‹ch sá»±, chuáº©n má»±c. ThÃ nh viÃªn sá»­ dá»¥ng ngÃ´n ngá»¯ báº¥t lá»‹ch sá»±, thiáº¿u tÃ´n trá»ng ngÆ°á»i khÃ¡c sáº½ bá»‹ xoÃ¡ vÄ©nh viá»…n khá»i Forum. 8. CÃ¡c comment spam sáº½ bá»‹ xoÃ¡ vÃ  thÃ nh viÃªn sáº½ bá»‹ xoÃ¡ khá»i group. Comment chá»‰ cÃ³ cÃ¡c dáº¥u cháº¥m (.) sáº½ bá»‹ coi lÃ  spam. Náº¿u báº¡n muá»‘n follow má»™t post, báº¡n cÃ³ thá»ƒ chá»n cháº¿ Ä‘á»™ ""Turn on notifications for this post"". 9. CÃ¡c post khÃ´ng Ä‘Æ°á»£c approve cÃ³ thá»ƒ do má»™t trong cÃ¡c lÃ½ do: * spam, * cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n Forum, * diá»…n Ä‘áº¡t khÃ³ hiá»ƒu (ká»ƒ cáº£ viá»‡c viáº¿t tiáº¿ng Viá»‡t khÃ´ng dáº¥u) * cÃ¢u há»i láº·p * cÃ¡c ná»™i dung vi pháº¡m báº£n quyá»n. 10. Admins cÃ³ thá»ƒ xoÃ¡ báº¥t cá»© bÃ i hoáº·c bÃ¬nh luáº­n nÃ o mÃ  khÃ´ng cáº§n giáº£i thÃ­ch. CÃ¡c bÃ i/bÃ¬nh luáº­n bá»‹ 3 report trá»Ÿ lÃªn cÅ©ng sáº½ bá»‹ xoÃ¡. ------------------------- Tiáº¿p tá»¥c cáº­p nháº­t. Má»i cÃ¡c báº¡n bá»• sung.","#python,	#tensorfow,	#caffe,	#objectdetection,	#nlp,	#jupyter_notebook,...",,,,
"[Thá»‘ng kÃª - CheatSheet CS106]
Thá»‘ng kÃª lÃ  má»™t bá»™ mÃ´n khoa há»c lÃ¢u Ä‘á»i vÃ  cÃ³ tÃ­nh á»©ng dá»¥ng cao. Dá»±a trÃªn thá»‘ng kÃª chÃºng ta cÃ³ thá»ƒ Ä‘Æ°a ra dá»± bÃ¡o vá» biÃªn Ä‘á»™ giao Ä‘á»™ng cá»§a nhiá»‡t Ä‘á»™, Ä‘á»™ áº©m, lÆ°á»£ng mÆ°a, giÃ¡ cáº£ cá»§a cÃ¡c hÃ ng hoÃ¡, giÃ¡ chá»©ng khoÃ¡n, â€¦ kÃ¨m theo Ä‘á»™ tin cáº­y xÃ¡c Ä‘á»‹nh.
Äá»“ng thá»i dá»±a vÃ o thá»‘ng kÃª chÃºng ta cÅ©ng cÃ³ cÆ¡ sá»Ÿ Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cháº¥p nháº­n hay bÃ¡c bá» nhá»¯ng giáº£ thuyáº¿t ráº¥t thiáº¿t thá»±c trong cuá»™c sá»‘ng nhÆ°: Trung bÃ¬nh chiá»u cao cá»§a ngÆ°á»i Viá»‡t Nam lÃ  1m65? GiÃ¡ chung cÆ° táº¡i HÃ  Ná»™i cao hÆ¡n so vá»›i HCM? Thu nháº­p bÃ¬nh quÃ¢n Ä‘áº§u ngÆ°á»i cá»§a Viá»‡t Nam sáº½ trÃªn 2500$ vÃ o nÄƒm sau?
Hiá»ƒu Ä‘Æ°á»£c cÃ¡c qui luáº­t thá»‘ng kÃª vÃ  biáº¿t cÃ¡ch Ã¡p dá»¥ng chÃºng sáº½ giÃºp báº¡n Ä‘Æ°a ra Ä‘Æ°á»£c nhiá»u káº¿t luáº­n thÃº vá»‹ vÃ  lÃ m cá»§ng cá»‘ thÃªm sá»± cháº¯c cháº¯n cho viá»‡c ra quyáº¿t Ä‘á»‹nh.
ÄÃ¢y lÃ  cheat sheet cá»§a khoÃ¡ há»c cs106 cung cáº¥p má»™t sá»‘ kiáº¿n thá»©c ná»n quan trá»ng vá» thá»‘ng kÃª:
- KhÃ¡i niá»‡m vá» biáº¿n ngáº«u nhiÃªn, Æ°á»›c lÆ°á»£ng tham sá»‘, Ä‘á»™ chá»‡ch Æ°á»›c lÆ°á»£ng.
- Æ¯á»›c lÆ°á»£ng trung bÃ¬nh, phÆ°Æ¡ng sai,
- Æ¯á»›c lÆ°á»£ng khoáº£ng tin cáº­y: chÆ°a biáº¿t vÃ  Ä‘Ã£ biáº¿t phÆ°Æ¡ng sai tá»•ng thá»ƒ.
- Hai loáº¡i máº¯c sai láº§m: loáº¡i 1 (false alarm) vÃ  loáº¡i 2 (miss alarm)
- P-value vÃ  kiá»ƒm Ä‘á»‹nh phi tham sá»‘.
- CÃ¡c kiá»ƒm Ä‘á»‹nh má»™t phÃ­a, hai phÃ­a.
- Kiá»ƒm Ä‘á»‹nh sai sá»‘ giá»¯a hai trung bÃ¬nh máº«u
- Kiá»ƒm Ä‘á»‹nh Ä‘á»™ phÃ¹ há»£p phÃ¢n phá»‘i.
- Kiá»ƒm Ä‘á»‹nh dáº¥u vÃ  kiá»ƒm Ä‘á»‹nh xu hÆ°á»›ng.
- Æ¯á»›c lÆ°á»£ng OLS vÃ  khoáº£ng tin cáº­y cá»§a cÃ¡c tham sá»‘ Æ°á»›c lÆ°á»£ng.
Link:
https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics","[Thá»‘ng kÃª - CheatSheet CS106] Thá»‘ng kÃª lÃ  má»™t bá»™ mÃ´n khoa há»c lÃ¢u Ä‘á»i vÃ  cÃ³ tÃ­nh á»©ng dá»¥ng cao. Dá»±a trÃªn thá»‘ng kÃª chÃºng ta cÃ³ thá»ƒ Ä‘Æ°a ra dá»± bÃ¡o vá» biÃªn Ä‘á»™ giao Ä‘á»™ng cá»§a nhiá»‡t Ä‘á»™, Ä‘á»™ áº©m, lÆ°á»£ng mÆ°a, giÃ¡ cáº£ cá»§a cÃ¡c hÃ ng hoÃ¡, giÃ¡ chá»©ng khoÃ¡n, â€¦ kÃ¨m theo Ä‘á»™ tin cáº­y xÃ¡c Ä‘á»‹nh. Äá»“ng thá»i dá»±a vÃ o thá»‘ng kÃª chÃºng ta cÅ©ng cÃ³ cÆ¡ sá»Ÿ Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cháº¥p nháº­n hay bÃ¡c bá» nhá»¯ng giáº£ thuyáº¿t ráº¥t thiáº¿t thá»±c trong cuá»™c sá»‘ng nhÆ°: Trung bÃ¬nh chiá»u cao cá»§a ngÆ°á»i Viá»‡t Nam lÃ  1m65? GiÃ¡ chung cÆ° táº¡i HÃ  Ná»™i cao hÆ¡n so vá»›i HCM? Thu nháº­p bÃ¬nh quÃ¢n Ä‘áº§u ngÆ°á»i cá»§a Viá»‡t Nam sáº½ trÃªn 2500$ vÃ o nÄƒm sau? Hiá»ƒu Ä‘Æ°á»£c cÃ¡c qui luáº­t thá»‘ng kÃª vÃ  biáº¿t cÃ¡ch Ã¡p dá»¥ng chÃºng sáº½ giÃºp báº¡n Ä‘Æ°a ra Ä‘Æ°á»£c nhiá»u káº¿t luáº­n thÃº vá»‹ vÃ  lÃ m cá»§ng cá»‘ thÃªm sá»± cháº¯c cháº¯n cho viá»‡c ra quyáº¿t Ä‘á»‹nh. ÄÃ¢y lÃ  cheat sheet cá»§a khoÃ¡ há»c cs106 cung cáº¥p má»™t sá»‘ kiáº¿n thá»©c ná»n quan trá»ng vá» thá»‘ng kÃª: - KhÃ¡i niá»‡m vá» biáº¿n ngáº«u nhiÃªn, Æ°á»›c lÆ°á»£ng tham sá»‘, Ä‘á»™ chá»‡ch Æ°á»›c lÆ°á»£ng. - Æ¯á»›c lÆ°á»£ng trung bÃ¬nh, phÆ°Æ¡ng sai, - Æ¯á»›c lÆ°á»£ng khoáº£ng tin cáº­y: chÆ°a biáº¿t vÃ  Ä‘Ã£ biáº¿t phÆ°Æ¡ng sai tá»•ng thá»ƒ. - Hai loáº¡i máº¯c sai láº§m: loáº¡i 1 (false alarm) vÃ  loáº¡i 2 (miss alarm) - P-value vÃ  kiá»ƒm Ä‘á»‹nh phi tham sá»‘. - CÃ¡c kiá»ƒm Ä‘á»‹nh má»™t phÃ­a, hai phÃ­a. - Kiá»ƒm Ä‘á»‹nh sai sá»‘ giá»¯a hai trung bÃ¬nh máº«u - Kiá»ƒm Ä‘á»‹nh Ä‘á»™ phÃ¹ há»£p phÃ¢n phá»‘i. - Kiá»ƒm Ä‘á»‹nh dáº¥u vÃ  kiá»ƒm Ä‘á»‹nh xu hÆ°á»›ng. - Æ¯á»›c lÆ°á»£ng OLS vÃ  khoáº£ng tin cáº­y cá»§a cÃ¡c tham sá»‘ Æ°á»›c lÆ°á»£ng. Link: https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics",,,"#sharing, #math",,
"[AI Share]
Tá»•ng há»£p má»™t sá»‘ tool Ä‘á»ƒ thiáº¿t káº¿ vÃ  visualize kiáº¿n trÃºc máº¡ng Neural Network
1. ğ‘·ğ’ğ’ğ’•ğ‘µğ’†ğ’–ğ’“ğ’‚ğ’ğ‘µğ’†ğ’• : sá»­ dá»¥ng latex Ä‘á»ƒ váº½ máº¡ng neural network cho paper, slide...
Github: https://github.com/HarisIqbal88/PlotNeuralNet
Demo FCN-32 : https://www.overleaf.com/project/5ee51458e88684000165e8be
Demo Holistically-Nested Edge Detection: https://www.overleaf.com/project/5ee51033e88684000165e37c
2. ğ’ğ’†ğ’•2ğ’—ğ’Šğ’” : visualize kiáº¿n trÃºc neural network tá»« model Keras
Github: https://github.com/viscom-ulm/Net2Vis
Demo á»Ÿ Ä‘Ã¢y: https://viscom.net2vis.uni-ulm.de/
3. ğ’—ğ’Šğ’”ğ’–ğ’‚ğ’ğ’Œğ’†ğ’“ğ’‚ğ’” lÃ  má»™t package cá»§a Python Ä‘á»ƒ visualize kiáº¿n trÃºc máº¡ng neural network tá»« model Keras.
Github: https://github.com/paulgavrikov/visualkeras/
4. ğ’…ğ’“ğ’‚ğ’˜_ğ’„ğ’ğ’ğ’—ğ’ğ’†ğ’• : visualize máº¡ng Convolution Neural Network
Github: https://github.com/gwding/draw_convnet
5. ğ‘µğ‘µ-ğ‘ºğ‘½ğ‘® : táº¡o cÃ¡c kiáº¿n trÃºc neural network theo cÃ¡c tham sá»‘ nhÆ° sá»‘ lá»›p áº©n, sá»‘ nÆ¡-ron trong má»™t lá»›p, khoáº£ng cÃ¡ch giá»¯a cÃ¡c lá»›p, mÃ u sáº¯c,...
Github: https://github.com/alexlenail/NN-SVG
Demo : http://alexlenail.me/NN-SVG/AlexNet.html
6. ğ‘»ğ’†ğ’ğ’”ğ’ğ’“ğ’ƒğ’ğ’‚ğ’“ğ’… : visualize kiáº¿n trÃºc máº¡ng neural network tá»« Tensorflow graph.
Github: https://github.com/tensorflow/tensorboard
Demo trÃªn colab: https://colab.research.google.com/.../docs/graphs.ipynb
7. ğ‘µğ’†ğ’•ğ’“ğ’ğ’ : Netron giÃºp visualize cÃ¡c kiáº¿n trÃºc máº¡ng phá»©c táº¡p trong Deep Learning , táº¡o ra cÃ¡c hÃ¬nh áº£nh Ä‘áº¹p Ä‘á»ƒ truyá»n Ä‘áº¡t rÃµ rÃ ng kiáº¿n trÃºc cá»§a máº¡ng vÃ  cÃ³ thá»ƒ khÃ¡m phÃ¡ cÃ¡c mÃ´ hÃ¬nh má»™t cÃ¡ch chi tiáº¿t.","[AI Share] Tá»•ng há»£p má»™t sá»‘ tool Ä‘á»ƒ thiáº¿t káº¿ vÃ  visualize kiáº¿n trÃºc máº¡ng Neural Network 1. : sá»­ dá»¥ng latex Ä‘á»ƒ váº½ máº¡ng neural network cho paper, slide... Github: https://github.com/HarisIqbal88/PlotNeuralNet Demo FCN-32 : https://www.overleaf.com/project/5ee51458e88684000165e8be Demo Holistically-Nested Edge Detection: https://www.overleaf.com/project/5ee51033e88684000165e37c 2. 2 : visualize kiáº¿n trÃºc neural network tá»« model Keras Github: https://github.com/viscom-ulm/Net2Vis Demo á»Ÿ Ä‘Ã¢y: https://viscom.net2vis.uni-ulm.de/ 3. lÃ  má»™t package cá»§a Python Ä‘á»ƒ visualize kiáº¿n trÃºc máº¡ng neural network tá»« model Keras. Github: https://github.com/paulgavrikov/visualkeras/ 4. _ : visualize máº¡ng Convolution Neural Network Github: https://github.com/gwding/draw_convnet 5. - : táº¡o cÃ¡c kiáº¿n trÃºc neural network theo cÃ¡c tham sá»‘ nhÆ° sá»‘ lá»›p áº©n, sá»‘ nÆ¡-ron trong má»™t lá»›p, khoáº£ng cÃ¡ch giá»¯a cÃ¡c lá»›p, mÃ u sáº¯c,... Github: https://github.com/alexlenail/NN-SVG Demo : http://alexlenail.me/NN-SVG/AlexNet.html 6. : visualize kiáº¿n trÃºc máº¡ng neural network tá»« Tensorflow graph. Github: https://github.com/tensorflow/tensorboard Demo trÃªn colab: https://colab.research.google.com/.../docs/graphs.ipynb 7. : Netron giÃºp visualize cÃ¡c kiáº¿n trÃºc máº¡ng phá»©c táº¡p trong Deep Learning , táº¡o ra cÃ¡c hÃ¬nh áº£nh Ä‘áº¹p Ä‘á»ƒ truyá»n Ä‘áº¡t rÃµ rÃ ng kiáº¿n trÃºc cá»§a máº¡ng vÃ  cÃ³ thá»ƒ khÃ¡m phÃ¡ cÃ¡c mÃ´ hÃ¬nh má»™t cÃ¡ch chi tiáº¿t.",,,,,
"Xin chÃ o mn,
Mn cho mÃ¬nh há»i, mÃ¬nh cÃ³ 1 Ä‘oáº¡n Ã¢m thanh Ä‘á»c cÃ¡c sá»‘ tá»« 1 Ä‘áº¿n 9, khi Ä‘á»c xong 1 sá»‘ mÃ¬nh sáº½ nghá»‰ khoáº£ng 1s. MÃ¬nh muá»‘n dÃ¹ng Matlab Ä‘á»ƒ cáº¯t tá»« Ä‘oáº¡n Ã¢m thanh nÃ y ra tá»«ng file Ã¢m thanh nhá» cá»§a tá»«ng sá»‘. Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ thá»­ dÃ¹ng so sÃ¡nh ngÆ°á»¡ng nÄƒng lÆ°á»£ng nhÆ°ng váº«n chÆ°a cáº¯t Ä‘Æ°á»£c, nÃ³ chá»‰ plot Ä‘Æ°á»£c vÃ¹ng nÃ o cÃ³ voice vÃ¹ng nÃ o khÃ´ng.
Mn cho mÃ¬nh há»i giáº£i thuáº­t nÃ o Ä‘Æ¡n giáº£n Ä‘á»ƒ dÃ¹ng cho bÃ i toÃ¡n nÃ y áº¡
Xin cáº£m Æ¡n mn","Xin chÃ o mn, Mn cho mÃ¬nh há»i, mÃ¬nh cÃ³ 1 Ä‘oáº¡n Ã¢m thanh Ä‘á»c cÃ¡c sá»‘ tá»« 1 Ä‘áº¿n 9, khi Ä‘á»c xong 1 sá»‘ mÃ¬nh sáº½ nghá»‰ khoáº£ng 1s. MÃ¬nh muá»‘n dÃ¹ng Matlab Ä‘á»ƒ cáº¯t tá»« Ä‘oáº¡n Ã¢m thanh nÃ y ra tá»«ng file Ã¢m thanh nhá» cá»§a tá»«ng sá»‘. Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ thá»­ dÃ¹ng so sÃ¡nh ngÆ°á»¡ng nÄƒng lÆ°á»£ng nhÆ°ng váº«n chÆ°a cáº¯t Ä‘Æ°á»£c, nÃ³ chá»‰ plot Ä‘Æ°á»£c vÃ¹ng nÃ o cÃ³ voice vÃ¹ng nÃ o khÃ´ng. Mn cho mÃ¬nh há»i giáº£i thuáº­t nÃ o Ä‘Æ¡n giáº£n Ä‘á»ƒ dÃ¹ng cho bÃ i toÃ¡n nÃ y áº¡ Xin cáº£m Æ¡n mn",,,,,
"Mn cho em há»i, táº¡i sau Ma tráº­n hiá»‡p phÆ°Æ¡ng sai cáº§n pháº£i giá»‘ng nhau vÃ  lÃ  ma tráº­n Ä‘Æ¡n vá»‹ áº¡. VÃ  táº¡i sau ""cov"" lÃ  ma tráº­n Ä‘Æ¡n vá»‹ 2 hÃ ng, 2 cá»™t mÃ  khÃ´ng pháº£i 3 hÃ ng, 3 cá»™t hoáº·c hÆ¡n áº¡. Em cáº£m Æ¡n mn nhiá»u.","Mn cho em há»i, táº¡i sau Ma tráº­n hiá»‡p phÆ°Æ¡ng sai cáº§n pháº£i giá»‘ng nhau vÃ  lÃ  ma tráº­n Ä‘Æ¡n vá»‹ áº¡. VÃ  táº¡i sau ""cov"" lÃ  ma tráº­n Ä‘Æ¡n vá»‹ 2 hÃ ng, 2 cá»™t mÃ  khÃ´ng pháº£i 3 hÃ ng, 3 cá»™t hoáº·c hÆ¡n áº¡. Em cáº£m Æ¡n mn nhiá»u.",,,"#Q&A, #math",,
"Má»i ngÆ°á»i Æ¡i cho em há»i chÃºt áº¡.
Má»i ngÆ°á»i cÃ³ biáº¿t dataset áº£nh nÃ o vá» thá»i tiáº¿t ko áº¡? Kiá»ƒu foggy sunny snow cloudy rain etc Ã½ áº¡. Má»™t cÃ¡i vÃ­ dá»¥ vá» áº£nh snow nhÆ° trong hÃ¬nh áº¡. Ko quan tÃ¢m bá»‘i cáº£nh nhÆ° tháº¿ nÃ o láº¯m chá»‰ quan tÃ¢m thá»i tiáº¿t nhÆ° tháº¿ nÃ o thÃ´i áº¡.
Em Ä‘ang lÃ m final project cá»§a lá»›p ML vá» weather classification vÃ  em Ä‘ang cá»‘ tÃ¬m thÃªm data áº£nh Ä‘á»ƒ nhÃ©t vÃ´ model áº¡.
Náº¿u cÃ³ ai biáº¿t thÃªm dataset nÃ o á»•n thÃ¬ chá»‰ em vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i!!",Má»i ngÆ°á»i Æ¡i cho em há»i chÃºt áº¡. Má»i ngÆ°á»i cÃ³ biáº¿t dataset áº£nh nÃ o vá» thá»i tiáº¿t ko áº¡? Kiá»ƒu foggy sunny snow cloudy rain etc Ã½ áº¡. Má»™t cÃ¡i vÃ­ dá»¥ vá» áº£nh snow nhÆ° trong hÃ¬nh áº¡. Ko quan tÃ¢m bá»‘i cáº£nh nhÆ° tháº¿ nÃ o láº¯m chá»‰ quan tÃ¢m thá»i tiáº¿t nhÆ° tháº¿ nÃ o thÃ´i áº¡. Em Ä‘ang lÃ m final project cá»§a lá»›p ML vá» weather classification vÃ  em Ä‘ang cá»‘ tÃ¬m thÃªm data áº£nh Ä‘á»ƒ nhÃ©t vÃ´ model áº¡. Náº¿u cÃ³ ai biáº¿t thÃªm dataset nÃ o á»•n thÃ¬ chá»‰ em vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i!!,,,,,
"A/c cho e há»i cÃ³ tool nÃ o annotate image segmentation mÃ  cÃ³ model há»— trá»£ predict annotation sáºµn, mÃ¬nh chá»‰ vÃ o chá»‰nh láº¡i thÃ´i ko áº¡?","A/c cho e há»i cÃ³ tool nÃ o annotate image segmentation mÃ  cÃ³ model há»— trá»£ predict annotation sáºµn, mÃ¬nh chá»‰ vÃ o chá»‰nh láº¡i thÃ´i ko áº¡?",,,,,
"MÃ¬nh Ä‘ang cÃ³ chÃºt váº¥n Ä‘á» vá»›i hÃ m np.linalg.svd, hÃ m nÃ y tÃ­nh gÃ­a trá»‹ riÃªng cá»§a ma tráº­n. TrÃªn python thÆ° viá»‡n numpy cháº¡y hÃ m trÃªn vá»›i full core cá»§a mÃ¡y nhÆ°ng á»Ÿ c++ hay java thÃ¬ nÃ³ láº¡i chá»‰ cháº¡y trÃªn 1 core, thÃ nh ra vá»›i ma tráº­n 1000x1000 python háº¿t cÃ³ 0.456s thÃ¬ trÃªn c++ hay java Ä‘á»u máº¥t Ä‘áº¿n 3s. MÃŒnh thá»­ cáº£ opencv, numcpp hay eigen Ä‘á»u chá»‰ cháº¡y trÃªn 1 core, cÃ³ b nÃ o biáº¿t library nÃ o cháº¡y full core Ä‘á»ƒ tá»‘i Æ°u performance hoáº·c giáº£i thuáº­t nÃ o cÃ³ thá»ƒ implement láº¡i Ä‘Æ°á»£c ko áº¡?","MÃ¬nh Ä‘ang cÃ³ chÃºt váº¥n Ä‘á» vá»›i hÃ m np.linalg.svd, hÃ m nÃ y tÃ­nh gÃ­a trá»‹ riÃªng cá»§a ma tráº­n. TrÃªn python thÆ° viá»‡n numpy cháº¡y hÃ m trÃªn vá»›i full core cá»§a mÃ¡y nhÆ°ng á»Ÿ c++ hay java thÃ¬ nÃ³ láº¡i chá»‰ cháº¡y trÃªn 1 core, thÃ nh ra vá»›i ma tráº­n 1000x1000 python háº¿t cÃ³ 0.456s thÃ¬ trÃªn c++ hay java Ä‘á»u máº¥t Ä‘áº¿n 3s. MÃŒnh thá»­ cáº£ opencv, numcpp hay eigen Ä‘á»u chá»‰ cháº¡y trÃªn 1 core, cÃ³ b nÃ o biáº¿t library nÃ o cháº¡y full core Ä‘á»ƒ tá»‘i Æ°u performance hoáº·c giáº£i thuáº­t nÃ o cÃ³ thá»ƒ implement láº¡i Ä‘Æ°á»£c ko áº¡?",,,,,
"Google Research Ä‘ang má»Ÿ Ä‘Æ¡n PhD Fellowship cho nhiá»u khu vá»±c, trong Ä‘Ã³ cÃ³ cÃ¡c trÆ°á»ng táº¡i ÄÃ´ng Nam Ã. CÃ¡c báº¡n Ä‘Æ°á»£c nháº­n vÃ o chÆ°Æ¡ng trÃ¬nh sáº½ Ä‘Æ°á»£c há»— trá»£ tÃ i chÃ­nh tá»‘i Ä‘a 3 nÄƒm, cÃ³ mentor tá»« Google Research, vÃ  cÃ³ cÆ¡ há»™i thá»±c táº­p táº¡i Google Research náº¿u phá»ng váº¥n tá»‘t. Háº¡n ná»™p Ä‘Æ¡n: 11:59 PM UTC on Thursday, 22nd April 2021.
ThÃ´ng tin vá» chÆ°Æ¡ng trÃ¬nh: https://research.google/outreach/phd-fellowship/
ÄÆ¡n dÃ nh cho trÆ°á»ng táº¡i ÄÃ´ng Nam Ã (cÃ³ thá»ƒ truy cáº­p tá»« link bÃªn trÃªn): https://cseduapplication.withgoogle.com/applications/phdfellowshipsea2021/create-application/edit","Google Research Ä‘ang má»Ÿ Ä‘Æ¡n PhD Fellowship cho nhiá»u khu vá»±c, trong Ä‘Ã³ cÃ³ cÃ¡c trÆ°á»ng táº¡i ÄÃ´ng Nam Ã. CÃ¡c báº¡n Ä‘Æ°á»£c nháº­n vÃ o chÆ°Æ¡ng trÃ¬nh sáº½ Ä‘Æ°á»£c há»— trá»£ tÃ i chÃ­nh tá»‘i Ä‘a 3 nÄƒm, cÃ³ mentor tá»« Google Research, vÃ  cÃ³ cÆ¡ há»™i thá»±c táº­p táº¡i Google Research náº¿u phá»ng váº¥n tá»‘t. Háº¡n ná»™p Ä‘Æ¡n: 11:59 PM UTC on Thursday, 22nd April 2021. ThÃ´ng tin vá» chÆ°Æ¡ng trÃ¬nh: https://research.google/outreach/phd-fellowship/ ÄÆ¡n dÃ nh cho trÆ°á»ng táº¡i ÄÃ´ng Nam Ã (cÃ³ thá»ƒ truy cáº­p tá»« link bÃªn trÃªn): https://cseduapplication.withgoogle.com/applications/phdfellowshipsea2021/create-application/edit",,,,,
Mn cho em há»i Ä‘áº¡o hÃ m nhÆ° tháº¿ nÃ o Ä‘á»ƒ ra Ä‘Æ°á»£c nhÆ° váº­y áº¡. Em Ä‘Ã£ xem nhá»¯ng Ä‘áº¡o hÃ m thÆ°á»ng gáº·p cá»§a anh Tiá»‡p nhÆ°ng váº«n ko hiá»ƒu. Em cáº£m Æ¡n mn nhiá»u.,Mn cho em há»i Ä‘áº¡o hÃ m nhÆ° tháº¿ nÃ o Ä‘á»ƒ ra Ä‘Æ°á»£c nhÆ° váº­y áº¡. Em Ä‘Ã£ xem nhá»¯ng Ä‘áº¡o hÃ m thÆ°á»ng gáº·p cá»§a anh Tiá»‡p nhÆ°ng váº«n ko hiá»ƒu. Em cáº£m Æ¡n mn nhiá»u.,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, dáº¡o nÃ y em Ä‘ang nghiÃªn cá»©u Retinanet (á»Ÿ má»©c Ä‘á»™ á»©ng dá»¥ng) nháº±m kháº¯c phá»¥c viá»‡c YOLO detect small object kÃ©m quÃ¡ vÃ  tiá»‡n nghiÃªn cá»©u luÃ´n bÃ i toÃ¡n nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng Ä‘á»ƒ há»c táº­p.
Em máº¡nh dáº¡n viáº¿t bÃ i chia sáº» Ä‘á»ƒ giÃºp cÃ¡c báº¡n newbie má»›i há»c tham kháº£o cÃ¹ng vÃ  giao lÆ°u cÃ¹ng! Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o vÃ  mong admin duyá»‡t bÃ i áº¡.","KÃ­nh chÃ o cÃ¡c bÃ¡c, dáº¡o nÃ y em Ä‘ang nghiÃªn cá»©u Retinanet (á»Ÿ má»©c Ä‘á»™ á»©ng dá»¥ng) nháº±m kháº¯c phá»¥c viá»‡c YOLO detect small object kÃ©m quÃ¡ vÃ  tiá»‡n nghiÃªn cá»©u luÃ´n bÃ i toÃ¡n nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng Ä‘á»ƒ há»c táº­p. Em máº¡nh dáº¡n viáº¿t bÃ i chia sáº» Ä‘á»ƒ giÃºp cÃ¡c báº¡n newbie má»›i há»c tham kháº£o cÃ¹ng vÃ  giao lÆ°u cÃ¹ng! Mong cÃ¡c bÃ¡c chá»‰ giÃ¡o vÃ  mong admin duyá»‡t bÃ i áº¡.",,,,,
MÃ¬nh cÃ³ thÃ´ng tin : Vinuni Ä‘ang tuyá»ƒn vá»‹ trÃ­ research assistant gá»­i cÃ¡c báº¡n quan tÃ¢m .,MÃ¬nh cÃ³ thÃ´ng tin : Vinuni Ä‘ang tuyá»ƒn vá»‹ trÃ­ research assistant gá»­i cÃ¡c báº¡n quan tÃ¢m .,,,,,
"[Series Pytorch]
BÃ i 4: Train Neural Network
BÃ i nÃ y mÃ¬nh hÆ°á»›ng dáº«n má»i ngÆ°á»i train model Neural Network (NN), Convolutional Neural Network (CNN) báº±ng Pytorch.","[Series Pytorch] BÃ i 4: Train Neural Network BÃ i nÃ y mÃ¬nh hÆ°á»›ng dáº«n má»i ngÆ°á»i train model Neural Network (NN), Convolutional Neural Network (CNN) báº±ng Pytorch.",,,,,
"Hi mng, mÃ¬nh Ä‘áº¡ng há»c vá» mÃ´n statistic cÆ¡ báº£n vÃ  cÃ³ cÃ¢u há»i nÃ y cáº§n sá»± trá»£ giÃºp Ä‘áº¯c lá»±c tá»« mng :)","Hi mng, mÃ¬nh Ä‘áº¡ng há»c vá» mÃ´n statistic cÆ¡ báº£n vÃ  cÃ³ cÃ¢u há»i nÃ y cáº§n sá»± trá»£ giÃºp Ä‘áº¯c lá»±c tá»« mng :)",,,"#Q&A, #math",,
"CÃ¡c anh chá»‹ cho em há»i lÃ  táº¡i sao cÃ¡c perceptrons (neurons) trong cÃ¹ng 1 lá»›p Fully Connected Layer khÃ´ng káº¿t ná»‘i vá»›i nhau mÃ  chá»‰ káº¿t ná»‘i vá»›i lá»›p trÆ°á»›c hoáº·c sau Ä‘Ã³?

Em cÃ¡m Æ¡n.",CÃ¡c anh chá»‹ cho em há»i lÃ  táº¡i sao cÃ¡c perceptrons (neurons) trong cÃ¹ng 1 lá»›p Fully Connected Layer khÃ´ng káº¿t ná»‘i vá»›i nhau mÃ  chá»‰ káº¿t ná»‘i vá»›i lá»›p trÆ°á»›c hoáº·c sau Ä‘Ã³? Em cÃ¡m Æ¡n.,,,,,
"Mng Æ¡i, mÃ¬nh Ä‘ang há»c vá» classification predictive model vÃ  cáº§n sá»± trá»£ giÃºp mng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y!!","Mng Æ¡i, mÃ¬nh Ä‘ang há»c vá» classification predictive model vÃ  cáº§n sá»± trá»£ giÃºp mng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y!!",,,,,
"[VinDr Lab] [Open-source data annotation for Medical AI]
Github: https://github.com/vinbigdata-medical/vindr-lab/
â­ï¸ Sau cuá»™c thi VinBigData Chest X-ray Abnormalities Detection trÃªn Kaggle (https://www.kaggle.com/.../vinbigdata-chest-xray.../), phÃ²ng Xá»­ lÃ½ áº£nh y táº¿ - Viá»‡n NghiÃªn cá»©u Dá»¯ liá»‡u lá»›n Vingroup quyáº¿t Ä‘á»‹nh má»Ÿ mÃ£ nguá»“n cá»§a pháº§n má»m VinDr Lab.
â­ï¸ VinDr Lab lÃ  má»™t cÃ´ng cá»¥ gÃ¡n nhÃ£n hÃ¬nh áº£nh DICOM Ä‘ang Ä‘Æ°á»£c team sá»­ dá»¥ng. CÃ¡c tÃ­nh nÄƒng gÃ¡n nhÃ£n, quáº£n lÃ½ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a, phÃ¡t triá»ƒn tá»« nhá»¯ng váº¥n Ä‘á» thá»±c táº¿ gáº·p pháº£i, cáº£i thiá»‡n dáº§n qua quÃ¡ trÃ¬nh lÃ m viá»‡c vá»›i nhiá»u bá»™ dá»¯ liá»‡u y táº¿.
â­ï¸ Tiáº¿p sau viá»‡c má»Ÿ bá»™ dá»¯ liá»‡u y táº¿ quy mÃ´ lá»›n VinDr-CXR, Ä‘Ã¢y lÃ  Ä‘Ã³ng gÃ³p tiáº¿p theo cá»§a VinBigdata trong viá»‡c chia sáº» dá»¯ liá»‡u vÃ  cÃ´ng cá»¥ phÃ¡t triá»ƒn AI. Qua Ä‘Ã¢y, chÃºng mÃ¬nh khuyáº¿n khÃ­ch cá»™ng Ä‘á»“ng tÄƒng cÆ°á»ng viá»‡c chia sáº» dá»¯ liá»‡u Ä‘á»ƒ thÃºc Ä‘áº©y nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn AI táº¡i Viá»‡t Nam.
CÃ¡c báº¡n xem vÃ  Ä‘á»ƒ láº¡i feedback cho team nhÃ©.
ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» !","[VinDr Lab] [Open-source data annotation for Medical AI] Github: https://github.com/vinbigdata-medical/vindr-lab/ Sau cuá»™c thi VinBigData Chest X-ray Abnormalities Detection trÃªn Kaggle (https://www.kaggle.com/.../vinbigdata-chest-xray.../), phÃ²ng Xá»­ lÃ½ áº£nh y táº¿ - Viá»‡n NghiÃªn cá»©u Dá»¯ liá»‡u lá»›n Vingroup quyáº¿t Ä‘á»‹nh má»Ÿ mÃ£ nguá»“n cá»§a pháº§n má»m VinDr Lab. VinDr Lab lÃ  má»™t cÃ´ng cá»¥ gÃ¡n nhÃ£n hÃ¬nh áº£nh DICOM Ä‘ang Ä‘Æ°á»£c team sá»­ dá»¥ng. CÃ¡c tÃ­nh nÄƒng gÃ¡n nhÃ£n, quáº£n lÃ½ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a, phÃ¡t triá»ƒn tá»« nhá»¯ng váº¥n Ä‘á» thá»±c táº¿ gáº·p pháº£i, cáº£i thiá»‡n dáº§n qua quÃ¡ trÃ¬nh lÃ m viá»‡c vá»›i nhiá»u bá»™ dá»¯ liá»‡u y táº¿. Tiáº¿p sau viá»‡c má»Ÿ bá»™ dá»¯ liá»‡u y táº¿ quy mÃ´ lá»›n VinDr-CXR, Ä‘Ã¢y lÃ  Ä‘Ã³ng gÃ³p tiáº¿p theo cá»§a VinBigdata trong viá»‡c chia sáº» dá»¯ liá»‡u vÃ  cÃ´ng cá»¥ phÃ¡t triá»ƒn AI. Qua Ä‘Ã¢y, chÃºng mÃ¬nh khuyáº¿n khÃ­ch cá»™ng Ä‘á»“ng tÄƒng cÆ°á»ng viá»‡c chia sáº» dá»¯ liá»‡u Ä‘á»ƒ thÃºc Ä‘áº©y nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn AI táº¡i Viá»‡t Nam. CÃ¡c báº¡n xem vÃ  Ä‘á»ƒ láº¡i feedback cho team nhÃ©. ChÃºc má»i ngÆ°á»i cuá»‘i tuáº§n vui váº» !",,,,,
"ChÃ o má»i ngÆ°á»i! Cho mÃ¬nh há»i má»©c lÆ°Æ¡ng á»Ÿ VN cho data scientist (2 nÄƒm kn) khoáº£ng bn nhá»‰? Cá»¥ thá»ƒ vá»›i fintech thÃ¬ cÃ³ thá»ƒ deal á»Ÿ má»©c bao nhiÃªu ?
Cáº£m Æ¡n má»i ngÆ°á»i áº¡!",ChÃ o má»i ngÆ°á»i! Cho mÃ¬nh há»i má»©c lÆ°Æ¡ng á»Ÿ VN cho data scientist (2 nÄƒm kn) khoáº£ng bn nhá»‰? Cá»¥ thá»ƒ vá»›i fintech thÃ¬ cÃ³ thá»ƒ deal á»Ÿ má»©c bao nhiÃªu ? Cáº£m Æ¡n má»i ngÆ°á»i áº¡!,,,,,
Mn cho em há»i chá»— tÃ´ Ä‘áº­m sau láº¡i ra Ä‘Æ°á»£c nhÆ° váº­y áº¡. Em cáº£m Æ¡n mn nhiá»u. Mn thÃ´ng cáº£m náº¿u cÃ¢u há»i nÃ y cÃ³ hÆ¡i ngá»‘c áº¡.,Mn cho em há»i chá»— tÃ´ Ä‘áº­m sau láº¡i ra Ä‘Æ°á»£c nhÆ° váº­y áº¡. Em cáº£m Æ¡n mn nhiá»u. Mn thÃ´ng cáº£m náº¿u cÃ¢u há»i nÃ y cÃ³ hÆ¡i ngá»‘c áº¡.,,,,,
"ChÃ o anh chá»‹ áº¡,em cÃ³ má»™t cÃ¢u há»i lÃ  liá»‡u mÃ¬nh cÃ³ thá»ƒ káº¿t há»£p SURF vÃ  máº¡ng CNN Ä‘á»ƒ lÃ m object recognition Ä‘Æ°á»£c ko áº¡?Náº¿u Ä‘Æ°á»£c thÃ¬ lÃ m sao Ä‘á»ƒ mÃ¬nh input Ä‘Æ°á»£c keypoint mÃ  mÃ¬nh Ä‘Ã£ láº¥y ra á»Ÿ SURF Ä‘á»ƒ Ä‘Æ°a vÃ o CNN áº¡.Em cáº£m Æ¡n áº¡","ChÃ o anh chá»‹ áº¡,em cÃ³ má»™t cÃ¢u há»i lÃ  liá»‡u mÃ¬nh cÃ³ thá»ƒ káº¿t há»£p SURF vÃ  máº¡ng CNN Ä‘á»ƒ lÃ m object recognition Ä‘Æ°á»£c ko áº¡?Náº¿u Ä‘Æ°á»£c thÃ¬ lÃ m sao Ä‘á»ƒ mÃ¬nh input Ä‘Æ°á»£c keypoint mÃ  mÃ¬nh Ä‘Ã£ láº¥y ra á»Ÿ SURF Ä‘á»ƒ Ä‘Æ°a vÃ o CNN áº¡.Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o a/c, e Ä‘ang lÃ m project vá» autonomous navigation. Anh chá»‹ cho em xin má»™t vÃ i model vá» cÃ¡i nÃ y Ä‘á»ƒ tham kháº£o áº¡
Regards,","ChÃ o a/c, e Ä‘ang lÃ m project vá» autonomous navigation. Anh chá»‹ cho em xin má»™t vÃ i model vá» cÃ¡i nÃ y Ä‘á»ƒ tham kháº£o áº¡ Regards,",,,,,
Anh Chá»‹ cho em há»i em lÃ m vá» LSTM vÃ  GRU. optimizer em chá»n lÃ  Adam. khi cháº¡y thá»±c nghiá»‡m model em cÃ³ Ä‘á»ƒ sá»‘ epochs khÃ¡c nhau. Theo em Ä‘Æ°á»£c biáº¿t thÃ¬ sá»‘ epochs lÃ  sá»‘ láº§n mÃ´ hÃ¬nh duyá»‡t qua toÃ n bá»™ Ä‘iá»ƒm dá»¯ liá»‡u. TrÆ°á»ng há»£p cá»§a em lÃ  vá»›i epochs 100 láº§n 250 láº§n vÃ  500 láº§n. thÃ¬ 100 láº§n sáº½ cÃ³ káº¿t quáº£ tá»‘t nháº¥t. nhÆ° váº­y chÆ°a cháº¯c sá»‘ láº§n epochs cao thÃ¬ káº¿t quáº£ cho cÃ ng tá»‘t pháº£i khÃ´ng áº¡. (Náº¿u Ä‘Æ°á»£c nhá» Anh Chá»‹ giáº£i thÃ­ch giÃºp em táº¡i sao láº¡i nhÆ° váº­y áº¡. trÆ°á»›c kia e cá»© tÆ°á»Ÿng epochs cÃ ng nhiá»u thÃ¬ cÃ ng tá»‘t nhÆ°ng thá»i gian cháº¡y sáº½ lÃ¢u.),Anh Chá»‹ cho em há»i em lÃ m vá» LSTM vÃ  GRU. optimizer em chá»n lÃ  Adam. khi cháº¡y thá»±c nghiá»‡m model em cÃ³ Ä‘á»ƒ sá»‘ epochs khÃ¡c nhau. Theo em Ä‘Æ°á»£c biáº¿t thÃ¬ sá»‘ epochs lÃ  sá»‘ láº§n mÃ´ hÃ¬nh duyá»‡t qua toÃ n bá»™ Ä‘iá»ƒm dá»¯ liá»‡u. TrÆ°á»ng há»£p cá»§a em lÃ  vá»›i epochs 100 láº§n 250 láº§n vÃ  500 láº§n. thÃ¬ 100 láº§n sáº½ cÃ³ káº¿t quáº£ tá»‘t nháº¥t. nhÆ° váº­y chÆ°a cháº¯c sá»‘ láº§n epochs cao thÃ¬ káº¿t quáº£ cho cÃ ng tá»‘t pháº£i khÃ´ng áº¡. (Náº¿u Ä‘Æ°á»£c nhá» Anh Chá»‹ giáº£i thÃ­ch giÃºp em táº¡i sao láº¡i nhÆ° váº­y áº¡. trÆ°á»›c kia e cá»© tÆ°á»Ÿng epochs cÃ ng nhiá»u thÃ¬ cÃ ng tá»‘t nhÆ°ng thá»i gian cháº¡y sáº½ lÃ¢u.),,,,,
Mn cho em há»i Ä‘oáº¡n Ä‘Ã¡nh dáº¥u sau ra dc nhÆ° váº­y áº¡. Em cáº£m Æ¡n mn nhiá»u.,Mn cho em há»i Ä‘oáº¡n Ä‘Ã¡nh dáº¥u sau ra dc nhÆ° váº­y áº¡. Em cáº£m Æ¡n mn nhiá»u.,,,,,
"ChÃ o cÃ¡c Anh Chá»‹.
Em tháº¯c máº¯c má»™t xÃ­u vá» máº¡ng LSTM GRU keras. Mn giÃºp em vá»›i.
hiá»‡n táº¡i code em nhÆ° hÃ¬nh gá»­i kÃ¨m.
Sá»‘ Layer trong code nÃ y chá»n lÃ  bao nhiÃªu layer? mÃ¬nh cÃ³ tÃ­nh dropout lÃ  má»™t layer khÃ´ng? layer Dense(1) cÃ³ Ä‘Æ°á»£c tÃ­nh khÃ´ng áº¡?
theo em nghá»‰ lÃ  2 layer vÃ¬ khÃ´ng tÃ­nh dropout. Nhá» má»i ngÆ°á»i giÃºp em vá»›i. Em cáº£m Æ¡n nhiá»u áº¡.",ChÃ o cÃ¡c Anh Chá»‹. Em tháº¯c máº¯c má»™t xÃ­u vá» máº¡ng LSTM GRU keras. Mn giÃºp em vá»›i. hiá»‡n táº¡i code em nhÆ° hÃ¬nh gá»­i kÃ¨m. Sá»‘ Layer trong code nÃ y chá»n lÃ  bao nhiÃªu layer? mÃ¬nh cÃ³ tÃ­nh dropout lÃ  má»™t layer khÃ´ng? layer Dense(1) cÃ³ Ä‘Æ°á»£c tÃ­nh khÃ´ng áº¡? theo em nghá»‰ lÃ  2 layer vÃ¬ khÃ´ng tÃ­nh dropout. Nhá» má»i ngÆ°á»i giÃºp em vá»›i. Em cáº£m Æ¡n nhiá»u áº¡.,,,,,
"Má»™t sá»‘ models dá»±a trÃªn kiáº¿n trÃºc transformers cÃ´ng bá»‘ gáº§n Ä‘Ã¢y (tÃªn model ~ ngÃ y xuáº¥t báº£n theo thÃ¡ng/ngÃ y):
CaiT (3/31)
PiT (3/30)
ViViT (3/29)
ViL (3/29)
CvT (3/29)
CrossViT (3/27)
Swin Transformer (3/25)
STAM (3/25)
DPT (3/24)
DeepViT (3/22)
CeiT (3/22)
HVT (3/19)
ConViT (3/19)
PVT (2/24)
CPVT (2/22)
T2T-ViT (1/22)
â€¦.",Má»™t sá»‘ models dá»±a trÃªn kiáº¿n trÃºc transformers cÃ´ng bá»‘ gáº§n Ä‘Ã¢y (tÃªn model ~ ngÃ y xuáº¥t báº£n theo thÃ¡ng/ngÃ y): CaiT (3/31) PiT (3/30) ViViT (3/29) ViL (3/29) CvT (3/29) CrossViT (3/27) Swin Transformer (3/25) STAM (3/25) DPT (3/24) DeepViT (3/22) CeiT (3/22) HVT (3/19) ConViT (3/19) PVT (2/24) CPVT (2/22) T2T-ViT (1/22) â€¦.,,,,,
"Trong máº¥y thÃ¡ng Ä‘áº§u nÄƒm 2021, vá»›i sá»± ná»•i lÃªn cá»§a kiáº¿n trÃºc Transformer trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n vá» computer vision, Ä‘áº·c biá»‡t trong thÃ¡ng 3/2021 trÃªn trang paperwiththecodes.com cÃ³ tá»›i hÆ¡n ná»¯a 10 bÃ i vá» chá»§ Ä‘á» nÃ y. NhÆ°ng tá»›i 1/4 Google Brain Ä‘Ã£ cÃ´ng bá»‘ máº¡ng EfficientNetV2 táº¡i Ä‘Ã¢y https://arxiv.org/pdf/2104.00298.pdf. Chá»©ng tá» kiáº¿n trÃºc convolution sáº½ cÃ²n tá»“n táº¡i trong thá»i gian tá»›i. Náº¿u báº¡n nÃ o quan tÃ¢m tá»›i cÃ¡c cuá»™c thi trÃªn Kaggle thÃ¬ cÃ¡c Ä‘á»™i cÃ³ thÃ nh tÃ­ch cao ráº¥t thÆ°á»ng sá»­ dá»¥ng combo máº¡ng EfficientNetV1 Ä‘á»ƒ giÃ nh káº¿t quáº£ triá»ƒn vá»ng chung cuá»™c.","Trong máº¥y thÃ¡ng Ä‘áº§u nÄƒm 2021, vá»›i sá»± ná»•i lÃªn cá»§a kiáº¿n trÃºc Transformer trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n vá» computer vision, Ä‘áº·c biá»‡t trong thÃ¡ng 3/2021 trÃªn trang paperwiththecodes.com cÃ³ tá»›i hÆ¡n ná»¯a 10 bÃ i vá» chá»§ Ä‘á» nÃ y. NhÆ°ng tá»›i 1/4 Google Brain Ä‘Ã£ cÃ´ng bá»‘ máº¡ng EfficientNetV2 táº¡i Ä‘Ã¢y https://arxiv.org/pdf/2104.00298.pdf. Chá»©ng tá» kiáº¿n trÃºc convolution sáº½ cÃ²n tá»“n táº¡i trong thá»i gian tá»›i. Náº¿u báº¡n nÃ o quan tÃ¢m tá»›i cÃ¡c cuá»™c thi trÃªn Kaggle thÃ¬ cÃ¡c Ä‘á»™i cÃ³ thÃ nh tÃ­ch cao ráº¥t thÆ°á»ng sá»­ dá»¥ng combo máº¡ng EfficientNetV1 Ä‘á»ƒ giÃ nh káº¿t quáº£ triá»ƒn vá»ng chung cuá»™c.",,,,,
"Gáº§n Ä‘Ã¢y cÃ³ má»™t sá»‘ báº¡n há»i vá» viá»‡c nháº­n diá»‡n hÃ¬nh áº£nh, vÃ­ dá»¥ nhÆ° xÃ¡c nháº­n khuÃ´n máº·t, xÃ¡c nháº­n chá»¯ kÃ­ sá»‘, hay xÃ¡c nháº­n vÃ¢n tay. ÄÃ¢y lÃ  chá»§ Ä‘á» liÃªn quan tá»›i verification chá»© khÃ´ng pháº£i lÃ  classification (phÃ¢n loáº¡i chÃ³ ~ mÃ¨o), object detection (nháº­n diá»‡n xe cá»™), hay segmentation (khoanh vÃ¹ng láº¡i váº¿t ná»©t trÃªn bÃª tÃ´ng cháº³ng háº¡n). Váº­y phÆ°Æ¡ng phÃ¡p giáº£i bÃ i toÃ¡n nÃ y nhÆ° tháº¿ nÃ o? Ráº¥t may Ä‘Ã£ cÃ³ giáº£i phÃ¡p gá»i chung lÃ  Siamese Networks.
Sau Ä‘Ã¢y mÃ¬nh Ä‘Æ°a 1 sá»‘ tutorials cho cÃ¡c báº¡n:
1/ PyImageSearch vá»›i code trÃªn Keras/TensorFlow tham kháº£o táº¡i Ä‘Ã¢y: https://www.pyimagesearch.com/.../siamese-networks-with.../
2/ FastAI vá»›i code trÃªn FastAI/PyTorch tham kháº£o táº¡i Ä‘Ã¢y: https://docs.fast.ai/tutorial.siamese.html
3/ NgoÃ i ra cÃ²n cÃ³ cÃ¡c nguá»“n trÃªn Medium.com, nhÆ°ng giá» má»Ÿ báº±ng medium0.com cÅ©ng Ä‘Ã£ bá»‹ khoÃ¡, cháº¯c cÃ¡c báº¡n cáº§n dÃ¹ng dá»‹ch vá»¥ VPN khÃ¡c. MÃ¬nh dÃ¹ng duyá»‡t trÃ¬nh Tor Ä‘á»ƒ vÆ°á»£t qua tÆ°á»ng lá»­a!
ChÃºc cÃ¡c báº¡n vui!
https://www.pyimagesearch.com/.../keras_siamese_networks...
Ps. Náº¿u cÃ¡c báº¡n muá»‘n hiá»ƒu rÃµ hÆ¡n vá»›i cÃ¡ch giáº£i thÃ­ch ráº¥t thÃº vá»‹, cÃ¡c báº¡n cÃ³ thá»ƒ follow twitter cá»§a anh Santiago, @@svpino; blog cá»§a anh áº¥y http://digest.underfitted.io. Tháº­m trÃ­, cÃ¡c báº¡n cÃ³ thá»ƒ mua tÃ i khoáº£n NewLetter tá»« anh áº¥y. Anh nÃ y cÃ³ ráº¥t nhiá»u giáº£i thÃ­ch trá»±c quan vá» Gradient Descent, Batch size, overfitting~underfitting,.... cho tá»›i lÄ©nh vá»±c triá»ƒn khai models trong mÃ´i trÆ°á»ng cÃ´ng nghiá»‡p/doanh nghiá»‡p","Gáº§n Ä‘Ã¢y cÃ³ má»™t sá»‘ báº¡n há»i vá» viá»‡c nháº­n diá»‡n hÃ¬nh áº£nh, vÃ­ dá»¥ nhÆ° xÃ¡c nháº­n khuÃ´n máº·t, xÃ¡c nháº­n chá»¯ kÃ­ sá»‘, hay xÃ¡c nháº­n vÃ¢n tay. ÄÃ¢y lÃ  chá»§ Ä‘á» liÃªn quan tá»›i verification chá»© khÃ´ng pháº£i lÃ  classification (phÃ¢n loáº¡i chÃ³ ~ mÃ¨o), object detection (nháº­n diá»‡n xe cá»™), hay segmentation (khoanh vÃ¹ng láº¡i váº¿t ná»©t trÃªn bÃª tÃ´ng cháº³ng háº¡n). Váº­y phÆ°Æ¡ng phÃ¡p giáº£i bÃ i toÃ¡n nÃ y nhÆ° tháº¿ nÃ o? Ráº¥t may Ä‘Ã£ cÃ³ giáº£i phÃ¡p gá»i chung lÃ  Siamese Networks. Sau Ä‘Ã¢y mÃ¬nh Ä‘Æ°a 1 sá»‘ tutorials cho cÃ¡c báº¡n: 1/ PyImageSearch vá»›i code trÃªn Keras/TensorFlow tham kháº£o táº¡i Ä‘Ã¢y: https://www.pyimagesearch.com/.../siamese-networks-with.../ 2/ FastAI vá»›i code trÃªn FastAI/PyTorch tham kháº£o táº¡i Ä‘Ã¢y: https://docs.fast.ai/tutorial.siamese.html 3/ NgoÃ i ra cÃ²n cÃ³ cÃ¡c nguá»“n trÃªn Medium.com, nhÆ°ng giá» má»Ÿ báº±ng medium0.com cÅ©ng Ä‘Ã£ bá»‹ khoÃ¡, cháº¯c cÃ¡c báº¡n cáº§n dÃ¹ng dá»‹ch vá»¥ VPN khÃ¡c. MÃ¬nh dÃ¹ng duyá»‡t trÃ¬nh Tor Ä‘á»ƒ vÆ°á»£t qua tÆ°á»ng lá»­a! ChÃºc cÃ¡c báº¡n vui! https://www.pyimagesearch.com/.../keras_siamese_networks... Ps. Náº¿u cÃ¡c báº¡n muá»‘n hiá»ƒu rÃµ hÆ¡n vá»›i cÃ¡ch giáº£i thÃ­ch ráº¥t thÃº vá»‹, cÃ¡c báº¡n cÃ³ thá»ƒ follow twitter cá»§a anh Santiago, @@svpino; blog cá»§a anh áº¥y http://digest.underfitted.io. Tháº­m trÃ­, cÃ¡c báº¡n cÃ³ thá»ƒ mua tÃ i khoáº£n NewLetter tá»« anh áº¥y. Anh nÃ y cÃ³ ráº¥t nhiá»u giáº£i thÃ­ch trá»±c quan vá» Gradient Descent, Batch size, overfitting~underfitting,.... cho tá»›i lÄ©nh vá»±c triá»ƒn khai models trong mÃ´i trÆ°á»ng cÃ´ng nghiá»‡p/doanh nghiá»‡p",,,,,
ANN lá»£i hÆ¡n so vá»›i cÃ¡i giáº£i thuáº­t xá»­ lÃ½ áº£nh Ä‘á»ƒ extract ra Ä‘áº·c trÆ°ng á»Ÿ Ä‘iá»ƒm nÃ o áº¡ ?,ANN lá»£i hÆ¡n so vá»›i cÃ¡i giáº£i thuáº­t xá»­ lÃ½ áº£nh Ä‘á»ƒ extract ra Ä‘áº·c trÆ°ng á»Ÿ Ä‘iá»ƒm nÃ o áº¡ ?,,,,,
Má»i ngÆ°á»i Æ¡i cho em há»i cÃ¢u ráº¥t newbie luÃ´n áº¡. Trong dataset khÃ¡ch hÃ ng cung cáº¥p cho em Ä‘á»ƒ classify Ä‘á»™ng váº­t thÃ¬ cÃ¡i annotation lÃ  mÃ u Ä‘á» hÃ¬nh trÃ²n nhÆ° hÃ¬nh Ã½ . Em sá»­a láº¡i thÃ nh cÃ¡i mÃ u xanh nÆ°á»›c biá»ƒn thÃ¬ khi training cÃ³ dá»… hÆ¡n k áº¡. Em xin cáº£m Æ¡n,Má»i ngÆ°á»i Æ¡i cho em há»i cÃ¢u ráº¥t newbie luÃ´n áº¡. Trong dataset khÃ¡ch hÃ ng cung cáº¥p cho em Ä‘á»ƒ classify Ä‘á»™ng váº­t thÃ¬ cÃ¡i annotation lÃ  mÃ u Ä‘á» hÃ¬nh trÃ²n nhÆ° hÃ¬nh Ã½ . Em sá»­a láº¡i thÃ nh cÃ¡i mÃ u xanh nÆ°á»›c biá»ƒn thÃ¬ khi training cÃ³ dá»… hÆ¡n k áº¡. Em xin cáº£m Æ¡n,,,,,
"Em cÃ³ má»™t bÃ i tiá»ƒu luáº­n vá» nháº­n dáº¡ng vÃ¢n tay mÃ  khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u. Tháº§y cÃ³ Ä‘Æ°a ra 1 sá»‘ yÃªu cáº§u lÃ 
Pháº£i cÃ³ sÆ¡ Ä‘á»“ thuáº­t toÃ¡n vÃ  biá»‡n luáº­n Ä‘Æ°á»£c nÃ³
Giáº£i thÃ­ch Ä‘Æ°á»£c thuáº­t toÃ¡n vÃ  cho biáº¿t Input vÃ  output
Mong má»i ngÆ°á»i cho em hÆ°á»›ng tÃ¬m hiá»ƒu áº¡. Em cáº£m Æ¡n!",Em cÃ³ má»™t bÃ i tiá»ƒu luáº­n vá» nháº­n dáº¡ng vÃ¢n tay mÃ  khÃ´ng biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u. Tháº§y cÃ³ Ä‘Æ°a ra 1 sá»‘ yÃªu cáº§u lÃ  Pháº£i cÃ³ sÆ¡ Ä‘á»“ thuáº­t toÃ¡n vÃ  biá»‡n luáº­n Ä‘Æ°á»£c nÃ³ Giáº£i thÃ­ch Ä‘Æ°á»£c thuáº­t toÃ¡n vÃ  cho biáº¿t Input vÃ  output Mong má»i ngÆ°á»i cho em hÆ°á»›ng tÃ¬m hiá»ƒu áº¡. Em cáº£m Æ¡n!,,,,,
"NÄƒm 2021 thÃ¬ lÃ m gÃ¬?
MÃ¬nh cÃ³ tá»•ng há»£p láº¡i 1 sá»‘ cÃ¡c cuá»™c thi / competition Ä‘ang diá»…n ra, hi vá»ng há»¯u Ã­ch vá»›i mn :D
1. Shopee - Price Match Guarantee / Determine if two products are the same by their images https://www.kaggle.com/c/shopee-product-matching/overview
2. Graph Learning - KDD2021 https://ogb.stanford.edu/kddcup2021/
3. https://compete.hexagon-ml.com/practice/competition/39/#data
Multi-dataset Time Series Anomaly Detection - KDD2021
4. FGVC Workshop - CVPR2021 https://sites.google.com/view/fgvc8/competitions
5. City Brain Challenge - KDD2021 http://www.yunqiacademy.org
6. Recsys challenge 2021: https://recsys.acm.org/recsys21/challenge/
7. Discover how data is used for the public good https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/overview
8. Shared Task on Hateful Memes at WOAH 2021 - Multi-modal analysis
https://www.workshopononlineabuse.com/cfp/shared-task-on-hateful-memes
(C) https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/503511194389274/","NÄƒm 2021 thÃ¬ lÃ m gÃ¬? MÃ¬nh cÃ³ tá»•ng há»£p láº¡i 1 sá»‘ cÃ¡c cuá»™c thi / competition Ä‘ang diá»…n ra, hi vá»ng há»¯u Ã­ch vá»›i mn :D 1. Shopee - Price Match Guarantee / Determine if two products are the same by their images https://www.kaggle.com/c/shopee-product-matching/overview 2. Graph Learning - KDD2021 https://ogb.stanford.edu/kddcup2021/ 3. https://compete.hexagon-ml.com/practice/competition/39/#data Multi-dataset Time Series Anomaly Detection - KDD2021 4. FGVC Workshop - CVPR2021 https://sites.google.com/view/fgvc8/competitions 5. City Brain Challenge - KDD2021 http://www.yunqiacademy.org 6. Recsys challenge 2021: https://recsys.acm.org/recsys21/challenge/ 7. Discover how data is used for the public good https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/overview 8. Shared Task on Hateful Memes at WOAH 2021 - Multi-modal analysis https://www.workshopononlineabuse.com/cfp/shared-task-on-hateful-memes (C) https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/503511194389274/",,,,,
"Xin chÃ o má»i ngÆ°á»i, sau vÃ i thÃ¡ng mÃ y mÃ² thÃ¬ e Ä‘Ã£ náº¯m báº¯t Ä‘c kiáº¿n thá»©c vá» DL cÆ¡ báº£n rá»“i. E cÃ³ ráº£i CV 1 vÃ i cÃ´ng ty vÃ  há» cÃ³ yÃªu cáº§u vá» dá»± Ã¡n Ä‘Ã£ lÃ m, e khÃ´ng biáº¿t dá»± Ã¡n há» cáº§n á»Ÿ má»©c Ä‘á»™ nhÆ° tháº¿ nÃ o?? NhÃ¢n tiá»‡n má»i ngÆ°á»i cÃ³ thá»ƒ cho e 1 vÃ i Ã½ tÆ°á»Ÿng dá»± Ã¡n vá» Computer vision hay NLP Ä‘c khÃ´ng áº¡??","Xin chÃ o má»i ngÆ°á»i, sau vÃ i thÃ¡ng mÃ y mÃ² thÃ¬ e Ä‘Ã£ náº¯m báº¯t Ä‘c kiáº¿n thá»©c vá» DL cÆ¡ báº£n rá»“i. E cÃ³ ráº£i CV 1 vÃ i cÃ´ng ty vÃ  há» cÃ³ yÃªu cáº§u vá» dá»± Ã¡n Ä‘Ã£ lÃ m, e khÃ´ng biáº¿t dá»± Ã¡n há» cáº§n á»Ÿ má»©c Ä‘á»™ nhÆ° tháº¿ nÃ o?? NhÃ¢n tiá»‡n má»i ngÆ°á»i cÃ³ thá»ƒ cho e 1 vÃ i Ã½ tÆ°á»Ÿng dá»± Ã¡n vá» Computer vision hay NLP Ä‘c khÃ´ng áº¡??",,,,,
Má»i ngÆ°á»i cho e há»i lÃ  bÃ¢y giá» lÃ m nhÆ° nÃ o Ä‘á»ƒ cÃ¡i x axis cÃ¡i graph trÃªn giá»‘ng cá»§a graph dÆ°á»›i v áº¡. Thanks má»i ngÆ°á»i,Má»i ngÆ°á»i cho e há»i lÃ  bÃ¢y giá» lÃ m nhÆ° nÃ o Ä‘á»ƒ cÃ¡i x axis cÃ¡i graph trÃªn giá»‘ng cá»§a graph dÆ°á»›i v áº¡. Thanks má»i ngÆ°á»i,,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ tÃ¬m hiá»ƒu má»™t chÃºt vá» cÆ¡ cháº¿ ""Self Attention"" vÃ  mong muá»‘n chia sáº» tá»›i má»i ngÆ°á»i. Hy vá»ng sáº½ bÃ i Ä‘á»c sáº½ giÃºp Ã­ch Ã­t nhiá»u cho má»i ngÆ°á»i tÃ¬m hiá»ƒu kiáº¿n thá»©c nÃ y. Náº¿u cÃ³ Ä‘iá»u gÃ¬ sai sÃ³t trong bÃ i, má»i ngÆ°á»i cÃ³ thá»ƒ gÃ³p Ã½ giÃºp mÃ¬nh dÆ°á»›i bÃ i viáº¿t nÃ y a. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ theo dÃµi áº¡. :))","Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ tÃ¬m hiá»ƒu má»™t chÃºt vá» cÆ¡ cháº¿ ""Self Attention"" vÃ  mong muá»‘n chia sáº» tá»›i má»i ngÆ°á»i. Hy vá»ng sáº½ bÃ i Ä‘á»c sáº½ giÃºp Ã­ch Ã­t nhiá»u cho má»i ngÆ°á»i tÃ¬m hiá»ƒu kiáº¿n thá»©c nÃ y. Náº¿u cÃ³ Ä‘iá»u gÃ¬ sai sÃ³t trong bÃ i, má»i ngÆ°á»i cÃ³ thá»ƒ gÃ³p Ã½ giÃºp mÃ¬nh dÆ°á»›i bÃ i viáº¿t nÃ y a. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ theo dÃµi áº¡. :))",,,,,
"ChÃ o cÃ¡c anh chá»‹ áº¡! Em tháº¥y hiá»‡n nay AI á»Ÿ Viá»‡t Nam Ä‘ang ráº¥t phÃ¡t triá»ƒn
BÃ¬nh thÆ°á»ng má»i ngÆ°á»i cÃ³ dÃ¹ng á»©ng dá»¥ng AI nÃ o vÃ o cÃ´ng viá»‡c hay cuá»™c sá»‘ng khÃ´ng áº¡? Trá»« kiá»ƒu Siri hay Cortana ra... Em khÃ¡ tÃ² mÃ² vá» Ä‘iá»u nÃ y, hy vá»ng anh chá»‹ cÃ³ thá»ƒ chia sáº» áº¡","ChÃ o cÃ¡c anh chá»‹ áº¡! Em tháº¥y hiá»‡n nay AI á»Ÿ Viá»‡t Nam Ä‘ang ráº¥t phÃ¡t triá»ƒn BÃ¬nh thÆ°á»ng má»i ngÆ°á»i cÃ³ dÃ¹ng á»©ng dá»¥ng AI nÃ o vÃ o cÃ´ng viá»‡c hay cuá»™c sá»‘ng khÃ´ng áº¡? Trá»« kiá»ƒu Siri hay Cortana ra... Em khÃ¡ tÃ² mÃ² vá» Ä‘iá»u nÃ y, hy vá»ng anh chá»‹ cÃ³ thá»ƒ chia sáº» áº¡",,,,,
"ChÃ o má»i ngÆ°á»i!
MÃ¬nh Ä‘ang káº¿ hoáº¡ch Ä‘á»c láº¡i kiáº¿n thá»©c Machine Learning cÆ¡ báº£n vÃ¬ hiá»‡n táº¡i háº§u nhÆ° chá»‰ sá»­ dá»¥ng thÆ° viá»‡n vÃ  google nÃªn nhiá»u pháº§n chÆ°a náº¯m cháº¯c. MÃ¬nh Ä‘Ã£ cÃ³ kiáº¿n thá»©c ná»n vá» toÃ¡n, thá»‘ng kÃª vÃ  láº­p trÃ¬nh Python. MÃ¬nh tháº¥y sÃ¡ch Machine Learning cÆ¡ báº£n cá»§a anh Tiá»‡p ráº¥t hay vÃ¬ tá»•ng há»£p kiáº¿n thá»©c cÃ³ há»‡ thá»‘ng vÃ  phÃ¹ há»£p vá»›i tÆ° duy há»c cá»§a ngÆ°á»i Viá»‡t (náº¿u anh Tiá»‡p Ä‘á»c Ä‘Æ°á»£c thÃ¬ cáº£m Æ¡n anh nhiá»u áº¡) nÃªn muá»‘n Ã´n láº¡i kiáº¿n thá»©c theo sÃ¡ch anh Tiá»‡p.
Tuy nhiÃªn, mÃ¬nh Ä‘Ã£ hÆ¡n 10 nÄƒm khÃ´ng Ä‘á»c sÃ¡ch giÃ¡o khoa tiáº¿ng Viá»‡t vÃ  cÃ¡c kiáº¿n thá»©c vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh vÃ  thá»‘ng kÃª mÃ¬nh Ä‘ang quen khÃ¡i niá»‡m tiáº¿ng Anh nÃªn Ä‘á»c sÃ¡ch cá»§a anh Tiá»‡p mÃ¬nh pháº£i liÃªn tá»¥c dá»‹ch sang tiáº¿ng Anh Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c vá» máº·t ngÃ´n ngá»¯. MÃ¬nh dá»± Ä‘á»‹nh sáº½ theo lá»™ trÃ¬nh trong sÃ¡ch anh Tiá»‡p vÃ  tham kháº£o thÃªm nguá»“n tiáº¿ng Anh Ä‘á»ƒ hiá»ƒu nhanh hÆ¡n. Má»i ngÆ°á»i cÃ³ thá»ƒ chia sáº» cÃ¡c khoÃ¡ há»c báº±ng tiáº¿ng Anh hoáº·c sÃ¡ch nÃ o báº±ng Tiáº¿ng Anh Ä‘á»ƒ mÃ¬nh sá»­ dá»¥ng thÃªm song song vá»›i sÃ¡ch tiáº¿ng Viá»‡t cá»§a anh Tiá»‡p khÃ´ng áº¡? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang káº¿ hoáº¡ch Ä‘á»c láº¡i kiáº¿n thá»©c Machine Learning cÆ¡ báº£n vÃ¬ hiá»‡n táº¡i háº§u nhÆ° chá»‰ sá»­ dá»¥ng thÆ° viá»‡n vÃ  google nÃªn nhiá»u pháº§n chÆ°a náº¯m cháº¯c. MÃ¬nh Ä‘Ã£ cÃ³ kiáº¿n thá»©c ná»n vá» toÃ¡n, thá»‘ng kÃª vÃ  láº­p trÃ¬nh Python. MÃ¬nh tháº¥y sÃ¡ch Machine Learning cÆ¡ báº£n cá»§a anh Tiá»‡p ráº¥t hay vÃ¬ tá»•ng há»£p kiáº¿n thá»©c cÃ³ há»‡ thá»‘ng vÃ  phÃ¹ há»£p vá»›i tÆ° duy há»c cá»§a ngÆ°á»i Viá»‡t (náº¿u anh Tiá»‡p Ä‘á»c Ä‘Æ°á»£c thÃ¬ cáº£m Æ¡n anh nhiá»u áº¡) nÃªn muá»‘n Ã´n láº¡i kiáº¿n thá»©c theo sÃ¡ch anh Tiá»‡p. Tuy nhiÃªn, mÃ¬nh Ä‘Ã£ hÆ¡n 10 nÄƒm khÃ´ng Ä‘á»c sÃ¡ch giÃ¡o khoa tiáº¿ng Viá»‡t vÃ  cÃ¡c kiáº¿n thá»©c vá» Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh vÃ  thá»‘ng kÃª mÃ¬nh Ä‘ang quen khÃ¡i niá»‡m tiáº¿ng Anh nÃªn Ä‘á»c sÃ¡ch cá»§a anh Tiá»‡p mÃ¬nh pháº£i liÃªn tá»¥c dá»‹ch sang tiáº¿ng Anh Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c vá» máº·t ngÃ´n ngá»¯. MÃ¬nh dá»± Ä‘á»‹nh sáº½ theo lá»™ trÃ¬nh trong sÃ¡ch anh Tiá»‡p vÃ  tham kháº£o thÃªm nguá»“n tiáº¿ng Anh Ä‘á»ƒ hiá»ƒu nhanh hÆ¡n. Má»i ngÆ°á»i cÃ³ thá»ƒ chia sáº» cÃ¡c khoÃ¡ há»c báº±ng tiáº¿ng Anh hoáº·c sÃ¡ch nÃ o báº±ng Tiáº¿ng Anh Ä‘á»ƒ mÃ¬nh sá»­ dá»¥ng thÃªm song song vá»›i sÃ¡ch tiáº¿ng Viá»‡t cá»§a anh Tiá»‡p khÃ´ng áº¡? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"Má»i ngÆ°á»i Æ¡i cÃ³ thá»ƒ cho em há»i, khi em train YOLOv4 thÃ¬ 2 chá»‰ sá»‘ total_bbox: 4411 vÃ  rewritten_bbox: 0.00000% cÃ³ nghÄ©a lÃ  gÃ¬ váº­y áº¡? VÃ  cÃ³ pháº£i chá»‰ sá»‘ rewritten_bbox cá»§a em báº±ng 0% thÃ¬ cÃ³ nghÄ©a lÃ  model Ä‘ang há»c khÃ´ng tá»‘t khÃ´ng áº¡? Em cáº£m Æ¡n.","Má»i ngÆ°á»i Æ¡i cÃ³ thá»ƒ cho em há»i, khi em train YOLOv4 thÃ¬ 2 chá»‰ sá»‘ total_bbox: 4411 vÃ  rewritten_bbox: 0.00000% cÃ³ nghÄ©a lÃ  gÃ¬ váº­y áº¡? VÃ  cÃ³ pháº£i chá»‰ sá»‘ rewritten_bbox cá»§a em báº±ng 0% thÃ¬ cÃ³ nghÄ©a lÃ  model Ä‘ang há»c khÃ´ng tá»‘t khÃ´ng áº¡? Em cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ tháº¯c máº¯c nhÆ° sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡:
Trong khÃ´ng gian n chiá»u, cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ táº¡o ra m Ä‘iá»ƒm (m > n+1) vÃ  thá»a mÃ£n Ä‘iá»ƒu kiá»‡n lÃ  khoáº£ng cÃ¡ch (c) giá»¯a cÃ¡c Ä‘iá»ƒm lÃ  báº±ng nhau khÃ´ng áº¡.
VÃ­ dá»¥ 
d(x0,x1) = d(x0,x2) = ... = d(x0,xm) = c
d(x1,x0) = d(x1,x2) = ... = d(x1,xm) = c
....
Trong trÆ°á»ng há»£p khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh m Ä‘iá»ƒm vá»›i Ä‘iá»u kiá»‡n nhÆ° trÃªn, cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o khÃ¡c Ä‘áº£m báº£o khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm m khÃ´ng cÃ³ sá»± chÃªnh lá»‡ch nhiá»u vá» máº·t khoáº£ng cÃ¡ch khÃ´ng? Em xin cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, em cÃ³ tháº¯c máº¯c nhÆ° sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡: Trong khÃ´ng gian n chiá»u, cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ táº¡o ra m Ä‘iá»ƒm (m > n+1) vÃ  thá»a mÃ£n Ä‘iá»ƒu kiá»‡n lÃ  khoáº£ng cÃ¡ch (c) giá»¯a cÃ¡c Ä‘iá»ƒm lÃ  báº±ng nhau khÃ´ng áº¡. VÃ­ dá»¥ d(x0,x1) = d(x0,x2) = ... = d(x0,xm) = c d(x1,x0) = d(x1,x2) = ... = d(x1,xm) = c .... Trong trÆ°á»ng há»£p khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh m Ä‘iá»ƒm vá»›i Ä‘iá»u kiá»‡n nhÆ° trÃªn, cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o khÃ¡c Ä‘áº£m báº£o khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm m khÃ´ng cÃ³ sá»± chÃªnh lá»‡ch nhiá»u vá» máº·t khoáº£ng cÃ¡ch khÃ´ng? Em xin cáº£m Æ¡n áº¡.",,,"#Q&A, #math",,
"ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang gáº·p váº¥n Ä‘á» vá» viá»‡c Pruning Parameters báº±ng Pytorch, mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p.
Váº¥n Ä‘á» cá»§a em nhÆ° sau:
-, Giáº£ sá»­ em cÃ³ 1 weight tensor Ä‘Æ¡n giáº£n cáº§n pruning : Z = [ a b c ]
-, Sau khi pruning 66%, thu vá» Ä‘Æ°á»£c 1 mask G = [ 1 0 0]
-, LÃºc nÃ y sáº½ cÃ³ weight má»›i lÃ  Z(1) = Z*G = [ a 0 0]
-, Sau Ä‘Ã³ em váº«n dÃ¹ng Z Ä‘á»ƒ retrain láº¡i model, nhÆ°ng yÃªu cáº§u lÃ  tham sá»‘ a sáº½ cá»‘ Ä‘á»‹nh ( tá»©c kiá»ƒu stop_gradient (a), mÃ¬nh sáº½ khÃ´ng há»c tham sá»‘ a ná»¯a ). VÃ  sau khi retrain thu Ä‘Æ°á»£c Z"" = [ a d e]. LÃºc nÃ y em chá»‰ muá»‘n Ã¡p dá»¥ng prunning lÃªn d vÃ  e thÃ´i. Tá»©c nhá»¯ng tham sá»‘ nÃ o Ä‘Ã£ Ä‘Æ°á»£c prunning láº§n 1 vÃ  Ã¡p dá»¥ng stop_gradient thÃ¬ sáº½ bá»‹ prunning ná»¯a.
Em Ä‘ang gáº·p váº¥n Ä‘á» trong viá»‡c triá»ƒn khai code. Cá»¥ thá»ƒ á»Ÿ pháº§n lÃ m sao láº¥y ra Ä‘Æ°á»£c táº¥t cáº£ cÃ¡c tham sá»‘ Ä‘Æ°á»£c giá»¯ láº¡i sau láº§n prunning thá»© nháº¥t vÃ  Ã¡p dá»¥ng stop_gradient lÃªn chÃºng. Káº¿ Ä‘Ã³ lÃ  Ã¡p dá»¥ng prunning láº§n 2 lÃªn nhá»¯ng index tham sá»‘ chÆ°a Ä‘Æ°á»£c prunning á»Ÿ láº§n 1.
Em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang gáº·p váº¥n Ä‘á» vá» viá»‡c Pruning Parameters báº±ng Pytorch, mong Ä‘Æ°á»£c má»i ngÆ°á»i giáº£i Ä‘Ã¡p. Váº¥n Ä‘á» cá»§a em nhÆ° sau: -, Giáº£ sá»­ em cÃ³ 1 weight tensor Ä‘Æ¡n giáº£n cáº§n pruning : Z = [ a b c ] -, Sau khi pruning 66%, thu vá» Ä‘Æ°á»£c 1 mask G = [ 1 0 0] -, LÃºc nÃ y sáº½ cÃ³ weight má»›i lÃ  Z(1) = Z*G = [ a 0 0] -, Sau Ä‘Ã³ em váº«n dÃ¹ng Z Ä‘á»ƒ retrain láº¡i model, nhÆ°ng yÃªu cáº§u lÃ  tham sá»‘ a sáº½ cá»‘ Ä‘á»‹nh ( tá»©c kiá»ƒu stop_gradient (a), mÃ¬nh sáº½ khÃ´ng há»c tham sá»‘ a ná»¯a ). VÃ  sau khi retrain thu Ä‘Æ°á»£c Z"" = [ a d e]. LÃºc nÃ y em chá»‰ muá»‘n Ã¡p dá»¥ng prunning lÃªn d vÃ  e thÃ´i. Tá»©c nhá»¯ng tham sá»‘ nÃ o Ä‘Ã£ Ä‘Æ°á»£c prunning láº§n 1 vÃ  Ã¡p dá»¥ng stop_gradient thÃ¬ sáº½ bá»‹ prunning ná»¯a. Em Ä‘ang gáº·p váº¥n Ä‘á» trong viá»‡c triá»ƒn khai code. Cá»¥ thá»ƒ á»Ÿ pháº§n lÃ m sao láº¥y ra Ä‘Æ°á»£c táº¥t cáº£ cÃ¡c tham sá»‘ Ä‘Æ°á»£c giá»¯ láº¡i sau láº§n prunning thá»© nháº¥t vÃ  Ã¡p dá»¥ng stop_gradient lÃªn chÃºng. Káº¿ Ä‘Ã³ lÃ  Ã¡p dá»¥ng prunning láº§n 2 lÃªn nhá»¯ng index tham sá»‘ chÆ°a Ä‘Æ°á»£c prunning á»Ÿ láº§n 1. Em xin cáº£m Æ¡n.",,,,,
"#SVM
ChÃ o má»i ngÆ°á»i em Ä‘ang há»c SVM thÃ´ng qua bÃ i viáº¿t cá»§a anh Tiep.
Link blog: https://machinelearningcoban.com/2017/04/09/smv/#-xay-dung-bai-toan-toi-uu-cho-svm
Em cÃ³ 1 sá»‘ tháº¯c máº¯c nhÆ° sau áº¡ :
1. ""Nháº­n xÃ©t quan trá»ng nháº¥t lÃ  náº¿u ta thay vector há»‡ sá»‘ w bá»Ÿi kw vÃ  b bá»Ÿi kb trong Ä‘Ã³ k lÃ  má»™t háº±ng sá»‘ dÆ°Æ¡ng thÃ¬ máº·t phÃ¢n chia khÃ´ng thay Ä‘á»•i, tá»©c khoáº£ng cÃ¡ch tá»« tá»«ng Ä‘iá»ƒm Ä‘áº¿n máº·t phÃ¢n chia khÃ´ng Ä‘á»•i,"" --> Táº¡i sao láº¡i khoáº£ng cÃ¡ch khÃ´ng Ä‘á»•i áº¡ ? theo em nghÄ© thÃ¬ khoáº£ng cÃ¡ch Ä‘Ã³ váº«n Ä‘á»•i khi ta nhÃ¢n thÃªm 1 sá»‘ k vÃ o chá»© áº¡ ?
2.
""Dá»±a trÃªn tÃ­nh cháº¥t nÃ y, ta cÃ³ thá»ƒ giáº£ sá»­: yn(wTxn+b)=1"". Táº¡i sao mÃ¬nh lai giáº£ sá»­ giÃ¡ trá»‹ nÃ y báº±ng 1. MÃ  sao khÃ´ng lÃ  0.1 hoáº·c lÃ  0.5 áº¡ ? Hay giÃ¡ trá»‹ nÃ o cÅ©ng Ä‘Æ°á»£c miá»…n lÃ  cho triá»‡t tiÃªu Ä‘i biá»ƒu thá»©c yn(wTxn+b) ?
Em cÃ¡m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i em Ä‘ang há»c SVM thÃ´ng qua bÃ i viáº¿t cá»§a anh Tiep. Link blog: https://machinelearningcoban.com/2017/04/09/smv/#-xay-dung-bai-toan-toi-uu-cho-svm Em cÃ³ 1 sá»‘ tháº¯c máº¯c nhÆ° sau áº¡ : 1. ""Nháº­n xÃ©t quan trá»ng nháº¥t lÃ  náº¿u ta thay vector há»‡ sá»‘ w bá»Ÿi kw vÃ  b bá»Ÿi kb trong Ä‘Ã³ k lÃ  má»™t háº±ng sá»‘ dÆ°Æ¡ng thÃ¬ máº·t phÃ¢n chia khÃ´ng thay Ä‘á»•i, tá»©c khoáº£ng cÃ¡ch tá»« tá»«ng Ä‘iá»ƒm Ä‘áº¿n máº·t phÃ¢n chia khÃ´ng Ä‘á»•i,"" --> Táº¡i sao láº¡i khoáº£ng cÃ¡ch khÃ´ng Ä‘á»•i áº¡ ? theo em nghÄ© thÃ¬ khoáº£ng cÃ¡ch Ä‘Ã³ váº«n Ä‘á»•i khi ta nhÃ¢n thÃªm 1 sá»‘ k vÃ o chá»© áº¡ ? 2. ""Dá»±a trÃªn tÃ­nh cháº¥t nÃ y, ta cÃ³ thá»ƒ giáº£ sá»­: yn(wTxn+b)=1"". Táº¡i sao mÃ¬nh lai giáº£ sá»­ giÃ¡ trá»‹ nÃ y báº±ng 1. MÃ  sao khÃ´ng lÃ  0.1 hoáº·c lÃ  0.5 áº¡ ? Hay giÃ¡ trá»‹ nÃ o cÅ©ng Ä‘Æ°á»£c miá»…n lÃ  cho triá»‡t tiÃªu Ä‘i biá»ƒu thá»©c yn(wTxn+b) ? Em cÃ¡m Æ¡n má»i ngÆ°á»i.",#SVM,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang cÃ³ má»™t váº¥n Ä‘á» cáº§n giáº£i quyáº¿t nhÆ° sau, má»™t khÃ¡ch hÃ ng khi apply vÃ o ngÃ¢n hÃ ng cá»§a mÃ¬nh, sáº½ Ä‘Æ°á»£c phÃ¢n vÃ o má»™t loáº¡i campaign Ä‘á»ƒ cÃ³ cÃ¡c promotion kÃ­ch thÃ­ch chi tiÃªu tÆ°Æ¡ng á»©ng.
NhÆ°ng theo thá»i gian, campaign Ä‘Ã³ cÃ³ thá»ƒ sáº½ khÃ´ng cÃ²n chÃ­nh xÃ¡c ná»¯a. MÃ¬nh cáº§n quan sÃ¡t behaviour cá»§a khÃ¡ch hÃ ng, Ä‘á»ƒ cÃ³ thá»ƒ phÃ¢n loáº¡i láº¡i khÃ¡ch hÃ ng vÃ o cÃ¡c campaign phÃ¹ há»£p hÆ¡n, hoáº·c nghÄ© ra cÃ¡c campaign má»›i cho má»™t nhÃ³m khÃ¡ch hÃ ng nÃ o Ä‘Ã³.
MÃ¬nh muá»‘n lÃ m má»™t bÃ i toÃ¡n segmentation khÃ¡ch hÃ ng, dá»±a trÃªn behaviour vá»›i cÃ¡c segment cá»¥ thá»ƒ. MÃ´ hÃ¬nh Kmeans cÃ³ váº» Ä‘Æ°á»£c Æ°a chuá»™ng, nhÆ°ng cÃ¡c báº¡n Ä‘Ã£ thá»±c hÃ nh Kmeans rá»•i cÃ³ thá»ƒ tháº¥y ráº±ng, cÃ¡c phÃ¢n cá»¥m nhiá»…u khÃ¡ nhiá»u, mÃ¬nh khÃ´ng thá»ƒ Ä‘Æ°a ra Ä‘á»‹nh nghÄ©a gÃ¬ cá»¥ thá»ƒ cho nhÃ³m khÃ¡ch hÃ ng Ä‘Ã³. NgoÃ i ra mÃ¬nh cÃ²n ká»³ vá»ng sáº½ build Ä‘Æ°á»£c score cho tá»«ng khÃ¡ch hÃ ng, Ä‘á»ƒ Ä‘o Ä‘á»™ fixed cá»§a khÃ¡ch hÃ ng vá»›i segment, canpaign.
Báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ gá»£i Ã½ má»™t chÃºt vá» mÃ´ hÃ¬nh mÃ¬nh nÃªn dÃ¹ng, hÆ°á»›ng giáº£i quyáº¿t cho bÃ i toÃ¡n trÃªn Ä‘Æ°á»£c khÃ´ng?
Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang cÃ³ má»™t váº¥n Ä‘á» cáº§n giáº£i quyáº¿t nhÆ° sau, má»™t khÃ¡ch hÃ ng khi apply vÃ o ngÃ¢n hÃ ng cá»§a mÃ¬nh, sáº½ Ä‘Æ°á»£c phÃ¢n vÃ o má»™t loáº¡i campaign Ä‘á»ƒ cÃ³ cÃ¡c promotion kÃ­ch thÃ­ch chi tiÃªu tÆ°Æ¡ng á»©ng. NhÆ°ng theo thá»i gian, campaign Ä‘Ã³ cÃ³ thá»ƒ sáº½ khÃ´ng cÃ²n chÃ­nh xÃ¡c ná»¯a. MÃ¬nh cáº§n quan sÃ¡t behaviour cá»§a khÃ¡ch hÃ ng, Ä‘á»ƒ cÃ³ thá»ƒ phÃ¢n loáº¡i láº¡i khÃ¡ch hÃ ng vÃ o cÃ¡c campaign phÃ¹ há»£p hÆ¡n, hoáº·c nghÄ© ra cÃ¡c campaign má»›i cho má»™t nhÃ³m khÃ¡ch hÃ ng nÃ o Ä‘Ã³. MÃ¬nh muá»‘n lÃ m má»™t bÃ i toÃ¡n segmentation khÃ¡ch hÃ ng, dá»±a trÃªn behaviour vá»›i cÃ¡c segment cá»¥ thá»ƒ. MÃ´ hÃ¬nh Kmeans cÃ³ váº» Ä‘Æ°á»£c Æ°a chuá»™ng, nhÆ°ng cÃ¡c báº¡n Ä‘Ã£ thá»±c hÃ nh Kmeans rá»•i cÃ³ thá»ƒ tháº¥y ráº±ng, cÃ¡c phÃ¢n cá»¥m nhiá»…u khÃ¡ nhiá»u, mÃ¬nh khÃ´ng thá»ƒ Ä‘Æ°a ra Ä‘á»‹nh nghÄ©a gÃ¬ cá»¥ thá»ƒ cho nhÃ³m khÃ¡ch hÃ ng Ä‘Ã³. NgoÃ i ra mÃ¬nh cÃ²n ká»³ vá»ng sáº½ build Ä‘Æ°á»£c score cho tá»«ng khÃ¡ch hÃ ng, Ä‘á»ƒ Ä‘o Ä‘á»™ fixed cá»§a khÃ¡ch hÃ ng vá»›i segment, canpaign. Báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ gá»£i Ã½ má»™t chÃºt vá» mÃ´ hÃ¬nh mÃ¬nh nÃªn dÃ¹ng, hÆ°á»›ng giáº£i quyáº¿t cho bÃ i toÃ¡n trÃªn Ä‘Æ°á»£c khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Gáº§n Ä‘Ã¢y, AMD má»›i há»— trá»£ cho cáº£ TensorFLow vÃ  PyTorch qua package cÃ³ tÃªn lÃ  ROCm. KhÃ´ng biáº¿t cÃ³ ai cÃ i thá»­ vÃ  lÃ m benchmark khi trÃªn models trÃªn 2 frameworks phá»• biáº¿n nÃ y chÆ°a nhá»‰? Náº¿u cÃ³, cho xin thÃ´ng tin review nhÃ©. Cáº£m Æ¡n cáº£ nhÃ ","Gáº§n Ä‘Ã¢y, AMD má»›i há»— trá»£ cho cáº£ TensorFLow vÃ  PyTorch qua package cÃ³ tÃªn lÃ  ROCm. KhÃ´ng biáº¿t cÃ³ ai cÃ i thá»­ vÃ  lÃ m benchmark khi trÃªn models trÃªn 2 frameworks phá»• biáº¿n nÃ y chÆ°a nhá»‰? Náº¿u cÃ³, cho xin thÃ´ng tin review nhÃ©. Cáº£m Æ¡n cáº£ nhÃ ",,,,,
"trÆ°á»›c giá» em cÅ©ng cÃ³ lÃ m 1 vÃ i dá»± Ã¡n vá» data science mÃ  chá»§ yáº¿u lÃ  trÃªn python áº¡, giá» em muá»‘n lÃ m trÃªn java nhÆ°ng k biáº¿t cÃ i thÆ° viá»‡n tháº¿ nÃ o do hÆ¡i yáº¿u java, mn cÃ³ ai dÃ¹ng deep4j vÃ  ndarray rá»“i cÃ³ thá»ƒ chá»‰ em khÃ´ng áº¡.","trÆ°á»›c giá» em cÅ©ng cÃ³ lÃ m 1 vÃ i dá»± Ã¡n vá» data science mÃ  chá»§ yáº¿u lÃ  trÃªn python áº¡, giá» em muá»‘n lÃ m trÃªn java nhÆ°ng k biáº¿t cÃ i thÆ° viá»‡n tháº¿ nÃ o do hÆ¡i yáº¿u java, mn cÃ³ ai dÃ¹ng deep4j vÃ  ndarray rá»“i cÃ³ thá»ƒ chá»‰ em khÃ´ng áº¡.",,,,,
CÃ³ ai dÃ¹ng ML Model Binding cá»§a Android Studio cho mÃ¬nh há»i lÃ  cÃ³ option nÃ o tÆ°Æ¡ng tá»± nhÆ° GpuDelegate.setPrecisionLossAllowed khÃ´ng áº¡?,CÃ³ ai dÃ¹ng ML Model Binding cá»§a Android Studio cho mÃ¬nh há»i lÃ  cÃ³ option nÃ o tÆ°Æ¡ng tá»± nhÆ° GpuDelegate.setPrecisionLossAllowed khÃ´ng áº¡?,,,,,
"Hello má»i ngÆ°á»i ğŸ˜ƒ. MÃ¬nh vá»«a táº¡o group vá» MLOps Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ cÃ¹ng nhau chia sáº» kiáº¿n thá»©c vÃ  bÃ n luáº­n xung quanh váº¥n Ä‘á» ""bring ML models into production"". Ai quan tÃ¢m Ä‘áº¿n váº¥n Ä‘á» nÃ y thÃ¬ join cho vui áº¡. Xin cáº£m Æ¡n má»i ngÆ°á»i ğŸ˜ƒ
https://www.facebook.com/groups/240875227766690/","Hello má»i ngÆ°á»i . MÃ¬nh vá»«a táº¡o group vá» MLOps Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ cÃ¹ng nhau chia sáº» kiáº¿n thá»©c vÃ  bÃ n luáº­n xung quanh váº¥n Ä‘á» ""bring ML models into production"". Ai quan tÃ¢m Ä‘áº¿n váº¥n Ä‘á» nÃ y thÃ¬ join cho vui áº¡. Xin cáº£m Æ¡n má»i ngÆ°á»i https://www.facebook.com/groups/240875227766690/",,,,,
"Má»i ngÆ°á»i cho em há»i cÃ´ng thá»©c O(epsilon) á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c nÃ o vÃ  táº¡i sao á»Ÿ cÃ´ng thá»©c (4) ta láº¡i cÃ³ O(epsilon^2) áº¡.
Em xin cáº£m Æ¡n áº¡.",Má»i ngÆ°á»i cho em há»i cÃ´ng thá»©c O(epsilon) á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c nÃ o vÃ  táº¡i sao á»Ÿ cÃ´ng thá»©c (4) ta láº¡i cÃ³ O(epsilon^2) áº¡. Em xin cáº£m Æ¡n áº¡.,,,"#Q&A, #math",,
"[Project khÃ³a Python for Data Science]
MÃ¬nh Ä‘Äƒng nhiá»u project cuá»‘i khÃ³a Data Science á»©ng dá»¥ng trong tÃ i chÃ­nh, ngÃ¢n hÃ ng, thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ rá»“i, nay mÃ¬nh Ä‘Äƒng má»™t sá»‘ project á»©ng dá»¥ng trong tin sinh.
1. á»¨ng dá»¥ng trong phÃ¢n loáº¡i mÃ´ ung thÆ° vÃº dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm hÃ¬nh thÃ¡i.
2. á»¨ng dá»¥ng cháº©n Ä‘oÃ¡n bá»‡nh suy giáº£m trÃ­ nhá»› Alzheimer.","[Project khÃ³a Python for Data Science] MÃ¬nh Ä‘Äƒng nhiá»u project cuá»‘i khÃ³a Data Science á»©ng dá»¥ng trong tÃ i chÃ­nh, ngÃ¢n hÃ ng, thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ rá»“i, nay mÃ¬nh Ä‘Äƒng má»™t sá»‘ project á»©ng dá»¥ng trong tin sinh. 1. á»¨ng dá»¥ng trong phÃ¢n loáº¡i mÃ´ ung thÆ° vÃº dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm hÃ¬nh thÃ¡i. 2. á»¨ng dá»¥ng cháº©n Ä‘oÃ¡n bá»‡nh suy giáº£m trÃ­ nhá»› Alzheimer.",,,,,
Em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» xÃ¡c Ä‘á»‹nh lÆ°á»£ng tÆ°á»›i nÆ°á»›c cho khu vÆ°á»n. CÃ¡c bÃ¡c cÃ³ thá»ƒ gá»£i Ã½ cho em sá»­ dá»¥ng dataset nÃ o vá»›i?,Em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» xÃ¡c Ä‘á»‹nh lÆ°á»£ng tÆ°á»›i nÆ°á»›c cho khu vÆ°á»n. CÃ¡c bÃ¡c cÃ³ thá»ƒ gá»£i Ã½ cho em sá»­ dá»¥ng dataset nÃ o vá»›i?,,,,,
"Má»i ngÆ°á»i cho em há»i chÃºt: Em Ä‘ang test thá»­ self supervised learning sá»­ dá»¥ng cifar10 dataset. Em Ä‘á»‹nh dÃ¹ng resnet34 bá» Ä‘i layer cuá»‘i Ä‘á»ƒ láº¥y features vector r dÃ¹ng clustering (kmeans, kmedoids) phÃ¢n cá»¥m thÃ nh cÃ¡c class. Tháº¿ nhÆ°ng cÃ³ viá»‡c ráº¥t láº¡ lÃ  khi em test trÃªn pytorch thÃ¬ kmeans + resnet34 cháº¡y khÃ¡ á»•n, Ã­t nháº¥t nÃ³ táº¡o Ä‘Æ°á»£c 10 cá»¥m cho 10 class trÃªn cifar10 mÃ  Ä‘a sá»‘ sample má»—i cluster cÃ³ cÃ¹ng class, nhÆ°ng khi em chuyá»ƒn qua tensorflow keras thÃ¬ kmeans khÃ´ng phÃ¢n cá»¥m tá»‘t Ä‘Æ°á»£c nhÆ° váº­y, vÃ  hÆ¡n ná»¯a em tháº¥y resnet trÃªn keras vÃ  pytorch cÃ³ váº» khÃ¡c biá»‡t vÃ i layer, VD nhÆ° bÃªn pytorch cÃ³ AdaptAver/Pool layer nhÆ°ng bÃªn keras thÃ¬ khÃ´ng. CÃ³ ai tá»«ng test thá»­ 1 thÃ­ nghiá»‡m tÆ°Æ¡ng tá»± cÃ³ thá»ƒ giÃºp em giáº£i Ä‘Ã¡p máº¥y váº¥n Ä‘á» nÃ y khÃ´ng?","Má»i ngÆ°á»i cho em há»i chÃºt: Em Ä‘ang test thá»­ self supervised learning sá»­ dá»¥ng cifar10 dataset. Em Ä‘á»‹nh dÃ¹ng resnet34 bá» Ä‘i layer cuá»‘i Ä‘á»ƒ láº¥y features vector r dÃ¹ng clustering (kmeans, kmedoids) phÃ¢n cá»¥m thÃ nh cÃ¡c class. Tháº¿ nhÆ°ng cÃ³ viá»‡c ráº¥t láº¡ lÃ  khi em test trÃªn pytorch thÃ¬ kmeans + resnet34 cháº¡y khÃ¡ á»•n, Ã­t nháº¥t nÃ³ táº¡o Ä‘Æ°á»£c 10 cá»¥m cho 10 class trÃªn cifar10 mÃ  Ä‘a sá»‘ sample má»—i cluster cÃ³ cÃ¹ng class, nhÆ°ng khi em chuyá»ƒn qua tensorflow keras thÃ¬ kmeans khÃ´ng phÃ¢n cá»¥m tá»‘t Ä‘Æ°á»£c nhÆ° váº­y, vÃ  hÆ¡n ná»¯a em tháº¥y resnet trÃªn keras vÃ  pytorch cÃ³ váº» khÃ¡c biá»‡t vÃ i layer, VD nhÆ° bÃªn pytorch cÃ³ AdaptAver/Pool layer nhÆ°ng bÃªn keras thÃ¬ khÃ´ng. CÃ³ ai tá»«ng test thá»­ 1 thÃ­ nghiá»‡m tÆ°Æ¡ng tá»± cÃ³ thá»ƒ giÃºp em giáº£i Ä‘Ã¡p máº¥y váº¥n Ä‘á» nÃ y khÃ´ng?",,,,,
"#selfsupervised_learning
Xin chÃ o táº¥t cáº£ cÃ¡c tiá»n bá»‘i. MÃ¬nh lÃ  ngÆ°á»i má»›i. MÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» vá» viá»‡c build 1 model báº±ng self supervised learning.
MÃ¬nh cÃ³ thá»ƒ build Ä‘Æ°á»£c cÃ¡c model supervised or unsupervised. NhÆ°ng mÃ¬nh váº«n khÃ´ng biáº¿t Ä‘Æ°á»£c nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u Ä‘á»ƒ lÃ m Ä‘Æ°á»£c 1 model self-supervised. MÃ¬nh Ä‘Æ°á»£c biáº¿t lÃ  nÃ³ tá»± gáº¯n nhÃ£n cho 1 pháº§n data chÆ°a dÃ¡n nhÃ£n. Tháº­t sá»± khÃ´ng tÃ¬m Ä‘Æ°á»£c báº¥t cá»© má»™t hÆ°á»›ng dáº«n nÃ o cá»¥ thá»ƒ. Mong Ä‘Æ°á»£c má»i ngÆ°á»i chá»‰ giÃ¡o?",Xin chÃ o táº¥t cáº£ cÃ¡c tiá»n bá»‘i. MÃ¬nh lÃ  ngÆ°á»i má»›i. MÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» vá» viá»‡c build 1 model báº±ng self supervised learning. MÃ¬nh cÃ³ thá»ƒ build Ä‘Æ°á»£c cÃ¡c model supervised or unsupervised. NhÆ°ng mÃ¬nh váº«n khÃ´ng biáº¿t Ä‘Æ°á»£c nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u Ä‘á»ƒ lÃ m Ä‘Æ°á»£c 1 model self-supervised. MÃ¬nh Ä‘Æ°á»£c biáº¿t lÃ  nÃ³ tá»± gáº¯n nhÃ£n cho 1 pháº§n data chÆ°a dÃ¡n nhÃ£n. Tháº­t sá»± khÃ´ng tÃ¬m Ä‘Æ°á»£c báº¥t cá»© má»™t hÆ°á»›ng dáº«n nÃ o cá»¥ thá»ƒ. Mong Ä‘Æ°á»£c má»i ngÆ°á»i chá»‰ giÃ¡o?,#selfsupervised_learning,,,,
"em chÃ o anh/ chá»‹ áº¡?
em cÃ³ 1 cÃ¢u há»i mong ac giáº£i Ä‘Ã¡p.
Cháº³ng háº¡n e cÃ³ má»™t máº¡ng segmentation vÃ  má»™t bá»™ dá»¯ liá»‡u. giá» e muá»‘n Ä‘Æ°a toÃ n bá»™ dá»¯ liá»‡u qua máº¡ng Ä‘á»ƒ segment, output lÃ  nhá»¯ng mask(áº£nh) cá»§a pháº§n tá»­ cáº§n segment thÃ¬ lÃ m tháº¿ nÃ o Ä‘á»ƒ em thá»±c hiá»‡n viá»‡c Ä‘Æ°a toÃ n bá»™ áº£nh vÃ o vÃ  lÆ°u láº¡i nhá»¯ng áº£nh output Ä‘Ã³ ra 1 file áº¡? em cáº£m Æ¡n","em chÃ o anh/ chá»‹ áº¡? em cÃ³ 1 cÃ¢u há»i mong ac giáº£i Ä‘Ã¡p. Cháº³ng háº¡n e cÃ³ má»™t máº¡ng segmentation vÃ  má»™t bá»™ dá»¯ liá»‡u. giá» e muá»‘n Ä‘Æ°a toÃ n bá»™ dá»¯ liá»‡u qua máº¡ng Ä‘á»ƒ segment, output lÃ  nhá»¯ng mask(áº£nh) cá»§a pháº§n tá»­ cáº§n segment thÃ¬ lÃ m tháº¿ nÃ o Ä‘á»ƒ em thá»±c hiá»‡n viá»‡c Ä‘Æ°a toÃ n bá»™ áº£nh vÃ o vÃ  lÆ°u láº¡i nhá»¯ng áº£nh output Ä‘Ã³ ra 1 file áº¡? em cáº£m Æ¡n",,,,,
á» Má»¹ thÃ¬ thÃ´ng thÆ°á»ng 1 loáº¡i thuá»‘c má»›i sáº½ máº¥t hÆ¡n 10 nÄƒm Ä‘á»ƒ Ä‘i tá»« Ã½ tÆ°á»Ÿng cho Ä‘áº¿n khi Ä‘Æ°á»£c phÃ©p sáº£n xuáº¥t Ä‘áº¡i trÃ . Hi vá»ng lÃ  AI cÃ³ thá»ƒ giÃºp Ä‘áº©y nhanh quÃ¡ trÃ¬nh nÃ y trong tÆ°Æ¡ng lai khÃ´ng xa :),á» Má»¹ thÃ¬ thÃ´ng thÆ°á»ng 1 loáº¡i thuá»‘c má»›i sáº½ máº¥t hÆ¡n 10 nÄƒm Ä‘á»ƒ Ä‘i tá»« Ã½ tÆ°á»Ÿng cho Ä‘áº¿n khi Ä‘Æ°á»£c phÃ©p sáº£n xuáº¥t Ä‘áº¡i trÃ . Hi vá»ng lÃ  AI cÃ³ thá»ƒ giÃºp Ä‘áº©y nhanh quÃ¡ trÃ¬nh nÃ y trong tÆ°Æ¡ng lai khÃ´ng xa :),,,,,
"Sá»­ dá»¥ng cross validation/nested cross validation vÃ  early stopping cÃ¹ng lÃºc Ä‘á»ƒ tuning cÃ¡c siÃªu tham sá»‘ vÃ  lá»±a chá»n mÃ´ hÃ¬nh cho neural network?
ChÃ o má»i ngÆ°á»i, mÃ¬nh/em cÃ³ Ä‘á»c má»™t bÃ i trÃªn machinelearningmastery cÃ³ nÃ³i vá» viá»‡c khÃ´ng nÃªn dÃ¹ng early stopping khi sá»­ dá»¥ng cross validation, khÃ´ng biáº¿t quan Ä‘iá»ƒm cá»§a má»i ngÆ°á»i nhÆ° tháº¿ nÃ o vá» váº¥n Ä‘á» nÃ y áº¡?","Sá»­ dá»¥ng cross validation/nested cross validation vÃ  early stopping cÃ¹ng lÃºc Ä‘á»ƒ tuning cÃ¡c siÃªu tham sá»‘ vÃ  lá»±a chá»n mÃ´ hÃ¬nh cho neural network? ChÃ o má»i ngÆ°á»i, mÃ¬nh/em cÃ³ Ä‘á»c má»™t bÃ i trÃªn machinelearningmastery cÃ³ nÃ³i vá» viá»‡c khÃ´ng nÃªn dÃ¹ng early stopping khi sá»­ dá»¥ng cross validation, khÃ´ng biáº¿t quan Ä‘iá»ƒm cá»§a má»i ngÆ°á»i nhÆ° tháº¿ nÃ o vá» váº¥n Ä‘á» nÃ y áº¡?",,,,,
"[AI Share]
Tá»•ng há»£p cÃ¡c cÃ¢u há»i vá» má»™t sá»‘ topic vá» AI:
1. Top 100 cÃ¢u há»i vá» NLP :
https://drive.google.com/file/d/1L_9FKt10dWnzTnM0DJdQrU3Esf1f5_c5/view?fbclid=IwAR0uefXEPQWoZv0YG3YDZh4b8uH7g_OVNKKV2Vrk3ypJtjVvlcLR4cV_9wc
2. Top 100 cÃ¢u há»i vá» ML:
https://drive.google.com/file/d/1tIijzF1-OsRJciklC9XAg-Iyo__d2gaK/view?fbclid=IwAR3rszMons6v9da5dNlIf0VmC7v0KnEDgmN4lWYoX0xYQwr5FfVsGRIhMYM
3. CÃ¢u há»i vá» Data Science, Statistic, Data Analysis, Machine Learning, Deep Learning:
https://drive.google.com/file/d/1AxwUKd4onP4ZYFctzYcAju_JfU9l8wfD/view?usp=drivesdk
4. CÃ¢u há»i vá» Python:
https://drive.google.com/file/d/1yLnNMrxArqkQJIl_NpgN7NSOG4bfedv8/view?fbclid=IwAR0WVSPUqsTyC4cLSdX1I8_qT5q0W9eQtt0buPkc003NA4Nk-lmSnImid_4
Nguá»“n: https://www.linkedin.com/public-profile/in/stevenouri","[AI Share] Tá»•ng há»£p cÃ¡c cÃ¢u há»i vá» má»™t sá»‘ topic vá» AI: 1. Top 100 cÃ¢u há»i vá» NLP : https://drive.google.com/file/d/1L_9FKt10dWnzTnM0DJdQrU3Esf1f5_c5/view?fbclid=IwAR0uefXEPQWoZv0YG3YDZh4b8uH7g_OVNKKV2Vrk3ypJtjVvlcLR4cV_9wc 2. Top 100 cÃ¢u há»i vá» ML: https://drive.google.com/file/d/1tIijzF1-OsRJciklC9XAg-Iyo__d2gaK/view?fbclid=IwAR3rszMons6v9da5dNlIf0VmC7v0KnEDgmN4lWYoX0xYQwr5FfVsGRIhMYM 3. CÃ¢u há»i vá» Data Science, Statistic, Data Analysis, Machine Learning, Deep Learning: https://drive.google.com/file/d/1AxwUKd4onP4ZYFctzYcAju_JfU9l8wfD/view?usp=drivesdk 4. CÃ¢u há»i vá» Python: https://drive.google.com/file/d/1yLnNMrxArqkQJIl_NpgN7NSOG4bfedv8/view?fbclid=IwAR0WVSPUqsTyC4cLSdX1I8_qT5q0W9eQtt0buPkc003NA4Nk-lmSnImid_4 Nguá»“n: https://www.linkedin.com/public-profile/in/stevenouri",,,,,
Má»i cÃ¡c báº¡n join seminar bÃ¢y giá»: https://fpt-software.webex.com/fpt-software/onstage/g.php?MTID=ea41cf8ef8a7703f59c66de12fa71e795,Má»i cÃ¡c báº¡n join seminar bÃ¢y giá»: https://fpt-software.webex.com/fpt-software/onstage/g.php?MTID=ea41cf8ef8a7703f59c66de12fa71e795,,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 2 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 2 vÃ o comment cá»§a post nÃ y.",,,,,
"ChÃ o Anh, Chá»‹, Em cÃ³ tháº¯c máº¯c vá» mÃ´ hÃ¬nh arima cá»¥ thá»ƒ nhÆ° sau nhá» anh chá»‹ giÃºp em vá»›i áº¡.
Em cÃ³ táº­p train gá»“m 2000 Ä‘iá»ƒm dá»¯ liá»‡u vÃ  test 544 Ä‘iá»ƒm dá»¯ liá»‡u
em cÃ³ sá»­ dá»¥ng thÆ° viá»‡n statsmodels Ä‘á»ƒ lÃ m nhÆ° hÃ¬nh. cÃ¡c há»‡ sá»‘ p,d,q em chá»n lÃ  3,1,2 ( Ä‘Ã¢y cÅ©ng lÃ  mÃ´ hÃ¬nh tá»‘i Æ°u).
Hiá»‡n táº¡i em chÆ°a hiá»ƒu Ä‘Æ°á»£c cÃ¡ch váº­n hÃ nh cá»§a Ä‘oáº¡n code nÃ y khi train vá»›i 2000 Ä‘iá»ƒm vÃ  Ä‘oÃ¡n 544 Ä‘iá»ƒm dá»¯ liá»‡u má»›i thÃ¬ thÆ° viá»‡n statsmodel sáº½ tÃ­nh toÃ¡n ntn áº¡.
Náº¿u cÃ³ Anh, Chá»‹ nÃ o rÃ nh vá» pháº§n nÃ y giáº£i thÃ­ch giÃºp em vá»›i áº¡. E cáº£m Æ¡n ráº¥t nhiá»u.","ChÃ o Anh, Chá»‹, Em cÃ³ tháº¯c máº¯c vá» mÃ´ hÃ¬nh arima cá»¥ thá»ƒ nhÆ° sau nhá» anh chá»‹ giÃºp em vá»›i áº¡. Em cÃ³ táº­p train gá»“m 2000 Ä‘iá»ƒm dá»¯ liá»‡u vÃ  test 544 Ä‘iá»ƒm dá»¯ liá»‡u em cÃ³ sá»­ dá»¥ng thÆ° viá»‡n statsmodels Ä‘á»ƒ lÃ m nhÆ° hÃ¬nh. cÃ¡c há»‡ sá»‘ p,d,q em chá»n lÃ  3,1,2 ( Ä‘Ã¢y cÅ©ng lÃ  mÃ´ hÃ¬nh tá»‘i Æ°u). Hiá»‡n táº¡i em chÆ°a hiá»ƒu Ä‘Æ°á»£c cÃ¡ch váº­n hÃ nh cá»§a Ä‘oáº¡n code nÃ y khi train vá»›i 2000 Ä‘iá»ƒm vÃ  Ä‘oÃ¡n 544 Ä‘iá»ƒm dá»¯ liá»‡u má»›i thÃ¬ thÆ° viá»‡n statsmodel sáº½ tÃ­nh toÃ¡n ntn áº¡. Náº¿u cÃ³ Anh, Chá»‹ nÃ o rÃ nh vá» pháº§n nÃ y giáº£i thÃ­ch giÃºp em vá»›i áº¡. E cáº£m Æ¡n ráº¥t nhiá»u.",,,,,
"Lá»™ diá»‡n khÃ¡ch má»i Ä‘áº§u tiÃªn sáº½ tham gia ğ–ğğ›ğ¢ğ§ğšğ« ""ğ€ğˆ ğˆğ ğ€ğ‚ğ“ğˆğğ: ğˆğ§ğğ®ğ¬ğ­ğ«ğ¢ğšğ¥ ğ®ğ¬ğ ğœğšğ¬ğğ¬""
ğŸŒŸModerator: Nguyá»…n XuÃ¢n Phong
AI Scientist at Hitachi & Mila - Quebec AI Institute
__________________
Anh Phong tá»‘t nghiá»‡p Carnegie Mellon University (CMU) - má»™t trong nhá»¯ng trÆ°á»ng náº±m top Ä‘áº§u tháº¿ giá»›i vá» cÃ´ng nghá»‡ thÃ´ng tin.
NÄƒm 2013, sau thá»i gian thá»±c táº­p á»Ÿ táº­p Ä‘oÃ n Hitachi cá»§a Nháº­t Báº£n, anh Phong Ä‘Æ°á»£c má»i lÃ m viá»‡c táº¡i Trung tÃ¢m NghiÃªn cá»©u vÃ  PhÃ¡t triá»ƒn, nÆ¡i Ä‘Æ°á»£c coi lÃ  bá»™ nÃ£o cá»§a táº­p Ä‘oÃ n. Táº¡i táº­p Ä‘oÃ n Hitachi anh Phong trá»Ÿ thÃ nh má»™t trong nhá»¯ng chuyÃªn gia hÃ ng Ä‘áº§u vá» AI. NÄƒm 24 tuá»•i, anh Phong trá»Ÿ thÃ nh má»™t trong 50 nhÃ  khoa há»c hÃ ng Ä‘áº§u cá»§a táº­p Ä‘oÃ n Hitachi.
8 nÄƒm lÃ m viá»‡c táº¡i Nháº­t, anh Phong tiáº¿p tá»¥c nghiÃªn cá»©u sÃ¢u vá» AI vÃ  láº¥y báº±ng Tiáº¿n sÄ© táº¡i Äáº¡i há»c Tokyo ngÃ nh TrÃ­ tuá»‡ NhÃ¢n táº¡o á»©ng dá»¥ng.
NÄƒm 30 tuá»•i, anh Phong Ä‘Æ°á»£c táº­p Ä‘oÃ n cá»­ sang Mila (Canada), lÃ m viá»‡c táº¡i viá»‡n nghiÃªn cá»©u TrÃ­ tuá»‡ NhÃ¢n táº¡o hÃ ng Ä‘áº§u tháº¿ giá»›i. Táº¡i Ä‘Ã¢y, anh Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  trao Ä‘á»•i trá»±c tiáº¿p vá»›i giÃ¡o sÆ° Yoshua Bengio, ngÆ°á»i tá»«ng Ä‘oáº¡t giáº£i ACM A.M. Turing Award - giáº£i thÆ°á»Ÿng Ä‘Æ°á»£c vÃ­ nhÆ° giáº£i Nobel trong ngÃ nh khoa há»c mÃ¡y tÃ­nh.
Tham gia Webinar vá»›i vai trÃ² Moderator, anh Phong sáº½ káº¿t ná»‘i cÃ¢u chuyá»‡n cá»§a cÃ¡c diá»…n giáº£, giÃºp ngÆ°á»i tham gia cÃ³ nhá»¯ng gÃ³c nhÃ¬n tá»•ng quan hÆ¡n vá» chÆ°Æ¡ng trÃ¬nh.
___________________________
ThÃ´ng tin vá» event:
â° Thá»i gian diá»…n ra sá»± kiá»‡n: 14:00 JST, thá»© 7, ngÃ y 27 thÃ¡ng 03 nÄƒm 2021
ğŸ’» HÃ¬nh thá»©c tá»• chá»©c: Online (Qua Webex)
ğŸ“¥ ÄÄƒng kÃ½ táº¡i: https://www.surveymonkey.com/r/AiInAction
ğŸ“§ Má»i tháº¯c máº¯c vui lÃ²ng liÃªn há»‡: Fage FPT Japan Holdings","Lá»™ diá»‡n khÃ¡ch má»i Ä‘áº§u tiÃªn sáº½ tham gia "" : "" Moderator: Nguyá»…n XuÃ¢n Phong AI Scientist at Hitachi & Mila - Quebec AI Institute __________________ Anh Phong tá»‘t nghiá»‡p Carnegie Mellon University (CMU) - má»™t trong nhá»¯ng trÆ°á»ng náº±m top Ä‘áº§u tháº¿ giá»›i vá» cÃ´ng nghá»‡ thÃ´ng tin. NÄƒm 2013, sau thá»i gian thá»±c táº­p á»Ÿ táº­p Ä‘oÃ n Hitachi cá»§a Nháº­t Báº£n, anh Phong Ä‘Æ°á»£c má»i lÃ m viá»‡c táº¡i Trung tÃ¢m NghiÃªn cá»©u vÃ  PhÃ¡t triá»ƒn, nÆ¡i Ä‘Æ°á»£c coi lÃ  bá»™ nÃ£o cá»§a táº­p Ä‘oÃ n. Táº¡i táº­p Ä‘oÃ n Hitachi anh Phong trá»Ÿ thÃ nh má»™t trong nhá»¯ng chuyÃªn gia hÃ ng Ä‘áº§u vá» AI. NÄƒm 24 tuá»•i, anh Phong trá»Ÿ thÃ nh má»™t trong 50 nhÃ  khoa há»c hÃ ng Ä‘áº§u cá»§a táº­p Ä‘oÃ n Hitachi. 8 nÄƒm lÃ m viá»‡c táº¡i Nháº­t, anh Phong tiáº¿p tá»¥c nghiÃªn cá»©u sÃ¢u vá» AI vÃ  láº¥y báº±ng Tiáº¿n sÄ© táº¡i Äáº¡i há»c Tokyo ngÃ nh TrÃ­ tuá»‡ NhÃ¢n táº¡o á»©ng dá»¥ng. NÄƒm 30 tuá»•i, anh Phong Ä‘Æ°á»£c táº­p Ä‘oÃ n cá»­ sang Mila (Canada), lÃ m viá»‡c táº¡i viá»‡n nghiÃªn cá»©u TrÃ­ tuá»‡ NhÃ¢n táº¡o hÃ ng Ä‘áº§u tháº¿ giá»›i. Táº¡i Ä‘Ã¢y, anh Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  trao Ä‘á»•i trá»±c tiáº¿p vá»›i giÃ¡o sÆ° Yoshua Bengio, ngÆ°á»i tá»«ng Ä‘oáº¡t giáº£i ACM A.M. Turing Award - giáº£i thÆ°á»Ÿng Ä‘Æ°á»£c vÃ­ nhÆ° giáº£i Nobel trong ngÃ nh khoa há»c mÃ¡y tÃ­nh. Tham gia Webinar vá»›i vai trÃ² Moderator, anh Phong sáº½ káº¿t ná»‘i cÃ¢u chuyá»‡n cá»§a cÃ¡c diá»…n giáº£, giÃºp ngÆ°á»i tham gia cÃ³ nhá»¯ng gÃ³c nhÃ¬n tá»•ng quan hÆ¡n vá» chÆ°Æ¡ng trÃ¬nh. ___________________________ ThÃ´ng tin vá» event: â° Thá»i gian diá»…n ra sá»± kiá»‡n: 14:00 JST, thá»© 7, ngÃ y 27 thÃ¡ng 03 nÄƒm 2021 HÃ¬nh thá»©c tá»• chá»©c: Online (Qua Webex) ÄÄƒng kÃ½ táº¡i: https://www.surveymonkey.com/r/AiInAction Má»i tháº¯c máº¯c vui lÃ²ng liÃªn há»‡: Fage FPT Japan Holdings",,,,,
"chÃ o má»i ngÆ°á»i
hiá»‡n mÃ¡y mÃ¬nh gáº·p váº¥n Ä‘á» lÃ  : code thÃ¬ cháº¡y Ä‘Æ°á»£c nhÆ°ng khi gÃµ from tensforflow. thÃ¬ nÃ³ khÃ´ng hiá»‡n suggestion, bÃ¡o gáº¡ch chÃ¢n code nhÆ° nÃ y, mÃ¬nh tÃ¬m cÃ¡ch sá»­a khÃ´ng Ä‘Æ°á»£c, Báº¡n nÃ o biáº¿t nguyÃªn nhÃ¢n ko áº¡?
chá»‰ cÃ³ lá»‡nh from tensforflow. lÃ  nÃ³ khÃ´ng hiá»‡n suggestion cÃ²n cÃ¡c lá»‡nh khÃ¡c thÃ¬ bÃ¬nh thÆ°á»ng.","chÃ o má»i ngÆ°á»i hiá»‡n mÃ¡y mÃ¬nh gáº·p váº¥n Ä‘á» lÃ  : code thÃ¬ cháº¡y Ä‘Æ°á»£c nhÆ°ng khi gÃµ from tensforflow. thÃ¬ nÃ³ khÃ´ng hiá»‡n suggestion, bÃ¡o gáº¡ch chÃ¢n code nhÆ° nÃ y, mÃ¬nh tÃ¬m cÃ¡ch sá»­a khÃ´ng Ä‘Æ°á»£c, Báº¡n nÃ o biáº¿t nguyÃªn nhÃ¢n ko áº¡? chá»‰ cÃ³ lá»‡nh from tensforflow. lÃ  nÃ³ khÃ´ng hiá»‡n suggestion cÃ²n cÃ¡c lá»‡nh khÃ¡c thÃ¬ bÃ¬nh thÆ°á»ng.",,,,,
"Em chÃ o anh chá»‹ áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á» Ã¡n vá» machine learning, anh chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p cho em 1 sá»‘ cÃ¢u há»i khÃ´ng áº¡?
1. Thuáº­t toÃ¡n phÃ¢n lá»›p cÃ³ nhÃ£n lÃ  thuáº­t toÃ¡n nhÆ° tháº¿ nÃ o áº¡?
2. Sá»­ dá»¥ng 70% Ä‘á»ƒ learning vÃ  30% Ä‘á»ƒ quan sÃ¡t nghÄ©a lÃ  sao áº¡!
Em cáº£m Æ¡n anh chá»‹ ráº¥t nhiá»u áº¡!","Em chÃ o anh chá»‹ áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á» Ã¡n vá» machine learning, anh chá»‹ cÃ³ thá»ƒ giáº£i Ä‘Ã¡p cho em 1 sá»‘ cÃ¢u há»i khÃ´ng áº¡? 1. Thuáº­t toÃ¡n phÃ¢n lá»›p cÃ³ nhÃ£n lÃ  thuáº­t toÃ¡n nhÆ° tháº¿ nÃ o áº¡? 2. Sá»­ dá»¥ng 70% Ä‘á»ƒ learning vÃ  30% Ä‘á»ƒ quan sÃ¡t nghÄ©a lÃ  sao áº¡! Em cáº£m Æ¡n anh chá»‹ ráº¥t nhiá»u áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang code láº¡i cÃ¡i Linformer, theo paper nÃ y https://arxiv.org/pdf/2006.04768.pdf. Má»i thá»© cÃ³ váº» á»•n Ä‘áº¿n khi mÃ¬nh thiáº¿t káº¿ mask. Náº¿u trong Transformer thÃ¬ attention score sáº½ cÃ³ dimension lÃ  TxT vá»›i T lÃ  Ä‘á»™ dÃ i cá»§a chuá»—i, thÃ¬ giá» vá»›i Linformer, attention score lÃ  Txk vá»›i k lÃ  má»™t sá»‘ chá»n trÆ°á»›c. MÃ¬nh Ä‘ang tháº¯c máº¯c khÃ´ng biáº¿t lÃ m cÃ¡ch nÃ o Ä‘á»ƒ thiáº¿t káº¿ mask cho cÃ¡i nÃ y, nháº¥t lÃ  memory mask. Mong gá»i Ã½ tá»« má»i ngÆ°á»i.
Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang code láº¡i cÃ¡i Linformer, theo paper nÃ y https://arxiv.org/pdf/2006.04768.pdf. Má»i thá»© cÃ³ váº» á»•n Ä‘áº¿n khi mÃ¬nh thiáº¿t káº¿ mask. Náº¿u trong Transformer thÃ¬ attention score sáº½ cÃ³ dimension lÃ  TxT vá»›i T lÃ  Ä‘á»™ dÃ i cá»§a chuá»—i, thÃ¬ giá» vá»›i Linformer, attention score lÃ  Txk vá»›i k lÃ  má»™t sá»‘ chá»n trÆ°á»›c. MÃ¬nh Ä‘ang tháº¯c máº¯c khÃ´ng biáº¿t lÃ m cÃ¡ch nÃ o Ä‘á»ƒ thiáº¿t káº¿ mask cho cÃ¡i nÃ y, nháº¥t lÃ  memory mask. Mong gá»i Ã½ tá»« má»i ngÆ°á»i. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c vá» TFLite nÃªn máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng anh em tiáº¿p series vá» triá»ƒn khai model lÃªn cÃ¡c thiáº¿t bá»‹ Ä‘áº§u cuá»‘i. HÃ´m nay sáº½ lÃ  triá»ƒn khai model lÃªn mobile báº±ng TFLite nhÃ©! Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c.
Cáº£m Æ¡n cÃ¡c bÃ¡c vÃ  mong admin duyá»‡t bÃ i!",KÃ­nh chÃ o cÃ¡c bÃ¡c. Em Ä‘ang há»c vá» TFLite nÃªn máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng anh em tiáº¿p series vá» triá»ƒn khai model lÃªn cÃ¡c thiáº¿t bá»‹ Ä‘áº§u cuá»‘i. HÃ´m nay sáº½ lÃ  triá»ƒn khai model lÃªn mobile báº±ng TFLite nhÃ©! Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c. Cáº£m Æ¡n cÃ¡c bÃ¡c vÃ  mong admin duyá»‡t bÃ i!,,,,,
"ChÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n. Em cÃ³ má»™t bÃ i toÃ¡n tháº¿ nÃ y: dá»± Ä‘oÃ¡n giÃ¡ trá»‹ cá»§a báº¥t Ä‘á»™ng sáº£n táº¡i tp HCM trong tÆ°Æ¡ng lai gáº§n. Hiá»‡n táº¡i bá»n em Ä‘Ã£ crawl Ä‘Æ°á»£c data tá»« 09.03.2021, cÃ³ khoáº£ng 700k samples. Tuy nhiÃªn khi Ä‘Æ°a vÃ o bÃ i toÃ¡n time-series thÃ¬ em Ä‘ang bá»‹ cá»¥t Ä‘Æ°á»ng. Cá»¥ thá»ƒ hÆ°á»›ng giáº£i quyáº¿t cá»§a em lÃ  tháº¿ nÃ y: em sáº½ cluster data ra thÃ nh 5 clusters tÃ¹y theo features. Trong má»—i cluster, em láº¥y giÃ¡ trá»‹ trung bÃ¬nh, cáº­n trÃªn vÃ  cáº­n dÆ°á»›i Ä‘á»ƒ táº¡o thÃ nh time-series data. Bá»n em khÃ´ng cÃ³ Ä‘Æ°á»£c lá»‹ch sá»­ giÃ¡ nhÃ  bÃ¡n. Em muá»‘n há»i má»i ngÆ°á»i cÃ¡c giáº£i quyáº¿t áº¡.
Em cÃ²n suy nghÄ© khÃ¡c lÃ  dá»±a vÃ o nhá»¯ng thÃ´ng tin cÃ³ lá»‹ch sá»­: GDP, sá»‘ lÆ°á»£ng báº¥t Ä‘á»™ng sáº£n bÃ¡n/mua, sá»‘ lÆ°á»£ng cÃ´ng ty báº¥t Ä‘á»™ng sáº£n thÃ nh láº­p/giáº£i tháº¿ Ä‘á»ƒ há»— trá»£. Em cÃ³ tÃ¬m Ä‘á»c nhÆ°ng tá»‘i Ä‘Æ°á»ng. Em cÃ¡m Æ¡n áº¡.","ChÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n. Em cÃ³ má»™t bÃ i toÃ¡n tháº¿ nÃ y: dá»± Ä‘oÃ¡n giÃ¡ trá»‹ cá»§a báº¥t Ä‘á»™ng sáº£n táº¡i tp HCM trong tÆ°Æ¡ng lai gáº§n. Hiá»‡n táº¡i bá»n em Ä‘Ã£ crawl Ä‘Æ°á»£c data tá»« 09.03.2021, cÃ³ khoáº£ng 700k samples. Tuy nhiÃªn khi Ä‘Æ°a vÃ o bÃ i toÃ¡n time-series thÃ¬ em Ä‘ang bá»‹ cá»¥t Ä‘Æ°á»ng. Cá»¥ thá»ƒ hÆ°á»›ng giáº£i quyáº¿t cá»§a em lÃ  tháº¿ nÃ y: em sáº½ cluster data ra thÃ nh 5 clusters tÃ¹y theo features. Trong má»—i cluster, em láº¥y giÃ¡ trá»‹ trung bÃ¬nh, cáº­n trÃªn vÃ  cáº­n dÆ°á»›i Ä‘á»ƒ táº¡o thÃ nh time-series data. Bá»n em khÃ´ng cÃ³ Ä‘Æ°á»£c lá»‹ch sá»­ giÃ¡ nhÃ  bÃ¡n. Em muá»‘n há»i má»i ngÆ°á»i cÃ¡c giáº£i quyáº¿t áº¡. Em cÃ²n suy nghÄ© khÃ¡c lÃ  dá»±a vÃ o nhá»¯ng thÃ´ng tin cÃ³ lá»‹ch sá»­: GDP, sá»‘ lÆ°á»£ng báº¥t Ä‘á»™ng sáº£n bÃ¡n/mua, sá»‘ lÆ°á»£ng cÃ´ng ty báº¥t Ä‘á»™ng sáº£n thÃ nh láº­p/giáº£i tháº¿ Ä‘á»ƒ há»— trá»£. Em cÃ³ tÃ¬m Ä‘á»c nhÆ°ng tá»‘i Ä‘Æ°á»ng. Em cÃ¡m Æ¡n áº¡.",,,,,
"Em lÃ  sinh viÃªn chuyÃªn ngÃ nh vá» Ä‘iá»‡n tá»­ - viá»…n thÃ´ng. Má»›i nháº­p mÃ´n vá» ML, DL trong 2 thÃ¡ng. Äá»‹nh hÆ°á»›ng cá»§a em lÃ  sáº½ Ä‘i theo hÆ°á»›ng Computer Vision engineer vÃ¬ em nghÄ© nÃ³ liÃªn quan Ä‘áº¿n cÃ¡c á»©ng dá»¥ng bÃªn chuyÃªn ngÃ nh em nhiá»u nháº¥t.
Hiá»‡n em Ä‘Ã£ Ä‘á»c hiá»ƒu háº§u háº¿t cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n cá»§a Machine Learning, hiá»ƒu Ä‘Æ°á»£c cÃ¡c cáº¥u trÃºc cÆ¡ báº£n cá»§a DL, CNN. NhÆ°ng váº¥n Ä‘á» lÃ  khi Ä‘Æ°a ra 1 bÃ i toÃ¡n vÃ  báº¯t lá»±a chá»n phÆ°Æ¡ng phÃ¡p giáº£i sao cho Ä‘Ãºng thÃ¬ em tháº¥y Ä‘ang hoÃ n toÃ n bá»‹ Ä‘á»™ng.
NÃªn nhá» cÃ¡c anh chá»‹ tÆ° váº¥n cho em phÆ°Æ¡ng phÃ¡p há»c tiáº¿p theo lÃ m sao Ä‘á»ƒ cÃ³ thá»ƒ hÃ¬nh thÃ nh Ä‘Æ°á»£c tÆ° duy giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n vá» Computer Vision cho hiá»‡u quáº£, Ã¡p dá»¥ng Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c mÃ¬nh Ä‘Ã£ há»c vÃ o cÃ¡c dá»± Ã¡n thá»±c táº¿ thuáº§n thá»¥c hÆ¡n. (NhÆ° nÃªn theo tiáº¿p cÃ¡c khÃ³a há»c nÃ o, tham kháº£o nhá»¯ng tÃ i liá»‡u chuyÃªn ngÃ nh nÃ o,... ) Má»¥c tiÃªu ngáº¯n háº¡n nháº¥t lÃ  trong 3 thÃ¡ng tá»›i cÃ³ thá»ƒ pass Ä‘Æ°á»£c 1 vá»‹ trÃ­ Fresh táº¡i 1 cÃ´ng ty nÃ o Ä‘Ã³ áº¡.","Em lÃ  sinh viÃªn chuyÃªn ngÃ nh vá» Ä‘iá»‡n tá»­ - viá»…n thÃ´ng. Má»›i nháº­p mÃ´n vá» ML, DL trong 2 thÃ¡ng. Äá»‹nh hÆ°á»›ng cá»§a em lÃ  sáº½ Ä‘i theo hÆ°á»›ng Computer Vision engineer vÃ¬ em nghÄ© nÃ³ liÃªn quan Ä‘áº¿n cÃ¡c á»©ng dá»¥ng bÃªn chuyÃªn ngÃ nh em nhiá»u nháº¥t. Hiá»‡n em Ä‘Ã£ Ä‘á»c hiá»ƒu háº§u háº¿t cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n cá»§a Machine Learning, hiá»ƒu Ä‘Æ°á»£c cÃ¡c cáº¥u trÃºc cÆ¡ báº£n cá»§a DL, CNN. NhÆ°ng váº¥n Ä‘á» lÃ  khi Ä‘Æ°a ra 1 bÃ i toÃ¡n vÃ  báº¯t lá»±a chá»n phÆ°Æ¡ng phÃ¡p giáº£i sao cho Ä‘Ãºng thÃ¬ em tháº¥y Ä‘ang hoÃ n toÃ n bá»‹ Ä‘á»™ng. NÃªn nhá» cÃ¡c anh chá»‹ tÆ° váº¥n cho em phÆ°Æ¡ng phÃ¡p há»c tiáº¿p theo lÃ m sao Ä‘á»ƒ cÃ³ thá»ƒ hÃ¬nh thÃ nh Ä‘Æ°á»£c tÆ° duy giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n vá» Computer Vision cho hiá»‡u quáº£, Ã¡p dá»¥ng Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c mÃ¬nh Ä‘Ã£ há»c vÃ o cÃ¡c dá»± Ã¡n thá»±c táº¿ thuáº§n thá»¥c hÆ¡n. (NhÆ° nÃªn theo tiáº¿p cÃ¡c khÃ³a há»c nÃ o, tham kháº£o nhá»¯ng tÃ i liá»‡u chuyÃªn ngÃ nh nÃ o,... ) Má»¥c tiÃªu ngáº¯n háº¡n nháº¥t lÃ  trong 3 thÃ¡ng tá»›i cÃ³ thá»ƒ pass Ä‘Æ°á»£c 1 vá»‹ trÃ­ Fresh táº¡i 1 cÃ´ng ty nÃ o Ä‘Ã³ áº¡.",,,,,
"[XÃ¡c suáº¥t - cs106 Cheatsheet]
XÃ¡c suáº¥t lÃ  má»™t trong nhá»¯ng kiáº¿n thá»©c ráº¥t quan trá»ng trong AI. Má»™t sá»‘ phÃ¢n phá»‘i xÃ¡c suáº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ khá»Ÿi táº¡o trá»ng sá»‘ cá»§a máº¡ng neural network nhÆ° phÃ¢n phá»‘i chuáº©n, phÃ¢n phá»‘i Ä‘á»“ng nháº¥t. Má»™t sá»‘ khÃ¡c Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c models liÃªn quan tá»›i xÃ¡c suáº¥t nhÆ° LDA (dÃ¹ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh topics), Naive Bayes models (Ã¡p dá»¥ng trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n). XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n thÆ°á»ng Ä‘Æ°á»£c Ã¡p dá»¥ng trong cÃ¡c mÃ´ hÃ¬nh dá»‹ch mÃ¡y vÃ  graphical model. Batch normalization cÅ©ng Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn cÃ´ng thá»©c chuáº©n hoÃ¡ cá»§a phÃ¢n phá»‘i chuáº©n. Khi kháº£o sÃ¡t dá»¯ liá»‡u thÃ¬ báº¡n cáº§n nhÃ¬n vÃ o Ä‘áº·c trÆ°ng cá»§a dá»¯ liá»‡u nhÆ° trung bÃ¬nh, phÆ°Æ¡ng sai Ä‘á»ƒ xem dá»¯ liá»‡u cÃ³ phÃ¹ há»£p hay khÃ´ng. VÃ  vÃ´ sá»‘ nhá»¯ng kiáº¿n thá»©c khÃ¡c trong AI cáº§n sá»­ dá»¥ng xÃ¡c suáº¥t. Cheatsheet nÃ y sáº½ giÃºp báº¡n há»‡ thá»‘ng láº¡i nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n nháº¥t vá» xÃ¡c suáº¥t Ä‘á»ƒ viá»‡c há»c AI trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. Ná»™i dung bao gá»“m:
- KhÃ¡i niá»‡m vá» sá»± kiá»‡n vÃ  khÃ´ng gian máº«u.
- CÃ´ng thá»©c tá»• há»£p, chá»‰nh há»£p.
- XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n, cÃ´ng thá»©c Bayes vÃ  Bayes má»Ÿ rá»™ng.
- HÃ m máº­t Ä‘á»™ xÃ¡c suáº¥t pdf, phÃ¢n phá»‘i xÃ¡c suáº¥t pmf vÃ  phÃ¢n phá»‘i xÃ¡c suáº¥t tÃ­ch luá»¹ cdf
- CÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t phá»• biáº¿n bao gá»“m: PhÃ¢n phá»‘i rá»i ráº¡c, phÃ¢n phá»‘i liÃªn tá»¥c.
- CÃ¡c Ä‘áº·c trÆ°ng ká»³ vá»ng, phÆ°Æ¡ng sai, moment xÃ¡c suáº¥t cá»§a cÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t tiÃªu biá»ƒu.
- Hiá»‡p phÆ°Æ¡ng sai vÃ  há»‡ sá»‘ tÆ°Æ¡ng quan.
- XÃ¡c suáº¥t chung cá»§a nhiá»u biáº¿n ngáº«u nhiÃªn.
Nguá»“n:
https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability
--------------------------------------------------------------------------------------
Note: Báº¡n cÃ³ thá»ƒ comment á»Ÿ bÃªn dÆ°á»›i Ä‘á»ƒ cÃ¹ng tháº£o luáº­n kÄ© hÆ¡n.","[XÃ¡c suáº¥t - cs106 Cheatsheet] XÃ¡c suáº¥t lÃ  má»™t trong nhá»¯ng kiáº¿n thá»©c ráº¥t quan trá»ng trong AI. Má»™t sá»‘ phÃ¢n phá»‘i xÃ¡c suáº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ khá»Ÿi táº¡o trá»ng sá»‘ cá»§a máº¡ng neural network nhÆ° phÃ¢n phá»‘i chuáº©n, phÃ¢n phá»‘i Ä‘á»“ng nháº¥t. Má»™t sá»‘ khÃ¡c Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c models liÃªn quan tá»›i xÃ¡c suáº¥t nhÆ° LDA (dÃ¹ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh topics), Naive Bayes models (Ã¡p dá»¥ng trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n). XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n thÆ°á»ng Ä‘Æ°á»£c Ã¡p dá»¥ng trong cÃ¡c mÃ´ hÃ¬nh dá»‹ch mÃ¡y vÃ  graphical model. Batch normalization cÅ©ng Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn cÃ´ng thá»©c chuáº©n hoÃ¡ cá»§a phÃ¢n phá»‘i chuáº©n. Khi kháº£o sÃ¡t dá»¯ liá»‡u thÃ¬ báº¡n cáº§n nhÃ¬n vÃ o Ä‘áº·c trÆ°ng cá»§a dá»¯ liá»‡u nhÆ° trung bÃ¬nh, phÆ°Æ¡ng sai Ä‘á»ƒ xem dá»¯ liá»‡u cÃ³ phÃ¹ há»£p hay khÃ´ng. VÃ  vÃ´ sá»‘ nhá»¯ng kiáº¿n thá»©c khÃ¡c trong AI cáº§n sá»­ dá»¥ng xÃ¡c suáº¥t. Cheatsheet nÃ y sáº½ giÃºp báº¡n há»‡ thá»‘ng láº¡i nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n nháº¥t vá» xÃ¡c suáº¥t Ä‘á»ƒ viá»‡c há»c AI trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. Ná»™i dung bao gá»“m: - KhÃ¡i niá»‡m vá» sá»± kiá»‡n vÃ  khÃ´ng gian máº«u. - CÃ´ng thá»©c tá»• há»£p, chá»‰nh há»£p. - XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n, cÃ´ng thá»©c Bayes vÃ  Bayes má»Ÿ rá»™ng. - HÃ m máº­t Ä‘á»™ xÃ¡c suáº¥t pdf, phÃ¢n phá»‘i xÃ¡c suáº¥t pmf vÃ  phÃ¢n phá»‘i xÃ¡c suáº¥t tÃ­ch luá»¹ cdf - CÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t phá»• biáº¿n bao gá»“m: PhÃ¢n phá»‘i rá»i ráº¡c, phÃ¢n phá»‘i liÃªn tá»¥c. - CÃ¡c Ä‘áº·c trÆ°ng ká»³ vá»ng, phÆ°Æ¡ng sai, moment xÃ¡c suáº¥t cá»§a cÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t tiÃªu biá»ƒu. - Hiá»‡p phÆ°Æ¡ng sai vÃ  há»‡ sá»‘ tÆ°Æ¡ng quan. - XÃ¡c suáº¥t chung cá»§a nhiá»u biáº¿n ngáº«u nhiÃªn. Nguá»“n: https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability -------------------------------------------------------------------------------------- Note: Báº¡n cÃ³ thá»ƒ comment á»Ÿ bÃªn dÆ°á»›i Ä‘á»ƒ cÃ¹ng tháº£o luáº­n kÄ© hÆ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang giáº£i quyáº¿t bÃ i toÃ¡n regression, vÃ  gáº·p váº¥n Ä‘á» nhÆ° sau, em mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p cá»§a má»i ngÆ°á»i.
""In a dataset, there is a feature named ""Server/Machine Type"", how would you transform/prepare this feature so that it can be used in a regression model (one only accepting float/bool as value)?
Some example of values on this feature:
Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 2950 MHz, 385570 MB RAM, 12079 MB swap
Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz (x86_64), 2500 MHz, 95717 MB RAM, 149012 MB swap
Intel(R) Xeon(R) CPU E5-2697A v4 @ 2.60GHz (x86_64), 1300 MHz, 257868 MB RAM, 12027 MB swap
Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 3138 MHz, 772642 MB RAM, 9042 MB swap
Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 2214 MHz, 385570 MB RAM, 12090 MB swap
Core(TM) i7-6700HQ CPU @ 2.60GHz (x86_64), 2600 MHz, 40078 MB RAM, 75183 MB swap
Intel(R) Xeon(R) CPU E5-2697A v4 @ 2.60GHz (x86_64), 1199 MHz, 257868 MB RAM, 12247 MB swap
Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 3246 MHz, 514658 MB RAM, 10770 MB swap
Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 2483 MHz, 772642 MB RAM, 8266 MB swap""","ChÃ o má»i ngÆ°á»i, em Ä‘ang giáº£i quyáº¿t bÃ i toÃ¡n regression, vÃ  gáº·p váº¥n Ä‘á» nhÆ° sau, em mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p cá»§a má»i ngÆ°á»i. ""In a dataset, there is a feature named ""Server/Machine Type"", how would you transform/prepare this feature so that it can be used in a regression model (one only accepting float/bool as value)? Some example of values on this feature: Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 2950 MHz, 385570 MB RAM, 12079 MB swap Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz (x86_64), 2500 MHz, 95717 MB RAM, 149012 MB swap Intel(R) Xeon(R) CPU E5-2697A v4 @ 2.60GHz (x86_64), 1300 MHz, 257868 MB RAM, 12027 MB swap Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 3138 MHz, 772642 MB RAM, 9042 MB swap Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 2214 MHz, 385570 MB RAM, 12090 MB swap Core(TM) i7-6700HQ CPU @ 2.60GHz (x86_64), 2600 MHz, 40078 MB RAM, 75183 MB swap Intel(R) Xeon(R) CPU E5-2697A v4 @ 2.60GHz (x86_64), 1199 MHz, 257868 MB RAM, 12247 MB swap Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 3246 MHz, 514658 MB RAM, 10770 MB swap Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz (x86_64), 2483 MHz, 772642 MB RAM, 8266 MB swap""",,,,,
"chÃ o má»i ngÆ°á»i, sáº¯p tá»›i em sáº½ viáº¿t bÃ i tá»‘t nghiá»‡p, Ä‘á» bÃ i lÃ  nháº­n diá»‡n xem bÃ n tay cÃ³ Ä‘áº·t trÃªn vÃ´ lÄƒng khÃ´ng vÃ  cÃ³ Ä‘áº·t Ä‘Ãºng theo máº«u khÃ´ng, data Ä‘áº§u vÃ o kiá»ƒu tÆ°Æ¡ng tá»± nhÆ° áº£nh dÆ°á»›i Ä‘Ã¢y (gÃ³c áº£nh tá»« trÃªn xuá»‘ng). em Ä‘ang nghÄ© Ä‘áº¿n viá»‡c Ä‘áº§u tiÃªn tÃ¡ch Ä‘Æ°á»£c vÃ´ lÄƒng vÃ  bÃ n tay trÃªn vÃ´ lÄƒng rá»“i tiáº¿p Ä‘Ã³ phÃ¢n loáº¡i ra xem cÃ³ Ä‘áº·t tay Ä‘Ãºng yÃªu cáº§u khÃ´ng. em cÃ³ tÃ¬m hiá»ƒu qua tháº¥y cÃ³ phÆ°Æ¡ng phÃ¡p instance segmentation cÃ³ váº» phÃ¹ há»£p, cÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ gá»£i Ã½ cho em phÆ°Æ¡ng phÃ¡p hoáº·c keywords Ä‘á»ƒ em tÃ¬m hiá»ƒu thÃªm. em cáº£m Æ¡n áº¡","chÃ o má»i ngÆ°á»i, sáº¯p tá»›i em sáº½ viáº¿t bÃ i tá»‘t nghiá»‡p, Ä‘á» bÃ i lÃ  nháº­n diá»‡n xem bÃ n tay cÃ³ Ä‘áº·t trÃªn vÃ´ lÄƒng khÃ´ng vÃ  cÃ³ Ä‘áº·t Ä‘Ãºng theo máº«u khÃ´ng, data Ä‘áº§u vÃ o kiá»ƒu tÆ°Æ¡ng tá»± nhÆ° áº£nh dÆ°á»›i Ä‘Ã¢y (gÃ³c áº£nh tá»« trÃªn xuá»‘ng). em Ä‘ang nghÄ© Ä‘áº¿n viá»‡c Ä‘áº§u tiÃªn tÃ¡ch Ä‘Æ°á»£c vÃ´ lÄƒng vÃ  bÃ n tay trÃªn vÃ´ lÄƒng rá»“i tiáº¿p Ä‘Ã³ phÃ¢n loáº¡i ra xem cÃ³ Ä‘áº·t tay Ä‘Ãºng yÃªu cáº§u khÃ´ng. em cÃ³ tÃ¬m hiá»ƒu qua tháº¥y cÃ³ phÆ°Æ¡ng phÃ¡p instance segmentation cÃ³ váº» phÃ¹ há»£p, cÃ¡c anh chá»‹ cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ gá»£i Ã½ cho em phÆ°Æ¡ng phÃ¡p hoáº·c keywords Ä‘á»ƒ em tÃ¬m hiá»ƒu thÃªm. em cáº£m Æ¡n áº¡",,,,,
"ChÃ o  táº¥t cáº£  cÃ¡c  anh (chá»‹).
Hiá»‡n táº¡i em cÃ³ 1 bÃ i :  "" XÃ¡c Ä‘á»‹nh cá»™ng Ä‘á»“ng báº±ng cÃ¡ch phÃ¢n tÃ­ch cáº¥u trÃºc Ä‘á»“ thá»‹ cá»§a Wikipedia (Detect Communities by Analyzing Graph Structure of Wikipedia)"".
Váº¥n Ä‘á» cá»§a em: 
Em chÆ°a xÃ¡c Ä‘á»‹nh rÃµ Ä‘á» bÃ i yÃªu cáº§u lÃ m  gÃ¬, mong anh chá»‹ giáº£i  thÃ­ch (cho vÃ­ dá»¥ náº¿u Ä‘Æ°á»£c).
CÃ¡c kiáº¿n  thá»©c  cáº§n cÃ³ Ä‘á»  lÃ m bÃ i nÃ y ?
Anh (chá»‹) cÃ³ tÃ i liá»‡u (link, bÃ i bÃ¡o...) vá» váº¥n Ä‘á» nÃ y thÃ¬ cho em xin Ä‘á»ƒ  tham kháº£o  vá»›i áº¡.
Em cÃ¡m Æ¡n anh (chá»‹) Ä‘Ã£ xem, chÃºc anh(chá»‹) nhiá»u sá»©c khá»e.","ChÃ o táº¥t cáº£ cÃ¡c anh (chá»‹). Hiá»‡n táº¡i em cÃ³ 1 bÃ i : "" XÃ¡c Ä‘á»‹nh cá»™ng Ä‘á»“ng báº±ng cÃ¡ch phÃ¢n tÃ­ch cáº¥u trÃºc Ä‘á»“ thá»‹ cá»§a Wikipedia (Detect Communities by Analyzing Graph Structure of Wikipedia)"". Váº¥n Ä‘á» cá»§a em: Em chÆ°a xÃ¡c Ä‘á»‹nh rÃµ Ä‘á» bÃ i yÃªu cáº§u lÃ m gÃ¬, mong anh chá»‹ giáº£i thÃ­ch (cho vÃ­ dá»¥ náº¿u Ä‘Æ°á»£c). CÃ¡c kiáº¿n thá»©c cáº§n cÃ³ Ä‘á» lÃ m bÃ i nÃ y ? Anh (chá»‹) cÃ³ tÃ i liá»‡u (link, bÃ i bÃ¡o...) vá» váº¥n Ä‘á» nÃ y thÃ¬ cho em xin Ä‘á»ƒ tham kháº£o vá»›i áº¡. Em cÃ¡m Æ¡n anh (chá»‹) Ä‘Ã£ xem, chÃºc anh(chá»‹) nhiá»u sá»©c khá»e.",,,,,
"Em má»›i nháº­p mÃ´n vá» ML. HÃ´m nay em Ä‘á»c tá»›i bÃ i Logistic Regeression thÃ¬ cÃ³ 2 chá»— code á»Ÿ thuáº­t toÃ¡n mÃ  chÆ°a thá»ƒ hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a. Nhá» anh chá»‹ giáº£i Ä‘Ã¡p giÃºp em vá»›i áº¡.
1. (Khung mÃ u cam): Táº¡i sao pháº£i dÃ¹ng method reshape(d,1) cho X[ :, 1 ]. Theo nhÆ° em tháº¥y thÃ¬ vá»‘n dÄ© X[ :, 1 ] Ä‘Ã£ cÃ³ shape lÃ  (d, 1) rá»“i. Váº­y mÃ¬nh pháº£i reshape nÃ³ láº¡i 1 láº§n vá»›i shape tÆ°Æ¡ng tá»± ná»¯a Ä‘á»ƒ lÃ m gÃ¬.
2. (Khung há»“ng): Em váº«n chÆ°a hiá»ƒu táº¡i sao pháº£i chá» count Ä‘áº¿m tá»›i má»©c cá»§a check_w_after (tá»©c lÃ  20) má»›i kiá»ƒm tra Ä‘iá»u kiá»‡n tiáº¿p theo. VÃ  táº¡i sao check_w_after láº¡i set báº±ng 20 áº¡.
Link trÃ­ch dáº«n bÃ i viáº¿t vÃ  code: https://machinelearningcoban.com/2017/01/27/logisticregression/","Em má»›i nháº­p mÃ´n vá» ML. HÃ´m nay em Ä‘á»c tá»›i bÃ i Logistic Regeression thÃ¬ cÃ³ 2 chá»— code á»Ÿ thuáº­t toÃ¡n mÃ  chÆ°a thá»ƒ hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a. Nhá» anh chá»‹ giáº£i Ä‘Ã¡p giÃºp em vá»›i áº¡. 1. (Khung mÃ u cam): Táº¡i sao pháº£i dÃ¹ng method reshape(d,1) cho X[ :, 1 ]. Theo nhÆ° em tháº¥y thÃ¬ vá»‘n dÄ© X[ :, 1 ] Ä‘Ã£ cÃ³ shape lÃ  (d, 1) rá»“i. Váº­y mÃ¬nh pháº£i reshape nÃ³ láº¡i 1 láº§n vá»›i shape tÆ°Æ¡ng tá»± ná»¯a Ä‘á»ƒ lÃ m gÃ¬. 2. (Khung há»“ng): Em váº«n chÆ°a hiá»ƒu táº¡i sao pháº£i chá» count Ä‘áº¿m tá»›i má»©c cá»§a check_w_after (tá»©c lÃ  20) má»›i kiá»ƒm tra Ä‘iá»u kiá»‡n tiáº¿p theo. VÃ  táº¡i sao check_w_after láº¡i set báº±ng 20 áº¡. Link trÃ­ch dáº«n bÃ i viáº¿t vÃ  code: https://machinelearningcoban.com/2017/01/27/logisticregression/",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em Ä‘ang muá»‘n há»c lÃªn tháº¡c sÄ© á»Ÿ khu vá»±c phÃ­a HCM, em muá»‘n nhá» má»i ngÆ°á»i tÆ° váº¥n trÆ°á»ng cÃ³ nhiá»u Ä‘á» tÃ i nghiÃªn cá»©u khoa há»c Ä‘Æ°á»£c cÃ´ng bá»‘ trÃªn conference vÃ  cÃ³ nhiá»u tháº§y hÆ°á»›ng dáº«n tá»‘t áº¡. Em lÃ m nhiá»u bÃªn Computer Vision trong Deep Learning nÃªn náº¿u Ä‘Æ°á»£c em muá»‘n biáº¿t trÆ°á»ng nÃ o máº¡nh vá» máº£ng xá»­ lÃ½ áº£nh vá»›i áº¡.
Mong má»i ngÆ°á»i tÆ° váº¥n giÃºp em, em xin cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang muá»‘n há»c lÃªn tháº¡c sÄ© á»Ÿ khu vá»±c phÃ­a HCM, em muá»‘n nhá» má»i ngÆ°á»i tÆ° váº¥n trÆ°á»ng cÃ³ nhiá»u Ä‘á» tÃ i nghiÃªn cá»©u khoa há»c Ä‘Æ°á»£c cÃ´ng bá»‘ trÃªn conference vÃ  cÃ³ nhiá»u tháº§y hÆ°á»›ng dáº«n tá»‘t áº¡. Em lÃ m nhiá»u bÃªn Computer Vision trong Deep Learning nÃªn náº¿u Ä‘Æ°á»£c em muá»‘n biáº¿t trÆ°á»ng nÃ o máº¡nh vá» máº£ng xá»­ lÃ½ áº£nh vá»›i áº¡. Mong má»i ngÆ°á»i tÆ° váº¥n giÃºp em, em xin cáº£m Æ¡n áº¡.",,,,,
"Xin phÃ©p ad,
ChÃ o a/c, mn cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ xem Ä‘Æ°á»£c hÃ m loss mÃ  máº¡ng CNN dÃ¹ng lÃ  hÃ m gÃ¬ (L1, L2, CrossEntropy...) hoáº·c lÃ  optimizer mÃ¬nh dÃ¹ng lÃ  cÃ¡i nÃ o (SGD, Adam...) báº±ng cÃ¡ch nhÃ¬n vÃ o cáº¥u trÃºc cá»§a model chá»© khÃ´ng nhÃ¬n vÃ o code áº¡. E cÃ³ dÃ¹ng model.summary() hay model.state_dict() mÃ  váº«n khÃ´ng tháº¥y Ä‘Æ°á»£c, em cáº£m Æ¡n a/c.","Xin phÃ©p ad, ChÃ o a/c, mn cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ xem Ä‘Æ°á»£c hÃ m loss mÃ  máº¡ng CNN dÃ¹ng lÃ  hÃ m gÃ¬ (L1, L2, CrossEntropy...) hoáº·c lÃ  optimizer mÃ¬nh dÃ¹ng lÃ  cÃ¡i nÃ o (SGD, Adam...) báº±ng cÃ¡ch nhÃ¬n vÃ o cáº¥u trÃºc cá»§a model chá»© khÃ´ng nhÃ¬n vÃ o code áº¡. E cÃ³ dÃ¹ng model.summary() hay model.state_dict() mÃ  váº«n khÃ´ng tháº¥y Ä‘Æ°á»£c, em cáº£m Æ¡n a/c.",,,,,
"Má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em vá»›i áº¡!
Táº¡i sao láº¡i coi lÆ°á»£ng thay Ä‘á»•i giá»¯a theta_t vÃ  theta_(t+1) lÃ  váº­n tá»‘c áº¡? Máº·c dÃ¹, viÃªn bi Ä‘Æ°á»£c váº­n tá»‘c thÃºc Ä‘áº©y Ä‘á»ƒ xuá»‘ng Ä‘Ã¡y nÃºi nhanh hÆ¡n (vÃ­ dá»¥ trong bÃ i 8 cá»§a anh Tiá»‡p) nhÆ°ng em khÃ´ng tháº¥y sá»± liÃªn quan trong cÃ´ng thá»©c áº¡. Em cáº£m Æ¡n áº¡.","Má»i ngÆ°á»i giáº£i thÃ­ch giÃºp em vá»›i áº¡! Táº¡i sao láº¡i coi lÆ°á»£ng thay Ä‘á»•i giá»¯a theta_t vÃ  theta_(t+1) lÃ  váº­n tá»‘c áº¡? Máº·c dÃ¹, viÃªn bi Ä‘Æ°á»£c váº­n tá»‘c thÃºc Ä‘áº©y Ä‘á»ƒ xuá»‘ng Ä‘Ã¡y nÃºi nhanh hÆ¡n (vÃ­ dá»¥ trong bÃ i 8 cá»§a anh Tiá»‡p) nhÆ°ng em khÃ´ng tháº¥y sá»± liÃªn quan trong cÃ´ng thá»©c áº¡. Em cáº£m Æ¡n áº¡.",,,"#Q&A, #math",,
"[Logistic Classification - Xá»­ lÃ½ khi cÃ³ quÃ¡ nhiá»u biáº¿n tháº¿ nÃ o ]
ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang xÃ¢y model phÃ¢n loáº¡i ná»£ xáº¥u, hiá»‡n táº¡i mÃ¬nh cÃ³ ráº¥t nhiá»u biáº¿n Ä‘áº§u vÃ o (2000 biáº¿n), viá»‡c binning Ä‘á»ƒ tÃ­nh IV ráº¥t máº¥t thá»i gian. CÃ³ báº¡n nÃ o cÃ³ cÃ¡ch nÃ o xá»­ lÃ½ nhanh cÃ´ng Ä‘á»an nÃ y cÃ³ thá»ƒ chia sáº» giÃºp mÃ¬nh khÃ´ng. MÃ¬nh cÃ¡m Æ¡n.","[Logistic Classification - Xá»­ lÃ½ khi cÃ³ quÃ¡ nhiá»u biáº¿n tháº¿ nÃ o ] ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘ang xÃ¢y model phÃ¢n loáº¡i ná»£ xáº¥u, hiá»‡n táº¡i mÃ¬nh cÃ³ ráº¥t nhiá»u biáº¿n Ä‘áº§u vÃ o (2000 biáº¿n), viá»‡c binning Ä‘á»ƒ tÃ­nh IV ráº¥t máº¥t thá»i gian. CÃ³ báº¡n nÃ o cÃ³ cÃ¡ch nÃ o xá»­ lÃ½ nhanh cÃ´ng Ä‘á»an nÃ y cÃ³ thá»ƒ chia sáº» giÃºp mÃ¬nh khÃ´ng. MÃ¬nh cÃ¡m Æ¡n.",,,,,
"[Pytorch series]
BÃ i 3: Neural Network
BÃ i nÃ y mÃ¬nh hÆ°á»›ng dáº«n xÃ¢y dá»±ng model Neural Network, CNN báº±ng Pytorch. ThÃªm vÃ o Ä‘Ã³, mÃ¬nh nÃ³i vá» hook function trong Pytorch cÅ©ng nhÆ° so sÃ¡nh giá»¯a __call__ vÃ  forward, nn.ReLU vÃ  F.relu.","[Pytorch series] BÃ i 3: Neural Network BÃ i nÃ y mÃ¬nh hÆ°á»›ng dáº«n xÃ¢y dá»±ng model Neural Network, CNN báº±ng Pytorch. ThÃªm vÃ o Ä‘Ã³, mÃ¬nh nÃ³i vá» hook function trong Pytorch cÅ©ng nhÆ° so sÃ¡nh giá»¯a __call__ vÃ  forward, nn.ReLU vÃ  F.relu.",,,,,
"Mn cho e hoÌ‰i, e mÆ¡Ìi hoÌ£c vÃªÌ€ NN vaÌ€ code thÆ°Ì‰ Ä‘oaÌ£n nhoÌ‰. nhÆ°ng noÌ sai Æ¡Ì‰ model fit. LÃ´Ìƒi Ä‘oÌ laÌ€ sao thÃªÌ aÌ£?","Mn cho e hoÌ‰i, e mÆ¡Ìi hoÌ£c vÃªÌ€ NN vaÌ€ code thÆ°Ì‰ Ä‘oaÌ£n nhoÌ‰. nhÆ°ng noÌ sai Æ¡Ì‰ model fit. LÃ´Ìƒi Ä‘oÌ laÌ€ sao thÃªÌ aÌ£?",,,,,
MÃ¬nh Ä‘Ã£ áº¥p á»§ viá»‡c viáº¿t vá» Dá»¯ liá»‡u dáº¡ng báº£ng tá»« lÃ¢u nhÆ°ng chÆ°a bao giá» báº¯t Ä‘áº§u Ä‘Æ°á»£c. HÃ´m nay mÃ¬nh quyáº¿t Ä‘á»‹nh cÃ´ng bá»‘ Ä‘á»ƒ láº¥y Ä‘á»™ng lá»±c viáº¿t tá»« tá»«. Hy vá»ng dá»± Ã¡n nháº­n Ä‘Æ°á»£c sá»± á»§ng há»™ cá»§a cá»™ng Ä‘á»“ng.,MÃ¬nh Ä‘Ã£ áº¥p á»§ viá»‡c viáº¿t vá» Dá»¯ liá»‡u dáº¡ng báº£ng tá»« lÃ¢u nhÆ°ng chÆ°a bao giá» báº¯t Ä‘áº§u Ä‘Æ°á»£c. HÃ´m nay mÃ¬nh quyáº¿t Ä‘á»‹nh cÃ´ng bá»‘ Ä‘á»ƒ láº¥y Ä‘á»™ng lá»±c viáº¿t tá»« tá»«. Hy vá»ng dá»± Ã¡n nháº­n Ä‘Æ°á»£c sá»± á»§ng há»™ cá»§a cá»™ng Ä‘á»“ng.,,,,,
"ChÃ o má»i ngÆ°á»i, gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ tham dá»± webinar MATH & AI conference https://www.math-ia.fr/. MÃ¬nh muá»‘n chia sáº» 3 bÃ i nÃ³i mÃ¬nh tháº¥y há»¯u Ã­ch: 
Self-supervised learning and uncertainty representation, by Yann LeCun (Facebook) : https://vimeo.com/522390193 
Perspectives, by Michael Jordan (Berkeley) : https://vimeo.com/522733917
Convex and non-convex optimization for machine learning, by Francis Bach (Inria) : https://vimeo.com/522392083
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin.","ChÃ o má»i ngÆ°á»i, gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ tham dá»± webinar MATH & AI conference https://www.math-ia.fr/. MÃ¬nh muá»‘n chia sáº» 3 bÃ i nÃ³i mÃ¬nh tháº¥y há»¯u Ã­ch: Self-supervised learning and uncertainty representation, by Yann LeCun (Facebook) : https://vimeo.com/522390193 Perspectives, by Michael Jordan (Berkeley) : https://vimeo.com/522733917 Convex and non-convex optimization for machine learning, by Francis Bach (Inria) : https://vimeo.com/522392083 Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin.",,,,,
"em chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m project cáº§n tÃ¬m 1 dataset Ä‘á»ƒ phÃ¢n tÃ­ch. dÆ°á»›i Ä‘Ã¢y lÃ  1 vÃ­ dá»¥ cÃ´ Ä‘Æ°a cho. Em sáº½ dÃ¹ng R Ä‘á»ƒ cháº¡y vÃ  tráº£ lá»i nhá»¯ng cÃ¢u há»i tá»± nghÄ© ra. e cÃ³ Ä‘ang nghÄ© tá»›i vaccine vÃ  add thÃªm cÃ¡c yáº¿u tá»‘ cÃ¢n náº·ng, chiá»u cao, giá»›i tÃ­nh, há»c váº¥n,... vÃ  sau khi phÃ¢n tÃ­ch sáº½ tráº£ lá»i nhá»¯ng cÃ¢u há»i nhÆ° lÃ  cÃ¡c yáº¿u tá»‘ Ä‘Ã³ áº£nh hÆ°á»Ÿng ra sao, yáº¿u tá»‘ nÃ o lÃ  quan trá»ng... nhÆ°ng bá»™ data nhÆ° váº­y thÃ¬ ko tÃ¬m dc
mng Ä‘Ã£ ai lÃ m project tÆ°Æ¡ng tá»±, cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ cho 1 bá»™ data khÃ¡c ko thÃ¬ hdan e vá»›i áº¡. em tÃ¬m mÃ£i mÃ  bÃ­ quÃ¡.
thank you mng","em chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m project cáº§n tÃ¬m 1 dataset Ä‘á»ƒ phÃ¢n tÃ­ch. dÆ°á»›i Ä‘Ã¢y lÃ  1 vÃ­ dá»¥ cÃ´ Ä‘Æ°a cho. Em sáº½ dÃ¹ng R Ä‘á»ƒ cháº¡y vÃ  tráº£ lá»i nhá»¯ng cÃ¢u há»i tá»± nghÄ© ra. e cÃ³ Ä‘ang nghÄ© tá»›i vaccine vÃ  add thÃªm cÃ¡c yáº¿u tá»‘ cÃ¢n náº·ng, chiá»u cao, giá»›i tÃ­nh, há»c váº¥n,... vÃ  sau khi phÃ¢n tÃ­ch sáº½ tráº£ lá»i nhá»¯ng cÃ¢u há»i nhÆ° lÃ  cÃ¡c yáº¿u tá»‘ Ä‘Ã³ áº£nh hÆ°á»Ÿng ra sao, yáº¿u tá»‘ nÃ o lÃ  quan trá»ng... nhÆ°ng bá»™ data nhÆ° váº­y thÃ¬ ko tÃ¬m dc mng Ä‘Ã£ ai lÃ m project tÆ°Æ¡ng tá»±, cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ cho 1 bá»™ data khÃ¡c ko thÃ¬ hdan e vá»›i áº¡. em tÃ¬m mÃ£i mÃ  bÃ­ quÃ¡. thank you mng",,,,,
"[BÃ i giáº£ng Ä‘áº¡i chÃºng] GS. VÅ© HÃ  VÄƒn vá»›i CHUYá»†N Cá»¦A PAUL
Má»™t trong nhá»¯ng nhÃ¢n váº­t ná»•i tiáº¿ng nháº¥t cá»§a World Cup 2010 lÃ  anh Paul báº¡ch tuá»™c. Báº¡ch tuá»™c Ä‘Ã¢y khÃ´ng pháº£i tÃªn hiá»‡u xÃ£ há»™i Ä‘en cá»§a Paul, nhÆ° Háº£i rá»“ng xanh hay HoÃ ng sÆ° tá»­. Paul lÃ  má»™t báº¡ch tuá»™c chÃ­nh cá»‘ng, tá»©c lÃ  nÃ³ cÃ³ 8 vÃ²i, vÃ  bÆ¡i trong má»™t bá»ƒ nÆ°á»›c.
Paul ná»•i tiáº¿ng vÃ¬ nÃ³ Ä‘Ã£ Ä‘oÃ¡n trÃºng káº¿t quáº£ cáº£ 7 tráº­n Ä‘áº¥u cá»§a tuyá»ƒn Äá»©c. (Paul mang quá»‘c tá»‹ch Äá»©c, hay chÃ­nh xÃ¡c hÆ¡n, nÃ³ cÆ° trÃº trong bá»ƒ cÃ¡ cá»§a má»™t quÃ¡n Äƒn táº¡i Äá»©c.) Pháº£i nÃ³i ráº±ng Ä‘oÃ¡n trÃºng káº¿t quáº£ 3,4 tráº­n Ä‘áº¥u liÃªn tiáº¿p lÃ  Ä‘iá»u ráº¥t Ã­t nhÃ  bÃ¬nh luáº­n thá»ƒ thao nÃ o lÃ m Ä‘Æ°á»£c. Duy nháº¥t cÃ³ xÃ¡c xuáº¥t gáº§n 100 pháº§n trÄƒm ngang vá»›i Paul, khÃ´ng ai khÃ¡c ngoÃ i Pele vÄ© Ä‘áº¡i, ngÆ°á»i thÆ°á»ng xuyÃªn Ä‘oÃ¡n sai háº§u nhÆ° táº¥t cáº£ cÃ¡c tráº­n Ä‘áº¥u.
CÃ¹ng nhÃ¬n láº¡i chuyá»‡n cá»§a Paul vá»›i con máº¯t toÃ¡n há»c, vÃ  tháº£o luáº­n má»™t sá»‘ váº¥n Ä‘á» liÃªn quan qua pháº§n trÃ¬nh bÃ y cá»§a GS. VÅ© HÃ  VÄƒn (GiÃ¡m Ä‘á»‘c Khoa há»c Viá»‡n NghiÃªn cá»©u Dá»¯ liá»‡u lá»›n VinBigdata, GiÃ¡o sÆ° ToÃ¡n há»c ÄH Yale) táº¡i Ä‘Ã¢y.
youtube.com/watch?v=FEMJpwkizAU","[BÃ i giáº£ng Ä‘áº¡i chÃºng] GS. VÅ© HÃ  VÄƒn vá»›i CHUYá»†N Cá»¦A PAUL Má»™t trong nhá»¯ng nhÃ¢n váº­t ná»•i tiáº¿ng nháº¥t cá»§a World Cup 2010 lÃ  anh Paul báº¡ch tuá»™c. Báº¡ch tuá»™c Ä‘Ã¢y khÃ´ng pháº£i tÃªn hiá»‡u xÃ£ há»™i Ä‘en cá»§a Paul, nhÆ° Háº£i rá»“ng xanh hay HoÃ ng sÆ° tá»­. Paul lÃ  má»™t báº¡ch tuá»™c chÃ­nh cá»‘ng, tá»©c lÃ  nÃ³ cÃ³ 8 vÃ²i, vÃ  bÆ¡i trong má»™t bá»ƒ nÆ°á»›c. Paul ná»•i tiáº¿ng vÃ¬ nÃ³ Ä‘Ã£ Ä‘oÃ¡n trÃºng káº¿t quáº£ cáº£ 7 tráº­n Ä‘áº¥u cá»§a tuyá»ƒn Äá»©c. (Paul mang quá»‘c tá»‹ch Äá»©c, hay chÃ­nh xÃ¡c hÆ¡n, nÃ³ cÆ° trÃº trong bá»ƒ cÃ¡ cá»§a má»™t quÃ¡n Äƒn táº¡i Äá»©c.) Pháº£i nÃ³i ráº±ng Ä‘oÃ¡n trÃºng káº¿t quáº£ 3,4 tráº­n Ä‘áº¥u liÃªn tiáº¿p lÃ  Ä‘iá»u ráº¥t Ã­t nhÃ  bÃ¬nh luáº­n thá»ƒ thao nÃ o lÃ m Ä‘Æ°á»£c. Duy nháº¥t cÃ³ xÃ¡c xuáº¥t gáº§n 100 pháº§n trÄƒm ngang vá»›i Paul, khÃ´ng ai khÃ¡c ngoÃ i Pele vÄ© Ä‘áº¡i, ngÆ°á»i thÆ°á»ng xuyÃªn Ä‘oÃ¡n sai háº§u nhÆ° táº¥t cáº£ cÃ¡c tráº­n Ä‘áº¥u. CÃ¹ng nhÃ¬n láº¡i chuyá»‡n cá»§a Paul vá»›i con máº¯t toÃ¡n há»c, vÃ  tháº£o luáº­n má»™t sá»‘ váº¥n Ä‘á» liÃªn quan qua pháº§n trÃ¬nh bÃ y cá»§a GS. VÅ© HÃ  VÄƒn (GiÃ¡m Ä‘á»‘c Khoa há»c Viá»‡n NghiÃªn cá»©u Dá»¯ liá»‡u lá»›n VinBigdata, GiÃ¡o sÆ° ToÃ¡n há»c ÄH Yale) táº¡i Ä‘Ã¢y. youtube.com/watch?v=FEMJpwkizAU",,,,,
"#Cheatsheet #RNN
[Recurrent Neural Network - Cheatsheet]
Máº¡ng truy há»“i (Recurrent Neural Network) lÃ  má»™t kiáº¿n trÃºc quan trá»ng vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng ráº¥t nhiá»u trong Ä‘a dáº¡ng cÃ¡c lá»›p bÃ i toÃ¡n seq2seq, classification, prediction. ChÃºng ta cÃ³ thá»ƒ ká»ƒ tá»›i má»™t vÃ i á»©ng dá»¥ng ná»•i báº­t cá»§a nÃ³ nhÆ°: Dá»‹ch mÃ¡y (machine learning translation), phÃ¢n tÃ­ch tin tÃ­ch cá»±c/tiÃªu cá»±c (sentiment analysis), dá»± bÃ¡o chuá»—i thá»i gian (time series), há»‡ thá»‘ng gá»£i Ã½ (recommender system), dá»± bÃ¡o thá»i tiáº¿t, dá»± bÃ¡o phiÃªn tÄƒng/giáº£m cá»• phiáº¿u,... Hiá»ƒu Ä‘Æ°á»£c RNN sáº½ giÃºp báº¡n cÃ³ thÃªm cÃ´ng cá»¥ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» cÃ³ tÃ­nh á»©ng dá»¥ng thá»±c tiá»…n cao. VÃ¬ váº­y nÃ³ Ä‘Ã³ng má»™t vai trÃ² quan trá»ng vÃ  cáº§n thiáº¿t cho data scientist. Xin giá»›i thiá»‡u tá»›i cÃ¡c báº¡n má»™t cheatsheet Ä‘Ã¡ng tin cáº­y cá»§a khoÃ¡ há»c cs230 tá»•ng há»£p cÃ¡c kiáº¿n thá»©c vá» RNN má»™t cÃ¡ch ngáº¯n gá»n, dá»… hiá»ƒu. Qua Ä‘Ã³ báº¡n sáº½ Ä‘Æ°á»£c Ã´n táº­p cÃ¡c kiáº¿n thá»©c:
- Cáº¥u trÃºc cá»§a máº¡ng RNN
- CÃ¡c dáº¡ng bÃ i toÃ¡n mÃ  RNN cÃ³ thá»ƒ giáº£i quyáº¿t: One2One, One2Many, Many2One, Many2Many
- CÆ¡ cháº¿ lan truyá»n ngÆ°á»£c trong RNN vÃ  sá»± phá»¥ thuá»™c dÃ i háº¡n.
- CÃ¡c kiáº¿n trÃºc RNN tiÃªu biá»ƒu: LSTM, GRU.
- CÃ¡c biáº¿n thá»ƒ kiáº¿n trÃºc cá»§a RNN: DeepRNN, Bidirectional RNN
- PhÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»«: Word2Vec, GloVe, biá»ƒu diá»…n t-SNE
- BÃ i toÃ¡n dá»‹ch mÃ¡y: kiáº¿n trÃºc encoder-decoder, beam search, BLEU score
- CÆ¡ cháº¿ attention
Source:
https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks","[Recurrent Neural Network - Cheatsheet] Máº¡ng truy há»“i (Recurrent Neural Network) lÃ  má»™t kiáº¿n trÃºc quan trá»ng vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng ráº¥t nhiá»u trong Ä‘a dáº¡ng cÃ¡c lá»›p bÃ i toÃ¡n seq2seq, classification, prediction. ChÃºng ta cÃ³ thá»ƒ ká»ƒ tá»›i má»™t vÃ i á»©ng dá»¥ng ná»•i báº­t cá»§a nÃ³ nhÆ°: Dá»‹ch mÃ¡y (machine learning translation), phÃ¢n tÃ­ch tin tÃ­ch cá»±c/tiÃªu cá»±c (sentiment analysis), dá»± bÃ¡o chuá»—i thá»i gian (time series), há»‡ thá»‘ng gá»£i Ã½ (recommender system), dá»± bÃ¡o thá»i tiáº¿t, dá»± bÃ¡o phiÃªn tÄƒng/giáº£m cá»• phiáº¿u,... Hiá»ƒu Ä‘Æ°á»£c RNN sáº½ giÃºp báº¡n cÃ³ thÃªm cÃ´ng cá»¥ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» cÃ³ tÃ­nh á»©ng dá»¥ng thá»±c tiá»…n cao. VÃ¬ váº­y nÃ³ Ä‘Ã³ng má»™t vai trÃ² quan trá»ng vÃ  cáº§n thiáº¿t cho data scientist. Xin giá»›i thiá»‡u tá»›i cÃ¡c báº¡n má»™t cheatsheet Ä‘Ã¡ng tin cáº­y cá»§a khoÃ¡ há»c cs230 tá»•ng há»£p cÃ¡c kiáº¿n thá»©c vá» RNN má»™t cÃ¡ch ngáº¯n gá»n, dá»… hiá»ƒu. Qua Ä‘Ã³ báº¡n sáº½ Ä‘Æ°á»£c Ã´n táº­p cÃ¡c kiáº¿n thá»©c: - Cáº¥u trÃºc cá»§a máº¡ng RNN - CÃ¡c dáº¡ng bÃ i toÃ¡n mÃ  RNN cÃ³ thá»ƒ giáº£i quyáº¿t: One2One, One2Many, Many2One, Many2Many - CÆ¡ cháº¿ lan truyá»n ngÆ°á»£c trong RNN vÃ  sá»± phá»¥ thuá»™c dÃ i háº¡n. - CÃ¡c kiáº¿n trÃºc RNN tiÃªu biá»ƒu: LSTM, GRU. - CÃ¡c biáº¿n thá»ƒ kiáº¿n trÃºc cá»§a RNN: DeepRNN, Bidirectional RNN - PhÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»«: Word2Vec, GloVe, biá»ƒu diá»…n t-SNE - BÃ i toÃ¡n dá»‹ch mÃ¡y: kiáº¿n trÃºc encoder-decoder, beam search, BLEU score - CÆ¡ cháº¿ attention Source: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks",#Cheatsheet	#RNN,,,,
">>> NÄƒm má»›i thÃ¬ lÃ m gÃ¬?! - Pháº§n 2
Tiáº¿p ná»‘i pháº§n 1, tá»« 1 bÃ i chia sáº» mÃ¬nh Ä‘Ã£ Ä‘Äƒng cÃ¡ch Ä‘Ã¢y hÆ¡n 1 thÃ¡ng trÆ°á»›c, cÃ¡c cuá»™c thi / competition vá» ML/AI Ä‘ang Ä‘Æ°á»£c diá»…n ra:
Link pháº§n 1: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/474062150667512
6. https://ogb.stanford.edu/kddcup2021/
- Large-Scale Graph ML Competition, lÃ  1 cuá»™c thi vá» dá»¯ liá»‡u lá»›n dáº¡ng Ä‘á»“ thá»‹ (large-scale dataset) vá»›i 3 task con: Node classification, Link Prediction vÃ  Graph Regression, tá»• chá»©c bá»Ÿi KDD2021.
- Topic: Graph Neural Network, Knowledge Graph Embedding
----------
7. https://compete.hexagon-ml.com/practice/competition/39/
- Multi-dataset Time Series Anomaly Detection, cuá»™c thi vá» xÃ¡c Ä‘á»‹nh Ä‘iá»ƒm báº¥t thÆ°á»ng vá»›i dá»¯ liá»‡u theo thá»i gian (time-series), tá»• chá»©c bá»Ÿi KDD2021
- Topic: Time-series, Anomaly Detection
----------
8. http://www.yunqiacademy.org/
- City Brain Challenge - How many vehicles can you serve at most with a city-scale road network, cuá»™c thi vá» Ä‘iá»u phá»‘i lÆ°u lÆ°á»£ng giao thÃ´ng táº¡i cÃ¡c Ä‘iá»ƒm nÃºt vá»›i cÃ¡c Ä‘iá»u kiá»‡n cho trÆ°á»›c, tá»• chá»©c bá»Ÿi KDD2021.
----------
9. https://sites.google.com/view/fgvc8/competitions
- FGVC8 Competitions Workshop, 1 danh sÃ¡ch cÃ¡c cuá»™c thi vá» Computer Vision vá»›i nhiá»u chá»§ Ä‘á» khÃ¡c nhau, Ä‘á»“ng tá»• chá»©c bá»Ÿi Kaggle vÃ  CVPR2021
----------
Danh sÃ¡ch cÃ¡c bÃ i chia sáº» liÃªn quan khÃ¡c:
- NÄƒm má»›i thÃ¬ lÃ m gÃ¬?! - Pháº§n 1: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/474062150667512
- Must-read papers on graph neural networks (GNN) https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/492800285460365/
- ml-contests: Categorical list of ML and DL related challenges/contests https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/486196196120774/
- Ebook vá» GNN: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/478900516850342/
- BÃ i toÃ¡n trÃ­ch rÃºt thÃ´ng tin hÃ³a Ä‘Æ¡n vá»›i GCN: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/458796488860745/
- MC-OCR competition: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/427792028627858/
- MC-OCR solution, tÃ¡c giáº£ Nguyá»…n Viá»‡t HoÃ i: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/496813281725732/
>>> Náº¿u share bÃ i viáº¿t tá»›i cÃ¡c group liÃªn quan, cÃ¡c báº¡n vui lÃ²ng dáº«n link tá»›i bÃ i viáº¿t gá»‘c cá»§a Vietnam AI Link Sharing Community
#Q12021 #machine_learning #deep_learning #HappyNewYear #competition #challenge #kaggle #KDD2021",">>> NÄƒm má»›i thÃ¬ lÃ m gÃ¬?! - Pháº§n 2 Tiáº¿p ná»‘i pháº§n 1, tá»« 1 bÃ i chia sáº» mÃ¬nh Ä‘Ã£ Ä‘Äƒng cÃ¡ch Ä‘Ã¢y hÆ¡n 1 thÃ¡ng trÆ°á»›c, cÃ¡c cuá»™c thi / competition vá» ML/AI Ä‘ang Ä‘Æ°á»£c diá»…n ra: Link pháº§n 1: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/474062150667512 6. https://ogb.stanford.edu/kddcup2021/ - Large-Scale Graph ML Competition, lÃ  1 cuá»™c thi vá» dá»¯ liá»‡u lá»›n dáº¡ng Ä‘á»“ thá»‹ (large-scale dataset) vá»›i 3 task con: Node classification, Link Prediction vÃ  Graph Regression, tá»• chá»©c bá»Ÿi KDD2021. - Topic: Graph Neural Network, Knowledge Graph Embedding ---------- 7. https://compete.hexagon-ml.com/practice/competition/39/ - Multi-dataset Time Series Anomaly Detection, cuá»™c thi vá» xÃ¡c Ä‘á»‹nh Ä‘iá»ƒm báº¥t thÆ°á»ng vá»›i dá»¯ liá»‡u theo thá»i gian (time-series), tá»• chá»©c bá»Ÿi KDD2021 - Topic: Time-series, Anomaly Detection ---------- 8. http://www.yunqiacademy.org/ - City Brain Challenge - How many vehicles can you serve at most with a city-scale road network, cuá»™c thi vá» Ä‘iá»u phá»‘i lÆ°u lÆ°á»£ng giao thÃ´ng táº¡i cÃ¡c Ä‘iá»ƒm nÃºt vá»›i cÃ¡c Ä‘iá»u kiá»‡n cho trÆ°á»›c, tá»• chá»©c bá»Ÿi KDD2021. ---------- 9. https://sites.google.com/view/fgvc8/competitions - FGVC8 Competitions Workshop, 1 danh sÃ¡ch cÃ¡c cuá»™c thi vá» Computer Vision vá»›i nhiá»u chá»§ Ä‘á» khÃ¡c nhau, Ä‘á»“ng tá»• chá»©c bá»Ÿi Kaggle vÃ  CVPR2021 ---------- Danh sÃ¡ch cÃ¡c bÃ i chia sáº» liÃªn quan khÃ¡c: - NÄƒm má»›i thÃ¬ lÃ m gÃ¬?! - Pháº§n 1: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/474062150667512 - Must-read papers on graph neural networks (GNN) https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/492800285460365/ - ml-contests: Categorical list of ML and DL related challenges/contests https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/486196196120774/ - Ebook vá» GNN: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/478900516850342/ - BÃ i toÃ¡n trÃ­ch rÃºt thÃ´ng tin hÃ³a Ä‘Æ¡n vá»›i GCN: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/458796488860745/ - MC-OCR competition: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/427792028627858/ - MC-OCR solution, tÃ¡c giáº£ Nguyá»…n Viá»‡t HoÃ i: https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/496813281725732/ >>> Náº¿u share bÃ i viáº¿t tá»›i cÃ¡c group liÃªn quan, cÃ¡c báº¡n vui lÃ²ng dáº«n link tá»›i bÃ i viáº¿t gá»‘c cá»§a Vietnam AI Link Sharing Community",#Q12021	#machine_learning	#deep_learning	#HappyNewYear	#competition	#challenge	#kaggle	#KDD2021,,,,
"ChÃ o cáº£ nhÃ  áº¡
Cáº£ nhÃ  cho e há»i : e Ä‘ang nghiÃªn cá»©u thuáº­t toÃ¡n K - Mean á»©ng dá»¥ng vÃ o phÃ¢n cá»¥m khÃ¡ch hÃ ng dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ .Dá»¯ liá»‡u gá»“m cÃ¡c trÆ°á»ng (khÃ¡ch hÃ ng, tÃªn sáº£n pháº©m, Ä‘á»‹a chá»‰). Em thá»±c hiá»‡n phÃ¢n cá»¥m khÃ¡ch hÃ ng dá»±a vÃ o 2 trÆ°á»ng tÃªn sáº£n pháº©m vÃ  Ä‘á»‹a chá»‰
Váº­y GiÃ¡ trá»‹ tÃ¢m cá»¥m cÃ³ Ã½ nghÄ©a gÃ¬ trong viá»‡c xÃ¡c Ä‘á»‹nh tÃªn sáº£n pháº©m vÃ  Ä‘á»‹a chá»‰.
Em cáº£m Æ¡n áº¡.","ChÃ o cáº£ nhÃ  áº¡ Cáº£ nhÃ  cho e há»i : e Ä‘ang nghiÃªn cá»©u thuáº­t toÃ¡n K - Mean á»©ng dá»¥ng vÃ o phÃ¢n cá»¥m khÃ¡ch hÃ ng dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ .Dá»¯ liá»‡u gá»“m cÃ¡c trÆ°á»ng (khÃ¡ch hÃ ng, tÃªn sáº£n pháº©m, Ä‘á»‹a chá»‰). Em thá»±c hiá»‡n phÃ¢n cá»¥m khÃ¡ch hÃ ng dá»±a vÃ o 2 trÆ°á»ng tÃªn sáº£n pháº©m vÃ  Ä‘á»‹a chá»‰ Váº­y GiÃ¡ trá»‹ tÃ¢m cá»¥m cÃ³ Ã½ nghÄ©a gÃ¬ trong viá»‡c xÃ¡c Ä‘á»‹nh tÃªn sáº£n pháº©m vÃ  Ä‘á»‹a chá»‰. Em cáº£m Æ¡n áº¡.",,,,,
"ChÃ o mn, em Ä‘ang tÃ¬m hiá»ƒu vÃ  thá»­ nghiá»‡m thuáº­t toÃ¡n random forest. Hiá»‡n táº¡i em Ä‘Ã£ cÃ i Ä‘áº·t vÃ  cháº¡y thÃ nh cÃ´ng trÃªn PC báº±ng thÆ° viá»‡n cÃ³ sáºµn trong sklearn, lÆ°u save file báº±ng pickle hoáº·c joblib nhÆ° trong áº£nh
Em muá»‘n há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ load file save trÃªn Ä‘iá»‡n thoáº¡i android vÃ  thá»±c hiá»‡n predict ko áº¡ ?","ChÃ o mn, em Ä‘ang tÃ¬m hiá»ƒu vÃ  thá»­ nghiá»‡m thuáº­t toÃ¡n random forest. Hiá»‡n táº¡i em Ä‘Ã£ cÃ i Ä‘áº·t vÃ  cháº¡y thÃ nh cÃ´ng trÃªn PC báº±ng thÆ° viá»‡n cÃ³ sáºµn trong sklearn, lÆ°u save file báº±ng pickle hoáº·c joblib nhÆ° trong áº£nh Em muá»‘n há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ load file save trÃªn Ä‘iá»‡n thoáº¡i android vÃ  thá»±c hiá»‡n predict ko áº¡ ?",,,,,
"[URGENT] PhD studentship opportunity in theoretical machine learning for international students
I am looking for a strong candidate for the EUTOPIA PhD studentship opportunity. Should the candidate receive the funding, they will be hosted by my research lab at the University of Warwick, UK, and co-hosted for max 12 months at one of my project partners (most likely at Vrije Universiteit Brussel (VUB), Belgium). The research topics I am interested in are:
- algebraic topology/geometry + machine learning for explainable AI
- combinatorial optimisation + online machine learning
- theoretical RL with very large MDPs
- game theory + machine learning for strategic multi-agent learning
Since these topics require mathematical/theoretical computer science background, the candidate is expected to have good skills in at least one of the following topics: optimisation, control theory (theory side), theoretical computer science (algorithmic graph theory, complexity theory, etc). Knowledge in topological data analysis is an advantage.
*IMPORTANT*:
Eligibility requirement: The candidate should have a MSc degree by the start of the PhD.
Application deadline: 28th April 2021 (so if you are interested, please contact me asap at: long.tran-thanh@warwick.ac.uk)
More details can be found here:
https://warwick.ac.uk/global/partnerships/europe/eutopia/fundingop/eutopia_phd_call_description_2021_fv_1.pdf
A few words about Warwick: Its Computer Science department is one of the top ones in the UK. It has one of the strongest theoretical computer science research labs in Europe. Its discrete Maths centre (DIMAP) is also word-leading. My lab focuses on the theoretical side of human-agent learning (e.g., multiagent learning, strategic learning, explainability, etc.), which usually requires combinations of game theory, graph theory, algebraic topology etc. with machine learning.","[URGENT] PhD studentship opportunity in theoretical machine learning for international students I am looking for a strong candidate for the EUTOPIA PhD studentship opportunity. Should the candidate receive the funding, they will be hosted by my research lab at the University of Warwick, UK, and co-hosted for max 12 months at one of my project partners (most likely at Vrije Universiteit Brussel (VUB), Belgium). The research topics I am interested in are: - algebraic topology/geometry + machine learning for explainable AI - combinatorial optimisation + online machine learning - theoretical RL with very large MDPs - game theory + machine learning for strategic multi-agent learning Since these topics require mathematical/theoretical computer science background, the candidate is expected to have good skills in at least one of the following topics: optimisation, control theory (theory side), theoretical computer science (algorithmic graph theory, complexity theory, etc). Knowledge in topological data analysis is an advantage. *IMPORTANT*: Eligibility requirement: The candidate should have a MSc degree by the start of the PhD. Application deadline: 28th April 2021 (so if you are interested, please contact me asap at: long.tran-thanh@warwick.ac.uk) More details can be found here: https://warwick.ac.uk/global/partnerships/europe/eutopia/fundingop/eutopia_phd_call_description_2021_fv_1.pdf A few words about Warwick: Its Computer Science department is one of the top ones in the UK. It has one of the strongest theoretical computer science research labs in Europe. Its discrete Maths centre (DIMAP) is also word-leading. My lab focuses on the theoretical side of human-agent learning (e.g., multiagent learning, strategic learning, explainability, etc.), which usually requires combinations of game theory, graph theory, algebraic topology etc. with machine learning.",,,,,
"Mng Æ¡i cho em há»i lÃ  khi lÃ m máº¥y dá»± Ã¡n computer vision detection thÃ¬ mng hay chá»n algorithm nÃ o. CÃ³ yolov4 vs faster Rcnn lÃ  mÃ¬nh nghÄ© Ä‘áº¿n nhanh nháº¥t
Yolov4 khi xÃ©t vá» áº£nh thÃ¬ hiá»‡u quáº£ kÃ©m hÆ¡n faster rcnn. MÃ  yolov5 láº¡i kÃ©m hÆ¡n v4 vÃ  lÃ  hÃ ng nhÃ¡i Ä‘áº¡o tÃªn
Faster RCNN thÃ¬ ra tá»« 2015 rá»“i, cháº¯c bayh pháº£i cÃ³ algorithm nÃ o Ä‘áº¥y tá»‘t hÆ¡n chá»© nhá»‰?
Edit: classification -> detection
Pic for reference","Mng Æ¡i cho em há»i lÃ  khi lÃ m máº¥y dá»± Ã¡n computer vision detection thÃ¬ mng hay chá»n algorithm nÃ o. CÃ³ yolov4 vs faster Rcnn lÃ  mÃ¬nh nghÄ© Ä‘áº¿n nhanh nháº¥t Yolov4 khi xÃ©t vá» áº£nh thÃ¬ hiá»‡u quáº£ kÃ©m hÆ¡n faster rcnn. MÃ  yolov5 láº¡i kÃ©m hÆ¡n v4 vÃ  lÃ  hÃ ng nhÃ¡i Ä‘áº¡o tÃªn Faster RCNN thÃ¬ ra tá»« 2015 rá»“i, cháº¯c bayh pháº£i cÃ³ algorithm nÃ o Ä‘áº¥y tá»‘t hÆ¡n chá»© nhá»‰? Edit: classification -> detection Pic for reference",,,,,
FYI!,FYI!,,,,,
Chip Huyen is Live Now at the #FOSSASIA Summit 2021 speaking on #Machine learning for scalable applications,Chip Huyen is Live Now at the Summit 2021 speaking on learning for scalable applications,#FOSSASIA	#Machine,,,,
"ChÃ o má»i ngÆ°á»i, má»›i Ä‘Ã¢y thÃ¬ nhÃ³m nghiÃªn cá»©u cá»§a em vá»«a submit má»™t bÃ i bÃ¡o vá» thuáº­t toÃ¡n Newton má»Ÿ rá»™ng (GDNM, xem [2]), dÃ¹ng Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n tá»‘i Æ°u dáº¡ng tá»•ng cá»§a hÃ m toÃ n phÆ°Æ¡ng vÃ  má»™t hÃ m lá»“i.
NhÃ³m cÅ©ng Ä‘Ã£ thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m sá»‘ trÃªn bÃ i toÃ¡n Lasso (Lasso regression, l1 regression) vÃ  káº¿t quáº£ cho tháº¥y cÅ©ng kháº£ quan khi trong cÃ¡c trÆ°á»ng há»£p mÃ  GDNM cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c thÃ¬ tá»‘c Ä‘á»™ giáº£i Ä‘á»u cÆ¡ báº£n nhanh hÆ¡n cÃ¡c thuáº­t toÃ¡n ná»•i tiáº¿ng khÃ¡c nhÆ° FISTA, APG, ADMM, vÃ  má»™t thuáº­t toÃ¡n báº­c 2 má»›i ná»•i lÃ  SSNAL (xem hÃ¬nh vá» so sÃ¡nh tá»‘c Ä‘á»™ vÃ  thuáº­t toÃ¡n chi tiáº¿t). Thuáº­t toÃ¡n Ä‘áº·c biá»‡t há»¯u hiá»‡u khi cáº§n Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao.
á» Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh, thuáº­t toÃ¡n ADMM váº«n cho tháº¥y tá»‘c Ä‘á»™ tá»‘t hÆ¡n, má»™t pháº§n vÃ¬ pháº§n code cá»§a em cÅ©ng chÆ°a tá»‘i giáº£n, má»™t pháº§n vÃ¬ Ä‘Ã³ cÅ©ng lÃ  hiá»‡n tÆ°á»£ng trong cá»• Ä‘iá»ƒn (ADMM váº«n nhanh hÆ¡n Newton cá»• Ä‘iá»ƒn á»Ÿ Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh).
Em cÅ©ng mong muá»‘n lÃ m thá»­ image processing báº±ng Lasso nhÆ° bÃ i bÃ¡o [1] Ä‘á»‘i vá»›i FISTA (xem hÃ¬nh). VÃ¬ lÃ  ngÆ°á»i má»›i trong lÄ©nh vá»±c nÃ y nÃªn em mong muá»‘n Ä‘Æ°á»£c trao Ä‘á»•i má»™t sá»‘ cÃ¢u há»i nhÆ° sau áº¡.
1. CÃ³ tÃ i liá»‡u nÃ o mÃ´ táº£ chi tiáº¿t vá» bÃ i toÃ¡n linear inverse problems (deblurring images by Gaussian blur) khÃ´ng áº¡? Em cÃ³ Ä‘á»c trong bÃ i bÃ¡o [trang 184, 1], nhÆ°ng ngÆ°á»i ta khÃ´ng chá»‰ cá»¥ thá»ƒ cÃ¡ch lÃ m sao Ä‘á»ƒ láº¥y blur matrix, vÃ  inverse wavelet transform matrix.
2. Äá»ƒ lÃ m thÃ­ nghiá»‡m image processing (cá»¥ thá»ƒ lÃ  deblurring image) cho áº£nh (256x256) thÃ¬ cáº§n mÃ¡y cáº¥u hÃ¬nh nhÆ° tháº¿ nÃ o áº¡? Hiá»‡n táº¡i mÃ¡y em 16GB RAM thÃ¬ mÃ¡y bÃ¡o trÃ n bá»™ nhá»›, cáº§n khoáº£ng 50GB RAM. MÃ  em cÅ©ng khÃ´ng biáº¿t khi láº¯p ram 64GB vÃ´ cháº¡y Ä‘á»‘i vá»›i mÃ¡y CPU tá»‘c Ä‘á»™ 4.1 Ghz (khoáº£ng 500 bÆ°á»›c láº·p Ä‘á»‘i vá»›i FISTA) cÃ³ bá»‹ lÃ¢u (cá»¡ khoáº£ng vÃ i ngÃ y) khÃ´ng áº¡?
3. Thuáº­t toÃ¡n GDNM chÆ°a thá»ƒ xá»­ lÃ­ trÆ°á»ng há»£p ma tráº­n Ä‘Æ°á»£c cho lÃ  singular (hoáº·c sparse, gáº§n singular). Má»i ngÆ°á»i cho em há»i lÃ  cÃ¡c ma tráº­n gáº§n singular nhÆ° tháº¿ nÃ y cÃ³ gáº·p nhiá»u trong cÃ¡c bÃ i toÃ¡n Lasso thá»±c táº¿ khÃ´ng áº¡?
NgoÃ i ra, náº¿u má»i ngÆ°á»i cÃ³ thá»ƒ xem qua vÃ  cho em nháº­n xÃ©t vá» pháº§n code cá»§a em á»Ÿ https://github.com/he9180/GDNM thÃ¬ em cÅ©ng ráº¥t cáº£m Æ¡n áº¡!
[1] A. Beck, M. Teboulle: A fast iterative shrinkage-thresholding algorithm for linear inverse problems, SIAM journal on imaging sciences 2 (1), 183-202
link http://www.cs.cmu.edu/afs/cs/Web/People/airg/readings/2012_02_21_a_fast_iterative_shrinkage-thresholding.pdf
[2] PD. Khanh, B. Mordukhovich, VT. Phat, DB. Tran: Generalized Damped Newton Algorithms in Nonsmooth Optimization with Applications to Lasso Problems, arXiv preprint https://arxiv.org/abs/2101.10555
 â€” vá»›i VÃµ ThÃ nh PhÃ¡t.","ChÃ o má»i ngÆ°á»i, má»›i Ä‘Ã¢y thÃ¬ nhÃ³m nghiÃªn cá»©u cá»§a em vá»«a submit má»™t bÃ i bÃ¡o vá» thuáº­t toÃ¡n Newton má»Ÿ rá»™ng (GDNM, xem [2]), dÃ¹ng Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n tá»‘i Æ°u dáº¡ng tá»•ng cá»§a hÃ m toÃ n phÆ°Æ¡ng vÃ  má»™t hÃ m lá»“i. NhÃ³m cÅ©ng Ä‘Ã£ thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m sá»‘ trÃªn bÃ i toÃ¡n Lasso (Lasso regression, l1 regression) vÃ  káº¿t quáº£ cho tháº¥y cÅ©ng kháº£ quan khi trong cÃ¡c trÆ°á»ng há»£p mÃ  GDNM cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c thÃ¬ tá»‘c Ä‘á»™ giáº£i Ä‘á»u cÆ¡ báº£n nhanh hÆ¡n cÃ¡c thuáº­t toÃ¡n ná»•i tiáº¿ng khÃ¡c nhÆ° FISTA, APG, ADMM, vÃ  má»™t thuáº­t toÃ¡n báº­c 2 má»›i ná»•i lÃ  SSNAL (xem hÃ¬nh vá» so sÃ¡nh tá»‘c Ä‘á»™ vÃ  thuáº­t toÃ¡n chi tiáº¿t). Thuáº­t toÃ¡n Ä‘áº·c biá»‡t há»¯u hiá»‡u khi cáº§n Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao. á» Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh, thuáº­t toÃ¡n ADMM váº«n cho tháº¥y tá»‘c Ä‘á»™ tá»‘t hÆ¡n, má»™t pháº§n vÃ¬ pháº§n code cá»§a em cÅ©ng chÆ°a tá»‘i giáº£n, má»™t pháº§n vÃ¬ Ä‘Ã³ cÅ©ng lÃ  hiá»‡n tÆ°á»£ng trong cá»• Ä‘iá»ƒn (ADMM váº«n nhanh hÆ¡n Newton cá»• Ä‘iá»ƒn á»Ÿ Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh). Em cÅ©ng mong muá»‘n lÃ m thá»­ image processing báº±ng Lasso nhÆ° bÃ i bÃ¡o [1] Ä‘á»‘i vá»›i FISTA (xem hÃ¬nh). VÃ¬ lÃ  ngÆ°á»i má»›i trong lÄ©nh vá»±c nÃ y nÃªn em mong muá»‘n Ä‘Æ°á»£c trao Ä‘á»•i má»™t sá»‘ cÃ¢u há»i nhÆ° sau áº¡. 1. CÃ³ tÃ i liá»‡u nÃ o mÃ´ táº£ chi tiáº¿t vá» bÃ i toÃ¡n linear inverse problems (deblurring images by Gaussian blur) khÃ´ng áº¡? Em cÃ³ Ä‘á»c trong bÃ i bÃ¡o [trang 184, 1], nhÆ°ng ngÆ°á»i ta khÃ´ng chá»‰ cá»¥ thá»ƒ cÃ¡ch lÃ m sao Ä‘á»ƒ láº¥y blur matrix, vÃ  inverse wavelet transform matrix. 2. Äá»ƒ lÃ m thÃ­ nghiá»‡m image processing (cá»¥ thá»ƒ lÃ  deblurring image) cho áº£nh (256x256) thÃ¬ cáº§n mÃ¡y cáº¥u hÃ¬nh nhÆ° tháº¿ nÃ o áº¡? Hiá»‡n táº¡i mÃ¡y em 16GB RAM thÃ¬ mÃ¡y bÃ¡o trÃ n bá»™ nhá»›, cáº§n khoáº£ng 50GB RAM. MÃ  em cÅ©ng khÃ´ng biáº¿t khi láº¯p ram 64GB vÃ´ cháº¡y Ä‘á»‘i vá»›i mÃ¡y CPU tá»‘c Ä‘á»™ 4.1 Ghz (khoáº£ng 500 bÆ°á»›c láº·p Ä‘á»‘i vá»›i FISTA) cÃ³ bá»‹ lÃ¢u (cá»¡ khoáº£ng vÃ i ngÃ y) khÃ´ng áº¡? 3. Thuáº­t toÃ¡n GDNM chÆ°a thá»ƒ xá»­ lÃ­ trÆ°á»ng há»£p ma tráº­n Ä‘Æ°á»£c cho lÃ  singular (hoáº·c sparse, gáº§n singular). Má»i ngÆ°á»i cho em há»i lÃ  cÃ¡c ma tráº­n gáº§n singular nhÆ° tháº¿ nÃ y cÃ³ gáº·p nhiá»u trong cÃ¡c bÃ i toÃ¡n Lasso thá»±c táº¿ khÃ´ng áº¡? NgoÃ i ra, náº¿u má»i ngÆ°á»i cÃ³ thá»ƒ xem qua vÃ  cho em nháº­n xÃ©t vá» pháº§n code cá»§a em á»Ÿ https://github.com/he9180/GDNM thÃ¬ em cÅ©ng ráº¥t cáº£m Æ¡n áº¡! [1] A. Beck, M. Teboulle: A fast iterative shrinkage-thresholding algorithm for linear inverse problems, SIAM journal on imaging sciences 2 (1), 183-202 link http://www.cs.cmu.edu/afs/cs/Web/People/airg/readings/2012_02_21_a_fast_iterative_shrinkage-thresholding.pdf [2] PD. Khanh, B. Mordukhovich, VT. Phat, DB. Tran: Generalized Damped Newton Algorithms in Nonsmooth Optimization with Applications to Lasso Problems, arXiv preprint https://arxiv.org/abs/2101.10555 â€” vá»›i VÃµ ThÃ nh PhÃ¡t.",,,,,
"Mn cho em há»i cÃ³ cáº§n thiáº¿t pháº£i code Ä‘c thuáº­t toÃ¡n SVM from scratch ko? chá»© em Ä‘á»c bÃ i cÆ¡ sá»Ÿ toÃ¡n há»c tá»« bÃ i Convex cá»§a anh Tiá»‡p tháº¥y khÃ³ hiá»ƒu quÃ¡ Ã .
Thanks!",Mn cho em há»i cÃ³ cáº§n thiáº¿t pháº£i code Ä‘c thuáº­t toÃ¡n SVM from scratch ko? chá»© em Ä‘á»c bÃ i cÆ¡ sá»Ÿ toÃ¡n há»c tá»« bÃ i Convex cá»§a anh Tiá»‡p tháº¥y khÃ³ hiá»ƒu quÃ¡ Ã . Thanks!,,,,,
"Hey, I've created an introduction to different types of probability distributions using R programming: https://statisticsglobe.com/probability-distributions-in-r
#datascienceeducation #RStats","Hey, I've created an introduction to different types of probability distributions using R programming: https://statisticsglobe.com/probability-distributions-in-r",#datascienceeducation	#RStats,,,,
"CÃCH MÃŒNH ÄÃƒ Táº O RA PLUGIN Äáº¦U TIÃŠN TRÃŠN THáº¾ GIá»šI GIÃšP YOUTUBE NHáº¬N DIá»†N... TIáº¾NG KHOAI TÃ‚Y CHIÃŠN SAU 178 GIá»œ Ä‚N
Hi cÃ¡c báº¡n, mÃ¬nh lÃ  Minh, hiá»‡n Ä‘ang lÃ  má»™t kÄ© sÆ° AI táº¡i SÃ i GÃ²n
Äá»£t dá»‹ch vá»«a rá»“i, vÃ¬ á»Ÿ nhÃ  ráº£nh rá»—i vÃ  cÅ©ng Äƒn nhiá»u khoai tÃ¢y chiáº¿n quÃ¡ Ä‘Ã , nÃªn mÃ¬nh Ä‘Ã£ nháº­n ra má»™t váº¥n Ä‘á» VÃ” CÃ™NG NGHIÃŠM TRá»ŒNG: tiáº¿ng khoai tÃ¢y chiÃªn... Ã¡t máº¥t tiáº¿ng video youtube cá»§a mÃ¬nh.
ChÃ­nh vÃ¬ váº­y, mÃ¬nh Ä‘Ã£ phÃ¡t triá»ƒn má»™t plugin cÃ³ kháº£ nÄƒng tá»± Ä‘á»™ng nháº­n diá»‡n tiáº¿ng khoai tÃ¢y chiÃªn Ä‘á»ƒ kÃ­ch hoáº¡t phá»¥ Ä‘á», giÃºp báº¡n vá»«a nhai khoai tÃ¢y chiÃªn, vá»«a khÃ´ng lo bá» lá»¡ ná»™i dung video
Má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o link plugin táº¡i Ä‘Ã¢y nha: http://bit.ly/3eDI0t8

BÆ¯á»šC 01: Thu tháº­p dá»¯ liá»‡u
Äá»ƒ dáº¡y Ã¢m thanh giÃ²n cho mÃ¡y há»c, bá»™ sÆ°u táº­p gá»“m 17.512 máº«u Ã¢m thanh â€œgiÃ²n rá»¥m"" khÃ¡c nhau Ä‘Ã£ Ä‘Æ°á»£c thá»­ nghiá»‡m, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 178 giá» Äƒn khoai tÃ¢y chiÃªn.
Äiá»u nÃ y cÅ©ng Ä‘á»“ng nghÄ©a ráº¥t nhiá»u Snack Khoai TÃ¢y Ä‘Ã£ â€œhao tá»‘n"" trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn plugin.

BÆ¯á»šC 02: Tiá»n xá»­ lÃ½
LÃºc nÃ y, cÃ¡c Ã¢m thanh Ä‘Æ°á»£c chuáº©n bá»‹ sáºµn sÃ ng cho viá»‡c xá»­ lÃ½.
Äá»ƒ Ä‘áº£m báº£o plugin cháº¡y Ä‘Æ°á»£c hoÃ n toÃ n á»Ÿ phÃ­a ngÆ°á»i dÃ¹ng trÃªn trÃ¬nh duyá»‡t sá»­ dá»¥ng Tensorflow JS, cÃ¡c máº«u sá»­ dá»¥ng pháº£i tuÃ¢n thá»§ cÃ¡c Ä‘iá»u kiá»‡n vÃ  quy trÃ¬nh kháº¯t khe:
Ã‚m thanh Ä‘Æ¡n Ã¢m 22.050 KHz, cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i náº¿u cáº§n.
Sá»­ dá»¥ng librosa trong Python Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c máº«u Ã¢m thanh Ä‘á»ƒ xÃ¡c thá»±c hoáº·c loáº¡i bá».
Tiáº¿p Ä‘áº¿n, cÃ¡c há»‡ táº§n sá»‘ Mel Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh thÃ´ng tin nháº­n thá»©c vÃ  giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u. Cuá»‘i cÃ¹ng, dÃ¹ng Meyda Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u.
Sau cÃ¡c bÆ°á»›c ká»ƒ trÃªn, plugin Crispy Subtitles cÃ³ Ä‘Æ°á»£c thÃ´ng tin quang phá»• nhÆ° hÃ¬nh

BÆ¯á»šC 03: HÃ¬nh thÃ nh mÃ´ hÃ¬nh
Tiáº¿p theo, dÃ¹ng Keras vÃ  Tensorflow Ä‘á»ƒ thiáº¿t láº­p mÃ´ hÃ¬nh mÃ¡y há»c phÃ¢n loáº¡i Ã¢m thanh.
TrÆ°á»›c tiÃªn, táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n loáº¡i theo nhÃ£n tÃ­ch cá»±c vÃ  tiÃªu cá»±c, táº¡o nÃªn táº­p há»£p thá»­ nghiá»‡m vÃ  Ä‘Ã o táº¡o báº±ng sklearn.
Sau ráº¥t nhiá»u thá»­ nghiá»‡m, mÃ´ hÃ¬nh phÃ¢n lá»›p bao gá»“m 2 lá»›p Conv2D + Maxpooling2D, má»™t lá»›p Dense (128) vá»›i kÃ­ch hoáº¡t relu vÃ  má»™t lá»›p Dense (2) vá»›i kÃ­ch hoáº¡t softmax Ä‘Æ°á»£c lá»±a chá»n.
Nhá»¯ng Ã¢m thanh bá»‹ loáº¡i Ä‘Æ°á»£c thÃªm vÃ o giá»¯a má»—i lá»›p Ä‘á»ƒ trÃ¡nh bá»‹ quÃ¡ khá»›p.

BÆ¯á»šC 04: Huáº¥n luyá»‡n
Cross entropy phÃ¢n loáº¡i Ä‘á»ƒ tÃ­nh toÃ¡n tá»•n tháº¥t vÃ  sá»­ dá»¥ng trÃ¬nh tá»‘i Æ°u hÃ³a Adam Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh vá»›i kÃ­ch thÆ°á»›c lÃ´ lÃ  64 trong 75 epochs. Sau cÃ¹ng, mÃ´ hÃ¬nh cÃ³ Ä‘á»™ khÃ´ng chÃ­nh xÃ¡c lÃ  0,0831 vÃ  Ä‘á»™ chÃ­nh xÃ¡c lÃ  0,986.

BÆ¯á»šC 05: Thiáº¿t láº­p plugin vÃ  tÃ­ch há»£p mÃ´ hÃ¬nh
QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trong há»‡ sinh thÃ¡i Python.
Sau Ä‘Ã³, chÃºng Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i báº±ng Tensorflow JS vÃ  cuá»‘i cÃ¹ng chá»‰ cÃ²n kÃ­ch thÆ°á»›c dÆ°á»›i 5MB vÃ  Ä‘Æ°á»£c tÃ­ch há»£p trong plugin. Khi kÃ­ch hoáº¡t plugin, phá»¥ Ä‘á» sáº½ xuáº¥t hiá»‡n.
Trong trÆ°á»ng há»£p video cÃ³ phá»¥ Ä‘á» nhÆ°ng bá»‹ táº¯t thÃ¬ mÃ¡y há»c cÅ©ng sáº½ nháº­n diá»‡n vÃ  tá»± Ä‘á»™ng báº­t phá»¥ Ä‘á» lÃªn sau 10s.","CÃCH MÃŒNH ÄÃƒ Táº O RA PLUGIN Äáº¦U TIÃŠN TRÃŠN THáº¾ GIá»šI GIÃšP YOUTUBE NHáº¬N DIá»†N... TIáº¾NG KHOAI TÃ‚Y CHIÃŠN SAU 178 GIá»œ Ä‚N Hi cÃ¡c báº¡n, mÃ¬nh lÃ  Minh, hiá»‡n Ä‘ang lÃ  má»™t kÄ© sÆ° AI táº¡i SÃ i GÃ²n Äá»£t dá»‹ch vá»«a rá»“i, vÃ¬ á»Ÿ nhÃ  ráº£nh rá»—i vÃ  cÅ©ng Äƒn nhiá»u khoai tÃ¢y chiáº¿n quÃ¡ Ä‘Ã , nÃªn mÃ¬nh Ä‘Ã£ nháº­n ra má»™t váº¥n Ä‘á» VÃ” CÃ™NG NGHIÃŠM TRá»ŒNG: tiáº¿ng khoai tÃ¢y chiÃªn... Ã¡t máº¥t tiáº¿ng video youtube cá»§a mÃ¬nh. ChÃ­nh vÃ¬ váº­y, mÃ¬nh Ä‘Ã£ phÃ¡t triá»ƒn má»™t plugin cÃ³ kháº£ nÄƒng tá»± Ä‘á»™ng nháº­n diá»‡n tiáº¿ng khoai tÃ¢y chiÃªn Ä‘á»ƒ kÃ­ch hoáº¡t phá»¥ Ä‘á», giÃºp báº¡n vá»«a nhai khoai tÃ¢y chiÃªn, vá»«a khÃ´ng lo bá» lá»¡ ná»™i dung video Má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o link plugin táº¡i Ä‘Ã¢y nha: http://bit.ly/3eDI0t8 BÆ¯á»šC 01: Thu tháº­p dá»¯ liá»‡u Äá»ƒ dáº¡y Ã¢m thanh giÃ²n cho mÃ¡y há»c, bá»™ sÆ°u táº­p gá»“m 17.512 máº«u Ã¢m thanh â€œgiÃ²n rá»¥m"" khÃ¡c nhau Ä‘Ã£ Ä‘Æ°á»£c thá»­ nghiá»‡m, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 178 giá» Äƒn khoai tÃ¢y chiÃªn. Äiá»u nÃ y cÅ©ng Ä‘á»“ng nghÄ©a ráº¥t nhiá»u Snack Khoai TÃ¢y Ä‘Ã£ â€œhao tá»‘n"" trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn plugin. BÆ¯á»šC 02: Tiá»n xá»­ lÃ½ LÃºc nÃ y, cÃ¡c Ã¢m thanh Ä‘Æ°á»£c chuáº©n bá»‹ sáºµn sÃ ng cho viá»‡c xá»­ lÃ½. Äá»ƒ Ä‘áº£m báº£o plugin cháº¡y Ä‘Æ°á»£c hoÃ n toÃ n á»Ÿ phÃ­a ngÆ°á»i dÃ¹ng trÃªn trÃ¬nh duyá»‡t sá»­ dá»¥ng Tensorflow JS, cÃ¡c máº«u sá»­ dá»¥ng pháº£i tuÃ¢n thá»§ cÃ¡c Ä‘iá»u kiá»‡n vÃ  quy trÃ¬nh kháº¯t khe: Ã‚m thanh Ä‘Æ¡n Ã¢m 22.050 KHz, cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i náº¿u cáº§n. Sá»­ dá»¥ng librosa trong Python Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c máº«u Ã¢m thanh Ä‘á»ƒ xÃ¡c thá»±c hoáº·c loáº¡i bá». Tiáº¿p Ä‘áº¿n, cÃ¡c há»‡ táº§n sá»‘ Mel Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ chuyá»ƒn dá»¯ liá»‡u thÃ´ thÃ nh thÃ´ng tin nháº­n thá»©c vÃ  giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u. Cuá»‘i cÃ¹ng, dÃ¹ng Meyda Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u. Sau cÃ¡c bÆ°á»›c ká»ƒ trÃªn, plugin Crispy Subtitles cÃ³ Ä‘Æ°á»£c thÃ´ng tin quang phá»• nhÆ° hÃ¬nh BÆ¯á»šC 03: HÃ¬nh thÃ nh mÃ´ hÃ¬nh Tiáº¿p theo, dÃ¹ng Keras vÃ  Tensorflow Ä‘á»ƒ thiáº¿t láº­p mÃ´ hÃ¬nh mÃ¡y há»c phÃ¢n loáº¡i Ã¢m thanh. TrÆ°á»›c tiÃªn, táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n loáº¡i theo nhÃ£n tÃ­ch cá»±c vÃ  tiÃªu cá»±c, táº¡o nÃªn táº­p há»£p thá»­ nghiá»‡m vÃ  Ä‘Ã o táº¡o báº±ng sklearn. Sau ráº¥t nhiá»u thá»­ nghiá»‡m, mÃ´ hÃ¬nh phÃ¢n lá»›p bao gá»“m 2 lá»›p Conv2D + Maxpooling2D, má»™t lá»›p Dense (128) vá»›i kÃ­ch hoáº¡t relu vÃ  má»™t lá»›p Dense (2) vá»›i kÃ­ch hoáº¡t softmax Ä‘Æ°á»£c lá»±a chá»n. Nhá»¯ng Ã¢m thanh bá»‹ loáº¡i Ä‘Æ°á»£c thÃªm vÃ o giá»¯a má»—i lá»›p Ä‘á»ƒ trÃ¡nh bá»‹ quÃ¡ khá»›p. BÆ¯á»šC 04: Huáº¥n luyá»‡n Cross entropy phÃ¢n loáº¡i Ä‘á»ƒ tÃ­nh toÃ¡n tá»•n tháº¥t vÃ  sá»­ dá»¥ng trÃ¬nh tá»‘i Æ°u hÃ³a Adam Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh vá»›i kÃ­ch thÆ°á»›c lÃ´ lÃ  64 trong 75 epochs. Sau cÃ¹ng, mÃ´ hÃ¬nh cÃ³ Ä‘á»™ khÃ´ng chÃ­nh xÃ¡c lÃ  0,0831 vÃ  Ä‘á»™ chÃ­nh xÃ¡c lÃ  0,986. BÆ¯á»šC 05: Thiáº¿t láº­p plugin vÃ  tÃ­ch há»£p mÃ´ hÃ¬nh QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trong há»‡ sinh thÃ¡i Python. Sau Ä‘Ã³, chÃºng Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i báº±ng Tensorflow JS vÃ  cuá»‘i cÃ¹ng chá»‰ cÃ²n kÃ­ch thÆ°á»›c dÆ°á»›i 5MB vÃ  Ä‘Æ°á»£c tÃ­ch há»£p trong plugin. Khi kÃ­ch hoáº¡t plugin, phá»¥ Ä‘á» sáº½ xuáº¥t hiá»‡n. Trong trÆ°á»ng há»£p video cÃ³ phá»¥ Ä‘á» nhÆ°ng bá»‹ táº¯t thÃ¬ mÃ¡y há»c cÅ©ng sáº½ nháº­n diá»‡n vÃ  tá»± Ä‘á»™ng báº­t phá»¥ Ä‘á» lÃªn sau 10s.",,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ vÃ i tháº¯c máº¯c vá» mean, medium, mode.
MÃ¬nh biáº¿t cÃ¡ch tÃ­nh 3 giÃ¡ trá»‹ Ä‘Ã³. Tuy nhiÃªn khi nÃ o sá»­ dá»¥ng thÃ¬ váº«n cÃ²n mÆ¡ há»“. CÃ¡c sá»‘ nÃ y thÆ°á»ng sá»­ dá»¥ng nháº¥t lÃ  khi Ä‘iá»n vÃ o cÃ¡c giÃ¡ trá»‹ bá»‹ thiáº¿u.
Trong Ä‘áº§u mÃ¬nh máº·c Ä‘á»‹nh: Náº¿u dá»¯ liá»‡u cÃ¢n báº±ng. Auto dÃ¹ng mean. Náº¿u dá»¯ liá»‡u máº¥t cÃ¢n báº±ng, pháº£i sá»­ dá»¥ng median. CÃ¢u há»i: Táº¡i sao ngÆ°á»i ta khÃ´ng luÃ´n luÃ´n sá»­ dá»¥ng median? Cá»© xem nhÆ° dá»¯ liá»‡u luÃ´n máº¥t cÃ¢n báº±ng.
Mode sá»­ dá»¥ng khi nÃ o?
Náº¿u mÃ¬nh sá»± dá»¥ng má»™t Ä‘áº¡i lÆ°á»£ng má»›i: (mean+median)/2 lÃ m giÃ¡ trá»‹ trung bÃ¬nh thÃ¬ cÃ³ á»•n khÃ´ng?

Cáº£m Æ¡n nhiá»u.","ChÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ vÃ i tháº¯c máº¯c vá» mean, medium, mode. MÃ¬nh biáº¿t cÃ¡ch tÃ­nh 3 giÃ¡ trá»‹ Ä‘Ã³. Tuy nhiÃªn khi nÃ o sá»­ dá»¥ng thÃ¬ váº«n cÃ²n mÆ¡ há»“. CÃ¡c sá»‘ nÃ y thÆ°á»ng sá»­ dá»¥ng nháº¥t lÃ  khi Ä‘iá»n vÃ o cÃ¡c giÃ¡ trá»‹ bá»‹ thiáº¿u. Trong Ä‘áº§u mÃ¬nh máº·c Ä‘á»‹nh: Náº¿u dá»¯ liá»‡u cÃ¢n báº±ng. Auto dÃ¹ng mean. Náº¿u dá»¯ liá»‡u máº¥t cÃ¢n báº±ng, pháº£i sá»­ dá»¥ng median. CÃ¢u há»i: Táº¡i sao ngÆ°á»i ta khÃ´ng luÃ´n luÃ´n sá»­ dá»¥ng median? Cá»© xem nhÆ° dá»¯ liá»‡u luÃ´n máº¥t cÃ¢n báº±ng. Mode sá»­ dá»¥ng khi nÃ o? Náº¿u mÃ¬nh sá»± dá»¥ng má»™t Ä‘áº¡i lÆ°á»£ng má»›i: (mean+median)/2 lÃ m giÃ¡ trá»‹ trung bÃ¬nh thÃ¬ cÃ³ á»•n khÃ´ng? Cáº£m Æ¡n nhiá»u.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u sinh tiáº¿n sÄ© á»Ÿ DH Khoa há»c CÃ´ng Nghá»‡ Quá»‘c gia Seoul (SEOULTECH). MÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u vá» há»‡ thá»‘ng thá»­ áº£o quáº§n Ã¡o vÃ  cáº§n má»i ngÆ°á»i lÃ m bÃ i Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng há»‡ thá»‘ng.
NhÃ¢n tiá»‡n cÅ©ng xin há»i má»i ngÆ°á»i vá» cÃ¡ch Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng áº£nh Ä‘Æ°á»£c sinh ra áº¡. MÃ¬nh Ä‘ang dÃ¹ng IS, FID, LPIPS, SSIM. NhÆ°ng cÃ³ váº» khi áº£nh Ä‘Æ°á»£c sinh ra má»™t cÃ¡ch tá»± nhiÃªn vÃ  nhÆ° tháº­t nhÆ°ng khÃ´ng aligned vá»›i áº£nh groundtruth thÃ¬ cÃ¡c Ä‘á»™ Ä‘o nÃ y khÃ´ng Ä‘Ãºng láº¯m.
CÃ²n vá» áº£nh táº¡o ra mÃ  khÃ´ng cÃ³ groundtruth thÃ¬ ngoÃ i cÃ¡ch nhá» ngÆ°á»i dÃ¹ng Ä‘Ã¡nh giÃ¡ thÃ¬ cÃ²n cÃ¡c nÃ o khÃ¡c khÃ´ng áº¡?
Mong má»i ngÆ°á»i há»— trá»£ Ä‘Ã¡nh giÃ¡ vÃ  gÃ³p Ã½.
Xin chÃ¢n thÃ nh cáº£m Æ¡n.
Link Ä‘Ã¡nh giÃ¡ bÃªn dÆ°á»›i.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u sinh tiáº¿n sÄ© á»Ÿ DH Khoa há»c CÃ´ng Nghá»‡ Quá»‘c gia Seoul (SEOULTECH). MÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u vá» há»‡ thá»‘ng thá»­ áº£o quáº§n Ã¡o vÃ  cáº§n má»i ngÆ°á»i lÃ m bÃ i Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng há»‡ thá»‘ng. NhÃ¢n tiá»‡n cÅ©ng xin há»i má»i ngÆ°á»i vá» cÃ¡ch Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng áº£nh Ä‘Æ°á»£c sinh ra áº¡. MÃ¬nh Ä‘ang dÃ¹ng IS, FID, LPIPS, SSIM. NhÆ°ng cÃ³ váº» khi áº£nh Ä‘Æ°á»£c sinh ra má»™t cÃ¡ch tá»± nhiÃªn vÃ  nhÆ° tháº­t nhÆ°ng khÃ´ng aligned vá»›i áº£nh groundtruth thÃ¬ cÃ¡c Ä‘á»™ Ä‘o nÃ y khÃ´ng Ä‘Ãºng láº¯m. CÃ²n vá» áº£nh táº¡o ra mÃ  khÃ´ng cÃ³ groundtruth thÃ¬ ngoÃ i cÃ¡ch nhá» ngÆ°á»i dÃ¹ng Ä‘Ã¡nh giÃ¡ thÃ¬ cÃ²n cÃ¡c nÃ o khÃ¡c khÃ´ng áº¡? Mong má»i ngÆ°á»i há»— trá»£ Ä‘Ã¡nh giÃ¡ vÃ  gÃ³p Ã½. Xin chÃ¢n thÃ nh cáº£m Æ¡n. Link Ä‘Ã¡nh giÃ¡ bÃªn dÆ°á»›i.",,,,,
Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m vá» gá»£i Ã½ cÃ¡c sáº£n pháº©m thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­. Tá»©c lÃ  khi khÃ¡ch hÃ ng Ä‘áº·t click chá»n vÃ o cÃ¡c sáº£n pháº©m thÃ¬ sáº½ gá»£i Ã½ ra cÃ¡c sáº£n pháº©m tÆ°Æ¡ng tá»±. NhÆ°ng náº¿u thá»±c hiá»‡n theo phÆ°Æ¡ng phÃ¡p sau Ä‘Ã¢y thÃ¬ tháº¥y khÃ´ng kháº£ thi. Vá»›i trÆ°á»ng há»£p nÃ y mÃ¬nh nÃªn dÃ¹ng mÃ´ hÃ¬nh nÃ o Ä‘á»ƒ thá»±c hiá»‡n yÃªu cáº§u bÃ i toÃ¡n nÃ y háº£ mn?,Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m vá» gá»£i Ã½ cÃ¡c sáº£n pháº©m thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­. Tá»©c lÃ  khi khÃ¡ch hÃ ng Ä‘áº·t click chá»n vÃ o cÃ¡c sáº£n pháº©m thÃ¬ sáº½ gá»£i Ã½ ra cÃ¡c sáº£n pháº©m tÆ°Æ¡ng tá»±. NhÆ°ng náº¿u thá»±c hiá»‡n theo phÆ°Æ¡ng phÃ¡p sau Ä‘Ã¢y thÃ¬ tháº¥y khÃ´ng kháº£ thi. Vá»›i trÆ°á»ng há»£p nÃ y mÃ¬nh nÃªn dÃ¹ng mÃ´ hÃ¬nh nÃ o Ä‘á»ƒ thá»±c hiá»‡n yÃªu cáº§u bÃ i toÃ¡n nÃ y háº£ mn?,,,,,
"Xin phÃ©p Admin
Xin chÃ o má»i ngÆ°á»i, Seri HÆ°á»›ng dáº«n vá» Deeplearning Ä‘Ã£ ra Ä‘Æ°á»£c upload hoÃ n táº¥t, ae nÃ o má»›i tÃ¬m hiá»ƒu vá» Deepleaning thÃ¬ vÃ o xem nhÃ©. Mong sáº½ giÃºp Ä‘Æ°á»£c nhiá»u báº¡n hiá»ƒu rÃµ báº£n cháº¥t. Äá»ƒ láº¡i comment vá» cÃ¡c video Ä‘á»ƒ chÃºng tÃ´i cáº£i thiá»‡n nhÃ©!","Xin phÃ©p Admin Xin chÃ o má»i ngÆ°á»i, Seri HÆ°á»›ng dáº«n vá» Deeplearning Ä‘Ã£ ra Ä‘Æ°á»£c upload hoÃ n táº¥t, ae nÃ o má»›i tÃ¬m hiá»ƒu vá» Deepleaning thÃ¬ vÃ o xem nhÃ©. Mong sáº½ giÃºp Ä‘Æ°á»£c nhiá»u báº¡n hiá»ƒu rÃµ báº£n cháº¥t. Äá»ƒ láº¡i comment vá» cÃ¡c video Ä‘á»ƒ chÃºng tÃ´i cáº£i thiá»‡n nhÃ©!",,,,,
"Em chÃ o má»i ngÆ°á»i. VinAI Ä‘ang tá»• chá»©c má»™t chuá»—i research seminar vá»›i speakers lÃ  giÃ¡o sÆ° tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c hÃ ng Ä‘áº§u trÃªn tháº¿ giá»›i nhÆ° Stanford, UC Berkeley, UT Austin, etc. Seminar diá»…n ra online vÃ  má»i ngÆ°á»i chá»‰ cáº§n cÃ³ link Youtube lÃ  cÃ³ thá»ƒ theo dÃµi á»Ÿ báº¥t kÃ¬ Ä‘Ã¢u.
Seminar gáº§n nháº¥t sáº½ diá»…n ra vÃ o 10h sÃ¡ng thá»© sÃ¡u tuáº§n nÃ y, speaker lÃ  giÃ¡o sÆ° ğ€ğ§ğ¢ğ¦ğğ¬ğ¡ ğ†ğšğ«ğ  tá»« University of Toronto, vá»›i chá»§ Ä‘á» ""Generalization in Reinforcement Learning and Robotics"". 
ThÃ´ng tin chi tiáº¿t: https://www.facebook.com/2279355382307133/posts/2822994024609930/?d=n
Link youtube: https://www.youtube.com/watch?v=iRSh3FIs5lU
ThÃ´ng tin vá» cÃ¡c seminar Ä‘Ã£ vÃ  sáº½ diá»…n ra: https://sites.google.com/view/vinairesearchseminarseries/","Em chÃ o má»i ngÆ°á»i. VinAI Ä‘ang tá»• chá»©c má»™t chuá»—i research seminar vá»›i speakers lÃ  giÃ¡o sÆ° tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c hÃ ng Ä‘áº§u trÃªn tháº¿ giá»›i nhÆ° Stanford, UC Berkeley, UT Austin, etc. Seminar diá»…n ra online vÃ  má»i ngÆ°á»i chá»‰ cáº§n cÃ³ link Youtube lÃ  cÃ³ thá»ƒ theo dÃµi á»Ÿ báº¥t kÃ¬ Ä‘Ã¢u. Seminar gáº§n nháº¥t sáº½ diá»…n ra vÃ o 10h sÃ¡ng thá»© sÃ¡u tuáº§n nÃ y, speaker lÃ  giÃ¡o sÆ° tá»« University of Toronto, vá»›i chá»§ Ä‘á» ""Generalization in Reinforcement Learning and Robotics"". ThÃ´ng tin chi tiáº¿t: https://www.facebook.com/2279355382307133/posts/2822994024609930/?d=n Link youtube: https://www.youtube.com/watch?v=iRSh3FIs5lU ThÃ´ng tin vá» cÃ¡c seminar Ä‘Ã£ vÃ  sáº½ diá»…n ra: https://sites.google.com/view/vinairesearchseminarseries/",,,,,
"ChÃ o Anh, Chá»‹,
Cho em há»i vá» Arima model má»™t xÃ­u áº¡.
Nhá» cÃ¡c Anh, Chá»‹ chuyÃªn vá» pháº§n nÃ y giÃºp em vá»›i áº¡.
E cÃ³ Ä‘á»c má»™t bÃ i viáº¿t cá»§a anh KhÃ¡nh vá» cÃ¡ch kiá»ƒm Ä‘á»‹nh chuá»—i dá»«ng
Em tháº¯c máº¯c má»™t sá»‘ váº¥n Ä‘á» nhÆ°:
Há»‡ sá»‘ cháº·n lÃ  gÃ¬
P-value lÃ  gÃ¬, cÃ´ng thá»©c toÃ¡n há»c cá»§a nÃ³ ntn, táº¡i sao p-value <0.05 thÃ¬ bÃ¡c bá» giáº£ thuyáº¿t H0 vÃ  cháº¥p nháº­n H1 vÃ  káº¿t luáº­n chuá»—i dá»«ng.
Há»‡ sá»‘ L cá»§a phÆ°Æ¡ng trÃ¬nh Ä‘áº·c trÆ°ng nghÄ©a lÃ  gÃ¬.
Phi ^ vÃ  SE trong cÃ´ng thá»©c DF em gá»­i kÃ¨m theo trong hÃ¬nh lÃ  gÃ¬ áº¡.
Ráº¥t mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ giáº£i Ä‘Ã¡p giÃºp. E ráº¥t cáº£m Æ¡n, mong admin duyá»‡t bÃ i giÃºp em áº¡.","ChÃ o Anh, Chá»‹, Cho em há»i vá» Arima model má»™t xÃ­u áº¡. Nhá» cÃ¡c Anh, Chá»‹ chuyÃªn vá» pháº§n nÃ y giÃºp em vá»›i áº¡. E cÃ³ Ä‘á»c má»™t bÃ i viáº¿t cá»§a anh KhÃ¡nh vá» cÃ¡ch kiá»ƒm Ä‘á»‹nh chuá»—i dá»«ng Em tháº¯c máº¯c má»™t sá»‘ váº¥n Ä‘á» nhÆ°: Há»‡ sá»‘ cháº·n lÃ  gÃ¬ P-value lÃ  gÃ¬, cÃ´ng thá»©c toÃ¡n há»c cá»§a nÃ³ ntn, táº¡i sao p-value <0.05 thÃ¬ bÃ¡c bá» giáº£ thuyáº¿t H0 vÃ  cháº¥p nháº­n H1 vÃ  káº¿t luáº­n chuá»—i dá»«ng. Há»‡ sá»‘ L cá»§a phÆ°Æ¡ng trÃ¬nh Ä‘áº·c trÆ°ng nghÄ©a lÃ  gÃ¬. Phi ^ vÃ  SE trong cÃ´ng thá»©c DF em gá»­i kÃ¨m theo trong hÃ¬nh lÃ  gÃ¬ áº¡. Ráº¥t mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ giáº£i Ä‘Ã¡p giÃºp. E ráº¥t cáº£m Æ¡n, mong admin duyá»‡t bÃ i giÃºp em áº¡.",,,"#Q&A, #math",,
"CÃ¡c anh chá»‹ cho em há»i. Trainset vÃ  testset cá»§a em Ä‘Æ°á»£c táº¡o báº±ng MATLAB vá»›i kiá»ƒu dá»¯ liá»‡u double (theo em tÃ¬m hiá»ƒu thÃ¬ nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i float64). Tuy nhiÃªn model cá»§a em Ä‘Ã£ predict táº­p testset thÃ nh kiá»ƒu single (tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i float32). Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ keras luÃ´n tráº£ vá» float64 khÃ´ng, do em nghÄ© Ä‘iá»u nÃ y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh.","CÃ¡c anh chá»‹ cho em há»i. Trainset vÃ  testset cá»§a em Ä‘Æ°á»£c táº¡o báº±ng MATLAB vá»›i kiá»ƒu dá»¯ liá»‡u double (theo em tÃ¬m hiá»ƒu thÃ¬ nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i float64). Tuy nhiÃªn model cá»§a em Ä‘Ã£ predict táº­p testset thÃ nh kiá»ƒu single (tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i float32). Váº­y cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ keras luÃ´n tráº£ vá» float64 khÃ´ng, do em nghÄ© Ä‘iá»u nÃ y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i thÃ¬ em tá»‘t nghiá»‡p bÃ¡ch khoa tphcm cÅ©ng Ä‘Æ°á»£c gáº§n 3 nÄƒm, ngÃ nh Ä‘iá»‡n - Ä‘iá»‡n tá»­, gpa lÃºc trÆ°á»›c k khÃ¡ láº¯m do lÃºc há»c cÃ³ nhiá»u chuyá»‡n tÃ¡c Ä‘á»™ng. Giá» em muá»‘n há»c lÃªn cao há»c ngÃ nh Data science thÃ¬ nÃªn há»c chÆ°Æ¡ng trÃ¬nh tháº¡c sá»¹ DS cá»§a KHTN hay há»c tiep táº¡i BK HCM áº¡","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i thÃ¬ em tá»‘t nghiá»‡p bÃ¡ch khoa tphcm cÅ©ng Ä‘Æ°á»£c gáº§n 3 nÄƒm, ngÃ nh Ä‘iá»‡n - Ä‘iá»‡n tá»­, gpa lÃºc trÆ°á»›c k khÃ¡ láº¯m do lÃºc há»c cÃ³ nhiá»u chuyá»‡n tÃ¡c Ä‘á»™ng. Giá» em muá»‘n há»c lÃªn cao há»c ngÃ nh Data science thÃ¬ nÃªn há»c chÆ°Æ¡ng trÃ¬nh tháº¡c sá»¹ DS cá»§a KHTN hay há»c tiep táº¡i BK HCM áº¡",,,,,
"#Cheatsheet #CNN
[Convolutional Neural Network - Cheatsheet]
- Ká»ƒ tá»« khi Ä‘Æ°á»£c Yan Lecun á»©ng dá»¥ng vÃ o nÄƒm 1998 trong LeNet. ChÃºng ta khÃ´ng thá»ƒ phá»§ nháº­n ráº±ng CNN Ä‘Ã£ thay tháº¿ hoÃ n toÃ n cÃ¡c mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t truyá»n thá»‘ng nhÆ° SVM, kNN, Logistic,.... trong cÃ¡c tÃ¡c vá»¥ há»c cÃ³ giÃ¡m sÃ¡t cá»§a thá»‹ giÃ¡c mÃ¡y tÃ­nh.
- Cheatsheet nÃ y sáº½ giÃºp cÃ¡c báº¡n há»‡ thá»‘ng láº¡i cÃ¡c khÃ¡i niá»‡m chÃ­nh cá»§a tÃ­ch cháº­p bao gá»“m: Bá»™ lá»c, bÆ°á»›c nháº£y, padding, hÃ m kÃ­ch hoáº¡t, VÃ¹ng nháº­n thá»©c,.... cÃ¡c layer Convol2D, Maxpooling, Fully Connected vÃ  cÃ¡ch chÃºng káº¿t há»£p trong má»™t máº¡ng CNN Ä‘iá»ƒn hÃ¬nh.
- PhÃ¢n biá»‡t vÃ  hiá»ƒu sÃ¢u cÃ¡c lá»›p bÃ i toÃ¡n trong xá»­ lÃ½ áº£nh nhÆ°: Image Classification, Object Localization, Object Detection; cÃ¡c bÃ i toÃ¡n liÃªn quan tá»›i face nhÆ° Face Verification, Face Recognition.
- Lá»›p cÃ¡c mÃ´ hÃ¬nh cÆ¡ báº£n trong Object Detection: YOLO, Faster R-CNN. CÃ¡c bÆ°á»›c thá»±c thi vÃ  sá»± khÃ¡c biá»‡t giá»¯a chÃºng.
- Lá»›p cÃ¡c bÃ i toÃ¡n sinh áº£nh nghá»‡ thuáº­t nhÆ° Neural Style Transfer vÃ  GAN kÃ¨m theo nhá»¯ng diá»…n giáº£i ngáº¯n gá»n vÃ  dá»… hiá»ƒu.
Link tham kháº£o:
https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks","[Convolutional Neural Network - Cheatsheet] - Ká»ƒ tá»« khi Ä‘Æ°á»£c Yan Lecun á»©ng dá»¥ng vÃ o nÄƒm 1998 trong LeNet. ChÃºng ta khÃ´ng thá»ƒ phá»§ nháº­n ráº±ng CNN Ä‘Ã£ thay tháº¿ hoÃ n toÃ n cÃ¡c mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t truyá»n thá»‘ng nhÆ° SVM, kNN, Logistic,.... trong cÃ¡c tÃ¡c vá»¥ há»c cÃ³ giÃ¡m sÃ¡t cá»§a thá»‹ giÃ¡c mÃ¡y tÃ­nh. - Cheatsheet nÃ y sáº½ giÃºp cÃ¡c báº¡n há»‡ thá»‘ng láº¡i cÃ¡c khÃ¡i niá»‡m chÃ­nh cá»§a tÃ­ch cháº­p bao gá»“m: Bá»™ lá»c, bÆ°á»›c nháº£y, padding, hÃ m kÃ­ch hoáº¡t, VÃ¹ng nháº­n thá»©c,.... cÃ¡c layer Convol2D, Maxpooling, Fully Connected vÃ  cÃ¡ch chÃºng káº¿t há»£p trong má»™t máº¡ng CNN Ä‘iá»ƒn hÃ¬nh. - PhÃ¢n biá»‡t vÃ  hiá»ƒu sÃ¢u cÃ¡c lá»›p bÃ i toÃ¡n trong xá»­ lÃ½ áº£nh nhÆ°: Image Classification, Object Localization, Object Detection; cÃ¡c bÃ i toÃ¡n liÃªn quan tá»›i face nhÆ° Face Verification, Face Recognition. - Lá»›p cÃ¡c mÃ´ hÃ¬nh cÆ¡ báº£n trong Object Detection: YOLO, Faster R-CNN. CÃ¡c bÆ°á»›c thá»±c thi vÃ  sá»± khÃ¡c biá»‡t giá»¯a chÃºng. - Lá»›p cÃ¡c bÃ i toÃ¡n sinh áº£nh nghá»‡ thuáº­t nhÆ° Neural Style Transfer vÃ  GAN kÃ¨m theo nhá»¯ng diá»…n giáº£i ngáº¯n gá»n vÃ  dá»… hiá»ƒu. Link tham kháº£o: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks",#Cheatsheet	#CNN,,,,
"ChÃ o cÃ¡c anh chá»‹,
Hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» LSTM trong time-series database. A chá»‹ cho em há»i lÃ  lÃ m sao Ä‘á»ƒ mÃ¬nh lá»±a chá»n Ä‘Æ°á»£c sá»‘ layer phÃ¹ há»£p cho mÃ´ hÃ¬nh máº¡ng cá»§a mÃ¬nh Ä‘Æ°á»£c áº¡. Cá»¥ thá»ƒ dá»±a trÃªn tiÃªu chÃ­ gÃ¬ áº¡. Em cÃ³ Ä‘á»c cÃ¡c bÃ i bÃ¡o vá» LSTM nhÆ°ng pháº§n nÃ y cÃ¡c tÃ¡c giáº£ Ã­t Ä‘á» cáº­p Ä‘áº¿n áº¡. E ráº¥t mong tÃ¬m Ä‘Æ°á»£c anh chá»‹ nÃ o cÃ³ hÆ°á»›ng nghiÃªn cá»©u cÃ¹ng vá»›i em Ä‘á»ƒ giÃºp em thÃªm kiáº¿n thá»©c pháº§n nÃ y vá»›i áº¡.","ChÃ o cÃ¡c anh chá»‹, Hiá»‡n táº¡i em Ä‘ang nghiÃªn cá»©u vá» LSTM trong time-series database. A chá»‹ cho em há»i lÃ  lÃ m sao Ä‘á»ƒ mÃ¬nh lá»±a chá»n Ä‘Æ°á»£c sá»‘ layer phÃ¹ há»£p cho mÃ´ hÃ¬nh máº¡ng cá»§a mÃ¬nh Ä‘Æ°á»£c áº¡. Cá»¥ thá»ƒ dá»±a trÃªn tiÃªu chÃ­ gÃ¬ áº¡. Em cÃ³ Ä‘á»c cÃ¡c bÃ i bÃ¡o vá» LSTM nhÆ°ng pháº§n nÃ y cÃ¡c tÃ¡c giáº£ Ã­t Ä‘á» cáº­p Ä‘áº¿n áº¡. E ráº¥t mong tÃ¬m Ä‘Æ°á»£c anh chá»‹ nÃ o cÃ³ hÆ°á»›ng nghiÃªn cá»©u cÃ¹ng vá»›i em Ä‘á»ƒ giÃºp em thÃªm kiáº¿n thá»©c pháº§n nÃ y vá»›i áº¡.",,,,,
"Super Fast and Accurate 3D Object Detection based on LiDAR
Fast training, Fast inference
An Anchor-free approach
No Non-Max-Suppression
Model:
ResNet-based Keypoint Feature Pyramid Network (KFPN)
Inputs: Bird-eye-view (BEV) maps that are encoded by height, intensity, and density of 3D LiDAR point clouds.
Outputs: 7 degrees of freedom (7-DOF) of objects: 3D center (cx, cy, cz), 3D dimension (l, w, h), and heading angle (Î¸) in radians of bounding boxes.
Objects: Cars, Pedestrians, Cyclists.
The pre-trained model has been released in the repo.

Source code: https://github.com/maudzung/Super-Fast-Accurate-3D-Object-Detection

------------------------------------------------------
HÆ°á»›ng tiáº¿p cáº­n á»Ÿ trÃªn cÃ³ thá»ƒ má»Ÿ rá»™ng vá»›i bÃ i toÃ¡n xÃ¡c Ä‘á»‹nh vá»‹ trÃ­, kÃ­ch thÆ°á»›c, vÃ  phÃ¢n loáº¡i cÃ¡c há»™p xoay (rorated boxes) chá»©a váº­t thá»ƒ trong hÃ¬nh áº£nh 2D RGB thÃ´ng thÆ°á»ng. DÃ¹ng YOLO cÅ©ng cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n trÃªn nhÆ°ng cÃ³ má»™t sá»‘ háº¡n cháº¿ nhÆ°: Viá»‡c tÃ¬m anchors phÃ¹ há»£p khÃ´ng Ä‘Æ¡n giáº£n (vÃ¬ pháº£i quan tÃ¢m tá»›i cáº£ gÃ³c xoay), viá»‡c tÃ­nh toÃ¡n IoU giá»¯a cÃ¡c há»™p xoay cÅ©ng ráº¥t ""tá»‘n kÃ©m"", cháº­m vÃ¬ khÃ´ng vectorize Ä‘Æ°á»£c. Äiá»u Ä‘Ã³ dáº«n tá»›i há»‡ quáº£ lÃ  training model lÃ¢u hÆ¡n, tá»‘c Ä‘á»™ inference cháº­m hÆ¡n ráº¥t nhiá»u so vá»›i hÆ°á»›ng tiáº¿p cáº­n anchor-free. NgoÃ i ra, model sá»­ dá»¥ng á»Ÿ trong hÆ°á»›ng tiáº¿p cáº­n anchor-free á»Ÿ trÃªn cÅ©ng nhá» (Ã­t parameters) hÆ¡n nhiá»u so vá»›i YOLO models, Ä‘iá»u Ä‘Ã³ giÃºp trÃ¡nh overfitting khi táº­p dá»¯ liá»‡u khÃ´ng quÃ¡ lá»›n.","Super Fast and Accurate 3D Object Detection based on LiDAR Fast training, Fast inference An Anchor-free approach No Non-Max-Suppression Model: ResNet-based Keypoint Feature Pyramid Network (KFPN) Inputs: Bird-eye-view (BEV) maps that are encoded by height, intensity, and density of 3D LiDAR point clouds. Outputs: 7 degrees of freedom (7-DOF) of objects: 3D center (cx, cy, cz), 3D dimension (l, w, h), and heading angle (Î¸) in radians of bounding boxes. Objects: Cars, Pedestrians, Cyclists. The pre-trained model has been released in the repo. Source code: https://github.com/maudzung/Super-Fast-Accurate-3D-Object-Detection ------------------------------------------------------ HÆ°á»›ng tiáº¿p cáº­n á»Ÿ trÃªn cÃ³ thá»ƒ má»Ÿ rá»™ng vá»›i bÃ i toÃ¡n xÃ¡c Ä‘á»‹nh vá»‹ trÃ­, kÃ­ch thÆ°á»›c, vÃ  phÃ¢n loáº¡i cÃ¡c há»™p xoay (rorated boxes) chá»©a váº­t thá»ƒ trong hÃ¬nh áº£nh 2D RGB thÃ´ng thÆ°á»ng. DÃ¹ng YOLO cÅ©ng cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n trÃªn nhÆ°ng cÃ³ má»™t sá»‘ háº¡n cháº¿ nhÆ°: Viá»‡c tÃ¬m anchors phÃ¹ há»£p khÃ´ng Ä‘Æ¡n giáº£n (vÃ¬ pháº£i quan tÃ¢m tá»›i cáº£ gÃ³c xoay), viá»‡c tÃ­nh toÃ¡n IoU giá»¯a cÃ¡c há»™p xoay cÅ©ng ráº¥t ""tá»‘n kÃ©m"", cháº­m vÃ¬ khÃ´ng vectorize Ä‘Æ°á»£c. Äiá»u Ä‘Ã³ dáº«n tá»›i há»‡ quáº£ lÃ  training model lÃ¢u hÆ¡n, tá»‘c Ä‘á»™ inference cháº­m hÆ¡n ráº¥t nhiá»u so vá»›i hÆ°á»›ng tiáº¿p cáº­n anchor-free. NgoÃ i ra, model sá»­ dá»¥ng á»Ÿ trong hÆ°á»›ng tiáº¿p cáº­n anchor-free á»Ÿ trÃªn cÅ©ng nhá» (Ã­t parameters) hÆ¡n nhiá»u so vá»›i YOLO models, Ä‘iá»u Ä‘Ã³ giÃºp trÃ¡nh overfitting khi táº­p dá»¯ liá»‡u khÃ´ng quÃ¡ lá»›n.",,,,,
"Link chi tiáº¿t: https://www.reddit.com/r/MachineLearning/comments/m3li7t/p_pytorch_lightning_hydra_tensorboard_project/
ChÃ o má»i ngÆ°á»i,
chÃ¡n viá»‡c pháº£i má»Ÿ project cÅ© lÃªn Ä‘á»ƒ copy code qua project má»›i, mÃ¬nh cÃ³ viáº¿t má»™t cÃ¡i Github template Ä‘á»ƒ nhanh chÃ³ng báº¯t Ä‘áº§u má»™t dá»± Ã¡n Deep Learning cá»¡ nhá» sá»­ dá»¥ng Pytorch Lightning, Hydra vÃ  TensorBoard. CÃ¡c báº¡n vui lÃ²ng xem thÃªm chi tiáº¿t vÃ  gÃ³p Ã½ táº¡i link reddit á»Ÿ trÃªn.
Hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n.","Link chi tiáº¿t: https://www.reddit.com/r/MachineLearning/comments/m3li7t/p_pytorch_lightning_hydra_tensorboard_project/ ChÃ o má»i ngÆ°á»i, chÃ¡n viá»‡c pháº£i má»Ÿ project cÅ© lÃªn Ä‘á»ƒ copy code qua project má»›i, mÃ¬nh cÃ³ viáº¿t má»™t cÃ¡i Github template Ä‘á»ƒ nhanh chÃ³ng báº¯t Ä‘áº§u má»™t dá»± Ã¡n Deep Learning cá»¡ nhá» sá»­ dá»¥ng Pytorch Lightning, Hydra vÃ  TensorBoard. CÃ¡c báº¡n vui lÃ²ng xem thÃªm chi tiáº¿t vÃ  gÃ³p Ã½ táº¡i link reddit á»Ÿ trÃªn. Hi vá»ng sáº½ cÃ³ Ã­ch cho cÃ¡c báº¡n.",,,,,
"ChÃ o má»i ngÆ°á»i. DeepMind trao há»c bá»•ng Tháº¡c Sá»¹ vÃ  Tiáº¿n Sá»¹ táº¡i má»™t sá»‘ trÆ°á»ng Ä‘áº¡i há»c (bao gá»“m táº¡i Anh, MÄ©, Canada, PhÃ¡p) cho há»c sinh tá»« cÃ¡c nhÃ³m Ã­t Ä‘áº¡i diá»‡n trong AI. Trong Ä‘á»‹nh nghÄ©a ""Ã­t Ä‘áº¡i diá»‡n"" cÃ³ bao gá»“m cÃ¡c khu vá»±c lÃ£nh thá»• chÆ°a cÃ³ nhiá»u ngÆ°á»i lÃ m viá»‡c trong AI, vÃ  thÆ°á»ng thÃ¬ ÄÃ´ng Nam Ã, bao gá»“m Viá»‡t Nam, Ä‘Æ°á»£c tÃ­nh vÃ o khu vá»±c nÃ y.
Náº¿u cÃ¡c báº¡n muá»‘n tÃ¬m hiá»ƒu thÃªm thÃ´ng tin, thá»© 4 ngÃ y 24/3 lÃºc 19:00 - 20:00 giá» Viá»‡t Nam, DeepMind cÃ³ má»™t buá»•i giá»›i thiá»‡u trá»±c tuyáº¿n Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ nghe tá»« cÃ¡c sinh viÃªn Ä‘Æ°á»£c nháº­n há»c bá»•ng vÃ  DeepMinders vá» viá»‡c theo Ä‘uá»•i cao há»c, quÃ¡ trÃ¬nh phÃ¡t triá»ƒn nghá» nghiá»‡p vÃ  tráº£i nghiá»‡m chÆ°Æ¡ng trÃ¬nh há»c bá»•ng.
ThÃ´ng tin vá» há»c bá»•ng: https://deepmind.com/scholarships
ÄÄƒng kÃ½ tham gia buá»•i giá»›i thiá»‡u há»c bá»•ng: https://eventsonair.withgoogle.com/events/deepmind-hiai","ChÃ o má»i ngÆ°á»i. DeepMind trao há»c bá»•ng Tháº¡c Sá»¹ vÃ  Tiáº¿n Sá»¹ táº¡i má»™t sá»‘ trÆ°á»ng Ä‘áº¡i há»c (bao gá»“m táº¡i Anh, MÄ©, Canada, PhÃ¡p) cho há»c sinh tá»« cÃ¡c nhÃ³m Ã­t Ä‘áº¡i diá»‡n trong AI. Trong Ä‘á»‹nh nghÄ©a ""Ã­t Ä‘áº¡i diá»‡n"" cÃ³ bao gá»“m cÃ¡c khu vá»±c lÃ£nh thá»• chÆ°a cÃ³ nhiá»u ngÆ°á»i lÃ m viá»‡c trong AI, vÃ  thÆ°á»ng thÃ¬ ÄÃ´ng Nam Ã, bao gá»“m Viá»‡t Nam, Ä‘Æ°á»£c tÃ­nh vÃ o khu vá»±c nÃ y. Náº¿u cÃ¡c báº¡n muá»‘n tÃ¬m hiá»ƒu thÃªm thÃ´ng tin, thá»© 4 ngÃ y 24/3 lÃºc 19:00 - 20:00 giá» Viá»‡t Nam, DeepMind cÃ³ má»™t buá»•i giá»›i thiá»‡u trá»±c tuyáº¿n Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ nghe tá»« cÃ¡c sinh viÃªn Ä‘Æ°á»£c nháº­n há»c bá»•ng vÃ  DeepMinders vá» viá»‡c theo Ä‘uá»•i cao há»c, quÃ¡ trÃ¬nh phÃ¡t triá»ƒn nghá» nghiá»‡p vÃ  tráº£i nghiá»‡m chÆ°Æ¡ng trÃ¬nh há»c bá»•ng. ThÃ´ng tin vá» há»c bá»•ng: https://deepmind.com/scholarships ÄÄƒng kÃ½ tham gia buá»•i giá»›i thiá»‡u há»c bá»•ng: https://eventsonair.withgoogle.com/events/deepmind-hiai",,,,,
"Xin chÃ o má»£i ngÆ°á»i, chuyá»‡n lÃ  em Ä‘ang há»c mÃ´n thay tháº¿ tá»‘t nghiá»‡p vá» machine learning cá»¥ thá»ƒ hÆ¡n lÃ  Azure machine learning, anh chá»‹ nÃ o lÃ  master thÃ¬ cÃ³ thá»ƒ hÆ°á»›ng dáº«n em Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n.","Xin chÃ o má»£i ngÆ°á»i, chuyá»‡n lÃ  em Ä‘ang há»c mÃ´n thay tháº¿ tá»‘t nghiá»‡p vá» machine learning cá»¥ thá»ƒ hÆ¡n lÃ  Azure machine learning, anh chá»‹ nÃ o lÃ  master thÃ¬ cÃ³ thá»ƒ hÆ°á»›ng dáº«n em Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ tháº¯c máº¯c vá» 2 job data scientist vÃ  ML engineer. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p!
Khi mÃ¬nh cÃ²n há»c trÃªn giáº£ng Ä‘Æ°á»ng, mÃ¬nh thÆ°á»ng xuyÃªn Æ°á»›c mong trá»Ÿ thÃ nh data scientist vá»›i lÃ½ do: Ã­t code, chá»§ yáº¿u phÃ¢n tÃ­ch dá»±a vÃ o data (cÃ³ thá»ƒ dÃ¹ng tool Weka hoáº·c scikit learn ... káº¿t há»£p vá»›i toÃ¡n xÃ¡c suáº¥t, visualize ra Ä‘oÃ¡n), tá»« Ä‘Ã³ mÃ  cÃ¡c nhÃ  chiáº¿n lÆ°á»£c trong cÃ´ng ty sáº½ thay Ä‘á»•i cÃ¡ch lÃ m bla bla.
VÃ i thÃ¡ng sau, Ä‘á»‹nh nghÄ©a Ä‘Ã³ láº¡i thay Ä‘á»•i. Data science giá» Ä‘Ã¢y chÃ­nh lÃ  viá»‡c crawl dá»¯ liá»‡u, tiá»n xá»­ lÃ½, xÃ¢y dá»±ng sáºµn pipeline, dÃ¹ng thÆ° viá»‡n cÃ³ sáºµn apply model.
VÃ i thÃ¡ng káº¿, mÃ¬nh láº¡i tháº¥y sáº½ cÃ³ 1 nhÃ³m ngÆ°á»i lÃ m cÃ´ng viá»‡c crawl, pre-process, phÃ¢n tÃ­ch sÆ¡ bá»™ dá»¯ liá»‡u vá» nhiá»…u, loáº¡i bá» feature bá»‹ dÆ° thá»«a, nhÃ³m nÃ y mÃ¬nh gá»i lÃ  data mining/data analysis. VÃ  1 nhÃ³m ngÆ°á»i sáº½ xÃ¢y dá»±ng pipepline (tá»« lÃºc input vÃ o Ä‘áº¿n output, xÃ¢y luÃ´n inference), nhÃ³m nÃ y mÃ¬nh gá»i lÃ  ML engineer. VÃ  cuá»‘i cÃ¹ng, nhá»¯ng ngÆ°á»i Ä‘Æ°á»£c gá»i lÃ  data scientist sáº½ lÃ m nhá»¯ng viá»‡c nhÆ°: R&D model dá»±a vÃ o paper, tunning param, thá»­ má»™t sá»‘ mÃ´ hÃ¬nh má»›i.

VÃ  khi mÃ¬nh theo dÃµi má»™t sá»‘ tuyá»ƒn dá»¥ng cá»§a Viá»‡t Nam vÃ  nÆ°á»›c ngoÃ i, mÃ¬nh nháº­n tháº¥y ráº¥t nhiá»u cÃ´ng ty xem Data scientist vÃ  ML engineer lÃ  nhÆ° nhau. MÃ¬nh muá»‘n há»i nhá»¯ng ai Ä‘Ã£ lÃ m ML engineer vÃ  Data scientist ráº±ng, liá»‡u mÃ¬nh Ä‘Ã£ Ä‘á»‹nh nghÄ©a cÃ´ng viá»‡c pháº£i lÃ m cá»§a DS vÃ  ML engineer Ä‘Ãºng chÆ°a? 

.ps: Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m fresher ML vÃ  vÃ´ cÃ¹ng tháº¯c máº¯c tháº­t sá»± DS lÃ m nhá»¯ng gÃ¬. MÃ¬nh Ä‘ang cÃ³ Ã½ Ä‘á»‹nh switch qua DS lÃ m thá»­.
Thank you.","ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ tháº¯c máº¯c vá» 2 job data scientist vÃ  ML engineer. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p! Khi mÃ¬nh cÃ²n há»c trÃªn giáº£ng Ä‘Æ°á»ng, mÃ¬nh thÆ°á»ng xuyÃªn Æ°á»›c mong trá»Ÿ thÃ nh data scientist vá»›i lÃ½ do: Ã­t code, chá»§ yáº¿u phÃ¢n tÃ­ch dá»±a vÃ o data (cÃ³ thá»ƒ dÃ¹ng tool Weka hoáº·c scikit learn ... káº¿t há»£p vá»›i toÃ¡n xÃ¡c suáº¥t, visualize ra Ä‘oÃ¡n), tá»« Ä‘Ã³ mÃ  cÃ¡c nhÃ  chiáº¿n lÆ°á»£c trong cÃ´ng ty sáº½ thay Ä‘á»•i cÃ¡ch lÃ m bla bla. VÃ i thÃ¡ng sau, Ä‘á»‹nh nghÄ©a Ä‘Ã³ láº¡i thay Ä‘á»•i. Data science giá» Ä‘Ã¢y chÃ­nh lÃ  viá»‡c crawl dá»¯ liá»‡u, tiá»n xá»­ lÃ½, xÃ¢y dá»±ng sáºµn pipeline, dÃ¹ng thÆ° viá»‡n cÃ³ sáºµn apply model. VÃ i thÃ¡ng káº¿, mÃ¬nh láº¡i tháº¥y sáº½ cÃ³ 1 nhÃ³m ngÆ°á»i lÃ m cÃ´ng viá»‡c crawl, pre-process, phÃ¢n tÃ­ch sÆ¡ bá»™ dá»¯ liá»‡u vá» nhiá»…u, loáº¡i bá» feature bá»‹ dÆ° thá»«a, nhÃ³m nÃ y mÃ¬nh gá»i lÃ  data mining/data analysis. VÃ  1 nhÃ³m ngÆ°á»i sáº½ xÃ¢y dá»±ng pipepline (tá»« lÃºc input vÃ o Ä‘áº¿n output, xÃ¢y luÃ´n inference), nhÃ³m nÃ y mÃ¬nh gá»i lÃ  ML engineer. VÃ  cuá»‘i cÃ¹ng, nhá»¯ng ngÆ°á»i Ä‘Æ°á»£c gá»i lÃ  data scientist sáº½ lÃ m nhá»¯ng viá»‡c nhÆ°: R&D model dá»±a vÃ o paper, tunning param, thá»­ má»™t sá»‘ mÃ´ hÃ¬nh má»›i. VÃ  khi mÃ¬nh theo dÃµi má»™t sá»‘ tuyá»ƒn dá»¥ng cá»§a Viá»‡t Nam vÃ  nÆ°á»›c ngoÃ i, mÃ¬nh nháº­n tháº¥y ráº¥t nhiá»u cÃ´ng ty xem Data scientist vÃ  ML engineer lÃ  nhÆ° nhau. MÃ¬nh muá»‘n há»i nhá»¯ng ai Ä‘Ã£ lÃ m ML engineer vÃ  Data scientist ráº±ng, liá»‡u mÃ¬nh Ä‘Ã£ Ä‘á»‹nh nghÄ©a cÃ´ng viá»‡c pháº£i lÃ m cá»§a DS vÃ  ML engineer Ä‘Ãºng chÆ°a? .ps: Hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m fresher ML vÃ  vÃ´ cÃ¹ng tháº¯c máº¯c tháº­t sá»± DS lÃ m nhá»¯ng gÃ¬. MÃ¬nh Ä‘ang cÃ³ Ã½ Ä‘á»‹nh switch qua DS lÃ m thá»­. Thank you.",,,,,
"Mn Ä‘Ã£ Ä‘á»c qua code cá»§a anh tiá»‡p pháº§n K-means Clustering: Simple Applications. MÃ¬nh khÃ´ng hiá»ƒu code chá»— nÃ y nhÆ° nÃ o. Mn giÃºp mÃ¬nh vá»›i
link: https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/display_network.py",Mn Ä‘Ã£ Ä‘á»c qua code cá»§a anh tiá»‡p pháº§n K-means Clustering: Simple Applications. MÃ¬nh khÃ´ng hiá»ƒu code chá»— nÃ y nhÆ° nÃ o. Mn giÃºp mÃ¬nh vá»›i link: https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/display_network.py,,,,,
"[Pytorch series]
BÃ i 2: Autograd
BÃ i nÃ y á»Ÿ pháº§n Ä‘áº§u mÃ¬nh cÃ³ giáº£i thÃ­ch Machine Learning lÃ  gÃ¬? MÃ¬nh viáº¿t dá»… hiá»ƒu theo ngÃ´n ngá»¯ Ä‘á»i thÆ°á»ng, má»i ngÆ°á»i ai chÆ°a biáº¿t cÃ³ thá»ƒ vÃ o Ä‘á»c ğŸ¤©
Pháº§n sau mÃ¬nh nÃ³i kÄ© vá» cÆ¡ cháº¿ backpropagation trong Pytorch cÅ©ng nhÆ° cÃ¡c kÄ© thuáº­t, tips liÃªn quan.
Pháº§n cuá»‘i mÃ¬nh Ã¡p dá»¥ng autograd vÃ o bÃ i toÃ¡n Linear Regression.
Ps: Má»i ngÆ°á»i tháº¥y mÃ¬nh váº«n ra bÃ i Ä‘á»u khÃ´ng, táº¡i mÃ¬nh Ä‘ang dÃ¹ng 1000% Ä‘á»ƒ viáº¿t. Má»i ngÆ°á»i tháº¥y bÃ i hay cho mÃ¬nh xin 1 like, 1 share thÃ´i ğŸ˜ğŸ˜ğŸ˜","[Pytorch series] BÃ i 2: Autograd BÃ i nÃ y á»Ÿ pháº§n Ä‘áº§u mÃ¬nh cÃ³ giáº£i thÃ­ch Machine Learning lÃ  gÃ¬? MÃ¬nh viáº¿t dá»… hiá»ƒu theo ngÃ´n ngá»¯ Ä‘á»i thÆ°á»ng, má»i ngÆ°á»i ai chÆ°a biáº¿t cÃ³ thá»ƒ vÃ o Ä‘á»c Pháº§n sau mÃ¬nh nÃ³i kÄ© vá» cÆ¡ cháº¿ backpropagation trong Pytorch cÅ©ng nhÆ° cÃ¡c kÄ© thuáº­t, tips liÃªn quan. Pháº§n cuá»‘i mÃ¬nh Ã¡p dá»¥ng autograd vÃ o bÃ i toÃ¡n Linear Regression. Ps: Má»i ngÆ°á»i tháº¥y mÃ¬nh váº«n ra bÃ i Ä‘á»u khÃ´ng, táº¡i mÃ¬nh Ä‘ang dÃ¹ng 1000% Ä‘á»ƒ viáº¿t. Má»i ngÆ°á»i tháº¥y bÃ i hay cho mÃ¬nh xin 1 like, 1 share thÃ´i",,,,,
"Xin phÃ©p Admin
Xin chÃ o má»i ngÆ°á»i, Ä‘á»ƒ giÃºp nhá»¯ng NEWBIE vá» Deeplearning, hÃ´m nay mÃ¬nh ra tiáº¿p video Hiá»ƒu vÃ  LÃ m Deeplearning P2, mong ráº±ng sáº½ giÃºp Ä‘Æ°á»£c nhiá»u anh em hiá»ƒu Ä‘Æ°á»£c báº£n cháº¥t vÃ  tá»± xÃ¢y dá»±ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh Deep cá»§a riÃªng mÃ¬nh. HÃ£y Ä‘á»ƒ láº¡i pháº£n há»“i cho chÃºng tÃ´i Ä‘á»ƒ chá»‰nh sá»­a trong cÃ¡c video tiáº¿p theo nhÃ©, cáº£m Æ¡n Má»i ngÆ°á»i!","Xin phÃ©p Admin Xin chÃ o má»i ngÆ°á»i, Ä‘á»ƒ giÃºp nhá»¯ng NEWBIE vá» Deeplearning, hÃ´m nay mÃ¬nh ra tiáº¿p video Hiá»ƒu vÃ  LÃ m Deeplearning P2, mong ráº±ng sáº½ giÃºp Ä‘Æ°á»£c nhiá»u anh em hiá»ƒu Ä‘Æ°á»£c báº£n cháº¥t vÃ  tá»± xÃ¢y dá»±ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh Deep cá»§a riÃªng mÃ¬nh. HÃ£y Ä‘á»ƒ láº¡i pháº£n há»“i cho chÃºng tÃ´i Ä‘á»ƒ chá»‰nh sá»­a trong cÃ¡c video tiáº¿p theo nhÃ©, cáº£m Æ¡n Má»i ngÆ°á»i!",,,,,
"[Knowledge Distillation]
LÃ  Ã½ tÆ°á»Ÿng Ä‘Æ°á»£c sÃ¡ng táº¡o bá»Ÿi nhÃ  khoa há»c ná»•i tiáº¿ng Geoffrey Hinton. Knowledge Distillation cho phÃ©p mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c lá»›n hÆ¡n (teacher model) cÃ³ thá»ƒ chuyá»ƒn giao tri thá»©c láº¡i mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n (student model).
PhÆ°Æ¡ng phÃ¡p Ä‘Ã£ giÃºp cáº£i thiá»‡n pháº§n lá»›n Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c mÃ´ hÃ¬nh trong computer vision vÃ  NLP. CÃ¹ng tÃ¬m hiá»ƒu ná»™i dung má»™t cÃ¡ch dá»… hiá»ƒu, ngáº¯n gá»n vÃ  trá»±c quan qua bÃ i viáº¿t ká»³ nÃ y.
https://phamdinhkhanh.github.io/2021/03/13/KnownledgeDistillation.html","[Knowledge Distillation] LÃ  Ã½ tÆ°á»Ÿng Ä‘Æ°á»£c sÃ¡ng táº¡o bá»Ÿi nhÃ  khoa há»c ná»•i tiáº¿ng Geoffrey Hinton. Knowledge Distillation cho phÃ©p mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c lá»›n hÆ¡n (teacher model) cÃ³ thá»ƒ chuyá»ƒn giao tri thá»©c láº¡i mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n (student model). PhÆ°Æ¡ng phÃ¡p Ä‘Ã£ giÃºp cáº£i thiá»‡n pháº§n lá»›n Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c mÃ´ hÃ¬nh trong computer vision vÃ  NLP. CÃ¹ng tÃ¬m hiá»ƒu ná»™i dung má»™t cÃ¡ch dá»… hiá»ƒu, ngáº¯n gá»n vÃ  trá»±c quan qua bÃ i viáº¿t ká»³ nÃ y. https://phamdinhkhanh.github.io/2021/03/13/KnownledgeDistillation.html",,,,,
"ChÃ o má»i ngÆ°á»i, cÃ³ thá»ƒ chá»‰ em vá» Extreme gradient boost Ä‘Æ°á»£c khÃ´ng áº¡, vÃ­ dá»¥ nhÆ° kiá»ƒu code XGBoost cho Iris flower áº¡.","ChÃ o má»i ngÆ°á»i, cÃ³ thá»ƒ chá»‰ em vá» Extreme gradient boost Ä‘Æ°á»£c khÃ´ng áº¡, vÃ­ dá»¥ nhÆ° kiá»ƒu code XGBoost cho Iris flower áº¡.",,,,,
"xin phÃ©p ad ah.
anh chá»‹ cho há»i em Ä‘á»‹nh mua con card nÃ y. dÃ¹ng Ä‘á»ƒ test thÃ´i.
thÃ¬ cÃ³ Ä‘Æ°á»£c ko áº¡",xin phÃ©p ad ah. anh chá»‹ cho há»i em Ä‘á»‹nh mua con card nÃ y. dÃ¹ng Ä‘á»ƒ test thÃ´i. thÃ¬ cÃ³ Ä‘Æ°á»£c ko áº¡,,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang há»c ml, vÃ  Ä‘Ã¢y lÃ  má»™t bÃ i táº­p cá»§a em vá» giÃ¡ sáº£n pháº©m.
https://www.kaggle.com/c/mercari-price-suggestion-challenge
Cho em há»i lÃ  viá»‡c dá»± bÃ¡o giÃ¡ sáº£n pháº©m cÃ³ dÃ¹ng nhiá»u thuá»™c tÃ­nh nhÆ° lÃ  brand, category, conditon, .... Váº­y thÃ¬ vá»›i má»—i thuá»™c tÃ­nh mÃ¬nh sáº½ dÃ¹ng má»™t model, rá»“i káº¿t há»£p láº¡i vá»›i nhau áº¡? Náº¿u tháº¿ thÃ¬ káº¿t há»£p nhÆ° tháº¿ nÃ o, cÃ²n náº¿u khÃ´ng thÃ¬ hÆ°á»›ng giáº£i quyáº¿t ra sao áº¡?","ChÃ o má»i ngÆ°á»i, em Ä‘ang há»c ml, vÃ  Ä‘Ã¢y lÃ  má»™t bÃ i táº­p cá»§a em vá» giÃ¡ sáº£n pháº©m. https://www.kaggle.com/c/mercari-price-suggestion-challenge Cho em há»i lÃ  viá»‡c dá»± bÃ¡o giÃ¡ sáº£n pháº©m cÃ³ dÃ¹ng nhiá»u thuá»™c tÃ­nh nhÆ° lÃ  brand, category, conditon, .... Váº­y thÃ¬ vá»›i má»—i thuá»™c tÃ­nh mÃ¬nh sáº½ dÃ¹ng má»™t model, rá»“i káº¿t há»£p láº¡i vá»›i nhau áº¡? Náº¿u tháº¿ thÃ¬ káº¿t há»£p nhÆ° tháº¿ nÃ o, cÃ²n náº¿u khÃ´ng thÃ¬ hÆ°á»›ng giáº£i quyáº¿t ra sao áº¡?",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, hÃ´m nay em Ä‘ang há»c vá» TensorflowJS Ä‘á»ƒ triá»ƒn khai model lÃªn trÃ¬nh duyá»‡t nÃªn lÃ m clip chia sáº» cho cÃ¡c báº¡n má»›i há»c.
Mong ad duyá»‡t bÃ i vÃ  mong cÃ¡c bÃ¡c chá»‰ giÃ¡o thÃªm! Em xin cáº£m Æ¡n!","KÃ­nh chÃ o cÃ¡c bÃ¡c, hÃ´m nay em Ä‘ang há»c vá» TensorflowJS Ä‘á»ƒ triá»ƒn khai model lÃªn trÃ¬nh duyá»‡t nÃªn lÃ m clip chia sáº» cho cÃ¡c báº¡n má»›i há»c. Mong ad duyá»‡t bÃ i vÃ  mong cÃ¡c bÃ¡c chá»‰ giÃ¡o thÃªm! Em xin cáº£m Æ¡n!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang nghiÃªn cá»©u vá» depth image. Khi mÃ¬nh train thÃ¬ gáº·p váº¥n Ä‘á» nhÆ° sau: cÃ¡c disparity map luÃ´n xuáº¥t hiá»‡n váº¿t Ä‘en sá»c tráº¯ng tÆ°Æ¡ng á»©ng vá»›i vá»‹ trá»‹ báº§u trá»i hoáº·c khu vá»±c xa xÃ´i. MÃ¬nh khÃ´ng biáº¿t cÃ³ thuáº­t ngá»¯ nÃ o dÃ nh cho váº¥n Ä‘á» nÃ y hay khÃ´ng? Mong xin Ä‘Æ°á»£c Ã½ kiáº¿n má»i ngÆ°á»i.
Cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang nghiÃªn cá»©u vá» depth image. Khi mÃ¬nh train thÃ¬ gáº·p váº¥n Ä‘á» nhÆ° sau: cÃ¡c disparity map luÃ´n xuáº¥t hiá»‡n váº¿t Ä‘en sá»c tráº¯ng tÆ°Æ¡ng á»©ng vá»›i vá»‹ trá»‹ báº§u trá»i hoáº·c khu vá»±c xa xÃ´i. MÃ¬nh khÃ´ng biáº¿t cÃ³ thuáº­t ngá»¯ nÃ o dÃ nh cho váº¥n Ä‘á» nÃ y hay khÃ´ng? Mong xin Ä‘Æ°á»£c Ã½ kiáº¿n má»i ngÆ°á»i. Cáº£m Æ¡n.",,,,,
"Dá»¯ liá»‡u lÃ  cá»±c ká»³ quan trá»ng Ä‘á»‘i vá»›i cÃ¡c báº¡n lÃ m vá» há»c mÃ¡y, phÃ¢n tÃ­ch dá»¯ liá»‡u. Do Ä‘Ã³, thu tháº­p dá»¯ liá»‡u tá»« internet lÃ  má»™t ká»¹ nÄƒng cáº§n thiáº¿t Ä‘á»‘i vá»›i cÃ¡c báº¡n.
NhÃ¢n dá»‹p nghá»‰ lá»…, mÃ¬nh cÃ³ dÃ nh thá»i gian viáº¿t 1 bÃ i chia sáº» nho nhá» vá» cÃ¡ch thu tháº­p dá»¯ liá»‡u tin tá»©c cá»±c ká»³ Ä‘Æ¡n giáº£n. Hi vá»ng bÃ i viáº¿t nÃ y giÃºp Ã­ch Ä‘Æ°á»£c má»i ngÆ°á»i trong quÃ¡ trÃ¬nh há»c táº­p & lÃ m viá»‡c.
https://nguyenvanhieu.vn/thu-thap-du-lieu-cua-trang-tin-tuc-bat-ky/","Dá»¯ liá»‡u lÃ  cá»±c ká»³ quan trá»ng Ä‘á»‘i vá»›i cÃ¡c báº¡n lÃ m vá» há»c mÃ¡y, phÃ¢n tÃ­ch dá»¯ liá»‡u. Do Ä‘Ã³, thu tháº­p dá»¯ liá»‡u tá»« internet lÃ  má»™t ká»¹ nÄƒng cáº§n thiáº¿t Ä‘á»‘i vá»›i cÃ¡c báº¡n. NhÃ¢n dá»‹p nghá»‰ lá»…, mÃ¬nh cÃ³ dÃ nh thá»i gian viáº¿t 1 bÃ i chia sáº» nho nhá» vá» cÃ¡ch thu tháº­p dá»¯ liá»‡u tin tá»©c cá»±c ká»³ Ä‘Æ¡n giáº£n. Hi vá»ng bÃ i viáº¿t nÃ y giÃºp Ã­ch Ä‘Æ°á»£c má»i ngÆ°á»i trong quÃ¡ trÃ¬nh há»c táº­p & lÃ m viá»‡c. https://nguyenvanhieu.vn/thu-thap-du-lieu-cua-trang-tin-tuc-bat-ky/",,,,,
"Xin phÃ©p Admin, ChÃ o cÃ¡c báº¡n!
21/3 nÃ y bá»n mÃ¬nh cÃ³ má»Ÿ 1 dá»± Ã¡n Sá»­ dá»¥ng Python Ä‘á»ƒ phÃ¡t hiá»‡n tÆ° tháº¿ ngÆ°á»i cÃ³ trong áº£nh hoáº·c video.
Dá»± Ã¡n sáº½ Ä‘Æ°á»£c chia thÃ nh 03 giai Ä‘oáº¡n tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 3 pháº§n cÃ´ng viá»‡c chÃ­nh:
Giá»›i thiá»‡u vá» cÃ¡ch lÃ m viá»‡c vá»›i Pytorch vÃ  Openpose
XÃ¢y dá»±ng á»©ng dá»¥ng nháº­n biáº¿t tÆ° tháº¿ vá»›i Ä‘áº§u vÃ o lÃ  1 áº£nh
Má»Ÿ rá»™ng á»©ng dá»¥ng nháº­n biáº¿t tÆ° tháº¿ vá»›i 1 video
Äá»ƒ tham gia dá»± Ã¡n yÃªu cáº§u Ä‘Ã£ biáº¿t láº­p trÃ¬nh Python cÆ¡ báº£n.
Thá»i gian diá»…n ra trong 3 tuáº§n (21/3 start)
Mentor hÆ°á»›ng dáº«n dá»± Ã¡n: Anh Nguyá»…n CÃ´ng ThÃ nh - CEO HachiX Nháº­t Báº£n (ÄÆ°á»£c táº¡p chÃ­ Nikkei Asia vinh danh lÃ  ngÆ°á»i Viá»‡t Nam cÃ³ Ä‘Ã³ng gÃ³p lá»›n trong sá»± phÃ¡t triá»ƒn AI táº¡i Nháº­t Báº£n)
Dá»± Ã¡n lÃ  mÃ´i trÆ°á»ng há»c táº­p ráº¥t tá»‘t cho cÃ¡c báº¡n Ä‘ang há»c Python, sá»­ dá»¥ng Python nhÆ° lÃ  cÃ´ng cá»¥ chÃ­nh Ä‘á»ƒ lÃ m viá»‡c trong cÃ¡c lÄ©nh vá»±c nhÆ° AI, ML...
Dá»± Ã¡n cÃ³ háº¡n cháº¿ sá»‘ lÆ°á»£ng thÃ nh viÃªn vÃ  cÃ³ chÃ­nh sÃ¡ch tÃ i trá»£ 100% chi phÃ­ tham gia.
Náº¿u cÃ³ há»©ng thÃº hÃ£y inbox, giá»›i thiá»‡u báº£n thÃ¢n Ä‘á»ƒ Ä‘Äƒng kÃ½ vá»›i mÃ¬nh nhÃ©.","Xin phÃ©p Admin, ChÃ o cÃ¡c báº¡n! 21/3 nÃ y bá»n mÃ¬nh cÃ³ má»Ÿ 1 dá»± Ã¡n Sá»­ dá»¥ng Python Ä‘á»ƒ phÃ¡t hiá»‡n tÆ° tháº¿ ngÆ°á»i cÃ³ trong áº£nh hoáº·c video. Dá»± Ã¡n sáº½ Ä‘Æ°á»£c chia thÃ nh 03 giai Ä‘oáº¡n tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 3 pháº§n cÃ´ng viá»‡c chÃ­nh: Giá»›i thiá»‡u vá» cÃ¡ch lÃ m viá»‡c vá»›i Pytorch vÃ  Openpose XÃ¢y dá»±ng á»©ng dá»¥ng nháº­n biáº¿t tÆ° tháº¿ vá»›i Ä‘áº§u vÃ o lÃ  1 áº£nh Má»Ÿ rá»™ng á»©ng dá»¥ng nháº­n biáº¿t tÆ° tháº¿ vá»›i 1 video Äá»ƒ tham gia dá»± Ã¡n yÃªu cáº§u Ä‘Ã£ biáº¿t láº­p trÃ¬nh Python cÆ¡ báº£n. Thá»i gian diá»…n ra trong 3 tuáº§n (21/3 start) Mentor hÆ°á»›ng dáº«n dá»± Ã¡n: Anh Nguyá»…n CÃ´ng ThÃ nh - CEO HachiX Nháº­t Báº£n (ÄÆ°á»£c táº¡p chÃ­ Nikkei Asia vinh danh lÃ  ngÆ°á»i Viá»‡t Nam cÃ³ Ä‘Ã³ng gÃ³p lá»›n trong sá»± phÃ¡t triá»ƒn AI táº¡i Nháº­t Báº£n) Dá»± Ã¡n lÃ  mÃ´i trÆ°á»ng há»c táº­p ráº¥t tá»‘t cho cÃ¡c báº¡n Ä‘ang há»c Python, sá»­ dá»¥ng Python nhÆ° lÃ  cÃ´ng cá»¥ chÃ­nh Ä‘á»ƒ lÃ m viá»‡c trong cÃ¡c lÄ©nh vá»±c nhÆ° AI, ML... Dá»± Ã¡n cÃ³ háº¡n cháº¿ sá»‘ lÆ°á»£ng thÃ nh viÃªn vÃ  cÃ³ chÃ­nh sÃ¡ch tÃ i trá»£ 100% chi phÃ­ tham gia. Náº¿u cÃ³ há»©ng thÃº hÃ£y inbox, giá»›i thiá»‡u báº£n thÃ¢n Ä‘á»ƒ Ä‘Äƒng kÃ½ vá»›i mÃ¬nh nhÃ©.",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang tháº¯c máº¯c má»™t chÃºt vá» word embedding. Khi mÃ¬nh muá»‘n emdedding input thÃ¬ mÃ¬nh sáº½ thÆ°á»ng sá»­ dá»¥ng má»™t model pre-trained vÃ¬ theo mÃ¬nh nghÄ© thÃ¬ nÃ³ cÃ³ nhiá»u dá»¯ liá»‡u há»c hÆ¡n nÃªn sáº½ biá»ƒu diá»…n tá»‘t hÆ¡n, tuy nhiÃªn náº¿u nhÆ° model pre-trained khÃ´ng biá»ƒu diá»…n Ä‘Æ°á»£c háº¿t input (cÃ³ má»™t sá»‘ word input mÃ  model pre-trained khÃ´ng biá»ƒu diá»…n Ä‘Æ°á»£c) thÃ¬ pháº£i lÃ m nhÆ° nÃ o? (nÃªn tá»± build model embdding hay pháº£i lÃ m cÃ¡ch nÃ o?)
Liá»‡u mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng káº¿t há»£p Ä‘Æ°á»£c model mÃ¬nh tá»± build vá»›i má»™t model pre-trained khÃ´ng ?","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang tháº¯c máº¯c má»™t chÃºt vá» word embedding. Khi mÃ¬nh muá»‘n emdedding input thÃ¬ mÃ¬nh sáº½ thÆ°á»ng sá»­ dá»¥ng má»™t model pre-trained vÃ¬ theo mÃ¬nh nghÄ© thÃ¬ nÃ³ cÃ³ nhiá»u dá»¯ liá»‡u há»c hÆ¡n nÃªn sáº½ biá»ƒu diá»…n tá»‘t hÆ¡n, tuy nhiÃªn náº¿u nhÆ° model pre-trained khÃ´ng biá»ƒu diá»…n Ä‘Æ°á»£c háº¿t input (cÃ³ má»™t sá»‘ word input mÃ  model pre-trained khÃ´ng biá»ƒu diá»…n Ä‘Æ°á»£c) thÃ¬ pháº£i lÃ m nhÆ° nÃ o? (nÃªn tá»± build model embdding hay pháº£i lÃ m cÃ¡ch nÃ o?) Liá»‡u mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng káº¿t há»£p Ä‘Æ°á»£c model mÃ¬nh tá»± build vá»›i má»™t model pre-trained khÃ´ng ?",,,,,
"ChÃ o má»i ngÆ°á»i, e má»›i báº¯t Ä‘áº§u nghiÃªn cá»©u nhÃ¢n diá»‡n text trong áº£nh. Náº¿u áº£nh rá» nÃ©t thÃ¬ bÃ¬nh thÆ°á»ng, cÃ²n náº¿u áº£nh bá»‹ má» thÃ¬ khÃ´ng Ä‘á»c Ä‘Æ°á»£c hoáº·c lá»—i. Thá»­ Rescaling thÃ¬ káº¿t quáº£ chá»‰ cáº£i thiá»‡n 1 chÃºt.
CÃ³ giáº£i phÃ¡p nÃ o khÃ¡c phá»¥c khÃ´ng áº¡
demo báº±ng: pytesseract, opencv-python","ChÃ o má»i ngÆ°á»i, e má»›i báº¯t Ä‘áº§u nghiÃªn cá»©u nhÃ¢n diá»‡n text trong áº£nh. Náº¿u áº£nh rá» nÃ©t thÃ¬ bÃ¬nh thÆ°á»ng, cÃ²n náº¿u áº£nh bá»‹ má» thÃ¬ khÃ´ng Ä‘á»c Ä‘Æ°á»£c hoáº·c lá»—i. Thá»­ Rescaling thÃ¬ káº¿t quáº£ chá»‰ cáº£i thiá»‡n 1 chÃºt. CÃ³ giáº£i phÃ¡p nÃ o khÃ¡c phá»¥c khÃ´ng áº¡ demo báº±ng: pytesseract, opencv-python",,,,,
"ChÃ o cáº£ nhÃ 
MÃ¬nh cáº§n tÃ¬m giáº£i phÃ¡p Camera AI gÃ¬ Ä‘Ã³ cho cÃ¡c nhu cáº§u sau cho chuá»—i nhÃ  HÃ ng
1. TÃ­nh bÃ n trá»‘ng vÃ  biáº¿t táº§n suáº¥t sá»­ dá»¥ng, thá»i gian dÃ¹ng bÃ n, khu vá»±c
2. Nháº­n diá»‡n khÃ¡ch vÃ o CH, khÃ¡ch cÅ©, má»›i, tá»· lá»‡ chuyá»ƒn Ä‘á»•i
NgoÃ i ra báº¡n cÃ³ giáº£i phÃ¡p hay Ä‘á» xuáº¥t giÃºp nha
Cáº£m Æ¡n cáº£ nhÃ ","ChÃ o cáº£ nhÃ  MÃ¬nh cáº§n tÃ¬m giáº£i phÃ¡p Camera AI gÃ¬ Ä‘Ã³ cho cÃ¡c nhu cáº§u sau cho chuá»—i nhÃ  HÃ ng 1. TÃ­nh bÃ n trá»‘ng vÃ  biáº¿t táº§n suáº¥t sá»­ dá»¥ng, thá»i gian dÃ¹ng bÃ n, khu vá»±c 2. Nháº­n diá»‡n khÃ¡ch vÃ o CH, khÃ¡ch cÅ©, má»›i, tá»· lá»‡ chuyá»ƒn Ä‘á»•i NgoÃ i ra báº¡n cÃ³ giáº£i phÃ¡p hay Ä‘á» xuáº¥t giÃºp nha Cáº£m Æ¡n cáº£ nhÃ ",,,,,
"ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang cÃ³ tháº¯c máº¯c má»™t chÃºt vá» data normalization. Khi sá»­ dá»¥ng MinMaxScaler thÃ¬ ta sá»­ dá»¥ng min, max cá»§a táº­p train Ä‘á»ƒ fit sau Ä‘Ã³ tranform cho táº­p val/test, hay má»—i táº­p mÃ¬nh sá»­ dá»¥ng min, max riÃªng Ä‘á»ƒ rescale cho tá»«ng táº­p Ä‘Ã³ ?","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang cÃ³ tháº¯c máº¯c má»™t chÃºt vá» data normalization. Khi sá»­ dá»¥ng MinMaxScaler thÃ¬ ta sá»­ dá»¥ng min, max cá»§a táº­p train Ä‘á»ƒ fit sau Ä‘Ã³ tranform cho táº­p val/test, hay má»—i táº­p mÃ¬nh sá»­ dá»¥ng min, max riÃªng Ä‘á»ƒ rescale cho tá»«ng táº­p Ä‘Ã³ ?",,,,,
,nan,,,,,
">>> Must-read papers on graph neural networks (GNN)

(C) https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/492800285460365/ 
Trong nÄƒm 2020, cÃ¹ng vá»›i Transformer, GNN hay Graph Neural Network nháº­n Ä‘Æ°á»£c nhiá»u sá»± chÃº Ã½ vÃ  quan tÃ¢m hÆ¡n tá»« cá»™ng Ä‘á»“ng. 1 sá»‘ lá»›p bÃ i toÃ¡n Ä‘iá»ƒn hÃ¬nh cá»§a GNN bao gá»“m: Node Classification, Graph Classification, Link Prediction, Graph Clustering,...

Trong thá»±c táº¿, GNN cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o nhiá»u kiá»ƒu dá»¯ liá»‡u vÃ  bÃ i toÃ¡n khÃ¡c nhau. 1 sá»‘ á»©ng dá»¥ng nhÆ°:
- https://arxiv.org/abs/2102.07753 dÃ¹ng CNN vá»›i GNN phÃ­a sau cho metric learning Ä‘á»ƒ há»c embedding, cÃ³ so sÃ¡nh vá»›i ráº¥t nhiá»u cÃ¡c pp khÃ¡c tá»« triplet loss, angular loss,.. vÃ  lÃ  phÆ°Æ¡ng phÃ¡p SOTA hiá»‡n táº¡i
- https://arxiv.org/abs/2003.07493 : paper nÃ y thÃ¬ dÃ¹ng graph vá»›i bÃ i toÃ¡n scene text detection
- https://arxiv.org/abs/2002.01276 : paper nÃ y thÃ¬ dÃ¹ng GCN vá»›i CTC loss cho bÃ i toÃ¡n scene text recognition
- hay vÃ­ dá»¥ 1 bÃ i toÃ¡n Ä‘ang khÃ¡ ná»•i báº­t trong thá»i gian gáº§n Ä‘Ã¢y nhÆ°: Scene Graph Generation. 1 sá»‘ bÃ i toÃ¡n khÃ¡c nhÆ° keypoint matching (SuperGlue) https://arxiv.org/abs/1911.11763 , hand-pose estimation (HOPE): https://arxiv.org/abs/2004.00060 , information extraction tá»« áº£nh (PICK): https://arxiv.org/abs/2004.07464 . 
- task vá» Image-Text Matching, phá»¥c vá»¥ cho bÃ i toÃ¡n nhÆ° Visual Semantic Search Engine: https://arxiv.org/abs/1909.02701
- task vá» session-based recommend system: https://arxiv.org/abs/1811.00855
- task vá» text classification (TextGCN): https://arxiv.org/abs/1809.05679 , 1 paper khÃ¡c Ã¡p dá»¥ng GCN cho bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n tiáº¿ng Viá»‡t: https://www.researchgate.net/publication/344433020_Vietnamese_Document_Classification_Using_Graph_Convolutional_Network
- task vá» table structure recognition, lÆ°u giá»¯ Ä‘á»‹nh dáº¡ng báº£ng biá»ƒu: (Rethinking TSN) https://arxiv.org/abs/1905.13391 , (Complicated TSN) https://arxiv.org/abs/1908.04729
- GCN Ã¡p dá»¥ng trong bÃ i toÃ¡n Multi-Object Tracking: https://arxiv.org/abs/2006.13164
- GCN cÃ²n Ä‘Æ°á»£c sá»­ dá»¥ng trong y sinh, biá»ƒu diá»…n thuá»‘c, DNA dÆ°á»›i dáº¡ng graph, 1 paper kÃ¨m theo cá»§a tÃ¡c giáº£ Tuan Nguyen (tÃ¡c giáº£ ebook Deep Learning cÆ¡ báº£n)    https://ieeexplore.ieee.org/document/9359501
- vÃ  cÃ²n ráº¥t nhiá»u cÃ¡c á»©ng dá»¥ng khÃ¡c ná»¯a...

Tham kháº£o táº¡i: https://github.com/thunlp/GNNPapers
(C) https://mobile.twitter.com/omarsar0/status/1368167852763717641

1 sá»‘ bÃ i chia sáº» khÃ¡c trÃªn Viblo vá» GNN
- Tá»•ng quan vá» GNN: https://viblo.asia/p/6J3ZgP0qlmB
- GNN cho bÃ i toÃ¡n trÃ­ch rÃºt thÃ´ng tin tá»« áº£nh hÃ³a Ä‘Æ¡n: https://viblo.asia/p/djeZ1yPGZWz

#Q12021 #viblo #machine_learning #deep_learning #gnn #gcn #graph_neural_network #graph_convolutional_network",">>> Must-read papers on graph neural networks (GNN) (C) https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/492800285460365/ Trong nÄƒm 2020, cÃ¹ng vá»›i Transformer, GNN hay Graph Neural Network nháº­n Ä‘Æ°á»£c nhiá»u sá»± chÃº Ã½ vÃ  quan tÃ¢m hÆ¡n tá»« cá»™ng Ä‘á»“ng. 1 sá»‘ lá»›p bÃ i toÃ¡n Ä‘iá»ƒn hÃ¬nh cá»§a GNN bao gá»“m: Node Classification, Graph Classification, Link Prediction, Graph Clustering,... Trong thá»±c táº¿, GNN cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o nhiá»u kiá»ƒu dá»¯ liá»‡u vÃ  bÃ i toÃ¡n khÃ¡c nhau. 1 sá»‘ á»©ng dá»¥ng nhÆ°: - https://arxiv.org/abs/2102.07753 dÃ¹ng CNN vá»›i GNN phÃ­a sau cho metric learning Ä‘á»ƒ há»c embedding, cÃ³ so sÃ¡nh vá»›i ráº¥t nhiá»u cÃ¡c pp khÃ¡c tá»« triplet loss, angular loss,.. vÃ  lÃ  phÆ°Æ¡ng phÃ¡p SOTA hiá»‡n táº¡i - https://arxiv.org/abs/2003.07493 : paper nÃ y thÃ¬ dÃ¹ng graph vá»›i bÃ i toÃ¡n scene text detection - https://arxiv.org/abs/2002.01276 : paper nÃ y thÃ¬ dÃ¹ng GCN vá»›i CTC loss cho bÃ i toÃ¡n scene text recognition - hay vÃ­ dá»¥ 1 bÃ i toÃ¡n Ä‘ang khÃ¡ ná»•i báº­t trong thá»i gian gáº§n Ä‘Ã¢y nhÆ°: Scene Graph Generation. 1 sá»‘ bÃ i toÃ¡n khÃ¡c nhÆ° keypoint matching (SuperGlue) https://arxiv.org/abs/1911.11763 , hand-pose estimation (HOPE): https://arxiv.org/abs/2004.00060 , information extraction tá»« áº£nh (PICK): https://arxiv.org/abs/2004.07464 . - task vá» Image-Text Matching, phá»¥c vá»¥ cho bÃ i toÃ¡n nhÆ° Visual Semantic Search Engine: https://arxiv.org/abs/1909.02701 - task vá» session-based recommend system: https://arxiv.org/abs/1811.00855 - task vá» text classification (TextGCN): https://arxiv.org/abs/1809.05679 , 1 paper khÃ¡c Ã¡p dá»¥ng GCN cho bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n tiáº¿ng Viá»‡t: https://www.researchgate.net/publication/344433020_Vietnamese_Document_Classification_Using_Graph_Convolutional_Network - task vá» table structure recognition, lÆ°u giá»¯ Ä‘á»‹nh dáº¡ng báº£ng biá»ƒu: (Rethinking TSN) https://arxiv.org/abs/1905.13391 , (Complicated TSN) https://arxiv.org/abs/1908.04729 - GCN Ã¡p dá»¥ng trong bÃ i toÃ¡n Multi-Object Tracking: https://arxiv.org/abs/2006.13164 - GCN cÃ²n Ä‘Æ°á»£c sá»­ dá»¥ng trong y sinh, biá»ƒu diá»…n thuá»‘c, DNA dÆ°á»›i dáº¡ng graph, 1 paper kÃ¨m theo cá»§a tÃ¡c giáº£ Tuan Nguyen (tÃ¡c giáº£ ebook Deep Learning cÆ¡ báº£n) https://ieeexplore.ieee.org/document/9359501 - vÃ  cÃ²n ráº¥t nhiá»u cÃ¡c á»©ng dá»¥ng khÃ¡c ná»¯a... Tham kháº£o táº¡i: https://github.com/thunlp/GNNPapers (C) https://mobile.twitter.com/omarsar0/status/1368167852763717641 1 sá»‘ bÃ i chia sáº» khÃ¡c trÃªn Viblo vá» GNN - Tá»•ng quan vá» GNN: https://viblo.asia/p/6J3ZgP0qlmB - GNN cho bÃ i toÃ¡n trÃ­ch rÃºt thÃ´ng tin tá»« áº£nh hÃ³a Ä‘Æ¡n: https://viblo.asia/p/djeZ1yPGZWz",#Q12021	#viblo	#machine_learning	#deep_learning	#gnn	#gcn	#graph_neural_network	#graph_convolutional_network,,,,
"Xin phÃ©p Admin
Xin chÃ o má»i ngÆ°á»i, video Ä‘áº§u tiÃªn giÃºp cÃ¡c báº¡n má»›i há»c vá» Deeplearning cÃ³ thá»ƒ HIá»‚U Ä‘Æ°á»£c Báº¢N CHáº¤T vÃ  Tá»° XÃ‚Y Dá»°NG cÃ¡c mÃ´ hÃ¬nh Deep, mong ráº±ng sáº½ giÃºp Ä‘Æ°á»£c nhiá»u báº¡n. Má»i ngÆ°á»i xem hÃ£y Ä‘á»ƒ láº¡i pháº£n há»“i cho mÃ¬nh Ä‘á»ƒ chá»‰nh sá»­a trong cÃ¡c video tiáº¿p theo nhÃ©. Cáº£m Æ¡n mn!","Xin phÃ©p Admin Xin chÃ o má»i ngÆ°á»i, video Ä‘áº§u tiÃªn giÃºp cÃ¡c báº¡n má»›i há»c vá» Deeplearning cÃ³ thá»ƒ HIá»‚U Ä‘Æ°á»£c Báº¢N CHáº¤T vÃ  Tá»° XÃ‚Y Dá»°NG cÃ¡c mÃ´ hÃ¬nh Deep, mong ráº±ng sáº½ giÃºp Ä‘Æ°á»£c nhiá»u báº¡n. Má»i ngÆ°á»i xem hÃ£y Ä‘á»ƒ láº¡i pháº£n há»“i cho mÃ¬nh Ä‘á»ƒ chá»‰nh sá»­a trong cÃ¡c video tiáº¿p theo nhÃ©. Cáº£m Æ¡n mn!",,,,,
mn cho em há»i em táº¡o hÃ m active contour loss nhÆ°ng bá»‹ lá»—i khÃ´ng Ä‘Ãºng chiá»u nhÆ° nÃ y. Em pháº£i sá»­a ntn áº¡?,mn cho em há»i em táº¡o hÃ m active contour loss nhÆ°ng bá»‹ lá»—i khÃ´ng Ä‘Ãºng chiá»u nhÆ° nÃ y. Em pháº£i sá»­a ntn áº¡?,,,,,
"ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t á»Ÿ Ä‘Ã¢y cÃ³ ai há»c theo cuá»‘n `Computer Vision: Models, Learning, and Inference` khÃ´ng áº¡?
MÃ¬nh gáº·p má»™t váº¥n Ä‘á».
BÃ i toÃ¡n lÃ  chá»©ng minh, dá»±a vÃ o bayes vÃ  Schur complement. Há» cÃ³ cho má»™t pháº§n solution nhÆ°ng em Ä‘á»c váº«n khÃ´ng hiá»ƒu. Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ giáº£i Ä‘Ã¡p pháº§n lÃ½ thuyáº¿t nÃ y vá»›i áº¡. MÃ¬nh xin cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, khÃ´ng biáº¿t á»Ÿ Ä‘Ã¢y cÃ³ ai há»c theo cuá»‘n `Computer Vision: Models, Learning, and Inference` khÃ´ng áº¡? MÃ¬nh gáº·p má»™t váº¥n Ä‘á». BÃ i toÃ¡n lÃ  chá»©ng minh, dá»±a vÃ o bayes vÃ  Schur complement. Há» cÃ³ cho má»™t pháº§n solution nhÆ°ng em Ä‘á»c váº«n khÃ´ng hiá»ƒu. Mong Ä‘Æ°á»£c má»i ngÆ°á»i giÃºp Ä‘á»¡ giáº£i Ä‘Ã¡p pháº§n lÃ½ thuyáº¿t nÃ y vá»›i áº¡. MÃ¬nh xin cáº£m Æ¡n",,,,,
"Xin chÃ o má»i ngÆ°á»i, em import sugartensor thÃ¬ bá»‹ lá»—i AttributeError: module 'sugartensor' has no attribute 'GraphKeys', giÃºp em fix vá»›i áº¡, em cáº£m Æ¡n.

Log Ä‘áº§y Ä‘á»§:
2021-03-09 14:43:25.634133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2021-03-09 14:43:27.111468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2021-03-09 14:43:27.112350: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error
2021-03-09 14:43:27.114195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-88AGTME
2021-03-09 14:43:27.114346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-88AGTME
2021-03-09 14:43:27.114788: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-09 14:43:27.120568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17cb6bf58e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-09 14:43:27.120617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""preprocess.py"", line 5, in <module>
   import data
  File ""D:\workspace\pycharm\vietnamese-speech-to-text-wavenet\data_processing\data.py"", line 6, in <module>
    import sugartensor as tf
  File ""C:\Program Files\python\lib\site-packages\sugartensor\__init__.py"", line 5, in <module>
    from .sg_main import *
  File ""C:\Program Files\python\lib\site-packages\sugartensor\sg_main.py"", line 45, in <module>
    _phase = tf.Variable(False, name='phase', trainable=False, collections=[tf.GraphKeys.LOCAL_VARIABLES])
AttributeError: module 'sugartensor' has no attribute 'GraphKeys'","Xin chÃ o má»i ngÆ°á»i, em import sugartensor thÃ¬ bá»‹ lá»—i AttributeError: module 'sugartensor' has no attribute 'GraphKeys', giÃºp em fix vá»›i áº¡, em cáº£m Æ¡n. Log Ä‘áº§y Ä‘á»§: 2021-03-09 14:43:25.634133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll 2021-03-09 14:43:27.111468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll 2021-03-09 14:43:27.112350: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error 2021-03-09 14:43:27.114195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-88AGTME 2021-03-09 14:43:27.114346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-88AGTME 2021-03-09 14:43:27.114788: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-03-09 14:43:27.120568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17cb6bf58e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 2021-03-09 14:43:27.120617: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version Traceback (most recent call last): File ""preprocess.py"", line 5, in <module> import data File ""D:\workspace\pycharm\vietnamese-speech-to-text-wavenet\data_processing\data.py"", line 6, in <module> import sugartensor as tf File ""C:\Program Files\python\lib\site-packages\sugartensor\__init__.py"", line 5, in <module> from .sg_main import * File ""C:\Program Files\python\lib\site-packages\sugartensor\sg_main.py"", line 45, in <module> _phase = tf.Variable(False, name='phase', trainable=False, collections=[tf.GraphKeys.LOCAL_VARIABLES]) AttributeError: module 'sugartensor' has no attribute 'GraphKeys'",,,,,
"ChÃ o cáº£ nhÃ 
ÄÃ¢y lÃ  bÃ i giá»›i thiá»‡u tÃ³m táº¯t kÃ¨m demo cá»§a team mÃ¬nh vá» Dall-E, nghiÃªn cá»©u má»›i nháº¥t cá»§a OpenAI vá» xá»­ lÃ½ áº£nh.
Mong lÃ  nÃ³ cÃ³ Ã­ch cho cÃ¡c báº¡n :D","ChÃ o cáº£ nhÃ  ÄÃ¢y lÃ  bÃ i giá»›i thiá»‡u tÃ³m táº¯t kÃ¨m demo cá»§a team mÃ¬nh vá» Dall-E, nghiÃªn cá»©u má»›i nháº¥t cá»§a OpenAI vá» xá»­ lÃ½ áº£nh. Mong lÃ  nÃ³ cÃ³ Ã­ch cho cÃ¡c báº¡n :D",,,,,
"Nháº­n dáº¡ng áº£nh trong computer vision Ä‘Ã²i há»i pháº£i training vá»›i cÃ¡c áº£nh Ä‘Æ°á»£c dÃ¡n nhÃ£n, viá»‡c nÃ y tá»‘n nhiá»u cÃ´ng sá»©c vÃ  tiá»n báº¡c.
Facebook Ä‘Ã£ phÃ¡t triá»ƒn thuáº­t toÃ¡n SEER (SElf supERvised) vÃ  SwAV (SWapping Assignments between multiple Views) cÃ³ thá»ƒ nháº­n dáº¡ng táº­p áº£nh hÃ ng tá»· thÃ´ng sá»‘ tá»« Instagram mÃ  khÃ´ng cáº§n pháº£i dÃ¡n nhÃ£n.
Thuáº­t toÃ¡n dá»±a vÃ o kháº£ nÄƒng nháº­n dáº¡ng cá»§a nÃ£o em bÃ©.","Nháº­n dáº¡ng áº£nh trong computer vision Ä‘Ã²i há»i pháº£i training vá»›i cÃ¡c áº£nh Ä‘Æ°á»£c dÃ¡n nhÃ£n, viá»‡c nÃ y tá»‘n nhiá»u cÃ´ng sá»©c vÃ  tiá»n báº¡c. Facebook Ä‘Ã£ phÃ¡t triá»ƒn thuáº­t toÃ¡n SEER (SElf supERvised) vÃ  SwAV (SWapping Assignments between multiple Views) cÃ³ thá»ƒ nháº­n dáº¡ng táº­p áº£nh hÃ ng tá»· thÃ´ng sá»‘ tá»« Instagram mÃ  khÃ´ng cáº§n pháº£i dÃ¡n nhÃ£n. Thuáº­t toÃ¡n dá»±a vÃ o kháº£ nÄƒng nháº­n dáº¡ng cá»§a nÃ£o em bÃ©.",,,,,
"A e Ä‘ang implement: Giáº£i phÃ¡p thá»‘ng kÃª an toÃ n giao thÃ´ng thÃ´ng minh qua mÃ¡y há»c.
Gá»“m cÃ¡c váº¥n Ä‘á»
- Check máº­t Ä‘á»™ giao thÃ´ng
- Check khÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm
- Check vá»©t rÃ¡c bá»«a bÃ£i
- Check Ä‘Ã¡m Ä‘Ã´ng tá»¥ táº­p
Má»i pÃ  con vÃ o chá»‰ Ä‘áº¡o, chÃ©m giÃ³ Ä‘á»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c tiáº¿n bá»™ hÆ¡n nhÃ©.
CÃ¡m Æ¡n bÃ  con!
#koolj_deepimage
Má»i báº¡n thá»­:","A e Ä‘ang implement: Giáº£i phÃ¡p thá»‘ng kÃª an toÃ n giao thÃ´ng thÃ´ng minh qua mÃ¡y há»c. Gá»“m cÃ¡c váº¥n Ä‘á» - Check máº­t Ä‘á»™ giao thÃ´ng - Check khÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm - Check vá»©t rÃ¡c bá»«a bÃ£i - Check Ä‘Ã¡m Ä‘Ã´ng tá»¥ táº­p Má»i pÃ  con vÃ o chá»‰ Ä‘áº¡o, chÃ©m giÃ³ Ä‘á»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c tiáº¿n bá»™ hÆ¡n nhÃ©. CÃ¡m Æ¡n bÃ  con! Má»i báº¡n thá»­:",#koolj_deepimage,,,,
"[Help][LÃ m sao crawl toÃ n bá»™ dá»¯ liá»‡u trÃ² chuyá»‡n trÃªn Facebook fanpage]
Em chÃ o anh/chá»‹, hiá»‡n táº¡i em Ä‘ang lÃ m dá»± Ã¡n thÃ¬ cáº§n toÃ n bá»™ dá»¯ liá»‡u cuá»™c trÃ² chuyá»‡n giá»¯a admin vÃ  user trÃªn Facebook fanpage. KhÃ´ng biáº¿t cÃ³ anh/chá»‹ nÃ o mÃ¬nh cÃ³ kinh nghiá»‡m Ä‘á»ƒ mÃ¬nh crawl vá» báº±ng code khÃ´ng áº¡? Em search google thÃ¬ chá»‰ toÃ n lÃ  cÃ¡ch táº£i dá»¯ liá»‡u trÃ² chuyá»‡n cá»§a má»—i cÃ¡ nhÃ¢n thÃ´i.
Em cáº£m Æ¡n ráº¥t nhiá»u áº¡.","[Help][LÃ m sao crawl toÃ n bá»™ dá»¯ liá»‡u trÃ² chuyá»‡n trÃªn Facebook fanpage] Em chÃ o anh/chá»‹, hiá»‡n táº¡i em Ä‘ang lÃ m dá»± Ã¡n thÃ¬ cáº§n toÃ n bá»™ dá»¯ liá»‡u cuá»™c trÃ² chuyá»‡n giá»¯a admin vÃ  user trÃªn Facebook fanpage. KhÃ´ng biáº¿t cÃ³ anh/chá»‹ nÃ o mÃ¬nh cÃ³ kinh nghiá»‡m Ä‘á»ƒ mÃ¬nh crawl vá» báº±ng code khÃ´ng áº¡? Em search google thÃ¬ chá»‰ toÃ n lÃ  cÃ¡ch táº£i dá»¯ liá»‡u trÃ² chuyá»‡n cá»§a má»—i cÃ¡ nhÃ¢n thÃ´i. Em cáº£m Æ¡n ráº¥t nhiá»u áº¡.",,,,,
"Trong nhÃ³m cÃ³ báº¡n nÃ o lÃ m vá» Urban Growth Forecasting khÃ´ng nhá»‰?
CÃ¡c báº¡n cÃ³ thá»ƒ gá»£i Ã½ cho mÃ¬nh biáº¿t thÆ°á»ng náº¿u forecast growth cá»§a má»™t city (at census tract) level thÃ¬ cÃ³ nhá»¯ng model loáº¡i gÃ¬? Náº¿u muá»‘n predict growth cho 1 nÄƒm, 3nÄƒm, 5 nÄƒm thÃ¬ pháº£i lÃ m nhÆ° tháº¿ nÃ o? Náº¿u cÃ¡c báº¡n cÃ³ reference ná»¯a thÃ¬ tá»‘t quÃ¡.
Xin cáº£m Æ¡n táº¥t cáº£ cÃ¡c gá»£i Ã½ cá»§a cÃ¡c báº¡n.","Trong nhÃ³m cÃ³ báº¡n nÃ o lÃ m vá» Urban Growth Forecasting khÃ´ng nhá»‰? CÃ¡c báº¡n cÃ³ thá»ƒ gá»£i Ã½ cho mÃ¬nh biáº¿t thÆ°á»ng náº¿u forecast growth cá»§a má»™t city (at census tract) level thÃ¬ cÃ³ nhá»¯ng model loáº¡i gÃ¬? Náº¿u muá»‘n predict growth cho 1 nÄƒm, 3nÄƒm, 5 nÄƒm thÃ¬ pháº£i lÃ m nhÆ° tháº¿ nÃ o? Náº¿u cÃ¡c báº¡n cÃ³ reference ná»¯a thÃ¬ tá»‘t quÃ¡. Xin cáº£m Æ¡n táº¥t cáº£ cÃ¡c gá»£i Ã½ cá»§a cÃ¡c báº¡n.",,,,,
"[PyTorch]
ChÃ o má»i ngÆ°á»i, cÃ³ báº¡n nÃ o rÃ nh vá» Pytorch cho mÃ¬nh xin chÃºt kinh nghiá»‡m.
MÃ¬nh cÃ³ 1 model vÃ  list weight cá»§a model theo tá»«ng iterations. MÃ¬nh muá»‘n tÃ­nh gradient cá»§a model w.r.t tá»«ng weights trong cÃ¡i list mÃ¬nh cÃ³. Hiá»‡n giá» mÃ¬nh chá»‰ attribute weight vÃ o model rá»“i call loss.backward Ä‘á»ƒ tÃ¬m gradient cá»§a tá»«ng tháº±ng nhÆ°ng káº¿t quáº£ khÃ´ng há»£p lÃ½ so vá»›i má»™t version khÃ¡c mÃ  mÃ¬nh code gradient function báº±ng tay. CÃ³ báº¡n nÃ o biáº¿t cÃ¡ch khÃ¡c tÃ­nh gradient trÃªn pytorch thÃ¬ cho mÃ¬nh Ã­t cao kiáº¿n vá»›i.
Cáº£m Æ¡n cÃ¡c báº¡n","[PyTorch] ChÃ o má»i ngÆ°á»i, cÃ³ báº¡n nÃ o rÃ nh vá» Pytorch cho mÃ¬nh xin chÃºt kinh nghiá»‡m. MÃ¬nh cÃ³ 1 model vÃ  list weight cá»§a model theo tá»«ng iterations. MÃ¬nh muá»‘n tÃ­nh gradient cá»§a model w.r.t tá»«ng weights trong cÃ¡i list mÃ¬nh cÃ³. Hiá»‡n giá» mÃ¬nh chá»‰ attribute weight vÃ o model rá»“i call loss.backward Ä‘á»ƒ tÃ¬m gradient cá»§a tá»«ng tháº±ng nhÆ°ng káº¿t quáº£ khÃ´ng há»£p lÃ½ so vá»›i má»™t version khÃ¡c mÃ  mÃ¬nh code gradient function báº±ng tay. CÃ³ báº¡n nÃ o biáº¿t cÃ¡ch khÃ¡c tÃ­nh gradient trÃªn pytorch thÃ¬ cho mÃ¬nh Ã­t cao kiáº¿n vá»›i. Cáº£m Æ¡n cÃ¡c báº¡n",,,,,
"Hi má»i ngÆ°á»i,
E/MÃ¬nh muá»‘n lÃ m bÃ i toÃ¡n Time series Classification cho ECG HeartBeat nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c Dataset, cÃ³ báº¡n nÃ o biáº¿t chá»‰ mÃ¬nh vá»›i ,
MÃ¬nh cÃ³ tÃ¬m Ä‘Æ°á»£c 1 dataset trÃªn kaggle https://www.kaggle.com/shayanfazeli/heartbeat
nhÆ°ng má»—i cÃ¡i segmentation nÃ³ lÃ m cÃ³ 1 heartbeat nÃªn dá»¯ liá»‡u khÃ´ng cÃ²n lÃ  time-serie ná»¯a rá»“i
E/mÃ¬nh Xin cáº£m Æ¡n,","Hi má»i ngÆ°á»i, E/MÃ¬nh muá»‘n lÃ m bÃ i toÃ¡n Time series Classification cho ECG HeartBeat nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c Dataset, cÃ³ báº¡n nÃ o biáº¿t chá»‰ mÃ¬nh vá»›i , MÃ¬nh cÃ³ tÃ¬m Ä‘Æ°á»£c 1 dataset trÃªn kaggle https://www.kaggle.com/shayanfazeli/heartbeat nhÆ°ng má»—i cÃ¡i segmentation nÃ³ lÃ m cÃ³ 1 heartbeat nÃªn dá»¯ liá»‡u khÃ´ng cÃ²n lÃ  time-serie ná»¯a rá»“i E/mÃ¬nh Xin cáº£m Æ¡n,",,,,,
"ChÃ o mn, em dÃ¹ng ubuntu 20.04 import tensorflow thÃ¬ bá»‹ lá»—i nÃ y, giÃºp em vá»›i áº¡. Tks.
could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
Ignore above cudart dlerror if you do not have a GPU set up on your machine.","ChÃ o mn, em dÃ¹ng ubuntu 20.04 import tensorflow thÃ¬ bá»‹ lá»—i nÃ y, giÃºp em vá»›i áº¡. Tks. could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory Ignore above cudart dlerror if you do not have a GPU set up on your machine.",,,,,
"Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t pháº§n nhá» ná»¯a cá»§a cuá»‘n ""Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng""
https://machinelearningcoban.com/tabml_book/ch_model/decision_tree.html
Pháº§n nÃ y chÆ°a hoÃ n thÃ nh vÃ  chÆ°a khá»›p vá»›i ná»™i dung Ä‘Ã£ viáº¿t cá»§a cuá»‘n sÃ¡ch; tuy nhiÃªn mÃ¬nh Ä‘Äƒng lÃªn Ä‘Ã¢y Ä‘á»ƒ giá»›i thiá»‡u vá»›i cÃ¡c báº¡n vá» viá»‡c pháº§n nÃ y Ä‘Æ°á»£c báº¡n Tuáº¥n Nguyá»…n (DL cÆ¡ báº£n) Ä‘Ã³ng gÃ³p. Ráº¥t cáº£m Æ¡n báº¡n Ä‘Ã£ tham gia viáº¿t vá» pháº§n mÃ´ hÃ¬nh nÃ y.
Ná»™i dung cuá»‘n sÃ¡ch sáº½ thÆ°á»ng xuyÃªn Ä‘Æ°á»£c chá»‰nh sá»­a cho phÃ¹ há»£p vá»›i máº¡ch viáº¿t chung. MÃ¬nh sáº½ chá»‰nh sá»­a ná»™i dung cá»§a pháº§n nÃ y cho nháº¥t quÃ¡n vá»›i cÃ¡c pháº§n khÃ¡c cá»§a cuá»‘n sÃ¡ch khi viáº¿t tá»›i Ä‘Ã¢y.
 â€” vá»›i Tuan Nguyen.","Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t pháº§n nhá» ná»¯a cá»§a cuá»‘n ""Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng"" https://machinelearningcoban.com/tabml_book/ch_model/decision_tree.html Pháº§n nÃ y chÆ°a hoÃ n thÃ nh vÃ  chÆ°a khá»›p vá»›i ná»™i dung Ä‘Ã£ viáº¿t cá»§a cuá»‘n sÃ¡ch; tuy nhiÃªn mÃ¬nh Ä‘Äƒng lÃªn Ä‘Ã¢y Ä‘á»ƒ giá»›i thiá»‡u vá»›i cÃ¡c báº¡n vá» viá»‡c pháº§n nÃ y Ä‘Æ°á»£c báº¡n Tuáº¥n Nguyá»…n (DL cÆ¡ báº£n) Ä‘Ã³ng gÃ³p. Ráº¥t cáº£m Æ¡n báº¡n Ä‘Ã£ tham gia viáº¿t vá» pháº§n mÃ´ hÃ¬nh nÃ y. Ná»™i dung cuá»‘n sÃ¡ch sáº½ thÆ°á»ng xuyÃªn Ä‘Æ°á»£c chá»‰nh sá»­a cho phÃ¹ há»£p vá»›i máº¡ch viáº¿t chung. MÃ¬nh sáº½ chá»‰nh sá»­a ná»™i dung cá»§a pháº§n nÃ y cho nháº¥t quÃ¡n vá»›i cÃ¡c pháº§n khÃ¡c cá»§a cuá»‘n sÃ¡ch khi viáº¿t tá»›i Ä‘Ã¢y. â€” vá»›i Tuan Nguyen.",,,,,
"Nháº­p mÃ´n Machine Learning cÆ¡ báº£n báº±ng TensorFlow
ChÃ o má»i ngÆ°á»i! MÃ¬nh vá»«a má»›i upload 4 video nháº­p mÃ´n Machine Learning báº±ng tiáº¿ng Viá»‡t lÃªn kÃªnh YouTube cá»§a TensorFlow. 4 video nÃ y hÆ°á»›ng Ä‘áº¿n Ä‘á»‘i tÆ°á»£ng nhá»¯ng báº¡n muá»‘n tÃ¬m hiá»ƒu vá» machine learning theo hÆ°á»›ng thá»±c hÃ nh trÃªn code (má»³ Äƒn liá»n ğŸ˜€) thay vÃ¬ viá»‡c há»c cÃ¡c cÃ´ng thá»©c toÃ¡n. Hy vá»ng cÃ¡c báº¡n tháº¥y ná»™i dung nÃ y há»¯u Ã­ch, vÃ  cho mÃ¬nh feedback nhÃ© ğŸ™‚

https://youtu.be/NVsw-JrXv9I?list=PLQY2H8rRoyvxNqk9EV5VP5fS0cWEXW5QQ","Nháº­p mÃ´n Machine Learning cÆ¡ báº£n báº±ng TensorFlow ChÃ o má»i ngÆ°á»i! MÃ¬nh vá»«a má»›i upload 4 video nháº­p mÃ´n Machine Learning báº±ng tiáº¿ng Viá»‡t lÃªn kÃªnh YouTube cá»§a TensorFlow. 4 video nÃ y hÆ°á»›ng Ä‘áº¿n Ä‘á»‘i tÆ°á»£ng nhá»¯ng báº¡n muá»‘n tÃ¬m hiá»ƒu vá» machine learning theo hÆ°á»›ng thá»±c hÃ nh trÃªn code (má»³ Äƒn liá»n ) thay vÃ¬ viá»‡c há»c cÃ¡c cÃ´ng thá»©c toÃ¡n. Hy vá»ng cÃ¡c báº¡n tháº¥y ná»™i dung nÃ y há»¯u Ã­ch, vÃ  cho mÃ¬nh feedback nhÃ© https://youtu.be/NVsw-JrXv9I?list=PLQY2H8rRoyvxNqk9EV5VP5fS0cWEXW5QQ",,,,,
ChÃ o cÃ¡c anh chá»‹! Em Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡ch dÃ¹ng yolo v5 cho face recognition nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c dataset. CÃ¡c anh chá»‹ cÃ³ biáº¿t bá»™ dataset nÃ o dÃ¹ng cho face recognition cÃ³ label rá»“i ko áº¡.,ChÃ o cÃ¡c anh chá»‹! Em Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡ch dÃ¹ng yolo v5 cho face recognition nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c dataset. CÃ¡c anh chá»‹ cÃ³ biáº¿t bá»™ dataset nÃ o dÃ¹ng cho face recognition cÃ³ label rá»“i ko áº¡.,,,,,
"xin phÃ©p AE cho há»i: kinh nghiá»‡m mua card mÃ n hÃ¬nh Ä‘á»ƒ xá»­ lÃ½ áº£nh vÆ¡is áº¡h
hiá»‡n cÃ´ng ty em Ä‘ang lÃ m cÃ¡i há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t. em Ä‘ang dÃ¹ng python Ä‘á»ƒ lÃ m.
hiÃªn Ä‘ang cáº§n xá»­ lÃ½ khoáº£ng 20-50 cÃ¡i áº£nh chá»©a máº·t ngá»«oi trong cÃ¹ng 1 thá»i Ä‘iá»ƒm.
thÃ¬ nÃªn chá»n loáº¡i card nvidia nÃ o áº¡.
em cÃ¡m Æ¡n áº¡.",xin phÃ©p AE cho há»i: kinh nghiá»‡m mua card mÃ n hÃ¬nh Ä‘á»ƒ xá»­ lÃ½ áº£nh vÆ¡is áº¡h hiá»‡n cÃ´ng ty em Ä‘ang lÃ m cÃ¡i há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t. em Ä‘ang dÃ¹ng python Ä‘á»ƒ lÃ m. hiÃªn Ä‘ang cáº§n xá»­ lÃ½ khoáº£ng 20-50 cÃ¡i áº£nh chá»©a máº·t ngá»«oi trong cÃ¹ng 1 thá»i Ä‘iá»ƒm. thÃ¬ nÃªn chá»n loáº¡i card nvidia nÃ o áº¡. em cÃ¡m Æ¡n áº¡.,,,,,
"CÃ³ ae nÃ o Ä‘Ã£ lÃ m vá» bot ghi láº¡i cÃ¡c tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng vÃ  tá»± Ä‘á»™ng phÃ¢n tÃ­ch hÃ nh vi ko Cho mÃ¬nh xin 1 vÃ i info nhÃ©
Thanks !",CÃ³ ae nÃ o Ä‘Ã£ lÃ m vá» bot ghi láº¡i cÃ¡c tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng vÃ  tá»± Ä‘á»™ng phÃ¢n tÃ­ch hÃ nh vi ko Cho mÃ¬nh xin 1 vÃ i info nhÃ© Thanks !,,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh vá»«a up 4 video vá» hÆ°á»›ng dáº«n xÃ¢y dá»±ng MÃ´ HÃ¬nh Nháº­n Dáº¡ng Giá»ng nÃ³i do nhÃ³m mÃ¬nh nghiÃªn cá»©u thá»i gian qua, ráº¥t mong sáº½ giÃºp Ã­ch Ä‘Æ°á»£c cho má»i ngÆ°á»i vÃ  nháº­n Ä‘Æ°á»£c pháº£n há»“i, xin cáº£m Æ¡n!","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh vá»«a up 4 video vá» hÆ°á»›ng dáº«n xÃ¢y dá»±ng MÃ´ HÃ¬nh Nháº­n Dáº¡ng Giá»ng nÃ³i do nhÃ³m mÃ¬nh nghiÃªn cá»©u thá»i gian qua, ráº¥t mong sáº½ giÃºp Ã­ch Ä‘Æ°á»£c cho má»i ngÆ°á»i vÃ  nháº­n Ä‘Æ°á»£c pháº£n há»“i, xin cáº£m Æ¡n!",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Em cÃ³ Ä‘á»c qua statistic tá»« cuá»‘n Dive In to Deep Learning vÃ  coi sÆ¡ qua trÃªn máº¡ng nhÆ°ng em váº«n khÃ´ng hiá»ƒu Ä‘Æ°á»£c statistic cÃ³ tÃ¡c dá»¥ng gÃ¬ áº¡. Mong má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin link nÃ³i tá»•ng quÃ¡t vÃ  vÃ i tÃªn sÃ¡ch vá» statistic trong Machine/Deep Learning áº¡, em cÃ³ Ä‘á»c 1 cuá»‘n nhÆ°ng nÃ³ khÃ¡ nhiá»u thuáº­t ngá»¯ vá» bÃªn thá»‘ng kÃª thuáº§n nÃªn em khÃ´ng hiá»ƒu háº¿t Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a nÃ³, mong má»i ngÆ°á»i gá»£i Ã½ giÃºp em vÃ i cuá»‘n thiÃªn vá» ML nhiá»u hÆ¡n.
Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Em chÃ o má»i ngÆ°á»i áº¡. Em cÃ³ Ä‘á»c qua statistic tá»« cuá»‘n Dive In to Deep Learning vÃ  coi sÆ¡ qua trÃªn máº¡ng nhÆ°ng em váº«n khÃ´ng hiá»ƒu Ä‘Æ°á»£c statistic cÃ³ tÃ¡c dá»¥ng gÃ¬ áº¡. Mong má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin link nÃ³i tá»•ng quÃ¡t vÃ  vÃ i tÃªn sÃ¡ch vá» statistic trong Machine/Deep Learning áº¡, em cÃ³ Ä‘á»c 1 cuá»‘n nhÆ°ng nÃ³ khÃ¡ nhiá»u thuáº­t ngá»¯ vá» bÃªn thá»‘ng kÃª thuáº§n nÃªn em khÃ´ng hiá»ƒu háº¿t Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a nÃ³, mong má»i ngÆ°á»i gá»£i Ã½ giÃºp em vÃ i cuá»‘n thiÃªn vá» ML nhiá»u hÆ¡n. Em xin cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i,má»i ngÆ°á»i cho em há»i lÃ  há»c Tá»± Ä‘á»™ng hÃ³a sau nÃ y cÃ³ thá»ƒ lÃ m vá» Machine learning khÃ´ng áº¡? VÃ¬ em cÃ³ Ä‘á»c vá» hÆ°á»›ng nghiÃªn cá»©u cá»§a ngÃ nh thÃ¬ váº«n cÃ³ nháº­n dáº¡ng hÃ¬nh áº£nh , giá»ng nÃ³i...","ChÃ o má»i ngÆ°á»i,má»i ngÆ°á»i cho em há»i lÃ  há»c Tá»± Ä‘á»™ng hÃ³a sau nÃ y cÃ³ thá»ƒ lÃ m vá» Machine learning khÃ´ng áº¡? VÃ¬ em cÃ³ Ä‘á»c vá» hÆ°á»›ng nghiÃªn cá»©u cá»§a ngÃ nh thÃ¬ váº«n cÃ³ nháº­n dáº¡ng hÃ¬nh áº£nh , giá»ng nÃ³i...",,,,,
"[Pytorch Series]
BÃ i 1: Tensor
BÃ i nÃ y mÃ¬nh hÆ°á»›ng dáº«n cÃ¡c kiáº¿n thá»©c ná»n táº£ng vá» torch tensor: vector, ma tráº­n, tensor.
Tá»« pháº§n cÆ¡ báº£n nhÆ° index, slicing Ä‘áº¿n nhá»¯ng pháº§n phá»©c táº¡p hÆ¡n nhÆ° storage, size, offset, stride, hay contiguous tensor rá»“i Ä‘áº¿n tensor GPU, numpy sang tensor.
https://nttuan8.com/bai-1-tensor/
Ps: Hay thÃ¬ cho mÃ¬nh xin 1 like, 1 share â˜º","[Pytorch Series] BÃ i 1: Tensor BÃ i nÃ y mÃ¬nh hÆ°á»›ng dáº«n cÃ¡c kiáº¿n thá»©c ná»n táº£ng vá» torch tensor: vector, ma tráº­n, tensor. Tá»« pháº§n cÆ¡ báº£n nhÆ° index, slicing Ä‘áº¿n nhá»¯ng pháº§n phá»©c táº¡p hÆ¡n nhÆ° storage, size, offset, stride, hay contiguous tensor rá»“i Ä‘áº¿n tensor GPU, numpy sang tensor. https://nttuan8.com/bai-1-tensor/ Ps: Hay thÃ¬ cho mÃ¬nh xin 1 like, 1 share",,,,,
"CÃ¡c BÃ¡c cho em há»i vá»›i áº¡.
Em Ä‘ang Train Yolov4 -AlexDarknet, em Ä‘á»c cÅ©ng nhÆ° tÃ¬m hiá»ƒu thÃ¬ khi trainning thÃ¬ cÃ¡c áº£nh trong dataset cá»§a mÃ¬nh thÃ¬ yolo sáº½ resize áº£nh vá» weight vÃ  height Ä‘Æ°á»£c khai bÃ¡o trong file config vÃ  khÃ´ng giá»¯ aspect ratio vÃ¬ váº­y Ä‘a sá»‘ object trong áº£nh bá»‹ mÃ©o . VÃ  em cÃ³ set parameter Random = 1 á»Ÿ layer cuá»‘i thÃ¬ sáº½ resize network thÃ¬ tÆ°Æ¡ng á»©ng vá»›i viá»‡c resize input resolution Ä‘Ãºng k áº¡ ?
1 - vá»›i áº£nh trong train dataset mÃ  cÃ³ size khÃ¡c nhau thÃ¬ viá»‡c k giá»¯ aspect ratio khi train cÃ³ áº£nh hÆ°á»Ÿng gi Ä‘áº¿n accuracy khÃ´ng áº¡ ? .
2 - Náº¿u padding cho cÃ¡c áº£nh Ä‘á»ƒ giá»¯ aspect ratio dÃ¹ng letterbox thÃ¬ cÃ³ cáº£i thiá»‡n Ä‘Æ°á»£c káº¿t quáº£ trainning khÃ´ng áº¡ ?","CÃ¡c BÃ¡c cho em há»i vá»›i áº¡. Em Ä‘ang Train Yolov4 -AlexDarknet, em Ä‘á»c cÅ©ng nhÆ° tÃ¬m hiá»ƒu thÃ¬ khi trainning thÃ¬ cÃ¡c áº£nh trong dataset cá»§a mÃ¬nh thÃ¬ yolo sáº½ resize áº£nh vá» weight vÃ  height Ä‘Æ°á»£c khai bÃ¡o trong file config vÃ  khÃ´ng giá»¯ aspect ratio vÃ¬ váº­y Ä‘a sá»‘ object trong áº£nh bá»‹ mÃ©o . VÃ  em cÃ³ set parameter Random = 1 á»Ÿ layer cuá»‘i thÃ¬ sáº½ resize network thÃ¬ tÆ°Æ¡ng á»©ng vá»›i viá»‡c resize input resolution Ä‘Ãºng k áº¡ ? 1 - vá»›i áº£nh trong train dataset mÃ  cÃ³ size khÃ¡c nhau thÃ¬ viá»‡c k giá»¯ aspect ratio khi train cÃ³ áº£nh hÆ°á»Ÿng gi Ä‘áº¿n accuracy khÃ´ng áº¡ ? . 2 - Náº¿u padding cho cÃ¡c áº£nh Ä‘á»ƒ giá»¯ aspect ratio dÃ¹ng letterbox thÃ¬ cÃ³ cáº£i thiá»‡n Ä‘Æ°á»£c káº¿t quáº£ trainning khÃ´ng áº¡ ?",,,,,
"My minimal implementation of SSD: Single Shot MultiBox Detector
Source code: https://github.com/uvipen/SSD-pytorch
Full demo: https://youtu.be/Br0QiEuBMzU",My minimal implementation of SSD: Single Shot MultiBox Detector Source code: https://github.com/uvipen/SSD-pytorch Full demo: https://youtu.be/Br0QiEuBMzU,,,,,
"Má»™t pháº§n nhá» tiáº¿p theo cá»§a cuá»‘n ""Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng""
https://machinelearningcoban.com/tabml_book/ch_tabular_data/datasets.html.
Pháº§n nÃ y giá»›i thiá»‡u má»™t vÃ i (khÃ´ng pháº£i toÃ n bá»™) bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¹ng trong sÃ¡ch vÃ  giá»›i thiá»‡u vá» EDA -- bÆ°á»›c Ä‘áº§u tiÃªn khi lÃ m má»™t bÃ i toÃ¡n vá»›i dá»¯ liá»‡u dáº¡ng báº£ng.","Má»™t pháº§n nhá» tiáº¿p theo cá»§a cuá»‘n ""Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng"" https://machinelearningcoban.com/tabml_book/ch_tabular_data/datasets.html. Pháº§n nÃ y giá»›i thiá»‡u má»™t vÃ i (khÃ´ng pháº£i toÃ n bá»™) bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¹ng trong sÃ¡ch vÃ  giá»›i thiá»‡u vá» EDA -- bÆ°á»›c Ä‘áº§u tiÃªn khi lÃ m má»™t bÃ i toÃ¡n vá»›i dá»¯ liá»‡u dáº¡ng báº£ng.",,,,,
"Báº£n dá»‹ch cá»§a cuá»‘n sÃ¡ch Há»c mÃ¡y kháº£ diá»…n giáº£i Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh, cÃ¡c báº¡n cÃ³ thá»ƒ táº£i vá» báº£n pdf á»Ÿ Ä‘Ã¢y!
Github: https://github.com/giangnguyen2412/InterpretableMLBook-Vietnamese
Tweet cá»§a tÃ¡c giáº£ vá» báº£n dá»‹ch: https://twitter.com/ChristophMolnar/status/1366383437645574145","Báº£n dá»‹ch cá»§a cuá»‘n sÃ¡ch Há»c mÃ¡y kháº£ diá»…n giáº£i Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh, cÃ¡c báº¡n cÃ³ thá»ƒ táº£i vá» báº£n pdf á»Ÿ Ä‘Ã¢y! Github: https://github.com/giangnguyen2412/InterpretableMLBook-Vietnamese Tweet cá»§a tÃ¡c giáº£ vá» báº£n dá»‹ch: https://twitter.com/ChristophMolnar/status/1366383437645574145",,,,,
"Em chÃ o cÃ¡c anh chá»‹, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu cÃ¢y quyáº¿t Ä‘á»‹nh thÃ¬ trong káº¿t quáº£ cÃ³ hiá»ƒn thá»‹ value. 
VÃ­ dá»¥ value = [37, 34, 41] táº¡i node.
Em khÃ´ng biáº¿t lÃ  giÃ¡ trá»‹ value Ä‘Ã³ biá»ƒu thá»‹ vÃ  mang Ã½ nghÄ©a gÃ¬ áº¡.
Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡.

Nguá»“n: https://ichi.pro/vi/hinh-dung-cay-quyet-dinh-bang-python-scikit-learning-graphviz-matplotlib-31132954028252","Em chÃ o cÃ¡c anh chá»‹, hiá»‡n em Ä‘ang tÃ¬m hiá»ƒu cÃ¢y quyáº¿t Ä‘á»‹nh thÃ¬ trong káº¿t quáº£ cÃ³ hiá»ƒn thá»‹ value. VÃ­ dá»¥ value = [37, 34, 41] táº¡i node. Em khÃ´ng biáº¿t lÃ  giÃ¡ trá»‹ value Ä‘Ã³ biá»ƒu thá»‹ vÃ  mang Ã½ nghÄ©a gÃ¬ áº¡. Mong má»i ngÆ°á»i giáº£i Ä‘Ã¡p áº¡. Nguá»“n: https://ichi.pro/vi/hinh-dung-cay-quyet-dinh-bang-python-scikit-learning-graphviz-matplotlib-31132954028252",,,,,
FastICA - phÃ¢n tÃ­ch thÃ nh pháº§n Ä‘á»™c láº­p lÃ  má»™t thuáº­t toÃ¡n Unsupervised Learning ráº¥t há»¯u Ã­ch trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ Ä‘áº·c trÆ°ng. Äáº·c biá»‡t lÃ  nhá»¯ng tÃ­n hiá»‡u Ä‘á»™c láº­p hÃ²a trá»™n vÃ o nhau.,FastICA - phÃ¢n tÃ­ch thÃ nh pháº§n Ä‘á»™c láº­p lÃ  má»™t thuáº­t toÃ¡n Unsupervised Learning ráº¥t há»¯u Ã­ch trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ Ä‘áº·c trÆ°ng. Äáº·c biá»‡t lÃ  nhá»¯ng tÃ­n hiá»‡u Ä‘á»™c láº­p hÃ²a trá»™n vÃ o nhau.,,,,,
"Lá»c Ã½ tÆ°á»Ÿng cá»Ÿi nghiá»‡p AI/ML cho Healthcare, mÃ  nhÃ¬n quanh tháº¥y TÃ¢y TÃ u cÃ³ nhiá»u thá»© hay ho quÃ¡, nÃ o lÃ  AI doctors, remote patient monitoring, virtual scribes, precision medicine, ... hÆ¡i hoang mang. Cáº§n tÃ¬m ngÆ°á»i an á»§i hoáº·c Ä‘Ã¡nh Ä‘áº­p.","Lá»c Ã½ tÆ°á»Ÿng cá»Ÿi nghiá»‡p AI/ML cho Healthcare, mÃ  nhÃ¬n quanh tháº¥y TÃ¢y TÃ u cÃ³ nhiá»u thá»© hay ho quÃ¡, nÃ o lÃ  AI doctors, remote patient monitoring, virtual scribes, precision medicine, ... hÆ¡i hoang mang. Cáº§n tÃ¬m ngÆ°á»i an á»§i hoáº·c Ä‘Ã¡nh Ä‘áº­p.",,,,,
"ChÃ o mn, em muá»‘n há»c vá» máº£ng Ã¢m thanh nÃ³i chung, bao gá»“m phÃ¢n loáº¡i, nháº­n diá»‡n Ã¢m thanh, tá»•ng há»£p, nháº­n dáº¡ng tiáº¿ng nÃ³i, ... cá»§a ML, DL thÃ¬ lá»™ trÃ¬nh há»c nhÆ° nÃ o áº¡?
Hiá»‡n táº¡i em Ä‘Ã£ code tá»‘t python, Ä‘Ã£ tá»«ng lÃ m theo cÃ¡c project cÃ³ sáºµn trÃªn git vÃ  train Ä‘Æ°á»£c 1 sá»‘ model Ã¢m thanh; nhÆ°ng em cáº£m tháº¥y chÆ°a hiá»ƒu sÃ¢u
em muá»‘n há»c cÆ¡ báº£n tá»« Ä‘áº§u, tinh chá»‰nh Ä‘á»ƒ hiá»ƒu rÃµ tá»«ng param cá»§a model, tá»« Ä‘á»c input, tÃ­nh mfcc, fft, ....
mong má»i ngÆ°á»i chá»‰ dáº«n áº¡, em cáº£m Æ¡n","ChÃ o mn, em muá»‘n há»c vá» máº£ng Ã¢m thanh nÃ³i chung, bao gá»“m phÃ¢n loáº¡i, nháº­n diá»‡n Ã¢m thanh, tá»•ng há»£p, nháº­n dáº¡ng tiáº¿ng nÃ³i, ... cá»§a ML, DL thÃ¬ lá»™ trÃ¬nh há»c nhÆ° nÃ o áº¡? Hiá»‡n táº¡i em Ä‘Ã£ code tá»‘t python, Ä‘Ã£ tá»«ng lÃ m theo cÃ¡c project cÃ³ sáºµn trÃªn git vÃ  train Ä‘Æ°á»£c 1 sá»‘ model Ã¢m thanh; nhÆ°ng em cáº£m tháº¥y chÆ°a hiá»ƒu sÃ¢u em muá»‘n há»c cÆ¡ báº£n tá»« Ä‘áº§u, tinh chá»‰nh Ä‘á»ƒ hiá»ƒu rÃµ tá»«ng param cá»§a model, tá»« Ä‘á»c input, tÃ­nh mfcc, fft, .... mong má»i ngÆ°á»i chá»‰ dáº«n áº¡, em cáº£m Æ¡n",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c.
Nhiá»u anh em Ä‘ang há»c sá»‘t ruá»™t nÃªn Ä‘Ãªm qua em Ä‘Ã£ ra luÃ´n Pháº§n 2 cho anh em. Hi vá»ng sáº½ giÃºp Ä‘Æ°á»£c anh em cÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» triá»ƒn khai má»™t model nhÆ° nÃ o.
Kiáº¿n thá»©c trong bÃ i nÃ y hoÃ n toÃ n cÃ³ thá»ƒ Ã¡p dá»¥ng cho nhiá»u bÃ i khÃ¡c!
ChÃº Ã½: Em cÃ³ note vÃ i Ã½ trong bÃ i rá»“i, cÃ¡c báº¡n chÃº Ã½ Ä‘á»ƒ xá»­ lÃ½ thÃªm khi Ä‘Æ°a vÃ o thá»±c táº¿ nhÃ©.","KÃ­nh chÃ o cÃ¡c bÃ¡c. Nhiá»u anh em Ä‘ang há»c sá»‘t ruá»™t nÃªn Ä‘Ãªm qua em Ä‘Ã£ ra luÃ´n Pháº§n 2 cho anh em. Hi vá»ng sáº½ giÃºp Ä‘Æ°á»£c anh em cÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» triá»ƒn khai má»™t model nhÆ° nÃ o. Kiáº¿n thá»©c trong bÃ i nÃ y hoÃ n toÃ n cÃ³ thá»ƒ Ã¡p dá»¥ng cho nhiá»u bÃ i khÃ¡c! ChÃº Ã½: Em cÃ³ note vÃ i Ã½ trong bÃ i rá»“i, cÃ¡c báº¡n chÃº Ã½ Ä‘á»ƒ xá»­ lÃ½ thÃªm khi Ä‘Æ°a vÃ o thá»±c táº¿ nhÃ©.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang há»c trÃªn trang machinelearningcoban cá»§a anh Tiá»‡p. Em cÃ³ tháº¯c máº¯c ráº±ng táº¡i sao á»Ÿ hÃ m loss bÃ i Logistic Regression tÃ¡c giáº£ láº¡i dÃ¹ng log cÆ¡ sá»‘ e mÃ  khÃ´ng dÃ¹ng cÆ¡ sá»‘ khÃ¡c, nÃ³ cÃ³ Ã½ nghÄ©a gÃ¬ vá» máº·t toÃ¡n há»c khÃ´ng áº¡. Em xin cáº£m Æ¡n","Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang há»c trÃªn trang machinelearningcoban cá»§a anh Tiá»‡p. Em cÃ³ tháº¯c máº¯c ráº±ng táº¡i sao á»Ÿ hÃ m loss bÃ i Logistic Regression tÃ¡c giáº£ láº¡i dÃ¹ng log cÆ¡ sá»‘ e mÃ  khÃ´ng dÃ¹ng cÆ¡ sá»‘ khÃ¡c, nÃ³ cÃ³ Ã½ nghÄ©a gÃ¬ vá» máº·t toÃ¡n há»c khÃ´ng áº¡. Em xin cáº£m Æ¡n",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang lÃ m bÃ i toÃ¡n phÃ¡t hiá»‡n tiÃªu Ä‘á» mang tÃ­nh giáº­t gÃ¢n trÃªn bÃ¡o máº¡ng. Má»¥c tiÃªu lÃ  phÃ¢n tÃ­ch Ä‘á»‹nh tÃ­nh vÃ  phÃ¢n loáº¡i cÃ¡c tiÃªu Ä‘á» mang tÃ­nh giáº­t gÃ¢n trÃªn bÃ¡o (vÃ­ dá»¥: 'Toang' thá»±c sá»±, 150 tá»· USD biáº¿n máº¥t, dÃ¢n chÆ¡i hoáº£ng sá»£). GiÃºp cho ngÆ°á»i Ä‘á»c hiá»ƒu thÃªm vá» cÃ¡ch Ä‘áº·t cÃ¡c tiÃªu Ä‘á» giáº­t gÃ¢n trÃªn cÃ¡c bÃ¡o trÃªn khÃ­a cáº¡nh ngÃ´n ngá»¯. CÃ¡c cao nhÃ¢n cÃ³ nhiá»u kinh nghiá»‡m cÃ³ thá»ƒ cho em vÃ i gá»£i Ã½ vá»›i áº¡.","KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang lÃ m bÃ i toÃ¡n phÃ¡t hiá»‡n tiÃªu Ä‘á» mang tÃ­nh giáº­t gÃ¢n trÃªn bÃ¡o máº¡ng. Má»¥c tiÃªu lÃ  phÃ¢n tÃ­ch Ä‘á»‹nh tÃ­nh vÃ  phÃ¢n loáº¡i cÃ¡c tiÃªu Ä‘á» mang tÃ­nh giáº­t gÃ¢n trÃªn bÃ¡o (vÃ­ dá»¥: 'Toang' thá»±c sá»±, 150 tá»· USD biáº¿n máº¥t, dÃ¢n chÆ¡i hoáº£ng sá»£). GiÃºp cho ngÆ°á»i Ä‘á»c hiá»ƒu thÃªm vá» cÃ¡ch Ä‘áº·t cÃ¡c tiÃªu Ä‘á» giáº­t gÃ¢n trÃªn cÃ¡c bÃ¡o trÃªn khÃ­a cáº¡nh ngÃ´n ngá»¯. CÃ¡c cao nhÃ¢n cÃ³ nhiá»u kinh nghiá»‡m cÃ³ thá»ƒ cho em vÃ i gá»£i Ã½ vá»›i áº¡.",,,,,
"ChÃ o cÃ¡c anh chá»‹,
Hiá»‡n táº¡i em Ä‘ang gáº·p báº¿ táº¯c khi lÃ m viá»‡c vá»›i ARIMA model dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n dá»¯ liá»‡u Time series, cá»¥ thá»ƒ lÃ  dá»¯ liá»‡u stock, náº¿u cÃ³ anh chá»‹ nÃ o giÃºp Ä‘Æ°á»£c em, em xin cáº£m Æ¡n vÃ  háº­u táº¡, em á»Ÿ tp hcm áº¡.","ChÃ o cÃ¡c anh chá»‹, Hiá»‡n táº¡i em Ä‘ang gáº·p báº¿ táº¯c khi lÃ m viá»‡c vá»›i ARIMA model dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n dá»¯ liá»‡u Time series, cá»¥ thá»ƒ lÃ  dá»¯ liá»‡u stock, náº¿u cÃ³ anh chá»‹ nÃ o giÃºp Ä‘Æ°á»£c em, em xin cáº£m Æ¡n vÃ  háº­u táº¡, em á»Ÿ tp hcm áº¡.",,,,,
"[Xin giÃºp Ä‘á»¡ vá» training Unet3D trÃªn colab]
Em xin chÃ o má»i ngÆ°á»i,
Em Ä‘ang gáº·p váº¥n Ä‘á» vá» huáº¥n luyá»‡n máº¡ng Unet3D trÃªn Colab. Cá»¥ thá»ƒ lÃ  viá»‡c háº¿t VRAM trÃªn GPU.
Em sá»­ dá»¥ng gÃ³i Colab Pro, kÃ­ch thÆ°á»›c hÃ¬nh áº£nh Ä‘áº§u vÃ o lÃ  (4,128,128,128), kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Unet3D (áº£nh 1) . Khi huáº¥n luyá»‡n thÃ¬ Ä‘Æ°á»£c bÃ¡o lÃ  ""CUDA out of memory: (áº£nh 2), do em dÃ¹ng Colab Pro nÃªn cÃ²n thá»«a ráº¥t nhiá»u RAM chá»‰ sá»­ dá»¥ng 3.5/25,5GB.
KhÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± nhÆ° váº­y chÆ°a áº¡, em Ä‘Ã£ thá»­ nhiá»u cÃ¡ch tuy nhiÃªn khÃ´ng Ä‘Æ°á»£c, mong má»i ngÆ°á»i gÃ³p Ã½ cho em. Em xin cÃ¡m Æ¡n!
P/S: Em sá»­ dá»¥ng pytorch","[Xin giÃºp Ä‘á»¡ vá» training Unet3D trÃªn colab] Em xin chÃ o má»i ngÆ°á»i, Em Ä‘ang gáº·p váº¥n Ä‘á» vá» huáº¥n luyá»‡n máº¡ng Unet3D trÃªn Colab. Cá»¥ thá»ƒ lÃ  viá»‡c háº¿t VRAM trÃªn GPU. Em sá»­ dá»¥ng gÃ³i Colab Pro, kÃ­ch thÆ°á»›c hÃ¬nh áº£nh Ä‘áº§u vÃ o lÃ  (4,128,128,128), kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Unet3D (áº£nh 1) . Khi huáº¥n luyá»‡n thÃ¬ Ä‘Æ°á»£c bÃ¡o lÃ  ""CUDA out of memory: (áº£nh 2), do em dÃ¹ng Colab Pro nÃªn cÃ²n thá»«a ráº¥t nhiá»u RAM chá»‰ sá»­ dá»¥ng 3.5/25,5GB. KhÃ´ng biáº¿t Ä‘Ã£ cÃ³ ai huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± nhÆ° váº­y chÆ°a áº¡, em Ä‘Ã£ thá»­ nhiá»u cÃ¡ch tuy nhiÃªn khÃ´ng Ä‘Æ°á»£c, mong má»i ngÆ°á»i gÃ³p Ã½ cho em. Em xin cÃ¡m Æ¡n! P/S: Em sá»­ dá»¥ng pytorch",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, hÃ´m nay em má»›i há»c vá» YOLO v5 nÃªn xem xin máº¡nh dáº¡n viáº¿t bÃ i gá»­i Ä‘áº¿n anh em Pháº§n 1 cá»§a series lÃ m viá»‡c vá»›i YOLO v5. Hi vá»ng giÃºp Ä‘Æ°á»£c gÃ¬ Ä‘Ã³ cho anh em newbie má»›i há»c.
CÃ¡c cao thá»§ xin Ä‘Æ°á»£c chá»‰ giÃ¡o thÃªm ah.
Ps: CÃ¡c bÃ i trÃªn MÃ¬ AI chá»‰ mang tÃ­nh cháº¥t há»c táº­p, mong cÃ¡c bÃ¡c khÃ´ng comment nhÆ° má»™t sáº£n pháº©m thÆ°Æ¡ng máº¡i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, hÃ´m nay em má»›i há»c vá» YOLO v5 nÃªn xem xin máº¡nh dáº¡n viáº¿t bÃ i gá»­i Ä‘áº¿n anh em Pháº§n 1 cá»§a series lÃ m viá»‡c vá»›i YOLO v5. Hi vá»ng giÃºp Ä‘Æ°á»£c gÃ¬ Ä‘Ã³ cho anh em newbie má»›i há»c. CÃ¡c cao thá»§ xin Ä‘Æ°á»£c chá»‰ giÃ¡o thÃªm ah. Ps: CÃ¡c bÃ i trÃªn MÃ¬ AI chá»‰ mang tÃ­nh cháº¥t há»c táº­p, mong cÃ¡c bÃ¡c khÃ´ng comment nhÆ° má»™t sáº£n pháº©m thÆ°Æ¡ng máº¡i!",,,,,
"Dáº¡ em chÃ o má»i ngÆ°á»i, cho em há»i lÃ  cÃ³ thÆ° viá»‡n nÃ o há»• trá»£ mÃ¬nh táº¡o ra 1 chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ nháº­p input vÃ o trong mÃ´ hÃ¬nh neural network khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.","Dáº¡ em chÃ o má»i ngÆ°á»i, cho em há»i lÃ  cÃ³ thÆ° viá»‡n nÃ o há»• trá»£ mÃ¬nh táº¡o ra 1 chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ nháº­p input vÃ o trong mÃ´ hÃ¬nh neural network khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"[Series Pytorch]
Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ lÃ m má»™t vÃ i project vá» Pytorch nÃªn mÃ¬nh muá»‘n chia sáº» kiáº¿n thá»©c tá»›i má»i ngÆ°á»i. á» series Pytorch nÃ y, mÃ¬nh sáº½ viáº¿t chi tiáº¿t tá»« nhá»¯ng pháº§n cÆ¡ báº£n nháº¥t cá»§a Pytorch nhÆ° tensor cho Ä‘áº¿n pháº§n triá»ƒn khai model Ä‘Æ°a ra sá»­ dá»¥ng thá»±c táº¿ cho má»i ngÆ°á»i (deployment).
Äá»ƒ cho nhá»¯ng ngÆ°á»i má»›i chÆ°a sá»­ dá»¥ng Pytorch bao giá» cÅ©ng cÃ³ thá»ƒ hiá»ƒu cÃ¡c kiá»n thá»©c ná»n táº£ng cá»§a Pytorch, sau Ä‘Ã³ xÃ¢y dá»±ng vÃ  phÃ¡t triá»ƒn á»©ng dá»¥ng Deep Learning vá»›i Pytorch.
KhÃ¡c vá»›i series Deep Learning cÆ¡ báº£n, á»Ÿ series Pytorch láº§n nÃ y, mÃ¬nh táº­p trung vÃ o giáº£i thÃ­ch chi tiáº¿t cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng cá»§a Pytorch vÃ  cÃ¡ch triá»ƒn khai model Deep Learning ra ngoÃ i thá»±c táº¿ dÃ¹ng Pytorch.
Ná»™i dung series á»Ÿ Ä‘Ã¢y: https://nttuan8.com/gioi-thieu-series-pytorch/
Táº§n suáº¥t ra bÃ i : 1-2 tuáº§n/1 bÃ i vÃ o cuá»‘i tuáº§n.
Ps: NhÆ° thÆ°á»ng lá»‡ mÃ¬nh xin 1 like, 1 share Ä‘á»ƒ thÃªm tinh tháº§n viáº¿t ğŸ˜","[Series Pytorch] Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ lÃ m má»™t vÃ i project vá» Pytorch nÃªn mÃ¬nh muá»‘n chia sáº» kiáº¿n thá»©c tá»›i má»i ngÆ°á»i. á» series Pytorch nÃ y, mÃ¬nh sáº½ viáº¿t chi tiáº¿t tá»« nhá»¯ng pháº§n cÆ¡ báº£n nháº¥t cá»§a Pytorch nhÆ° tensor cho Ä‘áº¿n pháº§n triá»ƒn khai model Ä‘Æ°a ra sá»­ dá»¥ng thá»±c táº¿ cho má»i ngÆ°á»i (deployment). Äá»ƒ cho nhá»¯ng ngÆ°á»i má»›i chÆ°a sá»­ dá»¥ng Pytorch bao giá» cÅ©ng cÃ³ thá»ƒ hiá»ƒu cÃ¡c kiá»n thá»©c ná»n táº£ng cá»§a Pytorch, sau Ä‘Ã³ xÃ¢y dá»±ng vÃ  phÃ¡t triá»ƒn á»©ng dá»¥ng Deep Learning vá»›i Pytorch. KhÃ¡c vá»›i series Deep Learning cÆ¡ báº£n, á»Ÿ series Pytorch láº§n nÃ y, mÃ¬nh táº­p trung vÃ o giáº£i thÃ­ch chi tiáº¿t cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng cá»§a Pytorch vÃ  cÃ¡ch triá»ƒn khai model Deep Learning ra ngoÃ i thá»±c táº¿ dÃ¹ng Pytorch. Ná»™i dung series á»Ÿ Ä‘Ã¢y: https://nttuan8.com/gioi-thieu-series-pytorch/ Táº§n suáº¥t ra bÃ i : 1-2 tuáº§n/1 bÃ i vÃ o cuá»‘i tuáº§n. Ps: NhÆ° thÆ°á»ng lá»‡ mÃ¬nh xin 1 like, 1 share Ä‘á»ƒ thÃªm tinh tháº§n viáº¿t",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 3/2020 vÃ o comment cá»§a post nÃ y.","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 3/2020 vÃ o comment cá»§a post nÃ y.",,,,,
"[AI application] AI agent plays Contra
Source code: https://github.com/uvipen/Contra-PPO-pytorch
Full demo: https://youtu.be/YBd4l806Di8
#Python #AI #ReinforcementLearning",[AI application] AI agent plays Contra Source code: https://github.com/uvipen/Contra-PPO-pytorch Full demo: https://youtu.be/YBd4l806Di8,#Python	#AI	#ReinforcementLearning,,,,
"[Deep learning - Há»i vá» tráº­t tá»± cÃ¡c inputs cá»§a NN]
Xin chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n vá» Virtual try on trÃªn multiple pose.
Model mÃ¬nh dÃ¹ng lÃ  Unet like (pix2pixHD).
Input cá»§a mÃ´ hÃ¬nh mÃ¬nh sá»­ dá»¥ng lÃ  sá»± concat giá»¯a cÃ¡c Ä‘áº·c trÆ°ng nhÆ° lÃ : source image, pose heat map, segmentation,...
CÃ¢u há»i cá»§a mÃ¬nh lÃ : Viá»‡c sáº¯p xáº¿p thá»© tá»± cÃ¡c input cho model theo hai trÆ°á»ng há»£p sau thÃ¬ cÃ³ khÃ¡c nhau gÃ¬ khÃ´ng?
output1 = pix2pixHD(concat(inputA, inputB, inputC))
output2 = pix2pixHD(concat(inputB, inputC, inputA))
MÃ¬nh muá»‘n biáº¿t lÃ  sá»± sáº¯p xáº¿p thá»© tá»± cÃ¡c input cÃ³ Ã½ nghÄ©a nhÆ° tháº¿ nÃ o Ä‘áº¿n cháº¥t lÆ°á»£ng Ä‘áº§u ra ouput1 vs output2.
ThÃ¢n chÃ o.","[Deep learning - Há»i vá» tráº­t tá»± cÃ¡c inputs cá»§a NN] Xin chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n vá» Virtual try on trÃªn multiple pose. Model mÃ¬nh dÃ¹ng lÃ  Unet like (pix2pixHD). Input cá»§a mÃ´ hÃ¬nh mÃ¬nh sá»­ dá»¥ng lÃ  sá»± concat giá»¯a cÃ¡c Ä‘áº·c trÆ°ng nhÆ° lÃ : source image, pose heat map, segmentation,... CÃ¢u há»i cá»§a mÃ¬nh lÃ : Viá»‡c sáº¯p xáº¿p thá»© tá»± cÃ¡c input cho model theo hai trÆ°á»ng há»£p sau thÃ¬ cÃ³ khÃ¡c nhau gÃ¬ khÃ´ng? output1 = pix2pixHD(concat(inputA, inputB, inputC)) output2 = pix2pixHD(concat(inputB, inputC, inputA)) MÃ¬nh muá»‘n biáº¿t lÃ  sá»± sáº¯p xáº¿p thá»© tá»± cÃ¡c input cÃ³ Ã½ nghÄ©a nhÆ° tháº¿ nÃ o Ä‘áº¿n cháº¥t lÆ°á»£ng Ä‘áº§u ra ouput1 vs output2. ThÃ¢n chÃ o.",,,,,
,nan,,,,,
"HÃ nh trÃ¬nh AI cá»§a má»™t sinh viÃªn tá»“i
https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/485380192869041/
1 bÃ i viáº¿t khÃ¡ dÃ i vá» hÃ nh trÃ¬nh bÆ°á»›c chÃ¢n vÃ  theo Ä‘uá»•i AI (trÃ­ tuá»‡ nhÃ¢n táº¡o) cá»§a ... 1 báº¡n sinh viÃªn tá»“i. MÃ¬nh Ä‘á»c tháº¥y khÃ¡ thÃº vá»‹ vÃ  khÃ¡ vui :D Trong bÃ i tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p cÃ¡c dáº¥u má»‘c trÃªn con Ä‘Æ°á»ng há»c vÃ  lÃ m AI cá»§a mÃ¬nh. Tá»« nhá»¯ng bÆ°á»›c Ä‘áº§u Ä‘á»c blog ML cÆ¡ báº£n cá»§a a Tiá»‡p, blog DL cÆ¡ báº£n cá»§a a Tuáº¥n, láº§n thá»±c táº­p Ä‘áº§u tiÃªn, lÃªn lab nghiÃªn cá»©u vÃ  paper Ä‘áº§u tiÃªn,....
""Blog trÃ¬nh bÃ y ráº¥t máº¡ch láº¡c, vÄƒn phong vÃ  cÃ¡c biáº¿n Ä‘á»•i cÅ©ng dá»… hiá»ƒu, vÃ  cÃ¡i hay ho Ä‘Ã³ lÃ  tá»« lÃºc tiáº¿p cáº­n kiáº¿n thá»©c Ä‘áº¿n káº¿t luáº­n váº«n ráº¥t logic. MÃ¬nh vui nháº¥t lÃ  lÃºc mÃ¬nh train vÃ  cháº¡y Ä‘Æ°á»£c vÃ­ dá»¥ xe tá»± lÃ¡i trong bÃ i CNN. Trong blog bÃ i nÃ o cÅ©ng cÃ³ code vÃ­ dá»¥, vÃ  má»—i láº§n cháº¡y cÃ¡c vÃ­ dá»¥ trá»±c quan lÃ m mÃ¬nh vÃ´ cÃ¹ng pháº¥n khÃ­ch. VÃ­ dá»¥, bÃ i image captioning, mÃ¬nh cháº¡y vÃ  láº¥y ra caption cho cÃ¡i áº£nh tháº±ng báº¡n mÃ¬nh Ä‘ang ngá»“i Ä‘Ã¡nh Ä‘iá»‡n tá»­, sau Ä‘Ã³ mÃ¬nh gá»­i ngay cho máº¹ mÃ¬nh Ä‘á»ƒ khoe, máº¹ mÃ¬nh gá»­i cÃ¡i áº£nh kÃ¨m caption cho máº¹ tháº±ng báº¡n, máº¹ nÃ³ Ä‘Ã¡nh nÃ³ má»™t tráº­n, nÃ³ cÅ©ng cáº§m cÃ¡i áº£nh cÃ³ caption cho mÃ¬nh xem vÃ  khÃ´ng quÃªn kÃ¨m theo quáº£ Ä‘áº¥m cáº£m Æ¡n. Máº·c dÃ¹ miá»‡ng mÃ¬nh khÃ¡ Ä‘au sau quáº£ Ä‘áº¥m nhÆ°ng mÃ¬nh váº«n khÃ¡ vui vÃ  cá»‘ nhoáº»n miá»‡ng cÆ°á»i"" =)))
Author: Há»c Hiáº¿u
Viblo: https://viblo.asia/p/hanh-trinh-ai-cua-mot-sinh-vien-toi-m68Z0AVzlkG
1 bÃ i chia sáº» khÃ¡c cá»§a tÃ¡c giáº£ Nguyá»…n ThÃ nh Trung vá» con Ä‘Æ°á»ng theo Ä‘uá»•i AI: https://viblo.asia/p/con-duong-ai-cua-toi-XL6lADwpZek
MÃ¬nh Ä‘Ã£ tá»± há»c AI nhÆ° tháº¿ nÃ o? https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/479432823463778/
#viblo #Q12021 #machine_learning #deep_learning","HÃ nh trÃ¬nh AI cá»§a má»™t sinh viÃªn tá»“i https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/485380192869041/ 1 bÃ i viáº¿t khÃ¡ dÃ i vá» hÃ nh trÃ¬nh bÆ°á»›c chÃ¢n vÃ  theo Ä‘uá»•i AI (trÃ­ tuá»‡ nhÃ¢n táº¡o) cá»§a ... 1 báº¡n sinh viÃªn tá»“i. MÃ¬nh Ä‘á»c tháº¥y khÃ¡ thÃº vá»‹ vÃ  khÃ¡ vui :D Trong bÃ i tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p cÃ¡c dáº¥u má»‘c trÃªn con Ä‘Æ°á»ng há»c vÃ  lÃ m AI cá»§a mÃ¬nh. Tá»« nhá»¯ng bÆ°á»›c Ä‘áº§u Ä‘á»c blog ML cÆ¡ báº£n cá»§a a Tiá»‡p, blog DL cÆ¡ báº£n cá»§a a Tuáº¥n, láº§n thá»±c táº­p Ä‘áº§u tiÃªn, lÃªn lab nghiÃªn cá»©u vÃ  paper Ä‘áº§u tiÃªn,.... ""Blog trÃ¬nh bÃ y ráº¥t máº¡ch láº¡c, vÄƒn phong vÃ  cÃ¡c biáº¿n Ä‘á»•i cÅ©ng dá»… hiá»ƒu, vÃ  cÃ¡i hay ho Ä‘Ã³ lÃ  tá»« lÃºc tiáº¿p cáº­n kiáº¿n thá»©c Ä‘áº¿n káº¿t luáº­n váº«n ráº¥t logic. MÃ¬nh vui nháº¥t lÃ  lÃºc mÃ¬nh train vÃ  cháº¡y Ä‘Æ°á»£c vÃ­ dá»¥ xe tá»± lÃ¡i trong bÃ i CNN. Trong blog bÃ i nÃ o cÅ©ng cÃ³ code vÃ­ dá»¥, vÃ  má»—i láº§n cháº¡y cÃ¡c vÃ­ dá»¥ trá»±c quan lÃ m mÃ¬nh vÃ´ cÃ¹ng pháº¥n khÃ­ch. VÃ­ dá»¥, bÃ i image captioning, mÃ¬nh cháº¡y vÃ  láº¥y ra caption cho cÃ¡i áº£nh tháº±ng báº¡n mÃ¬nh Ä‘ang ngá»“i Ä‘Ã¡nh Ä‘iá»‡n tá»­, sau Ä‘Ã³ mÃ¬nh gá»­i ngay cho máº¹ mÃ¬nh Ä‘á»ƒ khoe, máº¹ mÃ¬nh gá»­i cÃ¡i áº£nh kÃ¨m caption cho máº¹ tháº±ng báº¡n, máº¹ nÃ³ Ä‘Ã¡nh nÃ³ má»™t tráº­n, nÃ³ cÅ©ng cáº§m cÃ¡i áº£nh cÃ³ caption cho mÃ¬nh xem vÃ  khÃ´ng quÃªn kÃ¨m theo quáº£ Ä‘áº¥m cáº£m Æ¡n. Máº·c dÃ¹ miá»‡ng mÃ¬nh khÃ¡ Ä‘au sau quáº£ Ä‘áº¥m nhÆ°ng mÃ¬nh váº«n khÃ¡ vui vÃ  cá»‘ nhoáº»n miá»‡ng cÆ°á»i"" =))) Author: Há»c Hiáº¿u Viblo: https://viblo.asia/p/hanh-trinh-ai-cua-mot-sinh-vien-toi-m68Z0AVzlkG 1 bÃ i chia sáº» khÃ¡c cá»§a tÃ¡c giáº£ Nguyá»…n ThÃ nh Trung vá» con Ä‘Æ°á»ng theo Ä‘uá»•i AI: https://viblo.asia/p/con-duong-ai-cua-toi-XL6lADwpZek MÃ¬nh Ä‘Ã£ tá»± há»c AI nhÆ° tháº¿ nÃ o? https://www.facebook.com/groups/VietnamAiLlinkSharing/permalink/479432823463778/",#viblo	#Q12021	#machine_learning	#deep_learning,,,,
"Halo anh chá»‹ <3
Hiá»‡n e Ä‘ang tÃ¬m hiá»ƒu sá»­ dá»¥ng Detectron2 cá»§a FaceBook.
NhÆ°ng Ä‘ang bá»‹ stuck chá»• labelImage. Em sá»­ dá»¥ng cÃ´ng cá»¥ labelme.
Äá»‹nh dáº¡ng khÃ´ng giÃ´ng bá»™ dataset cá»§a theo file Detectron2 Beginner's Tutorial.
Anh/chi nÃ o Ä‘Ã£ tá»«ng lÃ m cho em xin tips chuyá»ƒn data qua Ä‘Ãºng Ä‘á»‹nh dáº¡ng vá»›i áº¡.
Link :
github: https://github.com/facebookresearch/detectron2
Detectron2 Beginner's Tutorial : https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5
Data máº«u mÃ  FB sá»­ dá»¥ng : https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip
Tool Labelme : https://github.com/wkentaro/labelme",Halo anh chá»‹ <3 Hiá»‡n e Ä‘ang tÃ¬m hiá»ƒu sá»­ dá»¥ng Detectron2 cá»§a FaceBook. NhÆ°ng Ä‘ang bá»‹ stuck chá»• labelImage. Em sá»­ dá»¥ng cÃ´ng cá»¥ labelme. Äá»‹nh dáº¡ng khÃ´ng giÃ´ng bá»™ dataset cá»§a theo file Detectron2 Beginner's Tutorial. Anh/chi nÃ o Ä‘Ã£ tá»«ng lÃ m cho em xin tips chuyá»ƒn data qua Ä‘Ãºng Ä‘á»‹nh dáº¡ng vá»›i áº¡. Link : github: https://github.com/facebookresearch/detectron2 Detectron2 Beginner's Tutorial : https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5 Data máº«u mÃ  FB sá»­ dá»¥ng : https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip Tool Labelme : https://github.com/wkentaro/labelme,,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  náº¿u mÃ¬nh muá»‘n Ä‘em má»™t model ML lÃªn app thÃ¬ nÃªn viáº¿t API rá»“i request khi cáº§n hay xuáº¥t model ra tflite rá»“i incorperate nÃ³ vÃ o app luÃ´n áº¡
MÃ¬nh cáº£m Æ¡n",Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  náº¿u mÃ¬nh muá»‘n Ä‘em má»™t model ML lÃªn app thÃ¬ nÃªn viáº¿t API rá»“i request khi cáº§n hay xuáº¥t model ra tflite rá»“i incorperate nÃ³ vÃ o app luÃ´n áº¡ MÃ¬nh cáº£m Æ¡n,,,,,
Onward we match.,Onward we match.,,,,,
"ChÃ o cáº£ nhÃ 
MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n vá» chá»‘ng giáº£ máº¡o face. MÃ¬nh cÃ³ sá»­ dá»¥ng 1 model Ä‘Æ°á»£c train dataset casia-surf (Ä‘Æ°á»£c táº¡o tá»« camera intel realsense sr300). Vá» bá»™ dá»¯ liá»‡u nÃ y gá»“m 3 loáº¡i dá»¯ liá»‡u: rgb, depth , ir vÃ  áº£nh depth Ä‘Ã£ Ä‘Æ°á»£c convert thÃ nh áº£nh rgb 3 kÃªnh mÃ u. Vá» mÃ´ hÃ¬nh mÃ¬nh sá»­ dá»¥ng chá»‰ Ä‘Æ°á»£c training nguyÃªn trÃªn áº£nh depth . Sau Ä‘Ã³ mÃ¬nh test vá»›i camera intel realsense D435 thÃ¬ thu Ä‘Æ°á»£c káº¿t quáº£ ráº¥t tá»‡. MÃ¬nh Ä‘ang tháº¯c máº¯c váº¥n Ä‘á» cÃ³ thá»ƒ váº¥n Ä‘á» nhÆ° sau:
1, Viá»‡c convert áº£nh depth 16bit tá»« D435 thÃ nh color chÆ°a Ä‘Ãºng ==> dáº«n Ä‘áº¿n phÃ¢n phá»‘i depth khÃ¡c vá»›i casia-surf dataset. Vá» convert áº£nh depth sang rgb mÃ¬nh dÃ¹ng thÆ° viá»‡n pyrealsense2. MÃ¬nh cÃ³ thá»­ má»™t sá»‘ cÃ¡ch khÃ¡c nhÆ°ng váº«n khÃ´ng hiá»‡u quáº£.
2, CÃ³ thá»ƒ áº£nh depth thu tá»« camera d435 khÃ´ng thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c training vá»›i casia-surf dataset.
Ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ tá»« cáº£ nhÃ  :d :d :d
MÃ¬nh cÃ¡m Æ¡n","ChÃ o cáº£ nhÃ  MÃ¬nh Ä‘ang lÃ m bÃ i toÃ¡n vá» chá»‘ng giáº£ máº¡o face. MÃ¬nh cÃ³ sá»­ dá»¥ng 1 model Ä‘Æ°á»£c train dataset casia-surf (Ä‘Æ°á»£c táº¡o tá»« camera intel realsense sr300). Vá» bá»™ dá»¯ liá»‡u nÃ y gá»“m 3 loáº¡i dá»¯ liá»‡u: rgb, depth , ir vÃ  áº£nh depth Ä‘Ã£ Ä‘Æ°á»£c convert thÃ nh áº£nh rgb 3 kÃªnh mÃ u. Vá» mÃ´ hÃ¬nh mÃ¬nh sá»­ dá»¥ng chá»‰ Ä‘Æ°á»£c training nguyÃªn trÃªn áº£nh depth . Sau Ä‘Ã³ mÃ¬nh test vá»›i camera intel realsense D435 thÃ¬ thu Ä‘Æ°á»£c káº¿t quáº£ ráº¥t tá»‡. MÃ¬nh Ä‘ang tháº¯c máº¯c váº¥n Ä‘á» cÃ³ thá»ƒ váº¥n Ä‘á» nhÆ° sau: 1, Viá»‡c convert áº£nh depth 16bit tá»« D435 thÃ nh color chÆ°a Ä‘Ãºng ==> dáº«n Ä‘áº¿n phÃ¢n phá»‘i depth khÃ¡c vá»›i casia-surf dataset. Vá» convert áº£nh depth sang rgb mÃ¬nh dÃ¹ng thÆ° viá»‡n pyrealsense2. MÃ¬nh cÃ³ thá»­ má»™t sá»‘ cÃ¡ch khÃ¡c nhÆ°ng váº«n khÃ´ng hiá»‡u quáº£. 2, CÃ³ thá»ƒ áº£nh depth thu tá»« camera d435 khÃ´ng thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c training vá»›i casia-surf dataset. Ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ tá»« cáº£ nhÃ  :d :d :d MÃ¬nh cÃ¡m Æ¡n",,,,,
,nan,,,,,
Curve fitting in action :),Curve fitting in action :),,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Em xem trÃªn Group cÃ³ nhiá»u báº¡n khi cáº§n train model khÃ´ng cÃ³ chá»— Ä‘á»ƒ train: train PC thÃ¬ cháº­m, train COLAB thÃ¬ giá»›i háº¡n, mÃ¡y chá»§ thÃ¬ khÃ´ng cÃ³....
Em tháº¥y dá»‹ch vá»¥ thuÃª GPU nÃ y hay nÃªn lÃ m clip chia sáº» cÃ¹ng anh em newbie! Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c. Em xem trÃªn Group cÃ³ nhiá»u báº¡n khi cáº§n train model khÃ´ng cÃ³ chá»— Ä‘á»ƒ train: train PC thÃ¬ cháº­m, train COLAB thÃ¬ giá»›i háº¡n, mÃ¡y chá»§ thÃ¬ khÃ´ng cÃ³.... Em tháº¥y dá»‹ch vá»¥ thuÃª GPU nÃ y hay nÃªn lÃ m clip chia sáº» cÃ¹ng anh em newbie! Mong ad duyá»‡t bÃ i!",,,,,
"Má»i ngÆ°á»i cho em há»i:
Em Ä‘ang convert 1 model tá»« tf1 sang tf2, nhÆ°ng cÃ³ 1 module tf.contrib.slim em ko tÃ¬m ra cÃ¡ch chuyá»ƒn sang tf2 Ä‘c.
Má»i ngÆ°á»i ai cÃ³ cÃ¡ch nÃ o convert sang ko áº¡?","Má»i ngÆ°á»i cho em há»i: Em Ä‘ang convert 1 model tá»« tf1 sang tf2, nhÆ°ng cÃ³ 1 module tf.contrib.slim em ko tÃ¬m ra cÃ¡ch chuyá»ƒn sang tf2 Ä‘c. Má»i ngÆ°á»i ai cÃ³ cÃ¡ch nÃ o convert sang ko áº¡?",,,,,
"ChÃ o cÃ¡c bÃ¡c!
Em Ä‘ang lÃ m bÃ i toÃ¡n face anti-spoofing mÃ  gáº·p khÃ³ khÄƒn khÃ´ng kiáº¿m Ä‘Æ°á»£c dá»¯ liá»‡u.
Em cÃ³ nghiÃªn cá»©u vÃ  tháº¥y bá»™ MSU-USSA vÃ  CASIA-SURF khÃ¡ tá»‘t nhÆ°ng Ä‘á»ƒ táº£i vá» cáº§n cÃ³ chá»¯ kÃ½ cá»§a giÃ¡o sÆ°, cÃ¡i nÃ y em khÃ´ng cÃ³.
BÃ¡c nÃ o trong group cÃ³ cÃ¡c bá»™ dá»¯ liá»‡u nÃ y hoáº·c bá»™ dá»¯ liá»‡u khÃ¡c cho em xin vá»›i áº¡.
Äá»™i Æ¡n cÃ¡c bÃ¡c nhiá»u!","ChÃ o cÃ¡c bÃ¡c! Em Ä‘ang lÃ m bÃ i toÃ¡n face anti-spoofing mÃ  gáº·p khÃ³ khÄƒn khÃ´ng kiáº¿m Ä‘Æ°á»£c dá»¯ liá»‡u. Em cÃ³ nghiÃªn cá»©u vÃ  tháº¥y bá»™ MSU-USSA vÃ  CASIA-SURF khÃ¡ tá»‘t nhÆ°ng Ä‘á»ƒ táº£i vá» cáº§n cÃ³ chá»¯ kÃ½ cá»§a giÃ¡o sÆ°, cÃ¡i nÃ y em khÃ´ng cÃ³. BÃ¡c nÃ o trong group cÃ³ cÃ¡c bá»™ dá»¯ liá»‡u nÃ y hoáº·c bá»™ dá»¯ liá»‡u khÃ¡c cho em xin vá»›i áº¡. Äá»™i Æ¡n cÃ¡c bÃ¡c nhiá»u!",,,,,
"MÃ¬nh xin phÃ©p há»i má»™t cÃ¢u hÆ¡i ngoÃ i lá». MÃ¬nh muá»‘n viáº¿t má»™t pháº§n má»m test tiáº¿ng Anh, dá»¯ liá»‡u Ä‘áº§u vÃ o sáº½ lÃ  text, hÃ¬nh áº£nh, file nghe mp3 ( Ä‘á» cá»§a bÃ i test). Äáº§u ra sáº½ lÃ  káº¿t quáº£ lÃ m bÃ i dáº¡ng multiple choices, file viáº¿t cá»§a thÃ­ sinh vÃ  file nÃ³i cá»§a thÃ­ sinh. MÃ¬nh muá»‘n há»i lÃ  hiá»‡n táº¡i dÃ¹ng ngÃ´n ngá»¯ nÃ o sáº½ xá»­ lÃ½ nhá»¯ng cÃ´ng viá»‡c nhÆ° váº­y tá»‘t nháº¥t? MÃ¬nh cáº£m Æ¡n.","MÃ¬nh xin phÃ©p há»i má»™t cÃ¢u hÆ¡i ngoÃ i lá». MÃ¬nh muá»‘n viáº¿t má»™t pháº§n má»m test tiáº¿ng Anh, dá»¯ liá»‡u Ä‘áº§u vÃ o sáº½ lÃ  text, hÃ¬nh áº£nh, file nghe mp3 ( Ä‘á» cá»§a bÃ i test). Äáº§u ra sáº½ lÃ  káº¿t quáº£ lÃ m bÃ i dáº¡ng multiple choices, file viáº¿t cá»§a thÃ­ sinh vÃ  file nÃ³i cá»§a thÃ­ sinh. MÃ¬nh muá»‘n há»i lÃ  hiá»‡n táº¡i dÃ¹ng ngÃ´n ngá»¯ nÃ o sáº½ xá»­ lÃ½ nhá»¯ng cÃ´ng viá»‡c nhÆ° váº­y tá»‘t nháº¥t? MÃ¬nh cáº£m Æ¡n.",,,,,
"Em chÆ°a cÃ³ kiáº¿n thá»©c vá» ML vÃ  DL, em chá»‰ cÃ³ kiáº¿n thá»©c bÃªn Ä‘iá»‡n tá»­. Äá» tÃ i Ä‘a cá»§a em cÃ³ liÃªn quan Ä‘áº¿n anomaly detection. Em Ä‘ang muá»‘n tÃ¬m má»™t vÃ i sáº£n pháº©m sá»­ dá»¥ng thuáº­t toÃ¡n nÃ y trong cÃ¡c mÃ¡y cÃ´ng nghiá»‡p. Em cáº£m Æ¡n","Em chÆ°a cÃ³ kiáº¿n thá»©c vá» ML vÃ  DL, em chá»‰ cÃ³ kiáº¿n thá»©c bÃªn Ä‘iá»‡n tá»­. Äá» tÃ i Ä‘a cá»§a em cÃ³ liÃªn quan Ä‘áº¿n anomaly detection. Em Ä‘ang muá»‘n tÃ¬m má»™t vÃ i sáº£n pháº©m sá»­ dá»¥ng thuáº­t toÃ¡n nÃ y trong cÃ¡c mÃ¡y cÃ´ng nghiá»‡p. Em cáº£m Æ¡n",,,,,
"e Ä‘ang lÃ m app scan dá»¯ liá»‡u tá»« a4 cáº§n Ä‘á»“ chÃ­nh xÃ¡c cao rá»“i dÃ¹ng iron ocr xuáº¥t ra excel, má»i ngÆ°á»i cho e xin Ã­t thÃ´ng tin loáº¡i camera chuyÃªn dá»¥ng áº¡h ?? giÃ¡ táº§m 5tr Ä‘á»• láº¡i","e Ä‘ang lÃ m app scan dá»¯ liá»‡u tá»« a4 cáº§n Ä‘á»“ chÃ­nh xÃ¡c cao rá»“i dÃ¹ng iron ocr xuáº¥t ra excel, má»i ngÆ°á»i cho e xin Ã­t thÃ´ng tin loáº¡i camera chuyÃªn dá»¥ng áº¡h ?? giÃ¡ táº§m 5tr Ä‘á»• láº¡i",,,,,
"Xin chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m bÃ i toÃ¡n binary classification, cÃ³ 36 features nhÆ°ng Ä‘á»u lÃ  binary feature vÃ  pháº§n lá»›n cÃ¡c giÃ¡ trá»‹ lÃ  False. em Ä‘Ã£ thá»­ cÃ¡c classifier khÃ¡c nhau, nhÆ°ng káº¿t quáº£ Ä‘áº¡t khÃ¡ tháº¥p, táº§m 0.5641. Xin cÃ¡c Anh/Chá»‹/Em cho em lá»i khuyÃªn cho bÃ i toÃ¡n nÃ y áº¡. Em cáº£m Æ¡n","Xin chÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m bÃ i toÃ¡n binary classification, cÃ³ 36 features nhÆ°ng Ä‘á»u lÃ  binary feature vÃ  pháº§n lá»›n cÃ¡c giÃ¡ trá»‹ lÃ  False. em Ä‘Ã£ thá»­ cÃ¡c classifier khÃ¡c nhau, nhÆ°ng káº¿t quáº£ Ä‘áº¡t khÃ¡ tháº¥p, táº§m 0.5641. Xin cÃ¡c Anh/Chá»‹/Em cho em lá»i khuyÃªn cho bÃ i toÃ¡n nÃ y áº¡. Em cáº£m Æ¡n",,,,,
"CÃ³ ace nÃ o vá» lÃ m Ä‘á»“ng nghiá»‡p vá»›i em khÃ´ng áº¡?
Viá»‡n ToÃ¡n á»©ng dá»¥ng vÃ  Tin há»c tuyá»ƒn giáº£ng viÃªn trong cÃ¡c lÄ©nh vá»±c:
ToÃ¡n, ToÃ¡n á»©ng dá»¥ng (ToÃ¡n CÃ´ng nghiá»‡p, ToÃ¡n Kinh táº¿, ToÃ¡n TÃ i ChÃ­nh, ...)
XÃ¡c suáº¥t, Thá»‘ng kÃª, Khoa há»c dá»¯ liá»‡u, MÃ¡y há»c, TrÃ­ tuá»‡ nhÃ¢n táº¡o
Tá»‘i Æ°u, Váº­n trÃ¹ há»c (Operation Research), Ká»¹ thuáº­t cÃ´ng nghiá»‡p (Industrial Engineering)
Khoa há»c MÃ¡y tÃ­nh, Ká»¹ thuáº­t MÃ¡y tÃ­nh, Tin há»c
VÃ  cÃ¡c lÄ©nh vá»±c liÃªn quan khÃ¡c ...
MÃ´i trÆ°á»ng lÃ m viá»‡c vui váº», hÃ²a Ä‘á»“ng, lÆ°Æ¡ng thÃ¡ng khoáº£ng 20tr ++
Æ¯u tiÃªn tuyá»ƒn dá»¥ng cÃ¡c cÃ¡n bá»™ trÃ¬nh Ä‘á»™ tiáº¿n sÄ©, cÃ³ káº¿t quáº£ nghiÃªn cá»©u khoa há»c tá»‘t, cÃ³ kinh nghiá»‡m giáº£ng dáº¡y, thÃ nh tháº¡o ngoáº¡i ngá»¯, NgoÃ i ra Æ°u tiÃªn cÃ¡c ace cÃ³ sá»Ÿ thÃ­ch thá»ƒ dá»¥c thá»ƒ thao nhÆ° Ä‘Ã¡ bÃ³ng, cháº¡y bá»™, ham thÃ­ch vÄƒn nghá»‡ nhÆ° hÃ¡t karaoke, ...
---------
PS: Em cÃ³ lÆ°Æ¡ng thÃ¡ng khoáº£ng 40tr ++","CÃ³ ace nÃ o vá» lÃ m Ä‘á»“ng nghiá»‡p vá»›i em khÃ´ng áº¡? Viá»‡n ToÃ¡n á»©ng dá»¥ng vÃ  Tin há»c tuyá»ƒn giáº£ng viÃªn trong cÃ¡c lÄ©nh vá»±c: ToÃ¡n, ToÃ¡n á»©ng dá»¥ng (ToÃ¡n CÃ´ng nghiá»‡p, ToÃ¡n Kinh táº¿, ToÃ¡n TÃ i ChÃ­nh, ...) XÃ¡c suáº¥t, Thá»‘ng kÃª, Khoa há»c dá»¯ liá»‡u, MÃ¡y há»c, TrÃ­ tuá»‡ nhÃ¢n táº¡o Tá»‘i Æ°u, Váº­n trÃ¹ há»c (Operation Research), Ká»¹ thuáº­t cÃ´ng nghiá»‡p (Industrial Engineering) Khoa há»c MÃ¡y tÃ­nh, Ká»¹ thuáº­t MÃ¡y tÃ­nh, Tin há»c VÃ  cÃ¡c lÄ©nh vá»±c liÃªn quan khÃ¡c ... MÃ´i trÆ°á»ng lÃ m viá»‡c vui váº», hÃ²a Ä‘á»“ng, lÆ°Æ¡ng thÃ¡ng khoáº£ng 20tr ++ Æ¯u tiÃªn tuyá»ƒn dá»¥ng cÃ¡c cÃ¡n bá»™ trÃ¬nh Ä‘á»™ tiáº¿n sÄ©, cÃ³ káº¿t quáº£ nghiÃªn cá»©u khoa há»c tá»‘t, cÃ³ kinh nghiá»‡m giáº£ng dáº¡y, thÃ nh tháº¡o ngoáº¡i ngá»¯, NgoÃ i ra Æ°u tiÃªn cÃ¡c ace cÃ³ sá»Ÿ thÃ­ch thá»ƒ dá»¥c thá»ƒ thao nhÆ° Ä‘Ã¡ bÃ³ng, cháº¡y bá»™, ham thÃ­ch vÄƒn nghá»‡ nhÆ° hÃ¡t karaoke, ... --------- PS: Em cÃ³ lÆ°Æ¡ng thÃ¡ng khoáº£ng 40tr ++",,,,,
"[Help][Dá»¯ liá»‡u Python Ä‘á»c DB vÃ o RAM quÃ¡ nhiá»u] CÃ¢u há»i má»›i cá»§a em Ä‘Ã¢y áº¡, cÃ¢u há»i cÅ© em Ä‘Ã£ cáº­p nháº­t Ä‘Æ°a xuá»‘ng dÆ°á»›i.
Trong lÃºc lÃ m viá»‡c vá»›i python, em nháº­n tháº¥y lÃ  do Python load vÃ o RAM quÃ¡ nhiá»u. CÃ¡c bÆ°á»›c em lÃ m nhÆ° sau:
BÆ°á»›c 1: Query dá»¯ liá»‡u tá»« MongoDB (BÆ°á»›c nÃ y em xem thÃ¬ dá»¯ liá»‡u cáº£ báº£ng chá»‰ chiáº¿n 170MB)
BÆ°á»›c 2: Chuyá»ƒn cÃ¢u query thÃ nh list (LÃºc nÃ y RAM báº¯t Ä‘áº§u tÄƒng lÃªn ráº¥t nhiá»u do Python Ä‘á»c dá»¯ liá»‡u vÃ o RAM)
BÆ°á»›c 3: Chuyá»ƒn sang pandas dataframe
Hiá»‡n táº¡i em Ä‘Ã£ tÃ¬m ra Ä‘Æ°á»£c 2 solution lÃ :
1. Query tá»« MongoDB trÃªn Python Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ mong muá»‘n (NhÆ° váº­y em khÃ´ng cáº§n qua BÆ°á»›c 2 vÃ  3 nhÆ° á»Ÿ trÃªn em trÃ¬nh bÃ y)
2. Sá»­ dá»¥ng thÆ° viá»‡n vaex thay cho pandas
KhÃ´ng biáº¿t anh chá»‹ vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ tÆ° váº¥n giÃºp em solution nÃ o tá»‘i Æ°u hÆ¡n hay cÃ³ solution khÃ¡c tá»‘i Æ°u hÆ¡n khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u
===========================================
CÃ¢u há»i cÅ©: [Help][Äá»c dá»¯ liá»‡u tá»« MongoDB vÃ o Python chiáº¿m quÃ¡ nhiá»u RAM]
Em chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang lÃ m viá»‡c vá»›i dá»¯ liá»‡u trÃªn python. VÃ  em gáº·p má»™t váº¥n Ä‘á» lÃ  khi Ä‘á»c dá»¯ liá»‡u má»™t báº£ng trong MongoDB vÃ o Pandas DataFrame thÃ¬ tháº¥y bá»‹ chiáº¿m quÃ¡ nhiá»u RAM, dá»¯ liá»‡u cá»§a em cÃ³ khoáº£ng 10000 dÃ²ng thÃ¬ chiáº¿m gáº§n 3GB RAM.
KhÃ´ng biáº¿t cÃ³ anh/chá»‹ hay báº¡n nÃ o gáº·p trÆ°á»ng há»£p nÃ y chÆ°a? CÃ³ gÃ¬ cho em xin chÃºt kinh nghiá»‡m vá»›i áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","[Help][Dá»¯ liá»‡u Python Ä‘á»c DB vÃ o RAM quÃ¡ nhiá»u] CÃ¢u há»i má»›i cá»§a em Ä‘Ã¢y áº¡, cÃ¢u há»i cÅ© em Ä‘Ã£ cáº­p nháº­t Ä‘Æ°a xuá»‘ng dÆ°á»›i. Trong lÃºc lÃ m viá»‡c vá»›i python, em nháº­n tháº¥y lÃ  do Python load vÃ o RAM quÃ¡ nhiá»u. CÃ¡c bÆ°á»›c em lÃ m nhÆ° sau: BÆ°á»›c 1: Query dá»¯ liá»‡u tá»« MongoDB (BÆ°á»›c nÃ y em xem thÃ¬ dá»¯ liá»‡u cáº£ báº£ng chá»‰ chiáº¿n 170MB) BÆ°á»›c 2: Chuyá»ƒn cÃ¢u query thÃ nh list (LÃºc nÃ y RAM báº¯t Ä‘áº§u tÄƒng lÃªn ráº¥t nhiá»u do Python Ä‘á»c dá»¯ liá»‡u vÃ o RAM) BÆ°á»›c 3: Chuyá»ƒn sang pandas dataframe Hiá»‡n táº¡i em Ä‘Ã£ tÃ¬m ra Ä‘Æ°á»£c 2 solution lÃ : 1. Query tá»« MongoDB trÃªn Python Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ mong muá»‘n (NhÆ° váº­y em khÃ´ng cáº§n qua BÆ°á»›c 2 vÃ  3 nhÆ° á»Ÿ trÃªn em trÃ¬nh bÃ y) 2. Sá»­ dá»¥ng thÆ° viá»‡n vaex thay cho pandas KhÃ´ng biáº¿t anh chá»‹ vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ tÆ° váº¥n giÃºp em solution nÃ o tá»‘i Æ°u hÆ¡n hay cÃ³ solution khÃ¡c tá»‘i Æ°u hÆ¡n khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u =========================================== CÃ¢u há»i cÅ©: [Help][Äá»c dá»¯ liá»‡u tá»« MongoDB vÃ o Python chiáº¿m quÃ¡ nhiá»u RAM] Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang lÃ m viá»‡c vá»›i dá»¯ liá»‡u trÃªn python. VÃ  em gáº·p má»™t váº¥n Ä‘á» lÃ  khi Ä‘á»c dá»¯ liá»‡u má»™t báº£ng trong MongoDB vÃ o Pandas DataFrame thÃ¬ tháº¥y bá»‹ chiáº¿m quÃ¡ nhiá»u RAM, dá»¯ liá»‡u cá»§a em cÃ³ khoáº£ng 10000 dÃ²ng thÃ¬ chiáº¿m gáº§n 3GB RAM. KhÃ´ng biáº¿t cÃ³ anh/chá»‹ hay báº¡n nÃ o gáº·p trÆ°á»ng há»£p nÃ y chÆ°a? CÃ³ gÃ¬ cho em xin chÃºt kinh nghiá»‡m vá»›i áº¡, em cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» tensorflow. CÃ³ má»™t chá»— hÆ¡i khÃ³ hiá»ƒu muá»‘n nhá» má»i ngÆ°á»i giáº£i thÃ­ch há»™. Táº¡i sao cÃ¡i parameter cá»§a hÃ m classifier.train() láº¡i lÃ  function, mÃ  khÃ´ng pháº£i lÃ  giÃ¡ trá»‹ mÃ  function Ä‘Ã³ tráº£ vá»? (dÃ¹ng lambda cÃ³ nghÄ©a lÃ  tráº£ vá» function object)","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» tensorflow. CÃ³ má»™t chá»— hÆ¡i khÃ³ hiá»ƒu muá»‘n nhá» má»i ngÆ°á»i giáº£i thÃ­ch há»™. Táº¡i sao cÃ¡i parameter cá»§a hÃ m classifier.train() láº¡i lÃ  function, mÃ  khÃ´ng pháº£i lÃ  giÃ¡ trá»‹ mÃ  function Ä‘Ã³ tráº£ vá»? (dÃ¹ng lambda cÃ³ nghÄ©a lÃ  tráº£ vá» function object)",,,,,
"Hi cáº£ nhÃ ! Em Ä‘ang muá»‘n tÃ¬m hiá»ƒu vá» Logistic Regression (theory thÃ´i áº¡)
Do em cáº§n hiá»ƒu vÃ  present cho ngÆ°á»i khÃ¡c nÃªn em muá»‘n há»i nÃªn lÃ m tháº¿ nÃ o?",Hi cáº£ nhÃ ! Em Ä‘ang muá»‘n tÃ¬m hiá»ƒu vá» Logistic Regression (theory thÃ´i áº¡) Do em cáº§n hiá»ƒu vÃ  present cho ngÆ°á»i khÃ¡c nÃªn em muá»‘n há»i nÃªn lÃ m tháº¿ nÃ o?,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang há»c vá» Vaex nÃªn Ä‘Äƒng bÃ i Ä‘á»ƒ mong Ä‘Æ°á»£c chia sáº» láº¡i bÃ i note cá»§a em vá» Vaex cho cÃ¡c báº¡n newbie. Mong nháº­n Ä‘Æ°á»£c cÃ¡c gÃ³p Ã½ cá»§a cÃ¡c bÃ¡c vÃ  mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang há»c vá» Vaex nÃªn Ä‘Äƒng bÃ i Ä‘á»ƒ mong Ä‘Æ°á»£c chia sáº» láº¡i bÃ i note cá»§a em vá» Vaex cho cÃ¡c báº¡n newbie. Mong nháº­n Ä‘Æ°á»£c cÃ¡c gÃ³p Ã½ cá»§a cÃ¡c bÃ¡c vÃ  mong ad duyá»‡t bÃ i!",,,,,
"Eddited:
LÃ m Æ¡n cho em há»i
Em cÃ³ 4 nghiá»‡m: R,G,B (láº¥y tá»« Instagram image), vÃ  Instagram like
Em muá»‘n cháº¡y Ä‘á»ƒ xem máº§u nÃ o cÃ³ kháº£ nÄƒng nháº­n Ä‘Æ°á»£c nhiá»u like nháº¥t
Em cÃ³ Ä‘á»c qua paper nÃ y vÃ  Ä‘á»‹nh dÃ¹ng K-Mean clustering cho 3 máº§u RGB vÃ  sau Ä‘Ã³ cháº¡y Poisson regression vá»›i clusters vÃ  like.
https://www.researchgate.net/profile/Robertas-Damasevicius/publication/318697867_Brand_communication_in_social_media_The_use_of_image_colours_in_popular_posts/links/59b048360f7e9b374346614d/Brand-communication-in-social-media-The-use-of-image-colours-in-popular-posts.pdf
Em khÃ´ng rÃµ viá»‡c em lÃ m cÃ³ nghÄ©a khÃ´ng, em khÃ´ng rÃµ lÃ m sao Ä‘á»ƒ tÃ­nh probabilities cá»§a tá»«ng máº§u nhÆ° trong bÃ i bÃ¡o Ä‘Æ°á»£c?
Em cáº£m Æ¡n","Eddited: LÃ m Æ¡n cho em há»i Em cÃ³ 4 nghiá»‡m: R,G,B (láº¥y tá»« Instagram image), vÃ  Instagram like Em muá»‘n cháº¡y Ä‘á»ƒ xem máº§u nÃ o cÃ³ kháº£ nÄƒng nháº­n Ä‘Æ°á»£c nhiá»u like nháº¥t Em cÃ³ Ä‘á»c qua paper nÃ y vÃ  Ä‘á»‹nh dÃ¹ng K-Mean clustering cho 3 máº§u RGB vÃ  sau Ä‘Ã³ cháº¡y Poisson regression vá»›i clusters vÃ  like. https://www.researchgate.net/profile/Robertas-Damasevicius/publication/318697867_Brand_communication_in_social_media_The_use_of_image_colours_in_popular_posts/links/59b048360f7e9b374346614d/Brand-communication-in-social-media-The-use-of-image-colours-in-popular-posts.pdf Em khÃ´ng rÃµ viá»‡c em lÃ m cÃ³ nghÄ©a khÃ´ng, em khÃ´ng rÃµ lÃ m sao Ä‘á»ƒ tÃ­nh probabilities cá»§a tá»«ng máº§u nhÆ° trong bÃ i bÃ¡o Ä‘Æ°á»£c? Em cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i,
Phoenix Team xin chia sáº» láº¡i source code vÃ  solution chi tiáº¿t cá»§a nhÃ³m á»Ÿ challenge Cassava Leaf Disease Classification trÃªn Kaggle. Hy vá»ng bÃ i viáº¿t vÃ  pháº§n source code há»¯u Ã­ch Ä‘á»‘i vá»›i cÃ¡c báº¡n Ä‘ang tÃ¬m hiá»ƒu vá» ML/DL.
Link chia sáº» vá» solution: https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/221113
Link source code: https://github.com/freedom1810/kaggle-cassava
1. ThÃ´ng tin vá» challenge:
- Dáº¡ng bÃ i: Image Classification with strongly noisy labels.
- Káº¿t quáº£ cá»§a nhÃ³m: Top 16/3900 trÃªn private leaderboard, gold medal.
2. Má»™t sá»‘ Ä‘iá»ƒm nháº¥n trong solution cá»§a nhÃ³m:
- EMA.
- Splitting strategies.
- Bi-tempered loss.
- Snapmix augmentation.
- SAM optimizer.
3. CÃ¡c thÃ nh viÃªn trong team: Nguyá»…n Háº£i Nam - xSeries - FUNiX, Nguyen Hai Son - SV nÄƒm cuá»‘i ÄHBKHN - Asilla.
Phoenix Team cÅ©ng Ä‘ang phá»¥ trÃ¡ch Ä‘Ã o táº¡o toÃ n bá»™ nhÃ³m há»c viÃªn nháº­n há»c bá»•ng AI Engineer tá»« QAI - FPT SOFTWARE cá»§a FUNiX cÃ¹ng vá»›i cÃ¡c mentor khÃ¡c cá»§a FUNiX. Báº¡n nÃ o cÃ³ há»©ng thÃº vÃ o há»c vÃ  tham gia cÃ¡c challenge vá»›i mÃ¬nh thÃ¬ Ä‘Äƒng kÃ½ á»Ÿ link nÃ y nhÃ©:
https://docs.google.com/forms/d/e/1FAIpQLScScbmRhUbsRiBdAY_MX6BTFudjI8vJMY6RFb2Xv3jYZctJYg/viewform
Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i vÃ  xem code, hy vá»ng trong thá»i gian tá»›i sáº½ gáº·p Ä‘Æ°á»£c nhiá»u cÃ¡c báº¡n AI Engineer cá»§a Viá»‡t Nam trÃªn cÃ¡c challenge cá»§a tháº¿ giá»›i :)","ChÃ o má»i ngÆ°á»i, Phoenix Team xin chia sáº» láº¡i source code vÃ  solution chi tiáº¿t cá»§a nhÃ³m á»Ÿ challenge Cassava Leaf Disease Classification trÃªn Kaggle. Hy vá»ng bÃ i viáº¿t vÃ  pháº§n source code há»¯u Ã­ch Ä‘á»‘i vá»›i cÃ¡c báº¡n Ä‘ang tÃ¬m hiá»ƒu vá» ML/DL. Link chia sáº» vá» solution: https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/221113 Link source code: https://github.com/freedom1810/kaggle-cassava 1. ThÃ´ng tin vá» challenge: - Dáº¡ng bÃ i: Image Classification with strongly noisy labels. - Káº¿t quáº£ cá»§a nhÃ³m: Top 16/3900 trÃªn private leaderboard, gold medal. 2. Má»™t sá»‘ Ä‘iá»ƒm nháº¥n trong solution cá»§a nhÃ³m: - EMA. - Splitting strategies. - Bi-tempered loss. - Snapmix augmentation. - SAM optimizer. 3. CÃ¡c thÃ nh viÃªn trong team: Nguyá»…n Háº£i Nam - xSeries - FUNiX, Nguyen Hai Son - SV nÄƒm cuá»‘i ÄHBKHN - Asilla. Phoenix Team cÅ©ng Ä‘ang phá»¥ trÃ¡ch Ä‘Ã o táº¡o toÃ n bá»™ nhÃ³m há»c viÃªn nháº­n há»c bá»•ng AI Engineer tá»« QAI - FPT SOFTWARE cá»§a FUNiX cÃ¹ng vá»›i cÃ¡c mentor khÃ¡c cá»§a FUNiX. Báº¡n nÃ o cÃ³ há»©ng thÃº vÃ o há»c vÃ  tham gia cÃ¡c challenge vá»›i mÃ¬nh thÃ¬ Ä‘Äƒng kÃ½ á»Ÿ link nÃ y nhÃ©: https://docs.google.com/forms/d/e/1FAIpQLScScbmRhUbsRiBdAY_MX6BTFudjI8vJMY6RFb2Xv3jYZctJYg/viewform Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i vÃ  xem code, hy vá»ng trong thá»i gian tá»›i sáº½ gáº·p Ä‘Æ°á»£c nhiá»u cÃ¡c báº¡n AI Engineer cá»§a Viá»‡t Nam trÃªn cÃ¡c challenge cá»§a tháº¿ giá»›i :)",,,,,
"Em Ä‘ang lÃ m thá»­ 1 bÃ i toÃ¡n vá» Time series. Input lÃ  n arrays, má»—i array lÃ  1000 steps. Output mong muá»‘n lÃ  1 array vá»›i 1000 steps. Má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ lÃ m bÃ i toÃ¡n trÃªn Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n.","Em Ä‘ang lÃ m thá»­ 1 bÃ i toÃ¡n vá» Time series. Input lÃ  n arrays, má»—i array lÃ  1000 steps. Output mong muá»‘n lÃ  1 array vá»›i 1000 steps. Má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ lÃ m bÃ i toÃ¡n trÃªn Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cáº£m Æ¡n.",,,,,
Mn cho e há»i. E update sklearn vÃ  test code nhÆ°ng nÃ³ ra Ä‘oáº¡n nÃ y lÃ  sao áº¡?,Mn cho e há»i. E update sklearn vÃ  test code nhÆ°ng nÃ³ ra Ä‘oáº¡n nÃ y lÃ  sao áº¡?,,,,,
"Hi má»i ngÆ°á»i mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu bÃ i bÃ¡o khoa há»c vá» CVPR, cÃ³ pháº§n sau khÃ´ng hiá»ƒu táº¡i sao ra váº­y 
Chá»‰ sá»‘ Recall@50, Recall@100, mÃ¬nh chÆ°a hiá»ƒu nÃ³ lÃ  gÃ¬ & cÃ¡ch Ä‘Ã¡nh giÃ¡ cá»§a nÃ³ Ä‘á»ƒ ra Ä‘Æ°á»£c báº£ng káº¿t quáº£ nhÆ° váº­y
Predicate Recognition/Union Box Detection/Two Boxes Detection - Ã½ nghÄ©a vÃ  cÃ¡ch dÃ¹ng
Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp mÃ¬nh nhá»¯ng pháº§n nÃ y
CÃ¡m Æ¡n má»i ngÆ°á»i!

https://drive.google.com/file/d/1R2TpNmWT9PEOKchkZ_FzTHR0-FzSfaeT/view?usp=sharing","Hi má»i ngÆ°á»i mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu bÃ i bÃ¡o khoa há»c vá» CVPR, cÃ³ pháº§n sau khÃ´ng hiá»ƒu táº¡i sao ra váº­y Chá»‰ sá»‘ Recall@50, Recall@100, mÃ¬nh chÆ°a hiá»ƒu nÃ³ lÃ  gÃ¬ & cÃ¡ch Ä‘Ã¡nh giÃ¡ cá»§a nÃ³ Ä‘á»ƒ ra Ä‘Æ°á»£c báº£ng káº¿t quáº£ nhÆ° váº­y Predicate Recognition/Union Box Detection/Two Boxes Detection - Ã½ nghÄ©a vÃ  cÃ¡ch dÃ¹ng Mong má»i ngÆ°á»i giáº£i thÃ­ch giÃºp mÃ¬nh nhá»¯ng pháº§n nÃ y CÃ¡m Æ¡n má»i ngÆ°á»i! https://drive.google.com/file/d/1R2TpNmWT9PEOKchkZ_FzTHR0-FzSfaeT/view?usp=sharing",,,,,
"Báº¡n Chip Huyá»n sáº½ cÃ³ má»™t bÃ i thuyáº¿t trÃ¬nh trá»±c tuyáº¿n vá» ""Machine learning for scalable applications"" táº¡i #Online FOSSASIA Summit thÃ¡ng 3, 13-21. NgoÃ i ra cÃ²n cÃ³ Product Lead cá»§a PyTorch vÃ  ráº¥t nhiá»u ná»™i dung háº¥p dáº«n vá» #AI vÃ  #MachineLearning. Má»i cÃ¡c báº¡n Ä‘Äƒng kÃ½ tham gia miá»…n phÃ­ táº¡i Ä‘Ã¢y https://eventyay.com/e/fa96ae2c","Báº¡n Chip Huyá»n sáº½ cÃ³ má»™t bÃ i thuyáº¿t trÃ¬nh trá»±c tuyáº¿n vá» ""Machine learning for scalable applications"" táº¡i FOSSASIA Summit thÃ¡ng 3, 13-21. NgoÃ i ra cÃ²n cÃ³ Product Lead cá»§a PyTorch vÃ  ráº¥t nhiá»u ná»™i dung háº¥p dáº«n vá» vÃ  Má»i cÃ¡c báº¡n Ä‘Äƒng kÃ½ tham gia miá»…n phÃ­ táº¡i Ä‘Ã¢y https://eventyay.com/e/fa96ae2c",#Online	#AI	#MachineLearning.,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2020 vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 9/2020 vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
"ChÃ o má»i ngÆ°á»i, trÆ°á»›c Ä‘Ã¢y khi Ä‘á»¥ng pháº£i dataset khÃ´ng cÃ¢n báº±ng thÃ¬ ngoÃ i augment thÃªm hÃ¬nh, em cÅ©ng Ã¡p dá»¥ng ROC curve Ä‘á»ƒ tÃ¬m threshold tá»‘i Æ°u nháº¥t vÃ  luÃ´n cho r káº¿t quáº£ ráº¥t kháº£ quan.
NhÆ°ng láº§n nÃ y káº¿t quáº£ cÃ³ váº» tá»‡ hÆ¡n ban Ä‘áº§u má»™t chÃºt. Má»i ngÆ°á»i cho em há»i Ä‘Ã¢y cÃ³ pháº£i lÃ  do model váº«n chÆ°a Ä‘á»§ tá»‘t, hay hÆ°á»›ng tiáº¿p cáº­n ROC curve cho dataset nÃ y lÃ  sai áº¡? Vá»›i dataset máº¥t cÃ¢n báº±ng thÃ¬ cÃ²n cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ giáº£i quyáº¿t khÃ´ng áº¡?
p/s: hÃ¬nh Ä‘áº§u tiÃªn threshold máº·c Ä‘á»‹nh 0.5","ChÃ o má»i ngÆ°á»i, trÆ°á»›c Ä‘Ã¢y khi Ä‘á»¥ng pháº£i dataset khÃ´ng cÃ¢n báº±ng thÃ¬ ngoÃ i augment thÃªm hÃ¬nh, em cÅ©ng Ã¡p dá»¥ng ROC curve Ä‘á»ƒ tÃ¬m threshold tá»‘i Æ°u nháº¥t vÃ  luÃ´n cho r káº¿t quáº£ ráº¥t kháº£ quan. NhÆ°ng láº§n nÃ y káº¿t quáº£ cÃ³ váº» tá»‡ hÆ¡n ban Ä‘áº§u má»™t chÃºt. Má»i ngÆ°á»i cho em há»i Ä‘Ã¢y cÃ³ pháº£i lÃ  do model váº«n chÆ°a Ä‘á»§ tá»‘t, hay hÆ°á»›ng tiáº¿p cáº­n ROC curve cho dataset nÃ y lÃ  sai áº¡? Vá»›i dataset máº¥t cÃ¢n báº±ng thÃ¬ cÃ²n cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ giáº£i quyáº¿t khÃ´ng áº¡? p/s: hÃ¬nh Ä‘áº§u tiÃªn threshold máº·c Ä‘á»‹nh 0.5",,,,,
,nan,,,,,
"Xin chÃ o anh/chá»‹, em lÃ  sinh viÃªn Ä‘áº¡i há»c Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá» Ms Azure Kinect. Má»™t mÃ¬nh tá»± tÃ¬m hiá»ƒu hÆ¡i khÃ³ nÃªn ai cÃ³ há»©ng thÃº & am hiá»ƒu vá» nÃ³ cÃ³ thá»ƒ káº¿t báº¡n, cÃ¹ng tÃ¬m hiá»ƒu & chá»‰ thÃªm cho em áº¡. Em cáº£m Æ¡n!","Xin chÃ o anh/chá»‹, em lÃ  sinh viÃªn Ä‘áº¡i há»c Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vá» Ms Azure Kinect. Má»™t mÃ¬nh tá»± tÃ¬m hiá»ƒu hÆ¡i khÃ³ nÃªn ai cÃ³ há»©ng thÃº & am hiá»ƒu vá» nÃ³ cÃ³ thá»ƒ káº¿t báº¡n, cÃ¹ng tÃ¬m hiá»ƒu & chá»‰ thÃªm cho em áº¡. Em cáº£m Æ¡n!",,,,,
MoÌ£i ngÆ°Æ¡Ì€i cho miÌ€nh hoÌ‰i cÃ¢Ì€n hoÌ£c nhÆ°Ìƒng giÌ€ Ä‘ÃªÌ‰ coÌ Ä‘Æ°Æ¡Ì£c 1 cÃ´ng viÃªÌ£c Æ¡Ì‰ viÌ£ triÌ Data Engineer vÃ¢Ì£y ?,MoÌ£i ngÆ°Æ¡Ì€i cho miÌ€nh hoÌ‰i cÃ¢Ì€n hoÌ£c nhÆ°Ìƒng giÌ€ Ä‘ÃªÌ‰ coÌ Ä‘Æ°Æ¡Ì£c 1 cÃ´ng viÃªÌ£c Æ¡Ì‰ viÌ£ triÌ Data Engineer vÃ¢Ì£y ?,,,,,
"#MLNET
ChÃ o má»i ngÆ°á»i.
Hiá»‡n táº¡i mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu tháº±ng ML.NET mÃ¬nh Detect Ä‘Æ°á»£c Object rá»“i, nhÆ°ng lÃ m sao Ä‘á»ƒ nÃ³ dÃ¹ng GPU Ä‘á»ƒ Detect nhá»‰? MÃ¬nh Search tá»« hÃ´m qua Ä‘áº¿n giá» váº«n khÃ´ng cÃ³ bÃ i viáº¿t nÃ o nÃ³i váº¥n Ä‘á» nÃ y. CÃ¡c bÃ¡c cÃ³ ai lÃ m qua rá»“i thÃ¬ Support mÃ¬nh vá»›i.","ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu tháº±ng ML.NET mÃ¬nh Detect Ä‘Æ°á»£c Object rá»“i, nhÆ°ng lÃ m sao Ä‘á»ƒ nÃ³ dÃ¹ng GPU Ä‘á»ƒ Detect nhá»‰? MÃ¬nh Search tá»« hÃ´m qua Ä‘áº¿n giá» váº«n khÃ´ng cÃ³ bÃ i viáº¿t nÃ o nÃ³i váº¥n Ä‘á» nÃ y. CÃ¡c bÃ¡c cÃ³ ai lÃ m qua rá»“i thÃ¬ Support mÃ¬nh vá»›i.",#MLNET,,,,
"ChÃ o cÃ¡c báº¡n :) mÃ¬nh má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu AI ML DL â€¦ báº¡n nÃ o Ä‘Ã£ tÃ¬m hiá»ƒu qua cÃ³ thá»ƒ hÆ°á»›ng dáº«n vÃ  kÃ¨m cáº·p mÃ¬nh cÃ¡ch há»c, hÆ°á»›ng há»c vá»›i Ä‘Æ°á»£c khÃ´ng áº¡ ^_^ cÃ¡m Æ¡n cÃ¡c báº¡n quan tÃ¢m.","ChÃ o cÃ¡c báº¡n :) mÃ¬nh má»›i báº¯t Ä‘áº§u tÃ¬m hiá»ƒu AI ML DL â€¦ báº¡n nÃ o Ä‘Ã£ tÃ¬m hiá»ƒu qua cÃ³ thá»ƒ hÆ°á»›ng dáº«n vÃ  kÃ¨m cáº·p mÃ¬nh cÃ¡ch há»c, hÆ°á»›ng há»c vá»›i Ä‘Æ°á»£c khÃ´ng áº¡ ^_^ cÃ¡m Æ¡n cÃ¡c báº¡n quan tÃ¢m.",,,,,
"#deeplearning #efficientnet
Em bá»‹ khÃºc máº¯c khi train model nÃ y vá»›i táº­p data nhá» ( táº§m 1300 áº£nh) thÃ¬ hÃ m loss tá»‘i Æ°u giáº£m dáº§n.
NhÆ°ng khi lÃªn data to ( 33 000 áº£nh) thÃ¬ loss láº¡i khá»±ng láº¡i.
Má»i ngÆ°á»i chá»‰ ra váº¥n Ä‘á» giÃºp em vá»›i áº¡.
Cáº£m Æ¡n group",Em bá»‹ khÃºc máº¯c khi train model nÃ y vá»›i táº­p data nhá» ( táº§m 1300 áº£nh) thÃ¬ hÃ m loss tá»‘i Æ°u giáº£m dáº§n. NhÆ°ng khi lÃªn data to ( 33 000 áº£nh) thÃ¬ loss láº¡i khá»±ng láº¡i. Má»i ngÆ°á»i chá»‰ ra váº¥n Ä‘á» giÃºp em vá»›i áº¡. Cáº£m Æ¡n group,#deeplearning	#efficientnet,,,,
"Xin chÃ o cáº£ nhÃ , em lÃ  thÃ nh viÃªn má»›i cá»§a nhÃ³m, em Ä‘ang nghiÃªn cá»©u vá» kháº£ nÄƒng á»©ng dá»¥ng ML trong lÄ©nh vá»±c Ä‘á»‹nh vá»‹ dáº«n Ä‘Æ°á»ng thiáº¿t bá»‹ chuyá»ƒn Ä‘á»™ng trong thá»i gian thá»±c. Em cÃ³ má»™t cÃ¢u há»i ráº¥t mong cÃ¡c ace trong nhÃ³m cÃ³ thá»ƒ tráº£ lá»i giÃºp em áº¡:
Em Ä‘ang sá»­ dá»¥ng máº¡ng Extreme learning mahchine (ELM) Ä‘á»ƒ huáº¥n luyá»‡n má»™t máº¡ng thá»i gian thá»±c, Em dÃ¹ng hÃ m sigmoid lÃ  hÃ m kÃ­ch hoáº¡t cho khÃ¢u cuá»‘i cÃ¹ng cá»§a máº¡ng, do váº­y trÆ°á»›c khi Ä‘Æ°a vÃ o huáº¥n luyá»‡n máº¡ng thÃ¬ pháº§n dá»¯ liá»‡u cá»§a táº­p target em cáº§n pháº£i scale vá» miá»n giÃ¡ trá»‹ tá»« 0-1, do Ä‘Ã³ táº­p giÃ¡ trá»‹ trá»ng sá»‘ W thu Ä‘Æ°á»£c sau khi luyá»‡n sáº½ á»©ng vá»›i target lÃ  trong khoáº£ng 0-1. Váº­y khi chuyá»ƒn qua quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n náº¿u ta sá»­ dá»¥ng bá»™ trá»ng sá»‘ W thu Ä‘Æ°á»£c á»Ÿ trÃªn Ä‘á»ƒ dá»± Ä‘oÃ¡n Ä‘áº§u ra thÃ¬ giÃ¡ trá»‹ Ä‘áº§u ra cÅ©ng sáº½ náº±m trong miá»n giÃ¡ trá»‹ 0-1, váº­y lÃºc nÃ y lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh tráº£ vá» giÃ¡ trá»‹ Ä‘Ãºng cá»§a giÃ¡ trá»‹ Ä‘áº§u ra? ace nÃ o biáº¿t cÃ¡ch cÃ³ thá»ƒ giÃºp em cÃ¢u há»i nÃ y Ä‘Æ°á»£c khÃ´ng áº¡, em cÃ¡m Æ¡n ráº¥t nhiá»u áº¡","Xin chÃ o cáº£ nhÃ , em lÃ  thÃ nh viÃªn má»›i cá»§a nhÃ³m, em Ä‘ang nghiÃªn cá»©u vá» kháº£ nÄƒng á»©ng dá»¥ng ML trong lÄ©nh vá»±c Ä‘á»‹nh vá»‹ dáº«n Ä‘Æ°á»ng thiáº¿t bá»‹ chuyá»ƒn Ä‘á»™ng trong thá»i gian thá»±c. Em cÃ³ má»™t cÃ¢u há»i ráº¥t mong cÃ¡c ace trong nhÃ³m cÃ³ thá»ƒ tráº£ lá»i giÃºp em áº¡: Em Ä‘ang sá»­ dá»¥ng máº¡ng Extreme learning mahchine (ELM) Ä‘á»ƒ huáº¥n luyá»‡n má»™t máº¡ng thá»i gian thá»±c, Em dÃ¹ng hÃ m sigmoid lÃ  hÃ m kÃ­ch hoáº¡t cho khÃ¢u cuá»‘i cÃ¹ng cá»§a máº¡ng, do váº­y trÆ°á»›c khi Ä‘Æ°a vÃ o huáº¥n luyá»‡n máº¡ng thÃ¬ pháº§n dá»¯ liá»‡u cá»§a táº­p target em cáº§n pháº£i scale vá» miá»n giÃ¡ trá»‹ tá»« 0-1, do Ä‘Ã³ táº­p giÃ¡ trá»‹ trá»ng sá»‘ W thu Ä‘Æ°á»£c sau khi luyá»‡n sáº½ á»©ng vá»›i target lÃ  trong khoáº£ng 0-1. Váº­y khi chuyá»ƒn qua quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n náº¿u ta sá»­ dá»¥ng bá»™ trá»ng sá»‘ W thu Ä‘Æ°á»£c á»Ÿ trÃªn Ä‘á»ƒ dá»± Ä‘oÃ¡n Ä‘áº§u ra thÃ¬ giÃ¡ trá»‹ Ä‘áº§u ra cÅ©ng sáº½ náº±m trong miá»n giÃ¡ trá»‹ 0-1, váº­y lÃºc nÃ y lÃ m cÃ¡ch nÃ o Ä‘á»ƒ mÃ¬nh tráº£ vá» giÃ¡ trá»‹ Ä‘Ãºng cá»§a giÃ¡ trá»‹ Ä‘áº§u ra? ace nÃ o biáº¿t cÃ¡ch cÃ³ thá»ƒ giÃºp em cÃ¢u há»i nÃ y Ä‘Æ°á»£c khÃ´ng áº¡, em cÃ¡m Æ¡n ráº¥t nhiá»u áº¡",,,,,
"Hello cáº£ nhÃ .
Má»i ngÆ°á»i Ä‘Ã£ nghe nÃ³i tá»›i SOTA má»›i NFNets do DeepMind giá»›i thiá»‡u vá» image classification chÆ°a? (Link paper: https://arxiv.org/abs/2102.06171). NghiÃªn cá»©u má»›i nÃ y Ä‘Ã£ chá»‰ ra nhá»¯ng Ä‘iá»ƒm tá»‘t vÃ  háº¡n cháº¿ cá»§a BatchNorm, tá»« Ä‘Ã³ tiáº¿n tá»›i loáº¡i bá» nÃ³. DeepMind cÃ³ Ä‘á» xuáº¥t má»™t há» cÃ¡c models NFNets Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c tá»›i 86,5% acc top1 trÃªn imagenet, Ä‘Ã¡nh báº¡i EfficientNets vá» cáº£ Ä‘á»™ chÃ­nh xÃ¡c vÃ  thá»i gian.
MÃ¬nh cÃ³ implement nhá»¯ng models nÃ y báº±ng Tensorflow2 theo link dÆ°á»›i Ä‘Ã¢y. Báº¡n nÃ o cÃ³ mÃ¡y cáº¥u hÃ¬nh máº¡nh cÃ³ thá»ƒ thá»­ train thá»­ xem káº¿t quáº£ cuá»‘i cÃ¹ng ra sao, nháº¥t lÃ  máº¥y models náº·ng nháº¥t. Báº¡n nÃ o cÃ³ há»©ng thÃº cÃ³ thá»ƒ ib tháº£o luáº­n thÃªm hoáº·c trá»±c tiáº¿p pull requests/create issues, youâ€™re welcome.
https://github.com/hoangthang1607/nfnets-Tensorflow-2
Update: ThÃªm pre-trained weights converted tá»« bÃªn DeepMind.","Hello cáº£ nhÃ . Má»i ngÆ°á»i Ä‘Ã£ nghe nÃ³i tá»›i SOTA má»›i NFNets do DeepMind giá»›i thiá»‡u vá» image classification chÆ°a? (Link paper: https://arxiv.org/abs/2102.06171). NghiÃªn cá»©u má»›i nÃ y Ä‘Ã£ chá»‰ ra nhá»¯ng Ä‘iá»ƒm tá»‘t vÃ  háº¡n cháº¿ cá»§a BatchNorm, tá»« Ä‘Ã³ tiáº¿n tá»›i loáº¡i bá» nÃ³. DeepMind cÃ³ Ä‘á» xuáº¥t má»™t há» cÃ¡c models NFNets Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c tá»›i 86,5% acc top1 trÃªn imagenet, Ä‘Ã¡nh báº¡i EfficientNets vá» cáº£ Ä‘á»™ chÃ­nh xÃ¡c vÃ  thá»i gian. MÃ¬nh cÃ³ implement nhá»¯ng models nÃ y báº±ng Tensorflow2 theo link dÆ°á»›i Ä‘Ã¢y. Báº¡n nÃ o cÃ³ mÃ¡y cáº¥u hÃ¬nh máº¡nh cÃ³ thá»ƒ thá»­ train thá»­ xem káº¿t quáº£ cuá»‘i cÃ¹ng ra sao, nháº¥t lÃ  máº¥y models náº·ng nháº¥t. Báº¡n nÃ o cÃ³ há»©ng thÃº cÃ³ thá»ƒ ib tháº£o luáº­n thÃªm hoáº·c trá»±c tiáº¿p pull requests/create issues, youâ€™re welcome. https://github.com/hoangthang1607/nfnets-Tensorflow-2 Update: ThÃªm pre-trained weights converted tá»« bÃªn DeepMind.",,,,,
"Xin chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» DDPG trong reinforcement learning nhÆ°ng khÃ³ hiá»ƒu quÃ¡. CÃ³ anh chá»‹ nÃ o cÃ³ tai liÃªu dá»… hiá»ƒu xin giÃºp em vá»›i.
Xin cÃ¡m Æ¡n",Xin chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» DDPG trong reinforcement learning nhÆ°ng khÃ³ hiá»ƒu quÃ¡. CÃ³ anh chá»‹ nÃ o cÃ³ tai liÃªu dá»… hiá»ƒu xin giÃºp em vá»›i. Xin cÃ¡m Æ¡n,,,,,
"MÃ¬nh cÃ³ dá»‹ch ná»™i dung pháº§n #matrixfactorization dÃ nh cho #Recommendationsystem. CÃ³ nhiá»u chá»— mÃ¬nh hiá»ƒu vÃ  dá»‹ch (vÃ  Ä‘á»c láº¡i thÃ¬ váº«n hiá»ƒu vÃ¬ Ä‘Ã£ hiá»ƒu tá»« nghÄ©a tiáº¿ng Viá»‡t) nhÆ°ng ko cháº¯c lÃ  ngÆ°á»i khÃ¡c Ä‘á»c cÃ³ hiá»ƒu liá»n ko. Do Ä‘Ã³ mÃ¬nh post lÃªn sáºµn nhá» má»i ngÆ°á»i review vÃ  Ä‘Ã³ng gÃ³p Ã½ kiáº¿n.
CÃ¡m Æ¡n anh VÅ© Há»¯u Tiá»‡p Ä‘Ã£ cho phÃ©p em translate ná»™i dung.",MÃ¬nh cÃ³ dá»‹ch ná»™i dung pháº§n dÃ nh cho CÃ³ nhiá»u chá»— mÃ¬nh hiá»ƒu vÃ  dá»‹ch (vÃ  Ä‘á»c láº¡i thÃ¬ váº«n hiá»ƒu vÃ¬ Ä‘Ã£ hiá»ƒu tá»« nghÄ©a tiáº¿ng Viá»‡t) nhÆ°ng ko cháº¯c lÃ  ngÆ°á»i khÃ¡c Ä‘á»c cÃ³ hiá»ƒu liá»n ko. Do Ä‘Ã³ mÃ¬nh post lÃªn sáºµn nhá» má»i ngÆ°á»i review vÃ  Ä‘Ã³ng gÃ³p Ã½ kiáº¿n. CÃ¡m Æ¡n anh VÅ© Há»¯u Tiá»‡p Ä‘Ã£ cho phÃ©p em translate ná»™i dung.,#matrixfactorization	#Recommendationsystem.,,,,
"em chÃ o má»i ngÆ°á»i áº¡!
Anh/ chá»‹ vÃ  cÃ¡c báº¡n cho em há»i lÃ  google cÃ³ open source / giáº£i phÃ¡p nÃ o trong Data assessment áº¡ ?
Em cáº£m Æ¡n!",em chÃ o má»i ngÆ°á»i áº¡! Anh/ chá»‹ vÃ  cÃ¡c báº¡n cho em há»i lÃ  google cÃ³ open source / giáº£i phÃ¡p nÃ o trong Data assessment áº¡ ? Em cáº£m Æ¡n!,,,,,
"Giá»›i thiá»‡u VN AIDr (https://dr.vnopenai.org/) - Ná»n táº£ng xá»­ lÃ½ áº£nh y táº¿ nguá»“n má»Ÿ xÃ¢y dá»±ng bá»Ÿi cÃ¡c kÄ© sÆ° Viá»‡t Nam!
Chi tiáº¿t xin má»i ngÆ°á»i xem á»Ÿ link dÆ°á»›i.",Giá»›i thiá»‡u VN AIDr (https://dr.vnopenai.org/) - Ná»n táº£ng xá»­ lÃ½ áº£nh y táº¿ nguá»“n má»Ÿ xÃ¢y dá»±ng bá»Ÿi cÃ¡c kÄ© sÆ° Viá»‡t Nam! Chi tiáº¿t xin má»i ngÆ°á»i xem á»Ÿ link dÆ°á»›i.,,,,,
"I'd like to post this opening we have (if the group admin permits).
Our company Yaraku Inc (developing adaptive machine translation systems) is looking for DL/NLP researchers/engineers passionate about languages and interested in working on machine translation. We have an opening at Yaraku Inc's office in Tokyo.
https://www.linkedin.com/jobs/view/2380307850/
Languages we are interested in translating to/from include English, Vietnamese, Korean, Thai and Chinese.
I have been looking for Vietnamese NLP/DL professionals for a long time and have not been able to find them, so I was hoping to find referrals to suitable candidates here. Please note: the job requires a good knowledge of English and excellent Python programming and algorithms skills in addition to the ability to build DL models from scratch and a good NLP/MT academic background. The candidate will be working remotely from Vietnam till Covid is over but is then expected to join the team in Tokyo.
Please apply directly using the LinkedIn link if interested.","I'd like to post this opening we have (if the group admin permits). Our company Yaraku Inc (developing adaptive machine translation systems) is looking for DL/NLP researchers/engineers passionate about languages and interested in working on machine translation. We have an opening at Yaraku Inc's office in Tokyo. https://www.linkedin.com/jobs/view/2380307850/ Languages we are interested in translating to/from include English, Vietnamese, Korean, Thai and Chinese. I have been looking for Vietnamese NLP/DL professionals for a long time and have not been able to find them, so I was hoping to find referrals to suitable candidates here. Please note: the job requires a good knowledge of English and excellent Python programming and algorithms skills in addition to the ability to build DL models from scratch and a good NLP/MT academic background. The candidate will be working remotely from Vietnam till Covid is over but is then expected to join the team in Tokyo. Please apply directly using the LinkedIn link if interested.",,,,,
"Xin chÃ o má»i ngÆ°á»i, em lÃ  ngÆ°á»i má»›i há»c machine learning, em hiá»‡n Ä‘ang lÃ m má»™t dá»± Ã¡n vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho tiáº¿ng Viá»‡t, em lÃ m bÆ°á»›c word embedding dÃ¹ng fastText vÃ  word2vec trÃªn táº­p dá»¯ liá»‡u mÃ  em crawl tá»« facebook, nhÆ°ng mÃ  káº¿t quáº£ cá»§a em khÃ´ng Ä‘Æ°á»£c tá»‘t, em cÃ³ xem cÃ¡c bÃ i hÆ°á»›ng dáº«n khÃ¡c thÃ¬ há» báº£o xÃ¢y dá»±ng trÃªn dataset cá»§a bÃ¡c LÃª Há»“ng PhÆ°Æ¡ng thÃ¬ khÃ¡ tá»‘t mÃ  em khÃ´ng tÃ¬m Ä‘á»ƒ táº£i Ä‘Æ°á»£c, cÃ³ bÃ¡c nÃ o cÃ³ thÃ´ng tin vá» bá»™ dataset nÃ o thÃ¬ cho em xin Ä‘Æ°á»£c khÃ´ng áº¡, em xin cáº£m Æ¡n nhiá»u áº¡.","Xin chÃ o má»i ngÆ°á»i, em lÃ  ngÆ°á»i má»›i há»c machine learning, em hiá»‡n Ä‘ang lÃ m má»™t dá»± Ã¡n vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho tiáº¿ng Viá»‡t, em lÃ m bÆ°á»›c word embedding dÃ¹ng fastText vÃ  word2vec trÃªn táº­p dá»¯ liá»‡u mÃ  em crawl tá»« facebook, nhÆ°ng mÃ  káº¿t quáº£ cá»§a em khÃ´ng Ä‘Æ°á»£c tá»‘t, em cÃ³ xem cÃ¡c bÃ i hÆ°á»›ng dáº«n khÃ¡c thÃ¬ há» báº£o xÃ¢y dá»±ng trÃªn dataset cá»§a bÃ¡c LÃª Há»“ng PhÆ°Æ¡ng thÃ¬ khÃ¡ tá»‘t mÃ  em khÃ´ng tÃ¬m Ä‘á»ƒ táº£i Ä‘Æ°á»£c, cÃ³ bÃ¡c nÃ o cÃ³ thÃ´ng tin vá» bá»™ dataset nÃ o thÃ¬ cho em xin Ä‘Æ°á»£c khÃ´ng áº¡, em xin cáº£m Æ¡n nhiá»u áº¡.",,,,,
"Trong lÃºc Ä‘áº¡i dá»‹ch Covid-19 chÆ°a buÃ´ng tha nhÃ¢n loáº¡i dÃ¹ Ä‘Ã£ cÃ³ vaccine. á» Viá»‡t Nam, dá»‹ch COVID-19 cÅ©ng gÃ¢y ra nhiá»u tá»•n tháº¥t vá» ngÆ°á»i, kinh táº¿, Ä‘áº£o lá»™n cuá»™c sá»‘ng vá»‘n Ä‘Ã£ khÃ³ khÄƒn cá»§a nhiá»u ngÆ°á»i. CÃ¹ng chung tay, gÃ³p sá»©c Ä‘áº©y lÃ¹i Ä‘áº¡i dá»‹ch, nhÃ³m phÃ¡t triá»ƒn pháº§n má»m cá»§a Äáº¡i há»c Duy TÃ¢n Ä‘Ã£ phÃ¡t triá»ƒn cÃ´ng cá»¥ cháº©n Ä‘oÃ¡n dá»±a trÃªn X Quang vÃ  CT phá»•i cÃ¡c tÃ¡c nhÃ¢n gÃ¢y viÃªm phá»•i lÃ  COVID-19, Lao phá»•i, viÃªm phá»•i do tÃ¡c nhÃ¢n khÃ¡c vÃ  áº£nh phá»•i bÃ¬nh thÆ°á»ng táº¡i Ä‘Ã¢y","Trong lÃºc Ä‘áº¡i dá»‹ch Covid-19 chÆ°a buÃ´ng tha nhÃ¢n loáº¡i dÃ¹ Ä‘Ã£ cÃ³ vaccine. á» Viá»‡t Nam, dá»‹ch COVID-19 cÅ©ng gÃ¢y ra nhiá»u tá»•n tháº¥t vá» ngÆ°á»i, kinh táº¿, Ä‘áº£o lá»™n cuá»™c sá»‘ng vá»‘n Ä‘Ã£ khÃ³ khÄƒn cá»§a nhiá»u ngÆ°á»i. CÃ¹ng chung tay, gÃ³p sá»©c Ä‘áº©y lÃ¹i Ä‘áº¡i dá»‹ch, nhÃ³m phÃ¡t triá»ƒn pháº§n má»m cá»§a Äáº¡i há»c Duy TÃ¢n Ä‘Ã£ phÃ¡t triá»ƒn cÃ´ng cá»¥ cháº©n Ä‘oÃ¡n dá»±a trÃªn X Quang vÃ  CT phá»•i cÃ¡c tÃ¡c nhÃ¢n gÃ¢y viÃªm phá»•i lÃ  COVID-19, Lao phá»•i, viÃªm phá»•i do tÃ¡c nhÃ¢n khÃ¡c vÃ  áº£nh phá»•i bÃ¬nh thÆ°á»ng táº¡i Ä‘Ã¢y",,,,,
"Em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n Invalid traffic classification.
VÃ­ dá»¥ trong má»™t chiáº¿n dá»‹ch quáº£ng cÃ¡o cÃ³ nhá»¯ng ngÆ°á»i click vÃ o, Invalid traffic sáº½ bao gá»“m vÃ´ tÃ¬nh báº¥m vÃ  cá»‘ tÃ¬nh báº§m(click farm)
Dá»¯ liá»‡u bao gá»“m nhÆ° hÃ¬nh.
CÃ¡c bÃ¡c cÃ³ Ã½ tÆ°á»Ÿng hay tá»«ng lÃ m bÃ i toÃ¡n nÃ y cho em xin tham kháº£o Ã½ tÆ°á»Ÿng áº¡. VÃ¬ nhÃ¬n vÃ o dá»¯ liá»‡u, em hiá»‡n táº¡i chÆ°a cÃ³ Ã½ tÆ°á»Ÿng :(","Em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n Invalid traffic classification. VÃ­ dá»¥ trong má»™t chiáº¿n dá»‹ch quáº£ng cÃ¡o cÃ³ nhá»¯ng ngÆ°á»i click vÃ o, Invalid traffic sáº½ bao gá»“m vÃ´ tÃ¬nh báº¥m vÃ  cá»‘ tÃ¬nh báº§m(click farm) Dá»¯ liá»‡u bao gá»“m nhÆ° hÃ¬nh. CÃ¡c bÃ¡c cÃ³ Ã½ tÆ°á»Ÿng hay tá»«ng lÃ m bÃ i toÃ¡n nÃ y cho em xin tham kháº£o Ã½ tÆ°á»Ÿng áº¡. VÃ¬ nhÃ¬n vÃ o dá»¯ liá»‡u, em hiá»‡n táº¡i chÆ°a cÃ³ Ã½ tÆ°á»Ÿng :(",,,,,
"mng cho e há»i sao w láº¡i lÃ  dáº¥u cá»™ng mÃ  khÃ´ng pháº£i dáº¥u trá»« v áº¡,
link:https://machinelearningcoban.com/2017/01/27/logisticregression/","mng cho e há»i sao w láº¡i lÃ  dáº¥u cá»™ng mÃ  khÃ´ng pháº£i dáº¥u trá»« v áº¡, link:https://machinelearningcoban.com/2017/01/27/logisticregression/",,,,,
"Marketing á»©ng dá»¥ng TrÃ­ Tuá»‡ NhÃ¢n Táº¡o (AI) nhÆ° tháº¿ nÃ o?
#AI #Marketing #MachineLearning #DeepLearning",Marketing á»©ng dá»¥ng TrÃ­ Tuá»‡ NhÃ¢n Táº¡o (AI) nhÆ° tháº¿ nÃ o?,#AI	#Marketing	#MachineLearning	#DeepLearning,,,,
"Tá»•ng há»£p giá»ng nÃ³i Ä‘Ã£ xuáº¥t hiá»‡n lÃ¢u rá»“i, nhÆ°ng náº¿u báº¡n muá»‘n mÃ y mÃ² viáº¿t chÆ°Æ¡ng trÃ¬nh python Ä‘á»c vÄƒn báº£n tiáº¿ng Viá»‡t dá»±a trÃªn cÃ¡c thÆ° viá»‡n Ä‘Ã£ cÃ³?
TÃ i liá»‡u lÆ°á»£m láº·t!","Tá»•ng há»£p giá»ng nÃ³i Ä‘Ã£ xuáº¥t hiá»‡n lÃ¢u rá»“i, nhÆ°ng náº¿u báº¡n muá»‘n mÃ y mÃ² viáº¿t chÆ°Æ¡ng trÃ¬nh python Ä‘á»c vÄƒn báº£n tiáº¿ng Viá»‡t dá»±a trÃªn cÃ¡c thÆ° viá»‡n Ä‘Ã£ cÃ³? TÃ i liá»‡u lÆ°á»£m láº·t!",,,,,
,nan,,,,,
"Em xin phÃ©p chia sáº» má»™t dá»± Ã¡n AI cho sá»©c khoáº» trong mÃ¹a dá»‹ch COVID: Äáº¿m sá»‘ hÃ­t Ä‘áº¥t trong luyá»‡n táº­p thá»ƒ thao.
Dá»± Ã¡n nÃ y má»›i á»Ÿ má»©c sÆ¡ khai, chÆ°a hoÃ n thiá»‡n. NhÃ³m em hi vá»ng cÃ³ thá»ƒ chia sáº» Ã½ tÆ°á»Ÿng vÃ  baseline Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng nhau hoÃ n thiá»‡n nÃ³ thÃ nh má»™t sáº£n pháº©m há»¯u Ã­ch cho ngÆ°á»i dÃ¹ng.
https://www.facebook.com/aicurious/posts/180473117203551","Em xin phÃ©p chia sáº» má»™t dá»± Ã¡n AI cho sá»©c khoáº» trong mÃ¹a dá»‹ch COVID: Äáº¿m sá»‘ hÃ­t Ä‘áº¥t trong luyá»‡n táº­p thá»ƒ thao. Dá»± Ã¡n nÃ y má»›i á»Ÿ má»©c sÆ¡ khai, chÆ°a hoÃ n thiá»‡n. NhÃ³m em hi vá»ng cÃ³ thá»ƒ chia sáº» Ã½ tÆ°á»Ÿng vÃ  baseline Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng nhau hoÃ n thiá»‡n nÃ³ thÃ nh má»™t sáº£n pháº©m há»¯u Ã­ch cho ngÆ°á»i dÃ¹ng. https://www.facebook.com/aicurious/posts/180473117203551",,,,,
"Má»i nguá»i cho em há»i vá»›i áº¡
Em Ä‘Ã£ train xong model vÃ  truá»›c Ä‘Ã³ em cÃ³ dÃ¹ng pd.get_dummies() cho táº­p X_test, giá» em muá»‘n model em predict má»™t single record Ä‘Ã£ xá»­ lÃ½ qua pd.get_dummies() nhÆ°ng nÃ³ cho ra Ã­t column hÆ¡n so vá»›i X_test, váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ kháº¯c phá»¥c áº¡, hoáº·c cÃ³ nhá»¯ng kÄ© thuáº­t nÃ o khÃ¡c Ä‘á»ƒ Ä‘Æ°a má»™t single record vÃ o Ä‘á»ƒ predict áº¡. Em cáº£m Æ¡n cÃ¡c bÃ¡c !","Má»i nguá»i cho em há»i vá»›i áº¡ Em Ä‘Ã£ train xong model vÃ  truá»›c Ä‘Ã³ em cÃ³ dÃ¹ng pd.get_dummies() cho táº­p X_test, giá» em muá»‘n model em predict má»™t single record Ä‘Ã£ xá»­ lÃ½ qua pd.get_dummies() nhÆ°ng nÃ³ cho ra Ã­t column hÆ¡n so vá»›i X_test, váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ kháº¯c phá»¥c áº¡, hoáº·c cÃ³ nhá»¯ng kÄ© thuáº­t nÃ o khÃ¡c Ä‘á»ƒ Ä‘Æ°a má»™t single record vÃ o Ä‘á»ƒ predict áº¡. Em cáº£m Æ¡n cÃ¡c bÃ¡c !",,,,,
"Hi má»i ngÆ°á»i, em Ä‘ang cÃ³ Ã½ Ä‘á»‹nh build má»™t ML model báº±ng C++ nhÆ°ng khÃ´ng biáº¿t cÃ³ thÆ° viá»‡n nÃ o cá»§a C++ chuyÃªn dÃ¹ng cho data visualization vÃ  algebra khÃ´ng. Mong cÃ¡c anh chá»‹ recommend giÃºp em áº¡. Em cÃ¡m Æ¡n má»i ngÆ°á»i.","Hi má»i ngÆ°á»i, em Ä‘ang cÃ³ Ã½ Ä‘á»‹nh build má»™t ML model báº±ng C++ nhÆ°ng khÃ´ng biáº¿t cÃ³ thÆ° viá»‡n nÃ o cá»§a C++ chuyÃªn dÃ¹ng cho data visualization vÃ  algebra khÃ´ng. Mong cÃ¡c anh chá»‹ recommend giÃºp em áº¡. Em cÃ¡m Æ¡n má»i ngÆ°á»i.",,,,,
"Dataset: Oulu-CASIA NIR&VIS.
MÃ¬nh xin chia sáº½ bá»™ dataset vá» cáº£m xÃºc khuÃ´n máº·t Oulu-CASIA NIR&VIS.
Dataset bao gá»“m 80 chá»§ thá»ƒ (people) )Ä‘Æ°á»£c quay bá»Ÿi 2 loáº¡i camera (Near Infrared vÃ  Camera thÆ°á»ng), má»—i camera quay dÆ°á»›i 3 Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau: Ã¡nh sÃ¡ng thÆ°á»ng, Ã¡nh sÃ¡ng yáº¿u (chá»‰ má»Ÿ má»—i mÃ n hÃ¬nh PC) vÃ  trÆ°á»ng há»£p tá»‘i (táº¯t háº¿t Ä‘Ã¨n).
Má»—i chá»§ thá»ƒ cÃ³ 6 cáº£m xÃºc.
Link download: https://drive.google.com/file/d/1UvAFqc6GIgpMd7wkEvFqNHGvwG0jA2Y4/view?usp=sharing
Source: download tá»« Baidu.","Dataset: Oulu-CASIA NIR&VIS. MÃ¬nh xin chia sáº½ bá»™ dataset vá» cáº£m xÃºc khuÃ´n máº·t Oulu-CASIA NIR&VIS. Dataset bao gá»“m 80 chá»§ thá»ƒ (people) )Ä‘Æ°á»£c quay bá»Ÿi 2 loáº¡i camera (Near Infrared vÃ  Camera thÆ°á»ng), má»—i camera quay dÆ°á»›i 3 Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau: Ã¡nh sÃ¡ng thÆ°á»ng, Ã¡nh sÃ¡ng yáº¿u (chá»‰ má»Ÿ má»—i mÃ n hÃ¬nh PC) vÃ  trÆ°á»ng há»£p tá»‘i (táº¯t háº¿t Ä‘Ã¨n). Má»—i chá»§ thá»ƒ cÃ³ 6 cáº£m xÃºc. Link download: https://drive.google.com/file/d/1UvAFqc6GIgpMd7wkEvFqNHGvwG0jA2Y4/view?usp=sharing Source: download tá»« Baidu.",,,,,
"Em chÃ o cÃ¡c anh chá»‹,
Em Ä‘ang lÃ m má»™t sá»‘ cÃ¢u quiz vá» confusion matrix. Em cÃ³ 1 sá»‘ cÃ¢u há»i sau:
1. TrÆ°á»›c Ä‘Ã¢y em hay chá»n ngÆ°á»¡ng Ä‘á»ƒ phÃ¢n predict label lÃ  0.5, hÃ´m nay em Ä‘á»c 1 bÃ i báº£o nÃªn chá»n ngÆ°á»¡ng mÃ  cÃ³ giÃ¡ trá»‹ F1 cao nháº¥t. Äiá»u nÃ y cÃ³ Ä‘Ãºng ko áº¡?
2. Em Ä‘Ã£ Ä‘á»c tÃ i liá»‡u nhÆ°ng ko hiá»ƒu rÃµ khi nÃ o dÃ¹ng f1score vá»›i average='macro' thÃ¬ há»£p lÃ½. Em thÆ°á»ng thá»­ vá»›i average='binary'.
3. Vá»›i 2 hÃ¬nh nhÆ° dÆ°á»›i, hÃ¬nh pháº£i thÃ¬ cÃ³ F1 score cao hÆ¡n nhÆ°ng TPR tháº¥p hÆ¡n, mÃ¬nh chá»n cÃ³ á»•n ko áº¡.
ÄÃ¢y lÃ  hÃ¬nh minh hoáº¡ nÃªn F1 score cáº£ 2 hÃ¬nh Ä‘á»u tháº¥p áº¡.
Xin cÃ¡m Æ¡n cÃ¡c anh chá»‹ chá»‰ giÃ¡o.","Em chÃ o cÃ¡c anh chá»‹, Em Ä‘ang lÃ m má»™t sá»‘ cÃ¢u quiz vá» confusion matrix. Em cÃ³ 1 sá»‘ cÃ¢u há»i sau: 1. TrÆ°á»›c Ä‘Ã¢y em hay chá»n ngÆ°á»¡ng Ä‘á»ƒ phÃ¢n predict label lÃ  0.5, hÃ´m nay em Ä‘á»c 1 bÃ i báº£o nÃªn chá»n ngÆ°á»¡ng mÃ  cÃ³ giÃ¡ trá»‹ F1 cao nháº¥t. Äiá»u nÃ y cÃ³ Ä‘Ãºng ko áº¡? 2. Em Ä‘Ã£ Ä‘á»c tÃ i liá»‡u nhÆ°ng ko hiá»ƒu rÃµ khi nÃ o dÃ¹ng f1score vá»›i average='macro' thÃ¬ há»£p lÃ½. Em thÆ°á»ng thá»­ vá»›i average='binary'. 3. Vá»›i 2 hÃ¬nh nhÆ° dÆ°á»›i, hÃ¬nh pháº£i thÃ¬ cÃ³ F1 score cao hÆ¡n nhÆ°ng TPR tháº¥p hÆ¡n, mÃ¬nh chá»n cÃ³ á»•n ko áº¡. ÄÃ¢y lÃ  hÃ¬nh minh hoáº¡ nÃªn F1 score cáº£ 2 hÃ¬nh Ä‘á»u tháº¥p áº¡. Xin cÃ¡m Æ¡n cÃ¡c anh chá»‹ chá»‰ giÃ¡o.",,,,,
"[Äáº¶T TRÆ¯á»šC] Báº£n dá»‹ch cuá»‘n Interpretable Machine Learning (Há»c mÃ¡y kháº£ diá»…n giáº£i)

ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘Ã£ tá»«ng kÃªu gá»i xÃ¢y dá»±ng nhÃ³m dá»‹ch cuá»‘n Interpretable Machine Learning nhÆ° hÃ¬nh dÆ°á»›i. Sau gáº§n 8 thÃ¡ng hoáº¡t Ä‘á»™ng liÃªn tá»¥c, nhÃ³m dá»‹ch gá»“m 2 dá»‹ch giáº£ chÃ­nh lÃ  mÃ¬nh (Giang Nguyen - KAIST) vÃ  Duy-Tung Nguyen (University of Missouri) dá»± kiáº¿n sáº½ release báº£n dá»‹ch cá»§a cuá»‘n sÃ¡ch vÃ o giá»¯a thÃ¡ng 2/2021. Táº¡i version Ä‘áº§u tiÃªn cá»§a cuá»‘n sÃ¡ch, nhÃ³m sáº½ chá»‰ gá»­i ra ÄÃšNG 200 báº£n vÃ  hoÃ n toÃ n FREE. Náº¿u báº¡n muá»‘n nháº­n báº£n dá»‹ch hÃ£y Ä‘á»ƒ láº¡i Ä‘á»‹a chá»‰ email dÆ°á»›i comment vÃ  nhÃ³m sáº½ gá»­i thÃ´ng tin cÅ©ng nhÆ° báº£n dá»‹ch cá»§a cuá»‘n sÃ¡ch cho báº¡n vÃ o giá»¯a thÃ¡ng sau.

CÃ¡m Æ¡n vÃ  chÃºc cÃ¡c báº¡n há»c vui váº»!
 â€” vá»›i Nguyá»…n TÃ¹ng.","[Äáº¶T TRÆ¯á»šC] Báº£n dá»‹ch cuá»‘n Interpretable Machine Learning (Há»c mÃ¡y kháº£ diá»…n giáº£i) ChÃ o cÃ¡c báº¡n, mÃ¬nh Ä‘Ã£ tá»«ng kÃªu gá»i xÃ¢y dá»±ng nhÃ³m dá»‹ch cuá»‘n Interpretable Machine Learning nhÆ° hÃ¬nh dÆ°á»›i. Sau gáº§n 8 thÃ¡ng hoáº¡t Ä‘á»™ng liÃªn tá»¥c, nhÃ³m dá»‹ch gá»“m 2 dá»‹ch giáº£ chÃ­nh lÃ  mÃ¬nh (Giang Nguyen - KAIST) vÃ  Duy-Tung Nguyen (University of Missouri) dá»± kiáº¿n sáº½ release báº£n dá»‹ch cá»§a cuá»‘n sÃ¡ch vÃ o giá»¯a thÃ¡ng 2/2021. Táº¡i version Ä‘áº§u tiÃªn cá»§a cuá»‘n sÃ¡ch, nhÃ³m sáº½ chá»‰ gá»­i ra ÄÃšNG 200 báº£n vÃ  hoÃ n toÃ n FREE. Náº¿u báº¡n muá»‘n nháº­n báº£n dá»‹ch hÃ£y Ä‘á»ƒ láº¡i Ä‘á»‹a chá»‰ email dÆ°á»›i comment vÃ  nhÃ³m sáº½ gá»­i thÃ´ng tin cÅ©ng nhÆ° báº£n dá»‹ch cá»§a cuá»‘n sÃ¡ch cho báº¡n vÃ o giá»¯a thÃ¡ng sau. CÃ¡m Æ¡n vÃ  chÃºc cÃ¡c báº¡n há»c vui váº»! â€” vá»›i Nguyá»…n TÃ¹ng.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang há»c vá» machine learning vÃ  Ä‘ang train má»™t model vá» food detection. Em cÃ³ sá»­ dá»¥ng data set á»Ÿ kaggle vÃ  sá»­ dá»¥ng pre-trained model : EfficientNetB0. Code em Ä‘á»ƒ link táº¡i Ä‘Ã¢y: https://www.kaggle.com/quynhngo7075/efficientnetb0-training
Sau khi nhÃ¬n vÃ o model thÃ¬ model cá»§a em bá»‹ overfitting (val_accurency tháº¥p nhÆ°ng train_accurency cao). Em Ä‘Ã£ thá»­ Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p data augmentation vÃ  add thÃªm dropout layers (vá»›i drop out rate = 0.2) nhÆ°ng accurency khÃ´ng Ä‘Æ°á»£c improve.
KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ cao kiáº¿n gÃ¬ Ä‘á»ƒ em cÃ³ thá»ƒ tÄƒng accurency lÃªn khÃ´ng áº¡ ? Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u
Edit láº§n 1:
ChÃ o má»i ngÆ°á»i láº§n ná»¯a áº¡, lá»i Ä‘áº§u tiÃªn cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ gÃ³p Ã½ kiáº¿n cÅ©ng nhÆ° chá»‰ ra nhá»¯ng lá»—i sai trong model cá»§a em.
Sau vÃ i ngÃ y chá»‰nh sá»­a, accuracy Ä‘Ã£ tÄƒng lÃªn Ä‘áº¿n 80% vÃ  Ä‘Æ°á»›i Ä‘Ã¢y lÃ  link code sau khi em Ä‘Ã£ chá»‰nh sá»­a Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o áº¡.
https://www.kaggle.com/quynhngo7075/efficientnetb0-training","Em chÃ o má»i ngÆ°á»i áº¡. Em Ä‘ang há»c vá» machine learning vÃ  Ä‘ang train má»™t model vá» food detection. Em cÃ³ sá»­ dá»¥ng data set á»Ÿ kaggle vÃ  sá»­ dá»¥ng pre-trained model : EfficientNetB0. Code em Ä‘á»ƒ link táº¡i Ä‘Ã¢y: https://www.kaggle.com/quynhngo7075/efficientnetb0-training Sau khi nhÃ¬n vÃ o model thÃ¬ model cá»§a em bá»‹ overfitting (val_accurency tháº¥p nhÆ°ng train_accurency cao). Em Ä‘Ã£ thá»­ Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p data augmentation vÃ  add thÃªm dropout layers (vá»›i drop out rate = 0.2) nhÆ°ng accurency khÃ´ng Ä‘Æ°á»£c improve. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ cao kiáº¿n gÃ¬ Ä‘á»ƒ em cÃ³ thá»ƒ tÄƒng accurency lÃªn khÃ´ng áº¡ ? Em cáº£m Æ¡n má»i ngÆ°á»i nhiá»u Edit láº§n 1: ChÃ o má»i ngÆ°á»i láº§n ná»¯a áº¡, lá»i Ä‘áº§u tiÃªn cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ gÃ³p Ã½ kiáº¿n cÅ©ng nhÆ° chá»‰ ra nhá»¯ng lá»—i sai trong model cá»§a em. Sau vÃ i ngÃ y chá»‰nh sá»­a, accuracy Ä‘Ã£ tÄƒng lÃªn Ä‘áº¿n 80% vÃ  Ä‘Æ°á»›i Ä‘Ã¢y lÃ  link code sau khi em Ä‘Ã£ chá»‰nh sá»­a Ä‘á»ƒ má»i ngÆ°á»i tham kháº£o áº¡. https://www.kaggle.com/quynhngo7075/efficientnetb0-training",,,,,
"Baidu Team Introduces ERNIE-M: A Multilingual Model that Learns 96 Languages from Monolingual Corpora
Paper Summary: https://www.marktechpost.com/2021/02/12/baidu-team-introduces-ernie-m-a-multilingual-model-that-learns-96-languages-from-monolingual-corpora/
Paper: https://arxiv.org/abs/2012.15674",Baidu Team Introduces ERNIE-M: A Multilingual Model that Learns 96 Languages from Monolingual Corpora Paper Summary: https://www.marktechpost.com/2021/02/12/baidu-team-introduces-ernie-m-a-multilingual-model-that-learns-96-languages-from-monolingual-corpora/ Paper: https://arxiv.org/abs/2012.15674,,,,,
"Náº¯ng Ä‘áº¹p mÃ¹ng 2 Táº¿t TÃ¢n Sá»­u 2021....
#share
ChÃºc anh chá»‹ em Ä‘ang Ä‘Ã£ vÃ  sáº½ tham gia nghá» phÃ¢n tÃ­ch dá»¯ liá»‡u, xá»­ lÃ½ dá»¯ liá»‡u, táº¡o á»©ng dá»¥ng ra quyáº¿t Ä‘á»‹nh thÃ´ng minh má»™t nÄƒm 2021 sá»©c khoáº» thÃ nh cÃ´ng!","Náº¯ng Ä‘áº¹p mÃ¹ng 2 Táº¿t TÃ¢n Sá»­u 2021.... ChÃºc anh chá»‹ em Ä‘ang Ä‘Ã£ vÃ  sáº½ tham gia nghá» phÃ¢n tÃ­ch dá»¯ liá»‡u, xá»­ lÃ½ dá»¯ liá»‡u, táº¡o á»©ng dá»¥ng ra quyáº¿t Ä‘á»‹nh thÃ´ng minh má»™t nÄƒm 2021 sá»©c khoáº» thÃ nh cÃ´ng!",#share,,,,
"LÃ m Æ¡n cho em há»i, em mÆ¡i há»c vÃ  Ä‘ang cá»‘ lÃ m mÃ´ hÃ¬nh Gan Ä‘á»ƒ dá»±ng láº¡i mÄƒt ngÆ°á»i cho image size 64 cÃ³ máº§u:
Input shape = (5299, 64, 64, 3) tá»« function load_read_samples() nhÆ°ng khi em Ä‘Ãºt vÃ o model thÃ¬ nÃ³ bá»‹ reshape thÃ nh (1, 5299, 64, 64) vÃ  bá»‹ throw lá»—i nhÆ° sau:
ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 32768 but received input with shape (1, 173604864)
WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='conv2d_3_input'), name='conv2d_3_input', description=""created by layer 'conv2d_3_input'""), but it was called on an input with incompatible shape (1, 5298, 64, 64, 3).
Em Ä‘Ã£ check láº¡i upscale and downscale layer vÃ  search google nhÆ°ng váº«n khÃ´ng biáº¿t sai á»Ÿ Ä‘Ã¢u. LÃ m Æ¡n giÃºp em vá»›i.
ÄÃ¢y lÃ  model em Ä‘ang lamf:
def define_discriminator(in_shape=(64,64,3)):
model = Sequential()
# downsample
model.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape))
model.add(LeakyReLU(alpha=0.2))
# downsample
model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))
model.add(LeakyReLU(alpha=0.2))
# classifier
model.add(Flatten())
model.add(Dropout(0.4))
model.add(Dense(1, activation='sigmoid'))
# compile model
opt = Adam(lr=0.0002, beta_1=0.5)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
return model
def define_generator(latent_dim):
model = Sequential()
# foundation for 7x7 image
n_nodes = 512 * 8 * 8
model.add(Dense(n_nodes, input_dim=latent_dim))
model.add(LeakyReLU(alpha=0.2))
model.add(Reshape((8, 8, 512)))
model.add(Conv2DTranspose(512, (4,4), strides=(2,2), padding='same'))
model.add(LeakyReLU(alpha=0.2))
model.add(Conv2DTranspose(512, (4,4), strides=(2,2), padding='same'))
model.add(LeakyReLU(alpha=0.2))
model.add(Conv2DTranspose(512, (4,4), strides=(2,2), padding='same'))
model.add(LeakyReLU(alpha=0.2))
# generate
model.add(Conv2D(3, (8,8), activation='tanh', padding='same'))
return model
def define_gan(generator, discriminator):
# make weights in the discriminator not trainable
discriminator.trainable = False
# connect them
model = Sequential()
# add generator
model.add(generator)
# add the discriminator
model.add(discriminator)
# compile model
opt = Adam(lr=0.0002, beta_1=0.5)
model.compile(loss='binary_crossentropy', optimizer=opt)
return model
# load fashion mnist images
def load_real_samples(path, size=(64,64)):
data_list = list()
# enumerate filenames in directory, assume all are images
for filename in listdir(path):
pixels = load_img(path + filename, target_size=size)
pixels = img_to_array(pixels)
data_list.append(pixels)
return asarray(data_list)

# def load_real_samples():
# # load dataset
# (trainX, _), (_, _) = load_data()
# # expand to 3d, e.g. add channels
# X = expand_dims(trainX, axis=-1)
# # convert from ints to floats
# X = X.astype('float32')
# # scale from [0,255] to [-1,1]
# X = (X - 127.5) / 127.5
# return X
# select real samples
def generate_real_samples(dataset, n_samples):
# choose random instances
ix = randint(0, 5298, n_samples).any()
# select images
X = dataset[ix]
# generate class labels
y = ones((n_samples, 1))
return X, y
# generate points in latent space as input for the generator
def generate_latent_points(latent_dim, n_samples):
# generate points in the latent space
x_input = randn(latent_dim * n_samples)
# reshape into a batch of inputs for the network
x_input = x_input.reshape(n_samples, latent_dim)
return x_input
# use the generator to generate n fake examples, with class labels
def generate_fake_samples(generator, latent_dim, n_samples):
# generate points in latent space
x_input = generate_latent_points(latent_dim, n_samples)
# predict outputs
X = generator.predict(x_input)
# create class labels
y = zeros((n_samples, 1))
return X, y
# train the generator and discriminator
def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=2):
bat_per_epo = int(5298 // n_batch)
half_batch = int(n_batch / 2)
# manually enumerate epochs
for i in range(n_epochs):
# enumerate batches over the training set
for j in range(bat_per_epo):
# get randomly selected 'real' samples
X_real, y_real = generate_real_samples(dataset, half_batch)
# update discriminator model weights
d_loss1, _ = d_model.train_on_batch(X_real, y_real)
# generate 'fake' examples
X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)
# update discriminator model weights
d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)
# prepare points in latent space as input for the generator
X_gan = generate_latent_points(latent_dim, n_batch)
# create inverted labels for the fake samples
y_gan = ones((n_batch, 1))
# update the generator via the discriminator's error
g_loss = gan_model.train_on_batch(X_gan, y_gan)
# summarize loss on this batch
print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %
(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))
# save the generator model
g_model.save('generator.h5')
# size of the latent space
latent_dim = 100
# create the discriminator
discriminator = define_discriminator()
# create the generator
generator = define_generator(latent_dim)
# create the gan
gan_model = define_gan(generator, discriminator)
# load image data
dataset = load_real_samples(dir)
# train model
train(generator, discriminator, gan_model, dataset, latent_dim)","LÃ m Æ¡n cho em há»i, em mÆ¡i há»c vÃ  Ä‘ang cá»‘ lÃ m mÃ´ hÃ¬nh Gan Ä‘á»ƒ dá»±ng láº¡i mÄƒt ngÆ°á»i cho image size 64 cÃ³ máº§u: Input shape = (5299, 64, 64, 3) tá»« function load_read_samples() nhÆ°ng khi em Ä‘Ãºt vÃ o model thÃ¬ nÃ³ bá»‹ reshape thÃ nh (1, 5299, 64, 64) vÃ  bá»‹ throw lá»—i nhÆ° sau: ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 32768 but received input with shape (1, 173604864) WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='conv2d_3_input'), name='conv2d_3_input', description=""created by layer 'conv2d_3_input'""), but it was called on an input with incompatible shape (1, 5298, 64, 64, 3). Em Ä‘Ã£ check láº¡i upscale and downscale layer vÃ  search google nhÆ°ng váº«n khÃ´ng biáº¿t sai á»Ÿ Ä‘Ã¢u. LÃ m Æ¡n giÃºp em vá»›i. ÄÃ¢y lÃ  model em Ä‘ang lamf: def define_discriminator(in_shape=(64,64,3)): model = Sequential() # downsample model.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape)) model.add(LeakyReLU(alpha=0.2)) # downsample model.add(Conv2D(128, (3,3), strides=(2,2), padding='same')) model.add(LeakyReLU(alpha=0.2)) # classifier model.add(Flatten()) model.add(Dropout(0.4)) model.add(Dense(1, activation='sigmoid')) # compile model opt = Adam(lr=0.0002, beta_1=0.5) model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) return model def define_generator(latent_dim): model = Sequential() # foundation for 7x7 image n_nodes = 512 * 8 * 8 model.add(Dense(n_nodes, input_dim=latent_dim)) model.add(LeakyReLU(alpha=0.2)) model.add(Reshape((8, 8, 512))) model.add(Conv2DTranspose(512, (4,4), strides=(2,2), padding='same')) model.add(LeakyReLU(alpha=0.2)) model.add(Conv2DTranspose(512, (4,4), strides=(2,2), padding='same')) model.add(LeakyReLU(alpha=0.2)) model.add(Conv2DTranspose(512, (4,4), strides=(2,2), padding='same')) model.add(LeakyReLU(alpha=0.2)) # generate model.add(Conv2D(3, (8,8), activation='tanh', padding='same')) return model def define_gan(generator, discriminator): # make weights in the discriminator not trainable discriminator.trainable = False # connect them model = Sequential() # add generator model.add(generator) # add the discriminator model.add(discriminator) # compile model opt = Adam(lr=0.0002, beta_1=0.5) model.compile(loss='binary_crossentropy', optimizer=opt) return model # load fashion mnist images def load_real_samples(path, size=(64,64)): data_list = list() # enumerate filenames in directory, assume all are images for filename in listdir(path): pixels = load_img(path + filename, target_size=size) pixels = img_to_array(pixels) data_list.append(pixels) return asarray(data_list) # def load_real_samples(): # # load dataset # (trainX, _), (_, _) = load_data() # # expand to 3d, e.g. add channels # X = expand_dims(trainX, axis=-1) # # convert from ints to floats # X = X.astype('float32') # # scale from [0,255] to [-1,1] # X = (X - 127.5) / 127.5 # return X # select real samples def generate_real_samples(dataset, n_samples): # choose random instances ix = randint(0, 5298, n_samples).any() # select images X = dataset[ix] # generate class labels y = ones((n_samples, 1)) return X, y # generate points in latent space as input for the generator def generate_latent_points(latent_dim, n_samples): # generate points in the latent space x_input = randn(latent_dim * n_samples) # reshape into a batch of inputs for the network x_input = x_input.reshape(n_samples, latent_dim) return x_input # use the generator to generate n fake examples, with class labels def generate_fake_samples(generator, latent_dim, n_samples): # generate points in latent space x_input = generate_latent_points(latent_dim, n_samples) # predict outputs X = generator.predict(x_input) # create class labels y = zeros((n_samples, 1)) return X, y # train the generator and discriminator def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=2): bat_per_epo = int(5298 // n_batch) half_batch = int(n_batch / 2) # manually enumerate epochs for i in range(n_epochs): # enumerate batches over the training set for j in range(bat_per_epo): # get randomly selected 'real' samples X_real, y_real = generate_real_samples(dataset, half_batch) # update discriminator model weights d_loss1, _ = d_model.train_on_batch(X_real, y_real) # generate 'fake' examples X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch) # update discriminator model weights d_loss2, _ = d_model.train_on_batch(X_fake, y_fake) # prepare points in latent space as input for the generator X_gan = generate_latent_points(latent_dim, n_batch) # create inverted labels for the fake samples y_gan = ones((n_batch, 1)) # update the generator via the discriminator's error g_loss = gan_model.train_on_batch(X_gan, y_gan) # summarize loss on this batch print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss)) # save the generator model g_model.save('generator.h5') # size of the latent space latent_dim = 100 # create the discriminator discriminator = define_discriminator() # create the generator generator = define_generator(latent_dim) # create the gan gan_model = define_gan(generator, discriminator) # load image data dataset = load_real_samples(dir) # train model train(generator, discriminator, gan_model, dataset, latent_dim)",,,,,
"[Student scholarship for AAMAS 2021] Dear all, AAMAS is one of the top-tier annual conferences in artificial intelligence. This year it will be virtual and therefore anyone from the world can attend online. There's a student scholarship scheme that allows students to attend the whole conference for free!! See the attached link below for more details.
The deadline is tomorrow (12 Febr). So I strongly encourage you to apply. It's a very good opportunity to attend a top-tier conference for free. We have so much funding + sponsorship so basically we can approve any application - but you need to apply on time!! It's quite, simple, you just need to fill an online form.
University faculty members: Please forward this message to your students and ask them to apply asap (the form asks you to be a PhD student, but MSc + undergrad students can also apply).
Looking forward to seeing you at the conference.","[Student scholarship for AAMAS 2021] Dear all, AAMAS is one of the top-tier annual conferences in artificial intelligence. This year it will be virtual and therefore anyone from the world can attend online. There's a student scholarship scheme that allows students to attend the whole conference for free!! See the attached link below for more details. The deadline is tomorrow (12 Febr). So I strongly encourage you to apply. It's a very good opportunity to attend a top-tier conference for free. We have so much funding + sponsorship so basically we can approve any application - but you need to apply on time!! It's quite, simple, you just need to fill an online form. University faculty members: Please forward this message to your students and ask them to apply asap (the form asks you to be a PhD student, but MSc + undergrad students can also apply). Looking forward to seeing you at the conference.",,,,,
,nan,,,,,
"Má»Ÿ Ä‘áº§u nÄƒm má»›i báº±ng 1 bÃ i viáº¿t má»›i, chÃºc báº¡n Ä‘á»c nÄƒm má»›i váº¡n sá»± nhÆ° Ã½
#Crawler","Má»Ÿ Ä‘áº§u nÄƒm má»›i báº±ng 1 bÃ i viáº¿t má»›i, chÃºc báº¡n Ä‘á»c nÄƒm má»›i váº¡n sá»± nhÆ° Ã½",#Crawler,,,,
"Má»™t báº¡n há»c PhD á»Ÿ Canada Ä‘á»c blog Machine Learning cÆ¡ báº£n tháº¥y thÃº vá»‹ Ä‘Ã£ dá»‹ch má»™t sá»‘ bÃ i ra tiáº¿ng Anh Ä‘á»ƒ chia sáº» vá»›i cÃ¡c báº¡n trong lab.
MÃ¬nh xin chia sáº» láº¡i á»Ÿ Ä‘Ã¢y. Báº£n nÃ y trÃ¬nh bÃ y cÃ²n Ä‘áº¹p hÆ¡n báº£n gá»‘c.
https://techsharing21.com/system-design/recommendation-system-basic-concepts
https://techsharing21.com/system-design/collaborative-filtering-an-introduction
ChÃºc má»«ng nÄƒm má»›i.",Má»™t báº¡n há»c PhD á»Ÿ Canada Ä‘á»c blog Machine Learning cÆ¡ báº£n tháº¥y thÃº vá»‹ Ä‘Ã£ dá»‹ch má»™t sá»‘ bÃ i ra tiáº¿ng Anh Ä‘á»ƒ chia sáº» vá»›i cÃ¡c báº¡n trong lab. MÃ¬nh xin chia sáº» láº¡i á»Ÿ Ä‘Ã¢y. Báº£n nÃ y trÃ¬nh bÃ y cÃ²n Ä‘áº¹p hÆ¡n báº£n gá»‘c. https://techsharing21.com/system-design/recommendation-system-basic-concepts https://techsharing21.com/system-design/collaborative-filtering-an-introduction ChÃºc má»«ng nÄƒm má»›i.,,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡h.
Em má»›i há»c Ä‘Æ°á»£c hai thÃ¡ng, xong supersived trÃªn coursera. LÃªn hiá»ƒu biáº¿t cÃ²n háº¡n cháº¿, nÃ´ng cáº¡n. Em cÃ³ Ä‘á»c hands on báº£n tiáº¿ng anh vÃ  vÃ i bÃ i bÃ¡o vá» cÃ´ng nghá»‡ nÃ y nhÆ°ng do má»—i bÃ i má»—i thuáº­t toÃ¡n khÃ¡c nhau. Em cÃ³ cÃ¢u há»i mong muá»‘n má»i ngÆ°á»i Ä‘Ã³ng gÃ³p Ã½ kiáº¿n áº¡h. Em chÃ¢n thÃ nh cáº£m Æ¡n áº¡h ( háº¡n cuá»‘i cá»§a em ná»™p cho manager cÃ²n gáº§n thÃ¡ng ná»¯a :(( )
* BÃ i toÃ¡n: nháº­n diá»‡n cá»­ chá»‰ ( gesture recognization) chuyá»‡n Ä‘á»™ng váº­t lÃ½ cá»§a bÃ n tay Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i mÃ n hÃ¬nh mÃ  khÃ´ng cáº§n cháº¡m
* Class: 4 ( quoÃ©t trÃ¡i, quoÃ©t pháº£i, vuá»‘t lÃªn, vuá»‘t xuá»‘ng)
* Tá»•ng sá»‘ máº«u: khoáº£ng 4000
* feature: 5
Em nÃªn dÃ¹ng thuáº­t toÃ¡n toÃ¡n nÃ o cho bÃ i toÃ¡n trÃªn áº¡h.
Em nÃªn dÃ¹ng phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh nÃ o cho bÃ i toÃ¡n trÃªn áº¡h.","Xin chÃ o má»i ngÆ°á»i áº¡h. Em má»›i há»c Ä‘Æ°á»£c hai thÃ¡ng, xong supersived trÃªn coursera. LÃªn hiá»ƒu biáº¿t cÃ²n háº¡n cháº¿, nÃ´ng cáº¡n. Em cÃ³ Ä‘á»c hands on báº£n tiáº¿ng anh vÃ  vÃ i bÃ i bÃ¡o vá» cÃ´ng nghá»‡ nÃ y nhÆ°ng do má»—i bÃ i má»—i thuáº­t toÃ¡n khÃ¡c nhau. Em cÃ³ cÃ¢u há»i mong muá»‘n má»i ngÆ°á»i Ä‘Ã³ng gÃ³p Ã½ kiáº¿n áº¡h. Em chÃ¢n thÃ nh cáº£m Æ¡n áº¡h ( háº¡n cuá»‘i cá»§a em ná»™p cho manager cÃ²n gáº§n thÃ¡ng ná»¯a :(( ) * BÃ i toÃ¡n: nháº­n diá»‡n cá»­ chá»‰ ( gesture recognization) chuyá»‡n Ä‘á»™ng váº­t lÃ½ cá»§a bÃ n tay Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i mÃ n hÃ¬nh mÃ  khÃ´ng cáº§n cháº¡m * Class: 4 ( quoÃ©t trÃ¡i, quoÃ©t pháº£i, vuá»‘t lÃªn, vuá»‘t xuá»‘ng) * Tá»•ng sá»‘ máº«u: khoáº£ng 4000 * feature: 5 Em nÃªn dÃ¹ng thuáº­t toÃ¡n toÃ¡n nÃ o cho bÃ i toÃ¡n trÃªn áº¡h. Em nÃªn dÃ¹ng phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh nÃ o cho bÃ i toÃ¡n trÃªn áº¡h.",,,,,
"mÃ¬nh Ä‘ang lÃ m 1 Ä‘á» tÃ i vá» NILM (phÃ¢n tÃ­ch Ä‘iá»‡n sá»­ dá»¥ng qua cÃ´ng tÆ¡ tá»•ng). mÃ¬nh cÃ³ nghiÃªn cá»©u khÃ¡ nhiá»u whitepaper máº¥y thÃ¡ng nay vá» lÃ½ thuyáº¿t mÃ  váº«n chÆ°a biáº¿t pháº£i cháº¡y code thá»±c trÃªn 1 há»‡ thá»‘ng thá»±c táº¿ (cá»§a mÃ¬nh phÃ¡t triá»ƒn) thÃ¬ nhÆ° tháº¿ nÃ o. cÃ³ cao nhÃ¢n nÃ o Ä‘Ã£ lÃ m qua Ä‘á» tÃ i nÃ y cho mÃ¬nh thá»‰nh giÃ¡o vá»›i.
mÃ¬nh tÃ³m táº¯t bÃ i toÃ¡n nhÆ° sau:
- vÃ­ dá»¥ Ä‘Æ¡n giáº£n nháº¥t: cÃ´ng tÆ¡ tá»•ng Ä‘o Ä‘iá»‡n nhÃ  cho sá»‘ 5000W, ML sáº½ phÃ¢n tÃ­ch ra gá»“m: 70% mÃ¡y láº¡nh, 20% microwave, 10% tá»§ láº¡nh
- supervised training (cÃ³ giÃ¡m sÃ¡t), data training Ä‘áº§u vÃ o lÃ  sá»‘ Ä‘o Ä‘iá»‡n tá»•ng & sá»‘ Ä‘o Ä‘iá»‡n tá»«ng thiáº¿t bá»‹ riÃªng biá»‡t
- data lÃºc cháº¡y live thÃ¬ chá»‰ cÃ³ 1 con sá»‘ tá»•ng","mÃ¬nh Ä‘ang lÃ m 1 Ä‘á» tÃ i vá» NILM (phÃ¢n tÃ­ch Ä‘iá»‡n sá»­ dá»¥ng qua cÃ´ng tÆ¡ tá»•ng). mÃ¬nh cÃ³ nghiÃªn cá»©u khÃ¡ nhiá»u whitepaper máº¥y thÃ¡ng nay vá» lÃ½ thuyáº¿t mÃ  váº«n chÆ°a biáº¿t pháº£i cháº¡y code thá»±c trÃªn 1 há»‡ thá»‘ng thá»±c táº¿ (cá»§a mÃ¬nh phÃ¡t triá»ƒn) thÃ¬ nhÆ° tháº¿ nÃ o. cÃ³ cao nhÃ¢n nÃ o Ä‘Ã£ lÃ m qua Ä‘á» tÃ i nÃ y cho mÃ¬nh thá»‰nh giÃ¡o vá»›i. mÃ¬nh tÃ³m táº¯t bÃ i toÃ¡n nhÆ° sau: - vÃ­ dá»¥ Ä‘Æ¡n giáº£n nháº¥t: cÃ´ng tÆ¡ tá»•ng Ä‘o Ä‘iá»‡n nhÃ  cho sá»‘ 5000W, ML sáº½ phÃ¢n tÃ­ch ra gá»“m: 70% mÃ¡y láº¡nh, 20% microwave, 10% tá»§ láº¡nh - supervised training (cÃ³ giÃ¡m sÃ¡t), data training Ä‘áº§u vÃ o lÃ  sá»‘ Ä‘o Ä‘iá»‡n tá»•ng & sá»‘ Ä‘o Ä‘iá»‡n tá»«ng thiáº¿t bá»‹ riÃªng biá»‡t - data lÃºc cháº¡y live thÃ¬ chá»‰ cÃ³ 1 con sá»‘ tá»•ng",,,,,
"NgÃ y cÃ ng nhiá»u cÃ´ng ty quan tÃ¢m Ä‘áº¿n ká»¹ nÄƒng Machine Learning System Design (MLSD). CÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n lÄ©nh vá»±c nÃ y cÅ©ng ngÃ y má»™t phá»• biáº¿n trong quÃ¡ trÃ¬nh phá»ng váº¥n. CÃ³ má»™t thá»±c táº¿ lÃ  dÃ¹ báº¡n cÃ³ thuáº­t toÃ¡n ráº¥t tá»‘t nhÆ°ng khÃ´ng cÃ³ thiáº¿t káº¿ há»‡ thá»‘ng tá»‘t thÃ¬ thuáº­t toÃ¡n Ä‘Ã³ mÃ£i chá»‰ á»Ÿ trÃªn notebook vÃ  trong cÃ¡c demo mÃ  thÃ´i. Viá»‡c log dá»¯ liá»‡u sao cho hiá»‡u quáº£ á»Ÿ quy mÃ´ lá»›n vÃ  tá»‘i Æ°u Ä‘á»™ trá»… trong viá»‡c dá»± Ä‘oÃ¡n cÃ³ vai trÃ² khÃ´ng kÃ©m Ä‘á»™ chÃ­nh xÃ¡c cá»§a thuáº­t toÃ¡n.
Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t khoÃ¡ há»c MLSD cá»§a má»™t anh báº¡n ngÆ°á»i Viá»‡t thiáº¿t káº¿ trÃªn educative.
https://www.educative.io/courses/machine-learning-system-design
(KhoÃ¡ há»c nÃ y cÃ³ phÃ­, cÃ³ chÃ­nh sÃ¡ch tráº£ láº¡i tiá»n.)","NgÃ y cÃ ng nhiá»u cÃ´ng ty quan tÃ¢m Ä‘áº¿n ká»¹ nÄƒng Machine Learning System Design (MLSD). CÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n lÄ©nh vá»±c nÃ y cÅ©ng ngÃ y má»™t phá»• biáº¿n trong quÃ¡ trÃ¬nh phá»ng váº¥n. CÃ³ má»™t thá»±c táº¿ lÃ  dÃ¹ báº¡n cÃ³ thuáº­t toÃ¡n ráº¥t tá»‘t nhÆ°ng khÃ´ng cÃ³ thiáº¿t káº¿ há»‡ thá»‘ng tá»‘t thÃ¬ thuáº­t toÃ¡n Ä‘Ã³ mÃ£i chá»‰ á»Ÿ trÃªn notebook vÃ  trong cÃ¡c demo mÃ  thÃ´i. Viá»‡c log dá»¯ liá»‡u sao cho hiá»‡u quáº£ á»Ÿ quy mÃ´ lá»›n vÃ  tá»‘i Æ°u Ä‘á»™ trá»… trong viá»‡c dá»± Ä‘oÃ¡n cÃ³ vai trÃ² khÃ´ng kÃ©m Ä‘á»™ chÃ­nh xÃ¡c cá»§a thuáº­t toÃ¡n. Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t khoÃ¡ há»c MLSD cá»§a má»™t anh báº¡n ngÆ°á»i Viá»‡t thiáº¿t káº¿ trÃªn educative. https://www.educative.io/courses/machine-learning-system-design (KhoÃ¡ há»c nÃ y cÃ³ phÃ­, cÃ³ chÃ­nh sÃ¡ch tráº£ láº¡i tiá»n.)",,,,,
"Em cÃ³ thá»ƒ xin chia sáº» tá»« cÃ¡c bÃ¡c Ä‘ang Ä‘i há»c Ä‘i lÃ m vá» nghÃ nh nghá» IT vÃ  cáº£ trong lÄ©nh vá»±c ML vá» cÃ¡c gÃ³c Ä‘á»™ nhÆ° cÆ¡ há»™i, mÃ´i trÆ°á»ng lÃ m viá»‡c, dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai phÃ¡t triá»ƒn cá»§a ML, káº¿ hoáº¡ch Ä‘i lÃ m Ä‘Æ°á»£c khÃ´ng áº¡?
Em cÃ¡m Æ¡n cÃ¡c bÃ¡c, em cÅ©ng xin tÆ° váº¥n thÃªm + tÃ i liá»‡u vÃ  káº¿ hoáº¡ch há»c táº­p áº¡","Em cÃ³ thá»ƒ xin chia sáº» tá»« cÃ¡c bÃ¡c Ä‘ang Ä‘i há»c Ä‘i lÃ m vá» nghÃ nh nghá» IT vÃ  cáº£ trong lÄ©nh vá»±c ML vá» cÃ¡c gÃ³c Ä‘á»™ nhÆ° cÆ¡ há»™i, mÃ´i trÆ°á»ng lÃ m viá»‡c, dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai phÃ¡t triá»ƒn cá»§a ML, káº¿ hoáº¡ch Ä‘i lÃ m Ä‘Æ°á»£c khÃ´ng áº¡? Em cÃ¡m Æ¡n cÃ¡c bÃ¡c, em cÅ©ng xin tÆ° váº¥n thÃªm + tÃ i liá»‡u vÃ  káº¿ hoáº¡ch há»c táº­p áº¡",,,,,
"[Chia Sáº»] HÆ°á»›ng Dáº«n Tá»± Há»c Data Science cho NgÆ°á»i Má»›i Báº¯t Äáº§u]
Hello má»i ngÆ°á»i,
NhÃ³m mÃ¬nh cÃ³ lÃ m Series vá» kiáº¿n thá»©c Data Science cÆ¡ báº£n dÃ nh cho cÃ¡c báº¡n má»›i báº¯t Ä‘áº§u hoáº·c Ä‘ang há»c á»Ÿ trÆ°á»ng. Tá»¥i mÃ¬nh hiá»‡n Ä‘ang lÃ  Software Engineer Ä‘ang lÃ m viá»‡c á»Ÿ Sing vá»›i hi vá»ng chia sáº» kiáº¿n thá»©c IT cho cÃ¡c báº¡n Ä‘am mÃª láº­p trÃ¬nh. Trong clip tá»¥i mÃ¬nh táº­p trung vÃ o:
HÆ°á»›ng Dáº«n CÃ i Äáº·t vÃ  LÃ m Quen vs Anaconda vÃ  Jupyter Notebook
LÃ m quen vá»›i Pandas vÃ  DataFrame
HÆ°á»›ng dáº«n cÃ¡c xá»­ lÃ½ má»™t dá»¯ liá»‡u cá»¥ thá»ƒ cá»§a má»™t nhÃ  hÃ ng.
Hi vá»ng clip nÃ y giÃºp Ã­ch Ä‘Æ°á»£c má»i ngÆ°á»i !","[Chia Sáº»] HÆ°á»›ng Dáº«n Tá»± Há»c Data Science cho NgÆ°á»i Má»›i Báº¯t Äáº§u] Hello má»i ngÆ°á»i, NhÃ³m mÃ¬nh cÃ³ lÃ m Series vá» kiáº¿n thá»©c Data Science cÆ¡ báº£n dÃ nh cho cÃ¡c báº¡n má»›i báº¯t Ä‘áº§u hoáº·c Ä‘ang há»c á»Ÿ trÆ°á»ng. Tá»¥i mÃ¬nh hiá»‡n Ä‘ang lÃ  Software Engineer Ä‘ang lÃ m viá»‡c á»Ÿ Sing vá»›i hi vá»ng chia sáº» kiáº¿n thá»©c IT cho cÃ¡c báº¡n Ä‘am mÃª láº­p trÃ¬nh. Trong clip tá»¥i mÃ¬nh táº­p trung vÃ o: HÆ°á»›ng Dáº«n CÃ i Äáº·t vÃ  LÃ m Quen vs Anaconda vÃ  Jupyter Notebook LÃ m quen vá»›i Pandas vÃ  DataFrame HÆ°á»›ng dáº«n cÃ¡c xá»­ lÃ½ má»™t dá»¯ liá»‡u cá»¥ thá»ƒ cá»§a má»™t nhÃ  hÃ ng. Hi vá»ng clip nÃ y giÃºp Ã­ch Ä‘Æ°á»£c má»i ngÆ°á»i !",,,,,
Xá»­ lÃ½ dá»¯ liá»‡u text dÃ¹ng python,Xá»­ lÃ½ dá»¯ liá»‡u text dÃ¹ng python,,,,,
"ChÃ o anh chá»‹ áº¡ !!!
Em vá»«a bÆ°á»›c vÃ o lÄ©nh vá»±c machibe learning nÃ y. Tháº§y cÃ³ giao tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh XGBoost. E Ä‘Ã£ Ä‘á»c 1 sá»‘ tÃ i liá»‡u tiáº¿ng viá»‡t láº«n tiáº¿ng anh. NhÆ°ng khÃ´ng Ä‘áº¿n Ä‘Ã¢u, trÃ¬nh bÃ y láº¡i mÃ´ hÃ¬nh cho ng khÃ¡c nghe, em khÃ´ng biáº¿t trÃ¬nh bÃ y nhÆ° tháº¿ nÃ o luÃ´n. CÃ³ anh chá»‹ nÃ o trong group biáº¿t vÃª mÃ´ hÃ¬nh nÃ y thÃ¬ cho em xin cÃ¡ch trÃ¬nh bÃ y mÃ´ hinh nÃ y vá»›i.
Em cáº£m Æ¡n má»i ng Ä‘Ã£ Ä‘á»c bÃ i.
ChÃºc má»i ngÆ°á»i buá»•i tá»‘i vui váº»","ChÃ o anh chá»‹ áº¡ !!! Em vá»«a bÆ°á»›c vÃ o lÄ©nh vá»±c machibe learning nÃ y. Tháº§y cÃ³ giao tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh XGBoost. E Ä‘Ã£ Ä‘á»c 1 sá»‘ tÃ i liá»‡u tiáº¿ng viá»‡t láº«n tiáº¿ng anh. NhÆ°ng khÃ´ng Ä‘áº¿n Ä‘Ã¢u, trÃ¬nh bÃ y láº¡i mÃ´ hÃ¬nh cho ng khÃ¡c nghe, em khÃ´ng biáº¿t trÃ¬nh bÃ y nhÆ° tháº¿ nÃ o luÃ´n. CÃ³ anh chá»‹ nÃ o trong group biáº¿t vÃª mÃ´ hÃ¬nh nÃ y thÃ¬ cho em xin cÃ¡ch trÃ¬nh bÃ y mÃ´ hinh nÃ y vá»›i. Em cáº£m Æ¡n má»i ng Ä‘Ã£ Ä‘á»c bÃ i. ChÃºc má»i ngÆ°á»i buá»•i tá»‘i vui váº»",,,,,
BÃ i viáº¿t Ä‘áº§u tay cá»§a mÃ¬nh vá» trade off bias-variance. Hy vá»ng giÃºp Ã­ch vÃ  Ä‘Æ°á»£c má»i ngÆ°á»i gÃ³p Ã½ thÃªm áº¡.,BÃ i viáº¿t Ä‘áº§u tay cá»§a mÃ¬nh vá» trade off bias-variance. Hy vá»ng giÃºp Ã­ch vÃ  Ä‘Æ°á»£c má»i ngÆ°á»i gÃ³p Ã½ thÃªm áº¡.,,,,,
"ChÃ o má»i ngÆ°á»i
Cho mÃ¬nh há»i chÃºt vá» BinaryAccuracy trong Tensorflow""
MÃ¬nh cÃ³ 2 cÃ¡i labels nhÆ° trÃªn:
[[1], [0], [1], [1]]
[[0.6], [0.51], [0], [0.6]]
Vá»›i threshold = 0.5:
=> 2 bá»™ true/pred labels sáº½ thÃ nh:
1 0 1 1
vÃ  1 1 0 1
vá»›i sample weight = 1,1,1,1
Binary Accuracy = 2/4 = 0.5(very clear!!)
NhÆ°ng vá»›i sample weight = 1,1,1,0, táº¡i sao Binary Accuracy láº¡i lÃ  0.333334 ?
MÃ¬nh gu gá»“ mÃ£i chÆ°a ra chá»— nÃ y.
Ráº¥t mong cÃ¡c báº¡n thÃ´ng nÃ£o, Ä‘Ã¢y lÃ  áº£nh mÃ¬nh chá»¥p khi run trÃªn Colab","ChÃ o má»i ngÆ°á»i Cho mÃ¬nh há»i chÃºt vá» BinaryAccuracy trong Tensorflow"" MÃ¬nh cÃ³ 2 cÃ¡i labels nhÆ° trÃªn: [[1], [0], [1], [1]] [[0.6], [0.51], [0], [0.6]] Vá»›i threshold = 0.5: => 2 bá»™ true/pred labels sáº½ thÃ nh: 1 0 1 1 vÃ  1 1 0 1 vá»›i sample weight = 1,1,1,1 Binary Accuracy = 2/4 = 0.5(very clear!!) NhÆ°ng vá»›i sample weight = 1,1,1,0, táº¡i sao Binary Accuracy láº¡i lÃ  0.333334 ? MÃ¬nh gu gá»“ mÃ£i chÆ°a ra chá»— nÃ y. Ráº¥t mong cÃ¡c báº¡n thÃ´ng nÃ£o, Ä‘Ã¢y lÃ  áº£nh mÃ¬nh chá»¥p khi run trÃªn Colab",,,,,
CÃ´ng cá»¥ xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t,CÃ´ng cá»¥ xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t,,,,,
"Láº­p trÃ¬nh máº¡ng nÆ¡ ron tá»‘t nháº¥t lÃ  dÃ¹ng cÃ¡c hÃ m trong python vÃ  thÆ° viá»‡n, nhÆ°ng náº¿u báº¡n tÃ² mÃ² muá»‘n láº­p trÃ¬nh tá»« Ä‘á»‹nh nghÄ©a toÃ¡n há»c?","Láº­p trÃ¬nh máº¡ng nÆ¡ ron tá»‘t nháº¥t lÃ  dÃ¹ng cÃ¡c hÃ m trong python vÃ  thÆ° viá»‡n, nhÆ°ng náº¿u báº¡n tÃ² mÃ² muá»‘n láº­p trÃ¬nh tá»« Ä‘á»‹nh nghÄ©a toÃ¡n há»c?",,,,,
"ChÃ o má»i ngÆ°á»i ,tháº§y giao em bÃ i táº­p tÃ¬m vÃ  lá»c Ã­t nháº¥t 4000 áº£nh vá» quáº£ chÃ´m chÃ´m Ä‘á»ƒ train, em tÃ¬m Ä‘Æ°á»£c web flickr thÃ¬ tháº¥y ok , nhÆ°ng láº¡i ko biáº¿t lÃ m sao Ä‘á»ƒ táº£i vÃ i trÄƒm / ngÃ n áº£nh vá» mÃ¡y cÃ¹ng 1 lÃºc Ä‘Æ°á»£c, ai chá»‰ cÃ¡ch cho em vá»›i áº¡, em lÃªn máº¡ng kiáº¿m máº¥y cÃ¡i source code nhÆ°ng láº¡i khÃ´ng biáº¿t cÃ¡ch dÃ¹ng","ChÃ o má»i ngÆ°á»i ,tháº§y giao em bÃ i táº­p tÃ¬m vÃ  lá»c Ã­t nháº¥t 4000 áº£nh vá» quáº£ chÃ´m chÃ´m Ä‘á»ƒ train, em tÃ¬m Ä‘Æ°á»£c web flickr thÃ¬ tháº¥y ok , nhÆ°ng láº¡i ko biáº¿t lÃ m sao Ä‘á»ƒ táº£i vÃ i trÄƒm / ngÃ n áº£nh vá» mÃ¡y cÃ¹ng 1 lÃºc Ä‘Æ°á»£c, ai chá»‰ cÃ¡ch cho em vá»›i áº¡, em lÃªn máº¡ng kiáº¿m máº¥y cÃ¡i source code nhÆ°ng láº¡i khÃ´ng biáº¿t cÃ¡ch dÃ¹ng",,,,,
"KhoÃ¡ Machine Learning System Design cá»§a Stanford Ä‘ang diá»…n ra, ráº¥t nhiá»u thÃ´ng tin bá»• Ã­ch cho cáº£ cÃ¡c báº¡n sinh viÃªn vÃ  cÃ¡c báº¡n lÃ m viá»‡c vá»›i ML in production:
https://stanford-cs329s.github.io/?fbclid=IwAR0C23h0nlJjIJQPcDs6YUKxBi-trWoPY5fRpm1CzZRF4SvxhFpIFb5fu4E","KhoÃ¡ Machine Learning System Design cá»§a Stanford Ä‘ang diá»…n ra, ráº¥t nhiá»u thÃ´ng tin bá»• Ã­ch cho cáº£ cÃ¡c báº¡n sinh viÃªn vÃ  cÃ¡c báº¡n lÃ m viá»‡c vá»›i ML in production: https://stanford-cs329s.github.io/?fbclid=IwAR0C23h0nlJjIJQPcDs6YUKxBi-trWoPY5fRpm1CzZRF4SvxhFpIFb5fu4E",,,,,
"Hi má»i ngÆ°á»i. Em Ä‘ang lÃ m vá» nháº­n diá»‡n tÃªn thuá»‘c, thÃ nh pháº§n thuá»‘c vÃ  sá»­a lá»—i chÃ­nh táº£ náº¿u cÃ³.
- Vá»›i pháº§n nháº­n diá»‡n tÃªn thuá»‘c vÃ  thÃ nh pháº§n thuá»‘c: Em xÃ¢y dá»±ng má»™t bá»™ phÃ¢n lá»›p cÃ³ 3 class: thuá»‘c, thÃ nh pháº§n vÃ  khÃ¡c
- Vá»›i pháº§n sá»­a lá»—i chÃ­nh táº£ em mong muá»‘n tÃ¬m má»™t model cho viá»‡c sá»­a lá»—i
Anh chá»‹ cÃ³ ai lÃ m vá» máº£ng nÃ y gÃ³p Ã½ giÃºp em vá»›i áº¡.","Hi má»i ngÆ°á»i. Em Ä‘ang lÃ m vá» nháº­n diá»‡n tÃªn thuá»‘c, thÃ nh pháº§n thuá»‘c vÃ  sá»­a lá»—i chÃ­nh táº£ náº¿u cÃ³. - Vá»›i pháº§n nháº­n diá»‡n tÃªn thuá»‘c vÃ  thÃ nh pháº§n thuá»‘c: Em xÃ¢y dá»±ng má»™t bá»™ phÃ¢n lá»›p cÃ³ 3 class: thuá»‘c, thÃ nh pháº§n vÃ  khÃ¡c - Vá»›i pháº§n sá»­a lá»—i chÃ­nh táº£ em mong muá»‘n tÃ¬m má»™t model cho viá»‡c sá»­a lá»—i Anh chá»‹ cÃ³ ai lÃ m vá» máº£ng nÃ y gÃ³p Ã½ giÃºp em vá»›i áº¡.",,,,,
"chÃ o mng, e cÃ³ 1 cÃ¢u há»i, e Ä‘á»c tá»›i giáº£ nghich Ä‘áº£o nÃ y thÃ¬ hÆ¡i lÃº , sinh ra giáº£ nghá»‹ch Ä‘áº£o Ä‘á»ƒ cho dÃ¹ nÃ³ ko cÃ³ ma tráº­n nghá»‹ch Ä‘áº£o thÃ¬ mÃ¬nh váº«n xÃ¢y dá»±ng dc giáº£ nghá»‹ch Ä‘áº£o v ko áº¡ ? v náº¿u lá»¡ trÃºng ma tráº­n Ä‘Ã³ ko cÃ³ nghichj Ä‘áº£o thÃ¬ xÃ¢y dá»±ng pseudo invertible nhÆ° tháº¿ nÃ o áº¡","chÃ o mng, e cÃ³ 1 cÃ¢u há»i, e Ä‘á»c tá»›i giáº£ nghich Ä‘áº£o nÃ y thÃ¬ hÆ¡i lÃº , sinh ra giáº£ nghá»‹ch Ä‘áº£o Ä‘á»ƒ cho dÃ¹ nÃ³ ko cÃ³ ma tráº­n nghá»‹ch Ä‘áº£o thÃ¬ mÃ¬nh váº«n xÃ¢y dá»±ng dc giáº£ nghá»‹ch Ä‘áº£o v ko áº¡ ? v náº¿u lá»¡ trÃºng ma tráº­n Ä‘Ã³ ko cÃ³ nghichj Ä‘áº£o thÃ¬ xÃ¢y dá»±ng pseudo invertible nhÆ° tháº¿ nÃ o áº¡",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. HÃ´m nay em thá»±c hiá»‡n ná»‘t mÃ³n quÃ  website Xem bÃ³i máº·t cho anh em newbie. Em máº¡nh dáº¡n chia sáº» Ä‘á»ƒ cÃ¡c báº¡n náº¯m Ä‘Æ°á»£c cÃ¡ch thá»©c xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Ä‘Æ¡n giáº£n, á»Ÿ má»©c Ä‘á»“ Ã¡n.
ChÃºc cÃ¡c bÃ¡c nÄƒm má»›i bÃ¬nh an, háº¡nh phÃºc!
Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c. HÃ´m nay em thá»±c hiá»‡n ná»‘t mÃ³n quÃ  website Xem bÃ³i máº·t cho anh em newbie. Em máº¡nh dáº¡n chia sáº» Ä‘á»ƒ cÃ¡c báº¡n náº¯m Ä‘Æ°á»£c cÃ¡ch thá»©c xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Ä‘Æ¡n giáº£n, á»Ÿ má»©c Ä‘á»“ Ã¡n. ChÃºc cÃ¡c bÃ¡c nÄƒm má»›i bÃ¬nh an, háº¡nh phÃºc! Mong ad duyá»‡t bÃ i!",,,,,
"Má»™t khoÃ¡ há»c hay khÃ¡c vá» ML, trong Ä‘Ã¢y cÃ³ hai pháº§n ráº¥t hay vá» dá»¯ liá»‡u dáº¡ng báº£ng (tabular data) lÃ  Feature Crosses vÃ  Embeddings.","Má»™t khoÃ¡ há»c hay khÃ¡c vá» ML, trong Ä‘Ã¢y cÃ³ hai pháº§n ráº¥t hay vá» dá»¯ liá»‡u dáº¡ng báº£ng (tabular data) lÃ  Feature Crosses vÃ  Embeddings.",,,,,
ChÃ o má»i ngÆ°á»i. mÃ¬nh lÃ  nguá»i má»›i vá» ML. mÃ¬nh cÃ³ váº¥n Ä‘á» vá» sá»­ dá»¥ng deeplearning Ä‘á»ƒ phÃ¢n tÃ­ch ná»™i dung ngá»¯ nghÄ©a Ä‘oáº¡n vÄƒn. Ä‘Ã£ cÃ³ ai lÃ m vá» nÃ y cho mÃ¬nh xin huá»›ng dáº«n vá»›i áº¡. Cáº£m Æ¡n Mn,ChÃ o má»i ngÆ°á»i. mÃ¬nh lÃ  nguá»i má»›i vá» ML. mÃ¬nh cÃ³ váº¥n Ä‘á» vá» sá»­ dá»¥ng deeplearning Ä‘á»ƒ phÃ¢n tÃ­ch ná»™i dung ngá»¯ nghÄ©a Ä‘oáº¡n vÄƒn. Ä‘Ã£ cÃ³ ai lÃ m vá» nÃ y cho mÃ¬nh xin huá»›ng dáº«n vá»›i áº¡. Cáº£m Æ¡n Mn,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Táº¿t Ä‘áº¿n xuÃ¢n sang, em cÃ³ xÃ¢y dá»±ng website xem bÃ³i máº·t, nháº­n vÃ o má»™t khuÃ´n máº·t vÃ  hiá»ƒn thá»‹ lÃªn kiá»ƒu máº·t: dÃ i, trÃ²n, trÃ¡i tim.... kÃ¨m theo cÃ¡c lá»i diá»…n giáº£i vá» tÆ°á»›ng sá»‘ liÃªn quan Ä‘áº¿n khuÃ´n máº·t Ä‘Ã³.
Nay em chia sáº» cÃ¹ng má»i ngÆ°á»i!
Mong giÃºp Ä‘á»¡ Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c! Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Táº¿t Ä‘áº¿n xuÃ¢n sang, em cÃ³ xÃ¢y dá»±ng website xem bÃ³i máº·t, nháº­n vÃ o má»™t khuÃ´n máº·t vÃ  hiá»ƒn thá»‹ lÃªn kiá»ƒu máº·t: dÃ i, trÃ²n, trÃ¡i tim.... kÃ¨m theo cÃ¡c lá»i diá»…n giáº£i vá» tÆ°á»›ng sá»‘ liÃªn quan Ä‘áº¿n khuÃ´n máº·t Ä‘Ã³. Nay em chia sáº» cÃ¹ng má»i ngÆ°á»i! Mong giÃºp Ä‘á»¡ Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c! Mong ad duyá»‡t bÃ i!",,,,,
"cÃ¡c anh, chá»‹ cho em há»i lá»—i nÃ y lÃ  gÃ¬ vÃ  cÃ¡ch kháº¯c phá»¥c Ä‘Æ°á»£c khÃ´ng áº¡? em cáº£m Æ¡n nhiá»uğŸ˜","cÃ¡c anh, chá»‹ cho em há»i lá»—i nÃ y lÃ  gÃ¬ vÃ  cÃ¡ch kháº¯c phá»¥c Ä‘Æ°á»£c khÃ´ng áº¡? em cáº£m Æ¡n nhiá»u",,,,,
"Hi má»i ngÆ°á»i,
HÃ´m nay mÃ¬nh xin phÃ©p chia sáº» blog vá» thá»±c nghiá»‡m cÃ¡c mÃ´ hÃ¬nh thÆ°á»ng hay Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i toÃ n OCR, cá»¥ thá»ƒ AttentionOCR vÃ  TransformerOCR, vÃ  tráº£ lá»i cÃ¢u há»i ""Liá»‡u sá»­ dá»¥ng kiáº¿n trÃºc má»›i nhÆ° transformer cÃ³ lÃ m tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a quÃ¡ trÃ¬nh nháº­n dáº¡ng lÃªn nhiá»u hay khÃ´ng?"",
Äá»“ng thá»i, mÃ¬nh cÅ©ng cung cáº¥p thÆ° viá»‡n VietOCR Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i má»¥c tiÃªu dá»… sÃ i, dá»… huáº¥n luyá»‡n cho ngÃ´n ngá»¯ tiáº¿ng viá»‡t, cÃ¹ng vá»›i pretrained model trÃªn 10m áº£nh.
ThÆ° viá»‡n: https://github.com/pbcquoc/vietocr
Blog: https://pbcquoc.github.io/vietocr/
Notebook hÆ°á»›ng dáº«n sá»­ dá»¥ng thÆ° viá»‡n: https://github.com/pbcquoc/vietocr/blob/master/vietocr_gettingstart.ipynb","Hi má»i ngÆ°á»i, HÃ´m nay mÃ¬nh xin phÃ©p chia sáº» blog vá» thá»±c nghiá»‡m cÃ¡c mÃ´ hÃ¬nh thÆ°á»ng hay Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i toÃ n OCR, cá»¥ thá»ƒ AttentionOCR vÃ  TransformerOCR, vÃ  tráº£ lá»i cÃ¢u há»i ""Liá»‡u sá»­ dá»¥ng kiáº¿n trÃºc má»›i nhÆ° transformer cÃ³ lÃ m tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a quÃ¡ trÃ¬nh nháº­n dáº¡ng lÃªn nhiá»u hay khÃ´ng?"", Äá»“ng thá»i, mÃ¬nh cÅ©ng cung cáº¥p thÆ° viá»‡n VietOCR Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i má»¥c tiÃªu dá»… sÃ i, dá»… huáº¥n luyá»‡n cho ngÃ´n ngá»¯ tiáº¿ng viá»‡t, cÃ¹ng vá»›i pretrained model trÃªn 10m áº£nh. ThÆ° viá»‡n: https://github.com/pbcquoc/vietocr Blog: https://pbcquoc.github.io/vietocr/ Notebook hÆ°á»›ng dáº«n sá»­ dá»¥ng thÆ° viá»‡n: https://github.com/pbcquoc/vietocr/blob/master/vietocr_gettingstart.ipynb",,,,,
Ai muá»‘n há»c Machine Learning miá»…n phÃ­ thÃ¬ lÆ°u láº¡i nhÃ©!,Ai muá»‘n há»c Machine Learning miá»…n phÃ­ thÃ¬ lÆ°u láº¡i nhÃ©!,,,,,
"ChÃ o cÃ¡c anh/chá»‹ vÃ  cÃ¡c báº¡n, em Ä‘ang gáº·p váº¥n Ä‘á» vá» Ä‘á»‹nh hÆ°á»›ng, em ráº¥t mong nháº­n Ä‘Æ°á»£c tÆ° váº¥n tá»« cÃ¡c anh/chá»‹ Ä‘i trÆ°á»›c.
Em lÃ  ngÆ°á»i chuyá»ƒn ngÃ nh, em muá»‘n lÃ m vá» cÃ´ng nghá»‡, nhÆ°ng em kiáº¿n thá»©c vÃ  kinh nghiá»‡m chÆ°a cÃ³ vÃ  chÆ°a hiá»ƒu biáº¿t gÃ¬ vá» ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin, nÃªn em quyáº¿t Ä‘á»‹nh xin thá»±c táº­p láº­p trÃ¬nh pháº§n má»m, em cáº£m tháº¥y hÆ¡i mÆ¡ há»“ vá»›i lá»±a chá»n cá»§a mÃ¬nh. VÃ o cÃ´ng ty thÃ¬ mÃ¬nh gáº§n nhÆ° khÃ´ng biáº¿t gÃ¬, má»›i toÃ n táº­p. Cty nÃ y cÃ³ sáº£n pháº©m lÃ  pháº§n má»m cho Doanh nghiá»‡p.
Em Ä‘ang suy nghÄ© lÃ  em sáº½ há»c cÃ¡c cÃ´ng cá»¥, kiáº¿n thá»©c Ä‘á»ƒ trÆ°á»›c máº¯t lÃ m viá»‡c táº¡i Cty, hiá»ƒu ngÃ nh - hiá»ƒu nghá» rá»“i sau khoáº£ng 1, 2 cÃ³ kinh nghiá»‡m rá»“i báº¯t Ä‘áº§u há»c thÃªm vá» dá»¯ liá»‡u, cÃ¡c thuáº­t toÃ¡n AI Ä‘á»ƒ á»©ng dá»¥ng nÃ³ vÃ o sáº£n pháº©m.
Em cÃ³ Ä‘á»c má»™t sá»‘ con Ä‘Æ°á»ng cá»§a nhá»¯ng ngÆ°á»i há»c ngÃ nh khÃ´ng pháº£i cÃ´ng nghá»‡ thÃ´ng tin hoáº·c KHMT, thÃ¬ háº§u háº¿t cÃ¢u tráº£ lá»i lÃ  tham gia cÃ¡c khÃ³a há»c trÃªn máº¡ng, thi trÃªn Kaggle... NhÆ°ng em chÆ°a chá»n vÃ¬ chÆ°a rÃµ má»¥c Ä‘Ã­ch mÃ¬nh sá»­ dá»¥ng AI Ä‘á»ƒ lÃ m gÃ¬.
Hiá»‡n táº¡i em Ä‘ang mÆ¡ há»“ vá» con Ä‘Æ°á»ng sá»± nghiá»‡p, mong má»i ngÆ°á»i chia sáº» kinh nghiá»‡m Ä‘á»ƒ em há»c há»i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o cÃ¡c anh/chá»‹ vÃ  cÃ¡c báº¡n, em Ä‘ang gáº·p váº¥n Ä‘á» vá» Ä‘á»‹nh hÆ°á»›ng, em ráº¥t mong nháº­n Ä‘Æ°á»£c tÆ° váº¥n tá»« cÃ¡c anh/chá»‹ Ä‘i trÆ°á»›c. Em lÃ  ngÆ°á»i chuyá»ƒn ngÃ nh, em muá»‘n lÃ m vá» cÃ´ng nghá»‡, nhÆ°ng em kiáº¿n thá»©c vÃ  kinh nghiá»‡m chÆ°a cÃ³ vÃ  chÆ°a hiá»ƒu biáº¿t gÃ¬ vá» ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin, nÃªn em quyáº¿t Ä‘á»‹nh xin thá»±c táº­p láº­p trÃ¬nh pháº§n má»m, em cáº£m tháº¥y hÆ¡i mÆ¡ há»“ vá»›i lá»±a chá»n cá»§a mÃ¬nh. VÃ o cÃ´ng ty thÃ¬ mÃ¬nh gáº§n nhÆ° khÃ´ng biáº¿t gÃ¬, má»›i toÃ n táº­p. Cty nÃ y cÃ³ sáº£n pháº©m lÃ  pháº§n má»m cho Doanh nghiá»‡p. Em Ä‘ang suy nghÄ© lÃ  em sáº½ há»c cÃ¡c cÃ´ng cá»¥, kiáº¿n thá»©c Ä‘á»ƒ trÆ°á»›c máº¯t lÃ m viá»‡c táº¡i Cty, hiá»ƒu ngÃ nh - hiá»ƒu nghá» rá»“i sau khoáº£ng 1, 2 cÃ³ kinh nghiá»‡m rá»“i báº¯t Ä‘áº§u há»c thÃªm vá» dá»¯ liá»‡u, cÃ¡c thuáº­t toÃ¡n AI Ä‘á»ƒ á»©ng dá»¥ng nÃ³ vÃ o sáº£n pháº©m. Em cÃ³ Ä‘á»c má»™t sá»‘ con Ä‘Æ°á»ng cá»§a nhá»¯ng ngÆ°á»i há»c ngÃ nh khÃ´ng pháº£i cÃ´ng nghá»‡ thÃ´ng tin hoáº·c KHMT, thÃ¬ háº§u háº¿t cÃ¢u tráº£ lá»i lÃ  tham gia cÃ¡c khÃ³a há»c trÃªn máº¡ng, thi trÃªn Kaggle... NhÆ°ng em chÆ°a chá»n vÃ¬ chÆ°a rÃµ má»¥c Ä‘Ã­ch mÃ¬nh sá»­ dá»¥ng AI Ä‘á»ƒ lÃ m gÃ¬. Hiá»‡n táº¡i em Ä‘ang mÆ¡ há»“ vá» con Ä‘Æ°á»ng sá»± nghiá»‡p, mong má»i ngÆ°á»i chia sáº» kinh nghiá»‡m Ä‘á»ƒ em há»c há»i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  má»™t newbie trong lÄ©nh vá»±c Machine learning, vÃ¬ váº­y ká»¹ nÄƒng vá» thao tÃ¡c vÃ  lÃ m viá»‡c vá»›i numpy cá»§a em cÃ²n nhiá»u háº¡n cháº¿. CÃ¡c anh, chá»‹ cÃ³ thá»ƒ recommend giÃºp em má»™t vÃ i khoÃ¡ há»c vá» numpy khÃ´ng áº¡? Em cÃ¡m Æ¡n nhiá»u áº¡.
Má»i ngÆ°á»i stay safe nhÃ©.","ChÃ o má»i ngÆ°á»i, em lÃ  má»™t newbie trong lÄ©nh vá»±c Machine learning, vÃ¬ váº­y ká»¹ nÄƒng vá» thao tÃ¡c vÃ  lÃ m viá»‡c vá»›i numpy cá»§a em cÃ²n nhiá»u háº¡n cháº¿. CÃ¡c anh, chá»‹ cÃ³ thá»ƒ recommend giÃºp em má»™t vÃ i khoÃ¡ há»c vá» numpy khÃ´ng áº¡? Em cÃ¡m Æ¡n nhiá»u áº¡. Má»i ngÆ°á»i stay safe nhÃ©.",,,,,
"MÃ¬nh chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang cÃ³ Ã½ Ä‘á»‹nh há»c Machine Learning á»Ÿ TPHCM. MÃ¬nh Ä‘ang phÃ¢n vÃ¢n giá»¯a há»c á»Ÿ VTC Academy hoáº·c lÃ  ÄH Khoa Há»c Tá»± NhiÃªn. Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m hÆ°á»›ng dáº«n mÃ¬nh vá»›i.
Cáº£m Æ¡n má»i ngÆ°á»i.",MÃ¬nh chÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang cÃ³ Ã½ Ä‘á»‹nh há»c Machine Learning á»Ÿ TPHCM. MÃ¬nh Ä‘ang phÃ¢n vÃ¢n giá»¯a há»c á»Ÿ VTC Academy hoáº·c lÃ  ÄH Khoa Há»c Tá»± NhiÃªn. Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m hÆ°á»›ng dáº«n mÃ¬nh vá»›i. Cáº£m Æ¡n má»i ngÆ°á»i.,,,,,
"Agree, an ML blogger also said this many times.
""""""
One superstar ML engineer once said: â€œStart small. Smaller. Still too big.â€ Starting with a small model has three benefits:
It helps you validate that your data can do something useful.
It helps you validate your pipeline to make sure that your training pipeline and inference pipeline do the same things.
Simple models can act as baselines to which you can compare your more complex models. Your complex models should do significantly better than simple models to justify their complexity.
""""""","Agree, an ML blogger also said this many times. """""" One superstar ML engineer once said: â€œStart small. Smaller. Still too big.â€ Starting with a small model has three benefits: It helps you validate that your data can do something useful. It helps you validate your pipeline to make sure that your training pipeline and inference pipeline do the same things. Simple models can act as baselines to which you can compare your more complex models. Your complex models should do significantly better than simple models to justify their complexity. """"""",,,,,
"VÃ¢ng, anh em Ä‘ang thá»­ bÃ i toÃ¡n cháº©n Ä‘oÃ¡n bá»‡nh qua phim X tá»« xa, dá»±a trÃªn mÃ¡y há»c, tá»« Vingroup
#koolj_deepimage
A em Ä‘Ã£ xá»­ lÃ½ cÆ¡ báº£n xong.
GPU detect khÃ¡ nhanh.
A e chuyá»ƒn demo sang:
Dathoc.net/vx
Má»i pÃ  con vÃ o Ä‘Ã¡nh giÃ¡ tiáº¿p.
Mong gÃ³p Ã½ tá»« anh em!","VÃ¢ng, anh em Ä‘ang thá»­ bÃ i toÃ¡n cháº©n Ä‘oÃ¡n bá»‡nh qua phim X tá»« xa, dá»±a trÃªn mÃ¡y há»c, tá»« Vingroup A em Ä‘Ã£ xá»­ lÃ½ cÆ¡ báº£n xong. GPU detect khÃ¡ nhanh. A e chuyá»ƒn demo sang: Dathoc.net/vx Má»i pÃ  con vÃ o Ä‘Ã¡nh giÃ¡ tiáº¿p. Mong gÃ³p Ã½ tá»« anh em!",#koolj_deepimage,,,,
"Adas: state-of-the-art training performance
#Share",Adas: state-of-the-art training performance,#Share,,,,
"ChÃ o cáº£ nhÃ , mÃ¬nh muá»‘n báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» text to speech cho Tiáº¿ng Viá»‡t thÃ¬ cÃ³ báº¯t Ä‘áº§u tá»« Ä‘Ã¢u hoáº·c cÃ³ code, data tham kháº£o á»Ÿ Ä‘Ã¢u thÃ¬ tá»‘t nhá»‰?
MÃ¬nh tÃ¬m qua má»™t lÆ°á»£t nhÆ°ng khÃ´ng tháº¥y nhiá»u láº¯m vÃ  khÃ¡ cÅ©.
Background: mÃ¬nh cÃ³ má»™t chÃºt kinh nghiá»‡m vá» xá»­ lÃ½ áº£nh/video vÃ  deep learning. ChÆ°a lÃ m vá» text vÃ  speech bao giá».
Xin cáº£m Æ¡n","ChÃ o cáº£ nhÃ , mÃ¬nh muá»‘n báº¯t Ä‘áº§u tÃ¬m hiá»ƒu vá» text to speech cho Tiáº¿ng Viá»‡t thÃ¬ cÃ³ báº¯t Ä‘áº§u tá»« Ä‘Ã¢u hoáº·c cÃ³ code, data tham kháº£o á»Ÿ Ä‘Ã¢u thÃ¬ tá»‘t nhá»‰? MÃ¬nh tÃ¬m qua má»™t lÆ°á»£t nhÆ°ng khÃ´ng tháº¥y nhiá»u láº¯m vÃ  khÃ¡ cÅ©. Background: mÃ¬nh cÃ³ má»™t chÃºt kinh nghiá»‡m vá» xá»­ lÃ½ áº£nh/video vÃ  deep learning. ChÆ°a lÃ m vá» text vÃ  speech bao giá». Xin cáº£m Æ¡n",,,,,
"Em chÃ o má»i ngÆ°á»i!!!
Em cÃ³ 1 cÃ¢u há»i lÃ 
Em cÃ³ hÃ ng dá»c nhÆ° trong áº£nh, em muá»‘n Ä‘á»•i nÃ³ thÃ nh hÃ ng ngang, trong openGL thÃ¬ lÃ m ntn áº¡, hoáº·c chá»‰ cáº§n cho e xin cÃ¡i keyword thÃ´i lÃ  em cáº£m Æ¡n láº¯m rá»“i","Em chÃ o má»i ngÆ°á»i!!! Em cÃ³ 1 cÃ¢u há»i lÃ  Em cÃ³ hÃ ng dá»c nhÆ° trong áº£nh, em muá»‘n Ä‘á»•i nÃ³ thÃ nh hÃ ng ngang, trong openGL thÃ¬ lÃ m ntn áº¡, hoáº·c chá»‰ cáº§n cho e xin cÃ¡i keyword thÃ´i lÃ  em cáº£m Æ¡n láº¯m rá»“i",,,,,
"Xin chÃ o má»i ngÆ°á»i áº¡. Cho em/mÃ¬nh há»i lÃ  cÃ³ cÃ¡ch nÃ o trÃ­ch vÃ  Ä‘Ã¡nh nhÃ£n luá»“ng tá»« file pcap cá»§a cÃ¡c bá»™ dá»¯ liá»‡u nhÆ° CIC IDS 2017 (https://www.unb.ca/cic/datasets/ids-2017.html) hay lÃ 
ToN-IoT (https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-ton-iot-Datasets/) khÃ´ng áº¡?",Xin chÃ o má»i ngÆ°á»i áº¡. Cho em/mÃ¬nh há»i lÃ  cÃ³ cÃ¡ch nÃ o trÃ­ch vÃ  Ä‘Ã¡nh nhÃ£n luá»“ng tá»« file pcap cá»§a cÃ¡c bá»™ dá»¯ liá»‡u nhÆ° CIC IDS 2017 (https://www.unb.ca/cic/datasets/ids-2017.html) hay lÃ  ToN-IoT (https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-ton-iot-Datasets/) khÃ´ng áº¡?,,,,,
"MÃ¬nh cáº§n viáº¿t 1 á»©ng dá»¥ng cÃ³ thá»ƒ giÃºp camera soi Ä‘á»ƒ xÃ¡c Ä‘á»‹nh váº­t thá»ƒ Ä‘Ã³ lÃ  gÃ¬? á»¨ng dung cho viá»‡c lá»c sáº£n pháº©m cá»§a cÃ´ng ty mÃ¬nh.
Báº¡n nÃ o cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c inbox bÃ¡o giÃ¡ giÃºp cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng?!
CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin.",MÃ¬nh cáº§n viáº¿t 1 á»©ng dá»¥ng cÃ³ thá»ƒ giÃºp camera soi Ä‘á»ƒ xÃ¡c Ä‘á»‹nh váº­t thá»ƒ Ä‘Ã³ lÃ  gÃ¬? á»¨ng dung cho viá»‡c lá»c sáº£n pháº©m cá»§a cÃ´ng ty mÃ¬nh. Báº¡n nÃ o cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c inbox bÃ¡o giÃ¡ giÃºp cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng?! CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin.,,,,,
"https://colab.research.google.com/drive/1grAiUD5hjlkxl5l0L1EaeaRCPPFR3NkL?usp=sharing
má»i ngÆ°á»i Æ¡i cho em há»i ngu há»i dáº¡i cÃ¡i. má»¥c tiÃªu cá»§a em lÃ  train data object detector. dÃ¹ng module cá»§a darknet. image = 6 labels = 13 , batch =  64, sub = 16 dÃ¹ng yolo v3. cho em há»i váº­y táº¡i sao khi train thÃ¬ á»Ÿ log nÃ³ ghi lÃ  71552 images váº­y. ^^ cÃ¡c tháº» yolo em Ä‘á»u Ä‘Ã£ chá»‰nh vá» 13 nhÆ° hÃ¬nh bÃªn dÆ°á»›i. cÃ¡i nÃ y em cáº§n sáº£n pháº©m chá»© em khÃ´ng há»c hÃ nh ká»¹ lÆ°á»¡ng má»i ngÆ°á»i biáº¿t giáº£i thÃ­ch giÃºp em phÃ¡t Ä‘á»ƒ em Ä‘á»¡ lo ngá»“i canh cháº¡y háº¿t 15 tiáº¿ng xong káº¿t quáº£ nhÆ° cá»©t thÃ¬ Ä‘Ãºng lÃ  quáº£i láº¯m Ã¡ ^^","https://colab.research.google.com/drive/1grAiUD5hjlkxl5l0L1EaeaRCPPFR3NkL?usp=sharing má»i ngÆ°á»i Æ¡i cho em há»i ngu há»i dáº¡i cÃ¡i. má»¥c tiÃªu cá»§a em lÃ  train data object detector. dÃ¹ng module cá»§a darknet. image = 6 labels = 13 , batch = 64, sub = 16 dÃ¹ng yolo v3. cho em há»i váº­y táº¡i sao khi train thÃ¬ á»Ÿ log nÃ³ ghi lÃ  71552 images váº­y. ^^ cÃ¡c tháº» yolo em Ä‘á»u Ä‘Ã£ chá»‰nh vá» 13 nhÆ° hÃ¬nh bÃªn dÆ°á»›i. cÃ¡i nÃ y em cáº§n sáº£n pháº©m chá»© em khÃ´ng há»c hÃ nh ká»¹ lÆ°á»¡ng má»i ngÆ°á»i biáº¿t giáº£i thÃ­ch giÃºp em phÃ¡t Ä‘á»ƒ em Ä‘á»¡ lo ngá»“i canh cháº¡y háº¿t 15 tiáº¿ng xong káº¿t quáº£ nhÆ° cá»©t thÃ¬ Ä‘Ãºng lÃ  quáº£i láº¯m Ã¡ ^^",,,,,
ChÃ o má»i ngÆ°á»i hiá»‡n táº¡i em má»›i tÃ¬m hiá»ƒu máº£ng xá»­ lÃ½ áº£nh sá»‘ nhÆ°ng bÆ°á»›c Ä‘áº§u cÃ i Ä‘áº·t OpenCv bá»‹ lá»—i nhÆ° tháº¿ nÃ y khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai biáº¿t cÃ¡ch sá»­a lá»—i khÃ´ng!,ChÃ o má»i ngÆ°á»i hiá»‡n táº¡i em má»›i tÃ¬m hiá»ƒu máº£ng xá»­ lÃ½ áº£nh sá»‘ nhÆ°ng bÆ°á»›c Ä‘áº§u cÃ i Ä‘áº·t OpenCv bá»‹ lá»—i nhÆ° tháº¿ nÃ y khÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ ai biáº¿t cÃ¡ch sá»­a lá»—i khÃ´ng!,,,,,
Em Ä‘ang lÃ m Ä‘á» tÃ i nÃ y má»i ngÆ°á»i chá»‰ em hÆ°á»›ng lÃ m vá»›i áº¡.Em xin cáº£m Æ¡n,Em Ä‘ang lÃ m Ä‘á» tÃ i nÃ y má»i ngÆ°á»i chá»‰ em hÆ°á»›ng lÃ m vá»›i áº¡.Em xin cáº£m Æ¡n,,,,,
"Colored ASCII generator (image2image and video2video) written in Python
Source code: https://github.com/uvipen/ASCII-generator",Colored ASCII generator (image2image and video2video) written in Python Source code: https://github.com/uvipen/ASCII-generator,,,,,
"#plot the error function
ChÃ o cÃ¡c anh chá»‹,
Sau khi train, test vá»›i SVM Ä‘Æ¡n giáº£n, thÃ¬ em cÃ³ mÃ´ hÃ¬nh, ypred, ytrue, AUC, AUPR... Em muá»‘n há»i lÃ  mÃ¬nh cáº§n váº½ hÃ m lá»—i trong Python thÃ¬ cÃ³ cÃ´ng cá»¥ há»— trá»£ ko áº¡ vÃ  cáº§n truyá»n tham sá»‘ nÃ o áº¡.
Em cÃ¡m Æ¡n má»i ngÆ°á»i!","the error function ChÃ o cÃ¡c anh chá»‹, Sau khi train, test vá»›i SVM Ä‘Æ¡n giáº£n, thÃ¬ em cÃ³ mÃ´ hÃ¬nh, ypred, ytrue, AUC, AUPR... Em muá»‘n há»i lÃ  mÃ¬nh cáº§n váº½ hÃ m lá»—i trong Python thÃ¬ cÃ³ cÃ´ng cá»¥ há»— trá»£ ko áº¡ vÃ  cáº§n truyá»n tham sá»‘ nÃ o áº¡. Em cÃ¡m Æ¡n má»i ngÆ°á»i!",#plot,,,,
"Hello cáº£ nhÃ ,
Em giáº£i quyáº¿t bÃ i toÃ¡n phÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng báº¥t ngá». vÃ­ dá»¥ : xe Ä‘á»©ng yÃªn, Ä‘á»™t ngá»™t tÄƒng tá»‘c. Cáº£ nhÃ  cho mÃ¬nh xin hÆ°á»›ng giáº£i quyáº¿t, thuáº­t ngá»¯ vá»›i áº¡.
Em cáº£m Æ¡n áº¡","Hello cáº£ nhÃ , Em giáº£i quyáº¿t bÃ i toÃ¡n phÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng báº¥t ngá». vÃ­ dá»¥ : xe Ä‘á»©ng yÃªn, Ä‘á»™t ngá»™t tÄƒng tá»‘c. Cáº£ nhÃ  cho mÃ¬nh xin hÆ°á»›ng giáº£i quyáº¿t, thuáº­t ngá»¯ vá»›i áº¡. Em cáº£m Æ¡n áº¡",,,,,
CÃ¡c bÃ¡c nÃ o cÃ³ biáº¿t nguá»“n láº¥y dataset cÃ¡c há»™i thoáº¡i viá»‡t nam cho em xin vá»›i áº¡ :D,CÃ¡c bÃ¡c nÃ o cÃ³ biáº¿t nguá»“n láº¥y dataset cÃ¡c há»™i thoáº¡i viá»‡t nam cho em xin vá»›i áº¡ :D,,,,,
Trong group mÃ¬nh cÃ³ ai Ä‘ang há»c ML mÃ  á»Ÿ ÄÃ  Náºµng khÃ´ng? MÃ¬nh Ä‘ang tÃ¬m báº¡n á»Ÿ gáº§n Ä‘á»ƒ láº­p team há»c,Trong group mÃ¬nh cÃ³ ai Ä‘ang há»c ML mÃ  á»Ÿ ÄÃ  Náºµng khÃ´ng? MÃ¬nh Ä‘ang tÃ¬m báº¡n á»Ÿ gáº§n Ä‘á»ƒ láº­p team há»c,,,,,
Anh em cÃ²n FA. Ráº£nh rá»•i thÃ¬ zo chat con con chatbot crush cá»§a mÃ¬nh nÃ³ thÃ´ng minh tÃ­ vá»›i.,Anh em cÃ²n FA. Ráº£nh rá»•i thÃ¬ zo chat con con chatbot crush cá»§a mÃ¬nh nÃ³ thÃ´ng minh tÃ­ vá»›i.,,,,,
"#kaggle #pytorch #cnn
Hi mn
- Chuyá»‡n lÃ  em Ä‘ang tÃ¬m káº¿t quáº£ cá»™t labels/target cá»§a táº­p dá»¯ liá»‡u TEST (test.csv) trong cuá»™c thi [siim-isic-melanoma-classification] trÃªn kaggle VÃ¬ cuá»™c thi nÃ y Ä‘Ã£ káº¿t thÃºc. KhÃ´ng biáº¿t lÃ  cÃ³ anh chá»‹ nÃ o tham gia vÃ  cÃ³ target/labels Ä‘Ã³ cho em xin áº¡.
Cáº£m Æ¡n anh chá»‹!
https://www.kaggle.com/c/siim-isic-melanoma-classification?fbclid=IwAR0UpQW3ftqcPyWmhigDy4rJvhDuvUFYpO8kRzSyqdIxQiRz5u8WYrVHtdE",Hi mn - Chuyá»‡n lÃ  em Ä‘ang tÃ¬m káº¿t quáº£ cá»™t labels/target cá»§a táº­p dá»¯ liá»‡u TEST (test.csv) trong cuá»™c thi [siim-isic-melanoma-classification] trÃªn kaggle VÃ¬ cuá»™c thi nÃ y Ä‘Ã£ káº¿t thÃºc. KhÃ´ng biáº¿t lÃ  cÃ³ anh chá»‹ nÃ o tham gia vÃ  cÃ³ target/labels Ä‘Ã³ cho em xin áº¡. Cáº£m Æ¡n anh chá»‹! https://www.kaggle.com/c/siim-isic-melanoma-classification?fbclid=IwAR0UpQW3ftqcPyWmhigDy4rJvhDuvUFYpO8kRzSyqdIxQiRz5u8WYrVHtdE,#kaggle	#pytorch	#cnn,,,,
"Hi má»i ngÆ°á»i,
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch chuáº©n Ä‘oÃ¡n bá»‡nh dá»±a trÃªn hÃ¬nh áº£nh, kiá»ƒu nhÆ° tháº¿ nÃ y: https://vingroup.net/tin-tuc-su-kien/bai-viet/2199/trien-khai-giai-phap-ai-vindr-trong-chan-doan-hinh-anh-y-te
Nhá» má»i ngÆ°á»i hÆ°á»›ng dáº«n gá»‹Ãºp mÃ¬nh má»™t sá»‘ tÃ i liá»‡u/video vá» Ä‘á»ƒ tÃ i nÃ y ? LÄ©nh vá»±c nÃ y cÃ³ tÃ i liá»‡u nÃ o kinh Ä‘iá»ƒn váº­y áº¡? MÃ¬nh search tháº¥y nhiá»u quÃ¡ mÃ  khÃ´ng biáº¿t tÃ i liá»‡u nÃ o á»•n nháº¥t áº¡
Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡. ","Hi má»i ngÆ°á»i, MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch chuáº©n Ä‘oÃ¡n bá»‡nh dá»±a trÃªn hÃ¬nh áº£nh, kiá»ƒu nhÆ° tháº¿ nÃ y: https://vingroup.net/tin-tuc-su-kien/bai-viet/2199/trien-khai-giai-phap-ai-vindr-trong-chan-doan-hinh-anh-y-te Nhá» má»i ngÆ°á»i hÆ°á»›ng dáº«n gá»‹Ãºp mÃ¬nh má»™t sá»‘ tÃ i liá»‡u/video vá» Ä‘á»ƒ tÃ i nÃ y ? LÄ©nh vá»±c nÃ y cÃ³ tÃ i liá»‡u nÃ o kinh Ä‘iá»ƒn váº­y áº¡? MÃ¬nh search tháº¥y nhiá»u quÃ¡ mÃ  khÃ´ng biáº¿t tÃ i liá»‡u nÃ o á»•n nháº¥t áº¡ Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u áº¡.",,,,,
"Chia sáº» vá»›i cÃ¡c báº¡n bÃ i viáº¿t cá»§a mÃ¬nh trÃªn medium.com. Trong bÃ i viáº¿t nÃ y, mÃ¬nh phÃ¢n tÃ­ch nhá»¯ng khÃ³ khÄƒn, thÃ¡ch thá»©c mÃ  doanh nghiá»‡p cÃ³ thá»ƒ gáº·p pháº£i khi váº­n hÃ nh vÃ  triá»ƒn khai mÃ´ hÃ¬nh ML ra mÃ´i trÆ°á»ng sáº£n pháº©m, vÃ  tá»•ng quan giáº£i phÃ¡p MLOps hiá»‡n Ä‘ang lÃ  xu hÆ°á»›ng Ä‘Æ°á»£c nhiá»u doanh nghiá»‡p vÃ  cÃ¡c cÃ¡ nhÃ¢n thá»±c hÃ nh ML quan tÃ¢m.
https://nghiacd.medium.com/duy-tr%C3%AC-v%E1%BA%ADn-h%C3%A0nh-m%C3%B4-h%C3%ACnh-machine-learning-kh%C3%B3-kh%C4%83n-th%C3%A1ch-th%E1%BB%A9c-v%C3%A0-gi%E1%BA%A3i-ph%C3%A1p-6b7b42743d78","Chia sáº» vá»›i cÃ¡c báº¡n bÃ i viáº¿t cá»§a mÃ¬nh trÃªn medium.com. Trong bÃ i viáº¿t nÃ y, mÃ¬nh phÃ¢n tÃ­ch nhá»¯ng khÃ³ khÄƒn, thÃ¡ch thá»©c mÃ  doanh nghiá»‡p cÃ³ thá»ƒ gáº·p pháº£i khi váº­n hÃ nh vÃ  triá»ƒn khai mÃ´ hÃ¬nh ML ra mÃ´i trÆ°á»ng sáº£n pháº©m, vÃ  tá»•ng quan giáº£i phÃ¡p MLOps hiá»‡n Ä‘ang lÃ  xu hÆ°á»›ng Ä‘Æ°á»£c nhiá»u doanh nghiá»‡p vÃ  cÃ¡c cÃ¡ nhÃ¢n thá»±c hÃ nh ML quan tÃ¢m. https://nghiacd.medium.com/duy-tr%C3%AC-v%E1%BA%ADn-h%C3%A0nh-m%C3%B4-h%C3%ACnh-machine-learning-kh%C3%B3-kh%C4%83n-th%C3%A1ch-th%E1%BB%A9c-v%C3%A0-gi%E1%BA%A3i-ph%C3%A1p-6b7b42743d78",,,,,
"Em Ä‘ang Ä‘á»c vá» máº¡ng inception v3 á»Ÿ trang
https://cloud.google.com/tpu/docs/inception-v3-advanced
Em nháº­n tháº¥y lÃ  á»Ÿ layer giá»¯a cÃ³ táº¡o ra má»™t output (áº£nh). Em khÃ´ng tháº¥y trong tÃ i liá»‡u cÃ³ nÃ³i vá» output nÃ y.
Váº­y output nÃ y cÃ³ tÃ¡c dá»¥ng gÃ¬ vÃ  sá»­ dá»¥ng trong nhá»¯ng trÆ°á»ng há»£p nÃ o
Em cáº£m Æ¡n áº¡",Em Ä‘ang Ä‘á»c vá» máº¡ng inception v3 á»Ÿ trang https://cloud.google.com/tpu/docs/inception-v3-advanced Em nháº­n tháº¥y lÃ  á»Ÿ layer giá»¯a cÃ³ táº¡o ra má»™t output (áº£nh). Em khÃ´ng tháº¥y trong tÃ i liá»‡u cÃ³ nÃ³i vá» output nÃ y. Váº­y output nÃ y cÃ³ tÃ¡c dá»¥ng gÃ¬ vÃ  sá»­ dá»¥ng trong nhá»¯ng trÆ°á»ng há»£p nÃ o Em cáº£m Æ¡n áº¡,,,,,
"Em Ä‘ang xá»­ lÃ­ má»™t bÃ i toÃ¡n text classification tiáº¿ng viá»‡t, tÆ°Æ¡ng tá»± bÃ i toÃ¡n Spam Classification khi nÃ³ cÃ³ 2 labels, táº­p dá»¯ liá»‡u khoáº£ng 4000 rows. Em cÃ³ dÃ¹ng nhiá»u thuáº­t toÃ¡n ML vÃ  nháº­n tháº¥y Naive Bayes cho káº¿t quáº£ tá»‘t nháº¥t, accuracy lÃ  83%. Cho e há»i cÃ¡c ac Ä‘Ã£ tá»«ng cÃ³ kinh nghiá»‡m xá»­ lÃ­ bÃ i toÃ¡n text classification tiáº¿ng viá»‡t, thÃ¬ ngoÃ i nhá»¯ng thuáº­t toÃ¡n ML thÃ¬ cÃ³ nhá»¯ng phÆ°Æ¡ng phÃ¡p Ä‘em láº¡i káº¿t quáº£ tá»‘t nháº¥t khÃ´ng áº¡? Em xin cáº£m Æ¡n.","Em Ä‘ang xá»­ lÃ­ má»™t bÃ i toÃ¡n text classification tiáº¿ng viá»‡t, tÆ°Æ¡ng tá»± bÃ i toÃ¡n Spam Classification khi nÃ³ cÃ³ 2 labels, táº­p dá»¯ liá»‡u khoáº£ng 4000 rows. Em cÃ³ dÃ¹ng nhiá»u thuáº­t toÃ¡n ML vÃ  nháº­n tháº¥y Naive Bayes cho káº¿t quáº£ tá»‘t nháº¥t, accuracy lÃ  83%. Cho e há»i cÃ¡c ac Ä‘Ã£ tá»«ng cÃ³ kinh nghiá»‡m xá»­ lÃ­ bÃ i toÃ¡n text classification tiáº¿ng viá»‡t, thÃ¬ ngoÃ i nhá»¯ng thuáº­t toÃ¡n ML thÃ¬ cÃ³ nhá»¯ng phÆ°Æ¡ng phÃ¡p Ä‘em láº¡i káº¿t quáº£ tá»‘t nháº¥t khÃ´ng áº¡? Em xin cáº£m Æ¡n.",,,,,
"BÃ i viáº¿t chia sáº» cá»§a mÃ¬nh vá» bÃ i toÃ¡n Key Information Extraction, trÃ­ch rÃºt thÃ´ng tin tá»« hÃ³a Ä‘Æ¡n vá»›i Graph Convolution Network ğŸ˜ hi vá»ng giÃºp Ã­ch cho cÃ¡c báº¡n ^^

#viblo","BÃ i viáº¿t chia sáº» cá»§a mÃ¬nh vá» bÃ i toÃ¡n Key Information Extraction, trÃ­ch rÃºt thÃ´ng tin tá»« hÃ³a Ä‘Æ¡n vá»›i Graph Convolution Network hi vá»ng giÃºp Ã­ch cho cÃ¡c báº¡n ^^",#viblo,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh tháº¥y cÃ³ 1 sá»‘ báº¡n trong nhÃ³m há»i vá» giáº£i phÃ¡p cháº¥m cÃ´ng, Ä‘iá»ƒm danh báº±ng nháº­n diá»‡n khuÃ´n máº·t, mÃ¬nh xin giá»›i thiá»‡u vá»›i cÃ¡c báº¡n HANET Ai Camera.
Hiá»‡n táº¡i bÃªn mÃ¬nh Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c tá»‘c Ä‘á»™ nhÆ° trong video, nháº­n cÃ¹ng lÃºc nhiá»u ngÆ°á»i, Ä‘eo kháº©u trang vÃ  di chuyá»ƒn nhanh. Nháº­n dáº¡ng offline, ngay cáº£ khi máº¥t káº¿t ná»‘i internet. VÃ  phÃ¡t hiá»‡n cháº¥m cÃ´ng báº±ng áº£nh.
BÃªn mÃ¬nh há»— trá»£ API cho cÃ¡c Ä‘á»‘i tÃ¡c cÃ¹ng phÃ¡t triá»ƒn giáº£i phÃ¡p.
TÃ i liá»‡u:
https://developers.hanet.ai/document
Camera giÃ¡: 3.5 triá»‡u.
á»ng kÃ­nh 2K
Ram 1GB
Wifi 2.4&5.8Ghz
EMMC 8Gb
LÆ°u trá»¯: 50.000 khuÃ´n máº·t.
TÃ­nh phÃ­ cloud lÆ°u trá»¯ video vÃ  sá»­ dá»¥ng FaceID
Chi tiáº¿t tham kháº£o:
https://hanet.com/hanet-ai-camera-m/
Ráº¥t mong Ä‘Æ°á»£c há»£p tÃ¡c cÃ¹ng phÃ¡t triá»ƒn!","ChÃ o cÃ¡c báº¡n, mÃ¬nh tháº¥y cÃ³ 1 sá»‘ báº¡n trong nhÃ³m há»i vá» giáº£i phÃ¡p cháº¥m cÃ´ng, Ä‘iá»ƒm danh báº±ng nháº­n diá»‡n khuÃ´n máº·t, mÃ¬nh xin giá»›i thiá»‡u vá»›i cÃ¡c báº¡n HANET Ai Camera. Hiá»‡n táº¡i bÃªn mÃ¬nh Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c tá»‘c Ä‘á»™ nhÆ° trong video, nháº­n cÃ¹ng lÃºc nhiá»u ngÆ°á»i, Ä‘eo kháº©u trang vÃ  di chuyá»ƒn nhanh. Nháº­n dáº¡ng offline, ngay cáº£ khi máº¥t káº¿t ná»‘i internet. VÃ  phÃ¡t hiá»‡n cháº¥m cÃ´ng báº±ng áº£nh. BÃªn mÃ¬nh há»— trá»£ API cho cÃ¡c Ä‘á»‘i tÃ¡c cÃ¹ng phÃ¡t triá»ƒn giáº£i phÃ¡p. TÃ i liá»‡u: https://developers.hanet.ai/document Camera giÃ¡: 3.5 triá»‡u. á»ng kÃ­nh 2K Ram 1GB Wifi 2.4&5.8Ghz EMMC 8Gb LÆ°u trá»¯: 50.000 khuÃ´n máº·t. TÃ­nh phÃ­ cloud lÆ°u trá»¯ video vÃ  sá»­ dá»¥ng FaceID Chi tiáº¿t tham kháº£o: https://hanet.com/hanet-ai-camera-m/ Ráº¥t mong Ä‘Æ°á»£c há»£p tÃ¡c cÃ¹ng phÃ¡t triá»ƒn!",,,,,
Má»i ngÆ°á»i Æ¡i cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ dÃ¹ng gradient descent Ä‘á»ƒ tÃ¬m Ä‘c global minimum cho function áº¡. E má»›i báº¯t Ä‘áº§u tá»± nghiÃªn cá»©u ML nÃªn chÆ°a rÃµ láº¯m vá» loss function vá»›i cÃ¡c library hay dÃ¹ng áº¡. Em chá»‰ biáº¿t dÃ¹ng basic python thÃ´i áº¡,Má»i ngÆ°á»i Æ¡i cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ dÃ¹ng gradient descent Ä‘á»ƒ tÃ¬m Ä‘c global minimum cho function áº¡. E má»›i báº¯t Ä‘áº§u tá»± nghiÃªn cá»©u ML nÃªn chÆ°a rÃµ láº¯m vá» loss function vá»›i cÃ¡c library hay dÃ¹ng áº¡. Em chá»‰ biáº¿t dÃ¹ng basic python thÃ´i áº¡,,,,,
"ChÃ o cÃ¡c bÃ¡c.
Chuyá»‡n lÃ  em Ä‘ang há»c cáº¥p 3 vÃ  muá»‘n tÃ¬m hiá»ƒu vá» Machine Learning thÃ¬ mÃ¬nh nÃªn há»c nhá»¯ng kiáº¿n thá»©c ná»n táº£ng toÃ¡n vÃ  láº­p trÃ¬nh nÃ o áº¡, táº¡i em cÃ³ Ä‘á»c thá»­ má»™t cuá»‘n vá» mÃ¡y há»c cá»§a ad mÃ  khá»±ng ngay tá»« vÃ i trang Ä‘áº§u ""Ã´n táº­p Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh"" vÃ¬ hÃ´ng hiá»ƒu gÃ¬ :""( hic
Mong cÃ¡c cao nhÃ¢n chá»‰ báº£o áº¡, e xin cáº£m Æ¡n :>","ChÃ o cÃ¡c bÃ¡c. Chuyá»‡n lÃ  em Ä‘ang há»c cáº¥p 3 vÃ  muá»‘n tÃ¬m hiá»ƒu vá» Machine Learning thÃ¬ mÃ¬nh nÃªn há»c nhá»¯ng kiáº¿n thá»©c ná»n táº£ng toÃ¡n vÃ  láº­p trÃ¬nh nÃ o áº¡, táº¡i em cÃ³ Ä‘á»c thá»­ má»™t cuá»‘n vá» mÃ¡y há»c cá»§a ad mÃ  khá»±ng ngay tá»« vÃ i trang Ä‘áº§u ""Ã´n táº­p Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh"" vÃ¬ hÃ´ng hiá»ƒu gÃ¬ :""( hic Mong cÃ¡c cao nhÃ¢n chá»‰ báº£o áº¡, e xin cáº£m Æ¡n :>",,,"#Q&A, #math, #machine_learning",,
"Em chÃ o cáº£ nhÃ  áº¡, hiá»‡n táº¡i táº­p training data cá»§a e cÃ³ khoáº£ng 2000 text loáº¡i nÃ y (á»Ÿ cÃ¡c trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, Ä‘áº¿m ngÆ°á»£c Ä‘á»ƒ mua hÃ ng). CÃ¡c anh chá»‹ cho e há»i lÃ  e nÃªn dÃ¹ng gÃ¬ Ä‘á»ƒ train Ä‘á»‘ng data nÃ y, Ä‘á»ƒ khi vÃ o má»™t trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ cÃ³ Ä‘áº¿m ngÆ°á»£c thÃ¬ e biáº¿t Ä‘Æ°á»£c lÃ  trang nÃ y cÃ³ Ä‘áº¿m váº­y áº¡?","Em chÃ o cáº£ nhÃ  áº¡, hiá»‡n táº¡i táº­p training data cá»§a e cÃ³ khoáº£ng 2000 text loáº¡i nÃ y (á»Ÿ cÃ¡c trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, Ä‘áº¿m ngÆ°á»£c Ä‘á»ƒ mua hÃ ng). CÃ¡c anh chá»‹ cho e há»i lÃ  e nÃªn dÃ¹ng gÃ¬ Ä‘á»ƒ train Ä‘á»‘ng data nÃ y, Ä‘á»ƒ khi vÃ o má»™t trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ cÃ³ Ä‘áº¿m ngÆ°á»£c thÃ¬ e biáº¿t Ä‘Æ°á»£c lÃ  trang nÃ y cÃ³ Ä‘áº¿m váº­y áº¡?",,,,,
,nan,,,,,
"[WiDS 2021 - updated]
Tiáº¿p ná»‘i thÃ´ng tin vá» chuá»—i sá»± kiá»‡n trong khuÃ´n khá»• WiDS 2021, nhÃ³m WiDS Vietnam gá»­i tá»›i cÃ¡c báº¡n thÃ´ng tin vá» webinar Fireside Chat 29/01/2021.
Ná»™i dung Datathon 2021 lÃ  xÃ¢y dá»±ng model dá»± Ä‘oÃ¡n xem má»™t bá»‡nh nhÃ¢n Ä‘Æ°á»£c chuyá»ƒn vÃ o phÃ²ng cáº¥p cá»©u cÃ³ tiá»n sá»­ máº¯c bá»‡nh tiá»ƒu Ä‘Æ°á»ng hay khÃ´ng, dá»±a trÃªn dá»¯ liá»‡u thu tháº­p trong 24h Ä‘áº§u tiÃªn. Äá»ƒ giÃºp cÃ¡c Ä‘á»™i thi bá»• sung kiáº¿n thá»©c vá» chuyÃªn mÃ´n vá» y khoa, phá»¥c vá»¥ cho viá»‡c xÃ¢y dá»±ng feature vÃ  tÄƒng hiá»‡u suáº¥t model, WiDS Stanford University tá»• chá»©c Webinar trá»±c tuyáº¿n vá»›i chá»§ Ä‘á» ""Medical history prediction: Predicting diabetes from ICU admission data"".
CÃ¡c speaker sáº½ Ä‘Ã¡nh giÃ¡ má»™t mÃ´ hÃ¬nh máº«u phÃ¢n loáº¡i (classification model) cÃ¡c loáº¡i bá»‡nh tiá»ƒu Ä‘Æ°á»ng tá»« bá»™ dá»¯ liá»‡u cá»§a datathon vÃ  cÃ¹ng trao Ä‘á»•i vá»›i ngÆ°á»i cÃ³ chuyÃªn mÃ´n vá» viá»‡c tá»‘i Æ°u mÃ´ hÃ¬nh.
Webinar khÃ´ng chá»‰ dÃ nh cho cÃ¡c team Ä‘ang dá»± thi mÃ  má»Ÿ rá»™ng tá»›i táº¥t cáº£ cÃ¡c báº¡n cÃ³ quan tÃ¢m tá»›i cháº©n Ä‘oÃ¡n, Ä‘iá»u trá»‹, vÃ  data science.
Speaker gá»“m:
Vani Mandava - Director of Data Science at Microsoft Research
Leo Anthony Celi MD MS MPH, MIT - Beth Israel Deaconess Medical Center
Roselyn Mateo MD MS - Rush University Medical Center
Sharada Kalanidhi - Stanford University
â° Thá»i gian: 23h00 Thá»© 6, ngÃ y 29/01/2021 (giá» Viá»‡t Nam).
ğŸ“ Link Ä‘Äƒng kÃ½: https://airtable.com/shrnv2FjiYnvXEmZQ
(Sau khi Ä‘Äƒng kÃ½, thÃ´ng tin login sáº½ Ä‘Æ°á»£c gá»­i trong vÃ²ng 24h trÆ°á»›c Webinar)
Náº¿u cÃ³ tháº¯c máº¯c trong quÃ¡ trÃ¬nh Ä‘Äƒng kÃ½ vÃ  dá»± thi Datathon 2021, báº¡n cÃ³ thá»ƒ liÃªn há»‡ vá»›i team WiDS Vietnam Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£.
#widsvietnam #wids
#datathon2021
#viettelgroup
__________________________
WOMEN IN DATA SCIENCE HANOI
Há»™i tháº£o Ä‘á»‹nh hÆ°á»›ng vÃ  truyá»n cáº£m há»©ng cho phá»¥ ná»¯ Viá»‡t Nam cÃ³ niá»m Ä‘am mÃª vá»›i ngÃ nh Khoa há»c dá»¯ liá»‡u vÃ  giÃºp káº¿t ná»‘i cÃ¡c Ä‘á»™i thi Ä‘áº¿n vá»›i cuá»™c thi WiDS Datathon.
â¤ Official fanpage:
https://www.facebook.com/Women-in-data-science-Vietnam-Wids-103440151734352/
â¤ Fanpage group:
https://www.facebook.com/groups/3744623902266580/
â¤ LinkedIn: https://www.linkedin.com/company/wids-hanoi/
â¤ Email: widshanoi@gmail.com
â¤ Hotline: 0345861051 (Tháº£o); 0973066876 (Háº¡nh)","[WiDS 2021 - updated] Tiáº¿p ná»‘i thÃ´ng tin vá» chuá»—i sá»± kiá»‡n trong khuÃ´n khá»• WiDS 2021, nhÃ³m WiDS Vietnam gá»­i tá»›i cÃ¡c báº¡n thÃ´ng tin vá» webinar Fireside Chat 29/01/2021. Ná»™i dung Datathon 2021 lÃ  xÃ¢y dá»±ng model dá»± Ä‘oÃ¡n xem má»™t bá»‡nh nhÃ¢n Ä‘Æ°á»£c chuyá»ƒn vÃ o phÃ²ng cáº¥p cá»©u cÃ³ tiá»n sá»­ máº¯c bá»‡nh tiá»ƒu Ä‘Æ°á»ng hay khÃ´ng, dá»±a trÃªn dá»¯ liá»‡u thu tháº­p trong 24h Ä‘áº§u tiÃªn. Äá»ƒ giÃºp cÃ¡c Ä‘á»™i thi bá»• sung kiáº¿n thá»©c vá» chuyÃªn mÃ´n vá» y khoa, phá»¥c vá»¥ cho viá»‡c xÃ¢y dá»±ng feature vÃ  tÄƒng hiá»‡u suáº¥t model, WiDS Stanford University tá»• chá»©c Webinar trá»±c tuyáº¿n vá»›i chá»§ Ä‘á» ""Medical history prediction: Predicting diabetes from ICU admission data"". CÃ¡c speaker sáº½ Ä‘Ã¡nh giÃ¡ má»™t mÃ´ hÃ¬nh máº«u phÃ¢n loáº¡i (classification model) cÃ¡c loáº¡i bá»‡nh tiá»ƒu Ä‘Æ°á»ng tá»« bá»™ dá»¯ liá»‡u cá»§a datathon vÃ  cÃ¹ng trao Ä‘á»•i vá»›i ngÆ°á»i cÃ³ chuyÃªn mÃ´n vá» viá»‡c tá»‘i Æ°u mÃ´ hÃ¬nh. Webinar khÃ´ng chá»‰ dÃ nh cho cÃ¡c team Ä‘ang dá»± thi mÃ  má»Ÿ rá»™ng tá»›i táº¥t cáº£ cÃ¡c báº¡n cÃ³ quan tÃ¢m tá»›i cháº©n Ä‘oÃ¡n, Ä‘iá»u trá»‹, vÃ  data science. Speaker gá»“m: Vani Mandava - Director of Data Science at Microsoft Research Leo Anthony Celi MD MS MPH, MIT - Beth Israel Deaconess Medical Center Roselyn Mateo MD MS - Rush University Medical Center Sharada Kalanidhi - Stanford University â° Thá»i gian: 23h00 Thá»© 6, ngÃ y 29/01/2021 (giá» Viá»‡t Nam). Link Ä‘Äƒng kÃ½: https://airtable.com/shrnv2FjiYnvXEmZQ (Sau khi Ä‘Äƒng kÃ½, thÃ´ng tin login sáº½ Ä‘Æ°á»£c gá»­i trong vÃ²ng 24h trÆ°á»›c Webinar) Náº¿u cÃ³ tháº¯c máº¯c trong quÃ¡ trÃ¬nh Ä‘Äƒng kÃ½ vÃ  dá»± thi Datathon 2021, báº¡n cÃ³ thá»ƒ liÃªn há»‡ vá»›i team WiDS Vietnam Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£. __________________________ WOMEN IN DATA SCIENCE HANOI Há»™i tháº£o Ä‘á»‹nh hÆ°á»›ng vÃ  truyá»n cáº£m há»©ng cho phá»¥ ná»¯ Viá»‡t Nam cÃ³ niá»m Ä‘am mÃª vá»›i ngÃ nh Khoa há»c dá»¯ liá»‡u vÃ  giÃºp káº¿t ná»‘i cÃ¡c Ä‘á»™i thi Ä‘áº¿n vá»›i cuá»™c thi WiDS Datathon. Official fanpage: https://www.facebook.com/Women-in-data-science-Vietnam-Wids-103440151734352/ Fanpage group: https://www.facebook.com/groups/3744623902266580/ LinkedIn: https://www.linkedin.com/company/wids-hanoi/ Email: widshanoi@gmail.com Hotline: 0345861051 (Tháº£o); 0973066876 (Háº¡nh)",#widsvietnam	#wids	#datathon2021	#viettelgroup,,,,
Mn cho e há»i BPE lÃ  gÃ¬ áº¡ vÃ  nÃ³ cÃ³ chá»©c nÄƒng giá»‘ng nhÆ° w2v khÃ´ng áº¡? E cáº£m Æ¡n,Mn cho e há»i BPE lÃ  gÃ¬ áº¡ vÃ  nÃ³ cÃ³ chá»©c nÄƒng giá»‘ng nhÆ° w2v khÃ´ng áº¡? E cáº£m Æ¡n,,,,,
,nan,,,,,
,nan,,,,,
"Em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p vá» camera NhÃ¢n diá»‡n hÃ nh Ä‘á»™ng giÃ¡m sÃ¡t trong nhÃ  báº±ng python Ä‘áº¿n giai Ä‘oáº¡n pre-training model báº±ng ResNets PyTorch, cho em há»i cÃ³ ai tá»«ng lÃ m vá» Ä‘á» tÃ i nÃ y cho em xin Ã­t tÃ i liá»‡u vá» cÃ¡ch pre-training model vá»›i áº¡, cÃ³ tiáº¿ng viá»‡t thÃ¬ cÃ ng tá»‘t áº¡ (only cpu - non gpu)","Em chÃ o má»i ngÆ°á»i áº¡, hiá»‡n táº¡i em Ä‘ang lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p vá» camera NhÃ¢n diá»‡n hÃ nh Ä‘á»™ng giÃ¡m sÃ¡t trong nhÃ  báº±ng python Ä‘áº¿n giai Ä‘oáº¡n pre-training model báº±ng ResNets PyTorch, cho em há»i cÃ³ ai tá»«ng lÃ m vá» Ä‘á» tÃ i nÃ y cho em xin Ã­t tÃ i liá»‡u vá» cÃ¡ch pre-training model vá»›i áº¡, cÃ³ tiáº¿ng viá»‡t thÃ¬ cÃ ng tá»‘t áº¡ (only cpu - non gpu)",,,,,
NhÃ³m mÃ¬nh cÃ³ cao nhÃ¢n nÃ o biáº¿t vá» láº­p trÃ¬nh plugin cho 3dsmax khÃ´ng nhá»‰. MÃ¬nh Ä‘ang muá»‘n há»£p tÃ¡c Ä‘á»ƒ láº­p 1 plugin trÃªn 3dsmax cho má»¥c Ä‘Ã­ch dá»± toÃ¡n ná»™i tháº¥t trÃªn ná»n táº£ng nháº­n diá»‡n hÃ¬nh áº£nh vÃ  váº­t liá»‡u.,NhÃ³m mÃ¬nh cÃ³ cao nhÃ¢n nÃ o biáº¿t vá» láº­p trÃ¬nh plugin cho 3dsmax khÃ´ng nhá»‰. MÃ¬nh Ä‘ang muá»‘n há»£p tÃ¡c Ä‘á»ƒ láº­p 1 plugin trÃªn 3dsmax cho má»¥c Ä‘Ã­ch dá»± toÃ¡n ná»™i tháº¥t trÃªn ná»n táº£ng nháº­n diá»‡n hÃ¬nh áº£nh vÃ  váº­t liá»‡u.,,,,,
"Xin chÃ o cÃ¡c báº¡n vÃ  cÃ¡c anh chá»‹,
MÃ¬nh xin phÃ©p chia sáº» vá»›i cÃ¡c báº¡n má»›i há»c Python má»™t sá»‘ video ngáº¯n, cÆ¡ báº£n vá» láº­p trÃ¬nh Python cho Khoa há»c Dá»¯ liá»‡u. NgÃ´n ngá»¯: tiáº¿ng Viá»‡t. 
https://www.facebook.com/184314072371636/posts/881926252610411/
#python #vicohub #vietacademy","Xin chÃ o cÃ¡c báº¡n vÃ  cÃ¡c anh chá»‹, MÃ¬nh xin phÃ©p chia sáº» vá»›i cÃ¡c báº¡n má»›i há»c Python má»™t sá»‘ video ngáº¯n, cÆ¡ báº£n vá» láº­p trÃ¬nh Python cho Khoa há»c Dá»¯ liá»‡u. NgÃ´n ngá»¯: tiáº¿ng Viá»‡t. https://www.facebook.com/184314072371636/posts/881926252610411/",#python	#vicohub	#vietacademy,,,,
"Dáº¡ em xin chia sáº» bÃ i phÃ¢n tÃ­ch dá»¯ liá»‡u nÃ y vá» PhÃ¢n loáº¡i bÃ¬nh luáº­n (Comments Clustering) trÃªn Youtube.
BÃ i viáº¿t sá»­ dá»¥ng trÆ°á»ng há»£p cá»¥ thá»ƒ lÃ  comment cá»§a US Presidential Debates, nhÆ°ng cÃ¡ch tiáº¿p cáº­n thÃ¬ cÃ³ thá»ƒ á»©ng dá»¥ng cho ráº¥t nhiá»u use cases khÃ¡c ná»¯a nhÆ°: Influencer sá»­ dá»¥ng Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c nhá»¯ng idea chÃ­nh trong sá»‘ hÃ ng ngÃ n comments nháº­n Ä‘Æ°á»£c vÃ  lÃ m video Ä‘á»ƒ tráº£ lá»i fan, hoáº·c cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng cho viá»‡c chÄƒm sÃ³c khÃ¡ch hÃ ng cá»§a doanh nghiá»‡p, tá»•ng há»£p Ã½ kiáº¿n tá»« survey, etc.","Dáº¡ em xin chia sáº» bÃ i phÃ¢n tÃ­ch dá»¯ liá»‡u nÃ y vá» PhÃ¢n loáº¡i bÃ¬nh luáº­n (Comments Clustering) trÃªn Youtube. BÃ i viáº¿t sá»­ dá»¥ng trÆ°á»ng há»£p cá»¥ thá»ƒ lÃ  comment cá»§a US Presidential Debates, nhÆ°ng cÃ¡ch tiáº¿p cáº­n thÃ¬ cÃ³ thá»ƒ á»©ng dá»¥ng cho ráº¥t nhiá»u use cases khÃ¡c ná»¯a nhÆ°: Influencer sá»­ dá»¥ng Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c nhá»¯ng idea chÃ­nh trong sá»‘ hÃ ng ngÃ n comments nháº­n Ä‘Æ°á»£c vÃ  lÃ m video Ä‘á»ƒ tráº£ lá»i fan, hoáº·c cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng cho viá»‡c chÄƒm sÃ³c khÃ¡ch hÃ ng cá»§a doanh nghiá»‡p, tá»•ng há»£p Ã½ kiáº¿n tá»« survey, etc.",,,,,
"#pytorch #ml
hi group,
KhÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o trong group tá»«ng Ä‘á»c qua cuá»‘n nÃ y, vÃ  thÆ° viá»‡n wtfml cá»§a tÃ¡c giáº£ khÃ´ng áº¡.
Em tÃ¬m ebook /pdf nÃ y( Ä‘Æ°á»£c thÃ¬ cÃ³ thá»ƒ share hoáº·c cho em xin :3)
CÅ©ng nhÆ° cáº§n tÃ¬m hiá»ƒu document cá»§a thÆ° viá»‡n ""wtfml""
Cáº£m Æ¡n mn.","hi group, KhÃ´ng biáº¿t cÃ³ anh chá»‹ nÃ o trong group tá»«ng Ä‘á»c qua cuá»‘n nÃ y, vÃ  thÆ° viá»‡n wtfml cá»§a tÃ¡c giáº£ khÃ´ng áº¡. Em tÃ¬m ebook /pdf nÃ y( Ä‘Æ°á»£c thÃ¬ cÃ³ thá»ƒ share hoáº·c cho em xin :3) CÅ©ng nhÆ° cáº§n tÃ¬m hiá»ƒu document cá»§a thÆ° viá»‡n ""wtfml"" Cáº£m Æ¡n mn.",#pytorch	#ml,,,,
"ChÃ o cÃ¡c bÃ¡c!
Em Ä‘ang tham kháº£o má»™t bÃ i bÃ¡o dá»± Ä‘oÃ¡n quá»¹ Ä‘áº¡o chuyá»ƒn Ä‘á»™ng cá»§a ngÆ°á»i ""Social LSTM: Human Trajectory Prediction in Crowded Spaces"". Code cá»§a bÃ i bÃ¡o Ä‘Æ°á»£c cung cáº¥p táº¡i https://github.com/quancore/social-lstm
Em Ä‘Ã£ Ä‘á»c vÃ  hiá»ƒu ná»™i dung bÃ i bÃ¡o, nhÆ°ng Ä‘ang khÃ³ khÄƒn trong viá»‡c hiá»‡n thá»±c hÃ³a nÃ³ trong thá»i gian thá»±c, cÃ³ bÃ¡c nÃ o Ä‘Ã£ visualize nÃ³ trÃªn video thÃ¬ cho em xin code Ä‘á»ƒ tham kháº£o Ä‘Æ°á»£c khÃ´ng.
CÃ¡m Æ¡n cÃ¡c bÃ¡c nhiá»u!","ChÃ o cÃ¡c bÃ¡c! Em Ä‘ang tham kháº£o má»™t bÃ i bÃ¡o dá»± Ä‘oÃ¡n quá»¹ Ä‘áº¡o chuyá»ƒn Ä‘á»™ng cá»§a ngÆ°á»i ""Social LSTM: Human Trajectory Prediction in Crowded Spaces"". Code cá»§a bÃ i bÃ¡o Ä‘Æ°á»£c cung cáº¥p táº¡i https://github.com/quancore/social-lstm Em Ä‘Ã£ Ä‘á»c vÃ  hiá»ƒu ná»™i dung bÃ i bÃ¡o, nhÆ°ng Ä‘ang khÃ³ khÄƒn trong viá»‡c hiá»‡n thá»±c hÃ³a nÃ³ trong thá»i gian thá»±c, cÃ³ bÃ¡c nÃ o Ä‘Ã£ visualize nÃ³ trÃªn video thÃ¬ cho em xin code Ä‘á»ƒ tham kháº£o Ä‘Æ°á»£c khÃ´ng. CÃ¡m Æ¡n cÃ¡c bÃ¡c nhiá»u!",,,,,
"Cho mÃ¬nh há»i, tháº§y mÃ¬nh giao bÃ i phÃ¢n loáº¡i vá» text thÃ¬ class mÃ¬nh bá»‹ imbalance náº·ng nhÆ° hÃ¬nh thÃ¬ lÃ m sao Ä‘á»ƒ balance Ä‘Æ°á»£c áº¡ ?","Cho mÃ¬nh há»i, tháº§y mÃ¬nh giao bÃ i phÃ¢n loáº¡i vá» text thÃ¬ class mÃ¬nh bá»‹ imbalance náº·ng nhÆ° hÃ¬nh thÃ¬ lÃ m sao Ä‘á»ƒ balance Ä‘Æ°á»£c áº¡ ?",,,,,
"ChÃ o má»i ngÆ°á»i, cháº£ lÃ  mÃ¬nh tÃ­nh mua Google Colab Pro, mÃ  khÃ´ng biáº¿t nÃ³ cÃ³ hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c á»Ÿ Viá»‡t Nam hay khÃ´ng. CÃ³ báº¡n nÃ o Ä‘Ã£ mua cÃ³ thá»ƒ thÃ´ng tin giÃºp mÃ¬nh vá»›i.","ChÃ o má»i ngÆ°á»i, cháº£ lÃ  mÃ¬nh tÃ­nh mua Google Colab Pro, mÃ  khÃ´ng biáº¿t nÃ³ cÃ³ hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c á»Ÿ Viá»‡t Nam hay khÃ´ng. CÃ³ báº¡n nÃ o Ä‘Ã£ mua cÃ³ thá»ƒ thÃ´ng tin giÃºp mÃ¬nh vá»›i.",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em tháº¥y Ã­t dá»¯ liá»‡u quÃ¡ hoáº·c dá»¯ liá»‡u phÃ¢n phá»‘i khÃ´ng Ä‘á»u dáº«n Ä‘áº¿n khi báº¡n chia train, val Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model sáº½ khÃ´ng chuáº©n, bá»‹ phiáº¿n diá»‡n (khÃ´ng dáº¡y model mÃ  váº«n báº¯t nÃ³ predict).
Do dÃ³ em nghiÃªn cá»©u thá»­ K-Fold Cross Validation vÃ  tiá»‡n luÃ´n em viáº¿t chÃºt chia sáº» cÃ¹ng cÃ¡c báº¡n!
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em chÃºt gÃ¬ Ä‘Ã³. Mong admin duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, em tháº¥y Ã­t dá»¯ liá»‡u quÃ¡ hoáº·c dá»¯ liá»‡u phÃ¢n phá»‘i khÃ´ng Ä‘á»u dáº«n Ä‘áº¿n khi báº¡n chia train, val Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model sáº½ khÃ´ng chuáº©n, bá»‹ phiáº¿n diá»‡n (khÃ´ng dáº¡y model mÃ  váº«n báº¯t nÃ³ predict). Do dÃ³ em nghiÃªn cá»©u thá»­ K-Fold Cross Validation vÃ  tiá»‡n luÃ´n em viáº¿t chÃºt chia sáº» cÃ¹ng cÃ¡c báº¡n! Hi vá»ng giÃºp Ä‘Æ°á»£c anh em chÃºt gÃ¬ Ä‘Ã³. Mong admin duyá»‡t bÃ i!",,,,,
"Xin phÃ©p admin cho share 1 sá»± kiá»‡n do cá»™ng Ä‘á»“ng nhá»¯ng ngÆ°á»i lÃ m vá» AI á»Ÿ Nháº­t báº£n tá»• chá»©c.
ÄÃ¢y lÃ  chÆ°Æ¡ng trÃ¬nh chia sáº» vá» á»©ng dá»¥ng cá»§a AI trong cÃ´ng nghiá»‡p do nhá»¯ng ngÆ°á»i Ä‘ang lÃ m viá»‡c trá»±c tiáº¿p chia sáº» vá» bÃ i toÃ¡n cÅ©ng nhÆ° khÃ³ khÄƒn thÃ¡ch thá»©c cá»§a nÃ³. Má»i má»i ngÆ°á»i cÃ¹ng tham gia vÃ  há»c há»i.",Xin phÃ©p admin cho share 1 sá»± kiá»‡n do cá»™ng Ä‘á»“ng nhá»¯ng ngÆ°á»i lÃ m vá» AI á»Ÿ Nháº­t báº£n tá»• chá»©c. ÄÃ¢y lÃ  chÆ°Æ¡ng trÃ¬nh chia sáº» vá» á»©ng dá»¥ng cá»§a AI trong cÃ´ng nghiá»‡p do nhá»¯ng ngÆ°á»i Ä‘ang lÃ m viá»‡c trá»±c tiáº¿p chia sáº» vá» bÃ i toÃ¡n cÅ©ng nhÆ° khÃ³ khÄƒn thÃ¡ch thá»©c cá»§a nÃ³. Má»i má»i ngÆ°á»i cÃ¹ng tham gia vÃ  há»c há»i.,,,,,
"ChÃ o má»i ngÆ°á»i
Em muá»‘n Ä‘Æ°á»£c há»i liá»‡u ML cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch cho subcribes trÃªn youtube, cá»¥ thá»ƒ má»¥c Ä‘Ã­ch chá»‰ lÃ  Ä‘á»ƒ tÄƒng subcribes. Liá»‡u vá»›i ML cÃ³ tricks gÃ¬ cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ cáº£i thiá»‡n Ä‘iá»u nÃ y chÆ°a áº¡!
E cáº£m Æ¡n má»i ngÆ°á»i áº¡!","ChÃ o má»i ngÆ°á»i Em muá»‘n Ä‘Æ°á»£c há»i liá»‡u ML cÃ³ thá»ƒ á»©ng dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch cho subcribes trÃªn youtube, cá»¥ thá»ƒ má»¥c Ä‘Ã­ch chá»‰ lÃ  Ä‘á»ƒ tÄƒng subcribes. Liá»‡u vá»›i ML cÃ³ tricks gÃ¬ cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ cáº£i thiá»‡n Ä‘iá»u nÃ y chÆ°a áº¡! E cáº£m Æ¡n má»i ngÆ°á»i áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, em cÃ³ má»™t bÃ i toÃ¡n vá» xá»­ lÃ½ áº£nh. Trong má»™t áº£nh cÃ³ nhiá»u vÃ¹ng mÃ u vÃ  máº­t Ä‘á»™ phÃ¢n bá»‘ pixel mÃ u trÃªn má»—i vÃ¹ng cÅ©ng khÃ¡c nhau. Em muá»‘n tÃ¬m máº­t Ä‘á»™ pixel cá»§a má»™t mÃ u hoáº·c má»™t dáº£i mÃ u phÃ¢n bá»‘ trÃªn má»™t vÃ¹ng cá»¥ thá»ƒ thÃ¬ cÃ³ thá»ƒ lÃ m cÃ¡ch nÃ o áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c viáº¿t cá»§a em áº¡.","ChÃ o má»i ngÆ°á»i áº¡, em cÃ³ má»™t bÃ i toÃ¡n vá» xá»­ lÃ½ áº£nh. Trong má»™t áº£nh cÃ³ nhiá»u vÃ¹ng mÃ u vÃ  máº­t Ä‘á»™ phÃ¢n bá»‘ pixel mÃ u trÃªn má»—i vÃ¹ng cÅ©ng khÃ¡c nhau. Em muá»‘n tÃ¬m máº­t Ä‘á»™ pixel cá»§a má»™t mÃ u hoáº·c má»™t dáº£i mÃ u phÃ¢n bá»‘ trÃªn má»™t vÃ¹ng cá»¥ thá»ƒ thÃ¬ cÃ³ thá»ƒ lÃ m cÃ¡ch nÃ o áº¡. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c viáº¿t cá»§a em áº¡.",,,,,
"#share
CÃ´ng cá»¥ plot neural network ra dáº¡ng Latex, gá»n nháº¹ vÃ  Ä‘áº¹p cho cÃ¡c bÃ i bÃ¡o cÃ¡o/ thuyáº¿t trÃ¬nh.","CÃ´ng cá»¥ plot neural network ra dáº¡ng Latex, gá»n nháº¹ vÃ  Ä‘áº¹p cho cÃ¡c bÃ i bÃ¡o cÃ¡o/ thuyáº¿t trÃ¬nh.",#share,,,,
"Em má»›i tÃ¬m hiá»ƒu Machine Learning Ä‘Æ°á»£c vÃ i thÃ¡ng, vÃ  vá»›i nhu cáº§u cÃ´ng viá»‡c e tÃ¬m hiá»ƒu cÃ¡c cÃ´ng nghá»‡ OCR. E cÃ³ tháº¯c máº¯c lÃ , táº¡i sao cÃ¡c cÃ´ng nghá»‡ OCR (open source dá»… tÃ¬m kiáº¿m trÃªn google) hiá»‡n nay Ä‘á»u lÃ  sá»± káº¿t há»£p giá»¯a CNN vÃ  RNN (hoáº·c máº¡nh hÆ¡n RNN nhÆ° LSTM, Transformer), váº­y tÃ¡c dá»¥ng cá»§a RNN trong quy trÃ¬nh OCR lÃ  gÃ¬ váº­y áº¡ ?","Em má»›i tÃ¬m hiá»ƒu Machine Learning Ä‘Æ°á»£c vÃ i thÃ¡ng, vÃ  vá»›i nhu cáº§u cÃ´ng viá»‡c e tÃ¬m hiá»ƒu cÃ¡c cÃ´ng nghá»‡ OCR. E cÃ³ tháº¯c máº¯c lÃ , táº¡i sao cÃ¡c cÃ´ng nghá»‡ OCR (open source dá»… tÃ¬m kiáº¿m trÃªn google) hiá»‡n nay Ä‘á»u lÃ  sá»± káº¿t há»£p giá»¯a CNN vÃ  RNN (hoáº·c máº¡nh hÆ¡n RNN nhÆ° LSTM, Transformer), váº­y tÃ¡c dá»¥ng cá»§a RNN trong quy trÃ¬nh OCR lÃ  gÃ¬ váº­y áº¡ ?",,,,,
"Xin chÃ o Anh/Chá»‹/Báº¡n,
Em báº¯t Ä‘áº§u há»c machine learning Ä‘á»ƒ apply cho longitudinal medical data. Dáº¡ anh/chá»‹/báº¡n cho em lá»i khuyÃªn thuáº­t toÃ¡n nÃ o tá»‘t Ä‘á»ƒ cáº£i thiá»‡n loáº¡i dá»¯ liá»‡u nÃ y áº¡? Cáº§n lÆ°u Ã½ Ä‘iá»u gÃ¬ khi train loáº¡i dá»¯ liá»‡u nÃ y? GiÃ¡o em cÅ©ng Ä‘Æ°a ra má»™t bÃ i toÃ¡n cho em vá» fusion of two cohorts, dáº¡ thÃ´ng thÆ°á»ng anh/chá»‹/báº¡n fusion nhÆ° tháº¿ nÃ o áº¡? Em cáº£m Æ¡n nhiá»u! ChÃºc má»i ngÆ°á»i ngÃ y má»›i vui váº».","Xin chÃ o Anh/Chá»‹/Báº¡n, Em báº¯t Ä‘áº§u há»c machine learning Ä‘á»ƒ apply cho longitudinal medical data. Dáº¡ anh/chá»‹/báº¡n cho em lá»i khuyÃªn thuáº­t toÃ¡n nÃ o tá»‘t Ä‘á»ƒ cáº£i thiá»‡n loáº¡i dá»¯ liá»‡u nÃ y áº¡? Cáº§n lÆ°u Ã½ Ä‘iá»u gÃ¬ khi train loáº¡i dá»¯ liá»‡u nÃ y? GiÃ¡o em cÅ©ng Ä‘Æ°a ra má»™t bÃ i toÃ¡n cho em vá» fusion of two cohorts, dáº¡ thÃ´ng thÆ°á»ng anh/chá»‹/báº¡n fusion nhÆ° tháº¿ nÃ o áº¡? Em cáº£m Æ¡n nhiá»u! ChÃºc má»i ngÆ°á»i ngÃ y má»›i vui váº».",,,,,
"ChÃ o admin vÃ  má»i ngÆ°á»i.
Em má»›i báº¯t Ä‘áº§u tá»± há»c python Ä‘Æ°á»£c má»™t thá»i gian, gá»‘c lÃ  dÃ¢n Äiá»‡n tá»­-Viá»…n thÃ´ng áº¡.
Em Ä‘ang dáº§n lÃ m quen vá»›i cÃ¡c giáº£i thuáº­t, mÃ´ hÃ¬nh toÃ¡n há»c vÃ  code trong ML nÃªn pháº§n nÃ y em sáº½ tiáº¿p tá»¥c tÃ¬m hiá»ƒu vÃ  khÃ´ng há»i quÃ¡ nhiá»u.
Hiá»‡n táº¡i em Ä‘ang triá»ƒn khai má»™t há»‡ thá»‘ng (cáº£ pháº§n cá»©ng vÃ  pháº§n má»m), trong Ä‘Ã³ pháº§n cá»©ng dÃ¹ng Ä‘á»ƒ thu vÃ  xá»­ lÃ½ dá»¯ liá»‡u (tá»« há»‡ cáº£m biáº¿n). Sau Ä‘Ã³ em sáº½ truyá»n khÃ´ng dÃ¢y lÃªn webserver lÃ m database (nguá»“n 1)
Má»™t nguá»“n dá»¯ liá»‡u khÃ¡c em sáº½ dÃ¹ng lÃ  tá»« má»™t trang web cho phÃ©p import data (nguá»“n 2).
Em Ä‘ang máº¯c á»Ÿ chá»— nÃ y (em Ä‘Ã£ search nhÆ°ng vÃ¬ kiáº¿n thá»©c vá» web háº¡n cháº¿ nÃªn chÆ°a cÃ³ nhiá»u káº¿t quáº£). BÃ¢y giá» em muá»‘n dÃ¹ng dá»¯ liá»‡u tá»« 2 nguá»“n trÃªn Ä‘á»ƒ xÃ¢y dá»±ng ML model thÃ¬ nÃªn tiáº¿p cáº­n nhÆ° nÃ o áº¡:
- Viáº¿t chÆ°Æ¡ng trÃ¬nh Ä‘á»c tá»« web (nguá»“n 2) vÃ  lÆ°u vá» webserver chá»©a data (nguá»“n 1) rá»“i má»›i báº¯t Ä‘áº§u build model.
Em Ä‘á»‹nh sáº½ lÃ m nhÆ° nÃ y vÃ¬ em mong muá»‘n xá»­ lÃ½ real time, tuy nhiÃªn chÆ°a thá»ƒ tÃ¬m ra cÃ´ng cá»¥ cá»¥ thá»ƒ áº¡.
Mong admin vÃ  má»i ngÆ°á»i giÃºp Ä‘á»¡, em cáº£m Æ¡n nhiá»u áº¡!","ChÃ o admin vÃ  má»i ngÆ°á»i. Em má»›i báº¯t Ä‘áº§u tá»± há»c python Ä‘Æ°á»£c má»™t thá»i gian, gá»‘c lÃ  dÃ¢n Äiá»‡n tá»­-Viá»…n thÃ´ng áº¡. Em Ä‘ang dáº§n lÃ m quen vá»›i cÃ¡c giáº£i thuáº­t, mÃ´ hÃ¬nh toÃ¡n há»c vÃ  code trong ML nÃªn pháº§n nÃ y em sáº½ tiáº¿p tá»¥c tÃ¬m hiá»ƒu vÃ  khÃ´ng há»i quÃ¡ nhiá»u. Hiá»‡n táº¡i em Ä‘ang triá»ƒn khai má»™t há»‡ thá»‘ng (cáº£ pháº§n cá»©ng vÃ  pháº§n má»m), trong Ä‘Ã³ pháº§n cá»©ng dÃ¹ng Ä‘á»ƒ thu vÃ  xá»­ lÃ½ dá»¯ liá»‡u (tá»« há»‡ cáº£m biáº¿n). Sau Ä‘Ã³ em sáº½ truyá»n khÃ´ng dÃ¢y lÃªn webserver lÃ m database (nguá»“n 1) Má»™t nguá»“n dá»¯ liá»‡u khÃ¡c em sáº½ dÃ¹ng lÃ  tá»« má»™t trang web cho phÃ©p import data (nguá»“n 2). Em Ä‘ang máº¯c á»Ÿ chá»— nÃ y (em Ä‘Ã£ search nhÆ°ng vÃ¬ kiáº¿n thá»©c vá» web háº¡n cháº¿ nÃªn chÆ°a cÃ³ nhiá»u káº¿t quáº£). BÃ¢y giá» em muá»‘n dÃ¹ng dá»¯ liá»‡u tá»« 2 nguá»“n trÃªn Ä‘á»ƒ xÃ¢y dá»±ng ML model thÃ¬ nÃªn tiáº¿p cáº­n nhÆ° nÃ o áº¡: - Viáº¿t chÆ°Æ¡ng trÃ¬nh Ä‘á»c tá»« web (nguá»“n 2) vÃ  lÆ°u vá» webserver chá»©a data (nguá»“n 1) rá»“i má»›i báº¯t Ä‘áº§u build model. Em Ä‘á»‹nh sáº½ lÃ m nhÆ° nÃ y vÃ¬ em mong muá»‘n xá»­ lÃ½ real time, tuy nhiÃªn chÆ°a thá»ƒ tÃ¬m ra cÃ´ng cá»¥ cá»¥ thá»ƒ áº¡. Mong admin vÃ  má»i ngÆ°á»i giÃºp Ä‘á»¡, em cáº£m Æ¡n nhiá»u áº¡!",,,,,
"ChÃ o mn,
Cho mÃ¬nh há»i náº¿u thu Ä‘Æ°á»£c loss train/val plot nhÆ° hÃ¬nh thÃ¬ mÃ¬nh nÃªn láº¥y weight á»Ÿ epoch nÃ o nhá»‰?
MÃ¬nh cÃ¡m Æ¡n,","ChÃ o mn, Cho mÃ¬nh há»i náº¿u thu Ä‘Æ°á»£c loss train/val plot nhÆ° hÃ¬nh thÃ¬ mÃ¬nh nÃªn láº¥y weight á»Ÿ epoch nÃ o nhá»‰? MÃ¬nh cÃ¡m Æ¡n,",,,,,
"ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m vá» bÃ i toÃ¡n nháº­n dáº¡ng áº£nh vá»›i 5 nhÃ£n, train data gá»“m 7721 áº£nh, test data gá»“m 856 áº£nh. Káº¿t quáº£ bÃªn dÆ°á»›i cho tháº¥y model bá»‹ overfiting. VÃ  má»™t sá»‘ nhÃ£n cho káº¿t quáº£ dá»± Ä‘oÃ¡n khÃ¡ tháº¥p (56 % vÃ  58 %). Theo nhÆ° em Ä‘Æ°á»£c biáº¿t thÃ¬ má»™t trong nhá»¯ng cÃ¡ch Ä‘á»ƒ cáº£i thiá»‡n cÃ¡c káº¿t quáº£ dá»± Ä‘oÃ¡n lÃ  thÃªm training data. KhÃ´ng biáº¿t nhá»¯ng Ä‘Ã¡nh giÃ¡ vÃ  nhá»¯ng hiá»ƒu biáº¿t nhÆ° váº­y cá»§a em cÃ³ Ä‘Ãºng khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i!!!","ChÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m vá» bÃ i toÃ¡n nháº­n dáº¡ng áº£nh vá»›i 5 nhÃ£n, train data gá»“m 7721 áº£nh, test data gá»“m 856 áº£nh. Káº¿t quáº£ bÃªn dÆ°á»›i cho tháº¥y model bá»‹ overfiting. VÃ  má»™t sá»‘ nhÃ£n cho káº¿t quáº£ dá»± Ä‘oÃ¡n khÃ¡ tháº¥p (56 % vÃ  58 %). Theo nhÆ° em Ä‘Æ°á»£c biáº¿t thÃ¬ má»™t trong nhá»¯ng cÃ¡ch Ä‘á»ƒ cáº£i thiá»‡n cÃ¡c káº¿t quáº£ dá»± Ä‘oÃ¡n lÃ  thÃªm training data. KhÃ´ng biáº¿t nhá»¯ng Ä‘Ã¡nh giÃ¡ vÃ  nhá»¯ng hiá»ƒu biáº¿t nhÆ° váº­y cá»§a em cÃ³ Ä‘Ãºng khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i!!!",,,,,
"ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn trÃ¡i ngÃ nh vÃ  Ä‘ang tá»± há»c vá» ML. Em Ä‘Ã£ hoÃ n thÃ nh khÃ³a Machine Learning vá»›i khÃ³a Deep Learning Specialization cá»§a tháº§y Andrew Ng, vÃ  khÃ³a Specialization Tensorflow trÃªn Coursera, em cÅ©ng xÃ¢y dá»±ng Ä‘Æ°á»£c má»™t vÃ i mÃ´ hÃ¬nh NN Ä‘Æ¡n giáº£n vá»›i cÃ¡c dataset cÃ³ sáºµn trÃªn máº¡ng.
CÃ¡c anh chá»‹ trong nghá» cho em há»i, AI engineer, cá»¥ thá»ƒ hÆ¡n á»Ÿ máº£ng computer vision cáº§n lÃ m nhá»¯ng gÃ¬ áº¡? Em cáº§n pháº£i cÃ³ thÃªm kiáº¿n thá»©c hay kinh nghiá»‡m vá» cÃ¡i gÃ¬ ná»¯a Ä‘á»ƒ xin Ä‘Æ°á»£c vá»‹ trÃ­ Internship/ Fresher váº­y áº¡? Kiá»ƒu nhÆ° pháº£i biáº¿t xÃ¢y dá»±ng 1 app/web AI hay sao áº¡?
Em cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, em lÃ  sinh viÃªn trÃ¡i ngÃ nh vÃ  Ä‘ang tá»± há»c vá» ML. Em Ä‘Ã£ hoÃ n thÃ nh khÃ³a Machine Learning vá»›i khÃ³a Deep Learning Specialization cá»§a tháº§y Andrew Ng, vÃ  khÃ³a Specialization Tensorflow trÃªn Coursera, em cÅ©ng xÃ¢y dá»±ng Ä‘Æ°á»£c má»™t vÃ i mÃ´ hÃ¬nh NN Ä‘Æ¡n giáº£n vá»›i cÃ¡c dataset cÃ³ sáºµn trÃªn máº¡ng. CÃ¡c anh chá»‹ trong nghá» cho em há»i, AI engineer, cá»¥ thá»ƒ hÆ¡n á»Ÿ máº£ng computer vision cáº§n lÃ m nhá»¯ng gÃ¬ áº¡? Em cáº§n pháº£i cÃ³ thÃªm kiáº¿n thá»©c hay kinh nghiá»‡m vá» cÃ¡i gÃ¬ ná»¯a Ä‘á»ƒ xin Ä‘Æ°á»£c vá»‹ trÃ­ Internship/ Fresher váº­y áº¡? Kiá»ƒu nhÆ° pháº£i biáº¿t xÃ¢y dá»±ng 1 app/web AI hay sao áº¡? Em cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i,
hiá»‡n mÃ¬nh Ä‘ang lÃ m vá» HPC, mÃ¬nh Ä‘ang ráº¥t cáº§n 1 anh expert cÃ³ thá»ƒ giÃºp mÃ¬nh cÃ i Ä‘áº·t SLURM, táº¡o 1 cluster Ä‘á»ƒ cháº¡y nextflow, quáº£n lÃ­ jobs trÃªn há»‡ thá»‘ng nhiá»u server ubuntu. CÃ¡c anh em cÃ³ ai cÃ³ kinh nghiá»‡m pháº§n nÃ y-slurm cÃ³ thá»ƒ giÃºp xin ib mÃ¬nh hoáº·c comment giÃºp vá»›i áº¡. BÃªn mÃ¬nh ráº¥t tá»‘t cho job nÃ y.
Hi all,
I am looking for an expert who can help me to install SLURM in my server ubuntu system, to build a cluster. Then I will integrate NEXTFLOW to slurm management. If you are available for this freelancer job, please dont hesitate to contact me. The rate for this job is very attractive!
thank you all,
Giang Vo: +84981419967","ChÃ o má»i ngÆ°á»i, hiá»‡n mÃ¬nh Ä‘ang lÃ m vá» HPC, mÃ¬nh Ä‘ang ráº¥t cáº§n 1 anh expert cÃ³ thá»ƒ giÃºp mÃ¬nh cÃ i Ä‘áº·t SLURM, táº¡o 1 cluster Ä‘á»ƒ cháº¡y nextflow, quáº£n lÃ­ jobs trÃªn há»‡ thá»‘ng nhiá»u server ubuntu. CÃ¡c anh em cÃ³ ai cÃ³ kinh nghiá»‡m pháº§n nÃ y-slurm cÃ³ thá»ƒ giÃºp xin ib mÃ¬nh hoáº·c comment giÃºp vá»›i áº¡. BÃªn mÃ¬nh ráº¥t tá»‘t cho job nÃ y. Hi all, I am looking for an expert who can help me to install SLURM in my server ubuntu system, to build a cluster. Then I will integrate NEXTFLOW to slurm management. If you are available for this freelancer job, please dont hesitate to contact me. The rate for this job is very attractive! thank you all, Giang Vo: +84981419967",,,,,
"Dear ALL, hiá»‡n mÃ¬nh cÃ³ 1 bÃ i toÃ¡n nhá» cÃ¡c báº¡n tÆ° váº¥n giÃºp ah, má»—i sáº£n pháº©m mÃ¬nh cÃ³ chá»¥p láº¡i áº£nh bá» máº·t, khi sáº£n pháº©m nÃ o bá»‹ lá»—i gÃ¬ Ä‘Ã³ bÃ¡m lÃªn bá» máº·t thÃ¬ áº£nh sáº½ cÃ³ cÃ¡c Ä‘á»‘m sÃ¡ng nhÆ° áº£nh Ä‘áº§u tiÃªn, tÃ¹y vÃ o hÃ¬nh dáº¡ng kÃ­ch thÆ°á»›c cá»§a Ä‘á»‘m sÃ¡ng mÃ  sáº½ quy Ä‘á»‹nh lÃ  lá»—i A, lá»—i B, lá»—i C gÃ¬ Ä‘Ã³, hoáº·c náº¿u bá» máº·t bá»‹ xÆ°á»›c má»™t Ä‘oáº¡n thÃ¬ sáº½ cÃ³ 1 vá»‡t sÃ¡ng má» trÃªn áº£nh nhÆ° áº£nh 2 cháº³ng háº¡n. MÃ¬nh muá»‘n Ã¡p dá»¥ng ML (image prediction) vÃ o bÃ i toÃ¡n nÃ y, xin cÃ¡c báº¡n cho Ã½ kiáº¿n vÃ  hÆ°á»›ng nÃ o cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c áº¡.","Dear ALL, hiá»‡n mÃ¬nh cÃ³ 1 bÃ i toÃ¡n nhá» cÃ¡c báº¡n tÆ° váº¥n giÃºp ah, má»—i sáº£n pháº©m mÃ¬nh cÃ³ chá»¥p láº¡i áº£nh bá» máº·t, khi sáº£n pháº©m nÃ o bá»‹ lá»—i gÃ¬ Ä‘Ã³ bÃ¡m lÃªn bá» máº·t thÃ¬ áº£nh sáº½ cÃ³ cÃ¡c Ä‘á»‘m sÃ¡ng nhÆ° áº£nh Ä‘áº§u tiÃªn, tÃ¹y vÃ o hÃ¬nh dáº¡ng kÃ­ch thÆ°á»›c cá»§a Ä‘á»‘m sÃ¡ng mÃ  sáº½ quy Ä‘á»‹nh lÃ  lá»—i A, lá»—i B, lá»—i C gÃ¬ Ä‘Ã³, hoáº·c náº¿u bá» máº·t bá»‹ xÆ°á»›c má»™t Ä‘oáº¡n thÃ¬ sáº½ cÃ³ 1 vá»‡t sÃ¡ng má» trÃªn áº£nh nhÆ° áº£nh 2 cháº³ng háº¡n. MÃ¬nh muá»‘n Ã¡p dá»¥ng ML (image prediction) vÃ o bÃ i toÃ¡n nÃ y, xin cÃ¡c báº¡n cho Ã½ kiáº¿n vÃ  hÆ°á»›ng nÃ o cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c áº¡.",,,,,
"[Chia sáº» cÆ¡ há»™i]
WiDS DATATHON 2021
Dear cÃ¡c báº¡n,
Nháº±m má»¥c Ä‘Ã­ch truyá»n cáº£m há»©ng vÃ  Ä‘á»‹nh hÆ°á»›ng giÃ¡o dá»¥c cho cÃ¡c nhÃ  khoa há»c dá»¯ liá»‡u táº¡i Viá»‡t Nam, Táº­p Ä‘oÃ n Viettel Ä‘á»“ng hÃ nh cÃ¹ng tá» chá»©c Women in Data Science thÃºc Ä‘áº©y cuá»™c thi Datathon vÃ  tá»• chá»©c Conference chuyÃªn sÃ¢u vá» Khoa há»c dá»¯ liá»‡u. Cuá»™c thi lÃ  cÆ¡ há»™i rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n báº£n thÃ¢n cho táº¥t cáº£ nhá»¯ng báº¡n yÃªu thÃ­ch cÃ´ng nghá»‡ vÃ  data science ğŸ˜ƒ
ğŸ‘‰ Láº­p team vÃ  sign up táº¡i https://www.kaggle.com/c/widsdatathon2021/
ğŸ†Giáº£i thÆ°á»Ÿng quy mÃ´ toÃ n cáº§u Datathon 2021:
ğŸ¥‡Giáº£i nháº¥t: $2,000 tiá»n máº·t
ğŸ¥ˆGiáº£i nhÃ¬: $1,500 tiá»n máº·t
ğŸ¥‰Giáº£i ba: $1,000 tiá»n máº·t
CÃ¡c má»‘c thá»i gian quan trá»ng cá»§a cuá»™c thi:
â€¢ NgÃ y 26/2/2021: Thá»i háº¡n táº­p há»£p nhÃ³m. ÄÃ¢y lÃ  ngÃ y cuá»‘i cÃ¹ng cÃ¡c Ä‘á»‘i thá»§ cÃ³ thá»ƒ tham gia hoáº·c táº­p há»£p nhÃ³m.
â€¢ NgÃ y 1/3/2021: Háº¡n ná»™p Kaggle cuá»‘i cÃ¹ng
â€¢ NgÃ y 8/3/2021: NgÆ°á»i chiáº¿n tháº¯ng trÃªn báº£n xáº¿p háº¡ng Datathon sáº½ Ä‘Æ°á»£c cÃ´ng bá»‘ táº¡i Há»™i nghá»‹ ToÃ n cáº§u WiDS.
ğŸ“ŒLÆ°u Ã½ lÃ :
â€¢ Team tá»‘i Ä‘a 4 ngÆ°á»i, trong Ä‘Ã³ 50% lÃ  ná»¯.
â€¢ Má»—i team Ä‘Æ°á»£c submit tá»‘i Ä‘a 15 vÃ  Ä‘Æ°á»£c lá»±a chá»n tá»‘i Ä‘a 2 káº¿t quáº£ submit tá»‘t nháº¥t Ä‘á»ƒ ná»™p láº§n cuá»‘i.
NgoÃ i ra, táº¡i Viá»‡t Nam, cÃ¡c Ä‘á»™i thi Ä‘áº¡t thÃ nh tÃ­ch cao sáº½ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tÆ°Æ¡ng xá»©ng.
ÄÃ¢y lÃ  cÆ¡ há»™i tuyá»‡t vá»i Ä‘á»ƒ rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n kháº£ nÄƒng cá»§a mÃ¬nh!
Team WiDS Vietnam sáº½ há»— trá»£ cÃ¡c báº¡n trong quÃ¡ trÃ¬nh dá»± thi!
#wids2021
#widsvietnam
#womenindatascience
#vietteldataanalyticscenter
_____________
WOMAN IN DATA SCIENCE HANOI
â¤ Official fanpage:
https://www.facebook.com/Women-in-data-science-Vietnam-Wids-103440151734352/
â¤ Fanpage group:
https://www.facebook.com/groups/3744623902266580/
â¤ LinkedIn: https://www.linkedin.com/company/wids-hanoi/
â¤ Email: widshanoi@gmail.com","[Chia sáº» cÆ¡ há»™i] WiDS DATATHON 2021 Dear cÃ¡c báº¡n, Nháº±m má»¥c Ä‘Ã­ch truyá»n cáº£m há»©ng vÃ  Ä‘á»‹nh hÆ°á»›ng giÃ¡o dá»¥c cho cÃ¡c nhÃ  khoa há»c dá»¯ liá»‡u táº¡i Viá»‡t Nam, Táº­p Ä‘oÃ n Viettel Ä‘á»“ng hÃ nh cÃ¹ng tá» chá»©c Women in Data Science thÃºc Ä‘áº©y cuá»™c thi Datathon vÃ  tá»• chá»©c Conference chuyÃªn sÃ¢u vá» Khoa há»c dá»¯ liá»‡u. Cuá»™c thi lÃ  cÆ¡ há»™i rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n báº£n thÃ¢n cho táº¥t cáº£ nhá»¯ng báº¡n yÃªu thÃ­ch cÃ´ng nghá»‡ vÃ  data science Láº­p team vÃ  sign up táº¡i https://www.kaggle.com/c/widsdatathon2021/ Giáº£i thÆ°á»Ÿng quy mÃ´ toÃ n cáº§u Datathon 2021: Giáº£i nháº¥t: $2,000 tiá»n máº·t Giáº£i nhÃ¬: $1,500 tiá»n máº·t Giáº£i ba: $1,000 tiá»n máº·t CÃ¡c má»‘c thá»i gian quan trá»ng cá»§a cuá»™c thi: â€¢ NgÃ y 26/2/2021: Thá»i háº¡n táº­p há»£p nhÃ³m. ÄÃ¢y lÃ  ngÃ y cuá»‘i cÃ¹ng cÃ¡c Ä‘á»‘i thá»§ cÃ³ thá»ƒ tham gia hoáº·c táº­p há»£p nhÃ³m. â€¢ NgÃ y 1/3/2021: Háº¡n ná»™p Kaggle cuá»‘i cÃ¹ng â€¢ NgÃ y 8/3/2021: NgÆ°á»i chiáº¿n tháº¯ng trÃªn báº£n xáº¿p háº¡ng Datathon sáº½ Ä‘Æ°á»£c cÃ´ng bá»‘ táº¡i Há»™i nghá»‹ ToÃ n cáº§u WiDS. LÆ°u Ã½ lÃ : â€¢ Team tá»‘i Ä‘a 4 ngÆ°á»i, trong Ä‘Ã³ 50% lÃ  ná»¯. â€¢ Má»—i team Ä‘Æ°á»£c submit tá»‘i Ä‘a 15 vÃ  Ä‘Æ°á»£c lá»±a chá»n tá»‘i Ä‘a 2 káº¿t quáº£ submit tá»‘t nháº¥t Ä‘á»ƒ ná»™p láº§n cuá»‘i. NgoÃ i ra, táº¡i Viá»‡t Nam, cÃ¡c Ä‘á»™i thi Ä‘áº¡t thÃ nh tÃ­ch cao sáº½ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tÆ°Æ¡ng xá»©ng. ÄÃ¢y lÃ  cÆ¡ há»™i tuyá»‡t vá»i Ä‘á»ƒ rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n kháº£ nÄƒng cá»§a mÃ¬nh! Team WiDS Vietnam sáº½ há»— trá»£ cÃ¡c báº¡n trong quÃ¡ trÃ¬nh dá»± thi! _____________ WOMAN IN DATA SCIENCE HANOI Official fanpage: https://www.facebook.com/Women-in-data-science-Vietnam-Wids-103440151734352/ Fanpage group: https://www.facebook.com/groups/3744623902266580/ LinkedIn: https://www.linkedin.com/company/wids-hanoi/ Email: widshanoi@gmail.com",#wids2021	#widsvietnam	#womenindatascience	#vietteldataanalyticscenter,,,,
"[Chia sáº» cÆ¡ há»™i]
WiDS DATATHON 2021
Nháº±m má»¥c Ä‘Ã­ch truyá»n cáº£m há»©ng vÃ  giÃ¡o dá»¥c hÆ°á»›ng nghiá»‡p cho cÃ¡c nhÃ  khoa há»c dá»¯ liá»‡u táº¡i Viá»‡t Nam, Táº­p Ä‘oÃ n Viettel Ä‘á»“ng hÃ nh cÃ¹ng tá»• chá»©c Women in Data Science thÃºc Ä‘áº©y cuá»™c thi Datathon vÃ  Conference chuyÃªn sÃ¢u vá» Khoa há»c dá»¯ liá»‡u. Cuá»™c thi lÃ  cÆ¡ há»™i rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n báº£n thÃ¢n cho táº¥t cáº£ nhá»¯ng báº¡n yÃªu thÃ­ch cÃ´ng nghá»‡ vÃ  data science ğŸ˜ƒ
ğŸ‘‰ Láº­p team vÃ  sign up táº¡i https://www.kaggle.com/c/widsdatathon2021/
ğŸ†Giáº£i thÆ°á»Ÿng quy mÃ´ toÃ n cáº§u Datathon 2021:
ğŸ¥‡Giáº£i nháº¥t: $2,000 tiá»n máº·t
ğŸ¥ˆGiáº£i nhÃ¬: $1,500 tiá»n máº·t
ğŸ¥‰Giáº£i ba: $1,000 tiá»n máº·t
CÃ¡c má»‘c thá»i gian quan trá»ng cá»§a cuá»™c thi:
â€¢ NgÃ y 26/2/2021: Thá»i háº¡n táº­p há»£p nhÃ³m. ÄÃ¢y lÃ  ngÃ y cuá»‘i cÃ¹ng cÃ¡c Ä‘á»‘i thá»§ cÃ³ thá»ƒ tham gia hoáº·c táº­p há»£p nhÃ³m.
â€¢ NgÃ y 1/3/2021: Háº¡n ná»™p Kaggle cuá»‘i cÃ¹ng
â€¢ NgÃ y 8/3/2021: NgÆ°á»i chiáº¿n tháº¯ng trÃªn báº£n xáº¿p háº¡ng Datathon sáº½ Ä‘Æ°á»£c cÃ´ng bá»‘ táº¡i Há»™i nghá»‹ ToÃ n cáº§u WiDS.
ğŸ“ŒLÆ°u Ã½ lÃ :
â€¢ Team tá»‘i Ä‘a 4 ngÆ°á»i, trong Ä‘Ã³ 50% lÃ  ná»¯.
â€¢ Má»—i team Ä‘Æ°á»£c submit tá»‘i Ä‘a 15 láº§n/ngÃ y cho Ä‘áº¿n thá»i Ä‘iá»ƒm deadline 1/3/2021 vÃ  Ä‘Æ°á»£c lá»±a chá»n tá»‘i Ä‘a 2 káº¿t quáº£ submit tá»‘t nháº¥t Ä‘á»ƒ ná»™p láº§n cuá»‘i.
NgoÃ i ra, táº¡i Viá»‡t Nam, cÃ¡c Ä‘á»™i thi Ä‘áº¡t thÃ nh tÃ­ch cao sáº½ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tÆ°Æ¡ng xá»©ng.
ÄÃ¢y lÃ  cÆ¡ há»™i tuyá»‡t vá»i Ä‘á»ƒ rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n kháº£ nÄƒng cá»§a mÃ¬nh!
Team WiDS Vietnam sáº½ há»— trá»£ cÃ¡c báº¡n trong quÃ¡ trÃ¬nh dá»± thi!
#wids2021
#widsvietnam
#womenindatascience
#vietteldataanalyticscenter
_____________
WOMEN IN DATA SCIENCE HANOI
â¤ Official fanpage:
https://www.facebook.com/Women-in-data-science-Vietnam-Wids-103440151734352/
â¤ Fanpage group:
https://www.facebook.com/groups/3744623902266580/
â¤ LinkedIn: https://www.linkedin.com/company/wids-hanoi/
â¤ Email: widshanoi@gmail.com","[Chia sáº» cÆ¡ há»™i] WiDS DATATHON 2021 Nháº±m má»¥c Ä‘Ã­ch truyá»n cáº£m há»©ng vÃ  giÃ¡o dá»¥c hÆ°á»›ng nghiá»‡p cho cÃ¡c nhÃ  khoa há»c dá»¯ liá»‡u táº¡i Viá»‡t Nam, Táº­p Ä‘oÃ n Viettel Ä‘á»“ng hÃ nh cÃ¹ng tá»• chá»©c Women in Data Science thÃºc Ä‘áº©y cuá»™c thi Datathon vÃ  Conference chuyÃªn sÃ¢u vá» Khoa há»c dá»¯ liá»‡u. Cuá»™c thi lÃ  cÆ¡ há»™i rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n báº£n thÃ¢n cho táº¥t cáº£ nhá»¯ng báº¡n yÃªu thÃ­ch cÃ´ng nghá»‡ vÃ  data science Láº­p team vÃ  sign up táº¡i https://www.kaggle.com/c/widsdatathon2021/ Giáº£i thÆ°á»Ÿng quy mÃ´ toÃ n cáº§u Datathon 2021: Giáº£i nháº¥t: $2,000 tiá»n máº·t Giáº£i nhÃ¬: $1,500 tiá»n máº·t Giáº£i ba: $1,000 tiá»n máº·t CÃ¡c má»‘c thá»i gian quan trá»ng cá»§a cuá»™c thi: â€¢ NgÃ y 26/2/2021: Thá»i háº¡n táº­p há»£p nhÃ³m. ÄÃ¢y lÃ  ngÃ y cuá»‘i cÃ¹ng cÃ¡c Ä‘á»‘i thá»§ cÃ³ thá»ƒ tham gia hoáº·c táº­p há»£p nhÃ³m. â€¢ NgÃ y 1/3/2021: Háº¡n ná»™p Kaggle cuá»‘i cÃ¹ng â€¢ NgÃ y 8/3/2021: NgÆ°á»i chiáº¿n tháº¯ng trÃªn báº£n xáº¿p háº¡ng Datathon sáº½ Ä‘Æ°á»£c cÃ´ng bá»‘ táº¡i Há»™i nghá»‹ ToÃ n cáº§u WiDS. LÆ°u Ã½ lÃ : â€¢ Team tá»‘i Ä‘a 4 ngÆ°á»i, trong Ä‘Ã³ 50% lÃ  ná»¯. â€¢ Má»—i team Ä‘Æ°á»£c submit tá»‘i Ä‘a 15 láº§n/ngÃ y cho Ä‘áº¿n thá»i Ä‘iá»ƒm deadline 1/3/2021 vÃ  Ä‘Æ°á»£c lá»±a chá»n tá»‘i Ä‘a 2 káº¿t quáº£ submit tá»‘t nháº¥t Ä‘á»ƒ ná»™p láº§n cuá»‘i. NgoÃ i ra, táº¡i Viá»‡t Nam, cÃ¡c Ä‘á»™i thi Ä‘áº¡t thÃ nh tÃ­ch cao sáº½ nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng tÆ°Æ¡ng xá»©ng. ÄÃ¢y lÃ  cÆ¡ há»™i tuyá»‡t vá»i Ä‘á»ƒ rÃ¨n luyá»‡n vÃ  thá»ƒ hiá»‡n kháº£ nÄƒng cá»§a mÃ¬nh! Team WiDS Vietnam sáº½ há»— trá»£ cÃ¡c báº¡n trong quÃ¡ trÃ¬nh dá»± thi! _____________ WOMEN IN DATA SCIENCE HANOI Official fanpage: https://www.facebook.com/Women-in-data-science-Vietnam-Wids-103440151734352/ Fanpage group: https://www.facebook.com/groups/3744623902266580/ LinkedIn: https://www.linkedin.com/company/wids-hanoi/ Email: widshanoi@gmail.com",#wids2021	#widsvietnam	#womenindatascience	#vietteldataanalyticscenter,,,,
"CÃ¡c anh/chá»‹ cho em há»i thÄƒm vá» viá»‡c Ä‘Äƒng kÃ½ bá»™ dá»¯ liá»‡u VLSP. Em vÃ o trang web chÃ­nh lÃ  https://vlsp.org.vn/ thÃ¬ khÃ´ng truy cáº­p Ä‘Æ°á»£c. Váº­y cÃ³ cÃ¡ch nÃ o khÃ¡c khÃ´ng áº¡? Em cáº£m Æ¡n nhiá»u áº¡.
Edit: Web má»Ÿ láº¡i rá»“i áº¡, em cáº£m Æ¡n má»i ngÆ°á»i.","CÃ¡c anh/chá»‹ cho em há»i thÄƒm vá» viá»‡c Ä‘Äƒng kÃ½ bá»™ dá»¯ liá»‡u VLSP. Em vÃ o trang web chÃ­nh lÃ  https://vlsp.org.vn/ thÃ¬ khÃ´ng truy cáº­p Ä‘Æ°á»£c. Váº­y cÃ³ cÃ¡ch nÃ o khÃ¡c khÃ´ng áº¡? Em cáº£m Æ¡n nhiá»u áº¡. Edit: Web má»Ÿ láº¡i rá»“i áº¡, em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Xin phÃ©p Admin, mÃ¬nh lÃ  thÃ nh viÃªn má»›i vÃ  tháº­t sá»± khÃ´ng pháº£i lÃ  dÃ¢n cÃ´ng nghá»‡ thÃ´ng tin (mÃ¬nh lÃ m bÃªn máº£ng cÆ¡ khÃ­ cháº¿ táº¡o mÃ¡y) vÃ  giá» cÃ´ng viá»‡c báº¯t buá»™c pháº£i xá»­ lÃ½ má»™t vÃ i sá»‘ liá»‡u thá»±c nghiá»‡m, mÃ¬nh Ä‘Ã£ gáº·p khÃ³ khÄƒn vÃ  mong Ä‘Æ°a bÃ i lÃªn Ä‘Ã¢y Ä‘á»ƒ xin Ä‘Æ°á»£c nhá»¯ng Ã½ kiáº¿n trá»£ giÃºp mÃ¬nh.
Sau khi mÃ´ phá»ng cÃ¡c tÃ­nh toÃ¡n váº­t lÃ½ cá»§a mÃ¬nh, mÃ¬nh Ä‘Ã£ cÃ³ má»™t báº£ng sá»‘ liá»‡u gá»“m cÃ³ 144 datasets trong tá»‡p ketqua.txt; mÃ¬nh chá»‰ quan tÃ¢m 2 cá»™t Ä‘áº§u vÃ o thá»© hai (X1) vÃ  thá»© ba (X2) trong file nÃ y; vÃ  tÆ°Æ¡ng á»©ng mÃ¬nh chá»‰ quan tÃ¢m cá»™t thá»© tÆ° ( Y) lÃ  káº¿t quáº£ Ä‘áº§u ra cá»§a mÃ¬nh. Tá»©c lÃ : cá»™t 4 lÃ  hÃ m phá»¥ thuá»™c vÃ o cá»™t 2 vÃ  cá»™t 3; hay: Y=f(X1,X2).
Giá» mÃ¬nh muá»‘n xÃ¢y dá»±ng má»™t Neural Network Ä‘á»ƒ xá»­ lÃ½ bá»™ sá»‘ liá»‡u nÃ y, mÃ¬nh dÃ¹ng Python vá»›i thÆ° viá»‡n keras káº¿t há»£p vá»›i numpy Ä‘á»ƒ táº¡o Neural Network (code file mÃ¬nh cÃ³ Ä‘Ã­nh kÃ¨m). TÆ°á»Ÿng chá»«ng ráº¥t Ä‘Æ¡n giáº£n nhÆ°ng nÃ³ tháº­t khÃ³ khÄƒn vÃ¬ viá»‡c lá»±a chá»n sá»‘ hidden layers cho máº¡ng vÃ  Ä‘áº·c biá»‡t lÃ  viá»‡c lá»±a chá»n cÃ¡c activation function tÆ°Æ¡ng á»©ng ! Trong code file mÃ¬nh trÃ¬nh bÃ y máº¡ng noron gá»“m: 2 Ä‘áº§u vÃ o, má»™t Ä‘áº§u ra vÃ  hai lá»›p áº©n: lá»›p áº©n 1 cÃ³ 12 noron, lá»›p áº©n 2 cÃ³ 8 noron. NhÆ°ng mÃ¬nh cháº¡y vÃ  tháº­t sá»± khÃ´ng thu Ä‘Æ°á»£c káº¿t quáº£ phÃ¹ há»£p vá»›i bá»™ sá»‘ liá»‡u Ä‘Ã£ chá»‰ Ä‘á»‹nh.
MÃ¬nh mong cÃ¡c báº¡n giÃºp mÃ¬nh hai váº¥n Ä‘á» sau:
Lá»±a chá»n sá»‘ lá»›p áº©n cÅ©ng nhÆ° sá»‘ neuron cá»§a tá»«ng lá»›p Ä‘á»ƒ há»£p lÃ½ cho káº¿t quáº£ tÃ­nh toÃ¡n (nÃ¢ng cao accuracy cá»§a bÃ i toÃ¡n, hiá»‡n táº¡i nÃ³ Ä‘ang lÃ  0, tá»©c lÃ  khÃ´ng Ä‘áº¡t yÃªu cáº§u);
Lá»±a chá»n activation functions tÆ°Æ¡ng á»©ng.
MÃ¬nh mong Ä‘Æ°á»£c trá»£ giÃºp sá»›m. Xin cáº£m Æ¡n áº¡.
Code file:
https://www.mediafire.com/file/kzdxvckqrmbjxg1/bTest.py/file
Data file:
https://www.mediafire.com/file/37k8i4e540uq2uv/Ketqua.txt/file","Xin phÃ©p Admin, mÃ¬nh lÃ  thÃ nh viÃªn má»›i vÃ  tháº­t sá»± khÃ´ng pháº£i lÃ  dÃ¢n cÃ´ng nghá»‡ thÃ´ng tin (mÃ¬nh lÃ m bÃªn máº£ng cÆ¡ khÃ­ cháº¿ táº¡o mÃ¡y) vÃ  giá» cÃ´ng viá»‡c báº¯t buá»™c pháº£i xá»­ lÃ½ má»™t vÃ i sá»‘ liá»‡u thá»±c nghiá»‡m, mÃ¬nh Ä‘Ã£ gáº·p khÃ³ khÄƒn vÃ  mong Ä‘Æ°a bÃ i lÃªn Ä‘Ã¢y Ä‘á»ƒ xin Ä‘Æ°á»£c nhá»¯ng Ã½ kiáº¿n trá»£ giÃºp mÃ¬nh. Sau khi mÃ´ phá»ng cÃ¡c tÃ­nh toÃ¡n váº­t lÃ½ cá»§a mÃ¬nh, mÃ¬nh Ä‘Ã£ cÃ³ má»™t báº£ng sá»‘ liá»‡u gá»“m cÃ³ 144 datasets trong tá»‡p ketqua.txt; mÃ¬nh chá»‰ quan tÃ¢m 2 cá»™t Ä‘áº§u vÃ o thá»© hai (X1) vÃ  thá»© ba (X2) trong file nÃ y; vÃ  tÆ°Æ¡ng á»©ng mÃ¬nh chá»‰ quan tÃ¢m cá»™t thá»© tÆ° ( Y) lÃ  káº¿t quáº£ Ä‘áº§u ra cá»§a mÃ¬nh. Tá»©c lÃ : cá»™t 4 lÃ  hÃ m phá»¥ thuá»™c vÃ o cá»™t 2 vÃ  cá»™t 3; hay: Y=f(X1,X2). Giá» mÃ¬nh muá»‘n xÃ¢y dá»±ng má»™t Neural Network Ä‘á»ƒ xá»­ lÃ½ bá»™ sá»‘ liá»‡u nÃ y, mÃ¬nh dÃ¹ng Python vá»›i thÆ° viá»‡n keras káº¿t há»£p vá»›i numpy Ä‘á»ƒ táº¡o Neural Network (code file mÃ¬nh cÃ³ Ä‘Ã­nh kÃ¨m). TÆ°á»Ÿng chá»«ng ráº¥t Ä‘Æ¡n giáº£n nhÆ°ng nÃ³ tháº­t khÃ³ khÄƒn vÃ¬ viá»‡c lá»±a chá»n sá»‘ hidden layers cho máº¡ng vÃ  Ä‘áº·c biá»‡t lÃ  viá»‡c lá»±a chá»n cÃ¡c activation function tÆ°Æ¡ng á»©ng ! Trong code file mÃ¬nh trÃ¬nh bÃ y máº¡ng noron gá»“m: 2 Ä‘áº§u vÃ o, má»™t Ä‘áº§u ra vÃ  hai lá»›p áº©n: lá»›p áº©n 1 cÃ³ 12 noron, lá»›p áº©n 2 cÃ³ 8 noron. NhÆ°ng mÃ¬nh cháº¡y vÃ  tháº­t sá»± khÃ´ng thu Ä‘Æ°á»£c káº¿t quáº£ phÃ¹ há»£p vá»›i bá»™ sá»‘ liá»‡u Ä‘Ã£ chá»‰ Ä‘á»‹nh. MÃ¬nh mong cÃ¡c báº¡n giÃºp mÃ¬nh hai váº¥n Ä‘á» sau: Lá»±a chá»n sá»‘ lá»›p áº©n cÅ©ng nhÆ° sá»‘ neuron cá»§a tá»«ng lá»›p Ä‘á»ƒ há»£p lÃ½ cho káº¿t quáº£ tÃ­nh toÃ¡n (nÃ¢ng cao accuracy cá»§a bÃ i toÃ¡n, hiá»‡n táº¡i nÃ³ Ä‘ang lÃ  0, tá»©c lÃ  khÃ´ng Ä‘áº¡t yÃªu cáº§u); Lá»±a chá»n activation functions tÆ°Æ¡ng á»©ng. MÃ¬nh mong Ä‘Æ°á»£c trá»£ giÃºp sá»›m. Xin cáº£m Æ¡n áº¡. Code file: https://www.mediafire.com/file/kzdxvckqrmbjxg1/bTest.py/file Data file: https://www.mediafire.com/file/37k8i4e540uq2uv/Ketqua.txt/file",,,,,
"Hi cÃ¡c anh chá»‹
Hiá»‡n e Ä‘ang cÃ³ bÃ i toÃ¡n cháº¥m cÃ´ng á»Ÿ cÃ´ng ty báº±ng máº·t ngá»«oi
hiá»‡n em Ä‘ang Ä‘á»‹nh Ä‘á» xuáº¥t mua mÃ¡y chá»§ Ä‘á»ƒ dÃ nh cho viá»‡c nháº­n dáº¡ng nÃ y.
hiá»‡n cháº¯c sáº½ dÃ¹ng lib ngoÃ i nhÆ° dlib hay vgg16 hay 19, ....
nhá» A E trong nhÃ³m tÆ° váº¥n nÃªn Ä‘áº§u tÆ° mÃ¡y chá»§ tháº¿ nÃ o cho há»£p lÃ½,
cáº£m Æ¡n AE","Hi cÃ¡c anh chá»‹ Hiá»‡n e Ä‘ang cÃ³ bÃ i toÃ¡n cháº¥m cÃ´ng á»Ÿ cÃ´ng ty báº±ng máº·t ngá»«oi hiá»‡n em Ä‘ang Ä‘á»‹nh Ä‘á» xuáº¥t mua mÃ¡y chá»§ Ä‘á»ƒ dÃ nh cho viá»‡c nháº­n dáº¡ng nÃ y. hiá»‡n cháº¯c sáº½ dÃ¹ng lib ngoÃ i nhÆ° dlib hay vgg16 hay 19, .... nhá» A E trong nhÃ³m tÆ° váº¥n nÃªn Ä‘áº§u tÆ° mÃ¡y chá»§ tháº¿ nÃ o cho há»£p lÃ½, cáº£m Æ¡n AE",,,,,
"ChÃ o cÃ¡c báº¡n
MÃ¬nh cÃ³ dá»± Ã¡n lÃ m robot Ä‘i 2 chÃ¢n, tÃ¬m hiá»ƒu mÃ  k biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u, cÃ¡c báº¡n cho lá»i khuyÃªn,
MÃ¬nh cÅ©ng muá»‘n thuÃª lÃ m, thÃ¬ khÃ´ng biáº¿t tÃ¬m ngÆ°á»i á»Ÿ Ä‘Ã¢u vÃ  chi phÃ­ nhÆ° tháº¿ nÃ o
MÃ¬nh muá»‘n há»i vá» pháº§n machine learning, cÃ²n pháº§n cá»©ng vÃ  máº¡ch Ä‘iá»‡n Ä‘iá»u khiá»ƒn thÃ¬ mÃ¬nh Ä‘Ã£ thiáº¿t káº¿ vÃ  tháº¥y ok rá»“i, hÃ¬nh dÆ°á»›i lÃ  pháº§n thiáº¿t káº¿ cÆ¡ khÃ­ má»›i hoÃ n thÃ nh, cáº§n gia cÃ´ng cÆ¡ khÃ­ chÃ­nh xÃ¡c ná»¯a lÃ  cÃ³ máº«u vÃ  láº¯p máº¡ch Ä‘iá»u khiá»ƒn ná»¯a lÃ  cÃ³ thá»ƒ láº­p trÃ¬nh","ChÃ o cÃ¡c báº¡n MÃ¬nh cÃ³ dá»± Ã¡n lÃ m robot Ä‘i 2 chÃ¢n, tÃ¬m hiá»ƒu mÃ  k biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u, cÃ¡c báº¡n cho lá»i khuyÃªn, MÃ¬nh cÅ©ng muá»‘n thuÃª lÃ m, thÃ¬ khÃ´ng biáº¿t tÃ¬m ngÆ°á»i á»Ÿ Ä‘Ã¢u vÃ  chi phÃ­ nhÆ° tháº¿ nÃ o MÃ¬nh muá»‘n há»i vá» pháº§n machine learning, cÃ²n pháº§n cá»©ng vÃ  máº¡ch Ä‘iá»‡n Ä‘iá»u khiá»ƒn thÃ¬ mÃ¬nh Ä‘Ã£ thiáº¿t káº¿ vÃ  tháº¥y ok rá»“i, hÃ¬nh dÆ°á»›i lÃ  pháº§n thiáº¿t káº¿ cÆ¡ khÃ­ má»›i hoÃ n thÃ nh, cáº§n gia cÃ´ng cÆ¡ khÃ­ chÃ­nh xÃ¡c ná»¯a lÃ  cÃ³ máº«u vÃ  láº¯p máº¡ch Ä‘iá»u khiá»ƒn ná»¯a lÃ  cÃ³ thá»ƒ láº­p trÃ¬nh",,,,,
"Trankit: A Light-Weight Transformer-based Python Toolkit for Multilingual Natural Language Processing
https://arxiv.org/pdf/2101.03289.pdf
-------------------
ChÃ o má»i ngÆ°á»i,
MÃ¬nh muá»‘n giá»›i thiá»‡u vá»›i má»i ngÆ°á»i bá»™ NLP toolkit Ä‘a ngÃ´n ngá»¯ do nhÃ³m mÃ¬nh á»Ÿ University of Oregon phÃ¡t triá»ƒn tÃªn lÃ  Trankit: https://github.com/nlp-uoregon/trankit.
Trankit hiá»‡n Ä‘ang giá»¯ hiá»‡u nÄƒng tá»‘t nháº¥t cho nhiá»u tasks (nhÆ° tÃ¡ch cÃ¢u, tÃ¡ch tá»«, gÃ¡n nhÃ£n tá»« loáº¡i, phÃ¢n tÃ­ch phá»¥ thuá»™c) cho 56 ngÃ´n ngá»¯ khÃ¡c nhau, vÆ°á»£t xa bá»™ toolkit Ä‘a ngÃ´n ngá»¯ tá»‘t nháº¥t hiá»‡n nay lÃ  Stanford NLP (Stanza) do Stanford phÃ¡t triá»ƒn.
Vá»›i Tiáº¿ng Viá»‡t, Trankit cÃ³ kháº£ nÄƒng xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n thÃ´ (raw text) vÃ  cho ra káº¿t quáº£ tá»‘t cho nhiá»u tasks khÃ¡c nhau nhÆ°: tÃ¡ch cÃ¢u, tÃ¡ch tá»«, gÃ¡n nhÃ£n tá»« loáº¡i, phÃ¢n tÃ­ch ngá»¯ phÃ¡p (dependency parsing), vÃ  nháº­n diá»‡n tÃªn thá»±c thá»ƒ (named entity recognition). Hiá»‡n táº¡i, bá»™ tÃ¡ch tá»« cá»§a Trankit Ä‘Æ°á»£c huáº¥n luáº­n trÃªn bá»™ dá»¯ liá»‡u cá»§a VLSP vÃ  Ä‘ang giá»¯ hiá»‡u nÄƒng tÃ¡ch tá»« tá»‘t nháº¥t cho Tiáº¿ng Viá»‡t vá»›i 98.03 F1.
Trankit Ä‘Æ°á»£c viáº¿t trÃªn Python vÃ  dá»… dÃ ng cÃ i Ä‘áº·t qua pip. NhÃ³m mÃ¬nh cÅ©ng táº¡o ra 1 demo website Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ trá»±c tiáº¿p dÃ¹ng thá»­ Trankit táº¡i Ä‘Ã¢y: http://nlp.uoregon.edu/trankit
Äá»ƒ biáº¿t thÃªm thÃ´ng tin vá» Trankit, cÃ¡c báº¡n cÃ³ thá»ƒ ghÃ© qua trang github (https://github.com/nlp-uoregon/trankit), documentation (https://trankit.readthedocs.io/en/latest/index.html ), hoáº·c bÃ i bÃ¡o (https://arxiv.org/pdf/2101.03289.pdf) cá»§a nhÃ³m mÃ¬nh.
NhÃ³m mÃ¬nh hi vá»ng Trankit sáº½ gÃ³p pháº§n phÃ¡t triá»ƒn cÃ¡c research vá» NLP cho Tiáº¿ng Viá»‡t.","Trankit: A Light-Weight Transformer-based Python Toolkit for Multilingual Natural Language Processing https://arxiv.org/pdf/2101.03289.pdf ------------------- ChÃ o má»i ngÆ°á»i, MÃ¬nh muá»‘n giá»›i thiá»‡u vá»›i má»i ngÆ°á»i bá»™ NLP toolkit Ä‘a ngÃ´n ngá»¯ do nhÃ³m mÃ¬nh á»Ÿ University of Oregon phÃ¡t triá»ƒn tÃªn lÃ  Trankit: https://github.com/nlp-uoregon/trankit. Trankit hiá»‡n Ä‘ang giá»¯ hiá»‡u nÄƒng tá»‘t nháº¥t cho nhiá»u tasks (nhÆ° tÃ¡ch cÃ¢u, tÃ¡ch tá»«, gÃ¡n nhÃ£n tá»« loáº¡i, phÃ¢n tÃ­ch phá»¥ thuá»™c) cho 56 ngÃ´n ngá»¯ khÃ¡c nhau, vÆ°á»£t xa bá»™ toolkit Ä‘a ngÃ´n ngá»¯ tá»‘t nháº¥t hiá»‡n nay lÃ  Stanford NLP (Stanza) do Stanford phÃ¡t triá»ƒn. Vá»›i Tiáº¿ng Viá»‡t, Trankit cÃ³ kháº£ nÄƒng xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n thÃ´ (raw text) vÃ  cho ra káº¿t quáº£ tá»‘t cho nhiá»u tasks khÃ¡c nhau nhÆ°: tÃ¡ch cÃ¢u, tÃ¡ch tá»«, gÃ¡n nhÃ£n tá»« loáº¡i, phÃ¢n tÃ­ch ngá»¯ phÃ¡p (dependency parsing), vÃ  nháº­n diá»‡n tÃªn thá»±c thá»ƒ (named entity recognition). Hiá»‡n táº¡i, bá»™ tÃ¡ch tá»« cá»§a Trankit Ä‘Æ°á»£c huáº¥n luáº­n trÃªn bá»™ dá»¯ liá»‡u cá»§a VLSP vÃ  Ä‘ang giá»¯ hiá»‡u nÄƒng tÃ¡ch tá»« tá»‘t nháº¥t cho Tiáº¿ng Viá»‡t vá»›i 98.03 F1. Trankit Ä‘Æ°á»£c viáº¿t trÃªn Python vÃ  dá»… dÃ ng cÃ i Ä‘áº·t qua pip. NhÃ³m mÃ¬nh cÅ©ng táº¡o ra 1 demo website Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ trá»±c tiáº¿p dÃ¹ng thá»­ Trankit táº¡i Ä‘Ã¢y: http://nlp.uoregon.edu/trankit Äá»ƒ biáº¿t thÃªm thÃ´ng tin vá» Trankit, cÃ¡c báº¡n cÃ³ thá»ƒ ghÃ© qua trang github (https://github.com/nlp-uoregon/trankit), documentation (https://trankit.readthedocs.io/en/latest/index.html ), hoáº·c bÃ i bÃ¡o (https://arxiv.org/pdf/2101.03289.pdf) cá»§a nhÃ³m mÃ¬nh. NhÃ³m mÃ¬nh hi vá»ng Trankit sáº½ gÃ³p pháº§n phÃ¡t triá»ƒn cÃ¡c research vá» NLP cho Tiáº¿ng Viá»‡t.",,,,,
"MÃ¬nh Ä‘ang há»c sá»­ dá»¥ng Nearest Neighbor cá»§a gÃ³i scikit-learn Ä‘á»ƒ lÃ m recommender sÃ½tem (phÆ°Æ¡ng collaborating-based). Äá»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng model mÃ¬nh sáº½ pháº£i pivot dá»¯ liá»‡u vá»›i columns lÃ  cÃ¡c item nghiÃªn cá»©u Ä‘á»ƒ recommend cho ngÆ°á»i dÃ¹ng.
Tuy nhiÃªn khi pivot_table thÃ¬ mÃ¬nh gáº·p pháº£i lá»—i â€œunstack dataframe is too big, causing int32 overflowâ€. MÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng filtering bá»›t dá»¯ liá»‡u nhÆ°ng mÃ¬nh lo ngáº¡i viá»‡c filter quÃ¡ nhiá»u sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng recommend.
CÃ³ ai cÃ³ kinh nghiá»‡m xá»­ lÃ½ váº¥n Ä‘á» nÃ y khÃ´ng nhá»‰","MÃ¬nh Ä‘ang há»c sá»­ dá»¥ng Nearest Neighbor cá»§a gÃ³i scikit-learn Ä‘á»ƒ lÃ m recommender sÃ½tem (phÆ°Æ¡ng collaborating-based). Äá»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng model mÃ¬nh sáº½ pháº£i pivot dá»¯ liá»‡u vá»›i columns lÃ  cÃ¡c item nghiÃªn cá»©u Ä‘á»ƒ recommend cho ngÆ°á»i dÃ¹ng. Tuy nhiÃªn khi pivot_table thÃ¬ mÃ¬nh gáº·p pháº£i lá»—i â€œunstack dataframe is too big, causing int32 overflowâ€. MÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng filtering bá»›t dá»¯ liá»‡u nhÆ°ng mÃ¬nh lo ngáº¡i viá»‡c filter quÃ¡ nhiá»u sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng recommend. CÃ³ ai cÃ³ kinh nghiá»‡m xá»­ lÃ½ váº¥n Ä‘á» nÃ y khÃ´ng nhá»‰",,,,,
"[TopDup - Core team recruitment]
ChÃ o má»i ngÆ°á»i,

NhÆ° má»i ngÆ°á»i Ä‘Ã£ biáº¿t thÃ¬ Ä‘áº§u thÃ¡ng 12 nÄƒm nay anh Tiá»‡p cÃ³ giá»›i thiá»‡u vá»›i forum mÃ¬nh vá» dá»± Ã¡n TopDup.

NÃ³i sÆ¡ qua vá» dá»± Ã¡n, ""TopDup lÃ  dá»± Ã¡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c khá»Ÿi xÆ°á»›ng bá»Ÿi Forum Machine Learning CÆ¡ báº£n nháº±m há»— trá»£ cÃ¡c website, blog cÃ´ng nghá»‡ báº£o vá»‡ báº£n quyá»n bÃ i viáº¿t vÃ  chá»‘ng sao chÃ©p.â€ CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm thÃ´ng tin chi tiáº¿t dá»± Ã¡n táº¡i: http://bit.ly/Topdup

Hiá»‡n táº¡i dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c cháº¡y vÃ  báº¯t Ä‘áº§u Iteration 1, tuy nhiÃªn tá»¥i mÃ¬nh váº«n ráº¥t cáº§n nhá»¯ng báº¡n tÃ¬nh nguyá»‡n viÃªn Ä‘á»ƒ Ä‘Ã³ng gÃ³p vÃ o dá»± Ã¡n vá»›i vai trÃ² core team á»Ÿ cÃ¡c vá»‹ trÃ­ sau:
DevOps
Backend Dev
Code Reviewer
UI/UX Designer
Tester
PR/Marketing Executive
HR Executive

MÃ´ táº£ cÃ´ng viá»‡c, yÃªu cáº§u vÃ  chá»‰ tiÃªu cá»§a tá»«ng vá»‹ trÃ­: http://bit.ly/TopDupcoreteam

VÃ¬ lÃ  dá»± Ã¡n phi lá»£i nhuáº­n nÃªn cÃ¡c báº¡n tham gia vÃ o sáº½ khÃ´ng cÃ³ lÆ°Æ¡ng, tuy nhiÃªn Ä‘Ã¢y cháº¯c cháº¯n sáº½ lÃ  cÆ¡ há»™i tá»‘t Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ há»c há»i, táº¡o network cÅ©ng nhÆ° váº­n dá»¥ng kiáº¿n thá»©c vÃ  kÄ© nÄƒng Ä‘á»ƒ Ä‘Ã³ng gÃ³p cho cá»™ng Ä‘á»“ng.

Nhá»¯ng báº¡n nÃ o muá»‘n tham gia dá»± Ã¡n thÃ¬ Ä‘iá»n vÃ o form nÃ y tá»« 31/12/2020 Ä‘áº¿n háº¿t ngÃ y 04/01/2021 https://forms.gle/crQzz5yuHLuLtQCF8
(CÃ¡c báº¡n muá»‘n contribute vá»›i tÆ° cÃ¡ch lÃ  volunteer bÃ¬nh thÆ°á»ng thÃ¬ cÃ³ thá»ƒ join xuyÃªn suá»‘t quÃ¡ trÃ¬nh thá»±c hiá»‡n dá»± Ã¡n nhÃ©) 

Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i vÃ  chÃºc má»i ngÆ°á»i nÄƒm má»›i vui váº»!","[TopDup - Core team recruitment] ChÃ o má»i ngÆ°á»i, NhÆ° má»i ngÆ°á»i Ä‘Ã£ biáº¿t thÃ¬ Ä‘áº§u thÃ¡ng 12 nÄƒm nay anh Tiá»‡p cÃ³ giá»›i thiá»‡u vá»›i forum mÃ¬nh vá» dá»± Ã¡n TopDup. NÃ³i sÆ¡ qua vá» dá»± Ã¡n, ""TopDup lÃ  dá»± Ã¡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c khá»Ÿi xÆ°á»›ng bá»Ÿi Forum Machine Learning CÆ¡ báº£n nháº±m há»— trá»£ cÃ¡c website, blog cÃ´ng nghá»‡ báº£o vá»‡ báº£n quyá»n bÃ i viáº¿t vÃ  chá»‘ng sao chÃ©p.â€ CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm thÃ´ng tin chi tiáº¿t dá»± Ã¡n táº¡i: http://bit.ly/Topdup Hiá»‡n táº¡i dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c cháº¡y vÃ  báº¯t Ä‘áº§u Iteration 1, tuy nhiÃªn tá»¥i mÃ¬nh váº«n ráº¥t cáº§n nhá»¯ng báº¡n tÃ¬nh nguyá»‡n viÃªn Ä‘á»ƒ Ä‘Ã³ng gÃ³p vÃ o dá»± Ã¡n vá»›i vai trÃ² core team á»Ÿ cÃ¡c vá»‹ trÃ­ sau: DevOps Backend Dev Code Reviewer UI/UX Designer Tester PR/Marketing Executive HR Executive MÃ´ táº£ cÃ´ng viá»‡c, yÃªu cáº§u vÃ  chá»‰ tiÃªu cá»§a tá»«ng vá»‹ trÃ­: http://bit.ly/TopDupcoreteam VÃ¬ lÃ  dá»± Ã¡n phi lá»£i nhuáº­n nÃªn cÃ¡c báº¡n tham gia vÃ o sáº½ khÃ´ng cÃ³ lÆ°Æ¡ng, tuy nhiÃªn Ä‘Ã¢y cháº¯c cháº¯n sáº½ lÃ  cÆ¡ há»™i tá»‘t Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ há»c há»i, táº¡o network cÅ©ng nhÆ° váº­n dá»¥ng kiáº¿n thá»©c vÃ  kÄ© nÄƒng Ä‘á»ƒ Ä‘Ã³ng gÃ³p cho cá»™ng Ä‘á»“ng. Nhá»¯ng báº¡n nÃ o muá»‘n tham gia dá»± Ã¡n thÃ¬ Ä‘iá»n vÃ o form nÃ y tá»« 31/12/2020 Ä‘áº¿n háº¿t ngÃ y 04/01/2021 https://forms.gle/crQzz5yuHLuLtQCF8 (CÃ¡c báº¡n muá»‘n contribute vá»›i tÆ° cÃ¡ch lÃ  volunteer bÃ¬nh thÆ°á»ng thÃ¬ cÃ³ thá»ƒ join xuyÃªn suá»‘t quÃ¡ trÃ¬nh thá»±c hiá»‡n dá»± Ã¡n nhÃ©) Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c bÃ i vÃ  chÃºc má»i ngÆ°á»i nÄƒm má»›i vui váº»!",,,,,
"chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» weka dÃ¹ng thuáº­t toÃ¡n association rule Ä‘á»ƒ phÃ¢n lá»›p. cÃ³ báº¡n nÃ o há»c vá» weka xin giÃºp Ä‘á»¡ vá»›i, thanks má»i ngÆ°á»i","chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» weka dÃ¹ng thuáº­t toÃ¡n association rule Ä‘á»ƒ phÃ¢n lá»›p. cÃ³ báº¡n nÃ o há»c vá» weka xin giÃºp Ä‘á»¡ vá»›i, thanks má»i ngÆ°á»i",,,,,
"Em xin chÃ o toÃ n thá»ƒ anh chá»‹ em trong group áº¡. Hiá»‡n táº¡i e cÃ³ má»™t bÃ i toÃ¡n vÃ  vÃ¬ má»›i há»c vá» ML nÃªn e chÆ°a biáº¿t cÃ¡ch nÃ o Ä‘á»ƒ xá»­ lÃ­ Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y áº¡:
Khi vÃ o má»™t trang web bÃ¡n hÃ ng, Ä‘Ã´i khi chÃºng ta tháº¥y sáº£n pháº©m nÃ o Ä‘Ã³ Ä‘ang Ä‘Æ°á»£c Ä‘áº¿m ngÆ°á»£c, kiá»ƒu nhÆ° lÃ  cÃ²n 01:20:30 ná»¯a lÃ  sáº½ káº¿t thÃºc giáº£m giÃ¡, Ä‘iá»u nÃ y sáº½ khiáº¿n khÃ¡ch hÃ ng ra quyáº¿t Ä‘á»‹nh sá»›m hÆ¡n. Hiá»‡n táº¡i, em Ä‘ang muá»‘n detect Ä‘Æ°á»£c cÃ¡i Ä‘á»“ng há»“ Ä‘áº¿m ngÆ°á»£c Ä‘Ã³ náº±m á»Ÿ Ä‘Ã¢u trong trang web. Ã tÆ°á»Ÿng cá»§a em lÃ  chá»¥p áº£nh mÃ n hÃ¬nh trang web rá»“i detect pháº§n countdown timer Ä‘Ã³. Má»i ngÆ°á»i cho e há»i lÃ  Ä‘á»ƒ detect Ä‘Æ°á»£c cÃ¡i Ä‘Ã³ thÃ¬ mÃ¬nh nÃªn dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o Ä‘Æ°á»£c ko áº¡. Em cáº£m Æ¡n cáº£ nhÃ  ráº¥t nhiá»u, chÃºc mn 1 tuáº§n lÃ m viá»‡c hiá»‡u quáº£","Em xin chÃ o toÃ n thá»ƒ anh chá»‹ em trong group áº¡. Hiá»‡n táº¡i e cÃ³ má»™t bÃ i toÃ¡n vÃ  vÃ¬ má»›i há»c vá» ML nÃªn e chÆ°a biáº¿t cÃ¡ch nÃ o Ä‘á»ƒ xá»­ lÃ­ Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y áº¡: Khi vÃ o má»™t trang web bÃ¡n hÃ ng, Ä‘Ã´i khi chÃºng ta tháº¥y sáº£n pháº©m nÃ o Ä‘Ã³ Ä‘ang Ä‘Æ°á»£c Ä‘áº¿m ngÆ°á»£c, kiá»ƒu nhÆ° lÃ  cÃ²n 01:20:30 ná»¯a lÃ  sáº½ káº¿t thÃºc giáº£m giÃ¡, Ä‘iá»u nÃ y sáº½ khiáº¿n khÃ¡ch hÃ ng ra quyáº¿t Ä‘á»‹nh sá»›m hÆ¡n. Hiá»‡n táº¡i, em Ä‘ang muá»‘n detect Ä‘Æ°á»£c cÃ¡i Ä‘á»“ng há»“ Ä‘áº¿m ngÆ°á»£c Ä‘Ã³ náº±m á»Ÿ Ä‘Ã¢u trong trang web. Ã tÆ°á»Ÿng cá»§a em lÃ  chá»¥p áº£nh mÃ n hÃ¬nh trang web rá»“i detect pháº§n countdown timer Ä‘Ã³. Má»i ngÆ°á»i cho e há»i lÃ  Ä‘á»ƒ detect Ä‘Æ°á»£c cÃ¡i Ä‘Ã³ thÃ¬ mÃ¬nh nÃªn dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o Ä‘Æ°á»£c ko áº¡. Em cáº£m Æ¡n cáº£ nhÃ  ráº¥t nhiá»u, chÃºc mn 1 tuáº§n lÃ m viá»‡c hiá»‡u quáº£",,,,,
"ECCV 2020 vÃ  CPVR 2020
MÃ¬nh Ä‘i há»c vÃ  project trong lá»›p lÃ  reproduce láº¡i 1 bÃ i cá»§a ECCV 2020 hoáº·c CPVR 2020, cÃ¡c báº¡n cÃ³ gá»£i Ã½ cho mÃ¬nh bÃ i nÃ o khÃ´ng?
Má»¥c tiÃªu cá»§a mÃ¬nh:
- BÃ i liÃªn quan vá» Segmentation
- BÃ i nÃ o cÃ³ data Ä‘á»ƒ train, GPU train táº§m 12h thÃ´i. KhÃ´ng cáº§n cao nhÆ° tÃ¡c giáº£, cÃ³ káº¿t quáº£ tÆ°Æ¡ng tá»± cÅ©ng Ä‘Æ°á»£c
- CÃ³ thá»ƒ implement Ä‘Æ°á»£c, mÃ¬nh Ä‘Ã£ code Ä‘Æ°á»£c UNet, vÃ  nhá»¯ng cÃ¡i tÆ°Æ¡ng tá»±
- CÃ³ baseline code github cÅ©ng tá»‘t
- Scope lÃ  project trong lá»›p há»c thÃ´i nÃªn cÅ©ng ko quÃ¡
CÃ¡m Æ¡n cÃ¡c báº¡n.","ECCV 2020 vÃ  CPVR 2020 MÃ¬nh Ä‘i há»c vÃ  project trong lá»›p lÃ  reproduce láº¡i 1 bÃ i cá»§a ECCV 2020 hoáº·c CPVR 2020, cÃ¡c báº¡n cÃ³ gá»£i Ã½ cho mÃ¬nh bÃ i nÃ o khÃ´ng? Má»¥c tiÃªu cá»§a mÃ¬nh: - BÃ i liÃªn quan vá» Segmentation - BÃ i nÃ o cÃ³ data Ä‘á»ƒ train, GPU train táº§m 12h thÃ´i. KhÃ´ng cáº§n cao nhÆ° tÃ¡c giáº£, cÃ³ káº¿t quáº£ tÆ°Æ¡ng tá»± cÅ©ng Ä‘Æ°á»£c - CÃ³ thá»ƒ implement Ä‘Æ°á»£c, mÃ¬nh Ä‘Ã£ code Ä‘Æ°á»£c UNet, vÃ  nhá»¯ng cÃ¡i tÆ°Æ¡ng tá»± - CÃ³ baseline code github cÅ©ng tá»‘t - Scope lÃ  project trong lá»›p há»c thÃ´i nÃªn cÅ©ng ko quÃ¡ CÃ¡m Æ¡n cÃ¡c báº¡n.",,,,,
"ChÃ o cÃ¡c a/c, em cÃ³ up bÃ i viáº¿t bÃªn forum mÃ  chÆ°a nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i nÃªn e xin há»i luÃ´n bÃªn Ä‘Ã¢y
Khi lÃ m viá»‡c vá»›i cÃ¡c task NLP mÃ¬nh cáº§n encode cÃ¡c sentence vá» dáº¡ng numerical, thÃ¬ mÃ¬nh cáº§n build Ä‘Æ°á»£c má»™t list vocabulary gá»“m cÃ¡c token and ids tá»« cÃ¡c sentence, em muá»‘n há»i á»Ÿ Ä‘Ã¢y lÃ  mÃ¬nh build vocabulary nÃ y lÃ  trÃªn táº­p train, táº­p test hay entire data vÃ¬ em nghÄ© cÃ³ má»™t sá»‘ thá»© sau Ä‘Ã¢y xáº£y ra
1. Náº¿u build vocabulary trÃªn táº­p train, thÃ¬ model sáº½ recognize khÃ¡ nhiá»u OOV(out of vocabulary) trÃªn cáº£ táº­p dev/test
2. Náº¿u build vocabulary trÃªn entire data thÃ¬ cÃ³ kháº£ nÄƒng model sáº½ ko gáº·p cÃ¡c unknown words vÃ¬ má»i word Ä‘á»u Ä‘Ã£ cÃ³ trong vocabulary, Ä‘iá»u nÃ y cÃ³ áº£nh hÆ°á»Ÿng tá»›i cháº¥t lÆ°á»£ng cá»§a model khi Ä‘Æ°a lÃªn product hay ko? vÃ¬ trÃªn thá»±c táº¿ cÃ³ nhiá»u OOV hÆ¡n áº¡","ChÃ o cÃ¡c a/c, em cÃ³ up bÃ i viáº¿t bÃªn forum mÃ  chÆ°a nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i nÃªn e xin há»i luÃ´n bÃªn Ä‘Ã¢y Khi lÃ m viá»‡c vá»›i cÃ¡c task NLP mÃ¬nh cáº§n encode cÃ¡c sentence vá» dáº¡ng numerical, thÃ¬ mÃ¬nh cáº§n build Ä‘Æ°á»£c má»™t list vocabulary gá»“m cÃ¡c token and ids tá»« cÃ¡c sentence, em muá»‘n há»i á»Ÿ Ä‘Ã¢y lÃ  mÃ¬nh build vocabulary nÃ y lÃ  trÃªn táº­p train, táº­p test hay entire data vÃ¬ em nghÄ© cÃ³ má»™t sá»‘ thá»© sau Ä‘Ã¢y xáº£y ra 1. Náº¿u build vocabulary trÃªn táº­p train, thÃ¬ model sáº½ recognize khÃ¡ nhiá»u OOV(out of vocabulary) trÃªn cáº£ táº­p dev/test 2. Náº¿u build vocabulary trÃªn entire data thÃ¬ cÃ³ kháº£ nÄƒng model sáº½ ko gáº·p cÃ¡c unknown words vÃ¬ má»i word Ä‘á»u Ä‘Ã£ cÃ³ trong vocabulary, Ä‘iá»u nÃ y cÃ³ áº£nh hÆ°á»Ÿng tá»›i cháº¥t lÆ°á»£ng cá»§a model khi Ä‘Æ°a lÃªn product hay ko? vÃ¬ trÃªn thá»±c táº¿ cÃ³ nhiá»u OOV hÆ¡n áº¡",,,,,
MÃ¬nh Ä‘ang cÃ³ váº¥n Ä‘á» lÃ  mÃ¬nh model bÃ i toÃ¡n NLP trÃªn python nhÆ°ng muá»‘n Ä‘Æ°a lÃªn product thÃ¬ pháº£i chuyá»ƒn code sang tÆ°Æ¡ng á»©ng vá»›i Java. CÃ¡c file model final Ä‘uÃ´i .pickle vÃ  .sav. MÃ¬nh muá»‘n há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ triá»ƒn khai model lÃªn product ná»n táº£ng Java tá»‘t nháº¥t mÃ  khÃ´ng pháº£i Ä‘i code Java láº¡i tá»« Ä‘áº§u.,MÃ¬nh Ä‘ang cÃ³ váº¥n Ä‘á» lÃ  mÃ¬nh model bÃ i toÃ¡n NLP trÃªn python nhÆ°ng muá»‘n Ä‘Æ°a lÃªn product thÃ¬ pháº£i chuyá»ƒn code sang tÆ°Æ¡ng á»©ng vá»›i Java. CÃ¡c file model final Ä‘uÃ´i .pickle vÃ  .sav. MÃ¬nh muá»‘n há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ triá»ƒn khai model lÃªn product ná»n táº£ng Java tá»‘t nháº¥t mÃ  khÃ´ng pháº£i Ä‘i code Java láº¡i tá»« Ä‘áº§u.,,,,,
"Hi guys
Má»i ngÆ°á»i phÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a phÆ°Æ¡ng phÃ¡p top- down( base vá» láº­p trÃ¬nh, framework) so vá»›i phÆ°Æ¡ng phÃ¡p bottom-up ( cáº§n chuáº©n bá»‹ base vá» ToÃ¡n ) khi há»c Ai Ko áº¡?","Hi guys Má»i ngÆ°á»i phÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a phÆ°Æ¡ng phÃ¡p top- down( base vá» láº­p trÃ¬nh, framework) so vá»›i phÆ°Æ¡ng phÃ¡p bottom-up ( cáº§n chuáº©n bá»‹ base vá» ToÃ¡n ) khi há»c Ai Ko áº¡?",,,,,
"#pytorch #melanoma
hi anh chá»‹,
Update: hÃ¬nh nhÆ° em hiá»ƒu váº¥n Ä‘á» r áº¡ :3
Em Ä‘ang trong quÃ¡ trÃ¬nh lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p vá» detection + deploy lÃªn website (django). VÃ  tÃ¬m Ä‘Æ°á»£c video cá»§a anh nÃ y. (youtube.com/watch?v=WaCFd-vL4HA&t=288s )
Sau khi xem xong video thÃ¬ em cÃ³ vá»c vÃ o dataset cá»§a kangle, Ä‘á»‹nh táº£i vá» thÃ¬ táº­n 108GB.
Váº­y mÃ¬nh nháº¥t thiáº¿t pháº£i táº£i khÃ´ng áº¡. hay cÃ²n cÃ¡ch nÃ o Ä‘á»ƒ nháº¹ hÆ¡n vÃ  tiá»‡n hÆ¡n cho quáº£ trÃ¬nh sau nÃ y deploy lÃªn website khÃ´ng áº¡.
Mong nháº­n Ä‘c gÃ³p Ã½ cá»§a anh chá»‹.
Cáº£m Æ¡n má»i ngÆ°á»i.","hi anh chá»‹, Update: hÃ¬nh nhÆ° em hiá»ƒu váº¥n Ä‘á» r áº¡ :3 Em Ä‘ang trong quÃ¡ trÃ¬nh lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p vá» detection + deploy lÃªn website (django). VÃ  tÃ¬m Ä‘Æ°á»£c video cá»§a anh nÃ y. (youtube.com/watch?v=WaCFd-vL4HA&t=288s ) Sau khi xem xong video thÃ¬ em cÃ³ vá»c vÃ o dataset cá»§a kangle, Ä‘á»‹nh táº£i vá» thÃ¬ táº­n 108GB. Váº­y mÃ¬nh nháº¥t thiáº¿t pháº£i táº£i khÃ´ng áº¡. hay cÃ²n cÃ¡ch nÃ o Ä‘á»ƒ nháº¹ hÆ¡n vÃ  tiá»‡n hÆ¡n cho quáº£ trÃ¬nh sau nÃ y deploy lÃªn website khÃ´ng áº¡. Mong nháº­n Ä‘c gÃ³p Ã½ cá»§a anh chá»‹. Cáº£m Æ¡n má»i ngÆ°á»i.",#pytorch	#melanoma,,,,
"ML Showcase 2020 - CÃ¹ng há»c kinh nghiá»‡m cá»§a nhá»¯ng á»©ng dá»¥ng AI thá»±c táº¿.
https://www.facebook.com/vietaipublic/videos/882651942567916",ML Showcase 2020 - CÃ¹ng há»c kinh nghiá»‡m cá»§a nhá»¯ng á»©ng dá»¥ng AI thá»±c táº¿. https://www.facebook.com/vietaipublic/videos/882651942567916,,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, Ä‘á»£t nÃ y em lÃ m nhiá»u API cho Machine Learning nÃªn cÃ³ tÃ¬m hiá»ƒu mÃ³n FastAPI. Tháº¥y nÃ³ hay vÃ  nhiá»u Æ°u Ä‘iá»ƒm quÃ¡ nÃªn máº¡nh dáº¡n lÃ m clip giá»›i thiá»‡u mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie nghiÃªn cá»©u thÃªm.
Mong ad duyá»‡t bÃ i ah!","KÃ­nh chÃ o cÃ¡c bÃ¡c, Ä‘á»£t nÃ y em lÃ m nhiá»u API cho Machine Learning nÃªn cÃ³ tÃ¬m hiá»ƒu mÃ³n FastAPI. Tháº¥y nÃ³ hay vÃ  nhiá»u Æ°u Ä‘iá»ƒm quÃ¡ nÃªn máº¡nh dáº¡n lÃ m clip giá»›i thiá»‡u mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie nghiÃªn cá»©u thÃªm. Mong ad duyá»‡t bÃ i ah!",,,,,
"Xin chÃ o má»i ngÆ°á»i!
Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t bÃ i toÃ¡n dá»± Ä‘oÃ¡n, dá»¯ liá»‡u dáº¡ng time-series, chÃºng em muá»‘n sá»­ dá»¥ng nhiá»‡t Ä‘á»™, thá»i tiáº¿t theo giá» Ä‘á»ƒ lÃ m má»™t Ä‘áº·c trÆ°ng. Tuy nhiÃªn chÃºng em láº¡i Ä‘ang gáº·p pháº£i viá»‡c khÃ´ng cÃ³ dá»¯ liá»‡u vá» nÃ³. Trong Ä‘Ã¢y cÃ³ ai Ä‘Ã£ cÃ³ dá»¯ liá»‡u vá» nhiá»‡t Ä‘á»™ vÃ  thá»i tiáº¿t táº¡i HÃ  Ná»™i trong khoáº£ng 12-15 nÄƒm gáº§n Ä‘Ã¢y khÃ´ng áº¡. Náº¿u cÃ³ thá»ƒ cho chÃºng em xin vá»›i áº¡ (chÃºng em lÃ  sinh viÃªn Ä‘ang tÃ¬m hiá»ƒu vÃ  tham gia NCKH).
ChÃºng em cÅ©ng tÃ¬m tháº¥y trang meteoblue.com tuy nhiÃªn há» chá»‰ cho download free 2 tuáº§n dá»¯ liá»‡u mua toÃ n bá»™ 30 nÄƒm máº¥t 100 EUR. Hoáº·c náº¿u cÃ³ trang nÃ o cho phÃ©p crawl dá»¯ liá»‡u má»i ngÆ°á»i chá»‰ em vá»›i áº¡.
CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ rÃ nh thá»i gian cho bÃ i viáº¿t cá»§a em <3","Xin chÃ o má»i ngÆ°á»i! Hiá»‡n táº¡i em Ä‘ang lÃ m má»™t bÃ i toÃ¡n dá»± Ä‘oÃ¡n, dá»¯ liá»‡u dáº¡ng time-series, chÃºng em muá»‘n sá»­ dá»¥ng nhiá»‡t Ä‘á»™, thá»i tiáº¿t theo giá» Ä‘á»ƒ lÃ m má»™t Ä‘áº·c trÆ°ng. Tuy nhiÃªn chÃºng em láº¡i Ä‘ang gáº·p pháº£i viá»‡c khÃ´ng cÃ³ dá»¯ liá»‡u vá» nÃ³. Trong Ä‘Ã¢y cÃ³ ai Ä‘Ã£ cÃ³ dá»¯ liá»‡u vá» nhiá»‡t Ä‘á»™ vÃ  thá»i tiáº¿t táº¡i HÃ  Ná»™i trong khoáº£ng 12-15 nÄƒm gáº§n Ä‘Ã¢y khÃ´ng áº¡. Náº¿u cÃ³ thá»ƒ cho chÃºng em xin vá»›i áº¡ (chÃºng em lÃ  sinh viÃªn Ä‘ang tÃ¬m hiá»ƒu vÃ  tham gia NCKH). ChÃºng em cÅ©ng tÃ¬m tháº¥y trang meteoblue.com tuy nhiÃªn há» chá»‰ cho download free 2 tuáº§n dá»¯ liá»‡u mua toÃ n bá»™ 30 nÄƒm máº¥t 100 EUR. Hoáº·c náº¿u cÃ³ trang nÃ o cho phÃ©p crawl dá»¯ liá»‡u má»i ngÆ°á»i chá»‰ em vá»›i áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ rÃ nh thá»i gian cho bÃ i viáº¿t cá»§a em <3",,,,,
ChÃ o má»i ngÆ°á»i! Em cÃ³ bá»™ dá»¯ liá»‡u gá»“m 5 nhÃ£n Ä‘Æ°á»£c chia tháº¿ nÃ y thÃ¬ cÃ³ há»£p lÃ½ chÆ°a áº¡? VÃ  dá»¯ liá»‡u nhÆ° tháº¿ nÃ y cÃ³ bá»‹ imbalanced khÃ´ng? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.,ChÃ o má»i ngÆ°á»i! Em cÃ³ bá»™ dá»¯ liá»‡u gá»“m 5 nhÃ£n Ä‘Æ°á»£c chia tháº¿ nÃ y thÃ¬ cÃ³ há»£p lÃ½ chÆ°a áº¡? VÃ  dá»¯ liá»‡u nhÆ° tháº¿ nÃ y cÃ³ bá»‹ imbalanced khÃ´ng? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡.,,,,,
"Má»i ngÆ°á»i cho em há»i chÃºt áº¡:
Hiá»‡n táº¡i e cÃ³ 1 Ã­t data cá»§a 2 con cáº£m biáº¿n; má»—i con tráº£ vá» 3 giÃ¡ trá»‹ cÃ¡c trá»¥c X,Y,Z táº¡i thá»i Ä‘iá»ƒm láº¥y máº«u; trong 1s e láº¥y máº«u 1024 láº§n => trong file csv sáº½ má»—i hÃ ng sáº½ chá»©a:
(6 cá»™t x,y,z cá»§a 2 cáº£m biáº¿n + 1 cá»™t timestamp) * 1024 láº§n láº¥y máº«u + cá»™t cuá»‘i cÃ¹ng lÃ  result 1 hoáº·c 0
*e táº¡o 1 file minh hoáº¡ nhÆ° hÃ¬nh dÆ°á»›i Ä‘á»ƒ mn dá»… hÃ¬nh dung
vá»›i cáº¥u trÃºc vÃ  tÃ­nh cháº¥t dataset nhÆ° váº­y em nÃªn dÃ¹ng thuáº­t toÃ¡n machine learning hoáº·c model deep learning nÃ o áº¡?
e tham kháº£o 1 sá»‘ nÆ¡i thÃ¬ cÃ³ 1 sá»‘ hÆ°á»›ng cÃ³ váº» liÃªn quan nhÆ° decision tree, lstm, linear regression, ... nhÆ°ng ko cháº¯c nÃªn dÃ¹ng cÃ¡i nÃ o","Má»i ngÆ°á»i cho em há»i chÃºt áº¡: Hiá»‡n táº¡i e cÃ³ 1 Ã­t data cá»§a 2 con cáº£m biáº¿n; má»—i con tráº£ vá» 3 giÃ¡ trá»‹ cÃ¡c trá»¥c X,Y,Z táº¡i thá»i Ä‘iá»ƒm láº¥y máº«u; trong 1s e láº¥y máº«u 1024 láº§n => trong file csv sáº½ má»—i hÃ ng sáº½ chá»©a: (6 cá»™t x,y,z cá»§a 2 cáº£m biáº¿n + 1 cá»™t timestamp) * 1024 láº§n láº¥y máº«u + cá»™t cuá»‘i cÃ¹ng lÃ  result 1 hoáº·c 0 *e táº¡o 1 file minh hoáº¡ nhÆ° hÃ¬nh dÆ°á»›i Ä‘á»ƒ mn dá»… hÃ¬nh dung vá»›i cáº¥u trÃºc vÃ  tÃ­nh cháº¥t dataset nhÆ° váº­y em nÃªn dÃ¹ng thuáº­t toÃ¡n machine learning hoáº·c model deep learning nÃ o áº¡? e tham kháº£o 1 sá»‘ nÆ¡i thÃ¬ cÃ³ 1 sá»‘ hÆ°á»›ng cÃ³ váº» liÃªn quan nhÆ° decision tree, lstm, linear regression, ... nhÆ°ng ko cháº¯c nÃªn dÃ¹ng cÃ¡i nÃ o",,,,,
Chao cac ban. Cho minh hoi trong group co ai biet ve weka. Cho minh hoi ve Association rule tren weka voi. Thanks so much,Chao cac ban. Cho minh hoi trong group co ai biet ve weka. Cho minh hoi ve Association rule tren weka voi. Thanks so much,,,,,
"Em Ä‘ang muá»‘n tÃ¬m hiá»ƒu vá» Python, data wrangling, data visualization, data modeling vá»›i machine learning, mong má»i ngÆ°á»i chia sáº» cho em má»™t sá»‘ thÃ´ng tin vá» má»™t sá»‘ khÃ³a há»c cÅ©ng nhÆ° tÃ i liá»‡u, sÃ¡ch áº¡, em nÃªn báº¯t Ä‘áº§u vá»›i lá»™ trÃ¬nh há»c nhÆ° nÃ o ná»¯a áº¡!
Em cáº£m Æ¡n má»i ngÆ°á»i!!!!","Em Ä‘ang muá»‘n tÃ¬m hiá»ƒu vá» Python, data wrangling, data visualization, data modeling vá»›i machine learning, mong má»i ngÆ°á»i chia sáº» cho em má»™t sá»‘ thÃ´ng tin vá» má»™t sá»‘ khÃ³a há»c cÅ©ng nhÆ° tÃ i liá»‡u, sÃ¡ch áº¡, em nÃªn báº¯t Ä‘áº§u vá»›i lá»™ trÃ¬nh há»c nhÆ° nÃ o ná»¯a áº¡! Em cáº£m Æ¡n má»i ngÆ°á»i!!!!",,,,,
"Hi má»i ngÆ°á»i
Em Ä‘ang lÃ m dÃ¹ng camera IP Ä‘áº¿m sá»‘ lÆ°á»£ng ngÆ°á»i trong phÃ²ng vÃ  gÃ¡n Ä‘Ãºng ID vÃ  tÃªn ngÆ°á»i Ä‘Ã³. NhÆ°ng cÃ³ váº¥n Ä‘á» xáº£y ra lÃ  trong phÃ²ng cÃ³ toilet, khi ngÆ°á»i A Ä‘i vÃ o toilet camera sáº½ khÃ´ng tracking Ä‘Æ°á»£c, khi ngÆ°á»i A Ä‘i ra nÃ³ sáº½ gÃ¡n sai ID vÃ  tÃªn cá»§a ngÆ°á»i A.
KhÃ´ng biáº¿t cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c Ä‘á»ƒ nÃ³ biáº¿t Ä‘Æ°á»£c ngÆ°á»i A má»›i vÃ o toilet vÃ  Ä‘i ra Ä‘á»ƒ nÃ³ gÃ¡n Ä‘Ãºng khÃ´ng áº¡. Mong anh Tháº¯ng vÃ  cÃ¡c cao nhÃ¢n chá»‰ giÃ¡o :)))
Em cÃ¡m Æ¡n.","Hi má»i ngÆ°á»i Em Ä‘ang lÃ m dÃ¹ng camera IP Ä‘áº¿m sá»‘ lÆ°á»£ng ngÆ°á»i trong phÃ²ng vÃ  gÃ¡n Ä‘Ãºng ID vÃ  tÃªn ngÆ°á»i Ä‘Ã³. NhÆ°ng cÃ³ váº¥n Ä‘á» xáº£y ra lÃ  trong phÃ²ng cÃ³ toilet, khi ngÆ°á»i A Ä‘i vÃ o toilet camera sáº½ khÃ´ng tracking Ä‘Æ°á»£c, khi ngÆ°á»i A Ä‘i ra nÃ³ sáº½ gÃ¡n sai ID vÃ  tÃªn cá»§a ngÆ°á»i A. KhÃ´ng biáº¿t cÃ³ cÃ¡ch nÃ o kháº¯c phá»¥c Ä‘á»ƒ nÃ³ biáº¿t Ä‘Æ°á»£c ngÆ°á»i A má»›i vÃ o toilet vÃ  Ä‘i ra Ä‘á»ƒ nÃ³ gÃ¡n Ä‘Ãºng khÃ´ng áº¡. Mong anh Tháº¯ng vÃ  cÃ¡c cao nhÃ¢n chá»‰ giÃ¡o :))) Em cÃ¡m Æ¡n.",,,,,
"ChÃ o cÃ¡c anh chá»‹ em Ä‘ang há»c Machine Learning cÆ¡ báº£n, hiá»‡n e tÃ¬m hiá»u vá» káº¿t há»£p giá»¯a mÃ´ hÃ¬nh RFM vÃ  K-means Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n khÃºc khÃ¡ch hÃ ng. 
Nhá» Æ¡n cÃ¡c anh chá»‹ Ä‘i trÆ°á»›c Ä‘á»ƒ láº¡i ráº¥t nhiá»u tÃ i liá»‡u phÃ¢n tÃ­ch thÃ¬ em cÃ³ thá»±c nghiá»‡m viá»‡c phÃ¢n khÃºc theo 2 hÆ°á»›ng:
HÆ°á»›ng 1 lÃ  phÃ¢n cá»¥m tá»«ng thuá»™c tÃ­nh R,F,M rá»“i ra rank chung(Ä‘á»ƒ dá»… Ã¡p dá»¥ng trong trÆ°á»ng há»£p trá»ng sá»‘ cá»§a cÃ¡c thuá»™c tÃ­nh khÃ¡c nhau).
HÆ°á»›ng 2 lÃ  phÃ¢n cá»¥m dá»±a trÃªn dá»¯ liá»‡u 3 chiá»u xyz (tÆ°Æ¡ng á»©ng vá»›i 3 giÃ¡ trá»‹ cá»§a RFM) Ä‘á»ƒ gom cÃ¡c Ä‘á»‘i tÆ°á»£ng láº¡i nhÃ³m cÃ³ trá»ng tÃ¢m gáº§n nÃ³ nháº¥t.
Em Ã¡p dá»¥ng Ä‘á»™ lá»—i elbow Ä‘á»ƒ xÃ¡c Ä‘á»‹nh k theo phÆ°Æ¡ng phÃ¡p khá»§y tay, tá»« Ä‘Ã³ tÃ¬m ra sá»‘ k tá»‘i Æ°u.
Hiá»‡n em muá»‘n má»Ÿ rá»™ng viá»‡c tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» nÃ y nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c 1 hÆ°á»›ng Ä‘i chuyÃªn sÃ¢u hÆ¡n, cÃ¡c anh chá»‹ Ä‘Ã£ tá»«ng tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ gá»£i Ã½ giÃºp em vá»›i áº¡. Em chÃ¢n thÃ nh cáº£m Æ¡n.","ChÃ o cÃ¡c anh chá»‹ em Ä‘ang há»c Machine Learning cÆ¡ báº£n, hiá»‡n e tÃ¬m hiá»u vá» káº¿t há»£p giá»¯a mÃ´ hÃ¬nh RFM vÃ  K-means Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n khÃºc khÃ¡ch hÃ ng. Nhá» Æ¡n cÃ¡c anh chá»‹ Ä‘i trÆ°á»›c Ä‘á»ƒ láº¡i ráº¥t nhiá»u tÃ i liá»‡u phÃ¢n tÃ­ch thÃ¬ em cÃ³ thá»±c nghiá»‡m viá»‡c phÃ¢n khÃºc theo 2 hÆ°á»›ng: HÆ°á»›ng 1 lÃ  phÃ¢n cá»¥m tá»«ng thuá»™c tÃ­nh R,F,M rá»“i ra rank chung(Ä‘á»ƒ dá»… Ã¡p dá»¥ng trong trÆ°á»ng há»£p trá»ng sá»‘ cá»§a cÃ¡c thuá»™c tÃ­nh khÃ¡c nhau). HÆ°á»›ng 2 lÃ  phÃ¢n cá»¥m dá»±a trÃªn dá»¯ liá»‡u 3 chiá»u xyz (tÆ°Æ¡ng á»©ng vá»›i 3 giÃ¡ trá»‹ cá»§a RFM) Ä‘á»ƒ gom cÃ¡c Ä‘á»‘i tÆ°á»£ng láº¡i nhÃ³m cÃ³ trá»ng tÃ¢m gáº§n nÃ³ nháº¥t. Em Ã¡p dá»¥ng Ä‘á»™ lá»—i elbow Ä‘á»ƒ xÃ¡c Ä‘á»‹nh k theo phÆ°Æ¡ng phÃ¡p khá»§y tay, tá»« Ä‘Ã³ tÃ¬m ra sá»‘ k tá»‘i Æ°u. Hiá»‡n em muá»‘n má»Ÿ rá»™ng viá»‡c tÃ¬m hiá»ƒu vá» váº¥n Ä‘á» nÃ y nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c 1 hÆ°á»›ng Ä‘i chuyÃªn sÃ¢u hÆ¡n, cÃ¡c anh chá»‹ Ä‘Ã£ tá»«ng tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ gá»£i Ã½ giÃºp em vá»›i áº¡. Em chÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
"DÃ¹ng gabor filter trong nháº­n dáº¡ng khuÃ´n máº·t ai lÃ m qua rá»“i cho e xin tÃ i liá»‡u hoáº·c code tham kháº£o dc khÃ´ng áº¡, e dÃ¹ng python, e cáº£m Æ¡n áº¡.","DÃ¹ng gabor filter trong nháº­n dáº¡ng khuÃ´n máº·t ai lÃ m qua rá»“i cho e xin tÃ i liá»‡u hoáº·c code tham kháº£o dc khÃ´ng áº¡, e dÃ¹ng python, e cáº£m Æ¡n áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m bÃ i vá» phÃ¢n loáº¡i mÃ£ Ä‘á»™c trÃªn Android thÃ´ng qua cÃ¡c file APK. Hiá»‡n táº¡i em Ä‘ang muá»‘n láº¥y káº¿t quáº£ vá» tá»· lá»‡ phÃ¢n loáº¡i chÃ­nh xÃ¡c tá»« cÃ¡c chÆ°Æ¡ng trÃ¬nh cÃ³ sáºµn cháº¡y trÃªn máº«u cá»§a em Ä‘á»ƒ so sÃ¡nh vá»›i phÆ°Æ¡ng phÃ¡p trong chÆ°Æ¡ng trÃ¬nh cá»§a mÃ¬nh nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c source nÃ o public nÃªn khÃ´ng biáº¿t cÃ³ ai cÃ³ source hay cÃ³ thá»ƒ cháº¡y giÃºp em ra káº¿t quáº£ khÃ´ng áº¡ .","ChÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m bÃ i vá» phÃ¢n loáº¡i mÃ£ Ä‘á»™c trÃªn Android thÃ´ng qua cÃ¡c file APK. Hiá»‡n táº¡i em Ä‘ang muá»‘n láº¥y káº¿t quáº£ vá» tá»· lá»‡ phÃ¢n loáº¡i chÃ­nh xÃ¡c tá»« cÃ¡c chÆ°Æ¡ng trÃ¬nh cÃ³ sáºµn cháº¡y trÃªn máº«u cá»§a em Ä‘á»ƒ so sÃ¡nh vá»›i phÆ°Æ¡ng phÃ¡p trong chÆ°Æ¡ng trÃ¬nh cá»§a mÃ¬nh nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c source nÃ o public nÃªn khÃ´ng biáº¿t cÃ³ ai cÃ³ source hay cÃ³ thá»ƒ cháº¡y giÃºp em ra káº¿t quáº£ khÃ´ng áº¡ .",,,,,
,nan,,,,,
Trong group cá»§a mÃ¬nh cÃ³ ai cÃ³ algorithm dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u khÃ´ng áº¡? Em Ä‘ang lÃ m má»™t project vá» tÃ i chÃ­nh vÃ  ráº¥t muá»‘n dÃ¹ng ML/AI agorithm Ä‘á»ƒ Ä‘á»‘i chiáº¿u káº¿t quáº£. Em cáº£m Æ¡n áº¡,Trong group cá»§a mÃ¬nh cÃ³ ai cÃ³ algorithm dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u khÃ´ng áº¡? Em Ä‘ang lÃ m má»™t project vá» tÃ i chÃ­nh vÃ  ráº¥t muá»‘n dÃ¹ng ML/AI agorithm Ä‘á»ƒ Ä‘á»‘i chiáº¿u káº¿t quáº£. Em cáº£m Æ¡n áº¡,,,,,
CÃ³ ai chá»‰ dÃ¹m em lÃ m thuáº­t toÃ¡n K-Means train dá»¯ liá»‡u text Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh khÃ´ng áº¡? Em cáº£m Æ¡n!,CÃ³ ai chá»‰ dÃ¹m em lÃ m thuáº­t toÃ¡n K-Means train dá»¯ liá»‡u text Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh khÃ´ng áº¡? Em cáº£m Æ¡n!,,,,,
"ChÃ o má»á»‹ ngÆ°á»i. MÃ¬nh cÃ³ má»™t cÃ¢u há»i nhanh liÃªn quan Ä‘áº¿n thuáº­t toÃ¡n *Bag of Embedding* (BoE). (Paper: https://www.ijcai.org/Proceedings/16/Papers/401.pdf) MÃ¬nh báº¯t gáº·p nÃ³ trong tutorial Text Classification cá»§a PyTorch (https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html). Trong tutorial Ä‘Ã³, tÃ¡c giáº£ Ä‘Ã£ sá»­ dá»¥ng má»™t lá»›p *Bag of Embedding* vÃ  má»™t lá»›p *linear* Ä‘á»ƒ thá»±c hiá»‡n viá»‡c classify text. [Q]: CÃ¢u há»i cá»§a mÃ¬nh Ä‘Ã³ lÃ : 1. CÃ¡ch BoE thá»±c sá»± hoáº¡t Ä‘á»™ng? 2. NÃ³ thá»±c sá»± khÃ¡c biá»‡t gÃ¬ so vá»›i báº£n word embedding truyá»n thá»‘ng vÃ  táº¡i sao / khi nÃ o chÃºng ta cáº§n nÃ³? Hi vá»ng mÃ¬nh cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c nhá»¯ng comment mang tÃ­nh Ä‘Ã³ng gÃ³p tá»›i tá»« cÃ¡c báº¡n.","ChÃ o má»á»‹ ngÆ°á»i. MÃ¬nh cÃ³ má»™t cÃ¢u há»i nhanh liÃªn quan Ä‘áº¿n thuáº­t toÃ¡n *Bag of Embedding* (BoE). (Paper: https://www.ijcai.org/Proceedings/16/Papers/401.pdf) MÃ¬nh báº¯t gáº·p nÃ³ trong tutorial Text Classification cá»§a PyTorch (https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html). Trong tutorial Ä‘Ã³, tÃ¡c giáº£ Ä‘Ã£ sá»­ dá»¥ng má»™t lá»›p *Bag of Embedding* vÃ  má»™t lá»›p *linear* Ä‘á»ƒ thá»±c hiá»‡n viá»‡c classify text. [Q]: CÃ¢u há»i cá»§a mÃ¬nh Ä‘Ã³ lÃ : 1. CÃ¡ch BoE thá»±c sá»± hoáº¡t Ä‘á»™ng? 2. NÃ³ thá»±c sá»± khÃ¡c biá»‡t gÃ¬ so vá»›i báº£n word embedding truyá»n thá»‘ng vÃ  táº¡i sao / khi nÃ o chÃºng ta cáº§n nÃ³? Hi vá»ng mÃ¬nh cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c nhá»¯ng comment mang tÃ­nh Ä‘Ã³ng gÃ³p tá»›i tá»« cÃ¡c báº¡n.",,,,,
"Xin phÃ©p Ad cho mÃ¬nh Ä‘Äƒng bÃ i áº¡.
MÃ¬nh Ä‘ang cáº§n tÃ¬m má»™t team lÃ m vá» dá»± Ã¡n NLP - tiáº¿ng viá»‡t. Dá»± Ã¡n Ä‘Ã£ cÃ³ dá»¯ liá»‡u, yÃªu cáº§u rÃµ rÃ ng cÃ³ thá»ƒ start ngay.
Anh chá»‹ em Ä‘i qua ai cÃ³ thÃ´ng tin cho mÃ¬nh xin liÃªn láº¡c nhÃ©.
cáº£m Æ¡n má»i ngÆ°á»i áº¡.","Xin phÃ©p Ad cho mÃ¬nh Ä‘Äƒng bÃ i áº¡. MÃ¬nh Ä‘ang cáº§n tÃ¬m má»™t team lÃ m vá» dá»± Ã¡n NLP - tiáº¿ng viá»‡t. Dá»± Ã¡n Ä‘Ã£ cÃ³ dá»¯ liá»‡u, yÃªu cáº§u rÃµ rÃ ng cÃ³ thá»ƒ start ngay. Anh chá»‹ em Ä‘i qua ai cÃ³ thÃ´ng tin cho mÃ¬nh xin liÃªn láº¡c nhÃ©. cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,,,
CÃ³ báº¡n nÃ o tá»«ng lÃ m qua dáº¡ng bÃ i vá» 2-class Naive Bayes algorithm nÃ y chÆ°a áº¡?,CÃ³ báº¡n nÃ o tá»«ng lÃ m qua dáº¡ng bÃ i vá» 2-class Naive Bayes algorithm nÃ y chÆ°a áº¡?,,,,,
PhÆ°Æ¡ng phÃ¡p training cÃ³ thá»ƒ giÃºp giáº£i thÃ­ch concept cá»§a dá»± Ä‘oÃ¡n.,PhÆ°Æ¡ng phÃ¡p training cÃ³ thá»ƒ giÃºp giáº£i thÃ­ch concept cá»§a dá»± Ä‘oÃ¡n.,,,,,
"[Imbalanced dataset]
ChÃ o má»i ngÆ°á»i, em Ä‘ang deal vá»›i bÃ i toÃ¡n classifications. NhÆ°ng dataset cá»§a em Ä‘ang cÃ³ dáº¥u hiá»‡u imbalanced. CÃ³ 2 nhÃ£n lÃ  0 vÃ  1, nhÃ£n 0 chiáº¿m khoáº£ng 17% (dataset cÃ³ khoáº£ng 90k observations). Váº­y trong trÆ°á»ng há»£p nÃ y mÃ¬nh cÃ³ thá»ƒ xem lÃ  imbalanced chÆ°a áº¡.
Xin cÃ¡m Æ¡n má»i ngÆ°á»i!","[Imbalanced dataset] ChÃ o má»i ngÆ°á»i, em Ä‘ang deal vá»›i bÃ i toÃ¡n classifications. NhÆ°ng dataset cá»§a em Ä‘ang cÃ³ dáº¥u hiá»‡u imbalanced. CÃ³ 2 nhÃ£n lÃ  0 vÃ  1, nhÃ£n 0 chiáº¿m khoáº£ng 17% (dataset cÃ³ khoáº£ng 90k observations). Váº­y trong trÆ°á»ng há»£p nÃ y mÃ¬nh cÃ³ thá»ƒ xem lÃ  imbalanced chÆ°a áº¡. Xin cÃ¡m Æ¡n má»i ngÆ°á»i!",,,,,
"ğŸ“·ğŸ“·[CÃ¡c khÃ³a há»c Academy - StandFord]ğŸ“·ğŸ“·
á» láº§n trÆ°á»›c mÃ¬nh Ä‘Ã£ giá»›i thiá»‡u cÃ¡c khÃ³a há»c hand-on trong AI, Data Scientist.
Láº§n nÃ y mÃ¬nh sáº½ giá»›i thiá»‡u tiáº¿p cÃ¡c khÃ³a há»c Acedemy trong lÄ©nh vá»±c nÃ y. ÄÃ¢y lÃ  nhá»¯ng khÃ³a há»c náº±m trong chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o cá»§a StandFord, Ä‘Æ°á»£c giáº£ng dáº¡y bá»Ÿi nhá»¯ng tiáº¿n sÄ©, giÃ¡o sÆ° hÃ ng Ä‘áº§u.
ğŸ“· Vá»›i cÃ¡c báº¡n yÃªu thÃ­ch thá»‘ng kÃª cÃ³ thá»ƒ há»c cÃ¡c khÃ³a:
1. CS109 (Probability for Computer Scientists)
2. CS229T (Statistical Learning Theory)
3. EE337 (Statistics and Information Theory)
4. CS246: Mining Massive Data Sets
ğŸ“· Vá» Machine Learning:
1. CS229 Machine Learning
2. CS229A Applied Machine Learning
3. CS224W Machine Learning with Graphs
ğŸ“· Deep Learning:
1. CS230 (Deep Learning)
2. CS231N Convolutional Neural Networks for Visual Recognition
3. CS224 (NLP), CS231 (Computer Vision)
4. CS234 (Reinforcement Learning)
5. CS330 (Deep Multi-Task and Meta Learning)
ğŸ“· CÃ¡c khÃ³a dÃ nh riÃªng cho Biology:
1. CS279 Computational Biology: Structure and Organization of Biomolecules and Cells
2. CS371 Computational Biology in Four Dimensions
ğŸ“· Robotic:
1. CS223A Introduction to Robotics
2. CS225A Experimental Robotics
3. CS326 Topics in Advanced Robotic Manipulation
4. CS327A Advanced Robotic Manipulation
5. CS333 Safe and Interactive Robotics
6. CS237A Principles of Robotic
https://ai.stanford.edu/courses/","[CÃ¡c khÃ³a há»c Academy - StandFord] á» láº§n trÆ°á»›c mÃ¬nh Ä‘Ã£ giá»›i thiá»‡u cÃ¡c khÃ³a há»c hand-on trong AI, Data Scientist. Láº§n nÃ y mÃ¬nh sáº½ giá»›i thiá»‡u tiáº¿p cÃ¡c khÃ³a há»c Acedemy trong lÄ©nh vá»±c nÃ y. ÄÃ¢y lÃ  nhá»¯ng khÃ³a há»c náº±m trong chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o cá»§a StandFord, Ä‘Æ°á»£c giáº£ng dáº¡y bá»Ÿi nhá»¯ng tiáº¿n sÄ©, giÃ¡o sÆ° hÃ ng Ä‘áº§u. Vá»›i cÃ¡c báº¡n yÃªu thÃ­ch thá»‘ng kÃª cÃ³ thá»ƒ há»c cÃ¡c khÃ³a: 1. CS109 (Probability for Computer Scientists) 2. CS229T (Statistical Learning Theory) 3. EE337 (Statistics and Information Theory) 4. CS246: Mining Massive Data Sets Vá» Machine Learning: 1. CS229 Machine Learning 2. CS229A Applied Machine Learning 3. CS224W Machine Learning with Graphs Deep Learning: 1. CS230 (Deep Learning) 2. CS231N Convolutional Neural Networks for Visual Recognition 3. CS224 (NLP), CS231 (Computer Vision) 4. CS234 (Reinforcement Learning) 5. CS330 (Deep Multi-Task and Meta Learning) CÃ¡c khÃ³a dÃ nh riÃªng cho Biology: 1. CS279 Computational Biology: Structure and Organization of Biomolecules and Cells 2. CS371 Computational Biology in Four Dimensions Robotic: 1. CS223A Introduction to Robotics 2. CS225A Experimental Robotics 3. CS326 Topics in Advanced Robotic Manipulation 4. CS327A Advanced Robotic Manipulation 5. CS333 Safe and Interactive Robotics 6. CS237A Principles of Robotic https://ai.stanford.edu/courses/",,,,,
"Mnist khi apply vÃ o thá»±c táº¿.
#Wowww",Mnist khi apply vÃ o thá»±c táº¿.,#Wowww,,,,
"HÃ´m trÆ°á»›c em cÃ³ há»i vá» cÃ¡ch tÃ¡ch,  xá»­ lÃ½ video vÃ  em Ä‘Ã£ lÃ m Ä‘Æ°á»£c rá»“i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ^^

Hiá»‡n táº¡i em Ä‘ang tÃ¬m cÃ¡ch thá»±c hiá»‡n xá»­ lÃ½ GAN qua webcam vÃ  real-time. Thá»i gian xá»­ lÃ½ GAN vÃ  nháº­n diá»‡n object detection offline cá»§a em khÃ´ng quÃ¡ lÃ¢u nhÆ°ng cÅ©ng khÃ´ng nhanh ngay láº­p tá»©c Ä‘Æ°á»£c (táº§m 1-2s). KhÃ´ng biáº¿t anh chá»‹ cÃ³ lá»i khuyÃªn hay nÃªn search keyword gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ tá»‘i Æ°u real-time processing time khÃ´ng áº¡? (Hiá»‡n táº¡i, trong Ä‘áº§u em Ä‘ang nghÄ© Ä‘áº¿n 1 sá»‘ solution nhÆ° convert sang tf lite, use google cloud)
Hiá»‡n táº¡i pre-trained model chá»‰ cháº¡y Ä‘Æ°á»£c trÃªn má»™t sá»‘ image size nháº¥t Ä‘á»‹nh. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ cho em cÃ¡ch cháº¡y model trÃªn má»i image size mÃ  khÃ´ng pháº£i train Ä‘i train láº¡i nhiá»u láº§n trÃªn tá»«ng image size khÃ¡c nhau khÃ´ng áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u. 
ThÃ¢n,","HÃ´m trÆ°á»›c em cÃ³ há»i vá» cÃ¡ch tÃ¡ch, xá»­ lÃ½ video vÃ  em Ä‘Ã£ lÃ m Ä‘Æ°á»£c rá»“i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i ^^ Hiá»‡n táº¡i em Ä‘ang tÃ¬m cÃ¡ch thá»±c hiá»‡n xá»­ lÃ½ GAN qua webcam vÃ  real-time. Thá»i gian xá»­ lÃ½ GAN vÃ  nháº­n diá»‡n object detection offline cá»§a em khÃ´ng quÃ¡ lÃ¢u nhÆ°ng cÅ©ng khÃ´ng nhanh ngay láº­p tá»©c Ä‘Æ°á»£c (táº§m 1-2s). KhÃ´ng biáº¿t anh chá»‹ cÃ³ lá»i khuyÃªn hay nÃªn search keyword gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ tá»‘i Æ°u real-time processing time khÃ´ng áº¡? (Hiá»‡n táº¡i, trong Ä‘áº§u em Ä‘ang nghÄ© Ä‘áº¿n 1 sá»‘ solution nhÆ° convert sang tf lite, use google cloud) Hiá»‡n táº¡i pre-trained model chá»‰ cháº¡y Ä‘Æ°á»£c trÃªn má»™t sá»‘ image size nháº¥t Ä‘á»‹nh. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ cho em cÃ¡ch cháº¡y model trÃªn má»i image size mÃ  khÃ´ng pháº£i train Ä‘i train láº¡i nhiá»u láº§n trÃªn tá»«ng image size khÃ¡c nhau khÃ´ng áº¡? Em xin cáº£m Æ¡n má»i ngÆ°á»i nhiá»u. ThÃ¢n,",,,,,
"Má»i ngÆ°á»i Æ¡i cho em há»i áº¡, cÃ³ khÃ³a há»c online/ youtube video playlist nÃ o dáº¡y theo cuá»‘n ""Pattern recognition and Machine Learning"" hoáº·c cuá»‘n ""The elements of statistical learning"" khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i áº¡!","Má»i ngÆ°á»i Æ¡i cho em há»i áº¡, cÃ³ khÃ³a há»c online/ youtube video playlist nÃ o dáº¡y theo cuá»‘n ""Pattern recognition and Machine Learning"" hoáº·c cuá»‘n ""The elements of statistical learning"" khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang cÃ³ bÃ i toÃ¡n xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t GAN vá»›i dá»¯ liá»‡u dáº¡ng video. Em hiá»ƒu Ä‘Æ°á»£c cÃ¡ch lÃ m vá»›i hÃ¬nh áº£nh nhÆ°ng khÃ´ng biáº¿t cÃ¡ch xá»­ lÃ½ tá»«ng frame vÃ  ghÃ©p láº¡i thÃ nh 1 video. Máº£ng nÃ y hÆ¡i má»›i vá»›i em nÃªn ráº¥t cáº£m Æ¡n má»i ngÆ°á»i áº¡.
ThÃ¢n,","ChÃ o má»i ngÆ°á»i, Em Ä‘ang cÃ³ bÃ i toÃ¡n xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t GAN vá»›i dá»¯ liá»‡u dáº¡ng video. Em hiá»ƒu Ä‘Æ°á»£c cÃ¡ch lÃ m vá»›i hÃ¬nh áº£nh nhÆ°ng khÃ´ng biáº¿t cÃ¡ch xá»­ lÃ½ tá»«ng frame vÃ  ghÃ©p láº¡i thÃ nh 1 video. Máº£ng nÃ y hÆ¡i má»›i vá»›i em nÃªn ráº¥t cáº£m Æ¡n má»i ngÆ°á»i áº¡. ThÃ¢n,",,,,,
"#Tuvan #MasterProgram
ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m ká»¹ sÆ° vá» lÄ©nh vá»±c Computer Vision. TrÆ°á»›c mÃ¬nh há»c Tá»± Ä‘á»™ng hÃ³a. BÃ¢y giá» mÃ¬nh Ä‘ang cÃ³ káº¿ hoáº¡ch há»c chÆ°Æ¡ng trÃ¬nh Tháº¡c sá»¹. MÃ¬nh Ä‘ang phÃ¢n vÃ¢n giá»¯a chÆ°Æ¡ng trÃ¬nh Ä‘Ã o tháº¡c sá»¹ Khoa há»c dá»¯ liá»‡u cá»§a Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o tháº¡c sá»¹ CÆ¡ sá»Ÿ toÃ¡n cho tin há»c cá»§a Äáº¡i há»c Khoa há»c tá»± nhiÃªn. MÃ¬nh Ä‘ang cÃ³ pháº§n Æ°u tiÃªn hÆ¡n cho Äáº¡i há»c Khoa há»c tá»± nhiÃªn vÃ¬ trÆ°á»›c mÃ¬nh há»c khÃ´ng Ä‘Ãºng ngÃ nh, mÃ¬nh tÃ¬m hiá»ƒu Äáº¡i há»c Khoa há»c tá»± nhiÃªn cÃ¡c mÃ´n cÆ¡ báº£n vá» toÃ¡n Ä‘Æ°á»£c Ä‘Ã o táº¡o khÃ¡ ká»¹ (Ä‘Ã¢y mÃ  Ä‘iá»u mÃ¬nh Ä‘ang ráº¥t cáº§n). Dá»± Ä‘á»‹nh cá»§a mÃ¬nh cÃ³ thiÃªn hÆ°á»›ng Ä‘i theo há»c thuáº­t. HÆ°á»›ng nghiÃªn cá»©u dá»± Ä‘á»‹nh cá»§a mÃ¬nh vá» Reinforcement Learning, Representation Learning, Meta Learning, Latent Reasoning, Generative Models,... Tuy nhiÃªn mÃ¬nh váº«n chá»‰ tÃ¬m hiá»ƒu mÃ  chÆ°a tráº£i nghiá»‡m thá»±c sá»± hai chÆ°Æ¡ng trÃ¬nh trÃªn. MÃ¬nh sáº½ vá»«a lÃ m vá»«a há»c. Má»i ngÆ°á»i Ä‘Ã£ ai há»c má»™t trong hai chÆ°Æ¡ng trÃ¬nh ThS trÃªn chÆ°a cÃ³ thá»ƒ cho mÃ¬nh cáº£m nháº­n Ä‘Æ°á»£c khÃ´ng (nhÆ° vá» cÃ¡c tháº§y cÃ´ giáº£ng dáº­y, chÆ°Æ¡ng trÃ¬nh há»c, tráº£i nghiá»‡m quÃ¡ trÃ¬nh há»c, lÄ©nh vá»±c nghiÃªn cá»©u, lá»‹ch há»c,...)? Hoáº·c báº¥t ká»³ ai cÃ³ lá»i khuyÃªn cho mÃ¬nh, mÃ¬nh ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± tÆ° váº¥n cá»§a má»i ngÆ°á»i. MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang lÃ m ká»¹ sÆ° vá» lÄ©nh vá»±c Computer Vision. TrÆ°á»›c mÃ¬nh há»c Tá»± Ä‘á»™ng hÃ³a. BÃ¢y giá» mÃ¬nh Ä‘ang cÃ³ káº¿ hoáº¡ch há»c chÆ°Æ¡ng trÃ¬nh Tháº¡c sá»¹. MÃ¬nh Ä‘ang phÃ¢n vÃ¢n giá»¯a chÆ°Æ¡ng trÃ¬nh Ä‘Ã o tháº¡c sá»¹ Khoa há»c dá»¯ liá»‡u cá»§a Äáº¡i há»c BÃ¡ch Khoa HÃ  Ná»™i vÃ  chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o tháº¡c sá»¹ CÆ¡ sá»Ÿ toÃ¡n cho tin há»c cá»§a Äáº¡i há»c Khoa há»c tá»± nhiÃªn. MÃ¬nh Ä‘ang cÃ³ pháº§n Æ°u tiÃªn hÆ¡n cho Äáº¡i há»c Khoa há»c tá»± nhiÃªn vÃ¬ trÆ°á»›c mÃ¬nh há»c khÃ´ng Ä‘Ãºng ngÃ nh, mÃ¬nh tÃ¬m hiá»ƒu Äáº¡i há»c Khoa há»c tá»± nhiÃªn cÃ¡c mÃ´n cÆ¡ báº£n vá» toÃ¡n Ä‘Æ°á»£c Ä‘Ã o táº¡o khÃ¡ ká»¹ (Ä‘Ã¢y mÃ  Ä‘iá»u mÃ¬nh Ä‘ang ráº¥t cáº§n). Dá»± Ä‘á»‹nh cá»§a mÃ¬nh cÃ³ thiÃªn hÆ°á»›ng Ä‘i theo há»c thuáº­t. HÆ°á»›ng nghiÃªn cá»©u dá»± Ä‘á»‹nh cá»§a mÃ¬nh vá» Reinforcement Learning, Representation Learning, Meta Learning, Latent Reasoning, Generative Models,... Tuy nhiÃªn mÃ¬nh váº«n chá»‰ tÃ¬m hiá»ƒu mÃ  chÆ°a tráº£i nghiá»‡m thá»±c sá»± hai chÆ°Æ¡ng trÃ¬nh trÃªn. MÃ¬nh sáº½ vá»«a lÃ m vá»«a há»c. Má»i ngÆ°á»i Ä‘Ã£ ai há»c má»™t trong hai chÆ°Æ¡ng trÃ¬nh ThS trÃªn chÆ°a cÃ³ thá»ƒ cho mÃ¬nh cáº£m nháº­n Ä‘Æ°á»£c khÃ´ng (nhÆ° vá» cÃ¡c tháº§y cÃ´ giáº£ng dáº­y, chÆ°Æ¡ng trÃ¬nh há»c, tráº£i nghiá»‡m quÃ¡ trÃ¬nh há»c, lÄ©nh vá»±c nghiÃªn cá»©u, lá»‹ch há»c,...)? Hoáº·c báº¥t ká»³ ai cÃ³ lá»i khuyÃªn cho mÃ¬nh, mÃ¬nh ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± tÆ° váº¥n cá»§a má»i ngÆ°á»i. MÃ¬nh cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",#Tuvan	#MasterProgram,,,,
"[Practical stats books]
Thá»±c ra cÃ¡c thuáº­t toÃ¡n Machine Learning Ä‘á»u dá»±a trÃªn ná»n cá»§a thá»‘ng kÃª. Tuy nhiÃªn báº¡n Ä‘Ã£ quÃ¡ lÃ¢u chÆ°a Ä‘á»™ng láº¡i Ä‘áº¿n toÃ¡n, Ä‘áº¿n xÃ¡c suáº¥t, thá»‘ng kÃª. Giá» Ä‘á»c cÃ¡c sÃ¡ch lÃ½ thuyáº¿t vá» thá»‘ng kÃª cÅ©ng chÃ¡n.
Nay mÃ¬nh giá»›i thiá»‡u 2 cuá»‘n sÃ¡ch dáº¡y thá»‘ng kÃª theo kiá»ƒu thá»±c hÃ nh, sáº½ cÃ³ code Ä‘i kÃ¨m vÃ  giáº£i thÃ­ch Ã½ nghÄ©a cá»§a cÃ¡c khÃ¡i niá»‡m trong thá»‘ng kÃª.","[Practical stats books] Thá»±c ra cÃ¡c thuáº­t toÃ¡n Machine Learning Ä‘á»u dá»±a trÃªn ná»n cá»§a thá»‘ng kÃª. Tuy nhiÃªn báº¡n Ä‘Ã£ quÃ¡ lÃ¢u chÆ°a Ä‘á»™ng láº¡i Ä‘áº¿n toÃ¡n, Ä‘áº¿n xÃ¡c suáº¥t, thá»‘ng kÃª. Giá» Ä‘á»c cÃ¡c sÃ¡ch lÃ½ thuyáº¿t vá» thá»‘ng kÃª cÅ©ng chÃ¡n. Nay mÃ¬nh giá»›i thiá»‡u 2 cuá»‘n sÃ¡ch dáº¡y thá»‘ng kÃª theo kiá»ƒu thá»±c hÃ nh, sáº½ cÃ³ code Ä‘i kÃ¨m vÃ  giáº£i thÃ­ch Ã½ nghÄ©a cá»§a cÃ¡c khÃ¡i niá»‡m trong thá»‘ng kÃª.",,,"#sharing, #math, #machine_learning",,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m bÃ i toÃ¡n ""nháº­n dáº¡ng luá»‘ng cÃ¢y"" (crop row detection). Hiá»‡n táº¡i, em Ä‘ang dÃ¹ng OpenCV theo cÃ¡c bÆ°á»›c nhÆ° sau: color filter -> edge detection -> hough line transform. Tuy nhiÃªn cÃ¡ch nÃ y cÃ³ váº» chÆ°a Ä‘Æ°á»£c tá»‘t (nhÆ° áº£nh dÆ°á»›i). NguyÃªn nhÃ¢n cÃ³ láº½ do áº£nh chá»¥p gáº§n vÃ  cÃ¡c khÃ³m cÃ¢y sÃ¡t nhau.
Mong má»i ngÆ°á»i cho em xin má»™t vÃ i gá»£i Ã½ Ä‘á»ƒ giáº£i quyáº¿t.
Em cáº£m Æ¡n!
P/S: yÃªu cáº§u cháº¡y trÃªn drone nÃªn cháº¯c khÃ³ cÃ³ thá»ƒ dÃ¹ng DL.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m bÃ i toÃ¡n ""nháº­n dáº¡ng luá»‘ng cÃ¢y"" (crop row detection). Hiá»‡n táº¡i, em Ä‘ang dÃ¹ng OpenCV theo cÃ¡c bÆ°á»›c nhÆ° sau: color filter -> edge detection -> hough line transform. Tuy nhiÃªn cÃ¡ch nÃ y cÃ³ váº» chÆ°a Ä‘Æ°á»£c tá»‘t (nhÆ° áº£nh dÆ°á»›i). NguyÃªn nhÃ¢n cÃ³ láº½ do áº£nh chá»¥p gáº§n vÃ  cÃ¡c khÃ³m cÃ¢y sÃ¡t nhau. Mong má»i ngÆ°á»i cho em xin má»™t vÃ i gá»£i Ã½ Ä‘á»ƒ giáº£i quyáº¿t. Em cáº£m Æ¡n! P/S: yÃªu cáº§u cháº¡y trÃªn drone nÃªn cháº¯c khÃ³ cÃ³ thá»ƒ dÃ¹ng DL.",,,,,
"[TRá»°C TIáº¾P]
BÃ i giáº£ng cá»§a GS. VÅ© HÃ  VÄƒn, GiÃ¡m Ä‘á»‘c Khoa há»c Vingroup Big Data Institute vá» TÄƒng tá»‘c giáº£i quyáº¿t ma tráº­n khá»•ng lá»“: Fast computation - The magic of Sampling.
#math #DataScience #colloquium #sharing","[TRá»°C TIáº¾P] BÃ i giáº£ng cá»§a GS. VÅ© HÃ  VÄƒn, GiÃ¡m Ä‘á»‘c Khoa há»c Vingroup Big Data Institute vá» TÄƒng tá»‘c giáº£i quyáº¿t ma tráº­n khá»•ng lá»“: Fast computation - The magic of Sampling.",#math	#DataScience	#colloquium	#sharing,,,,
"Pháº§n Phá»¥ lá»¥c vá» toÃ¡n vÃ  cÃ¡c cÃ´ng cá»¥ cho Há»c sÃ¢u cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh.
https://d2l.aivivn.com/chapter_appendix-mathematics-for-deep-learning/index_vn.html
NhÆ° váº­y cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch xong sau hÆ¡n 10 thÃ¡ng. NhÃ³m dá»‹ch sáº½ sá»­a chá»¯a cÃ¡c lá»—i nhá» trÆ°á»›c khi táº¡o báº£n pdf.
Cáº£m Æ¡n táº¥t cáº£ cÃ¡c thÃ nh viÃªn trong nhÃ³m dá»‹ch Ä‘Ã£ tÃ­ch cá»±c tham gia trong suá»‘t nhiá»u thÃ¡ng vá»«a rá»“i. ChÃºng tÃ´i cÅ©ng cáº£m Æ¡n cÃ¡c báº¡n Ä‘á»™c giáº£ Ä‘Ã£ á»§ng há»™. Hy vá»ng Forum cÃ³ thá»ƒ tiáº¿p tá»¥c tá»• chá»©c thÃ nh cÃ´ng nhiá»u dá»± Ã¡n cá»™ng Ä‘á»“ng khÃ¡c ná»¯a.",Pháº§n Phá»¥ lá»¥c vá» toÃ¡n vÃ  cÃ¡c cÃ´ng cá»¥ cho Há»c sÃ¢u cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh. https://d2l.aivivn.com/chapter_appendix-mathematics-for-deep-learning/index_vn.html NhÆ° váº­y cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch xong sau hÆ¡n 10 thÃ¡ng. NhÃ³m dá»‹ch sáº½ sá»­a chá»¯a cÃ¡c lá»—i nhá» trÆ°á»›c khi táº¡o báº£n pdf. Cáº£m Æ¡n táº¥t cáº£ cÃ¡c thÃ nh viÃªn trong nhÃ³m dá»‹ch Ä‘Ã£ tÃ­ch cá»±c tham gia trong suá»‘t nhiá»u thÃ¡ng vá»«a rá»“i. ChÃºng tÃ´i cÅ©ng cáº£m Æ¡n cÃ¡c báº¡n Ä‘á»™c giáº£ Ä‘Ã£ á»§ng há»™. Hy vá»ng Forum cÃ³ thá»ƒ tiáº¿p tá»¥c tá»• chá»©c thÃ nh cÃ´ng nhiá»u dá»± Ã¡n cá»™ng Ä‘á»“ng khÃ¡c ná»¯a.,,,,,
"Hi má»i ngÆ°á»i, cÃ³ anh chá»‹ nÃ o setup Ä‘Æ°á»£c gpu 3080 Ä‘á»ƒ cháº¡y tensorflow object detection 1.x khÃ´ng áº¡. Anh chá»‹ nÃ o lÃ m Ä‘Æ°á»£c thÃ¬ chá»‰ em vá»›i áº¡","Hi má»i ngÆ°á»i, cÃ³ anh chá»‹ nÃ o setup Ä‘Æ°á»£c gpu 3080 Ä‘á»ƒ cháº¡y tensorflow object detection 1.x khÃ´ng áº¡. Anh chá»‹ nÃ o lÃ m Ä‘Æ°á»£c thÃ¬ chá»‰ em vá»›i áº¡",,,,,
"MÃ¬nh tÃ­nh L2 Regularization Cost, báº±ng python, dÆ°á»›i Ä‘Ã¢y lÃ  code mÃ¬nh viáº¿t:
"" L2_regularization_cost =(1/m)*(lambd/2)*(np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)) ) ""
mÃ¬nh cáº£m tháº¥y nhÆ° váº­y hÆ¡i dÃ i, vÃ  chÆ°a táº­n dá»¥ng háº¿t python, báº¡n nÃ o biáº¿t chá»‰ mÃ¬nh vá»›i, mÃ¬nh cÃ¡m Æ¡n nhiá»u áº¡","MÃ¬nh tÃ­nh L2 Regularization Cost, báº±ng python, dÆ°á»›i Ä‘Ã¢y lÃ  code mÃ¬nh viáº¿t: "" L2_regularization_cost =(1/m)*(lambd/2)*(np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)) ) "" mÃ¬nh cáº£m tháº¥y nhÆ° váº­y hÆ¡i dÃ i, vÃ  chÆ°a táº­n dá»¥ng háº¿t python, báº¡n nÃ o biáº¿t chá»‰ mÃ¬nh vá»›i, mÃ¬nh cÃ¡m Æ¡n nhiá»u áº¡",,,,,
"ChÃ o má»i ngÆ°á»i,
Vá»£ em ráº¥t sá»£ ráº¯n, em Ä‘ang lÃ m má»™t há»‡ thá»‘ng cáº£nh bÃ¡o phÃ¡t hiá»‡n náº¿u nhÆ° cÃ³ con ráº¯n nÃ o bÃ² vÃ o nhÃ , sá»­ dá»¥ng camera an ninh. cÃ¡c camera Ä‘áº·t trÃªn cao (thÆ°á»ng lÃ  tá»« 2,3 mÃ©t hoáº·c hÆ¡n) cháº¥t lÆ°á»£ng hÃ¬nh áº£nh á»Ÿ má»©c cháº¥p nháº­n Ä‘Æ°á»£c. hiá»‡n giá» em Ä‘ang gáº·p khÃ³ khÄƒn trong viá»‡c tÃ¬m dá»¯ liá»‡u Ä‘á»ƒ train. em Ä‘ang cÃ¢n nháº¯c viá»‡c Ä‘áº·t camera tháº¥p xuá»‘ng nhÆ°ng náº¿u tháº¿ thÃ¬ ko dÃ¹ng Ä‘á»ƒ quan sÃ¡t an ninh trong nhÃ  náº¿u nhÆ° cÃ³ káº» trá»™m xÃ¢m nháº­p. em cÅ©ng Ä‘á»‹nh dÃ¹ng thermal camera nhÆ°ng há» nÃ³i nÃ³ ko hoáº¡t Ä‘á»™ng tá»‘t vá»›i cÃ¡c loÃ i Ä‘á»™ng váº­t mÃ¡u láº¡nh vÃ  Ä‘áº·c biá»‡t lÃ  náº¿u bá»n chÃºng hÆ¡i nhá» vÃ  chi phÃ­ cÅ©ng tá»‘n kÃ©m.
Má»i ngÆ°á»i cÃ³ thá»ƒ cho em Ã­t lá»i khuyÃªn Ä‘Æ°á»£c khÃ´ng áº¡?
em xin cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i, Vá»£ em ráº¥t sá»£ ráº¯n, em Ä‘ang lÃ m má»™t há»‡ thá»‘ng cáº£nh bÃ¡o phÃ¡t hiá»‡n náº¿u nhÆ° cÃ³ con ráº¯n nÃ o bÃ² vÃ o nhÃ , sá»­ dá»¥ng camera an ninh. cÃ¡c camera Ä‘áº·t trÃªn cao (thÆ°á»ng lÃ  tá»« 2,3 mÃ©t hoáº·c hÆ¡n) cháº¥t lÆ°á»£ng hÃ¬nh áº£nh á»Ÿ má»©c cháº¥p nháº­n Ä‘Æ°á»£c. hiá»‡n giá» em Ä‘ang gáº·p khÃ³ khÄƒn trong viá»‡c tÃ¬m dá»¯ liá»‡u Ä‘á»ƒ train. em Ä‘ang cÃ¢n nháº¯c viá»‡c Ä‘áº·t camera tháº¥p xuá»‘ng nhÆ°ng náº¿u tháº¿ thÃ¬ ko dÃ¹ng Ä‘á»ƒ quan sÃ¡t an ninh trong nhÃ  náº¿u nhÆ° cÃ³ káº» trá»™m xÃ¢m nháº­p. em cÅ©ng Ä‘á»‹nh dÃ¹ng thermal camera nhÆ°ng há» nÃ³i nÃ³ ko hoáº¡t Ä‘á»™ng tá»‘t vá»›i cÃ¡c loÃ i Ä‘á»™ng váº­t mÃ¡u láº¡nh vÃ  Ä‘áº·c biá»‡t lÃ  náº¿u bá»n chÃºng hÆ¡i nhá» vÃ  chi phÃ­ cÅ©ng tá»‘n kÃ©m. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em Ã­t lá»i khuyÃªn Ä‘Æ°á»£c khÃ´ng áº¡? em xin cáº£m Æ¡n.",,,,,
"Nhá» cÃ¡c báº¡n trong group chia sáº» vá»›i cÃ¡c tháº¿ há»‡ tiáº¿p theo. NhÃ³m STEAM for Vietnam nÃ y cÃ³ ráº¥t nhiá»u tháº§y giá»i.
https://www.steamforvietnam.org/courses?fbclid=IwAR1YNwyDyEIu3-Vcw7ejV_-2BL24uPiFgSMQFTXXHIhopv_grkK1ZFP5V04
 â€” vá»›i Hung Tran.",Nhá» cÃ¡c báº¡n trong group chia sáº» vá»›i cÃ¡c tháº¿ há»‡ tiáº¿p theo. NhÃ³m STEAM for Vietnam nÃ y cÃ³ ráº¥t nhiá»u tháº§y giá»i. https://www.steamforvietnam.org/courses?fbclid=IwAR1YNwyDyEIu3-Vcw7ejV_-2BL24uPiFgSMQFTXXHIhopv_grkK1ZFP5V04 â€” vá»›i Hung Tran.,,,,,
"#chiase
Video Ä‘áº§u tiÃªn trong series video vá» cÃ¡c bÃ i toÃ¡n OCR
Text detection vá»›i CRAFT",Video Ä‘áº§u tiÃªn trong series video vá» cÃ¡c bÃ i toÃ¡n OCR Text detection vá»›i CRAFT,#chiase,,,,
"em má»›i nháº­p mÃ´n deep learning Ä‘Æ°á»£c chÃºt, má»i ngÆ°á»i cho em há»i lÃ  e training sao loss vÃ  acc láº¡i cÃ¹ng giáº£m lÃ  do lÃ½ do gÃ¬ áº¡, em cáº£m Æ¡n áº¡!","em má»›i nháº­p mÃ´n deep learning Ä‘Æ°á»£c chÃºt, má»i ngÆ°á»i cho em há»i lÃ  e training sao loss vÃ  acc láº¡i cÃ¹ng giáº£m lÃ  do lÃ½ do gÃ¬ áº¡, em cáº£m Æ¡n áº¡!",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, lÃ¢u nay em váº«n tháº¯c máº¯c khi ta Ä‘Æ°a má»™t vÃ o máº¡ng má»™t hÃ¬nh áº£nh (má»™t cÃ´ gÃ¡i cháº³ng háº¡n) thÃ¬ Ã´ng CNN Ã´ng áº¥y nhÃ¬n tháº¥y cÃ´ gÃ¡i Ä‘Ã³ nhÆ° nÃ o? CÃ³ nhÆ° ta nhÃ¬n khÃ´ng? VÃ  táº­p trung vÃ o pháº§n nÃ o cá»§a cÃ´ gÃ¡i? CÃ³ giá»‘ng chÃºng ta khi nhÃ¬n vÃ o cÃ¡c cÃ´ gÃ¡i thÃ¬ hay táº­p trung vÃ oâ€¦â€¦â€¦â€¦â€¦khÃ´ng =))
NÃªn hÃ´m nay em máº¡nh dáº¡n tÃ¬m hiá»ƒu vÃ  chia sáº» cÃ¡ch visualize feature map vÃ  heatmap. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c, mong admin duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, lÃ¢u nay em váº«n tháº¯c máº¯c khi ta Ä‘Æ°a má»™t vÃ o máº¡ng má»™t hÃ¬nh áº£nh (má»™t cÃ´ gÃ¡i cháº³ng háº¡n) thÃ¬ Ã´ng CNN Ã´ng áº¥y nhÃ¬n tháº¥y cÃ´ gÃ¡i Ä‘Ã³ nhÆ° nÃ o? CÃ³ nhÆ° ta nhÃ¬n khÃ´ng? VÃ  táº­p trung vÃ o pháº§n nÃ o cá»§a cÃ´ gÃ¡i? CÃ³ giá»‘ng chÃºng ta khi nhÃ¬n vÃ o cÃ¡c cÃ´ gÃ¡i thÃ¬ hay táº­p trung vÃ oâ€¦â€¦â€¦â€¦â€¦khÃ´ng =)) NÃªn hÃ´m nay em máº¡nh dáº¡n tÃ¬m hiá»ƒu vÃ  chia sáº» cÃ¡ch visualize feature map vÃ  heatmap. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c, mong admin duyá»‡t bÃ i!",,,,,
"Hi all.
MÃ¬nh muá»‘n nhá» chÃºt áº¡.
MÃ¬nh Ä‘ang cÃ³ file audio muá»‘n chuyá»ƒn sang word. CÃ¡c báº¡n nÃ o cÃ³ source code thÃ¬ cÃ³ thá»ƒ share cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡?
Hoáº·c lÃ  ibox riÃªng cho mÃ¬nh xin giÃ¡ áº¡?
VÃ¬ mÃ¬nh Ä‘ang cÃ³ ngÆ°á»i bÃ¡c, muá»‘n chuyá»ƒn file thu Ã¢m thÃ nh word.
MÃ¬nh cÃ¡m Æ¡n.","Hi all. MÃ¬nh muá»‘n nhá» chÃºt áº¡. MÃ¬nh Ä‘ang cÃ³ file audio muá»‘n chuyá»ƒn sang word. CÃ¡c báº¡n nÃ o cÃ³ source code thÃ¬ cÃ³ thá»ƒ share cho mÃ¬nh Ä‘Æ°á»£c khÃ´ng áº¡? Hoáº·c lÃ  ibox riÃªng cho mÃ¬nh xin giÃ¡ áº¡? VÃ¬ mÃ¬nh Ä‘ang cÃ³ ngÆ°á»i bÃ¡c, muá»‘n chuyá»ƒn file thu Ã¢m thÃ nh word. MÃ¬nh cÃ¡m Æ¡n.",,,,,
"ChÃ o mn, em Ä‘ang lÃ m 1 bÃ i toÃ¡n vá» nháº­n diá»‡n cáº£m xÃºc mÃ  lÃºc predict test toÃ n ra sad.
Chi tiáº¿t bÃ i toÃ¡n vÃ  code em Ä‘á»ƒ trong file sau:","ChÃ o mn, em Ä‘ang lÃ m 1 bÃ i toÃ¡n vá» nháº­n diá»‡n cáº£m xÃºc mÃ  lÃºc predict test toÃ n ra sad. Chi tiáº¿t bÃ i toÃ¡n vÃ  code em Ä‘á»ƒ trong file sau:",,,,,
"Hello má»i ngÆ°á»i áº¡. Em tháº¥y cÃ¡i roadmap nÃ y vá»›i máº¥y cÃ¡i em xem á»Ÿ máº¥y trang khÃ¡c sau nÃ³ ngÆ°á»£c ngÆ°á»£c kiá»ƒu gÃ¬, em ko biáº¿t pháº£i báº¯t Ä‘áº§u tá»« Ä‘Ã¢u ná»¯a áº¡. MÃ  cÃ³ máº¥y cÃ¡i tra gg em cÅ©ng ko biáº¿t ra sao nhÆ° lÃ  ""Just-In-Time"",..H em mÃ´ng lung quÃ¡ ko biáº¿t sao. Má»i ngÆ°á»i giÃºp em vá»›i áº¡","Hello má»i ngÆ°á»i áº¡. Em tháº¥y cÃ¡i roadmap nÃ y vá»›i máº¥y cÃ¡i em xem á»Ÿ máº¥y trang khÃ¡c sau nÃ³ ngÆ°á»£c ngÆ°á»£c kiá»ƒu gÃ¬, em ko biáº¿t pháº£i báº¯t Ä‘áº§u tá»« Ä‘Ã¢u ná»¯a áº¡. MÃ  cÃ³ máº¥y cÃ¡i tra gg em cÅ©ng ko biáº¿t ra sao nhÆ° lÃ  ""Just-In-Time"",..H em mÃ´ng lung quÃ¡ ko biáº¿t sao. Má»i ngÆ°á»i giÃºp em vá»›i áº¡",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡!!
Dáº¡ cho em há»i lÃ  á»Ÿ trong nÃ y, cÃ³ ai theo ngÃ nh Computer Graphics hay lÃ  lÃ m vá» Shape Matching, deformable modeling khÃ´ng áº¡?
Em má»›i táº­p tá»…nh bÆ°á»›c chÃ¢n vÃ o ngÃ nh nÃ y Ä‘á»ƒ tÃ¬m hiá»ƒu, hiá»‡n táº¡i em Ä‘ang thá»±c táº­p táº¡i phÃ²ng lab vá»›i GiÃ¡o sÆ° vÃ  cÃ³ Ã½ Ä‘á»‹nh há»c lÃªn master, anh chá»‹ em Ä‘i trÆ°á»›c cÃ³ kinh nghiá»‡m truyá»n cho em Ã­t Ä‘á»ƒ Ä‘á»c paper vá»›i áº¡, tá»« tiáº¿ng anh Ä‘Ã£ khÃ³, tá»« chuyÃªn ngÃ nh cÃ ng khÃ³ hÆ¡n, ai nháº­n Ä‘á»ƒ tá»­ thÃ¬ cho em á»©ng tuyá»ƒn vá»›i, há»©a ngoan ngoÃ£n nghe lá»i ^^","Em chÃ o má»i ngÆ°á»i áº¡!! Dáº¡ cho em há»i lÃ  á»Ÿ trong nÃ y, cÃ³ ai theo ngÃ nh Computer Graphics hay lÃ  lÃ m vá» Shape Matching, deformable modeling khÃ´ng áº¡? Em má»›i táº­p tá»…nh bÆ°á»›c chÃ¢n vÃ o ngÃ nh nÃ y Ä‘á»ƒ tÃ¬m hiá»ƒu, hiá»‡n táº¡i em Ä‘ang thá»±c táº­p táº¡i phÃ²ng lab vá»›i GiÃ¡o sÆ° vÃ  cÃ³ Ã½ Ä‘á»‹nh há»c lÃªn master, anh chá»‹ em Ä‘i trÆ°á»›c cÃ³ kinh nghiá»‡m truyá»n cho em Ã­t Ä‘á»ƒ Ä‘á»c paper vá»›i áº¡, tá»« tiáº¿ng anh Ä‘Ã£ khÃ³, tá»« chuyÃªn ngÃ nh cÃ ng khÃ³ hÆ¡n, ai nháº­n Ä‘á»ƒ tá»­ thÃ¬ cho em á»©ng tuyá»ƒn vá»›i, há»©a ngoan ngoÃ£n nghe lá»i ^^",,,,,
"ChÆ°Æ¡ng trÃ¬nh giá»›i thiá»‡u há»c bá»•ng Sau Ä‘áº¡i há»c VEF 2.0 du há»c táº¡i Hoa Ká»³ giÃ nh cho cÃ¡c ngÃ nh Khoa há»c, Ká»¹ thuáº­t vÃ  CÃ´ng nghá»‡ nÄƒm nay khá»Ÿi Ä‘á»™ng táº¡i ÄH Kinh táº¿ quá»‘c dÃ¢n vá»›i buá»•i nÃ³i chuyá»‡n Ä‘Æ°á»£c tá»• chá»©c táº¡i:
D2 302, Äáº¡i há»c Kinh táº¿ Quá»‘c dÃ¢n, sá»‘ 207 Giáº£i PhÃ³ng, HÃ  Ná»™i
Äáº·c biá»‡t báº¡n Nguyá»…n Há»¯u HoÃ ng, cá»±u sinh viÃªn NEU K55 sáº½ chia sáº» vá» kinh nghiá»‡m cho nhá»¯ng báº¡n muá»‘n tiáº¿p tá»¥c theo há»c trong cÃ¡c lÄ©nh vá»±c DA, BA, DE, DS, ...
TrÃ¢n trá»ng kÃ­nh má»i cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n tham dá»± vÃ  tÃ¬m hiá»ƒu vá» cÆ¡ há»™i du há»c sau Ä‘áº¡i há»c táº¡i Hoa Ká»³!","ChÆ°Æ¡ng trÃ¬nh giá»›i thiá»‡u há»c bá»•ng Sau Ä‘áº¡i há»c VEF 2.0 du há»c táº¡i Hoa Ká»³ giÃ nh cho cÃ¡c ngÃ nh Khoa há»c, Ká»¹ thuáº­t vÃ  CÃ´ng nghá»‡ nÄƒm nay khá»Ÿi Ä‘á»™ng táº¡i ÄH Kinh táº¿ quá»‘c dÃ¢n vá»›i buá»•i nÃ³i chuyá»‡n Ä‘Æ°á»£c tá»• chá»©c táº¡i: D2 302, Äáº¡i há»c Kinh táº¿ Quá»‘c dÃ¢n, sá»‘ 207 Giáº£i PhÃ³ng, HÃ  Ná»™i Äáº·c biá»‡t báº¡n Nguyá»…n Há»¯u HoÃ ng, cá»±u sinh viÃªn NEU K55 sáº½ chia sáº» vá» kinh nghiá»‡m cho nhá»¯ng báº¡n muá»‘n tiáº¿p tá»¥c theo há»c trong cÃ¡c lÄ©nh vá»±c DA, BA, DE, DS, ... TrÃ¢n trá»ng kÃ­nh má»i cÃ¡c báº¡n quan tÃ¢m Ä‘áº¿n tham dá»± vÃ  tÃ¬m hiá»ƒu vá» cÆ¡ há»™i du há»c sau Ä‘áº¡i há»c táº¡i Hoa Ká»³!",,,,,
"[Danh sÃ¡ch cÃ¡c Startup trong lÃ£nh vá»±c AI / Machine Learning á»Ÿ Viá»‡t Nam]
[Update: 03/01/2020]
MÃ¬nh update danh sÃ¡ch thÃªm cÃ¡c cÃ´ng ty Ä‘Æ°á»£c cÃ¡c báº¡n comment bÃªn dÆ°á»›i:
voicon.ai
sharitek.com
eyeq.tech
olli-ai.com
asilla.vn
trustingsocial.com
abivin.com
cinnamon.is
nextsmarty.com
hiip.asia
orm.vn
---
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c doanh nghiá»‡p tráº» chuyÃªn phÃ¡t triá»ƒn á»©ng dá»¥ng AI, Machine Learning á»Ÿ VN, khÃ´ng tÃ­nh cÃ¡c cÃ´ng ty lá»›n lÃ¢u nÄƒm cÃ³ máº£ng AI mÃ  chá»‰ cÃ´ng ty chuyÃªn vá» AI. TÃ¬m mÃ£i mÃ  chá»‰ tÃ¬m Ä‘Æ°á»£c vÃ i cÃ´ng ty.
MÃ¬nh tá»± há»i láº½ nÃ o VN mÃ¬nh cÃ³ Ã­t Startup trong AI tháº¿? CÃ³ báº¡n nÃ o biáº¿t cÃ²n cÃ´ng ty nÃ o khÃ¡c xin comment bÃªn dÆ°á»›i giá»›i thiá»‡u giÃºp mÃ¬nh tÃªn cÃ´ng ty & website vá»›i. CÃ³ danh sÃ¡ch nÃ y mÃ¬nh nghÄ© cÅ©ng tiá»‡n cho cÃ¡c báº¡n nÃ o muá»‘n tÃ¬m viá»‡c lÃ m trong lÃ£nh vá»±c AI.","[Danh sÃ¡ch cÃ¡c Startup trong lÃ£nh vá»±c AI / Machine Learning á»Ÿ Viá»‡t Nam] [Update: 03/01/2020] MÃ¬nh update danh sÃ¡ch thÃªm cÃ¡c cÃ´ng ty Ä‘Æ°á»£c cÃ¡c báº¡n comment bÃªn dÆ°á»›i: voicon.ai sharitek.com eyeq.tech olli-ai.com asilla.vn trustingsocial.com abivin.com cinnamon.is nextsmarty.com hiip.asia orm.vn --- MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» cÃ¡c doanh nghiá»‡p tráº» chuyÃªn phÃ¡t triá»ƒn á»©ng dá»¥ng AI, Machine Learning á»Ÿ VN, khÃ´ng tÃ­nh cÃ¡c cÃ´ng ty lá»›n lÃ¢u nÄƒm cÃ³ máº£ng AI mÃ  chá»‰ cÃ´ng ty chuyÃªn vá» AI. TÃ¬m mÃ£i mÃ  chá»‰ tÃ¬m Ä‘Æ°á»£c vÃ i cÃ´ng ty. MÃ¬nh tá»± há»i láº½ nÃ o VN mÃ¬nh cÃ³ Ã­t Startup trong AI tháº¿? CÃ³ báº¡n nÃ o biáº¿t cÃ²n cÃ´ng ty nÃ o khÃ¡c xin comment bÃªn dÆ°á»›i giá»›i thiá»‡u giÃºp mÃ¬nh tÃªn cÃ´ng ty & website vá»›i. CÃ³ danh sÃ¡ch nÃ y mÃ¬nh nghÄ© cÅ©ng tiá»‡n cho cÃ¡c báº¡n nÃ o muá»‘n tÃ¬m viá»‡c lÃ m trong lÃ£nh vá»±c AI.",,,,,
"ChÃ o cÃ¡c bÃ¡c áº¡, hiá»‡n táº¡i em muá»‘n lÃ m 1 lÃ  course Machine learning theo kiá»ƒu cá»±c kÃ¬ cÆ¡ báº£n(nháº­p mÃ´n) cho máº¥y báº¡n khÃ´ng chuyÃªn thÃ¬ syllabus dÆ°á»›i nÃ y cÃ³ á»•n khÃ´ng áº¡.
Em tÃ­nh lÃ m kiá»ƒu nÃ³i sÆ¡ cÆ¡ báº£n vá» lÃ½ thuyáº¿t vÃ  cÃ²n láº¡i lÃ  code step by step.
Edit: Hiá»‡n táº¡i mÃ¬nh chá»‰ vá»«a má»›i lÃªn plans thÃ´i váº«n chÆ°a cÃ³ content bÃªn trong. Khi mÃ¬nh cáº£m tháº¥y má»i thá»© á»•n rá»“i mÃ¬nh sáº½ public free cho má»i ngÆ°á»i cÃ³ thá»ƒ tiáº¿p cáº­n.","ChÃ o cÃ¡c bÃ¡c áº¡, hiá»‡n táº¡i em muá»‘n lÃ m 1 lÃ  course Machine learning theo kiá»ƒu cá»±c kÃ¬ cÆ¡ báº£n(nháº­p mÃ´n) cho máº¥y báº¡n khÃ´ng chuyÃªn thÃ¬ syllabus dÆ°á»›i nÃ y cÃ³ á»•n khÃ´ng áº¡. Em tÃ­nh lÃ m kiá»ƒu nÃ³i sÆ¡ cÆ¡ báº£n vá» lÃ½ thuyáº¿t vÃ  cÃ²n láº¡i lÃ  code step by step. Edit: Hiá»‡n táº¡i mÃ¬nh chá»‰ vá»«a má»›i lÃªn plans thÃ´i váº«n chÆ°a cÃ³ content bÃªn trong. Khi mÃ¬nh cáº£m tháº¥y má»i thá»© á»•n rá»“i mÃ¬nh sáº½ public free cho má»i ngÆ°á»i cÃ³ thá»ƒ tiáº¿p cáº­n.",,,,,
"[Xin gá»£i Ã½ tÃ i liá»‡u]
Xin chÃ o anh chá»‹ em trong group.
Minh Ä‘ang thá»±c hiá»‡n Ä‘á» tÃ i vá» Speech-Command-Interface vÃ  TinyML cho vi Ä‘iá»u khiá»ƒn. MÃ¬nh vá»‘n khÃ´ng pháº£i dÃ¢n chuyÃªn vá» AI vÃ  Deep  Learning nÃªn cáº§n má»i ngÆ°á»i trá»£ giÃºp chÃºt xÃ­u. Ai Ä‘Ã£ nghiÃªn cá»©u qua Ä‘á»  tÃ i nÃ y cÃ³ thá»ƒ gá»£i Ã½ cho mÃ¬nh Ã­t tÃ i liá»‡u Ä‘á»ƒ tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡.
Hiá»‡n táº¡i mÃ¬nh má»›i chá»‰ Ä‘á»c qua documentation cá»§a tensorflow vÃ  bÃ i viáº¿t mÃ´ táº£  vá» dataset cá»§a há». NgoÃ i ra mÃ¬nh cÅ©ng Ä‘ang Ä‘á»c thÃªm cÃ¡c bÃ i viáº¿t cá»§a  tÃ¡c giáº£ Jonathan Hui trÃªn Medium. Do dá»‹ch bá»‡nh nÃªn thÆ° viá»‡n chá»— mÃ¬nh  Ä‘Ã³ng cá»­a, nguá»“n tÃ i liá»‡u hÆ¡i khÃ³ tiáº¿p cáº­n. VÃ¬ váº­y nÃªn mong muá»‘n lÃ  tÃ i  liá»‡u dáº¡ng bÃ i viáº¿t hoáº·c nghiÃªn cá»©u cÃ³ thá»ƒ trÃ­ch xuáº¥t vÃ  truy cáº­p báº±ng  internet Ä‘Æ°á»£c thÃ¬ tuyá»‡t vá»i.
Mong má»i ngÆ°á»i giÃºp áº¡!
(áº£nh chá»‘ng trÃ´i)","[Xin gá»£i Ã½ tÃ i liá»‡u] Xin chÃ o anh chá»‹ em trong group. Minh Ä‘ang thá»±c hiá»‡n Ä‘á» tÃ i vá» Speech-Command-Interface vÃ  TinyML cho vi Ä‘iá»u khiá»ƒn. MÃ¬nh vá»‘n khÃ´ng pháº£i dÃ¢n chuyÃªn vá» AI vÃ  Deep Learning nÃªn cáº§n má»i ngÆ°á»i trá»£ giÃºp chÃºt xÃ­u. Ai Ä‘Ã£ nghiÃªn cá»©u qua Ä‘á» tÃ i nÃ y cÃ³ thá»ƒ gá»£i Ã½ cho mÃ¬nh Ã­t tÃ i liá»‡u Ä‘á»ƒ tham kháº£o Ä‘Æ°á»£c khÃ´ng áº¡. Hiá»‡n táº¡i mÃ¬nh má»›i chá»‰ Ä‘á»c qua documentation cá»§a tensorflow vÃ  bÃ i viáº¿t mÃ´ táº£ vá» dataset cá»§a há». NgoÃ i ra mÃ¬nh cÅ©ng Ä‘ang Ä‘á»c thÃªm cÃ¡c bÃ i viáº¿t cá»§a tÃ¡c giáº£ Jonathan Hui trÃªn Medium. Do dá»‹ch bá»‡nh nÃªn thÆ° viá»‡n chá»— mÃ¬nh Ä‘Ã³ng cá»­a, nguá»“n tÃ i liá»‡u hÆ¡i khÃ³ tiáº¿p cáº­n. VÃ¬ váº­y nÃªn mong muá»‘n lÃ  tÃ i liá»‡u dáº¡ng bÃ i viáº¿t hoáº·c nghiÃªn cá»©u cÃ³ thá»ƒ trÃ­ch xuáº¥t vÃ  truy cáº­p báº±ng internet Ä‘Æ°á»£c thÃ¬ tuyá»‡t vá»i. Mong má»i ngÆ°á»i giÃºp áº¡! (áº£nh chá»‘ng trÃ´i)",,,,,
ChÃ o mn. MÃ¬nh Ä‘ang muá»‘n báº¯t Ä‘áº§u nghiÃªn cá»©u vá» ML nhÆ°ng hiá»‡n táº¡i biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vÃ  lá»™ trÃ¬nh tháº¿ nÃ o. Mong mn tÆ° váº¥n giÃºp mÃ¬nh,ChÃ o mn. MÃ¬nh Ä‘ang muá»‘n báº¯t Ä‘áº§u nghiÃªn cá»©u vá» ML nhÆ°ng hiá»‡n táº¡i biáº¿t báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vÃ  lá»™ trÃ¬nh tháº¿ nÃ o. Mong mn tÆ° váº¥n giÃºp mÃ¬nh,,,,,
"Finding partners to join Discord study group for Data Structures and Algorithms specialisation - UCSD (Python)
Hi everyone,
This is not a promoting/advertising post.
I just want to invite who are studying the Data Structures and Algorithms specialisation (University of California San Diego) in Python and wish to have a group to frequently discuss the lectures/assignments/Pycharm related issues, to join our Discord study group. I'm just a beginner, have 1 year experience with Python (from DataCamp, CS50 and my MSc in Business Analytics). I'm studying full-time and hopefully could finish the specialisation in 2 months, so I would try to make the group as active as possible.
>>>> DM me for the Discord link.
Keep studying and Best regards.","Finding partners to join Discord study group for Data Structures and Algorithms specialisation - UCSD (Python) Hi everyone, This is not a promoting/advertising post. I just want to invite who are studying the Data Structures and Algorithms specialisation (University of California San Diego) in Python and wish to have a group to frequently discuss the lectures/assignments/Pycharm related issues, to join our Discord study group. I'm just a beginner, have 1 year experience with Python (from DataCamp, CS50 and my MSc in Business Analytics). I'm studying full-time and hopefully could finish the specialisation in 2 months, so I would try to make the group as active as possible. >>>> DM me for the Discord link. Keep studying and Best regards.",,,,,
"CÃ¡c a/c cho e há»i vá»›i áº¡!
Khi inference model pytorch version 1.2 trÃªn cpu support cáº£ avx2 vÃ  avx512 thÃ¬ lib mkldnn Ä‘á»ƒ default lÃ  avx512. Giá» em muá»‘n config Ä‘á»ƒ cháº¡y báº±ng avx2 thÃ¬ cáº§n set láº¡i enviroment param nhÆ° nÃ o áº¡?!
Em xin cáº£m Æ¡n!",CÃ¡c a/c cho e há»i vá»›i áº¡! Khi inference model pytorch version 1.2 trÃªn cpu support cáº£ avx2 vÃ  avx512 thÃ¬ lib mkldnn Ä‘á»ƒ default lÃ  avx512. Giá» em muá»‘n config Ä‘á»ƒ cháº¡y báº±ng avx2 thÃ¬ cáº§n set láº¡i enviroment param nhÆ° nÃ o áº¡?! Em xin cáº£m Æ¡n!,,,,,
"1 cuá»™c thi vá» áº£nh y táº¿ má»›i trÃªn Kaggle do team mÃ¬nh Ä‘á»©ng ra host vá»«a Ä‘Æ°á»£c launch: https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection
Sáº½ cÃ³ 1 giáº£i Ä‘áº·c biá»‡t ($8k) giÃ nh riÃªng cho team Viá»‡t Nam xuáº¥t sáº¯c nháº¥t nÃªn mÃ¬nh hy vá»ng má»i ngÆ°á»i sáº½ tham gia nhiá»‡t tÃ¬nh ğŸ˜",1 cuá»™c thi vá» áº£nh y táº¿ má»›i trÃªn Kaggle do team mÃ¬nh Ä‘á»©ng ra host vá»«a Ä‘Æ°á»£c launch: https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection Sáº½ cÃ³ 1 giáº£i Ä‘áº·c biá»‡t ($8k) giÃ nh riÃªng cho team Viá»‡t Nam xuáº¥t sáº¯c nháº¥t nÃªn mÃ¬nh hy vá»ng má»i ngÆ°á»i sáº½ tham gia nhiá»‡t tÃ¬nh,,,,,
"Hiá»‡n TopDup Ä‘ang ráº¥t cáº§n má»™t báº¡n cÃ³ kinh nghiá»‡m UI/UX design Ä‘á»ƒ lead pháº§n nÃ y cá»§a dá»± Ã¡n. Náº¿u há»©ng thÃº, báº¡n cÃ³ thá»ƒ Ä‘iá»n form Ä‘á»ƒ join slack hoáº·c ping mÃ¬nh trá»±c tiáº¿p cÃ³ kÃ¨m email.
Cáº£m Æ¡n báº¡n.","Hiá»‡n TopDup Ä‘ang ráº¥t cáº§n má»™t báº¡n cÃ³ kinh nghiá»‡m UI/UX design Ä‘á»ƒ lead pháº§n nÃ y cá»§a dá»± Ã¡n. Náº¿u há»©ng thÃº, báº¡n cÃ³ thá»ƒ Ä‘iá»n form Ä‘á»ƒ join slack hoáº·c ping mÃ¬nh trá»±c tiáº¿p cÃ³ kÃ¨m email. Cáº£m Æ¡n báº¡n.",,,,,
"Em chÃ o mn. Em Ä‘ang lÃ  sv nÄƒm cuá»‘i, sáº¯p ra trg, tÃ­nh mua 1 c laptop/desktop Ä‘á»ƒ training, há»c táº­p, giáº£i trÃ­.
Em tÃ­nh mua chiáº¿c msi gt73 i7 7700hq, 1080. Liá»‡u cÃ³ á»•n ko mn nhá»‰? Hay táº§m tiá»n Ä‘Ã³ cÃ³ thá»ƒ mua Ä‘c 1 em rtx 2060+i7 9750 hÆ¡n?
Build desktop em sá»£ ko tiá»‡n láº¯m nÃªn cÅ©ng Ä‘áº¯n Ä‘o. VÃ¬ desk táº§m 30tr lÃ  cÃ³ 2080 rá»“i.
Em cáº£m Æ¡n mn áº¡.","Em chÃ o mn. Em Ä‘ang lÃ  sv nÄƒm cuá»‘i, sáº¯p ra trg, tÃ­nh mua 1 c laptop/desktop Ä‘á»ƒ training, há»c táº­p, giáº£i trÃ­. Em tÃ­nh mua chiáº¿c msi gt73 i7 7700hq, 1080. Liá»‡u cÃ³ á»•n ko mn nhá»‰? Hay táº§m tiá»n Ä‘Ã³ cÃ³ thá»ƒ mua Ä‘c 1 em rtx 2060+i7 9750 hÆ¡n? Build desktop em sá»£ ko tiá»‡n láº¯m nÃªn cÅ©ng Ä‘áº¯n Ä‘o. VÃ¬ desk táº§m 30tr lÃ  cÃ³ 2080 rá»“i. Em cáº£m Æ¡n mn áº¡.",,,,,
"Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘Æ°á»£c giao task trÃ­ch xuáº¥t text trong hÃ¬nh áº£nh, do mÃ¬nh khÃ´ng chuyÃªn compuer vison nÃªn mÃ¬nh muá»‘n há»i hiá»‡n táº¡i mÃ´ hÃ¬nh hoáº·c pretrain nÃ o tá»‘t nháº¥t Ä‘á»ƒ lÃ m váº¥n Ä‘á» nÃ y, mong má»i ngÆ°á»i chá»‰ giÃ¡o.","Xin chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘Æ°á»£c giao task trÃ­ch xuáº¥t text trong hÃ¬nh áº£nh, do mÃ¬nh khÃ´ng chuyÃªn compuer vison nÃªn mÃ¬nh muá»‘n há»i hiá»‡n táº¡i mÃ´ hÃ¬nh hoáº·c pretrain nÃ o tá»‘t nháº¥t Ä‘á»ƒ lÃ m váº¥n Ä‘á» nÃ y, mong má»i ngÆ°á»i chá»‰ giÃ¡o.",,,,,
ThÃªm má»™t bÃ i tá»•ng há»£p vá» cÃ¡c cÃ´ng ty lÃ m MLOps nÄƒm 2020 https://huyenchip.com/2020/12/30/mlops-v2.html?fbclid=IwAR0RgMkzShsYTdCM5-2pWzIAeaZzpIeaMqdwV51st4FghQPDBMff4UaSQd8,ThÃªm má»™t bÃ i tá»•ng há»£p vá» cÃ¡c cÃ´ng ty lÃ m MLOps nÄƒm 2020 https://huyenchip.com/2020/12/30/mlops-v2.html?fbclid=IwAR0RgMkzShsYTdCM5-2pWzIAeaZzpIeaMqdwV51st4FghQPDBMff4UaSQd8,,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i mÃ¬nh cÃ i opencv contrib python báº±ng lá»‡nh: pip install opencv-contrib-python bá»‹ lá»—i nhÆ° dÆ°á»›i Ä‘Ã¢y, má»i ngÆ°á»i tá»«ng gáº·p cÃ³ thá»ƒ chá»‰ mÃ¬nh cÃ¡ch fix vá»›i, mÃ¬nh cáº£m Æ¡n áº¡","Má»i ngÆ°á»i cho mÃ¬nh há»i mÃ¬nh cÃ i opencv contrib python báº±ng lá»‡nh: pip install opencv-contrib-python bá»‹ lá»—i nhÆ° dÆ°á»›i Ä‘Ã¢y, má»i ngÆ°á»i tá»«ng gáº·p cÃ³ thá»ƒ chá»‰ mÃ¬nh cÃ¡ch fix vá»›i, mÃ¬nh cáº£m Æ¡n áº¡",,,,,
"[NEW BOOK] - PROBABILISTIC MACHINE LEARNING: AN INTRODUCTION (2021)
ÄÃ¢y lÃ  sÃ¡ch má»›i cá»§a Murphy, Ä‘Æ°á»£c updated tá»« quyá»ƒn â€œMachine Learning: A Probabilistic Perspectiveâ€ (2012) lÃ  má»™t trong nhá»¯ng cuá»‘n sÃ¡ch ná»n táº£ng vá» xÃ¡c suáº¥t á»©ng dá»¥ng trong Machine Learning.
CÃ¡c báº¡n cÃ³ thá»ƒ chÆ°a biáº¿t â€œMachine Learning: A Probabilistic Perspectiveâ€ (2012) nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng danh giÃ¡ DeGroot Prize (https://bayesian.org/project/degroot-prize/) nÄƒm 2013 cho nhá»¯ng Ä‘Ã³ng gÃ³p xuáº¥t sáº¯c trong lÄ©nh vá»±c khoa há»c thá»‘ng kÃª. Cuá»‘n sÃ¡ch covers ráº¥t nhiá»u topics khÃ¡c nhau cá»§a xÃ¡c suáº¥t thá»‘ng kÃª vÃ  tÃ­nh liÃªn há»‡ máº­t thiáº¿t trong mÃ¡y há»c nhÆ° Probability Optimization, Conditional Random Fields, L1 Regularization, Bayesian Decision Theory, Gaussian Models vÃ  Deep Learning.
NÄƒm 2012 Ä‘Æ°á»£c nháº­n Ä‘á»‹nh lÃ  khá»Ÿi Ä‘áº§u cá»§a â€œká»· nguyÃªn há»c sÃ¢uâ€ (Deep Learning Revolution). Khoáº£ng 8 nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y chÃºng ta Ä‘Ã£ chá»©ng kiáº¿n nhá»¯ng á»©ng dá»¥ng vÃ´ cÃ¹ng ná»•i báº­t cá»§a Machine Learning vÃ  Deep Learning trong Computer Vision, Natural Language Processing vÃ  Reinforcement Learning. NÄƒm 2018, Murphy nháº­n tháº¥y cÃ²n nhiá»u thiáº¿u sÃ³t trong quyá»ƒn sÃ¡ch Ä‘áº§u tay cá»§a mÃ¬nh nÃªn Ä‘Ã£ tiáº¿n hÃ nh viáº¿t hoÃ n thiá»‡n nÃ³.
Báº£n tháº£o Ä‘áº§u tiÃªn khi hoÃ n thÃ nh (2020) dÃ i khoáº£ng 1600 trang, tuy nhiÃªn MIT Press khÃ´ng thá»ƒ publish má»™t quyá»ƒn sÃ¡ch dÃ i nhÆ° váº­y! Murphy quyáº¿t Ä‘á»‹nh chia thÃ nh 2 quyá»ƒn khÃ¡c nhau. ÄÃ³ lÃ  â€œProbabilistic Machine Learning: An Introduction (2021)â€ vÃ  â€œProbabilistic Machine Learning: Advanced Topics (2022)â€. Hai quyá»ƒn káº¿ thá»«a nhá»¯ng Ä‘iá»ƒm máº¥u chá»‘t vÃ  xuáº¥t sáº¯c tá»« quyá»ƒn Ä‘áº§u tiÃªn. ThÃªm vÃ o Ä‘Ã³ lÃ  ráº¥t nhiá»u ná»™i dung má»›i cá»§a â€œká»· nguyÃªn há»c sÃ¢uâ€ nhÆ° Generative Models, Variational Inference vÃ  Reinforcement Learning.
Vá»›i phong cÃ¡ch viáº¿t giáº£n dá»‹, gáº§n gÅ©i, dá»… tiáº¿p cáº­n vÃ  hoÃ n chá»‰nh cho cÃ¡c thuáº­t toÃ¡n, Ä‘á»“ng thá»i vá»›i ráº¥t nhiá»u hÃ¬nh áº£nh vÃ  vÃ­ dá»¥ trá»±c quan, mÃ¬nh tin ráº±ng cÃ¡c báº¡n sáº½ há»c Ä‘Æ°á»£c ráº¥t nhiá»u Ä‘iá»u thÃº vá»‹ vÃ  bá»• Ã­ch trong quyá»ƒn sÃ¡ch nÃ y.
Trang chá»§ vÃ  draft version (2021) cá»§a 2 quyá»ƒn sÃ¡ch: https://probml.github.io/pml-book/
Happy Learning and Happy New Year! ğŸ˜‰
**************************************************
MÃ¬nh cÃ³ note láº¡i danh sÃ¡ch nhá»¯ng quyá»ƒn sÃ¡ch â€œgá»‘i Ä‘áº§uâ€ trong Machine Learning, cÃ¡c báº¡n cÃ³ thá»ƒ xem qua nhÃ©!
Pattern Recognition and Machine Learning (2006) â€“ Bishop (https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/)
The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (2009) - Trevor Hastie et al. (https://web.stanford.edu/~hastie/ElemStatLearn/)
Machine Learning: A Probabilistic Perspective (2012) â€“ Murphy (https://probml.github.io/pml-book/)
Deep Learning (2015) â€“ Ian Goodfellow et al. (https://www.deeplearningbook.org/)
Foundations of Machine Learning, Second Edition (2018) - Mehryar Mohri et al. (https://cs.nyu.edu/~mohri/mlbook/)","[NEW BOOK] - PROBABILISTIC MACHINE LEARNING: AN INTRODUCTION (2021) ÄÃ¢y lÃ  sÃ¡ch má»›i cá»§a Murphy, Ä‘Æ°á»£c updated tá»« quyá»ƒn â€œMachine Learning: A Probabilistic Perspectiveâ€ (2012) lÃ  má»™t trong nhá»¯ng cuá»‘n sÃ¡ch ná»n táº£ng vá» xÃ¡c suáº¥t á»©ng dá»¥ng trong Machine Learning. CÃ¡c báº¡n cÃ³ thá»ƒ chÆ°a biáº¿t â€œMachine Learning: A Probabilistic Perspectiveâ€ (2012) nháº­n Ä‘Æ°á»£c giáº£i thÆ°á»Ÿng danh giÃ¡ DeGroot Prize (https://bayesian.org/project/degroot-prize/) nÄƒm 2013 cho nhá»¯ng Ä‘Ã³ng gÃ³p xuáº¥t sáº¯c trong lÄ©nh vá»±c khoa há»c thá»‘ng kÃª. Cuá»‘n sÃ¡ch covers ráº¥t nhiá»u topics khÃ¡c nhau cá»§a xÃ¡c suáº¥t thá»‘ng kÃª vÃ  tÃ­nh liÃªn há»‡ máº­t thiáº¿t trong mÃ¡y há»c nhÆ° Probability Optimization, Conditional Random Fields, L1 Regularization, Bayesian Decision Theory, Gaussian Models vÃ  Deep Learning. NÄƒm 2012 Ä‘Æ°á»£c nháº­n Ä‘á»‹nh lÃ  khá»Ÿi Ä‘áº§u cá»§a â€œká»· nguyÃªn há»c sÃ¢uâ€ (Deep Learning Revolution). Khoáº£ng 8 nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y chÃºng ta Ä‘Ã£ chá»©ng kiáº¿n nhá»¯ng á»©ng dá»¥ng vÃ´ cÃ¹ng ná»•i báº­t cá»§a Machine Learning vÃ  Deep Learning trong Computer Vision, Natural Language Processing vÃ  Reinforcement Learning. NÄƒm 2018, Murphy nháº­n tháº¥y cÃ²n nhiá»u thiáº¿u sÃ³t trong quyá»ƒn sÃ¡ch Ä‘áº§u tay cá»§a mÃ¬nh nÃªn Ä‘Ã£ tiáº¿n hÃ nh viáº¿t hoÃ n thiá»‡n nÃ³. Báº£n tháº£o Ä‘áº§u tiÃªn khi hoÃ n thÃ nh (2020) dÃ i khoáº£ng 1600 trang, tuy nhiÃªn MIT Press khÃ´ng thá»ƒ publish má»™t quyá»ƒn sÃ¡ch dÃ i nhÆ° váº­y! Murphy quyáº¿t Ä‘á»‹nh chia thÃ nh 2 quyá»ƒn khÃ¡c nhau. ÄÃ³ lÃ  â€œProbabilistic Machine Learning: An Introduction (2021)â€ vÃ  â€œProbabilistic Machine Learning: Advanced Topics (2022)â€. Hai quyá»ƒn káº¿ thá»«a nhá»¯ng Ä‘iá»ƒm máº¥u chá»‘t vÃ  xuáº¥t sáº¯c tá»« quyá»ƒn Ä‘áº§u tiÃªn. ThÃªm vÃ o Ä‘Ã³ lÃ  ráº¥t nhiá»u ná»™i dung má»›i cá»§a â€œká»· nguyÃªn há»c sÃ¢uâ€ nhÆ° Generative Models, Variational Inference vÃ  Reinforcement Learning. Vá»›i phong cÃ¡ch viáº¿t giáº£n dá»‹, gáº§n gÅ©i, dá»… tiáº¿p cáº­n vÃ  hoÃ n chá»‰nh cho cÃ¡c thuáº­t toÃ¡n, Ä‘á»“ng thá»i vá»›i ráº¥t nhiá»u hÃ¬nh áº£nh vÃ  vÃ­ dá»¥ trá»±c quan, mÃ¬nh tin ráº±ng cÃ¡c báº¡n sáº½ há»c Ä‘Æ°á»£c ráº¥t nhiá»u Ä‘iá»u thÃº vá»‹ vÃ  bá»• Ã­ch trong quyá»ƒn sÃ¡ch nÃ y. Trang chá»§ vÃ  draft version (2021) cá»§a 2 quyá»ƒn sÃ¡ch: https://probml.github.io/pml-book/ Happy Learning and Happy New Year! ************************************************** MÃ¬nh cÃ³ note láº¡i danh sÃ¡ch nhá»¯ng quyá»ƒn sÃ¡ch â€œgá»‘i Ä‘áº§uâ€ trong Machine Learning, cÃ¡c báº¡n cÃ³ thá»ƒ xem qua nhÃ©! Pattern Recognition and Machine Learning (2006) â€“ Bishop (https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (2009) - Trevor Hastie et al. (https://web.stanford.edu/~hastie/ElemStatLearn/) Machine Learning: A Probabilistic Perspective (2012) â€“ Murphy (https://probml.github.io/pml-book/) Deep Learning (2015) â€“ Ian Goodfellow et al. (https://www.deeplearningbook.org/) Foundations of Machine Learning, Second Edition (2018) - Mehryar Mohri et al. (https://cs.nyu.edu/~mohri/mlbook/)",,,,,
,nan,,,,,
"ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i,
Cho miÌ€nh hoÌ‰i laÌ€m sao Ä‘ÃªÌ‰ tiÌ€m ra mÃ´Ì£t ngÆ°Æ¡Ìƒng threshold phuÌ€ hÆ¡Ì£p Ä‘ÃªÌ‰ chuyÃªÌ‰n Ä‘Ã´Ì‰i tÆ°Ì€ thuÃ´Ì£c tiÌnh coÌ giaÌ triÌ£ liÃªn tuÌ£c sang thuÃ´Ì£c tiÌnh coÌ daÌ£ng categorical ? MiÌ€nh Ä‘ang duÌ€ng ID3 cho Decision Tree.
CaÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i.","ChaÌ€o moÌ£i ngÆ°Æ¡Ì€i, Cho miÌ€nh hoÌ‰i laÌ€m sao Ä‘ÃªÌ‰ tiÌ€m ra mÃ´Ì£t ngÆ°Æ¡Ìƒng threshold phuÌ€ hÆ¡Ì£p Ä‘ÃªÌ‰ chuyÃªÌ‰n Ä‘Ã´Ì‰i tÆ°Ì€ thuÃ´Ì£c tiÌnh coÌ giaÌ triÌ£ liÃªn tuÌ£c sang thuÃ´Ì£c tiÌnh coÌ daÌ£ng categorical ? MiÌ€nh Ä‘ang duÌ€ng ID3 cho Decision Tree. CaÌ‰m Æ¡n moÌ£i ngÆ°Æ¡Ì€i.",,,,,
https://m.facebook.com/groups/VietnamAiLlinkSharing/permalink/444600300280364/,https://m.facebook.com/groups/VietnamAiLlinkSharing/permalink/444600300280364/,,,,,
"Cho há»i báº¡n nÃ o biáº¿t Ä‘oáº¡n code nÃ o káº¿t há»£p 2 hay nhiá»u thuáº­t toÃ¡n phÃ¢n cá»¥m nhÆ° :
Agglomerative Clustering, BIRCH,DBSCAN,K-Means,Mini-Batch K-Means, Mean Shift, OPTICS, Spectral Clustering, Mixture of
Gaussians láº¡i vá»›i nhau khÃ´ng
Cáº£m Æ¡n !","Cho há»i báº¡n nÃ o biáº¿t Ä‘oáº¡n code nÃ o káº¿t há»£p 2 hay nhiá»u thuáº­t toÃ¡n phÃ¢n cá»¥m nhÆ° : Agglomerative Clustering, BIRCH,DBSCAN,K-Means,Mini-Batch K-Means, Mean Shift, OPTICS, Spectral Clustering, Mixture of Gaussians láº¡i vá»›i nhau khÃ´ng Cáº£m Æ¡n !",,,,,
"Má»i ngÆ°á»i cho em xin vÃ i tá»±a sÃ¡ch (textbook), bÃ i giáº£ng (lecture) hoáº·c khoÃ¡ há»c (course) vá» toÃ¡n rá»i ráº¡c Ä‘áº§y Ä‘á»§ kiáº¿n thá»©c tá»« táº­p há»£p-logic Ä‘áº¿n tá»• há»£p, Ä‘á»“ thá»‹ áº¡.
P/s: tiáº¿ng Anh cÅ©ng Ä‘Æ°á»£c áº¡.","Má»i ngÆ°á»i cho em xin vÃ i tá»±a sÃ¡ch (textbook), bÃ i giáº£ng (lecture) hoáº·c khoÃ¡ há»c (course) vá» toÃ¡n rá»i ráº¡c Ä‘áº§y Ä‘á»§ kiáº¿n thá»©c tá»« táº­p há»£p-logic Ä‘áº¿n tá»• há»£p, Ä‘á»“ thá»‹ áº¡. P/s: tiáº¿ng Anh cÅ©ng Ä‘Æ°á»£c áº¡.",,,,,
"ChÃ o anh em,
MÃ¬nh hiá»‡n táº¡i báº¯t Ä‘áº§u há»c vá» ML vá»›i AI, nhá» anh em cho mÃ¬nh thÃªm lá»i khuyÃªn, cÃ¡c lá»™ trÃ¬nh tá»± há»c vÃ  cÃ¡c khÃ³a há»c tham kháº£o Ä‘á»ƒ cÃ³ thá»ƒ tá»± há»c nhanh vÃ  hiá»‡u quáº£ nháº¥t.
NgoÃ i ra, Ä‘á»ƒ nghiÃªn cá»©u chuyÃªn sÃ¢u thÃ¬ mÃ¬nh cáº§n chuáº©n bá»‹ kiáº¿n thá»©c toÃ¡n há»c gá»“m nhá»¯ng pháº§n nÃ o lÃ  Ä‘á»§ váº­y?
Hiá»‡n táº¡i mÃ¬nh lÃ  .NET Developer, Ä‘á»ƒ há»c ML thÃ¬ cáº§n code Ä‘Æ°á»£c Python. Nhá» anh em introduce mÃ¬nh thÃªm cÃ¡c courses vá» Python for ML nhÃ©.
CÃ¡m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","ChÃ o anh em, MÃ¬nh hiá»‡n táº¡i báº¯t Ä‘áº§u há»c vá» ML vá»›i AI, nhá» anh em cho mÃ¬nh thÃªm lá»i khuyÃªn, cÃ¡c lá»™ trÃ¬nh tá»± há»c vÃ  cÃ¡c khÃ³a há»c tham kháº£o Ä‘á»ƒ cÃ³ thá»ƒ tá»± há»c nhanh vÃ  hiá»‡u quáº£ nháº¥t. NgoÃ i ra, Ä‘á»ƒ nghiÃªn cá»©u chuyÃªn sÃ¢u thÃ¬ mÃ¬nh cáº§n chuáº©n bá»‹ kiáº¿n thá»©c toÃ¡n há»c gá»“m nhá»¯ng pháº§n nÃ o lÃ  Ä‘á»§ váº­y? Hiá»‡n táº¡i mÃ¬nh lÃ  .NET Developer, Ä‘á»ƒ há»c ML thÃ¬ cáº§n code Ä‘Æ°á»£c Python. Nhá» anh em introduce mÃ¬nh thÃªm cÃ¡c courses vá» Python for ML nhÃ©. CÃ¡m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"CÃC A Æ I EM MUá»N Sá»¬A Äáº¦U VÃ€O Cá»¦A BÃ€I NHáº¬N DIá»†N BIá»‚N Sá» XE Báº°NG WPOD VÃ€ TESSERACT OCR  LÃ€ FILE VIDEO CÆ  MÃ€ Bá»Š Lá»–I CÃC BÃC Sá»¬A GIÃšP E Vá»šI áº  . E Cáº¢M Æ N MN
http://codepad.org/6SlQ0Vz1",CÃC A Æ I EM MUá»N Sá»¬A Äáº¦U VÃ€O Cá»¦A BÃ€I NHáº¬N DIá»†N BIá»‚N Sá» XE Báº°NG WPOD VÃ€ TESSERACT OCR LÃ€ FILE VIDEO CÆ  MÃ€ Bá»Š Lá»–I CÃC BÃC Sá»¬A GIÃšP E Vá»šI áº  . E Cáº¢M Æ N MN http://codepad.org/6SlQ0Vz1,,,,,
"Má»™t trong nhá»¯ng cuá»‘n sÃ¡ch yÃªu thÃ­ch cá»§a mÃ¬nh vá» Practical Machine Learning
https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/
Cuá»‘n nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch ra ráº¥t nhiá»u thá»© tiáº¿ng, hy vá»ng má»™t ngÃ y khÃ´ng xa sáº½ cÃ³ báº£n tiáº¿ng Viá»‡t ;)","Má»™t trong nhá»¯ng cuá»‘n sÃ¡ch yÃªu thÃ­ch cá»§a mÃ¬nh vá» Practical Machine Learning https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ Cuá»‘n nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch ra ráº¥t nhiá»u thá»© tiáº¿ng, hy vá»ng má»™t ngÃ y khÃ´ng xa sáº½ cÃ³ báº£n tiáº¿ng Viá»‡t ;)",,,,,
"#nlp
Má»i ngÆ°á»i cho em há»i hiá»‡n nay biá»ƒu diá»…n vector tá»« tiáº¿ng anh Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng thÃ¬ pretrained nÃ o tá»‘t nháº¥t áº¡? Em cáº£m Æ¡n",Má»i ngÆ°á»i cho em há»i hiá»‡n nay biá»ƒu diá»…n vector tá»« tiáº¿ng anh Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng thÃ¬ pretrained nÃ o tá»‘t nháº¥t áº¡? Em cáº£m Æ¡n,#nlp,,,,
"#hoidap #tensorflowSharp
má»i ngÆ°á»i Æ¡i cho em há»i vÃ i cÃ¢u:
https://teachablemachine.withgoogle.com/train/image
em dÃ¹ng trang nÃ y Ä‘á»ƒ gen ra file .pb vÃ  labels.txt
em dÃ¹ng https://github.com/Syn-McJ/TFClassify-Unity
vÃ  tháº¿ cÃ¡i .pb Ä‘Ã³ vÃ o code example : Assets/Scripts/Detector.cs line 41 thÃ¬ gáº·p lá»—i invalid graphDef
em tÃ¬m kháº¯p nÆ¡i rá»“i nhÆ°ng cÅ©ng chá»‰ nÃ³i má»™t vÃ i thÃ´ng tin á»Ÿ python. cÃ²n C# thÃ¬ khÃ´ng cÃ³ function tÆ°Æ¡ng á»©ng ^^
Há»I: cÃ³ dÃ¹ng trang web cá»§a google kia train rá»“i láº¥y model vá» dÃ¹ng cho TFSharp Ä‘Æ°á»£c khÃ´ng ?
cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ Import khÃ´ng ?",má»i ngÆ°á»i Æ¡i cho em há»i vÃ i cÃ¢u: https://teachablemachine.withgoogle.com/train/image em dÃ¹ng trang nÃ y Ä‘á»ƒ gen ra file .pb vÃ  labels.txt em dÃ¹ng https://github.com/Syn-McJ/TFClassify-Unity vÃ  tháº¿ cÃ¡i .pb Ä‘Ã³ vÃ o code example : Assets/Scripts/Detector.cs line 41 thÃ¬ gáº·p lá»—i invalid graphDef em tÃ¬m kháº¯p nÆ¡i rá»“i nhÆ°ng cÅ©ng chá»‰ nÃ³i má»™t vÃ i thÃ´ng tin á»Ÿ python. cÃ²n C# thÃ¬ khÃ´ng cÃ³ function tÆ°Æ¡ng á»©ng ^^ Há»I: cÃ³ dÃ¹ng trang web cá»§a google kia train rá»“i láº¥y model vá» dÃ¹ng cho TFSharp Ä‘Æ°á»£c khÃ´ng ? cÃ³ cÃ¡ch nÃ o khÃ¡c Ä‘á»ƒ Import khÃ´ng ?,#hoidap	#tensorflowSharp,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, tiáº¿p tá»¥c series BERT. HÃ´m nay em xin máº¡nh dáº¡n chia sáº» cÃ¹ng anh em bÃ i toÃ¡n nháº­n diá»‡n cáº£m xÃºc vÄƒn báº£n Tiáº¿ng Viá»‡t sá»­ dá»¥ng PhoBERT cá»§a VinAI mÃ  em vá»«a há»c.
Hi vá»ng giÃºp Ä‘Æ°á»£c anh em trong cÃ¡c bÃ i toÃ¡n NLP.
Ps: TÃ i liá»‡u chá»‰ mong giÃºp cÃ¡c anh em newbie má»›i há»c thÃ´i ah. Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, tiáº¿p tá»¥c series BERT. HÃ´m nay em xin máº¡nh dáº¡n chia sáº» cÃ¹ng anh em bÃ i toÃ¡n nháº­n diá»‡n cáº£m xÃºc vÄƒn báº£n Tiáº¿ng Viá»‡t sá»­ dá»¥ng PhoBERT cá»§a VinAI mÃ  em vá»«a há»c. Hi vá»ng giÃºp Ä‘Æ°á»£c anh em trong cÃ¡c bÃ i toÃ¡n NLP. Ps: TÃ i liá»‡u chá»‰ mong giÃºp cÃ¡c anh em newbie má»›i há»c thÃ´i ah. Mong ad duyá»‡t bÃ i!",,,,,
"ChÃ o má»i ngÆ°á»i, em hiá»‡n Ä‘ang lÃ m má»™t cuá»™c kháº£o sÃ¡t vá» viá»‡c á»©ng dá»¥ng machine learning hoáº·c deep learning trong cÃ´ng viá»‡c má»i ngÆ°á»i Ä‘ang lÃ m
Má»i ngÆ°á»i vui lÃ²ng click vÃ  tráº£ lá»i kháº£o sÃ¡t trÃªn google form nÃ y giÃºp e nhÃ©
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ há»£p tÃ¡c","ChÃ o má»i ngÆ°á»i, em hiá»‡n Ä‘ang lÃ m má»™t cuá»™c kháº£o sÃ¡t vá» viá»‡c á»©ng dá»¥ng machine learning hoáº·c deep learning trong cÃ´ng viá»‡c má»i ngÆ°á»i Ä‘ang lÃ m Má»i ngÆ°á»i vui lÃ²ng click vÃ  tráº£ lá»i kháº£o sÃ¡t trÃªn google form nÃ y giÃºp e nhÃ© Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ há»£p tÃ¡c",,,,,
"Machine learning models hiá»‡n Ä‘ang ngÃ y cÃ ng lá»›n vÃ  cháº¡y ngÃ y cÃ ng cháº­m. Nhiá»u ngÆ°á»i nghÄ© viá»‡c nÃ y lÃ  má»™t rÃ o cáº£n khiáº¿n cho viá»‡c Ä‘Æ°a cÃ¡c chÆ°Æ¡ng trÃ¬nh nÃ y vÃ o á»©ng dá»¥ng. Nhiá»u cÃ´ng ty khÃ´ng dÃ¡m cháº¡y online predictions mÃ  cháº¡y batch predictions.
Sau khi nÃ³i chuyá»‡n vá»›i cÃ¡c cÃ´ng ty lá»›n, mÃ¬nh nháº­n ra ráº±ng má»™t sá»‘ cÃ´ng ty khÃ´ng chá»‰ cháº¡y online predictions mÃ  cÃ²n cháº¡y online learning!
BÃ i viáº¿t nÃ y phÃ¢n tÃ­ch cÃ¡c á»©ng dá»¥ng cá»§a real-time machine learning dá»±a vÃ o cÃ¡c cuá»™c nÃ³i chuyá»‡n vá»›i cÃ¡c cÃ´ng ty lá»›n á»Ÿ cáº£ Má»¹ vÃ  Trung Quá»‘c, bao gá»“m Netflix, DoorDash, Yelp, Tencent, Alibaba, TikTok, â€¦ MÃ¬nh cÅ©ng khÃ¡ ngáº¡c nhiÃªn khi gáº·p má»™t sá»‘ ká»¹ sÆ° á»Ÿ Viá»‡t Nam ráº¥t máº¡nh vá» khoáº£n nÃ y, chuyÃªn sÃ¢u hÆ¡n háº³n khÃ¡ nhiá»u ká»¹ sÆ° mÃ¬nh Ä‘Ã£ nÃ³i chuyá»‡n á»Ÿ cÃ¡c cÃ´ng ty lá»›n cá»§a Má»¹.
Vá»›i real-time machine learning, infra lÃ  vÃ´ cÃ¹ng quan trá»ng, vÃ  mÃ¬nh tháº¥y cÃ¡c cÃ´ng ty TQ ráº¥t cÃ³ thá»ƒ Ä‘ang Ä‘i trÆ°á»›c cÃ¡c cÃ´ng ty Má»¹ vá» máº£ng infra cho AI.
Náº¿u báº¡n nÃ o trong nhÃ³m lÃ m vá» real-time machine learning, mÃ¬nh ráº¥t hy vá»ng cÃ³ thá»ƒ há»c há»i tá»« báº¡n!","Machine learning models hiá»‡n Ä‘ang ngÃ y cÃ ng lá»›n vÃ  cháº¡y ngÃ y cÃ ng cháº­m. Nhiá»u ngÆ°á»i nghÄ© viá»‡c nÃ y lÃ  má»™t rÃ o cáº£n khiáº¿n cho viá»‡c Ä‘Æ°a cÃ¡c chÆ°Æ¡ng trÃ¬nh nÃ y vÃ o á»©ng dá»¥ng. Nhiá»u cÃ´ng ty khÃ´ng dÃ¡m cháº¡y online predictions mÃ  cháº¡y batch predictions. Sau khi nÃ³i chuyá»‡n vá»›i cÃ¡c cÃ´ng ty lá»›n, mÃ¬nh nháº­n ra ráº±ng má»™t sá»‘ cÃ´ng ty khÃ´ng chá»‰ cháº¡y online predictions mÃ  cÃ²n cháº¡y online learning! BÃ i viáº¿t nÃ y phÃ¢n tÃ­ch cÃ¡c á»©ng dá»¥ng cá»§a real-time machine learning dá»±a vÃ o cÃ¡c cuá»™c nÃ³i chuyá»‡n vá»›i cÃ¡c cÃ´ng ty lá»›n á»Ÿ cáº£ Má»¹ vÃ  Trung Quá»‘c, bao gá»“m Netflix, DoorDash, Yelp, Tencent, Alibaba, TikTok, â€¦ MÃ¬nh cÅ©ng khÃ¡ ngáº¡c nhiÃªn khi gáº·p má»™t sá»‘ ká»¹ sÆ° á»Ÿ Viá»‡t Nam ráº¥t máº¡nh vá» khoáº£n nÃ y, chuyÃªn sÃ¢u hÆ¡n háº³n khÃ¡ nhiá»u ká»¹ sÆ° mÃ¬nh Ä‘Ã£ nÃ³i chuyá»‡n á»Ÿ cÃ¡c cÃ´ng ty lá»›n cá»§a Má»¹. Vá»›i real-time machine learning, infra lÃ  vÃ´ cÃ¹ng quan trá»ng, vÃ  mÃ¬nh tháº¥y cÃ¡c cÃ´ng ty TQ ráº¥t cÃ³ thá»ƒ Ä‘ang Ä‘i trÆ°á»›c cÃ¡c cÃ´ng ty Má»¹ vá» máº£ng infra cho AI. Náº¿u báº¡n nÃ o trong nhÃ³m lÃ m vá» real-time machine learning, mÃ¬nh ráº¥t hy vá»ng cÃ³ thá»ƒ há»c há»i tá»« báº¡n!",,,,,
"#hoidap
Má»i ngÆ°á»i Æ¡i, cho em há»i vá» viá»‡c phÃ¢n tÃ­ch sáº¯c thÃ¡i bÃ¬nh luáº­n trong machine learning vá»›i áº¡,em cÅ©ng má»›i há»c nghiÃªn cá»©u nÃªn chÆ°a hiá»ƒu sÃ¢u vÃ  cÃ³ tÃ¬m Ä‘Æ°á»£c 1 bÃ i cá»§a 1 anh Ä‘Ã£ lÃ m vÃ  cÃ³ source code á»Ÿ trÃªn forum rá»“i nÃªn lÃ  cÃ³ ai Ä‘Ã£ tá»«ng xem qua bÃ i trÃªn nÃ y cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em vá»›i ko áº¡?Em cáº£m Æ¡n","Má»i ngÆ°á»i Æ¡i, cho em há»i vá» viá»‡c phÃ¢n tÃ­ch sáº¯c thÃ¡i bÃ¬nh luáº­n trong machine learning vá»›i áº¡,em cÅ©ng má»›i há»c nghiÃªn cá»©u nÃªn chÆ°a hiá»ƒu sÃ¢u vÃ  cÃ³ tÃ¬m Ä‘Æ°á»£c 1 bÃ i cá»§a 1 anh Ä‘Ã£ lÃ m vÃ  cÃ³ source code á»Ÿ trÃªn forum rá»“i nÃªn lÃ  cÃ³ ai Ä‘Ã£ tá»«ng xem qua bÃ i trÃªn nÃ y cÃ³ thá»ƒ giáº£i thÃ­ch giÃºp em vá»›i ko áº¡?Em cáº£m Æ¡n",#hoidap,,,,
"Hello guys. Happy new year.
I decided to write a small blog during my new year vacation. It has been a while since my last blog, mostly due to the block of Medium in Vietnam ğŸ™
This time I will write about AI in audio industry. Not academic one but things/tips I learned during my 4 months working with them. Please don't asking for the code :))
https://sites.google.com/sssmar.../ai-in-audio-industry/home","Hello guys. Happy new year. I decided to write a small blog during my new year vacation. It has been a while since my last blog, mostly due to the block of Medium in Vietnam This time I will write about AI in audio industry. Not academic one but things/tips I learned during my 4 months working with them. Please don't asking for the code :)) https://sites.google.com/sssmar.../ai-in-audio-industry/home",,,,,
"E Ä‘ang lÃ m bÃ i toÃ¡n phÃ¢n loáº¡i K means, cáº§n phÃ¢n loáº¡i ~ 150.000 vector vá»›i K=1500, nÃªn cháº¡y ráº¥t lÃ¢u áº¡ (~1h)
Má»i ngÆ°á»i cho e há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÄƒng tá»‘c K means khÃ´ng áº¡?","E Ä‘ang lÃ m bÃ i toÃ¡n phÃ¢n loáº¡i K means, cáº§n phÃ¢n loáº¡i ~ 150.000 vector vá»›i K=1500, nÃªn cháº¡y ráº¥t lÃ¢u áº¡ (~1h) Má»i ngÆ°á»i cho e há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÄƒng tá»‘c K means khÃ´ng áº¡?",,,,,
"#computervision #face_recognition
ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ 1 bÃ i toÃ¡n sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡
Giáº£ sá»­ mÃ¬nh cÃ³ 2 Ä‘oáº¡n video Ä‘Æ°á»£c ghi bá»Ÿi cÃ¹ng 1 cam , cÃ¹ng 1 gÃ³c cam, cÃ¹ng thÃ´ng sá»‘. VÃ­ dá»¥ vá»›i video 1 sau khi mÃ¬nh sá»­ dá»¥ng face detection Ä‘á»ƒ cáº¯t thÃ¬ mÃ¬nh cáº¯t Ä‘Æ°á»£c máº·t cá»§a 3 ngÆ°á»i, má»—i ngÆ°á»i cÃ³ táº§m khoáº£ng 5,6 áº£nh
YÃªu cáº§u Ä‘á» bÃ i lÃ  vá»›i video thá»© 2 thÃ¬ lÃ m ntn Ä‘á»ƒ nháº­n diá»‡n ra 3 ngÆ°á»i mÃ¬nh Ä‘Ã£ cáº¯t ra á»Ÿ video 1
Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ thá»­ má»™t vÃ i cÃ¡ch :
- XÃ¢y dá»±ng bá»™ classification tá»« máº¥y áº£nh cáº¯t ra tá»« video 1. Vá»›i video 2 thÃ¬ mÃ¬nh dÃ¹ng face detection vÃ  Ä‘Æ°a vÃ o bá»™ phÃ¢n loáº¡i
- Sá»­ dá»¥ng cÃ¡c pretrain Ä‘á»ƒ extract embedding -> sá»­ dá»¥ng cÃ¡c hÃ m Ä‘á»ƒ tÃ­nh similarity nhÆ° Euclidean , Cosin
Vá»›i cÃ¡c cÃ¡ch cá»§a mÃ¬nh thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c Ä‘ang k Ä‘Æ°á»£c nhÆ° mong muá»‘n. Má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p gÃ¬ vá»›i bÃ i toÃ¡n cá»§a mÃ¬nh khÃ´ng thÃ¬ chia sáº» nhÃ© :D
MÃ¬nh cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ 1 bÃ i toÃ¡n sau mong má»i ngÆ°á»i giÃºp Ä‘á»¡ Giáº£ sá»­ mÃ¬nh cÃ³ 2 Ä‘oáº¡n video Ä‘Æ°á»£c ghi bá»Ÿi cÃ¹ng 1 cam , cÃ¹ng 1 gÃ³c cam, cÃ¹ng thÃ´ng sá»‘. VÃ­ dá»¥ vá»›i video 1 sau khi mÃ¬nh sá»­ dá»¥ng face detection Ä‘á»ƒ cáº¯t thÃ¬ mÃ¬nh cáº¯t Ä‘Æ°á»£c máº·t cá»§a 3 ngÆ°á»i, má»—i ngÆ°á»i cÃ³ táº§m khoáº£ng 5,6 áº£nh YÃªu cáº§u Ä‘á» bÃ i lÃ  vá»›i video thá»© 2 thÃ¬ lÃ m ntn Ä‘á»ƒ nháº­n diá»‡n ra 3 ngÆ°á»i mÃ¬nh Ä‘Ã£ cáº¯t ra á»Ÿ video 1 Hiá»‡n táº¡i mÃ¬nh Ä‘Ã£ thá»­ má»™t vÃ i cÃ¡ch : - XÃ¢y dá»±ng bá»™ classification tá»« máº¥y áº£nh cáº¯t ra tá»« video 1. Vá»›i video 2 thÃ¬ mÃ¬nh dÃ¹ng face detection vÃ  Ä‘Æ°a vÃ o bá»™ phÃ¢n loáº¡i - Sá»­ dá»¥ng cÃ¡c pretrain Ä‘á»ƒ extract embedding -> sá»­ dá»¥ng cÃ¡c hÃ m Ä‘á»ƒ tÃ­nh similarity nhÆ° Euclidean , Cosin Vá»›i cÃ¡c cÃ¡ch cá»§a mÃ¬nh thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c Ä‘ang k Ä‘Æ°á»£c nhÆ° mong muá»‘n. Má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p gÃ¬ vá»›i bÃ i toÃ¡n cá»§a mÃ¬nh khÃ´ng thÃ¬ chia sáº» nhÃ© :D MÃ¬nh cáº£m Æ¡n",#computervision	#face_recognition,,,,
"HÃ´m nay lÃ  sinh nháº­t láº§n thá»© tÆ° cá»§a Machine Learning CÆ¡ Báº£n. Sau bá»‘n nÄƒm, mÃ¬nh ráº¥t vui vÃ¬ chÃºng ta Ä‘Ã£ cÃ³ má»™t cá»™ng Ä‘á»“ng lá»›n vá»›i nhiá»u dá»± Ã¡n thÃº vá»‹.
Hy vá»ng Machine Learning CÆ¡ Báº£n sáº½ tiáº¿p tá»¥c mang Ä‘áº¿n nhá»¯ng giÃ¡ trá»‹ má»›i cho cá»™ng Ä‘á»“ng ML/AI Viá»‡t Nam.
 â€” vá»›i Cu Nguyen.","HÃ´m nay lÃ  sinh nháº­t láº§n thá»© tÆ° cá»§a Machine Learning CÆ¡ Báº£n. Sau bá»‘n nÄƒm, mÃ¬nh ráº¥t vui vÃ¬ chÃºng ta Ä‘Ã£ cÃ³ má»™t cá»™ng Ä‘á»“ng lá»›n vá»›i nhiá»u dá»± Ã¡n thÃº vá»‹. Hy vá»ng Machine Learning CÆ¡ Báº£n sáº½ tiáº¿p tá»¥c mang Ä‘áº¿n nhá»¯ng giÃ¡ trá»‹ má»›i cho cá»™ng Ä‘á»“ng ML/AI Viá»‡t Nam. â€” vá»›i Cu Nguyen.",,,,,
"Giáº£i trÃ­ cuá»‘i tuáº§n - má»i ngÆ°á»i nghÄ© AI sáº½ há»— trá»£ hay Ä‘Ã o tháº£i nghá»‡ sÄ© truyá»n thá»‘ng?
>>>BÃ i hÃ¡t mÃ´ phá»ng Katy Perry tá»« Jukebok - OpenAI: https://soundcloud.com/open.../jukebox-novel_lyrics-78968609",Giáº£i trÃ­ cuá»‘i tuáº§n - má»i ngÆ°á»i nghÄ© AI sáº½ há»— trá»£ hay Ä‘Ã o tháº£i nghá»‡ sÄ© truyá»n thá»‘ng? >>>BÃ i hÃ¡t mÃ´ phá»ng Katy Perry tá»« Jukebok - OpenAI: https://soundcloud.com/open.../jukebox-novel_lyrics-78968609,,,,,
CÃ¡c cao nhÃ¢n cho em há»i vá» genetic network programming. Em tÃ¬m tÃ i liá»‡u vÃ  code demo mÃ  khÃ³ quÃ¡. Em cáº£m Æ¡n,CÃ¡c cao nhÃ¢n cho em há»i vá» genetic network programming. Em tÃ¬m tÃ i liá»‡u vÃ  code demo mÃ  khÃ³ quÃ¡. Em cáº£m Æ¡n,,,,,
"MÃ¬nh cÃ³ nhiá»u file áº£nh chá»¥p cÃ¡c form khÃ¡c nhau trÃªn Ä‘Ã³ cÃ³ cÃ¡c trÆ°á»ng (dÃ¹ng chá»§ yáº¿u chá»¯ in Ä‘Ã¡nh mÃ¡y, nhÆ°ng thi thoáº£ng cÅ©ng cÃ³ chá»— viáº¿t tay), cáº§n cÃ³ má»™t tool cÃ³ thá»ƒ train Ä‘á»ƒ tÃ¡ch cÃ¡c dÃ²ng chá»¯ tá»« cÃ¡c áº£nh chá»©a form nÃ y (cÃ³ thá»ƒ cÃ³ nhiá»u loáº¡i form nhÆ° há»“ sÆ¡ nhÃ¢n sá»±, phiáº¿u gÃ³p Ã½, báº£ng Ä‘Äƒng kÃ½ dá»‹ch vá»¥...) vÃ  lÆ°u ra file (hay database) thÃ nh cÃ¡c dÃ²ng vÃ  cá»™t dá»¯ liá»‡u. TÃªn cá»™t Ä‘Æ°á»£c Ä‘áº·t theo tÃªn cÃ¡c trÆ°á»ng trÃªn form hay Ä‘áº·t thá»§ cÃ´ng cÅ©ng Ä‘Æ°á»£c.
Báº¡n nÃ o Ä‘Ã£ dÃ¹ng hay biáº¿t cÃ¡c cÃ´ng cá»¥ loáº¡i nÃ y, xin giá»›i thiá»‡u giÃ¹m.
Náº¿u báº¡n lÃ m Ä‘Æ°á»£c cÃ´ng cá»¥ nÃ y vÃ  muá»‘n bÃ¡n thÃ¬ xin liÃªn há»‡ vá»›i mÃ¬nh.
CÃ¡m Æ¡n cÃ¡c báº¡n.","MÃ¬nh cÃ³ nhiá»u file áº£nh chá»¥p cÃ¡c form khÃ¡c nhau trÃªn Ä‘Ã³ cÃ³ cÃ¡c trÆ°á»ng (dÃ¹ng chá»§ yáº¿u chá»¯ in Ä‘Ã¡nh mÃ¡y, nhÆ°ng thi thoáº£ng cÅ©ng cÃ³ chá»— viáº¿t tay), cáº§n cÃ³ má»™t tool cÃ³ thá»ƒ train Ä‘á»ƒ tÃ¡ch cÃ¡c dÃ²ng chá»¯ tá»« cÃ¡c áº£nh chá»©a form nÃ y (cÃ³ thá»ƒ cÃ³ nhiá»u loáº¡i form nhÆ° há»“ sÆ¡ nhÃ¢n sá»±, phiáº¿u gÃ³p Ã½, báº£ng Ä‘Äƒng kÃ½ dá»‹ch vá»¥...) vÃ  lÆ°u ra file (hay database) thÃ nh cÃ¡c dÃ²ng vÃ  cá»™t dá»¯ liá»‡u. TÃªn cá»™t Ä‘Æ°á»£c Ä‘áº·t theo tÃªn cÃ¡c trÆ°á»ng trÃªn form hay Ä‘áº·t thá»§ cÃ´ng cÅ©ng Ä‘Æ°á»£c. Báº¡n nÃ o Ä‘Ã£ dÃ¹ng hay biáº¿t cÃ¡c cÃ´ng cá»¥ loáº¡i nÃ y, xin giá»›i thiá»‡u giÃ¹m. Náº¿u báº¡n lÃ m Ä‘Æ°á»£c cÃ´ng cá»¥ nÃ y vÃ  muá»‘n bÃ¡n thÃ¬ xin liÃªn há»‡ vá»›i mÃ¬nh. CÃ¡m Æ¡n cÃ¡c báº¡n.",,,,,
"Dáº¡ em xin chÃ o cÃ¡c anh chá»‹.
Hiá»‡n táº¡i em Ä‘ang cÃ³ má»™t bÃ i táº­p á»Ÿ trÆ°á»ng lÃ : phÃ¢n loáº¡i xe báº±ng SVM. Em muá»‘n tÃ¬m thÃªm tÃ i liá»‡u vá» SVM Ä‘á»ƒ Ä‘á»c. Má»i ngÆ°á»i cho em xin Ã­t tÃ i liá»‡u cháº¥t lÆ°á»£ng Ä‘Æ°á»£c khÃ´ng áº¡. E xin chÃ¢n thÃ nh cÃ¡m Æ¡n.",Dáº¡ em xin chÃ o cÃ¡c anh chá»‹. Hiá»‡n táº¡i em Ä‘ang cÃ³ má»™t bÃ i táº­p á»Ÿ trÆ°á»ng lÃ : phÃ¢n loáº¡i xe báº±ng SVM. Em muá»‘n tÃ¬m thÃªm tÃ i liá»‡u vá» SVM Ä‘á»ƒ Ä‘á»c. Má»i ngÆ°á»i cho em xin Ã­t tÃ i liá»‡u cháº¥t lÆ°á»£ng Ä‘Æ°á»£c khÃ´ng áº¡. E xin chÃ¢n thÃ nh cÃ¡m Æ¡n.,,,,,
"Xin phÃ©p má»i ngÆ°á»i trong group vÃ  admin áº¡
Hiá»‡n táº¡i mÃ¬nh má»›i báº¯t Ä‘áº§u há»c AI nÃªn mÃ¬nh Ä‘á»‹nh láº­p má»™t nhÃ³m nhá» (chá»© khÃ´ng add trÃ n lan vÃ  Ä‘Æ°Æ¡ng nhiÃªn lÃ  sáº½ cÃ³ nhá»¯ng tiÃªu chuáº©n nháº¥t Ä‘á»‹nh) Ä‘á»ƒ cÃ¹ng nhau há»c. Hiá»‡n táº¡i thÃ¬ mÃ¬nh Ä‘ang há»c song song 3 mÃ´n Calculus,Linear Algebra vÃ  Python. Náº¿u báº¡n nÃ o quan tÃ¢m thÃ¬ cÃ³ thá»ƒ ib mÃ¬nh Ä‘á»ƒ chÃºng ta cÃ¹ng trao Ä‘á»•i thÃªm nhÃ©","Xin phÃ©p má»i ngÆ°á»i trong group vÃ  admin áº¡ Hiá»‡n táº¡i mÃ¬nh má»›i báº¯t Ä‘áº§u há»c AI nÃªn mÃ¬nh Ä‘á»‹nh láº­p má»™t nhÃ³m nhá» (chá»© khÃ´ng add trÃ n lan vÃ  Ä‘Æ°Æ¡ng nhiÃªn lÃ  sáº½ cÃ³ nhá»¯ng tiÃªu chuáº©n nháº¥t Ä‘á»‹nh) Ä‘á»ƒ cÃ¹ng nhau há»c. Hiá»‡n táº¡i thÃ¬ mÃ¬nh Ä‘ang há»c song song 3 mÃ´n Calculus,Linear Algebra vÃ  Python. Náº¿u báº¡n nÃ o quan tÃ¢m thÃ¬ cÃ³ thá»ƒ ib mÃ¬nh Ä‘á»ƒ chÃºng ta cÃ¹ng trao Ä‘á»•i thÃªm nhÃ©",,,,,
"BÃ i chia sáº» Ä‘áº§u tiÃªn vá» object detection solution vá»›i OneNet. Vá»›i content creator: BÃ© Na
Náº¿u cÃ¡c báº¡n muá»‘n chia sáº» vá» cÃ¡c chá»§ Ä‘á» AI thÃ¬ hÃ£y tham gia vá»›i bá»n mÃ¬nh nhÃ©",BÃ i chia sáº» Ä‘áº§u tiÃªn vá» object detection solution vá»›i OneNet. Vá»›i content creator: BÃ© Na Náº¿u cÃ¡c báº¡n muá»‘n chia sáº» vá» cÃ¡c chá»§ Ä‘á» AI thÃ¬ hÃ£y tham gia vá»›i bá»n mÃ¬nh nhÃ©,,,,,
Mn cho mÃ¬nh há»i lÃ m sao Ä‘á»ƒ chuyá»ƒn file .crash sang csv áº¡,Mn cho mÃ¬nh há»i lÃ m sao Ä‘á»ƒ chuyá»ƒn file .crash sang csv áº¡,,,,,
"ChÃ o má»i ngÆ°á»i
Em Ä‘ang lÃ m bÃ i táº­p vá» Thá»‹ giÃ¡c mÃ¡y tÃ­nh. BÃ i toÃ¡n cá»§a em lÃ  tá»« áº£nh, nháº­n diá»‡n ra product list vÃ  nháº­n diá»‡n text tá»« list. Product list cÃ³ thá»ƒ lÃ  cÃ³ border hoáº·c khÃ´ng.
Em cÃ³ 2 cÃ¢u há»i sau mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p:
HÆ°á»›ng tiáº¿p cáº­n cho nháº­n diá»‡n ra productlist. Em Ä‘Ã£ thá»­ cÃ¡c hÆ°á»›ng Tabletnet, CascadTabNet, SSD, YOLO nhÆ°ng káº¿t quáº£ khÃ´ng tá»‘t láº¯m.
Vá»›i nháº­n diá»‡n text trong product list, model thÆ°á»ng khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c cÃ¡c vÃ¹ng/ cá»™t chá»‰ cÃ³ sá»‘ lÆ°á»£ng lÃ  ""1"", ""x1"" . Em muá»‘n há»i vá» hÆ°á»›ng xá»­ lÃ½ trong trÆ°á»ng há»£p nÃ y.
Em cÃ¡m Æ¡n.","ChÃ o má»i ngÆ°á»i Em Ä‘ang lÃ m bÃ i táº­p vá» Thá»‹ giÃ¡c mÃ¡y tÃ­nh. BÃ i toÃ¡n cá»§a em lÃ  tá»« áº£nh, nháº­n diá»‡n ra product list vÃ  nháº­n diá»‡n text tá»« list. Product list cÃ³ thá»ƒ lÃ  cÃ³ border hoáº·c khÃ´ng. Em cÃ³ 2 cÃ¢u há»i sau mong Ä‘Æ°á»£c giáº£i Ä‘Ã¡p: HÆ°á»›ng tiáº¿p cáº­n cho nháº­n diá»‡n ra productlist. Em Ä‘Ã£ thá»­ cÃ¡c hÆ°á»›ng Tabletnet, CascadTabNet, SSD, YOLO nhÆ°ng káº¿t quáº£ khÃ´ng tá»‘t láº¯m. Vá»›i nháº­n diá»‡n text trong product list, model thÆ°á»ng khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c cÃ¡c vÃ¹ng/ cá»™t chá»‰ cÃ³ sá»‘ lÆ°á»£ng lÃ  ""1"", ""x1"" . Em muá»‘n há»i vá» hÆ°á»›ng xá»­ lÃ½ trong trÆ°á»ng há»£p nÃ y. Em cÃ¡m Æ¡n.",,,,,
"MÃ¬nh cÃ³ cÃ¡c file PMML (Predictive Model Markup Language) lÆ°u cÃ¡c trained model, káº¿t quáº£ cá»§a quÃ¡ trÃ¬nh phÃ¢n tÃ­ch dá»¯ liá»‡u. MÃ¬nh muá»‘n chuyá»ƒn Ä‘á»•i cÃ¡c trained model nÃ y thÃ nh cÃ¡c SQL function/stored proc Ä‘á»ƒ tÃ­nh toÃ¡n káº¿t quáº£ cho cÃ¡c dÃ²ng dá»¯ liá»‡u má»›i phÃ¡t sinh cho tiá»‡n. Báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» váº¥n Ä‘á» nÃ y xin gÃ³p Ã½ giÃºp. Hoáº·c cÃ³ thá»ƒ dÃ¹ng cÃ¡c PMML engine/library nhá» gá»n nÃ o Ä‘Ã³ cho C# cÅ©ng Ä‘Æ°á»£c. Xin cÃ¡m Æ¡n.","MÃ¬nh cÃ³ cÃ¡c file PMML (Predictive Model Markup Language) lÆ°u cÃ¡c trained model, káº¿t quáº£ cá»§a quÃ¡ trÃ¬nh phÃ¢n tÃ­ch dá»¯ liá»‡u. MÃ¬nh muá»‘n chuyá»ƒn Ä‘á»•i cÃ¡c trained model nÃ y thÃ nh cÃ¡c SQL function/stored proc Ä‘á»ƒ tÃ­nh toÃ¡n káº¿t quáº£ cho cÃ¡c dÃ²ng dá»¯ liá»‡u má»›i phÃ¡t sinh cho tiá»‡n. Báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» váº¥n Ä‘á» nÃ y xin gÃ³p Ã½ giÃºp. Hoáº·c cÃ³ thá»ƒ dÃ¹ng cÃ¡c PMML engine/library nhá» gá»n nÃ o Ä‘Ã³ cho C# cÅ©ng Ä‘Æ°á»£c. Xin cÃ¡m Æ¡n.",,,,,
"#summarization
Em xin phÃ©p há»i má»i ngÆ°á»i trong group áº¡,
Em Ä‘Æ°á»£c giao task tÃ³m táº¯t vÄƒn báº£n sá»­ dá»¥ng PEGASUS hoáº·c BART, nhÆ°ng váº¥n Ä‘á» lÃ  mÃ´ hÃ¬nh PEGASUS, BART chá»‰ cho max_length = 1024, em Ä‘ang muá»‘n finetuning vá»›i dá»¯ liá»‡u dÃ i nÃªn cÃ³ Ä‘iá»u chá»‰nh max_length = 2048, chi tiáº¿t e gá»­i trong code colab:
https://colab.research.google.com/drive/16XysqYk9Fef4R8HaJZI_4NTjpdIULP45?usp=sharing
Váº¥n Ä‘á» em gáº·p pháº£i lÃ  em bá»‹ trÃ n cuda memory, model PEGASUS em load lÃªn chá»‰ 2,2GB, vÃ  em chá»‰ chá»‰nh sá»­a positional encoding. DÃ¹ em Ä‘Ã£ thá»­ Ã­t dá»¯ liá»‡u hÆ¡n (chá»‰ 10 Ä‘iá»ƒm dá»¯ liá»‡u), batch_size = 1, nhÆ°ng ngay tá»« iter Ä‘áº§u tiÃªn Ä‘Ã£ bá»‹ cuda out of memory. Em muá»‘n há»i:
Má»i ngÆ°á»i cÃ³ thá»ƒ xem vÃ  cÃ³ thá»ƒ cho em lÃ­ do táº¡i sao bá»‹ out of memory cuda vÃ  hÆ°á»›ng giáº£i quyáº¿t.
Má»i ngÆ°á»i tá»«ng thá»­ finetuning mÃ´ hÃ¬nh nÃ o vá»›i dá»¯ liá»‡u dÃ i hÆ¡n chÆ°a áº¡, cÃ³ thá»ƒ cho em xin chá»‰ dáº«n vá»›i.
Em xin cáº£m Æ¡n áº¡!","Em xin phÃ©p há»i má»i ngÆ°á»i trong group áº¡, Em Ä‘Æ°á»£c giao task tÃ³m táº¯t vÄƒn báº£n sá»­ dá»¥ng PEGASUS hoáº·c BART, nhÆ°ng váº¥n Ä‘á» lÃ  mÃ´ hÃ¬nh PEGASUS, BART chá»‰ cho max_length = 1024, em Ä‘ang muá»‘n finetuning vá»›i dá»¯ liá»‡u dÃ i nÃªn cÃ³ Ä‘iá»u chá»‰nh max_length = 2048, chi tiáº¿t e gá»­i trong code colab: https://colab.research.google.com/drive/16XysqYk9Fef4R8HaJZI_4NTjpdIULP45?usp=sharing Váº¥n Ä‘á» em gáº·p pháº£i lÃ  em bá»‹ trÃ n cuda memory, model PEGASUS em load lÃªn chá»‰ 2,2GB, vÃ  em chá»‰ chá»‰nh sá»­a positional encoding. DÃ¹ em Ä‘Ã£ thá»­ Ã­t dá»¯ liá»‡u hÆ¡n (chá»‰ 10 Ä‘iá»ƒm dá»¯ liá»‡u), batch_size = 1, nhÆ°ng ngay tá»« iter Ä‘áº§u tiÃªn Ä‘Ã£ bá»‹ cuda out of memory. Em muá»‘n há»i: Má»i ngÆ°á»i cÃ³ thá»ƒ xem vÃ  cÃ³ thá»ƒ cho em lÃ­ do táº¡i sao bá»‹ out of memory cuda vÃ  hÆ°á»›ng giáº£i quyáº¿t. Má»i ngÆ°á»i tá»«ng thá»­ finetuning mÃ´ hÃ¬nh nÃ o vá»›i dá»¯ liá»‡u dÃ i hÆ¡n chÆ°a áº¡, cÃ³ thá»ƒ cho em xin chá»‰ dáº«n vá»›i. Em xin cáº£m Æ¡n áº¡!",#summarization,,,,
MÃ¬nh vá»«a lÃ m 2 video vá» on-device machine learning (cÃ²n gá»i lÃ  Edge ML) vá» cÃ¡ch cháº¡y TensorFlow model trÃªn mobile app vÃ  thiáº¿t bá»‹ IoT. ÄÃ¢y lÃ  video Ä‘áº§u tiÃªn má»›i Ä‘Æ°á»£c up lÃªn kÃªnh TensorFlow trÃªn YouTube. Má»i ngÆ°á»i xem tham kháº£o vÃ  gÃ³p Ã½ nhÃ© :),MÃ¬nh vá»«a lÃ m 2 video vá» on-device machine learning (cÃ²n gá»i lÃ  Edge ML) vá» cÃ¡ch cháº¡y TensorFlow model trÃªn mobile app vÃ  thiáº¿t bá»‹ IoT. ÄÃ¢y lÃ  video Ä‘áº§u tiÃªn má»›i Ä‘Æ°á»£c up lÃªn kÃªnh TensorFlow trÃªn YouTube. Má»i ngÆ°á»i xem tham kháº£o vÃ  gÃ³p Ã½ nhÃ© :),,,,,
"Hi má»i ngÆ°á»i,
Em Ä‘ang báº¯t Ä‘áº§u lÃ m viá»‡c vá»›i máº¡ng GAN. Xin há»i má»i ngÆ°á»i, cÃ³ cÃ¡ch nÃ o xÃ¢y dá»±ng má»™t máº¡ng/ kÄ© thuáº­t Ä‘á»ƒ cÃ³ thá»ƒ tá»« má»™t áº£nh sinh ra hai áº£nh vá»›i Ä‘iá»u kiá»‡n hai áº£nh cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng lá»›n mÃ  khÃ´ng giá»‘ng nhau hoÃ n toÃ n hay khÃ´ng áº¡?
Em xin cáº£m Æ¡n.","Hi má»i ngÆ°á»i, Em Ä‘ang báº¯t Ä‘áº§u lÃ m viá»‡c vá»›i máº¡ng GAN. Xin há»i má»i ngÆ°á»i, cÃ³ cÃ¡ch nÃ o xÃ¢y dá»±ng má»™t máº¡ng/ kÄ© thuáº­t Ä‘á»ƒ cÃ³ thá»ƒ tá»« má»™t áº£nh sinh ra hai áº£nh vá»›i Ä‘iá»u kiá»‡n hai áº£nh cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng lá»›n mÃ  khÃ´ng giá»‘ng nhau hoÃ n toÃ n hay khÃ´ng áº¡? Em xin cáº£m Æ¡n.",,,,,
"#T5 #QA
Hi all, 
Em Ä‘ang train T5 cho Question answering, 
em chÆ°a rÃµ format cá»§a cÃ¡i input nhÆ° nÃ o vÃ  encode nhÆ° nÃ o.
Em nghÄ© lÃ 
input: ""question ...? context ...""
target: ""answer""
nhÆ°ng mÃ  em khÃ´ng biáº¿t nÃªn encode vá» ids nhÆ° tháº¿ nÃ o.
vá» cÆ¡ báº£n cháº¯c váº«n lÃ  BPE nhÆ°ng mÃ  Ä‘ang tháº¯c máº¯c lÃ  cÃ¡i cÃ¡i extra_ids (aka Sentinels) nhÆ° nÃ o
Má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em vá»›i áº¡.","Hi all, Em Ä‘ang train T5 cho Question answering, em chÆ°a rÃµ format cá»§a cÃ¡i input nhÆ° nÃ o vÃ  encode nhÆ° nÃ o. Em nghÄ© lÃ  input: ""question ...? context ..."" target: ""answer"" nhÆ°ng mÃ  em khÃ´ng biáº¿t nÃªn encode vá» ids nhÆ° tháº¿ nÃ o. vá» cÆ¡ báº£n cháº¯c váº«n lÃ  BPE nhÆ°ng mÃ  Ä‘ang tháº¯c máº¯c lÃ  cÃ¡i cÃ¡i extra_ids (aka Sentinels) nhÆ° nÃ o Má»i ngÆ°á»i giáº£i Ä‘Ã¡p giÃºp em vá»›i áº¡.",#T5	#QA,,,,
"Em chÃ o má»i ngÆ°á»i áº¡,
Em Ä‘ang muá»‘n xÃ¢y dá»±ng má»™t há»‡ thá»‘ng gá»£i Ã½ sáº£n pháº©m tiáº¿p theo nÃªn mua dá»±a trÃªn data cá»§a ngÆ°á»i dÃ¹ng. Data nÃ y bao gá»“m : tuá»•i, giá»›i tÃ­nh, nhá»¯ng sáº£n pháº©m Ä‘Ã£ mua vá»«a qua.
Em cÃ³ thá»­ Time Series nhÆ°ng láº¡i khÃ´ng phÃ¹ há»£p
Má»™t Ã½ tÆ°á»Ÿng khÃ¡c lÃ  láº­p 1 tá»• há»£p cÃ¡c tá»« sao cho cÃ³ nghÄ©a, rá»“i dÃ¹ng NLP Ä‘á»ƒ gá»£i Ã½ sáº£n pháº©m.
Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n áº¡. Em cÃ¡m Æ¡n.","Em chÃ o má»i ngÆ°á»i áº¡, Em Ä‘ang muá»‘n xÃ¢y dá»±ng má»™t há»‡ thá»‘ng gá»£i Ã½ sáº£n pháº©m tiáº¿p theo nÃªn mua dá»±a trÃªn data cá»§a ngÆ°á»i dÃ¹ng. Data nÃ y bao gá»“m : tuá»•i, giá»›i tÃ­nh, nhá»¯ng sáº£n pháº©m Ä‘Ã£ mua vá»«a qua. Em cÃ³ thá»­ Time Series nhÆ°ng láº¡i khÃ´ng phÃ¹ há»£p Má»™t Ã½ tÆ°á»Ÿng khÃ¡c lÃ  láº­p 1 tá»• há»£p cÃ¡c tá»« sao cho cÃ³ nghÄ©a, rá»“i dÃ¹ng NLP Ä‘á»ƒ gá»£i Ã½ sáº£n pháº©m. Má»i ngÆ°á»i cho em xin Ã½ kiáº¿n áº¡. Em cÃ¡m Æ¡n.",,,,,
ChÃ o cáº£ nhÃ . MÃ¬nh Ä‘ang lÃ m thá»­ má»™t model Ä‘á»ƒ correct láº¡i káº¿t quáº£ nháº­n diá»‡n OCR cho tiáº¿ng Viá»‡t. Äang tÃ­nh sá»­ dá»¥ng phoBERT vá»›i masked model language. CÆ¡ mÃ  váº¥n Ä‘á» mÃ¬nh gáº·p pháº£i bÃ¢y giá» lÃ  lÃ m sao Ä‘á»ƒ biáº¿t trong cÃ¢u tá»« nÃ o sai Ä‘á»ƒ mÃ  mask nÃ³ láº¡i. CÃ¡c cao nhÃ¢n á»Ÿ Ä‘Ã¢y cÃ³ ai chá»‰ cho mÃ¬nh vÃ i con Ä‘Æ°á»ng láº¥p lÃ³ chÃºt tia sÃ¡ng Ä‘Æ°á»£c ko áº¡?,ChÃ o cáº£ nhÃ . MÃ¬nh Ä‘ang lÃ m thá»­ má»™t model Ä‘á»ƒ correct láº¡i káº¿t quáº£ nháº­n diá»‡n OCR cho tiáº¿ng Viá»‡t. Äang tÃ­nh sá»­ dá»¥ng phoBERT vá»›i masked model language. CÆ¡ mÃ  váº¥n Ä‘á» mÃ¬nh gáº·p pháº£i bÃ¢y giá» lÃ  lÃ m sao Ä‘á»ƒ biáº¿t trong cÃ¢u tá»« nÃ o sai Ä‘á»ƒ mÃ  mask nÃ³ láº¡i. CÃ¡c cao nhÃ¢n á»Ÿ Ä‘Ã¢y cÃ³ ai chá»‰ cho mÃ¬nh vÃ i con Ä‘Æ°á»ng láº¥p lÃ³ chÃºt tia sÃ¡ng Ä‘Æ°á»£c ko áº¡?,,,,,
"â— KHÃ”NG THá»‚ â€œÃ”Mâ€ Dá»® LIá»†U Má»˜T MÃŒNH, Äáº¶C BIá»†T LÃ€ Dá»® LIá»†U Y SINH â—
Ná»n táº£ng quáº£n lÃ½, phÃ¢n tÃ­ch dá»¯ liá»‡u y sinh cá»§a ngÆ°á»i Viá»‡t Ä‘Æ°á»£c ká»³ vá»ng giáº£i quyáº¿t nhu cáº§u tham chiáº¿u dá»¯ liá»‡u suá»‘t nhiá»u tháº­p ká»· táº¡i Viá»‡t Nam.
#sharing","KHÃ”NG THá»‚ â€œÃ”Mâ€ Dá»® LIá»†U Má»˜T MÃŒNH, Äáº¶C BIá»†T LÃ€ Dá»® LIá»†U Y SINH Ná»n táº£ng quáº£n lÃ½, phÃ¢n tÃ­ch dá»¯ liá»‡u y sinh cá»§a ngÆ°á»i Viá»‡t Ä‘Æ°á»£c ká»³ vá»ng giáº£i quyáº¿t nhu cáº§u tham chiáº¿u dá»¯ liá»‡u suá»‘t nhiá»u tháº­p ká»· táº¡i Viá»‡t Nam.",#sharing,,,,
"NHá»œ há»— trá»£ giáº£i thuáº­t ANFIS (Python)
Xin chÃ o cáº£ nhÃ !
MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu code python cho giáº£i thuáº­t ANFIS theo hÆ°á»›ng dáº«n: https://github.com/twmeggs/anfis
=> MÃ´ táº£ nÃ y cháº¡y cho 2 biáº¿n Ä‘áº§u vÃ o vÃ  1 biáº¿n Ä‘áº§u ra
Tuy nhiÃªn, mÃ¬nh gáº·p khÃ³ khi chÆ°a hiá»ƒu pháº£i thay Ä‘á»•i tham sá»‘ Ä‘áº§u vÃ o nhÆ° tháº¿ nÃ o cho bá»™ dá»¯ liá»‡u cá»§a mÃ¬nh (5 biáº¿n Ä‘áº§u vÃ o var1, ..., var5 vÃ  1 biáº¿n Ä‘Ã­ch target) trong mÃ´ hÃ¬nh cá»§a giáº£i thuáº­t ANFIS. Bá»™ dá»¯ liá»‡u cá»§a mÃ¬nh ko cáº§n quan tÃ¢m Ä‘áº¿n Time Series.
MÃ¬nh gá»­i táº­p dá»¯ liá»‡u máº«u kÃ¨m theo, xin nhá» má»i ngÆ°á»i trá»£ giÃºp tÃ i liá»‡u hoáº·c hÆ°á»›ng dáº«n cÃ¡ch thay Ä‘á»•i tham sá»‘ cho phÃ¹ há»£p.
https://drive.google.com/file/d/1g7E_S8V5_N9GI9At1wZwQZEqEk59gQGq/view?usp=sharing
TrÃ¢n trá»ng cáº£m Æ¡n má»i ngÆ°á»i!","NHá»œ há»— trá»£ giáº£i thuáº­t ANFIS (Python) Xin chÃ o cáº£ nhÃ ! MÃ¬nh Ä‘ang tÃ¬m hiá»ƒu code python cho giáº£i thuáº­t ANFIS theo hÆ°á»›ng dáº«n: https://github.com/twmeggs/anfis => MÃ´ táº£ nÃ y cháº¡y cho 2 biáº¿n Ä‘áº§u vÃ o vÃ  1 biáº¿n Ä‘áº§u ra Tuy nhiÃªn, mÃ¬nh gáº·p khÃ³ khi chÆ°a hiá»ƒu pháº£i thay Ä‘á»•i tham sá»‘ Ä‘áº§u vÃ o nhÆ° tháº¿ nÃ o cho bá»™ dá»¯ liá»‡u cá»§a mÃ¬nh (5 biáº¿n Ä‘áº§u vÃ o var1, ..., var5 vÃ  1 biáº¿n Ä‘Ã­ch target) trong mÃ´ hÃ¬nh cá»§a giáº£i thuáº­t ANFIS. Bá»™ dá»¯ liá»‡u cá»§a mÃ¬nh ko cáº§n quan tÃ¢m Ä‘áº¿n Time Series. MÃ¬nh gá»­i táº­p dá»¯ liá»‡u máº«u kÃ¨m theo, xin nhá» má»i ngÆ°á»i trá»£ giÃºp tÃ i liá»‡u hoáº·c hÆ°á»›ng dáº«n cÃ¡ch thay Ä‘á»•i tham sá»‘ cho phÃ¹ há»£p. https://drive.google.com/file/d/1g7E_S8V5_N9GI9At1wZwQZEqEk59gQGq/view?usp=sharing TrÃ¢n trá»ng cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"#tensorflow
mÃ¬nh dÃ¹ng
python 3.85
pip 20.3.2( cáº­p nháº­t má»›i nháº¥t)
lá»‡nh cÃ i Ä‘áº·t: pip install tensorflow
khi cÃ i tensorfow bá»‹ lá»—i khÃ´ng tÃ¬m Ä‘Æ°á»£c phiÃªn báº£n. báº¡n mÃ¬nh dÃ¹ng python 3.7 thÃ¬ cÃ i bÃ¬nh thÆ°á»ng, tham kháº£o lá»—i trÃªn stackoverflow vÃ  github chÆ°a tháº¥y máº¥y Ã´ chuyá»ƒn vá» python 3.7 cÃ i bÃ¬nh thÆ°á»ng, cÃ²n 3.8 die háº¿t. Group cÃ³ ai cÃ i Ä‘Æ°á»£c trÃªn python3.8 khÃ´ng hay pháº£i chuyá»ƒn xuá»‘ng python 3.7 váº­y. ğŸ¤”","mÃ¬nh dÃ¹ng python 3.85 pip 20.3.2( cáº­p nháº­t má»›i nháº¥t) lá»‡nh cÃ i Ä‘áº·t: pip install tensorflow khi cÃ i tensorfow bá»‹ lá»—i khÃ´ng tÃ¬m Ä‘Æ°á»£c phiÃªn báº£n. báº¡n mÃ¬nh dÃ¹ng python 3.7 thÃ¬ cÃ i bÃ¬nh thÆ°á»ng, tham kháº£o lá»—i trÃªn stackoverflow vÃ  github chÆ°a tháº¥y máº¥y Ã´ chuyá»ƒn vá» python 3.7 cÃ i bÃ¬nh thÆ°á»ng, cÃ²n 3.8 die háº¿t. Group cÃ³ ai cÃ i Ä‘Æ°á»£c trÃªn python3.8 khÃ´ng hay pháº£i chuyá»ƒn xuá»‘ng python 3.7 váº­y.",#tensorflow,,,,
"Dear all, cho mÃ¬nh há»i mÃ¡y á»Ÿ nhÃ  dÃ¹ng gpu rtx 3080 cuda 11.1 khi cÃ i pytorch vÃ o bÃ¡o lá»—i nhÆ° hÃ¬nh sau. LÃ m tháº¿ nÃ o Ä‘á»ƒ fix lá»—i vÃ  cÃ i pytorch Ä‘Æ°á»£c áº¡. Nhá» má»i ngÆ°á»i chá»‰ giÃºp, xin chÃ¢n thÃ nh cáº£m Æ¡n.","Dear all, cho mÃ¬nh há»i mÃ¡y á»Ÿ nhÃ  dÃ¹ng gpu rtx 3080 cuda 11.1 khi cÃ i pytorch vÃ o bÃ¡o lá»—i nhÆ° hÃ¬nh sau. LÃ m tháº¿ nÃ o Ä‘á»ƒ fix lá»—i vÃ  cÃ i pytorch Ä‘Æ°á»£c áº¡. Nhá» má»i ngÆ°á»i chá»‰ giÃºp, xin chÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i, trÆ°á»›c Ä‘Ã¢y em cÃ³ up trong group mÃ¬nh vá» bÃ i toÃ¡n Æ°á»›c lÆ°á»£ng khoáº£ng cÃ¡ch giÃ£n cÃ¡ch xÃ£ há»™i trong video. Hiá»‡n em Ä‘ang thá»­ nghiá»‡m cÃ¡c phÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng vá»›i 2 phÆ°Æ¡ng phÃ¡p trong 2 trang nÃ y áº¡:
OpenCV Social Distancing Detector - PyImageSearch
Subikshaa/Social-Distance-Detection-using-OpenCV (github.com)
Hiá»‡n táº¡i em cÃ³ má»™t sá»‘ tháº¯c máº¯c nhÆ° nÃ y áº¡:
Giáº£ sá»­ vá»›i 2 phÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng khoáº£ng cÃ¡ch á»Ÿ trong 2 link trÃªn, vá»›i trÆ°á»ng há»£p xÃ©t khoáº£ng cÃ¡ch 2 ngÆ°á»i, phÆ°Æ¡ng phÃ¡p Ä‘áº§u cho khoáº£ng cÃ¡ch Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c lÃ  5m, phÆ°Æ¡ng phÃ¡p thá»© 2 cho khoáº£ng cÃ¡ch Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c lÃ  4m. Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ biáº¿t Ä‘Æ°á»£c khoáº£ng cÃ¡ch thá»±c táº¿ cá»§a 2 ngÆ°á»i trong video ( hay nÃ³i Ä‘Ãºng hÆ¡n lÃ  táº¡i 1 frame xÃ¡c Ä‘á»‹nh trong video) lÃ  bao nhiÃªu Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ Ä‘Æ°a ra káº¿t quáº£ lÃ  phÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng nÃ o tá»‘t hÆ¡n?
Vá»›i trÆ°á»ng há»£p sá»‘ lÆ°á»£ng ngÆ°á»i cáº§n tÃ­nh lÃ  khÃ¡ nhiá»u, khoáº£ng tá»« 30 Ä‘áº¿n 40 ngÆ°á»i trá»Ÿ lÃªn, thÃ¬ mÃ¬nh cÃ³ má»™t sá»‘ phÆ°Æ¡ng phÃ¡p hay kÄ© thuáº­t gÃ¬ trong khi code Ä‘á»ƒ giáº£m thá»i gian tÃ­nh toÃ¡n cá»§a nÃ³ Ä‘á»ƒ cho ra káº¿t quáº£ nhanh hÆ¡n khÃ´ng áº¡?
Hiá»‡n táº¡i em Ä‘ang tháº¯c máº¯c nhÆ° nÃ y áº¡, mong má»i ngÆ°á»i cÃ³ thá»ƒ gÃ³p Ã½, tÆ° váº¥n cho em thÃªm áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, trÆ°á»›c Ä‘Ã¢y em cÃ³ up trong group mÃ¬nh vá» bÃ i toÃ¡n Æ°á»›c lÆ°á»£ng khoáº£ng cÃ¡ch giÃ£n cÃ¡ch xÃ£ há»™i trong video. Hiá»‡n em Ä‘ang thá»­ nghiá»‡m cÃ¡c phÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng vá»›i 2 phÆ°Æ¡ng phÃ¡p trong 2 trang nÃ y áº¡: OpenCV Social Distancing Detector - PyImageSearch Subikshaa/Social-Distance-Detection-using-OpenCV (github.com) Hiá»‡n táº¡i em cÃ³ má»™t sá»‘ tháº¯c máº¯c nhÆ° nÃ y áº¡: Giáº£ sá»­ vá»›i 2 phÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng khoáº£ng cÃ¡ch á»Ÿ trong 2 link trÃªn, vá»›i trÆ°á»ng há»£p xÃ©t khoáº£ng cÃ¡ch 2 ngÆ°á»i, phÆ°Æ¡ng phÃ¡p Ä‘áº§u cho khoáº£ng cÃ¡ch Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c lÃ  5m, phÆ°Æ¡ng phÃ¡p thá»© 2 cho khoáº£ng cÃ¡ch Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c lÃ  4m. Váº­y lÃ m tháº¿ nÃ o Ä‘á»ƒ biáº¿t Ä‘Æ°á»£c khoáº£ng cÃ¡ch thá»±c táº¿ cá»§a 2 ngÆ°á»i trong video ( hay nÃ³i Ä‘Ãºng hÆ¡n lÃ  táº¡i 1 frame xÃ¡c Ä‘á»‹nh trong video) lÃ  bao nhiÃªu Ä‘á»ƒ mÃ¬nh cÃ³ thá»ƒ Ä‘Æ°a ra káº¿t quáº£ lÃ  phÆ°Æ¡ng phÃ¡p Æ°á»›c lÆ°á»£ng nÃ o tá»‘t hÆ¡n? Vá»›i trÆ°á»ng há»£p sá»‘ lÆ°á»£ng ngÆ°á»i cáº§n tÃ­nh lÃ  khÃ¡ nhiá»u, khoáº£ng tá»« 30 Ä‘áº¿n 40 ngÆ°á»i trá»Ÿ lÃªn, thÃ¬ mÃ¬nh cÃ³ má»™t sá»‘ phÆ°Æ¡ng phÃ¡p hay kÄ© thuáº­t gÃ¬ trong khi code Ä‘á»ƒ giáº£m thá»i gian tÃ­nh toÃ¡n cá»§a nÃ³ Ä‘á»ƒ cho ra káº¿t quáº£ nhanh hÆ¡n khÃ´ng áº¡? Hiá»‡n táº¡i em Ä‘ang tháº¯c máº¯c nhÆ° nÃ y áº¡, mong má»i ngÆ°á»i cÃ³ thá»ƒ gÃ³p Ã½, tÆ° váº¥n cho em thÃªm áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Xin chÃ o a/c,
hiá»‡n em Ä‘ang Ä‘á»c dá»¯ liá»‡u tá»« camera ip (khÃ´ng pháº£i máº¡ng LAN) qua http báº±ng cv2.VideoCapture, sau Ä‘Ã³ dÃ¹ng imshow() lÃªn xem thÃ¬ gáº·p hiá»‡n tÆ°á»£ng bá»‹ bá» frame (cá»© 10 giÃ¢y thÃ¬ má»›i nháº£y sang frame má»›i 1 láº§n, nghÄ©a lÃ  thá»i Ä‘iá»ƒm a thÃ¬ hiá»‡n lÃªn frame a, sau Ä‘Ã³ Ä‘á»©ng yÃªn, sau Ä‘Ã³ 10s thÃ¬ hiá»‡n frama a+10 luÃ´n vÃ  bá» qua Ä‘oáº¡n á»Ÿ giá»¯a). Em má»Ÿ camrera xem báº±ng trÃ¬nh duyá»‡t web thÃ¬ ráº¥t mÆ°á»£t.
Má»i ngÆ°á»i Ä‘Ã£ gáº·p case nÃ o nhÆ° nÃ y chÆ°a áº¡. Náº¿u cÃ³ thÃ¬ cho em xin chÃºt kinh nghiá»‡m Ä‘á»ƒ xá»­ lÃ½ cho nÃ³ tuáº§n tá»± vá»›i áº¡. Em cáº£m Æ¡n.","Xin chÃ o a/c, hiá»‡n em Ä‘ang Ä‘á»c dá»¯ liá»‡u tá»« camera ip (khÃ´ng pháº£i máº¡ng LAN) qua http báº±ng cv2.VideoCapture, sau Ä‘Ã³ dÃ¹ng imshow() lÃªn xem thÃ¬ gáº·p hiá»‡n tÆ°á»£ng bá»‹ bá» frame (cá»© 10 giÃ¢y thÃ¬ má»›i nháº£y sang frame má»›i 1 láº§n, nghÄ©a lÃ  thá»i Ä‘iá»ƒm a thÃ¬ hiá»‡n lÃªn frame a, sau Ä‘Ã³ Ä‘á»©ng yÃªn, sau Ä‘Ã³ 10s thÃ¬ hiá»‡n frama a+10 luÃ´n vÃ  bá» qua Ä‘oáº¡n á»Ÿ giá»¯a). Em má»Ÿ camrera xem báº±ng trÃ¬nh duyá»‡t web thÃ¬ ráº¥t mÆ°á»£t. Má»i ngÆ°á»i Ä‘Ã£ gáº·p case nÃ o nhÆ° nÃ y chÆ°a áº¡. Náº¿u cÃ³ thÃ¬ cho em xin chÃºt kinh nghiá»‡m Ä‘á»ƒ xá»­ lÃ½ cho nÃ³ tuáº§n tá»± vá»›i áº¡. Em cáº£m Æ¡n.",,,,,
"Danh sÃ¡ch cÃ¡c best paper trong nÄƒm 2020 vá»›i Ä‘áº§y Ä‘á»§ video demo, tÃ³m táº¯t, paper vÃ  code cho cÃ¡c báº¡n tÃ¬m hiá»ƒu
#deeplearning","Danh sÃ¡ch cÃ¡c best paper trong nÄƒm 2020 vá»›i Ä‘áº§y Ä‘á»§ video demo, tÃ³m táº¯t, paper vÃ  code cho cÃ¡c báº¡n tÃ¬m hiá»ƒu",#deeplearning,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang há»c vá» pháº§n thÆ° viá»‡n Hugging Face Ä‘á»ƒ táº­p tá»e lÃ m BERT nÃªn cÃ³ viáº¿t má»™t bÃ i chia sáº» Ä‘á»ƒ cÃ¡c báº¡n má»›i há»c cÃ¹ng tÃ¬m hiá»ƒu cho bá»›t bá»¡ ngá»¡.
Mong ad duyá»‡t bÃ i vÃ  mong cÃ¡c bÃ¡c chá»‰ giÃ¡o ah!","KÃ­nh chÃ o cÃ¡c bÃ¡c, em Ä‘ang há»c vá» pháº§n thÆ° viá»‡n Hugging Face Ä‘á»ƒ táº­p tá»e lÃ m BERT nÃªn cÃ³ viáº¿t má»™t bÃ i chia sáº» Ä‘á»ƒ cÃ¡c báº¡n má»›i há»c cÃ¹ng tÃ¬m hiá»ƒu cho bá»›t bá»¡ ngá»¡. Mong ad duyá»‡t bÃ i vÃ  mong cÃ¡c bÃ¡c chá»‰ giÃ¡o ah!",,,,,
"Xin chÃ o má»i ngÆ°á»i !
MÃ¬nh train model cho object detection, dataset khoáº£ng 10k áº£nh. Initial Lr = 0.01, decay 50%.
DÆ°á»›i Ä‘Ã¢y lÃ  Ä‘á»“ thá»‹ pháº§n Training Loss. MÃ¬nh muá»‘n há»i vá» Ä‘á»“ thá»‹ Regularization Loss. MÃ¬nh Ä‘Ã£ nghÄ© ráº±ng Ä‘á»“ thá»‹ sáº½ Ä‘áº¡t tráº¡ng thÃ¡i cÃ¢n báº±ng, sau Ä‘Ã³ mÃ¬nh háº¡ Lr, Ä‘á»“ thá»‹ sáº½ giáº£m hoáº·c tÄƒng rá»“i láº¡i cÃ¢n báº±ng, sau Ä‘Ã³ mÃ¬nh tiáº¿p tá»¥c háº¡ Lr.
MÃ¬nh chÆ°a hiá»ƒu táº¡i sao Ä‘á»“ thá»‹ regularization loss láº¡i nhÆ° tháº¿ nÃ y vÃ  nÃ³ cÃ³ Ã½ nghÄ©a nhÆ° tháº¿ nÃ o ?
Má»i ngÆ°á»i lá»±a chá»n Lr vÃ  decay factor nhÆ° tháº¿ nÃ o vÃ  dá»±a trÃªn yáº¿u tá»‘ gÃ¬ ?
MÃ¬nh xin cáº£m Æ¡n trÆ°á»›c !","Xin chÃ o má»i ngÆ°á»i ! MÃ¬nh train model cho object detection, dataset khoáº£ng 10k áº£nh. Initial Lr = 0.01, decay 50%. DÆ°á»›i Ä‘Ã¢y lÃ  Ä‘á»“ thá»‹ pháº§n Training Loss. MÃ¬nh muá»‘n há»i vá» Ä‘á»“ thá»‹ Regularization Loss. MÃ¬nh Ä‘Ã£ nghÄ© ráº±ng Ä‘á»“ thá»‹ sáº½ Ä‘áº¡t tráº¡ng thÃ¡i cÃ¢n báº±ng, sau Ä‘Ã³ mÃ¬nh háº¡ Lr, Ä‘á»“ thá»‹ sáº½ giáº£m hoáº·c tÄƒng rá»“i láº¡i cÃ¢n báº±ng, sau Ä‘Ã³ mÃ¬nh tiáº¿p tá»¥c háº¡ Lr. MÃ¬nh chÆ°a hiá»ƒu táº¡i sao Ä‘á»“ thá»‹ regularization loss láº¡i nhÆ° tháº¿ nÃ y vÃ  nÃ³ cÃ³ Ã½ nghÄ©a nhÆ° tháº¿ nÃ o ? Má»i ngÆ°á»i lá»±a chá»n Lr vÃ  decay factor nhÆ° tháº¿ nÃ o vÃ  dá»±a trÃªn yáº¿u tá»‘ gÃ¬ ? MÃ¬nh xin cáº£m Æ¡n trÆ°á»›c !",,,,,
"ÄÆ°a láº¡i á»Ÿ Ä‘Ã¢y Ã½ kiáº¿n cá»§a Ta Quang Dong - má»™t trong nhá»¯ng chuyÃªn gia dá»‹ch thuáº­t vÃ  ngÃ´n ngá»¯ cÃ³ tÃªn tuá»•i Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a báº¡n ÄÄƒng KhÃ´i vá» dá»‹ch Logistics Regression nhÆ° tháº¿ nÃ o?
PS: Thks TQÄ Ä‘Ã£ gá»­i cho link!
https://www.facebook.com/246328782728796/posts/400259637335709/?d=n",ÄÆ°a láº¡i á»Ÿ Ä‘Ã¢y Ã½ kiáº¿n cá»§a Ta Quang Dong - má»™t trong nhá»¯ng chuyÃªn gia dá»‹ch thuáº­t vÃ  ngÃ´n ngá»¯ cÃ³ tÃªn tuá»•i Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a báº¡n ÄÄƒng KhÃ´i vá» dá»‹ch Logistics Regression nhÆ° tháº¿ nÃ o? PS: Thks TQÄ Ä‘Ã£ gá»­i cho link! https://www.facebook.com/246328782728796/posts/400259637335709/?d=n,,,,,
"CÃ³ ai dá»‹ch Ä‘Æ°á»£c tá»« Logistic regression qua Tiáº¿ng Viá»‡t mÃ  make sense chÃºt chÃºt Ä‘Æ°á»£c khÃ´ng. Äá»«ng cÃ³ dá»‹ch lÃ  há»“i quy háº­u cáº§n nhÃ© , Hjjjjjj.ğŸ™ƒ","CÃ³ ai dá»‹ch Ä‘Æ°á»£c tá»« Logistic regression qua Tiáº¿ng Viá»‡t mÃ  make sense chÃºt chÃºt Ä‘Æ°á»£c khÃ´ng. Äá»«ng cÃ³ dá»‹ch lÃ  há»“i quy háº­u cáº§n nhÃ© , Hjjjjjj.",,,,,
"How to build resnet model from scratch on tensorflow, pytorch, mxnet.","How to build resnet model from scratch on tensorflow, pytorch, mxnet.",,,,,
"Dáº¡ em chÃ o cÃ¡c anh/chá»‹ vÃ  cÃ¡c báº¡n áº¡. Em hiá»‡n Ä‘ang lÃ  web developer nhÆ°ng em cÃ³ Ä‘am mÃª lá»›n vá»›i AI, Ä‘áº·c biá»‡t lÃ  Machine Learning. Hiá»‡n nay em Ä‘ang cá»‘ tÃ¬m tÃ²i vÃ  há»c há»i nhá»¯ng tÃ i liá»‡u trÃªn máº¡ng, nhÆ°ng khi lÃªn forum vÃ  xem cÃ¡ch cÃ¡c báº¡n há»i láº«n cÃ¡ch giáº£i Ä‘Ã¡p cá»§a má»i ngÆ°á»i, em má»›i tháº­t sá»± cáº£m tháº¥y cÃ¡ch há»c cá»§a em hiá»‡n Ä‘ang khÃ´ng hiá»ƒu quáº£ vÃ¬ kiáº¿n thá»©c cá»§a em váº«n cÃ²n há»•ng nhiá»u quÃ¡. NÃªn em lÃªn Ä‘Ã¢y mong cÃ¡c anh/chá»‹ vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ cho em xin má»™t vÃ i lá»i khuyÃªn vá» viá»‡c báº¯t Ä‘áº§u há»c cÆ¡ báº£n ML nhÆ° tháº¿ nÃ o Ä‘Æ°á»£c khÃ´ng áº¡ (em hiá»‡n code khÃ¡ á»•n Python rá»“i áº¡)?
Em xin cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.","Dáº¡ em chÃ o cÃ¡c anh/chá»‹ vÃ  cÃ¡c báº¡n áº¡. Em hiá»‡n Ä‘ang lÃ  web developer nhÆ°ng em cÃ³ Ä‘am mÃª lá»›n vá»›i AI, Ä‘áº·c biá»‡t lÃ  Machine Learning. Hiá»‡n nay em Ä‘ang cá»‘ tÃ¬m tÃ²i vÃ  há»c há»i nhá»¯ng tÃ i liá»‡u trÃªn máº¡ng, nhÆ°ng khi lÃªn forum vÃ  xem cÃ¡ch cÃ¡c báº¡n há»i láº«n cÃ¡ch giáº£i Ä‘Ã¡p cá»§a má»i ngÆ°á»i, em má»›i tháº­t sá»± cáº£m tháº¥y cÃ¡ch há»c cá»§a em hiá»‡n Ä‘ang khÃ´ng hiá»ƒu quáº£ vÃ¬ kiáº¿n thá»©c cá»§a em váº«n cÃ²n há»•ng nhiá»u quÃ¡. NÃªn em lÃªn Ä‘Ã¢y mong cÃ¡c anh/chá»‹ vÃ  cÃ¡c báº¡n cÃ³ thá»ƒ cho em xin má»™t vÃ i lá»i khuyÃªn vá» viá»‡c báº¯t Ä‘áº§u há»c cÆ¡ báº£n ML nhÆ° tháº¿ nÃ o Ä‘Æ°á»£c khÃ´ng áº¡ (em hiá»‡n code khÃ¡ á»•n Python rá»“i áº¡)? Em xin cáº£m Æ¡n má»i ngÆ°á»i ráº¥t nhiá»u.",,,,,
"ChÃ o anh chá»‹ em cÃ³ Ä‘ang lÃ m project vá» sentiment analysis cho comment cá»§a khÃ¡ch hÃ ng trÃªn web. Em cÃ³ gáº·p chÃºt váº¥n Ä‘á» vá» cleaning data trong tiáº¿ng viá»‡t khi ngÆ°á»i dÃ¹ng viáº¿t táº¯t.
Mong anh chá»‹ trong nhÃ³m giÃºp em vá»›i áº¡. Em cáº£m Æ¡n !",ChÃ o anh chá»‹ em cÃ³ Ä‘ang lÃ m project vá» sentiment analysis cho comment cá»§a khÃ¡ch hÃ ng trÃªn web. Em cÃ³ gáº·p chÃºt váº¥n Ä‘á» vá» cleaning data trong tiáº¿ng viá»‡t khi ngÆ°á»i dÃ¹ng viáº¿t táº¯t. Mong anh chá»‹ trong nhÃ³m giÃºp em vá»›i áº¡. Em cáº£m Æ¡n !,,,,,
"RAdam (Rectified Adam) má»™t trÃ¬nh tá»‘i Æ°u Ä‘Æ°á»£c Liyuan Liu Ä‘á» xuáº¥t vÃ o nÄƒm 2019.
Hiá»‡n VN mÃ¬nh tháº¥y Ã­t ngÆ°á»i viáº¿t vá» trÃ¬nh tá»‘i Æ°u nÃ y nÃªn hÃ´m nay mÃ¬nh xin gá»­i tÆ¡i bÃ i viáº¿t vá» RAdam
Mong má»i ngÆ°á»i á»§ng há»™ áº¡ ğŸ˜ƒ",RAdam (Rectified Adam) má»™t trÃ¬nh tá»‘i Æ°u Ä‘Æ°á»£c Liyuan Liu Ä‘á» xuáº¥t vÃ o nÄƒm 2019. Hiá»‡n VN mÃ¬nh tháº¥y Ã­t ngÆ°á»i viáº¿t vá» trÃ¬nh tá»‘i Æ°u nÃ y nÃªn hÃ´m nay mÃ¬nh xin gá»­i tÆ¡i bÃ i viáº¿t vá» RAdam Mong má»i ngÆ°á»i á»§ng há»™ áº¡,,,,,
https://fb.watch/2lBlu9wUKq/,https://fb.watch/2lBlu9wUKq/,,,,,
"ChÃ o cÃ¡c anh/chá»‹ báº¡n mÃ¬nh cÃ³ cÃ¢u há»i nhá» má»i ngÆ°á»i tÆ° váº¥n giÃ¹m. HÃ¬nh dÆ°á»›i lÃ  áº£nh sau khi mÃ¬nh train model cá»§a mÃ¬nh vá»›i 300 epochs nhÆ°ng táº¡i epoch 80 loss nÃ³ tÄƒng vá»t lÃªn, mÃ¬nh ráº¥t muá»‘n biáº¿t má»™t vÃ i lÃ­ do dáº«n ra nguyÃªn nhÃ¢n nÃ y Ä‘á»ƒ kháº¯c phá»¥c áº¡!
Loss function: Adam, Lr=0.001, Bs=24,  dá»¯ liá»‡u khoáº£ng 10000 áº£nh, cÃ³ normalize [0-1], cÃ³ thá»±c hiá»‡n data augmentation. 
MÃ¬nh ráº¥t muá»‘n biáº¿t má»™t sá»‘ nguyÃªn nhÃ¢n táº¡i sao loss nháº£y vá»t lÃªn 1 láº§n nhÆ° váº­y. 
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem qua!","ChÃ o cÃ¡c anh/chá»‹ báº¡n mÃ¬nh cÃ³ cÃ¢u há»i nhá» má»i ngÆ°á»i tÆ° váº¥n giÃ¹m. HÃ¬nh dÆ°á»›i lÃ  áº£nh sau khi mÃ¬nh train model cá»§a mÃ¬nh vá»›i 300 epochs nhÆ°ng táº¡i epoch 80 loss nÃ³ tÄƒng vá»t lÃªn, mÃ¬nh ráº¥t muá»‘n biáº¿t má»™t vÃ i lÃ­ do dáº«n ra nguyÃªn nhÃ¢n nÃ y Ä‘á»ƒ kháº¯c phá»¥c áº¡! Loss function: Adam, Lr=0.001, Bs=24, dá»¯ liá»‡u khoáº£ng 10000 áº£nh, cÃ³ normalize [0-1], cÃ³ thá»±c hiá»‡n data augmentation. MÃ¬nh ráº¥t muá»‘n biáº¿t má»™t sá»‘ nguyÃªn nhÃ¢n táº¡i sao loss nháº£y vá»t lÃªn 1 láº§n nhÆ° váº­y. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ xem qua!",,,,,
"Nay tá»¥i mÃ¬nh cÃ³ livestream vá» cuá»™c thi ML Showcase 2020, giáº£i thÆ°á»Ÿng, kinh nghiá»‡m thi, cÃ¡ch á»©ng dá»¥ng AI vÃ o sáº£n pháº©m. Má»i ngÆ°á»i tham kháº£o nhÃ©. Hi vá»ng sáº½ cÃ³ nhiá»u nhÃ³m trong cá»™ng Ä‘á»“ng tham gia :D

https://www.facebook.com/vietaipublic/videos/141684164382216","Nay tá»¥i mÃ¬nh cÃ³ livestream vá» cuá»™c thi ML Showcase 2020, giáº£i thÆ°á»Ÿng, kinh nghiá»‡m thi, cÃ¡ch á»©ng dá»¥ng AI vÃ o sáº£n pháº©m. Má»i ngÆ°á»i tham kháº£o nhÃ©. Hi vá»ng sáº½ cÃ³ nhiá»u nhÃ³m trong cá»™ng Ä‘á»“ng tham gia :D https://www.facebook.com/vietaipublic/videos/141684164382216",,,,,
"Hi all,
MÃ¬nh muá»‘n chia sáº» 1 tool mÃ¬nh má»›i Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘á»ƒ há»c vÃ  thá»±c hÃ nh build ML models, Ä‘áº·c biá»‡t lÃ  Ä‘Ã¢y lÃ  1 visual tool nÃªn sáº½ Ä‘Æ¡n giáº£n hÆ¡n cho ngÆ°á»i má»›i báº¯t Ä‘áº§u.
Náº¿u ai Ä‘Ã£ quen vá»›i nhá»¯ng graphical programming tool nhÆ° Node Red (cho Javascript) vÃ  Scratch (cho Arduino/Microcontrollers) thÃ¬ cháº¯c sáº½ ko cÃ³ váº¥n Ä‘á» gÃ¬. TrÃªn trang web cÃ³ hÆ°á»›ng dáº«n cÆ¡ báº£n nha ğŸ˜
Have fun learning!","Hi all, MÃ¬nh muá»‘n chia sáº» 1 tool mÃ¬nh má»›i Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘á»ƒ há»c vÃ  thá»±c hÃ nh build ML models, Ä‘áº·c biá»‡t lÃ  Ä‘Ã¢y lÃ  1 visual tool nÃªn sáº½ Ä‘Æ¡n giáº£n hÆ¡n cho ngÆ°á»i má»›i báº¯t Ä‘áº§u. Náº¿u ai Ä‘Ã£ quen vá»›i nhá»¯ng graphical programming tool nhÆ° Node Red (cho Javascript) vÃ  Scratch (cho Arduino/Microcontrollers) thÃ¬ cháº¯c sáº½ ko cÃ³ váº¥n Ä‘á» gÃ¬. TrÃªn trang web cÃ³ hÆ°á»›ng dáº«n cÆ¡ báº£n nha Have fun learning!",,,,,
Xin chÃ o má»i ngÆ°á»i áº¡. Em má»›i táº­p lÃ m quen vá» machine learning. Em Ä‘Ã£ train xong model mÃ  khÃ´ng biáº¿t nÃ³ cÃ³ bá»‹ overfit hay khÃ´ng... Mong má»i ngÆ°á»i cÃ³ thá»ƒ nháº­n xÃ©t model cá»§a em áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡ .,Xin chÃ o má»i ngÆ°á»i áº¡. Em má»›i táº­p lÃ m quen vá» machine learning. Em Ä‘Ã£ train xong model mÃ  khÃ´ng biáº¿t nÃ³ cÃ³ bá»‹ overfit hay khÃ´ng... Mong má»i ngÆ°á»i cÃ³ thá»ƒ nháº­n xÃ©t model cá»§a em áº¡. CÃ¡m Æ¡n má»i ngÆ°á»i Ä‘Ã£ giÃºp Ä‘á»¡ .,,,,,
"ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t tháº¯c máº¯c nhÆ° tháº¿ nÃ y nhá» má»i ngÆ°á»i giÃºp áº¡.
Em cÃ³ má»™t táº¥m hÃ¬nh con chÃ³ nhÆ° bÃªn dÆ°á»›i, khi Ä‘Æ°a nÃ³ qua má»™t embedding model thÃ¬ output cá»§a nÃ³ lÃ  má»™t embedding vector. Em tháº¯c máº¯c má»™t Ä‘iá»u lÃ  cÃ³ thá»ƒ dÃ¹ng embedding vector Ä‘Ã³ Ä‘á»ƒ phá»¥c há»“i láº¡i áº£nh gá»‘c báº±ng cÃ¡ch tÃ­nh toÃ¡n ngÆ°á»£c láº¡i khÃ´ng?
Em xin cáº£m Æ¡n áº¡","ChÃ o má»i ngÆ°á»i, em cÃ³ má»™t tháº¯c máº¯c nhÆ° tháº¿ nÃ y nhá» má»i ngÆ°á»i giÃºp áº¡. Em cÃ³ má»™t táº¥m hÃ¬nh con chÃ³ nhÆ° bÃªn dÆ°á»›i, khi Ä‘Æ°a nÃ³ qua má»™t embedding model thÃ¬ output cá»§a nÃ³ lÃ  má»™t embedding vector. Em tháº¯c máº¯c má»™t Ä‘iá»u lÃ  cÃ³ thá»ƒ dÃ¹ng embedding vector Ä‘Ã³ Ä‘á»ƒ phá»¥c há»“i láº¡i áº£nh gá»‘c báº±ng cÃ¡ch tÃ­nh toÃ¡n ngÆ°á»£c láº¡i khÃ´ng? Em xin cáº£m Æ¡n áº¡",,,,,
it is so true,it is so true,,,,,
"Em chÃ o má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang lÃ m 1 cÃ¡i App theo dÃµi bá»‡nh nhÃ¢n tiá»ƒu Ä‘Æ°á»ng, nháº­p sá»‘ liá»‡u Ä‘Æ°á»ng huyáº¿t, thá»©c Äƒn, hoáº¡t Ä‘á»™ng má»—i ngÃ y, dá»¯ liá»‡u Ä‘á»§ lá»›n trÃªn 7 ngÃ y, em muá»‘n tÃ­ch há»£p dá»± Ä‘oÃ¡n chá»‰ sá»‘ Ä‘Æ°á»ng huyáº¿t cá»§a ngÃ y tiáº¿p theo. Má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p gÃ¬ giÃºp em. Cáº£m Æ¡n má»i ngÆ°á»i! ğŸ¥°","Em chÃ o má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang lÃ m 1 cÃ¡i App theo dÃµi bá»‡nh nhÃ¢n tiá»ƒu Ä‘Æ°á»ng, nháº­p sá»‘ liá»‡u Ä‘Æ°á»ng huyáº¿t, thá»©c Äƒn, hoáº¡t Ä‘á»™ng má»—i ngÃ y, dá»¯ liá»‡u Ä‘á»§ lá»›n trÃªn 7 ngÃ y, em muá»‘n tÃ­ch há»£p dá»± Ä‘oÃ¡n chá»‰ sá»‘ Ä‘Æ°á»ng huyáº¿t cá»§a ngÃ y tiáº¿p theo. Má»i ngÆ°á»i cÃ³ giáº£i phÃ¡p gÃ¬ giÃºp em. Cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
,nan,,,,,
"xin chÃ o
Má»i ngÆ°á»i biáº¿t lá»—i nÃ y sá»­a sao ko áº¡, t search Google cÅ©ng ko fix dc , (áº£nh dÆ°á»›i ghi thÃ´ng tin keras vÃ  tensforflow t Ä‘ang dÃ¹ng)","xin chÃ o Má»i ngÆ°á»i biáº¿t lá»—i nÃ y sá»­a sao ko áº¡, t search Google cÅ©ng ko fix dc , (áº£nh dÆ°á»›i ghi thÃ´ng tin keras vÃ  tensforflow t Ä‘ang dÃ¹ng)",,,,,
"[Deep Learning Project]
Má»™t sá»‘ project cá»§a cÃ¡c báº¡n há»c sinh khÃ³a Deep Learning.
1. Giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh báº±ng áº£nh: Input lÃ  áº£nh chá»©a há»‡ phÆ°Æ¡ng trÃ¬nh, output sáº½ lÃ  nghiá»‡m cá»§a há»‡ phÆ°Æ¡ng trÃ¬nh.
2. Tráº£ lá»i thÃ´ng tin trong áº£nh: Input lÃ  áº£nh vÃ  cÃ¢u há»i liÃªn quan tá»›i ná»™i dung bá»©c áº£nh, output lÃ  thÃ´ng tin tráº£ lá»i tá»« bá»©c áº£nh. VÃ­ dá»¥: input áº£nh 1 Ä‘á»™i bÃ³ng, há»i cÃ³ bao nhiÃªu cáº§u thá»§, thÃ¬ sáº½ tráº£ lá»i Ä‘Æ°á»£c sá»‘ lÆ°á»£ng cáº§u thá»§ trong áº£nh.
3. TÃ³m táº¯t vÄƒn báº£n: Dá»¯ liá»‡u láº¥y tá»« ná»™i dung bÃ¬nh luáº­n, nháº­n xÃ©t cá»§a ngÆ°á»i dÃ¹ng trÃªn amazon.","[Deep Learning Project] Má»™t sá»‘ project cá»§a cÃ¡c báº¡n há»c sinh khÃ³a Deep Learning. 1. Giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh báº±ng áº£nh: Input lÃ  áº£nh chá»©a há»‡ phÆ°Æ¡ng trÃ¬nh, output sáº½ lÃ  nghiá»‡m cá»§a há»‡ phÆ°Æ¡ng trÃ¬nh. 2. Tráº£ lá»i thÃ´ng tin trong áº£nh: Input lÃ  áº£nh vÃ  cÃ¢u há»i liÃªn quan tá»›i ná»™i dung bá»©c áº£nh, output lÃ  thÃ´ng tin tráº£ lá»i tá»« bá»©c áº£nh. VÃ­ dá»¥: input áº£nh 1 Ä‘á»™i bÃ³ng, há»i cÃ³ bao nhiÃªu cáº§u thá»§, thÃ¬ sáº½ tráº£ lá»i Ä‘Æ°á»£c sá»‘ lÆ°á»£ng cáº§u thá»§ trong áº£nh. 3. TÃ³m táº¯t vÄƒn báº£n: Dá»¯ liá»‡u láº¥y tá»« ná»™i dung bÃ¬nh luáº­n, nháº­n xÃ©t cá»§a ngÆ°á»i dÃ¹ng trÃªn amazon.",,,,,
"[Trá»±c tiáº¿p] Há»¢P TÃC QUá»C Táº¾ TRONG PHÃT TRIá»‚N Y Há»ŒC CHÃNH XÃC - RA Máº®T Há»† THá»NG PHÃ‚N TÃCH Dá»® LIá»†U Y SINH Lá»šN NHáº¤T VIá»†T NAM vÃ  Tá»ŒA ÄÃ€M: Dá»® LIá»†U Lá»šN TRONG Y Há»ŒC - CÆ  CHáº¾ QUáº¢N LÃ, Káº¾T Ná»I VÃ€ CHIA Sáºº
#bigdata #precisionmedicine","[Trá»±c tiáº¿p] Há»¢P TÃC QUá»C Táº¾ TRONG PHÃT TRIá»‚N Y Há»ŒC CHÃNH XÃC - RA Máº®T Há»† THá»NG PHÃ‚N TÃCH Dá»® LIá»†U Y SINH Lá»šN NHáº¤T VIá»†T NAM vÃ  Tá»ŒA ÄÃ€M: Dá»® LIá»†U Lá»šN TRONG Y Há»ŒC - CÆ  CHáº¾ QUáº¢N LÃ, Káº¾T Ná»I VÃ€ CHIA Sáºº",#bigdata	#precisionmedicine,,,,
"#YoloV4 
ChÃ o má»i ngÆ°á»i,
MÃ¬nh Ä‘ang train YoloV4 cho dataset 200 áº£nh tá»± label, dÃ¹ng darknet framework á»Ÿ Ä‘Ã¢y: https://github.com/AlexeyAB/darknet
Váº¥n Ä‘á» mÃ¬nh gáº·p pháº£i lÃ : 
Sau 350 epoches, loss cá»§a mÃ¬nh á»Ÿ khoáº£ng 1.6 (áº£nh 1), code bÃ¡o lÃ  ""performance bottleneck on CPU"" (do chÆ°a Ä‘Æ°á»£c cty cáº¥p GPU nÃªn mÃ¬nh pháº£i train táº¡m trÃªn CPU xem sao).
Sang epoch 351, loss tÄƒng lÃªn 2.4 (áº£nh 2). VÃ  á»Ÿ epoch nÃ y learning_rate tÄƒng tá»« 1*10^-6 lÃªn 2*10^-6.
Sang epoch 352, loss Ä‘á»™t nhiÃªn bá»‹ -nan (áº£nh 3).
Nhá»¯ng thÃ´ng sá»‘ chÃ­nh trong file config mÃ¬nh set nhÆ° sau:
batch=8
width=608
height=608
channels=3
momentum=0.949
decay=0.0005
learning_rate=0.0001
burn_in=1000
max_batches = 6000
policy=steps
steps=4800,5400

MÃ¬nh cÃ³ Ä‘á»c hÆ°á»›ng dáº«n trong link github trÃªn, tÃ¡c giáº£ nÃ³i lÃ  náº¿u bá»‹ NaN thÃ¬ giáº£m learning rate. NhÆ°ng mÃ¬nh tháº¥y learning rate = 2*10^-6 lÃ  Ä‘Ã£ ráº¥t nhá» rá»“i.

KhÃ´ng biáº¿t cÃ³ ai tá»«ng gáº·p pháº£i trÆ°á»ng há»£p nÃ y ko, cÃ³ thá»ƒ gá»£i Ã½ hÆ°á»›ng giáº£i quyáº¿t cho mÃ¬nh dc ko? MÃ¬nh cÃ¡m Æ¡n nhiá»u :D ","ChÃ o má»i ngÆ°á»i, MÃ¬nh Ä‘ang train YoloV4 cho dataset 200 áº£nh tá»± label, dÃ¹ng darknet framework á»Ÿ Ä‘Ã¢y: https://github.com/AlexeyAB/darknet Váº¥n Ä‘á» mÃ¬nh gáº·p pháº£i lÃ : Sau 350 epoches, loss cá»§a mÃ¬nh á»Ÿ khoáº£ng 1.6 (áº£nh 1), code bÃ¡o lÃ  ""performance bottleneck on CPU"" (do chÆ°a Ä‘Æ°á»£c cty cáº¥p GPU nÃªn mÃ¬nh pháº£i train táº¡m trÃªn CPU xem sao). Sang epoch 351, loss tÄƒng lÃªn 2.4 (áº£nh 2). VÃ  á»Ÿ epoch nÃ y learning_rate tÄƒng tá»« 1*10^-6 lÃªn 2*10^-6. Sang epoch 352, loss Ä‘á»™t nhiÃªn bá»‹ -nan (áº£nh 3). Nhá»¯ng thÃ´ng sá»‘ chÃ­nh trong file config mÃ¬nh set nhÆ° sau: batch=8 width=608 height=608 channels=3 momentum=0.949 decay=0.0005 learning_rate=0.0001 burn_in=1000 max_batches = 6000 policy=steps steps=4800,5400 MÃ¬nh cÃ³ Ä‘á»c hÆ°á»›ng dáº«n trong link github trÃªn, tÃ¡c giáº£ nÃ³i lÃ  náº¿u bá»‹ NaN thÃ¬ giáº£m learning rate. NhÆ°ng mÃ¬nh tháº¥y learning rate = 2*10^-6 lÃ  Ä‘Ã£ ráº¥t nhá» rá»“i. KhÃ´ng biáº¿t cÃ³ ai tá»«ng gáº·p pháº£i trÆ°á»ng há»£p nÃ y ko, cÃ³ thá»ƒ gá»£i Ã½ hÆ°á»›ng giáº£i quyáº¿t cho mÃ¬nh dc ko? MÃ¬nh cÃ¡m Æ¡n nhiá»u :D",#YoloV4,,,,
"Hi má»i ngÆ°á»i,
MÃ¬nh Ä‘ang cháº¡y thá»­ 3 phÆ°Æ¡ng phÃ¡p cho bÃ i toÃ¡n Instance Segmentation gá»“m: DetectoRS (A); Cascade Mask R-CNN (B); Mask R-CNN (C) trÃªn ResNet-50.
Theo paper Ä‘Ã£ test trÃªn COCO dataset thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cá»§a A>B>C.
Tuy nhiÃªn khi mÃ¬nh thá»­ trÃªn 3-4 áº£nh ngáº«u nhiÃªn thÃ¬ Ä‘a pháº§n A kÃ©m hÆ¡n so vá»›i B, C. Má»™t thÃ­ dá»¥ dÆ°á»›i Ä‘Ã¢y mÃ´ táº£ Ä‘á»™ chÃ­nh xÃ¡c cá»§a A<B<C, dá»… dÃ ng quan sÃ¡t Ä‘Æ°á»£c báº±ng máº¯t.
Má»i ngÆ°á»i lÃ½ giáº£i giÃºp táº¡i sao láº¡i nhÆ° váº­y nhá»‰? ğŸ˜’","Hi má»i ngÆ°á»i, MÃ¬nh Ä‘ang cháº¡y thá»­ 3 phÆ°Æ¡ng phÃ¡p cho bÃ i toÃ¡n Instance Segmentation gá»“m: DetectoRS (A); Cascade Mask R-CNN (B); Mask R-CNN (C) trÃªn ResNet-50. Theo paper Ä‘Ã£ test trÃªn COCO dataset thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cá»§a A>B>C. Tuy nhiÃªn khi mÃ¬nh thá»­ trÃªn 3-4 áº£nh ngáº«u nhiÃªn thÃ¬ Ä‘a pháº§n A kÃ©m hÆ¡n so vá»›i B, C. Má»™t thÃ­ dá»¥ dÆ°á»›i Ä‘Ã¢y mÃ´ táº£ Ä‘á»™ chÃ­nh xÃ¡c cá»§a A<B<C, dá»… dÃ ng quan sÃ¡t Ä‘Æ°á»£c báº±ng máº¯t. Má»i ngÆ°á»i lÃ½ giáº£i giÃºp táº¡i sao láº¡i nhÆ° váº­y nhá»‰?",,,,,
"Em xin chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em muá»‘n cháº¡y classifier báº±ng machine learning vá»›i C++, em cÃ³ xem qua vÃ  tháº¥y OpenCV, Dlib vÃ  LibSVM lÃ  cÃ³ há»— trá»£ trÃªn C++. NhÆ°ng OpenCV em test thá»­ khÃ´ng ra Ä‘Æ°á»£c confidence( vÃ  káº¿t quáº£ margin em tháº¥y cÃ³ váº» khÃ´ng á»•n), Dlib thÃ¬ xung Ä‘á»™t vá»›i Libtorch.
Hiá»‡n táº¡i em Ä‘ang thiÃªn vá» LibSVM nhÆ°ng source code train vÃ  predict quÃ¡ dÃ i, em mong má»i ngÆ°á»i cÃ³ ai tá»«ng lÃ m vá» LibSVM cÃ³ thá»ƒ share em code tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÃ  xá»­ lÃ½ trá»±c tiáº¿p mÃ  khÃ´ng pháº£i qua file data & test hoáº·c cÃ³ má»™t hÆ°á»›ng nÃ o khÃ¡c giÃºp em classifier dá»¯ liá»‡u vÃ  in ra Ä‘Æ°á»£c confidence khÃ´ng áº¡.
Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡.","Em xin chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em muá»‘n cháº¡y classifier báº±ng machine learning vá»›i C++, em cÃ³ xem qua vÃ  tháº¥y OpenCV, Dlib vÃ  LibSVM lÃ  cÃ³ há»— trá»£ trÃªn C++. NhÆ°ng OpenCV em test thá»­ khÃ´ng ra Ä‘Æ°á»£c confidence( vÃ  káº¿t quáº£ margin em tháº¥y cÃ³ váº» khÃ´ng á»•n), Dlib thÃ¬ xung Ä‘á»™t vá»›i Libtorch. Hiá»‡n táº¡i em Ä‘ang thiÃªn vá» LibSVM nhÆ°ng source code train vÃ  predict quÃ¡ dÃ i, em mong má»i ngÆ°á»i cÃ³ ai tá»«ng lÃ m vá» LibSVM cÃ³ thá»ƒ share em code tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÃ  xá»­ lÃ½ trá»±c tiáº¿p mÃ  khÃ´ng pháº£i qua file data & test hoáº·c cÃ³ má»™t hÆ°á»›ng nÃ o khÃ¡c giÃºp em classifier dá»¯ liá»‡u vÃ  in ra Ä‘Æ°á»£c confidence khÃ´ng áº¡. Em xin chÃ¢n thÃ nh cáº£m Æ¡n áº¡.",,,,,
"Dependency Parser
Xin chÃ o nhÃ³m, mÃ¬nh Ä‘ang lÃ m viá»‡c trÃªn cÃ¢y phá»¥ thuá»™c Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin cá»§a má»™t cÃ¢u tiáº¿ng viÃªt.
Váº¥n Ä‘á» lÃ  cÃ³ khÃ¡ nhiá»u tá»« viáº¿t tÄƒt nhÆ°: nsubj, case, nmod, ... MÃ¬nh muá»‘n hiá»ƒu ngá»¯ nghÄ©a, cÅ©ng nhÆ° cÃ¡c tá»« viáº¿t táº¯t Ä‘Ã³ theo tiáº¿ng viá»‡t thÃ¬ mÃ¬nh cÃ³ thá»ƒ tÃ¬m tÃ i liá»‡u á»Ÿ Ä‘Ã¢u Ä‘Æ°á»£c.
Mong má»i ngÆ°á»i tÆ° váº¥n.
Xin cáº£m Æ¡n.","Dependency Parser Xin chÃ o nhÃ³m, mÃ¬nh Ä‘ang lÃ m viá»‡c trÃªn cÃ¢y phá»¥ thuá»™c Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin cá»§a má»™t cÃ¢u tiáº¿ng viÃªt. Váº¥n Ä‘á» lÃ  cÃ³ khÃ¡ nhiá»u tá»« viáº¿t tÄƒt nhÆ°: nsubj, case, nmod, ... MÃ¬nh muá»‘n hiá»ƒu ngá»¯ nghÄ©a, cÅ©ng nhÆ° cÃ¡c tá»« viáº¿t táº¯t Ä‘Ã³ theo tiáº¿ng viá»‡t thÃ¬ mÃ¬nh cÃ³ thá»ƒ tÃ¬m tÃ i liá»‡u á»Ÿ Ä‘Ã¢u Ä‘Æ°á»£c. Mong má»i ngÆ°á»i tÆ° váº¥n. Xin cáº£m Æ¡n.",,,,,
,nan,,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang thá»±c hiá»‡n truy váº¥n áº£nh (Image Retrieval) vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n truy váº¥n. MÃ¬nh tham kháº£o nhiá»u bÃ i bÃ¡o thÃ¬ ngÆ°á»i ta Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u qá»§a cá»§a Image Retrieval thÃ´ng qua Precision - Recall. Tuy nhiÃªn mÃ¬nh Ä‘ang gáº·p vÆ°á»›ng máº¯c á»Ÿ viá»‡c tÃ­nh 
Recall  = (No. of relevant documents retrieved) / (No. of total relevant documents)
MÃ¬nh thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ trÃªn má»™t dataset cÃ³ 5 categories, tuy nhiÃªn má»—i category lÃ  do mÃ¬nh Crawl vá» vá»›i sá»‘ lÆ°á»£ng tá»«ng 1000~2000 áº£nh/category, vÃ¬ lÃ  dá»¯ liá»‡u crawl nÃªn cÃ³ nhiá»u áº£nh dÃ¹ trong Category 1 nhÆ°ng khÃ´ng háº³n ná»™i dung cá»§a áº£nh Ä‘Ã£ liÃªn quan Ä‘áº¿n nÃ³. nÃªn viá»‡c tÃ­nh Recall mÃ¬nh khÃ´ng biáº¿t lÃ  cá»© nÃªn tÃ­nh dá»±a trÃªn tá»•ng sá»‘ lÆ°á»£ng áº£nh cá»§a category Ä‘Ã³ hay pháº£i kiá»ƒm tra láº¡i tá»«ng áº£nh Ä‘á»ƒ xÃ¡c Ä‘á»‹nh áº£nh nÃ o má»›i tháº­t sá»± liÃªn quan Ä‘áº¿n áº£nh truy váº¥n? Cáº£m Æ¡n má»i ngÆ°á»i áº¡ ğŸ™‚","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i mÃ¬nh Ä‘ang thá»±c hiá»‡n truy váº¥n áº£nh (Image Retrieval) vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n truy váº¥n. MÃ¬nh tham kháº£o nhiá»u bÃ i bÃ¡o thÃ¬ ngÆ°á»i ta Ä‘Ã¡nh giÃ¡ Ä‘á»™ hiá»‡u qá»§a cá»§a Image Retrieval thÃ´ng qua Precision - Recall. Tuy nhiÃªn mÃ¬nh Ä‘ang gáº·p vÆ°á»›ng máº¯c á»Ÿ viá»‡c tÃ­nh Recall = (No. of relevant documents retrieved) / (No. of total relevant documents) MÃ¬nh thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ trÃªn má»™t dataset cÃ³ 5 categories, tuy nhiÃªn má»—i category lÃ  do mÃ¬nh Crawl vá» vá»›i sá»‘ lÆ°á»£ng tá»«ng 1000~2000 áº£nh/category, vÃ¬ lÃ  dá»¯ liá»‡u crawl nÃªn cÃ³ nhiá»u áº£nh dÃ¹ trong Category 1 nhÆ°ng khÃ´ng háº³n ná»™i dung cá»§a áº£nh Ä‘Ã£ liÃªn quan Ä‘áº¿n nÃ³. nÃªn viá»‡c tÃ­nh Recall mÃ¬nh khÃ´ng biáº¿t lÃ  cá»© nÃªn tÃ­nh dá»±a trÃªn tá»•ng sá»‘ lÆ°á»£ng áº£nh cá»§a category Ä‘Ã³ hay pháº£i kiá»ƒm tra láº¡i tá»«ng áº£nh Ä‘á»ƒ xÃ¡c Ä‘á»‹nh áº£nh nÃ o má»›i tháº­t sá»± liÃªn quan Ä‘áº¿n áº£nh truy váº¥n? Cáº£m Æ¡n má»i ngÆ°á»i áº¡",,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i, Vá»›i viá»‡c embeeding word báº±ng Tesorflow.keras.layers.Embeeding:  tf.keras.layers.Embedding thÃ¬ Keras dÃ¹ng methods gÃ¬ áº¡: Word2vect hay Glove. MÃ¬nh cáº£m Æ¡n ráº¥t nhiá»u","Má»i ngÆ°á»i cho mÃ¬nh há»i, Vá»›i viá»‡c embeeding word báº±ng Tesorflow.keras.layers.Embeeding: tf.keras.layers.Embedding thÃ¬ Keras dÃ¹ng methods gÃ¬ áº¡: Word2vect hay Glove. MÃ¬nh cáº£m Æ¡n ráº¥t nhiá»u",,,,,
Giáº£i thÆ°á»Ÿng nhá» nhÆ°ng dá»¯ liá»‡u khÃ¡ lá»›n (1M samples):,Giáº£i thÆ°á»Ÿng nhá» nhÆ°ng dá»¯ liá»‡u khÃ¡ lá»›n (1M samples):,,,,,
"MÃ¬nh Ä‘ang phaá»‰ lÃ m bÃ i táº­p nÃ y nhÆ°ng Ä‘ang lÃºng tÃºng trong viá»‡c tÃ­nh vÃ  update back propagation. CÃ³ báº¡n nÃ o tá»«ng lÃ m qua bÃ i táº­p dáº¡ng nÃ y chÆ°a, cho mÃ¬nh há»i vá»›i","MÃ¬nh Ä‘ang phaá»‰ lÃ m bÃ i táº­p nÃ y nhÆ°ng Ä‘ang lÃºng tÃºng trong viá»‡c tÃ­nh vÃ  update back propagation. CÃ³ báº¡n nÃ o tá»«ng lÃ m qua bÃ i táº­p dáº¡ng nÃ y chÆ°a, cho mÃ¬nh há»i vá»›i",,,,,
"ChÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m project vá» object detection, cÃ¡c anh/em nÃ o cÃ³ lÃ m qua cho e xin Ã½ kiáº¿n vá»›i:
em cÃ³:
+ 10 camera IP á»Ÿ 3 vÄƒn phÃ²ng khÃ¡c nhau
+ 1 con server card 3090 24GB/10496 cuda cores, ram 64 GB - max 256 GB
+ mÃ´ hÃ¬nh nháº­n dáº¡ng object detection Ä‘Ã£ train vÃ  test vá»›i tá»«ng camera á»Ÿ máº¡ng local
Hiá»‡n em muá»‘n stream tá»« 3 vÄƒn phÃ²ng Ä‘Ã³ vá» server em qua internet nhÆ°ng em khÃ´ng biáº¿t lÃ m cÃ¡ch nÃ o Ä‘á»ƒ stream vá» server rá»“i dÃ¹ng opencv Ä‘á»ƒ Ä‘á»c luá»“ng stream vá» nÃ y.
CÃ¡c anh chá»‹ nÃ o lÃ m rá»“i cho em há»i lÃ m sao Ä‘á»ƒ stream vá» server qua internet vá»›i áº¡, vá»›i stream nhÆ° váº­y thÃ¬ 1 con server nhÆ° cá»§a em thÃ¬ cÃ³ thá»ƒ chá»‹u Ä‘Æ°á»£c bao nhiÃªu luá»“ng cho mÃ´ hÃ¬nh object detection, stracking with deepsort áº¡?
CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.","ChÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m project vá» object detection, cÃ¡c anh/em nÃ o cÃ³ lÃ m qua cho e xin Ã½ kiáº¿n vá»›i: em cÃ³: + 10 camera IP á»Ÿ 3 vÄƒn phÃ²ng khÃ¡c nhau + 1 con server card 3090 24GB/10496 cuda cores, ram 64 GB - max 256 GB + mÃ´ hÃ¬nh nháº­n dáº¡ng object detection Ä‘Ã£ train vÃ  test vá»›i tá»«ng camera á»Ÿ máº¡ng local Hiá»‡n em muá»‘n stream tá»« 3 vÄƒn phÃ²ng Ä‘Ã³ vá» server em qua internet nhÆ°ng em khÃ´ng biáº¿t lÃ m cÃ¡ch nÃ o Ä‘á»ƒ stream vá» server rá»“i dÃ¹ng opencv Ä‘á»ƒ Ä‘á»c luá»“ng stream vá» nÃ y. CÃ¡c anh chá»‹ nÃ o lÃ m rá»“i cho em há»i lÃ m sao Ä‘á»ƒ stream vá» server qua internet vá»›i áº¡, vá»›i stream nhÆ° váº­y thÃ¬ 1 con server nhÆ° cá»§a em thÃ¬ cÃ³ thá»ƒ chá»‹u Ä‘Æ°á»£c bao nhiÃªu luá»“ng cho mÃ´ hÃ¬nh object detection, stracking with deepsort áº¡? CÃ¡m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"ğŸ¯KÃ­nh chÃ o cÃ¡c bÃ¡c. Sau khi tÃ¬m hiá»ƒu vá» vá» Transformer, hÃ´m nay em máº¡nh dáº¡n tÃ¬m hiá»ƒu BERT vÃ Ã¬ tháº¥y BERT lÃ  má»™t SOTA má»›i ná»•i trong lÃ ng NLP. Em tháº¥y viá»‡c á»©ng dá»¥ng BERT sáº½ lÃ m cho model cá»§a cÃ¡c báº¡n tÄƒng cháº¥t lÆ°á»£ng vÃ  giáº£m thá»i gian xÃ¢y dá»±ng Ä‘Ã¡ng ká»ƒ.
Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c pháº§n nÃ o!
CÃ¡c cao thá»§ mong correct giÃºp em vÃ  mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c. Sau khi tÃ¬m hiá»ƒu vá» vá» Transformer, hÃ´m nay em máº¡nh dáº¡n tÃ¬m hiá»ƒu BERT vÃ Ã¬ tháº¥y BERT lÃ  má»™t SOTA má»›i ná»•i trong lÃ ng NLP. Em tháº¥y viá»‡c á»©ng dá»¥ng BERT sáº½ lÃ m cho model cá»§a cÃ¡c báº¡n tÄƒng cháº¥t lÆ°á»£ng vÃ  giáº£m thá»i gian xÃ¢y dá»±ng Ä‘Ã¡ng ká»ƒ. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c pháº§n nÃ o! CÃ¡c cao thá»§ mong correct giÃºp em vÃ  mong ad duyá»‡t bÃ i!",,,,,
"[PCA] ChÃ o má»i ngÆ°á»i, mÃ¬nh má»›i cháº­p chá»¯ng há»c vá» data vÃ  Ä‘ang bÃ­ hÆ°á»›ng Ä‘i cho PCA. Äá» bÃ i Ä‘c giao lÃ  xá»­ dá»¥ng PCA cho water level. Dáº¡o má»™t vÃ²ng trÃªn google thÃ¬ cháº³ng cÃ³ vÃ­ dá»¥ nÃ o na nÃ¡ nhÆ° cá»§a mÃ¬nh. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh xin vÃ i Ã½ tÆ°á»Ÿng/hÆ°á»›ng Ä‘i Ä‘Æ°á»£c khÃ´ng áº¡. ChÃ¢n thÃ nh cáº£m Æ¡n :)","[PCA] ChÃ o má»i ngÆ°á»i, mÃ¬nh má»›i cháº­p chá»¯ng há»c vá» data vÃ  Ä‘ang bÃ­ hÆ°á»›ng Ä‘i cho PCA. Äá» bÃ i Ä‘c giao lÃ  xá»­ dá»¥ng PCA cho water level. Dáº¡o má»™t vÃ²ng trÃªn google thÃ¬ cháº³ng cÃ³ vÃ­ dá»¥ nÃ o na nÃ¡ nhÆ° cá»§a mÃ¬nh. Má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh xin vÃ i Ã½ tÆ°á»Ÿng/hÆ°á»›ng Ä‘i Ä‘Æ°á»£c khÃ´ng áº¡. ChÃ¢n thÃ nh cáº£m Æ¡n :)",,,,,
"Há»c sÃ¢u (Deep learning), hÃ nh trÃ¬nh 70 nÄƒm Ä‘i tÃ¬m chÃ¢n Ã¡i
(BÃ i mang tÃ­nh cháº¥t giáº£i trÃ­ lÃ  chÃ­nh)
HÃ´m nay tranh thá»§ cáº­u con trai vá» quÃª vá»›i Ã´ng bÃ  ná»™i, cÃ³ thá»i gian tháº£nh thÆ¡i Ä‘áº§u Ã³c ngáº«m nghÄ© nhÃ¢n tÃ¬nh tháº¿ thÃ¡i. LÆ°á»£n qua lÆ°á»£n láº¡i trÃªn cÃ¡c diá»…n Ä‘Ã n, há»™i nhÃ³m tháº¥y ngÆ°á»i ta nÃ³i nhiá»u vá» Deep Learning, Ä‘áº¿n cáº£ Ä‘á»©a báº¡n mÃ¬nh há»c kinh táº¿ cÅ©ng há»i há»c code AI, Deep Learning .... Cao há»©ng chia sáº» Ã­t hiá»ƒu biáº¿t báº£n thÃ¢n vá» cÃ¡i thá»© â€œso deepâ€ Ä‘ang lÃ m mÆ°a lÃ m giÃ³ kháº¯p cÃ¡c máº·t tráº­n nÃ y.
CÃ¡i gÃ¬ cÅ©ng cÃ³ Ä‘iá»ƒm báº¯t Ä‘áº§u, Ä‘á»‘i vá»›i Deep Learning Ä‘iá»ƒm khá»Ÿi thá»§y phÃ¹ há»£p nháº¥t tÃ´i nghÄ© cÃ³ láº½ lÃ  vÃ o nhá»¯ng nÄƒm 1950, á»Ÿ má»™t lÄ©nh vá»±c khÃ´ng liÃªn quan Ä‘áº¿n AI: Sinh há»c.
NgÆ°á»i thá»£ xÃ¢y Ä‘áº·t viÃªn gáº¡ch Ä‘áº§u tiÃªn nÃ y lÃ  David H. Hubel, á»Ÿ má»™t thÃ­ nghiá»‡m khÃ´ng láº¥y gÃ¬ lÃ m liÃªn quan. Ã”ng vÃ  Ä‘á»“ng nghiá»‡p cá»§a mÃ¬nh (Wiesel) Ä‘áº·t nhá»¯ng Ä‘iá»‡n cá»±c nhá» vÃ o trong pháº§n vá» nÃ£o xá»­ lÃ½ thá»‹ giÃ¡c cá»§a nhá»¯ng con mÃ¨o Ä‘Ã£ Ä‘Æ°á»£c gÃ¢y mÃª, há» chiáº¿u cÃ¡c kiá»ƒu tia sÃ¡ng khÃ¡c nhau lÃªn má»™t mÃ n hÃ¬nh trÆ°á»›c con mÃ¨o vÃ  nháº­n tháº¥y má»™t sá»‘ neuron nháº¥t Ä‘á»‹nh pháº£n á»©ng nhanh hÆ¡n vá»›i má»™t vÃ i kiá»ƒu sÃ¡ng nÃ y, trong khi cÃ¡c neuron khÃ¡c pháº£n nhanh hÆ¡n á»Ÿ kiá»ƒu sÃ¡ng khÃ¡c. Tá»©c má»—i neuron cÃ³ 1 tráº¡ng thÃ¡i kÃ­ch thÃ­ch khÃ¡c nhau (weight) trÆ°á»›c cÃ¹ng má»™t Ä‘á»‘i tÆ°á»£ng . Tá»« Ä‘Ã³ má»Ÿ ra má»™t chÆ°Æ¡ng má»›i cho lá»‹ch sá»­ nghiÃªn cá»©u hoáº¡t Ä‘á»™ng cá»§a neuron tháº§n kinh con ngÆ°á»i. Nhá» nhá»¯ng Ä‘Ã³ng gÃ³p Ä‘Ã³, nÄƒm 1981 Ã´ng Ä‘Æ°á»£c nháº­n giáº£i Nobel vá» sinh há»c vÃ  y há»c (Ä‘á»“ng nhÃ¢n giáº£i vá»›i Wiesel).
NhÆ°ng cÃ³ náº±m mÆ¡ Hubel cÅ©ng khÃ´ng tÆ°á»Ÿng tÆ°á»£ng ra Ä‘Æ°á»£c tÃ¡c Ä‘á»™ng lá»›n lao cá»§a nhá»¯ng nghiÃªn cá»©u cá»§a Ã´ng trÃªn lÃªn lÄ©nh vá»±c AI nhá»¯ng nÄƒm sau Ä‘Ã³.
VÃ o má»™t ngÃ y Ä‘áº¹p trá»i mÃ¹a thu nÄƒm 1958, Frank Rosenblatt nhÃ¢m nhi má»™t tÃ¡ch cafe trong phÃ²ng lab Naval Research, Ã´ng nhÃ¬n ra dÃ²ng kÃªnh xanh ngÃ¡t phÃ­a cá»­a sá»• nghÄ© miÃªn man vá» cÃ¡ch lÃ m cho mÃ¡y tÃ­nh trá»Ÿ nÃªn há»¯u dá»¥ng hÆ¡n, giáº£i Ä‘Æ°á»£c nhiá»u bÃ i toÃ¡n hÆ¡n vÃ  Ä‘áº·c biá»‡t lÃ  cÃ³ thá»ƒ suy nghÄ© nhÆ° con ngÆ°á»i. Ã”ng tÃ¬nh cá» Ä‘á»c Ä‘Æ°á»£c nghiÃªn cá»©u cá»§a Hubel vá» cÆ¡ cháº¿ váº­n hÃ nh cá»§a cÃ¡c neuron tháº§n kinh, vá» cÃ¡ch chÃºng pháº£n á»©ng nhiá»u Ã­t khÃ¡c nhau vá»›i cÃ¹ng 1 kÃ­ch thÃ­ch.
Ã”ng láº©m nháº©m: náº¿u má»—i neuron lÃ  1 biáº¿n, vÃ  má»©c pháº£n á»©ng lÃ  giÃ¡ trá»‹ cao tháº¥p cá»§a biáº¿n Ä‘Ã³ thÃ¬ nhÆ° nÃ o nhá»‰, cÃ³ pháº£i ...
NhÆ° sÃ©t Ä‘Ã¡nh ngang tai!
Ã”ng vá»— Ä‘Ã¹i cÃ¡i rá»™p, rá»“i cháº¡y ngay xuá»‘ng phÃ²ng lab nÆ¡i chiáº¿c mÃ¡y tÃ­nh IBM 704 náº·ng 5 táº¥n Ä‘ang cháº¡y cÃ¡c phÃ©p toÃ¡n, tiáº¿ng á»“n phÃ¡t ra cá»¡ ngang lÃºc báº¡n Ä‘á»©ng á»Ÿ ngÃ£ tÆ° LÃª VÄƒn LÆ°Æ¡ng giá» tan táº§m.
Vá»«a cháº¡y vá»«a hÃ´ lá»›n: â€œÄÃ¹, tÃ¬m ra rá»“i! tÃ¬m ra rá»“iâ€ (hoáº·c cÅ©ng cÃ³ thá»ƒ lá»‹ch sá»± hÆ¡n)
Rosenblatt Ä‘Ã£ táº¡o ra Ä‘Æ°á»£c há»‡ thá»‘ng mÃ´ phá»ng láº¡i hoáº¡t Ä‘á»™ng cá»§a neuron nÃ£o bá»™ (neural network) Ä‘áº§u tiÃªn Ä‘áº§u tiÃªn chá»‰ gá»“m 2 layer (input, output), Ä‘áº§u vÃ o lÃ  ma tráº­n 20x20 chá»©a pixel hÃ¬nh áº£nh con váº­t, Ä‘áº§u ra chá»‰ cÃ³ 2 node (2 class) phÃ¢n biá»‡t Ä‘Ã³ lÃ  chÃ³ hay mÃ¨o.
CÅ©ng nhÆ° trending AI hiá»‡n giá», khi cÃ³ 1 khÃ¡m phÃ¡ má»›i, bÃ¡o chÃ­ sáº½ viáº¿t bÃ i ráº§n ráº§n. TrÃªn tá» New York Time lÃºc Ä‘Ã³ cÃ³ Ä‘Æ°a bÃ i trÃªn trang nháº¥t â€œNEW NAVY DEVICE LEARNS BY DOING: Psychologist Shows Embryo of Computer Designed to Read and Grow Wiserâ€. Äáº¡i khÃ¡i dá»‹ch lÃ  nhá»¯ng nhÃ  tÃ¢m lÃ½ há»c Ä‘Ã£ lÃ m cho mÃ¡y tÃ­nh cÃ³ thá»ƒ Ä‘á»c, vÃ  trá»Ÿ nÃªn thÃ´ng minh hÆ¡n. Nhá»¯ng phÃ³ng viÃªn nhiá»‡t tÃ¬nh khÃ´ng quÃªn â€œchÃ©mâ€:  â€œÄá»‘i thá»§ náº·ng ká»³ Ä‘áº§u tiÃªn cá»§a nÃ£o bá»™ con ngÆ°á»i Ä‘Ã£ Ä‘Æ°á»£c táº¡o raâ€, ráº±ng cÃ³ thá»ƒ chÃºng ta sáº¯p mÃ´ phá»ng láº¡i Ä‘Æ°á»£c bá»™ nÃ£o cá»§a con ngÆ°á»i, ráº±ng mÃ¡y tÃ­nh sáº¯p suy nghÄ©, lÃ m viá»‡c, giáº£i quyáº¿t váº¥n Ä‘á» nhÆ° con ngÆ°á»i bla bla ... Sau hÆ¡n ná»­a tháº¿ ká»· Ä‘iá»u Ä‘Ã³ váº«n chÆ°a Ä‘áº¿n, tháº¿ má»›i tháº¥y sá»± láº¡c quan cá»§a con ngÆ°á»i lÃ  vÃ´ háº¡n. May mÃ  há» chÆ°a láº¡c quan Ä‘áº¿n má»©c lo ngáº¡i vá» viá»‡c bá»‹ mÃ¡y tÃ­nh láº¥y máº¥t viá»‡c lÃ m cá»§a con ngÆ°á»i nhÆ° chÃºng ta hiá»‡n nay.
Thá»i gian chá»©ng minh chÆ°Æ¡ng trÃ¬nh cá»§a Rosenblatt lÃ  chÆ°a hoÃ n háº£o, váº«n nhiá»u dá»± Ä‘oÃ¡n sai dÃ¹ traning nhiá»u láº§n nhÆ° nÃ o chÄƒng ná»¯a. Má»i thá»© láº¡i Ä‘i vÃ o báº¿ táº¯c. BÃ¡o chÃ­ láº¡i tiáº¿p tá»¥c chuyá»ƒn chá»§ Ä‘á» sang cÆ°á»›p, giáº¿t, hiáº¿p nhÆ° thÆ°á»ng lá»‡.
Pháº£i Ä‘áº¿n nÄƒm 1960, khi Marvin Minsky nhÃ  khoa há»c mÃ¡y tÃ­nh Ä‘áº¿n tá»« MIT trong cuá»‘n sÃ¡ch mang tÃªn â€œPerceptronsâ€ cá»§a mÃ¬nh chá»©ng minh báº±ng toÃ¡n há»c ráº±ng 2 layer lÃ  khÃ´ng Ä‘á»§, chÃºng ta cáº§n nhiá»u hÆ¡n tháº¿. Äáº¿n nay Ä‘Ã³ váº«n Ä‘Æ°á»£c coi lÃ  má»™t cuá»‘n sÃ¡ch quan trá»ng trong lá»‹ch sá»­ AI. NhÆ°ng vá»›i trá»±c giÃ¡c thiÃªn tÃ i cá»§a mÃ¬nh, Ã´ng cÅ©ng khÃ´ng quÃªn cáº£nh bÃ¡o: â€œKhÃ´ng pháº£i cá»© cho cÃ ng nhiá»u node lÃ  ta giáº£i quyáº¿t Ä‘Æ°á»£c má»i váº¥n Ä‘á» Ä‘Ã¢u broâ€. Äáº¿n táº­n ngÃ y nay, sau 60 nÄƒm cuá»‘n sÃ¡ch ra Ä‘á»i, nhá»¯ng háº­u bá»‘i chÃºng ta váº«n hay vÆ°á»›ng pháº£i lá»—i Ä‘Ã³. Má»—i khi model neuron network cho tá»‰ lá»‡ chÃ­nh xÃ¡c tháº¥p, viá»‡c Ä‘áº§u tiÃªn chÃºng ta hay nghÄ© Ä‘áº¿n lÃ  â€œadd more node, more layerâ€ (hay lÃ  chá»‰ mÃ¬nh tÃ´i máº¯c lá»—i tÆ° duy Ä‘Ã³?)
Trong suá»‘t giai Ä‘oáº¡n 1960-2000, neuron network chá»©ng kiáº¿n sá»± hÆ°ng thá»‹nh vÃ  thoÃ¡i trÃ o dáº§n dáº§n. Sá»± nhiá»‡t tÃ¬nh nÃ o rá»“i cÅ©ng lÃºc nguá»™i láº¡nh khi Ä‘Æ°á»ng Ä‘i ngÃ y má»™t tá»‘i.
NgÆ°á»i kiÃªn trÃ¬ theo Ä‘uá»•i Neuron Network nháº¥t cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n má»™t vÃ i cÃ¡i tÃªn nhÆ° Yoshua Bengio, Geoff Hinton mÃ  khÃ´ng thá»ƒ khÃ´ng nháº¯c Ä‘áº¿n Yann Lecun.
NgÆ°á»i Ä‘á»i nÃ³i ráº±ng â€œtÃ­ch cá»±c quay tay, váº­n may sáº½ Ä‘áº¿nâ€. TÃ´i pháº£i khÃ¢m phá»¥c sá»± kiÃªn trÃ¬ cá»§a Ã´ng trong quÃ¡ trÃ¬nh theo Ä‘uá»•i Neuron Network. ChÃºng ta pháº£i trá»Ÿ láº¡i bá»‘i cáº£nh giai Ä‘oáº¡n nÄƒm 1990-2010. LÃºc nÃ y Neuron Network Ã­t nhiá»u thoÃ¡i trÃ o, nhÆ°á»ng chá»— cho nhá»¯ng phÆ°Æ¡ng phÃ¡p Marchine Learning thá»i thÆ°á»£ng khÃ¡c. Tiá»n ngÃ¢n sÃ¡ch (funding) vá» Neuron Network thÃ¬ khÃ³ xin nhÆ° Ä‘i lÃªn trá»i, cÃ¡c Shark quan tÃ¢m nhiá»u Ä‘áº¿n cÃ¡c hÆ°á»›ng Ä‘i má»›i, Ä‘á»“ng nghiá»‡p, rá»“i nghiÃªn cá»©u sinh dÆ°á»›i quyá»n ai cÅ©ng uá»ƒ oáº£i, chÃ¡n chÆ°á»ng rá»“i lÅ© lÆ°á»£t rá»§ nhau bá» cuá»™c chÆ¡i.
áº¤y váº­y mÃ  Yan Lecun váº«n khÃ´ng bá» cuá»™c, khÃ´ng gÃ¬ ngÄƒn Ä‘Æ°á»£c sá»± nhiá»‡t tÃ¬nh cá»§a tuá»•i tráº». NÄƒm  nÄƒm 1990 Ã´ng cÃ¹ng Ä‘á»“ng nghiá»‡p ra Ä‘Æ°á»£c model nháº­n diá»‡n chá»¯ viáº¿t tay cÃ³ tÃªn LeNet (Ä‘áº§u vÃ o lÃ  ma tráº­n 16x16 pixcel) cho Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ cao, táº¡o Ä‘Æ°á»£c Ã­t nhiá»u tiáº¿ng vang. Nhiá»u ngÆ°á»i tháº¿ há»‡ Ä‘Ã³ láº¡i Ä‘Æ°á»£c truyá»n cáº£m há»©ng quay trá»Ÿ láº¡i vá»›i neuron network. á»¨ng dá»¥ng rÃµ nháº¥t thá»i Ä‘iá»ƒm Ä‘Ã³ lÃ  trong cÃ¡c ngÃ¢n hÃ ng Ä‘á»ƒ nháº­n diá»‡n chá»¯ viáº¿t tay. Æ¯á»›c lÆ°á»£ng cÃ³ khoáº£ng 10% giao dá»‹ch báº±ng xÃ©c (check) trÃªn Ä‘áº¥t Má»¹ Ä‘Æ°á»£c nháº­n diá»‡n qua há»‡ thá»‘ng nhÃ¢n diá»‡n tá»± Ä‘á»™ng. NhÆ°ng áº¥y lÃ  khi SVM chÆ°a ra Ä‘á»i!
NÄƒm 1992, Vapnik Ä‘á»“ng nghiá»‡p cá»§a Yan Lecun (phÃ²ng thÃ­ nghiá»‡m AT&Bell), dÃ¬m Neuron Network chÃ¬m sÃ¢u vÃ o vÃ¹ng quÃªn lÃ£ng báº±ng viá»‡c táº¡o ra thuáº­t toÃ¡n SVM (Support Vector Machine) cho Ä‘á»™ chÃ­nh xÃ¡c hÆ¡n nhiá»u Neuron Network trong ráº¥t nhiá»u bÃ i Ä‘áº·c biá»‡t lÃ  nháº­n dáº¡ng chá»¯ viáº¿t, phÃ¢n loáº¡i áº£nh, NLP (xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn). NgÆ°á»i ta Äƒn SVM, ngá»§ SVM, cÃ  phÃª bÃ n luáº­n vá» SVM. Tiá»n láº¡i cÃ³ nÆ¡i Ä‘á»ƒ Ä‘á»•, bÃ¡o chÃ­ láº¡i Ä‘Æ°á»£c dá»‹p ra bÃ i lia lá»‹a.
Giai Ä‘oáº¡n nÃ y nghÄ© cÅ©ng tá»™i Ã´ng Yan Lecun, váº«n ra bÃ i Ä‘á»u táº§m 5-10 bÃ i 1 nÄƒm nhÆ°ng quÃ¡ ná»•i báº­t, khÃ´ng nhiá»u ngÆ°á»i  â€œlikeâ€ (cited theo ngÃ´n ngá»¯ khoa há»c), mÃ£i sau tÃªn tuá»•i ná»•i nhÆ° cá»“n thÃ¬ láº¡i thi nhau cite láº¡i cáº£ cÃ¡c bÃ i cá»•, ngÆ°á»i Ä‘á»i vá»‘n váº­y.
NÄƒm 2012 diá»…n ra má»™t biáº¿n cá»‘ quan trá»ng trong lÄ©nh vá»±c AI, Ä‘áº·t ná»n mÃ³ng cho Deep Learning ngÃ y nay cÅ©ng nhÆ° Ä‘Æ°a Yan Lecun trá»Ÿ thÃ nh ngÆ°á»i mÃ  ai cÅ©ng biáº¿t. NgÆ°á»i Ä‘Ã³ng gÃ³p cho sá»± kiá»‡n nÃ y lÃ  tháº§y cá»§a Yan Lecun: Geoffrey Hinton. NhÆ°ng hÃ£y chá», nÃ³i má»™t chÃºt vá» GPU Ä‘Ã£.
Má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n nháº¥t cá»§a máº¡ng neuron (neural network) lÃ  viá»‡c tÃ­nh toÃ¡n ráº¥t náº·ng, thÃªm má»™t node hay 1 layer vÃ o thÃ´i lÃ  pháº£i thÃªm cáº£ trÄƒm, cáº£ nghÃ¬n phÃ©p toÃ¡n, cá»© tháº¿ cáº¥p sá»‘ nhÃ¢n lÃªn. CPU thá»i báº¥y giá» váº«n cÃ¹i báº¯p, nhiá»u nhÃ  khoa há»c thá»i báº¥y giá» chia sáº», Ä‘á»ƒ training má»™t máº¡ng neuron cho tá»­ táº¿ cÃ³ khi máº¥t cáº£ tuáº§n, hoáº·c tháº­m chÃ­ tÃ­nh báº±ng thÃ¡ng. Loay hoay Ä‘iá»u chá»‰nh tham sá»‘, cháº¡y vÃ i turn training nhÆ° váº­y khÃ´ng khÃ©o lá»¡ toi máº¥t ká»³ bÃ¡o bÃ¡o.
GPU ra Ä‘á»i ban Ä‘áº§u vá»›i má»¥c Ä‘Ã­ch dung tá»¥c hÆ¡n lÃ  phá»¥c vá»¥ cÃ¡c mÃ¡y chÆ¡i game vÃ  xá»­ lÃ½ Ä‘á»“ há»a. NhÆ°ng dáº§n dÃ  ngÆ°á»i ta phÃ¡t hiá»‡n ra cÃ¡ch tÃ­nh toÃ¡n cá»§a GPU cá»±c ká»³ phÃ¹ há»£p vá»›i viá»‡c nhÃ¢n cháº­p ma tráº­n (viá»‡c mÃ  neuron network thÆ°á»ng xuyÃªn pháº£i xá»­ lÃ½). áº¤y tháº¿ lÃ  láº¡i tÃ¬m ra Ã¡nh sÃ¡ng cuá»‘i Ä‘Æ°á»ng háº§m. Nhá» GPU, giá» Ä‘Ã¢y ta Ä‘Ã£ cÃ³ thá»ƒ training nhá»¯ng máº¡ng neuron ráº¥t lá»›n mÃ  thá»i gian chá» khÃ´ng quÃ¡ lÃ¢u.
Chuyá»‡n gÃ¬ Ä‘áº¿n sáº½ Ä‘áº¿n!
Tá»« nhá»¯ng nÄƒm 2010, Ä‘á»™i ngÅ© Hinton Ä‘Ã£ báº¯t Ä‘áº§u á»©ng dá»¥ng GPU vÃ o viá»‡c tÃ­nh toÃ¡n neuron network, nhá» Ä‘Ã³ cÃ³ thá»ƒ huáº¥n luyá»‡n Ä‘Æ°á»£c nhá»¯ng máº¡ng cá»¡ lá»›n. NÄƒm 2012, team Hinton Ä‘áº¡t Ä‘Æ°á»£c thÃ nh tá»±u lá»›n vá»›i viá»‡c phÃ¢n loáº¡i áº£nh trÃªn data set ImageNet. Vá»›i sá»©c máº¡nh cá»§a GPU, vÃ  táº¥t nhiÃªn cáº£ â€œmáº¡nh vÃ¬ gáº¡o, báº¡o vÃ¬ tiá»nâ€, Ã´ng cÃ¹ng Ä‘á»™i nghiÃªn cá»©u cá»§a mÃ¬nh (khÃ´ng cÃ³ Yan Lecun) tiáº¿n hÃ nh traning (huáº¥n luyá»‡n) trÃªn network gá»“m 60 triá»‡u tham sá»‘, 650.000 neuron, thá»±c hiá»‡n trÃªn training data set (dá»¯ liá»‡u huáº¥n luyá»‡n) 1.2 triá»‡u hÃ¬nh áº£nh, 1000 class (thÆ° má»¥c hÃ¬nh áº£nh),  test trÃªn 150.000 hÃ¬nh áº£nh vá»›i Ä‘á»™ chÃ­nh xÃ¡c lÃªn tÆ¡i 84%, gÃ¢y xá»‘c náº·ng giá»›i computer science lÃºc báº¥y giá» (75% Ä‘Ã£ lÃ  cao háº¿t táº§m rá»“i). Má»™t Ä‘iá»u tÃ´i ráº¥t ná»ƒ Geoffrey Hinton á»Ÿ chá»—, Ã´ng khÃ´ng quÃªn cite bÃ i cá»§a há»c trÃ² cá»§a mÃ¬nh nÄƒm 1990 vá» nháº­n dáº¡ng chá»¯ viáº¿t tay, nÃ³i ráº±ng cÃ´ng trÃ¬nh cá»§a Ã´ng káº¿ thá»«a nhiá»u tá»« bÃ i bÃ¡o Ä‘Ã³. Yan Lecun lÃªn hÆ°Æ¡ng, Geoffrey Hinton cÅ©ng hÆ°á»Ÿng Ä‘á»§ (thÃ nh láº­p cÃ´ng ty riÃªng vá» AI). NgÆ°á»i quen hÆ¡n nhau lÃ  á»Ÿ chá»— Ä‘Ã³.
Tá»« nhá»¯ng cÃ´ng trÃ¬nh cá»§a Geoffrey Hinton, hÃ ng loáº¡t net má»›i ra Ä‘á»i, vá»›i nhiá»u tham sá»‘ hÆ¡n, nhiá»u layer hÆ¡n, data set khá»§ng hÆ¡n, ká»· lá»¥c liÃªn tá»¥c bá»‹ xÃ´ Ä‘á»•. Deep Learning dáº§n trá»Ÿ thÃ nh cuá»™c chÆ¡i cá»§a nhá»¯ng Ä‘á»™i láº¯m tiá»n, láº¯m gáº¡o. Nhá»¯ng diá»…n biáº¿n gáº§n Ä‘Ã¢y cháº¯c ai cÅ©ng cáº­p nháº­t rá»“i nÃªn tÃ´i ko nháº¯c láº¡i ná»¯a.
Google cÅ©ng khÃ´ng náº±m ngoÃ i trending nÃ y, DeepMind Ä‘Æ°á»£c google mua láº¡i vá»›i giÃ¡ 500 triá»‡u Ä‘Ã´ trump nÄƒm 2014. Tá»« Ä‘Ã¢y AlphaStar, AlphaGo, AlphaFold Ä‘Æ°á»£c ra Ä‘á»i vÃ  ná»•i tiáº¿ng toÃ n tháº¿ giá»›i. Chá»‰ thÃ¡ng trÆ°á»›c thÃ´i, AlphaFold Ä‘Ã£ dá»± Ä‘oÃ¡n ráº¥t chÃ­nh xÃ¡c cáº¥u trÃºc cuá»™n 3D cá»§a protein, viáº¿t nÃªn lá»‹ch sá»­ ngÃ nh sinh há»c phÃ¢n tá»­.
Má»™t con Ä‘Æ°á»ng dÃ i cÃ²n á»Ÿ phÃ­a trÆ°á»›c, phong trÃ o nghiÃªn cá»©u Deep Learning Ä‘ang ná»•i lÃªn ráº¥t máº¡nh trÃªn toÃ n tháº¿ giá»›i, trong Ä‘Ã³ ngÆ°á»i tráº» Viá»‡t Nam cÅ©ng tham gia ráº¥t tÃ­ch cá»±c. Æ  mÃ¢y zing, gÃºt chÃ³p my friends.
ChÃ©m giÃ³ cho vui tháº¿ thÃ´i, giá» pháº£i Ä‘i thay bá»‰m cho con Ä‘Ã£. Háº¹n gáº·p má»i ngÆ°á»i gáº§n Ä‘Ã¢y nháº¥t.

Edit: Sau comment cá»§a báº¡n Phong Thanh DÆ°Æ¡ng, mÃ¬nh xin sá»­a láº¡i thá»i Ä‘iá»ƒm team Hinton lÃ m báº¯t Ä‘áº§u á»©ng dá»¥ng GPU traning tá»« giai Ä‘oáº¡n 2010, ra bÃ¡o cÃ¡o (paper) ná»•i danh vÃ o nÄƒm 2012. Xin lá»—i cÃ¡c báº¡n vÃ¬ sai má»‘c thá»i gian.

DÆ°Æ¡ng Thá»‹nh

Nguá»“n tham kháº£o:
https://en.wikipedia.org/wiki/David_H._Hubel
https://en.wikipedia.org/wiki/Frank_Rosenblatt
https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon
https://en.wikipedia.org/wiki/Yann_LeCun
https://en.wikipedia.org/wiki/Geoffrey_Hinton
Handwritten digit recognition with a back-propagation network. In Advances in Neural Information Processing Systems (1990)
https://en.wikipedia.org/wiki/Support_vector_machine
https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
https://www.theguardian.com/technology/2020/nov/30/deepmind-ai-cracks-50-year-old-problem-of-biology-research","Há»c sÃ¢u (Deep learning), hÃ nh trÃ¬nh 70 nÄƒm Ä‘i tÃ¬m chÃ¢n Ã¡i (BÃ i mang tÃ­nh cháº¥t giáº£i trÃ­ lÃ  chÃ­nh) HÃ´m nay tranh thá»§ cáº­u con trai vá» quÃª vá»›i Ã´ng bÃ  ná»™i, cÃ³ thá»i gian tháº£nh thÆ¡i Ä‘áº§u Ã³c ngáº«m nghÄ© nhÃ¢n tÃ¬nh tháº¿ thÃ¡i. LÆ°á»£n qua lÆ°á»£n láº¡i trÃªn cÃ¡c diá»…n Ä‘Ã n, há»™i nhÃ³m tháº¥y ngÆ°á»i ta nÃ³i nhiá»u vá» Deep Learning, Ä‘áº¿n cáº£ Ä‘á»©a báº¡n mÃ¬nh há»c kinh táº¿ cÅ©ng há»i há»c code AI, Deep Learning .... Cao há»©ng chia sáº» Ã­t hiá»ƒu biáº¿t báº£n thÃ¢n vá» cÃ¡i thá»© â€œso deepâ€ Ä‘ang lÃ m mÆ°a lÃ m giÃ³ kháº¯p cÃ¡c máº·t tráº­n nÃ y. CÃ¡i gÃ¬ cÅ©ng cÃ³ Ä‘iá»ƒm báº¯t Ä‘áº§u, Ä‘á»‘i vá»›i Deep Learning Ä‘iá»ƒm khá»Ÿi thá»§y phÃ¹ há»£p nháº¥t tÃ´i nghÄ© cÃ³ láº½ lÃ  vÃ o nhá»¯ng nÄƒm 1950, á»Ÿ má»™t lÄ©nh vá»±c khÃ´ng liÃªn quan Ä‘áº¿n AI: Sinh há»c. NgÆ°á»i thá»£ xÃ¢y Ä‘áº·t viÃªn gáº¡ch Ä‘áº§u tiÃªn nÃ y lÃ  David H. Hubel, á»Ÿ má»™t thÃ­ nghiá»‡m khÃ´ng láº¥y gÃ¬ lÃ m liÃªn quan. Ã”ng vÃ  Ä‘á»“ng nghiá»‡p cá»§a mÃ¬nh (Wiesel) Ä‘áº·t nhá»¯ng Ä‘iá»‡n cá»±c nhá» vÃ o trong pháº§n vá» nÃ£o xá»­ lÃ½ thá»‹ giÃ¡c cá»§a nhá»¯ng con mÃ¨o Ä‘Ã£ Ä‘Æ°á»£c gÃ¢y mÃª, há» chiáº¿u cÃ¡c kiá»ƒu tia sÃ¡ng khÃ¡c nhau lÃªn má»™t mÃ n hÃ¬nh trÆ°á»›c con mÃ¨o vÃ  nháº­n tháº¥y má»™t sá»‘ neuron nháº¥t Ä‘á»‹nh pháº£n á»©ng nhanh hÆ¡n vá»›i má»™t vÃ i kiá»ƒu sÃ¡ng nÃ y, trong khi cÃ¡c neuron khÃ¡c pháº£n nhanh hÆ¡n á»Ÿ kiá»ƒu sÃ¡ng khÃ¡c. Tá»©c má»—i neuron cÃ³ 1 tráº¡ng thÃ¡i kÃ­ch thÃ­ch khÃ¡c nhau (weight) trÆ°á»›c cÃ¹ng má»™t Ä‘á»‘i tÆ°á»£ng . Tá»« Ä‘Ã³ má»Ÿ ra má»™t chÆ°Æ¡ng má»›i cho lá»‹ch sá»­ nghiÃªn cá»©u hoáº¡t Ä‘á»™ng cá»§a neuron tháº§n kinh con ngÆ°á»i. Nhá» nhá»¯ng Ä‘Ã³ng gÃ³p Ä‘Ã³, nÄƒm 1981 Ã´ng Ä‘Æ°á»£c nháº­n giáº£i Nobel vá» sinh há»c vÃ  y há»c (Ä‘á»“ng nhÃ¢n giáº£i vá»›i Wiesel). NhÆ°ng cÃ³ náº±m mÆ¡ Hubel cÅ©ng khÃ´ng tÆ°á»Ÿng tÆ°á»£ng ra Ä‘Æ°á»£c tÃ¡c Ä‘á»™ng lá»›n lao cá»§a nhá»¯ng nghiÃªn cá»©u cá»§a Ã´ng trÃªn lÃªn lÄ©nh vá»±c AI nhá»¯ng nÄƒm sau Ä‘Ã³. VÃ o má»™t ngÃ y Ä‘áº¹p trá»i mÃ¹a thu nÄƒm 1958, Frank Rosenblatt nhÃ¢m nhi má»™t tÃ¡ch cafe trong phÃ²ng lab Naval Research, Ã´ng nhÃ¬n ra dÃ²ng kÃªnh xanh ngÃ¡t phÃ­a cá»­a sá»• nghÄ© miÃªn man vá» cÃ¡ch lÃ m cho mÃ¡y tÃ­nh trá»Ÿ nÃªn há»¯u dá»¥ng hÆ¡n, giáº£i Ä‘Æ°á»£c nhiá»u bÃ i toÃ¡n hÆ¡n vÃ  Ä‘áº·c biá»‡t lÃ  cÃ³ thá»ƒ suy nghÄ© nhÆ° con ngÆ°á»i. Ã”ng tÃ¬nh cá» Ä‘á»c Ä‘Æ°á»£c nghiÃªn cá»©u cá»§a Hubel vá» cÆ¡ cháº¿ váº­n hÃ nh cá»§a cÃ¡c neuron tháº§n kinh, vá» cÃ¡ch chÃºng pháº£n á»©ng nhiá»u Ã­t khÃ¡c nhau vá»›i cÃ¹ng 1 kÃ­ch thÃ­ch. Ã”ng láº©m nháº©m: náº¿u má»—i neuron lÃ  1 biáº¿n, vÃ  má»©c pháº£n á»©ng lÃ  giÃ¡ trá»‹ cao tháº¥p cá»§a biáº¿n Ä‘Ã³ thÃ¬ nhÆ° nÃ o nhá»‰, cÃ³ pháº£i ... NhÆ° sÃ©t Ä‘Ã¡nh ngang tai! Ã”ng vá»— Ä‘Ã¹i cÃ¡i rá»™p, rá»“i cháº¡y ngay xuá»‘ng phÃ²ng lab nÆ¡i chiáº¿c mÃ¡y tÃ­nh IBM 704 náº·ng 5 táº¥n Ä‘ang cháº¡y cÃ¡c phÃ©p toÃ¡n, tiáº¿ng á»“n phÃ¡t ra cá»¡ ngang lÃºc báº¡n Ä‘á»©ng á»Ÿ ngÃ£ tÆ° LÃª VÄƒn LÆ°Æ¡ng giá» tan táº§m. Vá»«a cháº¡y vá»«a hÃ´ lá»›n: â€œÄÃ¹, tÃ¬m ra rá»“i! tÃ¬m ra rá»“iâ€ (hoáº·c cÅ©ng cÃ³ thá»ƒ lá»‹ch sá»± hÆ¡n) Rosenblatt Ä‘Ã£ táº¡o ra Ä‘Æ°á»£c há»‡ thá»‘ng mÃ´ phá»ng láº¡i hoáº¡t Ä‘á»™ng cá»§a neuron nÃ£o bá»™ (neural network) Ä‘áº§u tiÃªn Ä‘áº§u tiÃªn chá»‰ gá»“m 2 layer (input, output), Ä‘áº§u vÃ o lÃ  ma tráº­n 20x20 chá»©a pixel hÃ¬nh áº£nh con váº­t, Ä‘áº§u ra chá»‰ cÃ³ 2 node (2 class) phÃ¢n biá»‡t Ä‘Ã³ lÃ  chÃ³ hay mÃ¨o. CÅ©ng nhÆ° trending AI hiá»‡n giá», khi cÃ³ 1 khÃ¡m phÃ¡ má»›i, bÃ¡o chÃ­ sáº½ viáº¿t bÃ i ráº§n ráº§n. TrÃªn tá» New York Time lÃºc Ä‘Ã³ cÃ³ Ä‘Æ°a bÃ i trÃªn trang nháº¥t â€œNEW NAVY DEVICE LEARNS BY DOING: Psychologist Shows Embryo of Computer Designed to Read and Grow Wiserâ€. Äáº¡i khÃ¡i dá»‹ch lÃ  nhá»¯ng nhÃ  tÃ¢m lÃ½ há»c Ä‘Ã£ lÃ m cho mÃ¡y tÃ­nh cÃ³ thá»ƒ Ä‘á»c, vÃ  trá»Ÿ nÃªn thÃ´ng minh hÆ¡n. Nhá»¯ng phÃ³ng viÃªn nhiá»‡t tÃ¬nh khÃ´ng quÃªn â€œchÃ©mâ€: â€œÄá»‘i thá»§ náº·ng ká»³ Ä‘áº§u tiÃªn cá»§a nÃ£o bá»™ con ngÆ°á»i Ä‘Ã£ Ä‘Æ°á»£c táº¡o raâ€, ráº±ng cÃ³ thá»ƒ chÃºng ta sáº¯p mÃ´ phá»ng láº¡i Ä‘Æ°á»£c bá»™ nÃ£o cá»§a con ngÆ°á»i, ráº±ng mÃ¡y tÃ­nh sáº¯p suy nghÄ©, lÃ m viá»‡c, giáº£i quyáº¿t váº¥n Ä‘á» nhÆ° con ngÆ°á»i bla bla ... Sau hÆ¡n ná»­a tháº¿ ká»· Ä‘iá»u Ä‘Ã³ váº«n chÆ°a Ä‘áº¿n, tháº¿ má»›i tháº¥y sá»± láº¡c quan cá»§a con ngÆ°á»i lÃ  vÃ´ háº¡n. May mÃ  há» chÆ°a láº¡c quan Ä‘áº¿n má»©c lo ngáº¡i vá» viá»‡c bá»‹ mÃ¡y tÃ­nh láº¥y máº¥t viá»‡c lÃ m cá»§a con ngÆ°á»i nhÆ° chÃºng ta hiá»‡n nay. Thá»i gian chá»©ng minh chÆ°Æ¡ng trÃ¬nh cá»§a Rosenblatt lÃ  chÆ°a hoÃ n háº£o, váº«n nhiá»u dá»± Ä‘oÃ¡n sai dÃ¹ traning nhiá»u láº§n nhÆ° nÃ o chÄƒng ná»¯a. Má»i thá»© láº¡i Ä‘i vÃ o báº¿ táº¯c. BÃ¡o chÃ­ láº¡i tiáº¿p tá»¥c chuyá»ƒn chá»§ Ä‘á» sang cÆ°á»›p, giáº¿t, hiáº¿p nhÆ° thÆ°á»ng lá»‡. Pháº£i Ä‘áº¿n nÄƒm 1960, khi Marvin Minsky nhÃ  khoa há»c mÃ¡y tÃ­nh Ä‘áº¿n tá»« MIT trong cuá»‘n sÃ¡ch mang tÃªn â€œPerceptronsâ€ cá»§a mÃ¬nh chá»©ng minh báº±ng toÃ¡n há»c ráº±ng 2 layer lÃ  khÃ´ng Ä‘á»§, chÃºng ta cáº§n nhiá»u hÆ¡n tháº¿. Äáº¿n nay Ä‘Ã³ váº«n Ä‘Æ°á»£c coi lÃ  má»™t cuá»‘n sÃ¡ch quan trá»ng trong lá»‹ch sá»­ AI. NhÆ°ng vá»›i trá»±c giÃ¡c thiÃªn tÃ i cá»§a mÃ¬nh, Ã´ng cÅ©ng khÃ´ng quÃªn cáº£nh bÃ¡o: â€œKhÃ´ng pháº£i cá»© cho cÃ ng nhiá»u node lÃ  ta giáº£i quyáº¿t Ä‘Æ°á»£c má»i váº¥n Ä‘á» Ä‘Ã¢u broâ€. Äáº¿n táº­n ngÃ y nay, sau 60 nÄƒm cuá»‘n sÃ¡ch ra Ä‘á»i, nhá»¯ng háº­u bá»‘i chÃºng ta váº«n hay vÆ°á»›ng pháº£i lá»—i Ä‘Ã³. Má»—i khi model neuron network cho tá»‰ lá»‡ chÃ­nh xÃ¡c tháº¥p, viá»‡c Ä‘áº§u tiÃªn chÃºng ta hay nghÄ© Ä‘áº¿n lÃ  â€œadd more node, more layerâ€ (hay lÃ  chá»‰ mÃ¬nh tÃ´i máº¯c lá»—i tÆ° duy Ä‘Ã³?) Trong suá»‘t giai Ä‘oáº¡n 1960-2000, neuron network chá»©ng kiáº¿n sá»± hÆ°ng thá»‹nh vÃ  thoÃ¡i trÃ o dáº§n dáº§n. Sá»± nhiá»‡t tÃ¬nh nÃ o rá»“i cÅ©ng lÃºc nguá»™i láº¡nh khi Ä‘Æ°á»ng Ä‘i ngÃ y má»™t tá»‘i. NgÆ°á»i kiÃªn trÃ¬ theo Ä‘uá»•i Neuron Network nháº¥t cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n má»™t vÃ i cÃ¡i tÃªn nhÆ° Yoshua Bengio, Geoff Hinton mÃ  khÃ´ng thá»ƒ khÃ´ng nháº¯c Ä‘áº¿n Yann Lecun. NgÆ°á»i Ä‘á»i nÃ³i ráº±ng â€œtÃ­ch cá»±c quay tay, váº­n may sáº½ Ä‘áº¿nâ€. TÃ´i pháº£i khÃ¢m phá»¥c sá»± kiÃªn trÃ¬ cá»§a Ã´ng trong quÃ¡ trÃ¬nh theo Ä‘uá»•i Neuron Network. ChÃºng ta pháº£i trá»Ÿ láº¡i bá»‘i cáº£nh giai Ä‘oáº¡n nÄƒm 1990-2010. LÃºc nÃ y Neuron Network Ã­t nhiá»u thoÃ¡i trÃ o, nhÆ°á»ng chá»— cho nhá»¯ng phÆ°Æ¡ng phÃ¡p Marchine Learning thá»i thÆ°á»£ng khÃ¡c. Tiá»n ngÃ¢n sÃ¡ch (funding) vá» Neuron Network thÃ¬ khÃ³ xin nhÆ° Ä‘i lÃªn trá»i, cÃ¡c Shark quan tÃ¢m nhiá»u Ä‘áº¿n cÃ¡c hÆ°á»›ng Ä‘i má»›i, Ä‘á»“ng nghiá»‡p, rá»“i nghiÃªn cá»©u sinh dÆ°á»›i quyá»n ai cÅ©ng uá»ƒ oáº£i, chÃ¡n chÆ°á»ng rá»“i lÅ© lÆ°á»£t rá»§ nhau bá» cuá»™c chÆ¡i. áº¤y váº­y mÃ  Yan Lecun váº«n khÃ´ng bá» cuá»™c, khÃ´ng gÃ¬ ngÄƒn Ä‘Æ°á»£c sá»± nhiá»‡t tÃ¬nh cá»§a tuá»•i tráº». NÄƒm nÄƒm 1990 Ã´ng cÃ¹ng Ä‘á»“ng nghiá»‡p ra Ä‘Æ°á»£c model nháº­n diá»‡n chá»¯ viáº¿t tay cÃ³ tÃªn LeNet (Ä‘áº§u vÃ o lÃ  ma tráº­n 16x16 pixcel) cho Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ cao, táº¡o Ä‘Æ°á»£c Ã­t nhiá»u tiáº¿ng vang. Nhiá»u ngÆ°á»i tháº¿ há»‡ Ä‘Ã³ láº¡i Ä‘Æ°á»£c truyá»n cáº£m há»©ng quay trá»Ÿ láº¡i vá»›i neuron network. á»¨ng dá»¥ng rÃµ nháº¥t thá»i Ä‘iá»ƒm Ä‘Ã³ lÃ  trong cÃ¡c ngÃ¢n hÃ ng Ä‘á»ƒ nháº­n diá»‡n chá»¯ viáº¿t tay. Æ¯á»›c lÆ°á»£ng cÃ³ khoáº£ng 10% giao dá»‹ch báº±ng xÃ©c (check) trÃªn Ä‘áº¥t Má»¹ Ä‘Æ°á»£c nháº­n diá»‡n qua há»‡ thá»‘ng nhÃ¢n diá»‡n tá»± Ä‘á»™ng. NhÆ°ng áº¥y lÃ  khi SVM chÆ°a ra Ä‘á»i! NÄƒm 1992, Vapnik Ä‘á»“ng nghiá»‡p cá»§a Yan Lecun (phÃ²ng thÃ­ nghiá»‡m AT&Bell), dÃ¬m Neuron Network chÃ¬m sÃ¢u vÃ o vÃ¹ng quÃªn lÃ£ng báº±ng viá»‡c táº¡o ra thuáº­t toÃ¡n SVM (Support Vector Machine) cho Ä‘á»™ chÃ­nh xÃ¡c hÆ¡n nhiá»u Neuron Network trong ráº¥t nhiá»u bÃ i Ä‘áº·c biá»‡t lÃ  nháº­n dáº¡ng chá»¯ viáº¿t, phÃ¢n loáº¡i áº£nh, NLP (xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn). NgÆ°á»i ta Äƒn SVM, ngá»§ SVM, cÃ  phÃª bÃ n luáº­n vá» SVM. Tiá»n láº¡i cÃ³ nÆ¡i Ä‘á»ƒ Ä‘á»•, bÃ¡o chÃ­ láº¡i Ä‘Æ°á»£c dá»‹p ra bÃ i lia lá»‹a. Giai Ä‘oáº¡n nÃ y nghÄ© cÅ©ng tá»™i Ã´ng Yan Lecun, váº«n ra bÃ i Ä‘á»u táº§m 5-10 bÃ i 1 nÄƒm nhÆ°ng quÃ¡ ná»•i báº­t, khÃ´ng nhiá»u ngÆ°á»i â€œlikeâ€ (cited theo ngÃ´n ngá»¯ khoa há»c), mÃ£i sau tÃªn tuá»•i ná»•i nhÆ° cá»“n thÃ¬ láº¡i thi nhau cite láº¡i cáº£ cÃ¡c bÃ i cá»•, ngÆ°á»i Ä‘á»i vá»‘n váº­y. NÄƒm 2012 diá»…n ra má»™t biáº¿n cá»‘ quan trá»ng trong lÄ©nh vá»±c AI, Ä‘áº·t ná»n mÃ³ng cho Deep Learning ngÃ y nay cÅ©ng nhÆ° Ä‘Æ°a Yan Lecun trá»Ÿ thÃ nh ngÆ°á»i mÃ  ai cÅ©ng biáº¿t. NgÆ°á»i Ä‘Ã³ng gÃ³p cho sá»± kiá»‡n nÃ y lÃ  tháº§y cá»§a Yan Lecun: Geoffrey Hinton. NhÆ°ng hÃ£y chá», nÃ³i má»™t chÃºt vá» GPU Ä‘Ã£. Má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n nháº¥t cá»§a máº¡ng neuron (neural network) lÃ  viá»‡c tÃ­nh toÃ¡n ráº¥t náº·ng, thÃªm má»™t node hay 1 layer vÃ o thÃ´i lÃ  pháº£i thÃªm cáº£ trÄƒm, cáº£ nghÃ¬n phÃ©p toÃ¡n, cá»© tháº¿ cáº¥p sá»‘ nhÃ¢n lÃªn. CPU thá»i báº¥y giá» váº«n cÃ¹i báº¯p, nhiá»u nhÃ  khoa há»c thá»i báº¥y giá» chia sáº», Ä‘á»ƒ training má»™t máº¡ng neuron cho tá»­ táº¿ cÃ³ khi máº¥t cáº£ tuáº§n, hoáº·c tháº­m chÃ­ tÃ­nh báº±ng thÃ¡ng. Loay hoay Ä‘iá»u chá»‰nh tham sá»‘, cháº¡y vÃ i turn training nhÆ° váº­y khÃ´ng khÃ©o lá»¡ toi máº¥t ká»³ bÃ¡o bÃ¡o. GPU ra Ä‘á»i ban Ä‘áº§u vá»›i má»¥c Ä‘Ã­ch dung tá»¥c hÆ¡n lÃ  phá»¥c vá»¥ cÃ¡c mÃ¡y chÆ¡i game vÃ  xá»­ lÃ½ Ä‘á»“ há»a. NhÆ°ng dáº§n dÃ  ngÆ°á»i ta phÃ¡t hiá»‡n ra cÃ¡ch tÃ­nh toÃ¡n cá»§a GPU cá»±c ká»³ phÃ¹ há»£p vá»›i viá»‡c nhÃ¢n cháº­p ma tráº­n (viá»‡c mÃ  neuron network thÆ°á»ng xuyÃªn pháº£i xá»­ lÃ½). áº¤y tháº¿ lÃ  láº¡i tÃ¬m ra Ã¡nh sÃ¡ng cuá»‘i Ä‘Æ°á»ng háº§m. Nhá» GPU, giá» Ä‘Ã¢y ta Ä‘Ã£ cÃ³ thá»ƒ training nhá»¯ng máº¡ng neuron ráº¥t lá»›n mÃ  thá»i gian chá» khÃ´ng quÃ¡ lÃ¢u. Chuyá»‡n gÃ¬ Ä‘áº¿n sáº½ Ä‘áº¿n! Tá»« nhá»¯ng nÄƒm 2010, Ä‘á»™i ngÅ© Hinton Ä‘Ã£ báº¯t Ä‘áº§u á»©ng dá»¥ng GPU vÃ o viá»‡c tÃ­nh toÃ¡n neuron network, nhá» Ä‘Ã³ cÃ³ thá»ƒ huáº¥n luyá»‡n Ä‘Æ°á»£c nhá»¯ng máº¡ng cá»¡ lá»›n. NÄƒm 2012, team Hinton Ä‘áº¡t Ä‘Æ°á»£c thÃ nh tá»±u lá»›n vá»›i viá»‡c phÃ¢n loáº¡i áº£nh trÃªn data set ImageNet. Vá»›i sá»©c máº¡nh cá»§a GPU, vÃ  táº¥t nhiÃªn cáº£ â€œmáº¡nh vÃ¬ gáº¡o, báº¡o vÃ¬ tiá»nâ€, Ã´ng cÃ¹ng Ä‘á»™i nghiÃªn cá»©u cá»§a mÃ¬nh (khÃ´ng cÃ³ Yan Lecun) tiáº¿n hÃ nh traning (huáº¥n luyá»‡n) trÃªn network gá»“m 60 triá»‡u tham sá»‘, 650.000 neuron, thá»±c hiá»‡n trÃªn training data set (dá»¯ liá»‡u huáº¥n luyá»‡n) 1.2 triá»‡u hÃ¬nh áº£nh, 1000 class (thÆ° má»¥c hÃ¬nh áº£nh), test trÃªn 150.000 hÃ¬nh áº£nh vá»›i Ä‘á»™ chÃ­nh xÃ¡c lÃªn tÆ¡i 84%, gÃ¢y xá»‘c náº·ng giá»›i computer science lÃºc báº¥y giá» (75% Ä‘Ã£ lÃ  cao háº¿t táº§m rá»“i). Má»™t Ä‘iá»u tÃ´i ráº¥t ná»ƒ Geoffrey Hinton á»Ÿ chá»—, Ã´ng khÃ´ng quÃªn cite bÃ i cá»§a há»c trÃ² cá»§a mÃ¬nh nÄƒm 1990 vá» nháº­n dáº¡ng chá»¯ viáº¿t tay, nÃ³i ráº±ng cÃ´ng trÃ¬nh cá»§a Ã´ng káº¿ thá»«a nhiá»u tá»« bÃ i bÃ¡o Ä‘Ã³. Yan Lecun lÃªn hÆ°Æ¡ng, Geoffrey Hinton cÅ©ng hÆ°á»Ÿng Ä‘á»§ (thÃ nh láº­p cÃ´ng ty riÃªng vá» AI). NgÆ°á»i quen hÆ¡n nhau lÃ  á»Ÿ chá»— Ä‘Ã³. Tá»« nhá»¯ng cÃ´ng trÃ¬nh cá»§a Geoffrey Hinton, hÃ ng loáº¡t net má»›i ra Ä‘á»i, vá»›i nhiá»u tham sá»‘ hÆ¡n, nhiá»u layer hÆ¡n, data set khá»§ng hÆ¡n, ká»· lá»¥c liÃªn tá»¥c bá»‹ xÃ´ Ä‘á»•. Deep Learning dáº§n trá»Ÿ thÃ nh cuá»™c chÆ¡i cá»§a nhá»¯ng Ä‘á»™i láº¯m tiá»n, láº¯m gáº¡o. Nhá»¯ng diá»…n biáº¿n gáº§n Ä‘Ã¢y cháº¯c ai cÅ©ng cáº­p nháº­t rá»“i nÃªn tÃ´i ko nháº¯c láº¡i ná»¯a. Google cÅ©ng khÃ´ng náº±m ngoÃ i trending nÃ y, DeepMind Ä‘Æ°á»£c google mua láº¡i vá»›i giÃ¡ 500 triá»‡u Ä‘Ã´ trump nÄƒm 2014. Tá»« Ä‘Ã¢y AlphaStar, AlphaGo, AlphaFold Ä‘Æ°á»£c ra Ä‘á»i vÃ  ná»•i tiáº¿ng toÃ n tháº¿ giá»›i. Chá»‰ thÃ¡ng trÆ°á»›c thÃ´i, AlphaFold Ä‘Ã£ dá»± Ä‘oÃ¡n ráº¥t chÃ­nh xÃ¡c cáº¥u trÃºc cuá»™n 3D cá»§a protein, viáº¿t nÃªn lá»‹ch sá»­ ngÃ nh sinh há»c phÃ¢n tá»­. Má»™t con Ä‘Æ°á»ng dÃ i cÃ²n á»Ÿ phÃ­a trÆ°á»›c, phong trÃ o nghiÃªn cá»©u Deep Learning Ä‘ang ná»•i lÃªn ráº¥t máº¡nh trÃªn toÃ n tháº¿ giá»›i, trong Ä‘Ã³ ngÆ°á»i tráº» Viá»‡t Nam cÅ©ng tham gia ráº¥t tÃ­ch cá»±c. Æ  mÃ¢y zing, gÃºt chÃ³p my friends. ChÃ©m giÃ³ cho vui tháº¿ thÃ´i, giá» pháº£i Ä‘i thay bá»‰m cho con Ä‘Ã£. Háº¹n gáº·p má»i ngÆ°á»i gáº§n Ä‘Ã¢y nháº¥t. Edit: Sau comment cá»§a báº¡n Phong Thanh DÆ°Æ¡ng, mÃ¬nh xin sá»­a láº¡i thá»i Ä‘iá»ƒm team Hinton lÃ m báº¯t Ä‘áº§u á»©ng dá»¥ng GPU traning tá»« giai Ä‘oáº¡n 2010, ra bÃ¡o cÃ¡o (paper) ná»•i danh vÃ o nÄƒm 2012. Xin lá»—i cÃ¡c báº¡n vÃ¬ sai má»‘c thá»i gian. DÆ°Æ¡ng Thá»‹nh Nguá»“n tham kháº£o: https://en.wikipedia.org/wiki/David_H._Hubel https://en.wikipedia.org/wiki/Frank_Rosenblatt https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon https://en.wikipedia.org/wiki/Yann_LeCun https://en.wikipedia.org/wiki/Geoffrey_Hinton Handwritten digit recognition with a back-propagation network. In Advances in Neural Information Processing Systems (1990) https://en.wikipedia.org/wiki/Support_vector_machine https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf https://www.theguardian.com/technology/2020/nov/30/deepmind-ai-cracks-50-year-old-problem-of-biology-research",,,,,
"HÆ¯á»šNG DáºªN Láº¬P TRÃŒNH IRON MAN FRIDAY ÄIá»€U KHIá»‚N MÃY TÃNH Báº°NG GIá»ŒNG NÃ“I Vá»šI PYTHON
Hello má»i ngÆ°á»i,
NhÃ³m mÃ¬nh cÃ³ cÃ¡i clip chia sáº» cÃ¡ch lÃ m trá»£ lÃ½ áº£o Friday giá»‘ng cá»§a Iron Man trÃªn PC.Vá»›i Friday chá»‰ cáº§n ra lá»‡nh báº±ng giá»ng nÃ³i má»i ngÆ°á»i cÃ³ thá»ƒ:
Tá»± Ä‘á»™ng má»Ÿ nháº¡c hoáº·c xem phim
TÃ¬m kiáº¿m trÃªn Google vÃ  Youtube
Xem thá»i gian
Hi vá»ng clip sáº½ giÃºp Ã­ch Ä‘Æ°á»£c nhiá»u cho cÃ¡c báº¡n Ä‘am mÃª láº­p trÃ¬nh.","HÆ¯á»šNG DáºªN Láº¬P TRÃŒNH IRON MAN FRIDAY ÄIá»€U KHIá»‚N MÃY TÃNH Báº°NG GIá»ŒNG NÃ“I Vá»šI PYTHON Hello má»i ngÆ°á»i, NhÃ³m mÃ¬nh cÃ³ cÃ¡i clip chia sáº» cÃ¡ch lÃ m trá»£ lÃ½ áº£o Friday giá»‘ng cá»§a Iron Man trÃªn PC.Vá»›i Friday chá»‰ cáº§n ra lá»‡nh báº±ng giá»ng nÃ³i má»i ngÆ°á»i cÃ³ thá»ƒ: Tá»± Ä‘á»™ng má»Ÿ nháº¡c hoáº·c xem phim TÃ¬m kiáº¿m trÃªn Google vÃ  Youtube Xem thá»i gian Hi vá»ng clip sáº½ giÃºp Ã­ch Ä‘Æ°á»£c nhiá»u cho cÃ¡c báº¡n Ä‘am mÃª láº­p trÃ¬nh.",,,,,
Má»i ngÆ°á»i cho mÃ¬nh há»i náº¿u muá»‘n process image 10k áº£nh trá»Ÿ lÃªn vá»›i opencv trÃªn colab thÃ¬ pháº£i lÃ m ntn áº¡ vÃ¬ nÃ³ cá»© bÃ¡o bá»‹ trÃ n ram. Em cÃ³ thá»­ lÃ m chá»‰ vá»›i 5k áº£nh nhÆ°ng Ä‘áº¿n khi convert sang numpy thÃ¬ nÃ³ bá»‹ nhÆ° váº­y tiáº¿p. CÃ³ cÃ¡ch nÃ o xá»­ lÃ½ k áº¡ mÃ¬nh cáº£m Æ¡n,Má»i ngÆ°á»i cho mÃ¬nh há»i náº¿u muá»‘n process image 10k áº£nh trá»Ÿ lÃªn vá»›i opencv trÃªn colab thÃ¬ pháº£i lÃ m ntn áº¡ vÃ¬ nÃ³ cá»© bÃ¡o bá»‹ trÃ n ram. Em cÃ³ thá»­ lÃ m chá»‰ vá»›i 5k áº£nh nhÆ°ng Ä‘áº¿n khi convert sang numpy thÃ¬ nÃ³ bá»‹ nhÆ° váº­y tiáº¿p. CÃ³ cÃ¡ch nÃ o xá»­ lÃ½ k áº¡ mÃ¬nh cáº£m Æ¡n,,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m bÃ i táº­p lá»›n vá» NLP sá»­ dá»¥ng framework LSTM cá»§a Keras Ä‘á»ƒ train model, sau Ä‘Ã³ em sá»­ dá»¥ng save Ä‘á»ƒ lÆ°u model vÃ  dÃ¹ng load_model Ä‘á»ƒ gá»i mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n. Káº¿t quáº£ dá»± Ä‘oÃ¡n trÆ°á»›c khi lÆ°u model vá»›i sau khi lÆ°u model khÃ¡c nhau hoÃ n toÃ n áº¡. Má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng gáº·p trÆ°á»ng há»£p nÃ y cÃ³ thá»ƒ vá»›i giÃºp em vá»›i áº¡, em cÃ¡m Æ¡n nhiá»u áº¡","ChÃ o má»i ngÆ°á»i, em Ä‘ang lÃ m bÃ i táº­p lá»›n vá» NLP sá»­ dá»¥ng framework LSTM cá»§a Keras Ä‘á»ƒ train model, sau Ä‘Ã³ em sá»­ dá»¥ng save Ä‘á»ƒ lÆ°u model vÃ  dÃ¹ng load_model Ä‘á»ƒ gá»i mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n. Káº¿t quáº£ dá»± Ä‘oÃ¡n trÆ°á»›c khi lÆ°u model vá»›i sau khi lÆ°u model khÃ¡c nhau hoÃ n toÃ n áº¡. Má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng gáº·p trÆ°á»ng há»£p nÃ y cÃ³ thá»ƒ vá»›i giÃºp em vá»›i áº¡, em cÃ¡m Æ¡n nhiá»u áº¡",,,,,
"chÃ o má»i ngÆ°á»Ÿi, em Ä‘ang sá»­ dá»¥ng yolov4 thÃ¬ gáº·p lá»—i tÆ°Æ¡ng tá»± nhÆ° nÃ y. má»i ngÆ°á»Ÿi cÃ³ ai cÃ³ cÃ¡ch fix khÃ´ng áº¡. 
link bÃ i viáº¿t :object detection - YOLO cannot display the class name on prediction picture - Stack Overflow","chÃ o má»i ngÆ°á»Ÿi, em Ä‘ang sá»­ dá»¥ng yolov4 thÃ¬ gáº·p lá»—i tÆ°Æ¡ng tá»± nhÆ° nÃ y. má»i ngÆ°á»Ÿi cÃ³ ai cÃ³ cÃ¡ch fix khÃ´ng áº¡. link bÃ i viáº¿t :object detection - YOLO cannot display the class name on prediction picture - Stack Overflow",,,,,
"Má»i ngÆ°á»i Ä‘Ã£ ai lÃ m vá» thuáº­t toÃ¡n word beam search trÃªn linux mÃ  khi load thÆ° viá»‡n TFWordBeamSearch.so bá»‹ lá»—i ntn chÆ°a áº¡ !
Em gáº·p lá»—i nÃ y mÃ  chÆ°a biáº¿t cÃ¡ch fix tháº¿ nÃ o ! Em cáº£m Æ¡n !
tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so: cannot open shared object file: No such file or directory",Má»i ngÆ°á»i Ä‘Ã£ ai lÃ m vá» thuáº­t toÃ¡n word beam search trÃªn linux mÃ  khi load thÆ° viá»‡n TFWordBeamSearch.so bá»‹ lá»—i ntn chÆ°a áº¡ ! Em gáº·p lá»—i nÃ y mÃ  chÆ°a biáº¿t cÃ¡ch fix tháº¿ nÃ o ! Em cáº£m Æ¡n ! tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so: cannot open shared object file: No such file or directory,,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang phÃ¡t triá»ƒn má»™t sá»‘ á»©ng dá»¥ng Desktop sá»­ dá»¥ng python, em muá»‘n há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº£o vá»‡ á»©ng dá»¥ng cá»§a mÃ¬nh trÃ¡nh bá»‹ dá»‹ch ngÆ°á»£c khÃ´ng áº¡. Em Ä‘Ã£ cÃ³ google xem nhiá»u phÆ°Æ¡ng phÃ¡p trÆ°á»›c rá»“i, em viáº¿t bÃ i nÃ y Ä‘á»ƒ mong nháº­n Ä‘Æ°á»£c nhiá»u sá»± gÃ³p Ã½ cá»§a cÃ¡c anh chá»‹ trong nhÃ³m. Cáº£m Æ¡n Admin Ä‘Ã£ cho em Ä‘Äƒng bÃ i áº¡, chÃºc má»i ngÆ°á»i má»™t ngÃ y tá»‘t lÃ nh.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang phÃ¡t triá»ƒn má»™t sá»‘ á»©ng dá»¥ng Desktop sá»­ dá»¥ng python, em muá»‘n há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº£o vá»‡ á»©ng dá»¥ng cá»§a mÃ¬nh trÃ¡nh bá»‹ dá»‹ch ngÆ°á»£c khÃ´ng áº¡. Em Ä‘Ã£ cÃ³ google xem nhiá»u phÆ°Æ¡ng phÃ¡p trÆ°á»›c rá»“i, em viáº¿t bÃ i nÃ y Ä‘á»ƒ mong nháº­n Ä‘Æ°á»£c nhiá»u sá»± gÃ³p Ã½ cá»§a cÃ¡c anh chá»‹ trong nhÃ³m. Cáº£m Æ¡n Admin Ä‘Ã£ cho em Ä‘Äƒng bÃ i áº¡, chÃºc má»i ngÆ°á»i má»™t ngÃ y tá»‘t lÃ nh.",,,,,
ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang cÃ³ Ä‘á» tÃ i lÃ m chatbot báº±ng Rasa. VÃ  Ä‘Æ°á»£c yÃªu cáº§u tÃ­ch há»£n spaCy hoáº·c underthesea Ä‘á»ƒ phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh Ä‘áº§u vÃ o cá»§a ngÆ°á»i dÃ¹ng. NhÆ°ng hiá»‡n táº¡i trÃªn spaCy thÃ¬ khÃ´ng cÃ³ model sáºµn cá»§a tiáº¿ng Viá»‡t cÃ²n underthesea thÃ¬ khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i Rasa 2.1(náº¿u dowgrade Rasa xuá»‘ng 2.0 thÃ¬ ko test Ä‘c trÃªn Rasa X). Má»i ngÆ°á»i ai tá»«ng lÃ m bÃ i toÃ¡n ntn cÃ³ thá»ƒ há»— trá»£ em Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.,ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em Ä‘ang cÃ³ Ä‘á» tÃ i lÃ m chatbot báº±ng Rasa. VÃ  Ä‘Æ°á»£c yÃªu cáº§u tÃ­ch há»£n spaCy hoáº·c underthesea Ä‘á»ƒ phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh Ä‘áº§u vÃ o cá»§a ngÆ°á»i dÃ¹ng. NhÆ°ng hiá»‡n táº¡i trÃªn spaCy thÃ¬ khÃ´ng cÃ³ model sáºµn cá»§a tiáº¿ng Viá»‡t cÃ²n underthesea thÃ¬ khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i Rasa 2.1(náº¿u dowgrade Rasa xuá»‘ng 2.0 thÃ¬ ko test Ä‘c trÃªn Rasa X). Má»i ngÆ°á»i ai tá»«ng lÃ m bÃ i toÃ¡n ntn cÃ³ thá»ƒ há»— trá»£ em Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.,,,,,
"SPEECH RECOGNITION SERIES - JONATHAN HUI
Jonathan Hui - Má»™t trong nhá»¯ng tÃ¡c giáº£ ná»•i báº­t vÃ  viáº¿t cÃ³ tÃ¢m nháº¥t trÃªn medium. CÃ¡c bÃ i viáº¿t cá»§a Ã´ng viáº¿t ráº¥t dá»… hiá»ƒu, kiáº¿n thá»©c tá»« ná»n táº£ng tá»›i chi tiáº¿t vá»›i nhá»¯ng phÃ¢n tÃ­ch rÃµ rÃ ng vÃ  trá»±c quan. ÄÃ¢y lÃ  1 trong nhá»¯ng nguá»“n tÃ i liá»‡u ráº¥t quÃ½.  DÆ°á»›i Ä‘Ã¢y lÃ  1 series cá»§a Ã´ng mÃ  mÃ¬nh muá»‘n giá»›i thiá»‡u tá»›i cÃ¡c báº¡n má»›i trong lÄ©nh vá»±c xá»­ lÃ­ tiáº¿ng nÃ³i - Speech recognition series.
https://jonathan-hui.medium.com/speech-recognition-series-71fd6784551a","SPEECH RECOGNITION SERIES - JONATHAN HUI Jonathan Hui - Má»™t trong nhá»¯ng tÃ¡c giáº£ ná»•i báº­t vÃ  viáº¿t cÃ³ tÃ¢m nháº¥t trÃªn medium. CÃ¡c bÃ i viáº¿t cá»§a Ã´ng viáº¿t ráº¥t dá»… hiá»ƒu, kiáº¿n thá»©c tá»« ná»n táº£ng tá»›i chi tiáº¿t vá»›i nhá»¯ng phÃ¢n tÃ­ch rÃµ rÃ ng vÃ  trá»±c quan. ÄÃ¢y lÃ  1 trong nhá»¯ng nguá»“n tÃ i liá»‡u ráº¥t quÃ½. DÆ°á»›i Ä‘Ã¢y lÃ  1 series cá»§a Ã´ng mÃ  mÃ¬nh muá»‘n giá»›i thiá»‡u tá»›i cÃ¡c báº¡n má»›i trong lÄ©nh vá»±c xá»­ lÃ­ tiáº¿ng nÃ³i - Speech recognition series. https://jonathan-hui.medium.com/speech-recognition-series-71fd6784551a",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, dáº¡o nÃ y trÃªn Group cÃ³ nhiá»u báº¡n há»i vá» train Colab. CÃ³ báº¡n hiá»ƒu sai cÃ¡ch dÃ¹ng Colab vÃ  mang code lÃªn cháº¡y trÃªn colab Ä‘á»ƒ váº½ vÃ  hiá»ƒn thá»‹ áº£nh thay vÃ¬ dÃ¹ng nÃ³ Ä‘á»ƒ train model.
Do váº­y em lÃ m clip nÃ y mong giÃºp Ä‘Æ°á»£c anh em newbie. Clip siÃªu chi tiáº¿t dÃ i gáº§n 1 tiáº¿ng ah!
Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c, dáº¡o nÃ y trÃªn Group cÃ³ nhiá»u báº¡n há»i vá» train Colab. CÃ³ báº¡n hiá»ƒu sai cÃ¡ch dÃ¹ng Colab vÃ  mang code lÃªn cháº¡y trÃªn colab Ä‘á»ƒ váº½ vÃ  hiá»ƒn thá»‹ áº£nh thay vÃ¬ dÃ¹ng nÃ³ Ä‘á»ƒ train model. Do váº­y em lÃ m clip nÃ y mong giÃºp Ä‘Æ°á»£c anh em newbie. Clip siÃªu chi tiáº¿t dÃ i gáº§n 1 tiáº¿ng ah! Mong ad duyá»‡t bÃ i!",,,,,
"[ PhÃ¢n cá»¥m dá»¯ liá»‡u HDBSCAN]
[Giáº£m chiá»u dá»¯ liá»‡u UMAP]
Hi cá»™ng Ä‘á»“ng, má»i ngÆ°á»i cÃ³ ai tá»«ng lÃ m vá» HDBSCAN vÃ  UMAP chÆ°a áº¡ ? KhÃ´ng biáº¿t cÃ³ thá»ƒ chia sáº½ má»™t Ã­t cÃ¡ch Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ 2 thuáº­t toÃ¡n Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i !!!","[ PhÃ¢n cá»¥m dá»¯ liá»‡u HDBSCAN] [Giáº£m chiá»u dá»¯ liá»‡u UMAP] Hi cá»™ng Ä‘á»“ng, má»i ngÆ°á»i cÃ³ ai tá»«ng lÃ m vá» HDBSCAN vÃ  UMAP chÆ°a áº¡ ? KhÃ´ng biáº¿t cÃ³ thá»ƒ chia sáº½ má»™t Ã­t cÃ¡ch Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ 2 thuáº­t toÃ¡n Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i !!!",,,,,
"Xin chia sáº» cÃ¡c báº¡n tá»•ng há»£p nhá»¯ng kinh nghiá»‡m thá»±c táº¿ vá» phá»ng váº¥n ML engineer va Data scientist. Hy vá»ng há»¯u Ã­ch vÃ  giÃºp cÃ¡c báº¡n luyá»‡n hiá»‡u quáº£ hÆ¡n.
https://rebrand.ly/MLInterview",Xin chia sáº» cÃ¡c báº¡n tá»•ng há»£p nhá»¯ng kinh nghiá»‡m thá»±c táº¿ vá» phá»ng váº¥n ML engineer va Data scientist. Hy vá»ng há»¯u Ã­ch vÃ  giÃºp cÃ¡c báº¡n luyá»‡n hiá»‡u quáº£ hÆ¡n. https://rebrand.ly/MLInterview,,,,,
"Xin Ä‘Æ°á»£c giá»›i thiá»‡u vá»›i má»i ngÆ°á»i dá»± Ã¡n ALBERT for Vietnamese do 1 báº¡n tráº» tÃ i nÄƒng(Ngoan Pháº¡m) thá»±c hiá»‡n. Äáº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i Ä‘Ã¢y lÃ  ngÃ´n ngá»¯ thá»© 3 sau English/Chinese cÃ³ hiá»‡n thá»±c 1 trong nhá»¯ng state of the arts cá»§a NLP inn 2019. Má»i má»i ngÆ°á»i contribute/use/build applications Ä‘á»ƒ cá»™ng Ä‘á»“ng phÃ¡t triá»ƒn hÆ¡n ná»¯a.
Chia sáº» thÃªm lÃ  Ngoan cÅ©ng lÃ  ngÆ°á»i tháº¯ng giáº£i Zalo AI Chanllenge 2019 cho bÃ i Vietnamese Wikipedia Question Answering. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm solution cá»§a báº¡n áº¥y táº¡i git repo.
ALBERT < 3
https://github.com/ngoanpv/albert_vi",Xin Ä‘Æ°á»£c giá»›i thiá»‡u vá»›i má»i ngÆ°á»i dá»± Ã¡n ALBERT for Vietnamese do 1 báº¡n tráº» tÃ i nÄƒng(Ngoan Pháº¡m) thá»±c hiá»‡n. Äáº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i Ä‘Ã¢y lÃ  ngÃ´n ngá»¯ thá»© 3 sau English/Chinese cÃ³ hiá»‡n thá»±c 1 trong nhá»¯ng state of the arts cá»§a NLP inn 2019. Má»i má»i ngÆ°á»i contribute/use/build applications Ä‘á»ƒ cá»™ng Ä‘á»“ng phÃ¡t triá»ƒn hÆ¡n ná»¯a. Chia sáº» thÃªm lÃ  Ngoan cÅ©ng lÃ  ngÆ°á»i tháº¯ng giáº£i Zalo AI Chanllenge 2019 cho bÃ i Vietnamese Wikipedia Question Answering. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm solution cá»§a báº¡n áº¥y táº¡i git repo. ALBERT < 3 https://github.com/ngoanpv/albert_vi,,,,,
"Má»i tham gia challenge mobile-captured receipt recognition (MC-OCR). ChÃ o cáº£ nhÃ , nhá» dá»¯ liá»‡u hoÃ¡ Ä‘Æ¡n mÃ  ACE diá»…n Ä‘Ã n cung cáº¥p, cÃ¹ng vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c tÃ i trá»£. MC-OCR Ä‘Ã£ cÃ³ thá»ƒ chÃ­nh thá»©c diá»…n ra cÃ¹ng vá»›i RIVF2021. Má»i ACE quan tÃ¢m tá»›i bÃ n toÃ¡n nháº­n dáº¡ng OCR cho hoÃ¡ Ä‘Æ¡n Ä‘Äƒng kÃ½ tham gia á»Ÿ Ä‘Ã¢y [1]. Call 4 participants [2]. Ngay trong ngÃ y mai lÃ  Ä‘Ã£ cÃ³ dá»¯ liá»‡u warm-up rá»“i nhÃ© cáº£ nhÃ .
[1] https://rivf2021-mc-ocr.vietnlp.com/home
[2] https://drive.google.com/file/d/14bLt1HE38Gtpv7-YLYRjsf9pbWtV_v0a/view?usp=sharing
 â€” vá»›i Tiep VuHuu.","Má»i tham gia challenge mobile-captured receipt recognition (MC-OCR). ChÃ o cáº£ nhÃ , nhá» dá»¯ liá»‡u hoÃ¡ Ä‘Æ¡n mÃ  ACE diá»…n Ä‘Ã n cung cáº¥p, cÃ¹ng vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c tÃ i trá»£. MC-OCR Ä‘Ã£ cÃ³ thá»ƒ chÃ­nh thá»©c diá»…n ra cÃ¹ng vá»›i RIVF2021. Má»i ACE quan tÃ¢m tá»›i bÃ n toÃ¡n nháº­n dáº¡ng OCR cho hoÃ¡ Ä‘Æ¡n Ä‘Äƒng kÃ½ tham gia á»Ÿ Ä‘Ã¢y [1]. Call 4 participants [2]. Ngay trong ngÃ y mai lÃ  Ä‘Ã£ cÃ³ dá»¯ liá»‡u warm-up rá»“i nhÃ© cáº£ nhÃ . [1] https://rivf2021-mc-ocr.vietnlp.com/home [2] https://drive.google.com/file/d/14bLt1HE38Gtpv7-YLYRjsf9pbWtV_v0a/view?usp=sharing â€” vá»›i Tiep VuHuu.",,,,,
"ChÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i Ä‘ang gáº·p váº¥n Ä‘á» vá»›i tensorflow.js em Ä‘Ã£ gg nhÆ°ng káº¿t quáº£ khÃ´ng kháº£ quan, Hy vá»ng anh chá»‹, hoáº·c báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» tfjs giÃºp em vá»›i áº¡.
Em Ä‘ang dÃ¹ng deeplab Ä‘á»ƒ segmentation áº£nh, Ä‘oáº¡n code dÆ°á»›i lÃ  em láº¥y áº£nh, processing vÃ  predict nhÆ°ng nÃ³ bá»‹ lá»—i khi predict áº¡. Em Ä‘Ã£ thá»­ nhiá»u cÃ¡ch nhÆ°ng khÃ´ng thá»ƒ sá»­a, mong má»i ngÆ°á»i cho em lá»i khuyÃªn, cáº£m Æ¡n áº¡
DÆ°á»›i Ä‘Ã¢y lÃ  toÃ n bá»™ Ä‘oáº¡n code cá»§a em áº¡ :
https://drive.google.com/file/d/1an0l73LbzPnti3RLnVYaf1ATKQmhazN5/view?usp=sharing
Edit: em lÃ m theo git nÃ y áº¡
https://github.com/tensorflow/tfjs-models/tree/master/deeplab","ChÃ o má»i ngÆ°á»i, em hiá»‡n táº¡i Ä‘ang gáº·p váº¥n Ä‘á» vá»›i tensorflow.js em Ä‘Ã£ gg nhÆ°ng káº¿t quáº£ khÃ´ng kháº£ quan, Hy vá»ng anh chá»‹, hoáº·c báº¡n nÃ o cÃ³ kinh nghiá»‡m vá» tfjs giÃºp em vá»›i áº¡. Em Ä‘ang dÃ¹ng deeplab Ä‘á»ƒ segmentation áº£nh, Ä‘oáº¡n code dÆ°á»›i lÃ  em láº¥y áº£nh, processing vÃ  predict nhÆ°ng nÃ³ bá»‹ lá»—i khi predict áº¡. Em Ä‘Ã£ thá»­ nhiá»u cÃ¡ch nhÆ°ng khÃ´ng thá»ƒ sá»­a, mong má»i ngÆ°á»i cho em lá»i khuyÃªn, cáº£m Æ¡n áº¡ DÆ°á»›i Ä‘Ã¢y lÃ  toÃ n bá»™ Ä‘oáº¡n code cá»§a em áº¡ : https://drive.google.com/file/d/1an0l73LbzPnti3RLnVYaf1ATKQmhazN5/view?usp=sharing Edit: em lÃ m theo git nÃ y áº¡ https://github.com/tensorflow/tfjs-models/tree/master/deeplab",,,,,
"#AVATECH #ShareData
CÃ³ khi nÃ o báº¡n cáº£m tháº¥y viá»‡c lÆ°á»£n má»™t vÃ²ng siÃªu thá»‹ rá»“i nhanh tay lÆ°á»£m, lÆ°á»£m hÃ ng tÃ¡ Ä‘á»“ dÃ¹ng, cÃ¡c thá»© Ä‘áº§y giá» thá»±c sá»± lÃ  má»™t Ä‘am mÃª nhÆ°ng nghÄ© Ä‘áº¿n cáº£nh sáº½ pháº£i xáº¿p hÃ ng dÃ i chá» tá»›i lÆ°á»£t mÃ¬nh thanh toÃ¡n thÃ¬ Ã´i thÃ´i, tháº­t ngÃ¡n ngáº©m!
ThÃ´ng thÆ°á»ng táº¡i cÃ¡c há»‡ thá»‘ng siÃªu thá»‹ lá»›n sáº½ cÃ³ khoáº£ng gáº§n chá»¥c cá»­a thanh toÃ¡n kÃ¨m nhÃ¢n viÃªn thu ngÃ¢n nhÆ°ng cÃ³ váº» so vá»›i sá»‘ lÆ°á»£ng sáº£n pháº©m vÃ  lÆ°á»£ng ngÆ°á»i tiÃªu dÃ¹ng lá»›n nhÆ° váº­y thÃ¬ viá»‡c check mÃ£ tá»«ng sáº£n pháº©m khÃ´ng cÃ²n tá»‘i Æ°u ná»¯a. AVA Ä‘Ã£ thá»­ nghiá»‡m há»‡ thá»‘ng tÃ­nh tiá»n tá»± Ä‘á»™ng sá»­ dá»¥ng cÃ´ng nghá»‡ Deep Learning cho phÃ©p thanh toÃ¡n nhiá»u sáº£n pháº©m cÃ¹ng lÃºc.
CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u áº£nh dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng cho riÃªng mÃ¬nh nhÃ©.
Link download dá»¯ liá»‡u: http://avatech.com.vn/phan-loai-san-pham/he-thong-tinh-tien-tu-dong-su-dung-cong-nghe-deep-learning","CÃ³ khi nÃ o báº¡n cáº£m tháº¥y viá»‡c lÆ°á»£n má»™t vÃ²ng siÃªu thá»‹ rá»“i nhanh tay lÆ°á»£m, lÆ°á»£m hÃ ng tÃ¡ Ä‘á»“ dÃ¹ng, cÃ¡c thá»© Ä‘áº§y giá» thá»±c sá»± lÃ  má»™t Ä‘am mÃª nhÆ°ng nghÄ© Ä‘áº¿n cáº£nh sáº½ pháº£i xáº¿p hÃ ng dÃ i chá» tá»›i lÆ°á»£t mÃ¬nh thanh toÃ¡n thÃ¬ Ã´i thÃ´i, tháº­t ngÃ¡n ngáº©m! ThÃ´ng thÆ°á»ng táº¡i cÃ¡c há»‡ thá»‘ng siÃªu thá»‹ lá»›n sáº½ cÃ³ khoáº£ng gáº§n chá»¥c cá»­a thanh toÃ¡n kÃ¨m nhÃ¢n viÃªn thu ngÃ¢n nhÆ°ng cÃ³ váº» so vá»›i sá»‘ lÆ°á»£ng sáº£n pháº©m vÃ  lÆ°á»£ng ngÆ°á»i tiÃªu dÃ¹ng lá»›n nhÆ° váº­y thÃ¬ viá»‡c check mÃ£ tá»«ng sáº£n pháº©m khÃ´ng cÃ²n tá»‘i Æ°u ná»¯a. AVA Ä‘Ã£ thá»­ nghiá»‡m há»‡ thá»‘ng tÃ­nh tiá»n tá»± Ä‘á»™ng sá»­ dá»¥ng cÃ´ng nghá»‡ Deep Learning cho phÃ©p thanh toÃ¡n nhiá»u sáº£n pháº©m cÃ¹ng lÃºc. CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u áº£nh dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng cho riÃªng mÃ¬nh nhÃ©. Link download dá»¯ liá»‡u: http://avatech.com.vn/phan-loai-san-pham/he-thong-tinh-tien-tu-dong-su-dung-cong-nghe-deep-learning",#AVATECH	#ShareData,,,,
"ChÃºc má»«ng nÄƒm má»›i 2020.
CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 1 vÃ o comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n nÄƒm má»›i nhiá»u thÃ nh cÃ´ng má»›i.","ChÃºc má»«ng nÄƒm má»›i 2020. CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n thÃ¡ng 1 vÃ o comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n nÄƒm má»›i nhiá»u thÃ nh cÃ´ng má»›i.",,,,,
"SÃ¡ch má»›i free cá»§a John Wright vÃ  Yi Ma, hai tÃªn tuá»•i lá»›n trong lÄ©nh vá»±c sparse coding, vá» ""High-Dimensional Data Analysis with Low-Dimensional Models"":","SÃ¡ch má»›i free cá»§a John Wright vÃ  Yi Ma, hai tÃªn tuá»•i lá»›n trong lÄ©nh vá»±c sparse coding, vá» ""High-Dimensional Data Analysis with Low-Dimensional Models"":",,,,,
"Advanced IT paves the way for online learning which is advantageous to anyone who want to expand their knowledge or even switch to a new area. So, I'd like to share with you my online courses for Data Science program from Coursera that I have been taking for the last 2 years.","Advanced IT paves the way for online learning which is advantageous to anyone who want to expand their knowledge or even switch to a new area. So, I'd like to share with you my online courses for Data Science program from Coursera that I have been taking for the last 2 years.",,,,,
"TÃ€I LIá»†U Tá»° Há»ŒC DEEP LEARNING NLP CHO Má»ŒI NGÆ¯á»œI
Hiá»‡n nay, sá»‘ lÆ°á»£ng báº¡n cÃ³ nhu cáº§u há»c NLP Ä‘ang tÄƒng cao, bao gá»“m cÃ¡c báº¡n Advanced vÃ  má»›i báº¯t Ä‘áº§u. Tuy nhiÃªn, tÃ i liá»‡u Ä‘a sá»‘ tá»« nÆ°á»›c ngoÃ i vÃ  chÆ°a cÃ³ thÆ° viá»‡n táº­p há»£p, hoáº·c cÃ³ thÃ¬ cÅ©ng ráº£i rÃ¡c vÃ  khÃ³ cho cÃ¡c báº¡n má»›i vÃ  tá»± há»c.
ÄÃ³ lÃ  lÃ½ do VietAI kÃªu gá»i & káº¿t ná»‘i cÃ¡c báº¡n trong cá»™ng Ä‘á»“ng AI/ML/DL Ä‘á»ƒ Ä‘Ã³ng gÃ³p vÃ o ThÆ° viá»‡n Tá»± há»c NLP:
ğŸ“ŒNhá»¯ng báº¡n Chia sáº»: chia sáº» nguá»“n há»c/tÃ i liá»‡u NLP/paper tá»« má»i nÆ¡i trÃªn tháº¿ giá»›i
ğŸ“Œ Nhá»¯ng báº¡n Ä‘Æ°á»£c chia sáº»: xem, tá»± há»c, tÃ¬m hiá»ƒu & chá»§ Ä‘á»™ng chia sáº» thÃªm
Táº¥t cáº£ cÃ¡c báº¡n chia sáº» sáº½ nháº­n CREDIT trá»±c tiáº¿p trÃªn file vÃ  tÃ¹y thuá»™c vÃ o má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p, VietAI sáº½ há»— trá»£ Ä‘á»ƒ cÃ¹ng báº¡n tá»• chá»©c nhiá»u hoáº¡t Ä‘á»™ng chia sáº» bá»• Ã­ch.
ThÆ° viá»‡n Ä‘Ã£ cÃ³ má»¥c lá»¥c cÃ³ sáºµn. Má»i ngÆ°á»i chá»‰ cáº§n chia sáº» (paste link) vÃ o. Náº¿u cÃ¡c báº¡n cÃ³ Ä‘Ã³ng gÃ³p vá» cÃ¡ch thá»©c xÃ¢y dá»±ng má»¥c lá»¥c cá»§a ThÆ° viá»‡n cÃ³ thá»ƒ comment phÃ­a dÆ°á»›i hoáº·c inbox An. File sáº½ Ä‘Æ°á»£c monitor thÆ°á»ng xuyÃªn Ä‘á»ƒ Ä‘áº£m báº£o rÃµ rÃ ng vÃ  credit Ä‘á»§ cho táº¥t cáº£ anh/chá»‹ Ä‘Ã³ng gÃ³p.
About us: VietAI is a non-profit organization. Our mission is to build a community of world-Â­class AI talents in Vietnam to solve meaningful and impactful problems for not just Vietnam but also the world.","TÃ€I LIá»†U Tá»° Há»ŒC DEEP LEARNING NLP CHO Má»ŒI NGÆ¯á»œI Hiá»‡n nay, sá»‘ lÆ°á»£ng báº¡n cÃ³ nhu cáº§u há»c NLP Ä‘ang tÄƒng cao, bao gá»“m cÃ¡c báº¡n Advanced vÃ  má»›i báº¯t Ä‘áº§u. Tuy nhiÃªn, tÃ i liá»‡u Ä‘a sá»‘ tá»« nÆ°á»›c ngoÃ i vÃ  chÆ°a cÃ³ thÆ° viá»‡n táº­p há»£p, hoáº·c cÃ³ thÃ¬ cÅ©ng ráº£i rÃ¡c vÃ  khÃ³ cho cÃ¡c báº¡n má»›i vÃ  tá»± há»c. ÄÃ³ lÃ  lÃ½ do VietAI kÃªu gá»i & káº¿t ná»‘i cÃ¡c báº¡n trong cá»™ng Ä‘á»“ng AI/ML/DL Ä‘á»ƒ Ä‘Ã³ng gÃ³p vÃ o ThÆ° viá»‡n Tá»± há»c NLP: Nhá»¯ng báº¡n Chia sáº»: chia sáº» nguá»“n há»c/tÃ i liá»‡u NLP/paper tá»« má»i nÆ¡i trÃªn tháº¿ giá»›i Nhá»¯ng báº¡n Ä‘Æ°á»£c chia sáº»: xem, tá»± há»c, tÃ¬m hiá»ƒu & chá»§ Ä‘á»™ng chia sáº» thÃªm Táº¥t cáº£ cÃ¡c báº¡n chia sáº» sáº½ nháº­n CREDIT trá»±c tiáº¿p trÃªn file vÃ  tÃ¹y thuá»™c vÃ o má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p, VietAI sáº½ há»— trá»£ Ä‘á»ƒ cÃ¹ng báº¡n tá»• chá»©c nhiá»u hoáº¡t Ä‘á»™ng chia sáº» bá»• Ã­ch. ThÆ° viá»‡n Ä‘Ã£ cÃ³ má»¥c lá»¥c cÃ³ sáºµn. Má»i ngÆ°á»i chá»‰ cáº§n chia sáº» (paste link) vÃ o. Náº¿u cÃ¡c báº¡n cÃ³ Ä‘Ã³ng gÃ³p vá» cÃ¡ch thá»©c xÃ¢y dá»±ng má»¥c lá»¥c cá»§a ThÆ° viá»‡n cÃ³ thá»ƒ comment phÃ­a dÆ°á»›i hoáº·c inbox An. File sáº½ Ä‘Æ°á»£c monitor thÆ°á»ng xuyÃªn Ä‘á»ƒ Ä‘áº£m báº£o rÃµ rÃ ng vÃ  credit Ä‘á»§ cho táº¥t cáº£ anh/chá»‹ Ä‘Ã³ng gÃ³p. About us: VietAI is a non-profit organization. Our mission is to build a community of world-Â­class AI talents in Vietnam to solve meaningful and impactful problems for not just Vietnam but also the world.",,,,,
"ChÃ o cÃ¡c bro, e Ä‘ang lÃ m 1 model Ä‘á»ƒ forecast VN30 futures sá»­ dá»¥ng Deep Q NN, mÃ´ hÃ¬nh e NN sá»­ dá»¥ng lÃ  RNN/ GRU
E Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»›i 2 chá»‰ sá»‘:
(1): Profit/ Max profit ~ 80% vá»›i profit lÃ  tá»•ng giÃ¡ trá»‹ (tháº¯ng - thua) trong 1 ká»³; max profit lÃ  tá»•ng giÃ¡ trá»‹ cÃ³ thá»ƒ tháº¯ng trong ká»³ Ä‘Ã³.
(2): win/loss ~ 4-6 láº§n vá»›i win lÃ  tá»•ng giÃ¡ trá»‹ tháº¯ng; loss lÃ  tá»•ng giÃ¡ trá»‹ thua trong ká»³.
VD: Vá»›i chuá»—i giÃ¡ vÃ  hÃ nh Ä‘á»™ng nhÆ° sau:
Prices = [1, 3, 2, 5, 7] ; Actions = [mua, giá»¯, bÃ¡n, mua]
Max profit = 2 + 0 + 3 + 2 = 7
Profit = 2 - 1 + 0 + 2 = 3
Win = 2 + 2 = 4
Loss = -1
Ká»³ cÃ³ thá»ƒ lÃ  weekly, monthly, quaterly.
E khÃ´ng cÃ³ benchmark vá» cÃ¡c chá»‰ sá»‘ nÃ y Ä‘á»ƒ biáº¿t model nhÆ° tháº¿ nÃ o lÃ  tá»‘t, ACE chá»‰a sáº» e chÃºt kinh nghiá»‡m, Ä‘áº·c biá»‡t lÃ  cÃ¡c chá»‰ sá»‘ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model performance nhÃ©.
E cháº¡y validate vá»›i VNindex vÃ  Down jones 30 thÃ¬ Profit/ Max profit ~ 45-55%","ChÃ o cÃ¡c bro, e Ä‘ang lÃ m 1 model Ä‘á»ƒ forecast VN30 futures sá»­ dá»¥ng Deep Q NN, mÃ´ hÃ¬nh e NN sá»­ dá»¥ng lÃ  RNN/ GRU E Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh vá»›i 2 chá»‰ sá»‘: (1): Profit/ Max profit ~ 80% vá»›i profit lÃ  tá»•ng giÃ¡ trá»‹ (tháº¯ng - thua) trong 1 ká»³; max profit lÃ  tá»•ng giÃ¡ trá»‹ cÃ³ thá»ƒ tháº¯ng trong ká»³ Ä‘Ã³. (2): win/loss ~ 4-6 láº§n vá»›i win lÃ  tá»•ng giÃ¡ trá»‹ tháº¯ng; loss lÃ  tá»•ng giÃ¡ trá»‹ thua trong ká»³. VD: Vá»›i chuá»—i giÃ¡ vÃ  hÃ nh Ä‘á»™ng nhÆ° sau: Prices = [1, 3, 2, 5, 7] ; Actions = [mua, giá»¯, bÃ¡n, mua] Max profit = 2 + 0 + 3 + 2 = 7 Profit = 2 - 1 + 0 + 2 = 3 Win = 2 + 2 = 4 Loss = -1 Ká»³ cÃ³ thá»ƒ lÃ  weekly, monthly, quaterly. E khÃ´ng cÃ³ benchmark vá» cÃ¡c chá»‰ sá»‘ nÃ y Ä‘á»ƒ biáº¿t model nhÆ° tháº¿ nÃ o lÃ  tá»‘t, ACE chá»‰a sáº» e chÃºt kinh nghiá»‡m, Ä‘áº·c biá»‡t lÃ  cÃ¡c chá»‰ sá»‘ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model performance nhÃ©. E cháº¡y validate vá»›i VNindex vÃ  Down jones 30 thÃ¬ Profit/ Max profit ~ 45-55%",,,,,
"Xin lá»—i cÃ¡c bÃ¡c cho em há»i chÃºt vá» statistics 2 cÃ´ng thá»©c trong hÃ¬nh
CÃ´ng thá»©c Ä‘áº§u tiÃªn lÃ  residual sum of squares (RSS) lÃ  giÃ¡ trá»‹ quan sÃ¡t Ä‘Æ°á»£c observed trá»« Ä‘i estimation theo model thÃ¬ sao láº¡i báº±ng sigma vá»‘n dÄ© dÃ¹ng mean.
CÃ´ng thá»©c thá»© 2 thÃ¬ em ngu luÃ´n khÃ´ng hiá»ƒu sao ra Ä‘Æ°á»£c nhÆ° váº­y!
Nguá»“n sÃ¡ch:. An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics) trang 76",Xin lá»—i cÃ¡c bÃ¡c cho em há»i chÃºt vá» statistics 2 cÃ´ng thá»©c trong hÃ¬nh CÃ´ng thá»©c Ä‘áº§u tiÃªn lÃ  residual sum of squares (RSS) lÃ  giÃ¡ trá»‹ quan sÃ¡t Ä‘Æ°á»£c observed trá»« Ä‘i estimation theo model thÃ¬ sao láº¡i báº±ng sigma vá»‘n dÄ© dÃ¹ng mean. CÃ´ng thá»©c thá»© 2 thÃ¬ em ngu luÃ´n khÃ´ng hiá»ƒu sao ra Ä‘Æ°á»£c nhÆ° váº­y! Nguá»“n sÃ¡ch:. An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics) trang 76,,,"#Q&A, #math",,
"Paper khÃ¡ hay cho má»i ngÆ°á»i muá»‘n dá»±ng App mobile 2d to 3d
Chuyá»ƒn view Ä‘á»ƒ dá»±ng 3d tá»« Má»˜T hoáº·c nhiá»u áº£nh 2d.",Paper khÃ¡ hay cho má»i ngÆ°á»i muá»‘n dá»±ng App mobile 2d to 3d Chuyá»ƒn view Ä‘á»ƒ dá»±ng 3d tá»« Má»˜T hoáº·c nhiá»u áº£nh 2d.,,,,,
"Xin lá»—i má»i ngÆ°á»i,
Em thá»­ dÃ¹ng pretrain gpt2 cá»§a transformer Ä‘á»ƒ generate text, mÃ  bá»‹ lá»—i nhÆ° nÃ y ğŸ˜¢. Em cÃ³ search trÃªn stackoverflow nhÆ°ng váº«n chÆ°a tÃ¬m ra giáº£i phÃ¡p.
Link google colab:
https://colab.research.google.com/drive/1ksOkmNLRSAkur3Ym-IudkTWDkGrz0f9f?usp=sharing","Xin lá»—i má»i ngÆ°á»i, Em thá»­ dÃ¹ng pretrain gpt2 cá»§a transformer Ä‘á»ƒ generate text, mÃ  bá»‹ lá»—i nhÆ° nÃ y . Em cÃ³ search trÃªn stackoverflow nhÆ°ng váº«n chÆ°a tÃ¬m ra giáº£i phÃ¡p. Link google colab: https://colab.research.google.com/drive/1ksOkmNLRSAkur3Ym-IudkTWDkGrz0f9f?usp=sharing",,,,,
"Giá»›i thiá»‡u dá»± Ã¡n TopDup
""TopDup lÃ  dá»± Ã¡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c khá»Ÿi xÆ°á»›ng bá»Ÿi Forum Machine Learning CÆ¡ báº£n nháº±m há»— trá»£ cÃ¡c website, blog cÃ´ng nghá»‡ báº£o vá»‡ báº£n quyá»n bÃ i viáº¿t vÃ  chá»‘ng sao chÃ©p.
Ã tÆ°á»Ÿng cÆ¡ báº£n cá»§a dá»± Ã¡n lÃ  quÃ©t toÃ n bá»™ tin tá»©c tá»« cÃ¡c website, blog cÃ´ng nghá»‡ phá»• biáº¿n táº¡i Viá»‡t Nam, phÃ¢n tÃ­ch Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhá»¯ng bÃ i viáº¿t giá»‘ng nhau vÃ  liá»‡t kÃª táº¥t cáº£ nhá»¯ng trÆ°á»ng há»£p trÃ¹ng láº·p phÃ¡t hiá»‡n Ä‘Æ°á»£c. Danh sÃ¡ch trÃ¹ng láº·p Ä‘Æ°á»£c cÃ´ng bá»‘ cÃ´ng khai táº¡i website cá»§a dá»± Ã¡n: https://topdup.xyz, tá»« Ä‘Ã³ giÃºp tÃ¡c giáº£ bÃ i viáº¿t / chá»§ blog / website dá»… dÃ ng phÃ¡t hiá»‡n náº¿u bÃ i viáº¿t cá»§a mÃ¬nh bá»‹ sao chÃ©p trÃ¡i phÃ©p.""
Dá»± Ã¡n ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ tá»« cá»™ng Ä‘á»“ng vá» Ã½ nghÄ©a, tÃ­nh kháº£ thi cá»§a dá»± Ã¡n vÃ  cÃ¡c Ã½ tÆ°á»Ÿng Ä‘á»ƒ cÃ³ sáº£n pháº©m tá»‘t hÆ¡n. ThÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n cÃ³ thá»ƒ Ä‘Æ°á»£c xem thÃªm táº¡i https://docs.google.com/document/d/12_ogaEmYt_E0PlxdN5vWQJ5uYoMs5y70EVzenw71f0c/edit?pli=1.
NhÃ³m phÃ¡t triá»ƒn ban Ä‘áº§u cÅ©ng ráº¥t sáºµn lÃ²ng tÃ­ch há»£p TopDup vÃ o cÃ¡c ná»n táº£ng Ä‘á»c bÃ¡o cÃ´ng nghá»‡ Ä‘ang hoáº¡t Ä‘á»™ng.
MÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n Äáº·ng Háº£i Lá»™c (founder VNAlert) vÃ  cÃ¡c báº¡n ká»¹ sÆ° bÃªn Viblo Ä‘Ã£ tham gia khá»Ÿi táº¡o dá»± Ã¡n nÃ y.","Giá»›i thiá»‡u dá»± Ã¡n TopDup ""TopDup lÃ  dá»± Ã¡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c khá»Ÿi xÆ°á»›ng bá»Ÿi Forum Machine Learning CÆ¡ báº£n nháº±m há»— trá»£ cÃ¡c website, blog cÃ´ng nghá»‡ báº£o vá»‡ báº£n quyá»n bÃ i viáº¿t vÃ  chá»‘ng sao chÃ©p. Ã tÆ°á»Ÿng cÆ¡ báº£n cá»§a dá»± Ã¡n lÃ  quÃ©t toÃ n bá»™ tin tá»©c tá»« cÃ¡c website, blog cÃ´ng nghá»‡ phá»• biáº¿n táº¡i Viá»‡t Nam, phÃ¢n tÃ­ch Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhá»¯ng bÃ i viáº¿t giá»‘ng nhau vÃ  liá»‡t kÃª táº¥t cáº£ nhá»¯ng trÆ°á»ng há»£p trÃ¹ng láº·p phÃ¡t hiá»‡n Ä‘Æ°á»£c. Danh sÃ¡ch trÃ¹ng láº·p Ä‘Æ°á»£c cÃ´ng bá»‘ cÃ´ng khai táº¡i website cá»§a dá»± Ã¡n: https://topdup.xyz, tá»« Ä‘Ã³ giÃºp tÃ¡c giáº£ bÃ i viáº¿t / chá»§ blog / website dá»… dÃ ng phÃ¡t hiá»‡n náº¿u bÃ i viáº¿t cá»§a mÃ¬nh bá»‹ sao chÃ©p trÃ¡i phÃ©p."" Dá»± Ã¡n ráº¥t mong nháº­n Ä‘Æ°á»£c sá»± gÃ³p Ã½ tá»« cá»™ng Ä‘á»“ng vá» Ã½ nghÄ©a, tÃ­nh kháº£ thi cá»§a dá»± Ã¡n vÃ  cÃ¡c Ã½ tÆ°á»Ÿng Ä‘á»ƒ cÃ³ sáº£n pháº©m tá»‘t hÆ¡n. ThÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n cÃ³ thá»ƒ Ä‘Æ°á»£c xem thÃªm táº¡i https://docs.google.com/document/d/12_ogaEmYt_E0PlxdN5vWQJ5uYoMs5y70EVzenw71f0c/edit?pli=1. NhÃ³m phÃ¡t triá»ƒn ban Ä‘áº§u cÅ©ng ráº¥t sáºµn lÃ²ng tÃ­ch há»£p TopDup vÃ o cÃ¡c ná»n táº£ng Ä‘á»c bÃ¡o cÃ´ng nghá»‡ Ä‘ang hoáº¡t Ä‘á»™ng. MÃ¬nh xin chÃ¢n thÃ nh cáº£m Æ¡n Äáº·ng Háº£i Lá»™c (founder VNAlert) vÃ  cÃ¡c báº¡n ká»¹ sÆ° bÃªn Viblo Ä‘Ã£ tham gia khá»Ÿi táº¡o dá»± Ã¡n nÃ y.",,,,,
"ChÃ o mn, em Ä‘ang Ä‘á»c vá» face_recognition sau khi embedding face, sao khÃ´ng dÃ¹ng euclidean distance mÃ  láº¡i dÃ¹ng cosine distance Ä‘á»ƒ so sÃ¡nh sá»± giá»‘ng nhau cá»§a 2 vecto váº­y áº¡, em má»›i há»c nÃªn mong mn chá»‰ giÃ¡o áº¡!","ChÃ o mn, em Ä‘ang Ä‘á»c vá» face_recognition sau khi embedding face, sao khÃ´ng dÃ¹ng euclidean distance mÃ  láº¡i dÃ¹ng cosine distance Ä‘á»ƒ so sÃ¡nh sá»± giá»‘ng nhau cá»§a 2 vecto váº­y áº¡, em má»›i há»c nÃªn mong mn chá»‰ giÃ¡o áº¡!",,,,,
Please allow me to share this. Thank you.,Please allow me to share this. Thank you.,,,,,
"ChÃ o má»i ngÆ°á»i trong group,
Em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n tÃ­nh khoáº£ng cÃ¡ch giÃ£n cÃ¡ch xÃ£ há»™i trong video. Em Ä‘ang tÃ¬m hiá»ƒu theo 2 trang nÃ y:
OpenCV Social Distancing Detector - PyImageSearch
Subikshaa/Social-Distance-Detection-using-OpenCV (github.com)
ThÃ¬ trong link github em Ä‘ang xem vá» phÆ°Æ¡ng phÃ¡p Triangle similarity, trong Ä‘Ã³ pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c tiÃªu cá»± F (Focal length), nhÆ°ng trong code thÃ¬ Ä‘Ã£ set sáºµn lÃ  615. CÃ²n chiá»u cao ngÆ°á»i H thÃ¬ há» Ä‘á»ƒ trung bÃ¬nh lÃ  165cm. Cho em há»i F mÃ¬nh cÃ³ cÃ¡ch nÃ o tÃ­nh rÃµ rÃ ng khÃ´ng áº¡ vÃ¬ trong github Ä‘Ã£ cÃ³ cÃ´ng thá»©c tÃ­nh nhÆ°ng há» Ä‘Ã£ Ä‘á»ƒ 1 giÃ¡ trá»‹ nÃ o Ä‘Ã³ nhÆ°ng em váº«n chÆ°a hiá»ƒu vÃ¬ sao há» Ä‘á»ƒ nhÆ° váº­y áº¡. CÃ²n chiá»u cao trung bÃ¬nh cá»§a ngÆ°á»i thÃ¬ mÃ¬nh cÃ³ thá»ƒ dá»±a vÃ o Ä‘Ã¢u Ä‘á»ƒ cÃ³ thá»ƒ set cho há»£p lÃ½ áº¡?
VÃ¬ em Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vÃ  sau nÃ y khi viáº¿t bÃ¡o cÃ¡o em cÃ³ Ä‘á»§ cÄƒn cá»© Ä‘á»ƒ cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘Æ°á»£c cho há»™i Ä‘á»“ng náº¿u há»™i Ä‘á»“ng cÃ³ há»i vá» cÃ¡i nÃ y áº¡. Náº¿u má»i ngÆ°á»i Ä‘Ã£ tá»«ng lÃ m vá» Ä‘á» tÃ i nÃ y hoáº·c cÃ³ tÃ¬m hiá»ƒu qua vá» phÆ°Æ¡ng phÃ¡p triangle similarity nÃ y cÃ³ thá»ƒ giáº£i thÃ­ch hoáº·c gá»£i Ã½ Ä‘á»ƒ em hiá»ƒu thÃªm vá» váº¥n Ä‘á» em vá»«a nÃªu á»Ÿ trÃªn áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i trong group, Em Ä‘ang tÃ¬m hiá»ƒu vá» bÃ i toÃ¡n tÃ­nh khoáº£ng cÃ¡ch giÃ£n cÃ¡ch xÃ£ há»™i trong video. Em Ä‘ang tÃ¬m hiá»ƒu theo 2 trang nÃ y: OpenCV Social Distancing Detector - PyImageSearch Subikshaa/Social-Distance-Detection-using-OpenCV (github.com) ThÃ¬ trong link github em Ä‘ang xem vá» phÆ°Æ¡ng phÃ¡p Triangle similarity, trong Ä‘Ã³ pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c tiÃªu cá»± F (Focal length), nhÆ°ng trong code thÃ¬ Ä‘Ã£ set sáºµn lÃ  615. CÃ²n chiá»u cao ngÆ°á»i H thÃ¬ há» Ä‘á»ƒ trung bÃ¬nh lÃ  165cm. Cho em há»i F mÃ¬nh cÃ³ cÃ¡ch nÃ o tÃ­nh rÃµ rÃ ng khÃ´ng áº¡ vÃ¬ trong github Ä‘Ã£ cÃ³ cÃ´ng thá»©c tÃ­nh nhÆ°ng há» Ä‘Ã£ Ä‘á»ƒ 1 giÃ¡ trá»‹ nÃ o Ä‘Ã³ nhÆ°ng em váº«n chÆ°a hiá»ƒu vÃ¬ sao há» Ä‘á»ƒ nhÆ° váº­y áº¡. CÃ²n chiá»u cao trung bÃ¬nh cá»§a ngÆ°á»i thÃ¬ mÃ¬nh cÃ³ thá»ƒ dá»±a vÃ o Ä‘Ã¢u Ä‘á»ƒ cÃ³ thá»ƒ set cho há»£p lÃ½ áº¡? VÃ¬ em Ä‘ang lÃ m Ä‘á»“ Ã¡n tá»‘t nghiá»‡p vÃ  sau nÃ y khi viáº¿t bÃ¡o cÃ¡o em cÃ³ Ä‘á»§ cÄƒn cá»© Ä‘á»ƒ cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘Æ°á»£c cho há»™i Ä‘á»“ng náº¿u há»™i Ä‘á»“ng cÃ³ há»i vá» cÃ¡i nÃ y áº¡. Náº¿u má»i ngÆ°á»i Ä‘Ã£ tá»«ng lÃ m vá» Ä‘á» tÃ i nÃ y hoáº·c cÃ³ tÃ¬m hiá»ƒu qua vá» phÆ°Æ¡ng phÃ¡p triangle similarity nÃ y cÃ³ thá»ƒ giáº£i thÃ­ch hoáº·c gá»£i Ã½ Ä‘á»ƒ em hiá»ƒu thÃªm vá» váº¥n Ä‘á» em vá»«a nÃªu á»Ÿ trÃªn áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"TrÆ°á»›c Ä‘i há»c Ä‘h cÅ©ng rá»›t mÃ´n xstk sml, giá» mÃ¬nh chia sáº» láº¡i kÃªnh nÃ y cho cÃ¡c báº¡n, kÃªnh nÃ y Ä‘Ã£ giÃºp mÃ¬nh qua mÃ´n","TrÆ°á»›c Ä‘i há»c Ä‘h cÅ©ng rá»›t mÃ´n xstk sml, giá» mÃ¬nh chia sáº» láº¡i kÃªnh nÃ y cho cÃ¡c báº¡n, kÃªnh nÃ y Ä‘Ã£ giÃºp mÃ¬nh qua mÃ´n",,,"#sharing, #math",,
"Group Vector and Clustering
chÃ o má»i ngÆ°á»i
E Ä‘ang gáº·p váº¥n Ä‘á» nÃ y á»Ÿ bÆ°á»›c 1 k biáº¿t xá»­ lÃ½ nhÆ° nÃ o.
ban Ä‘áº§u mÃ¬nh cÃ³ ma tráº­n 1 triá»‡u milion vÃ  200 dimension
bÆ°á»›c 1: mÃ¬nh pháº£i giáº£m sá»‘ chiá»u vÃ  sorting ma tráº­n nÃ y thÃ nh nhiá»u block khÃ¡c nhau, tÆ°Æ¡ng á»©ng lÃ  cÃ¡c vector cÅ©ng pháº£i sáº¯p xáº¿p theo kiá»ƒu giá»‘ng nhau thÃ nh 1 block.
bÆ°á»›c 2: sau Ä‘Ã³ get tá»«ng block rá»“i cháº¡y thá»­ vs dbscan , kmeans, optics cho tá»«ng block Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
bÆ°á»›c 3 : cÃ³ thá»ƒ cháº¡y product quantization vá»›i 1 block vÃ  sau Ä‘Ã³ cháº¡y thuáº­t toÃ¡n PQKMEANS Ä‘á»ƒ tÄƒng tá»‘c clustering
nhÆ°ng em k biáº¿t cÃ¡i bÆ°á»›c sá»‘ 1 mÃ¬nh cÃ³ thá»ƒ dÃ¹ng thuáº­t toÃ¡n gÃ¬ Ä‘á»ƒ vector quantization vÃ  lÃ m sao Ä‘á»ƒ group cÃ¡c vector láº¡i vá»›i nhau Ä‘Æ°á»£c thÃ nh 1 block.
e Ä‘Ã£ thá»­ nearpy, faiss distance scipy nhÆ°ng Ä‘Ã³ chá»‰ lÃ  1 sá»‘ thuáº­t toÃ¡n indexx dá»¯ liá»‡u vÃ  dÃ¹ng cho viá»‡c tÃ¬m kiáº¿m.
má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ thÃ¬ giÃºp e vá»›i nhÃ©, thanks
áº£nh mÃ´ táº£ quÃ¡ trÃ¬nh bÆ°á»›c 1 .","Group Vector and Clustering chÃ o má»i ngÆ°á»i E Ä‘ang gáº·p váº¥n Ä‘á» nÃ y á»Ÿ bÆ°á»›c 1 k biáº¿t xá»­ lÃ½ nhÆ° nÃ o. ban Ä‘áº§u mÃ¬nh cÃ³ ma tráº­n 1 triá»‡u milion vÃ  200 dimension bÆ°á»›c 1: mÃ¬nh pháº£i giáº£m sá»‘ chiá»u vÃ  sorting ma tráº­n nÃ y thÃ nh nhiá»u block khÃ¡c nhau, tÆ°Æ¡ng á»©ng lÃ  cÃ¡c vector cÅ©ng pháº£i sáº¯p xáº¿p theo kiá»ƒu giá»‘ng nhau thÃ nh 1 block. bÆ°á»›c 2: sau Ä‘Ã³ get tá»«ng block rá»“i cháº¡y thá»­ vs dbscan , kmeans, optics cho tá»«ng block Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ bÆ°á»›c 3 : cÃ³ thá»ƒ cháº¡y product quantization vá»›i 1 block vÃ  sau Ä‘Ã³ cháº¡y thuáº­t toÃ¡n PQKMEANS Ä‘á»ƒ tÄƒng tá»‘c clustering nhÆ°ng em k biáº¿t cÃ¡i bÆ°á»›c sá»‘ 1 mÃ¬nh cÃ³ thá»ƒ dÃ¹ng thuáº­t toÃ¡n gÃ¬ Ä‘á»ƒ vector quantization vÃ  lÃ m sao Ä‘á»ƒ group cÃ¡c vector láº¡i vá»›i nhau Ä‘Æ°á»£c thÃ nh 1 block. e Ä‘Ã£ thá»­ nearpy, faiss distance scipy nhÆ°ng Ä‘Ã³ chá»‰ lÃ  1 sá»‘ thuáº­t toÃ¡n indexx dá»¯ liá»‡u vÃ  dÃ¹ng cho viá»‡c tÃ¬m kiáº¿m. má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ thÃ¬ giÃºp e vá»›i nhÃ©, thanks áº£nh mÃ´ táº£ quÃ¡ trÃ¬nh bÆ°á»›c 1 .",,,,,
"ChÃ o cÃ¡c anh/chá»‹, em Ä‘ang lÃ  sinh viÃªn chuyÃªn ngÃ nh SE. Hiá»‡n táº¡i thÃ¬ em muá»‘n thá»­ sá»©c vá»›i ML á»Ÿ má»©c lÃ  sá»­ dá»¥ng Ä‘Æ°á»£c nhá»¯ng model cÃ³ sáºµn thÃ¬ em nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡? ( em khÃ´ng biáº¿t lÃ  dÃ¹ng tá»« nhÆ° nÃ y cÃ³ Ä‘Ãºng hay khÃ´ng ).
Náº¿u cÃ¢u há»i cá»§a em cÃ³ ngá»› ngáº«n quÃ¡ thÃ¬ cmt Ä‘á»ƒ em xoÃ¡, em xin lá»—i trÆ°á»›c :((","ChÃ o cÃ¡c anh/chá»‹, em Ä‘ang lÃ  sinh viÃªn chuyÃªn ngÃ nh SE. Hiá»‡n táº¡i thÃ¬ em muá»‘n thá»­ sá»©c vá»›i ML á»Ÿ má»©c lÃ  sá»­ dá»¥ng Ä‘Æ°á»£c nhá»¯ng model cÃ³ sáºµn thÃ¬ em nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u áº¡? ( em khÃ´ng biáº¿t lÃ  dÃ¹ng tá»« nhÆ° nÃ y cÃ³ Ä‘Ãºng hay khÃ´ng ). Náº¿u cÃ¢u há»i cá»§a em cÃ³ ngá»› ngáº«n quÃ¡ thÃ¬ cmt Ä‘á»ƒ em xoÃ¡, em xin lá»—i trÆ°á»›c :((",,,,,
"Má»i ngÆ°á»i Æ¡i cho mÃ¬nh há»i ngÃ nh nÃ y mÃ¬nh muá»‘n kiáº¿m viá»‡c lÃ m thÃ¬ focus vÃ o 1 thá»© nhÆ° Computer Vision , Deep learning hoáº·c NLP , .. chá»© ngta ko yÃªu cáº§u pháº£i biáº¿t háº¿t Ä‘Ãºng k áº¡","Má»i ngÆ°á»i Æ¡i cho mÃ¬nh há»i ngÃ nh nÃ y mÃ¬nh muá»‘n kiáº¿m viá»‡c lÃ m thÃ¬ focus vÃ o 1 thá»© nhÆ° Computer Vision , Deep learning hoáº·c NLP , .. chá»© ngta ko yÃªu cáº§u pháº£i biáº¿t háº¿t Ä‘Ãºng k áº¡",,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i mÃ¬nh muá»‘n focus vÃ o 1 máº£ng NLP Ä‘á»ƒ Ä‘i xin viá»‡c lÃ m thÃ¬ path carrer cá»§a NLP lÃ  ntn áº¡ , em cáº£m Æ¡n mn áº¡","Má»i ngÆ°á»i cho mÃ¬nh há»i mÃ¬nh muá»‘n focus vÃ o 1 máº£ng NLP Ä‘á»ƒ Ä‘i xin viá»‡c lÃ m thÃ¬ path carrer cá»§a NLP lÃ  ntn áº¡ , em cáº£m Æ¡n mn áº¡",,,,,
"Share cho cÃ¡c báº¡n trong nhÃ³m cuá»™c thi ML showcase 2020, cuá»™c thi cuá»‘i nÄƒm vinh danh cÃ¡c á»©ng dá»¥ng ML cÃ³ á»©ng dá»¥ng trong thá»±c táº¿.
Giáº£i thÆ°á»Ÿng trong link nhÃ© má»i ngÆ°á»i :D","Share cho cÃ¡c báº¡n trong nhÃ³m cuá»™c thi ML showcase 2020, cuá»™c thi cuá»‘i nÄƒm vinh danh cÃ¡c á»©ng dá»¥ng ML cÃ³ á»©ng dá»¥ng trong thá»±c táº¿. Giáº£i thÆ°á»Ÿng trong link nhÃ© má»i ngÆ°á»i :D",,,,,
CÃ¡c master xÃ¡c suáº¥t cho em há»i lÃ  sÃ¡ch sai hay em sai váº­y áº¡? CÃ¡i P(A) áº¥y má»i ngÆ°á»i. E cáº£m Æ¡n áº¡!,CÃ¡c master xÃ¡c suáº¥t cho em há»i lÃ  sÃ¡ch sai hay em sai váº­y áº¡? CÃ¡i P(A) áº¥y má»i ngÆ°á»i. E cáº£m Æ¡n áº¡!,,,"#Q&A, #math",,
"Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m build tensorflow cpp trÃªn windows chÆ°a áº¡?
Cho em xin Ã­t kinh nghiá»‡m. Em build ra rá»“i mÃ  cÃ³ váº» váº«n bá»‹ thiáº¿u 1 vÃ i file header áº¡",Má»i ngÆ°á»i ai cÃ³ kinh nghiá»‡m build tensorflow cpp trÃªn windows chÆ°a áº¡? Cho em xin Ã­t kinh nghiá»‡m. Em build ra rá»“i mÃ  cÃ³ váº» váº«n bá»‹ thiáº¿u 1 vÃ i file header áº¡,,,,,
"[Shameless self advertisement - my apologies] As NeurIPS 2020 (a top-tier conference in machine learning) is starting soon, I would like to shamelessly advertise our work presented at the conference, which is in bandit theory; federated learning with selfish agents; and topological machine learning (see details below). If you have time, please take a look at them, and if still interested, please stop by the sessions to discuss with my students and I:
1. Adversarial blocking bandits: Tuesday 8 Dec, 5-7pm UK time (9-11am PST)
https://neurips.cc/.../poster...
In this work, we extend Basu et al. (2019)'s blocking bandit paper to the adversarial setting. We first prove that the underlying offline problem, which is a non-preemptive interval scheduling problem, is strongly NP-hard. Then we provide a approximation ratio for the online greedy (AFAIK this is the first approx. result for online non-preemptive deterministic interval scheduling algs). Then we prove that in the bandit setting, sub-linear regret cannot be achieved without having an additional bound on the total path variation. We then propose 2 algorithms with sub-linear regret bounds for the case when we know this budget, and when we don't respectively.
2. Optimal learning from verified training data: Thursday 10 Dec, 5-7pm UK time (9-11am PST)
https://neurips.cc/.../poster...
This paper looks at a federated learning problem with selfish participants, where each participant can submit their data to a central learner for joint training. The goal of the selfish agents is to manipulate the central learning process so that the outcome is more favourable to them (e.g., becomes closer to a model that they prefer). We ask the question whether we can do something clever against this selfish behaviour. To answer this, we look at the Stackelberg prediction game (BrÃ¼ckner and Scheffer 2011) with linear regression models (SPG). Our main, and perhaps quite surprising, result is that this problem can be solved optimally (most results in SPG and bilevel optimisation can at most guarantee convergence to local optima). In particular, we show that solving an SPG of this type is equivalent to solving a quadratically constrained quadratic fractional program with a single constraint. Then, by using a novel combination of Dinkelbachâ€™s lemmas for fractional programming and the S-lemma for quadratic programs, we show that a combination of bisection search and semidefinite programming can be used to converge to global optima.
3. Two papers on topological ML at the TDA & Beyond Workshop: Friday 11 Dec (the whole day):
One is a spotlight presentation in which we prove that the class of hypotheses with the same persistent homology is non-uniformly learnable:
https://openreview.net/attachment?id=Ay-RgChnje&name=Poster
This work justifies the inclusion of topological losses as loss function/as a regulariser in the training phase (as has been done by many until now without theoretical justification).
The other work enables the usage of fuzzy clustering directly on the persistent diagram space:
https://openreview.net/attachment?id=I49l3mLYXl6&name=Poster
This work allows us to automatically process the topology of data without requiring addition of domain knowledge (as has been done until now).
We also show that it has great potential in transfer learning: When applied to a new domain, we can use fuzzy clustering to identify the closest topological clusters and use pre-trained models which have decision boundaries with most similar topologies to the new data set. Our experiments show that by doing so, the performance of transfer learning can be significantly improved.","[Shameless self advertisement - my apologies] As NeurIPS 2020 (a top-tier conference in machine learning) is starting soon, I would like to shamelessly advertise our work presented at the conference, which is in bandit theory; federated learning with selfish agents; and topological machine learning (see details below). If you have time, please take a look at them, and if still interested, please stop by the sessions to discuss with my students and I: 1. Adversarial blocking bandits: Tuesday 8 Dec, 5-7pm UK time (9-11am PST) https://neurips.cc/.../poster... In this work, we extend Basu et al. (2019)'s blocking bandit paper to the adversarial setting. We first prove that the underlying offline problem, which is a non-preemptive interval scheduling problem, is strongly NP-hard. Then we provide a approximation ratio for the online greedy (AFAIK this is the first approx. result for online non-preemptive deterministic interval scheduling algs). Then we prove that in the bandit setting, sub-linear regret cannot be achieved without having an additional bound on the total path variation. We then propose 2 algorithms with sub-linear regret bounds for the case when we know this budget, and when we don't respectively. 2. Optimal learning from verified training data: Thursday 10 Dec, 5-7pm UK time (9-11am PST) https://neurips.cc/.../poster... This paper looks at a federated learning problem with selfish participants, where each participant can submit their data to a central learner for joint training. The goal of the selfish agents is to manipulate the central learning process so that the outcome is more favourable to them (e.g., becomes closer to a model that they prefer). We ask the question whether we can do something clever against this selfish behaviour. To answer this, we look at the Stackelberg prediction game (BrÃ¼ckner and Scheffer 2011) with linear regression models (SPG). Our main, and perhaps quite surprising, result is that this problem can be solved optimally (most results in SPG and bilevel optimisation can at most guarantee convergence to local optima). In particular, we show that solving an SPG of this type is equivalent to solving a quadratically constrained quadratic fractional program with a single constraint. Then, by using a novel combination of Dinkelbachâ€™s lemmas for fractional programming and the S-lemma for quadratic programs, we show that a combination of bisection search and semidefinite programming can be used to converge to global optima. 3. Two papers on topological ML at the TDA & Beyond Workshop: Friday 11 Dec (the whole day): One is a spotlight presentation in which we prove that the class of hypotheses with the same persistent homology is non-uniformly learnable: https://openreview.net/attachment?id=Ay-RgChnje&name=Poster This work justifies the inclusion of topological losses as loss function/as a regulariser in the training phase (as has been done by many until now without theoretical justification). The other work enables the usage of fuzzy clustering directly on the persistent diagram space: https://openreview.net/attachment?id=I49l3mLYXl6&name=Poster This work allows us to automatically process the topology of data without requiring addition of domain knowledge (as has been done until now). We also show that it has great potential in transfer learning: When applied to a new domain, we can use fuzzy clustering to identify the closest topological clusters and use pre-trained models which have decision boundaries with most similar topologies to the new data set. Our experiments show that by doing so, the performance of transfer learning can be significantly improved.",,,,,
"ChÃ o cÃ¡c bÃ¡c, máº¥y hÃ´m rá»“i cháº¡y quanh Group tháº¥y anh em nhiá»u lá»—i khi há»c AI , Deep Learning trÃªn Windows quÃ¡ (Ä‘áº·c biá»‡t lÃ  tháº±ng Dlib) nÃªn mÃ¬nh ra bÃ i nÃ y hi vá»ng giÃºp Ä‘Æ°á»£c anh em newbie má»›i há»c.
Mong ad duyá»‡t bÃ i!","ChÃ o cÃ¡c bÃ¡c, máº¥y hÃ´m rá»“i cháº¡y quanh Group tháº¥y anh em nhiá»u lá»—i khi há»c AI , Deep Learning trÃªn Windows quÃ¡ (Ä‘áº·c biá»‡t lÃ  tháº±ng Dlib) nÃªn mÃ¬nh ra bÃ i nÃ y hi vá»ng giÃºp Ä‘Æ°á»£c anh em newbie má»›i há»c. Mong ad duyá»‡t bÃ i!",,,,,
"Em chÃ o anh/chá»‹, gáº§n Ä‘Ã¢y em cÃ³ tÃ¬m hiá»ƒu vá» YOLOv3 Ä‘á»ƒ lÃ m 1 project nhá» vá» detect playing card game. vÃ¬ trong pre-trained model ko cÃ³ data lÃ  playing card game nÃªn em quyáº¿t Ä‘á»‹nh tá»± train 1 cÃ¡i custom data set, em train trÃªn local machine áº¡. Tuy nhiÃªn lÃºc train thÃ¬ em bá»‹ káº¹t á»Ÿ chá»— `can not load image` vÃ  `STB Reason: can't fopen` áº¡. Em cÃ³ search google vÃ  fix theo hÆ°á»›ng dáº«n nhÆ°ng váº«n khÃ´ng Ä‘c. Anh/chá»‹ nÃ o biáº¿t thÃ¬ giÃºp em vá»›i áº¡, em cáº£m Æ¡n áº¡.","Em chÃ o anh/chá»‹, gáº§n Ä‘Ã¢y em cÃ³ tÃ¬m hiá»ƒu vá» YOLOv3 Ä‘á»ƒ lÃ m 1 project nhá» vá» detect playing card game. vÃ¬ trong pre-trained model ko cÃ³ data lÃ  playing card game nÃªn em quyáº¿t Ä‘á»‹nh tá»± train 1 cÃ¡i custom data set, em train trÃªn local machine áº¡. Tuy nhiÃªn lÃºc train thÃ¬ em bá»‹ káº¹t á»Ÿ chá»— `can not load image` vÃ  `STB Reason: can't fopen` áº¡. Em cÃ³ search google vÃ  fix theo hÆ°á»›ng dáº«n nhÆ°ng váº«n khÃ´ng Ä‘c. Anh/chá»‹ nÃ o biáº¿t thÃ¬ giÃºp em vá»›i áº¡, em cáº£m Æ¡n áº¡.",,,,,
"Viá»‡c chia dá»¯ liá»‡u lÃ m máº¥y pháº§n lÃ  má»™t bÆ°á»›c cÆ¡ báº£n, tÆ°á»Ÿng Ä‘Æ¡n giáº£n mÃ  láº¡i ráº¥t dá»… gÃ¢y nháº§m láº«n trong quÃ¡ trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y.
Blog láº§n nÃ y chia sáº» má»™t chÃºt kinh nghiá»‡m cá»§a mÃ¬nh vá» chá»§ Ä‘á» nÃ y... CÃ²n báº¡n thÃ¬ sao? Báº¡n cÃ³ kinh nghiá»‡m gÃ¬ thÃº vá»‹ vá» viá»‡c chia dá»¯ liá»‡u thÃ¬ hÃ£y chia sáº» Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng há»c há»i nha :)","Viá»‡c chia dá»¯ liá»‡u lÃ m máº¥y pháº§n lÃ  má»™t bÆ°á»›c cÆ¡ báº£n, tÆ°á»Ÿng Ä‘Æ¡n giáº£n mÃ  láº¡i ráº¥t dá»… gÃ¢y nháº§m láº«n trong quÃ¡ trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y. Blog láº§n nÃ y chia sáº» má»™t chÃºt kinh nghiá»‡m cá»§a mÃ¬nh vá» chá»§ Ä‘á» nÃ y... CÃ²n báº¡n thÃ¬ sao? Báº¡n cÃ³ kinh nghiá»‡m gÃ¬ thÃº vá»‹ vá» viá»‡c chia dá»¯ liá»‡u thÃ¬ hÃ£y chia sáº» Ä‘á»ƒ má»i ngÆ°á»i cÃ¹ng há»c há»i nha :)",,,,,
Em Ä‘Ã£ hoÃ n thÃ nh xong khoÃ¡ ML(Coursera cá»§a gs Andrew NG) giá» em muá»‘n há»c DL thÃ¬ khoÃ¡ nÃ o thÃ¬ cÃ³ lÃ½ thuyáº¿t + code áº¡,Em Ä‘Ã£ hoÃ n thÃ nh xong khoÃ¡ ML(Coursera cá»§a gs Andrew NG) giá» em muá»‘n há»c DL thÃ¬ khoÃ¡ nÃ o thÃ¬ cÃ³ lÃ½ thuyáº¿t + code áº¡,,,,,
"Xin chÃ o mn!
Em má»›i tÃ¬m hiá»ƒu vá» cÃ¡ch Ä‘Ã¡nh label cho áº£nh, em lÃ m theo link bÃªn dÆ°á»›i. Em dÃ¹ng Anaconda trÃªn window, nhÆ°ng khi má»Ÿ labelImg lÃªn rá»“i má»Ÿ Open file áº£nh lÃªn thÃ¬ áº£nh nÃ³ tá»± phÃ³ng to ra, má»™t há»“i sau lÃ  labelImg tá»± Ä‘á»™ng táº¯t.
Mn cho em há»i trÆ°á»ng há»£p nÃ y lÃ  lá»—i gÃ¬ váº­y áº¡? VÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o?
Em xin cáº£m Æ¡n!
https://github.com/tzutalin/labelImg","Xin chÃ o mn! Em má»›i tÃ¬m hiá»ƒu vá» cÃ¡ch Ä‘Ã¡nh label cho áº£nh, em lÃ m theo link bÃªn dÆ°á»›i. Em dÃ¹ng Anaconda trÃªn window, nhÆ°ng khi má»Ÿ labelImg lÃªn rá»“i má»Ÿ Open file áº£nh lÃªn thÃ¬ áº£nh nÃ³ tá»± phÃ³ng to ra, má»™t há»“i sau lÃ  labelImg tá»± Ä‘á»™ng táº¯t. Mn cho em há»i trÆ°á»ng há»£p nÃ y lÃ  lá»—i gÃ¬ váº­y áº¡? VÃ  cÃ¡ch kháº¯c phá»¥c nhÆ° tháº¿ nÃ o? Em xin cáº£m Æ¡n! https://github.com/tzutalin/labelImg",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c. Äá»ƒ cáº­p nháº­t kiáº¿n thá»©c em cÅ©ng máº¡nh dáº¡n tÃ¬m hiá»ƒu vÃ  lÃ m clip vá» TrÃ normer Ä‘á»ƒ lÃ m ná»n táº£ng cho clip tá»›i sáº½ há»c vá» BERT vÃ  á»©ng dá»¥ng cá»§a BERT.
Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie, cÃ¡c cao thá»§ Ä‘i qua comment giÃºp náº¿u em sai Ä‘á»ƒ em sá»­a kiáº¿n thá»©c cho chuáº©n ah.
Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c bÃ¡c. Äá»ƒ cáº­p nháº­t kiáº¿n thá»©c em cÅ©ng máº¡nh dáº¡n tÃ¬m hiá»ƒu vÃ  lÃ m clip vá» TrÃ normer Ä‘á»ƒ lÃ m ná»n táº£ng cho clip tá»›i sáº½ há»c vá» BERT vÃ  á»©ng dá»¥ng cá»§a BERT. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie, cÃ¡c cao thá»§ Ä‘i qua comment giÃºp náº¿u em sai Ä‘á»ƒ em sá»­a kiáº¿n thá»©c cho chuáº©n ah. Mong ad duyá»‡t bÃ i!",,,,,
"Cho mÃ¬nh xin Ä‘Æ°á»£c biáº¿t: táº¡i sao tÃ­nh liÃªn tá»¥c khÃ´ng Ä‘Æ°á»£c chÃº trá»ng vá»›i cÃ¡c active functions cÅ©ng nhÆ° Ä‘áº¡o hÃ m cá»§a nÃ³? MÃ¬nh xem ráº¥t nhiá»u active function thÃ´ng dá»¥ng nhÆ°ng Ã­t tháº¥y hÃ m nÃ o vá»«a Ä‘áº£m báº£o Ä‘Æ°á»£c tÃ­nh liÃªn tá»¥c cá»§a chÃ­nh nÃ³ vÃ  cho cáº£ Ä‘áº¡o hÃ m cá»§a nÃ³. NÃ³ cÃ³ áº£nh hÆ°á»Ÿng gÃ¬ Ä‘áº¿n quÃ¡ trÃ¬nh tÃ­nh toÃ¡n cá»§a mÃ´ hÃ¬nh deep learning táº¡i nhá»¯ng Ä‘iá»ƒm giÃ¡n Ä‘oáº¡n khÃ´ng? CÃ¡c hÃ m/thÆ° viá»‡n trÃªn Python chá»‰ cung cáº¥p á»Ÿ dáº¡ng API Ä‘á»ƒ khai thÃ¡c chá»© nÃ³ khÃ´ng cÃ³ document Ä‘á»ƒ mÃ´ táº£ viá»‡c thiáº¿t láº­p cÃ¡c API nÃ y, nÃªn mÃ¬nh khÃ´ng thá»ƒ biáº¿t bÃªn trong nÃ³ Ä‘Ã£ xá»­ lÃ½ tháº¿ nÃ o.
MÃ¬nh xin lá»—i khi Ä‘á» cáº­p Ä‘áº¿n váº¥n Ä‘á» nÃ y, nhÆ°ng nÃ³ lÃ  cÃ¡i mÃ¬nh khÃ´ng hiá»ƒu nÃªn mÃ¬nh máº¡nh dáº¡n há»i, xin cÃ¡c báº¡n chá»‰ Ä‘Ã¡p, mÃ¬nh xin cáº£m Æ¡n!","Cho mÃ¬nh xin Ä‘Æ°á»£c biáº¿t: táº¡i sao tÃ­nh liÃªn tá»¥c khÃ´ng Ä‘Æ°á»£c chÃº trá»ng vá»›i cÃ¡c active functions cÅ©ng nhÆ° Ä‘áº¡o hÃ m cá»§a nÃ³? MÃ¬nh xem ráº¥t nhiá»u active function thÃ´ng dá»¥ng nhÆ°ng Ã­t tháº¥y hÃ m nÃ o vá»«a Ä‘áº£m báº£o Ä‘Æ°á»£c tÃ­nh liÃªn tá»¥c cá»§a chÃ­nh nÃ³ vÃ  cho cáº£ Ä‘áº¡o hÃ m cá»§a nÃ³. NÃ³ cÃ³ áº£nh hÆ°á»Ÿng gÃ¬ Ä‘áº¿n quÃ¡ trÃ¬nh tÃ­nh toÃ¡n cá»§a mÃ´ hÃ¬nh deep learning táº¡i nhá»¯ng Ä‘iá»ƒm giÃ¡n Ä‘oáº¡n khÃ´ng? CÃ¡c hÃ m/thÆ° viá»‡n trÃªn Python chá»‰ cung cáº¥p á»Ÿ dáº¡ng API Ä‘á»ƒ khai thÃ¡c chá»© nÃ³ khÃ´ng cÃ³ document Ä‘á»ƒ mÃ´ táº£ viá»‡c thiáº¿t láº­p cÃ¡c API nÃ y, nÃªn mÃ¬nh khÃ´ng thá»ƒ biáº¿t bÃªn trong nÃ³ Ä‘Ã£ xá»­ lÃ½ tháº¿ nÃ o. MÃ¬nh xin lá»—i khi Ä‘á» cáº­p Ä‘áº¿n váº¥n Ä‘á» nÃ y, nhÆ°ng nÃ³ lÃ  cÃ¡i mÃ¬nh khÃ´ng hiá»ƒu nÃªn mÃ¬nh máº¡nh dáº¡n há»i, xin cÃ¡c báº¡n chá»‰ Ä‘Ã¡p, mÃ¬nh xin cáº£m Æ¡n!",,,,,
"Em chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu bÃ i toÃ¡n vá» bÃ³c tÃ¡ch layout vÃ  thá»© tá»± Ä‘á»c, bÆ°á»›c Ä‘áº§u Ä‘Ã£ ghÃ©p Ä‘Æ°á»£c cÃ¡c layout vÃ  ghÃ©p cÃ¡c paragraph, sentence vá»›i nhau. Giá» Ä‘ang vÆ°á»›ng máº¯c 1 vÃ i váº¥n Ä‘á». vá» thá»© tá»± Ä‘á»c cÅ©ng nhÆ° cÃ¡c layout khÃ³. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ má»™t vÃ i hÆ°á»›ng Ä‘i Ä‘Æ°á»£c khÃ´ng áº¡?
VÃ  tiá»‡n Ä‘Ã¢y em muá»‘n xin code cá»§a cá»§a paper dÆ°á»›i Ä‘Ã¢y do web cá»§a há» Ä‘Ã£ khÃ´ng cÃ²n giá»¯ áº¡.
Em cáº£m Æ¡n má»i ngÆ°á»i vÃ  chÃºc má»i ngÆ°á»i 1 ngÃ y tá»‘t lÃ nh.","Em chÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang tÃ¬m hiá»ƒu bÃ i toÃ¡n vá» bÃ³c tÃ¡ch layout vÃ  thá»© tá»± Ä‘á»c, bÆ°á»›c Ä‘áº§u Ä‘Ã£ ghÃ©p Ä‘Æ°á»£c cÃ¡c layout vÃ  ghÃ©p cÃ¡c paragraph, sentence vá»›i nhau. Giá» Ä‘ang vÆ°á»›ng máº¯c 1 vÃ i váº¥n Ä‘á». vá» thá»© tá»± Ä‘á»c cÅ©ng nhÆ° cÃ¡c layout khÃ³. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ má»™t vÃ i hÆ°á»›ng Ä‘i Ä‘Æ°á»£c khÃ´ng áº¡? VÃ  tiá»‡n Ä‘Ã¢y em muá»‘n xin code cá»§a cá»§a paper dÆ°á»›i Ä‘Ã¢y do web cá»§a há» Ä‘Ã£ khÃ´ng cÃ²n giá»¯ áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i vÃ  chÃºc má»i ngÆ°á»i 1 ngÃ y tá»‘t lÃ nh.",,,,,
"Cho em há»i cÃ³ ai cÃ i Ä‘Æ°á»£c thuáº­t toÃ¡n BERT Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c >80% nhÆ° trong bÃ¡o cÃ¡o cá»§a google nÃ³i chÆ°a (link: https://arxiv.org/pdf/1810.04805.pdf)
E cháº¡y Ä‘Æ°á»£c vá»›i epoch =600 (hÆ¡n ná»¯a thÃ¬ cháº¡y quÃ¡ lÃ¢u, vÆ°á»£t quÃ¡ thá»i gian cho free cá»§a colab). MÃ  Ä‘á»™ chÃ­nh xÃ¡c khoáº£ng 70% thÃ´i.
Tháº§y yÃªu cáº§u pháº£i chá»‰nh Ä‘áº¿n khi nÃ o Ä‘áº¡t >80% má»›i thÃ´i. CÃ³ ai giÃºp em vá»›i, Ä‘uá»‘i quÃ¡.","Cho em há»i cÃ³ ai cÃ i Ä‘Æ°á»£c thuáº­t toÃ¡n BERT Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c >80% nhÆ° trong bÃ¡o cÃ¡o cá»§a google nÃ³i chÆ°a (link: https://arxiv.org/pdf/1810.04805.pdf) E cháº¡y Ä‘Æ°á»£c vá»›i epoch =600 (hÆ¡n ná»¯a thÃ¬ cháº¡y quÃ¡ lÃ¢u, vÆ°á»£t quÃ¡ thá»i gian cho free cá»§a colab). MÃ  Ä‘á»™ chÃ­nh xÃ¡c khoáº£ng 70% thÃ´i. Tháº§y yÃªu cáº§u pháº£i chá»‰nh Ä‘áº¿n khi nÃ o Ä‘áº¡t >80% má»›i thÃ´i. CÃ³ ai giÃºp em vá»›i, Ä‘uá»‘i quÃ¡.",,,,,
"Má»i ngÆ°á»i cho e há»i, lÃ m tháº¿ nÃ o Ä‘á»ƒ biáº¿t trong 1 táº­p cÃ¡c vector thÃ¬ cÃ³ nhá»¯ng vector nÃ o giá»‘ng nhau áº¡? E dÃ¹ng set Ä‘á»ƒ add thÃ¬ set khÃ´ng add Ä‘c kiá»ƒu vector, ndarray áº¡?","Má»i ngÆ°á»i cho e há»i, lÃ m tháº¿ nÃ o Ä‘á»ƒ biáº¿t trong 1 táº­p cÃ¡c vector thÃ¬ cÃ³ nhá»¯ng vector nÃ o giá»‘ng nhau áº¡? E dÃ¹ng set Ä‘á»ƒ add thÃ¬ set khÃ´ng add Ä‘c kiá»ƒu vector, ndarray áº¡?",,,,,
"tiáº¿p tá»¥c series reinforcement learning vá»›i team AI camp táº¡i Quy NhÆ¡n
Link bÃ i viáº¿t gá»‘c : https://www.facebook.com/QNAICommunity/posts/176477823998645",tiáº¿p tá»¥c series reinforcement learning vá»›i team AI camp táº¡i Quy NhÆ¡n Link bÃ i viáº¿t gá»‘c : https://www.facebook.com/QNAICommunity/posts/176477823998645,,,,,
"1 Trang khÃ¡ hay dÃ nh cho nhá»¯ng báº¡n muá»‘n váº½ schematic NN architecture Ä‘Æ¡n giáº£n mÃ  khÃ´ng cáº§n láº§y lá»™i vá»›i draw.io
http://alexlenail.me/NN-SVG/LeNet.html",1 Trang khÃ¡ hay dÃ nh cho nhá»¯ng báº¡n muá»‘n váº½ schematic NN architecture Ä‘Æ¡n giáº£n mÃ  khÃ´ng cáº§n láº§y lá»™i vá»›i draw.io http://alexlenail.me/NN-SVG/LeNet.html,,,,,
"Nhiá»u báº¡n muá»‘n lÃ m cÃ¡c model vá» language nhiá»u khi khÃ´ng cÃ³ dá»¯ liá»‡u trong khi facebook láº¡i quÃ¡ nhiá»u thÃ´ng tin luÃ´n. Do Ä‘Ã³ em máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¡c crawl dá»¯ liá»‡u tá»« facebook. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c
Em cÅ©ng biáº¿t lÃ  cÃ²n nhiá»u mÃ³n cáº§n lÃ m nhÆ°: fake ip, change agent... trÃ¡nh bá»‹ block. Náº¿u cÃ¡c báº¡n cáº§n em sáº½ lÃ m trong má»™t video khÃ¡c ah.","Nhiá»u báº¡n muá»‘n lÃ m cÃ¡c model vá» language nhiá»u khi khÃ´ng cÃ³ dá»¯ liá»‡u trong khi facebook láº¡i quÃ¡ nhiá»u thÃ´ng tin luÃ´n. Do Ä‘Ã³ em máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¡c crawl dá»¯ liá»‡u tá»« facebook. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c Em cÅ©ng biáº¿t lÃ  cÃ²n nhiá»u mÃ³n cáº§n lÃ m nhÆ°: fake ip, change agent... trÃ¡nh bá»‹ block. Náº¿u cÃ¡c báº¡n cáº§n em sáº½ lÃ m trong má»™t video khÃ¡c ah.",,,,,
"Viá»‡c tÃ¡ch ná»n Ä‘Æ°á»£c thá»±c hiá»‡n nhá» U^2-Net (U square net).
Náº¿u cÃ¡c báº¡n cÃ³ báº¥t cá»© cÃ¢u há»i gÃ¬ vá» app nÃ y, mÃ¬nh sáº½ nhiá»‡t tÃ¬nh tráº£ lá»i, hi vá»ng chÃºng ta sáº½ cÃ³ nhá»¯ng tháº£o luáº­n há»¯u Ã­ch. Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¡c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p tá»« má»i ngÆ°á»i áº¡!","Viá»‡c tÃ¡ch ná»n Ä‘Æ°á»£c thá»±c hiá»‡n nhá» U^2-Net (U square net). Náº¿u cÃ¡c báº¡n cÃ³ báº¥t cá»© cÃ¢u há»i gÃ¬ vá» app nÃ y, mÃ¬nh sáº½ nhiá»‡t tÃ¬nh tráº£ lá»i, hi vá»ng chÃºng ta sáº½ cÃ³ nhá»¯ng tháº£o luáº­n há»¯u Ã­ch. Ráº¥t mong nháº­n Ä‘Æ°á»£c cÃ¡c Ã½ kiáº¿n Ä‘Ã³ng gÃ³p tá»« má»i ngÆ°á»i áº¡!",,,,,
"Em Ä‘ang cÃ³ cÃ¹ng cÃ¢u há»i áº¡.
Má»i ngÆ°á»i tÆ° váº¥n giÃºp em, cáº£m Æ¡n má»i ngÆ°á»i.
Thá»±c táº­p sinh Machine Learning, Deep Learning - Jobs/Events - Diá»…n Ä‘Ã n Machine Learning cÆ¡ báº£n (machinelearningcoban.com)","Em Ä‘ang cÃ³ cÃ¹ng cÃ¢u há»i áº¡. Má»i ngÆ°á»i tÆ° váº¥n giÃºp em, cáº£m Æ¡n má»i ngÆ°á»i. Thá»±c táº­p sinh Machine Learning, Deep Learning - Jobs/Events - Diá»…n Ä‘Ã n Machine Learning cÆ¡ báº£n (machinelearningcoban.com)",,,,,
,nan,,,,,
"Facebook AI Introduces Linformer: A New Transformer Architecture To Catch Hate Speech And Content That Incites Violence
Paper: https://arxiv.org/abs/2006.04768?
Github: https://github.com/pytorch/fairseq/tree/master/examples/linformer?
#FacebookAi #Opensource #speech",Facebook AI Introduces Linformer: A New Transformer Architecture To Catch Hate Speech And Content That Incites Violence Paper: https://arxiv.org/abs/2006.04768? Github: https://github.com/pytorch/fairseq/tree/master/examples/linformer?,#FacebookAi	#Opensource	#speech,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i em Ä‘ang tÃ¬m cÃ¡ch cháº¡y model train báº±ng pytorch trÃªn C++, em cÃ³ tÃ¬m tháº¥y ONNX vÃ  Caffe2 nhÆ°ng em khÃ´ng biáº¿t convert sang format nÃ o vÃ  dÃ¹ng cÃ¡ch nÃ o Ä‘á»ƒ cháº¡y trÃªn C++. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡.
Em xin cáº£m Æ¡n áº¡.","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang tÃ¬m cÃ¡ch cháº¡y model train báº±ng pytorch trÃªn C++, em cÃ³ tÃ¬m tháº¥y ONNX vÃ  Caffe2 nhÆ°ng em khÃ´ng biáº¿t convert sang format nÃ o vÃ  dÃ¹ng cÃ¡ch nÃ o Ä‘á»ƒ cháº¡y trÃªn C++. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡. Em xin cáº£m Æ¡n áº¡.",,,,,
"Xin chÃ o má»i ngÆ°á»i,
Em Ä‘ang lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p, Ä‘á» tÃ i lÃ  vá» Nháº­n dáº¡ng ngÆ°á»i báº±ng vÃ¢n tay (fingertips) vÃ  giá»ng nÃ³i (speaker identification).
Má»i ngÆ°á»i cho em há»i lÃ  em nÃªn há»c khÃ³a há»c nÃ o cÃ³ liÃªn quan Ä‘áº¿n Ä‘á» tÃ i áº¡, em Ä‘á»c cÃ¡c bÃ i bÃ¡o vá»›i sÃ¡ch cÅ©ng nhiá»u mÃ  tháº¥y váº«n chÆ°a Ä‘á»§ áº¡
Em xin cáº£m Æ¡n!","Xin chÃ o má»i ngÆ°á»i, Em Ä‘ang lÃ m luáº­n vÄƒn tá»‘t nghiá»‡p, Ä‘á» tÃ i lÃ  vá» Nháº­n dáº¡ng ngÆ°á»i báº±ng vÃ¢n tay (fingertips) vÃ  giá»ng nÃ³i (speaker identification). Má»i ngÆ°á»i cho em há»i lÃ  em nÃªn há»c khÃ³a há»c nÃ o cÃ³ liÃªn quan Ä‘áº¿n Ä‘á» tÃ i áº¡, em Ä‘á»c cÃ¡c bÃ i bÃ¡o vá»›i sÃ¡ch cÅ©ng nhiá»u mÃ  tháº¥y váº«n chÆ°a Ä‘á»§ áº¡ Em xin cáº£m Æ¡n!",,,,,
"ChÃ o má»i ngÆ°á»i e Ä‘ang há»c ML áº¡. E cÃ³ 1 bÃ i táº­p lÃ  mÃ¬nh cÃ³ 1 táº­p dá»¯ liá»‡u yÃªu cáº§u xá»­ lÃ½ táº­p dá»¯ liá»‡u báº±ng phÆ°Æ¡ng phÃ¡p cÃ¢y quyáº¿t Ä‘á»‹nh. Trong táº­p dá»¯ liá»‡u á»Ÿ pháº§n nhÃ£n cÃ³ kiá»ƒu chuá»—i, e cháº¡y thÃ¬ gáº·p lá»—i nhÆ° bÃªn dÆ°á»›i mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.","ChÃ o má»i ngÆ°á»i e Ä‘ang há»c ML áº¡. E cÃ³ 1 bÃ i táº­p lÃ  mÃ¬nh cÃ³ 1 táº­p dá»¯ liá»‡u yÃªu cáº§u xá»­ lÃ½ táº­p dá»¯ liá»‡u báº±ng phÆ°Æ¡ng phÃ¡p cÃ¢y quyáº¿t Ä‘á»‹nh. Trong táº­p dá»¯ liá»‡u á»Ÿ pháº§n nhÃ£n cÃ³ kiá»ƒu chuá»—i, e cháº¡y thÃ¬ gáº·p lá»—i nhÆ° bÃªn dÆ°á»›i mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡.",,,,,
"[Deep Learning Project]
Má»™t sá»‘ project cá»§a cÃ¡c báº¡n há»c sinh khÃ³a Deep Learning.
1. Sinh thÆ¡ lá»¥c bÃ¡t: Dá»¯ liá»‡u lÃ  cÃ¡c bÃ i thÆ¡ lá»¥c bÃ¡t Ä‘Æ°á»£c crawl vá» tá»« thivien.net
2. Há»‡ thá»‘ng Chabot: dá»¯ liá»‡u láº¥y tá»« Ä‘oáº¡n há»™i thoáº¡i cá»§a cÃ¡c bá»™ phim.
3. ÄÃ¡nh giÃ¡ sáº£n pháº©m trÃªn trang Lazada thÃ´ng qua bÃ¬nh luáº­n cá»§a khÃ¡ch hÃ ng: Crawl bÃ¬nh luáº­n cá»§a má»—i sáº£n pháº©m, phÃ¢n loáº¡i bÃ¬nh luáº­n tÃ­ch cá»±c, tiÃªu cá»±c vÃ  Ä‘Æ°a ra khuyáº¿n nghá»‹ cho khÃ¡ch hÃ ng.
Slide vÃ  code tham kháº£o á»Ÿ Ä‘Ã¢y: https://drive.google.com/drive/folders/1ab6ct5xDF8oJmki8-0RJZl3V4mha6yew?usp=sharing
P/s: áº¢nh dÆ°á»›i Ä‘Æ°á»£c AI sinh ra sau khi cho há»c tá»« thÆ¡ lá»¥c bÃ¡t, má»i ngÆ°á»i tháº¥y sinh ra cÃ³ cÃ¢u 6/8, cÃ³ váº§n khÃ¡ tá»‘t.","[Deep Learning Project] Má»™t sá»‘ project cá»§a cÃ¡c báº¡n há»c sinh khÃ³a Deep Learning. 1. Sinh thÆ¡ lá»¥c bÃ¡t: Dá»¯ liá»‡u lÃ  cÃ¡c bÃ i thÆ¡ lá»¥c bÃ¡t Ä‘Æ°á»£c crawl vá» tá»« thivien.net 2. Há»‡ thá»‘ng Chabot: dá»¯ liá»‡u láº¥y tá»« Ä‘oáº¡n há»™i thoáº¡i cá»§a cÃ¡c bá»™ phim. 3. ÄÃ¡nh giÃ¡ sáº£n pháº©m trÃªn trang Lazada thÃ´ng qua bÃ¬nh luáº­n cá»§a khÃ¡ch hÃ ng: Crawl bÃ¬nh luáº­n cá»§a má»—i sáº£n pháº©m, phÃ¢n loáº¡i bÃ¬nh luáº­n tÃ­ch cá»±c, tiÃªu cá»±c vÃ  Ä‘Æ°a ra khuyáº¿n nghá»‹ cho khÃ¡ch hÃ ng. Slide vÃ  code tham kháº£o á»Ÿ Ä‘Ã¢y: https://drive.google.com/drive/folders/1ab6ct5xDF8oJmki8-0RJZl3V4mha6yew?usp=sharing P/s: áº¢nh dÆ°á»›i Ä‘Æ°á»£c AI sinh ra sau khi cho há»c tá»« thÆ¡ lá»¥c bÃ¡t, má»i ngÆ°á»i tháº¥y sinh ra cÃ³ cÃ¢u 6/8, cÃ³ váº§n khÃ¡ tá»‘t.",,,,,
"Má»i ngÆ°á»i giÃºp em vá»›i áº¡, em cáº£m Æ¡n mn ğŸ¥°ğŸ¥°","Má»i ngÆ°á»i giÃºp em vá»›i áº¡, em cáº£m Æ¡n mn",,,,,
"Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang lÃ m má»™t Ä‘á» tÃ i nhá» lÃ  so sÃ¡nh cÃ¡c cÆ¡ cháº¿ kiá»ƒm soÃ¡t (regularization) cho bÃ i toÃ¡n phÃ¢n loáº¡i (classification) trÃªn máº«u dá»¯ liá»‡u sá»‘ viáº¿t tay MNIST. CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘ang so sÃ¡nh á»Ÿ Ä‘Ã¢y lÃ  Lasso, minimax concave penalty (MCP), smoothly clipped absolute deviation (SCAD). CÃ¡c thÆ° viá»‡n mÃ¬nh tÃ¬m tháº¥y trÃªn R hoáº·c Python Ä‘á»u khÃ´ng há»— trá»£ cÃ¹ng lÃºc softmax (multinomial) regression vÃ  cÃ¡c penalty á»›t trÃªn ngoáº¡i trá»« thÆ° viá»‡n ncpen trÃªn R.
MÃ¬nh sá»­ dá»¥ng thÆ° viá»‡n ncpen thÃ¬ bá»‹ bÃ¡o lá»—i std::bad_alloc. CÃ³ bÃ¡c nÃ o á»Ÿ Ä‘Ã¢y Ä‘Ã£ tá»«ng sá»­ dá»¥ng qua thÆ° viá»‡n nÃ y xin giÃºp mÃ¬nh lá»—i nÃ y hoáº·c cÃ³ báº¥t cá»© thÆ° viá»‡n nÃ o trÃªn R hay Python cÃ³ há»— trá»£ softmax (multinomial) regression cÃ¹ng vá»›i cÃ¡c penalty á»Ÿ trÃªn thÃ¬ cho mÃ¬nh xin. Cáº£m Æ¡n má»i ngÆ°á»i!
Mong ad duyá»‡t bÃ i
TÃ i liá»‡u gá»‘c","Xin chÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang lÃ m má»™t Ä‘á» tÃ i nhá» lÃ  so sÃ¡nh cÃ¡c cÆ¡ cháº¿ kiá»ƒm soÃ¡t (regularization) cho bÃ i toÃ¡n phÃ¢n loáº¡i (classification) trÃªn máº«u dá»¯ liá»‡u sá»‘ viáº¿t tay MNIST. CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘ang so sÃ¡nh á»Ÿ Ä‘Ã¢y lÃ  Lasso, minimax concave penalty (MCP), smoothly clipped absolute deviation (SCAD). CÃ¡c thÆ° viá»‡n mÃ¬nh tÃ¬m tháº¥y trÃªn R hoáº·c Python Ä‘á»u khÃ´ng há»— trá»£ cÃ¹ng lÃºc softmax (multinomial) regression vÃ  cÃ¡c penalty á»›t trÃªn ngoáº¡i trá»« thÆ° viá»‡n ncpen trÃªn R. MÃ¬nh sá»­ dá»¥ng thÆ° viá»‡n ncpen thÃ¬ bá»‹ bÃ¡o lá»—i std::bad_alloc. CÃ³ bÃ¡c nÃ o á»Ÿ Ä‘Ã¢y Ä‘Ã£ tá»«ng sá»­ dá»¥ng qua thÆ° viá»‡n nÃ y xin giÃºp mÃ¬nh lá»—i nÃ y hoáº·c cÃ³ báº¥t cá»© thÆ° viá»‡n nÃ o trÃªn R hay Python cÃ³ há»— trá»£ softmax (multinomial) regression cÃ¹ng vá»›i cÃ¡c penalty á»Ÿ trÃªn thÃ¬ cho mÃ¬nh xin. Cáº£m Æ¡n má»i ngÆ°á»i! Mong ad duyá»‡t bÃ i TÃ i liá»‡u gá»‘c",,,,,
"Hi group,
Em viáº¿t stt mong ACE share tÃªn má»™t vÃ i tutorial/book hay vá» xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c giai Ä‘oáº¡n apply training model.
Em cáº£m Æ¡n.","Hi group, Em viáº¿t stt mong ACE share tÃªn má»™t vÃ i tutorial/book hay vá» xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c giai Ä‘oáº¡n apply training model. Em cáº£m Æ¡n.",,,,,
Xin phÃ©p ad cho mÃ¬nh chia sáº» vá» blog nho nhá» cá»§a mÃ¬nh . MÃ¬nh lÃ  sinh viÃªn cÅ©ng Ä‘ang nghiÃªn cá»©u vá» amngr machine learning . MÃ¬nh táº¡o ra 1 blog vá»›i má»¥c Ä‘Ã­ch chia sáº» láº¡i nhá»¯ng gÃ¬ mÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c tá»« trÃªn máº¡ng ... ÄÃ¢y lÃ  bÃ i má»›i nháº¥t cá»§a blog . CÃ¡ch nháº­n diá»‡n váº­t thá»ƒ realtime vá»›i opencv,Xin phÃ©p ad cho mÃ¬nh chia sáº» vá» blog nho nhá» cá»§a mÃ¬nh . MÃ¬nh lÃ  sinh viÃªn cÅ©ng Ä‘ang nghiÃªn cá»©u vá» amngr machine learning . MÃ¬nh táº¡o ra 1 blog vá»›i má»¥c Ä‘Ã­ch chia sáº» láº¡i nhá»¯ng gÃ¬ mÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c tá»« trÃªn máº¡ng ... ÄÃ¢y lÃ  bÃ i má»›i nháº¥t cá»§a blog . CÃ¡ch nháº­n diá»‡n váº­t thá»ƒ realtime vá»›i opencv,,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m vá»›i bÃ i toÃ¡n bÃ³c tÃ¡ch Ä‘Æ°á»£c layout cá»§a 1 bÃ i bÃ¡o Ä‘Æ¡n giáº£n. Hiá»‡n táº¡i em sá»­ dá»¥ng split and merge tá»« káº¿t quáº£ tráº£ ra cá»§a pdf minner vÃ  cho ra káº¿t quáº£ khÃ¡ á»•n nhÆ°ng khi gáº·p cÃ¡c bÃ i bÃ¡o cÃ³ thá»© tá»± Ä‘á»c phá»©c táº¡p hÆ¡n thÃ¬ káº¿t quáº£ khÃ´ng tá»‘t.
Hiá»‡n táº¡i em Ä‘ang cÃ³ hÆ°á»›ng suy nghÄ© tá»›i viá»‡c ghÃ©p cÃ¡c cÃ¢u dá»±a theo Ã½ nghÄ©a. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin 1 vÃ i gá»£i Ã½ hoáº·c cÃ¡c hÆ°á»›ng tiáº¿p cáº­n Ä‘Æ°á»£c khÃ´ng áº¡?
Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c áº¡.","ChÃ o má»i ngÆ°á»i, hiá»‡n táº¡i em Ä‘ang lÃ m vá»›i bÃ i toÃ¡n bÃ³c tÃ¡ch Ä‘Æ°á»£c layout cá»§a 1 bÃ i bÃ¡o Ä‘Æ¡n giáº£n. Hiá»‡n táº¡i em sá»­ dá»¥ng split and merge tá»« káº¿t quáº£ tráº£ ra cá»§a pdf minner vÃ  cho ra káº¿t quáº£ khÃ¡ á»•n nhÆ°ng khi gáº·p cÃ¡c bÃ i bÃ¡o cÃ³ thá»© tá»± Ä‘á»c phá»©c táº¡p hÆ¡n thÃ¬ káº¿t quáº£ khÃ´ng tá»‘t. Hiá»‡n táº¡i em Ä‘ang cÃ³ hÆ°á»›ng suy nghÄ© tá»›i viá»‡c ghÃ©p cÃ¡c cÃ¢u dá»±a theo Ã½ nghÄ©a. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ thá»ƒ cho em xin 1 vÃ i gá»£i Ã½ hoáº·c cÃ¡c hÆ°á»›ng tiáº¿p cáº­n Ä‘Æ°á»£c khÃ´ng áº¡? Em cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c áº¡.",,,,,
Má»i ngÆ°á»i cho e há»i khÃ¡i niá»‡m Convolutional Neural Network cÃ³ pháº£i lÃ  thuáº­t toÃ¡n ko áº¡,Má»i ngÆ°á»i cho e há»i khÃ¡i niá»‡m Convolutional Neural Network cÃ³ pháº£i lÃ  thuáº­t toÃ¡n ko áº¡,,,,,
"DEEP LEARNING AND BEYOND: A TUTORIAL
On Dec 1st 2020 I will give a #tutorial on the current state of the arts in #DeepLearning and what might push the field forward beyond what we are experiencing. The tutorial is hosted by the 2020 IEEE Symposium Series on Computational #Intelligence, running virtual this year.
The topics include #transformer, #graph neural networks, deep #unsupervised learning, #BERT, fast weights, neural #memories, neural #reasoning, and neural #theoryofmind.
Slides are included here. Video will be available after the talk: https://truyentran.github.io/ssci2020-tute.html","DEEP LEARNING AND BEYOND: A TUTORIAL On Dec 1st 2020 I will give a on the current state of the arts in and what might push the field forward beyond what we are experiencing. The tutorial is hosted by the 2020 IEEE Symposium Series on Computational running virtual this year. The topics include neural networks, deep learning, fast weights, neural neural and neural Slides are included here. Video will be available after the talk: https://truyentran.github.io/ssci2020-tute.html","#tutorial	#DeepLearning	#Intelligence,	#transformer,	#graph	#unsupervised	#BERT,	#memories,	#reasoning,	#theoryofmind.",,,,
"https://youtu.be/Zg0t3f90n6Q
bai huong dan cua anh Le Viet Khanh dung tensorflow lite tren mobile device",https://youtu.be/Zg0t3f90n6Q bai huong dan cua anh Le Viet Khanh dung tensorflow lite tren mobile device,,,,,
"ChÃ o cÃ¡c báº¡n,
MÃ¬nh má»›i tÃ¬m hiá»ƒu má»™t chÃºt vá» computer vision, mÃ¬nh tháº¥y cÃ³ má»™t khÃ¡i niá»‡m lÃ  visual codebook. MÃ¬nh cÅ©ng khÃ´ng hiá»ƒu cá»¥ thá»ƒ Ã½ nghÄ©a cá»§a nÃ³, vÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ generate ra nÃ³. MÃ¬nh tháº¥y nÃ³ hay Ä‘Æ°á»£c nháº¯c tá»›i cÃ¹ng vá»›i bÃ i toÃ¡n k means clustering.
Báº¡n nÃ o Ä‘Ã³ cÃ³ thá»ƒ giáº£i thÃ­ch hoáº·c giá»›i thiá»‡u tÃ i liá»‡u Ä‘á»ƒ giáº£i thÃ­ch vá» chá»§ Ä‘á» nÃ y Ä‘Æ°á»£c khÃ´ng nhá»‰ ? MÃ¬nh Ä‘Ã£ tham kháº£o cuá»‘n Multiple View vÃ  cuá»‘n CV cá»§a Szeliski nhÆ°ng khÃ´ng tháº¥y nÃ³i cá»¥ thá»ƒ.
Thanks in advance !","ChÃ o cÃ¡c báº¡n, MÃ¬nh má»›i tÃ¬m hiá»ƒu má»™t chÃºt vá» computer vision, mÃ¬nh tháº¥y cÃ³ má»™t khÃ¡i niá»‡m lÃ  visual codebook. MÃ¬nh cÅ©ng khÃ´ng hiá»ƒu cá»¥ thá»ƒ Ã½ nghÄ©a cá»§a nÃ³, vÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ generate ra nÃ³. MÃ¬nh tháº¥y nÃ³ hay Ä‘Æ°á»£c nháº¯c tá»›i cÃ¹ng vá»›i bÃ i toÃ¡n k means clustering. Báº¡n nÃ o Ä‘Ã³ cÃ³ thá»ƒ giáº£i thÃ­ch hoáº·c giá»›i thiá»‡u tÃ i liá»‡u Ä‘á»ƒ giáº£i thÃ­ch vá» chá»§ Ä‘á» nÃ y Ä‘Æ°á»£c khÃ´ng nhá»‰ ? MÃ¬nh Ä‘Ã£ tham kháº£o cuá»‘n Multiple View vÃ  cuá»‘n CV cá»§a Szeliski nhÆ°ng khÃ´ng tháº¥y nÃ³i cá»¥ thá»ƒ. Thanks in advance !",,,,,
"Tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh reinforcement learning vá»›i data augmentation vÃ  latent space representations
BÃ¡c nÃ o Ä‘ang lÃ m vá» simulator hay forecasting cÃ³ thá»ƒ apply",Tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh reinforcement learning vá»›i data augmentation vÃ  latent space representations BÃ¡c nÃ o Ä‘ang lÃ m vá» simulator hay forecasting cÃ³ thá»ƒ apply,,,,,
"ChÃ o cÃ¡c anh chá»‹, má»i ngÆ°á»i cho em há»i 1 cÃ¢u vá» xá»­ lÃ½ sá»‘ liá»‡u. Giáº£ sá»­ em cÃ³ 2 bá»™ X, Y chá»©a 10 thÃ´ng sá»‘ Ä‘áº§u vÃ o X = (x1, x2, ..., x10) vÃ  Y = (y1, y2, ..., y10).
Giáº£ sá»­ Z chá»©a dá»¯ liá»‡u Ä‘áº§u ra phá»¥ thuá»™c vÃ o X vÃ  Y: X, Y -> Z.
Váº¥n Ä‘á» lÃ , vá»›i má»—i cáº·p (x, y) sáº½ cho ra 5 giÃ¡ trá»‹ z observed (data láº¥y tá»« experiments nÃªn má»—i láº§n lÃ m experiments láº¡i ra 1 sá»‘) vÃ  nÃ³ khÃ´ng khÃ¡c biá»‡t quÃ¡ quÃ¡ lá»›n nhÆ°ng váº«n cÃ³ sá»± khÃ¡c biá»‡t.
CÃ¢u há»i cá»§a em lÃ , trong trÆ°á»ng há»£p trÃªn má»i ngÆ°á»i xá»­ lÃ½ tháº¿ nÃ o áº¡ ? láº¥y giÃ¡ trá»‹ Mean cá»§a 5 z Ä‘Ã³ Ä‘á»ƒ táº¡o dataset má»—i x, y chá»‰ cho ra 1 z hay cÃ³ cÃ¡ch nÃ o khÃ¡c áº¡ ? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.
NgoÃ i ra, má»i ngÆ°á»i thÆ°á»ng dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ Ä‘á»ƒ remove outliers mÃ  khÃ´ng lÃ m giáº£m hoáº·c máº¥t properties cá»§a dataset áº¡ ?","ChÃ o cÃ¡c anh chá»‹, má»i ngÆ°á»i cho em há»i 1 cÃ¢u vá» xá»­ lÃ½ sá»‘ liá»‡u. Giáº£ sá»­ em cÃ³ 2 bá»™ X, Y chá»©a 10 thÃ´ng sá»‘ Ä‘áº§u vÃ o X = (x1, x2, ..., x10) vÃ  Y = (y1, y2, ..., y10). Giáº£ sá»­ Z chá»©a dá»¯ liá»‡u Ä‘áº§u ra phá»¥ thuá»™c vÃ o X vÃ  Y: X, Y -> Z. Váº¥n Ä‘á» lÃ , vá»›i má»—i cáº·p (x, y) sáº½ cho ra 5 giÃ¡ trá»‹ z observed (data láº¥y tá»« experiments nÃªn má»—i láº§n lÃ m experiments láº¡i ra 1 sá»‘) vÃ  nÃ³ khÃ´ng khÃ¡c biá»‡t quÃ¡ quÃ¡ lá»›n nhÆ°ng váº«n cÃ³ sá»± khÃ¡c biá»‡t. CÃ¢u há»i cá»§a em lÃ , trong trÆ°á»ng há»£p trÃªn má»i ngÆ°á»i xá»­ lÃ½ tháº¿ nÃ o áº¡ ? láº¥y giÃ¡ trá»‹ Mean cá»§a 5 z Ä‘Ã³ Ä‘á»ƒ táº¡o dataset má»—i x, y chá»‰ cho ra 1 z hay cÃ³ cÃ¡ch nÃ o khÃ¡c áº¡ ? Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u. NgoÃ i ra, má»i ngÆ°á»i thÆ°á»ng dÃ¹ng phÆ°Æ¡ng phÃ¡p gÃ¬ Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ Ä‘á»ƒ remove outliers mÃ  khÃ´ng lÃ m giáº£m hoáº·c máº¥t properties cá»§a dataset áº¡ ?",,,,,
"Em Ä‘ang lÃ m Ä‘á»“ Ã¡n Machine Learning, phÃ¡t hiá»‡n PHP Webshell dá»±a trÃªn há»c mÃ¡y sá»­ dá»¥ng CNN Model. Ai cÃ³ phÆ°Æ¡ng hÆ°á»›ng nÃ o chia sáº» cho e vá»›i áº¡","Em Ä‘ang lÃ m Ä‘á»“ Ã¡n Machine Learning, phÃ¡t hiá»‡n PHP Webshell dá»±a trÃªn há»c mÃ¡y sá»­ dá»¥ng CNN Model. Ai cÃ³ phÆ°Æ¡ng hÆ°á»›ng nÃ o chia sáº» cho e vá»›i áº¡",,,,,
"Anh,chá»‹ nÃ o Ä‘Ã£ cÃ i Ä‘Æ°á»£c thuáº­t toÃ¡n BERT cháº¡y trÃªn colab cho em há»i lÃ  cÃ³ bá»‹ lá»—i phiÃªn báº£n khÃ´ng áº¡. Em váº­t lá»™n máº¥y tuáº§n báº¥t lá»±c rá»“i, haizz
Code: https://colab.research.google.com/drive/1b_XfIgexXofEh4zjQmNxNImQvCVOqKIl?usp=sharing&fbclid=IwAR3idu4q3FM-XI9XwsxPZzJluXwBjT6IytVWBbflahO_XWBVhVXTw82GyWg
Folder:
https://drive.google.com/drive/u/1/folders/1GjxRGjGYHUafgPso2cSGo98ECEJ_QTPR?fbclid=IwAR3R20FX24ISAe9mG9U7Vf4buz70M0nKY40UHrlihBoDtfWnod7QL-LdMrI","Anh,chá»‹ nÃ o Ä‘Ã£ cÃ i Ä‘Æ°á»£c thuáº­t toÃ¡n BERT cháº¡y trÃªn colab cho em há»i lÃ  cÃ³ bá»‹ lá»—i phiÃªn báº£n khÃ´ng áº¡. Em váº­t lá»™n máº¥y tuáº§n báº¥t lá»±c rá»“i, haizz Code: https://colab.research.google.com/drive/1b_XfIgexXofEh4zjQmNxNImQvCVOqKIl?usp=sharing&fbclid=IwAR3idu4q3FM-XI9XwsxPZzJluXwBjT6IytVWBbflahO_XWBVhVXTw82GyWg Folder: https://drive.google.com/drive/u/1/folders/1GjxRGjGYHUafgPso2cSGo98ECEJ_QTPR?fbclid=IwAR3R20FX24ISAe9mG9U7Vf4buz70M0nKY40UHrlihBoDtfWnod7QL-LdMrI",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n vÃ o trong comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn sinh, tuyá»ƒn dá»¥ng, sá»± kiá»‡n vÃ o trong comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n ngÃ y má»›i thÃ¡ng má»›i vui váº».",,,,,
mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» machine learning. MÃ¬nh Ä‘ang crawl 2 web truyá»‡n nhÆ°ng cÃ³ nhá»¯ng truyá»‡n 2 bÃªn tÃªn nÃ³ Ä‘áº·t khÃ¡c nhau khÃ´ng giá»‘ng nhau hoÃ n toÃ n mÃ¬nh muá»‘n sá»­ dá»¥ng ml Ä‘á»ƒ dá»± Ä‘oÃ¡n truyá»‡n Ä‘Ã£ cÃ³ chÆ°a dá»±a vÃ o name vÃ  other name thÃ¬ cáº§n tÃ¬m hiá»ƒu thÆ° viá»‡n nÃ o,mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» machine learning. MÃ¬nh Ä‘ang crawl 2 web truyá»‡n nhÆ°ng cÃ³ nhá»¯ng truyá»‡n 2 bÃªn tÃªn nÃ³ Ä‘áº·t khÃ¡c nhau khÃ´ng giá»‘ng nhau hoÃ n toÃ n mÃ¬nh muá»‘n sá»­ dá»¥ng ml Ä‘á»ƒ dá»± Ä‘oÃ¡n truyá»‡n Ä‘Ã£ cÃ³ chÆ°a dá»±a vÃ o name vÃ  other name thÃ¬ cáº§n tÃ¬m hiá»ƒu thÆ° viá»‡n nÃ o,,,,,
"[Product quantization]
ChÃ o má»i ngÆ°á»i
mÃ¬nh dÃ¹ng thÆ° viá»‡n PKmeans trong Python Ä‘á»ƒ nÃ©n dataset ban Ä‘áº§u.má»¥c Ä‘Ã­ch lÃ m giáº£m sá»‘ chiá»u cá»§a bá»™ dataset.
Library: https://pypi.org/project/pqkmeans/
code on github : https://github.com/DwangoMediaVillage/pqkmeans
hiá»‡n táº¡i mÃ¬nh Ä‘ang bá»‹ máº¯c pháº§n get subvector sau khi chuyá»ƒn Ä‘á»•i tá»« vector nhiá»u chiá»u sang sub-vector vá»›i khÃ´ng gian nhá» hÆ¡n.
vÃ­ dá»¥ : vector (1000, 100 dimension ) = compress -> 5 láº§n x (1000 x 20 dimension).
sau Ä‘Ã³ mÃ¬nh muá»‘n get tá»«ng subvector Ä‘á»ƒ test tá»«ng subvector vá»›i tá»«ng thuáº­t toÃ¡n clustering vÃ  thá»‘ng kÃª lá»—i cá»§a tÆ°ng thuat toÃ¡n, rÃ¢t tiáº¿c pháº§n subvector chÆ°a cÃ³ láº¥y Ä‘Æ°á»£c.
trong vÃ­ dá»¥ cá»§a há» thÃ¬ chá»‰ cÃ³ pháº§n nÃ©n dataset . (thÆ° má»¥c tutorial /1 ). cÃ²n pháº§n láº¥y tÆ°ng subvector thÃ¬ k thÃ¢y nÃ³i Ä‘áº¿n .
CÃ¡c báº¡n Ä‘Ã£ tá»«ng lÃ m Product quantization thÃ¬ giup mÃ¬nh chá»— nÃ y nhÃ© ?
cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin .","[Product quantization] ChÃ o má»i ngÆ°á»i mÃ¬nh dÃ¹ng thÆ° viá»‡n PKmeans trong Python Ä‘á»ƒ nÃ©n dataset ban Ä‘áº§u.má»¥c Ä‘Ã­ch lÃ m giáº£m sá»‘ chiá»u cá»§a bá»™ dataset. Library: https://pypi.org/project/pqkmeans/ code on github : https://github.com/DwangoMediaVillage/pqkmeans hiá»‡n táº¡i mÃ¬nh Ä‘ang bá»‹ máº¯c pháº§n get subvector sau khi chuyá»ƒn Ä‘á»•i tá»« vector nhiá»u chiá»u sang sub-vector vá»›i khÃ´ng gian nhá» hÆ¡n. vÃ­ dá»¥ : vector (1000, 100 dimension ) = compress -> 5 láº§n x (1000 x 20 dimension). sau Ä‘Ã³ mÃ¬nh muá»‘n get tá»«ng subvector Ä‘á»ƒ test tá»«ng subvector vá»›i tá»«ng thuáº­t toÃ¡n clustering vÃ  thá»‘ng kÃª lá»—i cá»§a tÆ°ng thuat toÃ¡n, rÃ¢t tiáº¿c pháº§n subvector chÆ°a cÃ³ láº¥y Ä‘Æ°á»£c. trong vÃ­ dá»¥ cá»§a há» thÃ¬ chá»‰ cÃ³ pháº§n nÃ©n dataset . (thÆ° má»¥c tutorial /1 ). cÃ²n pháº§n láº¥y tÆ°ng subvector thÃ¬ k thÃ¢y nÃ³i Ä‘áº¿n . CÃ¡c báº¡n Ä‘Ã£ tá»«ng lÃ m Product quantization thÃ¬ giup mÃ¬nh chá»— nÃ y nhÃ© ? cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin .",,,,,
"Em dÃ¹ng YOLOv4 Ä‘á»ƒ train bá»™ data PlantDoc trÃªn roboflow vá»›i 2569 áº£nh vÃ  30 class, nhÆ°ng Ä‘áº¿n táº­n 20000 iterations mÃ  loss váº«n chÆ°a xuá»‘ng dÆ°á»›i 1. Má»i ngÆ°á»i cho em há»i lÃ :
Theo hÆ°á»›ng dáº«n cá»§a darknet thÃ¬ sá»‘ láº§n iteration = sá»‘ class*2000, tá»©c lÃ  sau 60000 thÃ¬ liá»‡u nÃ³ cÃ³ Ä‘áº£m báº£o káº¿t quáº£ tá»‘t khÃ´ng áº¡? 
VÃ  60000 láº§n iteration (tá»‘n khoáº£ng 65 tiáº¿ng khi dÃ¹ng colab pro) lÃ  bÃ¬nh thÆ°á»ng áº¡?
CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ nÃ³ há»™i tá»¥ sá»›m hÆ¡n khÃ´ng áº¡? 
Em cÃ³ biáº¿t Zalo hiá»‡n cÃ³ 1 cuá»™c thi trong Ä‘Ã³ cÃ³ bÃ i nháº­n diá»‡n biá»ƒn sá»‘ xe mÃ  ko Ä‘Æ°á»£c dÃ¹ng pretrained. Máº·c dÃ¹ ko tham gia, nhÆ°ng em cÃ³ tháº¯c máº¯c lÃ  vá»›i bá»™ dataset khoáº£ng 2000 áº£nh trÃªn Ä‘Ã£ tá»‘n ~65h train, thÃ¬ má»i ngÆ°á»i dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ tá»‘i Æ°u train bá»™ dataset ~16000 áº£nh (hÃ¬nh nhÆ° váº­y) váº­y áº¡?
Dataset: https://public.roboflow.com/object-detection/plantdoc
Em cáº£m Æ¡n. ","Em dÃ¹ng YOLOv4 Ä‘á»ƒ train bá»™ data PlantDoc trÃªn roboflow vá»›i 2569 áº£nh vÃ  30 class, nhÆ°ng Ä‘áº¿n táº­n 20000 iterations mÃ  loss váº«n chÆ°a xuá»‘ng dÆ°á»›i 1. Má»i ngÆ°á»i cho em há»i lÃ : Theo hÆ°á»›ng dáº«n cá»§a darknet thÃ¬ sá»‘ láº§n iteration = sá»‘ class*2000, tá»©c lÃ  sau 60000 thÃ¬ liá»‡u nÃ³ cÃ³ Ä‘áº£m báº£o káº¿t quáº£ tá»‘t khÃ´ng áº¡? VÃ  60000 láº§n iteration (tá»‘n khoáº£ng 65 tiáº¿ng khi dÃ¹ng colab pro) lÃ  bÃ¬nh thÆ°á»ng áº¡? CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ nÃ³ há»™i tá»¥ sá»›m hÆ¡n khÃ´ng áº¡? Em cÃ³ biáº¿t Zalo hiá»‡n cÃ³ 1 cuá»™c thi trong Ä‘Ã³ cÃ³ bÃ i nháº­n diá»‡n biá»ƒn sá»‘ xe mÃ  ko Ä‘Æ°á»£c dÃ¹ng pretrained. Máº·c dÃ¹ ko tham gia, nhÆ°ng em cÃ³ tháº¯c máº¯c lÃ  vá»›i bá»™ dataset khoáº£ng 2000 áº£nh trÃªn Ä‘Ã£ tá»‘n ~65h train, thÃ¬ má»i ngÆ°á»i dÃ¹ng phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ tá»‘i Æ°u train bá»™ dataset ~16000 áº£nh (hÃ¬nh nhÆ° váº­y) váº­y áº¡? Dataset: https://public.roboflow.com/object-detection/plantdoc Em cáº£m Æ¡n.",,,,,
"Em chÃ o cÃ¡c Anh Chá»‹. Em lÃ  newbie má»›i lÃ m quen vá»›i ML thÃ´i. Em cÃ³ má»™t bÃ i táº­p láº¥y trong M5 competition. Nhiá»‡m vá»¥ lÃ  dÃ¹ng thuáº­t toÃ¡n Moving Average Ä‘á»ƒ dá»± Ä‘oÃ¡n sá»‘ sáº£n pháº©m Ä‘c bÃ¡n ra trong cÃ¡c ngÃ y tiáº¿p theo. CÃ¡c anh chá»‹ cÃ³ thá»ƒ giÃºp em má»™t sá»‘ tháº¯c máº¯c Ä‘Æ°á»£c khÃ´ng áº¡?
1/ YÃªu cáº§u nhÆ° trong hÃ¬nh váº½, thÃ¬ cÃ³ chá»— â€œk is selected from [2,5] by minimizing MSEâ€ em khÃ´ng hiá»ƒu xá»­ lÃ­ vá»›i nÃ³ ntn?
2/ GiÃ¡ tiá»n sp thÃ¬ liÃªn quan ntn Ä‘áº¿n sá»‘ lÆ°á»£ng bÃ¡n ra váº­y áº¡?
Em cÃ¡m Æ¡n mng.","Em chÃ o cÃ¡c Anh Chá»‹. Em lÃ  newbie má»›i lÃ m quen vá»›i ML thÃ´i. Em cÃ³ má»™t bÃ i táº­p láº¥y trong M5 competition. Nhiá»‡m vá»¥ lÃ  dÃ¹ng thuáº­t toÃ¡n Moving Average Ä‘á»ƒ dá»± Ä‘oÃ¡n sá»‘ sáº£n pháº©m Ä‘c bÃ¡n ra trong cÃ¡c ngÃ y tiáº¿p theo. CÃ¡c anh chá»‹ cÃ³ thá»ƒ giÃºp em má»™t sá»‘ tháº¯c máº¯c Ä‘Æ°á»£c khÃ´ng áº¡? 1/ YÃªu cáº§u nhÆ° trong hÃ¬nh váº½, thÃ¬ cÃ³ chá»— â€œk is selected from [2,5] by minimizing MSEâ€ em khÃ´ng hiá»ƒu xá»­ lÃ­ vá»›i nÃ³ ntn? 2/ GiÃ¡ tiá»n sp thÃ¬ liÃªn quan ntn Ä‘áº¿n sá»‘ lÆ°á»£ng bÃ¡n ra váº­y áº¡? Em cÃ¡m Æ¡n mng.",,,,,
"[Xin phÃ©p Admin] ChÃ o má»i ngÆ°á»i, post nÃ y dÃ nh cho nhá»¯ng anh/chá»‹/báº¡n quan tÃ¢m Ä‘áº¿n metaheuristic optimization trong machine learning vÃ  AI áº¡.
[Update: Matlab code: https://www.mathworks.com/matlabcentral/fileexchange/76299-forensic-based-investigation-algorithm-fbi]
Náº¿u má»i ngÆ°á»i Ä‘ang tÃ¬m 1 thuáº­t toÃ¡n tá»‘i Æ°u xuáº¥t sáº¯c outperform cÃ¡c thuáº­t toÃ¡n khÃ¡c (gá»“m nhá»¯ng thuáº­t toÃ¡n cÅ© rÃ­ch nhÆ° GA, PSO, DE,... hay nhá»¯ng thuáº­t toÃ¡n gáº§n Ä‘Ã¢y nhÆ° SOS, TLBO, WOA,...), thÃ¬ hÃ£y thá»­ thuáº­t toÃ¡n FBI cá»§a mÃ¬nh, vá»«a Ä‘Æ°á»£c publish trÃªn Applied Soft Computing. NgÆ°á»i VN dÃ¹ng hÃ ng VN cháº¥t lÆ°á»£ng cao áº¡, mÃ¬nh tin má»i ngÆ°á»i sáº½ khÃ´ng tháº¥t vá»ng ^^ English below áº¡!
To Researchers: If you are facing an optimization problem, my newly developed algorithm can help.
The main motivation for developing a new algorithm is its capacity to effectively and efficiently solve various optimization problems. A novel optimization method, the forensic-based investigation algorithm (FBI), is developed to determine global solutions for continuous nonlinear functions with low computational effort and high accuracy. FBI is inspired by the suspect investigationâ€“locationâ€“pursuit process of police officers. Main features of FBI:
(1) FBI is a parameter-free optimization algorithm.
(2) FBI remarkably outperformed the well-known and newly developed algorithms.
(3) FBI has short computational time and rapidly reaches the optimal solutions in solving problems.
(4) FBI is effective in solving high-dimensional problems (D=1000).
(5) FBI structure has two teams that well balance exploration and exploitation.
Details can be found at: Chou J-S, Nguyen N-M, FBI inspired meta-optimization, Applied Soft Computing, 2020:106339, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2020.106339.
I would like to thank Distinguished Professor Jui-Sheng Chou, my husband Prof. Minh-Tu Cao, and my good friend Dr. Duc-Hoc Tran for their great supports.","[Xin phÃ©p Admin] ChÃ o má»i ngÆ°á»i, post nÃ y dÃ nh cho nhá»¯ng anh/chá»‹/báº¡n quan tÃ¢m Ä‘áº¿n metaheuristic optimization trong machine learning vÃ  AI áº¡. [Update: Matlab code: https://www.mathworks.com/matlabcentral/fileexchange/76299-forensic-based-investigation-algorithm-fbi] Náº¿u má»i ngÆ°á»i Ä‘ang tÃ¬m 1 thuáº­t toÃ¡n tá»‘i Æ°u xuáº¥t sáº¯c outperform cÃ¡c thuáº­t toÃ¡n khÃ¡c (gá»“m nhá»¯ng thuáº­t toÃ¡n cÅ© rÃ­ch nhÆ° GA, PSO, DE,... hay nhá»¯ng thuáº­t toÃ¡n gáº§n Ä‘Ã¢y nhÆ° SOS, TLBO, WOA,...), thÃ¬ hÃ£y thá»­ thuáº­t toÃ¡n FBI cá»§a mÃ¬nh, vá»«a Ä‘Æ°á»£c publish trÃªn Applied Soft Computing. NgÆ°á»i VN dÃ¹ng hÃ ng VN cháº¥t lÆ°á»£ng cao áº¡, mÃ¬nh tin má»i ngÆ°á»i sáº½ khÃ´ng tháº¥t vá»ng ^^ English below áº¡! To Researchers: If you are facing an optimization problem, my newly developed algorithm can help. The main motivation for developing a new algorithm is its capacity to effectively and efficiently solve various optimization problems. A novel optimization method, the forensic-based investigation algorithm (FBI), is developed to determine global solutions for continuous nonlinear functions with low computational effort and high accuracy. FBI is inspired by the suspect investigationâ€“locationâ€“pursuit process of police officers. Main features of FBI: (1) FBI is a parameter-free optimization algorithm. (2) FBI remarkably outperformed the well-known and newly developed algorithms. (3) FBI has short computational time and rapidly reaches the optimal solutions in solving problems. (4) FBI is effective in solving high-dimensional problems (D=1000). (5) FBI structure has two teams that well balance exploration and exploitation. Details can be found at: Chou J-S, Nguyen N-M, FBI inspired meta-optimization, Applied Soft Computing, 2020:106339, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2020.106339. I would like to thank Distinguished Professor Jui-Sheng Chou, my husband Prof. Minh-Tu Cao, and my good friend Dr. Duc-Hoc Tran for their great supports.",,,,,
"ChÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n nhá» mong Ä‘Æ°á»£c tÆ° váº¥n (mÃ¬nh lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o): má»™t bá»™ sá»‘ liá»‡u cá»§a mÃ¬nh cÃ³ 3 inputs vÃ  7 outputs. 3 cá»™t bÃ´i mÃ u vÃ ng trong file excel dÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c inputs (x1, x2, x3), nhá»¯ng cá»™t cÃ²n láº¡i (7 cá»™t) lÃ  cÃ¡c outputs (f1, f2,..., f7). MÃ¬nh Ä‘Ã£ sá»­ dá»¥ng há»“i quy tuyáº¿n tÃ­nh á»Ÿ dáº¡ng fi=W0+W1*x1+W2*x2+W3*x3 (vá»›i i=1...7) vÃ  cÃ¡c trá»ng sá»‘ Wi Ä‘Æ°á»£c mÃ¬nh xÃ¡c Ä‘á»‹nh ngay phÃ­a dÆ°á»›i cá»§a bá»™ sá»‘ liá»‡u cá»§a mÃ¬nh. Tuy nhiÃªn mÃ¬nh cáº£m tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ chá»n khÃ´ng phÃ¹ há»£p vá»›i ""quy luáº­t"" cá»§a bá»™ sá»‘ liá»‡u phÃ­a trÃªn. MÃ¬nh mong cÃ¡c báº¡n tÆ° váº¥n cho mÃ¬nh hÆ°á»›ng chá»n mÃ´ hÃ¬nh cho cÃ¡c outputs cá»§a mÃ¬nh Ä‘á»ƒ nÃ³ phÃ¹ há»£p nháº¥t vá»›i bá»™ sá»‘ liá»‡u á»Ÿ trÃªn ! Mong admin duyá»‡t bÃ i cho mÃ¬nh Ä‘á»ƒ mÃ¬nh giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» vÃ  há»c há»i thÃªm lÄ©nh vá»±c nÃ y. MÃ¬nh xin cáº£m Æ¡n.
Data: http://www.mediafire.com/file/cab9c6r3os6kiq2/Experiment_Data.xlsx/file","ChÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ má»™t bÃ i toÃ¡n nhá» mong Ä‘Æ°á»£c tÆ° váº¥n (mÃ¬nh lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o): má»™t bá»™ sá»‘ liá»‡u cá»§a mÃ¬nh cÃ³ 3 inputs vÃ  7 outputs. 3 cá»™t bÃ´i mÃ u vÃ ng trong file excel dÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c inputs (x1, x2, x3), nhá»¯ng cá»™t cÃ²n láº¡i (7 cá»™t) lÃ  cÃ¡c outputs (f1, f2,..., f7). MÃ¬nh Ä‘Ã£ sá»­ dá»¥ng há»“i quy tuyáº¿n tÃ­nh á»Ÿ dáº¡ng fi=W0+W1*x1+W2*x2+W3*x3 (vá»›i i=1...7) vÃ  cÃ¡c trá»ng sá»‘ Wi Ä‘Æ°á»£c mÃ¬nh xÃ¡c Ä‘á»‹nh ngay phÃ­a dÆ°á»›i cá»§a bá»™ sá»‘ liá»‡u cá»§a mÃ¬nh. Tuy nhiÃªn mÃ¬nh cáº£m tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ chá»n khÃ´ng phÃ¹ há»£p vá»›i ""quy luáº­t"" cá»§a bá»™ sá»‘ liá»‡u phÃ­a trÃªn. MÃ¬nh mong cÃ¡c báº¡n tÆ° váº¥n cho mÃ¬nh hÆ°á»›ng chá»n mÃ´ hÃ¬nh cho cÃ¡c outputs cá»§a mÃ¬nh Ä‘á»ƒ nÃ³ phÃ¹ há»£p nháº¥t vá»›i bá»™ sá»‘ liá»‡u á»Ÿ trÃªn ! Mong admin duyá»‡t bÃ i cho mÃ¬nh Ä‘á»ƒ mÃ¬nh giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» vÃ  há»c há»i thÃªm lÄ©nh vá»±c nÃ y. MÃ¬nh xin cáº£m Æ¡n. Data: http://www.mediafire.com/file/cab9c6r3os6kiq2/Experiment_Data.xlsx/file",,,,,
"MÃ¬nh má»›i tÃ¬m hiá»ƒu vá» ML, Ä‘Æ°á»£c báº¡n giá»›i thiá»‡u cho Project nháº­n diá»‡n trÃ¡i cÃ¢y, mÃ  mÃ¬nh cÃ i Ä‘á»§ thÆ° viá»‡n rá»“i nÃ³ váº«n ko tÃ¬m tháº¥y lÃ  sao áº¡. CÃ¡m Æ¡n","MÃ¬nh má»›i tÃ¬m hiá»ƒu vá» ML, Ä‘Æ°á»£c báº¡n giá»›i thiá»‡u cho Project nháº­n diá»‡n trÃ¡i cÃ¢y, mÃ  mÃ¬nh cÃ i Ä‘á»§ thÆ° viá»‡n rá»“i nÃ³ váº«n ko tÃ¬m tháº¥y lÃ  sao áº¡. CÃ¡m Æ¡n",,,,,
"Xin cho há»i, máº¥y anh chá»‹ em cÃ³ ai tá»«ng nghe qua Viá»‡n TrÃ­ Tuá»‡ NhÃ¢n Táº¡o VAIC chÆ°a váº­y? MÃ¬nh cáº§n liÃªn há»‡ lÃ m viá»‡c, mÃ  sao ko tÃ¬m tháº¥y web site. MÃ  tháº¥y cÅ©ng quáº£n cÃ¡o ráº§m rá»™.","Xin cho há»i, máº¥y anh chá»‹ em cÃ³ ai tá»«ng nghe qua Viá»‡n TrÃ­ Tuá»‡ NhÃ¢n Táº¡o VAIC chÆ°a váº­y? MÃ¬nh cáº§n liÃªn há»‡ lÃ m viá»‡c, mÃ  sao ko tÃ¬m tháº¥y web site. MÃ  tháº¥y cÅ©ng quáº£n cÃ¡o ráº§m rá»™.",,,,,
"hi group.
Em vá»«a xong khÃ³a Neural network bÃªn Andrew Ng.
VÃ  Ä‘ang Ä‘á»c tutorial cá»§a pytorch.
Em cÃ³ tháº¯c máº¯c lÃ  á»Ÿ forward Ä‘Ã¡ng nháº½ há» pháº£i láº¥y w1.T.dot(x) nhÆ°ng há» láº¡i láº¥y ngÆ°á»£c láº¡i.
Anh chá»‹ giáº£i thÃ­ch chá»— nÃ y cho em vá»›i.
Cáº£m Æ¡n má»i ngÆ°á»i.",hi group. Em vá»«a xong khÃ³a Neural network bÃªn Andrew Ng. VÃ  Ä‘ang Ä‘á»c tutorial cá»§a pytorch. Em cÃ³ tháº¯c máº¯c lÃ  á»Ÿ forward Ä‘Ã¡ng nháº½ há» pháº£i láº¥y w1.T.dot(x) nhÆ°ng há» láº¡i láº¥y ngÆ°á»£c láº¡i. Anh chá»‹ giáº£i thÃ­ch chá»— nÃ y cho em vá»›i. Cáº£m Æ¡n má»i ngÆ°á»i.,,,,,
"KÃ­nh chÃ o cáº£ nhÃ , em xin phÃ©p ra tiáº¿p bÃ i tiáº¿p theo cá»§a series MÃ¬ Python vá»›i pháº§n build BackEnd Server cho cÃ¡c bÃ i toÃ¡n vá» AI báº±ng Flask.
Mong ad duyá»‡t bÃ i Ä‘á»ƒ cÃ¡c báº¡n newbie cÃ³ tÃ i liá»‡u tham kháº£o ah.","KÃ­nh chÃ o cáº£ nhÃ , em xin phÃ©p ra tiáº¿p bÃ i tiáº¿p theo cá»§a series MÃ¬ Python vá»›i pháº§n build BackEnd Server cho cÃ¡c bÃ i toÃ¡n vá» AI báº±ng Flask. Mong ad duyá»‡t bÃ i Ä‘á»ƒ cÃ¡c báº¡n newbie cÃ³ tÃ i liá»‡u tham kháº£o ah.",,,,,
"Xin chÃ o má»i ngÆ°á»i, tui lÃ  dÃ¢n tay ngang Ä‘ang há»c há»i vá» ML. Báº¡n tui chá»‰ lÃ  má»›i báº¯t Ä‘áº§u thÃ¬ nÃªn Ä‘á»c vietsub trÆ°á»›c Ä‘á»ƒ hiá»ƒu concept xong Ä‘á»c báº£n E nÃªn tui Ä‘ang tÃ¬m ""Recursive deep models for semantic compositionality over a sentiment treebank in Stanford NLP"" báº£n tiáº¿ng Viá»‡t. KhÃ´ng biáº¿t cÃ³ báº£n tiáº¿ng Viá»‡t khÃ´ng áº¡ ? Náº¿u cÃ³ thÃ¬ vui lÃ²ng cho tui xin vá»›i áº¡. Xin cÃ¡m Æ¡n.
ÄÃ¢y lÃ  báº£n tiáº¿ng Anh áº¡","Xin chÃ o má»i ngÆ°á»i, tui lÃ  dÃ¢n tay ngang Ä‘ang há»c há»i vá» ML. Báº¡n tui chá»‰ lÃ  má»›i báº¯t Ä‘áº§u thÃ¬ nÃªn Ä‘á»c vietsub trÆ°á»›c Ä‘á»ƒ hiá»ƒu concept xong Ä‘á»c báº£n E nÃªn tui Ä‘ang tÃ¬m ""Recursive deep models for semantic compositionality over a sentiment treebank in Stanford NLP"" báº£n tiáº¿ng Viá»‡t. KhÃ´ng biáº¿t cÃ³ báº£n tiáº¿ng Viá»‡t khÃ´ng áº¡ ? Náº¿u cÃ³ thÃ¬ vui lÃ²ng cho tui xin vá»›i áº¡. Xin cÃ¡m Æ¡n. ÄÃ¢y lÃ  báº£n tiáº¿ng Anh áº¡",,,,,
"[ML scientist interview]
ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, mÃ¬nh cÃ³ má»™t cÃ¢u há»i phá»ng váº¥n sau vá» xÃ¡c xuáº¥t(Bayesian) nhÆ°ng khÃ´ng cháº¯c vá» káº¿t quáº£ nÃªn ráº¥t mong má»i ngÆ°á»i gÃ³p Ã½ áº¡.
""Consider a binary classification task with a prior probability p of class 1. Assume that each assessor labeling an instance makes an error with probability q. A given instance is labeled by n assessors and m of them assigned the label 1. What is the probability that the true label is 1?""","[ML scientist interview] ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, mÃ¬nh cÃ³ má»™t cÃ¢u há»i phá»ng váº¥n sau vá» xÃ¡c xuáº¥t(Bayesian) nhÆ°ng khÃ´ng cháº¯c vá» káº¿t quáº£ nÃªn ráº¥t mong má»i ngÆ°á»i gÃ³p Ã½ áº¡. ""Consider a binary classification task with a prior probability p of class 1. Assume that each assessor labeling an instance makes an error with probability q. A given instance is labeled by n assessors and m of them assigned the label 1. What is the probability that the true label is 1?""",,,,,
"[AI News]
Má»™t trong nhá»¯ng hÆ°á»›ng Ä‘i chÃ­nh cá»§a Facebook AI hiá»‡n nay lÃ  triá»ƒn khai cÃ¡c cÃ´ng nghá»‡ há»c mÃ¡y Ä‘á»ƒ báº£o vá»‡ ngÆ°á»i dÃ¹ng khá»i nhá»¯ng ná»™i dung Ä‘á»™c háº¡i. Má»¥c tiÃªu lÃ  nháº­n ra nhanh vÃ  chÃ­nh xÃ¡c nhá»¯ng Ä‘oáº¡n phÃ¡t ngÃ´n mang tÃ­nh táº¥n cÃ´ng hoáº·c gÃ¢y thÃ¹ ghÃ©t, nhá»¯ng thÃ´ng tin sai sá»± tháº­t hoáº·c nhá»¯ng ná»™i dung vi pháº¡m phÃ¡p luáº­t báº±ng má»i ngÃ´n ngá»¯ trÃªn tháº¿ giá»›i.
AI hiá»‡n nay Ä‘Ã£ cáº£i thiá»‡n ráº¥t nhiá»u, chá»§ Ä‘á»™ng phÃ¡t hiá»‡n 94.7% cÃ¡c Ä‘oáº¡n phÃ¡t ngÃ´n khÃ´ng há»£p lá»‡ bá»‹ xÃ³a khá»i Facebook, so vá»›i 80,5% cá»§a 2019 vÃ  24% cá»§a 2017. Äiá»u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi cÃ¡c cÃ´ng nghá»‡ nÃ¢ng cao vá» nháº­n diá»‡n tá»± Ä‘á»™ng khÃ¡c nhau nhÆ° XLM, Reinforced Integrity Optimizer, Linformer AI architecture, SimSearchNet, ...","[AI News] Má»™t trong nhá»¯ng hÆ°á»›ng Ä‘i chÃ­nh cá»§a Facebook AI hiá»‡n nay lÃ  triá»ƒn khai cÃ¡c cÃ´ng nghá»‡ há»c mÃ¡y Ä‘á»ƒ báº£o vá»‡ ngÆ°á»i dÃ¹ng khá»i nhá»¯ng ná»™i dung Ä‘á»™c háº¡i. Má»¥c tiÃªu lÃ  nháº­n ra nhanh vÃ  chÃ­nh xÃ¡c nhá»¯ng Ä‘oáº¡n phÃ¡t ngÃ´n mang tÃ­nh táº¥n cÃ´ng hoáº·c gÃ¢y thÃ¹ ghÃ©t, nhá»¯ng thÃ´ng tin sai sá»± tháº­t hoáº·c nhá»¯ng ná»™i dung vi pháº¡m phÃ¡p luáº­t báº±ng má»i ngÃ´n ngá»¯ trÃªn tháº¿ giá»›i. AI hiá»‡n nay Ä‘Ã£ cáº£i thiá»‡n ráº¥t nhiá»u, chá»§ Ä‘á»™ng phÃ¡t hiá»‡n 94.7% cÃ¡c Ä‘oáº¡n phÃ¡t ngÃ´n khÃ´ng há»£p lá»‡ bá»‹ xÃ³a khá»i Facebook, so vá»›i 80,5% cá»§a 2019 vÃ  24% cá»§a 2017. Äiá»u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi cÃ¡c cÃ´ng nghá»‡ nÃ¢ng cao vá» nháº­n diá»‡n tá»± Ä‘á»™ng khÃ¡c nhau nhÆ° XLM, Reinforced Integrity Optimizer, Linformer AI architecture, SimSearchNet, ...",,,,,
"MÃ¬nh muá»‘n há»c khoÃ¡ há»c ML cÆ¡ báº£n cá»§a Viá»‡n AI nÃ y! Tháº¥y Ä‘á»c thÃ´ng tin trÃªn web cá»§a Viá»‡n cÅ©ng ok láº¯m!
Báº¡n nÃ o há»c rá»“i cho mÃ¬nh Ã­t review vá»›i!
Ps: mÃ¬nh Ä‘Äƒng bÃ i há»i Ã½ kiáº¿n nhÆ° nÃ y máº¥y hÃ´m, sao ko Ä‘Æ°á»£c duyá»‡t. Mong ad duyá»‡t bÃ i!","MÃ¬nh muá»‘n há»c khoÃ¡ há»c ML cÆ¡ báº£n cá»§a Viá»‡n AI nÃ y! Tháº¥y Ä‘á»c thÃ´ng tin trÃªn web cá»§a Viá»‡n cÅ©ng ok láº¯m! Báº¡n nÃ o há»c rá»“i cho mÃ¬nh Ã­t review vá»›i! Ps: mÃ¬nh Ä‘Äƒng bÃ i há»i Ã½ kiáº¿n nhÆ° nÃ y máº¥y hÃ´m, sao ko Ä‘Æ°á»£c duyá»‡t. Mong ad duyá»‡t bÃ i!",,,,,
"Cáº§n má»i ngÆ°á»i giÃºp Ä‘á»¡ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng há»‡ thá»‘ng thá»­ áº£o quáº§n Ã¡o.
Má»¥c Ä‘Ã­ch lÃ  chá»n ra áº£nh (tá»± nhiÃªn nháº¥t, chÃ¢n thá»±c nháº¥t).
Tá»•ng cá»™ng cÃ³ 100 trÆ°á»ng há»£p (tá»‘n khoáº£ng 10 phÃºt) áº¡.
Mong Ä‘Æ°á»£c má»i ngÆ°á»i há»— trá»£.
ChÃ¢n thÃ nh cáº£m Æ¡n.","Cáº§n má»i ngÆ°á»i giÃºp Ä‘á»¡ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng há»‡ thá»‘ng thá»­ áº£o quáº§n Ã¡o. Má»¥c Ä‘Ã­ch lÃ  chá»n ra áº£nh (tá»± nhiÃªn nháº¥t, chÃ¢n thá»±c nháº¥t). Tá»•ng cá»™ng cÃ³ 100 trÆ°á»ng há»£p (tá»‘n khoáº£ng 10 phÃºt) áº¡. Mong Ä‘Æ°á»£c má»i ngÆ°á»i há»— trá»£. ChÃ¢n thÃ nh cáº£m Æ¡n.",,,,,
,nan,,,,,
"Hi cáº£ nhÃ , em Ä‘ang há»c láº¡i vá» Machine Learning vÃ  Ä‘ang há»c Ä‘áº¿n pháº§n K-Means vÃ  cÃ¡c chá»n Sá»‘ cá»¥m K. Em máº¡nh dáº¡n lÃ m clip Ä‘á»ƒ tá»•ng há»£p kiáº¿n thá»©c vÃ  cÅ©ng lÃ  Ä‘á»ƒ chia sáº» cho cÃ¡c báº¡n má»›i há»c!
Do em cÅ©ng khÃ´ng há»c trÆ°á»ng lá»›p nÃ o mÃ  tá»± google nÃªn náº¿u sai mong Ä‘Æ°á»£c corect Ä‘á»ƒ há»c tá»‘t hÆ¡n ah.
Mong ad duyá»‡t bÃ i!","Hi cáº£ nhÃ , em Ä‘ang há»c láº¡i vá» Machine Learning vÃ  Ä‘ang há»c Ä‘áº¿n pháº§n K-Means vÃ  cÃ¡c chá»n Sá»‘ cá»¥m K. Em máº¡nh dáº¡n lÃ m clip Ä‘á»ƒ tá»•ng há»£p kiáº¿n thá»©c vÃ  cÅ©ng lÃ  Ä‘á»ƒ chia sáº» cho cÃ¡c báº¡n má»›i há»c! Do em cÅ©ng khÃ´ng há»c trÆ°á»ng lá»›p nÃ o mÃ  tá»± google nÃªn náº¿u sai mong Ä‘Æ°á»£c corect Ä‘á»ƒ há»c tá»‘t hÆ¡n ah. Mong ad duyá»‡t bÃ i!",,,,,
"CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn dá»¥ng, tuyá»ƒn sinh, sá»± kiá»‡n thÃ¡ng 12 bÃªn dÆ°á»›i comment cá»§a post nÃ y.
ChÃºc cÃ¡c báº¡n má»™t thÃ¡ng vui váº».","CÃ¡c báº¡n vui lÃ²ng Ä‘Äƒng tin tuyá»ƒn dá»¥ng, tuyá»ƒn sinh, sá»± kiá»‡n thÃ¡ng 12 bÃªn dÆ°á»›i comment cá»§a post nÃ y. ChÃºc cÃ¡c báº¡n má»™t thÃ¡ng vui váº».",,,,,
"GÃ“C DEBUG!!
recognition_google khÃ´ng kháº£ dá»¥ng ná»¯a háº£ mn? Cao nhÃ¢n debug giÃºp",GÃ“C DEBUG!! recognition_google khÃ´ng kháº£ dá»¥ng ná»¯a háº£ mn? Cao nhÃ¢n debug giÃºp,,,,,
"MÃ¬nh Ä‘Ã£ má»Ÿ anacoda dÆ°á»›i quyá»n admin mÃ  khi cháº¡y váº¥n bá»‹ ""Permission denied"".
Má»i ngÆ°á»i giÃºp em fix lá»—i nÃ y vá»›i áº¡","MÃ¬nh Ä‘Ã£ má»Ÿ anacoda dÆ°á»›i quyá»n admin mÃ  khi cháº¡y váº¥n bá»‹ ""Permission denied"". Má»i ngÆ°á»i giÃºp em fix lá»—i nÃ y vá»›i áº¡",,,,,
"ChÃ o a/c,
Em lÃ  sinh viÃªn nÄƒm 4, ngÃ nh Ä‘iá»‡n Ä‘iá»‡n tá»­, e muá»‘n ra trÆ°á»ng lÃ m vá» ML, nÃªn e tÃ­nh kiáº¿m chá»— thá»±c táº­p vá» ML gáº§n (q9,hcm), e Ä‘Ã£ cÃ³ ná»n vá» python vÃ  má»™t Ã­t vá» DL, e chá»‰ mong muá»‘n há»c thÃªm kiáº¿n thá»©c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘i lm Ä‘Æ°á»£c nÃªn ko cáº§n lÆ°Æ¡ng áº¡! Anh chá»‹ nÃ o thÆ°Æ¡ng thÃ¬ giÃºp em.","ChÃ o a/c, Em lÃ  sinh viÃªn nÄƒm 4, ngÃ nh Ä‘iá»‡n Ä‘iá»‡n tá»­, e muá»‘n ra trÆ°á»ng lÃ m vá» ML, nÃªn e tÃ­nh kiáº¿m chá»— thá»±c táº­p vá» ML gáº§n (q9,hcm), e Ä‘Ã£ cÃ³ ná»n vá» python vÃ  má»™t Ã­t vá» DL, e chá»‰ mong muá»‘n há»c thÃªm kiáº¿n thá»©c Ä‘á»ƒ cÃ³ thá»ƒ Ä‘i lm Ä‘Æ°á»£c nÃªn ko cáº§n lÆ°Æ¡ng áº¡! Anh chá»‹ nÃ o thÆ°Æ¡ng thÃ¬ giÃºp em.",,,,,
"CÃ¡i bÃ i nÃ y cÃ³ váº» thÃº vá»‹
The $25,000,000,000 Eigenvector: The Linear Algebra behind Google","CÃ¡i bÃ i nÃ y cÃ³ váº» thÃº vá»‹ The $25,000,000,000 Eigenvector: The Linear Algebra behind Google",,,,,
"ChÃºc má»«ng Huyá»n Chip vÃ o top!
 â€” vá»›i Huyen Nguyen.",ChÃºc má»«ng Huyá»n Chip vÃ o top! â€” vá»›i Huyen Nguyen.,,,,,
"Em Ä‘ang test máº¡ng CNN cÆ¡ báº£n theo video hÆ°á»›ng dáº«n mÃ  em tháº¥y training hÆ¡i bá»‹ lÃ¢u áº¡(gáº¥p 10 láº§n trong video) máº·c dÃ¹ chÆ°Æ¡ng trÃ¬nh cháº¡y trÃªn GPU vÃ  trong video há» dÃ¹ng GTX1050 vÃ  em dÃ¹ng GTX1070ti áº¡.
Má»i ngÆ°á»i cho em há»i viá»‡c training cháº­m lÃ  do Ä‘Ã¢u váº­y áº¡ vÃ  hÆ°á»›ng kháº¯c phá»¥c lÃ  nhÆ° nÃ o áº¡?
Em cáº£m Æ¡n!!!",Em Ä‘ang test máº¡ng CNN cÆ¡ báº£n theo video hÆ°á»›ng dáº«n mÃ  em tháº¥y training hÆ¡i bá»‹ lÃ¢u áº¡(gáº¥p 10 láº§n trong video) máº·c dÃ¹ chÆ°Æ¡ng trÃ¬nh cháº¡y trÃªn GPU vÃ  trong video há» dÃ¹ng GTX1050 vÃ  em dÃ¹ng GTX1070ti áº¡. Má»i ngÆ°á»i cho em há»i viá»‡c training cháº­m lÃ  do Ä‘Ã¢u váº­y áº¡ vÃ  hÆ°á»›ng kháº¯c phá»¥c lÃ  nhÆ° nÃ o áº¡? Em cáº£m Æ¡n!!!,,,,,
"chÃ o má»i ngÆ°á»i vÃ  cÃ¡c báº¡n, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m viá»‡c trong máº£ng Big Data, mÃ¬nh nháº­n tháº¥y thá»i gian nÃ y vÃ²ng Ä‘á»i technique quay ráº¥t nhanh... mÃ¬nh tháº¯c máº¯c mÃ£i lÃ  khÃ´ng biáº¿t nÃªn tÃ¬m kÃªnh nÃ o Ä‘á»ƒ update xu hÆ°á»›ng cÃ´ng nghá»‡, mÃ¬nh cÅ©ng hay tÃ¬m sÃ¡ch Ä‘á»ƒ Ä‘á»c, nhÆ°ng Ä‘Ã´i khi tháº¥y nhá»¯ng trend mÃ  nhÃ  xuáº¥t báº£n viáº¿t cÅ©ng khÃ´ng Ä‘Ãºng láº¯m, nÃªn viáº¿t lÃªn Ä‘Ã¢y Ä‘á»ƒ mong nháº­n Ä‘Æ°á»£c sá»± chia sáº» cá»§a má»i ngÆ°á»i. MÃ¬nh xin cáº£m Æ¡n.","chÃ o má»i ngÆ°á»i vÃ  cÃ¡c báº¡n, hiá»‡n táº¡i mÃ¬nh Ä‘ang lÃ m viá»‡c trong máº£ng Big Data, mÃ¬nh nháº­n tháº¥y thá»i gian nÃ y vÃ²ng Ä‘á»i technique quay ráº¥t nhanh... mÃ¬nh tháº¯c máº¯c mÃ£i lÃ  khÃ´ng biáº¿t nÃªn tÃ¬m kÃªnh nÃ o Ä‘á»ƒ update xu hÆ°á»›ng cÃ´ng nghá»‡, mÃ¬nh cÅ©ng hay tÃ¬m sÃ¡ch Ä‘á»ƒ Ä‘á»c, nhÆ°ng Ä‘Ã´i khi tháº¥y nhá»¯ng trend mÃ  nhÃ  xuáº¥t báº£n viáº¿t cÅ©ng khÃ´ng Ä‘Ãºng láº¯m, nÃªn viáº¿t lÃªn Ä‘Ã¢y Ä‘á»ƒ mong nháº­n Ä‘Æ°á»£c sá»± chia sáº» cá»§a má»i ngÆ°á»i. MÃ¬nh xin cáº£m Æ¡n.",,,,,
"ChÃ o mn áº¡,
Cho em xin phÃ©p Ä‘Æ°á»£c há»i cÃ¡ch giáº£i quyáº¿t cÃ¢u 5. pháº§n early stopping vá»›i cÃ¡c model á»Ÿ cÃ¢u 4.(Ä‘Ã£ implement báº±ng sklearn) áº¡.","ChÃ o mn áº¡, Cho em xin phÃ©p Ä‘Æ°á»£c há»i cÃ¡ch giáº£i quyáº¿t cÃ¢u 5. pháº§n early stopping vá»›i cÃ¡c model á»Ÿ cÃ¢u 4.(Ä‘Ã£ implement báº±ng sklearn) áº¡.",,,,,
"Xin phÃ©p Ad,
chÃ o cÃ¡c a/c, má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng Ä‘áº©y GPU passthrough tá»« host vÃ o virtual machine cÃ³ thá»ƒ cho e Ã­t lá»i khuyÃªn ko áº¡ (e mong muá»‘n táº¡o 1 mÃ¡y áº£o ubuntu dÃ¹ng Ä‘Æ°á»£c GPU tá»« host Ä‘á»ƒ cháº¡y model). E Ä‘Ã£ tÃ¬m hiá»ƒu thÃ¬ biáº¿t Ä‘Æ°á»£c VMware Sphere cÃ³ há»— trá»£, nhÆ°ng khi e cÃ i Sphere xong thÃ¬ GPU ko active nhÆ° tháº¿ nÃ y, a/c Ä‘Ã£ tá»«ng lÃ m qua cÃ³ thá»ƒ cho e vÃ i lá»i khuyÃªn áº¡, e cÃ¡m Æ¡n mn!","Xin phÃ©p Ad, chÃ o cÃ¡c a/c, má»i ngÆ°á»i ai Ä‘Ã£ tá»«ng Ä‘áº©y GPU passthrough tá»« host vÃ o virtual machine cÃ³ thá»ƒ cho e Ã­t lá»i khuyÃªn ko áº¡ (e mong muá»‘n táº¡o 1 mÃ¡y áº£o ubuntu dÃ¹ng Ä‘Æ°á»£c GPU tá»« host Ä‘á»ƒ cháº¡y model). E Ä‘Ã£ tÃ¬m hiá»ƒu thÃ¬ biáº¿t Ä‘Æ°á»£c VMware Sphere cÃ³ há»— trá»£, nhÆ°ng khi e cÃ i Sphere xong thÃ¬ GPU ko active nhÆ° tháº¿ nÃ y, a/c Ä‘Ã£ tá»«ng lÃ m qua cÃ³ thá»ƒ cho e vÃ i lá»i khuyÃªn áº¡, e cÃ¡m Æ¡n mn!",,,,,
"ğŸ¯KÃ­nh chÃ o cÃ¡c bÃ¡c, hÃ´m nay em Ä‘ang há»c vá» pháº§n máº¡ng InceptionNet nÃªn em máº¡nh dáº¡n viáº¿t má»™t chÃºt vá»«a note láº¡i kiáº¿n thá»©c vá»«a chia sáº» cho cÃ¡c báº¡n má»›i há»c.
ğŸ¯Mong admin duyá»‡t bÃ i ah!","KÃ­nh chÃ o cÃ¡c bÃ¡c, hÃ´m nay em Ä‘ang há»c vá» pháº§n máº¡ng InceptionNet nÃªn em máº¡nh dáº¡n viáº¿t má»™t chÃºt vá»«a note láº¡i kiáº¿n thá»©c vá»«a chia sáº» cho cÃ¡c báº¡n má»›i há»c. Mong admin duyá»‡t bÃ i ah!",,,,,
"TÃ€I LIá»†U Há»ŒC MACHINE LEARNING CHO NGÆ¯á»œI Má»šI Báº®T Äáº¦U
Chia sáº» tá»« NghiÃªn cá»©u sinh Tiáº¿n sÄ© KhÃ¡nh Nguyá»…n, Ä‘áº¡i há»c Maryland, College Park. ChuyÃªn nghiÃªn cá»©u vá» NLP thÃ´ng qua giáº£ng dáº¡y vÃ  há»c táº­p, vá»›i nhá»¯ng nghiÃªn cá»©u mÅ©i nhá»n táº­p trung vÃ o phÆ°Æ¡ng phÃ¡p há»c tÆ°Æ¡ng tÃ¡c dá»±a trÃªn cáº¥u trÃºc cÃ³ sáºµn (instruction-based interactive learning). Vinh dá»± khi lÃ  Ä‘áº¡i diá»‡n diá»…n thuyáº¿t táº¡i Global Voices vá»›i chá»§ Ä‘á» ""Dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ Ä‘a ngÃ´n ngá»¯ má»›i nháº¥t"" (new evaluation dataset for cross-lingual summarization). NghiÃªn cá»©u cá»§a anh (Visual Navigation with Multimodal Natural Assistance) Ä‘Ã£ vinh dá»± náº±m trong danh sÃ¡ch EMNLP2019 (tá»· lá»‡ cháº¥p thuáº­n: 23.8%).","TÃ€I LIá»†U Há»ŒC MACHINE LEARNING CHO NGÆ¯á»œI Má»šI Báº®T Äáº¦U Chia sáº» tá»« NghiÃªn cá»©u sinh Tiáº¿n sÄ© KhÃ¡nh Nguyá»…n, Ä‘áº¡i há»c Maryland, College Park. ChuyÃªn nghiÃªn cá»©u vá» NLP thÃ´ng qua giáº£ng dáº¡y vÃ  há»c táº­p, vá»›i nhá»¯ng nghiÃªn cá»©u mÅ©i nhá»n táº­p trung vÃ o phÆ°Æ¡ng phÃ¡p há»c tÆ°Æ¡ng tÃ¡c dá»±a trÃªn cáº¥u trÃºc cÃ³ sáºµn (instruction-based interactive learning). Vinh dá»± khi lÃ  Ä‘áº¡i diá»‡n diá»…n thuyáº¿t táº¡i Global Voices vá»›i chá»§ Ä‘á» ""Dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ Ä‘a ngÃ´n ngá»¯ má»›i nháº¥t"" (new evaluation dataset for cross-lingual summarization). NghiÃªn cá»©u cá»§a anh (Visual Navigation with Multimodal Natural Assistance) Ä‘Ã£ vinh dá»± náº±m trong danh sÃ¡ch EMNLP2019 (tá»· lá»‡ cháº¥p thuáº­n: 23.8%).",,,,,
Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t cuá»™c thi má»›i do Bá»™ KHCN Ä‘á»“ng tá»• chá»©c sáº¯p tá»›i,Giá»›i thiá»‡u vá»›i cÃ¡c báº¡n má»™t cuá»™c thi má»›i do Bá»™ KHCN Ä‘á»“ng tá»• chá»©c sáº¯p tá»›i,,,,,
"Xin chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n,
MÃ¬nh lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o Ä‘ang há»c ML Ä‘á»ƒ phá»¥c vá»¥ cÃ´ng viá»‡c. MÃ¬nh muá»‘n há»i má»™t váº¥n Ä‘á» nÃ y, ráº¥t mong má»i ngÆ°á»i gÃ³p Ã½.
MÃ¬nh triá»ƒn khai cÃ¡c thuáº­t toÃ¡n ML cá»• Ä‘iá»ƒn báº±ng sklearn thÃ¬ tháº¥y má»—i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  1 vector 1 chiá»u chá»©a n feature values. Äá»‘i vá»›i Deep Learning sau khi sá»­ dá»¥ng cÃ¡c lá»›p tÃ­ch cháº­p Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng cá»§a áº£nh thÃ¬ váº«n qua 1 lá»›p flatten Ä‘á»ƒ tráº£i pháº³ng ma tráº­n 2 chiá»u thÃ nh vector 1 chiá»u trÆ°á»›c khi Ä‘Æ°a vÃ o 1 full connected layer.
Hiá»‡n nay cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u cá»§a mÃ¬nh Ä‘ang cÃ³ dáº¡ng lÃ  1 ma tráº­n 2 chiá»u Ä‘á»‘i xá»©ng nhÆ° hÃ¬nh váº½. Váº­y mÃ¬nh muá»‘n há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘Æ°a dáº¡ng dá»¯ liá»‡u nÃ y vÃ o cÃ¡c thuáº­t toÃ¡n ML khÃ´ng, hay báº¯t buá»™c pháº£i tráº£i pháº³ng ra, vÃ  viá»‡c tráº£i pháº³ng ra nhÆ° váº­y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh khÃ´ng áº¡?","Xin chÃ o cÃ¡c anh chá»‹ vÃ  cÃ¡c báº¡n, MÃ¬nh lÃ  dÃ¢n ngoáº¡i Ä‘áº¡o Ä‘ang há»c ML Ä‘á»ƒ phá»¥c vá»¥ cÃ´ng viá»‡c. MÃ¬nh muá»‘n há»i má»™t váº¥n Ä‘á» nÃ y, ráº¥t mong má»i ngÆ°á»i gÃ³p Ã½. MÃ¬nh triá»ƒn khai cÃ¡c thuáº­t toÃ¡n ML cá»• Ä‘iá»ƒn báº±ng sklearn thÃ¬ tháº¥y má»—i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  1 vector 1 chiá»u chá»©a n feature values. Äá»‘i vá»›i Deep Learning sau khi sá»­ dá»¥ng cÃ¡c lá»›p tÃ­ch cháº­p Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng cá»§a áº£nh thÃ¬ váº«n qua 1 lá»›p flatten Ä‘á»ƒ tráº£i pháº³ng ma tráº­n 2 chiá»u thÃ nh vector 1 chiá»u trÆ°á»›c khi Ä‘Æ°a vÃ o 1 full connected layer. Hiá»‡n nay cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u cá»§a mÃ¬nh Ä‘ang cÃ³ dáº¡ng lÃ  1 ma tráº­n 2 chiá»u Ä‘á»‘i xá»©ng nhÆ° hÃ¬nh váº½. Váº­y mÃ¬nh muá»‘n há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘Æ°a dáº¡ng dá»¯ liá»‡u nÃ y vÃ o cÃ¡c thuáº­t toÃ¡n ML khÃ´ng, hay báº¯t buá»™c pháº£i tráº£i pháº³ng ra, vÃ  viá»‡c tráº£i pháº³ng ra nhÆ° váº­y cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh khÃ´ng áº¡?",,,,,
"Xin chÃ o cÃ¡c báº¡n,
tÃ´i cÃ³ má»™t bÃ i bÃ¡o vá»«a Ä‘Æ°á»£c Ä‘Äƒng trÃªn Journal of Systems and Software cá»§a Elsevier, má»™t táº­p san khÃ¡ tá»‘t trong ngÃ nh Software Engineering (SE). BÃ i nÃ³i vá» á»©ng dá»¥ng máº¡ng CNN trong phÃ¢n loáº¡i metamodels (má»™t kiá»ƒu dá»¯ liá»‡u). Máº¡ng CNN Ä‘á» xuáº¥t khÃ´ng cÃ³ gÃ¬ Ä‘áº·c biá»‡t, khÃ´ng quÃ¡ sÃ¢u (deep) hay rá»™ng (wide). Náº¿u mang nÃ³ so vá»›i cÃ¡c cáº¥u trÃºc máº¡ng mÃ  nhiá»u báº¡n á»Ÿ Ä‘Ã¢y hay dÃ¹ng Ä‘á»ƒ nháº­n dáº¡ng áº£nh thÃ¬ giá»‘ng nhÆ° mang con tem dÃ¡n lÃªn tá» giáº¥y A4 :).
Trá»ng tÃ¢m cá»§a bÃ i lÃ  cÃ¡ch thá»©c Ä‘á»ƒ chuyá»ƒn metamodels thÃ nh má»™t loáº¡i format tÆ°Æ¡ng tá»± áº£nh, tá»« Ä‘Ã³ cÃ³ thá»ƒ táº­n dá»¥ng cÃ¡c Æ°u tháº¿ cá»§a CNN vá»›i áº£nh Ä‘á»ƒ phÃ¢n loáº¡i metamodels. TÃ´i nghÄ© cÃ³ thá»ƒ Ã¡p dá»¥ng ká»¹ thuáº­t nÃ y vá»›i cÃ¡c loáº¡i dá»¯ liá»‡u khÃ¡c, vÃ­ dá»¥ nhÆ° vÄƒn báº£n, táº¡o tiá»n Ä‘á» Ä‘á»ƒ triá»ƒn khai Deep Learning trÃªn cÃ¡c loáº¡i dá»¯ liá»‡u nÃ y.
Elsevier cho táº£i miá»…n phÃ­ trong giai Ä‘oáº¡n Ä‘áº§u khi bÃ i má»›i Ä‘Æ°á»£c Ä‘Äƒng, má»i cÃ¡c báº¡n quan tÃ¢m ghÃ© qua xem táº¡i Ä‘á»‹a chá»‰ sau: https://authors.elsevier.com/c/1c3xebKHp2KQi
Hiá»‡n nay, tÃ´i Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng vá» má»™t bÃ i bÃ¡o dÃ i hÆ¡i vá»›i chá»§ Ä‘á» lÃ  vá» SE + ML, tÃ´i cáº§n cÃ³ thÃªm Ä‘á»“ng tÃ¡c giáº£ (khoáº£ng 3 báº¡n ná»¯a) Ä‘á»ƒ cÃ¹ng Ä‘á»c tÃ i liá»‡u vÃ  viáº¿t bÃ i, dá»±a trÃªn phÃ¢n cÃ´ng cÃ´ng viá»‡c cá»¥ thá»ƒ. Náº¿u báº¡n nÃ o Ä‘ang nghiÃªn cá»©u (PhD, postdoc) cÃ¹ng lÄ©nh vá»±c, cÃ³ há»©ng thÃº há»£p tÃ¡c, cÅ©ng nhÆ° lÃ  cÃ³ thá»ƒ dÃ nh thá»i gian cho cÃ´ng viá»‡c nÃ y, xin hÃ£y liÃªn há»‡ vá»›i tÃ´i. Sáº£n pháº©m cuá»‘i cÃ¹ng lÃ  bÃ i bÃ¡o vÃ  (ráº¥t tiáº¿c lÃ ) khÃ´ng cÃ³ lá»£i Ã­ch vá» máº·t tÃ i chÃ­nh, nhÆ°ng cháº¯c cháº¯n sáº½ cÃ³ Ã½ nghÄ©a trong hÃ nh trang cá»§a má»—i ngÆ°á»i lÃ m nghiÃªn cá»©u.
Hy vá»ng cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c há»£p tÃ¡c vá»›i cÃ¡c báº¡n cÃ³ cÃ¹ng Ä‘am mÃª.
Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin vÃ  chÃºc cuá»‘i tuáº§n vui váº». Stay safe!
NTP","Xin chÃ o cÃ¡c báº¡n, tÃ´i cÃ³ má»™t bÃ i bÃ¡o vá»«a Ä‘Æ°á»£c Ä‘Äƒng trÃªn Journal of Systems and Software cá»§a Elsevier, má»™t táº­p san khÃ¡ tá»‘t trong ngÃ nh Software Engineering (SE). BÃ i nÃ³i vá» á»©ng dá»¥ng máº¡ng CNN trong phÃ¢n loáº¡i metamodels (má»™t kiá»ƒu dá»¯ liá»‡u). Máº¡ng CNN Ä‘á» xuáº¥t khÃ´ng cÃ³ gÃ¬ Ä‘áº·c biá»‡t, khÃ´ng quÃ¡ sÃ¢u (deep) hay rá»™ng (wide). Náº¿u mang nÃ³ so vá»›i cÃ¡c cáº¥u trÃºc máº¡ng mÃ  nhiá»u báº¡n á»Ÿ Ä‘Ã¢y hay dÃ¹ng Ä‘á»ƒ nháº­n dáº¡ng áº£nh thÃ¬ giá»‘ng nhÆ° mang con tem dÃ¡n lÃªn tá» giáº¥y A4 :). Trá»ng tÃ¢m cá»§a bÃ i lÃ  cÃ¡ch thá»©c Ä‘á»ƒ chuyá»ƒn metamodels thÃ nh má»™t loáº¡i format tÆ°Æ¡ng tá»± áº£nh, tá»« Ä‘Ã³ cÃ³ thá»ƒ táº­n dá»¥ng cÃ¡c Æ°u tháº¿ cá»§a CNN vá»›i áº£nh Ä‘á»ƒ phÃ¢n loáº¡i metamodels. TÃ´i nghÄ© cÃ³ thá»ƒ Ã¡p dá»¥ng ká»¹ thuáº­t nÃ y vá»›i cÃ¡c loáº¡i dá»¯ liá»‡u khÃ¡c, vÃ­ dá»¥ nhÆ° vÄƒn báº£n, táº¡o tiá»n Ä‘á» Ä‘á»ƒ triá»ƒn khai Deep Learning trÃªn cÃ¡c loáº¡i dá»¯ liá»‡u nÃ y. Elsevier cho táº£i miá»…n phÃ­ trong giai Ä‘oáº¡n Ä‘áº§u khi bÃ i má»›i Ä‘Æ°á»£c Ä‘Äƒng, má»i cÃ¡c báº¡n quan tÃ¢m ghÃ© qua xem táº¡i Ä‘á»‹a chá»‰ sau: https://authors.elsevier.com/c/1c3xebKHp2KQi Hiá»‡n nay, tÃ´i Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng vá» má»™t bÃ i bÃ¡o dÃ i hÆ¡i vá»›i chá»§ Ä‘á» lÃ  vá» SE + ML, tÃ´i cáº§n cÃ³ thÃªm Ä‘á»“ng tÃ¡c giáº£ (khoáº£ng 3 báº¡n ná»¯a) Ä‘á»ƒ cÃ¹ng Ä‘á»c tÃ i liá»‡u vÃ  viáº¿t bÃ i, dá»±a trÃªn phÃ¢n cÃ´ng cÃ´ng viá»‡c cá»¥ thá»ƒ. Náº¿u báº¡n nÃ o Ä‘ang nghiÃªn cá»©u (PhD, postdoc) cÃ¹ng lÄ©nh vá»±c, cÃ³ há»©ng thÃº há»£p tÃ¡c, cÅ©ng nhÆ° lÃ  cÃ³ thá»ƒ dÃ nh thá»i gian cho cÃ´ng viá»‡c nÃ y, xin hÃ£y liÃªn há»‡ vá»›i tÃ´i. Sáº£n pháº©m cuá»‘i cÃ¹ng lÃ  bÃ i bÃ¡o vÃ  (ráº¥t tiáº¿c lÃ ) khÃ´ng cÃ³ lá»£i Ã­ch vá» máº·t tÃ i chÃ­nh, nhÆ°ng cháº¯c cháº¯n sáº½ cÃ³ Ã½ nghÄ©a trong hÃ nh trang cá»§a má»—i ngÆ°á»i lÃ m nghiÃªn cá»©u. Hy vá»ng cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c há»£p tÃ¡c vá»›i cÃ¡c báº¡n cÃ³ cÃ¹ng Ä‘am mÃª. Cáº£m Æ¡n má»i ngÆ°á»i Ä‘Ã£ Ä‘á»c tin vÃ  chÃºc cuá»‘i tuáº§n vui váº». Stay safe! NTP",,,,,
"ChÃ o anh chá»‹.
E lÃ  sv nÄƒm 2 Ä‘ang suy nghÄ© Ã½ tÆ°á»Ÿng vá» Ä‘á» tÃ i ""á»©ng dá»¥ng AI vÃ o mÃ´ hÃ¬nh nhÃ  ná»•i chá»‘ng lÅ©"" vÃ  cÃ³ Ã½ tÆ°á»Ÿng lÃ  dÃ¹ng AI hoÄƒÌ£c IoT Ä‘á»ƒ phÃ¢n tÃ­ch má»±c nÆ°á»›c + tá»‘c Ä‘á»™ dÃ²ng cháº£y, sau Ä‘Ã³ Ä‘iá»u chá»‰nh tá»‘c Ä‘á»™ vÃ  hÆ°á»›ng cá»§a cÃ¡nh quáº¡t gáº¯n dÆ°á»›i nhÃ  ná»•i Ä‘á»ƒ tÄƒng Ä‘á»™ á»•n Ä‘á»‹nh cá»§a nhÃ  ná»•i. (kiá»ƒu nhÆ° cÃ¡nh quáº¡t cá»§a thuyá»n Ã¡ áº¡)
Äiá»u nÃ y vá» máº·t Ã½ tÆ°á»Ÿng cÃ³ kháº£ thi khÃ´ng áº¡? (chá»‰ dá»«ng láº¡i á»Ÿ máº·t Ã½ tÆ°á»Ÿng ko cáº§n chi tiáº¿t vá» ká»¹ thuáº­t)
NgoÃ i ra cÃ³ thá»ƒ á»©ng dá»¥ng AI vÃ o Ä‘Ã¢u ná»¯a ko áº¡?
Em cÃ¡m Æ¡n nhiá»u áº¡.","ChÃ o anh chá»‹. E lÃ  sv nÄƒm 2 Ä‘ang suy nghÄ© Ã½ tÆ°á»Ÿng vá» Ä‘á» tÃ i ""á»©ng dá»¥ng AI vÃ o mÃ´ hÃ¬nh nhÃ  ná»•i chá»‘ng lÅ©"" vÃ  cÃ³ Ã½ tÆ°á»Ÿng lÃ  dÃ¹ng AI hoÄƒÌ£c IoT Ä‘á»ƒ phÃ¢n tÃ­ch má»±c nÆ°á»›c + tá»‘c Ä‘á»™ dÃ²ng cháº£y, sau Ä‘Ã³ Ä‘iá»u chá»‰nh tá»‘c Ä‘á»™ vÃ  hÆ°á»›ng cá»§a cÃ¡nh quáº¡t gáº¯n dÆ°á»›i nhÃ  ná»•i Ä‘á»ƒ tÄƒng Ä‘á»™ á»•n Ä‘á»‹nh cá»§a nhÃ  ná»•i. (kiá»ƒu nhÆ° cÃ¡nh quáº¡t cá»§a thuyá»n Ã¡ áº¡) Äiá»u nÃ y vá» máº·t Ã½ tÆ°á»Ÿng cÃ³ kháº£ thi khÃ´ng áº¡? (chá»‰ dá»«ng láº¡i á»Ÿ máº·t Ã½ tÆ°á»Ÿng ko cáº§n chi tiáº¿t vá» ká»¹ thuáº­t) NgoÃ i ra cÃ³ thá»ƒ á»©ng dá»¥ng AI vÃ o Ä‘Ã¢u ná»¯a ko áº¡? Em cÃ¡m Æ¡n nhiá»u áº¡.",,,,,
"ChÃ o cÃ¡c anh chá»‹, em Ä‘ang tÃ¬m hiá»ƒu vá» Self-SVM thÃ¬ cÃ³ Ä‘oáº¡n nhÆ° hÃ¬nh. Em muá»‘n há»i lÃ  trong sklearn lÃ m tháº¿ nÃ o Ä‘á»ƒ láº¥y giÃ¡ trá»‹ object function áº¡. Em lÃ  newbie mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ hÆ°á»›ng dáº«n áº¡. Em xin cáº£m Æ¡n!","ChÃ o cÃ¡c anh chá»‹, em Ä‘ang tÃ¬m hiá»ƒu vá» Self-SVM thÃ¬ cÃ³ Ä‘oáº¡n nhÆ° hÃ¬nh. Em muá»‘n há»i lÃ  trong sklearn lÃ m tháº¿ nÃ o Ä‘á»ƒ láº¥y giÃ¡ trá»‹ object function áº¡. Em lÃ  newbie mong Ä‘Æ°á»£c cÃ¡c anh chá»‹ hÆ°á»›ng dáº«n áº¡. Em xin cáº£m Æ¡n!",,,,,
"CÃ¡c báº¡n khi lÃ m cÃ¡c bÃ i toÃ¡n nháº­n diá»‡n qua camera hay bá»‹ cháº­m, giáº­t, lag vÃ  cÃ³ ráº¥t nhiá»u cÃ¢u há»i kiá»ƒu ""LÃ m sao cho nhanh lÃªn anh Æ¡i"", ""Cháº­m quÃ¡ anh ah!"", hay ""GPU lÃ  gÃ¬ anh, mua thÃªm cÃ³ nhanh hÆ¡n khÃ´ng?"".
HÃ£y cÃ¹ng tÃ¬m hiá»ƒu qua video nÃ y nhÃ©!
Mong ad duyá»‡t bÃ i cho cÃ¡c báº¡n newbie há»c há»i thÃªm ah!","CÃ¡c báº¡n khi lÃ m cÃ¡c bÃ i toÃ¡n nháº­n diá»‡n qua camera hay bá»‹ cháº­m, giáº­t, lag vÃ  cÃ³ ráº¥t nhiá»u cÃ¢u há»i kiá»ƒu ""LÃ m sao cho nhanh lÃªn anh Æ¡i"", ""Cháº­m quÃ¡ anh ah!"", hay ""GPU lÃ  gÃ¬ anh, mua thÃªm cÃ³ nhanh hÆ¡n khÃ´ng?"". HÃ£y cÃ¹ng tÃ¬m hiá»ƒu qua video nÃ y nhÃ©! Mong ad duyá»‡t bÃ i cho cÃ¡c báº¡n newbie há»c há»i thÃªm ah!",,,,,
"ChÃ o má»i ngÆ°á»i!
MÃ¬nh xin chia sáº» má»™t pre-trained language model tiáº¿ng Viá»‡t cho mÃ´ hÃ¬nh má»›i ná»•i gáº§n Ä‘Ã¢y lÃ  ELECTRA. MÃ´ hÃ¬nh nÃ y dá»±a trÃªn Ã½ tÆ°á»Ÿng cá»§a GAN, huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh generator Ä‘á»ƒ Ä‘oÃ¡n tá»« bá»‹ mask (giá»‘ng BERT) vÃ  má»™t mÃ´ hÃ¬nh discriminator Ä‘á»ƒ Ä‘oÃ¡n xem tá»« nÃ o bá»‹ thay tháº¿. MÃ´ hÃ¬nh nÃ y theo nhÆ° cÃ´ng bá»‘ Ä‘áº¡t Ä‘Æ°á»£c SOTA trÃªn ráº¥t nhiá»u task NLP mÃ  kÃ­ch thÆ°á»›c vÃ  thá»i gian train model láº¡i tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ. (ÄÃ¢y lÃ  má»™t trong sá»‘ Ã­t cÃ¡c nghiÃªn cá»©u cá»§a google mÃ  khÃ´ng láº¥y tÃ i nguyÃªn Ä‘Ã¨ ngÆ°á»i ğŸ¥³)
Pre-trained mÃ¬nh chia sáº» lÃ  mÃ´ hÃ¬nh ELECTRA small Ä‘Æ°á»£c train trÃªn dá»¯ liá»‡u khÃ¡ lá»›n (~50GB text raw). Do giá»›i háº¡n tÃ i nguyÃªn nÃªn má»›i chá»‰ train Ä‘Æ°á»£c 400k steps trÃªn 1 GPU 2080ti. Tuy tháº¿ nhÆ°ng pháº§n generator vÃ  discriminator hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t (má»i ngÆ°á»i xem qua tut trong repo). MÃ¬nh Ä‘Ã£ port model sang tf2 vÃ  tÃ¡ch biá»‡t hai model generator vÃ  discriminator Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ sá»­ dá»¥ng.
Link github: https://github.com/nguyenvulebinh/vietnamese-electra
PS. NghiÃªn cá»©u nÃ y cÃ³ sá»± ghÃ³p máº·t cá»§a hai pro ngÆ°á»i Viá»‡t ráº¥t ná»•i tiáº¿ng lÃ  anh Tháº¯ng LÆ°Æ¡ng vÃ  Quá»‘c LÃª. ğŸ˜
 â€” vá»›i PhÃ­ Máº¡nh KiÃªn vÃ  Nguyen Minh Phuong.","ChÃ o má»i ngÆ°á»i! MÃ¬nh xin chia sáº» má»™t pre-trained language model tiáº¿ng Viá»‡t cho mÃ´ hÃ¬nh má»›i ná»•i gáº§n Ä‘Ã¢y lÃ  ELECTRA. MÃ´ hÃ¬nh nÃ y dá»±a trÃªn Ã½ tÆ°á»Ÿng cá»§a GAN, huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh generator Ä‘á»ƒ Ä‘oÃ¡n tá»« bá»‹ mask (giá»‘ng BERT) vÃ  má»™t mÃ´ hÃ¬nh discriminator Ä‘á»ƒ Ä‘oÃ¡n xem tá»« nÃ o bá»‹ thay tháº¿. MÃ´ hÃ¬nh nÃ y theo nhÆ° cÃ´ng bá»‘ Ä‘áº¡t Ä‘Æ°á»£c SOTA trÃªn ráº¥t nhiá»u task NLP mÃ  kÃ­ch thÆ°á»›c vÃ  thá»i gian train model láº¡i tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ. (ÄÃ¢y lÃ  má»™t trong sá»‘ Ã­t cÃ¡c nghiÃªn cá»©u cá»§a google mÃ  khÃ´ng láº¥y tÃ i nguyÃªn Ä‘Ã¨ ngÆ°á»i ) Pre-trained mÃ¬nh chia sáº» lÃ  mÃ´ hÃ¬nh ELECTRA small Ä‘Æ°á»£c train trÃªn dá»¯ liá»‡u khÃ¡ lá»›n (~50GB text raw). Do giá»›i háº¡n tÃ i nguyÃªn nÃªn má»›i chá»‰ train Ä‘Æ°á»£c 400k steps trÃªn 1 GPU 2080ti. Tuy tháº¿ nhÆ°ng pháº§n generator vÃ  discriminator hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t (má»i ngÆ°á»i xem qua tut trong repo). MÃ¬nh Ä‘Ã£ port model sang tf2 vÃ  tÃ¡ch biá»‡t hai model generator vÃ  discriminator Ä‘á»ƒ má»i ngÆ°á»i cÃ³ thá»ƒ sá»­ dá»¥ng. Link github: https://github.com/nguyenvulebinh/vietnamese-electra PS. NghiÃªn cá»©u nÃ y cÃ³ sá»± ghÃ³p máº·t cá»§a hai pro ngÆ°á»i Viá»‡t ráº¥t ná»•i tiáº¿ng lÃ  anh Tháº¯ng LÆ°Æ¡ng vÃ  Quá»‘c LÃª. â€” vá»›i PhÃ­ Máº¡nh KiÃªn vÃ  Nguyen Minh Phuong.",,,,,
"Em xin phÃ©p chia sáº» bÃ i tiáº¿p theo cá»§a series MÃ¬ Python. Mong giÃºp Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n nháº¥t cho cÃ¡c báº¡n newbie.
Mong ad duyá»‡t bÃ i!",Em xin phÃ©p chia sáº» bÃ i tiáº¿p theo cá»§a series MÃ¬ Python. Mong giÃºp Ä‘Æ°á»£c nhá»¯ng kiáº¿n thá»©c cÆ¡ báº£n nháº¥t cho cÃ¡c báº¡n newbie. Mong ad duyá»‡t bÃ i!,,,,,
"Xin chÃ o má»i ngÆ°á»i,
Cho mÃ¬nh há»i co cÃ¡i project nÃ o vá» ML trÃ­ch xuáº¥t thÃ´ng tin hÃ³a Ä‘Æ¡n tá»± Ä‘á»™ng hay khÃ´ng? ThÃ´ng tin ngÆ°á»i bÃ¡n, ngÆ°á»i mua, ngÃ y hÃ³a Ä‘Æ¡n, mÃ£ sá»‘ hÃ³a Ä‘Æ¡n, sáº£n pháº©m... Hoáº·c cÃ³ cÃ´ng ty nÃ o cung cáº¥p dá»‹ch vá»¥ nÃ y ko, hoáº·c ai cÃ³ Ã½ tÆ°á»Ÿng nÃ o xin cho mÃ¬nh cÃ¡i gá»£i Ã½
Cáº£m Æ¡n má»i ngÆ°á»i","Xin chÃ o má»i ngÆ°á»i, Cho mÃ¬nh há»i co cÃ¡i project nÃ o vá» ML trÃ­ch xuáº¥t thÃ´ng tin hÃ³a Ä‘Æ¡n tá»± Ä‘á»™ng hay khÃ´ng? ThÃ´ng tin ngÆ°á»i bÃ¡n, ngÆ°á»i mua, ngÃ y hÃ³a Ä‘Æ¡n, mÃ£ sá»‘ hÃ³a Ä‘Æ¡n, sáº£n pháº©m... Hoáº·c cÃ³ cÃ´ng ty nÃ o cung cáº¥p dá»‹ch vá»¥ nÃ y ko, hoáº·c ai cÃ³ Ã½ tÆ°á»Ÿng nÃ o xin cho mÃ¬nh cÃ¡i gá»£i Ã½ Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Sau khi hoÃ n thiá»‡n dá»‹ch cuá»‘n ""Machine Learning Yearning"" vÃ  Ä‘ang á»Ÿ trong giai Ä‘oáº¡n cuá»‘i cá»§a cuá»‘n ""Dive into Deep Learning"", nhÃ³m dá»‹ch thuáº­t MLCB cÃ³ káº¿ hoáº¡ch dá»‹ch thÃªm cÃ¡c cuá»‘n sÃ¡ch giÃ¡ trá»‹ khÃ¡c.
MÃ¬nh Ä‘áº·c biá»‡t thÃ­ch cuá»‘n ""Hands-On Machine Learning with Scikit-Learn and TensorFlow 2nd edition"" (link trong comment) vÃ  mong muá»‘n phá»• biáº¿n cuá»‘n sÃ¡ch nÃ y tá»›i cÃ¡c báº¡n Ä‘á»c sá»­ dá»¥ng tiáº¿ng Viá»‡t. CÃ³ má»™t Ä‘iá»ƒm khÃ¡c biá»‡t Ä‘Ã³ lÃ  cuá»‘n sÃ¡ch nÃ y cÃ³ báº£n quyá»n nÃªn nhÃ³m khÃ´ng thá»ƒ tá»± dá»‹ch vÃ  cÃ´ng bá»‘ Ä‘Æ°á»£c. Thay vÃ o Ä‘Ã³, nhÃ³m cáº§n lÃ m há»£p Ä‘á»“ng vá»›i O'Reilly vÃ  cam káº¿t cÃ¡c váº¥n Ä‘á» vá» báº£n quyá»n, xuáº¥t báº£n cÅ©ng nhÆ° giÃ¡ bÃ¡n. NhÃ³m dá»‹ch thuáº­t lÃ m viá»‡c hoÃ n toÃ n khÃ´ng vÃ¬ lá»£i nhuáº­n; náº¿u khÃ´ng vÃ¬ báº£n quyá»n, chÃºng tÃ´i Ä‘Ã£ kÃªu gá»i cá»™ng Ä‘á»“ng cÃ¹ng dá»‹ch nhÆ° hai cuá»‘n bÃªn trÃªn.
Xin cÃ¡c báº¡n má»™t phÃºt Ä‘iá»n báº£n kháº£o sÃ¡t nÃ y Ä‘á»ƒ chÃºng tÃ´i hiá»ƒu rÃµ hÆ¡n nhu cáº§u cá»§a cá»™ng Ä‘á»“ng trÆ°á»›c khi Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh kÃ½ há»£p Ä‘á»“ng. Cáº£m Æ¡n cÃ¡c báº¡n.
https://docs.google.com/forms/d/e/1FAIpQLSeO9gzKUOW9D9tR_aFJ-grDY7UM-SjxPLLifdlSX5qyh-2rvQ/viewform
VÃ¬ sÃ¡ch cÃ³ thá»ƒ cáº­p nháº­t thÃªm theo phiÃªn báº£n cá»§a scikit learn vÃ  TensorFlow nÃªn chÃºng tÃ´i chá»‰ dá»± Ä‘á»‹nh lÃ m ebook cho báº£n hiá»‡n táº¡i.","Sau khi hoÃ n thiá»‡n dá»‹ch cuá»‘n ""Machine Learning Yearning"" vÃ  Ä‘ang á»Ÿ trong giai Ä‘oáº¡n cuá»‘i cá»§a cuá»‘n ""Dive into Deep Learning"", nhÃ³m dá»‹ch thuáº­t MLCB cÃ³ káº¿ hoáº¡ch dá»‹ch thÃªm cÃ¡c cuá»‘n sÃ¡ch giÃ¡ trá»‹ khÃ¡c. MÃ¬nh Ä‘áº·c biá»‡t thÃ­ch cuá»‘n ""Hands-On Machine Learning with Scikit-Learn and TensorFlow 2nd edition"" (link trong comment) vÃ  mong muá»‘n phá»• biáº¿n cuá»‘n sÃ¡ch nÃ y tá»›i cÃ¡c báº¡n Ä‘á»c sá»­ dá»¥ng tiáº¿ng Viá»‡t. CÃ³ má»™t Ä‘iá»ƒm khÃ¡c biá»‡t Ä‘Ã³ lÃ  cuá»‘n sÃ¡ch nÃ y cÃ³ báº£n quyá»n nÃªn nhÃ³m khÃ´ng thá»ƒ tá»± dá»‹ch vÃ  cÃ´ng bá»‘ Ä‘Æ°á»£c. Thay vÃ o Ä‘Ã³, nhÃ³m cáº§n lÃ m há»£p Ä‘á»“ng vá»›i O'Reilly vÃ  cam káº¿t cÃ¡c váº¥n Ä‘á» vá» báº£n quyá»n, xuáº¥t báº£n cÅ©ng nhÆ° giÃ¡ bÃ¡n. NhÃ³m dá»‹ch thuáº­t lÃ m viá»‡c hoÃ n toÃ n khÃ´ng vÃ¬ lá»£i nhuáº­n; náº¿u khÃ´ng vÃ¬ báº£n quyá»n, chÃºng tÃ´i Ä‘Ã£ kÃªu gá»i cá»™ng Ä‘á»“ng cÃ¹ng dá»‹ch nhÆ° hai cuá»‘n bÃªn trÃªn. Xin cÃ¡c báº¡n má»™t phÃºt Ä‘iá»n báº£n kháº£o sÃ¡t nÃ y Ä‘á»ƒ chÃºng tÃ´i hiá»ƒu rÃµ hÆ¡n nhu cáº§u cá»§a cá»™ng Ä‘á»“ng trÆ°á»›c khi Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh kÃ½ há»£p Ä‘á»“ng. Cáº£m Æ¡n cÃ¡c báº¡n. https://docs.google.com/forms/d/e/1FAIpQLSeO9gzKUOW9D9tR_aFJ-grDY7UM-SjxPLLifdlSX5qyh-2rvQ/viewform VÃ¬ sÃ¡ch cÃ³ thá»ƒ cáº­p nháº­t thÃªm theo phiÃªn báº£n cá»§a scikit learn vÃ  TensorFlow nÃªn chÃºng tÃ´i chá»‰ dá»± Ä‘á»‹nh lÃ m ebook cho báº£n hiá»‡n táº¡i.",,,,,
Cheat Sheets for Machine Learning Interview,Cheat Sheets for Machine Learning Interview,,,,,
"Dear all,
Em muá»‘n mua mÃ¡y tÃ­nh Ä‘á»ƒ bÃ n, giÃ¡ khoáº£ng 40tr Ä‘á»ƒ cháº¡y code deep learning. Ai cÃ³ cÅ© bÃ¡n giÃ¡ ráº» thÃ¬ hay quÃ¡. Hoáº·c ai cÃ³ thá»ƒ tÆ° váº¥n chá»— mua hay cáº¥u hÃ¬nh mÃ¡y thÃ¬ em cÃ¡m Æ¡n. Do em chá»‰ lÃ  giÃ¡o viÃªn tin há»c cáº¥p ba á»Ÿ quÃª mÃ  Ä‘am mÃª nghiÃªn cá»©u nÃªn mong má»i ngÆ°á»i giÃºp Ä‘á»¡ giÃ¹m.","Dear all, Em muá»‘n mua mÃ¡y tÃ­nh Ä‘á»ƒ bÃ n, giÃ¡ khoáº£ng 40tr Ä‘á»ƒ cháº¡y code deep learning. Ai cÃ³ cÅ© bÃ¡n giÃ¡ ráº» thÃ¬ hay quÃ¡. Hoáº·c ai cÃ³ thá»ƒ tÆ° váº¥n chá»— mua hay cáº¥u hÃ¬nh mÃ¡y thÃ¬ em cÃ¡m Æ¡n. Do em chá»‰ lÃ  giÃ¡o viÃªn tin há»c cáº¥p ba á»Ÿ quÃª mÃ  Ä‘am mÃª nghiÃªn cá»©u nÃªn mong má»i ngÆ°á»i giÃºp Ä‘á»¡ giÃ¹m.",,,,,
"ChÃ o cÃ¡c anh chá»‹,
em Ä‘ang Ä‘Æ°á»£c giao tÃ¬m hiá»ƒu vá» má»™t bÃ i toÃ¡n kiá»ƒu nhÆ° Ä‘áº¿m sá»‘ lÆ°á»£ng cá»§a má»™t loáº¡i object trong má»™t hÃ¬nh áº£nh.
cÃ¡c object nÃ y nÃ³i chung lÃ  gáº§n giá»‘ng nhau, kiá»ƒu nhÆ° Ä‘áº¿m sá»‘ Ä‘á»“ng xu cÃ¹ng loáº¡i Ä‘áº·t trÃªn bÃ n cháº³ng háº¡n.
em muá»‘n há»i lÃ  bÃ i toÃ¡n nÃ y thÃ¬ thuá»™c loáº¡i bÃ i toÃ¡n nÃ o trong ML vÃ  nÃªn tÃ¬m kiáº¿m theo tá»« khÃ³a nÃ o nhá»‰ ?","ChÃ o cÃ¡c anh chá»‹, em Ä‘ang Ä‘Æ°á»£c giao tÃ¬m hiá»ƒu vá» má»™t bÃ i toÃ¡n kiá»ƒu nhÆ° Ä‘áº¿m sá»‘ lÆ°á»£ng cá»§a má»™t loáº¡i object trong má»™t hÃ¬nh áº£nh. cÃ¡c object nÃ y nÃ³i chung lÃ  gáº§n giá»‘ng nhau, kiá»ƒu nhÆ° Ä‘áº¿m sá»‘ Ä‘á»“ng xu cÃ¹ng loáº¡i Ä‘áº·t trÃªn bÃ n cháº³ng háº¡n. em muá»‘n há»i lÃ  bÃ i toÃ¡n nÃ y thÃ¬ thuá»™c loáº¡i bÃ i toÃ¡n nÃ o trong ML vÃ  nÃªn tÃ¬m kiáº¿m theo tá»« khÃ³a nÃ o nhá»‰ ?",,,,,
"MÃ¬nh Ä‘ang sá»­ dá»¥ng thÆ° viá»‡n VNCoreNLP Ä‘á»ƒ tÃ¡ch tá»«. CÃ³ má»™t sá»‘ tá»« thÆ° viá»‡n tÃ¡ch khÃ´ng chÃ­nh xÃ¡c, vÃ­ dá»¥ ""Ä‘Äƒk nÃ´ng"" sau khi tÃ¡ch tá»« thÃ nh 2 token ""Ä‘Äƒk"" vÃ  ""nÃ´ng"". MÃ¬nh sau Ä‘Ã³ cÃ³ thÃªm gáº¡ch ná»‘i á»Ÿ giá»¯a, thÃ nh ""Ä‘Äƒk_nÃ´ng"" nhÆ°ng VnCoreNLP láº¡i tÃ¡ch ra thÃ nh 3 token ""Ä‘Äƒk"", ""_"" vÃ  ""nÃ´ng"" chá»© khÃ´ng coi ""Ä‘Äƒk_nÃ´ng"" lÃ  1 token.
KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» VNCoreNLP tÃ¡ch má»™t sá»‘ tá»« khÃ´ng chuáº©n á»Ÿ trÃªn khÃ´ng?","MÃ¬nh Ä‘ang sá»­ dá»¥ng thÆ° viá»‡n VNCoreNLP Ä‘á»ƒ tÃ¡ch tá»«. CÃ³ má»™t sá»‘ tá»« thÆ° viá»‡n tÃ¡ch khÃ´ng chÃ­nh xÃ¡c, vÃ­ dá»¥ ""Ä‘Äƒk nÃ´ng"" sau khi tÃ¡ch tá»« thÃ nh 2 token ""Ä‘Äƒk"" vÃ  ""nÃ´ng"". MÃ¬nh sau Ä‘Ã³ cÃ³ thÃªm gáº¡ch ná»‘i á»Ÿ giá»¯a, thÃ nh ""Ä‘Äƒk_nÃ´ng"" nhÆ°ng VnCoreNLP láº¡i tÃ¡ch ra thÃ nh 3 token ""Ä‘Äƒk"", ""_"" vÃ  ""nÃ´ng"" chá»© khÃ´ng coi ""Ä‘Äƒk_nÃ´ng"" lÃ  1 token. KhÃ´ng biáº¿t má»i ngÆ°á»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» VNCoreNLP tÃ¡ch má»™t sá»‘ tá»« khÃ´ng chuáº©n á»Ÿ trÃªn khÃ´ng?",,,,,
Dáº¡ em chÃ o máº¥y anh chá»‹ áº¡. Em má»›i báº¯t Ä‘áº§u há»c vá» Machine Learning nhÆ°ng cÃ³ tháº¥y lÃ  pháº£i tá»‘t vá» toÃ¡n. Anh/ chá»‹ cÃ³ thá»ƒ cho em biáº¿t lÃ  em pháº£i há»c nhá»¯ng dáº¡ng toÃ¡n nÃ o Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i Machine Learning khÃ´ng áº¡. Em cÃ¡m Æ¡n áº¡,Dáº¡ em chÃ o máº¥y anh chá»‹ áº¡. Em má»›i báº¯t Ä‘áº§u há»c vá» Machine Learning nhÆ°ng cÃ³ tháº¥y lÃ  pháº£i tá»‘t vá» toÃ¡n. Anh/ chá»‹ cÃ³ thá»ƒ cho em biáº¿t lÃ  em pháº£i há»c nhá»¯ng dáº¡ng toÃ¡n nÃ o Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i Machine Learning khÃ´ng áº¡. Em cÃ¡m Æ¡n áº¡,,,"#Q&A, #math, #machine_learning",,
"#Conditional_Random_Fields
Hi all,
Em Ä‘ang muá»‘n dÃ¹ng CRF layer trong Tensorflow Keras mÃ  khi load model khÃ´ng load Ä‘Æ°á»£c CRF layer. Má»i ngÆ°á»i ai tá»«ng implement CRF vá»›i Tensorflow Keras rá»“i thÃ¬ giÃºp em vá»›i áº¡. Em build on top Ä‘á»ƒ classify tá»« BiLSTM.","Hi all, Em Ä‘ang muá»‘n dÃ¹ng CRF layer trong Tensorflow Keras mÃ  khi load model khÃ´ng load Ä‘Æ°á»£c CRF layer. Má»i ngÆ°á»i ai tá»«ng implement CRF vá»›i Tensorflow Keras rá»“i thÃ¬ giÃºp em vá»›i áº¡. Em build on top Ä‘á»ƒ classify tá»« BiLSTM.",#Conditional_Random_Fields,,,,
"BÃ n chuyá»‡n minh há»a cÃ¡c con sá»‘, khÃ´ng bÃ n chuyá»‡n chÃ­nh trá»‹. CÃ¡c comment dáº¡ng hate speech hoáº·c gÃ¢y háº¥n sáº½ bá»‹ block.
Sá»± viá»‡c xáº£y ra táº¡i Milwaukee, Wisconsin trong Ä‘Ãªm báº§u cá»­ tá»•ng thá»‘ng Má»¹. CÃ³ má»™t thá»i Ä‘iá»ƒm Ä‘Æ°á»ng mÃ u xanh ""bá»—ng dÆ°ng nháº£y vá»t"" dáº«n Ä‘áº¿n nghi ngá» vá» kháº£ nÄƒng gian láº­n báº§u cá»­ vÃ¬ Ä‘iá»u nÃ y phi lÃ½. MÃ¬nh khÃ´ng kháº³ng Ä‘á»‹nh cÃ³ gian láº­n hay khÃ´ng, mÃ¬nh chá»‰ xin nÃ³i ráº±ng viá»‡c nÃ y hoÃ n toÃ n dá»… hiá»ƒu.
á» Fig 1, hÃ¬nh bÃªn trÃ¡i lÃ  sá»‘ lÆ°á»£ng phiáº¿u mÃ  bÃªn xanh vÃ  Ä‘á» nháº­n Ä‘Æ°á»£c theo thá»i gian. HÃ¬nh bÃªn pháº£i lÃ  bá»©c hÃ¬nh cÆ°á»ng Ä‘iá»‡u hÃ¬nh bÃªn trÃ¡i Ä‘Æ°á»£c chia sáº» ráº¥t rá»™ng rÃ£i trÃªn cÃ¡c trang máº¡ng xÃ£ há»™i. NhÃ¬n thoÃ¡ng qua cÃ³ váº» hai hÃ¬nh nhÆ° má»™t. Náº¿u nhÃ¬n hÃ¬nh bÃªn pháº£i, ta sáº½ tháº¥y thá»±c sá»± phi lÃ½ vÃ¬ cÃ³ má»™t thá»i Ä‘iá»ƒm mÃ  100% sá»‘ phiáº¿u báº§u Ä‘Æ°á»£c gÃ¡n cho bÃªn xanh vÃ  0% cho bÃªn Ä‘á». NhÆ°ng sá»± tháº­t hoÃ n toÃ n khÃ¡c, cáº£m giÃ¡c ban Ä‘áº§u nÃ y lÃ  do cÃ¡ch minh hoáº¡ táº¡o ra.
NhÃ¬n ká»¹ hÃ¬nh gá»‘c, ta tháº¥y ráº±ng táº¡i thá»i Ä‘iá»ƒm xáº£y ra sá»± viá»‡c, cáº£ Ä‘Æ°á»ng mÃ u xanh vÃ  máº£u Ä‘á» Ä‘á»u cÃ³ sá»± thay Ä‘á»•i vá»›i Ä‘Æ°á»ng mÃ u xanh thay Ä‘á»•i khoáº£ng 4-5 láº§n so vá»›i Ä‘Æ°á»ng mÃ u Ä‘á». Sau Ä‘Ã³ hai Ä‘Æ°á»ng gáº§n nhÆ° báº±ng nhau trong má»™t khoáº£ng thá»i gian, nhÆ°ng do Ä‘Æ°á»ng mÃ u xanh ""Ä‘Ã¨"" lÃªn Ä‘Æ°á»ng mÃ u Ä‘á» nÃªn ta cÃ³ cáº£m giÃ¡c Ä‘Æ°á»ng mÃ u Ä‘á» Ä‘á»©ng im.
BÃ¢y giá» chÃºng ta Ä‘i sÃ¢u má»™t chÃºt vÃ o ""domain knowledge"" Ä‘á»ƒ tháº¥y ráº±ng Ä‘iá»u nÃ y lÃ  bÃ¬nh thÆ°á»ng. Táº¡i thá»i Ä‘iá»ƒm nÃ y, ráº¥t nhiá»u phiáº¿u báº§u cá»­ Ä‘Æ°á»£c Ä‘áº¿m xong táº¡i Milwaukee (má»™t trong nhá»¯ng thÃ nh phá»‘ lá»›n nháº¥t bang Wisconsin) vÃ  tá»•ng sá»‘ phiáº¿u Ä‘Æ°á»£c nháº­p má»™t lÆ°á»£t thay vÃ¬ Ä‘Æ°á»£c nháº­p theo má»™t lÆ°á»£ng phiáº¿u nhá» nhÆ° cÃ¡c vÃ¹ng khÃ¡c. VÃ  náº¿u cÃ¡c báº¡n biáº¿t vá» xu hÆ°á»›ng chÃ­nh trá»‹ cá»§a nÆ°á»›c Má»¹ hÆ¡n, báº¡n sáº½ hiá»ƒu ráº±ng cÃ¡c thÃ nh phá»‘ lá»›n cÃ³ xu hÆ°á»›ng thÃ­ch mÃ u xanh hÆ¡n mÃ u Ä‘á», cÃ¡c vÃ¹ng nÃ´ng thÃ´n thÃ¬ ngÆ°á»£c láº¡i. Vá»›i thÃ nh phá»‘ nÃ y, nÄƒm 2016 mÃ u xanh giÃ nh Ä‘Æ°á»£c 77% sá»‘ phiáº¿u so vá»›i 18% cá»§a mÃ u Ä‘á» (5% phiáº¿u cÃ²n láº¡i cÃ³ mÃ u khÃ¡c). Äá»“ng thá»i, do dÃ¢n chÃºng thÃ­ch mÃ u xanh cÅ©ng thÃ­ch gá»­i phiáº¿u qua thÆ° nÃªn trong táº­p há»£p cÃ¡c phiáº¿u qua thÆ° nÃ y, tá»‰ lá»‡ xanh/Ä‘á» cÃ³ thá»ƒ cÃ²n cao hÆ¡n ná»¯a.
Cáº£m giÃ¡c ""báº¥t thÆ°á»ng"" nÃ y xáº£y ra má»™t pháº§n do thá»© tá»± Ä‘áº¿m. Náº¿u káº¿t quáº£ Ä‘Æ°á»£c cáº­p nháº­t má»—i khi má»™t phiáº¿u Ä‘Æ°á»£c Ä‘áº¿m thÃ¬ chÃºng ta sáº½ khÃ´ng tháº¥y Ä‘iá»u nÃ y. Láº¥y thÃªm táº¥m hÃ¬nh á»Ÿ Pennsylvania (Fig 2) Ä‘á»ƒ cÃ¡c báº¡n tháº¥y rÃµ mÃ u Ä‘á» cÅ©ng tá»«ng cÃ³ Ä‘oáº¡n nháº£y vá»t so vá»›i mÃ u xanh nhÆ° tháº¿ vá»›i má»™t lÆ°á»£ng lá»›n hÆ¡n nhiá»u. Quan trá»ng lÃ  mÃ u nÃ o Ä‘Æ°á»£c Ä‘áº¿m trÆ°á»›c mÃ  thÃ´i.
Ráº¥t tiáº¿c hÃ¬nh áº£nh bÃªn pháº£i trong Fig 1 láº¡i Ä‘Æ°á»£c chia sáº» rá»™ng rÃ£i tháº­m chÃ­ bá»Ÿi cáº£ nhá»¯ng báº¡n bÃ¨ cá»§a mÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u khoa há»c. Tháº­m chÃ­ cÃ³ báº¡n cÃ²n cÆ°á»i cá»£t lÃ m háº³n má»™t bÃ i bÃ¡o khoa há»c vá»›i hÃ¬nh bÃªn pháº£i Ä‘á»ƒ chá»‰ ra ráº±ng Ä‘Ã¢y lÃ  nhá»¯ng Ä‘iá»u phÃ­ lÃ½ vÃ  cháº¯c cháº¯n cÃ³ gian láº­n báº§u cá»­.
MÃ¬nh khÃ´ng kháº³ng Ä‘á»‹nh dá»¯ liá»‡u cÃ³ bá»‹ xÃ o náº¥u hay khÃ´ng, viá»‡c nÃ y chá» tÃ²a Ã¡n vÃ o viá»‡c. MÃ¬nh chá»‰ muá»‘n nÃ³i ráº±ng cÃ¡c báº¡n nÃªn cÃ³ trÃ¡ch nhiá»‡m vá»›i nhá»¯ng gÃ¬ mÃ¬nh chia sáº». Má»™t chi tiáº¿t nhá» cÃ³ thá»ƒ dáº«n tá»›i má»™t cuá»™c chiáº¿n tranh to.
MÃ¬nh Ä‘ang Ä‘á»c cuá»‘n ""How to lie with statistics"", khi nÃ o Ä‘á»c xong sáº½ tÃ³m táº¯t láº¡i vÃ  Ä‘Äƒng lÃªn Ä‘Ã¢y chÃºng ta cÃ¹ng tháº£o luáº­n.","BÃ n chuyá»‡n minh há»a cÃ¡c con sá»‘, khÃ´ng bÃ n chuyá»‡n chÃ­nh trá»‹. CÃ¡c comment dáº¡ng hate speech hoáº·c gÃ¢y háº¥n sáº½ bá»‹ block. Sá»± viá»‡c xáº£y ra táº¡i Milwaukee, Wisconsin trong Ä‘Ãªm báº§u cá»­ tá»•ng thá»‘ng Má»¹. CÃ³ má»™t thá»i Ä‘iá»ƒm Ä‘Æ°á»ng mÃ u xanh ""bá»—ng dÆ°ng nháº£y vá»t"" dáº«n Ä‘áº¿n nghi ngá» vá» kháº£ nÄƒng gian láº­n báº§u cá»­ vÃ¬ Ä‘iá»u nÃ y phi lÃ½. MÃ¬nh khÃ´ng kháº³ng Ä‘á»‹nh cÃ³ gian láº­n hay khÃ´ng, mÃ¬nh chá»‰ xin nÃ³i ráº±ng viá»‡c nÃ y hoÃ n toÃ n dá»… hiá»ƒu. á» Fig 1, hÃ¬nh bÃªn trÃ¡i lÃ  sá»‘ lÆ°á»£ng phiáº¿u mÃ  bÃªn xanh vÃ  Ä‘á» nháº­n Ä‘Æ°á»£c theo thá»i gian. HÃ¬nh bÃªn pháº£i lÃ  bá»©c hÃ¬nh cÆ°á»ng Ä‘iá»‡u hÃ¬nh bÃªn trÃ¡i Ä‘Æ°á»£c chia sáº» ráº¥t rá»™ng rÃ£i trÃªn cÃ¡c trang máº¡ng xÃ£ há»™i. NhÃ¬n thoÃ¡ng qua cÃ³ váº» hai hÃ¬nh nhÆ° má»™t. Náº¿u nhÃ¬n hÃ¬nh bÃªn pháº£i, ta sáº½ tháº¥y thá»±c sá»± phi lÃ½ vÃ¬ cÃ³ má»™t thá»i Ä‘iá»ƒm mÃ  100% sá»‘ phiáº¿u báº§u Ä‘Æ°á»£c gÃ¡n cho bÃªn xanh vÃ  0% cho bÃªn Ä‘á». NhÆ°ng sá»± tháº­t hoÃ n toÃ n khÃ¡c, cáº£m giÃ¡c ban Ä‘áº§u nÃ y lÃ  do cÃ¡ch minh hoáº¡ táº¡o ra. NhÃ¬n ká»¹ hÃ¬nh gá»‘c, ta tháº¥y ráº±ng táº¡i thá»i Ä‘iá»ƒm xáº£y ra sá»± viá»‡c, cáº£ Ä‘Æ°á»ng mÃ u xanh vÃ  máº£u Ä‘á» Ä‘á»u cÃ³ sá»± thay Ä‘á»•i vá»›i Ä‘Æ°á»ng mÃ u xanh thay Ä‘á»•i khoáº£ng 4-5 láº§n so vá»›i Ä‘Æ°á»ng mÃ u Ä‘á». Sau Ä‘Ã³ hai Ä‘Æ°á»ng gáº§n nhÆ° báº±ng nhau trong má»™t khoáº£ng thá»i gian, nhÆ°ng do Ä‘Æ°á»ng mÃ u xanh ""Ä‘Ã¨"" lÃªn Ä‘Æ°á»ng mÃ u Ä‘á» nÃªn ta cÃ³ cáº£m giÃ¡c Ä‘Æ°á»ng mÃ u Ä‘á» Ä‘á»©ng im. BÃ¢y giá» chÃºng ta Ä‘i sÃ¢u má»™t chÃºt vÃ o ""domain knowledge"" Ä‘á»ƒ tháº¥y ráº±ng Ä‘iá»u nÃ y lÃ  bÃ¬nh thÆ°á»ng. Táº¡i thá»i Ä‘iá»ƒm nÃ y, ráº¥t nhiá»u phiáº¿u báº§u cá»­ Ä‘Æ°á»£c Ä‘áº¿m xong táº¡i Milwaukee (má»™t trong nhá»¯ng thÃ nh phá»‘ lá»›n nháº¥t bang Wisconsin) vÃ  tá»•ng sá»‘ phiáº¿u Ä‘Æ°á»£c nháº­p má»™t lÆ°á»£t thay vÃ¬ Ä‘Æ°á»£c nháº­p theo má»™t lÆ°á»£ng phiáº¿u nhá» nhÆ° cÃ¡c vÃ¹ng khÃ¡c. VÃ  náº¿u cÃ¡c báº¡n biáº¿t vá» xu hÆ°á»›ng chÃ­nh trá»‹ cá»§a nÆ°á»›c Má»¹ hÆ¡n, báº¡n sáº½ hiá»ƒu ráº±ng cÃ¡c thÃ nh phá»‘ lá»›n cÃ³ xu hÆ°á»›ng thÃ­ch mÃ u xanh hÆ¡n mÃ u Ä‘á», cÃ¡c vÃ¹ng nÃ´ng thÃ´n thÃ¬ ngÆ°á»£c láº¡i. Vá»›i thÃ nh phá»‘ nÃ y, nÄƒm 2016 mÃ u xanh giÃ nh Ä‘Æ°á»£c 77% sá»‘ phiáº¿u so vá»›i 18% cá»§a mÃ u Ä‘á» (5% phiáº¿u cÃ²n láº¡i cÃ³ mÃ u khÃ¡c). Äá»“ng thá»i, do dÃ¢n chÃºng thÃ­ch mÃ u xanh cÅ©ng thÃ­ch gá»­i phiáº¿u qua thÆ° nÃªn trong táº­p há»£p cÃ¡c phiáº¿u qua thÆ° nÃ y, tá»‰ lá»‡ xanh/Ä‘á» cÃ³ thá»ƒ cÃ²n cao hÆ¡n ná»¯a. Cáº£m giÃ¡c ""báº¥t thÆ°á»ng"" nÃ y xáº£y ra má»™t pháº§n do thá»© tá»± Ä‘áº¿m. Náº¿u káº¿t quáº£ Ä‘Æ°á»£c cáº­p nháº­t má»—i khi má»™t phiáº¿u Ä‘Æ°á»£c Ä‘áº¿m thÃ¬ chÃºng ta sáº½ khÃ´ng tháº¥y Ä‘iá»u nÃ y. Láº¥y thÃªm táº¥m hÃ¬nh á»Ÿ Pennsylvania (Fig 2) Ä‘á»ƒ cÃ¡c báº¡n tháº¥y rÃµ mÃ u Ä‘á» cÅ©ng tá»«ng cÃ³ Ä‘oáº¡n nháº£y vá»t so vá»›i mÃ u xanh nhÆ° tháº¿ vá»›i má»™t lÆ°á»£ng lá»›n hÆ¡n nhiá»u. Quan trá»ng lÃ  mÃ u nÃ o Ä‘Æ°á»£c Ä‘áº¿m trÆ°á»›c mÃ  thÃ´i. Ráº¥t tiáº¿c hÃ¬nh áº£nh bÃªn pháº£i trong Fig 1 láº¡i Ä‘Æ°á»£c chia sáº» rá»™ng rÃ£i tháº­m chÃ­ bá»Ÿi cáº£ nhá»¯ng báº¡n bÃ¨ cá»§a mÃ¬nh Ä‘ang lÃ m nghiÃªn cá»©u khoa há»c. Tháº­m chÃ­ cÃ³ báº¡n cÃ²n cÆ°á»i cá»£t lÃ m háº³n má»™t bÃ i bÃ¡o khoa há»c vá»›i hÃ¬nh bÃªn pháº£i Ä‘á»ƒ chá»‰ ra ráº±ng Ä‘Ã¢y lÃ  nhá»¯ng Ä‘iá»u phÃ­ lÃ½ vÃ  cháº¯c cháº¯n cÃ³ gian láº­n báº§u cá»­. MÃ¬nh khÃ´ng kháº³ng Ä‘á»‹nh dá»¯ liá»‡u cÃ³ bá»‹ xÃ o náº¥u hay khÃ´ng, viá»‡c nÃ y chá» tÃ²a Ã¡n vÃ o viá»‡c. MÃ¬nh chá»‰ muá»‘n nÃ³i ráº±ng cÃ¡c báº¡n nÃªn cÃ³ trÃ¡ch nhiá»‡m vá»›i nhá»¯ng gÃ¬ mÃ¬nh chia sáº». Má»™t chi tiáº¿t nhá» cÃ³ thá»ƒ dáº«n tá»›i má»™t cuá»™c chiáº¿n tranh to. MÃ¬nh Ä‘ang Ä‘á»c cuá»‘n ""How to lie with statistics"", khi nÃ o Ä‘á»c xong sáº½ tÃ³m táº¯t láº¡i vÃ  Ä‘Äƒng lÃªn Ä‘Ã¢y chÃºng ta cÃ¹ng tháº£o luáº­n.",,,,,
AI Ä‘i cÃ¹ng Covid-19,AI Ä‘i cÃ¹ng Covid-19,,,,,
"#AVATECH #SHAREDATA
Má»™t sá»‘ lá»—i ráº¥t dá»… xáº£y ra trong ngÃ nh sáº£n xuáº¥t váº£i nhÆ° lÃ  rÃ¡ch, váº¿t cÃ o, xÆ°á»›c trÃªn bá» máº·t váº£i, thiáº¿u sá»£i,...láº¡i gÃ¢y áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n cháº¥t lÆ°á»£ng váº£i. Äiá»u Ä‘áº·c biáº¿t cÃ¡c loáº¡i lá»—i nÃ y khÃ¡ khÃ³ phÃ¡t hiá»‡n, dá»… gÃ¢y thiáº¿u sÃ³t khi sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng. Hiá»‡n nay má»™t sá»‘ nÆ°á»›c trÃªn tháº¿ giá»›i Ä‘Ã£ sá»­ dá»¥ng há»‡ thá»‘ng AI há»c trá»±c tiáº¿p dá»¯ liá»‡u tá»« hÃ¬nh áº£nh vÃ  cho káº¿t quáº£ nhanh hÆ¡n, chÃ­nh xÃ¡c hÆ¡n.
Hi vá»ng bá»™ dá»¯ liá»‡u dÆ°á»›i Ä‘Ã¢y sáº½ giÃºp cÃ¡c báº¡n nghiÃªn cá»©u vÃ  giáº£i quyáº¿t bÃ i toÃ¡n nÃ y.
http://avatech.com.vn/kiem-tra-phat-hien-loi-san-pham/kiem-tra-chat-luong-vai-soi","Má»™t sá»‘ lá»—i ráº¥t dá»… xáº£y ra trong ngÃ nh sáº£n xuáº¥t váº£i nhÆ° lÃ  rÃ¡ch, váº¿t cÃ o, xÆ°á»›c trÃªn bá» máº·t váº£i, thiáº¿u sá»£i,...láº¡i gÃ¢y áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n cháº¥t lÆ°á»£ng váº£i. Äiá»u Ä‘áº·c biáº¿t cÃ¡c loáº¡i lá»—i nÃ y khÃ¡ khÃ³ phÃ¡t hiá»‡n, dá»… gÃ¢y thiáº¿u sÃ³t khi sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng. Hiá»‡n nay má»™t sá»‘ nÆ°á»›c trÃªn tháº¿ giá»›i Ä‘Ã£ sá»­ dá»¥ng há»‡ thá»‘ng AI há»c trá»±c tiáº¿p dá»¯ liá»‡u tá»« hÃ¬nh áº£nh vÃ  cho káº¿t quáº£ nhanh hÆ¡n, chÃ­nh xÃ¡c hÆ¡n. Hi vá»ng bá»™ dá»¯ liá»‡u dÆ°á»›i Ä‘Ã¢y sáº½ giÃºp cÃ¡c báº¡n nghiÃªn cá»©u vÃ  giáº£i quyáº¿t bÃ i toÃ¡n nÃ y. http://avatech.com.vn/kiem-tra-phat-hien-loi-san-pham/kiem-tra-chat-luong-vai-soi",#AVATECH	#SHAREDATA,,,,
"Bayesian Optimization lÃ  má»™t thuáº­t toÃ¡n tá»‘i Æ°u thÆ°á»ng dÃ¹ng trong cÃ¡c bÃ i tá»‘i tá»‘i Æ°u hÃ m sá»‘ há»™p Ä‘en (black-box functions) khi mÃ  chÃºng ta khÃ´ng cÃ³ cÃ´ng thá»©c tÆ°á»ng minh (hoáº·c cÃ´ng thá»©c tÆ°á»ng minh quÃ¡ khÃ³ Ä‘á»ƒ phÃ¢n tÃ­ch), chi phÃ­ tÃ­nh toÃ¡n hÃ m sá»‘ lá»›n. Trong bÃ i viáº¿t nÃ y chÃºng ta cÃ¹ng kháº£o sÃ¡t viá»‡c ""khai thÃ¡c"" & ""khÃ¡m phÃ¡"" Ä‘Ã¡nh Ä‘á»•i (exploitation vs. exploration tradeoff) nhÆ° tháº¿ nÃ o trong bÃ i toÃ¡n nÃ y, vÃ  chiáº¿n thuáº­t cá»§a Bayesian Optimization lÃ  gÃ¬ thÃ´ng qua pháº§n cÃ i Ä‘áº·t Ä‘Æ¡n giáº£n Ä‘Æ°á»£c trá»±c quan hÃ³a!
<3 ThetaLog - Nháº­t kÃ½ Theta!","Bayesian Optimization lÃ  má»™t thuáº­t toÃ¡n tá»‘i Æ°u thÆ°á»ng dÃ¹ng trong cÃ¡c bÃ i tá»‘i tá»‘i Æ°u hÃ m sá»‘ há»™p Ä‘en (black-box functions) khi mÃ  chÃºng ta khÃ´ng cÃ³ cÃ´ng thá»©c tÆ°á»ng minh (hoáº·c cÃ´ng thá»©c tÆ°á»ng minh quÃ¡ khÃ³ Ä‘á»ƒ phÃ¢n tÃ­ch), chi phÃ­ tÃ­nh toÃ¡n hÃ m sá»‘ lá»›n. Trong bÃ i viáº¿t nÃ y chÃºng ta cÃ¹ng kháº£o sÃ¡t viá»‡c ""khai thÃ¡c"" & ""khÃ¡m phÃ¡"" Ä‘Ã¡nh Ä‘á»•i (exploitation vs. exploration tradeoff) nhÆ° tháº¿ nÃ o trong bÃ i toÃ¡n nÃ y, vÃ  chiáº¿n thuáº­t cá»§a Bayesian Optimization lÃ  gÃ¬ thÃ´ng qua pháº§n cÃ i Ä‘áº·t Ä‘Æ¡n giáº£n Ä‘Æ°á»£c trá»±c quan hÃ³a! <3 ThetaLog - Nháº­t kÃ½ Theta!",,,"#sharing, #math",,
"Em chÃ o má»i ngÆ°á»i, em lÃ  newbie:
em cÃ³ train má»™t mÃ´ hÃ¬nh deep learning LSTM báº±ng colab vÃ  lÆ°u láº¡i file .h5
****
nhÆ°ng khi load file h5 vÃ o model thÃ¬  cÃ¢u tráº£ lá»i do mÃ´ hÃ¬nh sinh ra khÃ´ng cÃ³ Ã½ nghÄ©a nhÆ° tá»± train
****
em cÃ³ tÃ¬m hiá»ƒu thÃ¬ nhá»¯ng model khÃ¡c ngta cÃ³ load file weights, váº­y file h5 vÃ  file weight thÃ¬ anh tháº¥y em nÃªn chá»n load file nÃ o hay thÆ°á»ng thÃ¬ ngta sáº½ load cáº£ 2 loáº¡i vÃ o áº¡, em cáº£m Æ¡n áº¡","Em chÃ o má»i ngÆ°á»i, em lÃ  newbie: em cÃ³ train má»™t mÃ´ hÃ¬nh deep learning LSTM báº±ng colab vÃ  lÆ°u láº¡i file .h5 **** nhÆ°ng khi load file h5 vÃ o model thÃ¬ cÃ¢u tráº£ lá»i do mÃ´ hÃ¬nh sinh ra khÃ´ng cÃ³ Ã½ nghÄ©a nhÆ° tá»± train **** em cÃ³ tÃ¬m hiá»ƒu thÃ¬ nhá»¯ng model khÃ¡c ngta cÃ³ load file weights, váº­y file h5 vÃ  file weight thÃ¬ anh tháº¥y em nÃªn chá»n load file nÃ o hay thÆ°á»ng thÃ¬ ngta sáº½ load cáº£ 2 loáº¡i vÃ o áº¡, em cáº£m Æ¡n áº¡",,,,,
"xin chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n.
em Ä‘ang code 1 chÆ°Æ¡ng trÃ¬nh xÃ i CNN cá»§a pytorch nhÆ°ng em Ä‘ang gáº·p pháº£i 1 váº¥n Ä‘á» ráº±ng khi em dÃ¹ng dataloader cÃ³ shuffle = True thÃ¬ chÆ°Æ¡ng trÃ¬nh hiá»‡n ra lá»—i then stack expects each tensor to be equal size, but got [107] at entry 0 and [82] at entry 1. NhÆ°ng khi em cho shuffle = Flase chÆ°Æ¡ng trÃ¬nh khÃ´ng sáº£y ra lá»—i.
class FruitDataLoader(Dataset):
def __init__(self,dataset):
#random.shuffle(dataset)
self.__len__ = len(dataset)
self.datas = dataset
self.train_transform = transforms.Compose([
transforms.Resize((100,100)),
transforms.ToTensor()
])
def __getitem__(self,index):
x = read_image(self.datas[index][0])
y = self.datas[index][-1]
x = self.train_transform(x)
return x,y
def __len__(self):
return self.__len__
model = FruitCNN(262)
train_dataset = FruitDataLoader(dataset)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
batch_size=BATCH_SIZE,
shuffle=True)
Ä‘Ã¢y lÃ  code cá»§a em mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ em Ä‘Ã£ search vÃ  khÃ´ng biáº¿t fix á»Ÿ Ä‘Ã¢u Ä‘á»ƒ cÃ³ thá»ƒ shuffle Ä‘Æ°á»£c. Ã€ cÃ²n ná»¯a em cÃ³ sÃ i Batch_size = 1 thÃ¬ shuffle=True Ä‘Æ°á»£c luÃ´n :( .","xin chÃ o anh chá»‹ vÃ  cÃ¡c báº¡n. em Ä‘ang code 1 chÆ°Æ¡ng trÃ¬nh xÃ i CNN cá»§a pytorch nhÆ°ng em Ä‘ang gáº·p pháº£i 1 váº¥n Ä‘á» ráº±ng khi em dÃ¹ng dataloader cÃ³ shuffle = True thÃ¬ chÆ°Æ¡ng trÃ¬nh hiá»‡n ra lá»—i then stack expects each tensor to be equal size, but got [107] at entry 0 and [82] at entry 1. NhÆ°ng khi em cho shuffle = Flase chÆ°Æ¡ng trÃ¬nh khÃ´ng sáº£y ra lá»—i. class FruitDataLoader(Dataset): def __init__(self,dataset): self.__len__ = len(dataset) self.datas = dataset self.train_transform = transforms.Compose([ transforms.Resize((100,100)), transforms.ToTensor() ]) def __getitem__(self,index): x = read_image(self.datas[index][0]) y = self.datas[index][-1] x = self.train_transform(x) return x,y def __len__(self): return self.__len__ model = FruitCNN(262) train_dataset = FruitDataLoader(dataset) train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True) Ä‘Ã¢y lÃ  code cá»§a em mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ em Ä‘Ã£ search vÃ  khÃ´ng biáº¿t fix á»Ÿ Ä‘Ã¢u Ä‘á»ƒ cÃ³ thá»ƒ shuffle Ä‘Æ°á»£c. Ã€ cÃ²n ná»¯a em cÃ³ sÃ i Batch_size = 1 thÃ¬ shuffle=True Ä‘Æ°á»£c luÃ´n :( .",#random.shuffle(dataset),,,,
"ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, Em Ä‘ang lÃ m há»‡ thá»‘ng SNORT Báº±ng viá»‡c sá»­ dá»¥ng thuáº­t toÃ¡n KNN Ä‘á»ƒ lá»c cÃ¡c cáº£nh bÃ¡o tá»« há»‡ thá»‘ng Snort. Má»i ngÆ°á»i cho em xin hÆ°á»›ng giáº£i quyáº¿t vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o anh chá»‹ vÃ  cÃ¡c báº¡n, Em Ä‘ang lÃ m há»‡ thá»‘ng SNORT Báº±ng viá»‡c sá»­ dá»¥ng thuáº­t toÃ¡n KNN Ä‘á»ƒ lá»c cÃ¡c cáº£nh bÃ¡o tá»« há»‡ thá»‘ng Snort. Má»i ngÆ°á»i cho em xin hÆ°á»›ng giáº£i quyáº¿t vá»›i áº¡. Em cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"Em chÃ o cÃ¡c anh. Em Ä‘ang tham dá»± cuá»™c thi https://challenge.zalo.ai/.
Äá» bÃ i Traffic Sign Detection yÃªu cáº§u ko cho dÃ¹ng pretrain. Váº­y cÃ¡c a cho em há»i em dÃ¹ng YOLO , em cÃ³ train vÃ³i data cá»§a Zalo cho thÃ¬ cÃ³ gá»i pretrain ko ah? Hay transfer learning!?","Em chÃ o cÃ¡c anh. Em Ä‘ang tham dá»± cuá»™c thi https://challenge.zalo.ai/. Äá» bÃ i Traffic Sign Detection yÃªu cáº§u ko cho dÃ¹ng pretrain. Váº­y cÃ¡c a cho em há»i em dÃ¹ng YOLO , em cÃ³ train vÃ³i data cá»§a Zalo cho thÃ¬ cÃ³ gá»i pretrain ko ah? Hay transfer learning!?",,,,,
"ChÃ o má»i ngÆ°á»i,
CÃ³ ai biáº¿t cÃ³ trang web nÃ o Ä‘Äƒng cáº§n tÃ¬m ngÆ°á»i lÃ m project machine learning ngoÃ i giá» mÃ  cÃ³ tráº£ tiá»n, kiá»ƒu lÃ m cuá»‘i tuáº§n hoáº·c lÃ m ban Ä‘Ãªm. Láº¥y vÃ­ dá»¥ nhÆ° ngÆ°á»i ta Ä‘Æ°a mÃ¬nh 1 project, yÃªu cáº§u lÃ m trong vÃ²ng 30 ngÃ y, vá»›i cÃ³ yÃªu cáº§u vá» metric. Máº¥y hÃ´m trÆ°á»›c mÃ¬nh cÃ³ tÃ¬m tháº¥y 1 trang web nhÆ° tháº¿ nhÆ°ng giá» láº¡i tÃ¬m ko ra.
Thanks má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, CÃ³ ai biáº¿t cÃ³ trang web nÃ o Ä‘Äƒng cáº§n tÃ¬m ngÆ°á»i lÃ m project machine learning ngoÃ i giá» mÃ  cÃ³ tráº£ tiá»n, kiá»ƒu lÃ m cuá»‘i tuáº§n hoáº·c lÃ m ban Ä‘Ãªm. Láº¥y vÃ­ dá»¥ nhÆ° ngÆ°á»i ta Ä‘Æ°a mÃ¬nh 1 project, yÃªu cáº§u lÃ m trong vÃ²ng 30 ngÃ y, vá»›i cÃ³ yÃªu cáº§u vá» metric. Máº¥y hÃ´m trÆ°á»›c mÃ¬nh cÃ³ tÃ¬m tháº¥y 1 trang web nhÆ° tháº¿ nhÆ°ng giá» láº¡i tÃ¬m ko ra. Thanks má»i ngÆ°á»i.",,,,,
"ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang lÃ m Ä‘á» tÃ i vá» Ä‘áº¿m ngÆ°á»i trong há»“ bÆ¡i thÃ´ng qua camera an ninh. Em cÃ³ thá»­ dÃ¹ng yolo v4 Ä‘á»ƒ Ä‘áº¿m tuy nhiÃªn model chá»‰ Ä‘em láº¡i hiá»‡u quáº£ vá»›i nhá»¯ng áº£nh cáº­n cÃ²n nhá»¯ng áº£nh cá»§a camera an ninh thÃ¬ hÆ¡i khÃ³ (trong áº£nh dÆ°á»›i). Mong má»i ngÆ°á»i cho em lá»i khuyÃªn hay kinh nghiá»‡m vá» xá»­ lÃ½ Ä‘á» tÃ i nÃ y. Em xin cáº£m Æ¡n","ChÃ o má»i ngÆ°á»i, hiá»‡n em Ä‘ang lÃ m Ä‘á» tÃ i vá» Ä‘áº¿m ngÆ°á»i trong há»“ bÆ¡i thÃ´ng qua camera an ninh. Em cÃ³ thá»­ dÃ¹ng yolo v4 Ä‘á»ƒ Ä‘áº¿m tuy nhiÃªn model chá»‰ Ä‘em láº¡i hiá»‡u quáº£ vá»›i nhá»¯ng áº£nh cáº­n cÃ²n nhá»¯ng áº£nh cá»§a camera an ninh thÃ¬ hÆ¡i khÃ³ (trong áº£nh dÆ°á»›i). Mong má»i ngÆ°á»i cho em lá»i khuyÃªn hay kinh nghiá»‡m vá» xá»­ lÃ½ Ä‘á» tÃ i nÃ y. Em xin cáº£m Æ¡n",,,,,
"ChÃ o cáº£ nhÃ , mÃ¬nh sáº¯p tá»›i cÃ³ nÃ³i chuyá»‡n á»Ÿ Toronto Machine Learning Society annual event vÃ  cÃ³ 2 free tickets. Báº¡n nÃ o muá»‘n Ä‘i thÃ¬ email mÃ¬nh chip@huyenchip.com nhÃ©! https://www.eventbrite.ca/e/toronto-machine-learning-society-tmls-2020-annual-conference-expo-tickets-115917822327","ChÃ o cáº£ nhÃ , mÃ¬nh sáº¯p tá»›i cÃ³ nÃ³i chuyá»‡n á»Ÿ Toronto Machine Learning Society annual event vÃ  cÃ³ 2 free tickets. Báº¡n nÃ o muá»‘n Ä‘i thÃ¬ email mÃ¬nh chip@huyenchip.com nhÃ©! https://www.eventbrite.ca/e/toronto-machine-learning-society-tmls-2020-annual-conference-expo-tickets-115917822327",,,,,
"Hi mn.
Mn cho em há»i lÃ  Em nháº­n dáº¡ng váº­t thá»ƒ pháº£i resize áº£nh vá» kÃ­ch thÆ°á»›c 32x32. NhÆ°ng Ä‘á»‘i vá»›i nhá»¯ng áº£nh kÃ­ch thÆ°á»›c nhá» hÆ¡n ko resize vá» Ä‘Æ°á»£c thÃ¬ chÆ°Æ¡ng trÃ¬nh bá»‹ lá»—i.
Em ngÆ°á»i cho em há»i cÃ¡ch Ä‘á»ƒ fix vá»›i áº¡. E cáº£m Æ¡n",Hi mn. Mn cho em há»i lÃ  Em nháº­n dáº¡ng váº­t thá»ƒ pháº£i resize áº£nh vá» kÃ­ch thÆ°á»›c 32x32. NhÆ°ng Ä‘á»‘i vá»›i nhá»¯ng áº£nh kÃ­ch thÆ°á»›c nhá» hÆ¡n ko resize vá» Ä‘Æ°á»£c thÃ¬ chÆ°Æ¡ng trÃ¬nh bá»‹ lá»—i. Em ngÆ°á»i cho em há»i cÃ¡ch Ä‘á»ƒ fix vá»›i áº¡. E cáº£m Æ¡n,,,,,
"chÃ o m.n
e cÃ³ lÃ m 1 projcet nhá» phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng vá»›i yolo4, e gáº·p 1 váº¥n Ä‘á» nho nhá» lÃ  e dÃ¹ng 2 webcam tá»‘c Ä‘á»™ khÃ¡ cháº­m(0.33 fps)
cho e há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ trong1 thá»i Ä‘iá»ƒm chá»‰ cÃ³ 1 webcam cháº¡y khÃ´ng áº¡? hay cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ lÃªn k áº¡@","chÃ o m.n e cÃ³ lÃ m 1 projcet nhá» phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng vá»›i yolo4, e gáº·p 1 váº¥n Ä‘á» nho nhá» lÃ  e dÃ¹ng 2 webcam tá»‘c Ä‘á»™ khÃ¡ cháº­m(0.33 fps) cho e há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ trong1 thá»i Ä‘iá»ƒm chá»‰ cÃ³ 1 webcam cháº¡y khÃ´ng áº¡? hay cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ lÃªn k áº¡@",,,,,
"Má»i ngÆ°á»i cho em há»i, cÃ¡i nÃ y lÃ  váº¥n Ä‘á» lÃ½ thuyáº¿t thÃ´i áº¡.
Trong K-means clustering, ban Ä‘áº§u chá»n random K Ä‘iá»ƒm lÃ m centroids, vÃ  xáº¿p cÃ¡c data points vÃ o K clusters dá»±a vÃ o khoáº£ng cÃ¡ch tá»›i cÃ¡c centroids. Giáº£ sá»­ cÃ³ Ä‘iá»ƒm X1 cÃ³ cÃ¹ng khoáº£ng cÃ¡ch tá»›i 2 centroids lÃ  C1 vÃ  C2, thÃ¬ á»Ÿ láº§n phÃ¢n bá»• data nÃ y lÃ m sao Ä‘á»ƒ chá»n X1 thuá»™c C1 hay C2 áº¡?","Má»i ngÆ°á»i cho em há»i, cÃ¡i nÃ y lÃ  váº¥n Ä‘á» lÃ½ thuyáº¿t thÃ´i áº¡. Trong K-means clustering, ban Ä‘áº§u chá»n random K Ä‘iá»ƒm lÃ m centroids, vÃ  xáº¿p cÃ¡c data points vÃ o K clusters dá»±a vÃ o khoáº£ng cÃ¡ch tá»›i cÃ¡c centroids. Giáº£ sá»­ cÃ³ Ä‘iá»ƒm X1 cÃ³ cÃ¹ng khoáº£ng cÃ¡ch tá»›i 2 centroids lÃ  C1 vÃ  C2, thÃ¬ á»Ÿ láº§n phÃ¢n bá»• data nÃ y lÃ m sao Ä‘á»ƒ chá»n X1 thuá»™c C1 hay C2 áº¡?",,,,,
"MÃ¬nh cÃ³ Ä‘ang lÃ m má»™t project vá» Virtual Background. Tuy khÃ´ng to tÃ¡t gÃ¬ cho láº¯m nhÆ°ng cÅ©ng xin máº¡n phÃ©p chia sáº» vá»›i má»i ngÆ°á»i. Project á»Ÿ link https://github.com/tamnguyenvan/beecam.
Vá» Ä‘áº¡i khÃ¡i, chÆ°Æ¡ng trÃ¬nh cho phÃ©p thay Ä‘á»•i hÃ¬nh ná»n tá»« nguá»“n webcam/camera theo thá»i gian thá»±c trÃªn CPU. Há»— trá»£ virtual camera qua Ä‘Ã³ cÃ³ thá»ƒ káº¿t ná»‘i trá»±c tiáº¿p tá»›i cÃ¡c pháº§n má»m nhÆ° Skype, Zoom. MÃ¬nh cÃ³ build sáºµn má»™t báº£n cho Windows chá»‰ cáº§n táº£i vá» vÃ  cháº¡y.
Hy vá»ng nÃ³ cÃ³ Ã­ch cho ai Ä‘Ã³ ^^","MÃ¬nh cÃ³ Ä‘ang lÃ m má»™t project vá» Virtual Background. Tuy khÃ´ng to tÃ¡t gÃ¬ cho láº¯m nhÆ°ng cÅ©ng xin máº¡n phÃ©p chia sáº» vá»›i má»i ngÆ°á»i. Project á»Ÿ link https://github.com/tamnguyenvan/beecam. Vá» Ä‘áº¡i khÃ¡i, chÆ°Æ¡ng trÃ¬nh cho phÃ©p thay Ä‘á»•i hÃ¬nh ná»n tá»« nguá»“n webcam/camera theo thá»i gian thá»±c trÃªn CPU. Há»— trá»£ virtual camera qua Ä‘Ã³ cÃ³ thá»ƒ káº¿t ná»‘i trá»±c tiáº¿p tá»›i cÃ¡c pháº§n má»m nhÆ° Skype, Zoom. MÃ¬nh cÃ³ build sáºµn má»™t báº£n cho Windows chá»‰ cáº§n táº£i vá» vÃ  cháº¡y. Hy vá»ng nÃ³ cÃ³ Ã­ch cho ai Ä‘Ã³ ^^",,,,,
"mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Yolov5, khÃ´ng biáº¿t máº¥y sá»‘ mÃ¬nh khoan trÃ²n Ä‘á» cÃ³ pháº£i xÃ¡c suáº¥t phÃ¢n loáº¡i khÃ´ng?, lÃ m sao mÃ¬nh cÃ³ thá»ƒ láº¥y Ä‘Æ°á»£c nÃ³ vá» sau khi test tá»«ng hÃ¬nh","mÃ¬nh Ä‘ang tÃ¬m hiá»ƒu vá» Yolov5, khÃ´ng biáº¿t máº¥y sá»‘ mÃ¬nh khoan trÃ²n Ä‘á» cÃ³ pháº£i xÃ¡c suáº¥t phÃ¢n loáº¡i khÃ´ng?, lÃ m sao mÃ¬nh cÃ³ thá»ƒ láº¥y Ä‘Æ°á»£c nÃ³ vá» sau khi test tá»«ng hÃ¬nh",,,,,
"Em kÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u vá» Liveness Detection / Chá»‘ng giáº£ máº¡o trong nháº­n diá»‡n khuÃ´n máº·t vÃ  cÃ³ mÆ°á»£n Ä‘Æ°á»£c má»™t chiáº¿c Camera 3D nÃªn em xin máº¡n phÃ©p lÃ m bÃ i review demo mong giÃºp Ä‘á»¡ Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c
Mong ad duyá»‡t bÃ i!",Em kÃ­nh chÃ o cÃ¡c bÃ¡c. NhÃ¢n dá»‹p Ä‘ang nghiÃªn cá»©u vá» Liveness Detection / Chá»‘ng giáº£ máº¡o trong nháº­n diá»‡n khuÃ´n máº·t vÃ  cÃ³ mÆ°á»£n Ä‘Æ°á»£c má»™t chiáº¿c Camera 3D nÃªn em xin máº¡n phÃ©p lÃ m bÃ i review demo mong giÃºp Ä‘á»¡ Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c Mong ad duyá»‡t bÃ i!,,,,,
"Dáº¡ em chÃ o má»i ngÆ°á»i. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÃ¡ch cÃ¡c sá»‘ trong áº£nh ra Ä‘á»ƒ train , vÃ  nháº­n biáº¿t tá»a Ä‘á»™ cá»§a cá»§a con sá»‘ mÃ¬nh mong muá»‘n khÃ´ng áº¡","Dáº¡ em chÃ o má»i ngÆ°á»i. CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ tÃ¡ch cÃ¡c sá»‘ trong áº£nh ra Ä‘á»ƒ train , vÃ  nháº­n biáº¿t tá»a Ä‘á»™ cá»§a cá»§a con sá»‘ mÃ¬nh mong muá»‘n khÃ´ng áº¡",,,,,
"Hi má»i ngÆ°á»i,
Em vá»«a má»›i báº¯t Ä‘áº§u há»c Computer Vision cho máº£ng VR/AR. CÃ³ anh chá»‹ nÃ o trong group mÃ¬nh cÃ³ kinh nghiá»‡m vá» máº£ng nÃ y cho em há»i nÃªn báº¯t Ä‘áº§u há»c tá»« Ä‘Ã¢u áº¡? Em xin cáº£m Æ¡n.
P/S: Em Ä‘ang muá»‘n Ä‘Ã o sÃ¢u vá» Ã¡p dá»¥ng GANs trong 3D Object/Human shape. CÃ¡c technique vá»›i 2D image thÃ¬ em hiá»ƒu nhÆ°ng cÃ²n 3D thÃ¬ em tháº¥y cÃ²n phá»¥ thuá»™c nhiá»u vá» system vÃ  rendering ná»¯a, em khÃ´ng rÃ nh nÃªn há»i má»i ngÆ°á»i áº¡.","Hi má»i ngÆ°á»i, Em vá»«a má»›i báº¯t Ä‘áº§u há»c Computer Vision cho máº£ng VR/AR. CÃ³ anh chá»‹ nÃ o trong group mÃ¬nh cÃ³ kinh nghiá»‡m vá» máº£ng nÃ y cho em há»i nÃªn báº¯t Ä‘áº§u há»c tá»« Ä‘Ã¢u áº¡? Em xin cáº£m Æ¡n. P/S: Em Ä‘ang muá»‘n Ä‘Ã o sÃ¢u vá» Ã¡p dá»¥ng GANs trong 3D Object/Human shape. CÃ¡c technique vá»›i 2D image thÃ¬ em hiá»ƒu nhÆ°ng cÃ²n 3D thÃ¬ em tháº¥y cÃ²n phá»¥ thuá»™c nhiá»u vá» system vÃ  rendering ná»¯a, em khÃ´ng rÃ nh nÃªn há»i má»i ngÆ°á»i áº¡.",,,,,
CÃ³ anh/chá»‹ nÃ o Ä‘Ã£ apply financial aid thÃ nh cÃ´ng á»Ÿ khoÃ¡ deep learning specialization trÃªn coursera chÆ°a áº¡ kinh nghiá»‡m fill form vá»›i áº¡ em xin cáº£m Æ¡n.,CÃ³ anh/chá»‹ nÃ o Ä‘Ã£ apply financial aid thÃ nh cÃ´ng á»Ÿ khoÃ¡ deep learning specialization trÃªn coursera chÆ°a áº¡ kinh nghiá»‡m fill form vá»›i áº¡ em xin cáº£m Æ¡n.,,,,,
"#crawler
ChÃ o má»i ngÆ°á»i.
Hiá»‡n táº¡i em cÃ³ 1 list ráº¥t nhiá»u tá»« tiáº¿ng anh, vÃ  em muá»‘n thu tháº­p cÃ¡c cÃ¢u chá»©a má»—i tá»« Ä‘Ã³. Váº­y cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ crawl cÃ¡c cÃ¢u cá»§a má»—i tá»« trÃªn internet khÃ´ng áº¡ ? VÃ­ dá»¥ trong wiki thÃ¬ em chá»‰ cáº§n cÃ¡c cÃ¢u á»Ÿ pháº§n Ä‘á»‹nh nghÄ©a khi search tá»« Ä‘Ã³. KhÃ´ng biáº¿t cÃ³ ai cÃ³ kinh nghiá»‡m vá» váº¥n Ä‘á» nÃ y khÃ´ng áº¡ ?
Em cáº£m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em cÃ³ 1 list ráº¥t nhiá»u tá»« tiáº¿ng anh, vÃ  em muá»‘n thu tháº­p cÃ¡c cÃ¢u chá»©a má»—i tá»« Ä‘Ã³. Váº­y cho em há»i cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ crawl cÃ¡c cÃ¢u cá»§a má»—i tá»« trÃªn internet khÃ´ng áº¡ ? VÃ­ dá»¥ trong wiki thÃ¬ em chá»‰ cáº§n cÃ¡c cÃ¢u á»Ÿ pháº§n Ä‘á»‹nh nghÄ©a khi search tá»« Ä‘Ã³. KhÃ´ng biáº¿t cÃ³ ai cÃ³ kinh nghiá»‡m vá» váº¥n Ä‘á» nÃ y khÃ´ng áº¡ ? Em cáº£m Æ¡n áº¡.",#crawler,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» bÃ i bÃ¡o Vision Transformer, giá» Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng trÃªn ArXiv https://arxiv.org/pdf/2010.11929.pdf. TÃ¡c giáº£ Ä‘Ã£ chia sáº» source code gá»‘c (viáº¿t báº±ng JAX) táº¡i Ä‘Ã¢y https://github.com/google-research/vision_transformer/tree/master/vit_jax; Hay code Ä‘Æ°á»£c viáº¿t trÃªn Pytorch vÃ  pretrained weights cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c port sang PT táº¡i Ä‘Ã¢y https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py; Code viáº¿t báº±ng TensorFlow táº¡i Ä‘Ã¢y https://github.com/emla2805/vision-trÃ normer.
LÆ°u Ã½: ViT cáº§n ráº¥t nhiá»u dá»¯ liá»‡u Ä‘á»ƒ train nÃªn áº£nh hÆ°á»Ÿng cá»§a Transfer Learning Ä‘áº¿n viá»‡c á»©ng dá»¥ng vÃ o dataset cá»§a cÃ¡c báº¡n lÃ  ráº¥t lá»›n. NÃªn mÃ¬nh khuyÃªn hÃ£y sá»­ dá»¥ng original source code vÃ¬ cÃ³ pretrained weights. Tuy nhiÃªn, nÃ³ Ä‘Æ°á»£c viáº¿t báº±ng JAX, 1 framework do Google phÃ¡t triá»ƒn nhÆ°ng chÆ°a phá»• biáº¿n láº¯m cÃ³ thá»ƒ gÃ¢y khÃ³ khÄƒn ban Ä‘áº§u. Code viáº¿t trÃªn TF tÃ¡c giáº£ chÆ°a convert weights nÃªn cÃ¡c báº¡n pháº£i tá»± lÃ m. Theo mÃ¬nh code cá»§a anh Wightman trÃªn PT ráº¥t sáº¡ch, anh áº¥y Ä‘Ã£ port weights sang PT vÃ  down-Scale tá»« ViT-Base xuá»‘ng ViT-Small vá»›i image size 224 sáº½ ráº¥t tiá»‡n Ä‘á»ƒ train vá»›i tÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿.","Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ chia sáº» bÃ i bÃ¡o Vision Transformer, giá» Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng trÃªn ArXiv https://arxiv.org/pdf/2010.11929.pdf. TÃ¡c giáº£ Ä‘Ã£ chia sáº» source code gá»‘c (viáº¿t báº±ng JAX) táº¡i Ä‘Ã¢y https://github.com/google-research/vision_transformer/tree/master/vit_jax; Hay code Ä‘Æ°á»£c viáº¿t trÃªn Pytorch vÃ  pretrained weights cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c port sang PT táº¡i Ä‘Ã¢y https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py; Code viáº¿t báº±ng TensorFlow táº¡i Ä‘Ã¢y https://github.com/emla2805/vision-trÃ normer. LÆ°u Ã½: ViT cáº§n ráº¥t nhiá»u dá»¯ liá»‡u Ä‘á»ƒ train nÃªn áº£nh hÆ°á»Ÿng cá»§a Transfer Learning Ä‘áº¿n viá»‡c á»©ng dá»¥ng vÃ o dataset cá»§a cÃ¡c báº¡n lÃ  ráº¥t lá»›n. NÃªn mÃ¬nh khuyÃªn hÃ£y sá»­ dá»¥ng original source code vÃ¬ cÃ³ pretrained weights. Tuy nhiÃªn, nÃ³ Ä‘Æ°á»£c viáº¿t báº±ng JAX, 1 framework do Google phÃ¡t triá»ƒn nhÆ°ng chÆ°a phá»• biáº¿n láº¯m cÃ³ thá»ƒ gÃ¢y khÃ³ khÄƒn ban Ä‘áº§u. Code viáº¿t trÃªn TF tÃ¡c giáº£ chÆ°a convert weights nÃªn cÃ¡c báº¡n pháº£i tá»± lÃ m. Theo mÃ¬nh code cá»§a anh Wightman trÃªn PT ráº¥t sáº¡ch, anh áº¥y Ä‘Ã£ port weights sang PT vÃ  down-Scale tá»« ViT-Base xuá»‘ng ViT-Small vá»›i image size 224 sáº½ ráº¥t tiá»‡n Ä‘á»ƒ train vá»›i tÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿.",,,,,
"#Share_AIData
AVA chia sáº» bá»™ dá»¯ liá»‡u áº£nh giÃºp cÃ¡c báº¡n thá»±c hÃ nh huáº¥n luyá»‡n mÃ´ hÃ¬nh AI.
Bá»™ dá»¯ liá»‡u gá»“m 2670 áº£nh lÃ  ba máº«u hÃ¬nh dáº¡ng thuá»‘c cÆ¡ báº£n thÆ°á»ng tháº¥y trÃªn thá»‹ trÆ°á»ng vá»›i hai lá»—i hay gáº·p trong quÃ¡ trÃ¬nh sáº£n xuáº¥t thuá»‘c lÃ  dÃ­nh táº¡p cháº¥t vÃ  ná»©t vá»¡.
Dá»±a vÃ o bá»™ dá»¯ liá»‡u cÃ¡c báº¡n cÃ³ thá»ƒ tiáº¿n hÃ nh thá»­ nghiá»‡m cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i, phÃ¡t hiá»‡n lá»—i trá»n bá» máº·t sáº£n pháº©m.
Chi tiáº¿t link download dá»¯ liá»‡u vÃ  má»™t sá»‘ káº¿t quáº£ AVA cháº¡y Ä‘Æ°á»£c má»i cÃ¡c báº¡n xem táº¡i: http://avatech.com.vn/kiem-tra-phat-hien-loi-san-pham/kiem-tra-chat-luong-vien-thuoc","AVA chia sáº» bá»™ dá»¯ liá»‡u áº£nh giÃºp cÃ¡c báº¡n thá»±c hÃ nh huáº¥n luyá»‡n mÃ´ hÃ¬nh AI. Bá»™ dá»¯ liá»‡u gá»“m 2670 áº£nh lÃ  ba máº«u hÃ¬nh dáº¡ng thuá»‘c cÆ¡ báº£n thÆ°á»ng tháº¥y trÃªn thá»‹ trÆ°á»ng vá»›i hai lá»—i hay gáº·p trong quÃ¡ trÃ¬nh sáº£n xuáº¥t thuá»‘c lÃ  dÃ­nh táº¡p cháº¥t vÃ  ná»©t vá»¡. Dá»±a vÃ o bá»™ dá»¯ liá»‡u cÃ¡c báº¡n cÃ³ thá»ƒ tiáº¿n hÃ nh thá»­ nghiá»‡m cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i, phÃ¡t hiá»‡n lá»—i trá»n bá» máº·t sáº£n pháº©m. Chi tiáº¿t link download dá»¯ liá»‡u vÃ  má»™t sá»‘ káº¿t quáº£ AVA cháº¡y Ä‘Æ°á»£c má»i cÃ¡c báº¡n xem táº¡i: http://avatech.com.vn/kiem-tra-phat-hien-loi-san-pham/kiem-tra-chat-luong-vien-thuoc",#Share_AIData,,,,
"Há»™i mÃ¬nh cÃ³ ai cÃ³ mÃ¡y tÃ­nh desktop cÃ³ cáº¥u hÃ¬nh i7, gpu gtx 970, ram 16 gb ko áº¡?
Cho mÃ¬nh mÆ°á»£n cháº¡y inference Ä‘á»ƒ so sÃ¡nh cho fair vá»›i bÃ i cá»§a ngÆ°á»i ta, (táº¡i mÃ¡y mÃ¬nh chÃªnh lá»‡ch hiá»‡u nÄƒng quÃ¡ so vá»›i cáº¥u hÃ¬nh nÃ y), hoáº·c cÃ³ suggest gÃ¬ Ä‘á»ƒ 1 mÃ¡y máº¡nh hÆ¡n cháº¡y yáº¿u hÆ¡n Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng ko áº¡?
Cáº£m Æ¡n má»i ngÆ°á»i.
(Thá»i gian mÆ°á»£n cháº¯c Ä‘á»™ 30 phÃºt lÃ  xong).","Há»™i mÃ¬nh cÃ³ ai cÃ³ mÃ¡y tÃ­nh desktop cÃ³ cáº¥u hÃ¬nh i7, gpu gtx 970, ram 16 gb ko áº¡? Cho mÃ¬nh mÆ°á»£n cháº¡y inference Ä‘á»ƒ so sÃ¡nh cho fair vá»›i bÃ i cá»§a ngÆ°á»i ta, (táº¡i mÃ¡y mÃ¬nh chÃªnh lá»‡ch hiá»‡u nÄƒng quÃ¡ so vá»›i cáº¥u hÃ¬nh nÃ y), hoáº·c cÃ³ suggest gÃ¬ Ä‘á»ƒ 1 mÃ¡y máº¡nh hÆ¡n cháº¡y yáº¿u hÆ¡n Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng ko áº¡? Cáº£m Æ¡n má»i ngÆ°á»i. (Thá»i gian mÆ°á»£n cháº¯c Ä‘á»™ 30 phÃºt lÃ  xong).",,,,,
"Hi mn, mÃ¬nh há»i Ã½ kiáº¿m mn vá»›i áº¡. Hiá»‡n táº¡i mÃ¬nh chÆ°a há» biáº¿t gÃ¬ vÃ  chÆ°a cÃ³ kiáº¿n thá»©c vá» Machine Learning, mÃ¬nh cÃ³ khoáº£ng 3 thÃ¡ng ráº£nh khÃ´ng vÆ°á»›ng báº­n cv Ä‘á»ƒ há»c. mÃ¬nh cÃ³ Ã½ Ä‘á»‹nh ra HCM Ä‘á»ƒ há»c 1 khÃ³a á»Ÿ 1 trung tÃ¢m nÃ o Ä‘Ã³ (hiá»‡n táº¡i mÃ¬nh tháº¥y cÃ³ fpt software) cho dá»… vÃ o hÆ¡n rá»“i má»›i tá»± mÃ². m.n cÃ³ khÃ³a há»c nÃ o á»Ÿ HCM tá»‘t khÃ´ng áº¡.","Hi mn, mÃ¬nh há»i Ã½ kiáº¿m mn vá»›i áº¡. Hiá»‡n táº¡i mÃ¬nh chÆ°a há» biáº¿t gÃ¬ vÃ  chÆ°a cÃ³ kiáº¿n thá»©c vá» Machine Learning, mÃ¬nh cÃ³ khoáº£ng 3 thÃ¡ng ráº£nh khÃ´ng vÆ°á»›ng báº­n cv Ä‘á»ƒ há»c. mÃ¬nh cÃ³ Ã½ Ä‘á»‹nh ra HCM Ä‘á»ƒ há»c 1 khÃ³a á»Ÿ 1 trung tÃ¢m nÃ o Ä‘Ã³ (hiá»‡n táº¡i mÃ¬nh tháº¥y cÃ³ fpt software) cho dá»… vÃ o hÆ¡n rá»“i má»›i tá»± mÃ². m.n cÃ³ khÃ³a há»c nÃ o á»Ÿ HCM tá»‘t khÃ´ng áº¡.",,,,,
"HÃ´m trÆ°á»›c cÃ³ báº¡n nÃ o há»i pháº§n xÃ³a phÃ´ng cho mobile apps.
ÄÃ¢y lÃ  bÃ i SOTA má»›i vá» pháº§n nÃ y : high res, high accuracy.
Chá»‰ lÃ  chÆ°a convert sang mobile.","HÃ´m trÆ°á»›c cÃ³ báº¡n nÃ o há»i pháº§n xÃ³a phÃ´ng cho mobile apps. ÄÃ¢y lÃ  bÃ i SOTA má»›i vá» pháº§n nÃ y : high res, high accuracy. Chá»‰ lÃ  chÆ°a convert sang mobile.",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang vÆ°á»›ng á»Ÿ Ä‘á» tÃ i huáº¥n luyá»‡n Ä‘á»ƒ nháº­n diá»‡n mÃ£ váº¡ch.
á» trong nhÃ³m cÃ³ ai Ä‘Ã£ tÃ¬m hiá»ƒu thÃ¬ cÃ³ thá»ƒ chá»‰ mÃ¬nh vá» máº£ng nÃ y Ä‘Æ°á»£c khÃ´ng? MÃ¬nh khÃ´ng chuyÃªn vá» máº£ng nÃ y.
Xin cáº£m Æ¡n má»i ngÆ°á»i!","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang vÆ°á»›ng á»Ÿ Ä‘á» tÃ i huáº¥n luyá»‡n Ä‘á»ƒ nháº­n diá»‡n mÃ£ váº¡ch. á» trong nhÃ³m cÃ³ ai Ä‘Ã£ tÃ¬m hiá»ƒu thÃ¬ cÃ³ thá»ƒ chá»‰ mÃ¬nh vá» máº£ng nÃ y Ä‘Æ°á»£c khÃ´ng? MÃ¬nh khÃ´ng chuyÃªn vá» máº£ng nÃ y. Xin cáº£m Æ¡n má»i ngÆ°á»i!",,,,,
"Camera sá»­ dá»¥ng AI Ä‘á»ƒ tá»± Ä‘á»™ng quay vÃ  focus vÃ o trÃ¡i bÃ³ng. Tuy nhiÃªn, trong pháº§n lá»›n thá»i gian cá»§a tráº­n Ä‘áº¥u, khÃ¡n giáº£ Ä‘Æ°á»£c chiÃªm ngÆ°á»¡ng nhá»¯ng bÆ°á»›c cháº¡y cá»§a trá»ng tÃ i biÃªn thay vÃ¬ trÃ¡i bÃ³ng, ... bá»Ÿi vÃ¬ Ã´ng cÃ³ 1 cÃ¡i Ä‘áº§u trá»c... 
Láº§n sau cÃ³ láº½ bÃ¡c nÃªn Ä‘á»™i mÅ© Ä‘á»ƒ AI trÃ¡nh nháº§m láº«n vá»›i trÃ¡i bÃ³ng. Má»™t vÃ­ dá»¥ vá» AI trong á»©ng dá»¥ng Ä‘á»i sá»‘ng..., vÃ  Ä‘iá»u gÃ¬ sáº½ xáº£y ra khi xe tá»± Ä‘á»™ng lÃ¡i cÅ©ng cÃ³ nhá»¯ng nháº§m láº«n tÆ°Æ¡ng tá»±?
#adversarial_attack","Camera sá»­ dá»¥ng AI Ä‘á»ƒ tá»± Ä‘á»™ng quay vÃ  focus vÃ o trÃ¡i bÃ³ng. Tuy nhiÃªn, trong pháº§n lá»›n thá»i gian cá»§a tráº­n Ä‘áº¥u, khÃ¡n giáº£ Ä‘Æ°á»£c chiÃªm ngÆ°á»¡ng nhá»¯ng bÆ°á»›c cháº¡y cá»§a trá»ng tÃ i biÃªn thay vÃ¬ trÃ¡i bÃ³ng, ... bá»Ÿi vÃ¬ Ã´ng cÃ³ 1 cÃ¡i Ä‘áº§u trá»c... Láº§n sau cÃ³ láº½ bÃ¡c nÃªn Ä‘á»™i mÅ© Ä‘á»ƒ AI trÃ¡nh nháº§m láº«n vá»›i trÃ¡i bÃ³ng. Má»™t vÃ­ dá»¥ vá» AI trong á»©ng dá»¥ng Ä‘á»i sá»‘ng..., vÃ  Ä‘iá»u gÃ¬ sáº½ xáº£y ra khi xe tá»± Ä‘á»™ng lÃ¡i cÅ©ng cÃ³ nhá»¯ng nháº§m láº«n tÆ°Æ¡ng tá»±?",#adversarial_attack,,,,
"Hi má»i ngÆ°á»i,
Chuyá»‡n lÃ  em cÃ³ train 1 custom model vá»›i google automl vision. Giá» em muá»‘n xem architecture cá»§a model Ä‘Ã³ vá»›i file model.json vÃ  weights.bin thÃ¬ cÃ³ cÃ¡ch nÃ o khÃ´ng áº¡ ?","Hi má»i ngÆ°á»i, Chuyá»‡n lÃ  em cÃ³ train 1 custom model vá»›i google automl vision. Giá» em muá»‘n xem architecture cá»§a model Ä‘Ã³ vá»›i file model.json vÃ  weights.bin thÃ¬ cÃ³ cÃ¡ch nÃ o khÃ´ng áº¡ ?",,,,,
"[MÃŒ AI #4] - THá»¬ Láº¬P TRÃŒNH XE OTO Tá»° LÃI
Link bÃ i viáº¿t: http://miai.vn/2019/08/19/computer-vision-thu-lap-trinh-xe-o-to-dua-tu-lai/
ChÃ o tuáº§n má»›i cáº£ nhÃ , chÃºng ta láº¡i cÃ¹ng Äƒn mÃ¬ cÃ¹ng MÃ¬ AI â€“ há»c AI theo cÃ¡ch mÃ¬ Äƒn liá»n. MÃ¬nh sáº½ cá»‘ gáº¯ng Ä‘Æ¡n giáº£n hÃ³a cÃ¡c khÃ¡i niá»‡m phá»©c táº¡p, Ä‘á»ƒ lÃ m sao cÃ¡c báº¡n dá»… tiáº¿p cáº­n vÃ  lÃ m AI má»™t cÃ¡ch MÃ¬ Äƒn liá»n. ÄÃ­ch Ä‘áº¿n cuá»‘i cÃ¹ng lÃ  Ai cÅ©ng lÃ m Ä‘Æ°á»£c AI ğŸ˜€
Okie, háº³n cÃ¡c báº¡n Ä‘Ã£ nghe Ä‘áº¿n nhiá»u dá»± Ã¡n xe tá»± lÃ¡i cá»§a Google Ä‘Ãºng khÃ´ng? Xe sáº½ tá»± hÃ nh vÃ  Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn hoÃ n toÃ n báº±ng mÃ¡y tÃ­nh trÃªn xe, khÃ´ng cáº§n con ngÆ°á»i can thiá»‡p. HÃ´m nay chÃºng ta sáº½ cÃ¹ng nhau lÃ m má»™t model xe tá»± lÃ¡i Ä‘Æ¡n giáº£n Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c nguyÃªn lÃ½, cÃ¡ch lÃ m xe tá»± lÃ¡i nhÃ©.","[MÃŒ AI - THá»¬ Láº¬P TRÃŒNH XE OTO Tá»° LÃI Link bÃ i viáº¿t: http://miai.vn/2019/08/19/computer-vision-thu-lap-trinh-xe-o-to-dua-tu-lai/ ChÃ o tuáº§n má»›i cáº£ nhÃ , chÃºng ta láº¡i cÃ¹ng Äƒn mÃ¬ cÃ¹ng MÃ¬ AI â€“ há»c AI theo cÃ¡ch mÃ¬ Äƒn liá»n. MÃ¬nh sáº½ cá»‘ gáº¯ng Ä‘Æ¡n giáº£n hÃ³a cÃ¡c khÃ¡i niá»‡m phá»©c táº¡p, Ä‘á»ƒ lÃ m sao cÃ¡c báº¡n dá»… tiáº¿p cáº­n vÃ  lÃ m AI má»™t cÃ¡ch MÃ¬ Äƒn liá»n. ÄÃ­ch Ä‘áº¿n cuá»‘i cÃ¹ng lÃ  Ai cÅ©ng lÃ m Ä‘Æ°á»£c AI Okie, háº³n cÃ¡c báº¡n Ä‘Ã£ nghe Ä‘áº¿n nhiá»u dá»± Ã¡n xe tá»± lÃ¡i cá»§a Google Ä‘Ãºng khÃ´ng? Xe sáº½ tá»± hÃ nh vÃ  Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn hoÃ n toÃ n báº±ng mÃ¡y tÃ­nh trÃªn xe, khÃ´ng cáº§n con ngÆ°á»i can thiá»‡p. HÃ´m nay chÃºng ta sáº½ cÃ¹ng nhau lÃ m má»™t model xe tá»± lÃ¡i Ä‘Æ¡n giáº£n Ä‘á»ƒ hiá»ƒu Ä‘Æ°á»£c nguyÃªn lÃ½, cÃ¡ch lÃ m xe tá»± lÃ¡i nhÃ©.",#4],,,,
"ChÃ o má»i ngÆ°á»i.
MÃ¬nh Ä‘ang viáº¿t chÆ°Æ¡ng trÃ¬nh training model trÃªn nhiá»u gpus, hiá»‡n táº¡i lÃ  2 gpu, mÃ¬nh dÃ¹ng tf.distribute.MirroredStrategy(tensorflow 2.x). MÃ¬nh cháº¡y source tutorial cá»§a tensorflow , nhÆ°ng mÃ  training trÃªn 2gpu láº¡i khÃ´ng nhanh hÆ¡n 1gpu, tháº­m chÃ­ trÃªn 1gpu láº¡i nhanh hÆ¡n 1 chÃºt, mÃ¬nh Ä‘Ã£ tÃ¬m nguyÃªn nhÃ¢n trÃªn google nhÆ°ng mÃ  váº«n chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c. Ai Ä‘Ã£ tá»«ng lÃ m rá»“i cÃ³ thá»ƒ giÃºp mÃ¬nh vá»›i Ä‘Æ°á»£c khÃ´ng áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i","ChÃ o má»i ngÆ°á»i. MÃ¬nh Ä‘ang viáº¿t chÆ°Æ¡ng trÃ¬nh training model trÃªn nhiá»u gpus, hiá»‡n táº¡i lÃ  2 gpu, mÃ¬nh dÃ¹ng tf.distribute.MirroredStrategy(tensorflow 2.x). MÃ¬nh cháº¡y source tutorial cá»§a tensorflow , nhÆ°ng mÃ  training trÃªn 2gpu láº¡i khÃ´ng nhanh hÆ¡n 1gpu, tháº­m chÃ­ trÃªn 1gpu láº¡i nhanh hÆ¡n 1 chÃºt, mÃ¬nh Ä‘Ã£ tÃ¬m nguyÃªn nhÃ¢n trÃªn google nhÆ°ng mÃ  váº«n chÆ°a giáº£i quyáº¿t Ä‘Æ°á»£c. Ai Ä‘Ã£ tá»«ng lÃ m rá»“i cÃ³ thá»ƒ giÃºp mÃ¬nh vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. Cáº£m Æ¡n má»i ngÆ°á»i",,,,,
"URL2Video, má»™t nghiÃªn cá»©u má»›i cá»§a Google, cho phÃ©p tá»± Ä‘á»™ng táº¡o má»™t video ngáº¯n tá»« trang web.","URL2Video, má»™t nghiÃªn cá»©u má»›i cá»§a Google, cho phÃ©p tá»± Ä‘á»™ng táº¡o má»™t video ngáº¯n tá»« trang web.",,,,,
"Xin chÃ o Anh/Chá»‹,
Em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n tÃ¬m quÃ£ng Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t trÃªn map.
Anh/Chá»‹ gá»£i Ã½ giÃºp e má»™t sá»‘ cÃ¡ch xá»­ lÃ½ báº±ng ML.
Data em Ä‘ang cÃ³ tá»« Google API
+ Start point (lat/long)
+ End point (lat/long)
+ Distance Google API
+ Labled by bikers.
Káº¿t quáº£ mong muá»‘n:
+ Optimize láº¡i quÃ£ng Ä‘Æ°á»ng Ä‘Ã£ Ä‘i báº±ng 1 lá»‹ch trÃ¬nh má»›i ngáº¯n hÆ¡n mÃ  k bá»‹ vi pháº¡m luáº­t giao thÃ´ng (Ä‘i vÃ o Ä‘Æ°á»ng cáº¥m, Ä‘Æ°á»ng ngÆ°á»£c chiá»u)
+ Khi input 1 Start/End Point má»›i, ML sáº½ output lá»‹ch trÃ¬nh tá»‘t nháº¥t lÃ  data point mÃ  bikers cáº§n Ä‘i qua vÃ  distance cá»§a trip Ä‘Ã³.
Em xin cáº£m Æ¡n.","Xin chÃ o Anh/Chá»‹, Em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n tÃ¬m quÃ£ng Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t trÃªn map. Anh/Chá»‹ gá»£i Ã½ giÃºp e má»™t sá»‘ cÃ¡ch xá»­ lÃ½ báº±ng ML. Data em Ä‘ang cÃ³ tá»« Google API + Start point (lat/long) + End point (lat/long) + Distance Google API + Labled by bikers. Káº¿t quáº£ mong muá»‘n: + Optimize láº¡i quÃ£ng Ä‘Æ°á»ng Ä‘Ã£ Ä‘i báº±ng 1 lá»‹ch trÃ¬nh má»›i ngáº¯n hÆ¡n mÃ  k bá»‹ vi pháº¡m luáº­t giao thÃ´ng (Ä‘i vÃ o Ä‘Æ°á»ng cáº¥m, Ä‘Æ°á»ng ngÆ°á»£c chiá»u) + Khi input 1 Start/End Point má»›i, ML sáº½ output lá»‹ch trÃ¬nh tá»‘t nháº¥t lÃ  data point mÃ  bikers cáº§n Ä‘i qua vÃ  distance cá»§a trip Ä‘Ã³. Em xin cáº£m Æ¡n.",,,,,
"ChÃ o mn, em Ä‘ang Ä‘á»c vá» face_recognition vÃ  cÃ³ Ä‘á»c Ä‘áº¿n facenet, vÃ  Ä‘á»c vá» pre trained cá»§a nÃ³ nhÆ°ng em Ä‘ang khÃ´ng hiá»ƒu lÃ  nÃ³ trainning kiá»ƒu gÃ¬ áº¡, Ä‘áº§u vÃ o lÃ  áº£nh; Ä‘áº§u ra chá»‰ lÃ  1 vector 128D, váº­y label lÃ  gÃ¬, vÃ  nÃ³ tá»‘i Æ°u cÃ¡i máº¡ng facenet nÃ y nhÆ° nÃ o áº¡. Em chÆ°a nÃ³i Ä‘áº¿n pháº§n classify áº¡, á»Ÿ Ä‘Ã¢y em má»›i Ä‘ang tháº¯c máº¯c vá» cÃ¡i facenet Ä‘á»ƒ extracting áº£nh máº·t ngÆ°á»i thÃ nh vector 128D áº¡. Em cáº£m Æ¡n áº¡!","ChÃ o mn, em Ä‘ang Ä‘á»c vá» face_recognition vÃ  cÃ³ Ä‘á»c Ä‘áº¿n facenet, vÃ  Ä‘á»c vá» pre trained cá»§a nÃ³ nhÆ°ng em Ä‘ang khÃ´ng hiá»ƒu lÃ  nÃ³ trainning kiá»ƒu gÃ¬ áº¡, Ä‘áº§u vÃ o lÃ  áº£nh; Ä‘áº§u ra chá»‰ lÃ  1 vector 128D, váº­y label lÃ  gÃ¬, vÃ  nÃ³ tá»‘i Æ°u cÃ¡i máº¡ng facenet nÃ y nhÆ° nÃ o áº¡. Em chÆ°a nÃ³i Ä‘áº¿n pháº§n classify áº¡, á»Ÿ Ä‘Ã¢y em má»›i Ä‘ang tháº¯c máº¯c vá» cÃ¡i facenet Ä‘á»ƒ extracting áº£nh máº·t ngÆ°á»i thÃ nh vector 128D áº¡. Em cáº£m Æ¡n áº¡!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ 1 project cáº§n build tool Ä‘á»ƒ detect cÃ¡c triá»‡u chá»©ng vá» da máº·t khi upload hÃ¬nh lÃªn API.
MÃ¬nh tÃ¬m tháº¥y tÃ i liá»‡u vá» 1 team Ä‘Ã£ lÃ m pháº§n nÃ y ráº¥t á»•n. Má»i ngÆ°á»i xem qua, ai lÃ m Ä‘Æ°á»£c thÃ¬ PM mÃ¬nh nhÃ©.","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ 1 project cáº§n build tool Ä‘á»ƒ detect cÃ¡c triá»‡u chá»©ng vá» da máº·t khi upload hÃ¬nh lÃªn API. MÃ¬nh tÃ¬m tháº¥y tÃ i liá»‡u vá» 1 team Ä‘Ã£ lÃ m pháº§n nÃ y ráº¥t á»•n. Má»i ngÆ°á»i xem qua, ai lÃ m Ä‘Æ°á»£c thÃ¬ PM mÃ¬nh nhÃ©.",,,,,
"Hi má»i ngÆ°á»i,
MÃ¬nh Ä‘á»‹nh build má»™t pc Ä‘á»ƒ nghiÃªn cá»©u Deep learning theo hÆ°á»›ng dá»± bÃ¡o time series, thá»‰nh thoáº£ng cÃ³ cháº¡m vÃ o computer vision nhÆ°ng k pháº£i lÃ  hÆ°á»›ng nghiÃªn cá»©u chÃ­nh. Vá»›i chi phÃ­ táº§m 30tr, mÃ¬nh cÃ³ tham kháº£o Ä‘Æ°á»£c má»™t cáº¥u hÃ¬nh nhÆ° bÃªn dÆ°á»›i. Nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp cáº¥u hÃ¬nh nhÆ° váº­y cÃ³ á»•n khÃ´ng, cÃ³ cáº§n thay Ä‘á»•i gÃ¬ khÃ´ng?
Cáº£m Æ¡n má»i ngÆ°á»i.","Hi má»i ngÆ°á»i, MÃ¬nh Ä‘á»‹nh build má»™t pc Ä‘á»ƒ nghiÃªn cá»©u Deep learning theo hÆ°á»›ng dá»± bÃ¡o time series, thá»‰nh thoáº£ng cÃ³ cháº¡m vÃ o computer vision nhÆ°ng k pháº£i lÃ  hÆ°á»›ng nghiÃªn cá»©u chÃ­nh. Vá»›i chi phÃ­ táº§m 30tr, mÃ¬nh cÃ³ tham kháº£o Ä‘Æ°á»£c má»™t cáº¥u hÃ¬nh nhÆ° bÃªn dÆ°á»›i. Nhá» má»i ngÆ°á»i tÆ° váº¥n giÃºp cáº¥u hÃ¬nh nhÆ° váº­y cÃ³ á»•n khÃ´ng, cÃ³ cáº§n thay Ä‘á»•i gÃ¬ khÃ´ng? Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Xin chÃ o má»i ngÆ°á»i, em lÃ  dev mobile. Hiá»‡n em Ä‘ang lÃ m tÃ­nh nÄƒng virtual background trÃªn video call. HÆ°á»›ng Ä‘i cá»¥ thá»ƒ cá»§a em lÃ  láº¥y tá»«ng frame , thá»±c hiá»‡n detect (Image segmentation) vÃ  biáº¿t Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a pixel (CÃ³ pháº£i ngÆ°á»i hay 1 Ä‘á»‘i tÆ°á»£ng nÃ o khÃ¡c khÃ´ng) vÃ  thay tháº¿ tá»«ng pixel KHÃ”NG PHáº¢I NGÆ¯á»œI thÃ nh pixel cá»§a background (Ã½ em lÃ  chÃ©p tá»«ng pixel).
Em Ä‘ang sá»­ dung Tensorflow (https://www.tensorflow.org/lite/models/segmentation/overview) Ä‘á»ƒ Ä‘á»c model deeplabv3, káº¿t há»£p vá»›i opencv Ä‘á»ƒ xá»­ lÃ½ hÃ¬nh áº£nh
CÃ¢u há»i cá»§a em lÃ : CÃ³ model nÃ o khÃ¡c sá»­ lÃ½ Image segmentation nhan hÆ¡n khÃ´ng áº¡. BÃ¡c nÃ o tá»«ng cÃ³ kinh nghiá»‡m giáº£i quyáº¿t váº¥n Ä‘á» káº¿t há»£p vá»›i mobile kiá»ƒu nÃ y thÃ¬ cho em xin vÃ i lá»i khuyÃªn vá»›i áº¡
Mong má»i ngÆ°á»i giÃºp em áº¡. ÄÃ£ gáº§n 2 thÃ¡ng em váº­t lá»™n vá»›i cÃ¡i nÃ y vÃ  báº¯t Ä‘áº§u bÃ­ Ã½ tÆ°á»Ÿng vÃ  khÃ´ng biáº¿t lÃ m gÃ¬ Ä‘á»ƒ tá»‘i Æ°u. Láº§n Ä‘áº§u tiÃªn tiáº¿p xÃºc vá»›i ML nÃªn kiáº¿n thá»©c cá»§a em vÃ´ cÃ¹ng nÃ´ng cáº¡n vÃ  lung tung, mong Ä‘Æ°á»£c má»i ngÆ°á»i khai sÃ¡ng","Xin chÃ o má»i ngÆ°á»i, em lÃ  dev mobile. Hiá»‡n em Ä‘ang lÃ m tÃ­nh nÄƒng virtual background trÃªn video call. HÆ°á»›ng Ä‘i cá»¥ thá»ƒ cá»§a em lÃ  láº¥y tá»«ng frame , thá»±c hiá»‡n detect (Image segmentation) vÃ  biáº¿t Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a pixel (CÃ³ pháº£i ngÆ°á»i hay 1 Ä‘á»‘i tÆ°á»£ng nÃ o khÃ¡c khÃ´ng) vÃ  thay tháº¿ tá»«ng pixel KHÃ”NG PHáº¢I NGÆ¯á»œI thÃ nh pixel cá»§a background (Ã½ em lÃ  chÃ©p tá»«ng pixel). Em Ä‘ang sá»­ dung Tensorflow (https://www.tensorflow.org/lite/models/segmentation/overview) Ä‘á»ƒ Ä‘á»c model deeplabv3, káº¿t há»£p vá»›i opencv Ä‘á»ƒ xá»­ lÃ½ hÃ¬nh áº£nh CÃ¢u há»i cá»§a em lÃ : CÃ³ model nÃ o khÃ¡c sá»­ lÃ½ Image segmentation nhan hÆ¡n khÃ´ng áº¡. BÃ¡c nÃ o tá»«ng cÃ³ kinh nghiá»‡m giáº£i quyáº¿t váº¥n Ä‘á» káº¿t há»£p vá»›i mobile kiá»ƒu nÃ y thÃ¬ cho em xin vÃ i lá»i khuyÃªn vá»›i áº¡ Mong má»i ngÆ°á»i giÃºp em áº¡. ÄÃ£ gáº§n 2 thÃ¡ng em váº­t lá»™n vá»›i cÃ¡i nÃ y vÃ  báº¯t Ä‘áº§u bÃ­ Ã½ tÆ°á»Ÿng vÃ  khÃ´ng biáº¿t lÃ m gÃ¬ Ä‘á»ƒ tá»‘i Æ°u. Láº§n Ä‘áº§u tiÃªn tiáº¿p xÃºc vá»›i ML nÃªn kiáº¿n thá»©c cá»§a em vÃ´ cÃ¹ng nÃ´ng cáº¡n vÃ  lung tung, mong Ä‘Æ°á»£c má»i ngÆ°á»i khai sÃ¡ng",,,,,
,nan,,,,,
"[thiáº¿t bá»‹] [camera]
ChÃ o má»i ngÆ°á»i hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á» tÃ i cÃ³ pháº§n liÃªn quan Ä‘áº¿n nháº­n diá»‡n biá»ƒn sá»‘ xe.
Em dÃ¹ng yolov4 Ä‘á»ƒ detect license plate sau Ä‘Ã³ dÃ¹ng tesseract Ä‘á»ƒ chiáº¿t tá»±, káº¿t quáº£ khÃ´ng chÃ­nh xÃ¡c láº¯m nÃªn em train CNN Ä‘á»ƒ enhance tuy nhiÃªn cÅ©ng ko cáº£i thiá»‡n Ä‘Æ°á»£c nhiá»u.
Khi log file binary ra thÃ¬ má»›i biáº¿t áº£nh quÃ¡ má» Ä‘á»ƒ nháº­n dáº¡ng. VÃ¬ tháº¿ cho em há»i cÃ³ camera nÃ o trÃªn thá»‹ trÆ°á»ng Ä‘á»§ tá»‘t Ä‘á»ƒ láº¥y biá»ƒn sá»‘ tá»« cao vÃ  má»©c giÃ¡ phÃ¹ há»£p cho sinh viÃªn khÃ´ng áº¡ (tá»¥i em mua 2 cÃ¡i, má»—i cÃ¡i táº§m 6-700k Ä‘á»• láº¡i).
Hiá»‡n táº¡i em dÃ¹ng 2 camera IP Ezviz áº¡, thÃ­ch há»£p cho nháº­n diá»‡n gáº§n, hÃ ng má»›i.
https://tiki.vn/camera-ip-wifi-ezviz-c6n-1080p-hang-chinh-hang-p41319582.html
BÃ¡c nÃ o cÃ³ con camera phÃ¹ há»£p vá»›i Ä‘á»“ Ã¡n thÃ¬ tá»¥i em cÃ³ thá»ƒ mua láº¡i hoáº·c trade áº¡, em á»Ÿ TP HCM.
Hoáº·c cÃ³ cÃ¡ch nÃ o improve accuracy thÃ¬ cÅ©ng mong sá»± tÆ° váº¥n áº¡, em cáº£m Æ¡n ráº¥t nhiá»u vÃ¬ giÃºp Ä‘á»¡.","[thiáº¿t bá»‹] [camera] ChÃ o má»i ngÆ°á»i hiá»‡n táº¡i em Ä‘ang lÃ m Ä‘á» tÃ i cÃ³ pháº§n liÃªn quan Ä‘áº¿n nháº­n diá»‡n biá»ƒn sá»‘ xe. Em dÃ¹ng yolov4 Ä‘á»ƒ detect license plate sau Ä‘Ã³ dÃ¹ng tesseract Ä‘á»ƒ chiáº¿t tá»±, káº¿t quáº£ khÃ´ng chÃ­nh xÃ¡c láº¯m nÃªn em train CNN Ä‘á»ƒ enhance tuy nhiÃªn cÅ©ng ko cáº£i thiá»‡n Ä‘Æ°á»£c nhiá»u. Khi log file binary ra thÃ¬ má»›i biáº¿t áº£nh quÃ¡ má» Ä‘á»ƒ nháº­n dáº¡ng. VÃ¬ tháº¿ cho em há»i cÃ³ camera nÃ o trÃªn thá»‹ trÆ°á»ng Ä‘á»§ tá»‘t Ä‘á»ƒ láº¥y biá»ƒn sá»‘ tá»« cao vÃ  má»©c giÃ¡ phÃ¹ há»£p cho sinh viÃªn khÃ´ng áº¡ (tá»¥i em mua 2 cÃ¡i, má»—i cÃ¡i táº§m 6-700k Ä‘á»• láº¡i). Hiá»‡n táº¡i em dÃ¹ng 2 camera IP Ezviz áº¡, thÃ­ch há»£p cho nháº­n diá»‡n gáº§n, hÃ ng má»›i. https://tiki.vn/camera-ip-wifi-ezviz-c6n-1080p-hang-chinh-hang-p41319582.html BÃ¡c nÃ o cÃ³ con camera phÃ¹ há»£p vá»›i Ä‘á»“ Ã¡n thÃ¬ tá»¥i em cÃ³ thá»ƒ mua láº¡i hoáº·c trade áº¡, em á»Ÿ TP HCM. Hoáº·c cÃ³ cÃ¡ch nÃ o improve accuracy thÃ¬ cÅ©ng mong sá»± tÆ° váº¥n áº¡, em cáº£m Æ¡n ráº¥t nhiá»u vÃ¬ giÃºp Ä‘á»¡.",,,,,
"KÃ­nh chÃ o cÃ¡c member, cÃ¡c báº¡n má»›i há»c thÃ¬ hay lÃ m bÃ i táº­p trÃªn PC hoáº·c Colab nÃªn khi train hay bá»‹ trÃ n bá»™ nhá»› khi load nhiá»u dá»¯ liá»‡u (Ä‘áº·c biá»‡t lÃ  cÃ¡c bÃ i CNN, dá»¯ liá»‡u áº£nh). Em xin máº¡nh dáº¡n chia sáº» bÃ i viáº¿t vá» xá»­ lÃ½ váº¥n Ä‘á» nÃ y mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c ah. Cáº£m Æ¡n vÃ  mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c member, cÃ¡c báº¡n má»›i há»c thÃ¬ hay lÃ m bÃ i táº­p trÃªn PC hoáº·c Colab nÃªn khi train hay bá»‹ trÃ n bá»™ nhá»› khi load nhiá»u dá»¯ liá»‡u (Ä‘áº·c biá»‡t lÃ  cÃ¡c bÃ i CNN, dá»¯ liá»‡u áº£nh). Em xin máº¡nh dáº¡n chia sáº» bÃ i viáº¿t vá» xá»­ lÃ½ váº¥n Ä‘á» nÃ y mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n newbie má»›i há»c ah. Cáº£m Æ¡n vÃ  mong ad duyá»‡t bÃ i!",,,,,
"KÃ­nh chÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ lÃ m má»™t game nhá» dÃ¹ng OpenCV vÃ  Dlib nÃªn chia sáº» cÃ¹ng cÃ¡c báº¡n newbie má»›i há»c. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n ká»¹ nÄƒng code tá»« Ä‘áº§u má»™t bÃ i toÃ¡n ah.
Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c báº¡n, mÃ¬nh cÃ³ lÃ m má»™t game nhá» dÃ¹ng OpenCV vÃ  Dlib nÃªn chia sáº» cÃ¹ng cÃ¡c báº¡n newbie má»›i há»c. Mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n ká»¹ nÄƒng code tá»« Ä‘áº§u má»™t bÃ i toÃ¡n ah. Mong ad duyá»‡t bÃ i!",,,,,
"Em chaof má»i ngÆ°á»i, hiá»‡n em Ä‘ang cÃ³ lÃ m 1 project nhá» vá» 1 cÃ¡i mÃ¡y cá»© cÃ³ rÃ¡c trong phÃ²ng lÃ  sáº½ tá»± cháº¡y Ä‘áº¿n quÃ©t Ä‘i.
Váº¥n Ä‘á» cá»§a em hiá»‡n táº¡i: Em sáº½ cho ""rÃ¡c"" lÃ  nhá»¯ng thá»© Ä‘áº¡i loáº¡i nhÆ° máº©u giáº¥y vá»¥n, vá» chai nhá»±a.
Váº­y cÃ³ cÃ¡ch nÃ o xá»­ lÃ½ Ä‘Æ°á»£c nhanh(nhÆ° opencv) viá»‡c nÃ y khÃ´ng má»i ngÆ°á»i nhá»‰?
Cáº£m Æ¡n má»i ngÆ°á»i áº¡!","Em chaof má»i ngÆ°á»i, hiá»‡n em Ä‘ang cÃ³ lÃ m 1 project nhá» vá» 1 cÃ¡i mÃ¡y cá»© cÃ³ rÃ¡c trong phÃ²ng lÃ  sáº½ tá»± cháº¡y Ä‘áº¿n quÃ©t Ä‘i. Váº¥n Ä‘á» cá»§a em hiá»‡n táº¡i: Em sáº½ cho ""rÃ¡c"" lÃ  nhá»¯ng thá»© Ä‘áº¡i loáº¡i nhÆ° máº©u giáº¥y vá»¥n, vá» chai nhá»±a. Váº­y cÃ³ cÃ¡ch nÃ o xá»­ lÃ½ Ä‘Æ°á»£c nhanh(nhÆ° opencv) viá»‡c nÃ y khÃ´ng má»i ngÆ°á»i nhá»‰? Cáº£m Æ¡n má»i ngÆ°á»i áº¡!",,,,,
"ChÃ o cÃ¡c a/c,
Em Ä‘ang lÃ m bÃ i toÃ¡n vá» Classification, model e trained dá»±a trÃªn táº­p data TÃ¡o (3 bá»‡nh, 1 khoáº»), vÃ  em dÃ¹ng model nÃ y Ä‘á»ƒ cháº¡y trÃªn táº­p data BÆ°á»Ÿi (tÆ°Æ¡ng tá»± nhÆ° TÃ¡o cÅ©ng 3 bá»‡nh, 1 khoáº»). LÃ­ do em lÃ m tháº¿ nÃ y lÃ  vÃ¬ em khÃ´ng cÃ³ bá»™ data thu tháº­p thá»±c táº¿, nÃªn em muá»‘n dÃ¹ng model cháº¡y trÃªn 1 táº­p khÃ¡c cÃ³ Ä‘áº·c tÃ­nh tÆ°Æ¡ng tá»±, rá»“i sau Ä‘Ã³ e sáº½ cáº£i thiá»‡n model báº±ng cÃ¡ch tÃ¡c Ä‘á»™ng sÃ¢u hÆ¡n vÃ o kiáº¿n trÃºc cá»§a model nhÆ° Ä‘iá»u chÃ¬nh cÃ¡c thÃ´ng sá»‘: Hyperparameter, Regularization vÃ  Optimation... A/c nÃ o Ä‘Ã£ tá»«ng lÃ m qua bÃ i toÃ¡n tÆ°Æ¡ng tá»± cÃ³ thá»ƒ cho em vÃ i gá»£i Ã½, hoáº·c suggest cho e vÃ i bÃ i paper Ä‘c ko áº¡, em cÃ¡m Æ¡n mn.","ChÃ o cÃ¡c a/c, Em Ä‘ang lÃ m bÃ i toÃ¡n vá» Classification, model e trained dá»±a trÃªn táº­p data TÃ¡o (3 bá»‡nh, 1 khoáº»), vÃ  em dÃ¹ng model nÃ y Ä‘á»ƒ cháº¡y trÃªn táº­p data BÆ°á»Ÿi (tÆ°Æ¡ng tá»± nhÆ° TÃ¡o cÅ©ng 3 bá»‡nh, 1 khoáº»). LÃ­ do em lÃ m tháº¿ nÃ y lÃ  vÃ¬ em khÃ´ng cÃ³ bá»™ data thu tháº­p thá»±c táº¿, nÃªn em muá»‘n dÃ¹ng model cháº¡y trÃªn 1 táº­p khÃ¡c cÃ³ Ä‘áº·c tÃ­nh tÆ°Æ¡ng tá»±, rá»“i sau Ä‘Ã³ e sáº½ cáº£i thiá»‡n model báº±ng cÃ¡ch tÃ¡c Ä‘á»™ng sÃ¢u hÆ¡n vÃ o kiáº¿n trÃºc cá»§a model nhÆ° Ä‘iá»u chÃ¬nh cÃ¡c thÃ´ng sá»‘: Hyperparameter, Regularization vÃ  Optimation... A/c nÃ o Ä‘Ã£ tá»«ng lÃ m qua bÃ i toÃ¡n tÆ°Æ¡ng tá»± cÃ³ thá»ƒ cho em vÃ i gá»£i Ã½, hoáº·c suggest cho e vÃ i bÃ i paper Ä‘c ko áº¡, em cÃ¡m Æ¡n mn.",,,,,
"CÃ¡c bÃ¡c bÃªn ML cho em há»i xÃ­u lÃ , em xÃ¢y dá»±ng model ML cá»§a em rá»“i, vÃ  nháº­n tháº¥y ma tráº­n W vÃ  b nÃ³ cÃ³ nhiá»u sá»‘ 0 quÃ¡, nÃªn Ä‘ang muá»‘n tÃ¬m cÃ¡ch xÃ³a nÃ³ Ä‘i, thay Ä‘á»•i kÃ­ch thÆ°á»›c cá»§a W vÃ  b, Ä‘á»ƒ giáº£m thá»i gian tÃ­nh toÃ¡n cho model. KhÃ´ng biáº¿t cÃ³ phÆ°Æ¡ng phÃ¡p hay package nÃ o cÃ³ thá»ƒ giÃºp lÃ m chuyá»‡n nÃ y tá»‘t khÃ´ng? CÃ¡m Æ¡n cÃ¡c bÃ¡c.","CÃ¡c bÃ¡c bÃªn ML cho em há»i xÃ­u lÃ , em xÃ¢y dá»±ng model ML cá»§a em rá»“i, vÃ  nháº­n tháº¥y ma tráº­n W vÃ  b nÃ³ cÃ³ nhiá»u sá»‘ 0 quÃ¡, nÃªn Ä‘ang muá»‘n tÃ¬m cÃ¡ch xÃ³a nÃ³ Ä‘i, thay Ä‘á»•i kÃ­ch thÆ°á»›c cá»§a W vÃ  b, Ä‘á»ƒ giáº£m thá»i gian tÃ­nh toÃ¡n cho model. KhÃ´ng biáº¿t cÃ³ phÆ°Æ¡ng phÃ¡p hay package nÃ o cÃ³ thá»ƒ giÃºp lÃ m chuyá»‡n nÃ y tá»‘t khÃ´ng? CÃ¡m Æ¡n cÃ¡c bÃ¡c.",,,,,
"https://youtu.be/uGrBHohIgQY
co ban nao muon thu suc voi cuoc thi google kickstart khong?",https://youtu.be/uGrBHohIgQY co ban nao muon thu suc voi cuoc thi google kickstart khong?,,,,,
"Em chÃ o má»i ngÆ°á»i, em cÃ³ lÃ m má»™t ios App dÃ¹ng deep learning Ä‘á»ƒ nháº­n diá»‡n báº¡ch cáº§u qua hÃ¬nh áº£nh cho Sanford hackathon. Hackathon nÃ y cÃ³ giáº£i cho project Ä‘Æ°á»£c nhiá»u vote nháº¥t nÃªn cáº£ nhÃ  cÃ³ thá»i gian thÃ¬ vote giÃ¹m em áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ xem vÃ  vote cho project cá»§a em á»Ÿ link dÆ°á»›i Ä‘Ã¢y:
Ps: Náº¿u post cá»§a em khÃ´ng phÃ¹ há»£p vá»›i quy Ä‘á»‹nh cá»§a group thÃ¬ xin admin xoÃ¡ bÃ i giÃ¹m em.","Em chÃ o má»i ngÆ°á»i, em cÃ³ lÃ m má»™t ios App dÃ¹ng deep learning Ä‘á»ƒ nháº­n diá»‡n báº¡ch cáº§u qua hÃ¬nh áº£nh cho Sanford hackathon. Hackathon nÃ y cÃ³ giáº£i cho project Ä‘Æ°á»£c nhiá»u vote nháº¥t nÃªn cáº£ nhÃ  cÃ³ thá»i gian thÃ¬ vote giÃ¹m em áº¡. Má»i ngÆ°á»i cÃ³ thá»ƒ xem vÃ  vote cho project cá»§a em á»Ÿ link dÆ°á»›i Ä‘Ã¢y: Ps: Náº¿u post cá»§a em khÃ´ng phÃ¹ há»£p vá»›i quy Ä‘á»‹nh cá»§a group thÃ¬ xin admin xoÃ¡ bÃ i giÃ¹m em.",,,,,
1 phÆ°Æ¡ng phÃ¡p cho cÃ¡c bÃ¡c Ä‘ang nghiÃªn cá»©u vá» unsupervised learnings,1 phÆ°Æ¡ng phÃ¡p cho cÃ¡c bÃ¡c Ä‘ang nghiÃªn cá»©u vá» unsupervised learnings,,,,,
"Em chÃ o cÃ¡c anh chá»‹, em cÃ³ má»™t váº¥n Ä‘á» khi sá»­ dá»¥ng yolov3 mong cÃ¡c anh chá»‹ giÃºp Ä‘á»¡.
Em Ä‘Ã£ dÃ¹ng Yolo v3 Ä‘á»ƒ training nháº­n dáº¡ng táº¿ bÃ o mÃ¡u, vÃ  thu Ä‘Æ°á»£c file weight á»Ÿ hÆ¡n 4000 vÃ²ng. Data cá»§a em gá»“m cÃ³ 400 áº£nh vá»›i kÃ­ch thÆ°á»›c 640x480 vÃ  330 áº£nh cÃ³ kÃ­ch thÆ°á»›c 1392x1038 vá»›i mÃ u sáº¯c táº¿ bÃ o cÃ³ nhiá»u khÃ¡c biá»‡t do em thu tháº­p tá»« nhiá»u nguá»“n.
Tuy nhiÃªn khi em test thÃ¬ yolov3 chá»‰ nháº­n diá»‡n Ä‘Æ°á»£c cÃ¡c áº£nh gá»‘c cÃ³ kÃ­ch thÆ°á»›c 640x480, cÃ²n cÃ¡c áº£nh khÃ¡c khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c. Em cÅ©ng Ä‘Ã£ thá»­ crop áº£nh 1392x1038 vá» kÃ­ch thÆ°á»›c 640x480 cÅ©ng khÃ´ng thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c . Váº­y mong cÃ¡c anh cÃ³ cÃ¡ch nÃ o giÃºp em Ä‘á»ƒ em cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c áº£nh hoáº·c hÆ°á»›ng dáº«n em lÃ m cÃ¡ch nÃ o Ä‘á»ƒ phÃ¡t hiá»‡n ra váº¥n Ä‘á». Em cáº£m Æ¡n nhiá»u!
Trong Ä‘oáº¡n code: blob = cv2.dnn.blobFromImage(img, 0.00392, (896, 896), (0, 0, 0), em Ä‘á»ƒ kÃ­ch thÆ°á»›c 896 thÃ¬ nháº­n diá»‡n Ä‘Æ°á»£c áº£nh cÃ³ kÃ­ch thÆ°á»›c 640x480, CÃ²n náº¿u em Ä‘á»ƒ (416x416) thÃ¬ áº£nh cÃ³ kÃ­ch thÆ°á»›c 640x480 cÅ©ng khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c.","Em chÃ o cÃ¡c anh chá»‹, em cÃ³ má»™t váº¥n Ä‘á» khi sá»­ dá»¥ng yolov3 mong cÃ¡c anh chá»‹ giÃºp Ä‘á»¡. Em Ä‘Ã£ dÃ¹ng Yolo v3 Ä‘á»ƒ training nháº­n dáº¡ng táº¿ bÃ o mÃ¡u, vÃ  thu Ä‘Æ°á»£c file weight á»Ÿ hÆ¡n 4000 vÃ²ng. Data cá»§a em gá»“m cÃ³ 400 áº£nh vá»›i kÃ­ch thÆ°á»›c 640x480 vÃ  330 áº£nh cÃ³ kÃ­ch thÆ°á»›c 1392x1038 vá»›i mÃ u sáº¯c táº¿ bÃ o cÃ³ nhiá»u khÃ¡c biá»‡t do em thu tháº­p tá»« nhiá»u nguá»“n. Tuy nhiÃªn khi em test thÃ¬ yolov3 chá»‰ nháº­n diá»‡n Ä‘Æ°á»£c cÃ¡c áº£nh gá»‘c cÃ³ kÃ­ch thÆ°á»›c 640x480, cÃ²n cÃ¡c áº£nh khÃ¡c khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c. Em cÅ©ng Ä‘Ã£ thá»­ crop áº£nh 1392x1038 vá» kÃ­ch thÆ°á»›c 640x480 cÅ©ng khÃ´ng thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c . Váº­y mong cÃ¡c anh cÃ³ cÃ¡ch nÃ o giÃºp em Ä‘á»ƒ em cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c áº£nh hoáº·c hÆ°á»›ng dáº«n em lÃ m cÃ¡ch nÃ o Ä‘á»ƒ phÃ¡t hiá»‡n ra váº¥n Ä‘á». Em cáº£m Æ¡n nhiá»u! Trong Ä‘oáº¡n code: blob = cv2.dnn.blobFromImage(img, 0.00392, (896, 896), (0, 0, 0), em Ä‘á»ƒ kÃ­ch thÆ°á»›c 896 thÃ¬ nháº­n diá»‡n Ä‘Æ°á»£c áº£nh cÃ³ kÃ­ch thÆ°á»›c 640x480, CÃ²n náº¿u em Ä‘á»ƒ (416x416) thÃ¬ áº£nh cÃ³ kÃ­ch thÆ°á»›c 640x480 cÅ©ng khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c.",,,,,
"Em chÃ o cÃ¡c anh chá»‹ áº¡
Hiá»‡n táº¡i em Ä‘ang xÃ¢y dá»±ng máº¡ng VGGNET16 Ä‘á»ƒ phÃ¢n biá»‡t tÆ° tháº¿ ngÆ°á»i vÃ  cÃ³ khoáº£ng 17000 áº£nh chia lÃ m 3 lá»›p á»©ng vá»›i náº±m, Ä‘á»©ng vÃ  ngá»“i. Tuy nhiÃªn hiá»‡n táº¡i á»Ÿ bÆ°á»›c tiá»n xá»­ lÃ½ áº£nh Ä‘áº§u vÃ o Ä‘ang gáº·p má»™t chÃºt váº¥n Ä‘á» mÃ  em Ä‘Ã£ google rá»“i nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch giáº£i quyáº¿t. Em ráº¥t mong ai Ä‘Ã£ gáº·p váº¥n Ä‘á» nÃ y rá»“i cho em lá»i khuyÃªn vá»›i áº¡ =( .
Theo yÃªu cáº§u cá»§a máº¡ng VGGNET thÃ¬ kÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o lÃ  224x224. VÃ  á»Ÿ bÆ°á»›c tiá»n xá»­ lÃ½ em Ä‘Ã£ thá»±c hiá»‡n viá»‡c resize táº¥t cáº£ 17000 áº£nh vá» 224x224 nhÆ° Ä‘oáº¡n code á»Ÿ trÃªn. Tuy nhiÃªn, em tháº¥y nÃ³ ngá»‘n ráº¥t nhiá»u RAM trÃªn Google Colab, vÃ  khi resize Ä‘Æ°á»£c háº¿t thÃ¬ Colab nÃ³ tá»± bá»‹ ngáº¯t káº¿t ná»‘i ( lÃºc resize xong lÃ  háº¿t táº§m 11GB RAM cá»§a Colab). Em Ä‘oÃ¡n lÃ  do bá»‹ trÃ n RAM mÃ  váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c hÆ°á»›ng giáº£i quyáº¿t. TrÆ°á»›c Ä‘Ã³ em thá»­ resize vá» 64x64 thÃ¬ váº«n thá»±c hiá»‡n Ä‘Æ°á»£c (máº¥t khoáº£ng 2 tiáº¿ng) nhÆ°ng khi lÃ  224x224 thÃ¬ bá»‹ lá»—i nhÆ° em mÃ´ táº£ á»Ÿ trÃªn.
Em ráº¥t mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn tá»« cÃ¡c anh/chá»‹. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u !","Em chÃ o cÃ¡c anh chá»‹ áº¡ Hiá»‡n táº¡i em Ä‘ang xÃ¢y dá»±ng máº¡ng VGGNET16 Ä‘á»ƒ phÃ¢n biá»‡t tÆ° tháº¿ ngÆ°á»i vÃ  cÃ³ khoáº£ng 17000 áº£nh chia lÃ m 3 lá»›p á»©ng vá»›i náº±m, Ä‘á»©ng vÃ  ngá»“i. Tuy nhiÃªn hiá»‡n táº¡i á»Ÿ bÆ°á»›c tiá»n xá»­ lÃ½ áº£nh Ä‘áº§u vÃ o Ä‘ang gáº·p má»™t chÃºt váº¥n Ä‘á» mÃ  em Ä‘Ã£ google rá»“i nhÆ°ng chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch giáº£i quyáº¿t. Em ráº¥t mong ai Ä‘Ã£ gáº·p váº¥n Ä‘á» nÃ y rá»“i cho em lá»i khuyÃªn vá»›i áº¡ =( . Theo yÃªu cáº§u cá»§a máº¡ng VGGNET thÃ¬ kÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o lÃ  224x224. VÃ  á»Ÿ bÆ°á»›c tiá»n xá»­ lÃ½ em Ä‘Ã£ thá»±c hiá»‡n viá»‡c resize táº¥t cáº£ 17000 áº£nh vá» 224x224 nhÆ° Ä‘oáº¡n code á»Ÿ trÃªn. Tuy nhiÃªn, em tháº¥y nÃ³ ngá»‘n ráº¥t nhiá»u RAM trÃªn Google Colab, vÃ  khi resize Ä‘Æ°á»£c háº¿t thÃ¬ Colab nÃ³ tá»± bá»‹ ngáº¯t káº¿t ná»‘i ( lÃºc resize xong lÃ  háº¿t táº§m 11GB RAM cá»§a Colab). Em Ä‘oÃ¡n lÃ  do bá»‹ trÃ n RAM mÃ  váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c hÆ°á»›ng giáº£i quyáº¿t. TrÆ°á»›c Ä‘Ã³ em thá»­ resize vá» 64x64 thÃ¬ váº«n thá»±c hiá»‡n Ä‘Æ°á»£c (máº¥t khoáº£ng 2 tiáº¿ng) nhÆ°ng khi lÃ  224x224 thÃ¬ bá»‹ lá»—i nhÆ° em mÃ´ táº£ á»Ÿ trÃªn. Em ráº¥t mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn tá»« cÃ¡c anh/chá»‹. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u !",,,,,
"ChÃ o má»i ngÆ°á»i, em hiá»‡n Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» real time semantic segmentation. NhÆ°ng em Ä‘ang gáº·p váº¥n Ä‘á» vá» nháº­n diá»‡n máº·t Ä‘Æ°á»ng, cÃ²n láº¡i cÃ¡c váº­t thá»ƒ khÃ¡c bÃ¬nh thÆ°á»ng.
HIá»‡n em Ä‘ang sá»­ dá»¥ng Mask RCNN vá»›i 5000 áº£nh vÃ  10 lá»›p nhÆ°ng detect ra thÃ¬ máº·t Ä‘Æ°á»ng bá»‹ lem khÃ¡ nhiá»u. Má»i ngÆ°á»i cá»‘ thá»ƒ cho em xin cÃ¡ch giáº£i quyÃªt vÃ  má»™t sá»‘ mÃ´ hÃ¬nh nÃ o phÃ¹ há»£p hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡.
Em xin cÃ¡m Æ¡n áº¡.","ChÃ o má»i ngÆ°á»i, em hiá»‡n Ä‘ang lÃ m Ä‘á»“ Ã¡n vá» real time semantic segmentation. NhÆ°ng em Ä‘ang gáº·p váº¥n Ä‘á» vá» nháº­n diá»‡n máº·t Ä‘Æ°á»ng, cÃ²n láº¡i cÃ¡c váº­t thá»ƒ khÃ¡c bÃ¬nh thÆ°á»ng. HIá»‡n em Ä‘ang sá»­ dá»¥ng Mask RCNN vá»›i 5000 áº£nh vÃ  10 lá»›p nhÆ°ng detect ra thÃ¬ máº·t Ä‘Æ°á»ng bá»‹ lem khÃ¡ nhiá»u. Má»i ngÆ°á»i cá»‘ thá»ƒ cho em xin cÃ¡ch giáº£i quyÃªt vÃ  má»™t sá»‘ mÃ´ hÃ¬nh nÃ o phÃ¹ há»£p hÆ¡n Ä‘Æ°á»£c khÃ´ng áº¡. Em xin cÃ¡m Æ¡n áº¡.",,,,,
"Xin chÃ o cÃ¡c bÃ¡c, hÃ´m nay em xin tiáº¿p theo series vá» Python, Keras vÃ  CNN. Mong ráº±ng qua bÃ i nÃ y báº¡n nÃ o má»›i há»c cÅ©ng cÃ³ thá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c model CNN cho mÃ¬nh!
Mong ad duyá»‡t bÃ i!","Xin chÃ o cÃ¡c bÃ¡c, hÃ´m nay em xin tiáº¿p theo series vá» Python, Keras vÃ  CNN. Mong ráº±ng qua bÃ i nÃ y báº¡n nÃ o má»›i há»c cÅ©ng cÃ³ thá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c model CNN cho mÃ¬nh! Mong ad duyá»‡t bÃ i!",,,,,
"ChÃ o cáº£ nhÃ ,
BÃªn mÃ¬nh lÃ  cty sxuat Ä‘ang cáº§n tÃ¬m giáº£i phÃ¡p Ä‘á»ƒ tá»± Ä‘á»™ng hoÃ¡ 1 sá»‘ khÃ¢u sáº£n xuáº¥t, dÃ¹ng camera detection Ä‘á»ƒ phÃ¢n loáº¡i sáº£n pháº©m theo 5-6 tiÃªu chÃ­ vÃ  loáº¡i bá» hÃ ng k Ä‘áº¡t yÃªu cáº§u.
Báº¡n nÃ o quan tÃ¢m vÃ  cÃ³ Ä‘Æ°á»£c giáº£i phÃ¡p thid inbox mÃ¬nh hoáº·c liÃªn há»‡ qua zalo 0778107721 Ä‘á»ƒ trao Ä‘á»•i cá»¥ thá»ƒ hÆ¡n nhÃ©. MÃ¬nh xin cáº£m Æ¡n.","ChÃ o cáº£ nhÃ , BÃªn mÃ¬nh lÃ  cty sxuat Ä‘ang cáº§n tÃ¬m giáº£i phÃ¡p Ä‘á»ƒ tá»± Ä‘á»™ng hoÃ¡ 1 sá»‘ khÃ¢u sáº£n xuáº¥t, dÃ¹ng camera detection Ä‘á»ƒ phÃ¢n loáº¡i sáº£n pháº©m theo 5-6 tiÃªu chÃ­ vÃ  loáº¡i bá» hÃ ng k Ä‘áº¡t yÃªu cáº§u. Báº¡n nÃ o quan tÃ¢m vÃ  cÃ³ Ä‘Æ°á»£c giáº£i phÃ¡p thid inbox mÃ¬nh hoáº·c liÃªn há»‡ qua zalo 0778107721 Ä‘á»ƒ trao Ä‘á»•i cá»¥ thá»ƒ hÆ¡n nhÃ©. MÃ¬nh xin cáº£m Æ¡n.",,,,,
"Em chÃ o má»i ngÆ°á»i áº¡.
Hiá»‡n táº¡i, em Ä‘ang cÃ³ folder dá»¯ liá»‡u áº£nh vá»›i cÃ¡c nhÃ£n tÆ°Æ¡ng á»©ng. Em muá»‘n chia cÃ¡c dá»¯ liá»‡u áº£nh nÃ y thÃ nh 75% train, 15% validation vÃ  10% dÃ¹ng Ä‘á»ƒ test dáº¡ng nhÆ° áº£nh bÃªn dÆ°á»›i Ä‘á»ƒ load generator vÃ o cÃ¡c thÆ° viá»‡n kiá»ƒu nhÆ° flow_from_directory cá»§a keras. Em Ä‘Ã£ tra trÃªn Tensorflow thÃ¬ tháº¥y há» chá»‰ lÃ m vá»›i hÃ m tf.keras.preprocessing.image_dataset_from_directory, tá»©c lÃ  há»c chá»‰ chia thÃ nh 2 pháº§n train vÃ  validation. BÃ¢y giá», em muá»‘n chia lÃ m 3 nhÆ° áº£nh trÃªn thÃ¬ cÃ³ hÆ°á»›ng giáº£i quyáº¿t nÃ o khÃ´ng áº¡.
Ráº¥t mong má»i ngÆ°á»i cho em lá»i khuyÃªn áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.","Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i, em Ä‘ang cÃ³ folder dá»¯ liá»‡u áº£nh vá»›i cÃ¡c nhÃ£n tÆ°Æ¡ng á»©ng. Em muá»‘n chia cÃ¡c dá»¯ liá»‡u áº£nh nÃ y thÃ nh 75% train, 15% validation vÃ  10% dÃ¹ng Ä‘á»ƒ test dáº¡ng nhÆ° áº£nh bÃªn dÆ°á»›i Ä‘á»ƒ load generator vÃ o cÃ¡c thÆ° viá»‡n kiá»ƒu nhÆ° flow_from_directory cá»§a keras. Em Ä‘Ã£ tra trÃªn Tensorflow thÃ¬ tháº¥y há» chá»‰ lÃ m vá»›i hÃ m tf.keras.preprocessing.image_dataset_from_directory, tá»©c lÃ  há»c chá»‰ chia thÃ nh 2 pháº§n train vÃ  validation. BÃ¢y giá», em muá»‘n chia lÃ m 3 nhÆ° áº£nh trÃªn thÃ¬ cÃ³ hÆ°á»›ng giáº£i quyáº¿t nÃ o khÃ´ng áº¡. Ráº¥t mong má»i ngÆ°á»i cho em lá»i khuyÃªn áº¡. Cáº£m Æ¡n má»i ngÆ°á»i nhiá»u.",,,,,
"Hi má»i ngÆ°á»i,
Em cÃ³ cÃ¡i mÃ´ hÃ¬nh cháº¡y báº±ng sklearn , decision tree,
NhÆ°ng nuá»‘n deploy lÃªn android nÃªn cáº§n model xuáº¥t ra lÃ  Ä‘uÃ´i . Tflite
CÃ³ cÃ¡ch nÃ o lÆ°u hay convert model sklearn thÃ nh .tf khÃ´ng áº¡?
( em Ä‘á»‹nh train láº¡i báº±ng tensoflow nhÆ°ng láº¡i k tÃ¬m dc package Ä‘á»ƒ train )","Hi má»i ngÆ°á»i, Em cÃ³ cÃ¡i mÃ´ hÃ¬nh cháº¡y báº±ng sklearn , decision tree, NhÆ°ng nuá»‘n deploy lÃªn android nÃªn cáº§n model xuáº¥t ra lÃ  Ä‘uÃ´i . Tflite CÃ³ cÃ¡ch nÃ o lÆ°u hay convert model sklearn thÃ nh .tf khÃ´ng áº¡? ( em Ä‘á»‹nh train láº¡i báº±ng tensoflow nhÆ°ng láº¡i k tÃ¬m dc package Ä‘á»ƒ train )",,,,,
"AI for Accessibility Virtual Hackathon from Microsoft APAC
â­ ChÆ°Æ¡ng trÃ¬nh AI for Accessibility Virtual Hackathon lÃ  cuá»™c thi tÃ¬m kiáº¿m Ã½ tÆ°á»Ÿng vÃ  xÃ¢y dÆ°ng prototype há»— trá»£ ngÆ°á»i khuyáº¿t táº­t Ä‘áº¿n gáº§n vá»›i cÃ´ng viá»‡c Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ thu nháº­p vÃ  cáº£i thiá»‡n hoáº¡t Ä‘á»™ng hÃ ng ngÃ y cá»§a cÃ¡ nhÃ¢n (Ä‘i chá»£, Ä‘i bá»‡nh viá»‡n, Ä‘i xung quanh ğŸ˜Š) vÃ  cÃ³ thá»ƒ link Ä‘áº¿n public transport. CÃ¡c báº¡n thÃ nh láº­p team (2-5 ngÆ°á»i) vÃ  Ä‘Äƒng kÃ½ sáº½ Ä‘Æ°á»£c há»— trá»£ tá»« cÃ¡c chuyÃªn gia TrÃ­ Tuá»‡ NhÃ¢n Táº¡o cá»§a Microsoft coach vÃ  tham gia cÃ¡c khÃ³a há»c online Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng cho chÆ°Æ¡ng trÃ¬nh nÃ y. Sau vÃ²ng shortlist, nhá»¯ng presentation & demo Ã½ tÆ°á»Ÿng sáº½ thi cÃ¹ng nhau á»Ÿ viá»‡t nam Ä‘á»ƒ chá»n ra 1 winner.
â­ Cuá»™c thi nÃ y APAC cÃ³ 11 nÆ°á»›c cÃ¹ng tham gia. Äáº¡i diá»‡n má»—i nÆ°á»›c sáº½ Ä‘c tranh tÃ i trong cuá»™c thi cá»§a APAC vÃ  tranh giáº£i Microsoft AI for Good cá»§a global, giáº£i thÆ°á»Ÿng up to US$20,000 Azure Credits. VÃ  Ä‘Æ°á»£c tuyá»ƒn tháº³ng vÃ o ctrinh Microsoft Starts up competition, ngÆ°á»i tháº¯ng sáº½ cÃ³ fund support up to US$20 million.
â­ NhÆ° váº­y ctrinh nÃ y sáº½ cÃ³ lá»£i cho ngÆ°á»i tham dá»± vá» máº·t nÃ¢ng cao ká»¹ nÄƒng presentation vÃ  pitch ideas, má»™t qui trÃ¬nh hoÃ n chá»‰nh vá» xÃ¢y dá»±ng vÃ  phÃ¡t triá»ƒn cÃ¡c sÃ¡ng kiáº¿n cá»™ng Ä‘á»“ng, Ä‘áº·c biá»‡t lÃ  ngÆ°á»i khuyáº¿t táº­t. NÄƒm nay 3 chá»§ Ä‘á» chÃ­nh sáº½ táº­p trung vÃ o ngÆ°á»i khiáº¿m thá»‹. Má»¥c Ä‘Ã­ch cuá»‘i cÃ¹ng lÃ  mong nÃ¢ng cao nháº­n thá»©c vá» kháº£ nÄƒng Ä‘Ã³ng gÃ³p vÃ  impact cá»§a cÃ¡c báº¡n cÃ³ thá»ƒ táº¡o ra Ä‘á»ƒ phá»¥c vá»¥ cá»™ng Ä‘á»“ng, Ä‘iá»u Ä‘Ã³ khÃ´ng khÃ³ vÃ  hoÃ n toÃ n trong táº§m tay cÃ¡c báº¡n.
Link:","AI for Accessibility Virtual Hackathon from Microsoft APAC ChÆ°Æ¡ng trÃ¬nh AI for Accessibility Virtual Hackathon lÃ  cuá»™c thi tÃ¬m kiáº¿m Ã½ tÆ°á»Ÿng vÃ  xÃ¢y dÆ°ng prototype há»— trá»£ ngÆ°á»i khuyáº¿t táº­t Ä‘áº¿n gáº§n vá»›i cÃ´ng viá»‡c Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ thu nháº­p vÃ  cáº£i thiá»‡n hoáº¡t Ä‘á»™ng hÃ ng ngÃ y cá»§a cÃ¡ nhÃ¢n (Ä‘i chá»£, Ä‘i bá»‡nh viá»‡n, Ä‘i xung quanh ) vÃ  cÃ³ thá»ƒ link Ä‘áº¿n public transport. CÃ¡c báº¡n thÃ nh láº­p team (2-5 ngÆ°á»i) vÃ  Ä‘Äƒng kÃ½ sáº½ Ä‘Æ°á»£c há»— trá»£ tá»« cÃ¡c chuyÃªn gia TrÃ­ Tuá»‡ NhÃ¢n Táº¡o cá»§a Microsoft coach vÃ  tham gia cÃ¡c khÃ³a há»c online Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng cho chÆ°Æ¡ng trÃ¬nh nÃ y. Sau vÃ²ng shortlist, nhá»¯ng presentation & demo Ã½ tÆ°á»Ÿng sáº½ thi cÃ¹ng nhau á»Ÿ viá»‡t nam Ä‘á»ƒ chá»n ra 1 winner. Cuá»™c thi nÃ y APAC cÃ³ 11 nÆ°á»›c cÃ¹ng tham gia. Äáº¡i diá»‡n má»—i nÆ°á»›c sáº½ Ä‘c tranh tÃ i trong cuá»™c thi cá»§a APAC vÃ  tranh giáº£i Microsoft AI for Good cá»§a global, giáº£i thÆ°á»Ÿng up to US$20,000 Azure Credits. VÃ  Ä‘Æ°á»£c tuyá»ƒn tháº³ng vÃ o ctrinh Microsoft Starts up competition, ngÆ°á»i tháº¯ng sáº½ cÃ³ fund support up to US$20 million. NhÆ° váº­y ctrinh nÃ y sáº½ cÃ³ lá»£i cho ngÆ°á»i tham dá»± vá» máº·t nÃ¢ng cao ká»¹ nÄƒng presentation vÃ  pitch ideas, má»™t qui trÃ¬nh hoÃ n chá»‰nh vá» xÃ¢y dá»±ng vÃ  phÃ¡t triá»ƒn cÃ¡c sÃ¡ng kiáº¿n cá»™ng Ä‘á»“ng, Ä‘áº·c biá»‡t lÃ  ngÆ°á»i khuyáº¿t táº­t. NÄƒm nay 3 chá»§ Ä‘á» chÃ­nh sáº½ táº­p trung vÃ o ngÆ°á»i khiáº¿m thá»‹. Má»¥c Ä‘Ã­ch cuá»‘i cÃ¹ng lÃ  mong nÃ¢ng cao nháº­n thá»©c vá» kháº£ nÄƒng Ä‘Ã³ng gÃ³p vÃ  impact cá»§a cÃ¡c báº¡n cÃ³ thá»ƒ táº¡o ra Ä‘á»ƒ phá»¥c vá»¥ cá»™ng Ä‘á»“ng, Ä‘iá»u Ä‘Ã³ khÃ´ng khÃ³ vÃ  hoÃ n toÃ n trong táº§m tay cÃ¡c báº¡n. Link:",,,,,
"ChÃ o má»i ngÆ°á»i áº¡, em lÃ  thÃ nh viÃªn má»›i vÃ  lÃ  newbie má»›i bÆ°á»›c chÃ¢n vÃ o há»c ngÃ nh nÃ y.
Hiá»‡n táº¡i em Ä‘ang tá»± lÃ m 1 bÃ i toÃ¡n nhá» Ä‘Ã³ lÃ  phÃ¢n cá»¥m vÄƒn báº£n báº±ng thuáº­t toÃ¡n k-means. Em Ä‘Ã£ crawl data, tiá»n xá»­ lÃ½, vector hÃ³a vÄƒn báº£n thÃ nh cÃ¡c Ä‘iá»ƒm vÃ  phÃ¢n cá»¥m thÃ nh cÃ´ng. Tuy nhiÃªn láº­t láº¡i thÃ¬ em gáº·p 1 sá»‘ vÆ°á»›ng máº¯c, Ä‘Ã³ lÃ  lÃ m sao Ä‘á»ƒ biÃªt vÄƒn báº£n nÃ o thuá»™c vá» cá»¥m nÃ o? VÃ¬ má»i vÄƒn báº£n Ä‘á»u Ä‘c vector hÃ³a nÃªn vá» cÆ¡ báº£n lÃ  phÃ¢n cá»¥m cÃ¡c con sá»‘, sau khi phÃ¢n cá»¥m thÃ¬ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ Ã¡nh xáº¡ láº¡i vector Ä‘Ã³ trá» vá» vÄƒn báº£n tÆ°Æ¡ng á»©ng áº¡?
Láº§n Ä‘áº§u Ä‘Äƒng lÃªn group cÃ³ chá»— nÃ o chÆ°a Ä‘Ãºng ná»™i quy mong má»i ngÆ°á»i nháº¯c nhá» chá»© Ä‘á»«ng Ä‘Ã¡ em Ä‘i.","ChÃ o má»i ngÆ°á»i áº¡, em lÃ  thÃ nh viÃªn má»›i vÃ  lÃ  newbie má»›i bÆ°á»›c chÃ¢n vÃ o há»c ngÃ nh nÃ y. Hiá»‡n táº¡i em Ä‘ang tá»± lÃ m 1 bÃ i toÃ¡n nhá» Ä‘Ã³ lÃ  phÃ¢n cá»¥m vÄƒn báº£n báº±ng thuáº­t toÃ¡n k-means. Em Ä‘Ã£ crawl data, tiá»n xá»­ lÃ½, vector hÃ³a vÄƒn báº£n thÃ nh cÃ¡c Ä‘iá»ƒm vÃ  phÃ¢n cá»¥m thÃ nh cÃ´ng. Tuy nhiÃªn láº­t láº¡i thÃ¬ em gáº·p 1 sá»‘ vÆ°á»›ng máº¯c, Ä‘Ã³ lÃ  lÃ m sao Ä‘á»ƒ biÃªt vÄƒn báº£n nÃ o thuá»™c vá» cá»¥m nÃ o? VÃ¬ má»i vÄƒn báº£n Ä‘á»u Ä‘c vector hÃ³a nÃªn vá» cÆ¡ báº£n lÃ  phÃ¢n cá»¥m cÃ¡c con sá»‘, sau khi phÃ¢n cá»¥m thÃ¬ lÃ m cÃ¡ch nÃ o Ä‘á»ƒ Ã¡nh xáº¡ láº¡i vector Ä‘Ã³ trá» vá» vÄƒn báº£n tÆ°Æ¡ng á»©ng áº¡? Láº§n Ä‘áº§u Ä‘Äƒng lÃªn group cÃ³ chá»— nÃ o chÆ°a Ä‘Ãºng ná»™i quy mong má»i ngÆ°á»i nháº¯c nhá» chá»© Ä‘á»«ng Ä‘Ã¡ em Ä‘i.",,,,,
"chÃ o máº¥y a/c, a Tiep,
cho em há»i cÃ¢u ngoÃ i lá» xÃ­u, google facebook dÃ¹ng cÃ¡i gÃ¬ Ä‘á»ƒ lÆ°u trá»¯ hÃ ng tá»‰ Gb thÃ´ng tin ngÆ°á»i dÃ¹ng áº¡, sao cÃ¡c camera giÃ¡m sÃ¡t há» khÃ´ng dÃ¹ng cloud Ä‘á»ƒ lÆ°u video Ä‘á»ƒ cho hÃ¬nh áº£nh cháº¥t lÆ°á»£ng hÆ¡n, ko lo háº¿t bá»™ nhá»›!","chÃ o máº¥y a/c, a Tiep, cho em há»i cÃ¢u ngoÃ i lá» xÃ­u, google facebook dÃ¹ng cÃ¡i gÃ¬ Ä‘á»ƒ lÆ°u trá»¯ hÃ ng tá»‰ Gb thÃ´ng tin ngÆ°á»i dÃ¹ng áº¡, sao cÃ¡c camera giÃ¡m sÃ¡t há» khÃ´ng dÃ¹ng cloud Ä‘á»ƒ lÆ°u video Ä‘á»ƒ cho hÃ¬nh áº£nh cháº¥t lÆ°á»£ng hÆ¡n, ko lo háº¿t bá»™ nhá»›!",,,,,
"ChÃ o mn áº¡ ,em lÃ  newbie
Mn cho em há»i em Ä‘ang dÃ¹ng há»‡ Ä‘h Linux 16.04 . Em vá»«a cÃ i CudaToolkit thÃ¬ bÃ¢y giá» lÃ m sao Ä‘á»ƒ biáº¿t mÃ¬nh Ä‘ang train model báº±ng CPU hay GPU áº¡ ! Em cáº£m Æ¡n","ChÃ o mn áº¡ ,em lÃ  newbie Mn cho em há»i em Ä‘ang dÃ¹ng há»‡ Ä‘h Linux 16.04 . Em vá»«a cÃ i CudaToolkit thÃ¬ bÃ¢y giá» lÃ m sao Ä‘á»ƒ biáº¿t mÃ¬nh Ä‘ang train model báº±ng CPU hay GPU áº¡ ! Em cáº£m Æ¡n",,,,,
"Má»i ngÆ°á»i Æ¡i, hiá»‡n táº¡i em Ä‘ang lÃ m má»™t project liÃªn quan Ä‘áº¿n nháº­n diá»‡n biá»ƒn sá»‘ xe. Pháº§n detect biá»ƒn sá»‘ em Ä‘Ã£ hoÃ n thÃ nh xong. NhÆ°ng Ä‘áº¿n pháº§n Segment thÃ¬ gáº·p váº¥n Ä‘á». Em sá»­ dá»¥ng findCoutours() cá»§a OpenCV vÃ o bá»©c hÃ¬nh Ä‘Ã£ chuyá»ƒn vá» binary. Káº¿t quáº£ ra nhÆ° bÃªn dÆ°á»›i. LÃ m sao Ä‘á»ƒ xá»­ lÃ½ Ä‘oáº¡n nÃ y áº¡. Em cÃ¡m Æ¡n má»i
ngÆ°á»i.","Má»i ngÆ°á»i Æ¡i, hiá»‡n táº¡i em Ä‘ang lÃ m má»™t project liÃªn quan Ä‘áº¿n nháº­n diá»‡n biá»ƒn sá»‘ xe. Pháº§n detect biá»ƒn sá»‘ em Ä‘Ã£ hoÃ n thÃ nh xong. NhÆ°ng Ä‘áº¿n pháº§n Segment thÃ¬ gáº·p váº¥n Ä‘á». Em sá»­ dá»¥ng findCoutours() cá»§a OpenCV vÃ o bá»©c hÃ¬nh Ä‘Ã£ chuyá»ƒn vá» binary. Káº¿t quáº£ ra nhÆ° bÃªn dÆ°á»›i. LÃ m sao Ä‘á»ƒ xá»­ lÃ½ Ä‘oáº¡n nÃ y áº¡. Em cÃ¡m Æ¡n má»i ngÆ°á»i.",,,,,
"[AI News - Video Completion]
Äá»™i ngÅ© nghiÃªn cá»©u nhÃ  Virginia Tech and Facebook gáº§n Ä‘Ã¢y Ä‘Ã£ cÃ´ng bá»‘ thuáº­t toÃ¡n xÃ³a váº­t thá»ƒ chuyá»ƒn Ä‘á»™ng trong video á»©ng dá»¥ng AI cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao. NgÆ°á»i dÃ¹ng chá»‰ cáº§n khoanh kÃ­n vÃ¹ng cÃ³ Ä‘á»‘i tÆ°á»£ng vÃ  AI sáº½ loáº¡i bá» hoÃ n toÃ n Ä‘á»‘i tÆ°á»£ng Ä‘Ã³ trong video mÃ  khÃ´ng cáº§n sá»­ dá»¥ng cÃ¡c ká»¹ nÄƒng, thao tÃ¡c phá»©c táº¡p.
Trong vÃ i nÄƒm gáº§n Ä‘Ã¢y, cÅ©ng Ä‘Ã£ cÃ³ cÃ¡c thuáº­t toÃ¡n AI xÃ³a váº­t thá»ƒ chuyá»ƒn Ä‘á»™ng ra Ä‘á»i, tuy nhiÃªn káº¿t quáº£ váº«n cÃ²n nhÃ¬n rÃµ bÃ³ng hoáº·c dáº¥u váº¿t cÃ¡c cáº¡nh cá»§a váº­t thá»ƒ. Thuáº­t toÃ¡n má»›i nÃ y gáº§n nhÆ° kháº¯c phá»¥c Ä‘Æ°á»£c cÃ¡c háº¡n cháº¿ cá»§a cÃ¡c thuáº­t toÃ¡n hiá»‡n táº¡i. Flow edges, Non-local flow, Seamless blending vÃ  Memory efficiency lÃ m nÃªn thÃ nh cÃ´ng cá»§a thuáº­t toÃ¡n nÃ y. ÄÃ¢y lÃ  thuáº­t toÃ¡n cho ra káº¿t quáº£ tá»‘t nháº¥t so vá»›i cÃ¡c thuáº­t toÃ¡n hiá»‡n táº¡i.
BÃªn dÆ°á»›i lÃ  video Ä‘Æ°á»£c Ã¡p dá»¥ng thuáº­t toÃ¡n. KhÃ´ng biáº¿t cÃ³ pháº£i do bá»‘n máº¯t khÃ´ng mÃ  mÃ¬nh cháº³ng tháº¥y sá»± khÃ¡c biá»‡t gÃ¬ vá» khung cáº£nh giá»¯a trÆ°á»›c vÃ  sau khi xÃ³a váº­t thá»ƒ cáº£. CÃ²n cÃ¡c báº¡n thÃ¬ sao?
Paper vÃ  code cho báº¡n nÃ o cÃ³ há»©ng thÃº:
Paper: https://arxiv.org/abs/2009.01835
Code: https://github.com/vt-vl-lab/FGVC","[AI News - Video Completion] Äá»™i ngÅ© nghiÃªn cá»©u nhÃ  Virginia Tech and Facebook gáº§n Ä‘Ã¢y Ä‘Ã£ cÃ´ng bá»‘ thuáº­t toÃ¡n xÃ³a váº­t thá»ƒ chuyá»ƒn Ä‘á»™ng trong video á»©ng dá»¥ng AI cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao. NgÆ°á»i dÃ¹ng chá»‰ cáº§n khoanh kÃ­n vÃ¹ng cÃ³ Ä‘á»‘i tÆ°á»£ng vÃ  AI sáº½ loáº¡i bá» hoÃ n toÃ n Ä‘á»‘i tÆ°á»£ng Ä‘Ã³ trong video mÃ  khÃ´ng cáº§n sá»­ dá»¥ng cÃ¡c ká»¹ nÄƒng, thao tÃ¡c phá»©c táº¡p. Trong vÃ i nÄƒm gáº§n Ä‘Ã¢y, cÅ©ng Ä‘Ã£ cÃ³ cÃ¡c thuáº­t toÃ¡n AI xÃ³a váº­t thá»ƒ chuyá»ƒn Ä‘á»™ng ra Ä‘á»i, tuy nhiÃªn káº¿t quáº£ váº«n cÃ²n nhÃ¬n rÃµ bÃ³ng hoáº·c dáº¥u váº¿t cÃ¡c cáº¡nh cá»§a váº­t thá»ƒ. Thuáº­t toÃ¡n má»›i nÃ y gáº§n nhÆ° kháº¯c phá»¥c Ä‘Æ°á»£c cÃ¡c háº¡n cháº¿ cá»§a cÃ¡c thuáº­t toÃ¡n hiá»‡n táº¡i. Flow edges, Non-local flow, Seamless blending vÃ  Memory efficiency lÃ m nÃªn thÃ nh cÃ´ng cá»§a thuáº­t toÃ¡n nÃ y. ÄÃ¢y lÃ  thuáº­t toÃ¡n cho ra káº¿t quáº£ tá»‘t nháº¥t so vá»›i cÃ¡c thuáº­t toÃ¡n hiá»‡n táº¡i. BÃªn dÆ°á»›i lÃ  video Ä‘Æ°á»£c Ã¡p dá»¥ng thuáº­t toÃ¡n. KhÃ´ng biáº¿t cÃ³ pháº£i do bá»‘n máº¯t khÃ´ng mÃ  mÃ¬nh cháº³ng tháº¥y sá»± khÃ¡c biá»‡t gÃ¬ vá» khung cáº£nh giá»¯a trÆ°á»›c vÃ  sau khi xÃ³a váº­t thá»ƒ cáº£. CÃ²n cÃ¡c báº¡n thÃ¬ sao? Paper vÃ  code cho báº¡n nÃ o cÃ³ há»©ng thÃº: Paper: https://arxiv.org/abs/2009.01835 Code: https://github.com/vt-vl-lab/FGVC",,,,,
Cáº£ nhÃ  cÃ³ kinh nghiá»‡m xá»­ lÃ½ text classification vÃ  semantic search ntn báº±ng viá»‡c xá»­ dá»¥ng Reformer (Transformer) khÃ´ng? MÃ¬nh cáº£m Æ¡n,Cáº£ nhÃ  cÃ³ kinh nghiá»‡m xá»­ lÃ½ text classification vÃ  semantic search ntn báº±ng viá»‡c xá»­ dá»¥ng Reformer (Transformer) khÃ´ng? MÃ¬nh cáº£m Æ¡n,,,,,
"Respect!
 â€” vá»›i Huyen Nguyen.",Respect! â€” vá»›i Huyen Nguyen.,,,,,
"Em chÃ o cÃ¡c anh/chá»‹ áº¡

Em Ä‘ang lÃ m 1 bÃ i toÃ¡n forecasting (multivariate) sá»­ dá»¥ng LSTM (implement báº±ng torch) vÃ  gáº·p 1 sá»‘ váº¥n Ä‘á» khi update weights mong anh/chá»‹ gÃ³p Ã½ áº¡:

á» dÆ°á»›i Ä‘Ã¢y thÃ¬ em dÃ¹ng batch size = 64, learning rate = 0.001 thÃ¬ training loss (MSE) cÃ³ giáº£m nháº¹ trong quÃ¡ trÃ¬nh training nhÆ°ng ko Ä‘Ã¡ng ká»ƒ. CÃ²n nhá»¯ng hyperparam khÃ¡c thÃ¬ loss Ä‘á»u khÃ´ng giáº£m
Em cÃ³ plot thay Ä‘á»•i cá»§a loss theo tá»«ng batch vá»›i má»—i training epoch vÃ  plot cá»§a cÃ¡c epoch Ä‘á»u gáº§n nhÆ° y há»‡t nhau nhÆ° weights ko Ä‘c updates váº­y
Em cáº£m Æ¡n áº¡","Em chÃ o cÃ¡c anh/chá»‹ áº¡ Em Ä‘ang lÃ m 1 bÃ i toÃ¡n forecasting (multivariate) sá»­ dá»¥ng LSTM (implement báº±ng torch) vÃ  gáº·p 1 sá»‘ váº¥n Ä‘á» khi update weights mong anh/chá»‹ gÃ³p Ã½ áº¡: á» dÆ°á»›i Ä‘Ã¢y thÃ¬ em dÃ¹ng batch size = 64, learning rate = 0.001 thÃ¬ training loss (MSE) cÃ³ giáº£m nháº¹ trong quÃ¡ trÃ¬nh training nhÆ°ng ko Ä‘Ã¡ng ká»ƒ. CÃ²n nhá»¯ng hyperparam khÃ¡c thÃ¬ loss Ä‘á»u khÃ´ng giáº£m Em cÃ³ plot thay Ä‘á»•i cá»§a loss theo tá»«ng batch vá»›i má»—i training epoch vÃ  plot cá»§a cÃ¡c epoch Ä‘á»u gáº§n nhÆ° y há»‡t nhau nhÆ° weights ko Ä‘c updates váº­y Em cáº£m Æ¡n áº¡",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh dá»± Ä‘á»‹nh xÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n lá»›p cho vÄƒn báº£n báº±ng BERT.
Má»—i vÄƒn báº£n thuá»™c má»™t lÄ©nh vá»±c nÃ o Ä‘Ã³.
MÃ¬nh tháº¯c máº¯c á»Ÿ chá»— lÃ  BERT chá»‰ cho phÃ©p tá»‘i Ä‘a 512 tokens, cÃ²n vÄƒn báº£n cá»§a mÃ¬nh thÃ¬ cÃ³ khi lá»›n hÆ¡n nhiá»u, viá»‡c truncating cÃ³ thá»ƒ lÃ m máº¥t Ä‘i Ã½ nghÄ©a cá»§a dá»¯ liá»‡u.
Váº­y cÃ³ hÆ°á»›ng nÃ o Ä‘á»ƒ giáº£i quyáº¿t khÃ´ng áº¡?","ChÃ o má»i ngÆ°á»i, mÃ¬nh dá»± Ä‘á»‹nh xÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n lá»›p cho vÄƒn báº£n báº±ng BERT. Má»—i vÄƒn báº£n thuá»™c má»™t lÄ©nh vá»±c nÃ o Ä‘Ã³. MÃ¬nh tháº¯c máº¯c á»Ÿ chá»— lÃ  BERT chá»‰ cho phÃ©p tá»‘i Ä‘a 512 tokens, cÃ²n vÄƒn báº£n cá»§a mÃ¬nh thÃ¬ cÃ³ khi lá»›n hÆ¡n nhiá»u, viá»‡c truncating cÃ³ thá»ƒ lÃ m máº¥t Ä‘i Ã½ nghÄ©a cá»§a dá»¯ liá»‡u. Váº­y cÃ³ hÆ°á»›ng nÃ o Ä‘á»ƒ giáº£i quyáº¿t khÃ´ng áº¡?",,,,,
"Hi má»i ngÆ°á»i,
Cho em há»i lÃ  thÆ°á»ng trong bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh vá»›i Conv2D, trÆ°á»›c lá»›p cuá»‘i cÃ¹ng lÃ  Dense(num_classes, activation=""sigmoid/softmax"") thÃ¬ cÃ³ 1 layer ná»¯a lÃ  Dense(128, activation='relu')).
Tuá»³ vÃ o bÃ i mÃ  sáº½ cÃ³ sá»‘ khÃ¡c 128, váº­y con sá»‘ nÃ y lÃ  dá»±a vÃ o Ä‘Ã¢u Ä‘á»ƒ tÃ¬m áº¡. Em xin cáº£m Æ¡n ^^","Hi má»i ngÆ°á»i, Cho em há»i lÃ  thÆ°á»ng trong bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh vá»›i Conv2D, trÆ°á»›c lá»›p cuá»‘i cÃ¹ng lÃ  Dense(num_classes, activation=""sigmoid/softmax"") thÃ¬ cÃ³ 1 layer ná»¯a lÃ  Dense(128, activation='relu')). Tuá»³ vÃ o bÃ i mÃ  sáº½ cÃ³ sá»‘ khÃ¡c 128, váº­y con sá»‘ nÃ y lÃ  dá»±a vÃ o Ä‘Ã¢u Ä‘á»ƒ tÃ¬m áº¡. Em xin cáº£m Æ¡n ^^",,,,,
"Em chÃ o cÃ¡c anh chá»‹ áº¡, em cÃ³ cÃ¢u há»i lÃ  trong bÃ i toÃ¡n dá»‹ch mÃ¡y tá»± Ä‘á»™ng khi Ã¡p dá»¥ng cho tiáº¿ng viá»‡t + tiáº¿ng anh thÃ¬ ngoÃ i Ä‘iá»ƒm BLEU ra mÃ¬nh cÃ³ thá»ƒ dÃ¹ng Ä‘iá»ƒm nÃ o khÃ¡c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh khÃ´ng áº¡?","Em chÃ o cÃ¡c anh chá»‹ áº¡, em cÃ³ cÃ¢u há»i lÃ  trong bÃ i toÃ¡n dá»‹ch mÃ¡y tá»± Ä‘á»™ng khi Ã¡p dá»¥ng cho tiáº¿ng viá»‡t + tiáº¿ng anh thÃ¬ ngoÃ i Ä‘iá»ƒm BLEU ra mÃ¬nh cÃ³ thá»ƒ dÃ¹ng Ä‘iá»ƒm nÃ o khÃ¡c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh khÃ´ng áº¡?",,,,,
"Ká»¹ thuáº­t phÃ¢n chia dá»¯ liá»‡u cho ba nhÃ³m: training vÃ  test (thÃªm Validation)
ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ má»™t bÃ i táº­p nhá» vá» phÃ¢n chia dá»¯ liá»‡u cho má»™t mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n trong báº£o hiá»ƒm. Dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n bá»‹ lÃ  má»™t pandas vá»›i nhiá»u biáº¿n khÃ¡c nhau. MÃ¬nh cáº§n chia dá»¯ liá»‡u thÃ nh ba bá»™ pháº­n nÃ³i trÃªn: training, validation vÃ  test. MÃ¬nh cÃ³ máº¥y cÃ¢u há»i cáº§n sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c báº¡n nhÆ° sau:
1, Chá»‰ cáº§n chia thÃ nh training vÃ  test hay nháº¥t thiáº¿t pháº£i cÃ³ pháº§n thá»© 3 lÃ  validation. Tá»‰ lá»‡ hay gáº·p nháº¥t giá»¯a cÃ¡c pháº§n lÃ  bao nhiÃªu?
2. Ban Ä‘áº§u mÃ¬nh Ä‘á»‹nh láº¥y ngáº«u nhiÃªn 80% cho training vÃ  20% cho test nhÆ°ng láº¡i sá»£ phÃ¢n bá»‘ dá»¯ liá»‡u khÃ´ng Ä‘á»u nÃªn mÃ¬nh thay Ä‘á»•i lÃ : Láº¥y index chia cho 5: náº¿u index chia háº¿t cho 5 thÃ¬ láº¥y vÃ o bá»™ test, cÃ²n láº¡i sáº½ cho vÃ o bá»™ training.
Váº­y hai cÃ¡ch cá»§a mÃ¬nh cÃ³ há»£p lÃ½ khÃ´ng?
3. Báº¡n nÃ o biáº¿t vá» cÃ¡ch phÃ¢n chia dá»¯ liá»‡u thÃ¬ chia sáº» vá»›i mÃ¬nh báº±ng cÃ¡ch bÃ¬nh luáº­n táº¡i bÃ i viáº¿t nÃ y, Ä‘áº·c biá»‡t lÃ  mÃ¬nh cáº§n pháº§n code Python cá»¥ thá»ƒ Ä‘á»ƒ hiá»ƒu thÃªm ká»¹ thuáº­t nÃ y!
Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u!","Ká»¹ thuáº­t phÃ¢n chia dá»¯ liá»‡u cho ba nhÃ³m: training vÃ  test (thÃªm Validation) ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang cÃ³ má»™t bÃ i táº­p nhá» vá» phÃ¢n chia dá»¯ liá»‡u cho má»™t mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n trong báº£o hiá»ƒm. Dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n bá»‹ lÃ  má»™t pandas vá»›i nhiá»u biáº¿n khÃ¡c nhau. MÃ¬nh cáº§n chia dá»¯ liá»‡u thÃ nh ba bá»™ pháº­n nÃ³i trÃªn: training, validation vÃ  test. MÃ¬nh cÃ³ máº¥y cÃ¢u há»i cáº§n sá»± giÃºp Ä‘á»¡ cá»§a cÃ¡c báº¡n nhÆ° sau: 1, Chá»‰ cáº§n chia thÃ nh training vÃ  test hay nháº¥t thiáº¿t pháº£i cÃ³ pháº§n thá»© 3 lÃ  validation. Tá»‰ lá»‡ hay gáº·p nháº¥t giá»¯a cÃ¡c pháº§n lÃ  bao nhiÃªu? 2. Ban Ä‘áº§u mÃ¬nh Ä‘á»‹nh láº¥y ngáº«u nhiÃªn 80% cho training vÃ  20% cho test nhÆ°ng láº¡i sá»£ phÃ¢n bá»‘ dá»¯ liá»‡u khÃ´ng Ä‘á»u nÃªn mÃ¬nh thay Ä‘á»•i lÃ : Láº¥y index chia cho 5: náº¿u index chia háº¿t cho 5 thÃ¬ láº¥y vÃ o bá»™ test, cÃ²n láº¡i sáº½ cho vÃ o bá»™ training. Váº­y hai cÃ¡ch cá»§a mÃ¬nh cÃ³ há»£p lÃ½ khÃ´ng? 3. Báº¡n nÃ o biáº¿t vá» cÃ¡ch phÃ¢n chia dá»¯ liá»‡u thÃ¬ chia sáº» vá»›i mÃ¬nh báº±ng cÃ¡ch bÃ¬nh luáº­n táº¡i bÃ i viáº¿t nÃ y, Ä‘áº·c biá»‡t lÃ  mÃ¬nh cáº§n pháº§n code Python cá»¥ thá»ƒ Ä‘á»ƒ hiá»ƒu thÃªm ká»¹ thuáº­t nÃ y! Cáº£m Æ¡n cÃ¡c báº¡n nhiá»u!",,,,,
"CÃ³ anh chá»‹ nÃ o biáº¿t platform Ä‘áº±ng sau cá»§a dá»‹ch vá»¥ OCR trong trang nÃ y khÃ´ng https://www.zoho.com/creator/newhelp/forms/fields/ocr/
Em xin nháº­n chia sáº» kinh nghiá»‡m áº¡!",CÃ³ anh chá»‹ nÃ o biáº¿t platform Ä‘áº±ng sau cá»§a dá»‹ch vá»¥ OCR trong trang nÃ y khÃ´ng https://www.zoho.com/creator/newhelp/forms/fields/ocr/ Em xin nháº­n chia sáº» kinh nghiá»‡m áº¡!,,,,,
"ChÃ o má»i ngÆ°á»i.
Cho mÃ¬nh há»i má»™t chÃºt vá» PySpark vÃ  Keras áº¡. CÃ³ cÃ¡ch nÃ o há»£p lÃ½ vÃ  Ä‘Ãºng logic káº¿t há»£p PySpark pandas_udf vá»›i model Keras Ä‘á»ƒ sá»­ dá»¥ng cho PySpark readStream() khÃ´ng áº¡?",ChÃ o má»i ngÆ°á»i. Cho mÃ¬nh há»i má»™t chÃºt vá» PySpark vÃ  Keras áº¡. CÃ³ cÃ¡ch nÃ o há»£p lÃ½ vÃ  Ä‘Ãºng logic káº¿t há»£p PySpark pandas_udf vá»›i model Keras Ä‘á»ƒ sá»­ dá»¥ng cho PySpark readStream() khÃ´ng áº¡?,,,,,
"em Ä‘ang há»p vá»›i ngÆ°á»i nháº­t vÃ  ngÆ°á»i áº¥n Ä‘á»™ khÃ¡ nhiá»u. em Ä‘ang tÃ¬m má»™t tool Ä‘á»ƒ nháº­n diá»‡n giá»ng nÃ³i cá»§a má»i ngÆ°á»i Ä‘á»ƒ dá»… dÃ ng nghe Ä‘Æ°á»£c hÆ¡n. YÃªu cáº§u thÃ¬ cáº§n realtime, khÃ´ng quÃ¡ cháº­m Ä‘á» dÃ¹ng lÃºc há»p máº·t luÃ´n áº¡.
Liá»‡u giá» há»c mÃ¡y Ä‘Ã£ cÃ³ sáº£n pháº©m nÃ o há»— trá»£ Ä‘Æ°á»£c tá»‘c Ä‘á»™ vÃ  vá»«a tÃºi tiá»n khÃ´ng áº¡. ( em nghÄ© chi phÃ­ má»™t thÃ¡ng em bá» ra Ä‘Æ°á»£c cháº¯c sáº½ lÃ  khoáº£ng max 3 triá»‡u thui áº¡ ).
P/S em ko thuÃª lÃ m tÃ¹e Ä‘aÃ¹a mÃ  Ä‘ang tÃ¬m má»™t product nÃ o sáºµn há» bÃ¡n cho nhiá»u user. MÃ  hiá»‡n táº¡i em tÃ¬m product nhÆ° tháº¿ mÃ  khÃ´ng tháº¥y nÃªn nghÄ© má»i ngÆ°á»i lÃ m nÃªn sáº½ biáº¿t cÃ¡c sáº£n pháº©m ná»•i tiáº¿ng áº¡. 3 Triá»‡u lÃ  tiá»n mua license thui áº¡.","em Ä‘ang há»p vá»›i ngÆ°á»i nháº­t vÃ  ngÆ°á»i áº¥n Ä‘á»™ khÃ¡ nhiá»u. em Ä‘ang tÃ¬m má»™t tool Ä‘á»ƒ nháº­n diá»‡n giá»ng nÃ³i cá»§a má»i ngÆ°á»i Ä‘á»ƒ dá»… dÃ ng nghe Ä‘Æ°á»£c hÆ¡n. YÃªu cáº§u thÃ¬ cáº§n realtime, khÃ´ng quÃ¡ cháº­m Ä‘á» dÃ¹ng lÃºc há»p máº·t luÃ´n áº¡. Liá»‡u giá» há»c mÃ¡y Ä‘Ã£ cÃ³ sáº£n pháº©m nÃ o há»— trá»£ Ä‘Æ°á»£c tá»‘c Ä‘á»™ vÃ  vá»«a tÃºi tiá»n khÃ´ng áº¡. ( em nghÄ© chi phÃ­ má»™t thÃ¡ng em bá» ra Ä‘Æ°á»£c cháº¯c sáº½ lÃ  khoáº£ng max 3 triá»‡u thui áº¡ ). P/S em ko thuÃª lÃ m tÃ¹e Ä‘aÃ¹a mÃ  Ä‘ang tÃ¬m má»™t product nÃ o sáºµn há» bÃ¡n cho nhiá»u user. MÃ  hiá»‡n táº¡i em tÃ¬m product nhÆ° tháº¿ mÃ  khÃ´ng tháº¥y nÃªn nghÄ© má»i ngÆ°á»i lÃ m nÃªn sáº½ biáº¿t cÃ¡c sáº£n pháº©m ná»•i tiáº¿ng áº¡. 3 Triá»‡u lÃ  tiá»n mua license thui áº¡.",,,,,
"ChÃ o má»i ngÆ°á»i!
MÃ¬nh Ä‘ang muá»‘n dÃ¹ng google_image_download Ä‘á»ƒ táº¡o database training yolo. NhÆ°ng khi cháº¡y chÆ°Æ¡ng trÃ¬nh thÃ¬ gáº·p lá»—i nÃ y.
Má»i ngÆ°á»i chá»‰ mÃ¬nh cÃ¡ch khÃ¡c phá»¥ vá»›i áº¡. Hay cÃ³ phÆ°Æ¡ng phÃ¡p khÃ¡c cÅ©ng Ä‘Æ°á»£c
MÃ¬nh cáº£m Æ¡n",ChÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang muá»‘n dÃ¹ng google_image_download Ä‘á»ƒ táº¡o database training yolo. NhÆ°ng khi cháº¡y chÆ°Æ¡ng trÃ¬nh thÃ¬ gáº·p lá»—i nÃ y. Má»i ngÆ°á»i chá»‰ mÃ¬nh cÃ¡ch khÃ¡c phá»¥ vá»›i áº¡. Hay cÃ³ phÆ°Æ¡ng phÃ¡p khÃ¡c cÅ©ng Ä‘Æ°á»£c MÃ¬nh cáº£m Æ¡n,,,,,
"ChÃ o anh chá»‹, em Ä‘ang cÃ³ má»™t bÃ i táº­p vá» two-way ANOVA vÃ  Tukey HSD trÃªn Python, em cÃ³ 2 cÃ¢u há»i:
CÃ¢u 1: táº­p dá»¯ liá»‡u cá»§a em gá»“m 3 thuá»™c tÃ­nh lÃ  Pclass (loáº¡i vÃ© mÃ  hÃ nh khÃ¡ch sá»­ dá»¥ng, nhÆ° lÃ  thÆ°Æ¡ng gia, bÃ¬nh thÆ°á»ng,... Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh sá»‘), Sex (giá»›i tÃ­nh gá»“m male vÃ  female), cuá»‘i cÃ¹ng lÃ  Fare (sá»‘ tiá»n bá» ra mua vÃ© cá»§a má»™t ngÆ°á»i). Em Ä‘Ã£ lÃ m xong two-way ANOVA rá»“i, má»i ngÆ°á»i cho em há»i H0 cá»§a em lÃºc nÃ y cÃ³ pháº£i lÃ  3 thuá»™c tÃ­nh Pclass, Sex, Fare lÃ  Ä‘á»™c láº­p khÃ´ng áº¡.
CÃ¢u 2: em tiáº¿n hÃ nh phÃ¢n tÃ­ch Tukey HSD vÃ  thu Ä‘Æ°á»£c báº£n dÆ°á»›i Ä‘Ã¢y, thÃ¬ em cÃ³ Ä‘á»c tÃ i liá»‡u thÃ¬ Ä‘Æ°á»£c biáº¿t lÃ  náº¿u reject = False thÃ¬ mÃ¬nh sáº½ bÃ¡c bá» H0, nhÆ°ng H0 lÃºc nÃ y lÃ  H0 á»Ÿ cÃ¢u 1 hay lÃ  má»™t phÃ¡t biá»ƒu khÃ¡c áº¡, em cáº£m Æ¡n.","ChÃ o anh chá»‹, em Ä‘ang cÃ³ má»™t bÃ i táº­p vá» two-way ANOVA vÃ  Tukey HSD trÃªn Python, em cÃ³ 2 cÃ¢u há»i: CÃ¢u 1: táº­p dá»¯ liá»‡u cá»§a em gá»“m 3 thuá»™c tÃ­nh lÃ  Pclass (loáº¡i vÃ© mÃ  hÃ nh khÃ¡ch sá»­ dá»¥ng, nhÆ° lÃ  thÆ°Æ¡ng gia, bÃ¬nh thÆ°á»ng,... Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh sá»‘), Sex (giá»›i tÃ­nh gá»“m male vÃ  female), cuá»‘i cÃ¹ng lÃ  Fare (sá»‘ tiá»n bá» ra mua vÃ© cá»§a má»™t ngÆ°á»i). Em Ä‘Ã£ lÃ m xong two-way ANOVA rá»“i, má»i ngÆ°á»i cho em há»i H0 cá»§a em lÃºc nÃ y cÃ³ pháº£i lÃ  3 thuá»™c tÃ­nh Pclass, Sex, Fare lÃ  Ä‘á»™c láº­p khÃ´ng áº¡. CÃ¢u 2: em tiáº¿n hÃ nh phÃ¢n tÃ­ch Tukey HSD vÃ  thu Ä‘Æ°á»£c báº£n dÆ°á»›i Ä‘Ã¢y, thÃ¬ em cÃ³ Ä‘á»c tÃ i liá»‡u thÃ¬ Ä‘Æ°á»£c biáº¿t lÃ  náº¿u reject = False thÃ¬ mÃ¬nh sáº½ bÃ¡c bá» H0, nhÆ°ng H0 lÃºc nÃ y lÃ  H0 á»Ÿ cÃ¢u 1 hay lÃ  má»™t phÃ¡t biá»ƒu khÃ¡c áº¡, em cáº£m Æ¡n.",,,,,
"ChÃ o má»i ngÆ°á»i. Mong tÃ¬m Ä‘Æ°á»£c cao nhÃ¢n nÃ o giÃºp em vá»¥ nÃ y! Em Ä‘g cá»‘ convert h5 model qua Ä‘uÃ´i mlmodel báº±ng coremltools nhÆ°ng gáº·p lá»—i: Keras layerâ€™<class â€™tensorflow.python.keras.layers.convolutional.Conv2Dâ€™>â€™ not supported. MÃ² máº«m google mÃ£i cÅ©ng khÃ´ng biáº¿t lÃ m sao sá»­a. Btw em Ä‘ang dÃ¹ng python 3.7, coremltools 4.0, tensorflow 2.3.1 vÃ  keras 2.2.4; cÃ²n model nÃ y lÃ  nháº­n diá»‡n vÃ  phÃ¢n loáº¡i biá»ƒn bÃ¡o giao thÃ´ng. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡!","ChÃ o má»i ngÆ°á»i. Mong tÃ¬m Ä‘Æ°á»£c cao nhÃ¢n nÃ o giÃºp em vá»¥ nÃ y! Em Ä‘g cá»‘ convert h5 model qua Ä‘uÃ´i mlmodel báº±ng coremltools nhÆ°ng gáº·p lá»—i: Keras layerâ€™<class â€™tensorflow.python.keras.layers.convolutional.Conv2Dâ€™>â€™ not supported. MÃ² máº«m google mÃ£i cÅ©ng khÃ´ng biáº¿t lÃ m sao sá»­a. Btw em Ä‘ang dÃ¹ng python 3.7, coremltools 4.0, tensorflow 2.3.1 vÃ  keras 2.2.4; cÃ²n model nÃ y lÃ  nháº­n diá»‡n vÃ  phÃ¢n loáº¡i biá»ƒn bÃ¡o giao thÃ´ng. Mong má»i ngÆ°á»i giÃºp Ä‘á»¡!",,,,,
"ChÃ o má»i ngÆ°á»i !
Em Ä‘ang cÃ³ file áº£nh lÆ°u cÃ¡c áº£nh theo dáº¡ng train_i.png vá»›i i tá»« 0 -> 2000. Em muá»‘n má»Ÿ tá»«ng file theo thá»© tá»± tuy nhiÃªn nÃ³ láº¡i sáº¯p xáº¿p theo kiá»ƒu ráº¥t khÃ³ hiá»ƒu. Má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em cáº£m Æ¡n!",ChÃ o má»i ngÆ°á»i ! Em Ä‘ang cÃ³ file áº£nh lÆ°u cÃ¡c áº£nh theo dáº¡ng train_i.png vá»›i i tá»« 0 -> 2000. Em muá»‘n má»Ÿ tá»«ng file theo thá»© tá»± tuy nhiÃªn nÃ³ láº¡i sáº¯p xáº¿p theo kiá»ƒu ráº¥t khÃ³ hiá»ƒu. Má»i ngÆ°á»i giÃºp em vá»›i áº¡. Em cáº£m Æ¡n!,,,,,
"ChÃ o má»i ngÆ°á»i áº¡!
Do váº¥n Ä‘á» vá» memory GPU nÃªn em dÃ¹ng Ä‘áº·t model.fit trong vÃ²ng láº·p for, (3500 pháº§n tá»­ e chia thÃ nh 70 loops 50 pháº§n tá»­) nhÆ°ng cÃ³ váº» nhÆ° cÃ ng vá» loops sau thá»i gian train cÃ ng lÃ¢u, cÃ³ váº» lÃ  do RAM lÆ°u váº«n cÃ²n lÆ°u dá»¯ liá»‡u preprocess nÃªn bá»‹ trÃ n thÃ¬ pháº£i. Má»i ngÆ°á»i giÃºp em kháº¯c phá»¥c vá»›i áº¡! Em xin cáº£m Æ¡n áº¡!","ChÃ o má»i ngÆ°á»i áº¡! Do váº¥n Ä‘á» vá» memory GPU nÃªn em dÃ¹ng Ä‘áº·t model.fit trong vÃ²ng láº·p for, (3500 pháº§n tá»­ e chia thÃ nh 70 loops 50 pháº§n tá»­) nhÆ°ng cÃ³ váº» nhÆ° cÃ ng vá» loops sau thá»i gian train cÃ ng lÃ¢u, cÃ³ váº» lÃ  do RAM lÆ°u váº«n cÃ²n lÆ°u dá»¯ liá»‡u preprocess nÃªn bá»‹ trÃ n thÃ¬ pháº£i. Má»i ngÆ°á»i giÃºp em kháº¯c phá»¥c vá»›i áº¡! Em xin cáº£m Æ¡n áº¡!",,,,,
"Em convert darknet model sang file .pb gáº·p lá»—i nÃ y mong ae giáº£i Ä‘Ã¡p, em cáº£m Æ¡n áº¡ !","Em convert darknet model sang file .pb gáº·p lá»—i nÃ y mong ae giáº£i Ä‘Ã¡p, em cáº£m Æ¡n áº¡ !",,,,,
"cÃ¡c bÃ¡c Æ¡i cÃ³ khoÃ¡ há»c python, SQL online á»•n á»•n nÃ o cho beginner khÃ´ng áº¡? hoáº·c youtube cÅ©ng Ä‘Æ°á»£c, em Ä‘ang há»c á»Ÿ lá»›p mÃ  tháº§y dáº¡y sÆ°Æ¡ng sÆ°Æ¡ng thui k hiá»ƒu láº¯m áº¡ hic, pháº£i tá»± tÃ¬m hiá»ƒu lÃ  chÃ­nh.","cÃ¡c bÃ¡c Æ¡i cÃ³ khoÃ¡ há»c python, SQL online á»•n á»•n nÃ o cho beginner khÃ´ng áº¡? hoáº·c youtube cÅ©ng Ä‘Æ°á»£c, em Ä‘ang há»c á»Ÿ lá»›p mÃ  tháº§y dáº¡y sÆ°Æ¡ng sÆ°Æ¡ng thui k hiá»ƒu láº¯m áº¡ hic, pháº£i tá»± tÃ¬m hiá»ƒu lÃ  chÃ­nh.",,,,,
"chÃ o a Tiep, cÃ¡c a/c
cho mÃ¬nh há»i cÃ³ ai cÃ³ ebook machine learning cÆ¡ báº£n cÃ³ mÃ u cá»§a a Tiep ko áº¡, cho mÃ¬nh xin vá»›i, cÃ¡i báº£n mÃ¬nh kiáº¿m trÃªn forum lÃ  báº£n tráº¯ng Ä‘en, mÃ¬nh Ä‘áº·t mua sÃ¡ch nhÆ°ng hiá»‡n ko cÃ³ xuáº¥t báº£n ná»¯a! thanks m.n","chÃ o a Tiep, cÃ¡c a/c cho mÃ¬nh há»i cÃ³ ai cÃ³ ebook machine learning cÆ¡ báº£n cÃ³ mÃ u cá»§a a Tiep ko áº¡, cho mÃ¬nh xin vá»›i, cÃ¡i báº£n mÃ¬nh kiáº¿m trÃªn forum lÃ  báº£n tráº¯ng Ä‘en, mÃ¬nh Ä‘áº·t mua sÃ¡ch nhÆ°ng hiá»‡n ko cÃ³ xuáº¥t báº£n ná»¯a! thanks m.n",,,,,
"Hi má»i ngÆ°á»i,
Cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ flow ImageDataGenerator tá»« tfds áº¡? (Em biáº¿t cÃ¡ch lÃ m vá»›i local dataset báº±ng flow_from_directory nhÆ°ng cÃ²n data tá»« tensorflow thÃ¬ luÃ´n bá»‹ 'path should be string, bytes, os.PathLike, integer or None, not DatasetV1Adapter')
Em xin cáº£m Æ¡n ^^.","Hi má»i ngÆ°á»i, Cho em há»i lÃ m cÃ¡ch nÃ o Ä‘á»ƒ flow ImageDataGenerator tá»« tfds áº¡? (Em biáº¿t cÃ¡ch lÃ m vá»›i local dataset báº±ng flow_from_directory nhÆ°ng cÃ²n data tá»« tensorflow thÃ¬ luÃ´n bá»‹ 'path should be string, bytes, os.PathLike, integer or None, not DatasetV1Adapter') Em xin cáº£m Æ¡n ^^.",,,,,
CÃ³ tools nÃ y cÃ³ váº» hay cho anh em lÃ m vá» DNN.,CÃ³ tools nÃ y cÃ³ váº» hay cho anh em lÃ m vá» DNN.,,,,,
"cho em há»i xong váº¥n Ä‘á» nÃ y em sáº½ xÃ³a bÃ i ^^.
láº§n Ä‘áº§u tiÃªn em dÃ¹ng tá»›i cnn cá»§a Tensorflow nÃªn há»i khÃ´ng hiá»ƒu láº¯m vá» Checkpoint, theo nhÆ° em Ä‘á»c trÃªn máº¡ng thÃ¬ checkpoint cÃ³ kháº£ nÄƒng lÆ°u láº¡i sau má»—i láº§n káº¿t thÃºc Epoch, mÃ¬nh cÃ³ thá»ƒ dÃ¹ng ckpt Ä‘á»ƒ tÃ­nh Accuracy gáº§n nháº¥t mÃ  ckpt Ä‘Ã³ lÆ°u Ä‘Æ°á»£c, nhÆ°ng mÃ  em khÃ´ng biáº¿t náº¿u Ä‘ang train trÃªn 50 epoch, mÃ¬nh lÆ°u Ä‘c 10 epoch Ä‘áº§u thÃ¬ cÃ³ cÃ¡ch nÃ o load cÃ¡i checkpoint Ä‘Ã³ Ä‘á»ƒ cháº¡y tiáº¿p 40 epoch sau khÃ´ng áº¡.
em cáº£m Æ¡n. ^^","cho em há»i xong váº¥n Ä‘á» nÃ y em sáº½ xÃ³a bÃ i ^^. láº§n Ä‘áº§u tiÃªn em dÃ¹ng tá»›i cnn cá»§a Tensorflow nÃªn há»i khÃ´ng hiá»ƒu láº¯m vá» Checkpoint, theo nhÆ° em Ä‘á»c trÃªn máº¡ng thÃ¬ checkpoint cÃ³ kháº£ nÄƒng lÆ°u láº¡i sau má»—i láº§n káº¿t thÃºc Epoch, mÃ¬nh cÃ³ thá»ƒ dÃ¹ng ckpt Ä‘á»ƒ tÃ­nh Accuracy gáº§n nháº¥t mÃ  ckpt Ä‘Ã³ lÆ°u Ä‘Æ°á»£c, nhÆ°ng mÃ  em khÃ´ng biáº¿t náº¿u Ä‘ang train trÃªn 50 epoch, mÃ¬nh lÆ°u Ä‘c 10 epoch Ä‘áº§u thÃ¬ cÃ³ cÃ¡ch nÃ o load cÃ¡i checkpoint Ä‘Ã³ Ä‘á»ƒ cháº¡y tiáº¿p 40 epoch sau khÃ´ng áº¡. em cáº£m Æ¡n. ^^",,,,,
"CÃ³ thá»ƒ cho mÃ¬nh má»™t vÃ­ dá»¥ nhá» vá»›i source code sá»± khÃ¡c nhau giá»¯a deep learning vÃ  machine learning khÃ´ng? Hiá»‡n táº¡i mÃ¬nh chÆ°a phÃ¢n biá»‡t Ä‘Æ°á»£c chÃºng, Ä‘á»c lÃ½ thuyáº¿t mÃ¬nh cÅ©ng khÃ´ng thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c. Source code vá»›i nhá»¯ng bÃ i thá»±c hÃ nh nhá» cÃ³ láº½ mÃ¬nh sáº½ hiá»ƒu Ä‘Æ°á»£c nÃ³ dá»… dÃ ng hÆ¡n. MÃ¬nh xin cáº£m Æ¡n.","CÃ³ thá»ƒ cho mÃ¬nh má»™t vÃ­ dá»¥ nhá» vá»›i source code sá»± khÃ¡c nhau giá»¯a deep learning vÃ  machine learning khÃ´ng? Hiá»‡n táº¡i mÃ¬nh chÆ°a phÃ¢n biá»‡t Ä‘Æ°á»£c chÃºng, Ä‘á»c lÃ½ thuyáº¿t mÃ¬nh cÅ©ng khÃ´ng thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c. Source code vá»›i nhá»¯ng bÃ i thá»±c hÃ nh nhá» cÃ³ láº½ mÃ¬nh sáº½ hiá»ƒu Ä‘Æ°á»£c nÃ³ dá»… dÃ ng hÆ¡n. MÃ¬nh xin cáº£m Æ¡n.",,,,,
"Xin phÃ©p ad má»™t Ã­t tÃ i nguyÃªn cá»§a nhÃ³m. Cáº£m Æ¡n
Xin chÃ o cÃ¡c báº¡n. Hiá»‡n táº¡i mÃ¬nh Ä‘ang xÃ¢y dá»±ng dá»± Ã¡n. Tra cá»©u bÃ¡c sÄ©. ÄÃ£ cÃ³ demo á»Ÿ Ä‘Ã¢y: http://huhivn90.pythonanywhere.com/
Ã tÆ°á»Ÿng lÃ  1 Dá»± Ã¡n nÃ y miá»…n phÃ­ hoÃ n toÃ n Ä‘á»ƒ cÃ¡c bá»‡nh viá»‡n hoáº·c phÃ²ng khÃ¡m nhá» cÃ³ thá»ƒ triá»ƒn khai vá»›i chi phÃ­ tá»‘i thiá»ƒu. NÃ´m na nÃ³ nhÆ° má»™t máº¡ng xÃ£ há»™i mini cho bÃ¡c sÄ© vÃ  bá»‡nh nhÃ¢n. CÃ³ tÃ­nh nÄƒng book lá»‹ch khÃ¡m vÃ  Ä‘Ã¡nh giÃ¡, há»i Ä‘Ã¡p.
Hiá»‡n á»©ng dá»¥ng Ä‘Ã£ bÃ¡o cÃ¡o táº¡i há»™i tháº£o á»©ng dá»¥ng cntt vá» y táº¿ do cá»¥c cntt trao chá»©ng nháº­n. (Há»™i tháº£o cntt vá» y táº¿ táº¡i tp vinh ngÃ y 24/10, google xem thÃªm, mÃ¬nh k tiá»‡n dáº«n link)
Má»™t mÃ¬nh lÃ m hiá»‡n hÆ¡i Ä‘uá»‘i sá»©c vÃ¬ mÃ¬nh Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng tÃ­ch há»£p thÃªm tÃ­nh nÄƒng tá»± Ä‘á»™ng gÃ¡n nhÃ£n cho cÃ¡c bÃ¬nh luáº­n vÃ  cÃ¡c mÃ´ táº£ lÃºc Ä‘Äƒng kÃ½ khÃ¡m.
VÃ¬ tháº¿, báº¡n nÃ o cÃ³ chung Ã½ tÆ°á»Ÿng hoáº·c há»©ng thÃº vá»›i dá»± Ã¡n nÃ y muá»‘n cÃ¹ng xÃ¢y dá»±ng tá»« sáº£n pháº©m demo Ä‘áº¿n product. ThÃ¬ liÃªn há»‡ vá»›i mÃ¬nh nhÃ©. Cáº£m Æ¡n Ä‘Ã£ Ä‘á»c tin","Xin phÃ©p ad má»™t Ã­t tÃ i nguyÃªn cá»§a nhÃ³m. Cáº£m Æ¡n Xin chÃ o cÃ¡c báº¡n. Hiá»‡n táº¡i mÃ¬nh Ä‘ang xÃ¢y dá»±ng dá»± Ã¡n. Tra cá»©u bÃ¡c sÄ©. ÄÃ£ cÃ³ demo á»Ÿ Ä‘Ã¢y: http://huhivn90.pythonanywhere.com/ Ã tÆ°á»Ÿng lÃ  1 Dá»± Ã¡n nÃ y miá»…n phÃ­ hoÃ n toÃ n Ä‘á»ƒ cÃ¡c bá»‡nh viá»‡n hoáº·c phÃ²ng khÃ¡m nhá» cÃ³ thá»ƒ triá»ƒn khai vá»›i chi phÃ­ tá»‘i thiá»ƒu. NÃ´m na nÃ³ nhÆ° má»™t máº¡ng xÃ£ há»™i mini cho bÃ¡c sÄ© vÃ  bá»‡nh nhÃ¢n. CÃ³ tÃ­nh nÄƒng book lá»‹ch khÃ¡m vÃ  Ä‘Ã¡nh giÃ¡, há»i Ä‘Ã¡p. Hiá»‡n á»©ng dá»¥ng Ä‘Ã£ bÃ¡o cÃ¡o táº¡i há»™i tháº£o á»©ng dá»¥ng cntt vá» y táº¿ do cá»¥c cntt trao chá»©ng nháº­n. (Há»™i tháº£o cntt vá» y táº¿ táº¡i tp vinh ngÃ y 24/10, google xem thÃªm, mÃ¬nh k tiá»‡n dáº«n link) Má»™t mÃ¬nh lÃ m hiá»‡n hÆ¡i Ä‘uá»‘i sá»©c vÃ¬ mÃ¬nh Ä‘ang cÃ³ Ã½ tÆ°á»Ÿng tÃ­ch há»£p thÃªm tÃ­nh nÄƒng tá»± Ä‘á»™ng gÃ¡n nhÃ£n cho cÃ¡c bÃ¬nh luáº­n vÃ  cÃ¡c mÃ´ táº£ lÃºc Ä‘Äƒng kÃ½ khÃ¡m. VÃ¬ tháº¿, báº¡n nÃ o cÃ³ chung Ã½ tÆ°á»Ÿng hoáº·c há»©ng thÃº vá»›i dá»± Ã¡n nÃ y muá»‘n cÃ¹ng xÃ¢y dá»±ng tá»« sáº£n pháº©m demo Ä‘áº¿n product. ThÃ¬ liÃªn há»‡ vá»›i mÃ¬nh nhÃ©. Cáº£m Æ¡n Ä‘Ã£ Ä‘á»c tin",,,,,
ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em cáº§n down má»™t lÆ°á»£ng lá»›n video tá»« youtube cá»¥ thá»ƒ lÃ  táº­p dataset MS ASL. Em cÃ³ dÃ¹ng script Python download nhÆ°ng chá»‰ download Ä‘Æ°á»£c vÃ i video thÃ¬ nÃ³ bÃ¡o quÃ¡ nhiá»u request. Mn cÃ³ giáº£i phÃ¡p gÃ¬ khÃ´ng áº¡. Em cáº£m Æ¡n áº¡.,ChÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em cáº§n down má»™t lÆ°á»£ng lá»›n video tá»« youtube cá»¥ thá»ƒ lÃ  táº­p dataset MS ASL. Em cÃ³ dÃ¹ng script Python download nhÆ°ng chá»‰ download Ä‘Æ°á»£c vÃ i video thÃ¬ nÃ³ bÃ¡o quÃ¡ nhiá»u request. Mn cÃ³ giáº£i phÃ¡p gÃ¬ khÃ´ng áº¡. Em cáº£m Æ¡n áº¡.,,,,,
"Xin chÃ o má»i ngÆ°á»i, khi mÃ¬nh dÃ¹ng lá»‡nh pip install fastBPE thÃ¬ bá»‹ lá»—i ntn , mÃ¬nh cÃ³ táº£i buildtools rá»“i mÃ  váº«n lá»—i nhÆ° kÃ¬a, mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ :((","Xin chÃ o má»i ngÆ°á»i, khi mÃ¬nh dÃ¹ng lá»‡nh pip install fastBPE thÃ¬ bá»‹ lá»—i ntn , mÃ¬nh cÃ³ táº£i buildtools rá»“i mÃ  váº«n lá»—i nhÆ° kÃ¬a, mong má»i ngÆ°á»i giÃºp Ä‘á»¡ áº¡ :((",,,,,
Cho miÌ€nh hoÌ‰i sau khi tiÌ€m Ä‘Æ°Æ¡Ì£c mÃ´ hiÌ€nh dÆ°Ì£ Ä‘oaÌn ngoaÌ€i thay tÃ¢Ì£p test vaÌ€o Ä‘ÃªÌ‰ so saÌnh thiÌ€ coÌ cÃ¢Ì€n phaÌ‰i laÌ€m thÃªm bÆ°Æ¡Ìc naÌ€o Ä‘ÃªÌ‰ kiÃªÌ‰m tra mÃ´ hiÌ€nh nÆ°Ìƒa khÃ´ng ?,Cho miÌ€nh hoÌ‰i sau khi tiÌ€m Ä‘Æ°Æ¡Ì£c mÃ´ hiÌ€nh dÆ°Ì£ Ä‘oaÌn ngoaÌ€i thay tÃ¢Ì£p test vaÌ€o Ä‘ÃªÌ‰ so saÌnh thiÌ€ coÌ cÃ¢Ì€n phaÌ‰i laÌ€m thÃªm bÆ°Æ¡Ìc naÌ€o Ä‘ÃªÌ‰ kiÃªÌ‰m tra mÃ´ hiÌ€nh nÆ°Ìƒa khÃ´ng ?,,,,,
"Lastly, the game in vision recognition tasks can be changed from CNN to Transformer!
Cuá»‘i cÃ¹ng cÅ©ng nhÆ° mong Ä‘á»£i lÃ  bÃ i bÃ¡o Vision Transformer (AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE) Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ source code. VÃ  cÅ©ng khÃ´ng ngoÃ i dá»± Ä‘oÃ¡n cá»§a mÃ¬nh ráº±ng bÃ i bÃ¡o do nhÃ³m nghiÃªn cá»©u cá»§a Google.
ÄÃ¢y lÃ  bÃ i bÃ¡o: https://openreview.net/pdf?id=YicbFdNTTy
Hay á»Ÿ trÃªn Arxiv https://arxiv.org/pdf/2010.11929.pdf
ÄÃ¢y lÃ  code Ä‘Æ°á»£c Ross Wightman port sang PyTorch: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py
ÄÃ¢y lÃ  source code cá»§a bÃ i bÃ¡o Ä‘Æ°á»£c viáº¿t báº±ng jax thay vÃ¬ TF trÃªn Python https://github.com/google-research/vision_transformer
ChÃºc cáº£ nhÃ  cuá»‘i tuáº§n vui váº»!","Lastly, the game in vision recognition tasks can be changed from CNN to Transformer! Cuá»‘i cÃ¹ng cÅ©ng nhÆ° mong Ä‘á»£i lÃ  bÃ i bÃ¡o Vision Transformer (AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE) Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ source code. VÃ  cÅ©ng khÃ´ng ngoÃ i dá»± Ä‘oÃ¡n cá»§a mÃ¬nh ráº±ng bÃ i bÃ¡o do nhÃ³m nghiÃªn cá»©u cá»§a Google. ÄÃ¢y lÃ  bÃ i bÃ¡o: https://openreview.net/pdf?id=YicbFdNTTy Hay á»Ÿ trÃªn Arxiv https://arxiv.org/pdf/2010.11929.pdf ÄÃ¢y lÃ  code Ä‘Æ°á»£c Ross Wightman port sang PyTorch: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py ÄÃ¢y lÃ  source code cá»§a bÃ i bÃ¡o Ä‘Æ°á»£c viáº¿t báº±ng jax thay vÃ¬ TF trÃªn Python https://github.com/google-research/vision_transformer ChÃºc cáº£ nhÃ  cuá»‘i tuáº§n vui váº»!",,,,,
"KÃ­nh gá»­i Ä‘áº¿n cáº£ nhÃ  clip chia sáº» vá» ğŸš©[Má»³ Python] BÃ i 4. Python vá»›i Keras (Pháº§n 1)
âœï¸Link video: https://www.youtube.com/watch?v=hPhnqTtidnA
âœï¸Link playlist full bá»™: https://www.youtube.com/watch?v=TY43q0w1Eh0&list=PLZPCoTKpEddAay-lItE-pn27uNNrApORH
Pháº§n nÃ y hi vá»ng sáº½ mang Ä‘áº¿n cho cÃ¡c báº¡n má»›i há»c cÃ¡i nhÃ¬n cÆ¡ báº£n vá» Python, Keras, vá» cÃ¡ch xÃ¢y dá»±ng má»™t máº¡ng NN cÆ¡ báº£n báº±ng Keras, cÃ¡ch chia dá»¯ liá»‡u train, test, validation...
Mong cÃ¡c cao thá»§ chá»‰ giÃ¡o vÃ  mong ad duyá»‡t bÃ i!","KÃ­nh gá»­i Ä‘áº¿n cáº£ nhÃ  clip chia sáº» vá» [Má»³ Python] BÃ i 4. Python vá»›i Keras (Pháº§n 1) Link video: https://www.youtube.com/watch?v=hPhnqTtidnA Link playlist full bá»™: https://www.youtube.com/watch?v=TY43q0w1Eh0&list=PLZPCoTKpEddAay-lItE-pn27uNNrApORH Pháº§n nÃ y hi vá»ng sáº½ mang Ä‘áº¿n cho cÃ¡c báº¡n má»›i há»c cÃ¡i nhÃ¬n cÆ¡ báº£n vá» Python, Keras, vá» cÃ¡ch xÃ¢y dá»±ng má»™t máº¡ng NN cÆ¡ báº£n báº±ng Keras, cÃ¡ch chia dá»¯ liá»‡u train, test, validation... Mong cÃ¡c cao thá»§ chá»‰ giÃ¡o vÃ  mong ad duyá»‡t bÃ i!",,,,,
"[PaddleOCR]
Há»‡ thá»‘ng Nháº­n dáº¡ng chá»¯ viáº¿t (OCR) Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong thá»±c táº¿ nhÆ° nháº­n dáº¡ng chá»©ng minh thÆ°, báº±ng lÃ¡i xe. Tuy nhiÃªn, OCR váº«n lÃ  má»™t nhiá»‡m vá»¥ Ä‘áº§y thÃ¡ch thá»©c vá» cáº£ Ä‘á»™ chÃ­nh xÃ¡c vÃ  tá»‘c Ä‘á»™ tÃ­nh toÃ¡n. Do Ä‘Ã³, PaddleOCR ra Ä‘á»i há»— trá»£ nháº­n dáº¡ng tiáº¿ng Trung, tiáº¿ng Anh, chá»¯ sá»‘ vÃ  nháº­n dáº¡ng cÃ¡c vÄƒn báº£n dÃ i. NgoÃ i ra, PaddleOCR cÃ²n há»— trá»£ nháº­n dáº¡ng nhiá»u ngÃ´n ngá»¯: HÃ n Quá»‘c, Nháº­t Báº£n, Äá»©c, PhÃ¡p. Äáº·c biá»‡t lÃ  PaddleOCR ráº¥t nháº¹ do sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh.
Paper: https://arxiv.org/abs/2009.09941
Github: https://github.com/PaddlePaddle/PaddleOCR","[PaddleOCR] Há»‡ thá»‘ng Nháº­n dáº¡ng chá»¯ viáº¿t (OCR) Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong thá»±c táº¿ nhÆ° nháº­n dáº¡ng chá»©ng minh thÆ°, báº±ng lÃ¡i xe. Tuy nhiÃªn, OCR váº«n lÃ  má»™t nhiá»‡m vá»¥ Ä‘áº§y thÃ¡ch thá»©c vá» cáº£ Ä‘á»™ chÃ­nh xÃ¡c vÃ  tá»‘c Ä‘á»™ tÃ­nh toÃ¡n. Do Ä‘Ã³, PaddleOCR ra Ä‘á»i há»— trá»£ nháº­n dáº¡ng tiáº¿ng Trung, tiáº¿ng Anh, chá»¯ sá»‘ vÃ  nháº­n dáº¡ng cÃ¡c vÄƒn báº£n dÃ i. NgoÃ i ra, PaddleOCR cÃ²n há»— trá»£ nháº­n dáº¡ng nhiá»u ngÃ´n ngá»¯: HÃ n Quá»‘c, Nháº­t Báº£n, Äá»©c, PhÃ¡p. Äáº·c biá»‡t lÃ  PaddleOCR ráº¥t nháº¹ do sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh. Paper: https://arxiv.org/abs/2009.09941 Github: https://github.com/PaddlePaddle/PaddleOCR",,,,,
Em Ä‘Ã£ convert .py to .exe thÃ nh cÃ´ng. NhÆ°ng khi cháº¡y file exe thÃ¬ bá»‹ lá»—i nhÆ° nÃ y áº¡. Ai gáº·p lá»—i tÆ°Æ¡ng tá»± rá»“i giÃºp em vá»›i áº¡. Em xin cáº£m Æ¡n áº¡,Em Ä‘Ã£ convert .py to .exe thÃ nh cÃ´ng. NhÆ°ng khi cháº¡y file exe thÃ¬ bá»‹ lá»—i nhÆ° nÃ y áº¡. Ai gáº·p lá»—i tÆ°Æ¡ng tá»± rá»“i giÃºp em vá»›i áº¡. Em xin cáº£m Æ¡n áº¡,,,,,
Má»i ngÆ°á»i giÃºp em cÃ¢u 3 vá»›i áº¡,Má»i ngÆ°á»i giÃºp em cÃ¢u 3 vá»›i áº¡,,,,,
Mn Æ¡i cho em há»i cÃ³ APIs nÃ o tá»± summarize paragraph tiáº¿ng viá»‡t ko áº¡. Em cáº£m Æ¡n áº¡,Mn Æ¡i cho em há»i cÃ³ APIs nÃ o tá»± summarize paragraph tiáº¿ng viá»‡t ko áº¡. Em cáº£m Æ¡n áº¡,,,,,
"[AI News - Multilingual Machine Translation]
Pháº§n lá»›n cÃ¡c mÃ´ hÃ¬nh dá»‹ch mÃ¡y giá»¯a hai ngÃ´n ngá»¯ báº¥t ká»³ hiá»‡n nay Ä‘á»u dá»±a vÃ o ngÃ´n ngá»¯ trung gian lÃ  tiáº¿ng Anh. Tuy nhiÃªn, viá»‡c dá»‹ch qua ngÃ´n ngá»¯ trung gian máº¥t nhiá»u thá»i gian, giáº£m Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ã½ nghÄ©a cÅ©ng sáº½ khÃ³ Ä‘Æ°á»£c lÆ°u giá»¯ trá»n váº¹n.
Gáº§n Ä‘Ã¢y, Facebook AI Ä‘Ã£ phÃ¡t triá»ƒn mÃ´ hÃ¬nh dá»‹ch mÃ¡y Ä‘a ngÃ´n ngá»¯, cÃ³ thá»ƒ dá»‹ch giá»¯a cÃ¡c ngÃ´n ngá»¯ khÃ´ng cáº§n thÃ´ng qua tiáº¿ng Anh. MÃ´ hÃ¬nh M2M-100 nÃ y lÃ  mÃ´ hÃ¬nh Ä‘áº§u tiÃªn cÃ³ thá»ƒ dá»‹ch trá»±c tiáº¿p báº¥t ká»³ cáº·p nÃ o giá»¯a 100 ngÃ´n ngá»¯ khÃ¡c nhau, Ä‘áº¡t Ä‘Æ°á»£c hÆ¡n 10 Ä‘iá»ƒm BLEU (Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ song ngá»¯) tá»‘t hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh thÃ´ng qua tiáº¿ng anh hiá»‡n táº¡i. MÃ´ hÃ¬nh Ä‘ang tiáº¿p tá»¥c Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»ƒ cÃ³ thá»ƒ á»©ng dá»¥ng vÃ o trÃ¬nh dá»‹ch trÃªn Facebook.
Paper: https://ai.facebook.com/research/publications/Beyond-English-Centric-Multilingual-Machine-Translation/
Github: https://github.com/pytorch/fairseq/tree/master/examples/m2m_100","[AI News - Multilingual Machine Translation] Pháº§n lá»›n cÃ¡c mÃ´ hÃ¬nh dá»‹ch mÃ¡y giá»¯a hai ngÃ´n ngá»¯ báº¥t ká»³ hiá»‡n nay Ä‘á»u dá»±a vÃ o ngÃ´n ngá»¯ trung gian lÃ  tiáº¿ng Anh. Tuy nhiÃªn, viá»‡c dá»‹ch qua ngÃ´n ngá»¯ trung gian máº¥t nhiá»u thá»i gian, giáº£m Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ã½ nghÄ©a cÅ©ng sáº½ khÃ³ Ä‘Æ°á»£c lÆ°u giá»¯ trá»n váº¹n. Gáº§n Ä‘Ã¢y, Facebook AI Ä‘Ã£ phÃ¡t triá»ƒn mÃ´ hÃ¬nh dá»‹ch mÃ¡y Ä‘a ngÃ´n ngá»¯, cÃ³ thá»ƒ dá»‹ch giá»¯a cÃ¡c ngÃ´n ngá»¯ khÃ´ng cáº§n thÃ´ng qua tiáº¿ng Anh. MÃ´ hÃ¬nh M2M-100 nÃ y lÃ  mÃ´ hÃ¬nh Ä‘áº§u tiÃªn cÃ³ thá»ƒ dá»‹ch trá»±c tiáº¿p báº¥t ká»³ cáº·p nÃ o giá»¯a 100 ngÃ´n ngá»¯ khÃ¡c nhau, Ä‘áº¡t Ä‘Æ°á»£c hÆ¡n 10 Ä‘iá»ƒm BLEU (Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ song ngá»¯) tá»‘t hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh thÃ´ng qua tiáº¿ng anh hiá»‡n táº¡i. MÃ´ hÃ¬nh Ä‘ang tiáº¿p tá»¥c Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»ƒ cÃ³ thá»ƒ á»©ng dá»¥ng vÃ o trÃ¬nh dá»‹ch trÃªn Facebook. Paper: https://ai.facebook.com/research/publications/Beyond-English-Centric-Multilingual-Machine-Translation/ Github: https://github.com/pytorch/fairseq/tree/master/examples/m2m_100",,,,,
"[MÃŒ AI #32] [Nháº­n diá»‡n biá»ƒn sá»‘ xe] ChÆ°Æ¡ng 5 â€“ Nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng WPOD vÃ  SVM
Link bÃ i viáº¿t: https://www.miai.vn/2019/12/05/nhan-dien-bien-so-xe-chuong-5-nhan-dien-bien-so-xe-bang-wpod-va-svm/?fbclid=IwAR3gpWwRFDeNL52f-iFNUpkobH2ODay5otSF5llnVJBQL7IukqnjgFlU-rA
(CÃ³ share full bá»™ dá»¯ liá»‡u kÃ½ tá»±, táº£i vá» xÃ i Ä‘Æ°á»£c ngay khÃ´ng pháº£i táº¡o dá»¯ liá»‡u)
Xin chÃ o cáº£ nhÃ , Táº¿t Ä‘áº¿n nÆ¡i rá»“i nÃªn báº­n kinh khá»§ng, tuáº§n vá»«a qua mÃ¬nh tá»‘i máº¯t tá»‘i mÅ©i thanh ra khÃ´ng thá»ƒ ra bÃ i ká»‹p thá»i mong cÃ¡c báº¡n thÃ´ng cáº£m nhÃ©. HÃ´m nay chÃºng ta sáº½ cÃ¹ng nhau Nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng WPOD vÃ  SVM nhÃ©!
HÃ´m trÆ°á»›c mÃ¬nh cÃ³ guide cÃ¡c báº¡n cÃ¡ch nháº­n diá»‡n biá»ƒn sá»‘ báº±ng WPOD vÃ  Tesseract OCR.CÃ¡ch Ä‘Ã³ thÃ¬ Ä‘Æ¡n giáº£n nhÆ°ng sáº½ bá»‹ phá»¥ thuá»™c vÃ o Tess nhiá»u, vÃ  nhiá»u báº¡n nÃ³i nÃ³ ""tÃ¹"". Do váº­y bÃ¢y giá» chÃºng ta sáº½ cÃ¹ng nhau tá»± lÃ m báº±ng OpenCV vÃ  dÃ¹ng SVM Ä‘á»ƒ nháº­n kÃ½ tá»± nhÃ©.
miaifull #MÃ¬AI 
Fanpage: http://facebook.com/miaiblog 
Group trao Ä‘á»•i, chia sáº»: https://facebook.com/groups/miaigroup 
Website: http://ainoodle.tech 
Youtube: http://bit.ly/miaiyoutube","[MÃŒ AI [Nháº­n diá»‡n biá»ƒn sá»‘ xe] ChÆ°Æ¡ng 5 â€“ Nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng WPOD vÃ  SVM Link bÃ i viáº¿t: https://www.miai.vn/2019/12/05/nhan-dien-bien-so-xe-chuong-5-nhan-dien-bien-so-xe-bang-wpod-va-svm/?fbclid=IwAR3gpWwRFDeNL52f-iFNUpkobH2ODay5otSF5llnVJBQL7IukqnjgFlU-rA (CÃ³ share full bá»™ dá»¯ liá»‡u kÃ½ tá»±, táº£i vá» xÃ i Ä‘Æ°á»£c ngay khÃ´ng pháº£i táº¡o dá»¯ liá»‡u) Xin chÃ o cáº£ nhÃ , Táº¿t Ä‘áº¿n nÆ¡i rá»“i nÃªn báº­n kinh khá»§ng, tuáº§n vá»«a qua mÃ¬nh tá»‘i máº¯t tá»‘i mÅ©i thanh ra khÃ´ng thá»ƒ ra bÃ i ká»‹p thá»i mong cÃ¡c báº¡n thÃ´ng cáº£m nhÃ©. HÃ´m nay chÃºng ta sáº½ cÃ¹ng nhau Nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng WPOD vÃ  SVM nhÃ©! HÃ´m trÆ°á»›c mÃ¬nh cÃ³ guide cÃ¡c báº¡n cÃ¡ch nháº­n diá»‡n biá»ƒn sá»‘ báº±ng WPOD vÃ  Tesseract OCR.CÃ¡ch Ä‘Ã³ thÃ¬ Ä‘Æ¡n giáº£n nhÆ°ng sáº½ bá»‹ phá»¥ thuá»™c vÃ o Tess nhiá»u, vÃ  nhiá»u báº¡n nÃ³i nÃ³ ""tÃ¹"". Do váº­y bÃ¢y giá» chÃºng ta sáº½ cÃ¹ng nhau tá»± lÃ m báº±ng OpenCV vÃ  dÃ¹ng SVM Ä‘á»ƒ nháº­n kÃ½ tá»± nhÃ©. miaifull Fanpage: http://facebook.com/miaiblog Group trao Ä‘á»•i, chia sáº»: https://facebook.com/groups/miaigroup Website: http://ainoodle.tech Youtube: http://bit.ly/miaiyoutube",#32]	#MÃ¬AI,,,,
"#retinaface
Hi anh em,
MÃ¬nh Ä‘ang sá»­ dá»¥ng retinaface Ä‘á»ƒ trÃ­ch xuáº¥t gÆ°Æ¡ng máº·t nhÆ°ng hiá»‡n cÃ³ má»™t váº¥n Ä‘á» lÃ  khi mÃ¬nh crop vÃ  lÆ°u gÆ°Æ¡ng máº·t xuá»‘ng folder thÃ¬ bá»‹ lá»—i nhÆ° tháº¿ nÃ y. Theo mÃ¬nh research trÃªn google thÃ¬ tháº¥y há» báº£o lÃ  check cÃ¡c shape trÆ°á»›c, lÃºc mÃ¬nh print cÃ¡c shape ra thÃ¬ tháº¥y shape váº«n cÃ³ gÃ­a trá»‹ Ä‘Æ°á»£c xuáº¥t ra.
Ae nÃ o Ä‘Ã£ gáº·p váº¥n Ä‘á» nÃ y cho mÃ¬nh xin cÃ¡ch fÄ©x vá»›i áº¡. MÃ¬nh cÃ¡m Æ¡n.","Hi anh em, MÃ¬nh Ä‘ang sá»­ dá»¥ng retinaface Ä‘á»ƒ trÃ­ch xuáº¥t gÆ°Æ¡ng máº·t nhÆ°ng hiá»‡n cÃ³ má»™t váº¥n Ä‘á» lÃ  khi mÃ¬nh crop vÃ  lÆ°u gÆ°Æ¡ng máº·t xuá»‘ng folder thÃ¬ bá»‹ lá»—i nhÆ° tháº¿ nÃ y. Theo mÃ¬nh research trÃªn google thÃ¬ tháº¥y há» báº£o lÃ  check cÃ¡c shape trÆ°á»›c, lÃºc mÃ¬nh print cÃ¡c shape ra thÃ¬ tháº¥y shape váº«n cÃ³ gÃ­a trá»‹ Ä‘Æ°á»£c xuáº¥t ra. Ae nÃ o Ä‘Ã£ gáº·p váº¥n Ä‘á» nÃ y cho mÃ¬nh xin cÃ¡ch fÄ©x vá»›i áº¡. MÃ¬nh cÃ¡m Æ¡n.",#retinaface,,,,
"HÃ´m trÆ°á»›c cÃ³ 1 sá»‘ báº¡n há»i nÃªn mÃ¬nh share source cho solution cá»§a mÃ¬nh trong cuá»™c thi ERC2019 https://erc2019.com/ (Audio Emotion Recognition).
https://github.com/suicao/Pytorch-Audio-Emotion-Recognition
ÄÃ¢y lÃ  cuá»™c thi phÃ¢n loáº¡i cáº£m xÃºc tuy nhiÃªn model nÃ y cÃ³ thá»ƒ dÃ¹ng cho audio classifcation nÃ³i chung, mÃ¬nh láº¥y láº¡i tá»« cuá»™c thi Freesound 2019 cá»§a Kaggle thÃ´i.
Má»™t sá»‘ key features:
Mixup + SpecAugment for data augmentation.
CNN for audio classification with customized pooling.
Cosine annealing learning scheduler.
Test time augmentation (TTA)
Enjoy.","HÃ´m trÆ°á»›c cÃ³ 1 sá»‘ báº¡n há»i nÃªn mÃ¬nh share source cho solution cá»§a mÃ¬nh trong cuá»™c thi ERC2019 https://erc2019.com/ (Audio Emotion Recognition). https://github.com/suicao/Pytorch-Audio-Emotion-Recognition ÄÃ¢y lÃ  cuá»™c thi phÃ¢n loáº¡i cáº£m xÃºc tuy nhiÃªn model nÃ y cÃ³ thá»ƒ dÃ¹ng cho audio classifcation nÃ³i chung, mÃ¬nh láº¥y láº¡i tá»« cuá»™c thi Freesound 2019 cá»§a Kaggle thÃ´i. Má»™t sá»‘ key features: Mixup + SpecAugment for data augmentation. CNN for audio classification with customized pooling. Cosine annealing learning scheduler. Test time augmentation (TTA) Enjoy.",,,,,
"http://szeliski.org/Book/
sÃ¡ch giÃ¡o khoa vá» computer vision cho ae nÃ o cáº§n (báº£n draft)",http://szeliski.org/Book/ sÃ¡ch giÃ¡o khoa vá» computer vision cho ae nÃ o cáº§n (báº£n draft),,,,,
"Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  GRU giáº£i quyáº¿t vanishing gradient nhÆ° tháº¿ nÃ o áº¡?
MÃ¬nh hiá»ƒu ráº±ng GRU cÃ³ thá»ƒ cháº¯t lá»c nhá»¯ng thÃ´ng tin cáº§n thiáº¿t vÃ  bá» nhá»¯ng thÃ´ng tin thá»«a tháº£i Ä‘á»ƒ mang nhá»¯ng htoong tin quan trá»ng Ä‘i Ä‘áº¿n nhá»¯ng layer xa hÆ¡n. NhÆ°ng váº«n chÆ°a thá»±c sá»± hiá»ƒu viá»‡c khi thÃ´ng tin qua cá»•ng update = 0, tá»©c giá»¯ nguyÃªn giÃ¡ trá»‹ trÆ°á»›c Ä‘Ã³ láº¡i cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» vanishing gradient.
MÃ¬nh cáº£m Æ¡n trÆ°á»›c.","Má»i ngÆ°á»i cho mÃ¬nh há»i lÃ  GRU giáº£i quyáº¿t vanishing gradient nhÆ° tháº¿ nÃ o áº¡? MÃ¬nh hiá»ƒu ráº±ng GRU cÃ³ thá»ƒ cháº¯t lá»c nhá»¯ng thÃ´ng tin cáº§n thiáº¿t vÃ  bá» nhá»¯ng thÃ´ng tin thá»«a tháº£i Ä‘á»ƒ mang nhá»¯ng htoong tin quan trá»ng Ä‘i Ä‘áº¿n nhá»¯ng layer xa hÆ¡n. NhÆ°ng váº«n chÆ°a thá»±c sá»± hiá»ƒu viá»‡c khi thÃ´ng tin qua cá»•ng update = 0, tá»©c giá»¯ nguyÃªn giÃ¡ trá»‹ trÆ°á»›c Ä‘Ã³ láº¡i cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» vanishing gradient. MÃ¬nh cáº£m Æ¡n trÆ°á»›c.",,,,,
"Hi má»i ngÆ°á»i, hiá»‡n táº¡i, em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n vá» table/document extraction cho tá» khai háº£i quan. Em muá»‘n extract má»—i cÃ¡i subtable ""Sá»‘ lÆ°á»£ng vÃ  mÃ´ táº£ chi tiáº¿t ná»™i dung bÆ°u pháº©m + Khá»‘i lÆ°á»£ng + GiÃ¡ trá»‹"" vÃ  subtable ""DÃ nh cho bÆ°u pháº©m lÃ  hÃ ng hoÃ¡. Náº¿u biáº¿t sá»‘ thuáº¿ HS"".
Em thá»­ dÃ¹ng Google Form Parser nhÆ°ng váº«n ko thÃ nh cÃ´ng nhÆ° mong muá»‘n. Hiá»‡n táº¡i, em nghÄ© vá» cÃ¡ch sá»­ dá»¥ng deep learning Ä‘á»ƒ locate bounding box Ä‘á»ƒ crop rá»“i dÃ¹ng Google vision Ä‘á»ƒ extract info. NhÆ°ng em muá»‘n nghe lá»i khuyÃªn tá»« cÃ¡c anh chá»‹ vá» cÃ¡ch approach bÃ i toÃ¡n nÃ y vÃ¬ em ko biáº¿t cÃ¡ch lÃ m cá»§a hiá»‡n táº¡i cÃ³ pháº£i lÃ  most efficient khÃ´ng. Em cáº£m Æ¡n nhiá»u áº¡ vÃ  mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn tá»« má»i ngÆ°á»i.","Hi má»i ngÆ°á»i, hiá»‡n táº¡i, em Ä‘ang cÃ³ má»™t bÃ i toÃ¡n vá» table/document extraction cho tá» khai háº£i quan. Em muá»‘n extract má»—i cÃ¡i subtable ""Sá»‘ lÆ°á»£ng vÃ  mÃ´ táº£ chi tiáº¿t ná»™i dung bÆ°u pháº©m + Khá»‘i lÆ°á»£ng + GiÃ¡ trá»‹"" vÃ  subtable ""DÃ nh cho bÆ°u pháº©m lÃ  hÃ ng hoÃ¡. Náº¿u biáº¿t sá»‘ thuáº¿ HS"". Em thá»­ dÃ¹ng Google Form Parser nhÆ°ng váº«n ko thÃ nh cÃ´ng nhÆ° mong muá»‘n. Hiá»‡n táº¡i, em nghÄ© vá» cÃ¡ch sá»­ dá»¥ng deep learning Ä‘á»ƒ locate bounding box Ä‘á»ƒ crop rá»“i dÃ¹ng Google vision Ä‘á»ƒ extract info. NhÆ°ng em muá»‘n nghe lá»i khuyÃªn tá»« cÃ¡c anh chá»‹ vá» cÃ¡ch approach bÃ i toÃ¡n nÃ y vÃ¬ em ko biáº¿t cÃ¡ch lÃ m cá»§a hiá»‡n táº¡i cÃ³ pháº£i lÃ  most efficient khÃ´ng. Em cáº£m Æ¡n nhiá»u áº¡ vÃ  mong nháº­n Ä‘Æ°á»£c lá»i khuyÃªn tá»« má»i ngÆ°á»i.",,,,,
CÃ¡c báº¡n nÃ o cÃ³ Ä‘iá»u kiá»‡n tham gia thÃ¬ cÃ¹ng chung tay vá»›i Lá»™c.,CÃ¡c báº¡n nÃ o cÃ³ Ä‘iá»u kiá»‡n tham gia thÃ¬ cÃ¹ng chung tay vá»›i Lá»™c.,,,,,
,nan,,,,,
"Khi nháº¯c Ä‘áº¿n COVID-19, cÃ³ láº½ má»i ngÆ°á»i Ä‘Ã£ quÃ¡ quen vá»›i nhá»¯ng chá»‰ sá»‘ nhÆ° sá»‘ ca nhiá»…m má»›i, sá»‘ ca tá»­ vong, sá»‘ xÃ©t nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n,â€¦
Tuy nhiÃªn, cÃ³ má»™t chá»‰ sá»‘ khÃ¡c cÅ©ng ráº¥t quan trá»ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a má»™t dá»‹ch bá»‡nh. BÃ i hÃ´m nay mÃ¬nh xin giá»›i thiá»‡u qua vá» há»‡ sá»‘ lÃ¢y nhiá»…m R vÃ  á»©ng dá»¥ng cá»§a chá»‰ sá»‘ nÃ y.","Khi nháº¯c Ä‘áº¿n COVID-19, cÃ³ láº½ má»i ngÆ°á»i Ä‘Ã£ quÃ¡ quen vá»›i nhá»¯ng chá»‰ sá»‘ nhÆ° sá»‘ ca nhiá»…m má»›i, sá»‘ ca tá»­ vong, sá»‘ xÃ©t nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n,â€¦ Tuy nhiÃªn, cÃ³ má»™t chá»‰ sá»‘ khÃ¡c cÅ©ng ráº¥t quan trá»ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a má»™t dá»‹ch bá»‡nh. BÃ i hÃ´m nay mÃ¬nh xin giá»›i thiá»‡u qua vá» há»‡ sá»‘ lÃ¢y nhiá»…m R vÃ  á»©ng dá»¥ng cá»§a chá»‰ sá»‘ nÃ y.",,,,,
"DÆ°á»ng nhÆ° xu tháº¿ sá»­ dá»¥ng kiáº¿n trÃºc Transformers Ä‘ang dáº§n thay tháº¿ cho Convolution lÃ  khÃ´ng thá»ƒ Ä‘áº£o ngÆ°á»£c cho bÃ i toÃ¡n Image Recognition Tasks trong tÆ°Æ¡ng lai ráº¥t gáº§n https://openreview.net/pdf?id=xTJEN-ggl1b#page4
CÃ¡c báº¡n cÃ³ thá»ƒ xem YouTube giáº£i thÃ­ch vá» bÃ i bÃ¡o nÃ y thÃªm https://m.youtube.com/watch?feature=youtu.be&v=3qxJ2WD8p4w",DÆ°á»ng nhÆ° xu tháº¿ sá»­ dá»¥ng kiáº¿n trÃºc Transformers Ä‘ang dáº§n thay tháº¿ cho Convolution lÃ  khÃ´ng thá»ƒ Ä‘áº£o ngÆ°á»£c cho bÃ i toÃ¡n Image Recognition Tasks trong tÆ°Æ¡ng lai ráº¥t gáº§n https://openreview.net/pdf?id=xTJEN-ggl1b#page4 CÃ¡c báº¡n cÃ³ thá»ƒ xem YouTube giáº£i thÃ­ch vá» bÃ i bÃ¡o nÃ y thÃªm https://m.youtube.com/watch?feature=youtu.be&v=3qxJ2WD8p4w,,,,,
"ğŸ IMAGE STITCHING - PANORAMA IMAGE
ğŸ€ LÃ m viá»‡c trong lÄ©nh vá»±c Computer Vision, chÃºng ta Ã­t nhiá»u cÅ©ng pháº£i Ä‘á»™ng tá»›i cÃ¡c thuáº­t toÃ¡n xá»­ lÃ­ áº£nh. Váº­y nÃªn hÃ´m nay, ta sáº½ Ä‘á»•i giÃ³ má»™t chÃºt vá»›i cÃ¡c xá»­ lÃ­ áº£nh nhÃ©. Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ mÃ´ táº£ cÃ¡c thuáº­t toÃ¡n vÃ  code cho bÃ i toÃ¡n Image Stitching Ä‘á»ƒ ghÃ©p ná»‘i cÃ¡c táº¥m áº£nh Ä‘Æ°á»£c chá»¥p tá»« nhiá»u gÃ³c Ä‘á»™, vá»‹ trÃ­ khÃ¡c nhau. Tá»« Ä‘Ã³ táº¡o nÃªn 1 táº¥m áº£nh cÃ³ kÃ­ch thÆ°á»›c lá»›n vÃ  toÃ n cáº£nh.
ğŸ€ Ná»™i dung bÃ i cÃ³ viáº¿t vá» cÃ¡c thuáº­t toÃ¡n SIFT, SUFT, Match Agorithms, RANSAC, homography transform, ...
#image_processing , #feature_based, #feature_extraction, #homography
https://viblo.asia/p/image-stitching-thuat-toan-dung-dang-sau-cong-nghe-anh-panorama-LzD5dee4KjY","IMAGE STITCHING - PANORAMA IMAGE LÃ m viá»‡c trong lÄ©nh vá»±c Computer Vision, chÃºng ta Ã­t nhiá»u cÅ©ng pháº£i Ä‘á»™ng tá»›i cÃ¡c thuáº­t toÃ¡n xá»­ lÃ­ áº£nh. Váº­y nÃªn hÃ´m nay, ta sáº½ Ä‘á»•i giÃ³ má»™t chÃºt vá»›i cÃ¡c xá»­ lÃ­ áº£nh nhÃ©. Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ mÃ´ táº£ cÃ¡c thuáº­t toÃ¡n vÃ  code cho bÃ i toÃ¡n Image Stitching Ä‘á»ƒ ghÃ©p ná»‘i cÃ¡c táº¥m áº£nh Ä‘Æ°á»£c chá»¥p tá»« nhiá»u gÃ³c Ä‘á»™, vá»‹ trÃ­ khÃ¡c nhau. Tá»« Ä‘Ã³ táº¡o nÃªn 1 táº¥m áº£nh cÃ³ kÃ­ch thÆ°á»›c lá»›n vÃ  toÃ n cáº£nh. Ná»™i dung bÃ i cÃ³ viáº¿t vá» cÃ¡c thuáº­t toÃ¡n SIFT, SUFT, Match Agorithms, RANSAC, homography transform, ... , https://viblo.asia/p/image-stitching-thuat-toan-dung-dang-sau-cong-nghe-anh-panorama-LzD5dee4KjY","#image_processing	#feature_based,	#feature_extraction,	#homography",,,,
"Cho mÃ¬nh xin nguá»“n tÃ i liá»‡u tá»« vá»±ng tiáº¿ng anh vá» AI vÃ  thá»‘ng kÃª áº¡. MÃ¬nh Ä‘ang Ä‘á»c tÃ i liá»‡u tiáº¿ng anh, cáº£m tháº¥y tá»± dá»‹ch khÃ´ng cÃ³ sÃ¡t nghÄ©a láº¯m.","Cho mÃ¬nh xin nguá»“n tÃ i liá»‡u tá»« vá»±ng tiáº¿ng anh vá» AI vÃ  thá»‘ng kÃª áº¡. MÃ¬nh Ä‘ang Ä‘á»c tÃ i liá»‡u tiáº¿ng anh, cáº£m tháº¥y tá»± dá»‹ch khÃ´ng cÃ³ sÃ¡t nghÄ©a láº¯m.",,,,,
"ğŸœ KÃ­nh chÃ o cáº£ nhÃ , em Ä‘ang lÃ m dá»± Ã¡n cáº§n camera IP nhÆ°ng do Ä‘ang test nÃªn chÆ°a mua vÃ  giáº£ láº­p trÃªn Android cho tiá»‡n.
Tháº¥y nhiá»u báº¡n cáº§n nÃªn em lÃ m clip share mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c ah
Mong ad duyá»‡t bÃ i!","KÃ­nh chÃ o cáº£ nhÃ , em Ä‘ang lÃ m dá»± Ã¡n cáº§n camera IP nhÆ°ng do Ä‘ang test nÃªn chÆ°a mua vÃ  giáº£ láº­p trÃªn Android cho tiá»‡n. Tháº¥y nhiá»u báº¡n cáº§n nÃªn em lÃ m clip share mong giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n má»›i há»c ah Mong ad duyá»‡t bÃ i!",,,,,
"The ASGAARD lab ((University of Alberta, Canada) has 3 funded positions (2 PhD and 1 MSc) starting Summer or Fall 2021! If you are interested in working on:
(1) automated quality assurance processes for games and/or
(2) software engineering for the modern AI stack
check the website below:","The ASGAARD lab ((University of Alberta, Canada) has 3 funded positions (2 PhD and 1 MSc) starting Summer or Fall 2021! If you are interested in working on: (1) automated quality assurance processes for games and/or (2) software engineering for the modern AI stack check the website below:",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  thÃ nh viÃªn má»›i cá»§a nhÃ³m . Hiá»‡n táº¡i mÃ¬nh Ä‘ang há»c mÃ´n machine learning vÃ  mÃ¬nh sáº½ pháº£i thi káº¿t thÃºc mÃ´n báº±ng bÃ i táº­p lá»›n. CÃ¡c báº¡n cÃ³ thá»ƒ gá»£i Ã½ cho mÃ¬nh 1 sá»‘ Ä‘á» tÃ i khÃ´ng áº¡ ? CÃ³ tÃ i liá»‡u luÃ´n thÃ¬ cÃ ng tá»‘t áº¡ ğŸ¤£
MÃ¬nh xin cáº£m Æ¡n ğŸ˜ŠğŸ˜Š","ChÃ o má»i ngÆ°á»i, mÃ¬nh lÃ  thÃ nh viÃªn má»›i cá»§a nhÃ³m . Hiá»‡n táº¡i mÃ¬nh Ä‘ang há»c mÃ´n machine learning vÃ  mÃ¬nh sáº½ pháº£i thi káº¿t thÃºc mÃ´n báº±ng bÃ i táº­p lá»›n. CÃ¡c báº¡n cÃ³ thá»ƒ gá»£i Ã½ cho mÃ¬nh 1 sá»‘ Ä‘á» tÃ i khÃ´ng áº¡ ? CÃ³ tÃ i liá»‡u luÃ´n thÃ¬ cÃ ng tá»‘t áº¡ MÃ¬nh xin cáº£m Æ¡n",,,,,
"ChÃ o má»i ngÆ°á»i, dá»¯ liá»‡u Ä‘áº§u vÃ o cá»§a em lÃ  string [há» tÃªn ngÆ°á»i Viá»‡t] - lÃ  káº¿t quáº£ sau khi gá»i text ocr detection, vÃ¬ text ocr detection chÆ°a tá»‘t nÃªn há» tÃªn váº«n cÃ²n chÆ°a chÃ­nh xÃ¡c, vd: 
result :""PHáº M LÆ¯U HOANG"", thá»±c táº¿ lÃ : ""PHáº M LÆ¯U HOÃ€NG""
result: ""TRÃ‚N THE Yáº¾N THUY"", thá»±c táº¿ lÃ  ""TRáº¦N THá»Š Yáº¾N THÃ™Y""
em muá»‘n tÃ¬m má»™t model cÃ³ thá»ƒ lÃ m tÄƒng kháº£ nÄƒng chÃ­nh xÃ¡c cho text ocr detection, model khÃ´ng nháº¥t thiáº¿t pháº£i sá»­a toÃ n bá»™ string há» tÃªn. vd:
result: ""TRÃ‚N THE Yáº¾N THUY"". ouput model: ""TRáº¦N THá»Š Yáº¾N THUY"". cá»¥m tá»« ""TRáº¦N THE Yáº¾N"" cÃ³ thá»ƒ dá»… dÃ ng sá»­a thÃ nh ""TRáº¦N THá»Š Yáº¾N"", nhÆ°ng cá»¥m tá»« ""Yáº¾N THUY"" cÃ³ thá»ƒ sá»­a thÃ nh ""Yáº¾N THÃ™Y"" hoáº·c ""Yáº¾N THá»¦Y"" - cÃ³ Ä‘á»™ phá»• biáº¿n gáº§n ngang nhau nÃªn em khÃ´ng yÃªu cáº§u model recorrect cá»¥m tá»« nÃ y (sáº½ cÃ³ má»™t cÃ¡ch khÃ¡c ngoÃ i model Ä‘á»ƒ tiáº¿p tá»¥c recorrect).
 Ä‘Ã³ lÃ  cÃ¡ch giáº£i quyáº¿t mÃ  em Ä‘ang hÆ°á»›ng tá»›i, model Ä‘Ã³ lÃ  gÃ¬? hoáº·c cÃ³ cÃ¡ch giáº£i quyáº¿t nÃ o tá»‘t hÆ¡n mong mn giÃºp Ä‘á»¡!","ChÃ o má»i ngÆ°á»i, dá»¯ liá»‡u Ä‘áº§u vÃ o cá»§a em lÃ  string [há» tÃªn ngÆ°á»i Viá»‡t] - lÃ  káº¿t quáº£ sau khi gá»i text ocr detection, vÃ¬ text ocr detection chÆ°a tá»‘t nÃªn há» tÃªn váº«n cÃ²n chÆ°a chÃ­nh xÃ¡c, vd: result :""PHáº M LÆ¯U HOANG"", thá»±c táº¿ lÃ : ""PHáº M LÆ¯U HOÃ€NG"" result: ""TRÃ‚N THE Yáº¾N THUY"", thá»±c táº¿ lÃ  ""TRáº¦N THá»Š Yáº¾N THÃ™Y"" em muá»‘n tÃ¬m má»™t model cÃ³ thá»ƒ lÃ m tÄƒng kháº£ nÄƒng chÃ­nh xÃ¡c cho text ocr detection, model khÃ´ng nháº¥t thiáº¿t pháº£i sá»­a toÃ n bá»™ string há» tÃªn. vd: result: ""TRÃ‚N THE Yáº¾N THUY"". ouput model: ""TRáº¦N THá»Š Yáº¾N THUY"". cá»¥m tá»« ""TRáº¦N THE Yáº¾N"" cÃ³ thá»ƒ dá»… dÃ ng sá»­a thÃ nh ""TRáº¦N THá»Š Yáº¾N"", nhÆ°ng cá»¥m tá»« ""Yáº¾N THUY"" cÃ³ thá»ƒ sá»­a thÃ nh ""Yáº¾N THÃ™Y"" hoáº·c ""Yáº¾N THá»¦Y"" - cÃ³ Ä‘á»™ phá»• biáº¿n gáº§n ngang nhau nÃªn em khÃ´ng yÃªu cáº§u model recorrect cá»¥m tá»« nÃ y (sáº½ cÃ³ má»™t cÃ¡ch khÃ¡c ngoÃ i model Ä‘á»ƒ tiáº¿p tá»¥c recorrect). Ä‘Ã³ lÃ  cÃ¡ch giáº£i quyáº¿t mÃ  em Ä‘ang hÆ°á»›ng tá»›i, model Ä‘Ã³ lÃ  gÃ¬? hoáº·c cÃ³ cÃ¡ch giáº£i quyáº¿t nÃ o tá»‘t hÆ¡n mong mn giÃºp Ä‘á»¡!",,,,,
"#hoidap
Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang cÃ³ cáº§n crawl cÃ¡c skill tiáº¿ng anh liÃªn quan Ä‘áº¿n bÃ i toÃ¡n tuyá»ƒn dá»¥ng. Má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ cho em vÃ i trang web tuyá»ƒn dá»¥ng hay gÃ¬ Ä‘Ã³ mÃ  cÃ³ thá»ƒ crawl Ä‘Æ°á»£c cÃ¡c skill khÃ´ng áº¡ ? Em cáº£m Æ¡n",Em chÃ o má»i ngÆ°á»i áº¡. Hiá»‡n táº¡i em Ä‘ang cÃ³ cáº§n crawl cÃ¡c skill tiáº¿ng anh liÃªn quan Ä‘áº¿n bÃ i toÃ¡n tuyá»ƒn dá»¥ng. Má»i ngÆ°á»i cÃ³ thá»ƒ gá»£i Ã½ cho em vÃ i trang web tuyá»ƒn dá»¥ng hay gÃ¬ Ä‘Ã³ mÃ  cÃ³ thá»ƒ crawl Ä‘Æ°á»£c cÃ¡c skill khÃ´ng áº¡ ? Em cáº£m Æ¡n,#hoidap,,,,
"Em cÃ³ má»™t sá»‘ táº¥m hÃ¬nh chá»¥p cÃ¢y cáº£i tháº£o nhÆ° bÃªn dÆ°á»›i vÃ  cáº§n Ä‘áº¿m sá»‘ cÃ¢y trÃªn ruá»™ng. Má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng nÃ o Ä‘á»ƒ thá»±c hiá»‡n khÃ´ng áº¡.
LÆ°á»£ng áº£nh cÃ³ thá»ƒ chá»¥p thÃªm, em chá»‰ gá»­i 2 táº¥m mÃ¬nh há»a áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i!!!!!","Em cÃ³ má»™t sá»‘ táº¥m hÃ¬nh chá»¥p cÃ¢y cáº£i tháº£o nhÆ° bÃªn dÆ°á»›i vÃ  cáº§n Ä‘áº¿m sá»‘ cÃ¢y trÃªn ruá»™ng. Má»i ngÆ°á»i cÃ³ Ã½ tÆ°á»Ÿng nÃ o Ä‘á»ƒ thá»±c hiá»‡n khÃ´ng áº¡. LÆ°á»£ng áº£nh cÃ³ thá»ƒ chá»¥p thÃªm, em chá»‰ gá»­i 2 táº¥m mÃ¬nh há»a áº¡. Cáº£m Æ¡n má»i ngÆ°á»i!!!!!",,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang muá»‘n há»i vá» sá»± khÃ¡c nhau giá»¯a validation, test vÃ  cross-validation. Theo mÃ¬nh hiá»ƒu, validation sá»­ dá»¥ng Ä‘á»ƒ Ä‘o lÆ°á»ng test statistics CV(n) Ä‘á»ƒ xem sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh lÃ  bao nhiÃªu (ngÄƒn ngá»«a overfit) cÃ²n táº­p test Ä‘á»ƒ Ä‘o lÆ°á»ng true (test) MSE, chá»n ra model tá»‘i Æ°u, Ä‘Ãºng khÃ´ng nhá»‰? Váº­y thÃ¬ sau khi tÃ¬m Ä‘Æ°á»£c sá»‘ lÆ°á»£ng tham sá»‘, mÃ¬nh láº¡i cháº¡y láº¡i mÃ´ hÃ¬nh trÃªn táº­p train Ä‘á»ƒ tÃ¬m ra mÃ´ hÃ¬nh tá»‘i Æ°u test láº¡i trÃªn táº­p test Ä‘Ãºng khÃ´ng? (Sá»­ dá»¥ng adjusted R square as a test statistic cháº³ng háº¡n?)","ChÃ o má»i ngÆ°á»i, mÃ¬nh Ä‘ang muá»‘n há»i vá» sá»± khÃ¡c nhau giá»¯a validation, test vÃ  cross-validation. Theo mÃ¬nh hiá»ƒu, validation sá»­ dá»¥ng Ä‘á»ƒ Ä‘o lÆ°á»ng test statistics CV(n) Ä‘á»ƒ xem sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh lÃ  bao nhiÃªu (ngÄƒn ngá»«a overfit) cÃ²n táº­p test Ä‘á»ƒ Ä‘o lÆ°á»ng true (test) MSE, chá»n ra model tá»‘i Æ°u, Ä‘Ãºng khÃ´ng nhá»‰? Váº­y thÃ¬ sau khi tÃ¬m Ä‘Æ°á»£c sá»‘ lÆ°á»£ng tham sá»‘, mÃ¬nh láº¡i cháº¡y láº¡i mÃ´ hÃ¬nh trÃªn táº­p train Ä‘á»ƒ tÃ¬m ra mÃ´ hÃ¬nh tá»‘i Æ°u test láº¡i trÃªn táº­p test Ä‘Ãºng khÃ´ng? (Sá»­ dá»¥ng adjusted R square as a test statistic cháº³ng háº¡n?)",,,,,
"MÃ¬nh cÃ²n nhá»› 2-3 nÄƒm trÆ°á»›c bÃ¡c áº¥y cÃ³ nÃ³i tá»›i trends in AI lÃ  unsupervised learning. CÃ²n nay lÃ :
1/ Self-supervised Learning;
2/ Federated Learning;
3/ Transformers architectures",MÃ¬nh cÃ²n nhá»› 2-3 nÄƒm trÆ°á»›c bÃ¡c áº¥y cÃ³ nÃ³i tá»›i trends in AI lÃ  unsupervised learning. CÃ²n nay lÃ : 1/ Self-supervised Learning; 2/ Federated Learning; 3/ Transformers architectures,,,,,
"Em lÃ  sinh viÃªn vÃ  Ä‘ang lÃ m bÃ i táº­p lá»›n vá» Neural Networks. Äá» bÃ i cá»§a em lÃ  ""Nháº­n dáº¡ng cÃ¡c chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9"", em sá»­ dá»¥ng dá»¯ liá»‡u tá»« mnist dataset. Hiá»‡n em Ä‘ang gáº·p khÃ³ khÄƒn trong viá»‡c chá»n máº¡ng Ä‘á»ƒ xá»­ lÃ½ bÃ i toÃ¡n. Mong má»i ngÆ°á»i cho thá»ƒ cho em biáº¿t nhá»¯ng loáº¡i máº¡ng nÃ o cÃ³ thá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n cá»§a em (trá»« CNN vÃ  MLP áº¡, 2 máº¡ng nÃ y Ä‘Ã£ cÃ³ nhÃ³m dÃ¹ng). Code vá»›i em khÃ´ng lÃ  váº¥n Ä‘á» áº¡","Em lÃ  sinh viÃªn vÃ  Ä‘ang lÃ m bÃ i táº­p lá»›n vá» Neural Networks. Äá» bÃ i cá»§a em lÃ  ""Nháº­n dáº¡ng cÃ¡c chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9"", em sá»­ dá»¥ng dá»¯ liá»‡u tá»« mnist dataset. Hiá»‡n em Ä‘ang gáº·p khÃ³ khÄƒn trong viá»‡c chá»n máº¡ng Ä‘á»ƒ xá»­ lÃ½ bÃ i toÃ¡n. Mong má»i ngÆ°á»i cho thá»ƒ cho em biáº¿t nhá»¯ng loáº¡i máº¡ng nÃ o cÃ³ thá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n cá»§a em (trá»« CNN vÃ  MLP áº¡, 2 máº¡ng nÃ y Ä‘Ã£ cÃ³ nhÃ³m dÃ¹ng). Code vá»›i em khÃ´ng lÃ  váº¥n Ä‘á» áº¡",,,,,
"Má»i Anh EM Forum ML mÃ¬nh tham gia nghe vÃ  tháº£o luáº­n online Tech Talk vá» cÃ¡c cÃ´ng nghÃªÌ£ AI, BigData, IoT, 5G-6G, Blockchain, Fintech vaÌ€ Robotics nhÃ©.
. Trong Tech Talk naÌ€y, caÌc cÃ´ng nghÃªÌ£ trÃªn seÌƒ Ä‘Æ°Æ¡Ì£c triÌ€nh baÌ€y vaÌ€ thaÌ‰o luÃ¢Ì£n. CaÌc speakers nÃ´Ì‰i bÃ¢Ì£t trong mÃ´Ìƒi topic seÌƒ Ä‘Æ°a chuÌng ta tÆ¡Ìi nhÆ°Ìƒng khiÌa caÌ£nh khaÌc nhau vÃªÌ€ caÌc cÃ´ng nghÃªÌ£ trÃªn tÆ°Ì€ goÌc nhiÌ€n nghiÃªn cÆ°Ìu, startup, vaÌ€ cÃ´ng nghiÃªÌ£p. MoÌ£i ngÆ°Æ¡Ì€i haÌƒy cuÌ€ng Ä‘Äƒng kyÌ tham gia thaÌ‰o luÃ¢Ì£n vÆ¡Ìi caÌc speakers vÃªÌ€ cÃ´ng nghÃªÌ£ yÃªu thiÌch vaÌ€ triÃªÌ‰n voÌ£ng trong tÆ°Æ¡ng lai nheÌ.
HaÌƒy choÌ£n NUÌT ""THAM GIA"" trong Facebook event dÆ°Æ¡Ìi vaÌ€ Ä‘Äƒng kiÌ choÌ£n Talk 6 chá»§ Ä‘á» ""ICT CONVERGENCE â€“ SHAPING THE FUTURE OF VIETNAM: Há»˜I Tá»¤ CÃ”NG NGHá»† THÃ”NG TIN VÃ€ TRUYá»€N THÃ”NG CHO Sá»° PHÃT TRIá»‚N Cá»¦A Äáº¤T NÆ¯á»šC"" trÃªn website http://trithuctrevietnam.vn Ä‘ÃªÌ‰ nhÃ¢Ì£n Ä‘Æ°Æ¡Ì£c link cuÌ‰a Online Talk cuÌ‰a miÌ€nh qua Zoom sÆ¡Ìm nhÃ¢Ìt nheÌ!
ThÆ¡Ì€i gian diÃªÌƒn ra Online Tech Talk: 12h00-14h10 (giá» Viá»‡t Nam), thá»© báº£y vaÌ€ chuÌ‰ nhÃ¢Ì£t, 17 vaÌ€ 18/10/2020","Má»i Anh EM Forum ML mÃ¬nh tham gia nghe vÃ  tháº£o luáº­n online Tech Talk vá» cÃ¡c cÃ´ng nghÃªÌ£ AI, BigData, IoT, 5G-6G, Blockchain, Fintech vaÌ€ Robotics nhÃ©. . Trong Tech Talk naÌ€y, caÌc cÃ´ng nghÃªÌ£ trÃªn seÌƒ Ä‘Æ°Æ¡Ì£c triÌ€nh baÌ€y vaÌ€ thaÌ‰o luÃ¢Ì£n. CaÌc speakers nÃ´Ì‰i bÃ¢Ì£t trong mÃ´Ìƒi topic seÌƒ Ä‘Æ°a chuÌng ta tÆ¡Ìi nhÆ°Ìƒng khiÌa caÌ£nh khaÌc nhau vÃªÌ€ caÌc cÃ´ng nghÃªÌ£ trÃªn tÆ°Ì€ goÌc nhiÌ€n nghiÃªn cÆ°Ìu, startup, vaÌ€ cÃ´ng nghiÃªÌ£p. MoÌ£i ngÆ°Æ¡Ì€i haÌƒy cuÌ€ng Ä‘Äƒng kyÌ tham gia thaÌ‰o luÃ¢Ì£n vÆ¡Ìi caÌc speakers vÃªÌ€ cÃ´ng nghÃªÌ£ yÃªu thiÌch vaÌ€ triÃªÌ‰n voÌ£ng trong tÆ°Æ¡ng lai nheÌ. HaÌƒy choÌ£n NUÌT ""THAM GIA"" trong Facebook event dÆ°Æ¡Ìi vaÌ€ Ä‘Äƒng kiÌ choÌ£n Talk 6 chá»§ Ä‘á» ""ICT CONVERGENCE â€“ SHAPING THE FUTURE OF VIETNAM: Há»˜I Tá»¤ CÃ”NG NGHá»† THÃ”NG TIN VÃ€ TRUYá»€N THÃ”NG CHO Sá»° PHÃT TRIá»‚N Cá»¦A Äáº¤T NÆ¯á»šC"" trÃªn website http://trithuctrevietnam.vn Ä‘ÃªÌ‰ nhÃ¢Ì£n Ä‘Æ°Æ¡Ì£c link cuÌ‰a Online Talk cuÌ‰a miÌ€nh qua Zoom sÆ¡Ìm nhÃ¢Ìt nheÌ! ThÆ¡Ì€i gian diÃªÌƒn ra Online Tech Talk: 12h00-14h10 (giá» Viá»‡t Nam), thá»© báº£y vaÌ€ chuÌ‰ nhÃ¢Ì£t, 17 vaÌ€ 18/10/2020",,,,,
"Hi mn.

Em Ä‘ang dÃ¹ng CNN Ä‘á»ƒ nháº­n dáº¡ng Ä‘Ã¨n giao thÃ´ng.Mn ai tá»«ng lÃ m Ä‘á» tÃ i cÃ³ thá»ƒ cho em xin Data Ä‘Æ°á»£c ko áº¡ ?Em cÃ¡m Æ¡n.",Hi mn. Em Ä‘ang dÃ¹ng CNN Ä‘á»ƒ nháº­n dáº¡ng Ä‘Ã¨n giao thÃ´ng.Mn ai tá»«ng lÃ m Ä‘á» tÃ i cÃ³ thá»ƒ cho em xin Data Ä‘Æ°á»£c ko áº¡ ?Em cÃ¡m Æ¡n.,,,,,
"Em cÃ³ 1 tháº¯c máº¯c nÃ y muá»‘n nhá» cÃ¡c bÃ¡c chá»‰ giÃ¡o.
Khi so sÃ¡nh 2 model A (Mask R-CNN ResNeXt-101-32x4d) vÃ  B (Cascade Mask R-CNN ResNet-50) trÃªn 1 táº­p khoáº£ng ~ 1k áº£nh, tá»‰ lá»‡ train:val:test lÃ  70:15:15, xáº£y ra váº¥n Ä‘á»:
Khi training vÃ  validation: Precision vÃ  Recall cá»§a model B tá»‘t hÆ¡n model A.
Tuy nhiÃªn, khi testing: Precision vÃ  Recall cá»§a model A láº¡i tá»‘t hÆ¡n model B.
CÃ¡c bÃ¡c cho em xin lá»i giáº£i thÃ­ch vÃ  cÃ¡c kháº¯c phá»¥c cho Ä‘Ãºng láº½ ko áº¡? ğŸ˜¢ğŸ˜¢ğŸ˜¢
P/s: áº£nh testing sáº½ khÃ¡c chÃºt Ã­t so vá»›i train vÃ  val","Em cÃ³ 1 tháº¯c máº¯c nÃ y muá»‘n nhá» cÃ¡c bÃ¡c chá»‰ giÃ¡o. Khi so sÃ¡nh 2 model A (Mask R-CNN ResNeXt-101-32x4d) vÃ  B (Cascade Mask R-CNN ResNet-50) trÃªn 1 táº­p khoáº£ng ~ 1k áº£nh, tá»‰ lá»‡ train:val:test lÃ  70:15:15, xáº£y ra váº¥n Ä‘á»: Khi training vÃ  validation: Precision vÃ  Recall cá»§a model B tá»‘t hÆ¡n model A. Tuy nhiÃªn, khi testing: Precision vÃ  Recall cá»§a model A láº¡i tá»‘t hÆ¡n model B. CÃ¡c bÃ¡c cho em xin lá»i giáº£i thÃ­ch vÃ  cÃ¡c kháº¯c phá»¥c cho Ä‘Ãºng láº½ ko áº¡? P/s: áº£nh testing sáº½ khÃ¡c chÃºt Ã­t so vá»›i train vÃ  val",,,,,
"Má»i ngÆ°á»i cho em há»i cÃ³ pretrained model nÃ o cho bÃ i toÃ¡n phÃ¢n loáº¡i (classification) áº£nh 3D khÃ´ng áº¡?
BÃ i toÃ¡n cá»§a em lÃ  phÃ¢n loáº¡i má»™t ngÆ°á»i bá»‡nh/khÃ´ng bá»‡nh dá»±a trÃªn cÃ¡c áº£nh CT scans dáº¡ng 2D cá»§a bá»‡nh nhÃ¢n, vÃ  cÃ¡c áº£nh nÃ y cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ reconstruct thÃ nh 3D. Tuy nhiÃªn trÆ°á»›c giá» em má»›i chá»‰ biáº¿t Ä‘áº¿n cÃ¡c 2D models (resnet, efficientnet, mobilenet, etc.) mÃ  chÆ°a tháº¥y cÃ¡c á»©ng dá»¥ng tÆ°Æ¡ng tá»± cho 3D CNN. Cao nhÃ¢n nÃ o cÃ³ thÃ´ng tin cho em xin vá»›i áº¡. Náº¿u model built trÃªn keras/tensorflow thÃ¬ cÃ ng tá»‘t áº¡. Em xin cáº£m Æ¡n!","Má»i ngÆ°á»i cho em há»i cÃ³ pretrained model nÃ o cho bÃ i toÃ¡n phÃ¢n loáº¡i (classification) áº£nh 3D khÃ´ng áº¡? BÃ i toÃ¡n cá»§a em lÃ  phÃ¢n loáº¡i má»™t ngÆ°á»i bá»‡nh/khÃ´ng bá»‡nh dá»±a trÃªn cÃ¡c áº£nh CT scans dáº¡ng 2D cá»§a bá»‡nh nhÃ¢n, vÃ  cÃ¡c áº£nh nÃ y cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ reconstruct thÃ nh 3D. Tuy nhiÃªn trÆ°á»›c giá» em má»›i chá»‰ biáº¿t Ä‘áº¿n cÃ¡c 2D models (resnet, efficientnet, mobilenet, etc.) mÃ  chÆ°a tháº¥y cÃ¡c á»©ng dá»¥ng tÆ°Æ¡ng tá»± cho 3D CNN. Cao nhÃ¢n nÃ o cÃ³ thÃ´ng tin cho em xin vá»›i áº¡. Náº¿u model built trÃªn keras/tensorflow thÃ¬ cÃ ng tá»‘t áº¡. Em xin cáº£m Æ¡n!",,,,,
"Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ post bÃ i bÃ¡o dÆ°á»›i dáº¡ng open under review vá» Vision Transformers táº¡i Ä‘Ã¢y https://openreview.net/pdf?id=YicbFdNTTy; Váº­y nÃªn mÃ¬nh thá»­ á»©ng dá»¥ng chÃºng vÃ o giáº£i quyáº¿t bÃ i toÃ¡n liÃªn quan tá»›i áº£nh X quang phá»•i cháº©n Ä‘oÃ¡n Covid-19. Datasets cho viá»‡c nÃ y mÃ¬nh thu tháº­p táº¡i dá»±a trÃªn nhiá»u nguá»“n má»Ÿ https://github.com/lindawangg/COVID-Net; https://github.com/ieee8023/covid-chestxray-dataset; & https://figshare.com/articles/COVID-19_Chest_X-Ray_Image_Repository/12580328. Trong pháº§n nÃ y mÃ¬nh dÃ¹ng Hybrid model vá»›i backbone lÃ  EfficientNet-B0 káº¿t há»£p vá»›i Transformers. VÃ  káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c ráº¥t kháº£ quan sau vÃ i giá» huáº¥n luyá»‡n (xem confusion matrix). Káº¿t quáº£ nÃ y tá»‘t hÆ¡n so vá»›i káº¿t quáº£ gáº§n Ä‘Ã¢y cá»§a nhÃ³m mÃ¬nh, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y https://www.medrxiv.org/content/10.1101/2020.08.13.20173997v1.full.pdf. KhÃ´ng hiá»ƒu sao stt trÃªn Facebook khÃ´ng cho chÃ¨n áº£nh nÃªn mÃ¬nh Ä‘Æ°a CM xuá»‘ng pháº§n comment","Gáº§n Ä‘Ã¢y mÃ¬nh cÃ³ post bÃ i bÃ¡o dÆ°á»›i dáº¡ng open under review vá» Vision Transformers táº¡i Ä‘Ã¢y https://openreview.net/pdf?id=YicbFdNTTy; Váº­y nÃªn mÃ¬nh thá»­ á»©ng dá»¥ng chÃºng vÃ o giáº£i quyáº¿t bÃ i toÃ¡n liÃªn quan tá»›i áº£nh X quang phá»•i cháº©n Ä‘oÃ¡n Covid-19. Datasets cho viá»‡c nÃ y mÃ¬nh thu tháº­p táº¡i dá»±a trÃªn nhiá»u nguá»“n má»Ÿ https://github.com/lindawangg/COVID-Net; https://github.com/ieee8023/covid-chestxray-dataset; & https://figshare.com/articles/COVID-19_Chest_X-Ray_Image_Repository/12580328. Trong pháº§n nÃ y mÃ¬nh dÃ¹ng Hybrid model vá»›i backbone lÃ  EfficientNet-B0 káº¿t há»£p vá»›i Transformers. VÃ  káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c ráº¥t kháº£ quan sau vÃ i giá» huáº¥n luyá»‡n (xem confusion matrix). Káº¿t quáº£ nÃ y tá»‘t hÆ¡n so vá»›i káº¿t quáº£ gáº§n Ä‘Ã¢y cá»§a nhÃ³m mÃ¬nh, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y https://www.medrxiv.org/content/10.1101/2020.08.13.20173997v1.full.pdf. KhÃ´ng hiá»ƒu sao stt trÃªn Facebook khÃ´ng cho chÃ¨n áº£nh nÃªn mÃ¬nh Ä‘Æ°a CM xuá»‘ng pháº§n comment",,,,,
"EM ÄANG LÃ€M Vá»€ TEXT TO IMAGE, Äáº¦U VÃ€O Cá»¦A EM LÃ€ 1 ÄOáº N, CÃ‚U VÄ‚N MÃ” Táº¢ PHONG Cáº¢NH, Sá»° Váº¬T, Äáº¦U RA LÃ€ 1 Bá»¨C áº¢NH. GIÃšP CHO MÃY CÃ“ KHáº¢ NÄ‚NG TÆ¯á»NG TÆ¯á»¢NG. HIá»†N EM ÄANG Gáº¶P KHÃ“ KHÄ‚N TRONG VIá»†C CHá»ŒN Máº NG Äá»‚ Xá»¬ LÃ BÃ€I TOÃN.MONG Má»ŒI NGÆ¯á»œI CHO THá»‚ CHO EM BIáº¾T NHá»®NG LOáº I Máº NG NÃ€O CÃ“ THá»‚ GIáº¢I QUYáº¾T BÃ€I TOÃN Cá»¦A EM","EM ÄANG LÃ€M Vá»€ TEXT TO IMAGE, Äáº¦U VÃ€O Cá»¦A EM LÃ€ 1 ÄOáº N, CÃ‚U VÄ‚N MÃ” Táº¢ PHONG Cáº¢NH, Sá»° Váº¬T, Äáº¦U RA LÃ€ 1 Bá»¨C áº¢NH. GIÃšP CHO MÃY CÃ“ KHáº¢ NÄ‚NG TÆ¯á»NG TÆ¯á»¢NG. HIá»†N EM ÄANG Gáº¶P KHÃ“ KHÄ‚N TRONG VIá»†C CHá»ŒN Máº NG Äá»‚ Xá»¬ LÃ BÃ€I TOÃN.MONG Má»ŒI NGÆ¯á»œI CHO THá»‚ CHO EM BIáº¾T NHá»®NG LOáº I Máº NG NÃ€O CÃ“ THá»‚ GIáº¢I QUYáº¾T BÃ€I TOÃN Cá»¦A EM",,,,,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, cháº£ lÃ  hÃ´m rá»“i em lÃ m má»™t bÃ i cáº§n pháº£i Custom Loss nÃªn máº¡nh dáº¡n note láº¡i Ä‘á»ƒ chia sáº» cÃ¹ng anh em newbie má»›i há»c.
Mong giÃºp Ä‘Æ°á»£c anh em vÃ  mong ad duyá»‡t bÃ i! CÃ¡c bÃ¡c cao thá»§ Ä‘i qua chá»‰ giÃ¡o thÃªm Ä‘á»ƒ em Ä‘Æ°á»£c má»Ÿ mang kiáº¿n thá»©c ah!","KÃ­nh chÃ o cÃ¡c bÃ¡c, cháº£ lÃ  hÃ´m rá»“i em lÃ m má»™t bÃ i cáº§n pháº£i Custom Loss nÃªn máº¡nh dáº¡n note láº¡i Ä‘á»ƒ chia sáº» cÃ¹ng anh em newbie má»›i há»c. Mong giÃºp Ä‘Æ°á»£c anh em vÃ  mong ad duyá»‡t bÃ i! CÃ¡c bÃ¡c cao thá»§ Ä‘i qua chá»‰ giÃ¡o thÃªm Ä‘á»ƒ em Ä‘Æ°á»£c má»Ÿ mang kiáº¿n thá»©c ah!",,,,,
Cho em há»i cÃ³ ai Ä‘Ã£ tá»«ng táº¡o má»™t cÃ¡i environment trong zeppelin chÆ°a áº¡. Em táº¡o má»™t cÃ¡i vÃ  list ra thÃ¬ tháº¥y cÃ³ mÃ  khÃ´ng hiá»ƒu sao khÃ´ng thá»ƒ chá»‰ tá»›i mÃ´i trÆ°á»ng Ä‘Ã³ lÃ m viá»‡c lÃ  sao áº¡? Cáº£m Æ¡n cáº£ nhÃ !,Cho em há»i cÃ³ ai Ä‘Ã£ tá»«ng táº¡o má»™t cÃ¡i environment trong zeppelin chÆ°a áº¡. Em táº¡o má»™t cÃ¡i vÃ  list ra thÃ¬ tháº¥y cÃ³ mÃ  khÃ´ng hiá»ƒu sao khÃ´ng thá»ƒ chá»‰ tá»›i mÃ´i trÆ°á»ng Ä‘Ã³ lÃ m viá»‡c lÃ  sao áº¡? Cáº£m Æ¡n cáº£ nhÃ !,,,,,
"Anh chá»‹ cho em há»i vá»›i áº¡. Em Ä‘ang tÃ¬m hiá»ƒu vá» Seq2Seq Encoder Decoder model áº¡. Em muá»‘n há»i lÃ :
1:
Input cá»§a pháº§n Encoder lÃ  cÃ¡c embedding vector (nhÆ° Word2Vec, Glove, ...) pháº£i khÃ´ng áº¡.

2:
<EOS> (EndOfSequence) á»Ÿ Ä‘Ã¢y cá»¥ thá»ƒ lÃ  gÃ¬ áº¡? <EOS> sáº½ lÃ  má»™t Embedding input vector nhÆ° bao tá»« bÃ¬nh thÆ°á»ng khÃ¡c. Hay sáº½ lÃ  má»™t cÃ¡ch Ä‘Ã¡nh dáº¥u káº¿t thÃºc cÃ¢u nÃ o Ä‘Ã³ áº¡?

3:
Greedy search hay Beam search Ä‘Æ°á»£c dÃ¹ng á»Ÿ bÆ°á»›c test pháº£i khÃ´ng áº¡. Tá»©c lÃ  sau khi train xong rá»“i, thÃ¬ má»›i dÃ¹ng Ä‘áº¿n 2 giáº£i thuáº­t kia Ä‘á»ƒ quyáº¿t Ä‘á»‹nh dá»‹ch sang cÃ¢u nÃ o pháº£i khÃ´ng áº¡. 
CÃ²n khi train thÃ¬ Ä‘Æ¡n giáº£n lÃ  tá»‘i Æ°u sao cho vá»‹ trÃ­ cá»§a tá»« mong muá»‘n trong vector output cá»§a decoder cÃ³ giÃ¡ trÃ­ cÃ ng gáº§n 1 cÃ ng tá»‘t, cÃ¡c vá»‹ trÃ­ cÃ²n láº¡i thÃ¬ cÃ ng gáº§n 0 lÃ  Ä‘Æ°á»£c pháº£i khÃ´ng áº¡. Tá»©c lÃ  á»Ÿ ngÃ´n ngá»¯ Ä‘Æ°á»£c dá»‹ch ra, ta khÃ´ng cáº§n embedding kiá»ƒu word2vec, glove mÃ  chá»‰ cáº§n dáº¡ng one hot vector áº¡.

HÆ¡i dÃ i áº¡. Em mong anh, chá»‹ giÃºp em vá»›i áº¡. Em cáº£m Æ¡n anh chá»‹ nhiá»u áº¡.","Anh chá»‹ cho em há»i vá»›i áº¡. Em Ä‘ang tÃ¬m hiá»ƒu vá» Seq2Seq Encoder Decoder model áº¡. Em muá»‘n há»i lÃ : 1: Input cá»§a pháº§n Encoder lÃ  cÃ¡c embedding vector (nhÆ° Word2Vec, Glove, ...) pháº£i khÃ´ng áº¡. 2: <EOS> (EndOfSequence) á»Ÿ Ä‘Ã¢y cá»¥ thá»ƒ lÃ  gÃ¬ áº¡? <EOS> sáº½ lÃ  má»™t Embedding input vector nhÆ° bao tá»« bÃ¬nh thÆ°á»ng khÃ¡c. Hay sáº½ lÃ  má»™t cÃ¡ch Ä‘Ã¡nh dáº¥u káº¿t thÃºc cÃ¢u nÃ o Ä‘Ã³ áº¡? 3: Greedy search hay Beam search Ä‘Æ°á»£c dÃ¹ng á»Ÿ bÆ°á»›c test pháº£i khÃ´ng áº¡. Tá»©c lÃ  sau khi train xong rá»“i, thÃ¬ má»›i dÃ¹ng Ä‘áº¿n 2 giáº£i thuáº­t kia Ä‘á»ƒ quyáº¿t Ä‘á»‹nh dá»‹ch sang cÃ¢u nÃ o pháº£i khÃ´ng áº¡. CÃ²n khi train thÃ¬ Ä‘Æ¡n giáº£n lÃ  tá»‘i Æ°u sao cho vá»‹ trÃ­ cá»§a tá»« mong muá»‘n trong vector output cá»§a decoder cÃ³ giÃ¡ trÃ­ cÃ ng gáº§n 1 cÃ ng tá»‘t, cÃ¡c vá»‹ trÃ­ cÃ²n láº¡i thÃ¬ cÃ ng gáº§n 0 lÃ  Ä‘Æ°á»£c pháº£i khÃ´ng áº¡. Tá»©c lÃ  á»Ÿ ngÃ´n ngá»¯ Ä‘Æ°á»£c dá»‹ch ra, ta khÃ´ng cáº§n embedding kiá»ƒu word2vec, glove mÃ  chá»‰ cáº§n dáº¡ng one hot vector áº¡. HÆ¡i dÃ i áº¡. Em mong anh, chá»‹ giÃºp em vá»›i áº¡. Em cáº£m Æ¡n anh chá»‹ nhiá»u áº¡.",,,,,
"Hi má»i ngÆ°á»i,
Cho em há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xÃ i version control trÃªn Google Colab nhÆ° Git khÃ´ng áº¡? Em cáº£m Æ¡n ^^","Hi má»i ngÆ°á»i, Cho em há»i lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ xÃ i version control trÃªn Google Colab nhÆ° Git khÃ´ng áº¡? Em cáº£m Æ¡n ^^",,,,,
Anh chá»‹ cho em há»i vá»›i áº¡. Dáº¡ em Ä‘ang cháº¡y code detect khuÃ´n máº·t thÃ¬ bá»‹ lá»—i nÃ y áº¡. Anh chá»‹ giÃºp em vá»›i áº¡.,Anh chá»‹ cho em há»i vá»›i áº¡. Dáº¡ em Ä‘ang cháº¡y code detect khuÃ´n máº·t thÃ¬ bá»‹ lá»—i nÃ y áº¡. Anh chá»‹ giÃºp em vá»›i áº¡.,,,,,
"[OCR]
Hi má»i ngÆ°á»i,
Hiá»‡n táº¡i em Ä‘ang cÃ³ bÃ i toÃ¡n nháº­n diá»‡n OCR hÃ ng ngang vá»›i case giÃ¡ trá»‹ sá»‘ cÃ³ thá»ƒ bá»‹ lá»‡ch so vá»›i giÃ¡ trá»‹ chá»¯. VÃ­ dá»¥ nhÆ° khi detect Creatinine, thÃ¬ thay vÃ¬ nháº­n diá»‡n 0.8 cÃ¹ng hÃ ng nhÆ°ng láº¡i bá»‹ lá»‡ch thÃ nh 0.5 hoáº·c 115.51. Má»i ngÆ°á»i cÃ³ suggestion gÃ¬ cho bÃ i toÃ¡n nÃ y khÃ´ng áº¡, em xin cáº£m Æ¡n ^^","[OCR] Hi má»i ngÆ°á»i, Hiá»‡n táº¡i em Ä‘ang cÃ³ bÃ i toÃ¡n nháº­n diá»‡n OCR hÃ ng ngang vá»›i case giÃ¡ trá»‹ sá»‘ cÃ³ thá»ƒ bá»‹ lá»‡ch so vá»›i giÃ¡ trá»‹ chá»¯. VÃ­ dá»¥ nhÆ° khi detect Creatinine, thÃ¬ thay vÃ¬ nháº­n diá»‡n 0.8 cÃ¹ng hÃ ng nhÆ°ng láº¡i bá»‹ lá»‡ch thÃ nh 0.5 hoáº·c 115.51. Má»i ngÆ°á»i cÃ³ suggestion gÃ¬ cho bÃ i toÃ¡n nÃ y khÃ´ng áº¡, em xin cáº£m Æ¡n ^^",,,,,
"Hai chÆ°Æ¡ng chÃ­nh thá»©c cuá»‘i cÃ¹ng cá»§a cuá»‘n ""Dive into Deep Learning"" Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch xong:
https://d2l.aivivn.com/chapter_recommender-systems/index_vn.html
Hai chÆ°Æ¡ng nÃ y trÃ¬nh bÃ y cÃ¡c ká»¹ thuáº­t trong Há»‡ thá»‘ng Äá» xuáº¥t (Recommendation System) vÃ  GAN. Pháº§n cÃ²n láº¡i cá»§a cuá»‘n sÃ¡ch lÃ  cÃ¡c chÆ°Æ¡ng phá»¥ lá»¥c.","Hai chÆ°Æ¡ng chÃ­nh thá»©c cuá»‘i cÃ¹ng cá»§a cuá»‘n ""Dive into Deep Learning"" Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch xong: https://d2l.aivivn.com/chapter_recommender-systems/index_vn.html Hai chÆ°Æ¡ng nÃ y trÃ¬nh bÃ y cÃ¡c ká»¹ thuáº­t trong Há»‡ thá»‘ng Äá» xuáº¥t (Recommendation System) vÃ  GAN. Pháº§n cÃ²n láº¡i cá»§a cuá»‘n sÃ¡ch lÃ  cÃ¡c chÆ°Æ¡ng phá»¥ lá»¥c.",,,,,
"xin chÃ o má»i ngÆ°á»i áº¡
em má»›i táº­p code pytorch vÃ  tiá»‡n lÃ m bÃ i toÃ¡n regression x -> y vá»›i y lÃ  1 vector nhiá»u chiá»u e Ä‘Ã£ viáº¿t tá»± implement vá»›i hÃ m MSE thÃ nh cÃ´ng. nhÆ°ng Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c em muá»‘n thÃªm cáº£ hÃ m tÃ­nh cos vÃ o ná»¯a. NhÆ°ng cÃ³ váº» hÃ m cos nÃ³ khÃ´ng tÃ­nh backpropagation Ä‘Æ°á»£c hay sao Ã½. 
em Ä‘Äƒng post nÃ y mong cÃ¡c cao thá»§ giÃºp em vá»›i áº¡ .
hÃ m cos em viáº¿t tá»«ng viáº¿t Ä‘Ã¢y vÃ  nÃ³ khÃ´ng hoáº¡t Ä‘á»™ng :( 
import torch
def loss_cosin(y,y_pred):
    return -torch.nn.CosineSimilarity(y,y_pred).mean()","xin chÃ o má»i ngÆ°á»i áº¡ em má»›i táº­p code pytorch vÃ  tiá»‡n lÃ m bÃ i toÃ¡n regression x -> y vá»›i y lÃ  1 vector nhiá»u chiá»u e Ä‘Ã£ viáº¿t tá»± implement vá»›i hÃ m MSE thÃ nh cÃ´ng. nhÆ°ng Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c em muá»‘n thÃªm cáº£ hÃ m tÃ­nh cos vÃ o ná»¯a. NhÆ°ng cÃ³ váº» hÃ m cos nÃ³ khÃ´ng tÃ­nh backpropagation Ä‘Æ°á»£c hay sao Ã½. em Ä‘Äƒng post nÃ y mong cÃ¡c cao thá»§ giÃºp em vá»›i áº¡ . hÃ m cos em viáº¿t tá»«ng viáº¿t Ä‘Ã¢y vÃ  nÃ³ khÃ´ng hoáº¡t Ä‘á»™ng :( import torch def loss_cosin(y,y_pred): return -torch.nn.CosineSimilarity(y,y_pred).mean()",,,,,
"https://blog.facebit.net/2018/09/07/zalo-ai-challenge-problems-and-solutions/?fbclid=IwAR0WkkWSurvGy5xm2uowPzgtc52dBB8ueHSPMGpK4iFMakM8dAKqm5jooG4
Anh chá»‹ cho e há»i vá»›i áº¡. Em cÃ³ truy cáº­p vÃ o link zalo on chanllenge nÃ y Ä‘á»ƒ táº£i bá»™ dá»¯ liá»‡u vá» Challenge 3: Voice Gender/Accent Classification mÃ  hiá»‡n táº¡i link khÃ´ng táº£i Ä‘Æ°á»£c. Anh chá»‹ nÃ o cÃ³ bá»™ dá»¯ liá»‡u nÃ y cho e xin vá»›i áº¡. Em cáº£m Æ¡n.",https://blog.facebit.net/2018/09/07/zalo-ai-challenge-problems-and-solutions/?fbclid=IwAR0WkkWSurvGy5xm2uowPzgtc52dBB8ueHSPMGpK4iFMakM8dAKqm5jooG4 Anh chá»‹ cho e há»i vá»›i áº¡. Em cÃ³ truy cáº­p vÃ o link zalo on chanllenge nÃ y Ä‘á»ƒ táº£i bá»™ dá»¯ liá»‡u vá» Challenge 3: Voice Gender/Accent Classification mÃ  hiá»‡n táº¡i link khÃ´ng táº£i Ä‘Æ°á»£c. Anh chá»‹ nÃ o cÃ³ bá»™ dá»¯ liá»‡u nÃ y cho e xin vá»›i áº¡. Em cáº£m Æ¡n.,,,,,
"ChÃ o má»i ngÆ°á»i. E Ä‘ang cáº§n dataset Ä‘á»ƒ lÃ m á»©ng dá»¥ng nháº­n dáº¡ng tiáº¿ng nÃ³i. Input file audio vÃ  out vÃ¹ng miá»n nÃ o á»Ÿ VN, trai hay gÃ¡i ( zalo al change 2018 cÃ³ Ä‘á» tÃ i nayg mÃ  e vÃ o link táº£i khÃ´ng Ä‘x) anh chá»‹ nÃ o cÃ³ cho e xin vá»›i áº¡. Em cáº£m Æ¡n.","ChÃ o má»i ngÆ°á»i. E Ä‘ang cáº§n dataset Ä‘á»ƒ lÃ m á»©ng dá»¥ng nháº­n dáº¡ng tiáº¿ng nÃ³i. Input file audio vÃ  out vÃ¹ng miá»n nÃ o á»Ÿ VN, trai hay gÃ¡i ( zalo al change 2018 cÃ³ Ä‘á» tÃ i nayg mÃ  e vÃ o link táº£i khÃ´ng Ä‘x) anh chá»‹ nÃ o cÃ³ cho e xin vá»›i áº¡. Em cáº£m Æ¡n.",,,,,
"Do táº­p nhá»¯ng táº­p dá»¯ liá»‡u mÃ¬nh train hao hao giá»‘ng nhau nÃªnÄ‘á»ƒ tÄƒng tÃ­nh chÃ­nh xÃ¡c vÃ  giáº£m nhiá»…u khi train nhiá»u class, mÃ¬nh Ä‘Ã£ tÃ¡ch 2 bá»™ dá»¯ liá»‡u khÃ¡c nhau train thÃ nh 2 file weights.
Giá» Ä‘á»ƒ cho gá»n model, mÃ¬nh muá»‘n ghÃ©p 2 cÃ¡i Ä‘Ã³ thÃ nh 1 file chung, liá»‡u cÃ³ model há»— trá»£ cho viá»‡c Ä‘Ã³ khÃ´ng áº¡, hay pháº£i code káº¿t há»£p bÃªn ngoÃ i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.","Do táº­p nhá»¯ng táº­p dá»¯ liá»‡u mÃ¬nh train hao hao giá»‘ng nhau nÃªnÄ‘á»ƒ tÄƒng tÃ­nh chÃ­nh xÃ¡c vÃ  giáº£m nhiá»…u khi train nhiá»u class, mÃ¬nh Ä‘Ã£ tÃ¡ch 2 bá»™ dá»¯ liá»‡u khÃ¡c nhau train thÃ nh 2 file weights. Giá» Ä‘á»ƒ cho gá»n model, mÃ¬nh muá»‘n ghÃ©p 2 cÃ¡i Ä‘Ã³ thÃ nh 1 file chung, liá»‡u cÃ³ model há»— trá»£ cho viá»‡c Ä‘Ã³ khÃ´ng áº¡, hay pháº£i code káº¿t há»£p bÃªn ngoÃ i áº¡. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"Má»i ngÆ°á»i cho em há»i náº¿u há»c ML thÃ¬ cÃ³ cáº§n biáº¿t vá» máº¡ch Ä‘iá»‡n tá»­ ko áº¡? Nhá»¯ng cÃ´ng viá»‡c cá»¥ thá»ƒ Ä‘á»ƒ cÃ³ thá»ƒ lÃ m sau khi tá»‘t nghiá»‡p, e Ä‘ang phÃ¢n vÃ¢n giá»¯a data analyst vá»›i computer vision, 1 cÃ¢u há»i nháº¡y cáº£m lÃ  má»©c lÆ°Æ¡ng nÃ³ ntn áº¡? E lÃ  newbie, thank m.n","Má»i ngÆ°á»i cho em há»i náº¿u há»c ML thÃ¬ cÃ³ cáº§n biáº¿t vá» máº¡ch Ä‘iá»‡n tá»­ ko áº¡? Nhá»¯ng cÃ´ng viá»‡c cá»¥ thá»ƒ Ä‘á»ƒ cÃ³ thá»ƒ lÃ m sau khi tá»‘t nghiá»‡p, e Ä‘ang phÃ¢n vÃ¢n giá»¯a data analyst vá»›i computer vision, 1 cÃ¢u há»i nháº¡y cáº£m lÃ  má»©c lÆ°Æ¡ng nÃ³ ntn áº¡? E lÃ  newbie, thank m.n",,,,,
Em hoÃ n thÃ nh xong khoÃ¡ ML cá»§a tháº§y Andrew rá»“i giá» em muá»‘n há»c sau hÆ¡n vá» pháº§n toÃ¡n thÃ¬ nÃªn há»c khoÃ¡ nÃ o ná»¯a áº¡?,Em hoÃ n thÃ nh xong khoÃ¡ ML cá»§a tháº§y Andrew rá»“i giá» em muá»‘n há»c sau hÆ¡n vá» pháº§n toÃ¡n thÃ¬ nÃªn há»c khoÃ¡ nÃ o ná»¯a áº¡?,,,"#Q&A, #math, #machine_learning",,
"#Object_Detection
ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» model mobilenet SSD v1. Theo em hiá»ƒu Æ°u Ä‘iá»ƒm cá»§a model nÃ y káº¿t há»£p giá»¯a mobilenet (pháº§n embedding) vÃ  SSD giÃºp triá»ƒn khai mÃ´ hÃ¬nh object detection nhanh hÆ¡n (Ä‘á»™ chÃ­nh xÃ¡c kÃ©m hÆ¡n SSD nhÆ°ng k Ä‘Ã¡ng ká»ƒ), cÃ³ thá»ƒ cháº¡y realtime trÃªn cÃ¡c thiáº¿t bá»‹ nhÆ° jetson nano. KhÃ´ng biáº¿t em hiá»ƒu Ä‘Ãºng k, mong anh chá»‹ giÃºp em hiá»ƒu thÃªm vá»›i. náº¿u Ä‘Æ°á»£c thÃ¬ nÃ³i giÃºp em thÃªm pháº§n Æ°u Ä‘iá»ƒm vá»›i. Em cáº£m Æ¡n nhiá»u áº¡.","ChÃ o má»i ngÆ°á»i, em Ä‘ang tÃ¬m hiá»ƒu vá» model mobilenet SSD v1. Theo em hiá»ƒu Æ°u Ä‘iá»ƒm cá»§a model nÃ y káº¿t há»£p giá»¯a mobilenet (pháº§n embedding) vÃ  SSD giÃºp triá»ƒn khai mÃ´ hÃ¬nh object detection nhanh hÆ¡n (Ä‘á»™ chÃ­nh xÃ¡c kÃ©m hÆ¡n SSD nhÆ°ng k Ä‘Ã¡ng ká»ƒ), cÃ³ thá»ƒ cháº¡y realtime trÃªn cÃ¡c thiáº¿t bá»‹ nhÆ° jetson nano. KhÃ´ng biáº¿t em hiá»ƒu Ä‘Ãºng k, mong anh chá»‹ giÃºp em hiá»ƒu thÃªm vá»›i. náº¿u Ä‘Æ°á»£c thÃ¬ nÃ³i giÃºp em thÃªm pháº§n Æ°u Ä‘iá»ƒm vá»›i. Em cáº£m Æ¡n nhiá»u áº¡.",#Object_Detection,,,,
"ChÃ o cÃ¡c báº¡n, Vietnam Document Analysis group (VnDAG) & AiViVn Ä‘ang lÃªn káº¿ hoáº¡ch tá»• chá»©c challenge cho nháº­n dáº¡ng hoÃ¡ Ä‘Æ¡n tiáº¿ng Viá»‡t. NhÃ³m mong sá»± trá»£ giÃºp tá»« cÃ¡c báº¡n báº±ng cÃ¡ch chá»¥p áº£nh báº¥t ká»³ hoÃ¡ Ä‘Æ¡n mua bÃ¡n (vÃ­ dá»¥ hoÃ¡ Ä‘Æ¡n siÃªu thá»‹) mÃ  báº¡n cÃ³ vÃ  upload qua dá»‹ch vá»¥ cá»§a nhÃ³m. Chi tiáº¿t mÃ´ táº£ nhÆ° sau:
- 1. HoÃ¡ Ä‘Æ¡n dáº¡ng dÃ i, ná»™i dung lÃ  cÃ¡c sáº£n pháº©m mua sáº¯m vÃ  giÃ¡ tiá»n (xem áº£nh vÃ­ dá»¥).
- 2. HoÃ¡ Ä‘Æ¡n cáº§n báº±ng tiáº¿ng Viá»‡t, cáº§n rÃµ ná»™i dung, ko bá»‹ nhoÃ¨ chá»¯. MÃ¬nh cÃ³ Ä‘Ã­nh kÃ¨m 2 áº£nh: 1 áº£nh tiáº¿ng viá»‡t vÃ  1 áº£nh vÃ­ dá»¥ tuy ko pháº³ng nhÆ°ng váº«n Ä‘áº¡t cháº¥t lÆ°á»£ng.
- 3. Báº¡n chá»¥p vÃ  upload áº£nh chá»¥p qua website: http://vndag.vietnlp.com. Náº¿u báº¡n cÃ³ nhiá»u hoÃ¡ Ä‘Æ¡n, báº¡n cÃ³ thá»ƒ gá»­i nhiá»u láº§n hoáº·c nÃ©n vÃ  gá»­i file nÃ©n.
- 4. Thá»i gian Ä‘Ã³ng gÃ³p hoÃ¡ Ä‘Æ¡n: 5 ngÃ y (tá»« ngÃ y Aug 13 - Aug 18).
- Äá»ƒ Ä‘á»§ dá»¯ liá»‡u cho challenge Ä‘Æ°á»£c thá»±c hiá»‡n, nhÃ³m xÃ¡c Ä‘á»‹nh cáº§n 2000 - 3000 hoÃ¡ Ä‘Æ¡n. NÃªn náº¿u má»—i thÃ nh viÃªn Ä‘á»c Ä‘Æ°á»£c bÃ i Ä‘Ã³ng gÃ³p 1 hoÃ¡ Ä‘Æ¡n lÃ  nhÃ³m Ä‘Ã£ cÃ³ Ä‘á»§ sá»‘ lÆ°á»£ng Ä‘á»ƒ tiáº¿n hÃ nh annotate dá»¯ liá»‡u cho challenge.
Ráº¥t mong sá»± Ä‘Ã³ng gÃ³p dá»¯ liá»‡u vÃ  tham gia nhiá»‡t tÃ¬nh tá»« cÃ¡c báº¡n cho challenge sáº¯p tá»›i.
PS. NhÃ³m VnDAG cÃ³ tuyá»ƒn 2 cá»™ng tÃ¡c viÃªn lÃ  cÃ¡c báº¡n sinh viÃªn nhiá»‡t tÃ¬nh vÃ  cÃ³ Ä‘am mÃª nghiÃªn cá»©u lÄ©nh vá»±c Document Analysis. CÆ¡ há»™i Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ tham gia vÃ o nghiÃªn cá»©u cÃ¡c challenges thá»±c táº¿, tiáº¿p cáº­n vÃ  há»c há»i / trao Ä‘á»•i cÃ¡c kiáº¿n thá»©c má»›i nháº¥t cÅ©ng nhÆ° Ä‘Æ°á»£c mentor bá»Ÿi cÃ¡c tiá»n bá»‘i trong domain nÃ y trÃªn tháº¿ giá»›i. CÃ¡c báº¡n gá»­i email kÃ¨m CV Ä‘áº¿n vndag@vietnlp.com Ä‘á»ƒ Ä‘Æ°á»£c liÃªn há»‡ vÃ  trao Ä‘á»•i chi tiáº¿t.","ChÃ o cÃ¡c báº¡n, Vietnam Document Analysis group (VnDAG) & AiViVn Ä‘ang lÃªn káº¿ hoáº¡ch tá»• chá»©c challenge cho nháº­n dáº¡ng hoÃ¡ Ä‘Æ¡n tiáº¿ng Viá»‡t. NhÃ³m mong sá»± trá»£ giÃºp tá»« cÃ¡c báº¡n báº±ng cÃ¡ch chá»¥p áº£nh báº¥t ká»³ hoÃ¡ Ä‘Æ¡n mua bÃ¡n (vÃ­ dá»¥ hoÃ¡ Ä‘Æ¡n siÃªu thá»‹) mÃ  báº¡n cÃ³ vÃ  upload qua dá»‹ch vá»¥ cá»§a nhÃ³m. Chi tiáº¿t mÃ´ táº£ nhÆ° sau: - 1. HoÃ¡ Ä‘Æ¡n dáº¡ng dÃ i, ná»™i dung lÃ  cÃ¡c sáº£n pháº©m mua sáº¯m vÃ  giÃ¡ tiá»n (xem áº£nh vÃ­ dá»¥). - 2. HoÃ¡ Ä‘Æ¡n cáº§n báº±ng tiáº¿ng Viá»‡t, cáº§n rÃµ ná»™i dung, ko bá»‹ nhoÃ¨ chá»¯. MÃ¬nh cÃ³ Ä‘Ã­nh kÃ¨m 2 áº£nh: 1 áº£nh tiáº¿ng viá»‡t vÃ  1 áº£nh vÃ­ dá»¥ tuy ko pháº³ng nhÆ°ng váº«n Ä‘áº¡t cháº¥t lÆ°á»£ng. - 3. Báº¡n chá»¥p vÃ  upload áº£nh chá»¥p qua website: http://vndag.vietnlp.com. Náº¿u báº¡n cÃ³ nhiá»u hoÃ¡ Ä‘Æ¡n, báº¡n cÃ³ thá»ƒ gá»­i nhiá»u láº§n hoáº·c nÃ©n vÃ  gá»­i file nÃ©n. - 4. Thá»i gian Ä‘Ã³ng gÃ³p hoÃ¡ Ä‘Æ¡n: 5 ngÃ y (tá»« ngÃ y Aug 13 - Aug 18). - Äá»ƒ Ä‘á»§ dá»¯ liá»‡u cho challenge Ä‘Æ°á»£c thá»±c hiá»‡n, nhÃ³m xÃ¡c Ä‘á»‹nh cáº§n 2000 - 3000 hoÃ¡ Ä‘Æ¡n. NÃªn náº¿u má»—i thÃ nh viÃªn Ä‘á»c Ä‘Æ°á»£c bÃ i Ä‘Ã³ng gÃ³p 1 hoÃ¡ Ä‘Æ¡n lÃ  nhÃ³m Ä‘Ã£ cÃ³ Ä‘á»§ sá»‘ lÆ°á»£ng Ä‘á»ƒ tiáº¿n hÃ nh annotate dá»¯ liá»‡u cho challenge. Ráº¥t mong sá»± Ä‘Ã³ng gÃ³p dá»¯ liá»‡u vÃ  tham gia nhiá»‡t tÃ¬nh tá»« cÃ¡c báº¡n cho challenge sáº¯p tá»›i. PS. NhÃ³m VnDAG cÃ³ tuyá»ƒn 2 cá»™ng tÃ¡c viÃªn lÃ  cÃ¡c báº¡n sinh viÃªn nhiá»‡t tÃ¬nh vÃ  cÃ³ Ä‘am mÃª nghiÃªn cá»©u lÄ©nh vá»±c Document Analysis. CÆ¡ há»™i Ä‘á»ƒ cÃ¡c báº¡n cÃ³ thá»ƒ tham gia vÃ o nghiÃªn cá»©u cÃ¡c challenges thá»±c táº¿, tiáº¿p cáº­n vÃ  há»c há»i / trao Ä‘á»•i cÃ¡c kiáº¿n thá»©c má»›i nháº¥t cÅ©ng nhÆ° Ä‘Æ°á»£c mentor bá»Ÿi cÃ¡c tiá»n bá»‘i trong domain nÃ y trÃªn tháº¿ giá»›i. CÃ¡c báº¡n gá»­i email kÃ¨m CV Ä‘áº¿n vndag@vietnlp.com Ä‘á»ƒ Ä‘Æ°á»£c liÃªn há»‡ vÃ  trao Ä‘á»•i chi tiáº¿t.",,,,,
"Em chÃ o cÃ¡c bÃ¡c!
Hiá»‡n táº¡i em tÃ¬m hiá»ƒu bÃ i toÃ¡n IDcard detection, vá»›i output nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m.
Ban Ä‘áº§u em sá»­ dá»¥ng Opencv Ä‘á»ƒ giáº£i quyáº¿t nhÆ°ng khÃ´ng kháº£ thi láº¯m, tháº¥y nÃ³ chá»‰ tá»‘t khi background khÃ´ng quÃ¡ nhiá»u nhiá»…u.
Em tÃ­nh dÃ¹ng ML, trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu thÃ¬ tháº¥y cÃ³ má»™t vÃ i hÆ°á»›ng nhÆ° sau:
1. TÃ¬m 4 Ä‘iá»ƒm gÃ³c (keypoint detection - Kiá»ƒu bÃ i toÃ¡n human pose estimation).
2. Segmentation.
3. Coi 4 gÃ³c lÃ  Ä‘á»‘i tÆ°á»£ng => object detection (Giáº£i phÃ¡p nÃ y em tham kháº£o bÃªn FPT)
4. Text detection => bouding box
VÃ  cáº§n > 5 FPS (náº¿u mÃ  trÃªn mobile deivce thÃ¬ cÃ ng tá»‘t áº¡)
Hiá»‡n táº¡i em chÆ°a Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c phÆ°Æ¡ng phÃ¡p nÃ o kháº£ khi nháº¥t, ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a cÃ¡c bÃ¡c áº¡.
CÃ¡m Æ¡n cÃ¡c bÃ¡c, chÃºc cÃ¡c bÃ¡c má»™t ngÃ y lÃ m viá»‡c hiá»‡u quáº£ :D","Em chÃ o cÃ¡c bÃ¡c! Hiá»‡n táº¡i em tÃ¬m hiá»ƒu bÃ i toÃ¡n IDcard detection, vá»›i output nhÆ° hÃ¬nh Ä‘Ã­nh kÃ¨m. Ban Ä‘áº§u em sá»­ dá»¥ng Opencv Ä‘á»ƒ giáº£i quyáº¿t nhÆ°ng khÃ´ng kháº£ thi láº¯m, tháº¥y nÃ³ chá»‰ tá»‘t khi background khÃ´ng quÃ¡ nhiá»u nhiá»…u. Em tÃ­nh dÃ¹ng ML, trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu thÃ¬ tháº¥y cÃ³ má»™t vÃ i hÆ°á»›ng nhÆ° sau: 1. TÃ¬m 4 Ä‘iá»ƒm gÃ³c (keypoint detection - Kiá»ƒu bÃ i toÃ¡n human pose estimation). 2. Segmentation. 3. Coi 4 gÃ³c lÃ  Ä‘á»‘i tÆ°á»£ng => object detection (Giáº£i phÃ¡p nÃ y em tham kháº£o bÃªn FPT) 4. Text detection => bouding box VÃ  cáº§n > 5 FPS (náº¿u mÃ  trÃªn mobile deivce thÃ¬ cÃ ng tá»‘t áº¡) Hiá»‡n táº¡i em chÆ°a Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c phÆ°Æ¡ng phÃ¡p nÃ o kháº£ khi nháº¥t, ráº¥t mong nháº­n Ä‘Æ°á»£c gÃ³p Ã½ cá»§a cÃ¡c bÃ¡c áº¡. CÃ¡m Æ¡n cÃ¡c bÃ¡c, chÃºc cÃ¡c bÃ¡c má»™t ngÃ y lÃ m viá»‡c hiá»‡u quáº£ :D",,,,,
"#tensorflow
Em chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em cÃ³ 1 váº¥n Ä‘á» liÃªn quan dáº¿n tensorflow nhÆ° sau mong cÃ³ ai Ä‘Ã£ tá»«ng gáº·p pháº£i cho em cÃ¡ch sá»­a lá»—i.
áº¢nh thá»© nháº¥t lÃ  dataloader cá»§a em,theo em hiá»ƒu thÃ¬ sáº½ táº¡o ra 1 data_generator.
áº¢Nh thá»© 2 lÃ  hÃ m loss cá»§a em. VÃ  khi em in ra y_true,y_pred nhÆ° áº£nh 2 cÃ³ code thÃ¬ nÃ³ ko in ra tensor chá»©a sá»‘ liá»‡u mÃ  sáº½ ra nhÆ° hÃ¬nh thá»© 3.
Em cÃ³ xá»­ lÃ½ Ä‘iá»u Ä‘Ã³ báº±ng cÃ¡ch thÃªm 2 Ä‘oáº¡n code á»Ÿ hÃ¬nh thá»© 4.Äiá»u Ä‘Ã³ giÃºp em hoáº¡t Ä‘á»™ng á»Ÿ 1 máº¡ng khÃ¡c.
Tuy nhiÃªn á»Ÿ máº¡ng nÃ y cá»§a em thÃ¬ nÃ³ gÃ¢y ra lá»—i á»Ÿ hÃ¬nh thá»© 5, cÃ³ trá» Ä‘áº¿n lá»—i xuáº¥t phÃ¡t á»Ÿ viá»‡c gá»i model EfficientNetB0 á»Ÿ hÃ¬nh thá»© 6.
2 cÃ¡i bá»‹ config vá»›i nhau nÃªn em ko biáº¿t xá»­ lÃ½ tháº¿ nÃ o. Ko biáº¿t cÃ³ ai cÃ³ cao kiáº¿n gÃ¬ ko.
VÃ¬ váº¥n dá» khÃ¡ láº±ng nháº±ng nÃªn hi vá»ng cÃ³ ngÆ°á»i hiá»ƒu Ä‘Æ°á»£c Ã½ e :)))
Em cáº£m Æ¡n","Em chÃ o má»i ngÆ°á»i. Hiá»‡n táº¡i em cÃ³ 1 váº¥n Ä‘á» liÃªn quan dáº¿n tensorflow nhÆ° sau mong cÃ³ ai Ä‘Ã£ tá»«ng gáº·p pháº£i cho em cÃ¡ch sá»­a lá»—i. áº¢nh thá»© nháº¥t lÃ  dataloader cá»§a em,theo em hiá»ƒu thÃ¬ sáº½ táº¡o ra 1 data_generator. áº¢Nh thá»© 2 lÃ  hÃ m loss cá»§a em. VÃ  khi em in ra y_true,y_pred nhÆ° áº£nh 2 cÃ³ code thÃ¬ nÃ³ ko in ra tensor chá»©a sá»‘ liá»‡u mÃ  sáº½ ra nhÆ° hÃ¬nh thá»© 3. Em cÃ³ xá»­ lÃ½ Ä‘iá»u Ä‘Ã³ báº±ng cÃ¡ch thÃªm 2 Ä‘oáº¡n code á»Ÿ hÃ¬nh thá»© 4.Äiá»u Ä‘Ã³ giÃºp em hoáº¡t Ä‘á»™ng á»Ÿ 1 máº¡ng khÃ¡c. Tuy nhiÃªn á»Ÿ máº¡ng nÃ y cá»§a em thÃ¬ nÃ³ gÃ¢y ra lá»—i á»Ÿ hÃ¬nh thá»© 5, cÃ³ trá» Ä‘áº¿n lá»—i xuáº¥t phÃ¡t á»Ÿ viá»‡c gá»i model EfficientNetB0 á»Ÿ hÃ¬nh thá»© 6. 2 cÃ¡i bá»‹ config vá»›i nhau nÃªn em ko biáº¿t xá»­ lÃ½ tháº¿ nÃ o. Ko biáº¿t cÃ³ ai cÃ³ cao kiáº¿n gÃ¬ ko. VÃ¬ váº¥n dá» khÃ¡ láº±ng nháº±ng nÃªn hi vá»ng cÃ³ ngÆ°á»i hiá»ƒu Ä‘Æ°á»£c Ã½ e :))) Em cáº£m Æ¡n",#tensorflow,,,,
"[Human-learn]
Human learn lÃ  má»™t cÃ´ng cá»¥ cho phÃ©p báº¡n váº½ qua cÃ¡c táº­p dá»¯ liá»‡u cá»§a mÃ¬nh. Nhá»¯ng báº£n váº½ nÃ y sau Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh mÃ´ hÃ¬nh hoáº·c thÃ nh cÃ¡c cÃ´ng cá»¥ tiá»n xá»­ lÃ½. NgoÃ i ra, Human learn cÃ³ thá»ƒ káº¿t há»£p vá»›i scikit-learn giÃºp cho viá»‡c tiá»n xá»­ lÃ­ vÃ  xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh dá»… dÃ ng hÆ¡n.
Má»™t sá»‘ mÃ´ hÃ¬nh Ä‘Æ°á»£c há»— trá»£:
- Classification Models
- Regression Models
- Outlier Detection Models
- Preprocessing Models
Github: https://github.com/koaning/human-learn
Document: https://koaning.github.io/human-learn/","[Human-learn] Human learn lÃ  má»™t cÃ´ng cá»¥ cho phÃ©p báº¡n váº½ qua cÃ¡c táº­p dá»¯ liá»‡u cá»§a mÃ¬nh. Nhá»¯ng báº£n váº½ nÃ y sau Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh mÃ´ hÃ¬nh hoáº·c thÃ nh cÃ¡c cÃ´ng cá»¥ tiá»n xá»­ lÃ½. NgoÃ i ra, Human learn cÃ³ thá»ƒ káº¿t há»£p vá»›i scikit-learn giÃºp cho viá»‡c tiá»n xá»­ lÃ­ vÃ  xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh dá»… dÃ ng hÆ¡n. Má»™t sá»‘ mÃ´ hÃ¬nh Ä‘Æ°á»£c há»— trá»£: - Classification Models - Regression Models - Outlier Detection Models - Preprocessing Models Github: https://github.com/koaning/human-learn Document: https://koaning.github.io/human-learn/",,,,,
"ChÃ o cÃ¡c bÃ¡c,
Em Ä‘ang muá»‘n sá»­ dá»¥ng ML Ä‘á»ƒ phÃ¢n tÃ­ch cÃ¡c log cá»§a mÃ¡y chá»§ (vÃ­ dá»¥: IIS log, ...) Ä‘á»ƒ phÃ¢n biá»‡t Ä‘Ã¢u lÃ  truy cáº­p bÃ¬nh thÆ°á»ng, Ä‘Ã¢u lÃ  truy cáº­p báº¥t thÆ°á»ng nhÆ°ng em chÆ°a cÃ³ hÆ°á»›ng Ä‘i nÃ o cáº£.
Mong cÃ¡c bÃ¡c gá»£i Ã½ cá»¥ thá»ƒ giÃºp em áº¡.
Em má»›i tiáº¿p cáº­n ML nÃªn mong cÃ¡c bÃ¡c gá»£i Ã½ cÃ ng chi tiáº¿t cÃ ng tá»‘t áº¡. Em muá»‘n tá»« bÃ i toÃ¡n nÃ y Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ Ä‘á»™ng lá»±c Ä‘á»ƒ Ä‘i sÃ¢u tÃ¬m hiá»ƒu ML áº¡.
Cáº£m Æ¡n cÃ¡c bÃ¡c nhiá»u.","ChÃ o cÃ¡c bÃ¡c, Em Ä‘ang muá»‘n sá»­ dá»¥ng ML Ä‘á»ƒ phÃ¢n tÃ­ch cÃ¡c log cá»§a mÃ¡y chá»§ (vÃ­ dá»¥: IIS log, ...) Ä‘á»ƒ phÃ¢n biá»‡t Ä‘Ã¢u lÃ  truy cáº­p bÃ¬nh thÆ°á»ng, Ä‘Ã¢u lÃ  truy cáº­p báº¥t thÆ°á»ng nhÆ°ng em chÆ°a cÃ³ hÆ°á»›ng Ä‘i nÃ o cáº£. Mong cÃ¡c bÃ¡c gá»£i Ã½ cá»¥ thá»ƒ giÃºp em áº¡. Em má»›i tiáº¿p cáº­n ML nÃªn mong cÃ¡c bÃ¡c gá»£i Ã½ cÃ ng chi tiáº¿t cÃ ng tá»‘t áº¡. Em muá»‘n tá»« bÃ i toÃ¡n nÃ y Ä‘á»ƒ cÃ³ thá»ƒ cÃ³ Ä‘á»™ng lá»±c Ä‘á»ƒ Ä‘i sÃ¢u tÃ¬m hiá»ƒu ML áº¡. Cáº£m Æ¡n cÃ¡c bÃ¡c nhiá»u.",,,,,
"ChÃ o má»i ngÆ°á»i, em Ä‘ang muá»‘n xuáº¥t frame áº£nh tá»« videos trÃªn google colab, code bÃªn dÆ°á»›i cháº¡y khÃ´ng ra káº¿t quáº£, mong má»i ngÆ°á»i xem vÃ  hÆ°á»›ng dáº«n giÃºp, em cáº£m Æ¡n áº¡.
Edited: Code cháº¡y Ä‘Æ°á»£c rá»“i, e cáº£m Æ¡n mng nhiá»u áº¡ ğŸ˜€","ChÃ o má»i ngÆ°á»i, em Ä‘ang muá»‘n xuáº¥t frame áº£nh tá»« videos trÃªn google colab, code bÃªn dÆ°á»›i cháº¡y khÃ´ng ra káº¿t quáº£, mong má»i ngÆ°á»i xem vÃ  hÆ°á»›ng dáº«n giÃºp, em cáº£m Æ¡n áº¡. Edited: Code cháº¡y Ä‘Æ°á»£c rá»“i, e cáº£m Æ¡n mng nhiá»u áº¡",,,,,
"xin chÃ o cÃ¡c ace, mÃ¬nh má»›i báº¯t Ä‘áº§u há»c vá» lÄ©nh vá»±c nÃ y vÃ  báº¯t Ä‘áº§u há»c pháº§n Neuron Network Ä‘áº§u tiÃªn. MÃ¬nh Ä‘ang vÆ°á»›ng á»Ÿ 3 cÃ¢u há»i mÃ  mÃ¬nh chÆ°a hiá»ƒu vÃ  chÆ°a lÃ m Ä‘Æ°á»£c. Ace nÃ o ráº£nh giÃºp mÃ¬nh vá»›i a?
1. Design a NAND-gate using a network of McCulloch and Pitts neurons
2. Create a 4-bit adder using McCulloch and Pitts neurons
3. Create a 4-bit subtractor using McCulloch and Pitts neurons
MÃ¬nh cáº£m Æ¡n áº¡","xin chÃ o cÃ¡c ace, mÃ¬nh má»›i báº¯t Ä‘áº§u há»c vá» lÄ©nh vá»±c nÃ y vÃ  báº¯t Ä‘áº§u há»c pháº§n Neuron Network Ä‘áº§u tiÃªn. MÃ¬nh Ä‘ang vÆ°á»›ng á»Ÿ 3 cÃ¢u há»i mÃ  mÃ¬nh chÆ°a hiá»ƒu vÃ  chÆ°a lÃ m Ä‘Æ°á»£c. Ace nÃ o ráº£nh giÃºp mÃ¬nh vá»›i a? 1. Design a NAND-gate using a network of McCulloch and Pitts neurons 2. Create a 4-bit adder using McCulloch and Pitts neurons 3. Create a 4-bit subtractor using McCulloch and Pitts neurons MÃ¬nh cáº£m Æ¡n áº¡",,,,,
"[GÃ³c xin data]
Em Ä‘ang lÃ m Ä‘á»“ Ã¡n cáº§n data vá» cÃ¡c hÃ³a Ä‘Æ¡n: siÃªu thá»‹,Ä‘iá»‡n ,nÆ°á»›c...Anh chá»‹ nÃ o cÃ³ data cÃ³ thá»ƒ public thÃ¬ share cho em vá»›i Ä‘Æ°á»£c khÃ´ng áº¡.
Cáº£m Æ¡n má»i ngÆ°á»i !!!!","[GÃ³c xin data] Em Ä‘ang lÃ m Ä‘á»“ Ã¡n cáº§n data vá» cÃ¡c hÃ³a Ä‘Æ¡n: siÃªu thá»‹,Ä‘iá»‡n ,nÆ°á»›c...Anh chá»‹ nÃ o cÃ³ data cÃ³ thá»ƒ public thÃ¬ share cho em vá»›i Ä‘Æ°á»£c khÃ´ng áº¡. Cáº£m Æ¡n má»i ngÆ°á»i !!!!",,,,,
ChÃ o má»i ngÆ°á»i áº¡. Em lÃ  há»c sinh lá»›p 10 muá»‘n há»c vá» Machine learning nhÆ°ng bá»‹ thiáº¿u kiáº¿n thá»©c toÃ¡n thÃ¬ em pháº£i bá»• sung á»Ÿ Ä‘Ã¢u áº¡? Em Ä‘á»c sÃ¡ch Machine Learning cÆ¡ báº£n nhÆ°ng bá»‹ thiáº¿u kiáº¿n thá»©c toÃ¡n nÃªn em tháº¥y khÃ³ hiá»ƒu quÃ¡ áº¡. Em pháº£i bá»• sung nhá»¯ng kiáº¿n thá»©c toÃ¡n gÃ¬ áº¡? Em cáº£m Æ¡n,ChÃ o má»i ngÆ°á»i áº¡. Em lÃ  há»c sinh lá»›p 10 muá»‘n há»c vá» Machine learning nhÆ°ng bá»‹ thiáº¿u kiáº¿n thá»©c toÃ¡n thÃ¬ em pháº£i bá»• sung á»Ÿ Ä‘Ã¢u áº¡? Em Ä‘á»c sÃ¡ch Machine Learning cÆ¡ báº£n nhÆ°ng bá»‹ thiáº¿u kiáº¿n thá»©c toÃ¡n nÃªn em tháº¥y khÃ³ hiá»ƒu quÃ¡ áº¡. Em pháº£i bá»• sung nhá»¯ng kiáº¿n thá»©c toÃ¡n gÃ¬ áº¡? Em cáº£m Æ¡n,,,"#Q&A, #math, #machine_learning",,
"ChÃ o anh chá»‹, em cÃ³ giÃ¡ trá»‹ mean = 164, standard deviation = 6, má»™t biáº¿n X cÃ³ z-score = 1.67 vÃ  giÃ¡ trá»‹ cá»§a X = 174, váº­y lÃ m sao Ä‘á»ƒ em tÃ¬m biáº¿t Ä‘Æ°á»£c Ä‘iá»ƒm X nÃ y thuá»™c phÃ¢n vá»‹ thá»© máº¥y áº¡, em cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o anh chá»‹, em cÃ³ giÃ¡ trá»‹ mean = 164, standard deviation = 6, má»™t biáº¿n X cÃ³ z-score = 1.67 vÃ  giÃ¡ trá»‹ cá»§a X = 174, váº­y lÃ m sao Ä‘á»ƒ em tÃ¬m biáº¿t Ä‘Æ°á»£c Ä‘iá»ƒm X nÃ y thuá»™c phÃ¢n vá»‹ thá»© máº¥y áº¡, em cáº£m Æ¡n má»i ngÆ°á»i.",,,"#Q&A, #math",,
"KÃ­nh chÃ o cÃ¡c bÃ¡c, hiá»‡n nay kÃªnh youtube MÃ¬ AI vá»«a ra thÃªm series MÃ¬ Ãšp Ä‘á»ƒ giáº£i quyáº¿t nhanh cÃ¡c vÆ°á»›ng máº¯c cá»§a cÃ¡c báº¡n má»›i há»c.
ÄÃ¢y lÃ  series gá»“m cÃ¡c clip ngáº¯n (5,10 phÃºt) Ä‘á»ƒ táº­p trung duy nháº¥t vÃ o má»™t váº¥n Ä‘á» nÃ o Ä‘Ã³.
Mong cÃ¡c bÃ¡c á»§ng há»™ vÃ  chá»‰ giÃ¡o!","KÃ­nh chÃ o cÃ¡c bÃ¡c, hiá»‡n nay kÃªnh youtube MÃ¬ AI vá»«a ra thÃªm series MÃ¬ Ãšp Ä‘á»ƒ giáº£i quyáº¿t nhanh cÃ¡c vÆ°á»›ng máº¯c cá»§a cÃ¡c báº¡n má»›i há»c. ÄÃ¢y lÃ  series gá»“m cÃ¡c clip ngáº¯n (5,10 phÃºt) Ä‘á»ƒ táº­p trung duy nháº¥t vÃ o má»™t váº¥n Ä‘á» nÃ o Ä‘Ã³. Mong cÃ¡c bÃ¡c á»§ng há»™ vÃ  chá»‰ giÃ¡o!",,,,,
"hi má»i ngÆ°á»i, cho mÃ¬nh há»i cÃ¢u há»i nhanh:
Náº¿u training data cÃ³ labels nhÆ°ng test data thÃ¬ láº¡i khÃ´ng. ThÃ¬ lÃ m sao biáº¿t model perform tháº¿ nÃ o trÃªn test data?
Thanks, má»i ngÆ°á»i","hi má»i ngÆ°á»i, cho mÃ¬nh há»i cÃ¢u há»i nhanh: Náº¿u training data cÃ³ labels nhÆ°ng test data thÃ¬ láº¡i khÃ´ng. ThÃ¬ lÃ m sao biáº¿t model perform tháº¿ nÃ o trÃªn test data? Thanks, má»i ngÆ°á»i",,,,,
"Buá»•i há»™i tháº£o online trao Ä‘á»•i vá»›i Professor Alon Halevy, Director of Facebook AI, Professor táº¡i University of Washington cho báº¡n nÃ o quan tÃ¢m :)","Buá»•i há»™i tháº£o online trao Ä‘á»•i vá»›i Professor Alon Halevy, Director of Facebook AI, Professor táº¡i University of Washington cho báº¡n nÃ o quan tÃ¢m :)",,,,,
ChÃ o anh chá»‹ áº¡. Em Ä‘ang tÃ¬m hiá»ƒu vá» Model Faster R-CNN vÃ  code báº±ng Python. Anh/chá»‹ nÃ o am hiá»ƒu pháº§n nÃ y thÃ¬ cÃ³ thá»ƒ cho e há»i má»™t tÃ½ Ä‘Æ°á»£c k áº¡. VÃ¬ cÃ³ nhiá»u khÃºc máº¯c nÃªn k tiá»‡n Ä‘Äƒng lÃªn Ä‘á»ƒ má»i ngÆ°á»i bÃ n luáº­n. Náº¿u Ä‘Æ°á»£c thÃ¬ cho em ib riÃªng Ä‘á»ƒ khÃ´ng phiá»n Ä‘áº¿n nhá»¯ng ngÆ°á»i khÃ¡c áº¡. Em cáº£m Æ¡n. Mong Ad duyá»‡t bÃ i áº¡,ChÃ o anh chá»‹ áº¡. Em Ä‘ang tÃ¬m hiá»ƒu vá» Model Faster R-CNN vÃ  code báº±ng Python. Anh/chá»‹ nÃ o am hiá»ƒu pháº§n nÃ y thÃ¬ cÃ³ thá»ƒ cho e há»i má»™t tÃ½ Ä‘Æ°á»£c k áº¡. VÃ¬ cÃ³ nhiá»u khÃºc máº¯c nÃªn k tiá»‡n Ä‘Äƒng lÃªn Ä‘á»ƒ má»i ngÆ°á»i bÃ n luáº­n. Náº¿u Ä‘Æ°á»£c thÃ¬ cho em ib riÃªng Ä‘á»ƒ khÃ´ng phiá»n Ä‘áº¿n nhá»¯ng ngÆ°á»i khÃ¡c áº¡. Em cáº£m Æ¡n. Mong Ad duyá»‡t bÃ i áº¡,,,,,
"ChÃ o má»i ngÆ°á»i. MÃ¬nh cÃ³ cÃ¢u há»i muá»‘n Ä‘c giáº£i Ä‘Ã¡p: trong quÃ¡ trÃ¬nh chuyá»ƒn task tá»« image retrieval sang image classification thÃ¬ nhá»¯ng bÆ°á»›c cáº§n lÃ m lÃ  gÃ¬? CÃ³ Æ°u tiÃªn cá»¥ thá»ƒ nÃ o ko? Máº·c Ä‘á»‹nh cÃ¡c khÃ¢u khÃ¡c nhÆ° data, model, loss function, training, retrieval function Ä‘á»u Ä‘Ã£ cÃ³ sáºµn.
CÃ¡m Æ¡n má»i ngÆ°á»i trÆ°á»›c nhÃ©!","ChÃ o má»i ngÆ°á»i. MÃ¬nh cÃ³ cÃ¢u há»i muá»‘n Ä‘c giáº£i Ä‘Ã¡p: trong quÃ¡ trÃ¬nh chuyá»ƒn task tá»« image retrieval sang image classification thÃ¬ nhá»¯ng bÆ°á»›c cáº§n lÃ m lÃ  gÃ¬? CÃ³ Æ°u tiÃªn cá»¥ thá»ƒ nÃ o ko? Máº·c Ä‘á»‹nh cÃ¡c khÃ¢u khÃ¡c nhÆ° data, model, loss function, training, retrieval function Ä‘á»u Ä‘Ã£ cÃ³ sáºµn. CÃ¡m Æ¡n má»i ngÆ°á»i trÆ°á»›c nhÃ©!",,,,,
"[REGULARIZATION - OVERFITTING]
Em xin chÃ o anh chá»‹. CÃ³ má»™t vÃ i váº¥n Ä‘á» trong phÆ°Æ¡ng phÃ¡p chÃ­nh quy hÃ³a trong series cá»§a Andrew Ng (regularization) trong viá»‡c xá»­ lÃ½ overfiting em váº«n chÆ°a hiá»ƒu láº¯m
1. Trong cÃ´ng thá»©c mÃ  Andrew Ng Ä‘Æ°a ra á»Ÿ Regularization cho há»“i quy tuyáº¿n tÃ­nh thÃ¬ táº¡i sao láº¡i pháº£i Ä‘Æ°a vÃ o má»™t tham sá»‘ lamda (em chÆ°a hiá»ƒu rÃµ viá»‡c ""co"" cÃ¡i model nghÄ©a lÃ  gÃ¬ )
2. Váº«n trong cÃ´ng thá»©c Ä‘Ã³, thay vÃ¬ lÃ  theta bÃ¬nh phÆ°Æ¡ng thÃ¬ táº¡i sao khÃ´ng pháº£i lÃ  theta^3 ^4 hay cÃ¡c báº­c khÃ¡c.
Em xin cáº£m Æ¡n má»i ngÆ°á»i chá»‰ báº£o áº¡.","[REGULARIZATION - OVERFITTING] Em xin chÃ o anh chá»‹. CÃ³ má»™t vÃ i váº¥n Ä‘á» trong phÆ°Æ¡ng phÃ¡p chÃ­nh quy hÃ³a trong series cá»§a Andrew Ng (regularization) trong viá»‡c xá»­ lÃ½ overfiting em váº«n chÆ°a hiá»ƒu láº¯m 1. Trong cÃ´ng thá»©c mÃ  Andrew Ng Ä‘Æ°a ra á»Ÿ Regularization cho há»“i quy tuyáº¿n tÃ­nh thÃ¬ táº¡i sao láº¡i pháº£i Ä‘Æ°a vÃ o má»™t tham sá»‘ lamda (em chÆ°a hiá»ƒu rÃµ viá»‡c ""co"" cÃ¡i model nghÄ©a lÃ  gÃ¬ ) 2. Váº«n trong cÃ´ng thá»©c Ä‘Ã³, thay vÃ¬ lÃ  theta bÃ¬nh phÆ°Æ¡ng thÃ¬ táº¡i sao khÃ´ng pháº£i lÃ  theta^3 ^4 hay cÃ¡c báº­c khÃ¡c. Em xin cáº£m Æ¡n má»i ngÆ°á»i chá»‰ báº£o áº¡.",,,,,
"Dáº¡o nÃ y em Ä‘ang há»c vá» Pá»µthon vá»›i OpenCV nÃªn máº¡nh dáº¡n lÃ m clip vá»«a Ä‘á»ƒ Ã´n bÃ i vá»«a chia sáº» cho cÃ¡c báº¡n newbie. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n.
Xin cáº£m Æ¡n cáº£ nhÃ !
Má»i tháº¯c máº¯c xin má»i ngÆ°á»i cá»© trao Ä‘á»•i ah!
Group trao Ä‘á»•i, chia sáº»: https://www.facebook.com/groups/miaigroup","Dáº¡o nÃ y em Ä‘ang há»c vá» Pá»µthon vá»›i OpenCV nÃªn máº¡nh dáº¡n lÃ m clip vá»«a Ä‘á»ƒ Ã´n bÃ i vá»«a chia sáº» cho cÃ¡c báº¡n newbie. Hi vá»ng giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n. Xin cáº£m Æ¡n cáº£ nhÃ ! Má»i tháº¯c máº¯c xin má»i ngÆ°á»i cá»© trao Ä‘á»•i ah! Group trao Ä‘á»•i, chia sáº»: https://www.facebook.com/groups/miaigroup",,,,,
"ChÃ o cáº£ nhÃ  , má»i ngÆ°á»i cho em há»i chÃºt sÃ¡ch Anh Viá»‡t vá» Machine Learning cÃ³ báº£n PDF khÃ´ng áº¡ ? vÃ¬ em hay di chuyá»ƒn nÃªn náº¿u cÃ³ báº£n PDF Ä‘á»c sáº½ tá»‘t hÆ¡n áº¡","ChÃ o cáº£ nhÃ  , má»i ngÆ°á»i cho em há»i chÃºt sÃ¡ch Anh Viá»‡t vá» Machine Learning cÃ³ báº£n PDF khÃ´ng áº¡ ? vÃ¬ em hay di chuyá»ƒn nÃªn náº¿u cÃ³ báº£n PDF Ä‘á»c sáº½ tá»‘t hÆ¡n áº¡",,,,,
"CÃ¡c anh chá»‹ trong group cÃ³ ai tá»«ng tham gia vinai residency program chÆ°a áº¡?
CÃ¡c anh/chá»‹ cho em há»i chÃºt kinh nghiá»‡m vá» vÃ²ng phá»ng váº¥n áº¡? vá» kiáº¿n thá»©c vá» toÃ¡n? machine learning cÃ³ yÃªu cáº§u cao khÃ´ng áº¡?
Khi phá»ng váº¥n sáº½ há»i báº±ng tiáº¿ng anh hay báº±ng tiáº¿ng viá»‡t áº¡?
Em cáº£m Æ¡n.",CÃ¡c anh chá»‹ trong group cÃ³ ai tá»«ng tham gia vinai residency program chÆ°a áº¡? CÃ¡c anh/chá»‹ cho em há»i chÃºt kinh nghiá»‡m vá» vÃ²ng phá»ng váº¥n áº¡? vá» kiáº¿n thá»©c vá» toÃ¡n? machine learning cÃ³ yÃªu cáº§u cao khÃ´ng áº¡? Khi phá»ng váº¥n sáº½ há»i báº±ng tiáº¿ng anh hay báº±ng tiáº¿ng viá»‡t áº¡? Em cáº£m Æ¡n.,,,,,
CaÌc baÌ£n cho miÌ€nh hoÌ‰i sao Æ¡Ì‰ Ä‘Ã¢y noÌ laÌ£i cho thÃªm mÃ´Ì£t vector toaÌ€n sÃ´Ì 1 vaÌ€o Xbar rÃ´Ì€i mÆ¡Ìi Ä‘i tiÌnh cÃ´ng thÆ°Ìc vÃ¢Ì£y ?,CaÌc baÌ£n cho miÌ€nh hoÌ‰i sao Æ¡Ì‰ Ä‘Ã¢y noÌ laÌ£i cho thÃªm mÃ´Ì£t vector toaÌ€n sÃ´Ì 1 vaÌ€o Xbar rÃ´Ì€i mÆ¡Ìi Ä‘i tiÌnh cÃ´ng thÆ°Ìc vÃ¢Ì£y ?,,,"#Q&A, #math",,
"MÃ¬nh tháº¥y cÃ³ ráº¥t nhiá»u bÃªn Ä‘ang Ä‘Ã o táº¡o vá» Data Science, AI, ML nhÆ°:
1. MindX
2. VietAI
3. BigO
4. Sagan School
5. Protonx
6. VEF
CÃ³ láº½ dáº¡y AI Ä‘ang lÃ  1 má» vÃ ng khi ngÃ nh Ä‘ang hot mÃ  tá»± há»c thÃ¬ khÃ³. Tuy nhiÃªn, mÃ¬nh cÅ©ng Ä‘ang cÃ³ nhu cáº§u há»c tháº­t nÃªn nhá» ae review vá» cÃ¡c trung tÃ¢m nÃ y, cÃ ng chi tiáº¿t cÃ ng tá»‘t,
Há»c cÃ³ hiá»‡u quáº£ khÃ´ng?
Giáº£ng viÃªn quan tÃ¢m khÃ´ng?
Project Ä‘Æ°á»£c hÆ°á»›ng dáº«n cÃ³ sÃ¡t thá»±c táº¿ vÃ  cÃ³ tÃ­nh á»©ng dá»¥ng cao khÃ´ng?
Há»c xong báº¡n lÃ m Ä‘Æ°á»£c viá»‡c khÃ´ng?
.....
VÃ¬ cÃ¡c khÃ³a há»c trÃªn Ä‘á»u ráº¥t Ä‘áº¯t, phá»• biáº¿n á»Ÿ má»©c 5 triá»‡u / course, cÃ¡ biá»‡t cÃ³ Sagan School há»c phÃ­ lÃªn tá»›i 13.5 triá»‡u nÃªn mÃ¬nh cÅ©ng tÃ¢m tÆ° nhiá»u. Mong ae review táº­n tÃ¬nh.","MÃ¬nh tháº¥y cÃ³ ráº¥t nhiá»u bÃªn Ä‘ang Ä‘Ã o táº¡o vá» Data Science, AI, ML nhÆ°: 1. MindX 2. VietAI 3. BigO 4. Sagan School 5. Protonx 6. VEF CÃ³ láº½ dáº¡y AI Ä‘ang lÃ  1 má» vÃ ng khi ngÃ nh Ä‘ang hot mÃ  tá»± há»c thÃ¬ khÃ³. Tuy nhiÃªn, mÃ¬nh cÅ©ng Ä‘ang cÃ³ nhu cáº§u há»c tháº­t nÃªn nhá» ae review vá» cÃ¡c trung tÃ¢m nÃ y, cÃ ng chi tiáº¿t cÃ ng tá»‘t, Há»c cÃ³ hiá»‡u quáº£ khÃ´ng? Giáº£ng viÃªn quan tÃ¢m khÃ´ng? Project Ä‘Æ°á»£c hÆ°á»›ng dáº«n cÃ³ sÃ¡t thá»±c táº¿ vÃ  cÃ³ tÃ­nh á»©ng dá»¥ng cao khÃ´ng? Há»c xong báº¡n lÃ m Ä‘Æ°á»£c viá»‡c khÃ´ng? ..... VÃ¬ cÃ¡c khÃ³a há»c trÃªn Ä‘á»u ráº¥t Ä‘áº¯t, phá»• biáº¿n á»Ÿ má»©c 5 triá»‡u / course, cÃ¡ biá»‡t cÃ³ Sagan School há»c phÃ­ lÃªn tá»›i 13.5 triá»‡u nÃªn mÃ¬nh cÅ©ng tÃ¢m tÆ° nhiá»u. Mong ae review táº­n tÃ¬nh.",,,,,
https://blogs.nvidia.com/blog/2020/10/05/gan-video-conferencing-maxine/,https://blogs.nvidia.com/blog/2020/10/05/gan-video-conferencing-maxine/,,,,,
Cho mÃ¬nh há»i group mÃ¬nh cÃ³ ai cÃ³ ebook â€œRaspberry for Computer Visionâ€ cá»§a Adrian Rosebrock hoáº·c cÃ¡c tá»±a sÃ¡ch khÃ¡c cÃ¹ng tÃ¡c giáº£ khÃ´ng áº¡? Pass láº¡i cho mÃ¬nh vá»›i vÃ¬ sÃ¡ch cá»§a Adrian máº¯c quÃ¡ khÃ´ng Ä‘á»§ tiá»n mua ğŸ˜­ (giÃ¡ cáº£ thÆ°Æ¡ng lÆ°á»£ng áº¡).,Cho mÃ¬nh há»i group mÃ¬nh cÃ³ ai cÃ³ ebook â€œRaspberry for Computer Visionâ€ cá»§a Adrian Rosebrock hoáº·c cÃ¡c tá»±a sÃ¡ch khÃ¡c cÃ¹ng tÃ¡c giáº£ khÃ´ng áº¡? Pass láº¡i cho mÃ¬nh vá»›i vÃ¬ sÃ¡ch cá»§a Adrian máº¯c quÃ¡ khÃ´ng Ä‘á»§ tiá»n mua (giÃ¡ cáº£ thÆ°Æ¡ng lÆ°á»£ng áº¡).,,,,,
This is a short demonstration of a face mask detector for COVID-19 using PyTorch Lightning running on videos. The article and the git are in description of the video.,This is a short demonstration of a face mask detector for COVID-19 using PyTorch Lightning running on videos. The article and the git are in description of the video.,,,,,
"Xin tÃ i liá»‡u C++

MÃ¬nh Ä‘ang há»c vá» C++. MÃ¬nh cáº§n cá»™ng Ä‘á»“ng kháº£o sÃ¡t giÃºp vá» tÃ i liá»‡u nÃ o hay vá»›i ah.

Xin cáº£m Æ¡n!",Xin tÃ i liá»‡u C++ MÃ¬nh Ä‘ang há»c vá» C++. MÃ¬nh cáº§n cá»™ng Ä‘á»“ng kháº£o sÃ¡t giÃºp vá» tÃ i liá»‡u nÃ o hay vá»›i ah. Xin cáº£m Æ¡n!,,,,,
"ChÃ o má»i ngÆ°á»i.
Team em Ä‘ang cÃ³ má»™t dá»± Ã¡n vá» Speech To Text Tiáº¿ng Viá»‡t.
Má»i ngÆ°á»i cÃ³ thá»ƒ cho em gá»£i Ã½ vá» mÃ´ hÃ¬nh má»›i nháº¥t vá» Speech Recognize vÃ  cÃ³ nhiá»u tÃ i liá»‡u nháº¥t Ä‘Æ°á»£c khÃ´ng áº¡?
Em xin cáº£m Æ¡n.",ChÃ o má»i ngÆ°á»i. Team em Ä‘ang cÃ³ má»™t dá»± Ã¡n vá» Speech To Text Tiáº¿ng Viá»‡t. Má»i ngÆ°á»i cÃ³ thá»ƒ cho em gá»£i Ã½ vá» mÃ´ hÃ¬nh má»›i nháº¥t vá» Speech Recognize vÃ  cÃ³ nhiá»u tÃ i liá»‡u nháº¥t Ä‘Æ°á»£c khÃ´ng áº¡? Em xin cáº£m Æ¡n.,,,,,
"BÃ i bÃ¡o Ä‘ang á»Ÿ dáº¡ng open review káº¿t há»£p sá»©c máº¡nh cá»§a CNN vá»›i Transformers cho káº¿t quáº£ ráº¥t kháº£ quan, táº¥t nhiÃªn computation cost cÅ©ng khÃ´ng ráº» chÃºt nÃ o! https://openreview.net/pdf?id=YicbFdNTTy. Anh Ross Wrightman Ä‘Ã£ viáº¿t code táº¡i Ä‘Ã¢y: https://github.com/rwightman/pytorch-image-models/timm/models/vision_transformer.py
Hi vá»ng, chÃºng ta sáº½ cÃ³ GPT-3 trong á»©ng dá»¥ng Vision.
Ps. mÃ¬nh ráº¥t thÃ­ch dáº¡ng open review, náº¿u VN Ã¡p dá»¥ng cÃ¡ch nÃ y cho cÃ¡c luáº­n Ã¡n tiáº¿n sÄ© cháº¯c cháº¯n sáº½ khÃ´ng cÃ³ tiáº¿n sÄ© chÃ¢n vá»‹t gÃ¬ Ä‘Ã³! VÃ  cÃ²n hÆ¡n tháº¿ ná»¯a","BÃ i bÃ¡o Ä‘ang á»Ÿ dáº¡ng open review káº¿t há»£p sá»©c máº¡nh cá»§a CNN vá»›i Transformers cho káº¿t quáº£ ráº¥t kháº£ quan, táº¥t nhiÃªn computation cost cÅ©ng khÃ´ng ráº» chÃºt nÃ o! https://openreview.net/pdf?id=YicbFdNTTy. Anh Ross Wrightman Ä‘Ã£ viáº¿t code táº¡i Ä‘Ã¢y: https://github.com/rwightman/pytorch-image-models/timm/models/vision_transformer.py Hi vá»ng, chÃºng ta sáº½ cÃ³ GPT-3 trong á»©ng dá»¥ng Vision. Ps. mÃ¬nh ráº¥t thÃ­ch dáº¡ng open review, náº¿u VN Ã¡p dá»¥ng cÃ¡ch nÃ y cho cÃ¡c luáº­n Ã¡n tiáº¿n sÄ© cháº¯c cháº¯n sáº½ khÃ´ng cÃ³ tiáº¿n sÄ© chÃ¢n vá»‹t gÃ¬ Ä‘Ã³! VÃ  cÃ²n hÆ¡n tháº¿ ná»¯a",,,,,
"Dear má»i ngÆ°á»i
Cho mÃ¬nh há»i, trong bÃ i article nÃ y cÃ³ Ä‘oáº¡n nhÆ°ng mÃ¬nh chÆ°a hiá»ƒu Ã½ cá»¥ thá»ƒ nÃ³i gÃ¬:
ğ™ğ™ğ™ğ™¨ ğ™¢ğ™šğ™–ğ™£ğ™¨ ğ™ğ™™ğ™šğ™£ğ™©ğ™ğ™›ğ™®ğ™ğ™£ğ™œ ğ™©ğ™ğ™š ğ™§ğ™šğ™¡ğ™–ğ™©ğ™ğ™¤ğ™£ğ™¨ğ™ğ™ğ™¥ğ™¨ ğ™—ğ™šğ™©ğ™¬ğ™šğ™šğ™£ ğ™ğ™£ğ™™ğ™šğ™¥ğ™šğ™£ğ™™ğ™šğ™£ğ™© ğ™–ğ™£ğ™™ ğ™™ğ™šğ™¥ğ™šğ™£ğ™™ğ™šğ™£ğ™© ğ™›ğ™šğ™–ğ™©ğ™ªğ™§ğ™šğ™¨. ğ™ğ™ğ™ğ™¨ ğ™ğ™¨ ğ™¬ğ™ğ™©ğ™ ğ™©ğ™ğ™š ğ™ğ™šğ™¡ğ™¥ ğ™¤ğ™› ğ™œğ™§ğ™–ğ™¥ğ™ğ™¨ ğ™¡ğ™ğ™ ğ™š ğ™¥ğ™–ğ™ğ™§ ğ™¥ğ™¡ğ™¤ğ™©ğ™¨ ğ™¤ğ™§ ğ™˜ğ™¤ğ™§ğ™§ğ™šğ™¡ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™¢ğ™–ğ™©ğ™§ğ™ğ™­. ğ™ğ™ğ™šğ™£ ğ™©ğ™ğ™š ğ™ğ™™ğ™šğ™£ğ™©ğ™ğ™›ğ™ğ™šğ™™ ğ™§ğ™šğ™¡ğ™–ğ™©ğ™ğ™¤ğ™£ğ™¨ğ™ğ™ğ™¥ğ™¨ ğ™¬ğ™š ğ™˜ğ™–ğ™£ ğ™–ğ™™ğ™™ ğ™–ğ™¨ ğ™¥ğ™¤ğ™¡ğ™®ğ™£ğ™¤ğ™¢ğ™ğ™–ğ™¡ ğ™¤ğ™§ ğ™ğ™£ğ™©ğ™šğ™§ğ™–ğ™˜ğ™©ğ™ğ™¤ğ™£ ğ™›ğ™šğ™–ğ™©ğ™ªğ™§ğ™šğ™¨.
Source: https://towardsdatascience.com/supervised-machine-learning-model-validation-a-step-by-step-approach-771109ae0253
Váº­y giáº£ sá»­ trong nhá»¯ng columns ban Ä‘áº§u cá»§a dataset cÃ³ nhá»¯ng pairs mÃ  highly correlated vá»›i nhau thÃ¬ lÃºc lÃ m feature selection mÃ¬nh sáº½ Ä‘Æ°a nhá»¯ng pairs Ä‘Ã³ nhÃ¢n vá»›i nhau Ä‘Ãºng khÃ´ng?
VÃ­ dá»¥ nhÆ°: dataset cÃ³ A, B, C, D columns, A vÃ  C cÃ³ correlation coefficent lÃ  0.85 thÃ¬ khi viáº¿t formula Ä‘á»ƒ build model:
Output ~ A*C + B + D hay nÃ³i cÃ¡ch khÃ¡c lÃ  nhÃ¢n cÃ¡c features cÃ³ interaction vá»›i nhau (á»Ÿ Ä‘Ã¢y lÃ  correlation coefficient).
Thanks má»i ngÆ°á»i.","Dear má»i ngÆ°á»i Cho mÃ¬nh há»i, trong bÃ i article nÃ y cÃ³ Ä‘oáº¡n nhÆ°ng mÃ¬nh chÆ°a hiá»ƒu Ã½ cá»¥ thá»ƒ nÃ³i gÃ¬: . . . Source: https://towardsdatascience.com/supervised-machine-learning-model-validation-a-step-by-step-approach-771109ae0253 Váº­y giáº£ sá»­ trong nhá»¯ng columns ban Ä‘áº§u cá»§a dataset cÃ³ nhá»¯ng pairs mÃ  highly correlated vá»›i nhau thÃ¬ lÃºc lÃ m feature selection mÃ¬nh sáº½ Ä‘Æ°a nhá»¯ng pairs Ä‘Ã³ nhÃ¢n vá»›i nhau Ä‘Ãºng khÃ´ng? VÃ­ dá»¥ nhÆ°: dataset cÃ³ A, B, C, D columns, A vÃ  C cÃ³ correlation coefficent lÃ  0.85 thÃ¬ khi viáº¿t formula Ä‘á»ƒ build model: Output ~ A*C + B + D hay nÃ³i cÃ¡ch khÃ¡c lÃ  nhÃ¢n cÃ¡c features cÃ³ interaction vá»›i nhau (á»Ÿ Ä‘Ã¢y lÃ  correlation coefficient). Thanks má»i ngÆ°á»i.",,,,,
Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ¡ch Ä‘á»ƒ cáº¯t frames ra trong 1 video vÃ  xá»­ lÃ­ face detection báº±ng MTCNN sau Ä‘Ã³ lÆ°u ra file áº£nh nhÆ° tháº¿ nÃ o Ä‘Æ°á»£c ko áº¡? MÃ¬nh cáº£m Æ¡n nhiá»u,Má»i ngÆ°á»i cho mÃ¬nh há»i cÃ¡ch Ä‘á»ƒ cáº¯t frames ra trong 1 video vÃ  xá»­ lÃ­ face detection báº±ng MTCNN sau Ä‘Ã³ lÆ°u ra file áº£nh nhÆ° tháº¿ nÃ o Ä‘Æ°á»£c ko áº¡? MÃ¬nh cáº£m Æ¡n nhiá»u,,,,,
"MÃ¬nh Ä‘ang nghiÃªn cá»©u sá»­ dá»¥ng machine learning Ä‘á»ƒ speech to text tiáº¿ng Viá»‡t. Trong group cÃ³ báº¡n nÃ o cÃ³ tÃ i liá»‡u, kinh nghiá»‡m, cÃ¡c dá»¯ liá»‡u máº«u thÃ¬ chia sáº» nhÃ©.
Náº¿u thiáº¿u dá»¯ liá»‡u máº«u, anh em cÃ³ thá»ƒ chung tay xÃ¢y dá»±ng má»™t website Ä‘á»ƒ má»i ngÆ°á»i Ä‘Ã³ng gÃ³p cÃ¡c máº«u dá»¯ liá»‡u cÃ³ thá»ƒ sá»­ dá»¥ng chung cho táº¥t cáº£. Ráº¥t anh em quan tÃ¢m, gÃ³p Ã½.","MÃ¬nh Ä‘ang nghiÃªn cá»©u sá»­ dá»¥ng machine learning Ä‘á»ƒ speech to text tiáº¿ng Viá»‡t. Trong group cÃ³ báº¡n nÃ o cÃ³ tÃ i liá»‡u, kinh nghiá»‡m, cÃ¡c dá»¯ liá»‡u máº«u thÃ¬ chia sáº» nhÃ©. Náº¿u thiáº¿u dá»¯ liá»‡u máº«u, anh em cÃ³ thá»ƒ chung tay xÃ¢y dá»±ng má»™t website Ä‘á»ƒ má»i ngÆ°á»i Ä‘Ã³ng gÃ³p cÃ¡c máº«u dá»¯ liá»‡u cÃ³ thá»ƒ sá»­ dá»¥ng chung cho táº¥t cáº£. Ráº¥t anh em quan tÃ¢m, gÃ³p Ã½.",,,,,
"KÃ­nh chÃ o cÃ¡c anh em, hiá»‡n nay sao má»™t thá»i gian tá»± há»c thÃ¬ em tháº¥y cÃ³ nhiá»u báº¡n cÃ²n yáº¿u Python. Trong khi Ä‘Ã³ Python lÃ  má»™t cÃ´ng cá»¥ sáº¯c bÃ©n Ä‘á»ƒ tiáº¿p cáº­n AI, ML, DL....Do Ä‘Ã³, em vá»«a há»c vá»«a cÃ³ lÃ m má»™t khÃ³a Python cÆ¡ báº£n theo phong cÃ¡ch MÃ¬ Äƒn liá»n Ä‘á»ƒ cÃ¡c báº¡n tiáº¿p cáº­n nhanh vÃ  chÃº trá»ng vÃ o cÃ¡c pháº§n chÃ­nh liÃªn quan Ä‘áº¿n AI (cÃ¡c cÃ¡i khÃ¡c Ã­t dÃ¹ng bá» qua).
KhÃ³a nÃ y lÃ  ONLINE vÃ  hoÃ n toÃ n MIá»„N PHÃ ah.","KÃ­nh chÃ o cÃ¡c anh em, hiá»‡n nay sao má»™t thá»i gian tá»± há»c thÃ¬ em tháº¥y cÃ³ nhiá»u báº¡n cÃ²n yáº¿u Python. Trong khi Ä‘Ã³ Python lÃ  má»™t cÃ´ng cá»¥ sáº¯c bÃ©n Ä‘á»ƒ tiáº¿p cáº­n AI, ML, DL....Do Ä‘Ã³, em vá»«a há»c vá»«a cÃ³ lÃ m má»™t khÃ³a Python cÆ¡ báº£n theo phong cÃ¡ch MÃ¬ Äƒn liá»n Ä‘á»ƒ cÃ¡c báº¡n tiáº¿p cáº­n nhanh vÃ  chÃº trá»ng vÃ o cÃ¡c pháº§n chÃ­nh liÃªn quan Ä‘áº¿n AI (cÃ¡c cÃ¡i khÃ¡c Ã­t dÃ¹ng bá» qua). KhÃ³a nÃ y lÃ  ONLINE vÃ  hoÃ n toÃ n MIá»„N PHÃ ah.",,,,,
"CÆ¡ há»™i cho cÃ¡c báº¡n tráº» Ä‘am mÃª Data Engineering or Data Science muá»‘n lÃ m viá»‡c táº¡i Facebook HQ, MÄ©. MÃ¬nh chia sáº» thÃ´i nhÃ©, chá»© ko tÆ° váº¥n visa. ğŸ˜…Báº¡n cÃ³ thá»ƒ Ä‘i theo diá»‡n H1B hoáº·c vÃ o Ä‘Ã¢y xem thÃªm: https://www.uscis.gov/working-in-the-united-states
(Náº¿u mÃ  trÃºng tuyá»ƒn vÃ  láº¥y visa qua MÄ© dc thÃ¬ nhá»› xuá»‘ng LA Ä‘em theo quÃ  cáº£m Æ¡n mÃ¬nh nhoa. haha) ChÃºc cÃ¡c báº¡n tráº» may máº¯n! ğŸ¤“

Facebook University for Analytics is now accepting applications for Summer 2021. 
- We welcome Class of 2023 college students studying at a four-year university in the U.S to apply. 
-  FBU for Analytics is a paid, eight-week internship program designed to  provide exposure to students who are historically underrepresented in  this field.
- The application window will be open from 10/1/20-11/10/20. 
- Apply here: https://lnkd.in/gviayYf","CÆ¡ há»™i cho cÃ¡c báº¡n tráº» Ä‘am mÃª Data Engineering or Data Science muá»‘n lÃ m viá»‡c táº¡i Facebook HQ, MÄ©. MÃ¬nh chia sáº» thÃ´i nhÃ©, chá»© ko tÆ° váº¥n visa. Báº¡n cÃ³ thá»ƒ Ä‘i theo diá»‡n H1B hoáº·c vÃ o Ä‘Ã¢y xem thÃªm: https://www.uscis.gov/working-in-the-united-states (Náº¿u mÃ  trÃºng tuyá»ƒn vÃ  láº¥y visa qua MÄ© dc thÃ¬ nhá»› xuá»‘ng LA Ä‘em theo quÃ  cáº£m Æ¡n mÃ¬nh nhoa. haha) ChÃºc cÃ¡c báº¡n tráº» may máº¯n! Facebook University for Analytics is now accepting applications for Summer 2021. - We welcome Class of 2023 college students studying at a four-year university in the U.S to apply. - FBU for Analytics is a paid, eight-week internship program designed to provide exposure to students who are historically underrepresented in this field. - The application window will be open from 10/1/20-11/10/20. - Apply here: https://lnkd.in/gviayYf",,,,,
"NhÃ³m mÃ¬nh cÃ³ ai há»c data analysis trÃªn dataquest ko áº¡?
Share mÃ¬nh vs áº¡",NhÃ³m mÃ¬nh cÃ³ ai há»c data analysis trÃªn dataquest ko áº¡? Share mÃ¬nh vs áº¡,,,,,
Dáº¡ cÃ¡c bÃ¡c Æ¡i giÃºp em váº¥n Ä‘á» nÃ y vá»›i áº¡. Em cÃ³ 1 báº£ng gá»“m 4 chá»¯ sá»‘ Ä‘Ã£ Ä‘Æ°á»£c One hot ra. BÃ i toÃ¡n cá»§a em lÃ  tÃ¬m nhá»¯ng Ä‘oáº¡n giá»‘ng nhau báº±ng CNN áº¡. CÃ³ bÃ¡c nÃ o biáº¿t tÃ i liá»‡u nÃ o Ä‘á»ƒ Ä‘Æ°a vÃ o CNN hoáº·c Ä‘Ã£ lÃ m váº¥n Ä‘á» nÃ y cho em hÆ°á»›ng Ä‘i vá»›i áº¡. ThÃ¢n,Dáº¡ cÃ¡c bÃ¡c Æ¡i giÃºp em váº¥n Ä‘á» nÃ y vá»›i áº¡. Em cÃ³ 1 báº£ng gá»“m 4 chá»¯ sá»‘ Ä‘Ã£ Ä‘Æ°á»£c One hot ra. BÃ i toÃ¡n cá»§a em lÃ  tÃ¬m nhá»¯ng Ä‘oáº¡n giá»‘ng nhau báº±ng CNN áº¡. CÃ³ bÃ¡c nÃ o biáº¿t tÃ i liá»‡u nÃ o Ä‘á»ƒ Ä‘Æ°a vÃ o CNN hoáº·c Ä‘Ã£ lÃ m váº¥n Ä‘á» nÃ y cho em hÆ°á»›ng Ä‘i vá»›i áº¡. ThÃ¢n,,,,,
"Xin chÃ o má»i ngÆ°á»i.
Cho em há»i cÃ³ ai Ä‘Ã£ tá»«ng lÃ m viá»‡c vá»›i bá»™ dá»¯ liá»‡u 20BN-JESTER-V1 chÆ°a áº¡. Em Ä‘Ã£ táº£i xuá»‘ng vÃ  lÃ m theo hÆ°á»›ng dáº«n Ä‘á»ƒ giáº£i nÃ©n (cat 20bn-jester-v1-?? | tar zx)nhÆ°ng cÃ³ váº» nhÆ°ng chá»‰ giáº£i nÃ©n Ä‘Æ°á»£c 1/22 file . Em Ä‘ang dÃ¹ng dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Hand gesture recognition. Em cáº£m Æ¡n áº¡",Xin chÃ o má»i ngÆ°á»i. Cho em há»i cÃ³ ai Ä‘Ã£ tá»«ng lÃ m viá»‡c vá»›i bá»™ dá»¯ liá»‡u 20BN-JESTER-V1 chÆ°a áº¡. Em Ä‘Ã£ táº£i xuá»‘ng vÃ  lÃ m theo hÆ°á»›ng dáº«n Ä‘á»ƒ giáº£i nÃ©n (cat 20bn-jester-v1-?? | tar zx)nhÆ°ng cÃ³ váº» nhÆ°ng chá»‰ giáº£i nÃ©n Ä‘Æ°á»£c 1/22 file . Em Ä‘ang dÃ¹ng dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Hand gesture recognition. Em cáº£m Æ¡n áº¡,,,,,
kÃ¬ nÃ y em Ä‘ang lÃ m Ä‘á»“ Ã¡n nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng máº¡ng cnn.Má»i ngÆ°á»i cÃ³ source code hoáº·c tÃ i liá»‡u cho em xin vá»›i áº¡,kÃ¬ nÃ y em Ä‘ang lÃ m Ä‘á»“ Ã¡n nháº­n diá»‡n biá»ƒn sá»‘ xe báº±ng máº¡ng cnn.Má»i ngÆ°á»i cÃ³ source code hoáº·c tÃ i liá»‡u cho em xin vá»›i áº¡,,,,,
"ChÃ o anh chá»‹, em Ä‘ang tÃ¬m hiá»ƒu pháº§n phÃ¢n phá»‘i xÃ¡c suáº¥t hÃ¬nh há»c trong cuá»‘n Head First Statistics, thÃ¬ em nháº­n Ä‘Æ°á»£c cÃ¡i hÃ¬nh dÆ°á»›i Ä‘Ã¢y, cá»¥ thá»ƒ q = 0.8 lÃ  xÃ¡c suáº¥t tháº¥t báº¡i, p = 0.2 lÃ  xÃ¡c suáº¥t thÃ nh cÃ´ng, thÃ¬ cÃ¡i cá»™t x*P(X=x) thÃ¬ em Ä‘Ã£ hiá»ƒu rá»“i, nhÆ°ng á»Ÿ cÃ¡i cá»™t x*P(X<=x) thÃ¬ em tÃ­nh theo cÃ¡ch em nhÆ° sau, em láº¥y cá»¥ thá»ƒ x = 2, thÃ¬ P(X<=x) = 1 - q^x = 1 - 0.8^2 = 0.36 => x*P(X<=x) = 0.36*2 = 0.72 chá»©, sao trong sÃ¡ch ghi lÃ  0.52 váº­y. Mong má»i ngÆ°á»i giÃºp em, cáº£m Æ¡n má»i ngÆ°á»i áº¡.","ChÃ o anh chá»‹, em Ä‘ang tÃ¬m hiá»ƒu pháº§n phÃ¢n phá»‘i xÃ¡c suáº¥t hÃ¬nh há»c trong cuá»‘n Head First Statistics, thÃ¬ em nháº­n Ä‘Æ°á»£c cÃ¡i hÃ¬nh dÆ°á»›i Ä‘Ã¢y, cá»¥ thá»ƒ q = 0.8 lÃ  xÃ¡c suáº¥t tháº¥t báº¡i, p = 0.2 lÃ  xÃ¡c suáº¥t thÃ nh cÃ´ng, thÃ¬ cÃ¡i cá»™t x*P(X=x) thÃ¬ em Ä‘Ã£ hiá»ƒu rá»“i, nhÆ°ng á»Ÿ cÃ¡i cá»™t x*P(X<=x) thÃ¬ em tÃ­nh theo cÃ¡ch em nhÆ° sau, em láº¥y cá»¥ thá»ƒ x = 2, thÃ¬ P(X<=x) = 1 - q^x = 1 - 0.8^2 = 0.36 => x*P(X<=x) = 0.36*2 = 0.72 chá»©, sao trong sÃ¡ch ghi lÃ  0.52 váº­y. Mong má»i ngÆ°á»i giÃºp em, cáº£m Æ¡n má»i ngÆ°á»i áº¡.",,,"#Q&A, #math",,
"Hi mn,
Em Ä‘ang lÃ m nháº­n dang Ã´ tÃ´ trÃªn raspberry. Anh chá»‹ cÃ³ tÃ i liá»‡u CNN, Lenet hoáº·c thuáº­t toÃ¡n DL nÃ o Ä‘á»ƒ nháº­n dáº¡ng trÃªn raspberry cho em xin vá»›i áº¡ . Em cáº£m Æ¡n","Hi mn, Em Ä‘ang lÃ m nháº­n dang Ã´ tÃ´ trÃªn raspberry. Anh chá»‹ cÃ³ tÃ i liá»‡u CNN, Lenet hoáº·c thuáº­t toÃ¡n DL nÃ o Ä‘á»ƒ nháº­n dáº¡ng trÃªn raspberry cho em xin vá»›i áº¡ . Em cáº£m Æ¡n",,,,,
"#hoidap
Xin chÃ o má»i ngÆ°á»i!
MÃ¬nh Ä‘ang lÃ m Ä‘á» tÃ i vá» nháº­n dáº¡ng cá»­ chá»‰ tay (Hand Getsture), nhÆ°ng Ä‘ang vÆ°á»›ng ngay á»Ÿ bÆ°á»›c chuáº©n bá»‹ táº­p dá»¯ liá»‡u Ä‘á»ƒ há»c cho máº¡ng Neural. Váº­y má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh há»i nguá»“n táº£i Dá»¯ liá»‡u á»Ÿ Ä‘Ã¢u Ä‘Æ°á»£c khÃ´ng áº¡?
MÃ¬nh xin cáº£m Æ¡n ráº¥t nhiá»u!","Xin chÃ o má»i ngÆ°á»i! MÃ¬nh Ä‘ang lÃ m Ä‘á» tÃ i vá» nháº­n dáº¡ng cá»­ chá»‰ tay (Hand Getsture), nhÆ°ng Ä‘ang vÆ°á»›ng ngay á»Ÿ bÆ°á»›c chuáº©n bá»‹ táº­p dá»¯ liá»‡u Ä‘á»ƒ há»c cho máº¡ng Neural. Váº­y má»i ngÆ°á»i cÃ³ thá»ƒ cho mÃ¬nh há»i nguá»“n táº£i Dá»¯ liá»‡u á»Ÿ Ä‘Ã¢u Ä‘Æ°á»£c khÃ´ng áº¡? MÃ¬nh xin cáº£m Æ¡n ráº¥t nhiá»u!",#hoidap,,,,
"#ComputerVision #OpenCV #DeepLearning
--- EDITED ---
Cáº£m Æ¡n má»i ngÆ°á»i, tá»¥i mÃ¬nh Ä‘Ã£ quyáº¿t Ä‘á»‹nh thu háº¹p bÃ i toÃ¡n 2 - detect mÃ u báº±ng cÃ¡ch giáº£ sá»­ 2 chiáº¿c giÃ y sáº½ khÃ¡c má»™t máº£ng mÃ u Ä‘á»§ lá»›n Ä‘á»ƒ color histogram cá»§a 2 táº¥m áº£nh chÃªnh lá»‡ch rÃµ rÃ ng (káº¿t há»£p vá»›i viá»‡c amplify sá»± khÃ¡c biá»‡t), tá»« Ä‘Ã³ kháº³ng Ä‘á»‹nh 2 chiáº¿c giÃ y cÃ³ khÃ¡c mÃ u hay khÃ´ng ğŸ“·
Äá»‘i vá»›i nhá»¯ng vá»‡t mÃ u nhá», team sáº½ chuyá»ƒn qua thÃ nh bÃ i toÃ¡n detect cÃ¡c váº¿t báº©n vÃ  táº¡o táº­p data Ä‘á»ƒ train
---------------
Hiá»‡n táº¡i tá»¥i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá»›i Ä‘á» tÃ i: detect cÃ¡c lá»—i khÃ¡c biá»‡t trong dÃ¢y chuyá»n sáº£n xuáº¥t giÃ y nhÆ° khÃ¡c size, khÃ¡c mÃ u, báº©n, dÆ°/thiáº¿u keo v.v...
BÃ i toÃ¡n 1: detect size, chÃºng em sá»­ dá»¥ng Canny edge detection Ä‘á»ƒ tÃ¬m ra Ä‘Ã´i giÃ y --> khÃ¡ á»•n
BÃ i toÃ¡n 2: detect mÃ u, chÃºng em sá»­ dá»¥ng 2 phÆ°Æ¡ng phÃ¡p:
CÃ¡ch 1: Sá»­ dá»¥ng cv2.inRange Ä‘á»ƒ báº¯t cÃ¡c mÃ u náº±m trong má»™t khoáº£ng nÃ o Ä‘Ã³ --> khÃ¡ nhiá»…u vÃ  khÃ³ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh range mÃ u.
CÃ¡ch 2: preprocess táº¥m áº£nh (blur: giáº£m nhiá»…u, thay Ä‘á»•i contrast: nháº¥n máº¡nh khÃ¡c biá»‡t), sau Ä‘Ã³ chia áº£nh thÃ nh cÃ¡c ma tráº­n 3x3 hoáº·c 4x4 Ä‘á»ƒ so sÃ¡nh khÃ¡c biá»‡t tá»«ng pháº§n. Thuáº­t toÃ¡n so sÃ¡nh sá»­ dá»¥ng lÃ  SSIM (Structural similarity index). 
Qua nhiá»u láº§n thá»­, cÃ¡ch 2 tá» ra vÆ°á»£t trá»™i hÆ¡n nhÆ°ng cÃ³ má»™t sá»‘ háº¡n cháº¿:
KhÃ¡ nháº¡y vá» sá»± khÃ¡c biá»‡t vá» vá»‹ trÃ­ chiáº¿c giÃ y: 2 giÃ y giá»‘ng mÃ u nhÆ°ng hÆ¡i lá»‡ch nhau chÃºt thÃ¬ SSIM cÅ©ng xÃ¡c Ä‘á»‹nh lÃ  khÃ¡c nhau
KhÃ´ng thá»ƒ Ä‘áº£m báº£o cÃ¡c láº§n cháº¡y detect giÃ y Ä‘á»u cÃ¹ng náº±m chÃ­nh xÃ¡c má»™t vá»‹ trÃ­.
âœ¨âœ¨âœ¨ 
Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» phÆ°Æ¡ng hÆ°á»›ng cho bÃ i toÃ¡n thá»© 2. VÃ¬ lÆ°á»£ng data khÃ´ng nhiá»u nÃªn team chÆ°a nghÄ© Ä‘Æ°á»£c cÃ¡ch sá»­ dá»¥ng deep learning nhÆ° tháº¿ nÃ o.
Team xin cáº£m Æ¡n â¤ï¸â¤ï¸","--- EDITED --- Cáº£m Æ¡n má»i ngÆ°á»i, tá»¥i mÃ¬nh Ä‘Ã£ quyáº¿t Ä‘á»‹nh thu háº¹p bÃ i toÃ¡n 2 - detect mÃ u báº±ng cÃ¡ch giáº£ sá»­ 2 chiáº¿c giÃ y sáº½ khÃ¡c má»™t máº£ng mÃ u Ä‘á»§ lá»›n Ä‘á»ƒ color histogram cá»§a 2 táº¥m áº£nh chÃªnh lá»‡ch rÃµ rÃ ng (káº¿t há»£p vá»›i viá»‡c amplify sá»± khÃ¡c biá»‡t), tá»« Ä‘Ã³ kháº³ng Ä‘á»‹nh 2 chiáº¿c giÃ y cÃ³ khÃ¡c mÃ u hay khÃ´ng Äá»‘i vá»›i nhá»¯ng vá»‡t mÃ u nhá», team sáº½ chuyá»ƒn qua thÃ nh bÃ i toÃ¡n detect cÃ¡c váº¿t báº©n vÃ  táº¡o táº­p data Ä‘á»ƒ train --------------- Hiá»‡n táº¡i tá»¥i em Ä‘ang lÃ m Ä‘á»“ Ã¡n vá»›i Ä‘á» tÃ i: detect cÃ¡c lá»—i khÃ¡c biá»‡t trong dÃ¢y chuyá»n sáº£n xuáº¥t giÃ y nhÆ° khÃ¡c size, khÃ¡c mÃ u, báº©n, dÆ°/thiáº¿u keo v.v... BÃ i toÃ¡n 1: detect size, chÃºng em sá»­ dá»¥ng Canny edge detection Ä‘á»ƒ tÃ¬m ra Ä‘Ã´i giÃ y --> khÃ¡ á»•n BÃ i toÃ¡n 2: detect mÃ u, chÃºng em sá»­ dá»¥ng 2 phÆ°Æ¡ng phÃ¡p: CÃ¡ch 1: Sá»­ dá»¥ng cv2.inRange Ä‘á»ƒ báº¯t cÃ¡c mÃ u náº±m trong má»™t khoáº£ng nÃ o Ä‘Ã³ --> khÃ¡ nhiá»…u vÃ  khÃ³ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh range mÃ u. CÃ¡ch 2: preprocess táº¥m áº£nh (blur: giáº£m nhiá»…u, thay Ä‘á»•i contrast: nháº¥n máº¡nh khÃ¡c biá»‡t), sau Ä‘Ã³ chia áº£nh thÃ nh cÃ¡c ma tráº­n 3x3 hoáº·c 4x4 Ä‘á»ƒ so sÃ¡nh khÃ¡c biá»‡t tá»«ng pháº§n. Thuáº­t toÃ¡n so sÃ¡nh sá»­ dá»¥ng lÃ  SSIM (Structural similarity index). Qua nhiá»u láº§n thá»­, cÃ¡ch 2 tá» ra vÆ°á»£t trá»™i hÆ¡n nhÆ°ng cÃ³ má»™t sá»‘ háº¡n cháº¿: KhÃ¡ nháº¡y vá» sá»± khÃ¡c biá»‡t vá» vá»‹ trÃ­ chiáº¿c giÃ y: 2 giÃ y giá»‘ng mÃ u nhÆ°ng hÆ¡i lá»‡ch nhau chÃºt thÃ¬ SSIM cÅ©ng xÃ¡c Ä‘á»‹nh lÃ  khÃ¡c nhau KhÃ´ng thá»ƒ Ä‘áº£m báº£o cÃ¡c láº§n cháº¡y detect giÃ y Ä‘á»u cÃ¹ng náº±m chÃ­nh xÃ¡c má»™t vá»‹ trÃ­. Mong nháº­n Ä‘Æ°á»£c Ã½ kiáº¿n cá»§a má»i ngÆ°á»i vá» phÆ°Æ¡ng hÆ°á»›ng cho bÃ i toÃ¡n thá»© 2. VÃ¬ lÆ°á»£ng data khÃ´ng nhiá»u nÃªn team chÆ°a nghÄ© Ä‘Æ°á»£c cÃ¡ch sá»­ dá»¥ng deep learning nhÆ° tháº¿ nÃ o. Team xin cáº£m Æ¡n",#ComputerVision	#OpenCV	#DeepLearning,,,,
"Xin chÃ o má»i ngÆ°á»i.
Em Ä‘ang lÃ m vá» nháº­n dáº¡ng biá»ƒn sá»‘ xe. Sau khi tÃ¡ch Ä‘Æ°á»£c biá»ƒn sá»‘ ra khá»i áº£nh thÃ¬ cÃ²n 1 cÃ´ng Ä‘oáº¡n ná»¯a lÃ  tá»« áº£nh Ä‘Ã³ mÃ  suy ra Ä‘Æ°á»£c text biá»ƒn sá»‘ xe (dáº¡ng nhÆ° 63-B9 99999) thÃ¬ hiá»‡n táº¡i em khÃ´ng biáº¿t dÃ¹ng cÃ¡i gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ nháº­n diá»‡n ra Ä‘Æ°á»£c nhÆ° váº­y. (trá»« OCR).
Má»i ngÆ°á»i cho em Ã­t lá»i khuyÃªn vÃ  hÆ°á»›ng dáº«n vá»›i áº¡. Em xin cáº£m Æ¡n",Xin chÃ o má»i ngÆ°á»i. Em Ä‘ang lÃ m vá» nháº­n dáº¡ng biá»ƒn sá»‘ xe. Sau khi tÃ¡ch Ä‘Æ°á»£c biá»ƒn sá»‘ ra khá»i áº£nh thÃ¬ cÃ²n 1 cÃ´ng Ä‘oáº¡n ná»¯a lÃ  tá»« áº£nh Ä‘Ã³ mÃ  suy ra Ä‘Æ°á»£c text biá»ƒn sá»‘ xe (dáº¡ng nhÆ° 63-B9 99999) thÃ¬ hiá»‡n táº¡i em khÃ´ng biáº¿t dÃ¹ng cÃ¡i gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ nháº­n diá»‡n ra Ä‘Æ°á»£c nhÆ° váº­y. (trá»« OCR). Má»i ngÆ°á»i cho em Ã­t lá»i khuyÃªn vÃ  hÆ°á»›ng dáº«n vá»›i áº¡. Em xin cáº£m Æ¡n,,,,,
Má»i má»i ngÆ°á»i cÃ¹ng join chung nha,Má»i má»i ngÆ°á»i cÃ¹ng join chung nha,,,,,
"(Deep learning implementation on Pytorch)
Vá»›i má»™t máº¡ng neural nhiá»u lá»›p, thÃ´ng thÆ°á»ng khi ta muá»‘n láº¥y output cá»§a cÃ¡c hidden layer thÃ¬ pháº£i Ä‘áº·t tÃªn cho nÃ³ rá»“i má»›i dá»±a vÃ o tÃªn Ä‘á»ƒ láº¥y output cá»§a layer Ä‘Ã³ Ä‘Æ°á»£c.
Hiá»‡n táº¡i mÃ¬nh Ä‘ang train network vÃ  muá»‘n láº¥y output tá»« má»™t hidden layer nhÆ° á»Ÿ trÃªn nhÆ°ng mÃ¬nh khÃ´ng muá»‘n thay Ä‘á»•i bÃªn trong network.
Bá»Ÿi vÃ¬ náº¿u thay Ä‘á»•i vÃ  Ä‘áº·t tÃªn cÃ¡c layyer muá»‘n láº¥y thÃ´ng tin thÃ¬ lÃºc load pretrained params sáº½ cÃ³ thá»ƒ sinh ra lá»—i ???. MÃ  mÃ¬nh cÅ©ng khÃ´ng muá»‘n train láº¡i tá»« Ä‘áº§u( máº¥t gáº§n cáº£ thÃ¡ng má»›i train Ä‘Æ°á»£c xÃ­u)
Báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ chá»‰ cÃ¡ch cho mÃ¬nh láº¥y output tá»« má»™t layer nÃ o Ä‘Ã³ bÃªn trong neural network Ä‘Æ°á»£c khÃ´ng áº¡?
CÃ¡m Æ¡n.","(Deep learning implementation on Pytorch) Vá»›i má»™t máº¡ng neural nhiá»u lá»›p, thÃ´ng thÆ°á»ng khi ta muá»‘n láº¥y output cá»§a cÃ¡c hidden layer thÃ¬ pháº£i Ä‘áº·t tÃªn cho nÃ³ rá»“i má»›i dá»±a vÃ o tÃªn Ä‘á»ƒ láº¥y output cá»§a layer Ä‘Ã³ Ä‘Æ°á»£c. Hiá»‡n táº¡i mÃ¬nh Ä‘ang train network vÃ  muá»‘n láº¥y output tá»« má»™t hidden layer nhÆ° á»Ÿ trÃªn nhÆ°ng mÃ¬nh khÃ´ng muá»‘n thay Ä‘á»•i bÃªn trong network. Bá»Ÿi vÃ¬ náº¿u thay Ä‘á»•i vÃ  Ä‘áº·t tÃªn cÃ¡c layyer muá»‘n láº¥y thÃ´ng tin thÃ¬ lÃºc load pretrained params sáº½ cÃ³ thá»ƒ sinh ra lá»—i ???. MÃ  mÃ¬nh cÅ©ng khÃ´ng muá»‘n train láº¡i tá»« Ä‘áº§u( máº¥t gáº§n cáº£ thÃ¡ng má»›i train Ä‘Æ°á»£c xÃ­u) Báº¡n nÃ o cÃ³ kinh nghiá»‡m cÃ³ thá»ƒ chá»‰ cÃ¡ch cho mÃ¬nh láº¥y output tá»« má»™t layer nÃ o Ä‘Ã³ bÃªn trong neural network Ä‘Æ°á»£c khÃ´ng áº¡? CÃ¡m Æ¡n.",,,,,
"Hi Everyone,
I'd like to introduce you a video from Deeplearning.AI about GANs. Experts will discuss some of their current projects and the importance and future of GANs and also provide practical career advice for ML practitioners.
Enjoy!
https://www.youtube.com/watch?v=9d4jmPmTWmc","Hi Everyone, I'd like to introduce you a video from Deeplearning.AI about GANs. Experts will discuss some of their current projects and the importance and future of GANs and also provide practical career advice for ML practitioners. Enjoy! https://www.youtube.com/watch?v=9d4jmPmTWmc",,,,,
"#lda2vec
Hi forum, má»i ngÆ°á»i trong nhÃ³m cÃ³ ai tá»«ng lÃ m vá» lda2vec chÆ°a áº¡ ? Em newbie cÃ³ 1 sá»‘ váº¥n Ä‘á» cÃ²n tháº¯c máº¯c, mong anh chá»‹ chá»‰ giÃ¡o thÃªm:
1, LDA vÃ  lda2vec sá»± khÃ¡c nhau
2, Thuáº­t toÃ¡n cá»§a lda2vec
Má»i ngÆ°á»i chá»‰ cáº§n cháº¥m nháº¹ bÃ i viáº¿t thÃ¬ em sáº½ reply má»™t sá»‘ cÃ¡i ngay áº¡ ! Cáº£m Æ¡n má»i ngÆ°á»i.","Hi forum, má»i ngÆ°á»i trong nhÃ³m cÃ³ ai tá»«ng lÃ m vá» lda2vec chÆ°a áº¡ ? Em newbie cÃ³ 1 sá»‘ váº¥n Ä‘á» cÃ²n tháº¯c máº¯c, mong anh chá»‹ chá»‰ giÃ¡o thÃªm: 1, LDA vÃ  lda2vec sá»± khÃ¡c nhau 2, Thuáº­t toÃ¡n cá»§a lda2vec Má»i ngÆ°á»i chá»‰ cáº§n cháº¥m nháº¹ bÃ i viáº¿t thÃ¬ em sáº½ reply má»™t sá»‘ cÃ¡i ngay áº¡ ! Cáº£m Æ¡n má»i ngÆ°á»i.",#lda2vec,,,,
"KÃ­nh chÃ o cÃ¡c anh em, hÃ´m nay mÃ¬nh há»c tiáº¿p vá» Python cÆ¡ báº£n nÃªn máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng anh em. Hi vá»ng series 6 bÃ i vá» MÃ¬ Python sáº½ giÃºp anh em newbie cÃ²n yáº¿u Python cÃ³ cÆ¡ sá»Ÿ Ä‘á»ƒ dáº¥n thÃ¢n tiáº¿p tá»¥c trÃªn con Ä‘Æ°á»ng AI, ML.
Cáº£m Æ¡n MOD duyá»‡t bÃ i!","KÃ­nh chÃ o cÃ¡c anh em, hÃ´m nay mÃ¬nh há»c tiáº¿p vá» Python cÆ¡ báº£n nÃªn máº¡nh dáº¡n lÃ m clip chia sáº» cÃ¹ng anh em. Hi vá»ng series 6 bÃ i vá» MÃ¬ Python sáº½ giÃºp anh em newbie cÃ²n yáº¿u Python cÃ³ cÆ¡ sá»Ÿ Ä‘á»ƒ dáº¥n thÃ¢n tiáº¿p tá»¥c trÃªn con Ä‘Æ°á»ng AI, ML. Cáº£m Æ¡n MOD duyá»‡t bÃ i!",,,,,
Cáº§n tÃ¬m tÃ i liá»‡u Machine Learning hoáº·c deep learning trÃªn matlab. Mong má»i ngÆ°á»i giá»›i thiá»‡u,Cáº§n tÃ¬m tÃ i liá»‡u Machine Learning hoáº·c deep learning trÃªn matlab. Mong má»i ngÆ°á»i giá»›i thiá»‡u,,,,,
CÃ¡c anh chá»‹ lÃ m cÃ´ng nghiá»‡p rá»“i cÃ³ thá»ƒ chia sáº» cÃ³ khi nÃ o anh chá»‹ lÃ m viá»‡c vá»›i cÃ¡c dá»± Ã¡n thá»±c táº¿ mÃ  lÃ m mÃ£i nhiá»u phÆ°Æ¡ng Ã¡n mÃ  accuracy cá»§a model váº«n khÃ´ng cáº£i thiá»‡n khÃ´ng áº¡. Nháº¥t lÃ  dá»¯ liá»‡u dáº¡ng báº£ng sá»‘ Ä‘áº¥y áº¡. Em tháº¥y nhiá»u lÃºc nÃ³ mÃ´ng lung kinh khá»§ng khiáº¿p áº¡.,CÃ¡c anh chá»‹ lÃ m cÃ´ng nghiá»‡p rá»“i cÃ³ thá»ƒ chia sáº» cÃ³ khi nÃ o anh chá»‹ lÃ m viá»‡c vá»›i cÃ¡c dá»± Ã¡n thá»±c táº¿ mÃ  lÃ m mÃ£i nhiá»u phÆ°Æ¡ng Ã¡n mÃ  accuracy cá»§a model váº«n khÃ´ng cáº£i thiá»‡n khÃ´ng áº¡. Nháº¥t lÃ  dá»¯ liá»‡u dáº¡ng báº£ng sá»‘ Ä‘áº¥y áº¡. Em tháº¥y nhiá»u lÃºc nÃ³ mÃ´ng lung kinh khá»§ng khiáº¿p áº¡.,,,,,
"chÃ o má»i ngÆ°á»i!
CoÌ báº¡n naÌ€o Training nháº­n diá»‡n máº·t ngÆ°á»i báº±ng C++ chÆ°a aÌ£?
Cho mÃ¬nh xin taÌ€i liÃªÌ£u hoÄƒÌ£c hÆ°Æ¡Ìng dÃ¢Ìƒn vá»›i ah,
mÃ¬nh cÃ³ xem Opencv nhÆ°ng toÃ n lÃ  code python, chÆ°a tiÌ€m Ä‘Æ°Æ¡Ì£c hÆ°Æ¡Ìng dÃ¢Ìƒn nÃ o vá» C++ cáº£.
cáº£m Æ¡n moÌ£i ngÆ°Æ¡Ì€i!","chÃ o má»i ngÆ°á»i! CoÌ báº¡n naÌ€o Training nháº­n diá»‡n máº·t ngÆ°á»i báº±ng C++ chÆ°a aÌ£? Cho mÃ¬nh xin taÌ€i liÃªÌ£u hoÄƒÌ£c hÆ°Æ¡Ìng dÃ¢Ìƒn vá»›i ah, mÃ¬nh cÃ³ xem Opencv nhÆ°ng toÃ n lÃ  code python, chÆ°a tiÌ€m Ä‘Æ°Æ¡Ì£c hÆ°Æ¡Ìng dÃ¢Ìƒn nÃ o vá» C++ cáº£. cáº£m Æ¡n moÌ£i ngÆ°Æ¡Ì€i!",,,,,
"Cho em há»i má»™t chÃºt thÃ´ng tin:
Em Ä‘ang muá»‘n lÃ m há»c mÃ¡y vá» stock market thÃ¬ cÃ³ sÃ¡ch nÃ o cÆ¡ báº£n vá» nÃ y khÃ´ng áº¡? Vá» khoáº£n data thÃ¬ nÃªn láº¥y á»Ÿ Ä‘Ã¢u áº¡.
Anh chá»‹ cÃ³ biáº¿t group nÃ o chuyÃªn vá» há»c mÃ¡y vá» kinh táº¿ hay tÃ i chÃ­nh khÃ´ng áº¡?
Em Ä‘ang cháº­p chá»¯ng bÆ°á»›c vÃ o tÃ¬m hiá»ƒu nÃªn tinh tháº§n váº«n lÃ  cÃ y tá»« sá»‘ 0 áº¡.
Em trÃ¢n trá»ng cáº£m Æ¡n.",Cho em há»i má»™t chÃºt thÃ´ng tin: Em Ä‘ang muá»‘n lÃ m há»c mÃ¡y vá» stock market thÃ¬ cÃ³ sÃ¡ch nÃ o cÆ¡ báº£n vá» nÃ y khÃ´ng áº¡? Vá» khoáº£n data thÃ¬ nÃªn láº¥y á»Ÿ Ä‘Ã¢u áº¡. Anh chá»‹ cÃ³ biáº¿t group nÃ o chuyÃªn vá» há»c mÃ¡y vá» kinh táº¿ hay tÃ i chÃ­nh khÃ´ng áº¡? Em Ä‘ang cháº­p chá»¯ng bÆ°á»›c vÃ o tÃ¬m hiá»ƒu nÃªn tinh tháº§n váº«n lÃ  cÃ y tá»« sá»‘ 0 áº¡. Em trÃ¢n trá»ng cáº£m Æ¡n.,,,,,
"[Chia sáº» lá»i giáº£i cuá»™c thi Kalapa's CreditScoring Challenge For Students]
Cuá»™c thi Há»c mÃ¡y dÃ nh cho sinh viÃªn: Kalapa's CreditScoring For Students (https://challenge.kalapa.vn) Ä‘Ã£ káº¿t thÃºc vÃ  tÃ¬m Ä‘Æ°á»£c chá»§ nhÃ¢n cÃ¡c giáº£i cao nháº¥t.
DÆ°á»›i Ä‘Ã¢y lÃ  lá»i giáº£i cá»§a cÃ¡c Ä‘á»™i Ä‘áº¡t giáº£i, má»i cÃ¡c báº¡n tham kháº£o:
+ Giáº£i Äá»“ng Äá»™i - #1 - https://www.facebook.com/groups/615987485856981/permalink/791532624969132/
+ Giáº£i Äá»“ng Äá»™i - #2 - https://www.facebook.com/groups/615987485856981/permalink/792334541555607/
+ Giáº£i Äá»“ng Äá»™i - #3 - https://www.facebook.com/groups/615987485856981/permalink/791755111613550/
+ Giáº£i Äá»“ng Äá»™i - #4 - https://www.facebook.com/groups/615987485856981/permalink/793195211469540/
+ Giáº£i Äá»“ng Äá»™i - #5 - https://www.facebook.com/groups/615987485856981/permalink/793202004802194/
+ Giáº£i Äá»“ng Äá»™i - #6 - https://www.facebook.com/groups/615987485856981/permalink/792307464891648/
+ Giáº£i Äá»“ng Äá»™i - #7 - https://www.facebook.com/groups/615987485856981/permalink/793219171467144/
+ Giáº£i Äá»“ng Äá»™i - #8 - https://www.facebook.com/groups/615987485856981/permalink/793121468143581/
+ Giáº£i Äá»“ng Äá»™i - #9 - https://www.facebook.com/groups/615987485856981/permalink/793114414810953/
+ Giáº£i Äá»“ng Äá»™i - #10 - https://www.facebook.com/groups/615987485856981/permalink/791563901632671/
+ Giáº£i CÃ¡ NhÃ¢n - #1 - https://www.facebook.com/groups/615987485856981/permalink/791503054972089/
+ Giáº£i CÃ¡ NhÃ¢n - #3 - https://www.facebook.com/groups/615987485856981/permalink/793796124742782/
+ Giáº£i theo trÆ°á»ng - #10 - https://www.facebook.com/groups/615987485856981/permalink/793881651400896/

NgoÃ i ra, Lá»… trao giáº£i cuá»™c thi cÅ©ng Ä‘Æ°á»£c tá»• chá»©c vÃ o 8h30 thá»© 7 tuáº§n nÃ y (03/10/2020), má»i cÃ¡c báº¡n tham dá»±.
ğŸ“Œ Link sá»± kiá»‡n: https://fb.me/e/4JKfP42S7
ğŸ“Œ Ná»™i dung:
+ CÃ¡c Ä‘á»™i Ä‘áº¡t giáº£i trÃ¬nh bÃ y lá»i giáº£i. Há»i Ä‘Ã¡p vÃ  giao lÆ°u giá»¯a cÃ¡c Ä‘á»™i.
+ Giao lÆ°u vá»›i cÃ¡c khÃ¡ch má»i vá» lá»™ trÃ¬nh phÃ¡t triá»ƒn trong ngÃ nh Data Science.
ğŸ“Œ CÃ¡c khÃ¡ch má»i cá»§a chÆ°Æ¡ng trÃ¬nh:
ğŸ‘¨â€ğŸ’» Anh Tuáº¥n Nguyá»…n: Founder AI For Everyone
ğŸ‘¨â€ğŸ’» Anh Kháº£i Mai: Senior Data Engineer táº¡i AImesoft
ğŸ‘¨â€ğŸ’» Anh Pháº¡m ÄÃ¬nh KhÃ¡nh: Founder Khanh Blog, DataScientist táº¡i Vincomerce
ğŸ“Œ Äá»‘i tÆ°á»£ng phÃ¹ há»£p tham gia chÆ°Æ¡ng trÃ¬nh:
CÃ¡c Ä‘á»™i tham gia cuá»™c thi Kalapa's CreditScoring Challenge For Students
CÃ¡c báº¡n sinh viÃªn/Ä‘Ã£ ra trÆ°á»ng cÃ³ mong muá»‘n tÃ¬m hiá»ƒu vÃ  Ä‘á»‹nh hÆ°á»›ng sáº½ theo Machine Learning/Khoa há»c dá»¯ liá»‡u. CÃ¡c khÃ¡ch má»i sáº½ giÃºp Ä‘á»¡ cÃ¡c báº¡n trong viá»‡c Ä‘á»‹nh hÆ°á»›ng vÃ  xÃ¢y dá»±ng lá»™ trÃ¬nh.
ğŸ“ŒğŸ“ŒğŸ“Œ Link Ä‘Äƒng kÃ½ tham gia sá»± kiá»‡n váº«n Ä‘ang má»Ÿ: https://forms.gle/9L7nDua3wjVY6YYe6.
 â€” vá»›i Tuan Nguyen vÃ  3 ngÆ°á»i khÃ¡c.","[Chia sáº» lá»i giáº£i cuá»™c thi Kalapa's CreditScoring Challenge For Students] Cuá»™c thi Há»c mÃ¡y dÃ nh cho sinh viÃªn: Kalapa's CreditScoring For Students (https://challenge.kalapa.vn) Ä‘Ã£ káº¿t thÃºc vÃ  tÃ¬m Ä‘Æ°á»£c chá»§ nhÃ¢n cÃ¡c giáº£i cao nháº¥t. DÆ°á»›i Ä‘Ã¢y lÃ  lá»i giáº£i cá»§a cÃ¡c Ä‘á»™i Ä‘áº¡t giáº£i, má»i cÃ¡c báº¡n tham kháº£o: + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/791532624969132/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/792334541555607/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/791755111613550/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/793195211469540/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/793202004802194/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/792307464891648/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/793219171467144/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/793121468143581/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/793114414810953/ + Giáº£i Äá»“ng Äá»™i - - https://www.facebook.com/groups/615987485856981/permalink/791563901632671/ + Giáº£i CÃ¡ NhÃ¢n - - https://www.facebook.com/groups/615987485856981/permalink/791503054972089/ + Giáº£i CÃ¡ NhÃ¢n - - https://www.facebook.com/groups/615987485856981/permalink/793796124742782/ + Giáº£i theo trÆ°á»ng - - https://www.facebook.com/groups/615987485856981/permalink/793881651400896/ NgoÃ i ra, Lá»… trao giáº£i cuá»™c thi cÅ©ng Ä‘Æ°á»£c tá»• chá»©c vÃ o 8h30 thá»© 7 tuáº§n nÃ y (03/10/2020), má»i cÃ¡c báº¡n tham dá»±. Link sá»± kiá»‡n: https://fb.me/e/4JKfP42S7 Ná»™i dung: + CÃ¡c Ä‘á»™i Ä‘áº¡t giáº£i trÃ¬nh bÃ y lá»i giáº£i. Há»i Ä‘Ã¡p vÃ  giao lÆ°u giá»¯a cÃ¡c Ä‘á»™i. + Giao lÆ°u vá»›i cÃ¡c khÃ¡ch má»i vá» lá»™ trÃ¬nh phÃ¡t triá»ƒn trong ngÃ nh Data Science. CÃ¡c khÃ¡ch má»i cá»§a chÆ°Æ¡ng trÃ¬nh: Anh Tuáº¥n Nguyá»…n: Founder AI For Everyone Anh Kháº£i Mai: Senior Data Engineer táº¡i AImesoft Anh Pháº¡m ÄÃ¬nh KhÃ¡nh: Founder Khanh Blog, DataScientist táº¡i Vincomerce Äá»‘i tÆ°á»£ng phÃ¹ há»£p tham gia chÆ°Æ¡ng trÃ¬nh: CÃ¡c Ä‘á»™i tham gia cuá»™c thi Kalapa's CreditScoring Challenge For Students CÃ¡c báº¡n sinh viÃªn/Ä‘Ã£ ra trÆ°á»ng cÃ³ mong muá»‘n tÃ¬m hiá»ƒu vÃ  Ä‘á»‹nh hÆ°á»›ng sáº½ theo Machine Learning/Khoa há»c dá»¯ liá»‡u. CÃ¡c khÃ¡ch má»i sáº½ giÃºp Ä‘á»¡ cÃ¡c báº¡n trong viá»‡c Ä‘á»‹nh hÆ°á»›ng vÃ  xÃ¢y dá»±ng lá»™ trÃ¬nh. Link Ä‘Äƒng kÃ½ tham gia sá»± kiá»‡n váº«n Ä‘ang má»Ÿ: https://forms.gle/9L7nDua3wjVY6YYe6. â€” vá»›i Tuan Nguyen vÃ  3 ngÆ°á»i khÃ¡c.",#1	#2	#3	#4	#5	#6	#7	#8	#9	#10	#1	#3	#10,,,,
"ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ trÃ² chuyá»‡n vá»›i bÃ¡c Jeff Dean (GiÃ¡m Ä‘á»‘c Google AI) vÃ  anh BÃ¹i Háº£i HÆ°ng (Viá»‡n trÆ°á»Ÿng VinAI) vá» má»™t sá»‘ chá»§ Ä‘á» xoay quanh viá»‡c phÃ¡t triá»ƒn AI táº¡i Viá»‡t Nam. Buá»•i nÃ³i chuyá»‡n hoÃ n toÃ n báº±ng tiáº¿ng Anh, cÃ³ má»™t sá»‘ báº¡n khÃ´ng theo dÃµi Ä‘Æ°á»£c, nÃªn chÃºng mÃ¬nh Ä‘Ã£ hoÃ n thÃ nh phá»¥ Ä‘á» tiáº¿ng Viá»‡t vÃ  Ä‘Äƒng táº£i táº¡i bit.ly/JeffDeanInVietnam. Náº¿u báº¡n cÃ³ gá»£i Ã½ gÃ¬ cho báº£n dá»‹ch tá»‘t hÆ¡n thÃ¬ hÃ£y nháº¯n mÃ¬nh nha! Buá»•i nÃ³i chuyá»‡n dÃ i, nhiá»u tá»« chuyÃªn ngÃ nh, vÃ  dá»‹ch tá»« vÄƒn nÃ³i tiáº¿ng Anh, nÃªn khÃ´ng trÃ¡nh khá»i sai sÃ³t. Cáº£m Æ¡n má»i ngÆ°á»i.","ChÃ o má»i ngÆ°á»i, mÃ¬nh cÃ³ trÃ² chuyá»‡n vá»›i bÃ¡c Jeff Dean (GiÃ¡m Ä‘á»‘c Google AI) vÃ  anh BÃ¹i Háº£i HÆ°ng (Viá»‡n trÆ°á»Ÿng VinAI) vá» má»™t sá»‘ chá»§ Ä‘á» xoay quanh viá»‡c phÃ¡t triá»ƒn AI táº¡i Viá»‡t Nam. Buá»•i nÃ³i chuyá»‡n hoÃ n toÃ n báº±ng tiáº¿ng Anh, cÃ³ má»™t sá»‘ báº¡n khÃ´ng theo dÃµi Ä‘Æ°á»£c, nÃªn chÃºng mÃ¬nh Ä‘Ã£ hoÃ n thÃ nh phá»¥ Ä‘á» tiáº¿ng Viá»‡t vÃ  Ä‘Äƒng táº£i táº¡i bit.ly/JeffDeanInVietnam. Náº¿u báº¡n cÃ³ gá»£i Ã½ gÃ¬ cho báº£n dá»‹ch tá»‘t hÆ¡n thÃ¬ hÃ£y nháº¯n mÃ¬nh nha! Buá»•i nÃ³i chuyá»‡n dÃ i, nhiá»u tá»« chuyÃªn ngÃ nh, vÃ  dá»‹ch tá»« vÄƒn nÃ³i tiáº¿ng Anh, nÃªn khÃ´ng trÃ¡nh khá»i sai sÃ³t. Cáº£m Æ¡n má»i ngÆ°á»i.",,,,,
"MÃ¬nh xin chia sáº» Note cÃ¡ nhÃ¢n vá» ngÃ nh Bioinformatic vÃ  Big Data, Machine Learning.
Ãt ngÆ°á»i biáº¿t ráº±ng, hiá»‡n nay, Bioinfo Ä‘á»©ng top Ä‘áº§u vá» khá»‘i lÆ°á»£ng dá»¯ liá»‡u sinh ra vÃ  lÆ°u trá»¯ hÃ ng nÄƒm trÃªn tháº¿ giá»›i. CÃ¡c bÃ i toÃ¡n cáº§n giáº£i quyáº¿t trong Bioinfo thá»±c ra ráº¥t cáº§n nhá»¯ng cÃ´ng cá»¥, nhá»¯ng Ã½ tÆ°á»Ÿng má»›i Ä‘á»ƒ giáº£i quyáº¿t. VÃ­ dá»¥ nhÆ° bÃ i toÃ¡n vá» Y há»c chÃ­nh xÃ¡c, khi cáº§n tÃ¬m nhá»¯ng important feature. Hoáº·c khi cáº§n xÃ¢y dá»±ng bá»™ gen tham chiáº¿u, bÃ i toÃ¡n string assembly.
Hi vá»ng note cá»§a mÃ¬nh mang láº¡i thÃ´ng tin cho cÃ¡c báº¡n mong muá»‘n Ã¡p dá»¥ng ML/DL vÃ o má»™t lÄ©nh vá»±c vá»«a má»›i máº», vá»«a thÃ¡ch thá»©c.

https://www.facebook.com/notes/thanh-nguyen/big-data-trong-m%E1%BB%97i-ch%C3%BAng-ta/3609643259048929/

P/s: NgÃ y mai sáº½ cÃ³ toáº¡ Ä‘Ã m vá» Y há»c chÃ­nh xÃ¡c vÃ  giá»›i thiá»‡u vá» cá»•ng thÃ´ng tin cá»§a dá»± Ã¡n 1000 há»‡ gen Viá»‡t Nam (really really big data), báº¡n nÃ o cÃ³ nhu cáº§u cÃ³ thá»ƒ theo dÃµi táº¡i Ä‘Ã¢y nhÃ©: https://www.facebook.com/events/384333912564581/388122885519017/","MÃ¬nh xin chia sáº» Note cÃ¡ nhÃ¢n vá» ngÃ nh Bioinformatic vÃ  Big Data, Machine Learning. Ãt ngÆ°á»i biáº¿t ráº±ng, hiá»‡n nay, Bioinfo Ä‘á»©ng top Ä‘áº§u vá» khá»‘i lÆ°á»£ng dá»¯ liá»‡u sinh ra vÃ  lÆ°u trá»¯ hÃ ng nÄƒm trÃªn tháº¿ giá»›i. CÃ¡c bÃ i toÃ¡n cáº§n giáº£i quyáº¿t trong Bioinfo thá»±c ra ráº¥t cáº§n nhá»¯ng cÃ´ng cá»¥, nhá»¯ng Ã½ tÆ°á»Ÿng má»›i Ä‘á»ƒ giáº£i quyáº¿t. VÃ­ dá»¥ nhÆ° bÃ i toÃ¡n vá» Y há»c chÃ­nh xÃ¡c, khi cáº§n tÃ¬m nhá»¯ng important feature. Hoáº·c khi cáº§n xÃ¢y dá»±ng bá»™ gen tham chiáº¿u, bÃ i toÃ¡n string assembly. Hi vá»ng note cá»§a mÃ¬nh mang láº¡i thÃ´ng tin cho cÃ¡c báº¡n mong muá»‘n Ã¡p dá»¥ng ML/DL vÃ o má»™t lÄ©nh vá»±c vá»«a má»›i máº», vá»«a thÃ¡ch thá»©c. https://www.facebook.com/notes/thanh-nguyen/big-data-trong-m%E1%BB%97i-ch%C3%BAng-ta/3609643259048929/ P/s: NgÃ y mai sáº½ cÃ³ toáº¡ Ä‘Ã m vá» Y há»c chÃ­nh xÃ¡c vÃ  giá»›i thiá»‡u vá» cá»•ng thÃ´ng tin cá»§a dá»± Ã¡n 1000 há»‡ gen Viá»‡t Nam (really really big data), báº¡n nÃ o cÃ³ nhu cáº§u cÃ³ thá»ƒ theo dÃµi táº¡i Ä‘Ã¢y nhÃ©: https://www.facebook.com/events/384333912564581/388122885519017/",,,,,
"chÃ o cÃ¡c báº¡n, mÃ¬nh muá»‘n tÃ¬m má»™t quyá»ƒn machine learning cÆ¡ báº£n Ä‘á»ƒ Ä‘á»c tá»« Ä‘áº§u, mÃ¬nh lÃ  newbie. cÃ¡c báº¡n giá»›i thiá»‡u giÃºp nhÃ©, thanks","chÃ o cÃ¡c báº¡n, mÃ¬nh muá»‘n tÃ¬m má»™t quyá»ƒn machine learning cÆ¡ báº£n Ä‘á»ƒ Ä‘á»c tá»« Ä‘áº§u, mÃ¬nh lÃ  newbie. cÃ¡c báº¡n giá»›i thiá»‡u giÃºp nhÃ©, thanks",,,,,
Question Answering with deep embedders (such as BERT),Question Answering with deep embedders (such as BERT),,,,,